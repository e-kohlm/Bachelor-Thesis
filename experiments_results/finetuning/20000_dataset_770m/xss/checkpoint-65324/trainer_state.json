{
  "best_metric": 0.9349315068493151,
  "best_model_checkpoint": "../saved_models/xss_770/checkpoint-65324",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 65324,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002143163309044149,
      "grad_norm": 89.96290588378906,
      "learning_rate": 1.999971424489213e-05,
      "loss": 0.9159,
      "step": 1
    },
    {
      "epoch": 0.0021431633090441492,
      "grad_norm": 90.3918685913086,
      "learning_rate": 1.9997142448921276e-05,
      "loss": 0.759,
      "step": 10
    },
    {
      "epoch": 0.0042863266180882984,
      "grad_norm": 3.4894261360168457,
      "learning_rate": 1.999428489784255e-05,
      "loss": 0.5121,
      "step": 20
    },
    {
      "epoch": 0.006429489927132447,
      "grad_norm": 89.67173767089844,
      "learning_rate": 1.9991427346763827e-05,
      "loss": 1.009,
      "step": 30
    },
    {
      "epoch": 0.008572653236176597,
      "grad_norm": 0.6950515508651733,
      "learning_rate": 1.99885697956851e-05,
      "loss": 0.4133,
      "step": 40
    },
    {
      "epoch": 0.010715816545220747,
      "grad_norm": 100.7646484375,
      "learning_rate": 1.9985712244606375e-05,
      "loss": 1.809,
      "step": 50
    },
    {
      "epoch": 0.012858979854264894,
      "grad_norm": 0.40998950600624084,
      "learning_rate": 1.998285469352765e-05,
      "loss": 0.4856,
      "step": 60
    },
    {
      "epoch": 0.015002143163309044,
      "grad_norm": 0.3047834038734436,
      "learning_rate": 1.9979997142448923e-05,
      "loss": 0.2028,
      "step": 70
    },
    {
      "epoch": 0.017145306472353194,
      "grad_norm": 100.90289306640625,
      "learning_rate": 1.99771395913702e-05,
      "loss": 1.4237,
      "step": 80
    },
    {
      "epoch": 0.01928846978139734,
      "grad_norm": 0.5406858921051025,
      "learning_rate": 1.9974282040291474e-05,
      "loss": 0.7975,
      "step": 90
    },
    {
      "epoch": 0.021431633090441493,
      "grad_norm": 0.14907638728618622,
      "learning_rate": 1.9971424489212748e-05,
      "loss": 1.0387,
      "step": 100
    },
    {
      "epoch": 0.02357479639948564,
      "grad_norm": 0.2678329646587372,
      "learning_rate": 1.9968566938134018e-05,
      "loss": 0.5094,
      "step": 110
    },
    {
      "epoch": 0.02571795970852979,
      "grad_norm": 0.09569592773914337,
      "learning_rate": 1.9965709387055296e-05,
      "loss": 0.7897,
      "step": 120
    },
    {
      "epoch": 0.02786112301757394,
      "grad_norm": 0.21808063983917236,
      "learning_rate": 1.996285183597657e-05,
      "loss": 0.4974,
      "step": 130
    },
    {
      "epoch": 0.03000428632661809,
      "grad_norm": 0.02757144533097744,
      "learning_rate": 1.9959994284897843e-05,
      "loss": 0.2212,
      "step": 140
    },
    {
      "epoch": 0.03214744963566224,
      "grad_norm": 0.03818080946803093,
      "learning_rate": 1.9957136733819117e-05,
      "loss": 0.3122,
      "step": 150
    },
    {
      "epoch": 0.03429061294470639,
      "grad_norm": 67.42412567138672,
      "learning_rate": 1.995427918274039e-05,
      "loss": 1.2442,
      "step": 160
    },
    {
      "epoch": 0.036433776253750536,
      "grad_norm": 47.72037124633789,
      "learning_rate": 1.995142163166167e-05,
      "loss": 0.8604,
      "step": 170
    },
    {
      "epoch": 0.03857693956279468,
      "grad_norm": 0.1463678926229477,
      "learning_rate": 1.9948564080582943e-05,
      "loss": 0.4652,
      "step": 180
    },
    {
      "epoch": 0.04072010287183883,
      "grad_norm": 0.11968518793582916,
      "learning_rate": 1.9945706529504216e-05,
      "loss": 0.5812,
      "step": 190
    },
    {
      "epoch": 0.042863266180882986,
      "grad_norm": 48.70382308959961,
      "learning_rate": 1.994284897842549e-05,
      "loss": 0.6492,
      "step": 200
    },
    {
      "epoch": 0.045006429489927134,
      "grad_norm": 49.93838119506836,
      "learning_rate": 1.9939991427346764e-05,
      "loss": 0.2683,
      "step": 210
    },
    {
      "epoch": 0.04714959279897128,
      "grad_norm": 0.09541308879852295,
      "learning_rate": 1.993713387626804e-05,
      "loss": 0.2526,
      "step": 220
    },
    {
      "epoch": 0.04929275610801543,
      "grad_norm": 39.44675827026367,
      "learning_rate": 1.9934276325189316e-05,
      "loss": 0.5086,
      "step": 230
    },
    {
      "epoch": 0.05143591941705958,
      "grad_norm": 45.27381896972656,
      "learning_rate": 1.993141877411059e-05,
      "loss": 0.8199,
      "step": 240
    },
    {
      "epoch": 0.053579082726103726,
      "grad_norm": 1.8982555866241455,
      "learning_rate": 1.9928561223031863e-05,
      "loss": 0.5597,
      "step": 250
    },
    {
      "epoch": 0.05572224603514788,
      "grad_norm": 0.05120470002293587,
      "learning_rate": 1.9925703671953137e-05,
      "loss": 0.4452,
      "step": 260
    },
    {
      "epoch": 0.05786540934419203,
      "grad_norm": 0.06742159277200699,
      "learning_rate": 1.992284612087441e-05,
      "loss": 0.487,
      "step": 270
    },
    {
      "epoch": 0.06000857265323618,
      "grad_norm": 0.042698778212070465,
      "learning_rate": 1.991998856979569e-05,
      "loss": 0.2544,
      "step": 280
    },
    {
      "epoch": 0.062151735962280324,
      "grad_norm": 0.030219191685318947,
      "learning_rate": 1.9917131018716962e-05,
      "loss": 0.2575,
      "step": 290
    },
    {
      "epoch": 0.06429489927132448,
      "grad_norm": 0.3781060576438904,
      "learning_rate": 1.9914273467638236e-05,
      "loss": 0.4979,
      "step": 300
    },
    {
      "epoch": 0.06643806258036862,
      "grad_norm": 0.1584247350692749,
      "learning_rate": 1.991141591655951e-05,
      "loss": 0.7356,
      "step": 310
    },
    {
      "epoch": 0.06858122588941278,
      "grad_norm": 0.05153192579746246,
      "learning_rate": 1.9908558365480784e-05,
      "loss": 0.1546,
      "step": 320
    },
    {
      "epoch": 0.07072438919845692,
      "grad_norm": 0.6504324078559875,
      "learning_rate": 1.9905700814402058e-05,
      "loss": 1.0204,
      "step": 330
    },
    {
      "epoch": 0.07286755250750107,
      "grad_norm": 0.21675576269626617,
      "learning_rate": 1.9902843263323332e-05,
      "loss": 0.619,
      "step": 340
    },
    {
      "epoch": 0.07501071581654523,
      "grad_norm": 0.07112256437540054,
      "learning_rate": 1.9899985712244606e-05,
      "loss": 0.4607,
      "step": 350
    },
    {
      "epoch": 0.07715387912558937,
      "grad_norm": 0.07009671628475189,
      "learning_rate": 1.9897128161165883e-05,
      "loss": 0.2439,
      "step": 360
    },
    {
      "epoch": 0.07929704243463352,
      "grad_norm": 0.1026819720864296,
      "learning_rate": 1.9894270610087157e-05,
      "loss": 0.4716,
      "step": 370
    },
    {
      "epoch": 0.08144020574367766,
      "grad_norm": 0.3368527889251709,
      "learning_rate": 1.989141305900843e-05,
      "loss": 0.6937,
      "step": 380
    },
    {
      "epoch": 0.08358336905272182,
      "grad_norm": 0.04844096302986145,
      "learning_rate": 1.9888555507929705e-05,
      "loss": 0.2132,
      "step": 390
    },
    {
      "epoch": 0.08572653236176597,
      "grad_norm": 0.04852389544248581,
      "learning_rate": 1.988569795685098e-05,
      "loss": 0.5314,
      "step": 400
    },
    {
      "epoch": 0.08786969567081011,
      "grad_norm": 0.43498438596725464,
      "learning_rate": 1.9882840405772253e-05,
      "loss": 0.6905,
      "step": 410
    },
    {
      "epoch": 0.09001285897985427,
      "grad_norm": 0.04663049802184105,
      "learning_rate": 1.987998285469353e-05,
      "loss": 0.5291,
      "step": 420
    },
    {
      "epoch": 0.09215602228889841,
      "grad_norm": 1.084336519241333,
      "learning_rate": 1.9877125303614804e-05,
      "loss": 0.638,
      "step": 430
    },
    {
      "epoch": 0.09429918559794256,
      "grad_norm": 0.27062156796455383,
      "learning_rate": 1.9874267752536078e-05,
      "loss": 0.6057,
      "step": 440
    },
    {
      "epoch": 0.09644234890698672,
      "grad_norm": 0.18492889404296875,
      "learning_rate": 1.9871410201457352e-05,
      "loss": 0.6973,
      "step": 450
    },
    {
      "epoch": 0.09858551221603086,
      "grad_norm": 89.94739532470703,
      "learning_rate": 1.9868552650378626e-05,
      "loss": 0.4219,
      "step": 460
    },
    {
      "epoch": 0.10072867552507501,
      "grad_norm": 45.476890563964844,
      "learning_rate": 1.9865695099299903e-05,
      "loss": 0.9539,
      "step": 470
    },
    {
      "epoch": 0.10287183883411916,
      "grad_norm": 0.02629229985177517,
      "learning_rate": 1.9862837548221177e-05,
      "loss": 0.0033,
      "step": 480
    },
    {
      "epoch": 0.10501500214316331,
      "grad_norm": 0.025573167949914932,
      "learning_rate": 1.985997999714245e-05,
      "loss": 0.7937,
      "step": 490
    },
    {
      "epoch": 0.10715816545220745,
      "grad_norm": 0.1438608318567276,
      "learning_rate": 1.9857122446063725e-05,
      "loss": 0.3903,
      "step": 500
    },
    {
      "epoch": 0.1093013287612516,
      "grad_norm": 37.24038314819336,
      "learning_rate": 1.9854264894985e-05,
      "loss": 0.5942,
      "step": 510
    },
    {
      "epoch": 0.11144449207029576,
      "grad_norm": 1.1532721519470215,
      "learning_rate": 1.9851407343906276e-05,
      "loss": 0.5537,
      "step": 520
    },
    {
      "epoch": 0.1135876553793399,
      "grad_norm": 35.759681701660156,
      "learning_rate": 1.984854979282755e-05,
      "loss": 0.5309,
      "step": 530
    },
    {
      "epoch": 0.11573081868838406,
      "grad_norm": 0.328755259513855,
      "learning_rate": 1.984569224174882e-05,
      "loss": 0.7238,
      "step": 540
    },
    {
      "epoch": 0.1178739819974282,
      "grad_norm": 0.07062864303588867,
      "learning_rate": 1.9842834690670095e-05,
      "loss": 0.0016,
      "step": 550
    },
    {
      "epoch": 0.12001714530647235,
      "grad_norm": 0.012515905313193798,
      "learning_rate": 1.9839977139591372e-05,
      "loss": 0.2566,
      "step": 560
    },
    {
      "epoch": 0.12216030861551651,
      "grad_norm": 0.017847295850515366,
      "learning_rate": 1.9837119588512646e-05,
      "loss": 0.2664,
      "step": 570
    },
    {
      "epoch": 0.12430347192456065,
      "grad_norm": 0.04696369543671608,
      "learning_rate": 1.983426203743392e-05,
      "loss": 0.2562,
      "step": 580
    },
    {
      "epoch": 0.1264466352336048,
      "grad_norm": 0.08974331617355347,
      "learning_rate": 1.9831404486355194e-05,
      "loss": 0.4375,
      "step": 590
    },
    {
      "epoch": 0.12858979854264896,
      "grad_norm": 27.196643829345703,
      "learning_rate": 1.9828546935276468e-05,
      "loss": 0.5748,
      "step": 600
    },
    {
      "epoch": 0.13073296185169309,
      "grad_norm": 0.13185477256774902,
      "learning_rate": 1.9825689384197745e-05,
      "loss": 0.1567,
      "step": 610
    },
    {
      "epoch": 0.13287612516073724,
      "grad_norm": 0.273690789937973,
      "learning_rate": 1.982283183311902e-05,
      "loss": 0.5865,
      "step": 620
    },
    {
      "epoch": 0.1350192884697814,
      "grad_norm": 32.276947021484375,
      "learning_rate": 1.9819974282040293e-05,
      "loss": 0.8493,
      "step": 630
    },
    {
      "epoch": 0.13716245177882555,
      "grad_norm": 0.436480313539505,
      "learning_rate": 1.9817116730961567e-05,
      "loss": 0.5602,
      "step": 640
    },
    {
      "epoch": 0.1393056150878697,
      "grad_norm": 0.16986195743083954,
      "learning_rate": 1.981425917988284e-05,
      "loss": 0.3893,
      "step": 650
    },
    {
      "epoch": 0.14144877839691383,
      "grad_norm": 46.64535903930664,
      "learning_rate": 1.9811401628804118e-05,
      "loss": 0.643,
      "step": 660
    },
    {
      "epoch": 0.143591941705958,
      "grad_norm": 0.09127160906791687,
      "learning_rate": 1.9808544077725392e-05,
      "loss": 0.0017,
      "step": 670
    },
    {
      "epoch": 0.14573510501500214,
      "grad_norm": 0.30635595321655273,
      "learning_rate": 1.9805686526646666e-05,
      "loss": 0.8614,
      "step": 680
    },
    {
      "epoch": 0.1478782683240463,
      "grad_norm": 29.4506893157959,
      "learning_rate": 1.980282897556794e-05,
      "loss": 0.5714,
      "step": 690
    },
    {
      "epoch": 0.15002143163309045,
      "grad_norm": 0.5033556222915649,
      "learning_rate": 1.9799971424489214e-05,
      "loss": 0.4995,
      "step": 700
    },
    {
      "epoch": 0.15216459494213458,
      "grad_norm": 0.07418926805257797,
      "learning_rate": 1.979711387341049e-05,
      "loss": 0.0945,
      "step": 710
    },
    {
      "epoch": 0.15430775825117873,
      "grad_norm": 0.012693729251623154,
      "learning_rate": 1.9794256322331765e-05,
      "loss": 0.2787,
      "step": 720
    },
    {
      "epoch": 0.1564509215602229,
      "grad_norm": 53.98350524902344,
      "learning_rate": 1.979139877125304e-05,
      "loss": 0.4813,
      "step": 730
    },
    {
      "epoch": 0.15859408486926704,
      "grad_norm": 45.4928092956543,
      "learning_rate": 1.9788541220174313e-05,
      "loss": 0.9996,
      "step": 740
    },
    {
      "epoch": 0.1607372481783112,
      "grad_norm": 0.17859363555908203,
      "learning_rate": 1.9785683669095587e-05,
      "loss": 0.647,
      "step": 750
    },
    {
      "epoch": 0.16288041148735533,
      "grad_norm": 37.268150329589844,
      "learning_rate": 1.978282611801686e-05,
      "loss": 0.5532,
      "step": 760
    },
    {
      "epoch": 0.16502357479639948,
      "grad_norm": 0.40673571825027466,
      "learning_rate": 1.9779968566938135e-05,
      "loss": 0.7044,
      "step": 770
    },
    {
      "epoch": 0.16716673810544364,
      "grad_norm": 0.11617811769247055,
      "learning_rate": 1.977711101585941e-05,
      "loss": 0.3513,
      "step": 780
    },
    {
      "epoch": 0.1693099014144878,
      "grad_norm": 0.11685752868652344,
      "learning_rate": 1.9774253464780683e-05,
      "loss": 0.218,
      "step": 790
    },
    {
      "epoch": 0.17145306472353194,
      "grad_norm": 0.06165319308638573,
      "learning_rate": 1.977139591370196e-05,
      "loss": 0.5051,
      "step": 800
    },
    {
      "epoch": 0.17359622803257607,
      "grad_norm": 0.1579606831073761,
      "learning_rate": 1.9768538362623234e-05,
      "loss": 0.4416,
      "step": 810
    },
    {
      "epoch": 0.17573939134162023,
      "grad_norm": 0.07512126117944717,
      "learning_rate": 1.9765680811544508e-05,
      "loss": 0.002,
      "step": 820
    },
    {
      "epoch": 0.17788255465066438,
      "grad_norm": 0.04735911265015602,
      "learning_rate": 1.9762823260465782e-05,
      "loss": 0.1731,
      "step": 830
    },
    {
      "epoch": 0.18002571795970854,
      "grad_norm": 32.13825607299805,
      "learning_rate": 1.9759965709387056e-05,
      "loss": 0.2969,
      "step": 840
    },
    {
      "epoch": 0.1821688812687527,
      "grad_norm": 0.025405097752809525,
      "learning_rate": 1.9757108158308333e-05,
      "loss": 0.2561,
      "step": 850
    },
    {
      "epoch": 0.18431204457779682,
      "grad_norm": 26.404361724853516,
      "learning_rate": 1.9754250607229607e-05,
      "loss": 0.7747,
      "step": 860
    },
    {
      "epoch": 0.18645520788684097,
      "grad_norm": 0.3575984239578247,
      "learning_rate": 1.975139305615088e-05,
      "loss": 0.5867,
      "step": 870
    },
    {
      "epoch": 0.18859837119588513,
      "grad_norm": 0.17407181859016418,
      "learning_rate": 1.9748535505072155e-05,
      "loss": 0.3866,
      "step": 880
    },
    {
      "epoch": 0.19074153450492928,
      "grad_norm": 0.14546282589435577,
      "learning_rate": 1.974567795399343e-05,
      "loss": 0.4112,
      "step": 890
    },
    {
      "epoch": 0.19288469781397344,
      "grad_norm": 0.22171549499034882,
      "learning_rate": 1.9742820402914703e-05,
      "loss": 0.4038,
      "step": 900
    },
    {
      "epoch": 0.19502786112301757,
      "grad_norm": 0.4408980906009674,
      "learning_rate": 1.973996285183598e-05,
      "loss": 0.755,
      "step": 910
    },
    {
      "epoch": 0.19717102443206172,
      "grad_norm": 0.13176989555358887,
      "learning_rate": 1.9737105300757254e-05,
      "loss": 0.1897,
      "step": 920
    },
    {
      "epoch": 0.19931418774110587,
      "grad_norm": 24.167234420776367,
      "learning_rate": 1.9734247749678528e-05,
      "loss": 0.2132,
      "step": 930
    },
    {
      "epoch": 0.20145735105015003,
      "grad_norm": 0.06245633587241173,
      "learning_rate": 1.9731390198599802e-05,
      "loss": 0.2308,
      "step": 940
    },
    {
      "epoch": 0.20360051435919416,
      "grad_norm": 32.15546798706055,
      "learning_rate": 1.9728532647521076e-05,
      "loss": 1.0456,
      "step": 950
    },
    {
      "epoch": 0.2057436776682383,
      "grad_norm": 30.949321746826172,
      "learning_rate": 1.9725675096442353e-05,
      "loss": 0.5033,
      "step": 960
    },
    {
      "epoch": 0.20788684097728247,
      "grad_norm": 0.18624339997768402,
      "learning_rate": 1.9722817545363624e-05,
      "loss": 0.3063,
      "step": 970
    },
    {
      "epoch": 0.21003000428632662,
      "grad_norm": 0.2071845531463623,
      "learning_rate": 1.9719959994284897e-05,
      "loss": 0.3583,
      "step": 980
    },
    {
      "epoch": 0.21217316759537078,
      "grad_norm": 0.09440922737121582,
      "learning_rate": 1.9717102443206175e-05,
      "loss": 0.4501,
      "step": 990
    },
    {
      "epoch": 0.2143163309044149,
      "grad_norm": 0.153070867061615,
      "learning_rate": 1.971424489212745e-05,
      "loss": 0.3527,
      "step": 1000
    },
    {
      "epoch": 0.21645949421345906,
      "grad_norm": 27.176284790039062,
      "learning_rate": 1.9711387341048723e-05,
      "loss": 0.7999,
      "step": 1010
    },
    {
      "epoch": 0.2186026575225032,
      "grad_norm": 0.1467858999967575,
      "learning_rate": 1.9708529789969997e-05,
      "loss": 0.058,
      "step": 1020
    },
    {
      "epoch": 0.22074582083154737,
      "grad_norm": 0.017099350690841675,
      "learning_rate": 1.970567223889127e-05,
      "loss": 0.0008,
      "step": 1030
    },
    {
      "epoch": 0.22288898414059152,
      "grad_norm": 0.04364970326423645,
      "learning_rate": 1.9702814687812544e-05,
      "loss": 0.2689,
      "step": 1040
    },
    {
      "epoch": 0.22503214744963565,
      "grad_norm": 0.024372391402721405,
      "learning_rate": 1.9699957136733822e-05,
      "loss": 0.023,
      "step": 1050
    },
    {
      "epoch": 0.2271753107586798,
      "grad_norm": 0.0928901806473732,
      "learning_rate": 1.9697099585655096e-05,
      "loss": 0.7779,
      "step": 1060
    },
    {
      "epoch": 0.22931847406772396,
      "grad_norm": 0.18967245519161224,
      "learning_rate": 1.969424203457637e-05,
      "loss": 0.3937,
      "step": 1070
    },
    {
      "epoch": 0.23146163737676811,
      "grad_norm": 0.20651385188102722,
      "learning_rate": 1.9691384483497643e-05,
      "loss": 0.5201,
      "step": 1080
    },
    {
      "epoch": 0.23360480068581227,
      "grad_norm": 0.23542837798595428,
      "learning_rate": 1.9688526932418917e-05,
      "loss": 0.5117,
      "step": 1090
    },
    {
      "epoch": 0.2357479639948564,
      "grad_norm": 0.7383787035942078,
      "learning_rate": 1.9685669381340195e-05,
      "loss": 0.2051,
      "step": 1100
    },
    {
      "epoch": 0.23789112730390055,
      "grad_norm": 0.0803312435746193,
      "learning_rate": 1.968281183026147e-05,
      "loss": 0.3967,
      "step": 1110
    },
    {
      "epoch": 0.2400342906129447,
      "grad_norm": 26.110729217529297,
      "learning_rate": 1.9679954279182743e-05,
      "loss": 0.256,
      "step": 1120
    },
    {
      "epoch": 0.24217745392198886,
      "grad_norm": 0.05797630921006203,
      "learning_rate": 1.9677096728104017e-05,
      "loss": 0.2299,
      "step": 1130
    },
    {
      "epoch": 0.24432061723103302,
      "grad_norm": 0.05808686465024948,
      "learning_rate": 1.967423917702529e-05,
      "loss": 0.4553,
      "step": 1140
    },
    {
      "epoch": 0.24646378054007714,
      "grad_norm": 0.0645093247294426,
      "learning_rate": 1.9671381625946568e-05,
      "loss": 0.0026,
      "step": 1150
    },
    {
      "epoch": 0.2486069438491213,
      "grad_norm": 0.03960545361042023,
      "learning_rate": 1.966852407486784e-05,
      "loss": 0.0008,
      "step": 1160
    },
    {
      "epoch": 0.2507501071581654,
      "grad_norm": 0.010519674979150295,
      "learning_rate": 1.9665666523789116e-05,
      "loss": 0.0003,
      "step": 1170
    },
    {
      "epoch": 0.2528932704672096,
      "grad_norm": 0.03238236904144287,
      "learning_rate": 1.966280897271039e-05,
      "loss": 1.0871,
      "step": 1180
    },
    {
      "epoch": 0.25503643377625373,
      "grad_norm": 0.10705415904521942,
      "learning_rate": 1.9659951421631663e-05,
      "loss": 0.2239,
      "step": 1190
    },
    {
      "epoch": 0.2571795970852979,
      "grad_norm": 0.17000390589237213,
      "learning_rate": 1.9657093870552937e-05,
      "loss": 0.6227,
      "step": 1200
    },
    {
      "epoch": 0.25932276039434204,
      "grad_norm": 22.949628829956055,
      "learning_rate": 1.965423631947421e-05,
      "loss": 0.5787,
      "step": 1210
    },
    {
      "epoch": 0.26146592370338617,
      "grad_norm": 0.4322752058506012,
      "learning_rate": 1.9651378768395485e-05,
      "loss": 0.3376,
      "step": 1220
    },
    {
      "epoch": 0.26360908701243035,
      "grad_norm": 23.488018035888672,
      "learning_rate": 1.964852121731676e-05,
      "loss": 0.533,
      "step": 1230
    },
    {
      "epoch": 0.2657522503214745,
      "grad_norm": 0.578793466091156,
      "learning_rate": 1.9645663666238037e-05,
      "loss": 0.6581,
      "step": 1240
    },
    {
      "epoch": 0.26789541363051866,
      "grad_norm": 0.1160513311624527,
      "learning_rate": 1.964280611515931e-05,
      "loss": 0.0066,
      "step": 1250
    },
    {
      "epoch": 0.2700385769395628,
      "grad_norm": 0.030129823833703995,
      "learning_rate": 1.9639948564080584e-05,
      "loss": 0.2564,
      "step": 1260
    },
    {
      "epoch": 0.2721817402486069,
      "grad_norm": 0.04026505723595619,
      "learning_rate": 1.9637091013001858e-05,
      "loss": 0.4963,
      "step": 1270
    },
    {
      "epoch": 0.2743249035576511,
      "grad_norm": 0.13168704509735107,
      "learning_rate": 1.9634233461923132e-05,
      "loss": 0.433,
      "step": 1280
    },
    {
      "epoch": 0.27646806686669523,
      "grad_norm": 0.21769297122955322,
      "learning_rate": 1.963137591084441e-05,
      "loss": 0.3782,
      "step": 1290
    },
    {
      "epoch": 0.2786112301757394,
      "grad_norm": 0.21698619425296783,
      "learning_rate": 1.9628518359765683e-05,
      "loss": 0.5846,
      "step": 1300
    },
    {
      "epoch": 0.28075439348478354,
      "grad_norm": 0.229073628783226,
      "learning_rate": 1.9625660808686957e-05,
      "loss": 0.5831,
      "step": 1310
    },
    {
      "epoch": 0.28289755679382766,
      "grad_norm": 24.19940185546875,
      "learning_rate": 1.962280325760823e-05,
      "loss": 0.5354,
      "step": 1320
    },
    {
      "epoch": 0.28504072010287185,
      "grad_norm": 0.44170862436294556,
      "learning_rate": 1.9619945706529505e-05,
      "loss": 0.2921,
      "step": 1330
    },
    {
      "epoch": 0.287183883411916,
      "grad_norm": 0.07141801714897156,
      "learning_rate": 1.961708815545078e-05,
      "loss": 0.2301,
      "step": 1340
    },
    {
      "epoch": 0.28932704672096016,
      "grad_norm": 0.06372861564159393,
      "learning_rate": 1.9614230604372056e-05,
      "loss": 0.2248,
      "step": 1350
    },
    {
      "epoch": 0.2914702100300043,
      "grad_norm": 19.689922332763672,
      "learning_rate": 1.961137305329333e-05,
      "loss": 0.8651,
      "step": 1360
    },
    {
      "epoch": 0.2936133733390484,
      "grad_norm": 0.17860960960388184,
      "learning_rate": 1.9608515502214604e-05,
      "loss": 0.0038,
      "step": 1370
    },
    {
      "epoch": 0.2957565366480926,
      "grad_norm": 0.08483775705099106,
      "learning_rate": 1.9605657951135878e-05,
      "loss": 0.2329,
      "step": 1380
    },
    {
      "epoch": 0.2978996999571367,
      "grad_norm": 20.87779998779297,
      "learning_rate": 1.9602800400057152e-05,
      "loss": 1.0166,
      "step": 1390
    },
    {
      "epoch": 0.3000428632661809,
      "grad_norm": 0.5387968420982361,
      "learning_rate": 1.9599942848978426e-05,
      "loss": 0.487,
      "step": 1400
    },
    {
      "epoch": 0.30218602657522503,
      "grad_norm": 0.12285159528255463,
      "learning_rate": 1.95970852978997e-05,
      "loss": 0.2078,
      "step": 1410
    },
    {
      "epoch": 0.30432918988426916,
      "grad_norm": 0.07701315730810165,
      "learning_rate": 1.9594227746820974e-05,
      "loss": 0.204,
      "step": 1420
    },
    {
      "epoch": 0.30647235319331334,
      "grad_norm": 0.08484888076782227,
      "learning_rate": 1.959137019574225e-05,
      "loss": 0.2031,
      "step": 1430
    },
    {
      "epoch": 0.30861551650235747,
      "grad_norm": 36.69500732421875,
      "learning_rate": 1.9588512644663525e-05,
      "loss": 0.8468,
      "step": 1440
    },
    {
      "epoch": 0.31075867981140165,
      "grad_norm": 0.3112508952617645,
      "learning_rate": 1.95856550935848e-05,
      "loss": 0.3389,
      "step": 1450
    },
    {
      "epoch": 0.3129018431204458,
      "grad_norm": 0.31254902482032776,
      "learning_rate": 1.9582797542506073e-05,
      "loss": 0.4816,
      "step": 1460
    },
    {
      "epoch": 0.3150450064294899,
      "grad_norm": 0.19980812072753906,
      "learning_rate": 1.9579939991427347e-05,
      "loss": 0.1912,
      "step": 1470
    },
    {
      "epoch": 0.3171881697385341,
      "grad_norm": 0.10618568956851959,
      "learning_rate": 1.957708244034862e-05,
      "loss": 0.2978,
      "step": 1480
    },
    {
      "epoch": 0.3193313330475782,
      "grad_norm": 3.9197542667388916,
      "learning_rate": 1.9574224889269898e-05,
      "loss": 0.6277,
      "step": 1490
    },
    {
      "epoch": 0.3214744963566224,
      "grad_norm": 0.17368218302726746,
      "learning_rate": 1.9571367338191172e-05,
      "loss": 0.1478,
      "step": 1500
    },
    {
      "epoch": 0.3236176596656665,
      "grad_norm": 0.06173722818493843,
      "learning_rate": 1.9568509787112446e-05,
      "loss": 0.223,
      "step": 1510
    },
    {
      "epoch": 0.32576082297471065,
      "grad_norm": 0.06958498060703278,
      "learning_rate": 1.956565223603372e-05,
      "loss": 0.4507,
      "step": 1520
    },
    {
      "epoch": 0.32790398628375483,
      "grad_norm": 0.11428883671760559,
      "learning_rate": 1.9562794684954994e-05,
      "loss": 0.212,
      "step": 1530
    },
    {
      "epoch": 0.33004714959279896,
      "grad_norm": 0.09939656406641006,
      "learning_rate": 1.955993713387627e-05,
      "loss": 0.2195,
      "step": 1540
    },
    {
      "epoch": 0.33219031290184314,
      "grad_norm": 0.12885485589504242,
      "learning_rate": 1.9557079582797545e-05,
      "loss": 0.3775,
      "step": 1550
    },
    {
      "epoch": 0.33433347621088727,
      "grad_norm": 0.14752669632434845,
      "learning_rate": 1.955422203171882e-05,
      "loss": 0.4116,
      "step": 1560
    },
    {
      "epoch": 0.3364766395199314,
      "grad_norm": 150.24148559570312,
      "learning_rate": 1.9551364480640093e-05,
      "loss": 0.4712,
      "step": 1570
    },
    {
      "epoch": 0.3386198028289756,
      "grad_norm": 18.84168815612793,
      "learning_rate": 1.9548506929561367e-05,
      "loss": 0.3393,
      "step": 1580
    },
    {
      "epoch": 0.3407629661380197,
      "grad_norm": 0.11048439145088196,
      "learning_rate": 1.9545649378482644e-05,
      "loss": 0.4751,
      "step": 1590
    },
    {
      "epoch": 0.3429061294470639,
      "grad_norm": 0.050864044576883316,
      "learning_rate": 1.9542791827403918e-05,
      "loss": 0.0016,
      "step": 1600
    },
    {
      "epoch": 0.345049292756108,
      "grad_norm": 0.04256385564804077,
      "learning_rate": 1.9539934276325192e-05,
      "loss": 0.2596,
      "step": 1610
    },
    {
      "epoch": 0.34719245606515214,
      "grad_norm": 0.10192493349313736,
      "learning_rate": 1.9537076725246463e-05,
      "loss": 0.5089,
      "step": 1620
    },
    {
      "epoch": 0.3493356193741963,
      "grad_norm": 0.15114440023899078,
      "learning_rate": 1.953421917416774e-05,
      "loss": 0.4093,
      "step": 1630
    },
    {
      "epoch": 0.35147878268324045,
      "grad_norm": 21.644893646240234,
      "learning_rate": 1.9531361623089014e-05,
      "loss": 0.551,
      "step": 1640
    },
    {
      "epoch": 0.35362194599228464,
      "grad_norm": 0.3115434944629669,
      "learning_rate": 1.9528504072010288e-05,
      "loss": 0.3801,
      "step": 1650
    },
    {
      "epoch": 0.35576510930132876,
      "grad_norm": 0.08891740441322327,
      "learning_rate": 1.9525646520931562e-05,
      "loss": 0.0051,
      "step": 1660
    },
    {
      "epoch": 0.3579082726103729,
      "grad_norm": 0.24990607798099518,
      "learning_rate": 1.9522788969852836e-05,
      "loss": 0.4129,
      "step": 1670
    },
    {
      "epoch": 0.3600514359194171,
      "grad_norm": 0.22664476931095123,
      "learning_rate": 1.9519931418774113e-05,
      "loss": 0.8737,
      "step": 1680
    },
    {
      "epoch": 0.3621945992284612,
      "grad_norm": 0.29805174469947815,
      "learning_rate": 1.9517073867695387e-05,
      "loss": 0.733,
      "step": 1690
    },
    {
      "epoch": 0.3643377625375054,
      "grad_norm": 0.8804098963737488,
      "learning_rate": 1.951421631661666e-05,
      "loss": 0.8109,
      "step": 1700
    },
    {
      "epoch": 0.3664809258465495,
      "grad_norm": 0.28843334317207336,
      "learning_rate": 1.9511358765537935e-05,
      "loss": 0.8075,
      "step": 1710
    },
    {
      "epoch": 0.36862408915559364,
      "grad_norm": 0.11640054732561111,
      "learning_rate": 1.950850121445921e-05,
      "loss": 0.0072,
      "step": 1720
    },
    {
      "epoch": 0.3707672524646378,
      "grad_norm": 0.06295548379421234,
      "learning_rate": 1.9505643663380486e-05,
      "loss": 0.6371,
      "step": 1730
    },
    {
      "epoch": 0.37291041577368195,
      "grad_norm": 21.340574264526367,
      "learning_rate": 1.950278611230176e-05,
      "loss": 0.3813,
      "step": 1740
    },
    {
      "epoch": 0.37505357908272613,
      "grad_norm": 0.20781657099723816,
      "learning_rate": 1.9499928561223034e-05,
      "loss": 0.1703,
      "step": 1750
    },
    {
      "epoch": 0.37719674239177026,
      "grad_norm": 0.07231422513723373,
      "learning_rate": 1.9497071010144308e-05,
      "loss": 0.1583,
      "step": 1760
    },
    {
      "epoch": 0.3793399057008144,
      "grad_norm": 0.13033540546894073,
      "learning_rate": 1.9494213459065582e-05,
      "loss": 0.4409,
      "step": 1770
    },
    {
      "epoch": 0.38148306900985857,
      "grad_norm": 0.18720334768295288,
      "learning_rate": 1.949135590798686e-05,
      "loss": 0.2062,
      "step": 1780
    },
    {
      "epoch": 0.3836262323189027,
      "grad_norm": 0.05543001368641853,
      "learning_rate": 1.9488498356908133e-05,
      "loss": 0.5046,
      "step": 1790
    },
    {
      "epoch": 0.3857693956279469,
      "grad_norm": 0.24061335623264313,
      "learning_rate": 1.9485640805829407e-05,
      "loss": 0.5464,
      "step": 1800
    },
    {
      "epoch": 0.387912558936991,
      "grad_norm": 0.8350532054901123,
      "learning_rate": 1.948278325475068e-05,
      "loss": 0.6334,
      "step": 1810
    },
    {
      "epoch": 0.39005572224603513,
      "grad_norm": 0.05858811363577843,
      "learning_rate": 1.9479925703671955e-05,
      "loss": 0.0038,
      "step": 1820
    },
    {
      "epoch": 0.3921988855550793,
      "grad_norm": 0.04673033580183983,
      "learning_rate": 1.947706815259323e-05,
      "loss": 0.4875,
      "step": 1830
    },
    {
      "epoch": 0.39434204886412344,
      "grad_norm": 0.021452583372592926,
      "learning_rate": 1.9474210601514503e-05,
      "loss": 0.2551,
      "step": 1840
    },
    {
      "epoch": 0.3964852121731676,
      "grad_norm": 0.22393707931041718,
      "learning_rate": 1.9471353050435777e-05,
      "loss": 0.719,
      "step": 1850
    },
    {
      "epoch": 0.39862837548221175,
      "grad_norm": 0.1601196974515915,
      "learning_rate": 1.946849549935705e-05,
      "loss": 0.2096,
      "step": 1860
    },
    {
      "epoch": 0.4007715387912559,
      "grad_norm": 0.21967536211013794,
      "learning_rate": 1.9465637948278328e-05,
      "loss": 0.7468,
      "step": 1870
    },
    {
      "epoch": 0.40291470210030006,
      "grad_norm": 0.09088176488876343,
      "learning_rate": 1.9462780397199602e-05,
      "loss": 0.1342,
      "step": 1880
    },
    {
      "epoch": 0.4050578654093442,
      "grad_norm": 0.07211144268512726,
      "learning_rate": 1.9459922846120876e-05,
      "loss": 0.6027,
      "step": 1890
    },
    {
      "epoch": 0.4072010287183883,
      "grad_norm": 0.0515877828001976,
      "learning_rate": 1.945706529504215e-05,
      "loss": 0.213,
      "step": 1900
    },
    {
      "epoch": 0.4093441920274325,
      "grad_norm": 0.08840687572956085,
      "learning_rate": 1.9454207743963424e-05,
      "loss": 0.2046,
      "step": 1910
    },
    {
      "epoch": 0.4114873553364766,
      "grad_norm": 0.2215026319026947,
      "learning_rate": 1.94513501928847e-05,
      "loss": 0.6755,
      "step": 1920
    },
    {
      "epoch": 0.4136305186455208,
      "grad_norm": 0.877855122089386,
      "learning_rate": 1.9448492641805975e-05,
      "loss": 0.487,
      "step": 1930
    },
    {
      "epoch": 0.41577368195456493,
      "grad_norm": 0.15396586060523987,
      "learning_rate": 1.944563509072725e-05,
      "loss": 0.1058,
      "step": 1940
    },
    {
      "epoch": 0.41791684526360906,
      "grad_norm": 0.029071660712361336,
      "learning_rate": 1.9442777539648523e-05,
      "loss": 0.0012,
      "step": 1950
    },
    {
      "epoch": 0.42006000857265324,
      "grad_norm": 0.01677577756345272,
      "learning_rate": 1.9439919988569797e-05,
      "loss": 0.2463,
      "step": 1960
    },
    {
      "epoch": 0.42220317188169737,
      "grad_norm": 0.09106140583753586,
      "learning_rate": 1.943706243749107e-05,
      "loss": 1.0479,
      "step": 1970
    },
    {
      "epoch": 0.42434633519074155,
      "grad_norm": 0.29832643270492554,
      "learning_rate": 1.9434204886412348e-05,
      "loss": 0.0037,
      "step": 1980
    },
    {
      "epoch": 0.4264894984997857,
      "grad_norm": 0.11484610289335251,
      "learning_rate": 1.9431347335333622e-05,
      "loss": 0.3399,
      "step": 1990
    },
    {
      "epoch": 0.4286326618088298,
      "grad_norm": 0.04348268732428551,
      "learning_rate": 1.9428489784254896e-05,
      "loss": 0.003,
      "step": 2000
    },
    {
      "epoch": 0.430775825117874,
      "grad_norm": 0.014238481409847736,
      "learning_rate": 1.942563223317617e-05,
      "loss": 0.0015,
      "step": 2010
    },
    {
      "epoch": 0.4329189884269181,
      "grad_norm": 0.08036904782056808,
      "learning_rate": 1.9422774682097444e-05,
      "loss": 0.414,
      "step": 2020
    },
    {
      "epoch": 0.4350621517359623,
      "grad_norm": 0.05525243282318115,
      "learning_rate": 1.941991713101872e-05,
      "loss": 0.507,
      "step": 2030
    },
    {
      "epoch": 0.4372053150450064,
      "grad_norm": 0.7435259222984314,
      "learning_rate": 1.941705957993999e-05,
      "loss": 0.3384,
      "step": 2040
    },
    {
      "epoch": 0.43934847835405055,
      "grad_norm": 19.802356719970703,
      "learning_rate": 1.9414202028861265e-05,
      "loss": 0.2607,
      "step": 2050
    },
    {
      "epoch": 0.44149164166309474,
      "grad_norm": 0.28851789236068726,
      "learning_rate": 1.9411344477782543e-05,
      "loss": 0.8046,
      "step": 2060
    },
    {
      "epoch": 0.44363480497213886,
      "grad_norm": 0.1354118287563324,
      "learning_rate": 1.9408486926703817e-05,
      "loss": 0.5225,
      "step": 2070
    },
    {
      "epoch": 0.44577796828118305,
      "grad_norm": 0.008075795136392117,
      "learning_rate": 1.940562937562509e-05,
      "loss": 0.2233,
      "step": 2080
    },
    {
      "epoch": 0.4479211315902272,
      "grad_norm": 0.17780879139900208,
      "learning_rate": 1.9402771824546364e-05,
      "loss": 0.628,
      "step": 2090
    },
    {
      "epoch": 0.4500642948992713,
      "grad_norm": 0.36702555418014526,
      "learning_rate": 1.939991427346764e-05,
      "loss": 0.0055,
      "step": 2100
    },
    {
      "epoch": 0.4522074582083155,
      "grad_norm": 0.07649874687194824,
      "learning_rate": 1.9397056722388912e-05,
      "loss": 0.7711,
      "step": 2110
    },
    {
      "epoch": 0.4543506215173596,
      "grad_norm": 1.2970830202102661,
      "learning_rate": 1.939419917131019e-05,
      "loss": 0.2534,
      "step": 2120
    },
    {
      "epoch": 0.4564937848264038,
      "grad_norm": 0.14961175620555878,
      "learning_rate": 1.9391341620231464e-05,
      "loss": 0.2921,
      "step": 2130
    },
    {
      "epoch": 0.4586369481354479,
      "grad_norm": 0.033541206270456314,
      "learning_rate": 1.9388484069152737e-05,
      "loss": 0.2995,
      "step": 2140
    },
    {
      "epoch": 0.46078011144449205,
      "grad_norm": 0.027767211198806763,
      "learning_rate": 1.938562651807401e-05,
      "loss": 0.0009,
      "step": 2150
    },
    {
      "epoch": 0.46292327475353623,
      "grad_norm": 0.034008223563432693,
      "learning_rate": 1.9382768966995285e-05,
      "loss": 0.0006,
      "step": 2160
    },
    {
      "epoch": 0.46506643806258036,
      "grad_norm": 0.08505546301603317,
      "learning_rate": 1.9379911415916563e-05,
      "loss": 0.4832,
      "step": 2170
    },
    {
      "epoch": 0.46720960137162454,
      "grad_norm": 0.15303148329257965,
      "learning_rate": 1.9377053864837837e-05,
      "loss": 0.7836,
      "step": 2180
    },
    {
      "epoch": 0.46935276468066867,
      "grad_norm": 0.26177433133125305,
      "learning_rate": 1.937419631375911e-05,
      "loss": 0.172,
      "step": 2190
    },
    {
      "epoch": 0.4714959279897128,
      "grad_norm": 19.719263076782227,
      "learning_rate": 1.9371338762680384e-05,
      "loss": 0.5317,
      "step": 2200
    },
    {
      "epoch": 0.473639091298757,
      "grad_norm": 0.10983297228813171,
      "learning_rate": 1.936848121160166e-05,
      "loss": 0.4828,
      "step": 2210
    },
    {
      "epoch": 0.4757822546078011,
      "grad_norm": 0.07677281647920609,
      "learning_rate": 1.9365623660522936e-05,
      "loss": 0.3195,
      "step": 2220
    },
    {
      "epoch": 0.4779254179168453,
      "grad_norm": 0.043667737394571304,
      "learning_rate": 1.936276610944421e-05,
      "loss": 0.1646,
      "step": 2230
    },
    {
      "epoch": 0.4800685812258894,
      "grad_norm": 0.03625429794192314,
      "learning_rate": 1.9359908558365484e-05,
      "loss": 0.0018,
      "step": 2240
    },
    {
      "epoch": 0.48221174453493354,
      "grad_norm": 0.032536860555410385,
      "learning_rate": 1.9357051007286757e-05,
      "loss": 0.1386,
      "step": 2250
    },
    {
      "epoch": 0.4843549078439777,
      "grad_norm": 0.036749739199876785,
      "learning_rate": 1.935419345620803e-05,
      "loss": 0.28,
      "step": 2260
    },
    {
      "epoch": 0.48649807115302185,
      "grad_norm": 16.524885177612305,
      "learning_rate": 1.9351335905129305e-05,
      "loss": 0.4966,
      "step": 2270
    },
    {
      "epoch": 0.48864123446206603,
      "grad_norm": 0.33105137944221497,
      "learning_rate": 1.934847835405058e-05,
      "loss": 0.2227,
      "step": 2280
    },
    {
      "epoch": 0.49078439777111016,
      "grad_norm": 0.4234311878681183,
      "learning_rate": 1.9345620802971853e-05,
      "loss": 0.2303,
      "step": 2290
    },
    {
      "epoch": 0.4929275610801543,
      "grad_norm": 0.013708306476473808,
      "learning_rate": 1.9342763251893127e-05,
      "loss": 0.131,
      "step": 2300
    },
    {
      "epoch": 0.49507072438919847,
      "grad_norm": 0.026399627327919006,
      "learning_rate": 1.9339905700814404e-05,
      "loss": 0.2782,
      "step": 2310
    },
    {
      "epoch": 0.4972138876982426,
      "grad_norm": 0.05039907991886139,
      "learning_rate": 1.933704814973568e-05,
      "loss": 0.4593,
      "step": 2320
    },
    {
      "epoch": 0.4993570510072868,
      "grad_norm": 0.16575859487056732,
      "learning_rate": 1.9334190598656952e-05,
      "loss": 0.5306,
      "step": 2330
    },
    {
      "epoch": 0.5015002143163309,
      "grad_norm": 0.12635259330272675,
      "learning_rate": 1.9331333047578226e-05,
      "loss": 0.3066,
      "step": 2340
    },
    {
      "epoch": 0.503643377625375,
      "grad_norm": 0.030652588233351707,
      "learning_rate": 1.93284754964995e-05,
      "loss": 0.1314,
      "step": 2350
    },
    {
      "epoch": 0.5057865409344192,
      "grad_norm": 0.02501286379992962,
      "learning_rate": 1.9325617945420777e-05,
      "loss": 0.3173,
      "step": 2360
    },
    {
      "epoch": 0.5079297042434634,
      "grad_norm": 0.21278811991214752,
      "learning_rate": 1.932276039434205e-05,
      "loss": 0.7143,
      "step": 2370
    },
    {
      "epoch": 0.5100728675525075,
      "grad_norm": 0.06235656887292862,
      "learning_rate": 1.9319902843263325e-05,
      "loss": 0.2093,
      "step": 2380
    },
    {
      "epoch": 0.5122160308615517,
      "grad_norm": 0.07527477294206619,
      "learning_rate": 1.93170452921846e-05,
      "loss": 0.4599,
      "step": 2390
    },
    {
      "epoch": 0.5143591941705958,
      "grad_norm": 0.18228229880332947,
      "learning_rate": 1.9314187741105873e-05,
      "loss": 0.408,
      "step": 2400
    },
    {
      "epoch": 0.5165023574796399,
      "grad_norm": 0.7808074951171875,
      "learning_rate": 1.931133019002715e-05,
      "loss": 0.631,
      "step": 2410
    },
    {
      "epoch": 0.5186455207886841,
      "grad_norm": 0.25843545794487,
      "learning_rate": 1.9308472638948424e-05,
      "loss": 0.1694,
      "step": 2420
    },
    {
      "epoch": 0.5207886840977283,
      "grad_norm": 0.05799875408411026,
      "learning_rate": 1.93056150878697e-05,
      "loss": 0.0017,
      "step": 2430
    },
    {
      "epoch": 0.5229318474067723,
      "grad_norm": 0.024391211569309235,
      "learning_rate": 1.9302757536790972e-05,
      "loss": 0.254,
      "step": 2440
    },
    {
      "epoch": 0.5250750107158165,
      "grad_norm": 0.057203687727451324,
      "learning_rate": 1.9299899985712246e-05,
      "loss": 0.4969,
      "step": 2450
    },
    {
      "epoch": 0.5272181740248607,
      "grad_norm": 0.05206689611077309,
      "learning_rate": 1.929704243463352e-05,
      "loss": 0.0614,
      "step": 2460
    },
    {
      "epoch": 0.5293613373339049,
      "grad_norm": 0.04884964972734451,
      "learning_rate": 1.9294184883554794e-05,
      "loss": 0.2408,
      "step": 2470
    },
    {
      "epoch": 0.531504500642949,
      "grad_norm": 0.041298408061265945,
      "learning_rate": 1.9291327332476068e-05,
      "loss": 0.5043,
      "step": 2480
    },
    {
      "epoch": 0.5336476639519931,
      "grad_norm": 118.42778778076172,
      "learning_rate": 1.9288469781397342e-05,
      "loss": 0.382,
      "step": 2490
    },
    {
      "epoch": 0.5357908272610373,
      "grad_norm": 0.09352819621562958,
      "learning_rate": 1.928561223031862e-05,
      "loss": 0.2267,
      "step": 2500
    },
    {
      "epoch": 0.5379339905700814,
      "grad_norm": 0.0956602394580841,
      "learning_rate": 1.9282754679239893e-05,
      "loss": 0.1936,
      "step": 2510
    },
    {
      "epoch": 0.5400771538791256,
      "grad_norm": 19.855566024780273,
      "learning_rate": 1.9279897128161167e-05,
      "loss": 0.2218,
      "step": 2520
    },
    {
      "epoch": 0.5422203171881698,
      "grad_norm": 0.06053951010107994,
      "learning_rate": 1.927703957708244e-05,
      "loss": 0.4451,
      "step": 2530
    },
    {
      "epoch": 0.5443634804972138,
      "grad_norm": 0.06238453835248947,
      "learning_rate": 1.9274182026003715e-05,
      "loss": 0.0015,
      "step": 2540
    },
    {
      "epoch": 0.546506643806258,
      "grad_norm": 0.06502863764762878,
      "learning_rate": 1.9271324474924992e-05,
      "loss": 0.3257,
      "step": 2550
    },
    {
      "epoch": 0.5486498071153022,
      "grad_norm": 0.08930671215057373,
      "learning_rate": 1.9268466923846266e-05,
      "loss": 0.1002,
      "step": 2560
    },
    {
      "epoch": 0.5507929704243464,
      "grad_norm": 0.03341120108962059,
      "learning_rate": 1.926560937276754e-05,
      "loss": 0.0009,
      "step": 2570
    },
    {
      "epoch": 0.5529361337333905,
      "grad_norm": 0.026076631620526314,
      "learning_rate": 1.9262751821688814e-05,
      "loss": 0.2529,
      "step": 2580
    },
    {
      "epoch": 0.5550792970424346,
      "grad_norm": 0.0739247053861618,
      "learning_rate": 1.9259894270610088e-05,
      "loss": 0.2443,
      "step": 2590
    },
    {
      "epoch": 0.5572224603514788,
      "grad_norm": 20.484115600585938,
      "learning_rate": 1.9257036719531362e-05,
      "loss": 0.6509,
      "step": 2600
    },
    {
      "epoch": 0.5593656236605229,
      "grad_norm": 0.17278829216957092,
      "learning_rate": 1.925417916845264e-05,
      "loss": 0.0031,
      "step": 2610
    },
    {
      "epoch": 0.5615087869695671,
      "grad_norm": 0.13845030963420868,
      "learning_rate": 1.9251321617373913e-05,
      "loss": 0.1923,
      "step": 2620
    },
    {
      "epoch": 0.5636519502786113,
      "grad_norm": 0.2322407066822052,
      "learning_rate": 1.9248464066295187e-05,
      "loss": 0.604,
      "step": 2630
    },
    {
      "epoch": 0.5657951135876553,
      "grad_norm": 0.5559027791023254,
      "learning_rate": 1.924560651521646e-05,
      "loss": 0.4385,
      "step": 2640
    },
    {
      "epoch": 0.5679382768966995,
      "grad_norm": 0.23403358459472656,
      "learning_rate": 1.9242748964137735e-05,
      "loss": 0.3056,
      "step": 2650
    },
    {
      "epoch": 0.5700814402057437,
      "grad_norm": 0.06463061273097992,
      "learning_rate": 1.9239891413059012e-05,
      "loss": 0.3278,
      "step": 2660
    },
    {
      "epoch": 0.5722246035147879,
      "grad_norm": 0.35245850682258606,
      "learning_rate": 1.9237033861980286e-05,
      "loss": 0.3345,
      "step": 2670
    },
    {
      "epoch": 0.574367766823832,
      "grad_norm": 0.07966911792755127,
      "learning_rate": 1.923417631090156e-05,
      "loss": 0.4469,
      "step": 2680
    },
    {
      "epoch": 0.5765109301328761,
      "grad_norm": 36.242427825927734,
      "learning_rate": 1.9231318759822834e-05,
      "loss": 0.6294,
      "step": 2690
    },
    {
      "epoch": 0.5786540934419203,
      "grad_norm": 0.04735676571726799,
      "learning_rate": 1.9228461208744108e-05,
      "loss": 0.0023,
      "step": 2700
    },
    {
      "epoch": 0.5807972567509644,
      "grad_norm": 17.7862606048584,
      "learning_rate": 1.9225603657665382e-05,
      "loss": 0.4368,
      "step": 2710
    },
    {
      "epoch": 0.5829404200600086,
      "grad_norm": 0.0848601758480072,
      "learning_rate": 1.9222746106586656e-05,
      "loss": 0.4496,
      "step": 2720
    },
    {
      "epoch": 0.5850835833690528,
      "grad_norm": 0.215977281332016,
      "learning_rate": 1.921988855550793e-05,
      "loss": 0.5449,
      "step": 2730
    },
    {
      "epoch": 0.5872267466780968,
      "grad_norm": 19.778640747070312,
      "learning_rate": 1.9217031004429204e-05,
      "loss": 0.2056,
      "step": 2740
    },
    {
      "epoch": 0.589369909987141,
      "grad_norm": 0.15002699196338654,
      "learning_rate": 1.921417345335048e-05,
      "loss": 0.1927,
      "step": 2750
    },
    {
      "epoch": 0.5915130732961852,
      "grad_norm": 0.10587684065103531,
      "learning_rate": 1.9211315902271755e-05,
      "loss": 0.4005,
      "step": 2760
    },
    {
      "epoch": 0.5936562366052294,
      "grad_norm": 0.11117716133594513,
      "learning_rate": 1.920845835119303e-05,
      "loss": 0.4685,
      "step": 2770
    },
    {
      "epoch": 0.5957993999142734,
      "grad_norm": 0.11883113533258438,
      "learning_rate": 1.9205600800114303e-05,
      "loss": 0.0023,
      "step": 2780
    },
    {
      "epoch": 0.5979425632233176,
      "grad_norm": 0.10129962116479874,
      "learning_rate": 1.9202743249035577e-05,
      "loss": 0.0031,
      "step": 2790
    },
    {
      "epoch": 0.6000857265323618,
      "grad_norm": 0.02895081229507923,
      "learning_rate": 1.9199885697956854e-05,
      "loss": 0.0007,
      "step": 2800
    },
    {
      "epoch": 0.6022288898414059,
      "grad_norm": 0.023439565673470497,
      "learning_rate": 1.9197028146878128e-05,
      "loss": 0.5203,
      "step": 2810
    },
    {
      "epoch": 0.6043720531504501,
      "grad_norm": 0.02804138883948326,
      "learning_rate": 1.9194170595799402e-05,
      "loss": 0.6547,
      "step": 2820
    },
    {
      "epoch": 0.6065152164594942,
      "grad_norm": 33.08317947387695,
      "learning_rate": 1.9191313044720676e-05,
      "loss": 0.6183,
      "step": 2830
    },
    {
      "epoch": 0.6086583797685383,
      "grad_norm": 0.5131126046180725,
      "learning_rate": 1.918845549364195e-05,
      "loss": 0.7503,
      "step": 2840
    },
    {
      "epoch": 0.6108015430775825,
      "grad_norm": 29.653881072998047,
      "learning_rate": 1.9185597942563227e-05,
      "loss": 0.2426,
      "step": 2850
    },
    {
      "epoch": 0.6129447063866267,
      "grad_norm": 33.20301055908203,
      "learning_rate": 1.91827403914845e-05,
      "loss": 0.218,
      "step": 2860
    },
    {
      "epoch": 0.6150878696956709,
      "grad_norm": 65.3410873413086,
      "learning_rate": 1.9179882840405775e-05,
      "loss": 0.9233,
      "step": 2870
    },
    {
      "epoch": 0.6172310330047149,
      "grad_norm": 0.48357468843460083,
      "learning_rate": 1.917702528932705e-05,
      "loss": 0.1774,
      "step": 2880
    },
    {
      "epoch": 0.6193741963137591,
      "grad_norm": 7.666858673095703,
      "learning_rate": 1.9174167738248323e-05,
      "loss": 0.3019,
      "step": 2890
    },
    {
      "epoch": 0.6215173596228033,
      "grad_norm": 0.07343824207782745,
      "learning_rate": 1.9171310187169597e-05,
      "loss": 0.2222,
      "step": 2900
    },
    {
      "epoch": 0.6236605229318474,
      "grad_norm": 0.046566806733608246,
      "learning_rate": 1.916845263609087e-05,
      "loss": 0.0438,
      "step": 2910
    },
    {
      "epoch": 0.6258036862408916,
      "grad_norm": 0.10892623662948608,
      "learning_rate": 1.9165595085012145e-05,
      "loss": 0.2173,
      "step": 2920
    },
    {
      "epoch": 0.6279468495499357,
      "grad_norm": 0.08361281454563141,
      "learning_rate": 1.916273753393342e-05,
      "loss": 0.2095,
      "step": 2930
    },
    {
      "epoch": 0.6300900128589798,
      "grad_norm": 0.04395351558923721,
      "learning_rate": 1.9159879982854696e-05,
      "loss": 0.5975,
      "step": 2940
    },
    {
      "epoch": 0.632233176168024,
      "grad_norm": 0.1034475788474083,
      "learning_rate": 1.915702243177597e-05,
      "loss": 0.0014,
      "step": 2950
    },
    {
      "epoch": 0.6343763394770682,
      "grad_norm": 0.027960021048784256,
      "learning_rate": 1.9154164880697244e-05,
      "loss": 0.4738,
      "step": 2960
    },
    {
      "epoch": 0.6365195027861124,
      "grad_norm": 0.04330451041460037,
      "learning_rate": 1.9151307329618518e-05,
      "loss": 0.0024,
      "step": 2970
    },
    {
      "epoch": 0.6386626660951564,
      "grad_norm": 0.06847628951072693,
      "learning_rate": 1.914844977853979e-05,
      "loss": 0.4626,
      "step": 2980
    },
    {
      "epoch": 0.6408058294042006,
      "grad_norm": 74.06883239746094,
      "learning_rate": 1.914559222746107e-05,
      "loss": 0.1818,
      "step": 2990
    },
    {
      "epoch": 0.6429489927132448,
      "grad_norm": 0.03256307914853096,
      "learning_rate": 1.9142734676382343e-05,
      "loss": 0.2016,
      "step": 3000
    },
    {
      "epoch": 0.6450921560222889,
      "grad_norm": 0.021946759894490242,
      "learning_rate": 1.9139877125303617e-05,
      "loss": 0.2409,
      "step": 3010
    },
    {
      "epoch": 0.647235319331333,
      "grad_norm": 0.08527898788452148,
      "learning_rate": 1.913701957422489e-05,
      "loss": 0.2071,
      "step": 3020
    },
    {
      "epoch": 0.6493784826403772,
      "grad_norm": 0.027359846979379654,
      "learning_rate": 1.9134162023146165e-05,
      "loss": 0.1381,
      "step": 3030
    },
    {
      "epoch": 0.6515216459494213,
      "grad_norm": 0.12735724449157715,
      "learning_rate": 1.913130447206744e-05,
      "loss": 0.6334,
      "step": 3040
    },
    {
      "epoch": 0.6536648092584655,
      "grad_norm": 0.3812582790851593,
      "learning_rate": 1.9128446920988716e-05,
      "loss": 0.1369,
      "step": 3050
    },
    {
      "epoch": 0.6558079725675097,
      "grad_norm": 0.040683574974536896,
      "learning_rate": 1.912558936990999e-05,
      "loss": 0.2218,
      "step": 3060
    },
    {
      "epoch": 0.6579511358765537,
      "grad_norm": 1.5170576572418213,
      "learning_rate": 1.9122731818831264e-05,
      "loss": 0.3186,
      "step": 3070
    },
    {
      "epoch": 0.6600942991855979,
      "grad_norm": 0.02514691650867462,
      "learning_rate": 1.9119874267752538e-05,
      "loss": 0.2564,
      "step": 3080
    },
    {
      "epoch": 0.6622374624946421,
      "grad_norm": 156.81414794921875,
      "learning_rate": 1.911701671667381e-05,
      "loss": 0.3184,
      "step": 3090
    },
    {
      "epoch": 0.6643806258036863,
      "grad_norm": 0.07743982970714569,
      "learning_rate": 1.911415916559509e-05,
      "loss": 0.3156,
      "step": 3100
    },
    {
      "epoch": 0.6665237891127304,
      "grad_norm": 0.031016455963253975,
      "learning_rate": 1.9111301614516363e-05,
      "loss": 0.0008,
      "step": 3110
    },
    {
      "epoch": 0.6686669524217745,
      "grad_norm": 0.012824824079871178,
      "learning_rate": 1.9108444063437633e-05,
      "loss": 0.1228,
      "step": 3120
    },
    {
      "epoch": 0.6708101157308187,
      "grad_norm": 0.015229497104883194,
      "learning_rate": 1.910558651235891e-05,
      "loss": 0.0048,
      "step": 3130
    },
    {
      "epoch": 0.6729532790398628,
      "grad_norm": 0.008537587709724903,
      "learning_rate": 1.9102728961280185e-05,
      "loss": 0.0004,
      "step": 3140
    },
    {
      "epoch": 0.675096442348907,
      "grad_norm": 0.008412979543209076,
      "learning_rate": 1.909987141020146e-05,
      "loss": 0.1009,
      "step": 3150
    },
    {
      "epoch": 0.6772396056579512,
      "grad_norm": 38.11996078491211,
      "learning_rate": 1.9097013859122732e-05,
      "loss": 0.9176,
      "step": 3160
    },
    {
      "epoch": 0.6793827689669952,
      "grad_norm": 0.18899789452552795,
      "learning_rate": 1.9094156308044006e-05,
      "loss": 0.9752,
      "step": 3170
    },
    {
      "epoch": 0.6815259322760394,
      "grad_norm": 52.6903190612793,
      "learning_rate": 1.909129875696528e-05,
      "loss": 0.9866,
      "step": 3180
    },
    {
      "epoch": 0.6836690955850836,
      "grad_norm": 28.760164260864258,
      "learning_rate": 1.9088441205886558e-05,
      "loss": 0.6156,
      "step": 3190
    },
    {
      "epoch": 0.6858122588941278,
      "grad_norm": 15.526564598083496,
      "learning_rate": 1.908558365480783e-05,
      "loss": 0.0884,
      "step": 3200
    },
    {
      "epoch": 0.6879554222031719,
      "grad_norm": 22.75364875793457,
      "learning_rate": 1.9082726103729105e-05,
      "loss": 0.2084,
      "step": 3210
    },
    {
      "epoch": 0.690098585512216,
      "grad_norm": 0.03219183161854744,
      "learning_rate": 1.907986855265038e-05,
      "loss": 0.3234,
      "step": 3220
    },
    {
      "epoch": 0.6922417488212602,
      "grad_norm": 22.825672149658203,
      "learning_rate": 1.9077011001571653e-05,
      "loss": 0.2646,
      "step": 3230
    },
    {
      "epoch": 0.6943849121303043,
      "grad_norm": 0.049236051738262177,
      "learning_rate": 1.907415345049293e-05,
      "loss": 0.2522,
      "step": 3240
    },
    {
      "epoch": 0.6965280754393485,
      "grad_norm": 0.05137794837355614,
      "learning_rate": 1.9071295899414205e-05,
      "loss": 0.156,
      "step": 3250
    },
    {
      "epoch": 0.6986712387483927,
      "grad_norm": 1.3417737483978271,
      "learning_rate": 1.906843834833548e-05,
      "loss": 0.115,
      "step": 3260
    },
    {
      "epoch": 0.7008144020574367,
      "grad_norm": 0.03914962708950043,
      "learning_rate": 1.9065580797256752e-05,
      "loss": 0.0043,
      "step": 3270
    },
    {
      "epoch": 0.7029575653664809,
      "grad_norm": 0.023700015619397163,
      "learning_rate": 1.9062723246178026e-05,
      "loss": 0.3368,
      "step": 3280
    },
    {
      "epoch": 0.7051007286755251,
      "grad_norm": 0.03155748173594475,
      "learning_rate": 1.9059865695099304e-05,
      "loss": 0.1719,
      "step": 3290
    },
    {
      "epoch": 0.7072438919845693,
      "grad_norm": 0.026370810344815254,
      "learning_rate": 1.9057008144020578e-05,
      "loss": 0.0007,
      "step": 3300
    },
    {
      "epoch": 0.7093870552936133,
      "grad_norm": 0.057359494268894196,
      "learning_rate": 1.905415059294185e-05,
      "loss": 0.0007,
      "step": 3310
    },
    {
      "epoch": 0.7115302186026575,
      "grad_norm": 0.01315876841545105,
      "learning_rate": 1.9051293041863125e-05,
      "loss": 0.0004,
      "step": 3320
    },
    {
      "epoch": 0.7136733819117017,
      "grad_norm": 0.011587603017687798,
      "learning_rate": 1.90484354907844e-05,
      "loss": 0.4454,
      "step": 3330
    },
    {
      "epoch": 0.7158165452207458,
      "grad_norm": 0.030857985839247704,
      "learning_rate": 1.9045577939705673e-05,
      "loss": 0.6397,
      "step": 3340
    },
    {
      "epoch": 0.71795970852979,
      "grad_norm": 0.08769642561674118,
      "learning_rate": 1.9042720388626947e-05,
      "loss": 0.2436,
      "step": 3350
    },
    {
      "epoch": 0.7201028718388341,
      "grad_norm": 0.04164918512105942,
      "learning_rate": 1.903986283754822e-05,
      "loss": 0.07,
      "step": 3360
    },
    {
      "epoch": 0.7222460351478782,
      "grad_norm": 0.0458548404276371,
      "learning_rate": 1.9037005286469495e-05,
      "loss": 0.2452,
      "step": 3370
    },
    {
      "epoch": 0.7243891984569224,
      "grad_norm": 19.121143341064453,
      "learning_rate": 1.9034147735390772e-05,
      "loss": 0.6044,
      "step": 3380
    },
    {
      "epoch": 0.7265323617659666,
      "grad_norm": 38.00474166870117,
      "learning_rate": 1.9031290184312046e-05,
      "loss": 0.1963,
      "step": 3390
    },
    {
      "epoch": 0.7286755250750108,
      "grad_norm": 0.06413039565086365,
      "learning_rate": 1.902843263323332e-05,
      "loss": 0.4007,
      "step": 3400
    },
    {
      "epoch": 0.7308186883840548,
      "grad_norm": 8.74512767791748,
      "learning_rate": 1.9025575082154594e-05,
      "loss": 0.223,
      "step": 3410
    },
    {
      "epoch": 0.732961851693099,
      "grad_norm": 0.19374877214431763,
      "learning_rate": 1.9022717531075868e-05,
      "loss": 0.4337,
      "step": 3420
    },
    {
      "epoch": 0.7351050150021432,
      "grad_norm": 21.042367935180664,
      "learning_rate": 1.9019859979997145e-05,
      "loss": 0.3422,
      "step": 3430
    },
    {
      "epoch": 0.7372481783111873,
      "grad_norm": 0.3295840322971344,
      "learning_rate": 1.901700242891842e-05,
      "loss": 0.6066,
      "step": 3440
    },
    {
      "epoch": 0.7393913416202315,
      "grad_norm": 0.2512311339378357,
      "learning_rate": 1.9014144877839693e-05,
      "loss": 0.0074,
      "step": 3450
    },
    {
      "epoch": 0.7415345049292756,
      "grad_norm": 0.2234550267457962,
      "learning_rate": 1.9011287326760967e-05,
      "loss": 0.2326,
      "step": 3460
    },
    {
      "epoch": 0.7436776682383197,
      "grad_norm": 0.1229071393609047,
      "learning_rate": 1.900842977568224e-05,
      "loss": 0.3164,
      "step": 3470
    },
    {
      "epoch": 0.7458208315473639,
      "grad_norm": 3.692472457885742,
      "learning_rate": 1.900557222460352e-05,
      "loss": 0.2436,
      "step": 3480
    },
    {
      "epoch": 0.7479639948564081,
      "grad_norm": 7.294286727905273,
      "learning_rate": 1.9002714673524792e-05,
      "loss": 0.2314,
      "step": 3490
    },
    {
      "epoch": 0.7501071581654523,
      "grad_norm": 0.18353371322155,
      "learning_rate": 1.8999857122446066e-05,
      "loss": 0.1573,
      "step": 3500
    },
    {
      "epoch": 0.7522503214744963,
      "grad_norm": 0.062430210411548615,
      "learning_rate": 1.899699957136734e-05,
      "loss": 0.2035,
      "step": 3510
    },
    {
      "epoch": 0.7543934847835405,
      "grad_norm": 0.047735873609781265,
      "learning_rate": 1.8994142020288614e-05,
      "loss": 0.4287,
      "step": 3520
    },
    {
      "epoch": 0.7565366480925847,
      "grad_norm": 0.04550744593143463,
      "learning_rate": 1.8991284469209888e-05,
      "loss": 0.127,
      "step": 3530
    },
    {
      "epoch": 0.7586798114016288,
      "grad_norm": 53.50210189819336,
      "learning_rate": 1.8988426918131165e-05,
      "loss": 0.4858,
      "step": 3540
    },
    {
      "epoch": 0.760822974710673,
      "grad_norm": 0.05600571632385254,
      "learning_rate": 1.8985569367052436e-05,
      "loss": 0.0105,
      "step": 3550
    },
    {
      "epoch": 0.7629661380197171,
      "grad_norm": 0.03148796409368515,
      "learning_rate": 1.898271181597371e-05,
      "loss": 0.0694,
      "step": 3560
    },
    {
      "epoch": 0.7651093013287612,
      "grad_norm": 0.04409944266080856,
      "learning_rate": 1.8979854264894987e-05,
      "loss": 0.1242,
      "step": 3570
    },
    {
      "epoch": 0.7672524646378054,
      "grad_norm": 19.851585388183594,
      "learning_rate": 1.897699671381626e-05,
      "loss": 0.4051,
      "step": 3580
    },
    {
      "epoch": 0.7693956279468496,
      "grad_norm": 0.020660534501075745,
      "learning_rate": 1.8974139162737535e-05,
      "loss": 0.2522,
      "step": 3590
    },
    {
      "epoch": 0.7715387912558938,
      "grad_norm": 0.035090140998363495,
      "learning_rate": 1.897128161165881e-05,
      "loss": 0.1979,
      "step": 3600
    },
    {
      "epoch": 0.7736819545649378,
      "grad_norm": 81.75856018066406,
      "learning_rate": 1.8968424060580083e-05,
      "loss": 0.1247,
      "step": 3610
    },
    {
      "epoch": 0.775825117873982,
      "grad_norm": 24.549890518188477,
      "learning_rate": 1.896556650950136e-05,
      "loss": 1.196,
      "step": 3620
    },
    {
      "epoch": 0.7779682811830262,
      "grad_norm": 0.21313084661960602,
      "learning_rate": 1.8962708958422634e-05,
      "loss": 0.3916,
      "step": 3630
    },
    {
      "epoch": 0.7801114444920703,
      "grad_norm": 11.64712142944336,
      "learning_rate": 1.8959851407343908e-05,
      "loss": 0.2788,
      "step": 3640
    },
    {
      "epoch": 0.7822546078011144,
      "grad_norm": 18.348329544067383,
      "learning_rate": 1.8956993856265182e-05,
      "loss": 0.0649,
      "step": 3650
    },
    {
      "epoch": 0.7843977711101586,
      "grad_norm": 0.06488010287284851,
      "learning_rate": 1.8954136305186456e-05,
      "loss": 0.1076,
      "step": 3660
    },
    {
      "epoch": 0.7865409344192027,
      "grad_norm": 0.029764171689748764,
      "learning_rate": 1.895127875410773e-05,
      "loss": 0.0502,
      "step": 3670
    },
    {
      "epoch": 0.7886840977282469,
      "grad_norm": 0.014506456442177296,
      "learning_rate": 1.8948421203029007e-05,
      "loss": 0.0004,
      "step": 3680
    },
    {
      "epoch": 0.7908272610372911,
      "grad_norm": 19.8331356048584,
      "learning_rate": 1.894556365195028e-05,
      "loss": 0.2712,
      "step": 3690
    },
    {
      "epoch": 0.7929704243463352,
      "grad_norm": 0.02329001948237419,
      "learning_rate": 1.8942706100871555e-05,
      "loss": 0.2783,
      "step": 3700
    },
    {
      "epoch": 0.7951135876553793,
      "grad_norm": 0.028760239481925964,
      "learning_rate": 1.893984854979283e-05,
      "loss": 0.0006,
      "step": 3710
    },
    {
      "epoch": 0.7972567509644235,
      "grad_norm": 0.0360761359333992,
      "learning_rate": 1.8936990998714103e-05,
      "loss": 0.3945,
      "step": 3720
    },
    {
      "epoch": 0.7993999142734677,
      "grad_norm": 0.028418658301234245,
      "learning_rate": 1.893413344763538e-05,
      "loss": 0.2125,
      "step": 3730
    },
    {
      "epoch": 0.8015430775825118,
      "grad_norm": 0.027253812178969383,
      "learning_rate": 1.8931275896556654e-05,
      "loss": 0.2496,
      "step": 3740
    },
    {
      "epoch": 0.8036862408915559,
      "grad_norm": 0.07468383014202118,
      "learning_rate": 1.8928418345477928e-05,
      "loss": 0.437,
      "step": 3750
    },
    {
      "epoch": 0.8058294042006001,
      "grad_norm": 0.24604319036006927,
      "learning_rate": 1.8925560794399202e-05,
      "loss": 0.4151,
      "step": 3760
    },
    {
      "epoch": 0.8079725675096442,
      "grad_norm": 0.11127282679080963,
      "learning_rate": 1.8922703243320476e-05,
      "loss": 0.161,
      "step": 3770
    },
    {
      "epoch": 0.8101157308186884,
      "grad_norm": 0.07177914679050446,
      "learning_rate": 1.891984569224175e-05,
      "loss": 0.1795,
      "step": 3780
    },
    {
      "epoch": 0.8122588941277326,
      "grad_norm": 0.051314014941453934,
      "learning_rate": 1.8916988141163024e-05,
      "loss": 0.154,
      "step": 3790
    },
    {
      "epoch": 0.8144020574367766,
      "grad_norm": 0.037773679941892624,
      "learning_rate": 1.8914130590084298e-05,
      "loss": 0.2449,
      "step": 3800
    },
    {
      "epoch": 0.8165452207458208,
      "grad_norm": 0.028384188190102577,
      "learning_rate": 1.891127303900557e-05,
      "loss": 0.002,
      "step": 3810
    },
    {
      "epoch": 0.818688384054865,
      "grad_norm": 0.030195942148566246,
      "learning_rate": 1.890841548792685e-05,
      "loss": 0.2516,
      "step": 3820
    },
    {
      "epoch": 0.8208315473639092,
      "grad_norm": 0.02035539411008358,
      "learning_rate": 1.8905557936848123e-05,
      "loss": 0.0007,
      "step": 3830
    },
    {
      "epoch": 0.8229747106729532,
      "grad_norm": 0.016754155978560448,
      "learning_rate": 1.8902700385769397e-05,
      "loss": 0.0025,
      "step": 3840
    },
    {
      "epoch": 0.8251178739819974,
      "grad_norm": 0.02931354008615017,
      "learning_rate": 1.889984283469067e-05,
      "loss": 0.1397,
      "step": 3850
    },
    {
      "epoch": 0.8272610372910416,
      "grad_norm": 49.13785934448242,
      "learning_rate": 1.8896985283611945e-05,
      "loss": 0.3764,
      "step": 3860
    },
    {
      "epoch": 0.8294042006000857,
      "grad_norm": 0.029168011620640755,
      "learning_rate": 1.8894127732533222e-05,
      "loss": 0.2049,
      "step": 3870
    },
    {
      "epoch": 0.8315473639091299,
      "grad_norm": 0.04085128381848335,
      "learning_rate": 1.8891270181454496e-05,
      "loss": 0.001,
      "step": 3880
    },
    {
      "epoch": 0.833690527218174,
      "grad_norm": 0.0902445986866951,
      "learning_rate": 1.888841263037577e-05,
      "loss": 0.238,
      "step": 3890
    },
    {
      "epoch": 0.8358336905272181,
      "grad_norm": 0.05197572335600853,
      "learning_rate": 1.8885555079297044e-05,
      "loss": 0.1912,
      "step": 3900
    },
    {
      "epoch": 0.8379768538362623,
      "grad_norm": 0.026025505736470222,
      "learning_rate": 1.8882697528218318e-05,
      "loss": 0.1931,
      "step": 3910
    },
    {
      "epoch": 0.8401200171453065,
      "grad_norm": 0.030090531334280968,
      "learning_rate": 1.8879839977139595e-05,
      "loss": 0.0008,
      "step": 3920
    },
    {
      "epoch": 0.8422631804543507,
      "grad_norm": 0.07105346024036407,
      "learning_rate": 1.887698242606087e-05,
      "loss": 0.6969,
      "step": 3930
    },
    {
      "epoch": 0.8444063437633947,
      "grad_norm": 0.03426743671298027,
      "learning_rate": 1.8874124874982143e-05,
      "loss": 0.0857,
      "step": 3940
    },
    {
      "epoch": 0.8465495070724389,
      "grad_norm": 0.04877902939915657,
      "learning_rate": 1.8871267323903417e-05,
      "loss": 0.0609,
      "step": 3950
    },
    {
      "epoch": 0.8486926703814831,
      "grad_norm": 26.647306442260742,
      "learning_rate": 1.886840977282469e-05,
      "loss": 0.4469,
      "step": 3960
    },
    {
      "epoch": 0.8508358336905272,
      "grad_norm": 0.04308604449033737,
      "learning_rate": 1.8865552221745968e-05,
      "loss": 0.3264,
      "step": 3970
    },
    {
      "epoch": 0.8529789969995714,
      "grad_norm": 0.06533505767583847,
      "learning_rate": 1.886269467066724e-05,
      "loss": 0.0011,
      "step": 3980
    },
    {
      "epoch": 0.8551221603086155,
      "grad_norm": 0.0787484273314476,
      "learning_rate": 1.8859837119588512e-05,
      "loss": 0.8537,
      "step": 3990
    },
    {
      "epoch": 0.8572653236176596,
      "grad_norm": 0.2817978858947754,
      "learning_rate": 1.8856979568509786e-05,
      "loss": 0.3579,
      "step": 4000
    },
    {
      "epoch": 0.8594084869267038,
      "grad_norm": 0.06787434220314026,
      "learning_rate": 1.8854122017431064e-05,
      "loss": 0.018,
      "step": 4010
    },
    {
      "epoch": 0.861551650235748,
      "grad_norm": 0.032106030732393265,
      "learning_rate": 1.8851264466352338e-05,
      "loss": 0.0038,
      "step": 4020
    },
    {
      "epoch": 0.8636948135447922,
      "grad_norm": 0.01776587776839733,
      "learning_rate": 1.884840691527361e-05,
      "loss": 0.1694,
      "step": 4030
    },
    {
      "epoch": 0.8658379768538362,
      "grad_norm": 0.02042565308511257,
      "learning_rate": 1.8845549364194885e-05,
      "loss": 0.5208,
      "step": 4040
    },
    {
      "epoch": 0.8679811401628804,
      "grad_norm": 0.023645751178264618,
      "learning_rate": 1.884269181311616e-05,
      "loss": 0.0005,
      "step": 4050
    },
    {
      "epoch": 0.8701243034719246,
      "grad_norm": 0.1031745970249176,
      "learning_rate": 1.8839834262037437e-05,
      "loss": 0.3851,
      "step": 4060
    },
    {
      "epoch": 0.8722674667809687,
      "grad_norm": 0.4057020843029022,
      "learning_rate": 1.883697671095871e-05,
      "loss": 0.8992,
      "step": 4070
    },
    {
      "epoch": 0.8744106300900129,
      "grad_norm": 3.0351619720458984,
      "learning_rate": 1.8834119159879985e-05,
      "loss": 0.165,
      "step": 4080
    },
    {
      "epoch": 0.876553793399057,
      "grad_norm": 19.205644607543945,
      "learning_rate": 1.883126160880126e-05,
      "loss": 0.4896,
      "step": 4090
    },
    {
      "epoch": 0.8786969567081011,
      "grad_norm": 20.07870864868164,
      "learning_rate": 1.8828404057722532e-05,
      "loss": 0.5744,
      "step": 4100
    },
    {
      "epoch": 0.8808401200171453,
      "grad_norm": 0.055129118263721466,
      "learning_rate": 1.882554650664381e-05,
      "loss": 0.0725,
      "step": 4110
    },
    {
      "epoch": 0.8829832833261895,
      "grad_norm": 9.684659957885742,
      "learning_rate": 1.8822688955565084e-05,
      "loss": 0.1384,
      "step": 4120
    },
    {
      "epoch": 0.8851264466352337,
      "grad_norm": 0.07223629206418991,
      "learning_rate": 1.8819831404486358e-05,
      "loss": 0.3788,
      "step": 4130
    },
    {
      "epoch": 0.8872696099442777,
      "grad_norm": 0.30232542753219604,
      "learning_rate": 1.881697385340763e-05,
      "loss": 0.2329,
      "step": 4140
    },
    {
      "epoch": 0.8894127732533219,
      "grad_norm": 0.04798870161175728,
      "learning_rate": 1.8814116302328905e-05,
      "loss": 0.0084,
      "step": 4150
    },
    {
      "epoch": 0.8915559365623661,
      "grad_norm": 0.04707879573106766,
      "learning_rate": 1.881125875125018e-05,
      "loss": 0.323,
      "step": 4160
    },
    {
      "epoch": 0.8936990998714102,
      "grad_norm": 0.2371985763311386,
      "learning_rate": 1.8808401200171457e-05,
      "loss": 0.3633,
      "step": 4170
    },
    {
      "epoch": 0.8958422631804543,
      "grad_norm": 19.974395751953125,
      "learning_rate": 1.880554364909273e-05,
      "loss": 0.4666,
      "step": 4180
    },
    {
      "epoch": 0.8979854264894985,
      "grad_norm": 0.034618329256772995,
      "learning_rate": 1.8802686098014e-05,
      "loss": 0.3745,
      "step": 4190
    },
    {
      "epoch": 0.9001285897985426,
      "grad_norm": 28.45328140258789,
      "learning_rate": 1.879982854693528e-05,
      "loss": 0.2058,
      "step": 4200
    },
    {
      "epoch": 0.9022717531075868,
      "grad_norm": 0.08973381668329239,
      "learning_rate": 1.8796970995856552e-05,
      "loss": 0.3859,
      "step": 4210
    },
    {
      "epoch": 0.904414916416631,
      "grad_norm": 187.02381896972656,
      "learning_rate": 1.8794113444777826e-05,
      "loss": 0.5989,
      "step": 4220
    },
    {
      "epoch": 0.9065580797256751,
      "grad_norm": 0.17115440964698792,
      "learning_rate": 1.87912558936991e-05,
      "loss": 0.3687,
      "step": 4230
    },
    {
      "epoch": 0.9087012430347192,
      "grad_norm": 0.22984205186367035,
      "learning_rate": 1.8788398342620374e-05,
      "loss": 0.3746,
      "step": 4240
    },
    {
      "epoch": 0.9108444063437634,
      "grad_norm": 0.1513751596212387,
      "learning_rate": 1.878554079154165e-05,
      "loss": 0.2172,
      "step": 4250
    },
    {
      "epoch": 0.9129875696528076,
      "grad_norm": 0.14202579855918884,
      "learning_rate": 1.8782683240462925e-05,
      "loss": 0.188,
      "step": 4260
    },
    {
      "epoch": 0.9151307329618517,
      "grad_norm": 2.3445703983306885,
      "learning_rate": 1.87798256893842e-05,
      "loss": 0.0058,
      "step": 4270
    },
    {
      "epoch": 0.9172738962708958,
      "grad_norm": 0.06800723820924759,
      "learning_rate": 1.8776968138305473e-05,
      "loss": 0.2274,
      "step": 4280
    },
    {
      "epoch": 0.91941705957994,
      "grad_norm": 0.048858825117349625,
      "learning_rate": 1.8774110587226747e-05,
      "loss": 0.0008,
      "step": 4290
    },
    {
      "epoch": 0.9215602228889841,
      "grad_norm": 34.14732360839844,
      "learning_rate": 1.877125303614802e-05,
      "loss": 0.8218,
      "step": 4300
    },
    {
      "epoch": 0.9237033861980283,
      "grad_norm": 20.29501724243164,
      "learning_rate": 1.87683954850693e-05,
      "loss": 0.3919,
      "step": 4310
    },
    {
      "epoch": 0.9258465495070725,
      "grad_norm": 0.1949610859155655,
      "learning_rate": 1.8765537933990572e-05,
      "loss": 0.3685,
      "step": 4320
    },
    {
      "epoch": 0.9279897128161166,
      "grad_norm": 0.13580089807510376,
      "learning_rate": 1.8762680382911846e-05,
      "loss": 0.3332,
      "step": 4330
    },
    {
      "epoch": 0.9301328761251607,
      "grad_norm": 17.953157424926758,
      "learning_rate": 1.875982283183312e-05,
      "loss": 0.5358,
      "step": 4340
    },
    {
      "epoch": 0.9322760394342049,
      "grad_norm": 0.12975706160068512,
      "learning_rate": 1.8756965280754394e-05,
      "loss": 0.1612,
      "step": 4350
    },
    {
      "epoch": 0.9344192027432491,
      "grad_norm": 154.75640869140625,
      "learning_rate": 1.875410772967567e-05,
      "loss": 0.8812,
      "step": 4360
    },
    {
      "epoch": 0.9365623660522931,
      "grad_norm": 0.2919718325138092,
      "learning_rate": 1.8751250178596945e-05,
      "loss": 0.5546,
      "step": 4370
    },
    {
      "epoch": 0.9387055293613373,
      "grad_norm": 0.4071057438850403,
      "learning_rate": 1.874839262751822e-05,
      "loss": 0.247,
      "step": 4380
    },
    {
      "epoch": 0.9408486926703815,
      "grad_norm": 0.05668187513947487,
      "learning_rate": 1.8745535076439493e-05,
      "loss": 0.2121,
      "step": 4390
    },
    {
      "epoch": 0.9429918559794256,
      "grad_norm": 0.07316669076681137,
      "learning_rate": 1.8742677525360767e-05,
      "loss": 0.2245,
      "step": 4400
    },
    {
      "epoch": 0.9451350192884698,
      "grad_norm": 0.06383676826953888,
      "learning_rate": 1.873981997428204e-05,
      "loss": 0.053,
      "step": 4410
    },
    {
      "epoch": 0.947278182597514,
      "grad_norm": 0.08158750087022781,
      "learning_rate": 1.8736962423203315e-05,
      "loss": 0.4163,
      "step": 4420
    },
    {
      "epoch": 0.9494213459065581,
      "grad_norm": 15.350950241088867,
      "learning_rate": 1.873410487212459e-05,
      "loss": 0.2984,
      "step": 4430
    },
    {
      "epoch": 0.9515645092156022,
      "grad_norm": 0.10888083279132843,
      "learning_rate": 1.8731247321045863e-05,
      "loss": 0.4004,
      "step": 4440
    },
    {
      "epoch": 0.9537076725246464,
      "grad_norm": 0.1515951305627823,
      "learning_rate": 1.872838976996714e-05,
      "loss": 0.3552,
      "step": 4450
    },
    {
      "epoch": 0.9558508358336906,
      "grad_norm": 0.11079737544059753,
      "learning_rate": 1.8725532218888414e-05,
      "loss": 0.2076,
      "step": 4460
    },
    {
      "epoch": 0.9579939991427346,
      "grad_norm": 24.024269104003906,
      "learning_rate": 1.8722674667809688e-05,
      "loss": 0.1369,
      "step": 4470
    },
    {
      "epoch": 0.9601371624517788,
      "grad_norm": 31.387596130371094,
      "learning_rate": 1.8719817116730962e-05,
      "loss": 0.2635,
      "step": 4480
    },
    {
      "epoch": 0.962280325760823,
      "grad_norm": 7.427433013916016,
      "learning_rate": 1.8716959565652236e-05,
      "loss": 0.4595,
      "step": 4490
    },
    {
      "epoch": 0.9644234890698671,
      "grad_norm": 0.048251137137413025,
      "learning_rate": 1.8714102014573513e-05,
      "loss": 0.2573,
      "step": 4500
    },
    {
      "epoch": 0.9665666523789113,
      "grad_norm": 0.10676241666078568,
      "learning_rate": 1.8711244463494787e-05,
      "loss": 0.1895,
      "step": 4510
    },
    {
      "epoch": 0.9687098156879554,
      "grad_norm": 0.09886172413825989,
      "learning_rate": 1.870838691241606e-05,
      "loss": 0.0085,
      "step": 4520
    },
    {
      "epoch": 0.9708529789969995,
      "grad_norm": 0.11268427222967148,
      "learning_rate": 1.8705529361337335e-05,
      "loss": 0.0138,
      "step": 4530
    },
    {
      "epoch": 0.9729961423060437,
      "grad_norm": 0.025232801213860512,
      "learning_rate": 1.870267181025861e-05,
      "loss": 0.2361,
      "step": 4540
    },
    {
      "epoch": 0.9751393056150879,
      "grad_norm": 0.06377068907022476,
      "learning_rate": 1.8699814259179886e-05,
      "loss": 0.2137,
      "step": 4550
    },
    {
      "epoch": 0.9772824689241321,
      "grad_norm": 0.031024273484945297,
      "learning_rate": 1.869695670810116e-05,
      "loss": 0.2857,
      "step": 4560
    },
    {
      "epoch": 0.9794256322331761,
      "grad_norm": 0.04569742828607559,
      "learning_rate": 1.8694099157022434e-05,
      "loss": 0.0137,
      "step": 4570
    },
    {
      "epoch": 0.9815687955422203,
      "grad_norm": 0.04173436388373375,
      "learning_rate": 1.8691241605943708e-05,
      "loss": 0.0941,
      "step": 4580
    },
    {
      "epoch": 0.9837119588512645,
      "grad_norm": 0.024779997766017914,
      "learning_rate": 1.8688384054864982e-05,
      "loss": 0.0007,
      "step": 4590
    },
    {
      "epoch": 0.9858551221603086,
      "grad_norm": 0.034862030297517776,
      "learning_rate": 1.8685526503786256e-05,
      "loss": 0.2593,
      "step": 4600
    },
    {
      "epoch": 0.9879982854693528,
      "grad_norm": 0.0401131771504879,
      "learning_rate": 1.8682668952707533e-05,
      "loss": 0.2382,
      "step": 4610
    },
    {
      "epoch": 0.9901414487783969,
      "grad_norm": 0.08513560146093369,
      "learning_rate": 1.8679811401628804e-05,
      "loss": 0.7123,
      "step": 4620
    },
    {
      "epoch": 0.992284612087441,
      "grad_norm": 0.26647475361824036,
      "learning_rate": 1.8676953850550078e-05,
      "loss": 0.3823,
      "step": 4630
    },
    {
      "epoch": 0.9944277753964852,
      "grad_norm": 0.04830947145819664,
      "learning_rate": 1.8674096299471355e-05,
      "loss": 0.0486,
      "step": 4640
    },
    {
      "epoch": 0.9965709387055294,
      "grad_norm": 18.537065505981445,
      "learning_rate": 1.867123874839263e-05,
      "loss": 0.2456,
      "step": 4650
    },
    {
      "epoch": 0.9987141020145736,
      "grad_norm": 0.02652926743030548,
      "learning_rate": 1.8668381197313903e-05,
      "loss": 0.0008,
      "step": 4660
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9366666666666666,
      "eval_f1": 0.6678321678321678,
      "eval_loss": 0.3320232629776001,
      "eval_precision": 0.7022058823529411,
      "eval_recall": 0.6366666666666667,
      "eval_runtime": 474.4481,
      "eval_samples_per_second": 6.323,
      "eval_steps_per_second": 2.108,
      "step": 4666
    },
    {
      "epoch": 1.0008572653236176,
      "grad_norm": 0.025212591513991356,
      "learning_rate": 1.8665523646235177e-05,
      "loss": 0.1753,
      "step": 4670
    },
    {
      "epoch": 1.0030004286326617,
      "grad_norm": 0.01829272136092186,
      "learning_rate": 1.866266609515645e-05,
      "loss": 0.2193,
      "step": 4680
    },
    {
      "epoch": 1.005143591941706,
      "grad_norm": 0.01594742387533188,
      "learning_rate": 1.8659808544077728e-05,
      "loss": 0.0019,
      "step": 4690
    },
    {
      "epoch": 1.00728675525075,
      "grad_norm": 0.026018241420388222,
      "learning_rate": 1.8656950992999002e-05,
      "loss": 0.5468,
      "step": 4700
    },
    {
      "epoch": 1.0094299185597944,
      "grad_norm": 0.03651805594563484,
      "learning_rate": 1.8654093441920276e-05,
      "loss": 0.1587,
      "step": 4710
    },
    {
      "epoch": 1.0115730818688384,
      "grad_norm": 0.5986367464065552,
      "learning_rate": 1.865123589084155e-05,
      "loss": 0.3229,
      "step": 4720
    },
    {
      "epoch": 1.0137162451778825,
      "grad_norm": 0.1954827904701233,
      "learning_rate": 1.8648378339762824e-05,
      "loss": 0.2314,
      "step": 4730
    },
    {
      "epoch": 1.0158594084869268,
      "grad_norm": 0.1968732625246048,
      "learning_rate": 1.8645520788684098e-05,
      "loss": 0.082,
      "step": 4740
    },
    {
      "epoch": 1.0180025717959709,
      "grad_norm": 1.7237869501113892,
      "learning_rate": 1.8642663237605375e-05,
      "loss": 0.0021,
      "step": 4750
    },
    {
      "epoch": 1.020145735105015,
      "grad_norm": 0.03016161546111107,
      "learning_rate": 1.863980568652665e-05,
      "loss": 0.3561,
      "step": 4760
    },
    {
      "epoch": 1.0222888984140592,
      "grad_norm": 0.061612389981746674,
      "learning_rate": 1.8636948135447923e-05,
      "loss": 0.6323,
      "step": 4770
    },
    {
      "epoch": 1.0244320617231033,
      "grad_norm": 0.0789434090256691,
      "learning_rate": 1.8634090584369197e-05,
      "loss": 0.2106,
      "step": 4780
    },
    {
      "epoch": 1.0265752250321474,
      "grad_norm": 19.106849670410156,
      "learning_rate": 1.863123303329047e-05,
      "loss": 0.4643,
      "step": 4790
    },
    {
      "epoch": 1.0287183883411917,
      "grad_norm": 0.08719542622566223,
      "learning_rate": 1.8628375482211748e-05,
      "loss": 0.0022,
      "step": 4800
    },
    {
      "epoch": 1.0308615516502357,
      "grad_norm": 0.062369897961616516,
      "learning_rate": 1.8625517931133022e-05,
      "loss": 0.2198,
      "step": 4810
    },
    {
      "epoch": 1.0330047149592798,
      "grad_norm": 34.92487716674805,
      "learning_rate": 1.8622660380054296e-05,
      "loss": 0.4411,
      "step": 4820
    },
    {
      "epoch": 1.035147878268324,
      "grad_norm": 0.12269439548254013,
      "learning_rate": 1.861980282897557e-05,
      "loss": 0.4289,
      "step": 4830
    },
    {
      "epoch": 1.0372910415773682,
      "grad_norm": 0.1555311232805252,
      "learning_rate": 1.8616945277896844e-05,
      "loss": 0.3147,
      "step": 4840
    },
    {
      "epoch": 1.0394342048864122,
      "grad_norm": 0.2080480009317398,
      "learning_rate": 1.8614087726818118e-05,
      "loss": 0.1729,
      "step": 4850
    },
    {
      "epoch": 1.0415773681954565,
      "grad_norm": 0.09476462751626968,
      "learning_rate": 1.861123017573939e-05,
      "loss": 0.1855,
      "step": 4860
    },
    {
      "epoch": 1.0437205315045006,
      "grad_norm": 22.57811737060547,
      "learning_rate": 1.8608372624660666e-05,
      "loss": 0.1815,
      "step": 4870
    },
    {
      "epoch": 1.0458636948135447,
      "grad_norm": 0.07207603752613068,
      "learning_rate": 1.860551507358194e-05,
      "loss": 0.4711,
      "step": 4880
    },
    {
      "epoch": 1.048006858122589,
      "grad_norm": 0.02886386029422283,
      "learning_rate": 1.8602657522503217e-05,
      "loss": 0.0019,
      "step": 4890
    },
    {
      "epoch": 1.050150021431633,
      "grad_norm": 0.02816639095544815,
      "learning_rate": 1.859979997142449e-05,
      "loss": 0.0007,
      "step": 4900
    },
    {
      "epoch": 1.0522931847406773,
      "grad_norm": 0.0359528549015522,
      "learning_rate": 1.8596942420345765e-05,
      "loss": 0.5653,
      "step": 4910
    },
    {
      "epoch": 1.0544363480497214,
      "grad_norm": 0.05024127662181854,
      "learning_rate": 1.859408486926704e-05,
      "loss": 0.2188,
      "step": 4920
    },
    {
      "epoch": 1.0565795113587655,
      "grad_norm": 0.060088980942964554,
      "learning_rate": 1.8591227318188313e-05,
      "loss": 0.0022,
      "step": 4930
    },
    {
      "epoch": 1.0587226746678098,
      "grad_norm": 0.07971490919589996,
      "learning_rate": 1.858836976710959e-05,
      "loss": 0.5378,
      "step": 4940
    },
    {
      "epoch": 1.0608658379768539,
      "grad_norm": 0.04266390576958656,
      "learning_rate": 1.8585512216030864e-05,
      "loss": 0.1742,
      "step": 4950
    },
    {
      "epoch": 1.063009001285898,
      "grad_norm": 0.035615015774965286,
      "learning_rate": 1.8582654664952138e-05,
      "loss": 0.0015,
      "step": 4960
    },
    {
      "epoch": 1.0651521645949422,
      "grad_norm": 0.018921250477433205,
      "learning_rate": 1.857979711387341e-05,
      "loss": 0.0004,
      "step": 4970
    },
    {
      "epoch": 1.0672953279039863,
      "grad_norm": 0.0810936912894249,
      "learning_rate": 1.8576939562794686e-05,
      "loss": 0.0017,
      "step": 4980
    },
    {
      "epoch": 1.0694384912130304,
      "grad_norm": 0.06047772616147995,
      "learning_rate": 1.8574082011715963e-05,
      "loss": 0.2887,
      "step": 4990
    },
    {
      "epoch": 1.0715816545220747,
      "grad_norm": 0.015408015809953213,
      "learning_rate": 1.8571224460637237e-05,
      "loss": 0.2953,
      "step": 5000
    },
    {
      "epoch": 1.0737248178311187,
      "grad_norm": 0.06854858994483948,
      "learning_rate": 1.856836690955851e-05,
      "loss": 0.3435,
      "step": 5010
    },
    {
      "epoch": 1.0758679811401628,
      "grad_norm": 0.036868784576654434,
      "learning_rate": 1.8565509358479785e-05,
      "loss": 0.2141,
      "step": 5020
    },
    {
      "epoch": 1.078011144449207,
      "grad_norm": 23.438282012939453,
      "learning_rate": 1.856265180740106e-05,
      "loss": 0.2876,
      "step": 5030
    },
    {
      "epoch": 1.0801543077582512,
      "grad_norm": 0.033835045993328094,
      "learning_rate": 1.8559794256322336e-05,
      "loss": 0.2023,
      "step": 5040
    },
    {
      "epoch": 1.0822974710672952,
      "grad_norm": 0.05480304732918739,
      "learning_rate": 1.8556936705243606e-05,
      "loss": 0.0006,
      "step": 5050
    },
    {
      "epoch": 1.0844406343763395,
      "grad_norm": 0.15517091751098633,
      "learning_rate": 1.855407915416488e-05,
      "loss": 0.6833,
      "step": 5060
    },
    {
      "epoch": 1.0865837976853836,
      "grad_norm": 0.1872350573539734,
      "learning_rate": 1.8551221603086154e-05,
      "loss": 0.1626,
      "step": 5070
    },
    {
      "epoch": 1.0887269609944277,
      "grad_norm": 0.171950563788414,
      "learning_rate": 1.854836405200743e-05,
      "loss": 0.4893,
      "step": 5080
    },
    {
      "epoch": 1.090870124303472,
      "grad_norm": 0.25680315494537354,
      "learning_rate": 1.8545506500928706e-05,
      "loss": 0.1432,
      "step": 5090
    },
    {
      "epoch": 1.093013287612516,
      "grad_norm": 44.192779541015625,
      "learning_rate": 1.854264894984998e-05,
      "loss": 0.3125,
      "step": 5100
    },
    {
      "epoch": 1.0951564509215603,
      "grad_norm": 0.08186127990484238,
      "learning_rate": 1.8539791398771253e-05,
      "loss": 0.1283,
      "step": 5110
    },
    {
      "epoch": 1.0972996142306044,
      "grad_norm": 0.03221779316663742,
      "learning_rate": 1.8536933847692527e-05,
      "loss": 0.4759,
      "step": 5120
    },
    {
      "epoch": 1.0994427775396485,
      "grad_norm": 0.6644291281700134,
      "learning_rate": 1.8534076296613805e-05,
      "loss": 0.2863,
      "step": 5130
    },
    {
      "epoch": 1.1015859408486928,
      "grad_norm": 0.024071786552667618,
      "learning_rate": 1.853121874553508e-05,
      "loss": 0.0527,
      "step": 5140
    },
    {
      "epoch": 1.1037291041577368,
      "grad_norm": 0.03352291136980057,
      "learning_rate": 1.8528361194456353e-05,
      "loss": 0.358,
      "step": 5150
    },
    {
      "epoch": 1.105872267466781,
      "grad_norm": 0.05001966282725334,
      "learning_rate": 1.8525503643377626e-05,
      "loss": 0.0594,
      "step": 5160
    },
    {
      "epoch": 1.1080154307758252,
      "grad_norm": 23.331972122192383,
      "learning_rate": 1.85226460922989e-05,
      "loss": 0.3678,
      "step": 5170
    },
    {
      "epoch": 1.1101585940848693,
      "grad_norm": 16.55106544494629,
      "learning_rate": 1.8519788541220178e-05,
      "loss": 0.0136,
      "step": 5180
    },
    {
      "epoch": 1.1123017573939133,
      "grad_norm": 0.011721380986273289,
      "learning_rate": 1.851693099014145e-05,
      "loss": 0.0081,
      "step": 5190
    },
    {
      "epoch": 1.1144449207029576,
      "grad_norm": 0.02367331273853779,
      "learning_rate": 1.8514073439062726e-05,
      "loss": 0.0019,
      "step": 5200
    },
    {
      "epoch": 1.1165880840120017,
      "grad_norm": 19.40732192993164,
      "learning_rate": 1.8511215887984e-05,
      "loss": 0.4927,
      "step": 5210
    },
    {
      "epoch": 1.1187312473210458,
      "grad_norm": 51.48336410522461,
      "learning_rate": 1.8508358336905273e-05,
      "loss": 0.3259,
      "step": 5220
    },
    {
      "epoch": 1.12087441063009,
      "grad_norm": 0.16925467550754547,
      "learning_rate": 1.8505500785826547e-05,
      "loss": 0.0012,
      "step": 5230
    },
    {
      "epoch": 1.1230175739391342,
      "grad_norm": 0.033313531428575516,
      "learning_rate": 1.8502643234747825e-05,
      "loss": 0.4094,
      "step": 5240
    },
    {
      "epoch": 1.1251607372481782,
      "grad_norm": 0.19509436190128326,
      "learning_rate": 1.84997856836691e-05,
      "loss": 0.3357,
      "step": 5250
    },
    {
      "epoch": 1.1273039005572225,
      "grad_norm": 0.04831714928150177,
      "learning_rate": 1.849692813259037e-05,
      "loss": 0.0031,
      "step": 5260
    },
    {
      "epoch": 1.1294470638662666,
      "grad_norm": 0.04026837646961212,
      "learning_rate": 1.8494070581511646e-05,
      "loss": 0.0937,
      "step": 5270
    },
    {
      "epoch": 1.1315902271753107,
      "grad_norm": 31.341175079345703,
      "learning_rate": 1.849121303043292e-05,
      "loss": 0.3947,
      "step": 5280
    },
    {
      "epoch": 1.133733390484355,
      "grad_norm": 0.2287646383047104,
      "learning_rate": 1.8488355479354194e-05,
      "loss": 0.2503,
      "step": 5290
    },
    {
      "epoch": 1.135876553793399,
      "grad_norm": 0.13328024744987488,
      "learning_rate": 1.8485497928275468e-05,
      "loss": 0.005,
      "step": 5300
    },
    {
      "epoch": 1.138019717102443,
      "grad_norm": 0.011123066768050194,
      "learning_rate": 1.8482640377196742e-05,
      "loss": 0.0009,
      "step": 5310
    },
    {
      "epoch": 1.1401628804114874,
      "grad_norm": 0.013245115987956524,
      "learning_rate": 1.847978282611802e-05,
      "loss": 0.0009,
      "step": 5320
    },
    {
      "epoch": 1.1423060437205315,
      "grad_norm": 0.005932810716331005,
      "learning_rate": 1.8476925275039293e-05,
      "loss": 0.0014,
      "step": 5330
    },
    {
      "epoch": 1.1444492070295755,
      "grad_norm": 0.012311751954257488,
      "learning_rate": 1.8474067723960567e-05,
      "loss": 0.2097,
      "step": 5340
    },
    {
      "epoch": 1.1465923703386198,
      "grad_norm": 0.004439343698322773,
      "learning_rate": 1.847121017288184e-05,
      "loss": 0.2428,
      "step": 5350
    },
    {
      "epoch": 1.148735533647664,
      "grad_norm": 0.007717174012213945,
      "learning_rate": 1.8468352621803115e-05,
      "loss": 0.2374,
      "step": 5360
    },
    {
      "epoch": 1.1508786969567082,
      "grad_norm": 0.007791575975716114,
      "learning_rate": 1.846549507072439e-05,
      "loss": 0.0006,
      "step": 5370
    },
    {
      "epoch": 1.1530218602657523,
      "grad_norm": 0.01686905510723591,
      "learning_rate": 1.8462637519645666e-05,
      "loss": 0.1056,
      "step": 5380
    },
    {
      "epoch": 1.1551650235747963,
      "grad_norm": 0.01517484337091446,
      "learning_rate": 1.845977996856694e-05,
      "loss": 0.2124,
      "step": 5390
    },
    {
      "epoch": 1.1573081868838406,
      "grad_norm": 0.02884805202484131,
      "learning_rate": 1.8456922417488214e-05,
      "loss": 0.2737,
      "step": 5400
    },
    {
      "epoch": 1.1594513501928847,
      "grad_norm": 0.06197993457317352,
      "learning_rate": 1.8454064866409488e-05,
      "loss": 0.4482,
      "step": 5410
    },
    {
      "epoch": 1.1615945135019288,
      "grad_norm": 0.09290418028831482,
      "learning_rate": 1.8451207315330762e-05,
      "loss": 0.1888,
      "step": 5420
    },
    {
      "epoch": 1.163737676810973,
      "grad_norm": 0.026450110599398613,
      "learning_rate": 1.844834976425204e-05,
      "loss": 0.2208,
      "step": 5430
    },
    {
      "epoch": 1.1658808401200171,
      "grad_norm": 0.06527384370565414,
      "learning_rate": 1.8445492213173313e-05,
      "loss": 0.2193,
      "step": 5440
    },
    {
      "epoch": 1.1680240034290612,
      "grad_norm": 0.1101551279425621,
      "learning_rate": 1.8442634662094587e-05,
      "loss": 0.2851,
      "step": 5450
    },
    {
      "epoch": 1.1701671667381055,
      "grad_norm": 25.021949768066406,
      "learning_rate": 1.843977711101586e-05,
      "loss": 0.1677,
      "step": 5460
    },
    {
      "epoch": 1.1723103300471496,
      "grad_norm": 0.02020234800875187,
      "learning_rate": 1.8436919559937135e-05,
      "loss": 0.0009,
      "step": 5470
    },
    {
      "epoch": 1.1744534933561936,
      "grad_norm": 0.241840198636055,
      "learning_rate": 1.843406200885841e-05,
      "loss": 0.1662,
      "step": 5480
    },
    {
      "epoch": 1.176596656665238,
      "grad_norm": 2.412717819213867,
      "learning_rate": 1.8431204457779683e-05,
      "loss": 0.124,
      "step": 5490
    },
    {
      "epoch": 1.178739819974282,
      "grad_norm": 0.02141551859676838,
      "learning_rate": 1.8428346906700957e-05,
      "loss": 0.0005,
      "step": 5500
    },
    {
      "epoch": 1.1808829832833263,
      "grad_norm": 24.968366622924805,
      "learning_rate": 1.842548935562223e-05,
      "loss": 0.4635,
      "step": 5510
    },
    {
      "epoch": 1.1830261465923704,
      "grad_norm": 0.13845627009868622,
      "learning_rate": 1.8422631804543508e-05,
      "loss": 0.3232,
      "step": 5520
    },
    {
      "epoch": 1.1851693099014144,
      "grad_norm": 0.018737781792879105,
      "learning_rate": 1.8419774253464782e-05,
      "loss": 0.0024,
      "step": 5530
    },
    {
      "epoch": 1.1873124732104587,
      "grad_norm": 0.014593934640288353,
      "learning_rate": 1.8416916702386056e-05,
      "loss": 0.1652,
      "step": 5540
    },
    {
      "epoch": 1.1894556365195028,
      "grad_norm": 0.02296777442097664,
      "learning_rate": 1.841405915130733e-05,
      "loss": 0.1944,
      "step": 5550
    },
    {
      "epoch": 1.1915987998285469,
      "grad_norm": 0.015328865498304367,
      "learning_rate": 1.8411201600228604e-05,
      "loss": 0.2548,
      "step": 5560
    },
    {
      "epoch": 1.1937419631375912,
      "grad_norm": 0.011550861410796642,
      "learning_rate": 1.840834404914988e-05,
      "loss": 0.1709,
      "step": 5570
    },
    {
      "epoch": 1.1958851264466352,
      "grad_norm": 0.01925409585237503,
      "learning_rate": 1.8405486498071155e-05,
      "loss": 0.1309,
      "step": 5580
    },
    {
      "epoch": 1.1980282897556793,
      "grad_norm": 17.25046157836914,
      "learning_rate": 1.840262894699243e-05,
      "loss": 0.3278,
      "step": 5590
    },
    {
      "epoch": 1.2001714530647236,
      "grad_norm": 0.03386051580309868,
      "learning_rate": 1.8399771395913703e-05,
      "loss": 0.2584,
      "step": 5600
    },
    {
      "epoch": 1.2023146163737677,
      "grad_norm": 0.03881872072815895,
      "learning_rate": 1.8396913844834977e-05,
      "loss": 0.0053,
      "step": 5610
    },
    {
      "epoch": 1.2044577796828118,
      "grad_norm": 0.550847589969635,
      "learning_rate": 1.8394056293756254e-05,
      "loss": 0.4224,
      "step": 5620
    },
    {
      "epoch": 1.206600942991856,
      "grad_norm": 0.13973937928676605,
      "learning_rate": 1.8391198742677528e-05,
      "loss": 0.0036,
      "step": 5630
    },
    {
      "epoch": 1.2087441063009001,
      "grad_norm": 0.06699258089065552,
      "learning_rate": 1.8388341191598802e-05,
      "loss": 0.2095,
      "step": 5640
    },
    {
      "epoch": 1.2108872696099442,
      "grad_norm": 2.6419968605041504,
      "learning_rate": 1.8385483640520076e-05,
      "loss": 0.1498,
      "step": 5650
    },
    {
      "epoch": 1.2130304329189885,
      "grad_norm": 0.23352649807929993,
      "learning_rate": 1.838262608944135e-05,
      "loss": 0.508,
      "step": 5660
    },
    {
      "epoch": 1.2151735962280326,
      "grad_norm": 0.030193351209163666,
      "learning_rate": 1.8379768538362627e-05,
      "loss": 0.0019,
      "step": 5670
    },
    {
      "epoch": 1.2173167595370766,
      "grad_norm": 21.72245216369629,
      "learning_rate": 1.83769109872839e-05,
      "loss": 0.2322,
      "step": 5680
    },
    {
      "epoch": 1.219459922846121,
      "grad_norm": 0.021550683304667473,
      "learning_rate": 1.8374053436205172e-05,
      "loss": 0.0009,
      "step": 5690
    },
    {
      "epoch": 1.221603086155165,
      "grad_norm": 0.018372224643826485,
      "learning_rate": 1.8371195885126446e-05,
      "loss": 0.0008,
      "step": 5700
    },
    {
      "epoch": 1.223746249464209,
      "grad_norm": 19.881275177001953,
      "learning_rate": 1.8368338334047723e-05,
      "loss": 0.1628,
      "step": 5710
    },
    {
      "epoch": 1.2258894127732534,
      "grad_norm": 0.011675205081701279,
      "learning_rate": 1.8365480782968997e-05,
      "loss": 0.363,
      "step": 5720
    },
    {
      "epoch": 1.2280325760822974,
      "grad_norm": 20.324905395507812,
      "learning_rate": 1.836262323189027e-05,
      "loss": 0.281,
      "step": 5730
    },
    {
      "epoch": 1.2301757393913415,
      "grad_norm": 0.04877098277211189,
      "learning_rate": 1.8359765680811545e-05,
      "loss": 0.0012,
      "step": 5740
    },
    {
      "epoch": 1.2323189027003858,
      "grad_norm": 0.7955985069274902,
      "learning_rate": 1.835690812973282e-05,
      "loss": 0.1369,
      "step": 5750
    },
    {
      "epoch": 1.2344620660094299,
      "grad_norm": 0.022255145013332367,
      "learning_rate": 1.8354050578654096e-05,
      "loss": 0.0004,
      "step": 5760
    },
    {
      "epoch": 1.2366052293184742,
      "grad_norm": 0.022471416741609573,
      "learning_rate": 1.835119302757537e-05,
      "loss": 0.2487,
      "step": 5770
    },
    {
      "epoch": 1.2387483926275182,
      "grad_norm": 0.012104647234082222,
      "learning_rate": 1.8348335476496644e-05,
      "loss": 0.4843,
      "step": 5780
    },
    {
      "epoch": 1.2408915559365623,
      "grad_norm": 0.4541853666305542,
      "learning_rate": 1.8345477925417918e-05,
      "loss": 0.0023,
      "step": 5790
    },
    {
      "epoch": 1.2430347192456066,
      "grad_norm": 0.04013945907354355,
      "learning_rate": 1.8342620374339192e-05,
      "loss": 0.0009,
      "step": 5800
    },
    {
      "epoch": 1.2451778825546507,
      "grad_norm": 0.006650787312537432,
      "learning_rate": 1.833976282326047e-05,
      "loss": 0.2684,
      "step": 5810
    },
    {
      "epoch": 1.2473210458636947,
      "grad_norm": 0.019377833232283592,
      "learning_rate": 1.8336905272181743e-05,
      "loss": 0.2921,
      "step": 5820
    },
    {
      "epoch": 1.249464209172739,
      "grad_norm": 32.36408615112305,
      "learning_rate": 1.8334047721103017e-05,
      "loss": 0.2562,
      "step": 5830
    },
    {
      "epoch": 1.251607372481783,
      "grad_norm": 0.8748367428779602,
      "learning_rate": 1.833119017002429e-05,
      "loss": 0.2499,
      "step": 5840
    },
    {
      "epoch": 1.2537505357908272,
      "grad_norm": 0.09290526807308197,
      "learning_rate": 1.8328332618945565e-05,
      "loss": 0.0033,
      "step": 5850
    },
    {
      "epoch": 1.2558936990998715,
      "grad_norm": 0.009235288947820663,
      "learning_rate": 1.832547506786684e-05,
      "loss": 0.1268,
      "step": 5860
    },
    {
      "epoch": 1.2580368624089155,
      "grad_norm": 0.04416818171739578,
      "learning_rate": 1.8322617516788116e-05,
      "loss": 0.1885,
      "step": 5870
    },
    {
      "epoch": 1.2601800257179598,
      "grad_norm": 23.65230941772461,
      "learning_rate": 1.831975996570939e-05,
      "loss": 0.9474,
      "step": 5880
    },
    {
      "epoch": 1.262323189027004,
      "grad_norm": 0.12911973893642426,
      "learning_rate": 1.8316902414630664e-05,
      "loss": 0.1329,
      "step": 5890
    },
    {
      "epoch": 1.264466352336048,
      "grad_norm": 0.05132655054330826,
      "learning_rate": 1.8314044863551938e-05,
      "loss": 0.0766,
      "step": 5900
    },
    {
      "epoch": 1.2666095156450923,
      "grad_norm": 0.02761591039597988,
      "learning_rate": 1.8311187312473212e-05,
      "loss": 0.0009,
      "step": 5910
    },
    {
      "epoch": 1.2687526789541363,
      "grad_norm": 53.156349182128906,
      "learning_rate": 1.8308329761394486e-05,
      "loss": 0.4224,
      "step": 5920
    },
    {
      "epoch": 1.2708958422631804,
      "grad_norm": 0.09348393231630325,
      "learning_rate": 1.830547221031576e-05,
      "loss": 0.2466,
      "step": 5930
    },
    {
      "epoch": 1.2730390055722247,
      "grad_norm": 173.29075622558594,
      "learning_rate": 1.8302614659237034e-05,
      "loss": 0.0429,
      "step": 5940
    },
    {
      "epoch": 1.2751821688812688,
      "grad_norm": 0.01319204643368721,
      "learning_rate": 1.829975710815831e-05,
      "loss": 0.2879,
      "step": 5950
    },
    {
      "epoch": 1.2773253321903129,
      "grad_norm": 0.012070339173078537,
      "learning_rate": 1.8296899557079585e-05,
      "loss": 0.2412,
      "step": 5960
    },
    {
      "epoch": 1.2794684954993572,
      "grad_norm": 25.916025161743164,
      "learning_rate": 1.829404200600086e-05,
      "loss": 0.4152,
      "step": 5970
    },
    {
      "epoch": 1.2816116588084012,
      "grad_norm": 0.08404175937175751,
      "learning_rate": 1.8291184454922133e-05,
      "loss": 0.4899,
      "step": 5980
    },
    {
      "epoch": 1.2837548221174453,
      "grad_norm": 0.03726476803421974,
      "learning_rate": 1.8288326903843407e-05,
      "loss": 0.0102,
      "step": 5990
    },
    {
      "epoch": 1.2858979854264896,
      "grad_norm": 0.012650142423808575,
      "learning_rate": 1.828546935276468e-05,
      "loss": 0.0131,
      "step": 6000
    },
    {
      "epoch": 1.2880411487355337,
      "grad_norm": 0.017422139644622803,
      "learning_rate": 1.8282611801685958e-05,
      "loss": 0.2386,
      "step": 6010
    },
    {
      "epoch": 1.2901843120445777,
      "grad_norm": 0.013784708455204964,
      "learning_rate": 1.8279754250607232e-05,
      "loss": 0.0006,
      "step": 6020
    },
    {
      "epoch": 1.292327475353622,
      "grad_norm": 0.13340647518634796,
      "learning_rate": 1.8276896699528506e-05,
      "loss": 0.0005,
      "step": 6030
    },
    {
      "epoch": 1.294470638662666,
      "grad_norm": 111.93534851074219,
      "learning_rate": 1.827403914844978e-05,
      "loss": 0.5979,
      "step": 6040
    },
    {
      "epoch": 1.2966138019717102,
      "grad_norm": 0.05777022987604141,
      "learning_rate": 1.8271181597371054e-05,
      "loss": 0.0011,
      "step": 6050
    },
    {
      "epoch": 1.2987569652807545,
      "grad_norm": 0.05207008123397827,
      "learning_rate": 1.826832404629233e-05,
      "loss": 0.2099,
      "step": 6060
    },
    {
      "epoch": 1.3009001285897985,
      "grad_norm": 0.07569724321365356,
      "learning_rate": 1.8265466495213605e-05,
      "loss": 0.2188,
      "step": 6070
    },
    {
      "epoch": 1.3030432918988426,
      "grad_norm": 0.020260820165276527,
      "learning_rate": 1.826260894413488e-05,
      "loss": 0.2537,
      "step": 6080
    },
    {
      "epoch": 1.305186455207887,
      "grad_norm": 30.429615020751953,
      "learning_rate": 1.8259751393056153e-05,
      "loss": 0.7078,
      "step": 6090
    },
    {
      "epoch": 1.307329618516931,
      "grad_norm": 0.15038302540779114,
      "learning_rate": 1.8256893841977427e-05,
      "loss": 0.2121,
      "step": 6100
    },
    {
      "epoch": 1.309472781825975,
      "grad_norm": 0.14808084070682526,
      "learning_rate": 1.8254036290898704e-05,
      "loss": 0.3444,
      "step": 6110
    },
    {
      "epoch": 1.3116159451350193,
      "grad_norm": 0.11372897028923035,
      "learning_rate": 1.8251178739819974e-05,
      "loss": 0.003,
      "step": 6120
    },
    {
      "epoch": 1.3137591084440634,
      "grad_norm": 0.05862430855631828,
      "learning_rate": 1.824832118874125e-05,
      "loss": 0.2022,
      "step": 6130
    },
    {
      "epoch": 1.3159022717531075,
      "grad_norm": 0.08481092005968094,
      "learning_rate": 1.8245463637662522e-05,
      "loss": 0.5886,
      "step": 6140
    },
    {
      "epoch": 1.3180454350621518,
      "grad_norm": 0.1287079155445099,
      "learning_rate": 1.82426060865838e-05,
      "loss": 0.1915,
      "step": 6150
    },
    {
      "epoch": 1.3201885983711958,
      "grad_norm": 0.4202515482902527,
      "learning_rate": 1.8239748535505073e-05,
      "loss": 0.5938,
      "step": 6160
    },
    {
      "epoch": 1.32233176168024,
      "grad_norm": 0.07422645390033722,
      "learning_rate": 1.8236890984426347e-05,
      "loss": 0.1926,
      "step": 6170
    },
    {
      "epoch": 1.3244749249892842,
      "grad_norm": 0.06296045333147049,
      "learning_rate": 1.823403343334762e-05,
      "loss": 0.0031,
      "step": 6180
    },
    {
      "epoch": 1.3266180882983283,
      "grad_norm": 0.03353336080908775,
      "learning_rate": 1.8231175882268895e-05,
      "loss": 0.6675,
      "step": 6190
    },
    {
      "epoch": 1.3287612516073724,
      "grad_norm": 0.4398830533027649,
      "learning_rate": 1.8228318331190173e-05,
      "loss": 0.0024,
      "step": 6200
    },
    {
      "epoch": 1.3309044149164166,
      "grad_norm": 0.4214347004890442,
      "learning_rate": 1.8225460780111447e-05,
      "loss": 0.0013,
      "step": 6210
    },
    {
      "epoch": 1.3330475782254607,
      "grad_norm": 47.61793899536133,
      "learning_rate": 1.822260322903272e-05,
      "loss": 0.7669,
      "step": 6220
    },
    {
      "epoch": 1.335190741534505,
      "grad_norm": 0.02215820550918579,
      "learning_rate": 1.8219745677953994e-05,
      "loss": 0.0021,
      "step": 6230
    },
    {
      "epoch": 1.337333904843549,
      "grad_norm": 0.03656358644366264,
      "learning_rate": 1.8216888126875268e-05,
      "loss": 0.6299,
      "step": 6240
    },
    {
      "epoch": 1.3394770681525932,
      "grad_norm": 0.0743870958685875,
      "learning_rate": 1.8214030575796546e-05,
      "loss": 0.5771,
      "step": 6250
    },
    {
      "epoch": 1.3416202314616374,
      "grad_norm": 0.1975862830877304,
      "learning_rate": 1.821117302471782e-05,
      "loss": 0.2022,
      "step": 6260
    },
    {
      "epoch": 1.3437633947706815,
      "grad_norm": 0.2272379994392395,
      "learning_rate": 1.8208315473639093e-05,
      "loss": 0.156,
      "step": 6270
    },
    {
      "epoch": 1.3459065580797258,
      "grad_norm": 0.5728729963302612,
      "learning_rate": 1.8205457922560367e-05,
      "loss": 0.1568,
      "step": 6280
    },
    {
      "epoch": 1.3480497213887699,
      "grad_norm": 0.022962087765336037,
      "learning_rate": 1.820260037148164e-05,
      "loss": 0.0011,
      "step": 6290
    },
    {
      "epoch": 1.350192884697814,
      "grad_norm": 0.02123095653951168,
      "learning_rate": 1.8199742820402915e-05,
      "loss": 0.1607,
      "step": 6300
    },
    {
      "epoch": 1.3523360480068582,
      "grad_norm": 1.054565668106079,
      "learning_rate": 1.8196885269324193e-05,
      "loss": 0.4322,
      "step": 6310
    },
    {
      "epoch": 1.3544792113159023,
      "grad_norm": 0.08578776568174362,
      "learning_rate": 1.8194027718245467e-05,
      "loss": 0.5372,
      "step": 6320
    },
    {
      "epoch": 1.3566223746249464,
      "grad_norm": 0.15883025527000427,
      "learning_rate": 1.819117016716674e-05,
      "loss": 0.2398,
      "step": 6330
    },
    {
      "epoch": 1.3587655379339907,
      "grad_norm": 0.06076361984014511,
      "learning_rate": 1.8188312616088014e-05,
      "loss": 0.0086,
      "step": 6340
    },
    {
      "epoch": 1.3609087012430348,
      "grad_norm": 0.046740058809518814,
      "learning_rate": 1.8185455065009288e-05,
      "loss": 0.678,
      "step": 6350
    },
    {
      "epoch": 1.3630518645520788,
      "grad_norm": 0.07327020913362503,
      "learning_rate": 1.8182597513930562e-05,
      "loss": 0.3733,
      "step": 6360
    },
    {
      "epoch": 1.3651950278611231,
      "grad_norm": 0.025586003437638283,
      "learning_rate": 1.8179739962851836e-05,
      "loss": 0.0029,
      "step": 6370
    },
    {
      "epoch": 1.3673381911701672,
      "grad_norm": 0.02054242044687271,
      "learning_rate": 1.817688241177311e-05,
      "loss": 0.0028,
      "step": 6380
    },
    {
      "epoch": 1.3694813544792113,
      "grad_norm": 0.03031671792268753,
      "learning_rate": 1.8174024860694387e-05,
      "loss": 0.3978,
      "step": 6390
    },
    {
      "epoch": 1.3716245177882556,
      "grad_norm": 1.2463047504425049,
      "learning_rate": 1.817116730961566e-05,
      "loss": 0.3839,
      "step": 6400
    },
    {
      "epoch": 1.3737676810972996,
      "grad_norm": 0.05343654751777649,
      "learning_rate": 1.8168309758536935e-05,
      "loss": 0.2166,
      "step": 6410
    },
    {
      "epoch": 1.3759108444063437,
      "grad_norm": 0.05252959579229355,
      "learning_rate": 1.816545220745821e-05,
      "loss": 0.161,
      "step": 6420
    },
    {
      "epoch": 1.378054007715388,
      "grad_norm": 0.041397519409656525,
      "learning_rate": 1.8162594656379483e-05,
      "loss": 0.0021,
      "step": 6430
    },
    {
      "epoch": 1.380197171024432,
      "grad_norm": 0.035807978361845016,
      "learning_rate": 1.815973710530076e-05,
      "loss": 0.3099,
      "step": 6440
    },
    {
      "epoch": 1.3823403343334761,
      "grad_norm": 0.02476912923157215,
      "learning_rate": 1.8156879554222034e-05,
      "loss": 0.0551,
      "step": 6450
    },
    {
      "epoch": 1.3844834976425204,
      "grad_norm": 0.021516907960176468,
      "learning_rate": 1.8154022003143308e-05,
      "loss": 0.1681,
      "step": 6460
    },
    {
      "epoch": 1.3866266609515645,
      "grad_norm": 0.25699499249458313,
      "learning_rate": 1.8151164452064582e-05,
      "loss": 0.1813,
      "step": 6470
    },
    {
      "epoch": 1.3887698242606086,
      "grad_norm": 0.017374945804476738,
      "learning_rate": 1.8148306900985856e-05,
      "loss": 0.0009,
      "step": 6480
    },
    {
      "epoch": 1.3909129875696529,
      "grad_norm": 0.027798926457762718,
      "learning_rate": 1.814544934990713e-05,
      "loss": 0.184,
      "step": 6490
    },
    {
      "epoch": 1.393056150878697,
      "grad_norm": 0.2468293309211731,
      "learning_rate": 1.8142591798828407e-05,
      "loss": 0.6171,
      "step": 6500
    },
    {
      "epoch": 1.395199314187741,
      "grad_norm": 49.811256408691406,
      "learning_rate": 1.813973424774968e-05,
      "loss": 0.2462,
      "step": 6510
    },
    {
      "epoch": 1.3973424774967853,
      "grad_norm": 0.08658657968044281,
      "learning_rate": 1.8136876696670955e-05,
      "loss": 0.1085,
      "step": 6520
    },
    {
      "epoch": 1.3994856408058294,
      "grad_norm": 0.02789522148668766,
      "learning_rate": 1.813401914559223e-05,
      "loss": 0.0013,
      "step": 6530
    },
    {
      "epoch": 1.4016288041148735,
      "grad_norm": 0.3260420262813568,
      "learning_rate": 1.8131161594513503e-05,
      "loss": 0.0009,
      "step": 6540
    },
    {
      "epoch": 1.4037719674239177,
      "grad_norm": 48.31497573852539,
      "learning_rate": 1.8128304043434777e-05,
      "loss": 1.2396,
      "step": 6550
    },
    {
      "epoch": 1.4059151307329618,
      "grad_norm": 0.3602312207221985,
      "learning_rate": 1.812544649235605e-05,
      "loss": 0.1572,
      "step": 6560
    },
    {
      "epoch": 1.4080582940420059,
      "grad_norm": 0.03945435956120491,
      "learning_rate": 1.8122588941277325e-05,
      "loss": 0.0035,
      "step": 6570
    },
    {
      "epoch": 1.4102014573510502,
      "grad_norm": 0.030218973755836487,
      "learning_rate": 1.8119731390198602e-05,
      "loss": 0.0066,
      "step": 6580
    },
    {
      "epoch": 1.4123446206600943,
      "grad_norm": 0.017814798280596733,
      "learning_rate": 1.8116873839119876e-05,
      "loss": 0.0007,
      "step": 6590
    },
    {
      "epoch": 1.4144877839691383,
      "grad_norm": 0.05527631938457489,
      "learning_rate": 1.811401628804115e-05,
      "loss": 0.1884,
      "step": 6600
    },
    {
      "epoch": 1.4166309472781826,
      "grad_norm": 0.010780036449432373,
      "learning_rate": 1.8111158736962424e-05,
      "loss": 0.0012,
      "step": 6610
    },
    {
      "epoch": 1.4187741105872267,
      "grad_norm": 20.644712448120117,
      "learning_rate": 1.8108301185883698e-05,
      "loss": 0.3441,
      "step": 6620
    },
    {
      "epoch": 1.4209172738962708,
      "grad_norm": 0.1404184103012085,
      "learning_rate": 1.8105443634804972e-05,
      "loss": 0.1571,
      "step": 6630
    },
    {
      "epoch": 1.423060437205315,
      "grad_norm": 0.06792272627353668,
      "learning_rate": 1.810258608372625e-05,
      "loss": 0.0009,
      "step": 6640
    },
    {
      "epoch": 1.4252036005143591,
      "grad_norm": 16.389923095703125,
      "learning_rate": 1.8099728532647523e-05,
      "loss": 0.1331,
      "step": 6650
    },
    {
      "epoch": 1.4273467638234034,
      "grad_norm": 0.007380224298685789,
      "learning_rate": 1.8096870981568797e-05,
      "loss": 0.0012,
      "step": 6660
    },
    {
      "epoch": 1.4294899271324475,
      "grad_norm": 0.012811683118343353,
      "learning_rate": 1.809401343049007e-05,
      "loss": 0.0007,
      "step": 6670
    },
    {
      "epoch": 1.4316330904414916,
      "grad_norm": 0.007051735185086727,
      "learning_rate": 1.8091155879411345e-05,
      "loss": 0.0001,
      "step": 6680
    },
    {
      "epoch": 1.4337762537505359,
      "grad_norm": 0.006669220514595509,
      "learning_rate": 1.8088298328332622e-05,
      "loss": 0.0007,
      "step": 6690
    },
    {
      "epoch": 1.43591941705958,
      "grad_norm": 18.03178596496582,
      "learning_rate": 1.8085440777253896e-05,
      "loss": 0.431,
      "step": 6700
    },
    {
      "epoch": 1.4380625803686242,
      "grad_norm": 0.011874833144247532,
      "learning_rate": 1.808258322617517e-05,
      "loss": 0.0005,
      "step": 6710
    },
    {
      "epoch": 1.4402057436776683,
      "grad_norm": 18.456140518188477,
      "learning_rate": 1.8079725675096444e-05,
      "loss": 0.3125,
      "step": 6720
    },
    {
      "epoch": 1.4423489069867124,
      "grad_norm": 0.010258952155709267,
      "learning_rate": 1.8076868124017718e-05,
      "loss": 0.0003,
      "step": 6730
    },
    {
      "epoch": 1.4444920702957567,
      "grad_norm": 0.01971466839313507,
      "learning_rate": 1.8074010572938995e-05,
      "loss": 0.2572,
      "step": 6740
    },
    {
      "epoch": 1.4466352336048007,
      "grad_norm": 0.02918044477701187,
      "learning_rate": 1.807115302186027e-05,
      "loss": 0.3487,
      "step": 6750
    },
    {
      "epoch": 1.4487783969138448,
      "grad_norm": 0.029104061424732208,
      "learning_rate": 1.8068295470781543e-05,
      "loss": 0.1831,
      "step": 6760
    },
    {
      "epoch": 1.450921560222889,
      "grad_norm": 0.02310110442340374,
      "learning_rate": 1.8065437919702814e-05,
      "loss": 0.001,
      "step": 6770
    },
    {
      "epoch": 1.4530647235319332,
      "grad_norm": 18.145790100097656,
      "learning_rate": 1.806258036862409e-05,
      "loss": 0.3732,
      "step": 6780
    },
    {
      "epoch": 1.4552078868409772,
      "grad_norm": 0.013630482368171215,
      "learning_rate": 1.8059722817545365e-05,
      "loss": 0.002,
      "step": 6790
    },
    {
      "epoch": 1.4573510501500215,
      "grad_norm": 0.015567503869533539,
      "learning_rate": 1.805686526646664e-05,
      "loss": 0.1764,
      "step": 6800
    },
    {
      "epoch": 1.4594942134590656,
      "grad_norm": 0.01171217579394579,
      "learning_rate": 1.8054007715387913e-05,
      "loss": 0.0018,
      "step": 6810
    },
    {
      "epoch": 1.4616373767681097,
      "grad_norm": 0.12719900906085968,
      "learning_rate": 1.8051150164309187e-05,
      "loss": 0.001,
      "step": 6820
    },
    {
      "epoch": 1.463780540077154,
      "grad_norm": 0.01974078267812729,
      "learning_rate": 1.8048292613230464e-05,
      "loss": 0.3117,
      "step": 6830
    },
    {
      "epoch": 1.465923703386198,
      "grad_norm": 0.014925593510270119,
      "learning_rate": 1.8045435062151738e-05,
      "loss": 0.2819,
      "step": 6840
    },
    {
      "epoch": 1.4680668666952421,
      "grad_norm": 0.023091139271855354,
      "learning_rate": 1.8042577511073012e-05,
      "loss": 0.0012,
      "step": 6850
    },
    {
      "epoch": 1.4702100300042864,
      "grad_norm": 0.02330310456454754,
      "learning_rate": 1.8039719959994286e-05,
      "loss": 0.1371,
      "step": 6860
    },
    {
      "epoch": 1.4723531933133305,
      "grad_norm": 0.04333212226629257,
      "learning_rate": 1.803686240891556e-05,
      "loss": 0.102,
      "step": 6870
    },
    {
      "epoch": 1.4744963566223745,
      "grad_norm": 0.030752738937735558,
      "learning_rate": 1.8034004857836837e-05,
      "loss": 0.2516,
      "step": 6880
    },
    {
      "epoch": 1.4766395199314188,
      "grad_norm": 0.08065178245306015,
      "learning_rate": 1.803114730675811e-05,
      "loss": 0.4707,
      "step": 6890
    },
    {
      "epoch": 1.478782683240463,
      "grad_norm": 0.03447161987423897,
      "learning_rate": 1.8028289755679385e-05,
      "loss": 0.0008,
      "step": 6900
    },
    {
      "epoch": 1.480925846549507,
      "grad_norm": 20.48695182800293,
      "learning_rate": 1.802543220460066e-05,
      "loss": 0.3571,
      "step": 6910
    },
    {
      "epoch": 1.4830690098585513,
      "grad_norm": 0.03626802936196327,
      "learning_rate": 1.8022574653521933e-05,
      "loss": 0.0101,
      "step": 6920
    },
    {
      "epoch": 1.4852121731675954,
      "grad_norm": 0.02306273765861988,
      "learning_rate": 1.8019717102443207e-05,
      "loss": 0.2417,
      "step": 6930
    },
    {
      "epoch": 1.4873553364766394,
      "grad_norm": 0.020432742312550545,
      "learning_rate": 1.8016859551364484e-05,
      "loss": 0.1447,
      "step": 6940
    },
    {
      "epoch": 1.4894984997856837,
      "grad_norm": 0.015760626643896103,
      "learning_rate": 1.8014002000285758e-05,
      "loss": 0.0026,
      "step": 6950
    },
    {
      "epoch": 1.4916416630947278,
      "grad_norm": 0.009842971339821815,
      "learning_rate": 1.8011144449207032e-05,
      "loss": 0.1727,
      "step": 6960
    },
    {
      "epoch": 1.4937848264037719,
      "grad_norm": 0.02694050595164299,
      "learning_rate": 1.8008286898128306e-05,
      "loss": 0.2684,
      "step": 6970
    },
    {
      "epoch": 1.4959279897128162,
      "grad_norm": 0.024302376434206963,
      "learning_rate": 1.800542934704958e-05,
      "loss": 0.2145,
      "step": 6980
    },
    {
      "epoch": 1.4980711530218602,
      "grad_norm": 63.91067123413086,
      "learning_rate": 1.8002571795970854e-05,
      "loss": 0.585,
      "step": 6990
    },
    {
      "epoch": 1.5002143163309043,
      "grad_norm": 0.13237836956977844,
      "learning_rate": 1.7999714244892128e-05,
      "loss": 0.5071,
      "step": 7000
    },
    {
      "epoch": 1.5023574796399486,
      "grad_norm": 0.02485605888068676,
      "learning_rate": 1.79968566938134e-05,
      "loss": 0.0057,
      "step": 7010
    },
    {
      "epoch": 1.5045006429489927,
      "grad_norm": 0.032247427850961685,
      "learning_rate": 1.799399914273468e-05,
      "loss": 0.3203,
      "step": 7020
    },
    {
      "epoch": 1.5066438062580367,
      "grad_norm": 0.01972983404994011,
      "learning_rate": 1.7991141591655953e-05,
      "loss": 0.4518,
      "step": 7030
    },
    {
      "epoch": 1.508786969567081,
      "grad_norm": 0.014720645733177662,
      "learning_rate": 1.7988284040577227e-05,
      "loss": 0.3448,
      "step": 7040
    },
    {
      "epoch": 1.5109301328761253,
      "grad_norm": 0.010762520134449005,
      "learning_rate": 1.79854264894985e-05,
      "loss": 0.0063,
      "step": 7050
    },
    {
      "epoch": 1.5130732961851692,
      "grad_norm": 0.008688042871654034,
      "learning_rate": 1.7982568938419774e-05,
      "loss": 0.092,
      "step": 7060
    },
    {
      "epoch": 1.5152164594942135,
      "grad_norm": 0.0073933363892138,
      "learning_rate": 1.797971138734105e-05,
      "loss": 0.0016,
      "step": 7070
    },
    {
      "epoch": 1.5173596228032578,
      "grad_norm": 0.005741563159972429,
      "learning_rate": 1.7976853836262326e-05,
      "loss": 0.0007,
      "step": 7080
    },
    {
      "epoch": 1.5195027861123016,
      "grad_norm": 0.008868257515132427,
      "learning_rate": 1.79739962851836e-05,
      "loss": 0.4804,
      "step": 7090
    },
    {
      "epoch": 1.521645949421346,
      "grad_norm": 0.011689357459545135,
      "learning_rate": 1.7971138734104874e-05,
      "loss": 0.0007,
      "step": 7100
    },
    {
      "epoch": 1.5237891127303902,
      "grad_norm": 0.02073981985449791,
      "learning_rate": 1.7968281183026147e-05,
      "loss": 0.0003,
      "step": 7110
    },
    {
      "epoch": 1.525932276039434,
      "grad_norm": 0.037602536380290985,
      "learning_rate": 1.796542363194742e-05,
      "loss": 0.0006,
      "step": 7120
    },
    {
      "epoch": 1.5280754393484783,
      "grad_norm": 0.00866734515875578,
      "learning_rate": 1.79625660808687e-05,
      "loss": 0.2102,
      "step": 7130
    },
    {
      "epoch": 1.5302186026575226,
      "grad_norm": 0.013391141779720783,
      "learning_rate": 1.7959708529789973e-05,
      "loss": 0.0004,
      "step": 7140
    },
    {
      "epoch": 1.5323617659665667,
      "grad_norm": 0.009974083863198757,
      "learning_rate": 1.7956850978711247e-05,
      "loss": 0.0006,
      "step": 7150
    },
    {
      "epoch": 1.5345049292756108,
      "grad_norm": 0.004614378325641155,
      "learning_rate": 1.795399342763252e-05,
      "loss": 0.0004,
      "step": 7160
    },
    {
      "epoch": 1.536648092584655,
      "grad_norm": 0.07229127734899521,
      "learning_rate": 1.7951135876553794e-05,
      "loss": 0.0004,
      "step": 7170
    },
    {
      "epoch": 1.5387912558936991,
      "grad_norm": 0.006731733679771423,
      "learning_rate": 1.7948278325475072e-05,
      "loss": 0.0006,
      "step": 7180
    },
    {
      "epoch": 1.5409344192027432,
      "grad_norm": 0.0068932040594518185,
      "learning_rate": 1.7945420774396346e-05,
      "loss": 0.0001,
      "step": 7190
    },
    {
      "epoch": 1.5430775825117875,
      "grad_norm": 0.06393801420927048,
      "learning_rate": 1.7942563223317616e-05,
      "loss": 0.309,
      "step": 7200
    },
    {
      "epoch": 1.5452207458208316,
      "grad_norm": 0.012659486383199692,
      "learning_rate": 1.793970567223889e-05,
      "loss": 0.1864,
      "step": 7210
    },
    {
      "epoch": 1.5473639091298756,
      "grad_norm": 0.01479441300034523,
      "learning_rate": 1.7936848121160167e-05,
      "loss": 0.2268,
      "step": 7220
    },
    {
      "epoch": 1.54950707243892,
      "grad_norm": 0.014782169833779335,
      "learning_rate": 1.793399057008144e-05,
      "loss": 0.2056,
      "step": 7230
    },
    {
      "epoch": 1.551650235747964,
      "grad_norm": 0.23315048217773438,
      "learning_rate": 1.7931133019002715e-05,
      "loss": 0.4204,
      "step": 7240
    },
    {
      "epoch": 1.553793399057008,
      "grad_norm": 0.03705538809299469,
      "learning_rate": 1.792827546792399e-05,
      "loss": 0.1328,
      "step": 7250
    },
    {
      "epoch": 1.5559365623660524,
      "grad_norm": 0.16906258463859558,
      "learning_rate": 1.7925417916845263e-05,
      "loss": 0.7232,
      "step": 7260
    },
    {
      "epoch": 1.5580797256750964,
      "grad_norm": 17.984966278076172,
      "learning_rate": 1.792256036576654e-05,
      "loss": 0.2111,
      "step": 7270
    },
    {
      "epoch": 1.5602228889841405,
      "grad_norm": 141.2674560546875,
      "learning_rate": 1.7919702814687814e-05,
      "loss": 0.4744,
      "step": 7280
    },
    {
      "epoch": 1.5623660522931848,
      "grad_norm": 0.0803169310092926,
      "learning_rate": 1.791684526360909e-05,
      "loss": 0.3723,
      "step": 7290
    },
    {
      "epoch": 1.5645092156022289,
      "grad_norm": 0.02986358106136322,
      "learning_rate": 1.7913987712530362e-05,
      "loss": 0.0013,
      "step": 7300
    },
    {
      "epoch": 1.566652378911273,
      "grad_norm": 0.03512110561132431,
      "learning_rate": 1.7911130161451636e-05,
      "loss": 0.3437,
      "step": 7310
    },
    {
      "epoch": 1.5687955422203173,
      "grad_norm": 18.909652709960938,
      "learning_rate": 1.7908272610372914e-05,
      "loss": 0.2089,
      "step": 7320
    },
    {
      "epoch": 1.5709387055293613,
      "grad_norm": 0.12093456089496613,
      "learning_rate": 1.7905415059294187e-05,
      "loss": 0.004,
      "step": 7330
    },
    {
      "epoch": 1.5730818688384054,
      "grad_norm": 0.04113534465432167,
      "learning_rate": 1.790255750821546e-05,
      "loss": 0.002,
      "step": 7340
    },
    {
      "epoch": 1.5752250321474497,
      "grad_norm": 0.09265843033790588,
      "learning_rate": 1.7899699957136735e-05,
      "loss": 0.001,
      "step": 7350
    },
    {
      "epoch": 1.5773681954564938,
      "grad_norm": 0.022621044889092445,
      "learning_rate": 1.789684240605801e-05,
      "loss": 0.0005,
      "step": 7360
    },
    {
      "epoch": 1.5795113587655378,
      "grad_norm": 0.023291435092687607,
      "learning_rate": 1.7893984854979287e-05,
      "loss": 0.206,
      "step": 7370
    },
    {
      "epoch": 1.5816545220745821,
      "grad_norm": 0.01981504261493683,
      "learning_rate": 1.789112730390056e-05,
      "loss": 0.0246,
      "step": 7380
    },
    {
      "epoch": 1.5837976853836262,
      "grad_norm": 45.080081939697266,
      "learning_rate": 1.7888269752821834e-05,
      "loss": 0.2422,
      "step": 7390
    },
    {
      "epoch": 1.5859408486926703,
      "grad_norm": 0.006408259738236666,
      "learning_rate": 1.788541220174311e-05,
      "loss": 0.0004,
      "step": 7400
    },
    {
      "epoch": 1.5880840120017146,
      "grad_norm": 0.01298708189278841,
      "learning_rate": 1.7882554650664382e-05,
      "loss": 0.1253,
      "step": 7410
    },
    {
      "epoch": 1.5902271753107586,
      "grad_norm": 0.013727757148444653,
      "learning_rate": 1.7879697099585656e-05,
      "loss": 0.2361,
      "step": 7420
    },
    {
      "epoch": 1.5923703386198027,
      "grad_norm": 1.3053417205810547,
      "learning_rate": 1.787683954850693e-05,
      "loss": 0.2019,
      "step": 7430
    },
    {
      "epoch": 1.594513501928847,
      "grad_norm": 0.029446570202708244,
      "learning_rate": 1.7873981997428204e-05,
      "loss": 0.3457,
      "step": 7440
    },
    {
      "epoch": 1.5966566652378913,
      "grad_norm": 23.35369110107422,
      "learning_rate": 1.7871124446349478e-05,
      "loss": 0.2556,
      "step": 7450
    },
    {
      "epoch": 1.5987998285469351,
      "grad_norm": 21.970951080322266,
      "learning_rate": 1.7868266895270755e-05,
      "loss": 0.2502,
      "step": 7460
    },
    {
      "epoch": 1.6009429918559794,
      "grad_norm": 0.018941646441817284,
      "learning_rate": 1.786540934419203e-05,
      "loss": 0.1782,
      "step": 7470
    },
    {
      "epoch": 1.6030861551650237,
      "grad_norm": 0.03179169073700905,
      "learning_rate": 1.7862551793113303e-05,
      "loss": 0.0011,
      "step": 7480
    },
    {
      "epoch": 1.6052293184740676,
      "grad_norm": 0.028183290734887123,
      "learning_rate": 1.7859694242034577e-05,
      "loss": 0.0013,
      "step": 7490
    },
    {
      "epoch": 1.6073724817831119,
      "grad_norm": 0.09845370054244995,
      "learning_rate": 1.785683669095585e-05,
      "loss": 0.1618,
      "step": 7500
    },
    {
      "epoch": 1.6095156450921562,
      "grad_norm": 0.021484270691871643,
      "learning_rate": 1.785397913987713e-05,
      "loss": 0.0007,
      "step": 7510
    },
    {
      "epoch": 1.6116588084012,
      "grad_norm": 0.008171585388481617,
      "learning_rate": 1.7851121588798402e-05,
      "loss": 0.1855,
      "step": 7520
    },
    {
      "epoch": 1.6138019717102443,
      "grad_norm": 0.008429210633039474,
      "learning_rate": 1.7848264037719676e-05,
      "loss": 0.0707,
      "step": 7530
    },
    {
      "epoch": 1.6159451350192886,
      "grad_norm": 0.006939012091606855,
      "learning_rate": 1.784540648664095e-05,
      "loss": 0.0007,
      "step": 7540
    },
    {
      "epoch": 1.6180882983283325,
      "grad_norm": 46.75822067260742,
      "learning_rate": 1.7842548935562224e-05,
      "loss": 1.0441,
      "step": 7550
    },
    {
      "epoch": 1.6202314616373767,
      "grad_norm": 0.24603676795959473,
      "learning_rate": 1.7839691384483498e-05,
      "loss": 0.0024,
      "step": 7560
    },
    {
      "epoch": 1.622374624946421,
      "grad_norm": 0.05935148894786835,
      "learning_rate": 1.7836833833404775e-05,
      "loss": 0.279,
      "step": 7570
    },
    {
      "epoch": 1.6245177882554651,
      "grad_norm": 0.02268795296549797,
      "learning_rate": 1.783397628232605e-05,
      "loss": 0.0016,
      "step": 7580
    },
    {
      "epoch": 1.6266609515645092,
      "grad_norm": 0.02381330542266369,
      "learning_rate": 1.7831118731247323e-05,
      "loss": 0.2052,
      "step": 7590
    },
    {
      "epoch": 1.6288041148735535,
      "grad_norm": 0.019355827942490578,
      "learning_rate": 1.7828261180168597e-05,
      "loss": 0.1548,
      "step": 7600
    },
    {
      "epoch": 1.6309472781825975,
      "grad_norm": 0.07235357165336609,
      "learning_rate": 1.782540362908987e-05,
      "loss": 0.1731,
      "step": 7610
    },
    {
      "epoch": 1.6330904414916416,
      "grad_norm": 18.62175941467285,
      "learning_rate": 1.782254607801115e-05,
      "loss": 0.5484,
      "step": 7620
    },
    {
      "epoch": 1.635233604800686,
      "grad_norm": 0.013974320143461227,
      "learning_rate": 1.781968852693242e-05,
      "loss": 0.0009,
      "step": 7630
    },
    {
      "epoch": 1.63737676810973,
      "grad_norm": 0.012259789742529392,
      "learning_rate": 1.7816830975853693e-05,
      "loss": 0.1239,
      "step": 7640
    },
    {
      "epoch": 1.639519931418774,
      "grad_norm": 21.5217342376709,
      "learning_rate": 1.781397342477497e-05,
      "loss": 0.2158,
      "step": 7650
    },
    {
      "epoch": 1.6416630947278184,
      "grad_norm": 0.08444393426179886,
      "learning_rate": 1.7811115873696244e-05,
      "loss": 0.1075,
      "step": 7660
    },
    {
      "epoch": 1.6438062580368624,
      "grad_norm": 17.244552612304688,
      "learning_rate": 1.7808258322617518e-05,
      "loss": 0.3262,
      "step": 7670
    },
    {
      "epoch": 1.6459494213459065,
      "grad_norm": 0.01973007433116436,
      "learning_rate": 1.7805400771538792e-05,
      "loss": 0.0953,
      "step": 7680
    },
    {
      "epoch": 1.6480925846549508,
      "grad_norm": 0.3076948821544647,
      "learning_rate": 1.7802543220460066e-05,
      "loss": 0.1102,
      "step": 7690
    },
    {
      "epoch": 1.6502357479639949,
      "grad_norm": 0.007146334275603294,
      "learning_rate": 1.779968566938134e-05,
      "loss": 0.1049,
      "step": 7700
    },
    {
      "epoch": 1.652378911273039,
      "grad_norm": 0.0286550372838974,
      "learning_rate": 1.7796828118302617e-05,
      "loss": 0.1161,
      "step": 7710
    },
    {
      "epoch": 1.6545220745820832,
      "grad_norm": 0.0030968908686190844,
      "learning_rate": 1.779397056722389e-05,
      "loss": 0.0058,
      "step": 7720
    },
    {
      "epoch": 1.6566652378911273,
      "grad_norm": 0.2797955274581909,
      "learning_rate": 1.7791113016145165e-05,
      "loss": 0.3032,
      "step": 7730
    },
    {
      "epoch": 1.6588084012001714,
      "grad_norm": 0.050414808094501495,
      "learning_rate": 1.778825546506644e-05,
      "loss": 0.0008,
      "step": 7740
    },
    {
      "epoch": 1.6609515645092157,
      "grad_norm": 0.0046613784506917,
      "learning_rate": 1.7785397913987713e-05,
      "loss": 0.0004,
      "step": 7750
    },
    {
      "epoch": 1.6630947278182597,
      "grad_norm": 0.07015755027532578,
      "learning_rate": 1.778254036290899e-05,
      "loss": 1.1276,
      "step": 7760
    },
    {
      "epoch": 1.6652378911273038,
      "grad_norm": 0.05651383846998215,
      "learning_rate": 1.7779682811830264e-05,
      "loss": 0.1714,
      "step": 7770
    },
    {
      "epoch": 1.667381054436348,
      "grad_norm": 0.025960758328437805,
      "learning_rate": 1.7776825260751538e-05,
      "loss": 0.0044,
      "step": 7780
    },
    {
      "epoch": 1.6695242177453922,
      "grad_norm": 0.0735040009021759,
      "learning_rate": 1.7773967709672812e-05,
      "loss": 0.2022,
      "step": 7790
    },
    {
      "epoch": 1.6716673810544362,
      "grad_norm": 0.023683108389377594,
      "learning_rate": 1.7771110158594086e-05,
      "loss": 0.0011,
      "step": 7800
    },
    {
      "epoch": 1.6738105443634805,
      "grad_norm": 0.02767437882721424,
      "learning_rate": 1.7768252607515363e-05,
      "loss": 0.0014,
      "step": 7810
    },
    {
      "epoch": 1.6759537076725246,
      "grad_norm": 0.017540525645017624,
      "learning_rate": 1.7765395056436637e-05,
      "loss": 0.0003,
      "step": 7820
    },
    {
      "epoch": 1.6780968709815687,
      "grad_norm": 0.17664729058742523,
      "learning_rate": 1.776253750535791e-05,
      "loss": 0.486,
      "step": 7830
    },
    {
      "epoch": 1.680240034290613,
      "grad_norm": 0.03452068567276001,
      "learning_rate": 1.775967995427918e-05,
      "loss": 0.0009,
      "step": 7840
    },
    {
      "epoch": 1.682383197599657,
      "grad_norm": 0.019332030788064003,
      "learning_rate": 1.775682240320046e-05,
      "loss": 0.0015,
      "step": 7850
    },
    {
      "epoch": 1.6845263609087011,
      "grad_norm": 0.005719844251871109,
      "learning_rate": 1.7753964852121733e-05,
      "loss": 0.0046,
      "step": 7860
    },
    {
      "epoch": 1.6866695242177454,
      "grad_norm": 0.007387950550764799,
      "learning_rate": 1.7751107301043007e-05,
      "loss": 0.2292,
      "step": 7870
    },
    {
      "epoch": 1.6888126875267897,
      "grad_norm": 0.0071956501342356205,
      "learning_rate": 1.774824974996428e-05,
      "loss": 0.1641,
      "step": 7880
    },
    {
      "epoch": 1.6909558508358336,
      "grad_norm": 0.009859629906713963,
      "learning_rate": 1.7745392198885555e-05,
      "loss": 0.0004,
      "step": 7890
    },
    {
      "epoch": 1.6930990141448778,
      "grad_norm": 0.014703229069709778,
      "learning_rate": 1.7742534647806832e-05,
      "loss": 0.2382,
      "step": 7900
    },
    {
      "epoch": 1.6952421774539221,
      "grad_norm": 0.1271858811378479,
      "learning_rate": 1.7739677096728106e-05,
      "loss": 0.2565,
      "step": 7910
    },
    {
      "epoch": 1.697385340762966,
      "grad_norm": 0.09595771133899689,
      "learning_rate": 1.773681954564938e-05,
      "loss": 0.001,
      "step": 7920
    },
    {
      "epoch": 1.6995285040720103,
      "grad_norm": 0.32441073656082153,
      "learning_rate": 1.7733961994570654e-05,
      "loss": 0.319,
      "step": 7930
    },
    {
      "epoch": 1.7016716673810546,
      "grad_norm": 0.016104161739349365,
      "learning_rate": 1.7731104443491928e-05,
      "loss": 0.0008,
      "step": 7940
    },
    {
      "epoch": 1.7038148306900984,
      "grad_norm": 0.018985440954566002,
      "learning_rate": 1.7728246892413205e-05,
      "loss": 0.2358,
      "step": 7950
    },
    {
      "epoch": 1.7059579939991427,
      "grad_norm": 0.2746157944202423,
      "learning_rate": 1.772538934133448e-05,
      "loss": 0.7149,
      "step": 7960
    },
    {
      "epoch": 1.708101157308187,
      "grad_norm": 0.07571423053741455,
      "learning_rate": 1.7722531790255753e-05,
      "loss": 0.0062,
      "step": 7970
    },
    {
      "epoch": 1.710244320617231,
      "grad_norm": 0.05638886243104935,
      "learning_rate": 1.7719674239177027e-05,
      "loss": 0.0023,
      "step": 7980
    },
    {
      "epoch": 1.7123874839262752,
      "grad_norm": 0.009145672433078289,
      "learning_rate": 1.77168166880983e-05,
      "loss": 0.0005,
      "step": 7990
    },
    {
      "epoch": 1.7145306472353194,
      "grad_norm": 0.008630807511508465,
      "learning_rate": 1.7713959137019578e-05,
      "loss": 0.2381,
      "step": 8000
    },
    {
      "epoch": 1.7166738105443635,
      "grad_norm": 0.041398294270038605,
      "learning_rate": 1.7711101585940852e-05,
      "loss": 0.0002,
      "step": 8010
    },
    {
      "epoch": 1.7188169738534076,
      "grad_norm": 0.008857037872076035,
      "learning_rate": 1.7708244034862126e-05,
      "loss": 0.0003,
      "step": 8020
    },
    {
      "epoch": 1.7209601371624519,
      "grad_norm": 0.07454099506139755,
      "learning_rate": 1.77053864837834e-05,
      "loss": 0.0008,
      "step": 8030
    },
    {
      "epoch": 1.723103300471496,
      "grad_norm": 0.004967230372130871,
      "learning_rate": 1.7702528932704674e-05,
      "loss": 0.0002,
      "step": 8040
    },
    {
      "epoch": 1.72524646378054,
      "grad_norm": 0.003907076548784971,
      "learning_rate": 1.7699671381625948e-05,
      "loss": 0.2158,
      "step": 8050
    },
    {
      "epoch": 1.7273896270895843,
      "grad_norm": 0.003097012173384428,
      "learning_rate": 1.769681383054722e-05,
      "loss": 0.0004,
      "step": 8060
    },
    {
      "epoch": 1.7295327903986284,
      "grad_norm": 0.0024538221769034863,
      "learning_rate": 1.7693956279468495e-05,
      "loss": 0.3491,
      "step": 8070
    },
    {
      "epoch": 1.7316759537076725,
      "grad_norm": 0.007677392568439245,
      "learning_rate": 1.769109872838977e-05,
      "loss": 0.0001,
      "step": 8080
    },
    {
      "epoch": 1.7338191170167168,
      "grad_norm": 0.02007414773106575,
      "learning_rate": 1.7688241177311047e-05,
      "loss": 0.5745,
      "step": 8090
    },
    {
      "epoch": 1.7359622803257608,
      "grad_norm": 0.013764811679720879,
      "learning_rate": 1.768538362623232e-05,
      "loss": 0.1999,
      "step": 8100
    },
    {
      "epoch": 1.738105443634805,
      "grad_norm": 0.03063182160258293,
      "learning_rate": 1.7682526075153595e-05,
      "loss": 0.4117,
      "step": 8110
    },
    {
      "epoch": 1.7402486069438492,
      "grad_norm": 0.08463246375322342,
      "learning_rate": 1.767966852407487e-05,
      "loss": 0.1817,
      "step": 8120
    },
    {
      "epoch": 1.7423917702528933,
      "grad_norm": 0.08874593675136566,
      "learning_rate": 1.7676810972996142e-05,
      "loss": 0.3093,
      "step": 8130
    },
    {
      "epoch": 1.7445349335619373,
      "grad_norm": 0.036702051758766174,
      "learning_rate": 1.767395342191742e-05,
      "loss": 0.1238,
      "step": 8140
    },
    {
      "epoch": 1.7466780968709816,
      "grad_norm": 0.05160896107554436,
      "learning_rate": 1.7671095870838694e-05,
      "loss": 0.2282,
      "step": 8150
    },
    {
      "epoch": 1.7488212601800257,
      "grad_norm": 0.02067413367331028,
      "learning_rate": 1.7668238319759968e-05,
      "loss": 0.0593,
      "step": 8160
    },
    {
      "epoch": 1.7509644234890698,
      "grad_norm": 0.11976589262485504,
      "learning_rate": 1.766538076868124e-05,
      "loss": 0.0012,
      "step": 8170
    },
    {
      "epoch": 1.753107586798114,
      "grad_norm": 0.012031756341457367,
      "learning_rate": 1.7662523217602515e-05,
      "loss": 0.0194,
      "step": 8180
    },
    {
      "epoch": 1.7552507501071581,
      "grad_norm": 0.006395905744284391,
      "learning_rate": 1.765966566652379e-05,
      "loss": 0.1418,
      "step": 8190
    },
    {
      "epoch": 1.7573939134162022,
      "grad_norm": 0.006493111606687307,
      "learning_rate": 1.7656808115445067e-05,
      "loss": 0.1357,
      "step": 8200
    },
    {
      "epoch": 1.7595370767252465,
      "grad_norm": 19.973344802856445,
      "learning_rate": 1.765395056436634e-05,
      "loss": 0.3986,
      "step": 8210
    },
    {
      "epoch": 1.7616802400342906,
      "grad_norm": 0.009103016927838326,
      "learning_rate": 1.7651093013287615e-05,
      "loss": 0.0016,
      "step": 8220
    },
    {
      "epoch": 1.7638234033433347,
      "grad_norm": 0.009612884372472763,
      "learning_rate": 1.764823546220889e-05,
      "loss": 0.4733,
      "step": 8230
    },
    {
      "epoch": 1.765966566652379,
      "grad_norm": 0.010317143052816391,
      "learning_rate": 1.7645377911130162e-05,
      "loss": 0.2657,
      "step": 8240
    },
    {
      "epoch": 1.768109729961423,
      "grad_norm": 18.076290130615234,
      "learning_rate": 1.764252036005144e-05,
      "loss": 0.3045,
      "step": 8250
    },
    {
      "epoch": 1.770252893270467,
      "grad_norm": 40.97014617919922,
      "learning_rate": 1.7639662808972714e-05,
      "loss": 0.2922,
      "step": 8260
    },
    {
      "epoch": 1.7723960565795114,
      "grad_norm": 0.062489647418260574,
      "learning_rate": 1.7636805257893984e-05,
      "loss": 0.2134,
      "step": 8270
    },
    {
      "epoch": 1.7745392198885555,
      "grad_norm": 0.10594750195741653,
      "learning_rate": 1.763394770681526e-05,
      "loss": 0.0684,
      "step": 8280
    },
    {
      "epoch": 1.7766823831975995,
      "grad_norm": 0.03185765817761421,
      "learning_rate": 1.7631090155736535e-05,
      "loss": 0.1501,
      "step": 8290
    },
    {
      "epoch": 1.7788255465066438,
      "grad_norm": 0.016304954886436462,
      "learning_rate": 1.762823260465781e-05,
      "loss": 0.0009,
      "step": 8300
    },
    {
      "epoch": 1.7809687098156881,
      "grad_norm": 0.019948329776525497,
      "learning_rate": 1.7625375053579083e-05,
      "loss": 0.0005,
      "step": 8310
    },
    {
      "epoch": 1.783111873124732,
      "grad_norm": 0.09122379124164581,
      "learning_rate": 1.7622517502500357e-05,
      "loss": 0.3173,
      "step": 8320
    },
    {
      "epoch": 1.7852550364337763,
      "grad_norm": 0.6211404204368591,
      "learning_rate": 1.761965995142163e-05,
      "loss": 0.1858,
      "step": 8330
    },
    {
      "epoch": 1.7873981997428205,
      "grad_norm": 26.4112491607666,
      "learning_rate": 1.761680240034291e-05,
      "loss": 0.4815,
      "step": 8340
    },
    {
      "epoch": 1.7895413630518644,
      "grad_norm": 0.1515897512435913,
      "learning_rate": 1.7613944849264182e-05,
      "loss": 0.2088,
      "step": 8350
    },
    {
      "epoch": 1.7916845263609087,
      "grad_norm": 0.038819897919893265,
      "learning_rate": 1.7611087298185456e-05,
      "loss": 0.3388,
      "step": 8360
    },
    {
      "epoch": 1.793827689669953,
      "grad_norm": 0.051681894809007645,
      "learning_rate": 1.760822974710673e-05,
      "loss": 0.244,
      "step": 8370
    },
    {
      "epoch": 1.7959708529789968,
      "grad_norm": 0.5744006037712097,
      "learning_rate": 1.7605372196028004e-05,
      "loss": 0.197,
      "step": 8380
    },
    {
      "epoch": 1.7981140162880411,
      "grad_norm": 0.08001463115215302,
      "learning_rate": 1.760251464494928e-05,
      "loss": 0.2308,
      "step": 8390
    },
    {
      "epoch": 1.8002571795970854,
      "grad_norm": 0.018858646973967552,
      "learning_rate": 1.7599657093870555e-05,
      "loss": 0.142,
      "step": 8400
    },
    {
      "epoch": 1.8024003429061295,
      "grad_norm": 0.4978843331336975,
      "learning_rate": 1.759679954279183e-05,
      "loss": 0.2234,
      "step": 8410
    },
    {
      "epoch": 1.8045435062151736,
      "grad_norm": 0.02690725401043892,
      "learning_rate": 1.7593941991713103e-05,
      "loss": 0.2078,
      "step": 8420
    },
    {
      "epoch": 1.8066866695242179,
      "grad_norm": 0.016526974737644196,
      "learning_rate": 1.7591084440634377e-05,
      "loss": 0.3361,
      "step": 8430
    },
    {
      "epoch": 1.808829832833262,
      "grad_norm": 0.029647542163729668,
      "learning_rate": 1.7588226889555654e-05,
      "loss": 0.0074,
      "step": 8440
    },
    {
      "epoch": 1.810972996142306,
      "grad_norm": 0.013979999348521233,
      "learning_rate": 1.758536933847693e-05,
      "loss": 0.0537,
      "step": 8450
    },
    {
      "epoch": 1.8131161594513503,
      "grad_norm": 0.007705377414822578,
      "learning_rate": 1.7582511787398202e-05,
      "loss": 0.0739,
      "step": 8460
    },
    {
      "epoch": 1.8152593227603944,
      "grad_norm": 0.0064379251562058926,
      "learning_rate": 1.7579654236319476e-05,
      "loss": 0.3344,
      "step": 8470
    },
    {
      "epoch": 1.8174024860694384,
      "grad_norm": 0.00751839904114604,
      "learning_rate": 1.757679668524075e-05,
      "loss": 0.2525,
      "step": 8480
    },
    {
      "epoch": 1.8195456493784827,
      "grad_norm": 0.030549362301826477,
      "learning_rate": 1.7573939134162024e-05,
      "loss": 0.3502,
      "step": 8490
    },
    {
      "epoch": 1.8216888126875268,
      "grad_norm": 0.0583774670958519,
      "learning_rate": 1.7571081583083298e-05,
      "loss": 0.0018,
      "step": 8500
    },
    {
      "epoch": 1.8238319759965709,
      "grad_norm": 0.022474151104688644,
      "learning_rate": 1.7568224032004572e-05,
      "loss": 0.1583,
      "step": 8510
    },
    {
      "epoch": 1.8259751393056152,
      "grad_norm": 0.0450977087020874,
      "learning_rate": 1.7565366480925846e-05,
      "loss": 0.6003,
      "step": 8520
    },
    {
      "epoch": 1.8281183026146592,
      "grad_norm": 0.07837225496768951,
      "learning_rate": 1.7562508929847123e-05,
      "loss": 0.002,
      "step": 8530
    },
    {
      "epoch": 1.8302614659237033,
      "grad_norm": 0.060387518256902695,
      "learning_rate": 1.7559651378768397e-05,
      "loss": 0.1072,
      "step": 8540
    },
    {
      "epoch": 1.8324046292327476,
      "grad_norm": 0.021124042570590973,
      "learning_rate": 1.755679382768967e-05,
      "loss": 0.0015,
      "step": 8550
    },
    {
      "epoch": 1.8345477925417917,
      "grad_norm": 0.029348980635404587,
      "learning_rate": 1.7553936276610945e-05,
      "loss": 0.1439,
      "step": 8560
    },
    {
      "epoch": 1.8366909558508357,
      "grad_norm": 0.012877111323177814,
      "learning_rate": 1.755107872553222e-05,
      "loss": 0.0005,
      "step": 8570
    },
    {
      "epoch": 1.83883411915988,
      "grad_norm": 0.0390840582549572,
      "learning_rate": 1.7548221174453496e-05,
      "loss": 0.2374,
      "step": 8580
    },
    {
      "epoch": 1.8409772824689241,
      "grad_norm": 0.017769688740372658,
      "learning_rate": 1.754536362337477e-05,
      "loss": 0.0011,
      "step": 8590
    },
    {
      "epoch": 1.8431204457779682,
      "grad_norm": 0.014895057305693626,
      "learning_rate": 1.7542506072296044e-05,
      "loss": 0.2012,
      "step": 8600
    },
    {
      "epoch": 1.8452636090870125,
      "grad_norm": 0.01634405553340912,
      "learning_rate": 1.7539648521217318e-05,
      "loss": 0.0006,
      "step": 8610
    },
    {
      "epoch": 1.8474067723960566,
      "grad_norm": 0.009819330647587776,
      "learning_rate": 1.7536790970138592e-05,
      "loss": 0.0003,
      "step": 8620
    },
    {
      "epoch": 1.8495499357051006,
      "grad_norm": 0.15596802532672882,
      "learning_rate": 1.7533933419059866e-05,
      "loss": 0.4074,
      "step": 8630
    },
    {
      "epoch": 1.851693099014145,
      "grad_norm": 0.016818726435303688,
      "learning_rate": 1.7531075867981143e-05,
      "loss": 0.0123,
      "step": 8640
    },
    {
      "epoch": 1.853836262323189,
      "grad_norm": 26.250064849853516,
      "learning_rate": 1.7528218316902417e-05,
      "loss": 0.2644,
      "step": 8650
    },
    {
      "epoch": 1.855979425632233,
      "grad_norm": 0.013621182180941105,
      "learning_rate": 1.752536076582369e-05,
      "loss": 0.2101,
      "step": 8660
    },
    {
      "epoch": 1.8581225889412774,
      "grad_norm": 0.013909008353948593,
      "learning_rate": 1.7522503214744965e-05,
      "loss": 0.0003,
      "step": 8670
    },
    {
      "epoch": 1.8602657522503214,
      "grad_norm": 0.010604515671730042,
      "learning_rate": 1.751964566366624e-05,
      "loss": 0.0011,
      "step": 8680
    },
    {
      "epoch": 1.8624089155593655,
      "grad_norm": 0.011144534684717655,
      "learning_rate": 1.7516788112587516e-05,
      "loss": 0.145,
      "step": 8690
    },
    {
      "epoch": 1.8645520788684098,
      "grad_norm": 0.015221484936773777,
      "learning_rate": 1.7513930561508787e-05,
      "loss": 0.4387,
      "step": 8700
    },
    {
      "epoch": 1.866695242177454,
      "grad_norm": 1.7147674560546875,
      "learning_rate": 1.751107301043006e-05,
      "loss": 0.2586,
      "step": 8710
    },
    {
      "epoch": 1.868838405486498,
      "grad_norm": 0.1079627126455307,
      "learning_rate": 1.7508215459351338e-05,
      "loss": 0.516,
      "step": 8720
    },
    {
      "epoch": 1.8709815687955422,
      "grad_norm": 0.07348992675542831,
      "learning_rate": 1.7505357908272612e-05,
      "loss": 0.121,
      "step": 8730
    },
    {
      "epoch": 1.8731247321045865,
      "grad_norm": 0.050307296216487885,
      "learning_rate": 1.7502500357193886e-05,
      "loss": 0.1083,
      "step": 8740
    },
    {
      "epoch": 1.8752678954136304,
      "grad_norm": 0.022450454533100128,
      "learning_rate": 1.749964280611516e-05,
      "loss": 0.002,
      "step": 8750
    },
    {
      "epoch": 1.8774110587226747,
      "grad_norm": 0.02988600917160511,
      "learning_rate": 1.7496785255036434e-05,
      "loss": 0.1168,
      "step": 8760
    },
    {
      "epoch": 1.879554222031719,
      "grad_norm": 0.16084741055965424,
      "learning_rate": 1.7493927703957708e-05,
      "loss": 0.0006,
      "step": 8770
    },
    {
      "epoch": 1.8816973853407628,
      "grad_norm": 0.020147426053881645,
      "learning_rate": 1.7491070152878985e-05,
      "loss": 0.0007,
      "step": 8780
    },
    {
      "epoch": 1.883840548649807,
      "grad_norm": 0.023912640288472176,
      "learning_rate": 1.748821260180026e-05,
      "loss": 0.001,
      "step": 8790
    },
    {
      "epoch": 1.8859837119588514,
      "grad_norm": 0.018554991111159325,
      "learning_rate": 1.7485355050721533e-05,
      "loss": 0.0003,
      "step": 8800
    },
    {
      "epoch": 1.8881268752678955,
      "grad_norm": 0.012405031360685825,
      "learning_rate": 1.7482497499642807e-05,
      "loss": 0.3012,
      "step": 8810
    },
    {
      "epoch": 1.8902700385769395,
      "grad_norm": 0.011267741210758686,
      "learning_rate": 1.747963994856408e-05,
      "loss": 0.0004,
      "step": 8820
    },
    {
      "epoch": 1.8924132018859838,
      "grad_norm": 0.048588644713163376,
      "learning_rate": 1.7476782397485358e-05,
      "loss": 0.0004,
      "step": 8830
    },
    {
      "epoch": 1.894556365195028,
      "grad_norm": 0.032465312629938126,
      "learning_rate": 1.7473924846406632e-05,
      "loss": 0.1871,
      "step": 8840
    },
    {
      "epoch": 1.896699528504072,
      "grad_norm": 0.005586911458522081,
      "learning_rate": 1.7471067295327906e-05,
      "loss": 0.2968,
      "step": 8850
    },
    {
      "epoch": 1.8988426918131163,
      "grad_norm": 0.03162231668829918,
      "learning_rate": 1.746820974424918e-05,
      "loss": 0.0005,
      "step": 8860
    },
    {
      "epoch": 1.9009858551221603,
      "grad_norm": 0.009095486253499985,
      "learning_rate": 1.7465352193170454e-05,
      "loss": 0.0011,
      "step": 8870
    },
    {
      "epoch": 1.9031290184312044,
      "grad_norm": 0.019833460450172424,
      "learning_rate": 1.746249464209173e-05,
      "loss": 0.2277,
      "step": 8880
    },
    {
      "epoch": 1.9052721817402487,
      "grad_norm": 0.012014077976346016,
      "learning_rate": 1.7459637091013005e-05,
      "loss": 0.0005,
      "step": 8890
    },
    {
      "epoch": 1.9074153450492928,
      "grad_norm": 0.013064068742096424,
      "learning_rate": 1.745677953993428e-05,
      "loss": 0.4284,
      "step": 8900
    },
    {
      "epoch": 1.9095585083583368,
      "grad_norm": 0.016265664249658585,
      "learning_rate": 1.745392198885555e-05,
      "loss": 0.0005,
      "step": 8910
    },
    {
      "epoch": 1.9117016716673811,
      "grad_norm": 0.2181858867406845,
      "learning_rate": 1.7451064437776827e-05,
      "loss": 0.0445,
      "step": 8920
    },
    {
      "epoch": 1.9138448349764252,
      "grad_norm": 0.10607222467660904,
      "learning_rate": 1.74482068866981e-05,
      "loss": 0.0007,
      "step": 8930
    },
    {
      "epoch": 1.9159879982854693,
      "grad_norm": 0.01697164587676525,
      "learning_rate": 1.7445349335619375e-05,
      "loss": 0.1707,
      "step": 8940
    },
    {
      "epoch": 1.9181311615945136,
      "grad_norm": 0.01107749529182911,
      "learning_rate": 1.744249178454065e-05,
      "loss": 0.0003,
      "step": 8950
    },
    {
      "epoch": 1.9202743249035577,
      "grad_norm": 0.010536019690334797,
      "learning_rate": 1.7439634233461922e-05,
      "loss": 0.059,
      "step": 8960
    },
    {
      "epoch": 1.9224174882126017,
      "grad_norm": 0.011171986348927021,
      "learning_rate": 1.74367766823832e-05,
      "loss": 0.2437,
      "step": 8970
    },
    {
      "epoch": 1.924560651521646,
      "grad_norm": 0.010966910049319267,
      "learning_rate": 1.7433919131304474e-05,
      "loss": 0.0003,
      "step": 8980
    },
    {
      "epoch": 1.92670381483069,
      "grad_norm": 0.011690878309309483,
      "learning_rate": 1.7431061580225748e-05,
      "loss": 0.0184,
      "step": 8990
    },
    {
      "epoch": 1.9288469781397342,
      "grad_norm": 0.014334727078676224,
      "learning_rate": 1.742820402914702e-05,
      "loss": 0.1863,
      "step": 9000
    },
    {
      "epoch": 1.9309901414487785,
      "grad_norm": 0.021277595311403275,
      "learning_rate": 1.7425346478068296e-05,
      "loss": 0.0008,
      "step": 9010
    },
    {
      "epoch": 1.9331333047578225,
      "grad_norm": 0.018451662734150887,
      "learning_rate": 1.7422488926989573e-05,
      "loss": 0.0912,
      "step": 9020
    },
    {
      "epoch": 1.9352764680668666,
      "grad_norm": 0.08818427473306656,
      "learning_rate": 1.7419631375910847e-05,
      "loss": 0.0016,
      "step": 9030
    },
    {
      "epoch": 1.9374196313759109,
      "grad_norm": 0.00850477535277605,
      "learning_rate": 1.741677382483212e-05,
      "loss": 0.0003,
      "step": 9040
    },
    {
      "epoch": 1.939562794684955,
      "grad_norm": 0.0058141425251960754,
      "learning_rate": 1.7413916273753395e-05,
      "loss": 0.2056,
      "step": 9050
    },
    {
      "epoch": 1.941705957993999,
      "grad_norm": 0.010973186232149601,
      "learning_rate": 1.741105872267467e-05,
      "loss": 0.2049,
      "step": 9060
    },
    {
      "epoch": 1.9438491213030433,
      "grad_norm": 0.013579919002950191,
      "learning_rate": 1.7408201171595946e-05,
      "loss": 0.1272,
      "step": 9070
    },
    {
      "epoch": 1.9459922846120874,
      "grad_norm": 0.011382633820176125,
      "learning_rate": 1.740534362051722e-05,
      "loss": 0.2488,
      "step": 9080
    },
    {
      "epoch": 1.9481354479211315,
      "grad_norm": 0.029451025649905205,
      "learning_rate": 1.7402486069438494e-05,
      "loss": 0.2658,
      "step": 9090
    },
    {
      "epoch": 1.9502786112301758,
      "grad_norm": 0.8724137544631958,
      "learning_rate": 1.7399628518359768e-05,
      "loss": 0.0247,
      "step": 9100
    },
    {
      "epoch": 1.9524217745392198,
      "grad_norm": 37.91250991821289,
      "learning_rate": 1.739677096728104e-05,
      "loss": 0.2429,
      "step": 9110
    },
    {
      "epoch": 1.954564937848264,
      "grad_norm": 0.009558047167956829,
      "learning_rate": 1.7393913416202316e-05,
      "loss": 0.0159,
      "step": 9120
    },
    {
      "epoch": 1.9567081011573082,
      "grad_norm": 0.018964309245347977,
      "learning_rate": 1.739105586512359e-05,
      "loss": 0.0096,
      "step": 9130
    },
    {
      "epoch": 1.9588512644663525,
      "grad_norm": 19.60114288330078,
      "learning_rate": 1.7388198314044863e-05,
      "loss": 0.559,
      "step": 9140
    },
    {
      "epoch": 1.9609944277753963,
      "grad_norm": 0.037290673702955246,
      "learning_rate": 1.7385340762966137e-05,
      "loss": 0.0006,
      "step": 9150
    },
    {
      "epoch": 1.9631375910844406,
      "grad_norm": 0.04254729673266411,
      "learning_rate": 1.7382483211887415e-05,
      "loss": 0.0015,
      "step": 9160
    },
    {
      "epoch": 1.965280754393485,
      "grad_norm": 0.022479046136140823,
      "learning_rate": 1.737962566080869e-05,
      "loss": 0.0095,
      "step": 9170
    },
    {
      "epoch": 1.9674239177025288,
      "grad_norm": 0.023461777716875076,
      "learning_rate": 1.7376768109729962e-05,
      "loss": 0.2795,
      "step": 9180
    },
    {
      "epoch": 1.969567081011573,
      "grad_norm": 0.020252594724297523,
      "learning_rate": 1.7373910558651236e-05,
      "loss": 0.0006,
      "step": 9190
    },
    {
      "epoch": 1.9717102443206174,
      "grad_norm": 0.012118306942284107,
      "learning_rate": 1.737105300757251e-05,
      "loss": 0.2482,
      "step": 9200
    },
    {
      "epoch": 1.9738534076296612,
      "grad_norm": 3.49894642829895,
      "learning_rate": 1.7368195456493788e-05,
      "loss": 0.0047,
      "step": 9210
    },
    {
      "epoch": 1.9759965709387055,
      "grad_norm": 0.024542849510908127,
      "learning_rate": 1.736533790541506e-05,
      "loss": 0.0005,
      "step": 9220
    },
    {
      "epoch": 1.9781397342477498,
      "grad_norm": 0.024772463366389275,
      "learning_rate": 1.7362480354336335e-05,
      "loss": 0.2522,
      "step": 9230
    },
    {
      "epoch": 1.9802828975567939,
      "grad_norm": 0.02499769628047943,
      "learning_rate": 1.735962280325761e-05,
      "loss": 0.1293,
      "step": 9240
    },
    {
      "epoch": 1.982426060865838,
      "grad_norm": 0.033273667097091675,
      "learning_rate": 1.7356765252178883e-05,
      "loss": 0.0008,
      "step": 9250
    },
    {
      "epoch": 1.9845692241748822,
      "grad_norm": 0.025838814675807953,
      "learning_rate": 1.7353907701100157e-05,
      "loss": 0.2197,
      "step": 9260
    },
    {
      "epoch": 1.9867123874839263,
      "grad_norm": 22.30376625061035,
      "learning_rate": 1.7351050150021435e-05,
      "loss": 0.1489,
      "step": 9270
    },
    {
      "epoch": 1.9888555507929704,
      "grad_norm": 0.09854064136743546,
      "learning_rate": 1.734819259894271e-05,
      "loss": 0.0005,
      "step": 9280
    },
    {
      "epoch": 1.9909987141020147,
      "grad_norm": 0.017342135310173035,
      "learning_rate": 1.7345335047863982e-05,
      "loss": 0.0004,
      "step": 9290
    },
    {
      "epoch": 1.9931418774110587,
      "grad_norm": 16.796865463256836,
      "learning_rate": 1.7342477496785256e-05,
      "loss": 0.4453,
      "step": 9300
    },
    {
      "epoch": 1.9952850407201028,
      "grad_norm": 0.014443025924265385,
      "learning_rate": 1.733961994570653e-05,
      "loss": 0.0064,
      "step": 9310
    },
    {
      "epoch": 1.9974282040291471,
      "grad_norm": 20.14068603515625,
      "learning_rate": 1.7336762394627808e-05,
      "loss": 0.2985,
      "step": 9320
    },
    {
      "epoch": 1.9995713673381912,
      "grad_norm": 0.013155004940927029,
      "learning_rate": 1.733390484354908e-05,
      "loss": 0.0005,
      "step": 9330
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9723333333333334,
      "eval_f1": 0.8541300527240775,
      "eval_loss": 0.1690472662448883,
      "eval_precision": 0.9033457249070632,
      "eval_recall": 0.81,
      "eval_runtime": 398.6974,
      "eval_samples_per_second": 7.525,
      "eval_steps_per_second": 2.508,
      "step": 9332
    },
    {
      "epoch": 2.0017145306472353,
      "grad_norm": 0.011237106285989285,
      "learning_rate": 1.7331047292470352e-05,
      "loss": 0.0015,
      "step": 9340
    },
    {
      "epoch": 2.0038576939562796,
      "grad_norm": 0.11393386125564575,
      "learning_rate": 1.732818974139163e-05,
      "loss": 0.2603,
      "step": 9350
    },
    {
      "epoch": 2.0060008572653234,
      "grad_norm": 0.020028414204716682,
      "learning_rate": 1.7325332190312903e-05,
      "loss": 0.0013,
      "step": 9360
    },
    {
      "epoch": 2.0081440205743677,
      "grad_norm": 0.011452795937657356,
      "learning_rate": 1.7322474639234177e-05,
      "loss": 0.0003,
      "step": 9370
    },
    {
      "epoch": 2.010287183883412,
      "grad_norm": 0.012401645071804523,
      "learning_rate": 1.731961708815545e-05,
      "loss": 0.0006,
      "step": 9380
    },
    {
      "epoch": 2.0124303471924563,
      "grad_norm": 0.009440061636269093,
      "learning_rate": 1.7316759537076725e-05,
      "loss": 0.0003,
      "step": 9390
    },
    {
      "epoch": 2.0145735105015,
      "grad_norm": 0.006871877703815699,
      "learning_rate": 1.7313901985998e-05,
      "loss": 0.0002,
      "step": 9400
    },
    {
      "epoch": 2.0167166738105444,
      "grad_norm": 0.006076272577047348,
      "learning_rate": 1.7311044434919276e-05,
      "loss": 0.0039,
      "step": 9410
    },
    {
      "epoch": 2.0188598371195887,
      "grad_norm": 0.011390755884349346,
      "learning_rate": 1.730818688384055e-05,
      "loss": 0.0002,
      "step": 9420
    },
    {
      "epoch": 2.0210030004286326,
      "grad_norm": 0.004861412104219198,
      "learning_rate": 1.7305329332761824e-05,
      "loss": 0.0004,
      "step": 9430
    },
    {
      "epoch": 2.023146163737677,
      "grad_norm": 0.004785417579114437,
      "learning_rate": 1.7302471781683098e-05,
      "loss": 0.0001,
      "step": 9440
    },
    {
      "epoch": 2.025289327046721,
      "grad_norm": 0.004246670752763748,
      "learning_rate": 1.7299614230604372e-05,
      "loss": 0.0001,
      "step": 9450
    },
    {
      "epoch": 2.027432490355765,
      "grad_norm": 18.299165725708008,
      "learning_rate": 1.729675667952565e-05,
      "loss": 0.2992,
      "step": 9460
    },
    {
      "epoch": 2.0295756536648093,
      "grad_norm": 0.027963874861598015,
      "learning_rate": 1.7293899128446923e-05,
      "loss": 0.5423,
      "step": 9470
    },
    {
      "epoch": 2.0317188169738536,
      "grad_norm": 0.018351707607507706,
      "learning_rate": 1.7291041577368197e-05,
      "loss": 0.2577,
      "step": 9480
    },
    {
      "epoch": 2.0338619802828974,
      "grad_norm": 0.029408521950244904,
      "learning_rate": 1.728818402628947e-05,
      "loss": 0.0008,
      "step": 9490
    },
    {
      "epoch": 2.0360051435919417,
      "grad_norm": 0.03364995867013931,
      "learning_rate": 1.7285326475210745e-05,
      "loss": 0.0606,
      "step": 9500
    },
    {
      "epoch": 2.038148306900986,
      "grad_norm": 113.63064575195312,
      "learning_rate": 1.7282468924132022e-05,
      "loss": 0.2551,
      "step": 9510
    },
    {
      "epoch": 2.04029147021003,
      "grad_norm": 0.056250594556331635,
      "learning_rate": 1.7279611373053296e-05,
      "loss": 0.1115,
      "step": 9520
    },
    {
      "epoch": 2.042434633519074,
      "grad_norm": 0.06727446615695953,
      "learning_rate": 1.727675382197457e-05,
      "loss": 0.3202,
      "step": 9530
    },
    {
      "epoch": 2.0445777968281185,
      "grad_norm": 0.060557518154382706,
      "learning_rate": 1.7273896270895844e-05,
      "loss": 0.3669,
      "step": 9540
    },
    {
      "epoch": 2.0467209601371623,
      "grad_norm": 1.8601466417312622,
      "learning_rate": 1.7271038719817118e-05,
      "loss": 0.0114,
      "step": 9550
    },
    {
      "epoch": 2.0488641234462066,
      "grad_norm": 0.019939720630645752,
      "learning_rate": 1.7268181168738392e-05,
      "loss": 0.1632,
      "step": 9560
    },
    {
      "epoch": 2.051007286755251,
      "grad_norm": 0.010356136597692966,
      "learning_rate": 1.7265323617659666e-05,
      "loss": 0.0009,
      "step": 9570
    },
    {
      "epoch": 2.0531504500642948,
      "grad_norm": 0.008120334707200527,
      "learning_rate": 1.726246606658094e-05,
      "loss": 0.001,
      "step": 9580
    },
    {
      "epoch": 2.055293613373339,
      "grad_norm": 3.396662712097168,
      "learning_rate": 1.7259608515502214e-05,
      "loss": 0.4195,
      "step": 9590
    },
    {
      "epoch": 2.0574367766823833,
      "grad_norm": 0.10882493853569031,
      "learning_rate": 1.725675096442349e-05,
      "loss": 0.4731,
      "step": 9600
    },
    {
      "epoch": 2.059579939991427,
      "grad_norm": 43.603702545166016,
      "learning_rate": 1.7253893413344765e-05,
      "loss": 0.0523,
      "step": 9610
    },
    {
      "epoch": 2.0617231033004715,
      "grad_norm": 0.040810201317071915,
      "learning_rate": 1.725103586226604e-05,
      "loss": 0.0021,
      "step": 9620
    },
    {
      "epoch": 2.0638662666095158,
      "grad_norm": 0.028469635173678398,
      "learning_rate": 1.7248178311187313e-05,
      "loss": 0.0209,
      "step": 9630
    },
    {
      "epoch": 2.0660094299185596,
      "grad_norm": 0.08348137140274048,
      "learning_rate": 1.7245320760108587e-05,
      "loss": 0.0008,
      "step": 9640
    },
    {
      "epoch": 2.068152593227604,
      "grad_norm": 0.020320069044828415,
      "learning_rate": 1.7242463209029864e-05,
      "loss": 0.0007,
      "step": 9650
    },
    {
      "epoch": 2.070295756536648,
      "grad_norm": 0.015514872968196869,
      "learning_rate": 1.7239605657951138e-05,
      "loss": 0.0006,
      "step": 9660
    },
    {
      "epoch": 2.072438919845692,
      "grad_norm": 0.029774369671940804,
      "learning_rate": 1.7236748106872412e-05,
      "loss": 0.2512,
      "step": 9670
    },
    {
      "epoch": 2.0745820831547364,
      "grad_norm": 0.025001846253871918,
      "learning_rate": 1.7233890555793686e-05,
      "loss": 0.0027,
      "step": 9680
    },
    {
      "epoch": 2.0767252464637806,
      "grad_norm": 0.008645012974739075,
      "learning_rate": 1.723103300471496e-05,
      "loss": 0.0006,
      "step": 9690
    },
    {
      "epoch": 2.0788684097728245,
      "grad_norm": 0.00969587080180645,
      "learning_rate": 1.7228175453636237e-05,
      "loss": 0.1915,
      "step": 9700
    },
    {
      "epoch": 2.081011573081869,
      "grad_norm": 0.006088848691433668,
      "learning_rate": 1.722531790255751e-05,
      "loss": 0.0003,
      "step": 9710
    },
    {
      "epoch": 2.083154736390913,
      "grad_norm": 0.004726996645331383,
      "learning_rate": 1.7222460351478785e-05,
      "loss": 0.0001,
      "step": 9720
    },
    {
      "epoch": 2.085297899699957,
      "grad_norm": 0.004764395300298929,
      "learning_rate": 1.721960280040006e-05,
      "loss": 0.001,
      "step": 9730
    },
    {
      "epoch": 2.0874410630090012,
      "grad_norm": 0.011250991374254227,
      "learning_rate": 1.7216745249321333e-05,
      "loss": 0.0472,
      "step": 9740
    },
    {
      "epoch": 2.0895842263180455,
      "grad_norm": 0.03947946056723595,
      "learning_rate": 1.7213887698242607e-05,
      "loss": 0.1316,
      "step": 9750
    },
    {
      "epoch": 2.0917273896270894,
      "grad_norm": 0.007231033407151699,
      "learning_rate": 1.7211030147163884e-05,
      "loss": 0.0003,
      "step": 9760
    },
    {
      "epoch": 2.0938705529361337,
      "grad_norm": 0.005757275503128767,
      "learning_rate": 1.7208172596085155e-05,
      "loss": 0.0001,
      "step": 9770
    },
    {
      "epoch": 2.096013716245178,
      "grad_norm": 0.006305400747805834,
      "learning_rate": 1.720531504500643e-05,
      "loss": 0.4761,
      "step": 9780
    },
    {
      "epoch": 2.098156879554222,
      "grad_norm": 0.007905579172074795,
      "learning_rate": 1.7202457493927706e-05,
      "loss": 0.1876,
      "step": 9790
    },
    {
      "epoch": 2.100300042863266,
      "grad_norm": 0.008576465770602226,
      "learning_rate": 1.719959994284898e-05,
      "loss": 0.0004,
      "step": 9800
    },
    {
      "epoch": 2.1024432061723104,
      "grad_norm": 0.011309556663036346,
      "learning_rate": 1.7196742391770254e-05,
      "loss": 0.0004,
      "step": 9810
    },
    {
      "epoch": 2.1045863694813547,
      "grad_norm": 0.006893142592161894,
      "learning_rate": 1.7193884840691528e-05,
      "loss": 0.0004,
      "step": 9820
    },
    {
      "epoch": 2.1067295327903985,
      "grad_norm": 0.18598318099975586,
      "learning_rate": 1.71910272896128e-05,
      "loss": 0.0004,
      "step": 9830
    },
    {
      "epoch": 2.108872696099443,
      "grad_norm": 0.01023570541292429,
      "learning_rate": 1.718816973853408e-05,
      "loss": 0.4927,
      "step": 9840
    },
    {
      "epoch": 2.111015859408487,
      "grad_norm": 0.017946764826774597,
      "learning_rate": 1.7185312187455353e-05,
      "loss": 0.1987,
      "step": 9850
    },
    {
      "epoch": 2.113159022717531,
      "grad_norm": 6.242777347564697,
      "learning_rate": 1.7182454636376627e-05,
      "loss": 0.5128,
      "step": 9860
    },
    {
      "epoch": 2.1153021860265753,
      "grad_norm": 0.02250640280544758,
      "learning_rate": 1.71795970852979e-05,
      "loss": 0.4438,
      "step": 9870
    },
    {
      "epoch": 2.1174453493356196,
      "grad_norm": 0.023401543498039246,
      "learning_rate": 1.7176739534219175e-05,
      "loss": 0.0007,
      "step": 9880
    },
    {
      "epoch": 2.1195885126446634,
      "grad_norm": 0.03493037819862366,
      "learning_rate": 1.717388198314045e-05,
      "loss": 0.0008,
      "step": 9890
    },
    {
      "epoch": 2.1217316759537077,
      "grad_norm": 0.017420822754502296,
      "learning_rate": 1.7171024432061726e-05,
      "loss": 0.0004,
      "step": 9900
    },
    {
      "epoch": 2.123874839262752,
      "grad_norm": 0.01728375442326069,
      "learning_rate": 1.7168166880983e-05,
      "loss": 0.2107,
      "step": 9910
    },
    {
      "epoch": 2.126018002571796,
      "grad_norm": 0.04542512074112892,
      "learning_rate": 1.7165309329904274e-05,
      "loss": 0.2118,
      "step": 9920
    },
    {
      "epoch": 2.12816116588084,
      "grad_norm": 0.1961108297109604,
      "learning_rate": 1.7162451778825548e-05,
      "loss": 0.0021,
      "step": 9930
    },
    {
      "epoch": 2.1303043291898844,
      "grad_norm": 22.829132080078125,
      "learning_rate": 1.715959422774682e-05,
      "loss": 0.351,
      "step": 9940
    },
    {
      "epoch": 2.1324474924989283,
      "grad_norm": 0.04423794150352478,
      "learning_rate": 1.71567366766681e-05,
      "loss": 0.0015,
      "step": 9950
    },
    {
      "epoch": 2.1345906558079726,
      "grad_norm": 17.588672637939453,
      "learning_rate": 1.7153879125589373e-05,
      "loss": 0.3285,
      "step": 9960
    },
    {
      "epoch": 2.136733819117017,
      "grad_norm": 0.01328315120190382,
      "learning_rate": 1.7151021574510647e-05,
      "loss": 0.2511,
      "step": 9970
    },
    {
      "epoch": 2.1388769824260607,
      "grad_norm": 0.020550396293401718,
      "learning_rate": 1.714816402343192e-05,
      "loss": 0.0009,
      "step": 9980
    },
    {
      "epoch": 2.141020145735105,
      "grad_norm": 0.011486729606986046,
      "learning_rate": 1.7145306472353195e-05,
      "loss": 0.0003,
      "step": 9990
    },
    {
      "epoch": 2.1431633090441493,
      "grad_norm": 0.015568582341074944,
      "learning_rate": 1.714244892127447e-05,
      "loss": 0.2718,
      "step": 10000
    },
    {
      "epoch": 2.145306472353193,
      "grad_norm": 0.016520051285624504,
      "learning_rate": 1.7139591370195743e-05,
      "loss": 0.0005,
      "step": 10010
    },
    {
      "epoch": 2.1474496356622375,
      "grad_norm": 0.012512284331023693,
      "learning_rate": 1.7136733819117016e-05,
      "loss": 0.0005,
      "step": 10020
    },
    {
      "epoch": 2.1495927989712817,
      "grad_norm": 0.02092677913606167,
      "learning_rate": 1.713387626803829e-05,
      "loss": 0.1607,
      "step": 10030
    },
    {
      "epoch": 2.1517359622803256,
      "grad_norm": 0.07236755639314651,
      "learning_rate": 1.7131018716959568e-05,
      "loss": 0.0006,
      "step": 10040
    },
    {
      "epoch": 2.15387912558937,
      "grad_norm": 0.012318029068410397,
      "learning_rate": 1.712816116588084e-05,
      "loss": 0.0004,
      "step": 10050
    },
    {
      "epoch": 2.156022288898414,
      "grad_norm": 21.949016571044922,
      "learning_rate": 1.7125303614802116e-05,
      "loss": 0.2129,
      "step": 10060
    },
    {
      "epoch": 2.158165452207458,
      "grad_norm": 0.03757963702082634,
      "learning_rate": 1.712244606372339e-05,
      "loss": 0.3809,
      "step": 10070
    },
    {
      "epoch": 2.1603086155165023,
      "grad_norm": 0.1949162632226944,
      "learning_rate": 1.7119588512644663e-05,
      "loss": 0.0011,
      "step": 10080
    },
    {
      "epoch": 2.1624517788255466,
      "grad_norm": 0.07240134477615356,
      "learning_rate": 1.711673096156594e-05,
      "loss": 0.1658,
      "step": 10090
    },
    {
      "epoch": 2.1645949421345905,
      "grad_norm": 0.016591308638453484,
      "learning_rate": 1.7113873410487215e-05,
      "loss": 0.0008,
      "step": 10100
    },
    {
      "epoch": 2.1667381054436348,
      "grad_norm": 0.17525486648082733,
      "learning_rate": 1.711101585940849e-05,
      "loss": 0.1958,
      "step": 10110
    },
    {
      "epoch": 2.168881268752679,
      "grad_norm": 0.02774323895573616,
      "learning_rate": 1.7108158308329763e-05,
      "loss": 0.1701,
      "step": 10120
    },
    {
      "epoch": 2.171024432061723,
      "grad_norm": 0.01926850713789463,
      "learning_rate": 1.7105300757251036e-05,
      "loss": 0.3721,
      "step": 10130
    },
    {
      "epoch": 2.173167595370767,
      "grad_norm": 0.025223972275853157,
      "learning_rate": 1.7102443206172314e-05,
      "loss": 0.2273,
      "step": 10140
    },
    {
      "epoch": 2.1753107586798115,
      "grad_norm": 0.3199666738510132,
      "learning_rate": 1.7099585655093588e-05,
      "loss": 0.2723,
      "step": 10150
    },
    {
      "epoch": 2.1774539219888553,
      "grad_norm": 0.027499716728925705,
      "learning_rate": 1.709672810401486e-05,
      "loss": 0.0037,
      "step": 10160
    },
    {
      "epoch": 2.1795970852978996,
      "grad_norm": 0.034902337938547134,
      "learning_rate": 1.7093870552936136e-05,
      "loss": 0.2432,
      "step": 10170
    },
    {
      "epoch": 2.181740248606944,
      "grad_norm": 0.057485051453113556,
      "learning_rate": 1.709101300185741e-05,
      "loss": 0.0004,
      "step": 10180
    },
    {
      "epoch": 2.1838834119159882,
      "grad_norm": 16.285268783569336,
      "learning_rate": 1.7088155450778683e-05,
      "loss": 0.5713,
      "step": 10190
    },
    {
      "epoch": 2.186026575225032,
      "grad_norm": 0.05796210467815399,
      "learning_rate": 1.7085297899699957e-05,
      "loss": 0.4404,
      "step": 10200
    },
    {
      "epoch": 2.1881697385340764,
      "grad_norm": 0.1370404213666916,
      "learning_rate": 1.708244034862123e-05,
      "loss": 0.1484,
      "step": 10210
    },
    {
      "epoch": 2.1903129018431207,
      "grad_norm": 0.37277090549468994,
      "learning_rate": 1.7079582797542505e-05,
      "loss": 0.3582,
      "step": 10220
    },
    {
      "epoch": 2.1924560651521645,
      "grad_norm": 0.07511216402053833,
      "learning_rate": 1.7076725246463783e-05,
      "loss": 0.0024,
      "step": 10230
    },
    {
      "epoch": 2.194599228461209,
      "grad_norm": 0.03173517435789108,
      "learning_rate": 1.7073867695385056e-05,
      "loss": 0.3623,
      "step": 10240
    },
    {
      "epoch": 2.196742391770253,
      "grad_norm": 0.03024199604988098,
      "learning_rate": 1.707101014430633e-05,
      "loss": 0.0008,
      "step": 10250
    },
    {
      "epoch": 2.198885555079297,
      "grad_norm": 0.022255657240748405,
      "learning_rate": 1.7068152593227604e-05,
      "loss": 0.001,
      "step": 10260
    },
    {
      "epoch": 2.2010287183883412,
      "grad_norm": 0.013904387131333351,
      "learning_rate": 1.7065295042148878e-05,
      "loss": 0.0023,
      "step": 10270
    },
    {
      "epoch": 2.2031718816973855,
      "grad_norm": 0.013463940471410751,
      "learning_rate": 1.7062437491070156e-05,
      "loss": 0.188,
      "step": 10280
    },
    {
      "epoch": 2.2053150450064294,
      "grad_norm": 0.0165118295699358,
      "learning_rate": 1.705957993999143e-05,
      "loss": 0.1706,
      "step": 10290
    },
    {
      "epoch": 2.2074582083154737,
      "grad_norm": 0.01899866759777069,
      "learning_rate": 1.7056722388912703e-05,
      "loss": 0.0594,
      "step": 10300
    },
    {
      "epoch": 2.209601371624518,
      "grad_norm": 0.06277976185083389,
      "learning_rate": 1.7053864837833977e-05,
      "loss": 0.0033,
      "step": 10310
    },
    {
      "epoch": 2.211744534933562,
      "grad_norm": 0.27931708097457886,
      "learning_rate": 1.705100728675525e-05,
      "loss": 0.2963,
      "step": 10320
    },
    {
      "epoch": 2.213887698242606,
      "grad_norm": 0.017170371487736702,
      "learning_rate": 1.7048149735676525e-05,
      "loss": 0.2749,
      "step": 10330
    },
    {
      "epoch": 2.2160308615516504,
      "grad_norm": 0.02391047775745392,
      "learning_rate": 1.7045292184597803e-05,
      "loss": 0.0007,
      "step": 10340
    },
    {
      "epoch": 2.2181740248606943,
      "grad_norm": 0.01886431872844696,
      "learning_rate": 1.7042434633519076e-05,
      "loss": 0.1872,
      "step": 10350
    },
    {
      "epoch": 2.2203171881697386,
      "grad_norm": 0.03317580372095108,
      "learning_rate": 1.703957708244035e-05,
      "loss": 0.1852,
      "step": 10360
    },
    {
      "epoch": 2.222460351478783,
      "grad_norm": 0.012791469693183899,
      "learning_rate": 1.7036719531361624e-05,
      "loss": 0.001,
      "step": 10370
    },
    {
      "epoch": 2.2246035147878267,
      "grad_norm": 0.018086891621351242,
      "learning_rate": 1.7033861980282898e-05,
      "loss": 0.1959,
      "step": 10380
    },
    {
      "epoch": 2.226746678096871,
      "grad_norm": 0.02007625624537468,
      "learning_rate": 1.7031004429204176e-05,
      "loss": 0.0006,
      "step": 10390
    },
    {
      "epoch": 2.2288898414059153,
      "grad_norm": 0.017434049397706985,
      "learning_rate": 1.702814687812545e-05,
      "loss": 0.0005,
      "step": 10400
    },
    {
      "epoch": 2.231033004714959,
      "grad_norm": 0.01896294578909874,
      "learning_rate": 1.7025289327046723e-05,
      "loss": 0.2069,
      "step": 10410
    },
    {
      "epoch": 2.2331761680240034,
      "grad_norm": 0.25013452768325806,
      "learning_rate": 1.7022431775967997e-05,
      "loss": 0.0984,
      "step": 10420
    },
    {
      "epoch": 2.2353193313330477,
      "grad_norm": 0.10977727919816971,
      "learning_rate": 1.701957422488927e-05,
      "loss": 0.3509,
      "step": 10430
    },
    {
      "epoch": 2.2374624946420916,
      "grad_norm": 0.027533579617738724,
      "learning_rate": 1.7016716673810545e-05,
      "loss": 0.0717,
      "step": 10440
    },
    {
      "epoch": 2.239605657951136,
      "grad_norm": 0.01564909517765045,
      "learning_rate": 1.701385912273182e-05,
      "loss": 0.002,
      "step": 10450
    },
    {
      "epoch": 2.24174882126018,
      "grad_norm": 0.013209238648414612,
      "learning_rate": 1.7011001571653093e-05,
      "loss": 0.0005,
      "step": 10460
    },
    {
      "epoch": 2.243891984569224,
      "grad_norm": 0.005261023994535208,
      "learning_rate": 1.7008144020574367e-05,
      "loss": 0.0001,
      "step": 10470
    },
    {
      "epoch": 2.2460351478782683,
      "grad_norm": 0.005615311674773693,
      "learning_rate": 1.7005286469495644e-05,
      "loss": 0.2379,
      "step": 10480
    },
    {
      "epoch": 2.2481783111873126,
      "grad_norm": 0.012910384684801102,
      "learning_rate": 1.7002428918416918e-05,
      "loss": 0.3117,
      "step": 10490
    },
    {
      "epoch": 2.2503214744963564,
      "grad_norm": 0.006287452764809132,
      "learning_rate": 1.6999571367338192e-05,
      "loss": 0.2547,
      "step": 10500
    },
    {
      "epoch": 2.2524646378054007,
      "grad_norm": 0.035360485315322876,
      "learning_rate": 1.6996713816259466e-05,
      "loss": 0.0992,
      "step": 10510
    },
    {
      "epoch": 2.254607801114445,
      "grad_norm": 0.005624497774988413,
      "learning_rate": 1.699385626518074e-05,
      "loss": 0.0005,
      "step": 10520
    },
    {
      "epoch": 2.256750964423489,
      "grad_norm": 0.012624010443687439,
      "learning_rate": 1.6990998714102017e-05,
      "loss": 0.2009,
      "step": 10530
    },
    {
      "epoch": 2.258894127732533,
      "grad_norm": 0.003559006145223975,
      "learning_rate": 1.698814116302329e-05,
      "loss": 0.0001,
      "step": 10540
    },
    {
      "epoch": 2.2610372910415775,
      "grad_norm": 0.008986205793917179,
      "learning_rate": 1.6985283611944565e-05,
      "loss": 0.2601,
      "step": 10550
    },
    {
      "epoch": 2.2631804543506213,
      "grad_norm": 0.012399710714817047,
      "learning_rate": 1.698242606086584e-05,
      "loss": 0.1979,
      "step": 10560
    },
    {
      "epoch": 2.2653236176596656,
      "grad_norm": 0.01403467170894146,
      "learning_rate": 1.6979568509787113e-05,
      "loss": 0.0004,
      "step": 10570
    },
    {
      "epoch": 2.26746678096871,
      "grad_norm": 0.12627503275871277,
      "learning_rate": 1.697671095870839e-05,
      "loss": 0.0017,
      "step": 10580
    },
    {
      "epoch": 2.2696099442777538,
      "grad_norm": 0.06850287318229675,
      "learning_rate": 1.6973853407629664e-05,
      "loss": 0.0005,
      "step": 10590
    },
    {
      "epoch": 2.271753107586798,
      "grad_norm": 0.004368413705378771,
      "learning_rate": 1.6970995856550938e-05,
      "loss": 0.2355,
      "step": 10600
    },
    {
      "epoch": 2.2738962708958423,
      "grad_norm": 0.020276648923754692,
      "learning_rate": 1.6968138305472212e-05,
      "loss": 0.0011,
      "step": 10610
    },
    {
      "epoch": 2.276039434204886,
      "grad_norm": 0.002715695183724165,
      "learning_rate": 1.6965280754393486e-05,
      "loss": 0.0022,
      "step": 10620
    },
    {
      "epoch": 2.2781825975139305,
      "grad_norm": 34.32848358154297,
      "learning_rate": 1.696242320331476e-05,
      "loss": 0.4617,
      "step": 10630
    },
    {
      "epoch": 2.280325760822975,
      "grad_norm": 0.011529332026839256,
      "learning_rate": 1.6959565652236034e-05,
      "loss": 0.0021,
      "step": 10640
    },
    {
      "epoch": 2.2824689241320186,
      "grad_norm": 0.011444836854934692,
      "learning_rate": 1.6956708101157308e-05,
      "loss": 0.0004,
      "step": 10650
    },
    {
      "epoch": 2.284612087441063,
      "grad_norm": 0.03264028578996658,
      "learning_rate": 1.6953850550078582e-05,
      "loss": 0.1934,
      "step": 10660
    },
    {
      "epoch": 2.286755250750107,
      "grad_norm": 0.01609966531395912,
      "learning_rate": 1.695099299899986e-05,
      "loss": 0.0004,
      "step": 10670
    },
    {
      "epoch": 2.288898414059151,
      "grad_norm": 0.007382323499768972,
      "learning_rate": 1.6948135447921133e-05,
      "loss": 0.0041,
      "step": 10680
    },
    {
      "epoch": 2.2910415773681954,
      "grad_norm": 0.005996807478368282,
      "learning_rate": 1.6945277896842407e-05,
      "loss": 0.0007,
      "step": 10690
    },
    {
      "epoch": 2.2931847406772397,
      "grad_norm": 0.004991344641894102,
      "learning_rate": 1.694242034576368e-05,
      "loss": 0.0003,
      "step": 10700
    },
    {
      "epoch": 2.295327903986284,
      "grad_norm": 16.407466888427734,
      "learning_rate": 1.6939562794684955e-05,
      "loss": 0.199,
      "step": 10710
    },
    {
      "epoch": 2.297471067295328,
      "grad_norm": 0.03508969768881798,
      "learning_rate": 1.6936705243606232e-05,
      "loss": 0.0002,
      "step": 10720
    },
    {
      "epoch": 2.299614230604372,
      "grad_norm": 0.004667784087359905,
      "learning_rate": 1.6933847692527506e-05,
      "loss": 0.284,
      "step": 10730
    },
    {
      "epoch": 2.3017573939134164,
      "grad_norm": 0.007499353494495153,
      "learning_rate": 1.693099014144878e-05,
      "loss": 0.0002,
      "step": 10740
    },
    {
      "epoch": 2.3039005572224602,
      "grad_norm": 0.012194911018013954,
      "learning_rate": 1.6928132590370054e-05,
      "loss": 0.2382,
      "step": 10750
    },
    {
      "epoch": 2.3060437205315045,
      "grad_norm": 0.07811848074197769,
      "learning_rate": 1.6925275039291328e-05,
      "loss": 0.5505,
      "step": 10760
    },
    {
      "epoch": 2.308186883840549,
      "grad_norm": 0.015746207907795906,
      "learning_rate": 1.6922417488212605e-05,
      "loss": 0.2116,
      "step": 10770
    },
    {
      "epoch": 2.3103300471495927,
      "grad_norm": 0.025289954617619514,
      "learning_rate": 1.691955993713388e-05,
      "loss": 0.1746,
      "step": 10780
    },
    {
      "epoch": 2.312473210458637,
      "grad_norm": 0.016751974821090698,
      "learning_rate": 1.6916702386055153e-05,
      "loss": 0.0008,
      "step": 10790
    },
    {
      "epoch": 2.3146163737676813,
      "grad_norm": 0.016363475471735,
      "learning_rate": 1.6913844834976427e-05,
      "loss": 0.0022,
      "step": 10800
    },
    {
      "epoch": 2.316759537076725,
      "grad_norm": 0.08687548339366913,
      "learning_rate": 1.69109872838977e-05,
      "loss": 0.0014,
      "step": 10810
    },
    {
      "epoch": 2.3189027003857694,
      "grad_norm": 0.14785902202129364,
      "learning_rate": 1.6908129732818975e-05,
      "loss": 0.0008,
      "step": 10820
    },
    {
      "epoch": 2.3210458636948137,
      "grad_norm": 0.00428403727710247,
      "learning_rate": 1.6905272181740252e-05,
      "loss": 0.0006,
      "step": 10830
    },
    {
      "epoch": 2.3231890270038575,
      "grad_norm": 0.007303569000214338,
      "learning_rate": 1.6902414630661526e-05,
      "loss": 0.2979,
      "step": 10840
    },
    {
      "epoch": 2.325332190312902,
      "grad_norm": 0.009938465431332588,
      "learning_rate": 1.6899557079582797e-05,
      "loss": 0.0004,
      "step": 10850
    },
    {
      "epoch": 2.327475353621946,
      "grad_norm": 0.014910365454852581,
      "learning_rate": 1.6896699528504074e-05,
      "loss": 0.3813,
      "step": 10860
    },
    {
      "epoch": 2.32961851693099,
      "grad_norm": 0.0176297165453434,
      "learning_rate": 1.6893841977425348e-05,
      "loss": 0.0006,
      "step": 10870
    },
    {
      "epoch": 2.3317616802400343,
      "grad_norm": 0.06858287006616592,
      "learning_rate": 1.6890984426346622e-05,
      "loss": 0.2073,
      "step": 10880
    },
    {
      "epoch": 2.3339048435490786,
      "grad_norm": 0.12969215214252472,
      "learning_rate": 1.6888126875267896e-05,
      "loss": 0.0041,
      "step": 10890
    },
    {
      "epoch": 2.3360480068581224,
      "grad_norm": 0.03386544808745384,
      "learning_rate": 1.688526932418917e-05,
      "loss": 0.0004,
      "step": 10900
    },
    {
      "epoch": 2.3381911701671667,
      "grad_norm": 0.007588509004563093,
      "learning_rate": 1.6882411773110447e-05,
      "loss": 0.2259,
      "step": 10910
    },
    {
      "epoch": 2.340334333476211,
      "grad_norm": 0.007910892367362976,
      "learning_rate": 1.687955422203172e-05,
      "loss": 0.0005,
      "step": 10920
    },
    {
      "epoch": 2.342477496785255,
      "grad_norm": 0.031137855723500252,
      "learning_rate": 1.6876696670952995e-05,
      "loss": 0.5248,
      "step": 10930
    },
    {
      "epoch": 2.344620660094299,
      "grad_norm": 0.07975461333990097,
      "learning_rate": 1.687383911987427e-05,
      "loss": 0.0008,
      "step": 10940
    },
    {
      "epoch": 2.3467638234033434,
      "grad_norm": 0.07581391930580139,
      "learning_rate": 1.6870981568795543e-05,
      "loss": 0.0008,
      "step": 10950
    },
    {
      "epoch": 2.3489069867123873,
      "grad_norm": 0.017863262444734573,
      "learning_rate": 1.6868124017716817e-05,
      "loss": 0.0009,
      "step": 10960
    },
    {
      "epoch": 2.3510501500214316,
      "grad_norm": 0.016415413469076157,
      "learning_rate": 1.6865266466638094e-05,
      "loss": 0.0006,
      "step": 10970
    },
    {
      "epoch": 2.353193313330476,
      "grad_norm": 0.010071196593344212,
      "learning_rate": 1.6862408915559368e-05,
      "loss": 0.0003,
      "step": 10980
    },
    {
      "epoch": 2.35533647663952,
      "grad_norm": 0.0273597352206707,
      "learning_rate": 1.6859551364480642e-05,
      "loss": 0.1059,
      "step": 10990
    },
    {
      "epoch": 2.357479639948564,
      "grad_norm": 18.04989242553711,
      "learning_rate": 1.6856693813401916e-05,
      "loss": 0.5016,
      "step": 11000
    },
    {
      "epoch": 2.3596228032576083,
      "grad_norm": 0.015276452526450157,
      "learning_rate": 1.685383626232319e-05,
      "loss": 0.0009,
      "step": 11010
    },
    {
      "epoch": 2.3617659665666526,
      "grad_norm": 0.01671573519706726,
      "learning_rate": 1.6850978711244467e-05,
      "loss": 0.2101,
      "step": 11020
    },
    {
      "epoch": 2.3639091298756965,
      "grad_norm": 0.019542502239346504,
      "learning_rate": 1.684812116016574e-05,
      "loss": 0.0007,
      "step": 11030
    },
    {
      "epoch": 2.3660522931847408,
      "grad_norm": 0.00951254554092884,
      "learning_rate": 1.6845263609087015e-05,
      "loss": 0.0006,
      "step": 11040
    },
    {
      "epoch": 2.368195456493785,
      "grad_norm": 0.011800562962889671,
      "learning_rate": 1.684240605800829e-05,
      "loss": 0.0003,
      "step": 11050
    },
    {
      "epoch": 2.370338619802829,
      "grad_norm": 0.009904592297971249,
      "learning_rate": 1.6839548506929563e-05,
      "loss": 0.0004,
      "step": 11060
    },
    {
      "epoch": 2.372481783111873,
      "grad_norm": 0.04583640769124031,
      "learning_rate": 1.6836690955850837e-05,
      "loss": 0.0004,
      "step": 11070
    },
    {
      "epoch": 2.3746249464209175,
      "grad_norm": 0.0457281731069088,
      "learning_rate": 1.683383340477211e-05,
      "loss": 0.0003,
      "step": 11080
    },
    {
      "epoch": 2.3767681097299613,
      "grad_norm": 0.009787063114345074,
      "learning_rate": 1.6830975853693384e-05,
      "loss": 0.4427,
      "step": 11090
    },
    {
      "epoch": 2.3789112730390056,
      "grad_norm": 0.030908502638339996,
      "learning_rate": 1.682811830261466e-05,
      "loss": 0.0005,
      "step": 11100
    },
    {
      "epoch": 2.38105443634805,
      "grad_norm": 0.007620339281857014,
      "learning_rate": 1.6825260751535936e-05,
      "loss": 0.0005,
      "step": 11110
    },
    {
      "epoch": 2.3831975996570938,
      "grad_norm": 0.422554612159729,
      "learning_rate": 1.682240320045721e-05,
      "loss": 0.1964,
      "step": 11120
    },
    {
      "epoch": 2.385340762966138,
      "grad_norm": 0.019148200750350952,
      "learning_rate": 1.6819545649378484e-05,
      "loss": 0.1733,
      "step": 11130
    },
    {
      "epoch": 2.3874839262751824,
      "grad_norm": 18.766035079956055,
      "learning_rate": 1.6816688098299757e-05,
      "loss": 0.3345,
      "step": 11140
    },
    {
      "epoch": 2.389627089584226,
      "grad_norm": 0.14021556079387665,
      "learning_rate": 1.681383054722103e-05,
      "loss": 0.243,
      "step": 11150
    },
    {
      "epoch": 2.3917702528932705,
      "grad_norm": 0.012661297805607319,
      "learning_rate": 1.681097299614231e-05,
      "loss": 0.0488,
      "step": 11160
    },
    {
      "epoch": 2.393913416202315,
      "grad_norm": 0.008053351193666458,
      "learning_rate": 1.6808115445063583e-05,
      "loss": 0.2833,
      "step": 11170
    },
    {
      "epoch": 2.3960565795113586,
      "grad_norm": 0.010497276671230793,
      "learning_rate": 1.6805257893984857e-05,
      "loss": 0.0003,
      "step": 11180
    },
    {
      "epoch": 2.398199742820403,
      "grad_norm": 0.01778615452349186,
      "learning_rate": 1.680240034290613e-05,
      "loss": 0.6524,
      "step": 11190
    },
    {
      "epoch": 2.4003429061294472,
      "grad_norm": 0.02913198247551918,
      "learning_rate": 1.6799542791827404e-05,
      "loss": 0.0008,
      "step": 11200
    },
    {
      "epoch": 2.402486069438491,
      "grad_norm": 0.04203220456838608,
      "learning_rate": 1.6796685240748682e-05,
      "loss": 0.2419,
      "step": 11210
    },
    {
      "epoch": 2.4046292327475354,
      "grad_norm": 0.12729699909687042,
      "learning_rate": 1.6793827689669956e-05,
      "loss": 0.0008,
      "step": 11220
    },
    {
      "epoch": 2.4067723960565797,
      "grad_norm": 0.04254118725657463,
      "learning_rate": 1.679097013859123e-05,
      "loss": 0.0007,
      "step": 11230
    },
    {
      "epoch": 2.4089155593656235,
      "grad_norm": 0.014159409329295158,
      "learning_rate": 1.6788112587512503e-05,
      "loss": 0.0006,
      "step": 11240
    },
    {
      "epoch": 2.411058722674668,
      "grad_norm": 0.014560332521796227,
      "learning_rate": 1.6785255036433777e-05,
      "loss": 0.1617,
      "step": 11250
    },
    {
      "epoch": 2.413201885983712,
      "grad_norm": 0.022364825010299683,
      "learning_rate": 1.6782397485355055e-05,
      "loss": 0.5179,
      "step": 11260
    },
    {
      "epoch": 2.415345049292756,
      "grad_norm": 0.028765426948666573,
      "learning_rate": 1.677953993427633e-05,
      "loss": 0.0007,
      "step": 11270
    },
    {
      "epoch": 2.4174882126018002,
      "grad_norm": 22.30449104309082,
      "learning_rate": 1.67766823831976e-05,
      "loss": 0.3445,
      "step": 11280
    },
    {
      "epoch": 2.4196313759108445,
      "grad_norm": 8.835171699523926,
      "learning_rate": 1.6773824832118873e-05,
      "loss": 0.0026,
      "step": 11290
    },
    {
      "epoch": 2.4217745392198884,
      "grad_norm": 0.006769692059606314,
      "learning_rate": 1.677096728104015e-05,
      "loss": 0.0006,
      "step": 11300
    },
    {
      "epoch": 2.4239177025289327,
      "grad_norm": 0.01216597855091095,
      "learning_rate": 1.6768109729961424e-05,
      "loss": 0.2246,
      "step": 11310
    },
    {
      "epoch": 2.426060865837977,
      "grad_norm": 0.008821019902825356,
      "learning_rate": 1.6765252178882698e-05,
      "loss": 0.0005,
      "step": 11320
    },
    {
      "epoch": 2.428204029147021,
      "grad_norm": 0.00815639179199934,
      "learning_rate": 1.6762394627803972e-05,
      "loss": 0.0005,
      "step": 11330
    },
    {
      "epoch": 2.430347192456065,
      "grad_norm": 0.005360219161957502,
      "learning_rate": 1.6759537076725246e-05,
      "loss": 0.2163,
      "step": 11340
    },
    {
      "epoch": 2.4324903557651094,
      "grad_norm": 0.012721367180347443,
      "learning_rate": 1.6756679525646523e-05,
      "loss": 0.0006,
      "step": 11350
    },
    {
      "epoch": 2.4346335190741533,
      "grad_norm": 0.007426928728818893,
      "learning_rate": 1.6753821974567797e-05,
      "loss": 0.0003,
      "step": 11360
    },
    {
      "epoch": 2.4367766823831976,
      "grad_norm": 0.008689414709806442,
      "learning_rate": 1.675096442348907e-05,
      "loss": 0.0002,
      "step": 11370
    },
    {
      "epoch": 2.438919845692242,
      "grad_norm": 0.008044298738241196,
      "learning_rate": 1.6748106872410345e-05,
      "loss": 0.9266,
      "step": 11380
    },
    {
      "epoch": 2.4410630090012857,
      "grad_norm": 0.02640165388584137,
      "learning_rate": 1.674524932133162e-05,
      "loss": 0.0007,
      "step": 11390
    },
    {
      "epoch": 2.44320617231033,
      "grad_norm": 0.016661381348967552,
      "learning_rate": 1.6742391770252897e-05,
      "loss": 0.0009,
      "step": 11400
    },
    {
      "epoch": 2.4453493356193743,
      "grad_norm": 0.011923303827643394,
      "learning_rate": 1.673953421917417e-05,
      "loss": 0.001,
      "step": 11410
    },
    {
      "epoch": 2.447492498928418,
      "grad_norm": 0.0072275870479643345,
      "learning_rate": 1.6736676668095444e-05,
      "loss": 0.0008,
      "step": 11420
    },
    {
      "epoch": 2.4496356622374624,
      "grad_norm": 0.130763441324234,
      "learning_rate": 1.6733819117016718e-05,
      "loss": 0.3005,
      "step": 11430
    },
    {
      "epoch": 2.4517788255465067,
      "grad_norm": 0.06805899739265442,
      "learning_rate": 1.6730961565937992e-05,
      "loss": 0.187,
      "step": 11440
    },
    {
      "epoch": 2.4539219888555506,
      "grad_norm": 1.3584147691726685,
      "learning_rate": 1.6728104014859266e-05,
      "loss": 2.0442,
      "step": 11450
    },
    {
      "epoch": 2.456065152164595,
      "grad_norm": 23.498775482177734,
      "learning_rate": 1.6725246463780543e-05,
      "loss": 0.3846,
      "step": 11460
    },
    {
      "epoch": 2.458208315473639,
      "grad_norm": 1.6357451677322388,
      "learning_rate": 1.6722388912701817e-05,
      "loss": 0.1491,
      "step": 11470
    },
    {
      "epoch": 2.460351478782683,
      "grad_norm": 5.202992916107178,
      "learning_rate": 1.671953136162309e-05,
      "loss": 0.4287,
      "step": 11480
    },
    {
      "epoch": 2.4624946420917273,
      "grad_norm": 18.512357711791992,
      "learning_rate": 1.6716673810544365e-05,
      "loss": 0.3903,
      "step": 11490
    },
    {
      "epoch": 2.4646378054007716,
      "grad_norm": 0.18180932104587555,
      "learning_rate": 1.671381625946564e-05,
      "loss": 0.275,
      "step": 11500
    },
    {
      "epoch": 2.4667809687098154,
      "grad_norm": 0.1200219914317131,
      "learning_rate": 1.6710958708386913e-05,
      "loss": 0.0024,
      "step": 11510
    },
    {
      "epoch": 2.4689241320188597,
      "grad_norm": 0.020527983084321022,
      "learning_rate": 1.6708101157308187e-05,
      "loss": 0.1628,
      "step": 11520
    },
    {
      "epoch": 2.471067295327904,
      "grad_norm": 0.22239771485328674,
      "learning_rate": 1.670524360622946e-05,
      "loss": 0.2138,
      "step": 11530
    },
    {
      "epoch": 2.4732104586369483,
      "grad_norm": 0.009873748756945133,
      "learning_rate": 1.6702386055150738e-05,
      "loss": 0.0008,
      "step": 11540
    },
    {
      "epoch": 2.475353621945992,
      "grad_norm": 0.014303927309811115,
      "learning_rate": 1.6699528504072012e-05,
      "loss": 0.0211,
      "step": 11550
    },
    {
      "epoch": 2.4774967852550365,
      "grad_norm": 0.026938546448946,
      "learning_rate": 1.6696670952993286e-05,
      "loss": 0.2878,
      "step": 11560
    },
    {
      "epoch": 2.4796399485640808,
      "grad_norm": 0.019423360005021095,
      "learning_rate": 1.669381340191456e-05,
      "loss": 0.0923,
      "step": 11570
    },
    {
      "epoch": 2.4817831118731246,
      "grad_norm": 0.020524753257632256,
      "learning_rate": 1.6690955850835834e-05,
      "loss": 0.0009,
      "step": 11580
    },
    {
      "epoch": 2.483926275182169,
      "grad_norm": 0.00868777371942997,
      "learning_rate": 1.6688098299757108e-05,
      "loss": 0.084,
      "step": 11590
    },
    {
      "epoch": 2.486069438491213,
      "grad_norm": 0.006161059252917767,
      "learning_rate": 1.6685240748678385e-05,
      "loss": 0.0037,
      "step": 11600
    },
    {
      "epoch": 2.488212601800257,
      "grad_norm": 0.007641287054866552,
      "learning_rate": 1.668238319759966e-05,
      "loss": 0.1706,
      "step": 11610
    },
    {
      "epoch": 2.4903557651093013,
      "grad_norm": 0.021748797968029976,
      "learning_rate": 1.6679525646520933e-05,
      "loss": 0.1305,
      "step": 11620
    },
    {
      "epoch": 2.4924989284183456,
      "grad_norm": 0.03271043300628662,
      "learning_rate": 1.6676668095442207e-05,
      "loss": 0.2319,
      "step": 11630
    },
    {
      "epoch": 2.4946420917273895,
      "grad_norm": 0.057660143822431564,
      "learning_rate": 1.667381054436348e-05,
      "loss": 0.5224,
      "step": 11640
    },
    {
      "epoch": 2.496785255036434,
      "grad_norm": 10.15608024597168,
      "learning_rate": 1.6670952993284758e-05,
      "loss": 0.3542,
      "step": 11650
    },
    {
      "epoch": 2.498928418345478,
      "grad_norm": 3.4904632568359375,
      "learning_rate": 1.6668095442206032e-05,
      "loss": 0.108,
      "step": 11660
    },
    {
      "epoch": 2.501071581654522,
      "grad_norm": 0.0036375669296830893,
      "learning_rate": 1.6665237891127306e-05,
      "loss": 0.0619,
      "step": 11670
    },
    {
      "epoch": 2.503214744963566,
      "grad_norm": 22.917469024658203,
      "learning_rate": 1.666238034004858e-05,
      "loss": 0.4603,
      "step": 11680
    },
    {
      "epoch": 2.5053579082726105,
      "grad_norm": 0.00459719356149435,
      "learning_rate": 1.6659522788969854e-05,
      "loss": 0.0014,
      "step": 11690
    },
    {
      "epoch": 2.5075010715816544,
      "grad_norm": 0.0025165665429085493,
      "learning_rate": 1.665666523789113e-05,
      "loss": 0.1731,
      "step": 11700
    },
    {
      "epoch": 2.5096442348906987,
      "grad_norm": 0.002743274439126253,
      "learning_rate": 1.6653807686812402e-05,
      "loss": 0.0011,
      "step": 11710
    },
    {
      "epoch": 2.511787398199743,
      "grad_norm": 0.0023493110202252865,
      "learning_rate": 1.6650950135733676e-05,
      "loss": 0.1169,
      "step": 11720
    },
    {
      "epoch": 2.5139305615087872,
      "grad_norm": 18.680883407592773,
      "learning_rate": 1.664809258465495e-05,
      "loss": 0.8035,
      "step": 11730
    },
    {
      "epoch": 2.516073724817831,
      "grad_norm": 0.01345636136829853,
      "learning_rate": 1.6645235033576227e-05,
      "loss": 0.0003,
      "step": 11740
    },
    {
      "epoch": 2.5182168881268754,
      "grad_norm": 0.014773968607187271,
      "learning_rate": 1.66423774824975e-05,
      "loss": 0.1373,
      "step": 11750
    },
    {
      "epoch": 2.5203600514359197,
      "grad_norm": 0.010618697851896286,
      "learning_rate": 1.6639519931418775e-05,
      "loss": 0.0021,
      "step": 11760
    },
    {
      "epoch": 2.5225032147449635,
      "grad_norm": 18.331022262573242,
      "learning_rate": 1.663666238034005e-05,
      "loss": 0.3039,
      "step": 11770
    },
    {
      "epoch": 2.524646378054008,
      "grad_norm": 0.07869993895292282,
      "learning_rate": 1.6633804829261323e-05,
      "loss": 0.0018,
      "step": 11780
    },
    {
      "epoch": 2.526789541363052,
      "grad_norm": 0.014981186017394066,
      "learning_rate": 1.66309472781826e-05,
      "loss": 0.0008,
      "step": 11790
    },
    {
      "epoch": 2.528932704672096,
      "grad_norm": 0.009408636949956417,
      "learning_rate": 1.6628089727103874e-05,
      "loss": 0.0005,
      "step": 11800
    },
    {
      "epoch": 2.5310758679811403,
      "grad_norm": 0.018603956326842308,
      "learning_rate": 1.6625232176025148e-05,
      "loss": 0.1744,
      "step": 11810
    },
    {
      "epoch": 2.5332190312901846,
      "grad_norm": 0.008461476303637028,
      "learning_rate": 1.6622374624946422e-05,
      "loss": 0.1875,
      "step": 11820
    },
    {
      "epoch": 2.5353621945992284,
      "grad_norm": 0.006606755778193474,
      "learning_rate": 1.6619517073867696e-05,
      "loss": 0.0002,
      "step": 11830
    },
    {
      "epoch": 2.5375053579082727,
      "grad_norm": 0.007136105559766293,
      "learning_rate": 1.6616659522788973e-05,
      "loss": 0.0005,
      "step": 11840
    },
    {
      "epoch": 2.539648521217317,
      "grad_norm": 0.13258598744869232,
      "learning_rate": 1.6613801971710247e-05,
      "loss": 0.0004,
      "step": 11850
    },
    {
      "epoch": 2.541791684526361,
      "grad_norm": 0.007416325155645609,
      "learning_rate": 1.661094442063152e-05,
      "loss": 0.2758,
      "step": 11860
    },
    {
      "epoch": 2.543934847835405,
      "grad_norm": 0.010280603542923927,
      "learning_rate": 1.6608086869552795e-05,
      "loss": 0.0008,
      "step": 11870
    },
    {
      "epoch": 2.5460780111444494,
      "grad_norm": 0.046689875423908234,
      "learning_rate": 1.660522931847407e-05,
      "loss": 0.0004,
      "step": 11880
    },
    {
      "epoch": 2.5482211744534933,
      "grad_norm": 0.009696274995803833,
      "learning_rate": 1.6602371767395343e-05,
      "loss": 0.0005,
      "step": 11890
    },
    {
      "epoch": 2.5503643377625376,
      "grad_norm": 0.008866853080689907,
      "learning_rate": 1.659951421631662e-05,
      "loss": 0.0003,
      "step": 11900
    },
    {
      "epoch": 2.552507501071582,
      "grad_norm": 0.04975264146924019,
      "learning_rate": 1.6596656665237894e-05,
      "loss": 0.0002,
      "step": 11910
    },
    {
      "epoch": 2.5546506643806257,
      "grad_norm": 0.006532597355544567,
      "learning_rate": 1.6593799114159164e-05,
      "loss": 0.1846,
      "step": 11920
    },
    {
      "epoch": 2.55679382768967,
      "grad_norm": 0.008712849579751492,
      "learning_rate": 1.6590941563080442e-05,
      "loss": 0.0003,
      "step": 11930
    },
    {
      "epoch": 2.5589369909987143,
      "grad_norm": 0.023819873109459877,
      "learning_rate": 1.6588084012001716e-05,
      "loss": 0.0007,
      "step": 11940
    },
    {
      "epoch": 2.561080154307758,
      "grad_norm": 0.006213622633367777,
      "learning_rate": 1.658522646092299e-05,
      "loss": 0.0002,
      "step": 11950
    },
    {
      "epoch": 2.5632233176168024,
      "grad_norm": 0.008509964682161808,
      "learning_rate": 1.6582368909844264e-05,
      "loss": 0.3033,
      "step": 11960
    },
    {
      "epoch": 2.5653664809258467,
      "grad_norm": 0.05822039023041725,
      "learning_rate": 1.6579511358765538e-05,
      "loss": 0.0005,
      "step": 11970
    },
    {
      "epoch": 2.5675096442348906,
      "grad_norm": 0.007720464840531349,
      "learning_rate": 1.6576653807686815e-05,
      "loss": 0.0002,
      "step": 11980
    },
    {
      "epoch": 2.569652807543935,
      "grad_norm": 0.007482481189072132,
      "learning_rate": 1.657379625660809e-05,
      "loss": 0.0003,
      "step": 11990
    },
    {
      "epoch": 2.571795970852979,
      "grad_norm": 0.007490014191716909,
      "learning_rate": 1.6570938705529363e-05,
      "loss": 0.0003,
      "step": 12000
    },
    {
      "epoch": 2.573939134162023,
      "grad_norm": 0.017784928902983665,
      "learning_rate": 1.6568081154450637e-05,
      "loss": 0.2673,
      "step": 12010
    },
    {
      "epoch": 2.5760822974710673,
      "grad_norm": 0.011961777694523335,
      "learning_rate": 1.656522360337191e-05,
      "loss": 0.0004,
      "step": 12020
    },
    {
      "epoch": 2.5782254607801116,
      "grad_norm": 0.021763721480965614,
      "learning_rate": 1.6562366052293184e-05,
      "loss": 0.2426,
      "step": 12030
    },
    {
      "epoch": 2.5803686240891555,
      "grad_norm": 0.01995398849248886,
      "learning_rate": 1.6559508501214462e-05,
      "loss": 0.0005,
      "step": 12040
    },
    {
      "epoch": 2.5825117873981998,
      "grad_norm": 0.02086062729358673,
      "learning_rate": 1.6556650950135736e-05,
      "loss": 0.0005,
      "step": 12050
    },
    {
      "epoch": 2.584654950707244,
      "grad_norm": 0.014268123544752598,
      "learning_rate": 1.655379339905701e-05,
      "loss": 0.1991,
      "step": 12060
    },
    {
      "epoch": 2.586798114016288,
      "grad_norm": 0.011219521053135395,
      "learning_rate": 1.6550935847978284e-05,
      "loss": 0.0003,
      "step": 12070
    },
    {
      "epoch": 2.588941277325332,
      "grad_norm": 0.022452227771282196,
      "learning_rate": 1.6548078296899558e-05,
      "loss": 0.1908,
      "step": 12080
    },
    {
      "epoch": 2.5910844406343765,
      "grad_norm": 0.08201999217271805,
      "learning_rate": 1.6545220745820835e-05,
      "loss": 0.0009,
      "step": 12090
    },
    {
      "epoch": 2.5932276039434203,
      "grad_norm": 0.013088757172226906,
      "learning_rate": 1.654236319474211e-05,
      "loss": 0.0005,
      "step": 12100
    },
    {
      "epoch": 2.5953707672524646,
      "grad_norm": 0.03645522519946098,
      "learning_rate": 1.6539505643663383e-05,
      "loss": 0.0198,
      "step": 12110
    },
    {
      "epoch": 2.597513930561509,
      "grad_norm": 0.008128351531922817,
      "learning_rate": 1.6536648092584657e-05,
      "loss": 0.0004,
      "step": 12120
    },
    {
      "epoch": 2.5996570938705528,
      "grad_norm": 17.959505081176758,
      "learning_rate": 1.653379054150593e-05,
      "loss": 0.2627,
      "step": 12130
    },
    {
      "epoch": 2.601800257179597,
      "grad_norm": 0.011470764875411987,
      "learning_rate": 1.6530932990427204e-05,
      "loss": 0.0003,
      "step": 12140
    },
    {
      "epoch": 2.6039434204886414,
      "grad_norm": 0.03935577720403671,
      "learning_rate": 1.652807543934848e-05,
      "loss": 0.0003,
      "step": 12150
    },
    {
      "epoch": 2.606086583797685,
      "grad_norm": 0.011247249320149422,
      "learning_rate": 1.6525217888269752e-05,
      "loss": 0.2582,
      "step": 12160
    },
    {
      "epoch": 2.6082297471067295,
      "grad_norm": 0.01354930829256773,
      "learning_rate": 1.6522360337191026e-05,
      "loss": 0.0131,
      "step": 12170
    },
    {
      "epoch": 2.610372910415774,
      "grad_norm": 0.021655436605215073,
      "learning_rate": 1.6519502786112304e-05,
      "loss": 0.2067,
      "step": 12180
    },
    {
      "epoch": 2.6125160737248176,
      "grad_norm": 0.1975356489419937,
      "learning_rate": 1.6516645235033577e-05,
      "loss": 0.2762,
      "step": 12190
    },
    {
      "epoch": 2.614659237033862,
      "grad_norm": 0.03764483332633972,
      "learning_rate": 1.651378768395485e-05,
      "loss": 0.0006,
      "step": 12200
    },
    {
      "epoch": 2.6168024003429062,
      "grad_norm": 0.033293407410383224,
      "learning_rate": 1.6510930132876125e-05,
      "loss": 0.0007,
      "step": 12210
    },
    {
      "epoch": 2.61894556365195,
      "grad_norm": 0.01342143677175045,
      "learning_rate": 1.65080725817974e-05,
      "loss": 0.1913,
      "step": 12220
    },
    {
      "epoch": 2.6210887269609944,
      "grad_norm": 0.014732579700648785,
      "learning_rate": 1.6505215030718677e-05,
      "loss": 0.1948,
      "step": 12230
    },
    {
      "epoch": 2.6232318902700387,
      "grad_norm": 19.464685440063477,
      "learning_rate": 1.650235747963995e-05,
      "loss": 0.2234,
      "step": 12240
    },
    {
      "epoch": 2.6253750535790825,
      "grad_norm": 0.016024120151996613,
      "learning_rate": 1.6499499928561224e-05,
      "loss": 0.001,
      "step": 12250
    },
    {
      "epoch": 2.627518216888127,
      "grad_norm": 0.015052242204546928,
      "learning_rate": 1.64966423774825e-05,
      "loss": 0.0009,
      "step": 12260
    },
    {
      "epoch": 2.629661380197171,
      "grad_norm": 0.013873693533241749,
      "learning_rate": 1.6493784826403772e-05,
      "loss": 0.001,
      "step": 12270
    },
    {
      "epoch": 2.631804543506215,
      "grad_norm": 0.01919778808951378,
      "learning_rate": 1.649092727532505e-05,
      "loss": 0.0009,
      "step": 12280
    },
    {
      "epoch": 2.6339477068152592,
      "grad_norm": 0.01037406362593174,
      "learning_rate": 1.6488069724246324e-05,
      "loss": 0.0006,
      "step": 12290
    },
    {
      "epoch": 2.6360908701243035,
      "grad_norm": 0.020909113809466362,
      "learning_rate": 1.6485212173167597e-05,
      "loss": 0.2315,
      "step": 12300
    },
    {
      "epoch": 2.6382340334333474,
      "grad_norm": 0.014975699596107006,
      "learning_rate": 1.648235462208887e-05,
      "loss": 0.0004,
      "step": 12310
    },
    {
      "epoch": 2.6403771967423917,
      "grad_norm": 0.036261510103940964,
      "learning_rate": 1.6479497071010145e-05,
      "loss": 0.2022,
      "step": 12320
    },
    {
      "epoch": 2.642520360051436,
      "grad_norm": 0.07287193834781647,
      "learning_rate": 1.6476639519931423e-05,
      "loss": 0.2083,
      "step": 12330
    },
    {
      "epoch": 2.64466352336048,
      "grad_norm": 0.05943555384874344,
      "learning_rate": 1.6473781968852697e-05,
      "loss": 0.2013,
      "step": 12340
    },
    {
      "epoch": 2.646806686669524,
      "grad_norm": 0.03250313922762871,
      "learning_rate": 1.6470924417773967e-05,
      "loss": 0.0013,
      "step": 12350
    },
    {
      "epoch": 2.6489498499785684,
      "grad_norm": 0.014745061285793781,
      "learning_rate": 1.646806686669524e-05,
      "loss": 0.1074,
      "step": 12360
    },
    {
      "epoch": 2.6510930132876123,
      "grad_norm": 0.031287454068660736,
      "learning_rate": 1.646520931561652e-05,
      "loss": 0.3902,
      "step": 12370
    },
    {
      "epoch": 2.6532361765966566,
      "grad_norm": 0.05308646708726883,
      "learning_rate": 1.6462351764537792e-05,
      "loss": 0.1471,
      "step": 12380
    },
    {
      "epoch": 2.655379339905701,
      "grad_norm": 0.04504455253481865,
      "learning_rate": 1.6459494213459066e-05,
      "loss": 0.0013,
      "step": 12390
    },
    {
      "epoch": 2.6575225032147447,
      "grad_norm": 0.01699475571513176,
      "learning_rate": 1.645663666238034e-05,
      "loss": 0.0008,
      "step": 12400
    },
    {
      "epoch": 2.659665666523789,
      "grad_norm": 0.029830629006028175,
      "learning_rate": 1.6453779111301614e-05,
      "loss": 0.0004,
      "step": 12410
    },
    {
      "epoch": 2.6618088298328333,
      "grad_norm": 0.00867161713540554,
      "learning_rate": 1.645092156022289e-05,
      "loss": 0.1631,
      "step": 12420
    },
    {
      "epoch": 2.663951993141877,
      "grad_norm": 0.025462917983531952,
      "learning_rate": 1.6448064009144165e-05,
      "loss": 0.4097,
      "step": 12430
    },
    {
      "epoch": 2.6660951564509214,
      "grad_norm": 0.04729905724525452,
      "learning_rate": 1.644520645806544e-05,
      "loss": 0.1327,
      "step": 12440
    },
    {
      "epoch": 2.6682383197599657,
      "grad_norm": 0.04610508307814598,
      "learning_rate": 1.6442348906986713e-05,
      "loss": 0.0019,
      "step": 12450
    },
    {
      "epoch": 2.67038148306901,
      "grad_norm": 0.014325371943414211,
      "learning_rate": 1.6439491355907987e-05,
      "loss": 0.2815,
      "step": 12460
    },
    {
      "epoch": 2.672524646378054,
      "grad_norm": 0.05992145091295242,
      "learning_rate": 1.6436633804829264e-05,
      "loss": 0.279,
      "step": 12470
    },
    {
      "epoch": 2.674667809687098,
      "grad_norm": 0.15278029441833496,
      "learning_rate": 1.643377625375054e-05,
      "loss": 0.3657,
      "step": 12480
    },
    {
      "epoch": 2.6768109729961425,
      "grad_norm": 0.047274526208639145,
      "learning_rate": 1.6430918702671812e-05,
      "loss": 0.2393,
      "step": 12490
    },
    {
      "epoch": 2.6789541363051863,
      "grad_norm": 0.03804542124271393,
      "learning_rate": 1.6428061151593086e-05,
      "loss": 0.001,
      "step": 12500
    },
    {
      "epoch": 2.6810972996142306,
      "grad_norm": 0.02762242779135704,
      "learning_rate": 1.642520360051436e-05,
      "loss": 0.0027,
      "step": 12510
    },
    {
      "epoch": 2.683240462923275,
      "grad_norm": 0.024087391793727875,
      "learning_rate": 1.6422346049435634e-05,
      "loss": 0.0005,
      "step": 12520
    },
    {
      "epoch": 2.6853836262323187,
      "grad_norm": 0.021525908261537552,
      "learning_rate": 1.641948849835691e-05,
      "loss": 0.165,
      "step": 12530
    },
    {
      "epoch": 2.687526789541363,
      "grad_norm": 0.01375309843569994,
      "learning_rate": 1.6416630947278185e-05,
      "loss": 0.1496,
      "step": 12540
    },
    {
      "epoch": 2.6896699528504073,
      "grad_norm": 0.011166879907250404,
      "learning_rate": 1.641377339619946e-05,
      "loss": 0.077,
      "step": 12550
    },
    {
      "epoch": 2.6918131161594516,
      "grad_norm": 0.012336138635873795,
      "learning_rate": 1.6410915845120733e-05,
      "loss": 0.2662,
      "step": 12560
    },
    {
      "epoch": 2.6939562794684955,
      "grad_norm": 24.461414337158203,
      "learning_rate": 1.6408058294042007e-05,
      "loss": 0.1176,
      "step": 12570
    },
    {
      "epoch": 2.6960994427775398,
      "grad_norm": 0.016703754663467407,
      "learning_rate": 1.640520074296328e-05,
      "loss": 0.1149,
      "step": 12580
    },
    {
      "epoch": 2.698242606086584,
      "grad_norm": 0.16379883885383606,
      "learning_rate": 1.6402343191884555e-05,
      "loss": 0.0011,
      "step": 12590
    },
    {
      "epoch": 2.700385769395628,
      "grad_norm": 46.39828872680664,
      "learning_rate": 1.639948564080583e-05,
      "loss": 0.3451,
      "step": 12600
    },
    {
      "epoch": 2.702528932704672,
      "grad_norm": 0.014713778160512447,
      "learning_rate": 1.6396628089727106e-05,
      "loss": 0.0434,
      "step": 12610
    },
    {
      "epoch": 2.7046720960137165,
      "grad_norm": 0.013368076644837856,
      "learning_rate": 1.639377053864838e-05,
      "loss": 0.0231,
      "step": 12620
    },
    {
      "epoch": 2.7068152593227603,
      "grad_norm": 0.010569616220891476,
      "learning_rate": 1.6390912987569654e-05,
      "loss": 0.0004,
      "step": 12630
    },
    {
      "epoch": 2.7089584226318046,
      "grad_norm": 0.3627610504627228,
      "learning_rate": 1.6388055436490928e-05,
      "loss": 0.0814,
      "step": 12640
    },
    {
      "epoch": 2.711101585940849,
      "grad_norm": 0.01169595681130886,
      "learning_rate": 1.6385197885412202e-05,
      "loss": 0.0004,
      "step": 12650
    },
    {
      "epoch": 2.713244749249893,
      "grad_norm": 0.009880507364869118,
      "learning_rate": 1.6382340334333476e-05,
      "loss": 0.0026,
      "step": 12660
    },
    {
      "epoch": 2.715387912558937,
      "grad_norm": 0.00999432522803545,
      "learning_rate": 1.6379482783254753e-05,
      "loss": 0.1652,
      "step": 12670
    },
    {
      "epoch": 2.7175310758679814,
      "grad_norm": 0.008662556298077106,
      "learning_rate": 1.6376625232176027e-05,
      "loss": 0.0062,
      "step": 12680
    },
    {
      "epoch": 2.719674239177025,
      "grad_norm": 0.03251902759075165,
      "learning_rate": 1.63737676810973e-05,
      "loss": 0.2656,
      "step": 12690
    },
    {
      "epoch": 2.7218174024860695,
      "grad_norm": 0.04142146185040474,
      "learning_rate": 1.6370910130018575e-05,
      "loss": 0.28,
      "step": 12700
    },
    {
      "epoch": 2.723960565795114,
      "grad_norm": 0.021425636485219002,
      "learning_rate": 1.636805257893985e-05,
      "loss": 0.0007,
      "step": 12710
    },
    {
      "epoch": 2.7261037291041577,
      "grad_norm": 0.09034889936447144,
      "learning_rate": 1.6365195027861126e-05,
      "loss": 0.1459,
      "step": 12720
    },
    {
      "epoch": 2.728246892413202,
      "grad_norm": 0.01571158692240715,
      "learning_rate": 1.63623374767824e-05,
      "loss": 0.1753,
      "step": 12730
    },
    {
      "epoch": 2.7303900557222462,
      "grad_norm": 0.6558188199996948,
      "learning_rate": 1.6359479925703674e-05,
      "loss": 0.0014,
      "step": 12740
    },
    {
      "epoch": 2.73253321903129,
      "grad_norm": 0.0172587763518095,
      "learning_rate": 1.6356622374624948e-05,
      "loss": 0.0004,
      "step": 12750
    },
    {
      "epoch": 2.7346763823403344,
      "grad_norm": 0.14376360177993774,
      "learning_rate": 1.6353764823546222e-05,
      "loss": 0.0009,
      "step": 12760
    },
    {
      "epoch": 2.7368195456493787,
      "grad_norm": 0.01685449667274952,
      "learning_rate": 1.63509072724675e-05,
      "loss": 0.2682,
      "step": 12770
    },
    {
      "epoch": 2.7389627089584225,
      "grad_norm": 77.58075714111328,
      "learning_rate": 1.634804972138877e-05,
      "loss": 0.1033,
      "step": 12780
    },
    {
      "epoch": 2.741105872267467,
      "grad_norm": 0.01966850273311138,
      "learning_rate": 1.6345192170310044e-05,
      "loss": 0.1232,
      "step": 12790
    },
    {
      "epoch": 2.743249035576511,
      "grad_norm": 0.17789186537265778,
      "learning_rate": 1.6342334619231318e-05,
      "loss": 0.2457,
      "step": 12800
    },
    {
      "epoch": 2.745392198885555,
      "grad_norm": 0.026559295132756233,
      "learning_rate": 1.6339477068152595e-05,
      "loss": 0.0055,
      "step": 12810
    },
    {
      "epoch": 2.7475353621945993,
      "grad_norm": 0.0286480113863945,
      "learning_rate": 1.633661951707387e-05,
      "loss": 0.0006,
      "step": 12820
    },
    {
      "epoch": 2.7496785255036436,
      "grad_norm": 0.05046309530735016,
      "learning_rate": 1.6333761965995143e-05,
      "loss": 0.2335,
      "step": 12830
    },
    {
      "epoch": 2.7518216888126874,
      "grad_norm": 0.09874017536640167,
      "learning_rate": 1.6330904414916417e-05,
      "loss": 0.1618,
      "step": 12840
    },
    {
      "epoch": 2.7539648521217317,
      "grad_norm": 0.02018379420042038,
      "learning_rate": 1.632804686383769e-05,
      "loss": 0.2068,
      "step": 12850
    },
    {
      "epoch": 2.756108015430776,
      "grad_norm": 0.017176557332277298,
      "learning_rate": 1.6325189312758968e-05,
      "loss": 0.0009,
      "step": 12860
    },
    {
      "epoch": 2.75825117873982,
      "grad_norm": 0.032037291675806046,
      "learning_rate": 1.6322331761680242e-05,
      "loss": 0.0006,
      "step": 12870
    },
    {
      "epoch": 2.760394342048864,
      "grad_norm": 0.018394744023680687,
      "learning_rate": 1.6319474210601516e-05,
      "loss": 0.1982,
      "step": 12880
    },
    {
      "epoch": 2.7625375053579084,
      "grad_norm": 0.019058123230934143,
      "learning_rate": 1.631661665952279e-05,
      "loss": 0.1798,
      "step": 12890
    },
    {
      "epoch": 2.7646806686669523,
      "grad_norm": 0.019335715100169182,
      "learning_rate": 1.6313759108444064e-05,
      "loss": 0.1597,
      "step": 12900
    },
    {
      "epoch": 2.7668238319759966,
      "grad_norm": 23.755840301513672,
      "learning_rate": 1.631090155736534e-05,
      "loss": 0.2636,
      "step": 12910
    },
    {
      "epoch": 2.768966995285041,
      "grad_norm": 0.24187463521957397,
      "learning_rate": 1.6308044006286615e-05,
      "loss": 0.0016,
      "step": 12920
    },
    {
      "epoch": 2.7711101585940847,
      "grad_norm": 0.008479133248329163,
      "learning_rate": 1.630518645520789e-05,
      "loss": 0.0008,
      "step": 12930
    },
    {
      "epoch": 2.773253321903129,
      "grad_norm": 0.004910828545689583,
      "learning_rate": 1.6302328904129163e-05,
      "loss": 0.0029,
      "step": 12940
    },
    {
      "epoch": 2.7753964852121733,
      "grad_norm": 0.0032900208607316017,
      "learning_rate": 1.6299471353050437e-05,
      "loss": 0.2893,
      "step": 12950
    },
    {
      "epoch": 2.777539648521217,
      "grad_norm": 0.011317984201014042,
      "learning_rate": 1.6296613801971714e-05,
      "loss": 0.2748,
      "step": 12960
    },
    {
      "epoch": 2.7796828118302614,
      "grad_norm": 0.717045247554779,
      "learning_rate": 1.6293756250892988e-05,
      "loss": 0.2269,
      "step": 12970
    },
    {
      "epoch": 2.7818259751393057,
      "grad_norm": 0.025471655651926994,
      "learning_rate": 1.6290898699814262e-05,
      "loss": 0.0006,
      "step": 12980
    },
    {
      "epoch": 2.7839691384483496,
      "grad_norm": 0.03863890841603279,
      "learning_rate": 1.6288041148735532e-05,
      "loss": 0.0007,
      "step": 12990
    },
    {
      "epoch": 2.786112301757394,
      "grad_norm": 0.012048669159412384,
      "learning_rate": 1.628518359765681e-05,
      "loss": 0.0004,
      "step": 13000
    },
    {
      "epoch": 2.788255465066438,
      "grad_norm": 0.048725374042987823,
      "learning_rate": 1.6282326046578084e-05,
      "loss": 0.0002,
      "step": 13010
    },
    {
      "epoch": 2.790398628375482,
      "grad_norm": 0.004956269636750221,
      "learning_rate": 1.6279468495499358e-05,
      "loss": 0.0001,
      "step": 13020
    },
    {
      "epoch": 2.7925417916845263,
      "grad_norm": 19.985042572021484,
      "learning_rate": 1.627661094442063e-05,
      "loss": 0.319,
      "step": 13030
    },
    {
      "epoch": 2.7946849549935706,
      "grad_norm": 0.057893529534339905,
      "learning_rate": 1.6273753393341905e-05,
      "loss": 0.284,
      "step": 13040
    },
    {
      "epoch": 2.7968281183026145,
      "grad_norm": 0.030190709978342056,
      "learning_rate": 1.6270895842263183e-05,
      "loss": 0.1796,
      "step": 13050
    },
    {
      "epoch": 2.7989712816116588,
      "grad_norm": 0.026692405343055725,
      "learning_rate": 1.6268038291184457e-05,
      "loss": 0.0009,
      "step": 13060
    },
    {
      "epoch": 2.801114444920703,
      "grad_norm": 0.014965005218982697,
      "learning_rate": 1.626518074010573e-05,
      "loss": 0.1459,
      "step": 13070
    },
    {
      "epoch": 2.803257608229747,
      "grad_norm": 0.017503129318356514,
      "learning_rate": 1.6262323189027005e-05,
      "loss": 0.0005,
      "step": 13080
    },
    {
      "epoch": 2.805400771538791,
      "grad_norm": 0.039829693734645844,
      "learning_rate": 1.625946563794828e-05,
      "loss": 0.0007,
      "step": 13090
    },
    {
      "epoch": 2.8075439348478355,
      "grad_norm": 0.008268671110272408,
      "learning_rate": 1.6256608086869556e-05,
      "loss": 0.3065,
      "step": 13100
    },
    {
      "epoch": 2.8096870981568793,
      "grad_norm": 0.036329612135887146,
      "learning_rate": 1.625375053579083e-05,
      "loss": 0.482,
      "step": 13110
    },
    {
      "epoch": 2.8118302614659236,
      "grad_norm": 0.15199296176433563,
      "learning_rate": 1.6250892984712104e-05,
      "loss": 0.0019,
      "step": 13120
    },
    {
      "epoch": 2.813973424774968,
      "grad_norm": 0.026438670232892036,
      "learning_rate": 1.6248035433633378e-05,
      "loss": 0.0012,
      "step": 13130
    },
    {
      "epoch": 2.8161165880840118,
      "grad_norm": 0.018408460542559624,
      "learning_rate": 1.624517788255465e-05,
      "loss": 0.1367,
      "step": 13140
    },
    {
      "epoch": 2.818259751393056,
      "grad_norm": 20.494733810424805,
      "learning_rate": 1.6242320331475925e-05,
      "loss": 0.2292,
      "step": 13150
    },
    {
      "epoch": 2.8204029147021004,
      "grad_norm": 0.06790375709533691,
      "learning_rate": 1.6239462780397203e-05,
      "loss": 0.0006,
      "step": 13160
    },
    {
      "epoch": 2.822546078011144,
      "grad_norm": 0.04108842462301254,
      "learning_rate": 1.6236605229318477e-05,
      "loss": 0.0005,
      "step": 13170
    },
    {
      "epoch": 2.8246892413201885,
      "grad_norm": 0.013264530338346958,
      "learning_rate": 1.623374767823975e-05,
      "loss": 0.0003,
      "step": 13180
    },
    {
      "epoch": 2.826832404629233,
      "grad_norm": 0.014126110821962357,
      "learning_rate": 1.6230890127161025e-05,
      "loss": 0.3292,
      "step": 13190
    },
    {
      "epoch": 2.8289755679382766,
      "grad_norm": 0.017731720581650734,
      "learning_rate": 1.62280325760823e-05,
      "loss": 0.0013,
      "step": 13200
    },
    {
      "epoch": 2.831118731247321,
      "grad_norm": 0.07963337004184723,
      "learning_rate": 1.6225175025003572e-05,
      "loss": 0.2291,
      "step": 13210
    },
    {
      "epoch": 2.8332618945563652,
      "grad_norm": 0.017550552263855934,
      "learning_rate": 1.6222317473924846e-05,
      "loss": 0.2054,
      "step": 13220
    },
    {
      "epoch": 2.835405057865409,
      "grad_norm": 0.009040765464305878,
      "learning_rate": 1.621945992284612e-05,
      "loss": 0.0003,
      "step": 13230
    },
    {
      "epoch": 2.8375482211744534,
      "grad_norm": 0.602078378200531,
      "learning_rate": 1.6216602371767398e-05,
      "loss": 0.4893,
      "step": 13240
    },
    {
      "epoch": 2.8396913844834977,
      "grad_norm": 0.07742685824632645,
      "learning_rate": 1.621374482068867e-05,
      "loss": 0.4152,
      "step": 13250
    },
    {
      "epoch": 2.8418345477925415,
      "grad_norm": 0.059562671929597855,
      "learning_rate": 1.6210887269609945e-05,
      "loss": 0.0064,
      "step": 13260
    },
    {
      "epoch": 2.843977711101586,
      "grad_norm": 0.020617805421352386,
      "learning_rate": 1.620802971853122e-05,
      "loss": 0.0009,
      "step": 13270
    },
    {
      "epoch": 2.84612087441063,
      "grad_norm": 0.021690206602215767,
      "learning_rate": 1.6205172167452493e-05,
      "loss": 0.0005,
      "step": 13280
    },
    {
      "epoch": 2.8482640377196744,
      "grad_norm": 0.02821805141866207,
      "learning_rate": 1.6202314616373767e-05,
      "loss": 0.2185,
      "step": 13290
    },
    {
      "epoch": 2.8504072010287183,
      "grad_norm": 0.016740672290325165,
      "learning_rate": 1.6199457065295045e-05,
      "loss": 0.0006,
      "step": 13300
    },
    {
      "epoch": 2.8525503643377625,
      "grad_norm": 0.016018150374293327,
      "learning_rate": 1.619659951421632e-05,
      "loss": 0.0004,
      "step": 13310
    },
    {
      "epoch": 2.854693527646807,
      "grad_norm": 0.01004051137715578,
      "learning_rate": 1.6193741963137592e-05,
      "loss": 0.0005,
      "step": 13320
    },
    {
      "epoch": 2.8568366909558507,
      "grad_norm": 0.016602763906121254,
      "learning_rate": 1.6190884412058866e-05,
      "loss": 0.4926,
      "step": 13330
    },
    {
      "epoch": 2.858979854264895,
      "grad_norm": 0.025255775079131126,
      "learning_rate": 1.618802686098014e-05,
      "loss": 0.0005,
      "step": 13340
    },
    {
      "epoch": 2.8611230175739393,
      "grad_norm": 0.02271953411400318,
      "learning_rate": 1.6185169309901418e-05,
      "loss": 0.1895,
      "step": 13350
    },
    {
      "epoch": 2.863266180882983,
      "grad_norm": 0.05217789113521576,
      "learning_rate": 1.618231175882269e-05,
      "loss": 0.3325,
      "step": 13360
    },
    {
      "epoch": 2.8654093441920274,
      "grad_norm": 0.035956401377916336,
      "learning_rate": 1.6179454207743965e-05,
      "loss": 0.1441,
      "step": 13370
    },
    {
      "epoch": 2.8675525075010717,
      "grad_norm": 0.0482950434088707,
      "learning_rate": 1.617659665666524e-05,
      "loss": 0.0009,
      "step": 13380
    },
    {
      "epoch": 2.869695670810116,
      "grad_norm": 0.02479945495724678,
      "learning_rate": 1.6173739105586513e-05,
      "loss": 0.3717,
      "step": 13390
    },
    {
      "epoch": 2.87183883411916,
      "grad_norm": 0.04529138281941414,
      "learning_rate": 1.617088155450779e-05,
      "loss": 0.0011,
      "step": 13400
    },
    {
      "epoch": 2.873981997428204,
      "grad_norm": 0.01564483903348446,
      "learning_rate": 1.6168024003429065e-05,
      "loss": 0.0005,
      "step": 13410
    },
    {
      "epoch": 2.8761251607372484,
      "grad_norm": 0.009888453409075737,
      "learning_rate": 1.6165166452350335e-05,
      "loss": 0.0003,
      "step": 13420
    },
    {
      "epoch": 2.8782683240462923,
      "grad_norm": 0.008881756104528904,
      "learning_rate": 1.616230890127161e-05,
      "loss": 0.0004,
      "step": 13430
    },
    {
      "epoch": 2.8804114873553366,
      "grad_norm": 17.889385223388672,
      "learning_rate": 1.6159451350192886e-05,
      "loss": 0.2814,
      "step": 13440
    },
    {
      "epoch": 2.882554650664381,
      "grad_norm": 0.008074679411947727,
      "learning_rate": 1.615659379911416e-05,
      "loss": 0.0002,
      "step": 13450
    },
    {
      "epoch": 2.8846978139734247,
      "grad_norm": 0.015038532204926014,
      "learning_rate": 1.6153736248035434e-05,
      "loss": 0.0006,
      "step": 13460
    },
    {
      "epoch": 2.886840977282469,
      "grad_norm": 0.051986027508974075,
      "learning_rate": 1.6150878696956708e-05,
      "loss": 0.0004,
      "step": 13470
    },
    {
      "epoch": 2.8889841405915133,
      "grad_norm": 0.016696132719516754,
      "learning_rate": 1.6148021145877982e-05,
      "loss": 0.3643,
      "step": 13480
    },
    {
      "epoch": 2.891127303900557,
      "grad_norm": 0.04772428050637245,
      "learning_rate": 1.614516359479926e-05,
      "loss": 0.0008,
      "step": 13490
    },
    {
      "epoch": 2.8932704672096015,
      "grad_norm": 0.03374050185084343,
      "learning_rate": 1.6142306043720533e-05,
      "loss": 0.0009,
      "step": 13500
    },
    {
      "epoch": 2.8954136305186458,
      "grad_norm": 0.06187773868441582,
      "learning_rate": 1.6139448492641807e-05,
      "loss": 0.1807,
      "step": 13510
    },
    {
      "epoch": 2.8975567938276896,
      "grad_norm": 0.015594612807035446,
      "learning_rate": 1.613659094156308e-05,
      "loss": 0.0004,
      "step": 13520
    },
    {
      "epoch": 2.899699957136734,
      "grad_norm": 0.006168942432850599,
      "learning_rate": 1.6133733390484355e-05,
      "loss": 0.0003,
      "step": 13530
    },
    {
      "epoch": 2.901843120445778,
      "grad_norm": 0.008535356260836124,
      "learning_rate": 1.6130875839405632e-05,
      "loss": 0.411,
      "step": 13540
    },
    {
      "epoch": 2.903986283754822,
      "grad_norm": 0.006386144552379847,
      "learning_rate": 1.6128018288326906e-05,
      "loss": 0.0763,
      "step": 13550
    },
    {
      "epoch": 2.9061294470638663,
      "grad_norm": 0.007530631963163614,
      "learning_rate": 1.612516073724818e-05,
      "loss": 0.1693,
      "step": 13560
    },
    {
      "epoch": 2.9082726103729106,
      "grad_norm": 0.007990945130586624,
      "learning_rate": 1.6122303186169454e-05,
      "loss": 0.0012,
      "step": 13570
    },
    {
      "epoch": 2.9104157736819545,
      "grad_norm": 16.874500274658203,
      "learning_rate": 1.6119445635090728e-05,
      "loss": 0.3121,
      "step": 13580
    },
    {
      "epoch": 2.9125589369909988,
      "grad_norm": 0.01314006932079792,
      "learning_rate": 1.6116588084012005e-05,
      "loss": 0.212,
      "step": 13590
    },
    {
      "epoch": 2.914702100300043,
      "grad_norm": 0.26375213265419006,
      "learning_rate": 1.611373053293328e-05,
      "loss": 0.0015,
      "step": 13600
    },
    {
      "epoch": 2.916845263609087,
      "grad_norm": 0.11535592377185822,
      "learning_rate": 1.6110872981854553e-05,
      "loss": 0.0021,
      "step": 13610
    },
    {
      "epoch": 2.918988426918131,
      "grad_norm": 0.005867764353752136,
      "learning_rate": 1.6108015430775827e-05,
      "loss": 0.0016,
      "step": 13620
    },
    {
      "epoch": 2.9211315902271755,
      "grad_norm": 0.004072605166584253,
      "learning_rate": 1.61051578796971e-05,
      "loss": 0.0008,
      "step": 13630
    },
    {
      "epoch": 2.9232747535362194,
      "grad_norm": 0.02647288516163826,
      "learning_rate": 1.6102300328618375e-05,
      "loss": 0.0005,
      "step": 13640
    },
    {
      "epoch": 2.9254179168452636,
      "grad_norm": 45.61272430419922,
      "learning_rate": 1.609944277753965e-05,
      "loss": 0.1079,
      "step": 13650
    },
    {
      "epoch": 2.927561080154308,
      "grad_norm": 0.004666315391659737,
      "learning_rate": 1.6096585226460923e-05,
      "loss": 0.2841,
      "step": 13660
    },
    {
      "epoch": 2.929704243463352,
      "grad_norm": 0.0073576332069933414,
      "learning_rate": 1.6093727675382197e-05,
      "loss": 0.0003,
      "step": 13670
    },
    {
      "epoch": 2.931847406772396,
      "grad_norm": 0.08309129625558853,
      "learning_rate": 1.6090870124303474e-05,
      "loss": 0.0851,
      "step": 13680
    },
    {
      "epoch": 2.9339905700814404,
      "grad_norm": 0.07883385568857193,
      "learning_rate": 1.6088012573224748e-05,
      "loss": 0.2574,
      "step": 13690
    },
    {
      "epoch": 2.9361337333904842,
      "grad_norm": 0.023211969062685966,
      "learning_rate": 1.6085155022146022e-05,
      "loss": 0.2345,
      "step": 13700
    },
    {
      "epoch": 2.9382768966995285,
      "grad_norm": 0.005660502705723047,
      "learning_rate": 1.6082297471067296e-05,
      "loss": 0.0008,
      "step": 13710
    },
    {
      "epoch": 2.940420060008573,
      "grad_norm": 17.654823303222656,
      "learning_rate": 1.607943991998857e-05,
      "loss": 0.2999,
      "step": 13720
    },
    {
      "epoch": 2.9425632233176167,
      "grad_norm": 0.008479021489620209,
      "learning_rate": 1.6076582368909847e-05,
      "loss": 0.0005,
      "step": 13730
    },
    {
      "epoch": 2.944706386626661,
      "grad_norm": 0.008324981667101383,
      "learning_rate": 1.607372481783112e-05,
      "loss": 0.0003,
      "step": 13740
    },
    {
      "epoch": 2.9468495499357052,
      "grad_norm": 23.38835906982422,
      "learning_rate": 1.6070867266752395e-05,
      "loss": 0.0142,
      "step": 13750
    },
    {
      "epoch": 2.948992713244749,
      "grad_norm": 0.005655238404870033,
      "learning_rate": 1.606800971567367e-05,
      "loss": 0.0002,
      "step": 13760
    },
    {
      "epoch": 2.9511358765537934,
      "grad_norm": 0.007633536122739315,
      "learning_rate": 1.6065152164594943e-05,
      "loss": 0.0004,
      "step": 13770
    },
    {
      "epoch": 2.9532790398628377,
      "grad_norm": 0.00625403830781579,
      "learning_rate": 1.6062294613516217e-05,
      "loss": 0.1596,
      "step": 13780
    },
    {
      "epoch": 2.9554222031718815,
      "grad_norm": 0.031003745272755623,
      "learning_rate": 1.6059437062437494e-05,
      "loss": 0.0003,
      "step": 13790
    },
    {
      "epoch": 2.957565366480926,
      "grad_norm": 0.006844062823802233,
      "learning_rate": 1.6056579511358768e-05,
      "loss": 0.3391,
      "step": 13800
    },
    {
      "epoch": 2.95970852978997,
      "grad_norm": 0.024398554116487503,
      "learning_rate": 1.6053721960280042e-05,
      "loss": 0.0008,
      "step": 13810
    },
    {
      "epoch": 2.961851693099014,
      "grad_norm": 0.0146334795281291,
      "learning_rate": 1.6050864409201316e-05,
      "loss": 0.1884,
      "step": 13820
    },
    {
      "epoch": 2.9639948564080583,
      "grad_norm": 0.020180024206638336,
      "learning_rate": 1.604800685812259e-05,
      "loss": 0.2365,
      "step": 13830
    },
    {
      "epoch": 2.9661380197171026,
      "grad_norm": 0.0704805925488472,
      "learning_rate": 1.6045149307043867e-05,
      "loss": 0.1137,
      "step": 13840
    },
    {
      "epoch": 2.9682811830261464,
      "grad_norm": 1.3442257642745972,
      "learning_rate": 1.6042291755965138e-05,
      "loss": 0.0052,
      "step": 13850
    },
    {
      "epoch": 2.9704243463351907,
      "grad_norm": 0.013253940269351006,
      "learning_rate": 1.603943420488641e-05,
      "loss": 0.2614,
      "step": 13860
    },
    {
      "epoch": 2.972567509644235,
      "grad_norm": 139.152587890625,
      "learning_rate": 1.603657665380769e-05,
      "loss": 0.1174,
      "step": 13870
    },
    {
      "epoch": 2.974710672953279,
      "grad_norm": 0.010617479681968689,
      "learning_rate": 1.6033719102728963e-05,
      "loss": 0.0063,
      "step": 13880
    },
    {
      "epoch": 2.976853836262323,
      "grad_norm": 0.006973594427108765,
      "learning_rate": 1.6030861551650237e-05,
      "loss": 0.0003,
      "step": 13890
    },
    {
      "epoch": 2.9789969995713674,
      "grad_norm": 0.008124135434627533,
      "learning_rate": 1.602800400057151e-05,
      "loss": 0.0007,
      "step": 13900
    },
    {
      "epoch": 2.9811401628804113,
      "grad_norm": 0.008647019974887371,
      "learning_rate": 1.6025146449492785e-05,
      "loss": 0.1953,
      "step": 13910
    },
    {
      "epoch": 2.9832833261894556,
      "grad_norm": 77.47824096679688,
      "learning_rate": 1.602228889841406e-05,
      "loss": 0.2595,
      "step": 13920
    },
    {
      "epoch": 2.9854264894985,
      "grad_norm": 0.014554275199770927,
      "learning_rate": 1.6019431347335336e-05,
      "loss": 0.2529,
      "step": 13930
    },
    {
      "epoch": 2.9875696528075437,
      "grad_norm": 0.0413922443985939,
      "learning_rate": 1.601657379625661e-05,
      "loss": 0.0013,
      "step": 13940
    },
    {
      "epoch": 2.989712816116588,
      "grad_norm": 0.05479617416858673,
      "learning_rate": 1.6013716245177884e-05,
      "loss": 0.0006,
      "step": 13950
    },
    {
      "epoch": 2.9918559794256323,
      "grad_norm": 0.008327888324856758,
      "learning_rate": 1.6010858694099158e-05,
      "loss": 0.0009,
      "step": 13960
    },
    {
      "epoch": 2.993999142734676,
      "grad_norm": 0.05318428575992584,
      "learning_rate": 1.600800114302043e-05,
      "loss": 0.1849,
      "step": 13970
    },
    {
      "epoch": 2.9961423060437204,
      "grad_norm": 0.008726641535758972,
      "learning_rate": 1.600514359194171e-05,
      "loss": 0.1773,
      "step": 13980
    },
    {
      "epoch": 2.9982854693527647,
      "grad_norm": 0.007709023077040911,
      "learning_rate": 1.6002286040862983e-05,
      "loss": 0.0003,
      "step": 13990
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.972,
      "eval_f1": 0.8478260869565217,
      "eval_loss": 0.1951988935470581,
      "eval_precision": 0.9285714285714286,
      "eval_recall": 0.78,
      "eval_runtime": 397.3793,
      "eval_samples_per_second": 7.549,
      "eval_steps_per_second": 2.516,
      "step": 13998
    },
    {
      "epoch": 3.000428632661809,
      "grad_norm": 0.006580533925443888,
      "learning_rate": 1.5999428489784257e-05,
      "loss": 0.0002,
      "step": 14000
    },
    {
      "epoch": 3.002571795970853,
      "grad_norm": 0.006198886316269636,
      "learning_rate": 1.599657093870553e-05,
      "loss": 0.0001,
      "step": 14010
    },
    {
      "epoch": 3.004714959279897,
      "grad_norm": 0.005944513715803623,
      "learning_rate": 1.5993713387626805e-05,
      "loss": 0.0003,
      "step": 14020
    },
    {
      "epoch": 3.0068581225889415,
      "grad_norm": 0.01058115903288126,
      "learning_rate": 1.5990855836548082e-05,
      "loss": 0.2679,
      "step": 14030
    },
    {
      "epoch": 3.0090012858979853,
      "grad_norm": 0.012213011272251606,
      "learning_rate": 1.5987998285469356e-05,
      "loss": 0.0005,
      "step": 14040
    },
    {
      "epoch": 3.0111444492070296,
      "grad_norm": 0.020209860056638718,
      "learning_rate": 1.598514073439063e-05,
      "loss": 0.0006,
      "step": 14050
    },
    {
      "epoch": 3.013287612516074,
      "grad_norm": 0.008480249904096127,
      "learning_rate": 1.5982283183311904e-05,
      "loss": 0.0003,
      "step": 14060
    },
    {
      "epoch": 3.0154307758251178,
      "grad_norm": 0.007826291024684906,
      "learning_rate": 1.5979425632233178e-05,
      "loss": 0.0003,
      "step": 14070
    },
    {
      "epoch": 3.017573939134162,
      "grad_norm": 0.018829671666026115,
      "learning_rate": 1.597656808115445e-05,
      "loss": 0.0002,
      "step": 14080
    },
    {
      "epoch": 3.0197171024432063,
      "grad_norm": 0.04222828149795532,
      "learning_rate": 1.5973710530075726e-05,
      "loss": 0.0003,
      "step": 14090
    },
    {
      "epoch": 3.02186026575225,
      "grad_norm": 0.004573006182909012,
      "learning_rate": 1.5970852978997e-05,
      "loss": 0.0003,
      "step": 14100
    },
    {
      "epoch": 3.0240034290612945,
      "grad_norm": 0.0053915283642709255,
      "learning_rate": 1.5967995427918273e-05,
      "loss": 0.1854,
      "step": 14110
    },
    {
      "epoch": 3.026146592370339,
      "grad_norm": 0.03309759125113487,
      "learning_rate": 1.596513787683955e-05,
      "loss": 0.217,
      "step": 14120
    },
    {
      "epoch": 3.0282897556793826,
      "grad_norm": 0.007620626594871283,
      "learning_rate": 1.5962280325760825e-05,
      "loss": 0.0005,
      "step": 14130
    },
    {
      "epoch": 3.030432918988427,
      "grad_norm": 0.01512065902352333,
      "learning_rate": 1.59594227746821e-05,
      "loss": 0.0001,
      "step": 14140
    },
    {
      "epoch": 3.032576082297471,
      "grad_norm": 0.059573717415332794,
      "learning_rate": 1.5956565223603372e-05,
      "loss": 0.0002,
      "step": 14150
    },
    {
      "epoch": 3.034719245606515,
      "grad_norm": 0.060300830751657486,
      "learning_rate": 1.5953707672524646e-05,
      "loss": 0.1544,
      "step": 14160
    },
    {
      "epoch": 3.0368624089155594,
      "grad_norm": 0.006839219015091658,
      "learning_rate": 1.5950850121445924e-05,
      "loss": 0.2935,
      "step": 14170
    },
    {
      "epoch": 3.0390055722246037,
      "grad_norm": 0.007186786271631718,
      "learning_rate": 1.5947992570367198e-05,
      "loss": 0.0003,
      "step": 14180
    },
    {
      "epoch": 3.0411487355336475,
      "grad_norm": 0.007651112508028746,
      "learning_rate": 1.594513501928847e-05,
      "loss": 0.0002,
      "step": 14190
    },
    {
      "epoch": 3.043291898842692,
      "grad_norm": 0.00655503012239933,
      "learning_rate": 1.5942277468209746e-05,
      "loss": 0.0003,
      "step": 14200
    },
    {
      "epoch": 3.045435062151736,
      "grad_norm": 0.004926891066133976,
      "learning_rate": 1.593941991713102e-05,
      "loss": 0.0001,
      "step": 14210
    },
    {
      "epoch": 3.04757822546078,
      "grad_norm": 0.05193554237484932,
      "learning_rate": 1.5936562366052293e-05,
      "loss": 0.0004,
      "step": 14220
    },
    {
      "epoch": 3.0497213887698242,
      "grad_norm": 0.009185616858303547,
      "learning_rate": 1.593370481497357e-05,
      "loss": 0.253,
      "step": 14230
    },
    {
      "epoch": 3.0518645520788685,
      "grad_norm": 0.056086234748363495,
      "learning_rate": 1.5930847263894845e-05,
      "loss": 0.2803,
      "step": 14240
    },
    {
      "epoch": 3.0540077153879124,
      "grad_norm": 22.244909286499023,
      "learning_rate": 1.592798971281612e-05,
      "loss": 0.1926,
      "step": 14250
    },
    {
      "epoch": 3.0561508786969567,
      "grad_norm": 0.22733256220817566,
      "learning_rate": 1.5925132161737392e-05,
      "loss": 0.0811,
      "step": 14260
    },
    {
      "epoch": 3.058294042006001,
      "grad_norm": 0.09902317076921463,
      "learning_rate": 1.5922274610658666e-05,
      "loss": 0.0021,
      "step": 14270
    },
    {
      "epoch": 3.060437205315045,
      "grad_norm": 0.020617233589291573,
      "learning_rate": 1.591941705957994e-05,
      "loss": 0.0009,
      "step": 14280
    },
    {
      "epoch": 3.062580368624089,
      "grad_norm": 46.90291213989258,
      "learning_rate": 1.5916559508501214e-05,
      "loss": 0.1408,
      "step": 14290
    },
    {
      "epoch": 3.0647235319331334,
      "grad_norm": 0.012368949130177498,
      "learning_rate": 1.5913701957422488e-05,
      "loss": 0.0003,
      "step": 14300
    },
    {
      "epoch": 3.0668666952421773,
      "grad_norm": 0.14774949848651886,
      "learning_rate": 1.5910844406343765e-05,
      "loss": 0.2062,
      "step": 14310
    },
    {
      "epoch": 3.0690098585512215,
      "grad_norm": 0.026902146637439728,
      "learning_rate": 1.590798685526504e-05,
      "loss": 0.0004,
      "step": 14320
    },
    {
      "epoch": 3.071153021860266,
      "grad_norm": 0.0063213747926056385,
      "learning_rate": 1.5905129304186313e-05,
      "loss": 0.0003,
      "step": 14330
    },
    {
      "epoch": 3.0732961851693097,
      "grad_norm": 37.03592300415039,
      "learning_rate": 1.5902271753107587e-05,
      "loss": 0.1666,
      "step": 14340
    },
    {
      "epoch": 3.075439348478354,
      "grad_norm": 0.007439658045768738,
      "learning_rate": 1.589941420202886e-05,
      "loss": 0.3999,
      "step": 14350
    },
    {
      "epoch": 3.0775825117873983,
      "grad_norm": 0.030246993526816368,
      "learning_rate": 1.5896556650950135e-05,
      "loss": 0.2682,
      "step": 14360
    },
    {
      "epoch": 3.0797256750964426,
      "grad_norm": 0.06777939200401306,
      "learning_rate": 1.5893699099871412e-05,
      "loss": 0.001,
      "step": 14370
    },
    {
      "epoch": 3.0818688384054864,
      "grad_norm": 0.02489704079926014,
      "learning_rate": 1.5890841548792686e-05,
      "loss": 0.4463,
      "step": 14380
    },
    {
      "epoch": 3.0840120017145307,
      "grad_norm": 0.02376564033329487,
      "learning_rate": 1.588798399771396e-05,
      "loss": 0.0015,
      "step": 14390
    },
    {
      "epoch": 3.086155165023575,
      "grad_norm": 0.10268056392669678,
      "learning_rate": 1.5885126446635234e-05,
      "loss": 0.1622,
      "step": 14400
    },
    {
      "epoch": 3.088298328332619,
      "grad_norm": 0.015148913487792015,
      "learning_rate": 1.5882268895556508e-05,
      "loss": 0.0011,
      "step": 14410
    },
    {
      "epoch": 3.090441491641663,
      "grad_norm": 0.08075405657291412,
      "learning_rate": 1.5879411344477785e-05,
      "loss": 0.0007,
      "step": 14420
    },
    {
      "epoch": 3.0925846549507074,
      "grad_norm": 0.009045200422406197,
      "learning_rate": 1.587655379339906e-05,
      "loss": 0.1557,
      "step": 14430
    },
    {
      "epoch": 3.0947278182597513,
      "grad_norm": 0.009137325920164585,
      "learning_rate": 1.5873696242320333e-05,
      "loss": 0.3474,
      "step": 14440
    },
    {
      "epoch": 3.0968709815687956,
      "grad_norm": 0.0070757619105279446,
      "learning_rate": 1.5870838691241607e-05,
      "loss": 0.0002,
      "step": 14450
    },
    {
      "epoch": 3.09901414487784,
      "grad_norm": 0.024041689932346344,
      "learning_rate": 1.586798114016288e-05,
      "loss": 0.231,
      "step": 14460
    },
    {
      "epoch": 3.1011573081868837,
      "grad_norm": 1.956339716911316,
      "learning_rate": 1.586512358908416e-05,
      "loss": 0.0026,
      "step": 14470
    },
    {
      "epoch": 3.103300471495928,
      "grad_norm": 0.017761534079909325,
      "learning_rate": 1.5862266038005432e-05,
      "loss": 0.0008,
      "step": 14480
    },
    {
      "epoch": 3.1054436348049723,
      "grad_norm": 0.029416238889098167,
      "learning_rate": 1.5859408486926706e-05,
      "loss": 0.0014,
      "step": 14490
    },
    {
      "epoch": 3.107586798114016,
      "grad_norm": 0.010750388726592064,
      "learning_rate": 1.5856550935847977e-05,
      "loss": 0.0007,
      "step": 14500
    },
    {
      "epoch": 3.1097299614230605,
      "grad_norm": 0.05760008096694946,
      "learning_rate": 1.5853693384769254e-05,
      "loss": 0.1608,
      "step": 14510
    },
    {
      "epoch": 3.1118731247321048,
      "grad_norm": 0.009239325299859047,
      "learning_rate": 1.5850835833690528e-05,
      "loss": 0.0004,
      "step": 14520
    },
    {
      "epoch": 3.1140162880411486,
      "grad_norm": 0.0042006406001746655,
      "learning_rate": 1.5847978282611802e-05,
      "loss": 0.0004,
      "step": 14530
    },
    {
      "epoch": 3.116159451350193,
      "grad_norm": 0.023419717326760292,
      "learning_rate": 1.5845120731533076e-05,
      "loss": 0.0004,
      "step": 14540
    },
    {
      "epoch": 3.118302614659237,
      "grad_norm": 0.005440735723823309,
      "learning_rate": 1.584226318045435e-05,
      "loss": 0.0007,
      "step": 14550
    },
    {
      "epoch": 3.120445777968281,
      "grad_norm": 0.004605013411492109,
      "learning_rate": 1.5839405629375627e-05,
      "loss": 0.0001,
      "step": 14560
    },
    {
      "epoch": 3.1225889412773253,
      "grad_norm": 0.04371681064367294,
      "learning_rate": 1.58365480782969e-05,
      "loss": 0.0002,
      "step": 14570
    },
    {
      "epoch": 3.1247321045863696,
      "grad_norm": 0.020235707983374596,
      "learning_rate": 1.5833690527218175e-05,
      "loss": 0.0004,
      "step": 14580
    },
    {
      "epoch": 3.1268752678954135,
      "grad_norm": 0.004015421494841576,
      "learning_rate": 1.583083297613945e-05,
      "loss": 0.0002,
      "step": 14590
    },
    {
      "epoch": 3.1290184312044578,
      "grad_norm": 0.022728512063622475,
      "learning_rate": 1.5827975425060723e-05,
      "loss": 0.0002,
      "step": 14600
    },
    {
      "epoch": 3.131161594513502,
      "grad_norm": 0.007234697695821524,
      "learning_rate": 1.5825117873982e-05,
      "loss": 0.0002,
      "step": 14610
    },
    {
      "epoch": 3.133304757822546,
      "grad_norm": 0.001727055641822517,
      "learning_rate": 1.5822260322903274e-05,
      "loss": 0.0003,
      "step": 14620
    },
    {
      "epoch": 3.13544792113159,
      "grad_norm": 0.002135276095941663,
      "learning_rate": 1.5819402771824548e-05,
      "loss": 0.0002,
      "step": 14630
    },
    {
      "epoch": 3.1375910844406345,
      "grad_norm": 0.004578228574246168,
      "learning_rate": 1.5816545220745822e-05,
      "loss": 0.0001,
      "step": 14640
    },
    {
      "epoch": 3.1397342477496784,
      "grad_norm": 0.01019602082669735,
      "learning_rate": 1.5813687669667096e-05,
      "loss": 0.0001,
      "step": 14650
    },
    {
      "epoch": 3.1418774110587226,
      "grad_norm": 0.008364218287169933,
      "learning_rate": 1.5810830118588373e-05,
      "loss": 0.1823,
      "step": 14660
    },
    {
      "epoch": 3.144020574367767,
      "grad_norm": 0.0021526941563934088,
      "learning_rate": 1.5807972567509647e-05,
      "loss": 0.2351,
      "step": 14670
    },
    {
      "epoch": 3.146163737676811,
      "grad_norm": 0.12571711838245392,
      "learning_rate": 1.580511501643092e-05,
      "loss": 0.1752,
      "step": 14680
    },
    {
      "epoch": 3.148306900985855,
      "grad_norm": 0.0021762519609183073,
      "learning_rate": 1.5802257465352195e-05,
      "loss": 0.0004,
      "step": 14690
    },
    {
      "epoch": 3.1504500642948994,
      "grad_norm": 0.0036247868556529284,
      "learning_rate": 1.579939991427347e-05,
      "loss": 0.2752,
      "step": 14700
    },
    {
      "epoch": 3.1525932276039432,
      "grad_norm": 0.06403231620788574,
      "learning_rate": 1.5796542363194743e-05,
      "loss": 0.4574,
      "step": 14710
    },
    {
      "epoch": 3.1547363909129875,
      "grad_norm": 0.032603517174720764,
      "learning_rate": 1.5793684812116017e-05,
      "loss": 0.1674,
      "step": 14720
    },
    {
      "epoch": 3.156879554222032,
      "grad_norm": 0.020256567746400833,
      "learning_rate": 1.579082726103729e-05,
      "loss": 0.1621,
      "step": 14730
    },
    {
      "epoch": 3.1590227175310757,
      "grad_norm": 0.1262635588645935,
      "learning_rate": 1.5787969709958565e-05,
      "loss": 0.0013,
      "step": 14740
    },
    {
      "epoch": 3.16116588084012,
      "grad_norm": 0.008107826113700867,
      "learning_rate": 1.5785112158879842e-05,
      "loss": 0.0056,
      "step": 14750
    },
    {
      "epoch": 3.1633090441491643,
      "grad_norm": 0.004097664728760719,
      "learning_rate": 1.5782254607801116e-05,
      "loss": 0.0002,
      "step": 14760
    },
    {
      "epoch": 3.165452207458208,
      "grad_norm": 0.019669881090521812,
      "learning_rate": 1.577939705672239e-05,
      "loss": 0.0006,
      "step": 14770
    },
    {
      "epoch": 3.1675953707672524,
      "grad_norm": 0.01909065805375576,
      "learning_rate": 1.5776539505643664e-05,
      "loss": 0.0007,
      "step": 14780
    },
    {
      "epoch": 3.1697385340762967,
      "grad_norm": 0.028804410248994827,
      "learning_rate": 1.5773681954564938e-05,
      "loss": 0.5091,
      "step": 14790
    },
    {
      "epoch": 3.1718816973853405,
      "grad_norm": 0.025578908622264862,
      "learning_rate": 1.5770824403486215e-05,
      "loss": 0.0006,
      "step": 14800
    },
    {
      "epoch": 3.174024860694385,
      "grad_norm": 0.04258502274751663,
      "learning_rate": 1.576796685240749e-05,
      "loss": 0.0017,
      "step": 14810
    },
    {
      "epoch": 3.176168024003429,
      "grad_norm": 0.04899638146162033,
      "learning_rate": 1.5765109301328763e-05,
      "loss": 0.0009,
      "step": 14820
    },
    {
      "epoch": 3.1783111873124734,
      "grad_norm": 0.025100992992520332,
      "learning_rate": 1.5762251750250037e-05,
      "loss": 0.0005,
      "step": 14830
    },
    {
      "epoch": 3.1804543506215173,
      "grad_norm": 0.009964875876903534,
      "learning_rate": 1.575939419917131e-05,
      "loss": 0.0003,
      "step": 14840
    },
    {
      "epoch": 3.1825975139305616,
      "grad_norm": 0.0067693693563342094,
      "learning_rate": 1.5756536648092585e-05,
      "loss": 0.1612,
      "step": 14850
    },
    {
      "epoch": 3.184740677239606,
      "grad_norm": 0.009427351877093315,
      "learning_rate": 1.5753679097013862e-05,
      "loss": 0.0004,
      "step": 14860
    },
    {
      "epoch": 3.1868838405486497,
      "grad_norm": 0.007223849650472403,
      "learning_rate": 1.5750821545935136e-05,
      "loss": 0.0006,
      "step": 14870
    },
    {
      "epoch": 3.189027003857694,
      "grad_norm": 0.006302654277533293,
      "learning_rate": 1.574796399485641e-05,
      "loss": 0.5642,
      "step": 14880
    },
    {
      "epoch": 3.1911701671667383,
      "grad_norm": 0.015172237530350685,
      "learning_rate": 1.5745106443777684e-05,
      "loss": 0.1778,
      "step": 14890
    },
    {
      "epoch": 3.193313330475782,
      "grad_norm": 0.008809443563222885,
      "learning_rate": 1.5742248892698958e-05,
      "loss": 0.0004,
      "step": 14900
    },
    {
      "epoch": 3.1954564937848264,
      "grad_norm": 0.019461600109934807,
      "learning_rate": 1.5739391341620235e-05,
      "loss": 0.0004,
      "step": 14910
    },
    {
      "epoch": 3.1975996570938707,
      "grad_norm": 0.011933793313801289,
      "learning_rate": 1.573653379054151e-05,
      "loss": 0.0005,
      "step": 14920
    },
    {
      "epoch": 3.1997428204029146,
      "grad_norm": 0.16418692469596863,
      "learning_rate": 1.573367623946278e-05,
      "loss": 0.0005,
      "step": 14930
    },
    {
      "epoch": 3.201885983711959,
      "grad_norm": 0.006117557641118765,
      "learning_rate": 1.5730818688384057e-05,
      "loss": 0.1525,
      "step": 14940
    },
    {
      "epoch": 3.204029147021003,
      "grad_norm": 0.0131929786875844,
      "learning_rate": 1.572796113730533e-05,
      "loss": 0.0013,
      "step": 14950
    },
    {
      "epoch": 3.206172310330047,
      "grad_norm": 0.004980313591659069,
      "learning_rate": 1.5725103586226605e-05,
      "loss": 0.216,
      "step": 14960
    },
    {
      "epoch": 3.2083154736390913,
      "grad_norm": 0.0029241025913506746,
      "learning_rate": 1.572224603514788e-05,
      "loss": 0.0004,
      "step": 14970
    },
    {
      "epoch": 3.2104586369481356,
      "grad_norm": 0.03167662024497986,
      "learning_rate": 1.5719388484069153e-05,
      "loss": 0.2463,
      "step": 14980
    },
    {
      "epoch": 3.2126018002571795,
      "grad_norm": 0.004917739424854517,
      "learning_rate": 1.5716530932990426e-05,
      "loss": 0.0005,
      "step": 14990
    },
    {
      "epoch": 3.2147449635662237,
      "grad_norm": 0.004263001028448343,
      "learning_rate": 1.5713673381911704e-05,
      "loss": 0.0002,
      "step": 15000
    },
    {
      "epoch": 3.216888126875268,
      "grad_norm": 0.007588549051433802,
      "learning_rate": 1.5710815830832978e-05,
      "loss": 0.0003,
      "step": 15010
    },
    {
      "epoch": 3.219031290184312,
      "grad_norm": 0.0028550883289426565,
      "learning_rate": 1.570795827975425e-05,
      "loss": 0.0002,
      "step": 15020
    },
    {
      "epoch": 3.221174453493356,
      "grad_norm": 0.004631069488823414,
      "learning_rate": 1.5705100728675526e-05,
      "loss": 0.1766,
      "step": 15030
    },
    {
      "epoch": 3.2233176168024005,
      "grad_norm": 0.003243929473683238,
      "learning_rate": 1.57022431775968e-05,
      "loss": 0.0002,
      "step": 15040
    },
    {
      "epoch": 3.2254607801114443,
      "grad_norm": 0.022326994687318802,
      "learning_rate": 1.5699385626518077e-05,
      "loss": 0.2528,
      "step": 15050
    },
    {
      "epoch": 3.2276039434204886,
      "grad_norm": 0.026225682348012924,
      "learning_rate": 1.569652807543935e-05,
      "loss": 0.1749,
      "step": 15060
    },
    {
      "epoch": 3.229747106729533,
      "grad_norm": 0.0061811413615942,
      "learning_rate": 1.5693670524360625e-05,
      "loss": 0.2245,
      "step": 15070
    },
    {
      "epoch": 3.2318902700385768,
      "grad_norm": 0.011837998405098915,
      "learning_rate": 1.56908129732819e-05,
      "loss": 0.0011,
      "step": 15080
    },
    {
      "epoch": 3.234033433347621,
      "grad_norm": 0.031024478375911713,
      "learning_rate": 1.5687955422203173e-05,
      "loss": 0.2955,
      "step": 15090
    },
    {
      "epoch": 3.2361765966566653,
      "grad_norm": 0.00501857278868556,
      "learning_rate": 1.568509787112445e-05,
      "loss": 0.0003,
      "step": 15100
    },
    {
      "epoch": 3.238319759965709,
      "grad_norm": 0.029660841450095177,
      "learning_rate": 1.5682240320045724e-05,
      "loss": 0.0002,
      "step": 15110
    },
    {
      "epoch": 3.2404629232747535,
      "grad_norm": 0.0023116031661629677,
      "learning_rate": 1.5679382768966998e-05,
      "loss": 0.001,
      "step": 15120
    },
    {
      "epoch": 3.242606086583798,
      "grad_norm": 0.0073316083289682865,
      "learning_rate": 1.567652521788827e-05,
      "loss": 0.0003,
      "step": 15130
    },
    {
      "epoch": 3.2447492498928416,
      "grad_norm": 0.009517810307443142,
      "learning_rate": 1.5673667666809546e-05,
      "loss": 0.0008,
      "step": 15140
    },
    {
      "epoch": 3.246892413201886,
      "grad_norm": 0.001854944508522749,
      "learning_rate": 1.567081011573082e-05,
      "loss": 0.2448,
      "step": 15150
    },
    {
      "epoch": 3.2490355765109302,
      "grad_norm": 0.0031004883348941803,
      "learning_rate": 1.5667952564652093e-05,
      "loss": 0.0002,
      "step": 15160
    },
    {
      "epoch": 3.2511787398199745,
      "grad_norm": 0.0029905245173722506,
      "learning_rate": 1.5665095013573367e-05,
      "loss": 0.0005,
      "step": 15170
    },
    {
      "epoch": 3.2533219031290184,
      "grad_norm": 0.03797268867492676,
      "learning_rate": 1.566223746249464e-05,
      "loss": 0.0001,
      "step": 15180
    },
    {
      "epoch": 3.2554650664380627,
      "grad_norm": 0.0066974228248000145,
      "learning_rate": 1.565937991141592e-05,
      "loss": 0.0055,
      "step": 15190
    },
    {
      "epoch": 3.257608229747107,
      "grad_norm": 0.034416597336530685,
      "learning_rate": 1.5656522360337193e-05,
      "loss": 0.3089,
      "step": 15200
    },
    {
      "epoch": 3.259751393056151,
      "grad_norm": 0.04139174893498421,
      "learning_rate": 1.5653664809258466e-05,
      "loss": 0.2088,
      "step": 15210
    },
    {
      "epoch": 3.261894556365195,
      "grad_norm": 0.013989911414682865,
      "learning_rate": 1.565080725817974e-05,
      "loss": 0.0007,
      "step": 15220
    },
    {
      "epoch": 3.2640377196742394,
      "grad_norm": 0.06502178311347961,
      "learning_rate": 1.5647949707101014e-05,
      "loss": 0.0013,
      "step": 15230
    },
    {
      "epoch": 3.2661808829832832,
      "grad_norm": 0.04881155490875244,
      "learning_rate": 1.564509215602229e-05,
      "loss": 0.1852,
      "step": 15240
    },
    {
      "epoch": 3.2683240462923275,
      "grad_norm": 0.008469667285680771,
      "learning_rate": 1.5642234604943566e-05,
      "loss": 0.0003,
      "step": 15250
    },
    {
      "epoch": 3.270467209601372,
      "grad_norm": 0.008124317973852158,
      "learning_rate": 1.563937705386484e-05,
      "loss": 0.201,
      "step": 15260
    },
    {
      "epoch": 3.2726103729104157,
      "grad_norm": 0.007960118353366852,
      "learning_rate": 1.5636519502786113e-05,
      "loss": 0.0009,
      "step": 15270
    },
    {
      "epoch": 3.27475353621946,
      "grad_norm": 0.004238484892994165,
      "learning_rate": 1.5633661951707387e-05,
      "loss": 0.1833,
      "step": 15280
    },
    {
      "epoch": 3.2768966995285043,
      "grad_norm": 0.005651871673762798,
      "learning_rate": 1.5630804400628665e-05,
      "loss": 0.0017,
      "step": 15290
    },
    {
      "epoch": 3.279039862837548,
      "grad_norm": 0.007819541729986668,
      "learning_rate": 1.562794684954994e-05,
      "loss": 0.0019,
      "step": 15300
    },
    {
      "epoch": 3.2811830261465924,
      "grad_norm": 0.04217741638422012,
      "learning_rate": 1.5625089298471213e-05,
      "loss": 0.0005,
      "step": 15310
    },
    {
      "epoch": 3.2833261894556367,
      "grad_norm": 0.026265308260917664,
      "learning_rate": 1.5622231747392486e-05,
      "loss": 0.1677,
      "step": 15320
    },
    {
      "epoch": 3.2854693527646806,
      "grad_norm": 0.0019824106711894274,
      "learning_rate": 1.561937419631376e-05,
      "loss": 0.2179,
      "step": 15330
    },
    {
      "epoch": 3.287612516073725,
      "grad_norm": 0.5053310990333557,
      "learning_rate": 1.5616516645235034e-05,
      "loss": 0.5456,
      "step": 15340
    },
    {
      "epoch": 3.289755679382769,
      "grad_norm": 0.00437722634524107,
      "learning_rate": 1.561365909415631e-05,
      "loss": 0.0012,
      "step": 15350
    },
    {
      "epoch": 3.291898842691813,
      "grad_norm": 0.10810655355453491,
      "learning_rate": 1.5610801543077582e-05,
      "loss": 0.0015,
      "step": 15360
    },
    {
      "epoch": 3.2940420060008573,
      "grad_norm": 0.0034861702006310225,
      "learning_rate": 1.5607943991998856e-05,
      "loss": 0.0007,
      "step": 15370
    },
    {
      "epoch": 3.2961851693099016,
      "grad_norm": 0.0022319573909044266,
      "learning_rate": 1.5605086440920133e-05,
      "loss": 0.0005,
      "step": 15380
    },
    {
      "epoch": 3.2983283326189454,
      "grad_norm": 0.013808716088533401,
      "learning_rate": 1.5602228889841407e-05,
      "loss": 0.1966,
      "step": 15390
    },
    {
      "epoch": 3.3004714959279897,
      "grad_norm": 0.002212585648521781,
      "learning_rate": 1.559937133876268e-05,
      "loss": 0.1631,
      "step": 15400
    },
    {
      "epoch": 3.302614659237034,
      "grad_norm": 31.906949996948242,
      "learning_rate": 1.5596513787683955e-05,
      "loss": 0.1096,
      "step": 15410
    },
    {
      "epoch": 3.304757822546078,
      "grad_norm": 0.05653080344200134,
      "learning_rate": 1.559365623660523e-05,
      "loss": 0.0013,
      "step": 15420
    },
    {
      "epoch": 3.306900985855122,
      "grad_norm": 0.0006115668220445514,
      "learning_rate": 1.5590798685526506e-05,
      "loss": 0.2219,
      "step": 15430
    },
    {
      "epoch": 3.3090441491641664,
      "grad_norm": 0.002288638614118099,
      "learning_rate": 1.558794113444778e-05,
      "loss": 0.3789,
      "step": 15440
    },
    {
      "epoch": 3.3111873124732103,
      "grad_norm": 0.007797709200531244,
      "learning_rate": 1.5585083583369054e-05,
      "loss": 0.0277,
      "step": 15450
    },
    {
      "epoch": 3.3133304757822546,
      "grad_norm": 0.005260628182440996,
      "learning_rate": 1.5582226032290328e-05,
      "loss": 0.2099,
      "step": 15460
    },
    {
      "epoch": 3.315473639091299,
      "grad_norm": 0.004069768823683262,
      "learning_rate": 1.5579368481211602e-05,
      "loss": 0.1889,
      "step": 15470
    },
    {
      "epoch": 3.3176168024003427,
      "grad_norm": 0.04570974037051201,
      "learning_rate": 1.5576510930132876e-05,
      "loss": 0.0008,
      "step": 15480
    },
    {
      "epoch": 3.319759965709387,
      "grad_norm": 0.048177413642406464,
      "learning_rate": 1.5573653379054153e-05,
      "loss": 0.1948,
      "step": 15490
    },
    {
      "epoch": 3.3219031290184313,
      "grad_norm": 0.003121475223451853,
      "learning_rate": 1.5570795827975427e-05,
      "loss": 0.0005,
      "step": 15500
    },
    {
      "epoch": 3.324046292327475,
      "grad_norm": 0.0795358419418335,
      "learning_rate": 1.55679382768967e-05,
      "loss": 0.2701,
      "step": 15510
    },
    {
      "epoch": 3.3261894556365195,
      "grad_norm": 0.0056285560131073,
      "learning_rate": 1.5565080725817975e-05,
      "loss": 0.0018,
      "step": 15520
    },
    {
      "epoch": 3.3283326189455638,
      "grad_norm": 0.05977700278162956,
      "learning_rate": 1.556222317473925e-05,
      "loss": 0.3181,
      "step": 15530
    },
    {
      "epoch": 3.3304757822546076,
      "grad_norm": 0.003885486861690879,
      "learning_rate": 1.5559365623660526e-05,
      "loss": 0.0006,
      "step": 15540
    },
    {
      "epoch": 3.332618945563652,
      "grad_norm": 0.004967580083757639,
      "learning_rate": 1.55565080725818e-05,
      "loss": 0.4077,
      "step": 15550
    },
    {
      "epoch": 3.334762108872696,
      "grad_norm": 0.007562594022601843,
      "learning_rate": 1.5553650521503074e-05,
      "loss": 0.0005,
      "step": 15560
    },
    {
      "epoch": 3.33690527218174,
      "grad_norm": 0.011663815937936306,
      "learning_rate": 1.5550792970424348e-05,
      "loss": 0.0004,
      "step": 15570
    },
    {
      "epoch": 3.3390484354907843,
      "grad_norm": 0.007694569882005453,
      "learning_rate": 1.5547935419345622e-05,
      "loss": 0.1743,
      "step": 15580
    },
    {
      "epoch": 3.3411915987998286,
      "grad_norm": 0.01441169809550047,
      "learning_rate": 1.5545077868266896e-05,
      "loss": 0.0019,
      "step": 15590
    },
    {
      "epoch": 3.3433347621088725,
      "grad_norm": 0.17315463721752167,
      "learning_rate": 1.554222031718817e-05,
      "loss": 0.0008,
      "step": 15600
    },
    {
      "epoch": 3.3454779254179168,
      "grad_norm": 0.004034451209008694,
      "learning_rate": 1.5539362766109444e-05,
      "loss": 0.1903,
      "step": 15610
    },
    {
      "epoch": 3.347621088726961,
      "grad_norm": 0.0030249350238591433,
      "learning_rate": 1.5536505215030718e-05,
      "loss": 0.3533,
      "step": 15620
    },
    {
      "epoch": 3.349764252036005,
      "grad_norm": 0.03395070880651474,
      "learning_rate": 1.5533647663951995e-05,
      "loss": 0.0009,
      "step": 15630
    },
    {
      "epoch": 3.351907415345049,
      "grad_norm": 0.029002651572227478,
      "learning_rate": 1.553079011287327e-05,
      "loss": 0.0021,
      "step": 15640
    },
    {
      "epoch": 3.3540505786540935,
      "grad_norm": 0.0019297089893370867,
      "learning_rate": 1.5527932561794543e-05,
      "loss": 0.0014,
      "step": 15650
    },
    {
      "epoch": 3.3561937419631374,
      "grad_norm": 0.0012478550197556615,
      "learning_rate": 1.5525075010715817e-05,
      "loss": 0.0005,
      "step": 15660
    },
    {
      "epoch": 3.3583369052721816,
      "grad_norm": 0.01116783358156681,
      "learning_rate": 1.552221745963709e-05,
      "loss": 0.0011,
      "step": 15670
    },
    {
      "epoch": 3.360480068581226,
      "grad_norm": 0.000672582071274519,
      "learning_rate": 1.5519359908558368e-05,
      "loss": 0.0002,
      "step": 15680
    },
    {
      "epoch": 3.36262323189027,
      "grad_norm": 0.0005678528686985373,
      "learning_rate": 1.5516502357479642e-05,
      "loss": 0.0,
      "step": 15690
    },
    {
      "epoch": 3.364766395199314,
      "grad_norm": 0.004510152153670788,
      "learning_rate": 1.5513644806400916e-05,
      "loss": 0.0001,
      "step": 15700
    },
    {
      "epoch": 3.3669095585083584,
      "grad_norm": 0.0003241050580982119,
      "learning_rate": 1.551078725532219e-05,
      "loss": 0.0,
      "step": 15710
    },
    {
      "epoch": 3.3690527218174027,
      "grad_norm": 0.0003541378246154636,
      "learning_rate": 1.5507929704243464e-05,
      "loss": 0.0,
      "step": 15720
    },
    {
      "epoch": 3.3711958851264465,
      "grad_norm": 0.0006425127503462136,
      "learning_rate": 1.550507215316474e-05,
      "loss": 0.0001,
      "step": 15730
    },
    {
      "epoch": 3.373339048435491,
      "grad_norm": 0.0005555890966206789,
      "learning_rate": 1.5502214602086015e-05,
      "loss": 0.1651,
      "step": 15740
    },
    {
      "epoch": 3.375482211744535,
      "grad_norm": 0.005391369108110666,
      "learning_rate": 1.549935705100729e-05,
      "loss": 0.0001,
      "step": 15750
    },
    {
      "epoch": 3.377625375053579,
      "grad_norm": 0.003358714282512665,
      "learning_rate": 1.5496499499928563e-05,
      "loss": 0.0,
      "step": 15760
    },
    {
      "epoch": 3.3797685383626233,
      "grad_norm": 0.0005658845766447484,
      "learning_rate": 1.5493641948849837e-05,
      "loss": 0.312,
      "step": 15770
    },
    {
      "epoch": 3.3819117016716675,
      "grad_norm": 0.02737298607826233,
      "learning_rate": 1.549078439777111e-05,
      "loss": 0.1985,
      "step": 15780
    },
    {
      "epoch": 3.3840548649807114,
      "grad_norm": 0.004472615197300911,
      "learning_rate": 1.5487926846692385e-05,
      "loss": 0.0001,
      "step": 15790
    },
    {
      "epoch": 3.3861980282897557,
      "grad_norm": 0.0026352277491241693,
      "learning_rate": 1.548506929561366e-05,
      "loss": 0.3935,
      "step": 15800
    },
    {
      "epoch": 3.3883411915988,
      "grad_norm": 0.0017665470950305462,
      "learning_rate": 1.5482211744534933e-05,
      "loss": 0.002,
      "step": 15810
    },
    {
      "epoch": 3.390484354907844,
      "grad_norm": 0.0015966322971507907,
      "learning_rate": 1.547935419345621e-05,
      "loss": 0.0003,
      "step": 15820
    },
    {
      "epoch": 3.392627518216888,
      "grad_norm": 0.01556896697729826,
      "learning_rate": 1.5476496642377484e-05,
      "loss": 0.405,
      "step": 15830
    },
    {
      "epoch": 3.3947706815259324,
      "grad_norm": 0.4649257957935333,
      "learning_rate": 1.5473639091298758e-05,
      "loss": 0.002,
      "step": 15840
    },
    {
      "epoch": 3.3969138448349763,
      "grad_norm": 0.002809137338772416,
      "learning_rate": 1.5470781540220032e-05,
      "loss": 0.0012,
      "step": 15850
    },
    {
      "epoch": 3.3990570081440206,
      "grad_norm": 0.0022110736463218927,
      "learning_rate": 1.5467923989141306e-05,
      "loss": 0.3537,
      "step": 15860
    },
    {
      "epoch": 3.401200171453065,
      "grad_norm": 0.0015917287673801184,
      "learning_rate": 1.5465066438062583e-05,
      "loss": 0.0097,
      "step": 15870
    },
    {
      "epoch": 3.4033433347621087,
      "grad_norm": 44.000823974609375,
      "learning_rate": 1.5462208886983857e-05,
      "loss": 0.2489,
      "step": 15880
    },
    {
      "epoch": 3.405486498071153,
      "grad_norm": 0.3229096829891205,
      "learning_rate": 1.545935133590513e-05,
      "loss": 0.0895,
      "step": 15890
    },
    {
      "epoch": 3.4076296613801973,
      "grad_norm": 0.0029626316390931606,
      "learning_rate": 1.5456493784826405e-05,
      "loss": 0.0001,
      "step": 15900
    },
    {
      "epoch": 3.409772824689241,
      "grad_norm": 0.05175517871975899,
      "learning_rate": 1.545363623374768e-05,
      "loss": 0.0008,
      "step": 15910
    },
    {
      "epoch": 3.4119159879982854,
      "grad_norm": 0.0012901329901069403,
      "learning_rate": 1.5450778682668953e-05,
      "loss": 0.1119,
      "step": 15920
    },
    {
      "epoch": 3.4140591513073297,
      "grad_norm": 0.0020110122859477997,
      "learning_rate": 1.544792113159023e-05,
      "loss": 0.0026,
      "step": 15930
    },
    {
      "epoch": 3.4162023146163736,
      "grad_norm": 0.0015190219273790717,
      "learning_rate": 1.5445063580511504e-05,
      "loss": 0.1012,
      "step": 15940
    },
    {
      "epoch": 3.418345477925418,
      "grad_norm": 0.002474651439115405,
      "learning_rate": 1.5442206029432778e-05,
      "loss": 0.2846,
      "step": 15950
    },
    {
      "epoch": 3.420488641234462,
      "grad_norm": 0.42990127205848694,
      "learning_rate": 1.5439348478354052e-05,
      "loss": 0.3197,
      "step": 15960
    },
    {
      "epoch": 3.4226318045435065,
      "grad_norm": 0.013916388154029846,
      "learning_rate": 1.5436490927275326e-05,
      "loss": 0.263,
      "step": 15970
    },
    {
      "epoch": 3.4247749678525503,
      "grad_norm": 0.0028610818553715944,
      "learning_rate": 1.5433633376196603e-05,
      "loss": 0.0002,
      "step": 15980
    },
    {
      "epoch": 3.4269181311615946,
      "grad_norm": 0.0016970422584563494,
      "learning_rate": 1.5430775825117877e-05,
      "loss": 0.0005,
      "step": 15990
    },
    {
      "epoch": 3.429061294470639,
      "grad_norm": 0.13213706016540527,
      "learning_rate": 1.5427918274039147e-05,
      "loss": 0.0998,
      "step": 16000
    },
    {
      "epoch": 3.4312044577796827,
      "grad_norm": 0.003970013465732336,
      "learning_rate": 1.5425060722960425e-05,
      "loss": 0.0001,
      "step": 16010
    },
    {
      "epoch": 3.433347621088727,
      "grad_norm": 0.001044139382429421,
      "learning_rate": 1.54222031718817e-05,
      "loss": 0.1003,
      "step": 16020
    },
    {
      "epoch": 3.4354907843977713,
      "grad_norm": 0.0014216325944289565,
      "learning_rate": 1.5419345620802973e-05,
      "loss": 0.0,
      "step": 16030
    },
    {
      "epoch": 3.437633947706815,
      "grad_norm": 0.002310323528945446,
      "learning_rate": 1.5416488069724247e-05,
      "loss": 0.0063,
      "step": 16040
    },
    {
      "epoch": 3.4397771110158595,
      "grad_norm": 0.014773165807127953,
      "learning_rate": 1.541363051864552e-05,
      "loss": 0.2393,
      "step": 16050
    },
    {
      "epoch": 3.4419202743249038,
      "grad_norm": 0.004263024311512709,
      "learning_rate": 1.5410772967566794e-05,
      "loss": 0.0002,
      "step": 16060
    },
    {
      "epoch": 3.4440634376339476,
      "grad_norm": 0.0036996693816035986,
      "learning_rate": 1.5407915416488072e-05,
      "loss": 0.2284,
      "step": 16070
    },
    {
      "epoch": 3.446206600942992,
      "grad_norm": 0.14440050721168518,
      "learning_rate": 1.5405057865409346e-05,
      "loss": 0.1745,
      "step": 16080
    },
    {
      "epoch": 3.448349764252036,
      "grad_norm": 0.0030681367497891188,
      "learning_rate": 1.540220031433062e-05,
      "loss": 0.0008,
      "step": 16090
    },
    {
      "epoch": 3.45049292756108,
      "grad_norm": 0.0016394134145230055,
      "learning_rate": 1.5399342763251894e-05,
      "loss": 0.0003,
      "step": 16100
    },
    {
      "epoch": 3.4526360908701244,
      "grad_norm": 0.0009161278139799833,
      "learning_rate": 1.5396485212173167e-05,
      "loss": 0.0006,
      "step": 16110
    },
    {
      "epoch": 3.4547792541791686,
      "grad_norm": 0.002314532408490777,
      "learning_rate": 1.5393627661094445e-05,
      "loss": 0.1252,
      "step": 16120
    },
    {
      "epoch": 3.4569224174882125,
      "grad_norm": 0.0012566728983074427,
      "learning_rate": 1.539077011001572e-05,
      "loss": 0.2722,
      "step": 16130
    },
    {
      "epoch": 3.459065580797257,
      "grad_norm": 0.012966740876436234,
      "learning_rate": 1.5387912558936993e-05,
      "loss": 0.0002,
      "step": 16140
    },
    {
      "epoch": 3.461208744106301,
      "grad_norm": 17.474422454833984,
      "learning_rate": 1.5385055007858267e-05,
      "loss": 0.2331,
      "step": 16150
    },
    {
      "epoch": 3.463351907415345,
      "grad_norm": 18.3200740814209,
      "learning_rate": 1.538219745677954e-05,
      "loss": 0.1845,
      "step": 16160
    },
    {
      "epoch": 3.4654950707243892,
      "grad_norm": 0.010385269299149513,
      "learning_rate": 1.5379339905700818e-05,
      "loss": 0.0007,
      "step": 16170
    },
    {
      "epoch": 3.4676382340334335,
      "grad_norm": 0.019381653517484665,
      "learning_rate": 1.5376482354622092e-05,
      "loss": 0.0006,
      "step": 16180
    },
    {
      "epoch": 3.4697813973424774,
      "grad_norm": 0.01741066202521324,
      "learning_rate": 1.5373624803543366e-05,
      "loss": 0.0009,
      "step": 16190
    },
    {
      "epoch": 3.4719245606515217,
      "grad_norm": 0.0020613300148397684,
      "learning_rate": 1.537076725246464e-05,
      "loss": 0.1129,
      "step": 16200
    },
    {
      "epoch": 3.474067723960566,
      "grad_norm": 0.0016969904536381364,
      "learning_rate": 1.5367909701385914e-05,
      "loss": 0.0004,
      "step": 16210
    },
    {
      "epoch": 3.47621088726961,
      "grad_norm": 0.02066432312130928,
      "learning_rate": 1.5365052150307187e-05,
      "loss": 0.0001,
      "step": 16220
    },
    {
      "epoch": 3.478354050578654,
      "grad_norm": 0.0014708316884934902,
      "learning_rate": 1.536219459922846e-05,
      "loss": 0.1849,
      "step": 16230
    },
    {
      "epoch": 3.4804972138876984,
      "grad_norm": 0.021372662857174873,
      "learning_rate": 1.5359337048149735e-05,
      "loss": 0.2463,
      "step": 16240
    },
    {
      "epoch": 3.4826403771967422,
      "grad_norm": 0.041266147047281265,
      "learning_rate": 1.535647949707101e-05,
      "loss": 0.0009,
      "step": 16250
    },
    {
      "epoch": 3.4847835405057865,
      "grad_norm": 0.03262826427817345,
      "learning_rate": 1.5353621945992287e-05,
      "loss": 0.2047,
      "step": 16260
    },
    {
      "epoch": 3.486926703814831,
      "grad_norm": 0.026005344465374947,
      "learning_rate": 1.535076439491356e-05,
      "loss": 0.0006,
      "step": 16270
    },
    {
      "epoch": 3.4890698671238747,
      "grad_norm": 0.008149826899170876,
      "learning_rate": 1.5347906843834834e-05,
      "loss": 0.0005,
      "step": 16280
    },
    {
      "epoch": 3.491213030432919,
      "grad_norm": 0.005793106742203236,
      "learning_rate": 1.534504929275611e-05,
      "loss": 0.0003,
      "step": 16290
    },
    {
      "epoch": 3.4933561937419633,
      "grad_norm": 0.023645469918847084,
      "learning_rate": 1.5342191741677382e-05,
      "loss": 0.1807,
      "step": 16300
    },
    {
      "epoch": 3.495499357051007,
      "grad_norm": 0.0022131756413728,
      "learning_rate": 1.533933419059866e-05,
      "loss": 0.0008,
      "step": 16310
    },
    {
      "epoch": 3.4976425203600514,
      "grad_norm": 0.002386049134656787,
      "learning_rate": 1.5336476639519933e-05,
      "loss": 0.0007,
      "step": 16320
    },
    {
      "epoch": 3.4997856836690957,
      "grad_norm": 0.005822769366204739,
      "learning_rate": 1.5333619088441207e-05,
      "loss": 0.263,
      "step": 16330
    },
    {
      "epoch": 3.5019288469781396,
      "grad_norm": 0.012828981503844261,
      "learning_rate": 1.533076153736248e-05,
      "loss": 0.1388,
      "step": 16340
    },
    {
      "epoch": 3.504072010287184,
      "grad_norm": 0.01046717818826437,
      "learning_rate": 1.5327903986283755e-05,
      "loss": 0.0003,
      "step": 16350
    },
    {
      "epoch": 3.506215173596228,
      "grad_norm": 0.0018024418968707323,
      "learning_rate": 1.5325046435205033e-05,
      "loss": 0.2106,
      "step": 16360
    },
    {
      "epoch": 3.508358336905272,
      "grad_norm": 0.0029712363611906767,
      "learning_rate": 1.5322188884126307e-05,
      "loss": 0.0001,
      "step": 16370
    },
    {
      "epoch": 3.5105015002143163,
      "grad_norm": 0.011407099664211273,
      "learning_rate": 1.531933133304758e-05,
      "loss": 0.0004,
      "step": 16380
    },
    {
      "epoch": 3.5126446635233606,
      "grad_norm": 0.002622199011966586,
      "learning_rate": 1.5316473781968854e-05,
      "loss": 0.0002,
      "step": 16390
    },
    {
      "epoch": 3.5147878268324044,
      "grad_norm": 0.0026766848750412464,
      "learning_rate": 1.531361623089013e-05,
      "loss": 0.4091,
      "step": 16400
    },
    {
      "epoch": 3.5169309901414487,
      "grad_norm": 0.17283307015895844,
      "learning_rate": 1.5310758679811402e-05,
      "loss": 0.3598,
      "step": 16410
    },
    {
      "epoch": 3.519074153450493,
      "grad_norm": 0.12026450037956238,
      "learning_rate": 1.530790112873268e-05,
      "loss": 0.0011,
      "step": 16420
    },
    {
      "epoch": 3.521217316759537,
      "grad_norm": 0.009427797980606556,
      "learning_rate": 1.530504357765395e-05,
      "loss": 0.0009,
      "step": 16430
    },
    {
      "epoch": 3.523360480068581,
      "grad_norm": 0.07920278608798981,
      "learning_rate": 1.5302186026575224e-05,
      "loss": 0.0005,
      "step": 16440
    },
    {
      "epoch": 3.5255036433776255,
      "grad_norm": 0.000474403437692672,
      "learning_rate": 1.52993284754965e-05,
      "loss": 0.0002,
      "step": 16450
    },
    {
      "epoch": 3.5276468066866693,
      "grad_norm": 0.0011965753510594368,
      "learning_rate": 1.5296470924417775e-05,
      "loss": 0.0002,
      "step": 16460
    },
    {
      "epoch": 3.5297899699957136,
      "grad_norm": 0.0009848920162767172,
      "learning_rate": 1.529361337333905e-05,
      "loss": 0.1773,
      "step": 16470
    },
    {
      "epoch": 3.531933133304758,
      "grad_norm": 0.0008078545797616243,
      "learning_rate": 1.5290755822260323e-05,
      "loss": 0.0,
      "step": 16480
    },
    {
      "epoch": 3.5340762966138017,
      "grad_norm": 0.0010249479673802853,
      "learning_rate": 1.5287898271181597e-05,
      "loss": 0.0005,
      "step": 16490
    },
    {
      "epoch": 3.536219459922846,
      "grad_norm": 0.00314163975417614,
      "learning_rate": 1.5285040720102874e-05,
      "loss": 0.0004,
      "step": 16500
    },
    {
      "epoch": 3.5383626232318903,
      "grad_norm": 0.0008271362748928368,
      "learning_rate": 1.5282183169024148e-05,
      "loss": 0.0002,
      "step": 16510
    },
    {
      "epoch": 3.540505786540934,
      "grad_norm": 0.0010322605958208442,
      "learning_rate": 1.5279325617945422e-05,
      "loss": 0.2311,
      "step": 16520
    },
    {
      "epoch": 3.5426489498499785,
      "grad_norm": 0.0012056289706379175,
      "learning_rate": 1.5276468066866696e-05,
      "loss": 0.5241,
      "step": 16530
    },
    {
      "epoch": 3.5447921131590228,
      "grad_norm": 0.011404106393456459,
      "learning_rate": 1.527361051578797e-05,
      "loss": 0.0005,
      "step": 16540
    },
    {
      "epoch": 3.5469352764680666,
      "grad_norm": 0.11369972676038742,
      "learning_rate": 1.5270752964709244e-05,
      "loss": 0.0036,
      "step": 16550
    },
    {
      "epoch": 3.549078439777111,
      "grad_norm": 0.0014107312308624387,
      "learning_rate": 1.526789541363052e-05,
      "loss": 0.0005,
      "step": 16560
    },
    {
      "epoch": 3.551221603086155,
      "grad_norm": 0.0416540801525116,
      "learning_rate": 1.5265037862551795e-05,
      "loss": 0.0007,
      "step": 16570
    },
    {
      "epoch": 3.553364766395199,
      "grad_norm": 0.0002728699764702469,
      "learning_rate": 1.526218031147307e-05,
      "loss": 0.0002,
      "step": 16580
    },
    {
      "epoch": 3.5555079297042433,
      "grad_norm": 0.0014315147418528795,
      "learning_rate": 1.5259322760394343e-05,
      "loss": 0.2062,
      "step": 16590
    },
    {
      "epoch": 3.5576510930132876,
      "grad_norm": 0.018423307687044144,
      "learning_rate": 1.5256465209315619e-05,
      "loss": 0.0003,
      "step": 16600
    },
    {
      "epoch": 3.5597942563223315,
      "grad_norm": 0.002444958547130227,
      "learning_rate": 1.5253607658236893e-05,
      "loss": 0.0002,
      "step": 16610
    },
    {
      "epoch": 3.561937419631376,
      "grad_norm": 0.04373396188020706,
      "learning_rate": 1.5250750107158168e-05,
      "loss": 0.3268,
      "step": 16620
    },
    {
      "epoch": 3.56408058294042,
      "grad_norm": 0.0002884603454731405,
      "learning_rate": 1.5247892556079442e-05,
      "loss": 0.2275,
      "step": 16630
    },
    {
      "epoch": 3.5662237462494644,
      "grad_norm": 0.008513330481946468,
      "learning_rate": 1.5245035005000714e-05,
      "loss": 0.0007,
      "step": 16640
    },
    {
      "epoch": 3.568366909558508,
      "grad_norm": 0.008036830462515354,
      "learning_rate": 1.5242177453921988e-05,
      "loss": 0.0002,
      "step": 16650
    },
    {
      "epoch": 3.5705100728675525,
      "grad_norm": 0.0005720585468225181,
      "learning_rate": 1.5239319902843264e-05,
      "loss": 0.0004,
      "step": 16660
    },
    {
      "epoch": 3.572653236176597,
      "grad_norm": 0.002355011645704508,
      "learning_rate": 1.5236462351764538e-05,
      "loss": 0.0005,
      "step": 16670
    },
    {
      "epoch": 3.5747963994856407,
      "grad_norm": 0.04820845648646355,
      "learning_rate": 1.5233604800685814e-05,
      "loss": 0.0003,
      "step": 16680
    },
    {
      "epoch": 3.576939562794685,
      "grad_norm": 16.351957321166992,
      "learning_rate": 1.5230747249607087e-05,
      "loss": 0.2052,
      "step": 16690
    },
    {
      "epoch": 3.5790827261037292,
      "grad_norm": 0.0005120402202010155,
      "learning_rate": 1.5227889698528361e-05,
      "loss": 0.0617,
      "step": 16700
    },
    {
      "epoch": 3.581225889412773,
      "grad_norm": 0.0019608871079981327,
      "learning_rate": 1.5225032147449637e-05,
      "loss": 0.0002,
      "step": 16710
    },
    {
      "epoch": 3.5833690527218174,
      "grad_norm": 0.14336873590946198,
      "learning_rate": 1.5222174596370911e-05,
      "loss": 0.1621,
      "step": 16720
    },
    {
      "epoch": 3.5855122160308617,
      "grad_norm": 0.10121986269950867,
      "learning_rate": 1.5219317045292185e-05,
      "loss": 0.0044,
      "step": 16730
    },
    {
      "epoch": 3.587655379339906,
      "grad_norm": 24.391963958740234,
      "learning_rate": 1.521645949421346e-05,
      "loss": 0.2198,
      "step": 16740
    },
    {
      "epoch": 3.58979854264895,
      "grad_norm": 17.349027633666992,
      "learning_rate": 1.5213601943134734e-05,
      "loss": 0.3934,
      "step": 16750
    },
    {
      "epoch": 3.591941705957994,
      "grad_norm": 0.0005020922981202602,
      "learning_rate": 1.521074439205601e-05,
      "loss": 0.1674,
      "step": 16760
    },
    {
      "epoch": 3.5940848692670384,
      "grad_norm": 0.00028339994605630636,
      "learning_rate": 1.5207886840977284e-05,
      "loss": 0.0,
      "step": 16770
    },
    {
      "epoch": 3.5962280325760823,
      "grad_norm": 0.048211719840765,
      "learning_rate": 1.5205029289898558e-05,
      "loss": 0.0012,
      "step": 16780
    },
    {
      "epoch": 3.5983711958851265,
      "grad_norm": 0.0001539559889351949,
      "learning_rate": 1.5202171738819834e-05,
      "loss": 0.0011,
      "step": 16790
    },
    {
      "epoch": 3.600514359194171,
      "grad_norm": 0.03354864567518234,
      "learning_rate": 1.5199314187741107e-05,
      "loss": 0.0005,
      "step": 16800
    },
    {
      "epoch": 3.6026575225032147,
      "grad_norm": 0.00021632233983837068,
      "learning_rate": 1.5196456636662383e-05,
      "loss": 0.4709,
      "step": 16810
    },
    {
      "epoch": 3.604800685812259,
      "grad_norm": 0.0017587218899279833,
      "learning_rate": 1.5193599085583657e-05,
      "loss": 0.0006,
      "step": 16820
    },
    {
      "epoch": 3.6069438491213033,
      "grad_norm": 0.07055774331092834,
      "learning_rate": 1.5190741534504931e-05,
      "loss": 0.0007,
      "step": 16830
    },
    {
      "epoch": 3.609087012430347,
      "grad_norm": 0.11146152764558792,
      "learning_rate": 1.5187883983426207e-05,
      "loss": 0.1751,
      "step": 16840
    },
    {
      "epoch": 3.6112301757393914,
      "grad_norm": 0.07502751052379608,
      "learning_rate": 1.518502643234748e-05,
      "loss": 0.0005,
      "step": 16850
    },
    {
      "epoch": 3.6133733390484357,
      "grad_norm": 0.017900977283716202,
      "learning_rate": 1.5182168881268753e-05,
      "loss": 0.0003,
      "step": 16860
    },
    {
      "epoch": 3.6155165023574796,
      "grad_norm": 0.039028096944093704,
      "learning_rate": 1.5179311330190027e-05,
      "loss": 0.0005,
      "step": 16870
    },
    {
      "epoch": 3.617659665666524,
      "grad_norm": 0.00043067167280241847,
      "learning_rate": 1.5176453779111302e-05,
      "loss": 0.2296,
      "step": 16880
    },
    {
      "epoch": 3.619802828975568,
      "grad_norm": 0.01881701685488224,
      "learning_rate": 1.5173596228032576e-05,
      "loss": 0.0002,
      "step": 16890
    },
    {
      "epoch": 3.621945992284612,
      "grad_norm": 0.0005398276844061911,
      "learning_rate": 1.5170738676953852e-05,
      "loss": 0.0003,
      "step": 16900
    },
    {
      "epoch": 3.6240891555936563,
      "grad_norm": 0.14577536284923553,
      "learning_rate": 1.5167881125875126e-05,
      "loss": 0.0005,
      "step": 16910
    },
    {
      "epoch": 3.6262323189027006,
      "grad_norm": 0.13427382707595825,
      "learning_rate": 1.51650235747964e-05,
      "loss": 0.1912,
      "step": 16920
    },
    {
      "epoch": 3.6283754822117444,
      "grad_norm": 0.006935643497854471,
      "learning_rate": 1.5162166023717675e-05,
      "loss": 0.0004,
      "step": 16930
    },
    {
      "epoch": 3.6305186455207887,
      "grad_norm": 0.01904539205133915,
      "learning_rate": 1.515930847263895e-05,
      "loss": 0.1952,
      "step": 16940
    },
    {
      "epoch": 3.632661808829833,
      "grad_norm": 0.00037665117997676134,
      "learning_rate": 1.5156450921560225e-05,
      "loss": 0.0003,
      "step": 16950
    },
    {
      "epoch": 3.634804972138877,
      "grad_norm": 0.12283188104629517,
      "learning_rate": 1.5153593370481499e-05,
      "loss": 0.0008,
      "step": 16960
    },
    {
      "epoch": 3.636948135447921,
      "grad_norm": 0.039087627083063126,
      "learning_rate": 1.5150735819402773e-05,
      "loss": 0.0003,
      "step": 16970
    },
    {
      "epoch": 3.6390912987569655,
      "grad_norm": 0.00016714184312149882,
      "learning_rate": 1.5147878268324048e-05,
      "loss": 0.0002,
      "step": 16980
    },
    {
      "epoch": 3.6412344620660093,
      "grad_norm": 0.07312925159931183,
      "learning_rate": 1.5145020717245322e-05,
      "loss": 0.2243,
      "step": 16990
    },
    {
      "epoch": 3.6433776253750536,
      "grad_norm": 21.96094512939453,
      "learning_rate": 1.5142163166166596e-05,
      "loss": 0.3021,
      "step": 17000
    },
    {
      "epoch": 3.645520788684098,
      "grad_norm": 0.032304685562849045,
      "learning_rate": 1.5139305615087872e-05,
      "loss": 0.3412,
      "step": 17010
    },
    {
      "epoch": 3.6476639519931418,
      "grad_norm": 0.0009857959812507033,
      "learning_rate": 1.5136448064009146e-05,
      "loss": 0.1814,
      "step": 17020
    },
    {
      "epoch": 3.649807115302186,
      "grad_norm": 0.0026053404435515404,
      "learning_rate": 1.5133590512930421e-05,
      "loss": 0.1592,
      "step": 17030
    },
    {
      "epoch": 3.6519502786112303,
      "grad_norm": 0.29903048276901245,
      "learning_rate": 1.5130732961851695e-05,
      "loss": 1.1869,
      "step": 17040
    },
    {
      "epoch": 3.654093441920274,
      "grad_norm": 18.68169403076172,
      "learning_rate": 1.512787541077297e-05,
      "loss": 0.5693,
      "step": 17050
    },
    {
      "epoch": 3.6562366052293185,
      "grad_norm": 0.07127221673727036,
      "learning_rate": 1.5125017859694245e-05,
      "loss": 0.2033,
      "step": 17060
    },
    {
      "epoch": 3.6583797685383628,
      "grad_norm": 0.11390168219804764,
      "learning_rate": 1.5122160308615517e-05,
      "loss": 0.0011,
      "step": 17070
    },
    {
      "epoch": 3.6605229318474066,
      "grad_norm": 0.010687649250030518,
      "learning_rate": 1.5119302757536791e-05,
      "loss": 0.001,
      "step": 17080
    },
    {
      "epoch": 3.662666095156451,
      "grad_norm": 0.015675945207476616,
      "learning_rate": 1.5116445206458067e-05,
      "loss": 0.5034,
      "step": 17090
    },
    {
      "epoch": 3.664809258465495,
      "grad_norm": 0.01778131164610386,
      "learning_rate": 1.511358765537934e-05,
      "loss": 0.0049,
      "step": 17100
    },
    {
      "epoch": 3.666952421774539,
      "grad_norm": 0.04444911330938339,
      "learning_rate": 1.5110730104300614e-05,
      "loss": 0.0009,
      "step": 17110
    },
    {
      "epoch": 3.6690955850835834,
      "grad_norm": 0.0053137014620006084,
      "learning_rate": 1.510787255322189e-05,
      "loss": 0.1546,
      "step": 17120
    },
    {
      "epoch": 3.6712387483926276,
      "grad_norm": 0.0072587053291499615,
      "learning_rate": 1.5105015002143164e-05,
      "loss": 0.0018,
      "step": 17130
    },
    {
      "epoch": 3.6733819117016715,
      "grad_norm": 0.019981497898697853,
      "learning_rate": 1.5102157451064438e-05,
      "loss": 0.1617,
      "step": 17140
    },
    {
      "epoch": 3.675525075010716,
      "grad_norm": 0.010193020105361938,
      "learning_rate": 1.5099299899985714e-05,
      "loss": 0.1434,
      "step": 17150
    },
    {
      "epoch": 3.67766823831976,
      "grad_norm": 0.0022023492492735386,
      "learning_rate": 1.5096442348906988e-05,
      "loss": 0.0005,
      "step": 17160
    },
    {
      "epoch": 3.679811401628804,
      "grad_norm": 0.005104753188788891,
      "learning_rate": 1.5093584797828263e-05,
      "loss": 0.2799,
      "step": 17170
    },
    {
      "epoch": 3.6819545649378482,
      "grad_norm": 0.04899094998836517,
      "learning_rate": 1.5090727246749537e-05,
      "loss": 0.0016,
      "step": 17180
    },
    {
      "epoch": 3.6840977282468925,
      "grad_norm": 0.010324366390705109,
      "learning_rate": 1.5087869695670811e-05,
      "loss": 0.5418,
      "step": 17190
    },
    {
      "epoch": 3.6862408915559364,
      "grad_norm": 0.020032992586493492,
      "learning_rate": 1.5085012144592087e-05,
      "loss": 0.1098,
      "step": 17200
    },
    {
      "epoch": 3.6883840548649807,
      "grad_norm": 0.014204363338649273,
      "learning_rate": 1.508215459351336e-05,
      "loss": 0.1517,
      "step": 17210
    },
    {
      "epoch": 3.690527218174025,
      "grad_norm": 0.054561033844947815,
      "learning_rate": 1.5079297042434634e-05,
      "loss": 0.0004,
      "step": 17220
    },
    {
      "epoch": 3.692670381483069,
      "grad_norm": 0.007196493912488222,
      "learning_rate": 1.507643949135591e-05,
      "loss": 0.215,
      "step": 17230
    },
    {
      "epoch": 3.694813544792113,
      "grad_norm": 0.012942259199917316,
      "learning_rate": 1.5073581940277184e-05,
      "loss": 0.0013,
      "step": 17240
    },
    {
      "epoch": 3.6969567081011574,
      "grad_norm": 41.90339279174805,
      "learning_rate": 1.507072438919846e-05,
      "loss": 0.1533,
      "step": 17250
    },
    {
      "epoch": 3.6990998714102012,
      "grad_norm": 0.002789241960272193,
      "learning_rate": 1.5067866838119734e-05,
      "loss": 0.0001,
      "step": 17260
    },
    {
      "epoch": 3.7012430347192455,
      "grad_norm": 0.004667256027460098,
      "learning_rate": 1.5065009287041008e-05,
      "loss": 0.0002,
      "step": 17270
    },
    {
      "epoch": 3.70338619802829,
      "grad_norm": 0.02779323048889637,
      "learning_rate": 1.5062151735962283e-05,
      "loss": 0.0002,
      "step": 17280
    },
    {
      "epoch": 3.7055293613373337,
      "grad_norm": 0.02278611809015274,
      "learning_rate": 1.5059294184883555e-05,
      "loss": 0.0002,
      "step": 17290
    },
    {
      "epoch": 3.707672524646378,
      "grad_norm": 0.02639775350689888,
      "learning_rate": 1.505643663380483e-05,
      "loss": 0.0001,
      "step": 17300
    },
    {
      "epoch": 3.7098156879554223,
      "grad_norm": 0.001989474054425955,
      "learning_rate": 1.5053579082726105e-05,
      "loss": 0.301,
      "step": 17310
    },
    {
      "epoch": 3.711958851264466,
      "grad_norm": 0.025948675349354744,
      "learning_rate": 1.5050721531647379e-05,
      "loss": 0.0001,
      "step": 17320
    },
    {
      "epoch": 3.7141020145735104,
      "grad_norm": 0.0075836945325136185,
      "learning_rate": 1.5047863980568653e-05,
      "loss": 0.0002,
      "step": 17330
    },
    {
      "epoch": 3.7162451778825547,
      "grad_norm": 0.009938173927366734,
      "learning_rate": 1.5045006429489928e-05,
      "loss": 0.0004,
      "step": 17340
    },
    {
      "epoch": 3.7183883411915986,
      "grad_norm": 0.08186254650354385,
      "learning_rate": 1.5042148878411202e-05,
      "loss": 0.2112,
      "step": 17350
    },
    {
      "epoch": 3.720531504500643,
      "grad_norm": 0.014124928042292595,
      "learning_rate": 1.5039291327332476e-05,
      "loss": 0.0005,
      "step": 17360
    },
    {
      "epoch": 3.722674667809687,
      "grad_norm": 0.0025268862955272198,
      "learning_rate": 1.5036433776253752e-05,
      "loss": 0.0008,
      "step": 17370
    },
    {
      "epoch": 3.724817831118731,
      "grad_norm": 0.0036169507075101137,
      "learning_rate": 1.5033576225175026e-05,
      "loss": 0.0006,
      "step": 17380
    },
    {
      "epoch": 3.7269609944277753,
      "grad_norm": 0.0018599957693368196,
      "learning_rate": 1.5030718674096301e-05,
      "loss": 0.3445,
      "step": 17390
    },
    {
      "epoch": 3.7291041577368196,
      "grad_norm": 0.0024346322752535343,
      "learning_rate": 1.5027861123017575e-05,
      "loss": 0.0002,
      "step": 17400
    },
    {
      "epoch": 3.7312473210458634,
      "grad_norm": 0.0017074189381673932,
      "learning_rate": 1.502500357193885e-05,
      "loss": 0.001,
      "step": 17410
    },
    {
      "epoch": 3.7333904843549077,
      "grad_norm": 0.01711948774755001,
      "learning_rate": 1.5022146020860125e-05,
      "loss": 0.2472,
      "step": 17420
    },
    {
      "epoch": 3.735533647663952,
      "grad_norm": 0.006128666922450066,
      "learning_rate": 1.5019288469781399e-05,
      "loss": 0.0004,
      "step": 17430
    },
    {
      "epoch": 3.737676810972996,
      "grad_norm": 21.216957092285156,
      "learning_rate": 1.5016430918702673e-05,
      "loss": 0.2138,
      "step": 17440
    },
    {
      "epoch": 3.73981997428204,
      "grad_norm": 0.0064762672409415245,
      "learning_rate": 1.5013573367623948e-05,
      "loss": 0.0001,
      "step": 17450
    },
    {
      "epoch": 3.7419631375910845,
      "grad_norm": 0.005697212181985378,
      "learning_rate": 1.5010715816545222e-05,
      "loss": 0.157,
      "step": 17460
    },
    {
      "epoch": 3.7441063009001287,
      "grad_norm": 0.0028108719270676374,
      "learning_rate": 1.5007858265466498e-05,
      "loss": 0.3245,
      "step": 17470
    },
    {
      "epoch": 3.7462494642091726,
      "grad_norm": 0.003326108679175377,
      "learning_rate": 1.5005000714387772e-05,
      "loss": 0.0001,
      "step": 17480
    },
    {
      "epoch": 3.748392627518217,
      "grad_norm": 0.003378036431968212,
      "learning_rate": 1.5002143163309046e-05,
      "loss": 0.2102,
      "step": 17490
    },
    {
      "epoch": 3.750535790827261,
      "grad_norm": 0.005612366367131472,
      "learning_rate": 1.4999285612230318e-05,
      "loss": 0.0001,
      "step": 17500
    },
    {
      "epoch": 3.752678954136305,
      "grad_norm": 0.0024062565062195063,
      "learning_rate": 1.4996428061151594e-05,
      "loss": 0.0002,
      "step": 17510
    },
    {
      "epoch": 3.7548221174453493,
      "grad_norm": 0.03332418575882912,
      "learning_rate": 1.4993570510072868e-05,
      "loss": 0.0004,
      "step": 17520
    },
    {
      "epoch": 3.7569652807543936,
      "grad_norm": 0.015384138561785221,
      "learning_rate": 1.4990712958994143e-05,
      "loss": 0.3227,
      "step": 17530
    },
    {
      "epoch": 3.7591084440634375,
      "grad_norm": 0.01561312098056078,
      "learning_rate": 1.4987855407915417e-05,
      "loss": 0.1647,
      "step": 17540
    },
    {
      "epoch": 3.7612516073724818,
      "grad_norm": 19.29875946044922,
      "learning_rate": 1.4984997856836691e-05,
      "loss": 0.1957,
      "step": 17550
    },
    {
      "epoch": 3.763394770681526,
      "grad_norm": 0.020099207758903503,
      "learning_rate": 1.4982140305757967e-05,
      "loss": 0.1992,
      "step": 17560
    },
    {
      "epoch": 3.7655379339905704,
      "grad_norm": 0.020471975207328796,
      "learning_rate": 1.497928275467924e-05,
      "loss": 0.0011,
      "step": 17570
    },
    {
      "epoch": 3.767681097299614,
      "grad_norm": 0.009140259586274624,
      "learning_rate": 1.4976425203600515e-05,
      "loss": 0.0012,
      "step": 17580
    },
    {
      "epoch": 3.7698242606086585,
      "grad_norm": 0.006925055291503668,
      "learning_rate": 1.497356765252179e-05,
      "loss": 0.0007,
      "step": 17590
    },
    {
      "epoch": 3.771967423917703,
      "grad_norm": 0.023816511034965515,
      "learning_rate": 1.4970710101443064e-05,
      "loss": 0.2262,
      "step": 17600
    },
    {
      "epoch": 3.7741105872267466,
      "grad_norm": 0.024330537766218185,
      "learning_rate": 1.496785255036434e-05,
      "loss": 0.1979,
      "step": 17610
    },
    {
      "epoch": 3.776253750535791,
      "grad_norm": 0.016106195747852325,
      "learning_rate": 1.4964994999285614e-05,
      "loss": 0.0008,
      "step": 17620
    },
    {
      "epoch": 3.7783969138448352,
      "grad_norm": 0.016075367107987404,
      "learning_rate": 1.4962137448206888e-05,
      "loss": 0.1842,
      "step": 17630
    },
    {
      "epoch": 3.780540077153879,
      "grad_norm": 0.0673527717590332,
      "learning_rate": 1.4959279897128163e-05,
      "loss": 0.2649,
      "step": 17640
    },
    {
      "epoch": 3.7826832404629234,
      "grad_norm": 0.0348515659570694,
      "learning_rate": 1.4956422346049437e-05,
      "loss": 0.001,
      "step": 17650
    },
    {
      "epoch": 3.7848264037719677,
      "grad_norm": 0.02093249000608921,
      "learning_rate": 1.4953564794970713e-05,
      "loss": 0.1692,
      "step": 17660
    },
    {
      "epoch": 3.7869695670810115,
      "grad_norm": 0.13448981940746307,
      "learning_rate": 1.4950707243891987e-05,
      "loss": 0.109,
      "step": 17670
    },
    {
      "epoch": 3.789112730390056,
      "grad_norm": 0.26475098729133606,
      "learning_rate": 1.494784969281326e-05,
      "loss": 0.2263,
      "step": 17680
    },
    {
      "epoch": 3.7912558936991,
      "grad_norm": 0.02628721110522747,
      "learning_rate": 1.4944992141734536e-05,
      "loss": 0.0018,
      "step": 17690
    },
    {
      "epoch": 3.793399057008144,
      "grad_norm": 0.010906128212809563,
      "learning_rate": 1.494213459065581e-05,
      "loss": 0.0008,
      "step": 17700
    },
    {
      "epoch": 3.7955422203171882,
      "grad_norm": 0.009715489111840725,
      "learning_rate": 1.4939277039577084e-05,
      "loss": 0.2028,
      "step": 17710
    },
    {
      "epoch": 3.7976853836262325,
      "grad_norm": 15.968243598937988,
      "learning_rate": 1.4936419488498356e-05,
      "loss": 0.2023,
      "step": 17720
    },
    {
      "epoch": 3.7998285469352764,
      "grad_norm": 0.012710238806903362,
      "learning_rate": 1.4933561937419632e-05,
      "loss": 0.0009,
      "step": 17730
    },
    {
      "epoch": 3.8019717102443207,
      "grad_norm": 0.048906441777944565,
      "learning_rate": 1.4930704386340906e-05,
      "loss": 0.2018,
      "step": 17740
    },
    {
      "epoch": 3.804114873553365,
      "grad_norm": 0.025641657412052155,
      "learning_rate": 1.4927846835262181e-05,
      "loss": 0.0005,
      "step": 17750
    },
    {
      "epoch": 3.806258036862409,
      "grad_norm": 0.004484264180064201,
      "learning_rate": 1.4924989284183455e-05,
      "loss": 0.0002,
      "step": 17760
    },
    {
      "epoch": 3.808401200171453,
      "grad_norm": 0.005646378733217716,
      "learning_rate": 1.492213173310473e-05,
      "loss": 0.0001,
      "step": 17770
    },
    {
      "epoch": 3.8105443634804974,
      "grad_norm": 0.04608900099992752,
      "learning_rate": 1.4919274182026005e-05,
      "loss": 0.0002,
      "step": 17780
    },
    {
      "epoch": 3.8126875267895413,
      "grad_norm": 0.0017573856748640537,
      "learning_rate": 1.4916416630947279e-05,
      "loss": 0.0008,
      "step": 17790
    },
    {
      "epoch": 3.8148306900985856,
      "grad_norm": 0.0015380661934614182,
      "learning_rate": 1.4913559079868554e-05,
      "loss": 0.0009,
      "step": 17800
    },
    {
      "epoch": 3.81697385340763,
      "grad_norm": 0.07463813573122025,
      "learning_rate": 1.4910701528789828e-05,
      "loss": 0.0003,
      "step": 17810
    },
    {
      "epoch": 3.8191170167166737,
      "grad_norm": 0.0019899781327694654,
      "learning_rate": 1.4907843977711102e-05,
      "loss": 0.1378,
      "step": 17820
    },
    {
      "epoch": 3.821260180025718,
      "grad_norm": 0.0035688390489667654,
      "learning_rate": 1.4904986426632378e-05,
      "loss": 0.0002,
      "step": 17830
    },
    {
      "epoch": 3.8234033433347623,
      "grad_norm": 0.002414227928966284,
      "learning_rate": 1.4902128875553652e-05,
      "loss": 0.0,
      "step": 17840
    },
    {
      "epoch": 3.825546506643806,
      "grad_norm": 0.0012269276194274426,
      "learning_rate": 1.4899271324474926e-05,
      "loss": 0.0004,
      "step": 17850
    },
    {
      "epoch": 3.8276896699528504,
      "grad_norm": 0.0013471832498908043,
      "learning_rate": 1.4896413773396201e-05,
      "loss": 0.0002,
      "step": 17860
    },
    {
      "epoch": 3.8298328332618947,
      "grad_norm": 0.0010251722997054458,
      "learning_rate": 1.4893556222317475e-05,
      "loss": 0.0004,
      "step": 17870
    },
    {
      "epoch": 3.8319759965709386,
      "grad_norm": 0.0011015445925295353,
      "learning_rate": 1.4890698671238751e-05,
      "loss": 0.0001,
      "step": 17880
    },
    {
      "epoch": 3.834119159879983,
      "grad_norm": 0.002913495758548379,
      "learning_rate": 1.4887841120160025e-05,
      "loss": 0.144,
      "step": 17890
    },
    {
      "epoch": 3.836262323189027,
      "grad_norm": 0.001018762239255011,
      "learning_rate": 1.4884983569081299e-05,
      "loss": 0.0,
      "step": 17900
    },
    {
      "epoch": 3.838405486498071,
      "grad_norm": 0.0013647896703332663,
      "learning_rate": 1.4882126018002574e-05,
      "loss": 0.3514,
      "step": 17910
    },
    {
      "epoch": 3.8405486498071153,
      "grad_norm": 0.002464862074702978,
      "learning_rate": 1.4879268466923848e-05,
      "loss": 0.0003,
      "step": 17920
    },
    {
      "epoch": 3.8426918131161596,
      "grad_norm": 0.0164675060659647,
      "learning_rate": 1.487641091584512e-05,
      "loss": 0.0002,
      "step": 17930
    },
    {
      "epoch": 3.8448349764252034,
      "grad_norm": 0.03266635164618492,
      "learning_rate": 1.4873553364766396e-05,
      "loss": 0.0034,
      "step": 17940
    },
    {
      "epoch": 3.8469781397342477,
      "grad_norm": 0.004523287061601877,
      "learning_rate": 1.487069581368767e-05,
      "loss": 0.0001,
      "step": 17950
    },
    {
      "epoch": 3.849121303043292,
      "grad_norm": 0.00230075279250741,
      "learning_rate": 1.4867838262608944e-05,
      "loss": 0.0001,
      "step": 17960
    },
    {
      "epoch": 3.851264466352336,
      "grad_norm": 0.18846918642520905,
      "learning_rate": 1.486498071153022e-05,
      "loss": 0.0097,
      "step": 17970
    },
    {
      "epoch": 3.85340762966138,
      "grad_norm": 0.02393554523587227,
      "learning_rate": 1.4862123160451494e-05,
      "loss": 0.0003,
      "step": 17980
    },
    {
      "epoch": 3.8555507929704245,
      "grad_norm": 0.0012890049256384373,
      "learning_rate": 1.4859265609372768e-05,
      "loss": 0.0002,
      "step": 17990
    },
    {
      "epoch": 3.8576939562794683,
      "grad_norm": 0.0018589170649647713,
      "learning_rate": 1.4856408058294043e-05,
      "loss": 0.0001,
      "step": 18000
    },
    {
      "epoch": 3.8598371195885126,
      "grad_norm": 0.030959926545619965,
      "learning_rate": 1.4853550507215317e-05,
      "loss": 0.0002,
      "step": 18010
    },
    {
      "epoch": 3.861980282897557,
      "grad_norm": 0.0012936964631080627,
      "learning_rate": 1.4850692956136593e-05,
      "loss": 0.419,
      "step": 18020
    },
    {
      "epoch": 3.8641234462066008,
      "grad_norm": 0.004793398082256317,
      "learning_rate": 1.4847835405057867e-05,
      "loss": 0.0079,
      "step": 18030
    },
    {
      "epoch": 3.866266609515645,
      "grad_norm": 0.00202416954562068,
      "learning_rate": 1.484497785397914e-05,
      "loss": 0.2,
      "step": 18040
    },
    {
      "epoch": 3.8684097728246893,
      "grad_norm": 0.004480109084397554,
      "learning_rate": 1.4842120302900416e-05,
      "loss": 0.0004,
      "step": 18050
    },
    {
      "epoch": 3.870552936133733,
      "grad_norm": 0.050917189568281174,
      "learning_rate": 1.483926275182169e-05,
      "loss": 0.4438,
      "step": 18060
    },
    {
      "epoch": 3.8726960994427775,
      "grad_norm": 0.0012725754640996456,
      "learning_rate": 1.4836405200742964e-05,
      "loss": 0.3236,
      "step": 18070
    },
    {
      "epoch": 3.8748392627518218,
      "grad_norm": 0.01933547854423523,
      "learning_rate": 1.483354764966424e-05,
      "loss": 0.0002,
      "step": 18080
    },
    {
      "epoch": 3.8769824260608656,
      "grad_norm": 0.003515210933983326,
      "learning_rate": 1.4830690098585514e-05,
      "loss": 0.0001,
      "step": 18090
    },
    {
      "epoch": 3.87912558936991,
      "grad_norm": 16.52029800415039,
      "learning_rate": 1.482783254750679e-05,
      "loss": 0.1315,
      "step": 18100
    },
    {
      "epoch": 3.881268752678954,
      "grad_norm": 0.001752363285049796,
      "learning_rate": 1.4824974996428063e-05,
      "loss": 0.2026,
      "step": 18110
    },
    {
      "epoch": 3.883411915987998,
      "grad_norm": 0.02598111517727375,
      "learning_rate": 1.4822117445349337e-05,
      "loss": 0.0003,
      "step": 18120
    },
    {
      "epoch": 3.8855550792970424,
      "grad_norm": 0.013810533098876476,
      "learning_rate": 1.4819259894270613e-05,
      "loss": 0.0003,
      "step": 18130
    },
    {
      "epoch": 3.8876982426060867,
      "grad_norm": 972.8082885742188,
      "learning_rate": 1.4816402343191887e-05,
      "loss": 0.1886,
      "step": 18140
    },
    {
      "epoch": 3.8898414059151305,
      "grad_norm": 0.007800910621881485,
      "learning_rate": 1.4813544792113159e-05,
      "loss": 0.0006,
      "step": 18150
    },
    {
      "epoch": 3.891984569224175,
      "grad_norm": 0.038238443434238434,
      "learning_rate": 1.4810687241034435e-05,
      "loss": 0.0001,
      "step": 18160
    },
    {
      "epoch": 3.894127732533219,
      "grad_norm": 0.0016960268840193748,
      "learning_rate": 1.4807829689955708e-05,
      "loss": 0.0002,
      "step": 18170
    },
    {
      "epoch": 3.896270895842263,
      "grad_norm": 0.038170065730810165,
      "learning_rate": 1.4804972138876982e-05,
      "loss": 0.0001,
      "step": 18180
    },
    {
      "epoch": 3.8984140591513072,
      "grad_norm": 0.024069782346487045,
      "learning_rate": 1.4802114587798258e-05,
      "loss": 0.3228,
      "step": 18190
    },
    {
      "epoch": 3.9005572224603515,
      "grad_norm": 0.0037307224702090025,
      "learning_rate": 1.4799257036719532e-05,
      "loss": 0.2174,
      "step": 18200
    },
    {
      "epoch": 3.9027003857693954,
      "grad_norm": 0.03232477605342865,
      "learning_rate": 1.4796399485640806e-05,
      "loss": 0.0019,
      "step": 18210
    },
    {
      "epoch": 3.9048435490784397,
      "grad_norm": 0.08315358310937881,
      "learning_rate": 1.4793541934562082e-05,
      "loss": 0.0007,
      "step": 18220
    },
    {
      "epoch": 3.906986712387484,
      "grad_norm": 0.07035288214683533,
      "learning_rate": 1.4790684383483355e-05,
      "loss": 0.184,
      "step": 18230
    },
    {
      "epoch": 3.909129875696528,
      "grad_norm": 0.013739998452365398,
      "learning_rate": 1.4787826832404631e-05,
      "loss": 0.1924,
      "step": 18240
    },
    {
      "epoch": 3.911273039005572,
      "grad_norm": 0.022254997864365578,
      "learning_rate": 1.4784969281325905e-05,
      "loss": 0.1729,
      "step": 18250
    },
    {
      "epoch": 3.9134162023146164,
      "grad_norm": 0.06311126053333282,
      "learning_rate": 1.4782111730247179e-05,
      "loss": 0.1058,
      "step": 18260
    },
    {
      "epoch": 3.9155593656236602,
      "grad_norm": 0.006440847180783749,
      "learning_rate": 1.4779254179168455e-05,
      "loss": 0.0008,
      "step": 18270
    },
    {
      "epoch": 3.9177025289327045,
      "grad_norm": 0.013754903338849545,
      "learning_rate": 1.4776396628089728e-05,
      "loss": 0.3066,
      "step": 18280
    },
    {
      "epoch": 3.919845692241749,
      "grad_norm": 0.004362029489129782,
      "learning_rate": 1.4773539077011002e-05,
      "loss": 0.0002,
      "step": 18290
    },
    {
      "epoch": 3.921988855550793,
      "grad_norm": 0.04528002813458443,
      "learning_rate": 1.4770681525932278e-05,
      "loss": 0.1828,
      "step": 18300
    },
    {
      "epoch": 3.924132018859837,
      "grad_norm": 0.002481811912730336,
      "learning_rate": 1.4767823974853552e-05,
      "loss": 0.1259,
      "step": 18310
    },
    {
      "epoch": 3.9262751821688813,
      "grad_norm": 0.007801288738846779,
      "learning_rate": 1.4764966423774828e-05,
      "loss": 0.0025,
      "step": 18320
    },
    {
      "epoch": 3.9284183454779256,
      "grad_norm": 39.12303924560547,
      "learning_rate": 1.4762108872696101e-05,
      "loss": 0.328,
      "step": 18330
    },
    {
      "epoch": 3.9305615087869694,
      "grad_norm": 0.0021122051402926445,
      "learning_rate": 1.4759251321617375e-05,
      "loss": 0.104,
      "step": 18340
    },
    {
      "epoch": 3.9327046720960137,
      "grad_norm": 3.7517194747924805,
      "learning_rate": 1.4756393770538651e-05,
      "loss": 0.2155,
      "step": 18350
    },
    {
      "epoch": 3.934847835405058,
      "grad_norm": 0.03700309619307518,
      "learning_rate": 1.4753536219459923e-05,
      "loss": 0.469,
      "step": 18360
    },
    {
      "epoch": 3.936990998714102,
      "grad_norm": 0.052293144166469574,
      "learning_rate": 1.4750678668381197e-05,
      "loss": 0.1099,
      "step": 18370
    },
    {
      "epoch": 3.939134162023146,
      "grad_norm": 24.982799530029297,
      "learning_rate": 1.4747821117302473e-05,
      "loss": 0.1231,
      "step": 18380
    },
    {
      "epoch": 3.9412773253321904,
      "grad_norm": 0.0014877060893923044,
      "learning_rate": 1.4744963566223747e-05,
      "loss": 0.0001,
      "step": 18390
    },
    {
      "epoch": 3.9434204886412347,
      "grad_norm": 0.0015893137315288186,
      "learning_rate": 1.474210601514502e-05,
      "loss": 0.0035,
      "step": 18400
    },
    {
      "epoch": 3.9455636519502786,
      "grad_norm": 0.010783080942928791,
      "learning_rate": 1.4739248464066296e-05,
      "loss": 0.1997,
      "step": 18410
    },
    {
      "epoch": 3.947706815259323,
      "grad_norm": 0.0017681021708995104,
      "learning_rate": 1.473639091298757e-05,
      "loss": 0.0003,
      "step": 18420
    },
    {
      "epoch": 3.949849978568367,
      "grad_norm": 0.010229812003672123,
      "learning_rate": 1.4733533361908844e-05,
      "loss": 0.2108,
      "step": 18430
    },
    {
      "epoch": 3.951993141877411,
      "grad_norm": 0.001972510479390621,
      "learning_rate": 1.473067581083012e-05,
      "loss": 0.0003,
      "step": 18440
    },
    {
      "epoch": 3.9541363051864553,
      "grad_norm": 0.06972429901361465,
      "learning_rate": 1.4727818259751394e-05,
      "loss": 0.1357,
      "step": 18450
    },
    {
      "epoch": 3.9562794684954996,
      "grad_norm": 0.13024555146694183,
      "learning_rate": 1.472496070867267e-05,
      "loss": 0.0003,
      "step": 18460
    },
    {
      "epoch": 3.9584226318045435,
      "grad_norm": 0.0011318247998133302,
      "learning_rate": 1.4722103157593943e-05,
      "loss": 0.0001,
      "step": 18470
    },
    {
      "epoch": 3.9605657951135878,
      "grad_norm": 0.002829951699823141,
      "learning_rate": 1.4719245606515217e-05,
      "loss": 0.0008,
      "step": 18480
    },
    {
      "epoch": 3.962708958422632,
      "grad_norm": 0.022364245727658272,
      "learning_rate": 1.4716388055436493e-05,
      "loss": 0.0019,
      "step": 18490
    },
    {
      "epoch": 3.964852121731676,
      "grad_norm": 0.0008681812323629856,
      "learning_rate": 1.4713530504357767e-05,
      "loss": 0.0007,
      "step": 18500
    },
    {
      "epoch": 3.96699528504072,
      "grad_norm": 0.0767875462770462,
      "learning_rate": 1.4710672953279042e-05,
      "loss": 0.0003,
      "step": 18510
    },
    {
      "epoch": 3.9691384483497645,
      "grad_norm": 0.033026181161403656,
      "learning_rate": 1.4707815402200316e-05,
      "loss": 0.0007,
      "step": 18520
    },
    {
      "epoch": 3.9712816116588083,
      "grad_norm": 0.022094575688242912,
      "learning_rate": 1.470495785112159e-05,
      "loss": 0.0007,
      "step": 18530
    },
    {
      "epoch": 3.9734247749678526,
      "grad_norm": 0.0004079245263710618,
      "learning_rate": 1.4702100300042866e-05,
      "loss": 0.0001,
      "step": 18540
    },
    {
      "epoch": 3.975567938276897,
      "grad_norm": 0.037594135850667953,
      "learning_rate": 1.469924274896414e-05,
      "loss": 0.0003,
      "step": 18550
    },
    {
      "epoch": 3.9777111015859408,
      "grad_norm": 0.0004679042031057179,
      "learning_rate": 1.4696385197885414e-05,
      "loss": 0.0003,
      "step": 18560
    },
    {
      "epoch": 3.979854264894985,
      "grad_norm": 0.18339776992797852,
      "learning_rate": 1.469352764680669e-05,
      "loss": 0.0004,
      "step": 18570
    },
    {
      "epoch": 3.9819974282040294,
      "grad_norm": 18.772048950195312,
      "learning_rate": 1.4690670095727962e-05,
      "loss": 0.7625,
      "step": 18580
    },
    {
      "epoch": 3.984140591513073,
      "grad_norm": 0.034576840698719025,
      "learning_rate": 1.4687812544649235e-05,
      "loss": 0.0003,
      "step": 18590
    },
    {
      "epoch": 3.9862837548221175,
      "grad_norm": 0.005038971081376076,
      "learning_rate": 1.4684954993570511e-05,
      "loss": 0.0007,
      "step": 18600
    },
    {
      "epoch": 3.988426918131162,
      "grad_norm": 0.006983688101172447,
      "learning_rate": 1.4682097442491785e-05,
      "loss": 0.2144,
      "step": 18610
    },
    {
      "epoch": 3.9905700814402056,
      "grad_norm": 0.08247888088226318,
      "learning_rate": 1.4679239891413059e-05,
      "loss": 0.3402,
      "step": 18620
    },
    {
      "epoch": 3.99271324474925,
      "grad_norm": 0.04761870950460434,
      "learning_rate": 1.4676382340334335e-05,
      "loss": 0.0009,
      "step": 18630
    },
    {
      "epoch": 3.9948564080582942,
      "grad_norm": 0.06210131570696831,
      "learning_rate": 1.4673524789255609e-05,
      "loss": 0.1399,
      "step": 18640
    },
    {
      "epoch": 3.996999571367338,
      "grad_norm": 0.02605103701353073,
      "learning_rate": 1.4670667238176884e-05,
      "loss": 0.344,
      "step": 18650
    },
    {
      "epoch": 3.9991427346763824,
      "grad_norm": 0.006206676363945007,
      "learning_rate": 1.4667809687098158e-05,
      "loss": 0.001,
      "step": 18660
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.983,
      "eval_f1": 0.9128205128205129,
      "eval_loss": 0.08768942952156067,
      "eval_precision": 0.9368421052631579,
      "eval_recall": 0.89,
      "eval_runtime": 396.4352,
      "eval_samples_per_second": 7.567,
      "eval_steps_per_second": 2.522,
      "step": 18664
    },
    {
      "epoch": 4.001285897985427,
      "grad_norm": 0.14573417603969574,
      "learning_rate": 1.4664952136019432e-05,
      "loss": 0.0024,
      "step": 18670
    },
    {
      "epoch": 4.0034290612944705,
      "grad_norm": 0.018228625878691673,
      "learning_rate": 1.4662094584940708e-05,
      "loss": 0.0012,
      "step": 18680
    },
    {
      "epoch": 4.005572224603514,
      "grad_norm": 0.07126682251691818,
      "learning_rate": 1.4659237033861982e-05,
      "loss": 0.1726,
      "step": 18690
    },
    {
      "epoch": 4.007715387912559,
      "grad_norm": 0.0007676589884795249,
      "learning_rate": 1.4656379482783255e-05,
      "loss": 0.0003,
      "step": 18700
    },
    {
      "epoch": 4.009858551221603,
      "grad_norm": 0.07517409324645996,
      "learning_rate": 1.4653521931704531e-05,
      "loss": 0.0003,
      "step": 18710
    },
    {
      "epoch": 4.012001714530647,
      "grad_norm": 0.00432909419760108,
      "learning_rate": 1.4650664380625805e-05,
      "loss": 0.0003,
      "step": 18720
    },
    {
      "epoch": 4.0141448778396915,
      "grad_norm": 0.3418278098106384,
      "learning_rate": 1.464780682954708e-05,
      "loss": 0.295,
      "step": 18730
    },
    {
      "epoch": 4.016288041148735,
      "grad_norm": 0.021975914016366005,
      "learning_rate": 1.4644949278468355e-05,
      "loss": 0.0008,
      "step": 18740
    },
    {
      "epoch": 4.01843120445778,
      "grad_norm": 0.0008663196349516511,
      "learning_rate": 1.4642091727389629e-05,
      "loss": 0.0006,
      "step": 18750
    },
    {
      "epoch": 4.020574367766824,
      "grad_norm": 18.87901496887207,
      "learning_rate": 1.4639234176310904e-05,
      "loss": 0.1878,
      "step": 18760
    },
    {
      "epoch": 4.022717531075868,
      "grad_norm": 0.013436307199299335,
      "learning_rate": 1.4636376625232178e-05,
      "loss": 0.0003,
      "step": 18770
    },
    {
      "epoch": 4.024860694384913,
      "grad_norm": 0.528281033039093,
      "learning_rate": 1.4633519074153452e-05,
      "loss": 0.1894,
      "step": 18780
    },
    {
      "epoch": 4.027003857693956,
      "grad_norm": 0.11799558997154236,
      "learning_rate": 1.4630661523074726e-05,
      "loss": 0.1481,
      "step": 18790
    },
    {
      "epoch": 4.029147021003,
      "grad_norm": 0.00151732936501503,
      "learning_rate": 1.4627803971996e-05,
      "loss": 0.0003,
      "step": 18800
    },
    {
      "epoch": 4.031290184312045,
      "grad_norm": 0.00046973375719971955,
      "learning_rate": 1.4624946420917274e-05,
      "loss": 0.1352,
      "step": 18810
    },
    {
      "epoch": 4.033433347621089,
      "grad_norm": 0.006754741538316011,
      "learning_rate": 1.462208886983855e-05,
      "loss": 0.0009,
      "step": 18820
    },
    {
      "epoch": 4.035576510930133,
      "grad_norm": 0.004137543961405754,
      "learning_rate": 1.4619231318759823e-05,
      "loss": 0.0001,
      "step": 18830
    },
    {
      "epoch": 4.037719674239177,
      "grad_norm": 0.011209496296942234,
      "learning_rate": 1.4616373767681097e-05,
      "loss": 0.0005,
      "step": 18840
    },
    {
      "epoch": 4.039862837548221,
      "grad_norm": 0.0008146088221110404,
      "learning_rate": 1.4613516216602373e-05,
      "loss": 0.0,
      "step": 18850
    },
    {
      "epoch": 4.042006000857265,
      "grad_norm": 0.002128520281985402,
      "learning_rate": 1.4610658665523647e-05,
      "loss": 0.0011,
      "step": 18860
    },
    {
      "epoch": 4.04414916416631,
      "grad_norm": 0.0002803489041980356,
      "learning_rate": 1.4607801114444922e-05,
      "loss": 0.0015,
      "step": 18870
    },
    {
      "epoch": 4.046292327475354,
      "grad_norm": 0.0003046179481316358,
      "learning_rate": 1.4604943563366196e-05,
      "loss": 0.0,
      "step": 18880
    },
    {
      "epoch": 4.048435490784398,
      "grad_norm": 0.00016087573021650314,
      "learning_rate": 1.460208601228747e-05,
      "loss": 0.0007,
      "step": 18890
    },
    {
      "epoch": 4.050578654093442,
      "grad_norm": 0.000187793280929327,
      "learning_rate": 1.4599228461208746e-05,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 4.052721817402486,
      "grad_norm": 0.00019231670012231916,
      "learning_rate": 1.459637091013002e-05,
      "loss": 0.0003,
      "step": 18910
    },
    {
      "epoch": 4.05486498071153,
      "grad_norm": 0.00036166489007882774,
      "learning_rate": 1.4593513359051294e-05,
      "loss": 0.0,
      "step": 18920
    },
    {
      "epoch": 4.057008144020575,
      "grad_norm": 0.00016906920063775033,
      "learning_rate": 1.459065580797257e-05,
      "loss": 0.0002,
      "step": 18930
    },
    {
      "epoch": 4.059151307329619,
      "grad_norm": 0.002006734721362591,
      "learning_rate": 1.4587798256893843e-05,
      "loss": 0.001,
      "step": 18940
    },
    {
      "epoch": 4.0612944706386624,
      "grad_norm": 0.0002252653648611158,
      "learning_rate": 1.4584940705815119e-05,
      "loss": 0.0004,
      "step": 18950
    },
    {
      "epoch": 4.063437633947707,
      "grad_norm": 0.00023091513139661402,
      "learning_rate": 1.4582083154736393e-05,
      "loss": 0.2274,
      "step": 18960
    },
    {
      "epoch": 4.065580797256751,
      "grad_norm": 17.296390533447266,
      "learning_rate": 1.4579225603657667e-05,
      "loss": 0.1511,
      "step": 18970
    },
    {
      "epoch": 4.067723960565795,
      "grad_norm": 0.000587901973631233,
      "learning_rate": 1.4576368052578942e-05,
      "loss": 0.0002,
      "step": 18980
    },
    {
      "epoch": 4.06986712387484,
      "grad_norm": 0.04798343405127525,
      "learning_rate": 1.4573510501500216e-05,
      "loss": 0.0004,
      "step": 18990
    },
    {
      "epoch": 4.0720102871838835,
      "grad_norm": 0.00018846553575713187,
      "learning_rate": 1.457065295042149e-05,
      "loss": 0.2782,
      "step": 19000
    },
    {
      "epoch": 4.074153450492927,
      "grad_norm": 0.00032394297886639833,
      "learning_rate": 1.4567795399342764e-05,
      "loss": 0.0001,
      "step": 19010
    },
    {
      "epoch": 4.076296613801972,
      "grad_norm": 0.00017796418978832662,
      "learning_rate": 1.4564937848264038e-05,
      "loss": 0.0002,
      "step": 19020
    },
    {
      "epoch": 4.078439777111016,
      "grad_norm": 0.00022935544257052243,
      "learning_rate": 1.4562080297185312e-05,
      "loss": 0.0005,
      "step": 19030
    },
    {
      "epoch": 4.08058294042006,
      "grad_norm": 0.06754640489816666,
      "learning_rate": 1.4559222746106588e-05,
      "loss": 0.1745,
      "step": 19040
    },
    {
      "epoch": 4.0827261037291045,
      "grad_norm": 0.0005022638943046331,
      "learning_rate": 1.4556365195027862e-05,
      "loss": 0.0001,
      "step": 19050
    },
    {
      "epoch": 4.084869267038148,
      "grad_norm": 0.005480504594743252,
      "learning_rate": 1.4553507643949136e-05,
      "loss": 0.0001,
      "step": 19060
    },
    {
      "epoch": 4.087012430347192,
      "grad_norm": 0.05226379260420799,
      "learning_rate": 1.4550650092870411e-05,
      "loss": 0.1572,
      "step": 19070
    },
    {
      "epoch": 4.089155593656237,
      "grad_norm": 0.00031745797605253756,
      "learning_rate": 1.4547792541791685e-05,
      "loss": 0.0006,
      "step": 19080
    },
    {
      "epoch": 4.091298756965281,
      "grad_norm": 0.0009107154328376055,
      "learning_rate": 1.454493499071296e-05,
      "loss": 0.0013,
      "step": 19090
    },
    {
      "epoch": 4.093441920274325,
      "grad_norm": 0.03625582531094551,
      "learning_rate": 1.4542077439634235e-05,
      "loss": 0.1841,
      "step": 19100
    },
    {
      "epoch": 4.095585083583369,
      "grad_norm": 0.0017875570338219404,
      "learning_rate": 1.4539219888555509e-05,
      "loss": 0.0002,
      "step": 19110
    },
    {
      "epoch": 4.097728246892413,
      "grad_norm": 0.0007351482636295259,
      "learning_rate": 1.4536362337476784e-05,
      "loss": 0.0003,
      "step": 19120
    },
    {
      "epoch": 4.099871410201457,
      "grad_norm": 0.0003554229624569416,
      "learning_rate": 1.4533504786398058e-05,
      "loss": 0.0006,
      "step": 19130
    },
    {
      "epoch": 4.102014573510502,
      "grad_norm": 0.0002667884109541774,
      "learning_rate": 1.4530647235319332e-05,
      "loss": 0.1891,
      "step": 19140
    },
    {
      "epoch": 4.104157736819546,
      "grad_norm": 0.0024890645872801542,
      "learning_rate": 1.4527789684240608e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 4.1063009001285895,
      "grad_norm": 0.07647485285997391,
      "learning_rate": 1.4524932133161882e-05,
      "loss": 0.0002,
      "step": 19160
    },
    {
      "epoch": 4.108444063437634,
      "grad_norm": 0.00014471622125711292,
      "learning_rate": 1.4522074582083157e-05,
      "loss": 0.0,
      "step": 19170
    },
    {
      "epoch": 4.110587226746678,
      "grad_norm": 0.0010166468564420938,
      "learning_rate": 1.4519217031004431e-05,
      "loss": 0.2717,
      "step": 19180
    },
    {
      "epoch": 4.112730390055722,
      "grad_norm": 0.0005414911429397762,
      "learning_rate": 1.4516359479925705e-05,
      "loss": 0.0,
      "step": 19190
    },
    {
      "epoch": 4.114873553364767,
      "grad_norm": 0.03327705338597298,
      "learning_rate": 1.451350192884698e-05,
      "loss": 0.1802,
      "step": 19200
    },
    {
      "epoch": 4.1170167166738105,
      "grad_norm": 0.0015125388745218515,
      "learning_rate": 1.4510644377768255e-05,
      "loss": 0.0758,
      "step": 19210
    },
    {
      "epoch": 4.119159879982854,
      "grad_norm": 0.001264083432033658,
      "learning_rate": 1.4507786826689527e-05,
      "loss": 0.1641,
      "step": 19220
    },
    {
      "epoch": 4.121303043291899,
      "grad_norm": 0.00046170499990694225,
      "learning_rate": 1.4504929275610802e-05,
      "loss": 0.0008,
      "step": 19230
    },
    {
      "epoch": 4.123446206600943,
      "grad_norm": 0.00013628817396238446,
      "learning_rate": 1.4502071724532076e-05,
      "loss": 0.0004,
      "step": 19240
    },
    {
      "epoch": 4.125589369909987,
      "grad_norm": 0.001867029583081603,
      "learning_rate": 1.449921417345335e-05,
      "loss": 0.0001,
      "step": 19250
    },
    {
      "epoch": 4.1277325332190316,
      "grad_norm": 0.00010904480586759746,
      "learning_rate": 1.4496356622374626e-05,
      "loss": 0.0001,
      "step": 19260
    },
    {
      "epoch": 4.129875696528075,
      "grad_norm": 0.0041130054742097855,
      "learning_rate": 1.44934990712959e-05,
      "loss": 0.3341,
      "step": 19270
    },
    {
      "epoch": 4.132018859837119,
      "grad_norm": 0.0007375028799287975,
      "learning_rate": 1.4490641520217174e-05,
      "loss": 0.0001,
      "step": 19280
    },
    {
      "epoch": 4.134162023146164,
      "grad_norm": 0.0005855436902493238,
      "learning_rate": 1.448778396913845e-05,
      "loss": 0.0001,
      "step": 19290
    },
    {
      "epoch": 4.136305186455208,
      "grad_norm": 0.0006420777644962072,
      "learning_rate": 1.4484926418059723e-05,
      "loss": 0.1632,
      "step": 19300
    },
    {
      "epoch": 4.138448349764252,
      "grad_norm": 0.001605591387487948,
      "learning_rate": 1.4482068866980999e-05,
      "loss": 0.0006,
      "step": 19310
    },
    {
      "epoch": 4.140591513073296,
      "grad_norm": 0.0006187199614942074,
      "learning_rate": 1.4479211315902273e-05,
      "loss": 0.0004,
      "step": 19320
    },
    {
      "epoch": 4.14273467638234,
      "grad_norm": 0.0003673648461699486,
      "learning_rate": 1.4476353764823547e-05,
      "loss": 0.0,
      "step": 19330
    },
    {
      "epoch": 4.144877839691384,
      "grad_norm": 0.0006011512596160173,
      "learning_rate": 1.4473496213744822e-05,
      "loss": 0.0,
      "step": 19340
    },
    {
      "epoch": 4.147021003000429,
      "grad_norm": 0.0004492975422181189,
      "learning_rate": 1.4470638662666096e-05,
      "loss": 0.0003,
      "step": 19350
    },
    {
      "epoch": 4.149164166309473,
      "grad_norm": 0.0012385660083964467,
      "learning_rate": 1.4467781111587372e-05,
      "loss": 0.365,
      "step": 19360
    },
    {
      "epoch": 4.151307329618517,
      "grad_norm": 0.006831279490143061,
      "learning_rate": 1.4464923560508646e-05,
      "loss": 0.0001,
      "step": 19370
    },
    {
      "epoch": 4.153450492927561,
      "grad_norm": 0.002356640761718154,
      "learning_rate": 1.446206600942992e-05,
      "loss": 0.0024,
      "step": 19380
    },
    {
      "epoch": 4.155593656236605,
      "grad_norm": 0.017442548647522926,
      "learning_rate": 1.4459208458351195e-05,
      "loss": 0.0001,
      "step": 19390
    },
    {
      "epoch": 4.157736819545649,
      "grad_norm": 0.0031758216209709644,
      "learning_rate": 1.445635090727247e-05,
      "loss": 0.0004,
      "step": 19400
    },
    {
      "epoch": 4.159879982854694,
      "grad_norm": 0.002280782675370574,
      "learning_rate": 1.4453493356193743e-05,
      "loss": 0.0001,
      "step": 19410
    },
    {
      "epoch": 4.162023146163738,
      "grad_norm": 0.004952456336468458,
      "learning_rate": 1.4450635805115019e-05,
      "loss": 0.1662,
      "step": 19420
    },
    {
      "epoch": 4.164166309472781,
      "grad_norm": 0.001635246560908854,
      "learning_rate": 1.4447778254036291e-05,
      "loss": 0.0006,
      "step": 19430
    },
    {
      "epoch": 4.166309472781826,
      "grad_norm": 0.00633955467492342,
      "learning_rate": 1.4444920702957565e-05,
      "loss": 0.0001,
      "step": 19440
    },
    {
      "epoch": 4.16845263609087,
      "grad_norm": 0.003172134980559349,
      "learning_rate": 1.444206315187884e-05,
      "loss": 0.0045,
      "step": 19450
    },
    {
      "epoch": 4.170595799399914,
      "grad_norm": 0.0025276511441916227,
      "learning_rate": 1.4439205600800115e-05,
      "loss": 0.0003,
      "step": 19460
    },
    {
      "epoch": 4.172738962708959,
      "grad_norm": 0.0031285742297768593,
      "learning_rate": 1.4436348049721389e-05,
      "loss": 0.0002,
      "step": 19470
    },
    {
      "epoch": 4.1748821260180025,
      "grad_norm": 0.037067726254463196,
      "learning_rate": 1.4433490498642664e-05,
      "loss": 0.2666,
      "step": 19480
    },
    {
      "epoch": 4.177025289327046,
      "grad_norm": 0.06746302545070648,
      "learning_rate": 1.4430632947563938e-05,
      "loss": 0.0003,
      "step": 19490
    },
    {
      "epoch": 4.179168452636091,
      "grad_norm": 0.4688180387020111,
      "learning_rate": 1.4427775396485214e-05,
      "loss": 0.0005,
      "step": 19500
    },
    {
      "epoch": 4.181311615945135,
      "grad_norm": 0.05095389857888222,
      "learning_rate": 1.4424917845406488e-05,
      "loss": 0.2897,
      "step": 19510
    },
    {
      "epoch": 4.183454779254179,
      "grad_norm": 0.030202895402908325,
      "learning_rate": 1.4422060294327762e-05,
      "loss": 0.2435,
      "step": 19520
    },
    {
      "epoch": 4.1855979425632235,
      "grad_norm": 165.47108459472656,
      "learning_rate": 1.4419202743249037e-05,
      "loss": 0.0696,
      "step": 19530
    },
    {
      "epoch": 4.187741105872267,
      "grad_norm": 0.0016484613297507167,
      "learning_rate": 1.4416345192170311e-05,
      "loss": 0.0001,
      "step": 19540
    },
    {
      "epoch": 4.189884269181311,
      "grad_norm": 0.0011086869053542614,
      "learning_rate": 1.4413487641091585e-05,
      "loss": 0.0001,
      "step": 19550
    },
    {
      "epoch": 4.192027432490356,
      "grad_norm": 0.0006510232924483716,
      "learning_rate": 1.441063009001286e-05,
      "loss": 0.0005,
      "step": 19560
    },
    {
      "epoch": 4.1941705957994,
      "grad_norm": 0.0020399740897119045,
      "learning_rate": 1.4407772538934135e-05,
      "loss": 0.1608,
      "step": 19570
    },
    {
      "epoch": 4.196313759108444,
      "grad_norm": 0.0010825160425156355,
      "learning_rate": 1.440491498785541e-05,
      "loss": 0.161,
      "step": 19580
    },
    {
      "epoch": 4.198456922417488,
      "grad_norm": 0.6968344449996948,
      "learning_rate": 1.4402057436776684e-05,
      "loss": 0.002,
      "step": 19590
    },
    {
      "epoch": 4.200600085726532,
      "grad_norm": 0.0014518386451527476,
      "learning_rate": 1.4399199885697958e-05,
      "loss": 0.1683,
      "step": 19600
    },
    {
      "epoch": 4.202743249035576,
      "grad_norm": 0.0011652532266452909,
      "learning_rate": 1.4396342334619234e-05,
      "loss": 0.2525,
      "step": 19610
    },
    {
      "epoch": 4.204886412344621,
      "grad_norm": 0.0015360432444140315,
      "learning_rate": 1.4393484783540508e-05,
      "loss": 0.0021,
      "step": 19620
    },
    {
      "epoch": 4.207029575653665,
      "grad_norm": 0.0020137731917202473,
      "learning_rate": 1.4390627232461782e-05,
      "loss": 0.0078,
      "step": 19630
    },
    {
      "epoch": 4.209172738962709,
      "grad_norm": 0.0010091643780469894,
      "learning_rate": 1.4387769681383057e-05,
      "loss": 0.0005,
      "step": 19640
    },
    {
      "epoch": 4.211315902271753,
      "grad_norm": 0.000999723095446825,
      "learning_rate": 1.438491213030433e-05,
      "loss": 0.0001,
      "step": 19650
    },
    {
      "epoch": 4.213459065580797,
      "grad_norm": 0.0007314308313652873,
      "learning_rate": 1.4382054579225603e-05,
      "loss": 0.0001,
      "step": 19660
    },
    {
      "epoch": 4.215602228889842,
      "grad_norm": 0.01808830536901951,
      "learning_rate": 1.4379197028146879e-05,
      "loss": 0.0003,
      "step": 19670
    },
    {
      "epoch": 4.217745392198886,
      "grad_norm": 0.0007196262013167143,
      "learning_rate": 1.4376339477068153e-05,
      "loss": 0.0001,
      "step": 19680
    },
    {
      "epoch": 4.2198885555079295,
      "grad_norm": 0.0027982627507299185,
      "learning_rate": 1.4373481925989427e-05,
      "loss": 0.0007,
      "step": 19690
    },
    {
      "epoch": 4.222031718816974,
      "grad_norm": 0.004117179196327925,
      "learning_rate": 1.4370624374910703e-05,
      "loss": 0.0003,
      "step": 19700
    },
    {
      "epoch": 4.224174882126018,
      "grad_norm": 0.0006556055159308016,
      "learning_rate": 1.4367766823831976e-05,
      "loss": 0.265,
      "step": 19710
    },
    {
      "epoch": 4.226318045435062,
      "grad_norm": 0.1074996218085289,
      "learning_rate": 1.4364909272753252e-05,
      "loss": 0.0001,
      "step": 19720
    },
    {
      "epoch": 4.228461208744107,
      "grad_norm": 0.011362908408045769,
      "learning_rate": 1.4362051721674526e-05,
      "loss": 0.0001,
      "step": 19730
    },
    {
      "epoch": 4.2306043720531505,
      "grad_norm": 0.00047515242476947606,
      "learning_rate": 1.43591941705958e-05,
      "loss": 0.0001,
      "step": 19740
    },
    {
      "epoch": 4.232747535362194,
      "grad_norm": 0.001120153465308249,
      "learning_rate": 1.4356336619517076e-05,
      "loss": 0.0004,
      "step": 19750
    },
    {
      "epoch": 4.234890698671239,
      "grad_norm": 0.00402385788038373,
      "learning_rate": 1.435347906843835e-05,
      "loss": 0.0001,
      "step": 19760
    },
    {
      "epoch": 4.237033861980283,
      "grad_norm": 0.00993757788091898,
      "learning_rate": 1.4350621517359623e-05,
      "loss": 0.0,
      "step": 19770
    },
    {
      "epoch": 4.239177025289327,
      "grad_norm": 0.0006993740098550916,
      "learning_rate": 1.4347763966280899e-05,
      "loss": 0.0001,
      "step": 19780
    },
    {
      "epoch": 4.241320188598372,
      "grad_norm": 0.00024165640934370458,
      "learning_rate": 1.4344906415202173e-05,
      "loss": 0.0,
      "step": 19790
    },
    {
      "epoch": 4.243463351907415,
      "grad_norm": 0.00027859440888278186,
      "learning_rate": 1.4342048864123449e-05,
      "loss": 0.1603,
      "step": 19800
    },
    {
      "epoch": 4.245606515216459,
      "grad_norm": 0.0539422370493412,
      "learning_rate": 1.4339191313044723e-05,
      "loss": 0.322,
      "step": 19810
    },
    {
      "epoch": 4.247749678525504,
      "grad_norm": 0.008463473990559578,
      "learning_rate": 1.4336333761965996e-05,
      "loss": 0.211,
      "step": 19820
    },
    {
      "epoch": 4.249892841834548,
      "grad_norm": 0.0027276482433080673,
      "learning_rate": 1.4333476210887272e-05,
      "loss": 0.0001,
      "step": 19830
    },
    {
      "epoch": 4.252036005143592,
      "grad_norm": 0.001387984142638743,
      "learning_rate": 1.4330618659808546e-05,
      "loss": 0.0,
      "step": 19840
    },
    {
      "epoch": 4.254179168452636,
      "grad_norm": 0.060985736548900604,
      "learning_rate": 1.432776110872982e-05,
      "loss": 0.2382,
      "step": 19850
    },
    {
      "epoch": 4.25632233176168,
      "grad_norm": 0.0016189664602279663,
      "learning_rate": 1.4324903557651094e-05,
      "loss": 0.0002,
      "step": 19860
    },
    {
      "epoch": 4.258465495070724,
      "grad_norm": 0.00234392611309886,
      "learning_rate": 1.4322046006572368e-05,
      "loss": 0.1862,
      "step": 19870
    },
    {
      "epoch": 4.260608658379769,
      "grad_norm": 26.86220359802246,
      "learning_rate": 1.4319188455493642e-05,
      "loss": 0.363,
      "step": 19880
    },
    {
      "epoch": 4.262751821688813,
      "grad_norm": 0.03102516569197178,
      "learning_rate": 1.4316330904414917e-05,
      "loss": 0.0947,
      "step": 19890
    },
    {
      "epoch": 4.264894984997857,
      "grad_norm": 0.014249885454773903,
      "learning_rate": 1.4313473353336191e-05,
      "loss": 0.0003,
      "step": 19900
    },
    {
      "epoch": 4.267038148306901,
      "grad_norm": 0.005633856635540724,
      "learning_rate": 1.4310615802257465e-05,
      "loss": 0.0006,
      "step": 19910
    },
    {
      "epoch": 4.269181311615945,
      "grad_norm": 18.58705711364746,
      "learning_rate": 1.430775825117874e-05,
      "loss": 0.3684,
      "step": 19920
    },
    {
      "epoch": 4.271324474924989,
      "grad_norm": 0.010508782230317593,
      "learning_rate": 1.4304900700100015e-05,
      "loss": 0.0003,
      "step": 19930
    },
    {
      "epoch": 4.273467638234034,
      "grad_norm": 0.005110751371830702,
      "learning_rate": 1.430204314902129e-05,
      "loss": 0.0001,
      "step": 19940
    },
    {
      "epoch": 4.275610801543078,
      "grad_norm": 0.003260345896705985,
      "learning_rate": 1.4299185597942564e-05,
      "loss": 0.2308,
      "step": 19950
    },
    {
      "epoch": 4.2777539648521214,
      "grad_norm": 0.004514778032898903,
      "learning_rate": 1.4296328046863838e-05,
      "loss": 0.0009,
      "step": 19960
    },
    {
      "epoch": 4.279897128161166,
      "grad_norm": 0.004755540285259485,
      "learning_rate": 1.4293470495785114e-05,
      "loss": 0.2029,
      "step": 19970
    },
    {
      "epoch": 4.28204029147021,
      "grad_norm": 0.035162553191185,
      "learning_rate": 1.4290612944706388e-05,
      "loss": 0.0645,
      "step": 19980
    },
    {
      "epoch": 4.284183454779254,
      "grad_norm": 0.004887085407972336,
      "learning_rate": 1.4287755393627662e-05,
      "loss": 0.1992,
      "step": 19990
    },
    {
      "epoch": 4.286326618088299,
      "grad_norm": 0.021418999880552292,
      "learning_rate": 1.4284897842548937e-05,
      "loss": 0.0193,
      "step": 20000
    },
    {
      "epoch": 4.2884697813973425,
      "grad_norm": 0.003250490641221404,
      "learning_rate": 1.4282040291470211e-05,
      "loss": 0.0009,
      "step": 20010
    },
    {
      "epoch": 4.290612944706386,
      "grad_norm": 0.0037578486371785402,
      "learning_rate": 1.4279182740391487e-05,
      "loss": 0.1851,
      "step": 20020
    },
    {
      "epoch": 4.292756108015431,
      "grad_norm": 0.006236688699573278,
      "learning_rate": 1.427632518931276e-05,
      "loss": 0.4138,
      "step": 20030
    },
    {
      "epoch": 4.294899271324475,
      "grad_norm": 0.14423996210098267,
      "learning_rate": 1.4273467638234035e-05,
      "loss": 0.0005,
      "step": 20040
    },
    {
      "epoch": 4.297042434633519,
      "grad_norm": 0.13479338586330414,
      "learning_rate": 1.427061008715531e-05,
      "loss": 0.179,
      "step": 20050
    },
    {
      "epoch": 4.2991855979425635,
      "grad_norm": 0.01788393221795559,
      "learning_rate": 1.4267752536076584e-05,
      "loss": 0.2777,
      "step": 20060
    },
    {
      "epoch": 4.301328761251607,
      "grad_norm": 0.06392619758844376,
      "learning_rate": 1.426489498499786e-05,
      "loss": 0.0016,
      "step": 20070
    },
    {
      "epoch": 4.303471924560651,
      "grad_norm": 0.0019574174657464027,
      "learning_rate": 1.4262037433919132e-05,
      "loss": 0.0005,
      "step": 20080
    },
    {
      "epoch": 4.305615087869696,
      "grad_norm": 0.0018221831414848566,
      "learning_rate": 1.4259179882840406e-05,
      "loss": 0.0003,
      "step": 20090
    },
    {
      "epoch": 4.30775825117874,
      "grad_norm": 0.0014051651814952493,
      "learning_rate": 1.425632233176168e-05,
      "loss": 0.0003,
      "step": 20100
    },
    {
      "epoch": 4.309901414487784,
      "grad_norm": 0.002134361770004034,
      "learning_rate": 1.4253464780682956e-05,
      "loss": 0.0002,
      "step": 20110
    },
    {
      "epoch": 4.312044577796828,
      "grad_norm": 0.0010467119282111526,
      "learning_rate": 1.425060722960423e-05,
      "loss": 0.0001,
      "step": 20120
    },
    {
      "epoch": 4.314187741105872,
      "grad_norm": 0.010335683822631836,
      "learning_rate": 1.4247749678525503e-05,
      "loss": 0.2825,
      "step": 20130
    },
    {
      "epoch": 4.316330904414916,
      "grad_norm": 0.00649612070992589,
      "learning_rate": 1.4244892127446779e-05,
      "loss": 0.0006,
      "step": 20140
    },
    {
      "epoch": 4.318474067723961,
      "grad_norm": 0.007429152727127075,
      "learning_rate": 1.4242034576368053e-05,
      "loss": 0.0005,
      "step": 20150
    },
    {
      "epoch": 4.320617231033005,
      "grad_norm": 0.02458941750228405,
      "learning_rate": 1.4239177025289329e-05,
      "loss": 0.0006,
      "step": 20160
    },
    {
      "epoch": 4.3227603943420485,
      "grad_norm": 0.003888997482135892,
      "learning_rate": 1.4236319474210603e-05,
      "loss": 0.4974,
      "step": 20170
    },
    {
      "epoch": 4.324903557651093,
      "grad_norm": 0.002374456962570548,
      "learning_rate": 1.4233461923131876e-05,
      "loss": 0.1736,
      "step": 20180
    },
    {
      "epoch": 4.327046720960137,
      "grad_norm": 0.29476198554039,
      "learning_rate": 1.4230604372053152e-05,
      "loss": 0.5001,
      "step": 20190
    },
    {
      "epoch": 4.329189884269181,
      "grad_norm": 0.052351146936416626,
      "learning_rate": 1.4227746820974426e-05,
      "loss": 0.0014,
      "step": 20200
    },
    {
      "epoch": 4.331333047578226,
      "grad_norm": 0.23478911817073822,
      "learning_rate": 1.4224889269895702e-05,
      "loss": 0.1534,
      "step": 20210
    },
    {
      "epoch": 4.3334762108872695,
      "grad_norm": 0.0046503241173923016,
      "learning_rate": 1.4222031718816976e-05,
      "loss": 0.1574,
      "step": 20220
    },
    {
      "epoch": 4.335619374196313,
      "grad_norm": 0.02383546531200409,
      "learning_rate": 1.421917416773825e-05,
      "loss": 0.0006,
      "step": 20230
    },
    {
      "epoch": 4.337762537505358,
      "grad_norm": 0.0026582826394587755,
      "learning_rate": 1.4216316616659525e-05,
      "loss": 0.145,
      "step": 20240
    },
    {
      "epoch": 4.339905700814402,
      "grad_norm": 0.004081908613443375,
      "learning_rate": 1.4213459065580799e-05,
      "loss": 0.1493,
      "step": 20250
    },
    {
      "epoch": 4.342048864123446,
      "grad_norm": 0.002359051490202546,
      "learning_rate": 1.4210601514502073e-05,
      "loss": 0.0006,
      "step": 20260
    },
    {
      "epoch": 4.3441920274324906,
      "grad_norm": 0.003778365906327963,
      "learning_rate": 1.4207743963423349e-05,
      "loss": 0.1093,
      "step": 20270
    },
    {
      "epoch": 4.346335190741534,
      "grad_norm": 0.15446196496486664,
      "learning_rate": 1.4204886412344623e-05,
      "loss": 0.0003,
      "step": 20280
    },
    {
      "epoch": 4.348478354050578,
      "grad_norm": 0.6321483850479126,
      "learning_rate": 1.4202028861265895e-05,
      "loss": 0.0014,
      "step": 20290
    },
    {
      "epoch": 4.350621517359623,
      "grad_norm": 0.0014651159290224314,
      "learning_rate": 1.419917131018717e-05,
      "loss": 0.1503,
      "step": 20300
    },
    {
      "epoch": 4.352764680668667,
      "grad_norm": 0.18910472095012665,
      "learning_rate": 1.4196313759108444e-05,
      "loss": 0.0017,
      "step": 20310
    },
    {
      "epoch": 4.354907843977711,
      "grad_norm": 0.46261754631996155,
      "learning_rate": 1.4193456208029718e-05,
      "loss": 0.0011,
      "step": 20320
    },
    {
      "epoch": 4.357051007286755,
      "grad_norm": 0.0008126044413074851,
      "learning_rate": 1.4190598656950994e-05,
      "loss": 0.094,
      "step": 20330
    },
    {
      "epoch": 4.359194170595799,
      "grad_norm": 0.002056697616353631,
      "learning_rate": 1.4187741105872268e-05,
      "loss": 0.0001,
      "step": 20340
    },
    {
      "epoch": 4.361337333904844,
      "grad_norm": 0.7828140258789062,
      "learning_rate": 1.4184883554793543e-05,
      "loss": 0.1452,
      "step": 20350
    },
    {
      "epoch": 4.363480497213888,
      "grad_norm": 0.0008443064871244133,
      "learning_rate": 1.4182026003714817e-05,
      "loss": 0.1444,
      "step": 20360
    },
    {
      "epoch": 4.365623660522932,
      "grad_norm": 0.0006488373037427664,
      "learning_rate": 1.4179168452636091e-05,
      "loss": 0.1407,
      "step": 20370
    },
    {
      "epoch": 4.3677668238319765,
      "grad_norm": 0.0014113185461610556,
      "learning_rate": 1.4176310901557367e-05,
      "loss": 0.0,
      "step": 20380
    },
    {
      "epoch": 4.36990998714102,
      "grad_norm": 0.0009132696432061493,
      "learning_rate": 1.417345335047864e-05,
      "loss": 0.0001,
      "step": 20390
    },
    {
      "epoch": 4.372053150450064,
      "grad_norm": 0.0016776437405496836,
      "learning_rate": 1.4170595799399915e-05,
      "loss": 0.646,
      "step": 20400
    },
    {
      "epoch": 4.374196313759109,
      "grad_norm": 0.005609230138361454,
      "learning_rate": 1.416773824832119e-05,
      "loss": 0.0046,
      "step": 20410
    },
    {
      "epoch": 4.376339477068153,
      "grad_norm": 43.209571838378906,
      "learning_rate": 1.4164880697242464e-05,
      "loss": 0.3099,
      "step": 20420
    },
    {
      "epoch": 4.378482640377197,
      "grad_norm": 0.5461189150810242,
      "learning_rate": 1.416202314616374e-05,
      "loss": 0.323,
      "step": 20430
    },
    {
      "epoch": 4.380625803686241,
      "grad_norm": 0.020200984552502632,
      "learning_rate": 1.4159165595085014e-05,
      "loss": 0.0337,
      "step": 20440
    },
    {
      "epoch": 4.382768966995285,
      "grad_norm": 0.009149841964244843,
      "learning_rate": 1.4156308044006288e-05,
      "loss": 0.1791,
      "step": 20450
    },
    {
      "epoch": 4.384912130304329,
      "grad_norm": 0.009901843033730984,
      "learning_rate": 1.4153450492927563e-05,
      "loss": 0.0006,
      "step": 20460
    },
    {
      "epoch": 4.387055293613374,
      "grad_norm": 0.10426349192857742,
      "learning_rate": 1.4150592941848837e-05,
      "loss": 0.0004,
      "step": 20470
    },
    {
      "epoch": 4.389198456922418,
      "grad_norm": 0.04013270512223244,
      "learning_rate": 1.4147735390770111e-05,
      "loss": 0.0004,
      "step": 20480
    },
    {
      "epoch": 4.3913416202314615,
      "grad_norm": 1.4763392210006714,
      "learning_rate": 1.4144877839691387e-05,
      "loss": 0.2375,
      "step": 20490
    },
    {
      "epoch": 4.393484783540506,
      "grad_norm": 0.6045023202896118,
      "learning_rate": 1.414202028861266e-05,
      "loss": 0.1564,
      "step": 20500
    },
    {
      "epoch": 4.39562794684955,
      "grad_norm": 0.043885260820388794,
      "learning_rate": 1.4139162737533933e-05,
      "loss": 0.1502,
      "step": 20510
    },
    {
      "epoch": 4.397771110158594,
      "grad_norm": 0.006160642020404339,
      "learning_rate": 1.4136305186455209e-05,
      "loss": 0.1652,
      "step": 20520
    },
    {
      "epoch": 4.399914273467639,
      "grad_norm": 0.006398066878318787,
      "learning_rate": 1.4133447635376483e-05,
      "loss": 0.0024,
      "step": 20530
    },
    {
      "epoch": 4.4020574367766825,
      "grad_norm": 0.0039566936902701855,
      "learning_rate": 1.4130590084297757e-05,
      "loss": 0.0008,
      "step": 20540
    },
    {
      "epoch": 4.404200600085726,
      "grad_norm": 0.007610753644257784,
      "learning_rate": 1.4127732533219032e-05,
      "loss": 0.0004,
      "step": 20550
    },
    {
      "epoch": 4.406343763394771,
      "grad_norm": 0.004778729286044836,
      "learning_rate": 1.4124874982140306e-05,
      "loss": 0.0003,
      "step": 20560
    },
    {
      "epoch": 4.408486926703815,
      "grad_norm": 0.002181663876399398,
      "learning_rate": 1.4122017431061582e-05,
      "loss": 0.4538,
      "step": 20570
    },
    {
      "epoch": 4.410630090012859,
      "grad_norm": 0.005742558743804693,
      "learning_rate": 1.4119159879982856e-05,
      "loss": 0.0005,
      "step": 20580
    },
    {
      "epoch": 4.4127732533219035,
      "grad_norm": 0.10090970247983932,
      "learning_rate": 1.411630232890413e-05,
      "loss": 0.0363,
      "step": 20590
    },
    {
      "epoch": 4.414916416630947,
      "grad_norm": 0.004012744408100843,
      "learning_rate": 1.4113444777825405e-05,
      "loss": 0.0005,
      "step": 20600
    },
    {
      "epoch": 4.417059579939991,
      "grad_norm": 0.005785039160400629,
      "learning_rate": 1.4110587226746679e-05,
      "loss": 0.0002,
      "step": 20610
    },
    {
      "epoch": 4.419202743249036,
      "grad_norm": 0.00313414609991014,
      "learning_rate": 1.4107729675667953e-05,
      "loss": 0.2282,
      "step": 20620
    },
    {
      "epoch": 4.42134590655808,
      "grad_norm": 0.038475945591926575,
      "learning_rate": 1.4104872124589229e-05,
      "loss": 0.1676,
      "step": 20630
    },
    {
      "epoch": 4.423489069867124,
      "grad_norm": 0.006110604386776686,
      "learning_rate": 1.4102014573510503e-05,
      "loss": 0.0004,
      "step": 20640
    },
    {
      "epoch": 4.425632233176168,
      "grad_norm": 0.07958792895078659,
      "learning_rate": 1.4099157022431778e-05,
      "loss": 0.0005,
      "step": 20650
    },
    {
      "epoch": 4.427775396485212,
      "grad_norm": 0.005241360515356064,
      "learning_rate": 1.4096299471353052e-05,
      "loss": 0.0023,
      "step": 20660
    },
    {
      "epoch": 4.429918559794256,
      "grad_norm": 0.008849631063640118,
      "learning_rate": 1.4093441920274326e-05,
      "loss": 0.0009,
      "step": 20670
    },
    {
      "epoch": 4.432061723103301,
      "grad_norm": 0.0015198546461760998,
      "learning_rate": 1.4090584369195602e-05,
      "loss": 0.0001,
      "step": 20680
    },
    {
      "epoch": 4.434204886412345,
      "grad_norm": 0.012695778161287308,
      "learning_rate": 1.4087726818116876e-05,
      "loss": 0.0002,
      "step": 20690
    },
    {
      "epoch": 4.4363480497213885,
      "grad_norm": 0.1039990782737732,
      "learning_rate": 1.408486926703815e-05,
      "loss": 0.1691,
      "step": 20700
    },
    {
      "epoch": 4.438491213030433,
      "grad_norm": 0.0009355797665193677,
      "learning_rate": 1.4082011715959425e-05,
      "loss": 0.0001,
      "step": 20710
    },
    {
      "epoch": 4.440634376339477,
      "grad_norm": 0.013271930627524853,
      "learning_rate": 1.4079154164880697e-05,
      "loss": 0.0001,
      "step": 20720
    },
    {
      "epoch": 4.442777539648521,
      "grad_norm": 0.0010736787226051092,
      "learning_rate": 1.4076296613801971e-05,
      "loss": 0.0001,
      "step": 20730
    },
    {
      "epoch": 4.444920702957566,
      "grad_norm": 0.01828305423259735,
      "learning_rate": 1.4073439062723247e-05,
      "loss": 0.4183,
      "step": 20740
    },
    {
      "epoch": 4.4470638662666095,
      "grad_norm": 0.0016725314781069756,
      "learning_rate": 1.4070581511644521e-05,
      "loss": 0.1133,
      "step": 20750
    },
    {
      "epoch": 4.449207029575653,
      "grad_norm": 0.0035586340818554163,
      "learning_rate": 1.4067723960565795e-05,
      "loss": 0.0015,
      "step": 20760
    },
    {
      "epoch": 4.451350192884698,
      "grad_norm": 47.03535461425781,
      "learning_rate": 1.406486640948707e-05,
      "loss": 0.0007,
      "step": 20770
    },
    {
      "epoch": 4.453493356193742,
      "grad_norm": 0.007144617848098278,
      "learning_rate": 1.4062008858408344e-05,
      "loss": 0.0002,
      "step": 20780
    },
    {
      "epoch": 4.455636519502786,
      "grad_norm": 0.0012038645800203085,
      "learning_rate": 1.405915130732962e-05,
      "loss": 0.0001,
      "step": 20790
    },
    {
      "epoch": 4.457779682811831,
      "grad_norm": 0.0874733179807663,
      "learning_rate": 1.4056293756250894e-05,
      "loss": 0.1791,
      "step": 20800
    },
    {
      "epoch": 4.459922846120874,
      "grad_norm": 0.0010736290132626891,
      "learning_rate": 1.4053436205172168e-05,
      "loss": 0.0002,
      "step": 20810
    },
    {
      "epoch": 4.462066009429918,
      "grad_norm": 0.008635845966637135,
      "learning_rate": 1.4050578654093443e-05,
      "loss": 0.0002,
      "step": 20820
    },
    {
      "epoch": 4.464209172738963,
      "grad_norm": 0.0008555544191040099,
      "learning_rate": 1.4047721103014717e-05,
      "loss": 0.0003,
      "step": 20830
    },
    {
      "epoch": 4.466352336048007,
      "grad_norm": 0.0017852048622444272,
      "learning_rate": 1.4044863551935991e-05,
      "loss": 0.0,
      "step": 20840
    },
    {
      "epoch": 4.468495499357051,
      "grad_norm": 0.016634486615657806,
      "learning_rate": 1.4042006000857267e-05,
      "loss": 0.4352,
      "step": 20850
    },
    {
      "epoch": 4.470638662666095,
      "grad_norm": 0.08407628536224365,
      "learning_rate": 1.4039148449778541e-05,
      "loss": 0.0003,
      "step": 20860
    },
    {
      "epoch": 4.472781825975139,
      "grad_norm": 0.11028461903333664,
      "learning_rate": 1.4036290898699816e-05,
      "loss": 0.0003,
      "step": 20870
    },
    {
      "epoch": 4.474924989284183,
      "grad_norm": 0.0013223913265392184,
      "learning_rate": 1.403343334762109e-05,
      "loss": 0.001,
      "step": 20880
    },
    {
      "epoch": 4.477068152593228,
      "grad_norm": 0.29066333174705505,
      "learning_rate": 1.4030575796542364e-05,
      "loss": 0.0009,
      "step": 20890
    },
    {
      "epoch": 4.479211315902272,
      "grad_norm": 0.0013352381065487862,
      "learning_rate": 1.402771824546364e-05,
      "loss": 0.4594,
      "step": 20900
    },
    {
      "epoch": 4.481354479211316,
      "grad_norm": 0.0006776397931389511,
      "learning_rate": 1.4024860694384914e-05,
      "loss": 0.0001,
      "step": 20910
    },
    {
      "epoch": 4.48349764252036,
      "grad_norm": 0.001181075582280755,
      "learning_rate": 1.402200314330619e-05,
      "loss": 0.0002,
      "step": 20920
    },
    {
      "epoch": 4.485640805829404,
      "grad_norm": 0.0417170412838459,
      "learning_rate": 1.4019145592227463e-05,
      "loss": 0.0004,
      "step": 20930
    },
    {
      "epoch": 4.487783969138448,
      "grad_norm": 0.001465996727347374,
      "learning_rate": 1.4016288041148736e-05,
      "loss": 0.0001,
      "step": 20940
    },
    {
      "epoch": 4.489927132447493,
      "grad_norm": 0.0005503015709109604,
      "learning_rate": 1.401343049007001e-05,
      "loss": 0.0001,
      "step": 20950
    },
    {
      "epoch": 4.492070295756537,
      "grad_norm": 0.0013410925166681409,
      "learning_rate": 1.4010572938991285e-05,
      "loss": 0.0005,
      "step": 20960
    },
    {
      "epoch": 4.4942134590655805,
      "grad_norm": 0.0005304903024807572,
      "learning_rate": 1.400771538791256e-05,
      "loss": 0.0,
      "step": 20970
    },
    {
      "epoch": 4.496356622374625,
      "grad_norm": 0.006757048889994621,
      "learning_rate": 1.4004857836833833e-05,
      "loss": 0.0002,
      "step": 20980
    },
    {
      "epoch": 4.498499785683669,
      "grad_norm": 0.0006299504893831909,
      "learning_rate": 1.4002000285755109e-05,
      "loss": 0.0001,
      "step": 20990
    },
    {
      "epoch": 4.500642948992713,
      "grad_norm": 0.000497003027703613,
      "learning_rate": 1.3999142734676383e-05,
      "loss": 0.0001,
      "step": 21000
    },
    {
      "epoch": 4.502786112301758,
      "grad_norm": 0.00047632810310460627,
      "learning_rate": 1.3996285183597658e-05,
      "loss": 0.0,
      "step": 21010
    },
    {
      "epoch": 4.5049292756108015,
      "grad_norm": 0.03747555986046791,
      "learning_rate": 1.3993427632518932e-05,
      "loss": 0.2273,
      "step": 21020
    },
    {
      "epoch": 4.507072438919845,
      "grad_norm": 0.0008649674709886312,
      "learning_rate": 1.3990570081440206e-05,
      "loss": 0.0001,
      "step": 21030
    },
    {
      "epoch": 4.50921560222889,
      "grad_norm": 0.0005307346000336111,
      "learning_rate": 1.3987712530361482e-05,
      "loss": 0.1396,
      "step": 21040
    },
    {
      "epoch": 4.511358765537934,
      "grad_norm": 0.024709761142730713,
      "learning_rate": 1.3984854979282756e-05,
      "loss": 0.1912,
      "step": 21050
    },
    {
      "epoch": 4.513501928846978,
      "grad_norm": 0.0005859279772266746,
      "learning_rate": 1.3981997428204031e-05,
      "loss": 0.0003,
      "step": 21060
    },
    {
      "epoch": 4.5156450921560225,
      "grad_norm": 0.008201084099709988,
      "learning_rate": 1.3979139877125305e-05,
      "loss": 0.4438,
      "step": 21070
    },
    {
      "epoch": 4.517788255465066,
      "grad_norm": 0.05224428325891495,
      "learning_rate": 1.397628232604658e-05,
      "loss": 0.0002,
      "step": 21080
    },
    {
      "epoch": 4.51993141877411,
      "grad_norm": 0.10111886262893677,
      "learning_rate": 1.3973424774967855e-05,
      "loss": 0.0005,
      "step": 21090
    },
    {
      "epoch": 4.522074582083155,
      "grad_norm": 0.03387001156806946,
      "learning_rate": 1.3970567223889129e-05,
      "loss": 0.0004,
      "step": 21100
    },
    {
      "epoch": 4.524217745392199,
      "grad_norm": 0.0005163998575881124,
      "learning_rate": 1.3967709672810403e-05,
      "loss": 0.0002,
      "step": 21110
    },
    {
      "epoch": 4.526360908701243,
      "grad_norm": 0.020160973072052002,
      "learning_rate": 1.3964852121731678e-05,
      "loss": 0.0002,
      "step": 21120
    },
    {
      "epoch": 4.528504072010287,
      "grad_norm": 0.002443701261654496,
      "learning_rate": 1.3961994570652952e-05,
      "loss": 0.1365,
      "step": 21130
    },
    {
      "epoch": 4.530647235319331,
      "grad_norm": 0.060775090008974075,
      "learning_rate": 1.3959137019574228e-05,
      "loss": 0.1697,
      "step": 21140
    },
    {
      "epoch": 4.532790398628375,
      "grad_norm": 0.030779292806982994,
      "learning_rate": 1.39562794684955e-05,
      "loss": 0.1377,
      "step": 21150
    },
    {
      "epoch": 4.53493356193742,
      "grad_norm": 0.0007662696880288422,
      "learning_rate": 1.3953421917416774e-05,
      "loss": 0.0013,
      "step": 21160
    },
    {
      "epoch": 4.537076725246464,
      "grad_norm": 0.002317508915439248,
      "learning_rate": 1.3950564366338048e-05,
      "loss": 0.0001,
      "step": 21170
    },
    {
      "epoch": 4.5392198885555075,
      "grad_norm": 0.00037705485010519624,
      "learning_rate": 1.3947706815259324e-05,
      "loss": 0.3019,
      "step": 21180
    },
    {
      "epoch": 4.541363051864552,
      "grad_norm": 0.2081066519021988,
      "learning_rate": 1.3944849264180597e-05,
      "loss": 0.0008,
      "step": 21190
    },
    {
      "epoch": 4.543506215173596,
      "grad_norm": 0.026448119431734085,
      "learning_rate": 1.3941991713101873e-05,
      "loss": 0.0033,
      "step": 21200
    },
    {
      "epoch": 4.54564937848264,
      "grad_norm": 0.02011609449982643,
      "learning_rate": 1.3939134162023147e-05,
      "loss": 0.2316,
      "step": 21210
    },
    {
      "epoch": 4.547792541791685,
      "grad_norm": 0.0011326323729008436,
      "learning_rate": 1.3936276610944421e-05,
      "loss": 0.0001,
      "step": 21220
    },
    {
      "epoch": 4.5499357051007285,
      "grad_norm": 0.03508162498474121,
      "learning_rate": 1.3933419059865697e-05,
      "loss": 0.0002,
      "step": 21230
    },
    {
      "epoch": 4.552078868409772,
      "grad_norm": 0.03064536303281784,
      "learning_rate": 1.393056150878697e-05,
      "loss": 0.0007,
      "step": 21240
    },
    {
      "epoch": 4.554222031718817,
      "grad_norm": 0.00047337866271845996,
      "learning_rate": 1.3927703957708244e-05,
      "loss": 0.0001,
      "step": 21250
    },
    {
      "epoch": 4.556365195027861,
      "grad_norm": 0.00027506385231390595,
      "learning_rate": 1.392484640662952e-05,
      "loss": 0.0001,
      "step": 21260
    },
    {
      "epoch": 4.558508358336905,
      "grad_norm": 0.005902691278606653,
      "learning_rate": 1.3921988855550794e-05,
      "loss": 0.5731,
      "step": 21270
    },
    {
      "epoch": 4.56065152164595,
      "grad_norm": 0.052323512732982635,
      "learning_rate": 1.391913130447207e-05,
      "loss": 0.0023,
      "step": 21280
    },
    {
      "epoch": 4.562794684954993,
      "grad_norm": 0.0025335887912660837,
      "learning_rate": 1.3916273753393344e-05,
      "loss": 0.0005,
      "step": 21290
    },
    {
      "epoch": 4.564937848264037,
      "grad_norm": 0.0038664175663143396,
      "learning_rate": 1.3913416202314617e-05,
      "loss": 0.0009,
      "step": 21300
    },
    {
      "epoch": 4.567081011573082,
      "grad_norm": 0.006324527785181999,
      "learning_rate": 1.3910558651235893e-05,
      "loss": 0.0001,
      "step": 21310
    },
    {
      "epoch": 4.569224174882126,
      "grad_norm": 0.018036428838968277,
      "learning_rate": 1.3907701100157167e-05,
      "loss": 0.2089,
      "step": 21320
    },
    {
      "epoch": 4.57136733819117,
      "grad_norm": 0.003917762544006109,
      "learning_rate": 1.3904843549078441e-05,
      "loss": 0.0007,
      "step": 21330
    },
    {
      "epoch": 4.573510501500214,
      "grad_norm": 0.0022788522765040398,
      "learning_rate": 1.3901985997999717e-05,
      "loss": 0.0832,
      "step": 21340
    },
    {
      "epoch": 4.575653664809258,
      "grad_norm": 0.0029465274419635534,
      "learning_rate": 1.389912844692099e-05,
      "loss": 0.001,
      "step": 21350
    },
    {
      "epoch": 4.577796828118302,
      "grad_norm": 0.0016592200845479965,
      "learning_rate": 1.3896270895842266e-05,
      "loss": 0.0005,
      "step": 21360
    },
    {
      "epoch": 4.579939991427347,
      "grad_norm": 0.0005021659308113158,
      "learning_rate": 1.3893413344763538e-05,
      "loss": 0.0004,
      "step": 21370
    },
    {
      "epoch": 4.582083154736391,
      "grad_norm": 0.03586139157414436,
      "learning_rate": 1.3890555793684812e-05,
      "loss": 0.2114,
      "step": 21380
    },
    {
      "epoch": 4.584226318045435,
      "grad_norm": 0.0009764795540831983,
      "learning_rate": 1.3887698242606086e-05,
      "loss": 0.0002,
      "step": 21390
    },
    {
      "epoch": 4.586369481354479,
      "grad_norm": 0.015351921319961548,
      "learning_rate": 1.3884840691527362e-05,
      "loss": 0.0001,
      "step": 21400
    },
    {
      "epoch": 4.588512644663523,
      "grad_norm": 0.0003234702453482896,
      "learning_rate": 1.3881983140448636e-05,
      "loss": 0.2034,
      "step": 21410
    },
    {
      "epoch": 4.590655807972568,
      "grad_norm": 0.0005668431986123323,
      "learning_rate": 1.3879125589369911e-05,
      "loss": 0.0001,
      "step": 21420
    },
    {
      "epoch": 4.592798971281612,
      "grad_norm": 0.0004025351954624057,
      "learning_rate": 1.3876268038291185e-05,
      "loss": 0.2265,
      "step": 21430
    },
    {
      "epoch": 4.594942134590656,
      "grad_norm": 0.022567516192793846,
      "learning_rate": 1.387341048721246e-05,
      "loss": 0.0002,
      "step": 21440
    },
    {
      "epoch": 4.5970852978997,
      "grad_norm": 0.0017800091300159693,
      "learning_rate": 1.3870552936133735e-05,
      "loss": 0.2125,
      "step": 21450
    },
    {
      "epoch": 4.599228461208744,
      "grad_norm": 0.027429306879639626,
      "learning_rate": 1.3867695385055009e-05,
      "loss": 0.0002,
      "step": 21460
    },
    {
      "epoch": 4.601371624517788,
      "grad_norm": 0.001575359026901424,
      "learning_rate": 1.3864837833976283e-05,
      "loss": 0.0003,
      "step": 21470
    },
    {
      "epoch": 4.603514787826833,
      "grad_norm": 0.0006612419965676963,
      "learning_rate": 1.3861980282897558e-05,
      "loss": 0.0001,
      "step": 21480
    },
    {
      "epoch": 4.605657951135877,
      "grad_norm": 0.00072525255382061,
      "learning_rate": 1.3859122731818832e-05,
      "loss": 0.0002,
      "step": 21490
    },
    {
      "epoch": 4.6078011144449205,
      "grad_norm": 0.05565906688570976,
      "learning_rate": 1.3856265180740108e-05,
      "loss": 0.0004,
      "step": 21500
    },
    {
      "epoch": 4.609944277753965,
      "grad_norm": 0.05183906853199005,
      "learning_rate": 1.3853407629661382e-05,
      "loss": 0.0002,
      "step": 21510
    },
    {
      "epoch": 4.612087441063009,
      "grad_norm": 0.00077171775046736,
      "learning_rate": 1.3850550078582656e-05,
      "loss": 0.0003,
      "step": 21520
    },
    {
      "epoch": 4.614230604372053,
      "grad_norm": 0.00046701793326064944,
      "learning_rate": 1.3847692527503931e-05,
      "loss": 0.0001,
      "step": 21530
    },
    {
      "epoch": 4.616373767681098,
      "grad_norm": 0.0002876687503885478,
      "learning_rate": 1.3844834976425205e-05,
      "loss": 0.17,
      "step": 21540
    },
    {
      "epoch": 4.6185169309901415,
      "grad_norm": 0.029870398342609406,
      "learning_rate": 1.384197742534648e-05,
      "loss": 0.3817,
      "step": 21550
    },
    {
      "epoch": 4.620660094299185,
      "grad_norm": 0.0020067582372576,
      "learning_rate": 1.3839119874267755e-05,
      "loss": 0.167,
      "step": 21560
    },
    {
      "epoch": 4.62280325760823,
      "grad_norm": 0.0027610461693257093,
      "learning_rate": 1.3836262323189029e-05,
      "loss": 0.0015,
      "step": 21570
    },
    {
      "epoch": 4.624946420917274,
      "grad_norm": 58.15721893310547,
      "learning_rate": 1.3833404772110301e-05,
      "loss": 0.2463,
      "step": 21580
    },
    {
      "epoch": 4.627089584226318,
      "grad_norm": 0.0006062215543352067,
      "learning_rate": 1.3830547221031577e-05,
      "loss": 0.1561,
      "step": 21590
    },
    {
      "epoch": 4.6292327475353625,
      "grad_norm": 0.0008571338839828968,
      "learning_rate": 1.382768966995285e-05,
      "loss": 0.0001,
      "step": 21600
    },
    {
      "epoch": 4.631375910844406,
      "grad_norm": 0.0005373947788029909,
      "learning_rate": 1.3824832118874124e-05,
      "loss": 0.0001,
      "step": 21610
    },
    {
      "epoch": 4.63351907415345,
      "grad_norm": 0.0006505105993710458,
      "learning_rate": 1.38219745677954e-05,
      "loss": 0.0001,
      "step": 21620
    },
    {
      "epoch": 4.635662237462495,
      "grad_norm": 0.15130674839019775,
      "learning_rate": 1.3819117016716674e-05,
      "loss": 0.3579,
      "step": 21630
    },
    {
      "epoch": 4.637805400771539,
      "grad_norm": 0.0026762839406728745,
      "learning_rate": 1.381625946563795e-05,
      "loss": 0.3807,
      "step": 21640
    },
    {
      "epoch": 4.639948564080583,
      "grad_norm": 0.018420327454805374,
      "learning_rate": 1.3813401914559224e-05,
      "loss": 0.001,
      "step": 21650
    },
    {
      "epoch": 4.642091727389627,
      "grad_norm": 0.0343468077480793,
      "learning_rate": 1.3810544363480497e-05,
      "loss": 0.0024,
      "step": 21660
    },
    {
      "epoch": 4.644234890698671,
      "grad_norm": 0.017145583406090736,
      "learning_rate": 1.3807686812401773e-05,
      "loss": 0.0022,
      "step": 21670
    },
    {
      "epoch": 4.646378054007715,
      "grad_norm": 32.14560317993164,
      "learning_rate": 1.3804829261323047e-05,
      "loss": 0.3555,
      "step": 21680
    },
    {
      "epoch": 4.64852121731676,
      "grad_norm": 0.001118836342357099,
      "learning_rate": 1.3801971710244321e-05,
      "loss": 0.003,
      "step": 21690
    },
    {
      "epoch": 4.650664380625804,
      "grad_norm": 0.033015843480825424,
      "learning_rate": 1.3799114159165597e-05,
      "loss": 0.0019,
      "step": 21700
    },
    {
      "epoch": 4.6528075439348475,
      "grad_norm": 0.01159253716468811,
      "learning_rate": 1.379625660808687e-05,
      "loss": 0.0001,
      "step": 21710
    },
    {
      "epoch": 4.654950707243892,
      "grad_norm": 0.013984470628201962,
      "learning_rate": 1.3793399057008146e-05,
      "loss": 0.0004,
      "step": 21720
    },
    {
      "epoch": 4.657093870552936,
      "grad_norm": 0.015032421797513962,
      "learning_rate": 1.379054150592942e-05,
      "loss": 0.167,
      "step": 21730
    },
    {
      "epoch": 4.65923703386198,
      "grad_norm": 0.000814475875813514,
      "learning_rate": 1.3787683954850694e-05,
      "loss": 0.0001,
      "step": 21740
    },
    {
      "epoch": 4.661380197171025,
      "grad_norm": 0.0007256600656546652,
      "learning_rate": 1.378482640377197e-05,
      "loss": 0.0007,
      "step": 21750
    },
    {
      "epoch": 4.6635233604800685,
      "grad_norm": 0.07851480692625046,
      "learning_rate": 1.3781968852693244e-05,
      "loss": 0.2311,
      "step": 21760
    },
    {
      "epoch": 4.665666523789112,
      "grad_norm": 0.0016653882339596748,
      "learning_rate": 1.377911130161452e-05,
      "loss": 0.0002,
      "step": 21770
    },
    {
      "epoch": 4.667809687098157,
      "grad_norm": 0.001120522734709084,
      "learning_rate": 1.3776253750535793e-05,
      "loss": 0.0003,
      "step": 21780
    },
    {
      "epoch": 4.669952850407201,
      "grad_norm": 0.0009426939650438726,
      "learning_rate": 1.3773396199457067e-05,
      "loss": 0.0001,
      "step": 21790
    },
    {
      "epoch": 4.672096013716245,
      "grad_norm": 0.023395545780658722,
      "learning_rate": 1.377053864837834e-05,
      "loss": 0.0883,
      "step": 21800
    },
    {
      "epoch": 4.67423917702529,
      "grad_norm": 0.016064757481217384,
      "learning_rate": 1.3767681097299615e-05,
      "loss": 0.0002,
      "step": 21810
    },
    {
      "epoch": 4.676382340334333,
      "grad_norm": 18.318649291992188,
      "learning_rate": 1.3764823546220889e-05,
      "loss": 0.1703,
      "step": 21820
    },
    {
      "epoch": 4.678525503643377,
      "grad_norm": 0.0009095003479160368,
      "learning_rate": 1.3761965995142163e-05,
      "loss": 0.0003,
      "step": 21830
    },
    {
      "epoch": 4.680668666952422,
      "grad_norm": 0.0005245106876827776,
      "learning_rate": 1.3759108444063438e-05,
      "loss": 0.0001,
      "step": 21840
    },
    {
      "epoch": 4.682811830261466,
      "grad_norm": 0.03320989012718201,
      "learning_rate": 1.3756250892984712e-05,
      "loss": 0.0005,
      "step": 21850
    },
    {
      "epoch": 4.68495499357051,
      "grad_norm": 1.2466239929199219,
      "learning_rate": 1.3753393341905988e-05,
      "loss": 0.0009,
      "step": 21860
    },
    {
      "epoch": 4.6870981568795544,
      "grad_norm": 0.0003710763994604349,
      "learning_rate": 1.3750535790827262e-05,
      "loss": 0.0001,
      "step": 21870
    },
    {
      "epoch": 4.689241320188598,
      "grad_norm": 0.0004284848109818995,
      "learning_rate": 1.3747678239748536e-05,
      "loss": 0.0001,
      "step": 21880
    },
    {
      "epoch": 4.691384483497642,
      "grad_norm": 0.02040712535381317,
      "learning_rate": 1.3744820688669811e-05,
      "loss": 0.1999,
      "step": 21890
    },
    {
      "epoch": 4.693527646806687,
      "grad_norm": 0.0004859181062784046,
      "learning_rate": 1.3741963137591085e-05,
      "loss": 0.2063,
      "step": 21900
    },
    {
      "epoch": 4.695670810115731,
      "grad_norm": 0.0005604805774055421,
      "learning_rate": 1.3739105586512361e-05,
      "loss": 0.0002,
      "step": 21910
    },
    {
      "epoch": 4.697813973424775,
      "grad_norm": 0.09649595618247986,
      "learning_rate": 1.3736248035433635e-05,
      "loss": 0.0004,
      "step": 21920
    },
    {
      "epoch": 4.699957136733819,
      "grad_norm": 0.009716098196804523,
      "learning_rate": 1.3733390484354909e-05,
      "loss": 0.0001,
      "step": 21930
    },
    {
      "epoch": 4.702100300042863,
      "grad_norm": 0.08899642527103424,
      "learning_rate": 1.3730532933276184e-05,
      "loss": 0.0005,
      "step": 21940
    },
    {
      "epoch": 4.704243463351908,
      "grad_norm": 0.0005372549640014768,
      "learning_rate": 1.3727675382197458e-05,
      "loss": 0.1819,
      "step": 21950
    },
    {
      "epoch": 4.706386626660952,
      "grad_norm": 0.02692609280347824,
      "learning_rate": 1.3724817831118732e-05,
      "loss": 0.0009,
      "step": 21960
    },
    {
      "epoch": 4.708529789969996,
      "grad_norm": 0.012145185843110085,
      "learning_rate": 1.3721960280040008e-05,
      "loss": 0.1443,
      "step": 21970
    },
    {
      "epoch": 4.71067295327904,
      "grad_norm": 0.0006732720066793263,
      "learning_rate": 1.3719102728961282e-05,
      "loss": 0.0006,
      "step": 21980
    },
    {
      "epoch": 4.712816116588084,
      "grad_norm": 0.0006787136080674827,
      "learning_rate": 1.3716245177882557e-05,
      "loss": 0.0003,
      "step": 21990
    },
    {
      "epoch": 4.714959279897128,
      "grad_norm": 0.001113450387492776,
      "learning_rate": 1.3713387626803831e-05,
      "loss": 0.1866,
      "step": 22000
    },
    {
      "epoch": 4.717102443206173,
      "grad_norm": 0.0578966848552227,
      "learning_rate": 1.3710530075725104e-05,
      "loss": 0.0002,
      "step": 22010
    },
    {
      "epoch": 4.719245606515217,
      "grad_norm": 0.0012773957569152117,
      "learning_rate": 1.3707672524646378e-05,
      "loss": 0.1257,
      "step": 22020
    },
    {
      "epoch": 4.7213887698242605,
      "grad_norm": 0.007045129779726267,
      "learning_rate": 1.3704814973567653e-05,
      "loss": 0.1309,
      "step": 22030
    },
    {
      "epoch": 4.723531933133305,
      "grad_norm": 0.0002590650401543826,
      "learning_rate": 1.3701957422488927e-05,
      "loss": 0.0009,
      "step": 22040
    },
    {
      "epoch": 4.725675096442349,
      "grad_norm": 0.0004853408318012953,
      "learning_rate": 1.3699099871410203e-05,
      "loss": 0.1839,
      "step": 22050
    },
    {
      "epoch": 4.727818259751393,
      "grad_norm": 0.2930687963962555,
      "learning_rate": 1.3696242320331477e-05,
      "loss": 0.1452,
      "step": 22060
    },
    {
      "epoch": 4.729961423060438,
      "grad_norm": 0.0005363827222026885,
      "learning_rate": 1.369338476925275e-05,
      "loss": 0.3348,
      "step": 22070
    },
    {
      "epoch": 4.7321045863694815,
      "grad_norm": 0.0023019250947982073,
      "learning_rate": 1.3690527218174026e-05,
      "loss": 0.0004,
      "step": 22080
    },
    {
      "epoch": 4.734247749678525,
      "grad_norm": 0.0006354678771458566,
      "learning_rate": 1.36876696670953e-05,
      "loss": 0.0003,
      "step": 22090
    },
    {
      "epoch": 4.73639091298757,
      "grad_norm": 0.03492513671517372,
      "learning_rate": 1.3684812116016574e-05,
      "loss": 0.3094,
      "step": 22100
    },
    {
      "epoch": 4.738534076296614,
      "grad_norm": 0.23791995644569397,
      "learning_rate": 1.368195456493785e-05,
      "loss": 0.0031,
      "step": 22110
    },
    {
      "epoch": 4.740677239605658,
      "grad_norm": 0.008153240196406841,
      "learning_rate": 1.3679097013859124e-05,
      "loss": 0.0002,
      "step": 22120
    },
    {
      "epoch": 4.7428204029147025,
      "grad_norm": 0.0034465391654521227,
      "learning_rate": 1.36762394627804e-05,
      "loss": 0.0001,
      "step": 22130
    },
    {
      "epoch": 4.744963566223746,
      "grad_norm": 0.0004486430552788079,
      "learning_rate": 1.3673381911701673e-05,
      "loss": 0.5441,
      "step": 22140
    },
    {
      "epoch": 4.74710672953279,
      "grad_norm": 0.18685589730739594,
      "learning_rate": 1.3670524360622947e-05,
      "loss": 0.1304,
      "step": 22150
    },
    {
      "epoch": 4.749249892841835,
      "grad_norm": 0.0004150191380176693,
      "learning_rate": 1.3667666809544223e-05,
      "loss": 0.0002,
      "step": 22160
    },
    {
      "epoch": 4.751393056150879,
      "grad_norm": 0.02440558932721615,
      "learning_rate": 1.3664809258465497e-05,
      "loss": 0.0008,
      "step": 22170
    },
    {
      "epoch": 4.753536219459923,
      "grad_norm": 0.06305616348981857,
      "learning_rate": 1.366195170738677e-05,
      "loss": 0.1603,
      "step": 22180
    },
    {
      "epoch": 4.755679382768967,
      "grad_norm": 0.0010603559203445911,
      "learning_rate": 1.3659094156308046e-05,
      "loss": 0.0019,
      "step": 22190
    },
    {
      "epoch": 4.757822546078011,
      "grad_norm": 0.01927899569272995,
      "learning_rate": 1.365623660522932e-05,
      "loss": 0.0002,
      "step": 22200
    },
    {
      "epoch": 4.759965709387055,
      "grad_norm": 0.01657937280833721,
      "learning_rate": 1.3653379054150596e-05,
      "loss": 0.0039,
      "step": 22210
    },
    {
      "epoch": 4.7621088726961,
      "grad_norm": 0.00034626107662916183,
      "learning_rate": 1.365052150307187e-05,
      "loss": 0.1895,
      "step": 22220
    },
    {
      "epoch": 4.764252036005144,
      "grad_norm": 0.05516237020492554,
      "learning_rate": 1.3647663951993142e-05,
      "loss": 0.1416,
      "step": 22230
    },
    {
      "epoch": 4.7663951993141875,
      "grad_norm": 0.00045832639443688095,
      "learning_rate": 1.3644806400914416e-05,
      "loss": 0.0005,
      "step": 22240
    },
    {
      "epoch": 4.768538362623232,
      "grad_norm": 0.0001628548197913915,
      "learning_rate": 1.3641948849835691e-05,
      "loss": 0.1231,
      "step": 22250
    },
    {
      "epoch": 4.770681525932276,
      "grad_norm": 0.48422831296920776,
      "learning_rate": 1.3639091298756965e-05,
      "loss": 0.0004,
      "step": 22260
    },
    {
      "epoch": 4.77282468924132,
      "grad_norm": 0.00031505778315477073,
      "learning_rate": 1.3636233747678241e-05,
      "loss": 0.2779,
      "step": 22270
    },
    {
      "epoch": 4.774967852550365,
      "grad_norm": 0.1088036522269249,
      "learning_rate": 1.3633376196599515e-05,
      "loss": 0.3035,
      "step": 22280
    },
    {
      "epoch": 4.777111015859409,
      "grad_norm": 0.11835701018571854,
      "learning_rate": 1.3630518645520789e-05,
      "loss": 0.0004,
      "step": 22290
    },
    {
      "epoch": 4.779254179168452,
      "grad_norm": 0.0035581388510763645,
      "learning_rate": 1.3627661094442064e-05,
      "loss": 0.0006,
      "step": 22300
    },
    {
      "epoch": 4.781397342477497,
      "grad_norm": 0.052100975066423416,
      "learning_rate": 1.3624803543363338e-05,
      "loss": 0.0005,
      "step": 22310
    },
    {
      "epoch": 4.783540505786541,
      "grad_norm": 0.1518232375383377,
      "learning_rate": 1.3621945992284612e-05,
      "loss": 0.0009,
      "step": 22320
    },
    {
      "epoch": 4.785683669095585,
      "grad_norm": 0.004646518733352423,
      "learning_rate": 1.3619088441205888e-05,
      "loss": 0.0007,
      "step": 22330
    },
    {
      "epoch": 4.78782683240463,
      "grad_norm": 0.0021970276720821857,
      "learning_rate": 1.3616230890127162e-05,
      "loss": 0.0003,
      "step": 22340
    },
    {
      "epoch": 4.789969995713673,
      "grad_norm": 0.016516225412487984,
      "learning_rate": 1.3613373339048438e-05,
      "loss": 0.0003,
      "step": 22350
    },
    {
      "epoch": 4.792113159022717,
      "grad_norm": 0.0331256166100502,
      "learning_rate": 1.3610515787969711e-05,
      "loss": 0.0004,
      "step": 22360
    },
    {
      "epoch": 4.794256322331762,
      "grad_norm": 0.10729814320802689,
      "learning_rate": 1.3607658236890985e-05,
      "loss": 0.2456,
      "step": 22370
    },
    {
      "epoch": 4.796399485640806,
      "grad_norm": 0.0011917693773284554,
      "learning_rate": 1.3604800685812261e-05,
      "loss": 0.3118,
      "step": 22380
    },
    {
      "epoch": 4.79854264894985,
      "grad_norm": 0.0004883036599494517,
      "learning_rate": 1.3601943134733535e-05,
      "loss": 0.0005,
      "step": 22390
    },
    {
      "epoch": 4.8006858122588945,
      "grad_norm": 0.00045416841749101877,
      "learning_rate": 1.359908558365481e-05,
      "loss": 0.0004,
      "step": 22400
    },
    {
      "epoch": 4.802828975567938,
      "grad_norm": 0.030566323548555374,
      "learning_rate": 1.3596228032576084e-05,
      "loss": 0.3641,
      "step": 22410
    },
    {
      "epoch": 4.804972138876982,
      "grad_norm": 0.003893128130584955,
      "learning_rate": 1.3593370481497358e-05,
      "loss": 0.0005,
      "step": 22420
    },
    {
      "epoch": 4.807115302186027,
      "grad_norm": 0.029720298945903778,
      "learning_rate": 1.3590512930418634e-05,
      "loss": 0.1615,
      "step": 22430
    },
    {
      "epoch": 4.809258465495071,
      "grad_norm": 0.0003383905568625778,
      "learning_rate": 1.3587655379339906e-05,
      "loss": 0.0005,
      "step": 22440
    },
    {
      "epoch": 4.811401628804115,
      "grad_norm": 0.0006547210505232215,
      "learning_rate": 1.358479782826118e-05,
      "loss": 0.1629,
      "step": 22450
    },
    {
      "epoch": 4.813544792113159,
      "grad_norm": 0.1290704309940338,
      "learning_rate": 1.3581940277182454e-05,
      "loss": 0.0008,
      "step": 22460
    },
    {
      "epoch": 4.815687955422203,
      "grad_norm": 0.0001972230093088001,
      "learning_rate": 1.357908272610373e-05,
      "loss": 0.0079,
      "step": 22470
    },
    {
      "epoch": 4.817831118731247,
      "grad_norm": 0.009461254812777042,
      "learning_rate": 1.3576225175025004e-05,
      "loss": 0.1498,
      "step": 22480
    },
    {
      "epoch": 4.819974282040292,
      "grad_norm": 0.00025909108808264136,
      "learning_rate": 1.357336762394628e-05,
      "loss": 0.0007,
      "step": 22490
    },
    {
      "epoch": 4.822117445349336,
      "grad_norm": 0.001195274293422699,
      "learning_rate": 1.3570510072867553e-05,
      "loss": 0.1038,
      "step": 22500
    },
    {
      "epoch": 4.8242606086583795,
      "grad_norm": 0.00027211595443077385,
      "learning_rate": 1.3567652521788827e-05,
      "loss": 0.0003,
      "step": 22510
    },
    {
      "epoch": 4.826403771967424,
      "grad_norm": 0.00023663441243115813,
      "learning_rate": 1.3564794970710103e-05,
      "loss": 0.0023,
      "step": 22520
    },
    {
      "epoch": 4.828546935276468,
      "grad_norm": 0.06872402876615524,
      "learning_rate": 1.3561937419631377e-05,
      "loss": 0.0005,
      "step": 22530
    },
    {
      "epoch": 4.830690098585512,
      "grad_norm": 0.00021029739582445472,
      "learning_rate": 1.3559079868552652e-05,
      "loss": 0.0001,
      "step": 22540
    },
    {
      "epoch": 4.832833261894557,
      "grad_norm": 0.06555359065532684,
      "learning_rate": 1.3556222317473926e-05,
      "loss": 0.0007,
      "step": 22550
    },
    {
      "epoch": 4.8349764252036005,
      "grad_norm": 0.0024420414119958878,
      "learning_rate": 1.35533647663952e-05,
      "loss": 0.0003,
      "step": 22560
    },
    {
      "epoch": 4.837119588512644,
      "grad_norm": 0.00018009460472967476,
      "learning_rate": 1.3550507215316476e-05,
      "loss": 0.0002,
      "step": 22570
    },
    {
      "epoch": 4.839262751821689,
      "grad_norm": 0.0006801059353165329,
      "learning_rate": 1.354764966423775e-05,
      "loss": 0.0003,
      "step": 22580
    },
    {
      "epoch": 4.841405915130733,
      "grad_norm": 0.00019772526866290718,
      "learning_rate": 1.3544792113159024e-05,
      "loss": 0.0,
      "step": 22590
    },
    {
      "epoch": 4.843549078439777,
      "grad_norm": 0.0037777028046548367,
      "learning_rate": 1.35419345620803e-05,
      "loss": 0.7169,
      "step": 22600
    },
    {
      "epoch": 4.8456922417488215,
      "grad_norm": 0.02780638262629509,
      "learning_rate": 1.3539077011001573e-05,
      "loss": 0.0311,
      "step": 22610
    },
    {
      "epoch": 4.847835405057865,
      "grad_norm": 0.04805648699402809,
      "learning_rate": 1.3536219459922849e-05,
      "loss": 0.769,
      "step": 22620
    },
    {
      "epoch": 4.849978568366909,
      "grad_norm": 0.0024332860484719276,
      "learning_rate": 1.3533361908844123e-05,
      "loss": 0.1806,
      "step": 22630
    },
    {
      "epoch": 4.852121731675954,
      "grad_norm": 0.013002871535718441,
      "learning_rate": 1.3530504357765397e-05,
      "loss": 0.158,
      "step": 22640
    },
    {
      "epoch": 4.854264894984998,
      "grad_norm": 0.004009227734059095,
      "learning_rate": 1.3527646806686672e-05,
      "loss": 0.1539,
      "step": 22650
    },
    {
      "epoch": 4.856408058294042,
      "grad_norm": 0.01632589101791382,
      "learning_rate": 1.3524789255607945e-05,
      "loss": 0.0002,
      "step": 22660
    },
    {
      "epoch": 4.858551221603086,
      "grad_norm": 0.0014825622783973813,
      "learning_rate": 1.3521931704529218e-05,
      "loss": 0.1502,
      "step": 22670
    },
    {
      "epoch": 4.86069438491213,
      "grad_norm": 16.463550567626953,
      "learning_rate": 1.3519074153450494e-05,
      "loss": 0.1516,
      "step": 22680
    },
    {
      "epoch": 4.862837548221174,
      "grad_norm": 0.01974712871015072,
      "learning_rate": 1.3516216602371768e-05,
      "loss": 0.2263,
      "step": 22690
    },
    {
      "epoch": 4.864980711530219,
      "grad_norm": 0.02114666812121868,
      "learning_rate": 1.3513359051293042e-05,
      "loss": 0.1238,
      "step": 22700
    },
    {
      "epoch": 4.867123874839263,
      "grad_norm": 0.019179079681634903,
      "learning_rate": 1.3510501500214318e-05,
      "loss": 0.0928,
      "step": 22710
    },
    {
      "epoch": 4.8692670381483065,
      "grad_norm": 0.16554252803325653,
      "learning_rate": 1.3507643949135591e-05,
      "loss": 0.0004,
      "step": 22720
    },
    {
      "epoch": 4.871410201457351,
      "grad_norm": 0.001069902558811009,
      "learning_rate": 1.3504786398056865e-05,
      "loss": 0.0009,
      "step": 22730
    },
    {
      "epoch": 4.873553364766395,
      "grad_norm": 0.00044215761590749025,
      "learning_rate": 1.3501928846978141e-05,
      "loss": 0.0001,
      "step": 22740
    },
    {
      "epoch": 4.875696528075439,
      "grad_norm": 0.016093816608190536,
      "learning_rate": 1.3499071295899415e-05,
      "loss": 0.0005,
      "step": 22750
    },
    {
      "epoch": 4.877839691384484,
      "grad_norm": 0.024051405489444733,
      "learning_rate": 1.349621374482069e-05,
      "loss": 0.0001,
      "step": 22760
    },
    {
      "epoch": 4.8799828546935275,
      "grad_norm": 0.0005316620809026062,
      "learning_rate": 1.3493356193741965e-05,
      "loss": 0.0,
      "step": 22770
    },
    {
      "epoch": 4.882126018002571,
      "grad_norm": 0.0010159725788980722,
      "learning_rate": 1.3490498642663238e-05,
      "loss": 0.1745,
      "step": 22780
    },
    {
      "epoch": 4.884269181311616,
      "grad_norm": 0.002013238612562418,
      "learning_rate": 1.3487641091584514e-05,
      "loss": 0.098,
      "step": 22790
    },
    {
      "epoch": 4.88641234462066,
      "grad_norm": 0.0006102162296883762,
      "learning_rate": 1.3484783540505788e-05,
      "loss": 0.1411,
      "step": 22800
    },
    {
      "epoch": 4.888555507929704,
      "grad_norm": 1.7573186159133911,
      "learning_rate": 1.3481925989427062e-05,
      "loss": 0.003,
      "step": 22810
    },
    {
      "epoch": 4.890698671238749,
      "grad_norm": 0.23402823507785797,
      "learning_rate": 1.3479068438348338e-05,
      "loss": 0.0015,
      "step": 22820
    },
    {
      "epoch": 4.892841834547792,
      "grad_norm": 0.0010783213656395674,
      "learning_rate": 1.3476210887269611e-05,
      "loss": 0.2869,
      "step": 22830
    },
    {
      "epoch": 4.894984997856836,
      "grad_norm": 0.0013415052089840174,
      "learning_rate": 1.3473353336190887e-05,
      "loss": 0.2061,
      "step": 22840
    },
    {
      "epoch": 4.897128161165881,
      "grad_norm": 0.012104772962629795,
      "learning_rate": 1.3470495785112161e-05,
      "loss": 0.1412,
      "step": 22850
    },
    {
      "epoch": 4.899271324474925,
      "grad_norm": 0.011024538427591324,
      "learning_rate": 1.3467638234033435e-05,
      "loss": 0.0003,
      "step": 22860
    },
    {
      "epoch": 4.901414487783969,
      "grad_norm": 0.0012381038395687938,
      "learning_rate": 1.3464780682954707e-05,
      "loss": 0.2414,
      "step": 22870
    },
    {
      "epoch": 4.9035576510930134,
      "grad_norm": 0.022301211953163147,
      "learning_rate": 1.3461923131875983e-05,
      "loss": 0.3241,
      "step": 22880
    },
    {
      "epoch": 4.905700814402057,
      "grad_norm": 15.79122257232666,
      "learning_rate": 1.3459065580797257e-05,
      "loss": 0.17,
      "step": 22890
    },
    {
      "epoch": 4.907843977711101,
      "grad_norm": 0.00639483705163002,
      "learning_rate": 1.3456208029718532e-05,
      "loss": 0.0034,
      "step": 22900
    },
    {
      "epoch": 4.909987141020146,
      "grad_norm": 0.09054621309041977,
      "learning_rate": 1.3453350478639806e-05,
      "loss": 0.1802,
      "step": 22910
    },
    {
      "epoch": 4.91213030432919,
      "grad_norm": 0.2383221983909607,
      "learning_rate": 1.345049292756108e-05,
      "loss": 0.2172,
      "step": 22920
    },
    {
      "epoch": 4.914273467638234,
      "grad_norm": 0.008306289091706276,
      "learning_rate": 1.3447635376482356e-05,
      "loss": 0.0013,
      "step": 22930
    },
    {
      "epoch": 4.916416630947278,
      "grad_norm": 0.07812784612178802,
      "learning_rate": 1.344477782540363e-05,
      "loss": 0.0009,
      "step": 22940
    },
    {
      "epoch": 4.918559794256322,
      "grad_norm": 0.001606771140359342,
      "learning_rate": 1.3441920274324904e-05,
      "loss": 0.0005,
      "step": 22950
    },
    {
      "epoch": 4.920702957565366,
      "grad_norm": 0.011529019102454185,
      "learning_rate": 1.343906272324618e-05,
      "loss": 0.0003,
      "step": 22960
    },
    {
      "epoch": 4.922846120874411,
      "grad_norm": 0.02011043019592762,
      "learning_rate": 1.3436205172167453e-05,
      "loss": 0.0007,
      "step": 22970
    },
    {
      "epoch": 4.924989284183455,
      "grad_norm": 0.000603265012614429,
      "learning_rate": 1.3433347621088729e-05,
      "loss": 0.0003,
      "step": 22980
    },
    {
      "epoch": 4.9271324474924985,
      "grad_norm": 0.0015409239567816257,
      "learning_rate": 1.3430490070010003e-05,
      "loss": 0.0002,
      "step": 22990
    },
    {
      "epoch": 4.929275610801543,
      "grad_norm": 0.022050436586141586,
      "learning_rate": 1.3427632518931277e-05,
      "loss": 0.1326,
      "step": 23000
    },
    {
      "epoch": 4.931418774110587,
      "grad_norm": 0.0014608859783038497,
      "learning_rate": 1.3424774967852552e-05,
      "loss": 0.0004,
      "step": 23010
    },
    {
      "epoch": 4.933561937419631,
      "grad_norm": 0.0015877083642408252,
      "learning_rate": 1.3421917416773826e-05,
      "loss": 0.0002,
      "step": 23020
    },
    {
      "epoch": 4.935705100728676,
      "grad_norm": 0.0004515501204878092,
      "learning_rate": 1.34190598656951e-05,
      "loss": 0.0003,
      "step": 23030
    },
    {
      "epoch": 4.9378482640377195,
      "grad_norm": 0.03852145001292229,
      "learning_rate": 1.3416202314616376e-05,
      "loss": 0.0003,
      "step": 23040
    },
    {
      "epoch": 4.939991427346763,
      "grad_norm": 0.0007345188641920686,
      "learning_rate": 1.341334476353765e-05,
      "loss": 0.0002,
      "step": 23050
    },
    {
      "epoch": 4.942134590655808,
      "grad_norm": 0.001435048645362258,
      "learning_rate": 1.3410487212458925e-05,
      "loss": 0.2342,
      "step": 23060
    },
    {
      "epoch": 4.944277753964852,
      "grad_norm": 0.11254914849996567,
      "learning_rate": 1.34076296613802e-05,
      "loss": 0.0002,
      "step": 23070
    },
    {
      "epoch": 4.946420917273897,
      "grad_norm": 0.00019121664809063077,
      "learning_rate": 1.3404772110301472e-05,
      "loss": 0.0003,
      "step": 23080
    },
    {
      "epoch": 4.9485640805829405,
      "grad_norm": 0.0021681461948901415,
      "learning_rate": 1.3401914559222745e-05,
      "loss": 0.0002,
      "step": 23090
    },
    {
      "epoch": 4.950707243891984,
      "grad_norm": 0.0002085505548166111,
      "learning_rate": 1.3399057008144021e-05,
      "loss": 0.0001,
      "step": 23100
    },
    {
      "epoch": 4.952850407201029,
      "grad_norm": 0.00039578767609782517,
      "learning_rate": 1.3396199457065295e-05,
      "loss": 0.0003,
      "step": 23110
    },
    {
      "epoch": 4.954993570510073,
      "grad_norm": 0.012870614416897297,
      "learning_rate": 1.339334190598657e-05,
      "loss": 0.0001,
      "step": 23120
    },
    {
      "epoch": 4.957136733819117,
      "grad_norm": 0.0005362436641007662,
      "learning_rate": 1.3390484354907845e-05,
      "loss": 0.0,
      "step": 23130
    },
    {
      "epoch": 4.9592798971281615,
      "grad_norm": 0.0001677262771409005,
      "learning_rate": 1.3387626803829118e-05,
      "loss": 0.0,
      "step": 23140
    },
    {
      "epoch": 4.961423060437205,
      "grad_norm": 0.0002577473351266235,
      "learning_rate": 1.3384769252750394e-05,
      "loss": 0.2164,
      "step": 23150
    },
    {
      "epoch": 4.963566223746249,
      "grad_norm": 0.00019380252342671156,
      "learning_rate": 1.3381911701671668e-05,
      "loss": 0.0002,
      "step": 23160
    },
    {
      "epoch": 4.965709387055294,
      "grad_norm": 0.06107889488339424,
      "learning_rate": 1.3379054150592942e-05,
      "loss": 0.0003,
      "step": 23170
    },
    {
      "epoch": 4.967852550364338,
      "grad_norm": 0.017024829983711243,
      "learning_rate": 1.3376196599514218e-05,
      "loss": 0.0001,
      "step": 23180
    },
    {
      "epoch": 4.969995713673382,
      "grad_norm": 0.013798154890537262,
      "learning_rate": 1.3373339048435492e-05,
      "loss": 0.0001,
      "step": 23190
    },
    {
      "epoch": 4.972138876982426,
      "grad_norm": 0.02981858141720295,
      "learning_rate": 1.3370481497356767e-05,
      "loss": 0.0002,
      "step": 23200
    },
    {
      "epoch": 4.97428204029147,
      "grad_norm": 114.36865997314453,
      "learning_rate": 1.3367623946278041e-05,
      "loss": 0.1643,
      "step": 23210
    },
    {
      "epoch": 4.976425203600514,
      "grad_norm": 0.00486996304243803,
      "learning_rate": 1.3364766395199315e-05,
      "loss": 0.0002,
      "step": 23220
    },
    {
      "epoch": 4.978568366909559,
      "grad_norm": 0.01899416744709015,
      "learning_rate": 1.336190884412059e-05,
      "loss": 0.202,
      "step": 23230
    },
    {
      "epoch": 4.980711530218603,
      "grad_norm": 0.0003561133926268667,
      "learning_rate": 1.3359051293041865e-05,
      "loss": 0.0002,
      "step": 23240
    },
    {
      "epoch": 4.9828546935276465,
      "grad_norm": 0.001457810285501182,
      "learning_rate": 1.335619374196314e-05,
      "loss": 0.0001,
      "step": 23250
    },
    {
      "epoch": 4.984997856836691,
      "grad_norm": 0.02487897500395775,
      "learning_rate": 1.3353336190884414e-05,
      "loss": 0.0009,
      "step": 23260
    },
    {
      "epoch": 4.987141020145735,
      "grad_norm": 0.0006608699331991374,
      "learning_rate": 1.3350478639805688e-05,
      "loss": 0.0002,
      "step": 23270
    },
    {
      "epoch": 4.989284183454779,
      "grad_norm": 0.0001084268806152977,
      "learning_rate": 1.3347621088726964e-05,
      "loss": 0.0001,
      "step": 23280
    },
    {
      "epoch": 4.991427346763824,
      "grad_norm": 96.77523040771484,
      "learning_rate": 1.3344763537648238e-05,
      "loss": 0.1623,
      "step": 23290
    },
    {
      "epoch": 4.993570510072868,
      "grad_norm": 0.02174384891986847,
      "learning_rate": 1.334190598656951e-05,
      "loss": 0.0003,
      "step": 23300
    },
    {
      "epoch": 4.995713673381911,
      "grad_norm": 7.677597750443965e-05,
      "learning_rate": 1.3339048435490784e-05,
      "loss": 0.0002,
      "step": 23310
    },
    {
      "epoch": 4.997856836690956,
      "grad_norm": 0.0329911932349205,
      "learning_rate": 1.333619088441206e-05,
      "loss": 0.4059,
      "step": 23320
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.03246885910630226,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0006,
      "step": 23330
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9816666666666667,
      "eval_f1": 0.9023090586145648,
      "eval_loss": 0.12003111094236374,
      "eval_precision": 0.9657794676806084,
      "eval_recall": 0.8466666666666667,
      "eval_runtime": 396.378,
      "eval_samples_per_second": 7.569,
      "eval_steps_per_second": 2.523,
      "step": 23330
    },
    {
      "epoch": 5.002143163309044,
      "grad_norm": 0.014508790336549282,
      "learning_rate": 1.3330475782254609e-05,
      "loss": 0.0007,
      "step": 23340
    },
    {
      "epoch": 5.004286326618089,
      "grad_norm": 0.01255677081644535,
      "learning_rate": 1.3327618231175883e-05,
      "loss": 0.0004,
      "step": 23350
    },
    {
      "epoch": 5.006429489927132,
      "grad_norm": 0.01060305256396532,
      "learning_rate": 1.3324760680097157e-05,
      "loss": 0.0003,
      "step": 23360
    },
    {
      "epoch": 5.008572653236176,
      "grad_norm": 0.024539677426218987,
      "learning_rate": 1.3321903129018432e-05,
      "loss": 0.0002,
      "step": 23370
    },
    {
      "epoch": 5.010715816545221,
      "grad_norm": 0.0649217739701271,
      "learning_rate": 1.3319045577939706e-05,
      "loss": 0.0586,
      "step": 23380
    },
    {
      "epoch": 5.012858979854265,
      "grad_norm": 0.011892188340425491,
      "learning_rate": 1.3316188026860982e-05,
      "loss": 0.0002,
      "step": 23390
    },
    {
      "epoch": 5.015002143163309,
      "grad_norm": 0.0011466016294434667,
      "learning_rate": 1.3313330475782256e-05,
      "loss": 0.0002,
      "step": 23400
    },
    {
      "epoch": 5.0171453064723535,
      "grad_norm": 0.0008524872246198356,
      "learning_rate": 1.331047292470353e-05,
      "loss": 0.0002,
      "step": 23410
    },
    {
      "epoch": 5.019288469781397,
      "grad_norm": 0.007381145842373371,
      "learning_rate": 1.3307615373624805e-05,
      "loss": 0.0001,
      "step": 23420
    },
    {
      "epoch": 5.021431633090441,
      "grad_norm": 0.013611326925456524,
      "learning_rate": 1.330475782254608e-05,
      "loss": 0.0001,
      "step": 23430
    },
    {
      "epoch": 5.023574796399486,
      "grad_norm": 0.008920148946344852,
      "learning_rate": 1.3301900271467353e-05,
      "loss": 0.0001,
      "step": 23440
    },
    {
      "epoch": 5.02571795970853,
      "grad_norm": 0.0006152199348434806,
      "learning_rate": 1.3299042720388629e-05,
      "loss": 0.0001,
      "step": 23450
    },
    {
      "epoch": 5.027861123017574,
      "grad_norm": 75.15921783447266,
      "learning_rate": 1.3296185169309903e-05,
      "loss": 0.3852,
      "step": 23460
    },
    {
      "epoch": 5.030004286326618,
      "grad_norm": 0.01972184330224991,
      "learning_rate": 1.3293327618231178e-05,
      "loss": 0.0001,
      "step": 23470
    },
    {
      "epoch": 5.032147449635662,
      "grad_norm": 0.0292704775929451,
      "learning_rate": 1.3290470067152452e-05,
      "loss": 0.0004,
      "step": 23480
    },
    {
      "epoch": 5.034290612944706,
      "grad_norm": 0.05549753084778786,
      "learning_rate": 1.3287612516073726e-05,
      "loss": 0.0006,
      "step": 23490
    },
    {
      "epoch": 5.036433776253751,
      "grad_norm": 0.003092848928645253,
      "learning_rate": 1.3284754964995002e-05,
      "loss": 0.0026,
      "step": 23500
    },
    {
      "epoch": 5.038576939562795,
      "grad_norm": 0.0011723118368536234,
      "learning_rate": 1.3281897413916274e-05,
      "loss": 0.0005,
      "step": 23510
    },
    {
      "epoch": 5.0407201028718385,
      "grad_norm": 0.0005910226609557867,
      "learning_rate": 1.3279039862837548e-05,
      "loss": 0.2052,
      "step": 23520
    },
    {
      "epoch": 5.042863266180883,
      "grad_norm": 0.010353406891226768,
      "learning_rate": 1.3276182311758824e-05,
      "loss": 0.0002,
      "step": 23530
    },
    {
      "epoch": 5.045006429489927,
      "grad_norm": 0.0007886232924647629,
      "learning_rate": 1.3273324760680098e-05,
      "loss": 0.0003,
      "step": 23540
    },
    {
      "epoch": 5.047149592798971,
      "grad_norm": 0.002485832665115595,
      "learning_rate": 1.3270467209601372e-05,
      "loss": 0.1804,
      "step": 23550
    },
    {
      "epoch": 5.049292756108016,
      "grad_norm": 0.04325326159596443,
      "learning_rate": 1.3267609658522647e-05,
      "loss": 0.1849,
      "step": 23560
    },
    {
      "epoch": 5.0514359194170595,
      "grad_norm": 0.0006759976968169212,
      "learning_rate": 1.3264752107443921e-05,
      "loss": 0.0001,
      "step": 23570
    },
    {
      "epoch": 5.053579082726103,
      "grad_norm": 0.001976324710994959,
      "learning_rate": 1.3261894556365195e-05,
      "loss": 0.0001,
      "step": 23580
    },
    {
      "epoch": 5.055722246035148,
      "grad_norm": 0.0011293034767732024,
      "learning_rate": 1.325903700528647e-05,
      "loss": 0.4862,
      "step": 23590
    },
    {
      "epoch": 5.057865409344192,
      "grad_norm": 0.035771433264017105,
      "learning_rate": 1.3256179454207745e-05,
      "loss": 0.001,
      "step": 23600
    },
    {
      "epoch": 5.060008572653236,
      "grad_norm": 0.015870431438088417,
      "learning_rate": 1.325332190312902e-05,
      "loss": 0.0008,
      "step": 23610
    },
    {
      "epoch": 5.0621517359622805,
      "grad_norm": 0.0032021976076066494,
      "learning_rate": 1.3250464352050294e-05,
      "loss": 0.1873,
      "step": 23620
    },
    {
      "epoch": 5.064294899271324,
      "grad_norm": 0.0013458316680043936,
      "learning_rate": 1.3247606800971568e-05,
      "loss": 0.0006,
      "step": 23630
    },
    {
      "epoch": 5.066438062580368,
      "grad_norm": 0.1160873994231224,
      "learning_rate": 1.3244749249892844e-05,
      "loss": 0.0009,
      "step": 23640
    },
    {
      "epoch": 5.068581225889413,
      "grad_norm": 0.0014146406902000308,
      "learning_rate": 1.3241891698814118e-05,
      "loss": 0.0003,
      "step": 23650
    },
    {
      "epoch": 5.070724389198457,
      "grad_norm": 0.0012100088642910123,
      "learning_rate": 1.3239034147735392e-05,
      "loss": 0.0004,
      "step": 23660
    },
    {
      "epoch": 5.072867552507501,
      "grad_norm": 0.009291671216487885,
      "learning_rate": 1.3236176596656667e-05,
      "loss": 0.0002,
      "step": 23670
    },
    {
      "epoch": 5.075010715816545,
      "grad_norm": 0.0905241072177887,
      "learning_rate": 1.3233319045577941e-05,
      "loss": 0.0005,
      "step": 23680
    },
    {
      "epoch": 5.077153879125589,
      "grad_norm": 0.018957335501909256,
      "learning_rate": 1.3230461494499217e-05,
      "loss": 0.1993,
      "step": 23690
    },
    {
      "epoch": 5.079297042434633,
      "grad_norm": 0.0021389417815953493,
      "learning_rate": 1.322760394342049e-05,
      "loss": 0.1921,
      "step": 23700
    },
    {
      "epoch": 5.081440205743678,
      "grad_norm": 0.017083914950489998,
      "learning_rate": 1.3224746392341765e-05,
      "loss": 0.0004,
      "step": 23710
    },
    {
      "epoch": 5.083583369052722,
      "grad_norm": 0.05074671655893326,
      "learning_rate": 1.322188884126304e-05,
      "loss": 0.3374,
      "step": 23720
    },
    {
      "epoch": 5.085726532361766,
      "grad_norm": 0.024205263704061508,
      "learning_rate": 1.3219031290184312e-05,
      "loss": 0.0001,
      "step": 23730
    },
    {
      "epoch": 5.08786969567081,
      "grad_norm": 0.0030606624204665422,
      "learning_rate": 1.3216173739105586e-05,
      "loss": 0.0003,
      "step": 23740
    },
    {
      "epoch": 5.090012858979854,
      "grad_norm": 0.0008605899638496339,
      "learning_rate": 1.3213316188026862e-05,
      "loss": 0.1217,
      "step": 23750
    },
    {
      "epoch": 5.092156022288899,
      "grad_norm": 0.09853670001029968,
      "learning_rate": 1.3210458636948136e-05,
      "loss": 0.0014,
      "step": 23760
    },
    {
      "epoch": 5.094299185597943,
      "grad_norm": 0.00044726571650244296,
      "learning_rate": 1.320760108586941e-05,
      "loss": 0.0004,
      "step": 23770
    },
    {
      "epoch": 5.0964423489069866,
      "grad_norm": 0.002590354299172759,
      "learning_rate": 1.3204743534790685e-05,
      "loss": 0.1649,
      "step": 23780
    },
    {
      "epoch": 5.098585512216031,
      "grad_norm": 0.0012255748733878136,
      "learning_rate": 1.320188598371196e-05,
      "loss": 0.1726,
      "step": 23790
    },
    {
      "epoch": 5.100728675525075,
      "grad_norm": 0.00032431510044261813,
      "learning_rate": 1.3199028432633233e-05,
      "loss": 0.0003,
      "step": 23800
    },
    {
      "epoch": 5.102871838834119,
      "grad_norm": 0.0012942679459229112,
      "learning_rate": 1.3196170881554509e-05,
      "loss": 0.0003,
      "step": 23810
    },
    {
      "epoch": 5.105015002143164,
      "grad_norm": 0.0007270639762282372,
      "learning_rate": 1.3193313330475783e-05,
      "loss": 0.0003,
      "step": 23820
    },
    {
      "epoch": 5.107158165452208,
      "grad_norm": 0.00038384459912776947,
      "learning_rate": 1.3190455779397059e-05,
      "loss": 0.0022,
      "step": 23830
    },
    {
      "epoch": 5.109301328761251,
      "grad_norm": 0.000222809161641635,
      "learning_rate": 1.3187598228318332e-05,
      "loss": 0.0,
      "step": 23840
    },
    {
      "epoch": 5.111444492070296,
      "grad_norm": 0.0002730823471210897,
      "learning_rate": 1.3184740677239606e-05,
      "loss": 0.2024,
      "step": 23850
    },
    {
      "epoch": 5.11358765537934,
      "grad_norm": 0.009585754945874214,
      "learning_rate": 1.3181883126160882e-05,
      "loss": 0.0003,
      "step": 23860
    },
    {
      "epoch": 5.115730818688384,
      "grad_norm": 17.648216247558594,
      "learning_rate": 1.3179025575082156e-05,
      "loss": 0.3677,
      "step": 23870
    },
    {
      "epoch": 5.117873981997429,
      "grad_norm": 16.664201736450195,
      "learning_rate": 1.317616802400343e-05,
      "loss": 0.1043,
      "step": 23880
    },
    {
      "epoch": 5.1200171453064725,
      "grad_norm": 0.00030580617021769285,
      "learning_rate": 1.3173310472924705e-05,
      "loss": 0.0,
      "step": 23890
    },
    {
      "epoch": 5.122160308615516,
      "grad_norm": 0.0003163510118611157,
      "learning_rate": 1.317045292184598e-05,
      "loss": 0.1394,
      "step": 23900
    },
    {
      "epoch": 5.124303471924561,
      "grad_norm": 19.88932228088379,
      "learning_rate": 1.3167595370767255e-05,
      "loss": 0.1375,
      "step": 23910
    },
    {
      "epoch": 5.126446635233605,
      "grad_norm": 0.00035356395528651774,
      "learning_rate": 1.3164737819688529e-05,
      "loss": 0.0013,
      "step": 23920
    },
    {
      "epoch": 5.128589798542649,
      "grad_norm": 0.0005496880621649325,
      "learning_rate": 1.3161880268609803e-05,
      "loss": 0.0016,
      "step": 23930
    },
    {
      "epoch": 5.1307329618516935,
      "grad_norm": 0.05686147138476372,
      "learning_rate": 1.3159022717531075e-05,
      "loss": 0.0006,
      "step": 23940
    },
    {
      "epoch": 5.132876125160737,
      "grad_norm": 0.0003162143984809518,
      "learning_rate": 1.315616516645235e-05,
      "loss": 0.0006,
      "step": 23950
    },
    {
      "epoch": 5.135019288469781,
      "grad_norm": 0.006167085375636816,
      "learning_rate": 1.3153307615373625e-05,
      "loss": 0.0001,
      "step": 23960
    },
    {
      "epoch": 5.137162451778826,
      "grad_norm": 0.00017686231876723468,
      "learning_rate": 1.31504500642949e-05,
      "loss": 0.0,
      "step": 23970
    },
    {
      "epoch": 5.13930561508787,
      "grad_norm": 0.00018084059411194175,
      "learning_rate": 1.3147592513216174e-05,
      "loss": 0.1531,
      "step": 23980
    },
    {
      "epoch": 5.141448778396914,
      "grad_norm": 0.00022533090668730438,
      "learning_rate": 1.3144734962137448e-05,
      "loss": 0.0,
      "step": 23990
    },
    {
      "epoch": 5.143591941705958,
      "grad_norm": 0.0001872031862149015,
      "learning_rate": 1.3141877411058724e-05,
      "loss": 0.0003,
      "step": 24000
    },
    {
      "epoch": 5.145735105015002,
      "grad_norm": 0.0002496257075108588,
      "learning_rate": 1.3139019859979998e-05,
      "loss": 0.0965,
      "step": 24010
    },
    {
      "epoch": 5.147878268324046,
      "grad_norm": 0.0004605645372066647,
      "learning_rate": 1.3136162308901272e-05,
      "loss": 0.0004,
      "step": 24020
    },
    {
      "epoch": 5.150021431633091,
      "grad_norm": 0.0006649621645919979,
      "learning_rate": 1.3133304757822547e-05,
      "loss": 0.0,
      "step": 24030
    },
    {
      "epoch": 5.152164594942135,
      "grad_norm": 0.0002762225631158799,
      "learning_rate": 1.3130447206743821e-05,
      "loss": 0.0002,
      "step": 24040
    },
    {
      "epoch": 5.1543077582511785,
      "grad_norm": 0.0013307984918355942,
      "learning_rate": 1.3127589655665097e-05,
      "loss": 0.0,
      "step": 24050
    },
    {
      "epoch": 5.156450921560223,
      "grad_norm": 0.012836369685828686,
      "learning_rate": 1.312473210458637e-05,
      "loss": 0.0001,
      "step": 24060
    },
    {
      "epoch": 5.158594084869267,
      "grad_norm": 0.00020050523744430393,
      "learning_rate": 1.3121874553507645e-05,
      "loss": 0.0027,
      "step": 24070
    },
    {
      "epoch": 5.160737248178311,
      "grad_norm": 0.2007254660129547,
      "learning_rate": 1.311901700242892e-05,
      "loss": 0.0001,
      "step": 24080
    },
    {
      "epoch": 5.162880411487356,
      "grad_norm": 0.03127150982618332,
      "learning_rate": 1.3116159451350194e-05,
      "loss": 0.0003,
      "step": 24090
    },
    {
      "epoch": 5.1650235747963995,
      "grad_norm": 0.0072330632247030735,
      "learning_rate": 1.311330190027147e-05,
      "loss": 0.0006,
      "step": 24100
    },
    {
      "epoch": 5.167166738105443,
      "grad_norm": 0.008584580384194851,
      "learning_rate": 1.3110444349192744e-05,
      "loss": 0.0,
      "step": 24110
    },
    {
      "epoch": 5.169309901414488,
      "grad_norm": 0.00015173041902016848,
      "learning_rate": 1.3107586798114018e-05,
      "loss": 0.0001,
      "step": 24120
    },
    {
      "epoch": 5.171453064723532,
      "grad_norm": 18.352182388305664,
      "learning_rate": 1.3104729247035293e-05,
      "loss": 0.3957,
      "step": 24130
    },
    {
      "epoch": 5.173596228032576,
      "grad_norm": 0.00027173725538887084,
      "learning_rate": 1.3101871695956567e-05,
      "loss": 0.1759,
      "step": 24140
    },
    {
      "epoch": 5.1757393913416205,
      "grad_norm": 0.0002493460779078305,
      "learning_rate": 1.3099014144877841e-05,
      "loss": 0.0,
      "step": 24150
    },
    {
      "epoch": 5.177882554650664,
      "grad_norm": 0.00582771236076951,
      "learning_rate": 1.3096156593799113e-05,
      "loss": 0.0006,
      "step": 24160
    },
    {
      "epoch": 5.180025717959708,
      "grad_norm": 0.0002330253046238795,
      "learning_rate": 1.3093299042720389e-05,
      "loss": 0.0003,
      "step": 24170
    },
    {
      "epoch": 5.182168881268753,
      "grad_norm": 0.00040571836871095,
      "learning_rate": 1.3090441491641663e-05,
      "loss": 0.142,
      "step": 24180
    },
    {
      "epoch": 5.184312044577797,
      "grad_norm": 0.002448202343657613,
      "learning_rate": 1.3087583940562939e-05,
      "loss": 0.0,
      "step": 24190
    },
    {
      "epoch": 5.186455207886841,
      "grad_norm": 0.006942292675375938,
      "learning_rate": 1.3084726389484212e-05,
      "loss": 0.0001,
      "step": 24200
    },
    {
      "epoch": 5.188598371195885,
      "grad_norm": 19.337724685668945,
      "learning_rate": 1.3081868838405486e-05,
      "loss": 0.1315,
      "step": 24210
    },
    {
      "epoch": 5.190741534504929,
      "grad_norm": 0.0005696393200196326,
      "learning_rate": 1.3079011287326762e-05,
      "loss": 0.1107,
      "step": 24220
    },
    {
      "epoch": 5.192884697813973,
      "grad_norm": 0.004164284095168114,
      "learning_rate": 1.3076153736248036e-05,
      "loss": 0.0015,
      "step": 24230
    },
    {
      "epoch": 5.195027861123018,
      "grad_norm": 0.0072730365209281445,
      "learning_rate": 1.3073296185169312e-05,
      "loss": 0.2334,
      "step": 24240
    },
    {
      "epoch": 5.197171024432062,
      "grad_norm": 0.0006067304057069123,
      "learning_rate": 1.3070438634090586e-05,
      "loss": 0.0344,
      "step": 24250
    },
    {
      "epoch": 5.1993141877411055,
      "grad_norm": 0.0006015263497829437,
      "learning_rate": 1.306758108301186e-05,
      "loss": 0.258,
      "step": 24260
    },
    {
      "epoch": 5.20145735105015,
      "grad_norm": 0.00017330324044451118,
      "learning_rate": 1.3064723531933135e-05,
      "loss": 0.0087,
      "step": 24270
    },
    {
      "epoch": 5.203600514359194,
      "grad_norm": 0.00023272610269486904,
      "learning_rate": 1.3061865980854409e-05,
      "loss": 0.0002,
      "step": 24280
    },
    {
      "epoch": 5.205743677668238,
      "grad_norm": 0.0738002359867096,
      "learning_rate": 1.3059008429775683e-05,
      "loss": 0.0004,
      "step": 24290
    },
    {
      "epoch": 5.207886840977283,
      "grad_norm": 0.00018338662630412728,
      "learning_rate": 1.3056150878696959e-05,
      "loss": 0.0004,
      "step": 24300
    },
    {
      "epoch": 5.210030004286327,
      "grad_norm": 0.00020984305592719465,
      "learning_rate": 1.3053293327618232e-05,
      "loss": 0.0007,
      "step": 24310
    },
    {
      "epoch": 5.21217316759537,
      "grad_norm": 0.00016636426153127104,
      "learning_rate": 1.3050435776539508e-05,
      "loss": 0.0001,
      "step": 24320
    },
    {
      "epoch": 5.214316330904415,
      "grad_norm": 0.000217491397052072,
      "learning_rate": 1.3047578225460782e-05,
      "loss": 0.2774,
      "step": 24330
    },
    {
      "epoch": 5.216459494213459,
      "grad_norm": 0.0004094420582987368,
      "learning_rate": 1.3044720674382056e-05,
      "loss": 0.0,
      "step": 24340
    },
    {
      "epoch": 5.218602657522503,
      "grad_norm": 0.0005889523308724165,
      "learning_rate": 1.3041863123303332e-05,
      "loss": 0.2136,
      "step": 24350
    },
    {
      "epoch": 5.220745820831548,
      "grad_norm": 0.000468697864562273,
      "learning_rate": 1.3039005572224606e-05,
      "loss": 0.0092,
      "step": 24360
    },
    {
      "epoch": 5.222888984140591,
      "grad_norm": 0.00038230197969824076,
      "learning_rate": 1.3036148021145878e-05,
      "loss": 0.0257,
      "step": 24370
    },
    {
      "epoch": 5.225032147449635,
      "grad_norm": 0.018220486119389534,
      "learning_rate": 1.3033290470067153e-05,
      "loss": 0.2103,
      "step": 24380
    },
    {
      "epoch": 5.22717531075868,
      "grad_norm": 0.0031230440363287926,
      "learning_rate": 1.3030432918988427e-05,
      "loss": 0.0527,
      "step": 24390
    },
    {
      "epoch": 5.229318474067724,
      "grad_norm": 0.001728865783661604,
      "learning_rate": 1.3027575367909701e-05,
      "loss": 0.0006,
      "step": 24400
    },
    {
      "epoch": 5.231461637376768,
      "grad_norm": 0.0002692698617465794,
      "learning_rate": 1.3024717816830977e-05,
      "loss": 0.1703,
      "step": 24410
    },
    {
      "epoch": 5.2336048006858125,
      "grad_norm": 0.00045208510709926486,
      "learning_rate": 1.302186026575225e-05,
      "loss": 0.0007,
      "step": 24420
    },
    {
      "epoch": 5.235747963994856,
      "grad_norm": 0.10246528685092926,
      "learning_rate": 1.3019002714673525e-05,
      "loss": 0.1607,
      "step": 24430
    },
    {
      "epoch": 5.2378911273039,
      "grad_norm": 0.006698851007968187,
      "learning_rate": 1.30161451635948e-05,
      "loss": 0.4713,
      "step": 24440
    },
    {
      "epoch": 5.240034290612945,
      "grad_norm": 0.0021172247361391783,
      "learning_rate": 1.3013287612516074e-05,
      "loss": 0.1265,
      "step": 24450
    },
    {
      "epoch": 5.242177453921989,
      "grad_norm": 0.0117246238514781,
      "learning_rate": 1.301043006143735e-05,
      "loss": 0.0011,
      "step": 24460
    },
    {
      "epoch": 5.244320617231033,
      "grad_norm": 0.0006110300309956074,
      "learning_rate": 1.3007572510358624e-05,
      "loss": 0.2676,
      "step": 24470
    },
    {
      "epoch": 5.246463780540077,
      "grad_norm": 0.14362260699272156,
      "learning_rate": 1.3004714959279898e-05,
      "loss": 0.0005,
      "step": 24480
    },
    {
      "epoch": 5.248606943849121,
      "grad_norm": 0.0018216391326859593,
      "learning_rate": 1.3001857408201173e-05,
      "loss": 0.0061,
      "step": 24490
    },
    {
      "epoch": 5.250750107158165,
      "grad_norm": 0.0003764060384128243,
      "learning_rate": 1.2998999857122447e-05,
      "loss": 0.0106,
      "step": 24500
    },
    {
      "epoch": 5.25289327046721,
      "grad_norm": 0.14981885254383087,
      "learning_rate": 1.2996142306043721e-05,
      "loss": 0.1959,
      "step": 24510
    },
    {
      "epoch": 5.255036433776254,
      "grad_norm": 0.00033062801230698824,
      "learning_rate": 1.2993284754964997e-05,
      "loss": 0.0034,
      "step": 24520
    },
    {
      "epoch": 5.2571795970852975,
      "grad_norm": 56.51141357421875,
      "learning_rate": 1.299042720388627e-05,
      "loss": 0.1912,
      "step": 24530
    },
    {
      "epoch": 5.259322760394342,
      "grad_norm": 0.0004334241966716945,
      "learning_rate": 1.2987569652807546e-05,
      "loss": 0.0002,
      "step": 24540
    },
    {
      "epoch": 5.261465923703386,
      "grad_norm": 0.13516077399253845,
      "learning_rate": 1.298471210172882e-05,
      "loss": 0.0006,
      "step": 24550
    },
    {
      "epoch": 5.26360908701243,
      "grad_norm": 0.006564923096448183,
      "learning_rate": 1.2981854550650094e-05,
      "loss": 0.3106,
      "step": 24560
    },
    {
      "epoch": 5.265752250321475,
      "grad_norm": 0.025818398222327232,
      "learning_rate": 1.297899699957137e-05,
      "loss": 0.0003,
      "step": 24570
    },
    {
      "epoch": 5.2678954136305185,
      "grad_norm": 0.014138102531433105,
      "learning_rate": 1.2976139448492644e-05,
      "loss": 0.0,
      "step": 24580
    },
    {
      "epoch": 5.270038576939562,
      "grad_norm": 0.0003870096697937697,
      "learning_rate": 1.2973281897413916e-05,
      "loss": 0.0002,
      "step": 24590
    },
    {
      "epoch": 5.272181740248607,
      "grad_norm": 0.00024022141587920487,
      "learning_rate": 1.2970424346335192e-05,
      "loss": 0.0,
      "step": 24600
    },
    {
      "epoch": 5.274324903557651,
      "grad_norm": 0.00020462425891309977,
      "learning_rate": 1.2967566795256466e-05,
      "loss": 0.0004,
      "step": 24610
    },
    {
      "epoch": 5.276468066866695,
      "grad_norm": 0.0008975628297775984,
      "learning_rate": 1.296470924417774e-05,
      "loss": 0.4047,
      "step": 24620
    },
    {
      "epoch": 5.2786112301757395,
      "grad_norm": 22.670774459838867,
      "learning_rate": 1.2961851693099015e-05,
      "loss": 0.24,
      "step": 24630
    },
    {
      "epoch": 5.280754393484783,
      "grad_norm": 0.0448402464389801,
      "learning_rate": 1.2958994142020289e-05,
      "loss": 0.0003,
      "step": 24640
    },
    {
      "epoch": 5.282897556793827,
      "grad_norm": 0.005258478224277496,
      "learning_rate": 1.2956136590941563e-05,
      "loss": 0.0005,
      "step": 24650
    },
    {
      "epoch": 5.285040720102872,
      "grad_norm": 0.06447622179985046,
      "learning_rate": 1.2953279039862839e-05,
      "loss": 0.2444,
      "step": 24660
    },
    {
      "epoch": 5.287183883411916,
      "grad_norm": 0.0059336400590837,
      "learning_rate": 1.2950421488784113e-05,
      "loss": 0.0009,
      "step": 24670
    },
    {
      "epoch": 5.2893270467209605,
      "grad_norm": 0.0008370408322662115,
      "learning_rate": 1.2947563937705388e-05,
      "loss": 0.0006,
      "step": 24680
    },
    {
      "epoch": 5.291470210030004,
      "grad_norm": 0.0004990367451682687,
      "learning_rate": 1.2944706386626662e-05,
      "loss": 0.0001,
      "step": 24690
    },
    {
      "epoch": 5.293613373339048,
      "grad_norm": 1.207801103591919,
      "learning_rate": 1.2941848835547936e-05,
      "loss": 0.0028,
      "step": 24700
    },
    {
      "epoch": 5.295756536648093,
      "grad_norm": 0.002041501458734274,
      "learning_rate": 1.2938991284469212e-05,
      "loss": 0.1229,
      "step": 24710
    },
    {
      "epoch": 5.297899699957137,
      "grad_norm": 0.0158137995749712,
      "learning_rate": 1.2936133733390486e-05,
      "loss": 0.0002,
      "step": 24720
    },
    {
      "epoch": 5.300042863266181,
      "grad_norm": 0.0003363071009516716,
      "learning_rate": 1.293327618231176e-05,
      "loss": 0.0,
      "step": 24730
    },
    {
      "epoch": 5.302186026575225,
      "grad_norm": 0.0002753646986093372,
      "learning_rate": 1.2930418631233035e-05,
      "loss": 0.0,
      "step": 24740
    },
    {
      "epoch": 5.304329189884269,
      "grad_norm": 0.0024657396133989096,
      "learning_rate": 1.2927561080154309e-05,
      "loss": 0.0,
      "step": 24750
    },
    {
      "epoch": 5.306472353193313,
      "grad_norm": 0.000711957283783704,
      "learning_rate": 1.2924703529075585e-05,
      "loss": 0.2033,
      "step": 24760
    },
    {
      "epoch": 5.308615516502358,
      "grad_norm": 0.0017394213937222958,
      "learning_rate": 1.2921845977996859e-05,
      "loss": 0.2306,
      "step": 24770
    },
    {
      "epoch": 5.310758679811402,
      "grad_norm": 0.000504464318510145,
      "learning_rate": 1.2918988426918133e-05,
      "loss": 0.0001,
      "step": 24780
    },
    {
      "epoch": 5.3129018431204456,
      "grad_norm": 0.028418049216270447,
      "learning_rate": 1.2916130875839408e-05,
      "loss": 0.2292,
      "step": 24790
    },
    {
      "epoch": 5.31504500642949,
      "grad_norm": 0.0522245429456234,
      "learning_rate": 1.291327332476068e-05,
      "loss": 0.0006,
      "step": 24800
    },
    {
      "epoch": 5.317188169738534,
      "grad_norm": 0.000616573088336736,
      "learning_rate": 1.2910415773681954e-05,
      "loss": 0.189,
      "step": 24810
    },
    {
      "epoch": 5.319331333047578,
      "grad_norm": 0.031364597380161285,
      "learning_rate": 1.290755822260323e-05,
      "loss": 0.0008,
      "step": 24820
    },
    {
      "epoch": 5.321474496356623,
      "grad_norm": 0.0011952442582696676,
      "learning_rate": 1.2904700671524504e-05,
      "loss": 0.129,
      "step": 24830
    },
    {
      "epoch": 5.323617659665667,
      "grad_norm": 0.05311812087893486,
      "learning_rate": 1.2901843120445778e-05,
      "loss": 0.0012,
      "step": 24840
    },
    {
      "epoch": 5.32576082297471,
      "grad_norm": 0.005698637571185827,
      "learning_rate": 1.2898985569367053e-05,
      "loss": 0.2104,
      "step": 24850
    },
    {
      "epoch": 5.327903986283755,
      "grad_norm": 0.254398375749588,
      "learning_rate": 1.2896128018288327e-05,
      "loss": 0.0013,
      "step": 24860
    },
    {
      "epoch": 5.330047149592799,
      "grad_norm": 0.00019496023014653474,
      "learning_rate": 1.2893270467209601e-05,
      "loss": 0.2951,
      "step": 24870
    },
    {
      "epoch": 5.332190312901843,
      "grad_norm": 0.12770381569862366,
      "learning_rate": 1.2890412916130877e-05,
      "loss": 0.4866,
      "step": 24880
    },
    {
      "epoch": 5.334333476210888,
      "grad_norm": 0.22519735991954803,
      "learning_rate": 1.288755536505215e-05,
      "loss": 0.0964,
      "step": 24890
    },
    {
      "epoch": 5.3364766395199315,
      "grad_norm": 0.0036483341827988625,
      "learning_rate": 1.2884697813973426e-05,
      "loss": 0.1303,
      "step": 24900
    },
    {
      "epoch": 5.338619802828975,
      "grad_norm": 0.028537608683109283,
      "learning_rate": 1.28818402628947e-05,
      "loss": 0.1567,
      "step": 24910
    },
    {
      "epoch": 5.34076296613802,
      "grad_norm": 28.002126693725586,
      "learning_rate": 1.2878982711815974e-05,
      "loss": 1.087,
      "step": 24920
    },
    {
      "epoch": 5.342906129447064,
      "grad_norm": 0.8757857084274292,
      "learning_rate": 1.287612516073725e-05,
      "loss": 0.3225,
      "step": 24930
    },
    {
      "epoch": 5.345049292756108,
      "grad_norm": 0.27519628405570984,
      "learning_rate": 1.2873267609658524e-05,
      "loss": 0.8114,
      "step": 24940
    },
    {
      "epoch": 5.3471924560651525,
      "grad_norm": 27.560848236083984,
      "learning_rate": 1.28704100585798e-05,
      "loss": 0.6228,
      "step": 24950
    },
    {
      "epoch": 5.349335619374196,
      "grad_norm": 0.3201659023761749,
      "learning_rate": 1.2867552507501073e-05,
      "loss": 0.8337,
      "step": 24960
    },
    {
      "epoch": 5.35147878268324,
      "grad_norm": 0.23192007839679718,
      "learning_rate": 1.2864694956422347e-05,
      "loss": 0.2989,
      "step": 24970
    },
    {
      "epoch": 5.353621945992285,
      "grad_norm": 27.575881958007812,
      "learning_rate": 1.2861837405343623e-05,
      "loss": 0.6774,
      "step": 24980
    },
    {
      "epoch": 5.355765109301329,
      "grad_norm": 46.44540023803711,
      "learning_rate": 1.2858979854264897e-05,
      "loss": 0.6475,
      "step": 24990
    },
    {
      "epoch": 5.357908272610373,
      "grad_norm": 27.100261688232422,
      "learning_rate": 1.285612230318617e-05,
      "loss": 0.7308,
      "step": 25000
    },
    {
      "epoch": 5.360051435919417,
      "grad_norm": 0.6320548057556152,
      "learning_rate": 1.2853264752107446e-05,
      "loss": 0.4344,
      "step": 25010
    },
    {
      "epoch": 5.362194599228461,
      "grad_norm": 26.74664878845215,
      "learning_rate": 1.2850407201028719e-05,
      "loss": 0.6236,
      "step": 25020
    },
    {
      "epoch": 5.364337762537505,
      "grad_norm": 28.680931091308594,
      "learning_rate": 1.2847549649949993e-05,
      "loss": 0.2236,
      "step": 25030
    },
    {
      "epoch": 5.36648092584655,
      "grad_norm": 28.897045135498047,
      "learning_rate": 1.2844692098871268e-05,
      "loss": 0.8207,
      "step": 25040
    },
    {
      "epoch": 5.368624089155594,
      "grad_norm": 21.98230743408203,
      "learning_rate": 1.2841834547792542e-05,
      "loss": 0.5917,
      "step": 25050
    },
    {
      "epoch": 5.3707672524646375,
      "grad_norm": 0.13949929177761078,
      "learning_rate": 1.2838976996713816e-05,
      "loss": 0.1602,
      "step": 25060
    },
    {
      "epoch": 5.372910415773682,
      "grad_norm": 0.30046480894088745,
      "learning_rate": 1.2836119445635092e-05,
      "loss": 0.7817,
      "step": 25070
    },
    {
      "epoch": 5.375053579082726,
      "grad_norm": 0.24130381643772125,
      "learning_rate": 1.2833261894556366e-05,
      "loss": 0.1878,
      "step": 25080
    },
    {
      "epoch": 5.37719674239177,
      "grad_norm": 22.791278839111328,
      "learning_rate": 1.2830404343477641e-05,
      "loss": 0.2312,
      "step": 25090
    },
    {
      "epoch": 5.379339905700815,
      "grad_norm": 0.04387986660003662,
      "learning_rate": 1.2827546792398915e-05,
      "loss": 0.001,
      "step": 25100
    },
    {
      "epoch": 5.3814830690098585,
      "grad_norm": 0.03402180224657059,
      "learning_rate": 1.2824689241320189e-05,
      "loss": 0.0008,
      "step": 25110
    },
    {
      "epoch": 5.383626232318902,
      "grad_norm": 0.06667220592498779,
      "learning_rate": 1.2821831690241465e-05,
      "loss": 0.0006,
      "step": 25120
    },
    {
      "epoch": 5.385769395627947,
      "grad_norm": 0.029412992298603058,
      "learning_rate": 1.2818974139162739e-05,
      "loss": 0.4895,
      "step": 25130
    },
    {
      "epoch": 5.387912558936991,
      "grad_norm": 0.04652068763971329,
      "learning_rate": 1.2816116588084013e-05,
      "loss": 0.2371,
      "step": 25140
    },
    {
      "epoch": 5.390055722246035,
      "grad_norm": 25.299123764038086,
      "learning_rate": 1.2813259037005288e-05,
      "loss": 0.8751,
      "step": 25150
    },
    {
      "epoch": 5.3921988855550795,
      "grad_norm": 24.672752380371094,
      "learning_rate": 1.2810401485926562e-05,
      "loss": 0.3567,
      "step": 25160
    },
    {
      "epoch": 5.394342048864123,
      "grad_norm": 0.38436654210090637,
      "learning_rate": 1.2807543934847838e-05,
      "loss": 0.5063,
      "step": 25170
    },
    {
      "epoch": 5.396485212173167,
      "grad_norm": 0.32043877243995667,
      "learning_rate": 1.2804686383769112e-05,
      "loss": 0.5186,
      "step": 25180
    },
    {
      "epoch": 5.398628375482212,
      "grad_norm": 25.493783950805664,
      "learning_rate": 1.2801828832690386e-05,
      "loss": 0.3038,
      "step": 25190
    },
    {
      "epoch": 5.400771538791256,
      "grad_norm": 0.09981634467840195,
      "learning_rate": 1.2798971281611661e-05,
      "loss": 0.5904,
      "step": 25200
    },
    {
      "epoch": 5.4029147021003,
      "grad_norm": 26.658493041992188,
      "learning_rate": 1.2796113730532935e-05,
      "loss": 0.6362,
      "step": 25210
    },
    {
      "epoch": 5.405057865409344,
      "grad_norm": 0.1971873641014099,
      "learning_rate": 1.2793256179454209e-05,
      "loss": 0.1809,
      "step": 25220
    },
    {
      "epoch": 5.407201028718388,
      "grad_norm": 0.2549877464771271,
      "learning_rate": 1.2790398628375483e-05,
      "loss": 0.4242,
      "step": 25230
    },
    {
      "epoch": 5.409344192027432,
      "grad_norm": 28.238603591918945,
      "learning_rate": 1.2787541077296757e-05,
      "loss": 0.5984,
      "step": 25240
    },
    {
      "epoch": 5.411487355336477,
      "grad_norm": 0.11678924411535263,
      "learning_rate": 1.2784683526218031e-05,
      "loss": 0.0029,
      "step": 25250
    },
    {
      "epoch": 5.413630518645521,
      "grad_norm": 0.127289280295372,
      "learning_rate": 1.2781825975139306e-05,
      "loss": 0.461,
      "step": 25260
    },
    {
      "epoch": 5.4157736819545645,
      "grad_norm": 0.11504562199115753,
      "learning_rate": 1.277896842406058e-05,
      "loss": 0.4151,
      "step": 25270
    },
    {
      "epoch": 5.417916845263609,
      "grad_norm": 23.13186264038086,
      "learning_rate": 1.2776110872981854e-05,
      "loss": 0.6273,
      "step": 25280
    },
    {
      "epoch": 5.420060008572653,
      "grad_norm": 0.17516648769378662,
      "learning_rate": 1.277325332190313e-05,
      "loss": 0.5552,
      "step": 25290
    },
    {
      "epoch": 5.422203171881697,
      "grad_norm": 0.3451063632965088,
      "learning_rate": 1.2770395770824404e-05,
      "loss": 0.1657,
      "step": 25300
    },
    {
      "epoch": 5.424346335190742,
      "grad_norm": 0.08958457410335541,
      "learning_rate": 1.276753821974568e-05,
      "loss": 0.6098,
      "step": 25310
    },
    {
      "epoch": 5.426489498499786,
      "grad_norm": 0.13844455778598785,
      "learning_rate": 1.2764680668666953e-05,
      "loss": 0.002,
      "step": 25320
    },
    {
      "epoch": 5.428632661808829,
      "grad_norm": 0.1715875118970871,
      "learning_rate": 1.2761823117588227e-05,
      "loss": 0.4887,
      "step": 25330
    },
    {
      "epoch": 5.430775825117874,
      "grad_norm": 0.25393128395080566,
      "learning_rate": 1.2758965566509503e-05,
      "loss": 1.051,
      "step": 25340
    },
    {
      "epoch": 5.432918988426918,
      "grad_norm": 0.46863868832588196,
      "learning_rate": 1.2756108015430777e-05,
      "loss": 0.3912,
      "step": 25350
    },
    {
      "epoch": 5.435062151735963,
      "grad_norm": 0.24753783643245697,
      "learning_rate": 1.2753250464352051e-05,
      "loss": 0.578,
      "step": 25360
    },
    {
      "epoch": 5.437205315045007,
      "grad_norm": 24.693204879760742,
      "learning_rate": 1.2750392913273326e-05,
      "loss": 1.0857,
      "step": 25370
    },
    {
      "epoch": 5.43934847835405,
      "grad_norm": 24.686960220336914,
      "learning_rate": 1.27475353621946e-05,
      "loss": 0.3385,
      "step": 25380
    },
    {
      "epoch": 5.441491641663095,
      "grad_norm": 0.6808927059173584,
      "learning_rate": 1.2744677811115876e-05,
      "loss": 0.6542,
      "step": 25390
    },
    {
      "epoch": 5.443634804972139,
      "grad_norm": 25.664276123046875,
      "learning_rate": 1.274182026003715e-05,
      "loss": 0.194,
      "step": 25400
    },
    {
      "epoch": 5.445777968281183,
      "grad_norm": 0.25364866852760315,
      "learning_rate": 1.2738962708958424e-05,
      "loss": 0.9032,
      "step": 25410
    },
    {
      "epoch": 5.447921131590228,
      "grad_norm": 0.29038554430007935,
      "learning_rate": 1.27361051578797e-05,
      "loss": 0.1937,
      "step": 25420
    },
    {
      "epoch": 5.4500642948992715,
      "grad_norm": 0.2278737723827362,
      "learning_rate": 1.2733247606800973e-05,
      "loss": 0.0034,
      "step": 25430
    },
    {
      "epoch": 5.452207458208315,
      "grad_norm": 24.795448303222656,
      "learning_rate": 1.2730390055722247e-05,
      "loss": 0.4174,
      "step": 25440
    },
    {
      "epoch": 5.45435062151736,
      "grad_norm": 0.14758418500423431,
      "learning_rate": 1.2727532504643521e-05,
      "loss": 1.0964,
      "step": 25450
    },
    {
      "epoch": 5.456493784826404,
      "grad_norm": 0.271110475063324,
      "learning_rate": 1.2724674953564795e-05,
      "loss": 0.5393,
      "step": 25460
    },
    {
      "epoch": 5.458636948135448,
      "grad_norm": 0.35683709383010864,
      "learning_rate": 1.2721817402486069e-05,
      "loss": 0.6549,
      "step": 25470
    },
    {
      "epoch": 5.4607801114444925,
      "grad_norm": 22.083343505859375,
      "learning_rate": 1.2718959851407345e-05,
      "loss": 0.3792,
      "step": 25480
    },
    {
      "epoch": 5.462923274753536,
      "grad_norm": 0.20138844847679138,
      "learning_rate": 1.2716102300328619e-05,
      "loss": 0.3881,
      "step": 25490
    },
    {
      "epoch": 5.46506643806258,
      "grad_norm": 0.12491203844547272,
      "learning_rate": 1.2713244749249893e-05,
      "loss": 0.3601,
      "step": 25500
    },
    {
      "epoch": 5.467209601371625,
      "grad_norm": 0.15423551201820374,
      "learning_rate": 1.2710387198171168e-05,
      "loss": 0.1989,
      "step": 25510
    },
    {
      "epoch": 5.469352764680669,
      "grad_norm": 28.041584014892578,
      "learning_rate": 1.2707529647092442e-05,
      "loss": 0.372,
      "step": 25520
    },
    {
      "epoch": 5.471495927989713,
      "grad_norm": 0.04562971368432045,
      "learning_rate": 1.2704672096013718e-05,
      "loss": 0.1994,
      "step": 25530
    },
    {
      "epoch": 5.473639091298757,
      "grad_norm": 0.34232762455940247,
      "learning_rate": 1.2701814544934992e-05,
      "loss": 0.8833,
      "step": 25540
    },
    {
      "epoch": 5.475782254607801,
      "grad_norm": 0.6245134472846985,
      "learning_rate": 1.2698956993856266e-05,
      "loss": 0.84,
      "step": 25550
    },
    {
      "epoch": 5.477925417916845,
      "grad_norm": 0.20006859302520752,
      "learning_rate": 1.2696099442777541e-05,
      "loss": 0.3185,
      "step": 25560
    },
    {
      "epoch": 5.48006858122589,
      "grad_norm": 0.16558875143527985,
      "learning_rate": 1.2693241891698815e-05,
      "loss": 0.1782,
      "step": 25570
    },
    {
      "epoch": 5.482211744534934,
      "grad_norm": 0.2452675700187683,
      "learning_rate": 1.2690384340620089e-05,
      "loss": 0.5954,
      "step": 25580
    },
    {
      "epoch": 5.4843549078439775,
      "grad_norm": 0.3248329162597656,
      "learning_rate": 1.2687526789541365e-05,
      "loss": 0.3977,
      "step": 25590
    },
    {
      "epoch": 5.486498071153022,
      "grad_norm": 0.10282061994075775,
      "learning_rate": 1.2684669238462639e-05,
      "loss": 0.0028,
      "step": 25600
    },
    {
      "epoch": 5.488641234462066,
      "grad_norm": 22.941783905029297,
      "learning_rate": 1.2681811687383914e-05,
      "loss": 1.0061,
      "step": 25610
    },
    {
      "epoch": 5.49078439777111,
      "grad_norm": 0.33575233817100525,
      "learning_rate": 1.2678954136305188e-05,
      "loss": 0.4976,
      "step": 25620
    },
    {
      "epoch": 5.492927561080155,
      "grad_norm": 0.21189431846141815,
      "learning_rate": 1.2676096585226462e-05,
      "loss": 0.3485,
      "step": 25630
    },
    {
      "epoch": 5.4950707243891985,
      "grad_norm": 25.757938385009766,
      "learning_rate": 1.2673239034147738e-05,
      "loss": 0.565,
      "step": 25640
    },
    {
      "epoch": 5.497213887698242,
      "grad_norm": 0.20776572823524475,
      "learning_rate": 1.2670381483069012e-05,
      "loss": 0.8825,
      "step": 25650
    },
    {
      "epoch": 5.499357051007287,
      "grad_norm": 1.1058696508407593,
      "learning_rate": 1.2667523931990284e-05,
      "loss": 0.738,
      "step": 25660
    },
    {
      "epoch": 5.501500214316331,
      "grad_norm": 25.444965362548828,
      "learning_rate": 1.266466638091156e-05,
      "loss": 0.6722,
      "step": 25670
    },
    {
      "epoch": 5.503643377625375,
      "grad_norm": 0.2680840790271759,
      "learning_rate": 1.2661808829832833e-05,
      "loss": 0.2403,
      "step": 25680
    },
    {
      "epoch": 5.5057865409344195,
      "grad_norm": 0.06636247783899307,
      "learning_rate": 1.2658951278754107e-05,
      "loss": 0.3796,
      "step": 25690
    },
    {
      "epoch": 5.507929704243463,
      "grad_norm": 25.584726333618164,
      "learning_rate": 1.2656093727675383e-05,
      "loss": 0.5251,
      "step": 25700
    },
    {
      "epoch": 5.510072867552507,
      "grad_norm": 0.22526633739471436,
      "learning_rate": 1.2653236176596657e-05,
      "loss": 0.1591,
      "step": 25710
    },
    {
      "epoch": 5.512216030861552,
      "grad_norm": 4.140895366668701,
      "learning_rate": 1.2650378625517931e-05,
      "loss": 0.1982,
      "step": 25720
    },
    {
      "epoch": 5.514359194170596,
      "grad_norm": 0.23567962646484375,
      "learning_rate": 1.2647521074439207e-05,
      "loss": 0.001,
      "step": 25730
    },
    {
      "epoch": 5.51650235747964,
      "grad_norm": 0.11670097708702087,
      "learning_rate": 1.264466352336048e-05,
      "loss": 0.008,
      "step": 25740
    },
    {
      "epoch": 5.518645520788684,
      "grad_norm": 0.004982901271432638,
      "learning_rate": 1.2641805972281756e-05,
      "loss": 0.0002,
      "step": 25750
    },
    {
      "epoch": 5.520788684097728,
      "grad_norm": 0.0017308787209913135,
      "learning_rate": 1.263894842120303e-05,
      "loss": 0.2031,
      "step": 25760
    },
    {
      "epoch": 5.522931847406772,
      "grad_norm": 0.0600963719189167,
      "learning_rate": 1.2636090870124304e-05,
      "loss": 0.0005,
      "step": 25770
    },
    {
      "epoch": 5.525075010715817,
      "grad_norm": 0.08324828743934631,
      "learning_rate": 1.263323331904558e-05,
      "loss": 0.258,
      "step": 25780
    },
    {
      "epoch": 5.527218174024861,
      "grad_norm": 0.032789599150419235,
      "learning_rate": 1.2630375767966853e-05,
      "loss": 0.0008,
      "step": 25790
    },
    {
      "epoch": 5.529361337333905,
      "grad_norm": 0.12822279334068298,
      "learning_rate": 1.2627518216888129e-05,
      "loss": 0.1227,
      "step": 25800
    },
    {
      "epoch": 5.531504500642949,
      "grad_norm": 0.0002345721295569092,
      "learning_rate": 1.2624660665809403e-05,
      "loss": 0.0001,
      "step": 25810
    },
    {
      "epoch": 5.533647663951993,
      "grad_norm": 0.00020555454830173403,
      "learning_rate": 1.2621803114730677e-05,
      "loss": 0.3973,
      "step": 25820
    },
    {
      "epoch": 5.535790827261037,
      "grad_norm": 0.0015308876754716039,
      "learning_rate": 1.2618945563651953e-05,
      "loss": 0.2078,
      "step": 25830
    },
    {
      "epoch": 5.537933990570082,
      "grad_norm": 0.07268308848142624,
      "learning_rate": 1.2616088012573227e-05,
      "loss": 0.0033,
      "step": 25840
    },
    {
      "epoch": 5.540077153879126,
      "grad_norm": 0.8960813283920288,
      "learning_rate": 1.26132304614945e-05,
      "loss": 0.1923,
      "step": 25850
    },
    {
      "epoch": 5.542220317188169,
      "grad_norm": 0.06923331320285797,
      "learning_rate": 1.2610372910415776e-05,
      "loss": 0.0016,
      "step": 25860
    },
    {
      "epoch": 5.544363480497214,
      "grad_norm": 0.1267743855714798,
      "learning_rate": 1.260751535933705e-05,
      "loss": 0.0011,
      "step": 25870
    },
    {
      "epoch": 5.546506643806258,
      "grad_norm": 0.07605160027742386,
      "learning_rate": 1.2604657808258322e-05,
      "loss": 0.0009,
      "step": 25880
    },
    {
      "epoch": 5.548649807115302,
      "grad_norm": 0.03373407572507858,
      "learning_rate": 1.2601800257179598e-05,
      "loss": 0.0002,
      "step": 25890
    },
    {
      "epoch": 5.550792970424347,
      "grad_norm": 0.00023339166364166886,
      "learning_rate": 1.2598942706100872e-05,
      "loss": 0.0003,
      "step": 25900
    },
    {
      "epoch": 5.5529361337333905,
      "grad_norm": 0.05210500210523605,
      "learning_rate": 1.2596085155022146e-05,
      "loss": 0.0008,
      "step": 25910
    },
    {
      "epoch": 5.555079297042434,
      "grad_norm": 0.006680996622890234,
      "learning_rate": 1.2593227603943421e-05,
      "loss": 0.1094,
      "step": 25920
    },
    {
      "epoch": 5.557222460351479,
      "grad_norm": 0.022060010582208633,
      "learning_rate": 1.2590370052864695e-05,
      "loss": 0.0002,
      "step": 25930
    },
    {
      "epoch": 5.559365623660523,
      "grad_norm": 0.005510745104402304,
      "learning_rate": 1.2587512501785971e-05,
      "loss": 0.0002,
      "step": 25940
    },
    {
      "epoch": 5.561508786969567,
      "grad_norm": 0.0001596918737050146,
      "learning_rate": 1.2584654950707245e-05,
      "loss": 0.1951,
      "step": 25950
    },
    {
      "epoch": 5.5636519502786115,
      "grad_norm": 0.13505908846855164,
      "learning_rate": 1.2581797399628519e-05,
      "loss": 0.0002,
      "step": 25960
    },
    {
      "epoch": 5.565795113587655,
      "grad_norm": 0.00017065320571418852,
      "learning_rate": 1.2578939848549794e-05,
      "loss": 0.0005,
      "step": 25970
    },
    {
      "epoch": 5.567938276896699,
      "grad_norm": 0.0028503690846264362,
      "learning_rate": 1.2576082297471068e-05,
      "loss": 0.0002,
      "step": 25980
    },
    {
      "epoch": 5.570081440205744,
      "grad_norm": 0.00013799095177091658,
      "learning_rate": 1.2573224746392342e-05,
      "loss": 0.0,
      "step": 25990
    },
    {
      "epoch": 5.572224603514788,
      "grad_norm": 0.028092237189412117,
      "learning_rate": 1.2570367195313618e-05,
      "loss": 0.5427,
      "step": 26000
    },
    {
      "epoch": 5.574367766823832,
      "grad_norm": 0.0001969787263078615,
      "learning_rate": 1.2567509644234892e-05,
      "loss": 0.0006,
      "step": 26010
    },
    {
      "epoch": 5.576510930132876,
      "grad_norm": 0.00023771633277647197,
      "learning_rate": 1.2564652093156167e-05,
      "loss": 0.0002,
      "step": 26020
    },
    {
      "epoch": 5.57865409344192,
      "grad_norm": 0.10372553765773773,
      "learning_rate": 1.2561794542077441e-05,
      "loss": 0.0008,
      "step": 26030
    },
    {
      "epoch": 5.580797256750964,
      "grad_norm": 0.006571589503437281,
      "learning_rate": 1.2558936990998715e-05,
      "loss": 0.2375,
      "step": 26040
    },
    {
      "epoch": 5.582940420060009,
      "grad_norm": 0.00015879637794569135,
      "learning_rate": 1.2556079439919991e-05,
      "loss": 0.0005,
      "step": 26050
    },
    {
      "epoch": 5.585083583369053,
      "grad_norm": 0.00010547367128310725,
      "learning_rate": 1.2553221888841265e-05,
      "loss": 0.0002,
      "step": 26060
    },
    {
      "epoch": 5.5872267466780965,
      "grad_norm": 0.06851314753293991,
      "learning_rate": 1.2550364337762539e-05,
      "loss": 0.1562,
      "step": 26070
    },
    {
      "epoch": 5.589369909987141,
      "grad_norm": 0.015062322840094566,
      "learning_rate": 1.2547506786683814e-05,
      "loss": 0.0006,
      "step": 26080
    },
    {
      "epoch": 5.591513073296185,
      "grad_norm": 0.00019479454203974456,
      "learning_rate": 1.2544649235605087e-05,
      "loss": 0.0003,
      "step": 26090
    },
    {
      "epoch": 5.593656236605229,
      "grad_norm": 0.00013391225365921855,
      "learning_rate": 1.254179168452636e-05,
      "loss": 0.0005,
      "step": 26100
    },
    {
      "epoch": 5.595799399914274,
      "grad_norm": 0.051256630569696426,
      "learning_rate": 1.2538934133447636e-05,
      "loss": 0.0002,
      "step": 26110
    },
    {
      "epoch": 5.5979425632233175,
      "grad_norm": 0.06930714100599289,
      "learning_rate": 1.253607658236891e-05,
      "loss": 0.0003,
      "step": 26120
    },
    {
      "epoch": 5.600085726532361,
      "grad_norm": 0.21543695032596588,
      "learning_rate": 1.2533219031290184e-05,
      "loss": 0.0005,
      "step": 26130
    },
    {
      "epoch": 5.602228889841406,
      "grad_norm": 0.00011441886454122141,
      "learning_rate": 1.253036148021146e-05,
      "loss": 0.0001,
      "step": 26140
    },
    {
      "epoch": 5.60437205315045,
      "grad_norm": 0.00030086899641901255,
      "learning_rate": 1.2527503929132734e-05,
      "loss": 0.0002,
      "step": 26150
    },
    {
      "epoch": 5.606515216459494,
      "grad_norm": 0.00010912313882727176,
      "learning_rate": 1.252464637805401e-05,
      "loss": 0.0001,
      "step": 26160
    },
    {
      "epoch": 5.6086583797685385,
      "grad_norm": 6.724847480654716e-05,
      "learning_rate": 1.2521788826975283e-05,
      "loss": 0.0002,
      "step": 26170
    },
    {
      "epoch": 5.610801543077582,
      "grad_norm": 0.0007084521930664778,
      "learning_rate": 1.2518931275896557e-05,
      "loss": 0.0001,
      "step": 26180
    },
    {
      "epoch": 5.612944706386626,
      "grad_norm": 9.753137419465929e-05,
      "learning_rate": 1.2516073724817833e-05,
      "loss": 0.0,
      "step": 26190
    },
    {
      "epoch": 5.615087869695671,
      "grad_norm": 8.58482817420736e-05,
      "learning_rate": 1.2513216173739107e-05,
      "loss": 0.1673,
      "step": 26200
    },
    {
      "epoch": 5.617231033004715,
      "grad_norm": 0.00011347036343067884,
      "learning_rate": 1.251035862266038e-05,
      "loss": 0.0016,
      "step": 26210
    },
    {
      "epoch": 5.619374196313759,
      "grad_norm": 0.00010003142961068079,
      "learning_rate": 1.2507501071581656e-05,
      "loss": 0.0002,
      "step": 26220
    },
    {
      "epoch": 5.621517359622803,
      "grad_norm": 0.0007332916720770299,
      "learning_rate": 1.250464352050293e-05,
      "loss": 0.0001,
      "step": 26230
    },
    {
      "epoch": 5.623660522931847,
      "grad_norm": 0.00816173106431961,
      "learning_rate": 1.2501785969424206e-05,
      "loss": 0.0001,
      "step": 26240
    },
    {
      "epoch": 5.625803686240891,
      "grad_norm": 9.649463754612952e-05,
      "learning_rate": 1.249892841834548e-05,
      "loss": 0.231,
      "step": 26250
    },
    {
      "epoch": 5.627946849549936,
      "grad_norm": 0.08138022571802139,
      "learning_rate": 1.2496070867266754e-05,
      "loss": 0.0003,
      "step": 26260
    },
    {
      "epoch": 5.63009001285898,
      "grad_norm": 0.05548777058720589,
      "learning_rate": 1.2493213316188029e-05,
      "loss": 0.0005,
      "step": 26270
    },
    {
      "epoch": 5.6322331761680235,
      "grad_norm": 0.007694074418395758,
      "learning_rate": 1.2490355765109303e-05,
      "loss": 0.0002,
      "step": 26280
    },
    {
      "epoch": 5.634376339477068,
      "grad_norm": 8.276992593891919e-05,
      "learning_rate": 1.2487498214030577e-05,
      "loss": 0.1957,
      "step": 26290
    },
    {
      "epoch": 5.636519502786112,
      "grad_norm": 0.00011135176464449614,
      "learning_rate": 1.2484640662951851e-05,
      "loss": 0.0004,
      "step": 26300
    },
    {
      "epoch": 5.638662666095156,
      "grad_norm": 0.0001690370700089261,
      "learning_rate": 1.2481783111873125e-05,
      "loss": 0.0009,
      "step": 26310
    },
    {
      "epoch": 5.640805829404201,
      "grad_norm": 0.038642767816782,
      "learning_rate": 1.2478925560794399e-05,
      "loss": 0.0002,
      "step": 26320
    },
    {
      "epoch": 5.642948992713245,
      "grad_norm": 0.00016661928384564817,
      "learning_rate": 1.2476068009715674e-05,
      "loss": 0.0,
      "step": 26330
    },
    {
      "epoch": 5.645092156022288,
      "grad_norm": 7.93286380940117e-05,
      "learning_rate": 1.2473210458636948e-05,
      "loss": 0.0,
      "step": 26340
    },
    {
      "epoch": 5.647235319331333,
      "grad_norm": 0.00804127287119627,
      "learning_rate": 1.2470352907558222e-05,
      "loss": 0.0002,
      "step": 26350
    },
    {
      "epoch": 5.649378482640377,
      "grad_norm": 6.459937867475674e-05,
      "learning_rate": 1.2467495356479498e-05,
      "loss": 0.0001,
      "step": 26360
    },
    {
      "epoch": 5.651521645949421,
      "grad_norm": 7.052813452901319e-05,
      "learning_rate": 1.2464637805400772e-05,
      "loss": 0.2264,
      "step": 26370
    },
    {
      "epoch": 5.653664809258466,
      "grad_norm": 6.514637061627582e-05,
      "learning_rate": 1.2461780254322047e-05,
      "loss": 0.0,
      "step": 26380
    },
    {
      "epoch": 5.6558079725675094,
      "grad_norm": 7.663883297936991e-05,
      "learning_rate": 1.2458922703243321e-05,
      "loss": 0.1109,
      "step": 26390
    },
    {
      "epoch": 5.657951135876553,
      "grad_norm": 30.6096248626709,
      "learning_rate": 1.2456065152164595e-05,
      "loss": 0.223,
      "step": 26400
    },
    {
      "epoch": 5.660094299185598,
      "grad_norm": 8.388885180465877e-05,
      "learning_rate": 1.2453207601085871e-05,
      "loss": 0.0001,
      "step": 26410
    },
    {
      "epoch": 5.662237462494642,
      "grad_norm": 0.0001148293522419408,
      "learning_rate": 1.2450350050007145e-05,
      "loss": 0.0004,
      "step": 26420
    },
    {
      "epoch": 5.664380625803687,
      "grad_norm": 0.042971622198820114,
      "learning_rate": 1.2447492498928419e-05,
      "loss": 0.1537,
      "step": 26430
    },
    {
      "epoch": 5.6665237891127305,
      "grad_norm": 0.00015005706518422812,
      "learning_rate": 1.2444634947849694e-05,
      "loss": 0.0007,
      "step": 26440
    },
    {
      "epoch": 5.668666952421774,
      "grad_norm": 8.876138599589467e-05,
      "learning_rate": 1.2441777396770968e-05,
      "loss": 0.0001,
      "step": 26450
    },
    {
      "epoch": 5.670810115730819,
      "grad_norm": 0.0002032419288298115,
      "learning_rate": 1.2438919845692244e-05,
      "loss": 0.0009,
      "step": 26460
    },
    {
      "epoch": 5.672953279039863,
      "grad_norm": 8.44052410684526e-05,
      "learning_rate": 1.2436062294613518e-05,
      "loss": 0.0015,
      "step": 26470
    },
    {
      "epoch": 5.675096442348907,
      "grad_norm": 9.40325771807693e-05,
      "learning_rate": 1.2433204743534792e-05,
      "loss": 0.1996,
      "step": 26480
    },
    {
      "epoch": 5.6772396056579515,
      "grad_norm": 0.06506099551916122,
      "learning_rate": 1.2430347192456067e-05,
      "loss": 0.1428,
      "step": 26490
    },
    {
      "epoch": 5.679382768966995,
      "grad_norm": 7.90125341154635e-05,
      "learning_rate": 1.2427489641377341e-05,
      "loss": 0.0001,
      "step": 26500
    },
    {
      "epoch": 5.681525932276039,
      "grad_norm": 0.10339491814374924,
      "learning_rate": 1.2424632090298617e-05,
      "loss": 0.0006,
      "step": 26510
    },
    {
      "epoch": 5.683669095585084,
      "grad_norm": 7.553491741418839e-05,
      "learning_rate": 1.242177453921989e-05,
      "loss": 0.0,
      "step": 26520
    },
    {
      "epoch": 5.685812258894128,
      "grad_norm": 7.612266199430451e-05,
      "learning_rate": 1.2418916988141163e-05,
      "loss": 0.0009,
      "step": 26530
    },
    {
      "epoch": 5.687955422203172,
      "grad_norm": 0.00806601531803608,
      "learning_rate": 1.2416059437062437e-05,
      "loss": 0.0002,
      "step": 26540
    },
    {
      "epoch": 5.690098585512216,
      "grad_norm": 0.0066391280852258205,
      "learning_rate": 1.2413201885983713e-05,
      "loss": 0.2311,
      "step": 26550
    },
    {
      "epoch": 5.69224174882126,
      "grad_norm": 0.08237815648317337,
      "learning_rate": 1.2410344334904987e-05,
      "loss": 0.0005,
      "step": 26560
    },
    {
      "epoch": 5.694384912130304,
      "grad_norm": 6.122963532106951e-05,
      "learning_rate": 1.240748678382626e-05,
      "loss": 0.0007,
      "step": 26570
    },
    {
      "epoch": 5.696528075439349,
      "grad_norm": 6.109738751547411e-05,
      "learning_rate": 1.2404629232747536e-05,
      "loss": 0.1433,
      "step": 26580
    },
    {
      "epoch": 5.698671238748393,
      "grad_norm": 7.655975059606135e-05,
      "learning_rate": 1.240177168166881e-05,
      "loss": 0.0005,
      "step": 26590
    },
    {
      "epoch": 5.7008144020574365,
      "grad_norm": 0.5237585306167603,
      "learning_rate": 1.2398914130590086e-05,
      "loss": 0.1103,
      "step": 26600
    },
    {
      "epoch": 5.702957565366481,
      "grad_norm": 9.199610212817788e-05,
      "learning_rate": 1.239605657951136e-05,
      "loss": 0.0002,
      "step": 26610
    },
    {
      "epoch": 5.705100728675525,
      "grad_norm": 7.689102494623512e-05,
      "learning_rate": 1.2393199028432634e-05,
      "loss": 0.0003,
      "step": 26620
    },
    {
      "epoch": 5.707243891984569,
      "grad_norm": 8.124388114083558e-05,
      "learning_rate": 1.239034147735391e-05,
      "loss": 0.0,
      "step": 26630
    },
    {
      "epoch": 5.709387055293614,
      "grad_norm": 9.813141514314339e-05,
      "learning_rate": 1.2387483926275183e-05,
      "loss": 0.0,
      "step": 26640
    },
    {
      "epoch": 5.7115302186026575,
      "grad_norm": 9.191779099637643e-05,
      "learning_rate": 1.2384626375196459e-05,
      "loss": 0.0056,
      "step": 26650
    },
    {
      "epoch": 5.713673381911701,
      "grad_norm": 0.035131216049194336,
      "learning_rate": 1.2381768824117733e-05,
      "loss": 0.0564,
      "step": 26660
    },
    {
      "epoch": 5.715816545220746,
      "grad_norm": 5.49462201888673e-05,
      "learning_rate": 1.2378911273039007e-05,
      "loss": 0.1886,
      "step": 26670
    },
    {
      "epoch": 5.71795970852979,
      "grad_norm": 0.00010819466115208343,
      "learning_rate": 1.2376053721960282e-05,
      "loss": 0.2784,
      "step": 26680
    },
    {
      "epoch": 5.720102871838834,
      "grad_norm": 0.050898000597953796,
      "learning_rate": 1.2373196170881556e-05,
      "loss": 0.0002,
      "step": 26690
    },
    {
      "epoch": 5.7222460351478786,
      "grad_norm": 0.047307614237070084,
      "learning_rate": 1.237033861980283e-05,
      "loss": 0.0005,
      "step": 26700
    },
    {
      "epoch": 5.724389198456922,
      "grad_norm": 0.061620067805051804,
      "learning_rate": 1.2367481068724106e-05,
      "loss": 0.0005,
      "step": 26710
    },
    {
      "epoch": 5.726532361765966,
      "grad_norm": 0.02775455452501774,
      "learning_rate": 1.236462351764538e-05,
      "loss": 0.0003,
      "step": 26720
    },
    {
      "epoch": 5.728675525075011,
      "grad_norm": 0.005840042605996132,
      "learning_rate": 1.2361765966566652e-05,
      "loss": 0.1331,
      "step": 26730
    },
    {
      "epoch": 5.730818688384055,
      "grad_norm": 19.370981216430664,
      "learning_rate": 1.2358908415487927e-05,
      "loss": 0.1833,
      "step": 26740
    },
    {
      "epoch": 5.732961851693099,
      "grad_norm": 57.602603912353516,
      "learning_rate": 1.2356050864409201e-05,
      "loss": 0.1541,
      "step": 26750
    },
    {
      "epoch": 5.735105015002143,
      "grad_norm": 7.700503192609176e-05,
      "learning_rate": 1.2353193313330475e-05,
      "loss": 0.0011,
      "step": 26760
    },
    {
      "epoch": 5.737248178311187,
      "grad_norm": 0.11656156182289124,
      "learning_rate": 1.2350335762251751e-05,
      "loss": 0.1321,
      "step": 26770
    },
    {
      "epoch": 5.739391341620231,
      "grad_norm": 0.0007155183702707291,
      "learning_rate": 1.2347478211173025e-05,
      "loss": 0.0004,
      "step": 26780
    },
    {
      "epoch": 5.741534504929276,
      "grad_norm": 8.61564403749071e-05,
      "learning_rate": 1.23446206600943e-05,
      "loss": 0.0006,
      "step": 26790
    },
    {
      "epoch": 5.74367766823832,
      "grad_norm": 0.0037377693224698305,
      "learning_rate": 1.2341763109015574e-05,
      "loss": 0.2017,
      "step": 26800
    },
    {
      "epoch": 5.745820831547364,
      "grad_norm": 0.001766366884112358,
      "learning_rate": 1.2338905557936848e-05,
      "loss": 0.0002,
      "step": 26810
    },
    {
      "epoch": 5.747963994856408,
      "grad_norm": 34.040287017822266,
      "learning_rate": 1.2336048006858124e-05,
      "loss": 0.1694,
      "step": 26820
    },
    {
      "epoch": 5.750107158165452,
      "grad_norm": 0.38548266887664795,
      "learning_rate": 1.2333190455779398e-05,
      "loss": 0.1515,
      "step": 26830
    },
    {
      "epoch": 5.752250321474496,
      "grad_norm": 0.013691240921616554,
      "learning_rate": 1.2330332904700672e-05,
      "loss": 0.0004,
      "step": 26840
    },
    {
      "epoch": 5.754393484783541,
      "grad_norm": 6.346002919599414e-05,
      "learning_rate": 1.2327475353621947e-05,
      "loss": 0.3084,
      "step": 26850
    },
    {
      "epoch": 5.756536648092585,
      "grad_norm": 6.687065615551546e-05,
      "learning_rate": 1.2324617802543221e-05,
      "loss": 0.1431,
      "step": 26860
    },
    {
      "epoch": 5.758679811401628,
      "grad_norm": 0.09162501990795135,
      "learning_rate": 1.2321760251464497e-05,
      "loss": 0.0004,
      "step": 26870
    },
    {
      "epoch": 5.760822974710673,
      "grad_norm": 0.06823049485683441,
      "learning_rate": 1.2318902700385771e-05,
      "loss": 0.0012,
      "step": 26880
    },
    {
      "epoch": 5.762966138019717,
      "grad_norm": 0.00020355285960249603,
      "learning_rate": 1.2316045149307045e-05,
      "loss": 0.0,
      "step": 26890
    },
    {
      "epoch": 5.765109301328761,
      "grad_norm": 5.2780742407776415e-05,
      "learning_rate": 1.231318759822832e-05,
      "loss": 0.0006,
      "step": 26900
    },
    {
      "epoch": 5.767252464637806,
      "grad_norm": 5.0697242841124535e-05,
      "learning_rate": 1.2310330047149594e-05,
      "loss": 0.0,
      "step": 26910
    },
    {
      "epoch": 5.7693956279468495,
      "grad_norm": 4.7480323701165617e-05,
      "learning_rate": 1.2307472496070868e-05,
      "loss": 0.0008,
      "step": 26920
    },
    {
      "epoch": 5.771538791255894,
      "grad_norm": 4.7734582039993256e-05,
      "learning_rate": 1.2304614944992144e-05,
      "loss": 0.1896,
      "step": 26930
    },
    {
      "epoch": 5.773681954564938,
      "grad_norm": 0.16751700639724731,
      "learning_rate": 1.2301757393913418e-05,
      "loss": 0.0006,
      "step": 26940
    },
    {
      "epoch": 5.775825117873982,
      "grad_norm": 0.14939311146736145,
      "learning_rate": 1.229889984283469e-05,
      "loss": 0.0002,
      "step": 26950
    },
    {
      "epoch": 5.777968281183027,
      "grad_norm": 0.0001830711553338915,
      "learning_rate": 1.2296042291755966e-05,
      "loss": 0.0001,
      "step": 26960
    },
    {
      "epoch": 5.7801114444920705,
      "grad_norm": 4.732099114335142e-05,
      "learning_rate": 1.229318474067724e-05,
      "loss": 0.0001,
      "step": 26970
    },
    {
      "epoch": 5.782254607801114,
      "grad_norm": 1.6155391931533813,
      "learning_rate": 1.2290327189598514e-05,
      "loss": 0.0013,
      "step": 26980
    },
    {
      "epoch": 5.784397771110159,
      "grad_norm": 4.9663049139780924e-05,
      "learning_rate": 1.228746963851979e-05,
      "loss": 0.1965,
      "step": 26990
    },
    {
      "epoch": 5.786540934419203,
      "grad_norm": 0.050532449036836624,
      "learning_rate": 1.2284612087441063e-05,
      "loss": 0.109,
      "step": 27000
    },
    {
      "epoch": 5.788684097728247,
      "grad_norm": 6.775065412512049e-05,
      "learning_rate": 1.2281754536362339e-05,
      "loss": 0.2457,
      "step": 27010
    },
    {
      "epoch": 5.7908272610372915,
      "grad_norm": 6.193401350174099e-05,
      "learning_rate": 1.2278896985283613e-05,
      "loss": 0.0003,
      "step": 27020
    },
    {
      "epoch": 5.792970424346335,
      "grad_norm": 1.1046756505966187,
      "learning_rate": 1.2276039434204887e-05,
      "loss": 0.002,
      "step": 27030
    },
    {
      "epoch": 5.795113587655379,
      "grad_norm": 0.12419392913579941,
      "learning_rate": 1.2273181883126162e-05,
      "loss": 0.1714,
      "step": 27040
    },
    {
      "epoch": 5.797256750964424,
      "grad_norm": 9.023164602695033e-05,
      "learning_rate": 1.2270324332047436e-05,
      "loss": 0.002,
      "step": 27050
    },
    {
      "epoch": 5.799399914273468,
      "grad_norm": 0.006704341620206833,
      "learning_rate": 1.226746678096871e-05,
      "loss": 0.3176,
      "step": 27060
    },
    {
      "epoch": 5.801543077582512,
      "grad_norm": 6.83887701597996e-05,
      "learning_rate": 1.2264609229889986e-05,
      "loss": 0.1945,
      "step": 27070
    },
    {
      "epoch": 5.803686240891556,
      "grad_norm": 0.005063219461590052,
      "learning_rate": 1.226175167881126e-05,
      "loss": 0.1746,
      "step": 27080
    },
    {
      "epoch": 5.8058294042006,
      "grad_norm": 4.895130769000389e-05,
      "learning_rate": 1.2258894127732535e-05,
      "loss": 0.0008,
      "step": 27090
    },
    {
      "epoch": 5.807972567509644,
      "grad_norm": 5.429131124401465e-05,
      "learning_rate": 1.225603657665381e-05,
      "loss": 0.0005,
      "step": 27100
    },
    {
      "epoch": 5.810115730818689,
      "grad_norm": 0.0032771830447018147,
      "learning_rate": 1.2253179025575083e-05,
      "loss": 0.0005,
      "step": 27110
    },
    {
      "epoch": 5.812258894127733,
      "grad_norm": 0.005015630275011063,
      "learning_rate": 1.2250321474496359e-05,
      "loss": 0.0002,
      "step": 27120
    },
    {
      "epoch": 5.8144020574367765,
      "grad_norm": 4.896371683571488e-05,
      "learning_rate": 1.2247463923417633e-05,
      "loss": 0.0,
      "step": 27130
    },
    {
      "epoch": 5.816545220745821,
      "grad_norm": 0.008305415511131287,
      "learning_rate": 1.2244606372338907e-05,
      "loss": 0.4277,
      "step": 27140
    },
    {
      "epoch": 5.818688384054865,
      "grad_norm": 0.03356706351041794,
      "learning_rate": 1.2241748821260182e-05,
      "loss": 0.0009,
      "step": 27150
    },
    {
      "epoch": 5.820831547363909,
      "grad_norm": 0.01391118485480547,
      "learning_rate": 1.2238891270181454e-05,
      "loss": 0.0002,
      "step": 27160
    },
    {
      "epoch": 5.822974710672954,
      "grad_norm": 0.008231669664382935,
      "learning_rate": 1.2236033719102728e-05,
      "loss": 0.0001,
      "step": 27170
    },
    {
      "epoch": 5.8251178739819975,
      "grad_norm": 0.0006335154757834971,
      "learning_rate": 1.2233176168024004e-05,
      "loss": 0.0,
      "step": 27180
    },
    {
      "epoch": 5.827261037291041,
      "grad_norm": 0.08745692670345306,
      "learning_rate": 1.2230318616945278e-05,
      "loss": 0.125,
      "step": 27190
    },
    {
      "epoch": 5.829404200600086,
      "grad_norm": 0.0002920127008110285,
      "learning_rate": 1.2227461065866552e-05,
      "loss": 0.0001,
      "step": 27200
    },
    {
      "epoch": 5.83154736390913,
      "grad_norm": 0.0003865945036523044,
      "learning_rate": 1.2224603514787828e-05,
      "loss": 0.1916,
      "step": 27210
    },
    {
      "epoch": 5.833690527218174,
      "grad_norm": 74.75753784179688,
      "learning_rate": 1.2221745963709101e-05,
      "loss": 0.004,
      "step": 27220
    },
    {
      "epoch": 5.835833690527219,
      "grad_norm": 0.00024078394926618785,
      "learning_rate": 1.2218888412630377e-05,
      "loss": 0.0005,
      "step": 27230
    },
    {
      "epoch": 5.837976853836262,
      "grad_norm": 0.005356667097657919,
      "learning_rate": 1.2216030861551651e-05,
      "loss": 0.0004,
      "step": 27240
    },
    {
      "epoch": 5.840120017145306,
      "grad_norm": 0.0004166222643107176,
      "learning_rate": 1.2213173310472925e-05,
      "loss": 0.169,
      "step": 27250
    },
    {
      "epoch": 5.842263180454351,
      "grad_norm": 0.03762872889637947,
      "learning_rate": 1.22103157593942e-05,
      "loss": 0.127,
      "step": 27260
    },
    {
      "epoch": 5.844406343763395,
      "grad_norm": 0.000550414202734828,
      "learning_rate": 1.2207458208315474e-05,
      "loss": 0.0001,
      "step": 27270
    },
    {
      "epoch": 5.846549507072439,
      "grad_norm": 0.0011930809123441577,
      "learning_rate": 1.2204600657236748e-05,
      "loss": 0.0022,
      "step": 27280
    },
    {
      "epoch": 5.848692670381483,
      "grad_norm": 0.00031484387000091374,
      "learning_rate": 1.2201743106158024e-05,
      "loss": 0.1634,
      "step": 27290
    },
    {
      "epoch": 5.850835833690527,
      "grad_norm": 0.05273947864770889,
      "learning_rate": 1.2198885555079298e-05,
      "loss": 0.0001,
      "step": 27300
    },
    {
      "epoch": 5.852978996999571,
      "grad_norm": 0.0003397659456823021,
      "learning_rate": 1.2196028004000574e-05,
      "loss": 0.2843,
      "step": 27310
    },
    {
      "epoch": 5.855122160308616,
      "grad_norm": 24.551109313964844,
      "learning_rate": 1.2193170452921848e-05,
      "loss": 0.5205,
      "step": 27320
    },
    {
      "epoch": 5.85726532361766,
      "grad_norm": 0.04342407360672951,
      "learning_rate": 1.2190312901843121e-05,
      "loss": 0.2632,
      "step": 27330
    },
    {
      "epoch": 5.859408486926704,
      "grad_norm": 0.2362062931060791,
      "learning_rate": 1.2187455350764397e-05,
      "loss": 0.1888,
      "step": 27340
    },
    {
      "epoch": 5.861551650235748,
      "grad_norm": 0.009700823575258255,
      "learning_rate": 1.2184597799685671e-05,
      "loss": 0.0018,
      "step": 27350
    },
    {
      "epoch": 5.863694813544792,
      "grad_norm": 0.20568883419036865,
      "learning_rate": 1.2181740248606947e-05,
      "loss": 0.0007,
      "step": 27360
    },
    {
      "epoch": 5.865837976853836,
      "grad_norm": 0.002920004306361079,
      "learning_rate": 1.217888269752822e-05,
      "loss": 0.0005,
      "step": 27370
    },
    {
      "epoch": 5.867981140162881,
      "grad_norm": 0.00121899857185781,
      "learning_rate": 1.2176025146449493e-05,
      "loss": 0.1631,
      "step": 27380
    },
    {
      "epoch": 5.870124303471925,
      "grad_norm": 0.06626012921333313,
      "learning_rate": 1.2173167595370767e-05,
      "loss": 0.0005,
      "step": 27390
    },
    {
      "epoch": 5.8722674667809684,
      "grad_norm": 0.00443137576803565,
      "learning_rate": 1.2170310044292042e-05,
      "loss": 0.1269,
      "step": 27400
    },
    {
      "epoch": 5.874410630090013,
      "grad_norm": 0.00026002657250501215,
      "learning_rate": 1.2167452493213316e-05,
      "loss": 0.0003,
      "step": 27410
    },
    {
      "epoch": 5.876553793399057,
      "grad_norm": 0.0010262279538437724,
      "learning_rate": 1.216459494213459e-05,
      "loss": 0.0004,
      "step": 27420
    },
    {
      "epoch": 5.878696956708101,
      "grad_norm": 0.00031205988489091396,
      "learning_rate": 1.2161737391055866e-05,
      "loss": 0.0004,
      "step": 27430
    },
    {
      "epoch": 5.880840120017146,
      "grad_norm": 0.0002371400478295982,
      "learning_rate": 1.215887983997714e-05,
      "loss": 0.0536,
      "step": 27440
    },
    {
      "epoch": 5.8829832833261895,
      "grad_norm": 35.4171142578125,
      "learning_rate": 1.2156022288898415e-05,
      "loss": 0.1753,
      "step": 27450
    },
    {
      "epoch": 5.885126446635233,
      "grad_norm": 0.0005402651149779558,
      "learning_rate": 1.215316473781969e-05,
      "loss": 0.3437,
      "step": 27460
    },
    {
      "epoch": 5.887269609944278,
      "grad_norm": 0.03900105506181717,
      "learning_rate": 1.2150307186740963e-05,
      "loss": 0.002,
      "step": 27470
    },
    {
      "epoch": 5.889412773253322,
      "grad_norm": 23.515737533569336,
      "learning_rate": 1.2147449635662239e-05,
      "loss": 0.1056,
      "step": 27480
    },
    {
      "epoch": 5.891555936562366,
      "grad_norm": 0.09424527734518051,
      "learning_rate": 1.2144592084583513e-05,
      "loss": 0.0016,
      "step": 27490
    },
    {
      "epoch": 5.8936990998714105,
      "grad_norm": 0.08018217235803604,
      "learning_rate": 1.2141734533504788e-05,
      "loss": 0.2903,
      "step": 27500
    },
    {
      "epoch": 5.895842263180454,
      "grad_norm": 0.0007630600593984127,
      "learning_rate": 1.2138876982426062e-05,
      "loss": 0.0003,
      "step": 27510
    },
    {
      "epoch": 5.897985426489498,
      "grad_norm": 0.0016641885740682483,
      "learning_rate": 1.2136019431347336e-05,
      "loss": 0.0004,
      "step": 27520
    },
    {
      "epoch": 5.900128589798543,
      "grad_norm": 0.039540860801935196,
      "learning_rate": 1.2133161880268612e-05,
      "loss": 0.0003,
      "step": 27530
    },
    {
      "epoch": 5.902271753107587,
      "grad_norm": 0.0006575487786903977,
      "learning_rate": 1.2130304329189886e-05,
      "loss": 0.0009,
      "step": 27540
    },
    {
      "epoch": 5.904414916416631,
      "grad_norm": 0.0006876213010400534,
      "learning_rate": 1.212744677811116e-05,
      "loss": 0.0,
      "step": 27550
    },
    {
      "epoch": 5.906558079725675,
      "grad_norm": 0.007367369253188372,
      "learning_rate": 1.2124589227032435e-05,
      "loss": 0.0003,
      "step": 27560
    },
    {
      "epoch": 5.908701243034719,
      "grad_norm": 0.01979844830930233,
      "learning_rate": 1.212173167595371e-05,
      "loss": 0.0027,
      "step": 27570
    },
    {
      "epoch": 5.910844406343763,
      "grad_norm": 17.69927978515625,
      "learning_rate": 1.2118874124874985e-05,
      "loss": 0.1978,
      "step": 27580
    },
    {
      "epoch": 5.912987569652808,
      "grad_norm": 0.0003570888948161155,
      "learning_rate": 1.2116016573796257e-05,
      "loss": 0.069,
      "step": 27590
    },
    {
      "epoch": 5.915130732961852,
      "grad_norm": 0.00043604584061540663,
      "learning_rate": 1.2113159022717531e-05,
      "loss": 0.1636,
      "step": 27600
    },
    {
      "epoch": 5.9172738962708955,
      "grad_norm": 0.004516944754868746,
      "learning_rate": 1.2110301471638805e-05,
      "loss": 0.1728,
      "step": 27610
    },
    {
      "epoch": 5.91941705957994,
      "grad_norm": 77.5860595703125,
      "learning_rate": 1.210744392056008e-05,
      "loss": 0.0878,
      "step": 27620
    },
    {
      "epoch": 5.921560222888984,
      "grad_norm": 0.0036242366768419743,
      "learning_rate": 1.2104586369481355e-05,
      "loss": 0.0003,
      "step": 27630
    },
    {
      "epoch": 5.923703386198028,
      "grad_norm": 0.00042839752859435976,
      "learning_rate": 1.210172881840263e-05,
      "loss": 0.0391,
      "step": 27640
    },
    {
      "epoch": 5.925846549507073,
      "grad_norm": 0.00024804583517834544,
      "learning_rate": 1.2098871267323904e-05,
      "loss": 0.0,
      "step": 27650
    },
    {
      "epoch": 5.9279897128161165,
      "grad_norm": 0.00014341302448883653,
      "learning_rate": 1.2096013716245178e-05,
      "loss": 0.0001,
      "step": 27660
    },
    {
      "epoch": 5.93013287612516,
      "grad_norm": 0.026167990639805794,
      "learning_rate": 1.2093156165166454e-05,
      "loss": 0.0482,
      "step": 27670
    },
    {
      "epoch": 5.932276039434205,
      "grad_norm": 0.012912161648273468,
      "learning_rate": 1.2090298614087728e-05,
      "loss": 0.0003,
      "step": 27680
    },
    {
      "epoch": 5.934419202743249,
      "grad_norm": 0.0015726526034995914,
      "learning_rate": 1.2087441063009001e-05,
      "loss": 0.5577,
      "step": 27690
    },
    {
      "epoch": 5.936562366052293,
      "grad_norm": 0.011094490997493267,
      "learning_rate": 1.2084583511930277e-05,
      "loss": 0.0001,
      "step": 27700
    },
    {
      "epoch": 5.9387055293613376,
      "grad_norm": 0.05989512428641319,
      "learning_rate": 1.2081725960851551e-05,
      "loss": 0.0003,
      "step": 27710
    },
    {
      "epoch": 5.940848692670381,
      "grad_norm": 0.031846389174461365,
      "learning_rate": 1.2078868409772827e-05,
      "loss": 0.0002,
      "step": 27720
    },
    {
      "epoch": 5.942991855979425,
      "grad_norm": 0.0023617881815880537,
      "learning_rate": 1.20760108586941e-05,
      "loss": 0.0002,
      "step": 27730
    },
    {
      "epoch": 5.94513501928847,
      "grad_norm": 0.008221945725381374,
      "learning_rate": 1.2073153307615375e-05,
      "loss": 0.0001,
      "step": 27740
    },
    {
      "epoch": 5.947278182597514,
      "grad_norm": 0.002107584150508046,
      "learning_rate": 1.207029575653665e-05,
      "loss": 0.1338,
      "step": 27750
    },
    {
      "epoch": 5.949421345906558,
      "grad_norm": 0.0007895000162534416,
      "learning_rate": 1.2067438205457924e-05,
      "loss": 0.0002,
      "step": 27760
    },
    {
      "epoch": 5.951564509215602,
      "grad_norm": 0.0008771018474362791,
      "learning_rate": 1.2064580654379198e-05,
      "loss": 0.0001,
      "step": 27770
    },
    {
      "epoch": 5.953707672524646,
      "grad_norm": 0.0015036273980513215,
      "learning_rate": 1.2061723103300474e-05,
      "loss": 0.3218,
      "step": 27780
    },
    {
      "epoch": 5.95585083583369,
      "grad_norm": 0.07686087489128113,
      "learning_rate": 1.2058865552221748e-05,
      "loss": 0.0006,
      "step": 27790
    },
    {
      "epoch": 5.957993999142735,
      "grad_norm": 0.015335842967033386,
      "learning_rate": 1.2056008001143023e-05,
      "loss": 0.0009,
      "step": 27800
    },
    {
      "epoch": 5.960137162451779,
      "grad_norm": 0.35522931814193726,
      "learning_rate": 1.2053150450064295e-05,
      "loss": 0.0008,
      "step": 27810
    },
    {
      "epoch": 5.962280325760823,
      "grad_norm": 0.0015984964556992054,
      "learning_rate": 1.205029289898557e-05,
      "loss": 0.0012,
      "step": 27820
    },
    {
      "epoch": 5.964423489069867,
      "grad_norm": 0.006148732732981443,
      "learning_rate": 1.2047435347906843e-05,
      "loss": 0.0001,
      "step": 27830
    },
    {
      "epoch": 5.966566652378911,
      "grad_norm": 0.0007496433681808412,
      "learning_rate": 1.2044577796828119e-05,
      "loss": 0.0,
      "step": 27840
    },
    {
      "epoch": 5.968709815687955,
      "grad_norm": 0.009468155913054943,
      "learning_rate": 1.2041720245749393e-05,
      "loss": 0.0001,
      "step": 27850
    },
    {
      "epoch": 5.970852978997,
      "grad_norm": 0.003094466868788004,
      "learning_rate": 1.2038862694670668e-05,
      "loss": 0.0004,
      "step": 27860
    },
    {
      "epoch": 5.972996142306044,
      "grad_norm": 0.0005435360944829881,
      "learning_rate": 1.2036005143591942e-05,
      "loss": 0.0,
      "step": 27870
    },
    {
      "epoch": 5.975139305615087,
      "grad_norm": 0.001320606330409646,
      "learning_rate": 1.2033147592513216e-05,
      "loss": 0.0069,
      "step": 27880
    },
    {
      "epoch": 5.977282468924132,
      "grad_norm": 0.000989097054116428,
      "learning_rate": 1.2030290041434492e-05,
      "loss": 0.0003,
      "step": 27890
    },
    {
      "epoch": 5.979425632233176,
      "grad_norm": 0.0005767389084212482,
      "learning_rate": 1.2027432490355766e-05,
      "loss": 0.0002,
      "step": 27900
    },
    {
      "epoch": 5.98156879554222,
      "grad_norm": 0.017562249675393105,
      "learning_rate": 1.202457493927704e-05,
      "loss": 0.0,
      "step": 27910
    },
    {
      "epoch": 5.983711958851265,
      "grad_norm": 0.0021566927898675203,
      "learning_rate": 1.2021717388198315e-05,
      "loss": 0.0001,
      "step": 27920
    },
    {
      "epoch": 5.9858551221603085,
      "grad_norm": 0.0005729937693104148,
      "learning_rate": 1.201885983711959e-05,
      "loss": 0.0001,
      "step": 27930
    },
    {
      "epoch": 5.987998285469352,
      "grad_norm": 0.00040679227095097303,
      "learning_rate": 1.2016002286040865e-05,
      "loss": 0.0001,
      "step": 27940
    },
    {
      "epoch": 5.990141448778397,
      "grad_norm": 0.00041778464219532907,
      "learning_rate": 1.2013144734962139e-05,
      "loss": 0.0001,
      "step": 27950
    },
    {
      "epoch": 5.992284612087441,
      "grad_norm": 0.0004972540191374719,
      "learning_rate": 1.2010287183883413e-05,
      "loss": 0.0,
      "step": 27960
    },
    {
      "epoch": 5.994427775396485,
      "grad_norm": 0.00042629262316040695,
      "learning_rate": 1.2007429632804688e-05,
      "loss": 0.0001,
      "step": 27970
    },
    {
      "epoch": 5.9965709387055295,
      "grad_norm": 0.00044151468318887055,
      "learning_rate": 1.2004572081725962e-05,
      "loss": 0.0,
      "step": 27980
    },
    {
      "epoch": 5.998714102014573,
      "grad_norm": 0.008199136704206467,
      "learning_rate": 1.2001714530647236e-05,
      "loss": 0.0,
      "step": 27990
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9836666666666667,
      "eval_f1": 0.9144851657940664,
      "eval_loss": 0.11845459043979645,
      "eval_precision": 0.9597069597069597,
      "eval_recall": 0.8733333333333333,
      "eval_runtime": 395.9368,
      "eval_samples_per_second": 7.577,
      "eval_steps_per_second": 2.526,
      "step": 27996
    },
    {
      "epoch": 6.000857265323618,
      "grad_norm": 0.003949918318539858,
      "learning_rate": 1.1998856979568512e-05,
      "loss": 0.0002,
      "step": 28000
    },
    {
      "epoch": 6.003000428632662,
      "grad_norm": 0.0003763502463698387,
      "learning_rate": 1.1995999428489786e-05,
      "loss": 0.2595,
      "step": 28010
    },
    {
      "epoch": 6.005143591941706,
      "grad_norm": 0.0006484367768280208,
      "learning_rate": 1.1993141877411058e-05,
      "loss": 0.0001,
      "step": 28020
    },
    {
      "epoch": 6.0072867552507505,
      "grad_norm": 0.0002658219018485397,
      "learning_rate": 1.1990284326332334e-05,
      "loss": 0.0002,
      "step": 28030
    },
    {
      "epoch": 6.009429918559794,
      "grad_norm": 0.0003491208190098405,
      "learning_rate": 1.1987426775253608e-05,
      "loss": 0.0001,
      "step": 28040
    },
    {
      "epoch": 6.011573081868838,
      "grad_norm": 0.0002913464268203825,
      "learning_rate": 1.1984569224174882e-05,
      "loss": 0.0001,
      "step": 28050
    },
    {
      "epoch": 6.013716245177883,
      "grad_norm": 0.0003071237006224692,
      "learning_rate": 1.1981711673096157e-05,
      "loss": 0.1505,
      "step": 28060
    },
    {
      "epoch": 6.015859408486927,
      "grad_norm": 0.0002525285817682743,
      "learning_rate": 1.1978854122017431e-05,
      "loss": 0.0001,
      "step": 28070
    },
    {
      "epoch": 6.018002571795971,
      "grad_norm": 0.0023890116717666388,
      "learning_rate": 1.1975996570938707e-05,
      "loss": 0.0002,
      "step": 28080
    },
    {
      "epoch": 6.020145735105015,
      "grad_norm": 0.0002745110250543803,
      "learning_rate": 1.197313901985998e-05,
      "loss": 0.0001,
      "step": 28090
    },
    {
      "epoch": 6.022288898414059,
      "grad_norm": 0.17466644942760468,
      "learning_rate": 1.1970281468781255e-05,
      "loss": 0.2737,
      "step": 28100
    },
    {
      "epoch": 6.024432061723103,
      "grad_norm": 0.6049882173538208,
      "learning_rate": 1.196742391770253e-05,
      "loss": 0.0007,
      "step": 28110
    },
    {
      "epoch": 6.026575225032148,
      "grad_norm": 0.23514433205127716,
      "learning_rate": 1.1964566366623804e-05,
      "loss": 0.0002,
      "step": 28120
    },
    {
      "epoch": 6.028718388341192,
      "grad_norm": 0.0258741807192564,
      "learning_rate": 1.1961708815545078e-05,
      "loss": 0.0001,
      "step": 28130
    },
    {
      "epoch": 6.0308615516502355,
      "grad_norm": 23.640159606933594,
      "learning_rate": 1.1958851264466354e-05,
      "loss": 0.2201,
      "step": 28140
    },
    {
      "epoch": 6.03300471495928,
      "grad_norm": 0.0013486876850947738,
      "learning_rate": 1.1955993713387628e-05,
      "loss": 0.3338,
      "step": 28150
    },
    {
      "epoch": 6.035147878268324,
      "grad_norm": 0.010851130820810795,
      "learning_rate": 1.1953136162308903e-05,
      "loss": 0.1339,
      "step": 28160
    },
    {
      "epoch": 6.037291041577368,
      "grad_norm": 0.0029458303470164537,
      "learning_rate": 1.1950278611230177e-05,
      "loss": 0.0011,
      "step": 28170
    },
    {
      "epoch": 6.039434204886413,
      "grad_norm": 0.2814241647720337,
      "learning_rate": 1.1947421060151451e-05,
      "loss": 0.0021,
      "step": 28180
    },
    {
      "epoch": 6.0415773681954565,
      "grad_norm": 0.0006612376892007887,
      "learning_rate": 1.1944563509072727e-05,
      "loss": 0.2955,
      "step": 28190
    },
    {
      "epoch": 6.0437205315045,
      "grad_norm": 0.0002749639970716089,
      "learning_rate": 1.1941705957994e-05,
      "loss": 0.0001,
      "step": 28200
    },
    {
      "epoch": 6.045863694813545,
      "grad_norm": 0.00025515156448818743,
      "learning_rate": 1.1938848406915276e-05,
      "loss": 0.0004,
      "step": 28210
    },
    {
      "epoch": 6.048006858122589,
      "grad_norm": 0.0016476245364174247,
      "learning_rate": 1.193599085583655e-05,
      "loss": 0.1047,
      "step": 28220
    },
    {
      "epoch": 6.050150021431633,
      "grad_norm": 0.001377974054776132,
      "learning_rate": 1.1933133304757824e-05,
      "loss": 0.2027,
      "step": 28230
    },
    {
      "epoch": 6.052293184740678,
      "grad_norm": 0.0037409327924251556,
      "learning_rate": 1.1930275753679096e-05,
      "loss": 0.0,
      "step": 28240
    },
    {
      "epoch": 6.054436348049721,
      "grad_norm": 0.00021113456750754267,
      "learning_rate": 1.1927418202600372e-05,
      "loss": 0.0022,
      "step": 28250
    },
    {
      "epoch": 6.056579511358765,
      "grad_norm": 0.00020912406034767628,
      "learning_rate": 1.1924560651521646e-05,
      "loss": 0.0002,
      "step": 28260
    },
    {
      "epoch": 6.05872267466781,
      "grad_norm": 0.00040801282739266753,
      "learning_rate": 1.192170310044292e-05,
      "loss": 0.0001,
      "step": 28270
    },
    {
      "epoch": 6.060865837976854,
      "grad_norm": 0.0002414109476376325,
      "learning_rate": 1.1918845549364195e-05,
      "loss": 0.0,
      "step": 28280
    },
    {
      "epoch": 6.063009001285898,
      "grad_norm": 0.0023419191129505634,
      "learning_rate": 1.191598799828547e-05,
      "loss": 0.0001,
      "step": 28290
    },
    {
      "epoch": 6.065152164594942,
      "grad_norm": 0.0001405814109602943,
      "learning_rate": 1.1913130447206745e-05,
      "loss": 0.0001,
      "step": 28300
    },
    {
      "epoch": 6.067295327903986,
      "grad_norm": 0.0022694747895002365,
      "learning_rate": 1.1910272896128019e-05,
      "loss": 0.0418,
      "step": 28310
    },
    {
      "epoch": 6.06943849121303,
      "grad_norm": 0.0001146656577475369,
      "learning_rate": 1.1907415345049293e-05,
      "loss": 0.0008,
      "step": 28320
    },
    {
      "epoch": 6.071581654522075,
      "grad_norm": 0.0002646565844770521,
      "learning_rate": 1.1904557793970568e-05,
      "loss": 0.2825,
      "step": 28330
    },
    {
      "epoch": 6.073724817831119,
      "grad_norm": 0.0006545193027704954,
      "learning_rate": 1.1901700242891842e-05,
      "loss": 0.0,
      "step": 28340
    },
    {
      "epoch": 6.075867981140163,
      "grad_norm": 0.018555626273155212,
      "learning_rate": 1.1898842691813118e-05,
      "loss": 0.0001,
      "step": 28350
    },
    {
      "epoch": 6.078011144449207,
      "grad_norm": 0.0014765976229682565,
      "learning_rate": 1.1895985140734392e-05,
      "loss": 0.0003,
      "step": 28360
    },
    {
      "epoch": 6.080154307758251,
      "grad_norm": 0.0017064345302060246,
      "learning_rate": 1.1893127589655666e-05,
      "loss": 0.0003,
      "step": 28370
    },
    {
      "epoch": 6.082297471067295,
      "grad_norm": 0.00035905317054130137,
      "learning_rate": 1.1890270038576942e-05,
      "loss": 0.0,
      "step": 28380
    },
    {
      "epoch": 6.08444063437634,
      "grad_norm": 0.00041585240978747606,
      "learning_rate": 1.1887412487498215e-05,
      "loss": 0.0001,
      "step": 28390
    },
    {
      "epoch": 6.086583797685384,
      "grad_norm": 0.0012898778077214956,
      "learning_rate": 1.188455493641949e-05,
      "loss": 0.0,
      "step": 28400
    },
    {
      "epoch": 6.0887269609944275,
      "grad_norm": 0.0006788797909393907,
      "learning_rate": 1.1881697385340765e-05,
      "loss": 0.3245,
      "step": 28410
    },
    {
      "epoch": 6.090870124303472,
      "grad_norm": 0.000907337584067136,
      "learning_rate": 1.1878839834262039e-05,
      "loss": 0.0001,
      "step": 28420
    },
    {
      "epoch": 6.093013287612516,
      "grad_norm": 0.0011201086454093456,
      "learning_rate": 1.1875982283183315e-05,
      "loss": 0.0002,
      "step": 28430
    },
    {
      "epoch": 6.09515645092156,
      "grad_norm": 0.0003080789465457201,
      "learning_rate": 1.1873124732104588e-05,
      "loss": 0.0001,
      "step": 28440
    },
    {
      "epoch": 6.097299614230605,
      "grad_norm": 0.002765977755188942,
      "learning_rate": 1.187026718102586e-05,
      "loss": 0.0,
      "step": 28450
    },
    {
      "epoch": 6.0994427775396485,
      "grad_norm": 0.0013755280524492264,
      "learning_rate": 1.1867409629947135e-05,
      "loss": 0.0,
      "step": 28460
    },
    {
      "epoch": 6.101585940848692,
      "grad_norm": 0.00592639297246933,
      "learning_rate": 1.186455207886841e-05,
      "loss": 0.0,
      "step": 28470
    },
    {
      "epoch": 6.103729104157737,
      "grad_norm": 0.00017942077829502523,
      "learning_rate": 1.1861694527789684e-05,
      "loss": 0.0,
      "step": 28480
    },
    {
      "epoch": 6.105872267466781,
      "grad_norm": 0.001205487409606576,
      "learning_rate": 1.185883697671096e-05,
      "loss": 0.0,
      "step": 28490
    },
    {
      "epoch": 6.108015430775825,
      "grad_norm": 0.014452706091105938,
      "learning_rate": 1.1855979425632234e-05,
      "loss": 0.0001,
      "step": 28500
    },
    {
      "epoch": 6.1101585940848695,
      "grad_norm": 0.0008830074220895767,
      "learning_rate": 1.1853121874553508e-05,
      "loss": 0.2819,
      "step": 28510
    },
    {
      "epoch": 6.112301757393913,
      "grad_norm": 0.0006038762512616813,
      "learning_rate": 1.1850264323474783e-05,
      "loss": 0.1763,
      "step": 28520
    },
    {
      "epoch": 6.114444920702957,
      "grad_norm": 0.0011790082789957523,
      "learning_rate": 1.1847406772396057e-05,
      "loss": 0.0,
      "step": 28530
    },
    {
      "epoch": 6.116588084012002,
      "grad_norm": 0.0012018661946058273,
      "learning_rate": 1.1844549221317331e-05,
      "loss": 0.0001,
      "step": 28540
    },
    {
      "epoch": 6.118731247321046,
      "grad_norm": 0.0056729381904006,
      "learning_rate": 1.1841691670238607e-05,
      "loss": 0.01,
      "step": 28550
    },
    {
      "epoch": 6.12087441063009,
      "grad_norm": 0.021894801408052444,
      "learning_rate": 1.183883411915988e-05,
      "loss": 0.0001,
      "step": 28560
    },
    {
      "epoch": 6.123017573939134,
      "grad_norm": 0.0007253737421706319,
      "learning_rate": 1.1835976568081156e-05,
      "loss": 0.0261,
      "step": 28570
    },
    {
      "epoch": 6.125160737248178,
      "grad_norm": 0.0006950696115382016,
      "learning_rate": 1.183311901700243e-05,
      "loss": 0.0001,
      "step": 28580
    },
    {
      "epoch": 6.127303900557222,
      "grad_norm": 0.006123607978224754,
      "learning_rate": 1.1830261465923704e-05,
      "loss": 0.0002,
      "step": 28590
    },
    {
      "epoch": 6.129447063866267,
      "grad_norm": 0.0019548952113837004,
      "learning_rate": 1.182740391484498e-05,
      "loss": 0.0,
      "step": 28600
    },
    {
      "epoch": 6.131590227175311,
      "grad_norm": 0.0006563239148817956,
      "learning_rate": 1.1824546363766254e-05,
      "loss": 0.0026,
      "step": 28610
    },
    {
      "epoch": 6.1337333904843545,
      "grad_norm": 0.0011997070396319032,
      "learning_rate": 1.1821688812687528e-05,
      "loss": 0.0001,
      "step": 28620
    },
    {
      "epoch": 6.135876553793399,
      "grad_norm": 0.0007609249441884458,
      "learning_rate": 1.1818831261608803e-05,
      "loss": 0.0,
      "step": 28630
    },
    {
      "epoch": 6.138019717102443,
      "grad_norm": 0.00042277530883438885,
      "learning_rate": 1.1815973710530077e-05,
      "loss": 0.0001,
      "step": 28640
    },
    {
      "epoch": 6.140162880411487,
      "grad_norm": 0.007902863435447216,
      "learning_rate": 1.1813116159451353e-05,
      "loss": 0.2573,
      "step": 28650
    },
    {
      "epoch": 6.142306043720532,
      "grad_norm": 0.008939406834542751,
      "learning_rate": 1.1810258608372627e-05,
      "loss": 0.0002,
      "step": 28660
    },
    {
      "epoch": 6.1444492070295755,
      "grad_norm": 0.0017257753061130643,
      "learning_rate": 1.1807401057293899e-05,
      "loss": 0.0003,
      "step": 28670
    },
    {
      "epoch": 6.146592370338619,
      "grad_norm": 0.0032046851702034473,
      "learning_rate": 1.1804543506215173e-05,
      "loss": 0.0001,
      "step": 28680
    },
    {
      "epoch": 6.148735533647664,
      "grad_norm": 0.0011083113495260477,
      "learning_rate": 1.1801685955136449e-05,
      "loss": 0.2162,
      "step": 28690
    },
    {
      "epoch": 6.150878696956708,
      "grad_norm": 0.001700310385785997,
      "learning_rate": 1.1798828404057722e-05,
      "loss": 0.0522,
      "step": 28700
    },
    {
      "epoch": 6.153021860265753,
      "grad_norm": 0.04962911456823349,
      "learning_rate": 1.1795970852978998e-05,
      "loss": 0.0003,
      "step": 28710
    },
    {
      "epoch": 6.155165023574797,
      "grad_norm": 0.00146822864189744,
      "learning_rate": 1.1793113301900272e-05,
      "loss": 0.1912,
      "step": 28720
    },
    {
      "epoch": 6.15730818688384,
      "grad_norm": 0.0008093087817542255,
      "learning_rate": 1.1790255750821546e-05,
      "loss": 0.0002,
      "step": 28730
    },
    {
      "epoch": 6.159451350192885,
      "grad_norm": 0.0013281040592119098,
      "learning_rate": 1.1787398199742822e-05,
      "loss": 0.0002,
      "step": 28740
    },
    {
      "epoch": 6.161594513501929,
      "grad_norm": 0.001738572376780212,
      "learning_rate": 1.1784540648664095e-05,
      "loss": 0.0,
      "step": 28750
    },
    {
      "epoch": 6.163737676810973,
      "grad_norm": 0.44211241602897644,
      "learning_rate": 1.178168309758537e-05,
      "loss": 0.0019,
      "step": 28760
    },
    {
      "epoch": 6.165880840120018,
      "grad_norm": 0.08363766968250275,
      "learning_rate": 1.1778825546506645e-05,
      "loss": 0.0003,
      "step": 28770
    },
    {
      "epoch": 6.168024003429061,
      "grad_norm": 0.02770131453871727,
      "learning_rate": 1.1775967995427919e-05,
      "loss": 0.0001,
      "step": 28780
    },
    {
      "epoch": 6.170167166738105,
      "grad_norm": 0.00039256797754205763,
      "learning_rate": 1.1773110444349195e-05,
      "loss": 0.0001,
      "step": 28790
    },
    {
      "epoch": 6.17231033004715,
      "grad_norm": 0.03172251954674721,
      "learning_rate": 1.1770252893270469e-05,
      "loss": 0.0001,
      "step": 28800
    },
    {
      "epoch": 6.174453493356194,
      "grad_norm": 0.0006056997808627784,
      "learning_rate": 1.1767395342191742e-05,
      "loss": 0.2146,
      "step": 28810
    },
    {
      "epoch": 6.176596656665238,
      "grad_norm": 0.0009210528223775327,
      "learning_rate": 1.1764537791113018e-05,
      "loss": 0.2024,
      "step": 28820
    },
    {
      "epoch": 6.1787398199742825,
      "grad_norm": 112.88999938964844,
      "learning_rate": 1.1761680240034292e-05,
      "loss": 0.2082,
      "step": 28830
    },
    {
      "epoch": 6.180882983283326,
      "grad_norm": 0.0007031394634395838,
      "learning_rate": 1.1758822688955568e-05,
      "loss": 0.0002,
      "step": 28840
    },
    {
      "epoch": 6.18302614659237,
      "grad_norm": 0.00813224259763956,
      "learning_rate": 1.1755965137876842e-05,
      "loss": 0.5131,
      "step": 28850
    },
    {
      "epoch": 6.185169309901415,
      "grad_norm": 0.015990545973181725,
      "learning_rate": 1.1753107586798115e-05,
      "loss": 0.0008,
      "step": 28860
    },
    {
      "epoch": 6.187312473210459,
      "grad_norm": 0.012684506364166737,
      "learning_rate": 1.1750250035719391e-05,
      "loss": 0.0023,
      "step": 28870
    },
    {
      "epoch": 6.189455636519503,
      "grad_norm": 0.012877589091658592,
      "learning_rate": 1.1747392484640663e-05,
      "loss": 0.0668,
      "step": 28880
    },
    {
      "epoch": 6.191598799828547,
      "grad_norm": 0.004779175389558077,
      "learning_rate": 1.1744534933561937e-05,
      "loss": 0.0002,
      "step": 28890
    },
    {
      "epoch": 6.193741963137591,
      "grad_norm": 0.05470500513911247,
      "learning_rate": 1.1741677382483211e-05,
      "loss": 0.0002,
      "step": 28900
    },
    {
      "epoch": 6.195885126446635,
      "grad_norm": 0.0020552726928144693,
      "learning_rate": 1.1738819831404487e-05,
      "loss": 0.0,
      "step": 28910
    },
    {
      "epoch": 6.19802828975568,
      "grad_norm": 0.0027908808551728725,
      "learning_rate": 1.173596228032576e-05,
      "loss": 0.0004,
      "step": 28920
    },
    {
      "epoch": 6.200171453064724,
      "grad_norm": 0.0010633671190589666,
      "learning_rate": 1.1733104729247036e-05,
      "loss": 0.0002,
      "step": 28930
    },
    {
      "epoch": 6.2023146163737675,
      "grad_norm": 0.0007521903025917709,
      "learning_rate": 1.173024717816831e-05,
      "loss": 0.0,
      "step": 28940
    },
    {
      "epoch": 6.204457779682812,
      "grad_norm": 0.0008747299434617162,
      "learning_rate": 1.1727389627089584e-05,
      "loss": 0.0002,
      "step": 28950
    },
    {
      "epoch": 6.206600942991856,
      "grad_norm": 0.0010458143660798669,
      "learning_rate": 1.172453207601086e-05,
      "loss": 0.0003,
      "step": 28960
    },
    {
      "epoch": 6.2087441063009,
      "grad_norm": 0.0013762741582468152,
      "learning_rate": 1.1721674524932134e-05,
      "loss": 0.333,
      "step": 28970
    },
    {
      "epoch": 6.210887269609945,
      "grad_norm": 0.004081603605300188,
      "learning_rate": 1.171881697385341e-05,
      "loss": 0.0001,
      "step": 28980
    },
    {
      "epoch": 6.2130304329189885,
      "grad_norm": 0.0017635701224207878,
      "learning_rate": 1.1715959422774683e-05,
      "loss": 0.0001,
      "step": 28990
    },
    {
      "epoch": 6.215173596228032,
      "grad_norm": 0.003276426112279296,
      "learning_rate": 1.1713101871695957e-05,
      "loss": 0.0001,
      "step": 29000
    },
    {
      "epoch": 6.217316759537077,
      "grad_norm": 0.0010801319731399417,
      "learning_rate": 1.1710244320617233e-05,
      "loss": 0.0001,
      "step": 29010
    },
    {
      "epoch": 6.219459922846121,
      "grad_norm": 0.003913207910954952,
      "learning_rate": 1.1707386769538507e-05,
      "loss": 0.0002,
      "step": 29020
    },
    {
      "epoch": 6.221603086155165,
      "grad_norm": 0.0006748893647454679,
      "learning_rate": 1.170452921845978e-05,
      "loss": 0.0002,
      "step": 29030
    },
    {
      "epoch": 6.2237462494642095,
      "grad_norm": 0.0040721530094742775,
      "learning_rate": 1.1701671667381056e-05,
      "loss": 0.0,
      "step": 29040
    },
    {
      "epoch": 6.225889412773253,
      "grad_norm": 0.7543780207633972,
      "learning_rate": 1.169881411630233e-05,
      "loss": 0.002,
      "step": 29050
    },
    {
      "epoch": 6.228032576082297,
      "grad_norm": 0.001854823320172727,
      "learning_rate": 1.1695956565223606e-05,
      "loss": 0.1504,
      "step": 29060
    },
    {
      "epoch": 6.230175739391342,
      "grad_norm": 0.000651669455692172,
      "learning_rate": 1.169309901414488e-05,
      "loss": 0.0002,
      "step": 29070
    },
    {
      "epoch": 6.232318902700386,
      "grad_norm": 0.0029168131295591593,
      "learning_rate": 1.1690241463066154e-05,
      "loss": 0.6515,
      "step": 29080
    },
    {
      "epoch": 6.23446206600943,
      "grad_norm": 0.00218155886977911,
      "learning_rate": 1.168738391198743e-05,
      "loss": 0.0004,
      "step": 29090
    },
    {
      "epoch": 6.236605229318474,
      "grad_norm": 0.0024816528894007206,
      "learning_rate": 1.1684526360908702e-05,
      "loss": 0.2696,
      "step": 29100
    },
    {
      "epoch": 6.238748392627518,
      "grad_norm": 0.09477238357067108,
      "learning_rate": 1.1681668809829976e-05,
      "loss": 0.001,
      "step": 29110
    },
    {
      "epoch": 6.240891555936562,
      "grad_norm": 0.0005175740807317197,
      "learning_rate": 1.1678811258751251e-05,
      "loss": 0.0009,
      "step": 29120
    },
    {
      "epoch": 6.243034719245607,
      "grad_norm": 0.00026491208700463176,
      "learning_rate": 1.1675953707672525e-05,
      "loss": 0.0005,
      "step": 29130
    },
    {
      "epoch": 6.245177882554651,
      "grad_norm": 0.0012937030987814069,
      "learning_rate": 1.1673096156593799e-05,
      "loss": 0.1685,
      "step": 29140
    },
    {
      "epoch": 6.2473210458636945,
      "grad_norm": 0.00047199398977681994,
      "learning_rate": 1.1670238605515075e-05,
      "loss": 0.0,
      "step": 29150
    },
    {
      "epoch": 6.249464209172739,
      "grad_norm": 0.11025922745466232,
      "learning_rate": 1.1667381054436349e-05,
      "loss": 0.0003,
      "step": 29160
    },
    {
      "epoch": 6.251607372481783,
      "grad_norm": 0.00933121144771576,
      "learning_rate": 1.1664523503357623e-05,
      "loss": 0.0728,
      "step": 29170
    },
    {
      "epoch": 6.253750535790827,
      "grad_norm": 0.044970542192459106,
      "learning_rate": 1.1661665952278898e-05,
      "loss": 0.0002,
      "step": 29180
    },
    {
      "epoch": 6.255893699099872,
      "grad_norm": 0.0004993312177248299,
      "learning_rate": 1.1658808401200172e-05,
      "loss": 0.126,
      "step": 29190
    },
    {
      "epoch": 6.2580368624089155,
      "grad_norm": 0.0005276204901747406,
      "learning_rate": 1.1655950850121448e-05,
      "loss": 0.0003,
      "step": 29200
    },
    {
      "epoch": 6.260180025717959,
      "grad_norm": 0.0017998178955167532,
      "learning_rate": 1.1653093299042722e-05,
      "loss": 0.0014,
      "step": 29210
    },
    {
      "epoch": 6.262323189027004,
      "grad_norm": 0.027448441833257675,
      "learning_rate": 1.1650235747963996e-05,
      "loss": 0.0004,
      "step": 29220
    },
    {
      "epoch": 6.264466352336048,
      "grad_norm": 0.0002620344457682222,
      "learning_rate": 1.1647378196885271e-05,
      "loss": 0.0001,
      "step": 29230
    },
    {
      "epoch": 6.266609515645092,
      "grad_norm": 0.0001884473895188421,
      "learning_rate": 1.1644520645806545e-05,
      "loss": 0.0001,
      "step": 29240
    },
    {
      "epoch": 6.268752678954137,
      "grad_norm": 0.09196764975786209,
      "learning_rate": 1.1641663094727819e-05,
      "loss": 0.0004,
      "step": 29250
    },
    {
      "epoch": 6.27089584226318,
      "grad_norm": 0.003541353391483426,
      "learning_rate": 1.1638805543649095e-05,
      "loss": 0.16,
      "step": 29260
    },
    {
      "epoch": 6.273039005572224,
      "grad_norm": 0.001575874979607761,
      "learning_rate": 1.1635947992570369e-05,
      "loss": 0.0002,
      "step": 29270
    },
    {
      "epoch": 6.275182168881269,
      "grad_norm": 0.00014038407243788242,
      "learning_rate": 1.1633090441491644e-05,
      "loss": 0.0003,
      "step": 29280
    },
    {
      "epoch": 6.277325332190313,
      "grad_norm": 0.00021619773178827018,
      "learning_rate": 1.1630232890412918e-05,
      "loss": 0.0,
      "step": 29290
    },
    {
      "epoch": 6.279468495499357,
      "grad_norm": 0.0002030605828622356,
      "learning_rate": 1.1627375339334192e-05,
      "loss": 0.0002,
      "step": 29300
    },
    {
      "epoch": 6.281611658808401,
      "grad_norm": 0.054600708186626434,
      "learning_rate": 1.1624517788255464e-05,
      "loss": 0.0001,
      "step": 29310
    },
    {
      "epoch": 6.283754822117445,
      "grad_norm": 0.00016115172184072435,
      "learning_rate": 1.162166023717674e-05,
      "loss": 0.0,
      "step": 29320
    },
    {
      "epoch": 6.285897985426489,
      "grad_norm": 0.00021555488638114184,
      "learning_rate": 1.1618802686098014e-05,
      "loss": 0.0003,
      "step": 29330
    },
    {
      "epoch": 6.288041148735534,
      "grad_norm": 0.00552012212574482,
      "learning_rate": 1.161594513501929e-05,
      "loss": 0.0001,
      "step": 29340
    },
    {
      "epoch": 6.290184312044578,
      "grad_norm": 0.00032936868956312537,
      "learning_rate": 1.1613087583940563e-05,
      "loss": 0.0,
      "step": 29350
    },
    {
      "epoch": 6.292327475353622,
      "grad_norm": 8.851332677295431e-05,
      "learning_rate": 1.1610230032861837e-05,
      "loss": 0.0003,
      "step": 29360
    },
    {
      "epoch": 6.294470638662666,
      "grad_norm": 0.0001343465701211244,
      "learning_rate": 1.1607372481783113e-05,
      "loss": 0.0,
      "step": 29370
    },
    {
      "epoch": 6.29661380197171,
      "grad_norm": 9.876646799966693e-05,
      "learning_rate": 1.1604514930704387e-05,
      "loss": 0.0003,
      "step": 29380
    },
    {
      "epoch": 6.298756965280754,
      "grad_norm": 0.00016368219803553075,
      "learning_rate": 1.160165737962566e-05,
      "loss": 0.0,
      "step": 29390
    },
    {
      "epoch": 6.300900128589799,
      "grad_norm": 0.003696403931826353,
      "learning_rate": 1.1598799828546936e-05,
      "loss": 0.0002,
      "step": 29400
    },
    {
      "epoch": 6.303043291898843,
      "grad_norm": 28.432952880859375,
      "learning_rate": 1.159594227746821e-05,
      "loss": 0.138,
      "step": 29410
    },
    {
      "epoch": 6.3051864552078865,
      "grad_norm": 0.00011736701708287,
      "learning_rate": 1.1593084726389486e-05,
      "loss": 0.0003,
      "step": 29420
    },
    {
      "epoch": 6.307329618516931,
      "grad_norm": 0.07981237769126892,
      "learning_rate": 1.159022717531076e-05,
      "loss": 0.0001,
      "step": 29430
    },
    {
      "epoch": 6.309472781825975,
      "grad_norm": 0.00010153061884921044,
      "learning_rate": 1.1587369624232034e-05,
      "loss": 0.0026,
      "step": 29440
    },
    {
      "epoch": 6.311615945135019,
      "grad_norm": 0.006025678478181362,
      "learning_rate": 1.158451207315331e-05,
      "loss": 0.0162,
      "step": 29450
    },
    {
      "epoch": 6.313759108444064,
      "grad_norm": 6.44875253783539e-05,
      "learning_rate": 1.1581654522074583e-05,
      "loss": 0.0844,
      "step": 29460
    },
    {
      "epoch": 6.3159022717531075,
      "grad_norm": 9.025036706589162e-05,
      "learning_rate": 1.1578796970995857e-05,
      "loss": 0.0001,
      "step": 29470
    },
    {
      "epoch": 6.318045435062151,
      "grad_norm": 5.546077954932116e-05,
      "learning_rate": 1.1575939419917133e-05,
      "loss": 0.0,
      "step": 29480
    },
    {
      "epoch": 6.320188598371196,
      "grad_norm": 5.613650500890799e-05,
      "learning_rate": 1.1573081868838407e-05,
      "loss": 0.0,
      "step": 29490
    },
    {
      "epoch": 6.32233176168024,
      "grad_norm": 6.309406307991594e-05,
      "learning_rate": 1.1570224317759682e-05,
      "loss": 0.0,
      "step": 29500
    },
    {
      "epoch": 6.324474924989284,
      "grad_norm": 0.0001229749759659171,
      "learning_rate": 1.1567366766680956e-05,
      "loss": 0.311,
      "step": 29510
    },
    {
      "epoch": 6.3266180882983285,
      "grad_norm": 0.006294785533100367,
      "learning_rate": 1.156450921560223e-05,
      "loss": 0.0004,
      "step": 29520
    },
    {
      "epoch": 6.328761251607372,
      "grad_norm": 0.0002576170372776687,
      "learning_rate": 1.1561651664523503e-05,
      "loss": 0.2183,
      "step": 29530
    },
    {
      "epoch": 6.330904414916416,
      "grad_norm": 0.0011723135830834508,
      "learning_rate": 1.1558794113444778e-05,
      "loss": 0.0008,
      "step": 29540
    },
    {
      "epoch": 6.333047578225461,
      "grad_norm": 0.001562917372211814,
      "learning_rate": 1.1555936562366052e-05,
      "loss": 0.0002,
      "step": 29550
    },
    {
      "epoch": 6.335190741534505,
      "grad_norm": 0.0036956151016056538,
      "learning_rate": 1.1553079011287328e-05,
      "loss": 0.0006,
      "step": 29560
    },
    {
      "epoch": 6.337333904843549,
      "grad_norm": 0.004068460315465927,
      "learning_rate": 1.1550221460208602e-05,
      "loss": 0.0633,
      "step": 29570
    },
    {
      "epoch": 6.339477068152593,
      "grad_norm": 0.005532304756343365,
      "learning_rate": 1.1547363909129876e-05,
      "loss": 0.0001,
      "step": 29580
    },
    {
      "epoch": 6.341620231461637,
      "grad_norm": 36.49164581298828,
      "learning_rate": 1.1544506358051151e-05,
      "loss": 0.3643,
      "step": 29590
    },
    {
      "epoch": 6.343763394770681,
      "grad_norm": 2.3500397205352783,
      "learning_rate": 1.1541648806972425e-05,
      "loss": 0.0017,
      "step": 29600
    },
    {
      "epoch": 6.345906558079726,
      "grad_norm": 0.030212346464395523,
      "learning_rate": 1.1538791255893699e-05,
      "loss": 0.15,
      "step": 29610
    },
    {
      "epoch": 6.34804972138877,
      "grad_norm": 0.005515409633517265,
      "learning_rate": 1.1535933704814975e-05,
      "loss": 0.0012,
      "step": 29620
    },
    {
      "epoch": 6.3501928846978135,
      "grad_norm": 0.0015487952623516321,
      "learning_rate": 1.1533076153736249e-05,
      "loss": 0.0002,
      "step": 29630
    },
    {
      "epoch": 6.352336048006858,
      "grad_norm": 0.0009446995100006461,
      "learning_rate": 1.1530218602657524e-05,
      "loss": 0.0,
      "step": 29640
    },
    {
      "epoch": 6.354479211315902,
      "grad_norm": 0.046830616891384125,
      "learning_rate": 1.1527361051578798e-05,
      "loss": 0.1376,
      "step": 29650
    },
    {
      "epoch": 6.356622374624947,
      "grad_norm": 0.0009460854926146567,
      "learning_rate": 1.1524503500500072e-05,
      "loss": 0.0005,
      "step": 29660
    },
    {
      "epoch": 6.358765537933991,
      "grad_norm": 0.00025580418878234923,
      "learning_rate": 1.1521645949421348e-05,
      "loss": 0.0,
      "step": 29670
    },
    {
      "epoch": 6.3609087012430345,
      "grad_norm": 0.0011683988850563765,
      "learning_rate": 1.1518788398342622e-05,
      "loss": 0.015,
      "step": 29680
    },
    {
      "epoch": 6.363051864552079,
      "grad_norm": 0.03663541004061699,
      "learning_rate": 1.1515930847263897e-05,
      "loss": 0.0001,
      "step": 29690
    },
    {
      "epoch": 6.365195027861123,
      "grad_norm": 0.01701699011027813,
      "learning_rate": 1.1513073296185171e-05,
      "loss": 0.0001,
      "step": 29700
    },
    {
      "epoch": 6.367338191170167,
      "grad_norm": 0.09695528447628021,
      "learning_rate": 1.1510215745106445e-05,
      "loss": 0.2946,
      "step": 29710
    },
    {
      "epoch": 6.369481354479212,
      "grad_norm": 0.0006123573402874172,
      "learning_rate": 1.150735819402772e-05,
      "loss": 0.0001,
      "step": 29720
    },
    {
      "epoch": 6.371624517788256,
      "grad_norm": 0.0002595557598397136,
      "learning_rate": 1.1504500642948995e-05,
      "loss": 0.0003,
      "step": 29730
    },
    {
      "epoch": 6.373767681097299,
      "grad_norm": 0.005958929657936096,
      "learning_rate": 1.1501643091870267e-05,
      "loss": 0.0003,
      "step": 29740
    },
    {
      "epoch": 6.375910844406344,
      "grad_norm": 0.0003373197978362441,
      "learning_rate": 1.149878554079154e-05,
      "loss": 0.0002,
      "step": 29750
    },
    {
      "epoch": 6.378054007715388,
      "grad_norm": 21.3067626953125,
      "learning_rate": 1.1495927989712816e-05,
      "loss": 0.1563,
      "step": 29760
    },
    {
      "epoch": 6.380197171024432,
      "grad_norm": 0.011417992413043976,
      "learning_rate": 1.149307043863409e-05,
      "loss": 0.0,
      "step": 29770
    },
    {
      "epoch": 6.382340334333477,
      "grad_norm": 0.00044297671411186457,
      "learning_rate": 1.1490212887555366e-05,
      "loss": 0.0,
      "step": 29780
    },
    {
      "epoch": 6.38448349764252,
      "grad_norm": 0.0006084384513087571,
      "learning_rate": 1.148735533647664e-05,
      "loss": 0.0006,
      "step": 29790
    },
    {
      "epoch": 6.386626660951564,
      "grad_norm": 0.0001354704872937873,
      "learning_rate": 1.1484497785397914e-05,
      "loss": 0.0009,
      "step": 29800
    },
    {
      "epoch": 6.388769824260609,
      "grad_norm": 0.00014792493311688304,
      "learning_rate": 1.148164023431919e-05,
      "loss": 0.0003,
      "step": 29810
    },
    {
      "epoch": 6.390912987569653,
      "grad_norm": 0.00023917130602058023,
      "learning_rate": 1.1478782683240463e-05,
      "loss": 0.0,
      "step": 29820
    },
    {
      "epoch": 6.393056150878697,
      "grad_norm": 0.00013149526785127819,
      "learning_rate": 1.1475925132161739e-05,
      "loss": 0.0001,
      "step": 29830
    },
    {
      "epoch": 6.3951993141877415,
      "grad_norm": 9.608995605958626e-05,
      "learning_rate": 1.1473067581083013e-05,
      "loss": 0.0,
      "step": 29840
    },
    {
      "epoch": 6.397342477496785,
      "grad_norm": 0.00039970551733858883,
      "learning_rate": 1.1470210030004287e-05,
      "loss": 0.0,
      "step": 29850
    },
    {
      "epoch": 6.399485640805829,
      "grad_norm": 0.003760901978239417,
      "learning_rate": 1.1467352478925563e-05,
      "loss": 0.0002,
      "step": 29860
    },
    {
      "epoch": 6.401628804114874,
      "grad_norm": 8.807154517853633e-05,
      "learning_rate": 1.1464494927846836e-05,
      "loss": 0.0001,
      "step": 29870
    },
    {
      "epoch": 6.403771967423918,
      "grad_norm": 9.058193973032758e-05,
      "learning_rate": 1.146163737676811e-05,
      "loss": 0.0005,
      "step": 29880
    },
    {
      "epoch": 6.405915130732962,
      "grad_norm": 0.0005620801821351051,
      "learning_rate": 1.1458779825689386e-05,
      "loss": 0.0,
      "step": 29890
    },
    {
      "epoch": 6.408058294042006,
      "grad_norm": 0.388862282037735,
      "learning_rate": 1.145592227461066e-05,
      "loss": 0.0005,
      "step": 29900
    },
    {
      "epoch": 6.41020145735105,
      "grad_norm": 0.0033306856639683247,
      "learning_rate": 1.1453064723531936e-05,
      "loss": 0.1791,
      "step": 29910
    },
    {
      "epoch": 6.412344620660094,
      "grad_norm": 0.011485634371638298,
      "learning_rate": 1.145020717245321e-05,
      "loss": 0.3163,
      "step": 29920
    },
    {
      "epoch": 6.414487783969139,
      "grad_norm": 0.0037358056288212538,
      "learning_rate": 1.1447349621374483e-05,
      "loss": 0.0323,
      "step": 29930
    },
    {
      "epoch": 6.416630947278183,
      "grad_norm": 0.005560305435210466,
      "learning_rate": 1.1444492070295759e-05,
      "loss": 0.4714,
      "step": 29940
    },
    {
      "epoch": 6.4187741105872265,
      "grad_norm": 0.008563360199332237,
      "learning_rate": 1.1441634519217031e-05,
      "loss": 0.0008,
      "step": 29950
    },
    {
      "epoch": 6.420917273896271,
      "grad_norm": 0.0011238845763728023,
      "learning_rate": 1.1438776968138305e-05,
      "loss": 0.0001,
      "step": 29960
    },
    {
      "epoch": 6.423060437205315,
      "grad_norm": 0.002547874115407467,
      "learning_rate": 1.143591941705958e-05,
      "loss": 0.0008,
      "step": 29970
    },
    {
      "epoch": 6.425203600514359,
      "grad_norm": 0.0008369273273274302,
      "learning_rate": 1.1433061865980855e-05,
      "loss": 0.3406,
      "step": 29980
    },
    {
      "epoch": 6.427346763823404,
      "grad_norm": 0.6513670086860657,
      "learning_rate": 1.1430204314902129e-05,
      "loss": 0.0062,
      "step": 29990
    },
    {
      "epoch": 6.4294899271324475,
      "grad_norm": 0.05889449268579483,
      "learning_rate": 1.1427346763823404e-05,
      "loss": 0.0002,
      "step": 30000
    },
    {
      "epoch": 6.431633090441491,
      "grad_norm": 0.07716868817806244,
      "learning_rate": 1.1424489212744678e-05,
      "loss": 0.0003,
      "step": 30010
    },
    {
      "epoch": 6.433776253750536,
      "grad_norm": 0.04377748444676399,
      "learning_rate": 1.1421631661665952e-05,
      "loss": 0.0003,
      "step": 30020
    },
    {
      "epoch": 6.43591941705958,
      "grad_norm": 0.00038043875247240067,
      "learning_rate": 1.1418774110587228e-05,
      "loss": 0.0,
      "step": 30030
    },
    {
      "epoch": 6.438062580368624,
      "grad_norm": 48.32855987548828,
      "learning_rate": 1.1415916559508502e-05,
      "loss": 0.2841,
      "step": 30040
    },
    {
      "epoch": 6.4402057436776685,
      "grad_norm": 0.0009918500436469913,
      "learning_rate": 1.1413059008429777e-05,
      "loss": 0.2829,
      "step": 30050
    },
    {
      "epoch": 6.442348906986712,
      "grad_norm": 0.00810729805380106,
      "learning_rate": 1.1410201457351051e-05,
      "loss": 0.1245,
      "step": 30060
    },
    {
      "epoch": 6.444492070295756,
      "grad_norm": 0.12133218348026276,
      "learning_rate": 1.1407343906272325e-05,
      "loss": 0.0009,
      "step": 30070
    },
    {
      "epoch": 6.446635233604801,
      "grad_norm": 0.016449930146336555,
      "learning_rate": 1.14044863551936e-05,
      "loss": 0.0014,
      "step": 30080
    },
    {
      "epoch": 6.448778396913845,
      "grad_norm": 0.0018178890459239483,
      "learning_rate": 1.1401628804114875e-05,
      "loss": 0.0004,
      "step": 30090
    },
    {
      "epoch": 6.450921560222889,
      "grad_norm": 0.002043097745627165,
      "learning_rate": 1.1398771253036149e-05,
      "loss": 0.0007,
      "step": 30100
    },
    {
      "epoch": 6.453064723531933,
      "grad_norm": 0.0012900306610390544,
      "learning_rate": 1.1395913701957424e-05,
      "loss": 0.0001,
      "step": 30110
    },
    {
      "epoch": 6.455207886840977,
      "grad_norm": 0.0031634364277124405,
      "learning_rate": 1.1393056150878698e-05,
      "loss": 0.0001,
      "step": 30120
    },
    {
      "epoch": 6.457351050150021,
      "grad_norm": 0.01270655170083046,
      "learning_rate": 1.1390198599799974e-05,
      "loss": 0.0001,
      "step": 30130
    },
    {
      "epoch": 6.459494213459066,
      "grad_norm": 18.371248245239258,
      "learning_rate": 1.1387341048721248e-05,
      "loss": 0.2087,
      "step": 30140
    },
    {
      "epoch": 6.46163737676811,
      "grad_norm": 0.0009182559442706406,
      "learning_rate": 1.1384483497642522e-05,
      "loss": 0.0001,
      "step": 30150
    },
    {
      "epoch": 6.4637805400771535,
      "grad_norm": 0.02309453673660755,
      "learning_rate": 1.1381625946563797e-05,
      "loss": 0.1637,
      "step": 30160
    },
    {
      "epoch": 6.465923703386198,
      "grad_norm": 0.007321368902921677,
      "learning_rate": 1.137876839548507e-05,
      "loss": 0.0007,
      "step": 30170
    },
    {
      "epoch": 6.468066866695242,
      "grad_norm": 0.0020261455792933702,
      "learning_rate": 1.1375910844406343e-05,
      "loss": 0.0009,
      "step": 30180
    },
    {
      "epoch": 6.470210030004286,
      "grad_norm": 0.0076439641416072845,
      "learning_rate": 1.1373053293327619e-05,
      "loss": 0.0003,
      "step": 30190
    },
    {
      "epoch": 6.472353193313331,
      "grad_norm": 0.0013585687847808003,
      "learning_rate": 1.1370195742248893e-05,
      "loss": 0.0003,
      "step": 30200
    },
    {
      "epoch": 6.4744963566223745,
      "grad_norm": 0.0016018095193430781,
      "learning_rate": 1.1367338191170167e-05,
      "loss": 0.0002,
      "step": 30210
    },
    {
      "epoch": 6.476639519931418,
      "grad_norm": 0.0538642555475235,
      "learning_rate": 1.1364480640091443e-05,
      "loss": 0.0006,
      "step": 30220
    },
    {
      "epoch": 6.478782683240463,
      "grad_norm": 0.05844610556960106,
      "learning_rate": 1.1361623089012716e-05,
      "loss": 0.0002,
      "step": 30230
    },
    {
      "epoch": 6.480925846549507,
      "grad_norm": 0.06336783617734909,
      "learning_rate": 1.135876553793399e-05,
      "loss": 0.0002,
      "step": 30240
    },
    {
      "epoch": 6.483069009858551,
      "grad_norm": 0.0006953810225240886,
      "learning_rate": 1.1355907986855266e-05,
      "loss": 0.0,
      "step": 30250
    },
    {
      "epoch": 6.485212173167596,
      "grad_norm": 0.0001289815700147301,
      "learning_rate": 1.135305043577654e-05,
      "loss": 0.0001,
      "step": 30260
    },
    {
      "epoch": 6.487355336476639,
      "grad_norm": 0.0009699109941720963,
      "learning_rate": 1.1350192884697816e-05,
      "loss": 0.196,
      "step": 30270
    },
    {
      "epoch": 6.489498499785683,
      "grad_norm": 0.0006741765537299216,
      "learning_rate": 1.134733533361909e-05,
      "loss": 0.0269,
      "step": 30280
    },
    {
      "epoch": 6.491641663094728,
      "grad_norm": 0.0029075220227241516,
      "learning_rate": 1.1344477782540363e-05,
      "loss": 0.0,
      "step": 30290
    },
    {
      "epoch": 6.493784826403772,
      "grad_norm": 0.0037787866313010454,
      "learning_rate": 1.1341620231461639e-05,
      "loss": 0.0003,
      "step": 30300
    },
    {
      "epoch": 6.495927989712816,
      "grad_norm": 0.00032502596150152385,
      "learning_rate": 1.1338762680382913e-05,
      "loss": 0.2261,
      "step": 30310
    },
    {
      "epoch": 6.4980711530218604,
      "grad_norm": 0.0019304591696709394,
      "learning_rate": 1.1335905129304187e-05,
      "loss": 0.0003,
      "step": 30320
    },
    {
      "epoch": 6.500214316330904,
      "grad_norm": 0.00040956115117296576,
      "learning_rate": 1.1333047578225463e-05,
      "loss": 0.0001,
      "step": 30330
    },
    {
      "epoch": 6.502357479639949,
      "grad_norm": 0.07176456600427628,
      "learning_rate": 1.1330190027146736e-05,
      "loss": 0.0006,
      "step": 30340
    },
    {
      "epoch": 6.504500642948993,
      "grad_norm": 0.056800659745931625,
      "learning_rate": 1.1327332476068012e-05,
      "loss": 0.0005,
      "step": 30350
    },
    {
      "epoch": 6.506643806258037,
      "grad_norm": 0.009484903886914253,
      "learning_rate": 1.1324474924989286e-05,
      "loss": 0.1993,
      "step": 30360
    },
    {
      "epoch": 6.5087869695670815,
      "grad_norm": 0.05425272136926651,
      "learning_rate": 1.132161737391056e-05,
      "loss": 0.0002,
      "step": 30370
    },
    {
      "epoch": 6.510930132876125,
      "grad_norm": 0.002353974850848317,
      "learning_rate": 1.1318759822831832e-05,
      "loss": 0.0002,
      "step": 30380
    },
    {
      "epoch": 6.513073296185169,
      "grad_norm": 0.0009470591321587563,
      "learning_rate": 1.1315902271753108e-05,
      "loss": 0.0003,
      "step": 30390
    },
    {
      "epoch": 6.515216459494214,
      "grad_norm": 0.00020984529692213982,
      "learning_rate": 1.1313044720674382e-05,
      "loss": 0.0001,
      "step": 30400
    },
    {
      "epoch": 6.517359622803258,
      "grad_norm": 0.007256223354488611,
      "learning_rate": 1.1310187169595657e-05,
      "loss": 0.0001,
      "step": 30410
    },
    {
      "epoch": 6.519502786112302,
      "grad_norm": 0.00470553757622838,
      "learning_rate": 1.1307329618516931e-05,
      "loss": 0.0002,
      "step": 30420
    },
    {
      "epoch": 6.521645949421346,
      "grad_norm": 253.6458282470703,
      "learning_rate": 1.1304472067438205e-05,
      "loss": 0.0715,
      "step": 30430
    },
    {
      "epoch": 6.52378911273039,
      "grad_norm": 0.00015089121006894857,
      "learning_rate": 1.1301614516359481e-05,
      "loss": 0.0005,
      "step": 30440
    },
    {
      "epoch": 6.525932276039434,
      "grad_norm": 0.07395744323730469,
      "learning_rate": 1.1298756965280755e-05,
      "loss": 0.1927,
      "step": 30450
    },
    {
      "epoch": 6.528075439348479,
      "grad_norm": 0.07940556854009628,
      "learning_rate": 1.1295899414202029e-05,
      "loss": 0.1953,
      "step": 30460
    },
    {
      "epoch": 6.530218602657523,
      "grad_norm": 0.26632216572761536,
      "learning_rate": 1.1293041863123304e-05,
      "loss": 0.0276,
      "step": 30470
    },
    {
      "epoch": 6.5323617659665665,
      "grad_norm": 0.012225241400301456,
      "learning_rate": 1.1290184312044578e-05,
      "loss": 0.0003,
      "step": 30480
    },
    {
      "epoch": 6.534504929275611,
      "grad_norm": 0.0010529852006584406,
      "learning_rate": 1.1287326760965854e-05,
      "loss": 0.1656,
      "step": 30490
    },
    {
      "epoch": 6.536648092584655,
      "grad_norm": 0.0003440671425778419,
      "learning_rate": 1.1284469209887128e-05,
      "loss": 0.0004,
      "step": 30500
    },
    {
      "epoch": 6.538791255893699,
      "grad_norm": 0.07639710605144501,
      "learning_rate": 1.1281611658808402e-05,
      "loss": 0.0003,
      "step": 30510
    },
    {
      "epoch": 6.540934419202744,
      "grad_norm": 0.0009796905796974897,
      "learning_rate": 1.1278754107729677e-05,
      "loss": 0.0609,
      "step": 30520
    },
    {
      "epoch": 6.5430775825117875,
      "grad_norm": 0.00011506683222251013,
      "learning_rate": 1.1275896556650951e-05,
      "loss": 0.2513,
      "step": 30530
    },
    {
      "epoch": 6.545220745820831,
      "grad_norm": 8.463632548227906e-05,
      "learning_rate": 1.1273039005572227e-05,
      "loss": 0.0001,
      "step": 30540
    },
    {
      "epoch": 6.547363909129876,
      "grad_norm": 2.830357551574707,
      "learning_rate": 1.12701814544935e-05,
      "loss": 0.0026,
      "step": 30550
    },
    {
      "epoch": 6.54950707243892,
      "grad_norm": 0.048728182911872864,
      "learning_rate": 1.1267323903414775e-05,
      "loss": 0.0004,
      "step": 30560
    },
    {
      "epoch": 6.551650235747964,
      "grad_norm": 0.07505538314580917,
      "learning_rate": 1.126446635233605e-05,
      "loss": 0.0002,
      "step": 30570
    },
    {
      "epoch": 6.5537933990570085,
      "grad_norm": 0.0029989033937454224,
      "learning_rate": 1.1261608801257324e-05,
      "loss": 0.1333,
      "step": 30580
    },
    {
      "epoch": 6.555936562366052,
      "grad_norm": 0.00010697149991756305,
      "learning_rate": 1.1258751250178598e-05,
      "loss": 0.1486,
      "step": 30590
    },
    {
      "epoch": 6.558079725675096,
      "grad_norm": 0.02698199450969696,
      "learning_rate": 1.125589369909987e-05,
      "loss": 0.0003,
      "step": 30600
    },
    {
      "epoch": 6.560222888984141,
      "grad_norm": 7.729558274149895e-05,
      "learning_rate": 1.1253036148021146e-05,
      "loss": 0.0001,
      "step": 30610
    },
    {
      "epoch": 6.562366052293185,
      "grad_norm": 9.901059092953801e-05,
      "learning_rate": 1.125017859694242e-05,
      "loss": 0.0,
      "step": 30620
    },
    {
      "epoch": 6.564509215602229,
      "grad_norm": 0.021503988653421402,
      "learning_rate": 1.1247321045863696e-05,
      "loss": 0.0001,
      "step": 30630
    },
    {
      "epoch": 6.566652378911273,
      "grad_norm": 0.0009676055051386356,
      "learning_rate": 1.124446349478497e-05,
      "loss": 0.0001,
      "step": 30640
    },
    {
      "epoch": 6.568795542220317,
      "grad_norm": 9.398209658684209e-05,
      "learning_rate": 1.1241605943706244e-05,
      "loss": 0.0002,
      "step": 30650
    },
    {
      "epoch": 6.570938705529361,
      "grad_norm": 0.0007357622380368412,
      "learning_rate": 1.1238748392627519e-05,
      "loss": 0.0001,
      "step": 30660
    },
    {
      "epoch": 6.573081868838406,
      "grad_norm": 0.00010143366671400145,
      "learning_rate": 1.1235890841548793e-05,
      "loss": 0.0002,
      "step": 30670
    },
    {
      "epoch": 6.57522503214745,
      "grad_norm": 0.0005193052347749472,
      "learning_rate": 1.1233033290470069e-05,
      "loss": 0.1247,
      "step": 30680
    },
    {
      "epoch": 6.5773681954564935,
      "grad_norm": 0.00018502293096389621,
      "learning_rate": 1.1230175739391343e-05,
      "loss": 0.4072,
      "step": 30690
    },
    {
      "epoch": 6.579511358765538,
      "grad_norm": 0.006432633846998215,
      "learning_rate": 1.1227318188312617e-05,
      "loss": 0.0003,
      "step": 30700
    },
    {
      "epoch": 6.581654522074582,
      "grad_norm": 0.00014244507474359125,
      "learning_rate": 1.1224460637233892e-05,
      "loss": 0.0,
      "step": 30710
    },
    {
      "epoch": 6.583797685383626,
      "grad_norm": 0.0003289614978712052,
      "learning_rate": 1.1221603086155166e-05,
      "loss": 0.1106,
      "step": 30720
    },
    {
      "epoch": 6.585940848692671,
      "grad_norm": 0.0001619206159375608,
      "learning_rate": 1.121874553507644e-05,
      "loss": 0.1136,
      "step": 30730
    },
    {
      "epoch": 6.588084012001715,
      "grad_norm": 0.00015924240869935602,
      "learning_rate": 1.1215887983997716e-05,
      "loss": 0.0026,
      "step": 30740
    },
    {
      "epoch": 6.590227175310758,
      "grad_norm": 0.0004562122921925038,
      "learning_rate": 1.121303043291899e-05,
      "loss": 0.0,
      "step": 30750
    },
    {
      "epoch": 6.592370338619803,
      "grad_norm": 0.0003614072338677943,
      "learning_rate": 1.1210172881840265e-05,
      "loss": 0.0001,
      "step": 30760
    },
    {
      "epoch": 6.594513501928847,
      "grad_norm": 0.00889623537659645,
      "learning_rate": 1.1207315330761539e-05,
      "loss": 0.0001,
      "step": 30770
    },
    {
      "epoch": 6.596656665237891,
      "grad_norm": 0.04954845458269119,
      "learning_rate": 1.1204457779682813e-05,
      "loss": 0.1227,
      "step": 30780
    },
    {
      "epoch": 6.598799828546936,
      "grad_norm": 0.12275591492652893,
      "learning_rate": 1.1201600228604089e-05,
      "loss": 0.0003,
      "step": 30790
    },
    {
      "epoch": 6.600942991855979,
      "grad_norm": 0.6908414363861084,
      "learning_rate": 1.1198742677525363e-05,
      "loss": 0.0729,
      "step": 30800
    },
    {
      "epoch": 6.603086155165023,
      "grad_norm": 0.00013484155351761729,
      "learning_rate": 1.1195885126446635e-05,
      "loss": 0.2112,
      "step": 30810
    },
    {
      "epoch": 6.605229318474068,
      "grad_norm": 7.620811084052548e-05,
      "learning_rate": 1.119302757536791e-05,
      "loss": 0.2256,
      "step": 30820
    },
    {
      "epoch": 6.607372481783112,
      "grad_norm": 0.00017270422540605068,
      "learning_rate": 1.1190170024289184e-05,
      "loss": 0.0006,
      "step": 30830
    },
    {
      "epoch": 6.609515645092156,
      "grad_norm": 0.0003216374898329377,
      "learning_rate": 1.1187312473210458e-05,
      "loss": 0.0001,
      "step": 30840
    },
    {
      "epoch": 6.6116588084012005,
      "grad_norm": 0.00020588113693520427,
      "learning_rate": 1.1184454922131734e-05,
      "loss": 0.0005,
      "step": 30850
    },
    {
      "epoch": 6.613801971710244,
      "grad_norm": 0.02790846861898899,
      "learning_rate": 1.1181597371053008e-05,
      "loss": 0.0001,
      "step": 30860
    },
    {
      "epoch": 6.615945135019288,
      "grad_norm": 0.05311931297183037,
      "learning_rate": 1.1178739819974282e-05,
      "loss": 0.0002,
      "step": 30870
    },
    {
      "epoch": 6.618088298328333,
      "grad_norm": 0.0020939859095960855,
      "learning_rate": 1.1175882268895557e-05,
      "loss": 0.0003,
      "step": 30880
    },
    {
      "epoch": 6.620231461637377,
      "grad_norm": 0.015259950421750546,
      "learning_rate": 1.1173024717816831e-05,
      "loss": 0.0001,
      "step": 30890
    },
    {
      "epoch": 6.622374624946421,
      "grad_norm": 26.63428497314453,
      "learning_rate": 1.1170167166738107e-05,
      "loss": 0.2917,
      "step": 30900
    },
    {
      "epoch": 6.624517788255465,
      "grad_norm": 9.48468514252454e-05,
      "learning_rate": 1.1167309615659381e-05,
      "loss": 0.0,
      "step": 30910
    },
    {
      "epoch": 6.626660951564509,
      "grad_norm": 16.542987823486328,
      "learning_rate": 1.1164452064580655e-05,
      "loss": 0.1211,
      "step": 30920
    },
    {
      "epoch": 6.628804114873553,
      "grad_norm": 25.484188079833984,
      "learning_rate": 1.116159451350193e-05,
      "loss": 0.3947,
      "step": 30930
    },
    {
      "epoch": 6.630947278182598,
      "grad_norm": 0.15327005088329315,
      "learning_rate": 1.1158736962423204e-05,
      "loss": 0.0007,
      "step": 30940
    },
    {
      "epoch": 6.633090441491642,
      "grad_norm": 0.0035711161326617002,
      "learning_rate": 1.1155879411344478e-05,
      "loss": 0.0014,
      "step": 30950
    },
    {
      "epoch": 6.6352336048006855,
      "grad_norm": 0.04709507152438164,
      "learning_rate": 1.1153021860265754e-05,
      "loss": 0.0013,
      "step": 30960
    },
    {
      "epoch": 6.63737676810973,
      "grad_norm": 0.006100865546613932,
      "learning_rate": 1.1150164309187028e-05,
      "loss": 0.0002,
      "step": 30970
    },
    {
      "epoch": 6.639519931418774,
      "grad_norm": 0.0023384359665215015,
      "learning_rate": 1.1147306758108303e-05,
      "loss": 0.0001,
      "step": 30980
    },
    {
      "epoch": 6.641663094727818,
      "grad_norm": 0.007725693751126528,
      "learning_rate": 1.1144449207029577e-05,
      "loss": 0.0002,
      "step": 30990
    },
    {
      "epoch": 6.643806258036863,
      "grad_norm": 0.004446518141776323,
      "learning_rate": 1.1141591655950851e-05,
      "loss": 0.0001,
      "step": 31000
    },
    {
      "epoch": 6.6459494213459065,
      "grad_norm": 0.003488068003207445,
      "learning_rate": 1.1138734104872127e-05,
      "loss": 0.0,
      "step": 31010
    },
    {
      "epoch": 6.64809258465495,
      "grad_norm": 0.0005632048123516142,
      "learning_rate": 1.1135876553793401e-05,
      "loss": 0.0001,
      "step": 31020
    },
    {
      "epoch": 6.650235747963995,
      "grad_norm": 0.0006353235221467912,
      "learning_rate": 1.1133019002714673e-05,
      "loss": 0.0031,
      "step": 31030
    },
    {
      "epoch": 6.652378911273039,
      "grad_norm": 0.0012851809151470661,
      "learning_rate": 1.1130161451635949e-05,
      "loss": 0.0001,
      "step": 31040
    },
    {
      "epoch": 6.654522074582083,
      "grad_norm": 0.0008417140343226492,
      "learning_rate": 1.1127303900557223e-05,
      "loss": 0.0003,
      "step": 31050
    },
    {
      "epoch": 6.6566652378911275,
      "grad_norm": 0.005386087112128735,
      "learning_rate": 1.1124446349478497e-05,
      "loss": 0.3422,
      "step": 31060
    },
    {
      "epoch": 6.658808401200171,
      "grad_norm": 0.06765127182006836,
      "learning_rate": 1.1121588798399772e-05,
      "loss": 0.289,
      "step": 31070
    },
    {
      "epoch": 6.660951564509215,
      "grad_norm": 0.013365007005631924,
      "learning_rate": 1.1118731247321046e-05,
      "loss": 0.0002,
      "step": 31080
    },
    {
      "epoch": 6.66309472781826,
      "grad_norm": 0.004732824396342039,
      "learning_rate": 1.111587369624232e-05,
      "loss": 0.0027,
      "step": 31090
    },
    {
      "epoch": 6.665237891127304,
      "grad_norm": 0.1623513102531433,
      "learning_rate": 1.1113016145163596e-05,
      "loss": 0.0021,
      "step": 31100
    },
    {
      "epoch": 6.667381054436348,
      "grad_norm": 0.0021150647662580013,
      "learning_rate": 1.111015859408487e-05,
      "loss": 0.1625,
      "step": 31110
    },
    {
      "epoch": 6.669524217745392,
      "grad_norm": 0.014814729802310467,
      "learning_rate": 1.1107301043006145e-05,
      "loss": 0.1764,
      "step": 31120
    },
    {
      "epoch": 6.671667381054436,
      "grad_norm": 0.001309509389102459,
      "learning_rate": 1.110444349192742e-05,
      "loss": 0.0001,
      "step": 31130
    },
    {
      "epoch": 6.67381054436348,
      "grad_norm": 0.0004853073915001005,
      "learning_rate": 1.1101585940848693e-05,
      "loss": 0.0003,
      "step": 31140
    },
    {
      "epoch": 6.675953707672525,
      "grad_norm": 0.001329813851043582,
      "learning_rate": 1.1098728389769969e-05,
      "loss": 0.0001,
      "step": 31150
    },
    {
      "epoch": 6.678096870981569,
      "grad_norm": 0.0007862903876230121,
      "learning_rate": 1.1095870838691243e-05,
      "loss": 0.2708,
      "step": 31160
    },
    {
      "epoch": 6.6802400342906125,
      "grad_norm": 0.000730843108613044,
      "learning_rate": 1.1093013287612517e-05,
      "loss": 0.0001,
      "step": 31170
    },
    {
      "epoch": 6.682383197599657,
      "grad_norm": 0.0011435869382694364,
      "learning_rate": 1.1090155736533792e-05,
      "loss": 0.0028,
      "step": 31180
    },
    {
      "epoch": 6.684526360908701,
      "grad_norm": 0.005292824469506741,
      "learning_rate": 1.1087298185455066e-05,
      "loss": 0.0011,
      "step": 31190
    },
    {
      "epoch": 6.686669524217745,
      "grad_norm": 0.00019201131362933666,
      "learning_rate": 1.1084440634376342e-05,
      "loss": 0.0001,
      "step": 31200
    },
    {
      "epoch": 6.68881268752679,
      "grad_norm": 0.000221707668970339,
      "learning_rate": 1.1081583083297616e-05,
      "loss": 0.0,
      "step": 31210
    },
    {
      "epoch": 6.6909558508358336,
      "grad_norm": 0.00022172124590724707,
      "learning_rate": 1.107872553221889e-05,
      "loss": 0.1121,
      "step": 31220
    },
    {
      "epoch": 6.693099014144877,
      "grad_norm": 0.0013306201435625553,
      "learning_rate": 1.1075867981140165e-05,
      "loss": 1.156,
      "step": 31230
    },
    {
      "epoch": 6.695242177453922,
      "grad_norm": 0.03690192848443985,
      "learning_rate": 1.1073010430061437e-05,
      "loss": 0.2724,
      "step": 31240
    },
    {
      "epoch": 6.697385340762966,
      "grad_norm": 23.143983840942383,
      "learning_rate": 1.1070152878982711e-05,
      "loss": 0.4221,
      "step": 31250
    },
    {
      "epoch": 6.69952850407201,
      "grad_norm": 0.03144432231783867,
      "learning_rate": 1.1067295327903987e-05,
      "loss": 0.3831,
      "step": 31260
    },
    {
      "epoch": 6.701671667381055,
      "grad_norm": 0.01924119144678116,
      "learning_rate": 1.1064437776825261e-05,
      "loss": 0.0009,
      "step": 31270
    },
    {
      "epoch": 6.703814830690098,
      "grad_norm": 0.015669358894228935,
      "learning_rate": 1.1061580225746535e-05,
      "loss": 0.0007,
      "step": 31280
    },
    {
      "epoch": 6.705957993999142,
      "grad_norm": 0.01585078239440918,
      "learning_rate": 1.105872267466781e-05,
      "loss": 0.0006,
      "step": 31290
    },
    {
      "epoch": 6.708101157308187,
      "grad_norm": 0.007197256665676832,
      "learning_rate": 1.1055865123589084e-05,
      "loss": 0.0007,
      "step": 31300
    },
    {
      "epoch": 6.710244320617231,
      "grad_norm": 0.026325788348913193,
      "learning_rate": 1.1053007572510358e-05,
      "loss": 0.0553,
      "step": 31310
    },
    {
      "epoch": 6.712387483926275,
      "grad_norm": 0.03927810862660408,
      "learning_rate": 1.1050150021431634e-05,
      "loss": 0.0006,
      "step": 31320
    },
    {
      "epoch": 6.7145306472353194,
      "grad_norm": 0.003499569371342659,
      "learning_rate": 1.1047292470352908e-05,
      "loss": 0.0003,
      "step": 31330
    },
    {
      "epoch": 6.716673810544363,
      "grad_norm": 0.0032877286430448294,
      "learning_rate": 1.1044434919274184e-05,
      "loss": 0.0005,
      "step": 31340
    },
    {
      "epoch": 6.718816973853407,
      "grad_norm": 0.0037992012221366167,
      "learning_rate": 1.1041577368195457e-05,
      "loss": 0.0001,
      "step": 31350
    },
    {
      "epoch": 6.720960137162452,
      "grad_norm": 0.016671372577548027,
      "learning_rate": 1.1038719817116731e-05,
      "loss": 0.0001,
      "step": 31360
    },
    {
      "epoch": 6.723103300471496,
      "grad_norm": 0.003092114580795169,
      "learning_rate": 1.1035862266038007e-05,
      "loss": 0.2315,
      "step": 31370
    },
    {
      "epoch": 6.72524646378054,
      "grad_norm": 0.018806999549269676,
      "learning_rate": 1.1033004714959281e-05,
      "loss": 0.2408,
      "step": 31380
    },
    {
      "epoch": 6.727389627089584,
      "grad_norm": 0.00875872652977705,
      "learning_rate": 1.1030147163880557e-05,
      "loss": 0.0013,
      "step": 31390
    },
    {
      "epoch": 6.729532790398628,
      "grad_norm": 0.004800446797162294,
      "learning_rate": 1.102728961280183e-05,
      "loss": 0.0045,
      "step": 31400
    },
    {
      "epoch": 6.731675953707673,
      "grad_norm": 0.013981525786221027,
      "learning_rate": 1.1024432061723104e-05,
      "loss": 0.0894,
      "step": 31410
    },
    {
      "epoch": 6.733819117016717,
      "grad_norm": 0.01674322411417961,
      "learning_rate": 1.102157451064438e-05,
      "loss": 0.0004,
      "step": 31420
    },
    {
      "epoch": 6.735962280325761,
      "grad_norm": 0.010643180459737778,
      "learning_rate": 1.1018716959565654e-05,
      "loss": 0.0007,
      "step": 31430
    },
    {
      "epoch": 6.738105443634805,
      "grad_norm": 0.0034987996332347393,
      "learning_rate": 1.1015859408486928e-05,
      "loss": 0.1248,
      "step": 31440
    },
    {
      "epoch": 6.740248606943849,
      "grad_norm": 0.004960331134498119,
      "learning_rate": 1.1013001857408204e-05,
      "loss": 0.0027,
      "step": 31450
    },
    {
      "epoch": 6.742391770252893,
      "grad_norm": 0.004873916041105986,
      "learning_rate": 1.1010144306329476e-05,
      "loss": 0.0001,
      "step": 31460
    },
    {
      "epoch": 6.744534933561938,
      "grad_norm": 0.0035696632694453,
      "learning_rate": 1.100728675525075e-05,
      "loss": 0.0001,
      "step": 31470
    },
    {
      "epoch": 6.746678096870982,
      "grad_norm": 0.004784690216183662,
      "learning_rate": 1.1004429204172025e-05,
      "loss": 0.0008,
      "step": 31480
    },
    {
      "epoch": 6.7488212601800255,
      "grad_norm": 0.003301153192296624,
      "learning_rate": 1.10015716530933e-05,
      "loss": 0.0951,
      "step": 31490
    },
    {
      "epoch": 6.75096442348907,
      "grad_norm": 0.0038381631020456553,
      "learning_rate": 1.0998714102014573e-05,
      "loss": 0.0001,
      "step": 31500
    },
    {
      "epoch": 6.753107586798114,
      "grad_norm": 0.002038088859990239,
      "learning_rate": 1.0995856550935849e-05,
      "loss": 0.0007,
      "step": 31510
    },
    {
      "epoch": 6.755250750107158,
      "grad_norm": 0.0018812076887115836,
      "learning_rate": 1.0992998999857123e-05,
      "loss": 0.0,
      "step": 31520
    },
    {
      "epoch": 6.757393913416203,
      "grad_norm": 0.003367431228980422,
      "learning_rate": 1.0990141448778398e-05,
      "loss": 0.0001,
      "step": 31530
    },
    {
      "epoch": 6.7595370767252465,
      "grad_norm": 16.40725326538086,
      "learning_rate": 1.0987283897699672e-05,
      "loss": 0.0902,
      "step": 31540
    },
    {
      "epoch": 6.76168024003429,
      "grad_norm": 0.0017438555369153619,
      "learning_rate": 1.0984426346620946e-05,
      "loss": 0.0,
      "step": 31550
    },
    {
      "epoch": 6.763823403343335,
      "grad_norm": 0.0020641041919589043,
      "learning_rate": 1.0981568795542222e-05,
      "loss": 0.0819,
      "step": 31560
    },
    {
      "epoch": 6.765966566652379,
      "grad_norm": 0.0015707286074757576,
      "learning_rate": 1.0978711244463496e-05,
      "loss": 0.007,
      "step": 31570
    },
    {
      "epoch": 6.768109729961423,
      "grad_norm": 0.002010724972933531,
      "learning_rate": 1.097585369338477e-05,
      "loss": 0.1021,
      "step": 31580
    },
    {
      "epoch": 6.7702528932704675,
      "grad_norm": 0.0023889250587671995,
      "learning_rate": 1.0972996142306045e-05,
      "loss": 0.0,
      "step": 31590
    },
    {
      "epoch": 6.772396056579511,
      "grad_norm": 21.96122932434082,
      "learning_rate": 1.097013859122732e-05,
      "loss": 0.3116,
      "step": 31600
    },
    {
      "epoch": 6.774539219888555,
      "grad_norm": 0.004324170295149088,
      "learning_rate": 1.0967281040148595e-05,
      "loss": 0.0001,
      "step": 31610
    },
    {
      "epoch": 6.7766823831976,
      "grad_norm": 0.0023928433656692505,
      "learning_rate": 1.0964423489069869e-05,
      "loss": 0.0001,
      "step": 31620
    },
    {
      "epoch": 6.778825546506644,
      "grad_norm": 0.0031342515721917152,
      "learning_rate": 1.0961565937991143e-05,
      "loss": 0.1113,
      "step": 31630
    },
    {
      "epoch": 6.780968709815688,
      "grad_norm": 0.002210267586633563,
      "learning_rate": 1.0958708386912418e-05,
      "loss": 0.0654,
      "step": 31640
    },
    {
      "epoch": 6.783111873124732,
      "grad_norm": 0.002463350538164377,
      "learning_rate": 1.0955850835833692e-05,
      "loss": 0.037,
      "step": 31650
    },
    {
      "epoch": 6.785255036433776,
      "grad_norm": 0.011332540772855282,
      "learning_rate": 1.0952993284754966e-05,
      "loss": 0.1479,
      "step": 31660
    },
    {
      "epoch": 6.78739819974282,
      "grad_norm": 0.002704035025089979,
      "learning_rate": 1.095013573367624e-05,
      "loss": 0.1131,
      "step": 31670
    },
    {
      "epoch": 6.789541363051865,
      "grad_norm": 0.0034165135584771633,
      "learning_rate": 1.0947278182597514e-05,
      "loss": 0.0016,
      "step": 31680
    },
    {
      "epoch": 6.791684526360909,
      "grad_norm": 0.0025892306584864855,
      "learning_rate": 1.0944420631518788e-05,
      "loss": 0.1673,
      "step": 31690
    },
    {
      "epoch": 6.7938276896699525,
      "grad_norm": 0.008842415176331997,
      "learning_rate": 1.0941563080440064e-05,
      "loss": 0.0201,
      "step": 31700
    },
    {
      "epoch": 6.795970852978997,
      "grad_norm": 0.002625473774969578,
      "learning_rate": 1.0938705529361338e-05,
      "loss": 0.0003,
      "step": 31710
    },
    {
      "epoch": 6.798114016288041,
      "grad_norm": 0.013475860469043255,
      "learning_rate": 1.0935847978282611e-05,
      "loss": 0.0002,
      "step": 31720
    },
    {
      "epoch": 6.800257179597085,
      "grad_norm": 0.0028347016777843237,
      "learning_rate": 1.0932990427203887e-05,
      "loss": 0.0002,
      "step": 31730
    },
    {
      "epoch": 6.80240034290613,
      "grad_norm": 0.0027110660448670387,
      "learning_rate": 1.0930132876125161e-05,
      "loss": 0.0769,
      "step": 31740
    },
    {
      "epoch": 6.804543506215174,
      "grad_norm": 0.002250381512567401,
      "learning_rate": 1.0927275325046437e-05,
      "loss": 0.0746,
      "step": 31750
    },
    {
      "epoch": 6.806686669524217,
      "grad_norm": 0.0019014871213585138,
      "learning_rate": 1.092441777396771e-05,
      "loss": 0.1329,
      "step": 31760
    },
    {
      "epoch": 6.808829832833262,
      "grad_norm": 0.002514537423849106,
      "learning_rate": 1.0921560222888984e-05,
      "loss": 0.0001,
      "step": 31770
    },
    {
      "epoch": 6.810972996142306,
      "grad_norm": 0.006159766111522913,
      "learning_rate": 1.091870267181026e-05,
      "loss": 0.2268,
      "step": 31780
    },
    {
      "epoch": 6.81311615945135,
      "grad_norm": 0.016758017241954803,
      "learning_rate": 1.0915845120731534e-05,
      "loss": 0.2415,
      "step": 31790
    },
    {
      "epoch": 6.815259322760395,
      "grad_norm": 19.53175163269043,
      "learning_rate": 1.0912987569652808e-05,
      "loss": 0.2508,
      "step": 31800
    },
    {
      "epoch": 6.817402486069438,
      "grad_norm": 0.007946319878101349,
      "learning_rate": 1.0910130018574084e-05,
      "loss": 0.0747,
      "step": 31810
    },
    {
      "epoch": 6.819545649378482,
      "grad_norm": 0.030612869188189507,
      "learning_rate": 1.0907272467495357e-05,
      "loss": 0.0713,
      "step": 31820
    },
    {
      "epoch": 6.821688812687527,
      "grad_norm": 0.0072991992346942425,
      "learning_rate": 1.0904414916416633e-05,
      "loss": 0.0566,
      "step": 31830
    },
    {
      "epoch": 6.823831975996571,
      "grad_norm": 0.010822153650224209,
      "learning_rate": 1.0901557365337907e-05,
      "loss": 0.0044,
      "step": 31840
    },
    {
      "epoch": 6.825975139305615,
      "grad_norm": 0.0070276446640491486,
      "learning_rate": 1.0898699814259181e-05,
      "loss": 0.0001,
      "step": 31850
    },
    {
      "epoch": 6.8281183026146595,
      "grad_norm": 0.05943387374281883,
      "learning_rate": 1.0895842263180457e-05,
      "loss": 0.1872,
      "step": 31860
    },
    {
      "epoch": 6.830261465923703,
      "grad_norm": 0.0021343857515603304,
      "learning_rate": 1.089298471210173e-05,
      "loss": 0.0004,
      "step": 31870
    },
    {
      "epoch": 6.832404629232747,
      "grad_norm": 0.011816457845270634,
      "learning_rate": 1.0890127161023004e-05,
      "loss": 0.0002,
      "step": 31880
    },
    {
      "epoch": 6.834547792541792,
      "grad_norm": 0.05757442116737366,
      "learning_rate": 1.0887269609944278e-05,
      "loss": 0.0004,
      "step": 31890
    },
    {
      "epoch": 6.836690955850836,
      "grad_norm": 0.002238902961835265,
      "learning_rate": 1.0884412058865552e-05,
      "loss": 0.0002,
      "step": 31900
    },
    {
      "epoch": 6.83883411915988,
      "grad_norm": 1.949026107788086,
      "learning_rate": 1.0881554507786826e-05,
      "loss": 0.004,
      "step": 31910
    },
    {
      "epoch": 6.840977282468924,
      "grad_norm": 0.0018611109117045999,
      "learning_rate": 1.0878696956708102e-05,
      "loss": 0.0001,
      "step": 31920
    },
    {
      "epoch": 6.843120445777968,
      "grad_norm": 0.007064967416226864,
      "learning_rate": 1.0875839405629376e-05,
      "loss": 0.3413,
      "step": 31930
    },
    {
      "epoch": 6.845263609087013,
      "grad_norm": 0.0037371355574578047,
      "learning_rate": 1.087298185455065e-05,
      "loss": 0.1762,
      "step": 31940
    },
    {
      "epoch": 6.847406772396057,
      "grad_norm": 0.013948295265436172,
      "learning_rate": 1.0870124303471925e-05,
      "loss": 0.1553,
      "step": 31950
    },
    {
      "epoch": 6.849549935705101,
      "grad_norm": 0.016282562166452408,
      "learning_rate": 1.08672667523932e-05,
      "loss": 0.0009,
      "step": 31960
    },
    {
      "epoch": 6.851693099014145,
      "grad_norm": 0.010524392127990723,
      "learning_rate": 1.0864409201314475e-05,
      "loss": 0.0003,
      "step": 31970
    },
    {
      "epoch": 6.853836262323189,
      "grad_norm": 0.010564742609858513,
      "learning_rate": 1.0861551650235749e-05,
      "loss": 0.0002,
      "step": 31980
    },
    {
      "epoch": 6.855979425632233,
      "grad_norm": 0.004449569154530764,
      "learning_rate": 1.0858694099157023e-05,
      "loss": 0.1854,
      "step": 31990
    },
    {
      "epoch": 6.858122588941278,
      "grad_norm": 0.02754419483244419,
      "learning_rate": 1.0855836548078298e-05,
      "loss": 0.0002,
      "step": 32000
    },
    {
      "epoch": 6.860265752250322,
      "grad_norm": 0.0035340336617082357,
      "learning_rate": 1.0852978996999572e-05,
      "loss": 0.0001,
      "step": 32010
    },
    {
      "epoch": 6.8624089155593655,
      "grad_norm": 0.0026929578743875027,
      "learning_rate": 1.0850121445920846e-05,
      "loss": 0.0008,
      "step": 32020
    },
    {
      "epoch": 6.86455207886841,
      "grad_norm": 0.0022173768375068903,
      "learning_rate": 1.0847263894842122e-05,
      "loss": 0.0004,
      "step": 32030
    },
    {
      "epoch": 6.866695242177454,
      "grad_norm": 0.007620370946824551,
      "learning_rate": 1.0844406343763396e-05,
      "loss": 0.0002,
      "step": 32040
    },
    {
      "epoch": 6.868838405486498,
      "grad_norm": 0.003473901655524969,
      "learning_rate": 1.0841548792684671e-05,
      "loss": 0.0001,
      "step": 32050
    },
    {
      "epoch": 6.870981568795543,
      "grad_norm": 0.0016540242359042168,
      "learning_rate": 1.0838691241605945e-05,
      "loss": 0.0,
      "step": 32060
    },
    {
      "epoch": 6.8731247321045865,
      "grad_norm": 0.0022768720518797636,
      "learning_rate": 1.083583369052722e-05,
      "loss": 0.0001,
      "step": 32070
    },
    {
      "epoch": 6.87526789541363,
      "grad_norm": 0.006708601955324411,
      "learning_rate": 1.0832976139448495e-05,
      "loss": 0.1843,
      "step": 32080
    },
    {
      "epoch": 6.877411058722675,
      "grad_norm": 0.0021495323162525892,
      "learning_rate": 1.0830118588369769e-05,
      "loss": 0.0001,
      "step": 32090
    },
    {
      "epoch": 6.879554222031719,
      "grad_norm": 0.0021660004276782274,
      "learning_rate": 1.0827261037291041e-05,
      "loss": 0.0005,
      "step": 32100
    },
    {
      "epoch": 6.881697385340763,
      "grad_norm": 0.0024942716117948294,
      "learning_rate": 1.0824403486212317e-05,
      "loss": 0.0002,
      "step": 32110
    },
    {
      "epoch": 6.8838405486498075,
      "grad_norm": 0.004136975854635239,
      "learning_rate": 1.082154593513359e-05,
      "loss": 0.0001,
      "step": 32120
    },
    {
      "epoch": 6.885983711958851,
      "grad_norm": 0.0016199309611693025,
      "learning_rate": 1.0818688384054865e-05,
      "loss": 0.0004,
      "step": 32130
    },
    {
      "epoch": 6.888126875267895,
      "grad_norm": 0.002400038531050086,
      "learning_rate": 1.081583083297614e-05,
      "loss": 0.0001,
      "step": 32140
    },
    {
      "epoch": 6.89027003857694,
      "grad_norm": 0.0019176430068910122,
      "learning_rate": 1.0812973281897414e-05,
      "loss": 0.3358,
      "step": 32150
    },
    {
      "epoch": 6.892413201885984,
      "grad_norm": 0.004857148043811321,
      "learning_rate": 1.0810115730818688e-05,
      "loss": 0.0002,
      "step": 32160
    },
    {
      "epoch": 6.894556365195028,
      "grad_norm": 0.0023576400708407164,
      "learning_rate": 1.0807258179739964e-05,
      "loss": 0.0037,
      "step": 32170
    },
    {
      "epoch": 6.896699528504072,
      "grad_norm": 0.005646857898682356,
      "learning_rate": 1.0804400628661238e-05,
      "loss": 0.0001,
      "step": 32180
    },
    {
      "epoch": 6.898842691813116,
      "grad_norm": 0.005746004171669483,
      "learning_rate": 1.0801543077582513e-05,
      "loss": 0.1712,
      "step": 32190
    },
    {
      "epoch": 6.90098585512216,
      "grad_norm": 0.004396871197968721,
      "learning_rate": 1.0798685526503787e-05,
      "loss": 0.0001,
      "step": 32200
    },
    {
      "epoch": 6.903129018431205,
      "grad_norm": 0.0028440693859010935,
      "learning_rate": 1.0795827975425061e-05,
      "loss": 0.0005,
      "step": 32210
    },
    {
      "epoch": 6.905272181740249,
      "grad_norm": 0.00623360276222229,
      "learning_rate": 1.0792970424346337e-05,
      "loss": 0.0745,
      "step": 32220
    },
    {
      "epoch": 6.9074153450492926,
      "grad_norm": 0.011269235983490944,
      "learning_rate": 1.079011287326761e-05,
      "loss": 0.0002,
      "step": 32230
    },
    {
      "epoch": 6.909558508358337,
      "grad_norm": 0.006919780746102333,
      "learning_rate": 1.0787255322188886e-05,
      "loss": 0.0007,
      "step": 32240
    },
    {
      "epoch": 6.911701671667381,
      "grad_norm": 0.007851130329072475,
      "learning_rate": 1.078439777111016e-05,
      "loss": 0.0001,
      "step": 32250
    },
    {
      "epoch": 6.913844834976425,
      "grad_norm": 0.0037767933681607246,
      "learning_rate": 1.0781540220031434e-05,
      "loss": 0.2299,
      "step": 32260
    },
    {
      "epoch": 6.91598799828547,
      "grad_norm": 0.0037745977751910686,
      "learning_rate": 1.077868266895271e-05,
      "loss": 0.0001,
      "step": 32270
    },
    {
      "epoch": 6.918131161594514,
      "grad_norm": 0.021810907870531082,
      "learning_rate": 1.0775825117873984e-05,
      "loss": 0.0002,
      "step": 32280
    },
    {
      "epoch": 6.920274324903557,
      "grad_norm": 0.002119906712323427,
      "learning_rate": 1.0772967566795258e-05,
      "loss": 0.0003,
      "step": 32290
    },
    {
      "epoch": 6.922417488212602,
      "grad_norm": 0.004423700738698244,
      "learning_rate": 1.0770110015716533e-05,
      "loss": 0.1414,
      "step": 32300
    },
    {
      "epoch": 6.924560651521646,
      "grad_norm": 0.002856286708265543,
      "learning_rate": 1.0767252464637807e-05,
      "loss": 0.155,
      "step": 32310
    },
    {
      "epoch": 6.92670381483069,
      "grad_norm": 0.00402815593406558,
      "learning_rate": 1.076439491355908e-05,
      "loss": 0.1153,
      "step": 32320
    },
    {
      "epoch": 6.928846978139735,
      "grad_norm": 0.004248902667313814,
      "learning_rate": 1.0761537362480355e-05,
      "loss": 0.0016,
      "step": 32330
    },
    {
      "epoch": 6.9309901414487785,
      "grad_norm": 0.01801344007253647,
      "learning_rate": 1.0758679811401629e-05,
      "loss": 0.1187,
      "step": 32340
    },
    {
      "epoch": 6.933133304757822,
      "grad_norm": 0.0026746601797640324,
      "learning_rate": 1.0755822260322903e-05,
      "loss": 0.0001,
      "step": 32350
    },
    {
      "epoch": 6.935276468066867,
      "grad_norm": 0.002223843475803733,
      "learning_rate": 1.0752964709244178e-05,
      "loss": 0.0003,
      "step": 32360
    },
    {
      "epoch": 6.937419631375911,
      "grad_norm": 0.002066351706162095,
      "learning_rate": 1.0750107158165452e-05,
      "loss": 0.126,
      "step": 32370
    },
    {
      "epoch": 6.939562794684955,
      "grad_norm": 0.004547769669443369,
      "learning_rate": 1.0747249607086728e-05,
      "loss": 0.0001,
      "step": 32380
    },
    {
      "epoch": 6.9417059579939995,
      "grad_norm": 0.45065388083457947,
      "learning_rate": 1.0744392056008002e-05,
      "loss": 0.004,
      "step": 32390
    },
    {
      "epoch": 6.943849121303043,
      "grad_norm": 0.013642141595482826,
      "learning_rate": 1.0741534504929276e-05,
      "loss": 0.0001,
      "step": 32400
    },
    {
      "epoch": 6.945992284612087,
      "grad_norm": 0.0016937716864049435,
      "learning_rate": 1.0738676953850551e-05,
      "loss": 0.0,
      "step": 32410
    },
    {
      "epoch": 6.948135447921132,
      "grad_norm": 0.00112817098852247,
      "learning_rate": 1.0735819402771825e-05,
      "loss": 0.0,
      "step": 32420
    },
    {
      "epoch": 6.950278611230176,
      "grad_norm": 0.7685372233390808,
      "learning_rate": 1.07329618516931e-05,
      "loss": 0.0011,
      "step": 32430
    },
    {
      "epoch": 6.95242177453922,
      "grad_norm": 0.0009801889536902308,
      "learning_rate": 1.0730104300614375e-05,
      "loss": 0.0,
      "step": 32440
    },
    {
      "epoch": 6.954564937848264,
      "grad_norm": 0.001067153993062675,
      "learning_rate": 1.0727246749535649e-05,
      "loss": 0.0003,
      "step": 32450
    },
    {
      "epoch": 6.956708101157308,
      "grad_norm": 0.0010756399715319276,
      "learning_rate": 1.0724389198456924e-05,
      "loss": 0.1135,
      "step": 32460
    },
    {
      "epoch": 6.958851264466352,
      "grad_norm": 0.001397851388901472,
      "learning_rate": 1.0721531647378198e-05,
      "loss": 0.0,
      "step": 32470
    },
    {
      "epoch": 6.960994427775397,
      "grad_norm": 0.0009226909023709595,
      "learning_rate": 1.0718674096299472e-05,
      "loss": 0.0,
      "step": 32480
    },
    {
      "epoch": 6.963137591084441,
      "grad_norm": 0.05012131109833717,
      "learning_rate": 1.0715816545220748e-05,
      "loss": 0.0001,
      "step": 32490
    },
    {
      "epoch": 6.9652807543934845,
      "grad_norm": 1.6645764112472534,
      "learning_rate": 1.0712958994142022e-05,
      "loss": 0.0009,
      "step": 32500
    },
    {
      "epoch": 6.967423917702529,
      "grad_norm": 0.0008102413266897202,
      "learning_rate": 1.0710101443063296e-05,
      "loss": 0.0,
      "step": 32510
    },
    {
      "epoch": 6.969567081011573,
      "grad_norm": 0.0012228358536958694,
      "learning_rate": 1.0707243891984571e-05,
      "loss": 0.0,
      "step": 32520
    },
    {
      "epoch": 6.971710244320617,
      "grad_norm": 0.000811157573480159,
      "learning_rate": 1.0704386340905844e-05,
      "loss": 0.0,
      "step": 32530
    },
    {
      "epoch": 6.973853407629662,
      "grad_norm": 0.0009631592547520995,
      "learning_rate": 1.0701528789827118e-05,
      "loss": 0.0,
      "step": 32540
    },
    {
      "epoch": 6.9759965709387055,
      "grad_norm": 0.0007628985331393778,
      "learning_rate": 1.0698671238748393e-05,
      "loss": 0.0,
      "step": 32550
    },
    {
      "epoch": 6.978139734247749,
      "grad_norm": 0.0006883770111016929,
      "learning_rate": 1.0695813687669667e-05,
      "loss": 0.0,
      "step": 32560
    },
    {
      "epoch": 6.980282897556794,
      "grad_norm": 0.000831522629596293,
      "learning_rate": 1.0692956136590941e-05,
      "loss": 0.4821,
      "step": 32570
    },
    {
      "epoch": 6.982426060865838,
      "grad_norm": 0.0011510718613862991,
      "learning_rate": 1.0690098585512217e-05,
      "loss": 0.0,
      "step": 32580
    },
    {
      "epoch": 6.984569224174882,
      "grad_norm": 0.0029099881649017334,
      "learning_rate": 1.068724103443349e-05,
      "loss": 0.2249,
      "step": 32590
    },
    {
      "epoch": 6.9867123874839265,
      "grad_norm": 0.001288620405830443,
      "learning_rate": 1.0684383483354766e-05,
      "loss": 0.0006,
      "step": 32600
    },
    {
      "epoch": 6.98885555079297,
      "grad_norm": 0.0013135562185198069,
      "learning_rate": 1.068152593227604e-05,
      "loss": 0.0001,
      "step": 32610
    },
    {
      "epoch": 6.990998714102014,
      "grad_norm": 0.0010360564338043332,
      "learning_rate": 1.0678668381197314e-05,
      "loss": 0.0001,
      "step": 32620
    },
    {
      "epoch": 6.993141877411059,
      "grad_norm": 0.001313921413384378,
      "learning_rate": 1.067581083011859e-05,
      "loss": 0.0039,
      "step": 32630
    },
    {
      "epoch": 6.995285040720103,
      "grad_norm": 26.44127082824707,
      "learning_rate": 1.0672953279039864e-05,
      "loss": 0.6681,
      "step": 32640
    },
    {
      "epoch": 6.997428204029147,
      "grad_norm": 0.002323722932487726,
      "learning_rate": 1.0670095727961138e-05,
      "loss": 0.0002,
      "step": 32650
    },
    {
      "epoch": 6.999571367338191,
      "grad_norm": 0.004244145471602678,
      "learning_rate": 1.0667238176882413e-05,
      "loss": 0.0003,
      "step": 32660
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9803333333333333,
      "eval_f1": 0.8981001727115717,
      "eval_loss": 0.10706104338169098,
      "eval_precision": 0.931899641577061,
      "eval_recall": 0.8666666666666667,
      "eval_runtime": 396.0888,
      "eval_samples_per_second": 7.574,
      "eval_steps_per_second": 2.525,
      "step": 32662
    },
    {
      "epoch": 7.001714530647235,
      "grad_norm": 0.003772530471906066,
      "learning_rate": 1.0664380625803687e-05,
      "loss": 0.1973,
      "step": 32670
    },
    {
      "epoch": 7.003857693956279,
      "grad_norm": 0.09816035628318787,
      "learning_rate": 1.0661523074724963e-05,
      "loss": 0.1126,
      "step": 32680
    },
    {
      "epoch": 7.006000857265324,
      "grad_norm": 0.02039823681116104,
      "learning_rate": 1.0658665523646237e-05,
      "loss": 0.0005,
      "step": 32690
    },
    {
      "epoch": 7.008144020574368,
      "grad_norm": 0.0035765257198363543,
      "learning_rate": 1.065580797256751e-05,
      "loss": 0.0006,
      "step": 32700
    },
    {
      "epoch": 7.0102871838834115,
      "grad_norm": 0.002938807476311922,
      "learning_rate": 1.0652950421488786e-05,
      "loss": 0.0002,
      "step": 32710
    },
    {
      "epoch": 7.012430347192456,
      "grad_norm": 0.12832069396972656,
      "learning_rate": 1.065009287041006e-05,
      "loss": 0.0003,
      "step": 32720
    },
    {
      "epoch": 7.0145735105015,
      "grad_norm": 0.006850220263004303,
      "learning_rate": 1.0647235319331334e-05,
      "loss": 0.0001,
      "step": 32730
    },
    {
      "epoch": 7.016716673810544,
      "grad_norm": 0.00089764449512586,
      "learning_rate": 1.064437776825261e-05,
      "loss": 0.0005,
      "step": 32740
    },
    {
      "epoch": 7.018859837119589,
      "grad_norm": 0.0017230617813766003,
      "learning_rate": 1.0641520217173882e-05,
      "loss": 0.0,
      "step": 32750
    },
    {
      "epoch": 7.021003000428633,
      "grad_norm": 0.0019557145424187183,
      "learning_rate": 1.0638662666095156e-05,
      "loss": 0.0003,
      "step": 32760
    },
    {
      "epoch": 7.023146163737676,
      "grad_norm": 0.0018193298019468784,
      "learning_rate": 1.0635805115016431e-05,
      "loss": 0.0001,
      "step": 32770
    },
    {
      "epoch": 7.025289327046721,
      "grad_norm": 0.007619134616106749,
      "learning_rate": 1.0632947563937705e-05,
      "loss": 0.0,
      "step": 32780
    },
    {
      "epoch": 7.027432490355765,
      "grad_norm": 0.001267278683371842,
      "learning_rate": 1.063009001285898e-05,
      "loss": 0.0,
      "step": 32790
    },
    {
      "epoch": 7.029575653664809,
      "grad_norm": 0.0009159005130641162,
      "learning_rate": 1.0627232461780255e-05,
      "loss": 0.3132,
      "step": 32800
    },
    {
      "epoch": 7.031718816973854,
      "grad_norm": 0.0016362491296604276,
      "learning_rate": 1.0624374910701529e-05,
      "loss": 0.0001,
      "step": 32810
    },
    {
      "epoch": 7.033861980282897,
      "grad_norm": 0.0013765663607046008,
      "learning_rate": 1.0621517359622805e-05,
      "loss": 0.0001,
      "step": 32820
    },
    {
      "epoch": 7.036005143591941,
      "grad_norm": 0.0011948198080062866,
      "learning_rate": 1.0618659808544078e-05,
      "loss": 0.082,
      "step": 32830
    },
    {
      "epoch": 7.038148306900986,
      "grad_norm": 0.0013029740657657385,
      "learning_rate": 1.0615802257465352e-05,
      "loss": 0.0,
      "step": 32840
    },
    {
      "epoch": 7.04029147021003,
      "grad_norm": 0.0026893119793385267,
      "learning_rate": 1.0612944706386628e-05,
      "loss": 0.0001,
      "step": 32850
    },
    {
      "epoch": 7.042434633519074,
      "grad_norm": 0.0012394231744110584,
      "learning_rate": 1.0610087155307902e-05,
      "loss": 0.0055,
      "step": 32860
    },
    {
      "epoch": 7.0445777968281185,
      "grad_norm": 0.0007498692139051855,
      "learning_rate": 1.0607229604229176e-05,
      "loss": 0.0,
      "step": 32870
    },
    {
      "epoch": 7.046720960137162,
      "grad_norm": 5.160586357116699,
      "learning_rate": 1.0604372053150451e-05,
      "loss": 0.0031,
      "step": 32880
    },
    {
      "epoch": 7.048864123446206,
      "grad_norm": 0.0006688401335850358,
      "learning_rate": 1.0601514502071725e-05,
      "loss": 0.0,
      "step": 32890
    },
    {
      "epoch": 7.051007286755251,
      "grad_norm": 0.0006538070738315582,
      "learning_rate": 1.0598656950993001e-05,
      "loss": 0.0008,
      "step": 32900
    },
    {
      "epoch": 7.053150450064295,
      "grad_norm": 0.0005631112726405263,
      "learning_rate": 1.0595799399914275e-05,
      "loss": 0.0001,
      "step": 32910
    },
    {
      "epoch": 7.055293613373339,
      "grad_norm": 0.0007206662558019161,
      "learning_rate": 1.0592941848835549e-05,
      "loss": 0.0,
      "step": 32920
    },
    {
      "epoch": 7.057436776682383,
      "grad_norm": 0.0005828651483170688,
      "learning_rate": 1.0590084297756825e-05,
      "loss": 0.0413,
      "step": 32930
    },
    {
      "epoch": 7.059579939991427,
      "grad_norm": 0.0007459850749000907,
      "learning_rate": 1.0587226746678098e-05,
      "loss": 0.0001,
      "step": 32940
    },
    {
      "epoch": 7.061723103300472,
      "grad_norm": 22.878482818603516,
      "learning_rate": 1.0584369195599374e-05,
      "loss": 0.1414,
      "step": 32950
    },
    {
      "epoch": 7.063866266609516,
      "grad_norm": 0.0017182303126901388,
      "learning_rate": 1.0581511644520646e-05,
      "loss": 0.0001,
      "step": 32960
    },
    {
      "epoch": 7.06600942991856,
      "grad_norm": 0.0004904757952317595,
      "learning_rate": 1.057865409344192e-05,
      "loss": 0.0001,
      "step": 32970
    },
    {
      "epoch": 7.068152593227604,
      "grad_norm": 0.0007061390206217766,
      "learning_rate": 1.0575796542363194e-05,
      "loss": 0.0,
      "step": 32980
    },
    {
      "epoch": 7.070295756536648,
      "grad_norm": 0.0007217531092464924,
      "learning_rate": 1.057293899128447e-05,
      "loss": 0.2586,
      "step": 32990
    },
    {
      "epoch": 7.072438919845692,
      "grad_norm": 0.0007239155238494277,
      "learning_rate": 1.0570081440205744e-05,
      "loss": 0.0001,
      "step": 33000
    },
    {
      "epoch": 7.074582083154737,
      "grad_norm": 0.012460891157388687,
      "learning_rate": 1.0567223889127018e-05,
      "loss": 0.1426,
      "step": 33010
    },
    {
      "epoch": 7.076725246463781,
      "grad_norm": 0.018085142597556114,
      "learning_rate": 1.0564366338048293e-05,
      "loss": 0.1372,
      "step": 33020
    },
    {
      "epoch": 7.0788684097728245,
      "grad_norm": 0.0007945459801703691,
      "learning_rate": 1.0561508786969567e-05,
      "loss": 0.0015,
      "step": 33030
    },
    {
      "epoch": 7.081011573081869,
      "grad_norm": 0.002221776405349374,
      "learning_rate": 1.0558651235890843e-05,
      "loss": 0.0031,
      "step": 33040
    },
    {
      "epoch": 7.083154736390913,
      "grad_norm": 0.24866710603237152,
      "learning_rate": 1.0555793684812117e-05,
      "loss": 0.0007,
      "step": 33050
    },
    {
      "epoch": 7.085297899699957,
      "grad_norm": 0.0007562943501397967,
      "learning_rate": 1.055293613373339e-05,
      "loss": 0.0004,
      "step": 33060
    },
    {
      "epoch": 7.087441063009002,
      "grad_norm": 0.034556593745946884,
      "learning_rate": 1.0550078582654666e-05,
      "loss": 0.0001,
      "step": 33070
    },
    {
      "epoch": 7.0895842263180455,
      "grad_norm": 0.000689562875777483,
      "learning_rate": 1.054722103157594e-05,
      "loss": 0.0,
      "step": 33080
    },
    {
      "epoch": 7.091727389627089,
      "grad_norm": 0.0005214450065977871,
      "learning_rate": 1.0544363480497216e-05,
      "loss": 0.0005,
      "step": 33090
    },
    {
      "epoch": 7.093870552936134,
      "grad_norm": 0.005589472129940987,
      "learning_rate": 1.054150592941849e-05,
      "loss": 0.0001,
      "step": 33100
    },
    {
      "epoch": 7.096013716245178,
      "grad_norm": 0.012618941254913807,
      "learning_rate": 1.0538648378339764e-05,
      "loss": 0.0,
      "step": 33110
    },
    {
      "epoch": 7.098156879554222,
      "grad_norm": 0.0006126819062046707,
      "learning_rate": 1.053579082726104e-05,
      "loss": 0.0,
      "step": 33120
    },
    {
      "epoch": 7.1003000428632665,
      "grad_norm": 0.000753114465624094,
      "learning_rate": 1.0532933276182313e-05,
      "loss": 0.0001,
      "step": 33130
    },
    {
      "epoch": 7.10244320617231,
      "grad_norm": 0.002930321032181382,
      "learning_rate": 1.0530075725103587e-05,
      "loss": 0.0001,
      "step": 33140
    },
    {
      "epoch": 7.104586369481354,
      "grad_norm": 0.0004851900739595294,
      "learning_rate": 1.0527218174024863e-05,
      "loss": 0.0,
      "step": 33150
    },
    {
      "epoch": 7.106729532790399,
      "grad_norm": 0.0006360508850775659,
      "learning_rate": 1.0524360622946137e-05,
      "loss": 0.0,
      "step": 33160
    },
    {
      "epoch": 7.108872696099443,
      "grad_norm": 0.0005062141572125256,
      "learning_rate": 1.0521503071867412e-05,
      "loss": 0.0031,
      "step": 33170
    },
    {
      "epoch": 7.111015859408487,
      "grad_norm": 0.0005206537898629904,
      "learning_rate": 1.0518645520788685e-05,
      "loss": 0.0,
      "step": 33180
    },
    {
      "epoch": 7.113159022717531,
      "grad_norm": 0.36199474334716797,
      "learning_rate": 1.0515787969709959e-05,
      "loss": 0.1653,
      "step": 33190
    },
    {
      "epoch": 7.115302186026575,
      "grad_norm": 0.0005098258261568844,
      "learning_rate": 1.0512930418631232e-05,
      "loss": 0.0005,
      "step": 33200
    },
    {
      "epoch": 7.117445349335619,
      "grad_norm": 22.741912841796875,
      "learning_rate": 1.0510072867552508e-05,
      "loss": 0.2938,
      "step": 33210
    },
    {
      "epoch": 7.119588512644664,
      "grad_norm": 0.0003903187462128699,
      "learning_rate": 1.0507215316473782e-05,
      "loss": 0.0,
      "step": 33220
    },
    {
      "epoch": 7.121731675953708,
      "grad_norm": 0.00043769527110271156,
      "learning_rate": 1.0504357765395058e-05,
      "loss": 0.0,
      "step": 33230
    },
    {
      "epoch": 7.123874839262752,
      "grad_norm": 0.001544836675748229,
      "learning_rate": 1.0501500214316332e-05,
      "loss": 0.0003,
      "step": 33240
    },
    {
      "epoch": 7.126018002571796,
      "grad_norm": 0.0036703122314065695,
      "learning_rate": 1.0498642663237605e-05,
      "loss": 0.0588,
      "step": 33250
    },
    {
      "epoch": 7.12816116588084,
      "grad_norm": 0.000595973979216069,
      "learning_rate": 1.0495785112158881e-05,
      "loss": 0.1443,
      "step": 33260
    },
    {
      "epoch": 7.130304329189884,
      "grad_norm": 0.003097478300333023,
      "learning_rate": 1.0492927561080155e-05,
      "loss": 0.0001,
      "step": 33270
    },
    {
      "epoch": 7.132447492498929,
      "grad_norm": 0.0014463122934103012,
      "learning_rate": 1.0490070010001429e-05,
      "loss": 0.1198,
      "step": 33280
    },
    {
      "epoch": 7.134590655807973,
      "grad_norm": 0.00040500468458049,
      "learning_rate": 1.0487212458922705e-05,
      "loss": 0.0008,
      "step": 33290
    },
    {
      "epoch": 7.136733819117016,
      "grad_norm": 0.00042857215157710016,
      "learning_rate": 1.0484354907843978e-05,
      "loss": 0.0002,
      "step": 33300
    },
    {
      "epoch": 7.138876982426061,
      "grad_norm": 0.0027225250378251076,
      "learning_rate": 1.0481497356765254e-05,
      "loss": 0.0006,
      "step": 33310
    },
    {
      "epoch": 7.141020145735105,
      "grad_norm": 0.0004641172708943486,
      "learning_rate": 1.0478639805686528e-05,
      "loss": 0.1673,
      "step": 33320
    },
    {
      "epoch": 7.143163309044149,
      "grad_norm": 0.0003301776305306703,
      "learning_rate": 1.0475782254607802e-05,
      "loss": 0.0,
      "step": 33330
    },
    {
      "epoch": 7.145306472353194,
      "grad_norm": 0.003284769132733345,
      "learning_rate": 1.0472924703529078e-05,
      "loss": 0.0,
      "step": 33340
    },
    {
      "epoch": 7.1474496356622375,
      "grad_norm": 0.0005369022837840021,
      "learning_rate": 1.0470067152450352e-05,
      "loss": 0.0,
      "step": 33350
    },
    {
      "epoch": 7.149592798971281,
      "grad_norm": 0.0003728258016053587,
      "learning_rate": 1.0467209601371625e-05,
      "loss": 0.0001,
      "step": 33360
    },
    {
      "epoch": 7.151735962280326,
      "grad_norm": 0.0041117300279438496,
      "learning_rate": 1.0464352050292901e-05,
      "loss": 0.0001,
      "step": 33370
    },
    {
      "epoch": 7.15387912558937,
      "grad_norm": 0.00045464513823390007,
      "learning_rate": 1.0461494499214175e-05,
      "loss": 0.0011,
      "step": 33380
    },
    {
      "epoch": 7.156022288898414,
      "grad_norm": 0.0005927425809204578,
      "learning_rate": 1.0458636948135447e-05,
      "loss": 0.1827,
      "step": 33390
    },
    {
      "epoch": 7.1581654522074585,
      "grad_norm": 0.0006313211633823812,
      "learning_rate": 1.0455779397056723e-05,
      "loss": 0.0,
      "step": 33400
    },
    {
      "epoch": 7.160308615516502,
      "grad_norm": 0.0006386705790646374,
      "learning_rate": 1.0452921845977997e-05,
      "loss": 0.0008,
      "step": 33410
    },
    {
      "epoch": 7.162451778825546,
      "grad_norm": 0.001410985249094665,
      "learning_rate": 1.045006429489927e-05,
      "loss": 0.0003,
      "step": 33420
    },
    {
      "epoch": 7.164594942134591,
      "grad_norm": 0.004261735826730728,
      "learning_rate": 1.0447206743820546e-05,
      "loss": 0.0993,
      "step": 33430
    },
    {
      "epoch": 7.166738105443635,
      "grad_norm": 0.002209498081356287,
      "learning_rate": 1.044434919274182e-05,
      "loss": 0.0004,
      "step": 33440
    },
    {
      "epoch": 7.168881268752679,
      "grad_norm": 0.002039824379608035,
      "learning_rate": 1.0441491641663096e-05,
      "loss": 0.0,
      "step": 33450
    },
    {
      "epoch": 7.171024432061723,
      "grad_norm": 0.002484086900949478,
      "learning_rate": 1.043863409058437e-05,
      "loss": 0.1153,
      "step": 33460
    },
    {
      "epoch": 7.173167595370767,
      "grad_norm": 17.87723731994629,
      "learning_rate": 1.0435776539505644e-05,
      "loss": 0.1399,
      "step": 33470
    },
    {
      "epoch": 7.175310758679811,
      "grad_norm": 0.002030933741480112,
      "learning_rate": 1.043291898842692e-05,
      "loss": 0.0038,
      "step": 33480
    },
    {
      "epoch": 7.177453921988856,
      "grad_norm": 0.03598073497414589,
      "learning_rate": 1.0430061437348193e-05,
      "loss": 0.11,
      "step": 33490
    },
    {
      "epoch": 7.1795970852979,
      "grad_norm": 0.0007617563242092729,
      "learning_rate": 1.0427203886269467e-05,
      "loss": 0.0865,
      "step": 33500
    },
    {
      "epoch": 7.1817402486069435,
      "grad_norm": 0.0004740110889542848,
      "learning_rate": 1.0424346335190743e-05,
      "loss": 0.0,
      "step": 33510
    },
    {
      "epoch": 7.183883411915988,
      "grad_norm": 0.000421764183556661,
      "learning_rate": 1.0421488784112017e-05,
      "loss": 0.0,
      "step": 33520
    },
    {
      "epoch": 7.186026575225032,
      "grad_norm": 0.0004488205013331026,
      "learning_rate": 1.0418631233033292e-05,
      "loss": 0.0,
      "step": 33530
    },
    {
      "epoch": 7.188169738534076,
      "grad_norm": 0.0005282205529510975,
      "learning_rate": 1.0415773681954566e-05,
      "loss": 0.0,
      "step": 33540
    },
    {
      "epoch": 7.190312901843121,
      "grad_norm": 0.002204019809141755,
      "learning_rate": 1.041291613087584e-05,
      "loss": 0.0,
      "step": 33550
    },
    {
      "epoch": 7.1924560651521645,
      "grad_norm": 0.005843959283083677,
      "learning_rate": 1.0410058579797116e-05,
      "loss": 0.0001,
      "step": 33560
    },
    {
      "epoch": 7.194599228461208,
      "grad_norm": 0.0017275642603635788,
      "learning_rate": 1.040720102871839e-05,
      "loss": 0.0782,
      "step": 33570
    },
    {
      "epoch": 7.196742391770253,
      "grad_norm": 0.0004567456489894539,
      "learning_rate": 1.0404343477639664e-05,
      "loss": 0.0001,
      "step": 33580
    },
    {
      "epoch": 7.198885555079297,
      "grad_norm": 0.0005856853676959872,
      "learning_rate": 1.040148592656094e-05,
      "loss": 0.0005,
      "step": 33590
    },
    {
      "epoch": 7.201028718388341,
      "grad_norm": 0.018349196761846542,
      "learning_rate": 1.0398628375482212e-05,
      "loss": 0.0,
      "step": 33600
    },
    {
      "epoch": 7.2031718816973855,
      "grad_norm": 0.0003924364282283932,
      "learning_rate": 1.0395770824403486e-05,
      "loss": 0.0,
      "step": 33610
    },
    {
      "epoch": 7.205315045006429,
      "grad_norm": 0.00038847976247780025,
      "learning_rate": 1.0392913273324761e-05,
      "loss": 0.0,
      "step": 33620
    },
    {
      "epoch": 7.207458208315473,
      "grad_norm": 0.00038047897396609187,
      "learning_rate": 1.0390055722246035e-05,
      "loss": 0.0,
      "step": 33630
    },
    {
      "epoch": 7.209601371624518,
      "grad_norm": 0.002094667637720704,
      "learning_rate": 1.0387198171167309e-05,
      "loss": 0.0,
      "step": 33640
    },
    {
      "epoch": 7.211744534933562,
      "grad_norm": 0.0006409846828319132,
      "learning_rate": 1.0384340620088585e-05,
      "loss": 0.0,
      "step": 33650
    },
    {
      "epoch": 7.213887698242606,
      "grad_norm": 0.0003464816836640239,
      "learning_rate": 1.0381483069009859e-05,
      "loss": 0.0,
      "step": 33660
    },
    {
      "epoch": 7.21603086155165,
      "grad_norm": 0.001234071678481996,
      "learning_rate": 1.0378625517931134e-05,
      "loss": 0.0,
      "step": 33670
    },
    {
      "epoch": 7.218174024860694,
      "grad_norm": 0.00039315581670962274,
      "learning_rate": 1.0375767966852408e-05,
      "loss": 0.0,
      "step": 33680
    },
    {
      "epoch": 7.220317188169738,
      "grad_norm": 0.0034450250677764416,
      "learning_rate": 1.0372910415773682e-05,
      "loss": 0.0,
      "step": 33690
    },
    {
      "epoch": 7.222460351478783,
      "grad_norm": 0.00039546607877127826,
      "learning_rate": 1.0370052864694958e-05,
      "loss": 0.0962,
      "step": 33700
    },
    {
      "epoch": 7.224603514787827,
      "grad_norm": 0.0004572273464873433,
      "learning_rate": 1.0367195313616232e-05,
      "loss": 0.0556,
      "step": 33710
    },
    {
      "epoch": 7.226746678096871,
      "grad_norm": 0.000442349148215726,
      "learning_rate": 1.0364337762537506e-05,
      "loss": 0.1758,
      "step": 33720
    },
    {
      "epoch": 7.228889841405915,
      "grad_norm": 0.0016628653975203633,
      "learning_rate": 1.0361480211458781e-05,
      "loss": 0.0399,
      "step": 33730
    },
    {
      "epoch": 7.231033004714959,
      "grad_norm": 0.0004220207629259676,
      "learning_rate": 1.0358622660380055e-05,
      "loss": 0.1189,
      "step": 33740
    },
    {
      "epoch": 7.233176168024004,
      "grad_norm": 0.002794851316139102,
      "learning_rate": 1.035576510930133e-05,
      "loss": 0.0069,
      "step": 33750
    },
    {
      "epoch": 7.235319331333048,
      "grad_norm": 0.001969607314094901,
      "learning_rate": 1.0352907558222605e-05,
      "loss": 0.0039,
      "step": 33760
    },
    {
      "epoch": 7.237462494642092,
      "grad_norm": 15.30750560760498,
      "learning_rate": 1.0350050007143879e-05,
      "loss": 0.086,
      "step": 33770
    },
    {
      "epoch": 7.239605657951136,
      "grad_norm": 0.0007942800293676555,
      "learning_rate": 1.0347192456065154e-05,
      "loss": 0.2771,
      "step": 33780
    },
    {
      "epoch": 7.24174882126018,
      "grad_norm": 0.005104179494082928,
      "learning_rate": 1.0344334904986428e-05,
      "loss": 0.0089,
      "step": 33790
    },
    {
      "epoch": 7.243891984569224,
      "grad_norm": 0.0006262401002459228,
      "learning_rate": 1.0341477353907704e-05,
      "loss": 0.0001,
      "step": 33800
    },
    {
      "epoch": 7.246035147878269,
      "grad_norm": 0.0005532526411116123,
      "learning_rate": 1.0338619802828978e-05,
      "loss": 0.0005,
      "step": 33810
    },
    {
      "epoch": 7.248178311187313,
      "grad_norm": 0.000506112992297858,
      "learning_rate": 1.033576225175025e-05,
      "loss": 0.0,
      "step": 33820
    },
    {
      "epoch": 7.2503214744963564,
      "grad_norm": 0.0006577022140845656,
      "learning_rate": 1.0332904700671524e-05,
      "loss": 0.0,
      "step": 33830
    },
    {
      "epoch": 7.252464637805401,
      "grad_norm": 0.0004701082070823759,
      "learning_rate": 1.03300471495928e-05,
      "loss": 0.0,
      "step": 33840
    },
    {
      "epoch": 7.254607801114445,
      "grad_norm": 0.001843329519033432,
      "learning_rate": 1.0327189598514073e-05,
      "loss": 0.0001,
      "step": 33850
    },
    {
      "epoch": 7.256750964423489,
      "grad_norm": 0.00034068868262693286,
      "learning_rate": 1.0324332047435347e-05,
      "loss": 0.0012,
      "step": 33860
    },
    {
      "epoch": 7.258894127732534,
      "grad_norm": 0.004702831618487835,
      "learning_rate": 1.0321474496356623e-05,
      "loss": 0.0,
      "step": 33870
    },
    {
      "epoch": 7.2610372910415775,
      "grad_norm": 0.0009433725499548018,
      "learning_rate": 1.0318616945277897e-05,
      "loss": 0.0009,
      "step": 33880
    },
    {
      "epoch": 7.263180454350621,
      "grad_norm": 0.0035842042416334152,
      "learning_rate": 1.0315759394199172e-05,
      "loss": 0.0003,
      "step": 33890
    },
    {
      "epoch": 7.265323617659666,
      "grad_norm": 0.00033207182423211634,
      "learning_rate": 1.0312901843120446e-05,
      "loss": 0.0,
      "step": 33900
    },
    {
      "epoch": 7.26746678096871,
      "grad_norm": 0.00023668578069191426,
      "learning_rate": 1.031004429204172e-05,
      "loss": 0.0,
      "step": 33910
    },
    {
      "epoch": 7.269609944277754,
      "grad_norm": 0.00027680190396495163,
      "learning_rate": 1.0307186740962996e-05,
      "loss": 0.0,
      "step": 33920
    },
    {
      "epoch": 7.2717531075867985,
      "grad_norm": 0.0021870697382837534,
      "learning_rate": 1.030432918988427e-05,
      "loss": 0.2611,
      "step": 33930
    },
    {
      "epoch": 7.273896270895842,
      "grad_norm": 0.0002755653695203364,
      "learning_rate": 1.0301471638805545e-05,
      "loss": 0.0,
      "step": 33940
    },
    {
      "epoch": 7.276039434204886,
      "grad_norm": 0.00037566787796095014,
      "learning_rate": 1.029861408772682e-05,
      "loss": 0.0,
      "step": 33950
    },
    {
      "epoch": 7.278182597513931,
      "grad_norm": 0.00028795769321732223,
      "learning_rate": 1.0295756536648093e-05,
      "loss": 0.0002,
      "step": 33960
    },
    {
      "epoch": 7.280325760822975,
      "grad_norm": 0.00021473794186022133,
      "learning_rate": 1.0292898985569369e-05,
      "loss": 0.0002,
      "step": 33970
    },
    {
      "epoch": 7.282468924132019,
      "grad_norm": 0.0002534361556172371,
      "learning_rate": 1.0290041434490643e-05,
      "loss": 0.0,
      "step": 33980
    },
    {
      "epoch": 7.284612087441063,
      "grad_norm": 0.0032220850698649883,
      "learning_rate": 1.0287183883411917e-05,
      "loss": 0.0,
      "step": 33990
    },
    {
      "epoch": 7.286755250750107,
      "grad_norm": 0.00791099201887846,
      "learning_rate": 1.0284326332333192e-05,
      "loss": 0.0001,
      "step": 34000
    },
    {
      "epoch": 7.288898414059151,
      "grad_norm": 0.0022546967957168818,
      "learning_rate": 1.0281468781254466e-05,
      "loss": 0.0,
      "step": 34010
    },
    {
      "epoch": 7.291041577368196,
      "grad_norm": 0.006825518328696489,
      "learning_rate": 1.0278611230175742e-05,
      "loss": 0.0,
      "step": 34020
    },
    {
      "epoch": 7.29318474067724,
      "grad_norm": 0.00034010972012765706,
      "learning_rate": 1.0275753679097014e-05,
      "loss": 0.2736,
      "step": 34030
    },
    {
      "epoch": 7.2953279039862835,
      "grad_norm": 0.000369062036043033,
      "learning_rate": 1.0272896128018288e-05,
      "loss": 0.0001,
      "step": 34040
    },
    {
      "epoch": 7.297471067295328,
      "grad_norm": 88.20013427734375,
      "learning_rate": 1.0270038576939562e-05,
      "loss": 0.5574,
      "step": 34050
    },
    {
      "epoch": 7.299614230604372,
      "grad_norm": 0.0010565046686679125,
      "learning_rate": 1.0267181025860838e-05,
      "loss": 0.0002,
      "step": 34060
    },
    {
      "epoch": 7.301757393913416,
      "grad_norm": 0.020862329751253128,
      "learning_rate": 1.0264323474782112e-05,
      "loss": 0.0002,
      "step": 34070
    },
    {
      "epoch": 7.303900557222461,
      "grad_norm": 0.0004959757206961513,
      "learning_rate": 1.0261465923703387e-05,
      "loss": 0.0001,
      "step": 34080
    },
    {
      "epoch": 7.3060437205315045,
      "grad_norm": 0.028743373230099678,
      "learning_rate": 1.0258608372624661e-05,
      "loss": 0.0001,
      "step": 34090
    },
    {
      "epoch": 7.308186883840548,
      "grad_norm": 0.0011145476019009948,
      "learning_rate": 1.0255750821545935e-05,
      "loss": 0.0002,
      "step": 34100
    },
    {
      "epoch": 7.310330047149593,
      "grad_norm": 0.0003069777740165591,
      "learning_rate": 1.025289327046721e-05,
      "loss": 0.0,
      "step": 34110
    },
    {
      "epoch": 7.312473210458637,
      "grad_norm": 0.0005261853220872581,
      "learning_rate": 1.0250035719388485e-05,
      "loss": 0.1704,
      "step": 34120
    },
    {
      "epoch": 7.314616373767681,
      "grad_norm": 0.010907856747508049,
      "learning_rate": 1.0247178168309759e-05,
      "loss": 0.0,
      "step": 34130
    },
    {
      "epoch": 7.3167595370767256,
      "grad_norm": 0.0009054424590431154,
      "learning_rate": 1.0244320617231034e-05,
      "loss": 0.0001,
      "step": 34140
    },
    {
      "epoch": 7.318902700385769,
      "grad_norm": 0.33101320266723633,
      "learning_rate": 1.0241463066152308e-05,
      "loss": 0.0006,
      "step": 34150
    },
    {
      "epoch": 7.321045863694813,
      "grad_norm": 0.0005135377869009972,
      "learning_rate": 1.0238605515073584e-05,
      "loss": 0.0,
      "step": 34160
    },
    {
      "epoch": 7.323189027003858,
      "grad_norm": 0.0009532647090964019,
      "learning_rate": 1.0235747963994858e-05,
      "loss": 0.1845,
      "step": 34170
    },
    {
      "epoch": 7.325332190312902,
      "grad_norm": 0.0009806351736187935,
      "learning_rate": 1.0232890412916132e-05,
      "loss": 0.0004,
      "step": 34180
    },
    {
      "epoch": 7.327475353621946,
      "grad_norm": 0.0004975820775143802,
      "learning_rate": 1.0230032861837407e-05,
      "loss": 0.0001,
      "step": 34190
    },
    {
      "epoch": 7.32961851693099,
      "grad_norm": 0.0038725933991372585,
      "learning_rate": 1.0227175310758681e-05,
      "loss": 0.0005,
      "step": 34200
    },
    {
      "epoch": 7.331761680240034,
      "grad_norm": 0.0006480130832642317,
      "learning_rate": 1.0224317759679955e-05,
      "loss": 0.155,
      "step": 34210
    },
    {
      "epoch": 7.333904843549078,
      "grad_norm": 0.0006750280153937638,
      "learning_rate": 1.022146020860123e-05,
      "loss": 0.004,
      "step": 34220
    },
    {
      "epoch": 7.336048006858123,
      "grad_norm": 0.01175556518137455,
      "learning_rate": 1.0218602657522505e-05,
      "loss": 0.0001,
      "step": 34230
    },
    {
      "epoch": 7.338191170167167,
      "grad_norm": 0.0007523545064032078,
      "learning_rate": 1.021574510644378e-05,
      "loss": 0.0001,
      "step": 34240
    },
    {
      "epoch": 7.340334333476211,
      "grad_norm": 0.00035460665822029114,
      "learning_rate": 1.0212887555365053e-05,
      "loss": 0.0001,
      "step": 34250
    },
    {
      "epoch": 7.342477496785255,
      "grad_norm": 0.006185638252645731,
      "learning_rate": 1.0210030004286326e-05,
      "loss": 0.0023,
      "step": 34260
    },
    {
      "epoch": 7.344620660094299,
      "grad_norm": 0.03483883664011955,
      "learning_rate": 1.02071724532076e-05,
      "loss": 0.0015,
      "step": 34270
    },
    {
      "epoch": 7.346763823403343,
      "grad_norm": 0.00031600467627868056,
      "learning_rate": 1.0204314902128876e-05,
      "loss": 0.0,
      "step": 34280
    },
    {
      "epoch": 7.348906986712388,
      "grad_norm": 0.00273903994821012,
      "learning_rate": 1.020145735105015e-05,
      "loss": 0.0,
      "step": 34290
    },
    {
      "epoch": 7.351050150021432,
      "grad_norm": 0.002629741095006466,
      "learning_rate": 1.0198599799971426e-05,
      "loss": 0.0,
      "step": 34300
    },
    {
      "epoch": 7.353193313330475,
      "grad_norm": 0.00019962151418440044,
      "learning_rate": 1.01957422488927e-05,
      "loss": 0.0008,
      "step": 34310
    },
    {
      "epoch": 7.35533647663952,
      "grad_norm": 0.0003138656902592629,
      "learning_rate": 1.0192884697813973e-05,
      "loss": 0.0,
      "step": 34320
    },
    {
      "epoch": 7.357479639948564,
      "grad_norm": 0.00023727105872239918,
      "learning_rate": 1.0190027146735249e-05,
      "loss": 0.0,
      "step": 34330
    },
    {
      "epoch": 7.359622803257608,
      "grad_norm": 0.0020295782014727592,
      "learning_rate": 1.0187169595656523e-05,
      "loss": 0.0,
      "step": 34340
    },
    {
      "epoch": 7.361765966566653,
      "grad_norm": 0.005734284874051809,
      "learning_rate": 1.0184312044577797e-05,
      "loss": 0.0,
      "step": 34350
    },
    {
      "epoch": 7.3639091298756965,
      "grad_norm": 0.00030202826019376516,
      "learning_rate": 1.0181454493499072e-05,
      "loss": 0.0,
      "step": 34360
    },
    {
      "epoch": 7.36605229318474,
      "grad_norm": 0.0006809383630752563,
      "learning_rate": 1.0178596942420346e-05,
      "loss": 0.0,
      "step": 34370
    },
    {
      "epoch": 7.368195456493785,
      "grad_norm": 0.004416316747665405,
      "learning_rate": 1.0175739391341622e-05,
      "loss": 0.0,
      "step": 34380
    },
    {
      "epoch": 7.370338619802829,
      "grad_norm": 0.000436782487668097,
      "learning_rate": 1.0172881840262896e-05,
      "loss": 0.0,
      "step": 34390
    },
    {
      "epoch": 7.372481783111873,
      "grad_norm": 0.0031857192516326904,
      "learning_rate": 1.017002428918417e-05,
      "loss": 0.0002,
      "step": 34400
    },
    {
      "epoch": 7.3746249464209175,
      "grad_norm": 0.00022714260558132082,
      "learning_rate": 1.0167166738105446e-05,
      "loss": 0.0,
      "step": 34410
    },
    {
      "epoch": 7.376768109729961,
      "grad_norm": 0.0021320900414139032,
      "learning_rate": 1.016430918702672e-05,
      "loss": 0.0,
      "step": 34420
    },
    {
      "epoch": 7.378911273039005,
      "grad_norm": 0.0003265618288423866,
      "learning_rate": 1.0161451635947993e-05,
      "loss": 0.1276,
      "step": 34430
    },
    {
      "epoch": 7.38105443634805,
      "grad_norm": 0.00022982493101153523,
      "learning_rate": 1.0158594084869269e-05,
      "loss": 0.0,
      "step": 34440
    },
    {
      "epoch": 7.383197599657094,
      "grad_norm": 0.0001817593874875456,
      "learning_rate": 1.0155736533790543e-05,
      "loss": 0.0,
      "step": 34450
    },
    {
      "epoch": 7.385340762966138,
      "grad_norm": 0.0016534217866137624,
      "learning_rate": 1.0152878982711815e-05,
      "loss": 0.0,
      "step": 34460
    },
    {
      "epoch": 7.387483926275182,
      "grad_norm": 0.00041035027243196964,
      "learning_rate": 1.015002143163309e-05,
      "loss": 0.0,
      "step": 34470
    },
    {
      "epoch": 7.389627089584226,
      "grad_norm": 0.00017376267351210117,
      "learning_rate": 1.0147163880554365e-05,
      "loss": 0.0,
      "step": 34480
    },
    {
      "epoch": 7.39177025289327,
      "grad_norm": 0.00015669276763219386,
      "learning_rate": 1.0144306329475639e-05,
      "loss": 0.0003,
      "step": 34490
    },
    {
      "epoch": 7.393913416202315,
      "grad_norm": 0.00018345957505516708,
      "learning_rate": 1.0141448778396914e-05,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 7.396056579511359,
      "grad_norm": 0.00023877964122220874,
      "learning_rate": 1.0138591227318188e-05,
      "loss": 0.0,
      "step": 34510
    },
    {
      "epoch": 7.3981997428204025,
      "grad_norm": 0.004738484974950552,
      "learning_rate": 1.0135733676239464e-05,
      "loss": 0.0,
      "step": 34520
    },
    {
      "epoch": 7.400342906129447,
      "grad_norm": 0.0001910429709823802,
      "learning_rate": 1.0132876125160738e-05,
      "loss": 0.0005,
      "step": 34530
    },
    {
      "epoch": 7.402486069438491,
      "grad_norm": 0.0012458695564419031,
      "learning_rate": 1.0130018574082012e-05,
      "loss": 0.0001,
      "step": 34540
    },
    {
      "epoch": 7.404629232747535,
      "grad_norm": 0.00017575046513229609,
      "learning_rate": 1.0127161023003287e-05,
      "loss": 0.0,
      "step": 34550
    },
    {
      "epoch": 7.40677239605658,
      "grad_norm": 0.0005794498138129711,
      "learning_rate": 1.0124303471924561e-05,
      "loss": 0.0,
      "step": 34560
    },
    {
      "epoch": 7.4089155593656235,
      "grad_norm": 0.00032302457839250565,
      "learning_rate": 1.0121445920845835e-05,
      "loss": 0.0,
      "step": 34570
    },
    {
      "epoch": 7.411058722674667,
      "grad_norm": 0.00014895886124577373,
      "learning_rate": 1.011858836976711e-05,
      "loss": 0.0,
      "step": 34580
    },
    {
      "epoch": 7.413201885983712,
      "grad_norm": 0.0016269738553091884,
      "learning_rate": 1.0115730818688385e-05,
      "loss": 0.0,
      "step": 34590
    },
    {
      "epoch": 7.415345049292756,
      "grad_norm": 0.00011713299318216741,
      "learning_rate": 1.011287326760966e-05,
      "loss": 0.2815,
      "step": 34600
    },
    {
      "epoch": 7.4174882126018,
      "grad_norm": 0.00018430230556987226,
      "learning_rate": 1.0110015716530934e-05,
      "loss": 0.0008,
      "step": 34610
    },
    {
      "epoch": 7.4196313759108445,
      "grad_norm": 19.365083694458008,
      "learning_rate": 1.0107158165452208e-05,
      "loss": 0.6812,
      "step": 34620
    },
    {
      "epoch": 7.421774539219888,
      "grad_norm": 0.18472278118133545,
      "learning_rate": 1.0104300614373484e-05,
      "loss": 0.0005,
      "step": 34630
    },
    {
      "epoch": 7.423917702528932,
      "grad_norm": 0.0007572862668894231,
      "learning_rate": 1.0101443063294758e-05,
      "loss": 0.0002,
      "step": 34640
    },
    {
      "epoch": 7.426060865837977,
      "grad_norm": 0.0008949873736128211,
      "learning_rate": 1.0098585512216033e-05,
      "loss": 0.0,
      "step": 34650
    },
    {
      "epoch": 7.428204029147021,
      "grad_norm": 0.00038551929173991084,
      "learning_rate": 1.0095727961137307e-05,
      "loss": 0.0002,
      "step": 34660
    },
    {
      "epoch": 7.430347192456066,
      "grad_norm": 0.016727354377508163,
      "learning_rate": 1.0092870410058581e-05,
      "loss": 0.0001,
      "step": 34670
    },
    {
      "epoch": 7.432490355765109,
      "grad_norm": 0.0004594168858602643,
      "learning_rate": 1.0090012858979853e-05,
      "loss": 0.0001,
      "step": 34680
    },
    {
      "epoch": 7.434633519074153,
      "grad_norm": 0.126695454120636,
      "learning_rate": 1.0087155307901129e-05,
      "loss": 0.002,
      "step": 34690
    },
    {
      "epoch": 7.436776682383198,
      "grad_norm": 0.0005885565187782049,
      "learning_rate": 1.0084297756822403e-05,
      "loss": 0.0003,
      "step": 34700
    },
    {
      "epoch": 7.438919845692242,
      "grad_norm": 0.001589350402355194,
      "learning_rate": 1.0081440205743677e-05,
      "loss": 0.0,
      "step": 34710
    },
    {
      "epoch": 7.441063009001286,
      "grad_norm": 0.0019455463625490665,
      "learning_rate": 1.0078582654664953e-05,
      "loss": 0.0,
      "step": 34720
    },
    {
      "epoch": 7.44320617231033,
      "grad_norm": 0.0005724846269004047,
      "learning_rate": 1.0075725103586226e-05,
      "loss": 0.0,
      "step": 34730
    },
    {
      "epoch": 7.445349335619374,
      "grad_norm": 0.00019459004397504032,
      "learning_rate": 1.0072867552507502e-05,
      "loss": 0.0,
      "step": 34740
    },
    {
      "epoch": 7.447492498928418,
      "grad_norm": 0.00020842325466219336,
      "learning_rate": 1.0070010001428776e-05,
      "loss": 0.0,
      "step": 34750
    },
    {
      "epoch": 7.449635662237463,
      "grad_norm": 0.0010744291357696056,
      "learning_rate": 1.006715245035005e-05,
      "loss": 0.0001,
      "step": 34760
    },
    {
      "epoch": 7.451778825546507,
      "grad_norm": 0.00019806623458862305,
      "learning_rate": 1.0064294899271326e-05,
      "loss": 0.0001,
      "step": 34770
    },
    {
      "epoch": 7.453921988855551,
      "grad_norm": 0.018361104652285576,
      "learning_rate": 1.00614373481926e-05,
      "loss": 0.3051,
      "step": 34780
    },
    {
      "epoch": 7.456065152164595,
      "grad_norm": 0.0007882401114329696,
      "learning_rate": 1.0058579797113875e-05,
      "loss": 0.0001,
      "step": 34790
    },
    {
      "epoch": 7.458208315473639,
      "grad_norm": 0.0016168523579835892,
      "learning_rate": 1.0055722246035149e-05,
      "loss": 0.0001,
      "step": 34800
    },
    {
      "epoch": 7.460351478782683,
      "grad_norm": 0.018528839573264122,
      "learning_rate": 1.0052864694956423e-05,
      "loss": 0.1638,
      "step": 34810
    },
    {
      "epoch": 7.462494642091728,
      "grad_norm": 0.0012712106108665466,
      "learning_rate": 1.0050007143877699e-05,
      "loss": 0.0013,
      "step": 34820
    },
    {
      "epoch": 7.464637805400772,
      "grad_norm": 0.001326845376752317,
      "learning_rate": 1.0047149592798973e-05,
      "loss": 0.246,
      "step": 34830
    },
    {
      "epoch": 7.4667809687098154,
      "grad_norm": 0.0008190680528059602,
      "learning_rate": 1.0044292041720246e-05,
      "loss": 0.0001,
      "step": 34840
    },
    {
      "epoch": 7.46892413201886,
      "grad_norm": 0.013610721565783024,
      "learning_rate": 1.0041434490641522e-05,
      "loss": 0.0002,
      "step": 34850
    },
    {
      "epoch": 7.471067295327904,
      "grad_norm": 0.0008826245320960879,
      "learning_rate": 1.0038576939562796e-05,
      "loss": 0.0001,
      "step": 34860
    },
    {
      "epoch": 7.473210458636948,
      "grad_norm": 0.0004001745255663991,
      "learning_rate": 1.0035719388484072e-05,
      "loss": 0.0003,
      "step": 34870
    },
    {
      "epoch": 7.475353621945993,
      "grad_norm": 0.002948281355202198,
      "learning_rate": 1.0032861837405346e-05,
      "loss": 0.0001,
      "step": 34880
    },
    {
      "epoch": 7.4774967852550365,
      "grad_norm": 0.0004232659994158894,
      "learning_rate": 1.0030004286326618e-05,
      "loss": 0.0,
      "step": 34890
    },
    {
      "epoch": 7.47963994856408,
      "grad_norm": 0.002614226657897234,
      "learning_rate": 1.0027146735247892e-05,
      "loss": 0.0001,
      "step": 34900
    },
    {
      "epoch": 7.481783111873125,
      "grad_norm": 0.002209399826824665,
      "learning_rate": 1.0024289184169167e-05,
      "loss": 0.0002,
      "step": 34910
    },
    {
      "epoch": 7.483926275182169,
      "grad_norm": 0.0007184157730080187,
      "learning_rate": 1.0021431633090441e-05,
      "loss": 0.2331,
      "step": 34920
    },
    {
      "epoch": 7.486069438491213,
      "grad_norm": 0.05721118673682213,
      "learning_rate": 1.0018574082011717e-05,
      "loss": 0.1857,
      "step": 34930
    },
    {
      "epoch": 7.4882126018002575,
      "grad_norm": 0.05137971043586731,
      "learning_rate": 1.001571653093299e-05,
      "loss": 0.0015,
      "step": 34940
    },
    {
      "epoch": 7.490355765109301,
      "grad_norm": 0.0011240836465731263,
      "learning_rate": 1.0012858979854265e-05,
      "loss": 0.0002,
      "step": 34950
    },
    {
      "epoch": 7.492498928418345,
      "grad_norm": 19.183008193969727,
      "learning_rate": 1.001000142877554e-05,
      "loss": 0.1283,
      "step": 34960
    },
    {
      "epoch": 7.49464209172739,
      "grad_norm": 0.0003513889678288251,
      "learning_rate": 1.0007143877696814e-05,
      "loss": 0.0003,
      "step": 34970
    },
    {
      "epoch": 7.496785255036434,
      "grad_norm": 0.0007399634923785925,
      "learning_rate": 1.0004286326618088e-05,
      "loss": 0.2446,
      "step": 34980
    },
    {
      "epoch": 7.498928418345478,
      "grad_norm": 0.0007894771406427026,
      "learning_rate": 1.0001428775539364e-05,
      "loss": 0.1905,
      "step": 34990
    },
    {
      "epoch": 7.501071581654522,
      "grad_norm": 0.013893204741179943,
      "learning_rate": 9.998571224460638e-06,
      "loss": 0.0001,
      "step": 35000
    },
    {
      "epoch": 7.503214744963566,
      "grad_norm": 0.0006163105135783553,
      "learning_rate": 9.995713673381913e-06,
      "loss": 0.0,
      "step": 35010
    },
    {
      "epoch": 7.50535790827261,
      "grad_norm": 0.022088319063186646,
      "learning_rate": 9.992856122303187e-06,
      "loss": 0.0002,
      "step": 35020
    },
    {
      "epoch": 7.507501071581655,
      "grad_norm": 0.013078189454972744,
      "learning_rate": 9.989998571224461e-06,
      "loss": 0.2072,
      "step": 35030
    },
    {
      "epoch": 7.509644234890699,
      "grad_norm": 0.00020462893007788807,
      "learning_rate": 9.987141020145737e-06,
      "loss": 0.0006,
      "step": 35040
    },
    {
      "epoch": 7.5117873981997425,
      "grad_norm": 0.00024480506544932723,
      "learning_rate": 9.984283469067009e-06,
      "loss": 0.0001,
      "step": 35050
    },
    {
      "epoch": 7.513930561508787,
      "grad_norm": 24.131025314331055,
      "learning_rate": 9.981425917988285e-06,
      "loss": 0.1144,
      "step": 35060
    },
    {
      "epoch": 7.516073724817831,
      "grad_norm": 0.018219342455267906,
      "learning_rate": 9.978568366909559e-06,
      "loss": 0.0008,
      "step": 35070
    },
    {
      "epoch": 7.518216888126875,
      "grad_norm": 0.012236688286066055,
      "learning_rate": 9.975710815830834e-06,
      "loss": 0.0002,
      "step": 35080
    },
    {
      "epoch": 7.52036005143592,
      "grad_norm": 0.00030871236231178045,
      "learning_rate": 9.972853264752108e-06,
      "loss": 0.1084,
      "step": 35090
    },
    {
      "epoch": 7.5225032147449635,
      "grad_norm": 0.00016317734844051301,
      "learning_rate": 9.969995713673382e-06,
      "loss": 0.0005,
      "step": 35100
    },
    {
      "epoch": 7.524646378054007,
      "grad_norm": 0.00014504679711535573,
      "learning_rate": 9.967138162594658e-06,
      "loss": 0.0,
      "step": 35110
    },
    {
      "epoch": 7.526789541363052,
      "grad_norm": 0.00016378717555198818,
      "learning_rate": 9.964280611515932e-06,
      "loss": 0.0,
      "step": 35120
    },
    {
      "epoch": 7.528932704672096,
      "grad_norm": 0.38855138421058655,
      "learning_rate": 9.961423060437206e-06,
      "loss": 0.0008,
      "step": 35130
    },
    {
      "epoch": 7.53107586798114,
      "grad_norm": 0.009363495744764805,
      "learning_rate": 9.958565509358481e-06,
      "loss": 0.0001,
      "step": 35140
    },
    {
      "epoch": 7.5332190312901846,
      "grad_norm": 0.00010243810538668185,
      "learning_rate": 9.955707958279755e-06,
      "loss": 0.2239,
      "step": 35150
    },
    {
      "epoch": 7.535362194599228,
      "grad_norm": 0.00010868463141378015,
      "learning_rate": 9.952850407201029e-06,
      "loss": 0.0007,
      "step": 35160
    },
    {
      "epoch": 7.537505357908272,
      "grad_norm": 18.339195251464844,
      "learning_rate": 9.949992856122303e-06,
      "loss": 0.2431,
      "step": 35170
    },
    {
      "epoch": 7.539648521217317,
      "grad_norm": 0.00011299006291665137,
      "learning_rate": 9.947135305043579e-06,
      "loss": 0.0,
      "step": 35180
    },
    {
      "epoch": 7.541791684526361,
      "grad_norm": 0.00018007715698331594,
      "learning_rate": 9.944277753964853e-06,
      "loss": 0.0003,
      "step": 35190
    },
    {
      "epoch": 7.543934847835405,
      "grad_norm": 0.01691652275621891,
      "learning_rate": 9.941420202886127e-06,
      "loss": 0.0,
      "step": 35200
    },
    {
      "epoch": 7.546078011144449,
      "grad_norm": 0.00016862689517438412,
      "learning_rate": 9.938562651807402e-06,
      "loss": 0.0,
      "step": 35210
    },
    {
      "epoch": 7.548221174453493,
      "grad_norm": 0.0001263040758203715,
      "learning_rate": 9.935705100728676e-06,
      "loss": 0.0014,
      "step": 35220
    },
    {
      "epoch": 7.550364337762537,
      "grad_norm": 0.017517725005745888,
      "learning_rate": 9.932847549649952e-06,
      "loss": 0.1675,
      "step": 35230
    },
    {
      "epoch": 7.552507501071582,
      "grad_norm": 0.04722408950328827,
      "learning_rate": 9.929989998571226e-06,
      "loss": 0.1289,
      "step": 35240
    },
    {
      "epoch": 7.554650664380626,
      "grad_norm": 0.00017381325596943498,
      "learning_rate": 9.9271324474925e-06,
      "loss": 0.1793,
      "step": 35250
    },
    {
      "epoch": 7.5567938276896705,
      "grad_norm": 0.0025413220282644033,
      "learning_rate": 9.924274896413775e-06,
      "loss": 0.0977,
      "step": 35260
    },
    {
      "epoch": 7.558936990998714,
      "grad_norm": 0.0001576390495756641,
      "learning_rate": 9.921417345335047e-06,
      "loss": 0.0002,
      "step": 35270
    },
    {
      "epoch": 7.561080154307758,
      "grad_norm": 0.0005137580446898937,
      "learning_rate": 9.918559794256323e-06,
      "loss": 0.1262,
      "step": 35280
    },
    {
      "epoch": 7.563223317616803,
      "grad_norm": 0.08968813717365265,
      "learning_rate": 9.915702243177597e-06,
      "loss": 0.0042,
      "step": 35290
    },
    {
      "epoch": 7.565366480925847,
      "grad_norm": 0.00015822825662326068,
      "learning_rate": 9.912844692098873e-06,
      "loss": 0.0002,
      "step": 35300
    },
    {
      "epoch": 7.567509644234891,
      "grad_norm": 9.876990225166082e-05,
      "learning_rate": 9.909987141020146e-06,
      "loss": 0.0001,
      "step": 35310
    },
    {
      "epoch": 7.569652807543935,
      "grad_norm": 0.019091125577688217,
      "learning_rate": 9.90712958994142e-06,
      "loss": 0.0804,
      "step": 35320
    },
    {
      "epoch": 7.571795970852979,
      "grad_norm": 0.00011468317825347185,
      "learning_rate": 9.904272038862696e-06,
      "loss": 0.0,
      "step": 35330
    },
    {
      "epoch": 7.573939134162023,
      "grad_norm": 7.835928408894688e-05,
      "learning_rate": 9.90141448778397e-06,
      "loss": 0.0006,
      "step": 35340
    },
    {
      "epoch": 7.576082297471068,
      "grad_norm": 0.00011866488785017282,
      "learning_rate": 9.898556936705246e-06,
      "loss": 0.0003,
      "step": 35350
    },
    {
      "epoch": 7.578225460780112,
      "grad_norm": 0.014493986964225769,
      "learning_rate": 9.89569938562652e-06,
      "loss": 0.0001,
      "step": 35360
    },
    {
      "epoch": 7.5803686240891555,
      "grad_norm": 9.441105794394389e-05,
      "learning_rate": 9.892841834547793e-06,
      "loss": 0.0014,
      "step": 35370
    },
    {
      "epoch": 7.5825117873982,
      "grad_norm": 6.37789853499271e-05,
      "learning_rate": 9.889984283469067e-06,
      "loss": 0.1554,
      "step": 35380
    },
    {
      "epoch": 7.584654950707244,
      "grad_norm": 0.02175218053162098,
      "learning_rate": 9.887126732390341e-06,
      "loss": 0.7034,
      "step": 35390
    },
    {
      "epoch": 7.586798114016288,
      "grad_norm": 0.029424237087368965,
      "learning_rate": 9.884269181311617e-06,
      "loss": 0.0003,
      "step": 35400
    },
    {
      "epoch": 7.588941277325333,
      "grad_norm": 0.023140545934438705,
      "learning_rate": 9.881411630232891e-06,
      "loss": 0.1215,
      "step": 35410
    },
    {
      "epoch": 7.5910844406343765,
      "grad_norm": 0.0026015162002295256,
      "learning_rate": 9.878554079154166e-06,
      "loss": 0.0069,
      "step": 35420
    },
    {
      "epoch": 7.59322760394342,
      "grad_norm": 0.008458090014755726,
      "learning_rate": 9.87569652807544e-06,
      "loss": 0.0031,
      "step": 35430
    },
    {
      "epoch": 7.595370767252465,
      "grad_norm": 0.0017001311061903834,
      "learning_rate": 9.872838976996714e-06,
      "loss": 0.0008,
      "step": 35440
    },
    {
      "epoch": 7.597513930561509,
      "grad_norm": 0.0011090850457549095,
      "learning_rate": 9.86998142591799e-06,
      "loss": 0.0004,
      "step": 35450
    },
    {
      "epoch": 7.599657093870553,
      "grad_norm": 0.00520389573648572,
      "learning_rate": 9.867123874839264e-06,
      "loss": 0.0001,
      "step": 35460
    },
    {
      "epoch": 7.6018002571795975,
      "grad_norm": 0.0017759433249011636,
      "learning_rate": 9.864266323760538e-06,
      "loss": 0.0001,
      "step": 35470
    },
    {
      "epoch": 7.603943420488641,
      "grad_norm": 0.01860062964260578,
      "learning_rate": 9.861408772681812e-06,
      "loss": 0.0003,
      "step": 35480
    },
    {
      "epoch": 7.606086583797685,
      "grad_norm": 0.01826922781765461,
      "learning_rate": 9.858551221603087e-06,
      "loss": 0.0001,
      "step": 35490
    },
    {
      "epoch": 7.60822974710673,
      "grad_norm": 0.0005443010595627129,
      "learning_rate": 9.855693670524361e-06,
      "loss": 0.0001,
      "step": 35500
    },
    {
      "epoch": 7.610372910415774,
      "grad_norm": 0.007609757129102945,
      "learning_rate": 9.852836119445635e-06,
      "loss": 0.0006,
      "step": 35510
    },
    {
      "epoch": 7.612516073724818,
      "grad_norm": 0.0006372522911988199,
      "learning_rate": 9.849978568366911e-06,
      "loss": 0.2215,
      "step": 35520
    },
    {
      "epoch": 7.614659237033862,
      "grad_norm": 0.0012292694300413132,
      "learning_rate": 9.847121017288185e-06,
      "loss": 0.0001,
      "step": 35530
    },
    {
      "epoch": 7.616802400342906,
      "grad_norm": 0.002713010413572192,
      "learning_rate": 9.844263466209459e-06,
      "loss": 0.0001,
      "step": 35540
    },
    {
      "epoch": 7.61894556365195,
      "grad_norm": 0.0014821832301095128,
      "learning_rate": 9.841405915130734e-06,
      "loss": 0.2323,
      "step": 35550
    },
    {
      "epoch": 7.621088726960995,
      "grad_norm": 0.02108045667409897,
      "learning_rate": 9.838548364052008e-06,
      "loss": 0.0003,
      "step": 35560
    },
    {
      "epoch": 7.623231890270039,
      "grad_norm": 0.0009335161303170025,
      "learning_rate": 9.835690812973284e-06,
      "loss": 0.0001,
      "step": 35570
    },
    {
      "epoch": 7.6253750535790825,
      "grad_norm": 0.000828814459964633,
      "learning_rate": 9.832833261894558e-06,
      "loss": 0.0001,
      "step": 35580
    },
    {
      "epoch": 7.627518216888127,
      "grad_norm": 0.0008437296492047608,
      "learning_rate": 9.829975710815832e-06,
      "loss": 0.0002,
      "step": 35590
    },
    {
      "epoch": 7.629661380197171,
      "grad_norm": 23.06896209716797,
      "learning_rate": 9.827118159737106e-06,
      "loss": 0.1851,
      "step": 35600
    },
    {
      "epoch": 7.631804543506215,
      "grad_norm": 0.01295736525207758,
      "learning_rate": 9.82426060865838e-06,
      "loss": 0.0004,
      "step": 35610
    },
    {
      "epoch": 7.63394770681526,
      "grad_norm": 0.01407347060739994,
      "learning_rate": 9.821403057579655e-06,
      "loss": 0.0001,
      "step": 35620
    },
    {
      "epoch": 7.6360908701243035,
      "grad_norm": 0.0010001767659559846,
      "learning_rate": 9.818545506500929e-06,
      "loss": 0.0001,
      "step": 35630
    },
    {
      "epoch": 7.638234033433347,
      "grad_norm": 0.005236893426626921,
      "learning_rate": 9.815687955422205e-06,
      "loss": 0.0001,
      "step": 35640
    },
    {
      "epoch": 7.640377196742392,
      "grad_norm": 0.0012452549999579787,
      "learning_rate": 9.812830404343479e-06,
      "loss": 0.1272,
      "step": 35650
    },
    {
      "epoch": 7.642520360051436,
      "grad_norm": 0.000798695080447942,
      "learning_rate": 9.809972853264753e-06,
      "loss": 0.001,
      "step": 35660
    },
    {
      "epoch": 7.64466352336048,
      "grad_norm": 0.0008974371594376862,
      "learning_rate": 9.807115302186028e-06,
      "loss": 0.0004,
      "step": 35670
    },
    {
      "epoch": 7.646806686669525,
      "grad_norm": 0.005823906976729631,
      "learning_rate": 9.804257751107302e-06,
      "loss": 0.2537,
      "step": 35680
    },
    {
      "epoch": 7.648949849978568,
      "grad_norm": 0.0012584921205416322,
      "learning_rate": 9.801400200028576e-06,
      "loss": 0.0001,
      "step": 35690
    },
    {
      "epoch": 7.651093013287612,
      "grad_norm": 0.00678078131750226,
      "learning_rate": 9.79854264894985e-06,
      "loss": 0.0001,
      "step": 35700
    },
    {
      "epoch": 7.653236176596657,
      "grad_norm": 0.008589702658355236,
      "learning_rate": 9.795685097871126e-06,
      "loss": 0.0002,
      "step": 35710
    },
    {
      "epoch": 7.655379339905701,
      "grad_norm": 0.0018892933148890734,
      "learning_rate": 9.7928275467924e-06,
      "loss": 0.0002,
      "step": 35720
    },
    {
      "epoch": 7.657522503214745,
      "grad_norm": 0.0038533825427293777,
      "learning_rate": 9.789969995713674e-06,
      "loss": 0.0002,
      "step": 35730
    },
    {
      "epoch": 7.659665666523789,
      "grad_norm": 0.0046904725022614,
      "learning_rate": 9.787112444634949e-06,
      "loss": 0.0003,
      "step": 35740
    },
    {
      "epoch": 7.661808829832833,
      "grad_norm": 0.004016329534351826,
      "learning_rate": 9.784254893556223e-06,
      "loss": 0.153,
      "step": 35750
    },
    {
      "epoch": 7.663951993141877,
      "grad_norm": 0.0007696471293456852,
      "learning_rate": 9.781397342477497e-06,
      "loss": 0.0001,
      "step": 35760
    },
    {
      "epoch": 7.666095156450922,
      "grad_norm": 0.000687003368511796,
      "learning_rate": 9.778539791398773e-06,
      "loss": 0.0,
      "step": 35770
    },
    {
      "epoch": 7.668238319759966,
      "grad_norm": 0.0023461775854229927,
      "learning_rate": 9.775682240320047e-06,
      "loss": 0.0001,
      "step": 35780
    },
    {
      "epoch": 7.67038148306901,
      "grad_norm": 0.0017972394125536084,
      "learning_rate": 9.772824689241322e-06,
      "loss": 0.0,
      "step": 35790
    },
    {
      "epoch": 7.672524646378054,
      "grad_norm": 0.05447261035442352,
      "learning_rate": 9.769967138162596e-06,
      "loss": 0.0011,
      "step": 35800
    },
    {
      "epoch": 7.674667809687098,
      "grad_norm": 0.00033046805765479803,
      "learning_rate": 9.76710958708387e-06,
      "loss": 0.0003,
      "step": 35810
    },
    {
      "epoch": 7.676810972996142,
      "grad_norm": 0.0017523394199088216,
      "learning_rate": 9.764252036005144e-06,
      "loss": 0.0001,
      "step": 35820
    },
    {
      "epoch": 7.678954136305187,
      "grad_norm": 0.019618621096014977,
      "learning_rate": 9.761394484926418e-06,
      "loss": 0.1974,
      "step": 35830
    },
    {
      "epoch": 7.681097299614231,
      "grad_norm": 0.1737651377916336,
      "learning_rate": 9.758536933847693e-06,
      "loss": 0.0004,
      "step": 35840
    },
    {
      "epoch": 7.6832404629232744,
      "grad_norm": 0.004323077853769064,
      "learning_rate": 9.755679382768967e-06,
      "loss": 0.1636,
      "step": 35850
    },
    {
      "epoch": 7.685383626232319,
      "grad_norm": 0.00027751681045629084,
      "learning_rate": 9.752821831690243e-06,
      "loss": 0.1638,
      "step": 35860
    },
    {
      "epoch": 7.687526789541363,
      "grad_norm": 0.011724449694156647,
      "learning_rate": 9.749964280611517e-06,
      "loss": 0.1772,
      "step": 35870
    },
    {
      "epoch": 7.689669952850407,
      "grad_norm": 0.0014467600267380476,
      "learning_rate": 9.747106729532791e-06,
      "loss": 0.0001,
      "step": 35880
    },
    {
      "epoch": 7.691813116159452,
      "grad_norm": 0.0003061749448534101,
      "learning_rate": 9.744249178454067e-06,
      "loss": 0.0,
      "step": 35890
    },
    {
      "epoch": 7.6939562794684955,
      "grad_norm": 0.00022458424791693687,
      "learning_rate": 9.74139162737534e-06,
      "loss": 0.0001,
      "step": 35900
    },
    {
      "epoch": 7.696099442777539,
      "grad_norm": 0.0007212318596430123,
      "learning_rate": 9.738534076296614e-06,
      "loss": 0.0009,
      "step": 35910
    },
    {
      "epoch": 7.698242606086584,
      "grad_norm": 0.0022017103619873524,
      "learning_rate": 9.735676525217888e-06,
      "loss": 0.0013,
      "step": 35920
    },
    {
      "epoch": 7.700385769395628,
      "grad_norm": 0.0002405148115940392,
      "learning_rate": 9.732818974139164e-06,
      "loss": 0.0001,
      "step": 35930
    },
    {
      "epoch": 7.702528932704672,
      "grad_norm": 0.0004921257495880127,
      "learning_rate": 9.729961423060438e-06,
      "loss": 0.1441,
      "step": 35940
    },
    {
      "epoch": 7.7046720960137165,
      "grad_norm": 0.00035570794716477394,
      "learning_rate": 9.727103871981712e-06,
      "loss": 0.1039,
      "step": 35950
    },
    {
      "epoch": 7.70681525932276,
      "grad_norm": 0.00040777900721877813,
      "learning_rate": 9.724246320902987e-06,
      "loss": 0.0001,
      "step": 35960
    },
    {
      "epoch": 7.708958422631804,
      "grad_norm": 0.0002126385224983096,
      "learning_rate": 9.721388769824261e-06,
      "loss": 0.0005,
      "step": 35970
    },
    {
      "epoch": 7.711101585940849,
      "grad_norm": 0.00021670393471140414,
      "learning_rate": 9.718531218745535e-06,
      "loss": 0.1622,
      "step": 35980
    },
    {
      "epoch": 7.713244749249893,
      "grad_norm": 0.00028896157164126635,
      "learning_rate": 9.715673667666811e-06,
      "loss": 0.0001,
      "step": 35990
    },
    {
      "epoch": 7.715387912558937,
      "grad_norm": 0.0002402662648819387,
      "learning_rate": 9.712816116588085e-06,
      "loss": 0.0001,
      "step": 36000
    },
    {
      "epoch": 7.717531075867981,
      "grad_norm": 0.000522953865583986,
      "learning_rate": 9.70995856550936e-06,
      "loss": 0.0,
      "step": 36010
    },
    {
      "epoch": 7.719674239177025,
      "grad_norm": 0.00039211317198351026,
      "learning_rate": 9.707101014430633e-06,
      "loss": 0.4358,
      "step": 36020
    },
    {
      "epoch": 7.721817402486069,
      "grad_norm": 0.0006213276647031307,
      "learning_rate": 9.704243463351908e-06,
      "loss": 0.0004,
      "step": 36030
    },
    {
      "epoch": 7.723960565795114,
      "grad_norm": 0.00045038206735625863,
      "learning_rate": 9.701385912273182e-06,
      "loss": 0.0004,
      "step": 36040
    },
    {
      "epoch": 7.726103729104158,
      "grad_norm": 24.374679565429688,
      "learning_rate": 9.698528361194456e-06,
      "loss": 0.2215,
      "step": 36050
    },
    {
      "epoch": 7.7282468924132015,
      "grad_norm": 0.0007701577269472182,
      "learning_rate": 9.695670810115732e-06,
      "loss": 0.3581,
      "step": 36060
    },
    {
      "epoch": 7.730390055722246,
      "grad_norm": 0.2528904676437378,
      "learning_rate": 9.692813259037006e-06,
      "loss": 0.0008,
      "step": 36070
    },
    {
      "epoch": 7.73253321903129,
      "grad_norm": 0.001910430728457868,
      "learning_rate": 9.689955707958281e-06,
      "loss": 0.0002,
      "step": 36080
    },
    {
      "epoch": 7.734676382340334,
      "grad_norm": 0.009962525218725204,
      "learning_rate": 9.687098156879555e-06,
      "loss": 0.2095,
      "step": 36090
    },
    {
      "epoch": 7.736819545649379,
      "grad_norm": 0.008218152448534966,
      "learning_rate": 9.68424060580083e-06,
      "loss": 0.0025,
      "step": 36100
    },
    {
      "epoch": 7.7389627089584225,
      "grad_norm": 0.0011949408799409866,
      "learning_rate": 9.681383054722105e-06,
      "loss": 0.0012,
      "step": 36110
    },
    {
      "epoch": 7.741105872267466,
      "grad_norm": 0.00194427405949682,
      "learning_rate": 9.678525503643379e-06,
      "loss": 0.0015,
      "step": 36120
    },
    {
      "epoch": 7.743249035576511,
      "grad_norm": 0.023159237578511238,
      "learning_rate": 9.675667952564653e-06,
      "loss": 0.0001,
      "step": 36130
    },
    {
      "epoch": 7.745392198885555,
      "grad_norm": 0.00059705157764256,
      "learning_rate": 9.672810401485927e-06,
      "loss": 0.0001,
      "step": 36140
    },
    {
      "epoch": 7.747535362194599,
      "grad_norm": 0.005832348484545946,
      "learning_rate": 9.669952850407202e-06,
      "loss": 0.0001,
      "step": 36150
    },
    {
      "epoch": 7.7496785255036436,
      "grad_norm": 1.0081777572631836,
      "learning_rate": 9.667095299328476e-06,
      "loss": 0.0034,
      "step": 36160
    },
    {
      "epoch": 7.751821688812687,
      "grad_norm": 0.0005906750448048115,
      "learning_rate": 9.66423774824975e-06,
      "loss": 0.0001,
      "step": 36170
    },
    {
      "epoch": 7.753964852121731,
      "grad_norm": 0.015207340009510517,
      "learning_rate": 9.661380197171026e-06,
      "loss": 0.2165,
      "step": 36180
    },
    {
      "epoch": 7.756108015430776,
      "grad_norm": 0.010973487049341202,
      "learning_rate": 9.6585226460923e-06,
      "loss": 0.152,
      "step": 36190
    },
    {
      "epoch": 7.75825117873982,
      "grad_norm": 0.0338062159717083,
      "learning_rate": 9.655665095013575e-06,
      "loss": 0.0001,
      "step": 36200
    },
    {
      "epoch": 7.760394342048864,
      "grad_norm": 0.0026581345591694117,
      "learning_rate": 9.65280754393485e-06,
      "loss": 0.0009,
      "step": 36210
    },
    {
      "epoch": 7.762537505357908,
      "grad_norm": 0.00041483616223558784,
      "learning_rate": 9.649949992856123e-06,
      "loss": 0.0006,
      "step": 36220
    },
    {
      "epoch": 7.764680668666952,
      "grad_norm": 19.055309295654297,
      "learning_rate": 9.647092441777397e-06,
      "loss": 0.2904,
      "step": 36230
    },
    {
      "epoch": 7.766823831975996,
      "grad_norm": 0.21952754259109497,
      "learning_rate": 9.644234890698671e-06,
      "loss": 0.0014,
      "step": 36240
    },
    {
      "epoch": 7.768966995285041,
      "grad_norm": 0.006294482387602329,
      "learning_rate": 9.641377339619947e-06,
      "loss": 0.0005,
      "step": 36250
    },
    {
      "epoch": 7.771110158594085,
      "grad_norm": 0.024238212034106255,
      "learning_rate": 9.63851978854122e-06,
      "loss": 0.0001,
      "step": 36260
    },
    {
      "epoch": 7.773253321903129,
      "grad_norm": 0.00039955435204319656,
      "learning_rate": 9.635662237462496e-06,
      "loss": 0.0007,
      "step": 36270
    },
    {
      "epoch": 7.775396485212173,
      "grad_norm": 0.00036542685120366514,
      "learning_rate": 9.63280468638377e-06,
      "loss": 0.0,
      "step": 36280
    },
    {
      "epoch": 7.777539648521217,
      "grad_norm": 0.0004351166426204145,
      "learning_rate": 9.629947135305044e-06,
      "loss": 0.0,
      "step": 36290
    },
    {
      "epoch": 7.779682811830261,
      "grad_norm": 0.00243359780870378,
      "learning_rate": 9.62708958422632e-06,
      "loss": 0.0001,
      "step": 36300
    },
    {
      "epoch": 7.781825975139306,
      "grad_norm": 0.0006843737792223692,
      "learning_rate": 9.624232033147594e-06,
      "loss": 0.0003,
      "step": 36310
    },
    {
      "epoch": 7.78396913844835,
      "grad_norm": 0.00024892593501135707,
      "learning_rate": 9.621374482068867e-06,
      "loss": 0.0,
      "step": 36320
    },
    {
      "epoch": 7.786112301757393,
      "grad_norm": 0.018723834306001663,
      "learning_rate": 9.618516930990143e-06,
      "loss": 0.0001,
      "step": 36330
    },
    {
      "epoch": 7.788255465066438,
      "grad_norm": 0.00045967771438881755,
      "learning_rate": 9.615659379911417e-06,
      "loss": 0.0,
      "step": 36340
    },
    {
      "epoch": 7.790398628375482,
      "grad_norm": 17.560123443603516,
      "learning_rate": 9.612801828832691e-06,
      "loss": 0.1234,
      "step": 36350
    },
    {
      "epoch": 7.792541791684526,
      "grad_norm": 0.0045542968437075615,
      "learning_rate": 9.609944277753965e-06,
      "loss": 0.0002,
      "step": 36360
    },
    {
      "epoch": 7.794684954993571,
      "grad_norm": 0.0003407147596590221,
      "learning_rate": 9.60708672667524e-06,
      "loss": 0.0002,
      "step": 36370
    },
    {
      "epoch": 7.7968281183026145,
      "grad_norm": 0.0018534960690885782,
      "learning_rate": 9.604229175596514e-06,
      "loss": 0.0001,
      "step": 36380
    },
    {
      "epoch": 7.798971281611658,
      "grad_norm": 0.000816904881503433,
      "learning_rate": 9.601371624517788e-06,
      "loss": 0.0001,
      "step": 36390
    },
    {
      "epoch": 7.801114444920703,
      "grad_norm": 0.00034667988074943423,
      "learning_rate": 9.598514073439064e-06,
      "loss": 0.0,
      "step": 36400
    },
    {
      "epoch": 7.803257608229747,
      "grad_norm": 0.02747233584523201,
      "learning_rate": 9.595656522360338e-06,
      "loss": 0.1198,
      "step": 36410
    },
    {
      "epoch": 7.805400771538792,
      "grad_norm": 0.00021953506802674383,
      "learning_rate": 9.592798971281614e-06,
      "loss": 0.0,
      "step": 36420
    },
    {
      "epoch": 7.8075439348478355,
      "grad_norm": 26.413070678710938,
      "learning_rate": 9.589941420202887e-06,
      "loss": 0.2484,
      "step": 36430
    },
    {
      "epoch": 7.809687098156879,
      "grad_norm": 0.0007508401176892221,
      "learning_rate": 9.587083869124161e-06,
      "loss": 0.0,
      "step": 36440
    },
    {
      "epoch": 7.811830261465924,
      "grad_norm": 0.0036040933337062597,
      "learning_rate": 9.584226318045435e-06,
      "loss": 0.0,
      "step": 36450
    },
    {
      "epoch": 7.813973424774968,
      "grad_norm": 0.00037765121669508517,
      "learning_rate": 9.58136876696671e-06,
      "loss": 0.0011,
      "step": 36460
    },
    {
      "epoch": 7.816116588084012,
      "grad_norm": 0.004502506926655769,
      "learning_rate": 9.578511215887985e-06,
      "loss": 0.0003,
      "step": 36470
    },
    {
      "epoch": 7.8182597513930565,
      "grad_norm": 0.011574020609259605,
      "learning_rate": 9.575653664809259e-06,
      "loss": 0.0021,
      "step": 36480
    },
    {
      "epoch": 7.8204029147021,
      "grad_norm": 0.011120383627712727,
      "learning_rate": 9.572796113730534e-06,
      "loss": 0.0001,
      "step": 36490
    },
    {
      "epoch": 7.822546078011144,
      "grad_norm": 0.00026829473790712655,
      "learning_rate": 9.569938562651808e-06,
      "loss": 0.0,
      "step": 36500
    },
    {
      "epoch": 7.824689241320189,
      "grad_norm": 0.0029981527477502823,
      "learning_rate": 9.567081011573082e-06,
      "loss": 0.1265,
      "step": 36510
    },
    {
      "epoch": 7.826832404629233,
      "grad_norm": 0.00013359347940422595,
      "learning_rate": 9.564223460494358e-06,
      "loss": 0.16,
      "step": 36520
    },
    {
      "epoch": 7.828975567938277,
      "grad_norm": 0.003258125390857458,
      "learning_rate": 9.561365909415632e-06,
      "loss": 0.0,
      "step": 36530
    },
    {
      "epoch": 7.831118731247321,
      "grad_norm": 0.00016709165356587619,
      "learning_rate": 9.558508358336906e-06,
      "loss": 0.2203,
      "step": 36540
    },
    {
      "epoch": 7.833261894556365,
      "grad_norm": 0.0001835948642110452,
      "learning_rate": 9.555650807258181e-06,
      "loss": 0.1231,
      "step": 36550
    },
    {
      "epoch": 7.835405057865409,
      "grad_norm": 0.1701316088438034,
      "learning_rate": 9.552793256179455e-06,
      "loss": 0.0002,
      "step": 36560
    },
    {
      "epoch": 7.837548221174454,
      "grad_norm": 0.00252651353366673,
      "learning_rate": 9.54993570510073e-06,
      "loss": 0.0048,
      "step": 36570
    },
    {
      "epoch": 7.839691384483498,
      "grad_norm": 0.00039937306428328156,
      "learning_rate": 9.547078154022003e-06,
      "loss": 0.1648,
      "step": 36580
    },
    {
      "epoch": 7.8418345477925415,
      "grad_norm": 0.0003248665598221123,
      "learning_rate": 9.544220602943279e-06,
      "loss": 0.0,
      "step": 36590
    },
    {
      "epoch": 7.843977711101586,
      "grad_norm": 0.00028699400718323886,
      "learning_rate": 9.541363051864553e-06,
      "loss": 0.0,
      "step": 36600
    },
    {
      "epoch": 7.84612087441063,
      "grad_norm": 0.0003120681503787637,
      "learning_rate": 9.538505500785827e-06,
      "loss": 0.0021,
      "step": 36610
    },
    {
      "epoch": 7.848264037719674,
      "grad_norm": 0.0002978823322337121,
      "learning_rate": 9.535647949707102e-06,
      "loss": 0.0,
      "step": 36620
    },
    {
      "epoch": 7.850407201028719,
      "grad_norm": 0.001050709281116724,
      "learning_rate": 9.532790398628376e-06,
      "loss": 0.0012,
      "step": 36630
    },
    {
      "epoch": 7.8525503643377625,
      "grad_norm": 0.00023580777633469552,
      "learning_rate": 9.529932847549652e-06,
      "loss": 0.1875,
      "step": 36640
    },
    {
      "epoch": 7.854693527646806,
      "grad_norm": 0.0003575784794520587,
      "learning_rate": 9.527075296470926e-06,
      "loss": 0.0001,
      "step": 36650
    },
    {
      "epoch": 7.856836690955851,
      "grad_norm": 0.015946917235851288,
      "learning_rate": 9.5242177453922e-06,
      "loss": 0.0004,
      "step": 36660
    },
    {
      "epoch": 7.858979854264895,
      "grad_norm": 0.00011224096670048311,
      "learning_rate": 9.521360194313474e-06,
      "loss": 0.0001,
      "step": 36670
    },
    {
      "epoch": 7.861123017573939,
      "grad_norm": 0.00015797301603015512,
      "learning_rate": 9.518502643234748e-06,
      "loss": 0.12,
      "step": 36680
    },
    {
      "epoch": 7.863266180882984,
      "grad_norm": 0.0002623356122057885,
      "learning_rate": 9.515645092156023e-06,
      "loss": 0.1288,
      "step": 36690
    },
    {
      "epoch": 7.865409344192027,
      "grad_norm": 0.35326623916625977,
      "learning_rate": 9.512787541077297e-06,
      "loss": 0.0019,
      "step": 36700
    },
    {
      "epoch": 7.867552507501071,
      "grad_norm": 0.012590209022164345,
      "learning_rate": 9.509929989998573e-06,
      "loss": 0.0019,
      "step": 36710
    },
    {
      "epoch": 7.869695670810116,
      "grad_norm": 0.00040377836558036506,
      "learning_rate": 9.507072438919847e-06,
      "loss": 0.3052,
      "step": 36720
    },
    {
      "epoch": 7.87183883411916,
      "grad_norm": 0.0003651785373222083,
      "learning_rate": 9.50421488784112e-06,
      "loss": 0.1387,
      "step": 36730
    },
    {
      "epoch": 7.873981997428204,
      "grad_norm": 0.014647009782493114,
      "learning_rate": 9.501357336762396e-06,
      "loss": 0.2455,
      "step": 36740
    },
    {
      "epoch": 7.876125160737248,
      "grad_norm": 0.0011554867960512638,
      "learning_rate": 9.49849978568367e-06,
      "loss": 0.0001,
      "step": 36750
    },
    {
      "epoch": 7.878268324046292,
      "grad_norm": 0.4519391357898712,
      "learning_rate": 9.495642234604944e-06,
      "loss": 0.001,
      "step": 36760
    },
    {
      "epoch": 7.880411487355336,
      "grad_norm": 0.000706646591424942,
      "learning_rate": 9.492784683526218e-06,
      "loss": 0.0,
      "step": 36770
    },
    {
      "epoch": 7.882554650664381,
      "grad_norm": 0.00038760880124755204,
      "learning_rate": 9.489927132447494e-06,
      "loss": 0.0001,
      "step": 36780
    },
    {
      "epoch": 7.884697813973425,
      "grad_norm": 0.00034094235161319375,
      "learning_rate": 9.487069581368768e-06,
      "loss": 0.0012,
      "step": 36790
    },
    {
      "epoch": 7.886840977282469,
      "grad_norm": 0.00022993292077444494,
      "learning_rate": 9.484212030290041e-06,
      "loss": 0.0008,
      "step": 36800
    },
    {
      "epoch": 7.888984140591513,
      "grad_norm": 0.014911172911524773,
      "learning_rate": 9.481354479211317e-06,
      "loss": 0.1319,
      "step": 36810
    },
    {
      "epoch": 7.891127303900557,
      "grad_norm": 0.010820938274264336,
      "learning_rate": 9.478496928132591e-06,
      "loss": 0.0001,
      "step": 36820
    },
    {
      "epoch": 7.893270467209601,
      "grad_norm": 0.00036448126775212586,
      "learning_rate": 9.475639377053865e-06,
      "loss": 0.0001,
      "step": 36830
    },
    {
      "epoch": 7.895413630518646,
      "grad_norm": 0.00029632015503011644,
      "learning_rate": 9.47278182597514e-06,
      "loss": 0.0005,
      "step": 36840
    },
    {
      "epoch": 7.89755679382769,
      "grad_norm": 0.011904760263860226,
      "learning_rate": 9.469924274896414e-06,
      "loss": 0.1167,
      "step": 36850
    },
    {
      "epoch": 7.8996999571367335,
      "grad_norm": 0.0001671125937718898,
      "learning_rate": 9.46706672381769e-06,
      "loss": 0.0,
      "step": 36860
    },
    {
      "epoch": 7.901843120445778,
      "grad_norm": 0.0002739925403147936,
      "learning_rate": 9.464209172738964e-06,
      "loss": 0.1637,
      "step": 36870
    },
    {
      "epoch": 7.903986283754822,
      "grad_norm": 0.11611198633909225,
      "learning_rate": 9.461351621660238e-06,
      "loss": 0.0003,
      "step": 36880
    },
    {
      "epoch": 7.906129447063866,
      "grad_norm": 0.005810068920254707,
      "learning_rate": 9.458494070581512e-06,
      "loss": 0.0001,
      "step": 36890
    },
    {
      "epoch": 7.908272610372911,
      "grad_norm": 0.00016384302580263466,
      "learning_rate": 9.455636519502786e-06,
      "loss": 0.0011,
      "step": 36900
    },
    {
      "epoch": 7.9104157736819545,
      "grad_norm": 0.00019895560399163514,
      "learning_rate": 9.452778968424061e-06,
      "loss": 0.1184,
      "step": 36910
    },
    {
      "epoch": 7.912558936990998,
      "grad_norm": 0.007446770090609789,
      "learning_rate": 9.449921417345335e-06,
      "loss": 0.0002,
      "step": 36920
    },
    {
      "epoch": 7.914702100300043,
      "grad_norm": 0.00021934400137979537,
      "learning_rate": 9.447063866266611e-06,
      "loss": 0.0,
      "step": 36930
    },
    {
      "epoch": 7.916845263609087,
      "grad_norm": 0.0029504061676561832,
      "learning_rate": 9.444206315187885e-06,
      "loss": 0.145,
      "step": 36940
    },
    {
      "epoch": 7.918988426918132,
      "grad_norm": 0.0001908516715047881,
      "learning_rate": 9.441348764109159e-06,
      "loss": 0.0001,
      "step": 36950
    },
    {
      "epoch": 7.9211315902271755,
      "grad_norm": 0.004778072237968445,
      "learning_rate": 9.438491213030434e-06,
      "loss": 0.001,
      "step": 36960
    },
    {
      "epoch": 7.923274753536219,
      "grad_norm": 0.00022734029334969819,
      "learning_rate": 9.435633661951708e-06,
      "loss": 0.0,
      "step": 36970
    },
    {
      "epoch": 7.925417916845264,
      "grad_norm": 0.0001631425111554563,
      "learning_rate": 9.432776110872984e-06,
      "loss": 0.0001,
      "step": 36980
    },
    {
      "epoch": 7.927561080154308,
      "grad_norm": 0.0002449876628816128,
      "learning_rate": 9.429918559794256e-06,
      "loss": 0.0,
      "step": 36990
    },
    {
      "epoch": 7.929704243463352,
      "grad_norm": 0.017561232671141624,
      "learning_rate": 9.427061008715532e-06,
      "loss": 0.0,
      "step": 37000
    },
    {
      "epoch": 7.9318474067723965,
      "grad_norm": 0.0001516265474492684,
      "learning_rate": 9.424203457636806e-06,
      "loss": 0.0001,
      "step": 37010
    },
    {
      "epoch": 7.93399057008144,
      "grad_norm": 0.009579570032656193,
      "learning_rate": 9.42134590655808e-06,
      "loss": 0.1724,
      "step": 37020
    },
    {
      "epoch": 7.936133733390484,
      "grad_norm": 0.00025366098270751536,
      "learning_rate": 9.418488355479355e-06,
      "loss": 0.5035,
      "step": 37030
    },
    {
      "epoch": 7.938276896699529,
      "grad_norm": 0.000596549129113555,
      "learning_rate": 9.41563080440063e-06,
      "loss": 0.0,
      "step": 37040
    },
    {
      "epoch": 7.940420060008573,
      "grad_norm": 0.027838420122861862,
      "learning_rate": 9.412773253321905e-06,
      "loss": 0.0003,
      "step": 37050
    },
    {
      "epoch": 7.942563223317617,
      "grad_norm": 0.0009836136596277356,
      "learning_rate": 9.409915702243179e-06,
      "loss": 0.0007,
      "step": 37060
    },
    {
      "epoch": 7.944706386626661,
      "grad_norm": 0.0017435615882277489,
      "learning_rate": 9.407058151164453e-06,
      "loss": 0.0001,
      "step": 37070
    },
    {
      "epoch": 7.946849549935705,
      "grad_norm": 0.0006813215441070497,
      "learning_rate": 9.404200600085728e-06,
      "loss": 0.0,
      "step": 37080
    },
    {
      "epoch": 7.948992713244749,
      "grad_norm": 0.0008842757670208812,
      "learning_rate": 9.401343049007e-06,
      "loss": 0.0001,
      "step": 37090
    },
    {
      "epoch": 7.951135876553794,
      "grad_norm": 0.001120609580539167,
      "learning_rate": 9.398485497928276e-06,
      "loss": 0.0,
      "step": 37100
    },
    {
      "epoch": 7.953279039862838,
      "grad_norm": 0.000739353068638593,
      "learning_rate": 9.39562794684955e-06,
      "loss": 0.0,
      "step": 37110
    },
    {
      "epoch": 7.9554222031718815,
      "grad_norm": 0.003529664594680071,
      "learning_rate": 9.392770395770826e-06,
      "loss": 0.0,
      "step": 37120
    },
    {
      "epoch": 7.957565366480926,
      "grad_norm": 0.0006355810910463333,
      "learning_rate": 9.3899128446921e-06,
      "loss": 0.0003,
      "step": 37130
    },
    {
      "epoch": 7.95970852978997,
      "grad_norm": 0.0008327682735398412,
      "learning_rate": 9.387055293613374e-06,
      "loss": 0.0003,
      "step": 37140
    },
    {
      "epoch": 7.961851693099014,
      "grad_norm": 0.0005193137330934405,
      "learning_rate": 9.38419774253465e-06,
      "loss": 0.1391,
      "step": 37150
    },
    {
      "epoch": 7.963994856408059,
      "grad_norm": 0.0004327424103394151,
      "learning_rate": 9.381340191455923e-06,
      "loss": 0.0006,
      "step": 37160
    },
    {
      "epoch": 7.966138019717103,
      "grad_norm": 0.000503366463817656,
      "learning_rate": 9.378482640377197e-06,
      "loss": 0.0001,
      "step": 37170
    },
    {
      "epoch": 7.968281183026146,
      "grad_norm": 0.779112696647644,
      "learning_rate": 9.375625089298473e-06,
      "loss": 0.0003,
      "step": 37180
    },
    {
      "epoch": 7.970424346335191,
      "grad_norm": 0.00034711885382421315,
      "learning_rate": 9.372767538219747e-06,
      "loss": 0.0003,
      "step": 37190
    },
    {
      "epoch": 7.972567509644235,
      "grad_norm": 0.00030309209250845015,
      "learning_rate": 9.36990998714102e-06,
      "loss": 0.0003,
      "step": 37200
    },
    {
      "epoch": 7.974710672953279,
      "grad_norm": 0.0013608006993308663,
      "learning_rate": 9.367052436062295e-06,
      "loss": 0.3181,
      "step": 37210
    },
    {
      "epoch": 7.976853836262324,
      "grad_norm": 0.006194169633090496,
      "learning_rate": 9.36419488498357e-06,
      "loss": 0.2385,
      "step": 37220
    },
    {
      "epoch": 7.978996999571367,
      "grad_norm": 0.0022634598426520824,
      "learning_rate": 9.361337333904844e-06,
      "loss": 0.0002,
      "step": 37230
    },
    {
      "epoch": 7.981140162880411,
      "grad_norm": 0.006375124678015709,
      "learning_rate": 9.358479782826118e-06,
      "loss": 0.0003,
      "step": 37240
    },
    {
      "epoch": 7.983283326189456,
      "grad_norm": 0.0028013866394758224,
      "learning_rate": 9.355622231747394e-06,
      "loss": 0.0002,
      "step": 37250
    },
    {
      "epoch": 7.9854264894985,
      "grad_norm": 0.024863004684448242,
      "learning_rate": 9.352764680668668e-06,
      "loss": 0.0002,
      "step": 37260
    },
    {
      "epoch": 7.987569652807544,
      "grad_norm": 0.003668221877887845,
      "learning_rate": 9.349907129589943e-06,
      "loss": 0.0001,
      "step": 37270
    },
    {
      "epoch": 7.9897128161165885,
      "grad_norm": 0.02217167243361473,
      "learning_rate": 9.347049578511217e-06,
      "loss": 0.1076,
      "step": 37280
    },
    {
      "epoch": 7.991855979425632,
      "grad_norm": 0.0015220183413475752,
      "learning_rate": 9.344192027432491e-06,
      "loss": 0.0003,
      "step": 37290
    },
    {
      "epoch": 7.993999142734676,
      "grad_norm": 0.0034606594126671553,
      "learning_rate": 9.341334476353767e-06,
      "loss": 0.0001,
      "step": 37300
    },
    {
      "epoch": 7.996142306043721,
      "grad_norm": 0.001768795889802277,
      "learning_rate": 9.338476925275039e-06,
      "loss": 0.0001,
      "step": 37310
    },
    {
      "epoch": 7.998285469352765,
      "grad_norm": 0.004901467356830835,
      "learning_rate": 9.335619374196315e-06,
      "loss": 0.0001,
      "step": 37320
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.983,
      "eval_f1": 0.9131175468483815,
      "eval_loss": 0.09951972216367722,
      "eval_precision": 0.9337979094076655,
      "eval_recall": 0.8933333333333333,
      "eval_runtime": 396.7252,
      "eval_samples_per_second": 7.562,
      "eval_steps_per_second": 2.521,
      "step": 37328
    },
    {
      "epoch": 8.000428632661809,
      "grad_norm": 0.0033635327126830816,
      "learning_rate": 9.332761823117588e-06,
      "loss": 0.0182,
      "step": 37330
    },
    {
      "epoch": 8.002571795970853,
      "grad_norm": 0.0032989869359880686,
      "learning_rate": 9.329904272038864e-06,
      "loss": 0.0005,
      "step": 37340
    },
    {
      "epoch": 8.004714959279896,
      "grad_norm": 0.001235787058249116,
      "learning_rate": 9.327046720960138e-06,
      "loss": 0.0005,
      "step": 37350
    },
    {
      "epoch": 8.006858122588941,
      "grad_norm": 0.004867230076342821,
      "learning_rate": 9.324189169881412e-06,
      "loss": 0.2716,
      "step": 37360
    },
    {
      "epoch": 8.009001285897986,
      "grad_norm": 0.00783799309283495,
      "learning_rate": 9.321331618802688e-06,
      "loss": 0.0928,
      "step": 37370
    },
    {
      "epoch": 8.011144449207029,
      "grad_norm": 0.6893308162689209,
      "learning_rate": 9.318474067723961e-06,
      "loss": 0.0002,
      "step": 37380
    },
    {
      "epoch": 8.013287612516073,
      "grad_norm": 0.001038110232912004,
      "learning_rate": 9.315616516645235e-06,
      "loss": 0.0002,
      "step": 37390
    },
    {
      "epoch": 8.015430775825118,
      "grad_norm": 0.0012733899056911469,
      "learning_rate": 9.312758965566511e-06,
      "loss": 0.0007,
      "step": 37400
    },
    {
      "epoch": 8.017573939134161,
      "grad_norm": 0.0007668343023397028,
      "learning_rate": 9.309901414487785e-06,
      "loss": 0.0733,
      "step": 37410
    },
    {
      "epoch": 8.019717102443206,
      "grad_norm": 0.0006293614278547466,
      "learning_rate": 9.307043863409059e-06,
      "loss": 0.1942,
      "step": 37420
    },
    {
      "epoch": 8.02186026575225,
      "grad_norm": 0.0032278152648359537,
      "learning_rate": 9.304186312330333e-06,
      "loss": 0.0001,
      "step": 37430
    },
    {
      "epoch": 8.024003429061294,
      "grad_norm": 0.0018925125477835536,
      "learning_rate": 9.301328761251608e-06,
      "loss": 0.0,
      "step": 37440
    },
    {
      "epoch": 8.026146592370338,
      "grad_norm": 0.004728145897388458,
      "learning_rate": 9.298471210172882e-06,
      "loss": 0.0686,
      "step": 37450
    },
    {
      "epoch": 8.028289755679383,
      "grad_norm": 0.0009710236918181181,
      "learning_rate": 9.295613659094156e-06,
      "loss": 0.0051,
      "step": 37460
    },
    {
      "epoch": 8.030432918988426,
      "grad_norm": 0.003766540205106139,
      "learning_rate": 9.292756108015432e-06,
      "loss": 0.0001,
      "step": 37470
    },
    {
      "epoch": 8.03257608229747,
      "grad_norm": 0.0009759018430486321,
      "learning_rate": 9.289898556936706e-06,
      "loss": 0.0001,
      "step": 37480
    },
    {
      "epoch": 8.034719245606516,
      "grad_norm": 0.009848498739302158,
      "learning_rate": 9.287041005857981e-06,
      "loss": 0.0061,
      "step": 37490
    },
    {
      "epoch": 8.03686240891556,
      "grad_norm": 0.0008638628642074764,
      "learning_rate": 9.284183454779255e-06,
      "loss": 0.0,
      "step": 37500
    },
    {
      "epoch": 8.039005572224603,
      "grad_norm": 0.005069266073405743,
      "learning_rate": 9.28132590370053e-06,
      "loss": 0.0,
      "step": 37510
    },
    {
      "epoch": 8.041148735533648,
      "grad_norm": 0.0006271607708185911,
      "learning_rate": 9.278468352621803e-06,
      "loss": 0.0049,
      "step": 37520
    },
    {
      "epoch": 8.043291898842693,
      "grad_norm": 0.0034356804098933935,
      "learning_rate": 9.275610801543077e-06,
      "loss": 0.0,
      "step": 37530
    },
    {
      "epoch": 8.045435062151736,
      "grad_norm": 0.0005792172742076218,
      "learning_rate": 9.272753250464353e-06,
      "loss": 0.0,
      "step": 37540
    },
    {
      "epoch": 8.04757822546078,
      "grad_norm": 0.0015601345803588629,
      "learning_rate": 9.269895699385627e-06,
      "loss": 0.0,
      "step": 37550
    },
    {
      "epoch": 8.049721388769825,
      "grad_norm": 0.001402402063831687,
      "learning_rate": 9.267038148306902e-06,
      "loss": 0.0907,
      "step": 37560
    },
    {
      "epoch": 8.051864552078868,
      "grad_norm": 0.0007522936211898923,
      "learning_rate": 9.264180597228176e-06,
      "loss": 0.0002,
      "step": 37570
    },
    {
      "epoch": 8.054007715387913,
      "grad_norm": 1.7476415634155273,
      "learning_rate": 9.26132304614945e-06,
      "loss": 0.0079,
      "step": 37580
    },
    {
      "epoch": 8.056150878696958,
      "grad_norm": 0.0016659513348713517,
      "learning_rate": 9.258465495070726e-06,
      "loss": 0.0,
      "step": 37590
    },
    {
      "epoch": 8.058294042006,
      "grad_norm": 0.0016144190449267626,
      "learning_rate": 9.255607943992e-06,
      "loss": 0.0,
      "step": 37600
    },
    {
      "epoch": 8.060437205315045,
      "grad_norm": 0.00036715096211992204,
      "learning_rate": 9.252750392913274e-06,
      "loss": 0.0,
      "step": 37610
    },
    {
      "epoch": 8.06258036862409,
      "grad_norm": 0.0009364098659716547,
      "learning_rate": 9.24989284183455e-06,
      "loss": 0.0,
      "step": 37620
    },
    {
      "epoch": 8.064723531933133,
      "grad_norm": 0.0027519152499735355,
      "learning_rate": 9.247035290755823e-06,
      "loss": 0.0,
      "step": 37630
    },
    {
      "epoch": 8.066866695242178,
      "grad_norm": 0.0002939582336694002,
      "learning_rate": 9.244177739677097e-06,
      "loss": 0.0,
      "step": 37640
    },
    {
      "epoch": 8.069009858551222,
      "grad_norm": 0.001115672173909843,
      "learning_rate": 9.241320188598371e-06,
      "loss": 0.0928,
      "step": 37650
    },
    {
      "epoch": 8.071153021860265,
      "grad_norm": 0.0006584947695955634,
      "learning_rate": 9.238462637519647e-06,
      "loss": 0.0,
      "step": 37660
    },
    {
      "epoch": 8.07329618516931,
      "grad_norm": 0.0006129178800620139,
      "learning_rate": 9.23560508644092e-06,
      "loss": 0.0,
      "step": 37670
    },
    {
      "epoch": 8.075439348478355,
      "grad_norm": 0.00020782934734597802,
      "learning_rate": 9.232747535362195e-06,
      "loss": 0.0003,
      "step": 37680
    },
    {
      "epoch": 8.077582511787398,
      "grad_norm": 0.0003884474281221628,
      "learning_rate": 9.22988998428347e-06,
      "loss": 0.0,
      "step": 37690
    },
    {
      "epoch": 8.079725675096443,
      "grad_norm": 0.0004309966752771288,
      "learning_rate": 9.227032433204744e-06,
      "loss": 0.1964,
      "step": 37700
    },
    {
      "epoch": 8.081868838405487,
      "grad_norm": 2.527768611907959,
      "learning_rate": 9.22417488212602e-06,
      "loss": 0.0014,
      "step": 37710
    },
    {
      "epoch": 8.08401200171453,
      "grad_norm": 251.8744354248047,
      "learning_rate": 9.221317331047294e-06,
      "loss": 0.0606,
      "step": 37720
    },
    {
      "epoch": 8.086155165023575,
      "grad_norm": 0.00036383126280270517,
      "learning_rate": 9.218459779968568e-06,
      "loss": 0.0,
      "step": 37730
    },
    {
      "epoch": 8.08829832833262,
      "grad_norm": 0.0008703439380042255,
      "learning_rate": 9.215602228889842e-06,
      "loss": 0.0,
      "step": 37740
    },
    {
      "epoch": 8.090441491641663,
      "grad_norm": 0.22487178444862366,
      "learning_rate": 9.212744677811115e-06,
      "loss": 0.0003,
      "step": 37750
    },
    {
      "epoch": 8.092584654950707,
      "grad_norm": 0.00030326851992867887,
      "learning_rate": 9.209887126732391e-06,
      "loss": 0.0,
      "step": 37760
    },
    {
      "epoch": 8.094727818259752,
      "grad_norm": 0.0012120422907173634,
      "learning_rate": 9.207029575653665e-06,
      "loss": 0.0,
      "step": 37770
    },
    {
      "epoch": 8.096870981568795,
      "grad_norm": 0.0008657802827656269,
      "learning_rate": 9.20417202457494e-06,
      "loss": 0.1282,
      "step": 37780
    },
    {
      "epoch": 8.09901414487784,
      "grad_norm": 0.0006214405293576419,
      "learning_rate": 9.201314473496215e-06,
      "loss": 0.0,
      "step": 37790
    },
    {
      "epoch": 8.101157308186885,
      "grad_norm": 0.002779998118057847,
      "learning_rate": 9.198456922417488e-06,
      "loss": 0.0,
      "step": 37800
    },
    {
      "epoch": 8.103300471495928,
      "grad_norm": 0.000996734481304884,
      "learning_rate": 9.195599371338764e-06,
      "loss": 0.0,
      "step": 37810
    },
    {
      "epoch": 8.105443634804972,
      "grad_norm": 0.0002810241130646318,
      "learning_rate": 9.192741820260038e-06,
      "loss": 0.0,
      "step": 37820
    },
    {
      "epoch": 8.107586798114017,
      "grad_norm": 0.013372404500842094,
      "learning_rate": 9.189884269181314e-06,
      "loss": 0.0,
      "step": 37830
    },
    {
      "epoch": 8.10972996142306,
      "grad_norm": 32.3569221496582,
      "learning_rate": 9.187026718102586e-06,
      "loss": 0.1571,
      "step": 37840
    },
    {
      "epoch": 8.111873124732105,
      "grad_norm": 16.76882553100586,
      "learning_rate": 9.184169167023862e-06,
      "loss": 0.0921,
      "step": 37850
    },
    {
      "epoch": 8.11401628804115,
      "grad_norm": 0.0007722857990302145,
      "learning_rate": 9.181311615945135e-06,
      "loss": 0.0602,
      "step": 37860
    },
    {
      "epoch": 8.116159451350192,
      "grad_norm": 0.03743990138173103,
      "learning_rate": 9.17845406486641e-06,
      "loss": 0.0001,
      "step": 37870
    },
    {
      "epoch": 8.118302614659237,
      "grad_norm": 0.0035839180927723646,
      "learning_rate": 9.175596513787685e-06,
      "loss": 0.0,
      "step": 37880
    },
    {
      "epoch": 8.120445777968282,
      "grad_norm": 0.0002202430769102648,
      "learning_rate": 9.172738962708959e-06,
      "loss": 0.0,
      "step": 37890
    },
    {
      "epoch": 8.122588941277325,
      "grad_norm": 0.0005298685864545405,
      "learning_rate": 9.169881411630235e-06,
      "loss": 0.0,
      "step": 37900
    },
    {
      "epoch": 8.12473210458637,
      "grad_norm": 0.0006202858639881015,
      "learning_rate": 9.167023860551508e-06,
      "loss": 0.0008,
      "step": 37910
    },
    {
      "epoch": 8.126875267895414,
      "grad_norm": 0.0028083189390599728,
      "learning_rate": 9.164166309472782e-06,
      "loss": 0.0333,
      "step": 37920
    },
    {
      "epoch": 8.129018431204457,
      "grad_norm": 0.00016909051919355989,
      "learning_rate": 9.161308758394058e-06,
      "loss": 0.0,
      "step": 37930
    },
    {
      "epoch": 8.131161594513502,
      "grad_norm": 0.00017176952678710222,
      "learning_rate": 9.158451207315332e-06,
      "loss": 0.0,
      "step": 37940
    },
    {
      "epoch": 8.133304757822547,
      "grad_norm": 0.0014140247367322445,
      "learning_rate": 9.155593656236606e-06,
      "loss": 0.0,
      "step": 37950
    },
    {
      "epoch": 8.13544792113159,
      "grad_norm": 0.0002069603797281161,
      "learning_rate": 9.15273610515788e-06,
      "loss": 0.0741,
      "step": 37960
    },
    {
      "epoch": 8.137591084440635,
      "grad_norm": 0.00043451975216157734,
      "learning_rate": 9.149878554079155e-06,
      "loss": 0.0277,
      "step": 37970
    },
    {
      "epoch": 8.13973424774968,
      "grad_norm": 0.00014548074977938086,
      "learning_rate": 9.14702100300043e-06,
      "loss": 0.0,
      "step": 37980
    },
    {
      "epoch": 8.141877411058722,
      "grad_norm": 0.0002117809490300715,
      "learning_rate": 9.144163451921703e-06,
      "loss": 0.0,
      "step": 37990
    },
    {
      "epoch": 8.144020574367767,
      "grad_norm": 0.0002513265353627503,
      "learning_rate": 9.141305900842979e-06,
      "loss": 0.0,
      "step": 38000
    },
    {
      "epoch": 8.146163737676812,
      "grad_norm": 0.00019128700660075992,
      "learning_rate": 9.138448349764253e-06,
      "loss": 0.0,
      "step": 38010
    },
    {
      "epoch": 8.148306900985855,
      "grad_norm": 0.007143302820622921,
      "learning_rate": 9.135590798685527e-06,
      "loss": 0.1299,
      "step": 38020
    },
    {
      "epoch": 8.1504500642949,
      "grad_norm": 0.00021841963462065905,
      "learning_rate": 9.132733247606802e-06,
      "loss": 0.0,
      "step": 38030
    },
    {
      "epoch": 8.152593227603944,
      "grad_norm": 0.0015116601716727018,
      "learning_rate": 9.129875696528076e-06,
      "loss": 0.0164,
      "step": 38040
    },
    {
      "epoch": 8.154736390912987,
      "grad_norm": 0.00048545634490437806,
      "learning_rate": 9.127018145449352e-06,
      "loss": 0.0314,
      "step": 38050
    },
    {
      "epoch": 8.156879554222032,
      "grad_norm": 0.00044938098290003836,
      "learning_rate": 9.124160594370624e-06,
      "loss": 0.0,
      "step": 38060
    },
    {
      "epoch": 8.159022717531077,
      "grad_norm": 0.000687412335537374,
      "learning_rate": 9.1213030432919e-06,
      "loss": 0.0,
      "step": 38070
    },
    {
      "epoch": 8.16116588084012,
      "grad_norm": 0.000295123114483431,
      "learning_rate": 9.118445492213174e-06,
      "loss": 0.0,
      "step": 38080
    },
    {
      "epoch": 8.163309044149164,
      "grad_norm": 0.0001530710724182427,
      "learning_rate": 9.115587941134448e-06,
      "loss": 0.0095,
      "step": 38090
    },
    {
      "epoch": 8.165452207458209,
      "grad_norm": 0.00023604382295161486,
      "learning_rate": 9.112730390055723e-06,
      "loss": 0.2403,
      "step": 38100
    },
    {
      "epoch": 8.167595370767252,
      "grad_norm": 0.0001933975436259061,
      "learning_rate": 9.109872838976997e-06,
      "loss": 0.0,
      "step": 38110
    },
    {
      "epoch": 8.169738534076297,
      "grad_norm": 0.00020094861974939704,
      "learning_rate": 9.107015287898273e-06,
      "loss": 0.3422,
      "step": 38120
    },
    {
      "epoch": 8.171881697385341,
      "grad_norm": 0.001285429229028523,
      "learning_rate": 9.104157736819547e-06,
      "loss": 0.0086,
      "step": 38130
    },
    {
      "epoch": 8.174024860694384,
      "grad_norm": 0.00024118632427416742,
      "learning_rate": 9.10130018574082e-06,
      "loss": 0.0293,
      "step": 38140
    },
    {
      "epoch": 8.17616802400343,
      "grad_norm": 0.000251307908911258,
      "learning_rate": 9.098442634662096e-06,
      "loss": 0.0003,
      "step": 38150
    },
    {
      "epoch": 8.178311187312474,
      "grad_norm": 9.983686322811991e-05,
      "learning_rate": 9.09558508358337e-06,
      "loss": 0.0,
      "step": 38160
    },
    {
      "epoch": 8.180454350621517,
      "grad_norm": 0.00014894748164806515,
      "learning_rate": 9.092727532504644e-06,
      "loss": 0.0001,
      "step": 38170
    },
    {
      "epoch": 8.182597513930562,
      "grad_norm": 0.0004112176247872412,
      "learning_rate": 9.089869981425918e-06,
      "loss": 0.0001,
      "step": 38180
    },
    {
      "epoch": 8.184740677239606,
      "grad_norm": 0.01351928897202015,
      "learning_rate": 9.087012430347194e-06,
      "loss": 0.0169,
      "step": 38190
    },
    {
      "epoch": 8.18688384054865,
      "grad_norm": 0.005671633407473564,
      "learning_rate": 9.084154879268468e-06,
      "loss": 0.0,
      "step": 38200
    },
    {
      "epoch": 8.189027003857694,
      "grad_norm": 0.0006063374457880855,
      "learning_rate": 9.081297328189742e-06,
      "loss": 0.0001,
      "step": 38210
    },
    {
      "epoch": 8.191170167166739,
      "grad_norm": 0.00026786583475768566,
      "learning_rate": 9.078439777111017e-06,
      "loss": 0.0,
      "step": 38220
    },
    {
      "epoch": 8.193313330475782,
      "grad_norm": 0.00011769236880354583,
      "learning_rate": 9.075582226032291e-06,
      "loss": 0.0003,
      "step": 38230
    },
    {
      "epoch": 8.195456493784826,
      "grad_norm": 0.00013837296864949167,
      "learning_rate": 9.072724674953565e-06,
      "loss": 0.0,
      "step": 38240
    },
    {
      "epoch": 8.197599657093871,
      "grad_norm": 9.821039566304535e-05,
      "learning_rate": 9.06986712387484e-06,
      "loss": 0.0,
      "step": 38250
    },
    {
      "epoch": 8.199742820402914,
      "grad_norm": 0.002769234823063016,
      "learning_rate": 9.067009572796115e-06,
      "loss": 0.0,
      "step": 38260
    },
    {
      "epoch": 8.201885983711959,
      "grad_norm": 0.00012076383427483961,
      "learning_rate": 9.064152021717389e-06,
      "loss": 0.0,
      "step": 38270
    },
    {
      "epoch": 8.204029147021004,
      "grad_norm": 6.279243825701997e-05,
      "learning_rate": 9.061294470638662e-06,
      "loss": 0.0008,
      "step": 38280
    },
    {
      "epoch": 8.206172310330047,
      "grad_norm": 0.00010332225065212697,
      "learning_rate": 9.058436919559938e-06,
      "loss": 0.0,
      "step": 38290
    },
    {
      "epoch": 8.208315473639091,
      "grad_norm": 0.0060455636121332645,
      "learning_rate": 9.055579368481212e-06,
      "loss": 0.2779,
      "step": 38300
    },
    {
      "epoch": 8.210458636948136,
      "grad_norm": 0.006107810884714127,
      "learning_rate": 9.052721817402486e-06,
      "loss": 0.0,
      "step": 38310
    },
    {
      "epoch": 8.212601800257179,
      "grad_norm": 0.0005479835672304034,
      "learning_rate": 9.049864266323762e-06,
      "loss": 0.0,
      "step": 38320
    },
    {
      "epoch": 8.214744963566224,
      "grad_norm": 0.0043710339814424515,
      "learning_rate": 9.047006715245035e-06,
      "loss": 0.0294,
      "step": 38330
    },
    {
      "epoch": 8.216888126875268,
      "grad_norm": 0.0002115159877575934,
      "learning_rate": 9.044149164166311e-06,
      "loss": 0.0,
      "step": 38340
    },
    {
      "epoch": 8.219031290184311,
      "grad_norm": 0.000283989094896242,
      "learning_rate": 9.041291613087585e-06,
      "loss": 0.2196,
      "step": 38350
    },
    {
      "epoch": 8.221174453493356,
      "grad_norm": 0.00017783402290660888,
      "learning_rate": 9.038434062008859e-06,
      "loss": 0.0,
      "step": 38360
    },
    {
      "epoch": 8.223317616802401,
      "grad_norm": 0.00022334755340125412,
      "learning_rate": 9.035576510930135e-06,
      "loss": 0.0,
      "step": 38370
    },
    {
      "epoch": 8.225460780111444,
      "grad_norm": 904.0211791992188,
      "learning_rate": 9.032718959851407e-06,
      "loss": 0.1402,
      "step": 38380
    },
    {
      "epoch": 8.227603943420489,
      "grad_norm": 0.00017772636783774942,
      "learning_rate": 9.029861408772682e-06,
      "loss": 0.0013,
      "step": 38390
    },
    {
      "epoch": 8.229747106729533,
      "grad_norm": 0.004952752497047186,
      "learning_rate": 9.027003857693956e-06,
      "loss": 0.54,
      "step": 38400
    },
    {
      "epoch": 8.231890270038576,
      "grad_norm": 0.004028713796287775,
      "learning_rate": 9.024146306615232e-06,
      "loss": 0.0716,
      "step": 38410
    },
    {
      "epoch": 8.234033433347621,
      "grad_norm": 0.001298237475566566,
      "learning_rate": 9.021288755536506e-06,
      "loss": 0.204,
      "step": 38420
    },
    {
      "epoch": 8.236176596656666,
      "grad_norm": 0.0014425083063542843,
      "learning_rate": 9.01843120445778e-06,
      "loss": 0.0001,
      "step": 38430
    },
    {
      "epoch": 8.238319759965709,
      "grad_norm": 0.0006399342091754079,
      "learning_rate": 9.015573653379055e-06,
      "loss": 0.1158,
      "step": 38440
    },
    {
      "epoch": 8.240462923274753,
      "grad_norm": 0.014970442280173302,
      "learning_rate": 9.01271610230033e-06,
      "loss": 0.0001,
      "step": 38450
    },
    {
      "epoch": 8.242606086583798,
      "grad_norm": 0.005762125831097364,
      "learning_rate": 9.009858551221603e-06,
      "loss": 0.0001,
      "step": 38460
    },
    {
      "epoch": 8.244749249892841,
      "grad_norm": 0.0009225332178175449,
      "learning_rate": 9.007001000142879e-06,
      "loss": 0.0001,
      "step": 38470
    },
    {
      "epoch": 8.246892413201886,
      "grad_norm": 0.0018508137436583638,
      "learning_rate": 9.004143449064153e-06,
      "loss": 0.0009,
      "step": 38480
    },
    {
      "epoch": 8.24903557651093,
      "grad_norm": 0.0004759731236845255,
      "learning_rate": 9.001285897985427e-06,
      "loss": 0.0,
      "step": 38490
    },
    {
      "epoch": 8.251178739819974,
      "grad_norm": 0.0025749646592885256,
      "learning_rate": 8.9984283469067e-06,
      "loss": 0.0001,
      "step": 38500
    },
    {
      "epoch": 8.253321903129018,
      "grad_norm": 0.0007591299363411963,
      "learning_rate": 8.995570795827976e-06,
      "loss": 0.0,
      "step": 38510
    },
    {
      "epoch": 8.255465066438063,
      "grad_norm": 0.0010982658714056015,
      "learning_rate": 8.99271324474925e-06,
      "loss": 0.0001,
      "step": 38520
    },
    {
      "epoch": 8.257608229747106,
      "grad_norm": 0.020208006724715233,
      "learning_rate": 8.989855693670524e-06,
      "loss": 0.0002,
      "step": 38530
    },
    {
      "epoch": 8.25975139305615,
      "grad_norm": 0.003770418232306838,
      "learning_rate": 8.9869981425918e-06,
      "loss": 0.0001,
      "step": 38540
    },
    {
      "epoch": 8.261894556365196,
      "grad_norm": 0.0057701109908521175,
      "learning_rate": 8.984140591513074e-06,
      "loss": 0.0,
      "step": 38550
    },
    {
      "epoch": 8.264037719674239,
      "grad_norm": 0.00023282907204702497,
      "learning_rate": 8.98128304043435e-06,
      "loss": 0.0,
      "step": 38560
    },
    {
      "epoch": 8.266180882983283,
      "grad_norm": 0.00029845439712516963,
      "learning_rate": 8.978425489355623e-06,
      "loss": 0.0014,
      "step": 38570
    },
    {
      "epoch": 8.268324046292328,
      "grad_norm": 0.001851333538070321,
      "learning_rate": 8.975567938276897e-06,
      "loss": 0.0,
      "step": 38580
    },
    {
      "epoch": 8.270467209601371,
      "grad_norm": 0.00030484955641441047,
      "learning_rate": 8.972710387198173e-06,
      "loss": 0.0,
      "step": 38590
    },
    {
      "epoch": 8.272610372910416,
      "grad_norm": 77.03535461425781,
      "learning_rate": 8.969852836119445e-06,
      "loss": 0.2693,
      "step": 38600
    },
    {
      "epoch": 8.27475353621946,
      "grad_norm": 0.00028118464979343116,
      "learning_rate": 8.96699528504072e-06,
      "loss": 0.0651,
      "step": 38610
    },
    {
      "epoch": 8.276896699528503,
      "grad_norm": 0.00019887702364940196,
      "learning_rate": 8.964137733961995e-06,
      "loss": 0.0,
      "step": 38620
    },
    {
      "epoch": 8.279039862837548,
      "grad_norm": 0.00025444035418331623,
      "learning_rate": 8.96128018288327e-06,
      "loss": 0.0002,
      "step": 38630
    },
    {
      "epoch": 8.281183026146593,
      "grad_norm": 0.0148211270570755,
      "learning_rate": 8.958422631804544e-06,
      "loss": 0.0001,
      "step": 38640
    },
    {
      "epoch": 8.283326189455636,
      "grad_norm": 0.00030262485961429775,
      "learning_rate": 8.955565080725818e-06,
      "loss": 0.0,
      "step": 38650
    },
    {
      "epoch": 8.28546935276468,
      "grad_norm": 0.00028878540615551174,
      "learning_rate": 8.952707529647094e-06,
      "loss": 0.0,
      "step": 38660
    },
    {
      "epoch": 8.287612516073725,
      "grad_norm": 0.0002007385337492451,
      "learning_rate": 8.949849978568368e-06,
      "loss": 0.1088,
      "step": 38670
    },
    {
      "epoch": 8.289755679382768,
      "grad_norm": 0.00013703701552003622,
      "learning_rate": 8.946992427489643e-06,
      "loss": 0.0001,
      "step": 38680
    },
    {
      "epoch": 8.291898842691813,
      "grad_norm": 0.0004535118059720844,
      "learning_rate": 8.944134876410917e-06,
      "loss": 0.0001,
      "step": 38690
    },
    {
      "epoch": 8.294042006000858,
      "grad_norm": 0.0005525436135940254,
      "learning_rate": 8.941277325332191e-06,
      "loss": 0.4214,
      "step": 38700
    },
    {
      "epoch": 8.2961851693099,
      "grad_norm": 0.003304998856037855,
      "learning_rate": 8.938419774253465e-06,
      "loss": 0.0002,
      "step": 38710
    },
    {
      "epoch": 8.298328332618945,
      "grad_norm": 0.027983497828245163,
      "learning_rate": 8.935562223174739e-06,
      "loss": 0.0003,
      "step": 38720
    },
    {
      "epoch": 8.30047149592799,
      "grad_norm": 0.000625645974650979,
      "learning_rate": 8.932704672096015e-06,
      "loss": 0.0002,
      "step": 38730
    },
    {
      "epoch": 8.302614659237033,
      "grad_norm": 0.0010601273970678449,
      "learning_rate": 8.929847121017289e-06,
      "loss": 0.0001,
      "step": 38740
    },
    {
      "epoch": 8.304757822546078,
      "grad_norm": 0.003210386261343956,
      "learning_rate": 8.926989569938564e-06,
      "loss": 0.0004,
      "step": 38750
    },
    {
      "epoch": 8.306900985855123,
      "grad_norm": 0.0015517477877438068,
      "learning_rate": 8.924132018859838e-06,
      "loss": 0.0003,
      "step": 38760
    },
    {
      "epoch": 8.309044149164166,
      "grad_norm": 0.0003349824692122638,
      "learning_rate": 8.921274467781112e-06,
      "loss": 0.0004,
      "step": 38770
    },
    {
      "epoch": 8.31118731247321,
      "grad_norm": 0.0018653301522135735,
      "learning_rate": 8.918416916702388e-06,
      "loss": 0.0,
      "step": 38780
    },
    {
      "epoch": 8.313330475782255,
      "grad_norm": 0.0003098980232607573,
      "learning_rate": 8.915559365623662e-06,
      "loss": 0.0002,
      "step": 38790
    },
    {
      "epoch": 8.315473639091298,
      "grad_norm": 0.003725970396772027,
      "learning_rate": 8.912701814544936e-06,
      "loss": 0.0,
      "step": 38800
    },
    {
      "epoch": 8.317616802400343,
      "grad_norm": 0.0015820780536159873,
      "learning_rate": 8.90984426346621e-06,
      "loss": 0.0001,
      "step": 38810
    },
    {
      "epoch": 8.319759965709387,
      "grad_norm": 0.0024215495213866234,
      "learning_rate": 8.906986712387485e-06,
      "loss": 0.0028,
      "step": 38820
    },
    {
      "epoch": 8.32190312901843,
      "grad_norm": 0.00015386143059004098,
      "learning_rate": 8.904129161308759e-06,
      "loss": 0.1452,
      "step": 38830
    },
    {
      "epoch": 8.324046292327475,
      "grad_norm": 0.001050157705321908,
      "learning_rate": 8.901271610230033e-06,
      "loss": 0.0,
      "step": 38840
    },
    {
      "epoch": 8.32618945563652,
      "grad_norm": 0.00035956353531219065,
      "learning_rate": 8.898414059151309e-06,
      "loss": 0.1127,
      "step": 38850
    },
    {
      "epoch": 8.328332618945563,
      "grad_norm": 0.003011018969118595,
      "learning_rate": 8.895556508072582e-06,
      "loss": 0.0,
      "step": 38860
    },
    {
      "epoch": 8.330475782254608,
      "grad_norm": 0.00021095943520776927,
      "learning_rate": 8.892698956993856e-06,
      "loss": 0.0,
      "step": 38870
    },
    {
      "epoch": 8.332618945563652,
      "grad_norm": 0.00020438407955225557,
      "learning_rate": 8.889841405915132e-06,
      "loss": 0.0,
      "step": 38880
    },
    {
      "epoch": 8.334762108872695,
      "grad_norm": 0.0029970358591526747,
      "learning_rate": 8.886983854836406e-06,
      "loss": 0.0139,
      "step": 38890
    },
    {
      "epoch": 8.33690527218174,
      "grad_norm": 0.00014865639968775213,
      "learning_rate": 8.884126303757682e-06,
      "loss": 0.0,
      "step": 38900
    },
    {
      "epoch": 8.339048435490785,
      "grad_norm": 0.0001420351181877777,
      "learning_rate": 8.881268752678955e-06,
      "loss": 0.0085,
      "step": 38910
    },
    {
      "epoch": 8.341191598799828,
      "grad_norm": 0.00015852942306082696,
      "learning_rate": 8.87841120160023e-06,
      "loss": 0.0,
      "step": 38920
    },
    {
      "epoch": 8.343334762108872,
      "grad_norm": 0.0005303514190018177,
      "learning_rate": 8.875553650521503e-06,
      "loss": 0.0019,
      "step": 38930
    },
    {
      "epoch": 8.345477925417917,
      "grad_norm": 0.002858498366549611,
      "learning_rate": 8.872696099442777e-06,
      "loss": 0.2396,
      "step": 38940
    },
    {
      "epoch": 8.34762108872696,
      "grad_norm": 0.001897210255265236,
      "learning_rate": 8.869838548364053e-06,
      "loss": 0.0,
      "step": 38950
    },
    {
      "epoch": 8.349764252036005,
      "grad_norm": 0.0021378572564572096,
      "learning_rate": 8.866980997285327e-06,
      "loss": 0.0002,
      "step": 38960
    },
    {
      "epoch": 8.35190741534505,
      "grad_norm": 0.00047590857138857245,
      "learning_rate": 8.864123446206602e-06,
      "loss": 0.0001,
      "step": 38970
    },
    {
      "epoch": 8.354050578654093,
      "grad_norm": 0.03401508182287216,
      "learning_rate": 8.861265895127876e-06,
      "loss": 0.0005,
      "step": 38980
    },
    {
      "epoch": 8.356193741963137,
      "grad_norm": 0.0009146081865765154,
      "learning_rate": 8.85840834404915e-06,
      "loss": 0.0,
      "step": 38990
    },
    {
      "epoch": 8.358336905272182,
      "grad_norm": 0.037094857543706894,
      "learning_rate": 8.855550792970426e-06,
      "loss": 0.101,
      "step": 39000
    },
    {
      "epoch": 8.360480068581225,
      "grad_norm": 0.00020820507779717445,
      "learning_rate": 8.8526932418917e-06,
      "loss": 0.2888,
      "step": 39010
    },
    {
      "epoch": 8.36262323189027,
      "grad_norm": 0.0001960357913048938,
      "learning_rate": 8.849835690812974e-06,
      "loss": 0.0001,
      "step": 39020
    },
    {
      "epoch": 8.364766395199315,
      "grad_norm": 0.2714720666408539,
      "learning_rate": 8.846978139734248e-06,
      "loss": 0.0015,
      "step": 39030
    },
    {
      "epoch": 8.366909558508357,
      "grad_norm": 0.0002542242291383445,
      "learning_rate": 8.844120588655523e-06,
      "loss": 0.0934,
      "step": 39040
    },
    {
      "epoch": 8.369052721817402,
      "grad_norm": 0.012579764239490032,
      "learning_rate": 8.841263037576797e-06,
      "loss": 0.0,
      "step": 39050
    },
    {
      "epoch": 8.371195885126447,
      "grad_norm": 0.00024687545374035835,
      "learning_rate": 8.838405486498071e-06,
      "loss": 0.0,
      "step": 39060
    },
    {
      "epoch": 8.37333904843549,
      "grad_norm": 0.00035803060745820403,
      "learning_rate": 8.835547935419347e-06,
      "loss": 0.0,
      "step": 39070
    },
    {
      "epoch": 8.375482211744535,
      "grad_norm": 0.0014099637046456337,
      "learning_rate": 8.83269038434062e-06,
      "loss": 0.0,
      "step": 39080
    },
    {
      "epoch": 8.37762537505358,
      "grad_norm": 0.0006106366636231542,
      "learning_rate": 8.829832833261895e-06,
      "loss": 0.2556,
      "step": 39090
    },
    {
      "epoch": 8.379768538362622,
      "grad_norm": 0.0004080694925505668,
      "learning_rate": 8.82697528218317e-06,
      "loss": 0.0015,
      "step": 39100
    },
    {
      "epoch": 8.381911701671667,
      "grad_norm": 0.0001411998237017542,
      "learning_rate": 8.824117731104444e-06,
      "loss": 0.0005,
      "step": 39110
    },
    {
      "epoch": 8.384054864980712,
      "grad_norm": 0.002226300770416856,
      "learning_rate": 8.82126018002572e-06,
      "loss": 0.0,
      "step": 39120
    },
    {
      "epoch": 8.386198028289755,
      "grad_norm": 0.004022353794425726,
      "learning_rate": 8.818402628946992e-06,
      "loss": 0.0,
      "step": 39130
    },
    {
      "epoch": 8.3883411915988,
      "grad_norm": 0.0024174910504370928,
      "learning_rate": 8.815545077868268e-06,
      "loss": 0.2189,
      "step": 39140
    },
    {
      "epoch": 8.390484354907844,
      "grad_norm": 0.0014553560176864266,
      "learning_rate": 8.812687526789542e-06,
      "loss": 0.0002,
      "step": 39150
    },
    {
      "epoch": 8.392627518216887,
      "grad_norm": 0.036721229553222656,
      "learning_rate": 8.809829975710816e-06,
      "loss": 0.4126,
      "step": 39160
    },
    {
      "epoch": 8.394770681525932,
      "grad_norm": 0.003322470234706998,
      "learning_rate": 8.806972424632091e-06,
      "loss": 0.0062,
      "step": 39170
    },
    {
      "epoch": 8.396913844834977,
      "grad_norm": 0.0004202781419735402,
      "learning_rate": 8.804114873553365e-06,
      "loss": 0.0001,
      "step": 39180
    },
    {
      "epoch": 8.39905700814402,
      "grad_norm": 0.005189120769500732,
      "learning_rate": 8.80125732247464e-06,
      "loss": 0.0002,
      "step": 39190
    },
    {
      "epoch": 8.401200171453064,
      "grad_norm": 0.000307314854580909,
      "learning_rate": 8.798399771395915e-06,
      "loss": 0.2202,
      "step": 39200
    },
    {
      "epoch": 8.40334333476211,
      "grad_norm": 0.0003216964250896126,
      "learning_rate": 8.795542220317189e-06,
      "loss": 0.0531,
      "step": 39210
    },
    {
      "epoch": 8.405486498071152,
      "grad_norm": 0.00025410018861293793,
      "learning_rate": 8.792684669238464e-06,
      "loss": 0.0002,
      "step": 39220
    },
    {
      "epoch": 8.407629661380197,
      "grad_norm": 0.0002489035250619054,
      "learning_rate": 8.789827118159738e-06,
      "loss": 0.0233,
      "step": 39230
    },
    {
      "epoch": 8.409772824689242,
      "grad_norm": 0.029631957411766052,
      "learning_rate": 8.786969567081012e-06,
      "loss": 0.0003,
      "step": 39240
    },
    {
      "epoch": 8.411915987998286,
      "grad_norm": 0.008975790813565254,
      "learning_rate": 8.784112016002286e-06,
      "loss": 0.026,
      "step": 39250
    },
    {
      "epoch": 8.41405915130733,
      "grad_norm": 0.00014051672769710422,
      "learning_rate": 8.781254464923562e-06,
      "loss": 0.0002,
      "step": 39260
    },
    {
      "epoch": 8.416202314616374,
      "grad_norm": 0.0003184742236044258,
      "learning_rate": 8.778396913844836e-06,
      "loss": 0.1852,
      "step": 39270
    },
    {
      "epoch": 8.418345477925419,
      "grad_norm": 0.0014301193878054619,
      "learning_rate": 8.77553936276611e-06,
      "loss": 0.0002,
      "step": 39280
    },
    {
      "epoch": 8.420488641234462,
      "grad_norm": 0.05516963452100754,
      "learning_rate": 8.772681811687385e-06,
      "loss": 0.0002,
      "step": 39290
    },
    {
      "epoch": 8.422631804543506,
      "grad_norm": 0.000488819379825145,
      "learning_rate": 8.769824260608659e-06,
      "loss": 0.0249,
      "step": 39300
    },
    {
      "epoch": 8.424774967852551,
      "grad_norm": 0.0009214550955221057,
      "learning_rate": 8.766966709529933e-06,
      "loss": 0.0,
      "step": 39310
    },
    {
      "epoch": 8.426918131161594,
      "grad_norm": 0.015312750823795795,
      "learning_rate": 8.764109158451209e-06,
      "loss": 0.0,
      "step": 39320
    },
    {
      "epoch": 8.429061294470639,
      "grad_norm": 0.00016474680160172284,
      "learning_rate": 8.761251607372483e-06,
      "loss": 0.0556,
      "step": 39330
    },
    {
      "epoch": 8.431204457779684,
      "grad_norm": 0.0037414156831800938,
      "learning_rate": 8.758394056293758e-06,
      "loss": 0.0,
      "step": 39340
    },
    {
      "epoch": 8.433347621088727,
      "grad_norm": 0.008779480122029781,
      "learning_rate": 8.75553650521503e-06,
      "loss": 0.0003,
      "step": 39350
    },
    {
      "epoch": 8.435490784397771,
      "grad_norm": 0.0031957742758095264,
      "learning_rate": 8.752678954136306e-06,
      "loss": 0.0,
      "step": 39360
    },
    {
      "epoch": 8.437633947706816,
      "grad_norm": 0.0003688843280542642,
      "learning_rate": 8.74982140305758e-06,
      "loss": 0.0,
      "step": 39370
    },
    {
      "epoch": 8.439777111015859,
      "grad_norm": 31.301212310791016,
      "learning_rate": 8.746963851978854e-06,
      "loss": 0.2098,
      "step": 39380
    },
    {
      "epoch": 8.441920274324904,
      "grad_norm": 0.0005313237197697163,
      "learning_rate": 8.74410630090013e-06,
      "loss": 0.0008,
      "step": 39390
    },
    {
      "epoch": 8.444063437633949,
      "grad_norm": 76.62095642089844,
      "learning_rate": 8.741248749821403e-06,
      "loss": 0.1977,
      "step": 39400
    },
    {
      "epoch": 8.446206600942991,
      "grad_norm": 8.103057189146057e-05,
      "learning_rate": 8.738391198742679e-06,
      "loss": 0.1064,
      "step": 39410
    },
    {
      "epoch": 8.448349764252036,
      "grad_norm": 6.509363447548822e-05,
      "learning_rate": 8.735533647663953e-06,
      "loss": 0.0001,
      "step": 39420
    },
    {
      "epoch": 8.450492927561081,
      "grad_norm": 0.01326223649084568,
      "learning_rate": 8.732676096585227e-06,
      "loss": 0.0001,
      "step": 39430
    },
    {
      "epoch": 8.452636090870124,
      "grad_norm": 53.502960205078125,
      "learning_rate": 8.729818545506502e-06,
      "loss": 0.1621,
      "step": 39440
    },
    {
      "epoch": 8.454779254179169,
      "grad_norm": 0.0005327074904926121,
      "learning_rate": 8.726960994427775e-06,
      "loss": 0.0007,
      "step": 39450
    },
    {
      "epoch": 8.456922417488213,
      "grad_norm": 0.00010087347618537024,
      "learning_rate": 8.72410344334905e-06,
      "loss": 0.0002,
      "step": 39460
    },
    {
      "epoch": 8.459065580797256,
      "grad_norm": 0.015880703926086426,
      "learning_rate": 8.721245892270324e-06,
      "loss": 0.0,
      "step": 39470
    },
    {
      "epoch": 8.461208744106301,
      "grad_norm": 0.00040525742224417627,
      "learning_rate": 8.7183883411916e-06,
      "loss": 0.0001,
      "step": 39480
    },
    {
      "epoch": 8.463351907415346,
      "grad_norm": 0.0005077412351965904,
      "learning_rate": 8.715530790112874e-06,
      "loss": 0.0001,
      "step": 39490
    },
    {
      "epoch": 8.465495070724389,
      "grad_norm": 0.0014935387298464775,
      "learning_rate": 8.712673239034148e-06,
      "loss": 0.0001,
      "step": 39500
    },
    {
      "epoch": 8.467638234033434,
      "grad_norm": 0.00025219653616659343,
      "learning_rate": 8.709815687955423e-06,
      "loss": 0.0001,
      "step": 39510
    },
    {
      "epoch": 8.469781397342478,
      "grad_norm": 0.016739146783947945,
      "learning_rate": 8.706958136876697e-06,
      "loss": 0.2148,
      "step": 39520
    },
    {
      "epoch": 8.471924560651521,
      "grad_norm": 0.00012944737682119012,
      "learning_rate": 8.704100585797973e-06,
      "loss": 0.0002,
      "step": 39530
    },
    {
      "epoch": 8.474067723960566,
      "grad_norm": 9.724585834192112e-05,
      "learning_rate": 8.701243034719247e-06,
      "loss": 0.0001,
      "step": 39540
    },
    {
      "epoch": 8.47621088726961,
      "grad_norm": 0.002584346104413271,
      "learning_rate": 8.69838548364052e-06,
      "loss": 0.0,
      "step": 39550
    },
    {
      "epoch": 8.478354050578654,
      "grad_norm": 0.00976155698299408,
      "learning_rate": 8.695527932561795e-06,
      "loss": 0.0,
      "step": 39560
    },
    {
      "epoch": 8.480497213887698,
      "grad_norm": 9.102546755457297e-05,
      "learning_rate": 8.692670381483069e-06,
      "loss": 0.0,
      "step": 39570
    },
    {
      "epoch": 8.482640377196743,
      "grad_norm": 0.0033487288746982813,
      "learning_rate": 8.689812830404344e-06,
      "loss": 0.0002,
      "step": 39580
    },
    {
      "epoch": 8.484783540505786,
      "grad_norm": 0.013253433629870415,
      "learning_rate": 8.686955279325618e-06,
      "loss": 0.0002,
      "step": 39590
    },
    {
      "epoch": 8.48692670381483,
      "grad_norm": 7.94739680713974e-05,
      "learning_rate": 8.684097728246894e-06,
      "loss": 0.0343,
      "step": 39600
    },
    {
      "epoch": 8.489069867123876,
      "grad_norm": 0.00035223879967816174,
      "learning_rate": 8.681240177168168e-06,
      "loss": 0.0,
      "step": 39610
    },
    {
      "epoch": 8.491213030432919,
      "grad_norm": 0.004719479940831661,
      "learning_rate": 8.678382626089442e-06,
      "loss": 0.0002,
      "step": 39620
    },
    {
      "epoch": 8.493356193741963,
      "grad_norm": 0.3247079849243164,
      "learning_rate": 8.675525075010717e-06,
      "loss": 0.0005,
      "step": 39630
    },
    {
      "epoch": 8.495499357051008,
      "grad_norm": 0.007869687862694263,
      "learning_rate": 8.672667523931991e-06,
      "loss": 0.0002,
      "step": 39640
    },
    {
      "epoch": 8.497642520360051,
      "grad_norm": 5.198491635383107e-05,
      "learning_rate": 8.669809972853265e-06,
      "loss": 0.0,
      "step": 39650
    },
    {
      "epoch": 8.499785683669096,
      "grad_norm": 5.7803536037681624e-05,
      "learning_rate": 8.66695242177454e-06,
      "loss": 0.0,
      "step": 39660
    },
    {
      "epoch": 8.50192884697814,
      "grad_norm": 0.003388789249584079,
      "learning_rate": 8.664094870695815e-06,
      "loss": 0.0149,
      "step": 39670
    },
    {
      "epoch": 8.504072010287183,
      "grad_norm": 0.007443970534950495,
      "learning_rate": 8.661237319617089e-06,
      "loss": 0.0,
      "step": 39680
    },
    {
      "epoch": 8.506215173596228,
      "grad_norm": 0.00019181438256055117,
      "learning_rate": 8.658379768538363e-06,
      "loss": 0.0,
      "step": 39690
    },
    {
      "epoch": 8.508358336905273,
      "grad_norm": 4.5901939301984385e-05,
      "learning_rate": 8.655522217459638e-06,
      "loss": 0.0,
      "step": 39700
    },
    {
      "epoch": 8.510501500214316,
      "grad_norm": 0.0002546559553593397,
      "learning_rate": 8.652664666380912e-06,
      "loss": 0.0,
      "step": 39710
    },
    {
      "epoch": 8.51264466352336,
      "grad_norm": 8.805019751889631e-05,
      "learning_rate": 8.649807115302186e-06,
      "loss": 0.0001,
      "step": 39720
    },
    {
      "epoch": 8.514787826832405,
      "grad_norm": 0.0011999952839687467,
      "learning_rate": 8.646949564223462e-06,
      "loss": 0.0,
      "step": 39730
    },
    {
      "epoch": 8.516930990141448,
      "grad_norm": 4.990835441276431e-05,
      "learning_rate": 8.644092013144736e-06,
      "loss": 0.0001,
      "step": 39740
    },
    {
      "epoch": 8.519074153450493,
      "grad_norm": 0.05502529442310333,
      "learning_rate": 8.641234462066011e-06,
      "loss": 0.0001,
      "step": 39750
    },
    {
      "epoch": 8.521217316759538,
      "grad_norm": 0.0010697093093767762,
      "learning_rate": 8.638376910987285e-06,
      "loss": 0.0,
      "step": 39760
    },
    {
      "epoch": 8.52336048006858,
      "grad_norm": 0.01792084239423275,
      "learning_rate": 8.635519359908559e-06,
      "loss": 0.0001,
      "step": 39770
    },
    {
      "epoch": 8.525503643377625,
      "grad_norm": 4.327624992583878e-05,
      "learning_rate": 8.632661808829833e-06,
      "loss": 0.0,
      "step": 39780
    },
    {
      "epoch": 8.52764680668667,
      "grad_norm": 4.4409989641280845e-05,
      "learning_rate": 8.629804257751107e-06,
      "loss": 0.0233,
      "step": 39790
    },
    {
      "epoch": 8.529789969995713,
      "grad_norm": 5.238421363173984e-05,
      "learning_rate": 8.626946706672383e-06,
      "loss": 0.0,
      "step": 39800
    },
    {
      "epoch": 8.531933133304758,
      "grad_norm": 39.01605224609375,
      "learning_rate": 8.624089155593656e-06,
      "loss": 0.3992,
      "step": 39810
    },
    {
      "epoch": 8.534076296613803,
      "grad_norm": 0.00027511370717547834,
      "learning_rate": 8.621231604514932e-06,
      "loss": 0.2224,
      "step": 39820
    },
    {
      "epoch": 8.536219459922846,
      "grad_norm": 0.2198425680398941,
      "learning_rate": 8.618374053436206e-06,
      "loss": 0.022,
      "step": 39830
    },
    {
      "epoch": 8.53836262323189,
      "grad_norm": 0.0009713731706142426,
      "learning_rate": 8.61551650235748e-06,
      "loss": 0.0001,
      "step": 39840
    },
    {
      "epoch": 8.540505786540935,
      "grad_norm": 0.0006204732926562428,
      "learning_rate": 8.612658951278756e-06,
      "loss": 0.0003,
      "step": 39850
    },
    {
      "epoch": 8.542648949849978,
      "grad_norm": 0.005902377888560295,
      "learning_rate": 8.60980140020003e-06,
      "loss": 0.0,
      "step": 39860
    },
    {
      "epoch": 8.544792113159023,
      "grad_norm": 0.0037712061312049627,
      "learning_rate": 8.606943849121303e-06,
      "loss": 0.0001,
      "step": 39870
    },
    {
      "epoch": 8.546935276468067,
      "grad_norm": 0.003676836844533682,
      "learning_rate": 8.604086298042577e-06,
      "loss": 0.0,
      "step": 39880
    },
    {
      "epoch": 8.54907843977711,
      "grad_norm": 0.004076459910720587,
      "learning_rate": 8.601228746963853e-06,
      "loss": 0.0001,
      "step": 39890
    },
    {
      "epoch": 8.551221603086155,
      "grad_norm": 0.0015653289156034589,
      "learning_rate": 8.598371195885127e-06,
      "loss": 0.0,
      "step": 39900
    },
    {
      "epoch": 8.5533647663952,
      "grad_norm": 0.014582797884941101,
      "learning_rate": 8.5955136448064e-06,
      "loss": 0.0,
      "step": 39910
    },
    {
      "epoch": 8.555507929704243,
      "grad_norm": 0.006664706859737635,
      "learning_rate": 8.592656093727676e-06,
      "loss": 0.2391,
      "step": 39920
    },
    {
      "epoch": 8.557651093013288,
      "grad_norm": 0.06764806061983109,
      "learning_rate": 8.58979854264895e-06,
      "loss": 0.0003,
      "step": 39930
    },
    {
      "epoch": 8.559794256322332,
      "grad_norm": 0.04655613750219345,
      "learning_rate": 8.586940991570224e-06,
      "loss": 0.0004,
      "step": 39940
    },
    {
      "epoch": 8.561937419631375,
      "grad_norm": 0.00042026082519441843,
      "learning_rate": 8.5840834404915e-06,
      "loss": 0.0001,
      "step": 39950
    },
    {
      "epoch": 8.56408058294042,
      "grad_norm": 18.254526138305664,
      "learning_rate": 8.581225889412774e-06,
      "loss": 0.1896,
      "step": 39960
    },
    {
      "epoch": 8.566223746249465,
      "grad_norm": 0.3464747369289398,
      "learning_rate": 8.57836833833405e-06,
      "loss": 0.0004,
      "step": 39970
    },
    {
      "epoch": 8.568366909558508,
      "grad_norm": 0.00029367918614298105,
      "learning_rate": 8.575510787255323e-06,
      "loss": 0.0001,
      "step": 39980
    },
    {
      "epoch": 8.570510072867553,
      "grad_norm": 0.0003468911745585501,
      "learning_rate": 8.572653236176597e-06,
      "loss": 0.0002,
      "step": 39990
    },
    {
      "epoch": 8.572653236176597,
      "grad_norm": 0.011285191401839256,
      "learning_rate": 8.569795685097871e-06,
      "loss": 0.0001,
      "step": 40000
    },
    {
      "epoch": 8.57479639948564,
      "grad_norm": 20.676025390625,
      "learning_rate": 8.566938134019145e-06,
      "loss": 0.2351,
      "step": 40010
    },
    {
      "epoch": 8.576939562794685,
      "grad_norm": 0.00028009730158373713,
      "learning_rate": 8.56408058294042e-06,
      "loss": 0.0001,
      "step": 40020
    },
    {
      "epoch": 8.57908272610373,
      "grad_norm": 0.021570686250925064,
      "learning_rate": 8.561223031861695e-06,
      "loss": 0.0001,
      "step": 40030
    },
    {
      "epoch": 8.581225889412773,
      "grad_norm": 0.1650834083557129,
      "learning_rate": 8.55836548078297e-06,
      "loss": 0.0005,
      "step": 40040
    },
    {
      "epoch": 8.583369052721817,
      "grad_norm": 0.01883300021290779,
      "learning_rate": 8.555507929704244e-06,
      "loss": 0.0,
      "step": 40050
    },
    {
      "epoch": 8.585512216030862,
      "grad_norm": 0.008504831232130527,
      "learning_rate": 8.552650378625518e-06,
      "loss": 0.0005,
      "step": 40060
    },
    {
      "epoch": 8.587655379339905,
      "grad_norm": 0.010175025090575218,
      "learning_rate": 8.549792827546794e-06,
      "loss": 0.0001,
      "step": 40070
    },
    {
      "epoch": 8.58979854264895,
      "grad_norm": 22.554656982421875,
      "learning_rate": 8.546935276468068e-06,
      "loss": 0.5429,
      "step": 40080
    },
    {
      "epoch": 8.591941705957995,
      "grad_norm": 0.006974400021135807,
      "learning_rate": 8.544077725389342e-06,
      "loss": 0.1407,
      "step": 40090
    },
    {
      "epoch": 8.594084869267038,
      "grad_norm": 0.0019555112812668085,
      "learning_rate": 8.541220174310616e-06,
      "loss": 0.0002,
      "step": 40100
    },
    {
      "epoch": 8.596228032576082,
      "grad_norm": 0.0012886904878541827,
      "learning_rate": 8.538362623231891e-06,
      "loss": 0.0001,
      "step": 40110
    },
    {
      "epoch": 8.598371195885127,
      "grad_norm": 0.011321033351123333,
      "learning_rate": 8.535505072153165e-06,
      "loss": 0.0004,
      "step": 40120
    },
    {
      "epoch": 8.60051435919417,
      "grad_norm": 0.0002307001268491149,
      "learning_rate": 8.532647521074439e-06,
      "loss": 0.0008,
      "step": 40130
    },
    {
      "epoch": 8.602657522503215,
      "grad_norm": 0.008140983060002327,
      "learning_rate": 8.529789969995715e-06,
      "loss": 0.1646,
      "step": 40140
    },
    {
      "epoch": 8.60480068581226,
      "grad_norm": 0.00018138856103178114,
      "learning_rate": 8.526932418916989e-06,
      "loss": 0.1494,
      "step": 40150
    },
    {
      "epoch": 8.606943849121302,
      "grad_norm": 0.015935849398374557,
      "learning_rate": 8.524074867838263e-06,
      "loss": 0.0002,
      "step": 40160
    },
    {
      "epoch": 8.609087012430347,
      "grad_norm": 0.1198783665895462,
      "learning_rate": 8.521217316759538e-06,
      "loss": 0.0005,
      "step": 40170
    },
    {
      "epoch": 8.611230175739392,
      "grad_norm": 0.17704057693481445,
      "learning_rate": 8.518359765680812e-06,
      "loss": 0.177,
      "step": 40180
    },
    {
      "epoch": 8.613373339048435,
      "grad_norm": 0.00024265686806757003,
      "learning_rate": 8.515502214602088e-06,
      "loss": 0.0001,
      "step": 40190
    },
    {
      "epoch": 8.61551650235748,
      "grad_norm": 0.018716443330049515,
      "learning_rate": 8.512644663523362e-06,
      "loss": 0.0001,
      "step": 40200
    },
    {
      "epoch": 8.617659665666524,
      "grad_norm": 0.01055549830198288,
      "learning_rate": 8.509787112444636e-06,
      "loss": 0.0001,
      "step": 40210
    },
    {
      "epoch": 8.619802828975567,
      "grad_norm": 0.0010883958311751485,
      "learning_rate": 8.50692956136591e-06,
      "loss": 0.1574,
      "step": 40220
    },
    {
      "epoch": 8.621945992284612,
      "grad_norm": 0.00020049815066158772,
      "learning_rate": 8.504072010287183e-06,
      "loss": 0.228,
      "step": 40230
    },
    {
      "epoch": 8.624089155593657,
      "grad_norm": 0.00020081325783394277,
      "learning_rate": 8.501214459208459e-06,
      "loss": 0.0001,
      "step": 40240
    },
    {
      "epoch": 8.6262323189027,
      "grad_norm": 0.0001581038668518886,
      "learning_rate": 8.498356908129733e-06,
      "loss": 0.1419,
      "step": 40250
    },
    {
      "epoch": 8.628375482211744,
      "grad_norm": 0.006485363934189081,
      "learning_rate": 8.495499357051009e-06,
      "loss": 0.0001,
      "step": 40260
    },
    {
      "epoch": 8.63051864552079,
      "grad_norm": 0.010914203710854053,
      "learning_rate": 8.492641805972283e-06,
      "loss": 0.0,
      "step": 40270
    },
    {
      "epoch": 8.632661808829832,
      "grad_norm": 0.05414015054702759,
      "learning_rate": 8.489784254893557e-06,
      "loss": 0.1366,
      "step": 40280
    },
    {
      "epoch": 8.634804972138877,
      "grad_norm": 0.0028079196345061064,
      "learning_rate": 8.486926703814832e-06,
      "loss": 0.0002,
      "step": 40290
    },
    {
      "epoch": 8.636948135447922,
      "grad_norm": 0.005899911746382713,
      "learning_rate": 8.484069152736106e-06,
      "loss": 0.0002,
      "step": 40300
    },
    {
      "epoch": 8.639091298756965,
      "grad_norm": 0.0001402107736794278,
      "learning_rate": 8.48121160165738e-06,
      "loss": 0.0004,
      "step": 40310
    },
    {
      "epoch": 8.64123446206601,
      "grad_norm": 0.0015524189220741391,
      "learning_rate": 8.478354050578654e-06,
      "loss": 0.0001,
      "step": 40320
    },
    {
      "epoch": 8.643377625375054,
      "grad_norm": 0.07302495837211609,
      "learning_rate": 8.47549649949993e-06,
      "loss": 0.029,
      "step": 40330
    },
    {
      "epoch": 8.645520788684097,
      "grad_norm": 0.0001133440964622423,
      "learning_rate": 8.472638948421203e-06,
      "loss": 0.0187,
      "step": 40340
    },
    {
      "epoch": 8.647663951993142,
      "grad_norm": 0.0031739857513457537,
      "learning_rate": 8.469781397342477e-06,
      "loss": 0.1044,
      "step": 40350
    },
    {
      "epoch": 8.649807115302186,
      "grad_norm": 0.00012042451271554455,
      "learning_rate": 8.466923846263753e-06,
      "loss": 0.0,
      "step": 40360
    },
    {
      "epoch": 8.65195027861123,
      "grad_norm": 0.038764502853155136,
      "learning_rate": 8.464066295185027e-06,
      "loss": 0.009,
      "step": 40370
    },
    {
      "epoch": 8.654093441920274,
      "grad_norm": 0.00018254238239023834,
      "learning_rate": 8.461208744106303e-06,
      "loss": 0.0,
      "step": 40380
    },
    {
      "epoch": 8.656236605229319,
      "grad_norm": 8.462901314487681e-05,
      "learning_rate": 8.458351193027577e-06,
      "loss": 0.0,
      "step": 40390
    },
    {
      "epoch": 8.658379768538362,
      "grad_norm": 9.243209206033498e-05,
      "learning_rate": 8.45549364194885e-06,
      "loss": 0.0297,
      "step": 40400
    },
    {
      "epoch": 8.660522931847407,
      "grad_norm": 0.005985703319311142,
      "learning_rate": 8.452636090870126e-06,
      "loss": 0.0,
      "step": 40410
    },
    {
      "epoch": 8.662666095156451,
      "grad_norm": 0.00010832263069460168,
      "learning_rate": 8.449778539791398e-06,
      "loss": 0.0,
      "step": 40420
    },
    {
      "epoch": 8.664809258465494,
      "grad_norm": 0.0017234347760677338,
      "learning_rate": 8.446920988712674e-06,
      "loss": 0.0006,
      "step": 40430
    },
    {
      "epoch": 8.666952421774539,
      "grad_norm": 0.0011171401711180806,
      "learning_rate": 8.444063437633948e-06,
      "loss": 0.0,
      "step": 40440
    },
    {
      "epoch": 8.669095585083584,
      "grad_norm": 0.0007745909388177097,
      "learning_rate": 8.441205886555223e-06,
      "loss": 0.0,
      "step": 40450
    },
    {
      "epoch": 8.671238748392627,
      "grad_norm": 0.00012942778994329274,
      "learning_rate": 8.438348335476497e-06,
      "loss": 0.1612,
      "step": 40460
    },
    {
      "epoch": 8.673381911701671,
      "grad_norm": 6.98019552230835,
      "learning_rate": 8.435490784397771e-06,
      "loss": 0.0153,
      "step": 40470
    },
    {
      "epoch": 8.675525075010716,
      "grad_norm": 0.01063785795122385,
      "learning_rate": 8.432633233319047e-06,
      "loss": 0.3986,
      "step": 40480
    },
    {
      "epoch": 8.67766823831976,
      "grad_norm": 0.00019563527894206345,
      "learning_rate": 8.429775682240321e-06,
      "loss": 0.1204,
      "step": 40490
    },
    {
      "epoch": 8.679811401628804,
      "grad_norm": 0.00016344193136319518,
      "learning_rate": 8.426918131161595e-06,
      "loss": 0.0008,
      "step": 40500
    },
    {
      "epoch": 8.681954564937849,
      "grad_norm": 0.00015239739150274545,
      "learning_rate": 8.42406058008287e-06,
      "loss": 0.0002,
      "step": 40510
    },
    {
      "epoch": 8.684097728246892,
      "grad_norm": 0.0001729508221615106,
      "learning_rate": 8.421203029004144e-06,
      "loss": 0.0002,
      "step": 40520
    },
    {
      "epoch": 8.686240891555936,
      "grad_norm": 0.0010711445938795805,
      "learning_rate": 8.418345477925418e-06,
      "loss": 0.0001,
      "step": 40530
    },
    {
      "epoch": 8.688384054864981,
      "grad_norm": 0.00011380074283806607,
      "learning_rate": 8.415487926846692e-06,
      "loss": 0.0168,
      "step": 40540
    },
    {
      "epoch": 8.690527218174024,
      "grad_norm": 0.0001941208029165864,
      "learning_rate": 8.412630375767968e-06,
      "loss": 0.3276,
      "step": 40550
    },
    {
      "epoch": 8.692670381483069,
      "grad_norm": 0.00038174825021997094,
      "learning_rate": 8.409772824689242e-06,
      "loss": 0.0002,
      "step": 40560
    },
    {
      "epoch": 8.694813544792114,
      "grad_norm": 0.015118394047021866,
      "learning_rate": 8.406915273610516e-06,
      "loss": 0.0001,
      "step": 40570
    },
    {
      "epoch": 8.696956708101157,
      "grad_norm": 31.105669021606445,
      "learning_rate": 8.404057722531791e-06,
      "loss": 0.2462,
      "step": 40580
    },
    {
      "epoch": 8.699099871410201,
      "grad_norm": 0.02719070203602314,
      "learning_rate": 8.401200171453065e-06,
      "loss": 0.0861,
      "step": 40590
    },
    {
      "epoch": 8.701243034719246,
      "grad_norm": 0.04820599779486656,
      "learning_rate": 8.398342620374341e-06,
      "loss": 0.0003,
      "step": 40600
    },
    {
      "epoch": 8.703386198028289,
      "grad_norm": 0.0008216970600187778,
      "learning_rate": 8.395485069295615e-06,
      "loss": 0.1589,
      "step": 40610
    },
    {
      "epoch": 8.705529361337334,
      "grad_norm": 0.0074472203850746155,
      "learning_rate": 8.392627518216889e-06,
      "loss": 0.0005,
      "step": 40620
    },
    {
      "epoch": 8.707672524646378,
      "grad_norm": 0.0004740594595205039,
      "learning_rate": 8.389769967138164e-06,
      "loss": 0.0004,
      "step": 40630
    },
    {
      "epoch": 8.709815687955421,
      "grad_norm": 0.06998270750045776,
      "learning_rate": 8.386912416059437e-06,
      "loss": 0.213,
      "step": 40640
    },
    {
      "epoch": 8.711958851264466,
      "grad_norm": 0.03806911036372185,
      "learning_rate": 8.384054864980712e-06,
      "loss": 0.0094,
      "step": 40650
    },
    {
      "epoch": 8.71410201457351,
      "grad_norm": 0.000667416665237397,
      "learning_rate": 8.381197313901986e-06,
      "loss": 0.1518,
      "step": 40660
    },
    {
      "epoch": 8.716245177882554,
      "grad_norm": 0.003864397993311286,
      "learning_rate": 8.378339762823262e-06,
      "loss": 0.0001,
      "step": 40670
    },
    {
      "epoch": 8.718388341191599,
      "grad_norm": 0.004243174102157354,
      "learning_rate": 8.375482211744536e-06,
      "loss": 0.0,
      "step": 40680
    },
    {
      "epoch": 8.720531504500643,
      "grad_norm": 0.0004983284743502736,
      "learning_rate": 8.37262466066581e-06,
      "loss": 0.0,
      "step": 40690
    },
    {
      "epoch": 8.722674667809688,
      "grad_norm": 0.004550048615783453,
      "learning_rate": 8.369767109587085e-06,
      "loss": 0.0004,
      "step": 40700
    },
    {
      "epoch": 8.724817831118731,
      "grad_norm": 0.04475211352109909,
      "learning_rate": 8.366909558508359e-06,
      "loss": 0.0003,
      "step": 40710
    },
    {
      "epoch": 8.726960994427776,
      "grad_norm": 0.0010684954468160868,
      "learning_rate": 8.364052007429633e-06,
      "loss": 0.0001,
      "step": 40720
    },
    {
      "epoch": 8.72910415773682,
      "grad_norm": 0.0031167473644018173,
      "learning_rate": 8.361194456350909e-06,
      "loss": 0.0003,
      "step": 40730
    },
    {
      "epoch": 8.731247321045863,
      "grad_norm": 0.0011793208541348577,
      "learning_rate": 8.358336905272183e-06,
      "loss": 0.0849,
      "step": 40740
    },
    {
      "epoch": 8.733390484354908,
      "grad_norm": 0.0004036171012558043,
      "learning_rate": 8.355479354193457e-06,
      "loss": 0.0,
      "step": 40750
    },
    {
      "epoch": 8.735533647663953,
      "grad_norm": 0.0001795994321582839,
      "learning_rate": 8.35262180311473e-06,
      "loss": 0.0005,
      "step": 40760
    },
    {
      "epoch": 8.737676810972996,
      "grad_norm": 0.0034780993591994047,
      "learning_rate": 8.349764252036006e-06,
      "loss": 0.2845,
      "step": 40770
    },
    {
      "epoch": 8.73981997428204,
      "grad_norm": 0.00011387769336579368,
      "learning_rate": 8.34690670095728e-06,
      "loss": 0.0,
      "step": 40780
    },
    {
      "epoch": 8.741963137591085,
      "grad_norm": 0.00868993904441595,
      "learning_rate": 8.344049149878554e-06,
      "loss": 0.0001,
      "step": 40790
    },
    {
      "epoch": 8.744106300900128,
      "grad_norm": 0.00031795050017535686,
      "learning_rate": 8.34119159879983e-06,
      "loss": 0.0003,
      "step": 40800
    },
    {
      "epoch": 8.746249464209173,
      "grad_norm": 0.00010511904110899195,
      "learning_rate": 8.338334047721104e-06,
      "loss": 0.0001,
      "step": 40810
    },
    {
      "epoch": 8.748392627518218,
      "grad_norm": 0.00013950280845165253,
      "learning_rate": 8.335476496642379e-06,
      "loss": 0.0002,
      "step": 40820
    },
    {
      "epoch": 8.75053579082726,
      "grad_norm": 8.030764729483053e-05,
      "learning_rate": 8.332618945563653e-06,
      "loss": 0.0,
      "step": 40830
    },
    {
      "epoch": 8.752678954136305,
      "grad_norm": 0.00014018596266396344,
      "learning_rate": 8.329761394484927e-06,
      "loss": 0.0,
      "step": 40840
    },
    {
      "epoch": 8.75482211744535,
      "grad_norm": 0.0001426937960786745,
      "learning_rate": 8.326903843406201e-06,
      "loss": 0.0,
      "step": 40850
    },
    {
      "epoch": 8.756965280754393,
      "grad_norm": 0.00022405209892895073,
      "learning_rate": 8.324046292327475e-06,
      "loss": 0.0,
      "step": 40860
    },
    {
      "epoch": 8.759108444063438,
      "grad_norm": 8.837834320729598e-05,
      "learning_rate": 8.32118874124875e-06,
      "loss": 0.0,
      "step": 40870
    },
    {
      "epoch": 8.761251607372483,
      "grad_norm": 0.00010483477672096342,
      "learning_rate": 8.318331190170024e-06,
      "loss": 0.0001,
      "step": 40880
    },
    {
      "epoch": 8.763394770681526,
      "grad_norm": 0.00010106307308888063,
      "learning_rate": 8.3154736390913e-06,
      "loss": 0.0001,
      "step": 40890
    },
    {
      "epoch": 8.76553793399057,
      "grad_norm": 9.35791977099143e-05,
      "learning_rate": 8.312616088012574e-06,
      "loss": 0.1223,
      "step": 40900
    },
    {
      "epoch": 8.767681097299615,
      "grad_norm": 0.03031090833246708,
      "learning_rate": 8.309758536933848e-06,
      "loss": 0.0773,
      "step": 40910
    },
    {
      "epoch": 8.769824260608658,
      "grad_norm": 0.00018814607756212354,
      "learning_rate": 8.306900985855123e-06,
      "loss": 0.2165,
      "step": 40920
    },
    {
      "epoch": 8.771967423917703,
      "grad_norm": 0.00010585317068034783,
      "learning_rate": 8.304043434776397e-06,
      "loss": 0.0001,
      "step": 40930
    },
    {
      "epoch": 8.774110587226748,
      "grad_norm": 0.0001736668637022376,
      "learning_rate": 8.301185883697671e-06,
      "loss": 0.0,
      "step": 40940
    },
    {
      "epoch": 8.77625375053579,
      "grad_norm": 0.0002890467585530132,
      "learning_rate": 8.298328332618947e-06,
      "loss": 0.0001,
      "step": 40950
    },
    {
      "epoch": 8.778396913844835,
      "grad_norm": 0.0006307948497124016,
      "learning_rate": 8.295470781540221e-06,
      "loss": 0.2037,
      "step": 40960
    },
    {
      "epoch": 8.78054007715388,
      "grad_norm": 0.011637388728559017,
      "learning_rate": 8.292613230461495e-06,
      "loss": 0.0003,
      "step": 40970
    },
    {
      "epoch": 8.782683240462923,
      "grad_norm": 0.00011972833453910425,
      "learning_rate": 8.289755679382769e-06,
      "loss": 0.0001,
      "step": 40980
    },
    {
      "epoch": 8.784826403771968,
      "grad_norm": 0.0001559235533932224,
      "learning_rate": 8.286898128304044e-06,
      "loss": 0.0,
      "step": 40990
    },
    {
      "epoch": 8.786969567081012,
      "grad_norm": 0.00014356574683915824,
      "learning_rate": 8.284040577225318e-06,
      "loss": 0.0001,
      "step": 41000
    },
    {
      "epoch": 8.789112730390055,
      "grad_norm": 0.010160290636122227,
      "learning_rate": 8.281183026146592e-06,
      "loss": 0.3689,
      "step": 41010
    },
    {
      "epoch": 8.7912558936991,
      "grad_norm": 0.00048033735947683454,
      "learning_rate": 8.278325475067868e-06,
      "loss": 0.0272,
      "step": 41020
    },
    {
      "epoch": 8.793399057008145,
      "grad_norm": 0.004120089579373598,
      "learning_rate": 8.275467923989142e-06,
      "loss": 0.001,
      "step": 41030
    },
    {
      "epoch": 8.795542220317188,
      "grad_norm": 0.03790288418531418,
      "learning_rate": 8.272610372910417e-06,
      "loss": 0.2295,
      "step": 41040
    },
    {
      "epoch": 8.797685383626233,
      "grad_norm": 0.008349576964974403,
      "learning_rate": 8.269752821831691e-06,
      "loss": 0.0001,
      "step": 41050
    },
    {
      "epoch": 8.799828546935277,
      "grad_norm": 0.0015149717219173908,
      "learning_rate": 8.266895270752965e-06,
      "loss": 0.001,
      "step": 41060
    },
    {
      "epoch": 8.80197171024432,
      "grad_norm": 0.02064031921327114,
      "learning_rate": 8.26403771967424e-06,
      "loss": 0.0002,
      "step": 41070
    },
    {
      "epoch": 8.804114873553365,
      "grad_norm": 0.014588737860321999,
      "learning_rate": 8.261180168595513e-06,
      "loss": 0.0001,
      "step": 41080
    },
    {
      "epoch": 8.80625803686241,
      "grad_norm": 0.001418514410033822,
      "learning_rate": 8.258322617516789e-06,
      "loss": 0.0001,
      "step": 41090
    },
    {
      "epoch": 8.808401200171453,
      "grad_norm": 0.002371283480897546,
      "learning_rate": 8.255465066438063e-06,
      "loss": 0.29,
      "step": 41100
    },
    {
      "epoch": 8.810544363480497,
      "grad_norm": 17.681228637695312,
      "learning_rate": 8.252607515359338e-06,
      "loss": 0.1787,
      "step": 41110
    },
    {
      "epoch": 8.812687526789542,
      "grad_norm": 0.002896832535043359,
      "learning_rate": 8.249749964280612e-06,
      "loss": 0.0003,
      "step": 41120
    },
    {
      "epoch": 8.814830690098585,
      "grad_norm": 0.07537058740854263,
      "learning_rate": 8.246892413201886e-06,
      "loss": 0.1653,
      "step": 41130
    },
    {
      "epoch": 8.81697385340763,
      "grad_norm": 0.02456195093691349,
      "learning_rate": 8.244034862123162e-06,
      "loss": 0.0062,
      "step": 41140
    },
    {
      "epoch": 8.819117016716675,
      "grad_norm": 0.002007949398830533,
      "learning_rate": 8.241177311044436e-06,
      "loss": 0.0105,
      "step": 41150
    },
    {
      "epoch": 8.821260180025718,
      "grad_norm": 0.056968867778778076,
      "learning_rate": 8.238319759965711e-06,
      "loss": 0.0002,
      "step": 41160
    },
    {
      "epoch": 8.823403343334762,
      "grad_norm": 0.006430185865610838,
      "learning_rate": 8.235462208886984e-06,
      "loss": 0.1358,
      "step": 41170
    },
    {
      "epoch": 8.825546506643807,
      "grad_norm": 0.0976538434624672,
      "learning_rate": 8.23260465780826e-06,
      "loss": 0.261,
      "step": 41180
    },
    {
      "epoch": 8.82768966995285,
      "grad_norm": 0.008687692694365978,
      "learning_rate": 8.229747106729533e-06,
      "loss": 0.1354,
      "step": 41190
    },
    {
      "epoch": 8.829832833261895,
      "grad_norm": 0.06803153455257416,
      "learning_rate": 8.226889555650807e-06,
      "loss": 0.0023,
      "step": 41200
    },
    {
      "epoch": 8.83197599657094,
      "grad_norm": 0.009327622130513191,
      "learning_rate": 8.224032004572083e-06,
      "loss": 0.0004,
      "step": 41210
    },
    {
      "epoch": 8.834119159879982,
      "grad_norm": 0.006849038414657116,
      "learning_rate": 8.221174453493357e-06,
      "loss": 0.0819,
      "step": 41220
    },
    {
      "epoch": 8.836262323189027,
      "grad_norm": 0.002060704631730914,
      "learning_rate": 8.218316902414632e-06,
      "loss": 0.0001,
      "step": 41230
    },
    {
      "epoch": 8.838405486498072,
      "grad_norm": 0.0010932765435427427,
      "learning_rate": 8.215459351335906e-06,
      "loss": 0.0001,
      "step": 41240
    },
    {
      "epoch": 8.840548649807115,
      "grad_norm": 0.0004636492521967739,
      "learning_rate": 8.21260180025718e-06,
      "loss": 0.0002,
      "step": 41250
    },
    {
      "epoch": 8.84269181311616,
      "grad_norm": 0.00041648559272289276,
      "learning_rate": 8.209744249178456e-06,
      "loss": 0.0001,
      "step": 41260
    },
    {
      "epoch": 8.844834976425204,
      "grad_norm": 33.510284423828125,
      "learning_rate": 8.20688669809973e-06,
      "loss": 0.0208,
      "step": 41270
    },
    {
      "epoch": 8.846978139734247,
      "grad_norm": 0.0002992433146573603,
      "learning_rate": 8.204029147021004e-06,
      "loss": 0.0011,
      "step": 41280
    },
    {
      "epoch": 8.849121303043292,
      "grad_norm": 0.0006839096313342452,
      "learning_rate": 8.201171595942277e-06,
      "loss": 0.0,
      "step": 41290
    },
    {
      "epoch": 8.851264466352337,
      "grad_norm": 0.10192056745290756,
      "learning_rate": 8.198314044863553e-06,
      "loss": 0.0003,
      "step": 41300
    },
    {
      "epoch": 8.85340762966138,
      "grad_norm": 0.00015281743253581226,
      "learning_rate": 8.195456493784827e-06,
      "loss": 0.0,
      "step": 41310
    },
    {
      "epoch": 8.855550792970424,
      "grad_norm": 0.00016908026009332389,
      "learning_rate": 8.192598942706101e-06,
      "loss": 0.0,
      "step": 41320
    },
    {
      "epoch": 8.85769395627947,
      "grad_norm": 0.0002753764274530113,
      "learning_rate": 8.189741391627377e-06,
      "loss": 0.0001,
      "step": 41330
    },
    {
      "epoch": 8.859837119588512,
      "grad_norm": 0.0017105231527239084,
      "learning_rate": 8.18688384054865e-06,
      "loss": 0.0,
      "step": 41340
    },
    {
      "epoch": 8.861980282897557,
      "grad_norm": 0.000379437580704689,
      "learning_rate": 8.184026289469924e-06,
      "loss": 0.2349,
      "step": 41350
    },
    {
      "epoch": 8.864123446206602,
      "grad_norm": 0.0001911103172460571,
      "learning_rate": 8.1811687383912e-06,
      "loss": 0.0001,
      "step": 41360
    },
    {
      "epoch": 8.866266609515645,
      "grad_norm": 0.0001864856603788212,
      "learning_rate": 8.178311187312474e-06,
      "loss": 0.0001,
      "step": 41370
    },
    {
      "epoch": 8.86840977282469,
      "grad_norm": 0.0007338894647546113,
      "learning_rate": 8.17545363623375e-06,
      "loss": 0.0006,
      "step": 41380
    },
    {
      "epoch": 8.870552936133734,
      "grad_norm": 0.0004725006001535803,
      "learning_rate": 8.172596085155022e-06,
      "loss": 0.0001,
      "step": 41390
    },
    {
      "epoch": 8.872696099442777,
      "grad_norm": 0.00014543252473231405,
      "learning_rate": 8.169738534076297e-06,
      "loss": 0.0001,
      "step": 41400
    },
    {
      "epoch": 8.874839262751822,
      "grad_norm": 0.00013237328676041216,
      "learning_rate": 8.166880982997571e-06,
      "loss": 0.0,
      "step": 41410
    },
    {
      "epoch": 8.876982426060867,
      "grad_norm": 0.0002504944277461618,
      "learning_rate": 8.164023431918845e-06,
      "loss": 0.0,
      "step": 41420
    },
    {
      "epoch": 8.87912558936991,
      "grad_norm": 0.000321618135785684,
      "learning_rate": 8.161165880840121e-06,
      "loss": 0.0008,
      "step": 41430
    },
    {
      "epoch": 8.881268752678954,
      "grad_norm": 0.046571142971515656,
      "learning_rate": 8.158308329761395e-06,
      "loss": 0.0002,
      "step": 41440
    },
    {
      "epoch": 8.883411915987999,
      "grad_norm": 0.0033628945238888264,
      "learning_rate": 8.15545077868267e-06,
      "loss": 0.0,
      "step": 41450
    },
    {
      "epoch": 8.885555079297042,
      "grad_norm": 0.00010381698666606098,
      "learning_rate": 8.152593227603944e-06,
      "loss": 0.0001,
      "step": 41460
    },
    {
      "epoch": 8.887698242606087,
      "grad_norm": 0.00010682411812013015,
      "learning_rate": 8.149735676525218e-06,
      "loss": 0.0,
      "step": 41470
    },
    {
      "epoch": 8.889841405915131,
      "grad_norm": 0.00010837033914867789,
      "learning_rate": 8.146878125446494e-06,
      "loss": 0.0,
      "step": 41480
    },
    {
      "epoch": 8.891984569224174,
      "grad_norm": 0.0002797228517010808,
      "learning_rate": 8.144020574367766e-06,
      "loss": 0.1098,
      "step": 41490
    },
    {
      "epoch": 8.894127732533219,
      "grad_norm": 0.004056703299283981,
      "learning_rate": 8.141163023289042e-06,
      "loss": 0.0,
      "step": 41500
    },
    {
      "epoch": 8.896270895842264,
      "grad_norm": 0.0001403637434123084,
      "learning_rate": 8.138305472210316e-06,
      "loss": 0.0,
      "step": 41510
    },
    {
      "epoch": 8.898414059151307,
      "grad_norm": 8.41057044453919e-05,
      "learning_rate": 8.135447921131591e-06,
      "loss": 0.0,
      "step": 41520
    },
    {
      "epoch": 8.900557222460352,
      "grad_norm": 0.0027295025065541267,
      "learning_rate": 8.132590370052865e-06,
      "loss": 0.0008,
      "step": 41530
    },
    {
      "epoch": 8.902700385769396,
      "grad_norm": 7.574297342216596e-05,
      "learning_rate": 8.12973281897414e-06,
      "loss": 0.0001,
      "step": 41540
    },
    {
      "epoch": 8.90484354907844,
      "grad_norm": 6.051153104635887e-05,
      "learning_rate": 8.126875267895415e-06,
      "loss": 0.0,
      "step": 41550
    },
    {
      "epoch": 8.906986712387484,
      "grad_norm": 0.0001490315917180851,
      "learning_rate": 8.124017716816689e-06,
      "loss": 0.0493,
      "step": 41560
    },
    {
      "epoch": 8.909129875696529,
      "grad_norm": 6.905580085003749e-05,
      "learning_rate": 8.121160165737963e-06,
      "loss": 0.0,
      "step": 41570
    },
    {
      "epoch": 8.911273039005572,
      "grad_norm": 9.795965888770297e-05,
      "learning_rate": 8.118302614659238e-06,
      "loss": 0.0,
      "step": 41580
    },
    {
      "epoch": 8.913416202314616,
      "grad_norm": 0.001194761716760695,
      "learning_rate": 8.115445063580512e-06,
      "loss": 0.0003,
      "step": 41590
    },
    {
      "epoch": 8.915559365623661,
      "grad_norm": 0.0003090263926424086,
      "learning_rate": 8.112587512501786e-06,
      "loss": 0.0002,
      "step": 41600
    },
    {
      "epoch": 8.917702528932704,
      "grad_norm": 0.00010169246525038034,
      "learning_rate": 8.10972996142306e-06,
      "loss": 0.0,
      "step": 41610
    },
    {
      "epoch": 8.919845692241749,
      "grad_norm": 0.00011410918523324654,
      "learning_rate": 8.106872410344336e-06,
      "loss": 0.0001,
      "step": 41620
    },
    {
      "epoch": 8.921988855550794,
      "grad_norm": 6.0026497521903366e-05,
      "learning_rate": 8.10401485926561e-06,
      "loss": 0.1541,
      "step": 41630
    },
    {
      "epoch": 8.924132018859837,
      "grad_norm": 0.00010156251664739102,
      "learning_rate": 8.101157308186884e-06,
      "loss": 0.0004,
      "step": 41640
    },
    {
      "epoch": 8.926275182168881,
      "grad_norm": 0.00010790454689413309,
      "learning_rate": 8.09829975710816e-06,
      "loss": 0.0,
      "step": 41650
    },
    {
      "epoch": 8.928418345477926,
      "grad_norm": 6.787415622966364e-05,
      "learning_rate": 8.095442206029433e-06,
      "loss": 0.0004,
      "step": 41660
    },
    {
      "epoch": 8.930561508786969,
      "grad_norm": 8.519620314473286e-05,
      "learning_rate": 8.092584654950709e-06,
      "loss": 0.0004,
      "step": 41670
    },
    {
      "epoch": 8.932704672096014,
      "grad_norm": 5.889587919227779e-05,
      "learning_rate": 8.089727103871983e-06,
      "loss": 0.0,
      "step": 41680
    },
    {
      "epoch": 8.934847835405058,
      "grad_norm": 2.3153882026672363,
      "learning_rate": 8.086869552793257e-06,
      "loss": 0.0028,
      "step": 41690
    },
    {
      "epoch": 8.936990998714101,
      "grad_norm": 6.70569934300147e-05,
      "learning_rate": 8.084012001714532e-06,
      "loss": 0.0009,
      "step": 41700
    },
    {
      "epoch": 8.939134162023146,
      "grad_norm": 7.361689495155588e-05,
      "learning_rate": 8.081154450635804e-06,
      "loss": 0.0004,
      "step": 41710
    },
    {
      "epoch": 8.94127732533219,
      "grad_norm": 6.644622044404969e-05,
      "learning_rate": 8.07829689955708e-06,
      "loss": 0.0688,
      "step": 41720
    },
    {
      "epoch": 8.943420488641234,
      "grad_norm": 6.2970670114737e-05,
      "learning_rate": 8.075439348478354e-06,
      "loss": 0.0,
      "step": 41730
    },
    {
      "epoch": 8.945563651950279,
      "grad_norm": 5.773275188403204e-05,
      "learning_rate": 8.07258179739963e-06,
      "loss": 0.0,
      "step": 41740
    },
    {
      "epoch": 8.947706815259323,
      "grad_norm": 8.591679943492636e-05,
      "learning_rate": 8.069724246320904e-06,
      "loss": 0.252,
      "step": 41750
    },
    {
      "epoch": 8.949849978568366,
      "grad_norm": 5.329390842234716e-05,
      "learning_rate": 8.066866695242178e-06,
      "loss": 0.0,
      "step": 41760
    },
    {
      "epoch": 8.951993141877411,
      "grad_norm": 5.238854282652028e-05,
      "learning_rate": 8.064009144163453e-06,
      "loss": 0.0,
      "step": 41770
    },
    {
      "epoch": 8.954136305186456,
      "grad_norm": 0.00010150907473871484,
      "learning_rate": 8.061151593084727e-06,
      "loss": 0.0149,
      "step": 41780
    },
    {
      "epoch": 8.956279468495499,
      "grad_norm": 0.0002039218961726874,
      "learning_rate": 8.058294042006003e-06,
      "loss": 0.0,
      "step": 41790
    },
    {
      "epoch": 8.958422631804543,
      "grad_norm": 0.00011288921814411879,
      "learning_rate": 8.055436490927277e-06,
      "loss": 0.0,
      "step": 41800
    },
    {
      "epoch": 8.960565795113588,
      "grad_norm": 0.00012751691974699497,
      "learning_rate": 8.05257893984855e-06,
      "loss": 0.0,
      "step": 41810
    },
    {
      "epoch": 8.962708958422631,
      "grad_norm": 0.0009628320694901049,
      "learning_rate": 8.049721388769824e-06,
      "loss": 0.1942,
      "step": 41820
    },
    {
      "epoch": 8.964852121731676,
      "grad_norm": 7.428330718539655e-05,
      "learning_rate": 8.046863837691098e-06,
      "loss": 0.0,
      "step": 41830
    },
    {
      "epoch": 8.96699528504072,
      "grad_norm": 0.014371881261467934,
      "learning_rate": 8.044006286612374e-06,
      "loss": 0.0007,
      "step": 41840
    },
    {
      "epoch": 8.969138448349764,
      "grad_norm": 6.234765896806493e-05,
      "learning_rate": 8.041148735533648e-06,
      "loss": 0.0001,
      "step": 41850
    },
    {
      "epoch": 8.971281611658808,
      "grad_norm": 5.564502134802751e-05,
      "learning_rate": 8.038291184454924e-06,
      "loss": 0.0,
      "step": 41860
    },
    {
      "epoch": 8.973424774967853,
      "grad_norm": 0.002644795225933194,
      "learning_rate": 8.035433633376198e-06,
      "loss": 0.0003,
      "step": 41870
    },
    {
      "epoch": 8.975567938276896,
      "grad_norm": 6.318993837339804e-05,
      "learning_rate": 8.032576082297471e-06,
      "loss": 0.0,
      "step": 41880
    },
    {
      "epoch": 8.97771110158594,
      "grad_norm": 5.193306060391478e-05,
      "learning_rate": 8.029718531218747e-06,
      "loss": 0.0,
      "step": 41890
    },
    {
      "epoch": 8.979854264894986,
      "grad_norm": 0.0001819867466110736,
      "learning_rate": 8.026860980140021e-06,
      "loss": 0.0,
      "step": 41900
    },
    {
      "epoch": 8.981997428204028,
      "grad_norm": 0.00272065750323236,
      "learning_rate": 8.024003429061295e-06,
      "loss": 0.0007,
      "step": 41910
    },
    {
      "epoch": 8.984140591513073,
      "grad_norm": 0.00010872310667764395,
      "learning_rate": 8.021145877982569e-06,
      "loss": 0.0,
      "step": 41920
    },
    {
      "epoch": 8.986283754822118,
      "grad_norm": 3.980533074354753e-05,
      "learning_rate": 8.018288326903844e-06,
      "loss": 0.0,
      "step": 41930
    },
    {
      "epoch": 8.988426918131161,
      "grad_norm": 4.6168453991413116e-05,
      "learning_rate": 8.015430775825118e-06,
      "loss": 0.0001,
      "step": 41940
    },
    {
      "epoch": 8.990570081440206,
      "grad_norm": 0.0001291362859774381,
      "learning_rate": 8.012573224746392e-06,
      "loss": 0.0,
      "step": 41950
    },
    {
      "epoch": 8.99271324474925,
      "grad_norm": 4.750333755509928e-05,
      "learning_rate": 8.009715673667668e-06,
      "loss": 0.0,
      "step": 41960
    },
    {
      "epoch": 8.994856408058293,
      "grad_norm": 6.458647840190679e-05,
      "learning_rate": 8.006858122588942e-06,
      "loss": 0.0001,
      "step": 41970
    },
    {
      "epoch": 8.996999571367338,
      "grad_norm": 7.701860158704221e-05,
      "learning_rate": 8.004000571510216e-06,
      "loss": 0.3354,
      "step": 41980
    },
    {
      "epoch": 8.999142734676383,
      "grad_norm": 0.0002977901021949947,
      "learning_rate": 8.001143020431491e-06,
      "loss": 0.0,
      "step": 41990
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.985,
      "eval_f1": 0.9233390119250426,
      "eval_loss": 0.10875317454338074,
      "eval_precision": 0.9442508710801394,
      "eval_recall": 0.9033333333333333,
      "eval_runtime": 1094.0139,
      "eval_samples_per_second": 2.742,
      "eval_steps_per_second": 0.914,
      "step": 41994
    },
    {
      "epoch": 9.001285897985426,
      "grad_norm": 0.00015920815349090844,
      "learning_rate": 7.998285469352765e-06,
      "loss": 0.0,
      "step": 42000
    },
    {
      "epoch": 9.00342906129447,
      "grad_norm": 0.00021061347797513008,
      "learning_rate": 7.995427918274041e-06,
      "loss": 0.0001,
      "step": 42010
    },
    {
      "epoch": 9.005572224603515,
      "grad_norm": 0.00018360030662734061,
      "learning_rate": 7.992570367195315e-06,
      "loss": 0.0,
      "step": 42020
    },
    {
      "epoch": 9.007715387912558,
      "grad_norm": 0.000955471710767597,
      "learning_rate": 7.989712816116589e-06,
      "loss": 0.0001,
      "step": 42030
    },
    {
      "epoch": 9.009858551221603,
      "grad_norm": 0.01207209937274456,
      "learning_rate": 7.986855265037863e-06,
      "loss": 0.0863,
      "step": 42040
    },
    {
      "epoch": 9.012001714530648,
      "grad_norm": 0.00020440483058337122,
      "learning_rate": 7.983997713959137e-06,
      "loss": 0.0,
      "step": 42050
    },
    {
      "epoch": 9.01414487783969,
      "grad_norm": 0.0027842228300869465,
      "learning_rate": 7.981140162880412e-06,
      "loss": 0.0001,
      "step": 42060
    },
    {
      "epoch": 9.016288041148735,
      "grad_norm": 0.01052879448980093,
      "learning_rate": 7.978282611801686e-06,
      "loss": 0.0,
      "step": 42070
    },
    {
      "epoch": 9.01843120445778,
      "grad_norm": 0.00013928901171311736,
      "learning_rate": 7.975425060722962e-06,
      "loss": 0.0,
      "step": 42080
    },
    {
      "epoch": 9.020574367766823,
      "grad_norm": 0.002361321821808815,
      "learning_rate": 7.972567509644236e-06,
      "loss": 0.0739,
      "step": 42090
    },
    {
      "epoch": 9.022717531075868,
      "grad_norm": 0.0005672999541275203,
      "learning_rate": 7.96970995856551e-06,
      "loss": 0.0,
      "step": 42100
    },
    {
      "epoch": 9.024860694384913,
      "grad_norm": 0.001689830794930458,
      "learning_rate": 7.966852407486785e-06,
      "loss": 0.0,
      "step": 42110
    },
    {
      "epoch": 9.027003857693956,
      "grad_norm": 0.00015290654846467078,
      "learning_rate": 7.96399485640806e-06,
      "loss": 0.0,
      "step": 42120
    },
    {
      "epoch": 9.029147021003,
      "grad_norm": 0.00020226591732352972,
      "learning_rate": 7.961137305329333e-06,
      "loss": 0.0402,
      "step": 42130
    },
    {
      "epoch": 9.031290184312045,
      "grad_norm": 0.00024255362222902477,
      "learning_rate": 7.958279754250607e-06,
      "loss": 0.0135,
      "step": 42140
    },
    {
      "epoch": 9.033433347621088,
      "grad_norm": 0.18230748176574707,
      "learning_rate": 7.955422203171883e-06,
      "loss": 0.1963,
      "step": 42150
    },
    {
      "epoch": 9.035576510930133,
      "grad_norm": 0.0025849409867078066,
      "learning_rate": 7.952564652093157e-06,
      "loss": 0.0,
      "step": 42160
    },
    {
      "epoch": 9.037719674239177,
      "grad_norm": 0.00023054513440001756,
      "learning_rate": 7.94970710101443e-06,
      "loss": 0.1348,
      "step": 42170
    },
    {
      "epoch": 9.03986283754822,
      "grad_norm": 0.0003544754581525922,
      "learning_rate": 7.946849549935706e-06,
      "loss": 0.1124,
      "step": 42180
    },
    {
      "epoch": 9.042006000857265,
      "grad_norm": 0.013049852102994919,
      "learning_rate": 7.94399199885698e-06,
      "loss": 0.0098,
      "step": 42190
    },
    {
      "epoch": 9.04414916416631,
      "grad_norm": 0.17864279448986053,
      "learning_rate": 7.941134447778254e-06,
      "loss": 0.0034,
      "step": 42200
    },
    {
      "epoch": 9.046292327475353,
      "grad_norm": 0.00013069971464574337,
      "learning_rate": 7.93827689669953e-06,
      "loss": 0.0028,
      "step": 42210
    },
    {
      "epoch": 9.048435490784398,
      "grad_norm": 0.0001559249358251691,
      "learning_rate": 7.935419345620804e-06,
      "loss": 0.0,
      "step": 42220
    },
    {
      "epoch": 9.050578654093442,
      "grad_norm": 9.771748591447249e-05,
      "learning_rate": 7.93256179454208e-06,
      "loss": 0.0003,
      "step": 42230
    },
    {
      "epoch": 9.052721817402485,
      "grad_norm": 9.160863555734977e-05,
      "learning_rate": 7.929704243463353e-06,
      "loss": 0.1614,
      "step": 42240
    },
    {
      "epoch": 9.05486498071153,
      "grad_norm": 0.0001479839120293036,
      "learning_rate": 7.926846692384627e-06,
      "loss": 0.0003,
      "step": 42250
    },
    {
      "epoch": 9.057008144020575,
      "grad_norm": 0.0020878289360553026,
      "learning_rate": 7.923989141305901e-06,
      "loss": 0.0,
      "step": 42260
    },
    {
      "epoch": 9.059151307329618,
      "grad_norm": 0.00010343074245611206,
      "learning_rate": 7.921131590227175e-06,
      "loss": 0.0,
      "step": 42270
    },
    {
      "epoch": 9.061294470638662,
      "grad_norm": 0.017987890169024467,
      "learning_rate": 7.91827403914845e-06,
      "loss": 0.0,
      "step": 42280
    },
    {
      "epoch": 9.063437633947707,
      "grad_norm": 0.0012326299911364913,
      "learning_rate": 7.915416488069725e-06,
      "loss": 0.0,
      "step": 42290
    },
    {
      "epoch": 9.06558079725675,
      "grad_norm": 0.000889378075953573,
      "learning_rate": 7.912558936991e-06,
      "loss": 0.1846,
      "step": 42300
    },
    {
      "epoch": 9.067723960565795,
      "grad_norm": 0.00030523655004799366,
      "learning_rate": 7.909701385912274e-06,
      "loss": 0.0,
      "step": 42310
    },
    {
      "epoch": 9.06986712387484,
      "grad_norm": 0.012071240693330765,
      "learning_rate": 7.906843834833548e-06,
      "loss": 0.0,
      "step": 42320
    },
    {
      "epoch": 9.072010287183883,
      "grad_norm": 0.00011673315748339519,
      "learning_rate": 7.903986283754824e-06,
      "loss": 0.0002,
      "step": 42330
    },
    {
      "epoch": 9.074153450492927,
      "grad_norm": 0.0002419576921965927,
      "learning_rate": 7.901128732676098e-06,
      "loss": 0.0044,
      "step": 42340
    },
    {
      "epoch": 9.076296613801972,
      "grad_norm": 0.00031369709176942706,
      "learning_rate": 7.898271181597371e-06,
      "loss": 0.0,
      "step": 42350
    },
    {
      "epoch": 9.078439777111015,
      "grad_norm": 0.0015828891191631556,
      "learning_rate": 7.895413630518645e-06,
      "loss": 0.0,
      "step": 42360
    },
    {
      "epoch": 9.08058294042006,
      "grad_norm": 0.00041038900963030756,
      "learning_rate": 7.892556079439921e-06,
      "loss": 0.0,
      "step": 42370
    },
    {
      "epoch": 9.082726103729104,
      "grad_norm": 0.00014453065523412079,
      "learning_rate": 7.889698528361195e-06,
      "loss": 0.0,
      "step": 42380
    },
    {
      "epoch": 9.084869267038147,
      "grad_norm": 0.0019898395985364914,
      "learning_rate": 7.886840977282469e-06,
      "loss": 0.0002,
      "step": 42390
    },
    {
      "epoch": 9.087012430347192,
      "grad_norm": 0.000536249135620892,
      "learning_rate": 7.883983426203745e-06,
      "loss": 0.2686,
      "step": 42400
    },
    {
      "epoch": 9.089155593656237,
      "grad_norm": 0.00028670980827882886,
      "learning_rate": 7.881125875125018e-06,
      "loss": 0.0,
      "step": 42410
    },
    {
      "epoch": 9.09129875696528,
      "grad_norm": 0.0002857130893971771,
      "learning_rate": 7.878268324046292e-06,
      "loss": 0.0,
      "step": 42420
    },
    {
      "epoch": 9.093441920274325,
      "grad_norm": 0.00021155053400434554,
      "learning_rate": 7.875410772967568e-06,
      "loss": 0.0005,
      "step": 42430
    },
    {
      "epoch": 9.09558508358337,
      "grad_norm": 0.002271172823384404,
      "learning_rate": 7.872553221888842e-06,
      "loss": 0.0,
      "step": 42440
    },
    {
      "epoch": 9.097728246892412,
      "grad_norm": 0.0014507347950711846,
      "learning_rate": 7.869695670810118e-06,
      "loss": 0.0,
      "step": 42450
    },
    {
      "epoch": 9.099871410201457,
      "grad_norm": 0.02817084826529026,
      "learning_rate": 7.86683811973139e-06,
      "loss": 0.0,
      "step": 42460
    },
    {
      "epoch": 9.102014573510502,
      "grad_norm": 0.002990482607856393,
      "learning_rate": 7.863980568652665e-06,
      "loss": 0.0009,
      "step": 42470
    },
    {
      "epoch": 9.104157736819545,
      "grad_norm": 0.009571376256644726,
      "learning_rate": 7.86112301757394e-06,
      "loss": 0.1224,
      "step": 42480
    },
    {
      "epoch": 9.10630090012859,
      "grad_norm": 0.059353578835725784,
      "learning_rate": 7.858265466495213e-06,
      "loss": 0.0003,
      "step": 42490
    },
    {
      "epoch": 9.108444063437634,
      "grad_norm": 0.0007598968222737312,
      "learning_rate": 7.855407915416489e-06,
      "loss": 0.0,
      "step": 42500
    },
    {
      "epoch": 9.110587226746677,
      "grad_norm": 0.0002883632550947368,
      "learning_rate": 7.852550364337763e-06,
      "loss": 0.0,
      "step": 42510
    },
    {
      "epoch": 9.112730390055722,
      "grad_norm": 0.001705994363874197,
      "learning_rate": 7.849692813259038e-06,
      "loss": 0.013,
      "step": 42520
    },
    {
      "epoch": 9.114873553364767,
      "grad_norm": 0.00013906355889048427,
      "learning_rate": 7.846835262180312e-06,
      "loss": 0.0,
      "step": 42530
    },
    {
      "epoch": 9.117016716673811,
      "grad_norm": 0.0019459103932604194,
      "learning_rate": 7.843977711101586e-06,
      "loss": 0.0011,
      "step": 42540
    },
    {
      "epoch": 9.119159879982854,
      "grad_norm": 0.00016681154374964535,
      "learning_rate": 7.841120160022862e-06,
      "loss": 0.0,
      "step": 42550
    },
    {
      "epoch": 9.1213030432919,
      "grad_norm": 0.0003459653235040605,
      "learning_rate": 7.838262608944136e-06,
      "loss": 0.0,
      "step": 42560
    },
    {
      "epoch": 9.123446206600944,
      "grad_norm": 0.00014080695109441876,
      "learning_rate": 7.83540505786541e-06,
      "loss": 0.0,
      "step": 42570
    },
    {
      "epoch": 9.125589369909987,
      "grad_norm": 0.00014941900735720992,
      "learning_rate": 7.832547506786684e-06,
      "loss": 0.0,
      "step": 42580
    },
    {
      "epoch": 9.127732533219032,
      "grad_norm": 0.00011153514060424641,
      "learning_rate": 7.82968995570796e-06,
      "loss": 0.0001,
      "step": 42590
    },
    {
      "epoch": 9.129875696528076,
      "grad_norm": 0.0017594221280887723,
      "learning_rate": 7.826832404629233e-06,
      "loss": 0.1792,
      "step": 42600
    },
    {
      "epoch": 9.13201885983712,
      "grad_norm": 0.00013577495701611042,
      "learning_rate": 7.823974853550507e-06,
      "loss": 0.0001,
      "step": 42610
    },
    {
      "epoch": 9.134162023146164,
      "grad_norm": 9.688161662779748e-05,
      "learning_rate": 7.821117302471783e-06,
      "loss": 0.0,
      "step": 42620
    },
    {
      "epoch": 9.136305186455209,
      "grad_norm": 0.00010687472968129441,
      "learning_rate": 7.818259751393057e-06,
      "loss": 0.0,
      "step": 42630
    },
    {
      "epoch": 9.138448349764252,
      "grad_norm": 8.099275873973966e-05,
      "learning_rate": 7.815402200314332e-06,
      "loss": 0.0,
      "step": 42640
    },
    {
      "epoch": 9.140591513073296,
      "grad_norm": 0.022735757753252983,
      "learning_rate": 7.812544649235606e-06,
      "loss": 0.0001,
      "step": 42650
    },
    {
      "epoch": 9.142734676382341,
      "grad_norm": 0.009473057463765144,
      "learning_rate": 7.80968709815688e-06,
      "loss": 0.2173,
      "step": 42660
    },
    {
      "epoch": 9.144877839691384,
      "grad_norm": 0.0011971010826528072,
      "learning_rate": 7.806829547078156e-06,
      "loss": 0.0001,
      "step": 42670
    },
    {
      "epoch": 9.147021003000429,
      "grad_norm": 0.0004142971010878682,
      "learning_rate": 7.803971995999428e-06,
      "loss": 0.0001,
      "step": 42680
    },
    {
      "epoch": 9.149164166309474,
      "grad_norm": 0.00028513421420939267,
      "learning_rate": 7.801114444920704e-06,
      "loss": 0.0002,
      "step": 42690
    },
    {
      "epoch": 9.151307329618517,
      "grad_norm": 0.00030379084637388587,
      "learning_rate": 7.798256893841978e-06,
      "loss": 0.0001,
      "step": 42700
    },
    {
      "epoch": 9.153450492927561,
      "grad_norm": 0.10211276262998581,
      "learning_rate": 7.795399342763253e-06,
      "loss": 0.1322,
      "step": 42710
    },
    {
      "epoch": 9.155593656236606,
      "grad_norm": 0.0005308649851940572,
      "learning_rate": 7.792541791684527e-06,
      "loss": 0.0006,
      "step": 42720
    },
    {
      "epoch": 9.157736819545649,
      "grad_norm": 0.016733042895793915,
      "learning_rate": 7.789684240605801e-06,
      "loss": 0.0001,
      "step": 42730
    },
    {
      "epoch": 9.159879982854694,
      "grad_norm": 0.00016210143803618848,
      "learning_rate": 7.786826689527077e-06,
      "loss": 0.0001,
      "step": 42740
    },
    {
      "epoch": 9.162023146163738,
      "grad_norm": 0.002898365957662463,
      "learning_rate": 7.78396913844835e-06,
      "loss": 0.0174,
      "step": 42750
    },
    {
      "epoch": 9.164166309472781,
      "grad_norm": 0.00017092864436563104,
      "learning_rate": 7.781111587369625e-06,
      "loss": 0.0,
      "step": 42760
    },
    {
      "epoch": 9.166309472781826,
      "grad_norm": 53.09885025024414,
      "learning_rate": 7.7782540362909e-06,
      "loss": 0.0389,
      "step": 42770
    },
    {
      "epoch": 9.168452636090871,
      "grad_norm": 0.00015702359087299556,
      "learning_rate": 7.775396485212174e-06,
      "loss": 0.0,
      "step": 42780
    },
    {
      "epoch": 9.170595799399914,
      "grad_norm": 0.000710060412529856,
      "learning_rate": 7.772538934133448e-06,
      "loss": 0.0,
      "step": 42790
    },
    {
      "epoch": 9.172738962708959,
      "grad_norm": 0.00018704042304307222,
      "learning_rate": 7.769681383054722e-06,
      "loss": 0.0006,
      "step": 42800
    },
    {
      "epoch": 9.174882126018003,
      "grad_norm": 0.0012923437170684338,
      "learning_rate": 7.766823831975998e-06,
      "loss": 0.0004,
      "step": 42810
    },
    {
      "epoch": 9.177025289327046,
      "grad_norm": 0.0013485393719747663,
      "learning_rate": 7.763966280897272e-06,
      "loss": 0.0463,
      "step": 42820
    },
    {
      "epoch": 9.179168452636091,
      "grad_norm": 0.00010101700172526762,
      "learning_rate": 7.761108729818545e-06,
      "loss": 0.0013,
      "step": 42830
    },
    {
      "epoch": 9.181311615945136,
      "grad_norm": 7.917657057987526e-05,
      "learning_rate": 7.758251178739821e-06,
      "loss": 0.0,
      "step": 42840
    },
    {
      "epoch": 9.183454779254179,
      "grad_norm": 0.0010186238214373589,
      "learning_rate": 7.755393627661095e-06,
      "loss": 0.0001,
      "step": 42850
    },
    {
      "epoch": 9.185597942563223,
      "grad_norm": 0.000440056377556175,
      "learning_rate": 7.75253607658237e-06,
      "loss": 0.0,
      "step": 42860
    },
    {
      "epoch": 9.187741105872268,
      "grad_norm": 8.80331572261639e-05,
      "learning_rate": 7.749678525503645e-06,
      "loss": 0.0,
      "step": 42870
    },
    {
      "epoch": 9.189884269181311,
      "grad_norm": 0.0008070959593169391,
      "learning_rate": 7.746820974424918e-06,
      "loss": 0.0,
      "step": 42880
    },
    {
      "epoch": 9.192027432490356,
      "grad_norm": 0.00014184617612045258,
      "learning_rate": 7.743963423346192e-06,
      "loss": 0.1737,
      "step": 42890
    },
    {
      "epoch": 9.1941705957994,
      "grad_norm": 0.00010230517364107072,
      "learning_rate": 7.741105872267466e-06,
      "loss": 0.0,
      "step": 42900
    },
    {
      "epoch": 9.196313759108444,
      "grad_norm": 7.284901948878542e-05,
      "learning_rate": 7.738248321188742e-06,
      "loss": 0.0161,
      "step": 42910
    },
    {
      "epoch": 9.198456922417488,
      "grad_norm": 0.003082706592977047,
      "learning_rate": 7.735390770110016e-06,
      "loss": 0.0,
      "step": 42920
    },
    {
      "epoch": 9.200600085726533,
      "grad_norm": 5.118917761137709e-05,
      "learning_rate": 7.732533219031292e-06,
      "loss": 0.0006,
      "step": 42930
    },
    {
      "epoch": 9.202743249035576,
      "grad_norm": 0.011283676140010357,
      "learning_rate": 7.729675667952565e-06,
      "loss": 0.325,
      "step": 42940
    },
    {
      "epoch": 9.20488641234462,
      "grad_norm": 7.267924956977367e-05,
      "learning_rate": 7.72681811687384e-06,
      "loss": 0.0,
      "step": 42950
    },
    {
      "epoch": 9.207029575653666,
      "grad_norm": 0.0002916974190156907,
      "learning_rate": 7.723960565795115e-06,
      "loss": 0.0007,
      "step": 42960
    },
    {
      "epoch": 9.209172738962708,
      "grad_norm": 7.599189120810479e-05,
      "learning_rate": 7.721103014716389e-06,
      "loss": 0.1791,
      "step": 42970
    },
    {
      "epoch": 9.211315902271753,
      "grad_norm": 0.0008951599593274295,
      "learning_rate": 7.718245463637663e-06,
      "loss": 0.0001,
      "step": 42980
    },
    {
      "epoch": 9.213459065580798,
      "grad_norm": 0.0020257686264812946,
      "learning_rate": 7.715387912558938e-06,
      "loss": 0.0004,
      "step": 42990
    },
    {
      "epoch": 9.215602228889841,
      "grad_norm": 0.003561459481716156,
      "learning_rate": 7.712530361480212e-06,
      "loss": 0.0003,
      "step": 43000
    },
    {
      "epoch": 9.217745392198886,
      "grad_norm": 0.00046242770622484386,
      "learning_rate": 7.709672810401486e-06,
      "loss": 0.0,
      "step": 43010
    },
    {
      "epoch": 9.21988855550793,
      "grad_norm": 0.001917839515954256,
      "learning_rate": 7.70681525932276e-06,
      "loss": 0.0006,
      "step": 43020
    },
    {
      "epoch": 9.222031718816973,
      "grad_norm": 0.000544231035746634,
      "learning_rate": 7.703957708244036e-06,
      "loss": 0.0,
      "step": 43030
    },
    {
      "epoch": 9.224174882126018,
      "grad_norm": 7.082437514327466e-05,
      "learning_rate": 7.70110015716531e-06,
      "loss": 0.0,
      "step": 43040
    },
    {
      "epoch": 9.226318045435063,
      "grad_norm": 7.483187800971791e-05,
      "learning_rate": 7.698242606086584e-06,
      "loss": 0.0,
      "step": 43050
    },
    {
      "epoch": 9.228461208744106,
      "grad_norm": 0.06201133131980896,
      "learning_rate": 7.69538505500786e-06,
      "loss": 0.0001,
      "step": 43060
    },
    {
      "epoch": 9.23060437205315,
      "grad_norm": 0.0001424209331162274,
      "learning_rate": 7.692527503929133e-06,
      "loss": 0.1558,
      "step": 43070
    },
    {
      "epoch": 9.232747535362195,
      "grad_norm": 8.751107088755816e-05,
      "learning_rate": 7.689669952850409e-06,
      "loss": 0.0,
      "step": 43080
    },
    {
      "epoch": 9.234890698671238,
      "grad_norm": 0.00692395307123661,
      "learning_rate": 7.686812401771683e-06,
      "loss": 0.0001,
      "step": 43090
    },
    {
      "epoch": 9.237033861980283,
      "grad_norm": 5.799549398943782e-05,
      "learning_rate": 7.683954850692957e-06,
      "loss": 0.0,
      "step": 43100
    },
    {
      "epoch": 9.239177025289328,
      "grad_norm": 0.008166002109646797,
      "learning_rate": 7.68109729961423e-06,
      "loss": 0.1699,
      "step": 43110
    },
    {
      "epoch": 9.24132018859837,
      "grad_norm": 0.00036010058829560876,
      "learning_rate": 7.678239748535505e-06,
      "loss": 0.0,
      "step": 43120
    },
    {
      "epoch": 9.243463351907415,
      "grad_norm": 0.00011607824126258492,
      "learning_rate": 7.67538219745678e-06,
      "loss": 0.0001,
      "step": 43130
    },
    {
      "epoch": 9.24560651521646,
      "grad_norm": 0.0030069006606936455,
      "learning_rate": 7.672524646378054e-06,
      "loss": 0.0,
      "step": 43140
    },
    {
      "epoch": 9.247749678525503,
      "grad_norm": 0.00017681388999335468,
      "learning_rate": 7.66966709529933e-06,
      "loss": 0.0,
      "step": 43150
    },
    {
      "epoch": 9.249892841834548,
      "grad_norm": 0.0001376488944515586,
      "learning_rate": 7.666809544220604e-06,
      "loss": 0.0,
      "step": 43160
    },
    {
      "epoch": 9.252036005143593,
      "grad_norm": 9.492951357970014e-05,
      "learning_rate": 7.663951993141878e-06,
      "loss": 0.0042,
      "step": 43170
    },
    {
      "epoch": 9.254179168452636,
      "grad_norm": 0.00012026201147818938,
      "learning_rate": 7.661094442063153e-06,
      "loss": 0.0,
      "step": 43180
    },
    {
      "epoch": 9.25632233176168,
      "grad_norm": 7.758710853522643e-05,
      "learning_rate": 7.658236890984427e-06,
      "loss": 0.0,
      "step": 43190
    },
    {
      "epoch": 9.258465495070725,
      "grad_norm": 0.00012279539078008384,
      "learning_rate": 7.655379339905701e-06,
      "loss": 0.0,
      "step": 43200
    },
    {
      "epoch": 9.260608658379768,
      "grad_norm": 0.00012750382302328944,
      "learning_rate": 7.652521788826975e-06,
      "loss": 0.0,
      "step": 43210
    },
    {
      "epoch": 9.262751821688813,
      "grad_norm": 0.004258191678673029,
      "learning_rate": 7.64966423774825e-06,
      "loss": 0.0,
      "step": 43220
    },
    {
      "epoch": 9.264894984997857,
      "grad_norm": 0.0030778178479522467,
      "learning_rate": 7.646806686669525e-06,
      "loss": 0.0002,
      "step": 43230
    },
    {
      "epoch": 9.2670381483069,
      "grad_norm": 7.908984844107181e-05,
      "learning_rate": 7.643949135590799e-06,
      "loss": 0.1648,
      "step": 43240
    },
    {
      "epoch": 9.269181311615945,
      "grad_norm": 0.00013235639198683202,
      "learning_rate": 7.641091584512074e-06,
      "loss": 0.0001,
      "step": 43250
    },
    {
      "epoch": 9.27132447492499,
      "grad_norm": 0.0001647688477532938,
      "learning_rate": 7.638234033433348e-06,
      "loss": 0.0001,
      "step": 43260
    },
    {
      "epoch": 9.273467638234033,
      "grad_norm": 6.90547312842682e-05,
      "learning_rate": 7.635376482354622e-06,
      "loss": 0.0897,
      "step": 43270
    },
    {
      "epoch": 9.275610801543078,
      "grad_norm": 0.4002228379249573,
      "learning_rate": 7.632518931275898e-06,
      "loss": 0.0008,
      "step": 43280
    },
    {
      "epoch": 9.277753964852122,
      "grad_norm": 9.607908577891067e-05,
      "learning_rate": 7.629661380197172e-06,
      "loss": 0.0001,
      "step": 43290
    },
    {
      "epoch": 9.279897128161165,
      "grad_norm": 39.75868225097656,
      "learning_rate": 7.626803829118446e-06,
      "loss": 0.1832,
      "step": 43300
    },
    {
      "epoch": 9.28204029147021,
      "grad_norm": 0.006577080115675926,
      "learning_rate": 7.623946278039721e-06,
      "loss": 0.0,
      "step": 43310
    },
    {
      "epoch": 9.284183454779255,
      "grad_norm": 28.444747924804688,
      "learning_rate": 7.621088726960994e-06,
      "loss": 0.1008,
      "step": 43320
    },
    {
      "epoch": 9.286326618088298,
      "grad_norm": 0.00017061296966858208,
      "learning_rate": 7.618231175882269e-06,
      "loss": 0.0,
      "step": 43330
    },
    {
      "epoch": 9.288469781397342,
      "grad_norm": 8.973389049060643e-05,
      "learning_rate": 7.615373624803544e-06,
      "loss": 0.0,
      "step": 43340
    },
    {
      "epoch": 9.290612944706387,
      "grad_norm": 8.923024142859504e-05,
      "learning_rate": 7.6125160737248185e-06,
      "loss": 0.0,
      "step": 43350
    },
    {
      "epoch": 9.29275610801543,
      "grad_norm": 0.0011317736934870481,
      "learning_rate": 7.6096585226460924e-06,
      "loss": 0.2185,
      "step": 43360
    },
    {
      "epoch": 9.294899271324475,
      "grad_norm": 0.00010510678112041205,
      "learning_rate": 7.606800971567367e-06,
      "loss": 0.0,
      "step": 43370
    },
    {
      "epoch": 9.29704243463352,
      "grad_norm": 0.00011598248238442466,
      "learning_rate": 7.603943420488642e-06,
      "loss": 0.106,
      "step": 43380
    },
    {
      "epoch": 9.299185597942563,
      "grad_norm": 0.0037007788196206093,
      "learning_rate": 7.601085869409917e-06,
      "loss": 0.0,
      "step": 43390
    },
    {
      "epoch": 9.301328761251607,
      "grad_norm": 0.00028730338090099394,
      "learning_rate": 7.5982283183311915e-06,
      "loss": 0.0021,
      "step": 43400
    },
    {
      "epoch": 9.303471924560652,
      "grad_norm": 0.00014571625797543675,
      "learning_rate": 7.5953707672524655e-06,
      "loss": 0.0,
      "step": 43410
    },
    {
      "epoch": 9.305615087869695,
      "grad_norm": 0.00020581016724463552,
      "learning_rate": 7.59251321617374e-06,
      "loss": 0.0001,
      "step": 43420
    },
    {
      "epoch": 9.30775825117874,
      "grad_norm": 0.02634255960583687,
      "learning_rate": 7.589655665095013e-06,
      "loss": 0.0001,
      "step": 43430
    },
    {
      "epoch": 9.309901414487785,
      "grad_norm": 0.00011449617886682972,
      "learning_rate": 7.586798114016288e-06,
      "loss": 0.0004,
      "step": 43440
    },
    {
      "epoch": 9.312044577796827,
      "grad_norm": 0.00030356316710822284,
      "learning_rate": 7.583940562937563e-06,
      "loss": 0.0001,
      "step": 43450
    },
    {
      "epoch": 9.314187741105872,
      "grad_norm": 0.0029474529437720776,
      "learning_rate": 7.581083011858838e-06,
      "loss": 0.0001,
      "step": 43460
    },
    {
      "epoch": 9.316330904414917,
      "grad_norm": 0.0027503282763063908,
      "learning_rate": 7.5782254607801124e-06,
      "loss": 0.2377,
      "step": 43470
    },
    {
      "epoch": 9.31847406772396,
      "grad_norm": 0.00018589683168102056,
      "learning_rate": 7.575367909701386e-06,
      "loss": 0.0,
      "step": 43480
    },
    {
      "epoch": 9.320617231033005,
      "grad_norm": 0.009202437475323677,
      "learning_rate": 7.572510358622661e-06,
      "loss": 0.0003,
      "step": 43490
    },
    {
      "epoch": 9.32276039434205,
      "grad_norm": 0.09134716540575027,
      "learning_rate": 7.569652807543936e-06,
      "loss": 0.0003,
      "step": 43500
    },
    {
      "epoch": 9.324903557651092,
      "grad_norm": 6.366919114952907e-05,
      "learning_rate": 7.566795256465211e-06,
      "loss": 0.0,
      "step": 43510
    },
    {
      "epoch": 9.327046720960137,
      "grad_norm": 0.005537544842809439,
      "learning_rate": 7.563937705386485e-06,
      "loss": 0.0,
      "step": 43520
    },
    {
      "epoch": 9.329189884269182,
      "grad_norm": 0.00014155099052004516,
      "learning_rate": 7.5610801543077585e-06,
      "loss": 0.2854,
      "step": 43530
    },
    {
      "epoch": 9.331333047578225,
      "grad_norm": 0.00022253299539443105,
      "learning_rate": 7.558222603229033e-06,
      "loss": 0.0,
      "step": 43540
    },
    {
      "epoch": 9.33347621088727,
      "grad_norm": 0.00011731340055121109,
      "learning_rate": 7.555365052150307e-06,
      "loss": 0.0005,
      "step": 43550
    },
    {
      "epoch": 9.335619374196314,
      "grad_norm": 0.0002758052432909608,
      "learning_rate": 7.552507501071582e-06,
      "loss": 0.0001,
      "step": 43560
    },
    {
      "epoch": 9.337762537505357,
      "grad_norm": 7.37339723855257e-05,
      "learning_rate": 7.549649949992857e-06,
      "loss": 0.0001,
      "step": 43570
    },
    {
      "epoch": 9.339905700814402,
      "grad_norm": 0.009863530285656452,
      "learning_rate": 7.5467923989141316e-06,
      "loss": 0.0,
      "step": 43580
    },
    {
      "epoch": 9.342048864123447,
      "grad_norm": 0.27570563554763794,
      "learning_rate": 7.5439348478354055e-06,
      "loss": 0.0004,
      "step": 43590
    },
    {
      "epoch": 9.34419202743249,
      "grad_norm": 6.05386339884717e-05,
      "learning_rate": 7.54107729675668e-06,
      "loss": 0.0,
      "step": 43600
    },
    {
      "epoch": 9.346335190741534,
      "grad_norm": 0.0001122172616305761,
      "learning_rate": 7.538219745677955e-06,
      "loss": 0.0001,
      "step": 43610
    },
    {
      "epoch": 9.34847835405058,
      "grad_norm": 7.000915502430871e-05,
      "learning_rate": 7.53536219459923e-06,
      "loss": 0.0005,
      "step": 43620
    },
    {
      "epoch": 9.350621517359622,
      "grad_norm": 6.680307706119493e-05,
      "learning_rate": 7.532504643520504e-06,
      "loss": 0.0001,
      "step": 43630
    },
    {
      "epoch": 9.352764680668667,
      "grad_norm": 4.395383075461723e-05,
      "learning_rate": 7.529647092441778e-06,
      "loss": 0.0057,
      "step": 43640
    },
    {
      "epoch": 9.354907843977712,
      "grad_norm": 0.0001110745215555653,
      "learning_rate": 7.5267895413630525e-06,
      "loss": 0.0,
      "step": 43650
    },
    {
      "epoch": 9.357051007286755,
      "grad_norm": 0.00010357692372053862,
      "learning_rate": 7.523931990284326e-06,
      "loss": 0.0,
      "step": 43660
    },
    {
      "epoch": 9.3591941705958,
      "grad_norm": 6.587909592781216e-05,
      "learning_rate": 7.521074439205601e-06,
      "loss": 0.0,
      "step": 43670
    },
    {
      "epoch": 9.361337333904844,
      "grad_norm": 5.1651917601702735e-05,
      "learning_rate": 7.518216888126876e-06,
      "loss": 0.0,
      "step": 43680
    },
    {
      "epoch": 9.363480497213887,
      "grad_norm": 3.8636844692518935e-05,
      "learning_rate": 7.515359337048151e-06,
      "loss": 0.0,
      "step": 43690
    },
    {
      "epoch": 9.365623660522932,
      "grad_norm": 0.00018225624808110297,
      "learning_rate": 7.512501785969425e-06,
      "loss": 0.0,
      "step": 43700
    },
    {
      "epoch": 9.367766823831976,
      "grad_norm": 0.0031934266444295645,
      "learning_rate": 7.509644234890699e-06,
      "loss": 0.1341,
      "step": 43710
    },
    {
      "epoch": 9.36990998714102,
      "grad_norm": 0.003434297163039446,
      "learning_rate": 7.506786683811974e-06,
      "loss": 0.0,
      "step": 43720
    },
    {
      "epoch": 9.372053150450064,
      "grad_norm": 7.122146053006873e-05,
      "learning_rate": 7.503929132733249e-06,
      "loss": 0.0,
      "step": 43730
    },
    {
      "epoch": 9.374196313759109,
      "grad_norm": 5.608327774098143e-05,
      "learning_rate": 7.501071581654523e-06,
      "loss": 0.0003,
      "step": 43740
    },
    {
      "epoch": 9.376339477068152,
      "grad_norm": 0.014948575757443905,
      "learning_rate": 7.498214030575797e-06,
      "loss": 0.243,
      "step": 43750
    },
    {
      "epoch": 9.378482640377197,
      "grad_norm": 0.00014620581350754946,
      "learning_rate": 7.495356479497072e-06,
      "loss": 0.0,
      "step": 43760
    },
    {
      "epoch": 9.380625803686241,
      "grad_norm": 7.560685480711982e-05,
      "learning_rate": 7.4924989284183455e-06,
      "loss": 0.1752,
      "step": 43770
    },
    {
      "epoch": 9.382768966995284,
      "grad_norm": 0.024810191243886948,
      "learning_rate": 7.48964137733962e-06,
      "loss": 0.0001,
      "step": 43780
    },
    {
      "epoch": 9.384912130304329,
      "grad_norm": 0.005415141582489014,
      "learning_rate": 7.486783826260895e-06,
      "loss": 0.0,
      "step": 43790
    },
    {
      "epoch": 9.387055293613374,
      "grad_norm": 0.00010944549285341054,
      "learning_rate": 7.48392627518217e-06,
      "loss": 0.0001,
      "step": 43800
    },
    {
      "epoch": 9.389198456922417,
      "grad_norm": 0.005239918362349272,
      "learning_rate": 7.481068724103444e-06,
      "loss": 0.0,
      "step": 43810
    },
    {
      "epoch": 9.391341620231461,
      "grad_norm": 0.02559678629040718,
      "learning_rate": 7.4782111730247186e-06,
      "loss": 0.0006,
      "step": 43820
    },
    {
      "epoch": 9.393484783540506,
      "grad_norm": 7.919582276372239e-05,
      "learning_rate": 7.475353621945993e-06,
      "loss": 0.0001,
      "step": 43830
    },
    {
      "epoch": 9.39562794684955,
      "grad_norm": 8.09946795925498e-05,
      "learning_rate": 7.472496070867268e-06,
      "loss": 0.0002,
      "step": 43840
    },
    {
      "epoch": 9.397771110158594,
      "grad_norm": 8.234572305809706e-05,
      "learning_rate": 7.469638519788542e-06,
      "loss": 0.0001,
      "step": 43850
    },
    {
      "epoch": 9.399914273467639,
      "grad_norm": 0.003067668527364731,
      "learning_rate": 7.466780968709816e-06,
      "loss": 0.0001,
      "step": 43860
    },
    {
      "epoch": 9.402057436776682,
      "grad_norm": 6.770484469598159e-05,
      "learning_rate": 7.463923417631091e-06,
      "loss": 0.0002,
      "step": 43870
    },
    {
      "epoch": 9.404200600085726,
      "grad_norm": 0.0009462532470934093,
      "learning_rate": 7.461065866552365e-06,
      "loss": 0.0221,
      "step": 43880
    },
    {
      "epoch": 9.406343763394771,
      "grad_norm": 0.00011307146633043885,
      "learning_rate": 7.4582083154736394e-06,
      "loss": 0.0,
      "step": 43890
    },
    {
      "epoch": 9.408486926703814,
      "grad_norm": 0.0022503912914544344,
      "learning_rate": 7.455350764394914e-06,
      "loss": 0.0,
      "step": 43900
    },
    {
      "epoch": 9.410630090012859,
      "grad_norm": 0.0021047138143330812,
      "learning_rate": 7.452493213316189e-06,
      "loss": 0.0001,
      "step": 43910
    },
    {
      "epoch": 9.412773253321904,
      "grad_norm": 8.359376806765795e-05,
      "learning_rate": 7.449635662237463e-06,
      "loss": 0.1828,
      "step": 43920
    },
    {
      "epoch": 9.414916416630946,
      "grad_norm": 0.004849323537200689,
      "learning_rate": 7.446778111158738e-06,
      "loss": 0.0,
      "step": 43930
    },
    {
      "epoch": 9.417059579939991,
      "grad_norm": 9.034313552547246e-05,
      "learning_rate": 7.4439205600800125e-06,
      "loss": 0.0581,
      "step": 43940
    },
    {
      "epoch": 9.419202743249036,
      "grad_norm": 136.68031311035156,
      "learning_rate": 7.441063009001287e-06,
      "loss": 0.1806,
      "step": 43950
    },
    {
      "epoch": 9.421345906558079,
      "grad_norm": 5.91542266192846e-05,
      "learning_rate": 7.43820545792256e-06,
      "loss": 0.0,
      "step": 43960
    },
    {
      "epoch": 9.423489069867124,
      "grad_norm": 8.331907156389207e-05,
      "learning_rate": 7.435347906843835e-06,
      "loss": 0.0189,
      "step": 43970
    },
    {
      "epoch": 9.425632233176168,
      "grad_norm": 8.048181189224124e-05,
      "learning_rate": 7.43249035576511e-06,
      "loss": 0.0,
      "step": 43980
    },
    {
      "epoch": 9.427775396485211,
      "grad_norm": 0.007936442270874977,
      "learning_rate": 7.429632804686384e-06,
      "loss": 0.0001,
      "step": 43990
    },
    {
      "epoch": 9.429918559794256,
      "grad_norm": 0.00010931417637038976,
      "learning_rate": 7.426775253607659e-06,
      "loss": 0.0998,
      "step": 44000
    },
    {
      "epoch": 9.4320617231033,
      "grad_norm": 6.956378638278693e-05,
      "learning_rate": 7.423917702528933e-06,
      "loss": 0.0001,
      "step": 44010
    },
    {
      "epoch": 9.434204886412344,
      "grad_norm": 0.00015577809244859964,
      "learning_rate": 7.421060151450208e-06,
      "loss": 0.0,
      "step": 44020
    },
    {
      "epoch": 9.436348049721389,
      "grad_norm": 0.004014430567622185,
      "learning_rate": 7.418202600371482e-06,
      "loss": 0.0001,
      "step": 44030
    },
    {
      "epoch": 9.438491213030433,
      "grad_norm": 6.863752059871331e-05,
      "learning_rate": 7.415345049292757e-06,
      "loss": 0.0001,
      "step": 44040
    },
    {
      "epoch": 9.440634376339476,
      "grad_norm": 5.273186252452433e-05,
      "learning_rate": 7.412487498214032e-06,
      "loss": 0.0,
      "step": 44050
    },
    {
      "epoch": 9.442777539648521,
      "grad_norm": 5.391754530137405e-05,
      "learning_rate": 7.409629947135306e-06,
      "loss": 0.0,
      "step": 44060
    },
    {
      "epoch": 9.444920702957566,
      "grad_norm": 0.0002554187667556107,
      "learning_rate": 7.4067723960565795e-06,
      "loss": 0.0,
      "step": 44070
    },
    {
      "epoch": 9.447063866266609,
      "grad_norm": 0.002612685551866889,
      "learning_rate": 7.403914844977854e-06,
      "loss": 0.0,
      "step": 44080
    },
    {
      "epoch": 9.449207029575653,
      "grad_norm": 7.054606976453215e-05,
      "learning_rate": 7.401057293899129e-06,
      "loss": 0.1273,
      "step": 44090
    },
    {
      "epoch": 9.451350192884698,
      "grad_norm": 7.833929703338072e-05,
      "learning_rate": 7.398199742820403e-06,
      "loss": 0.1406,
      "step": 44100
    },
    {
      "epoch": 9.453493356193743,
      "grad_norm": 7.46466321288608e-05,
      "learning_rate": 7.395342191741678e-06,
      "loss": 0.0001,
      "step": 44110
    },
    {
      "epoch": 9.455636519502786,
      "grad_norm": 5.3511081205215305e-05,
      "learning_rate": 7.3924846406629525e-06,
      "loss": 0.032,
      "step": 44120
    },
    {
      "epoch": 9.45777968281183,
      "grad_norm": 0.009004606865346432,
      "learning_rate": 7.389627089584227e-06,
      "loss": 0.0003,
      "step": 44130
    },
    {
      "epoch": 9.459922846120875,
      "grad_norm": 0.0014879259979352355,
      "learning_rate": 7.386769538505501e-06,
      "loss": 0.0,
      "step": 44140
    },
    {
      "epoch": 9.462066009429918,
      "grad_norm": 0.0036319775972515345,
      "learning_rate": 7.383911987426776e-06,
      "loss": 0.0005,
      "step": 44150
    },
    {
      "epoch": 9.464209172738963,
      "grad_norm": 5.1275619625812396e-05,
      "learning_rate": 7.381054436348051e-06,
      "loss": 0.0004,
      "step": 44160
    },
    {
      "epoch": 9.466352336048008,
      "grad_norm": 4.7409135731868446e-05,
      "learning_rate": 7.3781968852693255e-06,
      "loss": 0.0,
      "step": 44170
    },
    {
      "epoch": 9.46849549935705,
      "grad_norm": 0.030756544321775436,
      "learning_rate": 7.375339334190599e-06,
      "loss": 0.0,
      "step": 44180
    },
    {
      "epoch": 9.470638662666095,
      "grad_norm": 0.003724822774529457,
      "learning_rate": 7.372481783111873e-06,
      "loss": 0.0,
      "step": 44190
    },
    {
      "epoch": 9.47278182597514,
      "grad_norm": 4.946195622324012e-05,
      "learning_rate": 7.369624232033148e-06,
      "loss": 0.0,
      "step": 44200
    },
    {
      "epoch": 9.474924989284183,
      "grad_norm": 4.468506813282147e-05,
      "learning_rate": 7.366766680954422e-06,
      "loss": 0.0004,
      "step": 44210
    },
    {
      "epoch": 9.477068152593228,
      "grad_norm": 6.447682972066104e-05,
      "learning_rate": 7.363909129875697e-06,
      "loss": 0.0016,
      "step": 44220
    },
    {
      "epoch": 9.479211315902273,
      "grad_norm": 3.780755287152715e-05,
      "learning_rate": 7.361051578796972e-06,
      "loss": 0.0002,
      "step": 44230
    },
    {
      "epoch": 9.481354479211316,
      "grad_norm": 4.329612784204073e-05,
      "learning_rate": 7.358194027718246e-06,
      "loss": 0.0005,
      "step": 44240
    },
    {
      "epoch": 9.48349764252036,
      "grad_norm": 4.086142871528864e-05,
      "learning_rate": 7.355336476639521e-06,
      "loss": 0.0,
      "step": 44250
    },
    {
      "epoch": 9.485640805829405,
      "grad_norm": 4.409507164382376e-05,
      "learning_rate": 7.352478925560795e-06,
      "loss": 0.0,
      "step": 44260
    },
    {
      "epoch": 9.487783969138448,
      "grad_norm": 7.286272739293054e-05,
      "learning_rate": 7.34962137448207e-06,
      "loss": 0.0001,
      "step": 44270
    },
    {
      "epoch": 9.489927132447493,
      "grad_norm": 6.873745587654412e-05,
      "learning_rate": 7.346763823403345e-06,
      "loss": 0.7419,
      "step": 44280
    },
    {
      "epoch": 9.492070295756537,
      "grad_norm": 0.016232775524258614,
      "learning_rate": 7.343906272324618e-06,
      "loss": 0.0001,
      "step": 44290
    },
    {
      "epoch": 9.49421345906558,
      "grad_norm": 0.0016098904889076948,
      "learning_rate": 7.3410487212458925e-06,
      "loss": 0.0004,
      "step": 44300
    },
    {
      "epoch": 9.496356622374625,
      "grad_norm": 0.0013589563313871622,
      "learning_rate": 7.338191170167167e-06,
      "loss": 0.0002,
      "step": 44310
    },
    {
      "epoch": 9.49849978568367,
      "grad_norm": 0.002983326092362404,
      "learning_rate": 7.335333619088442e-06,
      "loss": 0.0002,
      "step": 44320
    },
    {
      "epoch": 9.500642948992713,
      "grad_norm": 0.0016402098117396235,
      "learning_rate": 7.332476068009716e-06,
      "loss": 0.0002,
      "step": 44330
    },
    {
      "epoch": 9.502786112301758,
      "grad_norm": 0.0008131303475238383,
      "learning_rate": 7.329618516930991e-06,
      "loss": 0.0102,
      "step": 44340
    },
    {
      "epoch": 9.504929275610802,
      "grad_norm": 0.0005447362782433629,
      "learning_rate": 7.3267609658522655e-06,
      "loss": 0.0014,
      "step": 44350
    },
    {
      "epoch": 9.507072438919845,
      "grad_norm": 23.90998077392578,
      "learning_rate": 7.32390341477354e-06,
      "loss": 0.3091,
      "step": 44360
    },
    {
      "epoch": 9.50921560222889,
      "grad_norm": 0.0043393876403570175,
      "learning_rate": 7.321045863694814e-06,
      "loss": 0.0012,
      "step": 44370
    },
    {
      "epoch": 9.511358765537935,
      "grad_norm": 0.01911318674683571,
      "learning_rate": 7.318188312616089e-06,
      "loss": 0.0002,
      "step": 44380
    },
    {
      "epoch": 9.513501928846978,
      "grad_norm": 0.007551930844783783,
      "learning_rate": 7.315330761537363e-06,
      "loss": 0.0003,
      "step": 44390
    },
    {
      "epoch": 9.515645092156022,
      "grad_norm": 0.005224902648478746,
      "learning_rate": 7.312473210458637e-06,
      "loss": 0.0004,
      "step": 44400
    },
    {
      "epoch": 9.517788255465067,
      "grad_norm": 0.024605117738246918,
      "learning_rate": 7.309615659379912e-06,
      "loss": 0.0044,
      "step": 44410
    },
    {
      "epoch": 9.51993141877411,
      "grad_norm": 0.001962818671017885,
      "learning_rate": 7.3067581083011864e-06,
      "loss": 0.0004,
      "step": 44420
    },
    {
      "epoch": 9.522074582083155,
      "grad_norm": 0.013552388176321983,
      "learning_rate": 7.303900557222461e-06,
      "loss": 0.0001,
      "step": 44430
    },
    {
      "epoch": 9.5242177453922,
      "grad_norm": 0.007233253214508295,
      "learning_rate": 7.301043006143735e-06,
      "loss": 0.0001,
      "step": 44440
    },
    {
      "epoch": 9.526360908701243,
      "grad_norm": 0.019100811332464218,
      "learning_rate": 7.29818545506501e-06,
      "loss": 0.0001,
      "step": 44450
    },
    {
      "epoch": 9.528504072010287,
      "grad_norm": 0.0009875576943159103,
      "learning_rate": 7.295327903986285e-06,
      "loss": 0.1817,
      "step": 44460
    },
    {
      "epoch": 9.530647235319332,
      "grad_norm": 0.010066557675600052,
      "learning_rate": 7.2924703529075595e-06,
      "loss": 0.0001,
      "step": 44470
    },
    {
      "epoch": 9.532790398628375,
      "grad_norm": 0.007312269881367683,
      "learning_rate": 7.289612801828833e-06,
      "loss": 0.0265,
      "step": 44480
    },
    {
      "epoch": 9.53493356193742,
      "grad_norm": 0.0012264723191037774,
      "learning_rate": 7.286755250750108e-06,
      "loss": 0.0002,
      "step": 44490
    },
    {
      "epoch": 9.537076725246465,
      "grad_norm": 0.003469631774351001,
      "learning_rate": 7.283897699671382e-06,
      "loss": 0.0001,
      "step": 44500
    },
    {
      "epoch": 9.539219888555508,
      "grad_norm": 0.002645784290507436,
      "learning_rate": 7.281040148592656e-06,
      "loss": 0.0,
      "step": 44510
    },
    {
      "epoch": 9.541363051864552,
      "grad_norm": 0.00065134052420035,
      "learning_rate": 7.278182597513931e-06,
      "loss": 0.0001,
      "step": 44520
    },
    {
      "epoch": 9.543506215173597,
      "grad_norm": 0.0023279180750250816,
      "learning_rate": 7.2753250464352056e-06,
      "loss": 0.0,
      "step": 44530
    },
    {
      "epoch": 9.54564937848264,
      "grad_norm": 0.006340413819998503,
      "learning_rate": 7.27246749535648e-06,
      "loss": 0.0003,
      "step": 44540
    },
    {
      "epoch": 9.547792541791685,
      "grad_norm": 0.0007956007029861212,
      "learning_rate": 7.269609944277754e-06,
      "loss": 0.0,
      "step": 44550
    },
    {
      "epoch": 9.54993570510073,
      "grad_norm": 0.00041138989035971463,
      "learning_rate": 7.266752393199029e-06,
      "loss": 0.0002,
      "step": 44560
    },
    {
      "epoch": 9.552078868409772,
      "grad_norm": 0.0005174002726562321,
      "learning_rate": 7.263894842120304e-06,
      "loss": 0.0,
      "step": 44570
    },
    {
      "epoch": 9.554222031718817,
      "grad_norm": 0.0005384216201491654,
      "learning_rate": 7.261037291041579e-06,
      "loss": 0.0,
      "step": 44580
    },
    {
      "epoch": 9.556365195027862,
      "grad_norm": 0.0003441559092607349,
      "learning_rate": 7.2581797399628525e-06,
      "loss": 0.0,
      "step": 44590
    },
    {
      "epoch": 9.558508358336905,
      "grad_norm": 0.0009260759688913822,
      "learning_rate": 7.255322188884127e-06,
      "loss": 0.1454,
      "step": 44600
    },
    {
      "epoch": 9.56065152164595,
      "grad_norm": 0.0002741007483564317,
      "learning_rate": 7.252464637805401e-06,
      "loss": 0.0007,
      "step": 44610
    },
    {
      "epoch": 9.562794684954994,
      "grad_norm": 0.0003419677959755063,
      "learning_rate": 7.249607086726675e-06,
      "loss": 0.0,
      "step": 44620
    },
    {
      "epoch": 9.564937848264037,
      "grad_norm": 0.0012452179798856378,
      "learning_rate": 7.24674953564795e-06,
      "loss": 0.0002,
      "step": 44630
    },
    {
      "epoch": 9.567081011573082,
      "grad_norm": 0.008494485169649124,
      "learning_rate": 7.243891984569225e-06,
      "loss": 0.0,
      "step": 44640
    },
    {
      "epoch": 9.569224174882127,
      "grad_norm": 0.000300749612506479,
      "learning_rate": 7.2410344334904995e-06,
      "loss": 0.0003,
      "step": 44650
    },
    {
      "epoch": 9.57136733819117,
      "grad_norm": 0.0008538411930203438,
      "learning_rate": 7.238176882411773e-06,
      "loss": 0.0,
      "step": 44660
    },
    {
      "epoch": 9.573510501500214,
      "grad_norm": 0.00018797555821947753,
      "learning_rate": 7.235319331333048e-06,
      "loss": 0.0001,
      "step": 44670
    },
    {
      "epoch": 9.57565366480926,
      "grad_norm": 17.982341766357422,
      "learning_rate": 7.232461780254323e-06,
      "loss": 0.2776,
      "step": 44680
    },
    {
      "epoch": 9.577796828118302,
      "grad_norm": 0.0034242335241287947,
      "learning_rate": 7.229604229175598e-06,
      "loss": 0.0022,
      "step": 44690
    },
    {
      "epoch": 9.579939991427347,
      "grad_norm": 0.0006351482006721199,
      "learning_rate": 7.226746678096872e-06,
      "loss": 0.0,
      "step": 44700
    },
    {
      "epoch": 9.582083154736392,
      "grad_norm": 0.00044033300946466625,
      "learning_rate": 7.223889127018146e-06,
      "loss": 0.0,
      "step": 44710
    },
    {
      "epoch": 9.584226318045435,
      "grad_norm": 0.00020800306810997427,
      "learning_rate": 7.22103157593942e-06,
      "loss": 0.0001,
      "step": 44720
    },
    {
      "epoch": 9.58636948135448,
      "grad_norm": 0.01194097101688385,
      "learning_rate": 7.218174024860694e-06,
      "loss": 0.0001,
      "step": 44730
    },
    {
      "epoch": 9.588512644663524,
      "grad_norm": 0.0004987725988030434,
      "learning_rate": 7.215316473781969e-06,
      "loss": 0.0001,
      "step": 44740
    },
    {
      "epoch": 9.590655807972567,
      "grad_norm": 0.0005199421430006623,
      "learning_rate": 7.212458922703244e-06,
      "loss": 0.0,
      "step": 44750
    },
    {
      "epoch": 9.592798971281612,
      "grad_norm": 0.00017136397946160287,
      "learning_rate": 7.209601371624519e-06,
      "loss": 0.0,
      "step": 44760
    },
    {
      "epoch": 9.594942134590656,
      "grad_norm": 0.0004938390920870006,
      "learning_rate": 7.2067438205457926e-06,
      "loss": 0.0003,
      "step": 44770
    },
    {
      "epoch": 9.5970852978997,
      "grad_norm": 0.00043834737152792513,
      "learning_rate": 7.203886269467067e-06,
      "loss": 0.0,
      "step": 44780
    },
    {
      "epoch": 9.599228461208744,
      "grad_norm": 0.010201722383499146,
      "learning_rate": 7.201028718388342e-06,
      "loss": 0.3245,
      "step": 44790
    },
    {
      "epoch": 9.601371624517789,
      "grad_norm": 0.0001803127961466089,
      "learning_rate": 7.198171167309617e-06,
      "loss": 0.0001,
      "step": 44800
    },
    {
      "epoch": 9.603514787826832,
      "grad_norm": 0.0002542675647418946,
      "learning_rate": 7.195313616230891e-06,
      "loss": 0.0,
      "step": 44810
    },
    {
      "epoch": 9.605657951135877,
      "grad_norm": 0.0004203933058306575,
      "learning_rate": 7.192456065152165e-06,
      "loss": 0.0,
      "step": 44820
    },
    {
      "epoch": 9.607801114444921,
      "grad_norm": 0.006235173903405666,
      "learning_rate": 7.1895985140734395e-06,
      "loss": 0.0001,
      "step": 44830
    },
    {
      "epoch": 9.609944277753964,
      "grad_norm": 0.003512617899104953,
      "learning_rate": 7.1867409629947134e-06,
      "loss": 0.0003,
      "step": 44840
    },
    {
      "epoch": 9.612087441063009,
      "grad_norm": 0.002782759489491582,
      "learning_rate": 7.183883411915988e-06,
      "loss": 0.0001,
      "step": 44850
    },
    {
      "epoch": 9.614230604372054,
      "grad_norm": 0.0002369270077906549,
      "learning_rate": 7.181025860837263e-06,
      "loss": 0.0002,
      "step": 44860
    },
    {
      "epoch": 9.616373767681097,
      "grad_norm": 9.393216168973595e-05,
      "learning_rate": 7.178168309758538e-06,
      "loss": 0.0001,
      "step": 44870
    },
    {
      "epoch": 9.618516930990141,
      "grad_norm": 0.00023143926227930933,
      "learning_rate": 7.175310758679812e-06,
      "loss": 0.0,
      "step": 44880
    },
    {
      "epoch": 9.620660094299186,
      "grad_norm": 0.157546266913414,
      "learning_rate": 7.1724532076010865e-06,
      "loss": 0.0003,
      "step": 44890
    },
    {
      "epoch": 9.62280325760823,
      "grad_norm": 0.0002470783656463027,
      "learning_rate": 7.169595656522361e-06,
      "loss": 0.0001,
      "step": 44900
    },
    {
      "epoch": 9.624946420917274,
      "grad_norm": 0.15874245762825012,
      "learning_rate": 7.166738105443636e-06,
      "loss": 0.0003,
      "step": 44910
    },
    {
      "epoch": 9.627089584226319,
      "grad_norm": 0.004631259012967348,
      "learning_rate": 7.16388055436491e-06,
      "loss": 0.0,
      "step": 44920
    },
    {
      "epoch": 9.629232747535362,
      "grad_norm": 0.00020270868844818324,
      "learning_rate": 7.161023003286184e-06,
      "loss": 0.0,
      "step": 44930
    },
    {
      "epoch": 9.631375910844406,
      "grad_norm": 0.0022900928743183613,
      "learning_rate": 7.158165452207459e-06,
      "loss": 0.0,
      "step": 44940
    },
    {
      "epoch": 9.633519074153451,
      "grad_norm": 0.000164428522111848,
      "learning_rate": 7.155307901128733e-06,
      "loss": 0.0002,
      "step": 44950
    },
    {
      "epoch": 9.635662237462494,
      "grad_norm": 29.58256721496582,
      "learning_rate": 7.152450350050007e-06,
      "loss": 0.0832,
      "step": 44960
    },
    {
      "epoch": 9.637805400771539,
      "grad_norm": 0.00020758526807185262,
      "learning_rate": 7.149592798971282e-06,
      "loss": 0.123,
      "step": 44970
    },
    {
      "epoch": 9.639948564080584,
      "grad_norm": 0.0012767048319801688,
      "learning_rate": 7.146735247892557e-06,
      "loss": 0.0001,
      "step": 44980
    },
    {
      "epoch": 9.642091727389626,
      "grad_norm": 0.00021540260058827698,
      "learning_rate": 7.143877696813831e-06,
      "loss": 0.2164,
      "step": 44990
    },
    {
      "epoch": 9.644234890698671,
      "grad_norm": 0.0034925707150250673,
      "learning_rate": 7.141020145735106e-06,
      "loss": 0.0,
      "step": 45000
    },
    {
      "epoch": 9.646378054007716,
      "grad_norm": 0.06775309890508652,
      "learning_rate": 7.13816259465638e-06,
      "loss": 0.0004,
      "step": 45010
    },
    {
      "epoch": 9.648521217316759,
      "grad_norm": 0.0003247791901230812,
      "learning_rate": 7.135305043577655e-06,
      "loss": 0.1797,
      "step": 45020
    },
    {
      "epoch": 9.650664380625804,
      "grad_norm": 0.00036477172398008406,
      "learning_rate": 7.13244749249893e-06,
      "loss": 0.0,
      "step": 45030
    },
    {
      "epoch": 9.652807543934848,
      "grad_norm": 0.021353818476200104,
      "learning_rate": 7.129589941420203e-06,
      "loss": 0.0005,
      "step": 45040
    },
    {
      "epoch": 9.654950707243891,
      "grad_norm": 0.0005247600493021309,
      "learning_rate": 7.126732390341478e-06,
      "loss": 0.0001,
      "step": 45050
    },
    {
      "epoch": 9.657093870552936,
      "grad_norm": 0.0005442466936074197,
      "learning_rate": 7.123874839262752e-06,
      "loss": 0.0005,
      "step": 45060
    },
    {
      "epoch": 9.65923703386198,
      "grad_norm": 0.019105933606624603,
      "learning_rate": 7.1210172881840265e-06,
      "loss": 0.0004,
      "step": 45070
    },
    {
      "epoch": 9.661380197171024,
      "grad_norm": 0.00018415710655972362,
      "learning_rate": 7.118159737105301e-06,
      "loss": 0.0,
      "step": 45080
    },
    {
      "epoch": 9.663523360480069,
      "grad_norm": 0.0017749543767422438,
      "learning_rate": 7.115302186026576e-06,
      "loss": 0.0001,
      "step": 45090
    },
    {
      "epoch": 9.665666523789113,
      "grad_norm": 0.0004903006483800709,
      "learning_rate": 7.112444634947851e-06,
      "loss": 0.1594,
      "step": 45100
    },
    {
      "epoch": 9.667809687098156,
      "grad_norm": 0.021508464589715004,
      "learning_rate": 7.109587083869125e-06,
      "loss": 0.0003,
      "step": 45110
    },
    {
      "epoch": 9.669952850407201,
      "grad_norm": 0.031394001096487045,
      "learning_rate": 7.1067295327903995e-06,
      "loss": 0.1814,
      "step": 45120
    },
    {
      "epoch": 9.672096013716246,
      "grad_norm": 0.0038904696702957153,
      "learning_rate": 7.103871981711674e-06,
      "loss": 0.0,
      "step": 45130
    },
    {
      "epoch": 9.674239177025289,
      "grad_norm": 0.016962885856628418,
      "learning_rate": 7.101014430632947e-06,
      "loss": 0.0003,
      "step": 45140
    },
    {
      "epoch": 9.676382340334333,
      "grad_norm": 0.00013939433847554028,
      "learning_rate": 7.098156879554222e-06,
      "loss": 0.0002,
      "step": 45150
    },
    {
      "epoch": 9.678525503643378,
      "grad_norm": 0.0015167584642767906,
      "learning_rate": 7.095299328475497e-06,
      "loss": 0.0,
      "step": 45160
    },
    {
      "epoch": 9.680668666952421,
      "grad_norm": 0.04456642270088196,
      "learning_rate": 7.092441777396772e-06,
      "loss": 0.0005,
      "step": 45170
    },
    {
      "epoch": 9.682811830261466,
      "grad_norm": 0.002430415479466319,
      "learning_rate": 7.089584226318046e-06,
      "loss": 0.0011,
      "step": 45180
    },
    {
      "epoch": 9.68495499357051,
      "grad_norm": 0.0001341198367299512,
      "learning_rate": 7.08672667523932e-06,
      "loss": 0.1603,
      "step": 45190
    },
    {
      "epoch": 9.687098156879554,
      "grad_norm": 0.0013340422883629799,
      "learning_rate": 7.083869124160595e-06,
      "loss": 0.0003,
      "step": 45200
    },
    {
      "epoch": 9.689241320188598,
      "grad_norm": 9.155279258266091e-05,
      "learning_rate": 7.08101157308187e-06,
      "loss": 0.0,
      "step": 45210
    },
    {
      "epoch": 9.691384483497643,
      "grad_norm": 0.003444586182013154,
      "learning_rate": 7.078154022003144e-06,
      "loss": 0.0,
      "step": 45220
    },
    {
      "epoch": 9.693527646806686,
      "grad_norm": 8.609962969785556e-05,
      "learning_rate": 7.075296470924419e-06,
      "loss": 0.0001,
      "step": 45230
    },
    {
      "epoch": 9.69567081011573,
      "grad_norm": 0.00020586182654369622,
      "learning_rate": 7.0724389198456934e-06,
      "loss": 0.1604,
      "step": 45240
    },
    {
      "epoch": 9.697813973424775,
      "grad_norm": 0.00016376824351027608,
      "learning_rate": 7.0695813687669665e-06,
      "loss": 0.0,
      "step": 45250
    },
    {
      "epoch": 9.699957136733818,
      "grad_norm": 0.0015004539163783193,
      "learning_rate": 7.066723817688241e-06,
      "loss": 0.0001,
      "step": 45260
    },
    {
      "epoch": 9.702100300042863,
      "grad_norm": 0.07053656131029129,
      "learning_rate": 7.063866266609516e-06,
      "loss": 0.0001,
      "step": 45270
    },
    {
      "epoch": 9.704243463351908,
      "grad_norm": 0.0001703228335827589,
      "learning_rate": 7.061008715530791e-06,
      "loss": 0.0003,
      "step": 45280
    },
    {
      "epoch": 9.70638662666095,
      "grad_norm": 0.0001656253298278898,
      "learning_rate": 7.058151164452065e-06,
      "loss": 0.0,
      "step": 45290
    },
    {
      "epoch": 9.708529789969996,
      "grad_norm": 0.0019412996480241418,
      "learning_rate": 7.0552936133733396e-06,
      "loss": 0.0,
      "step": 45300
    },
    {
      "epoch": 9.71067295327904,
      "grad_norm": 0.000299937732052058,
      "learning_rate": 7.052436062294614e-06,
      "loss": 0.145,
      "step": 45310
    },
    {
      "epoch": 9.712816116588083,
      "grad_norm": 0.002100557554513216,
      "learning_rate": 7.049578511215889e-06,
      "loss": 0.0,
      "step": 45320
    },
    {
      "epoch": 9.714959279897128,
      "grad_norm": 0.00016302177391480654,
      "learning_rate": 7.046720960137163e-06,
      "loss": 0.0,
      "step": 45330
    },
    {
      "epoch": 9.717102443206173,
      "grad_norm": 0.0004229315964039415,
      "learning_rate": 7.043863409058438e-06,
      "loss": 0.0,
      "step": 45340
    },
    {
      "epoch": 9.719245606515216,
      "grad_norm": 9.078434231923893e-05,
      "learning_rate": 7.041005857979713e-06,
      "loss": 0.0009,
      "step": 45350
    },
    {
      "epoch": 9.72138876982426,
      "grad_norm": 9.16869830689393e-05,
      "learning_rate": 7.038148306900986e-06,
      "loss": 0.1628,
      "step": 45360
    },
    {
      "epoch": 9.723531933133305,
      "grad_norm": 9.240344661520794e-05,
      "learning_rate": 7.0352907558222604e-06,
      "loss": 0.0,
      "step": 45370
    },
    {
      "epoch": 9.725675096442348,
      "grad_norm": 0.0028339356649667025,
      "learning_rate": 7.032433204743535e-06,
      "loss": 0.0001,
      "step": 45380
    },
    {
      "epoch": 9.727818259751393,
      "grad_norm": 9.800001862458885e-05,
      "learning_rate": 7.02957565366481e-06,
      "loss": 0.0,
      "step": 45390
    },
    {
      "epoch": 9.729961423060438,
      "grad_norm": 0.00013173569459468126,
      "learning_rate": 7.026718102586084e-06,
      "loss": 0.0002,
      "step": 45400
    },
    {
      "epoch": 9.73210458636948,
      "grad_norm": 9.727141878101975e-05,
      "learning_rate": 7.023860551507359e-06,
      "loss": 0.0,
      "step": 45410
    },
    {
      "epoch": 9.734247749678525,
      "grad_norm": 0.000483683223137632,
      "learning_rate": 7.0210030004286335e-06,
      "loss": 0.0003,
      "step": 45420
    },
    {
      "epoch": 9.73639091298757,
      "grad_norm": 0.0003281134704593569,
      "learning_rate": 7.018145449349908e-06,
      "loss": 0.1993,
      "step": 45430
    },
    {
      "epoch": 9.738534076296613,
      "grad_norm": 0.0001299313735216856,
      "learning_rate": 7.015287898271182e-06,
      "loss": 0.0005,
      "step": 45440
    },
    {
      "epoch": 9.740677239605658,
      "grad_norm": 0.0005704561481252313,
      "learning_rate": 7.012430347192457e-06,
      "loss": 0.1462,
      "step": 45450
    },
    {
      "epoch": 9.742820402914703,
      "grad_norm": 6.481051968876272e-05,
      "learning_rate": 7.009572796113732e-06,
      "loss": 0.0031,
      "step": 45460
    },
    {
      "epoch": 9.744963566223745,
      "grad_norm": 0.00033737908233888447,
      "learning_rate": 7.006715245035005e-06,
      "loss": 0.0003,
      "step": 45470
    },
    {
      "epoch": 9.74710672953279,
      "grad_norm": 0.00010422225022921339,
      "learning_rate": 7.00385769395628e-06,
      "loss": 0.0064,
      "step": 45480
    },
    {
      "epoch": 9.749249892841835,
      "grad_norm": 0.00011172609083587304,
      "learning_rate": 7.001000142877554e-06,
      "loss": 0.0,
      "step": 45490
    },
    {
      "epoch": 9.751393056150878,
      "grad_norm": 0.004347702022641897,
      "learning_rate": 6.998142591798829e-06,
      "loss": 0.0,
      "step": 45500
    },
    {
      "epoch": 9.753536219459923,
      "grad_norm": 0.006818845402449369,
      "learning_rate": 6.995285040720103e-06,
      "loss": 0.0,
      "step": 45510
    },
    {
      "epoch": 9.755679382768967,
      "grad_norm": 0.004999016877263784,
      "learning_rate": 6.992427489641378e-06,
      "loss": 0.1205,
      "step": 45520
    },
    {
      "epoch": 9.75782254607801,
      "grad_norm": 0.00028787110932171345,
      "learning_rate": 6.989569938562653e-06,
      "loss": 0.0002,
      "step": 45530
    },
    {
      "epoch": 9.759965709387055,
      "grad_norm": 6.401196878869087e-05,
      "learning_rate": 6.986712387483927e-06,
      "loss": 0.0,
      "step": 45540
    },
    {
      "epoch": 9.7621088726961,
      "grad_norm": 0.0005525975138880312,
      "learning_rate": 6.983854836405201e-06,
      "loss": 0.0,
      "step": 45550
    },
    {
      "epoch": 9.764252036005143,
      "grad_norm": 7.410597027046606e-05,
      "learning_rate": 6.980997285326476e-06,
      "loss": 0.0,
      "step": 45560
    },
    {
      "epoch": 9.766395199314188,
      "grad_norm": 3.912397733074613e-05,
      "learning_rate": 6.97813973424775e-06,
      "loss": 0.1964,
      "step": 45570
    },
    {
      "epoch": 9.768538362623232,
      "grad_norm": 9.12313989829272e-05,
      "learning_rate": 6.975282183169024e-06,
      "loss": 0.0,
      "step": 45580
    },
    {
      "epoch": 9.770681525932275,
      "grad_norm": 0.0001703705929685384,
      "learning_rate": 6.972424632090299e-06,
      "loss": 0.0003,
      "step": 45590
    },
    {
      "epoch": 9.77282468924132,
      "grad_norm": 2.6832187175750732,
      "learning_rate": 6.9695670810115735e-06,
      "loss": 0.0038,
      "step": 45600
    },
    {
      "epoch": 9.774967852550365,
      "grad_norm": 4.811128746950999e-05,
      "learning_rate": 6.966709529932848e-06,
      "loss": 0.0,
      "step": 45610
    },
    {
      "epoch": 9.777111015859408,
      "grad_norm": 0.0010210111504420638,
      "learning_rate": 6.963851978854122e-06,
      "loss": 0.0001,
      "step": 45620
    },
    {
      "epoch": 9.779254179168452,
      "grad_norm": 0.00014395634934771806,
      "learning_rate": 6.960994427775397e-06,
      "loss": 0.2165,
      "step": 45630
    },
    {
      "epoch": 9.781397342477497,
      "grad_norm": 0.0003302860714029521,
      "learning_rate": 6.958136876696672e-06,
      "loss": 0.0,
      "step": 45640
    },
    {
      "epoch": 9.78354050578654,
      "grad_norm": 0.000273689889581874,
      "learning_rate": 6.9552793256179465e-06,
      "loss": 0.0001,
      "step": 45650
    },
    {
      "epoch": 9.785683669095585,
      "grad_norm": 7.736725819995627e-05,
      "learning_rate": 6.9524217745392205e-06,
      "loss": 0.0,
      "step": 45660
    },
    {
      "epoch": 9.78782683240463,
      "grad_norm": 7.671672210562974e-05,
      "learning_rate": 6.949564223460495e-06,
      "loss": 0.0002,
      "step": 45670
    },
    {
      "epoch": 9.789969995713673,
      "grad_norm": 0.0009112641564570367,
      "learning_rate": 6.946706672381769e-06,
      "loss": 0.0,
      "step": 45680
    },
    {
      "epoch": 9.792113159022717,
      "grad_norm": 0.00012130207323934883,
      "learning_rate": 6.943849121303043e-06,
      "loss": 0.0,
      "step": 45690
    },
    {
      "epoch": 9.794256322331762,
      "grad_norm": 0.00011441305832704529,
      "learning_rate": 6.940991570224318e-06,
      "loss": 0.1706,
      "step": 45700
    },
    {
      "epoch": 9.796399485640805,
      "grad_norm": 0.0014309039106592536,
      "learning_rate": 6.938134019145593e-06,
      "loss": 0.0,
      "step": 45710
    },
    {
      "epoch": 9.79854264894985,
      "grad_norm": 0.00011408288264647126,
      "learning_rate": 6.935276468066867e-06,
      "loss": 0.0003,
      "step": 45720
    },
    {
      "epoch": 9.800685812258894,
      "grad_norm": 0.0008461392135359347,
      "learning_rate": 6.932418916988141e-06,
      "loss": 0.0,
      "step": 45730
    },
    {
      "epoch": 9.802828975567937,
      "grad_norm": 8.738265751162544e-05,
      "learning_rate": 6.929561365909416e-06,
      "loss": 0.1381,
      "step": 45740
    },
    {
      "epoch": 9.804972138876982,
      "grad_norm": 0.0002422130637569353,
      "learning_rate": 6.926703814830691e-06,
      "loss": 0.0,
      "step": 45750
    },
    {
      "epoch": 9.807115302186027,
      "grad_norm": 0.00037869781954213977,
      "learning_rate": 6.923846263751966e-06,
      "loss": 0.1635,
      "step": 45760
    },
    {
      "epoch": 9.80925846549507,
      "grad_norm": 0.0012061805464327335,
      "learning_rate": 6.92098871267324e-06,
      "loss": 0.0,
      "step": 45770
    },
    {
      "epoch": 9.811401628804115,
      "grad_norm": 0.00017967046005651355,
      "learning_rate": 6.918131161594514e-06,
      "loss": 0.0005,
      "step": 45780
    },
    {
      "epoch": 9.81354479211316,
      "grad_norm": 0.00022669616737402976,
      "learning_rate": 6.915273610515788e-06,
      "loss": 0.0,
      "step": 45790
    },
    {
      "epoch": 9.815687955422202,
      "grad_norm": 0.000649857975076884,
      "learning_rate": 6.912416059437062e-06,
      "loss": 0.0009,
      "step": 45800
    },
    {
      "epoch": 9.817831118731247,
      "grad_norm": 0.00012293399777263403,
      "learning_rate": 6.909558508358337e-06,
      "loss": 0.0001,
      "step": 45810
    },
    {
      "epoch": 9.819974282040292,
      "grad_norm": 0.00017800595378503203,
      "learning_rate": 6.906700957279612e-06,
      "loss": 0.0,
      "step": 45820
    },
    {
      "epoch": 9.822117445349335,
      "grad_norm": 0.0003399294801056385,
      "learning_rate": 6.9038434062008866e-06,
      "loss": 0.0002,
      "step": 45830
    },
    {
      "epoch": 9.82426060865838,
      "grad_norm": 9.708676225272939e-05,
      "learning_rate": 6.9009858551221605e-06,
      "loss": 0.0,
      "step": 45840
    },
    {
      "epoch": 9.826403771967424,
      "grad_norm": 0.00010195013601332903,
      "learning_rate": 6.898128304043435e-06,
      "loss": 0.0001,
      "step": 45850
    },
    {
      "epoch": 9.828546935276467,
      "grad_norm": 8.668619557283819e-05,
      "learning_rate": 6.89527075296471e-06,
      "loss": 0.0002,
      "step": 45860
    },
    {
      "epoch": 9.830690098585512,
      "grad_norm": 6.369398761307821e-05,
      "learning_rate": 6.892413201885985e-06,
      "loss": 0.0,
      "step": 45870
    },
    {
      "epoch": 9.832833261894557,
      "grad_norm": 0.00011268947855569422,
      "learning_rate": 6.88955565080726e-06,
      "loss": 0.1272,
      "step": 45880
    },
    {
      "epoch": 9.8349764252036,
      "grad_norm": 0.0007344624027609825,
      "learning_rate": 6.8866980997285335e-06,
      "loss": 0.0002,
      "step": 45890
    },
    {
      "epoch": 9.837119588512644,
      "grad_norm": 0.00045263045467436314,
      "learning_rate": 6.8838405486498074e-06,
      "loss": 0.0014,
      "step": 45900
    },
    {
      "epoch": 9.839262751821689,
      "grad_norm": 0.00012659428466577083,
      "learning_rate": 6.880982997571081e-06,
      "loss": 0.1457,
      "step": 45910
    },
    {
      "epoch": 9.841405915130732,
      "grad_norm": 0.00011828955757664517,
      "learning_rate": 6.878125446492356e-06,
      "loss": 0.0001,
      "step": 45920
    },
    {
      "epoch": 9.843549078439777,
      "grad_norm": 0.0007473563309758902,
      "learning_rate": 6.875267895413631e-06,
      "loss": 0.001,
      "step": 45930
    },
    {
      "epoch": 9.845692241748822,
      "grad_norm": 5.55087644897867e-05,
      "learning_rate": 6.872410344334906e-06,
      "loss": 0.0,
      "step": 45940
    },
    {
      "epoch": 9.847835405057864,
      "grad_norm": 0.00011731121048796922,
      "learning_rate": 6.8695527932561805e-06,
      "loss": 0.1406,
      "step": 45950
    },
    {
      "epoch": 9.84997856836691,
      "grad_norm": 9.898650750983506e-05,
      "learning_rate": 6.866695242177454e-06,
      "loss": 0.0,
      "step": 45960
    },
    {
      "epoch": 9.852121731675954,
      "grad_norm": 8.168426575139165e-05,
      "learning_rate": 6.863837691098729e-06,
      "loss": 0.0027,
      "step": 45970
    },
    {
      "epoch": 9.854264894984997,
      "grad_norm": 5.163309833733365e-05,
      "learning_rate": 6.860980140020004e-06,
      "loss": 0.0,
      "step": 45980
    },
    {
      "epoch": 9.856408058294042,
      "grad_norm": 6.88347063260153e-05,
      "learning_rate": 6.858122588941279e-06,
      "loss": 0.0016,
      "step": 45990
    },
    {
      "epoch": 9.858551221603086,
      "grad_norm": 0.0010030516423285007,
      "learning_rate": 6.855265037862552e-06,
      "loss": 0.0,
      "step": 46000
    },
    {
      "epoch": 9.860694384912131,
      "grad_norm": 6.264347757678479e-05,
      "learning_rate": 6.852407486783827e-06,
      "loss": 0.1334,
      "step": 46010
    },
    {
      "epoch": 9.862837548221174,
      "grad_norm": 5.770074494648725e-05,
      "learning_rate": 6.849549935705101e-06,
      "loss": 0.0,
      "step": 46020
    },
    {
      "epoch": 9.864980711530219,
      "grad_norm": 0.004276870284229517,
      "learning_rate": 6.846692384626375e-06,
      "loss": 0.0,
      "step": 46030
    },
    {
      "epoch": 9.867123874839264,
      "grad_norm": 0.00010312005906598642,
      "learning_rate": 6.84383483354765e-06,
      "loss": 0.1434,
      "step": 46040
    },
    {
      "epoch": 9.869267038148307,
      "grad_norm": 0.00027478227275423706,
      "learning_rate": 6.840977282468925e-06,
      "loss": 0.0003,
      "step": 46050
    },
    {
      "epoch": 9.871410201457351,
      "grad_norm": 0.0015682318480685353,
      "learning_rate": 6.8381197313902e-06,
      "loss": 0.0,
      "step": 46060
    },
    {
      "epoch": 9.873553364766396,
      "grad_norm": 5.6725784816080704e-05,
      "learning_rate": 6.8352621803114735e-06,
      "loss": 0.0001,
      "step": 46070
    },
    {
      "epoch": 9.875696528075439,
      "grad_norm": 0.00025236757937818766,
      "learning_rate": 6.832404629232748e-06,
      "loss": 0.0,
      "step": 46080
    },
    {
      "epoch": 9.877839691384484,
      "grad_norm": 0.0008936112280935049,
      "learning_rate": 6.829547078154023e-06,
      "loss": 0.0006,
      "step": 46090
    },
    {
      "epoch": 9.879982854693528,
      "grad_norm": 3.763426866498776e-05,
      "learning_rate": 6.826689527075298e-06,
      "loss": 0.0,
      "step": 46100
    },
    {
      "epoch": 9.882126018002571,
      "grad_norm": 0.00010392889089416713,
      "learning_rate": 6.823831975996571e-06,
      "loss": 0.0,
      "step": 46110
    },
    {
      "epoch": 9.884269181311616,
      "grad_norm": 4.184429417364299e-05,
      "learning_rate": 6.820974424917846e-06,
      "loss": 0.0,
      "step": 46120
    },
    {
      "epoch": 9.88641234462066,
      "grad_norm": 5.6956174375955015e-05,
      "learning_rate": 6.8181168738391205e-06,
      "loss": 0.0,
      "step": 46130
    },
    {
      "epoch": 9.888555507929704,
      "grad_norm": 6.479444709839299e-05,
      "learning_rate": 6.8152593227603944e-06,
      "loss": 0.0726,
      "step": 46140
    },
    {
      "epoch": 9.890698671238749,
      "grad_norm": 0.00039890166954137385,
      "learning_rate": 6.812401771681669e-06,
      "loss": 0.0001,
      "step": 46150
    },
    {
      "epoch": 9.892841834547793,
      "grad_norm": 4.350041854195297e-05,
      "learning_rate": 6.809544220602944e-06,
      "loss": 0.0,
      "step": 46160
    },
    {
      "epoch": 9.894984997856836,
      "grad_norm": 0.0002963641018141061,
      "learning_rate": 6.806686669524219e-06,
      "loss": 0.0,
      "step": 46170
    },
    {
      "epoch": 9.897128161165881,
      "grad_norm": 0.001079204841516912,
      "learning_rate": 6.803829118445493e-06,
      "loss": 0.0,
      "step": 46180
    },
    {
      "epoch": 9.899271324474926,
      "grad_norm": 0.0015047843335196376,
      "learning_rate": 6.8009715673667675e-06,
      "loss": 0.0,
      "step": 46190
    },
    {
      "epoch": 9.901414487783969,
      "grad_norm": 3.501469473121688e-05,
      "learning_rate": 6.798114016288042e-06,
      "loss": 0.0008,
      "step": 46200
    },
    {
      "epoch": 9.903557651093013,
      "grad_norm": 8.301295747514814e-05,
      "learning_rate": 6.795256465209317e-06,
      "loss": 0.1345,
      "step": 46210
    },
    {
      "epoch": 9.905700814402058,
      "grad_norm": 0.000747031532227993,
      "learning_rate": 6.79239891413059e-06,
      "loss": 0.1673,
      "step": 46220
    },
    {
      "epoch": 9.907843977711101,
      "grad_norm": 5.601244993158616e-05,
      "learning_rate": 6.789541363051865e-06,
      "loss": 0.0,
      "step": 46230
    },
    {
      "epoch": 9.909987141020146,
      "grad_norm": 3.920796007150784e-05,
      "learning_rate": 6.78668381197314e-06,
      "loss": 0.0001,
      "step": 46240
    },
    {
      "epoch": 9.91213030432919,
      "grad_norm": 0.1689218282699585,
      "learning_rate": 6.7838262608944136e-06,
      "loss": 0.0003,
      "step": 46250
    },
    {
      "epoch": 9.914273467638234,
      "grad_norm": 0.0001279831922147423,
      "learning_rate": 6.780968709815688e-06,
      "loss": 0.0,
      "step": 46260
    },
    {
      "epoch": 9.916416630947278,
      "grad_norm": 0.00028672313783317804,
      "learning_rate": 6.778111158736963e-06,
      "loss": 0.0001,
      "step": 46270
    },
    {
      "epoch": 9.918559794256323,
      "grad_norm": 0.005478649865835905,
      "learning_rate": 6.775253607658238e-06,
      "loss": 0.0018,
      "step": 46280
    },
    {
      "epoch": 9.920702957565366,
      "grad_norm": 3.872777597280219e-05,
      "learning_rate": 6.772396056579512e-06,
      "loss": 0.0003,
      "step": 46290
    },
    {
      "epoch": 9.92284612087441,
      "grad_norm": 0.00040810852078720927,
      "learning_rate": 6.769538505500787e-06,
      "loss": 0.0,
      "step": 46300
    },
    {
      "epoch": 9.924989284183455,
      "grad_norm": 0.000137354334583506,
      "learning_rate": 6.766680954422061e-06,
      "loss": 0.0,
      "step": 46310
    },
    {
      "epoch": 9.927132447492498,
      "grad_norm": 0.0007862603524699807,
      "learning_rate": 6.763823403343336e-06,
      "loss": 0.0001,
      "step": 46320
    },
    {
      "epoch": 9.929275610801543,
      "grad_norm": 3.728072624653578e-05,
      "learning_rate": 6.760965852264609e-06,
      "loss": 0.0,
      "step": 46330
    },
    {
      "epoch": 9.931418774110588,
      "grad_norm": 3.597901377361268e-05,
      "learning_rate": 6.758108301185884e-06,
      "loss": 0.0,
      "step": 46340
    },
    {
      "epoch": 9.933561937419631,
      "grad_norm": 2.575500911916606e-05,
      "learning_rate": 6.755250750107159e-06,
      "loss": 0.0013,
      "step": 46350
    },
    {
      "epoch": 9.935705100728676,
      "grad_norm": 0.0002676724980119616,
      "learning_rate": 6.752393199028433e-06,
      "loss": 0.3876,
      "step": 46360
    },
    {
      "epoch": 9.93784826403772,
      "grad_norm": 0.0005698693566955626,
      "learning_rate": 6.7495356479497075e-06,
      "loss": 0.0001,
      "step": 46370
    },
    {
      "epoch": 9.939991427346763,
      "grad_norm": 0.0009679144131951034,
      "learning_rate": 6.746678096870982e-06,
      "loss": 0.1335,
      "step": 46380
    },
    {
      "epoch": 9.942134590655808,
      "grad_norm": 0.0001849591062637046,
      "learning_rate": 6.743820545792257e-06,
      "loss": 0.0,
      "step": 46390
    },
    {
      "epoch": 9.944277753964853,
      "grad_norm": 0.18175427615642548,
      "learning_rate": 6.740962994713531e-06,
      "loss": 0.0003,
      "step": 46400
    },
    {
      "epoch": 9.946420917273896,
      "grad_norm": 0.0005728452233597636,
      "learning_rate": 6.738105443634806e-06,
      "loss": 0.0003,
      "step": 46410
    },
    {
      "epoch": 9.94856408058294,
      "grad_norm": 0.0004095575714018196,
      "learning_rate": 6.7352478925560805e-06,
      "loss": 0.0,
      "step": 46420
    },
    {
      "epoch": 9.950707243891985,
      "grad_norm": 0.00021370532340370119,
      "learning_rate": 6.732390341477354e-06,
      "loss": 0.0002,
      "step": 46430
    },
    {
      "epoch": 9.952850407201028,
      "grad_norm": 0.0038736495189368725,
      "learning_rate": 6.729532790398628e-06,
      "loss": 0.0,
      "step": 46440
    },
    {
      "epoch": 9.954993570510073,
      "grad_norm": 0.03738606721162796,
      "learning_rate": 6.726675239319903e-06,
      "loss": 0.0,
      "step": 46450
    },
    {
      "epoch": 9.957136733819118,
      "grad_norm": 0.006745890714228153,
      "learning_rate": 6.723817688241178e-06,
      "loss": 0.1327,
      "step": 46460
    },
    {
      "epoch": 9.95927989712816,
      "grad_norm": 8.25283641461283e-05,
      "learning_rate": 6.720960137162452e-06,
      "loss": 0.0,
      "step": 46470
    },
    {
      "epoch": 9.961423060437205,
      "grad_norm": 0.00033960241125896573,
      "learning_rate": 6.718102586083727e-06,
      "loss": 0.0,
      "step": 46480
    },
    {
      "epoch": 9.96356622374625,
      "grad_norm": 0.00024217466125264764,
      "learning_rate": 6.715245035005001e-06,
      "loss": 0.001,
      "step": 46490
    },
    {
      "epoch": 9.965709387055293,
      "grad_norm": 0.001249976339749992,
      "learning_rate": 6.712387483926276e-06,
      "loss": 0.0,
      "step": 46500
    },
    {
      "epoch": 9.967852550364338,
      "grad_norm": 0.0038927982095628977,
      "learning_rate": 6.70952993284755e-06,
      "loss": 0.0,
      "step": 46510
    },
    {
      "epoch": 9.969995713673383,
      "grad_norm": 7.760320295346901e-05,
      "learning_rate": 6.706672381768825e-06,
      "loss": 0.0,
      "step": 46520
    },
    {
      "epoch": 9.972138876982426,
      "grad_norm": 4.680461643147282e-05,
      "learning_rate": 6.7038148306901e-06,
      "loss": 0.0,
      "step": 46530
    },
    {
      "epoch": 9.97428204029147,
      "grad_norm": 6.272758037084714e-05,
      "learning_rate": 6.700957279611373e-06,
      "loss": 0.0,
      "step": 46540
    },
    {
      "epoch": 9.976425203600515,
      "grad_norm": 3.892934910254553e-05,
      "learning_rate": 6.6980997285326475e-06,
      "loss": 0.0,
      "step": 46550
    },
    {
      "epoch": 9.978568366909558,
      "grad_norm": 5.4816169722471386e-05,
      "learning_rate": 6.695242177453922e-06,
      "loss": 0.1604,
      "step": 46560
    },
    {
      "epoch": 9.980711530218603,
      "grad_norm": 0.0010150667512789369,
      "learning_rate": 6.692384626375197e-06,
      "loss": 0.0002,
      "step": 46570
    },
    {
      "epoch": 9.982854693527647,
      "grad_norm": 7.137594366213307e-05,
      "learning_rate": 6.689527075296471e-06,
      "loss": 0.0003,
      "step": 46580
    },
    {
      "epoch": 9.98499785683669,
      "grad_norm": 7.628355524502695e-05,
      "learning_rate": 6.686669524217746e-06,
      "loss": 0.0,
      "step": 46590
    },
    {
      "epoch": 9.987141020145735,
      "grad_norm": 0.1106986477971077,
      "learning_rate": 6.6838119731390205e-06,
      "loss": 0.3904,
      "step": 46600
    },
    {
      "epoch": 9.98928418345478,
      "grad_norm": 0.00024151489196810871,
      "learning_rate": 6.680954422060295e-06,
      "loss": 0.0,
      "step": 46610
    },
    {
      "epoch": 9.991427346763823,
      "grad_norm": 0.00037664431147277355,
      "learning_rate": 6.67809687098157e-06,
      "loss": 0.0,
      "step": 46620
    },
    {
      "epoch": 9.993570510072868,
      "grad_norm": 0.0008150335634127259,
      "learning_rate": 6.675239319902844e-06,
      "loss": 0.0,
      "step": 46630
    },
    {
      "epoch": 9.995713673381912,
      "grad_norm": 0.0018736079800873995,
      "learning_rate": 6.672381768824119e-06,
      "loss": 0.0,
      "step": 46640
    },
    {
      "epoch": 9.997856836690955,
      "grad_norm": 0.0002666438231244683,
      "learning_rate": 6.669524217745392e-06,
      "loss": 0.2424,
      "step": 46650
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.00036479378468357027,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0,
      "step": 46660
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9853333333333333,
      "eval_f1": 0.9243986254295531,
      "eval_loss": 0.10481278598308563,
      "eval_precision": 0.9539007092198581,
      "eval_recall": 0.8966666666666666,
      "eval_runtime": 401.1727,
      "eval_samples_per_second": 7.478,
      "eval_steps_per_second": 2.493,
      "step": 46660
    },
    {
      "epoch": 10.002143163309045,
      "grad_norm": 0.0005868338630534708,
      "learning_rate": 6.663809115587941e-06,
      "loss": 0.2336,
      "step": 46670
    },
    {
      "epoch": 10.004286326618088,
      "grad_norm": 0.001699582440778613,
      "learning_rate": 6.660951564509216e-06,
      "loss": 0.2452,
      "step": 46680
    },
    {
      "epoch": 10.006429489927132,
      "grad_norm": 0.003531206864863634,
      "learning_rate": 6.658094013430491e-06,
      "loss": 0.0004,
      "step": 46690
    },
    {
      "epoch": 10.008572653236177,
      "grad_norm": 0.13505429029464722,
      "learning_rate": 6.655236462351765e-06,
      "loss": 0.0005,
      "step": 46700
    },
    {
      "epoch": 10.01071581654522,
      "grad_norm": 0.001128341886214912,
      "learning_rate": 6.65237891127304e-06,
      "loss": 0.0002,
      "step": 46710
    },
    {
      "epoch": 10.012858979854265,
      "grad_norm": 0.29573068022727966,
      "learning_rate": 6.6495213601943145e-06,
      "loss": 0.0005,
      "step": 46720
    },
    {
      "epoch": 10.01500214316331,
      "grad_norm": 0.0006075822748243809,
      "learning_rate": 6.646663809115589e-06,
      "loss": 0.0,
      "step": 46730
    },
    {
      "epoch": 10.017145306472353,
      "grad_norm": 0.0002101463032886386,
      "learning_rate": 6.643806258036863e-06,
      "loss": 0.0,
      "step": 46740
    },
    {
      "epoch": 10.019288469781397,
      "grad_norm": 0.0005909541505388916,
      "learning_rate": 6.640948706958137e-06,
      "loss": 0.1296,
      "step": 46750
    },
    {
      "epoch": 10.021431633090442,
      "grad_norm": 0.0013745743781328201,
      "learning_rate": 6.638091155879412e-06,
      "loss": 0.0003,
      "step": 46760
    },
    {
      "epoch": 10.023574796399485,
      "grad_norm": 0.0005648752558045089,
      "learning_rate": 6.635233604800686e-06,
      "loss": 0.0002,
      "step": 46770
    },
    {
      "epoch": 10.02571795970853,
      "grad_norm": 0.0010723959421738982,
      "learning_rate": 6.6323760537219606e-06,
      "loss": 0.0,
      "step": 46780
    },
    {
      "epoch": 10.027861123017574,
      "grad_norm": 0.0003869009669870138,
      "learning_rate": 6.629518502643235e-06,
      "loss": 0.0005,
      "step": 46790
    },
    {
      "epoch": 10.030004286326617,
      "grad_norm": 0.0001951377489604056,
      "learning_rate": 6.62666095156451e-06,
      "loss": 0.0006,
      "step": 46800
    },
    {
      "epoch": 10.032147449635662,
      "grad_norm": 0.0007052306900732219,
      "learning_rate": 6.623803400485784e-06,
      "loss": 0.0,
      "step": 46810
    },
    {
      "epoch": 10.034290612944707,
      "grad_norm": 0.0006749247550033033,
      "learning_rate": 6.620945849407059e-06,
      "loss": 0.0007,
      "step": 46820
    },
    {
      "epoch": 10.03643377625375,
      "grad_norm": 0.0017762224888429046,
      "learning_rate": 6.618088298328334e-06,
      "loss": 0.0021,
      "step": 46830
    },
    {
      "epoch": 10.038576939562795,
      "grad_norm": 0.0001533822069177404,
      "learning_rate": 6.615230747249608e-06,
      "loss": 0.0001,
      "step": 46840
    },
    {
      "epoch": 10.04072010287184,
      "grad_norm": 0.00012409726332407445,
      "learning_rate": 6.612373196170882e-06,
      "loss": 0.0,
      "step": 46850
    },
    {
      "epoch": 10.042863266180882,
      "grad_norm": 0.00014111284690443426,
      "learning_rate": 6.609515645092156e-06,
      "loss": 0.0001,
      "step": 46860
    },
    {
      "epoch": 10.045006429489927,
      "grad_norm": 0.0007262113504111767,
      "learning_rate": 6.606658094013431e-06,
      "loss": 0.0001,
      "step": 46870
    },
    {
      "epoch": 10.047149592798972,
      "grad_norm": 0.0010191010078415275,
      "learning_rate": 6.603800542934705e-06,
      "loss": 0.0,
      "step": 46880
    },
    {
      "epoch": 10.049292756108015,
      "grad_norm": 7.348965300479904e-05,
      "learning_rate": 6.60094299185598e-06,
      "loss": 0.0,
      "step": 46890
    },
    {
      "epoch": 10.05143591941706,
      "grad_norm": 0.00018033920787274837,
      "learning_rate": 6.5980854407772545e-06,
      "loss": 0.0002,
      "step": 46900
    },
    {
      "epoch": 10.053579082726104,
      "grad_norm": 0.00010002079943660647,
      "learning_rate": 6.595227889698529e-06,
      "loss": 0.0,
      "step": 46910
    },
    {
      "epoch": 10.055722246035147,
      "grad_norm": 0.0012398804537951946,
      "learning_rate": 6.592370338619803e-06,
      "loss": 0.0,
      "step": 46920
    },
    {
      "epoch": 10.057865409344192,
      "grad_norm": 0.00021687943080905825,
      "learning_rate": 6.589512787541078e-06,
      "loss": 0.0,
      "step": 46930
    },
    {
      "epoch": 10.060008572653237,
      "grad_norm": 0.0002404942351859063,
      "learning_rate": 6.586655236462353e-06,
      "loss": 0.0,
      "step": 46940
    },
    {
      "epoch": 10.06215173596228,
      "grad_norm": 0.000379564065951854,
      "learning_rate": 6.5837976853836275e-06,
      "loss": 0.0001,
      "step": 46950
    },
    {
      "epoch": 10.064294899271324,
      "grad_norm": 6.754738569725305e-05,
      "learning_rate": 6.5809401343049014e-06,
      "loss": 0.1662,
      "step": 46960
    },
    {
      "epoch": 10.066438062580369,
      "grad_norm": 0.00048425389104522765,
      "learning_rate": 6.578082583226175e-06,
      "loss": 0.0001,
      "step": 46970
    },
    {
      "epoch": 10.068581225889412,
      "grad_norm": 0.00013600884994957596,
      "learning_rate": 6.57522503214745e-06,
      "loss": 0.0,
      "step": 46980
    },
    {
      "epoch": 10.070724389198457,
      "grad_norm": 0.03284372761845589,
      "learning_rate": 6.572367481068724e-06,
      "loss": 0.0001,
      "step": 46990
    },
    {
      "epoch": 10.072867552507502,
      "grad_norm": 9.088283695746213e-05,
      "learning_rate": 6.569509929989999e-06,
      "loss": 0.0,
      "step": 47000
    },
    {
      "epoch": 10.075010715816545,
      "grad_norm": 0.0006709690787829459,
      "learning_rate": 6.566652378911274e-06,
      "loss": 0.0,
      "step": 47010
    },
    {
      "epoch": 10.07715387912559,
      "grad_norm": 0.0002639113226905465,
      "learning_rate": 6.563794827832548e-06,
      "loss": 0.0,
      "step": 47020
    },
    {
      "epoch": 10.079297042434634,
      "grad_norm": 0.005208782851696014,
      "learning_rate": 6.560937276753822e-06,
      "loss": 0.0,
      "step": 47030
    },
    {
      "epoch": 10.081440205743677,
      "grad_norm": 0.006766302045434713,
      "learning_rate": 6.558079725675097e-06,
      "loss": 0.0,
      "step": 47040
    },
    {
      "epoch": 10.083583369052722,
      "grad_norm": 0.0002920079859904945,
      "learning_rate": 6.555222174596372e-06,
      "loss": 0.0,
      "step": 47050
    },
    {
      "epoch": 10.085726532361766,
      "grad_norm": 0.00015812681522220373,
      "learning_rate": 6.552364623517647e-06,
      "loss": 0.0,
      "step": 47060
    },
    {
      "epoch": 10.08786969567081,
      "grad_norm": 0.0005348046543076634,
      "learning_rate": 6.5495070724389206e-06,
      "loss": 0.0002,
      "step": 47070
    },
    {
      "epoch": 10.090012858979854,
      "grad_norm": 7.474068115698174e-05,
      "learning_rate": 6.5466495213601945e-06,
      "loss": 0.0,
      "step": 47080
    },
    {
      "epoch": 10.092156022288899,
      "grad_norm": 0.0001254779053851962,
      "learning_rate": 6.543791970281469e-06,
      "loss": 0.0,
      "step": 47090
    },
    {
      "epoch": 10.094299185597942,
      "grad_norm": 0.0007354324916377664,
      "learning_rate": 6.540934419202743e-06,
      "loss": 0.0001,
      "step": 47100
    },
    {
      "epoch": 10.096442348906987,
      "grad_norm": 8.647482900414616e-05,
      "learning_rate": 6.538076868124018e-06,
      "loss": 0.0,
      "step": 47110
    },
    {
      "epoch": 10.098585512216031,
      "grad_norm": 0.00010925057722488418,
      "learning_rate": 6.535219317045293e-06,
      "loss": 0.1854,
      "step": 47120
    },
    {
      "epoch": 10.100728675525074,
      "grad_norm": 0.0002439720119582489,
      "learning_rate": 6.5323617659665675e-06,
      "loss": 0.0,
      "step": 47130
    },
    {
      "epoch": 10.102871838834119,
      "grad_norm": 0.0013991901651024818,
      "learning_rate": 6.5295042148878415e-06,
      "loss": 0.0,
      "step": 47140
    },
    {
      "epoch": 10.105015002143164,
      "grad_norm": 0.00011589015048230067,
      "learning_rate": 6.526646663809116e-06,
      "loss": 0.0,
      "step": 47150
    },
    {
      "epoch": 10.107158165452207,
      "grad_norm": 0.000181344265001826,
      "learning_rate": 6.523789112730391e-06,
      "loss": 0.0002,
      "step": 47160
    },
    {
      "epoch": 10.109301328761251,
      "grad_norm": 0.00019144733960274607,
      "learning_rate": 6.520931561651666e-06,
      "loss": 0.0005,
      "step": 47170
    },
    {
      "epoch": 10.111444492070296,
      "grad_norm": 9.833546209847555e-05,
      "learning_rate": 6.518074010572939e-06,
      "loss": 0.0013,
      "step": 47180
    },
    {
      "epoch": 10.11358765537934,
      "grad_norm": 0.00032777173328213394,
      "learning_rate": 6.515216459494214e-06,
      "loss": 0.0,
      "step": 47190
    },
    {
      "epoch": 10.115730818688384,
      "grad_norm": 0.00010603004193399101,
      "learning_rate": 6.512358908415488e-06,
      "loss": 0.0,
      "step": 47200
    },
    {
      "epoch": 10.117873981997429,
      "grad_norm": 0.0019011215772479773,
      "learning_rate": 6.509501357336762e-06,
      "loss": 0.1761,
      "step": 47210
    },
    {
      "epoch": 10.120017145306472,
      "grad_norm": 0.00022701222042087466,
      "learning_rate": 6.506643806258037e-06,
      "loss": 0.0,
      "step": 47220
    },
    {
      "epoch": 10.122160308615516,
      "grad_norm": 0.00013040061458013952,
      "learning_rate": 6.503786255179312e-06,
      "loss": 0.0003,
      "step": 47230
    },
    {
      "epoch": 10.124303471924561,
      "grad_norm": 0.0003061704628635198,
      "learning_rate": 6.500928704100587e-06,
      "loss": 0.0,
      "step": 47240
    },
    {
      "epoch": 10.126446635233604,
      "grad_norm": 0.0009477399871684611,
      "learning_rate": 6.498071153021861e-06,
      "loss": 0.0,
      "step": 47250
    },
    {
      "epoch": 10.128589798542649,
      "grad_norm": 0.0002899102692026645,
      "learning_rate": 6.495213601943135e-06,
      "loss": 0.0,
      "step": 47260
    },
    {
      "epoch": 10.130732961851693,
      "grad_norm": 0.0001301557058468461,
      "learning_rate": 6.49235605086441e-06,
      "loss": 0.0008,
      "step": 47270
    },
    {
      "epoch": 10.132876125160736,
      "grad_norm": 0.0002596297999843955,
      "learning_rate": 6.489498499785685e-06,
      "loss": 0.0,
      "step": 47280
    },
    {
      "epoch": 10.135019288469781,
      "grad_norm": 0.00013267924077808857,
      "learning_rate": 6.486640948706958e-06,
      "loss": 0.0,
      "step": 47290
    },
    {
      "epoch": 10.137162451778826,
      "grad_norm": 0.0009738993248902261,
      "learning_rate": 6.483783397628233e-06,
      "loss": 0.2152,
      "step": 47300
    },
    {
      "epoch": 10.139305615087869,
      "grad_norm": 0.0004063123487867415,
      "learning_rate": 6.4809258465495076e-06,
      "loss": 0.0,
      "step": 47310
    },
    {
      "epoch": 10.141448778396914,
      "grad_norm": 0.0002088236651616171,
      "learning_rate": 6.4780682954707815e-06,
      "loss": 0.0,
      "step": 47320
    },
    {
      "epoch": 10.143591941705958,
      "grad_norm": 0.040511634200811386,
      "learning_rate": 6.475210744392056e-06,
      "loss": 0.0001,
      "step": 47330
    },
    {
      "epoch": 10.145735105015001,
      "grad_norm": 0.00013759195280727,
      "learning_rate": 6.472353193313331e-06,
      "loss": 0.0,
      "step": 47340
    },
    {
      "epoch": 10.147878268324046,
      "grad_norm": 0.000170567785971798,
      "learning_rate": 6.469495642234606e-06,
      "loss": 0.0,
      "step": 47350
    },
    {
      "epoch": 10.15002143163309,
      "grad_norm": 8.778842311585322e-05,
      "learning_rate": 6.46663809115588e-06,
      "loss": 0.0002,
      "step": 47360
    },
    {
      "epoch": 10.152164594942134,
      "grad_norm": 0.00010047438263427466,
      "learning_rate": 6.4637805400771545e-06,
      "loss": 0.0,
      "step": 47370
    },
    {
      "epoch": 10.154307758251178,
      "grad_norm": 0.00011726382945198566,
      "learning_rate": 6.460922988998429e-06,
      "loss": 0.0002,
      "step": 47380
    },
    {
      "epoch": 10.156450921560223,
      "grad_norm": 0.025265153497457504,
      "learning_rate": 6.458065437919704e-06,
      "loss": 0.2387,
      "step": 47390
    },
    {
      "epoch": 10.158594084869266,
      "grad_norm": 0.000359874393325299,
      "learning_rate": 6.455207886840977e-06,
      "loss": 0.0,
      "step": 47400
    },
    {
      "epoch": 10.160737248178311,
      "grad_norm": 0.0003358461253810674,
      "learning_rate": 6.452350335762252e-06,
      "loss": 0.0004,
      "step": 47410
    },
    {
      "epoch": 10.162880411487356,
      "grad_norm": 0.00043240029481239617,
      "learning_rate": 6.449492784683527e-06,
      "loss": 0.0004,
      "step": 47420
    },
    {
      "epoch": 10.165023574796399,
      "grad_norm": 0.003585029626265168,
      "learning_rate": 6.446635233604801e-06,
      "loss": 0.1397,
      "step": 47430
    },
    {
      "epoch": 10.167166738105443,
      "grad_norm": 0.026451963931322098,
      "learning_rate": 6.443777682526075e-06,
      "loss": 0.0,
      "step": 47440
    },
    {
      "epoch": 10.169309901414488,
      "grad_norm": 0.015273894183337688,
      "learning_rate": 6.44092013144735e-06,
      "loss": 0.0008,
      "step": 47450
    },
    {
      "epoch": 10.171453064723533,
      "grad_norm": 0.0007547333952970803,
      "learning_rate": 6.438062580368625e-06,
      "loss": 0.0001,
      "step": 47460
    },
    {
      "epoch": 10.173596228032576,
      "grad_norm": 0.0002972085203509778,
      "learning_rate": 6.4352050292899e-06,
      "loss": 0.0001,
      "step": 47470
    },
    {
      "epoch": 10.17573939134162,
      "grad_norm": 0.00018363406707067043,
      "learning_rate": 6.432347478211174e-06,
      "loss": 0.0001,
      "step": 47480
    },
    {
      "epoch": 10.177882554650665,
      "grad_norm": 0.16485443711280823,
      "learning_rate": 6.4294899271324484e-06,
      "loss": 0.0006,
      "step": 47490
    },
    {
      "epoch": 10.180025717959708,
      "grad_norm": 0.0001332422107225284,
      "learning_rate": 6.426632376053723e-06,
      "loss": 0.0002,
      "step": 47500
    },
    {
      "epoch": 10.182168881268753,
      "grad_norm": 0.00014100197586230934,
      "learning_rate": 6.423774824974996e-06,
      "loss": 0.0,
      "step": 47510
    },
    {
      "epoch": 10.184312044577798,
      "grad_norm": 0.0015436126850545406,
      "learning_rate": 6.420917273896271e-06,
      "loss": 0.1969,
      "step": 47520
    },
    {
      "epoch": 10.18645520788684,
      "grad_norm": 0.0005712300189770758,
      "learning_rate": 6.418059722817546e-06,
      "loss": 0.1446,
      "step": 47530
    },
    {
      "epoch": 10.188598371195885,
      "grad_norm": 0.00044625840382650495,
      "learning_rate": 6.415202171738821e-06,
      "loss": 0.0,
      "step": 47540
    },
    {
      "epoch": 10.19074153450493,
      "grad_norm": 0.00040814990643411875,
      "learning_rate": 6.4123446206600945e-06,
      "loss": 0.0001,
      "step": 47550
    },
    {
      "epoch": 10.192884697813973,
      "grad_norm": 0.00013158161891624331,
      "learning_rate": 6.409487069581369e-06,
      "loss": 0.0004,
      "step": 47560
    },
    {
      "epoch": 10.195027861123018,
      "grad_norm": 0.00022867537336423993,
      "learning_rate": 6.406629518502644e-06,
      "loss": 0.1617,
      "step": 47570
    },
    {
      "epoch": 10.197171024432063,
      "grad_norm": 0.049747318029403687,
      "learning_rate": 6.403771967423919e-06,
      "loss": 0.0001,
      "step": 47580
    },
    {
      "epoch": 10.199314187741106,
      "grad_norm": 0.000544218928553164,
      "learning_rate": 6.400914416345193e-06,
      "loss": 0.0002,
      "step": 47590
    },
    {
      "epoch": 10.20145735105015,
      "grad_norm": 0.00014715637371409684,
      "learning_rate": 6.3980568652664676e-06,
      "loss": 0.0001,
      "step": 47600
    },
    {
      "epoch": 10.203600514359195,
      "grad_norm": 0.00014107242168392986,
      "learning_rate": 6.3951993141877415e-06,
      "loss": 0.0002,
      "step": 47610
    },
    {
      "epoch": 10.205743677668238,
      "grad_norm": 0.0011857959907501936,
      "learning_rate": 6.3923417631090154e-06,
      "loss": 0.0,
      "step": 47620
    },
    {
      "epoch": 10.207886840977283,
      "grad_norm": 0.00012652191799134016,
      "learning_rate": 6.38948421203029e-06,
      "loss": 0.0,
      "step": 47630
    },
    {
      "epoch": 10.210030004286327,
      "grad_norm": 9.666296682553366e-05,
      "learning_rate": 6.386626660951565e-06,
      "loss": 0.0,
      "step": 47640
    },
    {
      "epoch": 10.21217316759537,
      "grad_norm": 6.973976269364357e-05,
      "learning_rate": 6.38376910987284e-06,
      "loss": 0.0,
      "step": 47650
    },
    {
      "epoch": 10.214316330904415,
      "grad_norm": 0.00031743705039843917,
      "learning_rate": 6.380911558794114e-06,
      "loss": 0.1657,
      "step": 47660
    },
    {
      "epoch": 10.21645949421346,
      "grad_norm": 7.077659392962232e-05,
      "learning_rate": 6.3780540077153885e-06,
      "loss": 0.0002,
      "step": 47670
    },
    {
      "epoch": 10.218602657522503,
      "grad_norm": 0.030314665287733078,
      "learning_rate": 6.375196456636663e-06,
      "loss": 0.0004,
      "step": 47680
    },
    {
      "epoch": 10.220745820831548,
      "grad_norm": 0.06188388913869858,
      "learning_rate": 6.372338905557938e-06,
      "loss": 0.0001,
      "step": 47690
    },
    {
      "epoch": 10.222888984140592,
      "grad_norm": 8.386674016946927e-05,
      "learning_rate": 6.369481354479212e-06,
      "loss": 0.1558,
      "step": 47700
    },
    {
      "epoch": 10.225032147449635,
      "grad_norm": 0.00027672084979712963,
      "learning_rate": 6.366623803400487e-06,
      "loss": 0.0,
      "step": 47710
    },
    {
      "epoch": 10.22717531075868,
      "grad_norm": 7.814531272742897e-05,
      "learning_rate": 6.363766252321761e-06,
      "loss": 0.0004,
      "step": 47720
    },
    {
      "epoch": 10.229318474067725,
      "grad_norm": 8.362201333511621e-05,
      "learning_rate": 6.3609087012430346e-06,
      "loss": 0.0,
      "step": 47730
    },
    {
      "epoch": 10.231461637376768,
      "grad_norm": 8.034884376684204e-05,
      "learning_rate": 6.358051150164309e-06,
      "loss": 0.0002,
      "step": 47740
    },
    {
      "epoch": 10.233604800685812,
      "grad_norm": 5.508576214197092e-05,
      "learning_rate": 6.355193599085584e-06,
      "loss": 0.1466,
      "step": 47750
    },
    {
      "epoch": 10.235747963994857,
      "grad_norm": 0.00022974713647272438,
      "learning_rate": 6.352336048006859e-06,
      "loss": 0.0001,
      "step": 47760
    },
    {
      "epoch": 10.2378911273039,
      "grad_norm": 0.0011223169276490808,
      "learning_rate": 6.349478496928133e-06,
      "loss": 0.0,
      "step": 47770
    },
    {
      "epoch": 10.240034290612945,
      "grad_norm": 0.00017171168292406946,
      "learning_rate": 6.346620945849408e-06,
      "loss": 0.0001,
      "step": 47780
    },
    {
      "epoch": 10.24217745392199,
      "grad_norm": 6.506200588773936e-05,
      "learning_rate": 6.343763394770682e-06,
      "loss": 0.0,
      "step": 47790
    },
    {
      "epoch": 10.244320617231033,
      "grad_norm": 5.396906999521889e-05,
      "learning_rate": 6.340905843691957e-06,
      "loss": 0.0001,
      "step": 47800
    },
    {
      "epoch": 10.246463780540077,
      "grad_norm": 0.00013920303899794817,
      "learning_rate": 6.338048292613231e-06,
      "loss": 0.0007,
      "step": 47810
    },
    {
      "epoch": 10.248606943849122,
      "grad_norm": 7.082312367856503e-05,
      "learning_rate": 6.335190741534506e-06,
      "loss": 0.0,
      "step": 47820
    },
    {
      "epoch": 10.250750107158165,
      "grad_norm": 0.009754674509167671,
      "learning_rate": 6.33233319045578e-06,
      "loss": 0.0001,
      "step": 47830
    },
    {
      "epoch": 10.25289327046721,
      "grad_norm": 4.1774492274271324e-05,
      "learning_rate": 6.329475639377054e-06,
      "loss": 0.0003,
      "step": 47840
    },
    {
      "epoch": 10.255036433776255,
      "grad_norm": 0.00018399296095594764,
      "learning_rate": 6.3266180882983285e-06,
      "loss": 0.0,
      "step": 47850
    },
    {
      "epoch": 10.257179597085297,
      "grad_norm": 0.0003342244599480182,
      "learning_rate": 6.323760537219603e-06,
      "loss": 0.0004,
      "step": 47860
    },
    {
      "epoch": 10.259322760394342,
      "grad_norm": 5.271851478028111e-05,
      "learning_rate": 6.320902986140878e-06,
      "loss": 0.0,
      "step": 47870
    },
    {
      "epoch": 10.261465923703387,
      "grad_norm": 5.275733565213159e-05,
      "learning_rate": 6.318045435062152e-06,
      "loss": 0.0,
      "step": 47880
    },
    {
      "epoch": 10.26360908701243,
      "grad_norm": 0.00032382135395891964,
      "learning_rate": 6.315187883983427e-06,
      "loss": 0.0,
      "step": 47890
    },
    {
      "epoch": 10.265752250321475,
      "grad_norm": 4.570337841869332e-05,
      "learning_rate": 6.3123303329047015e-06,
      "loss": 0.0,
      "step": 47900
    },
    {
      "epoch": 10.26789541363052,
      "grad_norm": 0.0007144907722249627,
      "learning_rate": 6.309472781825976e-06,
      "loss": 0.0,
      "step": 47910
    },
    {
      "epoch": 10.270038576939562,
      "grad_norm": 6.363631109707057e-05,
      "learning_rate": 6.30661523074725e-06,
      "loss": 0.0,
      "step": 47920
    },
    {
      "epoch": 10.272181740248607,
      "grad_norm": 0.008905715309083462,
      "learning_rate": 6.303757679668525e-06,
      "loss": 0.0,
      "step": 47930
    },
    {
      "epoch": 10.274324903557652,
      "grad_norm": 0.00027056760154664516,
      "learning_rate": 6.300900128589799e-06,
      "loss": 0.0001,
      "step": 47940
    },
    {
      "epoch": 10.276468066866695,
      "grad_norm": 2.5138115233858116e-05,
      "learning_rate": 6.298042577511073e-06,
      "loss": 0.0,
      "step": 47950
    },
    {
      "epoch": 10.27861123017574,
      "grad_norm": 7.343893958022818e-05,
      "learning_rate": 6.295185026432348e-06,
      "loss": 0.0,
      "step": 47960
    },
    {
      "epoch": 10.280754393484784,
      "grad_norm": 5.929368853685446e-05,
      "learning_rate": 6.292327475353622e-06,
      "loss": 0.0,
      "step": 47970
    },
    {
      "epoch": 10.282897556793827,
      "grad_norm": 5.496450830833055e-05,
      "learning_rate": 6.289469924274897e-06,
      "loss": 0.0003,
      "step": 47980
    },
    {
      "epoch": 10.285040720102872,
      "grad_norm": 0.00017948707682080567,
      "learning_rate": 6.286612373196171e-06,
      "loss": 0.0,
      "step": 47990
    },
    {
      "epoch": 10.287183883411917,
      "grad_norm": 3.158390973112546e-05,
      "learning_rate": 6.283754822117446e-06,
      "loss": 0.0,
      "step": 48000
    },
    {
      "epoch": 10.28932704672096,
      "grad_norm": 0.009471248835325241,
      "learning_rate": 6.280897271038721e-06,
      "loss": 0.0,
      "step": 48010
    },
    {
      "epoch": 10.291470210030004,
      "grad_norm": 0.00017150012718047947,
      "learning_rate": 6.2780397199599954e-06,
      "loss": 0.0001,
      "step": 48020
    },
    {
      "epoch": 10.29361337333905,
      "grad_norm": 0.037302978336811066,
      "learning_rate": 6.275182168881269e-06,
      "loss": 0.0004,
      "step": 48030
    },
    {
      "epoch": 10.295756536648092,
      "grad_norm": 2.2147336494526826e-05,
      "learning_rate": 6.272324617802543e-06,
      "loss": 0.0,
      "step": 48040
    },
    {
      "epoch": 10.297899699957137,
      "grad_norm": 3.019794894498773e-05,
      "learning_rate": 6.269467066723818e-06,
      "loss": 0.0003,
      "step": 48050
    },
    {
      "epoch": 10.300042863266182,
      "grad_norm": 7.750695658614859e-05,
      "learning_rate": 6.266609515645092e-06,
      "loss": 0.0,
      "step": 48060
    },
    {
      "epoch": 10.302186026575225,
      "grad_norm": 8.949885523179546e-05,
      "learning_rate": 6.263751964566367e-06,
      "loss": 0.0001,
      "step": 48070
    },
    {
      "epoch": 10.30432918988427,
      "grad_norm": 2.6286370484740473e-05,
      "learning_rate": 6.2608944134876415e-06,
      "loss": 0.0,
      "step": 48080
    },
    {
      "epoch": 10.306472353193314,
      "grad_norm": 1.7356253010802902e-05,
      "learning_rate": 6.258036862408916e-06,
      "loss": 0.0,
      "step": 48090
    },
    {
      "epoch": 10.308615516502357,
      "grad_norm": 2.351098373765126e-05,
      "learning_rate": 6.25517931133019e-06,
      "loss": 0.1584,
      "step": 48100
    },
    {
      "epoch": 10.310758679811402,
      "grad_norm": 3.001595541718416e-05,
      "learning_rate": 6.252321760251465e-06,
      "loss": 0.0,
      "step": 48110
    },
    {
      "epoch": 10.312901843120446,
      "grad_norm": 1.8235765310237184e-05,
      "learning_rate": 6.24946420917274e-06,
      "loss": 0.0,
      "step": 48120
    },
    {
      "epoch": 10.31504500642949,
      "grad_norm": 2.6505720597924665e-05,
      "learning_rate": 6.2466066580940146e-06,
      "loss": 0.0,
      "step": 48130
    },
    {
      "epoch": 10.317188169738534,
      "grad_norm": 0.0002057460369542241,
      "learning_rate": 6.2437491070152885e-06,
      "loss": 0.0,
      "step": 48140
    },
    {
      "epoch": 10.319331333047579,
      "grad_norm": 2.5592726160539314e-05,
      "learning_rate": 6.2408915559365624e-06,
      "loss": 0.0,
      "step": 48150
    },
    {
      "epoch": 10.321474496356622,
      "grad_norm": 2.358019264647737e-05,
      "learning_rate": 6.238034004857837e-06,
      "loss": 0.1551,
      "step": 48160
    },
    {
      "epoch": 10.323617659665667,
      "grad_norm": 3.132378333248198e-05,
      "learning_rate": 6.235176453779111e-06,
      "loss": 0.0002,
      "step": 48170
    },
    {
      "epoch": 10.325760822974711,
      "grad_norm": 2.4083103198790923e-05,
      "learning_rate": 6.232318902700386e-06,
      "loss": 0.0007,
      "step": 48180
    },
    {
      "epoch": 10.327903986283754,
      "grad_norm": 2.194925218645949e-05,
      "learning_rate": 6.229461351621661e-06,
      "loss": 0.0001,
      "step": 48190
    },
    {
      "epoch": 10.330047149592799,
      "grad_norm": 0.00013531277363654226,
      "learning_rate": 6.2266038005429355e-06,
      "loss": 0.0001,
      "step": 48200
    },
    {
      "epoch": 10.332190312901844,
      "grad_norm": 123.24594116210938,
      "learning_rate": 6.223746249464209e-06,
      "loss": 0.2325,
      "step": 48210
    },
    {
      "epoch": 10.334333476210887,
      "grad_norm": 0.00021742841636296362,
      "learning_rate": 6.220888698385484e-06,
      "loss": 0.0,
      "step": 48220
    },
    {
      "epoch": 10.336476639519931,
      "grad_norm": 5.456785220303573e-05,
      "learning_rate": 6.218031147306759e-06,
      "loss": 0.0,
      "step": 48230
    },
    {
      "epoch": 10.338619802828976,
      "grad_norm": 4.319606887293048e-05,
      "learning_rate": 6.215173596228034e-06,
      "loss": 0.0,
      "step": 48240
    },
    {
      "epoch": 10.34076296613802,
      "grad_norm": 2.2283287762547843e-05,
      "learning_rate": 6.2123160451493085e-06,
      "loss": 0.0,
      "step": 48250
    },
    {
      "epoch": 10.342906129447064,
      "grad_norm": 2.464410317770671e-05,
      "learning_rate": 6.2094584940705816e-06,
      "loss": 0.0,
      "step": 48260
    },
    {
      "epoch": 10.345049292756109,
      "grad_norm": 6.0952326748520136e-05,
      "learning_rate": 6.206600942991856e-06,
      "loss": 0.0003,
      "step": 48270
    },
    {
      "epoch": 10.347192456065152,
      "grad_norm": 2.905462315538898e-05,
      "learning_rate": 6.20374339191313e-06,
      "loss": 0.0003,
      "step": 48280
    },
    {
      "epoch": 10.349335619374196,
      "grad_norm": 1.864104524429422e-05,
      "learning_rate": 6.200885840834405e-06,
      "loss": 0.0,
      "step": 48290
    },
    {
      "epoch": 10.351478782683241,
      "grad_norm": 3.068366277148016e-05,
      "learning_rate": 6.19802828975568e-06,
      "loss": 0.0,
      "step": 48300
    },
    {
      "epoch": 10.353621945992284,
      "grad_norm": 3.583476791391149e-05,
      "learning_rate": 6.195170738676955e-06,
      "loss": 0.0,
      "step": 48310
    },
    {
      "epoch": 10.355765109301329,
      "grad_norm": 6.874472455820069e-05,
      "learning_rate": 6.192313187598229e-06,
      "loss": 0.0,
      "step": 48320
    },
    {
      "epoch": 10.357908272610374,
      "grad_norm": 0.0003524554776959121,
      "learning_rate": 6.189455636519503e-06,
      "loss": 0.0002,
      "step": 48330
    },
    {
      "epoch": 10.360051435919416,
      "grad_norm": 7.508699491154402e-05,
      "learning_rate": 6.186598085440778e-06,
      "loss": 0.0,
      "step": 48340
    },
    {
      "epoch": 10.362194599228461,
      "grad_norm": 0.0003084366035182029,
      "learning_rate": 6.183740534362053e-06,
      "loss": 0.0,
      "step": 48350
    },
    {
      "epoch": 10.364337762537506,
      "grad_norm": 1.9707626051967964e-05,
      "learning_rate": 6.180882983283326e-06,
      "loss": 0.0005,
      "step": 48360
    },
    {
      "epoch": 10.366480925846549,
      "grad_norm": 1.4335054402181413e-05,
      "learning_rate": 6.178025432204601e-06,
      "loss": 0.0,
      "step": 48370
    },
    {
      "epoch": 10.368624089155594,
      "grad_norm": 1.5313888070522808e-05,
      "learning_rate": 6.1751678811258755e-06,
      "loss": 0.0,
      "step": 48380
    },
    {
      "epoch": 10.370767252464638,
      "grad_norm": 0.0002624736225698143,
      "learning_rate": 6.17231033004715e-06,
      "loss": 0.0,
      "step": 48390
    },
    {
      "epoch": 10.372910415773681,
      "grad_norm": 2.936224700533785e-05,
      "learning_rate": 6.169452778968424e-06,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 10.375053579082726,
      "grad_norm": 0.0001073714520316571,
      "learning_rate": 6.166595227889699e-06,
      "loss": 0.0,
      "step": 48410
    },
    {
      "epoch": 10.37719674239177,
      "grad_norm": 3.48789690178819e-05,
      "learning_rate": 6.163737676810974e-06,
      "loss": 0.0004,
      "step": 48420
    },
    {
      "epoch": 10.379339905700814,
      "grad_norm": 2.0633362510125153e-05,
      "learning_rate": 6.1608801257322485e-06,
      "loss": 0.0,
      "step": 48430
    },
    {
      "epoch": 10.381483069009859,
      "grad_norm": 4.354284828878008e-05,
      "learning_rate": 6.1580225746535224e-06,
      "loss": 0.0,
      "step": 48440
    },
    {
      "epoch": 10.383626232318903,
      "grad_norm": 1.6094949387479573e-05,
      "learning_rate": 6.155165023574797e-06,
      "loss": 0.0,
      "step": 48450
    },
    {
      "epoch": 10.385769395627946,
      "grad_norm": 3.253161412430927e-05,
      "learning_rate": 6.152307472496072e-06,
      "loss": 0.0,
      "step": 48460
    },
    {
      "epoch": 10.387912558936991,
      "grad_norm": 2.4344006305909716e-05,
      "learning_rate": 6.149449921417345e-06,
      "loss": 0.0,
      "step": 48470
    },
    {
      "epoch": 10.390055722246036,
      "grad_norm": 2.797637353069149e-05,
      "learning_rate": 6.14659237033862e-06,
      "loss": 0.0,
      "step": 48480
    },
    {
      "epoch": 10.392198885555079,
      "grad_norm": 2.2701589841744862e-05,
      "learning_rate": 6.143734819259895e-06,
      "loss": 0.0005,
      "step": 48490
    },
    {
      "epoch": 10.394342048864123,
      "grad_norm": 0.00019998483185190707,
      "learning_rate": 6.140877268181169e-06,
      "loss": 0.0001,
      "step": 48500
    },
    {
      "epoch": 10.396485212173168,
      "grad_norm": 1.4729837857885286e-05,
      "learning_rate": 6.138019717102443e-06,
      "loss": 0.3802,
      "step": 48510
    },
    {
      "epoch": 10.398628375482211,
      "grad_norm": 1.8739174265647307e-05,
      "learning_rate": 6.135162166023718e-06,
      "loss": 0.0,
      "step": 48520
    },
    {
      "epoch": 10.400771538791256,
      "grad_norm": 1.568955667607952e-05,
      "learning_rate": 6.132304614944993e-06,
      "loss": 0.0,
      "step": 48530
    },
    {
      "epoch": 10.4029147021003,
      "grad_norm": 1.60489998961566e-05,
      "learning_rate": 6.129447063866268e-06,
      "loss": 0.0002,
      "step": 48540
    },
    {
      "epoch": 10.405057865409344,
      "grad_norm": 2.0930565369781107e-05,
      "learning_rate": 6.126589512787542e-06,
      "loss": 0.0,
      "step": 48550
    },
    {
      "epoch": 10.407201028718388,
      "grad_norm": 2.1715599359595217e-05,
      "learning_rate": 6.123731961708816e-06,
      "loss": 0.3192,
      "step": 48560
    },
    {
      "epoch": 10.409344192027433,
      "grad_norm": 3.488765287329443e-05,
      "learning_rate": 6.120874410630091e-06,
      "loss": 0.0,
      "step": 48570
    },
    {
      "epoch": 10.411487355336476,
      "grad_norm": 1.5773073755553924e-05,
      "learning_rate": 6.118016859551364e-06,
      "loss": 0.0,
      "step": 48580
    },
    {
      "epoch": 10.41363051864552,
      "grad_norm": 3.2260115403914824e-05,
      "learning_rate": 6.115159308472639e-06,
      "loss": 0.0,
      "step": 48590
    },
    {
      "epoch": 10.415773681954565,
      "grad_norm": 2.465434772602748e-05,
      "learning_rate": 6.112301757393914e-06,
      "loss": 0.0,
      "step": 48600
    },
    {
      "epoch": 10.417916845263608,
      "grad_norm": 0.00039947222103364766,
      "learning_rate": 6.1094442063151885e-06,
      "loss": 0.0,
      "step": 48610
    },
    {
      "epoch": 10.420060008572653,
      "grad_norm": 2.232268343504984e-05,
      "learning_rate": 6.1065866552364625e-06,
      "loss": 0.0005,
      "step": 48620
    },
    {
      "epoch": 10.422203171881698,
      "grad_norm": 1.9077586330240592e-05,
      "learning_rate": 6.103729104157737e-06,
      "loss": 0.0004,
      "step": 48630
    },
    {
      "epoch": 10.42434633519074,
      "grad_norm": 9.129633690463379e-05,
      "learning_rate": 6.100871553079012e-06,
      "loss": 0.0,
      "step": 48640
    },
    {
      "epoch": 10.426489498499786,
      "grad_norm": 1.4743799511052202e-05,
      "learning_rate": 6.098014002000287e-06,
      "loss": 0.0,
      "step": 48650
    },
    {
      "epoch": 10.42863266180883,
      "grad_norm": 2.59126700257184e-05,
      "learning_rate": 6.095156450921561e-06,
      "loss": 0.0,
      "step": 48660
    },
    {
      "epoch": 10.430775825117873,
      "grad_norm": 2.5691400878713466e-05,
      "learning_rate": 6.0922988998428355e-06,
      "loss": 0.0001,
      "step": 48670
    },
    {
      "epoch": 10.432918988426918,
      "grad_norm": 2.8927766834385693e-05,
      "learning_rate": 6.08944134876411e-06,
      "loss": 0.0005,
      "step": 48680
    },
    {
      "epoch": 10.435062151735963,
      "grad_norm": 1.6651902114972472e-05,
      "learning_rate": 6.086583797685383e-06,
      "loss": 0.0,
      "step": 48690
    },
    {
      "epoch": 10.437205315045006,
      "grad_norm": 1.4112609278527088e-05,
      "learning_rate": 6.083726246606658e-06,
      "loss": 0.0,
      "step": 48700
    },
    {
      "epoch": 10.43934847835405,
      "grad_norm": 0.00018820386321749538,
      "learning_rate": 6.080868695527933e-06,
      "loss": 0.0,
      "step": 48710
    },
    {
      "epoch": 10.441491641663095,
      "grad_norm": 6.894124817335978e-05,
      "learning_rate": 6.078011144449208e-06,
      "loss": 0.2198,
      "step": 48720
    },
    {
      "epoch": 10.443634804972138,
      "grad_norm": 4.5543707528850064e-05,
      "learning_rate": 6.075153593370482e-06,
      "loss": 0.1789,
      "step": 48730
    },
    {
      "epoch": 10.445777968281183,
      "grad_norm": 3.0723633244633675e-05,
      "learning_rate": 6.072296042291756e-06,
      "loss": 0.0,
      "step": 48740
    },
    {
      "epoch": 10.447921131590228,
      "grad_norm": 3.663837560452521e-05,
      "learning_rate": 6.069438491213031e-06,
      "loss": 0.0,
      "step": 48750
    },
    {
      "epoch": 10.45006429489927,
      "grad_norm": 0.0003919984446838498,
      "learning_rate": 6.066580940134306e-06,
      "loss": 0.0,
      "step": 48760
    },
    {
      "epoch": 10.452207458208315,
      "grad_norm": 0.000659941986668855,
      "learning_rate": 6.06372338905558e-06,
      "loss": 0.0,
      "step": 48770
    },
    {
      "epoch": 10.45435062151736,
      "grad_norm": 4.723338861367665e-05,
      "learning_rate": 6.060865837976855e-06,
      "loss": 0.0,
      "step": 48780
    },
    {
      "epoch": 10.456493784826403,
      "grad_norm": 3.3251366403419524e-05,
      "learning_rate": 6.0580082868981286e-06,
      "loss": 0.0003,
      "step": 48790
    },
    {
      "epoch": 10.458636948135448,
      "grad_norm": 2.1664125597453676e-05,
      "learning_rate": 6.0551507358194025e-06,
      "loss": 0.0,
      "step": 48800
    },
    {
      "epoch": 10.460780111444492,
      "grad_norm": 2.0031553503940813e-05,
      "learning_rate": 6.052293184740677e-06,
      "loss": 0.0003,
      "step": 48810
    },
    {
      "epoch": 10.462923274753535,
      "grad_norm": 2.4685292373760603e-05,
      "learning_rate": 6.049435633661952e-06,
      "loss": 0.0,
      "step": 48820
    },
    {
      "epoch": 10.46506643806258,
      "grad_norm": 0.07634692639112473,
      "learning_rate": 6.046578082583227e-06,
      "loss": 0.0001,
      "step": 48830
    },
    {
      "epoch": 10.467209601371625,
      "grad_norm": 3.862085213768296e-05,
      "learning_rate": 6.043720531504501e-06,
      "loss": 0.0,
      "step": 48840
    },
    {
      "epoch": 10.469352764680668,
      "grad_norm": 0.00032954555354081094,
      "learning_rate": 6.0408629804257755e-06,
      "loss": 0.0,
      "step": 48850
    },
    {
      "epoch": 10.471495927989713,
      "grad_norm": 2.465986108290963e-05,
      "learning_rate": 6.03800542934705e-06,
      "loss": 0.0003,
      "step": 48860
    },
    {
      "epoch": 10.473639091298757,
      "grad_norm": 1.545207851449959e-05,
      "learning_rate": 6.035147878268325e-06,
      "loss": 0.0,
      "step": 48870
    },
    {
      "epoch": 10.4757822546078,
      "grad_norm": 1.9821209207293577e-05,
      "learning_rate": 6.032290327189599e-06,
      "loss": 0.0,
      "step": 48880
    },
    {
      "epoch": 10.477925417916845,
      "grad_norm": 0.00017479655798524618,
      "learning_rate": 6.029432776110874e-06,
      "loss": 0.0,
      "step": 48890
    },
    {
      "epoch": 10.48006858122589,
      "grad_norm": 0.03179226815700531,
      "learning_rate": 6.026575225032148e-06,
      "loss": 0.0,
      "step": 48900
    },
    {
      "epoch": 10.482211744534933,
      "grad_norm": 0.05486978590488434,
      "learning_rate": 6.023717673953422e-06,
      "loss": 0.0,
      "step": 48910
    },
    {
      "epoch": 10.484354907843978,
      "grad_norm": 1.8572278349893168e-05,
      "learning_rate": 6.020860122874696e-06,
      "loss": 0.0,
      "step": 48920
    },
    {
      "epoch": 10.486498071153022,
      "grad_norm": 5.835871706949547e-05,
      "learning_rate": 6.018002571795971e-06,
      "loss": 0.0,
      "step": 48930
    },
    {
      "epoch": 10.488641234462065,
      "grad_norm": 0.0007997110369615257,
      "learning_rate": 6.015145020717246e-06,
      "loss": 0.0,
      "step": 48940
    },
    {
      "epoch": 10.49078439777111,
      "grad_norm": 3.5297787690069526e-05,
      "learning_rate": 6.01228746963852e-06,
      "loss": 0.0,
      "step": 48950
    },
    {
      "epoch": 10.492927561080155,
      "grad_norm": 2.1796044165967032e-05,
      "learning_rate": 6.009429918559795e-06,
      "loss": 0.0001,
      "step": 48960
    },
    {
      "epoch": 10.495070724389198,
      "grad_norm": 0.007863275706768036,
      "learning_rate": 6.0065723674810694e-06,
      "loss": 0.0003,
      "step": 48970
    },
    {
      "epoch": 10.497213887698242,
      "grad_norm": 2.0499206584645435e-05,
      "learning_rate": 6.003714816402344e-06,
      "loss": 0.0003,
      "step": 48980
    },
    {
      "epoch": 10.499357051007287,
      "grad_norm": 0.00042671128176152706,
      "learning_rate": 6.000857265323618e-06,
      "loss": 0.0,
      "step": 48990
    },
    {
      "epoch": 10.50150021431633,
      "grad_norm": 0.20395022630691528,
      "learning_rate": 5.997999714244893e-06,
      "loss": 0.0004,
      "step": 49000
    },
    {
      "epoch": 10.503643377625375,
      "grad_norm": 2.6371963031124324e-05,
      "learning_rate": 5.995142163166167e-06,
      "loss": 0.0,
      "step": 49010
    },
    {
      "epoch": 10.50578654093442,
      "grad_norm": 2.258469430671539e-05,
      "learning_rate": 5.992284612087441e-06,
      "loss": 0.0,
      "step": 49020
    },
    {
      "epoch": 10.507929704243463,
      "grad_norm": 1.8816817828337662e-05,
      "learning_rate": 5.9894270610087156e-06,
      "loss": 0.0,
      "step": 49030
    },
    {
      "epoch": 10.510072867552507,
      "grad_norm": 2.3039983716444112e-05,
      "learning_rate": 5.98656950992999e-06,
      "loss": 0.0,
      "step": 49040
    },
    {
      "epoch": 10.512216030861552,
      "grad_norm": 0.0001468518894398585,
      "learning_rate": 5.983711958851265e-06,
      "loss": 0.0,
      "step": 49050
    },
    {
      "epoch": 10.514359194170595,
      "grad_norm": 1.235222771356348e-05,
      "learning_rate": 5.980854407772539e-06,
      "loss": 0.0,
      "step": 49060
    },
    {
      "epoch": 10.51650235747964,
      "grad_norm": 4.7919103963067755e-05,
      "learning_rate": 5.977996856693814e-06,
      "loss": 0.1576,
      "step": 49070
    },
    {
      "epoch": 10.518645520788684,
      "grad_norm": 0.0008665684144943953,
      "learning_rate": 5.975139305615089e-06,
      "loss": 0.0,
      "step": 49080
    },
    {
      "epoch": 10.520788684097727,
      "grad_norm": 3.2339783501811326e-05,
      "learning_rate": 5.972281754536363e-06,
      "loss": 0.0,
      "step": 49090
    },
    {
      "epoch": 10.522931847406772,
      "grad_norm": 0.000205382879357785,
      "learning_rate": 5.969424203457638e-06,
      "loss": 0.0,
      "step": 49100
    },
    {
      "epoch": 10.525075010715817,
      "grad_norm": 5.978827175567858e-05,
      "learning_rate": 5.966566652378912e-06,
      "loss": 0.0,
      "step": 49110
    },
    {
      "epoch": 10.52721817402486,
      "grad_norm": 2.5740508135640994e-05,
      "learning_rate": 5.963709101300186e-06,
      "loss": 0.0003,
      "step": 49120
    },
    {
      "epoch": 10.529361337333905,
      "grad_norm": 0.00017573891091160476,
      "learning_rate": 5.96085155022146e-06,
      "loss": 0.1423,
      "step": 49130
    },
    {
      "epoch": 10.53150450064295,
      "grad_norm": 5.627809514408e-05,
      "learning_rate": 5.957993999142735e-06,
      "loss": 0.0,
      "step": 49140
    },
    {
      "epoch": 10.533647663951992,
      "grad_norm": 3.255324190831743e-05,
      "learning_rate": 5.9551364480640095e-06,
      "loss": 0.0,
      "step": 49150
    },
    {
      "epoch": 10.535790827261037,
      "grad_norm": 3.397615364519879e-05,
      "learning_rate": 5.952278896985284e-06,
      "loss": 0.0,
      "step": 49160
    },
    {
      "epoch": 10.537933990570082,
      "grad_norm": 2.3467649953090586e-05,
      "learning_rate": 5.949421345906559e-06,
      "loss": 0.0003,
      "step": 49170
    },
    {
      "epoch": 10.540077153879125,
      "grad_norm": 7.943453965708613e-05,
      "learning_rate": 5.946563794827833e-06,
      "loss": 0.1504,
      "step": 49180
    },
    {
      "epoch": 10.54222031718817,
      "grad_norm": 0.00028782940353266895,
      "learning_rate": 5.943706243749108e-06,
      "loss": 0.0,
      "step": 49190
    },
    {
      "epoch": 10.544363480497214,
      "grad_norm": 0.00017660888261161745,
      "learning_rate": 5.9408486926703825e-06,
      "loss": 0.0,
      "step": 49200
    },
    {
      "epoch": 10.546506643806257,
      "grad_norm": 3.5091528843622655e-05,
      "learning_rate": 5.937991141591657e-06,
      "loss": 0.0,
      "step": 49210
    },
    {
      "epoch": 10.548649807115302,
      "grad_norm": 0.0007205096771940589,
      "learning_rate": 5.93513359051293e-06,
      "loss": 0.0,
      "step": 49220
    },
    {
      "epoch": 10.550792970424347,
      "grad_norm": 2.3613067241967656e-05,
      "learning_rate": 5.932276039434205e-06,
      "loss": 0.0,
      "step": 49230
    },
    {
      "epoch": 10.55293613373339,
      "grad_norm": 2.9140657716197893e-05,
      "learning_rate": 5.92941848835548e-06,
      "loss": 0.0,
      "step": 49240
    },
    {
      "epoch": 10.555079297042434,
      "grad_norm": 4.884382360614836e-05,
      "learning_rate": 5.926560937276754e-06,
      "loss": 0.0,
      "step": 49250
    },
    {
      "epoch": 10.557222460351479,
      "grad_norm": 0.0031647896394133568,
      "learning_rate": 5.923703386198029e-06,
      "loss": 0.0,
      "step": 49260
    },
    {
      "epoch": 10.559365623660522,
      "grad_norm": 3.411373108974658e-05,
      "learning_rate": 5.920845835119303e-06,
      "loss": 0.0,
      "step": 49270
    },
    {
      "epoch": 10.561508786969567,
      "grad_norm": 1.7665242921793833e-05,
      "learning_rate": 5.917988284040578e-06,
      "loss": 0.0,
      "step": 49280
    },
    {
      "epoch": 10.563651950278611,
      "grad_norm": 2.6660714866011404e-05,
      "learning_rate": 5.915130732961852e-06,
      "loss": 0.0001,
      "step": 49290
    },
    {
      "epoch": 10.565795113587654,
      "grad_norm": 2.5190978703903966e-05,
      "learning_rate": 5.912273181883127e-06,
      "loss": 0.0,
      "step": 49300
    },
    {
      "epoch": 10.5679382768967,
      "grad_norm": 0.0001996264763874933,
      "learning_rate": 5.909415630804402e-06,
      "loss": 0.0052,
      "step": 49310
    },
    {
      "epoch": 10.570081440205744,
      "grad_norm": 0.00011950632324442267,
      "learning_rate": 5.906558079725676e-06,
      "loss": 0.0,
      "step": 49320
    },
    {
      "epoch": 10.572224603514789,
      "grad_norm": 0.0003460902953520417,
      "learning_rate": 5.9037005286469495e-06,
      "loss": 0.0,
      "step": 49330
    },
    {
      "epoch": 10.574367766823832,
      "grad_norm": 0.00014844218094367534,
      "learning_rate": 5.900842977568224e-06,
      "loss": 0.0,
      "step": 49340
    },
    {
      "epoch": 10.576510930132876,
      "grad_norm": 1.8875110981753096e-05,
      "learning_rate": 5.897985426489499e-06,
      "loss": 0.0,
      "step": 49350
    },
    {
      "epoch": 10.578654093441921,
      "grad_norm": 1.4358720363816246e-05,
      "learning_rate": 5.895127875410773e-06,
      "loss": 0.1314,
      "step": 49360
    },
    {
      "epoch": 10.580797256750964,
      "grad_norm": 1.1987031030002981e-05,
      "learning_rate": 5.892270324332048e-06,
      "loss": 0.0,
      "step": 49370
    },
    {
      "epoch": 10.582940420060009,
      "grad_norm": 1.4887863471813034e-05,
      "learning_rate": 5.8894127732533225e-06,
      "loss": 0.0,
      "step": 49380
    },
    {
      "epoch": 10.585083583369054,
      "grad_norm": 81.99479675292969,
      "learning_rate": 5.886555222174597e-06,
      "loss": 0.261,
      "step": 49390
    },
    {
      "epoch": 10.587226746678096,
      "grad_norm": 0.00011522049317136407,
      "learning_rate": 5.883697671095871e-06,
      "loss": 0.0,
      "step": 49400
    },
    {
      "epoch": 10.589369909987141,
      "grad_norm": 3.241737067583017e-05,
      "learning_rate": 5.880840120017146e-06,
      "loss": 0.0007,
      "step": 49410
    },
    {
      "epoch": 10.591513073296186,
      "grad_norm": 0.0010871284175664186,
      "learning_rate": 5.877982568938421e-06,
      "loss": 0.0,
      "step": 49420
    },
    {
      "epoch": 10.593656236605229,
      "grad_norm": 5.4578886192757636e-05,
      "learning_rate": 5.8751250178596956e-06,
      "loss": 0.0,
      "step": 49430
    },
    {
      "epoch": 10.595799399914274,
      "grad_norm": 0.00031054855207912624,
      "learning_rate": 5.872267466780969e-06,
      "loss": 0.0,
      "step": 49440
    },
    {
      "epoch": 10.597942563223318,
      "grad_norm": 2.4700699214008637e-05,
      "learning_rate": 5.869409915702243e-06,
      "loss": 0.0008,
      "step": 49450
    },
    {
      "epoch": 10.600085726532361,
      "grad_norm": 3.314642162877135e-05,
      "learning_rate": 5.866552364623518e-06,
      "loss": 0.0,
      "step": 49460
    },
    {
      "epoch": 10.602228889841406,
      "grad_norm": 0.0001646662421990186,
      "learning_rate": 5.863694813544792e-06,
      "loss": 0.1808,
      "step": 49470
    },
    {
      "epoch": 10.60437205315045,
      "grad_norm": 0.00020596380636561662,
      "learning_rate": 5.860837262466067e-06,
      "loss": 0.0015,
      "step": 49480
    },
    {
      "epoch": 10.606515216459494,
      "grad_norm": 2.1192772692302242e-05,
      "learning_rate": 5.857979711387342e-06,
      "loss": 0.0006,
      "step": 49490
    },
    {
      "epoch": 10.608658379768539,
      "grad_norm": 0.00027391116600483656,
      "learning_rate": 5.8551221603086164e-06,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 10.610801543077583,
      "grad_norm": 2.5133718736469746e-05,
      "learning_rate": 5.85226460922989e-06,
      "loss": 0.0003,
      "step": 49510
    },
    {
      "epoch": 10.612944706386626,
      "grad_norm": 0.0650482177734375,
      "learning_rate": 5.849407058151165e-06,
      "loss": 0.0002,
      "step": 49520
    },
    {
      "epoch": 10.615087869695671,
      "grad_norm": 1.7213966202689335e-05,
      "learning_rate": 5.84654950707244e-06,
      "loss": 0.0,
      "step": 49530
    },
    {
      "epoch": 10.617231033004716,
      "grad_norm": 1.5783876733621582e-05,
      "learning_rate": 5.843691955993715e-06,
      "loss": 0.0002,
      "step": 49540
    },
    {
      "epoch": 10.619374196313759,
      "grad_norm": 0.002392624272033572,
      "learning_rate": 5.840834404914988e-06,
      "loss": 0.0009,
      "step": 49550
    },
    {
      "epoch": 10.621517359622803,
      "grad_norm": 0.14225932955741882,
      "learning_rate": 5.8379768538362625e-06,
      "loss": 0.0002,
      "step": 49560
    },
    {
      "epoch": 10.623660522931848,
      "grad_norm": 1.743269240250811e-05,
      "learning_rate": 5.835119302757537e-06,
      "loss": 0.2377,
      "step": 49570
    },
    {
      "epoch": 10.625803686240891,
      "grad_norm": 2.603203938633669e-05,
      "learning_rate": 5.832261751678811e-06,
      "loss": 0.0,
      "step": 49580
    },
    {
      "epoch": 10.627946849549936,
      "grad_norm": 2.5798362912610173e-05,
      "learning_rate": 5.829404200600086e-06,
      "loss": 0.0,
      "step": 49590
    },
    {
      "epoch": 10.63009001285898,
      "grad_norm": 3.877449125866406e-05,
      "learning_rate": 5.826546649521361e-06,
      "loss": 0.0,
      "step": 49600
    },
    {
      "epoch": 10.632233176168024,
      "grad_norm": 0.0003515180142130703,
      "learning_rate": 5.823689098442636e-06,
      "loss": 0.1258,
      "step": 49610
    },
    {
      "epoch": 10.634376339477068,
      "grad_norm": 9.551096445648e-05,
      "learning_rate": 5.8208315473639095e-06,
      "loss": 0.0001,
      "step": 49620
    },
    {
      "epoch": 10.636519502786113,
      "grad_norm": 3.288768857601099e-05,
      "learning_rate": 5.817973996285184e-06,
      "loss": 0.0001,
      "step": 49630
    },
    {
      "epoch": 10.638662666095156,
      "grad_norm": 4.165885547990911e-05,
      "learning_rate": 5.815116445206459e-06,
      "loss": 0.0,
      "step": 49640
    },
    {
      "epoch": 10.6408058294042,
      "grad_norm": 3.143701906083152e-05,
      "learning_rate": 5.812258894127732e-06,
      "loss": 0.0004,
      "step": 49650
    },
    {
      "epoch": 10.642948992713245,
      "grad_norm": 5.85717789363116e-05,
      "learning_rate": 5.809401343049007e-06,
      "loss": 0.0,
      "step": 49660
    },
    {
      "epoch": 10.645092156022288,
      "grad_norm": 0.17388077080249786,
      "learning_rate": 5.806543791970282e-06,
      "loss": 0.0002,
      "step": 49670
    },
    {
      "epoch": 10.647235319331333,
      "grad_norm": 2.9854054446332157e-05,
      "learning_rate": 5.8036862408915565e-06,
      "loss": 0.0,
      "step": 49680
    },
    {
      "epoch": 10.649378482640378,
      "grad_norm": 0.00018396730592940003,
      "learning_rate": 5.80082868981283e-06,
      "loss": 0.0,
      "step": 49690
    },
    {
      "epoch": 10.65152164594942,
      "grad_norm": 2.9634044039994478e-05,
      "learning_rate": 5.797971138734105e-06,
      "loss": 0.0,
      "step": 49700
    },
    {
      "epoch": 10.653664809258466,
      "grad_norm": 4.1787840018514544e-05,
      "learning_rate": 5.79511358765538e-06,
      "loss": 0.1363,
      "step": 49710
    },
    {
      "epoch": 10.65580797256751,
      "grad_norm": 1.9707464161911048e-05,
      "learning_rate": 5.792256036576655e-06,
      "loss": 0.0,
      "step": 49720
    },
    {
      "epoch": 10.657951135876553,
      "grad_norm": 2.6721234462456778e-05,
      "learning_rate": 5.789398485497929e-06,
      "loss": 0.1749,
      "step": 49730
    },
    {
      "epoch": 10.660094299185598,
      "grad_norm": 3.876987102557905e-05,
      "learning_rate": 5.786540934419203e-06,
      "loss": 0.0,
      "step": 49740
    },
    {
      "epoch": 10.662237462494643,
      "grad_norm": 2.991277870023623e-05,
      "learning_rate": 5.783683383340478e-06,
      "loss": 0.0,
      "step": 49750
    },
    {
      "epoch": 10.664380625803686,
      "grad_norm": 3.0074135793256573e-05,
      "learning_rate": 5.780825832261751e-06,
      "loss": 0.0,
      "step": 49760
    },
    {
      "epoch": 10.66652378911273,
      "grad_norm": 2.4358363589271903e-05,
      "learning_rate": 5.777968281183026e-06,
      "loss": 0.0,
      "step": 49770
    },
    {
      "epoch": 10.668666952421775,
      "grad_norm": 0.0013121918309479952,
      "learning_rate": 5.775110730104301e-06,
      "loss": 0.0,
      "step": 49780
    },
    {
      "epoch": 10.670810115730818,
      "grad_norm": 3.089511665166356e-05,
      "learning_rate": 5.772253179025576e-06,
      "loss": 0.2114,
      "step": 49790
    },
    {
      "epoch": 10.672953279039863,
      "grad_norm": 0.00039711775025352836,
      "learning_rate": 5.7693956279468495e-06,
      "loss": 0.0002,
      "step": 49800
    },
    {
      "epoch": 10.675096442348908,
      "grad_norm": 3.3526139304740354e-05,
      "learning_rate": 5.766538076868124e-06,
      "loss": 0.0,
      "step": 49810
    },
    {
      "epoch": 10.67723960565795,
      "grad_norm": 2.9713715775869787e-05,
      "learning_rate": 5.763680525789399e-06,
      "loss": 0.2852,
      "step": 49820
    },
    {
      "epoch": 10.679382768966995,
      "grad_norm": 4.2831554310396314e-05,
      "learning_rate": 5.760822974710674e-06,
      "loss": 0.0,
      "step": 49830
    },
    {
      "epoch": 10.68152593227604,
      "grad_norm": 0.36304113268852234,
      "learning_rate": 5.757965423631949e-06,
      "loss": 0.0553,
      "step": 49840
    },
    {
      "epoch": 10.683669095585083,
      "grad_norm": 2.5169005311909132e-05,
      "learning_rate": 5.7551078725532226e-06,
      "loss": 0.0001,
      "step": 49850
    },
    {
      "epoch": 10.685812258894128,
      "grad_norm": 2.7556441636988893e-05,
      "learning_rate": 5.752250321474497e-06,
      "loss": 0.0,
      "step": 49860
    },
    {
      "epoch": 10.687955422203173,
      "grad_norm": 3.401419962756336e-05,
      "learning_rate": 5.74939277039577e-06,
      "loss": 0.0,
      "step": 49870
    },
    {
      "epoch": 10.690098585512215,
      "grad_norm": 0.06939771771430969,
      "learning_rate": 5.746535219317045e-06,
      "loss": 0.0001,
      "step": 49880
    },
    {
      "epoch": 10.69224174882126,
      "grad_norm": 4.091481605428271e-05,
      "learning_rate": 5.74367766823832e-06,
      "loss": 0.0005,
      "step": 49890
    },
    {
      "epoch": 10.694384912130305,
      "grad_norm": 2.576499173301272e-05,
      "learning_rate": 5.740820117159595e-06,
      "loss": 0.0,
      "step": 49900
    },
    {
      "epoch": 10.696528075439348,
      "grad_norm": 0.00010619077511364594,
      "learning_rate": 5.7379625660808695e-06,
      "loss": 0.0,
      "step": 49910
    },
    {
      "epoch": 10.698671238748393,
      "grad_norm": 0.007524534128606319,
      "learning_rate": 5.7351050150021434e-06,
      "loss": 0.0,
      "step": 49920
    },
    {
      "epoch": 10.700814402057437,
      "grad_norm": 6.105841748649254e-05,
      "learning_rate": 5.732247463923418e-06,
      "loss": 0.0,
      "step": 49930
    },
    {
      "epoch": 10.70295756536648,
      "grad_norm": 0.11197463423013687,
      "learning_rate": 5.729389912844693e-06,
      "loss": 0.0001,
      "step": 49940
    },
    {
      "epoch": 10.705100728675525,
      "grad_norm": 7.670287595828995e-05,
      "learning_rate": 5.726532361765968e-06,
      "loss": 0.0,
      "step": 49950
    },
    {
      "epoch": 10.70724389198457,
      "grad_norm": 1.8459999409969896e-05,
      "learning_rate": 5.723674810687242e-06,
      "loss": 0.0,
      "step": 49960
    },
    {
      "epoch": 10.709387055293613,
      "grad_norm": 0.0002641598111949861,
      "learning_rate": 5.720817259608516e-06,
      "loss": 0.0001,
      "step": 49970
    },
    {
      "epoch": 10.711530218602658,
      "grad_norm": 1.6159478036570363e-05,
      "learning_rate": 5.71795970852979e-06,
      "loss": 0.0,
      "step": 49980
    },
    {
      "epoch": 10.713673381911702,
      "grad_norm": 0.0009003637242130935,
      "learning_rate": 5.715102157451064e-06,
      "loss": 0.0,
      "step": 49990
    },
    {
      "epoch": 10.715816545220745,
      "grad_norm": 3.0928353226045147e-05,
      "learning_rate": 5.712244606372339e-06,
      "loss": 0.0003,
      "step": 50000
    },
    {
      "epoch": 10.71795970852979,
      "grad_norm": 1.6329138816217892e-05,
      "learning_rate": 5.709387055293614e-06,
      "loss": 0.0001,
      "step": 50010
    },
    {
      "epoch": 10.720102871838835,
      "grad_norm": 0.0010160080855712295,
      "learning_rate": 5.706529504214889e-06,
      "loss": 0.0,
      "step": 50020
    },
    {
      "epoch": 10.722246035147878,
      "grad_norm": 1.6967207557172514e-05,
      "learning_rate": 5.703671953136163e-06,
      "loss": 0.0,
      "step": 50030
    },
    {
      "epoch": 10.724389198456922,
      "grad_norm": 0.00997335184365511,
      "learning_rate": 5.700814402057437e-06,
      "loss": 0.0001,
      "step": 50040
    },
    {
      "epoch": 10.726532361765967,
      "grad_norm": 0.011049837805330753,
      "learning_rate": 5.697956850978712e-06,
      "loss": 0.0,
      "step": 50050
    },
    {
      "epoch": 10.72867552507501,
      "grad_norm": 0.00027754358598031104,
      "learning_rate": 5.695099299899987e-06,
      "loss": 0.0,
      "step": 50060
    },
    {
      "epoch": 10.730818688384055,
      "grad_norm": 0.0011041081743314862,
      "learning_rate": 5.692241748821261e-06,
      "loss": 0.0,
      "step": 50070
    },
    {
      "epoch": 10.7329618516931,
      "grad_norm": 0.0007188258459791541,
      "learning_rate": 5.689384197742535e-06,
      "loss": 0.2537,
      "step": 50080
    },
    {
      "epoch": 10.735105015002143,
      "grad_norm": 3.647189078037627e-05,
      "learning_rate": 5.6865266466638095e-06,
      "loss": 0.0,
      "step": 50090
    },
    {
      "epoch": 10.737248178311187,
      "grad_norm": 0.00031344935996457934,
      "learning_rate": 5.6836690955850835e-06,
      "loss": 0.0,
      "step": 50100
    },
    {
      "epoch": 10.739391341620232,
      "grad_norm": 0.02482561394572258,
      "learning_rate": 5.680811544506358e-06,
      "loss": 0.0004,
      "step": 50110
    },
    {
      "epoch": 10.741534504929275,
      "grad_norm": 0.00012461889127735049,
      "learning_rate": 5.677953993427633e-06,
      "loss": 0.1329,
      "step": 50120
    },
    {
      "epoch": 10.74367766823832,
      "grad_norm": 0.0005481921834871173,
      "learning_rate": 5.675096442348908e-06,
      "loss": 0.0003,
      "step": 50130
    },
    {
      "epoch": 10.745820831547364,
      "grad_norm": 5.899815369048156e-05,
      "learning_rate": 5.672238891270182e-06,
      "loss": 0.1634,
      "step": 50140
    },
    {
      "epoch": 10.747963994856407,
      "grad_norm": 0.10688745975494385,
      "learning_rate": 5.6693813401914565e-06,
      "loss": 0.255,
      "step": 50150
    },
    {
      "epoch": 10.750107158165452,
      "grad_norm": 0.00011516360973473638,
      "learning_rate": 5.666523789112731e-06,
      "loss": 0.0027,
      "step": 50160
    },
    {
      "epoch": 10.752250321474497,
      "grad_norm": 0.001296250382438302,
      "learning_rate": 5.663666238034006e-06,
      "loss": 0.0004,
      "step": 50170
    },
    {
      "epoch": 10.75439348478354,
      "grad_norm": 9.244946704711765e-05,
      "learning_rate": 5.66080868695528e-06,
      "loss": 0.0,
      "step": 50180
    },
    {
      "epoch": 10.756536648092585,
      "grad_norm": 0.004055463243275881,
      "learning_rate": 5.657951135876554e-06,
      "loss": 0.0001,
      "step": 50190
    },
    {
      "epoch": 10.75867981140163,
      "grad_norm": 113.86344909667969,
      "learning_rate": 5.655093584797829e-06,
      "loss": 0.1239,
      "step": 50200
    },
    {
      "epoch": 10.760822974710672,
      "grad_norm": 3.0545692425221205e-05,
      "learning_rate": 5.652236033719103e-06,
      "loss": 0.0,
      "step": 50210
    },
    {
      "epoch": 10.762966138019717,
      "grad_norm": 2.431943175906781e-05,
      "learning_rate": 5.649378482640377e-06,
      "loss": 0.0,
      "step": 50220
    },
    {
      "epoch": 10.765109301328762,
      "grad_norm": 0.0009991268161684275,
      "learning_rate": 5.646520931561652e-06,
      "loss": 0.1557,
      "step": 50230
    },
    {
      "epoch": 10.767252464637805,
      "grad_norm": 4.069264468853362e-05,
      "learning_rate": 5.643663380482927e-06,
      "loss": 0.0,
      "step": 50240
    },
    {
      "epoch": 10.76939562794685,
      "grad_norm": 5.649126251228154e-05,
      "learning_rate": 5.640805829404201e-06,
      "loss": 0.0007,
      "step": 50250
    },
    {
      "epoch": 10.771538791255894,
      "grad_norm": 3.4309163311263546e-05,
      "learning_rate": 5.637948278325476e-06,
      "loss": 0.0,
      "step": 50260
    },
    {
      "epoch": 10.773681954564937,
      "grad_norm": 2.2976681066211313e-05,
      "learning_rate": 5.63509072724675e-06,
      "loss": 0.0,
      "step": 50270
    },
    {
      "epoch": 10.775825117873982,
      "grad_norm": 1.9168104699929245e-05,
      "learning_rate": 5.632233176168025e-06,
      "loss": 0.0,
      "step": 50280
    },
    {
      "epoch": 10.777968281183027,
      "grad_norm": 1.718380008242093e-05,
      "learning_rate": 5.629375625089299e-06,
      "loss": 0.0,
      "step": 50290
    },
    {
      "epoch": 10.78011144449207,
      "grad_norm": 3.478794315014966e-05,
      "learning_rate": 5.626518074010573e-06,
      "loss": 0.0,
      "step": 50300
    },
    {
      "epoch": 10.782254607801114,
      "grad_norm": 2.4035402020672336e-05,
      "learning_rate": 5.623660522931848e-06,
      "loss": 0.0,
      "step": 50310
    },
    {
      "epoch": 10.784397771110159,
      "grad_norm": 5.7497840316500515e-05,
      "learning_rate": 5.620802971853122e-06,
      "loss": 0.0,
      "step": 50320
    },
    {
      "epoch": 10.786540934419202,
      "grad_norm": 2.545132338127587e-05,
      "learning_rate": 5.6179454207743965e-06,
      "loss": 0.0,
      "step": 50330
    },
    {
      "epoch": 10.788684097728247,
      "grad_norm": 1.757280006131623e-05,
      "learning_rate": 5.615087869695671e-06,
      "loss": 0.0004,
      "step": 50340
    },
    {
      "epoch": 10.790827261037292,
      "grad_norm": 2.0829342247452587e-05,
      "learning_rate": 5.612230318616946e-06,
      "loss": 0.0,
      "step": 50350
    },
    {
      "epoch": 10.792970424346334,
      "grad_norm": 0.035341668874025345,
      "learning_rate": 5.60937276753822e-06,
      "loss": 0.0007,
      "step": 50360
    },
    {
      "epoch": 10.79511358765538,
      "grad_norm": 0.00039910877239890397,
      "learning_rate": 5.606515216459495e-06,
      "loss": 0.1047,
      "step": 50370
    },
    {
      "epoch": 10.797256750964424,
      "grad_norm": 0.004229539539664984,
      "learning_rate": 5.6036576653807696e-06,
      "loss": 0.1432,
      "step": 50380
    },
    {
      "epoch": 10.799399914273467,
      "grad_norm": 0.0008549855556339025,
      "learning_rate": 5.600800114302044e-06,
      "loss": 0.1305,
      "step": 50390
    },
    {
      "epoch": 10.801543077582512,
      "grad_norm": 1.249026809091447e-05,
      "learning_rate": 5.597942563223317e-06,
      "loss": 0.0,
      "step": 50400
    },
    {
      "epoch": 10.803686240891556,
      "grad_norm": 1.7577413018443622e-05,
      "learning_rate": 5.595085012144592e-06,
      "loss": 0.0,
      "step": 50410
    },
    {
      "epoch": 10.8058294042006,
      "grad_norm": 1.8547616491559893e-05,
      "learning_rate": 5.592227461065867e-06,
      "loss": 0.0001,
      "step": 50420
    },
    {
      "epoch": 10.807972567509644,
      "grad_norm": 1.7767821191227995e-05,
      "learning_rate": 5.589369909987141e-06,
      "loss": 0.0,
      "step": 50430
    },
    {
      "epoch": 10.810115730818689,
      "grad_norm": 1.397124560753582e-05,
      "learning_rate": 5.586512358908416e-06,
      "loss": 0.0,
      "step": 50440
    },
    {
      "epoch": 10.812258894127732,
      "grad_norm": 8.854321094986517e-06,
      "learning_rate": 5.5836548078296904e-06,
      "loss": 0.0,
      "step": 50450
    },
    {
      "epoch": 10.814402057436777,
      "grad_norm": 1.5699752111686394e-05,
      "learning_rate": 5.580797256750965e-06,
      "loss": 0.0,
      "step": 50460
    },
    {
      "epoch": 10.816545220745821,
      "grad_norm": 1.8532791727920994e-05,
      "learning_rate": 5.577939705672239e-06,
      "loss": 0.0,
      "step": 50470
    },
    {
      "epoch": 10.818688384054864,
      "grad_norm": 0.00010430995462229475,
      "learning_rate": 5.575082154593514e-06,
      "loss": 0.0,
      "step": 50480
    },
    {
      "epoch": 10.820831547363909,
      "grad_norm": 1.3235619917395525e-05,
      "learning_rate": 5.572224603514789e-06,
      "loss": 0.0,
      "step": 50490
    },
    {
      "epoch": 10.822974710672954,
      "grad_norm": 1.9255394363426603e-05,
      "learning_rate": 5.5693670524360635e-06,
      "loss": 0.0,
      "step": 50500
    },
    {
      "epoch": 10.825117873981997,
      "grad_norm": 1.9158074792358093e-05,
      "learning_rate": 5.5665095013573366e-06,
      "loss": 0.0,
      "step": 50510
    },
    {
      "epoch": 10.827261037291041,
      "grad_norm": 1.3148041944077704e-05,
      "learning_rate": 5.563651950278611e-06,
      "loss": 0.0,
      "step": 50520
    },
    {
      "epoch": 10.829404200600086,
      "grad_norm": 2.199980190198403e-05,
      "learning_rate": 5.560794399199886e-06,
      "loss": 0.0,
      "step": 50530
    },
    {
      "epoch": 10.831547363909129,
      "grad_norm": 1.533208524051588e-05,
      "learning_rate": 5.55793684812116e-06,
      "loss": 0.0,
      "step": 50540
    },
    {
      "epoch": 10.833690527218174,
      "grad_norm": 0.27502262592315674,
      "learning_rate": 5.555079297042435e-06,
      "loss": 0.0005,
      "step": 50550
    },
    {
      "epoch": 10.835833690527219,
      "grad_norm": 3.465373083599843e-05,
      "learning_rate": 5.55222174596371e-06,
      "loss": 0.0,
      "step": 50560
    },
    {
      "epoch": 10.837976853836262,
      "grad_norm": 1.4025538803252857e-05,
      "learning_rate": 5.549364194884984e-06,
      "loss": 0.0,
      "step": 50570
    },
    {
      "epoch": 10.840120017145306,
      "grad_norm": 0.0005930362967774272,
      "learning_rate": 5.546506643806258e-06,
      "loss": 0.0,
      "step": 50580
    },
    {
      "epoch": 10.842263180454351,
      "grad_norm": 42.81108856201172,
      "learning_rate": 5.543649092727533e-06,
      "loss": 0.2206,
      "step": 50590
    },
    {
      "epoch": 10.844406343763394,
      "grad_norm": 0.0004251243080943823,
      "learning_rate": 5.540791541648808e-06,
      "loss": 0.4169,
      "step": 50600
    },
    {
      "epoch": 10.846549507072439,
      "grad_norm": 0.0008296245359815657,
      "learning_rate": 5.537933990570083e-06,
      "loss": 0.0,
      "step": 50610
    },
    {
      "epoch": 10.848692670381483,
      "grad_norm": 0.00814378634095192,
      "learning_rate": 5.535076439491356e-06,
      "loss": 0.0,
      "step": 50620
    },
    {
      "epoch": 10.850835833690526,
      "grad_norm": 0.0006354387733153999,
      "learning_rate": 5.5322188884126305e-06,
      "loss": 0.0002,
      "step": 50630
    },
    {
      "epoch": 10.852978996999571,
      "grad_norm": 0.0003968218807131052,
      "learning_rate": 5.529361337333905e-06,
      "loss": 0.0,
      "step": 50640
    },
    {
      "epoch": 10.855122160308616,
      "grad_norm": 0.003202296094968915,
      "learning_rate": 5.526503786255179e-06,
      "loss": 0.0005,
      "step": 50650
    },
    {
      "epoch": 10.857265323617659,
      "grad_norm": 0.0006958115845918655,
      "learning_rate": 5.523646235176454e-06,
      "loss": 0.0001,
      "step": 50660
    },
    {
      "epoch": 10.859408486926704,
      "grad_norm": 0.0004631101037375629,
      "learning_rate": 5.520788684097729e-06,
      "loss": 0.0,
      "step": 50670
    },
    {
      "epoch": 10.861551650235748,
      "grad_norm": 0.0003099735185969621,
      "learning_rate": 5.5179311330190035e-06,
      "loss": 0.0013,
      "step": 50680
    },
    {
      "epoch": 10.863694813544793,
      "grad_norm": 0.0003701485402416438,
      "learning_rate": 5.515073581940278e-06,
      "loss": 0.0,
      "step": 50690
    },
    {
      "epoch": 10.865837976853836,
      "grad_norm": 0.0021674863528460264,
      "learning_rate": 5.512216030861552e-06,
      "loss": 0.2061,
      "step": 50700
    },
    {
      "epoch": 10.86798114016288,
      "grad_norm": 0.0002497151726856828,
      "learning_rate": 5.509358479782827e-06,
      "loss": 0.0,
      "step": 50710
    },
    {
      "epoch": 10.870124303471925,
      "grad_norm": 0.0005668324884027243,
      "learning_rate": 5.506500928704102e-06,
      "loss": 0.0001,
      "step": 50720
    },
    {
      "epoch": 10.872267466780968,
      "grad_norm": 0.0007198421517387033,
      "learning_rate": 5.503643377625375e-06,
      "loss": 0.1222,
      "step": 50730
    },
    {
      "epoch": 10.874410630090013,
      "grad_norm": 0.043292559683322906,
      "learning_rate": 5.50078582654665e-06,
      "loss": 0.0,
      "step": 50740
    },
    {
      "epoch": 10.876553793399058,
      "grad_norm": 0.0004013633297290653,
      "learning_rate": 5.497928275467924e-06,
      "loss": 0.1252,
      "step": 50750
    },
    {
      "epoch": 10.8786969567081,
      "grad_norm": 0.00047204268048517406,
      "learning_rate": 5.495070724389199e-06,
      "loss": 0.1417,
      "step": 50760
    },
    {
      "epoch": 10.880840120017146,
      "grad_norm": 0.0010461995843797922,
      "learning_rate": 5.492213173310473e-06,
      "loss": 0.0,
      "step": 50770
    },
    {
      "epoch": 10.88298328332619,
      "grad_norm": 0.0010960771469399333,
      "learning_rate": 5.489355622231748e-06,
      "loss": 0.1031,
      "step": 50780
    },
    {
      "epoch": 10.885126446635233,
      "grad_norm": 0.0006845580064691603,
      "learning_rate": 5.486498071153023e-06,
      "loss": 0.0001,
      "step": 50790
    },
    {
      "epoch": 10.887269609944278,
      "grad_norm": 0.001411230769008398,
      "learning_rate": 5.483640520074297e-06,
      "loss": 0.0002,
      "step": 50800
    },
    {
      "epoch": 10.889412773253323,
      "grad_norm": 0.0005468723247759044,
      "learning_rate": 5.480782968995571e-06,
      "loss": 0.0,
      "step": 50810
    },
    {
      "epoch": 10.891555936562366,
      "grad_norm": 0.00038498497451655567,
      "learning_rate": 5.477925417916846e-06,
      "loss": 0.0,
      "step": 50820
    },
    {
      "epoch": 10.89369909987141,
      "grad_norm": 0.0006310442113317549,
      "learning_rate": 5.47506786683812e-06,
      "loss": 0.1227,
      "step": 50830
    },
    {
      "epoch": 10.895842263180455,
      "grad_norm": 0.0015465527540072799,
      "learning_rate": 5.472210315759394e-06,
      "loss": 0.0031,
      "step": 50840
    },
    {
      "epoch": 10.897985426489498,
      "grad_norm": 0.0029110668692737818,
      "learning_rate": 5.469352764680669e-06,
      "loss": 0.0012,
      "step": 50850
    },
    {
      "epoch": 10.900128589798543,
      "grad_norm": 0.000524809816852212,
      "learning_rate": 5.4664952136019435e-06,
      "loss": 0.0,
      "step": 50860
    },
    {
      "epoch": 10.902271753107588,
      "grad_norm": 0.0012954770354554057,
      "learning_rate": 5.463637662523218e-06,
      "loss": 0.0009,
      "step": 50870
    },
    {
      "epoch": 10.90441491641663,
      "grad_norm": 0.0003975594008807093,
      "learning_rate": 5.460780111444492e-06,
      "loss": 0.0,
      "step": 50880
    },
    {
      "epoch": 10.906558079725675,
      "grad_norm": 0.0005210317904129624,
      "learning_rate": 5.457922560365767e-06,
      "loss": 0.0,
      "step": 50890
    },
    {
      "epoch": 10.90870124303472,
      "grad_norm": 0.0002789644058793783,
      "learning_rate": 5.455065009287042e-06,
      "loss": 0.1117,
      "step": 50900
    },
    {
      "epoch": 10.910844406343763,
      "grad_norm": 0.34381383657455444,
      "learning_rate": 5.4522074582083166e-06,
      "loss": 0.0006,
      "step": 50910
    },
    {
      "epoch": 10.912987569652808,
      "grad_norm": 0.031303729861974716,
      "learning_rate": 5.4493499071295905e-06,
      "loss": 0.0,
      "step": 50920
    },
    {
      "epoch": 10.915130732961853,
      "grad_norm": 0.00160874892026186,
      "learning_rate": 5.446492356050865e-06,
      "loss": 0.0,
      "step": 50930
    },
    {
      "epoch": 10.917273896270896,
      "grad_norm": 0.0002540722780395299,
      "learning_rate": 5.443634804972139e-06,
      "loss": 0.0,
      "step": 50940
    },
    {
      "epoch": 10.91941705957994,
      "grad_norm": 0.0009958979208022356,
      "learning_rate": 5.440777253893413e-06,
      "loss": 0.0,
      "step": 50950
    },
    {
      "epoch": 10.921560222888985,
      "grad_norm": 0.002753595821559429,
      "learning_rate": 5.437919702814688e-06,
      "loss": 0.0,
      "step": 50960
    },
    {
      "epoch": 10.923703386198028,
      "grad_norm": 1.5893332958221436,
      "learning_rate": 5.435062151735963e-06,
      "loss": 0.0029,
      "step": 50970
    },
    {
      "epoch": 10.925846549507073,
      "grad_norm": 0.0001681068679317832,
      "learning_rate": 5.4322046006572374e-06,
      "loss": 0.0,
      "step": 50980
    },
    {
      "epoch": 10.927989712816117,
      "grad_norm": 0.00035433287848718464,
      "learning_rate": 5.429347049578511e-06,
      "loss": 0.0,
      "step": 50990
    },
    {
      "epoch": 10.93013287612516,
      "grad_norm": 0.0005501186824403703,
      "learning_rate": 5.426489498499786e-06,
      "loss": 0.1048,
      "step": 51000
    },
    {
      "epoch": 10.932276039434205,
      "grad_norm": 0.00018097441352438182,
      "learning_rate": 5.423631947421061e-06,
      "loss": 0.0,
      "step": 51010
    },
    {
      "epoch": 10.93441920274325,
      "grad_norm": 9.605287777958438e-05,
      "learning_rate": 5.420774396342336e-06,
      "loss": 0.1363,
      "step": 51020
    },
    {
      "epoch": 10.936562366052293,
      "grad_norm": 0.0004016797465737909,
      "learning_rate": 5.41791684526361e-06,
      "loss": 0.0003,
      "step": 51030
    },
    {
      "epoch": 10.938705529361338,
      "grad_norm": 7.933840970508754e-05,
      "learning_rate": 5.415059294184884e-06,
      "loss": 0.0851,
      "step": 51040
    },
    {
      "epoch": 10.940848692670382,
      "grad_norm": 8.630183583591133e-05,
      "learning_rate": 5.412201743106158e-06,
      "loss": 0.0004,
      "step": 51050
    },
    {
      "epoch": 10.942991855979425,
      "grad_norm": 0.0003463696630205959,
      "learning_rate": 5.409344192027432e-06,
      "loss": 0.0,
      "step": 51060
    },
    {
      "epoch": 10.94513501928847,
      "grad_norm": 7.34854766051285e-05,
      "learning_rate": 5.406486640948707e-06,
      "loss": 0.0001,
      "step": 51070
    },
    {
      "epoch": 10.947278182597515,
      "grad_norm": 6.1744314734824e-05,
      "learning_rate": 5.403629089869982e-06,
      "loss": 0.0005,
      "step": 51080
    },
    {
      "epoch": 10.949421345906558,
      "grad_norm": 5.3543193644145504e-05,
      "learning_rate": 5.400771538791257e-06,
      "loss": 0.0,
      "step": 51090
    },
    {
      "epoch": 10.951564509215602,
      "grad_norm": 4.5111431973055005e-05,
      "learning_rate": 5.3979139877125305e-06,
      "loss": 0.0,
      "step": 51100
    },
    {
      "epoch": 10.953707672524647,
      "grad_norm": 0.00045376684283837676,
      "learning_rate": 5.395056436633805e-06,
      "loss": 0.0,
      "step": 51110
    },
    {
      "epoch": 10.95585083583369,
      "grad_norm": 5.414711995399557e-05,
      "learning_rate": 5.39219888555508e-06,
      "loss": 0.0,
      "step": 51120
    },
    {
      "epoch": 10.957993999142735,
      "grad_norm": 5.735821105190553e-05,
      "learning_rate": 5.389341334476355e-06,
      "loss": 0.0,
      "step": 51130
    },
    {
      "epoch": 10.96013716245178,
      "grad_norm": 5.271228656056337e-05,
      "learning_rate": 5.386483783397629e-06,
      "loss": 0.0,
      "step": 51140
    },
    {
      "epoch": 10.962280325760823,
      "grad_norm": 6.18728154222481e-05,
      "learning_rate": 5.3836262323189035e-06,
      "loss": 0.0002,
      "step": 51150
    },
    {
      "epoch": 10.964423489069867,
      "grad_norm": 9.518637671135366e-05,
      "learning_rate": 5.3807686812401775e-06,
      "loss": 0.0,
      "step": 51160
    },
    {
      "epoch": 10.966566652378912,
      "grad_norm": 7.356830610660836e-05,
      "learning_rate": 5.377911130161451e-06,
      "loss": 0.0,
      "step": 51170
    },
    {
      "epoch": 10.968709815687955,
      "grad_norm": 0.0002319704508408904,
      "learning_rate": 5.375053579082726e-06,
      "loss": 0.0009,
      "step": 51180
    },
    {
      "epoch": 10.970852978997,
      "grad_norm": 3.774844662984833e-05,
      "learning_rate": 5.372196028004001e-06,
      "loss": 0.0,
      "step": 51190
    },
    {
      "epoch": 10.972996142306044,
      "grad_norm": 3.976707739639096e-05,
      "learning_rate": 5.369338476925276e-06,
      "loss": 0.0,
      "step": 51200
    },
    {
      "epoch": 10.975139305615087,
      "grad_norm": 0.00018804676074068993,
      "learning_rate": 5.36648092584655e-06,
      "loss": 0.002,
      "step": 51210
    },
    {
      "epoch": 10.977282468924132,
      "grad_norm": 2.6014651666628197e-05,
      "learning_rate": 5.3636233747678244e-06,
      "loss": 0.0,
      "step": 51220
    },
    {
      "epoch": 10.979425632233177,
      "grad_norm": 2.8793388992198743e-05,
      "learning_rate": 5.360765823689099e-06,
      "loss": 0.0,
      "step": 51230
    },
    {
      "epoch": 10.98156879554222,
      "grad_norm": 4.160543539910577e-05,
      "learning_rate": 5.357908272610374e-06,
      "loss": 0.0011,
      "step": 51240
    },
    {
      "epoch": 10.983711958851265,
      "grad_norm": 0.0003481319872662425,
      "learning_rate": 5.355050721531648e-06,
      "loss": 0.0,
      "step": 51250
    },
    {
      "epoch": 10.98585512216031,
      "grad_norm": 5.913998757023364e-05,
      "learning_rate": 5.352193170452922e-06,
      "loss": 0.0,
      "step": 51260
    },
    {
      "epoch": 10.987998285469352,
      "grad_norm": 3.087340883212164e-05,
      "learning_rate": 5.349335619374197e-06,
      "loss": 0.1276,
      "step": 51270
    },
    {
      "epoch": 10.990141448778397,
      "grad_norm": 0.001137514947913587,
      "learning_rate": 5.3464780682954705e-06,
      "loss": 0.0,
      "step": 51280
    },
    {
      "epoch": 10.992284612087442,
      "grad_norm": 0.00023184179735835642,
      "learning_rate": 5.343620517216745e-06,
      "loss": 0.1481,
      "step": 51290
    },
    {
      "epoch": 10.994427775396485,
      "grad_norm": 4.0809034544508904e-05,
      "learning_rate": 5.34076296613802e-06,
      "loss": 0.0,
      "step": 51300
    },
    {
      "epoch": 10.99657093870553,
      "grad_norm": 0.00017871928866952658,
      "learning_rate": 5.337905415059295e-06,
      "loss": 0.0,
      "step": 51310
    },
    {
      "epoch": 10.998714102014574,
      "grad_norm": 0.00015098442963790148,
      "learning_rate": 5.335047863980569e-06,
      "loss": 0.0,
      "step": 51320
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9853333333333333,
      "eval_f1": 0.9228070175438596,
      "eval_loss": 0.13245998322963715,
      "eval_precision": 0.9740740740740741,
      "eval_recall": 0.8766666666666667,
      "eval_runtime": 399.8792,
      "eval_samples_per_second": 7.502,
      "eval_steps_per_second": 2.501,
      "step": 51326
    },
    {
      "epoch": 11.000857265323617,
      "grad_norm": 5.115288513479754e-05,
      "learning_rate": 5.3321903129018436e-06,
      "loss": 0.0,
      "step": 51330
    },
    {
      "epoch": 11.003000428632662,
      "grad_norm": 0.00020606879843398929,
      "learning_rate": 5.329332761823118e-06,
      "loss": 0.112,
      "step": 51340
    },
    {
      "epoch": 11.005143591941707,
      "grad_norm": 8.224983321269974e-05,
      "learning_rate": 5.326475210744393e-06,
      "loss": 0.0,
      "step": 51350
    },
    {
      "epoch": 11.00728675525075,
      "grad_norm": 4.7114161134231836e-05,
      "learning_rate": 5.323617659665667e-06,
      "loss": 0.0,
      "step": 51360
    },
    {
      "epoch": 11.009429918559794,
      "grad_norm": 5.024413621868007e-05,
      "learning_rate": 5.320760108586941e-06,
      "loss": 0.0,
      "step": 51370
    },
    {
      "epoch": 11.011573081868839,
      "grad_norm": 0.0015533268451690674,
      "learning_rate": 5.317902557508216e-06,
      "loss": 0.0,
      "step": 51380
    },
    {
      "epoch": 11.013716245177882,
      "grad_norm": 4.708200867753476e-05,
      "learning_rate": 5.31504500642949e-06,
      "loss": 0.0,
      "step": 51390
    },
    {
      "epoch": 11.015859408486927,
      "grad_norm": 5.857757059857249e-05,
      "learning_rate": 5.3121874553507645e-06,
      "loss": 0.0,
      "step": 51400
    },
    {
      "epoch": 11.018002571795972,
      "grad_norm": 0.00013324634346645325,
      "learning_rate": 5.309329904272039e-06,
      "loss": 0.0,
      "step": 51410
    },
    {
      "epoch": 11.020145735105014,
      "grad_norm": 6.171705172164366e-05,
      "learning_rate": 5.306472353193314e-06,
      "loss": 0.0,
      "step": 51420
    },
    {
      "epoch": 11.02228889841406,
      "grad_norm": 0.0002347496192669496,
      "learning_rate": 5.303614802114588e-06,
      "loss": 0.0,
      "step": 51430
    },
    {
      "epoch": 11.024432061723104,
      "grad_norm": 6.39982390566729e-05,
      "learning_rate": 5.300757251035863e-06,
      "loss": 0.0,
      "step": 51440
    },
    {
      "epoch": 11.026575225032147,
      "grad_norm": 4.871746205026284e-05,
      "learning_rate": 5.2978996999571375e-06,
      "loss": 0.0,
      "step": 51450
    },
    {
      "epoch": 11.028718388341192,
      "grad_norm": 0.0004499706265050918,
      "learning_rate": 5.295042148878412e-06,
      "loss": 0.0,
      "step": 51460
    },
    {
      "epoch": 11.030861551650236,
      "grad_norm": 0.0009341060067526996,
      "learning_rate": 5.292184597799687e-06,
      "loss": 0.1385,
      "step": 51470
    },
    {
      "epoch": 11.03300471495928,
      "grad_norm": 6.975566066103056e-05,
      "learning_rate": 5.28932704672096e-06,
      "loss": 0.0,
      "step": 51480
    },
    {
      "epoch": 11.035147878268324,
      "grad_norm": 0.0013282346772029996,
      "learning_rate": 5.286469495642235e-06,
      "loss": 0.0,
      "step": 51490
    },
    {
      "epoch": 11.037291041577369,
      "grad_norm": 0.0005547149921767414,
      "learning_rate": 5.283611944563509e-06,
      "loss": 0.0,
      "step": 51500
    },
    {
      "epoch": 11.039434204886412,
      "grad_norm": 7.364961493294686e-05,
      "learning_rate": 5.280754393484784e-06,
      "loss": 0.0,
      "step": 51510
    },
    {
      "epoch": 11.041577368195457,
      "grad_norm": 9.673707245383412e-05,
      "learning_rate": 5.277896842406058e-06,
      "loss": 0.0,
      "step": 51520
    },
    {
      "epoch": 11.043720531504501,
      "grad_norm": 0.0006121335318312049,
      "learning_rate": 5.275039291327333e-06,
      "loss": 0.0,
      "step": 51530
    },
    {
      "epoch": 11.045863694813544,
      "grad_norm": 5.179570507607423e-05,
      "learning_rate": 5.272181740248608e-06,
      "loss": 0.0,
      "step": 51540
    },
    {
      "epoch": 11.048006858122589,
      "grad_norm": 5.1711722335312515e-05,
      "learning_rate": 5.269324189169882e-06,
      "loss": 0.0942,
      "step": 51550
    },
    {
      "epoch": 11.050150021431634,
      "grad_norm": 5.967545439489186e-05,
      "learning_rate": 5.266466638091157e-06,
      "loss": 0.0024,
      "step": 51560
    },
    {
      "epoch": 11.052293184740677,
      "grad_norm": 7.3664231300354,
      "learning_rate": 5.263609087012431e-06,
      "loss": 0.0153,
      "step": 51570
    },
    {
      "epoch": 11.054436348049721,
      "grad_norm": 4.7986177378334105e-05,
      "learning_rate": 5.260751535933706e-06,
      "loss": 0.0,
      "step": 51580
    },
    {
      "epoch": 11.056579511358766,
      "grad_norm": 3.5729499359149486e-05,
      "learning_rate": 5.257893984854979e-06,
      "loss": 0.0,
      "step": 51590
    },
    {
      "epoch": 11.05872267466781,
      "grad_norm": 0.00014492421178147197,
      "learning_rate": 5.255036433776254e-06,
      "loss": 0.0,
      "step": 51600
    },
    {
      "epoch": 11.060865837976854,
      "grad_norm": 0.3755466938018799,
      "learning_rate": 5.252178882697529e-06,
      "loss": 0.0005,
      "step": 51610
    },
    {
      "epoch": 11.063009001285899,
      "grad_norm": 9.321799007011577e-05,
      "learning_rate": 5.249321331618803e-06,
      "loss": 0.0,
      "step": 51620
    },
    {
      "epoch": 11.065152164594942,
      "grad_norm": 3.702019967022352e-05,
      "learning_rate": 5.2464637805400775e-06,
      "loss": 0.0937,
      "step": 51630
    },
    {
      "epoch": 11.067295327903986,
      "grad_norm": 0.00037276538205333054,
      "learning_rate": 5.243606229461352e-06,
      "loss": 0.0,
      "step": 51640
    },
    {
      "epoch": 11.069438491213031,
      "grad_norm": 0.00021181975898798555,
      "learning_rate": 5.240748678382627e-06,
      "loss": 0.0,
      "step": 51650
    },
    {
      "epoch": 11.071581654522074,
      "grad_norm": 4.023030851385556e-05,
      "learning_rate": 5.237891127303901e-06,
      "loss": 0.001,
      "step": 51660
    },
    {
      "epoch": 11.073724817831119,
      "grad_norm": 5.140449502505362e-05,
      "learning_rate": 5.235033576225176e-06,
      "loss": 0.0,
      "step": 51670
    },
    {
      "epoch": 11.075867981140163,
      "grad_norm": 2.5571431251592003e-05,
      "learning_rate": 5.2321760251464505e-06,
      "loss": 0.0,
      "step": 51680
    },
    {
      "epoch": 11.078011144449206,
      "grad_norm": 1.951223202922847e-05,
      "learning_rate": 5.229318474067724e-06,
      "loss": 0.0,
      "step": 51690
    },
    {
      "epoch": 11.080154307758251,
      "grad_norm": 2.545219467720017e-05,
      "learning_rate": 5.226460922988998e-06,
      "loss": 0.0,
      "step": 51700
    },
    {
      "epoch": 11.082297471067296,
      "grad_norm": 3.862953599309549e-05,
      "learning_rate": 5.223603371910273e-06,
      "loss": 0.0,
      "step": 51710
    },
    {
      "epoch": 11.084440634376339,
      "grad_norm": 0.00010236875095870346,
      "learning_rate": 5.220745820831548e-06,
      "loss": 0.0,
      "step": 51720
    },
    {
      "epoch": 11.086583797685384,
      "grad_norm": 3.469007060630247e-05,
      "learning_rate": 5.217888269752822e-06,
      "loss": 0.0,
      "step": 51730
    },
    {
      "epoch": 11.088726960994428,
      "grad_norm": 2.490312181180343e-05,
      "learning_rate": 5.215030718674097e-06,
      "loss": 0.0,
      "step": 51740
    },
    {
      "epoch": 11.090870124303471,
      "grad_norm": 8.341387001564726e-05,
      "learning_rate": 5.2121731675953714e-06,
      "loss": 0.0,
      "step": 51750
    },
    {
      "epoch": 11.093013287612516,
      "grad_norm": 0.00015643359802197665,
      "learning_rate": 5.209315616516646e-06,
      "loss": 0.2028,
      "step": 51760
    },
    {
      "epoch": 11.09515645092156,
      "grad_norm": 0.0006523523479700089,
      "learning_rate": 5.20645806543792e-06,
      "loss": 0.0,
      "step": 51770
    },
    {
      "epoch": 11.097299614230604,
      "grad_norm": 0.0003794794320128858,
      "learning_rate": 5.203600514359195e-06,
      "loss": 0.0,
      "step": 51780
    },
    {
      "epoch": 11.099442777539648,
      "grad_norm": 5.5254386097658426e-05,
      "learning_rate": 5.20074296328047e-06,
      "loss": 0.1394,
      "step": 51790
    },
    {
      "epoch": 11.101585940848693,
      "grad_norm": 7.807656947989017e-05,
      "learning_rate": 5.197885412201743e-06,
      "loss": 0.0,
      "step": 51800
    },
    {
      "epoch": 11.103729104157736,
      "grad_norm": 17.100709915161133,
      "learning_rate": 5.1950278611230175e-06,
      "loss": 0.1433,
      "step": 51810
    },
    {
      "epoch": 11.105872267466781,
      "grad_norm": 8.889177843229845e-05,
      "learning_rate": 5.192170310044292e-06,
      "loss": 0.0,
      "step": 51820
    },
    {
      "epoch": 11.108015430775826,
      "grad_norm": 6.897158891661093e-05,
      "learning_rate": 5.189312758965567e-06,
      "loss": 0.0,
      "step": 51830
    },
    {
      "epoch": 11.110158594084869,
      "grad_norm": 0.00029166636522859335,
      "learning_rate": 5.186455207886841e-06,
      "loss": 0.0,
      "step": 51840
    },
    {
      "epoch": 11.112301757393913,
      "grad_norm": 0.00012419828271958977,
      "learning_rate": 5.183597656808116e-06,
      "loss": 0.0008,
      "step": 51850
    },
    {
      "epoch": 11.114444920702958,
      "grad_norm": 0.022335024550557137,
      "learning_rate": 5.1807401057293906e-06,
      "loss": 0.0,
      "step": 51860
    },
    {
      "epoch": 11.116588084012001,
      "grad_norm": 6.16353572695516e-05,
      "learning_rate": 5.177882554650665e-06,
      "loss": 0.0,
      "step": 51870
    },
    {
      "epoch": 11.118731247321046,
      "grad_norm": 5.561470607062802e-05,
      "learning_rate": 5.175025003571939e-06,
      "loss": 0.0,
      "step": 51880
    },
    {
      "epoch": 11.12087441063009,
      "grad_norm": 0.00024063025193754584,
      "learning_rate": 5.172167452493214e-06,
      "loss": 0.0004,
      "step": 51890
    },
    {
      "epoch": 11.123017573939133,
      "grad_norm": 0.0001897702313726768,
      "learning_rate": 5.169309901414489e-06,
      "loss": 0.0,
      "step": 51900
    },
    {
      "epoch": 11.125160737248178,
      "grad_norm": 3.695832856465131e-05,
      "learning_rate": 5.166452350335762e-06,
      "loss": 0.0,
      "step": 51910
    },
    {
      "epoch": 11.127303900557223,
      "grad_norm": 0.00011816287587862462,
      "learning_rate": 5.163594799257037e-06,
      "loss": 0.0014,
      "step": 51920
    },
    {
      "epoch": 11.129447063866266,
      "grad_norm": 4.505358811002225e-05,
      "learning_rate": 5.1607372481783115e-06,
      "loss": 0.0,
      "step": 51930
    },
    {
      "epoch": 11.13159022717531,
      "grad_norm": 3.7189791328273714e-05,
      "learning_rate": 5.157879697099586e-06,
      "loss": 0.0,
      "step": 51940
    },
    {
      "epoch": 11.133733390484355,
      "grad_norm": 3.1809326173970476e-05,
      "learning_rate": 5.15502214602086e-06,
      "loss": 0.0717,
      "step": 51950
    },
    {
      "epoch": 11.135876553793398,
      "grad_norm": 0.0001634005893720314,
      "learning_rate": 5.152164594942135e-06,
      "loss": 0.0,
      "step": 51960
    },
    {
      "epoch": 11.138019717102443,
      "grad_norm": 6.945923087187111e-05,
      "learning_rate": 5.14930704386341e-06,
      "loss": 0.0,
      "step": 51970
    },
    {
      "epoch": 11.140162880411488,
      "grad_norm": 0.00010128495341632515,
      "learning_rate": 5.1464494927846845e-06,
      "loss": 0.0026,
      "step": 51980
    },
    {
      "epoch": 11.14230604372053,
      "grad_norm": 0.0006030818331055343,
      "learning_rate": 5.143591941705958e-06,
      "loss": 0.0,
      "step": 51990
    },
    {
      "epoch": 11.144449207029576,
      "grad_norm": 2.812463753798511e-05,
      "learning_rate": 5.140734390627233e-06,
      "loss": 0.0,
      "step": 52000
    },
    {
      "epoch": 11.14659237033862,
      "grad_norm": 1.3006855249404907,
      "learning_rate": 5.137876839548507e-06,
      "loss": 0.1245,
      "step": 52010
    },
    {
      "epoch": 11.148735533647663,
      "grad_norm": 4.132635876885615e-05,
      "learning_rate": 5.135019288469781e-06,
      "loss": 0.0,
      "step": 52020
    },
    {
      "epoch": 11.150878696956708,
      "grad_norm": 4.129178341827355e-05,
      "learning_rate": 5.132161737391056e-06,
      "loss": 0.0,
      "step": 52030
    },
    {
      "epoch": 11.153021860265753,
      "grad_norm": 0.00013328039494808763,
      "learning_rate": 5.129304186312331e-06,
      "loss": 0.0,
      "step": 52040
    },
    {
      "epoch": 11.155165023574796,
      "grad_norm": 4.437063034856692e-05,
      "learning_rate": 5.126446635233605e-06,
      "loss": 0.0,
      "step": 52050
    },
    {
      "epoch": 11.15730818688384,
      "grad_norm": 1.7796449661254883,
      "learning_rate": 5.123589084154879e-06,
      "loss": 0.0032,
      "step": 52060
    },
    {
      "epoch": 11.159451350192885,
      "grad_norm": 0.00033939641434699297,
      "learning_rate": 5.120731533076154e-06,
      "loss": 0.0,
      "step": 52070
    },
    {
      "epoch": 11.161594513501928,
      "grad_norm": 2.7809343009721488e-05,
      "learning_rate": 5.117873981997429e-06,
      "loss": 0.0,
      "step": 52080
    },
    {
      "epoch": 11.163737676810973,
      "grad_norm": 0.00012907125346828252,
      "learning_rate": 5.115016430918704e-06,
      "loss": 0.0008,
      "step": 52090
    },
    {
      "epoch": 11.165880840120018,
      "grad_norm": 4.09935018979013e-05,
      "learning_rate": 5.1121588798399775e-06,
      "loss": 0.0,
      "step": 52100
    },
    {
      "epoch": 11.16802400342906,
      "grad_norm": 0.00016018628957681358,
      "learning_rate": 5.109301328761252e-06,
      "loss": 0.0,
      "step": 52110
    },
    {
      "epoch": 11.170167166738105,
      "grad_norm": 2.863275949493982e-05,
      "learning_rate": 5.106443777682526e-06,
      "loss": 0.0001,
      "step": 52120
    },
    {
      "epoch": 11.17231033004715,
      "grad_norm": 2.3652417439734563e-05,
      "learning_rate": 5.1035862266038e-06,
      "loss": 0.0,
      "step": 52130
    },
    {
      "epoch": 11.174453493356193,
      "grad_norm": 2.4218388716690242e-05,
      "learning_rate": 5.100728675525075e-06,
      "loss": 0.0,
      "step": 52140
    },
    {
      "epoch": 11.176596656665238,
      "grad_norm": 2.1556448700721376e-05,
      "learning_rate": 5.09787112444635e-06,
      "loss": 0.0002,
      "step": 52150
    },
    {
      "epoch": 11.178739819974282,
      "grad_norm": 0.19655990600585938,
      "learning_rate": 5.0950135733676245e-06,
      "loss": 0.0004,
      "step": 52160
    },
    {
      "epoch": 11.180882983283325,
      "grad_norm": 0.00011325371451675892,
      "learning_rate": 5.0921560222888984e-06,
      "loss": 0.0006,
      "step": 52170
    },
    {
      "epoch": 11.18302614659237,
      "grad_norm": 0.00011384177196305245,
      "learning_rate": 5.089298471210173e-06,
      "loss": 0.0004,
      "step": 52180
    },
    {
      "epoch": 11.185169309901415,
      "grad_norm": 1.3672528439201415e-05,
      "learning_rate": 5.086440920131448e-06,
      "loss": 0.0,
      "step": 52190
    },
    {
      "epoch": 11.187312473210458,
      "grad_norm": 1.1319179975544102e-05,
      "learning_rate": 5.083583369052723e-06,
      "loss": 0.0,
      "step": 52200
    },
    {
      "epoch": 11.189455636519503,
      "grad_norm": 1.9657385564642027e-05,
      "learning_rate": 5.080725817973997e-06,
      "loss": 0.0,
      "step": 52210
    },
    {
      "epoch": 11.191598799828547,
      "grad_norm": 3.4584627428557724e-05,
      "learning_rate": 5.0778682668952715e-06,
      "loss": 0.0,
      "step": 52220
    },
    {
      "epoch": 11.19374196313759,
      "grad_norm": 3.6682587960967794e-05,
      "learning_rate": 5.075010715816545e-06,
      "loss": 0.0,
      "step": 52230
    },
    {
      "epoch": 11.195885126446635,
      "grad_norm": 1.682777474343311e-05,
      "learning_rate": 5.072153164737819e-06,
      "loss": 0.0002,
      "step": 52240
    },
    {
      "epoch": 11.19802828975568,
      "grad_norm": 2.922908606706187e-05,
      "learning_rate": 5.069295613659094e-06,
      "loss": 0.0809,
      "step": 52250
    },
    {
      "epoch": 11.200171453064723,
      "grad_norm": 2.554158345446922e-05,
      "learning_rate": 5.066438062580369e-06,
      "loss": 0.0,
      "step": 52260
    },
    {
      "epoch": 11.202314616373767,
      "grad_norm": 2.3538405002909712e-05,
      "learning_rate": 5.063580511501644e-06,
      "loss": 0.0,
      "step": 52270
    },
    {
      "epoch": 11.204457779682812,
      "grad_norm": 5.268831591820344e-05,
      "learning_rate": 5.0607229604229176e-06,
      "loss": 0.0,
      "step": 52280
    },
    {
      "epoch": 11.206600942991855,
      "grad_norm": 4.138064832659438e-05,
      "learning_rate": 5.057865409344192e-06,
      "loss": 0.0,
      "step": 52290
    },
    {
      "epoch": 11.2087441063009,
      "grad_norm": 1.8127519069821574e-05,
      "learning_rate": 5.055007858265467e-06,
      "loss": 0.0,
      "step": 52300
    },
    {
      "epoch": 11.210887269609945,
      "grad_norm": 2.1922318410361186e-05,
      "learning_rate": 5.052150307186742e-06,
      "loss": 0.114,
      "step": 52310
    },
    {
      "epoch": 11.213030432918988,
      "grad_norm": 3.651423321571201e-05,
      "learning_rate": 5.049292756108017e-06,
      "loss": 0.1396,
      "step": 52320
    },
    {
      "epoch": 11.215173596228032,
      "grad_norm": 5.562363367062062e-05,
      "learning_rate": 5.046435205029291e-06,
      "loss": 0.0,
      "step": 52330
    },
    {
      "epoch": 11.217316759537077,
      "grad_norm": 0.005399057175964117,
      "learning_rate": 5.0435776539505645e-06,
      "loss": 0.0,
      "step": 52340
    },
    {
      "epoch": 11.21945992284612,
      "grad_norm": 2.1927002308075316e-05,
      "learning_rate": 5.0407201028718385e-06,
      "loss": 0.0,
      "step": 52350
    },
    {
      "epoch": 11.221603086155165,
      "grad_norm": 2.4512124582543038e-05,
      "learning_rate": 5.037862551793113e-06,
      "loss": 0.0,
      "step": 52360
    },
    {
      "epoch": 11.22374624946421,
      "grad_norm": 8.691580296726897e-05,
      "learning_rate": 5.035005000714388e-06,
      "loss": 0.0004,
      "step": 52370
    },
    {
      "epoch": 11.225889412773252,
      "grad_norm": 3.540014222380705e-05,
      "learning_rate": 5.032147449635663e-06,
      "loss": 0.0,
      "step": 52380
    },
    {
      "epoch": 11.228032576082297,
      "grad_norm": 3.633421511040069e-05,
      "learning_rate": 5.0292898985569376e-06,
      "loss": 0.0001,
      "step": 52390
    },
    {
      "epoch": 11.230175739391342,
      "grad_norm": 1.998849620576948e-05,
      "learning_rate": 5.0264323474782115e-06,
      "loss": 0.0011,
      "step": 52400
    },
    {
      "epoch": 11.232318902700385,
      "grad_norm": 8.158991113305092e-05,
      "learning_rate": 5.023574796399486e-06,
      "loss": 0.0,
      "step": 52410
    },
    {
      "epoch": 11.23446206600943,
      "grad_norm": 3.65174091712106e-05,
      "learning_rate": 5.020717245320761e-06,
      "loss": 0.0,
      "step": 52420
    },
    {
      "epoch": 11.236605229318474,
      "grad_norm": 0.00012189545668661594,
      "learning_rate": 5.017859694242036e-06,
      "loss": 0.0,
      "step": 52430
    },
    {
      "epoch": 11.238748392627517,
      "grad_norm": 1.8911085135187022e-05,
      "learning_rate": 5.015002143163309e-06,
      "loss": 0.0,
      "step": 52440
    },
    {
      "epoch": 11.240891555936562,
      "grad_norm": 2.632317045936361e-05,
      "learning_rate": 5.012144592084584e-06,
      "loss": 0.0,
      "step": 52450
    },
    {
      "epoch": 11.243034719245607,
      "grad_norm": 4.271652505849488e-05,
      "learning_rate": 5.0092870410058584e-06,
      "loss": 0.0,
      "step": 52460
    },
    {
      "epoch": 11.24517788255465,
      "grad_norm": 5.637419963022694e-05,
      "learning_rate": 5.006429489927132e-06,
      "loss": 0.0,
      "step": 52470
    },
    {
      "epoch": 11.247321045863695,
      "grad_norm": 0.002700748387724161,
      "learning_rate": 5.003571938848407e-06,
      "loss": 0.0,
      "step": 52480
    },
    {
      "epoch": 11.24946420917274,
      "grad_norm": 1.8365146388532594e-05,
      "learning_rate": 5.000714387769682e-06,
      "loss": 0.0,
      "step": 52490
    },
    {
      "epoch": 11.251607372481782,
      "grad_norm": 0.02777084708213806,
      "learning_rate": 4.997856836690957e-06,
      "loss": 0.0,
      "step": 52500
    },
    {
      "epoch": 11.253750535790827,
      "grad_norm": 2.0697523723356426e-05,
      "learning_rate": 4.994999285612231e-06,
      "loss": 0.0004,
      "step": 52510
    },
    {
      "epoch": 11.255893699099872,
      "grad_norm": 2.1259025743347593e-05,
      "learning_rate": 4.9921417345335046e-06,
      "loss": 0.1516,
      "step": 52520
    },
    {
      "epoch": 11.258036862408915,
      "grad_norm": 0.00019149250874761492,
      "learning_rate": 4.989284183454779e-06,
      "loss": 0.0004,
      "step": 52530
    },
    {
      "epoch": 11.26018002571796,
      "grad_norm": 0.00011162058945046738,
      "learning_rate": 4.986426632376054e-06,
      "loss": 0.0,
      "step": 52540
    },
    {
      "epoch": 11.262323189027004,
      "grad_norm": 3.4205713745905086e-05,
      "learning_rate": 4.983569081297329e-06,
      "loss": 0.0,
      "step": 52550
    },
    {
      "epoch": 11.264466352336047,
      "grad_norm": 0.00014461252430919558,
      "learning_rate": 4.980711530218603e-06,
      "loss": 0.0,
      "step": 52560
    },
    {
      "epoch": 11.266609515645092,
      "grad_norm": 1.8201561033492908e-05,
      "learning_rate": 4.977853979139878e-06,
      "loss": 0.0001,
      "step": 52570
    },
    {
      "epoch": 11.268752678954137,
      "grad_norm": 3.237725468352437e-05,
      "learning_rate": 4.9749964280611515e-06,
      "loss": 0.0,
      "step": 52580
    },
    {
      "epoch": 11.270895842263181,
      "grad_norm": 0.0025613841135054827,
      "learning_rate": 4.972138876982426e-06,
      "loss": 0.0,
      "step": 52590
    },
    {
      "epoch": 11.273039005572224,
      "grad_norm": 0.00015054659161251038,
      "learning_rate": 4.969281325903701e-06,
      "loss": 0.0,
      "step": 52600
    },
    {
      "epoch": 11.275182168881269,
      "grad_norm": 0.00010112488234881312,
      "learning_rate": 4.966423774824976e-06,
      "loss": 0.0,
      "step": 52610
    },
    {
      "epoch": 11.277325332190314,
      "grad_norm": 0.4017784297466278,
      "learning_rate": 4.96356622374625e-06,
      "loss": 0.0009,
      "step": 52620
    },
    {
      "epoch": 11.279468495499357,
      "grad_norm": 2.147892701032106e-05,
      "learning_rate": 4.960708672667524e-06,
      "loss": 0.0,
      "step": 52630
    },
    {
      "epoch": 11.281611658808401,
      "grad_norm": 2.4758917788858525e-05,
      "learning_rate": 4.9578511215887985e-06,
      "loss": 0.0,
      "step": 52640
    },
    {
      "epoch": 11.283754822117446,
      "grad_norm": 2.6307645384804346e-05,
      "learning_rate": 4.954993570510073e-06,
      "loss": 0.0,
      "step": 52650
    },
    {
      "epoch": 11.28589798542649,
      "grad_norm": 1.8190623450209387e-05,
      "learning_rate": 4.952136019431348e-06,
      "loss": 0.0,
      "step": 52660
    },
    {
      "epoch": 11.288041148735534,
      "grad_norm": 0.00010923593799816445,
      "learning_rate": 4.949278468352623e-06,
      "loss": 0.0006,
      "step": 52670
    },
    {
      "epoch": 11.290184312044579,
      "grad_norm": 2.040899926214479e-05,
      "learning_rate": 4.946420917273897e-06,
      "loss": 0.0007,
      "step": 52680
    },
    {
      "epoch": 11.292327475353622,
      "grad_norm": 4.365847780718468e-05,
      "learning_rate": 4.943563366195171e-06,
      "loss": 0.0014,
      "step": 52690
    },
    {
      "epoch": 11.294470638662666,
      "grad_norm": 2.983967169711832e-05,
      "learning_rate": 4.9407058151164454e-06,
      "loss": 0.0,
      "step": 52700
    },
    {
      "epoch": 11.296613801971711,
      "grad_norm": 5.7164750614902005e-05,
      "learning_rate": 4.93784826403772e-06,
      "loss": 0.0,
      "step": 52710
    },
    {
      "epoch": 11.298756965280754,
      "grad_norm": 4.7867080866126344e-05,
      "learning_rate": 4.934990712958995e-06,
      "loss": 0.0,
      "step": 52720
    },
    {
      "epoch": 11.300900128589799,
      "grad_norm": 0.026338063180446625,
      "learning_rate": 4.932133161880269e-06,
      "loss": 0.0,
      "step": 52730
    },
    {
      "epoch": 11.303043291898843,
      "grad_norm": 1.9935310774599202e-05,
      "learning_rate": 4.929275610801544e-06,
      "loss": 0.1658,
      "step": 52740
    },
    {
      "epoch": 11.305186455207886,
      "grad_norm": 7.232472125906497e-05,
      "learning_rate": 4.926418059722818e-06,
      "loss": 0.0,
      "step": 52750
    },
    {
      "epoch": 11.307329618516931,
      "grad_norm": 3.374899097252637e-05,
      "learning_rate": 4.923560508644092e-06,
      "loss": 0.0,
      "step": 52760
    },
    {
      "epoch": 11.309472781825976,
      "grad_norm": 2.1804531570523977e-05,
      "learning_rate": 4.920702957565367e-06,
      "loss": 0.0,
      "step": 52770
    },
    {
      "epoch": 11.311615945135019,
      "grad_norm": 2.601158121251501e-05,
      "learning_rate": 4.917845406486642e-06,
      "loss": 0.0,
      "step": 52780
    },
    {
      "epoch": 11.313759108444064,
      "grad_norm": 5.2233259339118376e-05,
      "learning_rate": 4.914987855407916e-06,
      "loss": 0.0002,
      "step": 52790
    },
    {
      "epoch": 11.315902271753108,
      "grad_norm": 2.0460151063161902e-05,
      "learning_rate": 4.91213030432919e-06,
      "loss": 0.0,
      "step": 52800
    },
    {
      "epoch": 11.318045435062151,
      "grad_norm": 1.4315741282189265e-05,
      "learning_rate": 4.9092727532504646e-06,
      "loss": 0.0,
      "step": 52810
    },
    {
      "epoch": 11.320188598371196,
      "grad_norm": 0.00012586198863573372,
      "learning_rate": 4.906415202171739e-06,
      "loss": 0.2638,
      "step": 52820
    },
    {
      "epoch": 11.32233176168024,
      "grad_norm": 0.0012535068672150373,
      "learning_rate": 4.903557651093014e-06,
      "loss": 0.139,
      "step": 52830
    },
    {
      "epoch": 11.324474924989284,
      "grad_norm": 0.00032400176860392094,
      "learning_rate": 4.900700100014288e-06,
      "loss": 0.0002,
      "step": 52840
    },
    {
      "epoch": 11.326618088298329,
      "grad_norm": 2.4139553715940565e-05,
      "learning_rate": 4.897842548935563e-06,
      "loss": 0.0,
      "step": 52850
    },
    {
      "epoch": 11.328761251607373,
      "grad_norm": 0.00024754213518463075,
      "learning_rate": 4.894984997856837e-06,
      "loss": 0.0,
      "step": 52860
    },
    {
      "epoch": 11.330904414916416,
      "grad_norm": 7.971710874699056e-05,
      "learning_rate": 4.8921274467781115e-06,
      "loss": 0.0,
      "step": 52870
    },
    {
      "epoch": 11.333047578225461,
      "grad_norm": 2.8345200917101465e-05,
      "learning_rate": 4.889269895699386e-06,
      "loss": 0.0,
      "step": 52880
    },
    {
      "epoch": 11.335190741534506,
      "grad_norm": 0.00010770858352771029,
      "learning_rate": 4.886412344620661e-06,
      "loss": 0.0,
      "step": 52890
    },
    {
      "epoch": 11.337333904843549,
      "grad_norm": 0.00019846190116368234,
      "learning_rate": 4.883554793541935e-06,
      "loss": 0.0,
      "step": 52900
    },
    {
      "epoch": 11.339477068152593,
      "grad_norm": 2.0830104404012673e-05,
      "learning_rate": 4.880697242463209e-06,
      "loss": 0.0002,
      "step": 52910
    },
    {
      "epoch": 11.341620231461638,
      "grad_norm": 0.1509072482585907,
      "learning_rate": 4.877839691384484e-06,
      "loss": 0.0002,
      "step": 52920
    },
    {
      "epoch": 11.343763394770681,
      "grad_norm": 1.587497717991937e-05,
      "learning_rate": 4.8749821403057585e-06,
      "loss": 0.0,
      "step": 52930
    },
    {
      "epoch": 11.345906558079726,
      "grad_norm": 0.0002787388802971691,
      "learning_rate": 4.872124589227033e-06,
      "loss": 0.0,
      "step": 52940
    },
    {
      "epoch": 11.34804972138877,
      "grad_norm": 5.101826900499873e-05,
      "learning_rate": 4.869267038148307e-06,
      "loss": 0.0,
      "step": 52950
    },
    {
      "epoch": 11.350192884697814,
      "grad_norm": 2.3725129722151905e-05,
      "learning_rate": 4.866409487069582e-06,
      "loss": 0.0,
      "step": 52960
    },
    {
      "epoch": 11.352336048006858,
      "grad_norm": 0.00017704960191622376,
      "learning_rate": 4.863551935990856e-06,
      "loss": 0.0008,
      "step": 52970
    },
    {
      "epoch": 11.354479211315903,
      "grad_norm": 2.5548533812980168e-05,
      "learning_rate": 4.860694384912131e-06,
      "loss": 0.289,
      "step": 52980
    },
    {
      "epoch": 11.356622374624946,
      "grad_norm": 0.00010002758062910289,
      "learning_rate": 4.8578368338334054e-06,
      "loss": 0.0,
      "step": 52990
    },
    {
      "epoch": 11.35876553793399,
      "grad_norm": 0.00031855839188210666,
      "learning_rate": 4.85497928275468e-06,
      "loss": 0.0,
      "step": 53000
    },
    {
      "epoch": 11.360908701243035,
      "grad_norm": 8.758501644479111e-05,
      "learning_rate": 4.852121731675954e-06,
      "loss": 0.0008,
      "step": 53010
    },
    {
      "epoch": 11.363051864552078,
      "grad_norm": 0.00024323519028257579,
      "learning_rate": 4.849264180597228e-06,
      "loss": 0.0003,
      "step": 53020
    },
    {
      "epoch": 11.365195027861123,
      "grad_norm": 0.00014329201076179743,
      "learning_rate": 4.846406629518503e-06,
      "loss": 0.0,
      "step": 53030
    },
    {
      "epoch": 11.367338191170168,
      "grad_norm": 0.00019061377679463476,
      "learning_rate": 4.843549078439778e-06,
      "loss": 0.2497,
      "step": 53040
    },
    {
      "epoch": 11.36948135447921,
      "grad_norm": 0.00010314842802472413,
      "learning_rate": 4.840691527361052e-06,
      "loss": 0.0,
      "step": 53050
    },
    {
      "epoch": 11.371624517788256,
      "grad_norm": 0.0001221043785335496,
      "learning_rate": 4.837833976282326e-06,
      "loss": 0.0,
      "step": 53060
    },
    {
      "epoch": 11.3737676810973,
      "grad_norm": 5.743386645917781e-05,
      "learning_rate": 4.834976425203601e-06,
      "loss": 0.0,
      "step": 53070
    },
    {
      "epoch": 11.375910844406343,
      "grad_norm": 0.023302767425775528,
      "learning_rate": 4.832118874124875e-06,
      "loss": 0.259,
      "step": 53080
    },
    {
      "epoch": 11.378054007715388,
      "grad_norm": 7.54574139136821e-05,
      "learning_rate": 4.82926132304615e-06,
      "loss": 0.0,
      "step": 53090
    },
    {
      "epoch": 11.380197171024433,
      "grad_norm": 0.00011730936967069283,
      "learning_rate": 4.826403771967425e-06,
      "loss": 0.0,
      "step": 53100
    },
    {
      "epoch": 11.382340334333476,
      "grad_norm": 0.0004593956400640309,
      "learning_rate": 4.8235462208886985e-06,
      "loss": 0.0002,
      "step": 53110
    },
    {
      "epoch": 11.38448349764252,
      "grad_norm": 0.00010134165495401248,
      "learning_rate": 4.820688669809973e-06,
      "loss": 0.0,
      "step": 53120
    },
    {
      "epoch": 11.386626660951565,
      "grad_norm": 0.00035044195828959346,
      "learning_rate": 4.817831118731248e-06,
      "loss": 0.0,
      "step": 53130
    },
    {
      "epoch": 11.388769824260608,
      "grad_norm": 3.747063965420239e-05,
      "learning_rate": 4.814973567652522e-06,
      "loss": 0.0,
      "step": 53140
    },
    {
      "epoch": 11.390912987569653,
      "grad_norm": 3.9182137697935104e-05,
      "learning_rate": 4.812116016573797e-06,
      "loss": 0.0,
      "step": 53150
    },
    {
      "epoch": 11.393056150878698,
      "grad_norm": 4.938683923683129e-05,
      "learning_rate": 4.8092584654950715e-06,
      "loss": 0.0,
      "step": 53160
    },
    {
      "epoch": 11.39519931418774,
      "grad_norm": 4.728420390165411e-05,
      "learning_rate": 4.8064009144163455e-06,
      "loss": 0.0002,
      "step": 53170
    },
    {
      "epoch": 11.397342477496785,
      "grad_norm": 4.119984441786073e-05,
      "learning_rate": 4.80354336333762e-06,
      "loss": 0.0,
      "step": 53180
    },
    {
      "epoch": 11.39948564080583,
      "grad_norm": 6.298373773461208e-05,
      "learning_rate": 4.800685812258894e-06,
      "loss": 0.0,
      "step": 53190
    },
    {
      "epoch": 11.401628804114873,
      "grad_norm": 0.0010655007790774107,
      "learning_rate": 4.797828261180169e-06,
      "loss": 0.0,
      "step": 53200
    },
    {
      "epoch": 11.403771967423918,
      "grad_norm": 0.0011440011439844966,
      "learning_rate": 4.794970710101444e-06,
      "loss": 0.0,
      "step": 53210
    },
    {
      "epoch": 11.405915130732962,
      "grad_norm": 193.66458129882812,
      "learning_rate": 4.792113159022718e-06,
      "loss": 0.0598,
      "step": 53220
    },
    {
      "epoch": 11.408058294042005,
      "grad_norm": 0.00015747758152429014,
      "learning_rate": 4.7892556079439924e-06,
      "loss": 0.0,
      "step": 53230
    },
    {
      "epoch": 11.41020145735105,
      "grad_norm": 0.00011316984455334023,
      "learning_rate": 4.786398056865267e-06,
      "loss": 0.0,
      "step": 53240
    },
    {
      "epoch": 11.412344620660095,
      "grad_norm": 9.985820361180231e-05,
      "learning_rate": 4.783540505786541e-06,
      "loss": 0.0,
      "step": 53250
    },
    {
      "epoch": 11.414487783969138,
      "grad_norm": 4.0642164094606414e-05,
      "learning_rate": 4.780682954707816e-06,
      "loss": 0.0,
      "step": 53260
    },
    {
      "epoch": 11.416630947278183,
      "grad_norm": 0.00012873634113930166,
      "learning_rate": 4.777825403629091e-06,
      "loss": 0.0001,
      "step": 53270
    },
    {
      "epoch": 11.418774110587227,
      "grad_norm": 4.6781799028394744e-05,
      "learning_rate": 4.774967852550365e-06,
      "loss": 0.0,
      "step": 53280
    },
    {
      "epoch": 11.42091727389627,
      "grad_norm": 0.00017919630045071244,
      "learning_rate": 4.772110301471639e-06,
      "loss": 0.0001,
      "step": 53290
    },
    {
      "epoch": 11.423060437205315,
      "grad_norm": 5.0178030505776405e-05,
      "learning_rate": 4.769252750392913e-06,
      "loss": 0.0,
      "step": 53300
    },
    {
      "epoch": 11.42520360051436,
      "grad_norm": 2.7278980269329622e-05,
      "learning_rate": 4.766395199314188e-06,
      "loss": 0.0012,
      "step": 53310
    },
    {
      "epoch": 11.427346763823403,
      "grad_norm": 4.250638448866084e-05,
      "learning_rate": 4.763537648235463e-06,
      "loss": 0.0,
      "step": 53320
    },
    {
      "epoch": 11.429489927132447,
      "grad_norm": 0.00010185074643231928,
      "learning_rate": 4.760680097156737e-06,
      "loss": 0.0,
      "step": 53330
    },
    {
      "epoch": 11.431633090441492,
      "grad_norm": 4.550405719783157e-05,
      "learning_rate": 4.7578225460780116e-06,
      "loss": 0.0,
      "step": 53340
    },
    {
      "epoch": 11.433776253750535,
      "grad_norm": 3.713177648023702e-05,
      "learning_rate": 4.754964994999286e-06,
      "loss": 0.0,
      "step": 53350
    },
    {
      "epoch": 11.43591941705958,
      "grad_norm": 4.622753112926148e-05,
      "learning_rate": 4.75210744392056e-06,
      "loss": 0.0,
      "step": 53360
    },
    {
      "epoch": 11.438062580368625,
      "grad_norm": 2.198930633312557e-05,
      "learning_rate": 4.749249892841835e-06,
      "loss": 0.0,
      "step": 53370
    },
    {
      "epoch": 11.440205743677668,
      "grad_norm": 0.00024141714675351977,
      "learning_rate": 4.746392341763109e-06,
      "loss": 0.0,
      "step": 53380
    },
    {
      "epoch": 11.442348906986712,
      "grad_norm": 3.658667628769763e-05,
      "learning_rate": 4.743534790684384e-06,
      "loss": 0.0,
      "step": 53390
    },
    {
      "epoch": 11.444492070295757,
      "grad_norm": 0.0007869736873544753,
      "learning_rate": 4.7406772396056585e-06,
      "loss": 0.0,
      "step": 53400
    },
    {
      "epoch": 11.4466352336048,
      "grad_norm": 3.8953872717684135e-05,
      "learning_rate": 4.7378196885269325e-06,
      "loss": 0.0,
      "step": 53410
    },
    {
      "epoch": 11.448778396913845,
      "grad_norm": 2.7183334168512374e-05,
      "learning_rate": 4.734962137448207e-06,
      "loss": 0.0,
      "step": 53420
    },
    {
      "epoch": 11.45092156022289,
      "grad_norm": 5.679245077772066e-05,
      "learning_rate": 4.732104586369482e-06,
      "loss": 0.0,
      "step": 53430
    },
    {
      "epoch": 11.453064723531933,
      "grad_norm": 4.8613390390528366e-05,
      "learning_rate": 4.729247035290756e-06,
      "loss": 0.138,
      "step": 53440
    },
    {
      "epoch": 11.455207886840977,
      "grad_norm": 6.588788528461009e-05,
      "learning_rate": 4.726389484212031e-06,
      "loss": 0.0,
      "step": 53450
    },
    {
      "epoch": 11.457351050150022,
      "grad_norm": 9.402856812812388e-05,
      "learning_rate": 4.7235319331333055e-06,
      "loss": 0.0,
      "step": 53460
    },
    {
      "epoch": 11.459494213459065,
      "grad_norm": 0.00021053265663795173,
      "learning_rate": 4.720674382054579e-06,
      "loss": 0.0,
      "step": 53470
    },
    {
      "epoch": 11.46163737676811,
      "grad_norm": 0.549055814743042,
      "learning_rate": 4.717816830975854e-06,
      "loss": 0.0002,
      "step": 53480
    },
    {
      "epoch": 11.463780540077154,
      "grad_norm": 5.81965250603389e-05,
      "learning_rate": 4.714959279897128e-06,
      "loss": 0.0,
      "step": 53490
    },
    {
      "epoch": 11.465923703386197,
      "grad_norm": 6.82509271427989e-05,
      "learning_rate": 4.712101728818403e-06,
      "loss": 0.0,
      "step": 53500
    },
    {
      "epoch": 11.468066866695242,
      "grad_norm": 0.00010046169336419553,
      "learning_rate": 4.709244177739678e-06,
      "loss": 0.0,
      "step": 53510
    },
    {
      "epoch": 11.470210030004287,
      "grad_norm": 5.36921143066138e-05,
      "learning_rate": 4.7063866266609524e-06,
      "loss": 0.0,
      "step": 53520
    },
    {
      "epoch": 11.47235319331333,
      "grad_norm": 2.6040250304504298e-05,
      "learning_rate": 4.703529075582226e-06,
      "loss": 0.0,
      "step": 53530
    },
    {
      "epoch": 11.474496356622375,
      "grad_norm": 5.153620440978557e-05,
      "learning_rate": 4.7006715245035e-06,
      "loss": 0.0,
      "step": 53540
    },
    {
      "epoch": 11.47663951993142,
      "grad_norm": 0.00013332429807633162,
      "learning_rate": 4.697813973424775e-06,
      "loss": 0.0,
      "step": 53550
    },
    {
      "epoch": 11.478782683240462,
      "grad_norm": 4.5578457502415404e-05,
      "learning_rate": 4.69495642234605e-06,
      "loss": 0.0,
      "step": 53560
    },
    {
      "epoch": 11.480925846549507,
      "grad_norm": 5.303047510096803e-05,
      "learning_rate": 4.692098871267325e-06,
      "loss": 0.0,
      "step": 53570
    },
    {
      "epoch": 11.483069009858552,
      "grad_norm": 4.063448068336584e-05,
      "learning_rate": 4.6892413201885986e-06,
      "loss": 0.0,
      "step": 53580
    },
    {
      "epoch": 11.485212173167595,
      "grad_norm": 3.451564407441765e-05,
      "learning_rate": 4.686383769109873e-06,
      "loss": 0.0,
      "step": 53590
    },
    {
      "epoch": 11.48735533647664,
      "grad_norm": 6.083002517698333e-05,
      "learning_rate": 4.683526218031147e-06,
      "loss": 0.0,
      "step": 53600
    },
    {
      "epoch": 11.489498499785684,
      "grad_norm": 4.478287519305013e-05,
      "learning_rate": 4.680668666952422e-06,
      "loss": 0.0,
      "step": 53610
    },
    {
      "epoch": 11.491641663094727,
      "grad_norm": 6.959211168577895e-05,
      "learning_rate": 4.677811115873697e-06,
      "loss": 0.0,
      "step": 53620
    },
    {
      "epoch": 11.493784826403772,
      "grad_norm": 4.834994251723401e-05,
      "learning_rate": 4.674953564794972e-06,
      "loss": 0.0009,
      "step": 53630
    },
    {
      "epoch": 11.495927989712817,
      "grad_norm": 4.341406383900903e-05,
      "learning_rate": 4.6720960137162455e-06,
      "loss": 0.0,
      "step": 53640
    },
    {
      "epoch": 11.49807115302186,
      "grad_norm": 3.589368861867115e-05,
      "learning_rate": 4.6692384626375194e-06,
      "loss": 0.0,
      "step": 53650
    },
    {
      "epoch": 11.500214316330904,
      "grad_norm": 0.00021805833966936916,
      "learning_rate": 4.666380911558794e-06,
      "loss": 0.0,
      "step": 53660
    },
    {
      "epoch": 11.502357479639949,
      "grad_norm": 3.455955447861925e-05,
      "learning_rate": 4.663523360480069e-06,
      "loss": 0.0,
      "step": 53670
    },
    {
      "epoch": 11.504500642948992,
      "grad_norm": 2.9949289455544204e-05,
      "learning_rate": 4.660665809401344e-06,
      "loss": 0.0,
      "step": 53680
    },
    {
      "epoch": 11.506643806258037,
      "grad_norm": 37.10343933105469,
      "learning_rate": 4.657808258322618e-06,
      "loss": 0.2183,
      "step": 53690
    },
    {
      "epoch": 11.508786969567081,
      "grad_norm": 3.357078821863979e-05,
      "learning_rate": 4.6549507072438925e-06,
      "loss": 0.0,
      "step": 53700
    },
    {
      "epoch": 11.510930132876124,
      "grad_norm": 0.00017312748241238296,
      "learning_rate": 4.652093156165166e-06,
      "loss": 0.0,
      "step": 53710
    },
    {
      "epoch": 11.51307329618517,
      "grad_norm": 0.000155493471538648,
      "learning_rate": 4.649235605086441e-06,
      "loss": 0.0,
      "step": 53720
    },
    {
      "epoch": 11.515216459494214,
      "grad_norm": 0.3938688337802887,
      "learning_rate": 4.646378054007716e-06,
      "loss": 0.0033,
      "step": 53730
    },
    {
      "epoch": 11.517359622803257,
      "grad_norm": 4.081786755705252e-05,
      "learning_rate": 4.643520502928991e-06,
      "loss": 0.0,
      "step": 53740
    },
    {
      "epoch": 11.519502786112302,
      "grad_norm": 3.67145512427669e-05,
      "learning_rate": 4.640662951850265e-06,
      "loss": 0.0,
      "step": 53750
    },
    {
      "epoch": 11.521645949421346,
      "grad_norm": 1.9425968275754713e-05,
      "learning_rate": 4.637805400771539e-06,
      "loss": 0.0,
      "step": 53760
    },
    {
      "epoch": 11.52378911273039,
      "grad_norm": 2.1877922335988842e-05,
      "learning_rate": 4.634947849692813e-06,
      "loss": 0.1314,
      "step": 53770
    },
    {
      "epoch": 11.525932276039434,
      "grad_norm": 0.0003052038373425603,
      "learning_rate": 4.632090298614088e-06,
      "loss": 0.0003,
      "step": 53780
    },
    {
      "epoch": 11.528075439348479,
      "grad_norm": 9.681955998530611e-05,
      "learning_rate": 4.629232747535363e-06,
      "loss": 0.0,
      "step": 53790
    },
    {
      "epoch": 11.530218602657522,
      "grad_norm": 2.870793832698837e-05,
      "learning_rate": 4.626375196456637e-06,
      "loss": 0.0,
      "step": 53800
    },
    {
      "epoch": 11.532361765966566,
      "grad_norm": 4.504114622250199e-05,
      "learning_rate": 4.623517645377912e-06,
      "loss": 0.1739,
      "step": 53810
    },
    {
      "epoch": 11.534504929275611,
      "grad_norm": 4.898709084955044e-05,
      "learning_rate": 4.6206600942991855e-06,
      "loss": 0.0,
      "step": 53820
    },
    {
      "epoch": 11.536648092584654,
      "grad_norm": 3.220023063477129e-05,
      "learning_rate": 4.61780254322046e-06,
      "loss": 0.0005,
      "step": 53830
    },
    {
      "epoch": 11.538791255893699,
      "grad_norm": 2.501969902368728e-05,
      "learning_rate": 4.614944992141735e-06,
      "loss": 0.0,
      "step": 53840
    },
    {
      "epoch": 11.540934419202744,
      "grad_norm": 3.5632754588732496e-05,
      "learning_rate": 4.61208744106301e-06,
      "loss": 0.0,
      "step": 53850
    },
    {
      "epoch": 11.543077582511787,
      "grad_norm": 0.0004777736612595618,
      "learning_rate": 4.609229889984284e-06,
      "loss": 0.0,
      "step": 53860
    },
    {
      "epoch": 11.545220745820831,
      "grad_norm": 0.00021455588284879923,
      "learning_rate": 4.606372338905558e-06,
      "loss": 0.0,
      "step": 53870
    },
    {
      "epoch": 11.547363909129876,
      "grad_norm": 3.6225406802259386e-05,
      "learning_rate": 4.6035147878268325e-06,
      "loss": 0.1443,
      "step": 53880
    },
    {
      "epoch": 11.549507072438919,
      "grad_norm": 4.1530242015141994e-05,
      "learning_rate": 4.600657236748107e-06,
      "loss": 0.0,
      "step": 53890
    },
    {
      "epoch": 11.551650235747964,
      "grad_norm": 0.00018260753131471574,
      "learning_rate": 4.597799685669382e-06,
      "loss": 0.0,
      "step": 53900
    },
    {
      "epoch": 11.553793399057009,
      "grad_norm": 0.00077725452138111,
      "learning_rate": 4.594942134590657e-06,
      "loss": 0.0,
      "step": 53910
    },
    {
      "epoch": 11.555936562366051,
      "grad_norm": 0.0002241926995338872,
      "learning_rate": 4.592084583511931e-06,
      "loss": 0.0002,
      "step": 53920
    },
    {
      "epoch": 11.558079725675096,
      "grad_norm": 0.0008333551231771708,
      "learning_rate": 4.589227032433205e-06,
      "loss": 0.0,
      "step": 53930
    },
    {
      "epoch": 11.560222888984141,
      "grad_norm": 5.465248614200391e-05,
      "learning_rate": 4.5863694813544795e-06,
      "loss": 0.0,
      "step": 53940
    },
    {
      "epoch": 11.562366052293184,
      "grad_norm": 2.5835897758952342e-05,
      "learning_rate": 4.583511930275754e-06,
      "loss": 0.0,
      "step": 53950
    },
    {
      "epoch": 11.564509215602229,
      "grad_norm": 3.3729822462191805e-05,
      "learning_rate": 4.580654379197029e-06,
      "loss": 0.0,
      "step": 53960
    },
    {
      "epoch": 11.566652378911273,
      "grad_norm": 4.2663104977691546e-05,
      "learning_rate": 4.577796828118303e-06,
      "loss": 0.1231,
      "step": 53970
    },
    {
      "epoch": 11.568795542220316,
      "grad_norm": 4.408913082443178e-05,
      "learning_rate": 4.574939277039578e-06,
      "loss": 0.0,
      "step": 53980
    },
    {
      "epoch": 11.570938705529361,
      "grad_norm": 5.7075121731031686e-05,
      "learning_rate": 4.572081725960852e-06,
      "loss": 0.0,
      "step": 53990
    },
    {
      "epoch": 11.573081868838406,
      "grad_norm": 0.0002181098097935319,
      "learning_rate": 4.569224174882126e-06,
      "loss": 0.0,
      "step": 54000
    },
    {
      "epoch": 11.57522503214745,
      "grad_norm": 3.334775465191342e-05,
      "learning_rate": 4.566366623803401e-06,
      "loss": 0.0,
      "step": 54010
    },
    {
      "epoch": 11.577368195456494,
      "grad_norm": 2.9664079193025827e-05,
      "learning_rate": 4.563509072724676e-06,
      "loss": 0.0,
      "step": 54020
    },
    {
      "epoch": 11.579511358765538,
      "grad_norm": 6.486446363851428e-05,
      "learning_rate": 4.56065152164595e-06,
      "loss": 0.0,
      "step": 54030
    },
    {
      "epoch": 11.581654522074583,
      "grad_norm": 4.341259045759216e-05,
      "learning_rate": 4.557793970567224e-06,
      "loss": 0.0,
      "step": 54040
    },
    {
      "epoch": 11.583797685383626,
      "grad_norm": 0.0002354845346417278,
      "learning_rate": 4.554936419488499e-06,
      "loss": 0.0,
      "step": 54050
    },
    {
      "epoch": 11.58594084869267,
      "grad_norm": 4.15257309214212e-05,
      "learning_rate": 4.552078868409773e-06,
      "loss": 0.0,
      "step": 54060
    },
    {
      "epoch": 11.588084012001715,
      "grad_norm": 0.00013580442464444786,
      "learning_rate": 4.549221317331048e-06,
      "loss": 0.0,
      "step": 54070
    },
    {
      "epoch": 11.590227175310758,
      "grad_norm": 0.5824985504150391,
      "learning_rate": 4.546363766252322e-06,
      "loss": 0.0003,
      "step": 54080
    },
    {
      "epoch": 11.592370338619803,
      "grad_norm": 7.09320156602189e-05,
      "learning_rate": 4.543506215173597e-06,
      "loss": 0.0,
      "step": 54090
    },
    {
      "epoch": 11.594513501928848,
      "grad_norm": 2.282306013512425e-05,
      "learning_rate": 4.540648664094871e-06,
      "loss": 0.0,
      "step": 54100
    },
    {
      "epoch": 11.59665666523789,
      "grad_norm": 0.00019319368584547192,
      "learning_rate": 4.5377911130161456e-06,
      "loss": 0.0,
      "step": 54110
    },
    {
      "epoch": 11.598799828546936,
      "grad_norm": 2.557421612436883e-05,
      "learning_rate": 4.53493356193742e-06,
      "loss": 0.0,
      "step": 54120
    },
    {
      "epoch": 11.60094299185598,
      "grad_norm": 2.258572021673899e-05,
      "learning_rate": 4.532076010858694e-06,
      "loss": 0.0,
      "step": 54130
    },
    {
      "epoch": 11.603086155165023,
      "grad_norm": 5.204914486967027e-05,
      "learning_rate": 4.529218459779969e-06,
      "loss": 0.0,
      "step": 54140
    },
    {
      "epoch": 11.605229318474068,
      "grad_norm": 2.8350767024676315e-05,
      "learning_rate": 4.526360908701243e-06,
      "loss": 0.5244,
      "step": 54150
    },
    {
      "epoch": 11.607372481783113,
      "grad_norm": 0.00022944144438952208,
      "learning_rate": 4.523503357622518e-06,
      "loss": 0.0,
      "step": 54160
    },
    {
      "epoch": 11.609515645092156,
      "grad_norm": 0.00047247856855392456,
      "learning_rate": 4.5206458065437925e-06,
      "loss": 0.0,
      "step": 54170
    },
    {
      "epoch": 11.6116588084012,
      "grad_norm": 0.00012343813432380557,
      "learning_rate": 4.517788255465067e-06,
      "loss": 0.0005,
      "step": 54180
    },
    {
      "epoch": 11.613801971710245,
      "grad_norm": 0.0009191276622004807,
      "learning_rate": 4.514930704386341e-06,
      "loss": 0.0,
      "step": 54190
    },
    {
      "epoch": 11.615945135019288,
      "grad_norm": 0.00021906339679844677,
      "learning_rate": 4.512073153307616e-06,
      "loss": 0.0,
      "step": 54200
    },
    {
      "epoch": 11.618088298328333,
      "grad_norm": 0.0001831047557061538,
      "learning_rate": 4.50921560222889e-06,
      "loss": 0.0001,
      "step": 54210
    },
    {
      "epoch": 11.620231461637378,
      "grad_norm": 0.00011973559594480321,
      "learning_rate": 4.506358051150165e-06,
      "loss": 0.0,
      "step": 54220
    },
    {
      "epoch": 11.62237462494642,
      "grad_norm": 0.00010562924580881372,
      "learning_rate": 4.5035005000714395e-06,
      "loss": 0.0,
      "step": 54230
    },
    {
      "epoch": 11.624517788255465,
      "grad_norm": 0.008840474300086498,
      "learning_rate": 4.500642948992713e-06,
      "loss": 0.0,
      "step": 54240
    },
    {
      "epoch": 11.62666095156451,
      "grad_norm": 0.00022034418361727148,
      "learning_rate": 4.497785397913988e-06,
      "loss": 0.0,
      "step": 54250
    },
    {
      "epoch": 11.628804114873553,
      "grad_norm": 9.628032421460375e-05,
      "learning_rate": 4.494927846835262e-06,
      "loss": 0.3012,
      "step": 54260
    },
    {
      "epoch": 11.630947278182598,
      "grad_norm": 0.0002925703302025795,
      "learning_rate": 4.492070295756537e-06,
      "loss": 0.0012,
      "step": 54270
    },
    {
      "epoch": 11.633090441491643,
      "grad_norm": 7.481782085960731e-05,
      "learning_rate": 4.489212744677812e-06,
      "loss": 0.0,
      "step": 54280
    },
    {
      "epoch": 11.635233604800685,
      "grad_norm": 0.0001166833535535261,
      "learning_rate": 4.4863551935990864e-06,
      "loss": 0.0,
      "step": 54290
    },
    {
      "epoch": 11.63737676810973,
      "grad_norm": 0.0002197949797846377,
      "learning_rate": 4.48349764252036e-06,
      "loss": 0.0,
      "step": 54300
    },
    {
      "epoch": 11.639519931418775,
      "grad_norm": 0.00020064125419594347,
      "learning_rate": 4.480640091441635e-06,
      "loss": 0.0,
      "step": 54310
    },
    {
      "epoch": 11.641663094727818,
      "grad_norm": 6.178506009746343e-05,
      "learning_rate": 4.477782540362909e-06,
      "loss": 0.0,
      "step": 54320
    },
    {
      "epoch": 11.643806258036863,
      "grad_norm": 0.00015404543955810368,
      "learning_rate": 4.474924989284184e-06,
      "loss": 0.1869,
      "step": 54330
    },
    {
      "epoch": 11.645949421345907,
      "grad_norm": 0.00019502354552969337,
      "learning_rate": 4.472067438205459e-06,
      "loss": 0.001,
      "step": 54340
    },
    {
      "epoch": 11.64809258465495,
      "grad_norm": 0.0013988105347380042,
      "learning_rate": 4.4692098871267325e-06,
      "loss": 0.0,
      "step": 54350
    },
    {
      "epoch": 11.650235747963995,
      "grad_norm": 0.0003337136877235025,
      "learning_rate": 4.466352336048007e-06,
      "loss": 0.203,
      "step": 54360
    },
    {
      "epoch": 11.65237891127304,
      "grad_norm": 0.0024758209474384785,
      "learning_rate": 4.463494784969282e-06,
      "loss": 0.0003,
      "step": 54370
    },
    {
      "epoch": 11.654522074582083,
      "grad_norm": 0.00029337641899473965,
      "learning_rate": 4.460637233890556e-06,
      "loss": 0.0,
      "step": 54380
    },
    {
      "epoch": 11.656665237891128,
      "grad_norm": 0.0001096250198315829,
      "learning_rate": 4.457779682811831e-06,
      "loss": 0.0,
      "step": 54390
    },
    {
      "epoch": 11.658808401200172,
      "grad_norm": 0.0001162246335297823,
      "learning_rate": 4.454922131733105e-06,
      "loss": 0.0,
      "step": 54400
    },
    {
      "epoch": 11.660951564509215,
      "grad_norm": 0.0002522513968870044,
      "learning_rate": 4.4520645806543795e-06,
      "loss": 0.0,
      "step": 54410
    },
    {
      "epoch": 11.66309472781826,
      "grad_norm": 0.0004296858096495271,
      "learning_rate": 4.449207029575654e-06,
      "loss": 0.0,
      "step": 54420
    },
    {
      "epoch": 11.665237891127305,
      "grad_norm": 0.0006889064679853618,
      "learning_rate": 4.446349478496928e-06,
      "loss": 0.0,
      "step": 54430
    },
    {
      "epoch": 11.667381054436348,
      "grad_norm": 6.02221189183183e-05,
      "learning_rate": 4.443491927418203e-06,
      "loss": 0.0,
      "step": 54440
    },
    {
      "epoch": 11.669524217745392,
      "grad_norm": 0.0020221094600856304,
      "learning_rate": 4.440634376339478e-06,
      "loss": 0.0003,
      "step": 54450
    },
    {
      "epoch": 11.671667381054437,
      "grad_norm": 0.0028110931161791086,
      "learning_rate": 4.437776825260752e-06,
      "loss": 0.0,
      "step": 54460
    },
    {
      "epoch": 11.67381054436348,
      "grad_norm": 8.574534149374813e-05,
      "learning_rate": 4.4349192741820265e-06,
      "loss": 0.0013,
      "step": 54470
    },
    {
      "epoch": 11.675953707672525,
      "grad_norm": 0.00039844756247475743,
      "learning_rate": 4.432061723103301e-06,
      "loss": 0.0,
      "step": 54480
    },
    {
      "epoch": 11.67809687098157,
      "grad_norm": 0.00034558240440674126,
      "learning_rate": 4.429204172024575e-06,
      "loss": 0.0,
      "step": 54490
    },
    {
      "epoch": 11.680240034290613,
      "grad_norm": 0.0007437263848260045,
      "learning_rate": 4.42634662094585e-06,
      "loss": 0.0,
      "step": 54500
    },
    {
      "epoch": 11.682383197599657,
      "grad_norm": 5.39375287189614e-05,
      "learning_rate": 4.423489069867124e-06,
      "loss": 0.0,
      "step": 54510
    },
    {
      "epoch": 11.684526360908702,
      "grad_norm": 0.00019007278024218976,
      "learning_rate": 4.420631518788399e-06,
      "loss": 0.0,
      "step": 54520
    },
    {
      "epoch": 11.686669524217745,
      "grad_norm": 0.00036785067641176283,
      "learning_rate": 4.417773967709673e-06,
      "loss": 0.0001,
      "step": 54530
    },
    {
      "epoch": 11.68881268752679,
      "grad_norm": 5.809235153719783e-05,
      "learning_rate": 4.414916416630947e-06,
      "loss": 0.0,
      "step": 54540
    },
    {
      "epoch": 11.690955850835834,
      "grad_norm": 6.121878686826676e-05,
      "learning_rate": 4.412058865552222e-06,
      "loss": 0.0,
      "step": 54550
    },
    {
      "epoch": 11.693099014144877,
      "grad_norm": 0.00010871612903429195,
      "learning_rate": 4.409201314473496e-06,
      "loss": 0.0,
      "step": 54560
    },
    {
      "epoch": 11.695242177453922,
      "grad_norm": 0.0001456478057662025,
      "learning_rate": 4.406343763394771e-06,
      "loss": 0.0001,
      "step": 54570
    },
    {
      "epoch": 11.697385340762967,
      "grad_norm": 0.044606659561395645,
      "learning_rate": 4.403486212316046e-06,
      "loss": 0.0,
      "step": 54580
    },
    {
      "epoch": 11.69952850407201,
      "grad_norm": 6.62790407659486e-05,
      "learning_rate": 4.40062866123732e-06,
      "loss": 0.0,
      "step": 54590
    },
    {
      "epoch": 11.701671667381055,
      "grad_norm": 3.176705649821088e-05,
      "learning_rate": 4.397771110158594e-06,
      "loss": 0.0001,
      "step": 54600
    },
    {
      "epoch": 11.7038148306901,
      "grad_norm": 3.8471349398605525e-05,
      "learning_rate": 4.394913559079869e-06,
      "loss": 0.0001,
      "step": 54610
    },
    {
      "epoch": 11.705957993999142,
      "grad_norm": 0.0004090233996976167,
      "learning_rate": 4.392056008001143e-06,
      "loss": 0.0,
      "step": 54620
    },
    {
      "epoch": 11.708101157308187,
      "grad_norm": 5.1957373216282576e-05,
      "learning_rate": 4.389198456922418e-06,
      "loss": 0.0,
      "step": 54630
    },
    {
      "epoch": 11.710244320617232,
      "grad_norm": 0.0009496511775068939,
      "learning_rate": 4.3863409058436925e-06,
      "loss": 0.0,
      "step": 54640
    },
    {
      "epoch": 11.712387483926275,
      "grad_norm": 0.00014864969125483185,
      "learning_rate": 4.3834833547649665e-06,
      "loss": 0.0,
      "step": 54650
    },
    {
      "epoch": 11.71453064723532,
      "grad_norm": 3.8347723602782935e-05,
      "learning_rate": 4.380625803686241e-06,
      "loss": 0.0,
      "step": 54660
    },
    {
      "epoch": 11.716673810544364,
      "grad_norm": 4.480725692701526e-05,
      "learning_rate": 4.377768252607515e-06,
      "loss": 0.0,
      "step": 54670
    },
    {
      "epoch": 11.718816973853407,
      "grad_norm": 6.855295214336365e-05,
      "learning_rate": 4.37491070152879e-06,
      "loss": 0.1733,
      "step": 54680
    },
    {
      "epoch": 11.720960137162452,
      "grad_norm": 5.0660430133575574e-05,
      "learning_rate": 4.372053150450065e-06,
      "loss": 0.0,
      "step": 54690
    },
    {
      "epoch": 11.723103300471497,
      "grad_norm": 5.015169153921306e-05,
      "learning_rate": 4.3691955993713395e-06,
      "loss": 0.0001,
      "step": 54700
    },
    {
      "epoch": 11.72524646378054,
      "grad_norm": 0.00014592346269637346,
      "learning_rate": 4.3663380482926134e-06,
      "loss": 0.0,
      "step": 54710
    },
    {
      "epoch": 11.727389627089584,
      "grad_norm": 0.00013379592564888299,
      "learning_rate": 4.363480497213887e-06,
      "loss": 0.0,
      "step": 54720
    },
    {
      "epoch": 11.729532790398629,
      "grad_norm": 6.999148899922147e-05,
      "learning_rate": 4.360622946135162e-06,
      "loss": 0.0,
      "step": 54730
    },
    {
      "epoch": 11.731675953707672,
      "grad_norm": 0.0007441991474479437,
      "learning_rate": 4.357765395056437e-06,
      "loss": 0.0,
      "step": 54740
    },
    {
      "epoch": 11.733819117016717,
      "grad_norm": 4.338246435509063e-05,
      "learning_rate": 4.354907843977712e-06,
      "loss": 0.0,
      "step": 54750
    },
    {
      "epoch": 11.735962280325761,
      "grad_norm": 7.26759826648049e-05,
      "learning_rate": 4.3520502928989865e-06,
      "loss": 0.0,
      "step": 54760
    },
    {
      "epoch": 11.738105443634804,
      "grad_norm": 0.00028889652458019555,
      "learning_rate": 4.34919274182026e-06,
      "loss": 0.0,
      "step": 54770
    },
    {
      "epoch": 11.74024860694385,
      "grad_norm": 0.00010596000356599689,
      "learning_rate": 4.346335190741534e-06,
      "loss": 0.1953,
      "step": 54780
    },
    {
      "epoch": 11.742391770252894,
      "grad_norm": 6.47113483864814e-05,
      "learning_rate": 4.343477639662809e-06,
      "loss": 0.0,
      "step": 54790
    },
    {
      "epoch": 11.744534933561937,
      "grad_norm": 0.0004367622022982687,
      "learning_rate": 4.340620088584084e-06,
      "loss": 0.0,
      "step": 54800
    },
    {
      "epoch": 11.746678096870982,
      "grad_norm": 5.702056296286173e-05,
      "learning_rate": 4.337762537505359e-06,
      "loss": 0.0,
      "step": 54810
    },
    {
      "epoch": 11.748821260180026,
      "grad_norm": 0.0011972308857366443,
      "learning_rate": 4.3349049864266326e-06,
      "loss": 0.0001,
      "step": 54820
    },
    {
      "epoch": 11.75096442348907,
      "grad_norm": 3.623152952059172e-05,
      "learning_rate": 4.332047435347907e-06,
      "loss": 0.0002,
      "step": 54830
    },
    {
      "epoch": 11.753107586798114,
      "grad_norm": 3.588047547964379e-05,
      "learning_rate": 4.329189884269181e-06,
      "loss": 0.0,
      "step": 54840
    },
    {
      "epoch": 11.755250750107159,
      "grad_norm": 0.0007870234549045563,
      "learning_rate": 4.326332333190456e-06,
      "loss": 0.0,
      "step": 54850
    },
    {
      "epoch": 11.757393913416202,
      "grad_norm": 9.146083903033286e-05,
      "learning_rate": 4.323474782111731e-06,
      "loss": 0.0,
      "step": 54860
    },
    {
      "epoch": 11.759537076725247,
      "grad_norm": 0.00033408289891667664,
      "learning_rate": 4.320617231033006e-06,
      "loss": 0.0,
      "step": 54870
    },
    {
      "epoch": 11.761680240034291,
      "grad_norm": 4.3786854803329334e-05,
      "learning_rate": 4.3177596799542795e-06,
      "loss": 0.0,
      "step": 54880
    },
    {
      "epoch": 11.763823403343334,
      "grad_norm": 6.257249333430082e-05,
      "learning_rate": 4.3149021288755535e-06,
      "loss": 0.1122,
      "step": 54890
    },
    {
      "epoch": 11.765966566652379,
      "grad_norm": 3.9304035453824326e-05,
      "learning_rate": 4.312044577796828e-06,
      "loss": 0.0008,
      "step": 54900
    },
    {
      "epoch": 11.768109729961424,
      "grad_norm": 9.479624714003876e-05,
      "learning_rate": 4.309187026718103e-06,
      "loss": 0.0,
      "step": 54910
    },
    {
      "epoch": 11.770252893270467,
      "grad_norm": 4.649430775316432e-05,
      "learning_rate": 4.306329475639378e-06,
      "loss": 0.0,
      "step": 54920
    },
    {
      "epoch": 11.772396056579511,
      "grad_norm": 4.1420375055167824e-05,
      "learning_rate": 4.303471924560652e-06,
      "loss": 0.0,
      "step": 54930
    },
    {
      "epoch": 11.774539219888556,
      "grad_norm": 3.09087845380418e-05,
      "learning_rate": 4.3006143734819265e-06,
      "loss": 0.0,
      "step": 54940
    },
    {
      "epoch": 11.776682383197599,
      "grad_norm": 3.209718124708161e-05,
      "learning_rate": 4.2977568224032e-06,
      "loss": 0.0,
      "step": 54950
    },
    {
      "epoch": 11.778825546506644,
      "grad_norm": 0.0001379467867081985,
      "learning_rate": 4.294899271324475e-06,
      "loss": 0.0,
      "step": 54960
    },
    {
      "epoch": 11.780968709815689,
      "grad_norm": 4.9820097046904266e-05,
      "learning_rate": 4.29204172024575e-06,
      "loss": 0.0,
      "step": 54970
    },
    {
      "epoch": 11.783111873124732,
      "grad_norm": 0.00019196812354493886,
      "learning_rate": 4.289184169167025e-06,
      "loss": 0.0,
      "step": 54980
    },
    {
      "epoch": 11.785255036433776,
      "grad_norm": 4.93697079946287e-05,
      "learning_rate": 4.286326618088299e-06,
      "loss": 0.0,
      "step": 54990
    },
    {
      "epoch": 11.787398199742821,
      "grad_norm": 4.806287688552402e-05,
      "learning_rate": 4.283469067009573e-06,
      "loss": 0.0,
      "step": 55000
    },
    {
      "epoch": 11.789541363051864,
      "grad_norm": 0.0003263465187046677,
      "learning_rate": 4.280611515930847e-06,
      "loss": 0.0,
      "step": 55010
    },
    {
      "epoch": 11.791684526360909,
      "grad_norm": 9.376812522532418e-05,
      "learning_rate": 4.277753964852122e-06,
      "loss": 0.0,
      "step": 55020
    },
    {
      "epoch": 11.793827689669953,
      "grad_norm": 4.225479642627761e-05,
      "learning_rate": 4.274896413773397e-06,
      "loss": 0.0,
      "step": 55030
    },
    {
      "epoch": 11.795970852978996,
      "grad_norm": 8.945798617787659e-05,
      "learning_rate": 4.272038862694671e-06,
      "loss": 0.0002,
      "step": 55040
    },
    {
      "epoch": 11.798114016288041,
      "grad_norm": 6.187700637383386e-05,
      "learning_rate": 4.269181311615946e-06,
      "loss": 0.0,
      "step": 55050
    },
    {
      "epoch": 11.800257179597086,
      "grad_norm": 0.0001738280989229679,
      "learning_rate": 4.2663237605372196e-06,
      "loss": 0.0,
      "step": 55060
    },
    {
      "epoch": 11.802400342906129,
      "grad_norm": 3.732304321601987e-05,
      "learning_rate": 4.263466209458494e-06,
      "loss": 0.0,
      "step": 55070
    },
    {
      "epoch": 11.804543506215174,
      "grad_norm": 3.727811781573109e-05,
      "learning_rate": 4.260608658379769e-06,
      "loss": 0.0,
      "step": 55080
    },
    {
      "epoch": 11.806686669524218,
      "grad_norm": 3.2094631023937836e-05,
      "learning_rate": 4.257751107301044e-06,
      "loss": 0.0011,
      "step": 55090
    },
    {
      "epoch": 11.808829832833261,
      "grad_norm": 3.6900696754455566,
      "learning_rate": 4.254893556222318e-06,
      "loss": 0.0042,
      "step": 55100
    },
    {
      "epoch": 11.810972996142306,
      "grad_norm": 0.0002459291717968881,
      "learning_rate": 4.252036005143592e-06,
      "loss": 0.242,
      "step": 55110
    },
    {
      "epoch": 11.81311615945135,
      "grad_norm": 6.0935792134841904e-05,
      "learning_rate": 4.2491784540648665e-06,
      "loss": 0.0,
      "step": 55120
    },
    {
      "epoch": 11.815259322760394,
      "grad_norm": 0.00042290278361178935,
      "learning_rate": 4.246320902986141e-06,
      "loss": 0.0002,
      "step": 55130
    },
    {
      "epoch": 11.817402486069438,
      "grad_norm": 0.03030352294445038,
      "learning_rate": 4.243463351907416e-06,
      "loss": 0.0,
      "step": 55140
    },
    {
      "epoch": 11.819545649378483,
      "grad_norm": 0.00019510711717884988,
      "learning_rate": 4.24060580082869e-06,
      "loss": 0.0001,
      "step": 55150
    },
    {
      "epoch": 11.821688812687526,
      "grad_norm": 0.10486430674791336,
      "learning_rate": 4.237748249749965e-06,
      "loss": 0.0002,
      "step": 55160
    },
    {
      "epoch": 11.82383197599657,
      "grad_norm": 0.14659540355205536,
      "learning_rate": 4.234890698671239e-06,
      "loss": 0.0002,
      "step": 55170
    },
    {
      "epoch": 11.825975139305616,
      "grad_norm": 5.5428525229217485e-05,
      "learning_rate": 4.2320331475925135e-06,
      "loss": 0.0004,
      "step": 55180
    },
    {
      "epoch": 11.828118302614659,
      "grad_norm": 4.217698369757272e-05,
      "learning_rate": 4.229175596513788e-06,
      "loss": 0.1389,
      "step": 55190
    },
    {
      "epoch": 11.830261465923703,
      "grad_norm": 0.002607651287689805,
      "learning_rate": 4.226318045435063e-06,
      "loss": 0.0001,
      "step": 55200
    },
    {
      "epoch": 11.832404629232748,
      "grad_norm": 0.2260124385356903,
      "learning_rate": 4.223460494356337e-06,
      "loss": 0.0002,
      "step": 55210
    },
    {
      "epoch": 11.834547792541791,
      "grad_norm": 0.00016348381177522242,
      "learning_rate": 4.220602943277612e-06,
      "loss": 0.0,
      "step": 55220
    },
    {
      "epoch": 11.836690955850836,
      "grad_norm": 0.0002136551047442481,
      "learning_rate": 4.217745392198886e-06,
      "loss": 0.0,
      "step": 55230
    },
    {
      "epoch": 11.83883411915988,
      "grad_norm": 0.005948570556938648,
      "learning_rate": 4.2148878411201604e-06,
      "loss": 0.0,
      "step": 55240
    },
    {
      "epoch": 11.840977282468923,
      "grad_norm": 7.136815111152828e-05,
      "learning_rate": 4.212030290041435e-06,
      "loss": 0.0,
      "step": 55250
    },
    {
      "epoch": 11.843120445777968,
      "grad_norm": 3.939167800126597e-05,
      "learning_rate": 4.209172738962709e-06,
      "loss": 0.0,
      "step": 55260
    },
    {
      "epoch": 11.845263609087013,
      "grad_norm": 2.8959839255549014e-05,
      "learning_rate": 4.206315187883984e-06,
      "loss": 0.0006,
      "step": 55270
    },
    {
      "epoch": 11.847406772396056,
      "grad_norm": 0.00011752443242585286,
      "learning_rate": 4.203457636805258e-06,
      "loss": 0.0,
      "step": 55280
    },
    {
      "epoch": 11.8495499357051,
      "grad_norm": 4.240201087668538e-05,
      "learning_rate": 4.200600085726533e-06,
      "loss": 0.0001,
      "step": 55290
    },
    {
      "epoch": 11.851693099014145,
      "grad_norm": 16.906221389770508,
      "learning_rate": 4.197742534647807e-06,
      "loss": 0.1587,
      "step": 55300
    },
    {
      "epoch": 11.853836262323188,
      "grad_norm": 3.603687582653947e-05,
      "learning_rate": 4.194884983569082e-06,
      "loss": 0.0001,
      "step": 55310
    },
    {
      "epoch": 11.855979425632233,
      "grad_norm": 3.601784919737838e-05,
      "learning_rate": 4.192027432490356e-06,
      "loss": 0.0,
      "step": 55320
    },
    {
      "epoch": 11.858122588941278,
      "grad_norm": 4.17809933423996e-05,
      "learning_rate": 4.189169881411631e-06,
      "loss": 0.1629,
      "step": 55330
    },
    {
      "epoch": 11.86026575225032,
      "grad_norm": 8.513790817232803e-05,
      "learning_rate": 4.186312330332905e-06,
      "loss": 0.0,
      "step": 55340
    },
    {
      "epoch": 11.862408915559365,
      "grad_norm": 0.00019859716121573,
      "learning_rate": 4.1834547792541796e-06,
      "loss": 0.0,
      "step": 55350
    },
    {
      "epoch": 11.86455207886841,
      "grad_norm": 0.00022282732243184,
      "learning_rate": 4.180597228175454e-06,
      "loss": 0.0,
      "step": 55360
    },
    {
      "epoch": 11.866695242177453,
      "grad_norm": 5.0251823267899454e-05,
      "learning_rate": 4.177739677096728e-06,
      "loss": 0.0,
      "step": 55370
    },
    {
      "epoch": 11.868838405486498,
      "grad_norm": 0.00014648944488726556,
      "learning_rate": 4.174882126018003e-06,
      "loss": 0.0,
      "step": 55380
    },
    {
      "epoch": 11.870981568795543,
      "grad_norm": 0.00011218624422326684,
      "learning_rate": 4.172024574939277e-06,
      "loss": 0.0,
      "step": 55390
    },
    {
      "epoch": 11.873124732104586,
      "grad_norm": 3.7818081182194874e-05,
      "learning_rate": 4.169167023860552e-06,
      "loss": 0.0,
      "step": 55400
    },
    {
      "epoch": 11.87526789541363,
      "grad_norm": 4.1566203435650095e-05,
      "learning_rate": 4.1663094727818265e-06,
      "loss": 0.0003,
      "step": 55410
    },
    {
      "epoch": 11.877411058722675,
      "grad_norm": 3.503970947349444e-05,
      "learning_rate": 4.1634519217031005e-06,
      "loss": 0.0,
      "step": 55420
    },
    {
      "epoch": 11.879554222031718,
      "grad_norm": 2.7178599339094944e-05,
      "learning_rate": 4.160594370624375e-06,
      "loss": 0.0,
      "step": 55430
    },
    {
      "epoch": 11.881697385340763,
      "grad_norm": 0.00022458060993812978,
      "learning_rate": 4.15773681954565e-06,
      "loss": 0.0,
      "step": 55440
    },
    {
      "epoch": 11.883840548649808,
      "grad_norm": 0.0006080055609345436,
      "learning_rate": 4.154879268466924e-06,
      "loss": 0.0,
      "step": 55450
    },
    {
      "epoch": 11.88598371195885,
      "grad_norm": 5.187834540265612e-05,
      "learning_rate": 4.152021717388199e-06,
      "loss": 0.0,
      "step": 55460
    },
    {
      "epoch": 11.888126875267895,
      "grad_norm": 4.532296225079335e-05,
      "learning_rate": 4.1491641663094735e-06,
      "loss": 0.0,
      "step": 55470
    },
    {
      "epoch": 11.89027003857694,
      "grad_norm": 3.9122354792198166e-05,
      "learning_rate": 4.146306615230747e-06,
      "loss": 0.0,
      "step": 55480
    },
    {
      "epoch": 11.892413201885983,
      "grad_norm": 3.545463550835848e-05,
      "learning_rate": 4.143449064152022e-06,
      "loss": 0.0,
      "step": 55490
    },
    {
      "epoch": 11.894556365195028,
      "grad_norm": 5.3940391808282584e-05,
      "learning_rate": 4.140591513073296e-06,
      "loss": 0.0,
      "step": 55500
    },
    {
      "epoch": 11.896699528504072,
      "grad_norm": 0.00020102343114558607,
      "learning_rate": 4.137733961994571e-06,
      "loss": 0.0,
      "step": 55510
    },
    {
      "epoch": 11.898842691813115,
      "grad_norm": 0.05372815206646919,
      "learning_rate": 4.134876410915846e-06,
      "loss": 0.0,
      "step": 55520
    },
    {
      "epoch": 11.90098585512216,
      "grad_norm": 9.862727165454999e-05,
      "learning_rate": 4.13201885983712e-06,
      "loss": 0.1806,
      "step": 55530
    },
    {
      "epoch": 11.903129018431205,
      "grad_norm": 6.799310358474031e-05,
      "learning_rate": 4.129161308758394e-06,
      "loss": 0.0,
      "step": 55540
    },
    {
      "epoch": 11.905272181740248,
      "grad_norm": 4.906376852886751e-05,
      "learning_rate": 4.126303757679669e-06,
      "loss": 0.0,
      "step": 55550
    },
    {
      "epoch": 11.907415345049293,
      "grad_norm": 0.000115250724775251,
      "learning_rate": 4.123446206600943e-06,
      "loss": 0.0,
      "step": 55560
    },
    {
      "epoch": 11.909558508358337,
      "grad_norm": 6.211549043655396e-05,
      "learning_rate": 4.120588655522218e-06,
      "loss": 0.0,
      "step": 55570
    },
    {
      "epoch": 11.91170167166738,
      "grad_norm": 3.4153388696722686e-05,
      "learning_rate": 4.117731104443492e-06,
      "loss": 0.0001,
      "step": 55580
    },
    {
      "epoch": 11.913844834976425,
      "grad_norm": 0.0001986532734008506,
      "learning_rate": 4.1148735533647666e-06,
      "loss": 0.0,
      "step": 55590
    },
    {
      "epoch": 11.91598799828547,
      "grad_norm": 5.9347970818635076e-05,
      "learning_rate": 4.112016002286041e-06,
      "loss": 0.0,
      "step": 55600
    },
    {
      "epoch": 11.918131161594513,
      "grad_norm": 6.997590389801189e-05,
      "learning_rate": 4.109158451207316e-06,
      "loss": 0.0,
      "step": 55610
    },
    {
      "epoch": 11.920274324903557,
      "grad_norm": 0.0001410008844686672,
      "learning_rate": 4.10630090012859e-06,
      "loss": 0.0,
      "step": 55620
    },
    {
      "epoch": 11.922417488212602,
      "grad_norm": 8.454886119579896e-05,
      "learning_rate": 4.103443349049865e-06,
      "loss": 0.0,
      "step": 55630
    },
    {
      "epoch": 11.924560651521645,
      "grad_norm": 0.00013678526738658547,
      "learning_rate": 4.100585797971139e-06,
      "loss": 0.2074,
      "step": 55640
    },
    {
      "epoch": 11.92670381483069,
      "grad_norm": 0.0008389087743125856,
      "learning_rate": 4.0977282468924135e-06,
      "loss": 0.0,
      "step": 55650
    },
    {
      "epoch": 11.928846978139735,
      "grad_norm": 0.0002209394151577726,
      "learning_rate": 4.094870695813688e-06,
      "loss": 0.0022,
      "step": 55660
    },
    {
      "epoch": 11.930990141448778,
      "grad_norm": 0.0022802723105996847,
      "learning_rate": 4.092013144734962e-06,
      "loss": 0.0,
      "step": 55670
    },
    {
      "epoch": 11.933133304757822,
      "grad_norm": 0.0001925305841723457,
      "learning_rate": 4.089155593656237e-06,
      "loss": 0.1117,
      "step": 55680
    },
    {
      "epoch": 11.935276468066867,
      "grad_norm": 0.00036242417991161346,
      "learning_rate": 4.086298042577511e-06,
      "loss": 0.1936,
      "step": 55690
    },
    {
      "epoch": 11.93741963137591,
      "grad_norm": 0.0003190706775058061,
      "learning_rate": 4.083440491498786e-06,
      "loss": 0.0,
      "step": 55700
    },
    {
      "epoch": 11.939562794684955,
      "grad_norm": 0.00014237839786801487,
      "learning_rate": 4.0805829404200605e-06,
      "loss": 0.0,
      "step": 55710
    },
    {
      "epoch": 11.941705957994,
      "grad_norm": 9.145608055405319e-05,
      "learning_rate": 4.077725389341335e-06,
      "loss": 0.0,
      "step": 55720
    },
    {
      "epoch": 11.943849121303042,
      "grad_norm": 8.600262663094327e-05,
      "learning_rate": 4.074867838262609e-06,
      "loss": 0.1556,
      "step": 55730
    },
    {
      "epoch": 11.945992284612087,
      "grad_norm": 0.24681606888771057,
      "learning_rate": 4.072010287183883e-06,
      "loss": 0.002,
      "step": 55740
    },
    {
      "epoch": 11.948135447921132,
      "grad_norm": 0.0014427030691877007,
      "learning_rate": 4.069152736105158e-06,
      "loss": 0.0001,
      "step": 55750
    },
    {
      "epoch": 11.950278611230175,
      "grad_norm": 0.0006301028188318014,
      "learning_rate": 4.066295185026433e-06,
      "loss": 0.0002,
      "step": 55760
    },
    {
      "epoch": 11.95242177453922,
      "grad_norm": 0.0009147846139967442,
      "learning_rate": 4.0634376339477074e-06,
      "loss": 0.0001,
      "step": 55770
    },
    {
      "epoch": 11.954564937848264,
      "grad_norm": 0.004876039922237396,
      "learning_rate": 4.060580082868981e-06,
      "loss": 0.0,
      "step": 55780
    },
    {
      "epoch": 11.956708101157307,
      "grad_norm": 0.00312057021073997,
      "learning_rate": 4.057722531790256e-06,
      "loss": 0.0,
      "step": 55790
    },
    {
      "epoch": 11.958851264466352,
      "grad_norm": 0.000632467505056411,
      "learning_rate": 4.05486498071153e-06,
      "loss": 0.0002,
      "step": 55800
    },
    {
      "epoch": 11.960994427775397,
      "grad_norm": 0.007259969599545002,
      "learning_rate": 4.052007429632805e-06,
      "loss": 0.0,
      "step": 55810
    },
    {
      "epoch": 11.96313759108444,
      "grad_norm": 0.00012572492414619774,
      "learning_rate": 4.04914987855408e-06,
      "loss": 0.0,
      "step": 55820
    },
    {
      "epoch": 11.965280754393484,
      "grad_norm": 7.047339749988168e-05,
      "learning_rate": 4.046292327475354e-06,
      "loss": 0.0,
      "step": 55830
    },
    {
      "epoch": 11.96742391770253,
      "grad_norm": 9.013710223371163e-05,
      "learning_rate": 4.043434776396628e-06,
      "loss": 0.0001,
      "step": 55840
    },
    {
      "epoch": 11.969567081011572,
      "grad_norm": 7.609446765854955e-05,
      "learning_rate": 4.040577225317902e-06,
      "loss": 0.3055,
      "step": 55850
    },
    {
      "epoch": 11.971710244320617,
      "grad_norm": 0.00045290618436411023,
      "learning_rate": 4.037719674239177e-06,
      "loss": 0.0001,
      "step": 55860
    },
    {
      "epoch": 11.973853407629662,
      "grad_norm": 9.509890514891595e-05,
      "learning_rate": 4.034862123160452e-06,
      "loss": 0.0003,
      "step": 55870
    },
    {
      "epoch": 11.975996570938705,
      "grad_norm": 6.550108082592487e-05,
      "learning_rate": 4.0320045720817266e-06,
      "loss": 0.0034,
      "step": 55880
    },
    {
      "epoch": 11.97813973424775,
      "grad_norm": 0.035930100828409195,
      "learning_rate": 4.029147021003001e-06,
      "loss": 0.0001,
      "step": 55890
    },
    {
      "epoch": 11.980282897556794,
      "grad_norm": 4.0636383346281946e-05,
      "learning_rate": 4.026289469924275e-06,
      "loss": 0.0,
      "step": 55900
    },
    {
      "epoch": 11.982426060865837,
      "grad_norm": 4.147513027419336e-05,
      "learning_rate": 4.023431918845549e-06,
      "loss": 0.0002,
      "step": 55910
    },
    {
      "epoch": 11.984569224174882,
      "grad_norm": 3.437889608903788e-05,
      "learning_rate": 4.020574367766824e-06,
      "loss": 0.0,
      "step": 55920
    },
    {
      "epoch": 11.986712387483927,
      "grad_norm": 0.006744293961673975,
      "learning_rate": 4.017716816688099e-06,
      "loss": 0.0,
      "step": 55930
    },
    {
      "epoch": 11.98885555079297,
      "grad_norm": 8.125555905280635e-05,
      "learning_rate": 4.0148592656093735e-06,
      "loss": 0.1243,
      "step": 55940
    },
    {
      "epoch": 11.990998714102014,
      "grad_norm": 5.761053034802899e-05,
      "learning_rate": 4.0120017145306475e-06,
      "loss": 0.0002,
      "step": 55950
    },
    {
      "epoch": 11.993141877411059,
      "grad_norm": 0.00016848629456944764,
      "learning_rate": 4.009144163451922e-06,
      "loss": 0.0,
      "step": 55960
    },
    {
      "epoch": 11.995285040720102,
      "grad_norm": 3.0272613003035076e-05,
      "learning_rate": 4.006286612373196e-06,
      "loss": 0.0008,
      "step": 55970
    },
    {
      "epoch": 11.997428204029147,
      "grad_norm": 4.789348167832941e-05,
      "learning_rate": 4.003429061294471e-06,
      "loss": 0.0,
      "step": 55980
    },
    {
      "epoch": 11.999571367338191,
      "grad_norm": 3.820331403403543e-05,
      "learning_rate": 4.000571510215746e-06,
      "loss": 0.0,
      "step": 55990
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.986,
      "eval_f1": 0.926829268292683,
      "eval_loss": 0.12295302003622055,
      "eval_precision": 0.9708029197080292,
      "eval_recall": 0.8866666666666667,
      "eval_runtime": 400.8813,
      "eval_samples_per_second": 7.484,
      "eval_steps_per_second": 2.495,
      "step": 55992
    },
    {
      "epoch": 12.001714530647236,
      "grad_norm": 0.00016189362213481218,
      "learning_rate": 3.9977139591370205e-06,
      "loss": 0.1105,
      "step": 56000
    },
    {
      "epoch": 12.003857693956279,
      "grad_norm": 4.102352249901742e-05,
      "learning_rate": 3.994856408058294e-06,
      "loss": 0.0,
      "step": 56010
    },
    {
      "epoch": 12.006000857265324,
      "grad_norm": 0.1471881866455078,
      "learning_rate": 3.991998856979568e-06,
      "loss": 0.0002,
      "step": 56020
    },
    {
      "epoch": 12.008144020574369,
      "grad_norm": 4.066143083036877e-05,
      "learning_rate": 3.989141305900843e-06,
      "loss": 0.0004,
      "step": 56030
    },
    {
      "epoch": 12.010287183883412,
      "grad_norm": 0.15618574619293213,
      "learning_rate": 3.986283754822118e-06,
      "loss": 0.0001,
      "step": 56040
    },
    {
      "epoch": 12.012430347192456,
      "grad_norm": 0.00010753094829851761,
      "learning_rate": 3.983426203743393e-06,
      "loss": 0.0,
      "step": 56050
    },
    {
      "epoch": 12.014573510501501,
      "grad_norm": 2.066367960651405e-05,
      "learning_rate": 3.980568652664667e-06,
      "loss": 0.0,
      "step": 56060
    },
    {
      "epoch": 12.016716673810544,
      "grad_norm": 2.2380863811122254e-05,
      "learning_rate": 3.977711101585941e-06,
      "loss": 0.1186,
      "step": 56070
    },
    {
      "epoch": 12.018859837119589,
      "grad_norm": 0.00014966986782383174,
      "learning_rate": 3.974853550507215e-06,
      "loss": 0.0,
      "step": 56080
    },
    {
      "epoch": 12.021003000428633,
      "grad_norm": 2.978349402837921e-05,
      "learning_rate": 3.97199599942849e-06,
      "loss": 0.0001,
      "step": 56090
    },
    {
      "epoch": 12.023146163737676,
      "grad_norm": 5.6706081522861496e-05,
      "learning_rate": 3.969138448349765e-06,
      "loss": 0.0,
      "step": 56100
    },
    {
      "epoch": 12.025289327046721,
      "grad_norm": 2.3940207029227167e-05,
      "learning_rate": 3.96628089727104e-06,
      "loss": 0.0,
      "step": 56110
    },
    {
      "epoch": 12.027432490355766,
      "grad_norm": 0.0004080978105776012,
      "learning_rate": 3.9634233461923136e-06,
      "loss": 0.0,
      "step": 56120
    },
    {
      "epoch": 12.029575653664809,
      "grad_norm": 0.0001078554560081102,
      "learning_rate": 3.9605657951135875e-06,
      "loss": 0.0,
      "step": 56130
    },
    {
      "epoch": 12.031718816973854,
      "grad_norm": 2.918782593042124e-05,
      "learning_rate": 3.957708244034862e-06,
      "loss": 0.0001,
      "step": 56140
    },
    {
      "epoch": 12.033861980282898,
      "grad_norm": 4.873113357461989e-05,
      "learning_rate": 3.954850692956137e-06,
      "loss": 0.0,
      "step": 56150
    },
    {
      "epoch": 12.036005143591941,
      "grad_norm": 5.6893055443651974e-05,
      "learning_rate": 3.951993141877412e-06,
      "loss": 0.0,
      "step": 56160
    },
    {
      "epoch": 12.038148306900986,
      "grad_norm": 0.0001248393818968907,
      "learning_rate": 3.949135590798686e-06,
      "loss": 0.0,
      "step": 56170
    },
    {
      "epoch": 12.04029147021003,
      "grad_norm": 5.902379780309275e-05,
      "learning_rate": 3.9462780397199605e-06,
      "loss": 0.0,
      "step": 56180
    },
    {
      "epoch": 12.042434633519074,
      "grad_norm": 2.38576321862638e-05,
      "learning_rate": 3.9434204886412344e-06,
      "loss": 0.0,
      "step": 56190
    },
    {
      "epoch": 12.044577796828118,
      "grad_norm": 2.1645653760060668e-05,
      "learning_rate": 3.940562937562509e-06,
      "loss": 0.0,
      "step": 56200
    },
    {
      "epoch": 12.046720960137163,
      "grad_norm": 0.0007806421490386128,
      "learning_rate": 3.937705386483784e-06,
      "loss": 0.0,
      "step": 56210
    },
    {
      "epoch": 12.048864123446206,
      "grad_norm": 2.9304732379387133e-05,
      "learning_rate": 3.934847835405059e-06,
      "loss": 0.0,
      "step": 56220
    },
    {
      "epoch": 12.051007286755251,
      "grad_norm": 2.1598991224891506e-05,
      "learning_rate": 3.931990284326333e-06,
      "loss": 0.0,
      "step": 56230
    },
    {
      "epoch": 12.053150450064296,
      "grad_norm": 2.5389294023625553e-05,
      "learning_rate": 3.929132733247607e-06,
      "loss": 0.0,
      "step": 56240
    },
    {
      "epoch": 12.055293613373339,
      "grad_norm": 2.4168266463675536e-05,
      "learning_rate": 3.926275182168881e-06,
      "loss": 0.0,
      "step": 56250
    },
    {
      "epoch": 12.057436776682383,
      "grad_norm": 1.8333013940718956e-05,
      "learning_rate": 3.923417631090156e-06,
      "loss": 0.001,
      "step": 56260
    },
    {
      "epoch": 12.059579939991428,
      "grad_norm": 0.054359693080186844,
      "learning_rate": 3.920560080011431e-06,
      "loss": 0.1096,
      "step": 56270
    },
    {
      "epoch": 12.061723103300471,
      "grad_norm": 6.0486792790470645e-05,
      "learning_rate": 3.917702528932705e-06,
      "loss": 0.0,
      "step": 56280
    },
    {
      "epoch": 12.063866266609516,
      "grad_norm": 0.0034034056589007378,
      "learning_rate": 3.91484497785398e-06,
      "loss": 0.0004,
      "step": 56290
    },
    {
      "epoch": 12.06600942991856,
      "grad_norm": 2.131133442162536e-05,
      "learning_rate": 3.911987426775254e-06,
      "loss": 0.0,
      "step": 56300
    },
    {
      "epoch": 12.068152593227603,
      "grad_norm": 2.3660755687160417e-05,
      "learning_rate": 3.909129875696528e-06,
      "loss": 0.0,
      "step": 56310
    },
    {
      "epoch": 12.070295756536648,
      "grad_norm": 2.1456440663314424e-05,
      "learning_rate": 3.906272324617803e-06,
      "loss": 0.0,
      "step": 56320
    },
    {
      "epoch": 12.072438919845693,
      "grad_norm": 0.0014234042027965188,
      "learning_rate": 3.903414773539078e-06,
      "loss": 0.0,
      "step": 56330
    },
    {
      "epoch": 12.074582083154736,
      "grad_norm": 1.4649092008767184e-05,
      "learning_rate": 3.900557222460352e-06,
      "loss": 0.0,
      "step": 56340
    },
    {
      "epoch": 12.07672524646378,
      "grad_norm": 2.5819472284638323e-05,
      "learning_rate": 3.897699671381627e-06,
      "loss": 0.2315,
      "step": 56350
    },
    {
      "epoch": 12.078868409772825,
      "grad_norm": 6.138976459624246e-05,
      "learning_rate": 3.8948421203029005e-06,
      "loss": 0.0,
      "step": 56360
    },
    {
      "epoch": 12.081011573081868,
      "grad_norm": 8.809188148006797e-05,
      "learning_rate": 3.891984569224175e-06,
      "loss": 0.0,
      "step": 56370
    },
    {
      "epoch": 12.083154736390913,
      "grad_norm": 2.0948215023963712e-05,
      "learning_rate": 3.88912701814545e-06,
      "loss": 0.084,
      "step": 56380
    },
    {
      "epoch": 12.085297899699958,
      "grad_norm": 3.46390443155542e-05,
      "learning_rate": 3.886269467066724e-06,
      "loss": 0.0,
      "step": 56390
    },
    {
      "epoch": 12.087441063009,
      "grad_norm": 0.00013574076001532376,
      "learning_rate": 3.883411915987999e-06,
      "loss": 0.0,
      "step": 56400
    },
    {
      "epoch": 12.089584226318046,
      "grad_norm": 0.00021214269509073347,
      "learning_rate": 3.880554364909273e-06,
      "loss": 0.0,
      "step": 56410
    },
    {
      "epoch": 12.09172738962709,
      "grad_norm": 0.00018484405882190913,
      "learning_rate": 3.8776968138305475e-06,
      "loss": 0.0,
      "step": 56420
    },
    {
      "epoch": 12.093870552936133,
      "grad_norm": 5.4355990869225934e-05,
      "learning_rate": 3.874839262751822e-06,
      "loss": 0.0,
      "step": 56430
    },
    {
      "epoch": 12.096013716245178,
      "grad_norm": 3.503223342704587e-05,
      "learning_rate": 3.871981711673096e-06,
      "loss": 0.0,
      "step": 56440
    },
    {
      "epoch": 12.098156879554223,
      "grad_norm": 1.8525326595408842e-05,
      "learning_rate": 3.869124160594371e-06,
      "loss": 0.0,
      "step": 56450
    },
    {
      "epoch": 12.100300042863266,
      "grad_norm": 5.4596148402197286e-05,
      "learning_rate": 3.866266609515646e-06,
      "loss": 0.0,
      "step": 56460
    },
    {
      "epoch": 12.10244320617231,
      "grad_norm": 7.054354500724003e-05,
      "learning_rate": 3.86340905843692e-06,
      "loss": 0.0,
      "step": 56470
    },
    {
      "epoch": 12.104586369481355,
      "grad_norm": 0.004407464060932398,
      "learning_rate": 3.8605515073581945e-06,
      "loss": 0.0001,
      "step": 56480
    },
    {
      "epoch": 12.106729532790398,
      "grad_norm": 1.7402229786966927e-05,
      "learning_rate": 3.857693956279469e-06,
      "loss": 0.0,
      "step": 56490
    },
    {
      "epoch": 12.108872696099443,
      "grad_norm": 3.256272248108871e-05,
      "learning_rate": 3.854836405200743e-06,
      "loss": 0.0,
      "step": 56500
    },
    {
      "epoch": 12.111015859408488,
      "grad_norm": 2.1331228708731942e-05,
      "learning_rate": 3.851978854122018e-06,
      "loss": 0.0,
      "step": 56510
    },
    {
      "epoch": 12.11315902271753,
      "grad_norm": 2.2391410311684012e-05,
      "learning_rate": 3.849121303043292e-06,
      "loss": 0.0,
      "step": 56520
    },
    {
      "epoch": 12.115302186026575,
      "grad_norm": 2.343358937650919e-05,
      "learning_rate": 3.846263751964567e-06,
      "loss": 0.0,
      "step": 56530
    },
    {
      "epoch": 12.11744534933562,
      "grad_norm": 2.368789864704013e-05,
      "learning_rate": 3.843406200885841e-06,
      "loss": 0.2234,
      "step": 56540
    },
    {
      "epoch": 12.119588512644663,
      "grad_norm": 0.00011067559535149485,
      "learning_rate": 3.840548649807115e-06,
      "loss": 0.0,
      "step": 56550
    },
    {
      "epoch": 12.121731675953708,
      "grad_norm": 0.14046747982501984,
      "learning_rate": 3.83769109872839e-06,
      "loss": 0.0958,
      "step": 56560
    },
    {
      "epoch": 12.123874839262752,
      "grad_norm": 0.00014515488874167204,
      "learning_rate": 3.834833547649665e-06,
      "loss": 0.0,
      "step": 56570
    },
    {
      "epoch": 12.126018002571795,
      "grad_norm": 0.0011499581160023808,
      "learning_rate": 3.831975996570939e-06,
      "loss": 0.0004,
      "step": 56580
    },
    {
      "epoch": 12.12816116588084,
      "grad_norm": 1.8309568986296654e-05,
      "learning_rate": 3.829118445492214e-06,
      "loss": 0.0,
      "step": 56590
    },
    {
      "epoch": 12.130304329189885,
      "grad_norm": 2.719254007388372e-05,
      "learning_rate": 3.8262608944134875e-06,
      "loss": 0.0,
      "step": 56600
    },
    {
      "epoch": 12.132447492498928,
      "grad_norm": 3.171543721691705e-05,
      "learning_rate": 3.823403343334762e-06,
      "loss": 0.0,
      "step": 56610
    },
    {
      "epoch": 12.134590655807973,
      "grad_norm": 0.2548191249370575,
      "learning_rate": 3.820545792256037e-06,
      "loss": 0.0004,
      "step": 56620
    },
    {
      "epoch": 12.136733819117017,
      "grad_norm": 3.449486393947154e-05,
      "learning_rate": 3.817688241177311e-06,
      "loss": 0.0009,
      "step": 56630
    },
    {
      "epoch": 12.13887698242606,
      "grad_norm": 0.0006300221430137753,
      "learning_rate": 3.814830690098586e-06,
      "loss": 0.0,
      "step": 56640
    },
    {
      "epoch": 12.141020145735105,
      "grad_norm": 5.173409954295494e-05,
      "learning_rate": 3.8119731390198606e-06,
      "loss": 0.0,
      "step": 56650
    },
    {
      "epoch": 12.14316330904415,
      "grad_norm": 1.7925312931765802e-05,
      "learning_rate": 3.8091155879411345e-06,
      "loss": 0.0,
      "step": 56660
    },
    {
      "epoch": 12.145306472353193,
      "grad_norm": 7.994756742846221e-05,
      "learning_rate": 3.8062580368624093e-06,
      "loss": 0.0,
      "step": 56670
    },
    {
      "epoch": 12.147449635662237,
      "grad_norm": 3.238877252442762e-05,
      "learning_rate": 3.8034004857836836e-06,
      "loss": 0.0,
      "step": 56680
    },
    {
      "epoch": 12.149592798971282,
      "grad_norm": 2.767630576272495e-05,
      "learning_rate": 3.8005429347049584e-06,
      "loss": 0.0,
      "step": 56690
    },
    {
      "epoch": 12.151735962280325,
      "grad_norm": 1.9116732801194303e-05,
      "learning_rate": 3.7976853836262327e-06,
      "loss": 0.0,
      "step": 56700
    },
    {
      "epoch": 12.15387912558937,
      "grad_norm": 2.6537702069617808e-05,
      "learning_rate": 3.7948278325475067e-06,
      "loss": 0.0,
      "step": 56710
    },
    {
      "epoch": 12.156022288898415,
      "grad_norm": 2.964775740110781e-05,
      "learning_rate": 3.7919702814687814e-06,
      "loss": 0.0,
      "step": 56720
    },
    {
      "epoch": 12.158165452207458,
      "grad_norm": 6.902182212797925e-05,
      "learning_rate": 3.7891127303900562e-06,
      "loss": 0.0,
      "step": 56730
    },
    {
      "epoch": 12.160308615516502,
      "grad_norm": 0.00012046206393279135,
      "learning_rate": 3.7862551793113306e-06,
      "loss": 0.0,
      "step": 56740
    },
    {
      "epoch": 12.162451778825547,
      "grad_norm": 2.2431697288993746e-05,
      "learning_rate": 3.7833976282326053e-06,
      "loss": 0.0,
      "step": 56750
    },
    {
      "epoch": 12.16459494213459,
      "grad_norm": 3.7045385397505015e-05,
      "learning_rate": 3.7805400771538793e-06,
      "loss": 0.2271,
      "step": 56760
    },
    {
      "epoch": 12.166738105443635,
      "grad_norm": 0.18164774775505066,
      "learning_rate": 3.7776825260751536e-06,
      "loss": 0.0002,
      "step": 56770
    },
    {
      "epoch": 12.16888126875268,
      "grad_norm": 4.191861444269307e-05,
      "learning_rate": 3.7748249749964284e-06,
      "loss": 0.0,
      "step": 56780
    },
    {
      "epoch": 12.171024432061722,
      "grad_norm": 0.00011908887245226651,
      "learning_rate": 3.7719674239177027e-06,
      "loss": 0.0,
      "step": 56790
    },
    {
      "epoch": 12.173167595370767,
      "grad_norm": 5.450202661450021e-05,
      "learning_rate": 3.7691098728389775e-06,
      "loss": 0.0,
      "step": 56800
    },
    {
      "epoch": 12.175310758679812,
      "grad_norm": 3.796589226112701e-05,
      "learning_rate": 3.766252321760252e-06,
      "loss": 0.0,
      "step": 56810
    },
    {
      "epoch": 12.177453921988855,
      "grad_norm": 7.051674037938938e-05,
      "learning_rate": 3.7633947706815262e-06,
      "loss": 0.0,
      "step": 56820
    },
    {
      "epoch": 12.1795970852979,
      "grad_norm": 4.0251718019135296e-05,
      "learning_rate": 3.7605372196028006e-06,
      "loss": 0.0,
      "step": 56830
    },
    {
      "epoch": 12.181740248606944,
      "grad_norm": 0.00010855371510842815,
      "learning_rate": 3.7576796685240754e-06,
      "loss": 0.0,
      "step": 56840
    },
    {
      "epoch": 12.183883411915987,
      "grad_norm": 8.505654113832861e-05,
      "learning_rate": 3.7548221174453497e-06,
      "loss": 0.0,
      "step": 56850
    },
    {
      "epoch": 12.186026575225032,
      "grad_norm": 5.012344990973361e-05,
      "learning_rate": 3.7519645663666245e-06,
      "loss": 0.0,
      "step": 56860
    },
    {
      "epoch": 12.188169738534077,
      "grad_norm": 0.00015318307850975543,
      "learning_rate": 3.7491070152878984e-06,
      "loss": 0.0007,
      "step": 56870
    },
    {
      "epoch": 12.19031290184312,
      "grad_norm": 0.6210632920265198,
      "learning_rate": 3.7462494642091728e-06,
      "loss": 0.0003,
      "step": 56880
    },
    {
      "epoch": 12.192456065152165,
      "grad_norm": 4.9773876526160166e-05,
      "learning_rate": 3.7433919131304475e-06,
      "loss": 0.0,
      "step": 56890
    },
    {
      "epoch": 12.19459922846121,
      "grad_norm": 0.027636129409074783,
      "learning_rate": 3.740534362051722e-06,
      "loss": 0.0,
      "step": 56900
    },
    {
      "epoch": 12.196742391770252,
      "grad_norm": 3.0557075660908595e-05,
      "learning_rate": 3.7376768109729967e-06,
      "loss": 0.0023,
      "step": 56910
    },
    {
      "epoch": 12.198885555079297,
      "grad_norm": 2.871106335078366e-05,
      "learning_rate": 3.734819259894271e-06,
      "loss": 0.1825,
      "step": 56920
    },
    {
      "epoch": 12.201028718388342,
      "grad_norm": 1.7629305148147978e-05,
      "learning_rate": 3.7319617088155454e-06,
      "loss": 0.0,
      "step": 56930
    },
    {
      "epoch": 12.203171881697385,
      "grad_norm": 2.780238719424233e-05,
      "learning_rate": 3.7291041577368197e-06,
      "loss": 0.0,
      "step": 56940
    },
    {
      "epoch": 12.20531504500643,
      "grad_norm": 0.01426366064697504,
      "learning_rate": 3.7262466066580945e-06,
      "loss": 0.0,
      "step": 56950
    },
    {
      "epoch": 12.207458208315474,
      "grad_norm": 6.858850974822417e-05,
      "learning_rate": 3.723389055579369e-06,
      "loss": 0.0,
      "step": 56960
    },
    {
      "epoch": 12.209601371624517,
      "grad_norm": 0.00028109594131819904,
      "learning_rate": 3.7205315045006436e-06,
      "loss": 0.0,
      "step": 56970
    },
    {
      "epoch": 12.211744534933562,
      "grad_norm": 0.0001016909591271542,
      "learning_rate": 3.7176739534219175e-06,
      "loss": 0.0,
      "step": 56980
    },
    {
      "epoch": 12.213887698242607,
      "grad_norm": 2.114012386300601e-05,
      "learning_rate": 3.714816402343192e-06,
      "loss": 0.0,
      "step": 56990
    },
    {
      "epoch": 12.21603086155165,
      "grad_norm": 6.923850014572963e-05,
      "learning_rate": 3.7119588512644667e-06,
      "loss": 0.0,
      "step": 57000
    },
    {
      "epoch": 12.218174024860694,
      "grad_norm": 2.2712434656568803e-05,
      "learning_rate": 3.709101300185741e-06,
      "loss": 0.0,
      "step": 57010
    },
    {
      "epoch": 12.220317188169739,
      "grad_norm": 5.4269690735964105e-05,
      "learning_rate": 3.706243749107016e-06,
      "loss": 0.0,
      "step": 57020
    },
    {
      "epoch": 12.222460351478782,
      "grad_norm": 2.374576433794573e-05,
      "learning_rate": 3.7033861980282897e-06,
      "loss": 0.1132,
      "step": 57030
    },
    {
      "epoch": 12.224603514787827,
      "grad_norm": 3.575768641894683e-05,
      "learning_rate": 3.7005286469495645e-06,
      "loss": 0.0,
      "step": 57040
    },
    {
      "epoch": 12.226746678096871,
      "grad_norm": 2.0010993466712534e-05,
      "learning_rate": 3.697671095870839e-06,
      "loss": 0.0,
      "step": 57050
    },
    {
      "epoch": 12.228889841405914,
      "grad_norm": 2.095028685289435e-05,
      "learning_rate": 3.6948135447921136e-06,
      "loss": 0.0,
      "step": 57060
    },
    {
      "epoch": 12.23103300471496,
      "grad_norm": 0.007418245542794466,
      "learning_rate": 3.691955993713388e-06,
      "loss": 0.1042,
      "step": 57070
    },
    {
      "epoch": 12.233176168024004,
      "grad_norm": 0.0004489501880016178,
      "learning_rate": 3.6890984426346628e-06,
      "loss": 0.0,
      "step": 57080
    },
    {
      "epoch": 12.235319331333047,
      "grad_norm": 3.112834019702859e-05,
      "learning_rate": 3.6862408915559367e-06,
      "loss": 0.0,
      "step": 57090
    },
    {
      "epoch": 12.237462494642092,
      "grad_norm": 1.922037517942954e-05,
      "learning_rate": 3.683383340477211e-06,
      "loss": 0.0001,
      "step": 57100
    },
    {
      "epoch": 12.239605657951136,
      "grad_norm": 1.8070284568239003e-05,
      "learning_rate": 3.680525789398486e-06,
      "loss": 0.0014,
      "step": 57110
    },
    {
      "epoch": 12.24174882126018,
      "grad_norm": 0.38954171538352966,
      "learning_rate": 3.6776682383197606e-06,
      "loss": 0.0008,
      "step": 57120
    },
    {
      "epoch": 12.243891984569224,
      "grad_norm": 2.416355891909916e-05,
      "learning_rate": 3.674810687241035e-06,
      "loss": 0.0,
      "step": 57130
    },
    {
      "epoch": 12.246035147878269,
      "grad_norm": 8.454603084828705e-05,
      "learning_rate": 3.671953136162309e-06,
      "loss": 0.121,
      "step": 57140
    },
    {
      "epoch": 12.248178311187312,
      "grad_norm": 0.0015684867976233363,
      "learning_rate": 3.6690955850835836e-06,
      "loss": 0.1052,
      "step": 57150
    },
    {
      "epoch": 12.250321474496356,
      "grad_norm": 2.7339687221683562e-05,
      "learning_rate": 3.666238034004858e-06,
      "loss": 0.0,
      "step": 57160
    },
    {
      "epoch": 12.252464637805401,
      "grad_norm": 2.1212117644608952e-05,
      "learning_rate": 3.6633804829261328e-06,
      "loss": 0.0,
      "step": 57170
    },
    {
      "epoch": 12.254607801114444,
      "grad_norm": 2.114441667799838e-05,
      "learning_rate": 3.660522931847407e-06,
      "loss": 0.0,
      "step": 57180
    },
    {
      "epoch": 12.256750964423489,
      "grad_norm": 0.46113723516464233,
      "learning_rate": 3.6576653807686815e-06,
      "loss": 0.0008,
      "step": 57190
    },
    {
      "epoch": 12.258894127732534,
      "grad_norm": 2.369885078223888e-05,
      "learning_rate": 3.654807829689956e-06,
      "loss": 0.0008,
      "step": 57200
    },
    {
      "epoch": 12.261037291041577,
      "grad_norm": 8.613074896857142e-05,
      "learning_rate": 3.6519502786112306e-06,
      "loss": 0.0019,
      "step": 57210
    },
    {
      "epoch": 12.263180454350621,
      "grad_norm": 2.506667806301266e-05,
      "learning_rate": 3.649092727532505e-06,
      "loss": 0.0,
      "step": 57220
    },
    {
      "epoch": 12.265323617659666,
      "grad_norm": 1.2478611097321846e-05,
      "learning_rate": 3.6462351764537797e-06,
      "loss": 0.0026,
      "step": 57230
    },
    {
      "epoch": 12.267466780968709,
      "grad_norm": 1.6064259398262948e-05,
      "learning_rate": 3.643377625375054e-06,
      "loss": 0.0008,
      "step": 57240
    },
    {
      "epoch": 12.269609944277754,
      "grad_norm": 5.311742643243633e-05,
      "learning_rate": 3.640520074296328e-06,
      "loss": 0.0,
      "step": 57250
    },
    {
      "epoch": 12.271753107586798,
      "grad_norm": 1.9909102775272913e-05,
      "learning_rate": 3.6376625232176028e-06,
      "loss": 0.0,
      "step": 57260
    },
    {
      "epoch": 12.273896270895841,
      "grad_norm": 1.2044250979670323e-05,
      "learning_rate": 3.634804972138877e-06,
      "loss": 0.0,
      "step": 57270
    },
    {
      "epoch": 12.276039434204886,
      "grad_norm": 8.352816075785086e-05,
      "learning_rate": 3.631947421060152e-06,
      "loss": 0.0006,
      "step": 57280
    },
    {
      "epoch": 12.278182597513931,
      "grad_norm": 1.6374915503547527e-05,
      "learning_rate": 3.6290898699814263e-06,
      "loss": 0.0,
      "step": 57290
    },
    {
      "epoch": 12.280325760822974,
      "grad_norm": 3.563610152923502e-05,
      "learning_rate": 3.6262323189027006e-06,
      "loss": 0.0015,
      "step": 57300
    },
    {
      "epoch": 12.282468924132019,
      "grad_norm": 1.8217939214082435e-05,
      "learning_rate": 3.623374767823975e-06,
      "loss": 0.0002,
      "step": 57310
    },
    {
      "epoch": 12.284612087441063,
      "grad_norm": 0.0001597794034751132,
      "learning_rate": 3.6205172167452497e-06,
      "loss": 0.0,
      "step": 57320
    },
    {
      "epoch": 12.286755250750106,
      "grad_norm": 0.07138971239328384,
      "learning_rate": 3.617659665666524e-06,
      "loss": 0.0004,
      "step": 57330
    },
    {
      "epoch": 12.288898414059151,
      "grad_norm": 1.5193853869277518e-05,
      "learning_rate": 3.614802114587799e-06,
      "loss": 0.0,
      "step": 57340
    },
    {
      "epoch": 12.291041577368196,
      "grad_norm": 1.1022163562302012e-05,
      "learning_rate": 3.611944563509073e-06,
      "loss": 0.0,
      "step": 57350
    },
    {
      "epoch": 12.293184740677239,
      "grad_norm": 1.4534115507558454e-05,
      "learning_rate": 3.609087012430347e-06,
      "loss": 0.0,
      "step": 57360
    },
    {
      "epoch": 12.295327903986284,
      "grad_norm": 1.2042465641570743e-05,
      "learning_rate": 3.606229461351622e-06,
      "loss": 0.0,
      "step": 57370
    },
    {
      "epoch": 12.297471067295328,
      "grad_norm": 1.1888036169693805e-05,
      "learning_rate": 3.6033719102728963e-06,
      "loss": 0.0,
      "step": 57380
    },
    {
      "epoch": 12.299614230604371,
      "grad_norm": 1.5053639799589291e-05,
      "learning_rate": 3.600514359194171e-06,
      "loss": 0.0,
      "step": 57390
    },
    {
      "epoch": 12.301757393913416,
      "grad_norm": 3.4441760362824425e-05,
      "learning_rate": 3.5976568081154454e-06,
      "loss": 0.0,
      "step": 57400
    },
    {
      "epoch": 12.30390055722246,
      "grad_norm": 9.943828445102554e-06,
      "learning_rate": 3.5947992570367198e-06,
      "loss": 0.0,
      "step": 57410
    },
    {
      "epoch": 12.306043720531505,
      "grad_norm": 2.2702834030496888e-05,
      "learning_rate": 3.591941705957994e-06,
      "loss": 0.0005,
      "step": 57420
    },
    {
      "epoch": 12.308186883840548,
      "grad_norm": 1.3467774806485977e-05,
      "learning_rate": 3.589084154879269e-06,
      "loss": 0.0,
      "step": 57430
    },
    {
      "epoch": 12.310330047149593,
      "grad_norm": 1.1418089343351312e-05,
      "learning_rate": 3.5862266038005432e-06,
      "loss": 0.0,
      "step": 57440
    },
    {
      "epoch": 12.312473210458638,
      "grad_norm": 1.0064431080536451e-05,
      "learning_rate": 3.583369052721818e-06,
      "loss": 0.0,
      "step": 57450
    },
    {
      "epoch": 12.31461637376768,
      "grad_norm": 5.5209653510246426e-05,
      "learning_rate": 3.580511501643092e-06,
      "loss": 0.0,
      "step": 57460
    },
    {
      "epoch": 12.316759537076726,
      "grad_norm": 1.7903532352647744e-05,
      "learning_rate": 3.5776539505643663e-06,
      "loss": 0.0,
      "step": 57470
    },
    {
      "epoch": 12.31890270038577,
      "grad_norm": 9.312732800026424e-06,
      "learning_rate": 3.574796399485641e-06,
      "loss": 0.0,
      "step": 57480
    },
    {
      "epoch": 12.321045863694813,
      "grad_norm": 2.0322844648035243e-05,
      "learning_rate": 3.5719388484069154e-06,
      "loss": 0.0,
      "step": 57490
    },
    {
      "epoch": 12.323189027003858,
      "grad_norm": 9.47771877690684e-06,
      "learning_rate": 3.56908129732819e-06,
      "loss": 0.0,
      "step": 57500
    },
    {
      "epoch": 12.325332190312903,
      "grad_norm": 3.220370854251087e-05,
      "learning_rate": 3.566223746249465e-06,
      "loss": 0.0,
      "step": 57510
    },
    {
      "epoch": 12.327475353621946,
      "grad_norm": 3.078324152738787e-05,
      "learning_rate": 3.563366195170739e-06,
      "loss": 0.0,
      "step": 57520
    },
    {
      "epoch": 12.32961851693099,
      "grad_norm": 0.000982877449132502,
      "learning_rate": 3.5605086440920133e-06,
      "loss": 0.0,
      "step": 57530
    },
    {
      "epoch": 12.331761680240035,
      "grad_norm": 1.1482678019092418e-05,
      "learning_rate": 3.557651093013288e-06,
      "loss": 0.0,
      "step": 57540
    },
    {
      "epoch": 12.333904843549078,
      "grad_norm": 1.1681540854624473e-05,
      "learning_rate": 3.5547935419345624e-06,
      "loss": 0.0,
      "step": 57550
    },
    {
      "epoch": 12.336048006858123,
      "grad_norm": 1.2239923307788558e-05,
      "learning_rate": 3.551935990855837e-06,
      "loss": 0.0,
      "step": 57560
    },
    {
      "epoch": 12.338191170167168,
      "grad_norm": 0.0002099026896758005,
      "learning_rate": 3.549078439777111e-06,
      "loss": 0.1371,
      "step": 57570
    },
    {
      "epoch": 12.34033433347621,
      "grad_norm": 1.3704647244594526e-05,
      "learning_rate": 3.546220888698386e-06,
      "loss": 0.0001,
      "step": 57580
    },
    {
      "epoch": 12.342477496785255,
      "grad_norm": 1.128872736444464e-05,
      "learning_rate": 3.54336333761966e-06,
      "loss": 0.0,
      "step": 57590
    },
    {
      "epoch": 12.3446206600943,
      "grad_norm": 1.1768125659727957e-05,
      "learning_rate": 3.540505786540935e-06,
      "loss": 0.0,
      "step": 57600
    },
    {
      "epoch": 12.346763823403343,
      "grad_norm": 1.2608400583267212,
      "learning_rate": 3.5376482354622093e-06,
      "loss": 0.0009,
      "step": 57610
    },
    {
      "epoch": 12.348906986712388,
      "grad_norm": 1.1636964700301178e-05,
      "learning_rate": 3.5347906843834833e-06,
      "loss": 0.0002,
      "step": 57620
    },
    {
      "epoch": 12.351050150021432,
      "grad_norm": 9.20652655622689e-06,
      "learning_rate": 3.531933133304758e-06,
      "loss": 0.0,
      "step": 57630
    },
    {
      "epoch": 12.353193313330475,
      "grad_norm": 1.0410827599116601e-05,
      "learning_rate": 3.5290755822260324e-06,
      "loss": 0.0,
      "step": 57640
    },
    {
      "epoch": 12.35533647663952,
      "grad_norm": 1.4116396414465271e-05,
      "learning_rate": 3.526218031147307e-06,
      "loss": 0.0,
      "step": 57650
    },
    {
      "epoch": 12.357479639948565,
      "grad_norm": 1.1041121069865767e-05,
      "learning_rate": 3.5233604800685815e-06,
      "loss": 0.0,
      "step": 57660
    },
    {
      "epoch": 12.359622803257608,
      "grad_norm": 1.1441360584285576e-05,
      "learning_rate": 3.5205029289898563e-06,
      "loss": 0.0,
      "step": 57670
    },
    {
      "epoch": 12.361765966566653,
      "grad_norm": 1.1596183867368381e-05,
      "learning_rate": 3.5176453779111302e-06,
      "loss": 0.0,
      "step": 57680
    },
    {
      "epoch": 12.363909129875697,
      "grad_norm": 0.006430984009057283,
      "learning_rate": 3.514787826832405e-06,
      "loss": 0.0,
      "step": 57690
    },
    {
      "epoch": 12.36605229318474,
      "grad_norm": 5.658030931954272e-05,
      "learning_rate": 3.5119302757536793e-06,
      "loss": 0.0,
      "step": 57700
    },
    {
      "epoch": 12.368195456493785,
      "grad_norm": 1.1128207006549928e-05,
      "learning_rate": 3.509072724674954e-06,
      "loss": 0.0,
      "step": 57710
    },
    {
      "epoch": 12.37033861980283,
      "grad_norm": 1.0018968168878928e-05,
      "learning_rate": 3.5062151735962285e-06,
      "loss": 0.0,
      "step": 57720
    },
    {
      "epoch": 12.372481783111873,
      "grad_norm": 1.5517132851528004e-05,
      "learning_rate": 3.5033576225175024e-06,
      "loss": 0.0,
      "step": 57730
    },
    {
      "epoch": 12.374624946420917,
      "grad_norm": 1.1382764569134451e-05,
      "learning_rate": 3.500500071438777e-06,
      "loss": 0.1108,
      "step": 57740
    },
    {
      "epoch": 12.376768109729962,
      "grad_norm": 1.3562697859015316e-05,
      "learning_rate": 3.4976425203600515e-06,
      "loss": 0.0,
      "step": 57750
    },
    {
      "epoch": 12.378911273039005,
      "grad_norm": 9.970550308935344e-06,
      "learning_rate": 3.4947849692813263e-06,
      "loss": 0.0,
      "step": 57760
    },
    {
      "epoch": 12.38105443634805,
      "grad_norm": 1.2293267900531646e-05,
      "learning_rate": 3.4919274182026007e-06,
      "loss": 0.0,
      "step": 57770
    },
    {
      "epoch": 12.383197599657095,
      "grad_norm": 9.817932550504338e-06,
      "learning_rate": 3.489069867123875e-06,
      "loss": 0.0,
      "step": 57780
    },
    {
      "epoch": 12.385340762966138,
      "grad_norm": 20.914621353149414,
      "learning_rate": 3.4862123160451494e-06,
      "loss": 0.1513,
      "step": 57790
    },
    {
      "epoch": 12.387483926275182,
      "grad_norm": 1.3141684576112311e-05,
      "learning_rate": 3.483354764966424e-06,
      "loss": 0.0,
      "step": 57800
    },
    {
      "epoch": 12.389627089584227,
      "grad_norm": 1.421102751919534e-05,
      "learning_rate": 3.4804972138876985e-06,
      "loss": 0.0,
      "step": 57810
    },
    {
      "epoch": 12.39177025289327,
      "grad_norm": 1.931004590005614e-05,
      "learning_rate": 3.4776396628089733e-06,
      "loss": 0.0,
      "step": 57820
    },
    {
      "epoch": 12.393913416202315,
      "grad_norm": 0.2917056381702423,
      "learning_rate": 3.4747821117302476e-06,
      "loss": 0.0004,
      "step": 57830
    },
    {
      "epoch": 12.39605657951136,
      "grad_norm": 0.4397450387477875,
      "learning_rate": 3.4719245606515215e-06,
      "loss": 0.0006,
      "step": 57840
    },
    {
      "epoch": 12.398199742820402,
      "grad_norm": 1.4283903510659002e-05,
      "learning_rate": 3.4690670095727963e-06,
      "loss": 0.0,
      "step": 57850
    },
    {
      "epoch": 12.400342906129447,
      "grad_norm": 1.1439339687058236e-05,
      "learning_rate": 3.4662094584940707e-06,
      "loss": 0.0,
      "step": 57860
    },
    {
      "epoch": 12.402486069438492,
      "grad_norm": 1.9691560737555847e-05,
      "learning_rate": 3.4633519074153454e-06,
      "loss": 0.0,
      "step": 57870
    },
    {
      "epoch": 12.404629232747535,
      "grad_norm": 1.3445891454466619e-05,
      "learning_rate": 3.46049435633662e-06,
      "loss": 0.0,
      "step": 57880
    },
    {
      "epoch": 12.40677239605658,
      "grad_norm": 1.4203437785909045e-05,
      "learning_rate": 3.457636805257894e-06,
      "loss": 0.1611,
      "step": 57890
    },
    {
      "epoch": 12.408915559365624,
      "grad_norm": 1.4808966625423636e-05,
      "learning_rate": 3.4547792541791685e-06,
      "loss": 0.0,
      "step": 57900
    },
    {
      "epoch": 12.411058722674667,
      "grad_norm": 6.374716758728027e-05,
      "learning_rate": 3.4519217031004433e-06,
      "loss": 0.0,
      "step": 57910
    },
    {
      "epoch": 12.413201885983712,
      "grad_norm": 4.608909512171522e-05,
      "learning_rate": 3.4490641520217176e-06,
      "loss": 0.0,
      "step": 57920
    },
    {
      "epoch": 12.415345049292757,
      "grad_norm": 1.41813561640447e-05,
      "learning_rate": 3.4462066009429924e-06,
      "loss": 0.0,
      "step": 57930
    },
    {
      "epoch": 12.4174882126018,
      "grad_norm": 4.065293614985421e-05,
      "learning_rate": 3.4433490498642668e-06,
      "loss": 0.0,
      "step": 57940
    },
    {
      "epoch": 12.419631375910845,
      "grad_norm": 6.403692532330751e-05,
      "learning_rate": 3.4404914987855407e-06,
      "loss": 0.103,
      "step": 57950
    },
    {
      "epoch": 12.42177453921989,
      "grad_norm": 1.4095246115175541e-05,
      "learning_rate": 3.4376339477068155e-06,
      "loss": 0.0025,
      "step": 57960
    },
    {
      "epoch": 12.423917702528932,
      "grad_norm": 1.6058911569416523e-05,
      "learning_rate": 3.4347763966280902e-06,
      "loss": 0.0,
      "step": 57970
    },
    {
      "epoch": 12.426060865837977,
      "grad_norm": 1.633313877391629e-05,
      "learning_rate": 3.4319188455493646e-06,
      "loss": 0.0003,
      "step": 57980
    },
    {
      "epoch": 12.428204029147022,
      "grad_norm": 6.903237226651981e-05,
      "learning_rate": 3.4290612944706394e-06,
      "loss": 0.0,
      "step": 57990
    },
    {
      "epoch": 12.430347192456065,
      "grad_norm": 1.3296579709276557e-05,
      "learning_rate": 3.4262037433919133e-06,
      "loss": 0.0,
      "step": 58000
    },
    {
      "epoch": 12.43249035576511,
      "grad_norm": 4.6413089876296e-05,
      "learning_rate": 3.4233461923131876e-06,
      "loss": 0.0,
      "step": 58010
    },
    {
      "epoch": 12.434633519074154,
      "grad_norm": 1.8502052625990473e-05,
      "learning_rate": 3.4204886412344624e-06,
      "loss": 0.0,
      "step": 58020
    },
    {
      "epoch": 12.436776682383197,
      "grad_norm": 4.4424563384382054e-05,
      "learning_rate": 3.4176310901557368e-06,
      "loss": 0.0,
      "step": 58030
    },
    {
      "epoch": 12.438919845692242,
      "grad_norm": 9.259267244488001e-05,
      "learning_rate": 3.4147735390770115e-06,
      "loss": 0.3667,
      "step": 58040
    },
    {
      "epoch": 12.441063009001287,
      "grad_norm": 1.7224481780431233e-05,
      "learning_rate": 3.4119159879982855e-06,
      "loss": 0.0,
      "step": 58050
    },
    {
      "epoch": 12.44320617231033,
      "grad_norm": 2.204351403634064e-05,
      "learning_rate": 3.4090584369195602e-06,
      "loss": 0.0,
      "step": 58060
    },
    {
      "epoch": 12.445349335619374,
      "grad_norm": 0.00013119439245201647,
      "learning_rate": 3.4062008858408346e-06,
      "loss": 0.0011,
      "step": 58070
    },
    {
      "epoch": 12.447492498928419,
      "grad_norm": 1.6599959053564817e-05,
      "learning_rate": 3.4033433347621094e-06,
      "loss": 0.0,
      "step": 58080
    },
    {
      "epoch": 12.449635662237462,
      "grad_norm": 0.00037862409953959286,
      "learning_rate": 3.4004857836833837e-06,
      "loss": 0.0,
      "step": 58090
    },
    {
      "epoch": 12.451778825546507,
      "grad_norm": 1.928176607179921e-05,
      "learning_rate": 3.3976282326046585e-06,
      "loss": 0.0,
      "step": 58100
    },
    {
      "epoch": 12.453921988855551,
      "grad_norm": 2.017911356233526e-05,
      "learning_rate": 3.3947706815259324e-06,
      "loss": 0.0,
      "step": 58110
    },
    {
      "epoch": 12.456065152164594,
      "grad_norm": 5.9752564993686974e-05,
      "learning_rate": 3.3919131304472068e-06,
      "loss": 0.1644,
      "step": 58120
    },
    {
      "epoch": 12.45820831547364,
      "grad_norm": 0.00016691438213456422,
      "learning_rate": 3.3890555793684816e-06,
      "loss": 0.0001,
      "step": 58130
    },
    {
      "epoch": 12.460351478782684,
      "grad_norm": 7.96383319539018e-05,
      "learning_rate": 3.386198028289756e-06,
      "loss": 0.0,
      "step": 58140
    },
    {
      "epoch": 12.462494642091727,
      "grad_norm": 2.4036638933466747e-05,
      "learning_rate": 3.3833404772110307e-06,
      "loss": 0.0,
      "step": 58150
    },
    {
      "epoch": 12.464637805400772,
      "grad_norm": 1.4395823200175073e-05,
      "learning_rate": 3.3804829261323046e-06,
      "loss": 0.0,
      "step": 58160
    },
    {
      "epoch": 12.466780968709816,
      "grad_norm": 0.00011128641926916316,
      "learning_rate": 3.3776253750535794e-06,
      "loss": 0.0,
      "step": 58170
    },
    {
      "epoch": 12.46892413201886,
      "grad_norm": 1.4136906429484952e-05,
      "learning_rate": 3.3747678239748537e-06,
      "loss": 0.0,
      "step": 58180
    },
    {
      "epoch": 12.471067295327904,
      "grad_norm": 2.0758572645718232e-05,
      "learning_rate": 3.3719102728961285e-06,
      "loss": 0.0,
      "step": 58190
    },
    {
      "epoch": 12.473210458636949,
      "grad_norm": 1.8977614672621712e-05,
      "learning_rate": 3.369052721817403e-06,
      "loss": 0.0,
      "step": 58200
    },
    {
      "epoch": 12.475353621945992,
      "grad_norm": 1.799135498004034e-05,
      "learning_rate": 3.366195170738677e-06,
      "loss": 0.0001,
      "step": 58210
    },
    {
      "epoch": 12.477496785255036,
      "grad_norm": 9.886426414595917e-05,
      "learning_rate": 3.3633376196599516e-06,
      "loss": 0.0,
      "step": 58220
    },
    {
      "epoch": 12.479639948564081,
      "grad_norm": 5.5062337196432054e-05,
      "learning_rate": 3.360480068581226e-06,
      "loss": 0.0,
      "step": 58230
    },
    {
      "epoch": 12.481783111873124,
      "grad_norm": 1.3267898793856148e-05,
      "learning_rate": 3.3576225175025007e-06,
      "loss": 0.0014,
      "step": 58240
    },
    {
      "epoch": 12.483926275182169,
      "grad_norm": 5.603126919595525e-05,
      "learning_rate": 3.354764966423775e-06,
      "loss": 0.0,
      "step": 58250
    },
    {
      "epoch": 12.486069438491214,
      "grad_norm": 1.5607902241754346e-05,
      "learning_rate": 3.35190741534505e-06,
      "loss": 0.0,
      "step": 58260
    },
    {
      "epoch": 12.488212601800257,
      "grad_norm": 7.058464689180255e-05,
      "learning_rate": 3.3490498642663238e-06,
      "loss": 0.0,
      "step": 58270
    },
    {
      "epoch": 12.490355765109301,
      "grad_norm": 1.6536894690943882e-05,
      "learning_rate": 3.3461923131875985e-06,
      "loss": 0.0,
      "step": 58280
    },
    {
      "epoch": 12.492498928418346,
      "grad_norm": 1.690051612968091e-05,
      "learning_rate": 3.343334762108873e-06,
      "loss": 0.0972,
      "step": 58290
    },
    {
      "epoch": 12.494642091727389,
      "grad_norm": 1.1785014066845179e-05,
      "learning_rate": 3.3404772110301477e-06,
      "loss": 0.0,
      "step": 58300
    },
    {
      "epoch": 12.496785255036434,
      "grad_norm": 0.00020464422414079309,
      "learning_rate": 3.337619659951422e-06,
      "loss": 0.0,
      "step": 58310
    },
    {
      "epoch": 12.498928418345479,
      "grad_norm": 1.1638305295491591e-05,
      "learning_rate": 3.334762108872696e-06,
      "loss": 0.0,
      "step": 58320
    },
    {
      "epoch": 12.501071581654521,
      "grad_norm": 0.00014432253374252468,
      "learning_rate": 3.3319045577939707e-06,
      "loss": 0.0,
      "step": 58330
    },
    {
      "epoch": 12.503214744963566,
      "grad_norm": 1.2244236131664366e-05,
      "learning_rate": 3.3290470067152455e-06,
      "loss": 0.0,
      "step": 58340
    },
    {
      "epoch": 12.505357908272611,
      "grad_norm": 1.9322749722050503e-05,
      "learning_rate": 3.32618945563652e-06,
      "loss": 0.0014,
      "step": 58350
    },
    {
      "epoch": 12.507501071581654,
      "grad_norm": 1.8819087927113287e-05,
      "learning_rate": 3.3233319045577946e-06,
      "loss": 0.0,
      "step": 58360
    },
    {
      "epoch": 12.509644234890699,
      "grad_norm": 9.319996024714783e-05,
      "learning_rate": 3.3204743534790685e-06,
      "loss": 0.0,
      "step": 58370
    },
    {
      "epoch": 12.511787398199743,
      "grad_norm": 0.00019302053260616958,
      "learning_rate": 3.317616802400343e-06,
      "loss": 0.0,
      "step": 58380
    },
    {
      "epoch": 12.513930561508786,
      "grad_norm": 1.3075183233013377e-05,
      "learning_rate": 3.3147592513216177e-06,
      "loss": 0.0,
      "step": 58390
    },
    {
      "epoch": 12.516073724817831,
      "grad_norm": 1.0511921573197469e-05,
      "learning_rate": 3.311901700242892e-06,
      "loss": 0.0,
      "step": 58400
    },
    {
      "epoch": 12.518216888126876,
      "grad_norm": 2.0953966668457724e-05,
      "learning_rate": 3.309044149164167e-06,
      "loss": 0.0,
      "step": 58410
    },
    {
      "epoch": 12.520360051435919,
      "grad_norm": 0.00030570896342396736,
      "learning_rate": 3.306186598085441e-06,
      "loss": 0.0,
      "step": 58420
    },
    {
      "epoch": 12.522503214744964,
      "grad_norm": 0.00012734656047541648,
      "learning_rate": 3.3033290470067155e-06,
      "loss": 0.0009,
      "step": 58430
    },
    {
      "epoch": 12.524646378054008,
      "grad_norm": 8.548538608010858e-05,
      "learning_rate": 3.30047149592799e-06,
      "loss": 0.0,
      "step": 58440
    },
    {
      "epoch": 12.526789541363051,
      "grad_norm": 1.115677605412202e-05,
      "learning_rate": 3.2976139448492646e-06,
      "loss": 0.0,
      "step": 58450
    },
    {
      "epoch": 12.528932704672096,
      "grad_norm": 1.1122518117190339e-05,
      "learning_rate": 3.294756393770539e-06,
      "loss": 0.0,
      "step": 58460
    },
    {
      "epoch": 12.53107586798114,
      "grad_norm": 2.1887879483983852e-05,
      "learning_rate": 3.2918988426918138e-06,
      "loss": 0.0,
      "step": 58470
    },
    {
      "epoch": 12.533219031290184,
      "grad_norm": 1.4739322978130076e-05,
      "learning_rate": 3.2890412916130877e-06,
      "loss": 0.0,
      "step": 58480
    },
    {
      "epoch": 12.535362194599228,
      "grad_norm": 0.00012470348156057298,
      "learning_rate": 3.286183740534362e-06,
      "loss": 0.0,
      "step": 58490
    },
    {
      "epoch": 12.537505357908273,
      "grad_norm": 1.2148798305133823e-05,
      "learning_rate": 3.283326189455637e-06,
      "loss": 0.0,
      "step": 58500
    },
    {
      "epoch": 12.539648521217316,
      "grad_norm": 8.471492765238509e-05,
      "learning_rate": 3.280468638376911e-06,
      "loss": 0.0,
      "step": 58510
    },
    {
      "epoch": 12.54179168452636,
      "grad_norm": 1.1169940080435481e-05,
      "learning_rate": 3.277611087298186e-06,
      "loss": 0.0,
      "step": 58520
    },
    {
      "epoch": 12.543934847835406,
      "grad_norm": 1.2891905498690903e-05,
      "learning_rate": 3.2747535362194603e-06,
      "loss": 0.0,
      "step": 58530
    },
    {
      "epoch": 12.546078011144449,
      "grad_norm": 0.0003110414545517415,
      "learning_rate": 3.2718959851407346e-06,
      "loss": 0.0012,
      "step": 58540
    },
    {
      "epoch": 12.548221174453493,
      "grad_norm": 7.948511665745173e-06,
      "learning_rate": 3.269038434062009e-06,
      "loss": 0.0001,
      "step": 58550
    },
    {
      "epoch": 12.550364337762538,
      "grad_norm": 7.084260869305581e-05,
      "learning_rate": 3.2661808829832838e-06,
      "loss": 0.0,
      "step": 58560
    },
    {
      "epoch": 12.552507501071581,
      "grad_norm": 2.029637835221365e-05,
      "learning_rate": 3.263323331904558e-06,
      "loss": 0.0,
      "step": 58570
    },
    {
      "epoch": 12.554650664380626,
      "grad_norm": 5.128581324242987e-05,
      "learning_rate": 3.260465780825833e-06,
      "loss": 0.0,
      "step": 58580
    },
    {
      "epoch": 12.55679382768967,
      "grad_norm": 1.2215437891427428e-05,
      "learning_rate": 3.257608229747107e-06,
      "loss": 0.0,
      "step": 58590
    },
    {
      "epoch": 12.558936990998713,
      "grad_norm": 1.2649046766455285e-05,
      "learning_rate": 3.254750678668381e-06,
      "loss": 0.0,
      "step": 58600
    },
    {
      "epoch": 12.561080154307758,
      "grad_norm": 2.016487815126311e-05,
      "learning_rate": 3.251893127589656e-06,
      "loss": 0.0001,
      "step": 58610
    },
    {
      "epoch": 12.563223317616803,
      "grad_norm": 1.6783815226517618e-05,
      "learning_rate": 3.2490355765109303e-06,
      "loss": 0.0,
      "step": 58620
    },
    {
      "epoch": 12.565366480925846,
      "grad_norm": 1.231888381880708e-05,
      "learning_rate": 3.246178025432205e-06,
      "loss": 0.0,
      "step": 58630
    },
    {
      "epoch": 12.56750964423489,
      "grad_norm": 0.00047365855425596237,
      "learning_rate": 3.243320474353479e-06,
      "loss": 0.2329,
      "step": 58640
    },
    {
      "epoch": 12.569652807543935,
      "grad_norm": 1.245485145773273e-05,
      "learning_rate": 3.2404629232747538e-06,
      "loss": 0.0,
      "step": 58650
    },
    {
      "epoch": 12.571795970852978,
      "grad_norm": 1.2524174962891266e-05,
      "learning_rate": 3.237605372196028e-06,
      "loss": 0.0,
      "step": 58660
    },
    {
      "epoch": 12.573939134162023,
      "grad_norm": 1.119838452723343e-05,
      "learning_rate": 3.234747821117303e-06,
      "loss": 0.0,
      "step": 58670
    },
    {
      "epoch": 12.576082297471068,
      "grad_norm": 1.3838700397172943e-05,
      "learning_rate": 3.2318902700385773e-06,
      "loss": 0.0,
      "step": 58680
    },
    {
      "epoch": 12.57822546078011,
      "grad_norm": 9.704907824925613e-06,
      "learning_rate": 3.229032718959852e-06,
      "loss": 0.0,
      "step": 58690
    },
    {
      "epoch": 12.580368624089155,
      "grad_norm": 0.00014183466555550694,
      "learning_rate": 3.226175167881126e-06,
      "loss": 0.0002,
      "step": 58700
    },
    {
      "epoch": 12.5825117873982,
      "grad_norm": 1.1978388101852033e-05,
      "learning_rate": 3.2233176168024003e-06,
      "loss": 0.0,
      "step": 58710
    },
    {
      "epoch": 12.584654950707243,
      "grad_norm": 8.69756331667304e-06,
      "learning_rate": 3.220460065723675e-06,
      "loss": 0.0,
      "step": 58720
    },
    {
      "epoch": 12.586798114016288,
      "grad_norm": 0.0013646548613905907,
      "learning_rate": 3.21760251464495e-06,
      "loss": 0.1464,
      "step": 58730
    },
    {
      "epoch": 12.588941277325333,
      "grad_norm": 9.766453331394587e-06,
      "learning_rate": 3.2147449635662242e-06,
      "loss": 0.0,
      "step": 58740
    },
    {
      "epoch": 12.591084440634376,
      "grad_norm": 0.000379450706532225,
      "learning_rate": 3.211887412487498e-06,
      "loss": 0.0,
      "step": 58750
    },
    {
      "epoch": 12.59322760394342,
      "grad_norm": 1.3449132893583737e-05,
      "learning_rate": 3.209029861408773e-06,
      "loss": 0.0,
      "step": 58760
    },
    {
      "epoch": 12.595370767252465,
      "grad_norm": 1.272748522751499e-05,
      "learning_rate": 3.2061723103300473e-06,
      "loss": 0.0,
      "step": 58770
    },
    {
      "epoch": 12.597513930561508,
      "grad_norm": 2.8600377845577896e-05,
      "learning_rate": 3.203314759251322e-06,
      "loss": 0.0,
      "step": 58780
    },
    {
      "epoch": 12.599657093870553,
      "grad_norm": 9.860242244030815e-06,
      "learning_rate": 3.2004572081725964e-06,
      "loss": 0.0,
      "step": 58790
    },
    {
      "epoch": 12.601800257179598,
      "grad_norm": 0.00012154238356743008,
      "learning_rate": 3.1975996570938708e-06,
      "loss": 0.0,
      "step": 58800
    },
    {
      "epoch": 12.60394342048864,
      "grad_norm": 8.352918666787446e-05,
      "learning_rate": 3.194742106015145e-06,
      "loss": 0.0,
      "step": 58810
    },
    {
      "epoch": 12.606086583797685,
      "grad_norm": 1.236899242940126e-05,
      "learning_rate": 3.19188455493642e-06,
      "loss": 0.0001,
      "step": 58820
    },
    {
      "epoch": 12.60822974710673,
      "grad_norm": 1.3687480532098562e-05,
      "learning_rate": 3.1890270038576942e-06,
      "loss": 0.0,
      "step": 58830
    },
    {
      "epoch": 12.610372910415773,
      "grad_norm": 7.789022674842272e-06,
      "learning_rate": 3.186169452778969e-06,
      "loss": 0.0007,
      "step": 58840
    },
    {
      "epoch": 12.612516073724818,
      "grad_norm": 1.4049278433958534e-05,
      "learning_rate": 3.1833119017002434e-06,
      "loss": 0.0,
      "step": 58850
    },
    {
      "epoch": 12.614659237033862,
      "grad_norm": 1.4337382708617952e-05,
      "learning_rate": 3.1804543506215173e-06,
      "loss": 0.0,
      "step": 58860
    },
    {
      "epoch": 12.616802400342905,
      "grad_norm": 1.5218412954709493e-05,
      "learning_rate": 3.177596799542792e-06,
      "loss": 0.0,
      "step": 58870
    },
    {
      "epoch": 12.61894556365195,
      "grad_norm": 3.1499192118644714e-05,
      "learning_rate": 3.1747392484640664e-06,
      "loss": 0.0,
      "step": 58880
    },
    {
      "epoch": 12.621088726960995,
      "grad_norm": 1.703148336673621e-05,
      "learning_rate": 3.171881697385341e-06,
      "loss": 0.0,
      "step": 58890
    },
    {
      "epoch": 12.623231890270038,
      "grad_norm": 1.5431705833179876e-05,
      "learning_rate": 3.1690241463066155e-06,
      "loss": 0.0,
      "step": 58900
    },
    {
      "epoch": 12.625375053579083,
      "grad_norm": 0.17599143087863922,
      "learning_rate": 3.16616659522789e-06,
      "loss": 0.0001,
      "step": 58910
    },
    {
      "epoch": 12.627518216888127,
      "grad_norm": 9.709596270113252e-06,
      "learning_rate": 3.1633090441491642e-06,
      "loss": 0.0,
      "step": 58920
    },
    {
      "epoch": 12.62966138019717,
      "grad_norm": 1.6733178199501708e-05,
      "learning_rate": 3.160451493070439e-06,
      "loss": 0.003,
      "step": 58930
    },
    {
      "epoch": 12.631804543506215,
      "grad_norm": 8.21858975541545e-06,
      "learning_rate": 3.1575939419917134e-06,
      "loss": 0.0,
      "step": 58940
    },
    {
      "epoch": 12.63394770681526,
      "grad_norm": 7.043707228149287e-06,
      "learning_rate": 3.154736390912988e-06,
      "loss": 0.0,
      "step": 58950
    },
    {
      "epoch": 12.636090870124303,
      "grad_norm": 4.9945763748837635e-05,
      "learning_rate": 3.1518788398342625e-06,
      "loss": 0.0,
      "step": 58960
    },
    {
      "epoch": 12.638234033433347,
      "grad_norm": 8.27253552415641e-06,
      "learning_rate": 3.1490212887555364e-06,
      "loss": 0.0,
      "step": 58970
    },
    {
      "epoch": 12.640377196742392,
      "grad_norm": 1.0665594339370728,
      "learning_rate": 3.146163737676811e-06,
      "loss": 0.0015,
      "step": 58980
    },
    {
      "epoch": 12.642520360051435,
      "grad_norm": 0.054690275341272354,
      "learning_rate": 3.1433061865980856e-06,
      "loss": 0.182,
      "step": 58990
    },
    {
      "epoch": 12.64466352336048,
      "grad_norm": 2.1731244487455115e-05,
      "learning_rate": 3.1404486355193603e-06,
      "loss": 0.0,
      "step": 59000
    },
    {
      "epoch": 12.646806686669525,
      "grad_norm": 1.3934594790043775e-05,
      "learning_rate": 3.1375910844406347e-06,
      "loss": 0.0,
      "step": 59010
    },
    {
      "epoch": 12.648949849978568,
      "grad_norm": 9.432091610506177e-05,
      "learning_rate": 3.134733533361909e-06,
      "loss": 0.0,
      "step": 59020
    },
    {
      "epoch": 12.651093013287612,
      "grad_norm": 1.2861098184657749e-05,
      "learning_rate": 3.1318759822831834e-06,
      "loss": 0.0,
      "step": 59030
    },
    {
      "epoch": 12.653236176596657,
      "grad_norm": 1.3890361515223049e-05,
      "learning_rate": 3.129018431204458e-06,
      "loss": 0.0,
      "step": 59040
    },
    {
      "epoch": 12.6553793399057,
      "grad_norm": 0.00011541935964487493,
      "learning_rate": 3.1261608801257325e-06,
      "loss": 0.0,
      "step": 59050
    },
    {
      "epoch": 12.657522503214745,
      "grad_norm": 1.629173129913397e-05,
      "learning_rate": 3.1233033290470073e-06,
      "loss": 0.179,
      "step": 59060
    },
    {
      "epoch": 12.65966566652379,
      "grad_norm": 1.3254843906906899e-05,
      "learning_rate": 3.1204457779682812e-06,
      "loss": 0.0,
      "step": 59070
    },
    {
      "epoch": 12.661808829832832,
      "grad_norm": 1.2898950444650836e-05,
      "learning_rate": 3.1175882268895556e-06,
      "loss": 0.0,
      "step": 59080
    },
    {
      "epoch": 12.663951993141877,
      "grad_norm": 0.00018019540584646165,
      "learning_rate": 3.1147306758108303e-06,
      "loss": 0.0,
      "step": 59090
    },
    {
      "epoch": 12.666095156450922,
      "grad_norm": 1.349708327325061e-05,
      "learning_rate": 3.1118731247321047e-06,
      "loss": 0.0003,
      "step": 59100
    },
    {
      "epoch": 12.668238319759965,
      "grad_norm": 4.108519715373404e-05,
      "learning_rate": 3.1090155736533795e-06,
      "loss": 0.0,
      "step": 59110
    },
    {
      "epoch": 12.67038148306901,
      "grad_norm": 1.142809196608141e-05,
      "learning_rate": 3.1061580225746542e-06,
      "loss": 0.0,
      "step": 59120
    },
    {
      "epoch": 12.672524646378054,
      "grad_norm": 0.0012616696767508984,
      "learning_rate": 3.103300471495928e-06,
      "loss": 0.0,
      "step": 59130
    },
    {
      "epoch": 12.674667809687097,
      "grad_norm": 1.0157354154216591e-05,
      "learning_rate": 3.1004429204172025e-06,
      "loss": 0.0001,
      "step": 59140
    },
    {
      "epoch": 12.676810972996142,
      "grad_norm": 1.3658247553394176e-05,
      "learning_rate": 3.0975853693384773e-06,
      "loss": 0.0,
      "step": 59150
    },
    {
      "epoch": 12.678954136305187,
      "grad_norm": 1.4535163245454896e-05,
      "learning_rate": 3.0947278182597517e-06,
      "loss": 0.0004,
      "step": 59160
    },
    {
      "epoch": 12.68109729961423,
      "grad_norm": 1.2241408512636553e-05,
      "learning_rate": 3.0918702671810264e-06,
      "loss": 0.0,
      "step": 59170
    },
    {
      "epoch": 12.683240462923274,
      "grad_norm": 1.390129909850657e-05,
      "learning_rate": 3.0890127161023004e-06,
      "loss": 0.0004,
      "step": 59180
    },
    {
      "epoch": 12.68538362623232,
      "grad_norm": 0.00046789669431746006,
      "learning_rate": 3.086155165023575e-06,
      "loss": 0.0,
      "step": 59190
    },
    {
      "epoch": 12.687526789541362,
      "grad_norm": 0.0016730893403291702,
      "learning_rate": 3.0832976139448495e-06,
      "loss": 0.0,
      "step": 59200
    },
    {
      "epoch": 12.689669952850407,
      "grad_norm": 1.9557473933673464e-05,
      "learning_rate": 3.0804400628661243e-06,
      "loss": 0.0,
      "step": 59210
    },
    {
      "epoch": 12.691813116159452,
      "grad_norm": 1.3949942513136193e-05,
      "learning_rate": 3.0775825117873986e-06,
      "loss": 0.0001,
      "step": 59220
    },
    {
      "epoch": 12.693956279468495,
      "grad_norm": 1.134924514190061e-05,
      "learning_rate": 3.0747249607086725e-06,
      "loss": 0.0,
      "step": 59230
    },
    {
      "epoch": 12.69609944277754,
      "grad_norm": 0.000252943835221231,
      "learning_rate": 3.0718674096299473e-06,
      "loss": 0.0,
      "step": 59240
    },
    {
      "epoch": 12.698242606086584,
      "grad_norm": 2.8080712581868283e-05,
      "learning_rate": 3.0690098585512217e-06,
      "loss": 0.0,
      "step": 59250
    },
    {
      "epoch": 12.700385769395627,
      "grad_norm": 1.0343549547542352e-05,
      "learning_rate": 3.0661523074724964e-06,
      "loss": 0.0,
      "step": 59260
    },
    {
      "epoch": 12.702528932704672,
      "grad_norm": 0.0001405338989570737,
      "learning_rate": 3.063294756393771e-06,
      "loss": 0.0,
      "step": 59270
    },
    {
      "epoch": 12.704672096013716,
      "grad_norm": 1.0017050044552889e-05,
      "learning_rate": 3.0604372053150456e-06,
      "loss": 0.0,
      "step": 59280
    },
    {
      "epoch": 12.70681525932276,
      "grad_norm": 0.0006155675509944558,
      "learning_rate": 3.0575796542363195e-06,
      "loss": 0.0722,
      "step": 59290
    },
    {
      "epoch": 12.708958422631804,
      "grad_norm": 0.00012084782792953774,
      "learning_rate": 3.0547221031575943e-06,
      "loss": 0.0,
      "step": 59300
    },
    {
      "epoch": 12.711101585940849,
      "grad_norm": 0.00012504297774285078,
      "learning_rate": 3.0518645520788686e-06,
      "loss": 0.0,
      "step": 59310
    },
    {
      "epoch": 12.713244749249894,
      "grad_norm": 1.4687248949485365e-05,
      "learning_rate": 3.0490070010001434e-06,
      "loss": 0.0,
      "step": 59320
    },
    {
      "epoch": 12.715387912558937,
      "grad_norm": 1.765067281667143e-05,
      "learning_rate": 3.0461494499214177e-06,
      "loss": 0.0,
      "step": 59330
    },
    {
      "epoch": 12.717531075867981,
      "grad_norm": 1.0599195775284898e-05,
      "learning_rate": 3.0432918988426917e-06,
      "loss": 0.0004,
      "step": 59340
    },
    {
      "epoch": 12.719674239177026,
      "grad_norm": 1.1560359780560248e-05,
      "learning_rate": 3.0404343477639665e-06,
      "loss": 0.0,
      "step": 59350
    },
    {
      "epoch": 12.721817402486069,
      "grad_norm": 2.426615174044855e-05,
      "learning_rate": 3.037576796685241e-06,
      "loss": 0.0,
      "step": 59360
    },
    {
      "epoch": 12.723960565795114,
      "grad_norm": 1.0867484888876788e-05,
      "learning_rate": 3.0347192456065156e-06,
      "loss": 0.0,
      "step": 59370
    },
    {
      "epoch": 12.726103729104159,
      "grad_norm": 1.0958528037008364e-05,
      "learning_rate": 3.03186169452779e-06,
      "loss": 0.0,
      "step": 59380
    },
    {
      "epoch": 12.728246892413202,
      "grad_norm": 1.1804772839241195e-05,
      "learning_rate": 3.0290041434490643e-06,
      "loss": 0.0,
      "step": 59390
    },
    {
      "epoch": 12.730390055722246,
      "grad_norm": 0.00729688024148345,
      "learning_rate": 3.0261465923703386e-06,
      "loss": 0.0,
      "step": 59400
    },
    {
      "epoch": 12.732533219031291,
      "grad_norm": 1.7200567526742816e-05,
      "learning_rate": 3.0232890412916134e-06,
      "loss": 0.0001,
      "step": 59410
    },
    {
      "epoch": 12.734676382340334,
      "grad_norm": 9.692161984276026e-05,
      "learning_rate": 3.0204314902128878e-06,
      "loss": 0.0,
      "step": 59420
    },
    {
      "epoch": 12.736819545649379,
      "grad_norm": 7.770106094540097e-06,
      "learning_rate": 3.0175739391341625e-06,
      "loss": 0.0005,
      "step": 59430
    },
    {
      "epoch": 12.738962708958423,
      "grad_norm": 1.1888742847077083e-05,
      "learning_rate": 3.014716388055437e-06,
      "loss": 0.0,
      "step": 59440
    },
    {
      "epoch": 12.741105872267466,
      "grad_norm": 0.00025963017833419144,
      "learning_rate": 3.011858836976711e-06,
      "loss": 0.3763,
      "step": 59450
    },
    {
      "epoch": 12.743249035576511,
      "grad_norm": 1.8509646906750277e-05,
      "learning_rate": 3.0090012858979856e-06,
      "loss": 0.001,
      "step": 59460
    },
    {
      "epoch": 12.745392198885556,
      "grad_norm": 4.5982058509252965e-05,
      "learning_rate": 3.00614373481926e-06,
      "loss": 0.0001,
      "step": 59470
    },
    {
      "epoch": 12.747535362194599,
      "grad_norm": 0.0004942652303725481,
      "learning_rate": 3.0032861837405347e-06,
      "loss": 0.1191,
      "step": 59480
    },
    {
      "epoch": 12.749678525503644,
      "grad_norm": 0.0001786662614904344,
      "learning_rate": 3.000428632661809e-06,
      "loss": 0.0,
      "step": 59490
    },
    {
      "epoch": 12.751821688812688,
      "grad_norm": 9.584945655660704e-05,
      "learning_rate": 2.9975710815830834e-06,
      "loss": 0.0079,
      "step": 59500
    },
    {
      "epoch": 12.753964852121731,
      "grad_norm": 2.799586218316108e-05,
      "learning_rate": 2.9947135305043578e-06,
      "loss": 0.182,
      "step": 59510
    },
    {
      "epoch": 12.756108015430776,
      "grad_norm": 0.00017801212379708886,
      "learning_rate": 2.9918559794256326e-06,
      "loss": 0.0,
      "step": 59520
    },
    {
      "epoch": 12.75825117873982,
      "grad_norm": 3.964380084653385e-05,
      "learning_rate": 2.988998428346907e-06,
      "loss": 0.15,
      "step": 59530
    },
    {
      "epoch": 12.760394342048864,
      "grad_norm": 4.354476186563261e-05,
      "learning_rate": 2.9861408772681817e-06,
      "loss": 0.0,
      "step": 59540
    },
    {
      "epoch": 12.762537505357908,
      "grad_norm": 0.00036508284392766654,
      "learning_rate": 2.983283326189456e-06,
      "loss": 0.0002,
      "step": 59550
    },
    {
      "epoch": 12.764680668666953,
      "grad_norm": 2.7739448341890238e-05,
      "learning_rate": 2.98042577511073e-06,
      "loss": 0.0,
      "step": 59560
    },
    {
      "epoch": 12.766823831975996,
      "grad_norm": 0.00014456240751314908,
      "learning_rate": 2.9775682240320047e-06,
      "loss": 0.0007,
      "step": 59570
    },
    {
      "epoch": 12.76896699528504,
      "grad_norm": 0.00017443746037315577,
      "learning_rate": 2.9747106729532795e-06,
      "loss": 0.0,
      "step": 59580
    },
    {
      "epoch": 12.771110158594086,
      "grad_norm": 2.4557013603043742e-05,
      "learning_rate": 2.971853121874554e-06,
      "loss": 0.0,
      "step": 59590
    },
    {
      "epoch": 12.773253321903129,
      "grad_norm": 8.11497593531385e-05,
      "learning_rate": 2.9689955707958286e-06,
      "loss": 0.0005,
      "step": 59600
    },
    {
      "epoch": 12.775396485212173,
      "grad_norm": 2.407788997516036e-05,
      "learning_rate": 2.9661380197171026e-06,
      "loss": 0.0,
      "step": 59610
    },
    {
      "epoch": 12.777539648521218,
      "grad_norm": 0.0006874596001580358,
      "learning_rate": 2.963280468638377e-06,
      "loss": 0.0,
      "step": 59620
    },
    {
      "epoch": 12.779682811830261,
      "grad_norm": 0.002514276187866926,
      "learning_rate": 2.9604229175596517e-06,
      "loss": 0.0,
      "step": 59630
    },
    {
      "epoch": 12.781825975139306,
      "grad_norm": 0.0002603346074465662,
      "learning_rate": 2.957565366480926e-06,
      "loss": 0.0,
      "step": 59640
    },
    {
      "epoch": 12.78396913844835,
      "grad_norm": 0.000409009080613032,
      "learning_rate": 2.954707815402201e-06,
      "loss": 0.0,
      "step": 59650
    },
    {
      "epoch": 12.786112301757393,
      "grad_norm": 0.00028427940560504794,
      "learning_rate": 2.9518502643234747e-06,
      "loss": 0.0,
      "step": 59660
    },
    {
      "epoch": 12.788255465066438,
      "grad_norm": 1.546638668514788e-05,
      "learning_rate": 2.9489927132447495e-06,
      "loss": 0.0,
      "step": 59670
    },
    {
      "epoch": 12.790398628375483,
      "grad_norm": 1.2672838238358963e-05,
      "learning_rate": 2.946135162166024e-06,
      "loss": 0.0003,
      "step": 59680
    },
    {
      "epoch": 12.792541791684526,
      "grad_norm": 6.329012103378773e-05,
      "learning_rate": 2.9432776110872986e-06,
      "loss": 0.0,
      "step": 59690
    },
    {
      "epoch": 12.79468495499357,
      "grad_norm": 4.354383054305799e-05,
      "learning_rate": 2.940420060008573e-06,
      "loss": 0.1373,
      "step": 59700
    },
    {
      "epoch": 12.796828118302615,
      "grad_norm": 2.314852099516429e-05,
      "learning_rate": 2.9375625089298478e-06,
      "loss": 0.0007,
      "step": 59710
    },
    {
      "epoch": 12.798971281611658,
      "grad_norm": 1.865261947386898e-05,
      "learning_rate": 2.9347049578511217e-06,
      "loss": 0.0,
      "step": 59720
    },
    {
      "epoch": 12.801114444920703,
      "grad_norm": 2.1530537196667865e-05,
      "learning_rate": 2.931847406772396e-06,
      "loss": 0.0,
      "step": 59730
    },
    {
      "epoch": 12.803257608229748,
      "grad_norm": 1.852005698310677e-05,
      "learning_rate": 2.928989855693671e-06,
      "loss": 0.0,
      "step": 59740
    },
    {
      "epoch": 12.80540077153879,
      "grad_norm": 1.4214866496331524e-05,
      "learning_rate": 2.926132304614945e-06,
      "loss": 0.0,
      "step": 59750
    },
    {
      "epoch": 12.807543934847835,
      "grad_norm": 0.007988947443664074,
      "learning_rate": 2.92327475353622e-06,
      "loss": 0.0,
      "step": 59760
    },
    {
      "epoch": 12.80968709815688,
      "grad_norm": 4.5384691475192085e-05,
      "learning_rate": 2.920417202457494e-06,
      "loss": 0.0,
      "step": 59770
    },
    {
      "epoch": 12.811830261465923,
      "grad_norm": 3.876968185068108e-05,
      "learning_rate": 2.9175596513787687e-06,
      "loss": 0.0,
      "step": 59780
    },
    {
      "epoch": 12.813973424774968,
      "grad_norm": 0.00024309064610861242,
      "learning_rate": 2.914702100300043e-06,
      "loss": 0.1595,
      "step": 59790
    },
    {
      "epoch": 12.816116588084013,
      "grad_norm": 1.9472938220133074e-05,
      "learning_rate": 2.911844549221318e-06,
      "loss": 0.0,
      "step": 59800
    },
    {
      "epoch": 12.818259751393056,
      "grad_norm": 0.29554083943367004,
      "learning_rate": 2.908986998142592e-06,
      "loss": 0.0003,
      "step": 59810
    },
    {
      "epoch": 12.8204029147021,
      "grad_norm": 1.2364318536128849e-05,
      "learning_rate": 2.906129447063866e-06,
      "loss": 0.0,
      "step": 59820
    },
    {
      "epoch": 12.822546078011145,
      "grad_norm": 0.00010713400115491822,
      "learning_rate": 2.903271895985141e-06,
      "loss": 0.0,
      "step": 59830
    },
    {
      "epoch": 12.824689241320188,
      "grad_norm": 7.977523637237027e-05,
      "learning_rate": 2.900414344906415e-06,
      "loss": 0.0,
      "step": 59840
    },
    {
      "epoch": 12.826832404629233,
      "grad_norm": 1.5814119251444936e-05,
      "learning_rate": 2.89755679382769e-06,
      "loss": 0.0,
      "step": 59850
    },
    {
      "epoch": 12.828975567938278,
      "grad_norm": 2.06228705792455e-05,
      "learning_rate": 2.8946992427489643e-06,
      "loss": 0.0,
      "step": 59860
    },
    {
      "epoch": 12.83111873124732,
      "grad_norm": 1.6285597666865215e-05,
      "learning_rate": 2.891841691670239e-06,
      "loss": 0.0002,
      "step": 59870
    },
    {
      "epoch": 12.833261894556365,
      "grad_norm": 0.00015123489720281214,
      "learning_rate": 2.888984140591513e-06,
      "loss": 0.0,
      "step": 59880
    },
    {
      "epoch": 12.83540505786541,
      "grad_norm": 1.2684139619523194e-05,
      "learning_rate": 2.886126589512788e-06,
      "loss": 0.0,
      "step": 59890
    },
    {
      "epoch": 12.837548221174453,
      "grad_norm": 1.2267268175492063e-05,
      "learning_rate": 2.883269038434062e-06,
      "loss": 0.0,
      "step": 59900
    },
    {
      "epoch": 12.839691384483498,
      "grad_norm": 1.1271012226643506e-05,
      "learning_rate": 2.880411487355337e-06,
      "loss": 0.0,
      "step": 59910
    },
    {
      "epoch": 12.841834547792542,
      "grad_norm": 2.0530902475002222e-05,
      "learning_rate": 2.8775539362766113e-06,
      "loss": 0.0,
      "step": 59920
    },
    {
      "epoch": 12.843977711101585,
      "grad_norm": 1.715116377454251e-05,
      "learning_rate": 2.874696385197885e-06,
      "loss": 0.0002,
      "step": 59930
    },
    {
      "epoch": 12.84612087441063,
      "grad_norm": 2.0361601855256595e-05,
      "learning_rate": 2.87183883411916e-06,
      "loss": 0.0,
      "step": 59940
    },
    {
      "epoch": 12.848264037719675,
      "grad_norm": 0.003088833298534155,
      "learning_rate": 2.8689812830404348e-06,
      "loss": 0.0,
      "step": 59950
    },
    {
      "epoch": 12.850407201028718,
      "grad_norm": 0.00028845560154877603,
      "learning_rate": 2.866123731961709e-06,
      "loss": 0.1355,
      "step": 59960
    },
    {
      "epoch": 12.852550364337763,
      "grad_norm": 2.1798083253088407e-05,
      "learning_rate": 2.863266180882984e-06,
      "loss": 0.0008,
      "step": 59970
    },
    {
      "epoch": 12.854693527646807,
      "grad_norm": 0.0001906111283460632,
      "learning_rate": 2.860408629804258e-06,
      "loss": 0.0,
      "step": 59980
    },
    {
      "epoch": 12.85683669095585,
      "grad_norm": 2.150437285308726e-05,
      "learning_rate": 2.857551078725532e-06,
      "loss": 0.0,
      "step": 59990
    },
    {
      "epoch": 12.858979854264895,
      "grad_norm": 1.6232257621595636e-05,
      "learning_rate": 2.854693527646807e-06,
      "loss": 0.0,
      "step": 60000
    },
    {
      "epoch": 12.86112301757394,
      "grad_norm": 7.014413858996704e-05,
      "learning_rate": 2.8518359765680813e-06,
      "loss": 0.0,
      "step": 60010
    },
    {
      "epoch": 12.863266180882983,
      "grad_norm": 0.00016833809786476195,
      "learning_rate": 2.848978425489356e-06,
      "loss": 0.0,
      "step": 60020
    },
    {
      "epoch": 12.865409344192027,
      "grad_norm": 0.0006199359195306897,
      "learning_rate": 2.8461208744106304e-06,
      "loss": 0.0,
      "step": 60030
    },
    {
      "epoch": 12.867552507501072,
      "grad_norm": 3.692718019010499e-05,
      "learning_rate": 2.8432633233319048e-06,
      "loss": 0.0005,
      "step": 60040
    },
    {
      "epoch": 12.869695670810115,
      "grad_norm": 1.343747953796992e-05,
      "learning_rate": 2.840405772253179e-06,
      "loss": 0.0876,
      "step": 60050
    },
    {
      "epoch": 12.87183883411916,
      "grad_norm": 1.5846304449951276e-05,
      "learning_rate": 2.837548221174454e-06,
      "loss": 0.0,
      "step": 60060
    },
    {
      "epoch": 12.873981997428205,
      "grad_norm": 1.2194726878078654e-05,
      "learning_rate": 2.8346906700957283e-06,
      "loss": 0.1176,
      "step": 60070
    },
    {
      "epoch": 12.876125160737248,
      "grad_norm": 0.0002789746504276991,
      "learning_rate": 2.831833119017003e-06,
      "loss": 0.0001,
      "step": 60080
    },
    {
      "epoch": 12.878268324046292,
      "grad_norm": 2.2166301278048195e-05,
      "learning_rate": 2.828975567938277e-06,
      "loss": 0.0,
      "step": 60090
    },
    {
      "epoch": 12.880411487355337,
      "grad_norm": 0.0001702700392343104,
      "learning_rate": 2.8261180168595513e-06,
      "loss": 0.0728,
      "step": 60100
    },
    {
      "epoch": 12.88255465066438,
      "grad_norm": 1.558585609018337e-05,
      "learning_rate": 2.823260465780826e-06,
      "loss": 0.0009,
      "step": 60110
    },
    {
      "epoch": 12.884697813973425,
      "grad_norm": 2.71978133241646e-05,
      "learning_rate": 2.8204029147021004e-06,
      "loss": 0.0,
      "step": 60120
    },
    {
      "epoch": 12.88684097728247,
      "grad_norm": 5.560815770877525e-05,
      "learning_rate": 2.817545363623375e-06,
      "loss": 0.0,
      "step": 60130
    },
    {
      "epoch": 12.888984140591512,
      "grad_norm": 0.00014386425027623773,
      "learning_rate": 2.8146878125446496e-06,
      "loss": 0.0001,
      "step": 60140
    },
    {
      "epoch": 12.891127303900557,
      "grad_norm": 2.6950807296088897e-05,
      "learning_rate": 2.811830261465924e-06,
      "loss": 0.0,
      "step": 60150
    },
    {
      "epoch": 12.893270467209602,
      "grad_norm": 0.0005786414258182049,
      "learning_rate": 2.8089727103871983e-06,
      "loss": 0.0,
      "step": 60160
    },
    {
      "epoch": 12.895413630518645,
      "grad_norm": 2.909220347646624e-05,
      "learning_rate": 2.806115159308473e-06,
      "loss": 0.0,
      "step": 60170
    },
    {
      "epoch": 12.89755679382769,
      "grad_norm": 9.68591048149392e-05,
      "learning_rate": 2.8032576082297474e-06,
      "loss": 0.0,
      "step": 60180
    },
    {
      "epoch": 12.899699957136734,
      "grad_norm": 2.0179757484584115e-05,
      "learning_rate": 2.800400057151022e-06,
      "loss": 0.0,
      "step": 60190
    },
    {
      "epoch": 12.901843120445777,
      "grad_norm": 0.00010683413711376488,
      "learning_rate": 2.797542506072296e-06,
      "loss": 0.1379,
      "step": 60200
    },
    {
      "epoch": 12.903986283754822,
      "grad_norm": 0.00017324801592621952,
      "learning_rate": 2.7946849549935704e-06,
      "loss": 0.1227,
      "step": 60210
    },
    {
      "epoch": 12.906129447063867,
      "grad_norm": 0.0001244370942004025,
      "learning_rate": 2.7918274039148452e-06,
      "loss": 0.0919,
      "step": 60220
    },
    {
      "epoch": 12.90827261037291,
      "grad_norm": 0.00031172571470960975,
      "learning_rate": 2.7889698528361196e-06,
      "loss": 0.0,
      "step": 60230
    },
    {
      "epoch": 12.910415773681954,
      "grad_norm": 0.0001143783811130561,
      "learning_rate": 2.7861123017573943e-06,
      "loss": 0.0,
      "step": 60240
    },
    {
      "epoch": 12.912558936991,
      "grad_norm": 0.00019448832608759403,
      "learning_rate": 2.7832547506786683e-06,
      "loss": 0.1187,
      "step": 60250
    },
    {
      "epoch": 12.914702100300042,
      "grad_norm": 0.00015719591465312988,
      "learning_rate": 2.780397199599943e-06,
      "loss": 0.0,
      "step": 60260
    },
    {
      "epoch": 12.916845263609087,
      "grad_norm": 1.527744643681217e-05,
      "learning_rate": 2.7775396485212174e-06,
      "loss": 0.0,
      "step": 60270
    },
    {
      "epoch": 12.918988426918132,
      "grad_norm": 2.2152349629322998e-05,
      "learning_rate": 2.774682097442492e-06,
      "loss": 0.0,
      "step": 60280
    },
    {
      "epoch": 12.921131590227175,
      "grad_norm": 1.0749005014076829e-05,
      "learning_rate": 2.7718245463637665e-06,
      "loss": 0.0014,
      "step": 60290
    },
    {
      "epoch": 12.92327475353622,
      "grad_norm": 0.00023260949819814414,
      "learning_rate": 2.7689669952850413e-06,
      "loss": 0.0,
      "step": 60300
    },
    {
      "epoch": 12.925417916845264,
      "grad_norm": 6.003247108310461e-05,
      "learning_rate": 2.7661094442063152e-06,
      "loss": 0.0033,
      "step": 60310
    },
    {
      "epoch": 12.927561080154307,
      "grad_norm": 1.296610298595624e-05,
      "learning_rate": 2.7632518931275896e-06,
      "loss": 0.0,
      "step": 60320
    },
    {
      "epoch": 12.929704243463352,
      "grad_norm": 0.00028127996483817697,
      "learning_rate": 2.7603943420488644e-06,
      "loss": 0.1082,
      "step": 60330
    },
    {
      "epoch": 12.931847406772397,
      "grad_norm": 16.510469436645508,
      "learning_rate": 2.757536790970139e-06,
      "loss": 0.1127,
      "step": 60340
    },
    {
      "epoch": 12.93399057008144,
      "grad_norm": 1.022476044454379e-05,
      "learning_rate": 2.7546792398914135e-06,
      "loss": 0.0,
      "step": 60350
    },
    {
      "epoch": 12.936133733390484,
      "grad_norm": 0.0001036027679219842,
      "learning_rate": 2.7518216888126874e-06,
      "loss": 0.0,
      "step": 60360
    },
    {
      "epoch": 12.938276896699529,
      "grad_norm": 6.168139225337654e-05,
      "learning_rate": 2.748964137733962e-06,
      "loss": 0.0,
      "step": 60370
    },
    {
      "epoch": 12.940420060008572,
      "grad_norm": 6.714448682032526e-05,
      "learning_rate": 2.7461065866552365e-06,
      "loss": 0.0,
      "step": 60380
    },
    {
      "epoch": 12.942563223317617,
      "grad_norm": 1.6067084288806655e-05,
      "learning_rate": 2.7432490355765113e-06,
      "loss": 0.0,
      "step": 60390
    },
    {
      "epoch": 12.944706386626661,
      "grad_norm": 0.0003171491262037307,
      "learning_rate": 2.7403914844977857e-06,
      "loss": 0.0007,
      "step": 60400
    },
    {
      "epoch": 12.946849549935704,
      "grad_norm": 2.0967714590369724e-05,
      "learning_rate": 2.73753393341906e-06,
      "loss": 0.0,
      "step": 60410
    },
    {
      "epoch": 12.948992713244749,
      "grad_norm": 1.877319664345123e-05,
      "learning_rate": 2.7346763823403344e-06,
      "loss": 0.0,
      "step": 60420
    },
    {
      "epoch": 12.951135876553794,
      "grad_norm": 2.2196521967998706e-05,
      "learning_rate": 2.731818831261609e-06,
      "loss": 0.0,
      "step": 60430
    },
    {
      "epoch": 12.953279039862837,
      "grad_norm": 1.4693820048705675e-05,
      "learning_rate": 2.7289612801828835e-06,
      "loss": 0.0,
      "step": 60440
    },
    {
      "epoch": 12.955422203171882,
      "grad_norm": 1.5689292922616005e-05,
      "learning_rate": 2.7261037291041583e-06,
      "loss": 0.0001,
      "step": 60450
    },
    {
      "epoch": 12.957565366480926,
      "grad_norm": 4.2906354792648926e-05,
      "learning_rate": 2.7232461780254326e-06,
      "loss": 0.1101,
      "step": 60460
    },
    {
      "epoch": 12.95970852978997,
      "grad_norm": 1.2584142496052664e-05,
      "learning_rate": 2.7203886269467066e-06,
      "loss": 0.0,
      "step": 60470
    },
    {
      "epoch": 12.961851693099014,
      "grad_norm": 1.4089362593949772e-05,
      "learning_rate": 2.7175310758679813e-06,
      "loss": 0.0003,
      "step": 60480
    },
    {
      "epoch": 12.963994856408059,
      "grad_norm": 0.0015763117698952556,
      "learning_rate": 2.7146735247892557e-06,
      "loss": 0.0,
      "step": 60490
    },
    {
      "epoch": 12.966138019717102,
      "grad_norm": 0.00012691199663095176,
      "learning_rate": 2.7118159737105305e-06,
      "loss": 0.0,
      "step": 60500
    },
    {
      "epoch": 12.968281183026146,
      "grad_norm": 5.1837938372045755e-05,
      "learning_rate": 2.708958422631805e-06,
      "loss": 0.0,
      "step": 60510
    },
    {
      "epoch": 12.970424346335191,
      "grad_norm": 1.1187666132173035e-05,
      "learning_rate": 2.706100871553079e-06,
      "loss": 0.0,
      "step": 60520
    },
    {
      "epoch": 12.972567509644234,
      "grad_norm": 0.004969986621290445,
      "learning_rate": 2.7032433204743535e-06,
      "loss": 0.0623,
      "step": 60530
    },
    {
      "epoch": 12.974710672953279,
      "grad_norm": 1.7188351193908602e-05,
      "learning_rate": 2.7003857693956283e-06,
      "loss": 0.0,
      "step": 60540
    },
    {
      "epoch": 12.976853836262324,
      "grad_norm": 1.1192463716724887e-05,
      "learning_rate": 2.6975282183169026e-06,
      "loss": 0.1069,
      "step": 60550
    },
    {
      "epoch": 12.978996999571367,
      "grad_norm": 1.2071772289345972e-05,
      "learning_rate": 2.6946706672381774e-06,
      "loss": 0.0,
      "step": 60560
    },
    {
      "epoch": 12.981140162880411,
      "grad_norm": 9.607110769138671e-06,
      "learning_rate": 2.6918131161594518e-06,
      "loss": 0.0,
      "step": 60570
    },
    {
      "epoch": 12.983283326189456,
      "grad_norm": 9.620359378459398e-06,
      "learning_rate": 2.6889555650807257e-06,
      "loss": 0.0,
      "step": 60580
    },
    {
      "epoch": 12.985426489498499,
      "grad_norm": 1.12090910988627e-05,
      "learning_rate": 2.6860980140020005e-06,
      "loss": 0.0,
      "step": 60590
    },
    {
      "epoch": 12.987569652807544,
      "grad_norm": 0.00018248565902467817,
      "learning_rate": 2.683240462923275e-06,
      "loss": 0.0,
      "step": 60600
    },
    {
      "epoch": 12.989712816116588,
      "grad_norm": 3.797533645411022e-05,
      "learning_rate": 2.6803829118445496e-06,
      "loss": 0.0,
      "step": 60610
    },
    {
      "epoch": 12.991855979425631,
      "grad_norm": 1.1963374163315166e-05,
      "learning_rate": 2.677525360765824e-06,
      "loss": 0.0,
      "step": 60620
    },
    {
      "epoch": 12.993999142734676,
      "grad_norm": 1.3894905350753106e-05,
      "learning_rate": 2.6746678096870983e-06,
      "loss": 0.0,
      "step": 60630
    },
    {
      "epoch": 12.996142306043721,
      "grad_norm": 0.00010303529415978119,
      "learning_rate": 2.6718102586083727e-06,
      "loss": 0.0,
      "step": 60640
    },
    {
      "epoch": 12.998285469352764,
      "grad_norm": 9.075854177353904e-05,
      "learning_rate": 2.6689527075296474e-06,
      "loss": 0.0001,
      "step": 60650
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.9863333333333333,
      "eval_f1": 0.9301533219761499,
      "eval_loss": 0.13066670298576355,
      "eval_precision": 0.9512195121951219,
      "eval_recall": 0.91,
      "eval_runtime": 400.1203,
      "eval_samples_per_second": 7.498,
      "eval_steps_per_second": 2.499,
      "step": 60658
    },
    {
      "epoch": 13.000428632661809,
      "grad_norm": 1.1637323041213676e-05,
      "learning_rate": 2.6660951564509218e-06,
      "loss": 0.0,
      "step": 60660
    },
    {
      "epoch": 13.002571795970853,
      "grad_norm": 1.023287586576771e-05,
      "learning_rate": 2.6632376053721966e-06,
      "loss": 0.0,
      "step": 60670
    },
    {
      "epoch": 13.004714959279896,
      "grad_norm": 1.677929685683921e-05,
      "learning_rate": 2.6603800542934705e-06,
      "loss": 0.1136,
      "step": 60680
    },
    {
      "epoch": 13.006858122588941,
      "grad_norm": 1.0671275958884507e-05,
      "learning_rate": 2.657522503214745e-06,
      "loss": 0.0,
      "step": 60690
    },
    {
      "epoch": 13.009001285897986,
      "grad_norm": 8.797998816589825e-06,
      "learning_rate": 2.6546649521360196e-06,
      "loss": 0.0002,
      "step": 60700
    },
    {
      "epoch": 13.011144449207029,
      "grad_norm": 2.5618797735660337e-05,
      "learning_rate": 2.651807401057294e-06,
      "loss": 0.001,
      "step": 60710
    },
    {
      "epoch": 13.013287612516073,
      "grad_norm": 2.6537509256741032e-05,
      "learning_rate": 2.6489498499785687e-06,
      "loss": 0.0004,
      "step": 60720
    },
    {
      "epoch": 13.015430775825118,
      "grad_norm": 15.95223617553711,
      "learning_rate": 2.6460922988998435e-06,
      "loss": 0.0669,
      "step": 60730
    },
    {
      "epoch": 13.017573939134161,
      "grad_norm": 1.3857799785910174e-05,
      "learning_rate": 2.6432347478211174e-06,
      "loss": 0.0004,
      "step": 60740
    },
    {
      "epoch": 13.019717102443206,
      "grad_norm": 1.0317132364434656e-05,
      "learning_rate": 2.640377196742392e-06,
      "loss": 0.002,
      "step": 60750
    },
    {
      "epoch": 13.02186026575225,
      "grad_norm": 3.1738112738821656e-05,
      "learning_rate": 2.6375196456636666e-06,
      "loss": 0.0,
      "step": 60760
    },
    {
      "epoch": 13.024003429061294,
      "grad_norm": 8.522559255652595e-06,
      "learning_rate": 2.634662094584941e-06,
      "loss": 0.0,
      "step": 60770
    },
    {
      "epoch": 13.026146592370338,
      "grad_norm": 8.637854989501648e-06,
      "learning_rate": 2.6318045435062157e-06,
      "loss": 0.0,
      "step": 60780
    },
    {
      "epoch": 13.028289755679383,
      "grad_norm": 8.077745405898895e-06,
      "learning_rate": 2.6289469924274896e-06,
      "loss": 0.0,
      "step": 60790
    },
    {
      "epoch": 13.030432918988426,
      "grad_norm": 1.242372854903806e-05,
      "learning_rate": 2.6260894413487644e-06,
      "loss": 0.0002,
      "step": 60800
    },
    {
      "epoch": 13.03257608229747,
      "grad_norm": 6.07801994192414e-05,
      "learning_rate": 2.6232318902700388e-06,
      "loss": 0.0,
      "step": 60810
    },
    {
      "epoch": 13.034719245606516,
      "grad_norm": 9.319383025285788e-06,
      "learning_rate": 2.6203743391913135e-06,
      "loss": 0.0,
      "step": 60820
    },
    {
      "epoch": 13.03686240891556,
      "grad_norm": 6.893532554386184e-05,
      "learning_rate": 2.617516788112588e-06,
      "loss": 0.0004,
      "step": 60830
    },
    {
      "epoch": 13.039005572224603,
      "grad_norm": 1.1194028957106639e-05,
      "learning_rate": 2.614659237033862e-06,
      "loss": 0.0,
      "step": 60840
    },
    {
      "epoch": 13.041148735533648,
      "grad_norm": 8.400927981710993e-06,
      "learning_rate": 2.6118016859551366e-06,
      "loss": 0.0,
      "step": 60850
    },
    {
      "epoch": 13.043291898842693,
      "grad_norm": 8.007930591702461e-05,
      "learning_rate": 2.608944134876411e-06,
      "loss": 0.0,
      "step": 60860
    },
    {
      "epoch": 13.045435062151736,
      "grad_norm": 6.614498488488607e-06,
      "learning_rate": 2.6060865837976857e-06,
      "loss": 0.0,
      "step": 60870
    },
    {
      "epoch": 13.04757822546078,
      "grad_norm": 7.783769433444832e-06,
      "learning_rate": 2.60322903271896e-06,
      "loss": 0.0001,
      "step": 60880
    },
    {
      "epoch": 13.049721388769825,
      "grad_norm": 1.4475353054876905e-05,
      "learning_rate": 2.600371481640235e-06,
      "loss": 0.0,
      "step": 60890
    },
    {
      "epoch": 13.051864552078868,
      "grad_norm": 1.4220868251868524e-05,
      "learning_rate": 2.5975139305615088e-06,
      "loss": 0.0,
      "step": 60900
    },
    {
      "epoch": 13.054007715387913,
      "grad_norm": 8.10440269560786e-06,
      "learning_rate": 2.5946563794827835e-06,
      "loss": 0.0,
      "step": 60910
    },
    {
      "epoch": 13.056150878696958,
      "grad_norm": 7.938011549413204e-06,
      "learning_rate": 2.591798828404058e-06,
      "loss": 0.0,
      "step": 60920
    },
    {
      "epoch": 13.058294042006,
      "grad_norm": 9.454087376070675e-06,
      "learning_rate": 2.5889412773253327e-06,
      "loss": 0.0,
      "step": 60930
    },
    {
      "epoch": 13.060437205315045,
      "grad_norm": 0.0010446538217365742,
      "learning_rate": 2.586083726246607e-06,
      "loss": 0.0007,
      "step": 60940
    },
    {
      "epoch": 13.06258036862409,
      "grad_norm": 0.0004037967009935528,
      "learning_rate": 2.583226175167881e-06,
      "loss": 0.025,
      "step": 60950
    },
    {
      "epoch": 13.064723531933133,
      "grad_norm": 7.830592039681505e-06,
      "learning_rate": 2.5803686240891557e-06,
      "loss": 0.0,
      "step": 60960
    },
    {
      "epoch": 13.066866695242178,
      "grad_norm": 6.474363999586785e-06,
      "learning_rate": 2.57751107301043e-06,
      "loss": 0.0001,
      "step": 60970
    },
    {
      "epoch": 13.069009858551222,
      "grad_norm": 9.105066055781208e-06,
      "learning_rate": 2.574653521931705e-06,
      "loss": 0.0,
      "step": 60980
    },
    {
      "epoch": 13.071153021860265,
      "grad_norm": 9.465697075938806e-06,
      "learning_rate": 2.571795970852979e-06,
      "loss": 0.0,
      "step": 60990
    },
    {
      "epoch": 13.07329618516931,
      "grad_norm": 1.0951264812320005e-05,
      "learning_rate": 2.5689384197742536e-06,
      "loss": 0.0,
      "step": 61000
    },
    {
      "epoch": 13.075439348478355,
      "grad_norm": 6.8249764808570035e-06,
      "learning_rate": 2.566080868695528e-06,
      "loss": 0.0,
      "step": 61010
    },
    {
      "epoch": 13.077582511787398,
      "grad_norm": 8.01904116087826e-06,
      "learning_rate": 2.5632233176168027e-06,
      "loss": 0.0,
      "step": 61020
    },
    {
      "epoch": 13.079725675096443,
      "grad_norm": 7.727077172603458e-05,
      "learning_rate": 2.560365766538077e-06,
      "loss": 0.0,
      "step": 61030
    },
    {
      "epoch": 13.081868838405487,
      "grad_norm": 6.160988050396554e-06,
      "learning_rate": 2.557508215459352e-06,
      "loss": 0.0,
      "step": 61040
    },
    {
      "epoch": 13.08401200171453,
      "grad_norm": 0.00031889835372567177,
      "learning_rate": 2.554650664380626e-06,
      "loss": 0.0,
      "step": 61050
    },
    {
      "epoch": 13.086155165023575,
      "grad_norm": 8.052891644183546e-06,
      "learning_rate": 2.5517931133019e-06,
      "loss": 0.0,
      "step": 61060
    },
    {
      "epoch": 13.08829832833262,
      "grad_norm": 4.866217204835266e-05,
      "learning_rate": 2.548935562223175e-06,
      "loss": 0.0,
      "step": 61070
    },
    {
      "epoch": 13.090441491641663,
      "grad_norm": 7.56058725528419e-05,
      "learning_rate": 2.5460780111444492e-06,
      "loss": 0.0,
      "step": 61080
    },
    {
      "epoch": 13.092584654950707,
      "grad_norm": 9.456709085498005e-05,
      "learning_rate": 2.543220460065724e-06,
      "loss": 0.0,
      "step": 61090
    },
    {
      "epoch": 13.094727818259752,
      "grad_norm": 7.23236053090659e-06,
      "learning_rate": 2.5403629089869983e-06,
      "loss": 0.0,
      "step": 61100
    },
    {
      "epoch": 13.096870981568795,
      "grad_norm": 0.0001265818573301658,
      "learning_rate": 2.5375053579082727e-06,
      "loss": 0.0,
      "step": 61110
    },
    {
      "epoch": 13.09901414487784,
      "grad_norm": 8.62641682033427e-05,
      "learning_rate": 2.534647806829547e-06,
      "loss": 0.0,
      "step": 61120
    },
    {
      "epoch": 13.101157308186885,
      "grad_norm": 6.81351957609877e-06,
      "learning_rate": 2.531790255750822e-06,
      "loss": 0.0,
      "step": 61130
    },
    {
      "epoch": 13.103300471495928,
      "grad_norm": 6.430021585401846e-06,
      "learning_rate": 2.528932704672096e-06,
      "loss": 0.0,
      "step": 61140
    },
    {
      "epoch": 13.105443634804972,
      "grad_norm": 1.0818511327670421e-05,
      "learning_rate": 2.526075153593371e-06,
      "loss": 0.0,
      "step": 61150
    },
    {
      "epoch": 13.107586798114017,
      "grad_norm": 7.929890671221074e-06,
      "learning_rate": 2.5232176025146453e-06,
      "loss": 0.0,
      "step": 61160
    },
    {
      "epoch": 13.10972996142306,
      "grad_norm": 0.00018607781385071576,
      "learning_rate": 2.5203600514359192e-06,
      "loss": 0.0,
      "step": 61170
    },
    {
      "epoch": 13.111873124732105,
      "grad_norm": 6.544762072735466e-06,
      "learning_rate": 2.517502500357194e-06,
      "loss": 0.0,
      "step": 61180
    },
    {
      "epoch": 13.11401628804115,
      "grad_norm": 7.758802894386463e-06,
      "learning_rate": 2.5146449492784688e-06,
      "loss": 0.0,
      "step": 61190
    },
    {
      "epoch": 13.116159451350192,
      "grad_norm": 7.724601891823113e-05,
      "learning_rate": 2.511787398199743e-06,
      "loss": 0.0,
      "step": 61200
    },
    {
      "epoch": 13.118302614659237,
      "grad_norm": 6.030708391335793e-06,
      "learning_rate": 2.508929847121018e-06,
      "loss": 0.0,
      "step": 61210
    },
    {
      "epoch": 13.120445777968282,
      "grad_norm": 8.505731784680393e-06,
      "learning_rate": 2.506072296042292e-06,
      "loss": 0.0,
      "step": 61220
    },
    {
      "epoch": 13.122588941277325,
      "grad_norm": 2.7249547201790847e-05,
      "learning_rate": 2.503214744963566e-06,
      "loss": 0.0,
      "step": 61230
    },
    {
      "epoch": 13.12473210458637,
      "grad_norm": 6.8949175329180434e-06,
      "learning_rate": 2.500357193884841e-06,
      "loss": 0.0,
      "step": 61240
    },
    {
      "epoch": 13.126875267895414,
      "grad_norm": 8.470471584587358e-06,
      "learning_rate": 2.4974996428061153e-06,
      "loss": 0.0,
      "step": 61250
    },
    {
      "epoch": 13.129018431204457,
      "grad_norm": 7.825253305782098e-06,
      "learning_rate": 2.4946420917273897e-06,
      "loss": 0.0,
      "step": 61260
    },
    {
      "epoch": 13.131161594513502,
      "grad_norm": 5.787353074993007e-06,
      "learning_rate": 2.4917845406486644e-06,
      "loss": 0.0,
      "step": 61270
    },
    {
      "epoch": 13.133304757822547,
      "grad_norm": 0.00012157275341451168,
      "learning_rate": 2.488926989569939e-06,
      "loss": 0.0,
      "step": 61280
    },
    {
      "epoch": 13.13544792113159,
      "grad_norm": 4.921163781546056e-05,
      "learning_rate": 2.486069438491213e-06,
      "loss": 0.0,
      "step": 61290
    },
    {
      "epoch": 13.137591084440635,
      "grad_norm": 4.994562186766416e-05,
      "learning_rate": 2.483211887412488e-06,
      "loss": 0.0,
      "step": 61300
    },
    {
      "epoch": 13.13973424774968,
      "grad_norm": 7.139772151276702e-06,
      "learning_rate": 2.480354336333762e-06,
      "loss": 0.0,
      "step": 61310
    },
    {
      "epoch": 13.141877411058722,
      "grad_norm": 7.408518740703585e-06,
      "learning_rate": 2.4774967852550366e-06,
      "loss": 0.0,
      "step": 61320
    },
    {
      "epoch": 13.144020574367767,
      "grad_norm": 6.353555363602936e-05,
      "learning_rate": 2.4746392341763114e-06,
      "loss": 0.0,
      "step": 61330
    },
    {
      "epoch": 13.146163737676812,
      "grad_norm": 8.275964319182094e-06,
      "learning_rate": 2.4717816830975853e-06,
      "loss": 0.0002,
      "step": 61340
    },
    {
      "epoch": 13.148306900985855,
      "grad_norm": 9.683823918749113e-06,
      "learning_rate": 2.46892413201886e-06,
      "loss": 0.0,
      "step": 61350
    },
    {
      "epoch": 13.1504500642949,
      "grad_norm": 0.001372391590848565,
      "learning_rate": 2.4660665809401345e-06,
      "loss": 0.0,
      "step": 61360
    },
    {
      "epoch": 13.152593227603944,
      "grad_norm": 7.486056802008534e-06,
      "learning_rate": 2.463209029861409e-06,
      "loss": 0.0,
      "step": 61370
    },
    {
      "epoch": 13.154736390912987,
      "grad_norm": 6.7430919443722814e-06,
      "learning_rate": 2.4603514787826836e-06,
      "loss": 0.0,
      "step": 61380
    },
    {
      "epoch": 13.156879554222032,
      "grad_norm": 8.686068213137332e-06,
      "learning_rate": 2.457493927703958e-06,
      "loss": 0.0,
      "step": 61390
    },
    {
      "epoch": 13.159022717531077,
      "grad_norm": 8.214635272452142e-06,
      "learning_rate": 2.4546363766252323e-06,
      "loss": 0.0,
      "step": 61400
    },
    {
      "epoch": 13.16116588084012,
      "grad_norm": 5.617762781184865e-06,
      "learning_rate": 2.451778825546507e-06,
      "loss": 0.0,
      "step": 61410
    },
    {
      "epoch": 13.163309044149164,
      "grad_norm": 9.330480679636821e-06,
      "learning_rate": 2.4489212744677814e-06,
      "loss": 0.0,
      "step": 61420
    },
    {
      "epoch": 13.165452207458209,
      "grad_norm": 6.074518751120195e-06,
      "learning_rate": 2.4460637233890558e-06,
      "loss": 0.0,
      "step": 61430
    },
    {
      "epoch": 13.167595370767252,
      "grad_norm": 5.873094414710067e-05,
      "learning_rate": 2.4432061723103305e-06,
      "loss": 0.0,
      "step": 61440
    },
    {
      "epoch": 13.169738534076297,
      "grad_norm": 9.584944200469181e-05,
      "learning_rate": 2.4403486212316045e-06,
      "loss": 0.0,
      "step": 61450
    },
    {
      "epoch": 13.171881697385341,
      "grad_norm": 3.369943078723736e-05,
      "learning_rate": 2.4374910701528792e-06,
      "loss": 0.0,
      "step": 61460
    },
    {
      "epoch": 13.174024860694384,
      "grad_norm": 7.823819942132104e-06,
      "learning_rate": 2.4346335190741536e-06,
      "loss": 0.0,
      "step": 61470
    },
    {
      "epoch": 13.17616802400343,
      "grad_norm": 0.00010195775394095108,
      "learning_rate": 2.431775967995428e-06,
      "loss": 0.0,
      "step": 61480
    },
    {
      "epoch": 13.178311187312474,
      "grad_norm": 6.821864371886477e-05,
      "learning_rate": 2.4289184169167027e-06,
      "loss": 0.0,
      "step": 61490
    },
    {
      "epoch": 13.180454350621517,
      "grad_norm": 6.054744972061599e-06,
      "learning_rate": 2.426060865837977e-06,
      "loss": 0.0,
      "step": 61500
    },
    {
      "epoch": 13.182597513930562,
      "grad_norm": 6.046808721293928e-06,
      "learning_rate": 2.4232033147592514e-06,
      "loss": 0.0,
      "step": 61510
    },
    {
      "epoch": 13.184740677239606,
      "grad_norm": 6.660898179688957e-06,
      "learning_rate": 2.420345763680526e-06,
      "loss": 0.0,
      "step": 61520
    },
    {
      "epoch": 13.18688384054865,
      "grad_norm": 3.597229442675598e-05,
      "learning_rate": 2.4174882126018006e-06,
      "loss": 0.0,
      "step": 61530
    },
    {
      "epoch": 13.189027003857694,
      "grad_norm": 6.753481102350634e-06,
      "learning_rate": 2.414630661523075e-06,
      "loss": 0.0,
      "step": 61540
    },
    {
      "epoch": 13.191170167166739,
      "grad_norm": 3.911140811396763e-05,
      "learning_rate": 2.4117731104443493e-06,
      "loss": 0.0,
      "step": 61550
    },
    {
      "epoch": 13.193313330475782,
      "grad_norm": 1.0765712431748398e-05,
      "learning_rate": 2.408915559365624e-06,
      "loss": 0.0,
      "step": 61560
    },
    {
      "epoch": 13.195456493784826,
      "grad_norm": 6.1610389820998535e-06,
      "learning_rate": 2.4060580082868984e-06,
      "loss": 0.0,
      "step": 61570
    },
    {
      "epoch": 13.197599657093871,
      "grad_norm": 7.77524764998816e-05,
      "learning_rate": 2.4032004572081727e-06,
      "loss": 0.0,
      "step": 61580
    },
    {
      "epoch": 13.199742820402914,
      "grad_norm": 7.596779596497072e-06,
      "learning_rate": 2.400342906129447e-06,
      "loss": 0.0,
      "step": 61590
    },
    {
      "epoch": 13.201885983711959,
      "grad_norm": 4.983576582162641e-05,
      "learning_rate": 2.397485355050722e-06,
      "loss": 0.2717,
      "step": 61600
    },
    {
      "epoch": 13.204029147021004,
      "grad_norm": 2.71501576207811e-05,
      "learning_rate": 2.3946278039719962e-06,
      "loss": 0.0,
      "step": 61610
    },
    {
      "epoch": 13.206172310330047,
      "grad_norm": 7.473826372006442e-06,
      "learning_rate": 2.3917702528932706e-06,
      "loss": 0.0,
      "step": 61620
    },
    {
      "epoch": 13.208315473639091,
      "grad_norm": 2.7017418688046746e-05,
      "learning_rate": 2.3889127018145453e-06,
      "loss": 0.0,
      "step": 61630
    },
    {
      "epoch": 13.210458636948136,
      "grad_norm": 16.35671043395996,
      "learning_rate": 2.3860551507358197e-06,
      "loss": 0.0504,
      "step": 61640
    },
    {
      "epoch": 13.212601800257179,
      "grad_norm": 4.605920548783615e-05,
      "learning_rate": 2.383197599657094e-06,
      "loss": 0.0,
      "step": 61650
    },
    {
      "epoch": 13.214744963566224,
      "grad_norm": 7.459371772711165e-06,
      "learning_rate": 2.3803400485783684e-06,
      "loss": 0.0,
      "step": 61660
    },
    {
      "epoch": 13.216888126875268,
      "grad_norm": 1.7695105270831846e-05,
      "learning_rate": 2.377482497499643e-06,
      "loss": 0.0001,
      "step": 61670
    },
    {
      "epoch": 13.219031290184311,
      "grad_norm": 6.252825642150128e-06,
      "learning_rate": 2.3746249464209175e-06,
      "loss": 0.0,
      "step": 61680
    },
    {
      "epoch": 13.221174453493356,
      "grad_norm": 6.227989160834113e-06,
      "learning_rate": 2.371767395342192e-06,
      "loss": 0.0002,
      "step": 61690
    },
    {
      "epoch": 13.223317616802401,
      "grad_norm": 3.486197965685278e-05,
      "learning_rate": 2.3689098442634662e-06,
      "loss": 0.0,
      "step": 61700
    },
    {
      "epoch": 13.225460780111444,
      "grad_norm": 8.242873263952788e-06,
      "learning_rate": 2.366052293184741e-06,
      "loss": 0.0,
      "step": 61710
    },
    {
      "epoch": 13.227603943420489,
      "grad_norm": 5.8480298321228474e-05,
      "learning_rate": 2.3631947421060154e-06,
      "loss": 0.0,
      "step": 61720
    },
    {
      "epoch": 13.229747106729533,
      "grad_norm": 9.139120265899692e-06,
      "learning_rate": 2.3603371910272897e-06,
      "loss": 0.0707,
      "step": 61730
    },
    {
      "epoch": 13.231890270038576,
      "grad_norm": 0.0026132112834602594,
      "learning_rate": 2.357479639948564e-06,
      "loss": 0.0,
      "step": 61740
    },
    {
      "epoch": 13.234033433347621,
      "grad_norm": 3.476666097412817e-05,
      "learning_rate": 2.354622088869839e-06,
      "loss": 0.0,
      "step": 61750
    },
    {
      "epoch": 13.236176596656666,
      "grad_norm": 6.730996574333403e-06,
      "learning_rate": 2.351764537791113e-06,
      "loss": 0.0,
      "step": 61760
    },
    {
      "epoch": 13.238319759965709,
      "grad_norm": 2.0954050341970287e-05,
      "learning_rate": 2.3489069867123875e-06,
      "loss": 0.0,
      "step": 61770
    },
    {
      "epoch": 13.240462923274753,
      "grad_norm": 9.761803084984422e-06,
      "learning_rate": 2.3460494356336623e-06,
      "loss": 0.0,
      "step": 61780
    },
    {
      "epoch": 13.242606086583798,
      "grad_norm": 9.202749424730428e-06,
      "learning_rate": 2.3431918845549367e-06,
      "loss": 0.0,
      "step": 61790
    },
    {
      "epoch": 13.244749249892841,
      "grad_norm": 6.18800504526007e-06,
      "learning_rate": 2.340334333476211e-06,
      "loss": 0.0,
      "step": 61800
    },
    {
      "epoch": 13.246892413201886,
      "grad_norm": 9.958358532458078e-06,
      "learning_rate": 2.337476782397486e-06,
      "loss": 0.0,
      "step": 61810
    },
    {
      "epoch": 13.24903557651093,
      "grad_norm": 9.308832886745222e-06,
      "learning_rate": 2.3346192313187597e-06,
      "loss": 0.0,
      "step": 61820
    },
    {
      "epoch": 13.251178739819974,
      "grad_norm": 6.480120191554306e-06,
      "learning_rate": 2.3317616802400345e-06,
      "loss": 0.0,
      "step": 61830
    },
    {
      "epoch": 13.253321903129018,
      "grad_norm": 9.104134733206593e-06,
      "learning_rate": 2.328904129161309e-06,
      "loss": 0.0,
      "step": 61840
    },
    {
      "epoch": 13.255465066438063,
      "grad_norm": 4.4624557631323114e-05,
      "learning_rate": 2.326046578082583e-06,
      "loss": 0.0,
      "step": 61850
    },
    {
      "epoch": 13.257608229747106,
      "grad_norm": 1.0505461432330776e-05,
      "learning_rate": 2.323189027003858e-06,
      "loss": 0.0,
      "step": 61860
    },
    {
      "epoch": 13.25975139305615,
      "grad_norm": 8.004684787010774e-06,
      "learning_rate": 2.3203314759251323e-06,
      "loss": 0.0,
      "step": 61870
    },
    {
      "epoch": 13.261894556365196,
      "grad_norm": 9.716730346553959e-06,
      "learning_rate": 2.3174739248464067e-06,
      "loss": 0.0,
      "step": 61880
    },
    {
      "epoch": 13.264037719674239,
      "grad_norm": 1.2775655704899691e-05,
      "learning_rate": 2.3146163737676815e-06,
      "loss": 0.0,
      "step": 61890
    },
    {
      "epoch": 13.266180882983283,
      "grad_norm": 0.29061681032180786,
      "learning_rate": 2.311758822688956e-06,
      "loss": 0.0002,
      "step": 61900
    },
    {
      "epoch": 13.268324046292328,
      "grad_norm": 6.293621936492855e-06,
      "learning_rate": 2.30890127161023e-06,
      "loss": 0.0,
      "step": 61910
    },
    {
      "epoch": 13.270467209601371,
      "grad_norm": 6.475008831330342e-06,
      "learning_rate": 2.306043720531505e-06,
      "loss": 0.0,
      "step": 61920
    },
    {
      "epoch": 13.272610372910416,
      "grad_norm": 0.9097699522972107,
      "learning_rate": 2.303186169452779e-06,
      "loss": 0.0017,
      "step": 61930
    },
    {
      "epoch": 13.27475353621946,
      "grad_norm": 6.734874659741763e-06,
      "learning_rate": 2.3003286183740536e-06,
      "loss": 0.0,
      "step": 61940
    },
    {
      "epoch": 13.276896699528503,
      "grad_norm": 5.7209463193430565e-06,
      "learning_rate": 2.2974710672953284e-06,
      "loss": 0.0,
      "step": 61950
    },
    {
      "epoch": 13.279039862837548,
      "grad_norm": 6.768186267436249e-06,
      "learning_rate": 2.2946135162166023e-06,
      "loss": 0.0,
      "step": 61960
    },
    {
      "epoch": 13.281183026146593,
      "grad_norm": 5.9931840041826945e-06,
      "learning_rate": 2.291755965137877e-06,
      "loss": 0.0,
      "step": 61970
    },
    {
      "epoch": 13.283326189455636,
      "grad_norm": 0.14741943776607513,
      "learning_rate": 2.2888984140591515e-06,
      "loss": 0.1084,
      "step": 61980
    },
    {
      "epoch": 13.28546935276468,
      "grad_norm": 6.1228920458233915e-06,
      "learning_rate": 2.286040862980426e-06,
      "loss": 0.0,
      "step": 61990
    },
    {
      "epoch": 13.287612516073725,
      "grad_norm": 7.660781193408184e-06,
      "learning_rate": 2.2831833119017006e-06,
      "loss": 0.1068,
      "step": 62000
    },
    {
      "epoch": 13.289755679382768,
      "grad_norm": 1.676720057730563e-05,
      "learning_rate": 2.280325760822975e-06,
      "loss": 0.0,
      "step": 62010
    },
    {
      "epoch": 13.291898842691813,
      "grad_norm": 7.730989636911545e-06,
      "learning_rate": 2.2774682097442493e-06,
      "loss": 0.0,
      "step": 62020
    },
    {
      "epoch": 13.294042006000858,
      "grad_norm": 8.053625606407877e-06,
      "learning_rate": 2.274610658665524e-06,
      "loss": 0.0,
      "step": 62030
    },
    {
      "epoch": 13.2961851693099,
      "grad_norm": 1.2171185517217964e-05,
      "learning_rate": 2.2717531075867984e-06,
      "loss": 0.0,
      "step": 62040
    },
    {
      "epoch": 13.298328332618945,
      "grad_norm": 8.724606232135557e-06,
      "learning_rate": 2.2688955565080728e-06,
      "loss": 0.0,
      "step": 62050
    },
    {
      "epoch": 13.30047149592799,
      "grad_norm": 7.93435719970148e-06,
      "learning_rate": 2.266038005429347e-06,
      "loss": 0.0,
      "step": 62060
    },
    {
      "epoch": 13.302614659237033,
      "grad_norm": 1.6200410755118355e-05,
      "learning_rate": 2.2631804543506215e-06,
      "loss": 0.0,
      "step": 62070
    },
    {
      "epoch": 13.304757822546078,
      "grad_norm": 5.9277567743265536e-06,
      "learning_rate": 2.2603229032718963e-06,
      "loss": 0.0,
      "step": 62080
    },
    {
      "epoch": 13.306900985855123,
      "grad_norm": 8.530048035026994e-06,
      "learning_rate": 2.2574653521931706e-06,
      "loss": 0.0,
      "step": 62090
    },
    {
      "epoch": 13.309044149164166,
      "grad_norm": 8.806257028481923e-06,
      "learning_rate": 2.254607801114445e-06,
      "loss": 0.0,
      "step": 62100
    },
    {
      "epoch": 13.31118731247321,
      "grad_norm": 5.5042633903212845e-05,
      "learning_rate": 2.2517502500357197e-06,
      "loss": 0.0003,
      "step": 62110
    },
    {
      "epoch": 13.313330475782255,
      "grad_norm": 7.076543261064216e-05,
      "learning_rate": 2.248892698956994e-06,
      "loss": 0.0,
      "step": 62120
    },
    {
      "epoch": 13.315473639091298,
      "grad_norm": 7.886124876677059e-06,
      "learning_rate": 2.2460351478782684e-06,
      "loss": 0.0034,
      "step": 62130
    },
    {
      "epoch": 13.317616802400343,
      "grad_norm": 36.63650894165039,
      "learning_rate": 2.2431775967995432e-06,
      "loss": 0.079,
      "step": 62140
    },
    {
      "epoch": 13.319759965709387,
      "grad_norm": 8.5412348198588e-06,
      "learning_rate": 2.2403200457208176e-06,
      "loss": 0.0,
      "step": 62150
    },
    {
      "epoch": 13.32190312901843,
      "grad_norm": 7.707596523687243e-06,
      "learning_rate": 2.237462494642092e-06,
      "loss": 0.0,
      "step": 62160
    },
    {
      "epoch": 13.324046292327475,
      "grad_norm": 6.795584340579808e-06,
      "learning_rate": 2.2346049435633663e-06,
      "loss": 0.0,
      "step": 62170
    },
    {
      "epoch": 13.32618945563652,
      "grad_norm": 7.332274435611907e-06,
      "learning_rate": 2.231747392484641e-06,
      "loss": 0.0,
      "step": 62180
    },
    {
      "epoch": 13.328332618945563,
      "grad_norm": 8.082181921054143e-06,
      "learning_rate": 2.2288898414059154e-06,
      "loss": 0.0,
      "step": 62190
    },
    {
      "epoch": 13.330475782254608,
      "grad_norm": 6.15257795288926e-06,
      "learning_rate": 2.2260322903271897e-06,
      "loss": 0.0,
      "step": 62200
    },
    {
      "epoch": 13.332618945563652,
      "grad_norm": 6.633276825596113e-06,
      "learning_rate": 2.223174739248464e-06,
      "loss": 0.0,
      "step": 62210
    },
    {
      "epoch": 13.334762108872695,
      "grad_norm": 5.426511052064598e-06,
      "learning_rate": 2.220317188169739e-06,
      "loss": 0.0027,
      "step": 62220
    },
    {
      "epoch": 13.33690527218174,
      "grad_norm": 9.182302164845169e-06,
      "learning_rate": 2.2174596370910132e-06,
      "loss": 0.0,
      "step": 62230
    },
    {
      "epoch": 13.339048435490785,
      "grad_norm": 9.28013560042018e-06,
      "learning_rate": 2.2146020860122876e-06,
      "loss": 0.0,
      "step": 62240
    },
    {
      "epoch": 13.341191598799828,
      "grad_norm": 3.209037458873354e-05,
      "learning_rate": 2.211744534933562e-06,
      "loss": 0.0,
      "step": 62250
    },
    {
      "epoch": 13.343334762108872,
      "grad_norm": 3.4588167181937024e-05,
      "learning_rate": 2.2088869838548367e-06,
      "loss": 0.0,
      "step": 62260
    },
    {
      "epoch": 13.345477925417917,
      "grad_norm": 6.440586730604991e-06,
      "learning_rate": 2.206029432776111e-06,
      "loss": 0.0,
      "step": 62270
    },
    {
      "epoch": 13.34762108872696,
      "grad_norm": 5.586582119576633e-06,
      "learning_rate": 2.2031718816973854e-06,
      "loss": 0.0,
      "step": 62280
    },
    {
      "epoch": 13.349764252036005,
      "grad_norm": 6.437059710151516e-06,
      "learning_rate": 2.20031433061866e-06,
      "loss": 0.0,
      "step": 62290
    },
    {
      "epoch": 13.35190741534505,
      "grad_norm": 6.334402769425651e-06,
      "learning_rate": 2.1974567795399345e-06,
      "loss": 0.0,
      "step": 62300
    },
    {
      "epoch": 13.354050578654093,
      "grad_norm": 8.173552487278357e-06,
      "learning_rate": 2.194599228461209e-06,
      "loss": 0.0,
      "step": 62310
    },
    {
      "epoch": 13.356193741963137,
      "grad_norm": 6.07782521910849e-06,
      "learning_rate": 2.1917416773824832e-06,
      "loss": 0.0,
      "step": 62320
    },
    {
      "epoch": 13.358336905272182,
      "grad_norm": 5.742203029512893e-06,
      "learning_rate": 2.1888841263037576e-06,
      "loss": 0.0,
      "step": 62330
    },
    {
      "epoch": 13.360480068581225,
      "grad_norm": 6.860446774226148e-06,
      "learning_rate": 2.1860265752250324e-06,
      "loss": 0.0,
      "step": 62340
    },
    {
      "epoch": 13.36262323189027,
      "grad_norm": 9.142955605057068e-06,
      "learning_rate": 2.1831690241463067e-06,
      "loss": 0.0002,
      "step": 62350
    },
    {
      "epoch": 13.364766395199315,
      "grad_norm": 6.0938855312997475e-06,
      "learning_rate": 2.180311473067581e-06,
      "loss": 0.0,
      "step": 62360
    },
    {
      "epoch": 13.366909558508357,
      "grad_norm": 0.0001048727790475823,
      "learning_rate": 2.177453921988856e-06,
      "loss": 0.0,
      "step": 62370
    },
    {
      "epoch": 13.369052721817402,
      "grad_norm": 5.890524789720075e-06,
      "learning_rate": 2.17459637091013e-06,
      "loss": 0.0,
      "step": 62380
    },
    {
      "epoch": 13.371195885126447,
      "grad_norm": 7.219634881039383e-06,
      "learning_rate": 2.1717388198314045e-06,
      "loss": 0.0,
      "step": 62390
    },
    {
      "epoch": 13.37333904843549,
      "grad_norm": 8.809178325464018e-06,
      "learning_rate": 2.1688812687526793e-06,
      "loss": 0.0,
      "step": 62400
    },
    {
      "epoch": 13.375482211744535,
      "grad_norm": 1.040098777593812e-05,
      "learning_rate": 2.1660237176739537e-06,
      "loss": 0.0002,
      "step": 62410
    },
    {
      "epoch": 13.37762537505358,
      "grad_norm": 8.677270670887083e-06,
      "learning_rate": 2.163166166595228e-06,
      "loss": 0.0,
      "step": 62420
    },
    {
      "epoch": 13.379768538362622,
      "grad_norm": 7.229543371067848e-06,
      "learning_rate": 2.160308615516503e-06,
      "loss": 0.0,
      "step": 62430
    },
    {
      "epoch": 13.381911701671667,
      "grad_norm": 9.251263691112399e-06,
      "learning_rate": 2.1574510644377767e-06,
      "loss": 0.0,
      "step": 62440
    },
    {
      "epoch": 13.384054864980712,
      "grad_norm": 1.8983286281581968e-05,
      "learning_rate": 2.1545935133590515e-06,
      "loss": 0.0,
      "step": 62450
    },
    {
      "epoch": 13.386198028289755,
      "grad_norm": 7.51580319047207e-06,
      "learning_rate": 2.151735962280326e-06,
      "loss": 0.0,
      "step": 62460
    },
    {
      "epoch": 13.3883411915988,
      "grad_norm": 6.119878435129067e-06,
      "learning_rate": 2.1488784112016e-06,
      "loss": 0.0,
      "step": 62470
    },
    {
      "epoch": 13.390484354907844,
      "grad_norm": 4.8831574531504884e-05,
      "learning_rate": 2.146020860122875e-06,
      "loss": 0.0,
      "step": 62480
    },
    {
      "epoch": 13.392627518216887,
      "grad_norm": 6.295402272371575e-06,
      "learning_rate": 2.1431633090441493e-06,
      "loss": 0.0,
      "step": 62490
    },
    {
      "epoch": 13.394770681525932,
      "grad_norm": 4.3814099626615644e-05,
      "learning_rate": 2.1403057579654237e-06,
      "loss": 0.0,
      "step": 62500
    },
    {
      "epoch": 13.396913844834977,
      "grad_norm": 6.317144652712159e-06,
      "learning_rate": 2.1374482068866985e-06,
      "loss": 0.0,
      "step": 62510
    },
    {
      "epoch": 13.39905700814402,
      "grad_norm": 5.834935109305661e-06,
      "learning_rate": 2.134590655807973e-06,
      "loss": 0.0,
      "step": 62520
    },
    {
      "epoch": 13.401200171453064,
      "grad_norm": 5.836846412421437e-06,
      "learning_rate": 2.131733104729247e-06,
      "loss": 0.0,
      "step": 62530
    },
    {
      "epoch": 13.40334333476211,
      "grad_norm": 6.262368515308481e-06,
      "learning_rate": 2.128875553650522e-06,
      "loss": 0.0,
      "step": 62540
    },
    {
      "epoch": 13.405486498071152,
      "grad_norm": 1.602496013219934e-05,
      "learning_rate": 2.126018002571796e-06,
      "loss": 0.0,
      "step": 62550
    },
    {
      "epoch": 13.407629661380197,
      "grad_norm": 5.888091891392833e-06,
      "learning_rate": 2.1231604514930706e-06,
      "loss": 0.0,
      "step": 62560
    },
    {
      "epoch": 13.409772824689242,
      "grad_norm": 7.491764790756861e-06,
      "learning_rate": 2.120302900414345e-06,
      "loss": 0.0,
      "step": 62570
    },
    {
      "epoch": 13.411915987998286,
      "grad_norm": 5.8642044677981175e-06,
      "learning_rate": 2.1174453493356193e-06,
      "loss": 0.0,
      "step": 62580
    },
    {
      "epoch": 13.41405915130733,
      "grad_norm": 5.662345756718423e-06,
      "learning_rate": 2.114587798256894e-06,
      "loss": 0.0001,
      "step": 62590
    },
    {
      "epoch": 13.416202314616374,
      "grad_norm": 6.100033260736382e-06,
      "learning_rate": 2.1117302471781685e-06,
      "loss": 0.0,
      "step": 62600
    },
    {
      "epoch": 13.418345477925419,
      "grad_norm": 9.138314635492861e-05,
      "learning_rate": 2.108872696099443e-06,
      "loss": 0.0,
      "step": 62610
    },
    {
      "epoch": 13.420488641234462,
      "grad_norm": 6.343678705889033e-06,
      "learning_rate": 2.1060151450207176e-06,
      "loss": 0.0,
      "step": 62620
    },
    {
      "epoch": 13.422631804543506,
      "grad_norm": 7.124023795768153e-06,
      "learning_rate": 2.103157593941992e-06,
      "loss": 0.0,
      "step": 62630
    },
    {
      "epoch": 13.424774967852551,
      "grad_norm": 6.899556410644436e-06,
      "learning_rate": 2.1003000428632663e-06,
      "loss": 0.0,
      "step": 62640
    },
    {
      "epoch": 13.426918131161594,
      "grad_norm": 5.747624527430162e-06,
      "learning_rate": 2.097442491784541e-06,
      "loss": 0.0,
      "step": 62650
    },
    {
      "epoch": 13.429061294470639,
      "grad_norm": 0.013501976616680622,
      "learning_rate": 2.0945849407058154e-06,
      "loss": 0.0,
      "step": 62660
    },
    {
      "epoch": 13.431204457779684,
      "grad_norm": 2.9490169254131615e-05,
      "learning_rate": 2.0917273896270898e-06,
      "loss": 0.0,
      "step": 62670
    },
    {
      "epoch": 13.433347621088727,
      "grad_norm": 0.00021874840604141355,
      "learning_rate": 2.088869838548364e-06,
      "loss": 0.0,
      "step": 62680
    },
    {
      "epoch": 13.435490784397771,
      "grad_norm": 7.908018233138137e-06,
      "learning_rate": 2.0860122874696385e-06,
      "loss": 0.0012,
      "step": 62690
    },
    {
      "epoch": 13.437633947706816,
      "grad_norm": 6.095717708376469e-06,
      "learning_rate": 2.0831547363909133e-06,
      "loss": 0.0,
      "step": 62700
    },
    {
      "epoch": 13.439777111015859,
      "grad_norm": 5.00703239440918,
      "learning_rate": 2.0802971853121876e-06,
      "loss": 0.0079,
      "step": 62710
    },
    {
      "epoch": 13.441920274324904,
      "grad_norm": 5.2450504881562665e-06,
      "learning_rate": 2.077439634233462e-06,
      "loss": 0.0,
      "step": 62720
    },
    {
      "epoch": 13.444063437633949,
      "grad_norm": 5.8427620388101786e-05,
      "learning_rate": 2.0745820831547367e-06,
      "loss": 0.0,
      "step": 62730
    },
    {
      "epoch": 13.446206600942991,
      "grad_norm": 2.0214225514791906e-05,
      "learning_rate": 2.071724532076011e-06,
      "loss": 0.0,
      "step": 62740
    },
    {
      "epoch": 13.448349764252036,
      "grad_norm": 5.559996225201758e-06,
      "learning_rate": 2.0688669809972854e-06,
      "loss": 0.0,
      "step": 62750
    },
    {
      "epoch": 13.450492927561081,
      "grad_norm": 6.806189958297182e-06,
      "learning_rate": 2.06600942991856e-06,
      "loss": 0.0,
      "step": 62760
    },
    {
      "epoch": 13.452636090870124,
      "grad_norm": 6.010932338540442e-06,
      "learning_rate": 2.0631518788398346e-06,
      "loss": 0.0,
      "step": 62770
    },
    {
      "epoch": 13.454779254179169,
      "grad_norm": 5.6381045396847185e-06,
      "learning_rate": 2.060294327761109e-06,
      "loss": 0.0,
      "step": 62780
    },
    {
      "epoch": 13.456922417488213,
      "grad_norm": 6.175665475893766e-06,
      "learning_rate": 2.0574367766823833e-06,
      "loss": 0.0,
      "step": 62790
    },
    {
      "epoch": 13.459065580797256,
      "grad_norm": 6.155472874525003e-06,
      "learning_rate": 2.054579225603658e-06,
      "loss": 0.0,
      "step": 62800
    },
    {
      "epoch": 13.461208744106301,
      "grad_norm": 6.279286935750861e-06,
      "learning_rate": 2.0517216745249324e-06,
      "loss": 0.0,
      "step": 62810
    },
    {
      "epoch": 13.463351907415346,
      "grad_norm": 3.0517359846271574e-05,
      "learning_rate": 2.0488641234462068e-06,
      "loss": 0.0,
      "step": 62820
    },
    {
      "epoch": 13.465495070724389,
      "grad_norm": 5.795010110887233e-06,
      "learning_rate": 2.046006572367481e-06,
      "loss": 0.0,
      "step": 62830
    },
    {
      "epoch": 13.467638234033434,
      "grad_norm": 0.0002540486748330295,
      "learning_rate": 2.0431490212887555e-06,
      "loss": 0.0,
      "step": 62840
    },
    {
      "epoch": 13.469781397342478,
      "grad_norm": 6.25426309852628e-06,
      "learning_rate": 2.0402914702100302e-06,
      "loss": 0.0012,
      "step": 62850
    },
    {
      "epoch": 13.471924560651521,
      "grad_norm": 4.0758583054412156e-05,
      "learning_rate": 2.0374339191313046e-06,
      "loss": 0.0,
      "step": 62860
    },
    {
      "epoch": 13.474067723960566,
      "grad_norm": 1.876530222943984e-05,
      "learning_rate": 2.034576368052579e-06,
      "loss": 0.0,
      "step": 62870
    },
    {
      "epoch": 13.47621088726961,
      "grad_norm": 5.871153462067014e-06,
      "learning_rate": 2.0317188169738537e-06,
      "loss": 0.0,
      "step": 62880
    },
    {
      "epoch": 13.478354050578654,
      "grad_norm": 1.0739657227532007e-05,
      "learning_rate": 2.028861265895128e-06,
      "loss": 0.0,
      "step": 62890
    },
    {
      "epoch": 13.480497213887698,
      "grad_norm": 5.9345775298425e-06,
      "learning_rate": 2.0260037148164024e-06,
      "loss": 0.0,
      "step": 62900
    },
    {
      "epoch": 13.482640377196743,
      "grad_norm": 0.0003201025538146496,
      "learning_rate": 2.023146163737677e-06,
      "loss": 0.0,
      "step": 62910
    },
    {
      "epoch": 13.484783540505786,
      "grad_norm": 5.9254221014271025e-06,
      "learning_rate": 2.020288612658951e-06,
      "loss": 0.0,
      "step": 62920
    },
    {
      "epoch": 13.48692670381483,
      "grad_norm": 2.6451196390553378e-05,
      "learning_rate": 2.017431061580226e-06,
      "loss": 0.0,
      "step": 62930
    },
    {
      "epoch": 13.489069867123876,
      "grad_norm": 6.134933300927514e-06,
      "learning_rate": 2.0145735105015007e-06,
      "loss": 0.0,
      "step": 62940
    },
    {
      "epoch": 13.491213030432919,
      "grad_norm": 7.94494008005131e-06,
      "learning_rate": 2.0117159594227746e-06,
      "loss": 0.0,
      "step": 62950
    },
    {
      "epoch": 13.493356193741963,
      "grad_norm": 5.459751264424995e-06,
      "learning_rate": 2.0088584083440494e-06,
      "loss": 0.0,
      "step": 62960
    },
    {
      "epoch": 13.495499357051008,
      "grad_norm": 5.38155381946126e-06,
      "learning_rate": 2.0060008572653237e-06,
      "loss": 0.0,
      "step": 62970
    },
    {
      "epoch": 13.497642520360051,
      "grad_norm": 6.443747679441003e-06,
      "learning_rate": 2.003143306186598e-06,
      "loss": 0.0,
      "step": 62980
    },
    {
      "epoch": 13.499785683669096,
      "grad_norm": 4.269450073479675e-05,
      "learning_rate": 2.000285755107873e-06,
      "loss": 0.0,
      "step": 62990
    },
    {
      "epoch": 13.50192884697814,
      "grad_norm": 5.7007077884918544e-06,
      "learning_rate": 1.997428204029147e-06,
      "loss": 0.0,
      "step": 63000
    },
    {
      "epoch": 13.504072010287183,
      "grad_norm": 5.531158876692643e-06,
      "learning_rate": 1.9945706529504216e-06,
      "loss": 0.0,
      "step": 63010
    },
    {
      "epoch": 13.506215173596228,
      "grad_norm": 5.594886260951171e-06,
      "learning_rate": 1.9917131018716963e-06,
      "loss": 0.0,
      "step": 63020
    },
    {
      "epoch": 13.508358336905273,
      "grad_norm": 8.016506762942299e-05,
      "learning_rate": 1.9888555507929707e-06,
      "loss": 0.0,
      "step": 63030
    },
    {
      "epoch": 13.510501500214316,
      "grad_norm": 5.523801974050002e-06,
      "learning_rate": 1.985997999714245e-06,
      "loss": 0.0,
      "step": 63040
    },
    {
      "epoch": 13.51264466352336,
      "grad_norm": 7.423176157317357e-06,
      "learning_rate": 1.98314044863552e-06,
      "loss": 0.0,
      "step": 63050
    },
    {
      "epoch": 13.514787826832405,
      "grad_norm": 2.318656515853945e-05,
      "learning_rate": 1.9802828975567937e-06,
      "loss": 0.0,
      "step": 63060
    },
    {
      "epoch": 13.516930990141448,
      "grad_norm": 6.164761089166859e-06,
      "learning_rate": 1.9774253464780685e-06,
      "loss": 0.0,
      "step": 63070
    },
    {
      "epoch": 13.519074153450493,
      "grad_norm": 8.371822332264856e-06,
      "learning_rate": 1.974567795399343e-06,
      "loss": 0.0,
      "step": 63080
    },
    {
      "epoch": 13.521217316759538,
      "grad_norm": 6.087556812417461e-06,
      "learning_rate": 1.9717102443206172e-06,
      "loss": 0.0,
      "step": 63090
    },
    {
      "epoch": 13.52336048006858,
      "grad_norm": 5.763873559772037e-06,
      "learning_rate": 1.968852693241892e-06,
      "loss": 0.0,
      "step": 63100
    },
    {
      "epoch": 13.525503643377625,
      "grad_norm": 5.878308456885861e-06,
      "learning_rate": 1.9659951421631663e-06,
      "loss": 0.0,
      "step": 63110
    },
    {
      "epoch": 13.52764680668667,
      "grad_norm": 0.000921824190299958,
      "learning_rate": 1.9631375910844407e-06,
      "loss": 0.0012,
      "step": 63120
    },
    {
      "epoch": 13.529789969995713,
      "grad_norm": 1.565399179526139e-05,
      "learning_rate": 1.9602800400057155e-06,
      "loss": 0.3922,
      "step": 63130
    },
    {
      "epoch": 13.531933133304758,
      "grad_norm": 7.791387361066882e-06,
      "learning_rate": 1.95742248892699e-06,
      "loss": 0.0,
      "step": 63140
    },
    {
      "epoch": 13.534076296613803,
      "grad_norm": 5.750900072598597e-06,
      "learning_rate": 1.954564937848264e-06,
      "loss": 0.0,
      "step": 63150
    },
    {
      "epoch": 13.536219459922846,
      "grad_norm": 8.393452844757121e-06,
      "learning_rate": 1.951707386769539e-06,
      "loss": 0.0,
      "step": 63160
    },
    {
      "epoch": 13.53836262323189,
      "grad_norm": 7.994702173164114e-06,
      "learning_rate": 1.9488498356908133e-06,
      "loss": 0.0511,
      "step": 63170
    },
    {
      "epoch": 13.540505786540935,
      "grad_norm": 6.546981694555143e-06,
      "learning_rate": 1.9459922846120877e-06,
      "loss": 0.0,
      "step": 63180
    },
    {
      "epoch": 13.542648949849978,
      "grad_norm": 6.417526310542598e-05,
      "learning_rate": 1.943134733533362e-06,
      "loss": 0.0,
      "step": 63190
    },
    {
      "epoch": 13.544792113159023,
      "grad_norm": 5.988524208078161e-06,
      "learning_rate": 1.9402771824546364e-06,
      "loss": 0.1052,
      "step": 63200
    },
    {
      "epoch": 13.546935276468067,
      "grad_norm": 6.993890110607026e-06,
      "learning_rate": 1.937419631375911e-06,
      "loss": 0.0,
      "step": 63210
    },
    {
      "epoch": 13.54907843977711,
      "grad_norm": 7.723885573795997e-06,
      "learning_rate": 1.9345620802971855e-06,
      "loss": 0.0,
      "step": 63220
    },
    {
      "epoch": 13.551221603086155,
      "grad_norm": 6.506261797767365e-06,
      "learning_rate": 1.93170452921846e-06,
      "loss": 0.0,
      "step": 63230
    },
    {
      "epoch": 13.5533647663952,
      "grad_norm": 1.522911770734936e-05,
      "learning_rate": 1.9288469781397346e-06,
      "loss": 0.115,
      "step": 63240
    },
    {
      "epoch": 13.555507929704243,
      "grad_norm": 6.4098971961357165e-06,
      "learning_rate": 1.925989427061009e-06,
      "loss": 0.0,
      "step": 63250
    },
    {
      "epoch": 13.557651093013288,
      "grad_norm": 9.973465239454526e-06,
      "learning_rate": 1.9231318759822833e-06,
      "loss": 0.2619,
      "step": 63260
    },
    {
      "epoch": 13.559794256322332,
      "grad_norm": 4.313604949857108e-05,
      "learning_rate": 1.9202743249035577e-06,
      "loss": 0.0003,
      "step": 63270
    },
    {
      "epoch": 13.561937419631375,
      "grad_norm": 9.27470773604e-06,
      "learning_rate": 1.9174167738248324e-06,
      "loss": 0.0,
      "step": 63280
    },
    {
      "epoch": 13.56408058294042,
      "grad_norm": 1.0946740985673387e-05,
      "learning_rate": 1.914559222746107e-06,
      "loss": 0.0031,
      "step": 63290
    },
    {
      "epoch": 13.566223746249465,
      "grad_norm": 7.034926511551021e-06,
      "learning_rate": 1.911701671667381e-06,
      "loss": 0.0,
      "step": 63300
    },
    {
      "epoch": 13.568366909558508,
      "grad_norm": 1.2405082998157013e-05,
      "learning_rate": 1.9088441205886555e-06,
      "loss": 0.0,
      "step": 63310
    },
    {
      "epoch": 13.570510072867553,
      "grad_norm": 5.2528059313772246e-05,
      "learning_rate": 1.9059865695099303e-06,
      "loss": 0.0,
      "step": 63320
    },
    {
      "epoch": 13.572653236176597,
      "grad_norm": 8.208584040403366e-05,
      "learning_rate": 1.9031290184312046e-06,
      "loss": 0.0,
      "step": 63330
    },
    {
      "epoch": 13.57479639948564,
      "grad_norm": 6.031981683918275e-05,
      "learning_rate": 1.9002714673524792e-06,
      "loss": 0.0,
      "step": 63340
    },
    {
      "epoch": 13.576939562794685,
      "grad_norm": 7.929559615149628e-06,
      "learning_rate": 1.8974139162737533e-06,
      "loss": 0.0,
      "step": 63350
    },
    {
      "epoch": 13.57908272610373,
      "grad_norm": 6.657816265942529e-05,
      "learning_rate": 1.8945563651950281e-06,
      "loss": 0.0,
      "step": 63360
    },
    {
      "epoch": 13.581225889412773,
      "grad_norm": 0.0013079033233225346,
      "learning_rate": 1.8916988141163027e-06,
      "loss": 0.144,
      "step": 63370
    },
    {
      "epoch": 13.583369052721817,
      "grad_norm": 8.920233085518703e-06,
      "learning_rate": 1.8888412630375768e-06,
      "loss": 0.0,
      "step": 63380
    },
    {
      "epoch": 13.585512216030862,
      "grad_norm": 0.00015901024744380265,
      "learning_rate": 1.8859837119588514e-06,
      "loss": 0.0,
      "step": 63390
    },
    {
      "epoch": 13.587655379339905,
      "grad_norm": 0.0028304285369813442,
      "learning_rate": 1.883126160880126e-06,
      "loss": 0.0,
      "step": 63400
    },
    {
      "epoch": 13.58979854264895,
      "grad_norm": 4.580518725560978e-05,
      "learning_rate": 1.8802686098014003e-06,
      "loss": 0.0,
      "step": 63410
    },
    {
      "epoch": 13.591941705957995,
      "grad_norm": 7.055074092932045e-05,
      "learning_rate": 1.8774110587226749e-06,
      "loss": 0.0,
      "step": 63420
    },
    {
      "epoch": 13.594084869267038,
      "grad_norm": 1.1955021363974083e-05,
      "learning_rate": 1.8745535076439492e-06,
      "loss": 0.0,
      "step": 63430
    },
    {
      "epoch": 13.596228032576082,
      "grad_norm": 1.0415729775559157e-05,
      "learning_rate": 1.8716959565652238e-06,
      "loss": 0.0,
      "step": 63440
    },
    {
      "epoch": 13.598371195885127,
      "grad_norm": 1.9543449525372125e-05,
      "learning_rate": 1.8688384054864983e-06,
      "loss": 0.0,
      "step": 63450
    },
    {
      "epoch": 13.60051435919417,
      "grad_norm": 1.2857592992077116e-05,
      "learning_rate": 1.8659808544077727e-06,
      "loss": 0.3345,
      "step": 63460
    },
    {
      "epoch": 13.602657522503215,
      "grad_norm": 2.935368061065674,
      "learning_rate": 1.8631233033290472e-06,
      "loss": 0.1753,
      "step": 63470
    },
    {
      "epoch": 13.60480068581226,
      "grad_norm": 1.12243778858101e-05,
      "learning_rate": 1.8602657522503218e-06,
      "loss": 0.0,
      "step": 63480
    },
    {
      "epoch": 13.606943849121302,
      "grad_norm": 4.168982195551507e-05,
      "learning_rate": 1.857408201171596e-06,
      "loss": 0.0,
      "step": 63490
    },
    {
      "epoch": 13.609087012430347,
      "grad_norm": 1.7993825167650357e-05,
      "learning_rate": 1.8545506500928705e-06,
      "loss": 0.0,
      "step": 63500
    },
    {
      "epoch": 13.611230175739392,
      "grad_norm": 2.9722239560214803e-05,
      "learning_rate": 1.8516930990141449e-06,
      "loss": 0.0,
      "step": 63510
    },
    {
      "epoch": 13.613373339048435,
      "grad_norm": 0.0023107673041522503,
      "learning_rate": 1.8488355479354194e-06,
      "loss": 0.0,
      "step": 63520
    },
    {
      "epoch": 13.61551650235748,
      "grad_norm": 1.6131158190546557e-05,
      "learning_rate": 1.845977996856694e-06,
      "loss": 0.1429,
      "step": 63530
    },
    {
      "epoch": 13.617659665666524,
      "grad_norm": 0.0001621450501261279,
      "learning_rate": 1.8431204457779683e-06,
      "loss": 0.0,
      "step": 63540
    },
    {
      "epoch": 13.619802828975567,
      "grad_norm": 0.009921487420797348,
      "learning_rate": 1.840262894699243e-06,
      "loss": 0.0005,
      "step": 63550
    },
    {
      "epoch": 13.621945992284612,
      "grad_norm": 2.3714719645795412e-05,
      "learning_rate": 1.8374053436205175e-06,
      "loss": 0.0,
      "step": 63560
    },
    {
      "epoch": 13.624089155593657,
      "grad_norm": 0.0007437095628120005,
      "learning_rate": 1.8345477925417918e-06,
      "loss": 0.0,
      "step": 63570
    },
    {
      "epoch": 13.6262323189027,
      "grad_norm": 1.212164443131769e-05,
      "learning_rate": 1.8316902414630664e-06,
      "loss": 0.0,
      "step": 63580
    },
    {
      "epoch": 13.628375482211744,
      "grad_norm": 2.255011713714339e-05,
      "learning_rate": 1.8288326903843407e-06,
      "loss": 0.0,
      "step": 63590
    },
    {
      "epoch": 13.63051864552079,
      "grad_norm": 1.4607324374082964e-05,
      "learning_rate": 1.8259751393056153e-06,
      "loss": 0.0,
      "step": 63600
    },
    {
      "epoch": 13.632661808829832,
      "grad_norm": 1.4578734408132732e-05,
      "learning_rate": 1.8231175882268899e-06,
      "loss": 0.0,
      "step": 63610
    },
    {
      "epoch": 13.634804972138877,
      "grad_norm": 1.570491622260306e-05,
      "learning_rate": 1.820260037148164e-06,
      "loss": 0.0,
      "step": 63620
    },
    {
      "epoch": 13.636948135447922,
      "grad_norm": 1.5221958165057003e-05,
      "learning_rate": 1.8174024860694386e-06,
      "loss": 0.0,
      "step": 63630
    },
    {
      "epoch": 13.639091298756965,
      "grad_norm": 6.753394700353965e-05,
      "learning_rate": 1.8145449349907131e-06,
      "loss": 0.0,
      "step": 63640
    },
    {
      "epoch": 13.64123446206601,
      "grad_norm": 6.750193279003724e-05,
      "learning_rate": 1.8116873839119875e-06,
      "loss": 0.0,
      "step": 63650
    },
    {
      "epoch": 13.643377625375054,
      "grad_norm": 1.358622557745548e-05,
      "learning_rate": 1.808829832833262e-06,
      "loss": 0.0,
      "step": 63660
    },
    {
      "epoch": 13.645520788684097,
      "grad_norm": 1.9816636267933063e-05,
      "learning_rate": 1.8059722817545364e-06,
      "loss": 0.0,
      "step": 63670
    },
    {
      "epoch": 13.647663951993142,
      "grad_norm": 3.237617784179747e-05,
      "learning_rate": 1.803114730675811e-06,
      "loss": 0.0,
      "step": 63680
    },
    {
      "epoch": 13.649807115302186,
      "grad_norm": 1.4175233445712365e-05,
      "learning_rate": 1.8002571795970855e-06,
      "loss": 0.0,
      "step": 63690
    },
    {
      "epoch": 13.65195027861123,
      "grad_norm": 2.5752902729436755e-05,
      "learning_rate": 1.7973996285183599e-06,
      "loss": 0.0,
      "step": 63700
    },
    {
      "epoch": 13.654093441920274,
      "grad_norm": 3.172384458594024e-05,
      "learning_rate": 1.7945420774396344e-06,
      "loss": 0.0,
      "step": 63710
    },
    {
      "epoch": 13.656236605229319,
      "grad_norm": 2.832636710081715e-05,
      "learning_rate": 1.791684526360909e-06,
      "loss": 0.0,
      "step": 63720
    },
    {
      "epoch": 13.658379768538362,
      "grad_norm": 0.38933685421943665,
      "learning_rate": 1.7888269752821831e-06,
      "loss": 0.0007,
      "step": 63730
    },
    {
      "epoch": 13.660522931847407,
      "grad_norm": 1.616163717699237e-05,
      "learning_rate": 1.7859694242034577e-06,
      "loss": 0.0,
      "step": 63740
    },
    {
      "epoch": 13.662666095156451,
      "grad_norm": 7.079464558046311e-05,
      "learning_rate": 1.7831118731247325e-06,
      "loss": 0.0,
      "step": 63750
    },
    {
      "epoch": 13.664809258465494,
      "grad_norm": 3.067057332373224e-05,
      "learning_rate": 1.7802543220460066e-06,
      "loss": 0.0,
      "step": 63760
    },
    {
      "epoch": 13.666952421774539,
      "grad_norm": 1.4803764315729495e-05,
      "learning_rate": 1.7773967709672812e-06,
      "loss": 0.0001,
      "step": 63770
    },
    {
      "epoch": 13.669095585083584,
      "grad_norm": 0.00013030240370426327,
      "learning_rate": 1.7745392198885555e-06,
      "loss": 0.0,
      "step": 63780
    },
    {
      "epoch": 13.671238748392627,
      "grad_norm": 4.224472650093958e-05,
      "learning_rate": 1.77168166880983e-06,
      "loss": 0.0,
      "step": 63790
    },
    {
      "epoch": 13.673381911701671,
      "grad_norm": 1.3843437045579776e-05,
      "learning_rate": 1.7688241177311047e-06,
      "loss": 0.0,
      "step": 63800
    },
    {
      "epoch": 13.675525075010716,
      "grad_norm": 0.00015610206173732877,
      "learning_rate": 1.765966566652379e-06,
      "loss": 0.0,
      "step": 63810
    },
    {
      "epoch": 13.67766823831976,
      "grad_norm": 2.399969525868073e-05,
      "learning_rate": 1.7631090155736536e-06,
      "loss": 0.0001,
      "step": 63820
    },
    {
      "epoch": 13.679811401628804,
      "grad_norm": 1.6490856069140136e-05,
      "learning_rate": 1.7602514644949281e-06,
      "loss": 0.0024,
      "step": 63830
    },
    {
      "epoch": 13.681954564937849,
      "grad_norm": 5.032687113271095e-05,
      "learning_rate": 1.7573939134162025e-06,
      "loss": 0.0857,
      "step": 63840
    },
    {
      "epoch": 13.684097728246892,
      "grad_norm": 6.47505876258947e-05,
      "learning_rate": 1.754536362337477e-06,
      "loss": 0.0,
      "step": 63850
    },
    {
      "epoch": 13.686240891555936,
      "grad_norm": 1.2568075362651143e-05,
      "learning_rate": 1.7516788112587512e-06,
      "loss": 0.0,
      "step": 63860
    },
    {
      "epoch": 13.688384054864981,
      "grad_norm": 6.601161294383928e-05,
      "learning_rate": 1.7488212601800258e-06,
      "loss": 0.0009,
      "step": 63870
    },
    {
      "epoch": 13.690527218174024,
      "grad_norm": 2.627202593430411e-05,
      "learning_rate": 1.7459637091013003e-06,
      "loss": 0.1074,
      "step": 63880
    },
    {
      "epoch": 13.692670381483069,
      "grad_norm": 1.1888847438967787e-05,
      "learning_rate": 1.7431061580225747e-06,
      "loss": 0.0,
      "step": 63890
    },
    {
      "epoch": 13.694813544792114,
      "grad_norm": 2.5435536372242495e-05,
      "learning_rate": 1.7402486069438492e-06,
      "loss": 0.0,
      "step": 63900
    },
    {
      "epoch": 13.696956708101157,
      "grad_norm": 7.535345503129065e-05,
      "learning_rate": 1.7373910558651238e-06,
      "loss": 0.0,
      "step": 63910
    },
    {
      "epoch": 13.699099871410201,
      "grad_norm": 4.9430669605499133e-05,
      "learning_rate": 1.7345335047863982e-06,
      "loss": 0.0,
      "step": 63920
    },
    {
      "epoch": 13.701243034719246,
      "grad_norm": 1.298087681789184e-05,
      "learning_rate": 1.7316759537076727e-06,
      "loss": 0.0,
      "step": 63930
    },
    {
      "epoch": 13.703386198028289,
      "grad_norm": 1.3735527318203822e-05,
      "learning_rate": 1.728818402628947e-06,
      "loss": 0.0,
      "step": 63940
    },
    {
      "epoch": 13.705529361337334,
      "grad_norm": 1.1735364751075394e-05,
      "learning_rate": 1.7259608515502216e-06,
      "loss": 0.0,
      "step": 63950
    },
    {
      "epoch": 13.707672524646378,
      "grad_norm": 7.047611143207178e-05,
      "learning_rate": 1.7231033004714962e-06,
      "loss": 0.0,
      "step": 63960
    },
    {
      "epoch": 13.709815687955421,
      "grad_norm": 2.3443655663868412e-05,
      "learning_rate": 1.7202457493927703e-06,
      "loss": 0.0,
      "step": 63970
    },
    {
      "epoch": 13.711958851264466,
      "grad_norm": 1.0471295354363974e-05,
      "learning_rate": 1.7173881983140451e-06,
      "loss": 0.0,
      "step": 63980
    },
    {
      "epoch": 13.71410201457351,
      "grad_norm": 0.00023051537573337555,
      "learning_rate": 1.7145306472353197e-06,
      "loss": 0.0,
      "step": 63990
    },
    {
      "epoch": 13.716245177882554,
      "grad_norm": 2.1146021026652306e-05,
      "learning_rate": 1.7116730961565938e-06,
      "loss": 0.0148,
      "step": 64000
    },
    {
      "epoch": 13.718388341191599,
      "grad_norm": 1.1858885955007281e-05,
      "learning_rate": 1.7088155450778684e-06,
      "loss": 0.0,
      "step": 64010
    },
    {
      "epoch": 13.720531504500643,
      "grad_norm": 1.3648837011714932e-05,
      "learning_rate": 1.7059579939991427e-06,
      "loss": 0.0,
      "step": 64020
    },
    {
      "epoch": 13.722674667809688,
      "grad_norm": 0.00014658681175205857,
      "learning_rate": 1.7031004429204173e-06,
      "loss": 0.0,
      "step": 64030
    },
    {
      "epoch": 13.724817831118731,
      "grad_norm": 3.239484431105666e-05,
      "learning_rate": 1.7002428918416919e-06,
      "loss": 0.0,
      "step": 64040
    },
    {
      "epoch": 13.726960994427776,
      "grad_norm": 9.319907985627651e-05,
      "learning_rate": 1.6973853407629662e-06,
      "loss": 0.0,
      "step": 64050
    },
    {
      "epoch": 13.72910415773682,
      "grad_norm": 1.4074986211198848e-05,
      "learning_rate": 1.6945277896842408e-06,
      "loss": 0.0,
      "step": 64060
    },
    {
      "epoch": 13.731247321045863,
      "grad_norm": 1.9596918718889356e-05,
      "learning_rate": 1.6916702386055153e-06,
      "loss": 0.0,
      "step": 64070
    },
    {
      "epoch": 13.733390484354908,
      "grad_norm": 1.4188607565301936e-05,
      "learning_rate": 1.6888126875267897e-06,
      "loss": 0.2742,
      "step": 64080
    },
    {
      "epoch": 13.735533647663953,
      "grad_norm": 1.0941152140730992e-05,
      "learning_rate": 1.6859551364480643e-06,
      "loss": 0.0,
      "step": 64090
    },
    {
      "epoch": 13.737676810972996,
      "grad_norm": 1.1582771549001336e-05,
      "learning_rate": 1.6830975853693384e-06,
      "loss": 0.0023,
      "step": 64100
    },
    {
      "epoch": 13.73981997428204,
      "grad_norm": 1.2006655197183136e-05,
      "learning_rate": 1.680240034290613e-06,
      "loss": 0.0,
      "step": 64110
    },
    {
      "epoch": 13.741963137591085,
      "grad_norm": 9.768841118784621e-05,
      "learning_rate": 1.6773824832118875e-06,
      "loss": 0.0,
      "step": 64120
    },
    {
      "epoch": 13.744106300900128,
      "grad_norm": 1.6521556972293183e-05,
      "learning_rate": 1.6745249321331619e-06,
      "loss": 0.0,
      "step": 64130
    },
    {
      "epoch": 13.746249464209173,
      "grad_norm": 1.0228342034679372e-05,
      "learning_rate": 1.6716673810544364e-06,
      "loss": 0.0,
      "step": 64140
    },
    {
      "epoch": 13.748392627518218,
      "grad_norm": 1.7249589291168377e-05,
      "learning_rate": 1.668809829975711e-06,
      "loss": 0.0891,
      "step": 64150
    },
    {
      "epoch": 13.75053579082726,
      "grad_norm": 2.0056844732607715e-05,
      "learning_rate": 1.6659522788969854e-06,
      "loss": 0.0027,
      "step": 64160
    },
    {
      "epoch": 13.752678954136305,
      "grad_norm": 7.737886335235089e-05,
      "learning_rate": 1.66309472781826e-06,
      "loss": 0.0,
      "step": 64170
    },
    {
      "epoch": 13.75482211744535,
      "grad_norm": 1.071612769010244e-05,
      "learning_rate": 1.6602371767395343e-06,
      "loss": 0.0,
      "step": 64180
    },
    {
      "epoch": 13.756965280754393,
      "grad_norm": 1.2049580618622713e-05,
      "learning_rate": 1.6573796256608088e-06,
      "loss": 0.0,
      "step": 64190
    },
    {
      "epoch": 13.759108444063438,
      "grad_norm": 1.2050802070007194e-05,
      "learning_rate": 1.6545220745820834e-06,
      "loss": 0.1033,
      "step": 64200
    },
    {
      "epoch": 13.761251607372483,
      "grad_norm": 4.06990475312341e-05,
      "learning_rate": 1.6516645235033577e-06,
      "loss": 0.0,
      "step": 64210
    },
    {
      "epoch": 13.763394770681526,
      "grad_norm": 1.3667897292179987e-05,
      "learning_rate": 1.6488069724246323e-06,
      "loss": 0.0,
      "step": 64220
    },
    {
      "epoch": 13.76553793399057,
      "grad_norm": 1.3741644579567946e-05,
      "learning_rate": 1.6459494213459069e-06,
      "loss": 0.0,
      "step": 64230
    },
    {
      "epoch": 13.767681097299615,
      "grad_norm": 1.235258696397068e-05,
      "learning_rate": 1.643091870267181e-06,
      "loss": 0.0,
      "step": 64240
    },
    {
      "epoch": 13.769824260608658,
      "grad_norm": 1.2216976756462827e-05,
      "learning_rate": 1.6402343191884556e-06,
      "loss": 0.0,
      "step": 64250
    },
    {
      "epoch": 13.771967423917703,
      "grad_norm": 2.8417118301149458e-05,
      "learning_rate": 1.6373767681097301e-06,
      "loss": 0.0,
      "step": 64260
    },
    {
      "epoch": 13.774110587226748,
      "grad_norm": 1.3251896234578453e-05,
      "learning_rate": 1.6345192170310045e-06,
      "loss": 0.0,
      "step": 64270
    },
    {
      "epoch": 13.77625375053579,
      "grad_norm": 1.6239278920693323e-05,
      "learning_rate": 1.631661665952279e-06,
      "loss": 0.0,
      "step": 64280
    },
    {
      "epoch": 13.778396913844835,
      "grad_norm": 1.2806710401491728e-05,
      "learning_rate": 1.6288041148735534e-06,
      "loss": 0.0,
      "step": 64290
    },
    {
      "epoch": 13.78054007715388,
      "grad_norm": 7.140984962461516e-05,
      "learning_rate": 1.625946563794828e-06,
      "loss": 0.0,
      "step": 64300
    },
    {
      "epoch": 13.782683240462923,
      "grad_norm": 1.1233583791181445e-05,
      "learning_rate": 1.6230890127161025e-06,
      "loss": 0.0,
      "step": 64310
    },
    {
      "epoch": 13.784826403771968,
      "grad_norm": 1.7687960280454718e-05,
      "learning_rate": 1.6202314616373769e-06,
      "loss": 0.0,
      "step": 64320
    },
    {
      "epoch": 13.786969567081012,
      "grad_norm": 1.3492712241713889e-05,
      "learning_rate": 1.6173739105586515e-06,
      "loss": 0.0,
      "step": 64330
    },
    {
      "epoch": 13.789112730390055,
      "grad_norm": 1.7402604498784058e-05,
      "learning_rate": 1.614516359479926e-06,
      "loss": 0.0,
      "step": 64340
    },
    {
      "epoch": 13.7912558936991,
      "grad_norm": 1.4339328117785044e-05,
      "learning_rate": 1.6116588084012002e-06,
      "loss": 0.0454,
      "step": 64350
    },
    {
      "epoch": 13.793399057008145,
      "grad_norm": 2.1560823370236903e-05,
      "learning_rate": 1.608801257322475e-06,
      "loss": 0.0,
      "step": 64360
    },
    {
      "epoch": 13.795542220317188,
      "grad_norm": 2.5954457669286057e-05,
      "learning_rate": 1.605943706243749e-06,
      "loss": 0.0,
      "step": 64370
    },
    {
      "epoch": 13.797685383626233,
      "grad_norm": 1.1615019502642099e-05,
      "learning_rate": 1.6030861551650236e-06,
      "loss": 0.0,
      "step": 64380
    },
    {
      "epoch": 13.799828546935277,
      "grad_norm": 1.1184448339918163e-05,
      "learning_rate": 1.6002286040862982e-06,
      "loss": 0.0011,
      "step": 64390
    },
    {
      "epoch": 13.80197171024432,
      "grad_norm": 1.4230740816856269e-05,
      "learning_rate": 1.5973710530075726e-06,
      "loss": 0.0009,
      "step": 64400
    },
    {
      "epoch": 13.804114873553365,
      "grad_norm": 0.0005849206354469061,
      "learning_rate": 1.5945135019288471e-06,
      "loss": 0.2783,
      "step": 64410
    },
    {
      "epoch": 13.80625803686241,
      "grad_norm": 4.50864972663112e-05,
      "learning_rate": 1.5916559508501217e-06,
      "loss": 0.0,
      "step": 64420
    },
    {
      "epoch": 13.808401200171453,
      "grad_norm": 1.2503684956755023e-05,
      "learning_rate": 1.588798399771396e-06,
      "loss": 0.0,
      "step": 64430
    },
    {
      "epoch": 13.810544363480497,
      "grad_norm": 1.8524558981880546e-05,
      "learning_rate": 1.5859408486926706e-06,
      "loss": 0.0,
      "step": 64440
    },
    {
      "epoch": 13.812687526789542,
      "grad_norm": 1.604102180863265e-05,
      "learning_rate": 1.583083297613945e-06,
      "loss": 0.1666,
      "step": 64450
    },
    {
      "epoch": 13.814830690098585,
      "grad_norm": 1.202872135763755e-05,
      "learning_rate": 1.5802257465352195e-06,
      "loss": 0.0,
      "step": 64460
    },
    {
      "epoch": 13.81697385340763,
      "grad_norm": 1.1464382623671554e-05,
      "learning_rate": 1.577368195456494e-06,
      "loss": 0.0001,
      "step": 64470
    },
    {
      "epoch": 13.819117016716675,
      "grad_norm": 1.332485226157587e-05,
      "learning_rate": 1.5745106443777682e-06,
      "loss": 0.0,
      "step": 64480
    },
    {
      "epoch": 13.821260180025718,
      "grad_norm": 0.00018441752763465047,
      "learning_rate": 1.5716530932990428e-06,
      "loss": 0.0,
      "step": 64490
    },
    {
      "epoch": 13.823403343334762,
      "grad_norm": 9.063251491170377e-05,
      "learning_rate": 1.5687955422203173e-06,
      "loss": 0.0,
      "step": 64500
    },
    {
      "epoch": 13.825546506643807,
      "grad_norm": 0.0009086612262763083,
      "learning_rate": 1.5659379911415917e-06,
      "loss": 0.0,
      "step": 64510
    },
    {
      "epoch": 13.82768966995285,
      "grad_norm": 0.00017282820772379637,
      "learning_rate": 1.5630804400628663e-06,
      "loss": 0.0952,
      "step": 64520
    },
    {
      "epoch": 13.829832833261895,
      "grad_norm": 1.58197435666807e-05,
      "learning_rate": 1.5602228889841406e-06,
      "loss": 0.0,
      "step": 64530
    },
    {
      "epoch": 13.83197599657094,
      "grad_norm": 0.00047319915029220283,
      "learning_rate": 1.5573653379054152e-06,
      "loss": 0.1013,
      "step": 64540
    },
    {
      "epoch": 13.834119159879982,
      "grad_norm": 1.6187401342904195e-05,
      "learning_rate": 1.5545077868266897e-06,
      "loss": 0.0,
      "step": 64550
    },
    {
      "epoch": 13.836262323189027,
      "grad_norm": 1.4572032341675367e-05,
      "learning_rate": 1.551650235747964e-06,
      "loss": 0.0,
      "step": 64560
    },
    {
      "epoch": 13.838405486498072,
      "grad_norm": 1.2662539120356087e-05,
      "learning_rate": 1.5487926846692386e-06,
      "loss": 0.0,
      "step": 64570
    },
    {
      "epoch": 13.840548649807115,
      "grad_norm": 1.0715316420828458e-05,
      "learning_rate": 1.5459351335905132e-06,
      "loss": 0.0006,
      "step": 64580
    },
    {
      "epoch": 13.84269181311616,
      "grad_norm": 1.7822168956627138e-05,
      "learning_rate": 1.5430775825117876e-06,
      "loss": 0.0,
      "step": 64590
    },
    {
      "epoch": 13.844834976425204,
      "grad_norm": 4.917987098451704e-05,
      "learning_rate": 1.5402200314330621e-06,
      "loss": 0.0005,
      "step": 64600
    },
    {
      "epoch": 13.846978139734247,
      "grad_norm": 1.4573396583728027e-05,
      "learning_rate": 1.5373624803543363e-06,
      "loss": 0.0,
      "step": 64610
    },
    {
      "epoch": 13.849121303043292,
      "grad_norm": 0.00033107007038779557,
      "learning_rate": 1.5345049292756108e-06,
      "loss": 0.0,
      "step": 64620
    },
    {
      "epoch": 13.851264466352337,
      "grad_norm": 9.94462170638144e-05,
      "learning_rate": 1.5316473781968854e-06,
      "loss": 0.0,
      "step": 64630
    },
    {
      "epoch": 13.85340762966138,
      "grad_norm": 1.1588565939746331e-05,
      "learning_rate": 1.5287898271181597e-06,
      "loss": 0.0,
      "step": 64640
    },
    {
      "epoch": 13.855550792970424,
      "grad_norm": 1.3698851944354828e-05,
      "learning_rate": 1.5259322760394343e-06,
      "loss": 0.0,
      "step": 64650
    },
    {
      "epoch": 13.85769395627947,
      "grad_norm": 1.35894679260673e-05,
      "learning_rate": 1.5230747249607089e-06,
      "loss": 0.0,
      "step": 64660
    },
    {
      "epoch": 13.859837119588512,
      "grad_norm": 0.001603972166776657,
      "learning_rate": 1.5202171738819832e-06,
      "loss": 0.0,
      "step": 64670
    },
    {
      "epoch": 13.861980282897557,
      "grad_norm": 1.11123927126755e-05,
      "learning_rate": 1.5173596228032578e-06,
      "loss": 0.0005,
      "step": 64680
    },
    {
      "epoch": 13.864123446206602,
      "grad_norm": 0.00012203362712170929,
      "learning_rate": 1.5145020717245321e-06,
      "loss": 0.0,
      "step": 64690
    },
    {
      "epoch": 13.866266609515645,
      "grad_norm": 3.68672153854277e-05,
      "learning_rate": 1.5116445206458067e-06,
      "loss": 0.0,
      "step": 64700
    },
    {
      "epoch": 13.86840977282469,
      "grad_norm": 1.984949631150812e-05,
      "learning_rate": 1.5087869695670813e-06,
      "loss": 0.0,
      "step": 64710
    },
    {
      "epoch": 13.870552936133734,
      "grad_norm": 6.416194082703441e-05,
      "learning_rate": 1.5059294184883554e-06,
      "loss": 0.0001,
      "step": 64720
    },
    {
      "epoch": 13.872696099442777,
      "grad_norm": 0.00015086021448951215,
      "learning_rate": 1.50307186740963e-06,
      "loss": 0.0001,
      "step": 64730
    },
    {
      "epoch": 13.874839262751822,
      "grad_norm": 1.1042367077607196e-05,
      "learning_rate": 1.5002143163309045e-06,
      "loss": 0.0,
      "step": 64740
    },
    {
      "epoch": 13.876982426060867,
      "grad_norm": 6.0942169511690736e-05,
      "learning_rate": 1.4973567652521789e-06,
      "loss": 0.0,
      "step": 64750
    },
    {
      "epoch": 13.87912558936991,
      "grad_norm": 1.9466948288027197e-05,
      "learning_rate": 1.4944992141734535e-06,
      "loss": 0.0,
      "step": 64760
    },
    {
      "epoch": 13.881268752678954,
      "grad_norm": 2.64241734839743e-05,
      "learning_rate": 1.491641663094728e-06,
      "loss": 0.0013,
      "step": 64770
    },
    {
      "epoch": 13.883411915987999,
      "grad_norm": 1.3525104805012234e-05,
      "learning_rate": 1.4887841120160024e-06,
      "loss": 0.0,
      "step": 64780
    },
    {
      "epoch": 13.885555079297042,
      "grad_norm": 0.00038188041071407497,
      "learning_rate": 1.485926560937277e-06,
      "loss": 0.0,
      "step": 64790
    },
    {
      "epoch": 13.887698242606087,
      "grad_norm": 1.742189851938747e-05,
      "learning_rate": 1.4830690098585513e-06,
      "loss": 0.0606,
      "step": 64800
    },
    {
      "epoch": 13.889841405915131,
      "grad_norm": 2.0362131181173027e-05,
      "learning_rate": 1.4802114587798258e-06,
      "loss": 0.1367,
      "step": 64810
    },
    {
      "epoch": 13.891984569224174,
      "grad_norm": 9.254143151338212e-06,
      "learning_rate": 1.4773539077011004e-06,
      "loss": 0.0,
      "step": 64820
    },
    {
      "epoch": 13.894127732533219,
      "grad_norm": 2.641117498569656e-05,
      "learning_rate": 1.4744963566223748e-06,
      "loss": 0.0,
      "step": 64830
    },
    {
      "epoch": 13.896270895842264,
      "grad_norm": 2.1611804186250083e-05,
      "learning_rate": 1.4716388055436493e-06,
      "loss": 0.0,
      "step": 64840
    },
    {
      "epoch": 13.898414059151307,
      "grad_norm": 1.7668193322606385e-05,
      "learning_rate": 1.4687812544649239e-06,
      "loss": 0.0006,
      "step": 64850
    },
    {
      "epoch": 13.900557222460352,
      "grad_norm": 1.4148619811749086e-05,
      "learning_rate": 1.465923703386198e-06,
      "loss": 0.1089,
      "step": 64860
    },
    {
      "epoch": 13.902700385769396,
      "grad_norm": 1.4800748431298416e-05,
      "learning_rate": 1.4630661523074726e-06,
      "loss": 0.0,
      "step": 64870
    },
    {
      "epoch": 13.90484354907844,
      "grad_norm": 0.00013040754129178822,
      "learning_rate": 1.460208601228747e-06,
      "loss": 0.0,
      "step": 64880
    },
    {
      "epoch": 13.906986712387484,
      "grad_norm": 0.0009408135083504021,
      "learning_rate": 1.4573510501500215e-06,
      "loss": 0.107,
      "step": 64890
    },
    {
      "epoch": 13.909129875696529,
      "grad_norm": 1.7800992281991057e-05,
      "learning_rate": 1.454493499071296e-06,
      "loss": 0.0005,
      "step": 64900
    },
    {
      "epoch": 13.911273039005572,
      "grad_norm": 1.6345044059562497e-05,
      "learning_rate": 1.4516359479925704e-06,
      "loss": 0.0,
      "step": 64910
    },
    {
      "epoch": 13.913416202314616,
      "grad_norm": 1.7118063624366187e-05,
      "learning_rate": 1.448778396913845e-06,
      "loss": 0.0,
      "step": 64920
    },
    {
      "epoch": 13.915559365623661,
      "grad_norm": 1.2383297871565446e-05,
      "learning_rate": 1.4459208458351195e-06,
      "loss": 0.3024,
      "step": 64930
    },
    {
      "epoch": 13.917702528932704,
      "grad_norm": 1.220507147081662e-05,
      "learning_rate": 1.443063294756394e-06,
      "loss": 0.0,
      "step": 64940
    },
    {
      "epoch": 13.919845692241749,
      "grad_norm": 0.0002991016663145274,
      "learning_rate": 1.4402057436776685e-06,
      "loss": 0.0019,
      "step": 64950
    },
    {
      "epoch": 13.921988855550794,
      "grad_norm": 2.3482665710616857e-05,
      "learning_rate": 1.4373481925989426e-06,
      "loss": 0.0,
      "step": 64960
    },
    {
      "epoch": 13.924132018859837,
      "grad_norm": 7.975207154231612e-06,
      "learning_rate": 1.4344906415202174e-06,
      "loss": 0.0,
      "step": 64970
    },
    {
      "epoch": 13.926275182168881,
      "grad_norm": 1.5930176232359372e-05,
      "learning_rate": 1.431633090441492e-06,
      "loss": 0.0,
      "step": 64980
    },
    {
      "epoch": 13.928418345477926,
      "grad_norm": 0.0008021143730729818,
      "learning_rate": 1.428775539362766e-06,
      "loss": 0.0,
      "step": 64990
    },
    {
      "epoch": 13.930561508786969,
      "grad_norm": 1.254980634257663e-05,
      "learning_rate": 1.4259179882840406e-06,
      "loss": 0.0013,
      "step": 65000
    },
    {
      "epoch": 13.932704672096014,
      "grad_norm": 1.1567343790375162e-05,
      "learning_rate": 1.4230604372053152e-06,
      "loss": 0.0,
      "step": 65010
    },
    {
      "epoch": 13.934847835405058,
      "grad_norm": 8.902091394702438e-06,
      "learning_rate": 1.4202028861265896e-06,
      "loss": 0.0,
      "step": 65020
    },
    {
      "epoch": 13.936990998714101,
      "grad_norm": 1.092991169571178e-05,
      "learning_rate": 1.4173453350478641e-06,
      "loss": 0.1376,
      "step": 65030
    },
    {
      "epoch": 13.939134162023146,
      "grad_norm": 1.5939212971716188e-05,
      "learning_rate": 1.4144877839691385e-06,
      "loss": 0.0,
      "step": 65040
    },
    {
      "epoch": 13.94127732533219,
      "grad_norm": 9.914641850627959e-06,
      "learning_rate": 1.411630232890413e-06,
      "loss": 0.0,
      "step": 65050
    },
    {
      "epoch": 13.943420488641234,
      "grad_norm": 0.0001434513251297176,
      "learning_rate": 1.4087726818116876e-06,
      "loss": 0.0,
      "step": 65060
    },
    {
      "epoch": 13.945563651950279,
      "grad_norm": 1.2272659660084173e-05,
      "learning_rate": 1.405915130732962e-06,
      "loss": 0.0,
      "step": 65070
    },
    {
      "epoch": 13.947706815259323,
      "grad_norm": 1.0748784916359e-05,
      "learning_rate": 1.4030575796542365e-06,
      "loss": 0.0,
      "step": 65080
    },
    {
      "epoch": 13.949849978568366,
      "grad_norm": 7.943130185594782e-05,
      "learning_rate": 1.400200028575511e-06,
      "loss": 0.0,
      "step": 65090
    },
    {
      "epoch": 13.951993141877411,
      "grad_norm": 0.0004047425463795662,
      "learning_rate": 1.3973424774967852e-06,
      "loss": 0.0,
      "step": 65100
    },
    {
      "epoch": 13.954136305186456,
      "grad_norm": 9.839717677095905e-06,
      "learning_rate": 1.3944849264180598e-06,
      "loss": 0.0,
      "step": 65110
    },
    {
      "epoch": 13.956279468495499,
      "grad_norm": 1.355924723611679e-05,
      "learning_rate": 1.3916273753393341e-06,
      "loss": 0.0,
      "step": 65120
    },
    {
      "epoch": 13.958422631804543,
      "grad_norm": 1.0526497135288082e-05,
      "learning_rate": 1.3887698242606087e-06,
      "loss": 0.0,
      "step": 65130
    },
    {
      "epoch": 13.960565795113588,
      "grad_norm": 1.4890807506162673e-05,
      "learning_rate": 1.3859122731818833e-06,
      "loss": 0.0,
      "step": 65140
    },
    {
      "epoch": 13.962708958422631,
      "grad_norm": 3.503153857309371e-05,
      "learning_rate": 1.3830547221031576e-06,
      "loss": 0.0,
      "step": 65150
    },
    {
      "epoch": 13.964852121731676,
      "grad_norm": 1.1652132343442645e-05,
      "learning_rate": 1.3801971710244322e-06,
      "loss": 0.0,
      "step": 65160
    },
    {
      "epoch": 13.96699528504072,
      "grad_norm": 1.1741351045202464e-05,
      "learning_rate": 1.3773396199457067e-06,
      "loss": 0.0,
      "step": 65170
    },
    {
      "epoch": 13.969138448349764,
      "grad_norm": 1.4677485523861833e-05,
      "learning_rate": 1.374482068866981e-06,
      "loss": 0.0006,
      "step": 65180
    },
    {
      "epoch": 13.971281611658808,
      "grad_norm": 1.140452513936907e-05,
      "learning_rate": 1.3716245177882557e-06,
      "loss": 0.0,
      "step": 65190
    },
    {
      "epoch": 13.973424774967853,
      "grad_norm": 9.56988787947921e-06,
      "learning_rate": 1.36876696670953e-06,
      "loss": 0.0,
      "step": 65200
    },
    {
      "epoch": 13.975567938276896,
      "grad_norm": 7.387084042420611e-05,
      "learning_rate": 1.3659094156308046e-06,
      "loss": 0.0,
      "step": 65210
    },
    {
      "epoch": 13.97771110158594,
      "grad_norm": 0.00036916552926413715,
      "learning_rate": 1.3630518645520791e-06,
      "loss": 0.0,
      "step": 65220
    },
    {
      "epoch": 13.979854264894986,
      "grad_norm": 1.1986600839009043e-05,
      "learning_rate": 1.3601943134733533e-06,
      "loss": 0.0,
      "step": 65230
    },
    {
      "epoch": 13.981997428204028,
      "grad_norm": 1.2635127859539352e-05,
      "learning_rate": 1.3573367623946278e-06,
      "loss": 0.098,
      "step": 65240
    },
    {
      "epoch": 13.984140591513073,
      "grad_norm": 1.242201506101992e-05,
      "learning_rate": 1.3544792113159024e-06,
      "loss": 0.0,
      "step": 65250
    },
    {
      "epoch": 13.986283754822118,
      "grad_norm": 0.00020409279386512935,
      "learning_rate": 1.3516216602371768e-06,
      "loss": 0.2012,
      "step": 65260
    },
    {
      "epoch": 13.988426918131161,
      "grad_norm": 0.00010217764065600932,
      "learning_rate": 1.3487641091584513e-06,
      "loss": 0.0,
      "step": 65270
    },
    {
      "epoch": 13.990570081440206,
      "grad_norm": 2.388794018770568e-05,
      "learning_rate": 1.3459065580797259e-06,
      "loss": 0.0,
      "step": 65280
    },
    {
      "epoch": 13.99271324474925,
      "grad_norm": 1.3339307770365849e-05,
      "learning_rate": 1.3430490070010002e-06,
      "loss": 0.0003,
      "step": 65290
    },
    {
      "epoch": 13.994856408058293,
      "grad_norm": 3.585748709156178e-05,
      "learning_rate": 1.3401914559222748e-06,
      "loss": 0.0011,
      "step": 65300
    },
    {
      "epoch": 13.996999571367338,
      "grad_norm": 1.8340364476898685e-05,
      "learning_rate": 1.3373339048435492e-06,
      "loss": 0.1021,
      "step": 65310
    },
    {
      "epoch": 13.999142734676383,
      "grad_norm": 1.552761568746064e-05,
      "learning_rate": 1.3344763537648237e-06,
      "loss": 0.0,
      "step": 65320
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9873333333333333,
      "eval_f1": 0.9349315068493151,
      "eval_loss": 0.13226959109306335,
      "eval_precision": 0.9612676056338029,
      "eval_recall": 0.91,
      "eval_runtime": 833.8463,
      "eval_samples_per_second": 3.598,
      "eval_steps_per_second": 1.199,
      "step": 65324
    }
  ],
  "logging_steps": 10,
  "max_steps": 69990,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5216945959524666e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
