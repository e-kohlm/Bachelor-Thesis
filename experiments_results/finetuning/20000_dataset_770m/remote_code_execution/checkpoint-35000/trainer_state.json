{
  "best_metric": 0.903225806451613,
  "best_model_checkpoint": "../saved_models/remote_code_execution_770/checkpoint-35000",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 35000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028571428571428574,
      "grad_norm": 84.25078582763672,
      "learning_rate": 1.999961904761905e-05,
      "loss": 1.2198,
      "step": 1
    },
    {
      "epoch": 0.002857142857142857,
      "grad_norm": 89.25782775878906,
      "learning_rate": 1.9996190476190477e-05,
      "loss": 0.4145,
      "step": 10
    },
    {
      "epoch": 0.005714285714285714,
      "grad_norm": 4.062402725219727,
      "learning_rate": 1.9992380952380953e-05,
      "loss": 0.5244,
      "step": 20
    },
    {
      "epoch": 0.008571428571428572,
      "grad_norm": 0.2011016458272934,
      "learning_rate": 1.9988571428571432e-05,
      "loss": 1.0745,
      "step": 30
    },
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 59.993553161621094,
      "learning_rate": 1.9984761904761907e-05,
      "loss": 0.6417,
      "step": 40
    },
    {
      "epoch": 0.014285714285714285,
      "grad_norm": 0.1754053682088852,
      "learning_rate": 1.9980952380952383e-05,
      "loss": 0.106,
      "step": 50
    },
    {
      "epoch": 0.017142857142857144,
      "grad_norm": 48.66507339477539,
      "learning_rate": 1.997714285714286e-05,
      "loss": 0.8952,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.046110741794109344,
      "learning_rate": 1.9973333333333334e-05,
      "loss": 0.7208,
      "step": 70
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 74.87274932861328,
      "learning_rate": 1.9969523809523813e-05,
      "loss": 0.5254,
      "step": 80
    },
    {
      "epoch": 0.025714285714285714,
      "grad_norm": 89.42598724365234,
      "learning_rate": 1.996571428571429e-05,
      "loss": 0.8822,
      "step": 90
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 0.956616997718811,
      "learning_rate": 1.9961904761904764e-05,
      "loss": 0.7758,
      "step": 100
    },
    {
      "epoch": 0.03142857142857143,
      "grad_norm": 0.33082500100135803,
      "learning_rate": 1.995809523809524e-05,
      "loss": 0.9174,
      "step": 110
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 1.5490036010742188,
      "learning_rate": 1.9954285714285715e-05,
      "loss": 0.7647,
      "step": 120
    },
    {
      "epoch": 0.037142857142857144,
      "grad_norm": 0.05433113873004913,
      "learning_rate": 1.995047619047619e-05,
      "loss": 0.3601,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 50.11719512939453,
      "learning_rate": 1.9946666666666667e-05,
      "loss": 0.411,
      "step": 140
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 0.2873600721359253,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 0.3658,
      "step": 150
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 0.4076616168022156,
      "learning_rate": 1.993904761904762e-05,
      "loss": 0.6412,
      "step": 160
    },
    {
      "epoch": 0.04857142857142857,
      "grad_norm": 54.491695404052734,
      "learning_rate": 1.9935238095238097e-05,
      "loss": 0.7645,
      "step": 170
    },
    {
      "epoch": 0.05142857142857143,
      "grad_norm": 0.057940732687711716,
      "learning_rate": 1.9931428571428572e-05,
      "loss": 0.2116,
      "step": 180
    },
    {
      "epoch": 0.054285714285714284,
      "grad_norm": 0.7918040156364441,
      "learning_rate": 1.9927619047619048e-05,
      "loss": 0.832,
      "step": 190
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 0.14167222380638123,
      "learning_rate": 1.9923809523809527e-05,
      "loss": 0.3715,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 63.88520812988281,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.8808,
      "step": 210
    },
    {
      "epoch": 0.06285714285714286,
      "grad_norm": 0.15374726057052612,
      "learning_rate": 1.9916190476190478e-05,
      "loss": 0.4592,
      "step": 220
    },
    {
      "epoch": 0.06571428571428571,
      "grad_norm": 33.62297058105469,
      "learning_rate": 1.9912380952380954e-05,
      "loss": 0.6613,
      "step": 230
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 36.19173812866211,
      "learning_rate": 1.990857142857143e-05,
      "loss": 0.5636,
      "step": 240
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 0.4786422848701477,
      "learning_rate": 1.9904761904761908e-05,
      "loss": 0.7256,
      "step": 250
    },
    {
      "epoch": 0.07428571428571429,
      "grad_norm": 27.04245948791504,
      "learning_rate": 1.9900952380952384e-05,
      "loss": 0.429,
      "step": 260
    },
    {
      "epoch": 0.07714285714285714,
      "grad_norm": 0.9129846096038818,
      "learning_rate": 1.989714285714286e-05,
      "loss": 0.6081,
      "step": 270
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.02484145574271679,
      "learning_rate": 1.9893333333333335e-05,
      "loss": 0.1462,
      "step": 280
    },
    {
      "epoch": 0.08285714285714285,
      "grad_norm": 31.725482940673828,
      "learning_rate": 1.988952380952381e-05,
      "loss": 0.6714,
      "step": 290
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 1.385628342628479,
      "learning_rate": 1.988571428571429e-05,
      "loss": 0.9388,
      "step": 300
    },
    {
      "epoch": 0.08857142857142856,
      "grad_norm": 0.0834205150604248,
      "learning_rate": 1.9881904761904765e-05,
      "loss": 0.2513,
      "step": 310
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 0.23724323511123657,
      "learning_rate": 1.987809523809524e-05,
      "loss": 0.5953,
      "step": 320
    },
    {
      "epoch": 0.09428571428571429,
      "grad_norm": 5.2892560958862305,
      "learning_rate": 1.9874285714285716e-05,
      "loss": 0.573,
      "step": 330
    },
    {
      "epoch": 0.09714285714285714,
      "grad_norm": 87.07234191894531,
      "learning_rate": 1.9870476190476192e-05,
      "loss": 0.4689,
      "step": 340
    },
    {
      "epoch": 0.1,
      "grad_norm": 47.83692169189453,
      "learning_rate": 1.9866666666666667e-05,
      "loss": 0.7992,
      "step": 350
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 28.47817611694336,
      "learning_rate": 1.9862857142857143e-05,
      "loss": 0.2944,
      "step": 360
    },
    {
      "epoch": 0.10571428571428572,
      "grad_norm": 46.94820785522461,
      "learning_rate": 1.985904761904762e-05,
      "loss": 0.6992,
      "step": 370
    },
    {
      "epoch": 0.10857142857142857,
      "grad_norm": 0.08941911160945892,
      "learning_rate": 1.9855238095238097e-05,
      "loss": 0.6739,
      "step": 380
    },
    {
      "epoch": 0.11142857142857143,
      "grad_norm": 0.5694489479064941,
      "learning_rate": 1.9851428571428573e-05,
      "loss": 0.4433,
      "step": 390
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.0491049587726593,
      "learning_rate": 1.984761904761905e-05,
      "loss": 0.6219,
      "step": 400
    },
    {
      "epoch": 0.11714285714285715,
      "grad_norm": 44.27484130859375,
      "learning_rate": 1.9843809523809524e-05,
      "loss": 0.6001,
      "step": 410
    },
    {
      "epoch": 0.12,
      "grad_norm": 40.774200439453125,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 0.6539,
      "step": 420
    },
    {
      "epoch": 0.12285714285714286,
      "grad_norm": 0.2571002244949341,
      "learning_rate": 1.983619047619048e-05,
      "loss": 0.5081,
      "step": 430
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 0.5556043386459351,
      "learning_rate": 1.9832380952380954e-05,
      "loss": 0.9552,
      "step": 440
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 39.853084564208984,
      "learning_rate": 1.982857142857143e-05,
      "loss": 0.5029,
      "step": 450
    },
    {
      "epoch": 0.13142857142857142,
      "grad_norm": 1.3318061828613281,
      "learning_rate": 1.9824761904761905e-05,
      "loss": 0.5786,
      "step": 460
    },
    {
      "epoch": 0.13428571428571429,
      "grad_norm": 31.99784278869629,
      "learning_rate": 1.9820952380952384e-05,
      "loss": 0.767,
      "step": 470
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 35.983394622802734,
      "learning_rate": 1.981714285714286e-05,
      "loss": 0.5643,
      "step": 480
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4420677125453949,
      "learning_rate": 1.9813333333333336e-05,
      "loss": 0.9597,
      "step": 490
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.08732369542121887,
      "learning_rate": 1.980952380952381e-05,
      "loss": 0.0046,
      "step": 500
    },
    {
      "epoch": 0.1457142857142857,
      "grad_norm": 0.03742500767111778,
      "learning_rate": 1.9805714285714287e-05,
      "loss": 0.6026,
      "step": 510
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 45.94509506225586,
      "learning_rate": 1.9801904761904766e-05,
      "loss": 0.7889,
      "step": 520
    },
    {
      "epoch": 0.15142857142857144,
      "grad_norm": 33.993221282958984,
      "learning_rate": 1.979809523809524e-05,
      "loss": 0.384,
      "step": 530
    },
    {
      "epoch": 0.15428571428571428,
      "grad_norm": 0.15617550909519196,
      "learning_rate": 1.9794285714285717e-05,
      "loss": 0.5407,
      "step": 540
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 43.87070846557617,
      "learning_rate": 1.9790476190476193e-05,
      "loss": 0.7277,
      "step": 550
    },
    {
      "epoch": 0.16,
      "grad_norm": 48.583621978759766,
      "learning_rate": 1.9786666666666668e-05,
      "loss": 0.5304,
      "step": 560
    },
    {
      "epoch": 0.16285714285714287,
      "grad_norm": 0.9249345064163208,
      "learning_rate": 1.9782857142857144e-05,
      "loss": 0.5367,
      "step": 570
    },
    {
      "epoch": 0.1657142857142857,
      "grad_norm": 24.678916931152344,
      "learning_rate": 1.977904761904762e-05,
      "loss": 0.4929,
      "step": 580
    },
    {
      "epoch": 0.16857142857142857,
      "grad_norm": 29.56648826599121,
      "learning_rate": 1.9775238095238095e-05,
      "loss": 0.6885,
      "step": 590
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 69.04790496826172,
      "learning_rate": 1.9771428571428574e-05,
      "loss": 0.8299,
      "step": 600
    },
    {
      "epoch": 0.1742857142857143,
      "grad_norm": 2.8688571453094482,
      "learning_rate": 1.976761904761905e-05,
      "loss": 0.7042,
      "step": 610
    },
    {
      "epoch": 0.17714285714285713,
      "grad_norm": 40.68878936767578,
      "learning_rate": 1.9763809523809525e-05,
      "loss": 0.7955,
      "step": 620
    },
    {
      "epoch": 0.18,
      "grad_norm": 22.45957374572754,
      "learning_rate": 1.976e-05,
      "loss": 0.5709,
      "step": 630
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 0.5819396376609802,
      "learning_rate": 1.9756190476190476e-05,
      "loss": 0.5195,
      "step": 640
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 0.0763365849852562,
      "learning_rate": 1.9752380952380955e-05,
      "loss": 0.5212,
      "step": 650
    },
    {
      "epoch": 0.18857142857142858,
      "grad_norm": 30.810258865356445,
      "learning_rate": 1.974857142857143e-05,
      "loss": 0.581,
      "step": 660
    },
    {
      "epoch": 0.19142857142857142,
      "grad_norm": 0.852252185344696,
      "learning_rate": 1.9744761904761906e-05,
      "loss": 0.6839,
      "step": 670
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 0.5583157539367676,
      "learning_rate": 1.9740952380952382e-05,
      "loss": 0.5026,
      "step": 680
    },
    {
      "epoch": 0.19714285714285715,
      "grad_norm": 21.651491165161133,
      "learning_rate": 1.973714285714286e-05,
      "loss": 0.6929,
      "step": 690
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7086730003356934,
      "learning_rate": 1.9733333333333336e-05,
      "loss": 0.4896,
      "step": 700
    },
    {
      "epoch": 0.20285714285714285,
      "grad_norm": 0.12095259130001068,
      "learning_rate": 1.9729523809523812e-05,
      "loss": 0.283,
      "step": 710
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 0.1649549901485443,
      "learning_rate": 1.9725714285714288e-05,
      "loss": 0.4808,
      "step": 720
    },
    {
      "epoch": 0.20857142857142857,
      "grad_norm": 0.08280225098133087,
      "learning_rate": 1.9721904761904763e-05,
      "loss": 0.0017,
      "step": 730
    },
    {
      "epoch": 0.21142857142857144,
      "grad_norm": 0.037765149027109146,
      "learning_rate": 1.9718095238095242e-05,
      "loss": 0.5428,
      "step": 740
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 1.569373607635498,
      "learning_rate": 1.9714285714285718e-05,
      "loss": 1.2951,
      "step": 750
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 0.32663020491600037,
      "learning_rate": 1.971047619047619e-05,
      "loss": 0.3711,
      "step": 760
    },
    {
      "epoch": 0.22,
      "grad_norm": 19.072956085205078,
      "learning_rate": 1.970666666666667e-05,
      "loss": 0.5251,
      "step": 770
    },
    {
      "epoch": 0.22285714285714286,
      "grad_norm": 0.3722932040691376,
      "learning_rate": 1.9702857142857144e-05,
      "loss": 0.7315,
      "step": 780
    },
    {
      "epoch": 0.2257142857142857,
      "grad_norm": 0.2513607144355774,
      "learning_rate": 1.969904761904762e-05,
      "loss": 0.2631,
      "step": 790
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.0901729092001915,
      "learning_rate": 1.9695238095238096e-05,
      "loss": 0.0022,
      "step": 800
    },
    {
      "epoch": 0.23142857142857143,
      "grad_norm": 41.73643493652344,
      "learning_rate": 1.969142857142857e-05,
      "loss": 0.6615,
      "step": 810
    },
    {
      "epoch": 0.2342857142857143,
      "grad_norm": 0.34982284903526306,
      "learning_rate": 1.968761904761905e-05,
      "loss": 0.3463,
      "step": 820
    },
    {
      "epoch": 0.23714285714285716,
      "grad_norm": 0.33085739612579346,
      "learning_rate": 1.9683809523809526e-05,
      "loss": 0.4322,
      "step": 830
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6504504680633545,
      "learning_rate": 1.968e-05,
      "loss": 0.4916,
      "step": 840
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 0.44860684871673584,
      "learning_rate": 1.9676190476190477e-05,
      "loss": 0.6319,
      "step": 850
    },
    {
      "epoch": 0.24571428571428572,
      "grad_norm": 35.055789947509766,
      "learning_rate": 1.9672380952380952e-05,
      "loss": 0.483,
      "step": 860
    },
    {
      "epoch": 0.24857142857142858,
      "grad_norm": 0.4826500713825226,
      "learning_rate": 1.966857142857143e-05,
      "loss": 0.4752,
      "step": 870
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 25.356721878051758,
      "learning_rate": 1.9664761904761907e-05,
      "loss": 0.5541,
      "step": 880
    },
    {
      "epoch": 0.2542857142857143,
      "grad_norm": 0.25434282422065735,
      "learning_rate": 1.9660952380952383e-05,
      "loss": 0.3966,
      "step": 890
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 0.3909609615802765,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 0.6691,
      "step": 900
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.06657121330499649,
      "learning_rate": 1.9653333333333334e-05,
      "loss": 0.0026,
      "step": 910
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 26.3468017578125,
      "learning_rate": 1.9649523809523813e-05,
      "loss": 0.3879,
      "step": 920
    },
    {
      "epoch": 0.26571428571428574,
      "grad_norm": 20.818754196166992,
      "learning_rate": 1.964571428571429e-05,
      "loss": 0.1834,
      "step": 930
    },
    {
      "epoch": 0.26857142857142857,
      "grad_norm": 0.1203976646065712,
      "learning_rate": 1.9641904761904764e-05,
      "loss": 0.4941,
      "step": 940
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 0.24063976109027863,
      "learning_rate": 1.963809523809524e-05,
      "loss": 0.2694,
      "step": 950
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 0.21895062923431396,
      "learning_rate": 1.963428571428572e-05,
      "loss": 0.322,
      "step": 960
    },
    {
      "epoch": 0.27714285714285714,
      "grad_norm": 0.06840768456459045,
      "learning_rate": 1.9630476190476194e-05,
      "loss": 0.4767,
      "step": 970
    },
    {
      "epoch": 0.28,
      "grad_norm": 22.443065643310547,
      "learning_rate": 1.9626666666666666e-05,
      "loss": 0.6778,
      "step": 980
    },
    {
      "epoch": 0.28285714285714286,
      "grad_norm": 0.5557012557983398,
      "learning_rate": 1.9622857142857142e-05,
      "loss": 0.6731,
      "step": 990
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 23.862533569335938,
      "learning_rate": 1.961904761904762e-05,
      "loss": 0.5954,
      "step": 1000
    },
    {
      "epoch": 0.2885714285714286,
      "grad_norm": 0.1657804548740387,
      "learning_rate": 1.9615238095238096e-05,
      "loss": 0.1153,
      "step": 1010
    },
    {
      "epoch": 0.2914285714285714,
      "grad_norm": 0.33166250586509705,
      "learning_rate": 1.9611428571428572e-05,
      "loss": 0.6966,
      "step": 1020
    },
    {
      "epoch": 0.29428571428571426,
      "grad_norm": 0.24204659461975098,
      "learning_rate": 1.9607619047619048e-05,
      "loss": 0.1273,
      "step": 1030
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 0.15267671644687653,
      "learning_rate": 1.9603809523809526e-05,
      "loss": 0.5296,
      "step": 1040
    },
    {
      "epoch": 0.3,
      "grad_norm": 20.335899353027344,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.7915,
      "step": 1050
    },
    {
      "epoch": 0.3028571428571429,
      "grad_norm": 1.0125153064727783,
      "learning_rate": 1.9596190476190478e-05,
      "loss": 0.4412,
      "step": 1060
    },
    {
      "epoch": 0.3057142857142857,
      "grad_norm": 0.13335244357585907,
      "learning_rate": 1.9592380952380953e-05,
      "loss": 0.3845,
      "step": 1070
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 0.2828969657421112,
      "learning_rate": 1.958857142857143e-05,
      "loss": 0.6678,
      "step": 1080
    },
    {
      "epoch": 0.31142857142857144,
      "grad_norm": 26.352807998657227,
      "learning_rate": 1.9584761904761908e-05,
      "loss": 0.2257,
      "step": 1090
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 0.24880851805210114,
      "learning_rate": 1.9580952380952383e-05,
      "loss": 0.5756,
      "step": 1100
    },
    {
      "epoch": 0.3171428571428571,
      "grad_norm": 0.5507546067237854,
      "learning_rate": 1.957714285714286e-05,
      "loss": 0.5963,
      "step": 1110
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.22979064285755157,
      "learning_rate": 1.9573333333333335e-05,
      "loss": 0.3038,
      "step": 1120
    },
    {
      "epoch": 0.32285714285714284,
      "grad_norm": 0.05827149376273155,
      "learning_rate": 1.956952380952381e-05,
      "loss": 0.429,
      "step": 1130
    },
    {
      "epoch": 0.32571428571428573,
      "grad_norm": 0.19238291680812836,
      "learning_rate": 1.956571428571429e-05,
      "loss": 0.2814,
      "step": 1140
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 0.20631638169288635,
      "learning_rate": 1.9561904761904765e-05,
      "loss": 0.1416,
      "step": 1150
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 16.80356788635254,
      "learning_rate": 1.955809523809524e-05,
      "loss": 0.5782,
      "step": 1160
    },
    {
      "epoch": 0.3342857142857143,
      "grad_norm": 0.36427968740463257,
      "learning_rate": 1.9554285714285716e-05,
      "loss": 0.5552,
      "step": 1170
    },
    {
      "epoch": 0.33714285714285713,
      "grad_norm": 1.6276780366897583,
      "learning_rate": 1.955047619047619e-05,
      "loss": 0.9393,
      "step": 1180
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.772297739982605,
      "learning_rate": 1.954666666666667e-05,
      "loss": 0.5677,
      "step": 1190
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.42259272933006287,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 0.4971,
      "step": 1200
    },
    {
      "epoch": 0.3457142857142857,
      "grad_norm": 0.1650380790233612,
      "learning_rate": 1.9539047619047618e-05,
      "loss": 0.2611,
      "step": 1210
    },
    {
      "epoch": 0.3485714285714286,
      "grad_norm": 0.19886143505573273,
      "learning_rate": 1.9535238095238097e-05,
      "loss": 0.5541,
      "step": 1220
    },
    {
      "epoch": 0.3514285714285714,
      "grad_norm": 0.2929515838623047,
      "learning_rate": 1.9531428571428573e-05,
      "loss": 0.1325,
      "step": 1230
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 17.834197998046875,
      "learning_rate": 1.9527619047619048e-05,
      "loss": 0.4207,
      "step": 1240
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 32.017417907714844,
      "learning_rate": 1.9523809523809524e-05,
      "loss": 0.4906,
      "step": 1250
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1917472779750824,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.2685,
      "step": 1260
    },
    {
      "epoch": 0.3628571428571429,
      "grad_norm": 3.2978439331054688,
      "learning_rate": 1.951619047619048e-05,
      "loss": 0.8362,
      "step": 1270
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 0.15418365597724915,
      "learning_rate": 1.9512380952380954e-05,
      "loss": 0.2428,
      "step": 1280
    },
    {
      "epoch": 0.36857142857142855,
      "grad_norm": 0.13591688871383667,
      "learning_rate": 1.950857142857143e-05,
      "loss": 0.3251,
      "step": 1290
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 17.60010528564453,
      "learning_rate": 1.9504761904761905e-05,
      "loss": 0.7022,
      "step": 1300
    },
    {
      "epoch": 0.3742857142857143,
      "grad_norm": 0.35252997279167175,
      "learning_rate": 1.9500952380952384e-05,
      "loss": 0.237,
      "step": 1310
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 0.4340313673019409,
      "learning_rate": 1.949714285714286e-05,
      "loss": 0.3606,
      "step": 1320
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.26303935050964355,
      "learning_rate": 1.9493333333333335e-05,
      "loss": 0.3886,
      "step": 1330
    },
    {
      "epoch": 0.38285714285714284,
      "grad_norm": 0.151530459523201,
      "learning_rate": 1.948952380952381e-05,
      "loss": 0.4347,
      "step": 1340
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 0.1643962264060974,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 0.5492,
      "step": 1350
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 20.21723175048828,
      "learning_rate": 1.9481904761904765e-05,
      "loss": 0.5683,
      "step": 1360
    },
    {
      "epoch": 0.3914285714285714,
      "grad_norm": 0.5511641502380371,
      "learning_rate": 1.947809523809524e-05,
      "loss": 0.4184,
      "step": 1370
    },
    {
      "epoch": 0.3942857142857143,
      "grad_norm": 0.042426902800798416,
      "learning_rate": 1.9474285714285717e-05,
      "loss": 0.0027,
      "step": 1380
    },
    {
      "epoch": 0.39714285714285713,
      "grad_norm": 23.34708595275879,
      "learning_rate": 1.9470476190476192e-05,
      "loss": 0.6549,
      "step": 1390
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.23069074749946594,
      "learning_rate": 1.9466666666666668e-05,
      "loss": 0.1393,
      "step": 1400
    },
    {
      "epoch": 0.40285714285714286,
      "grad_norm": 0.15411098301410675,
      "learning_rate": 1.9462857142857147e-05,
      "loss": 0.25,
      "step": 1410
    },
    {
      "epoch": 0.4057142857142857,
      "grad_norm": 25.494606018066406,
      "learning_rate": 1.945904761904762e-05,
      "loss": 0.4279,
      "step": 1420
    },
    {
      "epoch": 0.4085714285714286,
      "grad_norm": 25.95424461364746,
      "learning_rate": 1.9455238095238095e-05,
      "loss": 0.0743,
      "step": 1430
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 0.06235581636428833,
      "learning_rate": 1.9451428571428573e-05,
      "loss": 0.1574,
      "step": 1440
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 0.1329297423362732,
      "learning_rate": 1.944761904761905e-05,
      "loss": 0.5619,
      "step": 1450
    },
    {
      "epoch": 0.41714285714285715,
      "grad_norm": 19.87080192565918,
      "learning_rate": 1.9443809523809525e-05,
      "loss": 0.5553,
      "step": 1460
    },
    {
      "epoch": 0.42,
      "grad_norm": 17.394006729125977,
      "learning_rate": 1.944e-05,
      "loss": 0.573,
      "step": 1470
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 21.8866024017334,
      "learning_rate": 1.9436190476190476e-05,
      "loss": 0.4866,
      "step": 1480
    },
    {
      "epoch": 0.4257142857142857,
      "grad_norm": 0.10700096935033798,
      "learning_rate": 1.9432380952380955e-05,
      "loss": 0.5024,
      "step": 1490
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.8119301795959473,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.7727,
      "step": 1500
    },
    {
      "epoch": 0.43142857142857144,
      "grad_norm": 0.08617265522480011,
      "learning_rate": 1.9424761904761906e-05,
      "loss": 0.3165,
      "step": 1510
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 18.607391357421875,
      "learning_rate": 1.942095238095238e-05,
      "loss": 0.3704,
      "step": 1520
    },
    {
      "epoch": 0.43714285714285717,
      "grad_norm": 0.7129552960395813,
      "learning_rate": 1.941714285714286e-05,
      "loss": 0.7246,
      "step": 1530
    },
    {
      "epoch": 0.44,
      "grad_norm": 16.752723693847656,
      "learning_rate": 1.9413333333333336e-05,
      "loss": 0.4521,
      "step": 1540
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 0.5936293005943298,
      "learning_rate": 1.940952380952381e-05,
      "loss": 0.234,
      "step": 1550
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 20.328128814697266,
      "learning_rate": 1.9405714285714287e-05,
      "loss": 0.536,
      "step": 1560
    },
    {
      "epoch": 0.44857142857142857,
      "grad_norm": 0.12088245898485184,
      "learning_rate": 1.9401904761904763e-05,
      "loss": 0.1379,
      "step": 1570
    },
    {
      "epoch": 0.4514285714285714,
      "grad_norm": 0.5053002238273621,
      "learning_rate": 1.9398095238095242e-05,
      "loss": 0.3956,
      "step": 1580
    },
    {
      "epoch": 0.4542857142857143,
      "grad_norm": 0.10835964232683182,
      "learning_rate": 1.9394285714285717e-05,
      "loss": 0.0621,
      "step": 1590
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.027157703414559364,
      "learning_rate": 1.9390476190476193e-05,
      "loss": 0.7692,
      "step": 1600
    },
    {
      "epoch": 0.46,
      "grad_norm": 31.248079299926758,
      "learning_rate": 1.938666666666667e-05,
      "loss": 0.4162,
      "step": 1610
    },
    {
      "epoch": 0.46285714285714286,
      "grad_norm": 0.5672780275344849,
      "learning_rate": 1.9382857142857144e-05,
      "loss": 0.2249,
      "step": 1620
    },
    {
      "epoch": 0.4657142857142857,
      "grad_norm": 28.82352638244629,
      "learning_rate": 1.937904761904762e-05,
      "loss": 0.2803,
      "step": 1630
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 0.09057394415140152,
      "learning_rate": 1.9375238095238095e-05,
      "loss": 0.506,
      "step": 1640
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 24.46344757080078,
      "learning_rate": 1.937142857142857e-05,
      "loss": 0.5821,
      "step": 1650
    },
    {
      "epoch": 0.4742857142857143,
      "grad_norm": 0.30996373295783997,
      "learning_rate": 1.936761904761905e-05,
      "loss": 0.1093,
      "step": 1660
    },
    {
      "epoch": 0.47714285714285715,
      "grad_norm": 25.95821189880371,
      "learning_rate": 1.9363809523809525e-05,
      "loss": 0.6053,
      "step": 1670
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.0635613352060318,
      "learning_rate": 1.936e-05,
      "loss": 0.6203,
      "step": 1680
    },
    {
      "epoch": 0.4828571428571429,
      "grad_norm": 0.39678338170051575,
      "learning_rate": 1.9356190476190477e-05,
      "loss": 0.7723,
      "step": 1690
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 0.13594205677509308,
      "learning_rate": 1.9352380952380952e-05,
      "loss": 0.1224,
      "step": 1700
    },
    {
      "epoch": 0.48857142857142855,
      "grad_norm": 0.2273647040128708,
      "learning_rate": 1.934857142857143e-05,
      "loss": 0.5495,
      "step": 1710
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 26.079374313354492,
      "learning_rate": 1.9344761904761907e-05,
      "loss": 0.8599,
      "step": 1720
    },
    {
      "epoch": 0.4942857142857143,
      "grad_norm": 25.747772216796875,
      "learning_rate": 1.9340952380952382e-05,
      "loss": 0.4972,
      "step": 1730
    },
    {
      "epoch": 0.49714285714285716,
      "grad_norm": 18.64980125427246,
      "learning_rate": 1.9337142857142858e-05,
      "loss": 0.5438,
      "step": 1740
    },
    {
      "epoch": 0.5,
      "grad_norm": 28.027956008911133,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.3664,
      "step": 1750
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 0.04817027971148491,
      "learning_rate": 1.9329523809523812e-05,
      "loss": 0.3702,
      "step": 1760
    },
    {
      "epoch": 0.5057142857142857,
      "grad_norm": 0.05228954926133156,
      "learning_rate": 1.9325714285714288e-05,
      "loss": 0.1822,
      "step": 1770
    },
    {
      "epoch": 0.5085714285714286,
      "grad_norm": 24.889631271362305,
      "learning_rate": 1.9321904761904764e-05,
      "loss": 0.4334,
      "step": 1780
    },
    {
      "epoch": 0.5114285714285715,
      "grad_norm": 1.0723826885223389,
      "learning_rate": 1.931809523809524e-05,
      "loss": 0.5047,
      "step": 1790
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 1.5023974180221558,
      "learning_rate": 1.9314285714285718e-05,
      "loss": 0.2426,
      "step": 1800
    },
    {
      "epoch": 0.5171428571428571,
      "grad_norm": 0.09015033394098282,
      "learning_rate": 1.9310476190476194e-05,
      "loss": 0.4573,
      "step": 1810
    },
    {
      "epoch": 0.52,
      "grad_norm": 19.595205307006836,
      "learning_rate": 1.930666666666667e-05,
      "loss": 0.4969,
      "step": 1820
    },
    {
      "epoch": 0.5228571428571429,
      "grad_norm": 20.869873046875,
      "learning_rate": 1.9302857142857145e-05,
      "loss": 1.5066,
      "step": 1830
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 0.26032695174217224,
      "learning_rate": 1.929904761904762e-05,
      "loss": 0.1704,
      "step": 1840
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 4.5077738761901855,
      "learning_rate": 1.9295238095238096e-05,
      "loss": 0.3971,
      "step": 1850
    },
    {
      "epoch": 0.5314285714285715,
      "grad_norm": 0.1789378821849823,
      "learning_rate": 1.929142857142857e-05,
      "loss": 0.3633,
      "step": 1860
    },
    {
      "epoch": 0.5342857142857143,
      "grad_norm": 21.2937068939209,
      "learning_rate": 1.9287619047619047e-05,
      "loss": 0.4836,
      "step": 1870
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 0.06868991255760193,
      "learning_rate": 1.9283809523809526e-05,
      "loss": 0.0119,
      "step": 1880
    },
    {
      "epoch": 0.54,
      "grad_norm": 24.38346290588379,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 0.4997,
      "step": 1890
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 0.17882901430130005,
      "learning_rate": 1.9276190476190477e-05,
      "loss": 0.2464,
      "step": 1900
    },
    {
      "epoch": 0.5457142857142857,
      "grad_norm": 0.07756262272596359,
      "learning_rate": 1.9272380952380953e-05,
      "loss": 0.1185,
      "step": 1910
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 0.023021286353468895,
      "learning_rate": 1.926857142857143e-05,
      "loss": 0.146,
      "step": 1920
    },
    {
      "epoch": 0.5514285714285714,
      "grad_norm": 24.627330780029297,
      "learning_rate": 1.9264761904761907e-05,
      "loss": 0.728,
      "step": 1930
    },
    {
      "epoch": 0.5542857142857143,
      "grad_norm": 22.235700607299805,
      "learning_rate": 1.9260952380952383e-05,
      "loss": 0.3205,
      "step": 1940
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 0.1776823103427887,
      "learning_rate": 1.925714285714286e-05,
      "loss": 0.1835,
      "step": 1950
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.07572628557682037,
      "learning_rate": 1.9253333333333334e-05,
      "loss": 0.3106,
      "step": 1960
    },
    {
      "epoch": 0.5628571428571428,
      "grad_norm": 0.12393456697463989,
      "learning_rate": 1.924952380952381e-05,
      "loss": 0.4823,
      "step": 1970
    },
    {
      "epoch": 0.5657142857142857,
      "grad_norm": 34.16526794433594,
      "learning_rate": 1.924571428571429e-05,
      "loss": 0.5139,
      "step": 1980
    },
    {
      "epoch": 0.5685714285714286,
      "grad_norm": 27.50176429748535,
      "learning_rate": 1.9241904761904764e-05,
      "loss": 0.5097,
      "step": 1990
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.8290412425994873,
      "learning_rate": 1.923809523809524e-05,
      "loss": 0.1477,
      "step": 2000
    },
    {
      "epoch": 0.5742857142857143,
      "grad_norm": 46.570899963378906,
      "learning_rate": 1.9234285714285716e-05,
      "loss": 0.5144,
      "step": 2010
    },
    {
      "epoch": 0.5771428571428572,
      "grad_norm": 0.19365888833999634,
      "learning_rate": 1.923047619047619e-05,
      "loss": 0.4173,
      "step": 2020
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.29724937677383423,
      "learning_rate": 1.922666666666667e-05,
      "loss": 0.1415,
      "step": 2030
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 0.41485217213630676,
      "learning_rate": 1.9222857142857146e-05,
      "loss": 0.3852,
      "step": 2040
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 0.046354833990335464,
      "learning_rate": 1.921904761904762e-05,
      "loss": 0.2555,
      "step": 2050
    },
    {
      "epoch": 0.5885714285714285,
      "grad_norm": 0.01655798777937889,
      "learning_rate": 1.9215238095238097e-05,
      "loss": 0.2017,
      "step": 2060
    },
    {
      "epoch": 0.5914285714285714,
      "grad_norm": 0.018647361546754837,
      "learning_rate": 1.9211428571428572e-05,
      "loss": 0.0471,
      "step": 2070
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 0.09193462133407593,
      "learning_rate": 1.9207619047619048e-05,
      "loss": 0.6409,
      "step": 2080
    },
    {
      "epoch": 0.5971428571428572,
      "grad_norm": 0.06003516539931297,
      "learning_rate": 1.9203809523809524e-05,
      "loss": 0.1405,
      "step": 2090
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.33607110381126404,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.4899,
      "step": 2100
    },
    {
      "epoch": 0.6028571428571429,
      "grad_norm": 0.21596167981624603,
      "learning_rate": 1.9196190476190478e-05,
      "loss": 0.2792,
      "step": 2110
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 30.924114227294922,
      "learning_rate": 1.9192380952380954e-05,
      "loss": 0.4343,
      "step": 2120
    },
    {
      "epoch": 0.6085714285714285,
      "grad_norm": 0.6469313502311707,
      "learning_rate": 1.918857142857143e-05,
      "loss": 0.4779,
      "step": 2130
    },
    {
      "epoch": 0.6114285714285714,
      "grad_norm": 0.16251727938652039,
      "learning_rate": 1.9184761904761905e-05,
      "loss": 0.1879,
      "step": 2140
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 41.74284362792969,
      "learning_rate": 1.9180952380952384e-05,
      "loss": 0.4002,
      "step": 2150
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 0.06802085787057877,
      "learning_rate": 1.917714285714286e-05,
      "loss": 0.0017,
      "step": 2160
    },
    {
      "epoch": 0.62,
      "grad_norm": 20.911592483520508,
      "learning_rate": 1.9173333333333335e-05,
      "loss": 0.2984,
      "step": 2170
    },
    {
      "epoch": 0.6228571428571429,
      "grad_norm": 0.040194321423769,
      "learning_rate": 1.916952380952381e-05,
      "loss": 0.4571,
      "step": 2180
    },
    {
      "epoch": 0.6257142857142857,
      "grad_norm": 5.301441669464111,
      "learning_rate": 1.9165714285714286e-05,
      "loss": 0.1631,
      "step": 2190
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.09049271047115326,
      "learning_rate": 1.9161904761904765e-05,
      "loss": 0.0967,
      "step": 2200
    },
    {
      "epoch": 0.6314285714285715,
      "grad_norm": 1.5702271461486816,
      "learning_rate": 1.915809523809524e-05,
      "loss": 0.1881,
      "step": 2210
    },
    {
      "epoch": 0.6342857142857142,
      "grad_norm": 0.1509428769350052,
      "learning_rate": 1.9154285714285716e-05,
      "loss": 0.2156,
      "step": 2220
    },
    {
      "epoch": 0.6371428571428571,
      "grad_norm": 0.732454776763916,
      "learning_rate": 1.9150476190476192e-05,
      "loss": 0.3031,
      "step": 2230
    },
    {
      "epoch": 0.64,
      "grad_norm": 34.87100601196289,
      "learning_rate": 1.9146666666666667e-05,
      "loss": 0.5561,
      "step": 2240
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 0.0579184927046299,
      "learning_rate": 1.9142857142857146e-05,
      "loss": 0.257,
      "step": 2250
    },
    {
      "epoch": 0.6457142857142857,
      "grad_norm": 0.27855393290519714,
      "learning_rate": 1.9139047619047622e-05,
      "loss": 0.4274,
      "step": 2260
    },
    {
      "epoch": 0.6485714285714286,
      "grad_norm": 1.880355954170227,
      "learning_rate": 1.9135238095238098e-05,
      "loss": 0.1886,
      "step": 2270
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 25.432880401611328,
      "learning_rate": 1.9131428571428573e-05,
      "loss": 0.3536,
      "step": 2280
    },
    {
      "epoch": 0.6542857142857142,
      "grad_norm": 0.11038409918546677,
      "learning_rate": 1.912761904761905e-05,
      "loss": 0.3343,
      "step": 2290
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 10.635066032409668,
      "learning_rate": 1.9123809523809524e-05,
      "loss": 0.3143,
      "step": 2300
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.2816283106803894,
      "learning_rate": 1.912e-05,
      "loss": 0.1214,
      "step": 2310
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 29.86052131652832,
      "learning_rate": 1.9116190476190475e-05,
      "loss": 0.3085,
      "step": 2320
    },
    {
      "epoch": 0.6657142857142857,
      "grad_norm": 0.7531970739364624,
      "learning_rate": 1.9112380952380954e-05,
      "loss": 0.6323,
      "step": 2330
    },
    {
      "epoch": 0.6685714285714286,
      "grad_norm": 24.424671173095703,
      "learning_rate": 1.910857142857143e-05,
      "loss": 0.6206,
      "step": 2340
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 21.391887664794922,
      "learning_rate": 1.9104761904761906e-05,
      "loss": 0.5928,
      "step": 2350
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 4.339882850646973,
      "learning_rate": 1.910095238095238e-05,
      "loss": 0.2007,
      "step": 2360
    },
    {
      "epoch": 0.6771428571428572,
      "grad_norm": 11.97884750366211,
      "learning_rate": 1.909714285714286e-05,
      "loss": 0.1346,
      "step": 2370
    },
    {
      "epoch": 0.68,
      "grad_norm": 25.400169372558594,
      "learning_rate": 1.9093333333333336e-05,
      "loss": 0.2033,
      "step": 2380
    },
    {
      "epoch": 0.6828571428571428,
      "grad_norm": 0.04757780581712723,
      "learning_rate": 1.908952380952381e-05,
      "loss": 0.5449,
      "step": 2390
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.05109059065580368,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 0.2863,
      "step": 2400
    },
    {
      "epoch": 0.6885714285714286,
      "grad_norm": 0.061277713626623154,
      "learning_rate": 1.9081904761904762e-05,
      "loss": 0.535,
      "step": 2410
    },
    {
      "epoch": 0.6914285714285714,
      "grad_norm": 0.18474122881889343,
      "learning_rate": 1.907809523809524e-05,
      "loss": 0.1594,
      "step": 2420
    },
    {
      "epoch": 0.6942857142857143,
      "grad_norm": 0.3932398557662964,
      "learning_rate": 1.9074285714285717e-05,
      "loss": 0.4588,
      "step": 2430
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 29.33621597290039,
      "learning_rate": 1.9070476190476193e-05,
      "loss": 0.1367,
      "step": 2440
    },
    {
      "epoch": 0.7,
      "grad_norm": 45.13445281982422,
      "learning_rate": 1.9066666666666668e-05,
      "loss": 0.4261,
      "step": 2450
    },
    {
      "epoch": 0.7028571428571428,
      "grad_norm": 0.042779479175806046,
      "learning_rate": 1.9062857142857144e-05,
      "loss": 0.0813,
      "step": 2460
    },
    {
      "epoch": 0.7057142857142857,
      "grad_norm": 0.05173124000430107,
      "learning_rate": 1.9059047619047623e-05,
      "loss": 0.3842,
      "step": 2470
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 0.09938213974237442,
      "learning_rate": 1.90552380952381e-05,
      "loss": 0.1816,
      "step": 2480
    },
    {
      "epoch": 0.7114285714285714,
      "grad_norm": 0.1592504382133484,
      "learning_rate": 1.9051428571428574e-05,
      "loss": 0.1483,
      "step": 2490
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.12784890830516815,
      "learning_rate": 1.904761904761905e-05,
      "loss": 0.2822,
      "step": 2500
    },
    {
      "epoch": 0.7171428571428572,
      "grad_norm": 0.06188306212425232,
      "learning_rate": 1.9043809523809525e-05,
      "loss": 0.1778,
      "step": 2510
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.17031221091747284,
      "learning_rate": 1.904e-05,
      "loss": 0.3201,
      "step": 2520
    },
    {
      "epoch": 0.7228571428571429,
      "grad_norm": 0.10347744077444077,
      "learning_rate": 1.9036190476190476e-05,
      "loss": 0.0264,
      "step": 2530
    },
    {
      "epoch": 0.7257142857142858,
      "grad_norm": 18.705974578857422,
      "learning_rate": 1.9032380952380952e-05,
      "loss": 0.2957,
      "step": 2540
    },
    {
      "epoch": 0.7285714285714285,
      "grad_norm": 0.41892901062965393,
      "learning_rate": 1.902857142857143e-05,
      "loss": 0.4844,
      "step": 2550
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 23.688974380493164,
      "learning_rate": 1.9024761904761906e-05,
      "loss": 0.2039,
      "step": 2560
    },
    {
      "epoch": 0.7342857142857143,
      "grad_norm": 0.010581989772617817,
      "learning_rate": 1.9020952380952382e-05,
      "loss": 0.0363,
      "step": 2570
    },
    {
      "epoch": 0.7371428571428571,
      "grad_norm": 0.014548614621162415,
      "learning_rate": 1.9017142857142858e-05,
      "loss": 0.0009,
      "step": 2580
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.006180409342050552,
      "learning_rate": 1.9013333333333333e-05,
      "loss": 0.205,
      "step": 2590
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.010849597863852978,
      "learning_rate": 1.9009523809523812e-05,
      "loss": 0.0187,
      "step": 2600
    },
    {
      "epoch": 0.7457142857142857,
      "grad_norm": 0.012486892752349377,
      "learning_rate": 1.9005714285714288e-05,
      "loss": 0.2296,
      "step": 2610
    },
    {
      "epoch": 0.7485714285714286,
      "grad_norm": 32.92125701904297,
      "learning_rate": 1.9001904761904763e-05,
      "loss": 0.8567,
      "step": 2620
    },
    {
      "epoch": 0.7514285714285714,
      "grad_norm": 20.11109733581543,
      "learning_rate": 1.899809523809524e-05,
      "loss": 0.4435,
      "step": 2630
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 0.15372680127620697,
      "learning_rate": 1.8994285714285718e-05,
      "loss": 0.0042,
      "step": 2640
    },
    {
      "epoch": 0.7571428571428571,
      "grad_norm": 0.13121360540390015,
      "learning_rate": 1.8990476190476193e-05,
      "loss": 0.1868,
      "step": 2650
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.0410015732049942,
      "learning_rate": 1.898666666666667e-05,
      "loss": 0.2662,
      "step": 2660
    },
    {
      "epoch": 0.7628571428571429,
      "grad_norm": 0.03508773073554039,
      "learning_rate": 1.8982857142857145e-05,
      "loss": 0.3718,
      "step": 2670
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 0.11185619980096817,
      "learning_rate": 1.897904761904762e-05,
      "loss": 0.5334,
      "step": 2680
    },
    {
      "epoch": 0.7685714285714286,
      "grad_norm": 20.51291847229004,
      "learning_rate": 1.89752380952381e-05,
      "loss": 0.5166,
      "step": 2690
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 0.30175837874412537,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 0.1503,
      "step": 2700
    },
    {
      "epoch": 0.7742857142857142,
      "grad_norm": 0.22685952484607697,
      "learning_rate": 1.896761904761905e-05,
      "loss": 0.1453,
      "step": 2710
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 0.042315397411584854,
      "learning_rate": 1.8963809523809526e-05,
      "loss": 0.1319,
      "step": 2720
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5258446335792542,
      "learning_rate": 1.896e-05,
      "loss": 0.5953,
      "step": 2730
    },
    {
      "epoch": 0.7828571428571428,
      "grad_norm": 0.5498745441436768,
      "learning_rate": 1.8956190476190477e-05,
      "loss": 0.0917,
      "step": 2740
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 0.9583050012588501,
      "learning_rate": 1.8952380952380953e-05,
      "loss": 0.1219,
      "step": 2750
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 0.03859451040625572,
      "learning_rate": 1.8948571428571428e-05,
      "loss": 0.0225,
      "step": 2760
    },
    {
      "epoch": 0.7914285714285715,
      "grad_norm": 0.0223549697548151,
      "learning_rate": 1.8944761904761907e-05,
      "loss": 0.371,
      "step": 2770
    },
    {
      "epoch": 0.7942857142857143,
      "grad_norm": 0.07321210950613022,
      "learning_rate": 1.8940952380952383e-05,
      "loss": 0.5807,
      "step": 2780
    },
    {
      "epoch": 0.7971428571428572,
      "grad_norm": 0.49703335762023926,
      "learning_rate": 1.893714285714286e-05,
      "loss": 0.1779,
      "step": 2790
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.22323988378047943,
      "learning_rate": 1.8933333333333334e-05,
      "loss": 0.2524,
      "step": 2800
    },
    {
      "epoch": 0.8028571428571428,
      "grad_norm": 0.03506855666637421,
      "learning_rate": 1.892952380952381e-05,
      "loss": 0.0016,
      "step": 2810
    },
    {
      "epoch": 0.8057142857142857,
      "grad_norm": 0.09832269698381424,
      "learning_rate": 1.892571428571429e-05,
      "loss": 0.6995,
      "step": 2820
    },
    {
      "epoch": 0.8085714285714286,
      "grad_norm": 0.3036506474018097,
      "learning_rate": 1.8921904761904764e-05,
      "loss": 0.3339,
      "step": 2830
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 0.05883965641260147,
      "learning_rate": 1.891809523809524e-05,
      "loss": 0.0063,
      "step": 2840
    },
    {
      "epoch": 0.8142857142857143,
      "grad_norm": 0.019640162587165833,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 0.4413,
      "step": 2850
    },
    {
      "epoch": 0.8171428571428572,
      "grad_norm": 0.6981868147850037,
      "learning_rate": 1.891047619047619e-05,
      "loss": 0.3618,
      "step": 2860
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.26055604219436646,
      "learning_rate": 1.890666666666667e-05,
      "loss": 0.3804,
      "step": 2870
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 0.048239532858133316,
      "learning_rate": 1.8902857142857145e-05,
      "loss": 0.2308,
      "step": 2880
    },
    {
      "epoch": 0.8257142857142857,
      "grad_norm": 36.829307556152344,
      "learning_rate": 1.889904761904762e-05,
      "loss": 0.5012,
      "step": 2890
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 0.1633509248495102,
      "learning_rate": 1.8895238095238096e-05,
      "loss": 0.5394,
      "step": 2900
    },
    {
      "epoch": 0.8314285714285714,
      "grad_norm": 0.3573632538318634,
      "learning_rate": 1.8891428571428575e-05,
      "loss": 0.2018,
      "step": 2910
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 42.85517883300781,
      "learning_rate": 1.888761904761905e-05,
      "loss": 0.0891,
      "step": 2920
    },
    {
      "epoch": 0.8371428571428572,
      "grad_norm": 0.06278089433908463,
      "learning_rate": 1.8883809523809523e-05,
      "loss": 0.3928,
      "step": 2930
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.047654543071985245,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 0.0012,
      "step": 2940
    },
    {
      "epoch": 0.8428571428571429,
      "grad_norm": 0.05041980370879173,
      "learning_rate": 1.8876190476190478e-05,
      "loss": 0.4606,
      "step": 2950
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 0.12398307025432587,
      "learning_rate": 1.8872380952380953e-05,
      "loss": 0.2493,
      "step": 2960
    },
    {
      "epoch": 0.8485714285714285,
      "grad_norm": 18.763507843017578,
      "learning_rate": 1.886857142857143e-05,
      "loss": 0.1702,
      "step": 2970
    },
    {
      "epoch": 0.8514285714285714,
      "grad_norm": 23.381040573120117,
      "learning_rate": 1.8864761904761905e-05,
      "loss": 0.0324,
      "step": 2980
    },
    {
      "epoch": 0.8542857142857143,
      "grad_norm": 0.04621008783578873,
      "learning_rate": 1.8860952380952383e-05,
      "loss": 0.1514,
      "step": 2990
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.10457897931337357,
      "learning_rate": 1.885714285714286e-05,
      "loss": 0.0005,
      "step": 3000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.003039262257516384,
      "learning_rate": 1.8853333333333335e-05,
      "loss": 0.3402,
      "step": 3010
    },
    {
      "epoch": 0.8628571428571429,
      "grad_norm": 0.026349488645792007,
      "learning_rate": 1.884952380952381e-05,
      "loss": 0.0971,
      "step": 3020
    },
    {
      "epoch": 0.8657142857142858,
      "grad_norm": 0.5725266337394714,
      "learning_rate": 1.8845714285714286e-05,
      "loss": 0.0011,
      "step": 3030
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 0.02448619343340397,
      "learning_rate": 1.8841904761904765e-05,
      "loss": 0.1947,
      "step": 3040
    },
    {
      "epoch": 0.8714285714285714,
      "grad_norm": 0.11226197332143784,
      "learning_rate": 1.883809523809524e-05,
      "loss": 0.2586,
      "step": 3050
    },
    {
      "epoch": 0.8742857142857143,
      "grad_norm": 0.01903923973441124,
      "learning_rate": 1.8834285714285716e-05,
      "loss": 0.4883,
      "step": 3060
    },
    {
      "epoch": 0.8771428571428571,
      "grad_norm": 0.1385258287191391,
      "learning_rate": 1.883047619047619e-05,
      "loss": 0.344,
      "step": 3070
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.08266264200210571,
      "learning_rate": 1.8826666666666667e-05,
      "loss": 0.377,
      "step": 3080
    },
    {
      "epoch": 0.8828571428571429,
      "grad_norm": 0.11391504853963852,
      "learning_rate": 1.8822857142857146e-05,
      "loss": 0.1311,
      "step": 3090
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 0.03978288546204567,
      "learning_rate": 1.881904761904762e-05,
      "loss": 0.2476,
      "step": 3100
    },
    {
      "epoch": 0.8885714285714286,
      "grad_norm": 0.021155565977096558,
      "learning_rate": 1.8815238095238097e-05,
      "loss": 0.6026,
      "step": 3110
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 21.20499610900879,
      "learning_rate": 1.8811428571428573e-05,
      "loss": 0.4778,
      "step": 3120
    },
    {
      "epoch": 0.8942857142857142,
      "grad_norm": 38.27812576293945,
      "learning_rate": 1.8807619047619052e-05,
      "loss": 0.043,
      "step": 3130
    },
    {
      "epoch": 0.8971428571428571,
      "grad_norm": 30.15193748474121,
      "learning_rate": 1.8803809523809527e-05,
      "loss": 0.4958,
      "step": 3140
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6374394297599792,
      "learning_rate": 1.88e-05,
      "loss": 0.5842,
      "step": 3150
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 20.72459602355957,
      "learning_rate": 1.8796190476190475e-05,
      "loss": 0.4205,
      "step": 3160
    },
    {
      "epoch": 0.9057142857142857,
      "grad_norm": 0.0723794475197792,
      "learning_rate": 1.8792380952380954e-05,
      "loss": 0.2236,
      "step": 3170
    },
    {
      "epoch": 0.9085714285714286,
      "grad_norm": 0.05679628625512123,
      "learning_rate": 1.878857142857143e-05,
      "loss": 0.1414,
      "step": 3180
    },
    {
      "epoch": 0.9114285714285715,
      "grad_norm": 0.04509109631180763,
      "learning_rate": 1.8784761904761905e-05,
      "loss": 0.0284,
      "step": 3190
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.025839481502771378,
      "learning_rate": 1.878095238095238e-05,
      "loss": 0.4399,
      "step": 3200
    },
    {
      "epoch": 0.9171428571428571,
      "grad_norm": 0.03933423385024071,
      "learning_rate": 1.877714285714286e-05,
      "loss": 0.1203,
      "step": 3210
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1823396533727646,
      "learning_rate": 1.8773333333333335e-05,
      "loss": 0.2859,
      "step": 3220
    },
    {
      "epoch": 0.9228571428571428,
      "grad_norm": 0.022305645048618317,
      "learning_rate": 1.876952380952381e-05,
      "loss": 0.0069,
      "step": 3230
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 73.60216522216797,
      "learning_rate": 1.8765714285714287e-05,
      "loss": 0.1899,
      "step": 3240
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 0.05001707375049591,
      "learning_rate": 1.8761904761904762e-05,
      "loss": 0.3651,
      "step": 3250
    },
    {
      "epoch": 0.9314285714285714,
      "grad_norm": 42.46375274658203,
      "learning_rate": 1.875809523809524e-05,
      "loss": 0.251,
      "step": 3260
    },
    {
      "epoch": 0.9342857142857143,
      "grad_norm": 0.593156099319458,
      "learning_rate": 1.8754285714285717e-05,
      "loss": 0.2536,
      "step": 3270
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 18.705795288085938,
      "learning_rate": 1.8750476190476192e-05,
      "loss": 0.3494,
      "step": 3280
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.09559526294469833,
      "learning_rate": 1.8746666666666668e-05,
      "loss": 0.0328,
      "step": 3290
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 0.04503084719181061,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 0.2796,
      "step": 3300
    },
    {
      "epoch": 0.9457142857142857,
      "grad_norm": 0.06275857239961624,
      "learning_rate": 1.8739047619047622e-05,
      "loss": 0.2905,
      "step": 3310
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 0.040857817977666855,
      "learning_rate": 1.8735238095238098e-05,
      "loss": 0.261,
      "step": 3320
    },
    {
      "epoch": 0.9514285714285714,
      "grad_norm": 20.471263885498047,
      "learning_rate": 1.8731428571428574e-05,
      "loss": 0.1614,
      "step": 3330
    },
    {
      "epoch": 0.9542857142857143,
      "grad_norm": 0.06343606859445572,
      "learning_rate": 1.872761904761905e-05,
      "loss": 0.3166,
      "step": 3340
    },
    {
      "epoch": 0.9571428571428572,
      "grad_norm": 0.061884596943855286,
      "learning_rate": 1.8723809523809525e-05,
      "loss": 0.3903,
      "step": 3350
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.07836975157260895,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.0888,
      "step": 3360
    },
    {
      "epoch": 0.9628571428571429,
      "grad_norm": 57.06119155883789,
      "learning_rate": 1.8716190476190476e-05,
      "loss": 0.6533,
      "step": 3370
    },
    {
      "epoch": 0.9657142857142857,
      "grad_norm": 0.20150096714496613,
      "learning_rate": 1.871238095238095e-05,
      "loss": 0.2188,
      "step": 3380
    },
    {
      "epoch": 0.9685714285714285,
      "grad_norm": 17.291000366210938,
      "learning_rate": 1.870857142857143e-05,
      "loss": 0.2547,
      "step": 3390
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.19842906296253204,
      "learning_rate": 1.8704761904761906e-05,
      "loss": 0.0046,
      "step": 3400
    },
    {
      "epoch": 0.9742857142857143,
      "grad_norm": 0.046173837035894394,
      "learning_rate": 1.870095238095238e-05,
      "loss": 0.5403,
      "step": 3410
    },
    {
      "epoch": 0.9771428571428571,
      "grad_norm": 0.02673877775669098,
      "learning_rate": 1.8697142857142857e-05,
      "loss": 0.0239,
      "step": 3420
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3555278778076172,
      "learning_rate": 1.8693333333333333e-05,
      "loss": 0.1522,
      "step": 3430
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 0.018008695915341377,
      "learning_rate": 1.8689523809523812e-05,
      "loss": 0.2597,
      "step": 3440
    },
    {
      "epoch": 0.9857142857142858,
      "grad_norm": 0.03949357196688652,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 0.2049,
      "step": 3450
    },
    {
      "epoch": 0.9885714285714285,
      "grad_norm": 0.04477304220199585,
      "learning_rate": 1.8681904761904763e-05,
      "loss": 0.2367,
      "step": 3460
    },
    {
      "epoch": 0.9914285714285714,
      "grad_norm": 0.08243273943662643,
      "learning_rate": 1.867809523809524e-05,
      "loss": 0.3221,
      "step": 3470
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 0.07057680189609528,
      "learning_rate": 1.8674285714285717e-05,
      "loss": 0.003,
      "step": 3480
    },
    {
      "epoch": 0.9971428571428571,
      "grad_norm": 0.015459281392395496,
      "learning_rate": 1.8670476190476193e-05,
      "loss": 0.3563,
      "step": 3490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09167928248643875,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.6882,
      "step": 3500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.957,
      "eval_f1": 0.6906474820143884,
      "eval_loss": 0.2319348156452179,
      "eval_precision": 0.8834355828220859,
      "eval_recall": 0.5669291338582677,
      "eval_runtime": 256.8658,
      "eval_samples_per_second": 11.679,
      "eval_steps_per_second": 2.92,
      "step": 3500
    },
    {
      "epoch": 1.002857142857143,
      "grad_norm": 21.8320255279541,
      "learning_rate": 1.8662857142857144e-05,
      "loss": 0.315,
      "step": 3510
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 0.1493319422006607,
      "learning_rate": 1.865904761904762e-05,
      "loss": 0.0031,
      "step": 3520
    },
    {
      "epoch": 1.0085714285714287,
      "grad_norm": 0.025866584852337837,
      "learning_rate": 1.86552380952381e-05,
      "loss": 0.1072,
      "step": 3530
    },
    {
      "epoch": 1.0114285714285713,
      "grad_norm": 0.019378503784537315,
      "learning_rate": 1.8651428571428574e-05,
      "loss": 0.1184,
      "step": 3540
    },
    {
      "epoch": 1.0142857142857142,
      "grad_norm": 15.412638664245605,
      "learning_rate": 1.864761904761905e-05,
      "loss": 0.3929,
      "step": 3550
    },
    {
      "epoch": 1.0171428571428571,
      "grad_norm": 1.1221753358840942,
      "learning_rate": 1.8643809523809526e-05,
      "loss": 0.3698,
      "step": 3560
    },
    {
      "epoch": 1.02,
      "grad_norm": 39.44636154174805,
      "learning_rate": 1.864e-05,
      "loss": 0.2925,
      "step": 3570
    },
    {
      "epoch": 1.022857142857143,
      "grad_norm": 0.03519614413380623,
      "learning_rate": 1.8636190476190477e-05,
      "loss": 0.1203,
      "step": 3580
    },
    {
      "epoch": 1.0257142857142858,
      "grad_norm": 0.044690754264593124,
      "learning_rate": 1.8632380952380952e-05,
      "loss": 0.3081,
      "step": 3590
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 0.05226545408368111,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 0.1329,
      "step": 3600
    },
    {
      "epoch": 1.0314285714285714,
      "grad_norm": 0.015388000756502151,
      "learning_rate": 1.8624761904761907e-05,
      "loss": 0.4511,
      "step": 3610
    },
    {
      "epoch": 1.0342857142857143,
      "grad_norm": 0.13827459514141083,
      "learning_rate": 1.8620952380952382e-05,
      "loss": 0.1286,
      "step": 3620
    },
    {
      "epoch": 1.0371428571428571,
      "grad_norm": 0.09139753133058548,
      "learning_rate": 1.8617142857142858e-05,
      "loss": 0.0026,
      "step": 3630
    },
    {
      "epoch": 1.04,
      "grad_norm": 18.632360458374023,
      "learning_rate": 1.8613333333333334e-05,
      "loss": 0.1769,
      "step": 3640
    },
    {
      "epoch": 1.042857142857143,
      "grad_norm": 53.465240478515625,
      "learning_rate": 1.860952380952381e-05,
      "loss": 0.4143,
      "step": 3650
    },
    {
      "epoch": 1.0457142857142858,
      "grad_norm": 0.12212448567152023,
      "learning_rate": 1.8605714285714288e-05,
      "loss": 0.1571,
      "step": 3660
    },
    {
      "epoch": 1.0485714285714285,
      "grad_norm": 0.06663913279771805,
      "learning_rate": 1.8601904761904764e-05,
      "loss": 0.1856,
      "step": 3670
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 0.06733796745538712,
      "learning_rate": 1.859809523809524e-05,
      "loss": 0.3462,
      "step": 3680
    },
    {
      "epoch": 1.0542857142857143,
      "grad_norm": 0.13270480930805206,
      "learning_rate": 1.8594285714285715e-05,
      "loss": 0.0636,
      "step": 3690
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 19.525732040405273,
      "learning_rate": 1.859047619047619e-05,
      "loss": 0.1608,
      "step": 3700
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.012903930619359016,
      "learning_rate": 1.858666666666667e-05,
      "loss": 0.0007,
      "step": 3710
    },
    {
      "epoch": 1.062857142857143,
      "grad_norm": 0.024610595777630806,
      "learning_rate": 1.8582857142857145e-05,
      "loss": 0.2961,
      "step": 3720
    },
    {
      "epoch": 1.0657142857142856,
      "grad_norm": 20.991674423217773,
      "learning_rate": 1.857904761904762e-05,
      "loss": 0.2025,
      "step": 3730
    },
    {
      "epoch": 1.0685714285714285,
      "grad_norm": 0.024492783471941948,
      "learning_rate": 1.8575238095238096e-05,
      "loss": 0.0019,
      "step": 3740
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.04212086647748947,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.1987,
      "step": 3750
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 0.0585995614528656,
      "learning_rate": 1.856761904761905e-05,
      "loss": 0.4428,
      "step": 3760
    },
    {
      "epoch": 1.0771428571428572,
      "grad_norm": 0.1047653928399086,
      "learning_rate": 1.8563809523809526e-05,
      "loss": 0.221,
      "step": 3770
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.0920538380742073,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 0.3381,
      "step": 3780
    },
    {
      "epoch": 1.0828571428571427,
      "grad_norm": 0.090979665517807,
      "learning_rate": 1.8556190476190477e-05,
      "loss": 0.0962,
      "step": 3790
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.07746392488479614,
      "learning_rate": 1.8552380952380953e-05,
      "loss": 0.0929,
      "step": 3800
    },
    {
      "epoch": 1.0885714285714285,
      "grad_norm": 0.026116475462913513,
      "learning_rate": 1.854857142857143e-05,
      "loss": 0.1507,
      "step": 3810
    },
    {
      "epoch": 1.0914285714285714,
      "grad_norm": 0.008792019449174404,
      "learning_rate": 1.8544761904761904e-05,
      "loss": 0.0004,
      "step": 3820
    },
    {
      "epoch": 1.0942857142857143,
      "grad_norm": 0.00639289291575551,
      "learning_rate": 1.8540952380952383e-05,
      "loss": 0.3013,
      "step": 3830
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 24.68521499633789,
      "learning_rate": 1.853714285714286e-05,
      "loss": 0.421,
      "step": 3840
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.10249345749616623,
      "learning_rate": 1.8533333333333334e-05,
      "loss": 0.1449,
      "step": 3850
    },
    {
      "epoch": 1.1028571428571428,
      "grad_norm": 0.10459502786397934,
      "learning_rate": 1.852952380952381e-05,
      "loss": 0.2125,
      "step": 3860
    },
    {
      "epoch": 1.1057142857142856,
      "grad_norm": 0.060374125838279724,
      "learning_rate": 1.8525714285714285e-05,
      "loss": 0.1898,
      "step": 3870
    },
    {
      "epoch": 1.1085714285714285,
      "grad_norm": 0.023018496111035347,
      "learning_rate": 1.8521904761904764e-05,
      "loss": 0.2716,
      "step": 3880
    },
    {
      "epoch": 1.1114285714285714,
      "grad_norm": 0.055948831140995026,
      "learning_rate": 1.851809523809524e-05,
      "loss": 0.2197,
      "step": 3890
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 0.038117025047540665,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 0.0688,
      "step": 3900
    },
    {
      "epoch": 1.1171428571428572,
      "grad_norm": 0.043504733592271805,
      "learning_rate": 1.851047619047619e-05,
      "loss": 0.4033,
      "step": 3910
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.09898314625024796,
      "learning_rate": 1.8506666666666667e-05,
      "loss": 0.2873,
      "step": 3920
    },
    {
      "epoch": 1.1228571428571428,
      "grad_norm": 0.060884129256010056,
      "learning_rate": 1.8502857142857146e-05,
      "loss": 0.0085,
      "step": 3930
    },
    {
      "epoch": 1.1257142857142857,
      "grad_norm": 0.08616730570793152,
      "learning_rate": 1.849904761904762e-05,
      "loss": 0.1273,
      "step": 3940
    },
    {
      "epoch": 1.1285714285714286,
      "grad_norm": 0.13640521466732025,
      "learning_rate": 1.8495238095238097e-05,
      "loss": 0.2651,
      "step": 3950
    },
    {
      "epoch": 1.1314285714285715,
      "grad_norm": 0.005858791526407003,
      "learning_rate": 1.8491428571428573e-05,
      "loss": 0.0001,
      "step": 3960
    },
    {
      "epoch": 1.1342857142857143,
      "grad_norm": 27.90162467956543,
      "learning_rate": 1.848761904761905e-05,
      "loss": 0.4883,
      "step": 3970
    },
    {
      "epoch": 1.1371428571428572,
      "grad_norm": 0.10280237346887589,
      "learning_rate": 1.8483809523809527e-05,
      "loss": 0.3358,
      "step": 3980
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.03022344969213009,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 0.0098,
      "step": 3990
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.021099111065268517,
      "learning_rate": 1.8476190476190478e-05,
      "loss": 0.2726,
      "step": 4000
    },
    {
      "epoch": 1.1457142857142857,
      "grad_norm": 0.16526317596435547,
      "learning_rate": 1.8472380952380954e-05,
      "loss": 0.1546,
      "step": 4010
    },
    {
      "epoch": 1.1485714285714286,
      "grad_norm": 0.12983140349388123,
      "learning_rate": 1.846857142857143e-05,
      "loss": 0.002,
      "step": 4020
    },
    {
      "epoch": 1.1514285714285715,
      "grad_norm": 0.45068198442459106,
      "learning_rate": 1.8464761904761905e-05,
      "loss": 0.0006,
      "step": 4030
    },
    {
      "epoch": 1.1542857142857144,
      "grad_norm": 0.4133240878582001,
      "learning_rate": 1.846095238095238e-05,
      "loss": 0.4986,
      "step": 4040
    },
    {
      "epoch": 1.157142857142857,
      "grad_norm": 1.5738791227340698,
      "learning_rate": 1.845714285714286e-05,
      "loss": 0.1036,
      "step": 4050
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.07934322953224182,
      "learning_rate": 1.8453333333333335e-05,
      "loss": 0.3628,
      "step": 4060
    },
    {
      "epoch": 1.1628571428571428,
      "grad_norm": 0.21508412063121796,
      "learning_rate": 1.844952380952381e-05,
      "loss": 0.1249,
      "step": 4070
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 0.11779840290546417,
      "learning_rate": 1.8445714285714286e-05,
      "loss": 0.3129,
      "step": 4080
    },
    {
      "epoch": 1.1685714285714286,
      "grad_norm": 0.011138945817947388,
      "learning_rate": 1.8441904761904762e-05,
      "loss": 0.0008,
      "step": 4090
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 10.055977821350098,
      "learning_rate": 1.843809523809524e-05,
      "loss": 0.2261,
      "step": 4100
    },
    {
      "epoch": 1.1742857142857144,
      "grad_norm": 0.22440791130065918,
      "learning_rate": 1.8434285714285716e-05,
      "loss": 0.1809,
      "step": 4110
    },
    {
      "epoch": 1.177142857142857,
      "grad_norm": 0.010776291601359844,
      "learning_rate": 1.8430476190476192e-05,
      "loss": 0.2317,
      "step": 4120
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.025110138580203056,
      "learning_rate": 1.8426666666666668e-05,
      "loss": 0.0003,
      "step": 4130
    },
    {
      "epoch": 1.1828571428571428,
      "grad_norm": 0.08397608250379562,
      "learning_rate": 1.8422857142857143e-05,
      "loss": 0.0914,
      "step": 4140
    },
    {
      "epoch": 1.1857142857142857,
      "grad_norm": 0.05569176375865936,
      "learning_rate": 1.8419047619047622e-05,
      "loss": 0.1649,
      "step": 4150
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 2.9575722217559814,
      "learning_rate": 1.8415238095238098e-05,
      "loss": 0.0027,
      "step": 4160
    },
    {
      "epoch": 1.1914285714285715,
      "grad_norm": 41.00956344604492,
      "learning_rate": 1.8411428571428573e-05,
      "loss": 0.1005,
      "step": 4170
    },
    {
      "epoch": 1.1942857142857144,
      "grad_norm": 0.02162364311516285,
      "learning_rate": 1.840761904761905e-05,
      "loss": 0.3391,
      "step": 4180
    },
    {
      "epoch": 1.197142857142857,
      "grad_norm": 0.011281928047537804,
      "learning_rate": 1.8403809523809524e-05,
      "loss": 0.02,
      "step": 4190
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.019948212429881096,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.0014,
      "step": 4200
    },
    {
      "epoch": 1.2028571428571428,
      "grad_norm": 0.0698871910572052,
      "learning_rate": 1.839619047619048e-05,
      "loss": 0.2996,
      "step": 4210
    },
    {
      "epoch": 1.2057142857142857,
      "grad_norm": 0.12612198293209076,
      "learning_rate": 1.8392380952380955e-05,
      "loss": 0.4492,
      "step": 4220
    },
    {
      "epoch": 1.2085714285714286,
      "grad_norm": 4.586240768432617,
      "learning_rate": 1.838857142857143e-05,
      "loss": 0.0042,
      "step": 4230
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 0.06647414714097977,
      "learning_rate": 1.8384761904761906e-05,
      "loss": 0.0041,
      "step": 4240
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 21.98322105407715,
      "learning_rate": 1.838095238095238e-05,
      "loss": 0.5423,
      "step": 4250
    },
    {
      "epoch": 1.217142857142857,
      "grad_norm": 0.05261895805597305,
      "learning_rate": 1.8377142857142857e-05,
      "loss": 0.1453,
      "step": 4260
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.0891561508178711,
      "learning_rate": 1.8373333333333332e-05,
      "loss": 0.004,
      "step": 4270
    },
    {
      "epoch": 1.2228571428571429,
      "grad_norm": 103.78069305419922,
      "learning_rate": 1.836952380952381e-05,
      "loss": 0.4202,
      "step": 4280
    },
    {
      "epoch": 1.2257142857142858,
      "grad_norm": 20.9505615234375,
      "learning_rate": 1.8365714285714287e-05,
      "loss": 0.7907,
      "step": 4290
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 0.25620391964912415,
      "learning_rate": 1.8361904761904763e-05,
      "loss": 0.138,
      "step": 4300
    },
    {
      "epoch": 1.2314285714285713,
      "grad_norm": 0.02973361872136593,
      "learning_rate": 1.8358095238095238e-05,
      "loss": 0.3047,
      "step": 4310
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 0.03203567862510681,
      "learning_rate": 1.8354285714285717e-05,
      "loss": 0.1289,
      "step": 4320
    },
    {
      "epoch": 1.237142857142857,
      "grad_norm": 0.6304044723510742,
      "learning_rate": 1.8350476190476193e-05,
      "loss": 0.4567,
      "step": 4330
    },
    {
      "epoch": 1.24,
      "grad_norm": 44.44674301147461,
      "learning_rate": 1.834666666666667e-05,
      "loss": 0.1597,
      "step": 4340
    },
    {
      "epoch": 1.2428571428571429,
      "grad_norm": 0.025342106819152832,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 0.0098,
      "step": 4350
    },
    {
      "epoch": 1.2457142857142858,
      "grad_norm": 0.016709480434656143,
      "learning_rate": 1.833904761904762e-05,
      "loss": 0.0629,
      "step": 4360
    },
    {
      "epoch": 1.2485714285714287,
      "grad_norm": 0.013362476602196693,
      "learning_rate": 1.83352380952381e-05,
      "loss": 0.0012,
      "step": 4370
    },
    {
      "epoch": 1.2514285714285713,
      "grad_norm": 0.018195196986198425,
      "learning_rate": 1.8331428571428574e-05,
      "loss": 0.2227,
      "step": 4380
    },
    {
      "epoch": 1.2542857142857142,
      "grad_norm": 5.272280216217041,
      "learning_rate": 1.832761904761905e-05,
      "loss": 0.2876,
      "step": 4390
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.083217553794384,
      "learning_rate": 1.8323809523809525e-05,
      "loss": 0.0421,
      "step": 4400
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.34298357367515564,
      "learning_rate": 1.832e-05,
      "loss": 0.0757,
      "step": 4410
    },
    {
      "epoch": 1.262857142857143,
      "grad_norm": 0.011382513679564,
      "learning_rate": 1.831619047619048e-05,
      "loss": 0.002,
      "step": 4420
    },
    {
      "epoch": 1.2657142857142858,
      "grad_norm": 0.6748874187469482,
      "learning_rate": 1.8312380952380955e-05,
      "loss": 0.2823,
      "step": 4430
    },
    {
      "epoch": 1.2685714285714287,
      "grad_norm": 0.02375037781894207,
      "learning_rate": 1.830857142857143e-05,
      "loss": 0.2324,
      "step": 4440
    },
    {
      "epoch": 1.2714285714285714,
      "grad_norm": 0.059681523591279984,
      "learning_rate": 1.8304761904761906e-05,
      "loss": 0.1364,
      "step": 4450
    },
    {
      "epoch": 1.2742857142857142,
      "grad_norm": 1.5468031167984009,
      "learning_rate": 1.8300952380952382e-05,
      "loss": 0.3365,
      "step": 4460
    },
    {
      "epoch": 1.2771428571428571,
      "grad_norm": 48.86809158325195,
      "learning_rate": 1.8297142857142858e-05,
      "loss": 0.397,
      "step": 4470
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.06352657079696655,
      "learning_rate": 1.8293333333333333e-05,
      "loss": 0.0008,
      "step": 4480
    },
    {
      "epoch": 1.282857142857143,
      "grad_norm": 0.2237338423728943,
      "learning_rate": 1.828952380952381e-05,
      "loss": 0.0326,
      "step": 4490
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.011331378482282162,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 0.1558,
      "step": 4500
    },
    {
      "epoch": 1.2885714285714287,
      "grad_norm": 0.029012497514486313,
      "learning_rate": 1.8281904761904763e-05,
      "loss": 0.0061,
      "step": 4510
    },
    {
      "epoch": 1.2914285714285714,
      "grad_norm": 0.005301942117512226,
      "learning_rate": 1.827809523809524e-05,
      "loss": 0.2552,
      "step": 4520
    },
    {
      "epoch": 1.2942857142857143,
      "grad_norm": 0.06021527573466301,
      "learning_rate": 1.8274285714285715e-05,
      "loss": 0.0153,
      "step": 4530
    },
    {
      "epoch": 1.2971428571428572,
      "grad_norm": 0.017956770956516266,
      "learning_rate": 1.827047619047619e-05,
      "loss": 0.553,
      "step": 4540
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.01615821197628975,
      "learning_rate": 1.826666666666667e-05,
      "loss": 0.1202,
      "step": 4550
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 0.0292282123118639,
      "learning_rate": 1.8262857142857145e-05,
      "loss": 0.1621,
      "step": 4560
    },
    {
      "epoch": 1.3057142857142856,
      "grad_norm": 49.146793365478516,
      "learning_rate": 1.825904761904762e-05,
      "loss": 0.4461,
      "step": 4570
    },
    {
      "epoch": 1.3085714285714285,
      "grad_norm": 0.28207677602767944,
      "learning_rate": 1.8255238095238096e-05,
      "loss": 0.0977,
      "step": 4580
    },
    {
      "epoch": 1.3114285714285714,
      "grad_norm": 0.03590510040521622,
      "learning_rate": 1.8251428571428575e-05,
      "loss": 0.0078,
      "step": 4590
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 0.0028267342131584883,
      "learning_rate": 1.824761904761905e-05,
      "loss": 0.157,
      "step": 4600
    },
    {
      "epoch": 1.3171428571428572,
      "grad_norm": 0.0021945375483483076,
      "learning_rate": 1.8243809523809526e-05,
      "loss": 0.2439,
      "step": 4610
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.0024046548642218113,
      "learning_rate": 1.824e-05,
      "loss": 0.2615,
      "step": 4620
    },
    {
      "epoch": 1.322857142857143,
      "grad_norm": 30.39841651916504,
      "learning_rate": 1.8236190476190477e-05,
      "loss": 0.1802,
      "step": 4630
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 0.016754820942878723,
      "learning_rate": 1.8232380952380956e-05,
      "loss": 0.3524,
      "step": 4640
    },
    {
      "epoch": 1.3285714285714285,
      "grad_norm": 54.71649169921875,
      "learning_rate": 1.822857142857143e-05,
      "loss": 0.147,
      "step": 4650
    },
    {
      "epoch": 1.3314285714285714,
      "grad_norm": 0.12099259346723557,
      "learning_rate": 1.8224761904761907e-05,
      "loss": 0.0683,
      "step": 4660
    },
    {
      "epoch": 1.3342857142857143,
      "grad_norm": 0.12467543035745621,
      "learning_rate": 1.8220952380952383e-05,
      "loss": 0.0016,
      "step": 4670
    },
    {
      "epoch": 1.3371428571428572,
      "grad_norm": 0.012845341116189957,
      "learning_rate": 1.821714285714286e-05,
      "loss": 0.0002,
      "step": 4680
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.04037262499332428,
      "learning_rate": 1.8213333333333334e-05,
      "loss": 0.4508,
      "step": 4690
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 28.4140625,
      "learning_rate": 1.820952380952381e-05,
      "loss": 0.7128,
      "step": 4700
    },
    {
      "epoch": 1.3457142857142856,
      "grad_norm": 1.706868290901184,
      "learning_rate": 1.8205714285714285e-05,
      "loss": 0.1013,
      "step": 4710
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 0.013231528922915459,
      "learning_rate": 1.8201904761904764e-05,
      "loss": 0.1711,
      "step": 4720
    },
    {
      "epoch": 1.3514285714285714,
      "grad_norm": 0.012431295588612556,
      "learning_rate": 1.819809523809524e-05,
      "loss": 0.1261,
      "step": 4730
    },
    {
      "epoch": 1.3542857142857143,
      "grad_norm": 0.007440019398927689,
      "learning_rate": 1.8194285714285715e-05,
      "loss": 0.0012,
      "step": 4740
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 0.5499964356422424,
      "learning_rate": 1.819047619047619e-05,
      "loss": 0.3278,
      "step": 4750
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.012506809085607529,
      "learning_rate": 1.8186666666666666e-05,
      "loss": 0.1788,
      "step": 4760
    },
    {
      "epoch": 1.362857142857143,
      "grad_norm": 22.709848403930664,
      "learning_rate": 1.8182857142857145e-05,
      "loss": 0.6295,
      "step": 4770
    },
    {
      "epoch": 1.3657142857142857,
      "grad_norm": 0.04786396771669388,
      "learning_rate": 1.817904761904762e-05,
      "loss": 0.0017,
      "step": 4780
    },
    {
      "epoch": 1.3685714285714285,
      "grad_norm": 0.015982668846845627,
      "learning_rate": 1.8175238095238097e-05,
      "loss": 0.0051,
      "step": 4790
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 0.02782118134200573,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 0.3562,
      "step": 4800
    },
    {
      "epoch": 1.3742857142857143,
      "grad_norm": 0.12011276185512543,
      "learning_rate": 1.816761904761905e-05,
      "loss": 0.2582,
      "step": 4810
    },
    {
      "epoch": 1.3771428571428572,
      "grad_norm": 0.04235933721065521,
      "learning_rate": 1.8163809523809527e-05,
      "loss": 0.2314,
      "step": 4820
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.03602088615298271,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 0.1458,
      "step": 4830
    },
    {
      "epoch": 1.3828571428571428,
      "grad_norm": 0.07640901207923889,
      "learning_rate": 1.8156190476190478e-05,
      "loss": 0.4118,
      "step": 4840
    },
    {
      "epoch": 1.3857142857142857,
      "grad_norm": 26.76634407043457,
      "learning_rate": 1.8152380952380953e-05,
      "loss": 0.3119,
      "step": 4850
    },
    {
      "epoch": 1.3885714285714286,
      "grad_norm": 21.219234466552734,
      "learning_rate": 1.8148571428571432e-05,
      "loss": 0.1408,
      "step": 4860
    },
    {
      "epoch": 1.3914285714285715,
      "grad_norm": 30.047679901123047,
      "learning_rate": 1.8144761904761908e-05,
      "loss": 0.2284,
      "step": 4870
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 0.04281432181596756,
      "learning_rate": 1.8140952380952384e-05,
      "loss": 0.3914,
      "step": 4880
    },
    {
      "epoch": 1.3971428571428572,
      "grad_norm": 0.2650270462036133,
      "learning_rate": 1.813714285714286e-05,
      "loss": 0.0025,
      "step": 4890
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.020607372745871544,
      "learning_rate": 1.8133333333333335e-05,
      "loss": 0.262,
      "step": 4900
    },
    {
      "epoch": 1.4028571428571428,
      "grad_norm": 0.09199856966733932,
      "learning_rate": 1.812952380952381e-05,
      "loss": 0.1791,
      "step": 4910
    },
    {
      "epoch": 1.4057142857142857,
      "grad_norm": 0.027687493711709976,
      "learning_rate": 1.8125714285714286e-05,
      "loss": 0.0008,
      "step": 4920
    },
    {
      "epoch": 1.4085714285714286,
      "grad_norm": 0.05672021210193634,
      "learning_rate": 1.812190476190476e-05,
      "loss": 0.2278,
      "step": 4930
    },
    {
      "epoch": 1.4114285714285715,
      "grad_norm": 0.11868089437484741,
      "learning_rate": 1.811809523809524e-05,
      "loss": 0.2031,
      "step": 4940
    },
    {
      "epoch": 1.4142857142857144,
      "grad_norm": 0.04560631141066551,
      "learning_rate": 1.8114285714285716e-05,
      "loss": 0.0012,
      "step": 4950
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 0.03724850341677666,
      "learning_rate": 1.811047619047619e-05,
      "loss": 0.1637,
      "step": 4960
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.023504169657826424,
      "learning_rate": 1.8106666666666667e-05,
      "loss": 0.1501,
      "step": 4970
    },
    {
      "epoch": 1.4228571428571428,
      "grad_norm": 0.024073956534266472,
      "learning_rate": 1.8102857142857143e-05,
      "loss": 0.0813,
      "step": 4980
    },
    {
      "epoch": 1.4257142857142857,
      "grad_norm": 0.020983316004276276,
      "learning_rate": 1.8099047619047622e-05,
      "loss": 0.1541,
      "step": 4990
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.05558491125702858,
      "learning_rate": 1.8095238095238097e-05,
      "loss": 0.0006,
      "step": 5000
    },
    {
      "epoch": 1.4314285714285715,
      "grad_norm": 0.010544716380536556,
      "learning_rate": 1.8091428571428573e-05,
      "loss": 0.1808,
      "step": 5010
    },
    {
      "epoch": 1.4342857142857142,
      "grad_norm": 0.01012964267283678,
      "learning_rate": 1.808761904761905e-05,
      "loss": 0.001,
      "step": 5020
    },
    {
      "epoch": 1.4371428571428573,
      "grad_norm": 0.02620534785091877,
      "learning_rate": 1.8083809523809524e-05,
      "loss": 0.3768,
      "step": 5030
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.014289612881839275,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.1613,
      "step": 5040
    },
    {
      "epoch": 1.4428571428571428,
      "grad_norm": 0.07558757811784744,
      "learning_rate": 1.807619047619048e-05,
      "loss": 0.0008,
      "step": 5050
    },
    {
      "epoch": 1.4457142857142857,
      "grad_norm": 0.05155816674232483,
      "learning_rate": 1.8072380952380954e-05,
      "loss": 0.2806,
      "step": 5060
    },
    {
      "epoch": 1.4485714285714286,
      "grad_norm": 0.045063942670822144,
      "learning_rate": 1.806857142857143e-05,
      "loss": 0.0147,
      "step": 5070
    },
    {
      "epoch": 1.4514285714285715,
      "grad_norm": 0.054959457367658615,
      "learning_rate": 1.806476190476191e-05,
      "loss": 0.3685,
      "step": 5080
    },
    {
      "epoch": 1.4542857142857142,
      "grad_norm": 0.0860808938741684,
      "learning_rate": 1.8060952380952384e-05,
      "loss": 0.3238,
      "step": 5090
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 0.1684718132019043,
      "learning_rate": 1.8057142857142857e-05,
      "loss": 0.1176,
      "step": 5100
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.07803665846586227,
      "learning_rate": 1.8053333333333332e-05,
      "loss": 0.3532,
      "step": 5110
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 0.09496498107910156,
      "learning_rate": 1.804952380952381e-05,
      "loss": 0.167,
      "step": 5120
    },
    {
      "epoch": 1.4657142857142857,
      "grad_norm": 0.06116526201367378,
      "learning_rate": 1.8045714285714287e-05,
      "loss": 0.0895,
      "step": 5130
    },
    {
      "epoch": 1.4685714285714286,
      "grad_norm": 0.03064057230949402,
      "learning_rate": 1.8041904761904762e-05,
      "loss": 0.1551,
      "step": 5140
    },
    {
      "epoch": 1.4714285714285715,
      "grad_norm": 53.30009841918945,
      "learning_rate": 1.8038095238095238e-05,
      "loss": 0.1549,
      "step": 5150
    },
    {
      "epoch": 1.4742857142857142,
      "grad_norm": 19.0037841796875,
      "learning_rate": 1.8034285714285717e-05,
      "loss": 0.3724,
      "step": 5160
    },
    {
      "epoch": 1.477142857142857,
      "grad_norm": 0.10240556299686432,
      "learning_rate": 1.8030476190476192e-05,
      "loss": 0.1748,
      "step": 5170
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.04967421293258667,
      "learning_rate": 1.8026666666666668e-05,
      "loss": 0.5297,
      "step": 5180
    },
    {
      "epoch": 1.4828571428571429,
      "grad_norm": 0.042152974754571915,
      "learning_rate": 1.8022857142857144e-05,
      "loss": 0.0009,
      "step": 5190
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.04163261875510216,
      "learning_rate": 1.801904761904762e-05,
      "loss": 0.0183,
      "step": 5200
    },
    {
      "epoch": 1.4885714285714284,
      "grad_norm": 0.13672402501106262,
      "learning_rate": 1.8015238095238098e-05,
      "loss": 0.3285,
      "step": 5210
    },
    {
      "epoch": 1.4914285714285715,
      "grad_norm": 0.03463607653975487,
      "learning_rate": 1.8011428571428574e-05,
      "loss": 0.002,
      "step": 5220
    },
    {
      "epoch": 1.4942857142857142,
      "grad_norm": 0.019159674644470215,
      "learning_rate": 1.800761904761905e-05,
      "loss": 0.188,
      "step": 5230
    },
    {
      "epoch": 1.497142857142857,
      "grad_norm": 0.03839742764830589,
      "learning_rate": 1.8003809523809525e-05,
      "loss": 0.0009,
      "step": 5240
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.043429285287857056,
      "learning_rate": 1.8e-05,
      "loss": 0.1249,
      "step": 5250
    },
    {
      "epoch": 1.502857142857143,
      "grad_norm": 17.186098098754883,
      "learning_rate": 1.799619047619048e-05,
      "loss": 0.171,
      "step": 5260
    },
    {
      "epoch": 1.5057142857142858,
      "grad_norm": 0.047072432935237885,
      "learning_rate": 1.7992380952380955e-05,
      "loss": 0.0413,
      "step": 5270
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 5.428199768066406,
      "learning_rate": 1.798857142857143e-05,
      "loss": 0.136,
      "step": 5280
    },
    {
      "epoch": 1.5114285714285716,
      "grad_norm": 0.03102465532720089,
      "learning_rate": 1.7984761904761906e-05,
      "loss": 0.0009,
      "step": 5290
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 0.10812614858150482,
      "learning_rate": 1.7980952380952382e-05,
      "loss": 0.1237,
      "step": 5300
    },
    {
      "epoch": 1.5171428571428571,
      "grad_norm": 21.216903686523438,
      "learning_rate": 1.797714285714286e-05,
      "loss": 0.3443,
      "step": 5310
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.031232034787535667,
      "learning_rate": 1.7973333333333333e-05,
      "loss": 0.1822,
      "step": 5320
    },
    {
      "epoch": 1.522857142857143,
      "grad_norm": 21.106718063354492,
      "learning_rate": 1.796952380952381e-05,
      "loss": 0.4593,
      "step": 5330
    },
    {
      "epoch": 1.5257142857142858,
      "grad_norm": 37.75373840332031,
      "learning_rate": 1.7965714285714287e-05,
      "loss": 0.1919,
      "step": 5340
    },
    {
      "epoch": 1.5285714285714285,
      "grad_norm": 2.3779795169830322,
      "learning_rate": 1.7961904761904763e-05,
      "loss": 0.1097,
      "step": 5350
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 17.834442138671875,
      "learning_rate": 1.795809523809524e-05,
      "loss": 0.0095,
      "step": 5360
    },
    {
      "epoch": 1.5342857142857143,
      "grad_norm": 0.09529438614845276,
      "learning_rate": 1.7954285714285714e-05,
      "loss": 0.3522,
      "step": 5370
    },
    {
      "epoch": 1.5371428571428571,
      "grad_norm": 0.032773543149232864,
      "learning_rate": 1.7950476190476193e-05,
      "loss": 0.1306,
      "step": 5380
    },
    {
      "epoch": 1.54,
      "grad_norm": 23.715301513671875,
      "learning_rate": 1.794666666666667e-05,
      "loss": 0.2767,
      "step": 5390
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 0.22284644842147827,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 0.1434,
      "step": 5400
    },
    {
      "epoch": 1.5457142857142858,
      "grad_norm": 0.01838594488799572,
      "learning_rate": 1.793904761904762e-05,
      "loss": 0.0009,
      "step": 5410
    },
    {
      "epoch": 1.5485714285714285,
      "grad_norm": 0.04596269130706787,
      "learning_rate": 1.7935238095238096e-05,
      "loss": 0.1731,
      "step": 5420
    },
    {
      "epoch": 1.5514285714285714,
      "grad_norm": 0.08905293792486191,
      "learning_rate": 1.7931428571428574e-05,
      "loss": 0.6068,
      "step": 5430
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 0.10408584773540497,
      "learning_rate": 1.792761904761905e-05,
      "loss": 0.0889,
      "step": 5440
    },
    {
      "epoch": 1.5571428571428572,
      "grad_norm": 0.19569627940654755,
      "learning_rate": 1.7923809523809526e-05,
      "loss": 0.0849,
      "step": 5450
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.4806842803955078,
      "learning_rate": 1.792e-05,
      "loss": 0.016,
      "step": 5460
    },
    {
      "epoch": 1.5628571428571427,
      "grad_norm": 0.24144604802131653,
      "learning_rate": 1.7916190476190477e-05,
      "loss": 0.001,
      "step": 5470
    },
    {
      "epoch": 1.5657142857142858,
      "grad_norm": 0.01398967020213604,
      "learning_rate": 1.7912380952380956e-05,
      "loss": 0.1436,
      "step": 5480
    },
    {
      "epoch": 1.5685714285714285,
      "grad_norm": 0.02873656526207924,
      "learning_rate": 1.790857142857143e-05,
      "loss": 0.0006,
      "step": 5490
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 42.114952087402344,
      "learning_rate": 1.7904761904761907e-05,
      "loss": 0.151,
      "step": 5500
    },
    {
      "epoch": 1.5742857142857143,
      "grad_norm": 0.029488248750567436,
      "learning_rate": 1.7900952380952383e-05,
      "loss": 0.0003,
      "step": 5510
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 0.007673617452383041,
      "learning_rate": 1.7897142857142858e-05,
      "loss": 0.0002,
      "step": 5520
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.015393661335110664,
      "learning_rate": 1.7893333333333337e-05,
      "loss": 0.3079,
      "step": 5530
    },
    {
      "epoch": 1.5828571428571427,
      "grad_norm": 0.03900193050503731,
      "learning_rate": 1.788952380952381e-05,
      "loss": 0.1565,
      "step": 5540
    },
    {
      "epoch": 1.5857142857142859,
      "grad_norm": 0.01876128278672695,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 0.2185,
      "step": 5550
    },
    {
      "epoch": 1.5885714285714285,
      "grad_norm": 0.011382478289306164,
      "learning_rate": 1.7881904761904764e-05,
      "loss": 0.1606,
      "step": 5560
    },
    {
      "epoch": 1.5914285714285714,
      "grad_norm": 54.086952209472656,
      "learning_rate": 1.787809523809524e-05,
      "loss": 0.2834,
      "step": 5570
    },
    {
      "epoch": 1.5942857142857143,
      "grad_norm": 55.28590774536133,
      "learning_rate": 1.7874285714285715e-05,
      "loss": 0.411,
      "step": 5580
    },
    {
      "epoch": 1.5971428571428572,
      "grad_norm": 0.06371605396270752,
      "learning_rate": 1.787047619047619e-05,
      "loss": 0.0786,
      "step": 5590
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.6258068084716797,
      "learning_rate": 1.7866666666666666e-05,
      "loss": 0.2259,
      "step": 5600
    },
    {
      "epoch": 1.6028571428571428,
      "grad_norm": 0.07920946925878525,
      "learning_rate": 1.7862857142857145e-05,
      "loss": 0.2131,
      "step": 5610
    },
    {
      "epoch": 1.6057142857142859,
      "grad_norm": 0.019937414675951004,
      "learning_rate": 1.785904761904762e-05,
      "loss": 0.0784,
      "step": 5620
    },
    {
      "epoch": 1.6085714285714285,
      "grad_norm": 0.24056319892406464,
      "learning_rate": 1.7855238095238096e-05,
      "loss": 0.2051,
      "step": 5630
    },
    {
      "epoch": 1.6114285714285714,
      "grad_norm": 0.03911573439836502,
      "learning_rate": 1.7851428571428572e-05,
      "loss": 0.1395,
      "step": 5640
    },
    {
      "epoch": 1.6142857142857143,
      "grad_norm": 0.0423026904463768,
      "learning_rate": 1.784761904761905e-05,
      "loss": 0.2026,
      "step": 5650
    },
    {
      "epoch": 1.617142857142857,
      "grad_norm": 0.027692042291164398,
      "learning_rate": 1.7843809523809526e-05,
      "loss": 0.1961,
      "step": 5660
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.3110915720462799,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 0.2441,
      "step": 5670
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 0.019819127395749092,
      "learning_rate": 1.7836190476190478e-05,
      "loss": 0.0014,
      "step": 5680
    },
    {
      "epoch": 1.6257142857142857,
      "grad_norm": 0.06730984151363373,
      "learning_rate": 1.7832380952380953e-05,
      "loss": 0.214,
      "step": 5690
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 0.01084840577095747,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 0.0005,
      "step": 5700
    },
    {
      "epoch": 1.6314285714285715,
      "grad_norm": 11.251294136047363,
      "learning_rate": 1.7824761904761908e-05,
      "loss": 0.0672,
      "step": 5710
    },
    {
      "epoch": 1.6342857142857143,
      "grad_norm": 42.28056716918945,
      "learning_rate": 1.7820952380952383e-05,
      "loss": 0.1221,
      "step": 5720
    },
    {
      "epoch": 1.637142857142857,
      "grad_norm": 0.09752608090639114,
      "learning_rate": 1.781714285714286e-05,
      "loss": 0.0982,
      "step": 5730
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.2073591947555542,
      "learning_rate": 1.7813333333333334e-05,
      "loss": 0.0009,
      "step": 5740
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 0.008146099746227264,
      "learning_rate": 1.780952380952381e-05,
      "loss": 0.584,
      "step": 5750
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 0.024376433342695236,
      "learning_rate": 1.7805714285714286e-05,
      "loss": 0.0009,
      "step": 5760
    },
    {
      "epoch": 1.6485714285714286,
      "grad_norm": 0.024379823356866837,
      "learning_rate": 1.780190476190476e-05,
      "loss": 0.3586,
      "step": 5770
    },
    {
      "epoch": 1.6514285714285715,
      "grad_norm": 0.04192458465695381,
      "learning_rate": 1.779809523809524e-05,
      "loss": 0.1861,
      "step": 5780
    },
    {
      "epoch": 1.6542857142857144,
      "grad_norm": 10.189682960510254,
      "learning_rate": 1.7794285714285716e-05,
      "loss": 0.1755,
      "step": 5790
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.7204285860061646,
      "learning_rate": 1.779047619047619e-05,
      "loss": 0.3109,
      "step": 5800
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.04836687073111534,
      "learning_rate": 1.7786666666666667e-05,
      "loss": 0.0113,
      "step": 5810
    },
    {
      "epoch": 1.6628571428571428,
      "grad_norm": 0.018856937065720558,
      "learning_rate": 1.7782857142857142e-05,
      "loss": 0.0012,
      "step": 5820
    },
    {
      "epoch": 1.6657142857142857,
      "grad_norm": 0.01431623101234436,
      "learning_rate": 1.777904761904762e-05,
      "loss": 0.1961,
      "step": 5830
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 0.05839749798178673,
      "learning_rate": 1.7775238095238097e-05,
      "loss": 0.3054,
      "step": 5840
    },
    {
      "epoch": 1.6714285714285713,
      "grad_norm": 0.026279309764504433,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 0.0054,
      "step": 5850
    },
    {
      "epoch": 1.6742857142857144,
      "grad_norm": 0.027892695739865303,
      "learning_rate": 1.7767619047619048e-05,
      "loss": 0.3327,
      "step": 5860
    },
    {
      "epoch": 1.677142857142857,
      "grad_norm": 0.04409658536314964,
      "learning_rate": 1.7763809523809524e-05,
      "loss": 0.0012,
      "step": 5870
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.032377757132053375,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.2001,
      "step": 5880
    },
    {
      "epoch": 1.6828571428571428,
      "grad_norm": 24.064556121826172,
      "learning_rate": 1.775619047619048e-05,
      "loss": 0.471,
      "step": 5890
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 0.12255582213401794,
      "learning_rate": 1.7752380952380954e-05,
      "loss": 0.2757,
      "step": 5900
    },
    {
      "epoch": 1.6885714285714286,
      "grad_norm": 0.10347966849803925,
      "learning_rate": 1.774857142857143e-05,
      "loss": 0.2348,
      "step": 5910
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 0.020768076181411743,
      "learning_rate": 1.774476190476191e-05,
      "loss": 0.001,
      "step": 5920
    },
    {
      "epoch": 1.6942857142857144,
      "grad_norm": 0.009307542815804482,
      "learning_rate": 1.7740952380952384e-05,
      "loss": 0.0022,
      "step": 5930
    },
    {
      "epoch": 1.697142857142857,
      "grad_norm": 0.009959195740520954,
      "learning_rate": 1.773714285714286e-05,
      "loss": 0.1761,
      "step": 5940
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.02515401504933834,
      "learning_rate": 1.7733333333333335e-05,
      "loss": 0.0003,
      "step": 5950
    },
    {
      "epoch": 1.7028571428571428,
      "grad_norm": 0.009564700536429882,
      "learning_rate": 1.772952380952381e-05,
      "loss": 0.1965,
      "step": 5960
    },
    {
      "epoch": 1.7057142857142857,
      "grad_norm": 0.1540752351284027,
      "learning_rate": 1.7725714285714286e-05,
      "loss": 0.1621,
      "step": 5970
    },
    {
      "epoch": 1.7085714285714286,
      "grad_norm": 0.06317798048257828,
      "learning_rate": 1.7721904761904762e-05,
      "loss": 0.1687,
      "step": 5980
    },
    {
      "epoch": 1.7114285714285713,
      "grad_norm": 0.08583761006593704,
      "learning_rate": 1.7718095238095238e-05,
      "loss": 0.0166,
      "step": 5990
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.08440892398357391,
      "learning_rate": 1.7714285714285717e-05,
      "loss": 0.0091,
      "step": 6000
    },
    {
      "epoch": 1.717142857142857,
      "grad_norm": 0.04008905589580536,
      "learning_rate": 1.7710476190476192e-05,
      "loss": 0.2907,
      "step": 6010
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.01095692627131939,
      "learning_rate": 1.7706666666666668e-05,
      "loss": 0.0007,
      "step": 6020
    },
    {
      "epoch": 1.7228571428571429,
      "grad_norm": 0.011559915728867054,
      "learning_rate": 1.7702857142857143e-05,
      "loss": 0.0029,
      "step": 6030
    },
    {
      "epoch": 1.7257142857142858,
      "grad_norm": 61.522987365722656,
      "learning_rate": 1.769904761904762e-05,
      "loss": 0.3977,
      "step": 6040
    },
    {
      "epoch": 1.7285714285714286,
      "grad_norm": 0.055199772119522095,
      "learning_rate": 1.7695238095238098e-05,
      "loss": 0.336,
      "step": 6050
    },
    {
      "epoch": 1.7314285714285713,
      "grad_norm": 0.012335960753262043,
      "learning_rate": 1.7691428571428573e-05,
      "loss": 0.0005,
      "step": 6060
    },
    {
      "epoch": 1.7342857142857144,
      "grad_norm": 0.01677507720887661,
      "learning_rate": 1.768761904761905e-05,
      "loss": 0.0012,
      "step": 6070
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 0.02133426070213318,
      "learning_rate": 1.7683809523809525e-05,
      "loss": 0.0029,
      "step": 6080
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.01593761332333088,
      "learning_rate": 1.768e-05,
      "loss": 0.0004,
      "step": 6090
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.01584741286933422,
      "learning_rate": 1.767619047619048e-05,
      "loss": 0.1957,
      "step": 6100
    },
    {
      "epoch": 1.7457142857142856,
      "grad_norm": 0.028307979926466942,
      "learning_rate": 1.7672380952380955e-05,
      "loss": 0.1674,
      "step": 6110
    },
    {
      "epoch": 1.7485714285714287,
      "grad_norm": 28.895631790161133,
      "learning_rate": 1.766857142857143e-05,
      "loss": 0.3885,
      "step": 6120
    },
    {
      "epoch": 1.7514285714285713,
      "grad_norm": 0.14497631788253784,
      "learning_rate": 1.7664761904761906e-05,
      "loss": 0.4509,
      "step": 6130
    },
    {
      "epoch": 1.7542857142857144,
      "grad_norm": 0.4014911651611328,
      "learning_rate": 1.766095238095238e-05,
      "loss": 0.171,
      "step": 6140
    },
    {
      "epoch": 1.7571428571428571,
      "grad_norm": 17.949546813964844,
      "learning_rate": 1.765714285714286e-05,
      "loss": 0.177,
      "step": 6150
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.0372803658246994,
      "learning_rate": 1.7653333333333336e-05,
      "loss": 0.1489,
      "step": 6160
    },
    {
      "epoch": 1.762857142857143,
      "grad_norm": 0.04293191060423851,
      "learning_rate": 1.764952380952381e-05,
      "loss": 0.1826,
      "step": 6170
    },
    {
      "epoch": 1.7657142857142856,
      "grad_norm": 0.047669630497694016,
      "learning_rate": 1.7645714285714287e-05,
      "loss": 0.0879,
      "step": 6180
    },
    {
      "epoch": 1.7685714285714287,
      "grad_norm": 0.14961403608322144,
      "learning_rate": 1.7641904761904763e-05,
      "loss": 0.1491,
      "step": 6190
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 0.03869805112481117,
      "learning_rate": 1.7638095238095238e-05,
      "loss": 0.1114,
      "step": 6200
    },
    {
      "epoch": 1.7742857142857142,
      "grad_norm": 0.08368714898824692,
      "learning_rate": 1.7634285714285714e-05,
      "loss": 0.3215,
      "step": 6210
    },
    {
      "epoch": 1.7771428571428571,
      "grad_norm": 0.04066690057516098,
      "learning_rate": 1.7630476190476193e-05,
      "loss": 0.0009,
      "step": 6220
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.008388085290789604,
      "learning_rate": 1.762666666666667e-05,
      "loss": 0.0007,
      "step": 6230
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 0.05443562939763069,
      "learning_rate": 1.7622857142857144e-05,
      "loss": 0.3269,
      "step": 6240
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.024099528789520264,
      "learning_rate": 1.761904761904762e-05,
      "loss": 0.2598,
      "step": 6250
    },
    {
      "epoch": 1.7885714285714287,
      "grad_norm": 0.05930447205901146,
      "learning_rate": 1.7615238095238095e-05,
      "loss": 0.1079,
      "step": 6260
    },
    {
      "epoch": 1.7914285714285714,
      "grad_norm": 0.050862912088632584,
      "learning_rate": 1.7611428571428574e-05,
      "loss": 0.3918,
      "step": 6270
    },
    {
      "epoch": 1.7942857142857143,
      "grad_norm": 0.0026638018898665905,
      "learning_rate": 1.760761904761905e-05,
      "loss": 0.1323,
      "step": 6280
    },
    {
      "epoch": 1.7971428571428572,
      "grad_norm": 0.03437983617186546,
      "learning_rate": 1.7603809523809525e-05,
      "loss": 0.2825,
      "step": 6290
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.02969066984951496,
      "learning_rate": 1.76e-05,
      "loss": 0.0946,
      "step": 6300
    },
    {
      "epoch": 1.802857142857143,
      "grad_norm": 0.152192622423172,
      "learning_rate": 1.7596190476190476e-05,
      "loss": 0.0012,
      "step": 6310
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 0.09395469725131989,
      "learning_rate": 1.7592380952380955e-05,
      "loss": 0.0003,
      "step": 6320
    },
    {
      "epoch": 1.8085714285714287,
      "grad_norm": 0.03276189789175987,
      "learning_rate": 1.758857142857143e-05,
      "loss": 0.2461,
      "step": 6330
    },
    {
      "epoch": 1.8114285714285714,
      "grad_norm": 0.030010640621185303,
      "learning_rate": 1.7584761904761907e-05,
      "loss": 0.2349,
      "step": 6340
    },
    {
      "epoch": 1.8142857142857143,
      "grad_norm": 91.76335906982422,
      "learning_rate": 1.7580952380952382e-05,
      "loss": 0.1925,
      "step": 6350
    },
    {
      "epoch": 1.8171428571428572,
      "grad_norm": 0.036460503935813904,
      "learning_rate": 1.7577142857142858e-05,
      "loss": 0.098,
      "step": 6360
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.004672843962907791,
      "learning_rate": 1.7573333333333337e-05,
      "loss": 0.0005,
      "step": 6370
    },
    {
      "epoch": 1.822857142857143,
      "grad_norm": 0.016895676031708717,
      "learning_rate": 1.7569523809523812e-05,
      "loss": 0.101,
      "step": 6380
    },
    {
      "epoch": 1.8257142857142856,
      "grad_norm": 0.020525868982076645,
      "learning_rate": 1.7565714285714288e-05,
      "loss": 0.0002,
      "step": 6390
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.003920604474842548,
      "learning_rate": 1.7561904761904763e-05,
      "loss": 0.0003,
      "step": 6400
    },
    {
      "epoch": 1.8314285714285714,
      "grad_norm": 0.001969417557120323,
      "learning_rate": 1.755809523809524e-05,
      "loss": 0.0003,
      "step": 6410
    },
    {
      "epoch": 1.8342857142857143,
      "grad_norm": 0.002846847753971815,
      "learning_rate": 1.7554285714285715e-05,
      "loss": 0.2295,
      "step": 6420
    },
    {
      "epoch": 1.8371428571428572,
      "grad_norm": 0.00864428747445345,
      "learning_rate": 1.755047619047619e-05,
      "loss": 0.3901,
      "step": 6430
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.026338785886764526,
      "learning_rate": 1.7546666666666666e-05,
      "loss": 0.0009,
      "step": 6440
    },
    {
      "epoch": 1.842857142857143,
      "grad_norm": 0.05955450236797333,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 0.0007,
      "step": 6450
    },
    {
      "epoch": 1.8457142857142856,
      "grad_norm": 0.0976504310965538,
      "learning_rate": 1.753904761904762e-05,
      "loss": 0.0688,
      "step": 6460
    },
    {
      "epoch": 1.8485714285714285,
      "grad_norm": 0.014874735847115517,
      "learning_rate": 1.7535238095238096e-05,
      "loss": 0.0018,
      "step": 6470
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 0.018196769058704376,
      "learning_rate": 1.753142857142857e-05,
      "loss": 0.2084,
      "step": 6480
    },
    {
      "epoch": 1.8542857142857143,
      "grad_norm": 0.0149115901440382,
      "learning_rate": 1.752761904761905e-05,
      "loss": 0.3113,
      "step": 6490
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.021432889625430107,
      "learning_rate": 1.7523809523809526e-05,
      "loss": 0.0008,
      "step": 6500
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.02988831140100956,
      "learning_rate": 1.752e-05,
      "loss": 0.324,
      "step": 6510
    },
    {
      "epoch": 1.862857142857143,
      "grad_norm": 0.04404963552951813,
      "learning_rate": 1.7516190476190477e-05,
      "loss": 0.0006,
      "step": 6520
    },
    {
      "epoch": 1.8657142857142857,
      "grad_norm": 0.038742732256650925,
      "learning_rate": 1.7512380952380953e-05,
      "loss": 0.2615,
      "step": 6530
    },
    {
      "epoch": 1.8685714285714285,
      "grad_norm": 47.20213317871094,
      "learning_rate": 1.7508571428571432e-05,
      "loss": 0.1048,
      "step": 6540
    },
    {
      "epoch": 1.8714285714285714,
      "grad_norm": 0.048548374325037,
      "learning_rate": 1.7504761904761907e-05,
      "loss": 0.3729,
      "step": 6550
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 0.03364931046962738,
      "learning_rate": 1.7500952380952383e-05,
      "loss": 0.0922,
      "step": 6560
    },
    {
      "epoch": 1.8771428571428572,
      "grad_norm": 0.286735475063324,
      "learning_rate": 1.749714285714286e-05,
      "loss": 0.0009,
      "step": 6570
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.008277768269181252,
      "learning_rate": 1.7493333333333334e-05,
      "loss": 0.0004,
      "step": 6580
    },
    {
      "epoch": 1.882857142857143,
      "grad_norm": 0.009510825388133526,
      "learning_rate": 1.7489523809523813e-05,
      "loss": 0.1902,
      "step": 6590
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 0.011131040751934052,
      "learning_rate": 1.748571428571429e-05,
      "loss": 0.1091,
      "step": 6600
    },
    {
      "epoch": 1.8885714285714286,
      "grad_norm": 0.04205336421728134,
      "learning_rate": 1.7481904761904764e-05,
      "loss": 0.21,
      "step": 6610
    },
    {
      "epoch": 1.8914285714285715,
      "grad_norm": 0.4545529782772064,
      "learning_rate": 1.747809523809524e-05,
      "loss": 0.0006,
      "step": 6620
    },
    {
      "epoch": 1.8942857142857141,
      "grad_norm": 0.006978739518672228,
      "learning_rate": 1.7474285714285715e-05,
      "loss": 0.0002,
      "step": 6630
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 0.011764736846089363,
      "learning_rate": 1.747047619047619e-05,
      "loss": 0.1238,
      "step": 6640
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.18120788037776947,
      "learning_rate": 1.7466666666666667e-05,
      "loss": 0.1433,
      "step": 6650
    },
    {
      "epoch": 1.9028571428571428,
      "grad_norm": 0.03697209805250168,
      "learning_rate": 1.7462857142857142e-05,
      "loss": 0.1473,
      "step": 6660
    },
    {
      "epoch": 1.9057142857142857,
      "grad_norm": 0.2618740200996399,
      "learning_rate": 1.745904761904762e-05,
      "loss": 0.2133,
      "step": 6670
    },
    {
      "epoch": 1.9085714285714286,
      "grad_norm": 0.04468705505132675,
      "learning_rate": 1.7455238095238097e-05,
      "loss": 0.594,
      "step": 6680
    },
    {
      "epoch": 1.9114285714285715,
      "grad_norm": 0.102951779961586,
      "learning_rate": 1.7451428571428572e-05,
      "loss": 0.1329,
      "step": 6690
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 19.83055877685547,
      "learning_rate": 1.7447619047619048e-05,
      "loss": 0.3174,
      "step": 6700
    },
    {
      "epoch": 1.9171428571428573,
      "grad_norm": 0.21229350566864014,
      "learning_rate": 1.7443809523809523e-05,
      "loss": 0.0052,
      "step": 6710
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.02954982966184616,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.2777,
      "step": 6720
    },
    {
      "epoch": 1.9228571428571428,
      "grad_norm": 0.013921711593866348,
      "learning_rate": 1.7436190476190478e-05,
      "loss": 0.0025,
      "step": 6730
    },
    {
      "epoch": 1.9257142857142857,
      "grad_norm": 0.04060420021414757,
      "learning_rate": 1.7432380952380954e-05,
      "loss": 0.2578,
      "step": 6740
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 0.04252728819847107,
      "learning_rate": 1.742857142857143e-05,
      "loss": 0.1661,
      "step": 6750
    },
    {
      "epoch": 1.9314285714285715,
      "grad_norm": 0.07271694391965866,
      "learning_rate": 1.7424761904761908e-05,
      "loss": 0.0929,
      "step": 6760
    },
    {
      "epoch": 1.9342857142857142,
      "grad_norm": 27.8173885345459,
      "learning_rate": 1.7420952380952384e-05,
      "loss": 0.2007,
      "step": 6770
    },
    {
      "epoch": 1.9371428571428573,
      "grad_norm": 0.030091704800724983,
      "learning_rate": 1.741714285714286e-05,
      "loss": 0.1318,
      "step": 6780
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.017496589571237564,
      "learning_rate": 1.7413333333333335e-05,
      "loss": 0.1106,
      "step": 6790
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 0.0050131347961723804,
      "learning_rate": 1.740952380952381e-05,
      "loss": 0.0007,
      "step": 6800
    },
    {
      "epoch": 1.9457142857142857,
      "grad_norm": 0.017211593687534332,
      "learning_rate": 1.740571428571429e-05,
      "loss": 0.1179,
      "step": 6810
    },
    {
      "epoch": 1.9485714285714286,
      "grad_norm": 0.03705112636089325,
      "learning_rate": 1.7401904761904765e-05,
      "loss": 0.0002,
      "step": 6820
    },
    {
      "epoch": 1.9514285714285715,
      "grad_norm": 0.0160746518522501,
      "learning_rate": 1.739809523809524e-05,
      "loss": 0.0033,
      "step": 6830
    },
    {
      "epoch": 1.9542857142857142,
      "grad_norm": 43.984283447265625,
      "learning_rate": 1.7394285714285716e-05,
      "loss": 0.3454,
      "step": 6840
    },
    {
      "epoch": 1.9571428571428573,
      "grad_norm": 0.006423000246286392,
      "learning_rate": 1.7390476190476192e-05,
      "loss": 0.1863,
      "step": 6850
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.009133554063737392,
      "learning_rate": 1.7386666666666667e-05,
      "loss": 0.4033,
      "step": 6860
    },
    {
      "epoch": 1.9628571428571429,
      "grad_norm": 22.914113998413086,
      "learning_rate": 1.7382857142857143e-05,
      "loss": 0.4765,
      "step": 6870
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 0.06858369708061218,
      "learning_rate": 1.737904761904762e-05,
      "loss": 0.0605,
      "step": 6880
    },
    {
      "epoch": 1.9685714285714284,
      "grad_norm": 0.012559095397591591,
      "learning_rate": 1.7375238095238097e-05,
      "loss": 0.0034,
      "step": 6890
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 92.93463897705078,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 0.1005,
      "step": 6900
    },
    {
      "epoch": 1.9742857142857142,
      "grad_norm": 0.004129649605602026,
      "learning_rate": 1.736761904761905e-05,
      "loss": 0.0032,
      "step": 6910
    },
    {
      "epoch": 1.977142857142857,
      "grad_norm": 0.04539310559630394,
      "learning_rate": 1.7363809523809524e-05,
      "loss": 0.1955,
      "step": 6920
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.032767437398433685,
      "learning_rate": 1.736e-05,
      "loss": 0.2798,
      "step": 6930
    },
    {
      "epoch": 1.9828571428571429,
      "grad_norm": 0.005899649113416672,
      "learning_rate": 1.735619047619048e-05,
      "loss": 0.2711,
      "step": 6940
    },
    {
      "epoch": 1.9857142857142858,
      "grad_norm": 18.696557998657227,
      "learning_rate": 1.7352380952380954e-05,
      "loss": 0.4286,
      "step": 6950
    },
    {
      "epoch": 1.9885714285714284,
      "grad_norm": 0.04010351374745369,
      "learning_rate": 1.734857142857143e-05,
      "loss": 0.4423,
      "step": 6960
    },
    {
      "epoch": 1.9914285714285715,
      "grad_norm": 0.06138664484024048,
      "learning_rate": 1.7344761904761906e-05,
      "loss": 0.1283,
      "step": 6970
    },
    {
      "epoch": 1.9942857142857142,
      "grad_norm": 0.19022606313228607,
      "learning_rate": 1.734095238095238e-05,
      "loss": 0.1609,
      "step": 6980
    },
    {
      "epoch": 1.997142857142857,
      "grad_norm": 0.03249718248844147,
      "learning_rate": 1.733714285714286e-05,
      "loss": 0.0595,
      "step": 6990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.13405732810497284,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.225,
      "step": 7000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9776666666666667,
      "eval_f1": 0.860125260960334,
      "eval_loss": 0.1048397421836853,
      "eval_precision": 0.9155555555555556,
      "eval_recall": 0.8110236220472441,
      "eval_runtime": 260.3303,
      "eval_samples_per_second": 11.524,
      "eval_steps_per_second": 2.881,
      "step": 7000
    },
    {
      "epoch": 2.0028571428571427,
      "grad_norm": 0.02617553249001503,
      "learning_rate": 1.732952380952381e-05,
      "loss": 0.0013,
      "step": 7010
    },
    {
      "epoch": 2.005714285714286,
      "grad_norm": 0.09776295721530914,
      "learning_rate": 1.7325714285714287e-05,
      "loss": 0.0859,
      "step": 7020
    },
    {
      "epoch": 2.0085714285714285,
      "grad_norm": 0.040630824863910675,
      "learning_rate": 1.7321904761904766e-05,
      "loss": 0.0011,
      "step": 7030
    },
    {
      "epoch": 2.0114285714285716,
      "grad_norm": 0.021703757345676422,
      "learning_rate": 1.731809523809524e-05,
      "loss": 0.0007,
      "step": 7040
    },
    {
      "epoch": 2.0142857142857142,
      "grad_norm": 0.058705925941467285,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 0.0016,
      "step": 7050
    },
    {
      "epoch": 2.0171428571428573,
      "grad_norm": 0.01361118070781231,
      "learning_rate": 1.7310476190476193e-05,
      "loss": 0.0002,
      "step": 7060
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.004963640123605728,
      "learning_rate": 1.7306666666666668e-05,
      "loss": 0.1655,
      "step": 7070
    },
    {
      "epoch": 2.0228571428571427,
      "grad_norm": 0.011299632489681244,
      "learning_rate": 1.7302857142857144e-05,
      "loss": 0.1916,
      "step": 7080
    },
    {
      "epoch": 2.025714285714286,
      "grad_norm": 0.13276125490665436,
      "learning_rate": 1.729904761904762e-05,
      "loss": 0.1956,
      "step": 7090
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 0.01689712330698967,
      "learning_rate": 1.7295238095238095e-05,
      "loss": 0.0007,
      "step": 7100
    },
    {
      "epoch": 2.0314285714285716,
      "grad_norm": 0.04431844502687454,
      "learning_rate": 1.7291428571428574e-05,
      "loss": 0.1127,
      "step": 7110
    },
    {
      "epoch": 2.0342857142857143,
      "grad_norm": 0.0059337373822927475,
      "learning_rate": 1.728761904761905e-05,
      "loss": 0.0192,
      "step": 7120
    },
    {
      "epoch": 2.0371428571428574,
      "grad_norm": 0.003668262157589197,
      "learning_rate": 1.7283809523809525e-05,
      "loss": 0.0001,
      "step": 7130
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.00597733911126852,
      "learning_rate": 1.728e-05,
      "loss": 0.1687,
      "step": 7140
    },
    {
      "epoch": 2.0428571428571427,
      "grad_norm": 0.06132663041353226,
      "learning_rate": 1.7276190476190476e-05,
      "loss": 0.0003,
      "step": 7150
    },
    {
      "epoch": 2.045714285714286,
      "grad_norm": 0.008852677419781685,
      "learning_rate": 1.7272380952380955e-05,
      "loss": 0.0233,
      "step": 7160
    },
    {
      "epoch": 2.0485714285714285,
      "grad_norm": 0.010722612030804157,
      "learning_rate": 1.726857142857143e-05,
      "loss": 0.0011,
      "step": 7170
    },
    {
      "epoch": 2.0514285714285716,
      "grad_norm": 0.06001516059041023,
      "learning_rate": 1.7264761904761906e-05,
      "loss": 0.323,
      "step": 7180
    },
    {
      "epoch": 2.0542857142857143,
      "grad_norm": 0.053505342453718185,
      "learning_rate": 1.7260952380952382e-05,
      "loss": 0.034,
      "step": 7190
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 0.01742832362651825,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 0.1693,
      "step": 7200
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.013338759541511536,
      "learning_rate": 1.7253333333333336e-05,
      "loss": 0.206,
      "step": 7210
    },
    {
      "epoch": 2.0628571428571427,
      "grad_norm": 0.009752943180501461,
      "learning_rate": 1.7249523809523812e-05,
      "loss": 0.3586,
      "step": 7220
    },
    {
      "epoch": 2.065714285714286,
      "grad_norm": 0.013498743064701557,
      "learning_rate": 1.7245714285714288e-05,
      "loss": 0.1136,
      "step": 7230
    },
    {
      "epoch": 2.0685714285714285,
      "grad_norm": 0.01043235044926405,
      "learning_rate": 1.7241904761904763e-05,
      "loss": 0.1495,
      "step": 7240
    },
    {
      "epoch": 2.0714285714285716,
      "grad_norm": 0.1107068657875061,
      "learning_rate": 1.723809523809524e-05,
      "loss": 0.0008,
      "step": 7250
    },
    {
      "epoch": 2.0742857142857143,
      "grad_norm": 0.007835328578948975,
      "learning_rate": 1.7234285714285718e-05,
      "loss": 0.0176,
      "step": 7260
    },
    {
      "epoch": 2.077142857142857,
      "grad_norm": 0.030704330652952194,
      "learning_rate": 1.723047619047619e-05,
      "loss": 0.0005,
      "step": 7270
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.020754609256982803,
      "learning_rate": 1.7226666666666665e-05,
      "loss": 0.4072,
      "step": 7280
    },
    {
      "epoch": 2.0828571428571427,
      "grad_norm": 0.10060262680053711,
      "learning_rate": 1.7222857142857144e-05,
      "loss": 0.0025,
      "step": 7290
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 1.408111810684204,
      "learning_rate": 1.721904761904762e-05,
      "loss": 0.0032,
      "step": 7300
    },
    {
      "epoch": 2.0885714285714285,
      "grad_norm": 0.004208363126963377,
      "learning_rate": 1.7215238095238096e-05,
      "loss": 0.0003,
      "step": 7310
    },
    {
      "epoch": 2.0914285714285716,
      "grad_norm": 0.007372569292783737,
      "learning_rate": 1.721142857142857e-05,
      "loss": 0.0004,
      "step": 7320
    },
    {
      "epoch": 2.0942857142857143,
      "grad_norm": 0.0023976832162588835,
      "learning_rate": 1.720761904761905e-05,
      "loss": 0.3307,
      "step": 7330
    },
    {
      "epoch": 2.097142857142857,
      "grad_norm": 0.011306734755635262,
      "learning_rate": 1.7203809523809526e-05,
      "loss": 0.0003,
      "step": 7340
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.018365683034062386,
      "learning_rate": 1.72e-05,
      "loss": 0.0004,
      "step": 7350
    },
    {
      "epoch": 2.1028571428571428,
      "grad_norm": 0.03440038487315178,
      "learning_rate": 1.7196190476190477e-05,
      "loss": 0.0002,
      "step": 7360
    },
    {
      "epoch": 2.105714285714286,
      "grad_norm": 0.011879312805831432,
      "learning_rate": 1.7192380952380953e-05,
      "loss": 0.076,
      "step": 7370
    },
    {
      "epoch": 2.1085714285714285,
      "grad_norm": 0.009607510641217232,
      "learning_rate": 1.718857142857143e-05,
      "loss": 0.0003,
      "step": 7380
    },
    {
      "epoch": 2.111428571428571,
      "grad_norm": 0.009178996086120605,
      "learning_rate": 1.7184761904761907e-05,
      "loss": 0.0002,
      "step": 7390
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 0.00960905198007822,
      "learning_rate": 1.7180952380952383e-05,
      "loss": 0.0003,
      "step": 7400
    },
    {
      "epoch": 2.117142857142857,
      "grad_norm": 0.01929999329149723,
      "learning_rate": 1.7177142857142858e-05,
      "loss": 0.0484,
      "step": 7410
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.02090362459421158,
      "learning_rate": 1.7173333333333334e-05,
      "loss": 0.0068,
      "step": 7420
    },
    {
      "epoch": 2.1228571428571428,
      "grad_norm": 0.18012240529060364,
      "learning_rate": 1.7169523809523813e-05,
      "loss": 0.0003,
      "step": 7430
    },
    {
      "epoch": 2.125714285714286,
      "grad_norm": 0.0014261136529967189,
      "learning_rate": 1.716571428571429e-05,
      "loss": 0.1655,
      "step": 7440
    },
    {
      "epoch": 2.1285714285714286,
      "grad_norm": 0.0014479855308309197,
      "learning_rate": 1.7161904761904764e-05,
      "loss": 0.0001,
      "step": 7450
    },
    {
      "epoch": 2.1314285714285712,
      "grad_norm": 0.018741734325885773,
      "learning_rate": 1.715809523809524e-05,
      "loss": 0.2097,
      "step": 7460
    },
    {
      "epoch": 2.1342857142857143,
      "grad_norm": 0.019288023933768272,
      "learning_rate": 1.7154285714285715e-05,
      "loss": 0.0009,
      "step": 7470
    },
    {
      "epoch": 2.137142857142857,
      "grad_norm": 0.020374806597828865,
      "learning_rate": 1.7150476190476194e-05,
      "loss": 0.2108,
      "step": 7480
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.006347662303596735,
      "learning_rate": 1.7146666666666666e-05,
      "loss": 0.0876,
      "step": 7490
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.057046592235565186,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.0009,
      "step": 7500
    },
    {
      "epoch": 2.145714285714286,
      "grad_norm": 0.008103013038635254,
      "learning_rate": 1.713904761904762e-05,
      "loss": 0.0043,
      "step": 7510
    },
    {
      "epoch": 2.1485714285714286,
      "grad_norm": 0.17579782009124756,
      "learning_rate": 1.7135238095238096e-05,
      "loss": 0.0005,
      "step": 7520
    },
    {
      "epoch": 2.1514285714285712,
      "grad_norm": 0.003224389860406518,
      "learning_rate": 1.7131428571428572e-05,
      "loss": 0.11,
      "step": 7530
    },
    {
      "epoch": 2.1542857142857144,
      "grad_norm": 0.010126781649887562,
      "learning_rate": 1.7127619047619048e-05,
      "loss": 0.0004,
      "step": 7540
    },
    {
      "epoch": 2.157142857142857,
      "grad_norm": 0.0030697716865688562,
      "learning_rate": 1.7123809523809523e-05,
      "loss": 0.0005,
      "step": 7550
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.009596779011189938,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.3299,
      "step": 7560
    },
    {
      "epoch": 2.162857142857143,
      "grad_norm": 0.01040871161967516,
      "learning_rate": 1.7116190476190478e-05,
      "loss": 0.2082,
      "step": 7570
    },
    {
      "epoch": 2.1657142857142855,
      "grad_norm": 0.05280478671193123,
      "learning_rate": 1.7112380952380953e-05,
      "loss": 0.0003,
      "step": 7580
    },
    {
      "epoch": 2.1685714285714286,
      "grad_norm": 0.029601098969578743,
      "learning_rate": 1.710857142857143e-05,
      "loss": 0.0004,
      "step": 7590
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 0.0208461731672287,
      "learning_rate": 1.7104761904761908e-05,
      "loss": 0.0982,
      "step": 7600
    },
    {
      "epoch": 2.1742857142857144,
      "grad_norm": 0.019517241045832634,
      "learning_rate": 1.7100952380952383e-05,
      "loss": 0.0007,
      "step": 7610
    },
    {
      "epoch": 2.177142857142857,
      "grad_norm": 0.006407889071851969,
      "learning_rate": 1.709714285714286e-05,
      "loss": 0.1349,
      "step": 7620
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.007697800174355507,
      "learning_rate": 1.7093333333333335e-05,
      "loss": 0.0216,
      "step": 7630
    },
    {
      "epoch": 2.182857142857143,
      "grad_norm": 0.013981102965772152,
      "learning_rate": 1.708952380952381e-05,
      "loss": 0.1207,
      "step": 7640
    },
    {
      "epoch": 2.185714285714286,
      "grad_norm": 0.014762495644390583,
      "learning_rate": 1.708571428571429e-05,
      "loss": 0.1533,
      "step": 7650
    },
    {
      "epoch": 2.1885714285714286,
      "grad_norm": 0.10466745495796204,
      "learning_rate": 1.7081904761904765e-05,
      "loss": 0.001,
      "step": 7660
    },
    {
      "epoch": 2.1914285714285713,
      "grad_norm": 0.00598521064966917,
      "learning_rate": 1.707809523809524e-05,
      "loss": 0.4447,
      "step": 7670
    },
    {
      "epoch": 2.1942857142857144,
      "grad_norm": 0.07495453208684921,
      "learning_rate": 1.7074285714285716e-05,
      "loss": 0.1247,
      "step": 7680
    },
    {
      "epoch": 2.197142857142857,
      "grad_norm": 0.021918755024671555,
      "learning_rate": 1.707047619047619e-05,
      "loss": 0.0014,
      "step": 7690
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.06765609979629517,
      "learning_rate": 1.706666666666667e-05,
      "loss": 0.0006,
      "step": 7700
    },
    {
      "epoch": 2.202857142857143,
      "grad_norm": 0.10200045257806778,
      "learning_rate": 1.7062857142857143e-05,
      "loss": 0.3085,
      "step": 7710
    },
    {
      "epoch": 2.2057142857142855,
      "grad_norm": 0.007231589872390032,
      "learning_rate": 1.7059047619047618e-05,
      "loss": 0.0671,
      "step": 7720
    },
    {
      "epoch": 2.2085714285714286,
      "grad_norm": 27.1141414642334,
      "learning_rate": 1.7055238095238097e-05,
      "loss": 0.0076,
      "step": 7730
    },
    {
      "epoch": 2.2114285714285713,
      "grad_norm": 0.005555638577789068,
      "learning_rate": 1.7051428571428573e-05,
      "loss": 0.0892,
      "step": 7740
    },
    {
      "epoch": 2.2142857142857144,
      "grad_norm": 0.06568252295255661,
      "learning_rate": 1.704761904761905e-05,
      "loss": 0.0007,
      "step": 7750
    },
    {
      "epoch": 2.217142857142857,
      "grad_norm": 34.8016357421875,
      "learning_rate": 1.7043809523809524e-05,
      "loss": 0.1801,
      "step": 7760
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.008538711816072464,
      "learning_rate": 1.704e-05,
      "loss": 0.3196,
      "step": 7770
    },
    {
      "epoch": 2.222857142857143,
      "grad_norm": 0.10719018429517746,
      "learning_rate": 1.703619047619048e-05,
      "loss": 0.2427,
      "step": 7780
    },
    {
      "epoch": 2.2257142857142855,
      "grad_norm": 0.10245703160762787,
      "learning_rate": 1.7032380952380954e-05,
      "loss": 0.0014,
      "step": 7790
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 0.060727931559085846,
      "learning_rate": 1.702857142857143e-05,
      "loss": 0.0018,
      "step": 7800
    },
    {
      "epoch": 2.2314285714285713,
      "grad_norm": 0.0008681840263307095,
      "learning_rate": 1.7024761904761905e-05,
      "loss": 0.0002,
      "step": 7810
    },
    {
      "epoch": 2.2342857142857144,
      "grad_norm": 0.005418927408754826,
      "learning_rate": 1.702095238095238e-05,
      "loss": 0.117,
      "step": 7820
    },
    {
      "epoch": 2.237142857142857,
      "grad_norm": 0.012738770805299282,
      "learning_rate": 1.701714285714286e-05,
      "loss": 0.0004,
      "step": 7830
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.004064964130520821,
      "learning_rate": 1.7013333333333335e-05,
      "loss": 0.0055,
      "step": 7840
    },
    {
      "epoch": 2.242857142857143,
      "grad_norm": 0.002928101224824786,
      "learning_rate": 1.700952380952381e-05,
      "loss": 0.1088,
      "step": 7850
    },
    {
      "epoch": 2.2457142857142856,
      "grad_norm": 0.0018081758171319962,
      "learning_rate": 1.7005714285714286e-05,
      "loss": 0.1624,
      "step": 7860
    },
    {
      "epoch": 2.2485714285714287,
      "grad_norm": 0.0012216807808727026,
      "learning_rate": 1.7001904761904765e-05,
      "loss": 0.0001,
      "step": 7870
    },
    {
      "epoch": 2.2514285714285713,
      "grad_norm": 0.32155388593673706,
      "learning_rate": 1.699809523809524e-05,
      "loss": 0.0002,
      "step": 7880
    },
    {
      "epoch": 2.2542857142857144,
      "grad_norm": 1.409315824508667,
      "learning_rate": 1.6994285714285717e-05,
      "loss": 0.0014,
      "step": 7890
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 0.0005902673001401126,
      "learning_rate": 1.6990476190476192e-05,
      "loss": 0.3581,
      "step": 7900
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.0006049752701073885,
      "learning_rate": 1.6986666666666668e-05,
      "loss": 0.1668,
      "step": 7910
    },
    {
      "epoch": 2.262857142857143,
      "grad_norm": 0.0009871770162135363,
      "learning_rate": 1.6982857142857143e-05,
      "loss": 0.2106,
      "step": 7920
    },
    {
      "epoch": 2.2657142857142856,
      "grad_norm": 0.0025104947853833437,
      "learning_rate": 1.697904761904762e-05,
      "loss": 0.1023,
      "step": 7930
    },
    {
      "epoch": 2.2685714285714287,
      "grad_norm": 0.02762438729405403,
      "learning_rate": 1.6975238095238095e-05,
      "loss": 0.0004,
      "step": 7940
    },
    {
      "epoch": 2.2714285714285714,
      "grad_norm": 0.03470157831907272,
      "learning_rate": 1.6971428571428574e-05,
      "loss": 0.0004,
      "step": 7950
    },
    {
      "epoch": 2.2742857142857145,
      "grad_norm": 0.003493580734357238,
      "learning_rate": 1.696761904761905e-05,
      "loss": 0.1348,
      "step": 7960
    },
    {
      "epoch": 2.277142857142857,
      "grad_norm": 0.0009277223725803196,
      "learning_rate": 1.6963809523809525e-05,
      "loss": 0.217,
      "step": 7970
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.12789380550384521,
      "learning_rate": 1.696e-05,
      "loss": 0.0014,
      "step": 7980
    },
    {
      "epoch": 2.282857142857143,
      "grad_norm": 0.0031459301244467497,
      "learning_rate": 1.6956190476190476e-05,
      "loss": 0.2555,
      "step": 7990
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.013674193993210793,
      "learning_rate": 1.6952380952380955e-05,
      "loss": 0.2226,
      "step": 8000
    },
    {
      "epoch": 2.2885714285714287,
      "grad_norm": 0.025618981570005417,
      "learning_rate": 1.694857142857143e-05,
      "loss": 0.3445,
      "step": 8010
    },
    {
      "epoch": 2.2914285714285714,
      "grad_norm": 0.022212322801351547,
      "learning_rate": 1.6944761904761906e-05,
      "loss": 0.1096,
      "step": 8020
    },
    {
      "epoch": 2.2942857142857145,
      "grad_norm": 0.029711946845054626,
      "learning_rate": 1.694095238095238e-05,
      "loss": 0.0012,
      "step": 8030
    },
    {
      "epoch": 2.297142857142857,
      "grad_norm": 0.10367447882890701,
      "learning_rate": 1.6937142857142857e-05,
      "loss": 0.0005,
      "step": 8040
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.008091915398836136,
      "learning_rate": 1.6933333333333336e-05,
      "loss": 0.0003,
      "step": 8050
    },
    {
      "epoch": 2.302857142857143,
      "grad_norm": 17.521047592163086,
      "learning_rate": 1.692952380952381e-05,
      "loss": 0.1993,
      "step": 8060
    },
    {
      "epoch": 2.3057142857142856,
      "grad_norm": 0.01034447830170393,
      "learning_rate": 1.6925714285714287e-05,
      "loss": 0.1698,
      "step": 8070
    },
    {
      "epoch": 2.3085714285714287,
      "grad_norm": 0.03884115815162659,
      "learning_rate": 1.6921904761904763e-05,
      "loss": 0.3558,
      "step": 8080
    },
    {
      "epoch": 2.3114285714285714,
      "grad_norm": 0.015406127087771893,
      "learning_rate": 1.6918095238095242e-05,
      "loss": 0.0956,
      "step": 8090
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 15.575632095336914,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 0.283,
      "step": 8100
    },
    {
      "epoch": 2.317142857142857,
      "grad_norm": 0.8285516500473022,
      "learning_rate": 1.6910476190476193e-05,
      "loss": 0.3334,
      "step": 8110
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.07273457944393158,
      "learning_rate": 1.690666666666667e-05,
      "loss": 0.001,
      "step": 8120
    },
    {
      "epoch": 2.322857142857143,
      "grad_norm": 0.029227839782834053,
      "learning_rate": 1.6902857142857144e-05,
      "loss": 0.2004,
      "step": 8130
    },
    {
      "epoch": 2.3257142857142856,
      "grad_norm": 0.008330813609063625,
      "learning_rate": 1.689904761904762e-05,
      "loss": 0.001,
      "step": 8140
    },
    {
      "epoch": 2.3285714285714287,
      "grad_norm": 0.09365443885326385,
      "learning_rate": 1.6895238095238095e-05,
      "loss": 0.1446,
      "step": 8150
    },
    {
      "epoch": 2.3314285714285714,
      "grad_norm": 0.0580071322619915,
      "learning_rate": 1.689142857142857e-05,
      "loss": 0.0012,
      "step": 8160
    },
    {
      "epoch": 2.3342857142857145,
      "grad_norm": 0.030078105628490448,
      "learning_rate": 1.688761904761905e-05,
      "loss": 0.1263,
      "step": 8170
    },
    {
      "epoch": 2.337142857142857,
      "grad_norm": 0.0067404345609247684,
      "learning_rate": 1.6883809523809525e-05,
      "loss": 0.0027,
      "step": 8180
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.016218138858675957,
      "learning_rate": 1.688e-05,
      "loss": 0.0002,
      "step": 8190
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 0.003553649177774787,
      "learning_rate": 1.6876190476190477e-05,
      "loss": 0.1855,
      "step": 8200
    },
    {
      "epoch": 2.3457142857142856,
      "grad_norm": 37.5286750793457,
      "learning_rate": 1.6872380952380952e-05,
      "loss": 0.095,
      "step": 8210
    },
    {
      "epoch": 2.3485714285714288,
      "grad_norm": 0.00634758360683918,
      "learning_rate": 1.686857142857143e-05,
      "loss": 0.269,
      "step": 8220
    },
    {
      "epoch": 2.3514285714285714,
      "grad_norm": 0.7252091765403748,
      "learning_rate": 1.6864761904761907e-05,
      "loss": 0.0449,
      "step": 8230
    },
    {
      "epoch": 2.354285714285714,
      "grad_norm": 0.0012559972237795591,
      "learning_rate": 1.6860952380952382e-05,
      "loss": 0.0015,
      "step": 8240
    },
    {
      "epoch": 2.357142857142857,
      "grad_norm": 0.02174852043390274,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 0.0006,
      "step": 8250
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.0016229641623795033,
      "learning_rate": 1.6853333333333333e-05,
      "loss": 0.0003,
      "step": 8260
    },
    {
      "epoch": 2.362857142857143,
      "grad_norm": 0.005240978207439184,
      "learning_rate": 1.6849523809523812e-05,
      "loss": 0.5533,
      "step": 8270
    },
    {
      "epoch": 2.3657142857142857,
      "grad_norm": 0.0014105343725532293,
      "learning_rate": 1.6845714285714288e-05,
      "loss": 0.0002,
      "step": 8280
    },
    {
      "epoch": 2.3685714285714283,
      "grad_norm": 0.0030129142105579376,
      "learning_rate": 1.6841904761904764e-05,
      "loss": 0.0001,
      "step": 8290
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 0.6075071096420288,
      "learning_rate": 1.683809523809524e-05,
      "loss": 0.1768,
      "step": 8300
    },
    {
      "epoch": 2.374285714285714,
      "grad_norm": 0.009069421328604221,
      "learning_rate": 1.6834285714285715e-05,
      "loss": 0.0001,
      "step": 8310
    },
    {
      "epoch": 2.3771428571428572,
      "grad_norm": 0.03586050495505333,
      "learning_rate": 1.6830476190476194e-05,
      "loss": 0.0002,
      "step": 8320
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.009401955641806126,
      "learning_rate": 1.682666666666667e-05,
      "loss": 0.2459,
      "step": 8330
    },
    {
      "epoch": 2.382857142857143,
      "grad_norm": 0.024916095659136772,
      "learning_rate": 1.6822857142857145e-05,
      "loss": 0.0509,
      "step": 8340
    },
    {
      "epoch": 2.3857142857142857,
      "grad_norm": 0.037177909165620804,
      "learning_rate": 1.681904761904762e-05,
      "loss": 0.1579,
      "step": 8350
    },
    {
      "epoch": 2.388571428571429,
      "grad_norm": 0.00816495530307293,
      "learning_rate": 1.6815238095238096e-05,
      "loss": 0.1686,
      "step": 8360
    },
    {
      "epoch": 2.3914285714285715,
      "grad_norm": 0.006641686893999577,
      "learning_rate": 1.681142857142857e-05,
      "loss": 0.0002,
      "step": 8370
    },
    {
      "epoch": 2.394285714285714,
      "grad_norm": 0.016239367425441742,
      "learning_rate": 1.6807619047619047e-05,
      "loss": 0.0011,
      "step": 8380
    },
    {
      "epoch": 2.3971428571428572,
      "grad_norm": 0.01872199773788452,
      "learning_rate": 1.6803809523809523e-05,
      "loss": 0.1419,
      "step": 8390
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.011475213803350925,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.2009,
      "step": 8400
    },
    {
      "epoch": 2.402857142857143,
      "grad_norm": 0.0766129195690155,
      "learning_rate": 1.6796190476190477e-05,
      "loss": 0.1412,
      "step": 8410
    },
    {
      "epoch": 2.4057142857142857,
      "grad_norm": 0.008297455497086048,
      "learning_rate": 1.6792380952380953e-05,
      "loss": 0.0003,
      "step": 8420
    },
    {
      "epoch": 2.4085714285714284,
      "grad_norm": 0.007553696632385254,
      "learning_rate": 1.678857142857143e-05,
      "loss": 0.0003,
      "step": 8430
    },
    {
      "epoch": 2.4114285714285715,
      "grad_norm": 0.06460797041654587,
      "learning_rate": 1.6784761904761907e-05,
      "loss": 0.1712,
      "step": 8440
    },
    {
      "epoch": 2.414285714285714,
      "grad_norm": 0.11636891216039658,
      "learning_rate": 1.6780952380952383e-05,
      "loss": 0.0005,
      "step": 8450
    },
    {
      "epoch": 2.4171428571428573,
      "grad_norm": 0.0206068754196167,
      "learning_rate": 1.677714285714286e-05,
      "loss": 0.286,
      "step": 8460
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.015664298087358475,
      "learning_rate": 1.6773333333333334e-05,
      "loss": 0.0006,
      "step": 8470
    },
    {
      "epoch": 2.422857142857143,
      "grad_norm": 0.01014751847833395,
      "learning_rate": 1.676952380952381e-05,
      "loss": 0.1086,
      "step": 8480
    },
    {
      "epoch": 2.4257142857142857,
      "grad_norm": 0.0538121797144413,
      "learning_rate": 1.676571428571429e-05,
      "loss": 0.0008,
      "step": 8490
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.00691893370822072,
      "learning_rate": 1.6761904761904764e-05,
      "loss": 0.0005,
      "step": 8500
    },
    {
      "epoch": 2.4314285714285715,
      "grad_norm": 0.07353367656469345,
      "learning_rate": 1.675809523809524e-05,
      "loss": 0.253,
      "step": 8510
    },
    {
      "epoch": 2.434285714285714,
      "grad_norm": 0.11706189811229706,
      "learning_rate": 1.6754285714285716e-05,
      "loss": 0.0006,
      "step": 8520
    },
    {
      "epoch": 2.4371428571428573,
      "grad_norm": 0.996403157711029,
      "learning_rate": 1.675047619047619e-05,
      "loss": 0.0025,
      "step": 8530
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.011978767812252045,
      "learning_rate": 1.674666666666667e-05,
      "loss": 0.0226,
      "step": 8540
    },
    {
      "epoch": 2.442857142857143,
      "grad_norm": 0.00839401874691248,
      "learning_rate": 1.6742857142857146e-05,
      "loss": 0.101,
      "step": 8550
    },
    {
      "epoch": 2.4457142857142857,
      "grad_norm": 0.0023425817489624023,
      "learning_rate": 1.673904761904762e-05,
      "loss": 0.2135,
      "step": 8560
    },
    {
      "epoch": 2.4485714285714284,
      "grad_norm": 0.0016529664862900972,
      "learning_rate": 1.6735238095238097e-05,
      "loss": 0.0002,
      "step": 8570
    },
    {
      "epoch": 2.4514285714285715,
      "grad_norm": 0.0004968332941643894,
      "learning_rate": 1.6731428571428572e-05,
      "loss": 0.1268,
      "step": 8580
    },
    {
      "epoch": 2.454285714285714,
      "grad_norm": 0.001274891197681427,
      "learning_rate": 1.6727619047619048e-05,
      "loss": 0.0001,
      "step": 8590
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.001507458509877324,
      "learning_rate": 1.6723809523809524e-05,
      "loss": 0.4922,
      "step": 8600
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.015102568082511425,
      "learning_rate": 1.672e-05,
      "loss": 0.0012,
      "step": 8610
    },
    {
      "epoch": 2.4628571428571426,
      "grad_norm": 0.003435350488871336,
      "learning_rate": 1.6716190476190478e-05,
      "loss": 0.0005,
      "step": 8620
    },
    {
      "epoch": 2.4657142857142857,
      "grad_norm": 0.012438594363629818,
      "learning_rate": 1.6712380952380954e-05,
      "loss": 0.0026,
      "step": 8630
    },
    {
      "epoch": 2.4685714285714284,
      "grad_norm": 0.007709145080298185,
      "learning_rate": 1.670857142857143e-05,
      "loss": 0.0006,
      "step": 8640
    },
    {
      "epoch": 2.4714285714285715,
      "grad_norm": 0.003122016554698348,
      "learning_rate": 1.6704761904761905e-05,
      "loss": 0.0006,
      "step": 8650
    },
    {
      "epoch": 2.474285714285714,
      "grad_norm": 0.0022986328694969416,
      "learning_rate": 1.670095238095238e-05,
      "loss": 0.1675,
      "step": 8660
    },
    {
      "epoch": 2.4771428571428573,
      "grad_norm": 30.45313262939453,
      "learning_rate": 1.669714285714286e-05,
      "loss": 0.3074,
      "step": 8670
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.018169736489653587,
      "learning_rate": 1.6693333333333335e-05,
      "loss": 0.0005,
      "step": 8680
    },
    {
      "epoch": 2.482857142857143,
      "grad_norm": 34.292823791503906,
      "learning_rate": 1.668952380952381e-05,
      "loss": 0.2975,
      "step": 8690
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 22.959087371826172,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 0.2656,
      "step": 8700
    },
    {
      "epoch": 2.4885714285714284,
      "grad_norm": 0.009713944047689438,
      "learning_rate": 1.6681904761904765e-05,
      "loss": 0.007,
      "step": 8710
    },
    {
      "epoch": 2.4914285714285715,
      "grad_norm": 0.019265295937657356,
      "learning_rate": 1.667809523809524e-05,
      "loss": 0.001,
      "step": 8720
    },
    {
      "epoch": 2.494285714285714,
      "grad_norm": 0.04359849914908409,
      "learning_rate": 1.6674285714285716e-05,
      "loss": 0.0003,
      "step": 8730
    },
    {
      "epoch": 2.4971428571428573,
      "grad_norm": 0.020896757021546364,
      "learning_rate": 1.6670476190476192e-05,
      "loss": 0.2929,
      "step": 8740
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.002860664390027523,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0431,
      "step": 8750
    },
    {
      "epoch": 2.5028571428571427,
      "grad_norm": 0.014313427731394768,
      "learning_rate": 1.6662857142857146e-05,
      "loss": 0.0008,
      "step": 8760
    },
    {
      "epoch": 2.505714285714286,
      "grad_norm": 0.005142719950526953,
      "learning_rate": 1.6659047619047622e-05,
      "loss": 0.2721,
      "step": 8770
    },
    {
      "epoch": 2.5085714285714285,
      "grad_norm": 0.026270123198628426,
      "learning_rate": 1.6655238095238098e-05,
      "loss": 0.0005,
      "step": 8780
    },
    {
      "epoch": 2.5114285714285716,
      "grad_norm": 62.57490158081055,
      "learning_rate": 1.6651428571428573e-05,
      "loss": 0.2132,
      "step": 8790
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.0006171122076921165,
      "learning_rate": 1.664761904761905e-05,
      "loss": 0.1761,
      "step": 8800
    },
    {
      "epoch": 2.517142857142857,
      "grad_norm": 2.490602493286133,
      "learning_rate": 1.6643809523809524e-05,
      "loss": 0.0027,
      "step": 8810
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.011538141407072544,
      "learning_rate": 1.664e-05,
      "loss": 0.004,
      "step": 8820
    },
    {
      "epoch": 2.522857142857143,
      "grad_norm": 33.29909133911133,
      "learning_rate": 1.6636190476190476e-05,
      "loss": 0.1232,
      "step": 8830
    },
    {
      "epoch": 2.525714285714286,
      "grad_norm": 0.017700234428048134,
      "learning_rate": 1.6632380952380954e-05,
      "loss": 0.1869,
      "step": 8840
    },
    {
      "epoch": 2.5285714285714285,
      "grad_norm": 0.0018306791316717863,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.0458,
      "step": 8850
    },
    {
      "epoch": 2.5314285714285716,
      "grad_norm": 0.06254714727401733,
      "learning_rate": 1.6624761904761906e-05,
      "loss": 0.0006,
      "step": 8860
    },
    {
      "epoch": 2.5342857142857143,
      "grad_norm": 0.012850586324930191,
      "learning_rate": 1.662095238095238e-05,
      "loss": 0.0006,
      "step": 8870
    },
    {
      "epoch": 2.5371428571428574,
      "grad_norm": 0.06767906993627548,
      "learning_rate": 1.6617142857142857e-05,
      "loss": 0.2093,
      "step": 8880
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.012577072717249393,
      "learning_rate": 1.6613333333333336e-05,
      "loss": 0.0003,
      "step": 8890
    },
    {
      "epoch": 2.5428571428571427,
      "grad_norm": 0.005589868873357773,
      "learning_rate": 1.660952380952381e-05,
      "loss": 0.0003,
      "step": 8900
    },
    {
      "epoch": 2.545714285714286,
      "grad_norm": 0.16437961161136627,
      "learning_rate": 1.6605714285714287e-05,
      "loss": 0.3565,
      "step": 8910
    },
    {
      "epoch": 2.5485714285714285,
      "grad_norm": 0.0048548560589551926,
      "learning_rate": 1.6601904761904763e-05,
      "loss": 0.0002,
      "step": 8920
    },
    {
      "epoch": 2.5514285714285716,
      "grad_norm": 0.008465996012091637,
      "learning_rate": 1.659809523809524e-05,
      "loss": 0.0003,
      "step": 8930
    },
    {
      "epoch": 2.5542857142857143,
      "grad_norm": 0.0015980503521859646,
      "learning_rate": 1.6594285714285717e-05,
      "loss": 0.0995,
      "step": 8940
    },
    {
      "epoch": 2.557142857142857,
      "grad_norm": 0.0011251855175942183,
      "learning_rate": 1.6590476190476193e-05,
      "loss": 0.0004,
      "step": 8950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.09992212802171707,
      "learning_rate": 1.6586666666666668e-05,
      "loss": 0.1402,
      "step": 8960
    },
    {
      "epoch": 2.5628571428571427,
      "grad_norm": 0.0020972671918570995,
      "learning_rate": 1.6582857142857144e-05,
      "loss": 0.0001,
      "step": 8970
    },
    {
      "epoch": 2.565714285714286,
      "grad_norm": 0.016244571655988693,
      "learning_rate": 1.6579047619047623e-05,
      "loss": 0.0003,
      "step": 8980
    },
    {
      "epoch": 2.5685714285714285,
      "grad_norm": 0.00476851174607873,
      "learning_rate": 1.65752380952381e-05,
      "loss": 0.0006,
      "step": 8990
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.006946003530174494,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 2.5742857142857143,
      "grad_norm": 0.0007931102882139385,
      "learning_rate": 1.656761904761905e-05,
      "loss": 0.0002,
      "step": 9010
    },
    {
      "epoch": 2.5771428571428574,
      "grad_norm": 0.0007337878923863173,
      "learning_rate": 1.6563809523809525e-05,
      "loss": 0.0001,
      "step": 9020
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.0009737639920786023,
      "learning_rate": 1.656e-05,
      "loss": 0.1421,
      "step": 9030
    },
    {
      "epoch": 2.5828571428571427,
      "grad_norm": 0.0012562951305881143,
      "learning_rate": 1.6556190476190476e-05,
      "loss": 0.0001,
      "step": 9040
    },
    {
      "epoch": 2.585714285714286,
      "grad_norm": 31.244464874267578,
      "learning_rate": 1.6552380952380952e-05,
      "loss": 0.0035,
      "step": 9050
    },
    {
      "epoch": 2.5885714285714285,
      "grad_norm": 0.0006690396112389863,
      "learning_rate": 1.654857142857143e-05,
      "loss": 0.1184,
      "step": 9060
    },
    {
      "epoch": 2.5914285714285716,
      "grad_norm": 0.015762092545628548,
      "learning_rate": 1.6544761904761906e-05,
      "loss": 0.0006,
      "step": 9070
    },
    {
      "epoch": 2.5942857142857143,
      "grad_norm": 0.0008603626629337668,
      "learning_rate": 1.6540952380952382e-05,
      "loss": 0.1376,
      "step": 9080
    },
    {
      "epoch": 2.597142857142857,
      "grad_norm": 0.0202496275305748,
      "learning_rate": 1.6537142857142858e-05,
      "loss": 0.0002,
      "step": 9090
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.0016334033571183681,
      "learning_rate": 1.6533333333333333e-05,
      "loss": 0.0001,
      "step": 9100
    },
    {
      "epoch": 2.6028571428571428,
      "grad_norm": 0.0009137339657172561,
      "learning_rate": 1.6529523809523812e-05,
      "loss": 0.0001,
      "step": 9110
    },
    {
      "epoch": 2.605714285714286,
      "grad_norm": 0.02415325865149498,
      "learning_rate": 1.6525714285714288e-05,
      "loss": 0.1616,
      "step": 9120
    },
    {
      "epoch": 2.6085714285714285,
      "grad_norm": 0.24249590933322906,
      "learning_rate": 1.6521904761904763e-05,
      "loss": 0.3045,
      "step": 9130
    },
    {
      "epoch": 2.611428571428571,
      "grad_norm": 0.1870834231376648,
      "learning_rate": 1.651809523809524e-05,
      "loss": 0.001,
      "step": 9140
    },
    {
      "epoch": 2.6142857142857143,
      "grad_norm": 31.676115036010742,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.067,
      "step": 9150
    },
    {
      "epoch": 2.617142857142857,
      "grad_norm": 0.018642770126461983,
      "learning_rate": 1.6510476190476193e-05,
      "loss": 0.0373,
      "step": 9160
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.01667238026857376,
      "learning_rate": 1.650666666666667e-05,
      "loss": 0.4162,
      "step": 9170
    },
    {
      "epoch": 2.6228571428571428,
      "grad_norm": 0.0025446589570492506,
      "learning_rate": 1.6502857142857145e-05,
      "loss": 0.0032,
      "step": 9180
    },
    {
      "epoch": 2.6257142857142854,
      "grad_norm": 0.0006639047642238438,
      "learning_rate": 1.649904761904762e-05,
      "loss": 0.0002,
      "step": 9190
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 0.10415712743997574,
      "learning_rate": 1.64952380952381e-05,
      "loss": 0.0003,
      "step": 9200
    },
    {
      "epoch": 2.6314285714285717,
      "grad_norm": 0.005242884159088135,
      "learning_rate": 1.6491428571428575e-05,
      "loss": 0.0007,
      "step": 9210
    },
    {
      "epoch": 2.6342857142857143,
      "grad_norm": 0.00049583800137043,
      "learning_rate": 1.648761904761905e-05,
      "loss": 0.0422,
      "step": 9220
    },
    {
      "epoch": 2.637142857142857,
      "grad_norm": 0.003834113711491227,
      "learning_rate": 1.6483809523809522e-05,
      "loss": 0.178,
      "step": 9230
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.006721043959259987,
      "learning_rate": 1.648e-05,
      "loss": 0.0001,
      "step": 9240
    },
    {
      "epoch": 2.642857142857143,
      "grad_norm": 43.21637725830078,
      "learning_rate": 1.6476190476190477e-05,
      "loss": 0.2677,
      "step": 9250
    },
    {
      "epoch": 2.645714285714286,
      "grad_norm": 0.013478819280862808,
      "learning_rate": 1.6472380952380953e-05,
      "loss": 0.0003,
      "step": 9260
    },
    {
      "epoch": 2.6485714285714286,
      "grad_norm": 38.26038360595703,
      "learning_rate": 1.6468571428571428e-05,
      "loss": 0.1106,
      "step": 9270
    },
    {
      "epoch": 2.6514285714285712,
      "grad_norm": 0.0303683802485466,
      "learning_rate": 1.6464761904761907e-05,
      "loss": 0.0004,
      "step": 9280
    },
    {
      "epoch": 2.6542857142857144,
      "grad_norm": 0.0030821727123111486,
      "learning_rate": 1.6460952380952383e-05,
      "loss": 0.0035,
      "step": 9290
    },
    {
      "epoch": 2.657142857142857,
      "grad_norm": 17.608144760131836,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.5307,
      "step": 9300
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.00019793363753706217,
      "learning_rate": 1.6453333333333334e-05,
      "loss": 0.0016,
      "step": 9310
    },
    {
      "epoch": 2.662857142857143,
      "grad_norm": 0.07603716105222702,
      "learning_rate": 1.644952380952381e-05,
      "loss": 0.0002,
      "step": 9320
    },
    {
      "epoch": 2.6657142857142855,
      "grad_norm": 0.10606758296489716,
      "learning_rate": 1.644571428571429e-05,
      "loss": 0.2381,
      "step": 9330
    },
    {
      "epoch": 2.6685714285714286,
      "grad_norm": 0.02952524647116661,
      "learning_rate": 1.6441904761904764e-05,
      "loss": 0.0005,
      "step": 9340
    },
    {
      "epoch": 2.6714285714285713,
      "grad_norm": 0.0671476423740387,
      "learning_rate": 1.643809523809524e-05,
      "loss": 0.3719,
      "step": 9350
    },
    {
      "epoch": 2.6742857142857144,
      "grad_norm": 0.004270570352673531,
      "learning_rate": 1.6434285714285715e-05,
      "loss": 0.0187,
      "step": 9360
    },
    {
      "epoch": 2.677142857142857,
      "grad_norm": 0.0019968911074101925,
      "learning_rate": 1.643047619047619e-05,
      "loss": 0.0002,
      "step": 9370
    },
    {
      "epoch": 2.68,
      "grad_norm": 67.25627136230469,
      "learning_rate": 1.642666666666667e-05,
      "loss": 0.3883,
      "step": 9380
    },
    {
      "epoch": 2.682857142857143,
      "grad_norm": 0.01690266653895378,
      "learning_rate": 1.6422857142857145e-05,
      "loss": 0.2281,
      "step": 9390
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 0.24360418319702148,
      "learning_rate": 1.641904761904762e-05,
      "loss": 0.0522,
      "step": 9400
    },
    {
      "epoch": 2.6885714285714286,
      "grad_norm": 0.20892632007598877,
      "learning_rate": 1.6415238095238097e-05,
      "loss": 0.0009,
      "step": 9410
    },
    {
      "epoch": 2.6914285714285713,
      "grad_norm": 3.3542635440826416,
      "learning_rate": 1.6411428571428572e-05,
      "loss": 0.151,
      "step": 9420
    },
    {
      "epoch": 2.6942857142857144,
      "grad_norm": 0.002842330140992999,
      "learning_rate": 1.640761904761905e-05,
      "loss": 0.051,
      "step": 9430
    },
    {
      "epoch": 2.697142857142857,
      "grad_norm": 0.005099654197692871,
      "learning_rate": 1.6403809523809523e-05,
      "loss": 0.0009,
      "step": 9440
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.03926808014512062,
      "learning_rate": 1.64e-05,
      "loss": 0.0236,
      "step": 9450
    },
    {
      "epoch": 2.702857142857143,
      "grad_norm": 0.010340387932956219,
      "learning_rate": 1.6396190476190478e-05,
      "loss": 0.0002,
      "step": 9460
    },
    {
      "epoch": 2.7057142857142855,
      "grad_norm": 0.0052356659434735775,
      "learning_rate": 1.6392380952380953e-05,
      "loss": 0.234,
      "step": 9470
    },
    {
      "epoch": 2.7085714285714286,
      "grad_norm": 0.09004133939743042,
      "learning_rate": 1.638857142857143e-05,
      "loss": 0.001,
      "step": 9480
    },
    {
      "epoch": 2.7114285714285713,
      "grad_norm": 0.035353366285562515,
      "learning_rate": 1.6384761904761905e-05,
      "loss": 0.1535,
      "step": 9490
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.006243317853659391,
      "learning_rate": 1.6380952380952384e-05,
      "loss": 0.0005,
      "step": 9500
    },
    {
      "epoch": 2.717142857142857,
      "grad_norm": 0.003277688520029187,
      "learning_rate": 1.637714285714286e-05,
      "loss": 0.0,
      "step": 9510
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.004194853827357292,
      "learning_rate": 1.6373333333333335e-05,
      "loss": 0.0005,
      "step": 9520
    },
    {
      "epoch": 2.722857142857143,
      "grad_norm": 1.9269815683364868,
      "learning_rate": 1.636952380952381e-05,
      "loss": 0.001,
      "step": 9530
    },
    {
      "epoch": 2.725714285714286,
      "grad_norm": 0.0007139945519156754,
      "learning_rate": 1.6365714285714286e-05,
      "loss": 0.0003,
      "step": 9540
    },
    {
      "epoch": 2.7285714285714286,
      "grad_norm": 0.001602365868166089,
      "learning_rate": 1.6361904761904765e-05,
      "loss": 0.2183,
      "step": 9550
    },
    {
      "epoch": 2.7314285714285713,
      "grad_norm": 0.00349350250326097,
      "learning_rate": 1.635809523809524e-05,
      "loss": 0.0365,
      "step": 9560
    },
    {
      "epoch": 2.7342857142857144,
      "grad_norm": 0.004026682581752539,
      "learning_rate": 1.6354285714285716e-05,
      "loss": 0.0001,
      "step": 9570
    },
    {
      "epoch": 2.737142857142857,
      "grad_norm": 0.009579561650753021,
      "learning_rate": 1.635047619047619e-05,
      "loss": 0.103,
      "step": 9580
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.018683236092329025,
      "learning_rate": 1.6346666666666667e-05,
      "loss": 0.0002,
      "step": 9590
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 0.01633693091571331,
      "learning_rate": 1.6342857142857146e-05,
      "loss": 0.3877,
      "step": 9600
    },
    {
      "epoch": 2.7457142857142856,
      "grad_norm": 0.010127594694495201,
      "learning_rate": 1.633904761904762e-05,
      "loss": 0.0013,
      "step": 9610
    },
    {
      "epoch": 2.7485714285714287,
      "grad_norm": 0.01648046262562275,
      "learning_rate": 1.6335238095238097e-05,
      "loss": 0.0003,
      "step": 9620
    },
    {
      "epoch": 2.7514285714285713,
      "grad_norm": 36.36561965942383,
      "learning_rate": 1.6331428571428573e-05,
      "loss": 0.1384,
      "step": 9630
    },
    {
      "epoch": 2.7542857142857144,
      "grad_norm": 0.007766340859234333,
      "learning_rate": 1.632761904761905e-05,
      "loss": 0.0002,
      "step": 9640
    },
    {
      "epoch": 2.757142857142857,
      "grad_norm": 0.006477282382547855,
      "learning_rate": 1.6323809523809527e-05,
      "loss": 0.0061,
      "step": 9650
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.004697110038250685,
      "learning_rate": 1.632e-05,
      "loss": 0.1013,
      "step": 9660
    },
    {
      "epoch": 2.762857142857143,
      "grad_norm": 0.002425720449537039,
      "learning_rate": 1.6316190476190475e-05,
      "loss": 0.2062,
      "step": 9670
    },
    {
      "epoch": 2.7657142857142856,
      "grad_norm": 0.013935324735939503,
      "learning_rate": 1.6312380952380954e-05,
      "loss": 0.0004,
      "step": 9680
    },
    {
      "epoch": 2.7685714285714287,
      "grad_norm": 0.0033384887501597404,
      "learning_rate": 1.630857142857143e-05,
      "loss": 0.0002,
      "step": 9690
    },
    {
      "epoch": 2.7714285714285714,
      "grad_norm": 0.0015169424004852772,
      "learning_rate": 1.6304761904761905e-05,
      "loss": 0.0002,
      "step": 9700
    },
    {
      "epoch": 2.774285714285714,
      "grad_norm": 0.014121431857347488,
      "learning_rate": 1.630095238095238e-05,
      "loss": 0.1692,
      "step": 9710
    },
    {
      "epoch": 2.777142857142857,
      "grad_norm": 0.05668579041957855,
      "learning_rate": 1.6297142857142856e-05,
      "loss": 0.0009,
      "step": 9720
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 0.18806569278240204,
      "learning_rate": 1.6293333333333335e-05,
      "loss": 0.0004,
      "step": 9730
    },
    {
      "epoch": 2.782857142857143,
      "grad_norm": 0.06635639071464539,
      "learning_rate": 1.628952380952381e-05,
      "loss": 0.1078,
      "step": 9740
    },
    {
      "epoch": 2.7857142857142856,
      "grad_norm": 0.0009945275960490108,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.0001,
      "step": 9750
    },
    {
      "epoch": 2.7885714285714287,
      "grad_norm": 0.0021927934139966965,
      "learning_rate": 1.6281904761904762e-05,
      "loss": 0.0002,
      "step": 9760
    },
    {
      "epoch": 2.7914285714285714,
      "grad_norm": 0.0006558748427778482,
      "learning_rate": 1.627809523809524e-05,
      "loss": 0.0002,
      "step": 9770
    },
    {
      "epoch": 2.7942857142857145,
      "grad_norm": 0.022318607196211815,
      "learning_rate": 1.6274285714285717e-05,
      "loss": 0.0003,
      "step": 9780
    },
    {
      "epoch": 2.797142857142857,
      "grad_norm": 0.026059238240122795,
      "learning_rate": 1.6270476190476192e-05,
      "loss": 0.0002,
      "step": 9790
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.0017939897952601314,
      "learning_rate": 1.6266666666666668e-05,
      "loss": 0.2161,
      "step": 9800
    },
    {
      "epoch": 2.802857142857143,
      "grad_norm": 0.01029654499143362,
      "learning_rate": 1.6262857142857143e-05,
      "loss": 0.0006,
      "step": 9810
    },
    {
      "epoch": 2.8057142857142856,
      "grad_norm": 0.015676043927669525,
      "learning_rate": 1.6259047619047622e-05,
      "loss": 0.0969,
      "step": 9820
    },
    {
      "epoch": 2.8085714285714287,
      "grad_norm": 0.0018666553078219295,
      "learning_rate": 1.6255238095238098e-05,
      "loss": 0.2253,
      "step": 9830
    },
    {
      "epoch": 2.8114285714285714,
      "grad_norm": 0.02285872958600521,
      "learning_rate": 1.6251428571428574e-05,
      "loss": 0.0275,
      "step": 9840
    },
    {
      "epoch": 2.814285714285714,
      "grad_norm": 0.06332272291183472,
      "learning_rate": 1.624761904761905e-05,
      "loss": 0.1964,
      "step": 9850
    },
    {
      "epoch": 2.817142857142857,
      "grad_norm": 0.04397206008434296,
      "learning_rate": 1.6243809523809525e-05,
      "loss": 0.3533,
      "step": 9860
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.02552623674273491,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 0.0513,
      "step": 9870
    },
    {
      "epoch": 2.822857142857143,
      "grad_norm": 0.02514500916004181,
      "learning_rate": 1.6236190476190476e-05,
      "loss": 0.0005,
      "step": 9880
    },
    {
      "epoch": 2.8257142857142856,
      "grad_norm": 0.028338540345430374,
      "learning_rate": 1.623238095238095e-05,
      "loss": 0.0198,
      "step": 9890
    },
    {
      "epoch": 2.8285714285714287,
      "grad_norm": 0.06750816851854324,
      "learning_rate": 1.622857142857143e-05,
      "loss": 0.0003,
      "step": 9900
    },
    {
      "epoch": 2.8314285714285714,
      "grad_norm": 0.03928685188293457,
      "learning_rate": 1.6224761904761906e-05,
      "loss": 0.0714,
      "step": 9910
    },
    {
      "epoch": 2.8342857142857145,
      "grad_norm": 0.015025890432298183,
      "learning_rate": 1.622095238095238e-05,
      "loss": 0.1376,
      "step": 9920
    },
    {
      "epoch": 2.837142857142857,
      "grad_norm": 51.90665054321289,
      "learning_rate": 1.6217142857142857e-05,
      "loss": 0.0235,
      "step": 9930
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.0029103439301252365,
      "learning_rate": 1.6213333333333333e-05,
      "loss": 0.2262,
      "step": 9940
    },
    {
      "epoch": 2.842857142857143,
      "grad_norm": 0.025179989635944366,
      "learning_rate": 1.6209523809523812e-05,
      "loss": 0.0001,
      "step": 9950
    },
    {
      "epoch": 2.8457142857142856,
      "grad_norm": 0.04855214059352875,
      "learning_rate": 1.6205714285714287e-05,
      "loss": 0.165,
      "step": 9960
    },
    {
      "epoch": 2.8485714285714288,
      "grad_norm": 0.018278947100043297,
      "learning_rate": 1.6201904761904763e-05,
      "loss": 0.0076,
      "step": 9970
    },
    {
      "epoch": 2.8514285714285714,
      "grad_norm": 0.01454877108335495,
      "learning_rate": 1.619809523809524e-05,
      "loss": 0.0002,
      "step": 9980
    },
    {
      "epoch": 2.854285714285714,
      "grad_norm": 0.006774165667593479,
      "learning_rate": 1.6194285714285714e-05,
      "loss": 0.0003,
      "step": 9990
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.018114859238266945,
      "learning_rate": 1.6190476190476193e-05,
      "loss": 0.0004,
      "step": 10000
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.022048668935894966,
      "learning_rate": 1.618666666666667e-05,
      "loss": 0.3391,
      "step": 10010
    },
    {
      "epoch": 2.862857142857143,
      "grad_norm": 0.001354147563688457,
      "learning_rate": 1.6182857142857144e-05,
      "loss": 0.0005,
      "step": 10020
    },
    {
      "epoch": 2.8657142857142857,
      "grad_norm": 0.003357876790687442,
      "learning_rate": 1.617904761904762e-05,
      "loss": 0.3335,
      "step": 10030
    },
    {
      "epoch": 2.8685714285714283,
      "grad_norm": 78.36205291748047,
      "learning_rate": 1.61752380952381e-05,
      "loss": 0.2147,
      "step": 10040
    },
    {
      "epoch": 2.8714285714285714,
      "grad_norm": 0.03017709031701088,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 0.0087,
      "step": 10050
    },
    {
      "epoch": 2.8742857142857146,
      "grad_norm": 0.011046160943806171,
      "learning_rate": 1.616761904761905e-05,
      "loss": 0.0012,
      "step": 10060
    },
    {
      "epoch": 2.8771428571428572,
      "grad_norm": 0.004914361983537674,
      "learning_rate": 1.6163809523809526e-05,
      "loss": 0.0016,
      "step": 10070
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.03133511543273926,
      "learning_rate": 1.616e-05,
      "loss": 0.165,
      "step": 10080
    },
    {
      "epoch": 2.882857142857143,
      "grad_norm": 0.017877086997032166,
      "learning_rate": 1.6156190476190477e-05,
      "loss": 0.1788,
      "step": 10090
    },
    {
      "epoch": 2.8857142857142857,
      "grad_norm": 0.020857073366642,
      "learning_rate": 1.6152380952380952e-05,
      "loss": 0.3485,
      "step": 10100
    },
    {
      "epoch": 2.888571428571429,
      "grad_norm": 0.009963196702301502,
      "learning_rate": 1.6148571428571428e-05,
      "loss": 0.0005,
      "step": 10110
    },
    {
      "epoch": 2.8914285714285715,
      "grad_norm": 0.17907871305942535,
      "learning_rate": 1.6144761904761907e-05,
      "loss": 0.0586,
      "step": 10120
    },
    {
      "epoch": 2.894285714285714,
      "grad_norm": 0.006651011761277914,
      "learning_rate": 1.6140952380952382e-05,
      "loss": 0.0013,
      "step": 10130
    },
    {
      "epoch": 2.8971428571428572,
      "grad_norm": 21.899166107177734,
      "learning_rate": 1.6137142857142858e-05,
      "loss": 0.1484,
      "step": 10140
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.11793115735054016,
      "learning_rate": 1.6133333333333334e-05,
      "loss": 0.0004,
      "step": 10150
    },
    {
      "epoch": 2.902857142857143,
      "grad_norm": 0.0041915662586688995,
      "learning_rate": 1.612952380952381e-05,
      "loss": 0.0048,
      "step": 10160
    },
    {
      "epoch": 2.9057142857142857,
      "grad_norm": 0.16992777585983276,
      "learning_rate": 1.6125714285714288e-05,
      "loss": 0.1897,
      "step": 10170
    },
    {
      "epoch": 2.9085714285714284,
      "grad_norm": 0.021344756707549095,
      "learning_rate": 1.6121904761904764e-05,
      "loss": 0.495,
      "step": 10180
    },
    {
      "epoch": 2.9114285714285715,
      "grad_norm": 0.010532848536968231,
      "learning_rate": 1.611809523809524e-05,
      "loss": 0.012,
      "step": 10190
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 0.015638791024684906,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.0004,
      "step": 10200
    },
    {
      "epoch": 2.9171428571428573,
      "grad_norm": 0.003630389692261815,
      "learning_rate": 1.611047619047619e-05,
      "loss": 0.0002,
      "step": 10210
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.00859044212847948,
      "learning_rate": 1.610666666666667e-05,
      "loss": 0.0004,
      "step": 10220
    },
    {
      "epoch": 2.9228571428571426,
      "grad_norm": 0.025549767538905144,
      "learning_rate": 1.6102857142857145e-05,
      "loss": 0.0003,
      "step": 10230
    },
    {
      "epoch": 2.9257142857142857,
      "grad_norm": 0.007256413344293833,
      "learning_rate": 1.609904761904762e-05,
      "loss": 0.0004,
      "step": 10240
    },
    {
      "epoch": 2.928571428571429,
      "grad_norm": 0.0037815826945006847,
      "learning_rate": 1.6095238095238096e-05,
      "loss": 0.1242,
      "step": 10250
    },
    {
      "epoch": 2.9314285714285715,
      "grad_norm": 17.41282081604004,
      "learning_rate": 1.6091428571428572e-05,
      "loss": 0.2652,
      "step": 10260
    },
    {
      "epoch": 2.934285714285714,
      "grad_norm": 0.02813866175711155,
      "learning_rate": 1.608761904761905e-05,
      "loss": 0.0005,
      "step": 10270
    },
    {
      "epoch": 2.9371428571428573,
      "grad_norm": 0.0036297570914030075,
      "learning_rate": 1.6083809523809526e-05,
      "loss": 0.0002,
      "step": 10280
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.1967540681362152,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.0005,
      "step": 10290
    },
    {
      "epoch": 2.942857142857143,
      "grad_norm": 0.003542729653418064,
      "learning_rate": 1.6076190476190477e-05,
      "loss": 0.1349,
      "step": 10300
    },
    {
      "epoch": 2.9457142857142857,
      "grad_norm": 0.05600278824567795,
      "learning_rate": 1.6072380952380953e-05,
      "loss": 0.0002,
      "step": 10310
    },
    {
      "epoch": 2.9485714285714284,
      "grad_norm": 0.0018669278360903263,
      "learning_rate": 1.606857142857143e-05,
      "loss": 0.0623,
      "step": 10320
    },
    {
      "epoch": 2.9514285714285715,
      "grad_norm": 0.03615916892886162,
      "learning_rate": 1.6064761904761904e-05,
      "loss": 0.0001,
      "step": 10330
    },
    {
      "epoch": 2.954285714285714,
      "grad_norm": 0.0013566275592893362,
      "learning_rate": 1.6060952380952383e-05,
      "loss": 0.1156,
      "step": 10340
    },
    {
      "epoch": 2.9571428571428573,
      "grad_norm": 0.001026541693136096,
      "learning_rate": 1.605714285714286e-05,
      "loss": 0.0,
      "step": 10350
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.00537912966683507,
      "learning_rate": 1.6053333333333334e-05,
      "loss": 0.0007,
      "step": 10360
    },
    {
      "epoch": 2.9628571428571426,
      "grad_norm": 0.0016907858662307262,
      "learning_rate": 1.604952380952381e-05,
      "loss": 0.0001,
      "step": 10370
    },
    {
      "epoch": 2.9657142857142857,
      "grad_norm": 0.005068342201411724,
      "learning_rate": 1.6045714285714286e-05,
      "loss": 0.1593,
      "step": 10380
    },
    {
      "epoch": 2.9685714285714284,
      "grad_norm": 0.33258551359176636,
      "learning_rate": 1.6041904761904764e-05,
      "loss": 0.1604,
      "step": 10390
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 0.0015746850986033678,
      "learning_rate": 1.603809523809524e-05,
      "loss": 0.1478,
      "step": 10400
    },
    {
      "epoch": 2.974285714285714,
      "grad_norm": 0.011199156753718853,
      "learning_rate": 1.6034285714285716e-05,
      "loss": 0.139,
      "step": 10410
    },
    {
      "epoch": 2.977142857142857,
      "grad_norm": 0.009126458317041397,
      "learning_rate": 1.603047619047619e-05,
      "loss": 0.0006,
      "step": 10420
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.2259630262851715,
      "learning_rate": 1.6026666666666667e-05,
      "loss": 0.0049,
      "step": 10430
    },
    {
      "epoch": 2.982857142857143,
      "grad_norm": 0.0025542639195919037,
      "learning_rate": 1.6022857142857146e-05,
      "loss": 0.0129,
      "step": 10440
    },
    {
      "epoch": 2.9857142857142858,
      "grad_norm": 0.003146744566038251,
      "learning_rate": 1.601904761904762e-05,
      "loss": 0.0904,
      "step": 10450
    },
    {
      "epoch": 2.9885714285714284,
      "grad_norm": 82.77557373046875,
      "learning_rate": 1.6015238095238097e-05,
      "loss": 0.6256,
      "step": 10460
    },
    {
      "epoch": 2.9914285714285715,
      "grad_norm": 0.24995693564414978,
      "learning_rate": 1.6011428571428573e-05,
      "loss": 0.0016,
      "step": 10470
    },
    {
      "epoch": 2.994285714285714,
      "grad_norm": 0.002142516430467367,
      "learning_rate": 1.6007619047619048e-05,
      "loss": 0.2058,
      "step": 10480
    },
    {
      "epoch": 2.9971428571428573,
      "grad_norm": 0.0035394958686083555,
      "learning_rate": 1.6003809523809527e-05,
      "loss": 0.0001,
      "step": 10490
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.07828057557344437,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0932,
      "step": 10500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9786666666666667,
      "eval_f1": 0.8693877551020408,
      "eval_loss": 0.12811201810836792,
      "eval_precision": 0.902542372881356,
      "eval_recall": 0.8385826771653543,
      "eval_runtime": 261.0401,
      "eval_samples_per_second": 11.492,
      "eval_steps_per_second": 2.873,
      "step": 10500
    },
    {
      "epoch": 3.0028571428571427,
      "grad_norm": 0.004503392148762941,
      "learning_rate": 1.5996190476190478e-05,
      "loss": 0.0002,
      "step": 10510
    },
    {
      "epoch": 3.005714285714286,
      "grad_norm": 0.0033709928393363953,
      "learning_rate": 1.5992380952380954e-05,
      "loss": 0.1628,
      "step": 10520
    },
    {
      "epoch": 3.0085714285714285,
      "grad_norm": 0.0029827337712049484,
      "learning_rate": 1.598857142857143e-05,
      "loss": 0.0003,
      "step": 10530
    },
    {
      "epoch": 3.0114285714285716,
      "grad_norm": 0.005356469191610813,
      "learning_rate": 1.5984761904761905e-05,
      "loss": 0.1422,
      "step": 10540
    },
    {
      "epoch": 3.0142857142857142,
      "grad_norm": 0.0039200931787490845,
      "learning_rate": 1.598095238095238e-05,
      "loss": 0.0001,
      "step": 10550
    },
    {
      "epoch": 3.0171428571428573,
      "grad_norm": 0.08379900455474854,
      "learning_rate": 1.5977142857142856e-05,
      "loss": 0.0874,
      "step": 10560
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.004042876418679953,
      "learning_rate": 1.5973333333333335e-05,
      "loss": 0.0666,
      "step": 10570
    },
    {
      "epoch": 3.0228571428571427,
      "grad_norm": 0.2229185849428177,
      "learning_rate": 1.596952380952381e-05,
      "loss": 0.1573,
      "step": 10580
    },
    {
      "epoch": 3.025714285714286,
      "grad_norm": 0.11550585180521011,
      "learning_rate": 1.5965714285714286e-05,
      "loss": 0.0004,
      "step": 10590
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 0.000731161271687597,
      "learning_rate": 1.5961904761904762e-05,
      "loss": 0.0002,
      "step": 10600
    },
    {
      "epoch": 3.0314285714285716,
      "grad_norm": 0.001948902616277337,
      "learning_rate": 1.595809523809524e-05,
      "loss": 0.0983,
      "step": 10610
    },
    {
      "epoch": 3.0342857142857143,
      "grad_norm": 0.005136937368661165,
      "learning_rate": 1.5954285714285716e-05,
      "loss": 0.0328,
      "step": 10620
    },
    {
      "epoch": 3.0371428571428574,
      "grad_norm": 0.0014170805225148797,
      "learning_rate": 1.5950476190476192e-05,
      "loss": 0.1579,
      "step": 10630
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.04986421391367912,
      "learning_rate": 1.5946666666666668e-05,
      "loss": 0.0011,
      "step": 10640
    },
    {
      "epoch": 3.0428571428571427,
      "grad_norm": 0.0010999053483828902,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 0.0003,
      "step": 10650
    },
    {
      "epoch": 3.045714285714286,
      "grad_norm": 0.10962478816509247,
      "learning_rate": 1.5939047619047622e-05,
      "loss": 0.017,
      "step": 10660
    },
    {
      "epoch": 3.0485714285714285,
      "grad_norm": 0.0035210484638810158,
      "learning_rate": 1.5935238095238098e-05,
      "loss": 0.1594,
      "step": 10670
    },
    {
      "epoch": 3.0514285714285716,
      "grad_norm": 0.0012242667144164443,
      "learning_rate": 1.5931428571428573e-05,
      "loss": 0.0165,
      "step": 10680
    },
    {
      "epoch": 3.0542857142857143,
      "grad_norm": 0.0010088790440931916,
      "learning_rate": 1.592761904761905e-05,
      "loss": 0.0001,
      "step": 10690
    },
    {
      "epoch": 3.057142857142857,
      "grad_norm": 0.009145863354206085,
      "learning_rate": 1.5923809523809524e-05,
      "loss": 0.1122,
      "step": 10700
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.04705525562167168,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.0001,
      "step": 10710
    },
    {
      "epoch": 3.0628571428571427,
      "grad_norm": 0.015795934945344925,
      "learning_rate": 1.591619047619048e-05,
      "loss": 0.0003,
      "step": 10720
    },
    {
      "epoch": 3.065714285714286,
      "grad_norm": 0.03251875564455986,
      "learning_rate": 1.5912380952380955e-05,
      "loss": 0.0002,
      "step": 10730
    },
    {
      "epoch": 3.0685714285714285,
      "grad_norm": 0.008090413175523281,
      "learning_rate": 1.590857142857143e-05,
      "loss": 0.0001,
      "step": 10740
    },
    {
      "epoch": 3.0714285714285716,
      "grad_norm": 0.000671055109705776,
      "learning_rate": 1.5904761904761906e-05,
      "loss": 0.111,
      "step": 10750
    },
    {
      "epoch": 3.0742857142857143,
      "grad_norm": 0.7371626496315002,
      "learning_rate": 1.590095238095238e-05,
      "loss": 0.188,
      "step": 10760
    },
    {
      "epoch": 3.077142857142857,
      "grad_norm": 0.0027410394977778196,
      "learning_rate": 1.5897142857142857e-05,
      "loss": 0.0006,
      "step": 10770
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.0033438224345445633,
      "learning_rate": 1.5893333333333333e-05,
      "loss": 0.0576,
      "step": 10780
    },
    {
      "epoch": 3.0828571428571427,
      "grad_norm": 0.02958041988313198,
      "learning_rate": 1.588952380952381e-05,
      "loss": 0.175,
      "step": 10790
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 0.18446069955825806,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.1344,
      "step": 10800
    },
    {
      "epoch": 3.0885714285714285,
      "grad_norm": 0.0009332052432000637,
      "learning_rate": 1.5881904761904763e-05,
      "loss": 0.2187,
      "step": 10810
    },
    {
      "epoch": 3.0914285714285716,
      "grad_norm": 0.016577377915382385,
      "learning_rate": 1.5878095238095238e-05,
      "loss": 0.0004,
      "step": 10820
    },
    {
      "epoch": 3.0942857142857143,
      "grad_norm": 0.33286723494529724,
      "learning_rate": 1.5874285714285714e-05,
      "loss": 0.0003,
      "step": 10830
    },
    {
      "epoch": 3.097142857142857,
      "grad_norm": 0.007082279771566391,
      "learning_rate": 1.5870476190476193e-05,
      "loss": 0.0003,
      "step": 10840
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.0017295416910201311,
      "learning_rate": 1.586666666666667e-05,
      "loss": 0.1185,
      "step": 10850
    },
    {
      "epoch": 3.1028571428571428,
      "grad_norm": 0.04000717028975487,
      "learning_rate": 1.5862857142857144e-05,
      "loss": 0.0362,
      "step": 10860
    },
    {
      "epoch": 3.105714285714286,
      "grad_norm": 0.006120380014181137,
      "learning_rate": 1.585904761904762e-05,
      "loss": 0.0005,
      "step": 10870
    },
    {
      "epoch": 3.1085714285714285,
      "grad_norm": 0.0005570917273871601,
      "learning_rate": 1.58552380952381e-05,
      "loss": 0.0002,
      "step": 10880
    },
    {
      "epoch": 3.111428571428571,
      "grad_norm": 0.0010705055901780725,
      "learning_rate": 1.5851428571428574e-05,
      "loss": 0.2495,
      "step": 10890
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 0.0008090794435702264,
      "learning_rate": 1.584761904761905e-05,
      "loss": 0.0002,
      "step": 10900
    },
    {
      "epoch": 3.117142857142857,
      "grad_norm": 0.005148457828909159,
      "learning_rate": 1.5843809523809525e-05,
      "loss": 0.3699,
      "step": 10910
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.014041035436093807,
      "learning_rate": 1.584e-05,
      "loss": 0.11,
      "step": 10920
    },
    {
      "epoch": 3.1228571428571428,
      "grad_norm": 0.008381102234125137,
      "learning_rate": 1.583619047619048e-05,
      "loss": 0.0052,
      "step": 10930
    },
    {
      "epoch": 3.125714285714286,
      "grad_norm": 0.0006530044483952224,
      "learning_rate": 1.5832380952380955e-05,
      "loss": 0.1066,
      "step": 10940
    },
    {
      "epoch": 3.1285714285714286,
      "grad_norm": 0.0007811529794707894,
      "learning_rate": 1.582857142857143e-05,
      "loss": 0.0005,
      "step": 10950
    },
    {
      "epoch": 3.1314285714285712,
      "grad_norm": 0.025727996602654457,
      "learning_rate": 1.5824761904761907e-05,
      "loss": 0.3588,
      "step": 10960
    },
    {
      "epoch": 3.1342857142857143,
      "grad_norm": 0.00837311614304781,
      "learning_rate": 1.5820952380952382e-05,
      "loss": 0.0001,
      "step": 10970
    },
    {
      "epoch": 3.137142857142857,
      "grad_norm": 0.012205177918076515,
      "learning_rate": 1.5817142857142858e-05,
      "loss": 0.0948,
      "step": 10980
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.03153490647673607,
      "learning_rate": 1.5813333333333333e-05,
      "loss": 0.0002,
      "step": 10990
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.07890310138463974,
      "learning_rate": 1.580952380952381e-05,
      "loss": 0.0003,
      "step": 11000
    },
    {
      "epoch": 3.145714285714286,
      "grad_norm": 0.005124103743582964,
      "learning_rate": 1.5805714285714288e-05,
      "loss": 0.0576,
      "step": 11010
    },
    {
      "epoch": 3.1485714285714286,
      "grad_norm": 0.010409520007669926,
      "learning_rate": 1.5801904761904763e-05,
      "loss": 0.033,
      "step": 11020
    },
    {
      "epoch": 3.1514285714285712,
      "grad_norm": 0.018066242337226868,
      "learning_rate": 1.579809523809524e-05,
      "loss": 0.0006,
      "step": 11030
    },
    {
      "epoch": 3.1542857142857144,
      "grad_norm": 0.00836912915110588,
      "learning_rate": 1.5794285714285715e-05,
      "loss": 0.0001,
      "step": 11040
    },
    {
      "epoch": 3.157142857142857,
      "grad_norm": 0.001118781161494553,
      "learning_rate": 1.579047619047619e-05,
      "loss": 0.0001,
      "step": 11050
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.0012995776487514377,
      "learning_rate": 1.578666666666667e-05,
      "loss": 0.0001,
      "step": 11060
    },
    {
      "epoch": 3.162857142857143,
      "grad_norm": 0.00580254103988409,
      "learning_rate": 1.5782857142857145e-05,
      "loss": 0.0002,
      "step": 11070
    },
    {
      "epoch": 3.1657142857142855,
      "grad_norm": 0.0011817618506029248,
      "learning_rate": 1.577904761904762e-05,
      "loss": 0.1035,
      "step": 11080
    },
    {
      "epoch": 3.1685714285714286,
      "grad_norm": 0.0010191998444497585,
      "learning_rate": 1.5775238095238096e-05,
      "loss": 0.0442,
      "step": 11090
    },
    {
      "epoch": 3.1714285714285713,
      "grad_norm": 0.0025485858786851168,
      "learning_rate": 1.577142857142857e-05,
      "loss": 0.0,
      "step": 11100
    },
    {
      "epoch": 3.1742857142857144,
      "grad_norm": 0.02612941339612007,
      "learning_rate": 1.576761904761905e-05,
      "loss": 0.3007,
      "step": 11110
    },
    {
      "epoch": 3.177142857142857,
      "grad_norm": 0.015132931992411613,
      "learning_rate": 1.5763809523809526e-05,
      "loss": 0.1105,
      "step": 11120
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.0028155501931905746,
      "learning_rate": 1.576e-05,
      "loss": 0.0002,
      "step": 11130
    },
    {
      "epoch": 3.182857142857143,
      "grad_norm": 0.0006483981269411743,
      "learning_rate": 1.5756190476190477e-05,
      "loss": 0.0006,
      "step": 11140
    },
    {
      "epoch": 3.185714285714286,
      "grad_norm": 0.0006877512787468731,
      "learning_rate": 1.5752380952380956e-05,
      "loss": 0.0008,
      "step": 11150
    },
    {
      "epoch": 3.1885714285714286,
      "grad_norm": 0.0015655439347028732,
      "learning_rate": 1.5748571428571432e-05,
      "loss": 0.0,
      "step": 11160
    },
    {
      "epoch": 3.1914285714285713,
      "grad_norm": 0.00019920813792850822,
      "learning_rate": 1.5744761904761907e-05,
      "loss": 0.0008,
      "step": 11170
    },
    {
      "epoch": 3.1942857142857144,
      "grad_norm": 0.00982176698744297,
      "learning_rate": 1.5740952380952383e-05,
      "loss": 0.0001,
      "step": 11180
    },
    {
      "epoch": 3.197142857142857,
      "grad_norm": 0.0002575810649432242,
      "learning_rate": 1.573714285714286e-05,
      "loss": 0.0019,
      "step": 11190
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.0008272234699688852,
      "learning_rate": 1.5733333333333334e-05,
      "loss": 0.0004,
      "step": 11200
    },
    {
      "epoch": 3.202857142857143,
      "grad_norm": 0.0017464664997532964,
      "learning_rate": 1.572952380952381e-05,
      "loss": 0.0001,
      "step": 11210
    },
    {
      "epoch": 3.2057142857142855,
      "grad_norm": 0.0013628435553982854,
      "learning_rate": 1.5725714285714285e-05,
      "loss": 0.1965,
      "step": 11220
    },
    {
      "epoch": 3.2085714285714286,
      "grad_norm": 0.002443533856421709,
      "learning_rate": 1.5721904761904764e-05,
      "loss": 0.0,
      "step": 11230
    },
    {
      "epoch": 3.2114285714285713,
      "grad_norm": 0.004940690007060766,
      "learning_rate": 1.571809523809524e-05,
      "loss": 0.0031,
      "step": 11240
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 0.002822058042511344,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0047,
      "step": 11250
    },
    {
      "epoch": 3.217142857142857,
      "grad_norm": 0.389213502407074,
      "learning_rate": 1.571047619047619e-05,
      "loss": 0.0003,
      "step": 11260
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.00016294294619001448,
      "learning_rate": 1.5706666666666666e-05,
      "loss": 0.0166,
      "step": 11270
    },
    {
      "epoch": 3.222857142857143,
      "grad_norm": 0.006391206756234169,
      "learning_rate": 1.5702857142857145e-05,
      "loss": 0.0002,
      "step": 11280
    },
    {
      "epoch": 3.2257142857142855,
      "grad_norm": 0.00040403081220574677,
      "learning_rate": 1.569904761904762e-05,
      "loss": 0.0,
      "step": 11290
    },
    {
      "epoch": 3.2285714285714286,
      "grad_norm": 0.00012313161278143525,
      "learning_rate": 1.5695238095238097e-05,
      "loss": 0.0006,
      "step": 11300
    },
    {
      "epoch": 3.2314285714285713,
      "grad_norm": 0.000401053432142362,
      "learning_rate": 1.5691428571428572e-05,
      "loss": 0.0002,
      "step": 11310
    },
    {
      "epoch": 3.2342857142857144,
      "grad_norm": 21.019939422607422,
      "learning_rate": 1.5687619047619048e-05,
      "loss": 0.3247,
      "step": 11320
    },
    {
      "epoch": 3.237142857142857,
      "grad_norm": 0.001393742160871625,
      "learning_rate": 1.5683809523809527e-05,
      "loss": 0.0001,
      "step": 11330
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.0076341331005096436,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 0.0001,
      "step": 11340
    },
    {
      "epoch": 3.242857142857143,
      "grad_norm": 0.1638045758008957,
      "learning_rate": 1.5676190476190478e-05,
      "loss": 0.0131,
      "step": 11350
    },
    {
      "epoch": 3.2457142857142856,
      "grad_norm": 0.003638377645984292,
      "learning_rate": 1.5672380952380954e-05,
      "loss": 0.0002,
      "step": 11360
    },
    {
      "epoch": 3.2485714285714287,
      "grad_norm": 0.002285074908286333,
      "learning_rate": 1.566857142857143e-05,
      "loss": 0.1765,
      "step": 11370
    },
    {
      "epoch": 3.2514285714285713,
      "grad_norm": 28.941499710083008,
      "learning_rate": 1.5664761904761908e-05,
      "loss": 0.013,
      "step": 11380
    },
    {
      "epoch": 3.2542857142857144,
      "grad_norm": 0.1587619036436081,
      "learning_rate": 1.566095238095238e-05,
      "loss": 0.1225,
      "step": 11390
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 0.010015669278800488,
      "learning_rate": 1.5657142857142856e-05,
      "loss": 0.0003,
      "step": 11400
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.002587889553979039,
      "learning_rate": 1.5653333333333335e-05,
      "loss": 0.0002,
      "step": 11410
    },
    {
      "epoch": 3.262857142857143,
      "grad_norm": 0.001098898472264409,
      "learning_rate": 1.564952380952381e-05,
      "loss": 0.0004,
      "step": 11420
    },
    {
      "epoch": 3.2657142857142856,
      "grad_norm": 0.0071534947492182255,
      "learning_rate": 1.5645714285714286e-05,
      "loss": 0.0799,
      "step": 11430
    },
    {
      "epoch": 3.2685714285714287,
      "grad_norm": 0.003002700861543417,
      "learning_rate": 1.564190476190476e-05,
      "loss": 0.0711,
      "step": 11440
    },
    {
      "epoch": 3.2714285714285714,
      "grad_norm": 0.0003526093205437064,
      "learning_rate": 1.563809523809524e-05,
      "loss": 0.0001,
      "step": 11450
    },
    {
      "epoch": 3.2742857142857145,
      "grad_norm": 17.10944366455078,
      "learning_rate": 1.5634285714285716e-05,
      "loss": 0.0045,
      "step": 11460
    },
    {
      "epoch": 3.277142857142857,
      "grad_norm": 0.0006645709509029984,
      "learning_rate": 1.563047619047619e-05,
      "loss": 0.0,
      "step": 11470
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.004232736770063639,
      "learning_rate": 1.5626666666666667e-05,
      "loss": 0.21,
      "step": 11480
    },
    {
      "epoch": 3.282857142857143,
      "grad_norm": 0.0026046859566122293,
      "learning_rate": 1.5622857142857143e-05,
      "loss": 0.2106,
      "step": 11490
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 0.008240088820457458,
      "learning_rate": 1.5619047619047622e-05,
      "loss": 0.0002,
      "step": 11500
    },
    {
      "epoch": 3.2885714285714287,
      "grad_norm": 0.0102683799341321,
      "learning_rate": 1.5615238095238097e-05,
      "loss": 0.0879,
      "step": 11510
    },
    {
      "epoch": 3.2914285714285714,
      "grad_norm": 0.07109293341636658,
      "learning_rate": 1.5611428571428573e-05,
      "loss": 0.0003,
      "step": 11520
    },
    {
      "epoch": 3.2942857142857145,
      "grad_norm": 60.57399368286133,
      "learning_rate": 1.560761904761905e-05,
      "loss": 0.3074,
      "step": 11530
    },
    {
      "epoch": 3.297142857142857,
      "grad_norm": 1.0779746770858765,
      "learning_rate": 1.5603809523809524e-05,
      "loss": 0.1859,
      "step": 11540
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.039585281163454056,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0086,
      "step": 11550
    },
    {
      "epoch": 3.302857142857143,
      "grad_norm": 0.001222694176249206,
      "learning_rate": 1.559619047619048e-05,
      "loss": 0.0001,
      "step": 11560
    },
    {
      "epoch": 3.3057142857142856,
      "grad_norm": 0.00228653266094625,
      "learning_rate": 1.5592380952380954e-05,
      "loss": 0.0001,
      "step": 11570
    },
    {
      "epoch": 3.3085714285714287,
      "grad_norm": 0.0014996547251939774,
      "learning_rate": 1.558857142857143e-05,
      "loss": 0.0,
      "step": 11580
    },
    {
      "epoch": 3.3114285714285714,
      "grad_norm": 0.0033576753921806812,
      "learning_rate": 1.5584761904761905e-05,
      "loss": 0.423,
      "step": 11590
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 0.003300793468952179,
      "learning_rate": 1.5580952380952384e-05,
      "loss": 0.0002,
      "step": 11600
    },
    {
      "epoch": 3.317142857142857,
      "grad_norm": 0.012956565245985985,
      "learning_rate": 1.5577142857142857e-05,
      "loss": 0.0822,
      "step": 11610
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.017771964892745018,
      "learning_rate": 1.5573333333333332e-05,
      "loss": 0.0006,
      "step": 11620
    },
    {
      "epoch": 3.322857142857143,
      "grad_norm": 0.04251999780535698,
      "learning_rate": 1.556952380952381e-05,
      "loss": 0.2285,
      "step": 11630
    },
    {
      "epoch": 3.3257142857142856,
      "grad_norm": 0.08346416056156158,
      "learning_rate": 1.5565714285714287e-05,
      "loss": 0.0008,
      "step": 11640
    },
    {
      "epoch": 3.3285714285714287,
      "grad_norm": 0.08645641803741455,
      "learning_rate": 1.5561904761904762e-05,
      "loss": 0.0075,
      "step": 11650
    },
    {
      "epoch": 3.3314285714285714,
      "grad_norm": 0.0043617673218250275,
      "learning_rate": 1.5558095238095238e-05,
      "loss": 0.4516,
      "step": 11660
    },
    {
      "epoch": 3.3342857142857145,
      "grad_norm": 0.02709975093603134,
      "learning_rate": 1.5554285714285713e-05,
      "loss": 0.0002,
      "step": 11670
    },
    {
      "epoch": 3.337142857142857,
      "grad_norm": 1.249880313873291,
      "learning_rate": 1.5550476190476192e-05,
      "loss": 0.2437,
      "step": 11680
    },
    {
      "epoch": 3.34,
      "grad_norm": 39.87359619140625,
      "learning_rate": 1.5546666666666668e-05,
      "loss": 0.081,
      "step": 11690
    },
    {
      "epoch": 3.342857142857143,
      "grad_norm": 0.0094774654135108,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 0.0367,
      "step": 11700
    },
    {
      "epoch": 3.3457142857142856,
      "grad_norm": 0.008814201690256596,
      "learning_rate": 1.553904761904762e-05,
      "loss": 0.0003,
      "step": 11710
    },
    {
      "epoch": 3.3485714285714288,
      "grad_norm": 0.09928499162197113,
      "learning_rate": 1.5535238095238098e-05,
      "loss": 0.0918,
      "step": 11720
    },
    {
      "epoch": 3.3514285714285714,
      "grad_norm": 0.024960428476333618,
      "learning_rate": 1.5531428571428574e-05,
      "loss": 0.0055,
      "step": 11730
    },
    {
      "epoch": 3.354285714285714,
      "grad_norm": 0.016219638288021088,
      "learning_rate": 1.552761904761905e-05,
      "loss": 0.0475,
      "step": 11740
    },
    {
      "epoch": 3.357142857142857,
      "grad_norm": 0.0038190274499356747,
      "learning_rate": 1.5523809523809525e-05,
      "loss": 0.0002,
      "step": 11750
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.0031668771989643574,
      "learning_rate": 1.552e-05,
      "loss": 0.1603,
      "step": 11760
    },
    {
      "epoch": 3.362857142857143,
      "grad_norm": 0.0016410582466050982,
      "learning_rate": 1.551619047619048e-05,
      "loss": 0.0006,
      "step": 11770
    },
    {
      "epoch": 3.3657142857142857,
      "grad_norm": 0.0009423622977919877,
      "learning_rate": 1.5512380952380955e-05,
      "loss": 0.0017,
      "step": 11780
    },
    {
      "epoch": 3.3685714285714283,
      "grad_norm": 0.0006898210267536342,
      "learning_rate": 1.550857142857143e-05,
      "loss": 0.0001,
      "step": 11790
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 0.0016578740905970335,
      "learning_rate": 1.5504761904761906e-05,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 3.374285714285714,
      "grad_norm": 0.002804840449243784,
      "learning_rate": 1.5500952380952382e-05,
      "loss": 0.3961,
      "step": 11810
    },
    {
      "epoch": 3.3771428571428572,
      "grad_norm": 0.02588876150548458,
      "learning_rate": 1.549714285714286e-05,
      "loss": 0.0002,
      "step": 11820
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.025997523218393326,
      "learning_rate": 1.5493333333333333e-05,
      "loss": 0.1406,
      "step": 11830
    },
    {
      "epoch": 3.382857142857143,
      "grad_norm": 0.0017342931823804975,
      "learning_rate": 1.548952380952381e-05,
      "loss": 0.0007,
      "step": 11840
    },
    {
      "epoch": 3.3857142857142857,
      "grad_norm": 0.032354291528463364,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 0.0001,
      "step": 11850
    },
    {
      "epoch": 3.388571428571429,
      "grad_norm": 0.0013901679776608944,
      "learning_rate": 1.5481904761904763e-05,
      "loss": 0.0048,
      "step": 11860
    },
    {
      "epoch": 3.3914285714285715,
      "grad_norm": 0.007819466292858124,
      "learning_rate": 1.547809523809524e-05,
      "loss": 0.154,
      "step": 11870
    },
    {
      "epoch": 3.394285714285714,
      "grad_norm": 0.0007998538203537464,
      "learning_rate": 1.5474285714285714e-05,
      "loss": 0.0719,
      "step": 11880
    },
    {
      "epoch": 3.3971428571428572,
      "grad_norm": 0.0739036351442337,
      "learning_rate": 1.547047619047619e-05,
      "loss": 0.0002,
      "step": 11890
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.006214832421392202,
      "learning_rate": 1.546666666666667e-05,
      "loss": 0.0002,
      "step": 11900
    },
    {
      "epoch": 3.402857142857143,
      "grad_norm": 0.19107674062252045,
      "learning_rate": 1.5462857142857144e-05,
      "loss": 0.0003,
      "step": 11910
    },
    {
      "epoch": 3.4057142857142857,
      "grad_norm": 0.0008384085958823562,
      "learning_rate": 1.545904761904762e-05,
      "loss": 0.0,
      "step": 11920
    },
    {
      "epoch": 3.4085714285714284,
      "grad_norm": 0.0006074217380955815,
      "learning_rate": 1.5455238095238096e-05,
      "loss": 0.0857,
      "step": 11930
    },
    {
      "epoch": 3.4114285714285715,
      "grad_norm": 0.00021607038797810674,
      "learning_rate": 1.545142857142857e-05,
      "loss": 0.1125,
      "step": 11940
    },
    {
      "epoch": 3.414285714285714,
      "grad_norm": 0.03150705248117447,
      "learning_rate": 1.544761904761905e-05,
      "loss": 0.3777,
      "step": 11950
    },
    {
      "epoch": 3.4171428571428573,
      "grad_norm": 0.001934164552949369,
      "learning_rate": 1.5443809523809526e-05,
      "loss": 0.0001,
      "step": 11960
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.005802735220640898,
      "learning_rate": 1.544e-05,
      "loss": 0.0001,
      "step": 11970
    },
    {
      "epoch": 3.422857142857143,
      "grad_norm": 0.2174018770456314,
      "learning_rate": 1.5436190476190477e-05,
      "loss": 0.5704,
      "step": 11980
    },
    {
      "epoch": 3.4257142857142857,
      "grad_norm": 0.13642482459545135,
      "learning_rate": 1.5432380952380956e-05,
      "loss": 0.0067,
      "step": 11990
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.005929296836256981,
      "learning_rate": 1.542857142857143e-05,
      "loss": 0.0007,
      "step": 12000
    },
    {
      "epoch": 3.4314285714285715,
      "grad_norm": 0.014330883510410786,
      "learning_rate": 1.5424761904761907e-05,
      "loss": 0.1316,
      "step": 12010
    },
    {
      "epoch": 3.434285714285714,
      "grad_norm": 0.16120390594005585,
      "learning_rate": 1.5420952380952383e-05,
      "loss": 0.0943,
      "step": 12020
    },
    {
      "epoch": 3.4371428571428573,
      "grad_norm": 0.005482211709022522,
      "learning_rate": 1.5417142857142858e-05,
      "loss": 0.1178,
      "step": 12030
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.0006128633976913989,
      "learning_rate": 1.5413333333333337e-05,
      "loss": 0.0124,
      "step": 12040
    },
    {
      "epoch": 3.442857142857143,
      "grad_norm": 0.0010000885231420398,
      "learning_rate": 1.540952380952381e-05,
      "loss": 0.0003,
      "step": 12050
    },
    {
      "epoch": 3.4457142857142857,
      "grad_norm": 0.7180606126785278,
      "learning_rate": 1.5405714285714285e-05,
      "loss": 0.0008,
      "step": 12060
    },
    {
      "epoch": 3.4485714285714284,
      "grad_norm": 0.0025206736754626036,
      "learning_rate": 1.5401904761904764e-05,
      "loss": 0.0005,
      "step": 12070
    },
    {
      "epoch": 3.4514285714285715,
      "grad_norm": 0.0012451648944988847,
      "learning_rate": 1.539809523809524e-05,
      "loss": 0.0001,
      "step": 12080
    },
    {
      "epoch": 3.454285714285714,
      "grad_norm": 0.0020048862788826227,
      "learning_rate": 1.5394285714285715e-05,
      "loss": 0.2325,
      "step": 12090
    },
    {
      "epoch": 3.4571428571428573,
      "grad_norm": 0.061495859175920486,
      "learning_rate": 1.539047619047619e-05,
      "loss": 0.0005,
      "step": 12100
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.014121019281446934,
      "learning_rate": 1.5386666666666666e-05,
      "loss": 0.0578,
      "step": 12110
    },
    {
      "epoch": 3.4628571428571426,
      "grad_norm": 0.0023219971917569637,
      "learning_rate": 1.5382857142857145e-05,
      "loss": 0.0001,
      "step": 12120
    },
    {
      "epoch": 3.4657142857142857,
      "grad_norm": 0.007193815428763628,
      "learning_rate": 1.537904761904762e-05,
      "loss": 0.0001,
      "step": 12130
    },
    {
      "epoch": 3.4685714285714284,
      "grad_norm": 0.012309975922107697,
      "learning_rate": 1.5375238095238096e-05,
      "loss": 0.1745,
      "step": 12140
    },
    {
      "epoch": 3.4714285714285715,
      "grad_norm": 0.0032083988189697266,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.0002,
      "step": 12150
    },
    {
      "epoch": 3.474285714285714,
      "grad_norm": 0.006134902127087116,
      "learning_rate": 1.5367619047619047e-05,
      "loss": 0.0001,
      "step": 12160
    },
    {
      "epoch": 3.4771428571428573,
      "grad_norm": 0.0008762127836234868,
      "learning_rate": 1.5363809523809526e-05,
      "loss": 0.0,
      "step": 12170
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.013076506555080414,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 0.0878,
      "step": 12180
    },
    {
      "epoch": 3.482857142857143,
      "grad_norm": 0.0031132164876908064,
      "learning_rate": 1.5356190476190478e-05,
      "loss": 0.0,
      "step": 12190
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 0.0046043237671256065,
      "learning_rate": 1.5352380952380953e-05,
      "loss": 0.1422,
      "step": 12200
    },
    {
      "epoch": 3.4885714285714284,
      "grad_norm": 0.010971108451485634,
      "learning_rate": 1.534857142857143e-05,
      "loss": 0.15,
      "step": 12210
    },
    {
      "epoch": 3.4914285714285715,
      "grad_norm": 0.013998016715049744,
      "learning_rate": 1.5344761904761908e-05,
      "loss": 0.2077,
      "step": 12220
    },
    {
      "epoch": 3.494285714285714,
      "grad_norm": 0.26337793469429016,
      "learning_rate": 1.5340952380952383e-05,
      "loss": 0.0023,
      "step": 12230
    },
    {
      "epoch": 3.4971428571428573,
      "grad_norm": 0.005815248005092144,
      "learning_rate": 1.533714285714286e-05,
      "loss": 0.0617,
      "step": 12240
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.003859895747154951,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.0002,
      "step": 12250
    },
    {
      "epoch": 3.5028571428571427,
      "grad_norm": 0.006039263214915991,
      "learning_rate": 1.532952380952381e-05,
      "loss": 0.0002,
      "step": 12260
    },
    {
      "epoch": 3.505714285714286,
      "grad_norm": 0.006073374301195145,
      "learning_rate": 1.5325714285714286e-05,
      "loss": 0.0001,
      "step": 12270
    },
    {
      "epoch": 3.5085714285714285,
      "grad_norm": 0.004601579159498215,
      "learning_rate": 1.532190476190476e-05,
      "loss": 0.233,
      "step": 12280
    },
    {
      "epoch": 3.5114285714285716,
      "grad_norm": 0.011727666482329369,
      "learning_rate": 1.531809523809524e-05,
      "loss": 0.0003,
      "step": 12290
    },
    {
      "epoch": 3.5142857142857142,
      "grad_norm": 0.017361117526888847,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 0.0002,
      "step": 12300
    },
    {
      "epoch": 3.517142857142857,
      "grad_norm": 0.0031749638728797436,
      "learning_rate": 1.531047619047619e-05,
      "loss": 0.0002,
      "step": 12310
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.0053185392171144485,
      "learning_rate": 1.5306666666666667e-05,
      "loss": 0.0002,
      "step": 12320
    },
    {
      "epoch": 3.522857142857143,
      "grad_norm": 0.0043207937851548195,
      "learning_rate": 1.5302857142857143e-05,
      "loss": 0.1523,
      "step": 12330
    },
    {
      "epoch": 3.525714285714286,
      "grad_norm": 0.0024248266126960516,
      "learning_rate": 1.529904761904762e-05,
      "loss": 0.0002,
      "step": 12340
    },
    {
      "epoch": 3.5285714285714285,
      "grad_norm": 0.002312770113348961,
      "learning_rate": 1.5295238095238097e-05,
      "loss": 0.0001,
      "step": 12350
    },
    {
      "epoch": 3.5314285714285716,
      "grad_norm": 0.010054321959614754,
      "learning_rate": 1.5291428571428573e-05,
      "loss": 0.0001,
      "step": 12360
    },
    {
      "epoch": 3.5342857142857143,
      "grad_norm": 0.008595449849963188,
      "learning_rate": 1.5287619047619048e-05,
      "loss": 0.1881,
      "step": 12370
    },
    {
      "epoch": 3.5371428571428574,
      "grad_norm": 0.025834711268544197,
      "learning_rate": 1.5283809523809524e-05,
      "loss": 0.0002,
      "step": 12380
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.015595224685966969,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 0.1481,
      "step": 12390
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 0.007872382178902626,
      "learning_rate": 1.527619047619048e-05,
      "loss": 0.0003,
      "step": 12400
    },
    {
      "epoch": 3.545714285714286,
      "grad_norm": 0.0059461407363414764,
      "learning_rate": 1.5272380952380954e-05,
      "loss": 0.0004,
      "step": 12410
    },
    {
      "epoch": 3.5485714285714285,
      "grad_norm": 0.0020777720492333174,
      "learning_rate": 1.526857142857143e-05,
      "loss": 0.0002,
      "step": 12420
    },
    {
      "epoch": 3.5514285714285716,
      "grad_norm": 0.003653721883893013,
      "learning_rate": 1.5264761904761905e-05,
      "loss": 0.1007,
      "step": 12430
    },
    {
      "epoch": 3.5542857142857143,
      "grad_norm": 0.003878825344145298,
      "learning_rate": 1.5260952380952384e-05,
      "loss": 0.0003,
      "step": 12440
    },
    {
      "epoch": 3.557142857142857,
      "grad_norm": 0.0017257803119719028,
      "learning_rate": 1.525714285714286e-05,
      "loss": 0.0001,
      "step": 12450
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.003181286621838808,
      "learning_rate": 1.5253333333333335e-05,
      "loss": 0.1876,
      "step": 12460
    },
    {
      "epoch": 3.5628571428571427,
      "grad_norm": 39.42618179321289,
      "learning_rate": 1.5249523809523813e-05,
      "loss": 0.0678,
      "step": 12470
    },
    {
      "epoch": 3.565714285714286,
      "grad_norm": 0.006145545747131109,
      "learning_rate": 1.5245714285714286e-05,
      "loss": 0.1505,
      "step": 12480
    },
    {
      "epoch": 3.5685714285714285,
      "grad_norm": 0.0017431951127946377,
      "learning_rate": 1.5241904761904762e-05,
      "loss": 0.0003,
      "step": 12490
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.004936178680509329,
      "learning_rate": 1.523809523809524e-05,
      "loss": 0.0001,
      "step": 12500
    },
    {
      "epoch": 3.5742857142857143,
      "grad_norm": 0.001014743815176189,
      "learning_rate": 1.5234285714285715e-05,
      "loss": 0.0001,
      "step": 12510
    },
    {
      "epoch": 3.5771428571428574,
      "grad_norm": 0.0009973495034500957,
      "learning_rate": 1.523047619047619e-05,
      "loss": 0.0002,
      "step": 12520
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.00399045180529356,
      "learning_rate": 1.5226666666666668e-05,
      "loss": 0.0001,
      "step": 12530
    },
    {
      "epoch": 3.5828571428571427,
      "grad_norm": 0.0037413849495351315,
      "learning_rate": 1.5222857142857143e-05,
      "loss": 0.1376,
      "step": 12540
    },
    {
      "epoch": 3.585714285714286,
      "grad_norm": 0.17281506955623627,
      "learning_rate": 1.521904761904762e-05,
      "loss": 0.1322,
      "step": 12550
    },
    {
      "epoch": 3.5885714285714285,
      "grad_norm": 23.53717613220215,
      "learning_rate": 1.5215238095238096e-05,
      "loss": 0.4421,
      "step": 12560
    },
    {
      "epoch": 3.5914285714285716,
      "grad_norm": 0.009296976029872894,
      "learning_rate": 1.5211428571428572e-05,
      "loss": 0.001,
      "step": 12570
    },
    {
      "epoch": 3.5942857142857143,
      "grad_norm": 0.0009914092952385545,
      "learning_rate": 1.5207619047619049e-05,
      "loss": 0.0019,
      "step": 12580
    },
    {
      "epoch": 3.597142857142857,
      "grad_norm": 0.00040144450031220913,
      "learning_rate": 1.5203809523809525e-05,
      "loss": 0.1337,
      "step": 12590
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.15804246068000793,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.2069,
      "step": 12600
    },
    {
      "epoch": 3.6028571428571428,
      "grad_norm": 0.024098698049783707,
      "learning_rate": 1.5196190476190477e-05,
      "loss": 0.0004,
      "step": 12610
    },
    {
      "epoch": 3.605714285714286,
      "grad_norm": 0.03501174971461296,
      "learning_rate": 1.5192380952380955e-05,
      "loss": 0.0002,
      "step": 12620
    },
    {
      "epoch": 3.6085714285714285,
      "grad_norm": 0.01866169646382332,
      "learning_rate": 1.518857142857143e-05,
      "loss": 0.0003,
      "step": 12630
    },
    {
      "epoch": 3.611428571428571,
      "grad_norm": 0.06289453059434891,
      "learning_rate": 1.5184761904761906e-05,
      "loss": 0.0003,
      "step": 12640
    },
    {
      "epoch": 3.6142857142857143,
      "grad_norm": 0.0037969578988850117,
      "learning_rate": 1.5180952380952383e-05,
      "loss": 0.0003,
      "step": 12650
    },
    {
      "epoch": 3.617142857142857,
      "grad_norm": 0.0009499246953055263,
      "learning_rate": 1.5177142857142859e-05,
      "loss": 0.0003,
      "step": 12660
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.013435284607112408,
      "learning_rate": 1.5173333333333336e-05,
      "loss": 0.0001,
      "step": 12670
    },
    {
      "epoch": 3.6228571428571428,
      "grad_norm": 0.006438183598220348,
      "learning_rate": 1.5169523809523812e-05,
      "loss": 0.1178,
      "step": 12680
    },
    {
      "epoch": 3.6257142857142854,
      "grad_norm": 0.0008745459490455687,
      "learning_rate": 1.5165714285714289e-05,
      "loss": 0.0001,
      "step": 12690
    },
    {
      "epoch": 3.6285714285714286,
      "grad_norm": 0.00102873588912189,
      "learning_rate": 1.5161904761904763e-05,
      "loss": 0.1203,
      "step": 12700
    },
    {
      "epoch": 3.6314285714285717,
      "grad_norm": 0.005304668098688126,
      "learning_rate": 1.5158095238095238e-05,
      "loss": 0.0001,
      "step": 12710
    },
    {
      "epoch": 3.6342857142857143,
      "grad_norm": 0.0007941194344311953,
      "learning_rate": 1.5154285714285714e-05,
      "loss": 0.0931,
      "step": 12720
    },
    {
      "epoch": 3.637142857142857,
      "grad_norm": 0.10105589032173157,
      "learning_rate": 1.5150476190476191e-05,
      "loss": 0.0007,
      "step": 12730
    },
    {
      "epoch": 3.64,
      "grad_norm": 5.408360958099365,
      "learning_rate": 1.5146666666666667e-05,
      "loss": 0.0024,
      "step": 12740
    },
    {
      "epoch": 3.642857142857143,
      "grad_norm": 0.0005036123911850154,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 0.0001,
      "step": 12750
    },
    {
      "epoch": 3.645714285714286,
      "grad_norm": 0.0010934870224446058,
      "learning_rate": 1.513904761904762e-05,
      "loss": 0.0002,
      "step": 12760
    },
    {
      "epoch": 3.6485714285714286,
      "grad_norm": 0.0007987224380485713,
      "learning_rate": 1.5135238095238097e-05,
      "loss": 0.0101,
      "step": 12770
    },
    {
      "epoch": 3.6514285714285712,
      "grad_norm": 0.011460216715931892,
      "learning_rate": 1.5131428571428572e-05,
      "loss": 0.0004,
      "step": 12780
    },
    {
      "epoch": 3.6542857142857144,
      "grad_norm": 0.0012247400591149926,
      "learning_rate": 1.5127619047619048e-05,
      "loss": 0.0001,
      "step": 12790
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 0.0048891897313296795,
      "learning_rate": 1.5123809523809525e-05,
      "loss": 0.1815,
      "step": 12800
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.003460434265434742,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.0006,
      "step": 12810
    },
    {
      "epoch": 3.662857142857143,
      "grad_norm": 0.006219211034476757,
      "learning_rate": 1.5116190476190478e-05,
      "loss": 0.0912,
      "step": 12820
    },
    {
      "epoch": 3.6657142857142855,
      "grad_norm": 0.0010765927145257592,
      "learning_rate": 1.5112380952380954e-05,
      "loss": 0.0005,
      "step": 12830
    },
    {
      "epoch": 3.6685714285714286,
      "grad_norm": 0.007279318291693926,
      "learning_rate": 1.5108571428571431e-05,
      "loss": 0.0493,
      "step": 12840
    },
    {
      "epoch": 3.6714285714285713,
      "grad_norm": 0.01049291156232357,
      "learning_rate": 1.5104761904761907e-05,
      "loss": 0.1991,
      "step": 12850
    },
    {
      "epoch": 3.6742857142857144,
      "grad_norm": 0.007632419932633638,
      "learning_rate": 1.5100952380952382e-05,
      "loss": 0.0001,
      "step": 12860
    },
    {
      "epoch": 3.677142857142857,
      "grad_norm": 0.024958813562989235,
      "learning_rate": 1.509714285714286e-05,
      "loss": 0.0001,
      "step": 12870
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.011477097868919373,
      "learning_rate": 1.5093333333333335e-05,
      "loss": 0.0004,
      "step": 12880
    },
    {
      "epoch": 3.682857142857143,
      "grad_norm": 33.247459411621094,
      "learning_rate": 1.5089523809523812e-05,
      "loss": 0.0999,
      "step": 12890
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 0.0007870867266319692,
      "learning_rate": 1.5085714285714288e-05,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 3.6885714285714286,
      "grad_norm": 0.001172802527435124,
      "learning_rate": 1.5081904761904762e-05,
      "loss": 0.0023,
      "step": 12910
    },
    {
      "epoch": 3.6914285714285713,
      "grad_norm": 0.003168570576235652,
      "learning_rate": 1.5078095238095239e-05,
      "loss": 0.0,
      "step": 12920
    },
    {
      "epoch": 3.6942857142857144,
      "grad_norm": 0.00012550799874588847,
      "learning_rate": 1.5074285714285715e-05,
      "loss": 0.0,
      "step": 12930
    },
    {
      "epoch": 3.697142857142857,
      "grad_norm": 0.002244157250970602,
      "learning_rate": 1.507047619047619e-05,
      "loss": 0.1025,
      "step": 12940
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.014744414016604424,
      "learning_rate": 1.5066666666666668e-05,
      "loss": 0.0967,
      "step": 12950
    },
    {
      "epoch": 3.702857142857143,
      "grad_norm": 0.00025087938411161304,
      "learning_rate": 1.5062857142857143e-05,
      "loss": 0.0001,
      "step": 12960
    },
    {
      "epoch": 3.7057142857142855,
      "grad_norm": 0.005547600332647562,
      "learning_rate": 1.505904761904762e-05,
      "loss": 0.0001,
      "step": 12970
    },
    {
      "epoch": 3.7085714285714286,
      "grad_norm": 0.0024188237730413675,
      "learning_rate": 1.5055238095238096e-05,
      "loss": 0.0001,
      "step": 12980
    },
    {
      "epoch": 3.7114285714285713,
      "grad_norm": 0.0005080514238215983,
      "learning_rate": 1.5051428571428572e-05,
      "loss": 0.1816,
      "step": 12990
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.023680469021201134,
      "learning_rate": 1.5047619047619049e-05,
      "loss": 0.0003,
      "step": 13000
    },
    {
      "epoch": 3.717142857142857,
      "grad_norm": 0.005441881716251373,
      "learning_rate": 1.5043809523809524e-05,
      "loss": 0.0001,
      "step": 13010
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.009331930428743362,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.0029,
      "step": 13020
    },
    {
      "epoch": 3.722857142857143,
      "grad_norm": 0.004564724862575531,
      "learning_rate": 1.5036190476190477e-05,
      "loss": 0.0002,
      "step": 13030
    },
    {
      "epoch": 3.725714285714286,
      "grad_norm": 19.054981231689453,
      "learning_rate": 1.5032380952380955e-05,
      "loss": 0.1493,
      "step": 13040
    },
    {
      "epoch": 3.7285714285714286,
      "grad_norm": 0.04928746074438095,
      "learning_rate": 1.502857142857143e-05,
      "loss": 0.2096,
      "step": 13050
    },
    {
      "epoch": 3.7314285714285713,
      "grad_norm": 0.009280216880142689,
      "learning_rate": 1.5024761904761906e-05,
      "loss": 0.1302,
      "step": 13060
    },
    {
      "epoch": 3.7342857142857144,
      "grad_norm": 0.0017920939717441797,
      "learning_rate": 1.5020952380952383e-05,
      "loss": 0.0006,
      "step": 13070
    },
    {
      "epoch": 3.737142857142857,
      "grad_norm": 0.008462806232273579,
      "learning_rate": 1.5017142857142859e-05,
      "loss": 0.0003,
      "step": 13080
    },
    {
      "epoch": 3.74,
      "grad_norm": 71.91862487792969,
      "learning_rate": 1.5013333333333336e-05,
      "loss": 0.154,
      "step": 13090
    },
    {
      "epoch": 3.742857142857143,
      "grad_norm": 9.149186134338379,
      "learning_rate": 1.5009523809523811e-05,
      "loss": 0.1077,
      "step": 13100
    },
    {
      "epoch": 3.7457142857142856,
      "grad_norm": 0.04395991191267967,
      "learning_rate": 1.5005714285714289e-05,
      "loss": 0.2386,
      "step": 13110
    },
    {
      "epoch": 3.7485714285714287,
      "grad_norm": 0.061788883060216904,
      "learning_rate": 1.5001904761904764e-05,
      "loss": 0.0002,
      "step": 13120
    },
    {
      "epoch": 3.7514285714285713,
      "grad_norm": 0.02017263136804104,
      "learning_rate": 1.4998095238095238e-05,
      "loss": 0.0048,
      "step": 13130
    },
    {
      "epoch": 3.7542857142857144,
      "grad_norm": 0.02980457805097103,
      "learning_rate": 1.4994285714285714e-05,
      "loss": 0.1815,
      "step": 13140
    },
    {
      "epoch": 3.757142857142857,
      "grad_norm": 16.01209831237793,
      "learning_rate": 1.4990476190476191e-05,
      "loss": 0.0059,
      "step": 13150
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.020129213109612465,
      "learning_rate": 1.4986666666666667e-05,
      "loss": 0.0003,
      "step": 13160
    },
    {
      "epoch": 3.762857142857143,
      "grad_norm": 0.0046419850550591946,
      "learning_rate": 1.4982857142857144e-05,
      "loss": 0.0005,
      "step": 13170
    },
    {
      "epoch": 3.7657142857142856,
      "grad_norm": 0.0013578743673861027,
      "learning_rate": 1.497904761904762e-05,
      "loss": 0.0002,
      "step": 13180
    },
    {
      "epoch": 3.7685714285714287,
      "grad_norm": 7.479216575622559,
      "learning_rate": 1.4975238095238097e-05,
      "loss": 0.1119,
      "step": 13190
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 0.0018095191335305572,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.1998,
      "step": 13200
    },
    {
      "epoch": 3.774285714285714,
      "grad_norm": 0.0010496529284864664,
      "learning_rate": 1.4967619047619048e-05,
      "loss": 0.0002,
      "step": 13210
    },
    {
      "epoch": 3.777142857142857,
      "grad_norm": 0.0029734685085713863,
      "learning_rate": 1.4963809523809525e-05,
      "loss": 0.0032,
      "step": 13220
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 0.0027770595625042915,
      "learning_rate": 1.496e-05,
      "loss": 0.2391,
      "step": 13230
    },
    {
      "epoch": 3.782857142857143,
      "grad_norm": 0.024608558043837547,
      "learning_rate": 1.4956190476190478e-05,
      "loss": 0.0001,
      "step": 13240
    },
    {
      "epoch": 3.7857142857142856,
      "grad_norm": 0.009710625745356083,
      "learning_rate": 1.4952380952380954e-05,
      "loss": 0.0011,
      "step": 13250
    },
    {
      "epoch": 3.7885714285714287,
      "grad_norm": 0.00318076740950346,
      "learning_rate": 1.4948571428571431e-05,
      "loss": 0.0,
      "step": 13260
    },
    {
      "epoch": 3.7914285714285714,
      "grad_norm": 0.1968774050474167,
      "learning_rate": 1.4944761904761906e-05,
      "loss": 0.0002,
      "step": 13270
    },
    {
      "epoch": 3.7942857142857145,
      "grad_norm": 0.0007450648699887097,
      "learning_rate": 1.4940952380952382e-05,
      "loss": 0.0,
      "step": 13280
    },
    {
      "epoch": 3.797142857142857,
      "grad_norm": 0.006505350116640329,
      "learning_rate": 1.493714285714286e-05,
      "loss": 0.0043,
      "step": 13290
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.00039821292739361525,
      "learning_rate": 1.4933333333333335e-05,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 3.802857142857143,
      "grad_norm": 0.0006880713626742363,
      "learning_rate": 1.4929523809523812e-05,
      "loss": 0.0001,
      "step": 13310
    },
    {
      "epoch": 3.8057142857142856,
      "grad_norm": 0.0017603762680664659,
      "learning_rate": 1.4925714285714288e-05,
      "loss": 0.0024,
      "step": 13320
    },
    {
      "epoch": 3.8085714285714287,
      "grad_norm": 0.0015749664744362235,
      "learning_rate": 1.4921904761904763e-05,
      "loss": 0.0004,
      "step": 13330
    },
    {
      "epoch": 3.8114285714285714,
      "grad_norm": 0.000734786968678236,
      "learning_rate": 1.491809523809524e-05,
      "loss": 0.5969,
      "step": 13340
    },
    {
      "epoch": 3.814285714285714,
      "grad_norm": 0.017875710502266884,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.0002,
      "step": 13350
    },
    {
      "epoch": 3.817142857142857,
      "grad_norm": 0.026846420019865036,
      "learning_rate": 1.491047619047619e-05,
      "loss": 0.0002,
      "step": 13360
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.0012930152006447315,
      "learning_rate": 1.4906666666666667e-05,
      "loss": 0.0001,
      "step": 13370
    },
    {
      "epoch": 3.822857142857143,
      "grad_norm": 0.0025732149370014668,
      "learning_rate": 1.4902857142857143e-05,
      "loss": 0.1019,
      "step": 13380
    },
    {
      "epoch": 3.8257142857142856,
      "grad_norm": 0.0008447054424323142,
      "learning_rate": 1.489904761904762e-05,
      "loss": 0.0001,
      "step": 13390
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 0.0011631976813077927,
      "learning_rate": 1.4895238095238096e-05,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 3.8314285714285714,
      "grad_norm": 0.0030925492756068707,
      "learning_rate": 1.4891428571428571e-05,
      "loss": 0.001,
      "step": 13410
    },
    {
      "epoch": 3.8342857142857145,
      "grad_norm": 0.006459285970777273,
      "learning_rate": 1.4887619047619049e-05,
      "loss": 0.0,
      "step": 13420
    },
    {
      "epoch": 3.837142857142857,
      "grad_norm": 0.09335832297801971,
      "learning_rate": 1.4883809523809524e-05,
      "loss": 0.1955,
      "step": 13430
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.0041490173898637295,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 0.1664,
      "step": 13440
    },
    {
      "epoch": 3.842857142857143,
      "grad_norm": 0.0006676892517134547,
      "learning_rate": 1.4876190476190477e-05,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 3.8457142857142856,
      "grad_norm": 0.01703513413667679,
      "learning_rate": 1.4872380952380954e-05,
      "loss": 0.0003,
      "step": 13460
    },
    {
      "epoch": 3.8485714285714288,
      "grad_norm": 0.0007582299294881523,
      "learning_rate": 1.486857142857143e-05,
      "loss": 0.0005,
      "step": 13470
    },
    {
      "epoch": 3.8514285714285714,
      "grad_norm": 0.0007261540158651769,
      "learning_rate": 1.4864761904761906e-05,
      "loss": 0.0001,
      "step": 13480
    },
    {
      "epoch": 3.854285714285714,
      "grad_norm": 0.0006310861790552735,
      "learning_rate": 1.4860952380952383e-05,
      "loss": 0.0,
      "step": 13490
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 20.654277801513672,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.1576,
      "step": 13500
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.0015251543372869492,
      "learning_rate": 1.4853333333333336e-05,
      "loss": 0.0,
      "step": 13510
    },
    {
      "epoch": 3.862857142857143,
      "grad_norm": 0.01371068600565195,
      "learning_rate": 1.4849523809523811e-05,
      "loss": 0.0002,
      "step": 13520
    },
    {
      "epoch": 3.8657142857142857,
      "grad_norm": 0.002226593904197216,
      "learning_rate": 1.4845714285714289e-05,
      "loss": 0.1673,
      "step": 13530
    },
    {
      "epoch": 3.8685714285714283,
      "grad_norm": 18.97934341430664,
      "learning_rate": 1.4841904761904764e-05,
      "loss": 0.3073,
      "step": 13540
    },
    {
      "epoch": 3.8714285714285714,
      "grad_norm": 54.57352066040039,
      "learning_rate": 1.483809523809524e-05,
      "loss": 0.0163,
      "step": 13550
    },
    {
      "epoch": 3.8742857142857146,
      "grad_norm": 0.0408443883061409,
      "learning_rate": 1.4834285714285714e-05,
      "loss": 0.0004,
      "step": 13560
    },
    {
      "epoch": 3.8771428571428572,
      "grad_norm": 0.014553425833582878,
      "learning_rate": 1.4830476190476191e-05,
      "loss": 0.0008,
      "step": 13570
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.011604182422161102,
      "learning_rate": 1.4826666666666666e-05,
      "loss": 0.0006,
      "step": 13580
    },
    {
      "epoch": 3.882857142857143,
      "grad_norm": 0.004891776479780674,
      "learning_rate": 1.4822857142857144e-05,
      "loss": 0.0002,
      "step": 13590
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 0.008225268684327602,
      "learning_rate": 1.481904761904762e-05,
      "loss": 0.0539,
      "step": 13600
    },
    {
      "epoch": 3.888571428571429,
      "grad_norm": 0.0009561971528455615,
      "learning_rate": 1.4815238095238097e-05,
      "loss": 0.0001,
      "step": 13610
    },
    {
      "epoch": 3.8914285714285715,
      "grad_norm": 0.0009869049536064267,
      "learning_rate": 1.4811428571428572e-05,
      "loss": 0.1701,
      "step": 13620
    },
    {
      "epoch": 3.894285714285714,
      "grad_norm": 0.010249309241771698,
      "learning_rate": 1.4807619047619048e-05,
      "loss": 0.0,
      "step": 13630
    },
    {
      "epoch": 3.8971428571428572,
      "grad_norm": 40.902992248535156,
      "learning_rate": 1.4803809523809525e-05,
      "loss": 0.4648,
      "step": 13640
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.005505185108631849,
      "learning_rate": 1.48e-05,
      "loss": 0.0001,
      "step": 13650
    },
    {
      "epoch": 3.902857142857143,
      "grad_norm": 0.011000752449035645,
      "learning_rate": 1.4796190476190478e-05,
      "loss": 0.0003,
      "step": 13660
    },
    {
      "epoch": 3.9057142857142857,
      "grad_norm": 95.09706115722656,
      "learning_rate": 1.4792380952380953e-05,
      "loss": 0.2176,
      "step": 13670
    },
    {
      "epoch": 3.9085714285714284,
      "grad_norm": 0.008663144893944263,
      "learning_rate": 1.478857142857143e-05,
      "loss": 0.0005,
      "step": 13680
    },
    {
      "epoch": 3.9114285714285715,
      "grad_norm": 0.005626996047794819,
      "learning_rate": 1.4784761904761906e-05,
      "loss": 0.0002,
      "step": 13690
    },
    {
      "epoch": 3.914285714285714,
      "grad_norm": 0.006649651098996401,
      "learning_rate": 1.4780952380952382e-05,
      "loss": 0.0001,
      "step": 13700
    },
    {
      "epoch": 3.9171428571428573,
      "grad_norm": 0.0025528455153107643,
      "learning_rate": 1.477714285714286e-05,
      "loss": 0.0001,
      "step": 13710
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.012508033774793148,
      "learning_rate": 1.4773333333333335e-05,
      "loss": 0.1165,
      "step": 13720
    },
    {
      "epoch": 3.9228571428571426,
      "grad_norm": 0.003139234147965908,
      "learning_rate": 1.4769523809523812e-05,
      "loss": 0.0003,
      "step": 13730
    },
    {
      "epoch": 3.9257142857142857,
      "grad_norm": 0.0008531622588634491,
      "learning_rate": 1.4765714285714288e-05,
      "loss": 0.2156,
      "step": 13740
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 0.11578201502561569,
      "learning_rate": 1.4761904761904763e-05,
      "loss": 0.0001,
      "step": 13750
    },
    {
      "epoch": 3.9314285714285715,
      "grad_norm": 0.0018174053402617574,
      "learning_rate": 1.475809523809524e-05,
      "loss": 0.0003,
      "step": 13760
    },
    {
      "epoch": 3.934285714285714,
      "grad_norm": 0.0038993831258267164,
      "learning_rate": 1.4754285714285716e-05,
      "loss": 0.1102,
      "step": 13770
    },
    {
      "epoch": 3.9371428571428573,
      "grad_norm": 0.0016556958435103297,
      "learning_rate": 1.475047619047619e-05,
      "loss": 0.0514,
      "step": 13780
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.0006881598383188248,
      "learning_rate": 1.4746666666666667e-05,
      "loss": 0.0001,
      "step": 13790
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 0.0037653257604688406,
      "learning_rate": 1.4742857142857143e-05,
      "loss": 0.0001,
      "step": 13800
    },
    {
      "epoch": 3.9457142857142857,
      "grad_norm": 0.0017119956901296973,
      "learning_rate": 1.473904761904762e-05,
      "loss": 0.0001,
      "step": 13810
    },
    {
      "epoch": 3.9485714285714284,
      "grad_norm": 0.002385130152106285,
      "learning_rate": 1.4735238095238096e-05,
      "loss": 0.0001,
      "step": 13820
    },
    {
      "epoch": 3.9514285714285715,
      "grad_norm": 0.0015509696677327156,
      "learning_rate": 1.4731428571428571e-05,
      "loss": 0.0001,
      "step": 13830
    },
    {
      "epoch": 3.954285714285714,
      "grad_norm": 0.0006030852673575282,
      "learning_rate": 1.4727619047619049e-05,
      "loss": 0.0036,
      "step": 13840
    },
    {
      "epoch": 3.9571428571428573,
      "grad_norm": 0.004975319840013981,
      "learning_rate": 1.4723809523809524e-05,
      "loss": 0.2574,
      "step": 13850
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.0029806906823068857,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.0001,
      "step": 13860
    },
    {
      "epoch": 3.9628571428571426,
      "grad_norm": 0.005721914581954479,
      "learning_rate": 1.4716190476190477e-05,
      "loss": 0.0002,
      "step": 13870
    },
    {
      "epoch": 3.9657142857142857,
      "grad_norm": 0.003025889629498124,
      "learning_rate": 1.4712380952380954e-05,
      "loss": 0.0001,
      "step": 13880
    },
    {
      "epoch": 3.9685714285714284,
      "grad_norm": 0.004528330639004707,
      "learning_rate": 1.470857142857143e-05,
      "loss": 0.0002,
      "step": 13890
    },
    {
      "epoch": 3.9714285714285715,
      "grad_norm": 1.1221508979797363,
      "learning_rate": 1.4704761904761905e-05,
      "loss": 0.3619,
      "step": 13900
    },
    {
      "epoch": 3.974285714285714,
      "grad_norm": 1.362126350402832,
      "learning_rate": 1.4700952380952383e-05,
      "loss": 0.2825,
      "step": 13910
    },
    {
      "epoch": 3.977142857142857,
      "grad_norm": 0.03925500437617302,
      "learning_rate": 1.4697142857142858e-05,
      "loss": 0.0006,
      "step": 13920
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.030002186074852943,
      "learning_rate": 1.4693333333333336e-05,
      "loss": 0.1388,
      "step": 13930
    },
    {
      "epoch": 3.982857142857143,
      "grad_norm": 0.044275909662246704,
      "learning_rate": 1.4689523809523811e-05,
      "loss": 0.0007,
      "step": 13940
    },
    {
      "epoch": 3.9857142857142858,
      "grad_norm": 0.005300415679812431,
      "learning_rate": 1.4685714285714288e-05,
      "loss": 0.0002,
      "step": 13950
    },
    {
      "epoch": 3.9885714285714284,
      "grad_norm": 0.002713889582082629,
      "learning_rate": 1.4681904761904764e-05,
      "loss": 0.0002,
      "step": 13960
    },
    {
      "epoch": 3.9914285714285715,
      "grad_norm": 0.0005442556575872004,
      "learning_rate": 1.467809523809524e-05,
      "loss": 0.0001,
      "step": 13970
    },
    {
      "epoch": 3.994285714285714,
      "grad_norm": 0.0004387392837088555,
      "learning_rate": 1.4674285714285717e-05,
      "loss": 0.0,
      "step": 13980
    },
    {
      "epoch": 3.9971428571428573,
      "grad_norm": 31.11857032775879,
      "learning_rate": 1.4670476190476192e-05,
      "loss": 0.1556,
      "step": 13990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.0009655470494180918,
      "learning_rate": 1.4666666666666666e-05,
      "loss": 0.0002,
      "step": 14000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9783333333333334,
      "eval_f1": 0.8608137044967881,
      "eval_loss": 0.1615777611732483,
      "eval_precision": 0.9436619718309859,
      "eval_recall": 0.7913385826771654,
      "eval_runtime": 259.021,
      "eval_samples_per_second": 11.582,
      "eval_steps_per_second": 2.896,
      "step": 14000
    },
    {
      "epoch": 4.002857142857143,
      "grad_norm": 0.0003234033356420696,
      "learning_rate": 1.4662857142857144e-05,
      "loss": 0.0,
      "step": 14010
    },
    {
      "epoch": 4.005714285714285,
      "grad_norm": 0.002573433332145214,
      "learning_rate": 1.4659047619047619e-05,
      "loss": 0.0001,
      "step": 14020
    },
    {
      "epoch": 4.008571428571429,
      "grad_norm": 0.004166288301348686,
      "learning_rate": 1.4655238095238096e-05,
      "loss": 0.1682,
      "step": 14030
    },
    {
      "epoch": 4.011428571428572,
      "grad_norm": 0.010146811604499817,
      "learning_rate": 1.4651428571428572e-05,
      "loss": 0.0008,
      "step": 14040
    },
    {
      "epoch": 4.014285714285714,
      "grad_norm": 0.0032416151370853186,
      "learning_rate": 1.4647619047619048e-05,
      "loss": 0.0891,
      "step": 14050
    },
    {
      "epoch": 4.017142857142857,
      "grad_norm": 0.00441389437764883,
      "learning_rate": 1.4643809523809525e-05,
      "loss": 0.0008,
      "step": 14060
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.0006788949831388891,
      "learning_rate": 1.464e-05,
      "loss": 0.0002,
      "step": 14070
    },
    {
      "epoch": 4.022857142857143,
      "grad_norm": 0.007969009689986706,
      "learning_rate": 1.4636190476190478e-05,
      "loss": 0.0002,
      "step": 14080
    },
    {
      "epoch": 4.025714285714286,
      "grad_norm": 0.0005542903672903776,
      "learning_rate": 1.4632380952380953e-05,
      "loss": 0.0002,
      "step": 14090
    },
    {
      "epoch": 4.0285714285714285,
      "grad_norm": 0.0002768757694866508,
      "learning_rate": 1.462857142857143e-05,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 4.031428571428571,
      "grad_norm": 0.0016709950286895037,
      "learning_rate": 1.4624761904761906e-05,
      "loss": 0.1577,
      "step": 14110
    },
    {
      "epoch": 4.034285714285715,
      "grad_norm": 0.0030645043589174747,
      "learning_rate": 1.4620952380952382e-05,
      "loss": 0.0002,
      "step": 14120
    },
    {
      "epoch": 4.037142857142857,
      "grad_norm": 0.0028918804600834846,
      "learning_rate": 1.4617142857142859e-05,
      "loss": 0.0326,
      "step": 14130
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.029971513897180557,
      "learning_rate": 1.4613333333333335e-05,
      "loss": 0.0183,
      "step": 14140
    },
    {
      "epoch": 4.042857142857143,
      "grad_norm": 5.633100590785034e-05,
      "learning_rate": 1.4609523809523812e-05,
      "loss": 0.0001,
      "step": 14150
    },
    {
      "epoch": 4.045714285714285,
      "grad_norm": 0.0001087079945136793,
      "learning_rate": 1.4605714285714287e-05,
      "loss": 0.1459,
      "step": 14160
    },
    {
      "epoch": 4.048571428571429,
      "grad_norm": 0.0003092168481089175,
      "learning_rate": 1.4601904761904763e-05,
      "loss": 0.1516,
      "step": 14170
    },
    {
      "epoch": 4.051428571428572,
      "grad_norm": 0.00019912382413167506,
      "learning_rate": 1.459809523809524e-05,
      "loss": 0.0005,
      "step": 14180
    },
    {
      "epoch": 4.054285714285714,
      "grad_norm": 0.059188343584537506,
      "learning_rate": 1.4594285714285716e-05,
      "loss": 0.0003,
      "step": 14190
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 0.017279690131545067,
      "learning_rate": 1.4590476190476193e-05,
      "loss": 0.0001,
      "step": 14200
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.002610389608889818,
      "learning_rate": 1.4586666666666667e-05,
      "loss": 0.1327,
      "step": 14210
    },
    {
      "epoch": 4.062857142857143,
      "grad_norm": 0.001983574591577053,
      "learning_rate": 1.4582857142857143e-05,
      "loss": 0.0,
      "step": 14220
    },
    {
      "epoch": 4.065714285714286,
      "grad_norm": 0.00014910442405380309,
      "learning_rate": 1.457904761904762e-05,
      "loss": 0.0003,
      "step": 14230
    },
    {
      "epoch": 4.0685714285714285,
      "grad_norm": 0.0004129087901674211,
      "learning_rate": 1.4575238095238095e-05,
      "loss": 0.0155,
      "step": 14240
    },
    {
      "epoch": 4.071428571428571,
      "grad_norm": 0.0008800852228887379,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.0001,
      "step": 14250
    },
    {
      "epoch": 4.074285714285715,
      "grad_norm": 0.01782025583088398,
      "learning_rate": 1.4567619047619048e-05,
      "loss": 0.0001,
      "step": 14260
    },
    {
      "epoch": 4.077142857142857,
      "grad_norm": 0.00041512754978612065,
      "learning_rate": 1.4563809523809524e-05,
      "loss": 0.0,
      "step": 14270
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.0001158378945547156,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.0,
      "step": 14280
    },
    {
      "epoch": 4.082857142857143,
      "grad_norm": 0.0005862477701157331,
      "learning_rate": 1.4556190476190477e-05,
      "loss": 0.0,
      "step": 14290
    },
    {
      "epoch": 4.085714285714285,
      "grad_norm": 0.00012022912414977327,
      "learning_rate": 1.4552380952380954e-05,
      "loss": 0.1468,
      "step": 14300
    },
    {
      "epoch": 4.088571428571429,
      "grad_norm": 0.0003436828847043216,
      "learning_rate": 1.454857142857143e-05,
      "loss": 0.0001,
      "step": 14310
    },
    {
      "epoch": 4.091428571428572,
      "grad_norm": 0.005999938119202852,
      "learning_rate": 1.4544761904761905e-05,
      "loss": 0.1827,
      "step": 14320
    },
    {
      "epoch": 4.094285714285714,
      "grad_norm": 0.0073040202260017395,
      "learning_rate": 1.4540952380952383e-05,
      "loss": 0.0,
      "step": 14330
    },
    {
      "epoch": 4.097142857142857,
      "grad_norm": 0.00012055789557052776,
      "learning_rate": 1.4537142857142858e-05,
      "loss": 0.0007,
      "step": 14340
    },
    {
      "epoch": 4.1,
      "grad_norm": 3.5943328839493915e-05,
      "learning_rate": 1.4533333333333335e-05,
      "loss": 0.0001,
      "step": 14350
    },
    {
      "epoch": 4.102857142857143,
      "grad_norm": 0.00011805442773038521,
      "learning_rate": 1.4529523809523811e-05,
      "loss": 0.0001,
      "step": 14360
    },
    {
      "epoch": 4.105714285714286,
      "grad_norm": 21.00775718688965,
      "learning_rate": 1.4525714285714288e-05,
      "loss": 0.0984,
      "step": 14370
    },
    {
      "epoch": 4.1085714285714285,
      "grad_norm": 0.001152919139713049,
      "learning_rate": 1.4521904761904764e-05,
      "loss": 0.0,
      "step": 14380
    },
    {
      "epoch": 4.111428571428571,
      "grad_norm": 6.181989738252014e-05,
      "learning_rate": 1.451809523809524e-05,
      "loss": 0.0,
      "step": 14390
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 0.0005622218013741076,
      "learning_rate": 1.4514285714285717e-05,
      "loss": 0.0143,
      "step": 14400
    },
    {
      "epoch": 4.117142857142857,
      "grad_norm": 0.00019716983661055565,
      "learning_rate": 1.4510476190476192e-05,
      "loss": 0.0,
      "step": 14410
    },
    {
      "epoch": 4.12,
      "grad_norm": 3.583576835808344e-05,
      "learning_rate": 1.450666666666667e-05,
      "loss": 0.0071,
      "step": 14420
    },
    {
      "epoch": 4.122857142857143,
      "grad_norm": 0.00014298614405561239,
      "learning_rate": 1.4502857142857143e-05,
      "loss": 0.0001,
      "step": 14430
    },
    {
      "epoch": 4.1257142857142854,
      "grad_norm": 6.11203649896197e-05,
      "learning_rate": 1.4499047619047619e-05,
      "loss": 0.0,
      "step": 14440
    },
    {
      "epoch": 4.128571428571428,
      "grad_norm": 4.80471171613317e-05,
      "learning_rate": 1.4495238095238096e-05,
      "loss": 0.0,
      "step": 14450
    },
    {
      "epoch": 4.131428571428572,
      "grad_norm": 0.00021806653239764273,
      "learning_rate": 1.4491428571428572e-05,
      "loss": 0.0002,
      "step": 14460
    },
    {
      "epoch": 4.134285714285714,
      "grad_norm": 1.5940002413117327e-05,
      "learning_rate": 1.4487619047619047e-05,
      "loss": 0.0,
      "step": 14470
    },
    {
      "epoch": 4.137142857142857,
      "grad_norm": 0.00036352654569782317,
      "learning_rate": 1.4483809523809525e-05,
      "loss": 0.0,
      "step": 14480
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.00842318031936884,
      "learning_rate": 1.448e-05,
      "loss": 0.0066,
      "step": 14490
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 0.011633221060037613,
      "learning_rate": 1.4476190476190478e-05,
      "loss": 0.0,
      "step": 14500
    },
    {
      "epoch": 4.145714285714286,
      "grad_norm": 6.531632971018553e-05,
      "learning_rate": 1.4472380952380953e-05,
      "loss": 0.0,
      "step": 14510
    },
    {
      "epoch": 4.148571428571429,
      "grad_norm": 0.0014243752229958773,
      "learning_rate": 1.446857142857143e-05,
      "loss": 0.0,
      "step": 14520
    },
    {
      "epoch": 4.151428571428571,
      "grad_norm": 0.0004763973702210933,
      "learning_rate": 1.4464761904761906e-05,
      "loss": 0.0005,
      "step": 14530
    },
    {
      "epoch": 4.154285714285714,
      "grad_norm": 0.00010867474338738248,
      "learning_rate": 1.4460952380952382e-05,
      "loss": 0.0,
      "step": 14540
    },
    {
      "epoch": 4.1571428571428575,
      "grad_norm": 3.1308965844800696e-05,
      "learning_rate": 1.4457142857142859e-05,
      "loss": 0.0,
      "step": 14550
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.6423238776042126e-05,
      "learning_rate": 1.4453333333333334e-05,
      "loss": 0.4777,
      "step": 14560
    },
    {
      "epoch": 4.162857142857143,
      "grad_norm": 2.641323590069078e-05,
      "learning_rate": 1.4449523809523812e-05,
      "loss": 0.0617,
      "step": 14570
    },
    {
      "epoch": 4.1657142857142855,
      "grad_norm": 2.997292176587507e-05,
      "learning_rate": 1.4445714285714287e-05,
      "loss": 0.0,
      "step": 14580
    },
    {
      "epoch": 4.168571428571428,
      "grad_norm": 0.003972500562667847,
      "learning_rate": 1.4441904761904763e-05,
      "loss": 0.0,
      "step": 14590
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 0.1056879386305809,
      "learning_rate": 1.443809523809524e-05,
      "loss": 0.1046,
      "step": 14600
    },
    {
      "epoch": 4.174285714285714,
      "grad_norm": 0.05894382297992706,
      "learning_rate": 1.4434285714285716e-05,
      "loss": 0.0131,
      "step": 14610
    },
    {
      "epoch": 4.177142857142857,
      "grad_norm": 3.074625419685617e-05,
      "learning_rate": 1.4430476190476193e-05,
      "loss": 0.0,
      "step": 14620
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.0057028960436582565,
      "learning_rate": 1.4426666666666669e-05,
      "loss": 0.0,
      "step": 14630
    },
    {
      "epoch": 4.182857142857143,
      "grad_norm": 2.2650154278380796e-05,
      "learning_rate": 1.4422857142857146e-05,
      "loss": 0.0,
      "step": 14640
    },
    {
      "epoch": 4.185714285714286,
      "grad_norm": 1.712002995191142e-05,
      "learning_rate": 1.441904761904762e-05,
      "loss": 0.0004,
      "step": 14650
    },
    {
      "epoch": 4.188571428571429,
      "grad_norm": 1.2866600627603475e-05,
      "learning_rate": 1.4415238095238095e-05,
      "loss": 0.0,
      "step": 14660
    },
    {
      "epoch": 4.191428571428571,
      "grad_norm": 4.957874261890538e-05,
      "learning_rate": 1.4411428571428573e-05,
      "loss": 0.0492,
      "step": 14670
    },
    {
      "epoch": 4.194285714285714,
      "grad_norm": 0.00012920664448756725,
      "learning_rate": 1.4407619047619048e-05,
      "loss": 0.2203,
      "step": 14680
    },
    {
      "epoch": 4.1971428571428575,
      "grad_norm": 8.132216316880658e-05,
      "learning_rate": 1.4403809523809524e-05,
      "loss": 0.3053,
      "step": 14690
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.002494867192581296,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 4.202857142857143,
      "grad_norm": 0.0018112726975232363,
      "learning_rate": 1.4396190476190477e-05,
      "loss": 0.0002,
      "step": 14710
    },
    {
      "epoch": 4.2057142857142855,
      "grad_norm": 0.021529993042349815,
      "learning_rate": 1.4392380952380954e-05,
      "loss": 0.075,
      "step": 14720
    },
    {
      "epoch": 4.208571428571428,
      "grad_norm": 0.015805048868060112,
      "learning_rate": 1.438857142857143e-05,
      "loss": 0.0001,
      "step": 14730
    },
    {
      "epoch": 4.211428571428572,
      "grad_norm": 0.0025914045982062817,
      "learning_rate": 1.4384761904761905e-05,
      "loss": 0.0001,
      "step": 14740
    },
    {
      "epoch": 4.214285714285714,
      "grad_norm": 0.004972303286194801,
      "learning_rate": 1.4380952380952382e-05,
      "loss": 0.0002,
      "step": 14750
    },
    {
      "epoch": 4.217142857142857,
      "grad_norm": 0.0007599666132591665,
      "learning_rate": 1.4377142857142858e-05,
      "loss": 0.0001,
      "step": 14760
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.0015067426720634103,
      "learning_rate": 1.4373333333333335e-05,
      "loss": 0.0002,
      "step": 14770
    },
    {
      "epoch": 4.222857142857142,
      "grad_norm": 0.051338937133550644,
      "learning_rate": 1.436952380952381e-05,
      "loss": 0.0001,
      "step": 14780
    },
    {
      "epoch": 4.225714285714286,
      "grad_norm": 3.1233808994293213,
      "learning_rate": 1.4365714285714288e-05,
      "loss": 0.0021,
      "step": 14790
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 0.00023586690076626837,
      "learning_rate": 1.4361904761904764e-05,
      "loss": 0.002,
      "step": 14800
    },
    {
      "epoch": 4.231428571428571,
      "grad_norm": 0.00010104548709932715,
      "learning_rate": 1.435809523809524e-05,
      "loss": 0.0,
      "step": 14810
    },
    {
      "epoch": 4.234285714285714,
      "grad_norm": 0.0002634122793097049,
      "learning_rate": 1.4354285714285716e-05,
      "loss": 0.1892,
      "step": 14820
    },
    {
      "epoch": 4.2371428571428575,
      "grad_norm": 0.007935311645269394,
      "learning_rate": 1.4350476190476192e-05,
      "loss": 0.0,
      "step": 14830
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.0005559382261708379,
      "learning_rate": 1.434666666666667e-05,
      "loss": 0.0003,
      "step": 14840
    },
    {
      "epoch": 4.242857142857143,
      "grad_norm": 0.0019835138227790594,
      "learning_rate": 1.4342857142857145e-05,
      "loss": 0.3306,
      "step": 14850
    },
    {
      "epoch": 4.2457142857142856,
      "grad_norm": 0.0019884686917066574,
      "learning_rate": 1.433904761904762e-05,
      "loss": 0.0001,
      "step": 14860
    },
    {
      "epoch": 4.248571428571428,
      "grad_norm": 0.002779858186841011,
      "learning_rate": 1.4335238095238096e-05,
      "loss": 0.0023,
      "step": 14870
    },
    {
      "epoch": 4.251428571428572,
      "grad_norm": 0.004079411271959543,
      "learning_rate": 1.4331428571428572e-05,
      "loss": 0.0001,
      "step": 14880
    },
    {
      "epoch": 4.2542857142857144,
      "grad_norm": 0.002155022229999304,
      "learning_rate": 1.4327619047619047e-05,
      "loss": 0.0001,
      "step": 14890
    },
    {
      "epoch": 4.257142857142857,
      "grad_norm": 0.00036683143116533756,
      "learning_rate": 1.4323809523809525e-05,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.002299884334206581,
      "learning_rate": 1.432e-05,
      "loss": 0.0,
      "step": 14910
    },
    {
      "epoch": 4.2628571428571425,
      "grad_norm": 0.02545085921883583,
      "learning_rate": 1.4316190476190477e-05,
      "loss": 0.1105,
      "step": 14920
    },
    {
      "epoch": 4.265714285714286,
      "grad_norm": 0.006282020825892687,
      "learning_rate": 1.4312380952380953e-05,
      "loss": 0.0001,
      "step": 14930
    },
    {
      "epoch": 4.268571428571429,
      "grad_norm": 0.13182532787322998,
      "learning_rate": 1.430857142857143e-05,
      "loss": 0.0003,
      "step": 14940
    },
    {
      "epoch": 4.271428571428571,
      "grad_norm": 0.0011622841702774167,
      "learning_rate": 1.4304761904761906e-05,
      "loss": 0.0009,
      "step": 14950
    },
    {
      "epoch": 4.274285714285714,
      "grad_norm": 0.00024103511532302946,
      "learning_rate": 1.4300952380952381e-05,
      "loss": 0.0002,
      "step": 14960
    },
    {
      "epoch": 4.277142857142858,
      "grad_norm": 0.0013186747673898935,
      "learning_rate": 1.4297142857142859e-05,
      "loss": 0.0,
      "step": 14970
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.0011445590062066913,
      "learning_rate": 1.4293333333333334e-05,
      "loss": 0.0979,
      "step": 14980
    },
    {
      "epoch": 4.282857142857143,
      "grad_norm": 0.0016100214561447501,
      "learning_rate": 1.4289523809523812e-05,
      "loss": 0.2594,
      "step": 14990
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 1.894162893295288,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.093,
      "step": 15000
    },
    {
      "epoch": 4.288571428571428,
      "grad_norm": 0.0016422412591055036,
      "learning_rate": 1.4281904761904763e-05,
      "loss": 0.3506,
      "step": 15010
    },
    {
      "epoch": 4.291428571428572,
      "grad_norm": 0.00674628559499979,
      "learning_rate": 1.427809523809524e-05,
      "loss": 0.2445,
      "step": 15020
    },
    {
      "epoch": 4.2942857142857145,
      "grad_norm": 0.056126151233911514,
      "learning_rate": 1.4274285714285716e-05,
      "loss": 0.025,
      "step": 15030
    },
    {
      "epoch": 4.297142857142857,
      "grad_norm": 0.03701091185212135,
      "learning_rate": 1.4270476190476193e-05,
      "loss": 0.053,
      "step": 15040
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.00044409549445845187,
      "learning_rate": 1.4266666666666668e-05,
      "loss": 0.0002,
      "step": 15050
    },
    {
      "epoch": 4.3028571428571425,
      "grad_norm": 0.000569372670724988,
      "learning_rate": 1.4262857142857146e-05,
      "loss": 0.0277,
      "step": 15060
    },
    {
      "epoch": 4.305714285714286,
      "grad_norm": 0.0056032221764326096,
      "learning_rate": 1.4259047619047621e-05,
      "loss": 0.0,
      "step": 15070
    },
    {
      "epoch": 4.308571428571429,
      "grad_norm": 0.0002664572966750711,
      "learning_rate": 1.4255238095238095e-05,
      "loss": 0.0328,
      "step": 15080
    },
    {
      "epoch": 4.311428571428571,
      "grad_norm": 17.549989700317383,
      "learning_rate": 1.4251428571428572e-05,
      "loss": 0.1885,
      "step": 15090
    },
    {
      "epoch": 4.314285714285714,
      "grad_norm": 0.0001098557622754015,
      "learning_rate": 1.4247619047619048e-05,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 4.317142857142857,
      "grad_norm": 0.0006035644328221679,
      "learning_rate": 1.4243809523809524e-05,
      "loss": 0.0062,
      "step": 15110
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.0001993626938201487,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.0001,
      "step": 15120
    },
    {
      "epoch": 4.322857142857143,
      "grad_norm": 0.0005468025919981301,
      "learning_rate": 1.4236190476190476e-05,
      "loss": 0.1179,
      "step": 15130
    },
    {
      "epoch": 4.325714285714286,
      "grad_norm": 0.004956122022122145,
      "learning_rate": 1.4232380952380954e-05,
      "loss": 0.0357,
      "step": 15140
    },
    {
      "epoch": 4.328571428571428,
      "grad_norm": 0.01210689265280962,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.009,
      "step": 15150
    },
    {
      "epoch": 4.331428571428571,
      "grad_norm": 0.0023431857116520405,
      "learning_rate": 1.4224761904761905e-05,
      "loss": 0.0001,
      "step": 15160
    },
    {
      "epoch": 4.3342857142857145,
      "grad_norm": 0.0014087415765970945,
      "learning_rate": 1.4220952380952382e-05,
      "loss": 0.1421,
      "step": 15170
    },
    {
      "epoch": 4.337142857142857,
      "grad_norm": 0.0002666723448783159,
      "learning_rate": 1.4217142857142858e-05,
      "loss": 0.0001,
      "step": 15180
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.0008853356121107936,
      "learning_rate": 1.4213333333333335e-05,
      "loss": 0.2933,
      "step": 15190
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 0.003667007200419903,
      "learning_rate": 1.420952380952381e-05,
      "loss": 0.0005,
      "step": 15200
    },
    {
      "epoch": 4.345714285714286,
      "grad_norm": 0.0027116076089441776,
      "learning_rate": 1.4205714285714288e-05,
      "loss": 0.0002,
      "step": 15210
    },
    {
      "epoch": 4.348571428571429,
      "grad_norm": 0.048895277082920074,
      "learning_rate": 1.4201904761904763e-05,
      "loss": 0.0005,
      "step": 15220
    },
    {
      "epoch": 4.351428571428571,
      "grad_norm": 0.002285722177475691,
      "learning_rate": 1.4198095238095239e-05,
      "loss": 0.0001,
      "step": 15230
    },
    {
      "epoch": 4.354285714285714,
      "grad_norm": 0.005429146345704794,
      "learning_rate": 1.4194285714285716e-05,
      "loss": 0.0004,
      "step": 15240
    },
    {
      "epoch": 4.357142857142857,
      "grad_norm": 0.0011236689751967788,
      "learning_rate": 1.4190476190476192e-05,
      "loss": 0.0,
      "step": 15250
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.0013133217580616474,
      "learning_rate": 1.418666666666667e-05,
      "loss": 0.0005,
      "step": 15260
    },
    {
      "epoch": 4.362857142857143,
      "grad_norm": 0.0019370524678379297,
      "learning_rate": 1.4182857142857145e-05,
      "loss": 0.0001,
      "step": 15270
    },
    {
      "epoch": 4.365714285714286,
      "grad_norm": 0.0006300776149146259,
      "learning_rate": 1.417904761904762e-05,
      "loss": 0.0,
      "step": 15280
    },
    {
      "epoch": 4.368571428571428,
      "grad_norm": 0.00043539429316297174,
      "learning_rate": 1.4175238095238098e-05,
      "loss": 0.0037,
      "step": 15290
    },
    {
      "epoch": 4.371428571428572,
      "grad_norm": 0.003512118710204959,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 0.0001,
      "step": 15300
    },
    {
      "epoch": 4.3742857142857146,
      "grad_norm": 0.0018990356475114822,
      "learning_rate": 1.4167619047619047e-05,
      "loss": 0.0001,
      "step": 15310
    },
    {
      "epoch": 4.377142857142857,
      "grad_norm": 0.00023780044284649193,
      "learning_rate": 1.4163809523809524e-05,
      "loss": 0.0,
      "step": 15320
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.0003126053197775036,
      "learning_rate": 1.416e-05,
      "loss": 0.0,
      "step": 15330
    },
    {
      "epoch": 4.382857142857143,
      "grad_norm": 0.0021522934548556805,
      "learning_rate": 1.4156190476190477e-05,
      "loss": 0.0722,
      "step": 15340
    },
    {
      "epoch": 4.385714285714286,
      "grad_norm": 0.0005645627388730645,
      "learning_rate": 1.4152380952380953e-05,
      "loss": 0.0016,
      "step": 15350
    },
    {
      "epoch": 4.388571428571429,
      "grad_norm": 0.0024470638018101454,
      "learning_rate": 1.414857142857143e-05,
      "loss": 0.0,
      "step": 15360
    },
    {
      "epoch": 4.3914285714285715,
      "grad_norm": 0.00042674681753851473,
      "learning_rate": 1.4144761904761906e-05,
      "loss": 0.0002,
      "step": 15370
    },
    {
      "epoch": 4.394285714285714,
      "grad_norm": 0.0005539843696169555,
      "learning_rate": 1.4140952380952381e-05,
      "loss": 0.0001,
      "step": 15380
    },
    {
      "epoch": 4.397142857142857,
      "grad_norm": 0.0013306151377037168,
      "learning_rate": 1.4137142857142859e-05,
      "loss": 0.0,
      "step": 15390
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.00014007333084009588,
      "learning_rate": 1.4133333333333334e-05,
      "loss": 0.0017,
      "step": 15400
    },
    {
      "epoch": 4.402857142857143,
      "grad_norm": 0.00015639985213056207,
      "learning_rate": 1.4129523809523811e-05,
      "loss": 0.0003,
      "step": 15410
    },
    {
      "epoch": 4.405714285714286,
      "grad_norm": 0.0001248972985194996,
      "learning_rate": 1.4125714285714287e-05,
      "loss": 0.0583,
      "step": 15420
    },
    {
      "epoch": 4.408571428571428,
      "grad_norm": 0.0002787121629808098,
      "learning_rate": 1.4121904761904763e-05,
      "loss": 0.0,
      "step": 15430
    },
    {
      "epoch": 4.411428571428571,
      "grad_norm": 0.0020031374879181385,
      "learning_rate": 1.411809523809524e-05,
      "loss": 0.4356,
      "step": 15440
    },
    {
      "epoch": 4.414285714285715,
      "grad_norm": 0.20906658470630646,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.0002,
      "step": 15450
    },
    {
      "epoch": 4.417142857142857,
      "grad_norm": 0.0007073568995110691,
      "learning_rate": 1.4110476190476193e-05,
      "loss": 0.0,
      "step": 15460
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.0026573603972792625,
      "learning_rate": 1.4106666666666668e-05,
      "loss": 0.0,
      "step": 15470
    },
    {
      "epoch": 4.422857142857143,
      "grad_norm": 0.0027969335205852985,
      "learning_rate": 1.4102857142857146e-05,
      "loss": 0.0004,
      "step": 15480
    },
    {
      "epoch": 4.425714285714285,
      "grad_norm": 0.0017440803349018097,
      "learning_rate": 1.4099047619047621e-05,
      "loss": 0.0,
      "step": 15490
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.0004124683910049498,
      "learning_rate": 1.4095238095238097e-05,
      "loss": 0.0002,
      "step": 15500
    },
    {
      "epoch": 4.4314285714285715,
      "grad_norm": 0.005283910781145096,
      "learning_rate": 1.4091428571428574e-05,
      "loss": 0.0001,
      "step": 15510
    },
    {
      "epoch": 4.434285714285714,
      "grad_norm": 0.0017695521237328649,
      "learning_rate": 1.4087619047619048e-05,
      "loss": 0.0,
      "step": 15520
    },
    {
      "epoch": 4.437142857142857,
      "grad_norm": 0.0004825509968213737,
      "learning_rate": 1.4083809523809523e-05,
      "loss": 0.0,
      "step": 15530
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.002000434324145317,
      "learning_rate": 1.408e-05,
      "loss": 0.0,
      "step": 15540
    },
    {
      "epoch": 4.442857142857143,
      "grad_norm": 0.000335113174514845,
      "learning_rate": 1.4076190476190476e-05,
      "loss": 0.0,
      "step": 15550
    },
    {
      "epoch": 4.445714285714286,
      "grad_norm": 0.00065088109113276,
      "learning_rate": 1.4072380952380954e-05,
      "loss": 0.0,
      "step": 15560
    },
    {
      "epoch": 4.448571428571428,
      "grad_norm": 0.00030287037952803075,
      "learning_rate": 1.406857142857143e-05,
      "loss": 0.1055,
      "step": 15570
    },
    {
      "epoch": 4.451428571428571,
      "grad_norm": 0.0036601389292627573,
      "learning_rate": 1.4064761904761905e-05,
      "loss": 0.0001,
      "step": 15580
    },
    {
      "epoch": 4.454285714285715,
      "grad_norm": 0.0016595220658928156,
      "learning_rate": 1.4060952380952382e-05,
      "loss": 0.0003,
      "step": 15590
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 0.013510880060493946,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.164,
      "step": 15600
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.0005674019921571016,
      "learning_rate": 1.4053333333333335e-05,
      "loss": 0.0,
      "step": 15610
    },
    {
      "epoch": 4.462857142857143,
      "grad_norm": 0.00038160840631462634,
      "learning_rate": 1.404952380952381e-05,
      "loss": 0.0001,
      "step": 15620
    },
    {
      "epoch": 4.465714285714285,
      "grad_norm": 0.0007829393725842237,
      "learning_rate": 1.4045714285714288e-05,
      "loss": 0.1304,
      "step": 15630
    },
    {
      "epoch": 4.468571428571429,
      "grad_norm": 0.0005736526800319552,
      "learning_rate": 1.4041904761904763e-05,
      "loss": 0.0,
      "step": 15640
    },
    {
      "epoch": 4.4714285714285715,
      "grad_norm": 0.00041811555274762213,
      "learning_rate": 1.4038095238095239e-05,
      "loss": 0.015,
      "step": 15650
    },
    {
      "epoch": 4.474285714285714,
      "grad_norm": 0.0007581971003673971,
      "learning_rate": 1.4034285714285716e-05,
      "loss": 0.0001,
      "step": 15660
    },
    {
      "epoch": 4.477142857142857,
      "grad_norm": 0.0030831685289740562,
      "learning_rate": 1.4030476190476192e-05,
      "loss": 0.1358,
      "step": 15670
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.0035230498760938644,
      "learning_rate": 1.4026666666666669e-05,
      "loss": 0.0022,
      "step": 15680
    },
    {
      "epoch": 4.482857142857143,
      "grad_norm": 0.00125501852016896,
      "learning_rate": 1.4022857142857145e-05,
      "loss": 0.1693,
      "step": 15690
    },
    {
      "epoch": 4.485714285714286,
      "grad_norm": 0.027317170053720474,
      "learning_rate": 1.401904761904762e-05,
      "loss": 0.0002,
      "step": 15700
    },
    {
      "epoch": 4.488571428571428,
      "grad_norm": 4.14564323425293,
      "learning_rate": 1.4015238095238097e-05,
      "loss": 0.0025,
      "step": 15710
    },
    {
      "epoch": 4.491428571428571,
      "grad_norm": 0.00530199334025383,
      "learning_rate": 1.4011428571428573e-05,
      "loss": 0.2624,
      "step": 15720
    },
    {
      "epoch": 4.494285714285715,
      "grad_norm": 0.007290869485586882,
      "learning_rate": 1.4007619047619047e-05,
      "loss": 0.1656,
      "step": 15730
    },
    {
      "epoch": 4.497142857142857,
      "grad_norm": 0.0017740969778969884,
      "learning_rate": 1.4003809523809524e-05,
      "loss": 0.0007,
      "step": 15740
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.0076332115568220615,
      "learning_rate": 1.4e-05,
      "loss": 0.0913,
      "step": 15750
    },
    {
      "epoch": 4.502857142857143,
      "grad_norm": 0.014676310122013092,
      "learning_rate": 1.3996190476190477e-05,
      "loss": 0.0968,
      "step": 15760
    },
    {
      "epoch": 4.505714285714285,
      "grad_norm": 0.07703286409378052,
      "learning_rate": 1.3992380952380953e-05,
      "loss": 0.0006,
      "step": 15770
    },
    {
      "epoch": 4.508571428571429,
      "grad_norm": 0.021466273814439774,
      "learning_rate": 1.398857142857143e-05,
      "loss": 0.0025,
      "step": 15780
    },
    {
      "epoch": 4.511428571428572,
      "grad_norm": 0.0006875268300063908,
      "learning_rate": 1.3984761904761906e-05,
      "loss": 0.0002,
      "step": 15790
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 0.009672058746218681,
      "learning_rate": 1.3980952380952381e-05,
      "loss": 0.0,
      "step": 15800
    },
    {
      "epoch": 4.517142857142857,
      "grad_norm": 0.0005268514505587518,
      "learning_rate": 1.3977142857142858e-05,
      "loss": 0.0,
      "step": 15810
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.00040622917003929615,
      "learning_rate": 1.3973333333333334e-05,
      "loss": 0.2767,
      "step": 15820
    },
    {
      "epoch": 4.522857142857143,
      "grad_norm": 0.005461815744638443,
      "learning_rate": 1.3969523809523811e-05,
      "loss": 0.0318,
      "step": 15830
    },
    {
      "epoch": 4.525714285714286,
      "grad_norm": 0.012129446491599083,
      "learning_rate": 1.3965714285714287e-05,
      "loss": 0.1421,
      "step": 15840
    },
    {
      "epoch": 4.5285714285714285,
      "grad_norm": 0.9472437500953674,
      "learning_rate": 1.3961904761904762e-05,
      "loss": 0.0009,
      "step": 15850
    },
    {
      "epoch": 4.531428571428571,
      "grad_norm": 0.0007747522322461009,
      "learning_rate": 1.395809523809524e-05,
      "loss": 0.0001,
      "step": 15860
    },
    {
      "epoch": 4.534285714285714,
      "grad_norm": 0.0007098320056684315,
      "learning_rate": 1.3954285714285715e-05,
      "loss": 0.0001,
      "step": 15870
    },
    {
      "epoch": 4.537142857142857,
      "grad_norm": 0.001610427862033248,
      "learning_rate": 1.3950476190476193e-05,
      "loss": 0.0,
      "step": 15880
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.0014077458763495088,
      "learning_rate": 1.3946666666666668e-05,
      "loss": 0.0,
      "step": 15890
    },
    {
      "epoch": 4.542857142857143,
      "grad_norm": 0.0002271523408126086,
      "learning_rate": 1.3942857142857145e-05,
      "loss": 0.0005,
      "step": 15900
    },
    {
      "epoch": 4.545714285714285,
      "grad_norm": 0.00036344354157336056,
      "learning_rate": 1.3939047619047621e-05,
      "loss": 0.0,
      "step": 15910
    },
    {
      "epoch": 4.548571428571429,
      "grad_norm": 0.004795472137629986,
      "learning_rate": 1.3935238095238097e-05,
      "loss": 0.0002,
      "step": 15920
    },
    {
      "epoch": 4.551428571428572,
      "grad_norm": 0.015162941999733448,
      "learning_rate": 1.3931428571428574e-05,
      "loss": 0.0001,
      "step": 15930
    },
    {
      "epoch": 4.554285714285714,
      "grad_norm": 0.0002553698141127825,
      "learning_rate": 1.392761904761905e-05,
      "loss": 0.0007,
      "step": 15940
    },
    {
      "epoch": 4.557142857142857,
      "grad_norm": 0.0003163960645906627,
      "learning_rate": 1.3923809523809523e-05,
      "loss": 0.1222,
      "step": 15950
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.0004903829540126026,
      "learning_rate": 1.392e-05,
      "loss": 0.0,
      "step": 15960
    },
    {
      "epoch": 4.562857142857143,
      "grad_norm": 0.0006958127487450838,
      "learning_rate": 1.3916190476190476e-05,
      "loss": 0.0089,
      "step": 15970
    },
    {
      "epoch": 4.565714285714286,
      "grad_norm": 0.0036275931634008884,
      "learning_rate": 1.3912380952380953e-05,
      "loss": 0.0001,
      "step": 15980
    },
    {
      "epoch": 4.5685714285714285,
      "grad_norm": 0.0009767659939825535,
      "learning_rate": 1.3908571428571429e-05,
      "loss": 0.0001,
      "step": 15990
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.0005429867305792868,
      "learning_rate": 1.3904761904761905e-05,
      "loss": 0.2015,
      "step": 16000
    },
    {
      "epoch": 4.574285714285715,
      "grad_norm": 0.0009167235693894327,
      "learning_rate": 1.3900952380952382e-05,
      "loss": 0.0001,
      "step": 16010
    },
    {
      "epoch": 4.577142857142857,
      "grad_norm": 0.00026351024280302227,
      "learning_rate": 1.3897142857142857e-05,
      "loss": 0.0005,
      "step": 16020
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.05996595695614815,
      "learning_rate": 1.3893333333333335e-05,
      "loss": 0.0001,
      "step": 16030
    },
    {
      "epoch": 4.582857142857143,
      "grad_norm": 0.00064922432648018,
      "learning_rate": 1.388952380952381e-05,
      "loss": 0.2631,
      "step": 16040
    },
    {
      "epoch": 4.585714285714285,
      "grad_norm": 0.001940497080795467,
      "learning_rate": 1.3885714285714288e-05,
      "loss": 0.0854,
      "step": 16050
    },
    {
      "epoch": 4.588571428571429,
      "grad_norm": 0.006302493158727884,
      "learning_rate": 1.3881904761904763e-05,
      "loss": 0.0001,
      "step": 16060
    },
    {
      "epoch": 4.591428571428572,
      "grad_norm": 0.23679868876934052,
      "learning_rate": 1.3878095238095239e-05,
      "loss": 0.2063,
      "step": 16070
    },
    {
      "epoch": 4.594285714285714,
      "grad_norm": 0.007605418097227812,
      "learning_rate": 1.3874285714285716e-05,
      "loss": 0.0002,
      "step": 16080
    },
    {
      "epoch": 4.597142857142857,
      "grad_norm": 0.005220435094088316,
      "learning_rate": 1.3870476190476192e-05,
      "loss": 0.0003,
      "step": 16090
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0024603784549981356,
      "learning_rate": 1.3866666666666669e-05,
      "loss": 0.0002,
      "step": 16100
    },
    {
      "epoch": 4.602857142857143,
      "grad_norm": 0.019143037497997284,
      "learning_rate": 1.3862857142857144e-05,
      "loss": 0.0018,
      "step": 16110
    },
    {
      "epoch": 4.605714285714286,
      "grad_norm": 0.0012030896032229066,
      "learning_rate": 1.385904761904762e-05,
      "loss": 0.0004,
      "step": 16120
    },
    {
      "epoch": 4.6085714285714285,
      "grad_norm": 0.003844222519546747,
      "learning_rate": 1.3855238095238097e-05,
      "loss": 0.1872,
      "step": 16130
    },
    {
      "epoch": 4.611428571428571,
      "grad_norm": 0.15391290187835693,
      "learning_rate": 1.3851428571428573e-05,
      "loss": 0.0002,
      "step": 16140
    },
    {
      "epoch": 4.614285714285714,
      "grad_norm": 0.013856706209480762,
      "learning_rate": 1.384761904761905e-05,
      "loss": 0.0001,
      "step": 16150
    },
    {
      "epoch": 4.617142857142857,
      "grad_norm": 0.002112997928634286,
      "learning_rate": 1.3843809523809526e-05,
      "loss": 0.0265,
      "step": 16160
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.001678316737525165,
      "learning_rate": 1.384e-05,
      "loss": 0.0001,
      "step": 16170
    },
    {
      "epoch": 4.622857142857143,
      "grad_norm": 0.0016027613310143352,
      "learning_rate": 1.3836190476190477e-05,
      "loss": 0.0001,
      "step": 16180
    },
    {
      "epoch": 4.6257142857142854,
      "grad_norm": 0.07728560268878937,
      "learning_rate": 1.3832380952380952e-05,
      "loss": 0.0001,
      "step": 16190
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 0.0023910144809633493,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 4.631428571428572,
      "grad_norm": 0.015587355941534042,
      "learning_rate": 1.3824761904761905e-05,
      "loss": 0.0001,
      "step": 16210
    },
    {
      "epoch": 4.634285714285714,
      "grad_norm": 0.0005831745220348239,
      "learning_rate": 1.3820952380952381e-05,
      "loss": 0.0001,
      "step": 16220
    },
    {
      "epoch": 4.637142857142857,
      "grad_norm": 0.006382692139595747,
      "learning_rate": 1.3817142857142858e-05,
      "loss": 0.1027,
      "step": 16230
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.0004189521714579314,
      "learning_rate": 1.3813333333333334e-05,
      "loss": 0.0,
      "step": 16240
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 0.001148300594650209,
      "learning_rate": 1.3809523809523811e-05,
      "loss": 0.262,
      "step": 16250
    },
    {
      "epoch": 4.645714285714286,
      "grad_norm": 0.0020041444804519415,
      "learning_rate": 1.3805714285714287e-05,
      "loss": 0.0,
      "step": 16260
    },
    {
      "epoch": 4.648571428571429,
      "grad_norm": 0.0018073392566293478,
      "learning_rate": 1.3801904761904762e-05,
      "loss": 0.0001,
      "step": 16270
    },
    {
      "epoch": 4.651428571428571,
      "grad_norm": 0.00291076279245317,
      "learning_rate": 1.379809523809524e-05,
      "loss": 0.0747,
      "step": 16280
    },
    {
      "epoch": 4.654285714285714,
      "grad_norm": 0.0018251867732033134,
      "learning_rate": 1.3794285714285715e-05,
      "loss": 0.0002,
      "step": 16290
    },
    {
      "epoch": 4.6571428571428575,
      "grad_norm": 0.0027720846701413393,
      "learning_rate": 1.3790476190476192e-05,
      "loss": 0.0009,
      "step": 16300
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.0017310964176431298,
      "learning_rate": 1.3786666666666668e-05,
      "loss": 0.0017,
      "step": 16310
    },
    {
      "epoch": 4.662857142857143,
      "grad_norm": 0.000814036640804261,
      "learning_rate": 1.3782857142857145e-05,
      "loss": 0.0001,
      "step": 16320
    },
    {
      "epoch": 4.6657142857142855,
      "grad_norm": 0.00044827209785580635,
      "learning_rate": 1.377904761904762e-05,
      "loss": 0.0001,
      "step": 16330
    },
    {
      "epoch": 4.668571428571429,
      "grad_norm": 0.0005478351376950741,
      "learning_rate": 1.3775238095238096e-05,
      "loss": 0.0001,
      "step": 16340
    },
    {
      "epoch": 4.671428571428572,
      "grad_norm": 0.0004382144834380597,
      "learning_rate": 1.3771428571428574e-05,
      "loss": 0.0,
      "step": 16350
    },
    {
      "epoch": 4.674285714285714,
      "grad_norm": 0.00047132870531640947,
      "learning_rate": 1.376761904761905e-05,
      "loss": 0.0,
      "step": 16360
    },
    {
      "epoch": 4.677142857142857,
      "grad_norm": 0.0005872347392141819,
      "learning_rate": 1.3763809523809527e-05,
      "loss": 0.0,
      "step": 16370
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.000859452469740063,
      "learning_rate": 1.376e-05,
      "loss": 0.0,
      "step": 16380
    },
    {
      "epoch": 4.682857142857143,
      "grad_norm": 0.0007188542513176799,
      "learning_rate": 1.3756190476190476e-05,
      "loss": 0.0776,
      "step": 16390
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 0.0008793614688329399,
      "learning_rate": 1.3752380952380953e-05,
      "loss": 0.0001,
      "step": 16400
    },
    {
      "epoch": 4.688571428571429,
      "grad_norm": 0.00044555551721714437,
      "learning_rate": 1.3748571428571429e-05,
      "loss": 0.0001,
      "step": 16410
    },
    {
      "epoch": 4.691428571428571,
      "grad_norm": 0.000424744444899261,
      "learning_rate": 1.3744761904761904e-05,
      "loss": 0.0003,
      "step": 16420
    },
    {
      "epoch": 4.694285714285714,
      "grad_norm": 0.0006572333513759077,
      "learning_rate": 1.3740952380952382e-05,
      "loss": 0.0002,
      "step": 16430
    },
    {
      "epoch": 4.6971428571428575,
      "grad_norm": 0.0008470798493362963,
      "learning_rate": 1.3737142857142857e-05,
      "loss": 0.1627,
      "step": 16440
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.00047407421516254544,
      "learning_rate": 1.3733333333333335e-05,
      "loss": 0.0,
      "step": 16450
    },
    {
      "epoch": 4.702857142857143,
      "grad_norm": 0.009242558851838112,
      "learning_rate": 1.372952380952381e-05,
      "loss": 0.0,
      "step": 16460
    },
    {
      "epoch": 4.7057142857142855,
      "grad_norm": 0.0019164684927091002,
      "learning_rate": 1.3725714285714287e-05,
      "loss": 0.0,
      "step": 16470
    },
    {
      "epoch": 4.708571428571428,
      "grad_norm": 0.0013436067383736372,
      "learning_rate": 1.3721904761904763e-05,
      "loss": 0.0,
      "step": 16480
    },
    {
      "epoch": 4.711428571428572,
      "grad_norm": 0.0024654935114085674,
      "learning_rate": 1.3718095238095239e-05,
      "loss": 0.2695,
      "step": 16490
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 0.004338005091995001,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.0,
      "step": 16500
    },
    {
      "epoch": 4.717142857142857,
      "grad_norm": 0.007936742156744003,
      "learning_rate": 1.3710476190476191e-05,
      "loss": 0.0,
      "step": 16510
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.013494767248630524,
      "learning_rate": 1.3706666666666669e-05,
      "loss": 0.0001,
      "step": 16520
    },
    {
      "epoch": 4.722857142857142,
      "grad_norm": 0.001050471211783588,
      "learning_rate": 1.3702857142857144e-05,
      "loss": 0.2269,
      "step": 16530
    },
    {
      "epoch": 4.725714285714286,
      "grad_norm": 0.002111275214701891,
      "learning_rate": 1.369904761904762e-05,
      "loss": 0.0001,
      "step": 16540
    },
    {
      "epoch": 4.728571428571429,
      "grad_norm": 0.0029924034606665373,
      "learning_rate": 1.3695238095238097e-05,
      "loss": 0.0002,
      "step": 16550
    },
    {
      "epoch": 4.731428571428571,
      "grad_norm": 0.0016313223168253899,
      "learning_rate": 1.3691428571428573e-05,
      "loss": 0.0001,
      "step": 16560
    },
    {
      "epoch": 4.734285714285714,
      "grad_norm": 0.0012459668796509504,
      "learning_rate": 1.368761904761905e-05,
      "loss": 0.0002,
      "step": 16570
    },
    {
      "epoch": 4.737142857142857,
      "grad_norm": 0.005234202835708857,
      "learning_rate": 1.3683809523809526e-05,
      "loss": 0.0002,
      "step": 16580
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.0015921557787805796,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 0.0,
      "step": 16590
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 0.0027583101764321327,
      "learning_rate": 1.3676190476190477e-05,
      "loss": 0.0001,
      "step": 16600
    },
    {
      "epoch": 4.7457142857142856,
      "grad_norm": 0.0009841888677328825,
      "learning_rate": 1.3672380952380952e-05,
      "loss": 0.0001,
      "step": 16610
    },
    {
      "epoch": 4.748571428571428,
      "grad_norm": 0.002293192083016038,
      "learning_rate": 1.366857142857143e-05,
      "loss": 0.2013,
      "step": 16620
    },
    {
      "epoch": 4.751428571428572,
      "grad_norm": 0.006870930548757315,
      "learning_rate": 1.3664761904761905e-05,
      "loss": 0.0001,
      "step": 16630
    },
    {
      "epoch": 4.7542857142857144,
      "grad_norm": 0.009496519342064857,
      "learning_rate": 1.366095238095238e-05,
      "loss": 0.1652,
      "step": 16640
    },
    {
      "epoch": 4.757142857142857,
      "grad_norm": 0.003621672745794058,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.0001,
      "step": 16650
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.008436248637735844,
      "learning_rate": 1.3653333333333334e-05,
      "loss": 0.0001,
      "step": 16660
    },
    {
      "epoch": 4.762857142857143,
      "grad_norm": 0.012738161720335484,
      "learning_rate": 1.3649523809523811e-05,
      "loss": 0.1371,
      "step": 16670
    },
    {
      "epoch": 4.765714285714286,
      "grad_norm": 0.0024895882233977318,
      "learning_rate": 1.3645714285714286e-05,
      "loss": 0.0001,
      "step": 16680
    },
    {
      "epoch": 4.768571428571429,
      "grad_norm": 0.0008848216966725886,
      "learning_rate": 1.3641904761904762e-05,
      "loss": 0.0,
      "step": 16690
    },
    {
      "epoch": 4.771428571428571,
      "grad_norm": 0.004730659537017345,
      "learning_rate": 1.363809523809524e-05,
      "loss": 0.0002,
      "step": 16700
    },
    {
      "epoch": 4.774285714285714,
      "grad_norm": 0.008477777242660522,
      "learning_rate": 1.3634285714285715e-05,
      "loss": 0.0001,
      "step": 16710
    },
    {
      "epoch": 4.777142857142858,
      "grad_norm": 0.0014542945427820086,
      "learning_rate": 1.3630476190476192e-05,
      "loss": 0.1728,
      "step": 16720
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.0017102276906371117,
      "learning_rate": 1.3626666666666668e-05,
      "loss": 0.0,
      "step": 16730
    },
    {
      "epoch": 4.782857142857143,
      "grad_norm": 0.001936561893671751,
      "learning_rate": 1.3622857142857145e-05,
      "loss": 0.0001,
      "step": 16740
    },
    {
      "epoch": 4.785714285714286,
      "grad_norm": 0.0002643400803208351,
      "learning_rate": 1.361904761904762e-05,
      "loss": 0.0,
      "step": 16750
    },
    {
      "epoch": 4.788571428571428,
      "grad_norm": 0.00036475900560617447,
      "learning_rate": 1.3615238095238096e-05,
      "loss": 0.0002,
      "step": 16760
    },
    {
      "epoch": 4.791428571428572,
      "grad_norm": 0.00083261972758919,
      "learning_rate": 1.3611428571428573e-05,
      "loss": 0.0002,
      "step": 16770
    },
    {
      "epoch": 4.7942857142857145,
      "grad_norm": 0.04842564836144447,
      "learning_rate": 1.3607619047619049e-05,
      "loss": 0.0002,
      "step": 16780
    },
    {
      "epoch": 4.797142857142857,
      "grad_norm": 0.002085648011416197,
      "learning_rate": 1.3603809523809526e-05,
      "loss": 0.0001,
      "step": 16790
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.00037836868432350457,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0001,
      "step": 16800
    },
    {
      "epoch": 4.8028571428571425,
      "grad_norm": 0.003957811277359724,
      "learning_rate": 1.359619047619048e-05,
      "loss": 0.0001,
      "step": 16810
    },
    {
      "epoch": 4.805714285714286,
      "grad_norm": 0.0003017722920048982,
      "learning_rate": 1.3592380952380953e-05,
      "loss": 0.0002,
      "step": 16820
    },
    {
      "epoch": 4.808571428571429,
      "grad_norm": 0.0005163619644008577,
      "learning_rate": 1.3588571428571429e-05,
      "loss": 0.0001,
      "step": 16830
    },
    {
      "epoch": 4.811428571428571,
      "grad_norm": 0.0006288019358180463,
      "learning_rate": 1.3584761904761904e-05,
      "loss": 0.0,
      "step": 16840
    },
    {
      "epoch": 4.814285714285714,
      "grad_norm": 0.0010133159812539816,
      "learning_rate": 1.3580952380952382e-05,
      "loss": 0.0001,
      "step": 16850
    },
    {
      "epoch": 4.817142857142857,
      "grad_norm": 0.0002775101165752858,
      "learning_rate": 1.3577142857142857e-05,
      "loss": 0.1452,
      "step": 16860
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.0002378403878537938,
      "learning_rate": 1.3573333333333334e-05,
      "loss": 0.0001,
      "step": 16870
    },
    {
      "epoch": 4.822857142857143,
      "grad_norm": 0.000521822483278811,
      "learning_rate": 1.356952380952381e-05,
      "loss": 0.0002,
      "step": 16880
    },
    {
      "epoch": 4.825714285714286,
      "grad_norm": 0.00024314933398272842,
      "learning_rate": 1.3565714285714287e-05,
      "loss": 0.0,
      "step": 16890
    },
    {
      "epoch": 4.828571428571428,
      "grad_norm": 0.00043613859452307224,
      "learning_rate": 1.3561904761904763e-05,
      "loss": 0.0001,
      "step": 16900
    },
    {
      "epoch": 4.831428571428571,
      "grad_norm": 0.00018898099369835109,
      "learning_rate": 1.3558095238095238e-05,
      "loss": 0.0,
      "step": 16910
    },
    {
      "epoch": 4.8342857142857145,
      "grad_norm": 0.011075617745518684,
      "learning_rate": 1.3554285714285716e-05,
      "loss": 0.5186,
      "step": 16920
    },
    {
      "epoch": 4.837142857142857,
      "grad_norm": 0.04111297056078911,
      "learning_rate": 1.3550476190476191e-05,
      "loss": 0.1682,
      "step": 16930
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.025994062423706055,
      "learning_rate": 1.3546666666666669e-05,
      "loss": 0.0005,
      "step": 16940
    },
    {
      "epoch": 4.8428571428571425,
      "grad_norm": 0.008717324584722519,
      "learning_rate": 1.3542857142857144e-05,
      "loss": 0.0005,
      "step": 16950
    },
    {
      "epoch": 4.845714285714286,
      "grad_norm": 0.013345925137400627,
      "learning_rate": 1.3539047619047621e-05,
      "loss": 0.0001,
      "step": 16960
    },
    {
      "epoch": 4.848571428571429,
      "grad_norm": 0.001425522263161838,
      "learning_rate": 1.3535238095238097e-05,
      "loss": 0.0003,
      "step": 16970
    },
    {
      "epoch": 4.851428571428571,
      "grad_norm": 0.002421008422970772,
      "learning_rate": 1.3531428571428573e-05,
      "loss": 0.0001,
      "step": 16980
    },
    {
      "epoch": 4.854285714285714,
      "grad_norm": 0.0019109331769868731,
      "learning_rate": 1.352761904761905e-05,
      "loss": 0.0267,
      "step": 16990
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.0007736593252047896,
      "learning_rate": 1.3523809523809525e-05,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.0017036430072039366,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.0001,
      "step": 17010
    },
    {
      "epoch": 4.862857142857143,
      "grad_norm": 0.013460302725434303,
      "learning_rate": 1.3516190476190478e-05,
      "loss": 0.0,
      "step": 17020
    },
    {
      "epoch": 4.865714285714286,
      "grad_norm": 0.0006310372846201062,
      "learning_rate": 1.3512380952380952e-05,
      "loss": 0.0001,
      "step": 17030
    },
    {
      "epoch": 4.868571428571428,
      "grad_norm": 0.000433208275353536,
      "learning_rate": 1.350857142857143e-05,
      "loss": 0.0001,
      "step": 17040
    },
    {
      "epoch": 4.871428571428572,
      "grad_norm": 0.0008596066618338227,
      "learning_rate": 1.3504761904761905e-05,
      "loss": 0.0,
      "step": 17050
    },
    {
      "epoch": 4.8742857142857146,
      "grad_norm": 0.0006408154149539769,
      "learning_rate": 1.350095238095238e-05,
      "loss": 0.0,
      "step": 17060
    },
    {
      "epoch": 4.877142857142857,
      "grad_norm": 0.015797346830368042,
      "learning_rate": 1.3497142857142858e-05,
      "loss": 0.2129,
      "step": 17070
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.0030799047090113163,
      "learning_rate": 1.3493333333333333e-05,
      "loss": 0.0002,
      "step": 17080
    },
    {
      "epoch": 4.882857142857143,
      "grad_norm": 0.004478503949940205,
      "learning_rate": 1.348952380952381e-05,
      "loss": 0.0002,
      "step": 17090
    },
    {
      "epoch": 4.885714285714286,
      "grad_norm": 0.027952637523412704,
      "learning_rate": 1.3485714285714286e-05,
      "loss": 0.0003,
      "step": 17100
    },
    {
      "epoch": 4.888571428571429,
      "grad_norm": 0.10652567446231842,
      "learning_rate": 1.3481904761904762e-05,
      "loss": 0.0001,
      "step": 17110
    },
    {
      "epoch": 4.8914285714285715,
      "grad_norm": 0.001833032933063805,
      "learning_rate": 1.347809523809524e-05,
      "loss": 0.0001,
      "step": 17120
    },
    {
      "epoch": 4.894285714285714,
      "grad_norm": 0.006669960916042328,
      "learning_rate": 1.3474285714285715e-05,
      "loss": 0.2093,
      "step": 17130
    },
    {
      "epoch": 4.897142857142857,
      "grad_norm": 0.0014430406736209989,
      "learning_rate": 1.3470476190476192e-05,
      "loss": 0.0001,
      "step": 17140
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.0010564462281763554,
      "learning_rate": 1.3466666666666668e-05,
      "loss": 0.0001,
      "step": 17150
    },
    {
      "epoch": 4.902857142857143,
      "grad_norm": 0.006619920022785664,
      "learning_rate": 1.3462857142857145e-05,
      "loss": 0.0,
      "step": 17160
    },
    {
      "epoch": 4.905714285714286,
      "grad_norm": 0.0008669174276292324,
      "learning_rate": 1.345904761904762e-05,
      "loss": 0.0001,
      "step": 17170
    },
    {
      "epoch": 4.908571428571428,
      "grad_norm": 0.004842078313231468,
      "learning_rate": 1.3455238095238096e-05,
      "loss": 0.0,
      "step": 17180
    },
    {
      "epoch": 4.911428571428571,
      "grad_norm": 0.002871954347938299,
      "learning_rate": 1.3451428571428573e-05,
      "loss": 0.1931,
      "step": 17190
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 0.002293011173605919,
      "learning_rate": 1.3447619047619049e-05,
      "loss": 0.0002,
      "step": 17200
    },
    {
      "epoch": 4.917142857142857,
      "grad_norm": 0.009059080854058266,
      "learning_rate": 1.3443809523809526e-05,
      "loss": 0.1524,
      "step": 17210
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.003122023306787014,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 0.0002,
      "step": 17220
    },
    {
      "epoch": 4.922857142857143,
      "grad_norm": 0.018425974994897842,
      "learning_rate": 1.3436190476190479e-05,
      "loss": 0.0001,
      "step": 17230
    },
    {
      "epoch": 4.925714285714285,
      "grad_norm": 0.004320012871176004,
      "learning_rate": 1.3432380952380955e-05,
      "loss": 0.0003,
      "step": 17240
    },
    {
      "epoch": 4.928571428571429,
      "grad_norm": 0.0018700327491387725,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.0001,
      "step": 17250
    },
    {
      "epoch": 4.9314285714285715,
      "grad_norm": 0.0009729212033562362,
      "learning_rate": 1.3424761904761904e-05,
      "loss": 0.0001,
      "step": 17260
    },
    {
      "epoch": 4.934285714285714,
      "grad_norm": 0.00085019925609231,
      "learning_rate": 1.3420952380952381e-05,
      "loss": 0.0001,
      "step": 17270
    },
    {
      "epoch": 4.937142857142857,
      "grad_norm": 0.0011157769476994872,
      "learning_rate": 1.3417142857142857e-05,
      "loss": 0.0,
      "step": 17280
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.00460827024653554,
      "learning_rate": 1.3413333333333334e-05,
      "loss": 0.0002,
      "step": 17290
    },
    {
      "epoch": 4.942857142857143,
      "grad_norm": 0.000556773622520268,
      "learning_rate": 1.340952380952381e-05,
      "loss": 0.0,
      "step": 17300
    },
    {
      "epoch": 4.945714285714286,
      "grad_norm": 0.0033773689065128565,
      "learning_rate": 1.3405714285714287e-05,
      "loss": 0.0,
      "step": 17310
    },
    {
      "epoch": 4.948571428571428,
      "grad_norm": 0.0005993694649077952,
      "learning_rate": 1.3401904761904763e-05,
      "loss": 0.0,
      "step": 17320
    },
    {
      "epoch": 4.951428571428571,
      "grad_norm": 0.0003224884858354926,
      "learning_rate": 1.3398095238095238e-05,
      "loss": 0.0001,
      "step": 17330
    },
    {
      "epoch": 4.954285714285715,
      "grad_norm": 41.543556213378906,
      "learning_rate": 1.3394285714285716e-05,
      "loss": 0.1228,
      "step": 17340
    },
    {
      "epoch": 4.957142857142857,
      "grad_norm": 0.0025256990920752287,
      "learning_rate": 1.3390476190476191e-05,
      "loss": 0.0,
      "step": 17350
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.006493772380053997,
      "learning_rate": 1.3386666666666668e-05,
      "loss": 0.0,
      "step": 17360
    },
    {
      "epoch": 4.962857142857143,
      "grad_norm": 0.001155821024440229,
      "learning_rate": 1.3382857142857144e-05,
      "loss": 0.0,
      "step": 17370
    },
    {
      "epoch": 4.965714285714286,
      "grad_norm": 0.0032147837337106466,
      "learning_rate": 1.3379047619047621e-05,
      "loss": 0.0001,
      "step": 17380
    },
    {
      "epoch": 4.968571428571429,
      "grad_norm": 0.0004165839054621756,
      "learning_rate": 1.3375238095238097e-05,
      "loss": 0.0006,
      "step": 17390
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 0.002549238270148635,
      "learning_rate": 1.3371428571428572e-05,
      "loss": 0.0,
      "step": 17400
    },
    {
      "epoch": 4.974285714285714,
      "grad_norm": 62.81697463989258,
      "learning_rate": 1.336761904761905e-05,
      "loss": 0.1863,
      "step": 17410
    },
    {
      "epoch": 4.977142857142857,
      "grad_norm": 0.000994293368421495,
      "learning_rate": 1.3363809523809525e-05,
      "loss": 0.0,
      "step": 17420
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.005285818129777908,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 0.1847,
      "step": 17430
    },
    {
      "epoch": 4.982857142857143,
      "grad_norm": 0.010061618871986866,
      "learning_rate": 1.3356190476190478e-05,
      "loss": 0.1212,
      "step": 17440
    },
    {
      "epoch": 4.985714285714286,
      "grad_norm": 0.009889972396194935,
      "learning_rate": 1.3352380952380954e-05,
      "loss": 0.1389,
      "step": 17450
    },
    {
      "epoch": 4.988571428571428,
      "grad_norm": 0.001194023061543703,
      "learning_rate": 1.3348571428571431e-05,
      "loss": 0.0007,
      "step": 17460
    },
    {
      "epoch": 4.991428571428571,
      "grad_norm": 0.0022389530204236507,
      "learning_rate": 1.3344761904761905e-05,
      "loss": 0.0071,
      "step": 17470
    },
    {
      "epoch": 4.994285714285715,
      "grad_norm": 0.001767490990459919,
      "learning_rate": 1.334095238095238e-05,
      "loss": 0.0001,
      "step": 17480
    },
    {
      "epoch": 4.997142857142857,
      "grad_norm": 0.006706413347274065,
      "learning_rate": 1.3337142857142858e-05,
      "loss": 0.0001,
      "step": 17490
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0030567534267902374,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0,
      "step": 17500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9803333333333333,
      "eval_f1": 0.884990253411306,
      "eval_loss": 0.14757511019706726,
      "eval_precision": 0.8764478764478765,
      "eval_recall": 0.8937007874015748,
      "eval_runtime": 259.6479,
      "eval_samples_per_second": 11.554,
      "eval_steps_per_second": 2.889,
      "step": 17500
    },
    {
      "epoch": 5.002857142857143,
      "grad_norm": 0.002858897438272834,
      "learning_rate": 1.332952380952381e-05,
      "loss": 0.129,
      "step": 17510
    },
    {
      "epoch": 5.005714285714285,
      "grad_norm": 0.002574231242761016,
      "learning_rate": 1.3325714285714286e-05,
      "loss": 0.0,
      "step": 17520
    },
    {
      "epoch": 5.008571428571429,
      "grad_norm": 0.0018964014016091824,
      "learning_rate": 1.3321904761904762e-05,
      "loss": 0.1765,
      "step": 17530
    },
    {
      "epoch": 5.011428571428572,
      "grad_norm": 0.00739594642072916,
      "learning_rate": 1.3318095238095239e-05,
      "loss": 0.1899,
      "step": 17540
    },
    {
      "epoch": 5.014285714285714,
      "grad_norm": 0.007366207893937826,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.0005,
      "step": 17550
    },
    {
      "epoch": 5.017142857142857,
      "grad_norm": 0.006345633417367935,
      "learning_rate": 1.3310476190476192e-05,
      "loss": 0.0003,
      "step": 17560
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.0036886895541101694,
      "learning_rate": 1.3306666666666667e-05,
      "loss": 0.0001,
      "step": 17570
    },
    {
      "epoch": 5.022857142857143,
      "grad_norm": 0.004879570100456476,
      "learning_rate": 1.3302857142857145e-05,
      "loss": 0.0005,
      "step": 17580
    },
    {
      "epoch": 5.025714285714286,
      "grad_norm": 0.0013770126970484853,
      "learning_rate": 1.329904761904762e-05,
      "loss": 0.0,
      "step": 17590
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 30.32505989074707,
      "learning_rate": 1.3295238095238096e-05,
      "loss": 0.1398,
      "step": 17600
    },
    {
      "epoch": 5.031428571428571,
      "grad_norm": 0.0008500027470290661,
      "learning_rate": 1.3291428571428573e-05,
      "loss": 0.0,
      "step": 17610
    },
    {
      "epoch": 5.034285714285715,
      "grad_norm": 0.002404914703220129,
      "learning_rate": 1.3287619047619049e-05,
      "loss": 0.0,
      "step": 17620
    },
    {
      "epoch": 5.037142857142857,
      "grad_norm": 0.0003607521066442132,
      "learning_rate": 1.3283809523809526e-05,
      "loss": 0.0,
      "step": 17630
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.0008390888688154519,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.0,
      "step": 17640
    },
    {
      "epoch": 5.042857142857143,
      "grad_norm": 0.0006320517277345061,
      "learning_rate": 1.3276190476190479e-05,
      "loss": 0.0003,
      "step": 17650
    },
    {
      "epoch": 5.045714285714285,
      "grad_norm": 0.0004851095436606556,
      "learning_rate": 1.3272380952380954e-05,
      "loss": 0.0,
      "step": 17660
    },
    {
      "epoch": 5.048571428571429,
      "grad_norm": 0.00040854126564227045,
      "learning_rate": 1.326857142857143e-05,
      "loss": 0.0,
      "step": 17670
    },
    {
      "epoch": 5.051428571428572,
      "grad_norm": 0.0003747328300960362,
      "learning_rate": 1.3264761904761907e-05,
      "loss": 0.0005,
      "step": 17680
    },
    {
      "epoch": 5.054285714285714,
      "grad_norm": 0.001001527882181108,
      "learning_rate": 1.3260952380952381e-05,
      "loss": 0.0,
      "step": 17690
    },
    {
      "epoch": 5.057142857142857,
      "grad_norm": 0.00031007261713966727,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.0,
      "step": 17700
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.006777722854167223,
      "learning_rate": 1.3253333333333334e-05,
      "loss": 0.0001,
      "step": 17710
    },
    {
      "epoch": 5.062857142857143,
      "grad_norm": 0.0002571300428826362,
      "learning_rate": 1.324952380952381e-05,
      "loss": 0.0,
      "step": 17720
    },
    {
      "epoch": 5.065714285714286,
      "grad_norm": 0.00021648171241395175,
      "learning_rate": 1.3245714285714287e-05,
      "loss": 0.0,
      "step": 17730
    },
    {
      "epoch": 5.0685714285714285,
      "grad_norm": 0.000894793018233031,
      "learning_rate": 1.3241904761904762e-05,
      "loss": 0.0,
      "step": 17740
    },
    {
      "epoch": 5.071428571428571,
      "grad_norm": 0.00013442366616800427,
      "learning_rate": 1.3238095238095238e-05,
      "loss": 0.0002,
      "step": 17750
    },
    {
      "epoch": 5.074285714285715,
      "grad_norm": 0.00018928937788587064,
      "learning_rate": 1.3234285714285715e-05,
      "loss": 0.0004,
      "step": 17760
    },
    {
      "epoch": 5.077142857142857,
      "grad_norm": 0.00152171915397048,
      "learning_rate": 1.3230476190476191e-05,
      "loss": 0.0,
      "step": 17770
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.001221259357407689,
      "learning_rate": 1.3226666666666668e-05,
      "loss": 0.0001,
      "step": 17780
    },
    {
      "epoch": 5.082857142857143,
      "grad_norm": 0.00021955631382297724,
      "learning_rate": 1.3222857142857144e-05,
      "loss": 0.0002,
      "step": 17790
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 0.006050569470971823,
      "learning_rate": 1.3219047619047621e-05,
      "loss": 0.0,
      "step": 17800
    },
    {
      "epoch": 5.088571428571429,
      "grad_norm": 0.0001658333494560793,
      "learning_rate": 1.3215238095238097e-05,
      "loss": 0.0,
      "step": 17810
    },
    {
      "epoch": 5.091428571428572,
      "grad_norm": 0.0015505686169490218,
      "learning_rate": 1.3211428571428572e-05,
      "loss": 0.1478,
      "step": 17820
    },
    {
      "epoch": 5.094285714285714,
      "grad_norm": 0.001118826330639422,
      "learning_rate": 1.320761904761905e-05,
      "loss": 0.0,
      "step": 17830
    },
    {
      "epoch": 5.097142857142857,
      "grad_norm": 0.5525899529457092,
      "learning_rate": 1.3203809523809525e-05,
      "loss": 0.0003,
      "step": 17840
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.00015238809282891452,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.0,
      "step": 17850
    },
    {
      "epoch": 5.102857142857143,
      "grad_norm": 0.00018606620142236352,
      "learning_rate": 1.3196190476190478e-05,
      "loss": 0.0002,
      "step": 17860
    },
    {
      "epoch": 5.105714285714286,
      "grad_norm": 0.028366392478346825,
      "learning_rate": 1.3192380952380954e-05,
      "loss": 0.0848,
      "step": 17870
    },
    {
      "epoch": 5.1085714285714285,
      "grad_norm": 0.00023221860465127975,
      "learning_rate": 1.318857142857143e-05,
      "loss": 0.0,
      "step": 17880
    },
    {
      "epoch": 5.111428571428571,
      "grad_norm": 0.000575308979023248,
      "learning_rate": 1.3184761904761906e-05,
      "loss": 0.1826,
      "step": 17890
    },
    {
      "epoch": 5.114285714285714,
      "grad_norm": 0.0015671101864427328,
      "learning_rate": 1.318095238095238e-05,
      "loss": 0.1333,
      "step": 17900
    },
    {
      "epoch": 5.117142857142857,
      "grad_norm": 0.0002691668050829321,
      "learning_rate": 1.3177142857142858e-05,
      "loss": 0.0,
      "step": 17910
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.0012292219325900078,
      "learning_rate": 1.3173333333333333e-05,
      "loss": 0.0,
      "step": 17920
    },
    {
      "epoch": 5.122857142857143,
      "grad_norm": 0.00038300908636301756,
      "learning_rate": 1.316952380952381e-05,
      "loss": 0.2208,
      "step": 17930
    },
    {
      "epoch": 5.1257142857142854,
      "grad_norm": 0.00032791501143947244,
      "learning_rate": 1.3165714285714286e-05,
      "loss": 0.0001,
      "step": 17940
    },
    {
      "epoch": 5.128571428571428,
      "grad_norm": 0.0005428879521787167,
      "learning_rate": 1.3161904761904762e-05,
      "loss": 0.0001,
      "step": 17950
    },
    {
      "epoch": 5.131428571428572,
      "grad_norm": 0.0002780964714474976,
      "learning_rate": 1.3158095238095239e-05,
      "loss": 0.0002,
      "step": 17960
    },
    {
      "epoch": 5.134285714285714,
      "grad_norm": 0.000303248263662681,
      "learning_rate": 1.3154285714285714e-05,
      "loss": 0.0001,
      "step": 17970
    },
    {
      "epoch": 5.137142857142857,
      "grad_norm": 0.7624671459197998,
      "learning_rate": 1.3150476190476192e-05,
      "loss": 0.0001,
      "step": 17980
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.005697285756468773,
      "learning_rate": 1.3146666666666667e-05,
      "loss": 0.2104,
      "step": 17990
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.008620166219770908,
      "learning_rate": 1.3142857142857145e-05,
      "loss": 0.0001,
      "step": 18000
    },
    {
      "epoch": 5.145714285714286,
      "grad_norm": 0.0008276000735349953,
      "learning_rate": 1.313904761904762e-05,
      "loss": 0.0,
      "step": 18010
    },
    {
      "epoch": 5.148571428571429,
      "grad_norm": 0.0004356125427875668,
      "learning_rate": 1.3135238095238096e-05,
      "loss": 0.0,
      "step": 18020
    },
    {
      "epoch": 5.151428571428571,
      "grad_norm": 0.0035553104244172573,
      "learning_rate": 1.3131428571428573e-05,
      "loss": 0.0001,
      "step": 18030
    },
    {
      "epoch": 5.154285714285714,
      "grad_norm": 0.006591712590306997,
      "learning_rate": 1.3127619047619049e-05,
      "loss": 0.0001,
      "step": 18040
    },
    {
      "epoch": 5.1571428571428575,
      "grad_norm": 0.004994150251150131,
      "learning_rate": 1.3123809523809526e-05,
      "loss": 0.0002,
      "step": 18050
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.0008169433567672968,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.0,
      "step": 18060
    },
    {
      "epoch": 5.162857142857143,
      "grad_norm": 0.00027770348242484033,
      "learning_rate": 1.3116190476190479e-05,
      "loss": 0.0003,
      "step": 18070
    },
    {
      "epoch": 5.1657142857142855,
      "grad_norm": 0.00249796942807734,
      "learning_rate": 1.3112380952380954e-05,
      "loss": 0.0003,
      "step": 18080
    },
    {
      "epoch": 5.168571428571428,
      "grad_norm": 0.0002356082695769146,
      "learning_rate": 1.310857142857143e-05,
      "loss": 0.0,
      "step": 18090
    },
    {
      "epoch": 5.171428571428572,
      "grad_norm": 0.00017107998428400606,
      "learning_rate": 1.3104761904761907e-05,
      "loss": 0.0,
      "step": 18100
    },
    {
      "epoch": 5.174285714285714,
      "grad_norm": 0.021488256752490997,
      "learning_rate": 1.3100952380952383e-05,
      "loss": 0.0,
      "step": 18110
    },
    {
      "epoch": 5.177142857142857,
      "grad_norm": 0.001283847726881504,
      "learning_rate": 1.3097142857142857e-05,
      "loss": 0.0,
      "step": 18120
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.1846344769001007,
      "learning_rate": 1.3093333333333334e-05,
      "loss": 0.0011,
      "step": 18130
    },
    {
      "epoch": 5.182857142857143,
      "grad_norm": 0.00014886267308611423,
      "learning_rate": 1.308952380952381e-05,
      "loss": 0.0,
      "step": 18140
    },
    {
      "epoch": 5.185714285714286,
      "grad_norm": 0.00014583148004021496,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 0.0,
      "step": 18150
    },
    {
      "epoch": 5.188571428571429,
      "grad_norm": 0.00020588352344930172,
      "learning_rate": 1.3081904761904762e-05,
      "loss": 0.0,
      "step": 18160
    },
    {
      "epoch": 5.191428571428571,
      "grad_norm": 0.0001339610171271488,
      "learning_rate": 1.3078095238095238e-05,
      "loss": 0.0,
      "step": 18170
    },
    {
      "epoch": 5.194285714285714,
      "grad_norm": 0.0001291138760279864,
      "learning_rate": 1.3074285714285715e-05,
      "loss": 0.0,
      "step": 18180
    },
    {
      "epoch": 5.1971428571428575,
      "grad_norm": 0.00011304798681521788,
      "learning_rate": 1.307047619047619e-05,
      "loss": 0.0,
      "step": 18190
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.0001272205845452845,
      "learning_rate": 1.3066666666666668e-05,
      "loss": 0.0,
      "step": 18200
    },
    {
      "epoch": 5.202857142857143,
      "grad_norm": 0.00018884385644923896,
      "learning_rate": 1.3062857142857144e-05,
      "loss": 0.0,
      "step": 18210
    },
    {
      "epoch": 5.2057142857142855,
      "grad_norm": 0.0007278714911080897,
      "learning_rate": 1.3059047619047621e-05,
      "loss": 0.0,
      "step": 18220
    },
    {
      "epoch": 5.208571428571428,
      "grad_norm": 0.0001354261621600017,
      "learning_rate": 1.3055238095238096e-05,
      "loss": 0.0,
      "step": 18230
    },
    {
      "epoch": 5.211428571428572,
      "grad_norm": 0.003230016678571701,
      "learning_rate": 1.3051428571428572e-05,
      "loss": 0.1578,
      "step": 18240
    },
    {
      "epoch": 5.214285714285714,
      "grad_norm": 0.0010435591684654355,
      "learning_rate": 1.304761904761905e-05,
      "loss": 0.0,
      "step": 18250
    },
    {
      "epoch": 5.217142857142857,
      "grad_norm": 0.6708365678787231,
      "learning_rate": 1.3043809523809525e-05,
      "loss": 0.1425,
      "step": 18260
    },
    {
      "epoch": 5.22,
      "grad_norm": 0.00020623112504836172,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.0584,
      "step": 18270
    },
    {
      "epoch": 5.222857142857142,
      "grad_norm": 0.6512630581855774,
      "learning_rate": 1.3036190476190478e-05,
      "loss": 0.0003,
      "step": 18280
    },
    {
      "epoch": 5.225714285714286,
      "grad_norm": 0.00017781044880393893,
      "learning_rate": 1.3032380952380953e-05,
      "loss": 0.0,
      "step": 18290
    },
    {
      "epoch": 5.228571428571429,
      "grad_norm": 0.0004577913787215948,
      "learning_rate": 1.302857142857143e-05,
      "loss": 0.0,
      "step": 18300
    },
    {
      "epoch": 5.231428571428571,
      "grad_norm": 0.001526608713902533,
      "learning_rate": 1.3024761904761906e-05,
      "loss": 0.0,
      "step": 18310
    },
    {
      "epoch": 5.234285714285714,
      "grad_norm": 0.0001965560222743079,
      "learning_rate": 1.3020952380952384e-05,
      "loss": 0.0,
      "step": 18320
    },
    {
      "epoch": 5.2371428571428575,
      "grad_norm": 0.00015049490320961922,
      "learning_rate": 1.3017142857142859e-05,
      "loss": 0.0,
      "step": 18330
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.00032154787913896143,
      "learning_rate": 1.3013333333333333e-05,
      "loss": 0.0,
      "step": 18340
    },
    {
      "epoch": 5.242857142857143,
      "grad_norm": 0.00047673206427134573,
      "learning_rate": 1.300952380952381e-05,
      "loss": 0.0,
      "step": 18350
    },
    {
      "epoch": 5.2457142857142856,
      "grad_norm": 0.0004316236882004887,
      "learning_rate": 1.3005714285714286e-05,
      "loss": 0.0,
      "step": 18360
    },
    {
      "epoch": 5.248571428571428,
      "grad_norm": 0.0002972622460220009,
      "learning_rate": 1.3001904761904761e-05,
      "loss": 0.0,
      "step": 18370
    },
    {
      "epoch": 5.251428571428572,
      "grad_norm": 0.00044853700092062354,
      "learning_rate": 1.2998095238095239e-05,
      "loss": 0.2165,
      "step": 18380
    },
    {
      "epoch": 5.2542857142857144,
      "grad_norm": 0.0019680035766214132,
      "learning_rate": 1.2994285714285714e-05,
      "loss": 0.179,
      "step": 18390
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 0.0008053765050135553,
      "learning_rate": 1.2990476190476192e-05,
      "loss": 0.0001,
      "step": 18400
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.00041563232662156224,
      "learning_rate": 1.2986666666666667e-05,
      "loss": 0.0001,
      "step": 18410
    },
    {
      "epoch": 5.2628571428571425,
      "grad_norm": 40.09873962402344,
      "learning_rate": 1.2982857142857144e-05,
      "loss": 0.0885,
      "step": 18420
    },
    {
      "epoch": 5.265714285714286,
      "grad_norm": 0.010387181304395199,
      "learning_rate": 1.297904761904762e-05,
      "loss": 0.0002,
      "step": 18430
    },
    {
      "epoch": 5.268571428571429,
      "grad_norm": 0.00037038553273305297,
      "learning_rate": 1.2975238095238096e-05,
      "loss": 0.0008,
      "step": 18440
    },
    {
      "epoch": 5.271428571428571,
      "grad_norm": 0.0002113316731993109,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.0644,
      "step": 18450
    },
    {
      "epoch": 5.274285714285714,
      "grad_norm": 0.0017249103402718902,
      "learning_rate": 1.2967619047619048e-05,
      "loss": 0.0,
      "step": 18460
    },
    {
      "epoch": 5.277142857142858,
      "grad_norm": 0.00014350700075738132,
      "learning_rate": 1.2963809523809526e-05,
      "loss": 0.0001,
      "step": 18470
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.008399414829909801,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 0.0001,
      "step": 18480
    },
    {
      "epoch": 5.282857142857143,
      "grad_norm": 0.0007045870297588408,
      "learning_rate": 1.2956190476190479e-05,
      "loss": 0.0001,
      "step": 18490
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.00025611091405153275,
      "learning_rate": 1.2952380952380954e-05,
      "loss": 0.0,
      "step": 18500
    },
    {
      "epoch": 5.288571428571428,
      "grad_norm": 0.00017419224604964256,
      "learning_rate": 1.294857142857143e-05,
      "loss": 0.0,
      "step": 18510
    },
    {
      "epoch": 5.291428571428572,
      "grad_norm": 0.02319941110908985,
      "learning_rate": 1.2944761904761907e-05,
      "loss": 0.0,
      "step": 18520
    },
    {
      "epoch": 5.2942857142857145,
      "grad_norm": 0.0002581557782832533,
      "learning_rate": 1.2940952380952383e-05,
      "loss": 0.0012,
      "step": 18530
    },
    {
      "epoch": 5.297142857142857,
      "grad_norm": 0.002952923998236656,
      "learning_rate": 1.293714285714286e-05,
      "loss": 0.0,
      "step": 18540
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.0016696664970368147,
      "learning_rate": 1.2933333333333334e-05,
      "loss": 0.0,
      "step": 18550
    },
    {
      "epoch": 5.3028571428571425,
      "grad_norm": 0.00025988006382249296,
      "learning_rate": 1.292952380952381e-05,
      "loss": 0.0,
      "step": 18560
    },
    {
      "epoch": 5.305714285714286,
      "grad_norm": 0.00015494281251449138,
      "learning_rate": 1.2925714285714287e-05,
      "loss": 0.0,
      "step": 18570
    },
    {
      "epoch": 5.308571428571429,
      "grad_norm": 0.0004198644601274282,
      "learning_rate": 1.2921904761904762e-05,
      "loss": 0.0,
      "step": 18580
    },
    {
      "epoch": 5.311428571428571,
      "grad_norm": 0.0006285409326665103,
      "learning_rate": 1.2918095238095238e-05,
      "loss": 0.0,
      "step": 18590
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 0.00040070698014460504,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.0001,
      "step": 18600
    },
    {
      "epoch": 5.317142857142857,
      "grad_norm": 0.0004516476474236697,
      "learning_rate": 1.291047619047619e-05,
      "loss": 0.147,
      "step": 18610
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.0012267578858882189,
      "learning_rate": 1.2906666666666668e-05,
      "loss": 0.0,
      "step": 18620
    },
    {
      "epoch": 5.322857142857143,
      "grad_norm": 0.0006698003853671253,
      "learning_rate": 1.2902857142857143e-05,
      "loss": 0.1612,
      "step": 18630
    },
    {
      "epoch": 5.325714285714286,
      "grad_norm": 0.002551051788032055,
      "learning_rate": 1.289904761904762e-05,
      "loss": 0.0,
      "step": 18640
    },
    {
      "epoch": 5.328571428571428,
      "grad_norm": 0.0008508085156790912,
      "learning_rate": 1.2895238095238096e-05,
      "loss": 0.0004,
      "step": 18650
    },
    {
      "epoch": 5.331428571428571,
      "grad_norm": 0.00032552957418374717,
      "learning_rate": 1.2891428571428572e-05,
      "loss": 0.0,
      "step": 18660
    },
    {
      "epoch": 5.3342857142857145,
      "grad_norm": 0.00024399107496719807,
      "learning_rate": 1.288761904761905e-05,
      "loss": 0.0,
      "step": 18670
    },
    {
      "epoch": 5.337142857142857,
      "grad_norm": 0.00038285189657472074,
      "learning_rate": 1.2883809523809525e-05,
      "loss": 0.0,
      "step": 18680
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.00014823608216829598,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.0001,
      "step": 18690
    },
    {
      "epoch": 5.3428571428571425,
      "grad_norm": 0.0030453642830252647,
      "learning_rate": 1.2876190476190478e-05,
      "loss": 0.0002,
      "step": 18700
    },
    {
      "epoch": 5.345714285714286,
      "grad_norm": 0.0004252638609614223,
      "learning_rate": 1.2872380952380953e-05,
      "loss": 0.0015,
      "step": 18710
    },
    {
      "epoch": 5.348571428571429,
      "grad_norm": 8.416690252488479e-05,
      "learning_rate": 1.286857142857143e-05,
      "loss": 0.0,
      "step": 18720
    },
    {
      "epoch": 5.351428571428571,
      "grad_norm": 0.00021563768677879125,
      "learning_rate": 1.2864761904761906e-05,
      "loss": 0.0001,
      "step": 18730
    },
    {
      "epoch": 5.354285714285714,
      "grad_norm": 0.00010546323755988851,
      "learning_rate": 1.2860952380952383e-05,
      "loss": 0.0,
      "step": 18740
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.00013438936730381101,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.0,
      "step": 18750
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.0006033711833879352,
      "learning_rate": 1.2853333333333336e-05,
      "loss": 0.0,
      "step": 18760
    },
    {
      "epoch": 5.362857142857143,
      "grad_norm": 0.021437017247080803,
      "learning_rate": 1.284952380952381e-05,
      "loss": 0.0,
      "step": 18770
    },
    {
      "epoch": 5.365714285714286,
      "grad_norm": 0.0014865106204524636,
      "learning_rate": 1.2845714285714286e-05,
      "loss": 0.0007,
      "step": 18780
    },
    {
      "epoch": 5.368571428571428,
      "grad_norm": 7.667336467420682e-05,
      "learning_rate": 1.2841904761904763e-05,
      "loss": 0.0,
      "step": 18790
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 0.0001054435342666693,
      "learning_rate": 1.2838095238095239e-05,
      "loss": 0.0,
      "step": 18800
    },
    {
      "epoch": 5.3742857142857146,
      "grad_norm": 0.00010707332694437355,
      "learning_rate": 1.2834285714285714e-05,
      "loss": 0.0,
      "step": 18810
    },
    {
      "epoch": 5.377142857142857,
      "grad_norm": 9.370925545226783e-05,
      "learning_rate": 1.2830476190476191e-05,
      "loss": 0.1501,
      "step": 18820
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.0006138847675174475,
      "learning_rate": 1.2826666666666667e-05,
      "loss": 0.0,
      "step": 18830
    },
    {
      "epoch": 5.382857142857143,
      "grad_norm": 0.00027393878553994,
      "learning_rate": 1.2822857142857144e-05,
      "loss": 0.0001,
      "step": 18840
    },
    {
      "epoch": 5.385714285714286,
      "grad_norm": 0.00032392621506005526,
      "learning_rate": 1.281904761904762e-05,
      "loss": 0.0,
      "step": 18850
    },
    {
      "epoch": 5.388571428571429,
      "grad_norm": 0.0005566930631175637,
      "learning_rate": 1.2815238095238095e-05,
      "loss": 0.0,
      "step": 18860
    },
    {
      "epoch": 5.3914285714285715,
      "grad_norm": 0.00016076858446467668,
      "learning_rate": 1.2811428571428573e-05,
      "loss": 0.0,
      "step": 18870
    },
    {
      "epoch": 5.394285714285714,
      "grad_norm": 0.00011620957229752094,
      "learning_rate": 1.2807619047619048e-05,
      "loss": 0.0,
      "step": 18880
    },
    {
      "epoch": 5.397142857142857,
      "grad_norm": 0.0006917723803780973,
      "learning_rate": 1.2803809523809526e-05,
      "loss": 0.0,
      "step": 18890
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.0012708392459899187,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.1923,
      "step": 18900
    },
    {
      "epoch": 5.402857142857143,
      "grad_norm": 0.00035593201755546033,
      "learning_rate": 1.2796190476190478e-05,
      "loss": 0.0,
      "step": 18910
    },
    {
      "epoch": 5.405714285714286,
      "grad_norm": 0.0025551423896104097,
      "learning_rate": 1.2792380952380954e-05,
      "loss": 0.2343,
      "step": 18920
    },
    {
      "epoch": 5.408571428571428,
      "grad_norm": 0.004965224303305149,
      "learning_rate": 1.278857142857143e-05,
      "loss": 0.0775,
      "step": 18930
    },
    {
      "epoch": 5.411428571428571,
      "grad_norm": 0.6278324127197266,
      "learning_rate": 1.2784761904761907e-05,
      "loss": 0.0012,
      "step": 18940
    },
    {
      "epoch": 5.414285714285715,
      "grad_norm": 0.0029208678752183914,
      "learning_rate": 1.2780952380952382e-05,
      "loss": 0.0003,
      "step": 18950
    },
    {
      "epoch": 5.417142857142857,
      "grad_norm": 0.0007102942327037454,
      "learning_rate": 1.277714285714286e-05,
      "loss": 0.1177,
      "step": 18960
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.0011750453850254416,
      "learning_rate": 1.2773333333333335e-05,
      "loss": 0.0,
      "step": 18970
    },
    {
      "epoch": 5.422857142857143,
      "grad_norm": 0.0005935883964411914,
      "learning_rate": 1.2769523809523811e-05,
      "loss": 0.1395,
      "step": 18980
    },
    {
      "epoch": 5.425714285714285,
      "grad_norm": 0.025809483602643013,
      "learning_rate": 1.2765714285714286e-05,
      "loss": 0.2046,
      "step": 18990
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.021038226783275604,
      "learning_rate": 1.2761904761904762e-05,
      "loss": 0.0003,
      "step": 19000
    },
    {
      "epoch": 5.4314285714285715,
      "grad_norm": 0.0023249543737620115,
      "learning_rate": 1.2758095238095238e-05,
      "loss": 0.0001,
      "step": 19010
    },
    {
      "epoch": 5.434285714285714,
      "grad_norm": 0.0033210525289177895,
      "learning_rate": 1.2754285714285715e-05,
      "loss": 0.0003,
      "step": 19020
    },
    {
      "epoch": 5.437142857142857,
      "grad_norm": 0.004410639870911837,
      "learning_rate": 1.275047619047619e-05,
      "loss": 0.0001,
      "step": 19030
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.0013238702667877078,
      "learning_rate": 1.2746666666666668e-05,
      "loss": 0.0001,
      "step": 19040
    },
    {
      "epoch": 5.442857142857143,
      "grad_norm": 22.935941696166992,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 0.2113,
      "step": 19050
    },
    {
      "epoch": 5.445714285714286,
      "grad_norm": 0.006937941536307335,
      "learning_rate": 1.273904761904762e-05,
      "loss": 0.0001,
      "step": 19060
    },
    {
      "epoch": 5.448571428571428,
      "grad_norm": 0.004924300126731396,
      "learning_rate": 1.2735238095238096e-05,
      "loss": 0.0002,
      "step": 19070
    },
    {
      "epoch": 5.451428571428571,
      "grad_norm": 0.004098173696547747,
      "learning_rate": 1.2731428571428572e-05,
      "loss": 0.1674,
      "step": 19080
    },
    {
      "epoch": 5.454285714285715,
      "grad_norm": 0.09137405455112457,
      "learning_rate": 1.2727619047619049e-05,
      "loss": 0.0003,
      "step": 19090
    },
    {
      "epoch": 5.457142857142857,
      "grad_norm": 0.02226320095360279,
      "learning_rate": 1.2723809523809525e-05,
      "loss": 0.0646,
      "step": 19100
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.0021906602196395397,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.0518,
      "step": 19110
    },
    {
      "epoch": 5.462857142857143,
      "grad_norm": 0.003046529134735465,
      "learning_rate": 1.2716190476190477e-05,
      "loss": 0.0001,
      "step": 19120
    },
    {
      "epoch": 5.465714285714285,
      "grad_norm": 0.012821116484701633,
      "learning_rate": 1.2712380952380953e-05,
      "loss": 0.0001,
      "step": 19130
    },
    {
      "epoch": 5.468571428571429,
      "grad_norm": 0.014641618356108665,
      "learning_rate": 1.270857142857143e-05,
      "loss": 0.0001,
      "step": 19140
    },
    {
      "epoch": 5.4714285714285715,
      "grad_norm": 0.003997632302343845,
      "learning_rate": 1.2704761904761906e-05,
      "loss": 0.0002,
      "step": 19150
    },
    {
      "epoch": 5.474285714285714,
      "grad_norm": 0.004545839503407478,
      "learning_rate": 1.2700952380952383e-05,
      "loss": 0.0001,
      "step": 19160
    },
    {
      "epoch": 5.477142857142857,
      "grad_norm": 0.0005870918394066393,
      "learning_rate": 1.2697142857142859e-05,
      "loss": 0.0001,
      "step": 19170
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.0004403132479637861,
      "learning_rate": 1.2693333333333336e-05,
      "loss": 0.0001,
      "step": 19180
    },
    {
      "epoch": 5.482857142857143,
      "grad_norm": 0.05432701110839844,
      "learning_rate": 1.2689523809523812e-05,
      "loss": 0.0,
      "step": 19190
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 0.02029695361852646,
      "learning_rate": 1.2685714285714286e-05,
      "loss": 0.0001,
      "step": 19200
    },
    {
      "epoch": 5.488571428571428,
      "grad_norm": 0.0012437828117981553,
      "learning_rate": 1.2681904761904763e-05,
      "loss": 0.0,
      "step": 19210
    },
    {
      "epoch": 5.491428571428571,
      "grad_norm": 0.00032143128919415176,
      "learning_rate": 1.2678095238095238e-05,
      "loss": 0.0001,
      "step": 19220
    },
    {
      "epoch": 5.494285714285715,
      "grad_norm": 0.00018936755077447742,
      "learning_rate": 1.2674285714285714e-05,
      "loss": 0.0,
      "step": 19230
    },
    {
      "epoch": 5.497142857142857,
      "grad_norm": 0.00032973516499623656,
      "learning_rate": 1.2670476190476191e-05,
      "loss": 0.0,
      "step": 19240
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.0005126945907250047,
      "learning_rate": 1.2666666666666667e-05,
      "loss": 0.0,
      "step": 19250
    },
    {
      "epoch": 5.502857142857143,
      "grad_norm": 0.00020606274483725429,
      "learning_rate": 1.2662857142857144e-05,
      "loss": 0.068,
      "step": 19260
    },
    {
      "epoch": 5.505714285714285,
      "grad_norm": 0.001157936523668468,
      "learning_rate": 1.265904761904762e-05,
      "loss": 0.0,
      "step": 19270
    },
    {
      "epoch": 5.508571428571429,
      "grad_norm": 0.00037757903919555247,
      "learning_rate": 1.2655238095238095e-05,
      "loss": 0.0001,
      "step": 19280
    },
    {
      "epoch": 5.511428571428572,
      "grad_norm": 0.00693844398483634,
      "learning_rate": 1.2651428571428573e-05,
      "loss": 0.1564,
      "step": 19290
    },
    {
      "epoch": 5.514285714285714,
      "grad_norm": 0.0013485454255715013,
      "learning_rate": 1.2647619047619048e-05,
      "loss": 0.0,
      "step": 19300
    },
    {
      "epoch": 5.517142857142857,
      "grad_norm": 0.0011508859461173415,
      "learning_rate": 1.2643809523809525e-05,
      "loss": 0.0001,
      "step": 19310
    },
    {
      "epoch": 5.52,
      "grad_norm": 42.98573303222656,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.2776,
      "step": 19320
    },
    {
      "epoch": 5.522857142857143,
      "grad_norm": 0.0021844885777682066,
      "learning_rate": 1.2636190476190478e-05,
      "loss": 0.0001,
      "step": 19330
    },
    {
      "epoch": 5.525714285714286,
      "grad_norm": 0.0029609650373458862,
      "learning_rate": 1.2632380952380954e-05,
      "loss": 0.2094,
      "step": 19340
    },
    {
      "epoch": 5.5285714285714285,
      "grad_norm": 0.017754200845956802,
      "learning_rate": 1.262857142857143e-05,
      "loss": 0.0058,
      "step": 19350
    },
    {
      "epoch": 5.531428571428571,
      "grad_norm": 0.0020304271019995213,
      "learning_rate": 1.2624761904761907e-05,
      "loss": 0.0002,
      "step": 19360
    },
    {
      "epoch": 5.534285714285714,
      "grad_norm": 0.022236645221710205,
      "learning_rate": 1.2620952380952382e-05,
      "loss": 0.0003,
      "step": 19370
    },
    {
      "epoch": 5.537142857142857,
      "grad_norm": 0.0010840275790542364,
      "learning_rate": 1.261714285714286e-05,
      "loss": 0.0876,
      "step": 19380
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.002600038191303611,
      "learning_rate": 1.2613333333333335e-05,
      "loss": 0.0003,
      "step": 19390
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 0.005595389287918806,
      "learning_rate": 1.260952380952381e-05,
      "loss": 0.1178,
      "step": 19400
    },
    {
      "epoch": 5.545714285714285,
      "grad_norm": 0.005566804204136133,
      "learning_rate": 1.2605714285714288e-05,
      "loss": 0.0001,
      "step": 19410
    },
    {
      "epoch": 5.548571428571429,
      "grad_norm": 0.0007892574649304152,
      "learning_rate": 1.2601904761904762e-05,
      "loss": 0.0001,
      "step": 19420
    },
    {
      "epoch": 5.551428571428572,
      "grad_norm": 0.004129866603761911,
      "learning_rate": 1.2598095238095237e-05,
      "loss": 0.0,
      "step": 19430
    },
    {
      "epoch": 5.554285714285714,
      "grad_norm": 0.0071797906421124935,
      "learning_rate": 1.2594285714285715e-05,
      "loss": 0.0,
      "step": 19440
    },
    {
      "epoch": 5.557142857142857,
      "grad_norm": 0.1651856005191803,
      "learning_rate": 1.259047619047619e-05,
      "loss": 0.0053,
      "step": 19450
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 0.0006063246401026845,
      "learning_rate": 1.2586666666666668e-05,
      "loss": 0.0,
      "step": 19460
    },
    {
      "epoch": 5.562857142857143,
      "grad_norm": 0.0009519272716715932,
      "learning_rate": 1.2582857142857143e-05,
      "loss": 0.0001,
      "step": 19470
    },
    {
      "epoch": 5.565714285714286,
      "grad_norm": 0.0015199417248368263,
      "learning_rate": 1.257904761904762e-05,
      "loss": 0.0009,
      "step": 19480
    },
    {
      "epoch": 5.5685714285714285,
      "grad_norm": 0.001647832803428173,
      "learning_rate": 1.2575238095238096e-05,
      "loss": 0.1896,
      "step": 19490
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.000587913382332772,
      "learning_rate": 1.2571428571428572e-05,
      "loss": 0.0001,
      "step": 19500
    },
    {
      "epoch": 5.574285714285715,
      "grad_norm": 0.006840952672064304,
      "learning_rate": 1.2567619047619049e-05,
      "loss": 0.0841,
      "step": 19510
    },
    {
      "epoch": 5.577142857142857,
      "grad_norm": 0.0016281194984912872,
      "learning_rate": 1.2563809523809524e-05,
      "loss": 0.0,
      "step": 19520
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.0005246816435828805,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.0001,
      "step": 19530
    },
    {
      "epoch": 5.582857142857143,
      "grad_norm": 0.001488237758167088,
      "learning_rate": 1.2556190476190477e-05,
      "loss": 0.0001,
      "step": 19540
    },
    {
      "epoch": 5.585714285714285,
      "grad_norm": 104.25712585449219,
      "learning_rate": 1.2552380952380953e-05,
      "loss": 0.0704,
      "step": 19550
    },
    {
      "epoch": 5.588571428571429,
      "grad_norm": 0.000297369813779369,
      "learning_rate": 1.254857142857143e-05,
      "loss": 0.0017,
      "step": 19560
    },
    {
      "epoch": 5.591428571428572,
      "grad_norm": 0.003433801932260394,
      "learning_rate": 1.2544761904761906e-05,
      "loss": 0.0,
      "step": 19570
    },
    {
      "epoch": 5.594285714285714,
      "grad_norm": 0.00019636278739199042,
      "learning_rate": 1.2540952380952383e-05,
      "loss": 0.0,
      "step": 19580
    },
    {
      "epoch": 5.597142857142857,
      "grad_norm": 0.0018928507342934608,
      "learning_rate": 1.2537142857142859e-05,
      "loss": 0.0,
      "step": 19590
    },
    {
      "epoch": 5.6,
      "grad_norm": 46.25111770629883,
      "learning_rate": 1.2533333333333336e-05,
      "loss": 0.3678,
      "step": 19600
    },
    {
      "epoch": 5.602857142857143,
      "grad_norm": 0.004463743418455124,
      "learning_rate": 1.2529523809523811e-05,
      "loss": 0.0007,
      "step": 19610
    },
    {
      "epoch": 5.605714285714286,
      "grad_norm": 0.013369043357670307,
      "learning_rate": 1.2525714285714287e-05,
      "loss": 0.0001,
      "step": 19620
    },
    {
      "epoch": 5.6085714285714285,
      "grad_norm": 0.00841883011162281,
      "learning_rate": 1.2521904761904764e-05,
      "loss": 0.0002,
      "step": 19630
    },
    {
      "epoch": 5.611428571428571,
      "grad_norm": 0.004600129555910826,
      "learning_rate": 1.2518095238095238e-05,
      "loss": 0.0,
      "step": 19640
    },
    {
      "epoch": 5.614285714285714,
      "grad_norm": 0.03317089378833771,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 0.0001,
      "step": 19650
    },
    {
      "epoch": 5.617142857142857,
      "grad_norm": 0.00039353675674647093,
      "learning_rate": 1.2510476190476191e-05,
      "loss": 0.0003,
      "step": 19660
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.0006111607071943581,
      "learning_rate": 1.2506666666666667e-05,
      "loss": 0.0,
      "step": 19670
    },
    {
      "epoch": 5.622857142857143,
      "grad_norm": 41.97065353393555,
      "learning_rate": 1.2502857142857144e-05,
      "loss": 0.3753,
      "step": 19680
    },
    {
      "epoch": 5.6257142857142854,
      "grad_norm": 0.0007000808254815638,
      "learning_rate": 1.249904761904762e-05,
      "loss": 0.0003,
      "step": 19690
    },
    {
      "epoch": 5.628571428571428,
      "grad_norm": 0.0005969756748527288,
      "learning_rate": 1.2495238095238095e-05,
      "loss": 0.0002,
      "step": 19700
    },
    {
      "epoch": 5.631428571428572,
      "grad_norm": 0.019514592364430428,
      "learning_rate": 1.2491428571428572e-05,
      "loss": 0.0001,
      "step": 19710
    },
    {
      "epoch": 5.634285714285714,
      "grad_norm": 0.00027337201754562557,
      "learning_rate": 1.2487619047619048e-05,
      "loss": 0.0,
      "step": 19720
    },
    {
      "epoch": 5.637142857142857,
      "grad_norm": 0.0009032777743414044,
      "learning_rate": 1.2483809523809525e-05,
      "loss": 0.0,
      "step": 19730
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.005979018751531839,
      "learning_rate": 1.248e-05,
      "loss": 0.0,
      "step": 19740
    },
    {
      "epoch": 5.642857142857143,
      "grad_norm": 0.0003391955979168415,
      "learning_rate": 1.2476190476190478e-05,
      "loss": 0.0,
      "step": 19750
    },
    {
      "epoch": 5.645714285714286,
      "grad_norm": 0.003542351769283414,
      "learning_rate": 1.2472380952380954e-05,
      "loss": 0.0,
      "step": 19760
    },
    {
      "epoch": 5.648571428571429,
      "grad_norm": 0.00047019682824611664,
      "learning_rate": 1.246857142857143e-05,
      "loss": 0.0,
      "step": 19770
    },
    {
      "epoch": 5.651428571428571,
      "grad_norm": 0.0002942793071269989,
      "learning_rate": 1.2464761904761907e-05,
      "loss": 0.0004,
      "step": 19780
    },
    {
      "epoch": 5.654285714285714,
      "grad_norm": 0.05529084801673889,
      "learning_rate": 1.2460952380952382e-05,
      "loss": 0.0001,
      "step": 19790
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 0.0001696682593319565,
      "learning_rate": 1.245714285714286e-05,
      "loss": 0.0001,
      "step": 19800
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.00016942153160925955,
      "learning_rate": 1.2453333333333335e-05,
      "loss": 0.1185,
      "step": 19810
    },
    {
      "epoch": 5.662857142857143,
      "grad_norm": 0.0026661064475774765,
      "learning_rate": 1.244952380952381e-05,
      "loss": 0.0,
      "step": 19820
    },
    {
      "epoch": 5.6657142857142855,
      "grad_norm": 0.0001667455944698304,
      "learning_rate": 1.2445714285714288e-05,
      "loss": 0.0001,
      "step": 19830
    },
    {
      "epoch": 5.668571428571429,
      "grad_norm": 0.0006790572660975158,
      "learning_rate": 1.2441904761904763e-05,
      "loss": 0.0,
      "step": 19840
    },
    {
      "epoch": 5.671428571428572,
      "grad_norm": 0.00013934662274550647,
      "learning_rate": 1.243809523809524e-05,
      "loss": 0.0,
      "step": 19850
    },
    {
      "epoch": 5.674285714285714,
      "grad_norm": 0.003154781647026539,
      "learning_rate": 1.2434285714285715e-05,
      "loss": 0.0,
      "step": 19860
    },
    {
      "epoch": 5.677142857142857,
      "grad_norm": 0.0041239201091229916,
      "learning_rate": 1.243047619047619e-05,
      "loss": 0.0,
      "step": 19870
    },
    {
      "epoch": 5.68,
      "grad_norm": 6.10656788921915e-05,
      "learning_rate": 1.2426666666666667e-05,
      "loss": 0.0,
      "step": 19880
    },
    {
      "epoch": 5.682857142857143,
      "grad_norm": 0.0004694981616921723,
      "learning_rate": 1.2422857142857143e-05,
      "loss": 0.0,
      "step": 19890
    },
    {
      "epoch": 5.685714285714286,
      "grad_norm": 0.00011474620259832591,
      "learning_rate": 1.241904761904762e-05,
      "loss": 0.0291,
      "step": 19900
    },
    {
      "epoch": 5.688571428571429,
      "grad_norm": 0.0002727973915170878,
      "learning_rate": 1.2415238095238096e-05,
      "loss": 0.0,
      "step": 19910
    },
    {
      "epoch": 5.691428571428571,
      "grad_norm": 0.0001553248439449817,
      "learning_rate": 1.2411428571428571e-05,
      "loss": 0.0001,
      "step": 19920
    },
    {
      "epoch": 5.694285714285714,
      "grad_norm": 0.00023387139663100243,
      "learning_rate": 1.2407619047619049e-05,
      "loss": 0.0,
      "step": 19930
    },
    {
      "epoch": 5.6971428571428575,
      "grad_norm": 0.00021584340720437467,
      "learning_rate": 1.2403809523809524e-05,
      "loss": 0.0001,
      "step": 19940
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.00011164208990521729,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0,
      "step": 19950
    },
    {
      "epoch": 5.702857142857143,
      "grad_norm": 0.0003364427830092609,
      "learning_rate": 1.2396190476190477e-05,
      "loss": 0.0735,
      "step": 19960
    },
    {
      "epoch": 5.7057142857142855,
      "grad_norm": 0.00010655744699761271,
      "learning_rate": 1.2392380952380953e-05,
      "loss": 0.0001,
      "step": 19970
    },
    {
      "epoch": 5.708571428571428,
      "grad_norm": 0.010378857143223286,
      "learning_rate": 1.238857142857143e-05,
      "loss": 0.0,
      "step": 19980
    },
    {
      "epoch": 5.711428571428572,
      "grad_norm": 9.791430056793615e-05,
      "learning_rate": 1.2384761904761906e-05,
      "loss": 0.0,
      "step": 19990
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.0002598654245957732,
      "learning_rate": 1.2380952380952383e-05,
      "loss": 0.001,
      "step": 20000
    },
    {
      "epoch": 5.717142857142857,
      "grad_norm": 0.00012698340287897736,
      "learning_rate": 1.2377142857142858e-05,
      "loss": 0.0,
      "step": 20010
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.0007246980094350874,
      "learning_rate": 1.2373333333333336e-05,
      "loss": 0.0,
      "step": 20020
    },
    {
      "epoch": 5.722857142857142,
      "grad_norm": 0.001341500785201788,
      "learning_rate": 1.2369523809523811e-05,
      "loss": 0.0,
      "step": 20030
    },
    {
      "epoch": 5.725714285714286,
      "grad_norm": 0.00011257795267738402,
      "learning_rate": 1.2365714285714287e-05,
      "loss": 0.0,
      "step": 20040
    },
    {
      "epoch": 5.728571428571429,
      "grad_norm": 0.00043333027861081064,
      "learning_rate": 1.2361904761904764e-05,
      "loss": 0.0,
      "step": 20050
    },
    {
      "epoch": 5.731428571428571,
      "grad_norm": 8.56019469210878e-05,
      "learning_rate": 1.235809523809524e-05,
      "loss": 0.0,
      "step": 20060
    },
    {
      "epoch": 5.734285714285714,
      "grad_norm": 0.0001419087639078498,
      "learning_rate": 1.2354285714285714e-05,
      "loss": 0.0,
      "step": 20070
    },
    {
      "epoch": 5.737142857142857,
      "grad_norm": 0.0001807454536901787,
      "learning_rate": 1.2350476190476191e-05,
      "loss": 0.0,
      "step": 20080
    },
    {
      "epoch": 5.74,
      "grad_norm": 82.2369384765625,
      "learning_rate": 1.2346666666666666e-05,
      "loss": 0.0036,
      "step": 20090
    },
    {
      "epoch": 5.742857142857143,
      "grad_norm": 4.46742087660823e-05,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.0,
      "step": 20100
    },
    {
      "epoch": 5.7457142857142856,
      "grad_norm": 8.50260621518828e-05,
      "learning_rate": 1.233904761904762e-05,
      "loss": 0.0,
      "step": 20110
    },
    {
      "epoch": 5.748571428571428,
      "grad_norm": 5.404701369116083e-05,
      "learning_rate": 1.2335238095238095e-05,
      "loss": 0.0,
      "step": 20120
    },
    {
      "epoch": 5.751428571428572,
      "grad_norm": 0.00013131063315086067,
      "learning_rate": 1.2331428571428572e-05,
      "loss": 0.0,
      "step": 20130
    },
    {
      "epoch": 5.7542857142857144,
      "grad_norm": 0.0027883402071893215,
      "learning_rate": 1.2327619047619048e-05,
      "loss": 0.0,
      "step": 20140
    },
    {
      "epoch": 5.757142857142857,
      "grad_norm": 6.201244104886428e-05,
      "learning_rate": 1.2323809523809525e-05,
      "loss": 0.0,
      "step": 20150
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.0029158126562833786,
      "learning_rate": 1.232e-05,
      "loss": 0.0,
      "step": 20160
    },
    {
      "epoch": 5.762857142857143,
      "grad_norm": 0.006813960149884224,
      "learning_rate": 1.2316190476190478e-05,
      "loss": 0.0002,
      "step": 20170
    },
    {
      "epoch": 5.765714285714286,
      "grad_norm": 2.819059133529663,
      "learning_rate": 1.2312380952380953e-05,
      "loss": 0.0003,
      "step": 20180
    },
    {
      "epoch": 5.768571428571429,
      "grad_norm": 0.002120980992913246,
      "learning_rate": 1.2308571428571429e-05,
      "loss": 0.0,
      "step": 20190
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 0.0002502170973457396,
      "learning_rate": 1.2304761904761906e-05,
      "loss": 0.0498,
      "step": 20200
    },
    {
      "epoch": 5.774285714285714,
      "grad_norm": 0.0006328014424070716,
      "learning_rate": 1.2300952380952382e-05,
      "loss": 0.0,
      "step": 20210
    },
    {
      "epoch": 5.777142857142858,
      "grad_norm": 0.00023779839102644473,
      "learning_rate": 1.229714285714286e-05,
      "loss": 0.0,
      "step": 20220
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.009404895827174187,
      "learning_rate": 1.2293333333333335e-05,
      "loss": 0.0001,
      "step": 20230
    },
    {
      "epoch": 5.782857142857143,
      "grad_norm": 0.00020176226098556072,
      "learning_rate": 1.228952380952381e-05,
      "loss": 0.0004,
      "step": 20240
    },
    {
      "epoch": 5.785714285714286,
      "grad_norm": 0.0008546694298274815,
      "learning_rate": 1.2285714285714288e-05,
      "loss": 0.0,
      "step": 20250
    },
    {
      "epoch": 5.788571428571428,
      "grad_norm": 8.626023918623105e-05,
      "learning_rate": 1.2281904761904763e-05,
      "loss": 0.0,
      "step": 20260
    },
    {
      "epoch": 5.791428571428572,
      "grad_norm": 0.00025347829796373844,
      "learning_rate": 1.227809523809524e-05,
      "loss": 0.0,
      "step": 20270
    },
    {
      "epoch": 5.7942857142857145,
      "grad_norm": 7.610064494656399e-05,
      "learning_rate": 1.2274285714285716e-05,
      "loss": 0.0003,
      "step": 20280
    },
    {
      "epoch": 5.797142857142857,
      "grad_norm": 6.044221299816854e-05,
      "learning_rate": 1.227047619047619e-05,
      "loss": 0.0,
      "step": 20290
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.00015799705579411238,
      "learning_rate": 1.2266666666666667e-05,
      "loss": 0.0,
      "step": 20300
    },
    {
      "epoch": 5.8028571428571425,
      "grad_norm": 5.62149471079465e-05,
      "learning_rate": 1.2262857142857143e-05,
      "loss": 0.0,
      "step": 20310
    },
    {
      "epoch": 5.805714285714286,
      "grad_norm": 0.00033085988252423704,
      "learning_rate": 1.225904761904762e-05,
      "loss": 0.0,
      "step": 20320
    },
    {
      "epoch": 5.808571428571429,
      "grad_norm": 3.8729285734007135e-05,
      "learning_rate": 1.2255238095238096e-05,
      "loss": 0.0,
      "step": 20330
    },
    {
      "epoch": 5.811428571428571,
      "grad_norm": 2.8161750378785655e-05,
      "learning_rate": 1.2251428571428571e-05,
      "loss": 0.0,
      "step": 20340
    },
    {
      "epoch": 5.814285714285714,
      "grad_norm": 6.632235454162583e-05,
      "learning_rate": 1.2247619047619049e-05,
      "loss": 0.002,
      "step": 20350
    },
    {
      "epoch": 5.817142857142857,
      "grad_norm": 0.0013039964251220226,
      "learning_rate": 1.2243809523809524e-05,
      "loss": 0.0002,
      "step": 20360
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.9983550373581238e-05,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.0008,
      "step": 20370
    },
    {
      "epoch": 5.822857142857143,
      "grad_norm": 2.9012097002123483e-05,
      "learning_rate": 1.2236190476190477e-05,
      "loss": 0.1559,
      "step": 20380
    },
    {
      "epoch": 5.825714285714286,
      "grad_norm": 3.740080865100026e-05,
      "learning_rate": 1.2232380952380953e-05,
      "loss": 0.0,
      "step": 20390
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 7.751942030154169e-05,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.0,
      "step": 20400
    },
    {
      "epoch": 5.831428571428571,
      "grad_norm": 0.00015484419418498874,
      "learning_rate": 1.2224761904761905e-05,
      "loss": 0.0,
      "step": 20410
    },
    {
      "epoch": 5.8342857142857145,
      "grad_norm": 0.010327744297683239,
      "learning_rate": 1.2220952380952383e-05,
      "loss": 0.0,
      "step": 20420
    },
    {
      "epoch": 5.837142857142857,
      "grad_norm": 6.743668927811086e-05,
      "learning_rate": 1.2217142857142858e-05,
      "loss": 0.0,
      "step": 20430
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.00022329438070300967,
      "learning_rate": 1.2213333333333336e-05,
      "loss": 0.0,
      "step": 20440
    },
    {
      "epoch": 5.8428571428571425,
      "grad_norm": 0.00011458693916210905,
      "learning_rate": 1.2209523809523811e-05,
      "loss": 0.0,
      "step": 20450
    },
    {
      "epoch": 5.845714285714286,
      "grad_norm": 6.711626338073984e-05,
      "learning_rate": 1.2205714285714287e-05,
      "loss": 0.0,
      "step": 20460
    },
    {
      "epoch": 5.848571428571429,
      "grad_norm": 0.00015685180551372468,
      "learning_rate": 1.2201904761904764e-05,
      "loss": 0.0,
      "step": 20470
    },
    {
      "epoch": 5.851428571428571,
      "grad_norm": 0.07394269108772278,
      "learning_rate": 1.219809523809524e-05,
      "loss": 0.0,
      "step": 20480
    },
    {
      "epoch": 5.854285714285714,
      "grad_norm": 1.9859023094177246,
      "learning_rate": 1.2194285714285717e-05,
      "loss": 0.0001,
      "step": 20490
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 6.663399835815653e-05,
      "learning_rate": 1.2190476190476192e-05,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 5.86,
      "grad_norm": 46.34199523925781,
      "learning_rate": 1.2186666666666666e-05,
      "loss": 0.189,
      "step": 20510
    },
    {
      "epoch": 5.862857142857143,
      "grad_norm": 0.0035767981316894293,
      "learning_rate": 1.2182857142857144e-05,
      "loss": 0.0,
      "step": 20520
    },
    {
      "epoch": 5.865714285714286,
      "grad_norm": 0.018808988854289055,
      "learning_rate": 1.217904761904762e-05,
      "loss": 0.0,
      "step": 20530
    },
    {
      "epoch": 5.868571428571428,
      "grad_norm": 7.418097811751068e-05,
      "learning_rate": 1.2175238095238095e-05,
      "loss": 0.0,
      "step": 20540
    },
    {
      "epoch": 5.871428571428572,
      "grad_norm": 7.336192356888205e-05,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.165,
      "step": 20550
    },
    {
      "epoch": 5.8742857142857146,
      "grad_norm": 0.007511544041335583,
      "learning_rate": 1.2167619047619048e-05,
      "loss": 0.0001,
      "step": 20560
    },
    {
      "epoch": 5.877142857142857,
      "grad_norm": 0.004160588141530752,
      "learning_rate": 1.2163809523809525e-05,
      "loss": 0.0833,
      "step": 20570
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.003877646289765835,
      "learning_rate": 1.216e-05,
      "loss": 0.0001,
      "step": 20580
    },
    {
      "epoch": 5.882857142857143,
      "grad_norm": 0.00013788211799692363,
      "learning_rate": 1.2156190476190478e-05,
      "loss": 0.0,
      "step": 20590
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 0.025685623288154602,
      "learning_rate": 1.2152380952380953e-05,
      "loss": 0.0001,
      "step": 20600
    },
    {
      "epoch": 5.888571428571429,
      "grad_norm": 0.0008809113060124218,
      "learning_rate": 1.2148571428571429e-05,
      "loss": 0.0,
      "step": 20610
    },
    {
      "epoch": 5.8914285714285715,
      "grad_norm": 5.0138853112002835e-05,
      "learning_rate": 1.2144761904761906e-05,
      "loss": 0.1849,
      "step": 20620
    },
    {
      "epoch": 5.894285714285714,
      "grad_norm": 0.0009849403286352754,
      "learning_rate": 1.2140952380952382e-05,
      "loss": 0.0,
      "step": 20630
    },
    {
      "epoch": 5.897142857142857,
      "grad_norm": 0.023276852443814278,
      "learning_rate": 1.2137142857142859e-05,
      "loss": 0.2246,
      "step": 20640
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.0014189942739903927,
      "learning_rate": 1.2133333333333335e-05,
      "loss": 0.0,
      "step": 20650
    },
    {
      "epoch": 5.902857142857143,
      "grad_norm": 0.011648127809166908,
      "learning_rate": 1.212952380952381e-05,
      "loss": 0.0,
      "step": 20660
    },
    {
      "epoch": 5.905714285714286,
      "grad_norm": 0.0011647266801446676,
      "learning_rate": 1.2125714285714287e-05,
      "loss": 0.0001,
      "step": 20670
    },
    {
      "epoch": 5.908571428571428,
      "grad_norm": 0.11615031212568283,
      "learning_rate": 1.2121904761904763e-05,
      "loss": 0.0004,
      "step": 20680
    },
    {
      "epoch": 5.911428571428571,
      "grad_norm": 0.0517936572432518,
      "learning_rate": 1.211809523809524e-05,
      "loss": 0.0001,
      "step": 20690
    },
    {
      "epoch": 5.914285714285715,
      "grad_norm": 0.0002552054065745324,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.1597,
      "step": 20700
    },
    {
      "epoch": 5.917142857142857,
      "grad_norm": 0.0002243057533632964,
      "learning_rate": 1.2110476190476193e-05,
      "loss": 0.163,
      "step": 20710
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.034257661551237106,
      "learning_rate": 1.2106666666666667e-05,
      "loss": 0.0001,
      "step": 20720
    },
    {
      "epoch": 5.922857142857143,
      "grad_norm": 0.012862500734627247,
      "learning_rate": 1.2102857142857143e-05,
      "loss": 0.0001,
      "step": 20730
    },
    {
      "epoch": 5.925714285714285,
      "grad_norm": 0.0005934835644438863,
      "learning_rate": 1.209904761904762e-05,
      "loss": 0.0004,
      "step": 20740
    },
    {
      "epoch": 5.928571428571429,
      "grad_norm": 0.000992538291029632,
      "learning_rate": 1.2095238095238096e-05,
      "loss": 0.0002,
      "step": 20750
    },
    {
      "epoch": 5.9314285714285715,
      "grad_norm": 0.003644317854195833,
      "learning_rate": 1.2091428571428571e-05,
      "loss": 0.0001,
      "step": 20760
    },
    {
      "epoch": 5.934285714285714,
      "grad_norm": 0.0005644068005494773,
      "learning_rate": 1.2087619047619048e-05,
      "loss": 0.0,
      "step": 20770
    },
    {
      "epoch": 5.937142857142857,
      "grad_norm": 0.00028983611264266074,
      "learning_rate": 1.2083809523809524e-05,
      "loss": 0.0001,
      "step": 20780
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 0.00014512997586280107,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.0,
      "step": 20790
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 0.000232284190133214,
      "learning_rate": 1.2076190476190477e-05,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 5.945714285714286,
      "grad_norm": 0.00012189140397822484,
      "learning_rate": 1.2072380952380952e-05,
      "loss": 0.0029,
      "step": 20810
    },
    {
      "epoch": 5.948571428571428,
      "grad_norm": 0.0001324066543020308,
      "learning_rate": 1.206857142857143e-05,
      "loss": 0.0,
      "step": 20820
    },
    {
      "epoch": 5.951428571428571,
      "grad_norm": 0.0020777485333383083,
      "learning_rate": 1.2064761904761905e-05,
      "loss": 0.0001,
      "step": 20830
    },
    {
      "epoch": 5.954285714285715,
      "grad_norm": 0.00046844923053868115,
      "learning_rate": 1.2060952380952383e-05,
      "loss": 0.0296,
      "step": 20840
    },
    {
      "epoch": 5.957142857142857,
      "grad_norm": 0.0010674756485968828,
      "learning_rate": 1.2057142857142858e-05,
      "loss": 0.0,
      "step": 20850
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.001292797620408237,
      "learning_rate": 1.2053333333333335e-05,
      "loss": 0.0,
      "step": 20860
    },
    {
      "epoch": 5.962857142857143,
      "grad_norm": 0.0006119544268585742,
      "learning_rate": 1.2049523809523811e-05,
      "loss": 0.0,
      "step": 20870
    },
    {
      "epoch": 5.965714285714286,
      "grad_norm": 8.39166168589145e-05,
      "learning_rate": 1.2045714285714287e-05,
      "loss": 0.0006,
      "step": 20880
    },
    {
      "epoch": 5.968571428571429,
      "grad_norm": 4.90147212985903e-05,
      "learning_rate": 1.2041904761904764e-05,
      "loss": 0.0,
      "step": 20890
    },
    {
      "epoch": 5.9714285714285715,
      "grad_norm": 4.2778188799275085e-05,
      "learning_rate": 1.203809523809524e-05,
      "loss": 0.0,
      "step": 20900
    },
    {
      "epoch": 5.974285714285714,
      "grad_norm": 0.00027857007808052003,
      "learning_rate": 1.2034285714285717e-05,
      "loss": 0.0,
      "step": 20910
    },
    {
      "epoch": 5.977142857142857,
      "grad_norm": 5.539058838621713e-05,
      "learning_rate": 1.2030476190476192e-05,
      "loss": 0.0,
      "step": 20920
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.0011823712848126888,
      "learning_rate": 1.202666666666667e-05,
      "loss": 0.0357,
      "step": 20930
    },
    {
      "epoch": 5.982857142857143,
      "grad_norm": 5.252699338598177e-05,
      "learning_rate": 1.2022857142857143e-05,
      "loss": 0.0003,
      "step": 20940
    },
    {
      "epoch": 5.985714285714286,
      "grad_norm": 0.003566567087545991,
      "learning_rate": 1.2019047619047619e-05,
      "loss": 0.0,
      "step": 20950
    },
    {
      "epoch": 5.988571428571428,
      "grad_norm": 7.243862637551501e-05,
      "learning_rate": 1.2015238095238095e-05,
      "loss": 0.1852,
      "step": 20960
    },
    {
      "epoch": 5.991428571428571,
      "grad_norm": 0.0007200567633844912,
      "learning_rate": 1.2011428571428572e-05,
      "loss": 0.0,
      "step": 20970
    },
    {
      "epoch": 5.994285714285715,
      "grad_norm": 0.00124292669352144,
      "learning_rate": 1.2007619047619047e-05,
      "loss": 0.0066,
      "step": 20980
    },
    {
      "epoch": 5.997142857142857,
      "grad_norm": 6.556574226124212e-05,
      "learning_rate": 1.2003809523809525e-05,
      "loss": 0.0,
      "step": 20990
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.00012320584210101515,
      "learning_rate": 1.2e-05,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.982,
      "eval_f1": 0.891566265060241,
      "eval_loss": 0.1556379646062851,
      "eval_precision": 0.9098360655737705,
      "eval_recall": 0.8740157480314961,
      "eval_runtime": 351.3507,
      "eval_samples_per_second": 8.538,
      "eval_steps_per_second": 2.135,
      "step": 21000
    },
    {
      "epoch": 6.002857142857143,
      "grad_norm": 0.0002724038204178214,
      "learning_rate": 1.1996190476190478e-05,
      "loss": 0.0,
      "step": 21010
    },
    {
      "epoch": 6.005714285714285,
      "grad_norm": 4.649608308682218e-05,
      "learning_rate": 1.1992380952380953e-05,
      "loss": 0.0,
      "step": 21020
    },
    {
      "epoch": 6.008571428571429,
      "grad_norm": 4.2802708776434883e-05,
      "learning_rate": 1.1988571428571429e-05,
      "loss": 0.0,
      "step": 21030
    },
    {
      "epoch": 6.011428571428572,
      "grad_norm": 3.5630928323371336e-05,
      "learning_rate": 1.1984761904761906e-05,
      "loss": 0.0,
      "step": 21040
    },
    {
      "epoch": 6.014285714285714,
      "grad_norm": 0.00468429597094655,
      "learning_rate": 1.1980952380952382e-05,
      "loss": 0.0001,
      "step": 21050
    },
    {
      "epoch": 6.017142857142857,
      "grad_norm": 0.0041617779061198235,
      "learning_rate": 1.1977142857142859e-05,
      "loss": 0.0,
      "step": 21060
    },
    {
      "epoch": 6.02,
      "grad_norm": 4.5204349589766935e-05,
      "learning_rate": 1.1973333333333334e-05,
      "loss": 0.0,
      "step": 21070
    },
    {
      "epoch": 6.022857142857143,
      "grad_norm": 0.0114310747012496,
      "learning_rate": 1.196952380952381e-05,
      "loss": 0.0001,
      "step": 21080
    },
    {
      "epoch": 6.025714285714286,
      "grad_norm": 0.0012785702710971236,
      "learning_rate": 1.1965714285714287e-05,
      "loss": 0.0001,
      "step": 21090
    },
    {
      "epoch": 6.0285714285714285,
      "grad_norm": 0.00011511750926729292,
      "learning_rate": 1.1961904761904763e-05,
      "loss": 0.0,
      "step": 21100
    },
    {
      "epoch": 6.031428571428571,
      "grad_norm": 2.8708471290883608e-05,
      "learning_rate": 1.195809523809524e-05,
      "loss": 0.0,
      "step": 21110
    },
    {
      "epoch": 6.034285714285715,
      "grad_norm": 0.00017131117056123912,
      "learning_rate": 1.1954285714285716e-05,
      "loss": 0.181,
      "step": 21120
    },
    {
      "epoch": 6.037142857142857,
      "grad_norm": 0.00021911035582888871,
      "learning_rate": 1.1950476190476193e-05,
      "loss": 0.4136,
      "step": 21130
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.0006521555478684604,
      "learning_rate": 1.1946666666666669e-05,
      "loss": 0.0001,
      "step": 21140
    },
    {
      "epoch": 6.042857142857143,
      "grad_norm": 16.539634704589844,
      "learning_rate": 1.1942857142857144e-05,
      "loss": 0.2107,
      "step": 21150
    },
    {
      "epoch": 6.045714285714285,
      "grad_norm": 0.0011369636049494147,
      "learning_rate": 1.193904761904762e-05,
      "loss": 0.0003,
      "step": 21160
    },
    {
      "epoch": 6.048571428571429,
      "grad_norm": 0.000582139240577817,
      "learning_rate": 1.1935238095238095e-05,
      "loss": 0.0,
      "step": 21170
    },
    {
      "epoch": 6.051428571428572,
      "grad_norm": 0.0004389867826830596,
      "learning_rate": 1.1931428571428571e-05,
      "loss": 0.0001,
      "step": 21180
    },
    {
      "epoch": 6.054285714285714,
      "grad_norm": 0.0007141075329855084,
      "learning_rate": 1.1927619047619048e-05,
      "loss": 0.0001,
      "step": 21190
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 0.003940095193684101,
      "learning_rate": 1.1923809523809524e-05,
      "loss": 0.0001,
      "step": 21200
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.0004814598069060594,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.0,
      "step": 21210
    },
    {
      "epoch": 6.062857142857143,
      "grad_norm": 0.008475477807223797,
      "learning_rate": 1.1916190476190477e-05,
      "loss": 0.0,
      "step": 21220
    },
    {
      "epoch": 6.065714285714286,
      "grad_norm": 0.00022316288959700614,
      "learning_rate": 1.1912380952380952e-05,
      "loss": 0.0001,
      "step": 21230
    },
    {
      "epoch": 6.0685714285714285,
      "grad_norm": 0.0007137947832234204,
      "learning_rate": 1.190857142857143e-05,
      "loss": 0.0001,
      "step": 21240
    },
    {
      "epoch": 6.071428571428571,
      "grad_norm": 0.000671312038321048,
      "learning_rate": 1.1904761904761905e-05,
      "loss": 0.0001,
      "step": 21250
    },
    {
      "epoch": 6.074285714285715,
      "grad_norm": 0.0003298576921224594,
      "learning_rate": 1.1900952380952382e-05,
      "loss": 0.0,
      "step": 21260
    },
    {
      "epoch": 6.077142857142857,
      "grad_norm": 0.003601356875151396,
      "learning_rate": 1.1897142857142858e-05,
      "loss": 0.0,
      "step": 21270
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.0005309898406267166,
      "learning_rate": 1.1893333333333335e-05,
      "loss": 0.0,
      "step": 21280
    },
    {
      "epoch": 6.082857142857143,
      "grad_norm": 0.003966277465224266,
      "learning_rate": 1.188952380952381e-05,
      "loss": 0.0,
      "step": 21290
    },
    {
      "epoch": 6.085714285714285,
      "grad_norm": 8.393148891627789e-05,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 0.0,
      "step": 21300
    },
    {
      "epoch": 6.088571428571429,
      "grad_norm": 0.012621124275028706,
      "learning_rate": 1.1881904761904764e-05,
      "loss": 0.1796,
      "step": 21310
    },
    {
      "epoch": 6.091428571428572,
      "grad_norm": 0.021262628957629204,
      "learning_rate": 1.187809523809524e-05,
      "loss": 0.0001,
      "step": 21320
    },
    {
      "epoch": 6.094285714285714,
      "grad_norm": 0.01853371225297451,
      "learning_rate": 1.1874285714285717e-05,
      "loss": 0.0001,
      "step": 21330
    },
    {
      "epoch": 6.097142857142857,
      "grad_norm": 0.013875331729650497,
      "learning_rate": 1.1870476190476192e-05,
      "loss": 0.0001,
      "step": 21340
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.00020664819749072194,
      "learning_rate": 1.186666666666667e-05,
      "loss": 0.0001,
      "step": 21350
    },
    {
      "epoch": 6.102857142857143,
      "grad_norm": 0.00017170871433336288,
      "learning_rate": 1.1862857142857145e-05,
      "loss": 0.0738,
      "step": 21360
    },
    {
      "epoch": 6.105714285714286,
      "grad_norm": 0.007738566026091576,
      "learning_rate": 1.1859047619047619e-05,
      "loss": 0.0003,
      "step": 21370
    },
    {
      "epoch": 6.1085714285714285,
      "grad_norm": 0.020753446966409683,
      "learning_rate": 1.1855238095238094e-05,
      "loss": 0.0609,
      "step": 21380
    },
    {
      "epoch": 6.111428571428571,
      "grad_norm": 0.000737444672267884,
      "learning_rate": 1.1851428571428572e-05,
      "loss": 0.0001,
      "step": 21390
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 0.012805482372641563,
      "learning_rate": 1.1847619047619047e-05,
      "loss": 0.1649,
      "step": 21400
    },
    {
      "epoch": 6.117142857142857,
      "grad_norm": 0.0005436365026980639,
      "learning_rate": 1.1843809523809525e-05,
      "loss": 0.0002,
      "step": 21410
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.13813823461532593,
      "learning_rate": 1.184e-05,
      "loss": 0.0001,
      "step": 21420
    },
    {
      "epoch": 6.122857142857143,
      "grad_norm": 0.0009753004997037351,
      "learning_rate": 1.1836190476190477e-05,
      "loss": 0.0,
      "step": 21430
    },
    {
      "epoch": 6.1257142857142854,
      "grad_norm": 0.0024039251729846,
      "learning_rate": 1.1832380952380953e-05,
      "loss": 0.1235,
      "step": 21440
    },
    {
      "epoch": 6.128571428571428,
      "grad_norm": 0.025743113830685616,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.0,
      "step": 21450
    },
    {
      "epoch": 6.131428571428572,
      "grad_norm": 4.4393513235263526e-05,
      "learning_rate": 1.1824761904761906e-05,
      "loss": 0.1617,
      "step": 21460
    },
    {
      "epoch": 6.134285714285714,
      "grad_norm": 0.0028894057031720877,
      "learning_rate": 1.1820952380952381e-05,
      "loss": 0.0001,
      "step": 21470
    },
    {
      "epoch": 6.137142857142857,
      "grad_norm": 0.001095119514502585,
      "learning_rate": 1.1817142857142859e-05,
      "loss": 0.0002,
      "step": 21480
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.015497654676437378,
      "learning_rate": 1.1813333333333334e-05,
      "loss": 0.0002,
      "step": 21490
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.0014961735578253865,
      "learning_rate": 1.180952380952381e-05,
      "loss": 0.0193,
      "step": 21500
    },
    {
      "epoch": 6.145714285714286,
      "grad_norm": 0.0005874423077329993,
      "learning_rate": 1.1805714285714287e-05,
      "loss": 0.2585,
      "step": 21510
    },
    {
      "epoch": 6.148571428571429,
      "grad_norm": 6.349465547828004e-05,
      "learning_rate": 1.1801904761904763e-05,
      "loss": 0.0,
      "step": 21520
    },
    {
      "epoch": 6.151428571428571,
      "grad_norm": 0.006182800978422165,
      "learning_rate": 1.179809523809524e-05,
      "loss": 0.0001,
      "step": 21530
    },
    {
      "epoch": 6.154285714285714,
      "grad_norm": 4.212927524349652e-05,
      "learning_rate": 1.1794285714285716e-05,
      "loss": 0.0026,
      "step": 21540
    },
    {
      "epoch": 6.1571428571428575,
      "grad_norm": 0.00028251702315174043,
      "learning_rate": 1.1790476190476193e-05,
      "loss": 0.0,
      "step": 21550
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.006550038233399391,
      "learning_rate": 1.1786666666666668e-05,
      "loss": 0.1649,
      "step": 21560
    },
    {
      "epoch": 6.162857142857143,
      "grad_norm": 5.903622513869777e-05,
      "learning_rate": 1.1782857142857144e-05,
      "loss": 0.0,
      "step": 21570
    },
    {
      "epoch": 6.1657142857142855,
      "grad_norm": 0.006059066392481327,
      "learning_rate": 1.1779047619047621e-05,
      "loss": 0.0,
      "step": 21580
    },
    {
      "epoch": 6.168571428571428,
      "grad_norm": 0.0004908744595013559,
      "learning_rate": 1.1775238095238095e-05,
      "loss": 0.0001,
      "step": 21590
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 0.011229556985199451,
      "learning_rate": 1.177142857142857e-05,
      "loss": 0.0916,
      "step": 21600
    },
    {
      "epoch": 6.174285714285714,
      "grad_norm": 0.12877407670021057,
      "learning_rate": 1.1767619047619048e-05,
      "loss": 0.0003,
      "step": 21610
    },
    {
      "epoch": 6.177142857142857,
      "grad_norm": 0.2309209257364273,
      "learning_rate": 1.1763809523809524e-05,
      "loss": 0.0003,
      "step": 21620
    },
    {
      "epoch": 6.18,
      "grad_norm": 3.759462560992688e-05,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.0002,
      "step": 21630
    },
    {
      "epoch": 6.182857142857143,
      "grad_norm": 0.0033173132687807083,
      "learning_rate": 1.1756190476190476e-05,
      "loss": 0.0001,
      "step": 21640
    },
    {
      "epoch": 6.185714285714286,
      "grad_norm": 14.432305335998535,
      "learning_rate": 1.1752380952380952e-05,
      "loss": 0.1888,
      "step": 21650
    },
    {
      "epoch": 6.188571428571429,
      "grad_norm": 0.00038821701309643686,
      "learning_rate": 1.174857142857143e-05,
      "loss": 0.1942,
      "step": 21660
    },
    {
      "epoch": 6.191428571428571,
      "grad_norm": 0.0013502876972779632,
      "learning_rate": 1.1744761904761905e-05,
      "loss": 0.0,
      "step": 21670
    },
    {
      "epoch": 6.194285714285714,
      "grad_norm": 0.014811821281909943,
      "learning_rate": 1.1740952380952382e-05,
      "loss": 0.0001,
      "step": 21680
    },
    {
      "epoch": 6.1971428571428575,
      "grad_norm": 0.004428418353199959,
      "learning_rate": 1.1737142857142858e-05,
      "loss": 0.0002,
      "step": 21690
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.06349852681159973,
      "learning_rate": 1.1733333333333335e-05,
      "loss": 0.0001,
      "step": 21700
    },
    {
      "epoch": 6.202857142857143,
      "grad_norm": 0.0017270552925765514,
      "learning_rate": 1.172952380952381e-05,
      "loss": 0.1384,
      "step": 21710
    },
    {
      "epoch": 6.2057142857142855,
      "grad_norm": 0.0010050245327875018,
      "learning_rate": 1.1725714285714286e-05,
      "loss": 0.0001,
      "step": 21720
    },
    {
      "epoch": 6.208571428571428,
      "grad_norm": 0.007815699093043804,
      "learning_rate": 1.1721904761904763e-05,
      "loss": 0.0001,
      "step": 21730
    },
    {
      "epoch": 6.211428571428572,
      "grad_norm": 0.0029864965472370386,
      "learning_rate": 1.1718095238095239e-05,
      "loss": 0.0,
      "step": 21740
    },
    {
      "epoch": 6.214285714285714,
      "grad_norm": 0.0003999893378932029,
      "learning_rate": 1.1714285714285716e-05,
      "loss": 0.0003,
      "step": 21750
    },
    {
      "epoch": 6.217142857142857,
      "grad_norm": 52.94526672363281,
      "learning_rate": 1.1710476190476192e-05,
      "loss": 0.0562,
      "step": 21760
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.0026042931713163853,
      "learning_rate": 1.170666666666667e-05,
      "loss": 0.0002,
      "step": 21770
    },
    {
      "epoch": 6.222857142857142,
      "grad_norm": 5.3355670388555154e-05,
      "learning_rate": 1.1702857142857145e-05,
      "loss": 0.0,
      "step": 21780
    },
    {
      "epoch": 6.225714285714286,
      "grad_norm": 4.371133036329411e-05,
      "learning_rate": 1.169904761904762e-05,
      "loss": 0.0002,
      "step": 21790
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 0.00013786468480248004,
      "learning_rate": 1.1695238095238098e-05,
      "loss": 0.1719,
      "step": 21800
    },
    {
      "epoch": 6.231428571428571,
      "grad_norm": 9.120786126004532e-05,
      "learning_rate": 1.1691428571428572e-05,
      "loss": 0.0001,
      "step": 21810
    },
    {
      "epoch": 6.234285714285714,
      "grad_norm": 0.00023880632943473756,
      "learning_rate": 1.1687619047619047e-05,
      "loss": 0.0,
      "step": 21820
    },
    {
      "epoch": 6.2371428571428575,
      "grad_norm": 8.610891381977126e-05,
      "learning_rate": 1.1683809523809524e-05,
      "loss": 0.0002,
      "step": 21830
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.00012251875887159258,
      "learning_rate": 1.168e-05,
      "loss": 0.0002,
      "step": 21840
    },
    {
      "epoch": 6.242857142857143,
      "grad_norm": 0.0033262656070291996,
      "learning_rate": 1.1676190476190477e-05,
      "loss": 0.0,
      "step": 21850
    },
    {
      "epoch": 6.2457142857142856,
      "grad_norm": 7.294434180948883e-05,
      "learning_rate": 1.1672380952380953e-05,
      "loss": 0.0001,
      "step": 21860
    },
    {
      "epoch": 6.248571428571428,
      "grad_norm": 0.000519466120749712,
      "learning_rate": 1.1668571428571428e-05,
      "loss": 0.0,
      "step": 21870
    },
    {
      "epoch": 6.251428571428572,
      "grad_norm": 4.61286363133695e-05,
      "learning_rate": 1.1664761904761906e-05,
      "loss": 0.0,
      "step": 21880
    },
    {
      "epoch": 6.2542857142857144,
      "grad_norm": 7.13690315023996e-05,
      "learning_rate": 1.1660952380952381e-05,
      "loss": 0.0,
      "step": 21890
    },
    {
      "epoch": 6.257142857142857,
      "grad_norm": 0.00064130435930565,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.0001,
      "step": 21900
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.0014431958552449942,
      "learning_rate": 1.1653333333333334e-05,
      "loss": 0.472,
      "step": 21910
    },
    {
      "epoch": 6.2628571428571425,
      "grad_norm": 0.006885024253278971,
      "learning_rate": 1.1649523809523811e-05,
      "loss": 0.0002,
      "step": 21920
    },
    {
      "epoch": 6.265714285714286,
      "grad_norm": 0.036576755344867706,
      "learning_rate": 1.1645714285714287e-05,
      "loss": 0.002,
      "step": 21930
    },
    {
      "epoch": 6.268571428571429,
      "grad_norm": 0.03449110686779022,
      "learning_rate": 1.1641904761904763e-05,
      "loss": 0.0002,
      "step": 21940
    },
    {
      "epoch": 6.271428571428571,
      "grad_norm": 0.013069096952676773,
      "learning_rate": 1.163809523809524e-05,
      "loss": 0.0006,
      "step": 21950
    },
    {
      "epoch": 6.274285714285714,
      "grad_norm": 0.004568794276565313,
      "learning_rate": 1.1634285714285715e-05,
      "loss": 0.0925,
      "step": 21960
    },
    {
      "epoch": 6.277142857142858,
      "grad_norm": 0.0028746866155415773,
      "learning_rate": 1.1630476190476193e-05,
      "loss": 0.0001,
      "step": 21970
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.000795739411842078,
      "learning_rate": 1.1626666666666668e-05,
      "loss": 0.0002,
      "step": 21980
    },
    {
      "epoch": 6.282857142857143,
      "grad_norm": 0.0008773542358539999,
      "learning_rate": 1.1622857142857144e-05,
      "loss": 0.0001,
      "step": 21990
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.0009648230043239892,
      "learning_rate": 1.1619047619047621e-05,
      "loss": 0.0001,
      "step": 22000
    },
    {
      "epoch": 6.288571428571428,
      "grad_norm": 0.0019061905331909657,
      "learning_rate": 1.1615238095238097e-05,
      "loss": 0.0,
      "step": 22010
    },
    {
      "epoch": 6.291428571428572,
      "grad_norm": 0.0023077004589140415,
      "learning_rate": 1.161142857142857e-05,
      "loss": 0.0,
      "step": 22020
    },
    {
      "epoch": 6.2942857142857145,
      "grad_norm": 0.0008686910732649267,
      "learning_rate": 1.1607619047619048e-05,
      "loss": 0.0,
      "step": 22030
    },
    {
      "epoch": 6.297142857142857,
      "grad_norm": 0.0024184470530599356,
      "learning_rate": 1.1603809523809523e-05,
      "loss": 0.1476,
      "step": 22040
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.0018914510728791356,
      "learning_rate": 1.16e-05,
      "loss": 0.0,
      "step": 22050
    },
    {
      "epoch": 6.3028571428571425,
      "grad_norm": 0.0017338558100163937,
      "learning_rate": 1.1596190476190476e-05,
      "loss": 0.0001,
      "step": 22060
    },
    {
      "epoch": 6.305714285714286,
      "grad_norm": 0.000814105267636478,
      "learning_rate": 1.1592380952380952e-05,
      "loss": 0.0001,
      "step": 22070
    },
    {
      "epoch": 6.308571428571429,
      "grad_norm": 0.0002849510929081589,
      "learning_rate": 1.158857142857143e-05,
      "loss": 0.0,
      "step": 22080
    },
    {
      "epoch": 6.311428571428571,
      "grad_norm": 0.0002468224265612662,
      "learning_rate": 1.1584761904761905e-05,
      "loss": 0.0,
      "step": 22090
    },
    {
      "epoch": 6.314285714285714,
      "grad_norm": 0.0008279687608592212,
      "learning_rate": 1.1580952380952382e-05,
      "loss": 0.0,
      "step": 22100
    },
    {
      "epoch": 6.317142857142857,
      "grad_norm": 24.555898666381836,
      "learning_rate": 1.1577142857142858e-05,
      "loss": 0.0104,
      "step": 22110
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.19066834449768066,
      "learning_rate": 1.1573333333333335e-05,
      "loss": 0.1637,
      "step": 22120
    },
    {
      "epoch": 6.322857142857143,
      "grad_norm": 0.0018294616602361202,
      "learning_rate": 1.156952380952381e-05,
      "loss": 0.0,
      "step": 22130
    },
    {
      "epoch": 6.325714285714286,
      "grad_norm": 0.0013926152605563402,
      "learning_rate": 1.1565714285714286e-05,
      "loss": 0.2136,
      "step": 22140
    },
    {
      "epoch": 6.328571428571428,
      "grad_norm": 0.002841595560312271,
      "learning_rate": 1.1561904761904763e-05,
      "loss": 0.0005,
      "step": 22150
    },
    {
      "epoch": 6.331428571428571,
      "grad_norm": 0.0012555232970044017,
      "learning_rate": 1.1558095238095239e-05,
      "loss": 0.0,
      "step": 22160
    },
    {
      "epoch": 6.3342857142857145,
      "grad_norm": 0.0014015673659741879,
      "learning_rate": 1.1554285714285716e-05,
      "loss": 0.0003,
      "step": 22170
    },
    {
      "epoch": 6.337142857142857,
      "grad_norm": 0.00033128622453659773,
      "learning_rate": 1.1550476190476192e-05,
      "loss": 0.0,
      "step": 22180
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.04375447332859039,
      "learning_rate": 1.1546666666666669e-05,
      "loss": 0.0001,
      "step": 22190
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 0.005219416227191687,
      "learning_rate": 1.1542857142857145e-05,
      "loss": 0.0,
      "step": 22200
    },
    {
      "epoch": 6.345714285714286,
      "grad_norm": 0.0007283342420123518,
      "learning_rate": 1.153904761904762e-05,
      "loss": 0.0001,
      "step": 22210
    },
    {
      "epoch": 6.348571428571429,
      "grad_norm": 0.00030728004639968276,
      "learning_rate": 1.1535238095238097e-05,
      "loss": 0.0001,
      "step": 22220
    },
    {
      "epoch": 6.351428571428571,
      "grad_norm": 0.0021571246907114983,
      "learning_rate": 1.1531428571428573e-05,
      "loss": 0.0001,
      "step": 22230
    },
    {
      "epoch": 6.354285714285714,
      "grad_norm": 0.0002590264775790274,
      "learning_rate": 1.1527619047619047e-05,
      "loss": 0.0,
      "step": 22240
    },
    {
      "epoch": 6.357142857142857,
      "grad_norm": 0.0008494911016896367,
      "learning_rate": 1.1523809523809524e-05,
      "loss": 0.0001,
      "step": 22250
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.0006453669047914445,
      "learning_rate": 1.152e-05,
      "loss": 0.0,
      "step": 22260
    },
    {
      "epoch": 6.362857142857143,
      "grad_norm": 0.0002272801211802289,
      "learning_rate": 1.1516190476190477e-05,
      "loss": 0.0,
      "step": 22270
    },
    {
      "epoch": 6.365714285714286,
      "grad_norm": 0.0002653657866176218,
      "learning_rate": 1.1512380952380953e-05,
      "loss": 0.0,
      "step": 22280
    },
    {
      "epoch": 6.368571428571428,
      "grad_norm": 0.0002170891675632447,
      "learning_rate": 1.1508571428571428e-05,
      "loss": 0.0,
      "step": 22290
    },
    {
      "epoch": 6.371428571428572,
      "grad_norm": 0.0004617399536073208,
      "learning_rate": 1.1504761904761906e-05,
      "loss": 0.0,
      "step": 22300
    },
    {
      "epoch": 6.3742857142857146,
      "grad_norm": 0.0024541481398046017,
      "learning_rate": 1.1500952380952381e-05,
      "loss": 0.0,
      "step": 22310
    },
    {
      "epoch": 6.377142857142857,
      "grad_norm": 0.0011804536916315556,
      "learning_rate": 1.1497142857142858e-05,
      "loss": 0.0,
      "step": 22320
    },
    {
      "epoch": 6.38,
      "grad_norm": 0.010979006998240948,
      "learning_rate": 1.1493333333333334e-05,
      "loss": 0.0,
      "step": 22330
    },
    {
      "epoch": 6.382857142857143,
      "grad_norm": 9.766995208337903e-05,
      "learning_rate": 1.1489523809523811e-05,
      "loss": 0.0,
      "step": 22340
    },
    {
      "epoch": 6.385714285714286,
      "grad_norm": 0.0006800972623750567,
      "learning_rate": 1.1485714285714287e-05,
      "loss": 0.0,
      "step": 22350
    },
    {
      "epoch": 6.388571428571429,
      "grad_norm": 0.0009151971898972988,
      "learning_rate": 1.1481904761904762e-05,
      "loss": 0.0001,
      "step": 22360
    },
    {
      "epoch": 6.3914285714285715,
      "grad_norm": 0.00012110039097024128,
      "learning_rate": 1.147809523809524e-05,
      "loss": 0.0,
      "step": 22370
    },
    {
      "epoch": 6.394285714285714,
      "grad_norm": 0.0006996545707806945,
      "learning_rate": 1.1474285714285715e-05,
      "loss": 0.0,
      "step": 22380
    },
    {
      "epoch": 6.397142857142857,
      "grad_norm": 0.00011327620450174436,
      "learning_rate": 1.1470476190476193e-05,
      "loss": 0.0,
      "step": 22390
    },
    {
      "epoch": 6.4,
      "grad_norm": 8.62512897583656e-05,
      "learning_rate": 1.1466666666666668e-05,
      "loss": 0.0,
      "step": 22400
    },
    {
      "epoch": 6.402857142857143,
      "grad_norm": 0.000807335542049259,
      "learning_rate": 1.1462857142857144e-05,
      "loss": 0.0001,
      "step": 22410
    },
    {
      "epoch": 6.405714285714286,
      "grad_norm": 0.0003149403491988778,
      "learning_rate": 1.1459047619047621e-05,
      "loss": 0.0,
      "step": 22420
    },
    {
      "epoch": 6.408571428571428,
      "grad_norm": 0.0006115979049354792,
      "learning_rate": 1.1455238095238097e-05,
      "loss": 0.0001,
      "step": 22430
    },
    {
      "epoch": 6.411428571428571,
      "grad_norm": 0.0007009495748206973,
      "learning_rate": 1.1451428571428574e-05,
      "loss": 0.0001,
      "step": 22440
    },
    {
      "epoch": 6.414285714285715,
      "grad_norm": 0.0009997350862249732,
      "learning_rate": 1.144761904761905e-05,
      "loss": 0.0,
      "step": 22450
    },
    {
      "epoch": 6.417142857142857,
      "grad_norm": 5.6255146773764864e-05,
      "learning_rate": 1.1443809523809523e-05,
      "loss": 0.0,
      "step": 22460
    },
    {
      "epoch": 6.42,
      "grad_norm": 7.252509385580197e-05,
      "learning_rate": 1.144e-05,
      "loss": 0.0,
      "step": 22470
    },
    {
      "epoch": 6.422857142857143,
      "grad_norm": 5.529737245524302e-05,
      "learning_rate": 1.1436190476190476e-05,
      "loss": 0.0,
      "step": 22480
    },
    {
      "epoch": 6.425714285714285,
      "grad_norm": 0.0010027920361608267,
      "learning_rate": 1.1432380952380952e-05,
      "loss": 0.0,
      "step": 22490
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.0004205776785966009,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0,
      "step": 22500
    },
    {
      "epoch": 6.4314285714285715,
      "grad_norm": 5.4975673265289515e-05,
      "learning_rate": 1.1424761904761905e-05,
      "loss": 0.0,
      "step": 22510
    },
    {
      "epoch": 6.434285714285714,
      "grad_norm": 8.255885768448934e-05,
      "learning_rate": 1.1420952380952382e-05,
      "loss": 0.0,
      "step": 22520
    },
    {
      "epoch": 6.437142857142857,
      "grad_norm": 0.00013764049799647182,
      "learning_rate": 1.1417142857142857e-05,
      "loss": 0.0001,
      "step": 22530
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.00021971594833303243,
      "learning_rate": 1.1413333333333335e-05,
      "loss": 0.0,
      "step": 22540
    },
    {
      "epoch": 6.442857142857143,
      "grad_norm": 4.310983422328718e-05,
      "learning_rate": 1.140952380952381e-05,
      "loss": 0.0,
      "step": 22550
    },
    {
      "epoch": 6.445714285714286,
      "grad_norm": 0.0004921964136883616,
      "learning_rate": 1.1405714285714286e-05,
      "loss": 0.0675,
      "step": 22560
    },
    {
      "epoch": 6.448571428571428,
      "grad_norm": 0.00039354973705485463,
      "learning_rate": 1.1401904761904763e-05,
      "loss": 0.0,
      "step": 22570
    },
    {
      "epoch": 6.451428571428571,
      "grad_norm": 0.014136822894215584,
      "learning_rate": 1.1398095238095239e-05,
      "loss": 0.0,
      "step": 22580
    },
    {
      "epoch": 6.454285714285715,
      "grad_norm": 0.0008147694170475006,
      "learning_rate": 1.1394285714285716e-05,
      "loss": 0.0,
      "step": 22590
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 0.0004486889229156077,
      "learning_rate": 1.1390476190476192e-05,
      "loss": 0.0,
      "step": 22600
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.0011575701646506786,
      "learning_rate": 1.1386666666666669e-05,
      "loss": 0.0,
      "step": 22610
    },
    {
      "epoch": 6.462857142857143,
      "grad_norm": 0.00016124427202157676,
      "learning_rate": 1.1382857142857144e-05,
      "loss": 0.0,
      "step": 22620
    },
    {
      "epoch": 6.465714285714285,
      "grad_norm": 0.00010319051943952218,
      "learning_rate": 1.137904761904762e-05,
      "loss": 0.0,
      "step": 22630
    },
    {
      "epoch": 6.468571428571429,
      "grad_norm": 0.0006424256134778261,
      "learning_rate": 1.1375238095238097e-05,
      "loss": 0.0,
      "step": 22640
    },
    {
      "epoch": 6.4714285714285715,
      "grad_norm": 0.00011899620585609227,
      "learning_rate": 1.1371428571428573e-05,
      "loss": 0.0,
      "step": 22650
    },
    {
      "epoch": 6.474285714285714,
      "grad_norm": 0.014285186305642128,
      "learning_rate": 1.136761904761905e-05,
      "loss": 0.0,
      "step": 22660
    },
    {
      "epoch": 6.477142857142857,
      "grad_norm": 6.039667277946137e-05,
      "learning_rate": 1.1363809523809526e-05,
      "loss": 0.0,
      "step": 22670
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.0008208003710024059,
      "learning_rate": 1.136e-05,
      "loss": 0.0,
      "step": 22680
    },
    {
      "epoch": 6.482857142857143,
      "grad_norm": 0.0005532833747565746,
      "learning_rate": 1.1356190476190477e-05,
      "loss": 0.0,
      "step": 22690
    },
    {
      "epoch": 6.485714285714286,
      "grad_norm": 0.0001263340818695724,
      "learning_rate": 1.1352380952380953e-05,
      "loss": 0.0,
      "step": 22700
    },
    {
      "epoch": 6.488571428571428,
      "grad_norm": 0.0007703594164922833,
      "learning_rate": 1.1348571428571428e-05,
      "loss": 0.0,
      "step": 22710
    },
    {
      "epoch": 6.491428571428571,
      "grad_norm": 0.0010668603936210275,
      "learning_rate": 1.1344761904761905e-05,
      "loss": 0.0,
      "step": 22720
    },
    {
      "epoch": 6.494285714285715,
      "grad_norm": 0.0005669862730428576,
      "learning_rate": 1.1340952380952381e-05,
      "loss": 0.0,
      "step": 22730
    },
    {
      "epoch": 6.497142857142857,
      "grad_norm": 0.000268543983111158,
      "learning_rate": 1.1337142857142858e-05,
      "loss": 0.0,
      "step": 22740
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.0005731783458031714,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0,
      "step": 22750
    },
    {
      "epoch": 6.502857142857143,
      "grad_norm": 0.00039246841333806515,
      "learning_rate": 1.1329523809523811e-05,
      "loss": 0.0,
      "step": 22760
    },
    {
      "epoch": 6.505714285714285,
      "grad_norm": 0.00015662587247788906,
      "learning_rate": 1.1325714285714287e-05,
      "loss": 0.0,
      "step": 22770
    },
    {
      "epoch": 6.508571428571429,
      "grad_norm": 8.696836448507383e-05,
      "learning_rate": 1.1321904761904762e-05,
      "loss": 0.0,
      "step": 22780
    },
    {
      "epoch": 6.511428571428572,
      "grad_norm": 0.0007810593233443797,
      "learning_rate": 1.131809523809524e-05,
      "loss": 0.0,
      "step": 22790
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 6.954203854547814e-05,
      "learning_rate": 1.1314285714285715e-05,
      "loss": 0.0,
      "step": 22800
    },
    {
      "epoch": 6.517142857142857,
      "grad_norm": 9.017626871354878e-05,
      "learning_rate": 1.1310476190476192e-05,
      "loss": 0.1227,
      "step": 22810
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.0002760485222097486,
      "learning_rate": 1.1306666666666668e-05,
      "loss": 0.0,
      "step": 22820
    },
    {
      "epoch": 6.522857142857143,
      "grad_norm": 0.00111595808994025,
      "learning_rate": 1.1302857142857144e-05,
      "loss": 0.0002,
      "step": 22830
    },
    {
      "epoch": 6.525714285714286,
      "grad_norm": 0.00017805724928621203,
      "learning_rate": 1.129904761904762e-05,
      "loss": 0.0,
      "step": 22840
    },
    {
      "epoch": 6.5285714285714285,
      "grad_norm": 0.0011376704787835479,
      "learning_rate": 1.1295238095238096e-05,
      "loss": 0.0,
      "step": 22850
    },
    {
      "epoch": 6.531428571428571,
      "grad_norm": 6.640510400757194e-05,
      "learning_rate": 1.1291428571428574e-05,
      "loss": 0.0,
      "step": 22860
    },
    {
      "epoch": 6.534285714285714,
      "grad_norm": 8.05316012701951e-05,
      "learning_rate": 1.128761904761905e-05,
      "loss": 0.0,
      "step": 22870
    },
    {
      "epoch": 6.537142857142857,
      "grad_norm": 0.00017455688794143498,
      "learning_rate": 1.1283809523809527e-05,
      "loss": 0.0,
      "step": 22880
    },
    {
      "epoch": 6.54,
      "grad_norm": 67.95634460449219,
      "learning_rate": 1.128e-05,
      "loss": 0.305,
      "step": 22890
    },
    {
      "epoch": 6.542857142857143,
      "grad_norm": 0.0010460937628522515,
      "learning_rate": 1.1276190476190476e-05,
      "loss": 0.0,
      "step": 22900
    },
    {
      "epoch": 6.545714285714285,
      "grad_norm": 0.0033240332268178463,
      "learning_rate": 1.1272380952380952e-05,
      "loss": 0.0,
      "step": 22910
    },
    {
      "epoch": 6.548571428571429,
      "grad_norm": 3.4902393963420764e-05,
      "learning_rate": 1.1268571428571429e-05,
      "loss": 0.0001,
      "step": 22920
    },
    {
      "epoch": 6.551428571428572,
      "grad_norm": 2.749908344412688e-05,
      "learning_rate": 1.1264761904761904e-05,
      "loss": 0.0001,
      "step": 22930
    },
    {
      "epoch": 6.554285714285714,
      "grad_norm": 0.00012140038597863168,
      "learning_rate": 1.1260952380952382e-05,
      "loss": 0.2612,
      "step": 22940
    },
    {
      "epoch": 6.557142857142857,
      "grad_norm": 0.003941024653613567,
      "learning_rate": 1.1257142857142857e-05,
      "loss": 0.1881,
      "step": 22950
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.003006500191986561,
      "learning_rate": 1.1253333333333335e-05,
      "loss": 0.0001,
      "step": 22960
    },
    {
      "epoch": 6.562857142857143,
      "grad_norm": 0.008161233738064766,
      "learning_rate": 1.124952380952381e-05,
      "loss": 0.0002,
      "step": 22970
    },
    {
      "epoch": 6.565714285714286,
      "grad_norm": 0.028671858832240105,
      "learning_rate": 1.1245714285714286e-05,
      "loss": 0.1337,
      "step": 22980
    },
    {
      "epoch": 6.5685714285714285,
      "grad_norm": 0.053510166704654694,
      "learning_rate": 1.1241904761904763e-05,
      "loss": 0.1817,
      "step": 22990
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.029756050556898117,
      "learning_rate": 1.1238095238095239e-05,
      "loss": 0.0002,
      "step": 23000
    },
    {
      "epoch": 6.574285714285715,
      "grad_norm": 0.0023694008123129606,
      "learning_rate": 1.1234285714285716e-05,
      "loss": 0.0004,
      "step": 23010
    },
    {
      "epoch": 6.577142857142857,
      "grad_norm": 0.022416381165385246,
      "learning_rate": 1.1230476190476191e-05,
      "loss": 0.0012,
      "step": 23020
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.0015421180287376046,
      "learning_rate": 1.1226666666666669e-05,
      "loss": 0.0001,
      "step": 23030
    },
    {
      "epoch": 6.582857142857143,
      "grad_norm": 0.01145665068179369,
      "learning_rate": 1.1222857142857144e-05,
      "loss": 0.0,
      "step": 23040
    },
    {
      "epoch": 6.585714285714285,
      "grad_norm": 0.001715587917715311,
      "learning_rate": 1.121904761904762e-05,
      "loss": 0.0004,
      "step": 23050
    },
    {
      "epoch": 6.588571428571429,
      "grad_norm": 0.000705931568518281,
      "learning_rate": 1.1215238095238097e-05,
      "loss": 0.0,
      "step": 23060
    },
    {
      "epoch": 6.591428571428572,
      "grad_norm": 0.0004612327029462904,
      "learning_rate": 1.1211428571428573e-05,
      "loss": 0.0,
      "step": 23070
    },
    {
      "epoch": 6.594285714285714,
      "grad_norm": 0.0010358502622693777,
      "learning_rate": 1.120761904761905e-05,
      "loss": 0.0,
      "step": 23080
    },
    {
      "epoch": 6.597142857142857,
      "grad_norm": 0.29651588201522827,
      "learning_rate": 1.1203809523809526e-05,
      "loss": 0.0002,
      "step": 23090
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.0007350925588980317,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0,
      "step": 23100
    },
    {
      "epoch": 6.602857142857143,
      "grad_norm": 0.000406340608606115,
      "learning_rate": 1.1196190476190477e-05,
      "loss": 0.0,
      "step": 23110
    },
    {
      "epoch": 6.605714285714286,
      "grad_norm": 0.00015002948930487037,
      "learning_rate": 1.1192380952380952e-05,
      "loss": 0.0,
      "step": 23120
    },
    {
      "epoch": 6.6085714285714285,
      "grad_norm": 0.00034479593159630895,
      "learning_rate": 1.1188571428571428e-05,
      "loss": 0.0,
      "step": 23130
    },
    {
      "epoch": 6.611428571428571,
      "grad_norm": 0.009453127160668373,
      "learning_rate": 1.1184761904761905e-05,
      "loss": 0.0,
      "step": 23140
    },
    {
      "epoch": 6.614285714285714,
      "grad_norm": 0.00021299101354088634,
      "learning_rate": 1.118095238095238e-05,
      "loss": 0.0,
      "step": 23150
    },
    {
      "epoch": 6.617142857142857,
      "grad_norm": 0.001187549321912229,
      "learning_rate": 1.1177142857142858e-05,
      "loss": 0.0095,
      "step": 23160
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.00044183546560816467,
      "learning_rate": 1.1173333333333334e-05,
      "loss": 0.0,
      "step": 23170
    },
    {
      "epoch": 6.622857142857143,
      "grad_norm": 0.0013213551137596369,
      "learning_rate": 1.1169523809523811e-05,
      "loss": 0.1421,
      "step": 23180
    },
    {
      "epoch": 6.6257142857142854,
      "grad_norm": 0.00021076927077956498,
      "learning_rate": 1.1165714285714287e-05,
      "loss": 0.2712,
      "step": 23190
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 0.0007175934733822942,
      "learning_rate": 1.1161904761904762e-05,
      "loss": 0.0,
      "step": 23200
    },
    {
      "epoch": 6.631428571428572,
      "grad_norm": 0.000692234665621072,
      "learning_rate": 1.115809523809524e-05,
      "loss": 0.0001,
      "step": 23210
    },
    {
      "epoch": 6.634285714285714,
      "grad_norm": 0.001993246143683791,
      "learning_rate": 1.1154285714285715e-05,
      "loss": 0.0002,
      "step": 23220
    },
    {
      "epoch": 6.637142857142857,
      "grad_norm": 0.0006792330532334745,
      "learning_rate": 1.1150476190476192e-05,
      "loss": 0.0,
      "step": 23230
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.0025610921438783407,
      "learning_rate": 1.1146666666666668e-05,
      "loss": 0.0001,
      "step": 23240
    },
    {
      "epoch": 6.642857142857143,
      "grad_norm": 0.0018949860241264105,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 0.0,
      "step": 23250
    },
    {
      "epoch": 6.645714285714286,
      "grad_norm": 8.36382678244263e-05,
      "learning_rate": 1.113904761904762e-05,
      "loss": 0.0,
      "step": 23260
    },
    {
      "epoch": 6.648571428571429,
      "grad_norm": 0.0002575424441602081,
      "learning_rate": 1.1135238095238096e-05,
      "loss": 0.0003,
      "step": 23270
    },
    {
      "epoch": 6.651428571428571,
      "grad_norm": 0.010545016266405582,
      "learning_rate": 1.1131428571428574e-05,
      "loss": 0.0051,
      "step": 23280
    },
    {
      "epoch": 6.654285714285714,
      "grad_norm": 0.0003409485798329115,
      "learning_rate": 1.1127619047619049e-05,
      "loss": 0.0,
      "step": 23290
    },
    {
      "epoch": 6.6571428571428575,
      "grad_norm": 0.00931254681199789,
      "learning_rate": 1.1123809523809526e-05,
      "loss": 0.0,
      "step": 23300
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.0002792429004330188,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.0001,
      "step": 23310
    },
    {
      "epoch": 6.662857142857143,
      "grad_norm": 0.0003723757399711758,
      "learning_rate": 1.1116190476190478e-05,
      "loss": 0.0,
      "step": 23320
    },
    {
      "epoch": 6.6657142857142855,
      "grad_norm": 0.00036746382829733193,
      "learning_rate": 1.1112380952380951e-05,
      "loss": 0.0,
      "step": 23330
    },
    {
      "epoch": 6.668571428571429,
      "grad_norm": 0.0005846663261763752,
      "learning_rate": 1.1108571428571429e-05,
      "loss": 0.0,
      "step": 23340
    },
    {
      "epoch": 6.671428571428572,
      "grad_norm": 0.006675090175122023,
      "learning_rate": 1.1104761904761904e-05,
      "loss": 0.0,
      "step": 23350
    },
    {
      "epoch": 6.674285714285714,
      "grad_norm": 0.00018937808636110276,
      "learning_rate": 1.1100952380952382e-05,
      "loss": 0.0,
      "step": 23360
    },
    {
      "epoch": 6.677142857142857,
      "grad_norm": 0.0005646187928505242,
      "learning_rate": 1.1097142857142857e-05,
      "loss": 0.0,
      "step": 23370
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.0003590464184526354,
      "learning_rate": 1.1093333333333334e-05,
      "loss": 0.0,
      "step": 23380
    },
    {
      "epoch": 6.682857142857143,
      "grad_norm": 0.00015380846161860973,
      "learning_rate": 1.108952380952381e-05,
      "loss": 0.0,
      "step": 23390
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 0.0002859906235244125,
      "learning_rate": 1.1085714285714286e-05,
      "loss": 0.0,
      "step": 23400
    },
    {
      "epoch": 6.688571428571429,
      "grad_norm": 0.0003428617201279849,
      "learning_rate": 1.1081904761904763e-05,
      "loss": 0.0004,
      "step": 23410
    },
    {
      "epoch": 6.691428571428571,
      "grad_norm": 7.905566599220037e-05,
      "learning_rate": 1.1078095238095238e-05,
      "loss": 0.0,
      "step": 23420
    },
    {
      "epoch": 6.694285714285714,
      "grad_norm": 6.072453470551409e-05,
      "learning_rate": 1.1074285714285716e-05,
      "loss": 0.0,
      "step": 23430
    },
    {
      "epoch": 6.6971428571428575,
      "grad_norm": 0.0007273926748894155,
      "learning_rate": 1.1070476190476191e-05,
      "loss": 0.0,
      "step": 23440
    },
    {
      "epoch": 6.7,
      "grad_norm": 6.812022911617532e-05,
      "learning_rate": 1.1066666666666669e-05,
      "loss": 0.0,
      "step": 23450
    },
    {
      "epoch": 6.702857142857143,
      "grad_norm": 8.382835221709684e-05,
      "learning_rate": 1.1062857142857144e-05,
      "loss": 0.0,
      "step": 23460
    },
    {
      "epoch": 6.7057142857142855,
      "grad_norm": 0.00013025192311033607,
      "learning_rate": 1.105904761904762e-05,
      "loss": 0.0,
      "step": 23470
    },
    {
      "epoch": 6.708571428571428,
      "grad_norm": 0.0002605701156426221,
      "learning_rate": 1.1055238095238097e-05,
      "loss": 0.0,
      "step": 23480
    },
    {
      "epoch": 6.711428571428572,
      "grad_norm": 0.00010848591773537919,
      "learning_rate": 1.1051428571428573e-05,
      "loss": 0.0,
      "step": 23490
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 5.633140244754031e-05,
      "learning_rate": 1.104761904761905e-05,
      "loss": 0.0,
      "step": 23500
    },
    {
      "epoch": 6.717142857142857,
      "grad_norm": 0.00016794136899989098,
      "learning_rate": 1.1043809523809525e-05,
      "loss": 0.0,
      "step": 23510
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.00010369748633820564,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.0,
      "step": 23520
    },
    {
      "epoch": 6.722857142857142,
      "grad_norm": 0.00018924557662103325,
      "learning_rate": 1.1036190476190478e-05,
      "loss": 0.0037,
      "step": 23530
    },
    {
      "epoch": 6.725714285714286,
      "grad_norm": 0.0001332345709670335,
      "learning_rate": 1.1032380952380952e-05,
      "loss": 0.0,
      "step": 23540
    },
    {
      "epoch": 6.728571428571429,
      "grad_norm": 0.00017817701154854149,
      "learning_rate": 1.1028571428571428e-05,
      "loss": 0.0,
      "step": 23550
    },
    {
      "epoch": 6.731428571428571,
      "grad_norm": 0.0033776224590837955,
      "learning_rate": 1.1024761904761905e-05,
      "loss": 0.0,
      "step": 23560
    },
    {
      "epoch": 6.734285714285714,
      "grad_norm": 0.00042533528176136315,
      "learning_rate": 1.102095238095238e-05,
      "loss": 0.0,
      "step": 23570
    },
    {
      "epoch": 6.737142857142857,
      "grad_norm": 0.00029925795388408005,
      "learning_rate": 1.1017142857142858e-05,
      "loss": 0.0,
      "step": 23580
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.0004936594050377607,
      "learning_rate": 1.1013333333333333e-05,
      "loss": 0.0,
      "step": 23590
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 0.00019701638666447252,
      "learning_rate": 1.100952380952381e-05,
      "loss": 0.0,
      "step": 23600
    },
    {
      "epoch": 6.7457142857142856,
      "grad_norm": 0.018797531723976135,
      "learning_rate": 1.1005714285714286e-05,
      "loss": 0.0,
      "step": 23610
    },
    {
      "epoch": 6.748571428571428,
      "grad_norm": 0.00013639460667036474,
      "learning_rate": 1.1001904761904762e-05,
      "loss": 0.0,
      "step": 23620
    },
    {
      "epoch": 6.751428571428572,
      "grad_norm": 0.00012413623335305601,
      "learning_rate": 1.099809523809524e-05,
      "loss": 0.0,
      "step": 23630
    },
    {
      "epoch": 6.7542857142857144,
      "grad_norm": 0.006843876093626022,
      "learning_rate": 1.0994285714285715e-05,
      "loss": 0.2091,
      "step": 23640
    },
    {
      "epoch": 6.757142857142857,
      "grad_norm": 0.0002144120226148516,
      "learning_rate": 1.0990476190476192e-05,
      "loss": 0.0,
      "step": 23650
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.00017497445514891297,
      "learning_rate": 1.0986666666666668e-05,
      "loss": 0.1418,
      "step": 23660
    },
    {
      "epoch": 6.762857142857143,
      "grad_norm": 0.00019183792755939066,
      "learning_rate": 1.0982857142857143e-05,
      "loss": 0.0,
      "step": 23670
    },
    {
      "epoch": 6.765714285714286,
      "grad_norm": 0.0008509195176884532,
      "learning_rate": 1.097904761904762e-05,
      "loss": 0.0,
      "step": 23680
    },
    {
      "epoch": 6.768571428571429,
      "grad_norm": 0.0008237459696829319,
      "learning_rate": 1.0975238095238096e-05,
      "loss": 0.0,
      "step": 23690
    },
    {
      "epoch": 6.771428571428571,
      "grad_norm": 9.266296547139063e-05,
      "learning_rate": 1.0971428571428573e-05,
      "loss": 0.0,
      "step": 23700
    },
    {
      "epoch": 6.774285714285714,
      "grad_norm": 0.0076948413625359535,
      "learning_rate": 1.0967619047619049e-05,
      "loss": 0.0,
      "step": 23710
    },
    {
      "epoch": 6.777142857142858,
      "grad_norm": 0.000734272412955761,
      "learning_rate": 1.0963809523809526e-05,
      "loss": 0.0,
      "step": 23720
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.00030499734566546977,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.0001,
      "step": 23730
    },
    {
      "epoch": 6.782857142857143,
      "grad_norm": 0.0003263153485022485,
      "learning_rate": 1.0956190476190477e-05,
      "loss": 0.0,
      "step": 23740
    },
    {
      "epoch": 6.785714285714286,
      "grad_norm": 0.00010375300189480186,
      "learning_rate": 1.0952380952380955e-05,
      "loss": 0.0,
      "step": 23750
    },
    {
      "epoch": 6.788571428571428,
      "grad_norm": 0.00048339981003664434,
      "learning_rate": 1.0948571428571429e-05,
      "loss": 0.2026,
      "step": 23760
    },
    {
      "epoch": 6.791428571428572,
      "grad_norm": 0.01573892869055271,
      "learning_rate": 1.0944761904761904e-05,
      "loss": 0.0,
      "step": 23770
    },
    {
      "epoch": 6.7942857142857145,
      "grad_norm": 7.564047700725496e-05,
      "learning_rate": 1.0940952380952381e-05,
      "loss": 0.0001,
      "step": 23780
    },
    {
      "epoch": 6.797142857142857,
      "grad_norm": 0.00030106506892479956,
      "learning_rate": 1.0937142857142857e-05,
      "loss": 0.0,
      "step": 23790
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.0024060143623501062,
      "learning_rate": 1.0933333333333334e-05,
      "loss": 0.0001,
      "step": 23800
    },
    {
      "epoch": 6.8028571428571425,
      "grad_norm": 4.7248835471691564e-05,
      "learning_rate": 1.092952380952381e-05,
      "loss": 0.0,
      "step": 23810
    },
    {
      "epoch": 6.805714285714286,
      "grad_norm": 0.00014421704690903425,
      "learning_rate": 1.0925714285714285e-05,
      "loss": 0.0,
      "step": 23820
    },
    {
      "epoch": 6.808571428571429,
      "grad_norm": 4.840562542085536e-05,
      "learning_rate": 1.0921904761904763e-05,
      "loss": 0.0,
      "step": 23830
    },
    {
      "epoch": 6.811428571428571,
      "grad_norm": 0.00012585731747094542,
      "learning_rate": 1.0918095238095238e-05,
      "loss": 0.0,
      "step": 23840
    },
    {
      "epoch": 6.814285714285714,
      "grad_norm": 0.0005422955146059394,
      "learning_rate": 1.0914285714285716e-05,
      "loss": 0.0,
      "step": 23850
    },
    {
      "epoch": 6.817142857142857,
      "grad_norm": 0.0002990255306940526,
      "learning_rate": 1.0910476190476191e-05,
      "loss": 0.0114,
      "step": 23860
    },
    {
      "epoch": 6.82,
      "grad_norm": 6.042441964382306e-05,
      "learning_rate": 1.0906666666666668e-05,
      "loss": 0.0,
      "step": 23870
    },
    {
      "epoch": 6.822857142857143,
      "grad_norm": 6.734201451763511e-05,
      "learning_rate": 1.0902857142857144e-05,
      "loss": 0.0,
      "step": 23880
    },
    {
      "epoch": 6.825714285714286,
      "grad_norm": 0.0019175497582182288,
      "learning_rate": 1.089904761904762e-05,
      "loss": 0.0,
      "step": 23890
    },
    {
      "epoch": 6.828571428571428,
      "grad_norm": 8.873391925590113e-05,
      "learning_rate": 1.0895238095238097e-05,
      "loss": 0.0,
      "step": 23900
    },
    {
      "epoch": 6.831428571428571,
      "grad_norm": 4.327881833887659e-05,
      "learning_rate": 1.0891428571428572e-05,
      "loss": 0.0,
      "step": 23910
    },
    {
      "epoch": 6.8342857142857145,
      "grad_norm": 0.0007378461887128651,
      "learning_rate": 1.088761904761905e-05,
      "loss": 0.0,
      "step": 23920
    },
    {
      "epoch": 6.837142857142857,
      "grad_norm": 0.0001869730040198192,
      "learning_rate": 1.0883809523809525e-05,
      "loss": 0.0,
      "step": 23930
    },
    {
      "epoch": 6.84,
      "grad_norm": 3.433664096519351e-05,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.0,
      "step": 23940
    },
    {
      "epoch": 6.8428571428571425,
      "grad_norm": 0.00020784155640285462,
      "learning_rate": 1.0876190476190478e-05,
      "loss": 0.0,
      "step": 23950
    },
    {
      "epoch": 6.845714285714286,
      "grad_norm": 0.0001101209782063961,
      "learning_rate": 1.0872380952380954e-05,
      "loss": 0.0,
      "step": 23960
    },
    {
      "epoch": 6.848571428571429,
      "grad_norm": 0.0002968762710224837,
      "learning_rate": 1.0868571428571431e-05,
      "loss": 0.0,
      "step": 23970
    },
    {
      "epoch": 6.851428571428571,
      "grad_norm": 5.0582821131683886e-05,
      "learning_rate": 1.0864761904761905e-05,
      "loss": 0.0,
      "step": 23980
    },
    {
      "epoch": 6.854285714285714,
      "grad_norm": 0.0003226234985049814,
      "learning_rate": 1.086095238095238e-05,
      "loss": 0.0,
      "step": 23990
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 4.3070675019407645e-05,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 0.0,
      "step": 24000
    },
    {
      "epoch": 6.86,
      "grad_norm": 4.764349068864249e-05,
      "learning_rate": 1.0853333333333333e-05,
      "loss": 0.0,
      "step": 24010
    },
    {
      "epoch": 6.862857142857143,
      "grad_norm": 0.0016317351255565882,
      "learning_rate": 1.084952380952381e-05,
      "loss": 0.0,
      "step": 24020
    },
    {
      "epoch": 6.865714285714286,
      "grad_norm": 0.00021465901227202266,
      "learning_rate": 1.0845714285714286e-05,
      "loss": 0.0,
      "step": 24030
    },
    {
      "epoch": 6.868571428571428,
      "grad_norm": 0.00030423386488109827,
      "learning_rate": 1.0841904761904762e-05,
      "loss": 0.0,
      "step": 24040
    },
    {
      "epoch": 6.871428571428572,
      "grad_norm": 0.0006363202119246125,
      "learning_rate": 1.0838095238095239e-05,
      "loss": 0.0,
      "step": 24050
    },
    {
      "epoch": 6.8742857142857146,
      "grad_norm": 2.9531458494602703e-05,
      "learning_rate": 1.0834285714285715e-05,
      "loss": 0.0008,
      "step": 24060
    },
    {
      "epoch": 6.877142857142857,
      "grad_norm": 6.48010682198219e-05,
      "learning_rate": 1.0830476190476192e-05,
      "loss": 0.0,
      "step": 24070
    },
    {
      "epoch": 6.88,
      "grad_norm": 3.540747638908215e-05,
      "learning_rate": 1.0826666666666667e-05,
      "loss": 0.0,
      "step": 24080
    },
    {
      "epoch": 6.882857142857143,
      "grad_norm": 0.00016283465083688498,
      "learning_rate": 1.0822857142857143e-05,
      "loss": 0.0,
      "step": 24090
    },
    {
      "epoch": 6.885714285714286,
      "grad_norm": 2.5972996809286997e-05,
      "learning_rate": 1.081904761904762e-05,
      "loss": 0.0,
      "step": 24100
    },
    {
      "epoch": 6.888571428571429,
      "grad_norm": 2.1239389752736315e-05,
      "learning_rate": 1.0815238095238096e-05,
      "loss": 0.0,
      "step": 24110
    },
    {
      "epoch": 6.8914285714285715,
      "grad_norm": 0.00031443696934729815,
      "learning_rate": 1.0811428571428573e-05,
      "loss": 0.0,
      "step": 24120
    },
    {
      "epoch": 6.894285714285714,
      "grad_norm": 0.00022060064657125622,
      "learning_rate": 1.0807619047619049e-05,
      "loss": 0.0,
      "step": 24130
    },
    {
      "epoch": 6.897142857142857,
      "grad_norm": 3.266856219852343e-05,
      "learning_rate": 1.0803809523809526e-05,
      "loss": 0.1849,
      "step": 24140
    },
    {
      "epoch": 6.9,
      "grad_norm": 3.909578299499117e-05,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0,
      "step": 24150
    },
    {
      "epoch": 6.902857142857143,
      "grad_norm": 6.927113281562924e-05,
      "learning_rate": 1.0796190476190477e-05,
      "loss": 0.1921,
      "step": 24160
    },
    {
      "epoch": 6.905714285714286,
      "grad_norm": 0.00014898047083988786,
      "learning_rate": 1.0792380952380954e-05,
      "loss": 0.0005,
      "step": 24170
    },
    {
      "epoch": 6.908571428571428,
      "grad_norm": 0.0006001271540299058,
      "learning_rate": 1.078857142857143e-05,
      "loss": 0.0,
      "step": 24180
    },
    {
      "epoch": 6.911428571428571,
      "grad_norm": 0.000301189546007663,
      "learning_rate": 1.0784761904761904e-05,
      "loss": 0.0,
      "step": 24190
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 0.0003611828724388033,
      "learning_rate": 1.0780952380952381e-05,
      "loss": 0.0,
      "step": 24200
    },
    {
      "epoch": 6.917142857142857,
      "grad_norm": 0.005115479696542025,
      "learning_rate": 1.0777142857142857e-05,
      "loss": 0.1859,
      "step": 24210
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.000907750625628978,
      "learning_rate": 1.0773333333333334e-05,
      "loss": 0.0,
      "step": 24220
    },
    {
      "epoch": 6.922857142857143,
      "grad_norm": 5.638353104586713e-05,
      "learning_rate": 1.076952380952381e-05,
      "loss": 0.1788,
      "step": 24230
    },
    {
      "epoch": 6.925714285714285,
      "grad_norm": 321.2757568359375,
      "learning_rate": 1.0765714285714285e-05,
      "loss": 0.0658,
      "step": 24240
    },
    {
      "epoch": 6.928571428571429,
      "grad_norm": 0.0005156628903932869,
      "learning_rate": 1.0761904761904763e-05,
      "loss": 0.3755,
      "step": 24250
    },
    {
      "epoch": 6.9314285714285715,
      "grad_norm": 0.001485908403992653,
      "learning_rate": 1.0758095238095238e-05,
      "loss": 0.0001,
      "step": 24260
    },
    {
      "epoch": 6.934285714285714,
      "grad_norm": 0.14602306485176086,
      "learning_rate": 1.0754285714285715e-05,
      "loss": 0.0003,
      "step": 24270
    },
    {
      "epoch": 6.937142857142857,
      "grad_norm": 0.0010952933225780725,
      "learning_rate": 1.0750476190476191e-05,
      "loss": 0.0003,
      "step": 24280
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.0015663112280890346,
      "learning_rate": 1.0746666666666668e-05,
      "loss": 0.0002,
      "step": 24290
    },
    {
      "epoch": 6.942857142857143,
      "grad_norm": 0.004917421843856573,
      "learning_rate": 1.0742857142857144e-05,
      "loss": 0.0,
      "step": 24300
    },
    {
      "epoch": 6.945714285714286,
      "grad_norm": 0.0001525454717921093,
      "learning_rate": 1.073904761904762e-05,
      "loss": 0.1261,
      "step": 24310
    },
    {
      "epoch": 6.948571428571428,
      "grad_norm": 0.0009536553989164531,
      "learning_rate": 1.0735238095238097e-05,
      "loss": 0.0002,
      "step": 24320
    },
    {
      "epoch": 6.951428571428571,
      "grad_norm": 0.0005476712249219418,
      "learning_rate": 1.0731428571428572e-05,
      "loss": 0.0,
      "step": 24330
    },
    {
      "epoch": 6.954285714285715,
      "grad_norm": 0.01820041984319687,
      "learning_rate": 1.072761904761905e-05,
      "loss": 0.0,
      "step": 24340
    },
    {
      "epoch": 6.957142857142857,
      "grad_norm": 0.001386240473948419,
      "learning_rate": 1.0723809523809525e-05,
      "loss": 0.0,
      "step": 24350
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.000129962048958987,
      "learning_rate": 1.072e-05,
      "loss": 0.0,
      "step": 24360
    },
    {
      "epoch": 6.962857142857143,
      "grad_norm": 0.0018929800717160106,
      "learning_rate": 1.0716190476190478e-05,
      "loss": 0.0,
      "step": 24370
    },
    {
      "epoch": 6.965714285714286,
      "grad_norm": 0.00040725638973526657,
      "learning_rate": 1.0712380952380954e-05,
      "loss": 0.0,
      "step": 24380
    },
    {
      "epoch": 6.968571428571429,
      "grad_norm": 9.129387035500258e-05,
      "learning_rate": 1.070857142857143e-05,
      "loss": 0.0,
      "step": 24390
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 0.00017891755851451308,
      "learning_rate": 1.0704761904761906e-05,
      "loss": 0.0,
      "step": 24400
    },
    {
      "epoch": 6.974285714285714,
      "grad_norm": 0.012010416947305202,
      "learning_rate": 1.070095238095238e-05,
      "loss": 0.0,
      "step": 24410
    },
    {
      "epoch": 6.977142857142857,
      "grad_norm": 8.449020242551342e-05,
      "learning_rate": 1.0697142857142858e-05,
      "loss": 0.0,
      "step": 24420
    },
    {
      "epoch": 6.98,
      "grad_norm": 0.0028455262072384357,
      "learning_rate": 1.0693333333333333e-05,
      "loss": 0.0,
      "step": 24430
    },
    {
      "epoch": 6.982857142857143,
      "grad_norm": 0.00020152587967459112,
      "learning_rate": 1.068952380952381e-05,
      "loss": 0.0098,
      "step": 24440
    },
    {
      "epoch": 6.985714285714286,
      "grad_norm": 0.0003203362866770476,
      "learning_rate": 1.0685714285714286e-05,
      "loss": 0.0,
      "step": 24450
    },
    {
      "epoch": 6.988571428571428,
      "grad_norm": 9.06975765246898e-05,
      "learning_rate": 1.0681904761904762e-05,
      "loss": 0.0,
      "step": 24460
    },
    {
      "epoch": 6.991428571428571,
      "grad_norm": 8.768410771153867e-05,
      "learning_rate": 1.0678095238095239e-05,
      "loss": 0.0,
      "step": 24470
    },
    {
      "epoch": 6.994285714285715,
      "grad_norm": 0.0001438960462110117,
      "learning_rate": 1.0674285714285714e-05,
      "loss": 0.0001,
      "step": 24480
    },
    {
      "epoch": 6.997142857142857,
      "grad_norm": 0.0022561203222721815,
      "learning_rate": 1.0670476190476192e-05,
      "loss": 0.0,
      "step": 24490
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.00018291163723915815,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.0,
      "step": 24500
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9796666666666667,
      "eval_f1": 0.8792079207920793,
      "eval_loss": 0.16553674638271332,
      "eval_precision": 0.8844621513944223,
      "eval_recall": 0.8740157480314961,
      "eval_runtime": 372.8583,
      "eval_samples_per_second": 8.046,
      "eval_steps_per_second": 2.011,
      "step": 24500
    },
    {
      "epoch": 7.002857142857143,
      "grad_norm": 0.0001527218846604228,
      "learning_rate": 1.0662857142857143e-05,
      "loss": 0.0,
      "step": 24510
    },
    {
      "epoch": 7.005714285714285,
      "grad_norm": 0.00030133407562971115,
      "learning_rate": 1.065904761904762e-05,
      "loss": 0.0,
      "step": 24520
    },
    {
      "epoch": 7.008571428571429,
      "grad_norm": 0.00012094683916075155,
      "learning_rate": 1.0655238095238096e-05,
      "loss": 0.0007,
      "step": 24530
    },
    {
      "epoch": 7.011428571428572,
      "grad_norm": 0.0006689121364615858,
      "learning_rate": 1.0651428571428573e-05,
      "loss": 0.0,
      "step": 24540
    },
    {
      "epoch": 7.014285714285714,
      "grad_norm": 0.0003748421440832317,
      "learning_rate": 1.0647619047619049e-05,
      "loss": 0.0138,
      "step": 24550
    },
    {
      "epoch": 7.017142857142857,
      "grad_norm": 0.00012132451956858858,
      "learning_rate": 1.0643809523809526e-05,
      "loss": 0.0,
      "step": 24560
    },
    {
      "epoch": 7.02,
      "grad_norm": 7.757215644232929e-05,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.0,
      "step": 24570
    },
    {
      "epoch": 7.022857142857143,
      "grad_norm": 0.0006548410747200251,
      "learning_rate": 1.0636190476190477e-05,
      "loss": 0.0007,
      "step": 24580
    },
    {
      "epoch": 7.025714285714286,
      "grad_norm": 6.319097883533686e-05,
      "learning_rate": 1.0632380952380954e-05,
      "loss": 0.0,
      "step": 24590
    },
    {
      "epoch": 7.0285714285714285,
      "grad_norm": 0.0002782373921945691,
      "learning_rate": 1.062857142857143e-05,
      "loss": 0.0001,
      "step": 24600
    },
    {
      "epoch": 7.031428571428571,
      "grad_norm": 4.3323558202246204e-05,
      "learning_rate": 1.0624761904761907e-05,
      "loss": 0.0,
      "step": 24610
    },
    {
      "epoch": 7.034285714285715,
      "grad_norm": 4.8053199861897156e-05,
      "learning_rate": 1.0620952380952383e-05,
      "loss": 0.2081,
      "step": 24620
    },
    {
      "epoch": 7.037142857142857,
      "grad_norm": 0.00025599446962587535,
      "learning_rate": 1.0617142857142857e-05,
      "loss": 0.0,
      "step": 24630
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.0017350033158436418,
      "learning_rate": 1.0613333333333334e-05,
      "loss": 0.0,
      "step": 24640
    },
    {
      "epoch": 7.042857142857143,
      "grad_norm": 0.00022772123338654637,
      "learning_rate": 1.060952380952381e-05,
      "loss": 0.0002,
      "step": 24650
    },
    {
      "epoch": 7.045714285714285,
      "grad_norm": 0.00020215354743413627,
      "learning_rate": 1.0605714285714285e-05,
      "loss": 0.0,
      "step": 24660
    },
    {
      "epoch": 7.048571428571429,
      "grad_norm": 0.0015120197786018252,
      "learning_rate": 1.0601904761904762e-05,
      "loss": 0.0,
      "step": 24670
    },
    {
      "epoch": 7.051428571428572,
      "grad_norm": 5.5059848818928e-05,
      "learning_rate": 1.0598095238095238e-05,
      "loss": 0.0,
      "step": 24680
    },
    {
      "epoch": 7.054285714285714,
      "grad_norm": 0.00011976828682236373,
      "learning_rate": 1.0594285714285715e-05,
      "loss": 0.1478,
      "step": 24690
    },
    {
      "epoch": 7.057142857142857,
      "grad_norm": 0.00017516514344606549,
      "learning_rate": 1.059047619047619e-05,
      "loss": 0.0,
      "step": 24700
    },
    {
      "epoch": 7.06,
      "grad_norm": 8.67922863108106e-05,
      "learning_rate": 1.0586666666666668e-05,
      "loss": 0.0,
      "step": 24710
    },
    {
      "epoch": 7.062857142857143,
      "grad_norm": 0.0042201196774840355,
      "learning_rate": 1.0582857142857144e-05,
      "loss": 0.0,
      "step": 24720
    },
    {
      "epoch": 7.065714285714286,
      "grad_norm": 9.331959881819785e-05,
      "learning_rate": 1.057904761904762e-05,
      "loss": 0.0,
      "step": 24730
    },
    {
      "epoch": 7.0685714285714285,
      "grad_norm": 6.717108772136271e-05,
      "learning_rate": 1.0575238095238097e-05,
      "loss": 0.0,
      "step": 24740
    },
    {
      "epoch": 7.071428571428571,
      "grad_norm": 0.00037982448702678084,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 0.0,
      "step": 24750
    },
    {
      "epoch": 7.074285714285715,
      "grad_norm": 0.0001234036753885448,
      "learning_rate": 1.056761904761905e-05,
      "loss": 0.0,
      "step": 24760
    },
    {
      "epoch": 7.077142857142857,
      "grad_norm": 7.391969120362774e-05,
      "learning_rate": 1.0563809523809525e-05,
      "loss": 0.0,
      "step": 24770
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.0001395749277435243,
      "learning_rate": 1.056e-05,
      "loss": 0.0,
      "step": 24780
    },
    {
      "epoch": 7.082857142857143,
      "grad_norm": 0.0001287610939471051,
      "learning_rate": 1.0556190476190478e-05,
      "loss": 0.0,
      "step": 24790
    },
    {
      "epoch": 7.085714285714285,
      "grad_norm": 7.047960389172658e-05,
      "learning_rate": 1.0552380952380953e-05,
      "loss": 0.0002,
      "step": 24800
    },
    {
      "epoch": 7.088571428571429,
      "grad_norm": 0.00036691519198939204,
      "learning_rate": 1.054857142857143e-05,
      "loss": 0.0,
      "step": 24810
    },
    {
      "epoch": 7.091428571428572,
      "grad_norm": 0.004933362361043692,
      "learning_rate": 1.0544761904761906e-05,
      "loss": 0.0,
      "step": 24820
    },
    {
      "epoch": 7.094285714285714,
      "grad_norm": 0.0017634757095947862,
      "learning_rate": 1.0540952380952384e-05,
      "loss": 0.0,
      "step": 24830
    },
    {
      "epoch": 7.097142857142857,
      "grad_norm": 4.9374539230484515e-05,
      "learning_rate": 1.0537142857142857e-05,
      "loss": 0.0,
      "step": 24840
    },
    {
      "epoch": 7.1,
      "grad_norm": 6.253919855225831e-05,
      "learning_rate": 1.0533333333333333e-05,
      "loss": 0.0,
      "step": 24850
    },
    {
      "epoch": 7.102857142857143,
      "grad_norm": 8.729962428333238e-05,
      "learning_rate": 1.052952380952381e-05,
      "loss": 0.0,
      "step": 24860
    },
    {
      "epoch": 7.105714285714286,
      "grad_norm": 7.792424003127962e-05,
      "learning_rate": 1.0525714285714286e-05,
      "loss": 0.0,
      "step": 24870
    },
    {
      "epoch": 7.1085714285714285,
      "grad_norm": 0.0013679146068170667,
      "learning_rate": 1.0521904761904761e-05,
      "loss": 0.0001,
      "step": 24880
    },
    {
      "epoch": 7.111428571428571,
      "grad_norm": 5.91357093071565e-05,
      "learning_rate": 1.0518095238095239e-05,
      "loss": 0.0,
      "step": 24890
    },
    {
      "epoch": 7.114285714285714,
      "grad_norm": 4.489373532123864e-05,
      "learning_rate": 1.0514285714285714e-05,
      "loss": 0.0003,
      "step": 24900
    },
    {
      "epoch": 7.117142857142857,
      "grad_norm": 0.00020633780513890088,
      "learning_rate": 1.0510476190476192e-05,
      "loss": 0.0051,
      "step": 24910
    },
    {
      "epoch": 7.12,
      "grad_norm": 0.005204675253480673,
      "learning_rate": 1.0506666666666667e-05,
      "loss": 0.0001,
      "step": 24920
    },
    {
      "epoch": 7.122857142857143,
      "grad_norm": 4.445713057066314e-05,
      "learning_rate": 1.0502857142857143e-05,
      "loss": 0.0,
      "step": 24930
    },
    {
      "epoch": 7.1257142857142854,
      "grad_norm": 9.321609104517847e-05,
      "learning_rate": 1.049904761904762e-05,
      "loss": 0.0,
      "step": 24940
    },
    {
      "epoch": 7.128571428571428,
      "grad_norm": 0.0005420403322204947,
      "learning_rate": 1.0495238095238096e-05,
      "loss": 0.0,
      "step": 24950
    },
    {
      "epoch": 7.131428571428572,
      "grad_norm": 2.9380144042079337e-05,
      "learning_rate": 1.0491428571428573e-05,
      "loss": 0.0,
      "step": 24960
    },
    {
      "epoch": 7.134285714285714,
      "grad_norm": 3.4390461223665625e-05,
      "learning_rate": 1.0487619047619048e-05,
      "loss": 0.0,
      "step": 24970
    },
    {
      "epoch": 7.137142857142857,
      "grad_norm": 4.993193215341307e-05,
      "learning_rate": 1.0483809523809526e-05,
      "loss": 0.0,
      "step": 24980
    },
    {
      "epoch": 7.14,
      "grad_norm": 8.966591121861711e-05,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.0,
      "step": 24990
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 2.7544607291929424e-05,
      "learning_rate": 1.0476190476190477e-05,
      "loss": 0.0,
      "step": 25000
    },
    {
      "epoch": 7.145714285714286,
      "grad_norm": 2.2189000446815044e-05,
      "learning_rate": 1.0472380952380954e-05,
      "loss": 0.0,
      "step": 25010
    },
    {
      "epoch": 7.148571428571429,
      "grad_norm": 8.748381515033543e-05,
      "learning_rate": 1.046857142857143e-05,
      "loss": 0.0,
      "step": 25020
    },
    {
      "epoch": 7.151428571428571,
      "grad_norm": 0.0001081474038073793,
      "learning_rate": 1.0464761904761907e-05,
      "loss": 0.0,
      "step": 25030
    },
    {
      "epoch": 7.154285714285714,
      "grad_norm": 0.00015691232692915946,
      "learning_rate": 1.0460952380952383e-05,
      "loss": 0.0,
      "step": 25040
    },
    {
      "epoch": 7.1571428571428575,
      "grad_norm": 0.00020427191338967532,
      "learning_rate": 1.045714285714286e-05,
      "loss": 0.1668,
      "step": 25050
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.00016869867977220565,
      "learning_rate": 1.0453333333333334e-05,
      "loss": 0.0,
      "step": 25060
    },
    {
      "epoch": 7.162857142857143,
      "grad_norm": 3.248423308832571e-05,
      "learning_rate": 1.044952380952381e-05,
      "loss": 0.0,
      "step": 25070
    },
    {
      "epoch": 7.1657142857142855,
      "grad_norm": 0.0011391814332455397,
      "learning_rate": 1.0445714285714285e-05,
      "loss": 0.0,
      "step": 25080
    },
    {
      "epoch": 7.168571428571428,
      "grad_norm": 0.00013378912990447134,
      "learning_rate": 1.0441904761904762e-05,
      "loss": 0.0,
      "step": 25090
    },
    {
      "epoch": 7.171428571428572,
      "grad_norm": 0.0006032235105521977,
      "learning_rate": 1.0438095238095238e-05,
      "loss": 0.0,
      "step": 25100
    },
    {
      "epoch": 7.174285714285714,
      "grad_norm": 0.0005802126252092421,
      "learning_rate": 1.0434285714285715e-05,
      "loss": 0.0,
      "step": 25110
    },
    {
      "epoch": 7.177142857142857,
      "grad_norm": 3.495565033517778e-05,
      "learning_rate": 1.043047619047619e-05,
      "loss": 0.1152,
      "step": 25120
    },
    {
      "epoch": 7.18,
      "grad_norm": 0.0011627580970525742,
      "learning_rate": 1.0426666666666668e-05,
      "loss": 0.0002,
      "step": 25130
    },
    {
      "epoch": 7.182857142857143,
      "grad_norm": 5.905187572352588e-05,
      "learning_rate": 1.0422857142857143e-05,
      "loss": 0.0,
      "step": 25140
    },
    {
      "epoch": 7.185714285714286,
      "grad_norm": 0.00023318336752709,
      "learning_rate": 1.0419047619047619e-05,
      "loss": 0.0,
      "step": 25150
    },
    {
      "epoch": 7.188571428571429,
      "grad_norm": 0.00029508682200685143,
      "learning_rate": 1.0415238095238096e-05,
      "loss": 0.0002,
      "step": 25160
    },
    {
      "epoch": 7.191428571428571,
      "grad_norm": 0.00015595954027958214,
      "learning_rate": 1.0411428571428572e-05,
      "loss": 0.0,
      "step": 25170
    },
    {
      "epoch": 7.194285714285714,
      "grad_norm": 0.00026044747210107744,
      "learning_rate": 1.040761904761905e-05,
      "loss": 0.0006,
      "step": 25180
    },
    {
      "epoch": 7.1971428571428575,
      "grad_norm": 3.288429797976278e-05,
      "learning_rate": 1.0403809523809525e-05,
      "loss": 0.0,
      "step": 25190
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.0011426135897636414,
      "learning_rate": 1.04e-05,
      "loss": 0.0,
      "step": 25200
    },
    {
      "epoch": 7.202857142857143,
      "grad_norm": 2.338293779757805e-05,
      "learning_rate": 1.0396190476190478e-05,
      "loss": 0.0,
      "step": 25210
    },
    {
      "epoch": 7.2057142857142855,
      "grad_norm": 0.00025660404935479164,
      "learning_rate": 1.0392380952380953e-05,
      "loss": 0.0,
      "step": 25220
    },
    {
      "epoch": 7.208571428571428,
      "grad_norm": 2.6209234420093708e-05,
      "learning_rate": 1.038857142857143e-05,
      "loss": 0.0,
      "step": 25230
    },
    {
      "epoch": 7.211428571428572,
      "grad_norm": 2.1814001229358837e-05,
      "learning_rate": 1.0384761904761906e-05,
      "loss": 0.0,
      "step": 25240
    },
    {
      "epoch": 7.214285714285714,
      "grad_norm": 0.00020070266327820718,
      "learning_rate": 1.0380952380952383e-05,
      "loss": 0.0,
      "step": 25250
    },
    {
      "epoch": 7.217142857142857,
      "grad_norm": 0.0003166892856825143,
      "learning_rate": 1.0377142857142859e-05,
      "loss": 0.0,
      "step": 25260
    },
    {
      "epoch": 7.22,
      "grad_norm": 2.6855052055907436e-05,
      "learning_rate": 1.0373333333333335e-05,
      "loss": 0.0,
      "step": 25270
    },
    {
      "epoch": 7.222857142857142,
      "grad_norm": 3.373873914824799e-05,
      "learning_rate": 1.036952380952381e-05,
      "loss": 0.046,
      "step": 25280
    },
    {
      "epoch": 7.225714285714286,
      "grad_norm": 0.00015171716222539544,
      "learning_rate": 1.0365714285714286e-05,
      "loss": 0.0,
      "step": 25290
    },
    {
      "epoch": 7.228571428571429,
      "grad_norm": 0.00014042375551071018,
      "learning_rate": 1.0361904761904761e-05,
      "loss": 0.351,
      "step": 25300
    },
    {
      "epoch": 7.231428571428571,
      "grad_norm": 0.00032867013942450285,
      "learning_rate": 1.0358095238095239e-05,
      "loss": 0.0,
      "step": 25310
    },
    {
      "epoch": 7.234285714285714,
      "grad_norm": 0.00029822165379300714,
      "learning_rate": 1.0354285714285714e-05,
      "loss": 0.0,
      "step": 25320
    },
    {
      "epoch": 7.2371428571428575,
      "grad_norm": 0.0005207890644669533,
      "learning_rate": 1.0350476190476191e-05,
      "loss": 0.0,
      "step": 25330
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.0002722388890106231,
      "learning_rate": 1.0346666666666667e-05,
      "loss": 0.0,
      "step": 25340
    },
    {
      "epoch": 7.242857142857143,
      "grad_norm": 0.0008682321640662849,
      "learning_rate": 1.0342857142857143e-05,
      "loss": 0.0,
      "step": 25350
    },
    {
      "epoch": 7.2457142857142856,
      "grad_norm": 0.00021948434005025774,
      "learning_rate": 1.033904761904762e-05,
      "loss": 0.0,
      "step": 25360
    },
    {
      "epoch": 7.248571428571428,
      "grad_norm": 0.0011726865777745843,
      "learning_rate": 1.0335238095238095e-05,
      "loss": 0.0,
      "step": 25370
    },
    {
      "epoch": 7.251428571428572,
      "grad_norm": 0.0005412266473285854,
      "learning_rate": 1.0331428571428573e-05,
      "loss": 0.0,
      "step": 25380
    },
    {
      "epoch": 7.2542857142857144,
      "grad_norm": 0.0003879306896124035,
      "learning_rate": 1.0327619047619048e-05,
      "loss": 0.1179,
      "step": 25390
    },
    {
      "epoch": 7.257142857142857,
      "grad_norm": 0.0004487078113015741,
      "learning_rate": 1.0323809523809526e-05,
      "loss": 0.0,
      "step": 25400
    },
    {
      "epoch": 7.26,
      "grad_norm": 0.0003591416170820594,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.0,
      "step": 25410
    },
    {
      "epoch": 7.2628571428571425,
      "grad_norm": 0.0002445235732011497,
      "learning_rate": 1.0316190476190477e-05,
      "loss": 0.0,
      "step": 25420
    },
    {
      "epoch": 7.265714285714286,
      "grad_norm": 0.004561626818031073,
      "learning_rate": 1.0312380952380954e-05,
      "loss": 0.0,
      "step": 25430
    },
    {
      "epoch": 7.268571428571429,
      "grad_norm": 0.0008173260139301419,
      "learning_rate": 1.030857142857143e-05,
      "loss": 0.0,
      "step": 25440
    },
    {
      "epoch": 7.271428571428571,
      "grad_norm": 0.003920657094568014,
      "learning_rate": 1.0304761904761907e-05,
      "loss": 0.0,
      "step": 25450
    },
    {
      "epoch": 7.274285714285714,
      "grad_norm": 0.00025094315060414374,
      "learning_rate": 1.0300952380952382e-05,
      "loss": 0.0,
      "step": 25460
    },
    {
      "epoch": 7.277142857142858,
      "grad_norm": 0.00035500468220561743,
      "learning_rate": 1.029714285714286e-05,
      "loss": 0.0,
      "step": 25470
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.0008246111683547497,
      "learning_rate": 1.0293333333333335e-05,
      "loss": 0.0,
      "step": 25480
    },
    {
      "epoch": 7.282857142857143,
      "grad_norm": 0.0002516725508030504,
      "learning_rate": 1.0289523809523811e-05,
      "loss": 0.0,
      "step": 25490
    },
    {
      "epoch": 7.285714285714286,
      "grad_norm": 0.0021020977292209864,
      "learning_rate": 1.0285714285714285e-05,
      "loss": 0.0,
      "step": 25500
    },
    {
      "epoch": 7.288571428571428,
      "grad_norm": 0.0002747840480878949,
      "learning_rate": 1.0281904761904762e-05,
      "loss": 0.0,
      "step": 25510
    },
    {
      "epoch": 7.291428571428572,
      "grad_norm": 0.12252888083457947,
      "learning_rate": 1.0278095238095238e-05,
      "loss": 0.0001,
      "step": 25520
    },
    {
      "epoch": 7.2942857142857145,
      "grad_norm": 0.0003303487610537559,
      "learning_rate": 1.0274285714285715e-05,
      "loss": 0.0,
      "step": 25530
    },
    {
      "epoch": 7.297142857142857,
      "grad_norm": 0.00014699457096867263,
      "learning_rate": 1.027047619047619e-05,
      "loss": 0.0,
      "step": 25540
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.00015568919479846954,
      "learning_rate": 1.0266666666666668e-05,
      "loss": 0.0,
      "step": 25550
    },
    {
      "epoch": 7.3028571428571425,
      "grad_norm": 0.0002612220123410225,
      "learning_rate": 1.0262857142857143e-05,
      "loss": 0.0,
      "step": 25560
    },
    {
      "epoch": 7.305714285714286,
      "grad_norm": 0.00015590953989885747,
      "learning_rate": 1.0259047619047619e-05,
      "loss": 0.0,
      "step": 25570
    },
    {
      "epoch": 7.308571428571429,
      "grad_norm": 0.000224009359953925,
      "learning_rate": 1.0255238095238096e-05,
      "loss": 0.0,
      "step": 25580
    },
    {
      "epoch": 7.311428571428571,
      "grad_norm": 0.00022704934235662222,
      "learning_rate": 1.0251428571428572e-05,
      "loss": 0.0,
      "step": 25590
    },
    {
      "epoch": 7.314285714285714,
      "grad_norm": 0.00016911642160266638,
      "learning_rate": 1.0247619047619049e-05,
      "loss": 0.0,
      "step": 25600
    },
    {
      "epoch": 7.317142857142857,
      "grad_norm": 0.00010445196676300839,
      "learning_rate": 1.0243809523809525e-05,
      "loss": 0.0,
      "step": 25610
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.00016103967209346592,
      "learning_rate": 1.024e-05,
      "loss": 0.0,
      "step": 25620
    },
    {
      "epoch": 7.322857142857143,
      "grad_norm": 0.0001373640407109633,
      "learning_rate": 1.0236190476190477e-05,
      "loss": 0.0,
      "step": 25630
    },
    {
      "epoch": 7.325714285714286,
      "grad_norm": 0.0003110415709670633,
      "learning_rate": 1.0232380952380953e-05,
      "loss": 0.0,
      "step": 25640
    },
    {
      "epoch": 7.328571428571428,
      "grad_norm": 0.0001373264385620132,
      "learning_rate": 1.022857142857143e-05,
      "loss": 0.0,
      "step": 25650
    },
    {
      "epoch": 7.331428571428571,
      "grad_norm": 0.00013167850556783378,
      "learning_rate": 1.0224761904761906e-05,
      "loss": 0.0001,
      "step": 25660
    },
    {
      "epoch": 7.3342857142857145,
      "grad_norm": 0.00022924618679098785,
      "learning_rate": 1.0220952380952383e-05,
      "loss": 0.0,
      "step": 25670
    },
    {
      "epoch": 7.337142857142857,
      "grad_norm": 0.00030288950074464083,
      "learning_rate": 1.0217142857142859e-05,
      "loss": 0.0,
      "step": 25680
    },
    {
      "epoch": 7.34,
      "grad_norm": 0.018464792519807816,
      "learning_rate": 1.0213333333333334e-05,
      "loss": 0.0,
      "step": 25690
    },
    {
      "epoch": 7.3428571428571425,
      "grad_norm": 0.00016197384684346616,
      "learning_rate": 1.0209523809523812e-05,
      "loss": 0.0,
      "step": 25700
    },
    {
      "epoch": 7.345714285714286,
      "grad_norm": 0.0004560434026643634,
      "learning_rate": 1.0205714285714286e-05,
      "loss": 0.0,
      "step": 25710
    },
    {
      "epoch": 7.348571428571429,
      "grad_norm": 0.00026524465647526085,
      "learning_rate": 1.0201904761904761e-05,
      "loss": 0.0,
      "step": 25720
    },
    {
      "epoch": 7.351428571428571,
      "grad_norm": 0.0004778774455189705,
      "learning_rate": 1.0198095238095238e-05,
      "loss": 0.0,
      "step": 25730
    },
    {
      "epoch": 7.354285714285714,
      "grad_norm": 0.0001651118800509721,
      "learning_rate": 1.0194285714285714e-05,
      "loss": 0.0,
      "step": 25740
    },
    {
      "epoch": 7.357142857142857,
      "grad_norm": 0.00018165557412430644,
      "learning_rate": 1.0190476190476191e-05,
      "loss": 0.0,
      "step": 25750
    },
    {
      "epoch": 7.36,
      "grad_norm": 9.665329707786441e-05,
      "learning_rate": 1.0186666666666667e-05,
      "loss": 0.0,
      "step": 25760
    },
    {
      "epoch": 7.362857142857143,
      "grad_norm": 0.001875210553407669,
      "learning_rate": 1.0182857142857142e-05,
      "loss": 0.0,
      "step": 25770
    },
    {
      "epoch": 7.365714285714286,
      "grad_norm": 0.00020615167159121484,
      "learning_rate": 1.017904761904762e-05,
      "loss": 0.0,
      "step": 25780
    },
    {
      "epoch": 7.368571428571428,
      "grad_norm": 0.00011442531831562519,
      "learning_rate": 1.0175238095238095e-05,
      "loss": 0.0,
      "step": 25790
    },
    {
      "epoch": 7.371428571428572,
      "grad_norm": 0.0004876179154962301,
      "learning_rate": 1.0171428571428573e-05,
      "loss": 0.0,
      "step": 25800
    },
    {
      "epoch": 7.3742857142857146,
      "grad_norm": 0.00020638969726860523,
      "learning_rate": 1.0167619047619048e-05,
      "loss": 0.0,
      "step": 25810
    },
    {
      "epoch": 7.377142857142857,
      "grad_norm": 9.673999738879502e-05,
      "learning_rate": 1.0163809523809525e-05,
      "loss": 0.0,
      "step": 25820
    },
    {
      "epoch": 7.38,
      "grad_norm": 0.00014508164895232767,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.0,
      "step": 25830
    },
    {
      "epoch": 7.382857142857143,
      "grad_norm": 0.00012574385618790984,
      "learning_rate": 1.0156190476190477e-05,
      "loss": 0.004,
      "step": 25840
    },
    {
      "epoch": 7.385714285714286,
      "grad_norm": 0.000214836371014826,
      "learning_rate": 1.0152380952380954e-05,
      "loss": 0.0522,
      "step": 25850
    },
    {
      "epoch": 7.388571428571429,
      "grad_norm": 0.0001147082875831984,
      "learning_rate": 1.014857142857143e-05,
      "loss": 0.0,
      "step": 25860
    },
    {
      "epoch": 7.3914285714285715,
      "grad_norm": 0.00012212801084388047,
      "learning_rate": 1.0144761904761907e-05,
      "loss": 0.0,
      "step": 25870
    },
    {
      "epoch": 7.394285714285714,
      "grad_norm": 0.00011327587708365172,
      "learning_rate": 1.0140952380952382e-05,
      "loss": 0.0001,
      "step": 25880
    },
    {
      "epoch": 7.397142857142857,
      "grad_norm": 9.098810551222414e-05,
      "learning_rate": 1.013714285714286e-05,
      "loss": 0.0,
      "step": 25890
    },
    {
      "epoch": 7.4,
      "grad_norm": 7.969287253217772e-05,
      "learning_rate": 1.0133333333333335e-05,
      "loss": 0.0,
      "step": 25900
    },
    {
      "epoch": 7.402857142857143,
      "grad_norm": 0.00017614748503547162,
      "learning_rate": 1.012952380952381e-05,
      "loss": 0.0,
      "step": 25910
    },
    {
      "epoch": 7.405714285714286,
      "grad_norm": 0.0017761463532224298,
      "learning_rate": 1.0125714285714288e-05,
      "loss": 0.0,
      "step": 25920
    },
    {
      "epoch": 7.408571428571428,
      "grad_norm": 6.053334436728619e-05,
      "learning_rate": 1.0121904761904762e-05,
      "loss": 0.0,
      "step": 25930
    },
    {
      "epoch": 7.411428571428571,
      "grad_norm": 0.00011226691276533529,
      "learning_rate": 1.0118095238095237e-05,
      "loss": 0.1688,
      "step": 25940
    },
    {
      "epoch": 7.414285714285715,
      "grad_norm": 0.0002214892883785069,
      "learning_rate": 1.0114285714285715e-05,
      "loss": 0.0,
      "step": 25950
    },
    {
      "epoch": 7.417142857142857,
      "grad_norm": 0.0005055998335592449,
      "learning_rate": 1.011047619047619e-05,
      "loss": 0.0,
      "step": 25960
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.00029030180303379893,
      "learning_rate": 1.0106666666666668e-05,
      "loss": 0.0,
      "step": 25970
    },
    {
      "epoch": 7.422857142857143,
      "grad_norm": 0.00014583465235773474,
      "learning_rate": 1.0102857142857143e-05,
      "loss": 0.0,
      "step": 25980
    },
    {
      "epoch": 7.425714285714285,
      "grad_norm": 0.0012991197872906923,
      "learning_rate": 1.0099047619047619e-05,
      "loss": 0.2883,
      "step": 25990
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 0.0005531394854187965,
      "learning_rate": 1.0095238095238096e-05,
      "loss": 0.0,
      "step": 26000
    },
    {
      "epoch": 7.4314285714285715,
      "grad_norm": 0.0017116802046075463,
      "learning_rate": 1.0091428571428572e-05,
      "loss": 0.15,
      "step": 26010
    },
    {
      "epoch": 7.434285714285714,
      "grad_norm": 0.00015485477342735976,
      "learning_rate": 1.0087619047619049e-05,
      "loss": 0.0,
      "step": 26020
    },
    {
      "epoch": 7.437142857142857,
      "grad_norm": 0.00012345662980806082,
      "learning_rate": 1.0083809523809524e-05,
      "loss": 0.0,
      "step": 26030
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.00018231420835945755,
      "learning_rate": 1.008e-05,
      "loss": 0.0,
      "step": 26040
    },
    {
      "epoch": 7.442857142857143,
      "grad_norm": 9.93415669654496e-05,
      "learning_rate": 1.0076190476190477e-05,
      "loss": 0.0277,
      "step": 26050
    },
    {
      "epoch": 7.445714285714286,
      "grad_norm": 0.00010925056994892657,
      "learning_rate": 1.0072380952380953e-05,
      "loss": 0.0,
      "step": 26060
    },
    {
      "epoch": 7.448571428571428,
      "grad_norm": 0.0002143978636013344,
      "learning_rate": 1.006857142857143e-05,
      "loss": 0.0,
      "step": 26070
    },
    {
      "epoch": 7.451428571428571,
      "grad_norm": 0.0004419536853674799,
      "learning_rate": 1.0064761904761906e-05,
      "loss": 0.0,
      "step": 26080
    },
    {
      "epoch": 7.454285714285715,
      "grad_norm": 0.0001479083439335227,
      "learning_rate": 1.0060952380952383e-05,
      "loss": 0.0,
      "step": 26090
    },
    {
      "epoch": 7.457142857142857,
      "grad_norm": 0.003284769831225276,
      "learning_rate": 1.0057142857142859e-05,
      "loss": 0.0001,
      "step": 26100
    },
    {
      "epoch": 7.46,
      "grad_norm": 0.00010276646935380995,
      "learning_rate": 1.0053333333333334e-05,
      "loss": 0.0001,
      "step": 26110
    },
    {
      "epoch": 7.462857142857143,
      "grad_norm": 0.00010728510824264959,
      "learning_rate": 1.0049523809523811e-05,
      "loss": 0.0,
      "step": 26120
    },
    {
      "epoch": 7.465714285714285,
      "grad_norm": 8.717485616216436e-05,
      "learning_rate": 1.0045714285714287e-05,
      "loss": 0.0,
      "step": 26130
    },
    {
      "epoch": 7.468571428571429,
      "grad_norm": 0.00010081965592689812,
      "learning_rate": 1.0041904761904764e-05,
      "loss": 0.0,
      "step": 26140
    },
    {
      "epoch": 7.4714285714285715,
      "grad_norm": 0.000164129858603701,
      "learning_rate": 1.0038095238095238e-05,
      "loss": 0.0,
      "step": 26150
    },
    {
      "epoch": 7.474285714285714,
      "grad_norm": 0.00010902898065978661,
      "learning_rate": 1.0034285714285714e-05,
      "loss": 0.0002,
      "step": 26160
    },
    {
      "epoch": 7.477142857142857,
      "grad_norm": 0.06580546498298645,
      "learning_rate": 1.0030476190476191e-05,
      "loss": 0.0001,
      "step": 26170
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.00011274160351604223,
      "learning_rate": 1.0026666666666667e-05,
      "loss": 0.0,
      "step": 26180
    },
    {
      "epoch": 7.482857142857143,
      "grad_norm": 0.00021947690402157605,
      "learning_rate": 1.0022857142857142e-05,
      "loss": 0.0,
      "step": 26190
    },
    {
      "epoch": 7.485714285714286,
      "grad_norm": 9.725781274028122e-05,
      "learning_rate": 1.001904761904762e-05,
      "loss": 0.0,
      "step": 26200
    },
    {
      "epoch": 7.488571428571428,
      "grad_norm": 0.00011574631207622588,
      "learning_rate": 1.0015238095238095e-05,
      "loss": 0.0,
      "step": 26210
    },
    {
      "epoch": 7.491428571428571,
      "grad_norm": 0.0003662228409666568,
      "learning_rate": 1.0011428571428572e-05,
      "loss": 0.0,
      "step": 26220
    },
    {
      "epoch": 7.494285714285715,
      "grad_norm": 0.0002701781631913036,
      "learning_rate": 1.0007619047619048e-05,
      "loss": 0.3111,
      "step": 26230
    },
    {
      "epoch": 7.497142857142857,
      "grad_norm": 0.003255212912335992,
      "learning_rate": 1.0003809523809525e-05,
      "loss": 0.0,
      "step": 26240
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.0011170204961672425,
      "learning_rate": 1e-05,
      "loss": 0.0001,
      "step": 26250
    },
    {
      "epoch": 7.502857142857143,
      "grad_norm": 0.00024969319929368794,
      "learning_rate": 9.996190476190476e-06,
      "loss": 0.0,
      "step": 26260
    },
    {
      "epoch": 7.505714285714285,
      "grad_norm": 0.0008646914502605796,
      "learning_rate": 9.992380952380954e-06,
      "loss": 0.0,
      "step": 26270
    },
    {
      "epoch": 7.508571428571429,
      "grad_norm": 0.000800600741058588,
      "learning_rate": 9.98857142857143e-06,
      "loss": 0.0021,
      "step": 26280
    },
    {
      "epoch": 7.511428571428572,
      "grad_norm": 0.0004981749225407839,
      "learning_rate": 9.984761904761907e-06,
      "loss": 0.0,
      "step": 26290
    },
    {
      "epoch": 7.514285714285714,
      "grad_norm": 0.00040484563214704394,
      "learning_rate": 9.980952380952382e-06,
      "loss": 0.0,
      "step": 26300
    },
    {
      "epoch": 7.517142857142857,
      "grad_norm": 0.00021033255325164646,
      "learning_rate": 9.977142857142858e-06,
      "loss": 0.0,
      "step": 26310
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.00019656731456052512,
      "learning_rate": 9.973333333333333e-06,
      "loss": 0.0,
      "step": 26320
    },
    {
      "epoch": 7.522857142857143,
      "grad_norm": 0.00020471654715947807,
      "learning_rate": 9.96952380952381e-06,
      "loss": 0.0,
      "step": 26330
    },
    {
      "epoch": 7.525714285714286,
      "grad_norm": 0.00015456827532034367,
      "learning_rate": 9.965714285714286e-06,
      "loss": 0.0,
      "step": 26340
    },
    {
      "epoch": 7.5285714285714285,
      "grad_norm": 0.000272009230684489,
      "learning_rate": 9.961904761904763e-06,
      "loss": 0.0,
      "step": 26350
    },
    {
      "epoch": 7.531428571428571,
      "grad_norm": 0.0002889768802560866,
      "learning_rate": 9.958095238095239e-06,
      "loss": 0.0,
      "step": 26360
    },
    {
      "epoch": 7.534285714285714,
      "grad_norm": 0.00022990077559370548,
      "learning_rate": 9.954285714285715e-06,
      "loss": 0.0,
      "step": 26370
    },
    {
      "epoch": 7.537142857142857,
      "grad_norm": 0.00015860420535318553,
      "learning_rate": 9.950476190476192e-06,
      "loss": 0.0,
      "step": 26380
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.000397766794776544,
      "learning_rate": 9.946666666666667e-06,
      "loss": 0.0,
      "step": 26390
    },
    {
      "epoch": 7.542857142857143,
      "grad_norm": 0.0005644125049002469,
      "learning_rate": 9.942857142857145e-06,
      "loss": 0.0,
      "step": 26400
    },
    {
      "epoch": 7.545714285714285,
      "grad_norm": 0.00015803180576767772,
      "learning_rate": 9.93904761904762e-06,
      "loss": 0.0,
      "step": 26410
    },
    {
      "epoch": 7.548571428571429,
      "grad_norm": 0.0001786062348401174,
      "learning_rate": 9.935238095238096e-06,
      "loss": 0.0,
      "step": 26420
    },
    {
      "epoch": 7.551428571428572,
      "grad_norm": 0.0001459693448850885,
      "learning_rate": 9.931428571428571e-06,
      "loss": 0.0,
      "step": 26430
    },
    {
      "epoch": 7.554285714285714,
      "grad_norm": 0.00015778563101775944,
      "learning_rate": 9.927619047619049e-06,
      "loss": 0.0,
      "step": 26440
    },
    {
      "epoch": 7.557142857142857,
      "grad_norm": 0.0001572848850628361,
      "learning_rate": 9.923809523809524e-06,
      "loss": 0.0,
      "step": 26450
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.00014580485003534704,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.0,
      "step": 26460
    },
    {
      "epoch": 7.562857142857143,
      "grad_norm": 0.00014800805365666747,
      "learning_rate": 9.916190476190477e-06,
      "loss": 0.0003,
      "step": 26470
    },
    {
      "epoch": 7.565714285714286,
      "grad_norm": 0.0001417825696989894,
      "learning_rate": 9.912380952380953e-06,
      "loss": 0.0001,
      "step": 26480
    },
    {
      "epoch": 7.5685714285714285,
      "grad_norm": 0.00010611873585730791,
      "learning_rate": 9.90857142857143e-06,
      "loss": 0.0,
      "step": 26490
    },
    {
      "epoch": 7.571428571428571,
      "grad_norm": 0.00019671702466439456,
      "learning_rate": 9.904761904761906e-06,
      "loss": 0.0,
      "step": 26500
    },
    {
      "epoch": 7.574285714285715,
      "grad_norm": 0.00018119912419933826,
      "learning_rate": 9.900952380952383e-06,
      "loss": 0.0,
      "step": 26510
    },
    {
      "epoch": 7.577142857142857,
      "grad_norm": 0.0001288322382606566,
      "learning_rate": 9.897142857142858e-06,
      "loss": 0.0,
      "step": 26520
    },
    {
      "epoch": 7.58,
      "grad_norm": 0.00014829545398242772,
      "learning_rate": 9.893333333333334e-06,
      "loss": 0.0,
      "step": 26530
    },
    {
      "epoch": 7.582857142857143,
      "grad_norm": 0.00013436510926112533,
      "learning_rate": 9.88952380952381e-06,
      "loss": 0.0,
      "step": 26540
    },
    {
      "epoch": 7.585714285714285,
      "grad_norm": 9.949736704584211e-05,
      "learning_rate": 9.885714285714287e-06,
      "loss": 0.0,
      "step": 26550
    },
    {
      "epoch": 7.588571428571429,
      "grad_norm": 0.00010836149158421904,
      "learning_rate": 9.881904761904762e-06,
      "loss": 0.0,
      "step": 26560
    },
    {
      "epoch": 7.591428571428572,
      "grad_norm": 0.00011422840907471254,
      "learning_rate": 9.878095238095238e-06,
      "loss": 0.0,
      "step": 26570
    },
    {
      "epoch": 7.594285714285714,
      "grad_norm": 0.00012650889402721077,
      "learning_rate": 9.874285714285715e-06,
      "loss": 0.0,
      "step": 26580
    },
    {
      "epoch": 7.597142857142857,
      "grad_norm": 0.00022566480038221925,
      "learning_rate": 9.870476190476191e-06,
      "loss": 0.0,
      "step": 26590
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.00016337355191353709,
      "learning_rate": 9.866666666666668e-06,
      "loss": 0.0,
      "step": 26600
    },
    {
      "epoch": 7.602857142857143,
      "grad_norm": 0.00018449204799253494,
      "learning_rate": 9.862857142857144e-06,
      "loss": 0.0,
      "step": 26610
    },
    {
      "epoch": 7.605714285714286,
      "grad_norm": 0.00013812733232043684,
      "learning_rate": 9.859047619047621e-06,
      "loss": 0.0,
      "step": 26620
    },
    {
      "epoch": 7.6085714285714285,
      "grad_norm": 0.0001298910501645878,
      "learning_rate": 9.855238095238095e-06,
      "loss": 0.0,
      "step": 26630
    },
    {
      "epoch": 7.611428571428571,
      "grad_norm": 0.00017869517614599317,
      "learning_rate": 9.851428571428572e-06,
      "loss": 0.0,
      "step": 26640
    },
    {
      "epoch": 7.614285714285714,
      "grad_norm": 0.00013073344598524272,
      "learning_rate": 9.847619047619048e-06,
      "loss": 0.0,
      "step": 26650
    },
    {
      "epoch": 7.617142857142857,
      "grad_norm": 9.674059401731938e-05,
      "learning_rate": 9.843809523809525e-06,
      "loss": 0.0,
      "step": 26660
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.00011206605267943814,
      "learning_rate": 9.84e-06,
      "loss": 0.0,
      "step": 26670
    },
    {
      "epoch": 7.622857142857143,
      "grad_norm": 0.034972041845321655,
      "learning_rate": 9.836190476190476e-06,
      "loss": 0.0,
      "step": 26680
    },
    {
      "epoch": 7.6257142857142854,
      "grad_norm": 9.575939475325868e-05,
      "learning_rate": 9.832380952380954e-06,
      "loss": 0.0,
      "step": 26690
    },
    {
      "epoch": 7.628571428571428,
      "grad_norm": 0.00012498602154664695,
      "learning_rate": 9.828571428571429e-06,
      "loss": 0.0,
      "step": 26700
    },
    {
      "epoch": 7.631428571428572,
      "grad_norm": 0.0004158237425144762,
      "learning_rate": 9.824761904761906e-06,
      "loss": 0.0,
      "step": 26710
    },
    {
      "epoch": 7.634285714285714,
      "grad_norm": 0.00018700880173128098,
      "learning_rate": 9.820952380952382e-06,
      "loss": 0.0,
      "step": 26720
    },
    {
      "epoch": 7.637142857142857,
      "grad_norm": 0.00010978851787513122,
      "learning_rate": 9.81714285714286e-06,
      "loss": 0.0,
      "step": 26730
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.0007126728305593133,
      "learning_rate": 9.813333333333333e-06,
      "loss": 0.0,
      "step": 26740
    },
    {
      "epoch": 7.642857142857143,
      "grad_norm": 0.00015185013762675226,
      "learning_rate": 9.80952380952381e-06,
      "loss": 0.0,
      "step": 26750
    },
    {
      "epoch": 7.645714285714286,
      "grad_norm": 0.00010090344585478306,
      "learning_rate": 9.805714285714286e-06,
      "loss": 0.0,
      "step": 26760
    },
    {
      "epoch": 7.648571428571429,
      "grad_norm": 0.000403645564801991,
      "learning_rate": 9.801904761904763e-06,
      "loss": 0.0,
      "step": 26770
    },
    {
      "epoch": 7.651428571428571,
      "grad_norm": 78.75812530517578,
      "learning_rate": 9.798095238095239e-06,
      "loss": 0.1568,
      "step": 26780
    },
    {
      "epoch": 7.654285714285714,
      "grad_norm": 8.067045564530417e-05,
      "learning_rate": 9.794285714285714e-06,
      "loss": 0.0,
      "step": 26790
    },
    {
      "epoch": 7.6571428571428575,
      "grad_norm": 0.007355420384556055,
      "learning_rate": 9.790476190476192e-06,
      "loss": 0.0,
      "step": 26800
    },
    {
      "epoch": 7.66,
      "grad_norm": 6.23828309471719e-05,
      "learning_rate": 9.786666666666667e-06,
      "loss": 0.1493,
      "step": 26810
    },
    {
      "epoch": 7.662857142857143,
      "grad_norm": 9.814206714509055e-05,
      "learning_rate": 9.782857142857145e-06,
      "loss": 0.0001,
      "step": 26820
    },
    {
      "epoch": 7.6657142857142855,
      "grad_norm": 0.00035026256227865815,
      "learning_rate": 9.77904761904762e-06,
      "loss": 0.0,
      "step": 26830
    },
    {
      "epoch": 7.668571428571429,
      "grad_norm": 6.994681461947039e-05,
      "learning_rate": 9.775238095238096e-06,
      "loss": 0.0,
      "step": 26840
    },
    {
      "epoch": 7.671428571428572,
      "grad_norm": 0.011270847171545029,
      "learning_rate": 9.771428571428571e-06,
      "loss": 0.0,
      "step": 26850
    },
    {
      "epoch": 7.674285714285714,
      "grad_norm": 0.00025798779097385705,
      "learning_rate": 9.767619047619049e-06,
      "loss": 0.0,
      "step": 26860
    },
    {
      "epoch": 7.677142857142857,
      "grad_norm": 0.00013254047371447086,
      "learning_rate": 9.763809523809524e-06,
      "loss": 0.0,
      "step": 26870
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.00010129104339284822,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.0,
      "step": 26880
    },
    {
      "epoch": 7.682857142857143,
      "grad_norm": 0.00011880860984092578,
      "learning_rate": 9.756190476190477e-06,
      "loss": 0.0,
      "step": 26890
    },
    {
      "epoch": 7.685714285714286,
      "grad_norm": 7.448210089933127e-05,
      "learning_rate": 9.752380952380953e-06,
      "loss": 0.0,
      "step": 26900
    },
    {
      "epoch": 7.688571428571429,
      "grad_norm": 8.64558678586036e-05,
      "learning_rate": 9.74857142857143e-06,
      "loss": 0.0,
      "step": 26910
    },
    {
      "epoch": 7.691428571428571,
      "grad_norm": 0.00034379688440822065,
      "learning_rate": 9.744761904761905e-06,
      "loss": 0.0001,
      "step": 26920
    },
    {
      "epoch": 7.694285714285714,
      "grad_norm": 0.0012165365042164922,
      "learning_rate": 9.740952380952383e-06,
      "loss": 0.0,
      "step": 26930
    },
    {
      "epoch": 7.6971428571428575,
      "grad_norm": 0.00011538293620105833,
      "learning_rate": 9.737142857142858e-06,
      "loss": 0.0,
      "step": 26940
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.0009692074963822961,
      "learning_rate": 9.733333333333334e-06,
      "loss": 0.0,
      "step": 26950
    },
    {
      "epoch": 7.702857142857143,
      "grad_norm": 0.0001120523302233778,
      "learning_rate": 9.72952380952381e-06,
      "loss": 0.0,
      "step": 26960
    },
    {
      "epoch": 7.7057142857142855,
      "grad_norm": 7.92444625403732e-05,
      "learning_rate": 9.725714285714287e-06,
      "loss": 0.0,
      "step": 26970
    },
    {
      "epoch": 7.708571428571428,
      "grad_norm": 0.00021982246835250407,
      "learning_rate": 9.721904761904762e-06,
      "loss": 0.1527,
      "step": 26980
    },
    {
      "epoch": 7.711428571428572,
      "grad_norm": 0.0002052359632216394,
      "learning_rate": 9.718095238095238e-06,
      "loss": 0.0,
      "step": 26990
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 0.05382615700364113,
      "learning_rate": 9.714285714285715e-06,
      "loss": 0.0013,
      "step": 27000
    },
    {
      "epoch": 7.717142857142857,
      "grad_norm": 0.00013470611884258687,
      "learning_rate": 9.71047619047619e-06,
      "loss": 0.0,
      "step": 27010
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.0016984319081529975,
      "learning_rate": 9.706666666666668e-06,
      "loss": 0.0,
      "step": 27020
    },
    {
      "epoch": 7.722857142857142,
      "grad_norm": 0.00030706217512488365,
      "learning_rate": 9.702857142857144e-06,
      "loss": 0.0001,
      "step": 27030
    },
    {
      "epoch": 7.725714285714286,
      "grad_norm": 0.0003666502598207444,
      "learning_rate": 9.699047619047621e-06,
      "loss": 0.0,
      "step": 27040
    },
    {
      "epoch": 7.728571428571429,
      "grad_norm": 9.059889998752624e-05,
      "learning_rate": 9.695238095238096e-06,
      "loss": 0.0001,
      "step": 27050
    },
    {
      "epoch": 7.731428571428571,
      "grad_norm": 0.0001094790204660967,
      "learning_rate": 9.691428571428572e-06,
      "loss": 0.0,
      "step": 27060
    },
    {
      "epoch": 7.734285714285714,
      "grad_norm": 0.00011911470937775448,
      "learning_rate": 9.687619047619048e-06,
      "loss": 0.0,
      "step": 27070
    },
    {
      "epoch": 7.737142857142857,
      "grad_norm": 8.713684655958787e-05,
      "learning_rate": 9.683809523809525e-06,
      "loss": 0.0,
      "step": 27080
    },
    {
      "epoch": 7.74,
      "grad_norm": 0.0006179898045957088,
      "learning_rate": 9.68e-06,
      "loss": 0.3181,
      "step": 27090
    },
    {
      "epoch": 7.742857142857143,
      "grad_norm": 0.0008208646322600543,
      "learning_rate": 9.676190476190476e-06,
      "loss": 0.0,
      "step": 27100
    },
    {
      "epoch": 7.7457142857142856,
      "grad_norm": 0.007908416911959648,
      "learning_rate": 9.672380952380953e-06,
      "loss": 0.0,
      "step": 27110
    },
    {
      "epoch": 7.748571428571428,
      "grad_norm": 9.684392716735601e-05,
      "learning_rate": 9.668571428571429e-06,
      "loss": 0.0,
      "step": 27120
    },
    {
      "epoch": 7.751428571428572,
      "grad_norm": 0.014002451673150063,
      "learning_rate": 9.664761904761906e-06,
      "loss": 0.0,
      "step": 27130
    },
    {
      "epoch": 7.7542857142857144,
      "grad_norm": 9.371422493131831e-05,
      "learning_rate": 9.660952380952382e-06,
      "loss": 0.0,
      "step": 27140
    },
    {
      "epoch": 7.757142857142857,
      "grad_norm": 0.0007231627823784947,
      "learning_rate": 9.657142857142859e-06,
      "loss": 0.0,
      "step": 27150
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.00010233915963908657,
      "learning_rate": 9.653333333333335e-06,
      "loss": 0.0,
      "step": 27160
    },
    {
      "epoch": 7.762857142857143,
      "grad_norm": 0.00013824636698700488,
      "learning_rate": 9.64952380952381e-06,
      "loss": 0.0,
      "step": 27170
    },
    {
      "epoch": 7.765714285714286,
      "grad_norm": 0.00017620365542825311,
      "learning_rate": 9.645714285714286e-06,
      "loss": 0.0,
      "step": 27180
    },
    {
      "epoch": 7.768571428571429,
      "grad_norm": 0.0018094746628776193,
      "learning_rate": 9.641904761904763e-06,
      "loss": 0.0,
      "step": 27190
    },
    {
      "epoch": 7.771428571428571,
      "grad_norm": 0.004964561201632023,
      "learning_rate": 9.638095238095239e-06,
      "loss": 0.0,
      "step": 27200
    },
    {
      "epoch": 7.774285714285714,
      "grad_norm": 9.908347419695929e-05,
      "learning_rate": 9.634285714285714e-06,
      "loss": 0.0,
      "step": 27210
    },
    {
      "epoch": 7.777142857142858,
      "grad_norm": 0.0008146691252477467,
      "learning_rate": 9.630476190476192e-06,
      "loss": 0.0,
      "step": 27220
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.00013849504466634244,
      "learning_rate": 9.626666666666667e-06,
      "loss": 0.0,
      "step": 27230
    },
    {
      "epoch": 7.782857142857143,
      "grad_norm": 8.968164911493659e-05,
      "learning_rate": 9.622857142857144e-06,
      "loss": 0.0,
      "step": 27240
    },
    {
      "epoch": 7.785714285714286,
      "grad_norm": 0.0006532015395350754,
      "learning_rate": 9.61904761904762e-06,
      "loss": 0.0,
      "step": 27250
    },
    {
      "epoch": 7.788571428571428,
      "grad_norm": 8.263537165476009e-05,
      "learning_rate": 9.615238095238096e-06,
      "loss": 0.0,
      "step": 27260
    },
    {
      "epoch": 7.791428571428572,
      "grad_norm": 0.0018393612699583173,
      "learning_rate": 9.611428571428573e-06,
      "loss": 0.0,
      "step": 27270
    },
    {
      "epoch": 7.7942857142857145,
      "grad_norm": 7.905509119154885e-05,
      "learning_rate": 9.607619047619048e-06,
      "loss": 0.0,
      "step": 27280
    },
    {
      "epoch": 7.797142857142857,
      "grad_norm": 8.055081707425416e-05,
      "learning_rate": 9.603809523809524e-06,
      "loss": 0.0,
      "step": 27290
    },
    {
      "epoch": 7.8,
      "grad_norm": 9.505319758318365e-05,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0,
      "step": 27300
    },
    {
      "epoch": 7.8028571428571425,
      "grad_norm": 0.00047890920541249216,
      "learning_rate": 9.596190476190477e-06,
      "loss": 0.0,
      "step": 27310
    },
    {
      "epoch": 7.805714285714286,
      "grad_norm": 0.0006824528682045639,
      "learning_rate": 9.592380952380952e-06,
      "loss": 0.0,
      "step": 27320
    },
    {
      "epoch": 7.808571428571429,
      "grad_norm": 0.028243623673915863,
      "learning_rate": 9.58857142857143e-06,
      "loss": 0.092,
      "step": 27330
    },
    {
      "epoch": 7.811428571428571,
      "grad_norm": 0.00016830435197334737,
      "learning_rate": 9.584761904761905e-06,
      "loss": 0.0,
      "step": 27340
    },
    {
      "epoch": 7.814285714285714,
      "grad_norm": 7.242212450364605e-05,
      "learning_rate": 9.580952380952383e-06,
      "loss": 0.0,
      "step": 27350
    },
    {
      "epoch": 7.817142857142857,
      "grad_norm": 6.330660835374147e-05,
      "learning_rate": 9.577142857142858e-06,
      "loss": 0.0,
      "step": 27360
    },
    {
      "epoch": 7.82,
      "grad_norm": 5.934640648774803e-05,
      "learning_rate": 9.573333333333334e-06,
      "loss": 0.0,
      "step": 27370
    },
    {
      "epoch": 7.822857142857143,
      "grad_norm": 0.0018340355018153787,
      "learning_rate": 9.569523809523811e-06,
      "loss": 0.0001,
      "step": 27380
    },
    {
      "epoch": 7.825714285714286,
      "grad_norm": 9.341070835944265e-05,
      "learning_rate": 9.565714285714287e-06,
      "loss": 0.0,
      "step": 27390
    },
    {
      "epoch": 7.828571428571428,
      "grad_norm": 8.88192662387155e-05,
      "learning_rate": 9.561904761904762e-06,
      "loss": 0.0002,
      "step": 27400
    },
    {
      "epoch": 7.831428571428571,
      "grad_norm": 7.349935185629874e-05,
      "learning_rate": 9.558095238095238e-06,
      "loss": 0.0,
      "step": 27410
    },
    {
      "epoch": 7.8342857142857145,
      "grad_norm": 0.00023672592942602932,
      "learning_rate": 9.554285714285715e-06,
      "loss": 0.0,
      "step": 27420
    },
    {
      "epoch": 7.837142857142857,
      "grad_norm": 3.7733967474196106e-05,
      "learning_rate": 9.55047619047619e-06,
      "loss": 0.0,
      "step": 27430
    },
    {
      "epoch": 7.84,
      "grad_norm": 4.0107930544763803e-05,
      "learning_rate": 9.546666666666668e-06,
      "loss": 0.0,
      "step": 27440
    },
    {
      "epoch": 7.8428571428571425,
      "grad_norm": 4.54508735856507e-05,
      "learning_rate": 9.542857142857143e-06,
      "loss": 0.0,
      "step": 27450
    },
    {
      "epoch": 7.845714285714286,
      "grad_norm": 0.00021444194135256112,
      "learning_rate": 9.53904761904762e-06,
      "loss": 0.0,
      "step": 27460
    },
    {
      "epoch": 7.848571428571429,
      "grad_norm": 0.00013722595758736134,
      "learning_rate": 9.535238095238096e-06,
      "loss": 0.0,
      "step": 27470
    },
    {
      "epoch": 7.851428571428571,
      "grad_norm": 3.6712408473249525e-05,
      "learning_rate": 9.531428571428572e-06,
      "loss": 0.0,
      "step": 27480
    },
    {
      "epoch": 7.854285714285714,
      "grad_norm": 0.0004027123795822263,
      "learning_rate": 9.52761904761905e-06,
      "loss": 0.0,
      "step": 27490
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 3.5518736694939435e-05,
      "learning_rate": 9.523809523809525e-06,
      "loss": 0.0,
      "step": 27500
    },
    {
      "epoch": 7.86,
      "grad_norm": 3.916412970284e-05,
      "learning_rate": 9.52e-06,
      "loss": 0.0,
      "step": 27510
    },
    {
      "epoch": 7.862857142857143,
      "grad_norm": 3.618867413024418e-05,
      "learning_rate": 9.516190476190476e-06,
      "loss": 0.0,
      "step": 27520
    },
    {
      "epoch": 7.865714285714286,
      "grad_norm": 0.000349973066477105,
      "learning_rate": 9.512380952380953e-06,
      "loss": 0.0468,
      "step": 27530
    },
    {
      "epoch": 7.868571428571428,
      "grad_norm": 7.504870154662058e-05,
      "learning_rate": 9.508571428571429e-06,
      "loss": 0.0,
      "step": 27540
    },
    {
      "epoch": 7.871428571428572,
      "grad_norm": 0.0002481337287463248,
      "learning_rate": 9.504761904761906e-06,
      "loss": 0.0,
      "step": 27550
    },
    {
      "epoch": 7.8742857142857146,
      "grad_norm": 3.070916500291787e-05,
      "learning_rate": 9.500952380952382e-06,
      "loss": 0.0,
      "step": 27560
    },
    {
      "epoch": 7.877142857142857,
      "grad_norm": 4.6405177272390574e-05,
      "learning_rate": 9.497142857142859e-06,
      "loss": 0.0,
      "step": 27570
    },
    {
      "epoch": 7.88,
      "grad_norm": 0.00037247652653604746,
      "learning_rate": 9.493333333333334e-06,
      "loss": 0.0,
      "step": 27580
    },
    {
      "epoch": 7.882857142857143,
      "grad_norm": 5.984309973428026e-05,
      "learning_rate": 9.48952380952381e-06,
      "loss": 0.0,
      "step": 27590
    },
    {
      "epoch": 7.885714285714286,
      "grad_norm": 3.609254054026678e-05,
      "learning_rate": 9.485714285714287e-06,
      "loss": 0.0,
      "step": 27600
    },
    {
      "epoch": 7.888571428571429,
      "grad_norm": 5.288486136123538e-05,
      "learning_rate": 9.481904761904763e-06,
      "loss": 0.0,
      "step": 27610
    },
    {
      "epoch": 7.8914285714285715,
      "grad_norm": 0.0003036137204617262,
      "learning_rate": 9.478095238095239e-06,
      "loss": 0.0,
      "step": 27620
    },
    {
      "epoch": 7.894285714285714,
      "grad_norm": 0.0002397377829765901,
      "learning_rate": 9.474285714285714e-06,
      "loss": 0.0,
      "step": 27630
    },
    {
      "epoch": 7.897142857142857,
      "grad_norm": 9.98524556052871e-05,
      "learning_rate": 9.470476190476191e-06,
      "loss": 0.2124,
      "step": 27640
    },
    {
      "epoch": 7.9,
      "grad_norm": 6.307494186330587e-05,
      "learning_rate": 9.466666666666667e-06,
      "loss": 0.0,
      "step": 27650
    },
    {
      "epoch": 7.902857142857143,
      "grad_norm": 0.0013456355081871152,
      "learning_rate": 9.462857142857144e-06,
      "loss": 0.0,
      "step": 27660
    },
    {
      "epoch": 7.905714285714286,
      "grad_norm": 0.00010371175449108705,
      "learning_rate": 9.45904761904762e-06,
      "loss": 0.0,
      "step": 27670
    },
    {
      "epoch": 7.908571428571428,
      "grad_norm": 0.002374278847128153,
      "learning_rate": 9.455238095238095e-06,
      "loss": 0.0,
      "step": 27680
    },
    {
      "epoch": 7.911428571428571,
      "grad_norm": 5.06393589603249e-05,
      "learning_rate": 9.451428571428573e-06,
      "loss": 0.0,
      "step": 27690
    },
    {
      "epoch": 7.914285714285715,
      "grad_norm": 0.0006761243566870689,
      "learning_rate": 9.447619047619048e-06,
      "loss": 0.0,
      "step": 27700
    },
    {
      "epoch": 7.917142857142857,
      "grad_norm": 69.40569305419922,
      "learning_rate": 9.443809523809526e-06,
      "loss": 0.222,
      "step": 27710
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.00012289400910958648,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.0,
      "step": 27720
    },
    {
      "epoch": 7.922857142857143,
      "grad_norm": 0.00010778474825201556,
      "learning_rate": 9.436190476190477e-06,
      "loss": 0.1388,
      "step": 27730
    },
    {
      "epoch": 7.925714285714285,
      "grad_norm": 0.0005699396715499461,
      "learning_rate": 9.432380952380952e-06,
      "loss": 0.0,
      "step": 27740
    },
    {
      "epoch": 7.928571428571429,
      "grad_norm": 0.03654840961098671,
      "learning_rate": 9.42857142857143e-06,
      "loss": 0.1601,
      "step": 27750
    },
    {
      "epoch": 7.9314285714285715,
      "grad_norm": 1.1008050441741943,
      "learning_rate": 9.424761904761905e-06,
      "loss": 0.0975,
      "step": 27760
    },
    {
      "epoch": 7.934285714285714,
      "grad_norm": 0.00013474884326569736,
      "learning_rate": 9.420952380952382e-06,
      "loss": 0.0,
      "step": 27770
    },
    {
      "epoch": 7.937142857142857,
      "grad_norm": 0.012734523974359035,
      "learning_rate": 9.417142857142858e-06,
      "loss": 0.0002,
      "step": 27780
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 0.00012688458082266152,
      "learning_rate": 9.413333333333334e-06,
      "loss": 0.0,
      "step": 27790
    },
    {
      "epoch": 7.942857142857143,
      "grad_norm": 9.05417327885516e-05,
      "learning_rate": 9.40952380952381e-06,
      "loss": 0.0,
      "step": 27800
    },
    {
      "epoch": 7.945714285714286,
      "grad_norm": 0.00043885564082302153,
      "learning_rate": 9.405714285714286e-06,
      "loss": 0.0,
      "step": 27810
    },
    {
      "epoch": 7.948571428571428,
      "grad_norm": 0.00010725016181822866,
      "learning_rate": 9.401904761904764e-06,
      "loss": 0.0002,
      "step": 27820
    },
    {
      "epoch": 7.951428571428571,
      "grad_norm": 7.313667447306216e-05,
      "learning_rate": 9.398095238095238e-06,
      "loss": 0.0,
      "step": 27830
    },
    {
      "epoch": 7.954285714285715,
      "grad_norm": 0.0004559466615319252,
      "learning_rate": 9.394285714285715e-06,
      "loss": 0.0,
      "step": 27840
    },
    {
      "epoch": 7.957142857142857,
      "grad_norm": 0.002448596293106675,
      "learning_rate": 9.39047619047619e-06,
      "loss": 0.0002,
      "step": 27850
    },
    {
      "epoch": 7.96,
      "grad_norm": 9.632456203689799e-05,
      "learning_rate": 9.386666666666668e-06,
      "loss": 0.0001,
      "step": 27860
    },
    {
      "epoch": 7.962857142857143,
      "grad_norm": 0.00018644402734935284,
      "learning_rate": 9.382857142857143e-06,
      "loss": 0.0,
      "step": 27870
    },
    {
      "epoch": 7.965714285714286,
      "grad_norm": 0.0015181404305621982,
      "learning_rate": 9.37904761904762e-06,
      "loss": 0.0,
      "step": 27880
    },
    {
      "epoch": 7.968571428571429,
      "grad_norm": 5.284842700348236e-05,
      "learning_rate": 9.375238095238096e-06,
      "loss": 0.0,
      "step": 27890
    },
    {
      "epoch": 7.9714285714285715,
      "grad_norm": 0.002531181089580059,
      "learning_rate": 9.371428571428572e-06,
      "loss": 0.0,
      "step": 27900
    },
    {
      "epoch": 7.974285714285714,
      "grad_norm": 6.0133726947242394e-05,
      "learning_rate": 9.367619047619049e-06,
      "loss": 0.0,
      "step": 27910
    },
    {
      "epoch": 7.977142857142857,
      "grad_norm": 7.195222133304924e-05,
      "learning_rate": 9.363809523809525e-06,
      "loss": 0.0002,
      "step": 27920
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.0006516266148537397,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.0,
      "step": 27930
    },
    {
      "epoch": 7.982857142857143,
      "grad_norm": 5.457799124997109e-05,
      "learning_rate": 9.356190476190476e-06,
      "loss": 0.0,
      "step": 27940
    },
    {
      "epoch": 7.985714285714286,
      "grad_norm": 5.4583830205956474e-05,
      "learning_rate": 9.352380952380953e-06,
      "loss": 0.0,
      "step": 27950
    },
    {
      "epoch": 7.988571428571428,
      "grad_norm": 4.69012520625256e-05,
      "learning_rate": 9.348571428571429e-06,
      "loss": 0.0,
      "step": 27960
    },
    {
      "epoch": 7.991428571428571,
      "grad_norm": 5.521986895473674e-05,
      "learning_rate": 9.344761904761906e-06,
      "loss": 0.0,
      "step": 27970
    },
    {
      "epoch": 7.994285714285715,
      "grad_norm": 0.0005406101117841899,
      "learning_rate": 9.340952380952381e-06,
      "loss": 0.0,
      "step": 27980
    },
    {
      "epoch": 7.997142857142857,
      "grad_norm": 9.099459566641599e-05,
      "learning_rate": 9.337142857142859e-06,
      "loss": 0.0002,
      "step": 27990
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.009737163782119751,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.0,
      "step": 28000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9833333333333333,
      "eval_f1": 0.8979591836734694,
      "eval_loss": 0.17925864458084106,
      "eval_precision": 0.9322033898305084,
      "eval_recall": 0.8661417322834646,
      "eval_runtime": 358.4814,
      "eval_samples_per_second": 8.369,
      "eval_steps_per_second": 2.092,
      "step": 28000
    },
    {
      "epoch": 8.002857142857144,
      "grad_norm": 0.00025431509129703045,
      "learning_rate": 9.32952380952381e-06,
      "loss": 0.0,
      "step": 28010
    },
    {
      "epoch": 8.005714285714285,
      "grad_norm": 0.00010828352969838306,
      "learning_rate": 9.325714285714287e-06,
      "loss": 0.0,
      "step": 28020
    },
    {
      "epoch": 8.008571428571429,
      "grad_norm": 0.00014111657219473273,
      "learning_rate": 9.321904761904763e-06,
      "loss": 0.0,
      "step": 28030
    },
    {
      "epoch": 8.01142857142857,
      "grad_norm": 6.54572868370451e-05,
      "learning_rate": 9.318095238095238e-06,
      "loss": 0.0,
      "step": 28040
    },
    {
      "epoch": 8.014285714285714,
      "grad_norm": 6.519243470393121e-05,
      "learning_rate": 9.314285714285714e-06,
      "loss": 0.0,
      "step": 28050
    },
    {
      "epoch": 8.017142857142858,
      "grad_norm": 5.4776166507508606e-05,
      "learning_rate": 9.310476190476191e-06,
      "loss": 0.0,
      "step": 28060
    },
    {
      "epoch": 8.02,
      "grad_norm": 6.36028780718334e-05,
      "learning_rate": 9.306666666666667e-06,
      "loss": 0.0,
      "step": 28070
    },
    {
      "epoch": 8.022857142857143,
      "grad_norm": 6.546100485138595e-05,
      "learning_rate": 9.302857142857144e-06,
      "loss": 0.0,
      "step": 28080
    },
    {
      "epoch": 8.025714285714285,
      "grad_norm": 0.0006939559825696051,
      "learning_rate": 9.29904761904762e-06,
      "loss": 0.0,
      "step": 28090
    },
    {
      "epoch": 8.028571428571428,
      "grad_norm": 6.584530638065189e-05,
      "learning_rate": 9.295238095238095e-06,
      "loss": 0.1116,
      "step": 28100
    },
    {
      "epoch": 8.031428571428572,
      "grad_norm": 4.385608554002829e-05,
      "learning_rate": 9.291428571428572e-06,
      "loss": 0.0,
      "step": 28110
    },
    {
      "epoch": 8.034285714285714,
      "grad_norm": 5.109930134494789e-05,
      "learning_rate": 9.287619047619048e-06,
      "loss": 0.0,
      "step": 28120
    },
    {
      "epoch": 8.037142857142857,
      "grad_norm": 3.744506830116734e-05,
      "learning_rate": 9.283809523809525e-06,
      "loss": 0.0,
      "step": 28130
    },
    {
      "epoch": 8.04,
      "grad_norm": 4.008604446426034e-05,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.0,
      "step": 28140
    },
    {
      "epoch": 8.042857142857143,
      "grad_norm": 0.0030336633790284395,
      "learning_rate": 9.276190476190477e-06,
      "loss": 0.0,
      "step": 28150
    },
    {
      "epoch": 8.045714285714286,
      "grad_norm": 4.591559627442621e-05,
      "learning_rate": 9.272380952380952e-06,
      "loss": 0.0,
      "step": 28160
    },
    {
      "epoch": 8.048571428571428,
      "grad_norm": 4.614658246282488e-05,
      "learning_rate": 9.26857142857143e-06,
      "loss": 0.0001,
      "step": 28170
    },
    {
      "epoch": 8.051428571428572,
      "grad_norm": 3.2784391805762425e-05,
      "learning_rate": 9.264761904761905e-06,
      "loss": 0.0024,
      "step": 28180
    },
    {
      "epoch": 8.054285714285715,
      "grad_norm": 4.0377923141932115e-05,
      "learning_rate": 9.260952380952382e-06,
      "loss": 0.08,
      "step": 28190
    },
    {
      "epoch": 8.057142857142857,
      "grad_norm": 3.1850842788117006e-05,
      "learning_rate": 9.257142857142858e-06,
      "loss": 0.0001,
      "step": 28200
    },
    {
      "epoch": 8.06,
      "grad_norm": 4.9229085561819375e-05,
      "learning_rate": 9.253333333333333e-06,
      "loss": 0.0,
      "step": 28210
    },
    {
      "epoch": 8.062857142857142,
      "grad_norm": 0.002574342768639326,
      "learning_rate": 9.24952380952381e-06,
      "loss": 0.0,
      "step": 28220
    },
    {
      "epoch": 8.065714285714286,
      "grad_norm": 5.3623538406100124e-05,
      "learning_rate": 9.245714285714286e-06,
      "loss": 0.0,
      "step": 28230
    },
    {
      "epoch": 8.06857142857143,
      "grad_norm": 4.571209865389392e-05,
      "learning_rate": 9.241904761904764e-06,
      "loss": 0.2038,
      "step": 28240
    },
    {
      "epoch": 8.071428571428571,
      "grad_norm": 4.649116090149619e-05,
      "learning_rate": 9.238095238095239e-06,
      "loss": 0.0458,
      "step": 28250
    },
    {
      "epoch": 8.074285714285715,
      "grad_norm": 0.005279090721160173,
      "learning_rate": 9.234285714285715e-06,
      "loss": 0.0,
      "step": 28260
    },
    {
      "epoch": 8.077142857142857,
      "grad_norm": 0.0030305704567581415,
      "learning_rate": 9.23047619047619e-06,
      "loss": 0.2154,
      "step": 28270
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.0007550429436378181,
      "learning_rate": 9.226666666666668e-06,
      "loss": 0.1109,
      "step": 28280
    },
    {
      "epoch": 8.082857142857144,
      "grad_norm": 7.100206130417064e-05,
      "learning_rate": 9.222857142857143e-06,
      "loss": 0.0109,
      "step": 28290
    },
    {
      "epoch": 8.085714285714285,
      "grad_norm": 6.34706811979413e-05,
      "learning_rate": 9.21904761904762e-06,
      "loss": 0.0012,
      "step": 28300
    },
    {
      "epoch": 8.088571428571429,
      "grad_norm": 0.00252186949364841,
      "learning_rate": 9.215238095238096e-06,
      "loss": 0.3276,
      "step": 28310
    },
    {
      "epoch": 8.09142857142857,
      "grad_norm": 0.0002080258564092219,
      "learning_rate": 9.211428571428572e-06,
      "loss": 0.0001,
      "step": 28320
    },
    {
      "epoch": 8.094285714285714,
      "grad_norm": 0.00042577870772220194,
      "learning_rate": 9.207619047619049e-06,
      "loss": 0.2354,
      "step": 28330
    },
    {
      "epoch": 8.097142857142858,
      "grad_norm": 0.009259228594601154,
      "learning_rate": 9.203809523809524e-06,
      "loss": 0.0,
      "step": 28340
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.005413125269114971,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0,
      "step": 28350
    },
    {
      "epoch": 8.102857142857143,
      "grad_norm": 0.0007486711256206036,
      "learning_rate": 9.196190476190477e-06,
      "loss": 0.0,
      "step": 28360
    },
    {
      "epoch": 8.105714285714285,
      "grad_norm": 0.009287972003221512,
      "learning_rate": 9.192380952380953e-06,
      "loss": 0.0,
      "step": 28370
    },
    {
      "epoch": 8.108571428571429,
      "grad_norm": 0.0009134398424066603,
      "learning_rate": 9.188571428571428e-06,
      "loss": 0.0002,
      "step": 28380
    },
    {
      "epoch": 8.111428571428572,
      "grad_norm": 0.0007930607534945011,
      "learning_rate": 9.184761904761906e-06,
      "loss": 0.0001,
      "step": 28390
    },
    {
      "epoch": 8.114285714285714,
      "grad_norm": 0.0006079061422497034,
      "learning_rate": 9.180952380952381e-06,
      "loss": 0.0,
      "step": 28400
    },
    {
      "epoch": 8.117142857142857,
      "grad_norm": 0.0016843454213812947,
      "learning_rate": 9.177142857142859e-06,
      "loss": 0.0,
      "step": 28410
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.0009053389076143503,
      "learning_rate": 9.173333333333334e-06,
      "loss": 0.0,
      "step": 28420
    },
    {
      "epoch": 8.122857142857143,
      "grad_norm": 0.0005092693609185517,
      "learning_rate": 9.16952380952381e-06,
      "loss": 0.0,
      "step": 28430
    },
    {
      "epoch": 8.125714285714286,
      "grad_norm": 0.0013036951422691345,
      "learning_rate": 9.165714285714287e-06,
      "loss": 0.0,
      "step": 28440
    },
    {
      "epoch": 8.128571428571428,
      "grad_norm": 2.2636523246765137,
      "learning_rate": 9.161904761904763e-06,
      "loss": 0.0003,
      "step": 28450
    },
    {
      "epoch": 8.131428571428572,
      "grad_norm": 0.004885480273514986,
      "learning_rate": 9.15809523809524e-06,
      "loss": 0.0,
      "step": 28460
    },
    {
      "epoch": 8.134285714285713,
      "grad_norm": 0.05983951315283775,
      "learning_rate": 9.154285714285715e-06,
      "loss": 0.0001,
      "step": 28470
    },
    {
      "epoch": 8.137142857142857,
      "grad_norm": 0.0022895284928381443,
      "learning_rate": 9.150476190476191e-06,
      "loss": 0.0,
      "step": 28480
    },
    {
      "epoch": 8.14,
      "grad_norm": 0.0010615558130666614,
      "learning_rate": 9.146666666666667e-06,
      "loss": 0.0,
      "step": 28490
    },
    {
      "epoch": 8.142857142857142,
      "grad_norm": 0.0010349495569244027,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.0002,
      "step": 28500
    },
    {
      "epoch": 8.145714285714286,
      "grad_norm": 0.0031035325955599546,
      "learning_rate": 9.13904761904762e-06,
      "loss": 0.0,
      "step": 28510
    },
    {
      "epoch": 8.14857142857143,
      "grad_norm": 0.004101155791431665,
      "learning_rate": 9.135238095238095e-06,
      "loss": 0.0001,
      "step": 28520
    },
    {
      "epoch": 8.151428571428571,
      "grad_norm": 0.00042885253787972033,
      "learning_rate": 9.131428571428572e-06,
      "loss": 0.0,
      "step": 28530
    },
    {
      "epoch": 8.154285714285715,
      "grad_norm": 0.00041975019848905504,
      "learning_rate": 9.127619047619048e-06,
      "loss": 0.0,
      "step": 28540
    },
    {
      "epoch": 8.157142857142857,
      "grad_norm": 0.00027532182866707444,
      "learning_rate": 9.123809523809525e-06,
      "loss": 0.0,
      "step": 28550
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.0011162065202370286,
      "learning_rate": 9.12e-06,
      "loss": 0.0,
      "step": 28560
    },
    {
      "epoch": 8.162857142857144,
      "grad_norm": 0.010003790259361267,
      "learning_rate": 9.116190476190478e-06,
      "loss": 0.203,
      "step": 28570
    },
    {
      "epoch": 8.165714285714285,
      "grad_norm": 0.0015110052190721035,
      "learning_rate": 9.112380952380954e-06,
      "loss": 0.0001,
      "step": 28580
    },
    {
      "epoch": 8.168571428571429,
      "grad_norm": 0.002773720771074295,
      "learning_rate": 9.10857142857143e-06,
      "loss": 0.0002,
      "step": 28590
    },
    {
      "epoch": 8.17142857142857,
      "grad_norm": 0.0006067883223295212,
      "learning_rate": 9.104761904761905e-06,
      "loss": 0.0,
      "step": 28600
    },
    {
      "epoch": 8.174285714285714,
      "grad_norm": 0.0004231033963151276,
      "learning_rate": 9.100952380952382e-06,
      "loss": 0.0,
      "step": 28610
    },
    {
      "epoch": 8.177142857142858,
      "grad_norm": 0.0007949338178150356,
      "learning_rate": 9.097142857142858e-06,
      "loss": 0.0001,
      "step": 28620
    },
    {
      "epoch": 8.18,
      "grad_norm": 0.02351279743015766,
      "learning_rate": 9.093333333333333e-06,
      "loss": 0.0,
      "step": 28630
    },
    {
      "epoch": 8.182857142857143,
      "grad_norm": 0.000735236331820488,
      "learning_rate": 9.08952380952381e-06,
      "loss": 0.0,
      "step": 28640
    },
    {
      "epoch": 8.185714285714285,
      "grad_norm": 0.00024525399203412235,
      "learning_rate": 9.085714285714286e-06,
      "loss": 0.0,
      "step": 28650
    },
    {
      "epoch": 8.188571428571429,
      "grad_norm": 0.01920514926314354,
      "learning_rate": 9.081904761904763e-06,
      "loss": 0.0001,
      "step": 28660
    },
    {
      "epoch": 8.191428571428572,
      "grad_norm": 0.0006932797259651124,
      "learning_rate": 9.078095238095239e-06,
      "loss": 0.0,
      "step": 28670
    },
    {
      "epoch": 8.194285714285714,
      "grad_norm": 0.0002518588153179735,
      "learning_rate": 9.074285714285716e-06,
      "loss": 0.0001,
      "step": 28680
    },
    {
      "epoch": 8.197142857142858,
      "grad_norm": 0.0004030466661788523,
      "learning_rate": 9.070476190476192e-06,
      "loss": 0.0,
      "step": 28690
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.003166132140904665,
      "learning_rate": 9.066666666666667e-06,
      "loss": 0.0,
      "step": 28700
    },
    {
      "epoch": 8.202857142857143,
      "grad_norm": 0.00039549791836179793,
      "learning_rate": 9.062857142857143e-06,
      "loss": 0.0,
      "step": 28710
    },
    {
      "epoch": 8.205714285714286,
      "grad_norm": 0.0001794833951862529,
      "learning_rate": 9.05904761904762e-06,
      "loss": 0.0,
      "step": 28720
    },
    {
      "epoch": 8.208571428571428,
      "grad_norm": 0.0006084388587623835,
      "learning_rate": 9.055238095238096e-06,
      "loss": 0.0,
      "step": 28730
    },
    {
      "epoch": 8.211428571428572,
      "grad_norm": 0.005310319364070892,
      "learning_rate": 9.051428571428571e-06,
      "loss": 0.0,
      "step": 28740
    },
    {
      "epoch": 8.214285714285714,
      "grad_norm": 0.0013209772296249866,
      "learning_rate": 9.047619047619049e-06,
      "loss": 0.0,
      "step": 28750
    },
    {
      "epoch": 8.217142857142857,
      "grad_norm": 0.00017366492829751223,
      "learning_rate": 9.043809523809524e-06,
      "loss": 0.0,
      "step": 28760
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.0002988965134136379,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.0556,
      "step": 28770
    },
    {
      "epoch": 8.222857142857142,
      "grad_norm": 0.0003319718816783279,
      "learning_rate": 9.036190476190477e-06,
      "loss": 0.0,
      "step": 28780
    },
    {
      "epoch": 8.225714285714286,
      "grad_norm": 41.246131896972656,
      "learning_rate": 9.032380952380954e-06,
      "loss": 0.2659,
      "step": 28790
    },
    {
      "epoch": 8.228571428571428,
      "grad_norm": 0.0038280002772808075,
      "learning_rate": 9.028571428571428e-06,
      "loss": 0.0,
      "step": 28800
    },
    {
      "epoch": 8.231428571428571,
      "grad_norm": 0.004305707290768623,
      "learning_rate": 9.024761904761906e-06,
      "loss": 0.0,
      "step": 28810
    },
    {
      "epoch": 8.234285714285715,
      "grad_norm": 0.008852328173816204,
      "learning_rate": 9.020952380952381e-06,
      "loss": 0.0001,
      "step": 28820
    },
    {
      "epoch": 8.237142857142857,
      "grad_norm": 0.0019835885614156723,
      "learning_rate": 9.017142857142858e-06,
      "loss": 0.0002,
      "step": 28830
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.0002844248083420098,
      "learning_rate": 9.013333333333334e-06,
      "loss": 0.0,
      "step": 28840
    },
    {
      "epoch": 8.242857142857142,
      "grad_norm": 0.00029291186365298927,
      "learning_rate": 9.00952380952381e-06,
      "loss": 0.0,
      "step": 28850
    },
    {
      "epoch": 8.245714285714286,
      "grad_norm": 0.001787497429177165,
      "learning_rate": 9.005714285714287e-06,
      "loss": 0.0,
      "step": 28860
    },
    {
      "epoch": 8.248571428571429,
      "grad_norm": 0.00174891937058419,
      "learning_rate": 9.001904761904762e-06,
      "loss": 0.0,
      "step": 28870
    },
    {
      "epoch": 8.251428571428571,
      "grad_norm": 0.0007266097236424685,
      "learning_rate": 8.99809523809524e-06,
      "loss": 0.0,
      "step": 28880
    },
    {
      "epoch": 8.254285714285714,
      "grad_norm": 29.65496826171875,
      "learning_rate": 8.994285714285715e-06,
      "loss": 0.0047,
      "step": 28890
    },
    {
      "epoch": 8.257142857142856,
      "grad_norm": 0.0005490111070685089,
      "learning_rate": 8.990476190476191e-06,
      "loss": 0.0,
      "step": 28900
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.00836270023137331,
      "learning_rate": 8.986666666666666e-06,
      "loss": 0.1882,
      "step": 28910
    },
    {
      "epoch": 8.262857142857143,
      "grad_norm": 0.0004094317846465856,
      "learning_rate": 8.982857142857144e-06,
      "loss": 0.0465,
      "step": 28920
    },
    {
      "epoch": 8.265714285714285,
      "grad_norm": 0.0011484139831736684,
      "learning_rate": 8.97904761904762e-06,
      "loss": 0.0,
      "step": 28930
    },
    {
      "epoch": 8.268571428571429,
      "grad_norm": 0.0001084624818759039,
      "learning_rate": 8.975238095238097e-06,
      "loss": 0.0,
      "step": 28940
    },
    {
      "epoch": 8.271428571428572,
      "grad_norm": 0.0001389031094731763,
      "learning_rate": 8.971428571428572e-06,
      "loss": 0.0,
      "step": 28950
    },
    {
      "epoch": 8.274285714285714,
      "grad_norm": 0.0001106340714613907,
      "learning_rate": 8.967619047619048e-06,
      "loss": 0.0,
      "step": 28960
    },
    {
      "epoch": 8.277142857142858,
      "grad_norm": 0.00018060600268654525,
      "learning_rate": 8.963809523809525e-06,
      "loss": 0.0,
      "step": 28970
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.0001367423392366618,
      "learning_rate": 8.96e-06,
      "loss": 0.0,
      "step": 28980
    },
    {
      "epoch": 8.282857142857143,
      "grad_norm": 0.00048067717580124736,
      "learning_rate": 8.956190476190478e-06,
      "loss": 0.0,
      "step": 28990
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 0.00026705602067522705,
      "learning_rate": 8.952380952380953e-06,
      "loss": 0.0157,
      "step": 29000
    },
    {
      "epoch": 8.288571428571428,
      "grad_norm": 0.00016053603030741215,
      "learning_rate": 8.948571428571429e-06,
      "loss": 0.0,
      "step": 29010
    },
    {
      "epoch": 8.291428571428572,
      "grad_norm": 0.001681882655248046,
      "learning_rate": 8.944761904761905e-06,
      "loss": 0.0,
      "step": 29020
    },
    {
      "epoch": 8.294285714285714,
      "grad_norm": 0.000606540241278708,
      "learning_rate": 8.940952380952382e-06,
      "loss": 0.0,
      "step": 29030
    },
    {
      "epoch": 8.297142857142857,
      "grad_norm": 0.00010124812251888216,
      "learning_rate": 8.937142857142857e-06,
      "loss": 0.0,
      "step": 29040
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.0022931289859116077,
      "learning_rate": 8.933333333333333e-06,
      "loss": 0.0,
      "step": 29050
    },
    {
      "epoch": 8.302857142857142,
      "grad_norm": 0.00019269410404376686,
      "learning_rate": 8.92952380952381e-06,
      "loss": 0.0,
      "step": 29060
    },
    {
      "epoch": 8.305714285714286,
      "grad_norm": 0.00047845017979852855,
      "learning_rate": 8.925714285714286e-06,
      "loss": 0.0,
      "step": 29070
    },
    {
      "epoch": 8.308571428571428,
      "grad_norm": 0.00019290915224701166,
      "learning_rate": 8.921904761904763e-06,
      "loss": 0.0,
      "step": 29080
    },
    {
      "epoch": 8.311428571428571,
      "grad_norm": 0.00017835290054790676,
      "learning_rate": 8.918095238095239e-06,
      "loss": 0.0,
      "step": 29090
    },
    {
      "epoch": 8.314285714285715,
      "grad_norm": 9.371886699227616e-05,
      "learning_rate": 8.914285714285716e-06,
      "loss": 0.0001,
      "step": 29100
    },
    {
      "epoch": 8.317142857142857,
      "grad_norm": 0.00025396744604222476,
      "learning_rate": 8.910476190476192e-06,
      "loss": 0.0,
      "step": 29110
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.0013453341089189053,
      "learning_rate": 8.906666666666667e-06,
      "loss": 0.0,
      "step": 29120
    },
    {
      "epoch": 8.322857142857142,
      "grad_norm": 0.0003071427345275879,
      "learning_rate": 8.902857142857143e-06,
      "loss": 0.0,
      "step": 29130
    },
    {
      "epoch": 8.325714285714286,
      "grad_norm": 0.0002714524744078517,
      "learning_rate": 8.89904761904762e-06,
      "loss": 0.0,
      "step": 29140
    },
    {
      "epoch": 8.32857142857143,
      "grad_norm": 0.0005208871443755925,
      "learning_rate": 8.895238095238096e-06,
      "loss": 0.0,
      "step": 29150
    },
    {
      "epoch": 8.331428571428571,
      "grad_norm": 9.735781350173056e-05,
      "learning_rate": 8.891428571428571e-06,
      "loss": 0.0,
      "step": 29160
    },
    {
      "epoch": 8.334285714285715,
      "grad_norm": 0.002927580149844289,
      "learning_rate": 8.887619047619049e-06,
      "loss": 0.1855,
      "step": 29170
    },
    {
      "epoch": 8.337142857142856,
      "grad_norm": 0.00024826012668199837,
      "learning_rate": 8.883809523809524e-06,
      "loss": 0.0,
      "step": 29180
    },
    {
      "epoch": 8.34,
      "grad_norm": 0.0005051683983765543,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.0,
      "step": 29190
    },
    {
      "epoch": 8.342857142857143,
      "grad_norm": 0.00023070599127095193,
      "learning_rate": 8.876190476190477e-06,
      "loss": 0.0,
      "step": 29200
    },
    {
      "epoch": 8.345714285714285,
      "grad_norm": 0.00029008020646870136,
      "learning_rate": 8.872380952380954e-06,
      "loss": 0.0,
      "step": 29210
    },
    {
      "epoch": 8.348571428571429,
      "grad_norm": 0.000748545688111335,
      "learning_rate": 8.86857142857143e-06,
      "loss": 0.0,
      "step": 29220
    },
    {
      "epoch": 8.35142857142857,
      "grad_norm": 0.0003904387995135039,
      "learning_rate": 8.864761904761905e-06,
      "loss": 0.0,
      "step": 29230
    },
    {
      "epoch": 8.354285714285714,
      "grad_norm": 9.604312072042376e-05,
      "learning_rate": 8.860952380952381e-06,
      "loss": 0.0,
      "step": 29240
    },
    {
      "epoch": 8.357142857142858,
      "grad_norm": 0.00022647592413704842,
      "learning_rate": 8.857142857142858e-06,
      "loss": 0.0,
      "step": 29250
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.0001427703828085214,
      "learning_rate": 8.853333333333334e-06,
      "loss": 0.0,
      "step": 29260
    },
    {
      "epoch": 8.362857142857143,
      "grad_norm": 0.0001358836452709511,
      "learning_rate": 8.84952380952381e-06,
      "loss": 0.0,
      "step": 29270
    },
    {
      "epoch": 8.365714285714287,
      "grad_norm": 0.005338431801646948,
      "learning_rate": 8.845714285714287e-06,
      "loss": 0.0,
      "step": 29280
    },
    {
      "epoch": 8.368571428571428,
      "grad_norm": 0.0005314515437930822,
      "learning_rate": 8.841904761904762e-06,
      "loss": 0.0,
      "step": 29290
    },
    {
      "epoch": 8.371428571428572,
      "grad_norm": 0.00012701981177087873,
      "learning_rate": 8.83809523809524e-06,
      "loss": 0.0127,
      "step": 29300
    },
    {
      "epoch": 8.374285714285714,
      "grad_norm": 0.00010418849706184119,
      "learning_rate": 8.834285714285715e-06,
      "loss": 0.0,
      "step": 29310
    },
    {
      "epoch": 8.377142857142857,
      "grad_norm": 7.160226959967986e-05,
      "learning_rate": 8.83047619047619e-06,
      "loss": 0.0,
      "step": 29320
    },
    {
      "epoch": 8.38,
      "grad_norm": 9.82474084594287e-05,
      "learning_rate": 8.826666666666668e-06,
      "loss": 0.0,
      "step": 29330
    },
    {
      "epoch": 8.382857142857143,
      "grad_norm": 0.00012016407708870247,
      "learning_rate": 8.822857142857144e-06,
      "loss": 0.0,
      "step": 29340
    },
    {
      "epoch": 8.385714285714286,
      "grad_norm": 0.00019192625768482685,
      "learning_rate": 8.819047619047619e-06,
      "loss": 0.0,
      "step": 29350
    },
    {
      "epoch": 8.388571428571428,
      "grad_norm": 7.695533713558689e-05,
      "learning_rate": 8.815238095238096e-06,
      "loss": 0.0,
      "step": 29360
    },
    {
      "epoch": 8.391428571428571,
      "grad_norm": 9.863648301688954e-05,
      "learning_rate": 8.811428571428572e-06,
      "loss": 0.0,
      "step": 29370
    },
    {
      "epoch": 8.394285714285715,
      "grad_norm": 0.00034692452754825354,
      "learning_rate": 8.807619047619048e-06,
      "loss": 0.0,
      "step": 29380
    },
    {
      "epoch": 8.397142857142857,
      "grad_norm": 8.300691843032837e-05,
      "learning_rate": 8.803809523809525e-06,
      "loss": 0.0,
      "step": 29390
    },
    {
      "epoch": 8.4,
      "grad_norm": 8.889738819561899e-05,
      "learning_rate": 8.8e-06,
      "loss": 0.0,
      "step": 29400
    },
    {
      "epoch": 8.402857142857142,
      "grad_norm": 0.00013355982082430273,
      "learning_rate": 8.796190476190478e-06,
      "loss": 0.0001,
      "step": 29410
    },
    {
      "epoch": 8.405714285714286,
      "grad_norm": 9.084119665203616e-05,
      "learning_rate": 8.792380952380953e-06,
      "loss": 0.0,
      "step": 29420
    },
    {
      "epoch": 8.40857142857143,
      "grad_norm": 0.00038977849180810153,
      "learning_rate": 8.788571428571429e-06,
      "loss": 0.0,
      "step": 29430
    },
    {
      "epoch": 8.411428571428571,
      "grad_norm": 0.002296272199600935,
      "learning_rate": 8.784761904761906e-06,
      "loss": 0.0,
      "step": 29440
    },
    {
      "epoch": 8.414285714285715,
      "grad_norm": 0.00030325748957693577,
      "learning_rate": 8.780952380952382e-06,
      "loss": 0.0,
      "step": 29450
    },
    {
      "epoch": 8.417142857142856,
      "grad_norm": 0.4050583839416504,
      "learning_rate": 8.777142857142857e-06,
      "loss": 0.0003,
      "step": 29460
    },
    {
      "epoch": 8.42,
      "grad_norm": 8.852926112012938e-05,
      "learning_rate": 8.773333333333333e-06,
      "loss": 0.0,
      "step": 29470
    },
    {
      "epoch": 8.422857142857143,
      "grad_norm": 6.806233432143927e-05,
      "learning_rate": 8.76952380952381e-06,
      "loss": 0.0,
      "step": 29480
    },
    {
      "epoch": 8.425714285714285,
      "grad_norm": 6.764350837329403e-05,
      "learning_rate": 8.765714285714286e-06,
      "loss": 0.0,
      "step": 29490
    },
    {
      "epoch": 8.428571428571429,
      "grad_norm": 0.00010946323891403154,
      "learning_rate": 8.761904761904763e-06,
      "loss": 0.0,
      "step": 29500
    },
    {
      "epoch": 8.43142857142857,
      "grad_norm": 0.00010717504483181983,
      "learning_rate": 8.758095238095239e-06,
      "loss": 0.0,
      "step": 29510
    },
    {
      "epoch": 8.434285714285714,
      "grad_norm": 0.00022450488177128136,
      "learning_rate": 8.754285714285716e-06,
      "loss": 0.0,
      "step": 29520
    },
    {
      "epoch": 8.437142857142858,
      "grad_norm": 0.0015146832447499037,
      "learning_rate": 8.750476190476191e-06,
      "loss": 0.0,
      "step": 29530
    },
    {
      "epoch": 8.44,
      "grad_norm": 8.833940228214487e-05,
      "learning_rate": 8.746666666666667e-06,
      "loss": 0.0,
      "step": 29540
    },
    {
      "epoch": 8.442857142857143,
      "grad_norm": 0.00013084978854749352,
      "learning_rate": 8.742857142857144e-06,
      "loss": 0.0,
      "step": 29550
    },
    {
      "epoch": 8.445714285714285,
      "grad_norm": 6.060028317733668e-05,
      "learning_rate": 8.73904761904762e-06,
      "loss": 0.0,
      "step": 29560
    },
    {
      "epoch": 8.448571428571428,
      "grad_norm": 0.0001082688249880448,
      "learning_rate": 8.735238095238096e-06,
      "loss": 0.0,
      "step": 29570
    },
    {
      "epoch": 8.451428571428572,
      "grad_norm": 7.361766620306298e-05,
      "learning_rate": 8.731428571428571e-06,
      "loss": 0.0,
      "step": 29580
    },
    {
      "epoch": 8.454285714285714,
      "grad_norm": 0.00024594052229076624,
      "learning_rate": 8.727619047619048e-06,
      "loss": 0.0,
      "step": 29590
    },
    {
      "epoch": 8.457142857142857,
      "grad_norm": 0.00016250005865003914,
      "learning_rate": 8.723809523809524e-06,
      "loss": 0.0,
      "step": 29600
    },
    {
      "epoch": 8.46,
      "grad_norm": 7.873633148847148e-05,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.0,
      "step": 29610
    },
    {
      "epoch": 8.462857142857143,
      "grad_norm": 0.0001477970217820257,
      "learning_rate": 8.716190476190477e-06,
      "loss": 0.0,
      "step": 29620
    },
    {
      "epoch": 8.465714285714286,
      "grad_norm": 0.0001665596355451271,
      "learning_rate": 8.712380952380954e-06,
      "loss": 0.0002,
      "step": 29630
    },
    {
      "epoch": 8.468571428571428,
      "grad_norm": 0.00010595677304081619,
      "learning_rate": 8.70857142857143e-06,
      "loss": 0.0,
      "step": 29640
    },
    {
      "epoch": 8.471428571428572,
      "grad_norm": 0.0002023906708927825,
      "learning_rate": 8.704761904761905e-06,
      "loss": 0.0,
      "step": 29650
    },
    {
      "epoch": 8.474285714285715,
      "grad_norm": 0.0003071113314945251,
      "learning_rate": 8.700952380952383e-06,
      "loss": 0.0,
      "step": 29660
    },
    {
      "epoch": 8.477142857142857,
      "grad_norm": 7.838296733098105e-05,
      "learning_rate": 8.697142857142858e-06,
      "loss": 0.0002,
      "step": 29670
    },
    {
      "epoch": 8.48,
      "grad_norm": 8.126233296934515e-05,
      "learning_rate": 8.693333333333334e-06,
      "loss": 0.0,
      "step": 29680
    },
    {
      "epoch": 8.482857142857142,
      "grad_norm": 0.00010916801693383604,
      "learning_rate": 8.68952380952381e-06,
      "loss": 0.0,
      "step": 29690
    },
    {
      "epoch": 8.485714285714286,
      "grad_norm": 0.00040714669739827514,
      "learning_rate": 8.685714285714287e-06,
      "loss": 0.0,
      "step": 29700
    },
    {
      "epoch": 8.48857142857143,
      "grad_norm": 0.00022022325720172375,
      "learning_rate": 8.681904761904762e-06,
      "loss": 0.0,
      "step": 29710
    },
    {
      "epoch": 8.491428571428571,
      "grad_norm": 0.00011519197869347408,
      "learning_rate": 8.67809523809524e-06,
      "loss": 0.0001,
      "step": 29720
    },
    {
      "epoch": 8.494285714285715,
      "grad_norm": 0.00022960179194342345,
      "learning_rate": 8.674285714285715e-06,
      "loss": 0.0,
      "step": 29730
    },
    {
      "epoch": 8.497142857142856,
      "grad_norm": 0.00021648750407621264,
      "learning_rate": 8.67047619047619e-06,
      "loss": 0.0,
      "step": 29740
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.0003446292248554528,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.0,
      "step": 29750
    },
    {
      "epoch": 8.502857142857144,
      "grad_norm": 0.023817552253603935,
      "learning_rate": 8.662857142857143e-06,
      "loss": 0.0,
      "step": 29760
    },
    {
      "epoch": 8.505714285714285,
      "grad_norm": 0.006016427651047707,
      "learning_rate": 8.65904761904762e-06,
      "loss": 0.3296,
      "step": 29770
    },
    {
      "epoch": 8.508571428571429,
      "grad_norm": 0.00018391785852145404,
      "learning_rate": 8.655238095238096e-06,
      "loss": 0.0,
      "step": 29780
    },
    {
      "epoch": 8.51142857142857,
      "grad_norm": 5.67328097531572e-05,
      "learning_rate": 8.651428571428572e-06,
      "loss": 0.1646,
      "step": 29790
    },
    {
      "epoch": 8.514285714285714,
      "grad_norm": 217.69837951660156,
      "learning_rate": 8.647619047619047e-06,
      "loss": 0.1839,
      "step": 29800
    },
    {
      "epoch": 8.517142857142858,
      "grad_norm": 0.00016605263226665556,
      "learning_rate": 8.643809523809525e-06,
      "loss": 0.1334,
      "step": 29810
    },
    {
      "epoch": 8.52,
      "grad_norm": 5.299162876326591e-05,
      "learning_rate": 8.64e-06,
      "loss": 0.1067,
      "step": 29820
    },
    {
      "epoch": 8.522857142857143,
      "grad_norm": 4.960674777976237e-05,
      "learning_rate": 8.636190476190478e-06,
      "loss": 0.0,
      "step": 29830
    },
    {
      "epoch": 8.525714285714285,
      "grad_norm": 0.00014626806660089642,
      "learning_rate": 8.632380952380953e-06,
      "loss": 0.0,
      "step": 29840
    },
    {
      "epoch": 8.528571428571428,
      "grad_norm": 3.614356319303624e-05,
      "learning_rate": 8.628571428571429e-06,
      "loss": 0.0,
      "step": 29850
    },
    {
      "epoch": 8.531428571428572,
      "grad_norm": 3.8273570680757985e-05,
      "learning_rate": 8.624761904761906e-06,
      "loss": 0.0,
      "step": 29860
    },
    {
      "epoch": 8.534285714285714,
      "grad_norm": 0.00027224692166782916,
      "learning_rate": 8.620952380952382e-06,
      "loss": 0.0,
      "step": 29870
    },
    {
      "epoch": 8.537142857142857,
      "grad_norm": 0.001992898527532816,
      "learning_rate": 8.617142857142859e-06,
      "loss": 0.0,
      "step": 29880
    },
    {
      "epoch": 8.54,
      "grad_norm": 3.961511538363993e-05,
      "learning_rate": 8.613333333333333e-06,
      "loss": 0.0,
      "step": 29890
    },
    {
      "epoch": 8.542857142857143,
      "grad_norm": 0.00016907793178688735,
      "learning_rate": 8.60952380952381e-06,
      "loss": 0.2521,
      "step": 29900
    },
    {
      "epoch": 8.545714285714286,
      "grad_norm": 8.621352753834799e-05,
      "learning_rate": 8.605714285714286e-06,
      "loss": 0.0,
      "step": 29910
    },
    {
      "epoch": 8.548571428571428,
      "grad_norm": 0.00023358993348665535,
      "learning_rate": 8.601904761904763e-06,
      "loss": 0.0,
      "step": 29920
    },
    {
      "epoch": 8.551428571428572,
      "grad_norm": 0.0007026406237855554,
      "learning_rate": 8.598095238095238e-06,
      "loss": 0.0,
      "step": 29930
    },
    {
      "epoch": 8.554285714285715,
      "grad_norm": 0.0001393744460074231,
      "learning_rate": 8.594285714285716e-06,
      "loss": 0.0,
      "step": 29940
    },
    {
      "epoch": 8.557142857142857,
      "grad_norm": 0.00019119551870971918,
      "learning_rate": 8.590476190476191e-06,
      "loss": 0.0,
      "step": 29950
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.0001595689100213349,
      "learning_rate": 8.586666666666667e-06,
      "loss": 0.0,
      "step": 29960
    },
    {
      "epoch": 8.562857142857142,
      "grad_norm": 0.035977933555841446,
      "learning_rate": 8.582857142857144e-06,
      "loss": 0.0001,
      "step": 29970
    },
    {
      "epoch": 8.565714285714286,
      "grad_norm": 0.00018749684386420995,
      "learning_rate": 8.57904761904762e-06,
      "loss": 0.0,
      "step": 29980
    },
    {
      "epoch": 8.56857142857143,
      "grad_norm": 0.0002974607050418854,
      "learning_rate": 8.575238095238097e-06,
      "loss": 0.0017,
      "step": 29990
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.00017703470075502992,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.0,
      "step": 30000
    },
    {
      "epoch": 8.574285714285715,
      "grad_norm": 0.0005090069025754929,
      "learning_rate": 8.567619047619048e-06,
      "loss": 0.0,
      "step": 30010
    },
    {
      "epoch": 8.577142857142857,
      "grad_norm": 0.0002900415565818548,
      "learning_rate": 8.563809523809524e-06,
      "loss": 0.0,
      "step": 30020
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.0003109488170593977,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.0,
      "step": 30030
    },
    {
      "epoch": 8.582857142857144,
      "grad_norm": 0.0005253319977782667,
      "learning_rate": 8.556190476190477e-06,
      "loss": 0.2176,
      "step": 30040
    },
    {
      "epoch": 8.585714285714285,
      "grad_norm": 0.0009708914440125227,
      "learning_rate": 8.552380952380954e-06,
      "loss": 0.0001,
      "step": 30050
    },
    {
      "epoch": 8.588571428571429,
      "grad_norm": 0.04686466604471207,
      "learning_rate": 8.54857142857143e-06,
      "loss": 0.0002,
      "step": 30060
    },
    {
      "epoch": 8.59142857142857,
      "grad_norm": 0.0011659754673019052,
      "learning_rate": 8.544761904761905e-06,
      "loss": 0.0,
      "step": 30070
    },
    {
      "epoch": 8.594285714285714,
      "grad_norm": 0.004103334620594978,
      "learning_rate": 8.540952380952382e-06,
      "loss": 0.0001,
      "step": 30080
    },
    {
      "epoch": 8.597142857142858,
      "grad_norm": 0.0008199822041206062,
      "learning_rate": 8.537142857142858e-06,
      "loss": 0.0001,
      "step": 30090
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.00019959633937105536,
      "learning_rate": 8.533333333333335e-06,
      "loss": 0.0,
      "step": 30100
    },
    {
      "epoch": 8.602857142857143,
      "grad_norm": 0.016609547659754753,
      "learning_rate": 8.529523809523809e-06,
      "loss": 0.0,
      "step": 30110
    },
    {
      "epoch": 8.605714285714285,
      "grad_norm": 0.0006672825547866523,
      "learning_rate": 8.525714285714286e-06,
      "loss": 0.0,
      "step": 30120
    },
    {
      "epoch": 8.608571428571429,
      "grad_norm": 0.0006066341884434223,
      "learning_rate": 8.521904761904762e-06,
      "loss": 0.0,
      "step": 30130
    },
    {
      "epoch": 8.611428571428572,
      "grad_norm": 0.00017985790327657014,
      "learning_rate": 8.51809523809524e-06,
      "loss": 0.0,
      "step": 30140
    },
    {
      "epoch": 8.614285714285714,
      "grad_norm": 0.00021740375086665154,
      "learning_rate": 8.514285714285715e-06,
      "loss": 0.0,
      "step": 30150
    },
    {
      "epoch": 8.617142857142857,
      "grad_norm": 0.00010968675633193925,
      "learning_rate": 8.51047619047619e-06,
      "loss": 0.0,
      "step": 30160
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.00011640416050795466,
      "learning_rate": 8.506666666666668e-06,
      "loss": 0.0008,
      "step": 30170
    },
    {
      "epoch": 8.622857142857143,
      "grad_norm": 0.00023995489755179733,
      "learning_rate": 8.502857142857143e-06,
      "loss": 0.0,
      "step": 30180
    },
    {
      "epoch": 8.625714285714286,
      "grad_norm": 8.772400178713724e-05,
      "learning_rate": 8.49904761904762e-06,
      "loss": 0.0,
      "step": 30190
    },
    {
      "epoch": 8.628571428571428,
      "grad_norm": 0.0001136234714067541,
      "learning_rate": 8.495238095238096e-06,
      "loss": 0.0,
      "step": 30200
    },
    {
      "epoch": 8.631428571428572,
      "grad_norm": 0.00012509689258877188,
      "learning_rate": 8.491428571428572e-06,
      "loss": 0.2108,
      "step": 30210
    },
    {
      "epoch": 8.634285714285713,
      "grad_norm": 0.0004067863919772208,
      "learning_rate": 8.487619047619047e-06,
      "loss": 0.0,
      "step": 30220
    },
    {
      "epoch": 8.637142857142857,
      "grad_norm": 8.350548159796745e-05,
      "learning_rate": 8.483809523809525e-06,
      "loss": 0.1808,
      "step": 30230
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.0027836435474455357,
      "learning_rate": 8.48e-06,
      "loss": 0.0,
      "step": 30240
    },
    {
      "epoch": 8.642857142857142,
      "grad_norm": 0.0005722283967770636,
      "learning_rate": 8.476190476190477e-06,
      "loss": 0.0001,
      "step": 30250
    },
    {
      "epoch": 8.645714285714286,
      "grad_norm": 0.004911252297461033,
      "learning_rate": 8.472380952380953e-06,
      "loss": 0.0001,
      "step": 30260
    },
    {
      "epoch": 8.64857142857143,
      "grad_norm": 0.00012771826004609466,
      "learning_rate": 8.468571428571429e-06,
      "loss": 0.0,
      "step": 30270
    },
    {
      "epoch": 8.651428571428571,
      "grad_norm": 0.0013157246867194772,
      "learning_rate": 8.464761904761906e-06,
      "loss": 0.0,
      "step": 30280
    },
    {
      "epoch": 8.654285714285715,
      "grad_norm": 0.0001759701408445835,
      "learning_rate": 8.460952380952381e-06,
      "loss": 0.0,
      "step": 30290
    },
    {
      "epoch": 8.657142857142857,
      "grad_norm": 0.00019770195649471134,
      "learning_rate": 8.457142857142859e-06,
      "loss": 0.0,
      "step": 30300
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.0002153167879441753,
      "learning_rate": 8.453333333333334e-06,
      "loss": 0.0,
      "step": 30310
    },
    {
      "epoch": 8.662857142857142,
      "grad_norm": 0.0002907991874963045,
      "learning_rate": 8.44952380952381e-06,
      "loss": 0.0,
      "step": 30320
    },
    {
      "epoch": 8.665714285714285,
      "grad_norm": 0.00012004873133264482,
      "learning_rate": 8.445714285714285e-06,
      "loss": 0.0,
      "step": 30330
    },
    {
      "epoch": 8.668571428571429,
      "grad_norm": 0.00018793878552969545,
      "learning_rate": 8.441904761904763e-06,
      "loss": 0.0,
      "step": 30340
    },
    {
      "epoch": 8.67142857142857,
      "grad_norm": 0.00016121123917400837,
      "learning_rate": 8.438095238095238e-06,
      "loss": 0.0,
      "step": 30350
    },
    {
      "epoch": 8.674285714285714,
      "grad_norm": 0.00037248627631925046,
      "learning_rate": 8.434285714285716e-06,
      "loss": 0.0,
      "step": 30360
    },
    {
      "epoch": 8.677142857142858,
      "grad_norm": 9.075194247998297e-05,
      "learning_rate": 8.430476190476191e-06,
      "loss": 0.0,
      "step": 30370
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.007859254255890846,
      "learning_rate": 8.426666666666667e-06,
      "loss": 0.0,
      "step": 30380
    },
    {
      "epoch": 8.682857142857143,
      "grad_norm": 0.0005943007417954504,
      "learning_rate": 8.422857142857144e-06,
      "loss": 0.1892,
      "step": 30390
    },
    {
      "epoch": 8.685714285714285,
      "grad_norm": 0.020709548145532608,
      "learning_rate": 8.41904761904762e-06,
      "loss": 0.0002,
      "step": 30400
    },
    {
      "epoch": 8.688571428571429,
      "grad_norm": 0.012605303898453712,
      "learning_rate": 8.415238095238097e-06,
      "loss": 0.0001,
      "step": 30410
    },
    {
      "epoch": 8.691428571428572,
      "grad_norm": 0.006022338289767504,
      "learning_rate": 8.411428571428572e-06,
      "loss": 0.0,
      "step": 30420
    },
    {
      "epoch": 8.694285714285714,
      "grad_norm": 0.003267504507675767,
      "learning_rate": 8.407619047619048e-06,
      "loss": 0.0,
      "step": 30430
    },
    {
      "epoch": 8.697142857142858,
      "grad_norm": 0.000789811834692955,
      "learning_rate": 8.403809523809524e-06,
      "loss": 0.0001,
      "step": 30440
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.00040024431655183434,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0,
      "step": 30450
    },
    {
      "epoch": 8.702857142857143,
      "grad_norm": 0.0018907460616901517,
      "learning_rate": 8.396190476190476e-06,
      "loss": 0.0,
      "step": 30460
    },
    {
      "epoch": 8.705714285714286,
      "grad_norm": 0.0016745536122471094,
      "learning_rate": 8.392380952380954e-06,
      "loss": 0.0001,
      "step": 30470
    },
    {
      "epoch": 8.708571428571428,
      "grad_norm": 0.0003999834298156202,
      "learning_rate": 8.38857142857143e-06,
      "loss": 0.0,
      "step": 30480
    },
    {
      "epoch": 8.711428571428572,
      "grad_norm": 0.0001456786849303171,
      "learning_rate": 8.384761904761905e-06,
      "loss": 0.0,
      "step": 30490
    },
    {
      "epoch": 8.714285714285714,
      "grad_norm": 0.0003941222676075995,
      "learning_rate": 8.380952380952382e-06,
      "loss": 0.0,
      "step": 30500
    },
    {
      "epoch": 8.717142857142857,
      "grad_norm": 0.0015284104738384485,
      "learning_rate": 8.377142857142858e-06,
      "loss": 0.0,
      "step": 30510
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.0015470015350729227,
      "learning_rate": 8.373333333333335e-06,
      "loss": 0.0,
      "step": 30520
    },
    {
      "epoch": 8.722857142857142,
      "grad_norm": 0.00047778483713045716,
      "learning_rate": 8.36952380952381e-06,
      "loss": 0.0,
      "step": 30530
    },
    {
      "epoch": 8.725714285714286,
      "grad_norm": 0.0008179982542060316,
      "learning_rate": 8.365714285714286e-06,
      "loss": 0.0,
      "step": 30540
    },
    {
      "epoch": 8.728571428571428,
      "grad_norm": 0.00031207952997647226,
      "learning_rate": 8.361904761904762e-06,
      "loss": 0.0006,
      "step": 30550
    },
    {
      "epoch": 8.731428571428571,
      "grad_norm": 0.011148651130497456,
      "learning_rate": 8.358095238095239e-06,
      "loss": 0.0,
      "step": 30560
    },
    {
      "epoch": 8.734285714285715,
      "grad_norm": 0.0004950902657583356,
      "learning_rate": 8.354285714285715e-06,
      "loss": 0.0,
      "step": 30570
    },
    {
      "epoch": 8.737142857142857,
      "grad_norm": 0.0007243878790177405,
      "learning_rate": 8.35047619047619e-06,
      "loss": 0.0,
      "step": 30580
    },
    {
      "epoch": 8.74,
      "grad_norm": 0.004590504802763462,
      "learning_rate": 8.346666666666668e-06,
      "loss": 0.0,
      "step": 30590
    },
    {
      "epoch": 8.742857142857144,
      "grad_norm": 0.00022159208310768008,
      "learning_rate": 8.342857142857143e-06,
      "loss": 0.0,
      "step": 30600
    },
    {
      "epoch": 8.745714285714286,
      "grad_norm": 9.783660061657429e-05,
      "learning_rate": 8.33904761904762e-06,
      "loss": 0.0,
      "step": 30610
    },
    {
      "epoch": 8.748571428571429,
      "grad_norm": 0.00024203717475757003,
      "learning_rate": 8.335238095238096e-06,
      "loss": 0.0,
      "step": 30620
    },
    {
      "epoch": 8.751428571428571,
      "grad_norm": 0.0006356498342938721,
      "learning_rate": 8.331428571428573e-06,
      "loss": 0.0,
      "step": 30630
    },
    {
      "epoch": 8.754285714285714,
      "grad_norm": 0.0002071097114821896,
      "learning_rate": 8.327619047619049e-06,
      "loss": 0.0,
      "step": 30640
    },
    {
      "epoch": 8.757142857142856,
      "grad_norm": 0.0008355778991244733,
      "learning_rate": 8.323809523809524e-06,
      "loss": 0.1093,
      "step": 30650
    },
    {
      "epoch": 8.76,
      "grad_norm": 0.00011170025391038507,
      "learning_rate": 8.32e-06,
      "loss": 0.0,
      "step": 30660
    },
    {
      "epoch": 8.762857142857143,
      "grad_norm": 0.00010452984133735299,
      "learning_rate": 8.316190476190477e-06,
      "loss": 0.0,
      "step": 30670
    },
    {
      "epoch": 8.765714285714285,
      "grad_norm": 7.392014231299981e-05,
      "learning_rate": 8.312380952380953e-06,
      "loss": 0.0,
      "step": 30680
    },
    {
      "epoch": 8.768571428571429,
      "grad_norm": 9.064080950338393e-05,
      "learning_rate": 8.308571428571428e-06,
      "loss": 0.0,
      "step": 30690
    },
    {
      "epoch": 8.771428571428572,
      "grad_norm": 9.889894863590598e-05,
      "learning_rate": 8.304761904761906e-06,
      "loss": 0.0,
      "step": 30700
    },
    {
      "epoch": 8.774285714285714,
      "grad_norm": 0.00015495691332034767,
      "learning_rate": 8.300952380952381e-06,
      "loss": 0.0,
      "step": 30710
    },
    {
      "epoch": 8.777142857142858,
      "grad_norm": 0.00011019637167919427,
      "learning_rate": 8.297142857142859e-06,
      "loss": 0.0,
      "step": 30720
    },
    {
      "epoch": 8.78,
      "grad_norm": 9.19322410481982e-05,
      "learning_rate": 8.293333333333334e-06,
      "loss": 0.0,
      "step": 30730
    },
    {
      "epoch": 8.782857142857143,
      "grad_norm": 0.00036464876029640436,
      "learning_rate": 8.289523809523811e-06,
      "loss": 0.0,
      "step": 30740
    },
    {
      "epoch": 8.785714285714286,
      "grad_norm": 7.901894423412159e-05,
      "learning_rate": 8.285714285714287e-06,
      "loss": 0.0,
      "step": 30750
    },
    {
      "epoch": 8.788571428571428,
      "grad_norm": 0.0003100930480286479,
      "learning_rate": 8.281904761904763e-06,
      "loss": 0.0,
      "step": 30760
    },
    {
      "epoch": 8.791428571428572,
      "grad_norm": 0.00018330368038732558,
      "learning_rate": 8.278095238095238e-06,
      "loss": 0.0,
      "step": 30770
    },
    {
      "epoch": 8.794285714285714,
      "grad_norm": 0.0001591576001374051,
      "learning_rate": 8.274285714285715e-06,
      "loss": 0.0,
      "step": 30780
    },
    {
      "epoch": 8.797142857142857,
      "grad_norm": 0.00017735087021719664,
      "learning_rate": 8.270476190476191e-06,
      "loss": 0.0,
      "step": 30790
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.0004668372275773436,
      "learning_rate": 8.266666666666667e-06,
      "loss": 0.0,
      "step": 30800
    },
    {
      "epoch": 8.802857142857142,
      "grad_norm": 0.00026866651023738086,
      "learning_rate": 8.262857142857144e-06,
      "loss": 0.0,
      "step": 30810
    },
    {
      "epoch": 8.805714285714286,
      "grad_norm": 7.463458314305171e-05,
      "learning_rate": 8.25904761904762e-06,
      "loss": 0.0,
      "step": 30820
    },
    {
      "epoch": 8.808571428571428,
      "grad_norm": 0.00014751448179595172,
      "learning_rate": 8.255238095238097e-06,
      "loss": 0.0,
      "step": 30830
    },
    {
      "epoch": 8.811428571428571,
      "grad_norm": 6.78494106978178e-05,
      "learning_rate": 8.251428571428572e-06,
      "loss": 0.0,
      "step": 30840
    },
    {
      "epoch": 8.814285714285715,
      "grad_norm": 0.00011373800225555897,
      "learning_rate": 8.24761904761905e-06,
      "loss": 0.0,
      "step": 30850
    },
    {
      "epoch": 8.817142857142857,
      "grad_norm": 7.83721188781783e-05,
      "learning_rate": 8.243809523809525e-06,
      "loss": 0.0,
      "step": 30860
    },
    {
      "epoch": 8.82,
      "grad_norm": 9.565856453264132e-05,
      "learning_rate": 8.24e-06,
      "loss": 0.0,
      "step": 30870
    },
    {
      "epoch": 8.822857142857142,
      "grad_norm": 0.0006362118874676526,
      "learning_rate": 8.236190476190476e-06,
      "loss": 0.0968,
      "step": 30880
    },
    {
      "epoch": 8.825714285714286,
      "grad_norm": 0.00018218861077912152,
      "learning_rate": 8.232380952380954e-06,
      "loss": 0.0,
      "step": 30890
    },
    {
      "epoch": 8.82857142857143,
      "grad_norm": 0.0005744635709561408,
      "learning_rate": 8.22857142857143e-06,
      "loss": 0.0,
      "step": 30900
    },
    {
      "epoch": 8.831428571428571,
      "grad_norm": 8.280868496512994e-05,
      "learning_rate": 8.224761904761905e-06,
      "loss": 0.0,
      "step": 30910
    },
    {
      "epoch": 8.834285714285715,
      "grad_norm": 6.790392217226326e-05,
      "learning_rate": 8.220952380952382e-06,
      "loss": 0.0,
      "step": 30920
    },
    {
      "epoch": 8.837142857142858,
      "grad_norm": 0.0024424188304692507,
      "learning_rate": 8.217142857142858e-06,
      "loss": 0.0,
      "step": 30930
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.0001555737544549629,
      "learning_rate": 8.213333333333335e-06,
      "loss": 0.0,
      "step": 30940
    },
    {
      "epoch": 8.842857142857143,
      "grad_norm": 0.05377762019634247,
      "learning_rate": 8.20952380952381e-06,
      "loss": 0.0,
      "step": 30950
    },
    {
      "epoch": 8.845714285714285,
      "grad_norm": 1.146635890007019,
      "learning_rate": 8.205714285714286e-06,
      "loss": 0.0002,
      "step": 30960
    },
    {
      "epoch": 8.848571428571429,
      "grad_norm": 8.409172005485743e-05,
      "learning_rate": 8.201904761904762e-06,
      "loss": 0.0,
      "step": 30970
    },
    {
      "epoch": 8.85142857142857,
      "grad_norm": 8.862655522534624e-05,
      "learning_rate": 8.198095238095239e-06,
      "loss": 0.0,
      "step": 30980
    },
    {
      "epoch": 8.854285714285714,
      "grad_norm": 6.141460471553728e-05,
      "learning_rate": 8.194285714285714e-06,
      "loss": 0.0,
      "step": 30990
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 0.0001235600939253345,
      "learning_rate": 8.190476190476192e-06,
      "loss": 0.0,
      "step": 31000
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.0001004432124318555,
      "learning_rate": 8.186666666666667e-06,
      "loss": 0.0,
      "step": 31010
    },
    {
      "epoch": 8.862857142857143,
      "grad_norm": 3.8862643123138696e-05,
      "learning_rate": 8.182857142857143e-06,
      "loss": 0.0,
      "step": 31020
    },
    {
      "epoch": 8.865714285714287,
      "grad_norm": 0.00021147791994735599,
      "learning_rate": 8.17904761904762e-06,
      "loss": 0.0,
      "step": 31030
    },
    {
      "epoch": 8.868571428571428,
      "grad_norm": 9.317868534708396e-05,
      "learning_rate": 8.175238095238096e-06,
      "loss": 0.0,
      "step": 31040
    },
    {
      "epoch": 8.871428571428572,
      "grad_norm": 0.0001551629538880661,
      "learning_rate": 8.171428571428573e-06,
      "loss": 0.0,
      "step": 31050
    },
    {
      "epoch": 8.874285714285714,
      "grad_norm": 0.00023072304611559957,
      "learning_rate": 8.167619047619049e-06,
      "loss": 0.0,
      "step": 31060
    },
    {
      "epoch": 8.877142857142857,
      "grad_norm": 4.23016790591646e-05,
      "learning_rate": 8.163809523809524e-06,
      "loss": 0.0,
      "step": 31070
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.00025598020874895155,
      "learning_rate": 8.16e-06,
      "loss": 0.0,
      "step": 31080
    },
    {
      "epoch": 8.882857142857143,
      "grad_norm": 4.1224520828109235e-05,
      "learning_rate": 8.156190476190477e-06,
      "loss": 0.0004,
      "step": 31090
    },
    {
      "epoch": 8.885714285714286,
      "grad_norm": 3.357790774316527e-05,
      "learning_rate": 8.152380952380953e-06,
      "loss": 0.0,
      "step": 31100
    },
    {
      "epoch": 8.888571428571428,
      "grad_norm": 0.0031904715579003096,
      "learning_rate": 8.148571428571428e-06,
      "loss": 0.0,
      "step": 31110
    },
    {
      "epoch": 8.891428571428571,
      "grad_norm": 3.8956535718170926e-05,
      "learning_rate": 8.144761904761906e-06,
      "loss": 0.0,
      "step": 31120
    },
    {
      "epoch": 8.894285714285715,
      "grad_norm": 2.5507230020593852e-05,
      "learning_rate": 8.140952380952381e-06,
      "loss": 0.0,
      "step": 31130
    },
    {
      "epoch": 8.897142857142857,
      "grad_norm": 3.261779056629166e-05,
      "learning_rate": 8.137142857142858e-06,
      "loss": 0.0,
      "step": 31140
    },
    {
      "epoch": 8.9,
      "grad_norm": 2.6528574380790815e-05,
      "learning_rate": 8.133333333333334e-06,
      "loss": 0.0,
      "step": 31150
    },
    {
      "epoch": 8.902857142857142,
      "grad_norm": 3.14708668156527e-05,
      "learning_rate": 8.129523809523811e-06,
      "loss": 0.0,
      "step": 31160
    },
    {
      "epoch": 8.905714285714286,
      "grad_norm": 2.4756502170930617e-05,
      "learning_rate": 8.125714285714287e-06,
      "loss": 0.0,
      "step": 31170
    },
    {
      "epoch": 8.90857142857143,
      "grad_norm": 0.0008796749752946198,
      "learning_rate": 8.121904761904762e-06,
      "loss": 0.0,
      "step": 31180
    },
    {
      "epoch": 8.911428571428571,
      "grad_norm": 7.734354585409164e-05,
      "learning_rate": 8.118095238095238e-06,
      "loss": 0.0,
      "step": 31190
    },
    {
      "epoch": 8.914285714285715,
      "grad_norm": 0.0001580391835886985,
      "learning_rate": 8.114285714285715e-06,
      "loss": 0.0001,
      "step": 31200
    },
    {
      "epoch": 8.917142857142856,
      "grad_norm": 0.0019821403548121452,
      "learning_rate": 8.11047619047619e-06,
      "loss": 0.0,
      "step": 31210
    },
    {
      "epoch": 8.92,
      "grad_norm": 3.335296059958637e-05,
      "learning_rate": 8.106666666666666e-06,
      "loss": 0.0,
      "step": 31220
    },
    {
      "epoch": 8.922857142857143,
      "grad_norm": 2.7370499083190225e-05,
      "learning_rate": 8.102857142857144e-06,
      "loss": 0.2076,
      "step": 31230
    },
    {
      "epoch": 8.925714285714285,
      "grad_norm": 9.884593600872904e-05,
      "learning_rate": 8.09904761904762e-06,
      "loss": 0.1647,
      "step": 31240
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.00020131478959228843,
      "learning_rate": 8.095238095238097e-06,
      "loss": 0.0,
      "step": 31250
    },
    {
      "epoch": 8.93142857142857,
      "grad_norm": 0.01915719173848629,
      "learning_rate": 8.091428571428572e-06,
      "loss": 0.0,
      "step": 31260
    },
    {
      "epoch": 8.934285714285714,
      "grad_norm": 0.00024630248663015664,
      "learning_rate": 8.08761904761905e-06,
      "loss": 0.0,
      "step": 31270
    },
    {
      "epoch": 8.937142857142858,
      "grad_norm": 6.423705053748563e-05,
      "learning_rate": 8.083809523809525e-06,
      "loss": 0.0,
      "step": 31280
    },
    {
      "epoch": 8.94,
      "grad_norm": 0.00033406695001758635,
      "learning_rate": 8.08e-06,
      "loss": 0.0,
      "step": 31290
    },
    {
      "epoch": 8.942857142857143,
      "grad_norm": 4.1135430365102366e-05,
      "learning_rate": 8.076190476190476e-06,
      "loss": 0.0,
      "step": 31300
    },
    {
      "epoch": 8.945714285714285,
      "grad_norm": 0.0017216127598658204,
      "learning_rate": 8.072380952380953e-06,
      "loss": 0.0,
      "step": 31310
    },
    {
      "epoch": 8.948571428571428,
      "grad_norm": 0.004091483540832996,
      "learning_rate": 8.068571428571429e-06,
      "loss": 0.0,
      "step": 31320
    },
    {
      "epoch": 8.951428571428572,
      "grad_norm": 0.00035790991387329996,
      "learning_rate": 8.064761904761905e-06,
      "loss": 0.0,
      "step": 31330
    },
    {
      "epoch": 8.954285714285714,
      "grad_norm": 4.235827145748772e-05,
      "learning_rate": 8.060952380952382e-06,
      "loss": 0.0,
      "step": 31340
    },
    {
      "epoch": 8.957142857142857,
      "grad_norm": 0.00028135121101513505,
      "learning_rate": 8.057142857142857e-06,
      "loss": 0.0,
      "step": 31350
    },
    {
      "epoch": 8.96,
      "grad_norm": 3.800701961154118e-05,
      "learning_rate": 8.053333333333335e-06,
      "loss": 0.0,
      "step": 31360
    },
    {
      "epoch": 8.962857142857143,
      "grad_norm": 9.173170110443607e-05,
      "learning_rate": 8.04952380952381e-06,
      "loss": 0.0,
      "step": 31370
    },
    {
      "epoch": 8.965714285714286,
      "grad_norm": 9.662155207479373e-05,
      "learning_rate": 8.045714285714286e-06,
      "loss": 0.0011,
      "step": 31380
    },
    {
      "epoch": 8.968571428571428,
      "grad_norm": 2.6944542696583085e-05,
      "learning_rate": 8.041904761904763e-06,
      "loss": 0.0,
      "step": 31390
    },
    {
      "epoch": 8.971428571428572,
      "grad_norm": 8.541822171537206e-05,
      "learning_rate": 8.038095238095239e-06,
      "loss": 0.0,
      "step": 31400
    },
    {
      "epoch": 8.974285714285715,
      "grad_norm": 4.229317346471362e-05,
      "learning_rate": 8.034285714285714e-06,
      "loss": 0.0,
      "step": 31410
    },
    {
      "epoch": 8.977142857142857,
      "grad_norm": 3.071196988457814e-05,
      "learning_rate": 8.030476190476192e-06,
      "loss": 0.0,
      "step": 31420
    },
    {
      "epoch": 8.98,
      "grad_norm": 2.8424021365935914e-05,
      "learning_rate": 8.026666666666667e-06,
      "loss": 0.0,
      "step": 31430
    },
    {
      "epoch": 8.982857142857142,
      "grad_norm": 0.004854333586990833,
      "learning_rate": 8.022857142857143e-06,
      "loss": 0.0,
      "step": 31440
    },
    {
      "epoch": 8.985714285714286,
      "grad_norm": 2.5074094082810916e-05,
      "learning_rate": 8.01904761904762e-06,
      "loss": 0.0,
      "step": 31450
    },
    {
      "epoch": 8.98857142857143,
      "grad_norm": 0.0003728478914126754,
      "learning_rate": 8.015238095238096e-06,
      "loss": 0.0,
      "step": 31460
    },
    {
      "epoch": 8.991428571428571,
      "grad_norm": 3.4087555832229555e-05,
      "learning_rate": 8.011428571428573e-06,
      "loss": 0.0,
      "step": 31470
    },
    {
      "epoch": 8.994285714285715,
      "grad_norm": 3.5246441257186234e-05,
      "learning_rate": 8.007619047619048e-06,
      "loss": 0.0,
      "step": 31480
    },
    {
      "epoch": 8.997142857142856,
      "grad_norm": 3.695036502904259e-05,
      "learning_rate": 8.003809523809524e-06,
      "loss": 0.0,
      "step": 31490
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.00015272154996637255,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0,
      "step": 31500
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9813333333333333,
      "eval_f1": 0.8818565400843881,
      "eval_loss": 0.19436173141002655,
      "eval_precision": 0.95,
      "eval_recall": 0.8228346456692913,
      "eval_runtime": 360.2026,
      "eval_samples_per_second": 8.329,
      "eval_steps_per_second": 2.082,
      "step": 31500
    },
    {
      "epoch": 9.002857142857144,
      "grad_norm": 2.8477961677708663e-05,
      "learning_rate": 7.996190476190477e-06,
      "loss": 0.0,
      "step": 31510
    },
    {
      "epoch": 9.005714285714285,
      "grad_norm": 8.00474444986321e-05,
      "learning_rate": 7.992380952380952e-06,
      "loss": 0.0,
      "step": 31520
    },
    {
      "epoch": 9.008571428571429,
      "grad_norm": 9.459286229684949e-05,
      "learning_rate": 7.988571428571428e-06,
      "loss": 0.0,
      "step": 31530
    },
    {
      "epoch": 9.01142857142857,
      "grad_norm": 3.139266118523665e-05,
      "learning_rate": 7.984761904761905e-06,
      "loss": 0.2917,
      "step": 31540
    },
    {
      "epoch": 9.014285714285714,
      "grad_norm": 7.341087621171027e-05,
      "learning_rate": 7.980952380952381e-06,
      "loss": 0.0,
      "step": 31550
    },
    {
      "epoch": 9.017142857142858,
      "grad_norm": 181.15509033203125,
      "learning_rate": 7.977142857142858e-06,
      "loss": 0.2338,
      "step": 31560
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.0007648628670722246,
      "learning_rate": 7.973333333333334e-06,
      "loss": 0.0,
      "step": 31570
    },
    {
      "epoch": 9.022857142857143,
      "grad_norm": 0.005339330527931452,
      "learning_rate": 7.969523809523811e-06,
      "loss": 0.0,
      "step": 31580
    },
    {
      "epoch": 9.025714285714285,
      "grad_norm": 0.0009064618498086929,
      "learning_rate": 7.965714285714287e-06,
      "loss": 0.0,
      "step": 31590
    },
    {
      "epoch": 9.028571428571428,
      "grad_norm": 0.00015082296158652753,
      "learning_rate": 7.961904761904762e-06,
      "loss": 0.0001,
      "step": 31600
    },
    {
      "epoch": 9.031428571428572,
      "grad_norm": 0.013164919801056385,
      "learning_rate": 7.95809523809524e-06,
      "loss": 0.0,
      "step": 31610
    },
    {
      "epoch": 9.034285714285714,
      "grad_norm": 0.00018627675308380276,
      "learning_rate": 7.954285714285715e-06,
      "loss": 0.0,
      "step": 31620
    },
    {
      "epoch": 9.037142857142857,
      "grad_norm": 0.00109956378582865,
      "learning_rate": 7.95047619047619e-06,
      "loss": 0.0,
      "step": 31630
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.00015008643094915897,
      "learning_rate": 7.946666666666666e-06,
      "loss": 0.0,
      "step": 31640
    },
    {
      "epoch": 9.042857142857143,
      "grad_norm": 0.0002014831406995654,
      "learning_rate": 7.942857142857144e-06,
      "loss": 0.0,
      "step": 31650
    },
    {
      "epoch": 9.045714285714286,
      "grad_norm": 0.0010393987176939845,
      "learning_rate": 7.939047619047619e-06,
      "loss": 0.0,
      "step": 31660
    },
    {
      "epoch": 9.048571428571428,
      "grad_norm": 0.0001658717228565365,
      "learning_rate": 7.935238095238096e-06,
      "loss": 0.0,
      "step": 31670
    },
    {
      "epoch": 9.051428571428572,
      "grad_norm": 0.0007694392115809023,
      "learning_rate": 7.931428571428572e-06,
      "loss": 0.0001,
      "step": 31680
    },
    {
      "epoch": 9.054285714285715,
      "grad_norm": 0.0002624206827022135,
      "learning_rate": 7.92761904761905e-06,
      "loss": 0.0,
      "step": 31690
    },
    {
      "epoch": 9.057142857142857,
      "grad_norm": 8.43040324980393e-05,
      "learning_rate": 7.923809523809525e-06,
      "loss": 0.0,
      "step": 31700
    },
    {
      "epoch": 9.06,
      "grad_norm": 0.0062503027729690075,
      "learning_rate": 7.92e-06,
      "loss": 0.0,
      "step": 31710
    },
    {
      "epoch": 9.062857142857142,
      "grad_norm": 0.00019543997768778354,
      "learning_rate": 7.916190476190478e-06,
      "loss": 0.0,
      "step": 31720
    },
    {
      "epoch": 9.065714285714286,
      "grad_norm": 0.00011934105714317411,
      "learning_rate": 7.912380952380953e-06,
      "loss": 0.0,
      "step": 31730
    },
    {
      "epoch": 9.06857142857143,
      "grad_norm": 0.000178758695255965,
      "learning_rate": 7.908571428571429e-06,
      "loss": 0.0,
      "step": 31740
    },
    {
      "epoch": 9.071428571428571,
      "grad_norm": 6.246673001442105e-05,
      "learning_rate": 7.904761904761904e-06,
      "loss": 0.0,
      "step": 31750
    },
    {
      "epoch": 9.074285714285715,
      "grad_norm": 0.00014581250434275717,
      "learning_rate": 7.900952380952382e-06,
      "loss": 0.0,
      "step": 31760
    },
    {
      "epoch": 9.077142857142857,
      "grad_norm": 0.0006973284762352705,
      "learning_rate": 7.897142857142857e-06,
      "loss": 0.0,
      "step": 31770
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.00012806380982510746,
      "learning_rate": 7.893333333333335e-06,
      "loss": 0.0,
      "step": 31780
    },
    {
      "epoch": 9.082857142857144,
      "grad_norm": 0.00188400165643543,
      "learning_rate": 7.88952380952381e-06,
      "loss": 0.0,
      "step": 31790
    },
    {
      "epoch": 9.085714285714285,
      "grad_norm": 0.00014525542792398483,
      "learning_rate": 7.885714285714286e-06,
      "loss": 0.0,
      "step": 31800
    },
    {
      "epoch": 9.088571428571429,
      "grad_norm": 0.0034313907381147146,
      "learning_rate": 7.881904761904763e-06,
      "loss": 0.0,
      "step": 31810
    },
    {
      "epoch": 9.09142857142857,
      "grad_norm": 0.00015843893925193697,
      "learning_rate": 7.878095238095239e-06,
      "loss": 0.0,
      "step": 31820
    },
    {
      "epoch": 9.094285714285714,
      "grad_norm": 0.00010545211989665404,
      "learning_rate": 7.874285714285716e-06,
      "loss": 0.0,
      "step": 31830
    },
    {
      "epoch": 9.097142857142858,
      "grad_norm": 0.00029429630376398563,
      "learning_rate": 7.870476190476191e-06,
      "loss": 0.0,
      "step": 31840
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.00038122391561046243,
      "learning_rate": 7.866666666666667e-06,
      "loss": 0.0,
      "step": 31850
    },
    {
      "epoch": 9.102857142857143,
      "grad_norm": 0.000571560813114047,
      "learning_rate": 7.862857142857143e-06,
      "loss": 0.0,
      "step": 31860
    },
    {
      "epoch": 9.105714285714285,
      "grad_norm": 0.00015224878734443337,
      "learning_rate": 7.85904761904762e-06,
      "loss": 0.0,
      "step": 31870
    },
    {
      "epoch": 9.108571428571429,
      "grad_norm": 0.0002751813444774598,
      "learning_rate": 7.855238095238095e-06,
      "loss": 0.0,
      "step": 31880
    },
    {
      "epoch": 9.111428571428572,
      "grad_norm": 0.0007887444226071239,
      "learning_rate": 7.851428571428573e-06,
      "loss": 0.0,
      "step": 31890
    },
    {
      "epoch": 9.114285714285714,
      "grad_norm": 4.336347046773881e-05,
      "learning_rate": 7.847619047619048e-06,
      "loss": 0.0,
      "step": 31900
    },
    {
      "epoch": 9.117142857142857,
      "grad_norm": 8.090247138170525e-05,
      "learning_rate": 7.843809523809524e-06,
      "loss": 0.0,
      "step": 31910
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.000270137534243986,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.0,
      "step": 31920
    },
    {
      "epoch": 9.122857142857143,
      "grad_norm": 0.00045055992086417973,
      "learning_rate": 7.836190476190477e-06,
      "loss": 0.0,
      "step": 31930
    },
    {
      "epoch": 9.125714285714286,
      "grad_norm": 0.0017054916825145483,
      "learning_rate": 7.832380952380954e-06,
      "loss": 0.0,
      "step": 31940
    },
    {
      "epoch": 9.128571428571428,
      "grad_norm": 3.194234159309417e-05,
      "learning_rate": 7.828571428571428e-06,
      "loss": 0.0,
      "step": 31950
    },
    {
      "epoch": 9.131428571428572,
      "grad_norm": 7.762812310829759e-05,
      "learning_rate": 7.824761904761905e-06,
      "loss": 0.0,
      "step": 31960
    },
    {
      "epoch": 9.134285714285713,
      "grad_norm": 7.315751281566918e-05,
      "learning_rate": 7.82095238095238e-06,
      "loss": 0.0,
      "step": 31970
    },
    {
      "epoch": 9.137142857142857,
      "grad_norm": 0.0003234078176319599,
      "learning_rate": 7.817142857142858e-06,
      "loss": 0.0,
      "step": 31980
    },
    {
      "epoch": 9.14,
      "grad_norm": 9.909450454870239e-05,
      "learning_rate": 7.813333333333334e-06,
      "loss": 0.0,
      "step": 31990
    },
    {
      "epoch": 9.142857142857142,
      "grad_norm": 9.187433897750452e-05,
      "learning_rate": 7.809523809523811e-06,
      "loss": 0.0,
      "step": 32000
    },
    {
      "epoch": 9.145714285714286,
      "grad_norm": 0.0001777772413333878,
      "learning_rate": 7.805714285714286e-06,
      "loss": 0.0,
      "step": 32010
    },
    {
      "epoch": 9.14857142857143,
      "grad_norm": 0.0001422516506863758,
      "learning_rate": 7.801904761904762e-06,
      "loss": 0.0,
      "step": 32020
    },
    {
      "epoch": 9.151428571428571,
      "grad_norm": 8.593168604420498e-05,
      "learning_rate": 7.79809523809524e-06,
      "loss": 0.0,
      "step": 32030
    },
    {
      "epoch": 9.154285714285715,
      "grad_norm": 8.631334640085697e-05,
      "learning_rate": 7.794285714285715e-06,
      "loss": 0.0,
      "step": 32040
    },
    {
      "epoch": 9.157142857142857,
      "grad_norm": 5.595653783529997e-05,
      "learning_rate": 7.790476190476192e-06,
      "loss": 0.0,
      "step": 32050
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.0004057283513247967,
      "learning_rate": 7.786666666666666e-06,
      "loss": 0.0,
      "step": 32060
    },
    {
      "epoch": 9.162857142857144,
      "grad_norm": 3.76571188098751e-05,
      "learning_rate": 7.782857142857143e-06,
      "loss": 0.0,
      "step": 32070
    },
    {
      "epoch": 9.165714285714285,
      "grad_norm": 0.0003648333658929914,
      "learning_rate": 7.779047619047619e-06,
      "loss": 0.0,
      "step": 32080
    },
    {
      "epoch": 9.168571428571429,
      "grad_norm": 6.25134416623041e-05,
      "learning_rate": 7.775238095238096e-06,
      "loss": 0.0,
      "step": 32090
    },
    {
      "epoch": 9.17142857142857,
      "grad_norm": 5.472572593134828e-05,
      "learning_rate": 7.771428571428572e-06,
      "loss": 0.0,
      "step": 32100
    },
    {
      "epoch": 9.174285714285714,
      "grad_norm": 5.915644942433573e-05,
      "learning_rate": 7.767619047619049e-06,
      "loss": 0.0,
      "step": 32110
    },
    {
      "epoch": 9.177142857142858,
      "grad_norm": 0.0005512452917173505,
      "learning_rate": 7.763809523809525e-06,
      "loss": 0.0,
      "step": 32120
    },
    {
      "epoch": 9.18,
      "grad_norm": 8.17051695776172e-05,
      "learning_rate": 7.76e-06,
      "loss": 0.0,
      "step": 32130
    },
    {
      "epoch": 9.182857142857143,
      "grad_norm": 0.00019829708617180586,
      "learning_rate": 7.756190476190478e-06,
      "loss": 0.0,
      "step": 32140
    },
    {
      "epoch": 9.185714285714285,
      "grad_norm": 0.000159463903401047,
      "learning_rate": 7.752380952380953e-06,
      "loss": 0.0,
      "step": 32150
    },
    {
      "epoch": 9.188571428571429,
      "grad_norm": 6.731875328114256e-05,
      "learning_rate": 7.74857142857143e-06,
      "loss": 0.0,
      "step": 32160
    },
    {
      "epoch": 9.191428571428572,
      "grad_norm": 0.0008665032801218331,
      "learning_rate": 7.744761904761904e-06,
      "loss": 0.0,
      "step": 32170
    },
    {
      "epoch": 9.194285714285714,
      "grad_norm": 0.00029793099383823574,
      "learning_rate": 7.740952380952382e-06,
      "loss": 0.0,
      "step": 32180
    },
    {
      "epoch": 9.197142857142858,
      "grad_norm": 0.0003018973511643708,
      "learning_rate": 7.737142857142857e-06,
      "loss": 0.0,
      "step": 32190
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.0005697617307305336,
      "learning_rate": 7.733333333333334e-06,
      "loss": 0.0,
      "step": 32200
    },
    {
      "epoch": 9.202857142857143,
      "grad_norm": 2.947315624624025e-05,
      "learning_rate": 7.72952380952381e-06,
      "loss": 0.0,
      "step": 32210
    },
    {
      "epoch": 9.205714285714286,
      "grad_norm": 0.00012279144721105695,
      "learning_rate": 7.725714285714286e-06,
      "loss": 0.0001,
      "step": 32220
    },
    {
      "epoch": 9.208571428571428,
      "grad_norm": 5.114827217767015e-05,
      "learning_rate": 7.721904761904763e-06,
      "loss": 0.0,
      "step": 32230
    },
    {
      "epoch": 9.211428571428572,
      "grad_norm": 4.083547537447885e-05,
      "learning_rate": 7.718095238095238e-06,
      "loss": 0.0,
      "step": 32240
    },
    {
      "epoch": 9.214285714285714,
      "grad_norm": 0.0008154140668921173,
      "learning_rate": 7.714285714285716e-06,
      "loss": 0.0,
      "step": 32250
    },
    {
      "epoch": 9.217142857142857,
      "grad_norm": 5.301881901687011e-05,
      "learning_rate": 7.710476190476191e-06,
      "loss": 0.0,
      "step": 32260
    },
    {
      "epoch": 9.22,
      "grad_norm": 4.11745386372786e-05,
      "learning_rate": 7.706666666666669e-06,
      "loss": 0.0,
      "step": 32270
    },
    {
      "epoch": 9.222857142857142,
      "grad_norm": 0.00014535911031998694,
      "learning_rate": 7.702857142857142e-06,
      "loss": 0.0,
      "step": 32280
    },
    {
      "epoch": 9.225714285714286,
      "grad_norm": 9.759255772223696e-05,
      "learning_rate": 7.69904761904762e-06,
      "loss": 0.0,
      "step": 32290
    },
    {
      "epoch": 9.228571428571428,
      "grad_norm": 0.0004969617002643645,
      "learning_rate": 7.695238095238095e-06,
      "loss": 0.1465,
      "step": 32300
    },
    {
      "epoch": 9.231428571428571,
      "grad_norm": 0.0023927572183310986,
      "learning_rate": 7.691428571428573e-06,
      "loss": 0.0,
      "step": 32310
    },
    {
      "epoch": 9.234285714285715,
      "grad_norm": 3.482708416413516e-05,
      "learning_rate": 7.687619047619048e-06,
      "loss": 0.0,
      "step": 32320
    },
    {
      "epoch": 9.237142857142857,
      "grad_norm": 0.0002441288233967498,
      "learning_rate": 7.683809523809524e-06,
      "loss": 0.0,
      "step": 32330
    },
    {
      "epoch": 9.24,
      "grad_norm": 8.235336281359196e-05,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.0,
      "step": 32340
    },
    {
      "epoch": 9.242857142857142,
      "grad_norm": 3.904666664311662e-05,
      "learning_rate": 7.676190476190477e-06,
      "loss": 0.0001,
      "step": 32350
    },
    {
      "epoch": 9.245714285714286,
      "grad_norm": 6.190835119923577e-05,
      "learning_rate": 7.672380952380954e-06,
      "loss": 0.0,
      "step": 32360
    },
    {
      "epoch": 9.248571428571429,
      "grad_norm": 0.000277301121968776,
      "learning_rate": 7.66857142857143e-06,
      "loss": 0.0,
      "step": 32370
    },
    {
      "epoch": 9.251428571428571,
      "grad_norm": 3.9926337194629014e-05,
      "learning_rate": 7.664761904761905e-06,
      "loss": 0.0,
      "step": 32380
    },
    {
      "epoch": 9.254285714285714,
      "grad_norm": 4.7331544919870794e-05,
      "learning_rate": 7.66095238095238e-06,
      "loss": 0.0,
      "step": 32390
    },
    {
      "epoch": 9.257142857142856,
      "grad_norm": 0.00032321049366146326,
      "learning_rate": 7.657142857142858e-06,
      "loss": 0.0,
      "step": 32400
    },
    {
      "epoch": 9.26,
      "grad_norm": 2.7356685677659698e-05,
      "learning_rate": 7.653333333333333e-06,
      "loss": 0.0,
      "step": 32410
    },
    {
      "epoch": 9.262857142857143,
      "grad_norm": 3.0501119908876717e-05,
      "learning_rate": 7.64952380952381e-06,
      "loss": 0.0,
      "step": 32420
    },
    {
      "epoch": 9.265714285714285,
      "grad_norm": 5.699530083802529e-05,
      "learning_rate": 7.645714285714286e-06,
      "loss": 0.0,
      "step": 32430
    },
    {
      "epoch": 9.268571428571429,
      "grad_norm": 0.000402567267883569,
      "learning_rate": 7.641904761904762e-06,
      "loss": 0.0,
      "step": 32440
    },
    {
      "epoch": 9.271428571428572,
      "grad_norm": 8.834461186779663e-05,
      "learning_rate": 7.63809523809524e-06,
      "loss": 0.0,
      "step": 32450
    },
    {
      "epoch": 9.274285714285714,
      "grad_norm": 3.522011320455931e-05,
      "learning_rate": 7.634285714285715e-06,
      "loss": 0.0,
      "step": 32460
    },
    {
      "epoch": 9.277142857142858,
      "grad_norm": 7.967966666910797e-05,
      "learning_rate": 7.630476190476192e-06,
      "loss": 0.0,
      "step": 32470
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.00015260155487339944,
      "learning_rate": 7.626666666666668e-06,
      "loss": 0.0,
      "step": 32480
    },
    {
      "epoch": 9.282857142857143,
      "grad_norm": 0.00021905654284637421,
      "learning_rate": 7.622857142857143e-06,
      "loss": 0.0,
      "step": 32490
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 3.0397482987609692e-05,
      "learning_rate": 7.61904761904762e-06,
      "loss": 0.0,
      "step": 32500
    },
    {
      "epoch": 9.288571428571428,
      "grad_norm": 0.00013371002569328994,
      "learning_rate": 7.615238095238095e-06,
      "loss": 0.0,
      "step": 32510
    },
    {
      "epoch": 9.291428571428572,
      "grad_norm": 2.462713746353984e-05,
      "learning_rate": 7.611428571428572e-06,
      "loss": 0.0,
      "step": 32520
    },
    {
      "epoch": 9.294285714285714,
      "grad_norm": 3.240754813305102e-05,
      "learning_rate": 7.607619047619048e-06,
      "loss": 0.0,
      "step": 32530
    },
    {
      "epoch": 9.297142857142857,
      "grad_norm": 7.132781320251524e-05,
      "learning_rate": 7.6038095238095245e-06,
      "loss": 0.0,
      "step": 32540
    },
    {
      "epoch": 9.3,
      "grad_norm": 3.6018220271216705e-05,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0,
      "step": 32550
    },
    {
      "epoch": 9.302857142857142,
      "grad_norm": 4.2235271394019946e-05,
      "learning_rate": 7.596190476190477e-06,
      "loss": 0.0,
      "step": 32560
    },
    {
      "epoch": 9.305714285714286,
      "grad_norm": 0.003826514119282365,
      "learning_rate": 7.592380952380953e-06,
      "loss": 0.0,
      "step": 32570
    },
    {
      "epoch": 9.308571428571428,
      "grad_norm": 4.238271139911376e-05,
      "learning_rate": 7.588571428571429e-06,
      "loss": 0.0,
      "step": 32580
    },
    {
      "epoch": 9.311428571428571,
      "grad_norm": 0.0005459606181830168,
      "learning_rate": 7.584761904761906e-06,
      "loss": 0.0,
      "step": 32590
    },
    {
      "epoch": 9.314285714285715,
      "grad_norm": 0.0015380628174170852,
      "learning_rate": 7.580952380952381e-06,
      "loss": 0.0,
      "step": 32600
    },
    {
      "epoch": 9.317142857142857,
      "grad_norm": 2.1519461370189674e-05,
      "learning_rate": 7.577142857142857e-06,
      "loss": 0.0,
      "step": 32610
    },
    {
      "epoch": 9.32,
      "grad_norm": 2.1404541257652454e-05,
      "learning_rate": 7.573333333333333e-06,
      "loss": 0.0,
      "step": 32620
    },
    {
      "epoch": 9.322857142857142,
      "grad_norm": 3.24788416037336e-05,
      "learning_rate": 7.56952380952381e-06,
      "loss": 0.0,
      "step": 32630
    },
    {
      "epoch": 9.325714285714286,
      "grad_norm": 6.850405770819634e-05,
      "learning_rate": 7.565714285714286e-06,
      "loss": 0.0,
      "step": 32640
    },
    {
      "epoch": 9.32857142857143,
      "grad_norm": 0.003542699385434389,
      "learning_rate": 7.561904761904763e-06,
      "loss": 0.0,
      "step": 32650
    },
    {
      "epoch": 9.331428571428571,
      "grad_norm": 0.0001826236111810431,
      "learning_rate": 7.558095238095239e-06,
      "loss": 0.0,
      "step": 32660
    },
    {
      "epoch": 9.334285714285715,
      "grad_norm": 0.00039723870577290654,
      "learning_rate": 7.5542857142857155e-06,
      "loss": 0.0,
      "step": 32670
    },
    {
      "epoch": 9.337142857142856,
      "grad_norm": 0.0003515689750202,
      "learning_rate": 7.550476190476191e-06,
      "loss": 0.0393,
      "step": 32680
    },
    {
      "epoch": 9.34,
      "grad_norm": 0.007408850826323032,
      "learning_rate": 7.5466666666666675e-06,
      "loss": 0.0,
      "step": 32690
    },
    {
      "epoch": 9.342857142857143,
      "grad_norm": 2.1554033082793467e-05,
      "learning_rate": 7.542857142857144e-06,
      "loss": 0.0,
      "step": 32700
    },
    {
      "epoch": 9.345714285714285,
      "grad_norm": 0.0004965811967849731,
      "learning_rate": 7.5390476190476195e-06,
      "loss": 0.0001,
      "step": 32710
    },
    {
      "epoch": 9.348571428571429,
      "grad_norm": 1.7922755432664417e-05,
      "learning_rate": 7.535238095238095e-06,
      "loss": 0.0,
      "step": 32720
    },
    {
      "epoch": 9.35142857142857,
      "grad_norm": 0.0001570013992022723,
      "learning_rate": 7.5314285714285716e-06,
      "loss": 0.0,
      "step": 32730
    },
    {
      "epoch": 9.354285714285714,
      "grad_norm": 2.2756472390028648e-05,
      "learning_rate": 7.527619047619048e-06,
      "loss": 0.0,
      "step": 32740
    },
    {
      "epoch": 9.357142857142858,
      "grad_norm": 3.135690712952055e-05,
      "learning_rate": 7.523809523809524e-06,
      "loss": 0.0,
      "step": 32750
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.6833064364618622e-05,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.0,
      "step": 32760
    },
    {
      "epoch": 9.362857142857143,
      "grad_norm": 2.488939935574308e-05,
      "learning_rate": 7.516190476190477e-06,
      "loss": 0.0,
      "step": 32770
    },
    {
      "epoch": 9.365714285714287,
      "grad_norm": 0.00023727628285996616,
      "learning_rate": 7.512380952380953e-06,
      "loss": 0.0,
      "step": 32780
    },
    {
      "epoch": 9.368571428571428,
      "grad_norm": 7.143964467104524e-05,
      "learning_rate": 7.508571428571429e-06,
      "loss": 0.0,
      "step": 32790
    },
    {
      "epoch": 9.371428571428572,
      "grad_norm": 3.555077637429349e-05,
      "learning_rate": 7.504761904761906e-06,
      "loss": 0.0,
      "step": 32800
    },
    {
      "epoch": 9.374285714285714,
      "grad_norm": 2.5494038709439337e-05,
      "learning_rate": 7.500952380952382e-06,
      "loss": 0.0,
      "step": 32810
    },
    {
      "epoch": 9.377142857142857,
      "grad_norm": 1.6798752767499536e-05,
      "learning_rate": 7.497142857142857e-06,
      "loss": 0.0,
      "step": 32820
    },
    {
      "epoch": 9.38,
      "grad_norm": 0.0016097017796710134,
      "learning_rate": 7.493333333333333e-06,
      "loss": 0.0,
      "step": 32830
    },
    {
      "epoch": 9.382857142857143,
      "grad_norm": 0.0002983525046147406,
      "learning_rate": 7.48952380952381e-06,
      "loss": 0.0,
      "step": 32840
    },
    {
      "epoch": 9.385714285714286,
      "grad_norm": 7.234051008708775e-05,
      "learning_rate": 7.485714285714286e-06,
      "loss": 0.0,
      "step": 32850
    },
    {
      "epoch": 9.388571428571428,
      "grad_norm": 3.633005326264538e-05,
      "learning_rate": 7.481904761904763e-06,
      "loss": 0.0,
      "step": 32860
    },
    {
      "epoch": 9.391428571428571,
      "grad_norm": 0.00012853555381298065,
      "learning_rate": 7.478095238095239e-06,
      "loss": 0.0,
      "step": 32870
    },
    {
      "epoch": 9.394285714285715,
      "grad_norm": 1.5089464795892127e-05,
      "learning_rate": 7.4742857142857154e-06,
      "loss": 0.0,
      "step": 32880
    },
    {
      "epoch": 9.397142857142857,
      "grad_norm": 6.206750549608842e-05,
      "learning_rate": 7.470476190476191e-06,
      "loss": 0.0,
      "step": 32890
    },
    {
      "epoch": 9.4,
      "grad_norm": 1.9872339180437848e-05,
      "learning_rate": 7.4666666666666675e-06,
      "loss": 0.0,
      "step": 32900
    },
    {
      "epoch": 9.402857142857142,
      "grad_norm": 2.701012090255972e-05,
      "learning_rate": 7.462857142857144e-06,
      "loss": 0.0,
      "step": 32910
    },
    {
      "epoch": 9.405714285714286,
      "grad_norm": 0.47279950976371765,
      "learning_rate": 7.45904761904762e-06,
      "loss": 0.0001,
      "step": 32920
    },
    {
      "epoch": 9.40857142857143,
      "grad_norm": 1.2645855349546764e-05,
      "learning_rate": 7.455238095238095e-06,
      "loss": 0.0,
      "step": 32930
    },
    {
      "epoch": 9.411428571428571,
      "grad_norm": 9.284236875828356e-05,
      "learning_rate": 7.4514285714285715e-06,
      "loss": 0.0,
      "step": 32940
    },
    {
      "epoch": 9.414285714285715,
      "grad_norm": 2.4730032237130217e-05,
      "learning_rate": 7.447619047619048e-06,
      "loss": 0.0,
      "step": 32950
    },
    {
      "epoch": 9.417142857142856,
      "grad_norm": 1.75361055880785e-05,
      "learning_rate": 7.443809523809524e-06,
      "loss": 0.0,
      "step": 32960
    },
    {
      "epoch": 9.42,
      "grad_norm": 7.035497401375324e-05,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.0,
      "step": 32970
    },
    {
      "epoch": 9.422857142857143,
      "grad_norm": 0.0001248471235157922,
      "learning_rate": 7.436190476190477e-06,
      "loss": 0.0,
      "step": 32980
    },
    {
      "epoch": 9.425714285714285,
      "grad_norm": 2.7754897018894553e-05,
      "learning_rate": 7.432380952380953e-06,
      "loss": 0.0,
      "step": 32990
    },
    {
      "epoch": 9.428571428571429,
      "grad_norm": 0.00011945410369662568,
      "learning_rate": 7.428571428571429e-06,
      "loss": 0.0,
      "step": 33000
    },
    {
      "epoch": 9.43142857142857,
      "grad_norm": 3.5201283026253805e-05,
      "learning_rate": 7.424761904761906e-06,
      "loss": 0.0,
      "step": 33010
    },
    {
      "epoch": 9.434285714285714,
      "grad_norm": 1.146078921010485e-05,
      "learning_rate": 7.420952380952382e-06,
      "loss": 0.0,
      "step": 33020
    },
    {
      "epoch": 9.437142857142858,
      "grad_norm": 1.460279236198403e-05,
      "learning_rate": 7.417142857142857e-06,
      "loss": 0.0,
      "step": 33030
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.9783923562499695e-05,
      "learning_rate": 7.413333333333333e-06,
      "loss": 0.0,
      "step": 33040
    },
    {
      "epoch": 9.442857142857143,
      "grad_norm": 1.1962392818531953e-05,
      "learning_rate": 7.40952380952381e-06,
      "loss": 0.0,
      "step": 33050
    },
    {
      "epoch": 9.445714285714285,
      "grad_norm": 5.7155117247020826e-05,
      "learning_rate": 7.405714285714286e-06,
      "loss": 0.0,
      "step": 33060
    },
    {
      "epoch": 9.448571428571428,
      "grad_norm": 1.762581814546138e-05,
      "learning_rate": 7.4019047619047625e-06,
      "loss": 0.0,
      "step": 33070
    },
    {
      "epoch": 9.451428571428572,
      "grad_norm": 2.616637539176736e-05,
      "learning_rate": 7.398095238095239e-06,
      "loss": 0.0,
      "step": 33080
    },
    {
      "epoch": 9.454285714285714,
      "grad_norm": 1.3155861779523548e-05,
      "learning_rate": 7.394285714285715e-06,
      "loss": 0.0,
      "step": 33090
    },
    {
      "epoch": 9.457142857142857,
      "grad_norm": 1.3431152183329687e-05,
      "learning_rate": 7.390476190476191e-06,
      "loss": 0.0,
      "step": 33100
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.1235769306949805e-05,
      "learning_rate": 7.386666666666667e-06,
      "loss": 0.0,
      "step": 33110
    },
    {
      "epoch": 9.462857142857143,
      "grad_norm": 3.430915967328474e-05,
      "learning_rate": 7.382857142857144e-06,
      "loss": 0.0,
      "step": 33120
    },
    {
      "epoch": 9.465714285714286,
      "grad_norm": 1.3566566849476658e-05,
      "learning_rate": 7.37904761904762e-06,
      "loss": 0.0,
      "step": 33130
    },
    {
      "epoch": 9.468571428571428,
      "grad_norm": 1.578801493451465e-05,
      "learning_rate": 7.375238095238095e-06,
      "loss": 0.0,
      "step": 33140
    },
    {
      "epoch": 9.471428571428572,
      "grad_norm": 0.0007008157554082572,
      "learning_rate": 7.371428571428571e-06,
      "loss": 0.0,
      "step": 33150
    },
    {
      "epoch": 9.474285714285715,
      "grad_norm": 1.2614851584658027e-05,
      "learning_rate": 7.367619047619048e-06,
      "loss": 0.0,
      "step": 33160
    },
    {
      "epoch": 9.477142857142857,
      "grad_norm": 1.227019583893707e-05,
      "learning_rate": 7.363809523809524e-06,
      "loss": 0.0,
      "step": 33170
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.4259241652325727e-05,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.0,
      "step": 33180
    },
    {
      "epoch": 9.482857142857142,
      "grad_norm": 3.979328175773844e-05,
      "learning_rate": 7.356190476190477e-06,
      "loss": 0.0,
      "step": 33190
    },
    {
      "epoch": 9.485714285714286,
      "grad_norm": 0.00024381940602324903,
      "learning_rate": 7.352380952380953e-06,
      "loss": 0.0,
      "step": 33200
    },
    {
      "epoch": 9.48857142857143,
      "grad_norm": 8.116166281979531e-05,
      "learning_rate": 7.348571428571429e-06,
      "loss": 0.0,
      "step": 33210
    },
    {
      "epoch": 9.491428571428571,
      "grad_norm": 6.420216232072562e-05,
      "learning_rate": 7.3447619047619056e-06,
      "loss": 0.0,
      "step": 33220
    },
    {
      "epoch": 9.494285714285715,
      "grad_norm": 0.00011629820801317692,
      "learning_rate": 7.340952380952382e-06,
      "loss": 0.0,
      "step": 33230
    },
    {
      "epoch": 9.497142857142856,
      "grad_norm": 4.720423385151662e-05,
      "learning_rate": 7.337142857142858e-06,
      "loss": 0.0,
      "step": 33240
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.6021382180042565e-05,
      "learning_rate": 7.333333333333333e-06,
      "loss": 0.0,
      "step": 33250
    },
    {
      "epoch": 9.502857142857144,
      "grad_norm": 1.129348311224021e-05,
      "learning_rate": 7.3295238095238096e-06,
      "loss": 0.0,
      "step": 33260
    },
    {
      "epoch": 9.505714285714285,
      "grad_norm": 8.682053157826886e-05,
      "learning_rate": 7.325714285714286e-06,
      "loss": 0.0,
      "step": 33270
    },
    {
      "epoch": 9.508571428571429,
      "grad_norm": 1.721875560178887e-05,
      "learning_rate": 7.3219047619047624e-06,
      "loss": 0.0,
      "step": 33280
    },
    {
      "epoch": 9.51142857142857,
      "grad_norm": 6.745387508999556e-05,
      "learning_rate": 7.318095238095239e-06,
      "loss": 0.0,
      "step": 33290
    },
    {
      "epoch": 9.514285714285714,
      "grad_norm": 1.170454743260052e-05,
      "learning_rate": 7.314285714285715e-06,
      "loss": 0.0,
      "step": 33300
    },
    {
      "epoch": 9.517142857142858,
      "grad_norm": 4.185961006442085e-05,
      "learning_rate": 7.310476190476191e-06,
      "loss": 0.0,
      "step": 33310
    },
    {
      "epoch": 9.52,
      "grad_norm": 4.2590014345478266e-05,
      "learning_rate": 7.306666666666667e-06,
      "loss": 0.0,
      "step": 33320
    },
    {
      "epoch": 9.522857142857143,
      "grad_norm": 2.265215152874589e-05,
      "learning_rate": 7.302857142857144e-06,
      "loss": 0.0,
      "step": 33330
    },
    {
      "epoch": 9.525714285714285,
      "grad_norm": 2.008448245760519e-05,
      "learning_rate": 7.29904761904762e-06,
      "loss": 0.0,
      "step": 33340
    },
    {
      "epoch": 9.528571428571428,
      "grad_norm": 5.3022442443761975e-05,
      "learning_rate": 7.295238095238097e-06,
      "loss": 0.0,
      "step": 33350
    },
    {
      "epoch": 9.531428571428572,
      "grad_norm": 1.682517358858604e-05,
      "learning_rate": 7.291428571428571e-06,
      "loss": 0.0,
      "step": 33360
    },
    {
      "epoch": 9.534285714285714,
      "grad_norm": 1.099624660128029e-05,
      "learning_rate": 7.287619047619048e-06,
      "loss": 0.0,
      "step": 33370
    },
    {
      "epoch": 9.537142857142857,
      "grad_norm": 1.3075792594463564e-05,
      "learning_rate": 7.283809523809524e-06,
      "loss": 0.0,
      "step": 33380
    },
    {
      "epoch": 9.54,
      "grad_norm": 3.321112671983428e-05,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.0,
      "step": 33390
    },
    {
      "epoch": 9.542857142857143,
      "grad_norm": 2.865950773411896e-05,
      "learning_rate": 7.276190476190477e-06,
      "loss": 0.3305,
      "step": 33400
    },
    {
      "epoch": 9.545714285714286,
      "grad_norm": 0.0001616003573872149,
      "learning_rate": 7.272380952380953e-06,
      "loss": 0.0,
      "step": 33410
    },
    {
      "epoch": 9.548571428571428,
      "grad_norm": 0.0149606391787529,
      "learning_rate": 7.268571428571429e-06,
      "loss": 0.0,
      "step": 33420
    },
    {
      "epoch": 9.551428571428572,
      "grad_norm": 0.0005314499139785767,
      "learning_rate": 7.2647619047619055e-06,
      "loss": 0.0,
      "step": 33430
    },
    {
      "epoch": 9.554285714285715,
      "grad_norm": 0.0004301292938180268,
      "learning_rate": 7.260952380952382e-06,
      "loss": 0.0,
      "step": 33440
    },
    {
      "epoch": 9.557142857142857,
      "grad_norm": 0.0021311340387910604,
      "learning_rate": 7.257142857142858e-06,
      "loss": 0.0,
      "step": 33450
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.0003819567209575325,
      "learning_rate": 7.253333333333335e-06,
      "loss": 0.0,
      "step": 33460
    },
    {
      "epoch": 9.562857142857142,
      "grad_norm": 0.00010453244613017887,
      "learning_rate": 7.2495238095238095e-06,
      "loss": 0.0,
      "step": 33470
    },
    {
      "epoch": 9.565714285714286,
      "grad_norm": 0.0007379045127891004,
      "learning_rate": 7.245714285714286e-06,
      "loss": 0.0,
      "step": 33480
    },
    {
      "epoch": 9.56857142857143,
      "grad_norm": 7.975990592967719e-05,
      "learning_rate": 7.241904761904762e-06,
      "loss": 0.0,
      "step": 33490
    },
    {
      "epoch": 9.571428571428571,
      "grad_norm": 0.0005300368065945804,
      "learning_rate": 7.238095238095239e-06,
      "loss": 0.0,
      "step": 33500
    },
    {
      "epoch": 9.574285714285715,
      "grad_norm": 0.00039307717815972865,
      "learning_rate": 7.234285714285715e-06,
      "loss": 0.0,
      "step": 33510
    },
    {
      "epoch": 9.577142857142857,
      "grad_norm": 0.0003597452596295625,
      "learning_rate": 7.230476190476191e-06,
      "loss": 0.0,
      "step": 33520
    },
    {
      "epoch": 9.58,
      "grad_norm": 0.0003365613520145416,
      "learning_rate": 7.226666666666667e-06,
      "loss": 0.0,
      "step": 33530
    },
    {
      "epoch": 9.582857142857144,
      "grad_norm": 0.00016025625518523157,
      "learning_rate": 7.222857142857144e-06,
      "loss": 0.0,
      "step": 33540
    },
    {
      "epoch": 9.585714285714285,
      "grad_norm": 0.00012566716759465635,
      "learning_rate": 7.21904761904762e-06,
      "loss": 0.0,
      "step": 33550
    },
    {
      "epoch": 9.588571428571429,
      "grad_norm": 0.00025910494150593877,
      "learning_rate": 7.2152380952380965e-06,
      "loss": 0.0001,
      "step": 33560
    },
    {
      "epoch": 9.59142857142857,
      "grad_norm": 0.0005206096102483571,
      "learning_rate": 7.211428571428573e-06,
      "loss": 0.0,
      "step": 33570
    },
    {
      "epoch": 9.594285714285714,
      "grad_norm": 0.000203106232220307,
      "learning_rate": 7.207619047619048e-06,
      "loss": 0.0,
      "step": 33580
    },
    {
      "epoch": 9.597142857142858,
      "grad_norm": 0.00024119541922118515,
      "learning_rate": 7.203809523809524e-06,
      "loss": 0.0,
      "step": 33590
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.00032651290530338883,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0,
      "step": 33600
    },
    {
      "epoch": 9.602857142857143,
      "grad_norm": 7.375510176643729e-05,
      "learning_rate": 7.196190476190477e-06,
      "loss": 0.0,
      "step": 33610
    },
    {
      "epoch": 9.605714285714285,
      "grad_norm": 6.870986544527113e-05,
      "learning_rate": 7.1923809523809525e-06,
      "loss": 0.0,
      "step": 33620
    },
    {
      "epoch": 9.608571428571429,
      "grad_norm": 0.0008603426977060735,
      "learning_rate": 7.188571428571429e-06,
      "loss": 0.0,
      "step": 33630
    },
    {
      "epoch": 9.611428571428572,
      "grad_norm": 0.0017875301418825984,
      "learning_rate": 7.184761904761905e-06,
      "loss": 0.0,
      "step": 33640
    },
    {
      "epoch": 9.614285714285714,
      "grad_norm": 6.048853538231924e-05,
      "learning_rate": 7.180952380952382e-06,
      "loss": 0.0,
      "step": 33650
    },
    {
      "epoch": 9.617142857142857,
      "grad_norm": 0.00032698953873477876,
      "learning_rate": 7.177142857142858e-06,
      "loss": 0.0,
      "step": 33660
    },
    {
      "epoch": 9.62,
      "grad_norm": 0.0003010761283803731,
      "learning_rate": 7.173333333333335e-06,
      "loss": 0.0,
      "step": 33670
    },
    {
      "epoch": 9.622857142857143,
      "grad_norm": 0.0016634806524962187,
      "learning_rate": 7.16952380952381e-06,
      "loss": 0.0,
      "step": 33680
    },
    {
      "epoch": 9.625714285714286,
      "grad_norm": 0.00012333066842984408,
      "learning_rate": 7.165714285714286e-06,
      "loss": 0.0,
      "step": 33690
    },
    {
      "epoch": 9.628571428571428,
      "grad_norm": 8.900176908355206e-05,
      "learning_rate": 7.161904761904762e-06,
      "loss": 0.0,
      "step": 33700
    },
    {
      "epoch": 9.631428571428572,
      "grad_norm": 8.3534701843746e-05,
      "learning_rate": 7.158095238095239e-06,
      "loss": 0.0,
      "step": 33710
    },
    {
      "epoch": 9.634285714285713,
      "grad_norm": 9.298297663917765e-05,
      "learning_rate": 7.154285714285715e-06,
      "loss": 0.0,
      "step": 33720
    },
    {
      "epoch": 9.637142857142857,
      "grad_norm": 8.362921653315425e-05,
      "learning_rate": 7.150476190476191e-06,
      "loss": 0.0,
      "step": 33730
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.00029302629991434515,
      "learning_rate": 7.146666666666667e-06,
      "loss": 0.0,
      "step": 33740
    },
    {
      "epoch": 9.642857142857142,
      "grad_norm": 0.0005293515278026462,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.0,
      "step": 33750
    },
    {
      "epoch": 9.645714285714286,
      "grad_norm": 5.662225521518849e-05,
      "learning_rate": 7.13904761904762e-06,
      "loss": 0.2133,
      "step": 33760
    },
    {
      "epoch": 9.64857142857143,
      "grad_norm": 4.6404114982578903e-05,
      "learning_rate": 7.135238095238096e-06,
      "loss": 0.0,
      "step": 33770
    },
    {
      "epoch": 9.651428571428571,
      "grad_norm": 5.056855297880247e-05,
      "learning_rate": 7.131428571428573e-06,
      "loss": 0.0,
      "step": 33780
    },
    {
      "epoch": 9.654285714285715,
      "grad_norm": 3.653559906524606e-05,
      "learning_rate": 7.127619047619048e-06,
      "loss": 0.0,
      "step": 33790
    },
    {
      "epoch": 9.657142857142857,
      "grad_norm": 9.062024037120864e-05,
      "learning_rate": 7.123809523809524e-06,
      "loss": 0.2501,
      "step": 33800
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.00010414752614451572,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.0,
      "step": 33810
    },
    {
      "epoch": 9.662857142857142,
      "grad_norm": 0.009168323129415512,
      "learning_rate": 7.116190476190477e-06,
      "loss": 0.0,
      "step": 33820
    },
    {
      "epoch": 9.665714285714285,
      "grad_norm": 4.904281013295986e-05,
      "learning_rate": 7.1123809523809525e-06,
      "loss": 0.0,
      "step": 33830
    },
    {
      "epoch": 9.668571428571429,
      "grad_norm": 5.7078850659308955e-05,
      "learning_rate": 7.108571428571429e-06,
      "loss": 0.0,
      "step": 33840
    },
    {
      "epoch": 9.67142857142857,
      "grad_norm": 0.00017064978601410985,
      "learning_rate": 7.104761904761905e-06,
      "loss": 0.0,
      "step": 33850
    },
    {
      "epoch": 9.674285714285714,
      "grad_norm": 4.0189876017393544e-05,
      "learning_rate": 7.100952380952382e-06,
      "loss": 0.0,
      "step": 33860
    },
    {
      "epoch": 9.677142857142858,
      "grad_norm": 0.00012874932144768536,
      "learning_rate": 7.097142857142858e-06,
      "loss": 0.0,
      "step": 33870
    },
    {
      "epoch": 9.68,
      "grad_norm": 5.925920049776323e-05,
      "learning_rate": 7.093333333333335e-06,
      "loss": 0.0,
      "step": 33880
    },
    {
      "epoch": 9.682857142857143,
      "grad_norm": 0.00011501774861244485,
      "learning_rate": 7.08952380952381e-06,
      "loss": 0.0,
      "step": 33890
    },
    {
      "epoch": 9.685714285714285,
      "grad_norm": 3.886058402713388e-05,
      "learning_rate": 7.085714285714286e-06,
      "loss": 0.0,
      "step": 33900
    },
    {
      "epoch": 9.688571428571429,
      "grad_norm": 9.844856685958803e-05,
      "learning_rate": 7.081904761904762e-06,
      "loss": 0.0,
      "step": 33910
    },
    {
      "epoch": 9.691428571428572,
      "grad_norm": 4.433649519341998e-05,
      "learning_rate": 7.078095238095239e-06,
      "loss": 0.0,
      "step": 33920
    },
    {
      "epoch": 9.694285714285714,
      "grad_norm": 7.8686120104976e-05,
      "learning_rate": 7.074285714285715e-06,
      "loss": 0.0,
      "step": 33930
    },
    {
      "epoch": 9.697142857142858,
      "grad_norm": 7.652622298337519e-05,
      "learning_rate": 7.070476190476191e-06,
      "loss": 0.0,
      "step": 33940
    },
    {
      "epoch": 9.7,
      "grad_norm": 8.423967665294185e-05,
      "learning_rate": 7.066666666666667e-06,
      "loss": 0.0,
      "step": 33950
    },
    {
      "epoch": 9.702857142857143,
      "grad_norm": 4.296332917874679e-05,
      "learning_rate": 7.0628571428571435e-06,
      "loss": 0.0,
      "step": 33960
    },
    {
      "epoch": 9.705714285714286,
      "grad_norm": 3.7311765481717885e-05,
      "learning_rate": 7.05904761904762e-06,
      "loss": 0.0,
      "step": 33970
    },
    {
      "epoch": 9.708571428571428,
      "grad_norm": 9.329117892775685e-05,
      "learning_rate": 7.055238095238096e-06,
      "loss": 0.0,
      "step": 33980
    },
    {
      "epoch": 9.711428571428572,
      "grad_norm": 3.9943322917679325e-05,
      "learning_rate": 7.051428571428573e-06,
      "loss": 0.0,
      "step": 33990
    },
    {
      "epoch": 9.714285714285714,
      "grad_norm": 5.805312321172096e-05,
      "learning_rate": 7.047619047619048e-06,
      "loss": 0.0,
      "step": 34000
    },
    {
      "epoch": 9.717142857142857,
      "grad_norm": 5.117510590935126e-05,
      "learning_rate": 7.043809523809524e-06,
      "loss": 0.0,
      "step": 34010
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.00011810196883743629,
      "learning_rate": 7.04e-06,
      "loss": 0.0,
      "step": 34020
    },
    {
      "epoch": 9.722857142857142,
      "grad_norm": 4.188498132862151e-05,
      "learning_rate": 7.036190476190477e-06,
      "loss": 0.0,
      "step": 34030
    },
    {
      "epoch": 9.725714285714286,
      "grad_norm": 5.8037941926158965e-05,
      "learning_rate": 7.032380952380952e-06,
      "loss": 0.0,
      "step": 34040
    },
    {
      "epoch": 9.728571428571428,
      "grad_norm": 4.8435336793772876e-05,
      "learning_rate": 7.028571428571429e-06,
      "loss": 0.0,
      "step": 34050
    },
    {
      "epoch": 9.731428571428571,
      "grad_norm": 2.9572100174846128e-05,
      "learning_rate": 7.024761904761905e-06,
      "loss": 0.0,
      "step": 34060
    },
    {
      "epoch": 9.734285714285715,
      "grad_norm": 3.544495484675281e-05,
      "learning_rate": 7.020952380952382e-06,
      "loss": 0.0,
      "step": 34070
    },
    {
      "epoch": 9.737142857142857,
      "grad_norm": 3.1056322768563405e-05,
      "learning_rate": 7.017142857142858e-06,
      "loss": 0.0,
      "step": 34080
    },
    {
      "epoch": 9.74,
      "grad_norm": 4.635149525711313e-05,
      "learning_rate": 7.0133333333333345e-06,
      "loss": 0.0,
      "step": 34090
    },
    {
      "epoch": 9.742857142857144,
      "grad_norm": 6.149950786493719e-05,
      "learning_rate": 7.00952380952381e-06,
      "loss": 0.0,
      "step": 34100
    },
    {
      "epoch": 9.745714285714286,
      "grad_norm": 0.000148117178468965,
      "learning_rate": 7.0057142857142865e-06,
      "loss": 0.0,
      "step": 34110
    },
    {
      "epoch": 9.748571428571429,
      "grad_norm": 3.552406997187063e-05,
      "learning_rate": 7.001904761904762e-06,
      "loss": 0.0,
      "step": 34120
    },
    {
      "epoch": 9.751428571428571,
      "grad_norm": 3.257533171563409e-05,
      "learning_rate": 6.9980952380952385e-06,
      "loss": 0.1866,
      "step": 34130
    },
    {
      "epoch": 9.754285714285714,
      "grad_norm": 5.47347663086839e-05,
      "learning_rate": 6.994285714285715e-06,
      "loss": 0.0,
      "step": 34140
    },
    {
      "epoch": 9.757142857142856,
      "grad_norm": 8.780105417827144e-05,
      "learning_rate": 6.9904761904761905e-06,
      "loss": 0.2081,
      "step": 34150
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.0037100426852703094,
      "learning_rate": 6.986666666666667e-06,
      "loss": 0.0,
      "step": 34160
    },
    {
      "epoch": 9.762857142857143,
      "grad_norm": 0.00035240931902080774,
      "learning_rate": 6.982857142857143e-06,
      "loss": 0.0,
      "step": 34170
    },
    {
      "epoch": 9.765714285714285,
      "grad_norm": 0.0476868711411953,
      "learning_rate": 6.97904761904762e-06,
      "loss": 0.0,
      "step": 34180
    },
    {
      "epoch": 9.768571428571429,
      "grad_norm": 0.00014176972035784274,
      "learning_rate": 6.975238095238096e-06,
      "loss": 0.0,
      "step": 34190
    },
    {
      "epoch": 9.771428571428572,
      "grad_norm": 0.017539408057928085,
      "learning_rate": 6.971428571428573e-06,
      "loss": 0.0,
      "step": 34200
    },
    {
      "epoch": 9.774285714285714,
      "grad_norm": 0.00010149706940865144,
      "learning_rate": 6.967619047619048e-06,
      "loss": 0.0,
      "step": 34210
    },
    {
      "epoch": 9.777142857142858,
      "grad_norm": 0.0005455333739519119,
      "learning_rate": 6.963809523809525e-06,
      "loss": 0.0,
      "step": 34220
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.00010546855628490448,
      "learning_rate": 6.96e-06,
      "loss": 0.0,
      "step": 34230
    },
    {
      "epoch": 9.782857142857143,
      "grad_norm": 8.192649693228304e-05,
      "learning_rate": 6.956190476190477e-06,
      "loss": 0.0,
      "step": 34240
    },
    {
      "epoch": 9.785714285714286,
      "grad_norm": 9.275761840399355e-05,
      "learning_rate": 6.952380952380952e-06,
      "loss": 0.0,
      "step": 34250
    },
    {
      "epoch": 9.788571428571428,
      "grad_norm": 0.0011967010796070099,
      "learning_rate": 6.948571428571429e-06,
      "loss": 0.0,
      "step": 34260
    },
    {
      "epoch": 9.791428571428572,
      "grad_norm": 7.259332778630778e-05,
      "learning_rate": 6.944761904761905e-06,
      "loss": 0.0,
      "step": 34270
    },
    {
      "epoch": 9.794285714285714,
      "grad_norm": 0.0001884047087514773,
      "learning_rate": 6.9409523809523816e-06,
      "loss": 0.0,
      "step": 34280
    },
    {
      "epoch": 9.797142857142857,
      "grad_norm": 0.0001497389021096751,
      "learning_rate": 6.937142857142858e-06,
      "loss": 0.0,
      "step": 34290
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.00011476317013148218,
      "learning_rate": 6.9333333333333344e-06,
      "loss": 0.0,
      "step": 34300
    },
    {
      "epoch": 9.802857142857142,
      "grad_norm": 0.0009935608832165599,
      "learning_rate": 6.92952380952381e-06,
      "loss": 0.0,
      "step": 34310
    },
    {
      "epoch": 9.805714285714286,
      "grad_norm": 7.906238170107827e-05,
      "learning_rate": 6.9257142857142864e-06,
      "loss": 0.0,
      "step": 34320
    },
    {
      "epoch": 9.808571428571428,
      "grad_norm": 9.164562652586028e-05,
      "learning_rate": 6.921904761904763e-06,
      "loss": 0.0,
      "step": 34330
    },
    {
      "epoch": 9.811428571428571,
      "grad_norm": 0.00011314026778563857,
      "learning_rate": 6.9180952380952385e-06,
      "loss": 0.0,
      "step": 34340
    },
    {
      "epoch": 9.814285714285715,
      "grad_norm": 8.1686295743566e-05,
      "learning_rate": 6.914285714285715e-06,
      "loss": 0.0,
      "step": 34350
    },
    {
      "epoch": 9.817142857142857,
      "grad_norm": 0.00020453165052458644,
      "learning_rate": 6.9104761904761905e-06,
      "loss": 0.0,
      "step": 34360
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.0002789425489027053,
      "learning_rate": 6.906666666666667e-06,
      "loss": 0.0,
      "step": 34370
    },
    {
      "epoch": 9.822857142857142,
      "grad_norm": 6.955512799322605e-05,
      "learning_rate": 6.902857142857143e-06,
      "loss": 0.0,
      "step": 34380
    },
    {
      "epoch": 9.825714285714286,
      "grad_norm": 0.000180256218300201,
      "learning_rate": 6.89904761904762e-06,
      "loss": 0.0,
      "step": 34390
    },
    {
      "epoch": 9.82857142857143,
      "grad_norm": 0.0001272760855499655,
      "learning_rate": 6.895238095238096e-06,
      "loss": 0.0,
      "step": 34400
    },
    {
      "epoch": 9.831428571428571,
      "grad_norm": 9.64611754170619e-05,
      "learning_rate": 6.891428571428573e-06,
      "loss": 0.0,
      "step": 34410
    },
    {
      "epoch": 9.834285714285715,
      "grad_norm": 0.0004881957429461181,
      "learning_rate": 6.887619047619048e-06,
      "loss": 0.0,
      "step": 34420
    },
    {
      "epoch": 9.837142857142858,
      "grad_norm": 8.22064102976583e-05,
      "learning_rate": 6.883809523809525e-06,
      "loss": 0.0,
      "step": 34430
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.0002321810752619058,
      "learning_rate": 6.88e-06,
      "loss": 0.0,
      "step": 34440
    },
    {
      "epoch": 9.842857142857143,
      "grad_norm": 5.757332837674767e-05,
      "learning_rate": 6.876190476190477e-06,
      "loss": 0.0,
      "step": 34450
    },
    {
      "epoch": 9.845714285714285,
      "grad_norm": 0.0005064354627393186,
      "learning_rate": 6.872380952380952e-06,
      "loss": 0.0,
      "step": 34460
    },
    {
      "epoch": 9.848571428571429,
      "grad_norm": 5.0440707127563655e-05,
      "learning_rate": 6.868571428571429e-06,
      "loss": 0.0,
      "step": 34470
    },
    {
      "epoch": 9.85142857142857,
      "grad_norm": 9.523984044790268e-05,
      "learning_rate": 6.864761904761905e-06,
      "loss": 0.0,
      "step": 34480
    },
    {
      "epoch": 9.854285714285714,
      "grad_norm": 5.386489647207782e-05,
      "learning_rate": 6.8609523809523815e-06,
      "loss": 0.0,
      "step": 34490
    },
    {
      "epoch": 9.857142857142858,
      "grad_norm": 0.005364494398236275,
      "learning_rate": 6.857142857142858e-06,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.006671259179711342,
      "learning_rate": 6.853333333333334e-06,
      "loss": 0.0,
      "step": 34510
    },
    {
      "epoch": 9.862857142857143,
      "grad_norm": 6.262374517973512e-05,
      "learning_rate": 6.84952380952381e-06,
      "loss": 0.0,
      "step": 34520
    },
    {
      "epoch": 9.865714285714287,
      "grad_norm": 0.00011000347149092704,
      "learning_rate": 6.845714285714286e-06,
      "loss": 0.0,
      "step": 34530
    },
    {
      "epoch": 9.868571428571428,
      "grad_norm": 5.7900819228962064e-05,
      "learning_rate": 6.841904761904763e-06,
      "loss": 0.0,
      "step": 34540
    },
    {
      "epoch": 9.871428571428572,
      "grad_norm": 5.488814349519089e-05,
      "learning_rate": 6.838095238095238e-06,
      "loss": 0.0,
      "step": 34550
    },
    {
      "epoch": 9.874285714285714,
      "grad_norm": 5.9953057643724605e-05,
      "learning_rate": 6.834285714285715e-06,
      "loss": 0.0,
      "step": 34560
    },
    {
      "epoch": 9.877142857142857,
      "grad_norm": 9.075854904949665e-05,
      "learning_rate": 6.83047619047619e-06,
      "loss": 0.0,
      "step": 34570
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.00026340081240050495,
      "learning_rate": 6.826666666666667e-06,
      "loss": 0.0,
      "step": 34580
    },
    {
      "epoch": 9.882857142857143,
      "grad_norm": 5.057902308180928e-05,
      "learning_rate": 6.822857142857143e-06,
      "loss": 0.0,
      "step": 34590
    },
    {
      "epoch": 9.885714285714286,
      "grad_norm": 0.0010281450813636184,
      "learning_rate": 6.81904761904762e-06,
      "loss": 0.0059,
      "step": 34600
    },
    {
      "epoch": 9.888571428571428,
      "grad_norm": 0.0006243456737138331,
      "learning_rate": 6.815238095238096e-06,
      "loss": 0.0,
      "step": 34610
    },
    {
      "epoch": 9.891428571428571,
      "grad_norm": 0.002484792610630393,
      "learning_rate": 6.8114285714285725e-06,
      "loss": 0.0,
      "step": 34620
    },
    {
      "epoch": 9.894285714285715,
      "grad_norm": 0.0011657290160655975,
      "learning_rate": 6.807619047619048e-06,
      "loss": 0.0,
      "step": 34630
    },
    {
      "epoch": 9.897142857142857,
      "grad_norm": 0.0002378075005253777,
      "learning_rate": 6.8038095238095245e-06,
      "loss": 0.0,
      "step": 34640
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.00012200315541122109,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0,
      "step": 34650
    },
    {
      "epoch": 9.902857142857142,
      "grad_norm": 0.002373212482780218,
      "learning_rate": 6.7961904761904765e-06,
      "loss": 0.0,
      "step": 34660
    },
    {
      "epoch": 9.905714285714286,
      "grad_norm": 0.000627285277005285,
      "learning_rate": 6.792380952380952e-06,
      "loss": 0.0,
      "step": 34670
    },
    {
      "epoch": 9.90857142857143,
      "grad_norm": 0.00034000028972513974,
      "learning_rate": 6.7885714285714286e-06,
      "loss": 0.0,
      "step": 34680
    },
    {
      "epoch": 9.911428571428571,
      "grad_norm": 0.0001054795429809019,
      "learning_rate": 6.784761904761905e-06,
      "loss": 0.0,
      "step": 34690
    },
    {
      "epoch": 9.914285714285715,
      "grad_norm": 0.00011549401824595407,
      "learning_rate": 6.780952380952381e-06,
      "loss": 0.0,
      "step": 34700
    },
    {
      "epoch": 9.917142857142856,
      "grad_norm": 0.0004768934450112283,
      "learning_rate": 6.777142857142858e-06,
      "loss": 0.0,
      "step": 34710
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.00011144720338052139,
      "learning_rate": 6.773333333333334e-06,
      "loss": 0.0,
      "step": 34720
    },
    {
      "epoch": 9.922857142857143,
      "grad_norm": 8.855945634422824e-05,
      "learning_rate": 6.769523809523811e-06,
      "loss": 0.0,
      "step": 34730
    },
    {
      "epoch": 9.925714285714285,
      "grad_norm": 4.1100644011748955e-05,
      "learning_rate": 6.765714285714286e-06,
      "loss": 0.0,
      "step": 34740
    },
    {
      "epoch": 9.928571428571429,
      "grad_norm": 0.00018967152573168278,
      "learning_rate": 6.761904761904763e-06,
      "loss": 0.0,
      "step": 34750
    },
    {
      "epoch": 9.93142857142857,
      "grad_norm": 8.526355668436736e-05,
      "learning_rate": 6.758095238095239e-06,
      "loss": 0.0,
      "step": 34760
    },
    {
      "epoch": 9.934285714285714,
      "grad_norm": 0.0002699146280065179,
      "learning_rate": 6.754285714285715e-06,
      "loss": 0.0,
      "step": 34770
    },
    {
      "epoch": 9.937142857142858,
      "grad_norm": 6.380019476637244e-05,
      "learning_rate": 6.75047619047619e-06,
      "loss": 0.0,
      "step": 34780
    },
    {
      "epoch": 9.94,
      "grad_norm": 4.724038080894388e-05,
      "learning_rate": 6.746666666666667e-06,
      "loss": 0.0,
      "step": 34790
    },
    {
      "epoch": 9.942857142857143,
      "grad_norm": 6.479214789578691e-05,
      "learning_rate": 6.742857142857143e-06,
      "loss": 0.0,
      "step": 34800
    },
    {
      "epoch": 9.945714285714285,
      "grad_norm": 5.227637666394003e-05,
      "learning_rate": 6.73904761904762e-06,
      "loss": 0.0,
      "step": 34810
    },
    {
      "epoch": 9.948571428571428,
      "grad_norm": 0.00020007647981401533,
      "learning_rate": 6.735238095238096e-06,
      "loss": 0.0,
      "step": 34820
    },
    {
      "epoch": 9.951428571428572,
      "grad_norm": 5.032998160459101e-05,
      "learning_rate": 6.7314285714285724e-06,
      "loss": 0.0,
      "step": 34830
    },
    {
      "epoch": 9.954285714285714,
      "grad_norm": 0.0013085237005725503,
      "learning_rate": 6.727619047619048e-06,
      "loss": 0.0,
      "step": 34840
    },
    {
      "epoch": 9.957142857142857,
      "grad_norm": 0.00018094068218488246,
      "learning_rate": 6.7238095238095245e-06,
      "loss": 0.0,
      "step": 34850
    },
    {
      "epoch": 9.96,
      "grad_norm": 6.521979230456054e-05,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.0,
      "step": 34860
    },
    {
      "epoch": 9.962857142857143,
      "grad_norm": 7.235153316287324e-05,
      "learning_rate": 6.716190476190477e-06,
      "loss": 0.0,
      "step": 34870
    },
    {
      "epoch": 9.965714285714286,
      "grad_norm": 9.259557555196807e-05,
      "learning_rate": 6.712380952380952e-06,
      "loss": 0.0,
      "step": 34880
    },
    {
      "epoch": 9.968571428571428,
      "grad_norm": 8.726161468075588e-05,
      "learning_rate": 6.7085714285714285e-06,
      "loss": 0.0,
      "step": 34890
    },
    {
      "epoch": 9.971428571428572,
      "grad_norm": 0.00013731482613366097,
      "learning_rate": 6.704761904761905e-06,
      "loss": 0.0,
      "step": 34900
    },
    {
      "epoch": 9.974285714285715,
      "grad_norm": 5.337532638804987e-05,
      "learning_rate": 6.700952380952381e-06,
      "loss": 0.0,
      "step": 34910
    },
    {
      "epoch": 9.977142857142857,
      "grad_norm": 6.560338078998029e-05,
      "learning_rate": 6.697142857142858e-06,
      "loss": 0.0,
      "step": 34920
    },
    {
      "epoch": 9.98,
      "grad_norm": 6.30064751021564e-05,
      "learning_rate": 6.693333333333334e-06,
      "loss": 0.0,
      "step": 34930
    },
    {
      "epoch": 9.982857142857142,
      "grad_norm": 5.797626363346353e-05,
      "learning_rate": 6.689523809523811e-06,
      "loss": 0.0,
      "step": 34940
    },
    {
      "epoch": 9.985714285714286,
      "grad_norm": 2.8984062737436034e-05,
      "learning_rate": 6.685714285714286e-06,
      "loss": 0.0,
      "step": 34950
    },
    {
      "epoch": 9.98857142857143,
      "grad_norm": 2.9399971026577987e-05,
      "learning_rate": 6.681904761904763e-06,
      "loss": 0.0,
      "step": 34960
    },
    {
      "epoch": 9.991428571428571,
      "grad_norm": 0.00021675392054021358,
      "learning_rate": 6.678095238095239e-06,
      "loss": 0.0,
      "step": 34970
    },
    {
      "epoch": 9.994285714285715,
      "grad_norm": 2.895188663387671e-05,
      "learning_rate": 6.6742857142857155e-06,
      "loss": 0.0,
      "step": 34980
    },
    {
      "epoch": 9.997142857142856,
      "grad_norm": 0.00011846503184642643,
      "learning_rate": 6.67047619047619e-06,
      "loss": 0.0,
      "step": 34990
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.8240818210178986e-05,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0,
      "step": 35000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.984,
      "eval_f1": 0.903225806451613,
      "eval_loss": 0.17836710810661316,
      "eval_precision": 0.9256198347107438,
      "eval_recall": 0.8818897637795275,
      "eval_runtime": 359.2683,
      "eval_samples_per_second": 8.35,
      "eval_steps_per_second": 2.088,
      "step": 35000
    }
  ],
  "logging_steps": 10,
  "max_steps": 52500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.60773695103132e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
