{
  "best_metric": 0.9737584650112867,
  "best_model_checkpoint": "../saved_models/xsrf/checkpoint-14000",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 14000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005,
      "grad_norm": 33.189395904541016,
      "learning_rate": 1.9999000000000003e-05,
      "loss": 1.0388,
      "step": 1
    },
    {
      "epoch": 0.005,
      "grad_norm": 15.17622184753418,
      "learning_rate": 1.9990000000000003e-05,
      "loss": 0.5453,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.63216781616211,
      "learning_rate": 1.9980000000000002e-05,
      "loss": 0.4087,
      "step": 20
    },
    {
      "epoch": 0.015,
      "grad_norm": 12.151107788085938,
      "learning_rate": 1.9970000000000004e-05,
      "loss": 0.4379,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 14.043869018554688,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.4316,
      "step": 40
    },
    {
      "epoch": 0.025,
      "grad_norm": 13.866799354553223,
      "learning_rate": 1.9950000000000004e-05,
      "loss": 0.4231,
      "step": 50
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.980688095092773,
      "learning_rate": 1.9940000000000002e-05,
      "loss": 0.4249,
      "step": 60
    },
    {
      "epoch": 0.035,
      "grad_norm": 11.589059829711914,
      "learning_rate": 1.9930000000000004e-05,
      "loss": 0.3903,
      "step": 70
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.649087905883789,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.4388,
      "step": 80
    },
    {
      "epoch": 0.045,
      "grad_norm": 34.687103271484375,
      "learning_rate": 1.9910000000000004e-05,
      "loss": 0.4158,
      "step": 90
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.936203002929688,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.3664,
      "step": 100
    },
    {
      "epoch": 0.055,
      "grad_norm": 13.802696228027344,
      "learning_rate": 1.989e-05,
      "loss": 0.3808,
      "step": 110
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.511916160583496,
      "learning_rate": 1.9880000000000003e-05,
      "loss": 0.3481,
      "step": 120
    },
    {
      "epoch": 0.065,
      "grad_norm": 11.194314002990723,
      "learning_rate": 1.987e-05,
      "loss": 0.3989,
      "step": 130
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.802613258361816,
      "learning_rate": 1.9860000000000003e-05,
      "loss": 0.376,
      "step": 140
    },
    {
      "epoch": 0.075,
      "grad_norm": 7.947066307067871,
      "learning_rate": 1.985e-05,
      "loss": 0.3417,
      "step": 150
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.986963272094727,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 0.4223,
      "step": 160
    },
    {
      "epoch": 0.085,
      "grad_norm": 7.691741466522217,
      "learning_rate": 1.983e-05,
      "loss": 0.3596,
      "step": 170
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.5230207443237305,
      "learning_rate": 1.982e-05,
      "loss": 0.3469,
      "step": 180
    },
    {
      "epoch": 0.095,
      "grad_norm": 5.577236175537109,
      "learning_rate": 1.9810000000000002e-05,
      "loss": 0.3306,
      "step": 190
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.792284965515137,
      "learning_rate": 1.98e-05,
      "loss": 0.3281,
      "step": 200
    },
    {
      "epoch": 0.105,
      "grad_norm": 6.955507755279541,
      "learning_rate": 1.9790000000000002e-05,
      "loss": 0.3359,
      "step": 210
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.264588832855225,
      "learning_rate": 1.978e-05,
      "loss": 0.2777,
      "step": 220
    },
    {
      "epoch": 0.115,
      "grad_norm": 6.527657508850098,
      "learning_rate": 1.9770000000000002e-05,
      "loss": 0.3338,
      "step": 230
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.4319539070129395,
      "learning_rate": 1.976e-05,
      "loss": 0.2994,
      "step": 240
    },
    {
      "epoch": 0.125,
      "grad_norm": 5.104513645172119,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.3783,
      "step": 250
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.5518622398376465,
      "learning_rate": 1.974e-05,
      "loss": 0.2913,
      "step": 260
    },
    {
      "epoch": 0.135,
      "grad_norm": 6.202030658721924,
      "learning_rate": 1.9730000000000003e-05,
      "loss": 0.3474,
      "step": 270
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.957720756530762,
      "learning_rate": 1.972e-05,
      "loss": 0.2257,
      "step": 280
    },
    {
      "epoch": 0.145,
      "grad_norm": 4.352743148803711,
      "learning_rate": 1.9710000000000003e-05,
      "loss": 0.2583,
      "step": 290
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.732406139373779,
      "learning_rate": 1.97e-05,
      "loss": 0.2813,
      "step": 300
    },
    {
      "epoch": 0.155,
      "grad_norm": 5.801733016967773,
      "learning_rate": 1.9690000000000003e-05,
      "loss": 0.2921,
      "step": 310
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.074483871459961,
      "learning_rate": 1.968e-05,
      "loss": 0.2724,
      "step": 320
    },
    {
      "epoch": 0.165,
      "grad_norm": 9.27838134765625,
      "learning_rate": 1.9670000000000003e-05,
      "loss": 0.2731,
      "step": 330
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.228720188140869,
      "learning_rate": 1.966e-05,
      "loss": 0.2929,
      "step": 340
    },
    {
      "epoch": 0.175,
      "grad_norm": 9.13158130645752,
      "learning_rate": 1.9650000000000003e-05,
      "loss": 0.2516,
      "step": 350
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.119682312011719,
      "learning_rate": 1.9640000000000002e-05,
      "loss": 0.1969,
      "step": 360
    },
    {
      "epoch": 0.185,
      "grad_norm": 8.279934883117676,
      "learning_rate": 1.9630000000000003e-05,
      "loss": 0.2284,
      "step": 370
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.653332710266113,
      "learning_rate": 1.9620000000000002e-05,
      "loss": 0.2795,
      "step": 380
    },
    {
      "epoch": 0.195,
      "grad_norm": 4.5496392250061035,
      "learning_rate": 1.9610000000000004e-05,
      "loss": 0.217,
      "step": 390
    },
    {
      "epoch": 0.2,
      "grad_norm": 6.050220966339111,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.2447,
      "step": 400
    },
    {
      "epoch": 0.205,
      "grad_norm": 7.080542087554932,
      "learning_rate": 1.9590000000000004e-05,
      "loss": 0.232,
      "step": 410
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.64818811416626,
      "learning_rate": 1.9580000000000002e-05,
      "loss": 0.2367,
      "step": 420
    },
    {
      "epoch": 0.215,
      "grad_norm": 5.076964378356934,
      "learning_rate": 1.957e-05,
      "loss": 0.2262,
      "step": 430
    },
    {
      "epoch": 0.22,
      "grad_norm": 9.576979637145996,
      "learning_rate": 1.9560000000000002e-05,
      "loss": 0.1965,
      "step": 440
    },
    {
      "epoch": 0.225,
      "grad_norm": 4.264278411865234,
      "learning_rate": 1.955e-05,
      "loss": 0.2363,
      "step": 450
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.242294788360596,
      "learning_rate": 1.9540000000000003e-05,
      "loss": 0.2424,
      "step": 460
    },
    {
      "epoch": 0.235,
      "grad_norm": 5.494994163513184,
      "learning_rate": 1.953e-05,
      "loss": 0.2225,
      "step": 470
    },
    {
      "epoch": 0.24,
      "grad_norm": 10.553389549255371,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.2348,
      "step": 480
    },
    {
      "epoch": 0.245,
      "grad_norm": 4.689471244812012,
      "learning_rate": 1.951e-05,
      "loss": 0.2115,
      "step": 490
    },
    {
      "epoch": 0.25,
      "grad_norm": 22.233970642089844,
      "learning_rate": 1.95e-05,
      "loss": 0.2129,
      "step": 500
    },
    {
      "epoch": 0.255,
      "grad_norm": 4.995694160461426,
      "learning_rate": 1.949e-05,
      "loss": 0.2358,
      "step": 510
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.955077648162842,
      "learning_rate": 1.948e-05,
      "loss": 0.2369,
      "step": 520
    },
    {
      "epoch": 0.265,
      "grad_norm": 8.161537170410156,
      "learning_rate": 1.947e-05,
      "loss": 0.2088,
      "step": 530
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.844407081604004,
      "learning_rate": 1.946e-05,
      "loss": 0.1858,
      "step": 540
    },
    {
      "epoch": 0.275,
      "grad_norm": 4.287352561950684,
      "learning_rate": 1.9450000000000002e-05,
      "loss": 0.2394,
      "step": 550
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.237886428833008,
      "learning_rate": 1.944e-05,
      "loss": 0.2104,
      "step": 560
    },
    {
      "epoch": 0.285,
      "grad_norm": 4.724242687225342,
      "learning_rate": 1.9430000000000002e-05,
      "loss": 0.2113,
      "step": 570
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.026758193969727,
      "learning_rate": 1.942e-05,
      "loss": 0.1596,
      "step": 580
    },
    {
      "epoch": 0.295,
      "grad_norm": 8.651667594909668,
      "learning_rate": 1.9410000000000002e-05,
      "loss": 0.1586,
      "step": 590
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.023319721221924,
      "learning_rate": 1.94e-05,
      "loss": 0.2032,
      "step": 600
    },
    {
      "epoch": 0.305,
      "grad_norm": 5.160017967224121,
      "learning_rate": 1.9390000000000002e-05,
      "loss": 0.1635,
      "step": 610
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.455517768859863,
      "learning_rate": 1.938e-05,
      "loss": 0.2123,
      "step": 620
    },
    {
      "epoch": 0.315,
      "grad_norm": 3.5124008655548096,
      "learning_rate": 1.9370000000000003e-05,
      "loss": 0.1922,
      "step": 630
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.919220447540283,
      "learning_rate": 1.936e-05,
      "loss": 0.1787,
      "step": 640
    },
    {
      "epoch": 0.325,
      "grad_norm": 5.1089019775390625,
      "learning_rate": 1.9350000000000003e-05,
      "loss": 0.1579,
      "step": 650
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.6361894607543945,
      "learning_rate": 1.934e-05,
      "loss": 0.1489,
      "step": 660
    },
    {
      "epoch": 0.335,
      "grad_norm": 5.856285572052002,
      "learning_rate": 1.9330000000000003e-05,
      "loss": 0.1703,
      "step": 670
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.131976842880249,
      "learning_rate": 1.932e-05,
      "loss": 0.2085,
      "step": 680
    },
    {
      "epoch": 0.345,
      "grad_norm": 5.806479454040527,
      "learning_rate": 1.9310000000000003e-05,
      "loss": 0.1738,
      "step": 690
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.353700637817383,
      "learning_rate": 1.93e-05,
      "loss": 0.1466,
      "step": 700
    },
    {
      "epoch": 0.355,
      "grad_norm": 4.47605562210083,
      "learning_rate": 1.9290000000000003e-05,
      "loss": 0.1758,
      "step": 710
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.448433876037598,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 0.1465,
      "step": 720
    },
    {
      "epoch": 0.365,
      "grad_norm": 11.205039024353027,
      "learning_rate": 1.9270000000000004e-05,
      "loss": 0.1747,
      "step": 730
    },
    {
      "epoch": 0.37,
      "grad_norm": 6.791641712188721,
      "learning_rate": 1.9260000000000002e-05,
      "loss": 0.1451,
      "step": 740
    },
    {
      "epoch": 0.375,
      "grad_norm": 5.647871017456055,
      "learning_rate": 1.925e-05,
      "loss": 0.1678,
      "step": 750
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.139853477478027,
      "learning_rate": 1.9240000000000002e-05,
      "loss": 0.1763,
      "step": 760
    },
    {
      "epoch": 0.385,
      "grad_norm": 10.73344612121582,
      "learning_rate": 1.923e-05,
      "loss": 0.1761,
      "step": 770
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.488953590393066,
      "learning_rate": 1.9220000000000002e-05,
      "loss": 0.1624,
      "step": 780
    },
    {
      "epoch": 0.395,
      "grad_norm": 4.985908508300781,
      "learning_rate": 1.921e-05,
      "loss": 0.1516,
      "step": 790
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.546628952026367,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.1208,
      "step": 800
    },
    {
      "epoch": 0.405,
      "grad_norm": 3.0201034545898438,
      "learning_rate": 1.919e-05,
      "loss": 0.1283,
      "step": 810
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.77490234375,
      "learning_rate": 1.918e-05,
      "loss": 0.1629,
      "step": 820
    },
    {
      "epoch": 0.415,
      "grad_norm": 5.655553817749023,
      "learning_rate": 1.917e-05,
      "loss": 0.1257,
      "step": 830
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.6692986488342285,
      "learning_rate": 1.916e-05,
      "loss": 0.1253,
      "step": 840
    },
    {
      "epoch": 0.425,
      "grad_norm": 2.310102701187134,
      "learning_rate": 1.915e-05,
      "loss": 0.138,
      "step": 850
    },
    {
      "epoch": 0.43,
      "grad_norm": 8.123437881469727,
      "learning_rate": 1.914e-05,
      "loss": 0.1142,
      "step": 860
    },
    {
      "epoch": 0.435,
      "grad_norm": 4.877501010894775,
      "learning_rate": 1.913e-05,
      "loss": 0.1404,
      "step": 870
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.542311668395996,
      "learning_rate": 1.912e-05,
      "loss": 0.145,
      "step": 880
    },
    {
      "epoch": 0.445,
      "grad_norm": 4.515285015106201,
      "learning_rate": 1.911e-05,
      "loss": 0.1538,
      "step": 890
    },
    {
      "epoch": 0.45,
      "grad_norm": 6.78981351852417,
      "learning_rate": 1.91e-05,
      "loss": 0.1353,
      "step": 900
    },
    {
      "epoch": 0.455,
      "grad_norm": 5.570074558258057,
      "learning_rate": 1.9090000000000002e-05,
      "loss": 0.1524,
      "step": 910
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.684476852416992,
      "learning_rate": 1.908e-05,
      "loss": 0.1364,
      "step": 920
    },
    {
      "epoch": 0.465,
      "grad_norm": 4.711646556854248,
      "learning_rate": 1.9070000000000002e-05,
      "loss": 0.129,
      "step": 930
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.632051706314087,
      "learning_rate": 1.906e-05,
      "loss": 0.1815,
      "step": 940
    },
    {
      "epoch": 0.475,
      "grad_norm": 6.828104496002197,
      "learning_rate": 1.9050000000000002e-05,
      "loss": 0.1353,
      "step": 950
    },
    {
      "epoch": 0.48,
      "grad_norm": 10.1553955078125,
      "learning_rate": 1.904e-05,
      "loss": 0.1413,
      "step": 960
    },
    {
      "epoch": 0.485,
      "grad_norm": 7.025338649749756,
      "learning_rate": 1.9030000000000002e-05,
      "loss": 0.1473,
      "step": 970
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.179110527038574,
      "learning_rate": 1.902e-05,
      "loss": 0.1269,
      "step": 980
    },
    {
      "epoch": 0.495,
      "grad_norm": 7.104374408721924,
      "learning_rate": 1.9010000000000003e-05,
      "loss": 0.099,
      "step": 990
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.470987319946289,
      "learning_rate": 1.9e-05,
      "loss": 0.1266,
      "step": 1000
    },
    {
      "epoch": 0.505,
      "grad_norm": 3.819498062133789,
      "learning_rate": 1.8990000000000003e-05,
      "loss": 0.1448,
      "step": 1010
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.55535888671875,
      "learning_rate": 1.898e-05,
      "loss": 0.1178,
      "step": 1020
    },
    {
      "epoch": 0.515,
      "grad_norm": 4.7057785987854,
      "learning_rate": 1.8970000000000003e-05,
      "loss": 0.1356,
      "step": 1030
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.3091769218444824,
      "learning_rate": 1.896e-05,
      "loss": 0.0906,
      "step": 1040
    },
    {
      "epoch": 0.525,
      "grad_norm": 6.1416778564453125,
      "learning_rate": 1.8950000000000003e-05,
      "loss": 0.1323,
      "step": 1050
    },
    {
      "epoch": 0.53,
      "grad_norm": 7.64236307144165,
      "learning_rate": 1.894e-05,
      "loss": 0.1385,
      "step": 1060
    },
    {
      "epoch": 0.535,
      "grad_norm": 2.676051378250122,
      "learning_rate": 1.893e-05,
      "loss": 0.1366,
      "step": 1070
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.6257336139678955,
      "learning_rate": 1.8920000000000002e-05,
      "loss": 0.1014,
      "step": 1080
    },
    {
      "epoch": 0.545,
      "grad_norm": 6.6370768547058105,
      "learning_rate": 1.891e-05,
      "loss": 0.0707,
      "step": 1090
    },
    {
      "epoch": 0.55,
      "grad_norm": 9.946084976196289,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.1138,
      "step": 1100
    },
    {
      "epoch": 0.555,
      "grad_norm": 4.391378879547119,
      "learning_rate": 1.889e-05,
      "loss": 0.1009,
      "step": 1110
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.2444987297058105,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 0.1199,
      "step": 1120
    },
    {
      "epoch": 0.565,
      "grad_norm": 3.2712655067443848,
      "learning_rate": 1.887e-05,
      "loss": 0.1024,
      "step": 1130
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.975417137145996,
      "learning_rate": 1.886e-05,
      "loss": 0.1315,
      "step": 1140
    },
    {
      "epoch": 0.575,
      "grad_norm": 4.565963268280029,
      "learning_rate": 1.885e-05,
      "loss": 0.1029,
      "step": 1150
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.4673614501953125,
      "learning_rate": 1.884e-05,
      "loss": 0.0874,
      "step": 1160
    },
    {
      "epoch": 0.585,
      "grad_norm": 3.8986523151397705,
      "learning_rate": 1.883e-05,
      "loss": 0.073,
      "step": 1170
    },
    {
      "epoch": 0.59,
      "grad_norm": 7.614446640014648,
      "learning_rate": 1.882e-05,
      "loss": 0.113,
      "step": 1180
    },
    {
      "epoch": 0.595,
      "grad_norm": 5.694214820861816,
      "learning_rate": 1.881e-05,
      "loss": 0.0866,
      "step": 1190
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.172399044036865,
      "learning_rate": 1.88e-05,
      "loss": 0.105,
      "step": 1200
    },
    {
      "epoch": 0.605,
      "grad_norm": 0.6016880869865417,
      "learning_rate": 1.879e-05,
      "loss": 0.1005,
      "step": 1210
    },
    {
      "epoch": 0.61,
      "grad_norm": 11.756579399108887,
      "learning_rate": 1.878e-05,
      "loss": 0.117,
      "step": 1220
    },
    {
      "epoch": 0.615,
      "grad_norm": 5.441683769226074,
      "learning_rate": 1.877e-05,
      "loss": 0.1052,
      "step": 1230
    },
    {
      "epoch": 0.62,
      "grad_norm": 6.2819743156433105,
      "learning_rate": 1.876e-05,
      "loss": 0.0712,
      "step": 1240
    },
    {
      "epoch": 0.625,
      "grad_norm": 3.947678565979004,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0959,
      "step": 1250
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.3464925289154053,
      "learning_rate": 1.8740000000000004e-05,
      "loss": 0.1151,
      "step": 1260
    },
    {
      "epoch": 0.635,
      "grad_norm": 2.7214722633361816,
      "learning_rate": 1.8730000000000002e-05,
      "loss": 0.0884,
      "step": 1270
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.395996332168579,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.0812,
      "step": 1280
    },
    {
      "epoch": 0.645,
      "grad_norm": 3.1389412879943848,
      "learning_rate": 1.8710000000000002e-05,
      "loss": 0.1252,
      "step": 1290
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.519835948944092,
      "learning_rate": 1.8700000000000004e-05,
      "loss": 0.0836,
      "step": 1300
    },
    {
      "epoch": 0.655,
      "grad_norm": 5.012815952301025,
      "learning_rate": 1.8690000000000002e-05,
      "loss": 0.1466,
      "step": 1310
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.594688892364502,
      "learning_rate": 1.8680000000000004e-05,
      "loss": 0.1447,
      "step": 1320
    },
    {
      "epoch": 0.665,
      "grad_norm": 3.192474603652954,
      "learning_rate": 1.8670000000000003e-05,
      "loss": 0.0836,
      "step": 1330
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.324442744255066,
      "learning_rate": 1.866e-05,
      "loss": 0.0814,
      "step": 1340
    },
    {
      "epoch": 0.675,
      "grad_norm": 2.628019332885742,
      "learning_rate": 1.8650000000000003e-05,
      "loss": 0.0687,
      "step": 1350
    },
    {
      "epoch": 0.68,
      "grad_norm": 10.025606155395508,
      "learning_rate": 1.864e-05,
      "loss": 0.1608,
      "step": 1360
    },
    {
      "epoch": 0.685,
      "grad_norm": 3.45829176902771,
      "learning_rate": 1.8630000000000003e-05,
      "loss": 0.1158,
      "step": 1370
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.058227062225342,
      "learning_rate": 1.862e-05,
      "loss": 0.0825,
      "step": 1380
    },
    {
      "epoch": 0.695,
      "grad_norm": 6.8699421882629395,
      "learning_rate": 1.8610000000000003e-05,
      "loss": 0.0918,
      "step": 1390
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.8474650382995605,
      "learning_rate": 1.86e-05,
      "loss": 0.0794,
      "step": 1400
    },
    {
      "epoch": 0.705,
      "grad_norm": 6.015077590942383,
      "learning_rate": 1.859e-05,
      "loss": 0.1115,
      "step": 1410
    },
    {
      "epoch": 0.71,
      "grad_norm": 4.083528995513916,
      "learning_rate": 1.858e-05,
      "loss": 0.1016,
      "step": 1420
    },
    {
      "epoch": 0.715,
      "grad_norm": 2.8968331813812256,
      "learning_rate": 1.857e-05,
      "loss": 0.0773,
      "step": 1430
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2394795417785645,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 0.0705,
      "step": 1440
    },
    {
      "epoch": 0.725,
      "grad_norm": 2.9474761486053467,
      "learning_rate": 1.855e-05,
      "loss": 0.0876,
      "step": 1450
    },
    {
      "epoch": 0.73,
      "grad_norm": 10.018799781799316,
      "learning_rate": 1.8540000000000002e-05,
      "loss": 0.0905,
      "step": 1460
    },
    {
      "epoch": 0.735,
      "grad_norm": 6.314431190490723,
      "learning_rate": 1.853e-05,
      "loss": 0.087,
      "step": 1470
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.972264528274536,
      "learning_rate": 1.8520000000000002e-05,
      "loss": 0.0978,
      "step": 1480
    },
    {
      "epoch": 0.745,
      "grad_norm": 3.7875640392303467,
      "learning_rate": 1.851e-05,
      "loss": 0.1154,
      "step": 1490
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9827262163162231,
      "learning_rate": 1.8500000000000002e-05,
      "loss": 0.0756,
      "step": 1500
    },
    {
      "epoch": 0.755,
      "grad_norm": 3.5314674377441406,
      "learning_rate": 1.849e-05,
      "loss": 0.1008,
      "step": 1510
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.271841526031494,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 0.0824,
      "step": 1520
    },
    {
      "epoch": 0.765,
      "grad_norm": 6.170345306396484,
      "learning_rate": 1.847e-05,
      "loss": 0.0744,
      "step": 1530
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.460146427154541,
      "learning_rate": 1.8460000000000003e-05,
      "loss": 0.081,
      "step": 1540
    },
    {
      "epoch": 0.775,
      "grad_norm": 6.5651631355285645,
      "learning_rate": 1.845e-05,
      "loss": 0.0717,
      "step": 1550
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.489360332489014,
      "learning_rate": 1.8440000000000003e-05,
      "loss": 0.1009,
      "step": 1560
    },
    {
      "epoch": 0.785,
      "grad_norm": 1.662988543510437,
      "learning_rate": 1.843e-05,
      "loss": 0.0938,
      "step": 1570
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.60862398147583,
      "learning_rate": 1.8420000000000003e-05,
      "loss": 0.1135,
      "step": 1580
    },
    {
      "epoch": 0.795,
      "grad_norm": 5.1441121101379395,
      "learning_rate": 1.841e-05,
      "loss": 0.078,
      "step": 1590
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.245368957519531,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.0998,
      "step": 1600
    },
    {
      "epoch": 0.805,
      "grad_norm": 0.7515419125556946,
      "learning_rate": 1.8390000000000002e-05,
      "loss": 0.0725,
      "step": 1610
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.4574997425079346,
      "learning_rate": 1.8380000000000004e-05,
      "loss": 0.0952,
      "step": 1620
    },
    {
      "epoch": 0.815,
      "grad_norm": 3.151374101638794,
      "learning_rate": 1.8370000000000002e-05,
      "loss": 0.0801,
      "step": 1630
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.7300378084182739,
      "learning_rate": 1.8360000000000004e-05,
      "loss": 0.0645,
      "step": 1640
    },
    {
      "epoch": 0.825,
      "grad_norm": 5.659191608428955,
      "learning_rate": 1.8350000000000002e-05,
      "loss": 0.0996,
      "step": 1650
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9937341213226318,
      "learning_rate": 1.834e-05,
      "loss": 0.1228,
      "step": 1660
    },
    {
      "epoch": 0.835,
      "grad_norm": 1.1973384618759155,
      "learning_rate": 1.8330000000000002e-05,
      "loss": 0.0919,
      "step": 1670
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.532744884490967,
      "learning_rate": 1.832e-05,
      "loss": 0.0732,
      "step": 1680
    },
    {
      "epoch": 0.845,
      "grad_norm": 4.523127555847168,
      "learning_rate": 1.8310000000000003e-05,
      "loss": 0.0681,
      "step": 1690
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.7257299423217773,
      "learning_rate": 1.83e-05,
      "loss": 0.1326,
      "step": 1700
    },
    {
      "epoch": 0.855,
      "grad_norm": 0.8264597058296204,
      "learning_rate": 1.8290000000000003e-05,
      "loss": 0.1028,
      "step": 1710
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.5367722511291504,
      "learning_rate": 1.828e-05,
      "loss": 0.0844,
      "step": 1720
    },
    {
      "epoch": 0.865,
      "grad_norm": 1.181694507598877,
      "learning_rate": 1.827e-05,
      "loss": 0.0528,
      "step": 1730
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.252857685089111,
      "learning_rate": 1.826e-05,
      "loss": 0.0868,
      "step": 1740
    },
    {
      "epoch": 0.875,
      "grad_norm": 4.537235736846924,
      "learning_rate": 1.825e-05,
      "loss": 0.0922,
      "step": 1750
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.7097809314727783,
      "learning_rate": 1.824e-05,
      "loss": 0.0904,
      "step": 1760
    },
    {
      "epoch": 0.885,
      "grad_norm": 3.7089803218841553,
      "learning_rate": 1.823e-05,
      "loss": 0.0859,
      "step": 1770
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.5298075675964355,
      "learning_rate": 1.8220000000000002e-05,
      "loss": 0.082,
      "step": 1780
    },
    {
      "epoch": 0.895,
      "grad_norm": 2.6763103008270264,
      "learning_rate": 1.821e-05,
      "loss": 0.0735,
      "step": 1790
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.386482834815979,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0402,
      "step": 1800
    },
    {
      "epoch": 0.905,
      "grad_norm": 5.248522758483887,
      "learning_rate": 1.819e-05,
      "loss": 0.102,
      "step": 1810
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.258119821548462,
      "learning_rate": 1.8180000000000002e-05,
      "loss": 0.089,
      "step": 1820
    },
    {
      "epoch": 0.915,
      "grad_norm": 4.447569847106934,
      "learning_rate": 1.817e-05,
      "loss": 0.0735,
      "step": 1830
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2971174716949463,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 0.0894,
      "step": 1840
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.7660033106803894,
      "learning_rate": 1.815e-05,
      "loss": 0.0638,
      "step": 1850
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.142100811004639,
      "learning_rate": 1.8140000000000003e-05,
      "loss": 0.0574,
      "step": 1860
    },
    {
      "epoch": 0.935,
      "grad_norm": 3.588064193725586,
      "learning_rate": 1.813e-05,
      "loss": 0.0744,
      "step": 1870
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.4518887996673584,
      "learning_rate": 1.8120000000000003e-05,
      "loss": 0.1059,
      "step": 1880
    },
    {
      "epoch": 0.945,
      "grad_norm": 7.257094860076904,
      "learning_rate": 1.811e-05,
      "loss": 0.0809,
      "step": 1890
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.072493553161621,
      "learning_rate": 1.8100000000000003e-05,
      "loss": 0.05,
      "step": 1900
    },
    {
      "epoch": 0.955,
      "grad_norm": 2.2249531745910645,
      "learning_rate": 1.809e-05,
      "loss": 0.06,
      "step": 1910
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.0941667556762695,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.0854,
      "step": 1920
    },
    {
      "epoch": 0.965,
      "grad_norm": 4.960235595703125,
      "learning_rate": 1.807e-05,
      "loss": 0.0864,
      "step": 1930
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.005216598510742,
      "learning_rate": 1.8060000000000003e-05,
      "loss": 0.0622,
      "step": 1940
    },
    {
      "epoch": 0.975,
      "grad_norm": 3.014824390411377,
      "learning_rate": 1.805e-05,
      "loss": 0.0725,
      "step": 1950
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.0061795711517334,
      "learning_rate": 1.8040000000000003e-05,
      "loss": 0.0781,
      "step": 1960
    },
    {
      "epoch": 0.985,
      "grad_norm": 2.5962142944335938,
      "learning_rate": 1.8030000000000002e-05,
      "loss": 0.0721,
      "step": 1970
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.638859510421753,
      "learning_rate": 1.802e-05,
      "loss": 0.0708,
      "step": 1980
    },
    {
      "epoch": 0.995,
      "grad_norm": 0.24662253260612488,
      "learning_rate": 1.8010000000000002e-05,
      "loss": 0.0568,
      "step": 1990
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.042381763458252,
      "learning_rate": 1.8e-05,
      "loss": 0.0584,
      "step": 2000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9808197199533255,
      "eval_f1": 0.9253053109911956,
      "eval_loss": 0.059394411742687225,
      "eval_precision": 0.9340596330275229,
      "eval_recall": 0.9167135621834552,
      "eval_runtime": 903.2412,
      "eval_samples_per_second": 30.372,
      "eval_steps_per_second": 0.95,
      "step": 2000
    },
    {
      "epoch": 1.005,
      "grad_norm": 4.661092758178711,
      "learning_rate": 1.7990000000000002e-05,
      "loss": 0.0438,
      "step": 2010
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6551496982574463,
      "learning_rate": 1.798e-05,
      "loss": 0.0588,
      "step": 2020
    },
    {
      "epoch": 1.015,
      "grad_norm": 79.32284545898438,
      "learning_rate": 1.7970000000000002e-05,
      "loss": 0.0728,
      "step": 2030
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.884982109069824,
      "learning_rate": 1.796e-05,
      "loss": 0.044,
      "step": 2040
    },
    {
      "epoch": 1.025,
      "grad_norm": 0.5145539045333862,
      "learning_rate": 1.795e-05,
      "loss": 0.0472,
      "step": 2050
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.2363812923431396,
      "learning_rate": 1.794e-05,
      "loss": 0.0507,
      "step": 2060
    },
    {
      "epoch": 1.035,
      "grad_norm": 1.2279819250106812,
      "learning_rate": 1.793e-05,
      "loss": 0.0821,
      "step": 2070
    },
    {
      "epoch": 1.04,
      "grad_norm": 4.387508869171143,
      "learning_rate": 1.792e-05,
      "loss": 0.0561,
      "step": 2080
    },
    {
      "epoch": 1.045,
      "grad_norm": 2.9326071739196777,
      "learning_rate": 1.791e-05,
      "loss": 0.0883,
      "step": 2090
    },
    {
      "epoch": 1.05,
      "grad_norm": 5.3234333992004395,
      "learning_rate": 1.79e-05,
      "loss": 0.0637,
      "step": 2100
    },
    {
      "epoch": 1.055,
      "grad_norm": 5.626502990722656,
      "learning_rate": 1.789e-05,
      "loss": 0.0893,
      "step": 2110
    },
    {
      "epoch": 1.06,
      "grad_norm": 6.806096076965332,
      "learning_rate": 1.788e-05,
      "loss": 0.0837,
      "step": 2120
    },
    {
      "epoch": 1.065,
      "grad_norm": 0.639436662197113,
      "learning_rate": 1.787e-05,
      "loss": 0.0433,
      "step": 2130
    },
    {
      "epoch": 1.07,
      "grad_norm": 5.117229461669922,
      "learning_rate": 1.7860000000000002e-05,
      "loss": 0.082,
      "step": 2140
    },
    {
      "epoch": 1.075,
      "grad_norm": 5.8099846839904785,
      "learning_rate": 1.785e-05,
      "loss": 0.053,
      "step": 2150
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.7553129196166992,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 0.059,
      "step": 2160
    },
    {
      "epoch": 1.085,
      "grad_norm": 3.2954187393188477,
      "learning_rate": 1.783e-05,
      "loss": 0.0622,
      "step": 2170
    },
    {
      "epoch": 1.09,
      "grad_norm": 12.999591827392578,
      "learning_rate": 1.7820000000000002e-05,
      "loss": 0.0416,
      "step": 2180
    },
    {
      "epoch": 1.095,
      "grad_norm": 0.41489481925964355,
      "learning_rate": 1.781e-05,
      "loss": 0.0373,
      "step": 2190
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.059204339981079,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 0.0533,
      "step": 2200
    },
    {
      "epoch": 1.105,
      "grad_norm": 3.8905582427978516,
      "learning_rate": 1.779e-05,
      "loss": 0.042,
      "step": 2210
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.590199887752533,
      "learning_rate": 1.7780000000000003e-05,
      "loss": 0.024,
      "step": 2220
    },
    {
      "epoch": 1.115,
      "grad_norm": 5.262422561645508,
      "learning_rate": 1.777e-05,
      "loss": 0.0879,
      "step": 2230
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.8889625668525696,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.0632,
      "step": 2240
    },
    {
      "epoch": 1.125,
      "grad_norm": 0.34079745411872864,
      "learning_rate": 1.775e-05,
      "loss": 0.0854,
      "step": 2250
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.6555662155151367,
      "learning_rate": 1.7740000000000003e-05,
      "loss": 0.0434,
      "step": 2260
    },
    {
      "epoch": 1.135,
      "grad_norm": 3.5483474731445312,
      "learning_rate": 1.773e-05,
      "loss": 0.0422,
      "step": 2270
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 3.4534640312194824,
      "learning_rate": 1.7720000000000003e-05,
      "loss": 0.0652,
      "step": 2280
    },
    {
      "epoch": 1.145,
      "grad_norm": 0.5978917479515076,
      "learning_rate": 1.771e-05,
      "loss": 0.0386,
      "step": 2290
    },
    {
      "epoch": 1.15,
      "grad_norm": 15.850556373596191,
      "learning_rate": 1.77e-05,
      "loss": 0.0424,
      "step": 2300
    },
    {
      "epoch": 1.155,
      "grad_norm": 1.1351679563522339,
      "learning_rate": 1.7690000000000002e-05,
      "loss": 0.0693,
      "step": 2310
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.123938798904419,
      "learning_rate": 1.768e-05,
      "loss": 0.0424,
      "step": 2320
    },
    {
      "epoch": 1.165,
      "grad_norm": 0.6943418383598328,
      "learning_rate": 1.7670000000000002e-05,
      "loss": 0.0626,
      "step": 2330
    },
    {
      "epoch": 1.17,
      "grad_norm": 3.168511390686035,
      "learning_rate": 1.766e-05,
      "loss": 0.0437,
      "step": 2340
    },
    {
      "epoch": 1.175,
      "grad_norm": 1.0160231590270996,
      "learning_rate": 1.7650000000000002e-05,
      "loss": 0.0606,
      "step": 2350
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.5002951622009277,
      "learning_rate": 1.764e-05,
      "loss": 0.0468,
      "step": 2360
    },
    {
      "epoch": 1.185,
      "grad_norm": 0.1279882937669754,
      "learning_rate": 1.763e-05,
      "loss": 0.0598,
      "step": 2370
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.2830076217651367,
      "learning_rate": 1.762e-05,
      "loss": 0.0486,
      "step": 2380
    },
    {
      "epoch": 1.195,
      "grad_norm": 5.793625831604004,
      "learning_rate": 1.761e-05,
      "loss": 0.0368,
      "step": 2390
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5371941924095154,
      "learning_rate": 1.76e-05,
      "loss": 0.0473,
      "step": 2400
    },
    {
      "epoch": 1.205,
      "grad_norm": 0.43457645177841187,
      "learning_rate": 1.759e-05,
      "loss": 0.0438,
      "step": 2410
    },
    {
      "epoch": 1.21,
      "grad_norm": 4.220065593719482,
      "learning_rate": 1.758e-05,
      "loss": 0.0769,
      "step": 2420
    },
    {
      "epoch": 1.215,
      "grad_norm": 3.065779447555542,
      "learning_rate": 1.757e-05,
      "loss": 0.0644,
      "step": 2430
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.0939583778381348,
      "learning_rate": 1.756e-05,
      "loss": 0.0605,
      "step": 2440
    },
    {
      "epoch": 1.225,
      "grad_norm": 0.4341627359390259,
      "learning_rate": 1.755e-05,
      "loss": 0.0656,
      "step": 2450
    },
    {
      "epoch": 1.23,
      "grad_norm": 13.314654350280762,
      "learning_rate": 1.754e-05,
      "loss": 0.0694,
      "step": 2460
    },
    {
      "epoch": 1.2349999999999999,
      "grad_norm": 2.337441921234131,
      "learning_rate": 1.753e-05,
      "loss": 0.0555,
      "step": 2470
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.5949950218200684,
      "learning_rate": 1.752e-05,
      "loss": 0.0523,
      "step": 2480
    },
    {
      "epoch": 1.245,
      "grad_norm": 2.4415323734283447,
      "learning_rate": 1.751e-05,
      "loss": 0.0381,
      "step": 2490
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.173409938812256,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.0565,
      "step": 2500
    },
    {
      "epoch": 1.255,
      "grad_norm": 2.875784158706665,
      "learning_rate": 1.7490000000000004e-05,
      "loss": 0.0618,
      "step": 2510
    },
    {
      "epoch": 1.26,
      "grad_norm": 4.400348663330078,
      "learning_rate": 1.7480000000000002e-05,
      "loss": 0.056,
      "step": 2520
    },
    {
      "epoch": 1.2650000000000001,
      "grad_norm": 1.3932429552078247,
      "learning_rate": 1.7470000000000004e-05,
      "loss": 0.0184,
      "step": 2530
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.4811533987522125,
      "learning_rate": 1.7460000000000002e-05,
      "loss": 0.0331,
      "step": 2540
    },
    {
      "epoch": 1.275,
      "grad_norm": 2.7862331867218018,
      "learning_rate": 1.7450000000000004e-05,
      "loss": 0.0493,
      "step": 2550
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.4186768531799316,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.038,
      "step": 2560
    },
    {
      "epoch": 1.285,
      "grad_norm": 3.0923585891723633,
      "learning_rate": 1.743e-05,
      "loss": 0.1,
      "step": 2570
    },
    {
      "epoch": 1.29,
      "grad_norm": 3.561380386352539,
      "learning_rate": 1.7420000000000003e-05,
      "loss": 0.0515,
      "step": 2580
    },
    {
      "epoch": 1.295,
      "grad_norm": 0.7115433812141418,
      "learning_rate": 1.741e-05,
      "loss": 0.0345,
      "step": 2590
    },
    {
      "epoch": 1.3,
      "grad_norm": 6.158931255340576,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.052,
      "step": 2600
    },
    {
      "epoch": 1.305,
      "grad_norm": 5.405604362487793,
      "learning_rate": 1.739e-05,
      "loss": 0.051,
      "step": 2610
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.9344935417175293,
      "learning_rate": 1.7380000000000003e-05,
      "loss": 0.0474,
      "step": 2620
    },
    {
      "epoch": 1.315,
      "grad_norm": 4.65809440612793,
      "learning_rate": 1.737e-05,
      "loss": 0.0334,
      "step": 2630
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.9289458990097046,
      "learning_rate": 1.736e-05,
      "loss": 0.0707,
      "step": 2640
    },
    {
      "epoch": 1.325,
      "grad_norm": 0.19442325830459595,
      "learning_rate": 1.735e-05,
      "loss": 0.0442,
      "step": 2650
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5264521837234497,
      "learning_rate": 1.734e-05,
      "loss": 0.0539,
      "step": 2660
    },
    {
      "epoch": 1.335,
      "grad_norm": 0.1871626377105713,
      "learning_rate": 1.7330000000000002e-05,
      "loss": 0.071,
      "step": 2670
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.5980591773986816,
      "learning_rate": 1.732e-05,
      "loss": 0.0688,
      "step": 2680
    },
    {
      "epoch": 1.345,
      "grad_norm": 1.6182260513305664,
      "learning_rate": 1.7310000000000002e-05,
      "loss": 0.0494,
      "step": 2690
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.703549385070801,
      "learning_rate": 1.73e-05,
      "loss": 0.0521,
      "step": 2700
    },
    {
      "epoch": 1.355,
      "grad_norm": 3.2893447875976562,
      "learning_rate": 1.7290000000000002e-05,
      "loss": 0.0686,
      "step": 2710
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.23879076540470123,
      "learning_rate": 1.728e-05,
      "loss": 0.0449,
      "step": 2720
    },
    {
      "epoch": 1.365,
      "grad_norm": 5.05828857421875,
      "learning_rate": 1.7270000000000002e-05,
      "loss": 0.0478,
      "step": 2730
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.625956118106842,
      "learning_rate": 1.726e-05,
      "loss": 0.0473,
      "step": 2740
    },
    {
      "epoch": 1.375,
      "grad_norm": 1.5827564001083374,
      "learning_rate": 1.7250000000000003e-05,
      "loss": 0.0236,
      "step": 2750
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.1174979209899902,
      "learning_rate": 1.724e-05,
      "loss": 0.0377,
      "step": 2760
    },
    {
      "epoch": 1.385,
      "grad_norm": 0.16273953020572662,
      "learning_rate": 1.7230000000000003e-05,
      "loss": 0.0325,
      "step": 2770
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.14989197254180908,
      "learning_rate": 1.722e-05,
      "loss": 0.0484,
      "step": 2780
    },
    {
      "epoch": 1.395,
      "grad_norm": 8.253617286682129,
      "learning_rate": 1.7210000000000003e-05,
      "loss": 0.0444,
      "step": 2790
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.9515419006347656,
      "learning_rate": 1.72e-05,
      "loss": 0.0634,
      "step": 2800
    },
    {
      "epoch": 1.405,
      "grad_norm": 6.405828475952148,
      "learning_rate": 1.7190000000000003e-05,
      "loss": 0.0551,
      "step": 2810
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.796608805656433,
      "learning_rate": 1.718e-05,
      "loss": 0.0634,
      "step": 2820
    },
    {
      "epoch": 1.415,
      "grad_norm": 6.051104545593262,
      "learning_rate": 1.7170000000000003e-05,
      "loss": 0.0429,
      "step": 2830
    },
    {
      "epoch": 1.42,
      "grad_norm": 3.7109782695770264,
      "learning_rate": 1.7160000000000002e-05,
      "loss": 0.0726,
      "step": 2840
    },
    {
      "epoch": 1.425,
      "grad_norm": 5.6002068519592285,
      "learning_rate": 1.7150000000000004e-05,
      "loss": 0.0352,
      "step": 2850
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.8002647161483765,
      "learning_rate": 1.7140000000000002e-05,
      "loss": 0.0417,
      "step": 2860
    },
    {
      "epoch": 1.435,
      "grad_norm": 8.163612365722656,
      "learning_rate": 1.7130000000000004e-05,
      "loss": 0.0686,
      "step": 2870
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.5905324220657349,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.0691,
      "step": 2880
    },
    {
      "epoch": 1.445,
      "grad_norm": 1.9514472484588623,
      "learning_rate": 1.711e-05,
      "loss": 0.0452,
      "step": 2890
    },
    {
      "epoch": 1.45,
      "grad_norm": 5.551181793212891,
      "learning_rate": 1.7100000000000002e-05,
      "loss": 0.0674,
      "step": 2900
    },
    {
      "epoch": 1.455,
      "grad_norm": 5.427638530731201,
      "learning_rate": 1.709e-05,
      "loss": 0.0598,
      "step": 2910
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.2151824235916138,
      "learning_rate": 1.7080000000000002e-05,
      "loss": 0.0463,
      "step": 2920
    },
    {
      "epoch": 1.465,
      "grad_norm": 3.365894079208374,
      "learning_rate": 1.707e-05,
      "loss": 0.0342,
      "step": 2930
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1897485256195068,
      "learning_rate": 1.7060000000000003e-05,
      "loss": 0.07,
      "step": 2940
    },
    {
      "epoch": 1.475,
      "grad_norm": 2.8251848220825195,
      "learning_rate": 1.705e-05,
      "loss": 0.0434,
      "step": 2950
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.03226173296570778,
      "learning_rate": 1.704e-05,
      "loss": 0.0203,
      "step": 2960
    },
    {
      "epoch": 1.4849999999999999,
      "grad_norm": 1.2293075323104858,
      "learning_rate": 1.703e-05,
      "loss": 0.0749,
      "step": 2970
    },
    {
      "epoch": 1.49,
      "grad_norm": 2.012148857116699,
      "learning_rate": 1.702e-05,
      "loss": 0.0518,
      "step": 2980
    },
    {
      "epoch": 1.495,
      "grad_norm": 3.582261085510254,
      "learning_rate": 1.701e-05,
      "loss": 0.0499,
      "step": 2990
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.335337162017822,
      "learning_rate": 1.7e-05,
      "loss": 0.0667,
      "step": 3000
    },
    {
      "epoch": 1.505,
      "grad_norm": 1.15940260887146,
      "learning_rate": 1.699e-05,
      "loss": 0.0419,
      "step": 3010
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.11851518601179123,
      "learning_rate": 1.698e-05,
      "loss": 0.0531,
      "step": 3020
    },
    {
      "epoch": 1.5150000000000001,
      "grad_norm": 0.21142342686653137,
      "learning_rate": 1.6970000000000002e-05,
      "loss": 0.0685,
      "step": 3030
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.04719614982605,
      "learning_rate": 1.696e-05,
      "loss": 0.0401,
      "step": 3040
    },
    {
      "epoch": 1.525,
      "grad_norm": 0.6690573692321777,
      "learning_rate": 1.6950000000000002e-05,
      "loss": 0.0557,
      "step": 3050
    },
    {
      "epoch": 1.53,
      "grad_norm": 3.787719249725342,
      "learning_rate": 1.694e-05,
      "loss": 0.0503,
      "step": 3060
    },
    {
      "epoch": 1.5350000000000001,
      "grad_norm": 5.089447021484375,
      "learning_rate": 1.6930000000000002e-05,
      "loss": 0.0398,
      "step": 3070
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.798130989074707,
      "learning_rate": 1.692e-05,
      "loss": 0.0514,
      "step": 3080
    },
    {
      "epoch": 1.545,
      "grad_norm": 1.5867338180541992,
      "learning_rate": 1.6910000000000002e-05,
      "loss": 0.0493,
      "step": 3090
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.9567146301269531,
      "learning_rate": 1.69e-05,
      "loss": 0.0597,
      "step": 3100
    },
    {
      "epoch": 1.5550000000000002,
      "grad_norm": 1.7259860038757324,
      "learning_rate": 1.6890000000000003e-05,
      "loss": 0.0404,
      "step": 3110
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.9086713790893555,
      "learning_rate": 1.688e-05,
      "loss": 0.0676,
      "step": 3120
    },
    {
      "epoch": 1.565,
      "grad_norm": 2.1206493377685547,
      "learning_rate": 1.6870000000000003e-05,
      "loss": 0.0441,
      "step": 3130
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 3.2131004333496094,
      "learning_rate": 1.686e-05,
      "loss": 0.0559,
      "step": 3140
    },
    {
      "epoch": 1.575,
      "grad_norm": 2.6772961616516113,
      "learning_rate": 1.6850000000000003e-05,
      "loss": 0.0327,
      "step": 3150
    },
    {
      "epoch": 1.58,
      "grad_norm": 4.134924411773682,
      "learning_rate": 1.684e-05,
      "loss": 0.0355,
      "step": 3160
    },
    {
      "epoch": 1.585,
      "grad_norm": 0.16447089612483978,
      "learning_rate": 1.6830000000000003e-05,
      "loss": 0.0307,
      "step": 3170
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 2.7024872303009033,
      "learning_rate": 1.682e-05,
      "loss": 0.0551,
      "step": 3180
    },
    {
      "epoch": 1.595,
      "grad_norm": 0.5137229561805725,
      "learning_rate": 1.6810000000000003e-05,
      "loss": 0.0418,
      "step": 3190
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.685441493988037,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0442,
      "step": 3200
    },
    {
      "epoch": 1.605,
      "grad_norm": 1.673743724822998,
      "learning_rate": 1.679e-05,
      "loss": 0.0609,
      "step": 3210
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 4.2067999839782715,
      "learning_rate": 1.6780000000000002e-05,
      "loss": 0.0442,
      "step": 3220
    },
    {
      "epoch": 1.615,
      "grad_norm": 7.217648029327393,
      "learning_rate": 1.677e-05,
      "loss": 0.0603,
      "step": 3230
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.196650505065918,
      "learning_rate": 1.6760000000000002e-05,
      "loss": 0.0297,
      "step": 3240
    },
    {
      "epoch": 1.625,
      "grad_norm": 3.523942470550537,
      "learning_rate": 1.675e-05,
      "loss": 0.034,
      "step": 3250
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.8822519779205322,
      "learning_rate": 1.6740000000000002e-05,
      "loss": 0.0909,
      "step": 3260
    },
    {
      "epoch": 1.635,
      "grad_norm": 3.5284316539764404,
      "learning_rate": 1.673e-05,
      "loss": 0.0572,
      "step": 3270
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.7039216160774231,
      "learning_rate": 1.672e-05,
      "loss": 0.0292,
      "step": 3280
    },
    {
      "epoch": 1.645,
      "grad_norm": 3.922484874725342,
      "learning_rate": 1.671e-05,
      "loss": 0.0722,
      "step": 3290
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.95546817779541,
      "learning_rate": 1.67e-05,
      "loss": 0.0546,
      "step": 3300
    },
    {
      "epoch": 1.655,
      "grad_norm": 3.0626325607299805,
      "learning_rate": 1.669e-05,
      "loss": 0.0426,
      "step": 3310
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.6177287101745605,
      "learning_rate": 1.668e-05,
      "loss": 0.0519,
      "step": 3320
    },
    {
      "epoch": 1.665,
      "grad_norm": 1.742645263671875,
      "learning_rate": 1.667e-05,
      "loss": 0.0259,
      "step": 3330
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.4362274408340454,
      "learning_rate": 1.666e-05,
      "loss": 0.045,
      "step": 3340
    },
    {
      "epoch": 1.675,
      "grad_norm": 1.8427151441574097,
      "learning_rate": 1.665e-05,
      "loss": 0.0473,
      "step": 3350
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.20689627528190613,
      "learning_rate": 1.664e-05,
      "loss": 0.0292,
      "step": 3360
    },
    {
      "epoch": 1.685,
      "grad_norm": 0.1549060046672821,
      "learning_rate": 1.6630000000000002e-05,
      "loss": 0.0507,
      "step": 3370
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.48744338750839233,
      "learning_rate": 1.662e-05,
      "loss": 0.0447,
      "step": 3380
    },
    {
      "epoch": 1.6949999999999998,
      "grad_norm": 2.1891584396362305,
      "learning_rate": 1.6610000000000002e-05,
      "loss": 0.0608,
      "step": 3390
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.22542686760425568,
      "learning_rate": 1.66e-05,
      "loss": 0.041,
      "step": 3400
    },
    {
      "epoch": 1.705,
      "grad_norm": 0.6695535182952881,
      "learning_rate": 1.6590000000000002e-05,
      "loss": 0.0507,
      "step": 3410
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.7790734171867371,
      "learning_rate": 1.658e-05,
      "loss": 0.0773,
      "step": 3420
    },
    {
      "epoch": 1.7149999999999999,
      "grad_norm": 0.27772465348243713,
      "learning_rate": 1.6570000000000002e-05,
      "loss": 0.0369,
      "step": 3430
    },
    {
      "epoch": 1.72,
      "grad_norm": 4.680319786071777,
      "learning_rate": 1.656e-05,
      "loss": 0.0302,
      "step": 3440
    },
    {
      "epoch": 1.725,
      "grad_norm": 3.9222826957702637,
      "learning_rate": 1.6550000000000002e-05,
      "loss": 0.0352,
      "step": 3450
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7730019092559814,
      "learning_rate": 1.654e-05,
      "loss": 0.0425,
      "step": 3460
    },
    {
      "epoch": 1.7349999999999999,
      "grad_norm": 0.8723421692848206,
      "learning_rate": 1.6530000000000003e-05,
      "loss": 0.0481,
      "step": 3470
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.8750291466712952,
      "learning_rate": 1.652e-05,
      "loss": 0.0203,
      "step": 3480
    },
    {
      "epoch": 1.745,
      "grad_norm": 2.8629190921783447,
      "learning_rate": 1.6510000000000003e-05,
      "loss": 0.0348,
      "step": 3490
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.9166613817214966,
      "learning_rate": 1.65e-05,
      "loss": 0.0424,
      "step": 3500
    },
    {
      "epoch": 1.755,
      "grad_norm": 13.355779647827148,
      "learning_rate": 1.6490000000000003e-05,
      "loss": 0.0441,
      "step": 3510
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1921381801366806,
      "learning_rate": 1.648e-05,
      "loss": 0.0234,
      "step": 3520
    },
    {
      "epoch": 1.7650000000000001,
      "grad_norm": 0.12691842019557953,
      "learning_rate": 1.647e-05,
      "loss": 0.0169,
      "step": 3530
    },
    {
      "epoch": 1.77,
      "grad_norm": 4.792548656463623,
      "learning_rate": 1.646e-05,
      "loss": 0.0386,
      "step": 3540
    },
    {
      "epoch": 1.775,
      "grad_norm": 2.3393478393554688,
      "learning_rate": 1.645e-05,
      "loss": 0.0558,
      "step": 3550
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1862069368362427,
      "learning_rate": 1.6440000000000002e-05,
      "loss": 0.0556,
      "step": 3560
    },
    {
      "epoch": 1.7850000000000001,
      "grad_norm": 3.9360294342041016,
      "learning_rate": 1.643e-05,
      "loss": 0.0583,
      "step": 3570
    },
    {
      "epoch": 1.79,
      "grad_norm": 2.314180612564087,
      "learning_rate": 1.6420000000000002e-05,
      "loss": 0.0413,
      "step": 3580
    },
    {
      "epoch": 1.795,
      "grad_norm": 3.122324228286743,
      "learning_rate": 1.641e-05,
      "loss": 0.0514,
      "step": 3590
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.1580135822296143,
      "learning_rate": 1.64e-05,
      "loss": 0.0526,
      "step": 3600
    },
    {
      "epoch": 1.8050000000000002,
      "grad_norm": 4.143298149108887,
      "learning_rate": 1.639e-05,
      "loss": 0.0327,
      "step": 3610
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5684937238693237,
      "learning_rate": 1.638e-05,
      "loss": 0.0336,
      "step": 3620
    },
    {
      "epoch": 1.815,
      "grad_norm": 1.6328561305999756,
      "learning_rate": 1.637e-05,
      "loss": 0.0347,
      "step": 3630
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.6185222864151001,
      "learning_rate": 1.636e-05,
      "loss": 0.0389,
      "step": 3640
    },
    {
      "epoch": 1.825,
      "grad_norm": 1.8194594383239746,
      "learning_rate": 1.635e-05,
      "loss": 0.0392,
      "step": 3650
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.3017067909240723,
      "learning_rate": 1.634e-05,
      "loss": 0.0547,
      "step": 3660
    },
    {
      "epoch": 1.835,
      "grad_norm": 4.012589931488037,
      "learning_rate": 1.633e-05,
      "loss": 0.0437,
      "step": 3670
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 7.321303367614746,
      "learning_rate": 1.632e-05,
      "loss": 0.0565,
      "step": 3680
    },
    {
      "epoch": 1.845,
      "grad_norm": 0.7676529288291931,
      "learning_rate": 1.631e-05,
      "loss": 0.0349,
      "step": 3690
    },
    {
      "epoch": 1.85,
      "grad_norm": 4.350497245788574,
      "learning_rate": 1.63e-05,
      "loss": 0.0275,
      "step": 3700
    },
    {
      "epoch": 1.855,
      "grad_norm": 0.5878471732139587,
      "learning_rate": 1.629e-05,
      "loss": 0.0223,
      "step": 3710
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.124228000640869,
      "learning_rate": 1.628e-05,
      "loss": 0.0402,
      "step": 3720
    },
    {
      "epoch": 1.865,
      "grad_norm": 1.0805301666259766,
      "learning_rate": 1.6270000000000002e-05,
      "loss": 0.0259,
      "step": 3730
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.5974286794662476,
      "learning_rate": 1.626e-05,
      "loss": 0.0346,
      "step": 3740
    },
    {
      "epoch": 1.875,
      "grad_norm": 4.6439361572265625,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0429,
      "step": 3750
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.132568836212158,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 0.0386,
      "step": 3760
    },
    {
      "epoch": 1.885,
      "grad_norm": 0.021365273743867874,
      "learning_rate": 1.6230000000000002e-05,
      "loss": 0.0474,
      "step": 3770
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 0.6859809756278992,
      "learning_rate": 1.6220000000000004e-05,
      "loss": 0.0382,
      "step": 3780
    },
    {
      "epoch": 1.895,
      "grad_norm": 1.4698188304901123,
      "learning_rate": 1.6210000000000002e-05,
      "loss": 0.0206,
      "step": 3790
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.212857961654663,
      "learning_rate": 1.62e-05,
      "loss": 0.0696,
      "step": 3800
    },
    {
      "epoch": 1.905,
      "grad_norm": 2.1994388103485107,
      "learning_rate": 1.6190000000000003e-05,
      "loss": 0.0429,
      "step": 3810
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.8678959608078003,
      "learning_rate": 1.618e-05,
      "loss": 0.0277,
      "step": 3820
    },
    {
      "epoch": 1.915,
      "grad_norm": 3.7839560508728027,
      "learning_rate": 1.6170000000000003e-05,
      "loss": 0.0452,
      "step": 3830
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.386078119277954,
      "learning_rate": 1.616e-05,
      "loss": 0.0195,
      "step": 3840
    },
    {
      "epoch": 1.925,
      "grad_norm": 0.5698866844177246,
      "learning_rate": 1.6150000000000003e-05,
      "loss": 0.0375,
      "step": 3850
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 6.09175443649292,
      "learning_rate": 1.614e-05,
      "loss": 0.0378,
      "step": 3860
    },
    {
      "epoch": 1.935,
      "grad_norm": 1.378162145614624,
      "learning_rate": 1.613e-05,
      "loss": 0.0202,
      "step": 3870
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.0022889375686646,
      "learning_rate": 1.612e-05,
      "loss": 0.0314,
      "step": 3880
    },
    {
      "epoch": 1.9449999999999998,
      "grad_norm": 1.5581486225128174,
      "learning_rate": 1.611e-05,
      "loss": 0.024,
      "step": 3890
    },
    {
      "epoch": 1.95,
      "grad_norm": 4.273434162139893,
      "learning_rate": 1.6100000000000002e-05,
      "loss": 0.0355,
      "step": 3900
    },
    {
      "epoch": 1.955,
      "grad_norm": 6.426751136779785,
      "learning_rate": 1.609e-05,
      "loss": 0.041,
      "step": 3910
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.2635568380355835,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.0339,
      "step": 3920
    },
    {
      "epoch": 1.9649999999999999,
      "grad_norm": 1.3160628080368042,
      "learning_rate": 1.607e-05,
      "loss": 0.0273,
      "step": 3930
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.299485206604004,
      "learning_rate": 1.6060000000000002e-05,
      "loss": 0.0411,
      "step": 3940
    },
    {
      "epoch": 1.975,
      "grad_norm": 3.1346254348754883,
      "learning_rate": 1.605e-05,
      "loss": 0.0417,
      "step": 3950
    },
    {
      "epoch": 1.98,
      "grad_norm": 5.020414352416992,
      "learning_rate": 1.6040000000000002e-05,
      "loss": 0.0303,
      "step": 3960
    },
    {
      "epoch": 1.9849999999999999,
      "grad_norm": 0.15708084404468536,
      "learning_rate": 1.603e-05,
      "loss": 0.039,
      "step": 3970
    },
    {
      "epoch": 1.99,
      "grad_norm": 4.220382213592529,
      "learning_rate": 1.6020000000000002e-05,
      "loss": 0.0733,
      "step": 3980
    },
    {
      "epoch": 1.995,
      "grad_norm": 1.88214111328125,
      "learning_rate": 1.601e-05,
      "loss": 0.0299,
      "step": 3990
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.6135669946670532,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0507,
      "step": 4000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9884407817969662,
      "eval_f1": 0.9555462067031272,
      "eval_loss": 0.034219302237033844,
      "eval_precision": 0.9524741403410679,
      "eval_recall": 0.9586381541924592,
      "eval_runtime": 903.0083,
      "eval_samples_per_second": 30.38,
      "eval_steps_per_second": 0.95,
      "step": 4000
    },
    {
      "epoch": 2.005,
      "grad_norm": 2.8049895763397217,
      "learning_rate": 1.599e-05,
      "loss": 0.0295,
      "step": 4010
    },
    {
      "epoch": 2.01,
      "grad_norm": 2.474346876144409,
      "learning_rate": 1.5980000000000003e-05,
      "loss": 0.0198,
      "step": 4020
    },
    {
      "epoch": 2.015,
      "grad_norm": 2.522942066192627,
      "learning_rate": 1.597e-05,
      "loss": 0.0217,
      "step": 4030
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.8236571550369263,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.0281,
      "step": 4040
    },
    {
      "epoch": 2.025,
      "grad_norm": 0.17447274923324585,
      "learning_rate": 1.595e-05,
      "loss": 0.0253,
      "step": 4050
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.4709506034851074,
      "learning_rate": 1.5940000000000003e-05,
      "loss": 0.0191,
      "step": 4060
    },
    {
      "epoch": 2.035,
      "grad_norm": 0.4709603190422058,
      "learning_rate": 1.593e-05,
      "loss": 0.0381,
      "step": 4070
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.9945111274719238,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.0393,
      "step": 4080
    },
    {
      "epoch": 2.045,
      "grad_norm": 0.7549524903297424,
      "learning_rate": 1.5910000000000002e-05,
      "loss": 0.0259,
      "step": 4090
    },
    {
      "epoch": 2.05,
      "grad_norm": 4.171165466308594,
      "learning_rate": 1.5900000000000004e-05,
      "loss": 0.0354,
      "step": 4100
    },
    {
      "epoch": 2.055,
      "grad_norm": 1.376006007194519,
      "learning_rate": 1.5890000000000002e-05,
      "loss": 0.031,
      "step": 4110
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.8956945538520813,
      "learning_rate": 1.588e-05,
      "loss": 0.0263,
      "step": 4120
    },
    {
      "epoch": 2.065,
      "grad_norm": 0.5554711818695068,
      "learning_rate": 1.5870000000000002e-05,
      "loss": 0.0373,
      "step": 4130
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.2338828593492508,
      "learning_rate": 1.586e-05,
      "loss": 0.04,
      "step": 4140
    },
    {
      "epoch": 2.075,
      "grad_norm": 1.1651309728622437,
      "learning_rate": 1.5850000000000002e-05,
      "loss": 0.0273,
      "step": 4150
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.1321961879730225,
      "learning_rate": 1.584e-05,
      "loss": 0.0228,
      "step": 4160
    },
    {
      "epoch": 2.085,
      "grad_norm": 0.34178367257118225,
      "learning_rate": 1.5830000000000003e-05,
      "loss": 0.0452,
      "step": 4170
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.3465135395526886,
      "learning_rate": 1.582e-05,
      "loss": 0.0371,
      "step": 4180
    },
    {
      "epoch": 2.095,
      "grad_norm": 0.22643733024597168,
      "learning_rate": 1.581e-05,
      "loss": 0.0438,
      "step": 4190
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5866169333457947,
      "learning_rate": 1.58e-05,
      "loss": 0.0167,
      "step": 4200
    },
    {
      "epoch": 2.105,
      "grad_norm": 1.7598694562911987,
      "learning_rate": 1.579e-05,
      "loss": 0.0236,
      "step": 4210
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.1016392707824707,
      "learning_rate": 1.578e-05,
      "loss": 0.0391,
      "step": 4220
    },
    {
      "epoch": 2.115,
      "grad_norm": 2.6501588821411133,
      "learning_rate": 1.577e-05,
      "loss": 0.0191,
      "step": 4230
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6350285410881042,
      "learning_rate": 1.576e-05,
      "loss": 0.0458,
      "step": 4240
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.2123464345932007,
      "learning_rate": 1.575e-05,
      "loss": 0.0479,
      "step": 4250
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.9007868766784668,
      "learning_rate": 1.5740000000000002e-05,
      "loss": 0.0308,
      "step": 4260
    },
    {
      "epoch": 2.135,
      "grad_norm": 0.1602959781885147,
      "learning_rate": 1.573e-05,
      "loss": 0.0274,
      "step": 4270
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.7248905897140503,
      "learning_rate": 1.5720000000000002e-05,
      "loss": 0.0678,
      "step": 4280
    },
    {
      "epoch": 2.145,
      "grad_norm": 0.9592407941818237,
      "learning_rate": 1.571e-05,
      "loss": 0.0355,
      "step": 4290
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.5058560371398926,
      "learning_rate": 1.5700000000000002e-05,
      "loss": 0.0185,
      "step": 4300
    },
    {
      "epoch": 2.155,
      "grad_norm": 1.542272686958313,
      "learning_rate": 1.569e-05,
      "loss": 0.0197,
      "step": 4310
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.204360842704773,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 0.0226,
      "step": 4320
    },
    {
      "epoch": 2.165,
      "grad_norm": 1.1394767761230469,
      "learning_rate": 1.567e-05,
      "loss": 0.0354,
      "step": 4330
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.7876713275909424,
      "learning_rate": 1.5660000000000003e-05,
      "loss": 0.032,
      "step": 4340
    },
    {
      "epoch": 2.175,
      "grad_norm": 4.258134365081787,
      "learning_rate": 1.565e-05,
      "loss": 0.0305,
      "step": 4350
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.460517168045044,
      "learning_rate": 1.5640000000000003e-05,
      "loss": 0.0623,
      "step": 4360
    },
    {
      "epoch": 2.185,
      "grad_norm": 0.8141740560531616,
      "learning_rate": 1.563e-05,
      "loss": 0.0449,
      "step": 4370
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.18253298103809357,
      "learning_rate": 1.5620000000000003e-05,
      "loss": 0.0266,
      "step": 4380
    },
    {
      "epoch": 2.195,
      "grad_norm": 1.8415809869766235,
      "learning_rate": 1.561e-05,
      "loss": 0.0218,
      "step": 4390
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.20035171508789062,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0334,
      "step": 4400
    },
    {
      "epoch": 2.205,
      "grad_norm": 3.204805374145508,
      "learning_rate": 1.559e-05,
      "loss": 0.0239,
      "step": 4410
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.23679319024085999,
      "learning_rate": 1.5580000000000003e-05,
      "loss": 0.0477,
      "step": 4420
    },
    {
      "epoch": 2.215,
      "grad_norm": 0.9417625665664673,
      "learning_rate": 1.5570000000000002e-05,
      "loss": 0.0152,
      "step": 4430
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.5539122819900513,
      "learning_rate": 1.556e-05,
      "loss": 0.0304,
      "step": 4440
    },
    {
      "epoch": 2.225,
      "grad_norm": 3.1599504947662354,
      "learning_rate": 1.5550000000000002e-05,
      "loss": 0.019,
      "step": 4450
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.3247780799865723,
      "learning_rate": 1.554e-05,
      "loss": 0.0262,
      "step": 4460
    },
    {
      "epoch": 2.235,
      "grad_norm": 0.20453676581382751,
      "learning_rate": 1.5530000000000002e-05,
      "loss": 0.0162,
      "step": 4470
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.8235785961151123,
      "learning_rate": 1.552e-05,
      "loss": 0.0464,
      "step": 4480
    },
    {
      "epoch": 2.245,
      "grad_norm": 0.5579577088356018,
      "learning_rate": 1.5510000000000002e-05,
      "loss": 0.0097,
      "step": 4490
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.638334035873413,
      "learning_rate": 1.55e-05,
      "loss": 0.0256,
      "step": 4500
    },
    {
      "epoch": 2.255,
      "grad_norm": 8.335195541381836,
      "learning_rate": 1.549e-05,
      "loss": 0.0226,
      "step": 4510
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.030082717537879944,
      "learning_rate": 1.548e-05,
      "loss": 0.0121,
      "step": 4520
    },
    {
      "epoch": 2.265,
      "grad_norm": 0.03621063753962517,
      "learning_rate": 1.547e-05,
      "loss": 0.0407,
      "step": 4530
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.8007471561431885,
      "learning_rate": 1.546e-05,
      "loss": 0.0548,
      "step": 4540
    },
    {
      "epoch": 2.275,
      "grad_norm": 0.5598246455192566,
      "learning_rate": 1.545e-05,
      "loss": 0.0302,
      "step": 4550
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.7066395282745361,
      "learning_rate": 1.544e-05,
      "loss": 0.0281,
      "step": 4560
    },
    {
      "epoch": 2.285,
      "grad_norm": 0.9264969229698181,
      "learning_rate": 1.543e-05,
      "loss": 0.0191,
      "step": 4570
    },
    {
      "epoch": 2.29,
      "grad_norm": 1.1998639106750488,
      "learning_rate": 1.542e-05,
      "loss": 0.0243,
      "step": 4580
    },
    {
      "epoch": 2.295,
      "grad_norm": 0.9149230718612671,
      "learning_rate": 1.541e-05,
      "loss": 0.0478,
      "step": 4590
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.8509464263916016,
      "learning_rate": 1.54e-05,
      "loss": 0.032,
      "step": 4600
    },
    {
      "epoch": 2.305,
      "grad_norm": 2.6365673542022705,
      "learning_rate": 1.539e-05,
      "loss": 0.0289,
      "step": 4610
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.133084535598755,
      "learning_rate": 1.5380000000000002e-05,
      "loss": 0.0364,
      "step": 4620
    },
    {
      "epoch": 2.315,
      "grad_norm": 0.13891249895095825,
      "learning_rate": 1.537e-05,
      "loss": 0.0211,
      "step": 4630
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.28946176171302795,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 0.0406,
      "step": 4640
    },
    {
      "epoch": 2.325,
      "grad_norm": 1.6330000162124634,
      "learning_rate": 1.535e-05,
      "loss": 0.0224,
      "step": 4650
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.837576389312744,
      "learning_rate": 1.5340000000000002e-05,
      "loss": 0.0318,
      "step": 4660
    },
    {
      "epoch": 2.335,
      "grad_norm": 2.784630060195923,
      "learning_rate": 1.533e-05,
      "loss": 0.0347,
      "step": 4670
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.32152727246284485,
      "learning_rate": 1.5320000000000002e-05,
      "loss": 0.0254,
      "step": 4680
    },
    {
      "epoch": 2.3449999999999998,
      "grad_norm": 0.04646598547697067,
      "learning_rate": 1.531e-05,
      "loss": 0.0317,
      "step": 4690
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.04193329066038132,
      "learning_rate": 1.5300000000000003e-05,
      "loss": 0.032,
      "step": 4700
    },
    {
      "epoch": 2.355,
      "grad_norm": 2.689194679260254,
      "learning_rate": 1.529e-05,
      "loss": 0.0233,
      "step": 4710
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.009354346431791782,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 0.0193,
      "step": 4720
    },
    {
      "epoch": 2.365,
      "grad_norm": 1.5339857339859009,
      "learning_rate": 1.527e-05,
      "loss": 0.0369,
      "step": 4730
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.7919283509254456,
      "learning_rate": 1.5260000000000003e-05,
      "loss": 0.0177,
      "step": 4740
    },
    {
      "epoch": 2.375,
      "grad_norm": 0.23311015963554382,
      "learning_rate": 1.525e-05,
      "loss": 0.0177,
      "step": 4750
    },
    {
      "epoch": 2.38,
      "grad_norm": 5.377906799316406,
      "learning_rate": 1.5240000000000001e-05,
      "loss": 0.0257,
      "step": 4760
    },
    {
      "epoch": 2.385,
      "grad_norm": 2.810887575149536,
      "learning_rate": 1.523e-05,
      "loss": 0.0423,
      "step": 4770
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.206759452819824,
      "learning_rate": 1.5220000000000002e-05,
      "loss": 0.0293,
      "step": 4780
    },
    {
      "epoch": 2.395,
      "grad_norm": 1.502945065498352,
      "learning_rate": 1.521e-05,
      "loss": 0.0209,
      "step": 4790
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.2971693277359009,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.0236,
      "step": 4800
    },
    {
      "epoch": 2.4050000000000002,
      "grad_norm": 0.07213572412729263,
      "learning_rate": 1.519e-05,
      "loss": 0.0128,
      "step": 4810
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.11756610125303268,
      "learning_rate": 1.5180000000000002e-05,
      "loss": 0.007,
      "step": 4820
    },
    {
      "epoch": 2.415,
      "grad_norm": 6.679184436798096,
      "learning_rate": 1.517e-05,
      "loss": 0.0552,
      "step": 4830
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.9157798290252686,
      "learning_rate": 1.516e-05,
      "loss": 0.0169,
      "step": 4840
    },
    {
      "epoch": 2.425,
      "grad_norm": 0.13058005273342133,
      "learning_rate": 1.515e-05,
      "loss": 0.016,
      "step": 4850
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.0259459018707275,
      "learning_rate": 1.514e-05,
      "loss": 0.0334,
      "step": 4860
    },
    {
      "epoch": 2.435,
      "grad_norm": 2.275686264038086,
      "learning_rate": 1.513e-05,
      "loss": 0.0225,
      "step": 4870
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.8733729720115662,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.0285,
      "step": 4880
    },
    {
      "epoch": 2.445,
      "grad_norm": 1.180922508239746,
      "learning_rate": 1.5110000000000001e-05,
      "loss": 0.0076,
      "step": 4890
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.5664753913879395,
      "learning_rate": 1.5100000000000001e-05,
      "loss": 0.0296,
      "step": 4900
    },
    {
      "epoch": 2.455,
      "grad_norm": 1.6812644004821777,
      "learning_rate": 1.509e-05,
      "loss": 0.0123,
      "step": 4910
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.4881688952445984,
      "learning_rate": 1.5080000000000001e-05,
      "loss": 0.0537,
      "step": 4920
    },
    {
      "epoch": 2.465,
      "grad_norm": 1.6134378910064697,
      "learning_rate": 1.507e-05,
      "loss": 0.0383,
      "step": 4930
    },
    {
      "epoch": 2.4699999999999998,
      "grad_norm": 12.058206558227539,
      "learning_rate": 1.5060000000000001e-05,
      "loss": 0.024,
      "step": 4940
    },
    {
      "epoch": 2.475,
      "grad_norm": 0.023958217352628708,
      "learning_rate": 1.505e-05,
      "loss": 0.0419,
      "step": 4950
    },
    {
      "epoch": 2.48,
      "grad_norm": 4.227871894836426,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.0181,
      "step": 4960
    },
    {
      "epoch": 2.485,
      "grad_norm": 0.041394125670194626,
      "learning_rate": 1.503e-05,
      "loss": 0.0196,
      "step": 4970
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.185760974884033,
      "learning_rate": 1.5020000000000002e-05,
      "loss": 0.0126,
      "step": 4980
    },
    {
      "epoch": 2.495,
      "grad_norm": 3.6676976680755615,
      "learning_rate": 1.501e-05,
      "loss": 0.036,
      "step": 4990
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.3989756107330322,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.059,
      "step": 5000
    },
    {
      "epoch": 2.505,
      "grad_norm": 1.3124786615371704,
      "learning_rate": 1.4990000000000002e-05,
      "loss": 0.0128,
      "step": 5010
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.37117430567741394,
      "learning_rate": 1.498e-05,
      "loss": 0.0235,
      "step": 5020
    },
    {
      "epoch": 2.515,
      "grad_norm": 0.13273847103118896,
      "learning_rate": 1.4970000000000002e-05,
      "loss": 0.0232,
      "step": 5030
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.31951624155044556,
      "learning_rate": 1.496e-05,
      "loss": 0.0322,
      "step": 5040
    },
    {
      "epoch": 2.525,
      "grad_norm": 0.46175405383110046,
      "learning_rate": 1.4950000000000003e-05,
      "loss": 0.0467,
      "step": 5050
    },
    {
      "epoch": 2.5300000000000002,
      "grad_norm": 0.7921607494354248,
      "learning_rate": 1.4940000000000001e-05,
      "loss": 0.035,
      "step": 5060
    },
    {
      "epoch": 2.535,
      "grad_norm": 11.198163032531738,
      "learning_rate": 1.4930000000000003e-05,
      "loss": 0.0244,
      "step": 5070
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.425893783569336,
      "learning_rate": 1.4920000000000001e-05,
      "loss": 0.0373,
      "step": 5080
    },
    {
      "epoch": 2.545,
      "grad_norm": 2.8060247898101807,
      "learning_rate": 1.4910000000000003e-05,
      "loss": 0.0501,
      "step": 5090
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.5881853103637695,
      "learning_rate": 1.4900000000000001e-05,
      "loss": 0.0338,
      "step": 5100
    },
    {
      "epoch": 2.555,
      "grad_norm": 2.768315076828003,
      "learning_rate": 1.4890000000000001e-05,
      "loss": 0.0183,
      "step": 5110
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6263126730918884,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 0.0168,
      "step": 5120
    },
    {
      "epoch": 2.565,
      "grad_norm": 2.8908560276031494,
      "learning_rate": 1.4870000000000002e-05,
      "loss": 0.0422,
      "step": 5130
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.16525404155254364,
      "learning_rate": 1.4860000000000002e-05,
      "loss": 0.0331,
      "step": 5140
    },
    {
      "epoch": 2.575,
      "grad_norm": 0.35356590151786804,
      "learning_rate": 1.4850000000000002e-05,
      "loss": 0.0218,
      "step": 5150
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.7927172183990479,
      "learning_rate": 1.4840000000000002e-05,
      "loss": 0.0171,
      "step": 5160
    },
    {
      "epoch": 2.585,
      "grad_norm": 0.23398925364017487,
      "learning_rate": 1.4830000000000002e-05,
      "loss": 0.0159,
      "step": 5170
    },
    {
      "epoch": 2.59,
      "grad_norm": 1.1228888034820557,
      "learning_rate": 1.482e-05,
      "loss": 0.0282,
      "step": 5180
    },
    {
      "epoch": 2.5949999999999998,
      "grad_norm": 3.452059745788574,
      "learning_rate": 1.4810000000000002e-05,
      "loss": 0.0362,
      "step": 5190
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.49074915051460266,
      "learning_rate": 1.48e-05,
      "loss": 0.0282,
      "step": 5200
    },
    {
      "epoch": 2.605,
      "grad_norm": 1.1595298051834106,
      "learning_rate": 1.4790000000000002e-05,
      "loss": 0.0482,
      "step": 5210
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.7976784706115723,
      "learning_rate": 1.478e-05,
      "loss": 0.0378,
      "step": 5220
    },
    {
      "epoch": 2.615,
      "grad_norm": 1.7502361536026,
      "learning_rate": 1.4770000000000003e-05,
      "loss": 0.0213,
      "step": 5230
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.8780809640884399,
      "learning_rate": 1.4760000000000001e-05,
      "loss": 0.0347,
      "step": 5240
    },
    {
      "epoch": 2.625,
      "grad_norm": 0.9032683968544006,
      "learning_rate": 1.4750000000000003e-05,
      "loss": 0.0068,
      "step": 5250
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.7605239152908325,
      "learning_rate": 1.4740000000000001e-05,
      "loss": 0.0313,
      "step": 5260
    },
    {
      "epoch": 2.635,
      "grad_norm": 1.5267266035079956,
      "learning_rate": 1.4730000000000001e-05,
      "loss": 0.0247,
      "step": 5270
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7514129877090454,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.0138,
      "step": 5280
    },
    {
      "epoch": 2.645,
      "grad_norm": 1.7479755878448486,
      "learning_rate": 1.4710000000000001e-05,
      "loss": 0.0281,
      "step": 5290
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.5266610383987427,
      "learning_rate": 1.4700000000000002e-05,
      "loss": 0.0218,
      "step": 5300
    },
    {
      "epoch": 2.6550000000000002,
      "grad_norm": 3.600917339324951,
      "learning_rate": 1.4690000000000002e-05,
      "loss": 0.0251,
      "step": 5310
    },
    {
      "epoch": 2.66,
      "grad_norm": 7.127562522888184,
      "learning_rate": 1.4680000000000002e-05,
      "loss": 0.0294,
      "step": 5320
    },
    {
      "epoch": 2.665,
      "grad_norm": 0.7569423913955688,
      "learning_rate": 1.4670000000000002e-05,
      "loss": 0.0453,
      "step": 5330
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.058832261711359024,
      "learning_rate": 1.466e-05,
      "loss": 0.014,
      "step": 5340
    },
    {
      "epoch": 2.675,
      "grad_norm": 1.1607455015182495,
      "learning_rate": 1.4650000000000002e-05,
      "loss": 0.0158,
      "step": 5350
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.5632504820823669,
      "learning_rate": 1.464e-05,
      "loss": 0.0168,
      "step": 5360
    },
    {
      "epoch": 2.685,
      "grad_norm": 0.27417874336242676,
      "learning_rate": 1.4630000000000002e-05,
      "loss": 0.0194,
      "step": 5370
    },
    {
      "epoch": 2.69,
      "grad_norm": 1.2200571298599243,
      "learning_rate": 1.462e-05,
      "loss": 0.0175,
      "step": 5380
    },
    {
      "epoch": 2.695,
      "grad_norm": 0.8105467557907104,
      "learning_rate": 1.4610000000000002e-05,
      "loss": 0.0257,
      "step": 5390
    },
    {
      "epoch": 2.7,
      "grad_norm": 4.285807132720947,
      "learning_rate": 1.46e-05,
      "loss": 0.0384,
      "step": 5400
    },
    {
      "epoch": 2.705,
      "grad_norm": 0.21743199229240417,
      "learning_rate": 1.4590000000000003e-05,
      "loss": 0.0215,
      "step": 5410
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.1543880701065063,
      "learning_rate": 1.4580000000000001e-05,
      "loss": 0.0436,
      "step": 5420
    },
    {
      "epoch": 2.715,
      "grad_norm": 0.048368971794843674,
      "learning_rate": 1.4570000000000001e-05,
      "loss": 0.0131,
      "step": 5430
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.010688337497413158,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.0244,
      "step": 5440
    },
    {
      "epoch": 2.725,
      "grad_norm": 0.01631779409945011,
      "learning_rate": 1.4550000000000001e-05,
      "loss": 0.0268,
      "step": 5450
    },
    {
      "epoch": 2.73,
      "grad_norm": 13.472332954406738,
      "learning_rate": 1.4540000000000001e-05,
      "loss": 0.0262,
      "step": 5460
    },
    {
      "epoch": 2.735,
      "grad_norm": 8.174824714660645,
      "learning_rate": 1.4530000000000001e-05,
      "loss": 0.03,
      "step": 5470
    },
    {
      "epoch": 2.74,
      "grad_norm": 8.657591819763184,
      "learning_rate": 1.4520000000000002e-05,
      "loss": 0.0368,
      "step": 5480
    },
    {
      "epoch": 2.745,
      "grad_norm": 10.251482963562012,
      "learning_rate": 1.4510000000000002e-05,
      "loss": 0.0369,
      "step": 5490
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.8344842791557312,
      "learning_rate": 1.45e-05,
      "loss": 0.0127,
      "step": 5500
    },
    {
      "epoch": 2.755,
      "grad_norm": 4.129466533660889,
      "learning_rate": 1.4490000000000002e-05,
      "loss": 0.0223,
      "step": 5510
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.05610085651278496,
      "learning_rate": 1.448e-05,
      "loss": 0.0214,
      "step": 5520
    },
    {
      "epoch": 2.765,
      "grad_norm": 0.4483017027378082,
      "learning_rate": 1.4470000000000002e-05,
      "loss": 0.0285,
      "step": 5530
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.43778377771377563,
      "learning_rate": 1.446e-05,
      "loss": 0.0283,
      "step": 5540
    },
    {
      "epoch": 2.775,
      "grad_norm": 2.4978978633880615,
      "learning_rate": 1.4450000000000002e-05,
      "loss": 0.0247,
      "step": 5550
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 0.020251115784049034,
      "learning_rate": 1.444e-05,
      "loss": 0.0157,
      "step": 5560
    },
    {
      "epoch": 2.785,
      "grad_norm": 0.07945182174444199,
      "learning_rate": 1.4430000000000002e-05,
      "loss": 0.0328,
      "step": 5570
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.856379270553589,
      "learning_rate": 1.4420000000000001e-05,
      "loss": 0.0208,
      "step": 5580
    },
    {
      "epoch": 2.795,
      "grad_norm": 3.6301815509796143,
      "learning_rate": 1.4410000000000001e-05,
      "loss": 0.031,
      "step": 5590
    },
    {
      "epoch": 2.8,
      "grad_norm": 10.590304374694824,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0354,
      "step": 5600
    },
    {
      "epoch": 2.805,
      "grad_norm": 3.554612636566162,
      "learning_rate": 1.4390000000000001e-05,
      "loss": 0.0056,
      "step": 5610
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.5416917204856873,
      "learning_rate": 1.4380000000000001e-05,
      "loss": 0.0289,
      "step": 5620
    },
    {
      "epoch": 2.815,
      "grad_norm": 0.8076027035713196,
      "learning_rate": 1.4370000000000001e-05,
      "loss": 0.0073,
      "step": 5630
    },
    {
      "epoch": 2.82,
      "grad_norm": 8.68860912322998,
      "learning_rate": 1.4360000000000001e-05,
      "loss": 0.018,
      "step": 5640
    },
    {
      "epoch": 2.825,
      "grad_norm": 1.9938749074935913,
      "learning_rate": 1.4350000000000002e-05,
      "loss": 0.0246,
      "step": 5650
    },
    {
      "epoch": 2.83,
      "grad_norm": 6.172352313995361,
      "learning_rate": 1.434e-05,
      "loss": 0.0347,
      "step": 5660
    },
    {
      "epoch": 2.835,
      "grad_norm": 2.5160977840423584,
      "learning_rate": 1.4330000000000002e-05,
      "loss": 0.042,
      "step": 5670
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.0967544317245483,
      "learning_rate": 1.432e-05,
      "loss": 0.0289,
      "step": 5680
    },
    {
      "epoch": 2.8449999999999998,
      "grad_norm": 4.165370464324951,
      "learning_rate": 1.4310000000000002e-05,
      "loss": 0.0477,
      "step": 5690
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.5674911141395569,
      "learning_rate": 1.43e-05,
      "loss": 0.0107,
      "step": 5700
    },
    {
      "epoch": 2.855,
      "grad_norm": 1.4458335638046265,
      "learning_rate": 1.4290000000000002e-05,
      "loss": 0.0325,
      "step": 5710
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.5696001052856445,
      "learning_rate": 1.428e-05,
      "loss": 0.0219,
      "step": 5720
    },
    {
      "epoch": 2.865,
      "grad_norm": 0.0031758237164467573,
      "learning_rate": 1.4270000000000002e-05,
      "loss": 0.0133,
      "step": 5730
    },
    {
      "epoch": 2.87,
      "grad_norm": 1.4189380407333374,
      "learning_rate": 1.426e-05,
      "loss": 0.0196,
      "step": 5740
    },
    {
      "epoch": 2.875,
      "grad_norm": 5.818718433380127,
      "learning_rate": 1.425e-05,
      "loss": 0.0158,
      "step": 5750
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.7695608139038086,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.046,
      "step": 5760
    },
    {
      "epoch": 2.885,
      "grad_norm": 0.6127173900604248,
      "learning_rate": 1.4230000000000001e-05,
      "loss": 0.0283,
      "step": 5770
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.36024871468544006,
      "learning_rate": 1.4220000000000001e-05,
      "loss": 0.0237,
      "step": 5780
    },
    {
      "epoch": 2.895,
      "grad_norm": 2.0760953426361084,
      "learning_rate": 1.4210000000000001e-05,
      "loss": 0.0204,
      "step": 5790
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.1620869636535645,
      "learning_rate": 1.4200000000000001e-05,
      "loss": 0.0197,
      "step": 5800
    },
    {
      "epoch": 2.9050000000000002,
      "grad_norm": 2.8521008491516113,
      "learning_rate": 1.4190000000000001e-05,
      "loss": 0.0255,
      "step": 5810
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.2595335841178894,
      "learning_rate": 1.418e-05,
      "loss": 0.0331,
      "step": 5820
    },
    {
      "epoch": 2.915,
      "grad_norm": 6.154454231262207,
      "learning_rate": 1.4170000000000002e-05,
      "loss": 0.0191,
      "step": 5830
    },
    {
      "epoch": 2.92,
      "grad_norm": 4.10763692855835,
      "learning_rate": 1.416e-05,
      "loss": 0.0202,
      "step": 5840
    },
    {
      "epoch": 2.925,
      "grad_norm": 0.6131181120872498,
      "learning_rate": 1.4150000000000002e-05,
      "loss": 0.0169,
      "step": 5850
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.10648470371961594,
      "learning_rate": 1.414e-05,
      "loss": 0.0287,
      "step": 5860
    },
    {
      "epoch": 2.935,
      "grad_norm": 1.3371284008026123,
      "learning_rate": 1.4130000000000002e-05,
      "loss": 0.0087,
      "step": 5870
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.021473528817296028,
      "learning_rate": 1.412e-05,
      "loss": 0.0562,
      "step": 5880
    },
    {
      "epoch": 2.945,
      "grad_norm": 0.6622051000595093,
      "learning_rate": 1.4110000000000002e-05,
      "loss": 0.0392,
      "step": 5890
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.1332983821630478,
      "learning_rate": 1.41e-05,
      "loss": 0.0304,
      "step": 5900
    },
    {
      "epoch": 2.955,
      "grad_norm": 0.9085800647735596,
      "learning_rate": 1.409e-05,
      "loss": 0.0306,
      "step": 5910
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.4677220582962036,
      "learning_rate": 1.408e-05,
      "loss": 0.0151,
      "step": 5920
    },
    {
      "epoch": 2.965,
      "grad_norm": 0.7396504282951355,
      "learning_rate": 1.407e-05,
      "loss": 0.033,
      "step": 5930
    },
    {
      "epoch": 2.9699999999999998,
      "grad_norm": 1.860754370689392,
      "learning_rate": 1.4060000000000001e-05,
      "loss": 0.0376,
      "step": 5940
    },
    {
      "epoch": 2.975,
      "grad_norm": 0.8456026315689087,
      "learning_rate": 1.4050000000000001e-05,
      "loss": 0.0127,
      "step": 5950
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.02911611646413803,
      "learning_rate": 1.4040000000000001e-05,
      "loss": 0.0206,
      "step": 5960
    },
    {
      "epoch": 2.985,
      "grad_norm": 0.37692269682884216,
      "learning_rate": 1.4030000000000001e-05,
      "loss": 0.0335,
      "step": 5970
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6505323052406311,
      "learning_rate": 1.402e-05,
      "loss": 0.0189,
      "step": 5980
    },
    {
      "epoch": 2.995,
      "grad_norm": 7.567652225494385,
      "learning_rate": 1.4010000000000001e-05,
      "loss": 0.015,
      "step": 5990
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6691516041755676,
      "learning_rate": 1.4e-05,
      "loss": 0.0305,
      "step": 6000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9896076429404901,
      "eval_f1": 0.9599325179249263,
      "eval_loss": 0.030499214306473732,
      "eval_precision": 0.9592582186007306,
      "eval_recall": 0.9606077658975802,
      "eval_runtime": 911.5425,
      "eval_samples_per_second": 30.095,
      "eval_steps_per_second": 0.941,
      "step": 6000
    },
    {
      "epoch": 3.005,
      "grad_norm": 0.37347516417503357,
      "learning_rate": 1.3990000000000002e-05,
      "loss": 0.0206,
      "step": 6010
    },
    {
      "epoch": 3.01,
      "grad_norm": 5.040404796600342,
      "learning_rate": 1.398e-05,
      "loss": 0.0147,
      "step": 6020
    },
    {
      "epoch": 3.015,
      "grad_norm": 0.7441996335983276,
      "learning_rate": 1.3970000000000002e-05,
      "loss": 0.0182,
      "step": 6030
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.803250253200531,
      "learning_rate": 1.396e-05,
      "loss": 0.0227,
      "step": 6040
    },
    {
      "epoch": 3.025,
      "grad_norm": 0.08389800041913986,
      "learning_rate": 1.3950000000000002e-05,
      "loss": 0.0327,
      "step": 6050
    },
    {
      "epoch": 3.03,
      "grad_norm": 3.7090113162994385,
      "learning_rate": 1.394e-05,
      "loss": 0.0426,
      "step": 6060
    },
    {
      "epoch": 3.035,
      "grad_norm": 1.3879485130310059,
      "learning_rate": 1.393e-05,
      "loss": 0.0136,
      "step": 6070
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.7800817489624023,
      "learning_rate": 1.392e-05,
      "loss": 0.0306,
      "step": 6080
    },
    {
      "epoch": 3.045,
      "grad_norm": 0.35056304931640625,
      "learning_rate": 1.391e-05,
      "loss": 0.019,
      "step": 6090
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.808101236820221,
      "learning_rate": 1.39e-05,
      "loss": 0.0163,
      "step": 6100
    },
    {
      "epoch": 3.055,
      "grad_norm": 8.249258041381836,
      "learning_rate": 1.389e-05,
      "loss": 0.0242,
      "step": 6110
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.11998933553695679,
      "learning_rate": 1.3880000000000001e-05,
      "loss": 0.0266,
      "step": 6120
    },
    {
      "epoch": 3.065,
      "grad_norm": 0.8363417983055115,
      "learning_rate": 1.3870000000000001e-05,
      "loss": 0.0211,
      "step": 6130
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.9963586926460266,
      "learning_rate": 1.386e-05,
      "loss": 0.0141,
      "step": 6140
    },
    {
      "epoch": 3.075,
      "grad_norm": 0.1952146738767624,
      "learning_rate": 1.3850000000000001e-05,
      "loss": 0.027,
      "step": 6150
    },
    {
      "epoch": 3.08,
      "grad_norm": 9.082906723022461,
      "learning_rate": 1.384e-05,
      "loss": 0.0224,
      "step": 6160
    },
    {
      "epoch": 3.085,
      "grad_norm": 0.0038426565006375313,
      "learning_rate": 1.3830000000000001e-05,
      "loss": 0.008,
      "step": 6170
    },
    {
      "epoch": 3.09,
      "grad_norm": 3.0436391830444336,
      "learning_rate": 1.382e-05,
      "loss": 0.009,
      "step": 6180
    },
    {
      "epoch": 3.095,
      "grad_norm": 3.3160789012908936,
      "learning_rate": 1.3810000000000002e-05,
      "loss": 0.0113,
      "step": 6190
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.49472489953041077,
      "learning_rate": 1.38e-05,
      "loss": 0.0126,
      "step": 6200
    },
    {
      "epoch": 3.105,
      "grad_norm": 10.460466384887695,
      "learning_rate": 1.3790000000000002e-05,
      "loss": 0.0231,
      "step": 6210
    },
    {
      "epoch": 3.11,
      "grad_norm": 1.4641494750976562,
      "learning_rate": 1.378e-05,
      "loss": 0.0161,
      "step": 6220
    },
    {
      "epoch": 3.115,
      "grad_norm": 0.3788709044456482,
      "learning_rate": 1.377e-05,
      "loss": 0.0182,
      "step": 6230
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.35589414834976196,
      "learning_rate": 1.376e-05,
      "loss": 0.0195,
      "step": 6240
    },
    {
      "epoch": 3.125,
      "grad_norm": 1.5472654104232788,
      "learning_rate": 1.375e-05,
      "loss": 0.022,
      "step": 6250
    },
    {
      "epoch": 3.13,
      "grad_norm": 1.0222946405410767,
      "learning_rate": 1.3740000000000002e-05,
      "loss": 0.0212,
      "step": 6260
    },
    {
      "epoch": 3.135,
      "grad_norm": 0.4008108973503113,
      "learning_rate": 1.373e-05,
      "loss": 0.0152,
      "step": 6270
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.8205534219741821,
      "learning_rate": 1.3720000000000002e-05,
      "loss": 0.0211,
      "step": 6280
    },
    {
      "epoch": 3.145,
      "grad_norm": 0.36200112104415894,
      "learning_rate": 1.3710000000000001e-05,
      "loss": 0.0287,
      "step": 6290
    },
    {
      "epoch": 3.15,
      "grad_norm": 1.0766719579696655,
      "learning_rate": 1.3700000000000003e-05,
      "loss": 0.0164,
      "step": 6300
    },
    {
      "epoch": 3.155,
      "grad_norm": 18.18117904663086,
      "learning_rate": 1.3690000000000001e-05,
      "loss": 0.0413,
      "step": 6310
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.2482961416244507,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 0.0075,
      "step": 6320
    },
    {
      "epoch": 3.165,
      "grad_norm": 7.516999244689941,
      "learning_rate": 1.3670000000000001e-05,
      "loss": 0.0273,
      "step": 6330
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.23568302392959595,
      "learning_rate": 1.3660000000000001e-05,
      "loss": 0.0191,
      "step": 6340
    },
    {
      "epoch": 3.175,
      "grad_norm": 0.9186577796936035,
      "learning_rate": 1.3650000000000001e-05,
      "loss": 0.0254,
      "step": 6350
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.22502824664115906,
      "learning_rate": 1.3640000000000002e-05,
      "loss": 0.0166,
      "step": 6360
    },
    {
      "epoch": 3.185,
      "grad_norm": 0.04122573509812355,
      "learning_rate": 1.3630000000000002e-05,
      "loss": 0.0069,
      "step": 6370
    },
    {
      "epoch": 3.19,
      "grad_norm": 5.302548408508301,
      "learning_rate": 1.3620000000000002e-05,
      "loss": 0.0259,
      "step": 6380
    },
    {
      "epoch": 3.195,
      "grad_norm": 1.1419341564178467,
      "learning_rate": 1.3610000000000002e-05,
      "loss": 0.0097,
      "step": 6390
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.015887385234236717,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0299,
      "step": 6400
    },
    {
      "epoch": 3.205,
      "grad_norm": 2.575678825378418,
      "learning_rate": 1.359e-05,
      "loss": 0.0415,
      "step": 6410
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.1407890021800995,
      "learning_rate": 1.3580000000000002e-05,
      "loss": 0.0147,
      "step": 6420
    },
    {
      "epoch": 3.215,
      "grad_norm": 0.17924372851848602,
      "learning_rate": 1.357e-05,
      "loss": 0.0192,
      "step": 6430
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.39485594630241394,
      "learning_rate": 1.3560000000000002e-05,
      "loss": 0.0167,
      "step": 6440
    },
    {
      "epoch": 3.225,
      "grad_norm": 0.4332820773124695,
      "learning_rate": 1.355e-05,
      "loss": 0.0269,
      "step": 6450
    },
    {
      "epoch": 3.23,
      "grad_norm": 1.9139223098754883,
      "learning_rate": 1.3540000000000003e-05,
      "loss": 0.0236,
      "step": 6460
    },
    {
      "epoch": 3.235,
      "grad_norm": 0.09020931273698807,
      "learning_rate": 1.3530000000000001e-05,
      "loss": 0.0121,
      "step": 6470
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.4738698899745941,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.01,
      "step": 6480
    },
    {
      "epoch": 3.245,
      "grad_norm": 2.3791399002075195,
      "learning_rate": 1.3510000000000001e-05,
      "loss": 0.0231,
      "step": 6490
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.9605538845062256,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0204,
      "step": 6500
    },
    {
      "epoch": 3.255,
      "grad_norm": 7.885658264160156,
      "learning_rate": 1.3490000000000001e-05,
      "loss": 0.0139,
      "step": 6510
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.8560247421264648,
      "learning_rate": 1.3480000000000001e-05,
      "loss": 0.0111,
      "step": 6520
    },
    {
      "epoch": 3.265,
      "grad_norm": 0.3686034083366394,
      "learning_rate": 1.3470000000000001e-05,
      "loss": 0.0205,
      "step": 6530
    },
    {
      "epoch": 3.27,
      "grad_norm": 7.051418781280518,
      "learning_rate": 1.3460000000000002e-05,
      "loss": 0.0348,
      "step": 6540
    },
    {
      "epoch": 3.275,
      "grad_norm": 3.4385344982147217,
      "learning_rate": 1.3450000000000002e-05,
      "loss": 0.0574,
      "step": 6550
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.29976022243499756,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 0.0458,
      "step": 6560
    },
    {
      "epoch": 3.285,
      "grad_norm": 0.5904648303985596,
      "learning_rate": 1.343e-05,
      "loss": 0.0144,
      "step": 6570
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.049447737634181976,
      "learning_rate": 1.3420000000000002e-05,
      "loss": 0.0269,
      "step": 6580
    },
    {
      "epoch": 3.295,
      "grad_norm": 2.0963294506073,
      "learning_rate": 1.341e-05,
      "loss": 0.0164,
      "step": 6590
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.05905868858098984,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0146,
      "step": 6600
    },
    {
      "epoch": 3.305,
      "grad_norm": 0.11849534511566162,
      "learning_rate": 1.339e-05,
      "loss": 0.0183,
      "step": 6610
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.7109436988830566,
      "learning_rate": 1.3380000000000002e-05,
      "loss": 0.0369,
      "step": 6620
    },
    {
      "epoch": 3.315,
      "grad_norm": 1.4811174869537354,
      "learning_rate": 1.337e-05,
      "loss": 0.044,
      "step": 6630
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.9586947560310364,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 0.0285,
      "step": 6640
    },
    {
      "epoch": 3.325,
      "grad_norm": 1.7147812843322754,
      "learning_rate": 1.3350000000000001e-05,
      "loss": 0.0173,
      "step": 6650
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.10362599790096283,
      "learning_rate": 1.3340000000000001e-05,
      "loss": 0.0172,
      "step": 6660
    },
    {
      "epoch": 3.335,
      "grad_norm": 0.038568269461393356,
      "learning_rate": 1.3330000000000001e-05,
      "loss": 0.0116,
      "step": 6670
    },
    {
      "epoch": 3.34,
      "grad_norm": 6.051451683044434,
      "learning_rate": 1.3320000000000001e-05,
      "loss": 0.056,
      "step": 6680
    },
    {
      "epoch": 3.3449999999999998,
      "grad_norm": 0.029069814831018448,
      "learning_rate": 1.3310000000000001e-05,
      "loss": 0.0146,
      "step": 6690
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.4808191657066345,
      "learning_rate": 1.3300000000000001e-05,
      "loss": 0.025,
      "step": 6700
    },
    {
      "epoch": 3.355,
      "grad_norm": 0.017408963292837143,
      "learning_rate": 1.3290000000000002e-05,
      "loss": 0.0237,
      "step": 6710
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.2968719005584717,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.0179,
      "step": 6720
    },
    {
      "epoch": 3.365,
      "grad_norm": 1.0816246271133423,
      "learning_rate": 1.327e-05,
      "loss": 0.0252,
      "step": 6730
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.02688552439212799,
      "learning_rate": 1.3260000000000002e-05,
      "loss": 0.0188,
      "step": 6740
    },
    {
      "epoch": 3.375,
      "grad_norm": 4.031208515167236,
      "learning_rate": 1.325e-05,
      "loss": 0.0363,
      "step": 6750
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.6541783809661865,
      "learning_rate": 1.3240000000000002e-05,
      "loss": 0.0243,
      "step": 6760
    },
    {
      "epoch": 3.385,
      "grad_norm": 0.6610519289970398,
      "learning_rate": 1.323e-05,
      "loss": 0.019,
      "step": 6770
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.03579622879624367,
      "learning_rate": 1.3220000000000002e-05,
      "loss": 0.0192,
      "step": 6780
    },
    {
      "epoch": 3.395,
      "grad_norm": 1.7588082551956177,
      "learning_rate": 1.321e-05,
      "loss": 0.0155,
      "step": 6790
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.911231517791748,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.0112,
      "step": 6800
    },
    {
      "epoch": 3.4050000000000002,
      "grad_norm": 6.941629886627197,
      "learning_rate": 1.319e-05,
      "loss": 0.0273,
      "step": 6810
    },
    {
      "epoch": 3.41,
      "grad_norm": 9.875760078430176,
      "learning_rate": 1.3180000000000001e-05,
      "loss": 0.0319,
      "step": 6820
    },
    {
      "epoch": 3.415,
      "grad_norm": 3.4711754322052,
      "learning_rate": 1.3170000000000001e-05,
      "loss": 0.0223,
      "step": 6830
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.7424103021621704,
      "learning_rate": 1.3160000000000001e-05,
      "loss": 0.038,
      "step": 6840
    },
    {
      "epoch": 3.425,
      "grad_norm": 2.9504566192626953,
      "learning_rate": 1.3150000000000001e-05,
      "loss": 0.0448,
      "step": 6850
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.05601140484213829,
      "learning_rate": 1.3140000000000001e-05,
      "loss": 0.0158,
      "step": 6860
    },
    {
      "epoch": 3.435,
      "grad_norm": 0.342770516872406,
      "learning_rate": 1.3130000000000001e-05,
      "loss": 0.0284,
      "step": 6870
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.17649991810321808,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.0093,
      "step": 6880
    },
    {
      "epoch": 3.445,
      "grad_norm": 1.464778184890747,
      "learning_rate": 1.311e-05,
      "loss": 0.0163,
      "step": 6890
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.2935406267642975,
      "learning_rate": 1.3100000000000002e-05,
      "loss": 0.0139,
      "step": 6900
    },
    {
      "epoch": 3.455,
      "grad_norm": 0.0856192335486412,
      "learning_rate": 1.309e-05,
      "loss": 0.0103,
      "step": 6910
    },
    {
      "epoch": 3.46,
      "grad_norm": 6.668977737426758,
      "learning_rate": 1.3080000000000002e-05,
      "loss": 0.0335,
      "step": 6920
    },
    {
      "epoch": 3.465,
      "grad_norm": 0.01413900125771761,
      "learning_rate": 1.307e-05,
      "loss": 0.0061,
      "step": 6930
    },
    {
      "epoch": 3.4699999999999998,
      "grad_norm": 0.05818009376525879,
      "learning_rate": 1.3060000000000002e-05,
      "loss": 0.0247,
      "step": 6940
    },
    {
      "epoch": 3.475,
      "grad_norm": 5.844392776489258,
      "learning_rate": 1.305e-05,
      "loss": 0.0271,
      "step": 6950
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.42097267508506775,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.0091,
      "step": 6960
    },
    {
      "epoch": 3.485,
      "grad_norm": 0.3679424822330475,
      "learning_rate": 1.303e-05,
      "loss": 0.0205,
      "step": 6970
    },
    {
      "epoch": 3.49,
      "grad_norm": 2.077453136444092,
      "learning_rate": 1.302e-05,
      "loss": 0.0223,
      "step": 6980
    },
    {
      "epoch": 3.495,
      "grad_norm": 0.31294897198677063,
      "learning_rate": 1.301e-05,
      "loss": 0.0201,
      "step": 6990
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.8564579486846924,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0168,
      "step": 7000
    },
    {
      "epoch": 3.505,
      "grad_norm": 0.017267735674977303,
      "learning_rate": 1.2990000000000001e-05,
      "loss": 0.0066,
      "step": 7010
    },
    {
      "epoch": 3.51,
      "grad_norm": 3.515638589859009,
      "learning_rate": 1.2980000000000001e-05,
      "loss": 0.0292,
      "step": 7020
    },
    {
      "epoch": 3.515,
      "grad_norm": 0.5390595197677612,
      "learning_rate": 1.2970000000000001e-05,
      "loss": 0.0288,
      "step": 7030
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.272750973701477,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 0.0087,
      "step": 7040
    },
    {
      "epoch": 3.525,
      "grad_norm": 1.5029629468917847,
      "learning_rate": 1.295e-05,
      "loss": 0.0091,
      "step": 7050
    },
    {
      "epoch": 3.5300000000000002,
      "grad_norm": 0.19084049761295319,
      "learning_rate": 1.2940000000000001e-05,
      "loss": 0.0145,
      "step": 7060
    },
    {
      "epoch": 3.535,
      "grad_norm": 0.4099666476249695,
      "learning_rate": 1.293e-05,
      "loss": 0.0282,
      "step": 7070
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.699836015701294,
      "learning_rate": 1.2920000000000002e-05,
      "loss": 0.018,
      "step": 7080
    },
    {
      "epoch": 3.545,
      "grad_norm": 4.487478256225586,
      "learning_rate": 1.291e-05,
      "loss": 0.0199,
      "step": 7090
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.13997553288936615,
      "learning_rate": 1.2900000000000002e-05,
      "loss": 0.0218,
      "step": 7100
    },
    {
      "epoch": 3.555,
      "grad_norm": 0.4658551812171936,
      "learning_rate": 1.289e-05,
      "loss": 0.0205,
      "step": 7110
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.170143485069275,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.0244,
      "step": 7120
    },
    {
      "epoch": 3.565,
      "grad_norm": 1.53471040725708,
      "learning_rate": 1.287e-05,
      "loss": 0.0215,
      "step": 7130
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.447582483291626,
      "learning_rate": 1.286e-05,
      "loss": 0.0274,
      "step": 7140
    },
    {
      "epoch": 3.575,
      "grad_norm": 0.6372005343437195,
      "learning_rate": 1.285e-05,
      "loss": 0.0164,
      "step": 7150
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.6438603401184082,
      "learning_rate": 1.284e-05,
      "loss": 0.0306,
      "step": 7160
    },
    {
      "epoch": 3.585,
      "grad_norm": 1.525704026222229,
      "learning_rate": 1.283e-05,
      "loss": 0.0128,
      "step": 7170
    },
    {
      "epoch": 3.59,
      "grad_norm": 1.6322425603866577,
      "learning_rate": 1.2820000000000001e-05,
      "loss": 0.0051,
      "step": 7180
    },
    {
      "epoch": 3.5949999999999998,
      "grad_norm": 0.38173893094062805,
      "learning_rate": 1.2810000000000001e-05,
      "loss": 0.0095,
      "step": 7190
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.4872108995914459,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0183,
      "step": 7200
    },
    {
      "epoch": 3.605,
      "grad_norm": 0.1869032084941864,
      "learning_rate": 1.279e-05,
      "loss": 0.0105,
      "step": 7210
    },
    {
      "epoch": 3.61,
      "grad_norm": 3.7378227710723877,
      "learning_rate": 1.2780000000000001e-05,
      "loss": 0.0089,
      "step": 7220
    },
    {
      "epoch": 3.615,
      "grad_norm": 0.02126208506524563,
      "learning_rate": 1.277e-05,
      "loss": 0.0144,
      "step": 7230
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.01742102950811386,
      "learning_rate": 1.2760000000000001e-05,
      "loss": 0.0116,
      "step": 7240
    },
    {
      "epoch": 3.625,
      "grad_norm": 0.3440099060535431,
      "learning_rate": 1.275e-05,
      "loss": 0.0354,
      "step": 7250
    },
    {
      "epoch": 3.63,
      "grad_norm": 1.4695674180984497,
      "learning_rate": 1.2740000000000002e-05,
      "loss": 0.0553,
      "step": 7260
    },
    {
      "epoch": 3.635,
      "grad_norm": 0.107728511095047,
      "learning_rate": 1.273e-05,
      "loss": 0.0182,
      "step": 7270
    },
    {
      "epoch": 3.64,
      "grad_norm": 3.5106451511383057,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.0231,
      "step": 7280
    },
    {
      "epoch": 3.645,
      "grad_norm": 5.702500343322754,
      "learning_rate": 1.271e-05,
      "loss": 0.0278,
      "step": 7290
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.12436892837285995,
      "learning_rate": 1.27e-05,
      "loss": 0.0153,
      "step": 7300
    },
    {
      "epoch": 3.6550000000000002,
      "grad_norm": 4.4128899574279785,
      "learning_rate": 1.269e-05,
      "loss": 0.0218,
      "step": 7310
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.3616315424442291,
      "learning_rate": 1.268e-05,
      "loss": 0.0296,
      "step": 7320
    },
    {
      "epoch": 3.665,
      "grad_norm": 0.6517090201377869,
      "learning_rate": 1.267e-05,
      "loss": 0.0156,
      "step": 7330
    },
    {
      "epoch": 3.67,
      "grad_norm": 1.1143670082092285,
      "learning_rate": 1.266e-05,
      "loss": 0.0118,
      "step": 7340
    },
    {
      "epoch": 3.675,
      "grad_norm": 0.034467898309230804,
      "learning_rate": 1.2650000000000001e-05,
      "loss": 0.022,
      "step": 7350
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.5198168158531189,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.0255,
      "step": 7360
    },
    {
      "epoch": 3.685,
      "grad_norm": 2.325199842453003,
      "learning_rate": 1.263e-05,
      "loss": 0.0361,
      "step": 7370
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.7941809296607971,
      "learning_rate": 1.2620000000000001e-05,
      "loss": 0.0067,
      "step": 7380
    },
    {
      "epoch": 3.695,
      "grad_norm": 1.3136694431304932,
      "learning_rate": 1.261e-05,
      "loss": 0.0067,
      "step": 7390
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.006580364890396595,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0185,
      "step": 7400
    },
    {
      "epoch": 3.705,
      "grad_norm": 0.06525705754756927,
      "learning_rate": 1.259e-05,
      "loss": 0.0171,
      "step": 7410
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.1976376622915268,
      "learning_rate": 1.2580000000000002e-05,
      "loss": 0.0261,
      "step": 7420
    },
    {
      "epoch": 3.715,
      "grad_norm": 0.7458040118217468,
      "learning_rate": 1.257e-05,
      "loss": 0.0158,
      "step": 7430
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 3.3868257999420166,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.0239,
      "step": 7440
    },
    {
      "epoch": 3.725,
      "grad_norm": 0.01859312132000923,
      "learning_rate": 1.255e-05,
      "loss": 0.0117,
      "step": 7450
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.8488025069236755,
      "learning_rate": 1.254e-05,
      "loss": 0.013,
      "step": 7460
    },
    {
      "epoch": 3.735,
      "grad_norm": 0.0054540252313017845,
      "learning_rate": 1.253e-05,
      "loss": 0.0301,
      "step": 7470
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.008807349018752575,
      "learning_rate": 1.252e-05,
      "loss": 0.0339,
      "step": 7480
    },
    {
      "epoch": 3.745,
      "grad_norm": 1.210907220840454,
      "learning_rate": 1.251e-05,
      "loss": 0.0164,
      "step": 7490
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.7182429432868958,
      "learning_rate": 1.25e-05,
      "loss": 0.0188,
      "step": 7500
    },
    {
      "epoch": 3.755,
      "grad_norm": 0.03872179612517357,
      "learning_rate": 1.2490000000000002e-05,
      "loss": 0.0136,
      "step": 7510
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.026348350569605827,
      "learning_rate": 1.248e-05,
      "loss": 0.0066,
      "step": 7520
    },
    {
      "epoch": 3.765,
      "grad_norm": 1.2984297275543213,
      "learning_rate": 1.2470000000000003e-05,
      "loss": 0.0207,
      "step": 7530
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.0032248455099761486,
      "learning_rate": 1.2460000000000001e-05,
      "loss": 0.0121,
      "step": 7540
    },
    {
      "epoch": 3.775,
      "grad_norm": 0.43301400542259216,
      "learning_rate": 1.2450000000000003e-05,
      "loss": 0.0226,
      "step": 7550
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 0.009510224685072899,
      "learning_rate": 1.2440000000000001e-05,
      "loss": 0.0179,
      "step": 7560
    },
    {
      "epoch": 3.785,
      "grad_norm": 0.07116328179836273,
      "learning_rate": 1.2430000000000001e-05,
      "loss": 0.0079,
      "step": 7570
    },
    {
      "epoch": 3.79,
      "grad_norm": 1.3362274169921875,
      "learning_rate": 1.2420000000000001e-05,
      "loss": 0.0218,
      "step": 7580
    },
    {
      "epoch": 3.795,
      "grad_norm": 2.405764102935791,
      "learning_rate": 1.2410000000000001e-05,
      "loss": 0.0222,
      "step": 7590
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.8284969329833984,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.045,
      "step": 7600
    },
    {
      "epoch": 3.805,
      "grad_norm": 0.8238000869750977,
      "learning_rate": 1.2390000000000002e-05,
      "loss": 0.0043,
      "step": 7610
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.10970266163349152,
      "learning_rate": 1.2380000000000002e-05,
      "loss": 0.0113,
      "step": 7620
    },
    {
      "epoch": 3.815,
      "grad_norm": 0.01046542078256607,
      "learning_rate": 1.2370000000000002e-05,
      "loss": 0.0094,
      "step": 7630
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.04948710650205612,
      "learning_rate": 1.236e-05,
      "loss": 0.03,
      "step": 7640
    },
    {
      "epoch": 3.825,
      "grad_norm": 0.011744260787963867,
      "learning_rate": 1.2350000000000002e-05,
      "loss": 0.0053,
      "step": 7650
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.524709701538086,
      "learning_rate": 1.234e-05,
      "loss": 0.0238,
      "step": 7660
    },
    {
      "epoch": 3.835,
      "grad_norm": 0.08607903867959976,
      "learning_rate": 1.2330000000000002e-05,
      "loss": 0.0093,
      "step": 7670
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.9416909217834473,
      "learning_rate": 1.232e-05,
      "loss": 0.0261,
      "step": 7680
    },
    {
      "epoch": 3.8449999999999998,
      "grad_norm": 0.542163074016571,
      "learning_rate": 1.2310000000000002e-05,
      "loss": 0.0104,
      "step": 7690
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.03772398456931114,
      "learning_rate": 1.23e-05,
      "loss": 0.0118,
      "step": 7700
    },
    {
      "epoch": 3.855,
      "grad_norm": 1.5812760591506958,
      "learning_rate": 1.2290000000000003e-05,
      "loss": 0.0176,
      "step": 7710
    },
    {
      "epoch": 3.86,
      "grad_norm": 1.1692267656326294,
      "learning_rate": 1.2280000000000001e-05,
      "loss": 0.0335,
      "step": 7720
    },
    {
      "epoch": 3.865,
      "grad_norm": 1.319896936416626,
      "learning_rate": 1.2270000000000001e-05,
      "loss": 0.0076,
      "step": 7730
    },
    {
      "epoch": 3.87,
      "grad_norm": 1.0977673530578613,
      "learning_rate": 1.2260000000000001e-05,
      "loss": 0.0093,
      "step": 7740
    },
    {
      "epoch": 3.875,
      "grad_norm": 2.801692485809326,
      "learning_rate": 1.2250000000000001e-05,
      "loss": 0.0353,
      "step": 7750
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.3996943533420563,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.0182,
      "step": 7760
    },
    {
      "epoch": 3.885,
      "grad_norm": 6.422126293182373,
      "learning_rate": 1.2230000000000001e-05,
      "loss": 0.0238,
      "step": 7770
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.060526005923748016,
      "learning_rate": 1.2220000000000002e-05,
      "loss": 0.0366,
      "step": 7780
    },
    {
      "epoch": 3.895,
      "grad_norm": 0.040833085775375366,
      "learning_rate": 1.2210000000000002e-05,
      "loss": 0.016,
      "step": 7790
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.0411038398742676,
      "learning_rate": 1.22e-05,
      "loss": 0.0241,
      "step": 7800
    },
    {
      "epoch": 3.9050000000000002,
      "grad_norm": 0.6369974613189697,
      "learning_rate": 1.2190000000000002e-05,
      "loss": 0.0179,
      "step": 7810
    },
    {
      "epoch": 3.91,
      "grad_norm": 1.4932200908660889,
      "learning_rate": 1.218e-05,
      "loss": 0.0053,
      "step": 7820
    },
    {
      "epoch": 3.915,
      "grad_norm": 0.6143208742141724,
      "learning_rate": 1.2170000000000002e-05,
      "loss": 0.031,
      "step": 7830
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.8184114694595337,
      "learning_rate": 1.216e-05,
      "loss": 0.0195,
      "step": 7840
    },
    {
      "epoch": 3.925,
      "grad_norm": 0.03514295816421509,
      "learning_rate": 1.2150000000000002e-05,
      "loss": 0.0133,
      "step": 7850
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.009967934340238571,
      "learning_rate": 1.214e-05,
      "loss": 0.0332,
      "step": 7860
    },
    {
      "epoch": 3.935,
      "grad_norm": 0.8033139705657959,
      "learning_rate": 1.2130000000000002e-05,
      "loss": 0.0262,
      "step": 7870
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.30259859561920166,
      "learning_rate": 1.2120000000000001e-05,
      "loss": 0.0081,
      "step": 7880
    },
    {
      "epoch": 3.945,
      "grad_norm": 0.9169927835464478,
      "learning_rate": 1.2110000000000001e-05,
      "loss": 0.0218,
      "step": 7890
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.38230133056640625,
      "learning_rate": 1.2100000000000001e-05,
      "loss": 0.0283,
      "step": 7900
    },
    {
      "epoch": 3.955,
      "grad_norm": 0.32534587383270264,
      "learning_rate": 1.2090000000000001e-05,
      "loss": 0.0059,
      "step": 7910
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.7653389573097229,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.0072,
      "step": 7920
    },
    {
      "epoch": 3.965,
      "grad_norm": 0.02100333571434021,
      "learning_rate": 1.2070000000000001e-05,
      "loss": 0.0111,
      "step": 7930
    },
    {
      "epoch": 3.9699999999999998,
      "grad_norm": 0.8549485802650452,
      "learning_rate": 1.2060000000000001e-05,
      "loss": 0.0147,
      "step": 7940
    },
    {
      "epoch": 3.975,
      "grad_norm": 0.011923878453671932,
      "learning_rate": 1.2050000000000002e-05,
      "loss": 0.0105,
      "step": 7950
    },
    {
      "epoch": 3.98,
      "grad_norm": 7.876999378204346,
      "learning_rate": 1.204e-05,
      "loss": 0.0278,
      "step": 7960
    },
    {
      "epoch": 3.985,
      "grad_norm": 4.445222854614258,
      "learning_rate": 1.2030000000000002e-05,
      "loss": 0.0259,
      "step": 7970
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.6735930442810059,
      "learning_rate": 1.202e-05,
      "loss": 0.0138,
      "step": 7980
    },
    {
      "epoch": 3.995,
      "grad_norm": 0.34529194235801697,
      "learning_rate": 1.2010000000000002e-05,
      "loss": 0.0116,
      "step": 7990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.1881265640258789,
      "learning_rate": 1.2e-05,
      "loss": 0.0231,
      "step": 8000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9919778296382731,
      "eval_f1": 0.9687322342239908,
      "eval_loss": 0.024241134524345398,
      "eval_precision": 0.9787478460654796,
      "eval_recall": 0.9589195272931907,
      "eval_runtime": 909.5416,
      "eval_samples_per_second": 30.161,
      "eval_steps_per_second": 0.943,
      "step": 8000
    },
    {
      "epoch": 4.005,
      "grad_norm": 3.9978973865509033,
      "learning_rate": 1.1990000000000002e-05,
      "loss": 0.0076,
      "step": 8010
    },
    {
      "epoch": 4.01,
      "grad_norm": 1.2527167797088623,
      "learning_rate": 1.198e-05,
      "loss": 0.024,
      "step": 8020
    },
    {
      "epoch": 4.015,
      "grad_norm": 0.2803904712200165,
      "learning_rate": 1.1970000000000002e-05,
      "loss": 0.0114,
      "step": 8030
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3841469883918762,
      "learning_rate": 1.196e-05,
      "loss": 0.0065,
      "step": 8040
    },
    {
      "epoch": 4.025,
      "grad_norm": 0.5154185891151428,
      "learning_rate": 1.195e-05,
      "loss": 0.0063,
      "step": 8050
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.00404035858809948,
      "learning_rate": 1.1940000000000001e-05,
      "loss": 0.0251,
      "step": 8060
    },
    {
      "epoch": 4.035,
      "grad_norm": 0.9478206038475037,
      "learning_rate": 1.1930000000000001e-05,
      "loss": 0.0115,
      "step": 8070
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.046541377902030945,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.0104,
      "step": 8080
    },
    {
      "epoch": 4.045,
      "grad_norm": 0.09651005268096924,
      "learning_rate": 1.1910000000000001e-05,
      "loss": 0.0182,
      "step": 8090
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.46035534143447876,
      "learning_rate": 1.1900000000000001e-05,
      "loss": 0.0086,
      "step": 8100
    },
    {
      "epoch": 4.055,
      "grad_norm": 0.007240402977913618,
      "learning_rate": 1.1890000000000001e-05,
      "loss": 0.0147,
      "step": 8110
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.5908180475234985,
      "learning_rate": 1.188e-05,
      "loss": 0.0121,
      "step": 8120
    },
    {
      "epoch": 4.065,
      "grad_norm": 1.8289448022842407,
      "learning_rate": 1.1870000000000002e-05,
      "loss": 0.0271,
      "step": 8130
    },
    {
      "epoch": 4.07,
      "grad_norm": 10.151878356933594,
      "learning_rate": 1.186e-05,
      "loss": 0.0163,
      "step": 8140
    },
    {
      "epoch": 4.075,
      "grad_norm": 0.010523398406803608,
      "learning_rate": 1.1850000000000002e-05,
      "loss": 0.0038,
      "step": 8150
    },
    {
      "epoch": 4.08,
      "grad_norm": 8.942848205566406,
      "learning_rate": 1.184e-05,
      "loss": 0.0282,
      "step": 8160
    },
    {
      "epoch": 4.085,
      "grad_norm": 0.005223968531936407,
      "learning_rate": 1.1830000000000002e-05,
      "loss": 0.0015,
      "step": 8170
    },
    {
      "epoch": 4.09,
      "grad_norm": 4.273397445678711,
      "learning_rate": 1.182e-05,
      "loss": 0.0185,
      "step": 8180
    },
    {
      "epoch": 4.095,
      "grad_norm": 2.7232282161712646,
      "learning_rate": 1.1810000000000002e-05,
      "loss": 0.0139,
      "step": 8190
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.10089380294084549,
      "learning_rate": 1.18e-05,
      "loss": 0.0129,
      "step": 8200
    },
    {
      "epoch": 4.105,
      "grad_norm": 0.21648547053337097,
      "learning_rate": 1.179e-05,
      "loss": 0.0208,
      "step": 8210
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.005050772801041603,
      "learning_rate": 1.178e-05,
      "loss": 0.0211,
      "step": 8220
    },
    {
      "epoch": 4.115,
      "grad_norm": 0.5284351110458374,
      "learning_rate": 1.177e-05,
      "loss": 0.0088,
      "step": 8230
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.07102801650762558,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.0169,
      "step": 8240
    },
    {
      "epoch": 4.125,
      "grad_norm": 0.5070996880531311,
      "learning_rate": 1.1750000000000001e-05,
      "loss": 0.0269,
      "step": 8250
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.292562335729599,
      "learning_rate": 1.1740000000000001e-05,
      "loss": 0.0131,
      "step": 8260
    },
    {
      "epoch": 4.135,
      "grad_norm": 0.605155348777771,
      "learning_rate": 1.1730000000000001e-05,
      "loss": 0.0088,
      "step": 8270
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.18119485676288605,
      "learning_rate": 1.172e-05,
      "loss": 0.0085,
      "step": 8280
    },
    {
      "epoch": 4.145,
      "grad_norm": 1.9444893598556519,
      "learning_rate": 1.1710000000000001e-05,
      "loss": 0.0288,
      "step": 8290
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.010647430084645748,
      "learning_rate": 1.17e-05,
      "loss": 0.0196,
      "step": 8300
    },
    {
      "epoch": 4.155,
      "grad_norm": 0.015888649970293045,
      "learning_rate": 1.1690000000000002e-05,
      "loss": 0.0283,
      "step": 8310
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.01327885128557682,
      "learning_rate": 1.168e-05,
      "loss": 0.018,
      "step": 8320
    },
    {
      "epoch": 4.165,
      "grad_norm": 1.0238133668899536,
      "learning_rate": 1.1670000000000002e-05,
      "loss": 0.0236,
      "step": 8330
    },
    {
      "epoch": 4.17,
      "grad_norm": 3.9084432125091553,
      "learning_rate": 1.166e-05,
      "loss": 0.0203,
      "step": 8340
    },
    {
      "epoch": 4.175,
      "grad_norm": 1.3637696504592896,
      "learning_rate": 1.1650000000000002e-05,
      "loss": 0.0122,
      "step": 8350
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.1995205134153366,
      "learning_rate": 1.164e-05,
      "loss": 0.0018,
      "step": 8360
    },
    {
      "epoch": 4.185,
      "grad_norm": 0.23877497017383575,
      "learning_rate": 1.163e-05,
      "loss": 0.0133,
      "step": 8370
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.005476693622767925,
      "learning_rate": 1.162e-05,
      "loss": 0.0073,
      "step": 8380
    },
    {
      "epoch": 4.195,
      "grad_norm": 0.6017209887504578,
      "learning_rate": 1.161e-05,
      "loss": 0.0166,
      "step": 8390
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.3595760762691498,
      "learning_rate": 1.16e-05,
      "loss": 0.0144,
      "step": 8400
    },
    {
      "epoch": 4.205,
      "grad_norm": 0.028538458049297333,
      "learning_rate": 1.159e-05,
      "loss": 0.0018,
      "step": 8410
    },
    {
      "epoch": 4.21,
      "grad_norm": 5.901703834533691,
      "learning_rate": 1.1580000000000001e-05,
      "loss": 0.0061,
      "step": 8420
    },
    {
      "epoch": 4.215,
      "grad_norm": 0.893204927444458,
      "learning_rate": 1.1570000000000001e-05,
      "loss": 0.0331,
      "step": 8430
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.45797863602638245,
      "learning_rate": 1.156e-05,
      "loss": 0.0313,
      "step": 8440
    },
    {
      "epoch": 4.225,
      "grad_norm": 0.38590195775032043,
      "learning_rate": 1.1550000000000001e-05,
      "loss": 0.0211,
      "step": 8450
    },
    {
      "epoch": 4.23,
      "grad_norm": 2.7577593326568604,
      "learning_rate": 1.154e-05,
      "loss": 0.0253,
      "step": 8460
    },
    {
      "epoch": 4.235,
      "grad_norm": 0.35207289457321167,
      "learning_rate": 1.1530000000000001e-05,
      "loss": 0.0213,
      "step": 8470
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.32952091097831726,
      "learning_rate": 1.152e-05,
      "loss": 0.0128,
      "step": 8480
    },
    {
      "epoch": 4.245,
      "grad_norm": 0.15628033876419067,
      "learning_rate": 1.1510000000000002e-05,
      "loss": 0.0122,
      "step": 8490
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.03615616634488106,
      "learning_rate": 1.15e-05,
      "loss": 0.0259,
      "step": 8500
    },
    {
      "epoch": 4.255,
      "grad_norm": 4.044010162353516,
      "learning_rate": 1.1490000000000002e-05,
      "loss": 0.007,
      "step": 8510
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.23588842153549194,
      "learning_rate": 1.148e-05,
      "loss": 0.0057,
      "step": 8520
    },
    {
      "epoch": 4.265,
      "grad_norm": 8.565681457519531,
      "learning_rate": 1.147e-05,
      "loss": 0.0223,
      "step": 8530
    },
    {
      "epoch": 4.27,
      "grad_norm": 2.9519848823547363,
      "learning_rate": 1.146e-05,
      "loss": 0.018,
      "step": 8540
    },
    {
      "epoch": 4.275,
      "grad_norm": 0.013809735886752605,
      "learning_rate": 1.145e-05,
      "loss": 0.0197,
      "step": 8550
    },
    {
      "epoch": 4.28,
      "grad_norm": 2.959918737411499,
      "learning_rate": 1.144e-05,
      "loss": 0.0121,
      "step": 8560
    },
    {
      "epoch": 4.285,
      "grad_norm": 3.2887792587280273,
      "learning_rate": 1.143e-05,
      "loss": 0.0149,
      "step": 8570
    },
    {
      "epoch": 4.29,
      "grad_norm": 0.025024356320500374,
      "learning_rate": 1.142e-05,
      "loss": 0.0142,
      "step": 8580
    },
    {
      "epoch": 4.295,
      "grad_norm": 1.362295150756836,
      "learning_rate": 1.1410000000000001e-05,
      "loss": 0.0067,
      "step": 8590
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.753247857093811,
      "learning_rate": 1.14e-05,
      "loss": 0.0088,
      "step": 8600
    },
    {
      "epoch": 4.305,
      "grad_norm": 1.6984137296676636,
      "learning_rate": 1.1390000000000001e-05,
      "loss": 0.028,
      "step": 8610
    },
    {
      "epoch": 4.31,
      "grad_norm": 2.9926180839538574,
      "learning_rate": 1.138e-05,
      "loss": 0.0086,
      "step": 8620
    },
    {
      "epoch": 4.315,
      "grad_norm": 0.9062213897705078,
      "learning_rate": 1.1370000000000001e-05,
      "loss": 0.0094,
      "step": 8630
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.1618002653121948,
      "learning_rate": 1.136e-05,
      "loss": 0.0107,
      "step": 8640
    },
    {
      "epoch": 4.325,
      "grad_norm": 0.4841044545173645,
      "learning_rate": 1.1350000000000001e-05,
      "loss": 0.0457,
      "step": 8650
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.978172779083252,
      "learning_rate": 1.134e-05,
      "loss": 0.012,
      "step": 8660
    },
    {
      "epoch": 4.335,
      "grad_norm": 0.7911048531532288,
      "learning_rate": 1.1330000000000002e-05,
      "loss": 0.0033,
      "step": 8670
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.305175244808197,
      "learning_rate": 1.132e-05,
      "loss": 0.0187,
      "step": 8680
    },
    {
      "epoch": 4.345,
      "grad_norm": 0.5326801538467407,
      "learning_rate": 1.131e-05,
      "loss": 0.0131,
      "step": 8690
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.07223561406135559,
      "learning_rate": 1.13e-05,
      "loss": 0.0231,
      "step": 8700
    },
    {
      "epoch": 4.355,
      "grad_norm": 11.541669845581055,
      "learning_rate": 1.129e-05,
      "loss": 0.03,
      "step": 8710
    },
    {
      "epoch": 4.36,
      "grad_norm": 3.1172256469726562,
      "learning_rate": 1.128e-05,
      "loss": 0.0231,
      "step": 8720
    },
    {
      "epoch": 4.365,
      "grad_norm": 0.6228477358818054,
      "learning_rate": 1.127e-05,
      "loss": 0.0051,
      "step": 8730
    },
    {
      "epoch": 4.37,
      "grad_norm": 8.20397663116455,
      "learning_rate": 1.126e-05,
      "loss": 0.0224,
      "step": 8740
    },
    {
      "epoch": 4.375,
      "grad_norm": 0.2834762930870056,
      "learning_rate": 1.125e-05,
      "loss": 0.0101,
      "step": 8750
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.037331368774175644,
      "learning_rate": 1.1240000000000002e-05,
      "loss": 0.0029,
      "step": 8760
    },
    {
      "epoch": 4.385,
      "grad_norm": 0.0019480636110529304,
      "learning_rate": 1.1230000000000001e-05,
      "loss": 0.0099,
      "step": 8770
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.011084210127592087,
      "learning_rate": 1.1220000000000003e-05,
      "loss": 0.0047,
      "step": 8780
    },
    {
      "epoch": 4.395,
      "grad_norm": 0.003099177498370409,
      "learning_rate": 1.1210000000000001e-05,
      "loss": 0.0291,
      "step": 8790
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.7962654829025269,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0221,
      "step": 8800
    },
    {
      "epoch": 4.405,
      "grad_norm": 1.3351813554763794,
      "learning_rate": 1.1190000000000001e-05,
      "loss": 0.0055,
      "step": 8810
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.1935485601425171,
      "learning_rate": 1.1180000000000001e-05,
      "loss": 0.0164,
      "step": 8820
    },
    {
      "epoch": 4.415,
      "grad_norm": 0.07539525628089905,
      "learning_rate": 1.1170000000000001e-05,
      "loss": 0.0067,
      "step": 8830
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.0013667710591107607,
      "learning_rate": 1.1160000000000002e-05,
      "loss": 0.0214,
      "step": 8840
    },
    {
      "epoch": 4.425,
      "grad_norm": 0.03554581478238106,
      "learning_rate": 1.1150000000000002e-05,
      "loss": 0.0275,
      "step": 8850
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.016931116580963135,
      "learning_rate": 1.1140000000000002e-05,
      "loss": 0.0221,
      "step": 8860
    },
    {
      "epoch": 4.435,
      "grad_norm": 0.7655174136161804,
      "learning_rate": 1.113e-05,
      "loss": 0.0184,
      "step": 8870
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.020205248147249222,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.0126,
      "step": 8880
    },
    {
      "epoch": 4.445,
      "grad_norm": 0.07965490221977234,
      "learning_rate": 1.111e-05,
      "loss": 0.0204,
      "step": 8890
    },
    {
      "epoch": 4.45,
      "grad_norm": 1.8667820692062378,
      "learning_rate": 1.1100000000000002e-05,
      "loss": 0.0257,
      "step": 8900
    },
    {
      "epoch": 4.455,
      "grad_norm": 0.4871842861175537,
      "learning_rate": 1.109e-05,
      "loss": 0.0203,
      "step": 8910
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.023914257064461708,
      "learning_rate": 1.1080000000000002e-05,
      "loss": 0.0082,
      "step": 8920
    },
    {
      "epoch": 4.465,
      "grad_norm": 1.9387322664260864,
      "learning_rate": 1.107e-05,
      "loss": 0.018,
      "step": 8930
    },
    {
      "epoch": 4.47,
      "grad_norm": 0.3894728720188141,
      "learning_rate": 1.1060000000000003e-05,
      "loss": 0.0101,
      "step": 8940
    },
    {
      "epoch": 4.475,
      "grad_norm": 1.5807820558547974,
      "learning_rate": 1.1050000000000001e-05,
      "loss": 0.0163,
      "step": 8950
    },
    {
      "epoch": 4.48,
      "grad_norm": 6.886279106140137,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.0154,
      "step": 8960
    },
    {
      "epoch": 4.485,
      "grad_norm": 0.34549933671951294,
      "learning_rate": 1.1030000000000001e-05,
      "loss": 0.0382,
      "step": 8970
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.9664433598518372,
      "learning_rate": 1.1020000000000001e-05,
      "loss": 0.011,
      "step": 8980
    },
    {
      "epoch": 4.495,
      "grad_norm": 0.13220883905887604,
      "learning_rate": 1.1010000000000001e-05,
      "loss": 0.0134,
      "step": 8990
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.3185752630233765,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0131,
      "step": 9000
    },
    {
      "epoch": 4.505,
      "grad_norm": 0.03503794223070145,
      "learning_rate": 1.0990000000000002e-05,
      "loss": 0.0057,
      "step": 9010
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.06636399775743484,
      "learning_rate": 1.0980000000000002e-05,
      "loss": 0.0172,
      "step": 9020
    },
    {
      "epoch": 4.515,
      "grad_norm": 0.002343505620956421,
      "learning_rate": 1.097e-05,
      "loss": 0.0062,
      "step": 9030
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.021276211366057396,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.0137,
      "step": 9040
    },
    {
      "epoch": 4.525,
      "grad_norm": 0.14185267686843872,
      "learning_rate": 1.095e-05,
      "loss": 0.0113,
      "step": 9050
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.7792394161224365,
      "learning_rate": 1.0940000000000002e-05,
      "loss": 0.0187,
      "step": 9060
    },
    {
      "epoch": 4.535,
      "grad_norm": 0.8735334277153015,
      "learning_rate": 1.093e-05,
      "loss": 0.0181,
      "step": 9070
    },
    {
      "epoch": 4.54,
      "grad_norm": 6.254171371459961,
      "learning_rate": 1.0920000000000002e-05,
      "loss": 0.0253,
      "step": 9080
    },
    {
      "epoch": 4.545,
      "grad_norm": 0.16591876745224,
      "learning_rate": 1.091e-05,
      "loss": 0.009,
      "step": 9090
    },
    {
      "epoch": 4.55,
      "grad_norm": 1.1675993204116821,
      "learning_rate": 1.0900000000000002e-05,
      "loss": 0.018,
      "step": 9100
    },
    {
      "epoch": 4.555,
      "grad_norm": 0.01692179962992668,
      "learning_rate": 1.089e-05,
      "loss": 0.0062,
      "step": 9110
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 4.121622085571289,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.0295,
      "step": 9120
    },
    {
      "epoch": 4.5649999999999995,
      "grad_norm": 0.8866205215454102,
      "learning_rate": 1.0870000000000001e-05,
      "loss": 0.0157,
      "step": 9130
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.22080166637897491,
      "learning_rate": 1.0860000000000001e-05,
      "loss": 0.0076,
      "step": 9140
    },
    {
      "epoch": 4.575,
      "grad_norm": 0.0025317538529634476,
      "learning_rate": 1.0850000000000001e-05,
      "loss": 0.0124,
      "step": 9150
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.5669894218444824,
      "learning_rate": 1.0840000000000001e-05,
      "loss": 0.038,
      "step": 9160
    },
    {
      "epoch": 4.585,
      "grad_norm": 4.1847615242004395,
      "learning_rate": 1.0830000000000001e-05,
      "loss": 0.0234,
      "step": 9170
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.5947929620742798,
      "learning_rate": 1.0820000000000001e-05,
      "loss": 0.0346,
      "step": 9180
    },
    {
      "epoch": 4.595,
      "grad_norm": 0.03336011990904808,
      "learning_rate": 1.081e-05,
      "loss": 0.0081,
      "step": 9190
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.017424961552023888,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0054,
      "step": 9200
    },
    {
      "epoch": 4.605,
      "grad_norm": 7.526764392852783,
      "learning_rate": 1.079e-05,
      "loss": 0.0159,
      "step": 9210
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.8271438479423523,
      "learning_rate": 1.0780000000000002e-05,
      "loss": 0.0124,
      "step": 9220
    },
    {
      "epoch": 4.615,
      "grad_norm": 0.8516462445259094,
      "learning_rate": 1.077e-05,
      "loss": 0.013,
      "step": 9230
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.572354257106781,
      "learning_rate": 1.0760000000000002e-05,
      "loss": 0.0211,
      "step": 9240
    },
    {
      "epoch": 4.625,
      "grad_norm": 0.006442975252866745,
      "learning_rate": 1.075e-05,
      "loss": 0.0254,
      "step": 9250
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.01793455146253109,
      "learning_rate": 1.0740000000000002e-05,
      "loss": 0.0229,
      "step": 9260
    },
    {
      "epoch": 4.635,
      "grad_norm": 0.21530772745609283,
      "learning_rate": 1.073e-05,
      "loss": 0.0062,
      "step": 9270
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.9997374415397644,
      "learning_rate": 1.072e-05,
      "loss": 0.0148,
      "step": 9280
    },
    {
      "epoch": 4.645,
      "grad_norm": 0.004130984656512737,
      "learning_rate": 1.071e-05,
      "loss": 0.0108,
      "step": 9290
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.02680470049381256,
      "learning_rate": 1.0700000000000001e-05,
      "loss": 0.0061,
      "step": 9300
    },
    {
      "epoch": 4.655,
      "grad_norm": 0.0035752146504819393,
      "learning_rate": 1.0690000000000001e-05,
      "loss": 0.0152,
      "step": 9310
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.13892856240272522,
      "learning_rate": 1.0680000000000001e-05,
      "loss": 0.0092,
      "step": 9320
    },
    {
      "epoch": 4.665,
      "grad_norm": 0.5686845183372498,
      "learning_rate": 1.0670000000000001e-05,
      "loss": 0.0056,
      "step": 9330
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.008599506691098213,
      "learning_rate": 1.0660000000000001e-05,
      "loss": 0.0059,
      "step": 9340
    },
    {
      "epoch": 4.675,
      "grad_norm": 0.03598779812455177,
      "learning_rate": 1.065e-05,
      "loss": 0.0091,
      "step": 9350
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.001561892218887806,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.0108,
      "step": 9360
    },
    {
      "epoch": 4.6850000000000005,
      "grad_norm": 1.7044498920440674,
      "learning_rate": 1.063e-05,
      "loss": 0.0223,
      "step": 9370
    },
    {
      "epoch": 4.6899999999999995,
      "grad_norm": 0.4562288820743561,
      "learning_rate": 1.0620000000000002e-05,
      "loss": 0.0091,
      "step": 9380
    },
    {
      "epoch": 4.695,
      "grad_norm": 2.264312505722046,
      "learning_rate": 1.061e-05,
      "loss": 0.0136,
      "step": 9390
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.9467875957489014,
      "learning_rate": 1.0600000000000002e-05,
      "loss": 0.0227,
      "step": 9400
    },
    {
      "epoch": 4.705,
      "grad_norm": 0.004741309210658073,
      "learning_rate": 1.059e-05,
      "loss": 0.0156,
      "step": 9410
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.6433568596839905,
      "learning_rate": 1.0580000000000002e-05,
      "loss": 0.0039,
      "step": 9420
    },
    {
      "epoch": 4.715,
      "grad_norm": 11.273170471191406,
      "learning_rate": 1.057e-05,
      "loss": 0.014,
      "step": 9430
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.02076718956232071,
      "learning_rate": 1.056e-05,
      "loss": 0.0184,
      "step": 9440
    },
    {
      "epoch": 4.725,
      "grad_norm": 0.005081095267087221,
      "learning_rate": 1.055e-05,
      "loss": 0.012,
      "step": 9450
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.6388866901397705,
      "learning_rate": 1.054e-05,
      "loss": 0.0036,
      "step": 9460
    },
    {
      "epoch": 4.735,
      "grad_norm": 1.3020707368850708,
      "learning_rate": 1.053e-05,
      "loss": 0.0062,
      "step": 9470
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.6980836391448975,
      "learning_rate": 1.0520000000000001e-05,
      "loss": 0.0117,
      "step": 9480
    },
    {
      "epoch": 4.745,
      "grad_norm": 0.02780967392027378,
      "learning_rate": 1.0510000000000001e-05,
      "loss": 0.0082,
      "step": 9490
    },
    {
      "epoch": 4.75,
      "grad_norm": 5.660277366638184,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.0326,
      "step": 9500
    },
    {
      "epoch": 4.755,
      "grad_norm": 0.1153518483042717,
      "learning_rate": 1.049e-05,
      "loss": 0.016,
      "step": 9510
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.6270086765289307,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.0186,
      "step": 9520
    },
    {
      "epoch": 4.765,
      "grad_norm": 0.4474520981311798,
      "learning_rate": 1.047e-05,
      "loss": 0.018,
      "step": 9530
    },
    {
      "epoch": 4.77,
      "grad_norm": 0.14335940778255463,
      "learning_rate": 1.0460000000000001e-05,
      "loss": 0.0045,
      "step": 9540
    },
    {
      "epoch": 4.775,
      "grad_norm": 5.523618221282959,
      "learning_rate": 1.045e-05,
      "loss": 0.0278,
      "step": 9550
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.6050006151199341,
      "learning_rate": 1.0440000000000002e-05,
      "loss": 0.0113,
      "step": 9560
    },
    {
      "epoch": 4.785,
      "grad_norm": 0.00497992942109704,
      "learning_rate": 1.043e-05,
      "loss": 0.019,
      "step": 9570
    },
    {
      "epoch": 4.79,
      "grad_norm": 2.470273733139038,
      "learning_rate": 1.0420000000000002e-05,
      "loss": 0.0243,
      "step": 9580
    },
    {
      "epoch": 4.795,
      "grad_norm": 0.07789213955402374,
      "learning_rate": 1.041e-05,
      "loss": 0.0122,
      "step": 9590
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.18005183339118958,
      "learning_rate": 1.04e-05,
      "loss": 0.0093,
      "step": 9600
    },
    {
      "epoch": 4.805,
      "grad_norm": 0.005849634762853384,
      "learning_rate": 1.039e-05,
      "loss": 0.0097,
      "step": 9610
    },
    {
      "epoch": 4.8100000000000005,
      "grad_norm": 0.8368719816207886,
      "learning_rate": 1.038e-05,
      "loss": 0.0281,
      "step": 9620
    },
    {
      "epoch": 4.8149999999999995,
      "grad_norm": 0.652890682220459,
      "learning_rate": 1.037e-05,
      "loss": 0.0043,
      "step": 9630
    },
    {
      "epoch": 4.82,
      "grad_norm": 1.736790418624878,
      "learning_rate": 1.036e-05,
      "loss": 0.0376,
      "step": 9640
    },
    {
      "epoch": 4.825,
      "grad_norm": 0.0778292715549469,
      "learning_rate": 1.0350000000000001e-05,
      "loss": 0.016,
      "step": 9650
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.9886225461959839,
      "learning_rate": 1.0340000000000001e-05,
      "loss": 0.008,
      "step": 9660
    },
    {
      "epoch": 4.835,
      "grad_norm": 1.2447307109832764,
      "learning_rate": 1.033e-05,
      "loss": 0.0122,
      "step": 9670
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.011849562637507915,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.0203,
      "step": 9680
    },
    {
      "epoch": 4.845,
      "grad_norm": 0.48629143834114075,
      "learning_rate": 1.031e-05,
      "loss": 0.01,
      "step": 9690
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.4629712700843811,
      "learning_rate": 1.0300000000000001e-05,
      "loss": 0.0077,
      "step": 9700
    },
    {
      "epoch": 4.855,
      "grad_norm": 0.5941826105117798,
      "learning_rate": 1.029e-05,
      "loss": 0.02,
      "step": 9710
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.003571070497855544,
      "learning_rate": 1.0280000000000002e-05,
      "loss": 0.0152,
      "step": 9720
    },
    {
      "epoch": 4.865,
      "grad_norm": 1.2592355012893677,
      "learning_rate": 1.027e-05,
      "loss": 0.0191,
      "step": 9730
    },
    {
      "epoch": 4.87,
      "grad_norm": 1.7549700736999512,
      "learning_rate": 1.0260000000000002e-05,
      "loss": 0.0118,
      "step": 9740
    },
    {
      "epoch": 4.875,
      "grad_norm": 0.025041164830327034,
      "learning_rate": 1.025e-05,
      "loss": 0.0176,
      "step": 9750
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.9945430755615234,
      "learning_rate": 1.024e-05,
      "loss": 0.0141,
      "step": 9760
    },
    {
      "epoch": 4.885,
      "grad_norm": 0.07913181930780411,
      "learning_rate": 1.023e-05,
      "loss": 0.0108,
      "step": 9770
    },
    {
      "epoch": 4.89,
      "grad_norm": 2.492982864379883,
      "learning_rate": 1.022e-05,
      "loss": 0.0136,
      "step": 9780
    },
    {
      "epoch": 4.895,
      "grad_norm": 1.467274785041809,
      "learning_rate": 1.021e-05,
      "loss": 0.0102,
      "step": 9790
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.6597615480422974,
      "learning_rate": 1.02e-05,
      "loss": 0.0112,
      "step": 9800
    },
    {
      "epoch": 4.905,
      "grad_norm": 0.03589725121855736,
      "learning_rate": 1.019e-05,
      "loss": 0.0106,
      "step": 9810
    },
    {
      "epoch": 4.91,
      "grad_norm": 3.4299213886260986,
      "learning_rate": 1.018e-05,
      "loss": 0.0245,
      "step": 9820
    },
    {
      "epoch": 4.915,
      "grad_norm": 1.4612822532653809,
      "learning_rate": 1.017e-05,
      "loss": 0.0079,
      "step": 9830
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.002273334190249443,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.0067,
      "step": 9840
    },
    {
      "epoch": 4.925,
      "grad_norm": 0.02180178090929985,
      "learning_rate": 1.015e-05,
      "loss": 0.0038,
      "step": 9850
    },
    {
      "epoch": 4.93,
      "grad_norm": 2.1545674800872803,
      "learning_rate": 1.0140000000000001e-05,
      "loss": 0.012,
      "step": 9860
    },
    {
      "epoch": 4.9350000000000005,
      "grad_norm": 0.6558628082275391,
      "learning_rate": 1.013e-05,
      "loss": 0.0129,
      "step": 9870
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.29665136337280273,
      "learning_rate": 1.0120000000000001e-05,
      "loss": 0.0199,
      "step": 9880
    },
    {
      "epoch": 4.945,
      "grad_norm": 0.27401503920555115,
      "learning_rate": 1.011e-05,
      "loss": 0.0037,
      "step": 9890
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.020269323140382767,
      "learning_rate": 1.0100000000000002e-05,
      "loss": 0.0236,
      "step": 9900
    },
    {
      "epoch": 4.955,
      "grad_norm": 0.6452024579048157,
      "learning_rate": 1.009e-05,
      "loss": 0.0245,
      "step": 9910
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.05878504738211632,
      "learning_rate": 1.008e-05,
      "loss": 0.008,
      "step": 9920
    },
    {
      "epoch": 4.965,
      "grad_norm": 3.165532112121582,
      "learning_rate": 1.007e-05,
      "loss": 0.0189,
      "step": 9930
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.0781838446855545,
      "learning_rate": 1.006e-05,
      "loss": 0.0074,
      "step": 9940
    },
    {
      "epoch": 4.975,
      "grad_norm": 5.703340530395508,
      "learning_rate": 1.005e-05,
      "loss": 0.0223,
      "step": 9950
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.33058255910873413,
      "learning_rate": 1.004e-05,
      "loss": 0.0149,
      "step": 9960
    },
    {
      "epoch": 4.985,
      "grad_norm": 0.32639190554618835,
      "learning_rate": 1.003e-05,
      "loss": 0.0113,
      "step": 9970
    },
    {
      "epoch": 4.99,
      "grad_norm": 0.6972604393959045,
      "learning_rate": 1.002e-05,
      "loss": 0.0082,
      "step": 9980
    },
    {
      "epoch": 4.995,
      "grad_norm": 0.033576685935258865,
      "learning_rate": 1.0009999999999999e-05,
      "loss": 0.017,
      "step": 9990
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.4144410490989685,
      "learning_rate": 1e-05,
      "loss": 0.0128,
      "step": 10000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9923424737456242,
      "eval_f1": 0.9708414329352958,
      "eval_loss": 0.02353009022772312,
      "eval_precision": 0.9583333333333334,
      "eval_recall": 0.983680360157569,
      "eval_runtime": 912.4069,
      "eval_samples_per_second": 30.067,
      "eval_steps_per_second": 0.94,
      "step": 10000
    },
    {
      "epoch": 5.005,
      "grad_norm": 1.4113380908966064,
      "learning_rate": 9.990000000000001e-06,
      "loss": 0.0091,
      "step": 10010
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.3544412851333618,
      "learning_rate": 9.980000000000001e-06,
      "loss": 0.002,
      "step": 10020
    },
    {
      "epoch": 5.015,
      "grad_norm": 1.1316263675689697,
      "learning_rate": 9.970000000000001e-06,
      "loss": 0.0116,
      "step": 10030
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.002521333284676075,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.0017,
      "step": 10040
    },
    {
      "epoch": 5.025,
      "grad_norm": 0.640619158744812,
      "learning_rate": 9.950000000000001e-06,
      "loss": 0.0094,
      "step": 10050
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.4184213876724243,
      "learning_rate": 9.940000000000001e-06,
      "loss": 0.0146,
      "step": 10060
    },
    {
      "epoch": 5.035,
      "grad_norm": 0.2136240005493164,
      "learning_rate": 9.930000000000001e-06,
      "loss": 0.0313,
      "step": 10070
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.125962495803833,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.0148,
      "step": 10080
    },
    {
      "epoch": 5.045,
      "grad_norm": 0.475858598947525,
      "learning_rate": 9.91e-06,
      "loss": 0.0162,
      "step": 10090
    },
    {
      "epoch": 5.05,
      "grad_norm": 1.1883066892623901,
      "learning_rate": 9.9e-06,
      "loss": 0.0287,
      "step": 10100
    },
    {
      "epoch": 5.055,
      "grad_norm": 0.0041568283922970295,
      "learning_rate": 9.89e-06,
      "loss": 0.0088,
      "step": 10110
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.06290052831172943,
      "learning_rate": 9.88e-06,
      "loss": 0.0116,
      "step": 10120
    },
    {
      "epoch": 5.065,
      "grad_norm": 0.0604640431702137,
      "learning_rate": 9.87e-06,
      "loss": 0.0117,
      "step": 10130
    },
    {
      "epoch": 5.07,
      "grad_norm": 0.013875875622034073,
      "learning_rate": 9.86e-06,
      "loss": 0.0047,
      "step": 10140
    },
    {
      "epoch": 5.075,
      "grad_norm": 0.4385642111301422,
      "learning_rate": 9.85e-06,
      "loss": 0.0076,
      "step": 10150
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.03708404675126076,
      "learning_rate": 9.84e-06,
      "loss": 0.0084,
      "step": 10160
    },
    {
      "epoch": 5.085,
      "grad_norm": 0.003341255709528923,
      "learning_rate": 9.83e-06,
      "loss": 0.0121,
      "step": 10170
    },
    {
      "epoch": 5.09,
      "grad_norm": 0.01704990118741989,
      "learning_rate": 9.820000000000001e-06,
      "loss": 0.0067,
      "step": 10180
    },
    {
      "epoch": 5.095,
      "grad_norm": 1.703621506690979,
      "learning_rate": 9.810000000000001e-06,
      "loss": 0.0085,
      "step": 10190
    },
    {
      "epoch": 5.1,
      "grad_norm": 6.498355388641357,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0076,
      "step": 10200
    },
    {
      "epoch": 5.105,
      "grad_norm": 1.2490177154541016,
      "learning_rate": 9.790000000000001e-06,
      "loss": 0.0098,
      "step": 10210
    },
    {
      "epoch": 5.11,
      "grad_norm": 0.0035896741319447756,
      "learning_rate": 9.780000000000001e-06,
      "loss": 0.0068,
      "step": 10220
    },
    {
      "epoch": 5.115,
      "grad_norm": 5.718334197998047,
      "learning_rate": 9.770000000000001e-06,
      "loss": 0.0198,
      "step": 10230
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.007273596245795488,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.0085,
      "step": 10240
    },
    {
      "epoch": 5.125,
      "grad_norm": 0.00197534984908998,
      "learning_rate": 9.75e-06,
      "loss": 0.0054,
      "step": 10250
    },
    {
      "epoch": 5.13,
      "grad_norm": 0.8148818612098694,
      "learning_rate": 9.74e-06,
      "loss": 0.0116,
      "step": 10260
    },
    {
      "epoch": 5.135,
      "grad_norm": 0.4440773129463196,
      "learning_rate": 9.73e-06,
      "loss": 0.0084,
      "step": 10270
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.5178650617599487,
      "learning_rate": 9.72e-06,
      "loss": 0.0039,
      "step": 10280
    },
    {
      "epoch": 5.145,
      "grad_norm": 0.3132016360759735,
      "learning_rate": 9.71e-06,
      "loss": 0.0198,
      "step": 10290
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.009442123584449291,
      "learning_rate": 9.7e-06,
      "loss": 0.0422,
      "step": 10300
    },
    {
      "epoch": 5.155,
      "grad_norm": 0.013271691277623177,
      "learning_rate": 9.69e-06,
      "loss": 0.028,
      "step": 10310
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.698413610458374,
      "learning_rate": 9.68e-06,
      "loss": 0.0119,
      "step": 10320
    },
    {
      "epoch": 5.165,
      "grad_norm": 0.023014919832348824,
      "learning_rate": 9.67e-06,
      "loss": 0.0091,
      "step": 10330
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.003792875912040472,
      "learning_rate": 9.66e-06,
      "loss": 0.0092,
      "step": 10340
    },
    {
      "epoch": 5.175,
      "grad_norm": 0.12648668885231018,
      "learning_rate": 9.65e-06,
      "loss": 0.0048,
      "step": 10350
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.5105841755867004,
      "learning_rate": 9.640000000000001e-06,
      "loss": 0.0365,
      "step": 10360
    },
    {
      "epoch": 5.185,
      "grad_norm": 0.04504968225955963,
      "learning_rate": 9.630000000000001e-06,
      "loss": 0.0266,
      "step": 10370
    },
    {
      "epoch": 5.19,
      "grad_norm": 1.0881186723709106,
      "learning_rate": 9.620000000000001e-06,
      "loss": 0.018,
      "step": 10380
    },
    {
      "epoch": 5.195,
      "grad_norm": 19.842933654785156,
      "learning_rate": 9.610000000000001e-06,
      "loss": 0.015,
      "step": 10390
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.06798414885997772,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0064,
      "step": 10400
    },
    {
      "epoch": 5.205,
      "grad_norm": 0.0085026565939188,
      "learning_rate": 9.59e-06,
      "loss": 0.0129,
      "step": 10410
    },
    {
      "epoch": 5.21,
      "grad_norm": 0.009439737536013126,
      "learning_rate": 9.58e-06,
      "loss": 0.0055,
      "step": 10420
    },
    {
      "epoch": 5.215,
      "grad_norm": 0.5643526911735535,
      "learning_rate": 9.57e-06,
      "loss": 0.008,
      "step": 10430
    },
    {
      "epoch": 5.22,
      "grad_norm": 0.002077152021229267,
      "learning_rate": 9.56e-06,
      "loss": 0.0124,
      "step": 10440
    },
    {
      "epoch": 5.225,
      "grad_norm": 0.022034652531147003,
      "learning_rate": 9.55e-06,
      "loss": 0.0092,
      "step": 10450
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.7164607048034668,
      "learning_rate": 9.54e-06,
      "loss": 0.0139,
      "step": 10460
    },
    {
      "epoch": 5.235,
      "grad_norm": 2.5287811756134033,
      "learning_rate": 9.53e-06,
      "loss": 0.0093,
      "step": 10470
    },
    {
      "epoch": 5.24,
      "grad_norm": 9.19881820678711,
      "learning_rate": 9.52e-06,
      "loss": 0.0165,
      "step": 10480
    },
    {
      "epoch": 5.245,
      "grad_norm": 0.11100485175848007,
      "learning_rate": 9.51e-06,
      "loss": 0.0231,
      "step": 10490
    },
    {
      "epoch": 5.25,
      "grad_norm": 2.3485231399536133,
      "learning_rate": 9.5e-06,
      "loss": 0.0112,
      "step": 10500
    },
    {
      "epoch": 5.255,
      "grad_norm": 0.0020907572470605373,
      "learning_rate": 9.49e-06,
      "loss": 0.0078,
      "step": 10510
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.06158725917339325,
      "learning_rate": 9.48e-06,
      "loss": 0.0186,
      "step": 10520
    },
    {
      "epoch": 5.265,
      "grad_norm": 0.7095414400100708,
      "learning_rate": 9.47e-06,
      "loss": 0.0199,
      "step": 10530
    },
    {
      "epoch": 5.27,
      "grad_norm": 0.4601736068725586,
      "learning_rate": 9.460000000000001e-06,
      "loss": 0.0156,
      "step": 10540
    },
    {
      "epoch": 5.275,
      "grad_norm": 0.0035995044745504856,
      "learning_rate": 9.450000000000001e-06,
      "loss": 0.0051,
      "step": 10550
    },
    {
      "epoch": 5.28,
      "grad_norm": 9.359042167663574,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.0186,
      "step": 10560
    },
    {
      "epoch": 5.285,
      "grad_norm": 19.80644416809082,
      "learning_rate": 9.43e-06,
      "loss": 0.016,
      "step": 10570
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.021154260262846947,
      "learning_rate": 9.42e-06,
      "loss": 0.0198,
      "step": 10580
    },
    {
      "epoch": 5.295,
      "grad_norm": 1.976051926612854,
      "learning_rate": 9.41e-06,
      "loss": 0.02,
      "step": 10590
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.007172165904194117,
      "learning_rate": 9.4e-06,
      "loss": 0.0199,
      "step": 10600
    },
    {
      "epoch": 5.305,
      "grad_norm": 0.002497751032933593,
      "learning_rate": 9.39e-06,
      "loss": 0.0047,
      "step": 10610
    },
    {
      "epoch": 5.31,
      "grad_norm": 0.06427303701639175,
      "learning_rate": 9.38e-06,
      "loss": 0.0243,
      "step": 10620
    },
    {
      "epoch": 5.315,
      "grad_norm": 0.11616607755422592,
      "learning_rate": 9.370000000000002e-06,
      "loss": 0.012,
      "step": 10630
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.4761922359466553,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.0106,
      "step": 10640
    },
    {
      "epoch": 5.325,
      "grad_norm": 0.9288749694824219,
      "learning_rate": 9.350000000000002e-06,
      "loss": 0.0053,
      "step": 10650
    },
    {
      "epoch": 5.33,
      "grad_norm": 4.479211330413818,
      "learning_rate": 9.340000000000002e-06,
      "loss": 0.0109,
      "step": 10660
    },
    {
      "epoch": 5.335,
      "grad_norm": 0.002485110191628337,
      "learning_rate": 9.33e-06,
      "loss": 0.0151,
      "step": 10670
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.9356063604354858,
      "learning_rate": 9.32e-06,
      "loss": 0.0057,
      "step": 10680
    },
    {
      "epoch": 5.345,
      "grad_norm": 0.007471263408660889,
      "learning_rate": 9.31e-06,
      "loss": 0.01,
      "step": 10690
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.015404700301587582,
      "learning_rate": 9.3e-06,
      "loss": 0.023,
      "step": 10700
    },
    {
      "epoch": 5.355,
      "grad_norm": 0.009377715177834034,
      "learning_rate": 9.29e-06,
      "loss": 0.0069,
      "step": 10710
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.008841510862112045,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.0202,
      "step": 10720
    },
    {
      "epoch": 5.365,
      "grad_norm": 0.02707093209028244,
      "learning_rate": 9.270000000000001e-06,
      "loss": 0.0068,
      "step": 10730
    },
    {
      "epoch": 5.37,
      "grad_norm": 0.7291133999824524,
      "learning_rate": 9.260000000000001e-06,
      "loss": 0.0193,
      "step": 10740
    },
    {
      "epoch": 5.375,
      "grad_norm": 0.5446827411651611,
      "learning_rate": 9.250000000000001e-06,
      "loss": 0.0106,
      "step": 10750
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.9597292542457581,
      "learning_rate": 9.240000000000001e-06,
      "loss": 0.0135,
      "step": 10760
    },
    {
      "epoch": 5.385,
      "grad_norm": 0.5978193879127502,
      "learning_rate": 9.230000000000001e-06,
      "loss": 0.0056,
      "step": 10770
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.7808690667152405,
      "learning_rate": 9.220000000000002e-06,
      "loss": 0.0069,
      "step": 10780
    },
    {
      "epoch": 5.395,
      "grad_norm": 0.004302020184695721,
      "learning_rate": 9.210000000000002e-06,
      "loss": 0.019,
      "step": 10790
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.32702434062957764,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0123,
      "step": 10800
    },
    {
      "epoch": 5.405,
      "grad_norm": 1.4777315855026245,
      "learning_rate": 9.190000000000002e-06,
      "loss": 0.0112,
      "step": 10810
    },
    {
      "epoch": 5.41,
      "grad_norm": 0.14748646318912506,
      "learning_rate": 9.180000000000002e-06,
      "loss": 0.0242,
      "step": 10820
    },
    {
      "epoch": 5.415,
      "grad_norm": 0.012443497776985168,
      "learning_rate": 9.17e-06,
      "loss": 0.0088,
      "step": 10830
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.06931690126657486,
      "learning_rate": 9.16e-06,
      "loss": 0.0119,
      "step": 10840
    },
    {
      "epoch": 5.425,
      "grad_norm": 0.0023644042667001486,
      "learning_rate": 9.15e-06,
      "loss": 0.017,
      "step": 10850
    },
    {
      "epoch": 5.43,
      "grad_norm": 0.004942167084664106,
      "learning_rate": 9.14e-06,
      "loss": 0.0103,
      "step": 10860
    },
    {
      "epoch": 5.435,
      "grad_norm": 0.03963350132107735,
      "learning_rate": 9.13e-06,
      "loss": 0.0147,
      "step": 10870
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.38364076614379883,
      "learning_rate": 9.12e-06,
      "loss": 0.021,
      "step": 10880
    },
    {
      "epoch": 5.445,
      "grad_norm": 0.013009179383516312,
      "learning_rate": 9.110000000000001e-06,
      "loss": 0.0055,
      "step": 10890
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.0063187796622514725,
      "learning_rate": 9.100000000000001e-06,
      "loss": 0.0114,
      "step": 10900
    },
    {
      "epoch": 5.455,
      "grad_norm": 0.7971348762512207,
      "learning_rate": 9.090000000000001e-06,
      "loss": 0.0111,
      "step": 10910
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.8807374238967896,
      "learning_rate": 9.080000000000001e-06,
      "loss": 0.0154,
      "step": 10920
    },
    {
      "epoch": 5.465,
      "grad_norm": 0.015316336415708065,
      "learning_rate": 9.070000000000001e-06,
      "loss": 0.0191,
      "step": 10930
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.003939831629395485,
      "learning_rate": 9.060000000000001e-06,
      "loss": 0.0101,
      "step": 10940
    },
    {
      "epoch": 5.475,
      "grad_norm": 0.006312931887805462,
      "learning_rate": 9.050000000000001e-06,
      "loss": 0.0125,
      "step": 10950
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.011304580606520176,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.0079,
      "step": 10960
    },
    {
      "epoch": 5.485,
      "grad_norm": 0.007895328104496002,
      "learning_rate": 9.030000000000002e-06,
      "loss": 0.0164,
      "step": 10970
    },
    {
      "epoch": 5.49,
      "grad_norm": 0.12338810414075851,
      "learning_rate": 9.020000000000002e-06,
      "loss": 0.0049,
      "step": 10980
    },
    {
      "epoch": 5.495,
      "grad_norm": 0.26077985763549805,
      "learning_rate": 9.01e-06,
      "loss": 0.0176,
      "step": 10990
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.432241201400757,
      "learning_rate": 9e-06,
      "loss": 0.0251,
      "step": 11000
    },
    {
      "epoch": 5.505,
      "grad_norm": 0.25693467259407043,
      "learning_rate": 8.99e-06,
      "loss": 0.0088,
      "step": 11010
    },
    {
      "epoch": 5.51,
      "grad_norm": 0.0544440783560276,
      "learning_rate": 8.98e-06,
      "loss": 0.0043,
      "step": 11020
    },
    {
      "epoch": 5.515,
      "grad_norm": 0.5466721653938293,
      "learning_rate": 8.97e-06,
      "loss": 0.0108,
      "step": 11030
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.012962053529918194,
      "learning_rate": 8.96e-06,
      "loss": 0.0122,
      "step": 11040
    },
    {
      "epoch": 5.525,
      "grad_norm": 8.065438270568848,
      "learning_rate": 8.95e-06,
      "loss": 0.0252,
      "step": 11050
    },
    {
      "epoch": 5.53,
      "grad_norm": 0.20638667047023773,
      "learning_rate": 8.94e-06,
      "loss": 0.0085,
      "step": 11060
    },
    {
      "epoch": 5.535,
      "grad_norm": 0.008212551474571228,
      "learning_rate": 8.930000000000001e-06,
      "loss": 0.0173,
      "step": 11070
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.4123368263244629,
      "learning_rate": 8.920000000000001e-06,
      "loss": 0.0203,
      "step": 11080
    },
    {
      "epoch": 5.545,
      "grad_norm": 0.6468944549560547,
      "learning_rate": 8.910000000000001e-06,
      "loss": 0.0163,
      "step": 11090
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.3876558840274811,
      "learning_rate": 8.900000000000001e-06,
      "loss": 0.0147,
      "step": 11100
    },
    {
      "epoch": 5.555,
      "grad_norm": 0.6702349185943604,
      "learning_rate": 8.890000000000001e-06,
      "loss": 0.0106,
      "step": 11110
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 0.5378020405769348,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.0182,
      "step": 11120
    },
    {
      "epoch": 5.5649999999999995,
      "grad_norm": 0.1489594727754593,
      "learning_rate": 8.870000000000001e-06,
      "loss": 0.0072,
      "step": 11130
    },
    {
      "epoch": 5.57,
      "grad_norm": 2.0189733505249023,
      "learning_rate": 8.860000000000002e-06,
      "loss": 0.016,
      "step": 11140
    },
    {
      "epoch": 5.575,
      "grad_norm": 10.183005332946777,
      "learning_rate": 8.85e-06,
      "loss": 0.0369,
      "step": 11150
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.649948239326477,
      "learning_rate": 8.84e-06,
      "loss": 0.0155,
      "step": 11160
    },
    {
      "epoch": 5.585,
      "grad_norm": 1.5699862241744995,
      "learning_rate": 8.83e-06,
      "loss": 0.0093,
      "step": 11170
    },
    {
      "epoch": 5.59,
      "grad_norm": 0.010702274739742279,
      "learning_rate": 8.82e-06,
      "loss": 0.0034,
      "step": 11180
    },
    {
      "epoch": 5.595,
      "grad_norm": 0.022024482488632202,
      "learning_rate": 8.81e-06,
      "loss": 0.0093,
      "step": 11190
    },
    {
      "epoch": 5.6,
      "grad_norm": 13.767273902893066,
      "learning_rate": 8.8e-06,
      "loss": 0.0098,
      "step": 11200
    },
    {
      "epoch": 5.605,
      "grad_norm": 0.010592415928840637,
      "learning_rate": 8.79e-06,
      "loss": 0.017,
      "step": 11210
    },
    {
      "epoch": 5.61,
      "grad_norm": 0.023751284927129745,
      "learning_rate": 8.78e-06,
      "loss": 0.0093,
      "step": 11220
    },
    {
      "epoch": 5.615,
      "grad_norm": 0.006183592602610588,
      "learning_rate": 8.77e-06,
      "loss": 0.0034,
      "step": 11230
    },
    {
      "epoch": 5.62,
      "grad_norm": 1.1725188493728638,
      "learning_rate": 8.76e-06,
      "loss": 0.0201,
      "step": 11240
    },
    {
      "epoch": 5.625,
      "grad_norm": 0.09295964986085892,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.0095,
      "step": 11250
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.6363978385925293,
      "learning_rate": 8.740000000000001e-06,
      "loss": 0.0038,
      "step": 11260
    },
    {
      "epoch": 5.635,
      "grad_norm": 0.6756137609481812,
      "learning_rate": 8.730000000000001e-06,
      "loss": 0.0125,
      "step": 11270
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.20947562158107758,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.0109,
      "step": 11280
    },
    {
      "epoch": 5.645,
      "grad_norm": 0.6644493341445923,
      "learning_rate": 8.710000000000001e-06,
      "loss": 0.011,
      "step": 11290
    },
    {
      "epoch": 5.65,
      "grad_norm": 2.767594575881958,
      "learning_rate": 8.700000000000001e-06,
      "loss": 0.0168,
      "step": 11300
    },
    {
      "epoch": 5.655,
      "grad_norm": 0.008450849913060665,
      "learning_rate": 8.690000000000002e-06,
      "loss": 0.0128,
      "step": 11310
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.08265778422355652,
      "learning_rate": 8.68e-06,
      "loss": 0.0111,
      "step": 11320
    },
    {
      "epoch": 5.665,
      "grad_norm": 1.343044400215149,
      "learning_rate": 8.67e-06,
      "loss": 0.0083,
      "step": 11330
    },
    {
      "epoch": 5.67,
      "grad_norm": 4.026763916015625,
      "learning_rate": 8.66e-06,
      "loss": 0.0298,
      "step": 11340
    },
    {
      "epoch": 5.675,
      "grad_norm": 0.5184715986251831,
      "learning_rate": 8.65e-06,
      "loss": 0.0115,
      "step": 11350
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.4257987141609192,
      "learning_rate": 8.64e-06,
      "loss": 0.0095,
      "step": 11360
    },
    {
      "epoch": 5.6850000000000005,
      "grad_norm": 12.46027946472168,
      "learning_rate": 8.63e-06,
      "loss": 0.0201,
      "step": 11370
    },
    {
      "epoch": 5.6899999999999995,
      "grad_norm": 0.00522935576736927,
      "learning_rate": 8.62e-06,
      "loss": 0.0048,
      "step": 11380
    },
    {
      "epoch": 5.695,
      "grad_norm": 2.904492139816284,
      "learning_rate": 8.61e-06,
      "loss": 0.0247,
      "step": 11390
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.003305532271042466,
      "learning_rate": 8.6e-06,
      "loss": 0.0024,
      "step": 11400
    },
    {
      "epoch": 5.705,
      "grad_norm": 0.6223809123039246,
      "learning_rate": 8.59e-06,
      "loss": 0.0067,
      "step": 11410
    },
    {
      "epoch": 5.71,
      "grad_norm": 0.03795816749334335,
      "learning_rate": 8.580000000000001e-06,
      "loss": 0.0032,
      "step": 11420
    },
    {
      "epoch": 5.715,
      "grad_norm": 0.7459955811500549,
      "learning_rate": 8.570000000000001e-06,
      "loss": 0.0218,
      "step": 11430
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.006373936776071787,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.0029,
      "step": 11440
    },
    {
      "epoch": 5.725,
      "grad_norm": 1.1250572204589844,
      "learning_rate": 8.550000000000001e-06,
      "loss": 0.0057,
      "step": 11450
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.05155220627784729,
      "learning_rate": 8.540000000000001e-06,
      "loss": 0.0172,
      "step": 11460
    },
    {
      "epoch": 5.735,
      "grad_norm": 0.002516891108825803,
      "learning_rate": 8.530000000000001e-06,
      "loss": 0.0024,
      "step": 11470
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.00112080667167902,
      "learning_rate": 8.52e-06,
      "loss": 0.0059,
      "step": 11480
    },
    {
      "epoch": 5.745,
      "grad_norm": 2.4787991046905518,
      "learning_rate": 8.51e-06,
      "loss": 0.0138,
      "step": 11490
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.01855331100523472,
      "learning_rate": 8.5e-06,
      "loss": 0.0044,
      "step": 11500
    },
    {
      "epoch": 5.755,
      "grad_norm": 0.3891957700252533,
      "learning_rate": 8.49e-06,
      "loss": 0.0262,
      "step": 11510
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.1300641298294067,
      "learning_rate": 8.48e-06,
      "loss": 0.0138,
      "step": 11520
    },
    {
      "epoch": 5.765,
      "grad_norm": 1.3322114944458008,
      "learning_rate": 8.47e-06,
      "loss": 0.0073,
      "step": 11530
    },
    {
      "epoch": 5.77,
      "grad_norm": 1.145961880683899,
      "learning_rate": 8.46e-06,
      "loss": 0.0067,
      "step": 11540
    },
    {
      "epoch": 5.775,
      "grad_norm": 2.0452494621276855,
      "learning_rate": 8.45e-06,
      "loss": 0.0139,
      "step": 11550
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.9988259673118591,
      "learning_rate": 8.44e-06,
      "loss": 0.0094,
      "step": 11560
    },
    {
      "epoch": 5.785,
      "grad_norm": 0.2092854231595993,
      "learning_rate": 8.43e-06,
      "loss": 0.0081,
      "step": 11570
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.30283814668655396,
      "learning_rate": 8.42e-06,
      "loss": 0.007,
      "step": 11580
    },
    {
      "epoch": 5.795,
      "grad_norm": 0.9396481513977051,
      "learning_rate": 8.41e-06,
      "loss": 0.0231,
      "step": 11590
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.0012698577484115958,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0065,
      "step": 11600
    },
    {
      "epoch": 5.805,
      "grad_norm": 5.280235290527344,
      "learning_rate": 8.390000000000001e-06,
      "loss": 0.0274,
      "step": 11610
    },
    {
      "epoch": 5.8100000000000005,
      "grad_norm": 0.767734944820404,
      "learning_rate": 8.380000000000001e-06,
      "loss": 0.0127,
      "step": 11620
    },
    {
      "epoch": 5.8149999999999995,
      "grad_norm": 2.7392542362213135,
      "learning_rate": 8.370000000000001e-06,
      "loss": 0.0139,
      "step": 11630
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.5067119598388672,
      "learning_rate": 8.36e-06,
      "loss": 0.0223,
      "step": 11640
    },
    {
      "epoch": 5.825,
      "grad_norm": 0.0024552540853619576,
      "learning_rate": 8.35e-06,
      "loss": 0.0083,
      "step": 11650
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.04511543735861778,
      "learning_rate": 8.34e-06,
      "loss": 0.0205,
      "step": 11660
    },
    {
      "epoch": 5.835,
      "grad_norm": 0.8018801808357239,
      "learning_rate": 8.33e-06,
      "loss": 0.0104,
      "step": 11670
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.695376992225647,
      "learning_rate": 8.32e-06,
      "loss": 0.0161,
      "step": 11680
    },
    {
      "epoch": 5.845,
      "grad_norm": 2.0654475688934326,
      "learning_rate": 8.31e-06,
      "loss": 0.0089,
      "step": 11690
    },
    {
      "epoch": 5.85,
      "grad_norm": 2.8721375465393066,
      "learning_rate": 8.3e-06,
      "loss": 0.0113,
      "step": 11700
    },
    {
      "epoch": 5.855,
      "grad_norm": 0.0048181600868701935,
      "learning_rate": 8.29e-06,
      "loss": 0.0149,
      "step": 11710
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.5190703272819519,
      "learning_rate": 8.28e-06,
      "loss": 0.011,
      "step": 11720
    },
    {
      "epoch": 5.865,
      "grad_norm": 0.6084385514259338,
      "learning_rate": 8.27e-06,
      "loss": 0.0023,
      "step": 11730
    },
    {
      "epoch": 5.87,
      "grad_norm": 0.47846752405166626,
      "learning_rate": 8.26e-06,
      "loss": 0.0117,
      "step": 11740
    },
    {
      "epoch": 5.875,
      "grad_norm": 0.0996946170926094,
      "learning_rate": 8.25e-06,
      "loss": 0.0102,
      "step": 11750
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.9311425685882568,
      "learning_rate": 8.24e-06,
      "loss": 0.0232,
      "step": 11760
    },
    {
      "epoch": 5.885,
      "grad_norm": 0.004619759041815996,
      "learning_rate": 8.23e-06,
      "loss": 0.0146,
      "step": 11770
    },
    {
      "epoch": 5.89,
      "grad_norm": 0.00796146597713232,
      "learning_rate": 8.220000000000001e-06,
      "loss": 0.0076,
      "step": 11780
    },
    {
      "epoch": 5.895,
      "grad_norm": 0.0886722281575203,
      "learning_rate": 8.210000000000001e-06,
      "loss": 0.0047,
      "step": 11790
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.29535147547721863,
      "learning_rate": 8.2e-06,
      "loss": 0.0125,
      "step": 11800
    },
    {
      "epoch": 5.905,
      "grad_norm": 1.3561686277389526,
      "learning_rate": 8.19e-06,
      "loss": 0.0103,
      "step": 11810
    },
    {
      "epoch": 5.91,
      "grad_norm": 0.1896534413099289,
      "learning_rate": 8.18e-06,
      "loss": 0.0163,
      "step": 11820
    },
    {
      "epoch": 5.915,
      "grad_norm": 0.03840538114309311,
      "learning_rate": 8.17e-06,
      "loss": 0.006,
      "step": 11830
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.2815784811973572,
      "learning_rate": 8.16e-06,
      "loss": 0.0085,
      "step": 11840
    },
    {
      "epoch": 5.925,
      "grad_norm": 0.0006702604587189853,
      "learning_rate": 8.15e-06,
      "loss": 0.0074,
      "step": 11850
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.22746641933918,
      "learning_rate": 8.14e-06,
      "loss": 0.0145,
      "step": 11860
    },
    {
      "epoch": 5.9350000000000005,
      "grad_norm": 0.0022439775057137012,
      "learning_rate": 8.13e-06,
      "loss": 0.035,
      "step": 11870
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 0.5135675072669983,
      "learning_rate": 8.120000000000002e-06,
      "loss": 0.0171,
      "step": 11880
    },
    {
      "epoch": 5.945,
      "grad_norm": 0.005269171670079231,
      "learning_rate": 8.110000000000002e-06,
      "loss": 0.0029,
      "step": 11890
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.07386285066604614,
      "learning_rate": 8.1e-06,
      "loss": 0.0284,
      "step": 11900
    },
    {
      "epoch": 5.955,
      "grad_norm": 0.11206867545843124,
      "learning_rate": 8.09e-06,
      "loss": 0.0087,
      "step": 11910
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.37152501940727234,
      "learning_rate": 8.08e-06,
      "loss": 0.0103,
      "step": 11920
    },
    {
      "epoch": 5.965,
      "grad_norm": 0.002623904263600707,
      "learning_rate": 8.07e-06,
      "loss": 0.0135,
      "step": 11930
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.11714129894971848,
      "learning_rate": 8.06e-06,
      "loss": 0.0249,
      "step": 11940
    },
    {
      "epoch": 5.975,
      "grad_norm": 0.03570830821990967,
      "learning_rate": 8.050000000000001e-06,
      "loss": 0.0193,
      "step": 11950
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.0764665603637695,
      "learning_rate": 8.040000000000001e-06,
      "loss": 0.0121,
      "step": 11960
    },
    {
      "epoch": 5.985,
      "grad_norm": 0.002457525348290801,
      "learning_rate": 8.030000000000001e-06,
      "loss": 0.0139,
      "step": 11970
    },
    {
      "epoch": 5.99,
      "grad_norm": 2.3307180404663086,
      "learning_rate": 8.020000000000001e-06,
      "loss": 0.0223,
      "step": 11980
    },
    {
      "epoch": 5.995,
      "grad_norm": 0.0036757008638232946,
      "learning_rate": 8.010000000000001e-06,
      "loss": 0.0123,
      "step": 11990
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.19938555359840393,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0032,
      "step": 12000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9928165110851809,
      "eval_f1": 0.9722730471498946,
      "eval_loss": 0.022050872445106506,
      "eval_precision": 0.9726837510560405,
      "eval_recall": 0.971862689926843,
      "eval_runtime": 914.5068,
      "eval_samples_per_second": 29.998,
      "eval_steps_per_second": 0.938,
      "step": 12000
    },
    {
      "epoch": 6.005,
      "grad_norm": 0.08859703689813614,
      "learning_rate": 7.990000000000001e-06,
      "loss": 0.0116,
      "step": 12010
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.9591488242149353,
      "learning_rate": 7.980000000000002e-06,
      "loss": 0.0093,
      "step": 12020
    },
    {
      "epoch": 6.015,
      "grad_norm": 2.636195182800293,
      "learning_rate": 7.970000000000002e-06,
      "loss": 0.0237,
      "step": 12030
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.010339939035475254,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.0068,
      "step": 12040
    },
    {
      "epoch": 6.025,
      "grad_norm": 0.023251567035913467,
      "learning_rate": 7.950000000000002e-06,
      "loss": 0.0113,
      "step": 12050
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.44353175163269043,
      "learning_rate": 7.94e-06,
      "loss": 0.006,
      "step": 12060
    },
    {
      "epoch": 6.035,
      "grad_norm": 2.923036813735962,
      "learning_rate": 7.93e-06,
      "loss": 0.007,
      "step": 12070
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.24808618426322937,
      "learning_rate": 7.92e-06,
      "loss": 0.0054,
      "step": 12080
    },
    {
      "epoch": 6.045,
      "grad_norm": 0.004165097139775753,
      "learning_rate": 7.91e-06,
      "loss": 0.0064,
      "step": 12090
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.013553047552704811,
      "learning_rate": 7.9e-06,
      "loss": 0.0338,
      "step": 12100
    },
    {
      "epoch": 6.055,
      "grad_norm": 0.004380968399345875,
      "learning_rate": 7.89e-06,
      "loss": 0.0069,
      "step": 12110
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.638887882232666,
      "learning_rate": 7.88e-06,
      "loss": 0.0097,
      "step": 12120
    },
    {
      "epoch": 6.065,
      "grad_norm": 0.6028903126716614,
      "learning_rate": 7.870000000000001e-06,
      "loss": 0.0122,
      "step": 12130
    },
    {
      "epoch": 6.07,
      "grad_norm": 0.21518537402153015,
      "learning_rate": 7.860000000000001e-06,
      "loss": 0.0037,
      "step": 12140
    },
    {
      "epoch": 6.075,
      "grad_norm": 1.1598896980285645,
      "learning_rate": 7.850000000000001e-06,
      "loss": 0.0116,
      "step": 12150
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.3804015517234802,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.0098,
      "step": 12160
    },
    {
      "epoch": 6.085,
      "grad_norm": 0.1702299863100052,
      "learning_rate": 7.830000000000001e-06,
      "loss": 0.0031,
      "step": 12170
    },
    {
      "epoch": 6.09,
      "grad_norm": 0.004333387594670057,
      "learning_rate": 7.820000000000001e-06,
      "loss": 0.0224,
      "step": 12180
    },
    {
      "epoch": 6.095,
      "grad_norm": 0.33750927448272705,
      "learning_rate": 7.810000000000001e-06,
      "loss": 0.0121,
      "step": 12190
    },
    {
      "epoch": 6.1,
      "grad_norm": 1.361976146697998,
      "learning_rate": 7.800000000000002e-06,
      "loss": 0.0058,
      "step": 12200
    },
    {
      "epoch": 6.105,
      "grad_norm": 0.03193601593375206,
      "learning_rate": 7.790000000000002e-06,
      "loss": 0.0162,
      "step": 12210
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.3816908597946167,
      "learning_rate": 7.78e-06,
      "loss": 0.0138,
      "step": 12220
    },
    {
      "epoch": 6.115,
      "grad_norm": 0.06496002525091171,
      "learning_rate": 7.77e-06,
      "loss": 0.0016,
      "step": 12230
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.461588054895401,
      "learning_rate": 7.76e-06,
      "loss": 0.025,
      "step": 12240
    },
    {
      "epoch": 6.125,
      "grad_norm": 0.007203151937574148,
      "learning_rate": 7.75e-06,
      "loss": 0.0079,
      "step": 12250
    },
    {
      "epoch": 6.13,
      "grad_norm": 0.27663031220436096,
      "learning_rate": 7.74e-06,
      "loss": 0.0112,
      "step": 12260
    },
    {
      "epoch": 6.135,
      "grad_norm": 0.28955644369125366,
      "learning_rate": 7.73e-06,
      "loss": 0.0063,
      "step": 12270
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.6990833282470703,
      "learning_rate": 7.72e-06,
      "loss": 0.0045,
      "step": 12280
    },
    {
      "epoch": 6.145,
      "grad_norm": 1.7161495685577393,
      "learning_rate": 7.71e-06,
      "loss": 0.0075,
      "step": 12290
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.8446741700172424,
      "learning_rate": 7.7e-06,
      "loss": 0.0162,
      "step": 12300
    },
    {
      "epoch": 6.155,
      "grad_norm": 0.006340605206787586,
      "learning_rate": 7.690000000000001e-06,
      "loss": 0.0052,
      "step": 12310
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.003682394977658987,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.0082,
      "step": 12320
    },
    {
      "epoch": 6.165,
      "grad_norm": 1.844035029411316,
      "learning_rate": 7.670000000000001e-06,
      "loss": 0.0111,
      "step": 12330
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.003284139558672905,
      "learning_rate": 7.660000000000001e-06,
      "loss": 0.0108,
      "step": 12340
    },
    {
      "epoch": 6.175,
      "grad_norm": 1.1338837146759033,
      "learning_rate": 7.650000000000001e-06,
      "loss": 0.0114,
      "step": 12350
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.0660049170255661,
      "learning_rate": 7.640000000000001e-06,
      "loss": 0.0245,
      "step": 12360
    },
    {
      "epoch": 6.185,
      "grad_norm": 0.003326726146042347,
      "learning_rate": 7.630000000000001e-06,
      "loss": 0.0145,
      "step": 12370
    },
    {
      "epoch": 6.19,
      "grad_norm": 1.8996999263763428,
      "learning_rate": 7.620000000000001e-06,
      "loss": 0.0176,
      "step": 12380
    },
    {
      "epoch": 6.195,
      "grad_norm": 0.0024457003455609083,
      "learning_rate": 7.610000000000001e-06,
      "loss": 0.0109,
      "step": 12390
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.0424147844314575,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0092,
      "step": 12400
    },
    {
      "epoch": 6.205,
      "grad_norm": 0.2678811252117157,
      "learning_rate": 7.590000000000001e-06,
      "loss": 0.0028,
      "step": 12410
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.1197073832154274,
      "learning_rate": 7.58e-06,
      "loss": 0.0192,
      "step": 12420
    },
    {
      "epoch": 6.215,
      "grad_norm": 0.826169490814209,
      "learning_rate": 7.57e-06,
      "loss": 0.0134,
      "step": 12430
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.1264950931072235,
      "learning_rate": 7.5600000000000005e-06,
      "loss": 0.022,
      "step": 12440
    },
    {
      "epoch": 6.225,
      "grad_norm": 0.6275538802146912,
      "learning_rate": 7.5500000000000006e-06,
      "loss": 0.0118,
      "step": 12450
    },
    {
      "epoch": 6.23,
      "grad_norm": 0.0035595553927123547,
      "learning_rate": 7.540000000000001e-06,
      "loss": 0.0018,
      "step": 12460
    },
    {
      "epoch": 6.235,
      "grad_norm": 0.4926718473434448,
      "learning_rate": 7.530000000000001e-06,
      "loss": 0.0068,
      "step": 12470
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.10208996385335922,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.0078,
      "step": 12480
    },
    {
      "epoch": 6.245,
      "grad_norm": 0.0028298581019043922,
      "learning_rate": 7.510000000000001e-06,
      "loss": 0.0074,
      "step": 12490
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.1121075451374054,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0062,
      "step": 12500
    },
    {
      "epoch": 6.255,
      "grad_norm": 0.23568123579025269,
      "learning_rate": 7.49e-06,
      "loss": 0.0121,
      "step": 12510
    },
    {
      "epoch": 6.26,
      "grad_norm": 13.489957809448242,
      "learning_rate": 7.48e-06,
      "loss": 0.0093,
      "step": 12520
    },
    {
      "epoch": 6.265,
      "grad_norm": 0.008250284940004349,
      "learning_rate": 7.4700000000000005e-06,
      "loss": 0.0033,
      "step": 12530
    },
    {
      "epoch": 6.27,
      "grad_norm": 0.5336095094680786,
      "learning_rate": 7.4600000000000006e-06,
      "loss": 0.0079,
      "step": 12540
    },
    {
      "epoch": 6.275,
      "grad_norm": 0.0012366907903924584,
      "learning_rate": 7.450000000000001e-06,
      "loss": 0.0097,
      "step": 12550
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.0028453627601265907,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.0117,
      "step": 12560
    },
    {
      "epoch": 6.285,
      "grad_norm": 0.001790586276911199,
      "learning_rate": 7.430000000000001e-06,
      "loss": 0.0111,
      "step": 12570
    },
    {
      "epoch": 6.29,
      "grad_norm": 0.0020020913798362017,
      "learning_rate": 7.420000000000001e-06,
      "loss": 0.011,
      "step": 12580
    },
    {
      "epoch": 6.295,
      "grad_norm": 0.09801097959280014,
      "learning_rate": 7.41e-06,
      "loss": 0.0108,
      "step": 12590
    },
    {
      "epoch": 6.3,
      "grad_norm": 12.471318244934082,
      "learning_rate": 7.4e-06,
      "loss": 0.0172,
      "step": 12600
    },
    {
      "epoch": 6.305,
      "grad_norm": 0.5478127002716064,
      "learning_rate": 7.39e-06,
      "loss": 0.0049,
      "step": 12610
    },
    {
      "epoch": 6.31,
      "grad_norm": 0.003091375343501568,
      "learning_rate": 7.3800000000000005e-06,
      "loss": 0.0089,
      "step": 12620
    },
    {
      "epoch": 6.315,
      "grad_norm": 0.008396740071475506,
      "learning_rate": 7.370000000000001e-06,
      "loss": 0.0159,
      "step": 12630
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.003047103062272072,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.0036,
      "step": 12640
    },
    {
      "epoch": 6.325,
      "grad_norm": 1.0882192850112915,
      "learning_rate": 7.350000000000001e-06,
      "loss": 0.0088,
      "step": 12650
    },
    {
      "epoch": 6.33,
      "grad_norm": 0.001859090058133006,
      "learning_rate": 7.340000000000001e-06,
      "loss": 0.0079,
      "step": 12660
    },
    {
      "epoch": 6.335,
      "grad_norm": 0.00118129956535995,
      "learning_rate": 7.33e-06,
      "loss": 0.0131,
      "step": 12670
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.005328694358468056,
      "learning_rate": 7.32e-06,
      "loss": 0.0125,
      "step": 12680
    },
    {
      "epoch": 6.345,
      "grad_norm": 2.2514779567718506,
      "learning_rate": 7.31e-06,
      "loss": 0.01,
      "step": 12690
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.7417783141136169,
      "learning_rate": 7.3e-06,
      "loss": 0.0083,
      "step": 12700
    },
    {
      "epoch": 6.355,
      "grad_norm": 0.6480203866958618,
      "learning_rate": 7.2900000000000005e-06,
      "loss": 0.007,
      "step": 12710
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.6233960390090942,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.0103,
      "step": 12720
    },
    {
      "epoch": 6.365,
      "grad_norm": 0.28135809302330017,
      "learning_rate": 7.270000000000001e-06,
      "loss": 0.0059,
      "step": 12730
    },
    {
      "epoch": 6.37,
      "grad_norm": 0.03198859468102455,
      "learning_rate": 7.260000000000001e-06,
      "loss": 0.0072,
      "step": 12740
    },
    {
      "epoch": 6.375,
      "grad_norm": 0.25561538338661194,
      "learning_rate": 7.25e-06,
      "loss": 0.0214,
      "step": 12750
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.424250841140747,
      "learning_rate": 7.24e-06,
      "loss": 0.0074,
      "step": 12760
    },
    {
      "epoch": 6.385,
      "grad_norm": 0.1768547147512436,
      "learning_rate": 7.23e-06,
      "loss": 0.0093,
      "step": 12770
    },
    {
      "epoch": 6.39,
      "grad_norm": 0.03908007591962814,
      "learning_rate": 7.22e-06,
      "loss": 0.0039,
      "step": 12780
    },
    {
      "epoch": 6.395,
      "grad_norm": 0.047701213508844376,
      "learning_rate": 7.2100000000000004e-06,
      "loss": 0.0079,
      "step": 12790
    },
    {
      "epoch": 6.4,
      "grad_norm": 3.599135398864746,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0266,
      "step": 12800
    },
    {
      "epoch": 6.405,
      "grad_norm": 0.0026320135220885277,
      "learning_rate": 7.190000000000001e-06,
      "loss": 0.0038,
      "step": 12810
    },
    {
      "epoch": 6.41,
      "grad_norm": 0.14446164667606354,
      "learning_rate": 7.180000000000001e-06,
      "loss": 0.0085,
      "step": 12820
    },
    {
      "epoch": 6.415,
      "grad_norm": 0.8550339341163635,
      "learning_rate": 7.17e-06,
      "loss": 0.0048,
      "step": 12830
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.4080369472503662,
      "learning_rate": 7.16e-06,
      "loss": 0.0069,
      "step": 12840
    },
    {
      "epoch": 6.425,
      "grad_norm": 0.5402479767799377,
      "learning_rate": 7.15e-06,
      "loss": 0.0062,
      "step": 12850
    },
    {
      "epoch": 6.43,
      "grad_norm": 0.1322242021560669,
      "learning_rate": 7.14e-06,
      "loss": 0.0077,
      "step": 12860
    },
    {
      "epoch": 6.435,
      "grad_norm": 1.2304834127426147,
      "learning_rate": 7.13e-06,
      "loss": 0.0057,
      "step": 12870
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.07780638337135315,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.0132,
      "step": 12880
    },
    {
      "epoch": 6.445,
      "grad_norm": 0.0098424656316638,
      "learning_rate": 7.1100000000000005e-06,
      "loss": 0.0085,
      "step": 12890
    },
    {
      "epoch": 6.45,
      "grad_norm": 2.2848803997039795,
      "learning_rate": 7.100000000000001e-06,
      "loss": 0.0133,
      "step": 12900
    },
    {
      "epoch": 6.455,
      "grad_norm": 0.04975098744034767,
      "learning_rate": 7.09e-06,
      "loss": 0.0162,
      "step": 12910
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.0013771714875474572,
      "learning_rate": 7.08e-06,
      "loss": 0.0119,
      "step": 12920
    },
    {
      "epoch": 6.465,
      "grad_norm": 6.273162364959717,
      "learning_rate": 7.07e-06,
      "loss": 0.0062,
      "step": 12930
    },
    {
      "epoch": 6.47,
      "grad_norm": 0.26005998253822327,
      "learning_rate": 7.06e-06,
      "loss": 0.0106,
      "step": 12940
    },
    {
      "epoch": 6.475,
      "grad_norm": 0.10030384361743927,
      "learning_rate": 7.05e-06,
      "loss": 0.0161,
      "step": 12950
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.0032325584907084703,
      "learning_rate": 7.04e-06,
      "loss": 0.0049,
      "step": 12960
    },
    {
      "epoch": 6.485,
      "grad_norm": 3.115670680999756,
      "learning_rate": 7.0300000000000005e-06,
      "loss": 0.0163,
      "step": 12970
    },
    {
      "epoch": 6.49,
      "grad_norm": 0.3201257288455963,
      "learning_rate": 7.0200000000000006e-06,
      "loss": 0.0061,
      "step": 12980
    },
    {
      "epoch": 6.495,
      "grad_norm": 3.3219339847564697,
      "learning_rate": 7.01e-06,
      "loss": 0.0199,
      "step": 12990
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.6922703981399536,
      "learning_rate": 7e-06,
      "loss": 0.0058,
      "step": 13000
    },
    {
      "epoch": 6.505,
      "grad_norm": 0.004247790668159723,
      "learning_rate": 6.99e-06,
      "loss": 0.0029,
      "step": 13010
    },
    {
      "epoch": 6.51,
      "grad_norm": 0.011301260441541672,
      "learning_rate": 6.98e-06,
      "loss": 0.0109,
      "step": 13020
    },
    {
      "epoch": 6.515,
      "grad_norm": 3.1290383338928223,
      "learning_rate": 6.97e-06,
      "loss": 0.0208,
      "step": 13030
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.4014192521572113,
      "learning_rate": 6.96e-06,
      "loss": 0.0088,
      "step": 13040
    },
    {
      "epoch": 6.525,
      "grad_norm": 0.004120540339499712,
      "learning_rate": 6.95e-06,
      "loss": 0.004,
      "step": 13050
    },
    {
      "epoch": 6.53,
      "grad_norm": 0.0012842784635722637,
      "learning_rate": 6.9400000000000005e-06,
      "loss": 0.0146,
      "step": 13060
    },
    {
      "epoch": 6.535,
      "grad_norm": 1.820344090461731,
      "learning_rate": 6.93e-06,
      "loss": 0.0138,
      "step": 13070
    },
    {
      "epoch": 6.54,
      "grad_norm": 0.44551295042037964,
      "learning_rate": 6.92e-06,
      "loss": 0.0128,
      "step": 13080
    },
    {
      "epoch": 6.545,
      "grad_norm": 0.8617606163024902,
      "learning_rate": 6.91e-06,
      "loss": 0.0081,
      "step": 13090
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.002732318826019764,
      "learning_rate": 6.9e-06,
      "loss": 0.0105,
      "step": 13100
    },
    {
      "epoch": 6.555,
      "grad_norm": 0.5239226818084717,
      "learning_rate": 6.89e-06,
      "loss": 0.007,
      "step": 13110
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.001634906860999763,
      "learning_rate": 6.88e-06,
      "loss": 0.0083,
      "step": 13120
    },
    {
      "epoch": 6.5649999999999995,
      "grad_norm": 1.0197992324829102,
      "learning_rate": 6.870000000000001e-06,
      "loss": 0.0065,
      "step": 13130
    },
    {
      "epoch": 6.57,
      "grad_norm": 0.00345605774782598,
      "learning_rate": 6.860000000000001e-06,
      "loss": 0.0192,
      "step": 13140
    },
    {
      "epoch": 6.575,
      "grad_norm": 0.7091244459152222,
      "learning_rate": 6.850000000000001e-06,
      "loss": 0.0069,
      "step": 13150
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.008549756370484829,
      "learning_rate": 6.8400000000000014e-06,
      "loss": 0.0083,
      "step": 13160
    },
    {
      "epoch": 6.585,
      "grad_norm": 0.014911134727299213,
      "learning_rate": 6.830000000000001e-06,
      "loss": 0.0086,
      "step": 13170
    },
    {
      "epoch": 6.59,
      "grad_norm": 0.47953906655311584,
      "learning_rate": 6.820000000000001e-06,
      "loss": 0.0043,
      "step": 13180
    },
    {
      "epoch": 6.595,
      "grad_norm": 0.005159822758287191,
      "learning_rate": 6.810000000000001e-06,
      "loss": 0.005,
      "step": 13190
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.5005968809127808,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0069,
      "step": 13200
    },
    {
      "epoch": 6.605,
      "grad_norm": 5.492028713226318,
      "learning_rate": 6.790000000000001e-06,
      "loss": 0.0111,
      "step": 13210
    },
    {
      "epoch": 6.61,
      "grad_norm": 0.01727207377552986,
      "learning_rate": 6.780000000000001e-06,
      "loss": 0.0067,
      "step": 13220
    },
    {
      "epoch": 6.615,
      "grad_norm": 0.002945678075775504,
      "learning_rate": 6.770000000000001e-06,
      "loss": 0.0169,
      "step": 13230
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.012724168598651886,
      "learning_rate": 6.760000000000001e-06,
      "loss": 0.0048,
      "step": 13240
    },
    {
      "epoch": 6.625,
      "grad_norm": 0.4236784875392914,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0117,
      "step": 13250
    },
    {
      "epoch": 6.63,
      "grad_norm": 0.06466223299503326,
      "learning_rate": 6.740000000000001e-06,
      "loss": 0.0079,
      "step": 13260
    },
    {
      "epoch": 6.635,
      "grad_norm": 1.1230542659759521,
      "learning_rate": 6.730000000000001e-06,
      "loss": 0.0164,
      "step": 13270
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.009773122146725655,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.0157,
      "step": 13280
    },
    {
      "epoch": 6.645,
      "grad_norm": 0.002325809793546796,
      "learning_rate": 6.710000000000001e-06,
      "loss": 0.015,
      "step": 13290
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.06806640326976776,
      "learning_rate": 6.700000000000001e-06,
      "loss": 0.0055,
      "step": 13300
    },
    {
      "epoch": 6.655,
      "grad_norm": 0.005196813959628344,
      "learning_rate": 6.690000000000001e-06,
      "loss": 0.0053,
      "step": 13310
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.03417910635471344,
      "learning_rate": 6.680000000000001e-06,
      "loss": 0.0025,
      "step": 13320
    },
    {
      "epoch": 6.665,
      "grad_norm": 0.011727428995072842,
      "learning_rate": 6.6700000000000005e-06,
      "loss": 0.0024,
      "step": 13330
    },
    {
      "epoch": 6.67,
      "grad_norm": 0.4696149230003357,
      "learning_rate": 6.660000000000001e-06,
      "loss": 0.0093,
      "step": 13340
    },
    {
      "epoch": 6.675,
      "grad_norm": 0.0021864513400942087,
      "learning_rate": 6.650000000000001e-06,
      "loss": 0.009,
      "step": 13350
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.014701387844979763,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.0031,
      "step": 13360
    },
    {
      "epoch": 6.6850000000000005,
      "grad_norm": 1.0533583164215088,
      "learning_rate": 6.630000000000001e-06,
      "loss": 0.0173,
      "step": 13370
    },
    {
      "epoch": 6.6899999999999995,
      "grad_norm": 0.9004539847373962,
      "learning_rate": 6.620000000000001e-06,
      "loss": 0.0308,
      "step": 13380
    },
    {
      "epoch": 6.695,
      "grad_norm": 0.34861502051353455,
      "learning_rate": 6.610000000000001e-06,
      "loss": 0.002,
      "step": 13390
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.11439958959817886,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.0041,
      "step": 13400
    },
    {
      "epoch": 6.705,
      "grad_norm": 2.857219696044922,
      "learning_rate": 6.5900000000000004e-06,
      "loss": 0.0292,
      "step": 13410
    },
    {
      "epoch": 6.71,
      "grad_norm": 0.437597393989563,
      "learning_rate": 6.5800000000000005e-06,
      "loss": 0.0072,
      "step": 13420
    },
    {
      "epoch": 6.715,
      "grad_norm": 0.7921621203422546,
      "learning_rate": 6.570000000000001e-06,
      "loss": 0.0109,
      "step": 13430
    },
    {
      "epoch": 6.72,
      "grad_norm": 10.349128723144531,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.01,
      "step": 13440
    },
    {
      "epoch": 6.725,
      "grad_norm": 0.003251201007515192,
      "learning_rate": 6.550000000000001e-06,
      "loss": 0.0067,
      "step": 13450
    },
    {
      "epoch": 6.73,
      "grad_norm": 0.5074774026870728,
      "learning_rate": 6.540000000000001e-06,
      "loss": 0.0096,
      "step": 13460
    },
    {
      "epoch": 6.735,
      "grad_norm": 0.004538624547421932,
      "learning_rate": 6.530000000000001e-06,
      "loss": 0.0135,
      "step": 13470
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.3438611030578613,
      "learning_rate": 6.520000000000001e-06,
      "loss": 0.0135,
      "step": 13480
    },
    {
      "epoch": 6.745,
      "grad_norm": 0.19269458949565887,
      "learning_rate": 6.51e-06,
      "loss": 0.0126,
      "step": 13490
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.0041069146245718,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0026,
      "step": 13500
    },
    {
      "epoch": 6.755,
      "grad_norm": 0.002743847668170929,
      "learning_rate": 6.4900000000000005e-06,
      "loss": 0.0049,
      "step": 13510
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.0014711290132254362,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.0141,
      "step": 13520
    },
    {
      "epoch": 6.765,
      "grad_norm": 0.006557404529303312,
      "learning_rate": 6.470000000000001e-06,
      "loss": 0.01,
      "step": 13530
    },
    {
      "epoch": 6.77,
      "grad_norm": 0.0025308881886303425,
      "learning_rate": 6.460000000000001e-06,
      "loss": 0.0164,
      "step": 13540
    },
    {
      "epoch": 6.775,
      "grad_norm": 3.8578526973724365,
      "learning_rate": 6.450000000000001e-06,
      "loss": 0.0323,
      "step": 13550
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.40961599349975586,
      "learning_rate": 6.440000000000001e-06,
      "loss": 0.0081,
      "step": 13560
    },
    {
      "epoch": 6.785,
      "grad_norm": 0.4897230565547943,
      "learning_rate": 6.43e-06,
      "loss": 0.0076,
      "step": 13570
    },
    {
      "epoch": 6.79,
      "grad_norm": 0.5112456679344177,
      "learning_rate": 6.42e-06,
      "loss": 0.0166,
      "step": 13580
    },
    {
      "epoch": 6.795,
      "grad_norm": 2.1163923740386963,
      "learning_rate": 6.4100000000000005e-06,
      "loss": 0.0129,
      "step": 13590
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.005360276438295841,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0081,
      "step": 13600
    },
    {
      "epoch": 6.805,
      "grad_norm": 0.5589355230331421,
      "learning_rate": 6.390000000000001e-06,
      "loss": 0.0101,
      "step": 13610
    },
    {
      "epoch": 6.8100000000000005,
      "grad_norm": 0.23034796118736267,
      "learning_rate": 6.380000000000001e-06,
      "loss": 0.0068,
      "step": 13620
    },
    {
      "epoch": 6.8149999999999995,
      "grad_norm": 0.24139370024204254,
      "learning_rate": 6.370000000000001e-06,
      "loss": 0.0046,
      "step": 13630
    },
    {
      "epoch": 6.82,
      "grad_norm": 0.0011034189956262708,
      "learning_rate": 6.360000000000001e-06,
      "loss": 0.0123,
      "step": 13640
    },
    {
      "epoch": 6.825,
      "grad_norm": 0.44526585936546326,
      "learning_rate": 6.35e-06,
      "loss": 0.0083,
      "step": 13650
    },
    {
      "epoch": 6.83,
      "grad_norm": 0.2671267092227936,
      "learning_rate": 6.34e-06,
      "loss": 0.007,
      "step": 13660
    },
    {
      "epoch": 6.835,
      "grad_norm": 0.5800336003303528,
      "learning_rate": 6.33e-06,
      "loss": 0.0087,
      "step": 13670
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.009440245106816292,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.0111,
      "step": 13680
    },
    {
      "epoch": 6.845,
      "grad_norm": 0.8228190541267395,
      "learning_rate": 6.3100000000000006e-06,
      "loss": 0.0091,
      "step": 13690
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.02698494680225849,
      "learning_rate": 6.300000000000001e-06,
      "loss": 0.0186,
      "step": 13700
    },
    {
      "epoch": 6.855,
      "grad_norm": 0.0013946150429546833,
      "learning_rate": 6.290000000000001e-06,
      "loss": 0.0052,
      "step": 13710
    },
    {
      "epoch": 6.86,
      "grad_norm": 0.2970205247402191,
      "learning_rate": 6.280000000000001e-06,
      "loss": 0.0072,
      "step": 13720
    },
    {
      "epoch": 6.865,
      "grad_norm": 0.5278439521789551,
      "learning_rate": 6.27e-06,
      "loss": 0.0231,
      "step": 13730
    },
    {
      "epoch": 6.87,
      "grad_norm": 0.0012012996012344956,
      "learning_rate": 6.26e-06,
      "loss": 0.008,
      "step": 13740
    },
    {
      "epoch": 6.875,
      "grad_norm": 0.3071446120738983,
      "learning_rate": 6.25e-06,
      "loss": 0.0086,
      "step": 13750
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.49043795466423035,
      "learning_rate": 6.24e-06,
      "loss": 0.0061,
      "step": 13760
    },
    {
      "epoch": 6.885,
      "grad_norm": 2.805043935775757,
      "learning_rate": 6.2300000000000005e-06,
      "loss": 0.0083,
      "step": 13770
    },
    {
      "epoch": 6.89,
      "grad_norm": 0.0014100722037255764,
      "learning_rate": 6.220000000000001e-06,
      "loss": 0.0018,
      "step": 13780
    },
    {
      "epoch": 6.895,
      "grad_norm": 0.0014636126579716802,
      "learning_rate": 6.210000000000001e-06,
      "loss": 0.007,
      "step": 13790
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.42477157711982727,
      "learning_rate": 6.200000000000001e-06,
      "loss": 0.0043,
      "step": 13800
    },
    {
      "epoch": 6.905,
      "grad_norm": 1.6257668733596802,
      "learning_rate": 6.190000000000001e-06,
      "loss": 0.0202,
      "step": 13810
    },
    {
      "epoch": 6.91,
      "grad_norm": 0.007484607398509979,
      "learning_rate": 6.18e-06,
      "loss": 0.0157,
      "step": 13820
    },
    {
      "epoch": 6.915,
      "grad_norm": 0.5546714067459106,
      "learning_rate": 6.17e-06,
      "loss": 0.0053,
      "step": 13830
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.0010641326662153006,
      "learning_rate": 6.16e-06,
      "loss": 0.003,
      "step": 13840
    },
    {
      "epoch": 6.925,
      "grad_norm": 0.45626261830329895,
      "learning_rate": 6.15e-06,
      "loss": 0.0112,
      "step": 13850
    },
    {
      "epoch": 6.93,
      "grad_norm": 0.5067555904388428,
      "learning_rate": 6.1400000000000005e-06,
      "loss": 0.0059,
      "step": 13860
    },
    {
      "epoch": 6.9350000000000005,
      "grad_norm": 1.1593018770217896,
      "learning_rate": 6.130000000000001e-06,
      "loss": 0.0168,
      "step": 13870
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.5807974338531494,
      "learning_rate": 6.120000000000001e-06,
      "loss": 0.0079,
      "step": 13880
    },
    {
      "epoch": 6.945,
      "grad_norm": 0.23163282871246338,
      "learning_rate": 6.110000000000001e-06,
      "loss": 0.0059,
      "step": 13890
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.001420194748789072,
      "learning_rate": 6.1e-06,
      "loss": 0.0092,
      "step": 13900
    },
    {
      "epoch": 6.955,
      "grad_norm": 0.003327771322801709,
      "learning_rate": 6.09e-06,
      "loss": 0.0049,
      "step": 13910
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.006047129165381193,
      "learning_rate": 6.08e-06,
      "loss": 0.0045,
      "step": 13920
    },
    {
      "epoch": 6.965,
      "grad_norm": 0.5331684947013855,
      "learning_rate": 6.07e-06,
      "loss": 0.0081,
      "step": 13930
    },
    {
      "epoch": 6.97,
      "grad_norm": 0.4503293037414551,
      "learning_rate": 6.0600000000000004e-06,
      "loss": 0.01,
      "step": 13940
    },
    {
      "epoch": 6.975,
      "grad_norm": 0.1791563332080841,
      "learning_rate": 6.0500000000000005e-06,
      "loss": 0.0041,
      "step": 13950
    },
    {
      "epoch": 6.98,
      "grad_norm": 0.862334132194519,
      "learning_rate": 6.040000000000001e-06,
      "loss": 0.0064,
      "step": 13960
    },
    {
      "epoch": 6.985,
      "grad_norm": 0.3973042070865631,
      "learning_rate": 6.030000000000001e-06,
      "loss": 0.0037,
      "step": 13970
    },
    {
      "epoch": 6.99,
      "grad_norm": 0.0020137764513492584,
      "learning_rate": 6.02e-06,
      "loss": 0.004,
      "step": 13980
    },
    {
      "epoch": 6.995,
      "grad_norm": 0.45975786447525024,
      "learning_rate": 6.01e-06,
      "loss": 0.0095,
      "step": 13990
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0019493330037221313,
      "learning_rate": 6e-06,
      "loss": 0.0081,
      "step": 14000
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9932176196032673,
      "eval_f1": 0.9737584650112867,
      "eval_loss": 0.022113613784313202,
      "eval_precision": 0.9765138653084323,
      "eval_recall": 0.9710185706246482,
      "eval_runtime": 917.6009,
      "eval_samples_per_second": 29.896,
      "eval_steps_per_second": 0.935,
      "step": 14000
    }
  ],
  "logging_steps": 10,
  "max_steps": 20000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0358926294052352e+18,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
