{
  "best_metric": 0.9508196721311475,
  "best_model_checkpoint": "../saved_models/open_redirect/checkpoint-11142",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 11142,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005385029617662897,
      "grad_norm": 39.20782470703125,
      "learning_rate": 1.9998922994076467e-05,
      "loss": 0.7806,
      "step": 1
    },
    {
      "epoch": 0.005385029617662897,
      "grad_norm": 45.691497802734375,
      "learning_rate": 1.9989229940764676e-05,
      "loss": 0.4884,
      "step": 10
    },
    {
      "epoch": 0.010770059235325794,
      "grad_norm": 20.04640769958496,
      "learning_rate": 1.997845988152935e-05,
      "loss": 0.5018,
      "step": 20
    },
    {
      "epoch": 0.01615508885298869,
      "grad_norm": 15.81977367401123,
      "learning_rate": 1.9967689822294024e-05,
      "loss": 0.4597,
      "step": 30
    },
    {
      "epoch": 0.021540118470651588,
      "grad_norm": 51.06034851074219,
      "learning_rate": 1.9956919763058698e-05,
      "loss": 0.5533,
      "step": 40
    },
    {
      "epoch": 0.026925148088314487,
      "grad_norm": 27.792041778564453,
      "learning_rate": 1.9946149703823372e-05,
      "loss": 0.4127,
      "step": 50
    },
    {
      "epoch": 0.03231017770597738,
      "grad_norm": 21.55215072631836,
      "learning_rate": 1.9935379644588046e-05,
      "loss": 0.4706,
      "step": 60
    },
    {
      "epoch": 0.03769520732364028,
      "grad_norm": 12.629554748535156,
      "learning_rate": 1.992460958535272e-05,
      "loss": 0.4048,
      "step": 70
    },
    {
      "epoch": 0.043080236941303175,
      "grad_norm": 10.768050193786621,
      "learning_rate": 1.9913839526117394e-05,
      "loss": 0.3859,
      "step": 80
    },
    {
      "epoch": 0.048465266558966075,
      "grad_norm": 14.076838493347168,
      "learning_rate": 1.990306946688207e-05,
      "loss": 0.4394,
      "step": 90
    },
    {
      "epoch": 0.053850296176628974,
      "grad_norm": 15.933562278747559,
      "learning_rate": 1.9892299407646745e-05,
      "loss": 0.3626,
      "step": 100
    },
    {
      "epoch": 0.05923532579429187,
      "grad_norm": 13.155383110046387,
      "learning_rate": 1.9881529348411416e-05,
      "loss": 0.3958,
      "step": 110
    },
    {
      "epoch": 0.06462035541195477,
      "grad_norm": 15.707513809204102,
      "learning_rate": 1.987075928917609e-05,
      "loss": 0.418,
      "step": 120
    },
    {
      "epoch": 0.07000538502961766,
      "grad_norm": 17.90655517578125,
      "learning_rate": 1.9859989229940768e-05,
      "loss": 0.5428,
      "step": 130
    },
    {
      "epoch": 0.07539041464728057,
      "grad_norm": 25.473310470581055,
      "learning_rate": 1.984921917070544e-05,
      "loss": 0.4035,
      "step": 140
    },
    {
      "epoch": 0.08077544426494346,
      "grad_norm": 13.810471534729004,
      "learning_rate": 1.9838449111470116e-05,
      "loss": 0.4475,
      "step": 150
    },
    {
      "epoch": 0.08616047388260635,
      "grad_norm": 5.535758018493652,
      "learning_rate": 1.982767905223479e-05,
      "loss": 0.3582,
      "step": 160
    },
    {
      "epoch": 0.09154550350026926,
      "grad_norm": 23.316436767578125,
      "learning_rate": 1.9816908992999464e-05,
      "loss": 0.4483,
      "step": 170
    },
    {
      "epoch": 0.09693053311793215,
      "grad_norm": 17.980201721191406,
      "learning_rate": 1.9806138933764138e-05,
      "loss": 0.4108,
      "step": 180
    },
    {
      "epoch": 0.10231556273559504,
      "grad_norm": 9.187458992004395,
      "learning_rate": 1.9795368874528812e-05,
      "loss": 0.2937,
      "step": 190
    },
    {
      "epoch": 0.10770059235325795,
      "grad_norm": 14.641305923461914,
      "learning_rate": 1.9784598815293486e-05,
      "loss": 0.4981,
      "step": 200
    },
    {
      "epoch": 0.11308562197092084,
      "grad_norm": 17.912921905517578,
      "learning_rate": 1.977382875605816e-05,
      "loss": 0.4677,
      "step": 210
    },
    {
      "epoch": 0.11847065158858373,
      "grad_norm": 11.746259689331055,
      "learning_rate": 1.9763058696822834e-05,
      "loss": 0.4625,
      "step": 220
    },
    {
      "epoch": 0.12385568120624664,
      "grad_norm": 13.78906536102295,
      "learning_rate": 1.9752288637587508e-05,
      "loss": 0.3949,
      "step": 230
    },
    {
      "epoch": 0.12924071082390953,
      "grad_norm": 11.790627479553223,
      "learning_rate": 1.9741518578352182e-05,
      "loss": 0.4101,
      "step": 240
    },
    {
      "epoch": 0.13462574044157244,
      "grad_norm": 63.00135040283203,
      "learning_rate": 1.9730748519116856e-05,
      "loss": 0.3722,
      "step": 250
    },
    {
      "epoch": 0.14001077005923532,
      "grad_norm": 13.821002960205078,
      "learning_rate": 1.971997845988153e-05,
      "loss": 0.4473,
      "step": 260
    },
    {
      "epoch": 0.14539579967689822,
      "grad_norm": 10.107209205627441,
      "learning_rate": 1.9709208400646204e-05,
      "loss": 0.3647,
      "step": 270
    },
    {
      "epoch": 0.15078082929456113,
      "grad_norm": 7.167706489562988,
      "learning_rate": 1.9698438341410878e-05,
      "loss": 0.3703,
      "step": 280
    },
    {
      "epoch": 0.156165858912224,
      "grad_norm": 8.302070617675781,
      "learning_rate": 1.9687668282175552e-05,
      "loss": 0.3106,
      "step": 290
    },
    {
      "epoch": 0.16155088852988692,
      "grad_norm": 5.918763160705566,
      "learning_rate": 1.967689822294023e-05,
      "loss": 0.3402,
      "step": 300
    },
    {
      "epoch": 0.16693591814754982,
      "grad_norm": 8.456785202026367,
      "learning_rate": 1.9666128163704904e-05,
      "loss": 0.333,
      "step": 310
    },
    {
      "epoch": 0.1723209477652127,
      "grad_norm": 11.183812141418457,
      "learning_rate": 1.9655358104469574e-05,
      "loss": 0.4126,
      "step": 320
    },
    {
      "epoch": 0.1777059773828756,
      "grad_norm": 10.019926071166992,
      "learning_rate": 1.9644588045234248e-05,
      "loss": 0.3593,
      "step": 330
    },
    {
      "epoch": 0.1830910070005385,
      "grad_norm": 8.71060848236084,
      "learning_rate": 1.9633817985998926e-05,
      "loss": 0.3638,
      "step": 340
    },
    {
      "epoch": 0.1884760366182014,
      "grad_norm": 8.353341102600098,
      "learning_rate": 1.96230479267636e-05,
      "loss": 0.3561,
      "step": 350
    },
    {
      "epoch": 0.1938610662358643,
      "grad_norm": 10.387014389038086,
      "learning_rate": 1.9612277867528274e-05,
      "loss": 0.3664,
      "step": 360
    },
    {
      "epoch": 0.1992460958535272,
      "grad_norm": 11.02480697631836,
      "learning_rate": 1.9601507808292948e-05,
      "loss": 0.3465,
      "step": 370
    },
    {
      "epoch": 0.20463112547119008,
      "grad_norm": 8.86049747467041,
      "learning_rate": 1.9590737749057622e-05,
      "loss": 0.3326,
      "step": 380
    },
    {
      "epoch": 0.210016155088853,
      "grad_norm": 7.598443031311035,
      "learning_rate": 1.9579967689822296e-05,
      "loss": 0.3243,
      "step": 390
    },
    {
      "epoch": 0.2154011847065159,
      "grad_norm": 7.560652732849121,
      "learning_rate": 1.956919763058697e-05,
      "loss": 0.3105,
      "step": 400
    },
    {
      "epoch": 0.22078621432417878,
      "grad_norm": 12.119086265563965,
      "learning_rate": 1.9558427571351644e-05,
      "loss": 0.3761,
      "step": 410
    },
    {
      "epoch": 0.22617124394184168,
      "grad_norm": 9.059479713439941,
      "learning_rate": 1.9547657512116318e-05,
      "loss": 0.2948,
      "step": 420
    },
    {
      "epoch": 0.2315562735595046,
      "grad_norm": 6.37711763381958,
      "learning_rate": 1.9536887452880992e-05,
      "loss": 0.266,
      "step": 430
    },
    {
      "epoch": 0.23694130317716747,
      "grad_norm": 7.402123928070068,
      "learning_rate": 1.9526117393645666e-05,
      "loss": 0.2159,
      "step": 440
    },
    {
      "epoch": 0.24232633279483037,
      "grad_norm": 10.373698234558105,
      "learning_rate": 1.951534733441034e-05,
      "loss": 0.4064,
      "step": 450
    },
    {
      "epoch": 0.24771136241249328,
      "grad_norm": 8.984626770019531,
      "learning_rate": 1.9504577275175014e-05,
      "loss": 0.3052,
      "step": 460
    },
    {
      "epoch": 0.25309639203015616,
      "grad_norm": 8.592231750488281,
      "learning_rate": 1.9493807215939688e-05,
      "loss": 0.2469,
      "step": 470
    },
    {
      "epoch": 0.25848142164781907,
      "grad_norm": 8.992191314697266,
      "learning_rate": 1.9483037156704362e-05,
      "loss": 0.3502,
      "step": 480
    },
    {
      "epoch": 0.26386645126548197,
      "grad_norm": 4.679659843444824,
      "learning_rate": 1.9472267097469036e-05,
      "loss": 0.3145,
      "step": 490
    },
    {
      "epoch": 0.2692514808831449,
      "grad_norm": 19.459665298461914,
      "learning_rate": 1.9461497038233714e-05,
      "loss": 0.3939,
      "step": 500
    },
    {
      "epoch": 0.27463651050080773,
      "grad_norm": 8.04604721069336,
      "learning_rate": 1.9450726978998388e-05,
      "loss": 0.2582,
      "step": 510
    },
    {
      "epoch": 0.28002154011847064,
      "grad_norm": 11.414020538330078,
      "learning_rate": 1.9439956919763062e-05,
      "loss": 0.3468,
      "step": 520
    },
    {
      "epoch": 0.28540656973613354,
      "grad_norm": 5.711704254150391,
      "learning_rate": 1.9429186860527732e-05,
      "loss": 0.2464,
      "step": 530
    },
    {
      "epoch": 0.29079159935379645,
      "grad_norm": 12.513373374938965,
      "learning_rate": 1.9418416801292407e-05,
      "loss": 0.2919,
      "step": 540
    },
    {
      "epoch": 0.29617662897145935,
      "grad_norm": 13.121660232543945,
      "learning_rate": 1.9407646742057084e-05,
      "loss": 0.3128,
      "step": 550
    },
    {
      "epoch": 0.30156165858912226,
      "grad_norm": 7.76289701461792,
      "learning_rate": 1.9396876682821758e-05,
      "loss": 0.2849,
      "step": 560
    },
    {
      "epoch": 0.3069466882067851,
      "grad_norm": 5.9123735427856445,
      "learning_rate": 1.9386106623586432e-05,
      "loss": 0.246,
      "step": 570
    },
    {
      "epoch": 0.312331717824448,
      "grad_norm": 8.348857879638672,
      "learning_rate": 1.9375336564351106e-05,
      "loss": 0.2548,
      "step": 580
    },
    {
      "epoch": 0.3177167474421109,
      "grad_norm": 6.7680439949035645,
      "learning_rate": 1.936456650511578e-05,
      "loss": 0.2222,
      "step": 590
    },
    {
      "epoch": 0.32310177705977383,
      "grad_norm": 4.631667613983154,
      "learning_rate": 1.9353796445880454e-05,
      "loss": 0.2305,
      "step": 600
    },
    {
      "epoch": 0.32848680667743674,
      "grad_norm": 8.85511302947998,
      "learning_rate": 1.9343026386645128e-05,
      "loss": 0.2387,
      "step": 610
    },
    {
      "epoch": 0.33387183629509964,
      "grad_norm": 10.22871208190918,
      "learning_rate": 1.9332256327409802e-05,
      "loss": 0.2834,
      "step": 620
    },
    {
      "epoch": 0.3392568659127625,
      "grad_norm": 9.392901420593262,
      "learning_rate": 1.9321486268174476e-05,
      "loss": 0.235,
      "step": 630
    },
    {
      "epoch": 0.3446418955304254,
      "grad_norm": 7.815347194671631,
      "learning_rate": 1.931071620893915e-05,
      "loss": 0.2306,
      "step": 640
    },
    {
      "epoch": 0.3500269251480883,
      "grad_norm": 40.05780029296875,
      "learning_rate": 1.9299946149703824e-05,
      "loss": 0.362,
      "step": 650
    },
    {
      "epoch": 0.3554119547657512,
      "grad_norm": 7.615161418914795,
      "learning_rate": 1.92891760904685e-05,
      "loss": 0.3018,
      "step": 660
    },
    {
      "epoch": 0.3607969843834141,
      "grad_norm": 12.42711067199707,
      "learning_rate": 1.9278406031233176e-05,
      "loss": 0.2618,
      "step": 670
    },
    {
      "epoch": 0.366182014001077,
      "grad_norm": 6.968769073486328,
      "learning_rate": 1.9267635971997846e-05,
      "loss": 0.3308,
      "step": 680
    },
    {
      "epoch": 0.3715670436187399,
      "grad_norm": 7.55904483795166,
      "learning_rate": 1.925686591276252e-05,
      "loss": 0.2764,
      "step": 690
    },
    {
      "epoch": 0.3769520732364028,
      "grad_norm": 10.361438751220703,
      "learning_rate": 1.9246095853527195e-05,
      "loss": 0.1918,
      "step": 700
    },
    {
      "epoch": 0.3823371028540657,
      "grad_norm": 6.057435512542725,
      "learning_rate": 1.9235325794291872e-05,
      "loss": 0.1829,
      "step": 710
    },
    {
      "epoch": 0.3877221324717286,
      "grad_norm": 8.768560409545898,
      "learning_rate": 1.9224555735056546e-05,
      "loss": 0.1678,
      "step": 720
    },
    {
      "epoch": 0.3931071620893915,
      "grad_norm": 9.435702323913574,
      "learning_rate": 1.921378567582122e-05,
      "loss": 0.2708,
      "step": 730
    },
    {
      "epoch": 0.3984921917070544,
      "grad_norm": 9.459712028503418,
      "learning_rate": 1.9203015616585894e-05,
      "loss": 0.2492,
      "step": 740
    },
    {
      "epoch": 0.40387722132471726,
      "grad_norm": 11.38188648223877,
      "learning_rate": 1.9192245557350565e-05,
      "loss": 0.2015,
      "step": 750
    },
    {
      "epoch": 0.40926225094238017,
      "grad_norm": 6.55487060546875,
      "learning_rate": 1.9181475498115242e-05,
      "loss": 0.1579,
      "step": 760
    },
    {
      "epoch": 0.4146472805600431,
      "grad_norm": 4.889786720275879,
      "learning_rate": 1.9170705438879916e-05,
      "loss": 0.2412,
      "step": 770
    },
    {
      "epoch": 0.420032310177706,
      "grad_norm": 13.272236824035645,
      "learning_rate": 1.915993537964459e-05,
      "loss": 0.2836,
      "step": 780
    },
    {
      "epoch": 0.4254173397953689,
      "grad_norm": 10.58975887298584,
      "learning_rate": 1.9149165320409264e-05,
      "loss": 0.2342,
      "step": 790
    },
    {
      "epoch": 0.4308023694130318,
      "grad_norm": 5.444818019866943,
      "learning_rate": 1.9138395261173938e-05,
      "loss": 0.1555,
      "step": 800
    },
    {
      "epoch": 0.43618739903069464,
      "grad_norm": 8.538219451904297,
      "learning_rate": 1.9127625201938612e-05,
      "loss": 0.2317,
      "step": 810
    },
    {
      "epoch": 0.44157242864835755,
      "grad_norm": 3.744518995285034,
      "learning_rate": 1.9116855142703286e-05,
      "loss": 0.229,
      "step": 820
    },
    {
      "epoch": 0.44695745826602046,
      "grad_norm": 6.112356185913086,
      "learning_rate": 1.910608508346796e-05,
      "loss": 0.2117,
      "step": 830
    },
    {
      "epoch": 0.45234248788368336,
      "grad_norm": 8.980669021606445,
      "learning_rate": 1.9095315024232634e-05,
      "loss": 0.1015,
      "step": 840
    },
    {
      "epoch": 0.45772751750134627,
      "grad_norm": 5.178942680358887,
      "learning_rate": 1.908454496499731e-05,
      "loss": 0.2297,
      "step": 850
    },
    {
      "epoch": 0.4631125471190092,
      "grad_norm": 7.690022945404053,
      "learning_rate": 1.9073774905761983e-05,
      "loss": 0.1675,
      "step": 860
    },
    {
      "epoch": 0.46849757673667203,
      "grad_norm": 6.0590033531188965,
      "learning_rate": 1.9063004846526657e-05,
      "loss": 0.184,
      "step": 870
    },
    {
      "epoch": 0.47388260635433493,
      "grad_norm": 3.801241636276245,
      "learning_rate": 1.9052234787291334e-05,
      "loss": 0.1619,
      "step": 880
    },
    {
      "epoch": 0.47926763597199784,
      "grad_norm": 6.44157075881958,
      "learning_rate": 1.9041464728056005e-05,
      "loss": 0.2647,
      "step": 890
    },
    {
      "epoch": 0.48465266558966075,
      "grad_norm": 8.039706230163574,
      "learning_rate": 1.903069466882068e-05,
      "loss": 0.2015,
      "step": 900
    },
    {
      "epoch": 0.49003769520732365,
      "grad_norm": 10.199623107910156,
      "learning_rate": 1.9019924609585353e-05,
      "loss": 0.1693,
      "step": 910
    },
    {
      "epoch": 0.49542272482498656,
      "grad_norm": 6.907147407531738,
      "learning_rate": 1.900915455035003e-05,
      "loss": 0.1547,
      "step": 920
    },
    {
      "epoch": 0.5008077544426495,
      "grad_norm": 4.356924533843994,
      "learning_rate": 1.8998384491114704e-05,
      "loss": 0.2085,
      "step": 930
    },
    {
      "epoch": 0.5061927840603123,
      "grad_norm": 9.253764152526855,
      "learning_rate": 1.8987614431879378e-05,
      "loss": 0.196,
      "step": 940
    },
    {
      "epoch": 0.5115778136779753,
      "grad_norm": 7.574005603790283,
      "learning_rate": 1.8976844372644052e-05,
      "loss": 0.1362,
      "step": 950
    },
    {
      "epoch": 0.5169628432956381,
      "grad_norm": 4.205273628234863,
      "learning_rate": 1.8966074313408723e-05,
      "loss": 0.1351,
      "step": 960
    },
    {
      "epoch": 0.522347872913301,
      "grad_norm": 8.870896339416504,
      "learning_rate": 1.89553042541734e-05,
      "loss": 0.2105,
      "step": 970
    },
    {
      "epoch": 0.5277329025309639,
      "grad_norm": 7.242922782897949,
      "learning_rate": 1.8944534194938074e-05,
      "loss": 0.1963,
      "step": 980
    },
    {
      "epoch": 0.5331179321486268,
      "grad_norm": 3.4992058277130127,
      "learning_rate": 1.893376413570275e-05,
      "loss": 0.1584,
      "step": 990
    },
    {
      "epoch": 0.5385029617662898,
      "grad_norm": 8.522311210632324,
      "learning_rate": 1.8922994076467422e-05,
      "loss": 0.2143,
      "step": 1000
    },
    {
      "epoch": 0.5438879913839526,
      "grad_norm": 4.938847541809082,
      "learning_rate": 1.8912224017232096e-05,
      "loss": 0.1325,
      "step": 1010
    },
    {
      "epoch": 0.5492730210016155,
      "grad_norm": 4.301793098449707,
      "learning_rate": 1.890145395799677e-05,
      "loss": 0.1902,
      "step": 1020
    },
    {
      "epoch": 0.5546580506192784,
      "grad_norm": 5.66199254989624,
      "learning_rate": 1.8890683898761445e-05,
      "loss": 0.1552,
      "step": 1030
    },
    {
      "epoch": 0.5600430802369413,
      "grad_norm": 5.9007673263549805,
      "learning_rate": 1.887991383952612e-05,
      "loss": 0.1427,
      "step": 1040
    },
    {
      "epoch": 0.5654281098546042,
      "grad_norm": 2.848938226699829,
      "learning_rate": 1.8869143780290793e-05,
      "loss": 0.1244,
      "step": 1050
    },
    {
      "epoch": 0.5708131394722671,
      "grad_norm": 8.229132652282715,
      "learning_rate": 1.8858373721055467e-05,
      "loss": 0.1397,
      "step": 1060
    },
    {
      "epoch": 0.57619816908993,
      "grad_norm": 6.2134175300598145,
      "learning_rate": 1.884760366182014e-05,
      "loss": 0.1467,
      "step": 1070
    },
    {
      "epoch": 0.5815831987075929,
      "grad_norm": 8.852572441101074,
      "learning_rate": 1.8836833602584815e-05,
      "loss": 0.189,
      "step": 1080
    },
    {
      "epoch": 0.5869682283252557,
      "grad_norm": 3.1194112300872803,
      "learning_rate": 1.8826063543349492e-05,
      "loss": 0.1276,
      "step": 1090
    },
    {
      "epoch": 0.5923532579429187,
      "grad_norm": 4.414256572723389,
      "learning_rate": 1.8815293484114163e-05,
      "loss": 0.1521,
      "step": 1100
    },
    {
      "epoch": 0.5977382875605816,
      "grad_norm": 8.662125587463379,
      "learning_rate": 1.8804523424878837e-05,
      "loss": 0.2022,
      "step": 1110
    },
    {
      "epoch": 0.6031233171782445,
      "grad_norm": 2.4588916301727295,
      "learning_rate": 1.879375336564351e-05,
      "loss": 0.1338,
      "step": 1120
    },
    {
      "epoch": 0.6085083467959074,
      "grad_norm": 7.6077446937561035,
      "learning_rate": 1.878298330640819e-05,
      "loss": 0.1795,
      "step": 1130
    },
    {
      "epoch": 0.6138933764135702,
      "grad_norm": 4.1028523445129395,
      "learning_rate": 1.8772213247172862e-05,
      "loss": 0.1597,
      "step": 1140
    },
    {
      "epoch": 0.6192784060312332,
      "grad_norm": 3.333296060562134,
      "learning_rate": 1.8761443187937536e-05,
      "loss": 0.127,
      "step": 1150
    },
    {
      "epoch": 0.624663435648896,
      "grad_norm": 6.169602394104004,
      "learning_rate": 1.875067312870221e-05,
      "loss": 0.1976,
      "step": 1160
    },
    {
      "epoch": 0.630048465266559,
      "grad_norm": 6.739424705505371,
      "learning_rate": 1.873990306946688e-05,
      "loss": 0.1853,
      "step": 1170
    },
    {
      "epoch": 0.6354334948842219,
      "grad_norm": 7.8875412940979,
      "learning_rate": 1.872913301023156e-05,
      "loss": 0.1315,
      "step": 1180
    },
    {
      "epoch": 0.6408185245018848,
      "grad_norm": 6.773098468780518,
      "learning_rate": 1.8718362950996233e-05,
      "loss": 0.1565,
      "step": 1190
    },
    {
      "epoch": 0.6462035541195477,
      "grad_norm": 4.304327011108398,
      "learning_rate": 1.8707592891760907e-05,
      "loss": 0.1667,
      "step": 1200
    },
    {
      "epoch": 0.6515885837372105,
      "grad_norm": 7.822929382324219,
      "learning_rate": 1.869682283252558e-05,
      "loss": 0.1219,
      "step": 1210
    },
    {
      "epoch": 0.6569736133548735,
      "grad_norm": 3.562592029571533,
      "learning_rate": 1.8686052773290255e-05,
      "loss": 0.1234,
      "step": 1220
    },
    {
      "epoch": 0.6623586429725363,
      "grad_norm": 5.284435272216797,
      "learning_rate": 1.867528271405493e-05,
      "loss": 0.1871,
      "step": 1230
    },
    {
      "epoch": 0.6677436725901993,
      "grad_norm": 6.366511821746826,
      "learning_rate": 1.8664512654819603e-05,
      "loss": 0.1497,
      "step": 1240
    },
    {
      "epoch": 0.6731287022078621,
      "grad_norm": 7.445457935333252,
      "learning_rate": 1.8653742595584277e-05,
      "loss": 0.1035,
      "step": 1250
    },
    {
      "epoch": 0.678513731825525,
      "grad_norm": 8.820433616638184,
      "learning_rate": 1.864297253634895e-05,
      "loss": 0.1615,
      "step": 1260
    },
    {
      "epoch": 0.683898761443188,
      "grad_norm": 25.449586868286133,
      "learning_rate": 1.8632202477113625e-05,
      "loss": 0.1791,
      "step": 1270
    },
    {
      "epoch": 0.6892837910608508,
      "grad_norm": 7.94279670715332,
      "learning_rate": 1.86214324178783e-05,
      "loss": 0.1424,
      "step": 1280
    },
    {
      "epoch": 0.6946688206785138,
      "grad_norm": 4.812041282653809,
      "learning_rate": 1.8610662358642973e-05,
      "loss": 0.129,
      "step": 1290
    },
    {
      "epoch": 0.7000538502961766,
      "grad_norm": 7.2823262214660645,
      "learning_rate": 1.859989229940765e-05,
      "loss": 0.1505,
      "step": 1300
    },
    {
      "epoch": 0.7054388799138396,
      "grad_norm": 4.497454643249512,
      "learning_rate": 1.858912224017232e-05,
      "loss": 0.1579,
      "step": 1310
    },
    {
      "epoch": 0.7108239095315024,
      "grad_norm": 9.66834831237793,
      "learning_rate": 1.8578352180936995e-05,
      "loss": 0.1658,
      "step": 1320
    },
    {
      "epoch": 0.7162089391491653,
      "grad_norm": 4.679475784301758,
      "learning_rate": 1.856758212170167e-05,
      "loss": 0.1479,
      "step": 1330
    },
    {
      "epoch": 0.7215939687668282,
      "grad_norm": 9.810519218444824,
      "learning_rate": 1.8556812062466347e-05,
      "loss": 0.1076,
      "step": 1340
    },
    {
      "epoch": 0.7269789983844911,
      "grad_norm": 9.30803394317627,
      "learning_rate": 1.854604200323102e-05,
      "loss": 0.1576,
      "step": 1350
    },
    {
      "epoch": 0.732364028002154,
      "grad_norm": 6.386762619018555,
      "learning_rate": 1.8535271943995695e-05,
      "loss": 0.1854,
      "step": 1360
    },
    {
      "epoch": 0.7377490576198169,
      "grad_norm": 10.386069297790527,
      "learning_rate": 1.852450188476037e-05,
      "loss": 0.1285,
      "step": 1370
    },
    {
      "epoch": 0.7431340872374798,
      "grad_norm": 1.3014914989471436,
      "learning_rate": 1.851373182552504e-05,
      "loss": 0.0987,
      "step": 1380
    },
    {
      "epoch": 0.7485191168551427,
      "grad_norm": 12.723700523376465,
      "learning_rate": 1.8502961766289717e-05,
      "loss": 0.2028,
      "step": 1390
    },
    {
      "epoch": 0.7539041464728056,
      "grad_norm": 5.681638240814209,
      "learning_rate": 1.849219170705439e-05,
      "loss": 0.1,
      "step": 1400
    },
    {
      "epoch": 0.7592891760904685,
      "grad_norm": 5.799407958984375,
      "learning_rate": 1.8481421647819065e-05,
      "loss": 0.1557,
      "step": 1410
    },
    {
      "epoch": 0.7646742057081314,
      "grad_norm": 6.885965824127197,
      "learning_rate": 1.847065158858374e-05,
      "loss": 0.1353,
      "step": 1420
    },
    {
      "epoch": 0.7700592353257943,
      "grad_norm": 11.344090461730957,
      "learning_rate": 1.8459881529348413e-05,
      "loss": 0.0966,
      "step": 1430
    },
    {
      "epoch": 0.7754442649434572,
      "grad_norm": 6.37981653213501,
      "learning_rate": 1.8449111470113087e-05,
      "loss": 0.1661,
      "step": 1440
    },
    {
      "epoch": 0.78082929456112,
      "grad_norm": 9.134928703308105,
      "learning_rate": 1.843834141087776e-05,
      "loss": 0.1266,
      "step": 1450
    },
    {
      "epoch": 0.786214324178783,
      "grad_norm": 13.165169715881348,
      "learning_rate": 1.8427571351642435e-05,
      "loss": 0.1263,
      "step": 1460
    },
    {
      "epoch": 0.7915993537964459,
      "grad_norm": 10.351476669311523,
      "learning_rate": 1.841680129240711e-05,
      "loss": 0.1092,
      "step": 1470
    },
    {
      "epoch": 0.7969843834141088,
      "grad_norm": 13.398772239685059,
      "learning_rate": 1.8406031233171783e-05,
      "loss": 0.1872,
      "step": 1480
    },
    {
      "epoch": 0.8023694130317717,
      "grad_norm": 4.297983169555664,
      "learning_rate": 1.8395261173936457e-05,
      "loss": 0.1015,
      "step": 1490
    },
    {
      "epoch": 0.8077544426494345,
      "grad_norm": 6.480269908905029,
      "learning_rate": 1.8384491114701135e-05,
      "loss": 0.1354,
      "step": 1500
    },
    {
      "epoch": 0.8131394722670975,
      "grad_norm": 4.764298439025879,
      "learning_rate": 1.837372105546581e-05,
      "loss": 0.0755,
      "step": 1510
    },
    {
      "epoch": 0.8185245018847603,
      "grad_norm": 5.435818672180176,
      "learning_rate": 1.836295099623048e-05,
      "loss": 0.0939,
      "step": 1520
    },
    {
      "epoch": 0.8239095315024233,
      "grad_norm": 9.202637672424316,
      "learning_rate": 1.8352180936995153e-05,
      "loss": 0.1353,
      "step": 1530
    },
    {
      "epoch": 0.8292945611200861,
      "grad_norm": 2.511575222015381,
      "learning_rate": 1.8341410877759827e-05,
      "loss": 0.1164,
      "step": 1540
    },
    {
      "epoch": 0.8346795907377491,
      "grad_norm": 6.121518611907959,
      "learning_rate": 1.8330640818524505e-05,
      "loss": 0.1032,
      "step": 1550
    },
    {
      "epoch": 0.840064620355412,
      "grad_norm": 9.972620010375977,
      "learning_rate": 1.831987075928918e-05,
      "loss": 0.1834,
      "step": 1560
    },
    {
      "epoch": 0.8454496499730748,
      "grad_norm": 9.99992847442627,
      "learning_rate": 1.8309100700053853e-05,
      "loss": 0.1568,
      "step": 1570
    },
    {
      "epoch": 0.8508346795907378,
      "grad_norm": 1.2012861967086792,
      "learning_rate": 1.8298330640818527e-05,
      "loss": 0.1024,
      "step": 1580
    },
    {
      "epoch": 0.8562197092084006,
      "grad_norm": 6.692599296569824,
      "learning_rate": 1.8287560581583198e-05,
      "loss": 0.1296,
      "step": 1590
    },
    {
      "epoch": 0.8616047388260636,
      "grad_norm": 6.754271030426025,
      "learning_rate": 1.8276790522347875e-05,
      "loss": 0.1162,
      "step": 1600
    },
    {
      "epoch": 0.8669897684437264,
      "grad_norm": 3.48850417137146,
      "learning_rate": 1.826602046311255e-05,
      "loss": 0.0958,
      "step": 1610
    },
    {
      "epoch": 0.8723747980613893,
      "grad_norm": 9.110099792480469,
      "learning_rate": 1.8255250403877223e-05,
      "loss": 0.1039,
      "step": 1620
    },
    {
      "epoch": 0.8777598276790523,
      "grad_norm": 9.949969291687012,
      "learning_rate": 1.8244480344641897e-05,
      "loss": 0.0952,
      "step": 1630
    },
    {
      "epoch": 0.8831448572967151,
      "grad_norm": 10.131147384643555,
      "learning_rate": 1.823371028540657e-05,
      "loss": 0.1538,
      "step": 1640
    },
    {
      "epoch": 0.8885298869143781,
      "grad_norm": 5.671947956085205,
      "learning_rate": 1.8222940226171245e-05,
      "loss": 0.0656,
      "step": 1650
    },
    {
      "epoch": 0.8939149165320409,
      "grad_norm": 6.172966003417969,
      "learning_rate": 1.821217016693592e-05,
      "loss": 0.1007,
      "step": 1660
    },
    {
      "epoch": 0.8992999461497039,
      "grad_norm": 4.001192092895508,
      "learning_rate": 1.8201400107700593e-05,
      "loss": 0.1792,
      "step": 1670
    },
    {
      "epoch": 0.9046849757673667,
      "grad_norm": 9.393128395080566,
      "learning_rate": 1.8190630048465267e-05,
      "loss": 0.1351,
      "step": 1680
    },
    {
      "epoch": 0.9100700053850296,
      "grad_norm": 6.611989974975586,
      "learning_rate": 1.817985998922994e-05,
      "loss": 0.152,
      "step": 1690
    },
    {
      "epoch": 0.9154550350026925,
      "grad_norm": 7.562176704406738,
      "learning_rate": 1.8169089929994615e-05,
      "loss": 0.128,
      "step": 1700
    },
    {
      "epoch": 0.9208400646203554,
      "grad_norm": 6.388150215148926,
      "learning_rate": 1.8158319870759293e-05,
      "loss": 0.1211,
      "step": 1710
    },
    {
      "epoch": 0.9262250942380184,
      "grad_norm": 8.1511869430542,
      "learning_rate": 1.8147549811523967e-05,
      "loss": 0.1007,
      "step": 1720
    },
    {
      "epoch": 0.9316101238556812,
      "grad_norm": 9.909422874450684,
      "learning_rate": 1.8136779752288637e-05,
      "loss": 0.0859,
      "step": 1730
    },
    {
      "epoch": 0.9369951534733441,
      "grad_norm": 1.8673546314239502,
      "learning_rate": 1.812600969305331e-05,
      "loss": 0.1449,
      "step": 1740
    },
    {
      "epoch": 0.942380183091007,
      "grad_norm": 9.086822509765625,
      "learning_rate": 1.8115239633817986e-05,
      "loss": 0.1291,
      "step": 1750
    },
    {
      "epoch": 0.9477652127086699,
      "grad_norm": 3.6571156978607178,
      "learning_rate": 1.8104469574582663e-05,
      "loss": 0.0843,
      "step": 1760
    },
    {
      "epoch": 0.9531502423263328,
      "grad_norm": 7.234503746032715,
      "learning_rate": 1.8093699515347337e-05,
      "loss": 0.0878,
      "step": 1770
    },
    {
      "epoch": 0.9585352719439957,
      "grad_norm": 9.167521476745605,
      "learning_rate": 1.808292945611201e-05,
      "loss": 0.1141,
      "step": 1780
    },
    {
      "epoch": 0.9639203015616586,
      "grad_norm": 3.624159574508667,
      "learning_rate": 1.8072159396876685e-05,
      "loss": 0.0896,
      "step": 1790
    },
    {
      "epoch": 0.9693053311793215,
      "grad_norm": 5.035064220428467,
      "learning_rate": 1.806138933764136e-05,
      "loss": 0.1423,
      "step": 1800
    },
    {
      "epoch": 0.9746903607969843,
      "grad_norm": 8.206806182861328,
      "learning_rate": 1.8050619278406033e-05,
      "loss": 0.1462,
      "step": 1810
    },
    {
      "epoch": 0.9800753904146473,
      "grad_norm": 0.38753700256347656,
      "learning_rate": 1.8039849219170707e-05,
      "loss": 0.1057,
      "step": 1820
    },
    {
      "epoch": 0.9854604200323102,
      "grad_norm": 8.501983642578125,
      "learning_rate": 1.802907915993538e-05,
      "loss": 0.1723,
      "step": 1830
    },
    {
      "epoch": 0.9908454496499731,
      "grad_norm": 10.010391235351562,
      "learning_rate": 1.8018309100700055e-05,
      "loss": 0.1025,
      "step": 1840
    },
    {
      "epoch": 0.996230479267636,
      "grad_norm": 3.982682704925537,
      "learning_rate": 1.800753904146473e-05,
      "loss": 0.049,
      "step": 1850
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.963803391959799,
      "eval_f1": 0.8685486170516111,
      "eval_loss": 0.11652525514364243,
      "eval_precision": 0.8619128466327108,
      "eval_recall": 0.8752873563218391,
      "eval_runtime": 311.0685,
      "eval_samples_per_second": 40.956,
      "eval_steps_per_second": 1.283,
      "step": 1857
    },
    {
      "epoch": 1.001615508885299,
      "grad_norm": 4.820634841918945,
      "learning_rate": 1.7996768982229403e-05,
      "loss": 0.1683,
      "step": 1860
    },
    {
      "epoch": 1.0070005385029617,
      "grad_norm": 1.412761926651001,
      "learning_rate": 1.7985998922994077e-05,
      "loss": 0.0699,
      "step": 1870
    },
    {
      "epoch": 1.0123855681206246,
      "grad_norm": 1.1882878541946411,
      "learning_rate": 1.797522886375875e-05,
      "loss": 0.1255,
      "step": 1880
    },
    {
      "epoch": 1.0177705977382876,
      "grad_norm": 2.2013187408447266,
      "learning_rate": 1.7964458804523425e-05,
      "loss": 0.0537,
      "step": 1890
    },
    {
      "epoch": 1.0231556273559506,
      "grad_norm": 2.2082741260528564,
      "learning_rate": 1.79536887452881e-05,
      "loss": 0.1188,
      "step": 1900
    },
    {
      "epoch": 1.0285406569736133,
      "grad_norm": 11.710225105285645,
      "learning_rate": 1.7942918686052774e-05,
      "loss": 0.1216,
      "step": 1910
    },
    {
      "epoch": 1.0339256865912763,
      "grad_norm": 3.226954936981201,
      "learning_rate": 1.793214862681745e-05,
      "loss": 0.0646,
      "step": 1920
    },
    {
      "epoch": 1.0393107162089392,
      "grad_norm": 0.5325719714164734,
      "learning_rate": 1.7921378567582125e-05,
      "loss": 0.1119,
      "step": 1930
    },
    {
      "epoch": 1.044695745826602,
      "grad_norm": 6.096660137176514,
      "learning_rate": 1.79106085083468e-05,
      "loss": 0.0618,
      "step": 1940
    },
    {
      "epoch": 1.050080775444265,
      "grad_norm": 1.1899429559707642,
      "learning_rate": 1.789983844911147e-05,
      "loss": 0.0805,
      "step": 1950
    },
    {
      "epoch": 1.0554658050619279,
      "grad_norm": 5.274652004241943,
      "learning_rate": 1.7889068389876144e-05,
      "loss": 0.0783,
      "step": 1960
    },
    {
      "epoch": 1.0608508346795906,
      "grad_norm": 4.802250385284424,
      "learning_rate": 1.787829833064082e-05,
      "loss": 0.0402,
      "step": 1970
    },
    {
      "epoch": 1.0662358642972536,
      "grad_norm": 9.872638702392578,
      "learning_rate": 1.7867528271405495e-05,
      "loss": 0.0952,
      "step": 1980
    },
    {
      "epoch": 1.0716208939149166,
      "grad_norm": 6.781702041625977,
      "learning_rate": 1.785675821217017e-05,
      "loss": 0.107,
      "step": 1990
    },
    {
      "epoch": 1.0770059235325795,
      "grad_norm": 0.29380732774734497,
      "learning_rate": 1.7845988152934843e-05,
      "loss": 0.1279,
      "step": 2000
    },
    {
      "epoch": 1.0823909531502423,
      "grad_norm": 5.038172721862793,
      "learning_rate": 1.7835218093699517e-05,
      "loss": 0.0975,
      "step": 2010
    },
    {
      "epoch": 1.0877759827679052,
      "grad_norm": 2.6722371578216553,
      "learning_rate": 1.782444803446419e-05,
      "loss": 0.0665,
      "step": 2020
    },
    {
      "epoch": 1.0931610123855682,
      "grad_norm": 3.87473726272583,
      "learning_rate": 1.7813677975228865e-05,
      "loss": 0.0635,
      "step": 2030
    },
    {
      "epoch": 1.098546042003231,
      "grad_norm": 4.647465705871582,
      "learning_rate": 1.780290791599354e-05,
      "loss": 0.1443,
      "step": 2040
    },
    {
      "epoch": 1.1039310716208939,
      "grad_norm": 2.926752805709839,
      "learning_rate": 1.7792137856758213e-05,
      "loss": 0.0681,
      "step": 2050
    },
    {
      "epoch": 1.1093161012385568,
      "grad_norm": 5.882272720336914,
      "learning_rate": 1.7781367797522888e-05,
      "loss": 0.0854,
      "step": 2060
    },
    {
      "epoch": 1.1147011308562198,
      "grad_norm": 8.614397048950195,
      "learning_rate": 1.777059773828756e-05,
      "loss": 0.0866,
      "step": 2070
    },
    {
      "epoch": 1.1200861604738825,
      "grad_norm": 4.589439392089844,
      "learning_rate": 1.7759827679052236e-05,
      "loss": 0.0697,
      "step": 2080
    },
    {
      "epoch": 1.1254711900915455,
      "grad_norm": 7.100574016571045,
      "learning_rate": 1.774905761981691e-05,
      "loss": 0.1058,
      "step": 2090
    },
    {
      "epoch": 1.1308562197092085,
      "grad_norm": 7.481743335723877,
      "learning_rate": 1.7738287560581584e-05,
      "loss": 0.0718,
      "step": 2100
    },
    {
      "epoch": 1.1362412493268712,
      "grad_norm": 6.183924198150635,
      "learning_rate": 1.7727517501346258e-05,
      "loss": 0.079,
      "step": 2110
    },
    {
      "epoch": 1.1416262789445342,
      "grad_norm": 5.259193420410156,
      "learning_rate": 1.7716747442110932e-05,
      "loss": 0.0905,
      "step": 2120
    },
    {
      "epoch": 1.1470113085621971,
      "grad_norm": 2.854450225830078,
      "learning_rate": 1.770597738287561e-05,
      "loss": 0.1287,
      "step": 2130
    },
    {
      "epoch": 1.15239633817986,
      "grad_norm": 1.6678403615951538,
      "learning_rate": 1.7695207323640283e-05,
      "loss": 0.0951,
      "step": 2140
    },
    {
      "epoch": 1.1577813677975228,
      "grad_norm": 5.366413116455078,
      "learning_rate": 1.7684437264404957e-05,
      "loss": 0.0925,
      "step": 2150
    },
    {
      "epoch": 1.1631663974151858,
      "grad_norm": 0.17235244810581207,
      "learning_rate": 1.7673667205169628e-05,
      "loss": 0.0457,
      "step": 2160
    },
    {
      "epoch": 1.1685514270328488,
      "grad_norm": 5.242607116699219,
      "learning_rate": 1.7662897145934302e-05,
      "loss": 0.1262,
      "step": 2170
    },
    {
      "epoch": 1.1739364566505115,
      "grad_norm": 6.289979457855225,
      "learning_rate": 1.765212708669898e-05,
      "loss": 0.0625,
      "step": 2180
    },
    {
      "epoch": 1.1793214862681745,
      "grad_norm": 1.4604140520095825,
      "learning_rate": 1.7641357027463653e-05,
      "loss": 0.129,
      "step": 2190
    },
    {
      "epoch": 1.1847065158858374,
      "grad_norm": 7.635212421417236,
      "learning_rate": 1.7630586968228327e-05,
      "loss": 0.075,
      "step": 2200
    },
    {
      "epoch": 1.1900915455035004,
      "grad_norm": 0.4331016540527344,
      "learning_rate": 1.7619816908993e-05,
      "loss": 0.0395,
      "step": 2210
    },
    {
      "epoch": 1.1954765751211631,
      "grad_norm": 6.480723857879639,
      "learning_rate": 1.7609046849757676e-05,
      "loss": 0.0553,
      "step": 2220
    },
    {
      "epoch": 1.200861604738826,
      "grad_norm": 11.71823787689209,
      "learning_rate": 1.759827679052235e-05,
      "loss": 0.0589,
      "step": 2230
    },
    {
      "epoch": 1.206246634356489,
      "grad_norm": 8.407638549804688,
      "learning_rate": 1.7587506731287024e-05,
      "loss": 0.1167,
      "step": 2240
    },
    {
      "epoch": 1.2116316639741518,
      "grad_norm": 8.499982833862305,
      "learning_rate": 1.7576736672051698e-05,
      "loss": 0.0768,
      "step": 2250
    },
    {
      "epoch": 1.2170166935918147,
      "grad_norm": 0.5793482661247253,
      "learning_rate": 1.756596661281637e-05,
      "loss": 0.1424,
      "step": 2260
    },
    {
      "epoch": 1.2224017232094777,
      "grad_norm": 3.4496498107910156,
      "learning_rate": 1.7555196553581046e-05,
      "loss": 0.0842,
      "step": 2270
    },
    {
      "epoch": 1.2277867528271407,
      "grad_norm": 0.5060204267501831,
      "learning_rate": 1.754442649434572e-05,
      "loss": 0.072,
      "step": 2280
    },
    {
      "epoch": 1.2331717824448034,
      "grad_norm": 11.034462928771973,
      "learning_rate": 1.7533656435110397e-05,
      "loss": 0.0803,
      "step": 2290
    },
    {
      "epoch": 1.2385568120624664,
      "grad_norm": 13.1474609375,
      "learning_rate": 1.7522886375875068e-05,
      "loss": 0.1149,
      "step": 2300
    },
    {
      "epoch": 1.2439418416801293,
      "grad_norm": 6.030405044555664,
      "learning_rate": 1.7512116316639742e-05,
      "loss": 0.0788,
      "step": 2310
    },
    {
      "epoch": 1.249326871297792,
      "grad_norm": 6.5778374671936035,
      "learning_rate": 1.7501346257404416e-05,
      "loss": 0.0553,
      "step": 2320
    },
    {
      "epoch": 1.254711900915455,
      "grad_norm": 8.561310768127441,
      "learning_rate": 1.749057619816909e-05,
      "loss": 0.0987,
      "step": 2330
    },
    {
      "epoch": 1.260096930533118,
      "grad_norm": 0.24367034435272217,
      "learning_rate": 1.7479806138933767e-05,
      "loss": 0.0941,
      "step": 2340
    },
    {
      "epoch": 1.265481960150781,
      "grad_norm": 0.2706677317619324,
      "learning_rate": 1.746903607969844e-05,
      "loss": 0.0924,
      "step": 2350
    },
    {
      "epoch": 1.2708669897684437,
      "grad_norm": 3.712886095046997,
      "learning_rate": 1.7458266020463115e-05,
      "loss": 0.0663,
      "step": 2360
    },
    {
      "epoch": 1.2762520193861067,
      "grad_norm": 1.1982651948928833,
      "learning_rate": 1.7447495961227786e-05,
      "loss": 0.0235,
      "step": 2370
    },
    {
      "epoch": 1.2816370490037694,
      "grad_norm": 7.207663536071777,
      "learning_rate": 1.743672590199246e-05,
      "loss": 0.125,
      "step": 2380
    },
    {
      "epoch": 1.2870220786214324,
      "grad_norm": 8.383898735046387,
      "learning_rate": 1.7425955842757138e-05,
      "loss": 0.0983,
      "step": 2390
    },
    {
      "epoch": 1.2924071082390953,
      "grad_norm": 2.4890248775482178,
      "learning_rate": 1.741518578352181e-05,
      "loss": 0.074,
      "step": 2400
    },
    {
      "epoch": 1.2977921378567583,
      "grad_norm": 5.175917625427246,
      "learning_rate": 1.7404415724286486e-05,
      "loss": 0.1551,
      "step": 2410
    },
    {
      "epoch": 1.303177167474421,
      "grad_norm": 0.9388332962989807,
      "learning_rate": 1.739364566505116e-05,
      "loss": 0.1007,
      "step": 2420
    },
    {
      "epoch": 1.308562197092084,
      "grad_norm": 11.156424522399902,
      "learning_rate": 1.7382875605815834e-05,
      "loss": 0.1389,
      "step": 2430
    },
    {
      "epoch": 1.313947226709747,
      "grad_norm": 10.989344596862793,
      "learning_rate": 1.7372105546580508e-05,
      "loss": 0.0868,
      "step": 2440
    },
    {
      "epoch": 1.3193322563274097,
      "grad_norm": 4.642683029174805,
      "learning_rate": 1.7361335487345182e-05,
      "loss": 0.0612,
      "step": 2450
    },
    {
      "epoch": 1.3247172859450727,
      "grad_norm": 4.7634172439575195,
      "learning_rate": 1.7350565428109856e-05,
      "loss": 0.0713,
      "step": 2460
    },
    {
      "epoch": 1.3301023155627356,
      "grad_norm": 0.9296298623085022,
      "learning_rate": 1.733979536887453e-05,
      "loss": 0.0885,
      "step": 2470
    },
    {
      "epoch": 1.3354873451803986,
      "grad_norm": 4.778661251068115,
      "learning_rate": 1.7329025309639204e-05,
      "loss": 0.0661,
      "step": 2480
    },
    {
      "epoch": 1.3408723747980613,
      "grad_norm": 13.708284378051758,
      "learning_rate": 1.7318255250403878e-05,
      "loss": 0.092,
      "step": 2490
    },
    {
      "epoch": 1.3462574044157243,
      "grad_norm": 1.5048739910125732,
      "learning_rate": 1.7307485191168555e-05,
      "loss": 0.0602,
      "step": 2500
    },
    {
      "epoch": 1.3516424340333872,
      "grad_norm": 6.666408061981201,
      "learning_rate": 1.7296715131933226e-05,
      "loss": 0.0538,
      "step": 2510
    },
    {
      "epoch": 1.35702746365105,
      "grad_norm": 6.778573513031006,
      "learning_rate": 1.72859450726979e-05,
      "loss": 0.0574,
      "step": 2520
    },
    {
      "epoch": 1.362412493268713,
      "grad_norm": 7.919979572296143,
      "learning_rate": 1.7275175013462574e-05,
      "loss": 0.0906,
      "step": 2530
    },
    {
      "epoch": 1.367797522886376,
      "grad_norm": 4.170694828033447,
      "learning_rate": 1.7264404954227248e-05,
      "loss": 0.0395,
      "step": 2540
    },
    {
      "epoch": 1.3731825525040389,
      "grad_norm": 7.344732284545898,
      "learning_rate": 1.7253634894991926e-05,
      "loss": 0.0734,
      "step": 2550
    },
    {
      "epoch": 1.3785675821217016,
      "grad_norm": 2.3168256282806396,
      "learning_rate": 1.72428648357566e-05,
      "loss": 0.0754,
      "step": 2560
    },
    {
      "epoch": 1.3839526117393646,
      "grad_norm": 5.560019016265869,
      "learning_rate": 1.7232094776521274e-05,
      "loss": 0.0605,
      "step": 2570
    },
    {
      "epoch": 1.3893376413570275,
      "grad_norm": 7.275450229644775,
      "learning_rate": 1.7221324717285944e-05,
      "loss": 0.0837,
      "step": 2580
    },
    {
      "epoch": 1.3947226709746903,
      "grad_norm": 1.646761178970337,
      "learning_rate": 1.721055465805062e-05,
      "loss": 0.0981,
      "step": 2590
    },
    {
      "epoch": 1.4001077005923532,
      "grad_norm": 2.6325483322143555,
      "learning_rate": 1.7199784598815296e-05,
      "loss": 0.1187,
      "step": 2600
    },
    {
      "epoch": 1.4054927302100162,
      "grad_norm": 37.42554473876953,
      "learning_rate": 1.718901453957997e-05,
      "loss": 0.0591,
      "step": 2610
    },
    {
      "epoch": 1.4108777598276792,
      "grad_norm": 2.3649024963378906,
      "learning_rate": 1.7178244480344644e-05,
      "loss": 0.0522,
      "step": 2620
    },
    {
      "epoch": 1.416262789445342,
      "grad_norm": 7.84782075881958,
      "learning_rate": 1.7167474421109318e-05,
      "loss": 0.0444,
      "step": 2630
    },
    {
      "epoch": 1.4216478190630049,
      "grad_norm": 6.0838704109191895,
      "learning_rate": 1.7156704361873992e-05,
      "loss": 0.0568,
      "step": 2640
    },
    {
      "epoch": 1.4270328486806678,
      "grad_norm": 3.884108304977417,
      "learning_rate": 1.7145934302638666e-05,
      "loss": 0.0379,
      "step": 2650
    },
    {
      "epoch": 1.4324178782983306,
      "grad_norm": 0.11167294532060623,
      "learning_rate": 1.713516424340334e-05,
      "loss": 0.0542,
      "step": 2660
    },
    {
      "epoch": 1.4378029079159935,
      "grad_norm": 8.351853370666504,
      "learning_rate": 1.7124394184168014e-05,
      "loss": 0.0605,
      "step": 2670
    },
    {
      "epoch": 1.4431879375336565,
      "grad_norm": 6.822620391845703,
      "learning_rate": 1.7113624124932688e-05,
      "loss": 0.0877,
      "step": 2680
    },
    {
      "epoch": 1.4485729671513194,
      "grad_norm": 0.7173211574554443,
      "learning_rate": 1.7102854065697362e-05,
      "loss": 0.0497,
      "step": 2690
    },
    {
      "epoch": 1.4539579967689822,
      "grad_norm": 4.378771781921387,
      "learning_rate": 1.7092084006462036e-05,
      "loss": 0.1615,
      "step": 2700
    },
    {
      "epoch": 1.4593430263866451,
      "grad_norm": 36.16952133178711,
      "learning_rate": 1.7081313947226714e-05,
      "loss": 0.1041,
      "step": 2710
    },
    {
      "epoch": 1.4647280560043079,
      "grad_norm": 1.032867193222046,
      "learning_rate": 1.7070543887991384e-05,
      "loss": 0.0713,
      "step": 2720
    },
    {
      "epoch": 1.4701130856219708,
      "grad_norm": 5.354870796203613,
      "learning_rate": 1.7059773828756058e-05,
      "loss": 0.118,
      "step": 2730
    },
    {
      "epoch": 1.4754981152396338,
      "grad_norm": 4.277135372161865,
      "learning_rate": 1.7049003769520732e-05,
      "loss": 0.0755,
      "step": 2740
    },
    {
      "epoch": 1.4808831448572968,
      "grad_norm": 0.24556788802146912,
      "learning_rate": 1.7038233710285406e-05,
      "loss": 0.0605,
      "step": 2750
    },
    {
      "epoch": 1.4862681744749597,
      "grad_norm": 1.7122290134429932,
      "learning_rate": 1.7027463651050084e-05,
      "loss": 0.0483,
      "step": 2760
    },
    {
      "epoch": 1.4916532040926225,
      "grad_norm": 6.328273296356201,
      "learning_rate": 1.7016693591814758e-05,
      "loss": 0.0528,
      "step": 2770
    },
    {
      "epoch": 1.4970382337102854,
      "grad_norm": 0.03943921625614166,
      "learning_rate": 1.7005923532579432e-05,
      "loss": 0.0243,
      "step": 2780
    },
    {
      "epoch": 1.5024232633279482,
      "grad_norm": 5.228513240814209,
      "learning_rate": 1.6995153473344103e-05,
      "loss": 0.0817,
      "step": 2790
    },
    {
      "epoch": 1.5078082929456111,
      "grad_norm": 11.52298641204834,
      "learning_rate": 1.6984383414108777e-05,
      "loss": 0.0946,
      "step": 2800
    },
    {
      "epoch": 1.513193322563274,
      "grad_norm": 11.941008567810059,
      "learning_rate": 1.6973613354873454e-05,
      "loss": 0.1229,
      "step": 2810
    },
    {
      "epoch": 1.518578352180937,
      "grad_norm": 1.7651715278625488,
      "learning_rate": 1.6962843295638128e-05,
      "loss": 0.1376,
      "step": 2820
    },
    {
      "epoch": 1.5239633817986,
      "grad_norm": 0.2983749806880951,
      "learning_rate": 1.6952073236402802e-05,
      "loss": 0.0808,
      "step": 2830
    },
    {
      "epoch": 1.5293484114162628,
      "grad_norm": 4.6140522956848145,
      "learning_rate": 1.6941303177167476e-05,
      "loss": 0.0359,
      "step": 2840
    },
    {
      "epoch": 1.5347334410339257,
      "grad_norm": 1.3726636171340942,
      "learning_rate": 1.693053311793215e-05,
      "loss": 0.0548,
      "step": 2850
    },
    {
      "epoch": 1.5401184706515885,
      "grad_norm": 7.025284290313721,
      "learning_rate": 1.6919763058696824e-05,
      "loss": 0.0503,
      "step": 2860
    },
    {
      "epoch": 1.5455035002692514,
      "grad_norm": 0.016106069087982178,
      "learning_rate": 1.6908992999461498e-05,
      "loss": 0.0514,
      "step": 2870
    },
    {
      "epoch": 1.5508885298869144,
      "grad_norm": 4.827856540679932,
      "learning_rate": 1.6898222940226172e-05,
      "loss": 0.0541,
      "step": 2880
    },
    {
      "epoch": 1.5562735595045774,
      "grad_norm": 9.300636291503906,
      "learning_rate": 1.6887452880990846e-05,
      "loss": 0.1347,
      "step": 2890
    },
    {
      "epoch": 1.5616585891222403,
      "grad_norm": 0.28365838527679443,
      "learning_rate": 1.687668282175552e-05,
      "loss": 0.0738,
      "step": 2900
    },
    {
      "epoch": 1.567043618739903,
      "grad_norm": 0.04353669285774231,
      "learning_rate": 1.6865912762520194e-05,
      "loss": 0.0819,
      "step": 2910
    },
    {
      "epoch": 1.572428648357566,
      "grad_norm": 2.4681904315948486,
      "learning_rate": 1.6855142703284872e-05,
      "loss": 0.0681,
      "step": 2920
    },
    {
      "epoch": 1.5778136779752288,
      "grad_norm": 4.6952643394470215,
      "learning_rate": 1.6844372644049546e-05,
      "loss": 0.1077,
      "step": 2930
    },
    {
      "epoch": 1.5831987075928917,
      "grad_norm": 4.276517868041992,
      "learning_rate": 1.6833602584814216e-05,
      "loss": 0.0716,
      "step": 2940
    },
    {
      "epoch": 1.5885837372105547,
      "grad_norm": 4.025656223297119,
      "learning_rate": 1.682283252557889e-05,
      "loss": 0.0677,
      "step": 2950
    },
    {
      "epoch": 1.5939687668282176,
      "grad_norm": 6.032780647277832,
      "learning_rate": 1.6812062466343565e-05,
      "loss": 0.0653,
      "step": 2960
    },
    {
      "epoch": 1.5993537964458806,
      "grad_norm": 1.360717535018921,
      "learning_rate": 1.6801292407108242e-05,
      "loss": 0.0624,
      "step": 2970
    },
    {
      "epoch": 1.6047388260635433,
      "grad_norm": 0.048332955688238144,
      "learning_rate": 1.6790522347872916e-05,
      "loss": 0.0663,
      "step": 2980
    },
    {
      "epoch": 1.610123855681206,
      "grad_norm": 0.10862446576356888,
      "learning_rate": 1.677975228863759e-05,
      "loss": 0.0322,
      "step": 2990
    },
    {
      "epoch": 1.615508885298869,
      "grad_norm": 4.040528297424316,
      "learning_rate": 1.6768982229402264e-05,
      "loss": 0.0666,
      "step": 3000
    },
    {
      "epoch": 1.620893914916532,
      "grad_norm": 1.1262849569320679,
      "learning_rate": 1.6758212170166938e-05,
      "loss": 0.0831,
      "step": 3010
    },
    {
      "epoch": 1.626278944534195,
      "grad_norm": 3.6691253185272217,
      "learning_rate": 1.6747442110931612e-05,
      "loss": 0.1307,
      "step": 3020
    },
    {
      "epoch": 1.631663974151858,
      "grad_norm": 5.64491605758667,
      "learning_rate": 1.6736672051696286e-05,
      "loss": 0.0946,
      "step": 3030
    },
    {
      "epoch": 1.637049003769521,
      "grad_norm": 0.09888233989477158,
      "learning_rate": 1.672590199246096e-05,
      "loss": 0.1133,
      "step": 3040
    },
    {
      "epoch": 1.6424340333871836,
      "grad_norm": 4.826819896697998,
      "learning_rate": 1.6715131933225634e-05,
      "loss": 0.0713,
      "step": 3050
    },
    {
      "epoch": 1.6478190630048464,
      "grad_norm": 2.139380931854248,
      "learning_rate": 1.670436187399031e-05,
      "loss": 0.0573,
      "step": 3060
    },
    {
      "epoch": 1.6532040926225093,
      "grad_norm": 5.906825065612793,
      "learning_rate": 1.6693591814754982e-05,
      "loss": 0.1022,
      "step": 3070
    },
    {
      "epoch": 1.6585891222401723,
      "grad_norm": 6.613439559936523,
      "learning_rate": 1.6682821755519656e-05,
      "loss": 0.0668,
      "step": 3080
    },
    {
      "epoch": 1.6639741518578353,
      "grad_norm": 4.420385837554932,
      "learning_rate": 1.667205169628433e-05,
      "loss": 0.0828,
      "step": 3090
    },
    {
      "epoch": 1.6693591814754982,
      "grad_norm": 6.679767608642578,
      "learning_rate": 1.6661281637049004e-05,
      "loss": 0.0953,
      "step": 3100
    },
    {
      "epoch": 1.674744211093161,
      "grad_norm": 2.903181791305542,
      "learning_rate": 1.665051157781368e-05,
      "loss": 0.0491,
      "step": 3110
    },
    {
      "epoch": 1.680129240710824,
      "grad_norm": 3.866988182067871,
      "learning_rate": 1.6639741518578353e-05,
      "loss": 0.0698,
      "step": 3120
    },
    {
      "epoch": 1.6855142703284867,
      "grad_norm": 3.9951884746551514,
      "learning_rate": 1.662897145934303e-05,
      "loss": 0.0745,
      "step": 3130
    },
    {
      "epoch": 1.6908992999461496,
      "grad_norm": 5.410384178161621,
      "learning_rate": 1.6618201400107704e-05,
      "loss": 0.0882,
      "step": 3140
    },
    {
      "epoch": 1.6962843295638126,
      "grad_norm": 2.21185040473938,
      "learning_rate": 1.6607431340872375e-05,
      "loss": 0.0721,
      "step": 3150
    },
    {
      "epoch": 1.7016693591814755,
      "grad_norm": 5.53230619430542,
      "learning_rate": 1.659666128163705e-05,
      "loss": 0.0637,
      "step": 3160
    },
    {
      "epoch": 1.7070543887991385,
      "grad_norm": 0.8353804349899292,
      "learning_rate": 1.6585891222401723e-05,
      "loss": 0.1617,
      "step": 3170
    },
    {
      "epoch": 1.7124394184168013,
      "grad_norm": 4.1104583740234375,
      "learning_rate": 1.65751211631664e-05,
      "loss": 0.0801,
      "step": 3180
    },
    {
      "epoch": 1.7178244480344642,
      "grad_norm": 0.046511005610227585,
      "learning_rate": 1.6564351103931074e-05,
      "loss": 0.0538,
      "step": 3190
    },
    {
      "epoch": 1.723209477652127,
      "grad_norm": 3.395345687866211,
      "learning_rate": 1.6553581044695748e-05,
      "loss": 0.0697,
      "step": 3200
    },
    {
      "epoch": 1.72859450726979,
      "grad_norm": 13.70362377166748,
      "learning_rate": 1.6542810985460422e-05,
      "loss": 0.1094,
      "step": 3210
    },
    {
      "epoch": 1.7339795368874529,
      "grad_norm": 0.9366574287414551,
      "learning_rate": 1.6532040926225096e-05,
      "loss": 0.0762,
      "step": 3220
    },
    {
      "epoch": 1.7393645665051158,
      "grad_norm": 0.21848945319652557,
      "learning_rate": 1.652127086698977e-05,
      "loss": 0.0542,
      "step": 3230
    },
    {
      "epoch": 1.7447495961227788,
      "grad_norm": 3.590853691101074,
      "learning_rate": 1.6510500807754444e-05,
      "loss": 0.1053,
      "step": 3240
    },
    {
      "epoch": 1.7501346257404415,
      "grad_norm": 0.8855035901069641,
      "learning_rate": 1.649973074851912e-05,
      "loss": 0.0468,
      "step": 3250
    },
    {
      "epoch": 1.7555196553581045,
      "grad_norm": 3.440572500228882,
      "learning_rate": 1.6488960689283792e-05,
      "loss": 0.0622,
      "step": 3260
    },
    {
      "epoch": 1.7609046849757672,
      "grad_norm": 4.7537665367126465,
      "learning_rate": 1.6478190630048467e-05,
      "loss": 0.0715,
      "step": 3270
    },
    {
      "epoch": 1.7662897145934302,
      "grad_norm": 4.644999980926514,
      "learning_rate": 1.646742057081314e-05,
      "loss": 0.0451,
      "step": 3280
    },
    {
      "epoch": 1.7716747442110932,
      "grad_norm": 0.01866721361875534,
      "learning_rate": 1.6456650511577815e-05,
      "loss": 0.0529,
      "step": 3290
    },
    {
      "epoch": 1.7770597738287561,
      "grad_norm": 0.9513888359069824,
      "learning_rate": 1.644588045234249e-05,
      "loss": 0.0639,
      "step": 3300
    },
    {
      "epoch": 1.782444803446419,
      "grad_norm": 0.6002048850059509,
      "learning_rate": 1.6435110393107163e-05,
      "loss": 0.0633,
      "step": 3310
    },
    {
      "epoch": 1.7878298330640818,
      "grad_norm": 5.168825626373291,
      "learning_rate": 1.6424340333871837e-05,
      "loss": 0.1179,
      "step": 3320
    },
    {
      "epoch": 1.7932148626817448,
      "grad_norm": 2.290149211883545,
      "learning_rate": 1.641357027463651e-05,
      "loss": 0.0584,
      "step": 3330
    },
    {
      "epoch": 1.7985998922994075,
      "grad_norm": 2.0096094608306885,
      "learning_rate": 1.6402800215401188e-05,
      "loss": 0.0557,
      "step": 3340
    },
    {
      "epoch": 1.8039849219170705,
      "grad_norm": 6.073141098022461,
      "learning_rate": 1.6392030156165862e-05,
      "loss": 0.0728,
      "step": 3350
    },
    {
      "epoch": 1.8093699515347335,
      "grad_norm": 2.0516409873962402,
      "learning_rate": 1.6381260096930533e-05,
      "loss": 0.0739,
      "step": 3360
    },
    {
      "epoch": 1.8147549811523964,
      "grad_norm": 5.678369045257568,
      "learning_rate": 1.6370490037695207e-05,
      "loss": 0.0359,
      "step": 3370
    },
    {
      "epoch": 1.8201400107700594,
      "grad_norm": 0.9972606897354126,
      "learning_rate": 1.635971997845988e-05,
      "loss": 0.0598,
      "step": 3380
    },
    {
      "epoch": 1.8255250403877221,
      "grad_norm": 4.3669538497924805,
      "learning_rate": 1.634894991922456e-05,
      "loss": 0.0661,
      "step": 3390
    },
    {
      "epoch": 1.830910070005385,
      "grad_norm": 4.003198146820068,
      "learning_rate": 1.6338179859989232e-05,
      "loss": 0.1237,
      "step": 3400
    },
    {
      "epoch": 1.8362950996230478,
      "grad_norm": 4.304878234863281,
      "learning_rate": 1.6327409800753906e-05,
      "loss": 0.076,
      "step": 3410
    },
    {
      "epoch": 1.8416801292407108,
      "grad_norm": 0.6643492579460144,
      "learning_rate": 1.631663974151858e-05,
      "loss": 0.0627,
      "step": 3420
    },
    {
      "epoch": 1.8470651588583737,
      "grad_norm": 0.048654649406671524,
      "learning_rate": 1.6305869682283255e-05,
      "loss": 0.063,
      "step": 3430
    },
    {
      "epoch": 1.8524501884760367,
      "grad_norm": 3.7430200576782227,
      "learning_rate": 1.629509962304793e-05,
      "loss": 0.0564,
      "step": 3440
    },
    {
      "epoch": 1.8578352180936997,
      "grad_norm": 0.16469907760620117,
      "learning_rate": 1.6284329563812603e-05,
      "loss": 0.06,
      "step": 3450
    },
    {
      "epoch": 1.8632202477113624,
      "grad_norm": 6.63988733291626,
      "learning_rate": 1.6273559504577277e-05,
      "loss": 0.0403,
      "step": 3460
    },
    {
      "epoch": 1.8686052773290251,
      "grad_norm": 1.793119192123413,
      "learning_rate": 1.626278944534195e-05,
      "loss": 0.0516,
      "step": 3470
    },
    {
      "epoch": 1.8739903069466881,
      "grad_norm": 0.024832677096128464,
      "learning_rate": 1.6252019386106625e-05,
      "loss": 0.0537,
      "step": 3480
    },
    {
      "epoch": 1.879375336564351,
      "grad_norm": 0.18747478723526,
      "learning_rate": 1.62412493268713e-05,
      "loss": 0.0541,
      "step": 3490
    },
    {
      "epoch": 1.884760366182014,
      "grad_norm": 4.030195236206055,
      "learning_rate": 1.6230479267635973e-05,
      "loss": 0.0548,
      "step": 3500
    },
    {
      "epoch": 1.890145395799677,
      "grad_norm": 6.094484329223633,
      "learning_rate": 1.6219709208400647e-05,
      "loss": 0.0446,
      "step": 3510
    },
    {
      "epoch": 1.89553042541734,
      "grad_norm": 2.1956560611724854,
      "learning_rate": 1.620893914916532e-05,
      "loss": 0.0755,
      "step": 3520
    },
    {
      "epoch": 1.9009154550350027,
      "grad_norm": 4.077677249908447,
      "learning_rate": 1.6198169089929995e-05,
      "loss": 0.1014,
      "step": 3530
    },
    {
      "epoch": 1.9063004846526654,
      "grad_norm": 7.050076961517334,
      "learning_rate": 1.618739903069467e-05,
      "loss": 0.0488,
      "step": 3540
    },
    {
      "epoch": 1.9116855142703284,
      "grad_norm": 0.5934693217277527,
      "learning_rate": 1.6176628971459346e-05,
      "loss": 0.0835,
      "step": 3550
    },
    {
      "epoch": 1.9170705438879914,
      "grad_norm": 3.27640700340271,
      "learning_rate": 1.616585891222402e-05,
      "loss": 0.036,
      "step": 3560
    },
    {
      "epoch": 1.9224555735056543,
      "grad_norm": 0.08747022598981857,
      "learning_rate": 1.615508885298869e-05,
      "loss": 0.1417,
      "step": 3570
    },
    {
      "epoch": 1.9278406031233173,
      "grad_norm": 0.3538491725921631,
      "learning_rate": 1.6144318793753365e-05,
      "loss": 0.0488,
      "step": 3580
    },
    {
      "epoch": 1.93322563274098,
      "grad_norm": 4.145418167114258,
      "learning_rate": 1.613354873451804e-05,
      "loss": 0.0889,
      "step": 3590
    },
    {
      "epoch": 1.938610662358643,
      "grad_norm": 3.175569772720337,
      "learning_rate": 1.6122778675282717e-05,
      "loss": 0.0413,
      "step": 3600
    },
    {
      "epoch": 1.9439956919763057,
      "grad_norm": 0.17493993043899536,
      "learning_rate": 1.611200861604739e-05,
      "loss": 0.0853,
      "step": 3610
    },
    {
      "epoch": 1.9493807215939687,
      "grad_norm": 3.491271495819092,
      "learning_rate": 1.6101238556812065e-05,
      "loss": 0.0682,
      "step": 3620
    },
    {
      "epoch": 1.9547657512116317,
      "grad_norm": 3.302577495574951,
      "learning_rate": 1.609046849757674e-05,
      "loss": 0.0646,
      "step": 3630
    },
    {
      "epoch": 1.9601507808292946,
      "grad_norm": 6.174381256103516,
      "learning_rate": 1.6079698438341413e-05,
      "loss": 0.095,
      "step": 3640
    },
    {
      "epoch": 1.9655358104469576,
      "grad_norm": 6.124395370483398,
      "learning_rate": 1.6068928379106087e-05,
      "loss": 0.0646,
      "step": 3650
    },
    {
      "epoch": 1.9709208400646203,
      "grad_norm": 0.22435197234153748,
      "learning_rate": 1.605815831987076e-05,
      "loss": 0.1087,
      "step": 3660
    },
    {
      "epoch": 1.9763058696822833,
      "grad_norm": 2.078002691268921,
      "learning_rate": 1.6047388260635435e-05,
      "loss": 0.052,
      "step": 3670
    },
    {
      "epoch": 1.981690899299946,
      "grad_norm": 1.4578909873962402,
      "learning_rate": 1.603661820140011e-05,
      "loss": 0.0666,
      "step": 3680
    },
    {
      "epoch": 1.987075928917609,
      "grad_norm": 1.1693599224090576,
      "learning_rate": 1.6025848142164783e-05,
      "loss": 0.0727,
      "step": 3690
    },
    {
      "epoch": 1.992460958535272,
      "grad_norm": 4.354324817657471,
      "learning_rate": 1.6015078082929457e-05,
      "loss": 0.0779,
      "step": 3700
    },
    {
      "epoch": 1.997845988152935,
      "grad_norm": 3.4891152381896973,
      "learning_rate": 1.600430802369413e-05,
      "loss": 0.0448,
      "step": 3710
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9791928391959799,
      "eval_f1": 0.9233882625036137,
      "eval_loss": 0.06612813472747803,
      "eval_precision": 0.9290285049447353,
      "eval_recall": 0.917816091954023,
      "eval_runtime": 286.3886,
      "eval_samples_per_second": 44.485,
      "eval_steps_per_second": 1.393,
      "step": 3714
    },
    {
      "epoch": 2.003231017770598,
      "grad_norm": 0.059925470501184464,
      "learning_rate": 1.5993537964458805e-05,
      "loss": 0.0464,
      "step": 3720
    },
    {
      "epoch": 2.008616047388261,
      "grad_norm": 0.0285402312874794,
      "learning_rate": 1.598276790522348e-05,
      "loss": 0.1053,
      "step": 3730
    },
    {
      "epoch": 2.0140010770059233,
      "grad_norm": 1.116502046585083,
      "learning_rate": 1.5971997845988153e-05,
      "loss": 0.0512,
      "step": 3740
    },
    {
      "epoch": 2.0193861066235863,
      "grad_norm": 4.843655109405518,
      "learning_rate": 1.5961227786752827e-05,
      "loss": 0.0379,
      "step": 3750
    },
    {
      "epoch": 2.0247711362412493,
      "grad_norm": 0.8098581433296204,
      "learning_rate": 1.5950457727517505e-05,
      "loss": 0.035,
      "step": 3760
    },
    {
      "epoch": 2.0301561658589122,
      "grad_norm": 2.365630626678467,
      "learning_rate": 1.593968766828218e-05,
      "loss": 0.0537,
      "step": 3770
    },
    {
      "epoch": 2.035541195476575,
      "grad_norm": 3.527311086654663,
      "learning_rate": 1.592891760904685e-05,
      "loss": 0.0791,
      "step": 3780
    },
    {
      "epoch": 2.040926225094238,
      "grad_norm": 2.1931471824645996,
      "learning_rate": 1.5918147549811523e-05,
      "loss": 0.0234,
      "step": 3790
    },
    {
      "epoch": 2.046311254711901,
      "grad_norm": 0.2909884750843048,
      "learning_rate": 1.59073774905762e-05,
      "loss": 0.0617,
      "step": 3800
    },
    {
      "epoch": 2.0516962843295636,
      "grad_norm": 11.982576370239258,
      "learning_rate": 1.5896607431340875e-05,
      "loss": 0.0445,
      "step": 3810
    },
    {
      "epoch": 2.0570813139472266,
      "grad_norm": 1.581450343132019,
      "learning_rate": 1.588583737210555e-05,
      "loss": 0.084,
      "step": 3820
    },
    {
      "epoch": 2.0624663435648896,
      "grad_norm": 0.02880018763244152,
      "learning_rate": 1.5875067312870223e-05,
      "loss": 0.0194,
      "step": 3830
    },
    {
      "epoch": 2.0678513731825525,
      "grad_norm": 0.07443564385175705,
      "learning_rate": 1.5864297253634897e-05,
      "loss": 0.0181,
      "step": 3840
    },
    {
      "epoch": 2.0732364028002155,
      "grad_norm": 7.345201015472412,
      "learning_rate": 1.585352719439957e-05,
      "loss": 0.064,
      "step": 3850
    },
    {
      "epoch": 2.0786214324178784,
      "grad_norm": 1.1160072088241577,
      "learning_rate": 1.5842757135164245e-05,
      "loss": 0.0455,
      "step": 3860
    },
    {
      "epoch": 2.0840064620355414,
      "grad_norm": 5.182699680328369,
      "learning_rate": 1.583198707592892e-05,
      "loss": 0.0519,
      "step": 3870
    },
    {
      "epoch": 2.089391491653204,
      "grad_norm": 1.9098975658416748,
      "learning_rate": 1.5821217016693593e-05,
      "loss": 0.0743,
      "step": 3880
    },
    {
      "epoch": 2.094776521270867,
      "grad_norm": 2.240001916885376,
      "learning_rate": 1.5810446957458267e-05,
      "loss": 0.0553,
      "step": 3890
    },
    {
      "epoch": 2.10016155088853,
      "grad_norm": 1.1311581134796143,
      "learning_rate": 1.579967689822294e-05,
      "loss": 0.0468,
      "step": 3900
    },
    {
      "epoch": 2.105546580506193,
      "grad_norm": 8.510758399963379,
      "learning_rate": 1.5788906838987615e-05,
      "loss": 0.0591,
      "step": 3910
    },
    {
      "epoch": 2.1109316101238558,
      "grad_norm": 3.2116827964782715,
      "learning_rate": 1.577813677975229e-05,
      "loss": 0.0554,
      "step": 3920
    },
    {
      "epoch": 2.1163166397415187,
      "grad_norm": 4.576723575592041,
      "learning_rate": 1.5767366720516963e-05,
      "loss": 0.0754,
      "step": 3930
    },
    {
      "epoch": 2.1217016693591813,
      "grad_norm": 8.458757400512695,
      "learning_rate": 1.5756596661281637e-05,
      "loss": 0.0733,
      "step": 3940
    },
    {
      "epoch": 2.127086698976844,
      "grad_norm": 0.6570366024971008,
      "learning_rate": 1.574582660204631e-05,
      "loss": 0.0376,
      "step": 3950
    },
    {
      "epoch": 2.132471728594507,
      "grad_norm": 0.16095103323459625,
      "learning_rate": 1.5735056542810985e-05,
      "loss": 0.0427,
      "step": 3960
    },
    {
      "epoch": 2.13785675821217,
      "grad_norm": 0.4638773798942566,
      "learning_rate": 1.5724286483575663e-05,
      "loss": 0.0464,
      "step": 3970
    },
    {
      "epoch": 2.143241787829833,
      "grad_norm": 2.0426886081695557,
      "learning_rate": 1.5713516424340337e-05,
      "loss": 0.0461,
      "step": 3980
    },
    {
      "epoch": 2.148626817447496,
      "grad_norm": 9.898427963256836,
      "learning_rate": 1.5702746365105007e-05,
      "loss": 0.0961,
      "step": 3990
    },
    {
      "epoch": 2.154011847065159,
      "grad_norm": 0.2766062617301941,
      "learning_rate": 1.569197630586968e-05,
      "loss": 0.068,
      "step": 4000
    },
    {
      "epoch": 2.1593968766828215,
      "grad_norm": 0.026613933965563774,
      "learning_rate": 1.568120624663436e-05,
      "loss": 0.033,
      "step": 4010
    },
    {
      "epoch": 2.1647819063004845,
      "grad_norm": 0.2847446799278259,
      "learning_rate": 1.5670436187399033e-05,
      "loss": 0.0581,
      "step": 4020
    },
    {
      "epoch": 2.1701669359181475,
      "grad_norm": 3.792736768722534,
      "learning_rate": 1.5659666128163707e-05,
      "loss": 0.024,
      "step": 4030
    },
    {
      "epoch": 2.1755519655358104,
      "grad_norm": 1.5251692533493042,
      "learning_rate": 1.564889606892838e-05,
      "loss": 0.0661,
      "step": 4040
    },
    {
      "epoch": 2.1809369951534734,
      "grad_norm": 0.010741588659584522,
      "learning_rate": 1.5638126009693055e-05,
      "loss": 0.0371,
      "step": 4050
    },
    {
      "epoch": 2.1863220247711364,
      "grad_norm": 6.175940036773682,
      "learning_rate": 1.562735595045773e-05,
      "loss": 0.11,
      "step": 4060
    },
    {
      "epoch": 2.1917070543887993,
      "grad_norm": 0.03411238640546799,
      "learning_rate": 1.5616585891222403e-05,
      "loss": 0.0299,
      "step": 4070
    },
    {
      "epoch": 2.197092084006462,
      "grad_norm": 0.549146294593811,
      "learning_rate": 1.5605815831987077e-05,
      "loss": 0.0282,
      "step": 4080
    },
    {
      "epoch": 2.202477113624125,
      "grad_norm": 0.4953213930130005,
      "learning_rate": 1.559504577275175e-05,
      "loss": 0.0688,
      "step": 4090
    },
    {
      "epoch": 2.2078621432417878,
      "grad_norm": 3.142235517501831,
      "learning_rate": 1.5584275713516425e-05,
      "loss": 0.0365,
      "step": 4100
    },
    {
      "epoch": 2.2132471728594507,
      "grad_norm": 6.0869364738464355,
      "learning_rate": 1.55735056542811e-05,
      "loss": 0.0497,
      "step": 4110
    },
    {
      "epoch": 2.2186322024771137,
      "grad_norm": 6.040035247802734,
      "learning_rate": 1.5562735595045773e-05,
      "loss": 0.0503,
      "step": 4120
    },
    {
      "epoch": 2.2240172320947766,
      "grad_norm": 7.460186958312988,
      "learning_rate": 1.555196553581045e-05,
      "loss": 0.0379,
      "step": 4130
    },
    {
      "epoch": 2.2294022617124396,
      "grad_norm": 9.127163887023926,
      "learning_rate": 1.554119547657512e-05,
      "loss": 0.04,
      "step": 4140
    },
    {
      "epoch": 2.234787291330102,
      "grad_norm": 4.351470470428467,
      "learning_rate": 1.5530425417339795e-05,
      "loss": 0.043,
      "step": 4150
    },
    {
      "epoch": 2.240172320947765,
      "grad_norm": 2.191946268081665,
      "learning_rate": 1.551965535810447e-05,
      "loss": 0.0169,
      "step": 4160
    },
    {
      "epoch": 2.245557350565428,
      "grad_norm": 1.2029993534088135,
      "learning_rate": 1.5508885298869144e-05,
      "loss": 0.0363,
      "step": 4170
    },
    {
      "epoch": 2.250942380183091,
      "grad_norm": 5.711705684661865,
      "learning_rate": 1.549811523963382e-05,
      "loss": 0.0799,
      "step": 4180
    },
    {
      "epoch": 2.256327409800754,
      "grad_norm": 1.3558952808380127,
      "learning_rate": 1.5487345180398495e-05,
      "loss": 0.078,
      "step": 4190
    },
    {
      "epoch": 2.261712439418417,
      "grad_norm": 0.055728282779455185,
      "learning_rate": 1.547657512116317e-05,
      "loss": 0.0348,
      "step": 4200
    },
    {
      "epoch": 2.26709746903608,
      "grad_norm": 2.8781650066375732,
      "learning_rate": 1.546580506192784e-05,
      "loss": 0.0609,
      "step": 4210
    },
    {
      "epoch": 2.2724824986537424,
      "grad_norm": 3.3853533267974854,
      "learning_rate": 1.5455035002692517e-05,
      "loss": 0.0788,
      "step": 4220
    },
    {
      "epoch": 2.2778675282714054,
      "grad_norm": 0.5430214405059814,
      "learning_rate": 1.544426494345719e-05,
      "loss": 0.0099,
      "step": 4230
    },
    {
      "epoch": 2.2832525578890683,
      "grad_norm": 4.73587703704834,
      "learning_rate": 1.5433494884221865e-05,
      "loss": 0.0458,
      "step": 4240
    },
    {
      "epoch": 2.2886375875067313,
      "grad_norm": 0.1534416377544403,
      "learning_rate": 1.542272482498654e-05,
      "loss": 0.07,
      "step": 4250
    },
    {
      "epoch": 2.2940226171243943,
      "grad_norm": 3.7185192108154297,
      "learning_rate": 1.5411954765751213e-05,
      "loss": 0.0434,
      "step": 4260
    },
    {
      "epoch": 2.299407646742057,
      "grad_norm": 2.2311367988586426,
      "learning_rate": 1.5401184706515887e-05,
      "loss": 0.0082,
      "step": 4270
    },
    {
      "epoch": 2.30479267635972,
      "grad_norm": 2.7627737522125244,
      "learning_rate": 1.539041464728056e-05,
      "loss": 0.0397,
      "step": 4280
    },
    {
      "epoch": 2.3101777059773827,
      "grad_norm": 2.7608954906463623,
      "learning_rate": 1.5379644588045235e-05,
      "loss": 0.04,
      "step": 4290
    },
    {
      "epoch": 2.3155627355950457,
      "grad_norm": 0.6936342716217041,
      "learning_rate": 1.536887452880991e-05,
      "loss": 0.0388,
      "step": 4300
    },
    {
      "epoch": 2.3209477652127086,
      "grad_norm": 4.746708393096924,
      "learning_rate": 1.5358104469574584e-05,
      "loss": 0.0385,
      "step": 4310
    },
    {
      "epoch": 2.3263327948303716,
      "grad_norm": 3.910458564758301,
      "learning_rate": 1.5347334410339258e-05,
      "loss": 0.0467,
      "step": 4320
    },
    {
      "epoch": 2.3317178244480345,
      "grad_norm": 17.430042266845703,
      "learning_rate": 1.533656435110393e-05,
      "loss": 0.0424,
      "step": 4330
    },
    {
      "epoch": 2.3371028540656975,
      "grad_norm": 0.15954279899597168,
      "learning_rate": 1.532579429186861e-05,
      "loss": 0.0614,
      "step": 4340
    },
    {
      "epoch": 2.3424878836833605,
      "grad_norm": 4.575408458709717,
      "learning_rate": 1.531502423263328e-05,
      "loss": 0.0643,
      "step": 4350
    },
    {
      "epoch": 2.347872913301023,
      "grad_norm": 0.5225857496261597,
      "learning_rate": 1.5304254173397954e-05,
      "loss": 0.0585,
      "step": 4360
    },
    {
      "epoch": 2.353257942918686,
      "grad_norm": 6.129053592681885,
      "learning_rate": 1.5293484114162628e-05,
      "loss": 0.0743,
      "step": 4370
    },
    {
      "epoch": 2.358642972536349,
      "grad_norm": 0.717271625995636,
      "learning_rate": 1.5282714054927302e-05,
      "loss": 0.0834,
      "step": 4380
    },
    {
      "epoch": 2.364028002154012,
      "grad_norm": 0.7067549824714661,
      "learning_rate": 1.527194399569198e-05,
      "loss": 0.0511,
      "step": 4390
    },
    {
      "epoch": 2.369413031771675,
      "grad_norm": 1.992620587348938,
      "learning_rate": 1.5261173936456653e-05,
      "loss": 0.0772,
      "step": 4400
    },
    {
      "epoch": 2.374798061389338,
      "grad_norm": 0.6527653336524963,
      "learning_rate": 1.5250403877221327e-05,
      "loss": 0.043,
      "step": 4410
    },
    {
      "epoch": 2.3801830910070008,
      "grad_norm": 0.017079126089811325,
      "learning_rate": 1.5239633817986e-05,
      "loss": 0.0289,
      "step": 4420
    },
    {
      "epoch": 2.3855681206246633,
      "grad_norm": 0.7458987832069397,
      "learning_rate": 1.5228863758750674e-05,
      "loss": 0.0543,
      "step": 4430
    },
    {
      "epoch": 2.3909531502423262,
      "grad_norm": 0.6358818411827087,
      "learning_rate": 1.5218093699515348e-05,
      "loss": 0.0557,
      "step": 4440
    },
    {
      "epoch": 2.396338179859989,
      "grad_norm": 6.539273738861084,
      "learning_rate": 1.5207323640280023e-05,
      "loss": 0.0313,
      "step": 4450
    },
    {
      "epoch": 2.401723209477652,
      "grad_norm": 1.7600466012954712,
      "learning_rate": 1.5196553581044697e-05,
      "loss": 0.0276,
      "step": 4460
    },
    {
      "epoch": 2.407108239095315,
      "grad_norm": 0.006387552712112665,
      "learning_rate": 1.5185783521809372e-05,
      "loss": 0.0352,
      "step": 4470
    },
    {
      "epoch": 2.412493268712978,
      "grad_norm": 0.019848421216011047,
      "learning_rate": 1.5175013462574046e-05,
      "loss": 0.1222,
      "step": 4480
    },
    {
      "epoch": 2.417878298330641,
      "grad_norm": 0.38746994733810425,
      "learning_rate": 1.5164243403338718e-05,
      "loss": 0.0332,
      "step": 4490
    },
    {
      "epoch": 2.4232633279483036,
      "grad_norm": 2.197955369949341,
      "learning_rate": 1.5153473344103394e-05,
      "loss": 0.0441,
      "step": 4500
    },
    {
      "epoch": 2.4286483575659665,
      "grad_norm": 0.03268139436841011,
      "learning_rate": 1.5142703284868068e-05,
      "loss": 0.0249,
      "step": 4510
    },
    {
      "epoch": 2.4340333871836295,
      "grad_norm": 0.011329572647809982,
      "learning_rate": 1.5131933225632742e-05,
      "loss": 0.0263,
      "step": 4520
    },
    {
      "epoch": 2.4394184168012925,
      "grad_norm": 5.191584587097168,
      "learning_rate": 1.5121163166397417e-05,
      "loss": 0.0619,
      "step": 4530
    },
    {
      "epoch": 2.4448034464189554,
      "grad_norm": 0.17178989946842194,
      "learning_rate": 1.5110393107162091e-05,
      "loss": 0.0371,
      "step": 4540
    },
    {
      "epoch": 2.4501884760366184,
      "grad_norm": 5.047701358795166,
      "learning_rate": 1.5099623047926766e-05,
      "loss": 0.0301,
      "step": 4550
    },
    {
      "epoch": 2.4555735056542813,
      "grad_norm": 6.461675643920898,
      "learning_rate": 1.5088852988691438e-05,
      "loss": 0.0425,
      "step": 4560
    },
    {
      "epoch": 2.460958535271944,
      "grad_norm": 0.12529247999191284,
      "learning_rate": 1.5078082929456112e-05,
      "loss": 0.0303,
      "step": 4570
    },
    {
      "epoch": 2.466343564889607,
      "grad_norm": 1.151188611984253,
      "learning_rate": 1.5067312870220788e-05,
      "loss": 0.0679,
      "step": 4580
    },
    {
      "epoch": 2.47172859450727,
      "grad_norm": 0.3298807740211487,
      "learning_rate": 1.5056542810985462e-05,
      "loss": 0.0345,
      "step": 4590
    },
    {
      "epoch": 2.4771136241249327,
      "grad_norm": 1.4405797719955444,
      "learning_rate": 1.5045772751750136e-05,
      "loss": 0.0562,
      "step": 4600
    },
    {
      "epoch": 2.4824986537425957,
      "grad_norm": 6.818247318267822,
      "learning_rate": 1.5035002692514811e-05,
      "loss": 0.0554,
      "step": 4610
    },
    {
      "epoch": 2.4878836833602587,
      "grad_norm": 1.2486517429351807,
      "learning_rate": 1.5024232633279485e-05,
      "loss": 0.0439,
      "step": 4620
    },
    {
      "epoch": 2.493268712977921,
      "grad_norm": 8.566194534301758,
      "learning_rate": 1.5013462574044158e-05,
      "loss": 0.043,
      "step": 4630
    },
    {
      "epoch": 2.498653742595584,
      "grad_norm": 0.42735013365745544,
      "learning_rate": 1.5002692514808832e-05,
      "loss": 0.0353,
      "step": 4640
    },
    {
      "epoch": 2.504038772213247,
      "grad_norm": 0.03563723713159561,
      "learning_rate": 1.4991922455573506e-05,
      "loss": 0.0273,
      "step": 4650
    },
    {
      "epoch": 2.50942380183091,
      "grad_norm": 3.279825210571289,
      "learning_rate": 1.4981152396338182e-05,
      "loss": 0.0372,
      "step": 4660
    },
    {
      "epoch": 2.514808831448573,
      "grad_norm": 0.9153228402137756,
      "learning_rate": 1.4970382337102856e-05,
      "loss": 0.0418,
      "step": 4670
    },
    {
      "epoch": 2.520193861066236,
      "grad_norm": 0.29205814003944397,
      "learning_rate": 1.495961227786753e-05,
      "loss": 0.0274,
      "step": 4680
    },
    {
      "epoch": 2.5255788906838985,
      "grad_norm": 0.00939647015184164,
      "learning_rate": 1.4948842218632205e-05,
      "loss": 0.0896,
      "step": 4690
    },
    {
      "epoch": 2.530963920301562,
      "grad_norm": 0.9611678123474121,
      "learning_rate": 1.4938072159396876e-05,
      "loss": 0.0598,
      "step": 4700
    },
    {
      "epoch": 2.5363489499192244,
      "grad_norm": 0.4797405004501343,
      "learning_rate": 1.4927302100161552e-05,
      "loss": 0.0764,
      "step": 4710
    },
    {
      "epoch": 2.5417339795368874,
      "grad_norm": 6.720780849456787,
      "learning_rate": 1.4916532040926226e-05,
      "loss": 0.0896,
      "step": 4720
    },
    {
      "epoch": 2.5471190091545504,
      "grad_norm": 9.181135177612305,
      "learning_rate": 1.49057619816909e-05,
      "loss": 0.0238,
      "step": 4730
    },
    {
      "epoch": 2.5525040387722133,
      "grad_norm": 5.18995475769043,
      "learning_rate": 1.4894991922455576e-05,
      "loss": 0.0547,
      "step": 4740
    },
    {
      "epoch": 2.5578890683898763,
      "grad_norm": 2.2799222469329834,
      "learning_rate": 1.488422186322025e-05,
      "loss": 0.0186,
      "step": 4750
    },
    {
      "epoch": 2.563274098007539,
      "grad_norm": 2.1274425983428955,
      "learning_rate": 1.4873451803984924e-05,
      "loss": 0.0415,
      "step": 4760
    },
    {
      "epoch": 2.568659127625202,
      "grad_norm": 0.5973832011222839,
      "learning_rate": 1.4862681744749596e-05,
      "loss": 0.051,
      "step": 4770
    },
    {
      "epoch": 2.5740441572428647,
      "grad_norm": 0.09860163182020187,
      "learning_rate": 1.485191168551427e-05,
      "loss": 0.063,
      "step": 4780
    },
    {
      "epoch": 2.5794291868605277,
      "grad_norm": 7.470987796783447,
      "learning_rate": 1.4841141626278946e-05,
      "loss": 0.1084,
      "step": 4790
    },
    {
      "epoch": 2.5848142164781907,
      "grad_norm": 1.1193732023239136,
      "learning_rate": 1.483037156704362e-05,
      "loss": 0.0728,
      "step": 4800
    },
    {
      "epoch": 2.5901992460958536,
      "grad_norm": 8.416475296020508,
      "learning_rate": 1.4819601507808294e-05,
      "loss": 0.0655,
      "step": 4810
    },
    {
      "epoch": 2.5955842757135166,
      "grad_norm": 1.3609886169433594,
      "learning_rate": 1.480883144857297e-05,
      "loss": 0.0406,
      "step": 4820
    },
    {
      "epoch": 2.600969305331179,
      "grad_norm": 11.015863418579102,
      "learning_rate": 1.4798061389337644e-05,
      "loss": 0.0528,
      "step": 4830
    },
    {
      "epoch": 2.606354334948842,
      "grad_norm": 3.468998908996582,
      "learning_rate": 1.4787291330102316e-05,
      "loss": 0.0202,
      "step": 4840
    },
    {
      "epoch": 2.611739364566505,
      "grad_norm": 4.491041660308838,
      "learning_rate": 1.477652127086699e-05,
      "loss": 0.0398,
      "step": 4850
    },
    {
      "epoch": 2.617124394184168,
      "grad_norm": 0.018674634397029877,
      "learning_rate": 1.4765751211631664e-05,
      "loss": 0.0826,
      "step": 4860
    },
    {
      "epoch": 2.622509423801831,
      "grad_norm": 0.10160411149263382,
      "learning_rate": 1.475498115239634e-05,
      "loss": 0.0127,
      "step": 4870
    },
    {
      "epoch": 2.627894453419494,
      "grad_norm": 3.333423137664795,
      "learning_rate": 1.4744211093161014e-05,
      "loss": 0.0375,
      "step": 4880
    },
    {
      "epoch": 2.633279483037157,
      "grad_norm": 8.462836265563965,
      "learning_rate": 1.4733441033925688e-05,
      "loss": 0.0629,
      "step": 4890
    },
    {
      "epoch": 2.6386645126548194,
      "grad_norm": 0.6275829672813416,
      "learning_rate": 1.4722670974690364e-05,
      "loss": 0.0439,
      "step": 4900
    },
    {
      "epoch": 2.6440495422724823,
      "grad_norm": 5.510244369506836,
      "learning_rate": 1.4711900915455036e-05,
      "loss": 0.0697,
      "step": 4910
    },
    {
      "epoch": 2.6494345718901453,
      "grad_norm": 3.565054416656494,
      "learning_rate": 1.470113085621971e-05,
      "loss": 0.0109,
      "step": 4920
    },
    {
      "epoch": 2.6548196015078083,
      "grad_norm": 0.27229365706443787,
      "learning_rate": 1.4690360796984384e-05,
      "loss": 0.0911,
      "step": 4930
    },
    {
      "epoch": 2.6602046311254712,
      "grad_norm": 0.009135965257883072,
      "learning_rate": 1.4679590737749058e-05,
      "loss": 0.0179,
      "step": 4940
    },
    {
      "epoch": 2.665589660743134,
      "grad_norm": 7.454827308654785,
      "learning_rate": 1.4668820678513734e-05,
      "loss": 0.0628,
      "step": 4950
    },
    {
      "epoch": 2.670974690360797,
      "grad_norm": 7.0833539962768555,
      "learning_rate": 1.4658050619278408e-05,
      "loss": 0.0443,
      "step": 4960
    },
    {
      "epoch": 2.6763597199784597,
      "grad_norm": 2.622419595718384,
      "learning_rate": 1.4647280560043082e-05,
      "loss": 0.0495,
      "step": 4970
    },
    {
      "epoch": 2.6817447495961226,
      "grad_norm": 0.635196328163147,
      "learning_rate": 1.4636510500807754e-05,
      "loss": 0.0641,
      "step": 4980
    },
    {
      "epoch": 2.6871297792137856,
      "grad_norm": 0.06138519570231438,
      "learning_rate": 1.4625740441572428e-05,
      "loss": 0.0206,
      "step": 4990
    },
    {
      "epoch": 2.6925148088314486,
      "grad_norm": 0.31059184670448303,
      "learning_rate": 1.4614970382337104e-05,
      "loss": 0.0267,
      "step": 5000
    },
    {
      "epoch": 2.6978998384491115,
      "grad_norm": 3.446195125579834,
      "learning_rate": 1.4604200323101778e-05,
      "loss": 0.0514,
      "step": 5010
    },
    {
      "epoch": 2.7032848680667745,
      "grad_norm": 4.04874324798584,
      "learning_rate": 1.4593430263866452e-05,
      "loss": 0.0469,
      "step": 5020
    },
    {
      "epoch": 2.7086698976844374,
      "grad_norm": 4.5238423347473145,
      "learning_rate": 1.4582660204631128e-05,
      "loss": 0.0569,
      "step": 5030
    },
    {
      "epoch": 2.7140549273021,
      "grad_norm": 0.04939069226384163,
      "learning_rate": 1.4571890145395802e-05,
      "loss": 0.0557,
      "step": 5040
    },
    {
      "epoch": 2.719439956919763,
      "grad_norm": 5.736494064331055,
      "learning_rate": 1.4561120086160474e-05,
      "loss": 0.0605,
      "step": 5050
    },
    {
      "epoch": 2.724824986537426,
      "grad_norm": 5.443145275115967,
      "learning_rate": 1.4550350026925148e-05,
      "loss": 0.0306,
      "step": 5060
    },
    {
      "epoch": 2.730210016155089,
      "grad_norm": 0.2813229262828827,
      "learning_rate": 1.4539579967689822e-05,
      "loss": 0.028,
      "step": 5070
    },
    {
      "epoch": 2.735595045772752,
      "grad_norm": 0.10222785919904709,
      "learning_rate": 1.4528809908454498e-05,
      "loss": 0.0176,
      "step": 5080
    },
    {
      "epoch": 2.7409800753904148,
      "grad_norm": 0.7284383773803711,
      "learning_rate": 1.4518039849219172e-05,
      "loss": 0.033,
      "step": 5090
    },
    {
      "epoch": 2.7463651050080777,
      "grad_norm": 2.119593381881714,
      "learning_rate": 1.4507269789983846e-05,
      "loss": 0.0345,
      "step": 5100
    },
    {
      "epoch": 2.7517501346257403,
      "grad_norm": 0.0577213354408741,
      "learning_rate": 1.4496499730748522e-05,
      "loss": 0.0311,
      "step": 5110
    },
    {
      "epoch": 2.757135164243403,
      "grad_norm": 6.033320426940918,
      "learning_rate": 1.4485729671513194e-05,
      "loss": 0.0617,
      "step": 5120
    },
    {
      "epoch": 2.762520193861066,
      "grad_norm": 3.781165361404419,
      "learning_rate": 1.4474959612277868e-05,
      "loss": 0.0593,
      "step": 5130
    },
    {
      "epoch": 2.767905223478729,
      "grad_norm": 0.011091478168964386,
      "learning_rate": 1.4464189553042542e-05,
      "loss": 0.0596,
      "step": 5140
    },
    {
      "epoch": 2.773290253096392,
      "grad_norm": 0.4195709824562073,
      "learning_rate": 1.4453419493807216e-05,
      "loss": 0.0079,
      "step": 5150
    },
    {
      "epoch": 2.778675282714055,
      "grad_norm": 0.7543190121650696,
      "learning_rate": 1.4442649434571892e-05,
      "loss": 0.0254,
      "step": 5160
    },
    {
      "epoch": 2.784060312331718,
      "grad_norm": 1.4106394052505493,
      "learning_rate": 1.4431879375336566e-05,
      "loss": 0.0421,
      "step": 5170
    },
    {
      "epoch": 2.7894453419493805,
      "grad_norm": 2.8156144618988037,
      "learning_rate": 1.442110931610124e-05,
      "loss": 0.0784,
      "step": 5180
    },
    {
      "epoch": 2.7948303715670435,
      "grad_norm": 0.31983864307403564,
      "learning_rate": 1.4410339256865912e-05,
      "loss": 0.055,
      "step": 5190
    },
    {
      "epoch": 2.8002154011847065,
      "grad_norm": 0.07039771974086761,
      "learning_rate": 1.4399569197630587e-05,
      "loss": 0.0541,
      "step": 5200
    },
    {
      "epoch": 2.8056004308023694,
      "grad_norm": 4.913905143737793,
      "learning_rate": 1.4388799138395262e-05,
      "loss": 0.0325,
      "step": 5210
    },
    {
      "epoch": 2.8109854604200324,
      "grad_norm": 8.449939727783203,
      "learning_rate": 1.4378029079159936e-05,
      "loss": 0.0403,
      "step": 5220
    },
    {
      "epoch": 2.8163704900376954,
      "grad_norm": 1.3367440700531006,
      "learning_rate": 1.436725901992461e-05,
      "loss": 0.0136,
      "step": 5230
    },
    {
      "epoch": 2.8217555196553583,
      "grad_norm": 0.24994513392448425,
      "learning_rate": 1.4356488960689286e-05,
      "loss": 0.0189,
      "step": 5240
    },
    {
      "epoch": 2.827140549273021,
      "grad_norm": 26.66306495666504,
      "learning_rate": 1.434571890145396e-05,
      "loss": 0.0784,
      "step": 5250
    },
    {
      "epoch": 2.832525578890684,
      "grad_norm": 0.09858623892068863,
      "learning_rate": 1.4334948842218634e-05,
      "loss": 0.0214,
      "step": 5260
    },
    {
      "epoch": 2.8379106085083468,
      "grad_norm": 3.1594185829162598,
      "learning_rate": 1.4324178782983306e-05,
      "loss": 0.0203,
      "step": 5270
    },
    {
      "epoch": 2.8432956381260097,
      "grad_norm": 0.008695687167346478,
      "learning_rate": 1.431340872374798e-05,
      "loss": 0.0138,
      "step": 5280
    },
    {
      "epoch": 2.8486806677436727,
      "grad_norm": 2.0448315143585205,
      "learning_rate": 1.4302638664512656e-05,
      "loss": 0.0371,
      "step": 5290
    },
    {
      "epoch": 2.8540656973613356,
      "grad_norm": 0.514864981174469,
      "learning_rate": 1.429186860527733e-05,
      "loss": 0.0461,
      "step": 5300
    },
    {
      "epoch": 2.8594507269789986,
      "grad_norm": 3.1701114177703857,
      "learning_rate": 1.4281098546042004e-05,
      "loss": 0.0733,
      "step": 5310
    },
    {
      "epoch": 2.864835756596661,
      "grad_norm": 0.01887907274067402,
      "learning_rate": 1.427032848680668e-05,
      "loss": 0.0599,
      "step": 5320
    },
    {
      "epoch": 2.870220786214324,
      "grad_norm": 0.04380236566066742,
      "learning_rate": 1.4259558427571354e-05,
      "loss": 0.0465,
      "step": 5330
    },
    {
      "epoch": 2.875605815831987,
      "grad_norm": 0.4548782408237457,
      "learning_rate": 1.4248788368336026e-05,
      "loss": 0.0265,
      "step": 5340
    },
    {
      "epoch": 2.88099084544965,
      "grad_norm": 7.726229190826416,
      "learning_rate": 1.42380183091007e-05,
      "loss": 0.0946,
      "step": 5350
    },
    {
      "epoch": 2.886375875067313,
      "grad_norm": 0.04434990510344505,
      "learning_rate": 1.4227248249865375e-05,
      "loss": 0.0057,
      "step": 5360
    },
    {
      "epoch": 2.891760904684976,
      "grad_norm": 0.07636531442403793,
      "learning_rate": 1.421647819063005e-05,
      "loss": 0.0357,
      "step": 5370
    },
    {
      "epoch": 2.897145934302639,
      "grad_norm": 4.928172588348389,
      "learning_rate": 1.4205708131394724e-05,
      "loss": 0.0587,
      "step": 5380
    },
    {
      "epoch": 2.9025309639203014,
      "grad_norm": 0.26290738582611084,
      "learning_rate": 1.4194938072159398e-05,
      "loss": 0.0472,
      "step": 5390
    },
    {
      "epoch": 2.9079159935379644,
      "grad_norm": 4.2862548828125,
      "learning_rate": 1.4184168012924074e-05,
      "loss": 0.0799,
      "step": 5400
    },
    {
      "epoch": 2.9133010231556273,
      "grad_norm": 3.429434061050415,
      "learning_rate": 1.4173397953688746e-05,
      "loss": 0.0567,
      "step": 5410
    },
    {
      "epoch": 2.9186860527732903,
      "grad_norm": 0.8209537267684937,
      "learning_rate": 1.416262789445342e-05,
      "loss": 0.0579,
      "step": 5420
    },
    {
      "epoch": 2.9240710823909533,
      "grad_norm": 3.8845102787017822,
      "learning_rate": 1.4151857835218094e-05,
      "loss": 0.0475,
      "step": 5430
    },
    {
      "epoch": 2.9294561120086158,
      "grad_norm": 2.96151065826416,
      "learning_rate": 1.4141087775982769e-05,
      "loss": 0.0295,
      "step": 5440
    },
    {
      "epoch": 2.934841141626279,
      "grad_norm": 1.1346514225006104,
      "learning_rate": 1.4130317716747444e-05,
      "loss": 0.0333,
      "step": 5450
    },
    {
      "epoch": 2.9402261712439417,
      "grad_norm": 11.118425369262695,
      "learning_rate": 1.4119547657512118e-05,
      "loss": 0.054,
      "step": 5460
    },
    {
      "epoch": 2.9456112008616047,
      "grad_norm": 0.010661273263394833,
      "learning_rate": 1.4108777598276792e-05,
      "loss": 0.037,
      "step": 5470
    },
    {
      "epoch": 2.9509962304792676,
      "grad_norm": 0.9481421709060669,
      "learning_rate": 1.4098007539041465e-05,
      "loss": 0.0456,
      "step": 5480
    },
    {
      "epoch": 2.9563812600969306,
      "grad_norm": 0.029611587524414062,
      "learning_rate": 1.4087237479806139e-05,
      "loss": 0.0326,
      "step": 5490
    },
    {
      "epoch": 2.9617662897145935,
      "grad_norm": 0.7064836025238037,
      "learning_rate": 1.4076467420570814e-05,
      "loss": 0.0454,
      "step": 5500
    },
    {
      "epoch": 2.967151319332256,
      "grad_norm": 0.014086590148508549,
      "learning_rate": 1.4065697361335488e-05,
      "loss": 0.0514,
      "step": 5510
    },
    {
      "epoch": 2.9725363489499195,
      "grad_norm": 5.50809907913208,
      "learning_rate": 1.4054927302100163e-05,
      "loss": 0.0242,
      "step": 5520
    },
    {
      "epoch": 2.977921378567582,
      "grad_norm": 0.022021295502781868,
      "learning_rate": 1.4044157242864838e-05,
      "loss": 0.0053,
      "step": 5530
    },
    {
      "epoch": 2.983306408185245,
      "grad_norm": 0.08999413251876831,
      "learning_rate": 1.4033387183629512e-05,
      "loss": 0.0658,
      "step": 5540
    },
    {
      "epoch": 2.988691437802908,
      "grad_norm": 0.012881161645054817,
      "learning_rate": 1.4022617124394185e-05,
      "loss": 0.029,
      "step": 5550
    },
    {
      "epoch": 2.994076467420571,
      "grad_norm": 0.05053297057747841,
      "learning_rate": 1.4011847065158859e-05,
      "loss": 0.0369,
      "step": 5560
    },
    {
      "epoch": 2.999461497038234,
      "grad_norm": 4.580978870391846,
      "learning_rate": 1.4001077005923533e-05,
      "loss": 0.0647,
      "step": 5570
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9852386934673367,
      "eval_f1": 0.9460080413555427,
      "eval_loss": 0.05642335116863251,
      "eval_precision": 0.9454649827784156,
      "eval_recall": 0.946551724137931,
      "eval_runtime": 296.7503,
      "eval_samples_per_second": 42.932,
      "eval_steps_per_second": 1.345,
      "step": 5571
    },
    {
      "epoch": 3.004846526655897,
      "grad_norm": 0.021056728437542915,
      "learning_rate": 1.3990306946688208e-05,
      "loss": 0.034,
      "step": 5580
    },
    {
      "epoch": 3.0102315562735593,
      "grad_norm": 5.2033915519714355,
      "learning_rate": 1.3979536887452882e-05,
      "loss": 0.0201,
      "step": 5590
    },
    {
      "epoch": 3.0156165858912223,
      "grad_norm": 0.07079347223043442,
      "learning_rate": 1.3968766828217557e-05,
      "loss": 0.0101,
      "step": 5600
    },
    {
      "epoch": 3.0210016155088852,
      "grad_norm": 0.6395461559295654,
      "learning_rate": 1.3957996768982232e-05,
      "loss": 0.0271,
      "step": 5610
    },
    {
      "epoch": 3.026386645126548,
      "grad_norm": 3.1227920055389404,
      "learning_rate": 1.3947226709746905e-05,
      "loss": 0.0419,
      "step": 5620
    },
    {
      "epoch": 3.031771674744211,
      "grad_norm": 0.0731421634554863,
      "learning_rate": 1.3936456650511579e-05,
      "loss": 0.0155,
      "step": 5630
    },
    {
      "epoch": 3.037156704361874,
      "grad_norm": 0.005417810287326574,
      "learning_rate": 1.3925686591276253e-05,
      "loss": 0.0044,
      "step": 5640
    },
    {
      "epoch": 3.042541733979537,
      "grad_norm": 0.002896655350923538,
      "learning_rate": 1.3914916532040927e-05,
      "loss": 0.0214,
      "step": 5650
    },
    {
      "epoch": 3.0479267635971996,
      "grad_norm": 0.007613347377628088,
      "learning_rate": 1.3904146472805602e-05,
      "loss": 0.0013,
      "step": 5660
    },
    {
      "epoch": 3.0533117932148626,
      "grad_norm": 0.02327032946050167,
      "learning_rate": 1.3893376413570277e-05,
      "loss": 0.0182,
      "step": 5670
    },
    {
      "epoch": 3.0586968228325255,
      "grad_norm": 2.7013063430786133,
      "learning_rate": 1.388260635433495e-05,
      "loss": 0.0313,
      "step": 5680
    },
    {
      "epoch": 3.0640818524501885,
      "grad_norm": 3.357567548751831,
      "learning_rate": 1.3871836295099623e-05,
      "loss": 0.0529,
      "step": 5690
    },
    {
      "epoch": 3.0694668820678515,
      "grad_norm": 6.365084648132324,
      "learning_rate": 1.3861066235864299e-05,
      "loss": 0.0739,
      "step": 5700
    },
    {
      "epoch": 3.0748519116855144,
      "grad_norm": 0.08105237782001495,
      "learning_rate": 1.3850296176628973e-05,
      "loss": 0.0119,
      "step": 5710
    },
    {
      "epoch": 3.0802369413031774,
      "grad_norm": 0.012431097216904163,
      "learning_rate": 1.3839526117393647e-05,
      "loss": 0.045,
      "step": 5720
    },
    {
      "epoch": 3.08562197092084,
      "grad_norm": 4.671777248382568,
      "learning_rate": 1.382875605815832e-05,
      "loss": 0.04,
      "step": 5730
    },
    {
      "epoch": 3.091007000538503,
      "grad_norm": 4.384901523590088,
      "learning_rate": 1.3817985998922996e-05,
      "loss": 0.0159,
      "step": 5740
    },
    {
      "epoch": 3.096392030156166,
      "grad_norm": 0.3174789845943451,
      "learning_rate": 1.380721593968767e-05,
      "loss": 0.0499,
      "step": 5750
    },
    {
      "epoch": 3.101777059773829,
      "grad_norm": 0.010694453492760658,
      "learning_rate": 1.3796445880452343e-05,
      "loss": 0.0211,
      "step": 5760
    },
    {
      "epoch": 3.1071620893914917,
      "grad_norm": 6.005335807800293,
      "learning_rate": 1.3785675821217017e-05,
      "loss": 0.0411,
      "step": 5770
    },
    {
      "epoch": 3.1125471190091547,
      "grad_norm": 0.012913772836327553,
      "learning_rate": 1.3774905761981691e-05,
      "loss": 0.0263,
      "step": 5780
    },
    {
      "epoch": 3.1179321486268172,
      "grad_norm": 3.406614065170288,
      "learning_rate": 1.3764135702746367e-05,
      "loss": 0.0174,
      "step": 5790
    },
    {
      "epoch": 3.12331717824448,
      "grad_norm": 0.1299508959054947,
      "learning_rate": 1.375336564351104e-05,
      "loss": 0.013,
      "step": 5800
    },
    {
      "epoch": 3.128702207862143,
      "grad_norm": 0.009272146038711071,
      "learning_rate": 1.3742595584275715e-05,
      "loss": 0.0146,
      "step": 5810
    },
    {
      "epoch": 3.134087237479806,
      "grad_norm": 0.17101114988327026,
      "learning_rate": 1.373182552504039e-05,
      "loss": 0.0232,
      "step": 5820
    },
    {
      "epoch": 3.139472267097469,
      "grad_norm": 0.49460461735725403,
      "learning_rate": 1.3721055465805063e-05,
      "loss": 0.0201,
      "step": 5830
    },
    {
      "epoch": 3.144857296715132,
      "grad_norm": 0.0159468837082386,
      "learning_rate": 1.3710285406569737e-05,
      "loss": 0.0295,
      "step": 5840
    },
    {
      "epoch": 3.150242326332795,
      "grad_norm": 0.8500669598579407,
      "learning_rate": 1.3699515347334411e-05,
      "loss": 0.0393,
      "step": 5850
    },
    {
      "epoch": 3.1556273559504575,
      "grad_norm": 0.8874173760414124,
      "learning_rate": 1.3688745288099085e-05,
      "loss": 0.0376,
      "step": 5860
    },
    {
      "epoch": 3.1610123855681205,
      "grad_norm": 0.0813760980963707,
      "learning_rate": 1.367797522886376e-05,
      "loss": 0.021,
      "step": 5870
    },
    {
      "epoch": 3.1663974151857834,
      "grad_norm": 4.625375270843506,
      "learning_rate": 1.3667205169628435e-05,
      "loss": 0.118,
      "step": 5880
    },
    {
      "epoch": 3.1717824448034464,
      "grad_norm": 5.25938606262207,
      "learning_rate": 1.3656435110393109e-05,
      "loss": 0.0288,
      "step": 5890
    },
    {
      "epoch": 3.1771674744211094,
      "grad_norm": 0.3319769501686096,
      "learning_rate": 1.3645665051157781e-05,
      "loss": 0.0221,
      "step": 5900
    },
    {
      "epoch": 3.1825525040387723,
      "grad_norm": 0.6954137086868286,
      "learning_rate": 1.3634894991922457e-05,
      "loss": 0.0149,
      "step": 5910
    },
    {
      "epoch": 3.1879375336564353,
      "grad_norm": 0.06692046672105789,
      "learning_rate": 1.3624124932687131e-05,
      "loss": 0.0326,
      "step": 5920
    },
    {
      "epoch": 3.193322563274098,
      "grad_norm": 1.3967701196670532,
      "learning_rate": 1.3613354873451805e-05,
      "loss": 0.0757,
      "step": 5930
    },
    {
      "epoch": 3.1987075928917608,
      "grad_norm": 1.330841064453125,
      "learning_rate": 1.3602584814216479e-05,
      "loss": 0.0378,
      "step": 5940
    },
    {
      "epoch": 3.2040926225094237,
      "grad_norm": 34.480072021484375,
      "learning_rate": 1.3591814754981155e-05,
      "loss": 0.0112,
      "step": 5950
    },
    {
      "epoch": 3.2094776521270867,
      "grad_norm": 0.027903232723474503,
      "learning_rate": 1.3581044695745829e-05,
      "loss": 0.0117,
      "step": 5960
    },
    {
      "epoch": 3.2148626817447497,
      "grad_norm": 5.821045875549316,
      "learning_rate": 1.3570274636510501e-05,
      "loss": 0.0499,
      "step": 5970
    },
    {
      "epoch": 3.2202477113624126,
      "grad_norm": 3.8291714191436768,
      "learning_rate": 1.3559504577275175e-05,
      "loss": 0.0431,
      "step": 5980
    },
    {
      "epoch": 3.2256327409800756,
      "grad_norm": 5.244484901428223,
      "learning_rate": 1.3548734518039849e-05,
      "loss": 0.0362,
      "step": 5990
    },
    {
      "epoch": 3.231017770597738,
      "grad_norm": 0.23179534077644348,
      "learning_rate": 1.3537964458804525e-05,
      "loss": 0.0796,
      "step": 6000
    },
    {
      "epoch": 3.236402800215401,
      "grad_norm": 0.0063720992766320705,
      "learning_rate": 1.3527194399569199e-05,
      "loss": 0.0367,
      "step": 6010
    },
    {
      "epoch": 3.241787829833064,
      "grad_norm": 0.2429007589817047,
      "learning_rate": 1.3516424340333873e-05,
      "loss": 0.0206,
      "step": 6020
    },
    {
      "epoch": 3.247172859450727,
      "grad_norm": 0.08959564566612244,
      "learning_rate": 1.3505654281098549e-05,
      "loss": 0.0445,
      "step": 6030
    },
    {
      "epoch": 3.25255788906839,
      "grad_norm": 3.0412566661834717,
      "learning_rate": 1.3494884221863221e-05,
      "loss": 0.0257,
      "step": 6040
    },
    {
      "epoch": 3.257942918686053,
      "grad_norm": 3.1379735469818115,
      "learning_rate": 1.3484114162627895e-05,
      "loss": 0.0245,
      "step": 6050
    },
    {
      "epoch": 3.263327948303716,
      "grad_norm": 0.6056444644927979,
      "learning_rate": 1.3473344103392569e-05,
      "loss": 0.0387,
      "step": 6060
    },
    {
      "epoch": 3.2687129779213784,
      "grad_norm": 2.855884075164795,
      "learning_rate": 1.3462574044157243e-05,
      "loss": 0.0425,
      "step": 6070
    },
    {
      "epoch": 3.2740980075390413,
      "grad_norm": 0.006264042109251022,
      "learning_rate": 1.3451803984921919e-05,
      "loss": 0.007,
      "step": 6080
    },
    {
      "epoch": 3.2794830371567043,
      "grad_norm": 0.03491999953985214,
      "learning_rate": 1.3441033925686593e-05,
      "loss": 0.0302,
      "step": 6090
    },
    {
      "epoch": 3.2848680667743673,
      "grad_norm": 0.012452841736376286,
      "learning_rate": 1.3430263866451267e-05,
      "loss": 0.0042,
      "step": 6100
    },
    {
      "epoch": 3.2902530963920302,
      "grad_norm": 0.005861787125468254,
      "learning_rate": 1.341949380721594e-05,
      "loss": 0.0154,
      "step": 6110
    },
    {
      "epoch": 3.295638126009693,
      "grad_norm": 1.2154957056045532,
      "learning_rate": 1.3408723747980615e-05,
      "loss": 0.0393,
      "step": 6120
    },
    {
      "epoch": 3.301023155627356,
      "grad_norm": 0.09421594440937042,
      "learning_rate": 1.3397953688745289e-05,
      "loss": 0.0241,
      "step": 6130
    },
    {
      "epoch": 3.3064081852450187,
      "grad_norm": 0.0022104824893176556,
      "learning_rate": 1.3387183629509963e-05,
      "loss": 0.0497,
      "step": 6140
    },
    {
      "epoch": 3.3117932148626816,
      "grad_norm": 1.480000615119934,
      "learning_rate": 1.3376413570274637e-05,
      "loss": 0.0331,
      "step": 6150
    },
    {
      "epoch": 3.3171782444803446,
      "grad_norm": 6.336077690124512,
      "learning_rate": 1.3365643511039313e-05,
      "loss": 0.0298,
      "step": 6160
    },
    {
      "epoch": 3.3225632740980076,
      "grad_norm": 0.11689729988574982,
      "learning_rate": 1.3354873451803987e-05,
      "loss": 0.0355,
      "step": 6170
    },
    {
      "epoch": 3.3279483037156705,
      "grad_norm": 0.9982715249061584,
      "learning_rate": 1.334410339256866e-05,
      "loss": 0.0371,
      "step": 6180
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 2.0908658504486084,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0312,
      "step": 6190
    },
    {
      "epoch": 3.3387183629509964,
      "grad_norm": 0.08566410094499588,
      "learning_rate": 1.3322563274098009e-05,
      "loss": 0.0068,
      "step": 6200
    },
    {
      "epoch": 3.344103392568659,
      "grad_norm": 0.016782820224761963,
      "learning_rate": 1.3311793214862683e-05,
      "loss": 0.0068,
      "step": 6210
    },
    {
      "epoch": 3.349488422186322,
      "grad_norm": 0.03273342177271843,
      "learning_rate": 1.3301023155627357e-05,
      "loss": 0.0631,
      "step": 6220
    },
    {
      "epoch": 3.354873451803985,
      "grad_norm": 3.917894124984741,
      "learning_rate": 1.3290253096392031e-05,
      "loss": 0.0176,
      "step": 6230
    },
    {
      "epoch": 3.360258481421648,
      "grad_norm": 0.7471597194671631,
      "learning_rate": 1.3279483037156707e-05,
      "loss": 0.0373,
      "step": 6240
    },
    {
      "epoch": 3.365643511039311,
      "grad_norm": 1.4460018873214722,
      "learning_rate": 1.326871297792138e-05,
      "loss": 0.0149,
      "step": 6250
    },
    {
      "epoch": 3.3710285406569738,
      "grad_norm": 3.836468458175659,
      "learning_rate": 1.3257942918686053e-05,
      "loss": 0.0899,
      "step": 6260
    },
    {
      "epoch": 3.3764135702746367,
      "grad_norm": 0.0676703229546547,
      "learning_rate": 1.3247172859450727e-05,
      "loss": 0.027,
      "step": 6270
    },
    {
      "epoch": 3.3817985998922993,
      "grad_norm": 0.027904510498046875,
      "learning_rate": 1.3236402800215401e-05,
      "loss": 0.0347,
      "step": 6280
    },
    {
      "epoch": 3.387183629509962,
      "grad_norm": 1.2360793352127075,
      "learning_rate": 1.3225632740980077e-05,
      "loss": 0.0625,
      "step": 6290
    },
    {
      "epoch": 3.392568659127625,
      "grad_norm": 2.1614887714385986,
      "learning_rate": 1.3214862681744751e-05,
      "loss": 0.0426,
      "step": 6300
    },
    {
      "epoch": 3.397953688745288,
      "grad_norm": 0.028733301907777786,
      "learning_rate": 1.3204092622509425e-05,
      "loss": 0.0316,
      "step": 6310
    },
    {
      "epoch": 3.403338718362951,
      "grad_norm": 0.424995094537735,
      "learning_rate": 1.3193322563274097e-05,
      "loss": 0.0339,
      "step": 6320
    },
    {
      "epoch": 3.408723747980614,
      "grad_norm": 2.6918981075286865,
      "learning_rate": 1.3182552504038773e-05,
      "loss": 0.0178,
      "step": 6330
    },
    {
      "epoch": 3.414108777598277,
      "grad_norm": 10.473738670349121,
      "learning_rate": 1.3171782444803447e-05,
      "loss": 0.0507,
      "step": 6340
    },
    {
      "epoch": 3.4194938072159395,
      "grad_norm": 0.006929729599505663,
      "learning_rate": 1.3161012385568121e-05,
      "loss": 0.0151,
      "step": 6350
    },
    {
      "epoch": 3.4248788368336025,
      "grad_norm": 0.09105909615755081,
      "learning_rate": 1.3150242326332795e-05,
      "loss": 0.0187,
      "step": 6360
    },
    {
      "epoch": 3.4302638664512655,
      "grad_norm": 2.5970993041992188,
      "learning_rate": 1.3139472267097471e-05,
      "loss": 0.0804,
      "step": 6370
    },
    {
      "epoch": 3.4356488960689284,
      "grad_norm": 1.0256614685058594,
      "learning_rate": 1.3128702207862145e-05,
      "loss": 0.0153,
      "step": 6380
    },
    {
      "epoch": 3.4410339256865914,
      "grad_norm": 1.570630431175232,
      "learning_rate": 1.3117932148626819e-05,
      "loss": 0.029,
      "step": 6390
    },
    {
      "epoch": 3.4464189553042544,
      "grad_norm": 4.28395938873291,
      "learning_rate": 1.3107162089391491e-05,
      "loss": 0.0334,
      "step": 6400
    },
    {
      "epoch": 3.4518039849219173,
      "grad_norm": 0.657622218132019,
      "learning_rate": 1.3096392030156167e-05,
      "loss": 0.037,
      "step": 6410
    },
    {
      "epoch": 3.45718901453958,
      "grad_norm": 1.7013636827468872,
      "learning_rate": 1.3085621970920841e-05,
      "loss": 0.012,
      "step": 6420
    },
    {
      "epoch": 3.462574044157243,
      "grad_norm": 0.02145319990813732,
      "learning_rate": 1.3074851911685515e-05,
      "loss": 0.0652,
      "step": 6430
    },
    {
      "epoch": 3.4679590737749058,
      "grad_norm": 0.09644389897584915,
      "learning_rate": 1.306408185245019e-05,
      "loss": 0.0173,
      "step": 6440
    },
    {
      "epoch": 3.4733441033925687,
      "grad_norm": 6.4316935539245605,
      "learning_rate": 1.3053311793214865e-05,
      "loss": 0.0817,
      "step": 6450
    },
    {
      "epoch": 3.4787291330102317,
      "grad_norm": 3.181790590286255,
      "learning_rate": 1.3042541733979539e-05,
      "loss": 0.0371,
      "step": 6460
    },
    {
      "epoch": 3.4841141626278946,
      "grad_norm": 0.41067469120025635,
      "learning_rate": 1.3031771674744211e-05,
      "loss": 0.0358,
      "step": 6470
    },
    {
      "epoch": 3.489499192245557,
      "grad_norm": 0.2845490276813507,
      "learning_rate": 1.3021001615508886e-05,
      "loss": 0.0816,
      "step": 6480
    },
    {
      "epoch": 3.49488422186322,
      "grad_norm": 0.022572744637727737,
      "learning_rate": 1.301023155627356e-05,
      "loss": 0.0304,
      "step": 6490
    },
    {
      "epoch": 3.500269251480883,
      "grad_norm": 0.5424771308898926,
      "learning_rate": 1.2999461497038235e-05,
      "loss": 0.0158,
      "step": 6500
    },
    {
      "epoch": 3.505654281098546,
      "grad_norm": 0.6842243075370789,
      "learning_rate": 1.298869143780291e-05,
      "loss": 0.0625,
      "step": 6510
    },
    {
      "epoch": 3.511039310716209,
      "grad_norm": 4.807837963104248,
      "learning_rate": 1.2977921378567583e-05,
      "loss": 0.035,
      "step": 6520
    },
    {
      "epoch": 3.516424340333872,
      "grad_norm": 0.004692799411714077,
      "learning_rate": 1.2967151319332259e-05,
      "loss": 0.0327,
      "step": 6530
    },
    {
      "epoch": 3.5218093699515345,
      "grad_norm": 5.439798831939697,
      "learning_rate": 1.2956381260096931e-05,
      "loss": 0.0663,
      "step": 6540
    },
    {
      "epoch": 3.527194399569198,
      "grad_norm": 2.350480079650879,
      "learning_rate": 1.2945611200861605e-05,
      "loss": 0.011,
      "step": 6550
    },
    {
      "epoch": 3.5325794291868604,
      "grad_norm": 0.7169737219810486,
      "learning_rate": 1.293484114162628e-05,
      "loss": 0.0718,
      "step": 6560
    },
    {
      "epoch": 3.5379644588045234,
      "grad_norm": 0.2027725875377655,
      "learning_rate": 1.2924071082390954e-05,
      "loss": 0.031,
      "step": 6570
    },
    {
      "epoch": 3.5433494884221863,
      "grad_norm": 0.6119792461395264,
      "learning_rate": 1.291330102315563e-05,
      "loss": 0.0153,
      "step": 6580
    },
    {
      "epoch": 3.5487345180398493,
      "grad_norm": 27.641357421875,
      "learning_rate": 1.2902530963920303e-05,
      "loss": 0.0538,
      "step": 6590
    },
    {
      "epoch": 3.5541195476575123,
      "grad_norm": 3.458691120147705,
      "learning_rate": 1.2891760904684977e-05,
      "loss": 0.0134,
      "step": 6600
    },
    {
      "epoch": 3.5595045772751748,
      "grad_norm": 0.04646717756986618,
      "learning_rate": 1.288099084544965e-05,
      "loss": 0.0264,
      "step": 6610
    },
    {
      "epoch": 3.564889606892838,
      "grad_norm": 1.7402533292770386,
      "learning_rate": 1.2870220786214325e-05,
      "loss": 0.0219,
      "step": 6620
    },
    {
      "epoch": 3.5702746365105007,
      "grad_norm": 0.14782963693141937,
      "learning_rate": 1.2859450726979e-05,
      "loss": 0.0491,
      "step": 6630
    },
    {
      "epoch": 3.5756596661281637,
      "grad_norm": 0.02055331878364086,
      "learning_rate": 1.2848680667743674e-05,
      "loss": 0.0403,
      "step": 6640
    },
    {
      "epoch": 3.5810446957458266,
      "grad_norm": 0.0878891721367836,
      "learning_rate": 1.2837910608508348e-05,
      "loss": 0.0423,
      "step": 6650
    },
    {
      "epoch": 3.5864297253634896,
      "grad_norm": 0.03277828171849251,
      "learning_rate": 1.2827140549273023e-05,
      "loss": 0.0233,
      "step": 6660
    },
    {
      "epoch": 3.5918147549811525,
      "grad_norm": 3.612963914871216,
      "learning_rate": 1.2816370490037697e-05,
      "loss": 0.055,
      "step": 6670
    },
    {
      "epoch": 3.597199784598815,
      "grad_norm": 4.125499248504639,
      "learning_rate": 1.280560043080237e-05,
      "loss": 0.0552,
      "step": 6680
    },
    {
      "epoch": 3.602584814216478,
      "grad_norm": 2.1484873294830322,
      "learning_rate": 1.2794830371567044e-05,
      "loss": 0.0155,
      "step": 6690
    },
    {
      "epoch": 3.607969843834141,
      "grad_norm": 0.0064211394637823105,
      "learning_rate": 1.278406031233172e-05,
      "loss": 0.0142,
      "step": 6700
    },
    {
      "epoch": 3.613354873451804,
      "grad_norm": 0.5425055027008057,
      "learning_rate": 1.2773290253096393e-05,
      "loss": 0.0304,
      "step": 6710
    },
    {
      "epoch": 3.618739903069467,
      "grad_norm": 0.013084206730127335,
      "learning_rate": 1.2762520193861068e-05,
      "loss": 0.0259,
      "step": 6720
    },
    {
      "epoch": 3.62412493268713,
      "grad_norm": 0.005853682290762663,
      "learning_rate": 1.2751750134625742e-05,
      "loss": 0.0102,
      "step": 6730
    },
    {
      "epoch": 3.629509962304793,
      "grad_norm": 15.858506202697754,
      "learning_rate": 1.2740980075390417e-05,
      "loss": 0.0363,
      "step": 6740
    },
    {
      "epoch": 3.6348949919224554,
      "grad_norm": 20.427980422973633,
      "learning_rate": 1.273021001615509e-05,
      "loss": 0.0999,
      "step": 6750
    },
    {
      "epoch": 3.6402800215401183,
      "grad_norm": 0.031738974153995514,
      "learning_rate": 1.2719439956919764e-05,
      "loss": 0.0172,
      "step": 6760
    },
    {
      "epoch": 3.6456650511577813,
      "grad_norm": 0.9041752815246582,
      "learning_rate": 1.2708669897684438e-05,
      "loss": 0.0397,
      "step": 6770
    },
    {
      "epoch": 3.6510500807754442,
      "grad_norm": 0.04444092884659767,
      "learning_rate": 1.2697899838449112e-05,
      "loss": 0.0462,
      "step": 6780
    },
    {
      "epoch": 3.656435110393107,
      "grad_norm": 2.1524481773376465,
      "learning_rate": 1.2687129779213787e-05,
      "loss": 0.0469,
      "step": 6790
    },
    {
      "epoch": 3.66182014001077,
      "grad_norm": 1.7111607789993286,
      "learning_rate": 1.2676359719978462e-05,
      "loss": 0.0252,
      "step": 6800
    },
    {
      "epoch": 3.667205169628433,
      "grad_norm": 1.0068268775939941,
      "learning_rate": 1.2665589660743136e-05,
      "loss": 0.0347,
      "step": 6810
    },
    {
      "epoch": 3.6725901992460956,
      "grad_norm": 2.292816638946533,
      "learning_rate": 1.2654819601507808e-05,
      "loss": 0.0228,
      "step": 6820
    },
    {
      "epoch": 3.6779752288637586,
      "grad_norm": 0.48314449191093445,
      "learning_rate": 1.2644049542272484e-05,
      "loss": 0.0554,
      "step": 6830
    },
    {
      "epoch": 3.6833602584814216,
      "grad_norm": 0.30280742049217224,
      "learning_rate": 1.2633279483037158e-05,
      "loss": 0.0394,
      "step": 6840
    },
    {
      "epoch": 3.6887452880990845,
      "grad_norm": 0.006935219280421734,
      "learning_rate": 1.2622509423801832e-05,
      "loss": 0.0379,
      "step": 6850
    },
    {
      "epoch": 3.6941303177167475,
      "grad_norm": 24.915498733520508,
      "learning_rate": 1.2611739364566506e-05,
      "loss": 0.0192,
      "step": 6860
    },
    {
      "epoch": 3.6995153473344105,
      "grad_norm": 1.3152297735214233,
      "learning_rate": 1.2600969305331181e-05,
      "loss": 0.0606,
      "step": 6870
    },
    {
      "epoch": 3.7049003769520734,
      "grad_norm": 0.05365132540464401,
      "learning_rate": 1.2590199246095856e-05,
      "loss": 0.0415,
      "step": 6880
    },
    {
      "epoch": 3.710285406569736,
      "grad_norm": 1.3555748462677002,
      "learning_rate": 1.2579429186860528e-05,
      "loss": 0.0187,
      "step": 6890
    },
    {
      "epoch": 3.715670436187399,
      "grad_norm": 1.626258373260498,
      "learning_rate": 1.2568659127625202e-05,
      "loss": 0.0084,
      "step": 6900
    },
    {
      "epoch": 3.721055465805062,
      "grad_norm": 0.10348795354366302,
      "learning_rate": 1.2557889068389878e-05,
      "loss": 0.048,
      "step": 6910
    },
    {
      "epoch": 3.726440495422725,
      "grad_norm": 6.946320056915283,
      "learning_rate": 1.2547119009154552e-05,
      "loss": 0.0462,
      "step": 6920
    },
    {
      "epoch": 3.731825525040388,
      "grad_norm": 1.118412733078003,
      "learning_rate": 1.2536348949919226e-05,
      "loss": 0.0173,
      "step": 6930
    },
    {
      "epoch": 3.7372105546580507,
      "grad_norm": 23.703197479248047,
      "learning_rate": 1.25255788906839e-05,
      "loss": 0.064,
      "step": 6940
    },
    {
      "epoch": 3.7425955842757137,
      "grad_norm": 0.013588565401732922,
      "learning_rate": 1.2514808831448575e-05,
      "loss": 0.026,
      "step": 6950
    },
    {
      "epoch": 3.7479806138933762,
      "grad_norm": 21.492036819458008,
      "learning_rate": 1.2504038772213248e-05,
      "loss": 0.0228,
      "step": 6960
    },
    {
      "epoch": 3.753365643511039,
      "grad_norm": 0.008444279432296753,
      "learning_rate": 1.2493268712977922e-05,
      "loss": 0.0269,
      "step": 6970
    },
    {
      "epoch": 3.758750673128702,
      "grad_norm": 2.6771929264068604,
      "learning_rate": 1.2482498653742596e-05,
      "loss": 0.0551,
      "step": 6980
    },
    {
      "epoch": 3.764135702746365,
      "grad_norm": 1.3139227628707886,
      "learning_rate": 1.2471728594507272e-05,
      "loss": 0.013,
      "step": 6990
    },
    {
      "epoch": 3.769520732364028,
      "grad_norm": 0.03130348399281502,
      "learning_rate": 1.2460958535271946e-05,
      "loss": 0.0265,
      "step": 7000
    },
    {
      "epoch": 3.774905761981691,
      "grad_norm": 0.012217741459608078,
      "learning_rate": 1.245018847603662e-05,
      "loss": 0.0085,
      "step": 7010
    },
    {
      "epoch": 3.780290791599354,
      "grad_norm": 1.6942733526229858,
      "learning_rate": 1.2439418416801294e-05,
      "loss": 0.0127,
      "step": 7020
    },
    {
      "epoch": 3.7856758212170165,
      "grad_norm": 0.0037260425742715597,
      "learning_rate": 1.2428648357565966e-05,
      "loss": 0.0472,
      "step": 7030
    },
    {
      "epoch": 3.7910608508346795,
      "grad_norm": 0.0031482160557061434,
      "learning_rate": 1.2417878298330642e-05,
      "loss": 0.0151,
      "step": 7040
    },
    {
      "epoch": 3.7964458804523424,
      "grad_norm": 0.009143208153545856,
      "learning_rate": 1.2407108239095316e-05,
      "loss": 0.0324,
      "step": 7050
    },
    {
      "epoch": 3.8018309100700054,
      "grad_norm": 6.835501194000244,
      "learning_rate": 1.239633817985999e-05,
      "loss": 0.032,
      "step": 7060
    },
    {
      "epoch": 3.8072159396876684,
      "grad_norm": 0.007965423166751862,
      "learning_rate": 1.2385568120624664e-05,
      "loss": 0.0272,
      "step": 7070
    },
    {
      "epoch": 3.8126009693053313,
      "grad_norm": 0.010696545243263245,
      "learning_rate": 1.237479806138934e-05,
      "loss": 0.0189,
      "step": 7080
    },
    {
      "epoch": 3.8179859989229943,
      "grad_norm": 8.499281883239746,
      "learning_rate": 1.2364028002154014e-05,
      "loss": 0.0449,
      "step": 7090
    },
    {
      "epoch": 3.823371028540657,
      "grad_norm": 0.015915611758828163,
      "learning_rate": 1.2353257942918686e-05,
      "loss": 0.0146,
      "step": 7100
    },
    {
      "epoch": 3.8287560581583198,
      "grad_norm": 2.1216695308685303,
      "learning_rate": 1.234248788368336e-05,
      "loss": 0.0272,
      "step": 7110
    },
    {
      "epoch": 3.8341410877759827,
      "grad_norm": 0.04201504960656166,
      "learning_rate": 1.2331717824448036e-05,
      "loss": 0.0175,
      "step": 7120
    },
    {
      "epoch": 3.8395261173936457,
      "grad_norm": 6.554437160491943,
      "learning_rate": 1.232094776521271e-05,
      "loss": 0.0121,
      "step": 7130
    },
    {
      "epoch": 3.8449111470113086,
      "grad_norm": 4.003729820251465,
      "learning_rate": 1.2310177705977384e-05,
      "loss": 0.0515,
      "step": 7140
    },
    {
      "epoch": 3.8502961766289716,
      "grad_norm": 1.7445785999298096,
      "learning_rate": 1.2299407646742058e-05,
      "loss": 0.0517,
      "step": 7150
    },
    {
      "epoch": 3.8556812062466346,
      "grad_norm": 0.009334632195532322,
      "learning_rate": 1.2288637587506734e-05,
      "loss": 0.0166,
      "step": 7160
    },
    {
      "epoch": 3.861066235864297,
      "grad_norm": 2.5790133476257324,
      "learning_rate": 1.2277867528271406e-05,
      "loss": 0.0095,
      "step": 7170
    },
    {
      "epoch": 3.86645126548196,
      "grad_norm": 3.129469156265259,
      "learning_rate": 1.226709746903608e-05,
      "loss": 0.0463,
      "step": 7180
    },
    {
      "epoch": 3.871836295099623,
      "grad_norm": 0.4913027286529541,
      "learning_rate": 1.2256327409800754e-05,
      "loss": 0.0426,
      "step": 7190
    },
    {
      "epoch": 3.877221324717286,
      "grad_norm": 0.16926518082618713,
      "learning_rate": 1.224555735056543e-05,
      "loss": 0.0337,
      "step": 7200
    },
    {
      "epoch": 3.882606354334949,
      "grad_norm": 0.01857736147940159,
      "learning_rate": 1.2234787291330104e-05,
      "loss": 0.0657,
      "step": 7210
    },
    {
      "epoch": 3.887991383952612,
      "grad_norm": 1.4593220949172974,
      "learning_rate": 1.2224017232094778e-05,
      "loss": 0.0158,
      "step": 7220
    },
    {
      "epoch": 3.893376413570275,
      "grad_norm": 1.4890772104263306,
      "learning_rate": 1.2213247172859452e-05,
      "loss": 0.0117,
      "step": 7230
    },
    {
      "epoch": 3.8987614431879374,
      "grad_norm": 1.0951967239379883,
      "learning_rate": 1.2202477113624124e-05,
      "loss": 0.0275,
      "step": 7240
    },
    {
      "epoch": 3.9041464728056003,
      "grad_norm": 2.229127883911133,
      "learning_rate": 1.21917070543888e-05,
      "loss": 0.0388,
      "step": 7250
    },
    {
      "epoch": 3.9095315024232633,
      "grad_norm": 0.24950982630252838,
      "learning_rate": 1.2180936995153474e-05,
      "loss": 0.0322,
      "step": 7260
    },
    {
      "epoch": 3.9149165320409263,
      "grad_norm": 8.071725845336914,
      "learning_rate": 1.2170166935918148e-05,
      "loss": 0.069,
      "step": 7270
    },
    {
      "epoch": 3.9203015616585892,
      "grad_norm": 1.2194714546203613,
      "learning_rate": 1.2159396876682822e-05,
      "loss": 0.0175,
      "step": 7280
    },
    {
      "epoch": 3.9256865912762517,
      "grad_norm": 2.986360788345337,
      "learning_rate": 1.2148626817447498e-05,
      "loss": 0.037,
      "step": 7290
    },
    {
      "epoch": 3.931071620893915,
      "grad_norm": 0.0009091828251257539,
      "learning_rate": 1.2137856758212172e-05,
      "loss": 0.0237,
      "step": 7300
    },
    {
      "epoch": 3.9364566505115777,
      "grad_norm": 3.546086311340332,
      "learning_rate": 1.2127086698976844e-05,
      "loss": 0.0381,
      "step": 7310
    },
    {
      "epoch": 3.9418416801292406,
      "grad_norm": 0.002936430973932147,
      "learning_rate": 1.2116316639741518e-05,
      "loss": 0.0071,
      "step": 7320
    },
    {
      "epoch": 3.9472267097469036,
      "grad_norm": 0.10740263760089874,
      "learning_rate": 1.2105546580506194e-05,
      "loss": 0.0148,
      "step": 7330
    },
    {
      "epoch": 3.9526117393645666,
      "grad_norm": 2.351769208908081,
      "learning_rate": 1.2094776521270868e-05,
      "loss": 0.0384,
      "step": 7340
    },
    {
      "epoch": 3.9579967689822295,
      "grad_norm": 0.00854229275137186,
      "learning_rate": 1.2084006462035542e-05,
      "loss": 0.0117,
      "step": 7350
    },
    {
      "epoch": 3.963381798599892,
      "grad_norm": 1.2583043575286865,
      "learning_rate": 1.2073236402800216e-05,
      "loss": 0.0497,
      "step": 7360
    },
    {
      "epoch": 3.9687668282175554,
      "grad_norm": 11.521114349365234,
      "learning_rate": 1.2062466343564892e-05,
      "loss": 0.0166,
      "step": 7370
    },
    {
      "epoch": 3.974151857835218,
      "grad_norm": 0.013648541644215584,
      "learning_rate": 1.2051696284329564e-05,
      "loss": 0.0111,
      "step": 7380
    },
    {
      "epoch": 3.979536887452881,
      "grad_norm": 3.881747007369995,
      "learning_rate": 1.2040926225094238e-05,
      "loss": 0.0666,
      "step": 7390
    },
    {
      "epoch": 3.984921917070544,
      "grad_norm": 1.1769697666168213,
      "learning_rate": 1.2030156165858912e-05,
      "loss": 0.0219,
      "step": 7400
    },
    {
      "epoch": 3.990306946688207,
      "grad_norm": 14.360215187072754,
      "learning_rate": 1.2019386106623588e-05,
      "loss": 0.0213,
      "step": 7410
    },
    {
      "epoch": 3.99569197630587,
      "grad_norm": 3.1982548236846924,
      "learning_rate": 1.2008616047388262e-05,
      "loss": 0.0334,
      "step": 7420
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9856312814070352,
      "eval_f1": 0.9465381244522348,
      "eval_loss": 0.058130502700805664,
      "eval_precision": 0.9625668449197861,
      "eval_recall": 0.9310344827586207,
      "eval_runtime": 306.86,
      "eval_samples_per_second": 41.517,
      "eval_steps_per_second": 1.3,
      "step": 7428
    },
    {
      "epoch": 4.001077005923532,
      "grad_norm": 1.1046600341796875,
      "learning_rate": 1.1997845988152936e-05,
      "loss": 0.0299,
      "step": 7430
    },
    {
      "epoch": 4.006462035541196,
      "grad_norm": 0.014118091203272343,
      "learning_rate": 1.198707592891761e-05,
      "loss": 0.0057,
      "step": 7440
    },
    {
      "epoch": 4.011847065158858,
      "grad_norm": 0.02922144904732704,
      "learning_rate": 1.1976305869682283e-05,
      "loss": 0.019,
      "step": 7450
    },
    {
      "epoch": 4.017232094776522,
      "grad_norm": 1.2972465753555298,
      "learning_rate": 1.1965535810446958e-05,
      "loss": 0.0206,
      "step": 7460
    },
    {
      "epoch": 4.022617124394184,
      "grad_norm": 0.4997651278972626,
      "learning_rate": 1.1954765751211632e-05,
      "loss": 0.01,
      "step": 7470
    },
    {
      "epoch": 4.028002154011847,
      "grad_norm": 1.5540971755981445,
      "learning_rate": 1.1943995691976306e-05,
      "loss": 0.0154,
      "step": 7480
    },
    {
      "epoch": 4.03338718362951,
      "grad_norm": 5.295886516571045,
      "learning_rate": 1.1933225632740982e-05,
      "loss": 0.0236,
      "step": 7490
    },
    {
      "epoch": 4.038772213247173,
      "grad_norm": 0.001651210943236947,
      "learning_rate": 1.1922455573505656e-05,
      "loss": 0.0195,
      "step": 7500
    },
    {
      "epoch": 4.044157242864836,
      "grad_norm": 4.390405654907227,
      "learning_rate": 1.191168551427033e-05,
      "loss": 0.0063,
      "step": 7510
    },
    {
      "epoch": 4.0495422724824985,
      "grad_norm": 0.005809709895402193,
      "learning_rate": 1.1900915455035002e-05,
      "loss": 0.0195,
      "step": 7520
    },
    {
      "epoch": 4.054927302100162,
      "grad_norm": 0.23739203810691833,
      "learning_rate": 1.1890145395799677e-05,
      "loss": 0.0292,
      "step": 7530
    },
    {
      "epoch": 4.0603123317178245,
      "grad_norm": 0.028839780017733574,
      "learning_rate": 1.1879375336564352e-05,
      "loss": 0.0164,
      "step": 7540
    },
    {
      "epoch": 4.065697361335487,
      "grad_norm": 0.028293121606111526,
      "learning_rate": 1.1868605277329026e-05,
      "loss": 0.0158,
      "step": 7550
    },
    {
      "epoch": 4.07108239095315,
      "grad_norm": 0.01172093115746975,
      "learning_rate": 1.18578352180937e-05,
      "loss": 0.0224,
      "step": 7560
    },
    {
      "epoch": 4.076467420570813,
      "grad_norm": 0.007505745626986027,
      "learning_rate": 1.1847065158858374e-05,
      "loss": 0.0082,
      "step": 7570
    },
    {
      "epoch": 4.081852450188476,
      "grad_norm": 0.02253885008394718,
      "learning_rate": 1.183629509962305e-05,
      "loss": 0.0253,
      "step": 7580
    },
    {
      "epoch": 4.087237479806139,
      "grad_norm": 2.3664016723632812,
      "learning_rate": 1.1825525040387724e-05,
      "loss": 0.0343,
      "step": 7590
    },
    {
      "epoch": 4.092622509423802,
      "grad_norm": 3.481045961380005,
      "learning_rate": 1.1814754981152396e-05,
      "loss": 0.0386,
      "step": 7600
    },
    {
      "epoch": 4.098007539041465,
      "grad_norm": 0.004591355100274086,
      "learning_rate": 1.180398492191707e-05,
      "loss": 0.0546,
      "step": 7610
    },
    {
      "epoch": 4.103392568659127,
      "grad_norm": 0.0055277408100664616,
      "learning_rate": 1.1793214862681746e-05,
      "loss": 0.0126,
      "step": 7620
    },
    {
      "epoch": 4.108777598276791,
      "grad_norm": 11.799758911132812,
      "learning_rate": 1.178244480344642e-05,
      "loss": 0.0439,
      "step": 7630
    },
    {
      "epoch": 4.114162627894453,
      "grad_norm": 2.3410134315490723,
      "learning_rate": 1.1771674744211094e-05,
      "loss": 0.0281,
      "step": 7640
    },
    {
      "epoch": 4.119547657512117,
      "grad_norm": 23.943220138549805,
      "learning_rate": 1.1760904684975768e-05,
      "loss": 0.0409,
      "step": 7650
    },
    {
      "epoch": 4.124932687129779,
      "grad_norm": 0.0020266487263143063,
      "learning_rate": 1.1750134625740444e-05,
      "loss": 0.0103,
      "step": 7660
    },
    {
      "epoch": 4.1303177167474425,
      "grad_norm": 0.01983276754617691,
      "learning_rate": 1.1739364566505116e-05,
      "loss": 0.0077,
      "step": 7670
    },
    {
      "epoch": 4.135702746365105,
      "grad_norm": 0.08525019884109497,
      "learning_rate": 1.172859450726979e-05,
      "loss": 0.0354,
      "step": 7680
    },
    {
      "epoch": 4.141087775982768,
      "grad_norm": 11.368772506713867,
      "learning_rate": 1.1717824448034465e-05,
      "loss": 0.0157,
      "step": 7690
    },
    {
      "epoch": 4.146472805600431,
      "grad_norm": 0.005584443919360638,
      "learning_rate": 1.170705438879914e-05,
      "loss": 0.012,
      "step": 7700
    },
    {
      "epoch": 4.1518578352180935,
      "grad_norm": 1.6516027450561523,
      "learning_rate": 1.1696284329563814e-05,
      "loss": 0.0139,
      "step": 7710
    },
    {
      "epoch": 4.157242864835757,
      "grad_norm": 0.0026231936644762754,
      "learning_rate": 1.1685514270328488e-05,
      "loss": 0.041,
      "step": 7720
    },
    {
      "epoch": 4.162627894453419,
      "grad_norm": 0.007515567820519209,
      "learning_rate": 1.1674744211093162e-05,
      "loss": 0.033,
      "step": 7730
    },
    {
      "epoch": 4.168012924071083,
      "grad_norm": 0.008083350025117397,
      "learning_rate": 1.1663974151857835e-05,
      "loss": 0.0078,
      "step": 7740
    },
    {
      "epoch": 4.173397953688745,
      "grad_norm": 3.4254307746887207,
      "learning_rate": 1.165320409262251e-05,
      "loss": 0.0329,
      "step": 7750
    },
    {
      "epoch": 4.178782983306408,
      "grad_norm": 0.022095734253525734,
      "learning_rate": 1.1642434033387184e-05,
      "loss": 0.0388,
      "step": 7760
    },
    {
      "epoch": 4.184168012924071,
      "grad_norm": 0.004965373780578375,
      "learning_rate": 1.1631663974151859e-05,
      "loss": 0.0425,
      "step": 7770
    },
    {
      "epoch": 4.189553042541734,
      "grad_norm": 0.00490420451387763,
      "learning_rate": 1.1620893914916533e-05,
      "loss": 0.0287,
      "step": 7780
    },
    {
      "epoch": 4.194938072159397,
      "grad_norm": 2.320735454559326,
      "learning_rate": 1.1610123855681208e-05,
      "loss": 0.0486,
      "step": 7790
    },
    {
      "epoch": 4.20032310177706,
      "grad_norm": 11.069273948669434,
      "learning_rate": 1.1599353796445882e-05,
      "loss": 0.0242,
      "step": 7800
    },
    {
      "epoch": 4.205708131394722,
      "grad_norm": 0.00617124792188406,
      "learning_rate": 1.1588583737210555e-05,
      "loss": 0.0403,
      "step": 7810
    },
    {
      "epoch": 4.211093161012386,
      "grad_norm": 0.45724087953567505,
      "learning_rate": 1.1577813677975229e-05,
      "loss": 0.0121,
      "step": 7820
    },
    {
      "epoch": 4.216478190630048,
      "grad_norm": 4.32571268081665,
      "learning_rate": 1.1567043618739904e-05,
      "loss": 0.047,
      "step": 7830
    },
    {
      "epoch": 4.2218632202477115,
      "grad_norm": 0.038161784410476685,
      "learning_rate": 1.1556273559504578e-05,
      "loss": 0.0493,
      "step": 7840
    },
    {
      "epoch": 4.227248249865374,
      "grad_norm": 0.5673422813415527,
      "learning_rate": 1.1545503500269253e-05,
      "loss": 0.0115,
      "step": 7850
    },
    {
      "epoch": 4.2326332794830375,
      "grad_norm": 3.623246192932129,
      "learning_rate": 1.1534733441033927e-05,
      "loss": 0.026,
      "step": 7860
    },
    {
      "epoch": 4.2380183091007,
      "grad_norm": 0.029874689877033234,
      "learning_rate": 1.1523963381798602e-05,
      "loss": 0.0194,
      "step": 7870
    },
    {
      "epoch": 4.2434033387183625,
      "grad_norm": 3.3817057609558105,
      "learning_rate": 1.1513193322563275e-05,
      "loss": 0.0638,
      "step": 7880
    },
    {
      "epoch": 4.248788368336026,
      "grad_norm": 0.16550680994987488,
      "learning_rate": 1.1502423263327949e-05,
      "loss": 0.019,
      "step": 7890
    },
    {
      "epoch": 4.254173397953688,
      "grad_norm": 15.119372367858887,
      "learning_rate": 1.1491653204092623e-05,
      "loss": 0.0457,
      "step": 7900
    },
    {
      "epoch": 4.259558427571352,
      "grad_norm": 0.18002893030643463,
      "learning_rate": 1.1480883144857298e-05,
      "loss": 0.0105,
      "step": 7910
    },
    {
      "epoch": 4.264943457189014,
      "grad_norm": 1.8870153427124023,
      "learning_rate": 1.1470113085621972e-05,
      "loss": 0.0283,
      "step": 7920
    },
    {
      "epoch": 4.270328486806678,
      "grad_norm": 0.42783722281455994,
      "learning_rate": 1.1459343026386647e-05,
      "loss": 0.0217,
      "step": 7930
    },
    {
      "epoch": 4.27571351642434,
      "grad_norm": 0.027634186670184135,
      "learning_rate": 1.144857296715132e-05,
      "loss": 0.014,
      "step": 7940
    },
    {
      "epoch": 4.281098546042003,
      "grad_norm": 8.211078643798828,
      "learning_rate": 1.1437802907915993e-05,
      "loss": 0.0568,
      "step": 7950
    },
    {
      "epoch": 4.286483575659666,
      "grad_norm": 2.8063809871673584,
      "learning_rate": 1.1427032848680669e-05,
      "loss": 0.0208,
      "step": 7960
    },
    {
      "epoch": 4.291868605277329,
      "grad_norm": 0.5629372000694275,
      "learning_rate": 1.1416262789445343e-05,
      "loss": 0.0033,
      "step": 7970
    },
    {
      "epoch": 4.297253634894992,
      "grad_norm": 0.3073543608188629,
      "learning_rate": 1.1405492730210017e-05,
      "loss": 0.0477,
      "step": 7980
    },
    {
      "epoch": 4.302638664512655,
      "grad_norm": 4.909834384918213,
      "learning_rate": 1.1394722670974692e-05,
      "loss": 0.0146,
      "step": 7990
    },
    {
      "epoch": 4.308023694130318,
      "grad_norm": 1.9312635660171509,
      "learning_rate": 1.1383952611739367e-05,
      "loss": 0.0046,
      "step": 8000
    },
    {
      "epoch": 4.313408723747981,
      "grad_norm": 0.09473754465579987,
      "learning_rate": 1.137318255250404e-05,
      "loss": 0.0271,
      "step": 8010
    },
    {
      "epoch": 4.318793753365643,
      "grad_norm": 0.013543923385441303,
      "learning_rate": 1.1362412493268713e-05,
      "loss": 0.0391,
      "step": 8020
    },
    {
      "epoch": 4.3241787829833065,
      "grad_norm": 1.4507275819778442,
      "learning_rate": 1.1351642434033387e-05,
      "loss": 0.0395,
      "step": 8030
    },
    {
      "epoch": 4.329563812600969,
      "grad_norm": 0.03915302827954292,
      "learning_rate": 1.1340872374798063e-05,
      "loss": 0.0205,
      "step": 8040
    },
    {
      "epoch": 4.334948842218632,
      "grad_norm": 0.09249933809041977,
      "learning_rate": 1.1330102315562737e-05,
      "loss": 0.0226,
      "step": 8050
    },
    {
      "epoch": 4.340333871836295,
      "grad_norm": 0.030063826590776443,
      "learning_rate": 1.131933225632741e-05,
      "loss": 0.0135,
      "step": 8060
    },
    {
      "epoch": 4.345718901453958,
      "grad_norm": 0.01789744198322296,
      "learning_rate": 1.1308562197092085e-05,
      "loss": 0.0145,
      "step": 8070
    },
    {
      "epoch": 4.351103931071621,
      "grad_norm": 0.026527337729930878,
      "learning_rate": 1.129779213785676e-05,
      "loss": 0.0173,
      "step": 8080
    },
    {
      "epoch": 4.356488960689283,
      "grad_norm": 0.08444452285766602,
      "learning_rate": 1.1287022078621433e-05,
      "loss": 0.0338,
      "step": 8090
    },
    {
      "epoch": 4.361873990306947,
      "grad_norm": 0.002551321405917406,
      "learning_rate": 1.1276252019386107e-05,
      "loss": 0.006,
      "step": 8100
    },
    {
      "epoch": 4.367259019924609,
      "grad_norm": 0.12220911681652069,
      "learning_rate": 1.1265481960150781e-05,
      "loss": 0.0312,
      "step": 8110
    },
    {
      "epoch": 4.372644049542273,
      "grad_norm": 0.8348966240882874,
      "learning_rate": 1.1254711900915457e-05,
      "loss": 0.0204,
      "step": 8120
    },
    {
      "epoch": 4.378029079159935,
      "grad_norm": 0.8329360485076904,
      "learning_rate": 1.124394184168013e-05,
      "loss": 0.0145,
      "step": 8130
    },
    {
      "epoch": 4.383414108777599,
      "grad_norm": 3.701801300048828,
      "learning_rate": 1.1233171782444805e-05,
      "loss": 0.0268,
      "step": 8140
    },
    {
      "epoch": 4.388799138395261,
      "grad_norm": 1.7479283809661865,
      "learning_rate": 1.1222401723209479e-05,
      "loss": 0.0383,
      "step": 8150
    },
    {
      "epoch": 4.394184168012924,
      "grad_norm": 0.5946447849273682,
      "learning_rate": 1.1211631663974151e-05,
      "loss": 0.0124,
      "step": 8160
    },
    {
      "epoch": 4.399569197630587,
      "grad_norm": 0.0400872640311718,
      "learning_rate": 1.1200861604738827e-05,
      "loss": 0.0145,
      "step": 8170
    },
    {
      "epoch": 4.40495422724825,
      "grad_norm": 0.004546572919934988,
      "learning_rate": 1.1190091545503501e-05,
      "loss": 0.0202,
      "step": 8180
    },
    {
      "epoch": 4.410339256865913,
      "grad_norm": 2.040926694869995,
      "learning_rate": 1.1179321486268175e-05,
      "loss": 0.0206,
      "step": 8190
    },
    {
      "epoch": 4.4157242864835755,
      "grad_norm": 17.119308471679688,
      "learning_rate": 1.116855142703285e-05,
      "loss": 0.0209,
      "step": 8200
    },
    {
      "epoch": 4.421109316101239,
      "grad_norm": 0.008593344129621983,
      "learning_rate": 1.1157781367797525e-05,
      "loss": 0.0042,
      "step": 8210
    },
    {
      "epoch": 4.426494345718901,
      "grad_norm": 0.0342668741941452,
      "learning_rate": 1.1147011308562199e-05,
      "loss": 0.0503,
      "step": 8220
    },
    {
      "epoch": 4.431879375336564,
      "grad_norm": 0.22660061717033386,
      "learning_rate": 1.1136241249326871e-05,
      "loss": 0.0353,
      "step": 8230
    },
    {
      "epoch": 4.437264404954227,
      "grad_norm": 1.5704851150512695,
      "learning_rate": 1.1125471190091545e-05,
      "loss": 0.0151,
      "step": 8240
    },
    {
      "epoch": 4.44264943457189,
      "grad_norm": 1.4157888889312744,
      "learning_rate": 1.1114701130856221e-05,
      "loss": 0.0283,
      "step": 8250
    },
    {
      "epoch": 4.448034464189553,
      "grad_norm": 0.001597889233380556,
      "learning_rate": 1.1103931071620895e-05,
      "loss": 0.0446,
      "step": 8260
    },
    {
      "epoch": 4.453419493807216,
      "grad_norm": 0.1136169582605362,
      "learning_rate": 1.1093161012385569e-05,
      "loss": 0.0278,
      "step": 8270
    },
    {
      "epoch": 4.458804523424879,
      "grad_norm": 0.027531888335943222,
      "learning_rate": 1.1082390953150243e-05,
      "loss": 0.0055,
      "step": 8280
    },
    {
      "epoch": 4.464189553042542,
      "grad_norm": 0.769430935382843,
      "learning_rate": 1.1071620893914919e-05,
      "loss": 0.0442,
      "step": 8290
    },
    {
      "epoch": 4.469574582660204,
      "grad_norm": 6.416019916534424,
      "learning_rate": 1.1060850834679591e-05,
      "loss": 0.0605,
      "step": 8300
    },
    {
      "epoch": 4.474959612277868,
      "grad_norm": 0.14466890692710876,
      "learning_rate": 1.1050080775444265e-05,
      "loss": 0.042,
      "step": 8310
    },
    {
      "epoch": 4.48034464189553,
      "grad_norm": 0.14025665819644928,
      "learning_rate": 1.1039310716208939e-05,
      "loss": 0.0775,
      "step": 8320
    },
    {
      "epoch": 4.485729671513194,
      "grad_norm": 0.013404936529695988,
      "learning_rate": 1.1028540656973615e-05,
      "loss": 0.0088,
      "step": 8330
    },
    {
      "epoch": 4.491114701130856,
      "grad_norm": 0.002573934616521001,
      "learning_rate": 1.1017770597738289e-05,
      "loss": 0.0185,
      "step": 8340
    },
    {
      "epoch": 4.4964997307485195,
      "grad_norm": 0.19537214934825897,
      "learning_rate": 1.1007000538502963e-05,
      "loss": 0.0143,
      "step": 8350
    },
    {
      "epoch": 4.501884760366182,
      "grad_norm": 0.0036485856398940086,
      "learning_rate": 1.0996230479267637e-05,
      "loss": 0.0191,
      "step": 8360
    },
    {
      "epoch": 4.5072697899838445,
      "grad_norm": 0.6719664335250854,
      "learning_rate": 1.098546042003231e-05,
      "loss": 0.0176,
      "step": 8370
    },
    {
      "epoch": 4.512654819601508,
      "grad_norm": 2.5985233783721924,
      "learning_rate": 1.0974690360796985e-05,
      "loss": 0.0514,
      "step": 8380
    },
    {
      "epoch": 4.5180398492191705,
      "grad_norm": 0.37510186433792114,
      "learning_rate": 1.0963920301561659e-05,
      "loss": 0.0256,
      "step": 8390
    },
    {
      "epoch": 4.523424878836834,
      "grad_norm": 0.06804680079221725,
      "learning_rate": 1.0953150242326333e-05,
      "loss": 0.0111,
      "step": 8400
    },
    {
      "epoch": 4.528809908454496,
      "grad_norm": 0.16620996594429016,
      "learning_rate": 1.0942380183091009e-05,
      "loss": 0.0423,
      "step": 8410
    },
    {
      "epoch": 4.53419493807216,
      "grad_norm": 0.0064039165154099464,
      "learning_rate": 1.0931610123855683e-05,
      "loss": 0.0063,
      "step": 8420
    },
    {
      "epoch": 4.539579967689822,
      "grad_norm": 0.007609926164150238,
      "learning_rate": 1.0920840064620357e-05,
      "loss": 0.0229,
      "step": 8430
    },
    {
      "epoch": 4.544964997307485,
      "grad_norm": 0.9619948863983154,
      "learning_rate": 1.091007000538503e-05,
      "loss": 0.043,
      "step": 8440
    },
    {
      "epoch": 4.550350026925148,
      "grad_norm": 4.368240833282471,
      "learning_rate": 1.0899299946149703e-05,
      "loss": 0.0273,
      "step": 8450
    },
    {
      "epoch": 4.555735056542811,
      "grad_norm": 0.011305144988000393,
      "learning_rate": 1.0888529886914379e-05,
      "loss": 0.0237,
      "step": 8460
    },
    {
      "epoch": 4.561120086160474,
      "grad_norm": 0.04035774990916252,
      "learning_rate": 1.0877759827679053e-05,
      "loss": 0.0284,
      "step": 8470
    },
    {
      "epoch": 4.566505115778137,
      "grad_norm": 4.077869415283203,
      "learning_rate": 1.0866989768443727e-05,
      "loss": 0.0438,
      "step": 8480
    },
    {
      "epoch": 4.5718901453958,
      "grad_norm": 0.9205623269081116,
      "learning_rate": 1.0856219709208403e-05,
      "loss": 0.0292,
      "step": 8490
    },
    {
      "epoch": 4.577275175013463,
      "grad_norm": 0.3739566504955292,
      "learning_rate": 1.0845449649973077e-05,
      "loss": 0.0352,
      "step": 8500
    },
    {
      "epoch": 4.582660204631125,
      "grad_norm": 0.06055779010057449,
      "learning_rate": 1.083467959073775e-05,
      "loss": 0.0396,
      "step": 8510
    },
    {
      "epoch": 4.5880452342487885,
      "grad_norm": 0.0028346185572445393,
      "learning_rate": 1.0823909531502423e-05,
      "loss": 0.0069,
      "step": 8520
    },
    {
      "epoch": 4.593430263866451,
      "grad_norm": 0.3345244526863098,
      "learning_rate": 1.0813139472267097e-05,
      "loss": 0.0409,
      "step": 8530
    },
    {
      "epoch": 4.598815293484114,
      "grad_norm": 1.119684100151062,
      "learning_rate": 1.0802369413031773e-05,
      "loss": 0.0101,
      "step": 8540
    },
    {
      "epoch": 4.604200323101777,
      "grad_norm": 1.6714918613433838,
      "learning_rate": 1.0791599353796447e-05,
      "loss": 0.0167,
      "step": 8550
    },
    {
      "epoch": 4.60958535271944,
      "grad_norm": 0.15487609803676605,
      "learning_rate": 1.0780829294561121e-05,
      "loss": 0.017,
      "step": 8560
    },
    {
      "epoch": 4.614970382337103,
      "grad_norm": 0.9813747406005859,
      "learning_rate": 1.0770059235325795e-05,
      "loss": 0.0164,
      "step": 8570
    },
    {
      "epoch": 4.620355411954765,
      "grad_norm": 0.1395793855190277,
      "learning_rate": 1.0759289176090468e-05,
      "loss": 0.0421,
      "step": 8580
    },
    {
      "epoch": 4.625740441572429,
      "grad_norm": 4.982861042022705,
      "learning_rate": 1.0748519116855143e-05,
      "loss": 0.0319,
      "step": 8590
    },
    {
      "epoch": 4.631125471190091,
      "grad_norm": 0.021985473111271858,
      "learning_rate": 1.0737749057619817e-05,
      "loss": 0.007,
      "step": 8600
    },
    {
      "epoch": 4.636510500807755,
      "grad_norm": 0.8925957083702087,
      "learning_rate": 1.0726978998384491e-05,
      "loss": 0.0935,
      "step": 8610
    },
    {
      "epoch": 4.641895530425417,
      "grad_norm": 0.2816924452781677,
      "learning_rate": 1.0716208939149167e-05,
      "loss": 0.0389,
      "step": 8620
    },
    {
      "epoch": 4.647280560043081,
      "grad_norm": 0.1755744367837906,
      "learning_rate": 1.0705438879913841e-05,
      "loss": 0.0398,
      "step": 8630
    },
    {
      "epoch": 4.652665589660743,
      "grad_norm": 0.04394685477018356,
      "learning_rate": 1.0694668820678515e-05,
      "loss": 0.0233,
      "step": 8640
    },
    {
      "epoch": 4.658050619278406,
      "grad_norm": 3.4316580295562744,
      "learning_rate": 1.0683898761443187e-05,
      "loss": 0.0373,
      "step": 8650
    },
    {
      "epoch": 4.663435648896069,
      "grad_norm": 0.02381707914173603,
      "learning_rate": 1.0673128702207862e-05,
      "loss": 0.0035,
      "step": 8660
    },
    {
      "epoch": 4.668820678513732,
      "grad_norm": 0.019917387515306473,
      "learning_rate": 1.0662358642972537e-05,
      "loss": 0.0188,
      "step": 8670
    },
    {
      "epoch": 4.674205708131395,
      "grad_norm": 3.181286096572876,
      "learning_rate": 1.0651588583737211e-05,
      "loss": 0.0197,
      "step": 8680
    },
    {
      "epoch": 4.6795907377490575,
      "grad_norm": 0.020732203498482704,
      "learning_rate": 1.0640818524501885e-05,
      "loss": 0.0009,
      "step": 8690
    },
    {
      "epoch": 4.684975767366721,
      "grad_norm": 4.842607021331787,
      "learning_rate": 1.0630048465266561e-05,
      "loss": 0.0298,
      "step": 8700
    },
    {
      "epoch": 4.6903607969843835,
      "grad_norm": 0.05739529803395271,
      "learning_rate": 1.0619278406031235e-05,
      "loss": 0.0441,
      "step": 8710
    },
    {
      "epoch": 4.695745826602046,
      "grad_norm": 0.6953744292259216,
      "learning_rate": 1.060850834679591e-05,
      "loss": 0.0184,
      "step": 8720
    },
    {
      "epoch": 4.701130856219709,
      "grad_norm": 2.2994558811187744,
      "learning_rate": 1.0597738287560582e-05,
      "loss": 0.0217,
      "step": 8730
    },
    {
      "epoch": 4.706515885837372,
      "grad_norm": 0.014479649253189564,
      "learning_rate": 1.0586968228325256e-05,
      "loss": 0.0101,
      "step": 8740
    },
    {
      "epoch": 4.711900915455035,
      "grad_norm": 0.22766125202178955,
      "learning_rate": 1.0576198169089931e-05,
      "loss": 0.064,
      "step": 8750
    },
    {
      "epoch": 4.717285945072698,
      "grad_norm": 1.0647704601287842,
      "learning_rate": 1.0565428109854605e-05,
      "loss": 0.0217,
      "step": 8760
    },
    {
      "epoch": 4.722670974690361,
      "grad_norm": 0.2248738706111908,
      "learning_rate": 1.055465805061928e-05,
      "loss": 0.0476,
      "step": 8770
    },
    {
      "epoch": 4.728056004308024,
      "grad_norm": 0.013420574367046356,
      "learning_rate": 1.0543887991383955e-05,
      "loss": 0.0041,
      "step": 8780
    },
    {
      "epoch": 4.733441033925686,
      "grad_norm": 0.006396515294909477,
      "learning_rate": 1.0533117932148629e-05,
      "loss": 0.0116,
      "step": 8790
    },
    {
      "epoch": 4.73882606354335,
      "grad_norm": 7.056852340698242,
      "learning_rate": 1.0522347872913301e-05,
      "loss": 0.0462,
      "step": 8800
    },
    {
      "epoch": 4.744211093161012,
      "grad_norm": 14.894464492797852,
      "learning_rate": 1.0511577813677976e-05,
      "loss": 0.0241,
      "step": 8810
    },
    {
      "epoch": 4.749596122778676,
      "grad_norm": 0.01058141328394413,
      "learning_rate": 1.050080775444265e-05,
      "loss": 0.0737,
      "step": 8820
    },
    {
      "epoch": 4.754981152396338,
      "grad_norm": 0.030261225998401642,
      "learning_rate": 1.0490037695207325e-05,
      "loss": 0.0331,
      "step": 8830
    },
    {
      "epoch": 4.7603661820140015,
      "grad_norm": 0.44998428225517273,
      "learning_rate": 1.0479267635972e-05,
      "loss": 0.0126,
      "step": 8840
    },
    {
      "epoch": 4.765751211631664,
      "grad_norm": 0.010606635361909866,
      "learning_rate": 1.0468497576736673e-05,
      "loss": 0.0229,
      "step": 8850
    },
    {
      "epoch": 4.771136241249327,
      "grad_norm": 0.018649201840162277,
      "learning_rate": 1.0457727517501347e-05,
      "loss": 0.0091,
      "step": 8860
    },
    {
      "epoch": 4.77652127086699,
      "grad_norm": 0.15340952575206757,
      "learning_rate": 1.044695745826602e-05,
      "loss": 0.0355,
      "step": 8870
    },
    {
      "epoch": 4.7819063004846525,
      "grad_norm": 1.5946109294891357,
      "learning_rate": 1.0436187399030695e-05,
      "loss": 0.0453,
      "step": 8880
    },
    {
      "epoch": 4.787291330102316,
      "grad_norm": 3.9452261924743652,
      "learning_rate": 1.042541733979537e-05,
      "loss": 0.0128,
      "step": 8890
    },
    {
      "epoch": 4.792676359719978,
      "grad_norm": 0.11355108767747879,
      "learning_rate": 1.0414647280560044e-05,
      "loss": 0.021,
      "step": 8900
    },
    {
      "epoch": 4.798061389337642,
      "grad_norm": 0.014682459644973278,
      "learning_rate": 1.040387722132472e-05,
      "loss": 0.0059,
      "step": 8910
    },
    {
      "epoch": 4.803446418955304,
      "grad_norm": 1.5861537456512451,
      "learning_rate": 1.0393107162089393e-05,
      "loss": 0.0584,
      "step": 8920
    },
    {
      "epoch": 4.808831448572967,
      "grad_norm": 1.3253101110458374,
      "learning_rate": 1.0382337102854067e-05,
      "loss": 0.0398,
      "step": 8930
    },
    {
      "epoch": 4.81421647819063,
      "grad_norm": 0.023983413353562355,
      "learning_rate": 1.037156704361874e-05,
      "loss": 0.044,
      "step": 8940
    },
    {
      "epoch": 4.819601507808293,
      "grad_norm": 0.2335430085659027,
      "learning_rate": 1.0360796984383414e-05,
      "loss": 0.0293,
      "step": 8950
    },
    {
      "epoch": 4.824986537425956,
      "grad_norm": 1.0401798486709595,
      "learning_rate": 1.035002692514809e-05,
      "loss": 0.0276,
      "step": 8960
    },
    {
      "epoch": 4.830371567043619,
      "grad_norm": 0.1423269659280777,
      "learning_rate": 1.0339256865912764e-05,
      "loss": 0.0198,
      "step": 8970
    },
    {
      "epoch": 4.835756596661282,
      "grad_norm": 7.645847320556641,
      "learning_rate": 1.0328486806677438e-05,
      "loss": 0.0617,
      "step": 8980
    },
    {
      "epoch": 4.841141626278945,
      "grad_norm": 6.086015224456787,
      "learning_rate": 1.0317716747442113e-05,
      "loss": 0.0135,
      "step": 8990
    },
    {
      "epoch": 4.846526655896607,
      "grad_norm": 2.365563154220581,
      "learning_rate": 1.0306946688206787e-05,
      "loss": 0.0159,
      "step": 9000
    },
    {
      "epoch": 4.8519116855142705,
      "grad_norm": 2.7225563526153564,
      "learning_rate": 1.029617662897146e-05,
      "loss": 0.0279,
      "step": 9010
    },
    {
      "epoch": 4.857296715131933,
      "grad_norm": 2.286593437194824,
      "learning_rate": 1.0285406569736134e-05,
      "loss": 0.03,
      "step": 9020
    },
    {
      "epoch": 4.8626817447495965,
      "grad_norm": 0.02437679097056389,
      "learning_rate": 1.0274636510500808e-05,
      "loss": 0.0603,
      "step": 9030
    },
    {
      "epoch": 4.868066774367259,
      "grad_norm": 0.026240939274430275,
      "learning_rate": 1.0263866451265483e-05,
      "loss": 0.0414,
      "step": 9040
    },
    {
      "epoch": 4.873451803984922,
      "grad_norm": 0.054638367146253586,
      "learning_rate": 1.0253096392030158e-05,
      "loss": 0.0382,
      "step": 9050
    },
    {
      "epoch": 4.878836833602585,
      "grad_norm": 0.03316997364163399,
      "learning_rate": 1.0242326332794832e-05,
      "loss": 0.0553,
      "step": 9060
    },
    {
      "epoch": 4.884221863220247,
      "grad_norm": 4.203495502471924,
      "learning_rate": 1.0231556273559506e-05,
      "loss": 0.0497,
      "step": 9070
    },
    {
      "epoch": 4.889606892837911,
      "grad_norm": 2.1719586849212646,
      "learning_rate": 1.0220786214324178e-05,
      "loss": 0.0212,
      "step": 9080
    },
    {
      "epoch": 4.894991922455573,
      "grad_norm": 1.4202227592468262,
      "learning_rate": 1.0210016155088854e-05,
      "loss": 0.0266,
      "step": 9090
    },
    {
      "epoch": 4.900376952073237,
      "grad_norm": 0.08620695769786835,
      "learning_rate": 1.0199246095853528e-05,
      "loss": 0.0232,
      "step": 9100
    },
    {
      "epoch": 4.905761981690899,
      "grad_norm": 0.28933951258659363,
      "learning_rate": 1.0188476036618202e-05,
      "loss": 0.0289,
      "step": 9110
    },
    {
      "epoch": 4.911147011308563,
      "grad_norm": 8.791132926940918,
      "learning_rate": 1.0177705977382877e-05,
      "loss": 0.0507,
      "step": 9120
    },
    {
      "epoch": 4.916532040926225,
      "grad_norm": 0.054646603763103485,
      "learning_rate": 1.0166935918147552e-05,
      "loss": 0.009,
      "step": 9130
    },
    {
      "epoch": 4.921917070543888,
      "grad_norm": 5.2467732429504395,
      "learning_rate": 1.0156165858912226e-05,
      "loss": 0.0133,
      "step": 9140
    },
    {
      "epoch": 4.927302100161551,
      "grad_norm": 1.064334511756897,
      "learning_rate": 1.0145395799676898e-05,
      "loss": 0.0224,
      "step": 9150
    },
    {
      "epoch": 4.932687129779214,
      "grad_norm": 0.0726877972483635,
      "learning_rate": 1.0134625740441572e-05,
      "loss": 0.0239,
      "step": 9160
    },
    {
      "epoch": 4.938072159396877,
      "grad_norm": 0.002402212470769882,
      "learning_rate": 1.0123855681206248e-05,
      "loss": 0.0047,
      "step": 9170
    },
    {
      "epoch": 4.94345718901454,
      "grad_norm": 0.0026772702112793922,
      "learning_rate": 1.0113085621970922e-05,
      "loss": 0.0127,
      "step": 9180
    },
    {
      "epoch": 4.948842218632203,
      "grad_norm": 0.004558298271149397,
      "learning_rate": 1.0102315562735596e-05,
      "loss": 0.0086,
      "step": 9190
    },
    {
      "epoch": 4.9542272482498655,
      "grad_norm": 0.7653692960739136,
      "learning_rate": 1.0091545503500271e-05,
      "loss": 0.0519,
      "step": 9200
    },
    {
      "epoch": 4.959612277867528,
      "grad_norm": 0.008539840579032898,
      "learning_rate": 1.0080775444264946e-05,
      "loss": 0.0144,
      "step": 9210
    },
    {
      "epoch": 4.964997307485191,
      "grad_norm": 0.005527529399842024,
      "learning_rate": 1.0070005385029618e-05,
      "loss": 0.0211,
      "step": 9220
    },
    {
      "epoch": 4.970382337102854,
      "grad_norm": 0.015301370993256569,
      "learning_rate": 1.0059235325794292e-05,
      "loss": 0.0008,
      "step": 9230
    },
    {
      "epoch": 4.975767366720517,
      "grad_norm": 1.5773972272872925,
      "learning_rate": 1.0048465266558966e-05,
      "loss": 0.0422,
      "step": 9240
    },
    {
      "epoch": 4.98115239633818,
      "grad_norm": 1.151606559753418,
      "learning_rate": 1.0037695207323642e-05,
      "loss": 0.0321,
      "step": 9250
    },
    {
      "epoch": 4.986537425955842,
      "grad_norm": 3.0417258739471436,
      "learning_rate": 1.0026925148088316e-05,
      "loss": 0.0438,
      "step": 9260
    },
    {
      "epoch": 4.991922455573506,
      "grad_norm": 3.6291425228118896,
      "learning_rate": 1.001615508885299e-05,
      "loss": 0.029,
      "step": 9270
    },
    {
      "epoch": 4.997307485191168,
      "grad_norm": 0.08666334301233292,
      "learning_rate": 1.0005385029617665e-05,
      "loss": 0.0241,
      "step": 9280
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9853957286432161,
      "eval_f1": 0.9461805555555556,
      "eval_loss": 0.049452703446149826,
      "eval_precision": 0.9527972027972028,
      "eval_recall": 0.9396551724137931,
      "eval_runtime": 303.2288,
      "eval_samples_per_second": 42.014,
      "eval_steps_per_second": 1.316,
      "step": 9285
    },
    {
      "epoch": 5.002692514808832,
      "grad_norm": 2.0607070922851562,
      "learning_rate": 9.994614970382338e-06,
      "loss": 0.0132,
      "step": 9290
    },
    {
      "epoch": 5.008077544426494,
      "grad_norm": 0.061347998678684235,
      "learning_rate": 9.983844911147012e-06,
      "loss": 0.0348,
      "step": 9300
    },
    {
      "epoch": 5.013462574044158,
      "grad_norm": 0.18048255145549774,
      "learning_rate": 9.973074851911686e-06,
      "loss": 0.0088,
      "step": 9310
    },
    {
      "epoch": 5.01884760366182,
      "grad_norm": 1.0670547485351562,
      "learning_rate": 9.96230479267636e-06,
      "loss": 0.0153,
      "step": 9320
    },
    {
      "epoch": 5.024232633279483,
      "grad_norm": 0.06519117951393127,
      "learning_rate": 9.951534733441036e-06,
      "loss": 0.0228,
      "step": 9330
    },
    {
      "epoch": 5.029617662897146,
      "grad_norm": 0.09629441797733307,
      "learning_rate": 9.940764674205708e-06,
      "loss": 0.0296,
      "step": 9340
    },
    {
      "epoch": 5.035002692514809,
      "grad_norm": 2.451652765274048,
      "learning_rate": 9.929994614970384e-06,
      "loss": 0.0146,
      "step": 9350
    },
    {
      "epoch": 5.040387722132472,
      "grad_norm": 0.010013757273554802,
      "learning_rate": 9.919224555735058e-06,
      "loss": 0.0171,
      "step": 9360
    },
    {
      "epoch": 5.0457727517501345,
      "grad_norm": 1.4662023782730103,
      "learning_rate": 9.908454496499732e-06,
      "loss": 0.0107,
      "step": 9370
    },
    {
      "epoch": 5.051157781367798,
      "grad_norm": 0.35062944889068604,
      "learning_rate": 9.897684437264406e-06,
      "loss": 0.0052,
      "step": 9380
    },
    {
      "epoch": 5.05654281098546,
      "grad_norm": 0.004118934273719788,
      "learning_rate": 9.88691437802908e-06,
      "loss": 0.0301,
      "step": 9390
    },
    {
      "epoch": 5.061927840603123,
      "grad_norm": 0.45888808369636536,
      "learning_rate": 9.876144318793754e-06,
      "loss": 0.0299,
      "step": 9400
    },
    {
      "epoch": 5.067312870220786,
      "grad_norm": 0.029866976663470268,
      "learning_rate": 9.865374259558428e-06,
      "loss": 0.0238,
      "step": 9410
    },
    {
      "epoch": 5.072697899838449,
      "grad_norm": 0.003914689179509878,
      "learning_rate": 9.854604200323102e-06,
      "loss": 0.0115,
      "step": 9420
    },
    {
      "epoch": 5.078082929456112,
      "grad_norm": 0.0033120466396212578,
      "learning_rate": 9.843834141087776e-06,
      "loss": 0.0315,
      "step": 9430
    },
    {
      "epoch": 5.083467959073775,
      "grad_norm": 9.870609283447266,
      "learning_rate": 9.833064081852452e-06,
      "loss": 0.0094,
      "step": 9440
    },
    {
      "epoch": 5.088852988691438,
      "grad_norm": 1.2095892429351807,
      "learning_rate": 9.822294022617124e-06,
      "loss": 0.0171,
      "step": 9450
    },
    {
      "epoch": 5.094238018309101,
      "grad_norm": 0.4225747883319855,
      "learning_rate": 9.8115239633818e-06,
      "loss": 0.0199,
      "step": 9460
    },
    {
      "epoch": 5.099623047926763,
      "grad_norm": 2.196830987930298,
      "learning_rate": 9.800753904146474e-06,
      "loss": 0.0894,
      "step": 9470
    },
    {
      "epoch": 5.105008077544427,
      "grad_norm": 0.0031265094876289368,
      "learning_rate": 9.789983844911148e-06,
      "loss": 0.0085,
      "step": 9480
    },
    {
      "epoch": 5.110393107162089,
      "grad_norm": 3.5165743827819824,
      "learning_rate": 9.779213785675822e-06,
      "loss": 0.0146,
      "step": 9490
    },
    {
      "epoch": 5.115778136779753,
      "grad_norm": 0.47236549854278564,
      "learning_rate": 9.768443726440496e-06,
      "loss": 0.0148,
      "step": 9500
    },
    {
      "epoch": 5.121163166397415,
      "grad_norm": 0.03988395258784294,
      "learning_rate": 9.75767366720517e-06,
      "loss": 0.0143,
      "step": 9510
    },
    {
      "epoch": 5.1265481960150785,
      "grad_norm": 0.005920843221247196,
      "learning_rate": 9.746903607969844e-06,
      "loss": 0.0063,
      "step": 9520
    },
    {
      "epoch": 5.131933225632741,
      "grad_norm": 3.4704384803771973,
      "learning_rate": 9.736133548734518e-06,
      "loss": 0.0342,
      "step": 9530
    },
    {
      "epoch": 5.1373182552504035,
      "grad_norm": 0.010025006718933582,
      "learning_rate": 9.725363489499194e-06,
      "loss": 0.0069,
      "step": 9540
    },
    {
      "epoch": 5.142703284868067,
      "grad_norm": 4.022148609161377,
      "learning_rate": 9.714593430263866e-06,
      "loss": 0.0197,
      "step": 9550
    },
    {
      "epoch": 5.1480883144857295,
      "grad_norm": 0.007786952890455723,
      "learning_rate": 9.703823371028542e-06,
      "loss": 0.0208,
      "step": 9560
    },
    {
      "epoch": 5.153473344103393,
      "grad_norm": 0.002715763170272112,
      "learning_rate": 9.693053311793216e-06,
      "loss": 0.0109,
      "step": 9570
    },
    {
      "epoch": 5.158858373721055,
      "grad_norm": 0.8760581612586975,
      "learning_rate": 9.68228325255789e-06,
      "loss": 0.0008,
      "step": 9580
    },
    {
      "epoch": 5.164243403338719,
      "grad_norm": 0.0006480621523223817,
      "learning_rate": 9.671513193322564e-06,
      "loss": 0.0246,
      "step": 9590
    },
    {
      "epoch": 5.169628432956381,
      "grad_norm": 0.0016934151062741876,
      "learning_rate": 9.660743134087238e-06,
      "loss": 0.0069,
      "step": 9600
    },
    {
      "epoch": 5.175013462574044,
      "grad_norm": 0.0015059250872582197,
      "learning_rate": 9.649973074851912e-06,
      "loss": 0.0101,
      "step": 9610
    },
    {
      "epoch": 5.180398492191707,
      "grad_norm": 0.001026781857945025,
      "learning_rate": 9.639203015616588e-06,
      "loss": 0.001,
      "step": 9620
    },
    {
      "epoch": 5.18578352180937,
      "grad_norm": 0.3772038519382477,
      "learning_rate": 9.62843295638126e-06,
      "loss": 0.0114,
      "step": 9630
    },
    {
      "epoch": 5.191168551427033,
      "grad_norm": 0.003143906593322754,
      "learning_rate": 9.617662897145936e-06,
      "loss": 0.0457,
      "step": 9640
    },
    {
      "epoch": 5.196553581044696,
      "grad_norm": 1.0015490055084229,
      "learning_rate": 9.60689283791061e-06,
      "loss": 0.0292,
      "step": 9650
    },
    {
      "epoch": 5.201938610662358,
      "grad_norm": 3.623281955718994,
      "learning_rate": 9.596122778675282e-06,
      "loss": 0.0127,
      "step": 9660
    },
    {
      "epoch": 5.207323640280022,
      "grad_norm": 0.005399146117269993,
      "learning_rate": 9.585352719439958e-06,
      "loss": 0.0038,
      "step": 9670
    },
    {
      "epoch": 5.212708669897684,
      "grad_norm": 3.866682767868042,
      "learning_rate": 9.574582660204632e-06,
      "loss": 0.0114,
      "step": 9680
    },
    {
      "epoch": 5.2180936995153475,
      "grad_norm": 0.16296398639678955,
      "learning_rate": 9.563812600969306e-06,
      "loss": 0.0173,
      "step": 9690
    },
    {
      "epoch": 5.22347872913301,
      "grad_norm": 0.008734550327062607,
      "learning_rate": 9.55304254173398e-06,
      "loss": 0.0349,
      "step": 9700
    },
    {
      "epoch": 5.228863758750673,
      "grad_norm": 0.15502983331680298,
      "learning_rate": 9.542272482498654e-06,
      "loss": 0.0334,
      "step": 9710
    },
    {
      "epoch": 5.234248788368336,
      "grad_norm": 0.020353537052869797,
      "learning_rate": 9.531502423263328e-06,
      "loss": 0.0056,
      "step": 9720
    },
    {
      "epoch": 5.2396338179859985,
      "grad_norm": 0.1675870418548584,
      "learning_rate": 9.520732364028002e-06,
      "loss": 0.0246,
      "step": 9730
    },
    {
      "epoch": 5.245018847603662,
      "grad_norm": 1.6926485300064087,
      "learning_rate": 9.509962304792676e-06,
      "loss": 0.0206,
      "step": 9740
    },
    {
      "epoch": 5.250403877221324,
      "grad_norm": 2.167248249053955,
      "learning_rate": 9.499192245557352e-06,
      "loss": 0.03,
      "step": 9750
    },
    {
      "epoch": 5.255788906838988,
      "grad_norm": 0.009162701666355133,
      "learning_rate": 9.488422186322026e-06,
      "loss": 0.047,
      "step": 9760
    },
    {
      "epoch": 5.26117393645665,
      "grad_norm": 0.631333589553833,
      "learning_rate": 9.4776521270867e-06,
      "loss": 0.0307,
      "step": 9770
    },
    {
      "epoch": 5.266558966074314,
      "grad_norm": 0.027918826788663864,
      "learning_rate": 9.466882067851374e-06,
      "loss": 0.0201,
      "step": 9780
    },
    {
      "epoch": 5.271943995691976,
      "grad_norm": 15.87787914276123,
      "learning_rate": 9.456112008616048e-06,
      "loss": 0.0345,
      "step": 9790
    },
    {
      "epoch": 5.277329025309639,
      "grad_norm": 0.023922961205244064,
      "learning_rate": 9.445341949380722e-06,
      "loss": 0.0226,
      "step": 9800
    },
    {
      "epoch": 5.282714054927302,
      "grad_norm": 0.45947033166885376,
      "learning_rate": 9.434571890145396e-06,
      "loss": 0.0399,
      "step": 9810
    },
    {
      "epoch": 5.288099084544965,
      "grad_norm": 0.04635125398635864,
      "learning_rate": 9.42380183091007e-06,
      "loss": 0.0029,
      "step": 9820
    },
    {
      "epoch": 5.293484114162628,
      "grad_norm": 6.738995552062988,
      "learning_rate": 9.413031771674746e-06,
      "loss": 0.0327,
      "step": 9830
    },
    {
      "epoch": 5.298869143780291,
      "grad_norm": 1.0735292434692383,
      "learning_rate": 9.402261712439418e-06,
      "loss": 0.0152,
      "step": 9840
    },
    {
      "epoch": 5.304254173397954,
      "grad_norm": 2.6697256565093994,
      "learning_rate": 9.391491653204094e-06,
      "loss": 0.0109,
      "step": 9850
    },
    {
      "epoch": 5.3096392030156165,
      "grad_norm": 0.9197059869766235,
      "learning_rate": 9.380721593968768e-06,
      "loss": 0.0246,
      "step": 9860
    },
    {
      "epoch": 5.315024232633279,
      "grad_norm": 1.799217939376831,
      "learning_rate": 9.36995153473344e-06,
      "loss": 0.0299,
      "step": 9870
    },
    {
      "epoch": 5.3204092622509425,
      "grad_norm": 0.01283992175012827,
      "learning_rate": 9.359181475498116e-06,
      "loss": 0.0219,
      "step": 9880
    },
    {
      "epoch": 5.325794291868605,
      "grad_norm": 0.006539684254676104,
      "learning_rate": 9.34841141626279e-06,
      "loss": 0.008,
      "step": 9890
    },
    {
      "epoch": 5.331179321486268,
      "grad_norm": 1.328739881515503,
      "learning_rate": 9.337641357027464e-06,
      "loss": 0.0144,
      "step": 9900
    },
    {
      "epoch": 5.336564351103931,
      "grad_norm": 0.04532410204410553,
      "learning_rate": 9.326871297792138e-06,
      "loss": 0.007,
      "step": 9910
    },
    {
      "epoch": 5.341949380721594,
      "grad_norm": 3.1609342098236084,
      "learning_rate": 9.316101238556812e-06,
      "loss": 0.0182,
      "step": 9920
    },
    {
      "epoch": 5.347334410339257,
      "grad_norm": 0.0012636573519557714,
      "learning_rate": 9.305331179321486e-06,
      "loss": 0.0313,
      "step": 9930
    },
    {
      "epoch": 5.352719439956919,
      "grad_norm": 1.9346708059310913,
      "learning_rate": 9.29456112008616e-06,
      "loss": 0.0474,
      "step": 9940
    },
    {
      "epoch": 5.358104469574583,
      "grad_norm": 0.004881629720330238,
      "learning_rate": 9.283791060850835e-06,
      "loss": 0.0709,
      "step": 9950
    },
    {
      "epoch": 5.363489499192245,
      "grad_norm": 0.0039058332331478596,
      "learning_rate": 9.27302100161551e-06,
      "loss": 0.0096,
      "step": 9960
    },
    {
      "epoch": 5.368874528809909,
      "grad_norm": 2.2998476028442383,
      "learning_rate": 9.262250942380184e-06,
      "loss": 0.0157,
      "step": 9970
    },
    {
      "epoch": 5.374259558427571,
      "grad_norm": 0.009373611770570278,
      "learning_rate": 9.251480883144858e-06,
      "loss": 0.0181,
      "step": 9980
    },
    {
      "epoch": 5.379644588045235,
      "grad_norm": 0.05084752291440964,
      "learning_rate": 9.240710823909532e-06,
      "loss": 0.0157,
      "step": 9990
    },
    {
      "epoch": 5.385029617662897,
      "grad_norm": 0.005832823924720287,
      "learning_rate": 9.229940764674206e-06,
      "loss": 0.0201,
      "step": 10000
    },
    {
      "epoch": 5.39041464728056,
      "grad_norm": 0.00783520843833685,
      "learning_rate": 9.21917070543888e-06,
      "loss": 0.0052,
      "step": 10010
    },
    {
      "epoch": 5.395799676898223,
      "grad_norm": 0.005214318633079529,
      "learning_rate": 9.208400646203555e-06,
      "loss": 0.0102,
      "step": 10020
    },
    {
      "epoch": 5.401184706515886,
      "grad_norm": 2.0538339614868164,
      "learning_rate": 9.197630586968229e-06,
      "loss": 0.0449,
      "step": 10030
    },
    {
      "epoch": 5.406569736133549,
      "grad_norm": 2.930518388748169,
      "learning_rate": 9.186860527732904e-06,
      "loss": 0.0137,
      "step": 10040
    },
    {
      "epoch": 5.4119547657512115,
      "grad_norm": 5.049823760986328,
      "learning_rate": 9.176090468497577e-06,
      "loss": 0.0453,
      "step": 10050
    },
    {
      "epoch": 5.417339795368875,
      "grad_norm": 0.0351373553276062,
      "learning_rate": 9.165320409262252e-06,
      "loss": 0.0138,
      "step": 10060
    },
    {
      "epoch": 5.422724824986537,
      "grad_norm": 0.03705649450421333,
      "learning_rate": 9.154550350026926e-06,
      "loss": 0.0071,
      "step": 10070
    },
    {
      "epoch": 5.4281098546042,
      "grad_norm": 0.01642811857163906,
      "learning_rate": 9.143780290791599e-06,
      "loss": 0.0623,
      "step": 10080
    },
    {
      "epoch": 5.433494884221863,
      "grad_norm": 0.3957216739654541,
      "learning_rate": 9.133010231556274e-06,
      "loss": 0.0299,
      "step": 10090
    },
    {
      "epoch": 5.438879913839526,
      "grad_norm": 0.004463644698262215,
      "learning_rate": 9.122240172320949e-06,
      "loss": 0.0052,
      "step": 10100
    },
    {
      "epoch": 5.444264943457189,
      "grad_norm": 1.4799734354019165,
      "learning_rate": 9.111470113085623e-06,
      "loss": 0.0282,
      "step": 10110
    },
    {
      "epoch": 5.449649973074852,
      "grad_norm": 0.06919874250888824,
      "learning_rate": 9.100700053850297e-06,
      "loss": 0.0288,
      "step": 10120
    },
    {
      "epoch": 5.455035002692515,
      "grad_norm": 0.028533296659588814,
      "learning_rate": 9.08992999461497e-06,
      "loss": 0.0198,
      "step": 10130
    },
    {
      "epoch": 5.460420032310178,
      "grad_norm": 3.3539888858795166,
      "learning_rate": 9.079159935379646e-06,
      "loss": 0.0308,
      "step": 10140
    },
    {
      "epoch": 5.46580506192784,
      "grad_norm": 2.2098143100738525,
      "learning_rate": 9.068389876144319e-06,
      "loss": 0.0161,
      "step": 10150
    },
    {
      "epoch": 5.471190091545504,
      "grad_norm": 0.9247177243232727,
      "learning_rate": 9.057619816908993e-06,
      "loss": 0.0115,
      "step": 10160
    },
    {
      "epoch": 5.476575121163166,
      "grad_norm": 1.850825309753418,
      "learning_rate": 9.046849757673668e-06,
      "loss": 0.0074,
      "step": 10170
    },
    {
      "epoch": 5.4819601507808295,
      "grad_norm": 5.549841403961182,
      "learning_rate": 9.036079698438343e-06,
      "loss": 0.0748,
      "step": 10180
    },
    {
      "epoch": 5.487345180398492,
      "grad_norm": 0.010884607210755348,
      "learning_rate": 9.025309639203017e-06,
      "loss": 0.0129,
      "step": 10190
    },
    {
      "epoch": 5.4927302100161555,
      "grad_norm": 1.4124133586883545,
      "learning_rate": 9.01453957996769e-06,
      "loss": 0.0195,
      "step": 10200
    },
    {
      "epoch": 5.498115239633818,
      "grad_norm": 3.687830686569214,
      "learning_rate": 9.003769520732365e-06,
      "loss": 0.0182,
      "step": 10210
    },
    {
      "epoch": 5.5035002692514805,
      "grad_norm": 4.10643196105957,
      "learning_rate": 8.992999461497039e-06,
      "loss": 0.0219,
      "step": 10220
    },
    {
      "epoch": 5.508885298869144,
      "grad_norm": 0.04087440297007561,
      "learning_rate": 8.982229402261713e-06,
      "loss": 0.0142,
      "step": 10230
    },
    {
      "epoch": 5.514270328486806,
      "grad_norm": 0.007520928513258696,
      "learning_rate": 8.971459343026387e-06,
      "loss": 0.0245,
      "step": 10240
    },
    {
      "epoch": 5.51965535810447,
      "grad_norm": 0.5001220703125,
      "learning_rate": 8.960689283791063e-06,
      "loss": 0.0147,
      "step": 10250
    },
    {
      "epoch": 5.525040387722132,
      "grad_norm": 0.022208858281373978,
      "learning_rate": 8.949919224555735e-06,
      "loss": 0.0125,
      "step": 10260
    },
    {
      "epoch": 5.530425417339796,
      "grad_norm": 0.09213246405124664,
      "learning_rate": 8.93914916532041e-06,
      "loss": 0.0296,
      "step": 10270
    },
    {
      "epoch": 5.535810446957458,
      "grad_norm": 0.002902250736951828,
      "learning_rate": 8.928379106085085e-06,
      "loss": 0.0119,
      "step": 10280
    },
    {
      "epoch": 5.541195476575121,
      "grad_norm": 1.4450623989105225,
      "learning_rate": 8.917609046849759e-06,
      "loss": 0.0106,
      "step": 10290
    },
    {
      "epoch": 5.546580506192784,
      "grad_norm": 1.0427528619766235,
      "learning_rate": 8.906838987614433e-06,
      "loss": 0.0219,
      "step": 10300
    },
    {
      "epoch": 5.551965535810447,
      "grad_norm": 2.3232860565185547,
      "learning_rate": 8.896068928379107e-06,
      "loss": 0.0354,
      "step": 10310
    },
    {
      "epoch": 5.55735056542811,
      "grad_norm": 0.9447552561759949,
      "learning_rate": 8.88529886914378e-06,
      "loss": 0.0011,
      "step": 10320
    },
    {
      "epoch": 5.562735595045773,
      "grad_norm": 1.3070104122161865,
      "learning_rate": 8.874528809908455e-06,
      "loss": 0.0091,
      "step": 10330
    },
    {
      "epoch": 5.568120624663436,
      "grad_norm": 0.37254536151885986,
      "learning_rate": 8.863758750673129e-06,
      "loss": 0.0166,
      "step": 10340
    },
    {
      "epoch": 5.573505654281099,
      "grad_norm": 0.003916011191904545,
      "learning_rate": 8.852988691437805e-06,
      "loss": 0.0157,
      "step": 10350
    },
    {
      "epoch": 5.578890683898761,
      "grad_norm": 2.2618229389190674,
      "learning_rate": 8.842218632202479e-06,
      "loss": 0.0131,
      "step": 10360
    },
    {
      "epoch": 5.5842757135164245,
      "grad_norm": 0.5108580589294434,
      "learning_rate": 8.831448572967151e-06,
      "loss": 0.0082,
      "step": 10370
    },
    {
      "epoch": 5.589660743134087,
      "grad_norm": 0.0023983833380043507,
      "learning_rate": 8.820678513731827e-06,
      "loss": 0.0185,
      "step": 10380
    },
    {
      "epoch": 5.59504577275175,
      "grad_norm": 0.0825996845960617,
      "learning_rate": 8.8099084544965e-06,
      "loss": 0.0036,
      "step": 10390
    },
    {
      "epoch": 5.600430802369413,
      "grad_norm": 0.40615010261535645,
      "learning_rate": 8.799138395261175e-06,
      "loss": 0.0387,
      "step": 10400
    },
    {
      "epoch": 5.605815831987076,
      "grad_norm": 1.823205590248108,
      "learning_rate": 8.788368336025849e-06,
      "loss": 0.0244,
      "step": 10410
    },
    {
      "epoch": 5.611200861604739,
      "grad_norm": 0.7840537428855896,
      "learning_rate": 8.777598276790523e-06,
      "loss": 0.0057,
      "step": 10420
    },
    {
      "epoch": 5.616585891222401,
      "grad_norm": 0.002692112233489752,
      "learning_rate": 8.766828217555199e-06,
      "loss": 0.0083,
      "step": 10430
    },
    {
      "epoch": 5.621970920840065,
      "grad_norm": 0.007361350581049919,
      "learning_rate": 8.756058158319871e-06,
      "loss": 0.0043,
      "step": 10440
    },
    {
      "epoch": 5.627355950457727,
      "grad_norm": 0.131233811378479,
      "learning_rate": 8.745288099084545e-06,
      "loss": 0.0041,
      "step": 10450
    },
    {
      "epoch": 5.632740980075391,
      "grad_norm": 0.0010733219096437097,
      "learning_rate": 8.73451803984922e-06,
      "loss": 0.0137,
      "step": 10460
    },
    {
      "epoch": 5.638126009693053,
      "grad_norm": 2.6965692043304443,
      "learning_rate": 8.723747980613893e-06,
      "loss": 0.0227,
      "step": 10470
    },
    {
      "epoch": 5.643511039310717,
      "grad_norm": 0.0011990165803581476,
      "learning_rate": 8.712977921378569e-06,
      "loss": 0.005,
      "step": 10480
    },
    {
      "epoch": 5.648896068928379,
      "grad_norm": 0.0074239145033061504,
      "learning_rate": 8.702207862143243e-06,
      "loss": 0.0216,
      "step": 10490
    },
    {
      "epoch": 5.654281098546042,
      "grad_norm": 0.0033596318680793047,
      "learning_rate": 8.691437802907917e-06,
      "loss": 0.0157,
      "step": 10500
    },
    {
      "epoch": 5.659666128163705,
      "grad_norm": 0.0031309558544307947,
      "learning_rate": 8.680667743672591e-06,
      "loss": 0.0001,
      "step": 10510
    },
    {
      "epoch": 5.665051157781368,
      "grad_norm": 4.181332111358643,
      "learning_rate": 8.669897684437265e-06,
      "loss": 0.0438,
      "step": 10520
    },
    {
      "epoch": 5.670436187399031,
      "grad_norm": 0.0014384003588929772,
      "learning_rate": 8.659127625201939e-06,
      "loss": 0.0093,
      "step": 10530
    },
    {
      "epoch": 5.6758212170166935,
      "grad_norm": 0.00463886559009552,
      "learning_rate": 8.648357565966613e-06,
      "loss": 0.0034,
      "step": 10540
    },
    {
      "epoch": 5.681206246634357,
      "grad_norm": 1.585788607597351,
      "learning_rate": 8.637587506731287e-06,
      "loss": 0.0138,
      "step": 10550
    },
    {
      "epoch": 5.686591276252019,
      "grad_norm": 0.7575026750564575,
      "learning_rate": 8.626817447495963e-06,
      "loss": 0.0639,
      "step": 10560
    },
    {
      "epoch": 5.691976305869682,
      "grad_norm": 0.00238149706274271,
      "learning_rate": 8.616047388260637e-06,
      "loss": 0.0035,
      "step": 10570
    },
    {
      "epoch": 5.697361335487345,
      "grad_norm": 0.05024247244000435,
      "learning_rate": 8.60527732902531e-06,
      "loss": 0.0534,
      "step": 10580
    },
    {
      "epoch": 5.702746365105008,
      "grad_norm": 0.023246560245752335,
      "learning_rate": 8.594507269789985e-06,
      "loss": 0.0181,
      "step": 10590
    },
    {
      "epoch": 5.708131394722671,
      "grad_norm": 0.0974549725651741,
      "learning_rate": 8.583737210554659e-06,
      "loss": 0.017,
      "step": 10600
    },
    {
      "epoch": 5.713516424340334,
      "grad_norm": 0.0023938454687595367,
      "learning_rate": 8.572967151319333e-06,
      "loss": 0.0208,
      "step": 10610
    },
    {
      "epoch": 5.718901453957997,
      "grad_norm": 0.40866324305534363,
      "learning_rate": 8.562197092084007e-06,
      "loss": 0.0365,
      "step": 10620
    },
    {
      "epoch": 5.72428648357566,
      "grad_norm": 0.3213367462158203,
      "learning_rate": 8.551427032848681e-06,
      "loss": 0.0256,
      "step": 10630
    },
    {
      "epoch": 5.729671513193322,
      "grad_norm": 0.0036915040109306574,
      "learning_rate": 8.540656973613357e-06,
      "loss": 0.0146,
      "step": 10640
    },
    {
      "epoch": 5.735056542810986,
      "grad_norm": 0.3319568932056427,
      "learning_rate": 8.529886914378029e-06,
      "loss": 0.0011,
      "step": 10650
    },
    {
      "epoch": 5.740441572428648,
      "grad_norm": 1.3613547086715698,
      "learning_rate": 8.519116855142703e-06,
      "loss": 0.0156,
      "step": 10660
    },
    {
      "epoch": 5.745826602046312,
      "grad_norm": 0.17065797746181488,
      "learning_rate": 8.508346795907379e-06,
      "loss": 0.0296,
      "step": 10670
    },
    {
      "epoch": 5.751211631663974,
      "grad_norm": 0.00458296574652195,
      "learning_rate": 8.497576736672051e-06,
      "loss": 0.0185,
      "step": 10680
    },
    {
      "epoch": 5.7565966612816375,
      "grad_norm": 2.927628993988037,
      "learning_rate": 8.486806677436727e-06,
      "loss": 0.0461,
      "step": 10690
    },
    {
      "epoch": 5.7619816908993,
      "grad_norm": 0.005255031865090132,
      "learning_rate": 8.476036618201401e-06,
      "loss": 0.0299,
      "step": 10700
    },
    {
      "epoch": 5.7673667205169625,
      "grad_norm": 0.019051196053624153,
      "learning_rate": 8.465266558966075e-06,
      "loss": 0.0496,
      "step": 10710
    },
    {
      "epoch": 5.772751750134626,
      "grad_norm": 1.279808521270752,
      "learning_rate": 8.454496499730749e-06,
      "loss": 0.0253,
      "step": 10720
    },
    {
      "epoch": 5.7781367797522885,
      "grad_norm": 1.9710267782211304,
      "learning_rate": 8.443726440495423e-06,
      "loss": 0.0128,
      "step": 10730
    },
    {
      "epoch": 5.783521809369952,
      "grad_norm": 0.5988480448722839,
      "learning_rate": 8.432956381260097e-06,
      "loss": 0.0222,
      "step": 10740
    },
    {
      "epoch": 5.788906838987614,
      "grad_norm": 2.3266022205352783,
      "learning_rate": 8.422186322024773e-06,
      "loss": 0.0259,
      "step": 10750
    },
    {
      "epoch": 5.794291868605278,
      "grad_norm": 2.5785536766052246,
      "learning_rate": 8.411416262789445e-06,
      "loss": 0.0525,
      "step": 10760
    },
    {
      "epoch": 5.79967689822294,
      "grad_norm": 0.13754042983055115,
      "learning_rate": 8.400646203554121e-06,
      "loss": 0.0103,
      "step": 10770
    },
    {
      "epoch": 5.805061927840603,
      "grad_norm": 4.148038864135742,
      "learning_rate": 8.389876144318795e-06,
      "loss": 0.0528,
      "step": 10780
    },
    {
      "epoch": 5.810446957458266,
      "grad_norm": 0.8681252002716064,
      "learning_rate": 8.379106085083469e-06,
      "loss": 0.0334,
      "step": 10790
    },
    {
      "epoch": 5.815831987075929,
      "grad_norm": 0.031147001311182976,
      "learning_rate": 8.368336025848143e-06,
      "loss": 0.0121,
      "step": 10800
    },
    {
      "epoch": 5.821217016693592,
      "grad_norm": 0.0015505036571994424,
      "learning_rate": 8.357565966612817e-06,
      "loss": 0.023,
      "step": 10810
    },
    {
      "epoch": 5.826602046311255,
      "grad_norm": 0.9840591549873352,
      "learning_rate": 8.346795907377491e-06,
      "loss": 0.0156,
      "step": 10820
    },
    {
      "epoch": 5.831987075928918,
      "grad_norm": 7.215296745300293,
      "learning_rate": 8.336025848142165e-06,
      "loss": 0.0237,
      "step": 10830
    },
    {
      "epoch": 5.837372105546581,
      "grad_norm": 0.018100980669260025,
      "learning_rate": 8.32525578890684e-06,
      "loss": 0.0269,
      "step": 10840
    },
    {
      "epoch": 5.842757135164243,
      "grad_norm": 0.007954525761306286,
      "learning_rate": 8.314485729671515e-06,
      "loss": 0.0259,
      "step": 10850
    },
    {
      "epoch": 5.8481421647819065,
      "grad_norm": 1.1844524145126343,
      "learning_rate": 8.303715670436187e-06,
      "loss": 0.0154,
      "step": 10860
    },
    {
      "epoch": 5.853527194399569,
      "grad_norm": 0.002608496928587556,
      "learning_rate": 8.292945611200861e-06,
      "loss": 0.0152,
      "step": 10870
    },
    {
      "epoch": 5.858912224017232,
      "grad_norm": 0.27183422446250916,
      "learning_rate": 8.282175551965537e-06,
      "loss": 0.0153,
      "step": 10880
    },
    {
      "epoch": 5.864297253634895,
      "grad_norm": 1.3626154661178589,
      "learning_rate": 8.271405492730211e-06,
      "loss": 0.0072,
      "step": 10890
    },
    {
      "epoch": 5.869682283252558,
      "grad_norm": 0.0009945218916982412,
      "learning_rate": 8.260635433494885e-06,
      "loss": 0.0102,
      "step": 10900
    },
    {
      "epoch": 5.875067312870221,
      "grad_norm": 0.23932209610939026,
      "learning_rate": 8.24986537425956e-06,
      "loss": 0.0258,
      "step": 10910
    },
    {
      "epoch": 5.880452342487883,
      "grad_norm": 9.8719482421875,
      "learning_rate": 8.239095315024233e-06,
      "loss": 0.0131,
      "step": 10920
    },
    {
      "epoch": 5.885837372105547,
      "grad_norm": 0.00596378231421113,
      "learning_rate": 8.228325255788907e-06,
      "loss": 0.0185,
      "step": 10930
    },
    {
      "epoch": 5.891222401723209,
      "grad_norm": 0.014856947585940361,
      "learning_rate": 8.217555196553581e-06,
      "loss": 0.047,
      "step": 10940
    },
    {
      "epoch": 5.896607431340873,
      "grad_norm": 0.006821584887802601,
      "learning_rate": 8.206785137318255e-06,
      "loss": 0.0051,
      "step": 10950
    },
    {
      "epoch": 5.901992460958535,
      "grad_norm": 1.979598045349121,
      "learning_rate": 8.196015078082931e-06,
      "loss": 0.018,
      "step": 10960
    },
    {
      "epoch": 5.907377490576199,
      "grad_norm": 1.795578122138977,
      "learning_rate": 8.185245018847603e-06,
      "loss": 0.0317,
      "step": 10970
    },
    {
      "epoch": 5.912762520193861,
      "grad_norm": 0.010915471240878105,
      "learning_rate": 8.17447495961228e-06,
      "loss": 0.0012,
      "step": 10980
    },
    {
      "epoch": 5.918147549811524,
      "grad_norm": 1.11454439163208,
      "learning_rate": 8.163704900376953e-06,
      "loss": 0.0101,
      "step": 10990
    },
    {
      "epoch": 5.923532579429187,
      "grad_norm": 0.006553133483976126,
      "learning_rate": 8.152934841141627e-06,
      "loss": 0.0695,
      "step": 11000
    },
    {
      "epoch": 5.92891760904685,
      "grad_norm": 0.9756119251251221,
      "learning_rate": 8.142164781906301e-06,
      "loss": 0.0114,
      "step": 11010
    },
    {
      "epoch": 5.934302638664513,
      "grad_norm": 0.009962238371372223,
      "learning_rate": 8.131394722670975e-06,
      "loss": 0.0098,
      "step": 11020
    },
    {
      "epoch": 5.9396876682821755,
      "grad_norm": 2.66458797454834,
      "learning_rate": 8.12062466343565e-06,
      "loss": 0.0185,
      "step": 11030
    },
    {
      "epoch": 5.945072697899839,
      "grad_norm": 4.530253887176514,
      "learning_rate": 8.109854604200323e-06,
      "loss": 0.0204,
      "step": 11040
    },
    {
      "epoch": 5.9504577275175015,
      "grad_norm": 0.018200045451521873,
      "learning_rate": 8.099084544964997e-06,
      "loss": 0.0269,
      "step": 11050
    },
    {
      "epoch": 5.955842757135164,
      "grad_norm": 0.05682026967406273,
      "learning_rate": 8.088314485729673e-06,
      "loss": 0.0464,
      "step": 11060
    },
    {
      "epoch": 5.961227786752827,
      "grad_norm": 3.846208095550537,
      "learning_rate": 8.077544426494346e-06,
      "loss": 0.0407,
      "step": 11070
    },
    {
      "epoch": 5.96661281637049,
      "grad_norm": 0.008263414725661278,
      "learning_rate": 8.06677436725902e-06,
      "loss": 0.0157,
      "step": 11080
    },
    {
      "epoch": 5.971997845988153,
      "grad_norm": 0.1385127156972885,
      "learning_rate": 8.056004308023695e-06,
      "loss": 0.045,
      "step": 11090
    },
    {
      "epoch": 5.977382875605816,
      "grad_norm": 0.578924834728241,
      "learning_rate": 8.04523424878837e-06,
      "loss": 0.0137,
      "step": 11100
    },
    {
      "epoch": 5.982767905223478,
      "grad_norm": 0.037124089896678925,
      "learning_rate": 8.034464189553043e-06,
      "loss": 0.0177,
      "step": 11110
    },
    {
      "epoch": 5.988152934841142,
      "grad_norm": 0.047970980405807495,
      "learning_rate": 8.023694130317717e-06,
      "loss": 0.0191,
      "step": 11120
    },
    {
      "epoch": 5.993537964458804,
      "grad_norm": 0.014733321033418179,
      "learning_rate": 8.012924071082391e-06,
      "loss": 0.0116,
      "step": 11130
    },
    {
      "epoch": 5.998922994076468,
      "grad_norm": 0.09159104526042938,
      "learning_rate": 8.002154011847066e-06,
      "loss": 0.0239,
      "step": 11140
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9868090452261307,
      "eval_f1": 0.9508196721311475,
      "eval_loss": 0.05134778097271919,
      "eval_precision": 0.9689737470167065,
      "eval_recall": 0.9333333333333333,
      "eval_runtime": 299.9616,
      "eval_samples_per_second": 42.472,
      "eval_steps_per_second": 1.33,
      "step": 11142
    }
  ],
  "logging_steps": 10,
  "max_steps": 18570,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.133291755813888e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
