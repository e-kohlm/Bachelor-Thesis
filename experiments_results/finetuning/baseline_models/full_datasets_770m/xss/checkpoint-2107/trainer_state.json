{
  "best_metric": 0.9644533869885983,
  "best_model_checkpoint": "../saved_models/xss/checkpoint-2107",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 2107,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0033222591362126247,
      "grad_norm": 28.194189071655273,
      "learning_rate": 1.9993355481727577e-05,
      "loss": 1.108,
      "step": 1
    },
    {
      "epoch": 0.03322259136212625,
      "grad_norm": 7.338431358337402,
      "learning_rate": 1.9933554817275747e-05,
      "loss": 0.3965,
      "step": 10
    },
    {
      "epoch": 0.0664451827242525,
      "grad_norm": 7.537578105926514,
      "learning_rate": 1.9867109634551496e-05,
      "loss": 0.2991,
      "step": 20
    },
    {
      "epoch": 0.09966777408637874,
      "grad_norm": 10.088692665100098,
      "learning_rate": 1.9800664451827245e-05,
      "loss": 0.3108,
      "step": 30
    },
    {
      "epoch": 0.132890365448505,
      "grad_norm": 11.262338638305664,
      "learning_rate": 1.973421926910299e-05,
      "loss": 0.2858,
      "step": 40
    },
    {
      "epoch": 0.16611295681063123,
      "grad_norm": 6.998692989349365,
      "learning_rate": 1.966777408637874e-05,
      "loss": 0.2593,
      "step": 50
    },
    {
      "epoch": 0.19933554817275748,
      "grad_norm": 9.076861381530762,
      "learning_rate": 1.9601328903654486e-05,
      "loss": 0.2484,
      "step": 60
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 6.11497163772583,
      "learning_rate": 1.9534883720930235e-05,
      "loss": 0.2346,
      "step": 70
    },
    {
      "epoch": 0.26578073089701,
      "grad_norm": 7.664600849151611,
      "learning_rate": 1.9468438538205984e-05,
      "loss": 0.2024,
      "step": 80
    },
    {
      "epoch": 0.29900332225913623,
      "grad_norm": 7.059135913848877,
      "learning_rate": 1.940199335548173e-05,
      "loss": 0.203,
      "step": 90
    },
    {
      "epoch": 0.33222591362126247,
      "grad_norm": 6.039015769958496,
      "learning_rate": 1.933554817275748e-05,
      "loss": 0.1688,
      "step": 100
    },
    {
      "epoch": 0.3654485049833887,
      "grad_norm": 5.6140360832214355,
      "learning_rate": 1.9269102990033224e-05,
      "loss": 0.185,
      "step": 110
    },
    {
      "epoch": 0.39867109634551495,
      "grad_norm": 7.739616870880127,
      "learning_rate": 1.920265780730897e-05,
      "loss": 0.171,
      "step": 120
    },
    {
      "epoch": 0.4318936877076412,
      "grad_norm": 6.99114990234375,
      "learning_rate": 1.913621262458472e-05,
      "loss": 0.1809,
      "step": 130
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 8.185439109802246,
      "learning_rate": 1.9069767441860468e-05,
      "loss": 0.1701,
      "step": 140
    },
    {
      "epoch": 0.4983388704318937,
      "grad_norm": 3.617539644241333,
      "learning_rate": 1.9003322259136213e-05,
      "loss": 0.1427,
      "step": 150
    },
    {
      "epoch": 0.53156146179402,
      "grad_norm": 5.3530659675598145,
      "learning_rate": 1.8936877076411962e-05,
      "loss": 0.1332,
      "step": 160
    },
    {
      "epoch": 0.5647840531561462,
      "grad_norm": 4.289691925048828,
      "learning_rate": 1.8870431893687708e-05,
      "loss": 0.0998,
      "step": 170
    },
    {
      "epoch": 0.5980066445182725,
      "grad_norm": 5.025557041168213,
      "learning_rate": 1.8803986710963457e-05,
      "loss": 0.1263,
      "step": 180
    },
    {
      "epoch": 0.6312292358803987,
      "grad_norm": 5.528994083404541,
      "learning_rate": 1.8737541528239206e-05,
      "loss": 0.1207,
      "step": 190
    },
    {
      "epoch": 0.6644518272425249,
      "grad_norm": 5.495169162750244,
      "learning_rate": 1.867109634551495e-05,
      "loss": 0.1281,
      "step": 200
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 4.4545111656188965,
      "learning_rate": 1.86046511627907e-05,
      "loss": 0.1007,
      "step": 210
    },
    {
      "epoch": 0.7308970099667774,
      "grad_norm": 3.6531903743743896,
      "learning_rate": 1.8538205980066446e-05,
      "loss": 0.0985,
      "step": 220
    },
    {
      "epoch": 0.7641196013289037,
      "grad_norm": 2.697596788406372,
      "learning_rate": 1.8471760797342195e-05,
      "loss": 0.1155,
      "step": 230
    },
    {
      "epoch": 0.7973421926910299,
      "grad_norm": 2.1450424194335938,
      "learning_rate": 1.840531561461794e-05,
      "loss": 0.087,
      "step": 240
    },
    {
      "epoch": 0.8305647840531561,
      "grad_norm": 3.4826812744140625,
      "learning_rate": 1.833887043189369e-05,
      "loss": 0.0876,
      "step": 250
    },
    {
      "epoch": 0.8637873754152824,
      "grad_norm": 3.668987512588501,
      "learning_rate": 1.8272425249169436e-05,
      "loss": 0.0846,
      "step": 260
    },
    {
      "epoch": 0.8970099667774086,
      "grad_norm": 3.3107943534851074,
      "learning_rate": 1.8205980066445185e-05,
      "loss": 0.0916,
      "step": 270
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 5.2978644371032715,
      "learning_rate": 1.813953488372093e-05,
      "loss": 0.0672,
      "step": 280
    },
    {
      "epoch": 0.9634551495016611,
      "grad_norm": 4.965124607086182,
      "learning_rate": 1.807308970099668e-05,
      "loss": 0.0587,
      "step": 290
    },
    {
      "epoch": 0.9966777408637874,
      "grad_norm": 2.773890733718872,
      "learning_rate": 1.8006644518272428e-05,
      "loss": 0.0715,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9797722868217055,
      "eval_f1": 0.8829712683952349,
      "eval_loss": 0.059261567890644073,
      "eval_precision": 0.9375,
      "eval_recall": 0.8344370860927153,
      "eval_runtime": 144.8146,
      "eval_samples_per_second": 57.156,
      "eval_steps_per_second": 1.788,
      "step": 301
    },
    {
      "epoch": 1.0299003322259137,
      "grad_norm": 3.0501465797424316,
      "learning_rate": 1.7940199335548174e-05,
      "loss": 0.0543,
      "step": 310
    },
    {
      "epoch": 1.06312292358804,
      "grad_norm": 1.9099361896514893,
      "learning_rate": 1.787375415282392e-05,
      "loss": 0.0445,
      "step": 320
    },
    {
      "epoch": 1.0963455149501662,
      "grad_norm": 1.6978299617767334,
      "learning_rate": 1.780730897009967e-05,
      "loss": 0.0619,
      "step": 330
    },
    {
      "epoch": 1.1295681063122924,
      "grad_norm": 3.581249952316284,
      "learning_rate": 1.7740863787375418e-05,
      "loss": 0.0593,
      "step": 340
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 3.4123122692108154,
      "learning_rate": 1.7674418604651163e-05,
      "loss": 0.0395,
      "step": 350
    },
    {
      "epoch": 1.196013289036545,
      "grad_norm": 3.2203402519226074,
      "learning_rate": 1.7607973421926912e-05,
      "loss": 0.0464,
      "step": 360
    },
    {
      "epoch": 1.2292358803986712,
      "grad_norm": 2.3749191761016846,
      "learning_rate": 1.7541528239202658e-05,
      "loss": 0.0766,
      "step": 370
    },
    {
      "epoch": 1.2624584717607974,
      "grad_norm": 2.1678075790405273,
      "learning_rate": 1.7475083056478407e-05,
      "loss": 0.0522,
      "step": 380
    },
    {
      "epoch": 1.2956810631229236,
      "grad_norm": 1.8820973634719849,
      "learning_rate": 1.7408637873754156e-05,
      "loss": 0.0469,
      "step": 390
    },
    {
      "epoch": 1.3289036544850499,
      "grad_norm": 2.957566976547241,
      "learning_rate": 1.73421926910299e-05,
      "loss": 0.0566,
      "step": 400
    },
    {
      "epoch": 1.3621262458471761,
      "grad_norm": 2.890958070755005,
      "learning_rate": 1.727574750830565e-05,
      "loss": 0.038,
      "step": 410
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 5.704248428344727,
      "learning_rate": 1.7209302325581396e-05,
      "loss": 0.0546,
      "step": 420
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 2.464630126953125,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.0476,
      "step": 430
    },
    {
      "epoch": 1.4617940199335548,
      "grad_norm": 2.0950515270233154,
      "learning_rate": 1.7076411960132894e-05,
      "loss": 0.0383,
      "step": 440
    },
    {
      "epoch": 1.495016611295681,
      "grad_norm": 2.011876106262207,
      "learning_rate": 1.700996677740864e-05,
      "loss": 0.0596,
      "step": 450
    },
    {
      "epoch": 1.5282392026578073,
      "grad_norm": 2.605165719985962,
      "learning_rate": 1.6943521594684386e-05,
      "loss": 0.0503,
      "step": 460
    },
    {
      "epoch": 1.5614617940199336,
      "grad_norm": 1.563575267791748,
      "learning_rate": 1.6877076411960135e-05,
      "loss": 0.0497,
      "step": 470
    },
    {
      "epoch": 1.5946843853820598,
      "grad_norm": 1.6337060928344727,
      "learning_rate": 1.681063122923588e-05,
      "loss": 0.0325,
      "step": 480
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 1.8794381618499756,
      "learning_rate": 1.674418604651163e-05,
      "loss": 0.0207,
      "step": 490
    },
    {
      "epoch": 1.6611295681063123,
      "grad_norm": 3.7774930000305176,
      "learning_rate": 1.6677740863787378e-05,
      "loss": 0.0388,
      "step": 500
    },
    {
      "epoch": 1.6943521594684385,
      "grad_norm": 3.1544787883758545,
      "learning_rate": 1.6611295681063124e-05,
      "loss": 0.0936,
      "step": 510
    },
    {
      "epoch": 1.7275747508305648,
      "grad_norm": 3.5772178173065186,
      "learning_rate": 1.6544850498338873e-05,
      "loss": 0.0553,
      "step": 520
    },
    {
      "epoch": 1.760797342192691,
      "grad_norm": 1.3178421258926392,
      "learning_rate": 1.647840531561462e-05,
      "loss": 0.0403,
      "step": 530
    },
    {
      "epoch": 1.7940199335548173,
      "grad_norm": 5.218415260314941,
      "learning_rate": 1.6411960132890368e-05,
      "loss": 0.0356,
      "step": 540
    },
    {
      "epoch": 1.8272425249169435,
      "grad_norm": 2.3087732791900635,
      "learning_rate": 1.6345514950166113e-05,
      "loss": 0.0205,
      "step": 550
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 2.7871711254119873,
      "learning_rate": 1.6279069767441862e-05,
      "loss": 0.0535,
      "step": 560
    },
    {
      "epoch": 1.893687707641196,
      "grad_norm": 1.8825749158859253,
      "learning_rate": 1.6212624584717608e-05,
      "loss": 0.0242,
      "step": 570
    },
    {
      "epoch": 1.9269102990033222,
      "grad_norm": 0.2588242292404175,
      "learning_rate": 1.6146179401993357e-05,
      "loss": 0.0335,
      "step": 580
    },
    {
      "epoch": 1.9601328903654485,
      "grad_norm": 4.408539772033691,
      "learning_rate": 1.6079734219269106e-05,
      "loss": 0.0354,
      "step": 590
    },
    {
      "epoch": 1.9933554817275747,
      "grad_norm": 1.6282302141189575,
      "learning_rate": 1.601328903654485e-05,
      "loss": 0.0405,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9889777131782945,
      "eval_f1": 0.9380530973451329,
      "eval_loss": 0.033295270055532455,
      "eval_precision": 0.9649859943977591,
      "eval_recall": 0.9125827814569536,
      "eval_runtime": 144.6368,
      "eval_samples_per_second": 57.226,
      "eval_steps_per_second": 1.791,
      "step": 602
    },
    {
      "epoch": 2.026578073089701,
      "grad_norm": 2.3299829959869385,
      "learning_rate": 1.59468438538206e-05,
      "loss": 0.0326,
      "step": 610
    },
    {
      "epoch": 2.0598006644518274,
      "grad_norm": 2.2384166717529297,
      "learning_rate": 1.5880398671096346e-05,
      "loss": 0.0272,
      "step": 620
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 0.11172927916049957,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 0.0094,
      "step": 630
    },
    {
      "epoch": 2.12624584717608,
      "grad_norm": 0.41750863194465637,
      "learning_rate": 1.5747508305647844e-05,
      "loss": 0.0189,
      "step": 640
    },
    {
      "epoch": 2.159468438538206,
      "grad_norm": 3.081918954849243,
      "learning_rate": 1.568106312292359e-05,
      "loss": 0.0384,
      "step": 650
    },
    {
      "epoch": 2.1926910299003324,
      "grad_norm": 1.9112974405288696,
      "learning_rate": 1.5614617940199335e-05,
      "loss": 0.0237,
      "step": 660
    },
    {
      "epoch": 2.2259136212624586,
      "grad_norm": 3.1018941402435303,
      "learning_rate": 1.5548172757475084e-05,
      "loss": 0.024,
      "step": 670
    },
    {
      "epoch": 2.259136212624585,
      "grad_norm": 0.19740156829357147,
      "learning_rate": 1.548172757475083e-05,
      "loss": 0.0307,
      "step": 680
    },
    {
      "epoch": 2.292358803986711,
      "grad_norm": 0.37382084131240845,
      "learning_rate": 1.541528239202658e-05,
      "loss": 0.0225,
      "step": 690
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 2.3822271823883057,
      "learning_rate": 1.5348837209302328e-05,
      "loss": 0.0174,
      "step": 700
    },
    {
      "epoch": 2.3588039867109636,
      "grad_norm": 0.2466331124305725,
      "learning_rate": 1.5282392026578074e-05,
      "loss": 0.0319,
      "step": 710
    },
    {
      "epoch": 2.39202657807309,
      "grad_norm": 4.203530788421631,
      "learning_rate": 1.5215946843853821e-05,
      "loss": 0.0208,
      "step": 720
    },
    {
      "epoch": 2.425249169435216,
      "grad_norm": 2.0271027088165283,
      "learning_rate": 1.5149501661129568e-05,
      "loss": 0.0136,
      "step": 730
    },
    {
      "epoch": 2.4584717607973423,
      "grad_norm": 0.18124309182167053,
      "learning_rate": 1.5083056478405317e-05,
      "loss": 0.0194,
      "step": 740
    },
    {
      "epoch": 2.4916943521594686,
      "grad_norm": 3.626380205154419,
      "learning_rate": 1.5016611295681065e-05,
      "loss": 0.0262,
      "step": 750
    },
    {
      "epoch": 2.524916943521595,
      "grad_norm": 0.4580672085285187,
      "learning_rate": 1.4950166112956812e-05,
      "loss": 0.0258,
      "step": 760
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 1.9443567991256714,
      "learning_rate": 1.488372093023256e-05,
      "loss": 0.0251,
      "step": 770
    },
    {
      "epoch": 2.5913621262458473,
      "grad_norm": 0.10285709798336029,
      "learning_rate": 1.4817275747508307e-05,
      "loss": 0.007,
      "step": 780
    },
    {
      "epoch": 2.6245847176079735,
      "grad_norm": 1.0652852058410645,
      "learning_rate": 1.4750830564784054e-05,
      "loss": 0.0194,
      "step": 790
    },
    {
      "epoch": 2.6578073089700998,
      "grad_norm": 1.641539216041565,
      "learning_rate": 1.4684385382059803e-05,
      "loss": 0.0311,
      "step": 800
    },
    {
      "epoch": 2.691029900332226,
      "grad_norm": 1.0118852853775024,
      "learning_rate": 1.461794019933555e-05,
      "loss": 0.0148,
      "step": 810
    },
    {
      "epoch": 2.7242524916943522,
      "grad_norm": 2.082740545272827,
      "learning_rate": 1.4551495016611296e-05,
      "loss": 0.0166,
      "step": 820
    },
    {
      "epoch": 2.7574750830564785,
      "grad_norm": 0.10079199820756912,
      "learning_rate": 1.4485049833887043e-05,
      "loss": 0.0225,
      "step": 830
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 1.0426348447799683,
      "learning_rate": 1.441860465116279e-05,
      "loss": 0.0218,
      "step": 840
    },
    {
      "epoch": 2.823920265780731,
      "grad_norm": 1.0046002864837646,
      "learning_rate": 1.435215946843854e-05,
      "loss": 0.0285,
      "step": 850
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.2935540974140167,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.0233,
      "step": 860
    },
    {
      "epoch": 2.8903654485049834,
      "grad_norm": 2.144737720489502,
      "learning_rate": 1.4219269102990034e-05,
      "loss": 0.0314,
      "step": 870
    },
    {
      "epoch": 2.9235880398671097,
      "grad_norm": 0.27244052290916443,
      "learning_rate": 1.4152823920265782e-05,
      "loss": 0.0176,
      "step": 880
    },
    {
      "epoch": 2.956810631229236,
      "grad_norm": 1.7115349769592285,
      "learning_rate": 1.4086378737541529e-05,
      "loss": 0.0165,
      "step": 890
    },
    {
      "epoch": 2.990033222591362,
      "grad_norm": 0.3195211589336395,
      "learning_rate": 1.4019933554817278e-05,
      "loss": 0.027,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9921269379844961,
      "eval_f1": 0.9565217391304347,
      "eval_loss": 0.026764988899230957,
      "eval_precision": 0.9662162162162162,
      "eval_recall": 0.9470198675496688,
      "eval_runtime": 145.412,
      "eval_samples_per_second": 56.921,
      "eval_steps_per_second": 1.781,
      "step": 903
    },
    {
      "epoch": 3.0232558139534884,
      "grad_norm": 0.07520755380392075,
      "learning_rate": 1.3953488372093025e-05,
      "loss": 0.0086,
      "step": 910
    },
    {
      "epoch": 3.0564784053156147,
      "grad_norm": 1.6126221418380737,
      "learning_rate": 1.3887043189368771e-05,
      "loss": 0.0128,
      "step": 920
    },
    {
      "epoch": 3.089700996677741,
      "grad_norm": 0.12887872755527496,
      "learning_rate": 1.3820598006644518e-05,
      "loss": 0.0183,
      "step": 930
    },
    {
      "epoch": 3.122923588039867,
      "grad_norm": 0.18749715387821198,
      "learning_rate": 1.3754152823920266e-05,
      "loss": 0.0054,
      "step": 940
    },
    {
      "epoch": 3.1561461794019934,
      "grad_norm": 2.1259634494781494,
      "learning_rate": 1.3687707641196015e-05,
      "loss": 0.0309,
      "step": 950
    },
    {
      "epoch": 3.1893687707641196,
      "grad_norm": 0.497620552778244,
      "learning_rate": 1.3621262458471762e-05,
      "loss": 0.0189,
      "step": 960
    },
    {
      "epoch": 3.222591362126246,
      "grad_norm": 1.9357527494430542,
      "learning_rate": 1.355481727574751e-05,
      "loss": 0.0105,
      "step": 970
    },
    {
      "epoch": 3.255813953488372,
      "grad_norm": 1.0569361448287964,
      "learning_rate": 1.3488372093023257e-05,
      "loss": 0.013,
      "step": 980
    },
    {
      "epoch": 3.2890365448504983,
      "grad_norm": 1.8061378002166748,
      "learning_rate": 1.3421926910299004e-05,
      "loss": 0.0315,
      "step": 990
    },
    {
      "epoch": 3.3222591362126246,
      "grad_norm": 2.2347421646118164,
      "learning_rate": 1.3355481727574753e-05,
      "loss": 0.0177,
      "step": 1000
    },
    {
      "epoch": 3.355481727574751,
      "grad_norm": 0.6741374135017395,
      "learning_rate": 1.32890365448505e-05,
      "loss": 0.0129,
      "step": 1010
    },
    {
      "epoch": 3.388704318936877,
      "grad_norm": 1.298497200012207,
      "learning_rate": 1.3222591362126248e-05,
      "loss": 0.0248,
      "step": 1020
    },
    {
      "epoch": 3.4219269102990033,
      "grad_norm": 0.23493343591690063,
      "learning_rate": 1.3156146179401993e-05,
      "loss": 0.0137,
      "step": 1030
    },
    {
      "epoch": 3.4551495016611296,
      "grad_norm": 0.1388895958662033,
      "learning_rate": 1.308970099667774e-05,
      "loss": 0.0062,
      "step": 1040
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 1.4491432905197144,
      "learning_rate": 1.302325581395349e-05,
      "loss": 0.0188,
      "step": 1050
    },
    {
      "epoch": 3.521594684385382,
      "grad_norm": 4.973201274871826,
      "learning_rate": 1.2956810631229237e-05,
      "loss": 0.0276,
      "step": 1060
    },
    {
      "epoch": 3.5548172757475083,
      "grad_norm": 0.527586817741394,
      "learning_rate": 1.2890365448504984e-05,
      "loss": 0.0164,
      "step": 1070
    },
    {
      "epoch": 3.5880398671096345,
      "grad_norm": 1.777698040008545,
      "learning_rate": 1.2823920265780732e-05,
      "loss": 0.0184,
      "step": 1080
    },
    {
      "epoch": 3.6212624584717608,
      "grad_norm": 0.16324618458747864,
      "learning_rate": 1.2757475083056479e-05,
      "loss": 0.0147,
      "step": 1090
    },
    {
      "epoch": 3.654485049833887,
      "grad_norm": 0.1624033898115158,
      "learning_rate": 1.2691029900332228e-05,
      "loss": 0.0079,
      "step": 1100
    },
    {
      "epoch": 3.6877076411960132,
      "grad_norm": 2.8067500591278076,
      "learning_rate": 1.2624584717607975e-05,
      "loss": 0.019,
      "step": 1110
    },
    {
      "epoch": 3.7209302325581395,
      "grad_norm": 0.9455596208572388,
      "learning_rate": 1.2558139534883723e-05,
      "loss": 0.0097,
      "step": 1120
    },
    {
      "epoch": 3.7541528239202657,
      "grad_norm": 0.8081134557723999,
      "learning_rate": 1.2491694352159468e-05,
      "loss": 0.0141,
      "step": 1130
    },
    {
      "epoch": 3.787375415282392,
      "grad_norm": 0.2965069115161896,
      "learning_rate": 1.2425249169435216e-05,
      "loss": 0.02,
      "step": 1140
    },
    {
      "epoch": 3.820598006644518,
      "grad_norm": 2.4430906772613525,
      "learning_rate": 1.2358803986710965e-05,
      "loss": 0.0106,
      "step": 1150
    },
    {
      "epoch": 3.8538205980066444,
      "grad_norm": 0.22479145228862762,
      "learning_rate": 1.2292358803986712e-05,
      "loss": 0.0151,
      "step": 1160
    },
    {
      "epoch": 3.8870431893687707,
      "grad_norm": 2.4237582683563232,
      "learning_rate": 1.222591362126246e-05,
      "loss": 0.0197,
      "step": 1170
    },
    {
      "epoch": 3.920265780730897,
      "grad_norm": 1.5328409671783447,
      "learning_rate": 1.2159468438538207e-05,
      "loss": 0.0184,
      "step": 1180
    },
    {
      "epoch": 3.953488372093023,
      "grad_norm": 1.5180343389511108,
      "learning_rate": 1.2093023255813954e-05,
      "loss": 0.0201,
      "step": 1190
    },
    {
      "epoch": 3.9867109634551494,
      "grad_norm": 1.9449349641799927,
      "learning_rate": 1.2026578073089703e-05,
      "loss": 0.0293,
      "step": 1200
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9918846899224806,
      "eval_f1": 0.9548821548821549,
      "eval_loss": 0.023088259622454643,
      "eval_precision": 0.9712328767123287,
      "eval_recall": 0.9390728476821192,
      "eval_runtime": 143.4924,
      "eval_samples_per_second": 57.682,
      "eval_steps_per_second": 1.805,
      "step": 1204
    },
    {
      "epoch": 4.019933554817276,
      "grad_norm": 0.24396251142024994,
      "learning_rate": 1.196013289036545e-05,
      "loss": 0.0077,
      "step": 1210
    },
    {
      "epoch": 4.053156146179402,
      "grad_norm": 1.2927075624465942,
      "learning_rate": 1.1893687707641198e-05,
      "loss": 0.0115,
      "step": 1220
    },
    {
      "epoch": 4.086378737541528,
      "grad_norm": 0.22376514971256256,
      "learning_rate": 1.1827242524916945e-05,
      "loss": 0.005,
      "step": 1230
    },
    {
      "epoch": 4.119601328903655,
      "grad_norm": 0.6737408638000488,
      "learning_rate": 1.176079734219269e-05,
      "loss": 0.0188,
      "step": 1240
    },
    {
      "epoch": 4.152823920265781,
      "grad_norm": 0.5617955327033997,
      "learning_rate": 1.1694352159468441e-05,
      "loss": 0.0114,
      "step": 1250
    },
    {
      "epoch": 4.186046511627907,
      "grad_norm": 1.4095531702041626,
      "learning_rate": 1.1627906976744187e-05,
      "loss": 0.0171,
      "step": 1260
    },
    {
      "epoch": 4.219269102990033,
      "grad_norm": 0.8260856866836548,
      "learning_rate": 1.1561461794019934e-05,
      "loss": 0.0103,
      "step": 1270
    },
    {
      "epoch": 4.25249169435216,
      "grad_norm": 0.10946803539991379,
      "learning_rate": 1.1495016611295682e-05,
      "loss": 0.0108,
      "step": 1280
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.767169177532196,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0135,
      "step": 1290
    },
    {
      "epoch": 4.318936877076412,
      "grad_norm": 1.1835025548934937,
      "learning_rate": 1.1362126245847176e-05,
      "loss": 0.0128,
      "step": 1300
    },
    {
      "epoch": 4.352159468438538,
      "grad_norm": 2.6293599605560303,
      "learning_rate": 1.1295681063122925e-05,
      "loss": 0.0109,
      "step": 1310
    },
    {
      "epoch": 4.385382059800665,
      "grad_norm": 4.132768154144287,
      "learning_rate": 1.1229235880398673e-05,
      "loss": 0.0101,
      "step": 1320
    },
    {
      "epoch": 4.4186046511627906,
      "grad_norm": 2.121534585952759,
      "learning_rate": 1.116279069767442e-05,
      "loss": 0.0116,
      "step": 1330
    },
    {
      "epoch": 4.451827242524917,
      "grad_norm": 0.4916287660598755,
      "learning_rate": 1.1096345514950166e-05,
      "loss": 0.0114,
      "step": 1340
    },
    {
      "epoch": 4.485049833887043,
      "grad_norm": 1.483960747718811,
      "learning_rate": 1.1029900332225913e-05,
      "loss": 0.0172,
      "step": 1350
    },
    {
      "epoch": 4.51827242524917,
      "grad_norm": 0.08473242074251175,
      "learning_rate": 1.0963455149501662e-05,
      "loss": 0.0061,
      "step": 1360
    },
    {
      "epoch": 4.5514950166112955,
      "grad_norm": 2.9975476264953613,
      "learning_rate": 1.089700996677741e-05,
      "loss": 0.0106,
      "step": 1370
    },
    {
      "epoch": 4.584717607973422,
      "grad_norm": 0.10991346836090088,
      "learning_rate": 1.0830564784053157e-05,
      "loss": 0.0145,
      "step": 1380
    },
    {
      "epoch": 4.617940199335548,
      "grad_norm": 1.5414124727249146,
      "learning_rate": 1.0764119601328904e-05,
      "loss": 0.0095,
      "step": 1390
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 0.23227623105049133,
      "learning_rate": 1.0697674418604651e-05,
      "loss": 0.0161,
      "step": 1400
    },
    {
      "epoch": 4.6843853820598005,
      "grad_norm": 3.1351537704467773,
      "learning_rate": 1.06312292358804e-05,
      "loss": 0.0171,
      "step": 1410
    },
    {
      "epoch": 4.717607973421927,
      "grad_norm": 2.2802374362945557,
      "learning_rate": 1.0564784053156148e-05,
      "loss": 0.0143,
      "step": 1420
    },
    {
      "epoch": 4.750830564784053,
      "grad_norm": 0.19777429103851318,
      "learning_rate": 1.0498338870431895e-05,
      "loss": 0.015,
      "step": 1430
    },
    {
      "epoch": 4.78405315614618,
      "grad_norm": 0.05560567229986191,
      "learning_rate": 1.0431893687707642e-05,
      "loss": 0.0066,
      "step": 1440
    },
    {
      "epoch": 4.8172757475083055,
      "grad_norm": 0.07671797275543213,
      "learning_rate": 1.0365448504983388e-05,
      "loss": 0.0091,
      "step": 1450
    },
    {
      "epoch": 4.850498338870432,
      "grad_norm": 0.33311352133750916,
      "learning_rate": 1.0299003322259139e-05,
      "loss": 0.013,
      "step": 1460
    },
    {
      "epoch": 4.883720930232558,
      "grad_norm": 0.029068173840641975,
      "learning_rate": 1.0232558139534884e-05,
      "loss": 0.0158,
      "step": 1470
    },
    {
      "epoch": 4.916943521594685,
      "grad_norm": 1.0414320230484009,
      "learning_rate": 1.0166112956810632e-05,
      "loss": 0.005,
      "step": 1480
    },
    {
      "epoch": 4.95016611295681,
      "grad_norm": 0.007697423454374075,
      "learning_rate": 1.0099667774086379e-05,
      "loss": 0.0109,
      "step": 1490
    },
    {
      "epoch": 4.983388704318937,
      "grad_norm": 0.07504726201295853,
      "learning_rate": 1.0033222591362126e-05,
      "loss": 0.0137,
      "step": 1500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9933381782945736,
      "eval_f1": 0.962862930452397,
      "eval_loss": 0.02198965661227703,
      "eval_precision": 0.9820936639118457,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 144.6541,
      "eval_samples_per_second": 57.219,
      "eval_steps_per_second": 1.79,
      "step": 1505
    },
    {
      "epoch": 5.016611295681063,
      "grad_norm": 0.060293134301900864,
      "learning_rate": 9.966777408637874e-06,
      "loss": 0.0068,
      "step": 1510
    },
    {
      "epoch": 5.04983388704319,
      "grad_norm": 0.01000804454088211,
      "learning_rate": 9.900332225913623e-06,
      "loss": 0.0029,
      "step": 1520
    },
    {
      "epoch": 5.083056478405315,
      "grad_norm": 0.10305364429950714,
      "learning_rate": 9.83388704318937e-06,
      "loss": 0.0094,
      "step": 1530
    },
    {
      "epoch": 5.116279069767442,
      "grad_norm": 0.8278190493583679,
      "learning_rate": 9.767441860465117e-06,
      "loss": 0.0186,
      "step": 1540
    },
    {
      "epoch": 5.149501661129568,
      "grad_norm": 0.38508719205856323,
      "learning_rate": 9.700996677740865e-06,
      "loss": 0.0046,
      "step": 1550
    },
    {
      "epoch": 5.1827242524916945,
      "grad_norm": 0.5204586982727051,
      "learning_rate": 9.634551495016612e-06,
      "loss": 0.0024,
      "step": 1560
    },
    {
      "epoch": 5.21594684385382,
      "grad_norm": 1.3258378505706787,
      "learning_rate": 9.56810631229236e-06,
      "loss": 0.0104,
      "step": 1570
    },
    {
      "epoch": 5.249169435215947,
      "grad_norm": 0.54499351978302,
      "learning_rate": 9.501661129568107e-06,
      "loss": 0.0115,
      "step": 1580
    },
    {
      "epoch": 5.282392026578073,
      "grad_norm": 0.8262853622436523,
      "learning_rate": 9.435215946843854e-06,
      "loss": 0.0041,
      "step": 1590
    },
    {
      "epoch": 5.3156146179401995,
      "grad_norm": 2.2631235122680664,
      "learning_rate": 9.368770764119603e-06,
      "loss": 0.0088,
      "step": 1600
    },
    {
      "epoch": 5.348837209302325,
      "grad_norm": 0.1734304130077362,
      "learning_rate": 9.30232558139535e-06,
      "loss": 0.0026,
      "step": 1610
    },
    {
      "epoch": 5.382059800664452,
      "grad_norm": 0.17347626388072968,
      "learning_rate": 9.235880398671098e-06,
      "loss": 0.0066,
      "step": 1620
    },
    {
      "epoch": 5.415282392026578,
      "grad_norm": 0.6047820448875427,
      "learning_rate": 9.169435215946845e-06,
      "loss": 0.0115,
      "step": 1630
    },
    {
      "epoch": 5.4485049833887045,
      "grad_norm": 0.009644635021686554,
      "learning_rate": 9.102990033222592e-06,
      "loss": 0.0211,
      "step": 1640
    },
    {
      "epoch": 5.48172757475083,
      "grad_norm": 0.14375169575214386,
      "learning_rate": 9.03654485049834e-06,
      "loss": 0.0062,
      "step": 1650
    },
    {
      "epoch": 5.514950166112957,
      "grad_norm": 1.0212156772613525,
      "learning_rate": 8.970099667774087e-06,
      "loss": 0.0117,
      "step": 1660
    },
    {
      "epoch": 5.548172757475083,
      "grad_norm": 0.1250666081905365,
      "learning_rate": 8.903654485049834e-06,
      "loss": 0.0118,
      "step": 1670
    },
    {
      "epoch": 5.5813953488372094,
      "grad_norm": 0.45548126101493835,
      "learning_rate": 8.837209302325582e-06,
      "loss": 0.0047,
      "step": 1680
    },
    {
      "epoch": 5.614617940199335,
      "grad_norm": 0.04035773128271103,
      "learning_rate": 8.770764119601329e-06,
      "loss": 0.0132,
      "step": 1690
    },
    {
      "epoch": 5.647840531561462,
      "grad_norm": 0.6544476747512817,
      "learning_rate": 8.704318936877078e-06,
      "loss": 0.008,
      "step": 1700
    },
    {
      "epoch": 5.681063122923588,
      "grad_norm": 0.9990273118019104,
      "learning_rate": 8.637873754152825e-06,
      "loss": 0.0049,
      "step": 1710
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.6515280604362488,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.0104,
      "step": 1720
    },
    {
      "epoch": 5.74750830564784,
      "grad_norm": 0.8313305974006653,
      "learning_rate": 8.50498338870432e-06,
      "loss": 0.0157,
      "step": 1730
    },
    {
      "epoch": 5.780730897009967,
      "grad_norm": 1.1854767799377441,
      "learning_rate": 8.438538205980067e-06,
      "loss": 0.0167,
      "step": 1740
    },
    {
      "epoch": 5.813953488372093,
      "grad_norm": 1.0437983274459839,
      "learning_rate": 8.372093023255815e-06,
      "loss": 0.0138,
      "step": 1750
    },
    {
      "epoch": 5.847176079734219,
      "grad_norm": 1.2643011808395386,
      "learning_rate": 8.305647840531562e-06,
      "loss": 0.0118,
      "step": 1760
    },
    {
      "epoch": 5.880398671096345,
      "grad_norm": 0.10660819709300995,
      "learning_rate": 8.23920265780731e-06,
      "loss": 0.0095,
      "step": 1770
    },
    {
      "epoch": 5.913621262458472,
      "grad_norm": 0.11803936958312988,
      "learning_rate": 8.172757475083057e-06,
      "loss": 0.0108,
      "step": 1780
    },
    {
      "epoch": 5.946843853820598,
      "grad_norm": 0.353222131729126,
      "learning_rate": 8.106312292358804e-06,
      "loss": 0.0049,
      "step": 1790
    },
    {
      "epoch": 5.980066445182724,
      "grad_norm": 0.011621341109275818,
      "learning_rate": 8.039867109634553e-06,
      "loss": 0.0035,
      "step": 1800
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9933381782945736,
      "eval_f1": 0.9630624580255205,
      "eval_loss": 0.023844407871365547,
      "eval_precision": 0.9768392370572208,
      "eval_recall": 0.9496688741721855,
      "eval_runtime": 141.3982,
      "eval_samples_per_second": 58.537,
      "eval_steps_per_second": 1.832,
      "step": 1806
    },
    {
      "epoch": 6.01328903654485,
      "grad_norm": 1.279982566833496,
      "learning_rate": 7.9734219269103e-06,
      "loss": 0.0059,
      "step": 1810
    },
    {
      "epoch": 6.046511627906977,
      "grad_norm": 2.3451876640319824,
      "learning_rate": 7.906976744186048e-06,
      "loss": 0.0135,
      "step": 1820
    },
    {
      "epoch": 6.079734219269103,
      "grad_norm": 0.10925263911485672,
      "learning_rate": 7.840531561461795e-06,
      "loss": 0.0058,
      "step": 1830
    },
    {
      "epoch": 6.112956810631229,
      "grad_norm": 0.18377484381198883,
      "learning_rate": 7.774086378737542e-06,
      "loss": 0.0081,
      "step": 1840
    },
    {
      "epoch": 6.146179401993355,
      "grad_norm": 1.170370101928711,
      "learning_rate": 7.70764119601329e-06,
      "loss": 0.005,
      "step": 1850
    },
    {
      "epoch": 6.179401993355482,
      "grad_norm": 0.7760109305381775,
      "learning_rate": 7.641196013289037e-06,
      "loss": 0.0043,
      "step": 1860
    },
    {
      "epoch": 6.212624584717608,
      "grad_norm": 1.2082077264785767,
      "learning_rate": 7.574750830564784e-06,
      "loss": 0.0044,
      "step": 1870
    },
    {
      "epoch": 6.245847176079734,
      "grad_norm": 0.14065393805503845,
      "learning_rate": 7.508305647840532e-06,
      "loss": 0.0034,
      "step": 1880
    },
    {
      "epoch": 6.27906976744186,
      "grad_norm": 0.08646999299526215,
      "learning_rate": 7.44186046511628e-06,
      "loss": 0.0081,
      "step": 1890
    },
    {
      "epoch": 6.312292358803987,
      "grad_norm": 0.559810996055603,
      "learning_rate": 7.375415282392027e-06,
      "loss": 0.004,
      "step": 1900
    },
    {
      "epoch": 6.3455149501661126,
      "grad_norm": 2.5652031898498535,
      "learning_rate": 7.308970099667775e-06,
      "loss": 0.014,
      "step": 1910
    },
    {
      "epoch": 6.378737541528239,
      "grad_norm": 0.41970816254615784,
      "learning_rate": 7.242524916943522e-06,
      "loss": 0.0095,
      "step": 1920
    },
    {
      "epoch": 6.411960132890365,
      "grad_norm": 0.39562520384788513,
      "learning_rate": 7.17607973421927e-06,
      "loss": 0.0086,
      "step": 1930
    },
    {
      "epoch": 6.445182724252492,
      "grad_norm": 0.02285865508019924,
      "learning_rate": 7.109634551495017e-06,
      "loss": 0.0075,
      "step": 1940
    },
    {
      "epoch": 6.4784053156146175,
      "grad_norm": 0.8587521314620972,
      "learning_rate": 7.0431893687707646e-06,
      "loss": 0.0083,
      "step": 1950
    },
    {
      "epoch": 6.511627906976744,
      "grad_norm": 0.7996931672096252,
      "learning_rate": 6.976744186046513e-06,
      "loss": 0.0084,
      "step": 1960
    },
    {
      "epoch": 6.544850498338871,
      "grad_norm": 0.5360599756240845,
      "learning_rate": 6.910299003322259e-06,
      "loss": 0.0114,
      "step": 1970
    },
    {
      "epoch": 6.578073089700997,
      "grad_norm": 1.4666428565979004,
      "learning_rate": 6.843853820598007e-06,
      "loss": 0.0068,
      "step": 1980
    },
    {
      "epoch": 6.6112956810631225,
      "grad_norm": 0.012454922311007977,
      "learning_rate": 6.777408637873755e-06,
      "loss": 0.0091,
      "step": 1990
    },
    {
      "epoch": 6.644518272425249,
      "grad_norm": 0.8994121551513672,
      "learning_rate": 6.710963455149502e-06,
      "loss": 0.0071,
      "step": 2000
    },
    {
      "epoch": 6.677740863787376,
      "grad_norm": 0.10792426019906998,
      "learning_rate": 6.64451827242525e-06,
      "loss": 0.0055,
      "step": 2010
    },
    {
      "epoch": 6.710963455149502,
      "grad_norm": 0.38674384355545044,
      "learning_rate": 6.578073089700997e-06,
      "loss": 0.0034,
      "step": 2020
    },
    {
      "epoch": 6.7441860465116275,
      "grad_norm": 0.15462017059326172,
      "learning_rate": 6.511627906976745e-06,
      "loss": 0.0127,
      "step": 2030
    },
    {
      "epoch": 6.777408637873754,
      "grad_norm": 2.1169981956481934,
      "learning_rate": 6.445182724252492e-06,
      "loss": 0.0144,
      "step": 2040
    },
    {
      "epoch": 6.810631229235881,
      "grad_norm": 0.530330240726471,
      "learning_rate": 6.3787375415282395e-06,
      "loss": 0.0098,
      "step": 2050
    },
    {
      "epoch": 6.843853820598007,
      "grad_norm": 0.05954615771770477,
      "learning_rate": 6.312292358803988e-06,
      "loss": 0.0088,
      "step": 2060
    },
    {
      "epoch": 6.877076411960132,
      "grad_norm": 0.369876503944397,
      "learning_rate": 6.245847176079734e-06,
      "loss": 0.004,
      "step": 2070
    },
    {
      "epoch": 6.910299003322259,
      "grad_norm": 0.020280787721276283,
      "learning_rate": 6.179401993355482e-06,
      "loss": 0.0058,
      "step": 2080
    },
    {
      "epoch": 6.943521594684386,
      "grad_norm": 2.118306875228882,
      "learning_rate": 6.11295681063123e-06,
      "loss": 0.0068,
      "step": 2090
    },
    {
      "epoch": 6.976744186046512,
      "grad_norm": 1.423706293106079,
      "learning_rate": 6.046511627906977e-06,
      "loss": 0.0088,
      "step": 2100
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9935804263565892,
      "eval_f1": 0.9644533869885983,
      "eval_loss": 0.02064608968794346,
      "eval_precision": 0.9769021739130435,
      "eval_recall": 0.952317880794702,
      "eval_runtime": 142.2336,
      "eval_samples_per_second": 58.193,
      "eval_steps_per_second": 1.821,
      "step": 2107
    }
  ],
  "logging_steps": 10,
  "max_steps": 3010,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.158287624077184e+17,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
