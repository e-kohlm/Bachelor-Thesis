{
  "best_metric": 0.969645147498931,
  "best_model_checkpoint": "../saved_models/command_injection/checkpoint-24687",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 24687,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0003645643456069996,
      "grad_norm": 38.90433883666992,
      "learning_rate": 1.9999270871308788e-05,
      "loss": 1.0036,
      "step": 1
    },
    {
      "epoch": 0.0036456434560699965,
      "grad_norm": 15.493203163146973,
      "learning_rate": 1.999270871308786e-05,
      "loss": 0.6351,
      "step": 10
    },
    {
      "epoch": 0.007291286912139993,
      "grad_norm": 15.040669441223145,
      "learning_rate": 1.9985417426175723e-05,
      "loss": 0.4593,
      "step": 20
    },
    {
      "epoch": 0.01093693036820999,
      "grad_norm": 12.388368606567383,
      "learning_rate": 1.997812613926358e-05,
      "loss": 0.364,
      "step": 30
    },
    {
      "epoch": 0.014582573824279986,
      "grad_norm": 18.297264099121094,
      "learning_rate": 1.997083485235144e-05,
      "loss": 0.4135,
      "step": 40
    },
    {
      "epoch": 0.01822821728034998,
      "grad_norm": 20.259859085083008,
      "learning_rate": 1.99635435654393e-05,
      "loss": 0.5069,
      "step": 50
    },
    {
      "epoch": 0.02187386073641998,
      "grad_norm": 13.678214073181152,
      "learning_rate": 1.9956252278527163e-05,
      "loss": 0.3476,
      "step": 60
    },
    {
      "epoch": 0.025519504192489974,
      "grad_norm": 269.89666748046875,
      "learning_rate": 1.994896099161502e-05,
      "loss": 0.3608,
      "step": 70
    },
    {
      "epoch": 0.029165147648559972,
      "grad_norm": 16.13628578186035,
      "learning_rate": 1.9941669704702882e-05,
      "loss": 0.3988,
      "step": 80
    },
    {
      "epoch": 0.03281079110462997,
      "grad_norm": 11.970821380615234,
      "learning_rate": 1.993437841779074e-05,
      "loss": 0.3176,
      "step": 90
    },
    {
      "epoch": 0.03645643456069996,
      "grad_norm": 22.794883728027344,
      "learning_rate": 1.9927087130878603e-05,
      "loss": 0.3361,
      "step": 100
    },
    {
      "epoch": 0.04010207801676996,
      "grad_norm": 17.21355628967285,
      "learning_rate": 1.991979584396646e-05,
      "loss": 0.455,
      "step": 110
    },
    {
      "epoch": 0.04374772147283996,
      "grad_norm": 21.109209060668945,
      "learning_rate": 1.9912504557054322e-05,
      "loss": 0.4205,
      "step": 120
    },
    {
      "epoch": 0.04739336492890995,
      "grad_norm": 11.703630447387695,
      "learning_rate": 1.990521327014218e-05,
      "loss": 0.3881,
      "step": 130
    },
    {
      "epoch": 0.05103900838497995,
      "grad_norm": 14.641301155090332,
      "learning_rate": 1.9897921983230043e-05,
      "loss": 0.2836,
      "step": 140
    },
    {
      "epoch": 0.054684651841049946,
      "grad_norm": 18.666385650634766,
      "learning_rate": 1.98906306963179e-05,
      "loss": 0.3726,
      "step": 150
    },
    {
      "epoch": 0.058330295297119944,
      "grad_norm": 9.387175559997559,
      "learning_rate": 1.9883339409405762e-05,
      "loss": 0.2822,
      "step": 160
    },
    {
      "epoch": 0.061975938753189935,
      "grad_norm": 13.008644104003906,
      "learning_rate": 1.987604812249362e-05,
      "loss": 0.3656,
      "step": 170
    },
    {
      "epoch": 0.06562158220925994,
      "grad_norm": 16.513521194458008,
      "learning_rate": 1.9868756835581484e-05,
      "loss": 0.3172,
      "step": 180
    },
    {
      "epoch": 0.06926722566532993,
      "grad_norm": 16.65045928955078,
      "learning_rate": 1.986146554866934e-05,
      "loss": 0.3761,
      "step": 190
    },
    {
      "epoch": 0.07291286912139992,
      "grad_norm": 6.210821628570557,
      "learning_rate": 1.9854174261757202e-05,
      "loss": 0.3185,
      "step": 200
    },
    {
      "epoch": 0.07655851257746993,
      "grad_norm": 11.185832023620605,
      "learning_rate": 1.984688297484506e-05,
      "loss": 0.3305,
      "step": 210
    },
    {
      "epoch": 0.08020415603353992,
      "grad_norm": 6.615271091461182,
      "learning_rate": 1.9839591687932924e-05,
      "loss": 0.3323,
      "step": 220
    },
    {
      "epoch": 0.08384979948960991,
      "grad_norm": 13.31345272064209,
      "learning_rate": 1.983230040102078e-05,
      "loss": 0.406,
      "step": 230
    },
    {
      "epoch": 0.08749544294567992,
      "grad_norm": 10.15440845489502,
      "learning_rate": 1.9825009114108642e-05,
      "loss": 0.2342,
      "step": 240
    },
    {
      "epoch": 0.09114108640174991,
      "grad_norm": 19.409700393676758,
      "learning_rate": 1.98177178271965e-05,
      "loss": 0.3254,
      "step": 250
    },
    {
      "epoch": 0.0947867298578199,
      "grad_norm": 11.975164413452148,
      "learning_rate": 1.9810426540284364e-05,
      "loss": 0.3678,
      "step": 260
    },
    {
      "epoch": 0.0984323733138899,
      "grad_norm": 12.789876937866211,
      "learning_rate": 1.980313525337222e-05,
      "loss": 0.3979,
      "step": 270
    },
    {
      "epoch": 0.1020780167699599,
      "grad_norm": 5.865760326385498,
      "learning_rate": 1.9795843966460082e-05,
      "loss": 0.3634,
      "step": 280
    },
    {
      "epoch": 0.1057236602260299,
      "grad_norm": 7.068510055541992,
      "learning_rate": 1.978855267954794e-05,
      "loss": 0.2974,
      "step": 290
    },
    {
      "epoch": 0.10936930368209989,
      "grad_norm": 8.113744735717773,
      "learning_rate": 1.9781261392635804e-05,
      "loss": 0.2974,
      "step": 300
    },
    {
      "epoch": 0.11301494713816988,
      "grad_norm": 5.848804950714111,
      "learning_rate": 1.977397010572366e-05,
      "loss": 0.3544,
      "step": 310
    },
    {
      "epoch": 0.11666059059423989,
      "grad_norm": 10.211024284362793,
      "learning_rate": 1.9766678818811522e-05,
      "loss": 0.2893,
      "step": 320
    },
    {
      "epoch": 0.12030623405030988,
      "grad_norm": 9.275242805480957,
      "learning_rate": 1.975938753189938e-05,
      "loss": 0.2631,
      "step": 330
    },
    {
      "epoch": 0.12395187750637987,
      "grad_norm": 11.649063110351562,
      "learning_rate": 1.9752096244987244e-05,
      "loss": 0.2753,
      "step": 340
    },
    {
      "epoch": 0.12759752096244986,
      "grad_norm": 5.1637749671936035,
      "learning_rate": 1.97448049580751e-05,
      "loss": 0.2488,
      "step": 350
    },
    {
      "epoch": 0.13124316441851988,
      "grad_norm": 7.181201934814453,
      "learning_rate": 1.9737513671162962e-05,
      "loss": 0.3088,
      "step": 360
    },
    {
      "epoch": 0.13488880787458987,
      "grad_norm": 5.653654098510742,
      "learning_rate": 1.973022238425082e-05,
      "loss": 0.2835,
      "step": 370
    },
    {
      "epoch": 0.13853445133065986,
      "grad_norm": 14.171792984008789,
      "learning_rate": 1.9722931097338684e-05,
      "loss": 0.2556,
      "step": 380
    },
    {
      "epoch": 0.14218009478672985,
      "grad_norm": 8.751874923706055,
      "learning_rate": 1.971563981042654e-05,
      "loss": 0.3068,
      "step": 390
    },
    {
      "epoch": 0.14582573824279985,
      "grad_norm": 10.217016220092773,
      "learning_rate": 1.9708348523514402e-05,
      "loss": 0.2713,
      "step": 400
    },
    {
      "epoch": 0.14947138169886984,
      "grad_norm": 6.07996129989624,
      "learning_rate": 1.970105723660226e-05,
      "loss": 0.2346,
      "step": 410
    },
    {
      "epoch": 0.15311702515493986,
      "grad_norm": 10.32111644744873,
      "learning_rate": 1.9693765949690124e-05,
      "loss": 0.268,
      "step": 420
    },
    {
      "epoch": 0.15676266861100985,
      "grad_norm": 8.184852600097656,
      "learning_rate": 1.9686474662777983e-05,
      "loss": 0.2477,
      "step": 430
    },
    {
      "epoch": 0.16040831206707984,
      "grad_norm": 6.994274616241455,
      "learning_rate": 1.9679183375865842e-05,
      "loss": 0.2607,
      "step": 440
    },
    {
      "epoch": 0.16405395552314983,
      "grad_norm": 7.177631378173828,
      "learning_rate": 1.96718920889537e-05,
      "loss": 0.2612,
      "step": 450
    },
    {
      "epoch": 0.16769959897921982,
      "grad_norm": 5.892014503479004,
      "learning_rate": 1.9664600802041564e-05,
      "loss": 0.2424,
      "step": 460
    },
    {
      "epoch": 0.17134524243528984,
      "grad_norm": 7.53945779800415,
      "learning_rate": 1.9657309515129423e-05,
      "loss": 0.2086,
      "step": 470
    },
    {
      "epoch": 0.17499088589135983,
      "grad_norm": 10.191988945007324,
      "learning_rate": 1.9650018228217282e-05,
      "loss": 0.1962,
      "step": 480
    },
    {
      "epoch": 0.17863652934742982,
      "grad_norm": 11.795416831970215,
      "learning_rate": 1.964272694130514e-05,
      "loss": 0.2086,
      "step": 490
    },
    {
      "epoch": 0.18228217280349981,
      "grad_norm": 6.271683692932129,
      "learning_rate": 1.9635435654393004e-05,
      "loss": 0.2315,
      "step": 500
    },
    {
      "epoch": 0.1859278162595698,
      "grad_norm": 10.617093086242676,
      "learning_rate": 1.9628144367480863e-05,
      "loss": 0.2411,
      "step": 510
    },
    {
      "epoch": 0.1895734597156398,
      "grad_norm": 13.653867721557617,
      "learning_rate": 1.9620853080568722e-05,
      "loss": 0.2242,
      "step": 520
    },
    {
      "epoch": 0.19321910317170982,
      "grad_norm": 7.267673015594482,
      "learning_rate": 1.961356179365658e-05,
      "loss": 0.1935,
      "step": 530
    },
    {
      "epoch": 0.1968647466277798,
      "grad_norm": 5.509104251861572,
      "learning_rate": 1.9606270506744444e-05,
      "loss": 0.2224,
      "step": 540
    },
    {
      "epoch": 0.2005103900838498,
      "grad_norm": 7.803999423980713,
      "learning_rate": 1.9598979219832303e-05,
      "loss": 0.2432,
      "step": 550
    },
    {
      "epoch": 0.2041560335399198,
      "grad_norm": 10.040637016296387,
      "learning_rate": 1.9591687932920162e-05,
      "loss": 0.2227,
      "step": 560
    },
    {
      "epoch": 0.20780167699598978,
      "grad_norm": 7.337798118591309,
      "learning_rate": 1.958439664600802e-05,
      "loss": 0.2182,
      "step": 570
    },
    {
      "epoch": 0.2114473204520598,
      "grad_norm": 6.047829627990723,
      "learning_rate": 1.9577105359095884e-05,
      "loss": 0.191,
      "step": 580
    },
    {
      "epoch": 0.2150929639081298,
      "grad_norm": 13.459634780883789,
      "learning_rate": 1.9569814072183743e-05,
      "loss": 0.2226,
      "step": 590
    },
    {
      "epoch": 0.21873860736419978,
      "grad_norm": 8.260871887207031,
      "learning_rate": 1.9562522785271602e-05,
      "loss": 0.1853,
      "step": 600
    },
    {
      "epoch": 0.22238425082026977,
      "grad_norm": 5.283688068389893,
      "learning_rate": 1.955523149835946e-05,
      "loss": 0.1958,
      "step": 610
    },
    {
      "epoch": 0.22602989427633977,
      "grad_norm": 3.4411275386810303,
      "learning_rate": 1.9547940211447324e-05,
      "loss": 0.2047,
      "step": 620
    },
    {
      "epoch": 0.22967553773240976,
      "grad_norm": 12.195905685424805,
      "learning_rate": 1.9540648924535183e-05,
      "loss": 0.2049,
      "step": 630
    },
    {
      "epoch": 0.23332118118847978,
      "grad_norm": 3.0874993801116943,
      "learning_rate": 1.9533357637623042e-05,
      "loss": 0.1593,
      "step": 640
    },
    {
      "epoch": 0.23696682464454977,
      "grad_norm": 11.318832397460938,
      "learning_rate": 1.95260663507109e-05,
      "loss": 0.2196,
      "step": 650
    },
    {
      "epoch": 0.24061246810061976,
      "grad_norm": 6.744041442871094,
      "learning_rate": 1.9518775063798764e-05,
      "loss": 0.1717,
      "step": 660
    },
    {
      "epoch": 0.24425811155668975,
      "grad_norm": 4.739930152893066,
      "learning_rate": 1.9511483776886623e-05,
      "loss": 0.174,
      "step": 670
    },
    {
      "epoch": 0.24790375501275974,
      "grad_norm": 9.093582153320312,
      "learning_rate": 1.9504192489974482e-05,
      "loss": 0.2354,
      "step": 680
    },
    {
      "epoch": 0.25154939846882973,
      "grad_norm": 15.556307792663574,
      "learning_rate": 1.949690120306234e-05,
      "loss": 0.2,
      "step": 690
    },
    {
      "epoch": 0.2551950419248997,
      "grad_norm": 8.012629508972168,
      "learning_rate": 1.9489609916150204e-05,
      "loss": 0.1982,
      "step": 700
    },
    {
      "epoch": 0.2588406853809697,
      "grad_norm": 7.2259202003479,
      "learning_rate": 1.9482318629238063e-05,
      "loss": 0.1946,
      "step": 710
    },
    {
      "epoch": 0.26248632883703976,
      "grad_norm": 3.223832607269287,
      "learning_rate": 1.9475027342325922e-05,
      "loss": 0.1111,
      "step": 720
    },
    {
      "epoch": 0.26613197229310975,
      "grad_norm": 12.305190086364746,
      "learning_rate": 1.946773605541378e-05,
      "loss": 0.1695,
      "step": 730
    },
    {
      "epoch": 0.26977761574917974,
      "grad_norm": 13.438677787780762,
      "learning_rate": 1.9460444768501644e-05,
      "loss": 0.2416,
      "step": 740
    },
    {
      "epoch": 0.27342325920524974,
      "grad_norm": 8.759819030761719,
      "learning_rate": 1.9453153481589503e-05,
      "loss": 0.2148,
      "step": 750
    },
    {
      "epoch": 0.2770689026613197,
      "grad_norm": 6.869298458099365,
      "learning_rate": 1.9445862194677362e-05,
      "loss": 0.226,
      "step": 760
    },
    {
      "epoch": 0.2807145461173897,
      "grad_norm": 4.773869037628174,
      "learning_rate": 1.943857090776522e-05,
      "loss": 0.1664,
      "step": 770
    },
    {
      "epoch": 0.2843601895734597,
      "grad_norm": 6.14002799987793,
      "learning_rate": 1.9431279620853084e-05,
      "loss": 0.1917,
      "step": 780
    },
    {
      "epoch": 0.2880058330295297,
      "grad_norm": 9.535320281982422,
      "learning_rate": 1.9423988333940943e-05,
      "loss": 0.1669,
      "step": 790
    },
    {
      "epoch": 0.2916514764855997,
      "grad_norm": 4.744658946990967,
      "learning_rate": 1.9416697047028802e-05,
      "loss": 0.1206,
      "step": 800
    },
    {
      "epoch": 0.2952971199416697,
      "grad_norm": 11.80394458770752,
      "learning_rate": 1.940940576011666e-05,
      "loss": 0.1403,
      "step": 810
    },
    {
      "epoch": 0.2989427633977397,
      "grad_norm": 14.472023963928223,
      "learning_rate": 1.9402114473204524e-05,
      "loss": 0.1448,
      "step": 820
    },
    {
      "epoch": 0.3025884068538097,
      "grad_norm": 3.329132556915283,
      "learning_rate": 1.9394823186292383e-05,
      "loss": 0.185,
      "step": 830
    },
    {
      "epoch": 0.3062340503098797,
      "grad_norm": 4.434911727905273,
      "learning_rate": 1.9387531899380242e-05,
      "loss": 0.1384,
      "step": 840
    },
    {
      "epoch": 0.3098796937659497,
      "grad_norm": 12.790497779846191,
      "learning_rate": 1.93802406124681e-05,
      "loss": 0.1767,
      "step": 850
    },
    {
      "epoch": 0.3135253372220197,
      "grad_norm": 4.648712158203125,
      "learning_rate": 1.9372949325555964e-05,
      "loss": 0.2127,
      "step": 860
    },
    {
      "epoch": 0.3171709806780897,
      "grad_norm": 5.5924224853515625,
      "learning_rate": 1.9365658038643823e-05,
      "loss": 0.168,
      "step": 870
    },
    {
      "epoch": 0.3208166241341597,
      "grad_norm": 6.389983654022217,
      "learning_rate": 1.9358366751731683e-05,
      "loss": 0.259,
      "step": 880
    },
    {
      "epoch": 0.32446226759022967,
      "grad_norm": 5.322739601135254,
      "learning_rate": 1.935107546481954e-05,
      "loss": 0.1888,
      "step": 890
    },
    {
      "epoch": 0.32810791104629966,
      "grad_norm": 11.637168884277344,
      "learning_rate": 1.9343784177907404e-05,
      "loss": 0.2033,
      "step": 900
    },
    {
      "epoch": 0.33175355450236965,
      "grad_norm": 13.421339988708496,
      "learning_rate": 1.9336492890995263e-05,
      "loss": 0.1536,
      "step": 910
    },
    {
      "epoch": 0.33539919795843964,
      "grad_norm": 11.586691856384277,
      "learning_rate": 1.9329201604083123e-05,
      "loss": 0.1531,
      "step": 920
    },
    {
      "epoch": 0.33904484141450963,
      "grad_norm": 11.557616233825684,
      "learning_rate": 1.9321910317170982e-05,
      "loss": 0.1329,
      "step": 930
    },
    {
      "epoch": 0.3426904848705797,
      "grad_norm": 4.8806986808776855,
      "learning_rate": 1.9314619030258844e-05,
      "loss": 0.1879,
      "step": 940
    },
    {
      "epoch": 0.3463361283266497,
      "grad_norm": 4.745545387268066,
      "learning_rate": 1.9307327743346703e-05,
      "loss": 0.085,
      "step": 950
    },
    {
      "epoch": 0.34998177178271966,
      "grad_norm": 5.289493560791016,
      "learning_rate": 1.9300036456434563e-05,
      "loss": 0.1688,
      "step": 960
    },
    {
      "epoch": 0.35362741523878966,
      "grad_norm": 2.465270519256592,
      "learning_rate": 1.9292745169522422e-05,
      "loss": 0.1399,
      "step": 970
    },
    {
      "epoch": 0.35727305869485965,
      "grad_norm": 0.4611339271068573,
      "learning_rate": 1.9285453882610284e-05,
      "loss": 0.1364,
      "step": 980
    },
    {
      "epoch": 0.36091870215092964,
      "grad_norm": 3.5861830711364746,
      "learning_rate": 1.9278162595698143e-05,
      "loss": 0.1614,
      "step": 990
    },
    {
      "epoch": 0.36456434560699963,
      "grad_norm": 9.104381561279297,
      "learning_rate": 1.9270871308786003e-05,
      "loss": 0.1261,
      "step": 1000
    },
    {
      "epoch": 0.3682099890630696,
      "grad_norm": 7.633004188537598,
      "learning_rate": 1.9263580021873862e-05,
      "loss": 0.1211,
      "step": 1010
    },
    {
      "epoch": 0.3718556325191396,
      "grad_norm": 6.755957126617432,
      "learning_rate": 1.9256288734961724e-05,
      "loss": 0.1329,
      "step": 1020
    },
    {
      "epoch": 0.3755012759752096,
      "grad_norm": 2.7656524181365967,
      "learning_rate": 1.9248997448049584e-05,
      "loss": 0.1989,
      "step": 1030
    },
    {
      "epoch": 0.3791469194312796,
      "grad_norm": 9.923663139343262,
      "learning_rate": 1.9241706161137443e-05,
      "loss": 0.1612,
      "step": 1040
    },
    {
      "epoch": 0.38279256288734964,
      "grad_norm": 16.292236328125,
      "learning_rate": 1.9234414874225302e-05,
      "loss": 0.1769,
      "step": 1050
    },
    {
      "epoch": 0.38643820634341963,
      "grad_norm": 1.0896631479263306,
      "learning_rate": 1.9227123587313164e-05,
      "loss": 0.1104,
      "step": 1060
    },
    {
      "epoch": 0.3900838497994896,
      "grad_norm": 2.0946688652038574,
      "learning_rate": 1.9219832300401024e-05,
      "loss": 0.1276,
      "step": 1070
    },
    {
      "epoch": 0.3937294932555596,
      "grad_norm": 4.419357776641846,
      "learning_rate": 1.9212541013488883e-05,
      "loss": 0.1125,
      "step": 1080
    },
    {
      "epoch": 0.3973751367116296,
      "grad_norm": 4.387693881988525,
      "learning_rate": 1.9205249726576742e-05,
      "loss": 0.0949,
      "step": 1090
    },
    {
      "epoch": 0.4010207801676996,
      "grad_norm": 4.5619707107543945,
      "learning_rate": 1.91979584396646e-05,
      "loss": 0.0982,
      "step": 1100
    },
    {
      "epoch": 0.4046664236237696,
      "grad_norm": 1.9158557653427124,
      "learning_rate": 1.9190667152752464e-05,
      "loss": 0.0896,
      "step": 1110
    },
    {
      "epoch": 0.4083120670798396,
      "grad_norm": 5.321292400360107,
      "learning_rate": 1.9183375865840323e-05,
      "loss": 0.0793,
      "step": 1120
    },
    {
      "epoch": 0.41195771053590957,
      "grad_norm": 2.2080068588256836,
      "learning_rate": 1.9176084578928182e-05,
      "loss": 0.1676,
      "step": 1130
    },
    {
      "epoch": 0.41560335399197956,
      "grad_norm": 0.9893256425857544,
      "learning_rate": 1.916879329201604e-05,
      "loss": 0.0894,
      "step": 1140
    },
    {
      "epoch": 0.41924899744804955,
      "grad_norm": 2.5721187591552734,
      "learning_rate": 1.9161502005103904e-05,
      "loss": 0.0803,
      "step": 1150
    },
    {
      "epoch": 0.4228946409041196,
      "grad_norm": 8.6377534866333,
      "learning_rate": 1.9154210718191763e-05,
      "loss": 0.1835,
      "step": 1160
    },
    {
      "epoch": 0.4265402843601896,
      "grad_norm": 5.12967586517334,
      "learning_rate": 1.9146919431279622e-05,
      "loss": 0.1331,
      "step": 1170
    },
    {
      "epoch": 0.4301859278162596,
      "grad_norm": 3.688371419906616,
      "learning_rate": 1.913962814436748e-05,
      "loss": 0.0798,
      "step": 1180
    },
    {
      "epoch": 0.4338315712723296,
      "grad_norm": 7.943106651306152,
      "learning_rate": 1.9132336857455344e-05,
      "loss": 0.1416,
      "step": 1190
    },
    {
      "epoch": 0.43747721472839957,
      "grad_norm": 3.523015022277832,
      "learning_rate": 1.9125045570543203e-05,
      "loss": 0.0496,
      "step": 1200
    },
    {
      "epoch": 0.44112285818446956,
      "grad_norm": 9.37824535369873,
      "learning_rate": 1.9117754283631062e-05,
      "loss": 0.1302,
      "step": 1210
    },
    {
      "epoch": 0.44476850164053955,
      "grad_norm": 0.7311528325080872,
      "learning_rate": 1.911046299671892e-05,
      "loss": 0.0988,
      "step": 1220
    },
    {
      "epoch": 0.44841414509660954,
      "grad_norm": 6.978240013122559,
      "learning_rate": 1.9103171709806784e-05,
      "loss": 0.1055,
      "step": 1230
    },
    {
      "epoch": 0.45205978855267953,
      "grad_norm": 6.108020305633545,
      "learning_rate": 1.9095880422894643e-05,
      "loss": 0.1482,
      "step": 1240
    },
    {
      "epoch": 0.4557054320087495,
      "grad_norm": 9.689937591552734,
      "learning_rate": 1.9088589135982502e-05,
      "loss": 0.1572,
      "step": 1250
    },
    {
      "epoch": 0.4593510754648195,
      "grad_norm": 1.4958336353302002,
      "learning_rate": 1.908129784907036e-05,
      "loss": 0.1153,
      "step": 1260
    },
    {
      "epoch": 0.46299671892088956,
      "grad_norm": 1.0085173845291138,
      "learning_rate": 1.9074006562158224e-05,
      "loss": 0.1111,
      "step": 1270
    },
    {
      "epoch": 0.46664236237695955,
      "grad_norm": 0.7799527049064636,
      "learning_rate": 1.9066715275246083e-05,
      "loss": 0.1275,
      "step": 1280
    },
    {
      "epoch": 0.47028800583302954,
      "grad_norm": 4.153481960296631,
      "learning_rate": 1.9059423988333942e-05,
      "loss": 0.13,
      "step": 1290
    },
    {
      "epoch": 0.47393364928909953,
      "grad_norm": 6.482017993927002,
      "learning_rate": 1.90521327014218e-05,
      "loss": 0.1201,
      "step": 1300
    },
    {
      "epoch": 0.4775792927451695,
      "grad_norm": 0.519486129283905,
      "learning_rate": 1.9044841414509664e-05,
      "loss": 0.1007,
      "step": 1310
    },
    {
      "epoch": 0.4812249362012395,
      "grad_norm": 1.9966151714324951,
      "learning_rate": 1.9037550127597523e-05,
      "loss": 0.0614,
      "step": 1320
    },
    {
      "epoch": 0.4848705796573095,
      "grad_norm": 8.953083038330078,
      "learning_rate": 1.9030258840685382e-05,
      "loss": 0.1458,
      "step": 1330
    },
    {
      "epoch": 0.4885162231133795,
      "grad_norm": 0.5627970099449158,
      "learning_rate": 1.902296755377324e-05,
      "loss": 0.0755,
      "step": 1340
    },
    {
      "epoch": 0.4921618665694495,
      "grad_norm": 1.1422077417373657,
      "learning_rate": 1.9015676266861104e-05,
      "loss": 0.107,
      "step": 1350
    },
    {
      "epoch": 0.4958075100255195,
      "grad_norm": 0.40814635157585144,
      "learning_rate": 1.9008384979948963e-05,
      "loss": 0.0783,
      "step": 1360
    },
    {
      "epoch": 0.4994531534815895,
      "grad_norm": 5.5147705078125,
      "learning_rate": 1.9001093693036822e-05,
      "loss": 0.1284,
      "step": 1370
    },
    {
      "epoch": 0.5030987969376595,
      "grad_norm": 10.046525955200195,
      "learning_rate": 1.899380240612468e-05,
      "loss": 0.1682,
      "step": 1380
    },
    {
      "epoch": 0.5067444403937295,
      "grad_norm": 1.1553112268447876,
      "learning_rate": 1.8986511119212544e-05,
      "loss": 0.0991,
      "step": 1390
    },
    {
      "epoch": 0.5103900838497994,
      "grad_norm": 9.394681930541992,
      "learning_rate": 1.8979219832300403e-05,
      "loss": 0.0961,
      "step": 1400
    },
    {
      "epoch": 0.5140357273058694,
      "grad_norm": 10.382493019104004,
      "learning_rate": 1.8971928545388262e-05,
      "loss": 0.1348,
      "step": 1410
    },
    {
      "epoch": 0.5176813707619394,
      "grad_norm": 6.139308929443359,
      "learning_rate": 1.896463725847612e-05,
      "loss": 0.0887,
      "step": 1420
    },
    {
      "epoch": 0.5213270142180095,
      "grad_norm": 2.5336310863494873,
      "learning_rate": 1.8957345971563984e-05,
      "loss": 0.0926,
      "step": 1430
    },
    {
      "epoch": 0.5249726576740795,
      "grad_norm": 10.94369888305664,
      "learning_rate": 1.8950054684651843e-05,
      "loss": 0.0739,
      "step": 1440
    },
    {
      "epoch": 0.5286183011301495,
      "grad_norm": 0.21939148008823395,
      "learning_rate": 1.8942763397739702e-05,
      "loss": 0.068,
      "step": 1450
    },
    {
      "epoch": 0.5322639445862195,
      "grad_norm": 2.338388681411743,
      "learning_rate": 1.893547211082756e-05,
      "loss": 0.0433,
      "step": 1460
    },
    {
      "epoch": 0.5359095880422895,
      "grad_norm": 8.553412437438965,
      "learning_rate": 1.8928180823915424e-05,
      "loss": 0.1292,
      "step": 1470
    },
    {
      "epoch": 0.5395552314983595,
      "grad_norm": 12.965920448303223,
      "learning_rate": 1.8920889537003283e-05,
      "loss": 0.1287,
      "step": 1480
    },
    {
      "epoch": 0.5432008749544295,
      "grad_norm": 0.9198088049888611,
      "learning_rate": 1.8913598250091142e-05,
      "loss": 0.0871,
      "step": 1490
    },
    {
      "epoch": 0.5468465184104995,
      "grad_norm": 5.616525650024414,
      "learning_rate": 1.8906306963179e-05,
      "loss": 0.1437,
      "step": 1500
    },
    {
      "epoch": 0.5504921618665695,
      "grad_norm": 3.8967349529266357,
      "learning_rate": 1.8899015676266864e-05,
      "loss": 0.0922,
      "step": 1510
    },
    {
      "epoch": 0.5541378053226395,
      "grad_norm": 3.0178518295288086,
      "learning_rate": 1.8891724389354723e-05,
      "loss": 0.0784,
      "step": 1520
    },
    {
      "epoch": 0.5577834487787094,
      "grad_norm": 3.840369701385498,
      "learning_rate": 1.8884433102442582e-05,
      "loss": 0.1136,
      "step": 1530
    },
    {
      "epoch": 0.5614290922347794,
      "grad_norm": 6.231562614440918,
      "learning_rate": 1.887714181553044e-05,
      "loss": 0.1246,
      "step": 1540
    },
    {
      "epoch": 0.5650747356908494,
      "grad_norm": 4.312206268310547,
      "learning_rate": 1.8869850528618304e-05,
      "loss": 0.0776,
      "step": 1550
    },
    {
      "epoch": 0.5687203791469194,
      "grad_norm": 4.025968551635742,
      "learning_rate": 1.8862559241706163e-05,
      "loss": 0.0849,
      "step": 1560
    },
    {
      "epoch": 0.5723660226029894,
      "grad_norm": 15.01207447052002,
      "learning_rate": 1.8855267954794022e-05,
      "loss": 0.1279,
      "step": 1570
    },
    {
      "epoch": 0.5760116660590594,
      "grad_norm": 4.016630172729492,
      "learning_rate": 1.884797666788188e-05,
      "loss": 0.0633,
      "step": 1580
    },
    {
      "epoch": 0.5796573095151294,
      "grad_norm": 6.440378665924072,
      "learning_rate": 1.8840685380969744e-05,
      "loss": 0.114,
      "step": 1590
    },
    {
      "epoch": 0.5833029529711994,
      "grad_norm": 1.7403761148452759,
      "learning_rate": 1.8833394094057603e-05,
      "loss": 0.13,
      "step": 1600
    },
    {
      "epoch": 0.5869485964272694,
      "grad_norm": 8.510173797607422,
      "learning_rate": 1.8826102807145462e-05,
      "loss": 0.0555,
      "step": 1610
    },
    {
      "epoch": 0.5905942398833394,
      "grad_norm": 9.632681846618652,
      "learning_rate": 1.881881152023332e-05,
      "loss": 0.0644,
      "step": 1620
    },
    {
      "epoch": 0.5942398833394094,
      "grad_norm": 2.669842481613159,
      "learning_rate": 1.8811520233321184e-05,
      "loss": 0.2024,
      "step": 1630
    },
    {
      "epoch": 0.5978855267954793,
      "grad_norm": 8.956748008728027,
      "learning_rate": 1.8804228946409043e-05,
      "loss": 0.0554,
      "step": 1640
    },
    {
      "epoch": 0.6015311702515495,
      "grad_norm": 7.360642433166504,
      "learning_rate": 1.8796937659496902e-05,
      "loss": 0.085,
      "step": 1650
    },
    {
      "epoch": 0.6051768137076194,
      "grad_norm": 7.401841163635254,
      "learning_rate": 1.878964637258476e-05,
      "loss": 0.0821,
      "step": 1660
    },
    {
      "epoch": 0.6088224571636894,
      "grad_norm": 0.5906501412391663,
      "learning_rate": 1.8782355085672624e-05,
      "loss": 0.1344,
      "step": 1670
    },
    {
      "epoch": 0.6124681006197594,
      "grad_norm": 7.194533348083496,
      "learning_rate": 1.8775063798760483e-05,
      "loss": 0.0862,
      "step": 1680
    },
    {
      "epoch": 0.6161137440758294,
      "grad_norm": 5.478511333465576,
      "learning_rate": 1.8767772511848342e-05,
      "loss": 0.0969,
      "step": 1690
    },
    {
      "epoch": 0.6197593875318994,
      "grad_norm": 5.495135307312012,
      "learning_rate": 1.87604812249362e-05,
      "loss": 0.0862,
      "step": 1700
    },
    {
      "epoch": 0.6234050309879694,
      "grad_norm": 12.585234642028809,
      "learning_rate": 1.8753189938024064e-05,
      "loss": 0.1507,
      "step": 1710
    },
    {
      "epoch": 0.6270506744440394,
      "grad_norm": 0.4611488878726959,
      "learning_rate": 1.8745898651111923e-05,
      "loss": 0.102,
      "step": 1720
    },
    {
      "epoch": 0.6306963179001094,
      "grad_norm": 0.3579651713371277,
      "learning_rate": 1.8738607364199783e-05,
      "loss": 0.0927,
      "step": 1730
    },
    {
      "epoch": 0.6343419613561794,
      "grad_norm": 1.0463740825653076,
      "learning_rate": 1.8731316077287642e-05,
      "loss": 0.0691,
      "step": 1740
    },
    {
      "epoch": 0.6379876048122494,
      "grad_norm": 11.086969375610352,
      "learning_rate": 1.8724024790375504e-05,
      "loss": 0.087,
      "step": 1750
    },
    {
      "epoch": 0.6416332482683194,
      "grad_norm": 0.4413946270942688,
      "learning_rate": 1.8716733503463363e-05,
      "loss": 0.082,
      "step": 1760
    },
    {
      "epoch": 0.6452788917243893,
      "grad_norm": 4.889866352081299,
      "learning_rate": 1.8709442216551223e-05,
      "loss": 0.112,
      "step": 1770
    },
    {
      "epoch": 0.6489245351804593,
      "grad_norm": 70.73235321044922,
      "learning_rate": 1.8702150929639082e-05,
      "loss": 0.0996,
      "step": 1780
    },
    {
      "epoch": 0.6525701786365293,
      "grad_norm": 5.846304416656494,
      "learning_rate": 1.8694859642726944e-05,
      "loss": 0.0805,
      "step": 1790
    },
    {
      "epoch": 0.6562158220925993,
      "grad_norm": 6.3515944480896,
      "learning_rate": 1.8687568355814803e-05,
      "loss": 0.0894,
      "step": 1800
    },
    {
      "epoch": 0.6598614655486693,
      "grad_norm": 10.349235534667969,
      "learning_rate": 1.8680277068902663e-05,
      "loss": 0.1306,
      "step": 1810
    },
    {
      "epoch": 0.6635071090047393,
      "grad_norm": 2.5016605854034424,
      "learning_rate": 1.8672985781990522e-05,
      "loss": 0.0704,
      "step": 1820
    },
    {
      "epoch": 0.6671527524608093,
      "grad_norm": 6.9242119789123535,
      "learning_rate": 1.8665694495078384e-05,
      "loss": 0.0906,
      "step": 1830
    },
    {
      "epoch": 0.6707983959168793,
      "grad_norm": 4.116880893707275,
      "learning_rate": 1.8658403208166243e-05,
      "loss": 0.0607,
      "step": 1840
    },
    {
      "epoch": 0.6744440393729493,
      "grad_norm": 4.336385250091553,
      "learning_rate": 1.8651111921254103e-05,
      "loss": 0.0725,
      "step": 1850
    },
    {
      "epoch": 0.6780896828290193,
      "grad_norm": 11.306456565856934,
      "learning_rate": 1.8643820634341962e-05,
      "loss": 0.1317,
      "step": 1860
    },
    {
      "epoch": 0.6817353262850894,
      "grad_norm": 7.114599227905273,
      "learning_rate": 1.8636529347429824e-05,
      "loss": 0.1404,
      "step": 1870
    },
    {
      "epoch": 0.6853809697411594,
      "grad_norm": 0.24587371945381165,
      "learning_rate": 1.8629238060517684e-05,
      "loss": 0.0976,
      "step": 1880
    },
    {
      "epoch": 0.6890266131972294,
      "grad_norm": 7.144786357879639,
      "learning_rate": 1.8621946773605543e-05,
      "loss": 0.0461,
      "step": 1890
    },
    {
      "epoch": 0.6926722566532993,
      "grad_norm": 5.506282806396484,
      "learning_rate": 1.8614655486693402e-05,
      "loss": 0.0675,
      "step": 1900
    },
    {
      "epoch": 0.6963179001093693,
      "grad_norm": 0.5730737447738647,
      "learning_rate": 1.8607364199781264e-05,
      "loss": 0.0933,
      "step": 1910
    },
    {
      "epoch": 0.6999635435654393,
      "grad_norm": 0.0870688185095787,
      "learning_rate": 1.8600072912869124e-05,
      "loss": 0.1056,
      "step": 1920
    },
    {
      "epoch": 0.7036091870215093,
      "grad_norm": 0.6233345866203308,
      "learning_rate": 1.8592781625956983e-05,
      "loss": 0.0939,
      "step": 1930
    },
    {
      "epoch": 0.7072548304775793,
      "grad_norm": 9.149517059326172,
      "learning_rate": 1.8585490339044842e-05,
      "loss": 0.1259,
      "step": 1940
    },
    {
      "epoch": 0.7109004739336493,
      "grad_norm": 0.8946760296821594,
      "learning_rate": 1.8578199052132704e-05,
      "loss": 0.0803,
      "step": 1950
    },
    {
      "epoch": 0.7145461173897193,
      "grad_norm": 5.245448589324951,
      "learning_rate": 1.8570907765220564e-05,
      "loss": 0.0637,
      "step": 1960
    },
    {
      "epoch": 0.7181917608457893,
      "grad_norm": 12.663195610046387,
      "learning_rate": 1.8563616478308423e-05,
      "loss": 0.0997,
      "step": 1970
    },
    {
      "epoch": 0.7218374043018593,
      "grad_norm": 8.867022514343262,
      "learning_rate": 1.8556325191396282e-05,
      "loss": 0.0599,
      "step": 1980
    },
    {
      "epoch": 0.7254830477579293,
      "grad_norm": 5.056174278259277,
      "learning_rate": 1.8549033904484144e-05,
      "loss": 0.0862,
      "step": 1990
    },
    {
      "epoch": 0.7291286912139993,
      "grad_norm": 0.07379972189664841,
      "learning_rate": 1.8541742617572004e-05,
      "loss": 0.1043,
      "step": 2000
    },
    {
      "epoch": 0.7327743346700692,
      "grad_norm": 11.135749816894531,
      "learning_rate": 1.8534451330659863e-05,
      "loss": 0.1431,
      "step": 2010
    },
    {
      "epoch": 0.7364199781261392,
      "grad_norm": 2.703444719314575,
      "learning_rate": 1.8527160043747722e-05,
      "loss": 0.0415,
      "step": 2020
    },
    {
      "epoch": 0.7400656215822092,
      "grad_norm": 10.353707313537598,
      "learning_rate": 1.8519868756835585e-05,
      "loss": 0.1233,
      "step": 2030
    },
    {
      "epoch": 0.7437112650382792,
      "grad_norm": 8.675715446472168,
      "learning_rate": 1.8512577469923444e-05,
      "loss": 0.1293,
      "step": 2040
    },
    {
      "epoch": 0.7473569084943492,
      "grad_norm": 3.1471340656280518,
      "learning_rate": 1.8505286183011303e-05,
      "loss": 0.1006,
      "step": 2050
    },
    {
      "epoch": 0.7510025519504192,
      "grad_norm": 9.305685997009277,
      "learning_rate": 1.8497994896099162e-05,
      "loss": 0.0968,
      "step": 2060
    },
    {
      "epoch": 0.7546481954064892,
      "grad_norm": 7.079706192016602,
      "learning_rate": 1.8490703609187025e-05,
      "loss": 0.0875,
      "step": 2070
    },
    {
      "epoch": 0.7582938388625592,
      "grad_norm": 12.468436241149902,
      "learning_rate": 1.8483412322274884e-05,
      "loss": 0.0507,
      "step": 2080
    },
    {
      "epoch": 0.7619394823186293,
      "grad_norm": 0.20995639264583588,
      "learning_rate": 1.8476121035362743e-05,
      "loss": 0.0437,
      "step": 2090
    },
    {
      "epoch": 0.7655851257746993,
      "grad_norm": 0.5191231369972229,
      "learning_rate": 1.8468829748450602e-05,
      "loss": 0.1247,
      "step": 2100
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 7.363275051116943,
      "learning_rate": 1.8461538461538465e-05,
      "loss": 0.0642,
      "step": 2110
    },
    {
      "epoch": 0.7728764126868393,
      "grad_norm": 8.697044372558594,
      "learning_rate": 1.8454247174626324e-05,
      "loss": 0.1258,
      "step": 2120
    },
    {
      "epoch": 0.7765220561429093,
      "grad_norm": 6.947547435760498,
      "learning_rate": 1.8446955887714183e-05,
      "loss": 0.104,
      "step": 2130
    },
    {
      "epoch": 0.7801676995989792,
      "grad_norm": 0.419710636138916,
      "learning_rate": 1.8439664600802042e-05,
      "loss": 0.0402,
      "step": 2140
    },
    {
      "epoch": 0.7838133430550492,
      "grad_norm": 7.6664018630981445,
      "learning_rate": 1.8432373313889905e-05,
      "loss": 0.0696,
      "step": 2150
    },
    {
      "epoch": 0.7874589865111192,
      "grad_norm": 0.02161170355975628,
      "learning_rate": 1.8425082026977764e-05,
      "loss": 0.0602,
      "step": 2160
    },
    {
      "epoch": 0.7911046299671892,
      "grad_norm": 14.872517585754395,
      "learning_rate": 1.8417790740065623e-05,
      "loss": 0.057,
      "step": 2170
    },
    {
      "epoch": 0.7947502734232592,
      "grad_norm": 0.4041498303413391,
      "learning_rate": 1.8410499453153482e-05,
      "loss": 0.1536,
      "step": 2180
    },
    {
      "epoch": 0.7983959168793292,
      "grad_norm": 4.441067695617676,
      "learning_rate": 1.8403208166241345e-05,
      "loss": 0.1198,
      "step": 2190
    },
    {
      "epoch": 0.8020415603353992,
      "grad_norm": 2.9237499237060547,
      "learning_rate": 1.8395916879329204e-05,
      "loss": 0.045,
      "step": 2200
    },
    {
      "epoch": 0.8056872037914692,
      "grad_norm": 5.4219651222229,
      "learning_rate": 1.8388625592417063e-05,
      "loss": 0.0476,
      "step": 2210
    },
    {
      "epoch": 0.8093328472475392,
      "grad_norm": 5.897036552429199,
      "learning_rate": 1.8381334305504922e-05,
      "loss": 0.1095,
      "step": 2220
    },
    {
      "epoch": 0.8129784907036092,
      "grad_norm": 5.969394207000732,
      "learning_rate": 1.837404301859278e-05,
      "loss": 0.0579,
      "step": 2230
    },
    {
      "epoch": 0.8166241341596792,
      "grad_norm": 4.510804653167725,
      "learning_rate": 1.8366751731680644e-05,
      "loss": 0.0729,
      "step": 2240
    },
    {
      "epoch": 0.8202697776157492,
      "grad_norm": 0.46207451820373535,
      "learning_rate": 1.8359460444768503e-05,
      "loss": 0.0686,
      "step": 2250
    },
    {
      "epoch": 0.8239154210718191,
      "grad_norm": 14.224920272827148,
      "learning_rate": 1.8352169157856362e-05,
      "loss": 0.0219,
      "step": 2260
    },
    {
      "epoch": 0.8275610645278891,
      "grad_norm": 13.457635879516602,
      "learning_rate": 1.834487787094422e-05,
      "loss": 0.0442,
      "step": 2270
    },
    {
      "epoch": 0.8312067079839591,
      "grad_norm": 3.4507105350494385,
      "learning_rate": 1.8337586584032084e-05,
      "loss": 0.1532,
      "step": 2280
    },
    {
      "epoch": 0.8348523514400291,
      "grad_norm": 2.8774569034576416,
      "learning_rate": 1.8330295297119943e-05,
      "loss": 0.1051,
      "step": 2290
    },
    {
      "epoch": 0.8384979948960991,
      "grad_norm": 1.09470534324646,
      "learning_rate": 1.8323004010207802e-05,
      "loss": 0.0242,
      "step": 2300
    },
    {
      "epoch": 0.8421436383521692,
      "grad_norm": 6.225461959838867,
      "learning_rate": 1.831571272329566e-05,
      "loss": 0.0887,
      "step": 2310
    },
    {
      "epoch": 0.8457892818082392,
      "grad_norm": 7.55676794052124,
      "learning_rate": 1.8308421436383524e-05,
      "loss": 0.1062,
      "step": 2320
    },
    {
      "epoch": 0.8494349252643092,
      "grad_norm": 11.625783920288086,
      "learning_rate": 1.8301130149471383e-05,
      "loss": 0.0996,
      "step": 2330
    },
    {
      "epoch": 0.8530805687203792,
      "grad_norm": 10.310997009277344,
      "learning_rate": 1.8293838862559242e-05,
      "loss": 0.1012,
      "step": 2340
    },
    {
      "epoch": 0.8567262121764492,
      "grad_norm": 3.190518379211426,
      "learning_rate": 1.82865475756471e-05,
      "loss": 0.1697,
      "step": 2350
    },
    {
      "epoch": 0.8603718556325192,
      "grad_norm": 0.19450019299983978,
      "learning_rate": 1.8279256288734964e-05,
      "loss": 0.0773,
      "step": 2360
    },
    {
      "epoch": 0.8640174990885892,
      "grad_norm": 5.537888526916504,
      "learning_rate": 1.8271965001822823e-05,
      "loss": 0.127,
      "step": 2370
    },
    {
      "epoch": 0.8676631425446591,
      "grad_norm": 4.074941635131836,
      "learning_rate": 1.8264673714910682e-05,
      "loss": 0.0567,
      "step": 2380
    },
    {
      "epoch": 0.8713087860007291,
      "grad_norm": 0.408803790807724,
      "learning_rate": 1.825738242799854e-05,
      "loss": 0.0219,
      "step": 2390
    },
    {
      "epoch": 0.8749544294567991,
      "grad_norm": 6.036561965942383,
      "learning_rate": 1.8250091141086404e-05,
      "loss": 0.0595,
      "step": 2400
    },
    {
      "epoch": 0.8786000729128691,
      "grad_norm": 0.7863202095031738,
      "learning_rate": 1.8242799854174263e-05,
      "loss": 0.0382,
      "step": 2410
    },
    {
      "epoch": 0.8822457163689391,
      "grad_norm": 6.0624308586120605,
      "learning_rate": 1.8235508567262122e-05,
      "loss": 0.0732,
      "step": 2420
    },
    {
      "epoch": 0.8858913598250091,
      "grad_norm": 4.299421310424805,
      "learning_rate": 1.822821728034998e-05,
      "loss": 0.0966,
      "step": 2430
    },
    {
      "epoch": 0.8895370032810791,
      "grad_norm": 0.03539716452360153,
      "learning_rate": 1.8220925993437844e-05,
      "loss": 0.0408,
      "step": 2440
    },
    {
      "epoch": 0.8931826467371491,
      "grad_norm": 9.19991397857666,
      "learning_rate": 1.8213634706525703e-05,
      "loss": 0.0877,
      "step": 2450
    },
    {
      "epoch": 0.8968282901932191,
      "grad_norm": 0.06444880366325378,
      "learning_rate": 1.8206343419613562e-05,
      "loss": 0.1079,
      "step": 2460
    },
    {
      "epoch": 0.9004739336492891,
      "grad_norm": 0.32918229699134827,
      "learning_rate": 1.819905213270142e-05,
      "loss": 0.1656,
      "step": 2470
    },
    {
      "epoch": 0.9041195771053591,
      "grad_norm": 3.227550506591797,
      "learning_rate": 1.8191760845789284e-05,
      "loss": 0.0644,
      "step": 2480
    },
    {
      "epoch": 0.907765220561429,
      "grad_norm": 2.583772659301758,
      "learning_rate": 1.8184469558877143e-05,
      "loss": 0.0508,
      "step": 2490
    },
    {
      "epoch": 0.911410864017499,
      "grad_norm": 5.775896072387695,
      "learning_rate": 1.8177178271965002e-05,
      "loss": 0.1072,
      "step": 2500
    },
    {
      "epoch": 0.915056507473569,
      "grad_norm": 5.1329803466796875,
      "learning_rate": 1.816988698505286e-05,
      "loss": 0.0803,
      "step": 2510
    },
    {
      "epoch": 0.918702150929639,
      "grad_norm": 2.339167594909668,
      "learning_rate": 1.8162595698140724e-05,
      "loss": 0.065,
      "step": 2520
    },
    {
      "epoch": 0.9223477943857091,
      "grad_norm": 5.3847455978393555,
      "learning_rate": 1.8155304411228583e-05,
      "loss": 0.0882,
      "step": 2530
    },
    {
      "epoch": 0.9259934378417791,
      "grad_norm": 4.5623369216918945,
      "learning_rate": 1.8148013124316443e-05,
      "loss": 0.0251,
      "step": 2540
    },
    {
      "epoch": 0.9296390812978491,
      "grad_norm": 0.47316983342170715,
      "learning_rate": 1.81407218374043e-05,
      "loss": 0.0757,
      "step": 2550
    },
    {
      "epoch": 0.9332847247539191,
      "grad_norm": 4.353076457977295,
      "learning_rate": 1.8133430550492164e-05,
      "loss": 0.1054,
      "step": 2560
    },
    {
      "epoch": 0.9369303682099891,
      "grad_norm": 7.060211181640625,
      "learning_rate": 1.8126139263580023e-05,
      "loss": 0.1052,
      "step": 2570
    },
    {
      "epoch": 0.9405760116660591,
      "grad_norm": 7.831052780151367,
      "learning_rate": 1.8118847976667883e-05,
      "loss": 0.0649,
      "step": 2580
    },
    {
      "epoch": 0.9442216551221291,
      "grad_norm": 1.4241786003112793,
      "learning_rate": 1.8111556689755742e-05,
      "loss": 0.0446,
      "step": 2590
    },
    {
      "epoch": 0.9478672985781991,
      "grad_norm": 0.3833642303943634,
      "learning_rate": 1.8104265402843604e-05,
      "loss": 0.0456,
      "step": 2600
    },
    {
      "epoch": 0.9515129420342691,
      "grad_norm": 4.948339462280273,
      "learning_rate": 1.8096974115931463e-05,
      "loss": 0.1099,
      "step": 2610
    },
    {
      "epoch": 0.955158585490339,
      "grad_norm": 0.44015011191368103,
      "learning_rate": 1.8089682829019323e-05,
      "loss": 0.0576,
      "step": 2620
    },
    {
      "epoch": 0.958804228946409,
      "grad_norm": 0.12057872116565704,
      "learning_rate": 1.8082391542107182e-05,
      "loss": 0.0596,
      "step": 2630
    },
    {
      "epoch": 0.962449872402479,
      "grad_norm": 0.5151023864746094,
      "learning_rate": 1.8075100255195044e-05,
      "loss": 0.047,
      "step": 2640
    },
    {
      "epoch": 0.966095515858549,
      "grad_norm": 5.060622692108154,
      "learning_rate": 1.8067808968282903e-05,
      "loss": 0.0826,
      "step": 2650
    },
    {
      "epoch": 0.969741159314619,
      "grad_norm": 0.07733827829360962,
      "learning_rate": 1.8060517681370763e-05,
      "loss": 0.0442,
      "step": 2660
    },
    {
      "epoch": 0.973386802770689,
      "grad_norm": 6.2672929763793945,
      "learning_rate": 1.8053226394458622e-05,
      "loss": 0.0525,
      "step": 2670
    },
    {
      "epoch": 0.977032446226759,
      "grad_norm": 0.179958775639534,
      "learning_rate": 1.8045935107546484e-05,
      "loss": 0.0907,
      "step": 2680
    },
    {
      "epoch": 0.980678089682829,
      "grad_norm": 0.842701256275177,
      "learning_rate": 1.8038643820634344e-05,
      "loss": 0.0798,
      "step": 2690
    },
    {
      "epoch": 0.984323733138899,
      "grad_norm": 1.0735630989074707,
      "learning_rate": 1.8031352533722203e-05,
      "loss": 0.0406,
      "step": 2700
    },
    {
      "epoch": 0.987969376594969,
      "grad_norm": 3.6421759128570557,
      "learning_rate": 1.8024061246810062e-05,
      "loss": 0.0939,
      "step": 2710
    },
    {
      "epoch": 0.991615020051039,
      "grad_norm": 0.9530602097511292,
      "learning_rate": 1.8016769959897924e-05,
      "loss": 0.0759,
      "step": 2720
    },
    {
      "epoch": 0.995260663507109,
      "grad_norm": 5.784202575683594,
      "learning_rate": 1.8009478672985784e-05,
      "loss": 0.0605,
      "step": 2730
    },
    {
      "epoch": 0.998906306963179,
      "grad_norm": 5.47675895690918,
      "learning_rate": 1.8002187386073643e-05,
      "loss": 0.1095,
      "step": 2740
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9742866269165247,
      "eval_f1": 0.902127659574468,
      "eval_loss": 0.07673847675323486,
      "eval_precision": 0.8587962962962963,
      "eval_recall": 0.9500640204865557,
      "eval_runtime": 881.6481,
      "eval_samples_per_second": 21.34,
      "eval_steps_per_second": 0.667,
      "step": 2743
    },
    {
      "epoch": 1.002551950419249,
      "grad_norm": 3.240839958190918,
      "learning_rate": 1.7994896099161502e-05,
      "loss": 0.0427,
      "step": 2750
    },
    {
      "epoch": 1.006197593875319,
      "grad_norm": 0.01723742112517357,
      "learning_rate": 1.7987604812249364e-05,
      "loss": 0.0302,
      "step": 2760
    },
    {
      "epoch": 1.009843237331389,
      "grad_norm": 1.700087308883667,
      "learning_rate": 1.7980313525337224e-05,
      "loss": 0.0459,
      "step": 2770
    },
    {
      "epoch": 1.013488880787459,
      "grad_norm": 9.820521354675293,
      "learning_rate": 1.7973022238425083e-05,
      "loss": 0.1753,
      "step": 2780
    },
    {
      "epoch": 1.017134524243529,
      "grad_norm": 19.460968017578125,
      "learning_rate": 1.7965730951512942e-05,
      "loss": 0.0467,
      "step": 2790
    },
    {
      "epoch": 1.020780167699599,
      "grad_norm": 3.49379825592041,
      "learning_rate": 1.7958439664600804e-05,
      "loss": 0.0637,
      "step": 2800
    },
    {
      "epoch": 1.024425811155669,
      "grad_norm": 2.951308012008667,
      "learning_rate": 1.7951148377688664e-05,
      "loss": 0.0215,
      "step": 2810
    },
    {
      "epoch": 1.0280714546117389,
      "grad_norm": 0.03758886083960533,
      "learning_rate": 1.7943857090776523e-05,
      "loss": 0.0338,
      "step": 2820
    },
    {
      "epoch": 1.031717098067809,
      "grad_norm": 5.507812023162842,
      "learning_rate": 1.7936565803864382e-05,
      "loss": 0.0303,
      "step": 2830
    },
    {
      "epoch": 1.0353627415238789,
      "grad_norm": 4.422718048095703,
      "learning_rate": 1.7929274516952245e-05,
      "loss": 0.0347,
      "step": 2840
    },
    {
      "epoch": 1.039008384979949,
      "grad_norm": 0.4592677652835846,
      "learning_rate": 1.7921983230040104e-05,
      "loss": 0.0808,
      "step": 2850
    },
    {
      "epoch": 1.042654028436019,
      "grad_norm": 0.06274758279323578,
      "learning_rate": 1.7914691943127963e-05,
      "loss": 0.0754,
      "step": 2860
    },
    {
      "epoch": 1.046299671892089,
      "grad_norm": 8.89156723022461,
      "learning_rate": 1.7907400656215822e-05,
      "loss": 0.1254,
      "step": 2870
    },
    {
      "epoch": 1.049945315348159,
      "grad_norm": 0.273346871137619,
      "learning_rate": 1.7900109369303685e-05,
      "loss": 0.0493,
      "step": 2880
    },
    {
      "epoch": 1.053590958804229,
      "grad_norm": 4.5352044105529785,
      "learning_rate": 1.7892818082391544e-05,
      "loss": 0.0778,
      "step": 2890
    },
    {
      "epoch": 1.057236602260299,
      "grad_norm": 2.573110580444336,
      "learning_rate": 1.7885526795479403e-05,
      "loss": 0.0238,
      "step": 2900
    },
    {
      "epoch": 1.060882245716369,
      "grad_norm": 7.398395538330078,
      "learning_rate": 1.7878235508567262e-05,
      "loss": 0.0402,
      "step": 2910
    },
    {
      "epoch": 1.064527889172439,
      "grad_norm": 0.23764844238758087,
      "learning_rate": 1.7870944221655125e-05,
      "loss": 0.0242,
      "step": 2920
    },
    {
      "epoch": 1.068173532628509,
      "grad_norm": 0.04989950731396675,
      "learning_rate": 1.7863652934742984e-05,
      "loss": 0.0585,
      "step": 2930
    },
    {
      "epoch": 1.071819176084579,
      "grad_norm": 0.16954761743545532,
      "learning_rate": 1.7856361647830843e-05,
      "loss": 0.0427,
      "step": 2940
    },
    {
      "epoch": 1.0754648195406489,
      "grad_norm": 4.3156609535217285,
      "learning_rate": 1.7849070360918702e-05,
      "loss": 0.0736,
      "step": 2950
    },
    {
      "epoch": 1.079110462996719,
      "grad_norm": 0.4039609730243683,
      "learning_rate": 1.7841779074006565e-05,
      "loss": 0.0522,
      "step": 2960
    },
    {
      "epoch": 1.0827561064527889,
      "grad_norm": 2.7520899772644043,
      "learning_rate": 1.7834487787094424e-05,
      "loss": 0.0151,
      "step": 2970
    },
    {
      "epoch": 1.086401749908859,
      "grad_norm": 0.06029771640896797,
      "learning_rate": 1.7827196500182283e-05,
      "loss": 0.0331,
      "step": 2980
    },
    {
      "epoch": 1.0900473933649288,
      "grad_norm": 1.2932177782058716,
      "learning_rate": 1.7819905213270142e-05,
      "loss": 0.0587,
      "step": 2990
    },
    {
      "epoch": 1.093693036820999,
      "grad_norm": 6.894900321960449,
      "learning_rate": 1.7812613926358005e-05,
      "loss": 0.1116,
      "step": 3000
    },
    {
      "epoch": 1.0973386802770688,
      "grad_norm": 0.08345429599285126,
      "learning_rate": 1.7805322639445864e-05,
      "loss": 0.0457,
      "step": 3010
    },
    {
      "epoch": 1.100984323733139,
      "grad_norm": 3.7944679260253906,
      "learning_rate": 1.7798031352533723e-05,
      "loss": 0.0682,
      "step": 3020
    },
    {
      "epoch": 1.1046299671892088,
      "grad_norm": 2.2806546688079834,
      "learning_rate": 1.7790740065621582e-05,
      "loss": 0.0298,
      "step": 3030
    },
    {
      "epoch": 1.108275610645279,
      "grad_norm": 8.58541488647461,
      "learning_rate": 1.7783448778709445e-05,
      "loss": 0.0355,
      "step": 3040
    },
    {
      "epoch": 1.1119212541013488,
      "grad_norm": 0.4669185280799866,
      "learning_rate": 1.7776157491797304e-05,
      "loss": 0.0765,
      "step": 3050
    },
    {
      "epoch": 1.115566897557419,
      "grad_norm": 0.12921522557735443,
      "learning_rate": 1.7768866204885163e-05,
      "loss": 0.0504,
      "step": 3060
    },
    {
      "epoch": 1.1192125410134888,
      "grad_norm": 0.40289250016212463,
      "learning_rate": 1.7761574917973022e-05,
      "loss": 0.0173,
      "step": 3070
    },
    {
      "epoch": 1.1228581844695589,
      "grad_norm": 0.007169975433498621,
      "learning_rate": 1.7754283631060885e-05,
      "loss": 0.0599,
      "step": 3080
    },
    {
      "epoch": 1.126503827925629,
      "grad_norm": 0.25473394989967346,
      "learning_rate": 1.7746992344148744e-05,
      "loss": 0.1119,
      "step": 3090
    },
    {
      "epoch": 1.1301494713816989,
      "grad_norm": 0.08685756474733353,
      "learning_rate": 1.7739701057236603e-05,
      "loss": 0.066,
      "step": 3100
    },
    {
      "epoch": 1.133795114837769,
      "grad_norm": 0.09841587394475937,
      "learning_rate": 1.7732409770324462e-05,
      "loss": 0.0137,
      "step": 3110
    },
    {
      "epoch": 1.1374407582938388,
      "grad_norm": 0.09973575174808502,
      "learning_rate": 1.7725118483412325e-05,
      "loss": 0.0132,
      "step": 3120
    },
    {
      "epoch": 1.141086401749909,
      "grad_norm": 3.478029251098633,
      "learning_rate": 1.7717827196500184e-05,
      "loss": 0.0875,
      "step": 3130
    },
    {
      "epoch": 1.1447320452059788,
      "grad_norm": 5.478907108306885,
      "learning_rate": 1.7710535909588043e-05,
      "loss": 0.0908,
      "step": 3140
    },
    {
      "epoch": 1.148377688662049,
      "grad_norm": 1.3531349897384644,
      "learning_rate": 1.7703244622675902e-05,
      "loss": 0.0845,
      "step": 3150
    },
    {
      "epoch": 1.1520233321181188,
      "grad_norm": 0.08684499561786652,
      "learning_rate": 1.7695953335763765e-05,
      "loss": 0.0392,
      "step": 3160
    },
    {
      "epoch": 1.155668975574189,
      "grad_norm": 1.4155532121658325,
      "learning_rate": 1.7688662048851624e-05,
      "loss": 0.0745,
      "step": 3170
    },
    {
      "epoch": 1.1593146190302588,
      "grad_norm": 3.2182042598724365,
      "learning_rate": 1.7681370761939483e-05,
      "loss": 0.0655,
      "step": 3180
    },
    {
      "epoch": 1.1629602624863289,
      "grad_norm": 0.06524782627820969,
      "learning_rate": 1.7674079475027342e-05,
      "loss": 0.0731,
      "step": 3190
    },
    {
      "epoch": 1.1666059059423988,
      "grad_norm": 8.67846965789795,
      "learning_rate": 1.7666788188115205e-05,
      "loss": 0.0462,
      "step": 3200
    },
    {
      "epoch": 1.1702515493984689,
      "grad_norm": 0.4797174632549286,
      "learning_rate": 1.7659496901203064e-05,
      "loss": 0.123,
      "step": 3210
    },
    {
      "epoch": 1.1738971928545388,
      "grad_norm": 0.7769469022750854,
      "learning_rate": 1.7652205614290923e-05,
      "loss": 0.037,
      "step": 3220
    },
    {
      "epoch": 1.1775428363106089,
      "grad_norm": 0.4038148820400238,
      "learning_rate": 1.7644914327378782e-05,
      "loss": 0.0465,
      "step": 3230
    },
    {
      "epoch": 1.1811884797666787,
      "grad_norm": 2.289492607116699,
      "learning_rate": 1.7637623040466645e-05,
      "loss": 0.0492,
      "step": 3240
    },
    {
      "epoch": 1.1848341232227488,
      "grad_norm": 0.3052697777748108,
      "learning_rate": 1.7630331753554504e-05,
      "loss": 0.0567,
      "step": 3250
    },
    {
      "epoch": 1.1884797666788187,
      "grad_norm": 3.516357660293579,
      "learning_rate": 1.7623040466642363e-05,
      "loss": 0.0266,
      "step": 3260
    },
    {
      "epoch": 1.1921254101348888,
      "grad_norm": 0.012343348003923893,
      "learning_rate": 1.7615749179730222e-05,
      "loss": 0.0318,
      "step": 3270
    },
    {
      "epoch": 1.195771053590959,
      "grad_norm": 10.931611061096191,
      "learning_rate": 1.7608457892818085e-05,
      "loss": 0.0506,
      "step": 3280
    },
    {
      "epoch": 1.1994166970470288,
      "grad_norm": 5.4345808029174805,
      "learning_rate": 1.7601166605905944e-05,
      "loss": 0.1104,
      "step": 3290
    },
    {
      "epoch": 1.2030623405030987,
      "grad_norm": 3.59907865524292,
      "learning_rate": 1.7593875318993803e-05,
      "loss": 0.0644,
      "step": 3300
    },
    {
      "epoch": 1.2067079839591688,
      "grad_norm": 5.388316631317139,
      "learning_rate": 1.7586584032081662e-05,
      "loss": 0.0877,
      "step": 3310
    },
    {
      "epoch": 1.2103536274152389,
      "grad_norm": 0.803305447101593,
      "learning_rate": 1.757929274516952e-05,
      "loss": 0.0385,
      "step": 3320
    },
    {
      "epoch": 1.2139992708713088,
      "grad_norm": 0.5272870063781738,
      "learning_rate": 1.7572001458257384e-05,
      "loss": 0.0207,
      "step": 3330
    },
    {
      "epoch": 1.2176449143273789,
      "grad_norm": 4.8473944664001465,
      "learning_rate": 1.7564710171345243e-05,
      "loss": 0.0472,
      "step": 3340
    },
    {
      "epoch": 1.2212905577834487,
      "grad_norm": 6.674030780792236,
      "learning_rate": 1.7557418884433102e-05,
      "loss": 0.0604,
      "step": 3350
    },
    {
      "epoch": 1.2249362012395189,
      "grad_norm": 1.8459454774856567,
      "learning_rate": 1.755012759752096e-05,
      "loss": 0.04,
      "step": 3360
    },
    {
      "epoch": 1.2285818446955887,
      "grad_norm": 0.49037671089172363,
      "learning_rate": 1.7542836310608824e-05,
      "loss": 0.0717,
      "step": 3370
    },
    {
      "epoch": 1.2322274881516588,
      "grad_norm": 1.1427747011184692,
      "learning_rate": 1.7535545023696683e-05,
      "loss": 0.0331,
      "step": 3380
    },
    {
      "epoch": 1.2358731316077287,
      "grad_norm": 8.64637565612793,
      "learning_rate": 1.7528253736784543e-05,
      "loss": 0.0777,
      "step": 3390
    },
    {
      "epoch": 1.2395187750637988,
      "grad_norm": 2.4755375385284424,
      "learning_rate": 1.75209624498724e-05,
      "loss": 0.0742,
      "step": 3400
    },
    {
      "epoch": 1.2431644185198687,
      "grad_norm": 0.14801117777824402,
      "learning_rate": 1.7513671162960264e-05,
      "loss": 0.0638,
      "step": 3410
    },
    {
      "epoch": 1.2468100619759388,
      "grad_norm": 0.24936099350452423,
      "learning_rate": 1.7506379876048123e-05,
      "loss": 0.0484,
      "step": 3420
    },
    {
      "epoch": 1.2504557054320087,
      "grad_norm": 0.2721935212612152,
      "learning_rate": 1.7499088589135983e-05,
      "loss": 0.0273,
      "step": 3430
    },
    {
      "epoch": 1.2541013488880788,
      "grad_norm": 0.014793322421610355,
      "learning_rate": 1.7491797302223842e-05,
      "loss": 0.021,
      "step": 3440
    },
    {
      "epoch": 1.2577469923441487,
      "grad_norm": 6.665738582611084,
      "learning_rate": 1.7484506015311704e-05,
      "loss": 0.09,
      "step": 3450
    },
    {
      "epoch": 1.2613926358002188,
      "grad_norm": 0.761947512626648,
      "learning_rate": 1.7477214728399563e-05,
      "loss": 0.018,
      "step": 3460
    },
    {
      "epoch": 1.2650382792562889,
      "grad_norm": 0.5368320941925049,
      "learning_rate": 1.7469923441487423e-05,
      "loss": 0.0894,
      "step": 3470
    },
    {
      "epoch": 1.2686839227123587,
      "grad_norm": 2.342862367630005,
      "learning_rate": 1.7462632154575282e-05,
      "loss": 0.0188,
      "step": 3480
    },
    {
      "epoch": 1.2723295661684286,
      "grad_norm": 0.07095494121313095,
      "learning_rate": 1.7455340867663144e-05,
      "loss": 0.0256,
      "step": 3490
    },
    {
      "epoch": 1.2759752096244987,
      "grad_norm": 0.012769165448844433,
      "learning_rate": 1.7448049580751003e-05,
      "loss": 0.0424,
      "step": 3500
    },
    {
      "epoch": 1.2796208530805688,
      "grad_norm": 3.583453893661499,
      "learning_rate": 1.7440758293838863e-05,
      "loss": 0.0626,
      "step": 3510
    },
    {
      "epoch": 1.2832664965366387,
      "grad_norm": 5.990116119384766,
      "learning_rate": 1.7433467006926722e-05,
      "loss": 0.0112,
      "step": 3520
    },
    {
      "epoch": 1.2869121399927086,
      "grad_norm": 0.26303961873054504,
      "learning_rate": 1.7426175720014584e-05,
      "loss": 0.0513,
      "step": 3530
    },
    {
      "epoch": 1.2905577834487787,
      "grad_norm": 1.1718846559524536,
      "learning_rate": 1.7418884433102444e-05,
      "loss": 0.0239,
      "step": 3540
    },
    {
      "epoch": 1.2942034269048488,
      "grad_norm": 14.497406959533691,
      "learning_rate": 1.7411593146190303e-05,
      "loss": 0.1014,
      "step": 3550
    },
    {
      "epoch": 1.2978490703609187,
      "grad_norm": 0.4475855827331543,
      "learning_rate": 1.7404301859278162e-05,
      "loss": 0.0371,
      "step": 3560
    },
    {
      "epoch": 1.3014947138169888,
      "grad_norm": 7.928696155548096,
      "learning_rate": 1.7397010572366024e-05,
      "loss": 0.042,
      "step": 3570
    },
    {
      "epoch": 1.3051403572730587,
      "grad_norm": 7.08756685256958,
      "learning_rate": 1.7389719285453884e-05,
      "loss": 0.0636,
      "step": 3580
    },
    {
      "epoch": 1.3087860007291288,
      "grad_norm": 3.955296277999878,
      "learning_rate": 1.7382427998541743e-05,
      "loss": 0.0595,
      "step": 3590
    },
    {
      "epoch": 1.3124316441851986,
      "grad_norm": 3.844933032989502,
      "learning_rate": 1.7375136711629602e-05,
      "loss": 0.0934,
      "step": 3600
    },
    {
      "epoch": 1.3160772876412687,
      "grad_norm": 0.7393574714660645,
      "learning_rate": 1.7367845424717464e-05,
      "loss": 0.0394,
      "step": 3610
    },
    {
      "epoch": 1.3197229310973386,
      "grad_norm": 4.153385639190674,
      "learning_rate": 1.7360554137805324e-05,
      "loss": 0.0585,
      "step": 3620
    },
    {
      "epoch": 1.3233685745534087,
      "grad_norm": 1.4841768741607666,
      "learning_rate": 1.7353262850893183e-05,
      "loss": 0.0149,
      "step": 3630
    },
    {
      "epoch": 1.3270142180094786,
      "grad_norm": 3.2557456493377686,
      "learning_rate": 1.7345971563981042e-05,
      "loss": 0.0461,
      "step": 3640
    },
    {
      "epoch": 1.3306598614655487,
      "grad_norm": 0.22487545013427734,
      "learning_rate": 1.7338680277068904e-05,
      "loss": 0.0872,
      "step": 3650
    },
    {
      "epoch": 1.3343055049216186,
      "grad_norm": 3.255847692489624,
      "learning_rate": 1.7331388990156764e-05,
      "loss": 0.0427,
      "step": 3660
    },
    {
      "epoch": 1.3379511483776887,
      "grad_norm": 3.8344829082489014,
      "learning_rate": 1.7324097703244623e-05,
      "loss": 0.0103,
      "step": 3670
    },
    {
      "epoch": 1.3415967918337586,
      "grad_norm": 1.016495704650879,
      "learning_rate": 1.7316806416332482e-05,
      "loss": 0.0277,
      "step": 3680
    },
    {
      "epoch": 1.3452424352898287,
      "grad_norm": 7.233931541442871,
      "learning_rate": 1.7309515129420345e-05,
      "loss": 0.0601,
      "step": 3690
    },
    {
      "epoch": 1.3488880787458988,
      "grad_norm": 0.03266591578722,
      "learning_rate": 1.7302223842508204e-05,
      "loss": 0.1007,
      "step": 3700
    },
    {
      "epoch": 1.3525337222019687,
      "grad_norm": 1.79155695438385,
      "learning_rate": 1.7294932555596066e-05,
      "loss": 0.0561,
      "step": 3710
    },
    {
      "epoch": 1.3561793656580385,
      "grad_norm": 0.011805649846792221,
      "learning_rate": 1.7287641268683922e-05,
      "loss": 0.0309,
      "step": 3720
    },
    {
      "epoch": 1.3598250091141086,
      "grad_norm": 5.211819171905518,
      "learning_rate": 1.7280349981771785e-05,
      "loss": 0.0578,
      "step": 3730
    },
    {
      "epoch": 1.3634706525701787,
      "grad_norm": 8.464118957519531,
      "learning_rate": 1.7273058694859644e-05,
      "loss": 0.0438,
      "step": 3740
    },
    {
      "epoch": 1.3671162960262486,
      "grad_norm": 0.14896556735038757,
      "learning_rate": 1.7265767407947506e-05,
      "loss": 0.0531,
      "step": 3750
    },
    {
      "epoch": 1.3707619394823185,
      "grad_norm": 0.07457824051380157,
      "learning_rate": 1.7258476121035362e-05,
      "loss": 0.0309,
      "step": 3760
    },
    {
      "epoch": 1.3744075829383886,
      "grad_norm": 0.2575412094593048,
      "learning_rate": 1.7251184834123225e-05,
      "loss": 0.0365,
      "step": 3770
    },
    {
      "epoch": 1.3780532263944587,
      "grad_norm": 0.08739819377660751,
      "learning_rate": 1.7243893547211084e-05,
      "loss": 0.032,
      "step": 3780
    },
    {
      "epoch": 1.3816988698505286,
      "grad_norm": 10.056893348693848,
      "learning_rate": 1.7236602260298946e-05,
      "loss": 0.0789,
      "step": 3790
    },
    {
      "epoch": 1.3853445133065987,
      "grad_norm": 0.3560982942581177,
      "learning_rate": 1.7229310973386802e-05,
      "loss": 0.0213,
      "step": 3800
    },
    {
      "epoch": 1.3889901567626686,
      "grad_norm": 0.006952853873372078,
      "learning_rate": 1.7222019686474665e-05,
      "loss": 0.0483,
      "step": 3810
    },
    {
      "epoch": 1.3926358002187387,
      "grad_norm": 10.419718742370605,
      "learning_rate": 1.7214728399562524e-05,
      "loss": 0.0647,
      "step": 3820
    },
    {
      "epoch": 1.3962814436748086,
      "grad_norm": 4.663872241973877,
      "learning_rate": 1.7207437112650386e-05,
      "loss": 0.0595,
      "step": 3830
    },
    {
      "epoch": 1.3999270871308787,
      "grad_norm": 3.935575246810913,
      "learning_rate": 1.7200145825738242e-05,
      "loss": 0.0529,
      "step": 3840
    },
    {
      "epoch": 1.4035727305869485,
      "grad_norm": 0.6623913645744324,
      "learning_rate": 1.7192854538826105e-05,
      "loss": 0.0416,
      "step": 3850
    },
    {
      "epoch": 1.4072183740430186,
      "grad_norm": 5.6189045906066895,
      "learning_rate": 1.7185563251913964e-05,
      "loss": 0.0339,
      "step": 3860
    },
    {
      "epoch": 1.4108640174990885,
      "grad_norm": 4.954309463500977,
      "learning_rate": 1.7178271965001826e-05,
      "loss": 0.0338,
      "step": 3870
    },
    {
      "epoch": 1.4145096609551586,
      "grad_norm": 0.13825078308582306,
      "learning_rate": 1.7170980678089682e-05,
      "loss": 0.0125,
      "step": 3880
    },
    {
      "epoch": 1.4181553044112285,
      "grad_norm": 10.137568473815918,
      "learning_rate": 1.7163689391177545e-05,
      "loss": 0.0742,
      "step": 3890
    },
    {
      "epoch": 1.4218009478672986,
      "grad_norm": 2.4501280784606934,
      "learning_rate": 1.7156398104265404e-05,
      "loss": 0.0345,
      "step": 3900
    },
    {
      "epoch": 1.4254465913233685,
      "grad_norm": 1.8814009428024292,
      "learning_rate": 1.7149106817353266e-05,
      "loss": 0.0726,
      "step": 3910
    },
    {
      "epoch": 1.4290922347794386,
      "grad_norm": 0.1594863384962082,
      "learning_rate": 1.7141815530441122e-05,
      "loss": 0.0453,
      "step": 3920
    },
    {
      "epoch": 1.4327378782355087,
      "grad_norm": 0.5459432005882263,
      "learning_rate": 1.7134524243528985e-05,
      "loss": 0.0698,
      "step": 3930
    },
    {
      "epoch": 1.4363835216915786,
      "grad_norm": 4.268409252166748,
      "learning_rate": 1.7127232956616844e-05,
      "loss": 0.0414,
      "step": 3940
    },
    {
      "epoch": 1.4400291651476484,
      "grad_norm": 2.1738743782043457,
      "learning_rate": 1.7119941669704706e-05,
      "loss": 0.0265,
      "step": 3950
    },
    {
      "epoch": 1.4436748086037186,
      "grad_norm": 3.5864968299865723,
      "learning_rate": 1.7112650382792562e-05,
      "loss": 0.0774,
      "step": 3960
    },
    {
      "epoch": 1.4473204520597887,
      "grad_norm": 0.027664914727211,
      "learning_rate": 1.7105359095880425e-05,
      "loss": 0.0045,
      "step": 3970
    },
    {
      "epoch": 1.4509660955158585,
      "grad_norm": 1.5098812580108643,
      "learning_rate": 1.7098067808968284e-05,
      "loss": 0.0275,
      "step": 3980
    },
    {
      "epoch": 1.4546117389719284,
      "grad_norm": 6.953240394592285,
      "learning_rate": 1.7090776522056147e-05,
      "loss": 0.0322,
      "step": 3990
    },
    {
      "epoch": 1.4582573824279985,
      "grad_norm": 0.13586434721946716,
      "learning_rate": 1.7083485235144002e-05,
      "loss": 0.0718,
      "step": 4000
    },
    {
      "epoch": 1.4619030258840686,
      "grad_norm": 5.145320892333984,
      "learning_rate": 1.7076193948231865e-05,
      "loss": 0.0424,
      "step": 4010
    },
    {
      "epoch": 1.4655486693401385,
      "grad_norm": 1.3207426071166992,
      "learning_rate": 1.7068902661319724e-05,
      "loss": 0.093,
      "step": 4020
    },
    {
      "epoch": 1.4691943127962086,
      "grad_norm": 6.643189430236816,
      "learning_rate": 1.7061611374407587e-05,
      "loss": 0.0357,
      "step": 4030
    },
    {
      "epoch": 1.4728399562522785,
      "grad_norm": 2.164421796798706,
      "learning_rate": 1.7054320087495442e-05,
      "loss": 0.0916,
      "step": 4040
    },
    {
      "epoch": 1.4764855997083486,
      "grad_norm": 7.700155735015869,
      "learning_rate": 1.7047028800583305e-05,
      "loss": 0.0522,
      "step": 4050
    },
    {
      "epoch": 1.4801312431644185,
      "grad_norm": 3.394426107406616,
      "learning_rate": 1.7039737513671164e-05,
      "loss": 0.0171,
      "step": 4060
    },
    {
      "epoch": 1.4837768866204886,
      "grad_norm": 7.868777275085449,
      "learning_rate": 1.7032446226759027e-05,
      "loss": 0.0153,
      "step": 4070
    },
    {
      "epoch": 1.4874225300765584,
      "grad_norm": 1.5743978023529053,
      "learning_rate": 1.7025154939846882e-05,
      "loss": 0.0034,
      "step": 4080
    },
    {
      "epoch": 1.4910681735326285,
      "grad_norm": 0.7721174359321594,
      "learning_rate": 1.7017863652934745e-05,
      "loss": 0.0339,
      "step": 4090
    },
    {
      "epoch": 1.4947138169886984,
      "grad_norm": 0.019881896674633026,
      "learning_rate": 1.7010572366022604e-05,
      "loss": 0.0335,
      "step": 4100
    },
    {
      "epoch": 1.4983594604447685,
      "grad_norm": 12.731529235839844,
      "learning_rate": 1.7003281079110467e-05,
      "loss": 0.0616,
      "step": 4110
    },
    {
      "epoch": 1.5020051039008386,
      "grad_norm": 0.6083208322525024,
      "learning_rate": 1.6995989792198326e-05,
      "loss": 0.0604,
      "step": 4120
    },
    {
      "epoch": 1.5056507473569085,
      "grad_norm": 0.08806704729795456,
      "learning_rate": 1.6988698505286185e-05,
      "loss": 0.0699,
      "step": 4130
    },
    {
      "epoch": 1.5092963908129784,
      "grad_norm": 0.27575623989105225,
      "learning_rate": 1.6981407218374044e-05,
      "loss": 0.0356,
      "step": 4140
    },
    {
      "epoch": 1.5129420342690485,
      "grad_norm": 4.061877250671387,
      "learning_rate": 1.6974115931461907e-05,
      "loss": 0.0971,
      "step": 4150
    },
    {
      "epoch": 1.5165876777251186,
      "grad_norm": 2.233487129211426,
      "learning_rate": 1.6966824644549766e-05,
      "loss": 0.054,
      "step": 4160
    },
    {
      "epoch": 1.5202333211811885,
      "grad_norm": 1.6955691576004028,
      "learning_rate": 1.6959533357637625e-05,
      "loss": 0.0373,
      "step": 4170
    },
    {
      "epoch": 1.5238789646372584,
      "grad_norm": 2.654825448989868,
      "learning_rate": 1.6952242070725484e-05,
      "loss": 0.0339,
      "step": 4180
    },
    {
      "epoch": 1.5275246080933285,
      "grad_norm": 4.798010349273682,
      "learning_rate": 1.6944950783813347e-05,
      "loss": 0.0397,
      "step": 4190
    },
    {
      "epoch": 1.5311702515493986,
      "grad_norm": 0.13044023513793945,
      "learning_rate": 1.6937659496901206e-05,
      "loss": 0.0642,
      "step": 4200
    },
    {
      "epoch": 1.5348158950054684,
      "grad_norm": 7.45361328125,
      "learning_rate": 1.6930368209989065e-05,
      "loss": 0.0452,
      "step": 4210
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.09191245585680008,
      "learning_rate": 1.6923076923076924e-05,
      "loss": 0.0566,
      "step": 4220
    },
    {
      "epoch": 1.5421071819176084,
      "grad_norm": 0.05467411130666733,
      "learning_rate": 1.6915785636164787e-05,
      "loss": 0.0726,
      "step": 4230
    },
    {
      "epoch": 1.5457528253736785,
      "grad_norm": 0.6371143460273743,
      "learning_rate": 1.6908494349252646e-05,
      "loss": 0.0288,
      "step": 4240
    },
    {
      "epoch": 1.5493984688297484,
      "grad_norm": 0.5167322754859924,
      "learning_rate": 1.6901203062340505e-05,
      "loss": 0.0914,
      "step": 4250
    },
    {
      "epoch": 1.5530441122858183,
      "grad_norm": 0.04944566637277603,
      "learning_rate": 1.6893911775428364e-05,
      "loss": 0.0419,
      "step": 4260
    },
    {
      "epoch": 1.5566897557418884,
      "grad_norm": 2.2109336853027344,
      "learning_rate": 1.6886620488516227e-05,
      "loss": 0.0207,
      "step": 4270
    },
    {
      "epoch": 1.5603353991979585,
      "grad_norm": 0.40213215351104736,
      "learning_rate": 1.6879329201604086e-05,
      "loss": 0.0549,
      "step": 4280
    },
    {
      "epoch": 1.5639810426540284,
      "grad_norm": 0.4795985221862793,
      "learning_rate": 1.6872037914691945e-05,
      "loss": 0.0173,
      "step": 4290
    },
    {
      "epoch": 1.5676266861100985,
      "grad_norm": 6.107090473175049,
      "learning_rate": 1.6864746627779804e-05,
      "loss": 0.1003,
      "step": 4300
    },
    {
      "epoch": 1.5712723295661686,
      "grad_norm": 10.167640686035156,
      "learning_rate": 1.6857455340867667e-05,
      "loss": 0.0672,
      "step": 4310
    },
    {
      "epoch": 1.5749179730222385,
      "grad_norm": 0.4549114406108856,
      "learning_rate": 1.6850164053955526e-05,
      "loss": 0.0509,
      "step": 4320
    },
    {
      "epoch": 1.5785636164783083,
      "grad_norm": 5.911444187164307,
      "learning_rate": 1.6842872767043385e-05,
      "loss": 0.0764,
      "step": 4330
    },
    {
      "epoch": 1.5822092599343784,
      "grad_norm": 0.15316569805145264,
      "learning_rate": 1.6835581480131244e-05,
      "loss": 0.0177,
      "step": 4340
    },
    {
      "epoch": 1.5858549033904485,
      "grad_norm": 0.7551666498184204,
      "learning_rate": 1.6828290193219107e-05,
      "loss": 0.0246,
      "step": 4350
    },
    {
      "epoch": 1.5895005468465184,
      "grad_norm": 10.69442367553711,
      "learning_rate": 1.6820998906306966e-05,
      "loss": 0.0528,
      "step": 4360
    },
    {
      "epoch": 1.5931461903025883,
      "grad_norm": 0.2600388526916504,
      "learning_rate": 1.6813707619394825e-05,
      "loss": 0.0709,
      "step": 4370
    },
    {
      "epoch": 1.5967918337586584,
      "grad_norm": 0.2538663148880005,
      "learning_rate": 1.6806416332482684e-05,
      "loss": 0.0202,
      "step": 4380
    },
    {
      "epoch": 1.6004374772147285,
      "grad_norm": 0.038398128002882004,
      "learning_rate": 1.6799125045570544e-05,
      "loss": 0.0172,
      "step": 4390
    },
    {
      "epoch": 1.6040831206707984,
      "grad_norm": 0.04837111383676529,
      "learning_rate": 1.6791833758658406e-05,
      "loss": 0.0359,
      "step": 4400
    },
    {
      "epoch": 1.6077287641268683,
      "grad_norm": 0.007841878570616245,
      "learning_rate": 1.6784542471746262e-05,
      "loss": 0.0081,
      "step": 4410
    },
    {
      "epoch": 1.6113744075829384,
      "grad_norm": 0.0255406703799963,
      "learning_rate": 1.6777251184834124e-05,
      "loss": 0.0505,
      "step": 4420
    },
    {
      "epoch": 1.6150200510390085,
      "grad_norm": 0.04835175350308418,
      "learning_rate": 1.6769959897921984e-05,
      "loss": 0.038,
      "step": 4430
    },
    {
      "epoch": 1.6186656944950784,
      "grad_norm": 1.09157395362854,
      "learning_rate": 1.6762668611009846e-05,
      "loss": 0.0501,
      "step": 4440
    },
    {
      "epoch": 1.6223113379511482,
      "grad_norm": 4.181148052215576,
      "learning_rate": 1.6755377324097702e-05,
      "loss": 0.0289,
      "step": 4450
    },
    {
      "epoch": 1.6259569814072183,
      "grad_norm": 0.0897495448589325,
      "learning_rate": 1.6748086037185564e-05,
      "loss": 0.0189,
      "step": 4460
    },
    {
      "epoch": 1.6296026248632884,
      "grad_norm": 1.5890390872955322,
      "learning_rate": 1.6740794750273424e-05,
      "loss": 0.0149,
      "step": 4470
    },
    {
      "epoch": 1.6332482683193583,
      "grad_norm": 4.59074592590332,
      "learning_rate": 1.6733503463361286e-05,
      "loss": 0.0911,
      "step": 4480
    },
    {
      "epoch": 1.6368939117754282,
      "grad_norm": 1.5682950019836426,
      "learning_rate": 1.6726212176449145e-05,
      "loss": 0.0218,
      "step": 4490
    },
    {
      "epoch": 1.6405395552314985,
      "grad_norm": 0.012776621617376804,
      "learning_rate": 1.6718920889537004e-05,
      "loss": 0.0286,
      "step": 4500
    },
    {
      "epoch": 1.6441851986875684,
      "grad_norm": 1.353424072265625,
      "learning_rate": 1.6711629602624864e-05,
      "loss": 0.0406,
      "step": 4510
    },
    {
      "epoch": 1.6478308421436383,
      "grad_norm": 3.137532949447632,
      "learning_rate": 1.6704338315712726e-05,
      "loss": 0.1075,
      "step": 4520
    },
    {
      "epoch": 1.6514764855997084,
      "grad_norm": 6.643105506896973,
      "learning_rate": 1.6697047028800585e-05,
      "loss": 0.0689,
      "step": 4530
    },
    {
      "epoch": 1.6551221290557785,
      "grad_norm": 4.01979923248291,
      "learning_rate": 1.6689755741888445e-05,
      "loss": 0.0736,
      "step": 4540
    },
    {
      "epoch": 1.6587677725118484,
      "grad_norm": 0.40436187386512756,
      "learning_rate": 1.6682464454976304e-05,
      "loss": 0.0156,
      "step": 4550
    },
    {
      "epoch": 1.6624134159679183,
      "grad_norm": 0.004534176085144281,
      "learning_rate": 1.6675173168064166e-05,
      "loss": 0.0247,
      "step": 4560
    },
    {
      "epoch": 1.6660590594239884,
      "grad_norm": 0.05355721339583397,
      "learning_rate": 1.6667881881152025e-05,
      "loss": 0.1123,
      "step": 4570
    },
    {
      "epoch": 1.6697047028800585,
      "grad_norm": 3.0892269611358643,
      "learning_rate": 1.6660590594239885e-05,
      "loss": 0.0368,
      "step": 4580
    },
    {
      "epoch": 1.6733503463361283,
      "grad_norm": 0.06854789704084396,
      "learning_rate": 1.6653299307327744e-05,
      "loss": 0.0207,
      "step": 4590
    },
    {
      "epoch": 1.6769959897921982,
      "grad_norm": 1.1949628591537476,
      "learning_rate": 1.6646008020415606e-05,
      "loss": 0.0187,
      "step": 4600
    },
    {
      "epoch": 1.6806416332482683,
      "grad_norm": 2.8881726264953613,
      "learning_rate": 1.6638716733503465e-05,
      "loss": 0.0627,
      "step": 4610
    },
    {
      "epoch": 1.6842872767043384,
      "grad_norm": 5.047040939331055,
      "learning_rate": 1.6631425446591325e-05,
      "loss": 0.0601,
      "step": 4620
    },
    {
      "epoch": 1.6879329201604083,
      "grad_norm": 3.080076217651367,
      "learning_rate": 1.6624134159679184e-05,
      "loss": 0.0486,
      "step": 4630
    },
    {
      "epoch": 1.6915785636164782,
      "grad_norm": 5.403088092803955,
      "learning_rate": 1.6616842872767046e-05,
      "loss": 0.0422,
      "step": 4640
    },
    {
      "epoch": 1.6952242070725483,
      "grad_norm": 3.838057518005371,
      "learning_rate": 1.6609551585854905e-05,
      "loss": 0.0701,
      "step": 4650
    },
    {
      "epoch": 1.6988698505286184,
      "grad_norm": 0.017289038747549057,
      "learning_rate": 1.6602260298942765e-05,
      "loss": 0.0265,
      "step": 4660
    },
    {
      "epoch": 1.7025154939846883,
      "grad_norm": 3.923656940460205,
      "learning_rate": 1.6594969012030624e-05,
      "loss": 0.0588,
      "step": 4670
    },
    {
      "epoch": 1.7061611374407581,
      "grad_norm": 11.228569030761719,
      "learning_rate": 1.6587677725118486e-05,
      "loss": 0.059,
      "step": 4680
    },
    {
      "epoch": 1.7098067808968282,
      "grad_norm": 0.008224725723266602,
      "learning_rate": 1.6580386438206346e-05,
      "loss": 0.0455,
      "step": 4690
    },
    {
      "epoch": 1.7134524243528984,
      "grad_norm": 0.1780897080898285,
      "learning_rate": 1.6573095151294205e-05,
      "loss": 0.0592,
      "step": 4700
    },
    {
      "epoch": 1.7170980678089682,
      "grad_norm": 0.10112906247377396,
      "learning_rate": 1.6565803864382064e-05,
      "loss": 0.0346,
      "step": 4710
    },
    {
      "epoch": 1.7207437112650383,
      "grad_norm": 0.04425618052482605,
      "learning_rate": 1.6558512577469926e-05,
      "loss": 0.0224,
      "step": 4720
    },
    {
      "epoch": 1.7243893547211084,
      "grad_norm": 0.6180473566055298,
      "learning_rate": 1.6551221290557786e-05,
      "loss": 0.0327,
      "step": 4730
    },
    {
      "epoch": 1.7280349981771783,
      "grad_norm": 7.602211952209473,
      "learning_rate": 1.6543930003645645e-05,
      "loss": 0.0931,
      "step": 4740
    },
    {
      "epoch": 1.7316806416332482,
      "grad_norm": 4.481964111328125,
      "learning_rate": 1.6536638716733504e-05,
      "loss": 0.0502,
      "step": 4750
    },
    {
      "epoch": 1.7353262850893183,
      "grad_norm": 0.3284739851951599,
      "learning_rate": 1.6529347429821366e-05,
      "loss": 0.0345,
      "step": 4760
    },
    {
      "epoch": 1.7389719285453884,
      "grad_norm": 0.10627014935016632,
      "learning_rate": 1.6522056142909226e-05,
      "loss": 0.0499,
      "step": 4770
    },
    {
      "epoch": 1.7426175720014583,
      "grad_norm": 0.6257035136222839,
      "learning_rate": 1.6514764855997085e-05,
      "loss": 0.0638,
      "step": 4780
    },
    {
      "epoch": 1.7462632154575282,
      "grad_norm": 0.062387533485889435,
      "learning_rate": 1.6507473569084944e-05,
      "loss": 0.03,
      "step": 4790
    },
    {
      "epoch": 1.7499088589135983,
      "grad_norm": 0.23649698495864868,
      "learning_rate": 1.6500182282172806e-05,
      "loss": 0.063,
      "step": 4800
    },
    {
      "epoch": 1.7535545023696684,
      "grad_norm": 5.734347820281982,
      "learning_rate": 1.6492890995260666e-05,
      "loss": 0.1113,
      "step": 4810
    },
    {
      "epoch": 1.7572001458257382,
      "grad_norm": 0.9093871116638184,
      "learning_rate": 1.6485599708348525e-05,
      "loss": 0.0429,
      "step": 4820
    },
    {
      "epoch": 1.7608457892818081,
      "grad_norm": 0.28733959794044495,
      "learning_rate": 1.6478308421436384e-05,
      "loss": 0.0563,
      "step": 4830
    },
    {
      "epoch": 1.7644914327378782,
      "grad_norm": 4.500483989715576,
      "learning_rate": 1.6471017134524247e-05,
      "loss": 0.0373,
      "step": 4840
    },
    {
      "epoch": 1.7681370761939483,
      "grad_norm": 0.47276026010513306,
      "learning_rate": 1.6463725847612106e-05,
      "loss": 0.051,
      "step": 4850
    },
    {
      "epoch": 1.7717827196500182,
      "grad_norm": 1.4441766738891602,
      "learning_rate": 1.6456434560699965e-05,
      "loss": 0.0445,
      "step": 4860
    },
    {
      "epoch": 1.775428363106088,
      "grad_norm": 0.02931002713739872,
      "learning_rate": 1.6449143273787824e-05,
      "loss": 0.0153,
      "step": 4870
    },
    {
      "epoch": 1.7790740065621582,
      "grad_norm": 2.1712307929992676,
      "learning_rate": 1.6441851986875687e-05,
      "loss": 0.0064,
      "step": 4880
    },
    {
      "epoch": 1.7827196500182283,
      "grad_norm": 0.4373193681240082,
      "learning_rate": 1.6434560699963546e-05,
      "loss": 0.0093,
      "step": 4890
    },
    {
      "epoch": 1.7863652934742982,
      "grad_norm": 0.3035910129547119,
      "learning_rate": 1.6427269413051405e-05,
      "loss": 0.0991,
      "step": 4900
    },
    {
      "epoch": 1.790010936930368,
      "grad_norm": 4.116422176361084,
      "learning_rate": 1.6419978126139264e-05,
      "loss": 0.0778,
      "step": 4910
    },
    {
      "epoch": 1.7936565803864382,
      "grad_norm": 3.017059087753296,
      "learning_rate": 1.6412686839227127e-05,
      "loss": 0.0797,
      "step": 4920
    },
    {
      "epoch": 1.7973022238425083,
      "grad_norm": 32.403541564941406,
      "learning_rate": 1.6405395552314986e-05,
      "loss": 0.0459,
      "step": 4930
    },
    {
      "epoch": 1.8009478672985781,
      "grad_norm": 3.9560387134552,
      "learning_rate": 1.6398104265402845e-05,
      "loss": 0.0318,
      "step": 4940
    },
    {
      "epoch": 1.8045935107546482,
      "grad_norm": 0.7779421210289001,
      "learning_rate": 1.6390812978490704e-05,
      "loss": 0.0432,
      "step": 4950
    },
    {
      "epoch": 1.8082391542107183,
      "grad_norm": 3.6744768619537354,
      "learning_rate": 1.6383521691578567e-05,
      "loss": 0.0576,
      "step": 4960
    },
    {
      "epoch": 1.8118847976667882,
      "grad_norm": 0.21209576725959778,
      "learning_rate": 1.6376230404666426e-05,
      "loss": 0.0495,
      "step": 4970
    },
    {
      "epoch": 1.815530441122858,
      "grad_norm": 0.14712779223918915,
      "learning_rate": 1.6368939117754285e-05,
      "loss": 0.0599,
      "step": 4980
    },
    {
      "epoch": 1.8191760845789282,
      "grad_norm": 2.0321099758148193,
      "learning_rate": 1.6361647830842144e-05,
      "loss": 0.0077,
      "step": 4990
    },
    {
      "epoch": 1.8228217280349983,
      "grad_norm": 6.109596252441406,
      "learning_rate": 1.6354356543930007e-05,
      "loss": 0.0388,
      "step": 5000
    },
    {
      "epoch": 1.8264673714910682,
      "grad_norm": 0.207158625125885,
      "learning_rate": 1.6347065257017866e-05,
      "loss": 0.0381,
      "step": 5010
    },
    {
      "epoch": 1.830113014947138,
      "grad_norm": 8.272180557250977,
      "learning_rate": 1.6339773970105725e-05,
      "loss": 0.0958,
      "step": 5020
    },
    {
      "epoch": 1.8337586584032082,
      "grad_norm": 0.6294821500778198,
      "learning_rate": 1.6332482683193584e-05,
      "loss": 0.0312,
      "step": 5030
    },
    {
      "epoch": 1.8374043018592783,
      "grad_norm": 3.7365169525146484,
      "learning_rate": 1.6325191396281447e-05,
      "loss": 0.0637,
      "step": 5040
    },
    {
      "epoch": 1.8410499453153482,
      "grad_norm": 0.6557608246803284,
      "learning_rate": 1.6317900109369306e-05,
      "loss": 0.0149,
      "step": 5050
    },
    {
      "epoch": 1.844695588771418,
      "grad_norm": 8.046110153198242,
      "learning_rate": 1.6310608822457165e-05,
      "loss": 0.0306,
      "step": 5060
    },
    {
      "epoch": 1.8483412322274881,
      "grad_norm": 0.14041019976139069,
      "learning_rate": 1.6303317535545024e-05,
      "loss": 0.0484,
      "step": 5070
    },
    {
      "epoch": 1.8519868756835582,
      "grad_norm": 2.3270962238311768,
      "learning_rate": 1.6296026248632887e-05,
      "loss": 0.0544,
      "step": 5080
    },
    {
      "epoch": 1.8556325191396281,
      "grad_norm": 0.07275958359241486,
      "learning_rate": 1.6288734961720746e-05,
      "loss": 0.0435,
      "step": 5090
    },
    {
      "epoch": 1.859278162595698,
      "grad_norm": 9.077011108398438,
      "learning_rate": 1.6281443674808605e-05,
      "loss": 0.1135,
      "step": 5100
    },
    {
      "epoch": 1.862923806051768,
      "grad_norm": 0.07373521476984024,
      "learning_rate": 1.6274152387896464e-05,
      "loss": 0.029,
      "step": 5110
    },
    {
      "epoch": 1.8665694495078382,
      "grad_norm": 11.670869827270508,
      "learning_rate": 1.6266861100984327e-05,
      "loss": 0.0451,
      "step": 5120
    },
    {
      "epoch": 1.870215092963908,
      "grad_norm": 5.655535697937012,
      "learning_rate": 1.6259569814072186e-05,
      "loss": 0.0186,
      "step": 5130
    },
    {
      "epoch": 1.873860736419978,
      "grad_norm": 2.8484046459198,
      "learning_rate": 1.6252278527160045e-05,
      "loss": 0.0202,
      "step": 5140
    },
    {
      "epoch": 1.877506379876048,
      "grad_norm": 2.4667348861694336,
      "learning_rate": 1.6244987240247904e-05,
      "loss": 0.0423,
      "step": 5150
    },
    {
      "epoch": 1.8811520233321182,
      "grad_norm": 0.6709209680557251,
      "learning_rate": 1.6237695953335767e-05,
      "loss": 0.0471,
      "step": 5160
    },
    {
      "epoch": 1.884797666788188,
      "grad_norm": 2.98990797996521,
      "learning_rate": 1.6230404666423626e-05,
      "loss": 0.0675,
      "step": 5170
    },
    {
      "epoch": 1.8884433102442582,
      "grad_norm": 8.940446853637695,
      "learning_rate": 1.6223113379511485e-05,
      "loss": 0.0784,
      "step": 5180
    },
    {
      "epoch": 1.8920889537003283,
      "grad_norm": 0.5634245276451111,
      "learning_rate": 1.6215822092599344e-05,
      "loss": 0.0221,
      "step": 5190
    },
    {
      "epoch": 1.8957345971563981,
      "grad_norm": 0.04375767707824707,
      "learning_rate": 1.6208530805687207e-05,
      "loss": 0.0667,
      "step": 5200
    },
    {
      "epoch": 1.899380240612468,
      "grad_norm": 0.1094459667801857,
      "learning_rate": 1.6201239518775066e-05,
      "loss": 0.0479,
      "step": 5210
    },
    {
      "epoch": 1.9030258840685381,
      "grad_norm": 0.14363926649093628,
      "learning_rate": 1.6193948231862925e-05,
      "loss": 0.0532,
      "step": 5220
    },
    {
      "epoch": 1.9066715275246082,
      "grad_norm": 0.17535154521465302,
      "learning_rate": 1.6186656944950784e-05,
      "loss": 0.0176,
      "step": 5230
    },
    {
      "epoch": 1.910317170980678,
      "grad_norm": 1.1126048564910889,
      "learning_rate": 1.6179365658038647e-05,
      "loss": 0.0507,
      "step": 5240
    },
    {
      "epoch": 1.913962814436748,
      "grad_norm": 1.8439420461654663,
      "learning_rate": 1.6172074371126506e-05,
      "loss": 0.0155,
      "step": 5250
    },
    {
      "epoch": 1.917608457892818,
      "grad_norm": 0.009506331756711006,
      "learning_rate": 1.6164783084214365e-05,
      "loss": 0.0219,
      "step": 5260
    },
    {
      "epoch": 1.9212541013488882,
      "grad_norm": 5.467846393585205,
      "learning_rate": 1.6157491797302224e-05,
      "loss": 0.0375,
      "step": 5270
    },
    {
      "epoch": 1.924899744804958,
      "grad_norm": 0.02622915431857109,
      "learning_rate": 1.6150200510390087e-05,
      "loss": 0.091,
      "step": 5280
    },
    {
      "epoch": 1.928545388261028,
      "grad_norm": 1.3722898960113525,
      "learning_rate": 1.6142909223477946e-05,
      "loss": 0.0503,
      "step": 5290
    },
    {
      "epoch": 1.932191031717098,
      "grad_norm": 4.632193565368652,
      "learning_rate": 1.6135617936565805e-05,
      "loss": 0.0599,
      "step": 5300
    },
    {
      "epoch": 1.9358366751731682,
      "grad_norm": 2.0902931690216064,
      "learning_rate": 1.6128326649653664e-05,
      "loss": 0.0282,
      "step": 5310
    },
    {
      "epoch": 1.939482318629238,
      "grad_norm": 0.03624941036105156,
      "learning_rate": 1.6121035362741527e-05,
      "loss": 0.0104,
      "step": 5320
    },
    {
      "epoch": 1.943127962085308,
      "grad_norm": 0.09379804134368896,
      "learning_rate": 1.6113744075829386e-05,
      "loss": 0.0222,
      "step": 5330
    },
    {
      "epoch": 1.946773605541378,
      "grad_norm": 2.9816339015960693,
      "learning_rate": 1.6106452788917245e-05,
      "loss": 0.0495,
      "step": 5340
    },
    {
      "epoch": 1.9504192489974481,
      "grad_norm": 0.068691685795784,
      "learning_rate": 1.6099161502005104e-05,
      "loss": 0.0825,
      "step": 5350
    },
    {
      "epoch": 1.954064892453518,
      "grad_norm": 0.08208424597978592,
      "learning_rate": 1.6091870215092967e-05,
      "loss": 0.0432,
      "step": 5360
    },
    {
      "epoch": 1.9577105359095879,
      "grad_norm": 2.965930461883545,
      "learning_rate": 1.6084578928180826e-05,
      "loss": 0.0346,
      "step": 5370
    },
    {
      "epoch": 1.9613561793656582,
      "grad_norm": 0.024507170543074608,
      "learning_rate": 1.6077287641268685e-05,
      "loss": 0.0711,
      "step": 5380
    },
    {
      "epoch": 1.965001822821728,
      "grad_norm": 0.06999826431274414,
      "learning_rate": 1.6069996354356545e-05,
      "loss": 0.0242,
      "step": 5390
    },
    {
      "epoch": 1.968647466277798,
      "grad_norm": 0.09987325966358185,
      "learning_rate": 1.6062705067444407e-05,
      "loss": 0.0063,
      "step": 5400
    },
    {
      "epoch": 1.972293109733868,
      "grad_norm": 0.02087320387363434,
      "learning_rate": 1.6055413780532266e-05,
      "loss": 0.0187,
      "step": 5410
    },
    {
      "epoch": 1.9759387531899382,
      "grad_norm": 0.016905883327126503,
      "learning_rate": 1.6048122493620125e-05,
      "loss": 0.031,
      "step": 5420
    },
    {
      "epoch": 1.979584396646008,
      "grad_norm": 0.026778357103466988,
      "learning_rate": 1.6040831206707985e-05,
      "loss": 0.0223,
      "step": 5430
    },
    {
      "epoch": 1.983230040102078,
      "grad_norm": 0.06765738129615784,
      "learning_rate": 1.6033539919795847e-05,
      "loss": 0.055,
      "step": 5440
    },
    {
      "epoch": 1.986875683558148,
      "grad_norm": 8.38127326965332,
      "learning_rate": 1.6026248632883706e-05,
      "loss": 0.0315,
      "step": 5450
    },
    {
      "epoch": 1.9905213270142181,
      "grad_norm": 0.04643090441823006,
      "learning_rate": 1.6018957345971565e-05,
      "loss": 0.0285,
      "step": 5460
    },
    {
      "epoch": 1.994166970470288,
      "grad_norm": 1.1515026092529297,
      "learning_rate": 1.6011666059059425e-05,
      "loss": 0.0493,
      "step": 5470
    },
    {
      "epoch": 1.997812613926358,
      "grad_norm": 4.909876346588135,
      "learning_rate": 1.6004374772147287e-05,
      "loss": 0.0424,
      "step": 5480
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9859987223168655,
      "eval_f1": 0.9420321798545294,
      "eval_loss": 0.05066031217575073,
      "eval_precision": 0.9740200546946217,
      "eval_recall": 0.9120785317968416,
      "eval_runtime": 853.918,
      "eval_samples_per_second": 22.033,
      "eval_steps_per_second": 0.689,
      "step": 5486
    },
    {
      "epoch": 2.001458257382428,
      "grad_norm": 2.148604154586792,
      "learning_rate": 1.5997083485235146e-05,
      "loss": 0.0032,
      "step": 5490
    },
    {
      "epoch": 2.005103900838498,
      "grad_norm": 0.18511930108070374,
      "learning_rate": 1.5989792198323005e-05,
      "loss": 0.0705,
      "step": 5500
    },
    {
      "epoch": 2.008749544294568,
      "grad_norm": 9.199896812438965,
      "learning_rate": 1.5982500911410865e-05,
      "loss": 0.044,
      "step": 5510
    },
    {
      "epoch": 2.012395187750638,
      "grad_norm": 0.01271408423781395,
      "learning_rate": 1.5975209624498724e-05,
      "loss": 0.0086,
      "step": 5520
    },
    {
      "epoch": 2.016040831206708,
      "grad_norm": 0.09931720793247223,
      "learning_rate": 1.5967918337586586e-05,
      "loss": 0.0051,
      "step": 5530
    },
    {
      "epoch": 2.019686474662778,
      "grad_norm": 4.546739101409912,
      "learning_rate": 1.5960627050674446e-05,
      "loss": 0.0334,
      "step": 5540
    },
    {
      "epoch": 2.023332118118848,
      "grad_norm": 3.7648661136627197,
      "learning_rate": 1.5953335763762305e-05,
      "loss": 0.0463,
      "step": 5550
    },
    {
      "epoch": 2.026977761574918,
      "grad_norm": 0.01670559123158455,
      "learning_rate": 1.5946044476850164e-05,
      "loss": 0.0005,
      "step": 5560
    },
    {
      "epoch": 2.030623405030988,
      "grad_norm": 5.326959609985352,
      "learning_rate": 1.5938753189938026e-05,
      "loss": 0.0397,
      "step": 5570
    },
    {
      "epoch": 2.034269048487058,
      "grad_norm": 2.676378011703491,
      "learning_rate": 1.5931461903025886e-05,
      "loss": 0.049,
      "step": 5580
    },
    {
      "epoch": 2.037914691943128,
      "grad_norm": 0.01173839159309864,
      "learning_rate": 1.5924170616113745e-05,
      "loss": 0.0196,
      "step": 5590
    },
    {
      "epoch": 2.041560335399198,
      "grad_norm": 0.0704660713672638,
      "learning_rate": 1.5916879329201604e-05,
      "loss": 0.0083,
      "step": 5600
    },
    {
      "epoch": 2.045205978855268,
      "grad_norm": 1.8052263259887695,
      "learning_rate": 1.5909588042289466e-05,
      "loss": 0.0262,
      "step": 5610
    },
    {
      "epoch": 2.048851622311338,
      "grad_norm": 0.38510507345199585,
      "learning_rate": 1.5902296755377326e-05,
      "loss": 0.0233,
      "step": 5620
    },
    {
      "epoch": 2.052497265767408,
      "grad_norm": 0.012213978916406631,
      "learning_rate": 1.5895005468465185e-05,
      "loss": 0.0144,
      "step": 5630
    },
    {
      "epoch": 2.0561429092234778,
      "grad_norm": 0.38589373230934143,
      "learning_rate": 1.5887714181553044e-05,
      "loss": 0.0225,
      "step": 5640
    },
    {
      "epoch": 2.059788552679548,
      "grad_norm": 1.0169672966003418,
      "learning_rate": 1.5880422894640906e-05,
      "loss": 0.0107,
      "step": 5650
    },
    {
      "epoch": 2.063434196135618,
      "grad_norm": 0.0013868588721379638,
      "learning_rate": 1.5873131607728766e-05,
      "loss": 0.0298,
      "step": 5660
    },
    {
      "epoch": 2.067079839591688,
      "grad_norm": 12.736373901367188,
      "learning_rate": 1.5865840320816625e-05,
      "loss": 0.0442,
      "step": 5670
    },
    {
      "epoch": 2.0707254830477577,
      "grad_norm": 0.0051167611964046955,
      "learning_rate": 1.5858549033904484e-05,
      "loss": 0.0613,
      "step": 5680
    },
    {
      "epoch": 2.074371126503828,
      "grad_norm": 0.7056846618652344,
      "learning_rate": 1.5851257746992347e-05,
      "loss": 0.0009,
      "step": 5690
    },
    {
      "epoch": 2.078016769959898,
      "grad_norm": 0.8011111617088318,
      "learning_rate": 1.5843966460080206e-05,
      "loss": 0.0615,
      "step": 5700
    },
    {
      "epoch": 2.081662413415968,
      "grad_norm": 0.13622869551181793,
      "learning_rate": 1.5836675173168065e-05,
      "loss": 0.0327,
      "step": 5710
    },
    {
      "epoch": 2.085308056872038,
      "grad_norm": 5.590798854827881,
      "learning_rate": 1.5829383886255924e-05,
      "loss": 0.0669,
      "step": 5720
    },
    {
      "epoch": 2.088953700328108,
      "grad_norm": 1.72411048412323,
      "learning_rate": 1.5822092599343787e-05,
      "loss": 0.0212,
      "step": 5730
    },
    {
      "epoch": 2.092599343784178,
      "grad_norm": 3.1002309322357178,
      "learning_rate": 1.5814801312431646e-05,
      "loss": 0.0131,
      "step": 5740
    },
    {
      "epoch": 2.0962449872402478,
      "grad_norm": 4.005125522613525,
      "learning_rate": 1.5807510025519505e-05,
      "loss": 0.0536,
      "step": 5750
    },
    {
      "epoch": 2.099890630696318,
      "grad_norm": 2.617070436477661,
      "learning_rate": 1.5800218738607364e-05,
      "loss": 0.0373,
      "step": 5760
    },
    {
      "epoch": 2.103536274152388,
      "grad_norm": 2.937260389328003,
      "learning_rate": 1.5792927451695227e-05,
      "loss": 0.0288,
      "step": 5770
    },
    {
      "epoch": 2.107181917608458,
      "grad_norm": 0.16633205115795135,
      "learning_rate": 1.5785636164783086e-05,
      "loss": 0.0409,
      "step": 5780
    },
    {
      "epoch": 2.1108275610645277,
      "grad_norm": 0.7548664808273315,
      "learning_rate": 1.5778344877870945e-05,
      "loss": 0.0147,
      "step": 5790
    },
    {
      "epoch": 2.114473204520598,
      "grad_norm": 0.004282426554709673,
      "learning_rate": 1.5771053590958804e-05,
      "loss": 0.0629,
      "step": 5800
    },
    {
      "epoch": 2.118118847976668,
      "grad_norm": 1.9895153045654297,
      "learning_rate": 1.5763762304046667e-05,
      "loss": 0.0171,
      "step": 5810
    },
    {
      "epoch": 2.121764491432738,
      "grad_norm": 0.2863493859767914,
      "learning_rate": 1.5756471017134526e-05,
      "loss": 0.0199,
      "step": 5820
    },
    {
      "epoch": 2.1254101348888077,
      "grad_norm": 0.2798742949962616,
      "learning_rate": 1.5749179730222385e-05,
      "loss": 0.0493,
      "step": 5830
    },
    {
      "epoch": 2.129055778344878,
      "grad_norm": 1.3518327474594116,
      "learning_rate": 1.5741888443310244e-05,
      "loss": 0.0482,
      "step": 5840
    },
    {
      "epoch": 2.132701421800948,
      "grad_norm": 0.0453493632376194,
      "learning_rate": 1.5734597156398107e-05,
      "loss": 0.0224,
      "step": 5850
    },
    {
      "epoch": 2.136347065257018,
      "grad_norm": 0.06742439419031143,
      "learning_rate": 1.5727305869485966e-05,
      "loss": 0.0157,
      "step": 5860
    },
    {
      "epoch": 2.1399927087130877,
      "grad_norm": 20.378183364868164,
      "learning_rate": 1.5720014582573825e-05,
      "loss": 0.0191,
      "step": 5870
    },
    {
      "epoch": 2.143638352169158,
      "grad_norm": 6.957069396972656,
      "learning_rate": 1.5712723295661684e-05,
      "loss": 0.0878,
      "step": 5880
    },
    {
      "epoch": 2.147283995625228,
      "grad_norm": 0.5563385486602783,
      "learning_rate": 1.5705432008749547e-05,
      "loss": 0.0405,
      "step": 5890
    },
    {
      "epoch": 2.1509296390812978,
      "grad_norm": 0.0883517935872078,
      "learning_rate": 1.5698140721837406e-05,
      "loss": 0.0447,
      "step": 5900
    },
    {
      "epoch": 2.154575282537368,
      "grad_norm": 2.8002517223358154,
      "learning_rate": 1.5690849434925265e-05,
      "loss": 0.0163,
      "step": 5910
    },
    {
      "epoch": 2.158220925993438,
      "grad_norm": 0.04935910925269127,
      "learning_rate": 1.5683558148013124e-05,
      "loss": 0.0664,
      "step": 5920
    },
    {
      "epoch": 2.161866569449508,
      "grad_norm": 3.1945536136627197,
      "learning_rate": 1.5676266861100987e-05,
      "loss": 0.0321,
      "step": 5930
    },
    {
      "epoch": 2.1655122129055777,
      "grad_norm": 0.8343412280082703,
      "learning_rate": 1.5668975574188846e-05,
      "loss": 0.0187,
      "step": 5940
    },
    {
      "epoch": 2.1691578563616476,
      "grad_norm": 0.6203622221946716,
      "learning_rate": 1.5661684287276705e-05,
      "loss": 0.0145,
      "step": 5950
    },
    {
      "epoch": 2.172803499817718,
      "grad_norm": 8.463240623474121,
      "learning_rate": 1.5654393000364564e-05,
      "loss": 0.047,
      "step": 5960
    },
    {
      "epoch": 2.176449143273788,
      "grad_norm": 0.00925416313111782,
      "learning_rate": 1.5647101713452427e-05,
      "loss": 0.0168,
      "step": 5970
    },
    {
      "epoch": 2.1800947867298577,
      "grad_norm": 0.005526332650333643,
      "learning_rate": 1.5639810426540286e-05,
      "loss": 0.0161,
      "step": 5980
    },
    {
      "epoch": 2.183740430185928,
      "grad_norm": 0.013225138187408447,
      "learning_rate": 1.5632519139628145e-05,
      "loss": 0.0298,
      "step": 5990
    },
    {
      "epoch": 2.187386073641998,
      "grad_norm": 20.271747589111328,
      "learning_rate": 1.5625227852716004e-05,
      "loss": 0.0474,
      "step": 6000
    },
    {
      "epoch": 2.1910317170980678,
      "grad_norm": 1.760769248008728,
      "learning_rate": 1.5617936565803867e-05,
      "loss": 0.0322,
      "step": 6010
    },
    {
      "epoch": 2.1946773605541376,
      "grad_norm": 1.1777373552322388,
      "learning_rate": 1.5610645278891726e-05,
      "loss": 0.0579,
      "step": 6020
    },
    {
      "epoch": 2.198323004010208,
      "grad_norm": 0.6114841103553772,
      "learning_rate": 1.5603353991979585e-05,
      "loss": 0.0247,
      "step": 6030
    },
    {
      "epoch": 2.201968647466278,
      "grad_norm": 4.023649215698242,
      "learning_rate": 1.5596062705067444e-05,
      "loss": 0.0273,
      "step": 6040
    },
    {
      "epoch": 2.2056142909223477,
      "grad_norm": 0.47622665762901306,
      "learning_rate": 1.5588771418155307e-05,
      "loss": 0.0282,
      "step": 6050
    },
    {
      "epoch": 2.2092599343784176,
      "grad_norm": 2.288911819458008,
      "learning_rate": 1.5581480131243166e-05,
      "loss": 0.0156,
      "step": 6060
    },
    {
      "epoch": 2.212905577834488,
      "grad_norm": 1.5672290325164795,
      "learning_rate": 1.5574188844331025e-05,
      "loss": 0.0257,
      "step": 6070
    },
    {
      "epoch": 2.216551221290558,
      "grad_norm": 4.3078718185424805,
      "learning_rate": 1.5566897557418884e-05,
      "loss": 0.018,
      "step": 6080
    },
    {
      "epoch": 2.2201968647466277,
      "grad_norm": 0.009063484147191048,
      "learning_rate": 1.5559606270506747e-05,
      "loss": 0.0336,
      "step": 6090
    },
    {
      "epoch": 2.2238425082026976,
      "grad_norm": 0.002119428012520075,
      "learning_rate": 1.5552314983594606e-05,
      "loss": 0.0189,
      "step": 6100
    },
    {
      "epoch": 2.227488151658768,
      "grad_norm": 0.6584022045135498,
      "learning_rate": 1.5545023696682465e-05,
      "loss": 0.0195,
      "step": 6110
    },
    {
      "epoch": 2.231133795114838,
      "grad_norm": 0.002013295656070113,
      "learning_rate": 1.5537732409770324e-05,
      "loss": 0.008,
      "step": 6120
    },
    {
      "epoch": 2.2347794385709077,
      "grad_norm": 12.979530334472656,
      "learning_rate": 1.5530441122858187e-05,
      "loss": 0.0408,
      "step": 6130
    },
    {
      "epoch": 2.2384250820269775,
      "grad_norm": 0.3064662218093872,
      "learning_rate": 1.5523149835946046e-05,
      "loss": 0.0213,
      "step": 6140
    },
    {
      "epoch": 2.242070725483048,
      "grad_norm": 0.09097961336374283,
      "learning_rate": 1.5515858549033905e-05,
      "loss": 0.0194,
      "step": 6150
    },
    {
      "epoch": 2.2457163689391177,
      "grad_norm": 3.380430221557617,
      "learning_rate": 1.5508567262121764e-05,
      "loss": 0.0513,
      "step": 6160
    },
    {
      "epoch": 2.2493620123951876,
      "grad_norm": 1.1676663160324097,
      "learning_rate": 1.5501275975209627e-05,
      "loss": 0.0203,
      "step": 6170
    },
    {
      "epoch": 2.253007655851258,
      "grad_norm": 9.000951766967773,
      "learning_rate": 1.5493984688297486e-05,
      "loss": 0.0212,
      "step": 6180
    },
    {
      "epoch": 2.256653299307328,
      "grad_norm": 0.005927887745201588,
      "learning_rate": 1.5486693401385345e-05,
      "loss": 0.0102,
      "step": 6190
    },
    {
      "epoch": 2.2602989427633977,
      "grad_norm": 0.013734190724790096,
      "learning_rate": 1.5479402114473205e-05,
      "loss": 0.0347,
      "step": 6200
    },
    {
      "epoch": 2.2639445862194676,
      "grad_norm": 0.011983872391283512,
      "learning_rate": 1.5472110827561067e-05,
      "loss": 0.0221,
      "step": 6210
    },
    {
      "epoch": 2.267590229675538,
      "grad_norm": 15.96644401550293,
      "learning_rate": 1.5464819540648926e-05,
      "loss": 0.0808,
      "step": 6220
    },
    {
      "epoch": 2.271235873131608,
      "grad_norm": 1.1531577110290527,
      "learning_rate": 1.5457528253736785e-05,
      "loss": 0.0279,
      "step": 6230
    },
    {
      "epoch": 2.2748815165876777,
      "grad_norm": 8.776226043701172,
      "learning_rate": 1.5450236966824645e-05,
      "loss": 0.0195,
      "step": 6240
    },
    {
      "epoch": 2.2785271600437476,
      "grad_norm": 0.0962221622467041,
      "learning_rate": 1.5442945679912507e-05,
      "loss": 0.082,
      "step": 6250
    },
    {
      "epoch": 2.282172803499818,
      "grad_norm": 0.044043317437171936,
      "learning_rate": 1.5435654393000366e-05,
      "loss": 0.053,
      "step": 6260
    },
    {
      "epoch": 2.2858184469558878,
      "grad_norm": 0.14803431928157806,
      "learning_rate": 1.5428363106088225e-05,
      "loss": 0.0399,
      "step": 6270
    },
    {
      "epoch": 2.2894640904119576,
      "grad_norm": 0.2378372699022293,
      "learning_rate": 1.5421071819176085e-05,
      "loss": 0.0146,
      "step": 6280
    },
    {
      "epoch": 2.2931097338680275,
      "grad_norm": 0.4921732544898987,
      "learning_rate": 1.5413780532263947e-05,
      "loss": 0.0213,
      "step": 6290
    },
    {
      "epoch": 2.296755377324098,
      "grad_norm": 0.004560412839055061,
      "learning_rate": 1.5406489245351806e-05,
      "loss": 0.0122,
      "step": 6300
    },
    {
      "epoch": 2.3004010207801677,
      "grad_norm": 0.04691297933459282,
      "learning_rate": 1.5399197958439665e-05,
      "loss": 0.0186,
      "step": 6310
    },
    {
      "epoch": 2.3040466642362376,
      "grad_norm": 0.008545019663870335,
      "learning_rate": 1.5391906671527525e-05,
      "loss": 0.0195,
      "step": 6320
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.22544807195663452,
      "learning_rate": 1.5384615384615387e-05,
      "loss": 0.019,
      "step": 6330
    },
    {
      "epoch": 2.311337951148378,
      "grad_norm": 0.026703285053372383,
      "learning_rate": 1.5377324097703246e-05,
      "loss": 0.0017,
      "step": 6340
    },
    {
      "epoch": 2.3149835946044477,
      "grad_norm": 0.005078947637230158,
      "learning_rate": 1.5370032810791106e-05,
      "loss": 0.0068,
      "step": 6350
    },
    {
      "epoch": 2.3186292380605176,
      "grad_norm": 0.014487572945654392,
      "learning_rate": 1.5362741523878965e-05,
      "loss": 0.06,
      "step": 6360
    },
    {
      "epoch": 2.322274881516588,
      "grad_norm": 19.377012252807617,
      "learning_rate": 1.5355450236966827e-05,
      "loss": 0.0178,
      "step": 6370
    },
    {
      "epoch": 2.3259205249726578,
      "grad_norm": 0.009077128954231739,
      "learning_rate": 1.5348158950054686e-05,
      "loss": 0.0199,
      "step": 6380
    },
    {
      "epoch": 2.3295661684287277,
      "grad_norm": 5.729573726654053,
      "learning_rate": 1.5340867663142546e-05,
      "loss": 0.0098,
      "step": 6390
    },
    {
      "epoch": 2.3332118118847975,
      "grad_norm": 5.086490631103516,
      "learning_rate": 1.5333576376230405e-05,
      "loss": 0.0598,
      "step": 6400
    },
    {
      "epoch": 2.3368574553408674,
      "grad_norm": 0.029246388003230095,
      "learning_rate": 1.5326285089318267e-05,
      "loss": 0.0245,
      "step": 6410
    },
    {
      "epoch": 2.3405030987969377,
      "grad_norm": 0.012645930051803589,
      "learning_rate": 1.5318993802406126e-05,
      "loss": 0.0271,
      "step": 6420
    },
    {
      "epoch": 2.3441487422530076,
      "grad_norm": 0.04498552531003952,
      "learning_rate": 1.5311702515493986e-05,
      "loss": 0.0268,
      "step": 6430
    },
    {
      "epoch": 2.3477943857090775,
      "grad_norm": 1.3604881763458252,
      "learning_rate": 1.5304411228581845e-05,
      "loss": 0.0222,
      "step": 6440
    },
    {
      "epoch": 2.351440029165148,
      "grad_norm": 1.2815618515014648,
      "learning_rate": 1.5297119941669707e-05,
      "loss": 0.0363,
      "step": 6450
    },
    {
      "epoch": 2.3550856726212177,
      "grad_norm": 0.10490244626998901,
      "learning_rate": 1.5289828654757566e-05,
      "loss": 0.0708,
      "step": 6460
    },
    {
      "epoch": 2.3587313160772876,
      "grad_norm": 0.15977071225643158,
      "learning_rate": 1.5282537367845426e-05,
      "loss": 0.0392,
      "step": 6470
    },
    {
      "epoch": 2.3623769595333575,
      "grad_norm": 0.035217929631471634,
      "learning_rate": 1.5275246080933285e-05,
      "loss": 0.0052,
      "step": 6480
    },
    {
      "epoch": 2.366022602989428,
      "grad_norm": 0.0761946439743042,
      "learning_rate": 1.5267954794021147e-05,
      "loss": 0.0261,
      "step": 6490
    },
    {
      "epoch": 2.3696682464454977,
      "grad_norm": 0.006811619270592928,
      "learning_rate": 1.5260663507109007e-05,
      "loss": 0.0718,
      "step": 6500
    },
    {
      "epoch": 2.3733138899015676,
      "grad_norm": 2.2824254035949707,
      "learning_rate": 1.5253372220196867e-05,
      "loss": 0.0131,
      "step": 6510
    },
    {
      "epoch": 2.3769595333576374,
      "grad_norm": 0.4073787033557892,
      "learning_rate": 1.5246080933284727e-05,
      "loss": 0.0597,
      "step": 6520
    },
    {
      "epoch": 2.3806051768137078,
      "grad_norm": 1.3373160362243652,
      "learning_rate": 1.5238789646372587e-05,
      "loss": 0.0176,
      "step": 6530
    },
    {
      "epoch": 2.3842508202697776,
      "grad_norm": 0.004595518112182617,
      "learning_rate": 1.5231498359460447e-05,
      "loss": 0.0047,
      "step": 6540
    },
    {
      "epoch": 2.3878964637258475,
      "grad_norm": 0.0057419901713728905,
      "learning_rate": 1.5224207072548307e-05,
      "loss": 0.0509,
      "step": 6550
    },
    {
      "epoch": 2.391542107181918,
      "grad_norm": 1.71909761428833,
      "learning_rate": 1.5216915785636167e-05,
      "loss": 0.0271,
      "step": 6560
    },
    {
      "epoch": 2.3951877506379877,
      "grad_norm": 0.0864870473742485,
      "learning_rate": 1.5209624498724027e-05,
      "loss": 0.0472,
      "step": 6570
    },
    {
      "epoch": 2.3988333940940576,
      "grad_norm": 0.18788708746433258,
      "learning_rate": 1.5202333211811887e-05,
      "loss": 0.0229,
      "step": 6580
    },
    {
      "epoch": 2.4024790375501275,
      "grad_norm": 0.009504301473498344,
      "learning_rate": 1.5195041924899746e-05,
      "loss": 0.0278,
      "step": 6590
    },
    {
      "epoch": 2.4061246810061974,
      "grad_norm": 0.006075868383049965,
      "learning_rate": 1.5187750637987607e-05,
      "loss": 0.0451,
      "step": 6600
    },
    {
      "epoch": 2.4097703244622677,
      "grad_norm": 0.05711092799901962,
      "learning_rate": 1.5180459351075466e-05,
      "loss": 0.03,
      "step": 6610
    },
    {
      "epoch": 2.4134159679183376,
      "grad_norm": 0.04618803784251213,
      "learning_rate": 1.5173168064163327e-05,
      "loss": 0.0438,
      "step": 6620
    },
    {
      "epoch": 2.4170616113744074,
      "grad_norm": 0.6317053437232971,
      "learning_rate": 1.5165876777251186e-05,
      "loss": 0.0366,
      "step": 6630
    },
    {
      "epoch": 2.4207072548304778,
      "grad_norm": 0.07952603697776794,
      "learning_rate": 1.5158585490339047e-05,
      "loss": 0.0226,
      "step": 6640
    },
    {
      "epoch": 2.4243528982865477,
      "grad_norm": 0.14798888564109802,
      "learning_rate": 1.5151294203426906e-05,
      "loss": 0.0276,
      "step": 6650
    },
    {
      "epoch": 2.4279985417426175,
      "grad_norm": 9.458075523376465,
      "learning_rate": 1.5144002916514767e-05,
      "loss": 0.0447,
      "step": 6660
    },
    {
      "epoch": 2.4316441851986874,
      "grad_norm": 0.7710935473442078,
      "learning_rate": 1.5136711629602626e-05,
      "loss": 0.0448,
      "step": 6670
    },
    {
      "epoch": 2.4352898286547577,
      "grad_norm": 0.12258506566286087,
      "learning_rate": 1.5129420342690487e-05,
      "loss": 0.0326,
      "step": 6680
    },
    {
      "epoch": 2.4389354721108276,
      "grad_norm": 2.027982711791992,
      "learning_rate": 1.5122129055778346e-05,
      "loss": 0.0506,
      "step": 6690
    },
    {
      "epoch": 2.4425811155668975,
      "grad_norm": 2.046872854232788,
      "learning_rate": 1.5114837768866207e-05,
      "loss": 0.0202,
      "step": 6700
    },
    {
      "epoch": 2.4462267590229674,
      "grad_norm": 0.057607073336839676,
      "learning_rate": 1.5107546481954066e-05,
      "loss": 0.0305,
      "step": 6710
    },
    {
      "epoch": 2.4498724024790377,
      "grad_norm": 0.21088431775569916,
      "learning_rate": 1.5100255195041927e-05,
      "loss": 0.0197,
      "step": 6720
    },
    {
      "epoch": 2.4535180459351076,
      "grad_norm": 0.05022674798965454,
      "learning_rate": 1.5092963908129786e-05,
      "loss": 0.0308,
      "step": 6730
    },
    {
      "epoch": 2.4571636893911775,
      "grad_norm": 0.25364646315574646,
      "learning_rate": 1.5085672621217647e-05,
      "loss": 0.0186,
      "step": 6740
    },
    {
      "epoch": 2.460809332847248,
      "grad_norm": 0.12485034018754959,
      "learning_rate": 1.5078381334305506e-05,
      "loss": 0.0745,
      "step": 6750
    },
    {
      "epoch": 2.4644549763033177,
      "grad_norm": 0.05581443011760712,
      "learning_rate": 1.5071090047393367e-05,
      "loss": 0.0435,
      "step": 6760
    },
    {
      "epoch": 2.4681006197593875,
      "grad_norm": 0.02855716273188591,
      "learning_rate": 1.5063798760481226e-05,
      "loss": 0.0383,
      "step": 6770
    },
    {
      "epoch": 2.4717462632154574,
      "grad_norm": 0.09820384532213211,
      "learning_rate": 1.5056507473569087e-05,
      "loss": 0.0272,
      "step": 6780
    },
    {
      "epoch": 2.4753919066715273,
      "grad_norm": 2.72711181640625,
      "learning_rate": 1.5049216186656946e-05,
      "loss": 0.0097,
      "step": 6790
    },
    {
      "epoch": 2.4790375501275976,
      "grad_norm": 0.014756860211491585,
      "learning_rate": 1.5041924899744807e-05,
      "loss": 0.0079,
      "step": 6800
    },
    {
      "epoch": 2.4826831935836675,
      "grad_norm": 0.3462936580181122,
      "learning_rate": 1.5034633612832666e-05,
      "loss": 0.0083,
      "step": 6810
    },
    {
      "epoch": 2.4863288370397374,
      "grad_norm": 5.441719055175781,
      "learning_rate": 1.5027342325920527e-05,
      "loss": 0.0646,
      "step": 6820
    },
    {
      "epoch": 2.4899744804958077,
      "grad_norm": 7.3062825202941895,
      "learning_rate": 1.5020051039008386e-05,
      "loss": 0.0641,
      "step": 6830
    },
    {
      "epoch": 2.4936201239518776,
      "grad_norm": 0.20437584817409515,
      "learning_rate": 1.5012759752096247e-05,
      "loss": 0.0189,
      "step": 6840
    },
    {
      "epoch": 2.4972657674079475,
      "grad_norm": 0.304916113615036,
      "learning_rate": 1.5005468465184106e-05,
      "loss": 0.0395,
      "step": 6850
    },
    {
      "epoch": 2.5009114108640174,
      "grad_norm": 0.05353918671607971,
      "learning_rate": 1.4998177178271967e-05,
      "loss": 0.0317,
      "step": 6860
    },
    {
      "epoch": 2.5045570543200872,
      "grad_norm": 0.06370289623737335,
      "learning_rate": 1.4990885891359826e-05,
      "loss": 0.0324,
      "step": 6870
    },
    {
      "epoch": 2.5082026977761576,
      "grad_norm": 0.005622644908726215,
      "learning_rate": 1.4983594604447687e-05,
      "loss": 0.0286,
      "step": 6880
    },
    {
      "epoch": 2.5118483412322274,
      "grad_norm": 3.4763917922973633,
      "learning_rate": 1.4976303317535546e-05,
      "loss": 0.0591,
      "step": 6890
    },
    {
      "epoch": 2.5154939846882973,
      "grad_norm": 4.871367454528809,
      "learning_rate": 1.4969012030623407e-05,
      "loss": 0.0146,
      "step": 6900
    },
    {
      "epoch": 2.5191396281443676,
      "grad_norm": 1.6499037742614746,
      "learning_rate": 1.4961720743711266e-05,
      "loss": 0.0125,
      "step": 6910
    },
    {
      "epoch": 2.5227852716004375,
      "grad_norm": 0.029545847326517105,
      "learning_rate": 1.4954429456799127e-05,
      "loss": 0.0492,
      "step": 6920
    },
    {
      "epoch": 2.5264309150565074,
      "grad_norm": 0.012362511828541756,
      "learning_rate": 1.4947138169886986e-05,
      "loss": 0.0013,
      "step": 6930
    },
    {
      "epoch": 2.5300765585125777,
      "grad_norm": 46.249107360839844,
      "learning_rate": 1.4939846882974847e-05,
      "loss": 0.0603,
      "step": 6940
    },
    {
      "epoch": 2.5337222019686476,
      "grad_norm": 0.40153321623802185,
      "learning_rate": 1.4932555596062706e-05,
      "loss": 0.0308,
      "step": 6950
    },
    {
      "epoch": 2.5373678454247175,
      "grad_norm": 0.14856231212615967,
      "learning_rate": 1.4925264309150567e-05,
      "loss": 0.0071,
      "step": 6960
    },
    {
      "epoch": 2.5410134888807874,
      "grad_norm": 0.04863794520497322,
      "learning_rate": 1.4917973022238426e-05,
      "loss": 0.0257,
      "step": 6970
    },
    {
      "epoch": 2.5446591323368573,
      "grad_norm": 0.03989901393651962,
      "learning_rate": 1.4910681735326287e-05,
      "loss": 0.021,
      "step": 6980
    },
    {
      "epoch": 2.5483047757929276,
      "grad_norm": 0.03260471671819687,
      "learning_rate": 1.4903390448414146e-05,
      "loss": 0.06,
      "step": 6990
    },
    {
      "epoch": 2.5519504192489975,
      "grad_norm": 0.4581117630004883,
      "learning_rate": 1.4896099161502007e-05,
      "loss": 0.0207,
      "step": 7000
    },
    {
      "epoch": 2.5555960627050673,
      "grad_norm": 0.02208132855594158,
      "learning_rate": 1.4888807874589866e-05,
      "loss": 0.0481,
      "step": 7010
    },
    {
      "epoch": 2.5592417061611377,
      "grad_norm": 0.26878559589385986,
      "learning_rate": 1.4881516587677727e-05,
      "loss": 0.0149,
      "step": 7020
    },
    {
      "epoch": 2.5628873496172075,
      "grad_norm": 0.034860849380493164,
      "learning_rate": 1.4874225300765586e-05,
      "loss": 0.0127,
      "step": 7030
    },
    {
      "epoch": 2.5665329930732774,
      "grad_norm": 2.4172120094299316,
      "learning_rate": 1.4866934013853447e-05,
      "loss": 0.0086,
      "step": 7040
    },
    {
      "epoch": 2.5701786365293473,
      "grad_norm": 0.17971287667751312,
      "learning_rate": 1.4859642726941306e-05,
      "loss": 0.0599,
      "step": 7050
    },
    {
      "epoch": 2.573824279985417,
      "grad_norm": 0.013764613308012486,
      "learning_rate": 1.4852351440029167e-05,
      "loss": 0.0154,
      "step": 7060
    },
    {
      "epoch": 2.5774699234414875,
      "grad_norm": 0.05219440534710884,
      "learning_rate": 1.4845060153117026e-05,
      "loss": 0.0186,
      "step": 7070
    },
    {
      "epoch": 2.5811155668975574,
      "grad_norm": 0.06069507822394371,
      "learning_rate": 1.4837768866204887e-05,
      "loss": 0.0054,
      "step": 7080
    },
    {
      "epoch": 2.5847612103536273,
      "grad_norm": 3.57930326461792,
      "learning_rate": 1.4830477579292746e-05,
      "loss": 0.0179,
      "step": 7090
    },
    {
      "epoch": 2.5884068538096976,
      "grad_norm": 0.8295373320579529,
      "learning_rate": 1.4823186292380607e-05,
      "loss": 0.0335,
      "step": 7100
    },
    {
      "epoch": 2.5920524972657675,
      "grad_norm": 0.18189983069896698,
      "learning_rate": 1.4815895005468466e-05,
      "loss": 0.0135,
      "step": 7110
    },
    {
      "epoch": 2.5956981407218374,
      "grad_norm": 0.004485203884541988,
      "learning_rate": 1.4808603718556327e-05,
      "loss": 0.0092,
      "step": 7120
    },
    {
      "epoch": 2.5993437841779072,
      "grad_norm": 4.874934673309326,
      "learning_rate": 1.4801312431644186e-05,
      "loss": 0.0303,
      "step": 7130
    },
    {
      "epoch": 2.6029894276339776,
      "grad_norm": 15.465889930725098,
      "learning_rate": 1.4794021144732047e-05,
      "loss": 0.0413,
      "step": 7140
    },
    {
      "epoch": 2.6066350710900474,
      "grad_norm": 0.05760233476758003,
      "learning_rate": 1.4786729857819906e-05,
      "loss": 0.0348,
      "step": 7150
    },
    {
      "epoch": 2.6102807145461173,
      "grad_norm": 3.160236120223999,
      "learning_rate": 1.4779438570907767e-05,
      "loss": 0.0158,
      "step": 7160
    },
    {
      "epoch": 2.613926358002187,
      "grad_norm": 0.005412140861153603,
      "learning_rate": 1.4772147283995626e-05,
      "loss": 0.032,
      "step": 7170
    },
    {
      "epoch": 2.6175720014582575,
      "grad_norm": 0.0870506688952446,
      "learning_rate": 1.4764855997083487e-05,
      "loss": 0.0163,
      "step": 7180
    },
    {
      "epoch": 2.6212176449143274,
      "grad_norm": 3.6903748512268066,
      "learning_rate": 1.4757564710171346e-05,
      "loss": 0.0412,
      "step": 7190
    },
    {
      "epoch": 2.6248632883703973,
      "grad_norm": 1.6499462127685547,
      "learning_rate": 1.4750273423259207e-05,
      "loss": 0.0802,
      "step": 7200
    },
    {
      "epoch": 2.6285089318264676,
      "grad_norm": 0.500217616558075,
      "learning_rate": 1.4742982136347066e-05,
      "loss": 0.0556,
      "step": 7210
    },
    {
      "epoch": 2.6321545752825375,
      "grad_norm": 0.8197486996650696,
      "learning_rate": 1.4735690849434927e-05,
      "loss": 0.0331,
      "step": 7220
    },
    {
      "epoch": 2.6358002187386074,
      "grad_norm": 0.05614370480179787,
      "learning_rate": 1.4728399562522786e-05,
      "loss": 0.0282,
      "step": 7230
    },
    {
      "epoch": 2.6394458621946773,
      "grad_norm": 0.4123819172382355,
      "learning_rate": 1.4721108275610647e-05,
      "loss": 0.0192,
      "step": 7240
    },
    {
      "epoch": 2.643091505650747,
      "grad_norm": 0.032924629747867584,
      "learning_rate": 1.4713816988698506e-05,
      "loss": 0.0534,
      "step": 7250
    },
    {
      "epoch": 2.6467371491068175,
      "grad_norm": 0.29794907569885254,
      "learning_rate": 1.4706525701786367e-05,
      "loss": 0.0183,
      "step": 7260
    },
    {
      "epoch": 2.6503827925628873,
      "grad_norm": 0.05429622903466225,
      "learning_rate": 1.4699234414874226e-05,
      "loss": 0.007,
      "step": 7270
    },
    {
      "epoch": 2.654028436018957,
      "grad_norm": 0.3228699564933777,
      "learning_rate": 1.4691943127962087e-05,
      "loss": 0.0067,
      "step": 7280
    },
    {
      "epoch": 2.6576740794750275,
      "grad_norm": 6.581894874572754,
      "learning_rate": 1.4684651841049946e-05,
      "loss": 0.0317,
      "step": 7290
    },
    {
      "epoch": 2.6613197229310974,
      "grad_norm": 2.974959373474121,
      "learning_rate": 1.4677360554137807e-05,
      "loss": 0.0348,
      "step": 7300
    },
    {
      "epoch": 2.6649653663871673,
      "grad_norm": 7.057903289794922,
      "learning_rate": 1.4670069267225666e-05,
      "loss": 0.0838,
      "step": 7310
    },
    {
      "epoch": 2.668611009843237,
      "grad_norm": 0.9449300765991211,
      "learning_rate": 1.4662777980313527e-05,
      "loss": 0.0053,
      "step": 7320
    },
    {
      "epoch": 2.672256653299307,
      "grad_norm": 3.998908758163452,
      "learning_rate": 1.4655486693401386e-05,
      "loss": 0.0654,
      "step": 7330
    },
    {
      "epoch": 2.6759022967553774,
      "grad_norm": 0.012597933411598206,
      "learning_rate": 1.4648195406489247e-05,
      "loss": 0.0037,
      "step": 7340
    },
    {
      "epoch": 2.6795479402114473,
      "grad_norm": 0.0927485004067421,
      "learning_rate": 1.4640904119577107e-05,
      "loss": 0.0405,
      "step": 7350
    },
    {
      "epoch": 2.683193583667517,
      "grad_norm": 0.5784786939620972,
      "learning_rate": 1.4633612832664967e-05,
      "loss": 0.0153,
      "step": 7360
    },
    {
      "epoch": 2.6868392271235875,
      "grad_norm": 4.942211151123047,
      "learning_rate": 1.4626321545752827e-05,
      "loss": 0.0634,
      "step": 7370
    },
    {
      "epoch": 2.6904848705796574,
      "grad_norm": 0.08537252992391586,
      "learning_rate": 1.4619030258840687e-05,
      "loss": 0.0058,
      "step": 7380
    },
    {
      "epoch": 2.6941305140357272,
      "grad_norm": 6.190989971160889,
      "learning_rate": 1.4611738971928547e-05,
      "loss": 0.062,
      "step": 7390
    },
    {
      "epoch": 2.6977761574917976,
      "grad_norm": 1.377833604812622,
      "learning_rate": 1.4604447685016407e-05,
      "loss": 0.0282,
      "step": 7400
    },
    {
      "epoch": 2.7014218009478674,
      "grad_norm": 2.404670238494873,
      "learning_rate": 1.4597156398104267e-05,
      "loss": 0.0493,
      "step": 7410
    },
    {
      "epoch": 2.7050674444039373,
      "grad_norm": 4.733008861541748,
      "learning_rate": 1.4589865111192127e-05,
      "loss": 0.0487,
      "step": 7420
    },
    {
      "epoch": 2.708713087860007,
      "grad_norm": 3.8026082515716553,
      "learning_rate": 1.4582573824279987e-05,
      "loss": 0.0237,
      "step": 7430
    },
    {
      "epoch": 2.712358731316077,
      "grad_norm": 11.663143157958984,
      "learning_rate": 1.4575282537367847e-05,
      "loss": 0.0221,
      "step": 7440
    },
    {
      "epoch": 2.7160043747721474,
      "grad_norm": 0.39908427000045776,
      "learning_rate": 1.4567991250455707e-05,
      "loss": 0.0625,
      "step": 7450
    },
    {
      "epoch": 2.7196500182282173,
      "grad_norm": 0.03922971338033676,
      "learning_rate": 1.4560699963543567e-05,
      "loss": 0.0288,
      "step": 7460
    },
    {
      "epoch": 2.723295661684287,
      "grad_norm": 0.043279606848955154,
      "learning_rate": 1.4553408676631427e-05,
      "loss": 0.0041,
      "step": 7470
    },
    {
      "epoch": 2.7269413051403575,
      "grad_norm": 1.1537824869155884,
      "learning_rate": 1.4546117389719287e-05,
      "loss": 0.0224,
      "step": 7480
    },
    {
      "epoch": 2.7305869485964274,
      "grad_norm": 0.03596965968608856,
      "learning_rate": 1.4538826102807147e-05,
      "loss": 0.034,
      "step": 7490
    },
    {
      "epoch": 2.7342325920524972,
      "grad_norm": 0.024525117129087448,
      "learning_rate": 1.4531534815895008e-05,
      "loss": 0.014,
      "step": 7500
    },
    {
      "epoch": 2.737878235508567,
      "grad_norm": 0.26536044478416443,
      "learning_rate": 1.4524243528982867e-05,
      "loss": 0.0272,
      "step": 7510
    },
    {
      "epoch": 2.741523878964637,
      "grad_norm": 5.6428446769714355,
      "learning_rate": 1.4516952242070728e-05,
      "loss": 0.0241,
      "step": 7520
    },
    {
      "epoch": 2.7451695224207073,
      "grad_norm": 0.07623941451311111,
      "learning_rate": 1.4509660955158587e-05,
      "loss": 0.0549,
      "step": 7530
    },
    {
      "epoch": 2.748815165876777,
      "grad_norm": 1.1092692613601685,
      "learning_rate": 1.4502369668246448e-05,
      "loss": 0.0085,
      "step": 7540
    },
    {
      "epoch": 2.752460809332847,
      "grad_norm": 0.08104192465543747,
      "learning_rate": 1.4495078381334307e-05,
      "loss": 0.0055,
      "step": 7550
    },
    {
      "epoch": 2.7561064527889174,
      "grad_norm": 0.5398185849189758,
      "learning_rate": 1.4487787094422168e-05,
      "loss": 0.0122,
      "step": 7560
    },
    {
      "epoch": 2.7597520962449873,
      "grad_norm": 5.337368965148926,
      "learning_rate": 1.4480495807510027e-05,
      "loss": 0.013,
      "step": 7570
    },
    {
      "epoch": 2.763397739701057,
      "grad_norm": 0.005187653936445713,
      "learning_rate": 1.4473204520597888e-05,
      "loss": 0.0087,
      "step": 7580
    },
    {
      "epoch": 2.7670433831571275,
      "grad_norm": 0.02404007501900196,
      "learning_rate": 1.4465913233685747e-05,
      "loss": 0.0352,
      "step": 7590
    },
    {
      "epoch": 2.7706890266131974,
      "grad_norm": 8.264043807983398,
      "learning_rate": 1.4458621946773608e-05,
      "loss": 0.0367,
      "step": 7600
    },
    {
      "epoch": 2.7743346700692673,
      "grad_norm": 2.2387425899505615,
      "learning_rate": 1.4451330659861467e-05,
      "loss": 0.0404,
      "step": 7610
    },
    {
      "epoch": 2.777980313525337,
      "grad_norm": 2.3758726119995117,
      "learning_rate": 1.4444039372949328e-05,
      "loss": 0.066,
      "step": 7620
    },
    {
      "epoch": 2.781625956981407,
      "grad_norm": 0.043761856853961945,
      "learning_rate": 1.4436748086037187e-05,
      "loss": 0.0428,
      "step": 7630
    },
    {
      "epoch": 2.7852716004374773,
      "grad_norm": 0.08041898161172867,
      "learning_rate": 1.4429456799125048e-05,
      "loss": 0.0099,
      "step": 7640
    },
    {
      "epoch": 2.7889172438935472,
      "grad_norm": 9.19507122039795,
      "learning_rate": 1.4422165512212907e-05,
      "loss": 0.0456,
      "step": 7650
    },
    {
      "epoch": 2.792562887349617,
      "grad_norm": 0.04243212193250656,
      "learning_rate": 1.4414874225300768e-05,
      "loss": 0.029,
      "step": 7660
    },
    {
      "epoch": 2.7962085308056874,
      "grad_norm": 0.03955869376659393,
      "learning_rate": 1.4407582938388627e-05,
      "loss": 0.0132,
      "step": 7670
    },
    {
      "epoch": 2.7998541742617573,
      "grad_norm": 0.07881414890289307,
      "learning_rate": 1.4400291651476488e-05,
      "loss": 0.0024,
      "step": 7680
    },
    {
      "epoch": 2.803499817717827,
      "grad_norm": 15.359014511108398,
      "learning_rate": 1.4393000364564347e-05,
      "loss": 0.0447,
      "step": 7690
    },
    {
      "epoch": 2.807145461173897,
      "grad_norm": 1.9894081354141235,
      "learning_rate": 1.4385709077652206e-05,
      "loss": 0.0307,
      "step": 7700
    },
    {
      "epoch": 2.810791104629967,
      "grad_norm": 0.16187609732151031,
      "learning_rate": 1.4378417790740067e-05,
      "loss": 0.0597,
      "step": 7710
    },
    {
      "epoch": 2.8144367480860373,
      "grad_norm": 1.9887348413467407,
      "learning_rate": 1.4371126503827926e-05,
      "loss": 0.0444,
      "step": 7720
    },
    {
      "epoch": 2.818082391542107,
      "grad_norm": 0.514103889465332,
      "learning_rate": 1.4363835216915787e-05,
      "loss": 0.041,
      "step": 7730
    },
    {
      "epoch": 2.821728034998177,
      "grad_norm": 0.17460812628269196,
      "learning_rate": 1.4356543930003646e-05,
      "loss": 0.0042,
      "step": 7740
    },
    {
      "epoch": 2.8253736784542474,
      "grad_norm": 0.023720605298876762,
      "learning_rate": 1.4349252643091507e-05,
      "loss": 0.0335,
      "step": 7750
    },
    {
      "epoch": 2.8290193219103172,
      "grad_norm": 2.8471179008483887,
      "learning_rate": 1.4341961356179366e-05,
      "loss": 0.0386,
      "step": 7760
    },
    {
      "epoch": 2.832664965366387,
      "grad_norm": 0.02110174298286438,
      "learning_rate": 1.4334670069267227e-05,
      "loss": 0.0261,
      "step": 7770
    },
    {
      "epoch": 2.836310608822457,
      "grad_norm": 0.09607817977666855,
      "learning_rate": 1.4327378782355086e-05,
      "loss": 0.0509,
      "step": 7780
    },
    {
      "epoch": 2.839956252278527,
      "grad_norm": 3.6578495502471924,
      "learning_rate": 1.4320087495442947e-05,
      "loss": 0.0301,
      "step": 7790
    },
    {
      "epoch": 2.843601895734597,
      "grad_norm": 0.1268933266401291,
      "learning_rate": 1.4312796208530806e-05,
      "loss": 0.0315,
      "step": 7800
    },
    {
      "epoch": 2.847247539190667,
      "grad_norm": 0.029677843675017357,
      "learning_rate": 1.4305504921618667e-05,
      "loss": 0.0143,
      "step": 7810
    },
    {
      "epoch": 2.850893182646737,
      "grad_norm": 6.842905521392822,
      "learning_rate": 1.4298213634706526e-05,
      "loss": 0.0223,
      "step": 7820
    },
    {
      "epoch": 2.8545388261028073,
      "grad_norm": 2.04091739654541,
      "learning_rate": 1.4290922347794387e-05,
      "loss": 0.0295,
      "step": 7830
    },
    {
      "epoch": 2.858184469558877,
      "grad_norm": 2.7170627117156982,
      "learning_rate": 1.4283631060882246e-05,
      "loss": 0.045,
      "step": 7840
    },
    {
      "epoch": 2.861830113014947,
      "grad_norm": 0.03289534151554108,
      "learning_rate": 1.4276339773970107e-05,
      "loss": 0.0512,
      "step": 7850
    },
    {
      "epoch": 2.8654757564710174,
      "grad_norm": 0.9064000248908997,
      "learning_rate": 1.4269048487057966e-05,
      "loss": 0.0261,
      "step": 7860
    },
    {
      "epoch": 2.8691213999270873,
      "grad_norm": 4.10963773727417,
      "learning_rate": 1.4261757200145827e-05,
      "loss": 0.0331,
      "step": 7870
    },
    {
      "epoch": 2.872767043383157,
      "grad_norm": 0.011601870879530907,
      "learning_rate": 1.4254465913233686e-05,
      "loss": 0.0128,
      "step": 7880
    },
    {
      "epoch": 2.876412686839227,
      "grad_norm": 0.16801807284355164,
      "learning_rate": 1.4247174626321547e-05,
      "loss": 0.0149,
      "step": 7890
    },
    {
      "epoch": 2.880058330295297,
      "grad_norm": 16.65281867980957,
      "learning_rate": 1.4239883339409406e-05,
      "loss": 0.025,
      "step": 7900
    },
    {
      "epoch": 2.8837039737513672,
      "grad_norm": 7.392557144165039,
      "learning_rate": 1.4232592052497267e-05,
      "loss": 0.0843,
      "step": 7910
    },
    {
      "epoch": 2.887349617207437,
      "grad_norm": 0.008866011165082455,
      "learning_rate": 1.4225300765585126e-05,
      "loss": 0.026,
      "step": 7920
    },
    {
      "epoch": 2.890995260663507,
      "grad_norm": 0.7149606347084045,
      "learning_rate": 1.4218009478672987e-05,
      "loss": 0.0161,
      "step": 7930
    },
    {
      "epoch": 2.8946409041195773,
      "grad_norm": 3.975445032119751,
      "learning_rate": 1.4210718191760846e-05,
      "loss": 0.0108,
      "step": 7940
    },
    {
      "epoch": 2.898286547575647,
      "grad_norm": 0.38382506370544434,
      "learning_rate": 1.4203426904848707e-05,
      "loss": 0.0216,
      "step": 7950
    },
    {
      "epoch": 2.901932191031717,
      "grad_norm": 0.16307103633880615,
      "learning_rate": 1.4196135617936566e-05,
      "loss": 0.0494,
      "step": 7960
    },
    {
      "epoch": 2.905577834487787,
      "grad_norm": 0.28888657689094543,
      "learning_rate": 1.4188844331024427e-05,
      "loss": 0.0523,
      "step": 7970
    },
    {
      "epoch": 2.909223477943857,
      "grad_norm": 0.030129017308354378,
      "learning_rate": 1.4181553044112286e-05,
      "loss": 0.0078,
      "step": 7980
    },
    {
      "epoch": 2.912869121399927,
      "grad_norm": 2.5288503170013428,
      "learning_rate": 1.4174261757200147e-05,
      "loss": 0.0438,
      "step": 7990
    },
    {
      "epoch": 2.916514764855997,
      "grad_norm": 0.7804664969444275,
      "learning_rate": 1.4166970470288006e-05,
      "loss": 0.0109,
      "step": 8000
    },
    {
      "epoch": 2.920160408312067,
      "grad_norm": 3.9156293869018555,
      "learning_rate": 1.4159679183375867e-05,
      "loss": 0.0296,
      "step": 8010
    },
    {
      "epoch": 2.9238060517681372,
      "grad_norm": 0.45791149139404297,
      "learning_rate": 1.4152387896463726e-05,
      "loss": 0.016,
      "step": 8020
    },
    {
      "epoch": 2.927451695224207,
      "grad_norm": 3.0343759059906006,
      "learning_rate": 1.4145096609551587e-05,
      "loss": 0.0363,
      "step": 8030
    },
    {
      "epoch": 2.931097338680277,
      "grad_norm": 0.07693231850862503,
      "learning_rate": 1.4137805322639446e-05,
      "loss": 0.0313,
      "step": 8040
    },
    {
      "epoch": 2.9347429821363473,
      "grad_norm": 0.021725855767726898,
      "learning_rate": 1.4130514035727307e-05,
      "loss": 0.038,
      "step": 8050
    },
    {
      "epoch": 2.938388625592417,
      "grad_norm": 2.9633519649505615,
      "learning_rate": 1.4123222748815166e-05,
      "loss": 0.0134,
      "step": 8060
    },
    {
      "epoch": 2.942034269048487,
      "grad_norm": 18.41551399230957,
      "learning_rate": 1.4115931461903027e-05,
      "loss": 0.019,
      "step": 8070
    },
    {
      "epoch": 2.945679912504557,
      "grad_norm": 0.029153399169445038,
      "learning_rate": 1.4108640174990886e-05,
      "loss": 0.0387,
      "step": 8080
    },
    {
      "epoch": 2.949325555960627,
      "grad_norm": 0.03177278861403465,
      "learning_rate": 1.4101348888078747e-05,
      "loss": 0.0193,
      "step": 8090
    },
    {
      "epoch": 2.952971199416697,
      "grad_norm": 0.08856002241373062,
      "learning_rate": 1.4094057601166606e-05,
      "loss": 0.0103,
      "step": 8100
    },
    {
      "epoch": 2.956616842872767,
      "grad_norm": 0.13676747679710388,
      "learning_rate": 1.4086766314254467e-05,
      "loss": 0.0026,
      "step": 8110
    },
    {
      "epoch": 2.960262486328837,
      "grad_norm": 1.2975006103515625,
      "learning_rate": 1.4079475027342326e-05,
      "loss": 0.0225,
      "step": 8120
    },
    {
      "epoch": 2.9639081297849073,
      "grad_norm": 0.03466496244072914,
      "learning_rate": 1.4072183740430187e-05,
      "loss": 0.0289,
      "step": 8130
    },
    {
      "epoch": 2.967553773240977,
      "grad_norm": 0.07466363161802292,
      "learning_rate": 1.4064892453518046e-05,
      "loss": 0.0403,
      "step": 8140
    },
    {
      "epoch": 2.971199416697047,
      "grad_norm": 2.531949043273926,
      "learning_rate": 1.4057601166605907e-05,
      "loss": 0.0505,
      "step": 8150
    },
    {
      "epoch": 2.974845060153117,
      "grad_norm": 0.23320890963077545,
      "learning_rate": 1.4050309879693766e-05,
      "loss": 0.0034,
      "step": 8160
    },
    {
      "epoch": 2.9784907036091868,
      "grad_norm": 0.7103409171104431,
      "learning_rate": 1.4043018592781627e-05,
      "loss": 0.0741,
      "step": 8170
    },
    {
      "epoch": 2.982136347065257,
      "grad_norm": 1.556679368019104,
      "learning_rate": 1.4035727305869487e-05,
      "loss": 0.0237,
      "step": 8180
    },
    {
      "epoch": 2.985781990521327,
      "grad_norm": 0.048532966524362564,
      "learning_rate": 1.4028436018957347e-05,
      "loss": 0.0353,
      "step": 8190
    },
    {
      "epoch": 2.989427633977397,
      "grad_norm": 0.029208919033408165,
      "learning_rate": 1.4021144732045207e-05,
      "loss": 0.0471,
      "step": 8200
    },
    {
      "epoch": 2.993073277433467,
      "grad_norm": 3.8852317333221436,
      "learning_rate": 1.4013853445133067e-05,
      "loss": 0.0224,
      "step": 8210
    },
    {
      "epoch": 2.996718920889537,
      "grad_norm": 0.31448736786842346,
      "learning_rate": 1.4006562158220927e-05,
      "loss": 0.0198,
      "step": 8220
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.989192930153322,
      "eval_f1": 0.9569459172852598,
      "eval_loss": 0.03145618736743927,
      "eval_precision": 0.9510961214165261,
      "eval_recall": 0.9628681177976952,
      "eval_runtime": 893.2725,
      "eval_samples_per_second": 21.062,
      "eval_steps_per_second": 0.658,
      "step": 8229
    },
    {
      "epoch": 3.000364564345607,
      "grad_norm": 1.719850778579712,
      "learning_rate": 1.3999270871308787e-05,
      "loss": 0.017,
      "step": 8230
    },
    {
      "epoch": 3.004010207801677,
      "grad_norm": 0.008560946211218834,
      "learning_rate": 1.3991979584396647e-05,
      "loss": 0.0163,
      "step": 8240
    },
    {
      "epoch": 3.007655851257747,
      "grad_norm": 10.074967384338379,
      "learning_rate": 1.3984688297484507e-05,
      "loss": 0.0061,
      "step": 8250
    },
    {
      "epoch": 3.011301494713817,
      "grad_norm": 0.005093284882605076,
      "learning_rate": 1.3977397010572367e-05,
      "loss": 0.0007,
      "step": 8260
    },
    {
      "epoch": 3.014947138169887,
      "grad_norm": 0.0033181263133883476,
      "learning_rate": 1.3970105723660227e-05,
      "loss": 0.0045,
      "step": 8270
    },
    {
      "epoch": 3.018592781625957,
      "grad_norm": 0.049698200076818466,
      "learning_rate": 1.3962814436748087e-05,
      "loss": 0.0026,
      "step": 8280
    },
    {
      "epoch": 3.022238425082027,
      "grad_norm": 0.002391648245975375,
      "learning_rate": 1.3955523149835947e-05,
      "loss": 0.0379,
      "step": 8290
    },
    {
      "epoch": 3.025884068538097,
      "grad_norm": 0.01608005352318287,
      "learning_rate": 1.3948231862923807e-05,
      "loss": 0.0293,
      "step": 8300
    },
    {
      "epoch": 3.029529711994167,
      "grad_norm": 2.1919474601745605,
      "learning_rate": 1.3940940576011667e-05,
      "loss": 0.0388,
      "step": 8310
    },
    {
      "epoch": 3.0331753554502368,
      "grad_norm": 0.04674221947789192,
      "learning_rate": 1.3933649289099527e-05,
      "loss": 0.0361,
      "step": 8320
    },
    {
      "epoch": 3.036820998906307,
      "grad_norm": 0.09090491384267807,
      "learning_rate": 1.3926358002187388e-05,
      "loss": 0.0219,
      "step": 8330
    },
    {
      "epoch": 3.040466642362377,
      "grad_norm": 0.1493184119462967,
      "learning_rate": 1.3919066715275247e-05,
      "loss": 0.0183,
      "step": 8340
    },
    {
      "epoch": 3.044112285818447,
      "grad_norm": 0.04338083416223526,
      "learning_rate": 1.3911775428363108e-05,
      "loss": 0.0117,
      "step": 8350
    },
    {
      "epoch": 3.047757929274517,
      "grad_norm": 0.0288316048681736,
      "learning_rate": 1.3904484141450967e-05,
      "loss": 0.0054,
      "step": 8360
    },
    {
      "epoch": 3.051403572730587,
      "grad_norm": 0.8760872483253479,
      "learning_rate": 1.3897192854538828e-05,
      "loss": 0.0151,
      "step": 8370
    },
    {
      "epoch": 3.055049216186657,
      "grad_norm": 0.0261229258030653,
      "learning_rate": 1.3889901567626687e-05,
      "loss": 0.0571,
      "step": 8380
    },
    {
      "epoch": 3.058694859642727,
      "grad_norm": 0.05514156073331833,
      "learning_rate": 1.3882610280714548e-05,
      "loss": 0.0042,
      "step": 8390
    },
    {
      "epoch": 3.062340503098797,
      "grad_norm": 0.015816649422049522,
      "learning_rate": 1.3875318993802407e-05,
      "loss": 0.0013,
      "step": 8400
    },
    {
      "epoch": 3.065986146554867,
      "grad_norm": 0.6085622310638428,
      "learning_rate": 1.3868027706890268e-05,
      "loss": 0.0158,
      "step": 8410
    },
    {
      "epoch": 3.069631790010937,
      "grad_norm": 1.7202473878860474,
      "learning_rate": 1.3860736419978127e-05,
      "loss": 0.0287,
      "step": 8420
    },
    {
      "epoch": 3.0732774334670068,
      "grad_norm": 0.008571709506213665,
      "learning_rate": 1.3853445133065988e-05,
      "loss": 0.0354,
      "step": 8430
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 3.8046276569366455,
      "learning_rate": 1.3846153846153847e-05,
      "loss": 0.0503,
      "step": 8440
    },
    {
      "epoch": 3.080568720379147,
      "grad_norm": 0.06077865883708,
      "learning_rate": 1.3838862559241708e-05,
      "loss": 0.0056,
      "step": 8450
    },
    {
      "epoch": 3.084214363835217,
      "grad_norm": 0.03690674155950546,
      "learning_rate": 1.3831571272329567e-05,
      "loss": 0.0066,
      "step": 8460
    },
    {
      "epoch": 3.0878600072912867,
      "grad_norm": 0.1524711549282074,
      "learning_rate": 1.3824279985417428e-05,
      "loss": 0.0107,
      "step": 8470
    },
    {
      "epoch": 3.091505650747357,
      "grad_norm": 0.017346661537885666,
      "learning_rate": 1.3816988698505287e-05,
      "loss": 0.0174,
      "step": 8480
    },
    {
      "epoch": 3.095151294203427,
      "grad_norm": 3.4249701499938965,
      "learning_rate": 1.3809697411593148e-05,
      "loss": 0.0729,
      "step": 8490
    },
    {
      "epoch": 3.098796937659497,
      "grad_norm": 5.3955254554748535,
      "learning_rate": 1.3802406124681007e-05,
      "loss": 0.0679,
      "step": 8500
    },
    {
      "epoch": 3.1024425811155667,
      "grad_norm": 0.11924204975366592,
      "learning_rate": 1.3795114837768868e-05,
      "loss": 0.0235,
      "step": 8510
    },
    {
      "epoch": 3.106088224571637,
      "grad_norm": 0.07757969200611115,
      "learning_rate": 1.3787823550856727e-05,
      "loss": 0.013,
      "step": 8520
    },
    {
      "epoch": 3.109733868027707,
      "grad_norm": 0.004661689978092909,
      "learning_rate": 1.3780532263944588e-05,
      "loss": 0.0327,
      "step": 8530
    },
    {
      "epoch": 3.113379511483777,
      "grad_norm": 0.030155297368764877,
      "learning_rate": 1.3773240977032447e-05,
      "loss": 0.0394,
      "step": 8540
    },
    {
      "epoch": 3.1170251549398467,
      "grad_norm": 0.18000485002994537,
      "learning_rate": 1.3765949690120308e-05,
      "loss": 0.009,
      "step": 8550
    },
    {
      "epoch": 3.120670798395917,
      "grad_norm": 1.1335464715957642,
      "learning_rate": 1.3758658403208167e-05,
      "loss": 0.0073,
      "step": 8560
    },
    {
      "epoch": 3.124316441851987,
      "grad_norm": 0.10684307664632797,
      "learning_rate": 1.3751367116296028e-05,
      "loss": 0.0267,
      "step": 8570
    },
    {
      "epoch": 3.1279620853080567,
      "grad_norm": 0.12322823703289032,
      "learning_rate": 1.3744075829383887e-05,
      "loss": 0.0093,
      "step": 8580
    },
    {
      "epoch": 3.131607728764127,
      "grad_norm": 0.009341130033135414,
      "learning_rate": 1.3736784542471748e-05,
      "loss": 0.0216,
      "step": 8590
    },
    {
      "epoch": 3.135253372220197,
      "grad_norm": 0.01813119649887085,
      "learning_rate": 1.3729493255559607e-05,
      "loss": 0.0202,
      "step": 8600
    },
    {
      "epoch": 3.138899015676267,
      "grad_norm": 0.05181283503770828,
      "learning_rate": 1.3722201968647468e-05,
      "loss": 0.0105,
      "step": 8610
    },
    {
      "epoch": 3.1425446591323367,
      "grad_norm": 0.0074191708117723465,
      "learning_rate": 1.3714910681735327e-05,
      "loss": 0.0287,
      "step": 8620
    },
    {
      "epoch": 3.146190302588407,
      "grad_norm": 0.01575298048555851,
      "learning_rate": 1.3707619394823188e-05,
      "loss": 0.0307,
      "step": 8630
    },
    {
      "epoch": 3.149835946044477,
      "grad_norm": 0.00773634435608983,
      "learning_rate": 1.3700328107911047e-05,
      "loss": 0.0137,
      "step": 8640
    },
    {
      "epoch": 3.153481589500547,
      "grad_norm": 0.0055998023599386215,
      "learning_rate": 1.3693036820998908e-05,
      "loss": 0.0063,
      "step": 8650
    },
    {
      "epoch": 3.1571272329566167,
      "grad_norm": 0.01747068203985691,
      "learning_rate": 1.3685745534086767e-05,
      "loss": 0.0283,
      "step": 8660
    },
    {
      "epoch": 3.160772876412687,
      "grad_norm": 0.015796149149537086,
      "learning_rate": 1.3678454247174628e-05,
      "loss": 0.015,
      "step": 8670
    },
    {
      "epoch": 3.164418519868757,
      "grad_norm": 0.07228460907936096,
      "learning_rate": 1.3671162960262487e-05,
      "loss": 0.0107,
      "step": 8680
    },
    {
      "epoch": 3.1680641633248268,
      "grad_norm": 0.025422703474760056,
      "learning_rate": 1.3663871673350348e-05,
      "loss": 0.0106,
      "step": 8690
    },
    {
      "epoch": 3.1717098067808966,
      "grad_norm": 0.005962591618299484,
      "learning_rate": 1.3656580386438207e-05,
      "loss": 0.0182,
      "step": 8700
    },
    {
      "epoch": 3.175355450236967,
      "grad_norm": 1.510886549949646,
      "learning_rate": 1.3649289099526068e-05,
      "loss": 0.0039,
      "step": 8710
    },
    {
      "epoch": 3.179001093693037,
      "grad_norm": 0.0056550935842096806,
      "learning_rate": 1.3641997812613927e-05,
      "loss": 0.0045,
      "step": 8720
    },
    {
      "epoch": 3.1826467371491067,
      "grad_norm": 0.07535739243030548,
      "learning_rate": 1.3634706525701788e-05,
      "loss": 0.0169,
      "step": 8730
    },
    {
      "epoch": 3.1862923806051766,
      "grad_norm": 2.881319761276245,
      "learning_rate": 1.3627415238789647e-05,
      "loss": 0.0178,
      "step": 8740
    },
    {
      "epoch": 3.189938024061247,
      "grad_norm": 4.200191974639893,
      "learning_rate": 1.3620123951877508e-05,
      "loss": 0.0259,
      "step": 8750
    },
    {
      "epoch": 3.193583667517317,
      "grad_norm": 0.007696523796766996,
      "learning_rate": 1.3612832664965367e-05,
      "loss": 0.0127,
      "step": 8760
    },
    {
      "epoch": 3.1972293109733867,
      "grad_norm": 1.647860050201416,
      "learning_rate": 1.3605541378053228e-05,
      "loss": 0.0326,
      "step": 8770
    },
    {
      "epoch": 3.200874954429457,
      "grad_norm": 0.025871599093079567,
      "learning_rate": 1.3598250091141087e-05,
      "loss": 0.0583,
      "step": 8780
    },
    {
      "epoch": 3.204520597885527,
      "grad_norm": 0.22232414782047272,
      "learning_rate": 1.3590958804228946e-05,
      "loss": 0.0137,
      "step": 8790
    },
    {
      "epoch": 3.208166241341597,
      "grad_norm": 2.275844097137451,
      "learning_rate": 1.3583667517316807e-05,
      "loss": 0.0238,
      "step": 8800
    },
    {
      "epoch": 3.2118118847976667,
      "grad_norm": 5.423450946807861,
      "learning_rate": 1.3576376230404666e-05,
      "loss": 0.0287,
      "step": 8810
    },
    {
      "epoch": 3.215457528253737,
      "grad_norm": 0.3688053488731384,
      "learning_rate": 1.3569084943492527e-05,
      "loss": 0.0504,
      "step": 8820
    },
    {
      "epoch": 3.219103171709807,
      "grad_norm": 0.8198527097702026,
      "learning_rate": 1.3561793656580386e-05,
      "loss": 0.0058,
      "step": 8830
    },
    {
      "epoch": 3.2227488151658767,
      "grad_norm": 1.0310462713241577,
      "learning_rate": 1.3554502369668247e-05,
      "loss": 0.0229,
      "step": 8840
    },
    {
      "epoch": 3.2263944586219466,
      "grad_norm": 0.006222597323358059,
      "learning_rate": 1.3547211082756106e-05,
      "loss": 0.0138,
      "step": 8850
    },
    {
      "epoch": 3.230040102078017,
      "grad_norm": 11.254530906677246,
      "learning_rate": 1.3539919795843967e-05,
      "loss": 0.0359,
      "step": 8860
    },
    {
      "epoch": 3.233685745534087,
      "grad_norm": 0.011000442318618298,
      "learning_rate": 1.3532628508931826e-05,
      "loss": 0.0075,
      "step": 8870
    },
    {
      "epoch": 3.2373313889901567,
      "grad_norm": 0.053966548293828964,
      "learning_rate": 1.3525337222019687e-05,
      "loss": 0.0229,
      "step": 8880
    },
    {
      "epoch": 3.2409770324462266,
      "grad_norm": 0.1026138961315155,
      "learning_rate": 1.3518045935107546e-05,
      "loss": 0.0252,
      "step": 8890
    },
    {
      "epoch": 3.244622675902297,
      "grad_norm": 0.05197981372475624,
      "learning_rate": 1.3510754648195407e-05,
      "loss": 0.0076,
      "step": 8900
    },
    {
      "epoch": 3.248268319358367,
      "grad_norm": 0.17078782618045807,
      "learning_rate": 1.3503463361283266e-05,
      "loss": 0.0018,
      "step": 8910
    },
    {
      "epoch": 3.2519139628144367,
      "grad_norm": 0.011501708999276161,
      "learning_rate": 1.3496172074371127e-05,
      "loss": 0.0121,
      "step": 8920
    },
    {
      "epoch": 3.2555596062705066,
      "grad_norm": 0.003146159229800105,
      "learning_rate": 1.3488880787458986e-05,
      "loss": 0.0064,
      "step": 8930
    },
    {
      "epoch": 3.259205249726577,
      "grad_norm": 0.26008230447769165,
      "learning_rate": 1.3481589500546847e-05,
      "loss": 0.0204,
      "step": 8940
    },
    {
      "epoch": 3.2628508931826468,
      "grad_norm": 0.00590858981013298,
      "learning_rate": 1.3474298213634706e-05,
      "loss": 0.0043,
      "step": 8950
    },
    {
      "epoch": 3.2664965366387166,
      "grad_norm": 0.026734421029686928,
      "learning_rate": 1.3467006926722567e-05,
      "loss": 0.0341,
      "step": 8960
    },
    {
      "epoch": 3.270142180094787,
      "grad_norm": 0.02459675818681717,
      "learning_rate": 1.3459715639810426e-05,
      "loss": 0.028,
      "step": 8970
    },
    {
      "epoch": 3.273787823550857,
      "grad_norm": 0.02078583836555481,
      "learning_rate": 1.3452424352898287e-05,
      "loss": 0.0088,
      "step": 8980
    },
    {
      "epoch": 3.2774334670069267,
      "grad_norm": 0.005112077109515667,
      "learning_rate": 1.3445133065986146e-05,
      "loss": 0.0196,
      "step": 8990
    },
    {
      "epoch": 3.2810791104629966,
      "grad_norm": 0.04418058320879936,
      "learning_rate": 1.3437841779074007e-05,
      "loss": 0.0437,
      "step": 9000
    },
    {
      "epoch": 3.2847247539190665,
      "grad_norm": 2.7737624645233154,
      "learning_rate": 1.3430550492161866e-05,
      "loss": 0.0263,
      "step": 9010
    },
    {
      "epoch": 3.288370397375137,
      "grad_norm": 2.8235204219818115,
      "learning_rate": 1.3423259205249727e-05,
      "loss": 0.0133,
      "step": 9020
    },
    {
      "epoch": 3.2920160408312067,
      "grad_norm": 10.59081745147705,
      "learning_rate": 1.3415967918337587e-05,
      "loss": 0.0122,
      "step": 9030
    },
    {
      "epoch": 3.2956616842872766,
      "grad_norm": 5.2404398918151855,
      "learning_rate": 1.3408676631425447e-05,
      "loss": 0.0724,
      "step": 9040
    },
    {
      "epoch": 3.299307327743347,
      "grad_norm": 0.14767934381961823,
      "learning_rate": 1.3401385344513307e-05,
      "loss": 0.0224,
      "step": 9050
    },
    {
      "epoch": 3.3029529711994168,
      "grad_norm": 0.4746429920196533,
      "learning_rate": 1.3394094057601167e-05,
      "loss": 0.0027,
      "step": 9060
    },
    {
      "epoch": 3.3065986146554867,
      "grad_norm": 2.1213624477386475,
      "learning_rate": 1.3386802770689027e-05,
      "loss": 0.0177,
      "step": 9070
    },
    {
      "epoch": 3.3102442581115565,
      "grad_norm": 0.033161912113428116,
      "learning_rate": 1.3379511483776887e-05,
      "loss": 0.0171,
      "step": 9080
    },
    {
      "epoch": 3.313889901567627,
      "grad_norm": 0.004924338776618242,
      "learning_rate": 1.3372220196864747e-05,
      "loss": 0.015,
      "step": 9090
    },
    {
      "epoch": 3.3175355450236967,
      "grad_norm": 0.01918547973036766,
      "learning_rate": 1.3364928909952607e-05,
      "loss": 0.0597,
      "step": 9100
    },
    {
      "epoch": 3.3211811884797666,
      "grad_norm": 0.011172155849635601,
      "learning_rate": 1.3357637623040467e-05,
      "loss": 0.0007,
      "step": 9110
    },
    {
      "epoch": 3.3248268319358365,
      "grad_norm": 10.681621551513672,
      "learning_rate": 1.3350346336128327e-05,
      "loss": 0.0303,
      "step": 9120
    },
    {
      "epoch": 3.328472475391907,
      "grad_norm": 0.019639652222394943,
      "learning_rate": 1.3343055049216187e-05,
      "loss": 0.0021,
      "step": 9130
    },
    {
      "epoch": 3.3321181188479767,
      "grad_norm": 0.006149004679173231,
      "learning_rate": 1.3335763762304047e-05,
      "loss": 0.0079,
      "step": 9140
    },
    {
      "epoch": 3.3357637623040466,
      "grad_norm": 0.022486181929707527,
      "learning_rate": 1.3328472475391907e-05,
      "loss": 0.01,
      "step": 9150
    },
    {
      "epoch": 3.3394094057601165,
      "grad_norm": 0.3202683627605438,
      "learning_rate": 1.3321181188479767e-05,
      "loss": 0.0126,
      "step": 9160
    },
    {
      "epoch": 3.343055049216187,
      "grad_norm": 0.720492422580719,
      "learning_rate": 1.3313889901567627e-05,
      "loss": 0.0308,
      "step": 9170
    },
    {
      "epoch": 3.3467006926722567,
      "grad_norm": 12.044852256774902,
      "learning_rate": 1.3306598614655488e-05,
      "loss": 0.0352,
      "step": 9180
    },
    {
      "epoch": 3.3503463361283266,
      "grad_norm": 4.615191459655762,
      "learning_rate": 1.3299307327743347e-05,
      "loss": 0.0793,
      "step": 9190
    },
    {
      "epoch": 3.3539919795843964,
      "grad_norm": 16.36029052734375,
      "learning_rate": 1.3292016040831208e-05,
      "loss": 0.0422,
      "step": 9200
    },
    {
      "epoch": 3.3576376230404668,
      "grad_norm": 0.8085678219795227,
      "learning_rate": 1.3284724753919067e-05,
      "loss": 0.0275,
      "step": 9210
    },
    {
      "epoch": 3.3612832664965366,
      "grad_norm": 0.031358007341623306,
      "learning_rate": 1.3277433467006928e-05,
      "loss": 0.0026,
      "step": 9220
    },
    {
      "epoch": 3.3649289099526065,
      "grad_norm": 6.291719436645508,
      "learning_rate": 1.3270142180094787e-05,
      "loss": 0.0318,
      "step": 9230
    },
    {
      "epoch": 3.368574553408677,
      "grad_norm": 0.004157389979809523,
      "learning_rate": 1.3262850893182648e-05,
      "loss": 0.0016,
      "step": 9240
    },
    {
      "epoch": 3.3722201968647467,
      "grad_norm": 0.005856352858245373,
      "learning_rate": 1.3255559606270507e-05,
      "loss": 0.0029,
      "step": 9250
    },
    {
      "epoch": 3.3758658403208166,
      "grad_norm": 0.027113119140267372,
      "learning_rate": 1.3248268319358368e-05,
      "loss": 0.0216,
      "step": 9260
    },
    {
      "epoch": 3.3795114837768865,
      "grad_norm": 0.5964694619178772,
      "learning_rate": 1.3240977032446227e-05,
      "loss": 0.0275,
      "step": 9270
    },
    {
      "epoch": 3.383157127232957,
      "grad_norm": 0.0021453993394970894,
      "learning_rate": 1.3233685745534088e-05,
      "loss": 0.0087,
      "step": 9280
    },
    {
      "epoch": 3.3868027706890267,
      "grad_norm": 0.011366062797605991,
      "learning_rate": 1.3226394458621947e-05,
      "loss": 0.0138,
      "step": 9290
    },
    {
      "epoch": 3.3904484141450966,
      "grad_norm": 23.124847412109375,
      "learning_rate": 1.3219103171709808e-05,
      "loss": 0.0225,
      "step": 9300
    },
    {
      "epoch": 3.3940940576011664,
      "grad_norm": 0.002835959428921342,
      "learning_rate": 1.3211811884797667e-05,
      "loss": 0.0362,
      "step": 9310
    },
    {
      "epoch": 3.3977397010572368,
      "grad_norm": 7.025425434112549,
      "learning_rate": 1.3204520597885528e-05,
      "loss": 0.0051,
      "step": 9320
    },
    {
      "epoch": 3.4013853445133067,
      "grad_norm": 0.007119535002857447,
      "learning_rate": 1.3197229310973387e-05,
      "loss": 0.0267,
      "step": 9330
    },
    {
      "epoch": 3.4050309879693765,
      "grad_norm": 0.10692886263132095,
      "learning_rate": 1.3189938024061248e-05,
      "loss": 0.05,
      "step": 9340
    },
    {
      "epoch": 3.4086766314254464,
      "grad_norm": 2.1412155628204346,
      "learning_rate": 1.3182646737149107e-05,
      "loss": 0.0083,
      "step": 9350
    },
    {
      "epoch": 3.4123222748815167,
      "grad_norm": 16.65015411376953,
      "learning_rate": 1.3175355450236968e-05,
      "loss": 0.0136,
      "step": 9360
    },
    {
      "epoch": 3.4159679183375866,
      "grad_norm": 0.02383749559521675,
      "learning_rate": 1.3168064163324827e-05,
      "loss": 0.0383,
      "step": 9370
    },
    {
      "epoch": 3.4196135617936565,
      "grad_norm": 1.2549878358840942,
      "learning_rate": 1.3160772876412688e-05,
      "loss": 0.0028,
      "step": 9380
    },
    {
      "epoch": 3.4232592052497264,
      "grad_norm": 6.482868194580078,
      "learning_rate": 1.3153481589500547e-05,
      "loss": 0.0628,
      "step": 9390
    },
    {
      "epoch": 3.4269048487057967,
      "grad_norm": 1.2779066562652588,
      "learning_rate": 1.3146190302588408e-05,
      "loss": 0.0246,
      "step": 9400
    },
    {
      "epoch": 3.4305504921618666,
      "grad_norm": 0.01287880726158619,
      "learning_rate": 1.3138899015676267e-05,
      "loss": 0.0075,
      "step": 9410
    },
    {
      "epoch": 3.4341961356179365,
      "grad_norm": 0.019953686743974686,
      "learning_rate": 1.3131607728764128e-05,
      "loss": 0.0465,
      "step": 9420
    },
    {
      "epoch": 3.437841779074007,
      "grad_norm": 0.8075335621833801,
      "learning_rate": 1.3124316441851987e-05,
      "loss": 0.0201,
      "step": 9430
    },
    {
      "epoch": 3.4414874225300767,
      "grad_norm": 2.7750587463378906,
      "learning_rate": 1.311702515493985e-05,
      "loss": 0.0286,
      "step": 9440
    },
    {
      "epoch": 3.4451330659861465,
      "grad_norm": 0.1075858324766159,
      "learning_rate": 1.3109733868027707e-05,
      "loss": 0.0064,
      "step": 9450
    },
    {
      "epoch": 3.4487787094422164,
      "grad_norm": 0.3692406713962555,
      "learning_rate": 1.310244258111557e-05,
      "loss": 0.0016,
      "step": 9460
    },
    {
      "epoch": 3.4524243528982863,
      "grad_norm": 0.01080012135207653,
      "learning_rate": 1.3095151294203427e-05,
      "loss": 0.035,
      "step": 9470
    },
    {
      "epoch": 3.4560699963543566,
      "grad_norm": 0.8082107901573181,
      "learning_rate": 1.308786000729129e-05,
      "loss": 0.0038,
      "step": 9480
    },
    {
      "epoch": 3.4597156398104265,
      "grad_norm": 0.027030140161514282,
      "learning_rate": 1.3080568720379147e-05,
      "loss": 0.0468,
      "step": 9490
    },
    {
      "epoch": 3.4633612832664964,
      "grad_norm": 0.367328017950058,
      "learning_rate": 1.307327743346701e-05,
      "loss": 0.0211,
      "step": 9500
    },
    {
      "epoch": 3.4670069267225667,
      "grad_norm": 8.23060417175293,
      "learning_rate": 1.3065986146554867e-05,
      "loss": 0.0575,
      "step": 9510
    },
    {
      "epoch": 3.4706525701786366,
      "grad_norm": 3.5491700172424316,
      "learning_rate": 1.305869485964273e-05,
      "loss": 0.0336,
      "step": 9520
    },
    {
      "epoch": 3.4742982136347065,
      "grad_norm": 0.059759337455034256,
      "learning_rate": 1.3051403572730587e-05,
      "loss": 0.0027,
      "step": 9530
    },
    {
      "epoch": 3.4779438570907764,
      "grad_norm": 9.846202850341797,
      "learning_rate": 1.304411228581845e-05,
      "loss": 0.0295,
      "step": 9540
    },
    {
      "epoch": 3.4815895005468467,
      "grad_norm": 0.02491697110235691,
      "learning_rate": 1.3036820998906307e-05,
      "loss": 0.0058,
      "step": 9550
    },
    {
      "epoch": 3.4852351440029166,
      "grad_norm": 0.0009968709200620651,
      "learning_rate": 1.302952971199417e-05,
      "loss": 0.0057,
      "step": 9560
    },
    {
      "epoch": 3.4888807874589864,
      "grad_norm": 0.03079906292259693,
      "learning_rate": 1.3022238425082027e-05,
      "loss": 0.0145,
      "step": 9570
    },
    {
      "epoch": 3.4925264309150563,
      "grad_norm": 6.93637228012085,
      "learning_rate": 1.301494713816989e-05,
      "loss": 0.0364,
      "step": 9580
    },
    {
      "epoch": 3.4961720743711266,
      "grad_norm": 5.707268714904785,
      "learning_rate": 1.3007655851257747e-05,
      "loss": 0.0279,
      "step": 9590
    },
    {
      "epoch": 3.4998177178271965,
      "grad_norm": 2.595482587814331,
      "learning_rate": 1.300036456434561e-05,
      "loss": 0.0105,
      "step": 9600
    },
    {
      "epoch": 3.5034633612832664,
      "grad_norm": 0.011989598162472248,
      "learning_rate": 1.2993073277433467e-05,
      "loss": 0.0352,
      "step": 9610
    },
    {
      "epoch": 3.5071090047393367,
      "grad_norm": 25.619543075561523,
      "learning_rate": 1.298578199052133e-05,
      "loss": 0.0371,
      "step": 9620
    },
    {
      "epoch": 3.5107546481954066,
      "grad_norm": 1.9246045351028442,
      "learning_rate": 1.2978490703609187e-05,
      "loss": 0.0135,
      "step": 9630
    },
    {
      "epoch": 3.5144002916514765,
      "grad_norm": 0.3904092609882355,
      "learning_rate": 1.297119941669705e-05,
      "loss": 0.0234,
      "step": 9640
    },
    {
      "epoch": 3.5180459351075464,
      "grad_norm": 0.15643763542175293,
      "learning_rate": 1.2963908129784907e-05,
      "loss": 0.0518,
      "step": 9650
    },
    {
      "epoch": 3.5216915785636163,
      "grad_norm": 0.41673609614372253,
      "learning_rate": 1.295661684287277e-05,
      "loss": 0.0112,
      "step": 9660
    },
    {
      "epoch": 3.5253372220196866,
      "grad_norm": 0.027719911187887192,
      "learning_rate": 1.2949325555960627e-05,
      "loss": 0.0373,
      "step": 9670
    },
    {
      "epoch": 3.5289828654757565,
      "grad_norm": 2.377358913421631,
      "learning_rate": 1.294203426904849e-05,
      "loss": 0.0234,
      "step": 9680
    },
    {
      "epoch": 3.5326285089318263,
      "grad_norm": 0.03349916636943817,
      "learning_rate": 1.2934742982136347e-05,
      "loss": 0.0299,
      "step": 9690
    },
    {
      "epoch": 3.5362741523878967,
      "grad_norm": 0.15484772622585297,
      "learning_rate": 1.292745169522421e-05,
      "loss": 0.0075,
      "step": 9700
    },
    {
      "epoch": 3.5399197958439665,
      "grad_norm": 0.01467096246778965,
      "learning_rate": 1.2920160408312067e-05,
      "loss": 0.0056,
      "step": 9710
    },
    {
      "epoch": 3.5435654393000364,
      "grad_norm": 6.74354362487793,
      "learning_rate": 1.291286912139993e-05,
      "loss": 0.0151,
      "step": 9720
    },
    {
      "epoch": 3.5472110827561063,
      "grad_norm": 0.01259915716946125,
      "learning_rate": 1.2905577834487787e-05,
      "loss": 0.0147,
      "step": 9730
    },
    {
      "epoch": 3.550856726212176,
      "grad_norm": 0.17176321148872375,
      "learning_rate": 1.289828654757565e-05,
      "loss": 0.0106,
      "step": 9740
    },
    {
      "epoch": 3.5545023696682465,
      "grad_norm": 0.07814904302358627,
      "learning_rate": 1.2890995260663507e-05,
      "loss": 0.0004,
      "step": 9750
    },
    {
      "epoch": 3.5581480131243164,
      "grad_norm": 0.009605194441974163,
      "learning_rate": 1.288370397375137e-05,
      "loss": 0.0446,
      "step": 9760
    },
    {
      "epoch": 3.5617936565803863,
      "grad_norm": 2.2565934658050537,
      "learning_rate": 1.2876412686839227e-05,
      "loss": 0.0133,
      "step": 9770
    },
    {
      "epoch": 3.5654393000364566,
      "grad_norm": 0.03238056227564812,
      "learning_rate": 1.286912139992709e-05,
      "loss": 0.0097,
      "step": 9780
    },
    {
      "epoch": 3.5690849434925265,
      "grad_norm": 2.291579484939575,
      "learning_rate": 1.2861830113014947e-05,
      "loss": 0.0086,
      "step": 9790
    },
    {
      "epoch": 3.5727305869485964,
      "grad_norm": 0.004133488051593304,
      "learning_rate": 1.285453882610281e-05,
      "loss": 0.0245,
      "step": 9800
    },
    {
      "epoch": 3.5763762304046667,
      "grad_norm": 0.1416049301624298,
      "learning_rate": 1.2847247539190667e-05,
      "loss": 0.018,
      "step": 9810
    },
    {
      "epoch": 3.5800218738607366,
      "grad_norm": 0.054359275847673416,
      "learning_rate": 1.283995625227853e-05,
      "loss": 0.024,
      "step": 9820
    },
    {
      "epoch": 3.5836675173168064,
      "grad_norm": 0.042801324278116226,
      "learning_rate": 1.2832664965366389e-05,
      "loss": 0.0256,
      "step": 9830
    },
    {
      "epoch": 3.5873131607728763,
      "grad_norm": 1.1804040670394897,
      "learning_rate": 1.282537367845425e-05,
      "loss": 0.0045,
      "step": 9840
    },
    {
      "epoch": 3.590958804228946,
      "grad_norm": 0.004115369636565447,
      "learning_rate": 1.2818082391542109e-05,
      "loss": 0.0418,
      "step": 9850
    },
    {
      "epoch": 3.5946044476850165,
      "grad_norm": 0.9616856575012207,
      "learning_rate": 1.281079110462997e-05,
      "loss": 0.025,
      "step": 9860
    },
    {
      "epoch": 3.5982500911410864,
      "grad_norm": 0.04940326139330864,
      "learning_rate": 1.2803499817717829e-05,
      "loss": 0.0105,
      "step": 9870
    },
    {
      "epoch": 3.6018957345971563,
      "grad_norm": 0.004011139739304781,
      "learning_rate": 1.2796208530805687e-05,
      "loss": 0.0026,
      "step": 9880
    },
    {
      "epoch": 3.6055413780532266,
      "grad_norm": 3.151309013366699,
      "learning_rate": 1.2788917243893549e-05,
      "loss": 0.0166,
      "step": 9890
    },
    {
      "epoch": 3.6091870215092965,
      "grad_norm": 0.015566196292638779,
      "learning_rate": 1.2781625956981407e-05,
      "loss": 0.0263,
      "step": 9900
    },
    {
      "epoch": 3.6128326649653664,
      "grad_norm": 0.026662560179829597,
      "learning_rate": 1.2774334670069269e-05,
      "loss": 0.009,
      "step": 9910
    },
    {
      "epoch": 3.6164783084214362,
      "grad_norm": 0.1319827288389206,
      "learning_rate": 1.2767043383157127e-05,
      "loss": 0.0066,
      "step": 9920
    },
    {
      "epoch": 3.620123951877506,
      "grad_norm": 0.043047983199357986,
      "learning_rate": 1.2759752096244989e-05,
      "loss": 0.0124,
      "step": 9930
    },
    {
      "epoch": 3.6237695953335765,
      "grad_norm": 0.003980532288551331,
      "learning_rate": 1.2752460809332847e-05,
      "loss": 0.0342,
      "step": 9940
    },
    {
      "epoch": 3.6274152387896463,
      "grad_norm": 0.004447379615157843,
      "learning_rate": 1.2745169522420709e-05,
      "loss": 0.0004,
      "step": 9950
    },
    {
      "epoch": 3.631060882245716,
      "grad_norm": 0.006644202396273613,
      "learning_rate": 1.2737878235508567e-05,
      "loss": 0.0306,
      "step": 9960
    },
    {
      "epoch": 3.6347065257017865,
      "grad_norm": 0.5605255961418152,
      "learning_rate": 1.273058694859643e-05,
      "loss": 0.0589,
      "step": 9970
    },
    {
      "epoch": 3.6383521691578564,
      "grad_norm": 0.07746274024248123,
      "learning_rate": 1.2723295661684287e-05,
      "loss": 0.0414,
      "step": 9980
    },
    {
      "epoch": 3.6419978126139263,
      "grad_norm": 7.781890869140625,
      "learning_rate": 1.271600437477215e-05,
      "loss": 0.0416,
      "step": 9990
    },
    {
      "epoch": 3.6456434560699966,
      "grad_norm": 0.08504403382539749,
      "learning_rate": 1.2708713087860007e-05,
      "loss": 0.0055,
      "step": 10000
    },
    {
      "epoch": 3.6492890995260665,
      "grad_norm": 5.554968357086182,
      "learning_rate": 1.270142180094787e-05,
      "loss": 0.0477,
      "step": 10010
    },
    {
      "epoch": 3.6529347429821364,
      "grad_norm": 0.08308526873588562,
      "learning_rate": 1.2694130514035727e-05,
      "loss": 0.0121,
      "step": 10020
    },
    {
      "epoch": 3.6565803864382063,
      "grad_norm": 0.12125515192747116,
      "learning_rate": 1.268683922712359e-05,
      "loss": 0.0007,
      "step": 10030
    },
    {
      "epoch": 3.660226029894276,
      "grad_norm": 6.114034175872803,
      "learning_rate": 1.2679547940211447e-05,
      "loss": 0.0708,
      "step": 10040
    },
    {
      "epoch": 3.6638716733503465,
      "grad_norm": 0.06807542592287064,
      "learning_rate": 1.267225665329931e-05,
      "loss": 0.0008,
      "step": 10050
    },
    {
      "epoch": 3.6675173168064163,
      "grad_norm": 0.02270788699388504,
      "learning_rate": 1.2664965366387167e-05,
      "loss": 0.0538,
      "step": 10060
    },
    {
      "epoch": 3.6711629602624862,
      "grad_norm": 0.13038122653961182,
      "learning_rate": 1.265767407947503e-05,
      "loss": 0.0215,
      "step": 10070
    },
    {
      "epoch": 3.6748086037185566,
      "grad_norm": 0.46199333667755127,
      "learning_rate": 1.2650382792562887e-05,
      "loss": 0.0166,
      "step": 10080
    },
    {
      "epoch": 3.6784542471746264,
      "grad_norm": 2.019196033477783,
      "learning_rate": 1.264309150565075e-05,
      "loss": 0.0207,
      "step": 10090
    },
    {
      "epoch": 3.6820998906306963,
      "grad_norm": 0.0378640741109848,
      "learning_rate": 1.2635800218738607e-05,
      "loss": 0.0005,
      "step": 10100
    },
    {
      "epoch": 3.685745534086766,
      "grad_norm": 0.018698930740356445,
      "learning_rate": 1.262850893182647e-05,
      "loss": 0.0143,
      "step": 10110
    },
    {
      "epoch": 3.689391177542836,
      "grad_norm": 0.0038286938797682524,
      "learning_rate": 1.2621217644914327e-05,
      "loss": 0.0761,
      "step": 10120
    },
    {
      "epoch": 3.6930368209989064,
      "grad_norm": 0.013803183101117611,
      "learning_rate": 1.261392635800219e-05,
      "loss": 0.0119,
      "step": 10130
    },
    {
      "epoch": 3.6966824644549763,
      "grad_norm": 0.0060655041597783566,
      "learning_rate": 1.2606635071090047e-05,
      "loss": 0.0059,
      "step": 10140
    },
    {
      "epoch": 3.700328107911046,
      "grad_norm": 10.91398811340332,
      "learning_rate": 1.259934378417791e-05,
      "loss": 0.0352,
      "step": 10150
    },
    {
      "epoch": 3.7039737513671165,
      "grad_norm": 0.3043849766254425,
      "learning_rate": 1.2592052497265767e-05,
      "loss": 0.0364,
      "step": 10160
    },
    {
      "epoch": 3.7076193948231864,
      "grad_norm": 0.004621659405529499,
      "learning_rate": 1.258476121035363e-05,
      "loss": 0.0156,
      "step": 10170
    },
    {
      "epoch": 3.7112650382792562,
      "grad_norm": 0.09610867500305176,
      "learning_rate": 1.2577469923441487e-05,
      "loss": 0.0014,
      "step": 10180
    },
    {
      "epoch": 3.714910681735326,
      "grad_norm": 8.494250297546387,
      "learning_rate": 1.257017863652935e-05,
      "loss": 0.0278,
      "step": 10190
    },
    {
      "epoch": 3.718556325191396,
      "grad_norm": 0.00767505681142211,
      "learning_rate": 1.2562887349617207e-05,
      "loss": 0.0127,
      "step": 10200
    },
    {
      "epoch": 3.7222019686474663,
      "grad_norm": 0.0029810736887156963,
      "learning_rate": 1.255559606270507e-05,
      "loss": 0.0186,
      "step": 10210
    },
    {
      "epoch": 3.725847612103536,
      "grad_norm": 0.03950351104140282,
      "learning_rate": 1.2548304775792929e-05,
      "loss": 0.0175,
      "step": 10220
    },
    {
      "epoch": 3.729493255559606,
      "grad_norm": 0.043255288153886795,
      "learning_rate": 1.254101348888079e-05,
      "loss": 0.0099,
      "step": 10230
    },
    {
      "epoch": 3.7331388990156764,
      "grad_norm": 0.01063817460089922,
      "learning_rate": 1.2533722201968649e-05,
      "loss": 0.0427,
      "step": 10240
    },
    {
      "epoch": 3.7367845424717463,
      "grad_norm": 0.29306676983833313,
      "learning_rate": 1.252643091505651e-05,
      "loss": 0.0228,
      "step": 10250
    },
    {
      "epoch": 3.740430185927816,
      "grad_norm": 0.015013490803539753,
      "learning_rate": 1.2519139628144369e-05,
      "loss": 0.0418,
      "step": 10260
    },
    {
      "epoch": 3.7440758293838865,
      "grad_norm": 0.004455286078155041,
      "learning_rate": 1.251184834123223e-05,
      "loss": 0.01,
      "step": 10270
    },
    {
      "epoch": 3.7477214728399564,
      "grad_norm": 3.750603199005127,
      "learning_rate": 1.2504557054320089e-05,
      "loss": 0.0343,
      "step": 10280
    },
    {
      "epoch": 3.7513671162960263,
      "grad_norm": 2.127328634262085,
      "learning_rate": 1.249726576740795e-05,
      "loss": 0.0206,
      "step": 10290
    },
    {
      "epoch": 3.755012759752096,
      "grad_norm": 0.005879418924450874,
      "learning_rate": 1.2489974480495809e-05,
      "loss": 0.0112,
      "step": 10300
    },
    {
      "epoch": 3.758658403208166,
      "grad_norm": 7.636615753173828,
      "learning_rate": 1.248268319358367e-05,
      "loss": 0.043,
      "step": 10310
    },
    {
      "epoch": 3.7623040466642363,
      "grad_norm": 0.008116579614579678,
      "learning_rate": 1.2475391906671529e-05,
      "loss": 0.0046,
      "step": 10320
    },
    {
      "epoch": 3.7659496901203062,
      "grad_norm": 2.9606239795684814,
      "learning_rate": 1.246810061975939e-05,
      "loss": 0.0102,
      "step": 10330
    },
    {
      "epoch": 3.769595333576376,
      "grad_norm": 0.017526915296912193,
      "learning_rate": 1.2460809332847249e-05,
      "loss": 0.0308,
      "step": 10340
    },
    {
      "epoch": 3.7732409770324464,
      "grad_norm": 0.22931590676307678,
      "learning_rate": 1.245351804593511e-05,
      "loss": 0.0446,
      "step": 10350
    },
    {
      "epoch": 3.7768866204885163,
      "grad_norm": 0.11617611348628998,
      "learning_rate": 1.2446226759022969e-05,
      "loss": 0.0294,
      "step": 10360
    },
    {
      "epoch": 3.780532263944586,
      "grad_norm": 0.006171459797769785,
      "learning_rate": 1.243893547211083e-05,
      "loss": 0.0319,
      "step": 10370
    },
    {
      "epoch": 3.784177907400656,
      "grad_norm": 0.010626907460391521,
      "learning_rate": 1.2431644185198689e-05,
      "loss": 0.0263,
      "step": 10380
    },
    {
      "epoch": 3.787823550856726,
      "grad_norm": 0.05594957619905472,
      "learning_rate": 1.242435289828655e-05,
      "loss": 0.0362,
      "step": 10390
    },
    {
      "epoch": 3.7914691943127963,
      "grad_norm": 2.560307264328003,
      "learning_rate": 1.2417061611374409e-05,
      "loss": 0.0068,
      "step": 10400
    },
    {
      "epoch": 3.795114837768866,
      "grad_norm": 0.22661224007606506,
      "learning_rate": 1.240977032446227e-05,
      "loss": 0.0142,
      "step": 10410
    },
    {
      "epoch": 3.798760481224936,
      "grad_norm": 13.480430603027344,
      "learning_rate": 1.2402479037550129e-05,
      "loss": 0.033,
      "step": 10420
    },
    {
      "epoch": 3.8024061246810064,
      "grad_norm": 0.06075199320912361,
      "learning_rate": 1.239518775063799e-05,
      "loss": 0.0114,
      "step": 10430
    },
    {
      "epoch": 3.8060517681370762,
      "grad_norm": 0.17378142476081848,
      "learning_rate": 1.2387896463725849e-05,
      "loss": 0.0461,
      "step": 10440
    },
    {
      "epoch": 3.809697411593146,
      "grad_norm": 5.097420692443848,
      "learning_rate": 1.238060517681371e-05,
      "loss": 0.0177,
      "step": 10450
    },
    {
      "epoch": 3.8133430550492164,
      "grad_norm": 0.06413384526968002,
      "learning_rate": 1.2373313889901569e-05,
      "loss": 0.0212,
      "step": 10460
    },
    {
      "epoch": 3.8169886985052863,
      "grad_norm": 0.6342000365257263,
      "learning_rate": 1.236602260298943e-05,
      "loss": 0.0242,
      "step": 10470
    },
    {
      "epoch": 3.820634341961356,
      "grad_norm": 0.07484660297632217,
      "learning_rate": 1.2358731316077289e-05,
      "loss": 0.0398,
      "step": 10480
    },
    {
      "epoch": 3.824279985417426,
      "grad_norm": 0.009617405943572521,
      "learning_rate": 1.235144002916515e-05,
      "loss": 0.008,
      "step": 10490
    },
    {
      "epoch": 3.827925628873496,
      "grad_norm": 0.12949857115745544,
      "learning_rate": 1.2344148742253009e-05,
      "loss": 0.0329,
      "step": 10500
    },
    {
      "epoch": 3.8315712723295663,
      "grad_norm": 0.012710870243608952,
      "learning_rate": 1.233685745534087e-05,
      "loss": 0.0223,
      "step": 10510
    },
    {
      "epoch": 3.835216915785636,
      "grad_norm": 1.5735975503921509,
      "learning_rate": 1.2329566168428729e-05,
      "loss": 0.0303,
      "step": 10520
    },
    {
      "epoch": 3.838862559241706,
      "grad_norm": 0.0019194363849237561,
      "learning_rate": 1.232227488151659e-05,
      "loss": 0.0275,
      "step": 10530
    },
    {
      "epoch": 3.8425082026977764,
      "grad_norm": 0.00364738330245018,
      "learning_rate": 1.2314983594604449e-05,
      "loss": 0.0001,
      "step": 10540
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 2.0916264057159424,
      "learning_rate": 1.230769230769231e-05,
      "loss": 0.0386,
      "step": 10550
    },
    {
      "epoch": 3.849799489609916,
      "grad_norm": 2.8457438945770264,
      "learning_rate": 1.2300401020780169e-05,
      "loss": 0.01,
      "step": 10560
    },
    {
      "epoch": 3.853445133065986,
      "grad_norm": 4.721772193908691,
      "learning_rate": 1.229310973386803e-05,
      "loss": 0.0453,
      "step": 10570
    },
    {
      "epoch": 3.857090776522056,
      "grad_norm": 0.004149089567363262,
      "learning_rate": 1.2285818446955889e-05,
      "loss": 0.0098,
      "step": 10580
    },
    {
      "epoch": 3.860736419978126,
      "grad_norm": 0.04201115667819977,
      "learning_rate": 1.227852716004375e-05,
      "loss": 0.0294,
      "step": 10590
    },
    {
      "epoch": 3.864382063434196,
      "grad_norm": 0.4109817147254944,
      "learning_rate": 1.2271235873131609e-05,
      "loss": 0.0388,
      "step": 10600
    },
    {
      "epoch": 3.868027706890266,
      "grad_norm": 5.170765399932861,
      "learning_rate": 1.226394458621947e-05,
      "loss": 0.0837,
      "step": 10610
    },
    {
      "epoch": 3.8716733503463363,
      "grad_norm": 0.05840510129928589,
      "learning_rate": 1.2256653299307329e-05,
      "loss": 0.0011,
      "step": 10620
    },
    {
      "epoch": 3.875318993802406,
      "grad_norm": 0.012409012764692307,
      "learning_rate": 1.224936201239519e-05,
      "loss": 0.009,
      "step": 10630
    },
    {
      "epoch": 3.878964637258476,
      "grad_norm": 14.857769012451172,
      "learning_rate": 1.2242070725483049e-05,
      "loss": 0.0447,
      "step": 10640
    },
    {
      "epoch": 3.8826102807145464,
      "grad_norm": 1.2800071239471436,
      "learning_rate": 1.223477943857091e-05,
      "loss": 0.0046,
      "step": 10650
    },
    {
      "epoch": 3.8862559241706163,
      "grad_norm": 6.1152873039245605,
      "learning_rate": 1.2227488151658769e-05,
      "loss": 0.0521,
      "step": 10660
    },
    {
      "epoch": 3.889901567626686,
      "grad_norm": 0.004675446078181267,
      "learning_rate": 1.222019686474663e-05,
      "loss": 0.0215,
      "step": 10670
    },
    {
      "epoch": 3.893547211082756,
      "grad_norm": 0.0415172204375267,
      "learning_rate": 1.2212905577834489e-05,
      "loss": 0.0223,
      "step": 10680
    },
    {
      "epoch": 3.897192854538826,
      "grad_norm": 0.23679891228675842,
      "learning_rate": 1.220561429092235e-05,
      "loss": 0.0185,
      "step": 10690
    },
    {
      "epoch": 3.9008384979948962,
      "grad_norm": 15.222373008728027,
      "learning_rate": 1.2198323004010209e-05,
      "loss": 0.0325,
      "step": 10700
    },
    {
      "epoch": 3.904484141450966,
      "grad_norm": 13.382925033569336,
      "learning_rate": 1.219103171709807e-05,
      "loss": 0.0174,
      "step": 10710
    },
    {
      "epoch": 3.908129784907036,
      "grad_norm": 0.23605531454086304,
      "learning_rate": 1.2183740430185929e-05,
      "loss": 0.0569,
      "step": 10720
    },
    {
      "epoch": 3.9117754283631063,
      "grad_norm": 2.7532482147216797,
      "learning_rate": 1.217644914327379e-05,
      "loss": 0.0149,
      "step": 10730
    },
    {
      "epoch": 3.915421071819176,
      "grad_norm": 0.007619068026542664,
      "learning_rate": 1.2169157856361649e-05,
      "loss": 0.0131,
      "step": 10740
    },
    {
      "epoch": 3.919066715275246,
      "grad_norm": 2.0857605934143066,
      "learning_rate": 1.216186656944951e-05,
      "loss": 0.0323,
      "step": 10750
    },
    {
      "epoch": 3.922712358731316,
      "grad_norm": 0.03178692236542702,
      "learning_rate": 1.2154575282537369e-05,
      "loss": 0.0002,
      "step": 10760
    },
    {
      "epoch": 3.926358002187386,
      "grad_norm": 0.031546082347631454,
      "learning_rate": 1.214728399562523e-05,
      "loss": 0.0482,
      "step": 10770
    },
    {
      "epoch": 3.930003645643456,
      "grad_norm": 1.5186020135879517,
      "learning_rate": 1.2139992708713089e-05,
      "loss": 0.0568,
      "step": 10780
    },
    {
      "epoch": 3.933649289099526,
      "grad_norm": 0.24479128420352936,
      "learning_rate": 1.213270142180095e-05,
      "loss": 0.0141,
      "step": 10790
    },
    {
      "epoch": 3.937294932555596,
      "grad_norm": 0.5578870177268982,
      "learning_rate": 1.2125410134888809e-05,
      "loss": 0.0174,
      "step": 10800
    },
    {
      "epoch": 3.9409405760116663,
      "grad_norm": 2.096163034439087,
      "learning_rate": 1.211811884797667e-05,
      "loss": 0.0385,
      "step": 10810
    },
    {
      "epoch": 3.944586219467736,
      "grad_norm": 0.014982321299612522,
      "learning_rate": 1.211082756106453e-05,
      "loss": 0.0157,
      "step": 10820
    },
    {
      "epoch": 3.948231862923806,
      "grad_norm": 1.534724235534668,
      "learning_rate": 1.210353627415239e-05,
      "loss": 0.0197,
      "step": 10830
    },
    {
      "epoch": 3.951877506379876,
      "grad_norm": 0.026183446869254112,
      "learning_rate": 1.209624498724025e-05,
      "loss": 0.0067,
      "step": 10840
    },
    {
      "epoch": 3.9555231498359458,
      "grad_norm": 0.005801061633974314,
      "learning_rate": 1.208895370032811e-05,
      "loss": 0.0305,
      "step": 10850
    },
    {
      "epoch": 3.959168793292016,
      "grad_norm": 0.6923842430114746,
      "learning_rate": 1.208166241341597e-05,
      "loss": 0.0096,
      "step": 10860
    },
    {
      "epoch": 3.962814436748086,
      "grad_norm": 3.2766685485839844,
      "learning_rate": 1.207437112650383e-05,
      "loss": 0.0445,
      "step": 10870
    },
    {
      "epoch": 3.966460080204156,
      "grad_norm": 2.036905527114868,
      "learning_rate": 1.206707983959169e-05,
      "loss": 0.0162,
      "step": 10880
    },
    {
      "epoch": 3.970105723660226,
      "grad_norm": 0.007834509946405888,
      "learning_rate": 1.205978855267955e-05,
      "loss": 0.0274,
      "step": 10890
    },
    {
      "epoch": 3.973751367116296,
      "grad_norm": 0.04165065661072731,
      "learning_rate": 1.205249726576741e-05,
      "loss": 0.0539,
      "step": 10900
    },
    {
      "epoch": 3.977397010572366,
      "grad_norm": 13.1736478805542,
      "learning_rate": 1.204520597885527e-05,
      "loss": 0.0525,
      "step": 10910
    },
    {
      "epoch": 3.9810426540284363,
      "grad_norm": 0.13767103850841522,
      "learning_rate": 1.203791469194313e-05,
      "loss": 0.0143,
      "step": 10920
    },
    {
      "epoch": 3.984688297484506,
      "grad_norm": 0.040557730942964554,
      "learning_rate": 1.203062340503099e-05,
      "loss": 0.0107,
      "step": 10930
    },
    {
      "epoch": 3.988333940940576,
      "grad_norm": 0.01870187371969223,
      "learning_rate": 1.202333211811885e-05,
      "loss": 0.0541,
      "step": 10940
    },
    {
      "epoch": 3.991979584396646,
      "grad_norm": 4.9495768547058105,
      "learning_rate": 1.201604083120671e-05,
      "loss": 0.0272,
      "step": 10950
    },
    {
      "epoch": 3.995625227852716,
      "grad_norm": 0.05882478132843971,
      "learning_rate": 1.200874954429457e-05,
      "loss": 0.018,
      "step": 10960
    },
    {
      "epoch": 3.999270871308786,
      "grad_norm": 0.036280907690525055,
      "learning_rate": 1.200145825738243e-05,
      "loss": 0.0178,
      "step": 10970
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9906835604770017,
      "eval_f1": 0.962678609511623,
      "eval_loss": 0.031148478388786316,
      "eval_precision": 0.9620630861040068,
      "eval_recall": 0.9632949210413999,
      "eval_runtime": 828.2256,
      "eval_samples_per_second": 22.716,
      "eval_steps_per_second": 0.71,
      "step": 10972
    },
    {
      "epoch": 4.002916514764856,
      "grad_norm": 0.06220420449972153,
      "learning_rate": 1.199416697047029e-05,
      "loss": 0.0312,
      "step": 10980
    },
    {
      "epoch": 4.006562158220926,
      "grad_norm": 4.837426662445068,
      "learning_rate": 1.1986875683558148e-05,
      "loss": 0.0143,
      "step": 10990
    },
    {
      "epoch": 4.010207801676996,
      "grad_norm": 0.23863445222377777,
      "learning_rate": 1.197958439664601e-05,
      "loss": 0.0488,
      "step": 11000
    },
    {
      "epoch": 4.013853445133066,
      "grad_norm": 0.2936989963054657,
      "learning_rate": 1.1972293109733869e-05,
      "loss": 0.0021,
      "step": 11010
    },
    {
      "epoch": 4.017499088589136,
      "grad_norm": 3.475588321685791,
      "learning_rate": 1.196500182282173e-05,
      "loss": 0.0228,
      "step": 11020
    },
    {
      "epoch": 4.021144732045206,
      "grad_norm": 0.05546702817082405,
      "learning_rate": 1.1957710535909589e-05,
      "loss": 0.001,
      "step": 11030
    },
    {
      "epoch": 4.024790375501276,
      "grad_norm": 0.008381050080060959,
      "learning_rate": 1.195041924899745e-05,
      "loss": 0.0073,
      "step": 11040
    },
    {
      "epoch": 4.028436018957346,
      "grad_norm": 2.239341974258423,
      "learning_rate": 1.1943127962085309e-05,
      "loss": 0.0584,
      "step": 11050
    },
    {
      "epoch": 4.032081662413416,
      "grad_norm": 4.211215019226074,
      "learning_rate": 1.193583667517317e-05,
      "loss": 0.032,
      "step": 11060
    },
    {
      "epoch": 4.035727305869486,
      "grad_norm": 1.9325159788131714,
      "learning_rate": 1.1928545388261029e-05,
      "loss": 0.0143,
      "step": 11070
    },
    {
      "epoch": 4.039372949325556,
      "grad_norm": 0.18403717875480652,
      "learning_rate": 1.192125410134889e-05,
      "loss": 0.0124,
      "step": 11080
    },
    {
      "epoch": 4.043018592781626,
      "grad_norm": 0.010380836203694344,
      "learning_rate": 1.1913962814436749e-05,
      "loss": 0.0169,
      "step": 11090
    },
    {
      "epoch": 4.046664236237696,
      "grad_norm": 0.13400478661060333,
      "learning_rate": 1.190667152752461e-05,
      "loss": 0.0084,
      "step": 11100
    },
    {
      "epoch": 4.050309879693766,
      "grad_norm": 0.013570869341492653,
      "learning_rate": 1.1899380240612469e-05,
      "loss": 0.0075,
      "step": 11110
    },
    {
      "epoch": 4.053955523149836,
      "grad_norm": 0.03257201611995697,
      "learning_rate": 1.189208895370033e-05,
      "loss": 0.0132,
      "step": 11120
    },
    {
      "epoch": 4.057601166605906,
      "grad_norm": 0.005325680132955313,
      "learning_rate": 1.1884797666788189e-05,
      "loss": 0.0262,
      "step": 11130
    },
    {
      "epoch": 4.061246810061976,
      "grad_norm": 1.128670334815979,
      "learning_rate": 1.187750637987605e-05,
      "loss": 0.0063,
      "step": 11140
    },
    {
      "epoch": 4.064892453518046,
      "grad_norm": 3.053190231323242,
      "learning_rate": 1.1870215092963909e-05,
      "loss": 0.0266,
      "step": 11150
    },
    {
      "epoch": 4.068538096974116,
      "grad_norm": 1.5783438682556152,
      "learning_rate": 1.186292380605177e-05,
      "loss": 0.0061,
      "step": 11160
    },
    {
      "epoch": 4.0721837404301855,
      "grad_norm": 0.08540903776884079,
      "learning_rate": 1.1855632519139629e-05,
      "loss": 0.0046,
      "step": 11170
    },
    {
      "epoch": 4.075829383886256,
      "grad_norm": 0.013899645768105984,
      "learning_rate": 1.184834123222749e-05,
      "loss": 0.0207,
      "step": 11180
    },
    {
      "epoch": 4.079475027342326,
      "grad_norm": 0.0480804368853569,
      "learning_rate": 1.1841049945315349e-05,
      "loss": 0.0064,
      "step": 11190
    },
    {
      "epoch": 4.083120670798396,
      "grad_norm": 0.019632702693343163,
      "learning_rate": 1.183375865840321e-05,
      "loss": 0.003,
      "step": 11200
    },
    {
      "epoch": 4.086766314254466,
      "grad_norm": 0.020943334326148033,
      "learning_rate": 1.1826467371491069e-05,
      "loss": 0.0073,
      "step": 11210
    },
    {
      "epoch": 4.090411957710536,
      "grad_norm": 0.2516430616378784,
      "learning_rate": 1.181917608457893e-05,
      "loss": 0.0078,
      "step": 11220
    },
    {
      "epoch": 4.094057601166606,
      "grad_norm": 0.0177115797996521,
      "learning_rate": 1.1811884797666789e-05,
      "loss": 0.0009,
      "step": 11230
    },
    {
      "epoch": 4.097703244622676,
      "grad_norm": 0.003057504538446665,
      "learning_rate": 1.180459351075465e-05,
      "loss": 0.0194,
      "step": 11240
    },
    {
      "epoch": 4.101348888078746,
      "grad_norm": 0.00152088631875813,
      "learning_rate": 1.1797302223842509e-05,
      "loss": 0.0325,
      "step": 11250
    },
    {
      "epoch": 4.104994531534816,
      "grad_norm": 0.018767934292554855,
      "learning_rate": 1.179001093693037e-05,
      "loss": 0.0351,
      "step": 11260
    },
    {
      "epoch": 4.108640174990886,
      "grad_norm": 5.308318614959717,
      "learning_rate": 1.1782719650018229e-05,
      "loss": 0.0559,
      "step": 11270
    },
    {
      "epoch": 4.1122858184469555,
      "grad_norm": 2.924983024597168,
      "learning_rate": 1.177542836310609e-05,
      "loss": 0.0415,
      "step": 11280
    },
    {
      "epoch": 4.115931461903026,
      "grad_norm": 0.2824087142944336,
      "learning_rate": 1.1768137076193949e-05,
      "loss": 0.0083,
      "step": 11290
    },
    {
      "epoch": 4.119577105359096,
      "grad_norm": 0.35757675766944885,
      "learning_rate": 1.176084578928181e-05,
      "loss": 0.0023,
      "step": 11300
    },
    {
      "epoch": 4.123222748815166,
      "grad_norm": 0.8622379302978516,
      "learning_rate": 1.1753554502369669e-05,
      "loss": 0.0025,
      "step": 11310
    },
    {
      "epoch": 4.126868392271236,
      "grad_norm": 0.47738510370254517,
      "learning_rate": 1.174626321545753e-05,
      "loss": 0.0349,
      "step": 11320
    },
    {
      "epoch": 4.130514035727306,
      "grad_norm": 0.0037570958957076073,
      "learning_rate": 1.1738971928545389e-05,
      "loss": 0.0066,
      "step": 11330
    },
    {
      "epoch": 4.134159679183376,
      "grad_norm": 0.011609679087996483,
      "learning_rate": 1.173168064163325e-05,
      "loss": 0.0047,
      "step": 11340
    },
    {
      "epoch": 4.137805322639446,
      "grad_norm": 0.2751055359840393,
      "learning_rate": 1.1724389354721109e-05,
      "loss": 0.0025,
      "step": 11350
    },
    {
      "epoch": 4.141450966095515,
      "grad_norm": 0.004938473459333181,
      "learning_rate": 1.171709806780897e-05,
      "loss": 0.0031,
      "step": 11360
    },
    {
      "epoch": 4.145096609551586,
      "grad_norm": 5.906840801239014,
      "learning_rate": 1.1709806780896829e-05,
      "loss": 0.0488,
      "step": 11370
    },
    {
      "epoch": 4.148742253007656,
      "grad_norm": 0.013126938603818417,
      "learning_rate": 1.170251549398469e-05,
      "loss": 0.0411,
      "step": 11380
    },
    {
      "epoch": 4.1523878964637255,
      "grad_norm": 7.773020267486572,
      "learning_rate": 1.1695224207072549e-05,
      "loss": 0.0072,
      "step": 11390
    },
    {
      "epoch": 4.156033539919796,
      "grad_norm": 1.1195257902145386,
      "learning_rate": 1.168793292016041e-05,
      "loss": 0.0013,
      "step": 11400
    },
    {
      "epoch": 4.159679183375866,
      "grad_norm": 0.005141776986420155,
      "learning_rate": 1.1680641633248269e-05,
      "loss": 0.0059,
      "step": 11410
    },
    {
      "epoch": 4.163324826831936,
      "grad_norm": 0.00306516676209867,
      "learning_rate": 1.167335034633613e-05,
      "loss": 0.0087,
      "step": 11420
    },
    {
      "epoch": 4.166970470288006,
      "grad_norm": 2.573726177215576,
      "learning_rate": 1.1666059059423989e-05,
      "loss": 0.0291,
      "step": 11430
    },
    {
      "epoch": 4.170616113744076,
      "grad_norm": 0.012017304077744484,
      "learning_rate": 1.165876777251185e-05,
      "loss": 0.0054,
      "step": 11440
    },
    {
      "epoch": 4.174261757200146,
      "grad_norm": 0.020177708938717842,
      "learning_rate": 1.1651476485599709e-05,
      "loss": 0.0256,
      "step": 11450
    },
    {
      "epoch": 4.177907400656216,
      "grad_norm": 0.011761193163692951,
      "learning_rate": 1.164418519868757e-05,
      "loss": 0.0228,
      "step": 11460
    },
    {
      "epoch": 4.1815530441122855,
      "grad_norm": 0.010622741654515266,
      "learning_rate": 1.1636893911775429e-05,
      "loss": 0.0044,
      "step": 11470
    },
    {
      "epoch": 4.185198687568356,
      "grad_norm": 0.07130133360624313,
      "learning_rate": 1.162960262486329e-05,
      "loss": 0.0029,
      "step": 11480
    },
    {
      "epoch": 4.188844331024426,
      "grad_norm": 0.003686790354549885,
      "learning_rate": 1.1622311337951149e-05,
      "loss": 0.0129,
      "step": 11490
    },
    {
      "epoch": 4.1924899744804955,
      "grad_norm": 0.44724106788635254,
      "learning_rate": 1.161502005103901e-05,
      "loss": 0.0049,
      "step": 11500
    },
    {
      "epoch": 4.196135617936566,
      "grad_norm": 0.1209924966096878,
      "learning_rate": 1.1607728764126869e-05,
      "loss": 0.0156,
      "step": 11510
    },
    {
      "epoch": 4.199781261392636,
      "grad_norm": 0.4480285942554474,
      "learning_rate": 1.160043747721473e-05,
      "loss": 0.0024,
      "step": 11520
    },
    {
      "epoch": 4.203426904848706,
      "grad_norm": 1.2778966426849365,
      "learning_rate": 1.1593146190302589e-05,
      "loss": 0.0061,
      "step": 11530
    },
    {
      "epoch": 4.207072548304776,
      "grad_norm": 0.0021262916270643473,
      "learning_rate": 1.158585490339045e-05,
      "loss": 0.0234,
      "step": 11540
    },
    {
      "epoch": 4.210718191760845,
      "grad_norm": 0.004761401563882828,
      "learning_rate": 1.1578563616478309e-05,
      "loss": 0.0214,
      "step": 11550
    },
    {
      "epoch": 4.214363835216916,
      "grad_norm": 4.072790145874023,
      "learning_rate": 1.157127232956617e-05,
      "loss": 0.0493,
      "step": 11560
    },
    {
      "epoch": 4.218009478672986,
      "grad_norm": 0.010821600444614887,
      "learning_rate": 1.1563981042654029e-05,
      "loss": 0.0149,
      "step": 11570
    },
    {
      "epoch": 4.2216551221290555,
      "grad_norm": 0.034021418541669846,
      "learning_rate": 1.155668975574189e-05,
      "loss": 0.0055,
      "step": 11580
    },
    {
      "epoch": 4.225300765585126,
      "grad_norm": 1.7707158327102661,
      "learning_rate": 1.1549398468829749e-05,
      "loss": 0.02,
      "step": 11590
    },
    {
      "epoch": 4.228946409041196,
      "grad_norm": 1.216392993927002,
      "learning_rate": 1.154210718191761e-05,
      "loss": 0.0171,
      "step": 11600
    },
    {
      "epoch": 4.2325920524972656,
      "grad_norm": 0.24084880948066711,
      "learning_rate": 1.1534815895005469e-05,
      "loss": 0.036,
      "step": 11610
    },
    {
      "epoch": 4.236237695953336,
      "grad_norm": 0.2536057233810425,
      "learning_rate": 1.152752460809333e-05,
      "loss": 0.0058,
      "step": 11620
    },
    {
      "epoch": 4.239883339409406,
      "grad_norm": 0.012881578877568245,
      "learning_rate": 1.1520233321181189e-05,
      "loss": 0.0065,
      "step": 11630
    },
    {
      "epoch": 4.243528982865476,
      "grad_norm": 9.782228469848633,
      "learning_rate": 1.151294203426905e-05,
      "loss": 0.0407,
      "step": 11640
    },
    {
      "epoch": 4.247174626321546,
      "grad_norm": 0.4379538595676422,
      "learning_rate": 1.150565074735691e-05,
      "loss": 0.0152,
      "step": 11650
    },
    {
      "epoch": 4.250820269777615,
      "grad_norm": 0.003928764723241329,
      "learning_rate": 1.149835946044477e-05,
      "loss": 0.0056,
      "step": 11660
    },
    {
      "epoch": 4.254465913233686,
      "grad_norm": 0.013244818896055222,
      "learning_rate": 1.149106817353263e-05,
      "loss": 0.0067,
      "step": 11670
    },
    {
      "epoch": 4.258111556689756,
      "grad_norm": 2.2523975372314453,
      "learning_rate": 1.148377688662049e-05,
      "loss": 0.0215,
      "step": 11680
    },
    {
      "epoch": 4.2617572001458255,
      "grad_norm": 0.018523409962654114,
      "learning_rate": 1.147648559970835e-05,
      "loss": 0.0001,
      "step": 11690
    },
    {
      "epoch": 4.265402843601896,
      "grad_norm": 0.0007710597710683942,
      "learning_rate": 1.146919431279621e-05,
      "loss": 0.0008,
      "step": 11700
    },
    {
      "epoch": 4.269048487057966,
      "grad_norm": 0.0022522800136357546,
      "learning_rate": 1.146190302588407e-05,
      "loss": 0.0127,
      "step": 11710
    },
    {
      "epoch": 4.272694130514036,
      "grad_norm": 0.007178091444075108,
      "learning_rate": 1.145461173897193e-05,
      "loss": 0.0001,
      "step": 11720
    },
    {
      "epoch": 4.276339773970106,
      "grad_norm": 0.0032873048912733793,
      "learning_rate": 1.144732045205979e-05,
      "loss": 0.0002,
      "step": 11730
    },
    {
      "epoch": 4.279985417426175,
      "grad_norm": 24.450475692749023,
      "learning_rate": 1.144002916514765e-05,
      "loss": 0.0036,
      "step": 11740
    },
    {
      "epoch": 4.283631060882246,
      "grad_norm": 0.9306278228759766,
      "learning_rate": 1.143273787823551e-05,
      "loss": 0.0174,
      "step": 11750
    },
    {
      "epoch": 4.287276704338316,
      "grad_norm": 0.0008875924977473915,
      "learning_rate": 1.142544659132337e-05,
      "loss": 0.019,
      "step": 11760
    },
    {
      "epoch": 4.290922347794385,
      "grad_norm": 5.594891548156738,
      "learning_rate": 1.141815530441123e-05,
      "loss": 0.0034,
      "step": 11770
    },
    {
      "epoch": 4.294567991250456,
      "grad_norm": 10.385436058044434,
      "learning_rate": 1.141086401749909e-05,
      "loss": 0.0277,
      "step": 11780
    },
    {
      "epoch": 4.298213634706526,
      "grad_norm": 0.0016163733089342713,
      "learning_rate": 1.140357273058695e-05,
      "loss": 0.0094,
      "step": 11790
    },
    {
      "epoch": 4.3018592781625955,
      "grad_norm": 0.002513311570510268,
      "learning_rate": 1.139628144367481e-05,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 4.305504921618666,
      "grad_norm": 0.0017986564198508859,
      "learning_rate": 1.138899015676267e-05,
      "loss": 0.0304,
      "step": 11810
    },
    {
      "epoch": 4.309150565074736,
      "grad_norm": 0.0016465849475935102,
      "learning_rate": 1.138169886985053e-05,
      "loss": 0.0015,
      "step": 11820
    },
    {
      "epoch": 4.312796208530806,
      "grad_norm": 2.700713634490967,
      "learning_rate": 1.137440758293839e-05,
      "loss": 0.0033,
      "step": 11830
    },
    {
      "epoch": 4.316441851986876,
      "grad_norm": 0.01102951169013977,
      "learning_rate": 1.136711629602625e-05,
      "loss": 0.0316,
      "step": 11840
    },
    {
      "epoch": 4.320087495442945,
      "grad_norm": 17.361501693725586,
      "learning_rate": 1.135982500911411e-05,
      "loss": 0.0325,
      "step": 11850
    },
    {
      "epoch": 4.323733138899016,
      "grad_norm": 0.7954520583152771,
      "learning_rate": 1.135253372220197e-05,
      "loss": 0.0218,
      "step": 11860
    },
    {
      "epoch": 4.327378782355086,
      "grad_norm": 4.5846781730651855,
      "learning_rate": 1.134524243528983e-05,
      "loss": 0.0251,
      "step": 11870
    },
    {
      "epoch": 4.331024425811155,
      "grad_norm": 15.671133041381836,
      "learning_rate": 1.133795114837769e-05,
      "loss": 0.0167,
      "step": 11880
    },
    {
      "epoch": 4.334670069267226,
      "grad_norm": 1.814003825187683,
      "learning_rate": 1.133065986146555e-05,
      "loss": 0.0071,
      "step": 11890
    },
    {
      "epoch": 4.338315712723295,
      "grad_norm": 0.5953901410102844,
      "learning_rate": 1.132336857455341e-05,
      "loss": 0.0187,
      "step": 11900
    },
    {
      "epoch": 4.3419613561793655,
      "grad_norm": 0.11025166511535645,
      "learning_rate": 1.131607728764127e-05,
      "loss": 0.0015,
      "step": 11910
    },
    {
      "epoch": 4.345606999635436,
      "grad_norm": 1.003307580947876,
      "learning_rate": 1.130878600072913e-05,
      "loss": 0.005,
      "step": 11920
    },
    {
      "epoch": 4.349252643091505,
      "grad_norm": 0.007885979488492012,
      "learning_rate": 1.130149471381699e-05,
      "loss": 0.0067,
      "step": 11930
    },
    {
      "epoch": 4.352898286547576,
      "grad_norm": 2.261199474334717,
      "learning_rate": 1.129420342690485e-05,
      "loss": 0.0527,
      "step": 11940
    },
    {
      "epoch": 4.356543930003646,
      "grad_norm": 0.00033906850148923695,
      "learning_rate": 1.128691213999271e-05,
      "loss": 0.0172,
      "step": 11950
    },
    {
      "epoch": 4.360189573459715,
      "grad_norm": 0.04834470525383949,
      "learning_rate": 1.127962085308057e-05,
      "loss": 0.0005,
      "step": 11960
    },
    {
      "epoch": 4.363835216915786,
      "grad_norm": 0.002464046236127615,
      "learning_rate": 1.127232956616843e-05,
      "loss": 0.0259,
      "step": 11970
    },
    {
      "epoch": 4.367480860371856,
      "grad_norm": 0.00296720745973289,
      "learning_rate": 1.126503827925629e-05,
      "loss": 0.0134,
      "step": 11980
    },
    {
      "epoch": 4.3711265038279254,
      "grad_norm": 2.169532299041748,
      "learning_rate": 1.125774699234415e-05,
      "loss": 0.0438,
      "step": 11990
    },
    {
      "epoch": 4.374772147283996,
      "grad_norm": 0.0023993703071027994,
      "learning_rate": 1.125045570543201e-05,
      "loss": 0.0048,
      "step": 12000
    },
    {
      "epoch": 4.378417790740065,
      "grad_norm": 0.0021738356444984674,
      "learning_rate": 1.124316441851987e-05,
      "loss": 0.0072,
      "step": 12010
    },
    {
      "epoch": 4.3820634341961355,
      "grad_norm": 0.003532180329784751,
      "learning_rate": 1.123587313160773e-05,
      "loss": 0.003,
      "step": 12020
    },
    {
      "epoch": 4.385709077652206,
      "grad_norm": 2.0782887935638428,
      "learning_rate": 1.122858184469559e-05,
      "loss": 0.036,
      "step": 12030
    },
    {
      "epoch": 4.389354721108275,
      "grad_norm": 0.102473184466362,
      "learning_rate": 1.122129055778345e-05,
      "loss": 0.0035,
      "step": 12040
    },
    {
      "epoch": 4.393000364564346,
      "grad_norm": 0.005399663466960192,
      "learning_rate": 1.121399927087131e-05,
      "loss": 0.0102,
      "step": 12050
    },
    {
      "epoch": 4.396646008020416,
      "grad_norm": 0.05252966284751892,
      "learning_rate": 1.120670798395917e-05,
      "loss": 0.0024,
      "step": 12060
    },
    {
      "epoch": 4.400291651476485,
      "grad_norm": 1.330100655555725,
      "learning_rate": 1.119941669704703e-05,
      "loss": 0.0175,
      "step": 12070
    },
    {
      "epoch": 4.403937294932556,
      "grad_norm": 0.007570489775389433,
      "learning_rate": 1.1192125410134889e-05,
      "loss": 0.0153,
      "step": 12080
    },
    {
      "epoch": 4.407582938388625,
      "grad_norm": 0.0018922417657449841,
      "learning_rate": 1.118483412322275e-05,
      "loss": 0.0001,
      "step": 12090
    },
    {
      "epoch": 4.4112285818446955,
      "grad_norm": 0.007410923019051552,
      "learning_rate": 1.1177542836310609e-05,
      "loss": 0.0044,
      "step": 12100
    },
    {
      "epoch": 4.414874225300766,
      "grad_norm": 0.012134667485952377,
      "learning_rate": 1.117025154939847e-05,
      "loss": 0.0043,
      "step": 12110
    },
    {
      "epoch": 4.418519868756835,
      "grad_norm": 0.02119934745132923,
      "learning_rate": 1.1162960262486329e-05,
      "loss": 0.0403,
      "step": 12120
    },
    {
      "epoch": 4.4221655122129055,
      "grad_norm": 0.029825516045093536,
      "learning_rate": 1.115566897557419e-05,
      "loss": 0.0101,
      "step": 12130
    },
    {
      "epoch": 4.425811155668976,
      "grad_norm": 0.009646863676607609,
      "learning_rate": 1.1148377688662049e-05,
      "loss": 0.0035,
      "step": 12140
    },
    {
      "epoch": 4.429456799125045,
      "grad_norm": 0.021426452323794365,
      "learning_rate": 1.114108640174991e-05,
      "loss": 0.0129,
      "step": 12150
    },
    {
      "epoch": 4.433102442581116,
      "grad_norm": 9.57232666015625,
      "learning_rate": 1.1133795114837769e-05,
      "loss": 0.0172,
      "step": 12160
    },
    {
      "epoch": 4.436748086037186,
      "grad_norm": 0.004413168877363205,
      "learning_rate": 1.112650382792563e-05,
      "loss": 0.0006,
      "step": 12170
    },
    {
      "epoch": 4.440393729493255,
      "grad_norm": 0.0028620644006878138,
      "learning_rate": 1.1119212541013489e-05,
      "loss": 0.0377,
      "step": 12180
    },
    {
      "epoch": 4.444039372949326,
      "grad_norm": 0.004847225267440081,
      "learning_rate": 1.111192125410135e-05,
      "loss": 0.0013,
      "step": 12190
    },
    {
      "epoch": 4.447685016405395,
      "grad_norm": 0.012086242437362671,
      "learning_rate": 1.1104629967189209e-05,
      "loss": 0.0336,
      "step": 12200
    },
    {
      "epoch": 4.4513306598614655,
      "grad_norm": 0.005260596051812172,
      "learning_rate": 1.109733868027707e-05,
      "loss": 0.0008,
      "step": 12210
    },
    {
      "epoch": 4.454976303317536,
      "grad_norm": 0.2902086079120636,
      "learning_rate": 1.1090047393364929e-05,
      "loss": 0.0129,
      "step": 12220
    },
    {
      "epoch": 4.458621946773605,
      "grad_norm": 0.6815758943557739,
      "learning_rate": 1.108275610645279e-05,
      "loss": 0.0102,
      "step": 12230
    },
    {
      "epoch": 4.462267590229676,
      "grad_norm": 0.0037257748190313578,
      "learning_rate": 1.1075464819540649e-05,
      "loss": 0.0094,
      "step": 12240
    },
    {
      "epoch": 4.465913233685746,
      "grad_norm": 0.7391835451126099,
      "learning_rate": 1.106817353262851e-05,
      "loss": 0.0027,
      "step": 12250
    },
    {
      "epoch": 4.469558877141815,
      "grad_norm": 0.002187887439504266,
      "learning_rate": 1.1060882245716369e-05,
      "loss": 0.0151,
      "step": 12260
    },
    {
      "epoch": 4.473204520597886,
      "grad_norm": 0.0009156313608400524,
      "learning_rate": 1.105359095880423e-05,
      "loss": 0.0071,
      "step": 12270
    },
    {
      "epoch": 4.476850164053955,
      "grad_norm": 9.461395263671875,
      "learning_rate": 1.1046299671892089e-05,
      "loss": 0.0598,
      "step": 12280
    },
    {
      "epoch": 4.480495807510025,
      "grad_norm": 0.010850326158106327,
      "learning_rate": 1.103900838497995e-05,
      "loss": 0.021,
      "step": 12290
    },
    {
      "epoch": 4.484141450966096,
      "grad_norm": 1.1779299974441528,
      "learning_rate": 1.1031717098067809e-05,
      "loss": 0.0062,
      "step": 12300
    },
    {
      "epoch": 4.487787094422165,
      "grad_norm": 1.0085115432739258,
      "learning_rate": 1.102442581115567e-05,
      "loss": 0.0044,
      "step": 12310
    },
    {
      "epoch": 4.4914327378782355,
      "grad_norm": 2.4114227294921875,
      "learning_rate": 1.1017134524243529e-05,
      "loss": 0.0212,
      "step": 12320
    },
    {
      "epoch": 4.495078381334306,
      "grad_norm": 0.028358975425362587,
      "learning_rate": 1.100984323733139e-05,
      "loss": 0.0241,
      "step": 12330
    },
    {
      "epoch": 4.498724024790375,
      "grad_norm": 0.0014888339210301638,
      "learning_rate": 1.1002551950419249e-05,
      "loss": 0.011,
      "step": 12340
    },
    {
      "epoch": 4.502369668246446,
      "grad_norm": 0.8744140267372131,
      "learning_rate": 1.099526066350711e-05,
      "loss": 0.0036,
      "step": 12350
    },
    {
      "epoch": 4.506015311702516,
      "grad_norm": 3.4013919830322266,
      "learning_rate": 1.0987969376594969e-05,
      "loss": 0.0173,
      "step": 12360
    },
    {
      "epoch": 4.509660955158585,
      "grad_norm": 16.052780151367188,
      "learning_rate": 1.098067808968283e-05,
      "loss": 0.0586,
      "step": 12370
    },
    {
      "epoch": 4.513306598614656,
      "grad_norm": 0.001334784901700914,
      "learning_rate": 1.0973386802770689e-05,
      "loss": 0.0022,
      "step": 12380
    },
    {
      "epoch": 4.516952242070725,
      "grad_norm": 0.0011789511190727353,
      "learning_rate": 1.096609551585855e-05,
      "loss": 0.0079,
      "step": 12390
    },
    {
      "epoch": 4.520597885526795,
      "grad_norm": 0.0026315695140510798,
      "learning_rate": 1.0958804228946409e-05,
      "loss": 0.0284,
      "step": 12400
    },
    {
      "epoch": 4.524243528982866,
      "grad_norm": 0.0024360292591154575,
      "learning_rate": 1.095151294203427e-05,
      "loss": 0.0298,
      "step": 12410
    },
    {
      "epoch": 4.527889172438935,
      "grad_norm": 0.002603597939014435,
      "learning_rate": 1.0944221655122129e-05,
      "loss": 0.0237,
      "step": 12420
    },
    {
      "epoch": 4.5315348158950055,
      "grad_norm": 0.016922282055020332,
      "learning_rate": 1.093693036820999e-05,
      "loss": 0.0027,
      "step": 12430
    },
    {
      "epoch": 4.535180459351076,
      "grad_norm": 0.25806671380996704,
      "learning_rate": 1.0929639081297849e-05,
      "loss": 0.0183,
      "step": 12440
    },
    {
      "epoch": 4.538826102807145,
      "grad_norm": 0.00790775939822197,
      "learning_rate": 1.092234779438571e-05,
      "loss": 0.0192,
      "step": 12450
    },
    {
      "epoch": 4.542471746263216,
      "grad_norm": 0.010322807356715202,
      "learning_rate": 1.0915056507473569e-05,
      "loss": 0.006,
      "step": 12460
    },
    {
      "epoch": 4.546117389719285,
      "grad_norm": 0.1262873113155365,
      "learning_rate": 1.090776522056143e-05,
      "loss": 0.0124,
      "step": 12470
    },
    {
      "epoch": 4.549763033175355,
      "grad_norm": 0.010991940274834633,
      "learning_rate": 1.0900473933649289e-05,
      "loss": 0.035,
      "step": 12480
    },
    {
      "epoch": 4.553408676631426,
      "grad_norm": 0.0072092716582119465,
      "learning_rate": 1.089318264673715e-05,
      "loss": 0.0017,
      "step": 12490
    },
    {
      "epoch": 4.557054320087495,
      "grad_norm": 0.007878480479121208,
      "learning_rate": 1.088589135982501e-05,
      "loss": 0.0038,
      "step": 12500
    },
    {
      "epoch": 4.560699963543565,
      "grad_norm": 0.16902802884578705,
      "learning_rate": 1.087860007291287e-05,
      "loss": 0.0061,
      "step": 12510
    },
    {
      "epoch": 4.564345606999636,
      "grad_norm": 0.06199895590543747,
      "learning_rate": 1.087130878600073e-05,
      "loss": 0.0249,
      "step": 12520
    },
    {
      "epoch": 4.567991250455705,
      "grad_norm": 0.0071272472850978374,
      "learning_rate": 1.086401749908859e-05,
      "loss": 0.0157,
      "step": 12530
    },
    {
      "epoch": 4.5716368939117755,
      "grad_norm": 2.587111234664917,
      "learning_rate": 1.085672621217645e-05,
      "loss": 0.0183,
      "step": 12540
    },
    {
      "epoch": 4.575282537367846,
      "grad_norm": 4.284721374511719,
      "learning_rate": 1.084943492526431e-05,
      "loss": 0.0393,
      "step": 12550
    },
    {
      "epoch": 4.578928180823915,
      "grad_norm": 0.0067805033177137375,
      "learning_rate": 1.084214363835217e-05,
      "loss": 0.0132,
      "step": 12560
    },
    {
      "epoch": 4.582573824279986,
      "grad_norm": 0.018027901649475098,
      "learning_rate": 1.083485235144003e-05,
      "loss": 0.0156,
      "step": 12570
    },
    {
      "epoch": 4.586219467736055,
      "grad_norm": 1.3399394750595093,
      "learning_rate": 1.082756106452789e-05,
      "loss": 0.0437,
      "step": 12580
    },
    {
      "epoch": 4.589865111192125,
      "grad_norm": 0.6018697619438171,
      "learning_rate": 1.082026977761575e-05,
      "loss": 0.0137,
      "step": 12590
    },
    {
      "epoch": 4.593510754648196,
      "grad_norm": 0.7220544815063477,
      "learning_rate": 1.081297849070361e-05,
      "loss": 0.0027,
      "step": 12600
    },
    {
      "epoch": 4.597156398104265,
      "grad_norm": 4.004828929901123,
      "learning_rate": 1.080568720379147e-05,
      "loss": 0.0205,
      "step": 12610
    },
    {
      "epoch": 4.6008020415603355,
      "grad_norm": 0.008647886104881763,
      "learning_rate": 1.079839591687933e-05,
      "loss": 0.0386,
      "step": 12620
    },
    {
      "epoch": 4.604447685016406,
      "grad_norm": 0.020477820187807083,
      "learning_rate": 1.079110462996719e-05,
      "loss": 0.0216,
      "step": 12630
    },
    {
      "epoch": 4.608093328472475,
      "grad_norm": 0.00690814945846796,
      "learning_rate": 1.078381334305505e-05,
      "loss": 0.0087,
      "step": 12640
    },
    {
      "epoch": 4.6117389719285455,
      "grad_norm": 0.2682308256626129,
      "learning_rate": 1.077652205614291e-05,
      "loss": 0.0572,
      "step": 12650
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 0.8125718235969543,
      "learning_rate": 1.076923076923077e-05,
      "loss": 0.0086,
      "step": 12660
    },
    {
      "epoch": 4.619030258840685,
      "grad_norm": 0.014345133677124977,
      "learning_rate": 1.076193948231863e-05,
      "loss": 0.0227,
      "step": 12670
    },
    {
      "epoch": 4.622675902296756,
      "grad_norm": 0.017406543716788292,
      "learning_rate": 1.075464819540649e-05,
      "loss": 0.0163,
      "step": 12680
    },
    {
      "epoch": 4.626321545752825,
      "grad_norm": 0.020136909559369087,
      "learning_rate": 1.074735690849435e-05,
      "loss": 0.0311,
      "step": 12690
    },
    {
      "epoch": 4.629967189208895,
      "grad_norm": 0.004664367530494928,
      "learning_rate": 1.074006562158221e-05,
      "loss": 0.0027,
      "step": 12700
    },
    {
      "epoch": 4.633612832664966,
      "grad_norm": 0.01631241850554943,
      "learning_rate": 1.073277433467007e-05,
      "loss": 0.0073,
      "step": 12710
    },
    {
      "epoch": 4.637258476121035,
      "grad_norm": 0.002342546358704567,
      "learning_rate": 1.072548304775793e-05,
      "loss": 0.0318,
      "step": 12720
    },
    {
      "epoch": 4.6409041195771055,
      "grad_norm": 5.48561429977417,
      "learning_rate": 1.071819176084579e-05,
      "loss": 0.07,
      "step": 12730
    },
    {
      "epoch": 4.644549763033176,
      "grad_norm": 0.3275275230407715,
      "learning_rate": 1.071090047393365e-05,
      "loss": 0.0258,
      "step": 12740
    },
    {
      "epoch": 4.648195406489245,
      "grad_norm": 0.03296850994229317,
      "learning_rate": 1.070360918702151e-05,
      "loss": 0.0384,
      "step": 12750
    },
    {
      "epoch": 4.6518410499453156,
      "grad_norm": 0.021039560437202454,
      "learning_rate": 1.069631790010937e-05,
      "loss": 0.0018,
      "step": 12760
    },
    {
      "epoch": 4.655486693401385,
      "grad_norm": 0.05533885955810547,
      "learning_rate": 1.068902661319723e-05,
      "loss": 0.0211,
      "step": 12770
    },
    {
      "epoch": 4.659132336857455,
      "grad_norm": 0.6064233779907227,
      "learning_rate": 1.068173532628509e-05,
      "loss": 0.0141,
      "step": 12780
    },
    {
      "epoch": 4.662777980313526,
      "grad_norm": 0.10594873130321503,
      "learning_rate": 1.067444403937295e-05,
      "loss": 0.0103,
      "step": 12790
    },
    {
      "epoch": 4.666423623769595,
      "grad_norm": 5.836148738861084,
      "learning_rate": 1.066715275246081e-05,
      "loss": 0.0161,
      "step": 12800
    },
    {
      "epoch": 4.670069267225665,
      "grad_norm": 0.007577357813715935,
      "learning_rate": 1.065986146554867e-05,
      "loss": 0.0013,
      "step": 12810
    },
    {
      "epoch": 4.673714910681735,
      "grad_norm": 2.313411235809326,
      "learning_rate": 1.065257017863653e-05,
      "loss": 0.0093,
      "step": 12820
    },
    {
      "epoch": 4.677360554137805,
      "grad_norm": 0.029388874769210815,
      "learning_rate": 1.064527889172439e-05,
      "loss": 0.0607,
      "step": 12830
    },
    {
      "epoch": 4.6810061975938755,
      "grad_norm": 0.007747832685709,
      "learning_rate": 1.063798760481225e-05,
      "loss": 0.0136,
      "step": 12840
    },
    {
      "epoch": 4.684651841049945,
      "grad_norm": 0.07491681724786758,
      "learning_rate": 1.063069631790011e-05,
      "loss": 0.0135,
      "step": 12850
    },
    {
      "epoch": 4.688297484506015,
      "grad_norm": 0.10118245333433151,
      "learning_rate": 1.062340503098797e-05,
      "loss": 0.0023,
      "step": 12860
    },
    {
      "epoch": 4.691943127962086,
      "grad_norm": 0.28536808490753174,
      "learning_rate": 1.061611374407583e-05,
      "loss": 0.031,
      "step": 12870
    },
    {
      "epoch": 4.695588771418155,
      "grad_norm": 4.695225715637207,
      "learning_rate": 1.060882245716369e-05,
      "loss": 0.0334,
      "step": 12880
    },
    {
      "epoch": 4.699234414874225,
      "grad_norm": 8.555230140686035,
      "learning_rate": 1.060153117025155e-05,
      "loss": 0.0213,
      "step": 12890
    },
    {
      "epoch": 4.702880058330296,
      "grad_norm": 1.295739769935608,
      "learning_rate": 1.059423988333941e-05,
      "loss": 0.0138,
      "step": 12900
    },
    {
      "epoch": 4.706525701786365,
      "grad_norm": 3.326458215713501,
      "learning_rate": 1.058694859642727e-05,
      "loss": 0.0253,
      "step": 12910
    },
    {
      "epoch": 4.710171345242435,
      "grad_norm": 2.4330968856811523,
      "learning_rate": 1.057965730951513e-05,
      "loss": 0.0212,
      "step": 12920
    },
    {
      "epoch": 4.713816988698506,
      "grad_norm": 0.022754501551389694,
      "learning_rate": 1.057236602260299e-05,
      "loss": 0.0039,
      "step": 12930
    },
    {
      "epoch": 4.717462632154575,
      "grad_norm": 3.044558525085449,
      "learning_rate": 1.056507473569085e-05,
      "loss": 0.0145,
      "step": 12940
    },
    {
      "epoch": 4.7211082756106455,
      "grad_norm": 0.1649460345506668,
      "learning_rate": 1.055778344877871e-05,
      "loss": 0.0111,
      "step": 12950
    },
    {
      "epoch": 4.724753919066715,
      "grad_norm": 0.004091469570994377,
      "learning_rate": 1.055049216186657e-05,
      "loss": 0.0137,
      "step": 12960
    },
    {
      "epoch": 4.728399562522785,
      "grad_norm": 14.26157283782959,
      "learning_rate": 1.054320087495443e-05,
      "loss": 0.0445,
      "step": 12970
    },
    {
      "epoch": 4.732045205978856,
      "grad_norm": 0.059764571487903595,
      "learning_rate": 1.053590958804229e-05,
      "loss": 0.0067,
      "step": 12980
    },
    {
      "epoch": 4.735690849434925,
      "grad_norm": 0.00942777656018734,
      "learning_rate": 1.052861830113015e-05,
      "loss": 0.0291,
      "step": 12990
    },
    {
      "epoch": 4.739336492890995,
      "grad_norm": 0.0067800418473780155,
      "learning_rate": 1.052132701421801e-05,
      "loss": 0.0049,
      "step": 13000
    },
    {
      "epoch": 4.742982136347065,
      "grad_norm": 0.0021199840120971203,
      "learning_rate": 1.051403572730587e-05,
      "loss": 0.0095,
      "step": 13010
    },
    {
      "epoch": 4.746627779803135,
      "grad_norm": 0.005742720328271389,
      "learning_rate": 1.050674444039373e-05,
      "loss": 0.0003,
      "step": 13020
    },
    {
      "epoch": 4.750273423259205,
      "grad_norm": 0.27816393971443176,
      "learning_rate": 1.049945315348159e-05,
      "loss": 0.0328,
      "step": 13030
    },
    {
      "epoch": 4.753919066715275,
      "grad_norm": 4.464357376098633,
      "learning_rate": 1.049216186656945e-05,
      "loss": 0.0247,
      "step": 13040
    },
    {
      "epoch": 4.757564710171345,
      "grad_norm": 0.0025676873046904802,
      "learning_rate": 1.048487057965731e-05,
      "loss": 0.0295,
      "step": 13050
    },
    {
      "epoch": 4.7612103536274155,
      "grad_norm": 0.3523705005645752,
      "learning_rate": 1.047757929274517e-05,
      "loss": 0.001,
      "step": 13060
    },
    {
      "epoch": 4.764855997083485,
      "grad_norm": 0.02728665992617607,
      "learning_rate": 1.047028800583303e-05,
      "loss": 0.0149,
      "step": 13070
    },
    {
      "epoch": 4.768501640539555,
      "grad_norm": 5.120081901550293,
      "learning_rate": 1.046299671892089e-05,
      "loss": 0.065,
      "step": 13080
    },
    {
      "epoch": 4.772147283995626,
      "grad_norm": 13.189203262329102,
      "learning_rate": 1.045570543200875e-05,
      "loss": 0.0338,
      "step": 13090
    },
    {
      "epoch": 4.775792927451695,
      "grad_norm": 0.06631950289011002,
      "learning_rate": 1.044841414509661e-05,
      "loss": 0.022,
      "step": 13100
    },
    {
      "epoch": 4.779438570907765,
      "grad_norm": 0.017788730561733246,
      "learning_rate": 1.044112285818447e-05,
      "loss": 0.0031,
      "step": 13110
    },
    {
      "epoch": 4.783084214363836,
      "grad_norm": 4.912576675415039,
      "learning_rate": 1.043383157127233e-05,
      "loss": 0.0193,
      "step": 13120
    },
    {
      "epoch": 4.786729857819905,
      "grad_norm": 0.007102797739207745,
      "learning_rate": 1.0426540284360192e-05,
      "loss": 0.0345,
      "step": 13130
    },
    {
      "epoch": 4.7903755012759754,
      "grad_norm": 0.7773551940917969,
      "learning_rate": 1.041924899744805e-05,
      "loss": 0.0084,
      "step": 13140
    },
    {
      "epoch": 4.794021144732045,
      "grad_norm": 0.16648150980472565,
      "learning_rate": 1.0411957710535912e-05,
      "loss": 0.0048,
      "step": 13150
    },
    {
      "epoch": 4.797666788188115,
      "grad_norm": 4.199819564819336,
      "learning_rate": 1.040466642362377e-05,
      "loss": 0.049,
      "step": 13160
    },
    {
      "epoch": 4.8013124316441855,
      "grad_norm": 0.011802038177847862,
      "learning_rate": 1.0397375136711629e-05,
      "loss": 0.0064,
      "step": 13170
    },
    {
      "epoch": 4.804958075100255,
      "grad_norm": 1.1999586820602417,
      "learning_rate": 1.039008384979949e-05,
      "loss": 0.0123,
      "step": 13180
    },
    {
      "epoch": 4.808603718556325,
      "grad_norm": 0.02735571376979351,
      "learning_rate": 1.0382792562887349e-05,
      "loss": 0.0145,
      "step": 13190
    },
    {
      "epoch": 4.812249362012395,
      "grad_norm": 0.008693591691553593,
      "learning_rate": 1.037550127597521e-05,
      "loss": 0.0143,
      "step": 13200
    },
    {
      "epoch": 4.815895005468465,
      "grad_norm": 0.013929134234786034,
      "learning_rate": 1.0368209989063069e-05,
      "loss": 0.0263,
      "step": 13210
    },
    {
      "epoch": 4.819540648924535,
      "grad_norm": 0.26566824316978455,
      "learning_rate": 1.036091870215093e-05,
      "loss": 0.0031,
      "step": 13220
    },
    {
      "epoch": 4.823186292380605,
      "grad_norm": 2.23008131980896,
      "learning_rate": 1.0353627415238789e-05,
      "loss": 0.0275,
      "step": 13230
    },
    {
      "epoch": 4.826831935836675,
      "grad_norm": 0.011669172905385494,
      "learning_rate": 1.034633612832665e-05,
      "loss": 0.0035,
      "step": 13240
    },
    {
      "epoch": 4.8304775792927455,
      "grad_norm": 0.014459880068898201,
      "learning_rate": 1.0339044841414509e-05,
      "loss": 0.0211,
      "step": 13250
    },
    {
      "epoch": 4.834123222748815,
      "grad_norm": 0.7480533123016357,
      "learning_rate": 1.033175355450237e-05,
      "loss": 0.0035,
      "step": 13260
    },
    {
      "epoch": 4.837768866204885,
      "grad_norm": 0.012375758960843086,
      "learning_rate": 1.0324462267590229e-05,
      "loss": 0.0005,
      "step": 13270
    },
    {
      "epoch": 4.8414145096609555,
      "grad_norm": 0.002097410149872303,
      "learning_rate": 1.031717098067809e-05,
      "loss": 0.0009,
      "step": 13280
    },
    {
      "epoch": 4.845060153117025,
      "grad_norm": 0.0028438640292733908,
      "learning_rate": 1.0309879693765949e-05,
      "loss": 0.0131,
      "step": 13290
    },
    {
      "epoch": 4.848705796573095,
      "grad_norm": 0.006354921497404575,
      "learning_rate": 1.030258840685381e-05,
      "loss": 0.0072,
      "step": 13300
    },
    {
      "epoch": 4.852351440029166,
      "grad_norm": 0.0010562422685325146,
      "learning_rate": 1.0295297119941669e-05,
      "loss": 0.0046,
      "step": 13310
    },
    {
      "epoch": 4.855997083485235,
      "grad_norm": 1.022807002067566,
      "learning_rate": 1.028800583302953e-05,
      "loss": 0.0006,
      "step": 13320
    },
    {
      "epoch": 4.859642726941305,
      "grad_norm": 0.05099743977189064,
      "learning_rate": 1.028071454611739e-05,
      "loss": 0.0196,
      "step": 13330
    },
    {
      "epoch": 4.863288370397375,
      "grad_norm": 0.01512794941663742,
      "learning_rate": 1.027342325920525e-05,
      "loss": 0.0414,
      "step": 13340
    },
    {
      "epoch": 4.866934013853445,
      "grad_norm": 0.00988844409584999,
      "learning_rate": 1.026613197229311e-05,
      "loss": 0.0028,
      "step": 13350
    },
    {
      "epoch": 4.8705796573095155,
      "grad_norm": 0.015493474900722504,
      "learning_rate": 1.025884068538097e-05,
      "loss": 0.0044,
      "step": 13360
    },
    {
      "epoch": 4.874225300765585,
      "grad_norm": 0.019778884947299957,
      "learning_rate": 1.025154939846883e-05,
      "loss": 0.0133,
      "step": 13370
    },
    {
      "epoch": 4.877870944221655,
      "grad_norm": 1.0295871496200562,
      "learning_rate": 1.024425811155669e-05,
      "loss": 0.0242,
      "step": 13380
    },
    {
      "epoch": 4.881516587677725,
      "grad_norm": 0.01288058515638113,
      "learning_rate": 1.023696682464455e-05,
      "loss": 0.0169,
      "step": 13390
    },
    {
      "epoch": 4.885162231133795,
      "grad_norm": 0.015357506461441517,
      "learning_rate": 1.022967553773241e-05,
      "loss": 0.0147,
      "step": 13400
    },
    {
      "epoch": 4.888807874589865,
      "grad_norm": 5.857457637786865,
      "learning_rate": 1.022238425082027e-05,
      "loss": 0.0371,
      "step": 13410
    },
    {
      "epoch": 4.892453518045935,
      "grad_norm": 0.008520195260643959,
      "learning_rate": 1.021509296390813e-05,
      "loss": 0.0012,
      "step": 13420
    },
    {
      "epoch": 4.896099161502005,
      "grad_norm": 2.262908935546875,
      "learning_rate": 1.020780167699599e-05,
      "loss": 0.0129,
      "step": 13430
    },
    {
      "epoch": 4.899744804958075,
      "grad_norm": 0.15218549966812134,
      "learning_rate": 1.020051039008385e-05,
      "loss": 0.0577,
      "step": 13440
    },
    {
      "epoch": 4.903390448414145,
      "grad_norm": 0.02995757758617401,
      "learning_rate": 1.019321910317171e-05,
      "loss": 0.0051,
      "step": 13450
    },
    {
      "epoch": 4.907036091870215,
      "grad_norm": 0.5912350416183472,
      "learning_rate": 1.018592781625957e-05,
      "loss": 0.0071,
      "step": 13460
    },
    {
      "epoch": 4.9106817353262855,
      "grad_norm": 0.003991748206317425,
      "learning_rate": 1.017863652934743e-05,
      "loss": 0.0229,
      "step": 13470
    },
    {
      "epoch": 4.914327378782355,
      "grad_norm": 2.802388906478882,
      "learning_rate": 1.017134524243529e-05,
      "loss": 0.0232,
      "step": 13480
    },
    {
      "epoch": 4.917973022238425,
      "grad_norm": 0.325962096452713,
      "learning_rate": 1.016405395552315e-05,
      "loss": 0.0094,
      "step": 13490
    },
    {
      "epoch": 4.921618665694496,
      "grad_norm": 2.1321611404418945,
      "learning_rate": 1.015676266861101e-05,
      "loss": 0.017,
      "step": 13500
    },
    {
      "epoch": 4.925264309150565,
      "grad_norm": 6.332706451416016,
      "learning_rate": 1.014947138169887e-05,
      "loss": 0.0176,
      "step": 13510
    },
    {
      "epoch": 4.928909952606635,
      "grad_norm": 3.9275524616241455,
      "learning_rate": 1.0142180094786732e-05,
      "loss": 0.0089,
      "step": 13520
    },
    {
      "epoch": 4.932555596062705,
      "grad_norm": 0.1346503049135208,
      "learning_rate": 1.013488880787459e-05,
      "loss": 0.0143,
      "step": 13530
    },
    {
      "epoch": 4.936201239518775,
      "grad_norm": 0.0022700808476656675,
      "learning_rate": 1.0127597520962452e-05,
      "loss": 0.001,
      "step": 13540
    },
    {
      "epoch": 4.939846882974845,
      "grad_norm": 0.008952387608587742,
      "learning_rate": 1.012030623405031e-05,
      "loss": 0.0263,
      "step": 13550
    },
    {
      "epoch": 4.943492526430915,
      "grad_norm": 0.00255160522647202,
      "learning_rate": 1.0113014947138172e-05,
      "loss": 0.0029,
      "step": 13560
    },
    {
      "epoch": 4.947138169886985,
      "grad_norm": 4.831974506378174,
      "learning_rate": 1.010572366022603e-05,
      "loss": 0.0085,
      "step": 13570
    },
    {
      "epoch": 4.950783813343055,
      "grad_norm": 6.263254165649414,
      "learning_rate": 1.0098432373313892e-05,
      "loss": 0.0399,
      "step": 13580
    },
    {
      "epoch": 4.954429456799125,
      "grad_norm": 2.5439350605010986,
      "learning_rate": 1.009114108640175e-05,
      "loss": 0.0108,
      "step": 13590
    },
    {
      "epoch": 4.958075100255195,
      "grad_norm": 0.003188495757058263,
      "learning_rate": 1.0083849799489612e-05,
      "loss": 0.0126,
      "step": 13600
    },
    {
      "epoch": 4.961720743711265,
      "grad_norm": 0.06172753497958183,
      "learning_rate": 1.007655851257747e-05,
      "loss": 0.0253,
      "step": 13610
    },
    {
      "epoch": 4.965366387167335,
      "grad_norm": 18.29536247253418,
      "learning_rate": 1.0069267225665332e-05,
      "loss": 0.0188,
      "step": 13620
    },
    {
      "epoch": 4.969012030623405,
      "grad_norm": 3.5083465576171875,
      "learning_rate": 1.006197593875319e-05,
      "loss": 0.0295,
      "step": 13630
    },
    {
      "epoch": 4.972657674079475,
      "grad_norm": 3.130321741104126,
      "learning_rate": 1.0054684651841052e-05,
      "loss": 0.008,
      "step": 13640
    },
    {
      "epoch": 4.976303317535545,
      "grad_norm": 0.001794585376046598,
      "learning_rate": 1.004739336492891e-05,
      "loss": 0.0185,
      "step": 13650
    },
    {
      "epoch": 4.979948960991615,
      "grad_norm": 0.0023604384623467922,
      "learning_rate": 1.0040102078016772e-05,
      "loss": 0.011,
      "step": 13660
    },
    {
      "epoch": 4.983594604447685,
      "grad_norm": 0.0102694695815444,
      "learning_rate": 1.003281079110463e-05,
      "loss": 0.0114,
      "step": 13670
    },
    {
      "epoch": 4.987240247903755,
      "grad_norm": 0.005971831735223532,
      "learning_rate": 1.0025519504192492e-05,
      "loss": 0.0087,
      "step": 13680
    },
    {
      "epoch": 4.990885891359825,
      "grad_norm": 1.6518306732177734,
      "learning_rate": 1.001822821728035e-05,
      "loss": 0.0024,
      "step": 13690
    },
    {
      "epoch": 4.994531534815895,
      "grad_norm": 0.002785542979836464,
      "learning_rate": 1.0010936930368212e-05,
      "loss": 0.0078,
      "step": 13700
    },
    {
      "epoch": 4.998177178271965,
      "grad_norm": 0.9814998507499695,
      "learning_rate": 1.000364564345607e-05,
      "loss": 0.0072,
      "step": 13710
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9905770868824532,
      "eval_f1": 0.9619763694951666,
      "eval_loss": 0.03758411854505539,
      "eval_precision": 0.9684256055363322,
      "eval_recall": 0.9556124626547162,
      "eval_runtime": 808.1459,
      "eval_samples_per_second": 23.28,
      "eval_steps_per_second": 0.728,
      "step": 13715
    },
    {
      "epoch": 5.001822821728035,
      "grad_norm": 1.1446661949157715,
      "learning_rate": 9.99635435654393e-06,
      "loss": 0.0045,
      "step": 13720
    },
    {
      "epoch": 5.005468465184105,
      "grad_norm": 0.0013826623326167464,
      "learning_rate": 9.98906306963179e-06,
      "loss": 0.0006,
      "step": 13730
    },
    {
      "epoch": 5.009114108640175,
      "grad_norm": 0.0026724988128989935,
      "learning_rate": 9.98177178271965e-06,
      "loss": 0.0082,
      "step": 13740
    },
    {
      "epoch": 5.012759752096245,
      "grad_norm": 1.0065643787384033,
      "learning_rate": 9.97448049580751e-06,
      "loss": 0.0016,
      "step": 13750
    },
    {
      "epoch": 5.016405395552315,
      "grad_norm": 1.3841288089752197,
      "learning_rate": 9.96718920889537e-06,
      "loss": 0.0109,
      "step": 13760
    },
    {
      "epoch": 5.020051039008385,
      "grad_norm": 7.44824743270874,
      "learning_rate": 9.95989792198323e-06,
      "loss": 0.0288,
      "step": 13770
    },
    {
      "epoch": 5.023696682464455,
      "grad_norm": 0.1961309313774109,
      "learning_rate": 9.95260663507109e-06,
      "loss": 0.0002,
      "step": 13780
    },
    {
      "epoch": 5.027342325920525,
      "grad_norm": 0.0017944738501682878,
      "learning_rate": 9.94531534815895e-06,
      "loss": 0.0041,
      "step": 13790
    },
    {
      "epoch": 5.030987969376595,
      "grad_norm": 0.0011704966891556978,
      "learning_rate": 9.93802406124681e-06,
      "loss": 0.0038,
      "step": 13800
    },
    {
      "epoch": 5.034633612832665,
      "grad_norm": 0.0005774716264568269,
      "learning_rate": 9.93073277433467e-06,
      "loss": 0.0086,
      "step": 13810
    },
    {
      "epoch": 5.038279256288735,
      "grad_norm": 0.002910576993599534,
      "learning_rate": 9.92344148742253e-06,
      "loss": 0.0003,
      "step": 13820
    },
    {
      "epoch": 5.041924899744805,
      "grad_norm": 0.4167720377445221,
      "learning_rate": 9.91615020051039e-06,
      "loss": 0.0256,
      "step": 13830
    },
    {
      "epoch": 5.045570543200875,
      "grad_norm": 0.0011197056155651808,
      "learning_rate": 9.90885891359825e-06,
      "loss": 0.014,
      "step": 13840
    },
    {
      "epoch": 5.049216186656945,
      "grad_norm": 0.0018562402110546827,
      "learning_rate": 9.90156762668611e-06,
      "loss": 0.0382,
      "step": 13850
    },
    {
      "epoch": 5.052861830113015,
      "grad_norm": 1.7911837100982666,
      "learning_rate": 9.89427633977397e-06,
      "loss": 0.0121,
      "step": 13860
    },
    {
      "epoch": 5.056507473569085,
      "grad_norm": 0.11327559500932693,
      "learning_rate": 9.88698505286183e-06,
      "loss": 0.0303,
      "step": 13870
    },
    {
      "epoch": 5.060153117025155,
      "grad_norm": 0.002047777408733964,
      "learning_rate": 9.87969376594969e-06,
      "loss": 0.0136,
      "step": 13880
    },
    {
      "epoch": 5.063798760481225,
      "grad_norm": 0.001573940273374319,
      "learning_rate": 9.87240247903755e-06,
      "loss": 0.0059,
      "step": 13890
    },
    {
      "epoch": 5.067444403937295,
      "grad_norm": 0.005331881809979677,
      "learning_rate": 9.86511119212541e-06,
      "loss": 0.0006,
      "step": 13900
    },
    {
      "epoch": 5.071090047393365,
      "grad_norm": 0.5140591263771057,
      "learning_rate": 9.85781990521327e-06,
      "loss": 0.008,
      "step": 13910
    },
    {
      "epoch": 5.074735690849435,
      "grad_norm": 0.27548113465309143,
      "learning_rate": 9.85052861830113e-06,
      "loss": 0.0124,
      "step": 13920
    },
    {
      "epoch": 5.078381334305505,
      "grad_norm": 0.0031617525964975357,
      "learning_rate": 9.843237331388991e-06,
      "loss": 0.0053,
      "step": 13930
    },
    {
      "epoch": 5.082026977761575,
      "grad_norm": 0.008963537402451038,
      "learning_rate": 9.83594604447685e-06,
      "loss": 0.0183,
      "step": 13940
    },
    {
      "epoch": 5.085672621217645,
      "grad_norm": 0.12416432052850723,
      "learning_rate": 9.828654757564711e-06,
      "loss": 0.0075,
      "step": 13950
    },
    {
      "epoch": 5.0893182646737145,
      "grad_norm": 0.040261708199977875,
      "learning_rate": 9.82136347065257e-06,
      "loss": 0.0086,
      "step": 13960
    },
    {
      "epoch": 5.092963908129785,
      "grad_norm": 1.510672688484192,
      "learning_rate": 9.814072183740431e-06,
      "loss": 0.0192,
      "step": 13970
    },
    {
      "epoch": 5.096609551585855,
      "grad_norm": 0.0006897731800563633,
      "learning_rate": 9.80678089682829e-06,
      "loss": 0.0163,
      "step": 13980
    },
    {
      "epoch": 5.100255195041925,
      "grad_norm": 0.8936900496482849,
      "learning_rate": 9.799489609916152e-06,
      "loss": 0.0046,
      "step": 13990
    },
    {
      "epoch": 5.103900838497995,
      "grad_norm": 0.8436506390571594,
      "learning_rate": 9.79219832300401e-06,
      "loss": 0.0046,
      "step": 14000
    },
    {
      "epoch": 5.107546481954065,
      "grad_norm": 0.005140458699315786,
      "learning_rate": 9.784907036091872e-06,
      "loss": 0.0006,
      "step": 14010
    },
    {
      "epoch": 5.111192125410135,
      "grad_norm": 0.995783805847168,
      "learning_rate": 9.77761574917973e-06,
      "loss": 0.0167,
      "step": 14020
    },
    {
      "epoch": 5.114837768866205,
      "grad_norm": 1.170255184173584,
      "learning_rate": 9.770324462267592e-06,
      "loss": 0.001,
      "step": 14030
    },
    {
      "epoch": 5.118483412322275,
      "grad_norm": 0.004165344871580601,
      "learning_rate": 9.76303317535545e-06,
      "loss": 0.0063,
      "step": 14040
    },
    {
      "epoch": 5.122129055778345,
      "grad_norm": 0.008483382873237133,
      "learning_rate": 9.755741888443312e-06,
      "loss": 0.0344,
      "step": 14050
    },
    {
      "epoch": 5.125774699234415,
      "grad_norm": 0.03042709454894066,
      "learning_rate": 9.74845060153117e-06,
      "loss": 0.004,
      "step": 14060
    },
    {
      "epoch": 5.1294203426904845,
      "grad_norm": 0.008071620017290115,
      "learning_rate": 9.741159314619032e-06,
      "loss": 0.0084,
      "step": 14070
    },
    {
      "epoch": 5.133065986146555,
      "grad_norm": 0.0032305708155035973,
      "learning_rate": 9.73386802770689e-06,
      "loss": 0.0409,
      "step": 14080
    },
    {
      "epoch": 5.136711629602625,
      "grad_norm": 0.007193191908299923,
      "learning_rate": 9.726576740794752e-06,
      "loss": 0.0218,
      "step": 14090
    },
    {
      "epoch": 5.140357273058695,
      "grad_norm": 0.0016350226942449808,
      "learning_rate": 9.71928545388261e-06,
      "loss": 0.0327,
      "step": 14100
    },
    {
      "epoch": 5.144002916514765,
      "grad_norm": 0.004931329749524593,
      "learning_rate": 9.711994166970472e-06,
      "loss": 0.0042,
      "step": 14110
    },
    {
      "epoch": 5.147648559970835,
      "grad_norm": 0.08089211583137512,
      "learning_rate": 9.70470288005833e-06,
      "loss": 0.0036,
      "step": 14120
    },
    {
      "epoch": 5.151294203426905,
      "grad_norm": 0.006669003516435623,
      "learning_rate": 9.697411593146192e-06,
      "loss": 0.0015,
      "step": 14130
    },
    {
      "epoch": 5.154939846882975,
      "grad_norm": 0.000990477274172008,
      "learning_rate": 9.69012030623405e-06,
      "loss": 0.0096,
      "step": 14140
    },
    {
      "epoch": 5.1585854903390445,
      "grad_norm": 0.20452502369880676,
      "learning_rate": 9.682829019321912e-06,
      "loss": 0.0309,
      "step": 14150
    },
    {
      "epoch": 5.162231133795115,
      "grad_norm": 0.0010680624982342124,
      "learning_rate": 9.67553773240977e-06,
      "loss": 0.0081,
      "step": 14160
    },
    {
      "epoch": 5.165876777251185,
      "grad_norm": 0.0024291372392326593,
      "learning_rate": 9.668246445497632e-06,
      "loss": 0.0312,
      "step": 14170
    },
    {
      "epoch": 5.1695224207072545,
      "grad_norm": 0.19388210773468018,
      "learning_rate": 9.660955158585491e-06,
      "loss": 0.0329,
      "step": 14180
    },
    {
      "epoch": 5.173168064163325,
      "grad_norm": 0.060104433447122574,
      "learning_rate": 9.653663871673352e-06,
      "loss": 0.0086,
      "step": 14190
    },
    {
      "epoch": 5.176813707619395,
      "grad_norm": 0.0032330635003745556,
      "learning_rate": 9.646372584761211e-06,
      "loss": 0.0057,
      "step": 14200
    },
    {
      "epoch": 5.180459351075465,
      "grad_norm": 0.18299652636051178,
      "learning_rate": 9.639081297849072e-06,
      "loss": 0.0031,
      "step": 14210
    },
    {
      "epoch": 5.184104994531535,
      "grad_norm": 0.10272195190191269,
      "learning_rate": 9.631790010936931e-06,
      "loss": 0.0196,
      "step": 14220
    },
    {
      "epoch": 5.187750637987604,
      "grad_norm": 2.5395865440368652,
      "learning_rate": 9.624498724024792e-06,
      "loss": 0.0025,
      "step": 14230
    },
    {
      "epoch": 5.191396281443675,
      "grad_norm": 0.04542333260178566,
      "learning_rate": 9.617207437112651e-06,
      "loss": 0.0065,
      "step": 14240
    },
    {
      "epoch": 5.195041924899745,
      "grad_norm": 0.46743687987327576,
      "learning_rate": 9.609916150200512e-06,
      "loss": 0.0046,
      "step": 14250
    },
    {
      "epoch": 5.1986875683558145,
      "grad_norm": 0.005127506796270609,
      "learning_rate": 9.602624863288371e-06,
      "loss": 0.0052,
      "step": 14260
    },
    {
      "epoch": 5.202333211811885,
      "grad_norm": 0.0027420471888035536,
      "learning_rate": 9.595333576376232e-06,
      "loss": 0.0001,
      "step": 14270
    },
    {
      "epoch": 5.205978855267955,
      "grad_norm": 0.0027914803940802813,
      "learning_rate": 9.588042289464091e-06,
      "loss": 0.0162,
      "step": 14280
    },
    {
      "epoch": 5.2096244987240246,
      "grad_norm": 0.2744288146495819,
      "learning_rate": 9.580751002551952e-06,
      "loss": 0.0018,
      "step": 14290
    },
    {
      "epoch": 5.213270142180095,
      "grad_norm": 0.0024957021232694387,
      "learning_rate": 9.573459715639811e-06,
      "loss": 0.0375,
      "step": 14300
    },
    {
      "epoch": 5.216915785636165,
      "grad_norm": 0.07893114537000656,
      "learning_rate": 9.566168428727672e-06,
      "loss": 0.0082,
      "step": 14310
    },
    {
      "epoch": 5.220561429092235,
      "grad_norm": 20.643991470336914,
      "learning_rate": 9.558877141815531e-06,
      "loss": 0.0104,
      "step": 14320
    },
    {
      "epoch": 5.224207072548305,
      "grad_norm": 0.002968111541122198,
      "learning_rate": 9.551585854903392e-06,
      "loss": 0.0028,
      "step": 14330
    },
    {
      "epoch": 5.227852716004374,
      "grad_norm": 0.5183118581771851,
      "learning_rate": 9.544294567991251e-06,
      "loss": 0.0021,
      "step": 14340
    },
    {
      "epoch": 5.231498359460445,
      "grad_norm": 2.745279312133789,
      "learning_rate": 9.537003281079112e-06,
      "loss": 0.0032,
      "step": 14350
    },
    {
      "epoch": 5.235144002916515,
      "grad_norm": 0.001014716923236847,
      "learning_rate": 9.529711994166971e-06,
      "loss": 0.0001,
      "step": 14360
    },
    {
      "epoch": 5.2387896463725845,
      "grad_norm": 0.0008288282551802695,
      "learning_rate": 9.522420707254832e-06,
      "loss": 0.0062,
      "step": 14370
    },
    {
      "epoch": 5.242435289828655,
      "grad_norm": 0.041900329291820526,
      "learning_rate": 9.515129420342691e-06,
      "loss": 0.0045,
      "step": 14380
    },
    {
      "epoch": 5.246080933284725,
      "grad_norm": 0.002869404386729002,
      "learning_rate": 9.507838133430552e-06,
      "loss": 0.0281,
      "step": 14390
    },
    {
      "epoch": 5.249726576740795,
      "grad_norm": 0.000627366011030972,
      "learning_rate": 9.500546846518411e-06,
      "loss": 0.0,
      "step": 14400
    },
    {
      "epoch": 5.253372220196865,
      "grad_norm": 0.0007039551273919642,
      "learning_rate": 9.493255559606272e-06,
      "loss": 0.0229,
      "step": 14410
    },
    {
      "epoch": 5.257017863652934,
      "grad_norm": 0.6401991844177246,
      "learning_rate": 9.485964272694131e-06,
      "loss": 0.0391,
      "step": 14420
    },
    {
      "epoch": 5.260663507109005,
      "grad_norm": 1.0805329084396362,
      "learning_rate": 9.478672985781992e-06,
      "loss": 0.0157,
      "step": 14430
    },
    {
      "epoch": 5.264309150565075,
      "grad_norm": 0.86983722448349,
      "learning_rate": 9.471381698869851e-06,
      "loss": 0.0365,
      "step": 14440
    },
    {
      "epoch": 5.267954794021144,
      "grad_norm": 0.12494402378797531,
      "learning_rate": 9.464090411957712e-06,
      "loss": 0.0053,
      "step": 14450
    },
    {
      "epoch": 5.271600437477215,
      "grad_norm": 0.006226877216249704,
      "learning_rate": 9.456799125045571e-06,
      "loss": 0.0041,
      "step": 14460
    },
    {
      "epoch": 5.275246080933285,
      "grad_norm": 0.6261568069458008,
      "learning_rate": 9.449507838133432e-06,
      "loss": 0.0076,
      "step": 14470
    },
    {
      "epoch": 5.2788917243893545,
      "grad_norm": 0.0032320604659616947,
      "learning_rate": 9.442216551221291e-06,
      "loss": 0.0193,
      "step": 14480
    },
    {
      "epoch": 5.282537367845425,
      "grad_norm": 0.005719043780118227,
      "learning_rate": 9.434925264309152e-06,
      "loss": 0.0116,
      "step": 14490
    },
    {
      "epoch": 5.286183011301494,
      "grad_norm": 0.001058992580510676,
      "learning_rate": 9.427633977397011e-06,
      "loss": 0.0001,
      "step": 14500
    },
    {
      "epoch": 5.289828654757565,
      "grad_norm": 0.005083965603262186,
      "learning_rate": 9.420342690484872e-06,
      "loss": 0.0004,
      "step": 14510
    },
    {
      "epoch": 5.293474298213635,
      "grad_norm": 0.025697464123368263,
      "learning_rate": 9.413051403572731e-06,
      "loss": 0.0144,
      "step": 14520
    },
    {
      "epoch": 5.297119941669704,
      "grad_norm": 0.2967182397842407,
      "learning_rate": 9.405760116660592e-06,
      "loss": 0.019,
      "step": 14530
    },
    {
      "epoch": 5.300765585125775,
      "grad_norm": 3.052330493927002,
      "learning_rate": 9.398468829748451e-06,
      "loss": 0.0348,
      "step": 14540
    },
    {
      "epoch": 5.304411228581845,
      "grad_norm": 0.04015536978840828,
      "learning_rate": 9.391177542836312e-06,
      "loss": 0.0006,
      "step": 14550
    },
    {
      "epoch": 5.308056872037914,
      "grad_norm": 0.0013616400538012385,
      "learning_rate": 9.383886255924171e-06,
      "loss": 0.0075,
      "step": 14560
    },
    {
      "epoch": 5.311702515493985,
      "grad_norm": 0.00103013776242733,
      "learning_rate": 9.376594969012032e-06,
      "loss": 0.0146,
      "step": 14570
    },
    {
      "epoch": 5.315348158950055,
      "grad_norm": 0.3183879554271698,
      "learning_rate": 9.369303682099891e-06,
      "loss": 0.0503,
      "step": 14580
    },
    {
      "epoch": 5.3189938024061245,
      "grad_norm": 0.10978755354881287,
      "learning_rate": 9.362012395187752e-06,
      "loss": 0.0426,
      "step": 14590
    },
    {
      "epoch": 5.322639445862195,
      "grad_norm": 0.03730364516377449,
      "learning_rate": 9.354721108275611e-06,
      "loss": 0.018,
      "step": 14600
    },
    {
      "epoch": 5.326285089318264,
      "grad_norm": 0.2997879981994629,
      "learning_rate": 9.347429821363472e-06,
      "loss": 0.0013,
      "step": 14610
    },
    {
      "epoch": 5.329930732774335,
      "grad_norm": 0.13227179646492004,
      "learning_rate": 9.340138534451331e-06,
      "loss": 0.0146,
      "step": 14620
    },
    {
      "epoch": 5.333576376230405,
      "grad_norm": 0.006488636136054993,
      "learning_rate": 9.332847247539192e-06,
      "loss": 0.0081,
      "step": 14630
    },
    {
      "epoch": 5.337222019686474,
      "grad_norm": 0.008009160868823528,
      "learning_rate": 9.325555960627051e-06,
      "loss": 0.0015,
      "step": 14640
    },
    {
      "epoch": 5.340867663142545,
      "grad_norm": 0.8247984051704407,
      "learning_rate": 9.318264673714912e-06,
      "loss": 0.047,
      "step": 14650
    },
    {
      "epoch": 5.344513306598615,
      "grad_norm": 0.3221420645713806,
      "learning_rate": 9.310973386802771e-06,
      "loss": 0.0169,
      "step": 14660
    },
    {
      "epoch": 5.3481589500546844,
      "grad_norm": 0.023107364773750305,
      "learning_rate": 9.303682099890632e-06,
      "loss": 0.0006,
      "step": 14670
    },
    {
      "epoch": 5.351804593510755,
      "grad_norm": 0.6194562911987305,
      "learning_rate": 9.296390812978491e-06,
      "loss": 0.0052,
      "step": 14680
    },
    {
      "epoch": 5.355450236966824,
      "grad_norm": 0.15513360500335693,
      "learning_rate": 9.289099526066352e-06,
      "loss": 0.0216,
      "step": 14690
    },
    {
      "epoch": 5.3590958804228945,
      "grad_norm": 0.05326762795448303,
      "learning_rate": 9.281808239154211e-06,
      "loss": 0.0089,
      "step": 14700
    },
    {
      "epoch": 5.362741523878965,
      "grad_norm": 0.0991998091340065,
      "learning_rate": 9.274516952242072e-06,
      "loss": 0.0022,
      "step": 14710
    },
    {
      "epoch": 5.366387167335034,
      "grad_norm": 0.0034948710817843676,
      "learning_rate": 9.267225665329931e-06,
      "loss": 0.0198,
      "step": 14720
    },
    {
      "epoch": 5.370032810791105,
      "grad_norm": 0.21487294137477875,
      "learning_rate": 9.259934378417792e-06,
      "loss": 0.0081,
      "step": 14730
    },
    {
      "epoch": 5.373678454247175,
      "grad_norm": 0.004255432169884443,
      "learning_rate": 9.252643091505651e-06,
      "loss": 0.0202,
      "step": 14740
    },
    {
      "epoch": 5.377324097703244,
      "grad_norm": 1.371244192123413,
      "learning_rate": 9.245351804593512e-06,
      "loss": 0.0134,
      "step": 14750
    },
    {
      "epoch": 5.380969741159315,
      "grad_norm": 0.03865395486354828,
      "learning_rate": 9.238060517681371e-06,
      "loss": 0.0129,
      "step": 14760
    },
    {
      "epoch": 5.384615384615385,
      "grad_norm": 0.038806259632110596,
      "learning_rate": 9.230769230769232e-06,
      "loss": 0.01,
      "step": 14770
    },
    {
      "epoch": 5.3882610280714545,
      "grad_norm": 0.08230861276388168,
      "learning_rate": 9.223477943857091e-06,
      "loss": 0.0035,
      "step": 14780
    },
    {
      "epoch": 5.391906671527525,
      "grad_norm": 0.0722266137599945,
      "learning_rate": 9.216186656944952e-06,
      "loss": 0.0273,
      "step": 14790
    },
    {
      "epoch": 5.395552314983594,
      "grad_norm": 0.6776276230812073,
      "learning_rate": 9.208895370032811e-06,
      "loss": 0.0206,
      "step": 14800
    },
    {
      "epoch": 5.3991979584396645,
      "grad_norm": 1.6457571983337402,
      "learning_rate": 9.201604083120672e-06,
      "loss": 0.0149,
      "step": 14810
    },
    {
      "epoch": 5.402843601895735,
      "grad_norm": 1.6366443634033203,
      "learning_rate": 9.194312796208532e-06,
      "loss": 0.0029,
      "step": 14820
    },
    {
      "epoch": 5.406489245351804,
      "grad_norm": 0.0013397563016042113,
      "learning_rate": 9.18702150929639e-06,
      "loss": 0.0228,
      "step": 14830
    },
    {
      "epoch": 5.410134888807875,
      "grad_norm": 0.0032207961194217205,
      "learning_rate": 9.179730222384252e-06,
      "loss": 0.0206,
      "step": 14840
    },
    {
      "epoch": 5.413780532263945,
      "grad_norm": 0.02404169738292694,
      "learning_rate": 9.17243893547211e-06,
      "loss": 0.0105,
      "step": 14850
    },
    {
      "epoch": 5.417426175720014,
      "grad_norm": 0.017327651381492615,
      "learning_rate": 9.165147648559972e-06,
      "loss": 0.0027,
      "step": 14860
    },
    {
      "epoch": 5.421071819176085,
      "grad_norm": 1.4080067873001099,
      "learning_rate": 9.15785636164783e-06,
      "loss": 0.0079,
      "step": 14870
    },
    {
      "epoch": 5.424717462632154,
      "grad_norm": 0.03736106678843498,
      "learning_rate": 9.150565074735692e-06,
      "loss": 0.0073,
      "step": 14880
    },
    {
      "epoch": 5.4283631060882245,
      "grad_norm": 0.0574725903570652,
      "learning_rate": 9.14327378782355e-06,
      "loss": 0.0012,
      "step": 14890
    },
    {
      "epoch": 5.432008749544295,
      "grad_norm": 0.0008803731179796159,
      "learning_rate": 9.135982500911412e-06,
      "loss": 0.0061,
      "step": 14900
    },
    {
      "epoch": 5.435654393000364,
      "grad_norm": 0.5321453213691711,
      "learning_rate": 9.12869121399927e-06,
      "loss": 0.0049,
      "step": 14910
    },
    {
      "epoch": 5.439300036456435,
      "grad_norm": 0.0011532178614288568,
      "learning_rate": 9.121399927087132e-06,
      "loss": 0.0023,
      "step": 14920
    },
    {
      "epoch": 5.442945679912505,
      "grad_norm": 0.004767166916280985,
      "learning_rate": 9.11410864017499e-06,
      "loss": 0.0022,
      "step": 14930
    },
    {
      "epoch": 5.446591323368574,
      "grad_norm": 0.7467758655548096,
      "learning_rate": 9.106817353262852e-06,
      "loss": 0.0058,
      "step": 14940
    },
    {
      "epoch": 5.450236966824645,
      "grad_norm": 2.9869885444641113,
      "learning_rate": 9.09952606635071e-06,
      "loss": 0.005,
      "step": 14950
    },
    {
      "epoch": 5.453882610280715,
      "grad_norm": 0.3434717655181885,
      "learning_rate": 9.092234779438572e-06,
      "loss": 0.0256,
      "step": 14960
    },
    {
      "epoch": 5.457528253736784,
      "grad_norm": 0.9563578963279724,
      "learning_rate": 9.08494349252643e-06,
      "loss": 0.0035,
      "step": 14970
    },
    {
      "epoch": 5.461173897192855,
      "grad_norm": 0.00027151641552336514,
      "learning_rate": 9.077652205614292e-06,
      "loss": 0.0276,
      "step": 14980
    },
    {
      "epoch": 5.464819540648924,
      "grad_norm": 0.01358462031930685,
      "learning_rate": 9.07036091870215e-06,
      "loss": 0.0335,
      "step": 14990
    },
    {
      "epoch": 5.4684651841049945,
      "grad_norm": 0.00239884527400136,
      "learning_rate": 9.063069631790012e-06,
      "loss": 0.003,
      "step": 15000
    },
    {
      "epoch": 5.472110827561065,
      "grad_norm": 2.263197660446167,
      "learning_rate": 9.055778344877871e-06,
      "loss": 0.0199,
      "step": 15010
    },
    {
      "epoch": 5.475756471017134,
      "grad_norm": 0.00025304945302195847,
      "learning_rate": 9.048487057965732e-06,
      "loss": 0.0329,
      "step": 15020
    },
    {
      "epoch": 5.479402114473205,
      "grad_norm": 0.481568306684494,
      "learning_rate": 9.041195771053591e-06,
      "loss": 0.0079,
      "step": 15030
    },
    {
      "epoch": 5.483047757929275,
      "grad_norm": 0.0018964342307299376,
      "learning_rate": 9.033904484141452e-06,
      "loss": 0.0173,
      "step": 15040
    },
    {
      "epoch": 5.486693401385344,
      "grad_norm": 0.540800929069519,
      "learning_rate": 9.026613197229311e-06,
      "loss": 0.0157,
      "step": 15050
    },
    {
      "epoch": 5.490339044841415,
      "grad_norm": 0.0006054863915778697,
      "learning_rate": 9.019321910317172e-06,
      "loss": 0.0134,
      "step": 15060
    },
    {
      "epoch": 5.493984688297484,
      "grad_norm": 1.2091649770736694,
      "learning_rate": 9.012030623405031e-06,
      "loss": 0.0055,
      "step": 15070
    },
    {
      "epoch": 5.497630331753554,
      "grad_norm": 0.0013185550924390554,
      "learning_rate": 9.004739336492892e-06,
      "loss": 0.0276,
      "step": 15080
    },
    {
      "epoch": 5.501275975209625,
      "grad_norm": 0.0009048798820003867,
      "learning_rate": 8.997448049580751e-06,
      "loss": 0.0111,
      "step": 15090
    },
    {
      "epoch": 5.504921618665694,
      "grad_norm": 0.001451878109946847,
      "learning_rate": 8.990156762668612e-06,
      "loss": 0.045,
      "step": 15100
    },
    {
      "epoch": 5.5085672621217645,
      "grad_norm": 0.006387548055499792,
      "learning_rate": 8.982865475756471e-06,
      "loss": 0.0211,
      "step": 15110
    },
    {
      "epoch": 5.512212905577835,
      "grad_norm": 0.08688517659902573,
      "learning_rate": 8.975574188844332e-06,
      "loss": 0.0005,
      "step": 15120
    },
    {
      "epoch": 5.515858549033904,
      "grad_norm": 0.025024941191077232,
      "learning_rate": 8.968282901932191e-06,
      "loss": 0.0032,
      "step": 15130
    },
    {
      "epoch": 5.519504192489975,
      "grad_norm": 0.02990555763244629,
      "learning_rate": 8.960991615020052e-06,
      "loss": 0.0248,
      "step": 15140
    },
    {
      "epoch": 5.523149835946045,
      "grad_norm": 0.8727859258651733,
      "learning_rate": 8.953700328107911e-06,
      "loss": 0.0174,
      "step": 15150
    },
    {
      "epoch": 5.526795479402114,
      "grad_norm": 0.017929989844560623,
      "learning_rate": 8.946409041195772e-06,
      "loss": 0.0264,
      "step": 15160
    },
    {
      "epoch": 5.530441122858185,
      "grad_norm": 0.0012924016918987036,
      "learning_rate": 8.939117754283631e-06,
      "loss": 0.0115,
      "step": 15170
    },
    {
      "epoch": 5.534086766314254,
      "grad_norm": 0.012399202212691307,
      "learning_rate": 8.931826467371492e-06,
      "loss": 0.0276,
      "step": 15180
    },
    {
      "epoch": 5.537732409770324,
      "grad_norm": 0.007748112548142672,
      "learning_rate": 8.924535180459351e-06,
      "loss": 0.0282,
      "step": 15190
    },
    {
      "epoch": 5.541378053226395,
      "grad_norm": 1.6529749631881714,
      "learning_rate": 8.917243893547212e-06,
      "loss": 0.0068,
      "step": 15200
    },
    {
      "epoch": 5.545023696682464,
      "grad_norm": 0.038151927292346954,
      "learning_rate": 8.909952606635071e-06,
      "loss": 0.0143,
      "step": 15210
    },
    {
      "epoch": 5.5486693401385345,
      "grad_norm": 0.005899995565414429,
      "learning_rate": 8.902661319722932e-06,
      "loss": 0.0083,
      "step": 15220
    },
    {
      "epoch": 5.552314983594604,
      "grad_norm": 0.00020115690131206065,
      "learning_rate": 8.895370032810791e-06,
      "loss": 0.0075,
      "step": 15230
    },
    {
      "epoch": 5.555960627050674,
      "grad_norm": 0.0006448286585509777,
      "learning_rate": 8.888078745898652e-06,
      "loss": 0.0233,
      "step": 15240
    },
    {
      "epoch": 5.559606270506745,
      "grad_norm": 0.021319551393389702,
      "learning_rate": 8.880787458986511e-06,
      "loss": 0.0286,
      "step": 15250
    },
    {
      "epoch": 5.563251913962814,
      "grad_norm": 0.0014355629682540894,
      "learning_rate": 8.873496172074372e-06,
      "loss": 0.0001,
      "step": 15260
    },
    {
      "epoch": 5.566897557418884,
      "grad_norm": 0.011957526206970215,
      "learning_rate": 8.866204885162231e-06,
      "loss": 0.0068,
      "step": 15270
    },
    {
      "epoch": 5.570543200874955,
      "grad_norm": 0.11132630705833435,
      "learning_rate": 8.858913598250092e-06,
      "loss": 0.0054,
      "step": 15280
    },
    {
      "epoch": 5.574188844331024,
      "grad_norm": 1.7910979986190796,
      "learning_rate": 8.851622311337951e-06,
      "loss": 0.0075,
      "step": 15290
    },
    {
      "epoch": 5.5778344877870945,
      "grad_norm": 0.0003072590916417539,
      "learning_rate": 8.844331024425812e-06,
      "loss": 0.0052,
      "step": 15300
    },
    {
      "epoch": 5.581480131243165,
      "grad_norm": 0.00041922807577066123,
      "learning_rate": 8.837039737513671e-06,
      "loss": 0.024,
      "step": 15310
    },
    {
      "epoch": 5.585125774699234,
      "grad_norm": 0.0007143113762140274,
      "learning_rate": 8.829748450601532e-06,
      "loss": 0.0092,
      "step": 15320
    },
    {
      "epoch": 5.5887714181553045,
      "grad_norm": 0.021679731085896492,
      "learning_rate": 8.822457163689391e-06,
      "loss": 0.0001,
      "step": 15330
    },
    {
      "epoch": 5.592417061611375,
      "grad_norm": 0.018150988966226578,
      "learning_rate": 8.815165876777252e-06,
      "loss": 0.0405,
      "step": 15340
    },
    {
      "epoch": 5.596062705067444,
      "grad_norm": 0.11619696766138077,
      "learning_rate": 8.807874589865111e-06,
      "loss": 0.0107,
      "step": 15350
    },
    {
      "epoch": 5.599708348523515,
      "grad_norm": 0.0022986913099884987,
      "learning_rate": 8.800583302952972e-06,
      "loss": 0.0209,
      "step": 15360
    },
    {
      "epoch": 5.603353991979584,
      "grad_norm": 0.0024306525010615587,
      "learning_rate": 8.793292016040831e-06,
      "loss": 0.0186,
      "step": 15370
    },
    {
      "epoch": 5.606999635435654,
      "grad_norm": 0.038626134395599365,
      "learning_rate": 8.786000729128692e-06,
      "loss": 0.0123,
      "step": 15380
    },
    {
      "epoch": 5.610645278891725,
      "grad_norm": 0.09678022563457489,
      "learning_rate": 8.778709442216551e-06,
      "loss": 0.0047,
      "step": 15390
    },
    {
      "epoch": 5.614290922347794,
      "grad_norm": 0.00733112171292305,
      "learning_rate": 8.771418155304412e-06,
      "loss": 0.0003,
      "step": 15400
    },
    {
      "epoch": 5.6179365658038645,
      "grad_norm": 0.011837253347039223,
      "learning_rate": 8.764126868392271e-06,
      "loss": 0.0052,
      "step": 15410
    },
    {
      "epoch": 5.621582209259934,
      "grad_norm": 0.09761963784694672,
      "learning_rate": 8.756835581480132e-06,
      "loss": 0.0021,
      "step": 15420
    },
    {
      "epoch": 5.625227852716004,
      "grad_norm": 0.0013745103497058153,
      "learning_rate": 8.749544294567991e-06,
      "loss": 0.0011,
      "step": 15430
    },
    {
      "epoch": 5.6288734961720746,
      "grad_norm": 0.06069999188184738,
      "learning_rate": 8.742253007655852e-06,
      "loss": 0.0388,
      "step": 15440
    },
    {
      "epoch": 5.632519139628144,
      "grad_norm": 0.02170393615961075,
      "learning_rate": 8.734961720743711e-06,
      "loss": 0.0008,
      "step": 15450
    },
    {
      "epoch": 5.636164783084214,
      "grad_norm": 0.28711172938346863,
      "learning_rate": 8.727670433831572e-06,
      "loss": 0.0022,
      "step": 15460
    },
    {
      "epoch": 5.639810426540285,
      "grad_norm": 0.24483941495418549,
      "learning_rate": 8.720379146919431e-06,
      "loss": 0.0068,
      "step": 15470
    },
    {
      "epoch": 5.643456069996354,
      "grad_norm": 0.0347253642976284,
      "learning_rate": 8.713087860007292e-06,
      "loss": 0.0024,
      "step": 15480
    },
    {
      "epoch": 5.647101713452424,
      "grad_norm": 0.0007480587810277939,
      "learning_rate": 8.705796573095151e-06,
      "loss": 0.0243,
      "step": 15490
    },
    {
      "epoch": 5.650747356908495,
      "grad_norm": 0.003167319344356656,
      "learning_rate": 8.698505286183012e-06,
      "loss": 0.0155,
      "step": 15500
    },
    {
      "epoch": 5.654393000364564,
      "grad_norm": 0.03645046800374985,
      "learning_rate": 8.691213999270871e-06,
      "loss": 0.0001,
      "step": 15510
    },
    {
      "epoch": 5.6580386438206345,
      "grad_norm": 11.367352485656738,
      "learning_rate": 8.683922712358732e-06,
      "loss": 0.0148,
      "step": 15520
    },
    {
      "epoch": 5.661684287276705,
      "grad_norm": 0.0012114798882976174,
      "learning_rate": 8.676631425446591e-06,
      "loss": 0.0074,
      "step": 15530
    },
    {
      "epoch": 5.665329930732774,
      "grad_norm": 0.08862951397895813,
      "learning_rate": 8.669340138534452e-06,
      "loss": 0.0002,
      "step": 15540
    },
    {
      "epoch": 5.668975574188845,
      "grad_norm": 0.006296428386121988,
      "learning_rate": 8.662048851622311e-06,
      "loss": 0.0185,
      "step": 15550
    },
    {
      "epoch": 5.672621217644914,
      "grad_norm": 0.0012856132816523314,
      "learning_rate": 8.654757564710172e-06,
      "loss": 0.0011,
      "step": 15560
    },
    {
      "epoch": 5.676266861100984,
      "grad_norm": 0.014247816987335682,
      "learning_rate": 8.647466277798033e-06,
      "loss": 0.0001,
      "step": 15570
    },
    {
      "epoch": 5.679912504557055,
      "grad_norm": 0.003455938072875142,
      "learning_rate": 8.640174990885892e-06,
      "loss": 0.0046,
      "step": 15580
    },
    {
      "epoch": 5.683558148013124,
      "grad_norm": 0.0009990796679630876,
      "learning_rate": 8.632883703973753e-06,
      "loss": 0.0073,
      "step": 15590
    },
    {
      "epoch": 5.687203791469194,
      "grad_norm": 0.012638797983527184,
      "learning_rate": 8.625592417061612e-06,
      "loss": 0.0133,
      "step": 15600
    },
    {
      "epoch": 5.690849434925264,
      "grad_norm": 2.0923757553100586,
      "learning_rate": 8.618301130149473e-06,
      "loss": 0.0056,
      "step": 15610
    },
    {
      "epoch": 5.694495078381334,
      "grad_norm": 0.042706139385700226,
      "learning_rate": 8.611009843237332e-06,
      "loss": 0.009,
      "step": 15620
    },
    {
      "epoch": 5.6981407218374045,
      "grad_norm": 4.345988750457764,
      "learning_rate": 8.603718556325193e-06,
      "loss": 0.0357,
      "step": 15630
    },
    {
      "epoch": 5.701786365293474,
      "grad_norm": 0.4854809641838074,
      "learning_rate": 8.596427269413052e-06,
      "loss": 0.002,
      "step": 15640
    },
    {
      "epoch": 5.705432008749544,
      "grad_norm": 2.6158828735351562,
      "learning_rate": 8.589135982500913e-06,
      "loss": 0.0055,
      "step": 15650
    },
    {
      "epoch": 5.709077652205615,
      "grad_norm": 0.003145781811326742,
      "learning_rate": 8.581844695588772e-06,
      "loss": 0.0098,
      "step": 15660
    },
    {
      "epoch": 5.712723295661684,
      "grad_norm": 0.005805866792798042,
      "learning_rate": 8.574553408676633e-06,
      "loss": 0.0004,
      "step": 15670
    },
    {
      "epoch": 5.716368939117754,
      "grad_norm": 0.14256270229816437,
      "learning_rate": 8.567262121764492e-06,
      "loss": 0.002,
      "step": 15680
    },
    {
      "epoch": 5.720014582573825,
      "grad_norm": 0.0037478627637028694,
      "learning_rate": 8.559970834852353e-06,
      "loss": 0.0027,
      "step": 15690
    },
    {
      "epoch": 5.723660226029894,
      "grad_norm": 0.8091239333152771,
      "learning_rate": 8.552679547940212e-06,
      "loss": 0.0082,
      "step": 15700
    },
    {
      "epoch": 5.727305869485964,
      "grad_norm": 0.002747822552919388,
      "learning_rate": 8.545388261028073e-06,
      "loss": 0.0228,
      "step": 15710
    },
    {
      "epoch": 5.730951512942035,
      "grad_norm": 0.0012714763870462775,
      "learning_rate": 8.538096974115932e-06,
      "loss": 0.0077,
      "step": 15720
    },
    {
      "epoch": 5.734597156398104,
      "grad_norm": 0.0021257740445435047,
      "learning_rate": 8.530805687203793e-06,
      "loss": 0.0007,
      "step": 15730
    },
    {
      "epoch": 5.7382427998541745,
      "grad_norm": 0.0006093759438954294,
      "learning_rate": 8.523514400291652e-06,
      "loss": 0.0213,
      "step": 15740
    },
    {
      "epoch": 5.741888443310244,
      "grad_norm": 0.001578619470819831,
      "learning_rate": 8.516223113379513e-06,
      "loss": 0.0123,
      "step": 15750
    },
    {
      "epoch": 5.745534086766314,
      "grad_norm": 0.004718413110822439,
      "learning_rate": 8.508931826467372e-06,
      "loss": 0.0073,
      "step": 15760
    },
    {
      "epoch": 5.749179730222385,
      "grad_norm": 0.017509249970316887,
      "learning_rate": 8.501640539555233e-06,
      "loss": 0.0108,
      "step": 15770
    },
    {
      "epoch": 5.752825373678454,
      "grad_norm": 0.03346138447523117,
      "learning_rate": 8.494349252643092e-06,
      "loss": 0.0031,
      "step": 15780
    },
    {
      "epoch": 5.756471017134524,
      "grad_norm": 0.0039605796337127686,
      "learning_rate": 8.487057965730953e-06,
      "loss": 0.0093,
      "step": 15790
    },
    {
      "epoch": 5.760116660590594,
      "grad_norm": 0.0037278379313647747,
      "learning_rate": 8.479766678818812e-06,
      "loss": 0.0034,
      "step": 15800
    },
    {
      "epoch": 5.763762304046664,
      "grad_norm": 0.026424475014209747,
      "learning_rate": 8.472475391906673e-06,
      "loss": 0.0,
      "step": 15810
    },
    {
      "epoch": 5.7674079475027344,
      "grad_norm": 1.8986258506774902,
      "learning_rate": 8.465184104994533e-06,
      "loss": 0.0144,
      "step": 15820
    },
    {
      "epoch": 5.771053590958804,
      "grad_norm": 0.0020254100672900677,
      "learning_rate": 8.457892818082393e-06,
      "loss": 0.0168,
      "step": 15830
    },
    {
      "epoch": 5.774699234414874,
      "grad_norm": 0.001551946857944131,
      "learning_rate": 8.450601531170253e-06,
      "loss": 0.003,
      "step": 15840
    },
    {
      "epoch": 5.7783448778709445,
      "grad_norm": 0.0020849057473242283,
      "learning_rate": 8.443310244258113e-06,
      "loss": 0.0034,
      "step": 15850
    },
    {
      "epoch": 5.781990521327014,
      "grad_norm": 0.0016055206069722772,
      "learning_rate": 8.436018957345973e-06,
      "loss": 0.0156,
      "step": 15860
    },
    {
      "epoch": 5.785636164783084,
      "grad_norm": 0.002530378522351384,
      "learning_rate": 8.428727670433833e-06,
      "loss": 0.0033,
      "step": 15870
    },
    {
      "epoch": 5.789281808239155,
      "grad_norm": 0.14998911321163177,
      "learning_rate": 8.421436383521693e-06,
      "loss": 0.0198,
      "step": 15880
    },
    {
      "epoch": 5.792927451695224,
      "grad_norm": 0.007266154512763023,
      "learning_rate": 8.414145096609553e-06,
      "loss": 0.003,
      "step": 15890
    },
    {
      "epoch": 5.796573095151294,
      "grad_norm": 0.006666973233222961,
      "learning_rate": 8.406853809697413e-06,
      "loss": 0.0004,
      "step": 15900
    },
    {
      "epoch": 5.800218738607365,
      "grad_norm": 0.4727981686592102,
      "learning_rate": 8.399562522785272e-06,
      "loss": 0.0108,
      "step": 15910
    },
    {
      "epoch": 5.803864382063434,
      "grad_norm": 0.1289411187171936,
      "learning_rate": 8.392271235873131e-06,
      "loss": 0.0074,
      "step": 15920
    },
    {
      "epoch": 5.8075100255195045,
      "grad_norm": 0.026340197771787643,
      "learning_rate": 8.384979948960992e-06,
      "loss": 0.0019,
      "step": 15930
    },
    {
      "epoch": 5.811155668975574,
      "grad_norm": 2.1874659061431885,
      "learning_rate": 8.377688662048851e-06,
      "loss": 0.0135,
      "step": 15940
    },
    {
      "epoch": 5.814801312431644,
      "grad_norm": 0.0006305725546553731,
      "learning_rate": 8.370397375136712e-06,
      "loss": 0.0224,
      "step": 15950
    },
    {
      "epoch": 5.8184469558877145,
      "grad_norm": 0.0010051806457340717,
      "learning_rate": 8.363106088224573e-06,
      "loss": 0.0056,
      "step": 15960
    },
    {
      "epoch": 5.822092599343784,
      "grad_norm": 2.1189286708831787,
      "learning_rate": 8.355814801312432e-06,
      "loss": 0.0165,
      "step": 15970
    },
    {
      "epoch": 5.825738242799854,
      "grad_norm": 0.01301086600869894,
      "learning_rate": 8.348523514400293e-06,
      "loss": 0.0049,
      "step": 15980
    },
    {
      "epoch": 5.829383886255924,
      "grad_norm": 0.7751724123954773,
      "learning_rate": 8.341232227488152e-06,
      "loss": 0.0074,
      "step": 15990
    },
    {
      "epoch": 5.833029529711994,
      "grad_norm": 0.001271108747459948,
      "learning_rate": 8.333940940576013e-06,
      "loss": 0.0003,
      "step": 16000
    },
    {
      "epoch": 5.836675173168064,
      "grad_norm": 0.0014694628771394491,
      "learning_rate": 8.326649653663872e-06,
      "loss": 0.0203,
      "step": 16010
    },
    {
      "epoch": 5.840320816624134,
      "grad_norm": 1.9820891618728638,
      "learning_rate": 8.319358366751733e-06,
      "loss": 0.0113,
      "step": 16020
    },
    {
      "epoch": 5.843966460080204,
      "grad_norm": 0.044477447867393494,
      "learning_rate": 8.312067079839592e-06,
      "loss": 0.0234,
      "step": 16030
    },
    {
      "epoch": 5.8476121035362745,
      "grad_norm": 0.00508997542783618,
      "learning_rate": 8.304775792927453e-06,
      "loss": 0.0037,
      "step": 16040
    },
    {
      "epoch": 5.851257746992344,
      "grad_norm": 0.023659899830818176,
      "learning_rate": 8.297484506015312e-06,
      "loss": 0.0047,
      "step": 16050
    },
    {
      "epoch": 5.854903390448414,
      "grad_norm": 2.0422427654266357,
      "learning_rate": 8.290193219103173e-06,
      "loss": 0.0247,
      "step": 16060
    },
    {
      "epoch": 5.858549033904485,
      "grad_norm": 1.1500775814056396,
      "learning_rate": 8.282901932191032e-06,
      "loss": 0.0022,
      "step": 16070
    },
    {
      "epoch": 5.862194677360554,
      "grad_norm": 0.002171532716602087,
      "learning_rate": 8.275610645278893e-06,
      "loss": 0.0033,
      "step": 16080
    },
    {
      "epoch": 5.865840320816624,
      "grad_norm": 0.005289288703352213,
      "learning_rate": 8.268319358366752e-06,
      "loss": 0.0133,
      "step": 16090
    },
    {
      "epoch": 5.869485964272694,
      "grad_norm": 3.1439437866210938,
      "learning_rate": 8.261028071454613e-06,
      "loss": 0.009,
      "step": 16100
    },
    {
      "epoch": 5.873131607728764,
      "grad_norm": 0.03419540077447891,
      "learning_rate": 8.253736784542472e-06,
      "loss": 0.0089,
      "step": 16110
    },
    {
      "epoch": 5.876777251184834,
      "grad_norm": 0.0892544612288475,
      "learning_rate": 8.246445497630333e-06,
      "loss": 0.0218,
      "step": 16120
    },
    {
      "epoch": 5.880422894640904,
      "grad_norm": 0.004378499463200569,
      "learning_rate": 8.239154210718192e-06,
      "loss": 0.0083,
      "step": 16130
    },
    {
      "epoch": 5.884068538096974,
      "grad_norm": 0.005722984205931425,
      "learning_rate": 8.231862923806053e-06,
      "loss": 0.0252,
      "step": 16140
    },
    {
      "epoch": 5.8877141815530445,
      "grad_norm": 0.009807069785892963,
      "learning_rate": 8.224571636893912e-06,
      "loss": 0.0218,
      "step": 16150
    },
    {
      "epoch": 5.891359825009114,
      "grad_norm": 0.7668043971061707,
      "learning_rate": 8.217280349981773e-06,
      "loss": 0.0291,
      "step": 16160
    },
    {
      "epoch": 5.895005468465184,
      "grad_norm": 0.0076822019182145596,
      "learning_rate": 8.209989063069632e-06,
      "loss": 0.0096,
      "step": 16170
    },
    {
      "epoch": 5.898651111921254,
      "grad_norm": 1.7400046586990356,
      "learning_rate": 8.202697776157493e-06,
      "loss": 0.0102,
      "step": 16180
    },
    {
      "epoch": 5.902296755377324,
      "grad_norm": 0.00929163582623005,
      "learning_rate": 8.195406489245352e-06,
      "loss": 0.0107,
      "step": 16190
    },
    {
      "epoch": 5.905942398833394,
      "grad_norm": 0.1755078136920929,
      "learning_rate": 8.188115202333213e-06,
      "loss": 0.0106,
      "step": 16200
    },
    {
      "epoch": 5.909588042289464,
      "grad_norm": 1.792209267616272,
      "learning_rate": 8.180823915421072e-06,
      "loss": 0.0067,
      "step": 16210
    },
    {
      "epoch": 5.913233685745534,
      "grad_norm": 1.444535732269287,
      "learning_rate": 8.173532628508933e-06,
      "loss": 0.0203,
      "step": 16220
    },
    {
      "epoch": 5.916879329201604,
      "grad_norm": 0.008757136762142181,
      "learning_rate": 8.166241341596792e-06,
      "loss": 0.0043,
      "step": 16230
    },
    {
      "epoch": 5.920524972657674,
      "grad_norm": 0.0019106437684968114,
      "learning_rate": 8.158950054684653e-06,
      "loss": 0.0177,
      "step": 16240
    },
    {
      "epoch": 5.924170616113744,
      "grad_norm": 0.013283667154610157,
      "learning_rate": 8.151658767772512e-06,
      "loss": 0.0112,
      "step": 16250
    },
    {
      "epoch": 5.9278162595698145,
      "grad_norm": 0.5056592226028442,
      "learning_rate": 8.144367480860373e-06,
      "loss": 0.0021,
      "step": 16260
    },
    {
      "epoch": 5.931461903025884,
      "grad_norm": 0.002511007012799382,
      "learning_rate": 8.137076193948232e-06,
      "loss": 0.0006,
      "step": 16270
    },
    {
      "epoch": 5.935107546481954,
      "grad_norm": 1.5635969638824463,
      "learning_rate": 8.129784907036093e-06,
      "loss": 0.0022,
      "step": 16280
    },
    {
      "epoch": 5.938753189938024,
      "grad_norm": 0.0045439754612743855,
      "learning_rate": 8.122493620123952e-06,
      "loss": 0.0065,
      "step": 16290
    },
    {
      "epoch": 5.942398833394094,
      "grad_norm": 0.0017988593317568302,
      "learning_rate": 8.115202333211813e-06,
      "loss": 0.0063,
      "step": 16300
    },
    {
      "epoch": 5.946044476850164,
      "grad_norm": 0.001931015751324594,
      "learning_rate": 8.107911046299672e-06,
      "loss": 0.0238,
      "step": 16310
    },
    {
      "epoch": 5.949690120306234,
      "grad_norm": 0.0026409346610307693,
      "learning_rate": 8.100619759387533e-06,
      "loss": 0.0251,
      "step": 16320
    },
    {
      "epoch": 5.953335763762304,
      "grad_norm": 0.9469303488731384,
      "learning_rate": 8.093328472475392e-06,
      "loss": 0.0087,
      "step": 16330
    },
    {
      "epoch": 5.9569814072183735,
      "grad_norm": 1.5274507999420166,
      "learning_rate": 8.086037185563253e-06,
      "loss": 0.0134,
      "step": 16340
    },
    {
      "epoch": 5.960627050674444,
      "grad_norm": 0.00876521598547697,
      "learning_rate": 8.078745898651112e-06,
      "loss": 0.0012,
      "step": 16350
    },
    {
      "epoch": 5.964272694130514,
      "grad_norm": 0.007474055979400873,
      "learning_rate": 8.071454611738973e-06,
      "loss": 0.0053,
      "step": 16360
    },
    {
      "epoch": 5.967918337586584,
      "grad_norm": 0.22847722470760345,
      "learning_rate": 8.064163324826832e-06,
      "loss": 0.0001,
      "step": 16370
    },
    {
      "epoch": 5.971563981042654,
      "grad_norm": 0.00197134749032557,
      "learning_rate": 8.056872037914693e-06,
      "loss": 0.0017,
      "step": 16380
    },
    {
      "epoch": 5.975209624498724,
      "grad_norm": 0.0009396104724146426,
      "learning_rate": 8.049580751002552e-06,
      "loss": 0.0203,
      "step": 16390
    },
    {
      "epoch": 5.978855267954794,
      "grad_norm": 0.051665909588336945,
      "learning_rate": 8.042289464090413e-06,
      "loss": 0.0159,
      "step": 16400
    },
    {
      "epoch": 5.982500911410864,
      "grad_norm": 3.235440254211426,
      "learning_rate": 8.034998177178272e-06,
      "loss": 0.006,
      "step": 16410
    },
    {
      "epoch": 5.986146554866934,
      "grad_norm": 0.0008289201068691909,
      "learning_rate": 8.027706890266133e-06,
      "loss": 0.0366,
      "step": 16420
    },
    {
      "epoch": 5.989792198323004,
      "grad_norm": 0.0015826532617211342,
      "learning_rate": 8.020415603353992e-06,
      "loss": 0.0035,
      "step": 16430
    },
    {
      "epoch": 5.993437841779074,
      "grad_norm": 0.005418963730335236,
      "learning_rate": 8.013124316441853e-06,
      "loss": 0.0061,
      "step": 16440
    },
    {
      "epoch": 5.9970834852351445,
      "grad_norm": 0.021233556792140007,
      "learning_rate": 8.005833029529712e-06,
      "loss": 0.0009,
      "step": 16450
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9918015332197615,
      "eval_f1": 0.9672897196261682,
      "eval_loss": 0.033672429621219635,
      "eval_precision": 0.9627906976744186,
      "eval_recall": 0.971830985915493,
      "eval_runtime": 866.8209,
      "eval_samples_per_second": 21.705,
      "eval_steps_per_second": 0.678,
      "step": 16458
    },
    {
      "epoch": 6.000729128691214,
      "grad_norm": 0.007462664972990751,
      "learning_rate": 7.998541742617573e-06,
      "loss": 0.0076,
      "step": 16460
    },
    {
      "epoch": 6.004374772147284,
      "grad_norm": 0.008314631879329681,
      "learning_rate": 7.991250455705432e-06,
      "loss": 0.0246,
      "step": 16470
    },
    {
      "epoch": 6.008020415603354,
      "grad_norm": 0.0032519216183573008,
      "learning_rate": 7.983959168793293e-06,
      "loss": 0.0006,
      "step": 16480
    },
    {
      "epoch": 6.011666059059424,
      "grad_norm": 0.0008001324604265392,
      "learning_rate": 7.976667881881152e-06,
      "loss": 0.0058,
      "step": 16490
    },
    {
      "epoch": 6.015311702515494,
      "grad_norm": 0.001314980792813003,
      "learning_rate": 7.969376594969013e-06,
      "loss": 0.005,
      "step": 16500
    },
    {
      "epoch": 6.018957345971564,
      "grad_norm": 0.00044623311259783804,
      "learning_rate": 7.962085308056872e-06,
      "loss": 0.0121,
      "step": 16510
    },
    {
      "epoch": 6.022602989427634,
      "grad_norm": 0.003004498779773712,
      "learning_rate": 7.954794021144733e-06,
      "loss": 0.0033,
      "step": 16520
    },
    {
      "epoch": 6.026248632883704,
      "grad_norm": 0.0003674269828479737,
      "learning_rate": 7.947502734232592e-06,
      "loss": 0.0121,
      "step": 16530
    },
    {
      "epoch": 6.029894276339774,
      "grad_norm": 0.7849613428115845,
      "learning_rate": 7.940211447320453e-06,
      "loss": 0.0082,
      "step": 16540
    },
    {
      "epoch": 6.033539919795844,
      "grad_norm": 0.902833104133606,
      "learning_rate": 7.932920160408312e-06,
      "loss": 0.001,
      "step": 16550
    },
    {
      "epoch": 6.037185563251914,
      "grad_norm": 1.3066229820251465,
      "learning_rate": 7.925628873496173e-06,
      "loss": 0.0019,
      "step": 16560
    },
    {
      "epoch": 6.040831206707984,
      "grad_norm": 0.001340179005637765,
      "learning_rate": 7.918337586584032e-06,
      "loss": 0.0161,
      "step": 16570
    },
    {
      "epoch": 6.044476850164054,
      "grad_norm": 0.0021529949735850096,
      "learning_rate": 7.911046299671893e-06,
      "loss": 0.0111,
      "step": 16580
    },
    {
      "epoch": 6.048122493620124,
      "grad_norm": 0.0013550693402066827,
      "learning_rate": 7.903755012759752e-06,
      "loss": 0.0027,
      "step": 16590
    },
    {
      "epoch": 6.051768137076194,
      "grad_norm": 0.0027414970099925995,
      "learning_rate": 7.896463725847613e-06,
      "loss": 0.0004,
      "step": 16600
    },
    {
      "epoch": 6.055413780532264,
      "grad_norm": 1.9008609056472778,
      "learning_rate": 7.889172438935472e-06,
      "loss": 0.0137,
      "step": 16610
    },
    {
      "epoch": 6.059059423988334,
      "grad_norm": 3.3596158027648926,
      "learning_rate": 7.881881152023333e-06,
      "loss": 0.0346,
      "step": 16620
    },
    {
      "epoch": 6.062705067444404,
      "grad_norm": 0.47254565358161926,
      "learning_rate": 7.874589865111192e-06,
      "loss": 0.0083,
      "step": 16630
    },
    {
      "epoch": 6.0663507109004735,
      "grad_norm": 0.0006385839660651982,
      "learning_rate": 7.867298578199053e-06,
      "loss": 0.0014,
      "step": 16640
    },
    {
      "epoch": 6.069996354356544,
      "grad_norm": 0.004171125125139952,
      "learning_rate": 7.860007291286913e-06,
      "loss": 0.0019,
      "step": 16650
    },
    {
      "epoch": 6.073641997812614,
      "grad_norm": 0.002959608333185315,
      "learning_rate": 7.852716004374773e-06,
      "loss": 0.011,
      "step": 16660
    },
    {
      "epoch": 6.077287641268684,
      "grad_norm": 0.0005553620285354555,
      "learning_rate": 7.845424717462633e-06,
      "loss": 0.0007,
      "step": 16670
    },
    {
      "epoch": 6.080933284724754,
      "grad_norm": 1.2755053043365479,
      "learning_rate": 7.838133430550493e-06,
      "loss": 0.0142,
      "step": 16680
    },
    {
      "epoch": 6.084578928180824,
      "grad_norm": 0.16200436651706696,
      "learning_rate": 7.830842143638353e-06,
      "loss": 0.0042,
      "step": 16690
    },
    {
      "epoch": 6.088224571636894,
      "grad_norm": 9.47685718536377,
      "learning_rate": 7.823550856726213e-06,
      "loss": 0.013,
      "step": 16700
    },
    {
      "epoch": 6.091870215092964,
      "grad_norm": 0.001234671100974083,
      "learning_rate": 7.816259569814073e-06,
      "loss": 0.0017,
      "step": 16710
    },
    {
      "epoch": 6.095515858549034,
      "grad_norm": 0.00045395316556096077,
      "learning_rate": 7.808968282901933e-06,
      "loss": 0.0003,
      "step": 16720
    },
    {
      "epoch": 6.099161502005104,
      "grad_norm": 2.4246327877044678,
      "learning_rate": 7.801676995989793e-06,
      "loss": 0.013,
      "step": 16730
    },
    {
      "epoch": 6.102807145461174,
      "grad_norm": 0.001251346431672573,
      "learning_rate": 7.794385709077653e-06,
      "loss": 0.0066,
      "step": 16740
    },
    {
      "epoch": 6.1064527889172435,
      "grad_norm": 0.0005941731506027281,
      "learning_rate": 7.787094422165513e-06,
      "loss": 0.0051,
      "step": 16750
    },
    {
      "epoch": 6.110098432373314,
      "grad_norm": 0.007185847032815218,
      "learning_rate": 7.779803135253373e-06,
      "loss": 0.0038,
      "step": 16760
    },
    {
      "epoch": 6.113744075829384,
      "grad_norm": 0.25798124074935913,
      "learning_rate": 7.772511848341233e-06,
      "loss": 0.0074,
      "step": 16770
    },
    {
      "epoch": 6.117389719285454,
      "grad_norm": 0.01900496892631054,
      "learning_rate": 7.765220561429093e-06,
      "loss": 0.0097,
      "step": 16780
    },
    {
      "epoch": 6.121035362741524,
      "grad_norm": 0.012521306052803993,
      "learning_rate": 7.757929274516953e-06,
      "loss": 0.0142,
      "step": 16790
    },
    {
      "epoch": 6.124681006197594,
      "grad_norm": 0.001010119216516614,
      "learning_rate": 7.750637987604814e-06,
      "loss": 0.0034,
      "step": 16800
    },
    {
      "epoch": 6.128326649653664,
      "grad_norm": 0.0003500230668578297,
      "learning_rate": 7.743346700692673e-06,
      "loss": 0.0008,
      "step": 16810
    },
    {
      "epoch": 6.131972293109734,
      "grad_norm": 0.0005496985395438969,
      "learning_rate": 7.736055413780534e-06,
      "loss": 0.0137,
      "step": 16820
    },
    {
      "epoch": 6.1356179365658035,
      "grad_norm": 0.007166656665503979,
      "learning_rate": 7.728764126868393e-06,
      "loss": 0.004,
      "step": 16830
    },
    {
      "epoch": 6.139263580021874,
      "grad_norm": 0.0028388400096446276,
      "learning_rate": 7.721472839956254e-06,
      "loss": 0.0,
      "step": 16840
    },
    {
      "epoch": 6.142909223477944,
      "grad_norm": 0.0003810447233263403,
      "learning_rate": 7.714181553044113e-06,
      "loss": 0.0,
      "step": 16850
    },
    {
      "epoch": 6.1465548669340135,
      "grad_norm": 0.0008865462732501328,
      "learning_rate": 7.706890266131974e-06,
      "loss": 0.0025,
      "step": 16860
    },
    {
      "epoch": 6.150200510390084,
      "grad_norm": 0.12093646824359894,
      "learning_rate": 7.699598979219833e-06,
      "loss": 0.0084,
      "step": 16870
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 0.000582359207328409,
      "learning_rate": 7.692307692307694e-06,
      "loss": 0.0039,
      "step": 16880
    },
    {
      "epoch": 6.157491797302224,
      "grad_norm": 0.0003219287027604878,
      "learning_rate": 7.685016405395553e-06,
      "loss": 0.0066,
      "step": 16890
    },
    {
      "epoch": 6.161137440758294,
      "grad_norm": 0.010138141922652721,
      "learning_rate": 7.677725118483414e-06,
      "loss": 0.0094,
      "step": 16900
    },
    {
      "epoch": 6.164783084214363,
      "grad_norm": 0.003924705553799868,
      "learning_rate": 7.670433831571273e-06,
      "loss": 0.0015,
      "step": 16910
    },
    {
      "epoch": 6.168428727670434,
      "grad_norm": 0.00017293526616413146,
      "learning_rate": 7.663142544659134e-06,
      "loss": 0.0207,
      "step": 16920
    },
    {
      "epoch": 6.172074371126504,
      "grad_norm": 0.0023243706673383713,
      "learning_rate": 7.655851257746993e-06,
      "loss": 0.0314,
      "step": 16930
    },
    {
      "epoch": 6.1757200145825735,
      "grad_norm": 0.2907756567001343,
      "learning_rate": 7.648559970834854e-06,
      "loss": 0.003,
      "step": 16940
    },
    {
      "epoch": 6.179365658038644,
      "grad_norm": 0.0009813668439164758,
      "learning_rate": 7.641268683922713e-06,
      "loss": 0.0248,
      "step": 16950
    },
    {
      "epoch": 6.183011301494714,
      "grad_norm": 0.000680045282933861,
      "learning_rate": 7.633977397010574e-06,
      "loss": 0.0043,
      "step": 16960
    },
    {
      "epoch": 6.1866569449507836,
      "grad_norm": 0.3876620829105377,
      "learning_rate": 7.626686110098434e-06,
      "loss": 0.0055,
      "step": 16970
    },
    {
      "epoch": 6.190302588406854,
      "grad_norm": 0.0025302490685135126,
      "learning_rate": 7.619394823186294e-06,
      "loss": 0.0024,
      "step": 16980
    },
    {
      "epoch": 6.193948231862924,
      "grad_norm": 0.0009564580395817757,
      "learning_rate": 7.612103536274154e-06,
      "loss": 0.0036,
      "step": 16990
    },
    {
      "epoch": 6.197593875318994,
      "grad_norm": 0.006195597816258669,
      "learning_rate": 7.604812249362014e-06,
      "loss": 0.0256,
      "step": 17000
    },
    {
      "epoch": 6.201239518775064,
      "grad_norm": 0.0010847924277186394,
      "learning_rate": 7.597520962449873e-06,
      "loss": 0.0048,
      "step": 17010
    },
    {
      "epoch": 6.204885162231133,
      "grad_norm": 0.0002315801102668047,
      "learning_rate": 7.590229675537733e-06,
      "loss": 0.0001,
      "step": 17020
    },
    {
      "epoch": 6.208530805687204,
      "grad_norm": 0.19570010900497437,
      "learning_rate": 7.582938388625593e-06,
      "loss": 0.0047,
      "step": 17030
    },
    {
      "epoch": 6.212176449143274,
      "grad_norm": 0.6493533849716187,
      "learning_rate": 7.575647101713453e-06,
      "loss": 0.0022,
      "step": 17040
    },
    {
      "epoch": 6.2158220925993435,
      "grad_norm": 0.00020511419279500842,
      "learning_rate": 7.568355814801313e-06,
      "loss": 0.0058,
      "step": 17050
    },
    {
      "epoch": 6.219467736055414,
      "grad_norm": 1.2373228073120117,
      "learning_rate": 7.561064527889173e-06,
      "loss": 0.0008,
      "step": 17060
    },
    {
      "epoch": 6.223113379511484,
      "grad_norm": 0.0002491252380423248,
      "learning_rate": 7.553773240977033e-06,
      "loss": 0.001,
      "step": 17070
    },
    {
      "epoch": 6.226759022967554,
      "grad_norm": 5.922641277313232,
      "learning_rate": 7.546481954064893e-06,
      "loss": 0.0383,
      "step": 17080
    },
    {
      "epoch": 6.230404666423624,
      "grad_norm": 2.1236283779144287,
      "learning_rate": 7.539190667152753e-06,
      "loss": 0.0544,
      "step": 17090
    },
    {
      "epoch": 6.234050309879693,
      "grad_norm": 0.004103383515030146,
      "learning_rate": 7.531899380240613e-06,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 6.237695953335764,
      "grad_norm": 1.8302791118621826,
      "learning_rate": 7.524608093328473e-06,
      "loss": 0.0127,
      "step": 17110
    },
    {
      "epoch": 6.241341596791834,
      "grad_norm": 0.00043784172157756984,
      "learning_rate": 7.517316806416333e-06,
      "loss": 0.0024,
      "step": 17120
    },
    {
      "epoch": 6.244987240247903,
      "grad_norm": 0.015786392614245415,
      "learning_rate": 7.510025519504193e-06,
      "loss": 0.0131,
      "step": 17130
    },
    {
      "epoch": 6.248632883703974,
      "grad_norm": 2.281201124191284,
      "learning_rate": 7.502734232592053e-06,
      "loss": 0.0287,
      "step": 17140
    },
    {
      "epoch": 6.252278527160044,
      "grad_norm": 0.08585520833730698,
      "learning_rate": 7.495442945679913e-06,
      "loss": 0.0199,
      "step": 17150
    },
    {
      "epoch": 6.2559241706161135,
      "grad_norm": 0.04247063770890236,
      "learning_rate": 7.488151658767773e-06,
      "loss": 0.0086,
      "step": 17160
    },
    {
      "epoch": 6.259569814072184,
      "grad_norm": 15.852376937866211,
      "learning_rate": 7.480860371855633e-06,
      "loss": 0.0181,
      "step": 17170
    },
    {
      "epoch": 6.263215457528254,
      "grad_norm": 0.31179168820381165,
      "learning_rate": 7.473569084943493e-06,
      "loss": 0.044,
      "step": 17180
    },
    {
      "epoch": 6.266861100984324,
      "grad_norm": 0.0059939539059996605,
      "learning_rate": 7.466277798031353e-06,
      "loss": 0.0065,
      "step": 17190
    },
    {
      "epoch": 6.270506744440394,
      "grad_norm": 0.006899499800056219,
      "learning_rate": 7.458986511119213e-06,
      "loss": 0.008,
      "step": 17200
    },
    {
      "epoch": 6.274152387896463,
      "grad_norm": 0.031418222934007645,
      "learning_rate": 7.451695224207073e-06,
      "loss": 0.0041,
      "step": 17210
    },
    {
      "epoch": 6.277798031352534,
      "grad_norm": 0.002848002128303051,
      "learning_rate": 7.444403937294933e-06,
      "loss": 0.0117,
      "step": 17220
    },
    {
      "epoch": 6.281443674808604,
      "grad_norm": 1.0654157400131226,
      "learning_rate": 7.437112650382793e-06,
      "loss": 0.0094,
      "step": 17230
    },
    {
      "epoch": 6.285089318264673,
      "grad_norm": 0.010670531541109085,
      "learning_rate": 7.429821363470653e-06,
      "loss": 0.0001,
      "step": 17240
    },
    {
      "epoch": 6.288734961720744,
      "grad_norm": 4.187669277191162,
      "learning_rate": 7.422530076558513e-06,
      "loss": 0.008,
      "step": 17250
    },
    {
      "epoch": 6.292380605176814,
      "grad_norm": 0.022946910932660103,
      "learning_rate": 7.415238789646373e-06,
      "loss": 0.0082,
      "step": 17260
    },
    {
      "epoch": 6.2960262486328835,
      "grad_norm": 0.0039613801054656506,
      "learning_rate": 7.407947502734233e-06,
      "loss": 0.002,
      "step": 17270
    },
    {
      "epoch": 6.299671892088954,
      "grad_norm": 1.0935896635055542,
      "learning_rate": 7.400656215822093e-06,
      "loss": 0.0291,
      "step": 17280
    },
    {
      "epoch": 6.303317535545023,
      "grad_norm": 0.9284160137176514,
      "learning_rate": 7.393364928909953e-06,
      "loss": 0.0146,
      "step": 17290
    },
    {
      "epoch": 6.306963179001094,
      "grad_norm": 0.0024897430557757616,
      "learning_rate": 7.386073641997813e-06,
      "loss": 0.0044,
      "step": 17300
    },
    {
      "epoch": 6.310608822457164,
      "grad_norm": 0.08911648392677307,
      "learning_rate": 7.378782355085673e-06,
      "loss": 0.0013,
      "step": 17310
    },
    {
      "epoch": 6.314254465913233,
      "grad_norm": 0.0027389577589929104,
      "learning_rate": 7.371491068173533e-06,
      "loss": 0.0017,
      "step": 17320
    },
    {
      "epoch": 6.317900109369304,
      "grad_norm": 1.621669888496399,
      "learning_rate": 7.364199781261393e-06,
      "loss": 0.0087,
      "step": 17330
    },
    {
      "epoch": 6.321545752825374,
      "grad_norm": 0.0027379076927900314,
      "learning_rate": 7.356908494349253e-06,
      "loss": 0.0016,
      "step": 17340
    },
    {
      "epoch": 6.3251913962814434,
      "grad_norm": 0.0006170850829221308,
      "learning_rate": 7.349617207437113e-06,
      "loss": 0.0073,
      "step": 17350
    },
    {
      "epoch": 6.328837039737514,
      "grad_norm": 0.0028377813287079334,
      "learning_rate": 7.342325920524973e-06,
      "loss": 0.0156,
      "step": 17360
    },
    {
      "epoch": 6.332482683193584,
      "grad_norm": 0.0003397276741452515,
      "learning_rate": 7.335034633612833e-06,
      "loss": 0.0196,
      "step": 17370
    },
    {
      "epoch": 6.3361283266496535,
      "grad_norm": 0.0006774007924832404,
      "learning_rate": 7.327743346700693e-06,
      "loss": 0.004,
      "step": 17380
    },
    {
      "epoch": 6.339773970105724,
      "grad_norm": 0.0007424265495501459,
      "learning_rate": 7.320452059788553e-06,
      "loss": 0.0064,
      "step": 17390
    },
    {
      "epoch": 6.343419613561793,
      "grad_norm": 0.002699244301766157,
      "learning_rate": 7.313160772876413e-06,
      "loss": 0.0171,
      "step": 17400
    },
    {
      "epoch": 6.347065257017864,
      "grad_norm": 0.00016942435468081385,
      "learning_rate": 7.305869485964273e-06,
      "loss": 0.0015,
      "step": 17410
    },
    {
      "epoch": 6.350710900473934,
      "grad_norm": 0.009230045601725578,
      "learning_rate": 7.298578199052133e-06,
      "loss": 0.0126,
      "step": 17420
    },
    {
      "epoch": 6.354356543930003,
      "grad_norm": 0.0008377538761124015,
      "learning_rate": 7.291286912139993e-06,
      "loss": 0.001,
      "step": 17430
    },
    {
      "epoch": 6.358002187386074,
      "grad_norm": 0.19449838995933533,
      "learning_rate": 7.283995625227853e-06,
      "loss": 0.0106,
      "step": 17440
    },
    {
      "epoch": 6.361647830842144,
      "grad_norm": 0.0006447769701480865,
      "learning_rate": 7.276704338315713e-06,
      "loss": 0.0108,
      "step": 17450
    },
    {
      "epoch": 6.3652934742982135,
      "grad_norm": 0.011953683570027351,
      "learning_rate": 7.269413051403573e-06,
      "loss": 0.0062,
      "step": 17460
    },
    {
      "epoch": 6.368939117754284,
      "grad_norm": 0.0006353313801810145,
      "learning_rate": 7.262121764491433e-06,
      "loss": 0.0071,
      "step": 17470
    },
    {
      "epoch": 6.372584761210353,
      "grad_norm": 0.0005996528780087829,
      "learning_rate": 7.254830477579293e-06,
      "loss": 0.0031,
      "step": 17480
    },
    {
      "epoch": 6.3762304046664235,
      "grad_norm": 0.009831099770963192,
      "learning_rate": 7.247539190667153e-06,
      "loss": 0.0156,
      "step": 17490
    },
    {
      "epoch": 6.379876048122494,
      "grad_norm": 0.0032713317777961493,
      "learning_rate": 7.240247903755013e-06,
      "loss": 0.0113,
      "step": 17500
    },
    {
      "epoch": 6.383521691578563,
      "grad_norm": 0.0008998513803817332,
      "learning_rate": 7.232956616842873e-06,
      "loss": 0.0039,
      "step": 17510
    },
    {
      "epoch": 6.387167335034634,
      "grad_norm": 3.529884099960327,
      "learning_rate": 7.225665329930733e-06,
      "loss": 0.0105,
      "step": 17520
    },
    {
      "epoch": 6.390812978490704,
      "grad_norm": 0.007341173477470875,
      "learning_rate": 7.218374043018593e-06,
      "loss": 0.0031,
      "step": 17530
    },
    {
      "epoch": 6.394458621946773,
      "grad_norm": 0.9733806252479553,
      "learning_rate": 7.211082756106453e-06,
      "loss": 0.0055,
      "step": 17540
    },
    {
      "epoch": 6.398104265402844,
      "grad_norm": 1.3919639587402344,
      "learning_rate": 7.203791469194313e-06,
      "loss": 0.0423,
      "step": 17550
    },
    {
      "epoch": 6.401749908858914,
      "grad_norm": 0.00253947451710701,
      "learning_rate": 7.1965001822821734e-06,
      "loss": 0.0183,
      "step": 17560
    },
    {
      "epoch": 6.4053955523149835,
      "grad_norm": 0.00028997022309340537,
      "learning_rate": 7.1892088953700334e-06,
      "loss": 0.0013,
      "step": 17570
    },
    {
      "epoch": 6.409041195771054,
      "grad_norm": 0.2191622406244278,
      "learning_rate": 7.1819176084578934e-06,
      "loss": 0.0003,
      "step": 17580
    },
    {
      "epoch": 6.412686839227123,
      "grad_norm": 0.00032551679760217667,
      "learning_rate": 7.1746263215457535e-06,
      "loss": 0.0116,
      "step": 17590
    },
    {
      "epoch": 6.416332482683194,
      "grad_norm": 0.0004978759679943323,
      "learning_rate": 7.1673350346336135e-06,
      "loss": 0.0028,
      "step": 17600
    },
    {
      "epoch": 6.419978126139264,
      "grad_norm": 0.0006557167507708073,
      "learning_rate": 7.1600437477214735e-06,
      "loss": 0.0003,
      "step": 17610
    },
    {
      "epoch": 6.423623769595333,
      "grad_norm": 0.09257097542285919,
      "learning_rate": 7.1527524608093335e-06,
      "loss": 0.0038,
      "step": 17620
    },
    {
      "epoch": 6.427269413051404,
      "grad_norm": 0.028137458488345146,
      "learning_rate": 7.1454611738971935e-06,
      "loss": 0.0376,
      "step": 17630
    },
    {
      "epoch": 6.430915056507474,
      "grad_norm": 0.005741228349506855,
      "learning_rate": 7.1381698869850535e-06,
      "loss": 0.0147,
      "step": 17640
    },
    {
      "epoch": 6.434560699963543,
      "grad_norm": 0.4053085744380951,
      "learning_rate": 7.1308786000729135e-06,
      "loss": 0.0231,
      "step": 17650
    },
    {
      "epoch": 6.438206343419614,
      "grad_norm": 0.0009253215976059437,
      "learning_rate": 7.1235873131607735e-06,
      "loss": 0.0261,
      "step": 17660
    },
    {
      "epoch": 6.441851986875683,
      "grad_norm": 0.012074075639247894,
      "learning_rate": 7.1162960262486335e-06,
      "loss": 0.0003,
      "step": 17670
    },
    {
      "epoch": 6.4454976303317535,
      "grad_norm": 0.0019850898534059525,
      "learning_rate": 7.1090047393364935e-06,
      "loss": 0.0035,
      "step": 17680
    },
    {
      "epoch": 6.449143273787824,
      "grad_norm": 19.976924896240234,
      "learning_rate": 7.1017134524243536e-06,
      "loss": 0.0124,
      "step": 17690
    },
    {
      "epoch": 6.452788917243893,
      "grad_norm": 0.0034361216239631176,
      "learning_rate": 7.0944221655122136e-06,
      "loss": 0.0122,
      "step": 17700
    },
    {
      "epoch": 6.456434560699964,
      "grad_norm": 0.001269480213522911,
      "learning_rate": 7.087130878600074e-06,
      "loss": 0.0001,
      "step": 17710
    },
    {
      "epoch": 6.460080204156034,
      "grad_norm": 7.11100959777832,
      "learning_rate": 7.079839591687934e-06,
      "loss": 0.0185,
      "step": 17720
    },
    {
      "epoch": 6.463725847612103,
      "grad_norm": 0.0025846161879599094,
      "learning_rate": 7.072548304775794e-06,
      "loss": 0.0046,
      "step": 17730
    },
    {
      "epoch": 6.467371491068174,
      "grad_norm": 0.0017757905879989266,
      "learning_rate": 7.065257017863654e-06,
      "loss": 0.0019,
      "step": 17740
    },
    {
      "epoch": 6.471017134524244,
      "grad_norm": 0.0037208865396678448,
      "learning_rate": 7.057965730951514e-06,
      "loss": 0.0002,
      "step": 17750
    },
    {
      "epoch": 6.474662777980313,
      "grad_norm": 0.0005504353903234005,
      "learning_rate": 7.050674444039374e-06,
      "loss": 0.0049,
      "step": 17760
    },
    {
      "epoch": 6.478308421436384,
      "grad_norm": 0.0018804669380187988,
      "learning_rate": 7.043383157127234e-06,
      "loss": 0.0003,
      "step": 17770
    },
    {
      "epoch": 6.481954064892453,
      "grad_norm": 0.0009572431445121765,
      "learning_rate": 7.036091870215094e-06,
      "loss": 0.0,
      "step": 17780
    },
    {
      "epoch": 6.4855997083485235,
      "grad_norm": 0.0003706390562001616,
      "learning_rate": 7.028800583302954e-06,
      "loss": 0.0123,
      "step": 17790
    },
    {
      "epoch": 6.489245351804594,
      "grad_norm": 0.0005020613898523152,
      "learning_rate": 7.021509296390814e-06,
      "loss": 0.0049,
      "step": 17800
    },
    {
      "epoch": 6.492890995260663,
      "grad_norm": 0.000905199849512428,
      "learning_rate": 7.014218009478674e-06,
      "loss": 0.0231,
      "step": 17810
    },
    {
      "epoch": 6.496536638716734,
      "grad_norm": 1.7913413047790527,
      "learning_rate": 7.006926722566534e-06,
      "loss": 0.0092,
      "step": 17820
    },
    {
      "epoch": 6.500182282172803,
      "grad_norm": 0.0024373431224375963,
      "learning_rate": 6.999635435654394e-06,
      "loss": 0.0057,
      "step": 17830
    },
    {
      "epoch": 6.503827925628873,
      "grad_norm": 1.8177456855773926,
      "learning_rate": 6.992344148742254e-06,
      "loss": 0.0315,
      "step": 17840
    },
    {
      "epoch": 6.507473569084944,
      "grad_norm": 0.01058026310056448,
      "learning_rate": 6.985052861830114e-06,
      "loss": 0.0011,
      "step": 17850
    },
    {
      "epoch": 6.511119212541013,
      "grad_norm": 0.0031151887960731983,
      "learning_rate": 6.977761574917974e-06,
      "loss": 0.0174,
      "step": 17860
    },
    {
      "epoch": 6.514764855997083,
      "grad_norm": 0.0014317804016172886,
      "learning_rate": 6.970470288005834e-06,
      "loss": 0.002,
      "step": 17870
    },
    {
      "epoch": 6.518410499453154,
      "grad_norm": 0.4801260530948639,
      "learning_rate": 6.963179001093694e-06,
      "loss": 0.0076,
      "step": 17880
    },
    {
      "epoch": 6.522056142909223,
      "grad_norm": 0.8256401419639587,
      "learning_rate": 6.955887714181554e-06,
      "loss": 0.0021,
      "step": 17890
    },
    {
      "epoch": 6.5257017863652935,
      "grad_norm": 0.0026769491378217936,
      "learning_rate": 6.948596427269414e-06,
      "loss": 0.0164,
      "step": 17900
    },
    {
      "epoch": 6.529347429821364,
      "grad_norm": 0.013058158569037914,
      "learning_rate": 6.941305140357274e-06,
      "loss": 0.0157,
      "step": 17910
    },
    {
      "epoch": 6.532993073277433,
      "grad_norm": 0.38032278418540955,
      "learning_rate": 6.934013853445134e-06,
      "loss": 0.0147,
      "step": 17920
    },
    {
      "epoch": 6.536638716733504,
      "grad_norm": 0.0009967865189537406,
      "learning_rate": 6.926722566532994e-06,
      "loss": 0.0074,
      "step": 17930
    },
    {
      "epoch": 6.540284360189574,
      "grad_norm": 0.30911019444465637,
      "learning_rate": 6.919431279620854e-06,
      "loss": 0.0041,
      "step": 17940
    },
    {
      "epoch": 6.543930003645643,
      "grad_norm": 0.0893266424536705,
      "learning_rate": 6.912139992708714e-06,
      "loss": 0.0279,
      "step": 17950
    },
    {
      "epoch": 6.547575647101714,
      "grad_norm": 0.0059405239298939705,
      "learning_rate": 6.904848705796574e-06,
      "loss": 0.0033,
      "step": 17960
    },
    {
      "epoch": 6.551221290557783,
      "grad_norm": 0.0014602201990783215,
      "learning_rate": 6.897557418884434e-06,
      "loss": 0.0036,
      "step": 17970
    },
    {
      "epoch": 6.5548669340138535,
      "grad_norm": 13.740069389343262,
      "learning_rate": 6.890266131972294e-06,
      "loss": 0.0062,
      "step": 17980
    },
    {
      "epoch": 6.558512577469924,
      "grad_norm": 0.8191884160041809,
      "learning_rate": 6.882974845060154e-06,
      "loss": 0.0015,
      "step": 17990
    },
    {
      "epoch": 6.562158220925993,
      "grad_norm": 0.002083116676658392,
      "learning_rate": 6.875683558148014e-06,
      "loss": 0.0032,
      "step": 18000
    },
    {
      "epoch": 6.5658038643820635,
      "grad_norm": 1.9974545240402222,
      "learning_rate": 6.868392271235874e-06,
      "loss": 0.0158,
      "step": 18010
    },
    {
      "epoch": 6.569449507838133,
      "grad_norm": 0.011675928719341755,
      "learning_rate": 6.861100984323734e-06,
      "loss": 0.0074,
      "step": 18020
    },
    {
      "epoch": 6.573095151294203,
      "grad_norm": 4.894080638885498,
      "learning_rate": 6.853809697411594e-06,
      "loss": 0.0169,
      "step": 18030
    },
    {
      "epoch": 6.576740794750274,
      "grad_norm": 0.0051216380670666695,
      "learning_rate": 6.846518410499454e-06,
      "loss": 0.0027,
      "step": 18040
    },
    {
      "epoch": 6.580386438206343,
      "grad_norm": 0.4485548138618469,
      "learning_rate": 6.839227123587314e-06,
      "loss": 0.0119,
      "step": 18050
    },
    {
      "epoch": 6.584032081662413,
      "grad_norm": 0.0031755324453115463,
      "learning_rate": 6.831935836675174e-06,
      "loss": 0.0226,
      "step": 18060
    },
    {
      "epoch": 6.587677725118484,
      "grad_norm": 0.0006299795350059867,
      "learning_rate": 6.824644549763034e-06,
      "loss": 0.0001,
      "step": 18070
    },
    {
      "epoch": 6.591323368574553,
      "grad_norm": 13.493233680725098,
      "learning_rate": 6.817353262850894e-06,
      "loss": 0.0197,
      "step": 18080
    },
    {
      "epoch": 6.5949690120306235,
      "grad_norm": 0.00313765206374228,
      "learning_rate": 6.810061975938754e-06,
      "loss": 0.0011,
      "step": 18090
    },
    {
      "epoch": 6.598614655486694,
      "grad_norm": 0.0024620695039629936,
      "learning_rate": 6.802770689026614e-06,
      "loss": 0.0013,
      "step": 18100
    },
    {
      "epoch": 6.602260298942763,
      "grad_norm": 0.00033465877640992403,
      "learning_rate": 6.795479402114473e-06,
      "loss": 0.0301,
      "step": 18110
    },
    {
      "epoch": 6.6059059423988336,
      "grad_norm": 0.001381194917485118,
      "learning_rate": 6.788188115202333e-06,
      "loss": 0.0002,
      "step": 18120
    },
    {
      "epoch": 6.609551585854904,
      "grad_norm": 0.0013524466194212437,
      "learning_rate": 6.780896828290193e-06,
      "loss": 0.0063,
      "step": 18130
    },
    {
      "epoch": 6.613197229310973,
      "grad_norm": 0.40828609466552734,
      "learning_rate": 6.773605541378053e-06,
      "loss": 0.0109,
      "step": 18140
    },
    {
      "epoch": 6.616842872767044,
      "grad_norm": 0.0017572956858202815,
      "learning_rate": 6.766314254465913e-06,
      "loss": 0.0001,
      "step": 18150
    },
    {
      "epoch": 6.620488516223113,
      "grad_norm": 0.002229273784905672,
      "learning_rate": 6.759022967553773e-06,
      "loss": 0.0164,
      "step": 18160
    },
    {
      "epoch": 6.624134159679183,
      "grad_norm": 0.00285035721026361,
      "learning_rate": 6.751731680641633e-06,
      "loss": 0.0139,
      "step": 18170
    },
    {
      "epoch": 6.627779803135254,
      "grad_norm": 0.0009447445045225322,
      "learning_rate": 6.744440393729493e-06,
      "loss": 0.0004,
      "step": 18180
    },
    {
      "epoch": 6.631425446591323,
      "grad_norm": 1.439475417137146,
      "learning_rate": 6.737149106817353e-06,
      "loss": 0.0085,
      "step": 18190
    },
    {
      "epoch": 6.6350710900473935,
      "grad_norm": 1.2123169898986816,
      "learning_rate": 6.729857819905213e-06,
      "loss": 0.0062,
      "step": 18200
    },
    {
      "epoch": 6.638716733503463,
      "grad_norm": 0.0017532298807054758,
      "learning_rate": 6.722566532993073e-06,
      "loss": 0.0071,
      "step": 18210
    },
    {
      "epoch": 6.642362376959533,
      "grad_norm": 0.4080047607421875,
      "learning_rate": 6.715275246080933e-06,
      "loss": 0.0065,
      "step": 18220
    },
    {
      "epoch": 6.646008020415604,
      "grad_norm": 0.0012913133250549436,
      "learning_rate": 6.707983959168793e-06,
      "loss": 0.0105,
      "step": 18230
    },
    {
      "epoch": 6.649653663871673,
      "grad_norm": 0.0767015665769577,
      "learning_rate": 6.700692672256653e-06,
      "loss": 0.0148,
      "step": 18240
    },
    {
      "epoch": 6.653299307327743,
      "grad_norm": 0.001742329215630889,
      "learning_rate": 6.693401385344513e-06,
      "loss": 0.012,
      "step": 18250
    },
    {
      "epoch": 6.656944950783814,
      "grad_norm": 0.002463677665218711,
      "learning_rate": 6.686110098432373e-06,
      "loss": 0.0093,
      "step": 18260
    },
    {
      "epoch": 6.660590594239883,
      "grad_norm": 0.0007217350066639483,
      "learning_rate": 6.678818811520233e-06,
      "loss": 0.0305,
      "step": 18270
    },
    {
      "epoch": 6.664236237695953,
      "grad_norm": 0.12321780622005463,
      "learning_rate": 6.671527524608093e-06,
      "loss": 0.0114,
      "step": 18280
    },
    {
      "epoch": 6.667881881152024,
      "grad_norm": 20.52347183227539,
      "learning_rate": 6.664236237695953e-06,
      "loss": 0.0175,
      "step": 18290
    },
    {
      "epoch": 6.671527524608093,
      "grad_norm": 1.0528349876403809,
      "learning_rate": 6.656944950783813e-06,
      "loss": 0.0093,
      "step": 18300
    },
    {
      "epoch": 6.6751731680641635,
      "grad_norm": 1.4715511798858643,
      "learning_rate": 6.649653663871673e-06,
      "loss": 0.0066,
      "step": 18310
    },
    {
      "epoch": 6.678818811520233,
      "grad_norm": 0.9338942170143127,
      "learning_rate": 6.642362376959533e-06,
      "loss": 0.0126,
      "step": 18320
    },
    {
      "epoch": 6.682464454976303,
      "grad_norm": 0.22942453622817993,
      "learning_rate": 6.635071090047393e-06,
      "loss": 0.0093,
      "step": 18330
    },
    {
      "epoch": 6.686110098432374,
      "grad_norm": 0.006805160082876682,
      "learning_rate": 6.627779803135253e-06,
      "loss": 0.044,
      "step": 18340
    },
    {
      "epoch": 6.689755741888443,
      "grad_norm": 1.137183666229248,
      "learning_rate": 6.620488516223113e-06,
      "loss": 0.0034,
      "step": 18350
    },
    {
      "epoch": 6.693401385344513,
      "grad_norm": 0.02163904346525669,
      "learning_rate": 6.613197229310973e-06,
      "loss": 0.0022,
      "step": 18360
    },
    {
      "epoch": 6.697047028800584,
      "grad_norm": 0.011119898408651352,
      "learning_rate": 6.605905942398833e-06,
      "loss": 0.0084,
      "step": 18370
    },
    {
      "epoch": 6.700692672256653,
      "grad_norm": 0.0005967906909063458,
      "learning_rate": 6.598614655486693e-06,
      "loss": 0.0227,
      "step": 18380
    },
    {
      "epoch": 6.704338315712723,
      "grad_norm": 0.007392438594251871,
      "learning_rate": 6.591323368574553e-06,
      "loss": 0.0127,
      "step": 18390
    },
    {
      "epoch": 6.707983959168793,
      "grad_norm": 0.11233379691839218,
      "learning_rate": 6.5840320816624134e-06,
      "loss": 0.0019,
      "step": 18400
    },
    {
      "epoch": 6.711629602624863,
      "grad_norm": 0.3359678387641907,
      "learning_rate": 6.5767407947502734e-06,
      "loss": 0.0071,
      "step": 18410
    },
    {
      "epoch": 6.7152752460809335,
      "grad_norm": 0.008162999525666237,
      "learning_rate": 6.5694495078381334e-06,
      "loss": 0.0156,
      "step": 18420
    },
    {
      "epoch": 6.718920889537003,
      "grad_norm": 0.0068315244279801846,
      "learning_rate": 6.5621582209259935e-06,
      "loss": 0.0043,
      "step": 18430
    },
    {
      "epoch": 6.722566532993073,
      "grad_norm": 0.047274861484766006,
      "learning_rate": 6.5548669340138535e-06,
      "loss": 0.0018,
      "step": 18440
    },
    {
      "epoch": 6.726212176449144,
      "grad_norm": 0.5165824890136719,
      "learning_rate": 6.5475756471017135e-06,
      "loss": 0.0167,
      "step": 18450
    },
    {
      "epoch": 6.729857819905213,
      "grad_norm": 0.10867853462696075,
      "learning_rate": 6.5402843601895735e-06,
      "loss": 0.0264,
      "step": 18460
    },
    {
      "epoch": 6.733503463361283,
      "grad_norm": 0.04206577315926552,
      "learning_rate": 6.5329930732774335e-06,
      "loss": 0.0035,
      "step": 18470
    },
    {
      "epoch": 6.737149106817354,
      "grad_norm": 0.014715378172695637,
      "learning_rate": 6.5257017863652935e-06,
      "loss": 0.013,
      "step": 18480
    },
    {
      "epoch": 6.740794750273423,
      "grad_norm": 0.12973733246326447,
      "learning_rate": 6.5184104994531535e-06,
      "loss": 0.0099,
      "step": 18490
    },
    {
      "epoch": 6.744440393729493,
      "grad_norm": 0.760101318359375,
      "learning_rate": 6.5111192125410135e-06,
      "loss": 0.0063,
      "step": 18500
    },
    {
      "epoch": 6.748086037185563,
      "grad_norm": 0.010669431649148464,
      "learning_rate": 6.5038279256288735e-06,
      "loss": 0.003,
      "step": 18510
    },
    {
      "epoch": 6.751731680641633,
      "grad_norm": 0.00048302276991307735,
      "learning_rate": 6.4965366387167335e-06,
      "loss": 0.0142,
      "step": 18520
    },
    {
      "epoch": 6.7553773240977035,
      "grad_norm": 0.0015048428904265165,
      "learning_rate": 6.4892453518045936e-06,
      "loss": 0.0028,
      "step": 18530
    },
    {
      "epoch": 6.759022967553773,
      "grad_norm": 0.000810682715382427,
      "learning_rate": 6.4819540648924536e-06,
      "loss": 0.0038,
      "step": 18540
    },
    {
      "epoch": 6.762668611009843,
      "grad_norm": 0.0003469580551609397,
      "learning_rate": 6.474662777980314e-06,
      "loss": 0.0013,
      "step": 18550
    },
    {
      "epoch": 6.766314254465914,
      "grad_norm": 0.8965961337089539,
      "learning_rate": 6.467371491068174e-06,
      "loss": 0.0214,
      "step": 18560
    },
    {
      "epoch": 6.769959897921983,
      "grad_norm": 0.0074617560021579266,
      "learning_rate": 6.460080204156034e-06,
      "loss": 0.0074,
      "step": 18570
    },
    {
      "epoch": 6.773605541378053,
      "grad_norm": 0.059438012540340424,
      "learning_rate": 6.452788917243894e-06,
      "loss": 0.0126,
      "step": 18580
    },
    {
      "epoch": 6.777251184834123,
      "grad_norm": 0.0015449334168806672,
      "learning_rate": 6.445497630331754e-06,
      "loss": 0.0038,
      "step": 18590
    },
    {
      "epoch": 6.780896828290193,
      "grad_norm": 0.07100112736225128,
      "learning_rate": 6.438206343419614e-06,
      "loss": 0.008,
      "step": 18600
    },
    {
      "epoch": 6.7845424717462635,
      "grad_norm": 0.0003729881427716464,
      "learning_rate": 6.430915056507474e-06,
      "loss": 0.0046,
      "step": 18610
    },
    {
      "epoch": 6.788188115202333,
      "grad_norm": 0.0005565179162658751,
      "learning_rate": 6.423623769595334e-06,
      "loss": 0.0124,
      "step": 18620
    },
    {
      "epoch": 6.791833758658403,
      "grad_norm": 0.002037158701568842,
      "learning_rate": 6.4163324826831945e-06,
      "loss": 0.0045,
      "step": 18630
    },
    {
      "epoch": 6.7954794021144735,
      "grad_norm": 0.0050901188515126705,
      "learning_rate": 6.4090411957710545e-06,
      "loss": 0.0164,
      "step": 18640
    },
    {
      "epoch": 6.799125045570543,
      "grad_norm": 0.36291584372520447,
      "learning_rate": 6.4017499088589145e-06,
      "loss": 0.0222,
      "step": 18650
    },
    {
      "epoch": 6.802770689026613,
      "grad_norm": 0.033901385962963104,
      "learning_rate": 6.3944586219467745e-06,
      "loss": 0.0129,
      "step": 18660
    },
    {
      "epoch": 6.806416332482684,
      "grad_norm": 0.015661276876926422,
      "learning_rate": 6.3871673350346345e-06,
      "loss": 0.0108,
      "step": 18670
    },
    {
      "epoch": 6.810061975938753,
      "grad_norm": 0.002831400139257312,
      "learning_rate": 6.3798760481224946e-06,
      "loss": 0.0103,
      "step": 18680
    },
    {
      "epoch": 6.813707619394823,
      "grad_norm": 0.005742275156080723,
      "learning_rate": 6.3725847612103546e-06,
      "loss": 0.0123,
      "step": 18690
    },
    {
      "epoch": 6.817353262850893,
      "grad_norm": 0.5008161067962646,
      "learning_rate": 6.365293474298215e-06,
      "loss": 0.0142,
      "step": 18700
    },
    {
      "epoch": 6.820998906306963,
      "grad_norm": 0.0018417381215840578,
      "learning_rate": 6.358002187386075e-06,
      "loss": 0.0031,
      "step": 18710
    },
    {
      "epoch": 6.8246445497630335,
      "grad_norm": 0.005926932208240032,
      "learning_rate": 6.350710900473935e-06,
      "loss": 0.002,
      "step": 18720
    },
    {
      "epoch": 6.828290193219103,
      "grad_norm": 0.00032719067530706525,
      "learning_rate": 6.343419613561795e-06,
      "loss": 0.0189,
      "step": 18730
    },
    {
      "epoch": 6.831935836675173,
      "grad_norm": 0.07174855470657349,
      "learning_rate": 6.336128326649655e-06,
      "loss": 0.0046,
      "step": 18740
    },
    {
      "epoch": 6.835581480131243,
      "grad_norm": 0.0010614116908982396,
      "learning_rate": 6.328837039737515e-06,
      "loss": 0.0014,
      "step": 18750
    },
    {
      "epoch": 6.839227123587313,
      "grad_norm": 0.0043367561884224415,
      "learning_rate": 6.321545752825375e-06,
      "loss": 0.0107,
      "step": 18760
    },
    {
      "epoch": 6.842872767043383,
      "grad_norm": 1.085799217224121,
      "learning_rate": 6.314254465913235e-06,
      "loss": 0.0061,
      "step": 18770
    },
    {
      "epoch": 6.846518410499453,
      "grad_norm": 0.244851753115654,
      "learning_rate": 6.306963179001095e-06,
      "loss": 0.0089,
      "step": 18780
    },
    {
      "epoch": 6.850164053955523,
      "grad_norm": 0.0017464191187173128,
      "learning_rate": 6.299671892088955e-06,
      "loss": 0.0001,
      "step": 18790
    },
    {
      "epoch": 6.853809697411593,
      "grad_norm": 0.001134986523538828,
      "learning_rate": 6.292380605176815e-06,
      "loss": 0.006,
      "step": 18800
    },
    {
      "epoch": 6.857455340867663,
      "grad_norm": 0.15670301020145416,
      "learning_rate": 6.285089318264675e-06,
      "loss": 0.0066,
      "step": 18810
    },
    {
      "epoch": 6.861100984323733,
      "grad_norm": 1.3979835510253906,
      "learning_rate": 6.277798031352535e-06,
      "loss": 0.0083,
      "step": 18820
    },
    {
      "epoch": 6.8647466277798035,
      "grad_norm": 4.62334680557251,
      "learning_rate": 6.270506744440395e-06,
      "loss": 0.0035,
      "step": 18830
    },
    {
      "epoch": 6.868392271235873,
      "grad_norm": 0.011495593003928661,
      "learning_rate": 6.263215457528255e-06,
      "loss": 0.0262,
      "step": 18840
    },
    {
      "epoch": 6.872037914691943,
      "grad_norm": 0.017877686768770218,
      "learning_rate": 6.255924170616115e-06,
      "loss": 0.0006,
      "step": 18850
    },
    {
      "epoch": 6.875683558148014,
      "grad_norm": 0.007937920279800892,
      "learning_rate": 6.248632883703975e-06,
      "loss": 0.0095,
      "step": 18860
    },
    {
      "epoch": 6.879329201604083,
      "grad_norm": 0.0002852360194083303,
      "learning_rate": 6.241341596791835e-06,
      "loss": 0.0008,
      "step": 18870
    },
    {
      "epoch": 6.882974845060153,
      "grad_norm": 0.06120189651846886,
      "learning_rate": 6.234050309879695e-06,
      "loss": 0.0232,
      "step": 18880
    },
    {
      "epoch": 6.886620488516223,
      "grad_norm": 0.018014518544077873,
      "learning_rate": 6.226759022967555e-06,
      "loss": 0.0078,
      "step": 18890
    },
    {
      "epoch": 6.890266131972293,
      "grad_norm": 0.0005003443220630288,
      "learning_rate": 6.219467736055415e-06,
      "loss": 0.0154,
      "step": 18900
    },
    {
      "epoch": 6.893911775428363,
      "grad_norm": 0.05317674204707146,
      "learning_rate": 6.212176449143275e-06,
      "loss": 0.0125,
      "step": 18910
    },
    {
      "epoch": 6.897557418884433,
      "grad_norm": 1.4664344787597656,
      "learning_rate": 6.204885162231135e-06,
      "loss": 0.0063,
      "step": 18920
    },
    {
      "epoch": 6.901203062340503,
      "grad_norm": 0.00021560475579462945,
      "learning_rate": 6.197593875318995e-06,
      "loss": 0.0,
      "step": 18930
    },
    {
      "epoch": 6.904848705796573,
      "grad_norm": 0.5075740218162537,
      "learning_rate": 6.190302588406855e-06,
      "loss": 0.0042,
      "step": 18940
    },
    {
      "epoch": 6.908494349252643,
      "grad_norm": 0.002268581185489893,
      "learning_rate": 6.183011301494715e-06,
      "loss": 0.0188,
      "step": 18950
    },
    {
      "epoch": 6.912139992708713,
      "grad_norm": 0.00043712990009225905,
      "learning_rate": 6.175720014582575e-06,
      "loss": 0.0056,
      "step": 18960
    },
    {
      "epoch": 6.915785636164783,
      "grad_norm": 0.0006407627370208502,
      "learning_rate": 6.168428727670435e-06,
      "loss": 0.0023,
      "step": 18970
    },
    {
      "epoch": 6.919431279620853,
      "grad_norm": 0.9131108522415161,
      "learning_rate": 6.161137440758295e-06,
      "loss": 0.0077,
      "step": 18980
    },
    {
      "epoch": 6.923076923076923,
      "grad_norm": 7.719512939453125,
      "learning_rate": 6.153846153846155e-06,
      "loss": 0.0143,
      "step": 18990
    },
    {
      "epoch": 6.926722566532993,
      "grad_norm": 3.082292318344116,
      "learning_rate": 6.146554866934015e-06,
      "loss": 0.0108,
      "step": 19000
    },
    {
      "epoch": 6.930368209989063,
      "grad_norm": 2.519569158554077,
      "learning_rate": 6.139263580021875e-06,
      "loss": 0.0076,
      "step": 19010
    },
    {
      "epoch": 6.934013853445133,
      "grad_norm": 0.00031173904426395893,
      "learning_rate": 6.131972293109735e-06,
      "loss": 0.0093,
      "step": 19020
    },
    {
      "epoch": 6.937659496901203,
      "grad_norm": 0.8350309729576111,
      "learning_rate": 6.124681006197595e-06,
      "loss": 0.022,
      "step": 19030
    },
    {
      "epoch": 6.941305140357273,
      "grad_norm": 0.0007951455772854388,
      "learning_rate": 6.117389719285455e-06,
      "loss": 0.0065,
      "step": 19040
    },
    {
      "epoch": 6.9449507838133435,
      "grad_norm": 0.0010200050892308354,
      "learning_rate": 6.110098432373315e-06,
      "loss": 0.0043,
      "step": 19050
    },
    {
      "epoch": 6.948596427269413,
      "grad_norm": 0.0029054926708340645,
      "learning_rate": 6.102807145461175e-06,
      "loss": 0.0317,
      "step": 19060
    },
    {
      "epoch": 6.952242070725483,
      "grad_norm": 0.0003986205265391618,
      "learning_rate": 6.095515858549035e-06,
      "loss": 0.0114,
      "step": 19070
    },
    {
      "epoch": 6.955887714181553,
      "grad_norm": 0.00037684437120333314,
      "learning_rate": 6.088224571636895e-06,
      "loss": 0.0023,
      "step": 19080
    },
    {
      "epoch": 6.959533357637623,
      "grad_norm": 0.42428117990493774,
      "learning_rate": 6.080933284724755e-06,
      "loss": 0.001,
      "step": 19090
    },
    {
      "epoch": 6.963179001093693,
      "grad_norm": 0.00020750660041812807,
      "learning_rate": 6.073641997812615e-06,
      "loss": 0.0011,
      "step": 19100
    },
    {
      "epoch": 6.966824644549763,
      "grad_norm": 0.005415419116616249,
      "learning_rate": 6.066350710900475e-06,
      "loss": 0.0245,
      "step": 19110
    },
    {
      "epoch": 6.970470288005833,
      "grad_norm": 1.9358454942703247,
      "learning_rate": 6.059059423988335e-06,
      "loss": 0.0013,
      "step": 19120
    },
    {
      "epoch": 6.974115931461903,
      "grad_norm": 7.109623402357101e-05,
      "learning_rate": 6.051768137076195e-06,
      "loss": 0.0317,
      "step": 19130
    },
    {
      "epoch": 6.977761574917973,
      "grad_norm": 0.010225714184343815,
      "learning_rate": 6.044476850164055e-06,
      "loss": 0.0018,
      "step": 19140
    },
    {
      "epoch": 6.981407218374043,
      "grad_norm": 0.35041236877441406,
      "learning_rate": 6.037185563251915e-06,
      "loss": 0.0059,
      "step": 19150
    },
    {
      "epoch": 6.985052861830113,
      "grad_norm": 1.9911479949951172,
      "learning_rate": 6.029894276339775e-06,
      "loss": 0.0254,
      "step": 19160
    },
    {
      "epoch": 6.988698505286183,
      "grad_norm": 0.0003833599912468344,
      "learning_rate": 6.022602989427635e-06,
      "loss": 0.0003,
      "step": 19170
    },
    {
      "epoch": 6.992344148742253,
      "grad_norm": 0.01895904541015625,
      "learning_rate": 6.015311702515495e-06,
      "loss": 0.0049,
      "step": 19180
    },
    {
      "epoch": 6.995989792198323,
      "grad_norm": 2.276275873184204,
      "learning_rate": 6.008020415603355e-06,
      "loss": 0.0158,
      "step": 19190
    },
    {
      "epoch": 6.999635435654393,
      "grad_norm": 0.0011915608774870634,
      "learning_rate": 6.000729128691215e-06,
      "loss": 0.0058,
      "step": 19200
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9912159284497445,
      "eval_f1": 0.9651678277390754,
      "eval_loss": 0.03501836210489273,
      "eval_precision": 0.9548872180451128,
      "eval_recall": 0.9756722151088348,
      "eval_runtime": 865.5392,
      "eval_samples_per_second": 21.737,
      "eval_steps_per_second": 0.679,
      "step": 19201
    },
    {
      "epoch": 7.003281079110463,
      "grad_norm": 0.0008978819823823869,
      "learning_rate": 5.993437841779074e-06,
      "loss": 0.0006,
      "step": 19210
    },
    {
      "epoch": 7.006926722566533,
      "grad_norm": 0.0006588242249563336,
      "learning_rate": 5.986146554866934e-06,
      "loss": 0.0099,
      "step": 19220
    },
    {
      "epoch": 7.010572366022603,
      "grad_norm": 0.33489790558815,
      "learning_rate": 5.978855267954794e-06,
      "loss": 0.0073,
      "step": 19230
    },
    {
      "epoch": 7.014218009478673,
      "grad_norm": 0.04978077858686447,
      "learning_rate": 5.971563981042654e-06,
      "loss": 0.0042,
      "step": 19240
    },
    {
      "epoch": 7.017863652934743,
      "grad_norm": 0.0022035560104995966,
      "learning_rate": 5.964272694130514e-06,
      "loss": 0.0034,
      "step": 19250
    },
    {
      "epoch": 7.021509296390813,
      "grad_norm": 0.00043341954005882144,
      "learning_rate": 5.956981407218374e-06,
      "loss": 0.0119,
      "step": 19260
    },
    {
      "epoch": 7.025154939846883,
      "grad_norm": 0.12202829122543335,
      "learning_rate": 5.949690120306234e-06,
      "loss": 0.0121,
      "step": 19270
    },
    {
      "epoch": 7.028800583302953,
      "grad_norm": 0.0002367631095694378,
      "learning_rate": 5.942398833394094e-06,
      "loss": 0.0159,
      "step": 19280
    },
    {
      "epoch": 7.032446226759023,
      "grad_norm": 0.00019051780691370368,
      "learning_rate": 5.935107546481954e-06,
      "loss": 0.0047,
      "step": 19290
    },
    {
      "epoch": 7.036091870215093,
      "grad_norm": 0.02601747028529644,
      "learning_rate": 5.927816259569814e-06,
      "loss": 0.0018,
      "step": 19300
    },
    {
      "epoch": 7.039737513671163,
      "grad_norm": 0.0013499173801392317,
      "learning_rate": 5.920524972657674e-06,
      "loss": 0.0043,
      "step": 19310
    },
    {
      "epoch": 7.043383157127233,
      "grad_norm": 0.0006283465772867203,
      "learning_rate": 5.913233685745534e-06,
      "loss": 0.0037,
      "step": 19320
    },
    {
      "epoch": 7.047028800583303,
      "grad_norm": 0.6227515935897827,
      "learning_rate": 5.905942398833394e-06,
      "loss": 0.0027,
      "step": 19330
    },
    {
      "epoch": 7.050674444039373,
      "grad_norm": 0.001708534429781139,
      "learning_rate": 5.898651111921254e-06,
      "loss": 0.0002,
      "step": 19340
    },
    {
      "epoch": 7.054320087495443,
      "grad_norm": 0.01888810284435749,
      "learning_rate": 5.891359825009114e-06,
      "loss": 0.0001,
      "step": 19350
    },
    {
      "epoch": 7.057965730951513,
      "grad_norm": 0.8764918446540833,
      "learning_rate": 5.884068538096974e-06,
      "loss": 0.0062,
      "step": 19360
    },
    {
      "epoch": 7.061611374407583,
      "grad_norm": 0.00014346222451422364,
      "learning_rate": 5.876777251184834e-06,
      "loss": 0.0014,
      "step": 19370
    },
    {
      "epoch": 7.065257017863653,
      "grad_norm": 1.1997562646865845,
      "learning_rate": 5.869485964272694e-06,
      "loss": 0.0225,
      "step": 19380
    },
    {
      "epoch": 7.068902661319723,
      "grad_norm": 0.0008641062886454165,
      "learning_rate": 5.8621946773605544e-06,
      "loss": 0.0057,
      "step": 19390
    },
    {
      "epoch": 7.072548304775793,
      "grad_norm": 0.0015913816168904305,
      "learning_rate": 5.8549033904484144e-06,
      "loss": 0.0,
      "step": 19400
    },
    {
      "epoch": 7.076193948231863,
      "grad_norm": 0.004428883083164692,
      "learning_rate": 5.8476121035362744e-06,
      "loss": 0.0002,
      "step": 19410
    },
    {
      "epoch": 7.079839591687933,
      "grad_norm": 0.0006623473600484431,
      "learning_rate": 5.8403208166241345e-06,
      "loss": 0.0,
      "step": 19420
    },
    {
      "epoch": 7.0834852351440025,
      "grad_norm": 0.00023906564456410706,
      "learning_rate": 5.8330295297119945e-06,
      "loss": 0.0155,
      "step": 19430
    },
    {
      "epoch": 7.087130878600073,
      "grad_norm": 1.1984739303588867,
      "learning_rate": 5.8257382427998545e-06,
      "loss": 0.0093,
      "step": 19440
    },
    {
      "epoch": 7.090776522056143,
      "grad_norm": 0.00010081083019031212,
      "learning_rate": 5.8184469558877145e-06,
      "loss": 0.008,
      "step": 19450
    },
    {
      "epoch": 7.094422165512213,
      "grad_norm": 0.0020095573272556067,
      "learning_rate": 5.8111556689755745e-06,
      "loss": 0.018,
      "step": 19460
    },
    {
      "epoch": 7.098067808968283,
      "grad_norm": 1.0277942419052124,
      "learning_rate": 5.8038643820634345e-06,
      "loss": 0.0043,
      "step": 19470
    },
    {
      "epoch": 7.101713452424353,
      "grad_norm": 0.0001632777275517583,
      "learning_rate": 5.7965730951512945e-06,
      "loss": 0.0003,
      "step": 19480
    },
    {
      "epoch": 7.105359095880423,
      "grad_norm": 0.0038768616504967213,
      "learning_rate": 5.7892818082391545e-06,
      "loss": 0.0294,
      "step": 19490
    },
    {
      "epoch": 7.109004739336493,
      "grad_norm": 1.6626298427581787,
      "learning_rate": 5.7819905213270145e-06,
      "loss": 0.0045,
      "step": 19500
    },
    {
      "epoch": 7.1126503827925625,
      "grad_norm": 0.002152903936803341,
      "learning_rate": 5.7746992344148745e-06,
      "loss": 0.0037,
      "step": 19510
    },
    {
      "epoch": 7.116296026248633,
      "grad_norm": 0.004978606011718512,
      "learning_rate": 5.7674079475027346e-06,
      "loss": 0.0189,
      "step": 19520
    },
    {
      "epoch": 7.119941669704703,
      "grad_norm": 0.00018359854584559798,
      "learning_rate": 5.7601166605905946e-06,
      "loss": 0.0012,
      "step": 19530
    },
    {
      "epoch": 7.1235873131607725,
      "grad_norm": 0.0003517385048326105,
      "learning_rate": 5.752825373678455e-06,
      "loss": 0.0018,
      "step": 19540
    },
    {
      "epoch": 7.127232956616843,
      "grad_norm": 0.0003288922889623791,
      "learning_rate": 5.745534086766315e-06,
      "loss": 0.0003,
      "step": 19550
    },
    {
      "epoch": 7.130878600072913,
      "grad_norm": 0.0002900406252592802,
      "learning_rate": 5.738242799854175e-06,
      "loss": 0.0119,
      "step": 19560
    },
    {
      "epoch": 7.134524243528983,
      "grad_norm": 1.380921721458435,
      "learning_rate": 5.730951512942035e-06,
      "loss": 0.0049,
      "step": 19570
    },
    {
      "epoch": 7.138169886985053,
      "grad_norm": 0.00047051795991137624,
      "learning_rate": 5.723660226029895e-06,
      "loss": 0.0376,
      "step": 19580
    },
    {
      "epoch": 7.141815530441123,
      "grad_norm": 0.0018830805784091353,
      "learning_rate": 5.716368939117755e-06,
      "loss": 0.0033,
      "step": 19590
    },
    {
      "epoch": 7.145461173897193,
      "grad_norm": 0.00023590757336933166,
      "learning_rate": 5.709077652205615e-06,
      "loss": 0.0009,
      "step": 19600
    },
    {
      "epoch": 7.149106817353263,
      "grad_norm": 0.000418563315179199,
      "learning_rate": 5.701786365293475e-06,
      "loss": 0.0219,
      "step": 19610
    },
    {
      "epoch": 7.1527524608093325,
      "grad_norm": 0.001274323440156877,
      "learning_rate": 5.694495078381335e-06,
      "loss": 0.0023,
      "step": 19620
    },
    {
      "epoch": 7.156398104265403,
      "grad_norm": 0.0003061441530007869,
      "learning_rate": 5.687203791469195e-06,
      "loss": 0.0311,
      "step": 19630
    },
    {
      "epoch": 7.160043747721473,
      "grad_norm": 0.001908760634250939,
      "learning_rate": 5.679912504557055e-06,
      "loss": 0.0211,
      "step": 19640
    },
    {
      "epoch": 7.1636893911775426,
      "grad_norm": 0.0007883314392529428,
      "learning_rate": 5.672621217644915e-06,
      "loss": 0.002,
      "step": 19650
    },
    {
      "epoch": 7.167335034633613,
      "grad_norm": 0.0016629253514111042,
      "learning_rate": 5.665329930732775e-06,
      "loss": 0.0051,
      "step": 19660
    },
    {
      "epoch": 7.170980678089683,
      "grad_norm": 0.6103417277336121,
      "learning_rate": 5.658038643820635e-06,
      "loss": 0.0062,
      "step": 19670
    },
    {
      "epoch": 7.174626321545753,
      "grad_norm": 0.0008071918273344636,
      "learning_rate": 5.650747356908495e-06,
      "loss": 0.0235,
      "step": 19680
    },
    {
      "epoch": 7.178271965001823,
      "grad_norm": 0.0019912070129066706,
      "learning_rate": 5.643456069996355e-06,
      "loss": 0.0006,
      "step": 19690
    },
    {
      "epoch": 7.181917608457892,
      "grad_norm": 0.04277202486991882,
      "learning_rate": 5.636164783084215e-06,
      "loss": 0.0014,
      "step": 19700
    },
    {
      "epoch": 7.185563251913963,
      "grad_norm": 0.0034882717300206423,
      "learning_rate": 5.628873496172075e-06,
      "loss": 0.0,
      "step": 19710
    },
    {
      "epoch": 7.189208895370033,
      "grad_norm": 0.01073683425784111,
      "learning_rate": 5.621582209259935e-06,
      "loss": 0.0,
      "step": 19720
    },
    {
      "epoch": 7.1928545388261025,
      "grad_norm": 0.0008881372632458806,
      "learning_rate": 5.614290922347795e-06,
      "loss": 0.0012,
      "step": 19730
    },
    {
      "epoch": 7.196500182282173,
      "grad_norm": 0.0027199184987694025,
      "learning_rate": 5.606999635435655e-06,
      "loss": 0.0001,
      "step": 19740
    },
    {
      "epoch": 7.200145825738243,
      "grad_norm": 0.0013605126878246665,
      "learning_rate": 5.599708348523515e-06,
      "loss": 0.0027,
      "step": 19750
    },
    {
      "epoch": 7.203791469194313,
      "grad_norm": 0.061982162296772,
      "learning_rate": 5.592417061611375e-06,
      "loss": 0.0053,
      "step": 19760
    },
    {
      "epoch": 7.207437112650383,
      "grad_norm": 0.0050622643902897835,
      "learning_rate": 5.585125774699235e-06,
      "loss": 0.0045,
      "step": 19770
    },
    {
      "epoch": 7.211082756106453,
      "grad_norm": 0.00041601737029850483,
      "learning_rate": 5.577834487787095e-06,
      "loss": 0.0023,
      "step": 19780
    },
    {
      "epoch": 7.214728399562523,
      "grad_norm": 1.1241816282272339,
      "learning_rate": 5.570543200874955e-06,
      "loss": 0.007,
      "step": 19790
    },
    {
      "epoch": 7.218374043018593,
      "grad_norm": 0.020173627883195877,
      "learning_rate": 5.563251913962815e-06,
      "loss": 0.0239,
      "step": 19800
    },
    {
      "epoch": 7.222019686474662,
      "grad_norm": 0.0007422799244523048,
      "learning_rate": 5.555960627050675e-06,
      "loss": 0.0092,
      "step": 19810
    },
    {
      "epoch": 7.225665329930733,
      "grad_norm": 1.2710518836975098,
      "learning_rate": 5.548669340138535e-06,
      "loss": 0.0049,
      "step": 19820
    },
    {
      "epoch": 7.229310973386803,
      "grad_norm": 0.0004509417631197721,
      "learning_rate": 5.541378053226395e-06,
      "loss": 0.0025,
      "step": 19830
    },
    {
      "epoch": 7.2329566168428725,
      "grad_norm": 0.02805958315730095,
      "learning_rate": 5.534086766314255e-06,
      "loss": 0.0224,
      "step": 19840
    },
    {
      "epoch": 7.236602260298943,
      "grad_norm": 0.00040992905269376934,
      "learning_rate": 5.526795479402115e-06,
      "loss": 0.0031,
      "step": 19850
    },
    {
      "epoch": 7.240247903755013,
      "grad_norm": 0.001014271634630859,
      "learning_rate": 5.519504192489975e-06,
      "loss": 0.0025,
      "step": 19860
    },
    {
      "epoch": 7.243893547211083,
      "grad_norm": 0.00024406811280641705,
      "learning_rate": 5.512212905577835e-06,
      "loss": 0.005,
      "step": 19870
    },
    {
      "epoch": 7.247539190667153,
      "grad_norm": 0.0003178252372890711,
      "learning_rate": 5.504921618665695e-06,
      "loss": 0.0001,
      "step": 19880
    },
    {
      "epoch": 7.251184834123222,
      "grad_norm": 1.3184419870376587,
      "learning_rate": 5.497630331753555e-06,
      "loss": 0.0068,
      "step": 19890
    },
    {
      "epoch": 7.254830477579293,
      "grad_norm": 0.0017545672599226236,
      "learning_rate": 5.490339044841415e-06,
      "loss": 0.0183,
      "step": 19900
    },
    {
      "epoch": 7.258476121035363,
      "grad_norm": 0.0018069554353132844,
      "learning_rate": 5.483047757929275e-06,
      "loss": 0.0144,
      "step": 19910
    },
    {
      "epoch": 7.262121764491432,
      "grad_norm": 0.0009050178923644125,
      "learning_rate": 5.475756471017135e-06,
      "loss": 0.0057,
      "step": 19920
    },
    {
      "epoch": 7.265767407947503,
      "grad_norm": 1.000859260559082,
      "learning_rate": 5.468465184104995e-06,
      "loss": 0.0042,
      "step": 19930
    },
    {
      "epoch": 7.269413051403573,
      "grad_norm": 0.06811229139566422,
      "learning_rate": 5.461173897192855e-06,
      "loss": 0.0172,
      "step": 19940
    },
    {
      "epoch": 7.2730586948596425,
      "grad_norm": 0.0768565684556961,
      "learning_rate": 5.453882610280715e-06,
      "loss": 0.0029,
      "step": 19950
    },
    {
      "epoch": 7.276704338315713,
      "grad_norm": 5.886168956756592,
      "learning_rate": 5.446591323368575e-06,
      "loss": 0.019,
      "step": 19960
    },
    {
      "epoch": 7.280349981771783,
      "grad_norm": 0.8062627911567688,
      "learning_rate": 5.439300036456435e-06,
      "loss": 0.0076,
      "step": 19970
    },
    {
      "epoch": 7.283995625227853,
      "grad_norm": 1.5800211429595947,
      "learning_rate": 5.432008749544295e-06,
      "loss": 0.0053,
      "step": 19980
    },
    {
      "epoch": 7.287641268683923,
      "grad_norm": 1.8404932022094727,
      "learning_rate": 5.424717462632155e-06,
      "loss": 0.0238,
      "step": 19990
    },
    {
      "epoch": 7.291286912139992,
      "grad_norm": 0.0026417910121381283,
      "learning_rate": 5.417426175720015e-06,
      "loss": 0.0162,
      "step": 20000
    },
    {
      "epoch": 7.294932555596063,
      "grad_norm": 1.7645846605300903,
      "learning_rate": 5.410134888807875e-06,
      "loss": 0.024,
      "step": 20010
    },
    {
      "epoch": 7.298578199052133,
      "grad_norm": 0.0013620515819638968,
      "learning_rate": 5.402843601895735e-06,
      "loss": 0.0048,
      "step": 20020
    },
    {
      "epoch": 7.3022238425082024,
      "grad_norm": 0.8140173554420471,
      "learning_rate": 5.395552314983595e-06,
      "loss": 0.0015,
      "step": 20030
    },
    {
      "epoch": 7.305869485964273,
      "grad_norm": 0.0009573490242473781,
      "learning_rate": 5.388261028071455e-06,
      "loss": 0.0024,
      "step": 20040
    },
    {
      "epoch": 7.309515129420343,
      "grad_norm": 0.0007209026371128857,
      "learning_rate": 5.380969741159315e-06,
      "loss": 0.0121,
      "step": 20050
    },
    {
      "epoch": 7.3131607728764125,
      "grad_norm": 0.0013597648357972503,
      "learning_rate": 5.373678454247175e-06,
      "loss": 0.0003,
      "step": 20060
    },
    {
      "epoch": 7.316806416332483,
      "grad_norm": 0.17892888188362122,
      "learning_rate": 5.366387167335035e-06,
      "loss": 0.0097,
      "step": 20070
    },
    {
      "epoch": 7.320452059788552,
      "grad_norm": 0.015323194675147533,
      "learning_rate": 5.359095880422895e-06,
      "loss": 0.0028,
      "step": 20080
    },
    {
      "epoch": 7.324097703244623,
      "grad_norm": 0.0002755702007561922,
      "learning_rate": 5.351804593510755e-06,
      "loss": 0.0039,
      "step": 20090
    },
    {
      "epoch": 7.327743346700693,
      "grad_norm": 0.0011897750664502382,
      "learning_rate": 5.344513306598615e-06,
      "loss": 0.0044,
      "step": 20100
    },
    {
      "epoch": 7.331388990156762,
      "grad_norm": 0.005407858639955521,
      "learning_rate": 5.337222019686475e-06,
      "loss": 0.0,
      "step": 20110
    },
    {
      "epoch": 7.335034633612833,
      "grad_norm": 0.00037867529317736626,
      "learning_rate": 5.329930732774335e-06,
      "loss": 0.0077,
      "step": 20120
    },
    {
      "epoch": 7.338680277068903,
      "grad_norm": 0.0003395950479898602,
      "learning_rate": 5.322639445862195e-06,
      "loss": 0.0081,
      "step": 20130
    },
    {
      "epoch": 7.3423259205249725,
      "grad_norm": 0.0004301006847526878,
      "learning_rate": 5.315348158950055e-06,
      "loss": 0.0002,
      "step": 20140
    },
    {
      "epoch": 7.345971563981043,
      "grad_norm": 0.697009801864624,
      "learning_rate": 5.308056872037915e-06,
      "loss": 0.0035,
      "step": 20150
    },
    {
      "epoch": 7.349617207437113,
      "grad_norm": 0.0005226635839790106,
      "learning_rate": 5.300765585125775e-06,
      "loss": 0.014,
      "step": 20160
    },
    {
      "epoch": 7.3532628508931825,
      "grad_norm": 1.3053159713745117,
      "learning_rate": 5.293474298213635e-06,
      "loss": 0.004,
      "step": 20170
    },
    {
      "epoch": 7.356908494349253,
      "grad_norm": 0.001281057484447956,
      "learning_rate": 5.286183011301495e-06,
      "loss": 0.0228,
      "step": 20180
    },
    {
      "epoch": 7.360554137805322,
      "grad_norm": 0.0009916130220517516,
      "learning_rate": 5.278891724389355e-06,
      "loss": 0.0119,
      "step": 20190
    },
    {
      "epoch": 7.364199781261393,
      "grad_norm": 0.20394271612167358,
      "learning_rate": 5.271600437477215e-06,
      "loss": 0.0066,
      "step": 20200
    },
    {
      "epoch": 7.367845424717463,
      "grad_norm": 0.0023480169475078583,
      "learning_rate": 5.264309150565075e-06,
      "loss": 0.0049,
      "step": 20210
    },
    {
      "epoch": 7.371491068173532,
      "grad_norm": 0.6854129433631897,
      "learning_rate": 5.257017863652935e-06,
      "loss": 0.0089,
      "step": 20220
    },
    {
      "epoch": 7.375136711629603,
      "grad_norm": 0.001648197416216135,
      "learning_rate": 5.249726576740795e-06,
      "loss": 0.0031,
      "step": 20230
    },
    {
      "epoch": 7.378782355085672,
      "grad_norm": 0.00115382659714669,
      "learning_rate": 5.242435289828655e-06,
      "loss": 0.0073,
      "step": 20240
    },
    {
      "epoch": 7.3824279985417425,
      "grad_norm": 0.0032065820414572954,
      "learning_rate": 5.235144002916515e-06,
      "loss": 0.0098,
      "step": 20250
    },
    {
      "epoch": 7.386073641997813,
      "grad_norm": 0.0006391130154952407,
      "learning_rate": 5.227852716004375e-06,
      "loss": 0.0,
      "step": 20260
    },
    {
      "epoch": 7.389719285453882,
      "grad_norm": 0.00036497635301202536,
      "learning_rate": 5.220561429092235e-06,
      "loss": 0.0037,
      "step": 20270
    },
    {
      "epoch": 7.393364928909953,
      "grad_norm": 1.5520398616790771,
      "learning_rate": 5.213270142180096e-06,
      "loss": 0.0053,
      "step": 20280
    },
    {
      "epoch": 7.397010572366023,
      "grad_norm": 0.001351020997390151,
      "learning_rate": 5.205978855267956e-06,
      "loss": 0.0006,
      "step": 20290
    },
    {
      "epoch": 7.400656215822092,
      "grad_norm": 0.003916012588888407,
      "learning_rate": 5.1986875683558145e-06,
      "loss": 0.0279,
      "step": 20300
    },
    {
      "epoch": 7.404301859278163,
      "grad_norm": 0.004896032623946667,
      "learning_rate": 5.1913962814436745e-06,
      "loss": 0.0156,
      "step": 20310
    },
    {
      "epoch": 7.407947502734233,
      "grad_norm": 0.005246895365417004,
      "learning_rate": 5.1841049945315345e-06,
      "loss": 0.0115,
      "step": 20320
    },
    {
      "epoch": 7.411593146190302,
      "grad_norm": 0.0025314602535218,
      "learning_rate": 5.1768137076193945e-06,
      "loss": 0.0015,
      "step": 20330
    },
    {
      "epoch": 7.415238789646373,
      "grad_norm": 0.0019394132541492581,
      "learning_rate": 5.1695224207072545e-06,
      "loss": 0.0064,
      "step": 20340
    },
    {
      "epoch": 7.418884433102442,
      "grad_norm": 0.000258020096225664,
      "learning_rate": 5.1622311337951145e-06,
      "loss": 0.0002,
      "step": 20350
    },
    {
      "epoch": 7.4225300765585125,
      "grad_norm": 0.00016489610425196588,
      "learning_rate": 5.1549398468829746e-06,
      "loss": 0.0095,
      "step": 20360
    },
    {
      "epoch": 7.426175720014583,
      "grad_norm": 0.09454087913036346,
      "learning_rate": 5.1476485599708346e-06,
      "loss": 0.0002,
      "step": 20370
    },
    {
      "epoch": 7.429821363470652,
      "grad_norm": 0.0004089701105840504,
      "learning_rate": 5.140357273058695e-06,
      "loss": 0.0041,
      "step": 20380
    },
    {
      "epoch": 7.433467006926723,
      "grad_norm": 0.0006123633938841522,
      "learning_rate": 5.133065986146555e-06,
      "loss": 0.0051,
      "step": 20390
    },
    {
      "epoch": 7.437112650382793,
      "grad_norm": 1.5323920249938965,
      "learning_rate": 5.125774699234415e-06,
      "loss": 0.0086,
      "step": 20400
    },
    {
      "epoch": 7.440758293838862,
      "grad_norm": 1.70980703830719,
      "learning_rate": 5.118483412322275e-06,
      "loss": 0.0072,
      "step": 20410
    },
    {
      "epoch": 7.444403937294933,
      "grad_norm": 0.0006965714273974299,
      "learning_rate": 5.111192125410135e-06,
      "loss": 0.0058,
      "step": 20420
    },
    {
      "epoch": 7.448049580751002,
      "grad_norm": 0.03951828181743622,
      "learning_rate": 5.103900838497995e-06,
      "loss": 0.0052,
      "step": 20430
    },
    {
      "epoch": 7.451695224207072,
      "grad_norm": 0.00020749364921357483,
      "learning_rate": 5.096609551585855e-06,
      "loss": 0.0026,
      "step": 20440
    },
    {
      "epoch": 7.455340867663143,
      "grad_norm": 0.00033754963078536093,
      "learning_rate": 5.089318264673715e-06,
      "loss": 0.0188,
      "step": 20450
    },
    {
      "epoch": 7.458986511119212,
      "grad_norm": 0.003360343398526311,
      "learning_rate": 5.082026977761575e-06,
      "loss": 0.0,
      "step": 20460
    },
    {
      "epoch": 7.4626321545752825,
      "grad_norm": 0.00046050353557802737,
      "learning_rate": 5.074735690849435e-06,
      "loss": 0.001,
      "step": 20470
    },
    {
      "epoch": 7.466277798031353,
      "grad_norm": 0.0002468565944582224,
      "learning_rate": 5.067444403937295e-06,
      "loss": 0.0055,
      "step": 20480
    },
    {
      "epoch": 7.469923441487422,
      "grad_norm": 0.0010539564536884427,
      "learning_rate": 5.060153117025155e-06,
      "loss": 0.0002,
      "step": 20490
    },
    {
      "epoch": 7.473569084943493,
      "grad_norm": 0.0016873617423698306,
      "learning_rate": 5.052861830113015e-06,
      "loss": 0.0111,
      "step": 20500
    },
    {
      "epoch": 7.477214728399563,
      "grad_norm": 0.4462260901927948,
      "learning_rate": 5.045570543200875e-06,
      "loss": 0.0156,
      "step": 20510
    },
    {
      "epoch": 7.480860371855632,
      "grad_norm": 0.0014242761535570025,
      "learning_rate": 5.038279256288735e-06,
      "loss": 0.0055,
      "step": 20520
    },
    {
      "epoch": 7.484506015311703,
      "grad_norm": 0.0007783359615132213,
      "learning_rate": 5.030987969376595e-06,
      "loss": 0.0056,
      "step": 20530
    },
    {
      "epoch": 7.488151658767772,
      "grad_norm": 0.024355828762054443,
      "learning_rate": 5.023696682464455e-06,
      "loss": 0.0057,
      "step": 20540
    },
    {
      "epoch": 7.491797302223842,
      "grad_norm": 0.0006655976758338511,
      "learning_rate": 5.016405395552315e-06,
      "loss": 0.0084,
      "step": 20550
    },
    {
      "epoch": 7.495442945679913,
      "grad_norm": 0.513696014881134,
      "learning_rate": 5.009114108640175e-06,
      "loss": 0.0069,
      "step": 20560
    },
    {
      "epoch": 7.499088589135982,
      "grad_norm": 0.018589433282613754,
      "learning_rate": 5.001822821728035e-06,
      "loss": 0.0112,
      "step": 20570
    },
    {
      "epoch": 7.5027342325920525,
      "grad_norm": 1.2938196659088135,
      "learning_rate": 4.994531534815895e-06,
      "loss": 0.018,
      "step": 20580
    },
    {
      "epoch": 7.506379876048123,
      "grad_norm": 0.0014244873309507966,
      "learning_rate": 4.987240247903755e-06,
      "loss": 0.0,
      "step": 20590
    },
    {
      "epoch": 7.510025519504192,
      "grad_norm": 0.0002342360676266253,
      "learning_rate": 4.979948960991615e-06,
      "loss": 0.0001,
      "step": 20600
    },
    {
      "epoch": 7.513671162960263,
      "grad_norm": 0.0004940399085171521,
      "learning_rate": 4.972657674079475e-06,
      "loss": 0.0112,
      "step": 20610
    },
    {
      "epoch": 7.517316806416332,
      "grad_norm": 0.0004467106191441417,
      "learning_rate": 4.965366387167335e-06,
      "loss": 0.0,
      "step": 20620
    },
    {
      "epoch": 7.520962449872402,
      "grad_norm": 0.001468937611207366,
      "learning_rate": 4.958075100255195e-06,
      "loss": 0.0059,
      "step": 20630
    },
    {
      "epoch": 7.524608093328473,
      "grad_norm": 0.006584867835044861,
      "learning_rate": 4.950783813343055e-06,
      "loss": 0.0021,
      "step": 20640
    },
    {
      "epoch": 7.528253736784542,
      "grad_norm": 0.0004192667256575078,
      "learning_rate": 4.943492526430915e-06,
      "loss": 0.0032,
      "step": 20650
    },
    {
      "epoch": 7.5318993802406125,
      "grad_norm": 0.00030054125818423927,
      "learning_rate": 4.936201239518775e-06,
      "loss": 0.0061,
      "step": 20660
    },
    {
      "epoch": 7.535545023696683,
      "grad_norm": 4.231485843658447,
      "learning_rate": 4.928909952606635e-06,
      "loss": 0.0131,
      "step": 20670
    },
    {
      "epoch": 7.539190667152752,
      "grad_norm": 0.0002860531967598945,
      "learning_rate": 4.921618665694496e-06,
      "loss": 0.0005,
      "step": 20680
    },
    {
      "epoch": 7.5428363106088225,
      "grad_norm": 0.0008886581636033952,
      "learning_rate": 4.914327378782356e-06,
      "loss": 0.0102,
      "step": 20690
    },
    {
      "epoch": 7.546481954064893,
      "grad_norm": 1.5648995637893677,
      "learning_rate": 4.907036091870216e-06,
      "loss": 0.0034,
      "step": 20700
    },
    {
      "epoch": 7.550127597520962,
      "grad_norm": 0.0001299123396165669,
      "learning_rate": 4.899744804958076e-06,
      "loss": 0.0043,
      "step": 20710
    },
    {
      "epoch": 7.553773240977033,
      "grad_norm": 0.0002594601537566632,
      "learning_rate": 4.892453518045936e-06,
      "loss": 0.0034,
      "step": 20720
    },
    {
      "epoch": 7.557418884433102,
      "grad_norm": 6.360704719554633e-05,
      "learning_rate": 4.885162231133796e-06,
      "loss": 0.0016,
      "step": 20730
    },
    {
      "epoch": 7.561064527889172,
      "grad_norm": 5.575783143285662e-05,
      "learning_rate": 4.877870944221656e-06,
      "loss": 0.0071,
      "step": 20740
    },
    {
      "epoch": 7.564710171345243,
      "grad_norm": 0.0001371863909298554,
      "learning_rate": 4.870579657309516e-06,
      "loss": 0.0059,
      "step": 20750
    },
    {
      "epoch": 7.568355814801312,
      "grad_norm": 3.008826494216919,
      "learning_rate": 4.863288370397376e-06,
      "loss": 0.0103,
      "step": 20760
    },
    {
      "epoch": 7.5720014582573825,
      "grad_norm": 0.8001635670661926,
      "learning_rate": 4.855997083485236e-06,
      "loss": 0.0129,
      "step": 20770
    },
    {
      "epoch": 7.575647101713453,
      "grad_norm": 0.00013094049063511193,
      "learning_rate": 4.848705796573096e-06,
      "loss": 0.0095,
      "step": 20780
    },
    {
      "epoch": 7.579292745169522,
      "grad_norm": 0.0055043334141373634,
      "learning_rate": 4.841414509660956e-06,
      "loss": 0.0052,
      "step": 20790
    },
    {
      "epoch": 7.5829383886255926,
      "grad_norm": 0.0006620031781494617,
      "learning_rate": 4.834123222748816e-06,
      "loss": 0.0162,
      "step": 20800
    },
    {
      "epoch": 7.586584032081662,
      "grad_norm": 2.2481746673583984,
      "learning_rate": 4.826831935836676e-06,
      "loss": 0.0071,
      "step": 20810
    },
    {
      "epoch": 7.590229675537732,
      "grad_norm": 0.0012168694520369172,
      "learning_rate": 4.819540648924536e-06,
      "loss": 0.0035,
      "step": 20820
    },
    {
      "epoch": 7.593875318993803,
      "grad_norm": 0.00016196537762880325,
      "learning_rate": 4.812249362012396e-06,
      "loss": 0.0118,
      "step": 20830
    },
    {
      "epoch": 7.597520962449872,
      "grad_norm": 3.2977678775787354,
      "learning_rate": 4.804958075100256e-06,
      "loss": 0.0199,
      "step": 20840
    },
    {
      "epoch": 7.601166605905942,
      "grad_norm": 0.00010635473154252395,
      "learning_rate": 4.797666788188116e-06,
      "loss": 0.0005,
      "step": 20850
    },
    {
      "epoch": 7.604812249362013,
      "grad_norm": 0.00040161306969821453,
      "learning_rate": 4.790375501275976e-06,
      "loss": 0.0003,
      "step": 20860
    },
    {
      "epoch": 7.608457892818082,
      "grad_norm": 0.003334709908813238,
      "learning_rate": 4.783084214363836e-06,
      "loss": 0.0021,
      "step": 20870
    },
    {
      "epoch": 7.6121035362741525,
      "grad_norm": 0.13274306058883667,
      "learning_rate": 4.775792927451696e-06,
      "loss": 0.009,
      "step": 20880
    },
    {
      "epoch": 7.615749179730223,
      "grad_norm": 1.4216278791427612,
      "learning_rate": 4.768501640539556e-06,
      "loss": 0.0366,
      "step": 20890
    },
    {
      "epoch": 7.619394823186292,
      "grad_norm": 0.00013517348270397633,
      "learning_rate": 4.761210353627416e-06,
      "loss": 0.0348,
      "step": 20900
    },
    {
      "epoch": 7.623040466642363,
      "grad_norm": 0.00014589920465368778,
      "learning_rate": 4.753919066715276e-06,
      "loss": 0.0068,
      "step": 20910
    },
    {
      "epoch": 7.626686110098432,
      "grad_norm": 0.000624459411483258,
      "learning_rate": 4.746627779803136e-06,
      "loss": 0.0027,
      "step": 20920
    },
    {
      "epoch": 7.630331753554502,
      "grad_norm": 0.005199833307415247,
      "learning_rate": 4.739336492890996e-06,
      "loss": 0.0062,
      "step": 20930
    },
    {
      "epoch": 7.633977397010573,
      "grad_norm": 0.0002613361575640738,
      "learning_rate": 4.732045205978856e-06,
      "loss": 0.0002,
      "step": 20940
    },
    {
      "epoch": 7.637623040466642,
      "grad_norm": 0.0002647578075993806,
      "learning_rate": 4.724753919066716e-06,
      "loss": 0.0105,
      "step": 20950
    },
    {
      "epoch": 7.641268683922712,
      "grad_norm": 0.0002763178781606257,
      "learning_rate": 4.717462632154576e-06,
      "loss": 0.0034,
      "step": 20960
    },
    {
      "epoch": 7.644914327378783,
      "grad_norm": 0.003837121883407235,
      "learning_rate": 4.710171345242436e-06,
      "loss": 0.0072,
      "step": 20970
    },
    {
      "epoch": 7.648559970834852,
      "grad_norm": 0.0002857148938346654,
      "learning_rate": 4.702880058330296e-06,
      "loss": 0.007,
      "step": 20980
    },
    {
      "epoch": 7.6522056142909225,
      "grad_norm": 0.00045214331476017833,
      "learning_rate": 4.695588771418156e-06,
      "loss": 0.0,
      "step": 20990
    },
    {
      "epoch": 7.655851257746992,
      "grad_norm": 0.00023260684974957258,
      "learning_rate": 4.688297484506016e-06,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 7.659496901203062,
      "grad_norm": 0.0007438502507284284,
      "learning_rate": 4.681006197593876e-06,
      "loss": 0.0015,
      "step": 21010
    },
    {
      "epoch": 7.663142544659133,
      "grad_norm": 1.4060859680175781,
      "learning_rate": 4.673714910681736e-06,
      "loss": 0.0106,
      "step": 21020
    },
    {
      "epoch": 7.666788188115202,
      "grad_norm": 0.0002447104488965124,
      "learning_rate": 4.666423623769596e-06,
      "loss": 0.0042,
      "step": 21030
    },
    {
      "epoch": 7.670433831571272,
      "grad_norm": 0.00027842025156132877,
      "learning_rate": 4.659132336857456e-06,
      "loss": 0.0151,
      "step": 21040
    },
    {
      "epoch": 7.674079475027343,
      "grad_norm": 0.19273416697978973,
      "learning_rate": 4.651841049945316e-06,
      "loss": 0.0013,
      "step": 21050
    },
    {
      "epoch": 7.677725118483412,
      "grad_norm": 0.9788873791694641,
      "learning_rate": 4.644549763033176e-06,
      "loss": 0.0075,
      "step": 21060
    },
    {
      "epoch": 7.681370761939482,
      "grad_norm": 0.00011921010445803404,
      "learning_rate": 4.637258476121036e-06,
      "loss": 0.002,
      "step": 21070
    },
    {
      "epoch": 7.685016405395553,
      "grad_norm": 0.0012022634036839008,
      "learning_rate": 4.629967189208896e-06,
      "loss": 0.0065,
      "step": 21080
    },
    {
      "epoch": 7.688662048851622,
      "grad_norm": 0.00713817635551095,
      "learning_rate": 4.622675902296756e-06,
      "loss": 0.0154,
      "step": 21090
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 0.00011090301995864138,
      "learning_rate": 4.615384615384616e-06,
      "loss": 0.0043,
      "step": 21100
    },
    {
      "epoch": 7.695953335763762,
      "grad_norm": 0.00037708322633989155,
      "learning_rate": 4.608093328472476e-06,
      "loss": 0.0033,
      "step": 21110
    },
    {
      "epoch": 7.699598979219832,
      "grad_norm": 0.235111266374588,
      "learning_rate": 4.600802041560336e-06,
      "loss": 0.0025,
      "step": 21120
    },
    {
      "epoch": 7.703244622675903,
      "grad_norm": 0.0363151840865612,
      "learning_rate": 4.593510754648195e-06,
      "loss": 0.0009,
      "step": 21130
    },
    {
      "epoch": 7.706890266131972,
      "grad_norm": 0.0003593635919969529,
      "learning_rate": 4.586219467736055e-06,
      "loss": 0.0035,
      "step": 21140
    },
    {
      "epoch": 7.710535909588042,
      "grad_norm": 2.1616556644439697,
      "learning_rate": 4.578928180823915e-06,
      "loss": 0.0203,
      "step": 21150
    },
    {
      "epoch": 7.714181553044112,
      "grad_norm": 0.0003336339141242206,
      "learning_rate": 4.571636893911775e-06,
      "loss": 0.0,
      "step": 21160
    },
    {
      "epoch": 7.717827196500182,
      "grad_norm": 2.1598620414733887,
      "learning_rate": 4.564345606999635e-06,
      "loss": 0.0109,
      "step": 21170
    },
    {
      "epoch": 7.721472839956252,
      "grad_norm": 4.619071960449219,
      "learning_rate": 4.557054320087495e-06,
      "loss": 0.0304,
      "step": 21180
    },
    {
      "epoch": 7.725118483412322,
      "grad_norm": 0.0004736841656267643,
      "learning_rate": 4.549763033175355e-06,
      "loss": 0.0331,
      "step": 21190
    },
    {
      "epoch": 7.728764126868392,
      "grad_norm": 0.17860443890094757,
      "learning_rate": 4.542471746263215e-06,
      "loss": 0.0097,
      "step": 21200
    },
    {
      "epoch": 7.7324097703244625,
      "grad_norm": 0.005473419092595577,
      "learning_rate": 4.535180459351075e-06,
      "loss": 0.0194,
      "step": 21210
    },
    {
      "epoch": 7.736055413780532,
      "grad_norm": 0.0013047745451331139,
      "learning_rate": 4.5278891724389354e-06,
      "loss": 0.0278,
      "step": 21220
    },
    {
      "epoch": 7.739701057236602,
      "grad_norm": 0.09669771790504456,
      "learning_rate": 4.5205978855267954e-06,
      "loss": 0.0009,
      "step": 21230
    },
    {
      "epoch": 7.743346700692673,
      "grad_norm": 1.360617756843567,
      "learning_rate": 4.5133065986146554e-06,
      "loss": 0.0109,
      "step": 21240
    },
    {
      "epoch": 7.746992344148742,
      "grad_norm": 0.001355016604065895,
      "learning_rate": 4.5060153117025155e-06,
      "loss": 0.0143,
      "step": 21250
    },
    {
      "epoch": 7.750637987604812,
      "grad_norm": 0.15112248063087463,
      "learning_rate": 4.4987240247903755e-06,
      "loss": 0.0016,
      "step": 21260
    },
    {
      "epoch": 7.754283631060883,
      "grad_norm": 0.12143757194280624,
      "learning_rate": 4.4914327378782355e-06,
      "loss": 0.0001,
      "step": 21270
    },
    {
      "epoch": 7.757929274516952,
      "grad_norm": 0.0010428940877318382,
      "learning_rate": 4.4841414509660955e-06,
      "loss": 0.0288,
      "step": 21280
    },
    {
      "epoch": 7.7615749179730225,
      "grad_norm": 0.0040929121896624565,
      "learning_rate": 4.4768501640539555e-06,
      "loss": 0.0088,
      "step": 21290
    },
    {
      "epoch": 7.765220561429092,
      "grad_norm": 0.0004394010757096112,
      "learning_rate": 4.4695588771418155e-06,
      "loss": 0.0072,
      "step": 21300
    },
    {
      "epoch": 7.768866204885162,
      "grad_norm": 0.006502398289740086,
      "learning_rate": 4.4622675902296755e-06,
      "loss": 0.0,
      "step": 21310
    },
    {
      "epoch": 7.7725118483412325,
      "grad_norm": 0.016953499987721443,
      "learning_rate": 4.4549763033175355e-06,
      "loss": 0.0027,
      "step": 21320
    },
    {
      "epoch": 7.776157491797302,
      "grad_norm": 0.5682741403579712,
      "learning_rate": 4.4476850164053955e-06,
      "loss": 0.0133,
      "step": 21330
    },
    {
      "epoch": 7.779803135253372,
      "grad_norm": 1.7352964878082275,
      "learning_rate": 4.4403937294932555e-06,
      "loss": 0.0211,
      "step": 21340
    },
    {
      "epoch": 7.783448778709442,
      "grad_norm": 0.003950473852455616,
      "learning_rate": 4.4331024425811156e-06,
      "loss": 0.0023,
      "step": 21350
    },
    {
      "epoch": 7.787094422165512,
      "grad_norm": 1.2001044750213623,
      "learning_rate": 4.4258111556689756e-06,
      "loss": 0.0264,
      "step": 21360
    },
    {
      "epoch": 7.790740065621582,
      "grad_norm": 0.0009294410119764507,
      "learning_rate": 4.418519868756836e-06,
      "loss": 0.0048,
      "step": 21370
    },
    {
      "epoch": 7.794385709077652,
      "grad_norm": 0.5419737100601196,
      "learning_rate": 4.411228581844696e-06,
      "loss": 0.0024,
      "step": 21380
    },
    {
      "epoch": 7.798031352533722,
      "grad_norm": 0.023397544398903847,
      "learning_rate": 4.403937294932556e-06,
      "loss": 0.0142,
      "step": 21390
    },
    {
      "epoch": 7.8016769959897925,
      "grad_norm": 0.5749387145042419,
      "learning_rate": 4.396646008020416e-06,
      "loss": 0.0094,
      "step": 21400
    },
    {
      "epoch": 7.805322639445862,
      "grad_norm": 0.010674282908439636,
      "learning_rate": 4.389354721108276e-06,
      "loss": 0.0001,
      "step": 21410
    },
    {
      "epoch": 7.808968282901932,
      "grad_norm": 0.0010602058609947562,
      "learning_rate": 4.382063434196136e-06,
      "loss": 0.0026,
      "step": 21420
    },
    {
      "epoch": 7.812613926358003,
      "grad_norm": 0.0030478995759040117,
      "learning_rate": 4.374772147283996e-06,
      "loss": 0.0054,
      "step": 21430
    },
    {
      "epoch": 7.816259569814072,
      "grad_norm": 0.0001405837683705613,
      "learning_rate": 4.367480860371856e-06,
      "loss": 0.0094,
      "step": 21440
    },
    {
      "epoch": 7.819905213270142,
      "grad_norm": 0.21908363699913025,
      "learning_rate": 4.360189573459716e-06,
      "loss": 0.0049,
      "step": 21450
    },
    {
      "epoch": 7.823550856726213,
      "grad_norm": 1.9482907056808472,
      "learning_rate": 4.352898286547576e-06,
      "loss": 0.008,
      "step": 21460
    },
    {
      "epoch": 7.827196500182282,
      "grad_norm": 0.008324452675879002,
      "learning_rate": 4.345606999635436e-06,
      "loss": 0.0082,
      "step": 21470
    },
    {
      "epoch": 7.830842143638352,
      "grad_norm": 0.00045208336086943746,
      "learning_rate": 4.338315712723296e-06,
      "loss": 0.0054,
      "step": 21480
    },
    {
      "epoch": 7.834487787094422,
      "grad_norm": 0.36029675602912903,
      "learning_rate": 4.331024425811156e-06,
      "loss": 0.0012,
      "step": 21490
    },
    {
      "epoch": 7.838133430550492,
      "grad_norm": 0.0714588612318039,
      "learning_rate": 4.3237331388990166e-06,
      "loss": 0.001,
      "step": 21500
    },
    {
      "epoch": 7.8417790740065625,
      "grad_norm": 0.005559838376939297,
      "learning_rate": 4.3164418519868766e-06,
      "loss": 0.0001,
      "step": 21510
    },
    {
      "epoch": 7.845424717462632,
      "grad_norm": 1.0042544603347778,
      "learning_rate": 4.309150565074737e-06,
      "loss": 0.0028,
      "step": 21520
    },
    {
      "epoch": 7.849070360918702,
      "grad_norm": 3.4384686946868896,
      "learning_rate": 4.301859278162597e-06,
      "loss": 0.0273,
      "step": 21530
    },
    {
      "epoch": 7.852716004374772,
      "grad_norm": 0.0025266187731176615,
      "learning_rate": 4.294567991250457e-06,
      "loss": 0.0025,
      "step": 21540
    },
    {
      "epoch": 7.856361647830842,
      "grad_norm": 13.281376838684082,
      "learning_rate": 4.287276704338317e-06,
      "loss": 0.0235,
      "step": 21550
    },
    {
      "epoch": 7.860007291286912,
      "grad_norm": 0.00842417310923338,
      "learning_rate": 4.279985417426177e-06,
      "loss": 0.0001,
      "step": 21560
    },
    {
      "epoch": 7.863652934742982,
      "grad_norm": 0.002008498413488269,
      "learning_rate": 4.272694130514037e-06,
      "loss": 0.0095,
      "step": 21570
    },
    {
      "epoch": 7.867298578199052,
      "grad_norm": 0.0012159921461716294,
      "learning_rate": 4.265402843601897e-06,
      "loss": 0.0016,
      "step": 21580
    },
    {
      "epoch": 7.870944221655122,
      "grad_norm": 0.002060584956780076,
      "learning_rate": 4.258111556689757e-06,
      "loss": 0.0116,
      "step": 21590
    },
    {
      "epoch": 7.874589865111192,
      "grad_norm": 0.000897651189006865,
      "learning_rate": 4.250820269777617e-06,
      "loss": 0.0002,
      "step": 21600
    },
    {
      "epoch": 7.878235508567262,
      "grad_norm": 0.019105901941657066,
      "learning_rate": 4.243528982865477e-06,
      "loss": 0.0014,
      "step": 21610
    },
    {
      "epoch": 7.8818811520233325,
      "grad_norm": 0.0008252099505625665,
      "learning_rate": 4.236237695953337e-06,
      "loss": 0.0172,
      "step": 21620
    },
    {
      "epoch": 7.885526795479402,
      "grad_norm": 1.6706523895263672,
      "learning_rate": 4.228946409041197e-06,
      "loss": 0.0136,
      "step": 21630
    },
    {
      "epoch": 7.889172438935472,
      "grad_norm": 0.006084807682782412,
      "learning_rate": 4.221655122129057e-06,
      "loss": 0.0171,
      "step": 21640
    },
    {
      "epoch": 7.892818082391543,
      "grad_norm": 0.011973547749221325,
      "learning_rate": 4.214363835216917e-06,
      "loss": 0.0074,
      "step": 21650
    },
    {
      "epoch": 7.896463725847612,
      "grad_norm": 0.29026275873184204,
      "learning_rate": 4.207072548304777e-06,
      "loss": 0.0043,
      "step": 21660
    },
    {
      "epoch": 7.900109369303682,
      "grad_norm": 0.0020020930096507072,
      "learning_rate": 4.199781261392636e-06,
      "loss": 0.0021,
      "step": 21670
    },
    {
      "epoch": 7.903755012759752,
      "grad_norm": 0.015195480547845364,
      "learning_rate": 4.192489974480496e-06,
      "loss": 0.0002,
      "step": 21680
    },
    {
      "epoch": 7.907400656215822,
      "grad_norm": 0.729241132736206,
      "learning_rate": 4.185198687568356e-06,
      "loss": 0.0062,
      "step": 21690
    },
    {
      "epoch": 7.911046299671892,
      "grad_norm": 0.02852102369070053,
      "learning_rate": 4.177907400656216e-06,
      "loss": 0.0055,
      "step": 21700
    },
    {
      "epoch": 7.914691943127962,
      "grad_norm": 0.0015812213532626629,
      "learning_rate": 4.170616113744076e-06,
      "loss": 0.0174,
      "step": 21710
    },
    {
      "epoch": 7.918337586584032,
      "grad_norm": 0.0026340170297771692,
      "learning_rate": 4.163324826831936e-06,
      "loss": 0.009,
      "step": 21720
    },
    {
      "epoch": 7.921983230040102,
      "grad_norm": 0.001314273802563548,
      "learning_rate": 4.156033539919796e-06,
      "loss": 0.0127,
      "step": 21730
    },
    {
      "epoch": 7.925628873496172,
      "grad_norm": 0.281788170337677,
      "learning_rate": 4.148742253007656e-06,
      "loss": 0.0002,
      "step": 21740
    },
    {
      "epoch": 7.929274516952242,
      "grad_norm": 0.07302883267402649,
      "learning_rate": 4.141450966095516e-06,
      "loss": 0.0013,
      "step": 21750
    },
    {
      "epoch": 7.932920160408312,
      "grad_norm": 0.09778240323066711,
      "learning_rate": 4.134159679183376e-06,
      "loss": 0.003,
      "step": 21760
    },
    {
      "epoch": 7.936565803864382,
      "grad_norm": 8.388401329284534e-05,
      "learning_rate": 4.126868392271236e-06,
      "loss": 0.0024,
      "step": 21770
    },
    {
      "epoch": 7.940211447320452,
      "grad_norm": 0.0007414910942316055,
      "learning_rate": 4.119577105359096e-06,
      "loss": 0.0007,
      "step": 21780
    },
    {
      "epoch": 7.943857090776522,
      "grad_norm": 0.0031402437016367912,
      "learning_rate": 4.112285818446956e-06,
      "loss": 0.0011,
      "step": 21790
    },
    {
      "epoch": 7.947502734232592,
      "grad_norm": 0.0008826688281260431,
      "learning_rate": 4.104994531534816e-06,
      "loss": 0.004,
      "step": 21800
    },
    {
      "epoch": 7.9511483776886624,
      "grad_norm": 0.0003712287580128759,
      "learning_rate": 4.097703244622676e-06,
      "loss": 0.0001,
      "step": 21810
    },
    {
      "epoch": 7.954794021144732,
      "grad_norm": 0.0005184706533327699,
      "learning_rate": 4.090411957710536e-06,
      "loss": 0.0081,
      "step": 21820
    },
    {
      "epoch": 7.958439664600802,
      "grad_norm": 0.002950640395283699,
      "learning_rate": 4.083120670798396e-06,
      "loss": 0.0106,
      "step": 21830
    },
    {
      "epoch": 7.9620853080568725,
      "grad_norm": 0.0002913394710049033,
      "learning_rate": 4.075829383886256e-06,
      "loss": 0.0023,
      "step": 21840
    },
    {
      "epoch": 7.965730951512942,
      "grad_norm": 0.004684256389737129,
      "learning_rate": 4.068538096974116e-06,
      "loss": 0.0,
      "step": 21850
    },
    {
      "epoch": 7.969376594969012,
      "grad_norm": 0.0002286954113515094,
      "learning_rate": 4.061246810061976e-06,
      "loss": 0.0026,
      "step": 21860
    },
    {
      "epoch": 7.973022238425082,
      "grad_norm": 0.0009757165680639446,
      "learning_rate": 4.053955523149836e-06,
      "loss": 0.0118,
      "step": 21870
    },
    {
      "epoch": 7.976667881881152,
      "grad_norm": 1.1563751697540283,
      "learning_rate": 4.046664236237696e-06,
      "loss": 0.0061,
      "step": 21880
    },
    {
      "epoch": 7.980313525337222,
      "grad_norm": 0.00173023936804384,
      "learning_rate": 4.039372949325556e-06,
      "loss": 0.0003,
      "step": 21890
    },
    {
      "epoch": 7.983959168793292,
      "grad_norm": 0.25341445207595825,
      "learning_rate": 4.032081662413416e-06,
      "loss": 0.0093,
      "step": 21900
    },
    {
      "epoch": 7.987604812249362,
      "grad_norm": 0.13725066184997559,
      "learning_rate": 4.024790375501276e-06,
      "loss": 0.0062,
      "step": 21910
    },
    {
      "epoch": 7.991250455705432,
      "grad_norm": 0.0035901323426514864,
      "learning_rate": 4.017499088589136e-06,
      "loss": 0.005,
      "step": 21920
    },
    {
      "epoch": 7.994896099161502,
      "grad_norm": 7.688425102969632e-05,
      "learning_rate": 4.010207801676996e-06,
      "loss": 0.0001,
      "step": 21930
    },
    {
      "epoch": 7.998541742617572,
      "grad_norm": 0.012636289931833744,
      "learning_rate": 4.002916514764856e-06,
      "loss": 0.017,
      "step": 21940
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9915885860306644,
      "eval_f1": 0.9662825437473325,
      "eval_loss": 0.03388414904475212,
      "eval_precision": 0.9662825437473325,
      "eval_recall": 0.9662825437473325,
      "eval_runtime": 805.9662,
      "eval_samples_per_second": 23.343,
      "eval_steps_per_second": 0.73,
      "step": 21944
    },
    {
      "epoch": 8.002187386073642,
      "grad_norm": 0.00015775018255226314,
      "learning_rate": 3.995625227852716e-06,
      "loss": 0.0047,
      "step": 21950
    },
    {
      "epoch": 8.005833029529713,
      "grad_norm": 0.00012903429160360247,
      "learning_rate": 3.988333940940576e-06,
      "loss": 0.0067,
      "step": 21960
    },
    {
      "epoch": 8.009478672985782,
      "grad_norm": 0.04295290261507034,
      "learning_rate": 3.981042654028436e-06,
      "loss": 0.0142,
      "step": 21970
    },
    {
      "epoch": 8.013124316441852,
      "grad_norm": 0.001082178088836372,
      "learning_rate": 3.973751367116296e-06,
      "loss": 0.0029,
      "step": 21980
    },
    {
      "epoch": 8.016769959897921,
      "grad_norm": 0.0021186410449445248,
      "learning_rate": 3.966460080204156e-06,
      "loss": 0.0151,
      "step": 21990
    },
    {
      "epoch": 8.020415603353992,
      "grad_norm": 0.004989823326468468,
      "learning_rate": 3.959168793292016e-06,
      "loss": 0.0068,
      "step": 22000
    },
    {
      "epoch": 8.024061246810062,
      "grad_norm": 0.0026901797391474247,
      "learning_rate": 3.951877506379876e-06,
      "loss": 0.0086,
      "step": 22010
    },
    {
      "epoch": 8.027706890266131,
      "grad_norm": 2.0529322624206543,
      "learning_rate": 3.944586219467736e-06,
      "loss": 0.007,
      "step": 22020
    },
    {
      "epoch": 8.031352533722202,
      "grad_norm": 0.0011802386725321412,
      "learning_rate": 3.937294932555596e-06,
      "loss": 0.0024,
      "step": 22030
    },
    {
      "epoch": 8.034998177178272,
      "grad_norm": 0.0012132982956245542,
      "learning_rate": 3.930003645643456e-06,
      "loss": 0.0014,
      "step": 22040
    },
    {
      "epoch": 8.038643820634341,
      "grad_norm": 0.0005454486235976219,
      "learning_rate": 3.922712358731316e-06,
      "loss": 0.0012,
      "step": 22050
    },
    {
      "epoch": 8.042289464090413,
      "grad_norm": 0.00013681361451745033,
      "learning_rate": 3.915421071819176e-06,
      "loss": 0.0,
      "step": 22060
    },
    {
      "epoch": 8.045935107546482,
      "grad_norm": 9.173247963190079e-05,
      "learning_rate": 3.908129784907036e-06,
      "loss": 0.0087,
      "step": 22070
    },
    {
      "epoch": 8.049580751002551,
      "grad_norm": 0.0002072344213956967,
      "learning_rate": 3.900838497994896e-06,
      "loss": 0.0025,
      "step": 22080
    },
    {
      "epoch": 8.053226394458623,
      "grad_norm": 0.000634441094007343,
      "learning_rate": 3.893547211082756e-06,
      "loss": 0.0001,
      "step": 22090
    },
    {
      "epoch": 8.056872037914692,
      "grad_norm": 0.0001684118469711393,
      "learning_rate": 3.886255924170616e-06,
      "loss": 0.0076,
      "step": 22100
    },
    {
      "epoch": 8.060517681370762,
      "grad_norm": 9.797423263080418e-05,
      "learning_rate": 3.878964637258476e-06,
      "loss": 0.004,
      "step": 22110
    },
    {
      "epoch": 8.064163324826833,
      "grad_norm": 0.0002970446948893368,
      "learning_rate": 3.871673350346336e-06,
      "loss": 0.0002,
      "step": 22120
    },
    {
      "epoch": 8.067808968282902,
      "grad_norm": 0.06852100789546967,
      "learning_rate": 3.864382063434196e-06,
      "loss": 0.0043,
      "step": 22130
    },
    {
      "epoch": 8.071454611738972,
      "grad_norm": 0.00033744212123565376,
      "learning_rate": 3.857090776522056e-06,
      "loss": 0.003,
      "step": 22140
    },
    {
      "epoch": 8.075100255195043,
      "grad_norm": 0.00014484167331829667,
      "learning_rate": 3.849799489609916e-06,
      "loss": 0.0174,
      "step": 22150
    },
    {
      "epoch": 8.078745898651112,
      "grad_norm": 9.706170385470614e-05,
      "learning_rate": 3.842508202697776e-06,
      "loss": 0.006,
      "step": 22160
    },
    {
      "epoch": 8.082391542107182,
      "grad_norm": 0.0011246239300817251,
      "learning_rate": 3.835216915785636e-06,
      "loss": 0.008,
      "step": 22170
    },
    {
      "epoch": 8.086037185563251,
      "grad_norm": 7.648673636140302e-05,
      "learning_rate": 3.827925628873496e-06,
      "loss": 0.0052,
      "step": 22180
    },
    {
      "epoch": 8.089682829019322,
      "grad_norm": 0.00019172107568010688,
      "learning_rate": 3.820634341961356e-06,
      "loss": 0.0291,
      "step": 22190
    },
    {
      "epoch": 8.093328472475392,
      "grad_norm": 0.0004353063995949924,
      "learning_rate": 3.813343055049217e-06,
      "loss": 0.0053,
      "step": 22200
    },
    {
      "epoch": 8.096974115931461,
      "grad_norm": 0.002718058880418539,
      "learning_rate": 3.806051768137077e-06,
      "loss": 0.005,
      "step": 22210
    },
    {
      "epoch": 8.100619759387532,
      "grad_norm": 0.00646090367808938,
      "learning_rate": 3.7987604812249364e-06,
      "loss": 0.0001,
      "step": 22220
    },
    {
      "epoch": 8.104265402843602,
      "grad_norm": 1.357530951499939,
      "learning_rate": 3.7914691943127964e-06,
      "loss": 0.0089,
      "step": 22230
    },
    {
      "epoch": 8.107911046299671,
      "grad_norm": 0.4774499237537384,
      "learning_rate": 3.7841779074006565e-06,
      "loss": 0.0034,
      "step": 22240
    },
    {
      "epoch": 8.111556689755743,
      "grad_norm": 8.04258233984001e-05,
      "learning_rate": 3.7768866204885165e-06,
      "loss": 0.0137,
      "step": 22250
    },
    {
      "epoch": 8.115202333211812,
      "grad_norm": 0.04481419920921326,
      "learning_rate": 3.7695953335763765e-06,
      "loss": 0.0045,
      "step": 22260
    },
    {
      "epoch": 8.118847976667881,
      "grad_norm": 5.687186785507947e-05,
      "learning_rate": 3.7623040466642365e-06,
      "loss": 0.0082,
      "step": 22270
    },
    {
      "epoch": 8.122493620123953,
      "grad_norm": 0.00014315037697087973,
      "learning_rate": 3.7550127597520965e-06,
      "loss": 0.0045,
      "step": 22280
    },
    {
      "epoch": 8.126139263580022,
      "grad_norm": 0.00023561733542010188,
      "learning_rate": 3.7477214728399565e-06,
      "loss": 0.0083,
      "step": 22290
    },
    {
      "epoch": 8.129784907036091,
      "grad_norm": 5.890378475189209,
      "learning_rate": 3.7404301859278165e-06,
      "loss": 0.014,
      "step": 22300
    },
    {
      "epoch": 8.133430550492163,
      "grad_norm": 0.0005633836262859404,
      "learning_rate": 3.7331388990156765e-06,
      "loss": 0.0,
      "step": 22310
    },
    {
      "epoch": 8.137076193948232,
      "grad_norm": 0.001081796013750136,
      "learning_rate": 3.7258476121035365e-06,
      "loss": 0.0105,
      "step": 22320
    },
    {
      "epoch": 8.140721837404302,
      "grad_norm": 1.343436360359192,
      "learning_rate": 3.7185563251913965e-06,
      "loss": 0.0094,
      "step": 22330
    },
    {
      "epoch": 8.144367480860371,
      "grad_norm": 0.84434974193573,
      "learning_rate": 3.7112650382792566e-06,
      "loss": 0.0034,
      "step": 22340
    },
    {
      "epoch": 8.148013124316442,
      "grad_norm": 1.0761706829071045,
      "learning_rate": 3.7039737513671166e-06,
      "loss": 0.0024,
      "step": 22350
    },
    {
      "epoch": 8.151658767772512,
      "grad_norm": 0.0022247435990720987,
      "learning_rate": 3.6966824644549766e-06,
      "loss": 0.0063,
      "step": 22360
    },
    {
      "epoch": 8.155304411228581,
      "grad_norm": 5.722162313759327e-05,
      "learning_rate": 3.6893911775428366e-06,
      "loss": 0.0056,
      "step": 22370
    },
    {
      "epoch": 8.158950054684652,
      "grad_norm": 0.00019712172797881067,
      "learning_rate": 3.6820998906306966e-06,
      "loss": 0.0011,
      "step": 22380
    },
    {
      "epoch": 8.162595698140722,
      "grad_norm": 0.3331575393676758,
      "learning_rate": 3.6748086037185566e-06,
      "loss": 0.0003,
      "step": 22390
    },
    {
      "epoch": 8.166241341596791,
      "grad_norm": 0.0005853325710631907,
      "learning_rate": 3.6675173168064166e-06,
      "loss": 0.0211,
      "step": 22400
    },
    {
      "epoch": 8.169886985052862,
      "grad_norm": 0.00047884590458124876,
      "learning_rate": 3.6602260298942766e-06,
      "loss": 0.0,
      "step": 22410
    },
    {
      "epoch": 8.173532628508932,
      "grad_norm": 0.0008468063315376639,
      "learning_rate": 3.6529347429821366e-06,
      "loss": 0.0097,
      "step": 22420
    },
    {
      "epoch": 8.177178271965001,
      "grad_norm": 0.08464934676885605,
      "learning_rate": 3.6456434560699966e-06,
      "loss": 0.0069,
      "step": 22430
    },
    {
      "epoch": 8.180823915421072,
      "grad_norm": 0.006516553461551666,
      "learning_rate": 3.6383521691578567e-06,
      "loss": 0.0001,
      "step": 22440
    },
    {
      "epoch": 8.184469558877142,
      "grad_norm": 2.5756585597991943,
      "learning_rate": 3.6310608822457167e-06,
      "loss": 0.0086,
      "step": 22450
    },
    {
      "epoch": 8.188115202333211,
      "grad_norm": 0.6444757580757141,
      "learning_rate": 3.6237695953335767e-06,
      "loss": 0.0066,
      "step": 22460
    },
    {
      "epoch": 8.191760845789283,
      "grad_norm": 0.018171628937125206,
      "learning_rate": 3.6164783084214367e-06,
      "loss": 0.0082,
      "step": 22470
    },
    {
      "epoch": 8.195406489245352,
      "grad_norm": 0.0013395348796620965,
      "learning_rate": 3.6091870215092967e-06,
      "loss": 0.0002,
      "step": 22480
    },
    {
      "epoch": 8.199052132701421,
      "grad_norm": 0.02938508801162243,
      "learning_rate": 3.6018957345971567e-06,
      "loss": 0.0018,
      "step": 22490
    },
    {
      "epoch": 8.202697776157493,
      "grad_norm": 0.000672177760861814,
      "learning_rate": 3.5946044476850167e-06,
      "loss": 0.0006,
      "step": 22500
    },
    {
      "epoch": 8.206343419613562,
      "grad_norm": 0.032437391579151154,
      "learning_rate": 3.5873131607728767e-06,
      "loss": 0.011,
      "step": 22510
    },
    {
      "epoch": 8.209989063069631,
      "grad_norm": 0.9883422255516052,
      "learning_rate": 3.5800218738607367e-06,
      "loss": 0.0092,
      "step": 22520
    },
    {
      "epoch": 8.213634706525701,
      "grad_norm": 1.2280160188674927,
      "learning_rate": 3.5727305869485967e-06,
      "loss": 0.0084,
      "step": 22530
    },
    {
      "epoch": 8.217280349981772,
      "grad_norm": 0.00022525928216055036,
      "learning_rate": 3.5654393000364568e-06,
      "loss": 0.004,
      "step": 22540
    },
    {
      "epoch": 8.220925993437842,
      "grad_norm": 0.09675488620996475,
      "learning_rate": 3.5581480131243168e-06,
      "loss": 0.0097,
      "step": 22550
    },
    {
      "epoch": 8.224571636893911,
      "grad_norm": 0.0001557277428219095,
      "learning_rate": 3.5508567262121768e-06,
      "loss": 0.0007,
      "step": 22560
    },
    {
      "epoch": 8.228217280349982,
      "grad_norm": 0.0002826075942721218,
      "learning_rate": 3.543565439300037e-06,
      "loss": 0.0039,
      "step": 22570
    },
    {
      "epoch": 8.231862923806052,
      "grad_norm": 0.7847669124603271,
      "learning_rate": 3.536274152387897e-06,
      "loss": 0.0063,
      "step": 22580
    },
    {
      "epoch": 8.235508567262121,
      "grad_norm": 0.00684012658894062,
      "learning_rate": 3.528982865475757e-06,
      "loss": 0.0025,
      "step": 22590
    },
    {
      "epoch": 8.239154210718192,
      "grad_norm": 0.00010633427154971287,
      "learning_rate": 3.521691578563617e-06,
      "loss": 0.0019,
      "step": 22600
    },
    {
      "epoch": 8.242799854174262,
      "grad_norm": 0.00017118777032010257,
      "learning_rate": 3.514400291651477e-06,
      "loss": 0.0024,
      "step": 22610
    },
    {
      "epoch": 8.246445497630331,
      "grad_norm": 0.0004103062383364886,
      "learning_rate": 3.507109004739337e-06,
      "loss": 0.0018,
      "step": 22620
    },
    {
      "epoch": 8.250091141086402,
      "grad_norm": 0.0012972442200407386,
      "learning_rate": 3.499817717827197e-06,
      "loss": 0.0014,
      "step": 22630
    },
    {
      "epoch": 8.253736784542472,
      "grad_norm": 0.8829164505004883,
      "learning_rate": 3.492526430915057e-06,
      "loss": 0.0076,
      "step": 22640
    },
    {
      "epoch": 8.257382427998541,
      "grad_norm": 0.0001743335888022557,
      "learning_rate": 3.485235144002917e-06,
      "loss": 0.0162,
      "step": 22650
    },
    {
      "epoch": 8.261028071454612,
      "grad_norm": 1.479795217514038,
      "learning_rate": 3.477943857090777e-06,
      "loss": 0.0145,
      "step": 22660
    },
    {
      "epoch": 8.264673714910682,
      "grad_norm": 9.581894119037315e-05,
      "learning_rate": 3.470652570178637e-06,
      "loss": 0.0,
      "step": 22670
    },
    {
      "epoch": 8.268319358366751,
      "grad_norm": 0.00015077635180205107,
      "learning_rate": 3.463361283266497e-06,
      "loss": 0.0128,
      "step": 22680
    },
    {
      "epoch": 8.271965001822823,
      "grad_norm": 0.696593701839447,
      "learning_rate": 3.456069996354357e-06,
      "loss": 0.0033,
      "step": 22690
    },
    {
      "epoch": 8.275610645278892,
      "grad_norm": 0.0007055668393149972,
      "learning_rate": 3.448778709442217e-06,
      "loss": 0.0029,
      "step": 22700
    },
    {
      "epoch": 8.279256288734961,
      "grad_norm": 0.0002269262622576207,
      "learning_rate": 3.441487422530077e-06,
      "loss": 0.0069,
      "step": 22710
    },
    {
      "epoch": 8.28290193219103,
      "grad_norm": 0.0003170691488776356,
      "learning_rate": 3.434196135617937e-06,
      "loss": 0.0017,
      "step": 22720
    },
    {
      "epoch": 8.286547575647102,
      "grad_norm": 1.2944715023040771,
      "learning_rate": 3.426904848705797e-06,
      "loss": 0.0025,
      "step": 22730
    },
    {
      "epoch": 8.290193219103172,
      "grad_norm": 0.00010237607784802094,
      "learning_rate": 3.419613561793657e-06,
      "loss": 0.0022,
      "step": 22740
    },
    {
      "epoch": 8.293838862559241,
      "grad_norm": 7.900036871433258e-05,
      "learning_rate": 3.412322274881517e-06,
      "loss": 0.018,
      "step": 22750
    },
    {
      "epoch": 8.297484506015312,
      "grad_norm": 8.089865684509277,
      "learning_rate": 3.405030987969377e-06,
      "loss": 0.0135,
      "step": 22760
    },
    {
      "epoch": 8.301130149471382,
      "grad_norm": 0.021384211257100105,
      "learning_rate": 3.3977397010572366e-06,
      "loss": 0.0,
      "step": 22770
    },
    {
      "epoch": 8.304775792927451,
      "grad_norm": 0.00019272435747552663,
      "learning_rate": 3.3904484141450966e-06,
      "loss": 0.004,
      "step": 22780
    },
    {
      "epoch": 8.308421436383522,
      "grad_norm": 0.006755841430276632,
      "learning_rate": 3.3831571272329566e-06,
      "loss": 0.0004,
      "step": 22790
    },
    {
      "epoch": 8.312067079839592,
      "grad_norm": 0.00022922840435057878,
      "learning_rate": 3.3758658403208166e-06,
      "loss": 0.0,
      "step": 22800
    },
    {
      "epoch": 8.315712723295661,
      "grad_norm": 6.364457658492029e-05,
      "learning_rate": 3.3685745534086766e-06,
      "loss": 0.0041,
      "step": 22810
    },
    {
      "epoch": 8.319358366751732,
      "grad_norm": 0.0002813453902490437,
      "learning_rate": 3.3612832664965366e-06,
      "loss": 0.0083,
      "step": 22820
    },
    {
      "epoch": 8.323004010207802,
      "grad_norm": 0.0002752664149738848,
      "learning_rate": 3.3539919795843966e-06,
      "loss": 0.0,
      "step": 22830
    },
    {
      "epoch": 8.326649653663871,
      "grad_norm": 0.18005050718784332,
      "learning_rate": 3.3467006926722566e-06,
      "loss": 0.0208,
      "step": 22840
    },
    {
      "epoch": 8.330295297119942,
      "grad_norm": 0.00018720167281571776,
      "learning_rate": 3.3394094057601166e-06,
      "loss": 0.0014,
      "step": 22850
    },
    {
      "epoch": 8.333940940576012,
      "grad_norm": 0.00013970160216558725,
      "learning_rate": 3.3321181188479767e-06,
      "loss": 0.0013,
      "step": 22860
    },
    {
      "epoch": 8.337586584032081,
      "grad_norm": 8.176866685971618e-05,
      "learning_rate": 3.3248268319358367e-06,
      "loss": 0.0062,
      "step": 22870
    },
    {
      "epoch": 8.341232227488153,
      "grad_norm": 0.0008518858812749386,
      "learning_rate": 3.3175355450236967e-06,
      "loss": 0.0114,
      "step": 22880
    },
    {
      "epoch": 8.344877870944222,
      "grad_norm": 5.4155330872163177e-05,
      "learning_rate": 3.3102442581115567e-06,
      "loss": 0.0147,
      "step": 22890
    },
    {
      "epoch": 8.348523514400291,
      "grad_norm": 5.225801467895508,
      "learning_rate": 3.3029529711994167e-06,
      "loss": 0.0305,
      "step": 22900
    },
    {
      "epoch": 8.35216915785636,
      "grad_norm": 6.640065112151206e-05,
      "learning_rate": 3.2956616842872767e-06,
      "loss": 0.0035,
      "step": 22910
    },
    {
      "epoch": 8.355814801312432,
      "grad_norm": 2.9825119972229004,
      "learning_rate": 3.2883703973751367e-06,
      "loss": 0.0058,
      "step": 22920
    },
    {
      "epoch": 8.359460444768501,
      "grad_norm": 2.4012014865875244,
      "learning_rate": 3.2810791104629967e-06,
      "loss": 0.0291,
      "step": 22930
    },
    {
      "epoch": 8.363106088224571,
      "grad_norm": 0.00024120506714098155,
      "learning_rate": 3.2737878235508567e-06,
      "loss": 0.0054,
      "step": 22940
    },
    {
      "epoch": 8.366751731680642,
      "grad_norm": 0.000985723570920527,
      "learning_rate": 3.2664965366387167e-06,
      "loss": 0.0261,
      "step": 22950
    },
    {
      "epoch": 8.370397375136712,
      "grad_norm": 0.5271401405334473,
      "learning_rate": 3.2592052497265768e-06,
      "loss": 0.0052,
      "step": 22960
    },
    {
      "epoch": 8.374043018592781,
      "grad_norm": 1.2776356935501099,
      "learning_rate": 3.2519139628144368e-06,
      "loss": 0.0112,
      "step": 22970
    },
    {
      "epoch": 8.377688662048852,
      "grad_norm": 0.00010357762221246958,
      "learning_rate": 3.2446226759022968e-06,
      "loss": 0.0009,
      "step": 22980
    },
    {
      "epoch": 8.381334305504922,
      "grad_norm": 0.0001221201819134876,
      "learning_rate": 3.237331388990157e-06,
      "loss": 0.0071,
      "step": 22990
    },
    {
      "epoch": 8.384979948960991,
      "grad_norm": 6.533458508783951e-05,
      "learning_rate": 3.230040102078017e-06,
      "loss": 0.0034,
      "step": 23000
    },
    {
      "epoch": 8.388625592417062,
      "grad_norm": 2.249915599822998,
      "learning_rate": 3.222748815165877e-06,
      "loss": 0.0058,
      "step": 23010
    },
    {
      "epoch": 8.392271235873132,
      "grad_norm": 0.0002245960058644414,
      "learning_rate": 3.215457528253737e-06,
      "loss": 0.0011,
      "step": 23020
    },
    {
      "epoch": 8.395916879329201,
      "grad_norm": 4.240686416625977,
      "learning_rate": 3.2081662413415973e-06,
      "loss": 0.0185,
      "step": 23030
    },
    {
      "epoch": 8.399562522785272,
      "grad_norm": 0.16537289321422577,
      "learning_rate": 3.2008749544294573e-06,
      "loss": 0.0128,
      "step": 23040
    },
    {
      "epoch": 8.403208166241342,
      "grad_norm": 0.0003849299973808229,
      "learning_rate": 3.1935836675173173e-06,
      "loss": 0.0001,
      "step": 23050
    },
    {
      "epoch": 8.406853809697411,
      "grad_norm": 0.006101795006543398,
      "learning_rate": 3.1862923806051773e-06,
      "loss": 0.0021,
      "step": 23060
    },
    {
      "epoch": 8.41049945315348,
      "grad_norm": 5.648357546306215e-05,
      "learning_rate": 3.1790010936930373e-06,
      "loss": 0.0,
      "step": 23070
    },
    {
      "epoch": 8.414145096609552,
      "grad_norm": 0.00011112968059023842,
      "learning_rate": 3.1717098067808973e-06,
      "loss": 0.0004,
      "step": 23080
    },
    {
      "epoch": 8.417790740065621,
      "grad_norm": 0.0017382351215928793,
      "learning_rate": 3.1644185198687573e-06,
      "loss": 0.0014,
      "step": 23090
    },
    {
      "epoch": 8.42143638352169,
      "grad_norm": 0.0002558832347858697,
      "learning_rate": 3.1571272329566173e-06,
      "loss": 0.0032,
      "step": 23100
    },
    {
      "epoch": 8.425082026977762,
      "grad_norm": 8.25188253656961e-05,
      "learning_rate": 3.1498359460444773e-06,
      "loss": 0.0037,
      "step": 23110
    },
    {
      "epoch": 8.428727670433831,
      "grad_norm": 0.005536641925573349,
      "learning_rate": 3.1425446591323373e-06,
      "loss": 0.0001,
      "step": 23120
    },
    {
      "epoch": 8.4323733138899,
      "grad_norm": 0.00012275755580049008,
      "learning_rate": 3.1352533722201974e-06,
      "loss": 0.0087,
      "step": 23130
    },
    {
      "epoch": 8.436018957345972,
      "grad_norm": 0.00019683637947309762,
      "learning_rate": 3.1279620853080574e-06,
      "loss": 0.0013,
      "step": 23140
    },
    {
      "epoch": 8.439664600802042,
      "grad_norm": 16.43547248840332,
      "learning_rate": 3.1206707983959174e-06,
      "loss": 0.0023,
      "step": 23150
    },
    {
      "epoch": 8.443310244258111,
      "grad_norm": 0.00017944746650755405,
      "learning_rate": 3.1133795114837774e-06,
      "loss": 0.0034,
      "step": 23160
    },
    {
      "epoch": 8.446955887714182,
      "grad_norm": 0.00010852412378881127,
      "learning_rate": 3.1060882245716374e-06,
      "loss": 0.0057,
      "step": 23170
    },
    {
      "epoch": 8.450601531170252,
      "grad_norm": 6.429271161323413e-05,
      "learning_rate": 3.0987969376594974e-06,
      "loss": 0.0067,
      "step": 23180
    },
    {
      "epoch": 8.454247174626321,
      "grad_norm": 5.955259985057637e-05,
      "learning_rate": 3.0915056507473574e-06,
      "loss": 0.0,
      "step": 23190
    },
    {
      "epoch": 8.457892818082392,
      "grad_norm": 6.3453902839683e-05,
      "learning_rate": 3.0842143638352174e-06,
      "loss": 0.0048,
      "step": 23200
    },
    {
      "epoch": 8.461538461538462,
      "grad_norm": 9.388430044054985e-05,
      "learning_rate": 3.0769230769230774e-06,
      "loss": 0.0,
      "step": 23210
    },
    {
      "epoch": 8.465184104994531,
      "grad_norm": 6.923477485543117e-05,
      "learning_rate": 3.0696317900109374e-06,
      "loss": 0.0102,
      "step": 23220
    },
    {
      "epoch": 8.468829748450602,
      "grad_norm": 0.00016236607916653156,
      "learning_rate": 3.0623405030987975e-06,
      "loss": 0.0043,
      "step": 23230
    },
    {
      "epoch": 8.472475391906672,
      "grad_norm": 4.028242588043213,
      "learning_rate": 3.0550492161866575e-06,
      "loss": 0.0093,
      "step": 23240
    },
    {
      "epoch": 8.476121035362741,
      "grad_norm": 0.00019252233323641121,
      "learning_rate": 3.0477579292745175e-06,
      "loss": 0.0055,
      "step": 23250
    },
    {
      "epoch": 8.479766678818812,
      "grad_norm": 1.902721881866455,
      "learning_rate": 3.0404666423623775e-06,
      "loss": 0.0051,
      "step": 23260
    },
    {
      "epoch": 8.483412322274882,
      "grad_norm": 0.00047672956134192646,
      "learning_rate": 3.0331753554502375e-06,
      "loss": 0.0149,
      "step": 23270
    },
    {
      "epoch": 8.487057965730951,
      "grad_norm": 0.012942319735884666,
      "learning_rate": 3.0258840685380975e-06,
      "loss": 0.0071,
      "step": 23280
    },
    {
      "epoch": 8.49070360918702,
      "grad_norm": 0.0002304049558006227,
      "learning_rate": 3.0185927816259575e-06,
      "loss": 0.0001,
      "step": 23290
    },
    {
      "epoch": 8.494349252643092,
      "grad_norm": 2.2903215885162354,
      "learning_rate": 3.0113014947138175e-06,
      "loss": 0.0143,
      "step": 23300
    },
    {
      "epoch": 8.497994896099161,
      "grad_norm": 5.896331787109375,
      "learning_rate": 3.0040102078016775e-06,
      "loss": 0.011,
      "step": 23310
    },
    {
      "epoch": 8.50164053955523,
      "grad_norm": 0.00022131977311801165,
      "learning_rate": 2.996718920889537e-06,
      "loss": 0.0035,
      "step": 23320
    },
    {
      "epoch": 8.505286183011302,
      "grad_norm": 0.4668274223804474,
      "learning_rate": 2.989427633977397e-06,
      "loss": 0.0028,
      "step": 23330
    },
    {
      "epoch": 8.508931826467371,
      "grad_norm": 0.00014623093011323363,
      "learning_rate": 2.982136347065257e-06,
      "loss": 0.0059,
      "step": 23340
    },
    {
      "epoch": 8.51257746992344,
      "grad_norm": 0.00013762021262664348,
      "learning_rate": 2.974845060153117e-06,
      "loss": 0.001,
      "step": 23350
    },
    {
      "epoch": 8.516223113379512,
      "grad_norm": 1.4003328084945679,
      "learning_rate": 2.967553773240977e-06,
      "loss": 0.0041,
      "step": 23360
    },
    {
      "epoch": 8.519868756835582,
      "grad_norm": 0.00010050850687548518,
      "learning_rate": 2.960262486328837e-06,
      "loss": 0.003,
      "step": 23370
    },
    {
      "epoch": 8.523514400291651,
      "grad_norm": 7.310605724342167e-05,
      "learning_rate": 2.952971199416697e-06,
      "loss": 0.0048,
      "step": 23380
    },
    {
      "epoch": 8.527160043747722,
      "grad_norm": 0.00010763847240014002,
      "learning_rate": 2.945679912504557e-06,
      "loss": 0.0051,
      "step": 23390
    },
    {
      "epoch": 8.530805687203792,
      "grad_norm": 0.0001543413382023573,
      "learning_rate": 2.938388625592417e-06,
      "loss": 0.0031,
      "step": 23400
    },
    {
      "epoch": 8.534451330659861,
      "grad_norm": 0.0002045947767328471,
      "learning_rate": 2.9310973386802772e-06,
      "loss": 0.0041,
      "step": 23410
    },
    {
      "epoch": 8.538096974115932,
      "grad_norm": 0.006280934438109398,
      "learning_rate": 2.9238060517681372e-06,
      "loss": 0.0024,
      "step": 23420
    },
    {
      "epoch": 8.541742617572002,
      "grad_norm": 0.021088341251015663,
      "learning_rate": 2.9165147648559972e-06,
      "loss": 0.0042,
      "step": 23430
    },
    {
      "epoch": 8.545388261028071,
      "grad_norm": 1.1564087867736816,
      "learning_rate": 2.9092234779438572e-06,
      "loss": 0.0033,
      "step": 23440
    },
    {
      "epoch": 8.54903390448414,
      "grad_norm": 0.001055426662787795,
      "learning_rate": 2.9019321910317173e-06,
      "loss": 0.0024,
      "step": 23450
    },
    {
      "epoch": 8.552679547940212,
      "grad_norm": 0.00017154031957034022,
      "learning_rate": 2.8946409041195773e-06,
      "loss": 0.0037,
      "step": 23460
    },
    {
      "epoch": 8.556325191396281,
      "grad_norm": 0.00022949202684685588,
      "learning_rate": 2.8873496172074373e-06,
      "loss": 0.0045,
      "step": 23470
    },
    {
      "epoch": 8.55997083485235,
      "grad_norm": 5.949266051175073e-05,
      "learning_rate": 2.8800583302952973e-06,
      "loss": 0.0146,
      "step": 23480
    },
    {
      "epoch": 8.563616478308422,
      "grad_norm": 8.570458885515109e-05,
      "learning_rate": 2.8727670433831573e-06,
      "loss": 0.0,
      "step": 23490
    },
    {
      "epoch": 8.567262121764491,
      "grad_norm": 0.00011766733950935304,
      "learning_rate": 2.8654757564710173e-06,
      "loss": 0.0062,
      "step": 23500
    },
    {
      "epoch": 8.57090776522056,
      "grad_norm": 0.0005530212074518204,
      "learning_rate": 2.8581844695588773e-06,
      "loss": 0.0006,
      "step": 23510
    },
    {
      "epoch": 8.574553408676632,
      "grad_norm": 0.2875954210758209,
      "learning_rate": 2.8508931826467373e-06,
      "loss": 0.0045,
      "step": 23520
    },
    {
      "epoch": 8.578199052132701,
      "grad_norm": 0.0005032367189414799,
      "learning_rate": 2.8436018957345973e-06,
      "loss": 0.0016,
      "step": 23530
    },
    {
      "epoch": 8.58184469558877,
      "grad_norm": 9.567764936946332e-05,
      "learning_rate": 2.8363106088224573e-06,
      "loss": 0.0066,
      "step": 23540
    },
    {
      "epoch": 8.585490339044842,
      "grad_norm": 0.00011482741683721542,
      "learning_rate": 2.8290193219103174e-06,
      "loss": 0.0,
      "step": 23550
    },
    {
      "epoch": 8.589135982500911,
      "grad_norm": 0.8893130421638489,
      "learning_rate": 2.8217280349981774e-06,
      "loss": 0.005,
      "step": 23560
    },
    {
      "epoch": 8.592781625956981,
      "grad_norm": 0.00023047448485158384,
      "learning_rate": 2.8144367480860374e-06,
      "loss": 0.003,
      "step": 23570
    },
    {
      "epoch": 8.596427269413052,
      "grad_norm": 0.0024426996242254972,
      "learning_rate": 2.8071454611738974e-06,
      "loss": 0.004,
      "step": 23580
    },
    {
      "epoch": 8.600072912869122,
      "grad_norm": 9.416207467438653e-05,
      "learning_rate": 2.7998541742617574e-06,
      "loss": 0.0043,
      "step": 23590
    },
    {
      "epoch": 8.603718556325191,
      "grad_norm": 0.00010880297486437485,
      "learning_rate": 2.7925628873496174e-06,
      "loss": 0.0123,
      "step": 23600
    },
    {
      "epoch": 8.607364199781262,
      "grad_norm": 0.0008494348148815334,
      "learning_rate": 2.7852716004374774e-06,
      "loss": 0.0,
      "step": 23610
    },
    {
      "epoch": 8.611009843237332,
      "grad_norm": 0.0013363814214244485,
      "learning_rate": 2.7779803135253374e-06,
      "loss": 0.0064,
      "step": 23620
    },
    {
      "epoch": 8.614655486693401,
      "grad_norm": 0.0004671707865782082,
      "learning_rate": 2.7706890266131974e-06,
      "loss": 0.0048,
      "step": 23630
    },
    {
      "epoch": 8.618301130149472,
      "grad_norm": 0.425015926361084,
      "learning_rate": 2.7633977397010574e-06,
      "loss": 0.0106,
      "step": 23640
    },
    {
      "epoch": 8.621946773605542,
      "grad_norm": 8.224739576689899e-05,
      "learning_rate": 2.7561064527889175e-06,
      "loss": 0.0002,
      "step": 23650
    },
    {
      "epoch": 8.625592417061611,
      "grad_norm": 6.46125408820808e-05,
      "learning_rate": 2.7488151658767775e-06,
      "loss": 0.0001,
      "step": 23660
    },
    {
      "epoch": 8.62923806051768,
      "grad_norm": 0.019458698108792305,
      "learning_rate": 2.7415238789646375e-06,
      "loss": 0.005,
      "step": 23670
    },
    {
      "epoch": 8.632883703973752,
      "grad_norm": 9.484568727202713e-05,
      "learning_rate": 2.7342325920524975e-06,
      "loss": 0.0061,
      "step": 23680
    },
    {
      "epoch": 8.636529347429821,
      "grad_norm": 0.05477482080459595,
      "learning_rate": 2.7269413051403575e-06,
      "loss": 0.0017,
      "step": 23690
    },
    {
      "epoch": 8.64017499088589,
      "grad_norm": 6.370589835569263e-05,
      "learning_rate": 2.7196500182282175e-06,
      "loss": 0.0046,
      "step": 23700
    },
    {
      "epoch": 8.643820634341962,
      "grad_norm": 0.0001414711878169328,
      "learning_rate": 2.7123587313160775e-06,
      "loss": 0.0034,
      "step": 23710
    },
    {
      "epoch": 8.647466277798031,
      "grad_norm": 0.00021920901781413704,
      "learning_rate": 2.7050674444039375e-06,
      "loss": 0.0066,
      "step": 23720
    },
    {
      "epoch": 8.6511119212541,
      "grad_norm": 4.602200351655483e-05,
      "learning_rate": 2.6977761574917975e-06,
      "loss": 0.0026,
      "step": 23730
    },
    {
      "epoch": 8.654757564710172,
      "grad_norm": 0.7855585813522339,
      "learning_rate": 2.6904848705796575e-06,
      "loss": 0.0031,
      "step": 23740
    },
    {
      "epoch": 8.658403208166241,
      "grad_norm": 0.00014917827502358705,
      "learning_rate": 2.6831935836675176e-06,
      "loss": 0.0058,
      "step": 23750
    },
    {
      "epoch": 8.66204885162231,
      "grad_norm": 0.00013472118007484823,
      "learning_rate": 2.6759022967553776e-06,
      "loss": 0.004,
      "step": 23760
    },
    {
      "epoch": 8.665694495078382,
      "grad_norm": 0.0030828500166535378,
      "learning_rate": 2.6686110098432376e-06,
      "loss": 0.0052,
      "step": 23770
    },
    {
      "epoch": 8.669340138534452,
      "grad_norm": 1.0833607912063599,
      "learning_rate": 2.6613197229310976e-06,
      "loss": 0.002,
      "step": 23780
    },
    {
      "epoch": 8.672985781990521,
      "grad_norm": 0.0002273412683280185,
      "learning_rate": 2.6540284360189576e-06,
      "loss": 0.0024,
      "step": 23790
    },
    {
      "epoch": 8.67663142544659,
      "grad_norm": 0.8353422284126282,
      "learning_rate": 2.6467371491068176e-06,
      "loss": 0.0082,
      "step": 23800
    },
    {
      "epoch": 8.680277068902662,
      "grad_norm": 0.0005153043894097209,
      "learning_rate": 2.6394458621946776e-06,
      "loss": 0.032,
      "step": 23810
    },
    {
      "epoch": 8.683922712358731,
      "grad_norm": 7.968482532305643e-05,
      "learning_rate": 2.6321545752825376e-06,
      "loss": 0.0002,
      "step": 23820
    },
    {
      "epoch": 8.6875683558148,
      "grad_norm": 0.00012009220517938957,
      "learning_rate": 2.6248632883703976e-06,
      "loss": 0.0123,
      "step": 23830
    },
    {
      "epoch": 8.691213999270872,
      "grad_norm": 0.8769733309745789,
      "learning_rate": 2.6175720014582576e-06,
      "loss": 0.0108,
      "step": 23840
    },
    {
      "epoch": 8.694859642726941,
      "grad_norm": 0.00029157864628359675,
      "learning_rate": 2.6102807145461177e-06,
      "loss": 0.0001,
      "step": 23850
    },
    {
      "epoch": 8.69850528618301,
      "grad_norm": 0.00024582823971286416,
      "learning_rate": 2.602989427633978e-06,
      "loss": 0.0106,
      "step": 23860
    },
    {
      "epoch": 8.702150929639082,
      "grad_norm": 0.00041745862108655274,
      "learning_rate": 2.5956981407218373e-06,
      "loss": 0.0039,
      "step": 23870
    },
    {
      "epoch": 8.705796573095151,
      "grad_norm": 0.013030631467700005,
      "learning_rate": 2.5884068538096973e-06,
      "loss": 0.0101,
      "step": 23880
    },
    {
      "epoch": 8.70944221655122,
      "grad_norm": 0.0002815519110299647,
      "learning_rate": 2.5811155668975573e-06,
      "loss": 0.0,
      "step": 23890
    },
    {
      "epoch": 8.713087860007292,
      "grad_norm": 0.00013686703459825367,
      "learning_rate": 2.5738242799854173e-06,
      "loss": 0.0,
      "step": 23900
    },
    {
      "epoch": 8.716733503463361,
      "grad_norm": 0.0003077318542636931,
      "learning_rate": 2.5665329930732773e-06,
      "loss": 0.0062,
      "step": 23910
    },
    {
      "epoch": 8.72037914691943,
      "grad_norm": 0.00018243103113491088,
      "learning_rate": 2.5592417061611373e-06,
      "loss": 0.0121,
      "step": 23920
    },
    {
      "epoch": 8.724024790375502,
      "grad_norm": 0.11146734654903412,
      "learning_rate": 2.5519504192489973e-06,
      "loss": 0.0018,
      "step": 23930
    },
    {
      "epoch": 8.727670433831571,
      "grad_norm": 0.00012184094521217048,
      "learning_rate": 2.5446591323368573e-06,
      "loss": 0.021,
      "step": 23940
    },
    {
      "epoch": 8.73131607728764,
      "grad_norm": 0.00011783848458435386,
      "learning_rate": 2.5373678454247173e-06,
      "loss": 0.0022,
      "step": 23950
    },
    {
      "epoch": 8.734961720743712,
      "grad_norm": 0.000761079543735832,
      "learning_rate": 2.5300765585125773e-06,
      "loss": 0.0011,
      "step": 23960
    },
    {
      "epoch": 8.738607364199781,
      "grad_norm": 0.020519983023405075,
      "learning_rate": 2.5227852716004374e-06,
      "loss": 0.0088,
      "step": 23970
    },
    {
      "epoch": 8.742253007655851,
      "grad_norm": 2.2774930000305176,
      "learning_rate": 2.5154939846882974e-06,
      "loss": 0.0057,
      "step": 23980
    },
    {
      "epoch": 8.745898651111922,
      "grad_norm": 0.0005041147232986987,
      "learning_rate": 2.5082026977761574e-06,
      "loss": 0.0077,
      "step": 23990
    },
    {
      "epoch": 8.749544294567992,
      "grad_norm": 0.002230991842225194,
      "learning_rate": 2.5009114108640174e-06,
      "loss": 0.0052,
      "step": 24000
    },
    {
      "epoch": 8.753189938024061,
      "grad_norm": 0.008100134320557117,
      "learning_rate": 2.4936201239518774e-06,
      "loss": 0.0034,
      "step": 24010
    },
    {
      "epoch": 8.75683558148013,
      "grad_norm": 0.0003628911217674613,
      "learning_rate": 2.4863288370397374e-06,
      "loss": 0.0015,
      "step": 24020
    },
    {
      "epoch": 8.760481224936202,
      "grad_norm": 0.0009379842085763812,
      "learning_rate": 2.4790375501275974e-06,
      "loss": 0.0013,
      "step": 24030
    },
    {
      "epoch": 8.764126868392271,
      "grad_norm": 0.0003034485562238842,
      "learning_rate": 2.4717462632154574e-06,
      "loss": 0.0037,
      "step": 24040
    },
    {
      "epoch": 8.76777251184834,
      "grad_norm": 0.00013940708595328033,
      "learning_rate": 2.4644549763033174e-06,
      "loss": 0.0161,
      "step": 24050
    },
    {
      "epoch": 8.771418155304412,
      "grad_norm": 6.537036895751953,
      "learning_rate": 2.457163689391178e-06,
      "loss": 0.0256,
      "step": 24060
    },
    {
      "epoch": 8.775063798760481,
      "grad_norm": 0.018006103113293648,
      "learning_rate": 2.449872402479038e-06,
      "loss": 0.0051,
      "step": 24070
    },
    {
      "epoch": 8.77870944221655,
      "grad_norm": 0.0029793076682835817,
      "learning_rate": 2.442581115566898e-06,
      "loss": 0.0025,
      "step": 24080
    },
    {
      "epoch": 8.782355085672622,
      "grad_norm": 0.5310900807380676,
      "learning_rate": 2.435289828654758e-06,
      "loss": 0.0006,
      "step": 24090
    },
    {
      "epoch": 8.786000729128691,
      "grad_norm": 0.0047660465352237225,
      "learning_rate": 2.427998541742618e-06,
      "loss": 0.0071,
      "step": 24100
    },
    {
      "epoch": 8.78964637258476,
      "grad_norm": 0.0001417322491761297,
      "learning_rate": 2.420707254830478e-06,
      "loss": 0.0022,
      "step": 24110
    },
    {
      "epoch": 8.793292016040832,
      "grad_norm": 0.003406069241464138,
      "learning_rate": 2.413415967918338e-06,
      "loss": 0.007,
      "step": 24120
    },
    {
      "epoch": 8.796937659496901,
      "grad_norm": 0.00039211902185343206,
      "learning_rate": 2.406124681006198e-06,
      "loss": 0.0036,
      "step": 24130
    },
    {
      "epoch": 8.80058330295297,
      "grad_norm": 0.0003571116249077022,
      "learning_rate": 2.398833394094058e-06,
      "loss": 0.0031,
      "step": 24140
    },
    {
      "epoch": 8.804228946409042,
      "grad_norm": 0.0004912014119327068,
      "learning_rate": 2.391542107181918e-06,
      "loss": 0.0068,
      "step": 24150
    },
    {
      "epoch": 8.807874589865111,
      "grad_norm": 0.002052493393421173,
      "learning_rate": 2.384250820269778e-06,
      "loss": 0.0047,
      "step": 24160
    },
    {
      "epoch": 8.81152023332118,
      "grad_norm": 0.00018466959591023624,
      "learning_rate": 2.376959533357638e-06,
      "loss": 0.0022,
      "step": 24170
    },
    {
      "epoch": 8.81516587677725,
      "grad_norm": 0.0009765902068465948,
      "learning_rate": 2.369668246445498e-06,
      "loss": 0.0012,
      "step": 24180
    },
    {
      "epoch": 8.818811520233321,
      "grad_norm": 9.194688755087554e-05,
      "learning_rate": 2.362376959533358e-06,
      "loss": 0.0055,
      "step": 24190
    },
    {
      "epoch": 8.822457163689391,
      "grad_norm": 0.0004142147081438452,
      "learning_rate": 2.355085672621218e-06,
      "loss": 0.0176,
      "step": 24200
    },
    {
      "epoch": 8.82610280714546,
      "grad_norm": 0.6746460199356079,
      "learning_rate": 2.347794385709078e-06,
      "loss": 0.0036,
      "step": 24210
    },
    {
      "epoch": 8.829748450601532,
      "grad_norm": 0.00016974042227957398,
      "learning_rate": 2.340503098796938e-06,
      "loss": 0.0,
      "step": 24220
    },
    {
      "epoch": 8.833394094057601,
      "grad_norm": 8.87125133886002e-05,
      "learning_rate": 2.333211811884798e-06,
      "loss": 0.006,
      "step": 24230
    },
    {
      "epoch": 8.83703973751367,
      "grad_norm": 0.00018111118697561324,
      "learning_rate": 2.325920524972658e-06,
      "loss": 0.0016,
      "step": 24240
    },
    {
      "epoch": 8.840685380969742,
      "grad_norm": 0.015403550118207932,
      "learning_rate": 2.318629238060518e-06,
      "loss": 0.0025,
      "step": 24250
    },
    {
      "epoch": 8.844331024425811,
      "grad_norm": 0.0005157957784831524,
      "learning_rate": 2.311337951148378e-06,
      "loss": 0.0016,
      "step": 24260
    },
    {
      "epoch": 8.84797666788188,
      "grad_norm": 0.043882276862859726,
      "learning_rate": 2.304046664236238e-06,
      "loss": 0.0029,
      "step": 24270
    },
    {
      "epoch": 8.851622311337952,
      "grad_norm": 0.00040582704241387546,
      "learning_rate": 2.2967553773240977e-06,
      "loss": 0.0038,
      "step": 24280
    },
    {
      "epoch": 8.855267954794021,
      "grad_norm": 1.5721254348754883,
      "learning_rate": 2.2894640904119577e-06,
      "loss": 0.0086,
      "step": 24290
    },
    {
      "epoch": 8.85891359825009,
      "grad_norm": 0.0005777518381364644,
      "learning_rate": 2.2821728034998177e-06,
      "loss": 0.0257,
      "step": 24300
    },
    {
      "epoch": 8.862559241706162,
      "grad_norm": 1.6804701089859009,
      "learning_rate": 2.2748815165876777e-06,
      "loss": 0.0101,
      "step": 24310
    },
    {
      "epoch": 8.866204885162231,
      "grad_norm": 0.0004309906216803938,
      "learning_rate": 2.2675902296755377e-06,
      "loss": 0.0017,
      "step": 24320
    },
    {
      "epoch": 8.8698505286183,
      "grad_norm": 0.0001486580295022577,
      "learning_rate": 2.2602989427633977e-06,
      "loss": 0.0136,
      "step": 24330
    },
    {
      "epoch": 8.873496172074372,
      "grad_norm": 1.9910908937454224,
      "learning_rate": 2.2530076558512577e-06,
      "loss": 0.0145,
      "step": 24340
    },
    {
      "epoch": 8.877141815530441,
      "grad_norm": 1.61897611618042,
      "learning_rate": 2.2457163689391177e-06,
      "loss": 0.0079,
      "step": 24350
    },
    {
      "epoch": 8.88078745898651,
      "grad_norm": 7.327873754547909e-05,
      "learning_rate": 2.2384250820269777e-06,
      "loss": 0.003,
      "step": 24360
    },
    {
      "epoch": 8.884433102442582,
      "grad_norm": 0.03601115569472313,
      "learning_rate": 2.2311337951148378e-06,
      "loss": 0.0063,
      "step": 24370
    },
    {
      "epoch": 8.888078745898651,
      "grad_norm": 0.0004204732831567526,
      "learning_rate": 2.2238425082026978e-06,
      "loss": 0.0,
      "step": 24380
    },
    {
      "epoch": 8.89172438935472,
      "grad_norm": 10.917570114135742,
      "learning_rate": 2.2165512212905578e-06,
      "loss": 0.0157,
      "step": 24390
    },
    {
      "epoch": 8.89537003281079,
      "grad_norm": 0.00011126422032248229,
      "learning_rate": 2.209259934378418e-06,
      "loss": 0.0111,
      "step": 24400
    },
    {
      "epoch": 8.899015676266862,
      "grad_norm": 0.00013691380445379764,
      "learning_rate": 2.201968647466278e-06,
      "loss": 0.0045,
      "step": 24410
    },
    {
      "epoch": 8.902661319722931,
      "grad_norm": 0.00013395269343163818,
      "learning_rate": 2.194677360554138e-06,
      "loss": 0.0085,
      "step": 24420
    },
    {
      "epoch": 8.906306963179,
      "grad_norm": 0.0001853456924436614,
      "learning_rate": 2.187386073641998e-06,
      "loss": 0.0,
      "step": 24430
    },
    {
      "epoch": 8.909952606635072,
      "grad_norm": 0.0002323981316294521,
      "learning_rate": 2.180094786729858e-06,
      "loss": 0.0274,
      "step": 24440
    },
    {
      "epoch": 8.913598250091141,
      "grad_norm": 0.0013863755157217383,
      "learning_rate": 2.172803499817718e-06,
      "loss": 0.0028,
      "step": 24450
    },
    {
      "epoch": 8.91724389354721,
      "grad_norm": 0.00012780455290339887,
      "learning_rate": 2.165512212905578e-06,
      "loss": 0.002,
      "step": 24460
    },
    {
      "epoch": 8.920889537003282,
      "grad_norm": 0.03788198530673981,
      "learning_rate": 2.1582209259934383e-06,
      "loss": 0.0064,
      "step": 24470
    },
    {
      "epoch": 8.924535180459351,
      "grad_norm": 0.0029805125668644905,
      "learning_rate": 2.1509296390812983e-06,
      "loss": 0.0025,
      "step": 24480
    },
    {
      "epoch": 8.92818082391542,
      "grad_norm": 1.9473626613616943,
      "learning_rate": 2.1436383521691583e-06,
      "loss": 0.0087,
      "step": 24490
    },
    {
      "epoch": 8.931826467371492,
      "grad_norm": 1.0157619714736938,
      "learning_rate": 2.1363470652570183e-06,
      "loss": 0.0089,
      "step": 24500
    },
    {
      "epoch": 8.935472110827561,
      "grad_norm": 0.0002411314198980108,
      "learning_rate": 2.1290557783448783e-06,
      "loss": 0.0117,
      "step": 24510
    },
    {
      "epoch": 8.93911775428363,
      "grad_norm": 0.00028704330907203257,
      "learning_rate": 2.1217644914327383e-06,
      "loss": 0.0025,
      "step": 24520
    },
    {
      "epoch": 8.942763397739702,
      "grad_norm": 0.0008475131471641362,
      "learning_rate": 2.1144732045205983e-06,
      "loss": 0.0096,
      "step": 24530
    },
    {
      "epoch": 8.946409041195771,
      "grad_norm": 0.00011168311175424606,
      "learning_rate": 2.1071819176084584e-06,
      "loss": 0.0,
      "step": 24540
    },
    {
      "epoch": 8.95005468465184,
      "grad_norm": 0.00039743067463859916,
      "learning_rate": 2.099890630696318e-06,
      "loss": 0.0005,
      "step": 24550
    },
    {
      "epoch": 8.95370032810791,
      "grad_norm": 0.003709078300744295,
      "learning_rate": 2.092599343784178e-06,
      "loss": 0.0005,
      "step": 24560
    },
    {
      "epoch": 8.957345971563981,
      "grad_norm": 0.00011187276686541736,
      "learning_rate": 2.085308056872038e-06,
      "loss": 0.0001,
      "step": 24570
    },
    {
      "epoch": 8.96099161502005,
      "grad_norm": 0.037098921835422516,
      "learning_rate": 2.078016769959898e-06,
      "loss": 0.0038,
      "step": 24580
    },
    {
      "epoch": 8.96463725847612,
      "grad_norm": 0.00018717280181590468,
      "learning_rate": 2.070725483047758e-06,
      "loss": 0.0071,
      "step": 24590
    },
    {
      "epoch": 8.968282901932191,
      "grad_norm": 0.0016101864166557789,
      "learning_rate": 2.063434196135618e-06,
      "loss": 0.0086,
      "step": 24600
    },
    {
      "epoch": 8.971928545388261,
      "grad_norm": 0.000262152636423707,
      "learning_rate": 2.056142909223478e-06,
      "loss": 0.0072,
      "step": 24610
    },
    {
      "epoch": 8.97557418884433,
      "grad_norm": 0.0017654087860137224,
      "learning_rate": 2.048851622311338e-06,
      "loss": 0.0045,
      "step": 24620
    },
    {
      "epoch": 8.979219832300402,
      "grad_norm": 0.0011569669004529715,
      "learning_rate": 2.041560335399198e-06,
      "loss": 0.0074,
      "step": 24630
    },
    {
      "epoch": 8.982865475756471,
      "grad_norm": 0.00014969058975111693,
      "learning_rate": 2.034269048487058e-06,
      "loss": 0.0,
      "step": 24640
    },
    {
      "epoch": 8.98651111921254,
      "grad_norm": 0.00021989995730109513,
      "learning_rate": 2.026977761574918e-06,
      "loss": 0.0031,
      "step": 24650
    },
    {
      "epoch": 8.990156762668612,
      "grad_norm": 1.1268794536590576,
      "learning_rate": 2.019686474662778e-06,
      "loss": 0.0027,
      "step": 24660
    },
    {
      "epoch": 8.993802406124681,
      "grad_norm": 0.0007114868494682014,
      "learning_rate": 2.012395187750638e-06,
      "loss": 0.0055,
      "step": 24670
    },
    {
      "epoch": 8.99744804958075,
      "grad_norm": 0.000399523094529286,
      "learning_rate": 2.005103900838498e-06,
      "loss": 0.0071,
      "step": 24680
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9924403747870528,
      "eval_f1": 0.969645147498931,
      "eval_loss": 0.03712029755115509,
      "eval_precision": 0.9713062098501071,
      "eval_recall": 0.967989756722151,
      "eval_runtime": 811.3786,
      "eval_samples_per_second": 23.188,
      "eval_steps_per_second": 0.725,
      "step": 24687
    }
  ],
  "logging_steps": 10,
  "max_steps": 27430,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7129048997445632e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
