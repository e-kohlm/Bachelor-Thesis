{
  "best_metric": 0.9672355799177774,
  "best_model_checkpoint": "../saved_models/sql_770/checkpoint-83000",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 83000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00012048192771084337,
      "grad_norm": 38.514583587646484,
      "learning_rate": 1.999975903614458e-05,
      "loss": 1.0422,
      "step": 1
    },
    {
      "epoch": 0.0012048192771084338,
      "grad_norm": 29.48005485534668,
      "learning_rate": 1.9997590361445783e-05,
      "loss": 0.6481,
      "step": 10
    },
    {
      "epoch": 0.0024096385542168677,
      "grad_norm": 30.470157623291016,
      "learning_rate": 1.9995180722891568e-05,
      "loss": 0.5862,
      "step": 20
    },
    {
      "epoch": 0.0036144578313253013,
      "grad_norm": 24.42165756225586,
      "learning_rate": 1.999277108433735e-05,
      "loss": 0.5479,
      "step": 30
    },
    {
      "epoch": 0.004819277108433735,
      "grad_norm": 24.691486358642578,
      "learning_rate": 1.9990361445783134e-05,
      "loss": 0.4972,
      "step": 40
    },
    {
      "epoch": 0.006024096385542169,
      "grad_norm": 29.097822189331055,
      "learning_rate": 1.998795180722892e-05,
      "loss": 0.5199,
      "step": 50
    },
    {
      "epoch": 0.007228915662650603,
      "grad_norm": 19.533056259155273,
      "learning_rate": 1.99855421686747e-05,
      "loss": 0.5416,
      "step": 60
    },
    {
      "epoch": 0.008433734939759036,
      "grad_norm": 23.896738052368164,
      "learning_rate": 1.9983132530120482e-05,
      "loss": 0.4684,
      "step": 70
    },
    {
      "epoch": 0.00963855421686747,
      "grad_norm": 23.56159019470215,
      "learning_rate": 1.9980722891566267e-05,
      "loss": 0.4682,
      "step": 80
    },
    {
      "epoch": 0.010843373493975903,
      "grad_norm": 12.12376594543457,
      "learning_rate": 1.997831325301205e-05,
      "loss": 0.4617,
      "step": 90
    },
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 16.081430435180664,
      "learning_rate": 1.9975903614457833e-05,
      "loss": 0.4088,
      "step": 100
    },
    {
      "epoch": 0.01325301204819277,
      "grad_norm": 18.7154483795166,
      "learning_rate": 1.9973493975903615e-05,
      "loss": 0.4438,
      "step": 110
    },
    {
      "epoch": 0.014457831325301205,
      "grad_norm": 20.34906578063965,
      "learning_rate": 1.99710843373494e-05,
      "loss": 0.4863,
      "step": 120
    },
    {
      "epoch": 0.01566265060240964,
      "grad_norm": 21.796510696411133,
      "learning_rate": 1.9968674698795185e-05,
      "loss": 0.3773,
      "step": 130
    },
    {
      "epoch": 0.016867469879518072,
      "grad_norm": 21.2525577545166,
      "learning_rate": 1.9966265060240966e-05,
      "loss": 0.4208,
      "step": 140
    },
    {
      "epoch": 0.018072289156626505,
      "grad_norm": 14.115873336791992,
      "learning_rate": 1.9963855421686748e-05,
      "loss": 0.4027,
      "step": 150
    },
    {
      "epoch": 0.01927710843373494,
      "grad_norm": 13.841994285583496,
      "learning_rate": 1.9961445783132532e-05,
      "loss": 0.5681,
      "step": 160
    },
    {
      "epoch": 0.020481927710843374,
      "grad_norm": 11.967397689819336,
      "learning_rate": 1.9959036144578314e-05,
      "loss": 0.4921,
      "step": 170
    },
    {
      "epoch": 0.021686746987951807,
      "grad_norm": 15.426846504211426,
      "learning_rate": 1.99566265060241e-05,
      "loss": 0.4162,
      "step": 180
    },
    {
      "epoch": 0.02289156626506024,
      "grad_norm": 12.500714302062988,
      "learning_rate": 1.9954216867469884e-05,
      "loss": 0.3818,
      "step": 190
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 20.845571517944336,
      "learning_rate": 1.9951807228915665e-05,
      "loss": 0.5088,
      "step": 200
    },
    {
      "epoch": 0.02530120481927711,
      "grad_norm": 12.728619575500488,
      "learning_rate": 1.9949397590361447e-05,
      "loss": 0.4481,
      "step": 210
    },
    {
      "epoch": 0.02650602409638554,
      "grad_norm": 19.613502502441406,
      "learning_rate": 1.994698795180723e-05,
      "loss": 0.4287,
      "step": 220
    },
    {
      "epoch": 0.027710843373493974,
      "grad_norm": 8.475048065185547,
      "learning_rate": 1.9944578313253013e-05,
      "loss": 0.4882,
      "step": 230
    },
    {
      "epoch": 0.02891566265060241,
      "grad_norm": 10.927054405212402,
      "learning_rate": 1.9942168674698798e-05,
      "loss": 0.4605,
      "step": 240
    },
    {
      "epoch": 0.030120481927710843,
      "grad_norm": 11.121585845947266,
      "learning_rate": 1.993975903614458e-05,
      "loss": 0.4061,
      "step": 250
    },
    {
      "epoch": 0.03132530120481928,
      "grad_norm": 8.517807006835938,
      "learning_rate": 1.993734939759036e-05,
      "loss": 0.3604,
      "step": 260
    },
    {
      "epoch": 0.03253012048192771,
      "grad_norm": 11.554676055908203,
      "learning_rate": 1.9934939759036146e-05,
      "loss": 0.3454,
      "step": 270
    },
    {
      "epoch": 0.033734939759036145,
      "grad_norm": 7.484226226806641,
      "learning_rate": 1.993253012048193e-05,
      "loss": 0.4437,
      "step": 280
    },
    {
      "epoch": 0.03493975903614458,
      "grad_norm": 5.4318718910217285,
      "learning_rate": 1.9930120481927712e-05,
      "loss": 0.3941,
      "step": 290
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 10.204075813293457,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 0.4507,
      "step": 300
    },
    {
      "epoch": 0.03734939759036145,
      "grad_norm": 7.894901752471924,
      "learning_rate": 1.992530120481928e-05,
      "loss": 0.3666,
      "step": 310
    },
    {
      "epoch": 0.03855421686746988,
      "grad_norm": 7.022729396820068,
      "learning_rate": 1.992289156626506e-05,
      "loss": 0.3218,
      "step": 320
    },
    {
      "epoch": 0.03975903614457831,
      "grad_norm": 14.107623100280762,
      "learning_rate": 1.9920481927710845e-05,
      "loss": 0.3814,
      "step": 330
    },
    {
      "epoch": 0.04096385542168675,
      "grad_norm": 7.917597770690918,
      "learning_rate": 1.991807228915663e-05,
      "loss": 0.3802,
      "step": 340
    },
    {
      "epoch": 0.04216867469879518,
      "grad_norm": 10.857300758361816,
      "learning_rate": 1.991566265060241e-05,
      "loss": 0.417,
      "step": 350
    },
    {
      "epoch": 0.043373493975903614,
      "grad_norm": 6.557294845581055,
      "learning_rate": 1.9913253012048196e-05,
      "loss": 0.4489,
      "step": 360
    },
    {
      "epoch": 0.04457831325301205,
      "grad_norm": 9.838905334472656,
      "learning_rate": 1.9910843373493977e-05,
      "loss": 0.4458,
      "step": 370
    },
    {
      "epoch": 0.04578313253012048,
      "grad_norm": 5.813967704772949,
      "learning_rate": 1.990843373493976e-05,
      "loss": 0.438,
      "step": 380
    },
    {
      "epoch": 0.046987951807228916,
      "grad_norm": 6.434326648712158,
      "learning_rate": 1.9906024096385544e-05,
      "loss": 0.3826,
      "step": 390
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 9.150263786315918,
      "learning_rate": 1.9903614457831325e-05,
      "loss": 0.3913,
      "step": 400
    },
    {
      "epoch": 0.04939759036144578,
      "grad_norm": 7.70619535446167,
      "learning_rate": 1.990120481927711e-05,
      "loss": 0.4397,
      "step": 410
    },
    {
      "epoch": 0.05060240963855422,
      "grad_norm": 8.212285995483398,
      "learning_rate": 1.9898795180722895e-05,
      "loss": 0.4064,
      "step": 420
    },
    {
      "epoch": 0.051807228915662654,
      "grad_norm": 7.181381702423096,
      "learning_rate": 1.9896385542168677e-05,
      "loss": 0.3113,
      "step": 430
    },
    {
      "epoch": 0.05301204819277108,
      "grad_norm": 7.630715847015381,
      "learning_rate": 1.989397590361446e-05,
      "loss": 0.3177,
      "step": 440
    },
    {
      "epoch": 0.05421686746987952,
      "grad_norm": 11.775872230529785,
      "learning_rate": 1.9891566265060243e-05,
      "loss": 0.4231,
      "step": 450
    },
    {
      "epoch": 0.05542168674698795,
      "grad_norm": 4.915464878082275,
      "learning_rate": 1.9889156626506024e-05,
      "loss": 0.3345,
      "step": 460
    },
    {
      "epoch": 0.056626506024096385,
      "grad_norm": 8.405253410339355,
      "learning_rate": 1.988674698795181e-05,
      "loss": 0.3597,
      "step": 470
    },
    {
      "epoch": 0.05783132530120482,
      "grad_norm": 6.320950984954834,
      "learning_rate": 1.988433734939759e-05,
      "loss": 0.3231,
      "step": 480
    },
    {
      "epoch": 0.05903614457831325,
      "grad_norm": 5.689597129821777,
      "learning_rate": 1.9881927710843376e-05,
      "loss": 0.3909,
      "step": 490
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 16.484634399414062,
      "learning_rate": 1.987951807228916e-05,
      "loss": 0.3033,
      "step": 500
    },
    {
      "epoch": 0.06144578313253012,
      "grad_norm": 9.283970832824707,
      "learning_rate": 1.9877108433734942e-05,
      "loss": 0.3726,
      "step": 510
    },
    {
      "epoch": 0.06265060240963856,
      "grad_norm": 4.286323070526123,
      "learning_rate": 1.9874698795180723e-05,
      "loss": 0.3762,
      "step": 520
    },
    {
      "epoch": 0.06385542168674699,
      "grad_norm": 5.406025409698486,
      "learning_rate": 1.9872289156626508e-05,
      "loss": 0.3078,
      "step": 530
    },
    {
      "epoch": 0.06506024096385542,
      "grad_norm": 23.856595993041992,
      "learning_rate": 1.986987951807229e-05,
      "loss": 0.364,
      "step": 540
    },
    {
      "epoch": 0.06626506024096386,
      "grad_norm": 11.641674041748047,
      "learning_rate": 1.9867469879518075e-05,
      "loss": 0.3191,
      "step": 550
    },
    {
      "epoch": 0.06746987951807229,
      "grad_norm": 4.647512435913086,
      "learning_rate": 1.9865060240963856e-05,
      "loss": 0.4039,
      "step": 560
    },
    {
      "epoch": 0.06867469879518072,
      "grad_norm": 7.260754585266113,
      "learning_rate": 1.986265060240964e-05,
      "loss": 0.3306,
      "step": 570
    },
    {
      "epoch": 0.06987951807228916,
      "grad_norm": 6.032602310180664,
      "learning_rate": 1.9860240963855422e-05,
      "loss": 0.3915,
      "step": 580
    },
    {
      "epoch": 0.07108433734939759,
      "grad_norm": 6.995845317840576,
      "learning_rate": 1.9857831325301207e-05,
      "loss": 0.4341,
      "step": 590
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 7.485309600830078,
      "learning_rate": 1.985542168674699e-05,
      "loss": 0.3376,
      "step": 600
    },
    {
      "epoch": 0.07349397590361446,
      "grad_norm": 6.964789867401123,
      "learning_rate": 1.9853012048192774e-05,
      "loss": 0.3159,
      "step": 610
    },
    {
      "epoch": 0.0746987951807229,
      "grad_norm": 7.404204845428467,
      "learning_rate": 1.9850602409638555e-05,
      "loss": 0.4224,
      "step": 620
    },
    {
      "epoch": 0.07590361445783132,
      "grad_norm": 5.882349967956543,
      "learning_rate": 1.9848192771084337e-05,
      "loss": 0.3359,
      "step": 630
    },
    {
      "epoch": 0.07710843373493977,
      "grad_norm": 11.70466136932373,
      "learning_rate": 1.984578313253012e-05,
      "loss": 0.355,
      "step": 640
    },
    {
      "epoch": 0.0783132530120482,
      "grad_norm": 6.175135135650635,
      "learning_rate": 1.9843373493975906e-05,
      "loss": 0.2895,
      "step": 650
    },
    {
      "epoch": 0.07951807228915662,
      "grad_norm": 7.506266117095947,
      "learning_rate": 1.9840963855421688e-05,
      "loss": 0.3231,
      "step": 660
    },
    {
      "epoch": 0.08072289156626505,
      "grad_norm": 7.270594120025635,
      "learning_rate": 1.9838554216867473e-05,
      "loss": 0.3972,
      "step": 670
    },
    {
      "epoch": 0.0819277108433735,
      "grad_norm": 7.432936191558838,
      "learning_rate": 1.9836144578313254e-05,
      "loss": 0.3447,
      "step": 680
    },
    {
      "epoch": 0.08313253012048193,
      "grad_norm": 6.350452423095703,
      "learning_rate": 1.9833734939759036e-05,
      "loss": 0.3414,
      "step": 690
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 9.59085750579834,
      "learning_rate": 1.983132530120482e-05,
      "loss": 0.3583,
      "step": 700
    },
    {
      "epoch": 0.0855421686746988,
      "grad_norm": 8.847679138183594,
      "learning_rate": 1.9828915662650602e-05,
      "loss": 0.3464,
      "step": 710
    },
    {
      "epoch": 0.08674698795180723,
      "grad_norm": 5.152771472930908,
      "learning_rate": 1.9826506024096387e-05,
      "loss": 0.3566,
      "step": 720
    },
    {
      "epoch": 0.08795180722891566,
      "grad_norm": 12.622859954833984,
      "learning_rate": 1.9824096385542172e-05,
      "loss": 0.3515,
      "step": 730
    },
    {
      "epoch": 0.0891566265060241,
      "grad_norm": 8.950844764709473,
      "learning_rate": 1.9821686746987953e-05,
      "loss": 0.311,
      "step": 740
    },
    {
      "epoch": 0.09036144578313253,
      "grad_norm": 6.870842933654785,
      "learning_rate": 1.9819277108433738e-05,
      "loss": 0.2614,
      "step": 750
    },
    {
      "epoch": 0.09156626506024096,
      "grad_norm": 7.676474571228027,
      "learning_rate": 1.981686746987952e-05,
      "loss": 0.2941,
      "step": 760
    },
    {
      "epoch": 0.0927710843373494,
      "grad_norm": 4.7319111824035645,
      "learning_rate": 1.98144578313253e-05,
      "loss": 0.3172,
      "step": 770
    },
    {
      "epoch": 0.09397590361445783,
      "grad_norm": 5.985496997833252,
      "learning_rate": 1.9812048192771086e-05,
      "loss": 0.2844,
      "step": 780
    },
    {
      "epoch": 0.09518072289156626,
      "grad_norm": 10.027395248413086,
      "learning_rate": 1.980963855421687e-05,
      "loss": 0.2933,
      "step": 790
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 14.725357055664062,
      "learning_rate": 1.9807228915662652e-05,
      "loss": 0.3984,
      "step": 800
    },
    {
      "epoch": 0.09759036144578313,
      "grad_norm": 10.941905975341797,
      "learning_rate": 1.9804819277108437e-05,
      "loss": 0.4269,
      "step": 810
    },
    {
      "epoch": 0.09879518072289156,
      "grad_norm": 4.857684135437012,
      "learning_rate": 1.980240963855422e-05,
      "loss": 0.2846,
      "step": 820
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6704209446907043,
      "learning_rate": 1.98e-05,
      "loss": 0.2696,
      "step": 830
    },
    {
      "epoch": 0.10120481927710843,
      "grad_norm": 11.597119331359863,
      "learning_rate": 1.9797590361445785e-05,
      "loss": 0.4125,
      "step": 840
    },
    {
      "epoch": 0.10240963855421686,
      "grad_norm": 8.747631072998047,
      "learning_rate": 1.9795180722891567e-05,
      "loss": 0.3665,
      "step": 850
    },
    {
      "epoch": 0.10361445783132531,
      "grad_norm": 7.25557804107666,
      "learning_rate": 1.979277108433735e-05,
      "loss": 0.2839,
      "step": 860
    },
    {
      "epoch": 0.10481927710843374,
      "grad_norm": 10.38675594329834,
      "learning_rate": 1.9790361445783136e-05,
      "loss": 0.3557,
      "step": 870
    },
    {
      "epoch": 0.10602409638554217,
      "grad_norm": 7.652352809906006,
      "learning_rate": 1.9787951807228918e-05,
      "loss": 0.2915,
      "step": 880
    },
    {
      "epoch": 0.10722891566265061,
      "grad_norm": 9.645233154296875,
      "learning_rate": 1.97855421686747e-05,
      "loss": 0.3793,
      "step": 890
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 8.821734428405762,
      "learning_rate": 1.9783132530120484e-05,
      "loss": 0.3021,
      "step": 900
    },
    {
      "epoch": 0.10963855421686747,
      "grad_norm": 4.602203369140625,
      "learning_rate": 1.9780722891566266e-05,
      "loss": 0.3592,
      "step": 910
    },
    {
      "epoch": 0.1108433734939759,
      "grad_norm": 6.376530647277832,
      "learning_rate": 1.977831325301205e-05,
      "loss": 0.3119,
      "step": 920
    },
    {
      "epoch": 0.11204819277108434,
      "grad_norm": 14.845179557800293,
      "learning_rate": 1.9775903614457832e-05,
      "loss": 0.3127,
      "step": 930
    },
    {
      "epoch": 0.11325301204819277,
      "grad_norm": 8.763700485229492,
      "learning_rate": 1.9773493975903617e-05,
      "loss": 0.3373,
      "step": 940
    },
    {
      "epoch": 0.1144578313253012,
      "grad_norm": 4.838342189788818,
      "learning_rate": 1.9771084337349398e-05,
      "loss": 0.3638,
      "step": 950
    },
    {
      "epoch": 0.11566265060240964,
      "grad_norm": 3.2633984088897705,
      "learning_rate": 1.9768674698795183e-05,
      "loss": 0.257,
      "step": 960
    },
    {
      "epoch": 0.11686746987951807,
      "grad_norm": 5.632139682769775,
      "learning_rate": 1.9766265060240965e-05,
      "loss": 0.3846,
      "step": 970
    },
    {
      "epoch": 0.1180722891566265,
      "grad_norm": 7.638646602630615,
      "learning_rate": 1.976385542168675e-05,
      "loss": 0.2831,
      "step": 980
    },
    {
      "epoch": 0.11927710843373494,
      "grad_norm": 7.435015678405762,
      "learning_rate": 1.976144578313253e-05,
      "loss": 0.3061,
      "step": 990
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 7.441319942474365,
      "learning_rate": 1.9759036144578312e-05,
      "loss": 0.2625,
      "step": 1000
    },
    {
      "epoch": 0.1216867469879518,
      "grad_norm": 4.156005382537842,
      "learning_rate": 1.9756626506024097e-05,
      "loss": 0.3438,
      "step": 1010
    },
    {
      "epoch": 0.12289156626506025,
      "grad_norm": 4.528852939605713,
      "learning_rate": 1.9754216867469882e-05,
      "loss": 0.2593,
      "step": 1020
    },
    {
      "epoch": 0.12409638554216867,
      "grad_norm": 6.294732093811035,
      "learning_rate": 1.9751807228915664e-05,
      "loss": 0.298,
      "step": 1030
    },
    {
      "epoch": 0.12530120481927712,
      "grad_norm": 4.106697082519531,
      "learning_rate": 1.974939759036145e-05,
      "loss": 0.2358,
      "step": 1040
    },
    {
      "epoch": 0.12650602409638553,
      "grad_norm": 8.825439453125,
      "learning_rate": 1.974698795180723e-05,
      "loss": 0.3307,
      "step": 1050
    },
    {
      "epoch": 0.12771084337349398,
      "grad_norm": 2.998837947845459,
      "learning_rate": 1.9744578313253015e-05,
      "loss": 0.2991,
      "step": 1060
    },
    {
      "epoch": 0.12891566265060242,
      "grad_norm": 6.165511608123779,
      "learning_rate": 1.9742168674698796e-05,
      "loss": 0.3166,
      "step": 1070
    },
    {
      "epoch": 0.13012048192771083,
      "grad_norm": 2.9896657466888428,
      "learning_rate": 1.9739759036144578e-05,
      "loss": 0.2155,
      "step": 1080
    },
    {
      "epoch": 0.13132530120481928,
      "grad_norm": 4.077345848083496,
      "learning_rate": 1.9737349397590363e-05,
      "loss": 0.2934,
      "step": 1090
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 5.697873115539551,
      "learning_rate": 1.9734939759036148e-05,
      "loss": 0.2756,
      "step": 1100
    },
    {
      "epoch": 0.13373493975903614,
      "grad_norm": 4.179478645324707,
      "learning_rate": 1.973253012048193e-05,
      "loss": 0.2869,
      "step": 1110
    },
    {
      "epoch": 0.13493975903614458,
      "grad_norm": 5.086875915527344,
      "learning_rate": 1.9730120481927714e-05,
      "loss": 0.3091,
      "step": 1120
    },
    {
      "epoch": 0.13614457831325302,
      "grad_norm": 15.41264533996582,
      "learning_rate": 1.9727710843373495e-05,
      "loss": 0.2635,
      "step": 1130
    },
    {
      "epoch": 0.13734939759036144,
      "grad_norm": 10.469223976135254,
      "learning_rate": 1.9725301204819277e-05,
      "loss": 0.3531,
      "step": 1140
    },
    {
      "epoch": 0.13855421686746988,
      "grad_norm": 6.728142738342285,
      "learning_rate": 1.9722891566265062e-05,
      "loss": 0.3267,
      "step": 1150
    },
    {
      "epoch": 0.13975903614457832,
      "grad_norm": 3.7738542556762695,
      "learning_rate": 1.9720481927710843e-05,
      "loss": 0.3547,
      "step": 1160
    },
    {
      "epoch": 0.14096385542168674,
      "grad_norm": 9.845900535583496,
      "learning_rate": 1.9718072289156628e-05,
      "loss": 0.3096,
      "step": 1170
    },
    {
      "epoch": 0.14216867469879518,
      "grad_norm": 8.631593704223633,
      "learning_rate": 1.9715662650602413e-05,
      "loss": 0.2733,
      "step": 1180
    },
    {
      "epoch": 0.14337349397590363,
      "grad_norm": 6.3264288902282715,
      "learning_rate": 1.9713253012048194e-05,
      "loss": 0.3614,
      "step": 1190
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 4.877671718597412,
      "learning_rate": 1.9710843373493976e-05,
      "loss": 0.2213,
      "step": 1200
    },
    {
      "epoch": 0.14578313253012049,
      "grad_norm": 7.402860164642334,
      "learning_rate": 1.970843373493976e-05,
      "loss": 0.2563,
      "step": 1210
    },
    {
      "epoch": 0.14698795180722893,
      "grad_norm": 6.027994632720947,
      "learning_rate": 1.9706024096385542e-05,
      "loss": 0.2446,
      "step": 1220
    },
    {
      "epoch": 0.14819277108433734,
      "grad_norm": 8.91256046295166,
      "learning_rate": 1.9703614457831327e-05,
      "loss": 0.2274,
      "step": 1230
    },
    {
      "epoch": 0.1493975903614458,
      "grad_norm": 6.789714336395264,
      "learning_rate": 1.9701204819277112e-05,
      "loss": 0.2335,
      "step": 1240
    },
    {
      "epoch": 0.15060240963855423,
      "grad_norm": 9.927338600158691,
      "learning_rate": 1.9698795180722894e-05,
      "loss": 0.2642,
      "step": 1250
    },
    {
      "epoch": 0.15180722891566265,
      "grad_norm": 10.547345161437988,
      "learning_rate": 1.9696385542168675e-05,
      "loss": 0.3418,
      "step": 1260
    },
    {
      "epoch": 0.1530120481927711,
      "grad_norm": 4.905123233795166,
      "learning_rate": 1.969397590361446e-05,
      "loss": 0.2173,
      "step": 1270
    },
    {
      "epoch": 0.15421686746987953,
      "grad_norm": 4.399948596954346,
      "learning_rate": 1.969156626506024e-05,
      "loss": 0.2926,
      "step": 1280
    },
    {
      "epoch": 0.15542168674698795,
      "grad_norm": 5.38467264175415,
      "learning_rate": 1.9689156626506026e-05,
      "loss": 0.2681,
      "step": 1290
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 5.378241062164307,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 0.3194,
      "step": 1300
    },
    {
      "epoch": 0.1578313253012048,
      "grad_norm": 6.40663480758667,
      "learning_rate": 1.968433734939759e-05,
      "loss": 0.267,
      "step": 1310
    },
    {
      "epoch": 0.15903614457831325,
      "grad_norm": 6.289916038513184,
      "learning_rate": 1.9681927710843377e-05,
      "loss": 0.2613,
      "step": 1320
    },
    {
      "epoch": 0.1602409638554217,
      "grad_norm": 8.572108268737793,
      "learning_rate": 1.967951807228916e-05,
      "loss": 0.3217,
      "step": 1330
    },
    {
      "epoch": 0.1614457831325301,
      "grad_norm": 5.265111446380615,
      "learning_rate": 1.967710843373494e-05,
      "loss": 0.3087,
      "step": 1340
    },
    {
      "epoch": 0.16265060240963855,
      "grad_norm": 5.996319770812988,
      "learning_rate": 1.9674698795180725e-05,
      "loss": 0.2544,
      "step": 1350
    },
    {
      "epoch": 0.163855421686747,
      "grad_norm": 11.257925987243652,
      "learning_rate": 1.9672289156626507e-05,
      "loss": 0.284,
      "step": 1360
    },
    {
      "epoch": 0.1650602409638554,
      "grad_norm": 7.496851921081543,
      "learning_rate": 1.966987951807229e-05,
      "loss": 0.271,
      "step": 1370
    },
    {
      "epoch": 0.16626506024096385,
      "grad_norm": 8.362955093383789,
      "learning_rate": 1.9667469879518073e-05,
      "loss": 0.2937,
      "step": 1380
    },
    {
      "epoch": 0.1674698795180723,
      "grad_norm": 6.1625237464904785,
      "learning_rate": 1.9665060240963858e-05,
      "loss": 0.202,
      "step": 1390
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 4.077919006347656,
      "learning_rate": 1.966265060240964e-05,
      "loss": 0.1364,
      "step": 1400
    },
    {
      "epoch": 0.16987951807228915,
      "grad_norm": 4.378210067749023,
      "learning_rate": 1.9660240963855424e-05,
      "loss": 0.2364,
      "step": 1410
    },
    {
      "epoch": 0.1710843373493976,
      "grad_norm": 6.197845935821533,
      "learning_rate": 1.9657831325301206e-05,
      "loss": 0.278,
      "step": 1420
    },
    {
      "epoch": 0.172289156626506,
      "grad_norm": 8.914730072021484,
      "learning_rate": 1.965542168674699e-05,
      "loss": 0.2966,
      "step": 1430
    },
    {
      "epoch": 0.17349397590361446,
      "grad_norm": 3.7909398078918457,
      "learning_rate": 1.9653012048192772e-05,
      "loss": 0.302,
      "step": 1440
    },
    {
      "epoch": 0.1746987951807229,
      "grad_norm": 6.048590183258057,
      "learning_rate": 1.9650602409638554e-05,
      "loss": 0.2985,
      "step": 1450
    },
    {
      "epoch": 0.17590361445783131,
      "grad_norm": 5.930118560791016,
      "learning_rate": 1.964819277108434e-05,
      "loss": 0.1913,
      "step": 1460
    },
    {
      "epoch": 0.17710843373493976,
      "grad_norm": 9.223210334777832,
      "learning_rate": 1.9645783132530123e-05,
      "loss": 0.2981,
      "step": 1470
    },
    {
      "epoch": 0.1783132530120482,
      "grad_norm": 3.526811122894287,
      "learning_rate": 1.9643373493975905e-05,
      "loss": 0.2115,
      "step": 1480
    },
    {
      "epoch": 0.17951807228915662,
      "grad_norm": 4.703396320343018,
      "learning_rate": 1.964096385542169e-05,
      "loss": 0.2333,
      "step": 1490
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 5.331099510192871,
      "learning_rate": 1.963855421686747e-05,
      "loss": 0.3265,
      "step": 1500
    },
    {
      "epoch": 0.1819277108433735,
      "grad_norm": 3.2960658073425293,
      "learning_rate": 1.9636144578313253e-05,
      "loss": 0.224,
      "step": 1510
    },
    {
      "epoch": 0.18313253012048192,
      "grad_norm": 7.034844398498535,
      "learning_rate": 1.9633734939759038e-05,
      "loss": 0.2825,
      "step": 1520
    },
    {
      "epoch": 0.18433734939759036,
      "grad_norm": 5.621352195739746,
      "learning_rate": 1.963132530120482e-05,
      "loss": 0.2248,
      "step": 1530
    },
    {
      "epoch": 0.1855421686746988,
      "grad_norm": 7.1347975730896,
      "learning_rate": 1.9628915662650604e-05,
      "loss": 0.2854,
      "step": 1540
    },
    {
      "epoch": 0.18674698795180722,
      "grad_norm": 2.6680498123168945,
      "learning_rate": 1.962650602409639e-05,
      "loss": 0.1683,
      "step": 1550
    },
    {
      "epoch": 0.18795180722891566,
      "grad_norm": 7.452640056610107,
      "learning_rate": 1.962409638554217e-05,
      "loss": 0.2248,
      "step": 1560
    },
    {
      "epoch": 0.1891566265060241,
      "grad_norm": 4.452322959899902,
      "learning_rate": 1.9621686746987955e-05,
      "loss": 0.2569,
      "step": 1570
    },
    {
      "epoch": 0.19036144578313252,
      "grad_norm": 7.003268241882324,
      "learning_rate": 1.9619277108433737e-05,
      "loss": 0.295,
      "step": 1580
    },
    {
      "epoch": 0.19156626506024096,
      "grad_norm": 5.294804573059082,
      "learning_rate": 1.9616867469879518e-05,
      "loss": 0.3301,
      "step": 1590
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 3.0852160453796387,
      "learning_rate": 1.9614457831325303e-05,
      "loss": 0.2014,
      "step": 1600
    },
    {
      "epoch": 0.19397590361445782,
      "grad_norm": 3.480224370956421,
      "learning_rate": 1.9612048192771085e-05,
      "loss": 0.2022,
      "step": 1610
    },
    {
      "epoch": 0.19518072289156627,
      "grad_norm": 9.730610847473145,
      "learning_rate": 1.960963855421687e-05,
      "loss": 0.2547,
      "step": 1620
    },
    {
      "epoch": 0.1963855421686747,
      "grad_norm": 2.526064157485962,
      "learning_rate": 1.9607228915662654e-05,
      "loss": 0.1867,
      "step": 1630
    },
    {
      "epoch": 0.19759036144578312,
      "grad_norm": 8.208475112915039,
      "learning_rate": 1.9604819277108436e-05,
      "loss": 0.1925,
      "step": 1640
    },
    {
      "epoch": 0.19879518072289157,
      "grad_norm": 4.754239559173584,
      "learning_rate": 1.9602409638554217e-05,
      "loss": 0.2268,
      "step": 1650
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.399302005767822,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.1768,
      "step": 1660
    },
    {
      "epoch": 0.20120481927710843,
      "grad_norm": 8.841812133789062,
      "learning_rate": 1.9597590361445784e-05,
      "loss": 0.1789,
      "step": 1670
    },
    {
      "epoch": 0.20240963855421687,
      "grad_norm": 2.4974420070648193,
      "learning_rate": 1.959518072289157e-05,
      "loss": 0.177,
      "step": 1680
    },
    {
      "epoch": 0.2036144578313253,
      "grad_norm": 8.58941650390625,
      "learning_rate": 1.9592771084337353e-05,
      "loss": 0.2777,
      "step": 1690
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 6.2035722732543945,
      "learning_rate": 1.9590361445783135e-05,
      "loss": 0.3105,
      "step": 1700
    },
    {
      "epoch": 0.20602409638554217,
      "grad_norm": 5.199103355407715,
      "learning_rate": 1.9587951807228916e-05,
      "loss": 0.242,
      "step": 1710
    },
    {
      "epoch": 0.20722891566265061,
      "grad_norm": 5.122499942779541,
      "learning_rate": 1.95855421686747e-05,
      "loss": 0.2561,
      "step": 1720
    },
    {
      "epoch": 0.20843373493975903,
      "grad_norm": 2.7231006622314453,
      "learning_rate": 1.9583132530120483e-05,
      "loss": 0.1937,
      "step": 1730
    },
    {
      "epoch": 0.20963855421686747,
      "grad_norm": 8.52288818359375,
      "learning_rate": 1.9580722891566267e-05,
      "loss": 0.1722,
      "step": 1740
    },
    {
      "epoch": 0.21084337349397592,
      "grad_norm": 8.555729866027832,
      "learning_rate": 1.957831325301205e-05,
      "loss": 0.2488,
      "step": 1750
    },
    {
      "epoch": 0.21204819277108433,
      "grad_norm": 3.2782442569732666,
      "learning_rate": 1.957590361445783e-05,
      "loss": 0.2374,
      "step": 1760
    },
    {
      "epoch": 0.21325301204819277,
      "grad_norm": 7.365923881530762,
      "learning_rate": 1.9573493975903615e-05,
      "loss": 0.2154,
      "step": 1770
    },
    {
      "epoch": 0.21445783132530122,
      "grad_norm": 3.795229434967041,
      "learning_rate": 1.95710843373494e-05,
      "loss": 0.2355,
      "step": 1780
    },
    {
      "epoch": 0.21566265060240963,
      "grad_norm": 9.327421188354492,
      "learning_rate": 1.956867469879518e-05,
      "loss": 0.1852,
      "step": 1790
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 5.032540798187256,
      "learning_rate": 1.9566265060240967e-05,
      "loss": 0.1959,
      "step": 1800
    },
    {
      "epoch": 0.21807228915662652,
      "grad_norm": 5.728634357452393,
      "learning_rate": 1.9563855421686748e-05,
      "loss": 0.1997,
      "step": 1810
    },
    {
      "epoch": 0.21927710843373494,
      "grad_norm": 6.171658039093018,
      "learning_rate": 1.956144578313253e-05,
      "loss": 0.2386,
      "step": 1820
    },
    {
      "epoch": 0.22048192771084338,
      "grad_norm": 6.037586212158203,
      "learning_rate": 1.9559036144578314e-05,
      "loss": 0.1637,
      "step": 1830
    },
    {
      "epoch": 0.2216867469879518,
      "grad_norm": 6.421009063720703,
      "learning_rate": 1.95566265060241e-05,
      "loss": 0.2427,
      "step": 1840
    },
    {
      "epoch": 0.22289156626506024,
      "grad_norm": 3.4016103744506836,
      "learning_rate": 1.955421686746988e-05,
      "loss": 0.202,
      "step": 1850
    },
    {
      "epoch": 0.22409638554216868,
      "grad_norm": 8.404821395874023,
      "learning_rate": 1.9551807228915666e-05,
      "loss": 0.2493,
      "step": 1860
    },
    {
      "epoch": 0.2253012048192771,
      "grad_norm": 3.3605806827545166,
      "learning_rate": 1.9549397590361447e-05,
      "loss": 0.1782,
      "step": 1870
    },
    {
      "epoch": 0.22650602409638554,
      "grad_norm": 4.03907585144043,
      "learning_rate": 1.9546987951807232e-05,
      "loss": 0.1882,
      "step": 1880
    },
    {
      "epoch": 0.22771084337349398,
      "grad_norm": 3.2921159267425537,
      "learning_rate": 1.9544578313253013e-05,
      "loss": 0.1939,
      "step": 1890
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 5.46529483795166,
      "learning_rate": 1.9542168674698795e-05,
      "loss": 0.2058,
      "step": 1900
    },
    {
      "epoch": 0.23012048192771084,
      "grad_norm": 5.017631530761719,
      "learning_rate": 1.953975903614458e-05,
      "loss": 0.1531,
      "step": 1910
    },
    {
      "epoch": 0.23132530120481928,
      "grad_norm": 7.657460689544678,
      "learning_rate": 1.9537349397590365e-05,
      "loss": 0.2794,
      "step": 1920
    },
    {
      "epoch": 0.2325301204819277,
      "grad_norm": 3.555676221847534,
      "learning_rate": 1.9534939759036146e-05,
      "loss": 0.1574,
      "step": 1930
    },
    {
      "epoch": 0.23373493975903614,
      "grad_norm": 2.1374456882476807,
      "learning_rate": 1.953253012048193e-05,
      "loss": 0.172,
      "step": 1940
    },
    {
      "epoch": 0.23493975903614459,
      "grad_norm": 4.7425689697265625,
      "learning_rate": 1.9530120481927712e-05,
      "loss": 0.1478,
      "step": 1950
    },
    {
      "epoch": 0.236144578313253,
      "grad_norm": 9.77768325805664,
      "learning_rate": 1.9527710843373494e-05,
      "loss": 0.2535,
      "step": 1960
    },
    {
      "epoch": 0.23734939759036144,
      "grad_norm": 5.0772247314453125,
      "learning_rate": 1.952530120481928e-05,
      "loss": 0.2149,
      "step": 1970
    },
    {
      "epoch": 0.2385542168674699,
      "grad_norm": 1.9358603954315186,
      "learning_rate": 1.952289156626506e-05,
      "loss": 0.1145,
      "step": 1980
    },
    {
      "epoch": 0.2397590361445783,
      "grad_norm": 6.831792831420898,
      "learning_rate": 1.9520481927710845e-05,
      "loss": 0.2648,
      "step": 1990
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 6.604684352874756,
      "learning_rate": 1.951807228915663e-05,
      "loss": 0.2371,
      "step": 2000
    },
    {
      "epoch": 0.2421686746987952,
      "grad_norm": 7.196643829345703,
      "learning_rate": 1.951566265060241e-05,
      "loss": 0.2196,
      "step": 2010
    },
    {
      "epoch": 0.2433734939759036,
      "grad_norm": 5.780118942260742,
      "learning_rate": 1.9513253012048193e-05,
      "loss": 0.2379,
      "step": 2020
    },
    {
      "epoch": 0.24457831325301205,
      "grad_norm": 6.217657566070557,
      "learning_rate": 1.9510843373493978e-05,
      "loss": 0.2697,
      "step": 2030
    },
    {
      "epoch": 0.2457831325301205,
      "grad_norm": 3.2430992126464844,
      "learning_rate": 1.950843373493976e-05,
      "loss": 0.1577,
      "step": 2040
    },
    {
      "epoch": 0.2469879518072289,
      "grad_norm": 5.724827766418457,
      "learning_rate": 1.9506024096385544e-05,
      "loss": 0.2402,
      "step": 2050
    },
    {
      "epoch": 0.24819277108433735,
      "grad_norm": 6.085134029388428,
      "learning_rate": 1.9503614457831326e-05,
      "loss": 0.2213,
      "step": 2060
    },
    {
      "epoch": 0.2493975903614458,
      "grad_norm": 2.125946044921875,
      "learning_rate": 1.950120481927711e-05,
      "loss": 0.1844,
      "step": 2070
    },
    {
      "epoch": 0.25060240963855424,
      "grad_norm": 10.09416389465332,
      "learning_rate": 1.9498795180722892e-05,
      "loss": 0.2214,
      "step": 2080
    },
    {
      "epoch": 0.25180722891566265,
      "grad_norm": 5.641793251037598,
      "learning_rate": 1.9496385542168677e-05,
      "loss": 0.1508,
      "step": 2090
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 6.5862627029418945,
      "learning_rate": 1.949397590361446e-05,
      "loss": 0.1646,
      "step": 2100
    },
    {
      "epoch": 0.25421686746987954,
      "grad_norm": 1.6302560567855835,
      "learning_rate": 1.9491566265060243e-05,
      "loss": 0.2682,
      "step": 2110
    },
    {
      "epoch": 0.25542168674698795,
      "grad_norm": 4.620522499084473,
      "learning_rate": 1.9489156626506025e-05,
      "loss": 0.1945,
      "step": 2120
    },
    {
      "epoch": 0.25662650602409637,
      "grad_norm": 10.031213760375977,
      "learning_rate": 1.9486746987951806e-05,
      "loss": 0.2589,
      "step": 2130
    },
    {
      "epoch": 0.25783132530120484,
      "grad_norm": 7.641732215881348,
      "learning_rate": 1.9484337349397595e-05,
      "loss": 0.1266,
      "step": 2140
    },
    {
      "epoch": 0.25903614457831325,
      "grad_norm": 1.2444499731063843,
      "learning_rate": 1.9481927710843376e-05,
      "loss": 0.16,
      "step": 2150
    },
    {
      "epoch": 0.26024096385542167,
      "grad_norm": 7.473699569702148,
      "learning_rate": 1.9479518072289157e-05,
      "loss": 0.2052,
      "step": 2160
    },
    {
      "epoch": 0.26144578313253014,
      "grad_norm": 3.3013527393341064,
      "learning_rate": 1.9477108433734942e-05,
      "loss": 0.1524,
      "step": 2170
    },
    {
      "epoch": 0.26265060240963856,
      "grad_norm": 2.7294604778289795,
      "learning_rate": 1.9474698795180724e-05,
      "loss": 0.2348,
      "step": 2180
    },
    {
      "epoch": 0.26385542168674697,
      "grad_norm": 9.54156494140625,
      "learning_rate": 1.947228915662651e-05,
      "loss": 0.2207,
      "step": 2190
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 6.190511226654053,
      "learning_rate": 1.946987951807229e-05,
      "loss": 0.2219,
      "step": 2200
    },
    {
      "epoch": 0.26626506024096386,
      "grad_norm": 3.5583794116973877,
      "learning_rate": 1.9467469879518075e-05,
      "loss": 0.1478,
      "step": 2210
    },
    {
      "epoch": 0.2674698795180723,
      "grad_norm": 5.1528825759887695,
      "learning_rate": 1.9465060240963857e-05,
      "loss": 0.211,
      "step": 2220
    },
    {
      "epoch": 0.26867469879518074,
      "grad_norm": 8.00110149383545,
      "learning_rate": 1.946265060240964e-05,
      "loss": 0.1499,
      "step": 2230
    },
    {
      "epoch": 0.26987951807228916,
      "grad_norm": 8.695815086364746,
      "learning_rate": 1.9460240963855423e-05,
      "loss": 0.2264,
      "step": 2240
    },
    {
      "epoch": 0.2710843373493976,
      "grad_norm": 4.752155780792236,
      "learning_rate": 1.9457831325301208e-05,
      "loss": 0.1862,
      "step": 2250
    },
    {
      "epoch": 0.27228915662650605,
      "grad_norm": 6.559109687805176,
      "learning_rate": 1.945542168674699e-05,
      "loss": 0.171,
      "step": 2260
    },
    {
      "epoch": 0.27349397590361446,
      "grad_norm": 6.0981316566467285,
      "learning_rate": 1.945301204819277e-05,
      "loss": 0.1929,
      "step": 2270
    },
    {
      "epoch": 0.2746987951807229,
      "grad_norm": 6.55377721786499,
      "learning_rate": 1.9450602409638556e-05,
      "loss": 0.2229,
      "step": 2280
    },
    {
      "epoch": 0.27590361445783135,
      "grad_norm": 4.191379070281982,
      "learning_rate": 1.944819277108434e-05,
      "loss": 0.2632,
      "step": 2290
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 7.092325210571289,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 0.1549,
      "step": 2300
    },
    {
      "epoch": 0.2783132530120482,
      "grad_norm": 6.712291240692139,
      "learning_rate": 1.9443373493975907e-05,
      "loss": 0.2977,
      "step": 2310
    },
    {
      "epoch": 0.27951807228915665,
      "grad_norm": 10.387141227722168,
      "learning_rate": 1.944096385542169e-05,
      "loss": 0.2909,
      "step": 2320
    },
    {
      "epoch": 0.28072289156626506,
      "grad_norm": 6.017031192779541,
      "learning_rate": 1.943855421686747e-05,
      "loss": 0.2418,
      "step": 2330
    },
    {
      "epoch": 0.2819277108433735,
      "grad_norm": 4.997074604034424,
      "learning_rate": 1.9436144578313255e-05,
      "loss": 0.1706,
      "step": 2340
    },
    {
      "epoch": 0.28313253012048195,
      "grad_norm": 2.7696495056152344,
      "learning_rate": 1.9433734939759036e-05,
      "loss": 0.239,
      "step": 2350
    },
    {
      "epoch": 0.28433734939759037,
      "grad_norm": 4.427982807159424,
      "learning_rate": 1.943132530120482e-05,
      "loss": 0.1564,
      "step": 2360
    },
    {
      "epoch": 0.2855421686746988,
      "grad_norm": 6.675074577331543,
      "learning_rate": 1.9428915662650606e-05,
      "loss": 0.2756,
      "step": 2370
    },
    {
      "epoch": 0.28674698795180725,
      "grad_norm": 6.264098644256592,
      "learning_rate": 1.9426506024096387e-05,
      "loss": 0.1242,
      "step": 2380
    },
    {
      "epoch": 0.28795180722891567,
      "grad_norm": 5.286129474639893,
      "learning_rate": 1.942409638554217e-05,
      "loss": 0.169,
      "step": 2390
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 4.244844913482666,
      "learning_rate": 1.9421686746987954e-05,
      "loss": 0.1851,
      "step": 2400
    },
    {
      "epoch": 0.29036144578313255,
      "grad_norm": 4.535923957824707,
      "learning_rate": 1.9419277108433735e-05,
      "loss": 0.1953,
      "step": 2410
    },
    {
      "epoch": 0.29156626506024097,
      "grad_norm": 7.94540548324585,
      "learning_rate": 1.941686746987952e-05,
      "loss": 0.2392,
      "step": 2420
    },
    {
      "epoch": 0.2927710843373494,
      "grad_norm": 5.816745758056641,
      "learning_rate": 1.94144578313253e-05,
      "loss": 0.2284,
      "step": 2430
    },
    {
      "epoch": 0.29397590361445786,
      "grad_norm": 0.9242902398109436,
      "learning_rate": 1.9412048192771086e-05,
      "loss": 0.0914,
      "step": 2440
    },
    {
      "epoch": 0.29518072289156627,
      "grad_norm": 6.881667613983154,
      "learning_rate": 1.940963855421687e-05,
      "loss": 0.1648,
      "step": 2450
    },
    {
      "epoch": 0.2963855421686747,
      "grad_norm": 6.569538593292236,
      "learning_rate": 1.9407228915662653e-05,
      "loss": 0.2591,
      "step": 2460
    },
    {
      "epoch": 0.29759036144578316,
      "grad_norm": 4.580605983734131,
      "learning_rate": 1.9404819277108434e-05,
      "loss": 0.1587,
      "step": 2470
    },
    {
      "epoch": 0.2987951807228916,
      "grad_norm": 6.215828895568848,
      "learning_rate": 1.940240963855422e-05,
      "loss": 0.1769,
      "step": 2480
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.389387130737305,
      "learning_rate": 1.94e-05,
      "loss": 0.1803,
      "step": 2490
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 8.452051162719727,
      "learning_rate": 1.9397590361445785e-05,
      "loss": 0.2208,
      "step": 2500
    },
    {
      "epoch": 0.3024096385542169,
      "grad_norm": 5.735720157623291,
      "learning_rate": 1.939518072289157e-05,
      "loss": 0.151,
      "step": 2510
    },
    {
      "epoch": 0.3036144578313253,
      "grad_norm": 6.559477806091309,
      "learning_rate": 1.9392771084337352e-05,
      "loss": 0.1275,
      "step": 2520
    },
    {
      "epoch": 0.30481927710843376,
      "grad_norm": 5.46803617477417,
      "learning_rate": 1.9390361445783133e-05,
      "loss": 0.2249,
      "step": 2530
    },
    {
      "epoch": 0.3060240963855422,
      "grad_norm": 8.314395904541016,
      "learning_rate": 1.9387951807228918e-05,
      "loss": 0.1503,
      "step": 2540
    },
    {
      "epoch": 0.3072289156626506,
      "grad_norm": 4.342772960662842,
      "learning_rate": 1.93855421686747e-05,
      "loss": 0.136,
      "step": 2550
    },
    {
      "epoch": 0.30843373493975906,
      "grad_norm": 6.92494010925293,
      "learning_rate": 1.9383132530120485e-05,
      "loss": 0.1545,
      "step": 2560
    },
    {
      "epoch": 0.3096385542168675,
      "grad_norm": 3.9478747844696045,
      "learning_rate": 1.9380722891566266e-05,
      "loss": 0.1765,
      "step": 2570
    },
    {
      "epoch": 0.3108433734939759,
      "grad_norm": 6.093476295471191,
      "learning_rate": 1.9378313253012047e-05,
      "loss": 0.1617,
      "step": 2580
    },
    {
      "epoch": 0.31204819277108437,
      "grad_norm": 5.767611980438232,
      "learning_rate": 1.9375903614457832e-05,
      "loss": 0.233,
      "step": 2590
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 1.0746164321899414,
      "learning_rate": 1.9373493975903617e-05,
      "loss": 0.1588,
      "step": 2600
    },
    {
      "epoch": 0.3144578313253012,
      "grad_norm": 5.83290433883667,
      "learning_rate": 1.93710843373494e-05,
      "loss": 0.2221,
      "step": 2610
    },
    {
      "epoch": 0.3156626506024096,
      "grad_norm": 2.944486618041992,
      "learning_rate": 1.9368674698795184e-05,
      "loss": 0.116,
      "step": 2620
    },
    {
      "epoch": 0.3168674698795181,
      "grad_norm": 7.345919132232666,
      "learning_rate": 1.9366265060240965e-05,
      "loss": 0.158,
      "step": 2630
    },
    {
      "epoch": 0.3180722891566265,
      "grad_norm": 7.966898441314697,
      "learning_rate": 1.9363855421686747e-05,
      "loss": 0.1607,
      "step": 2640
    },
    {
      "epoch": 0.3192771084337349,
      "grad_norm": 4.5670013427734375,
      "learning_rate": 1.936144578313253e-05,
      "loss": 0.2283,
      "step": 2650
    },
    {
      "epoch": 0.3204819277108434,
      "grad_norm": 7.014620304107666,
      "learning_rate": 1.9359036144578316e-05,
      "loss": 0.1759,
      "step": 2660
    },
    {
      "epoch": 0.3216867469879518,
      "grad_norm": 2.2717361450195312,
      "learning_rate": 1.9356626506024098e-05,
      "loss": 0.2053,
      "step": 2670
    },
    {
      "epoch": 0.3228915662650602,
      "grad_norm": 8.202719688415527,
      "learning_rate": 1.9354216867469883e-05,
      "loss": 0.1384,
      "step": 2680
    },
    {
      "epoch": 0.3240963855421687,
      "grad_norm": 7.282330513000488,
      "learning_rate": 1.9351807228915664e-05,
      "loss": 0.1355,
      "step": 2690
    },
    {
      "epoch": 0.3253012048192771,
      "grad_norm": 5.567014217376709,
      "learning_rate": 1.9349397590361446e-05,
      "loss": 0.2426,
      "step": 2700
    },
    {
      "epoch": 0.3265060240963855,
      "grad_norm": 6.091856002807617,
      "learning_rate": 1.934698795180723e-05,
      "loss": 0.1415,
      "step": 2710
    },
    {
      "epoch": 0.327710843373494,
      "grad_norm": 5.637847900390625,
      "learning_rate": 1.9344578313253012e-05,
      "loss": 0.1706,
      "step": 2720
    },
    {
      "epoch": 0.3289156626506024,
      "grad_norm": 5.434848308563232,
      "learning_rate": 1.9342168674698797e-05,
      "loss": 0.1425,
      "step": 2730
    },
    {
      "epoch": 0.3301204819277108,
      "grad_norm": 1.9581104516983032,
      "learning_rate": 1.9339759036144582e-05,
      "loss": 0.1444,
      "step": 2740
    },
    {
      "epoch": 0.3313253012048193,
      "grad_norm": 5.649551868438721,
      "learning_rate": 1.9337349397590363e-05,
      "loss": 0.191,
      "step": 2750
    },
    {
      "epoch": 0.3325301204819277,
      "grad_norm": 4.072618007659912,
      "learning_rate": 1.9334939759036148e-05,
      "loss": 0.1497,
      "step": 2760
    },
    {
      "epoch": 0.3337349397590361,
      "grad_norm": 2.393462896347046,
      "learning_rate": 1.933253012048193e-05,
      "loss": 0.1172,
      "step": 2770
    },
    {
      "epoch": 0.3349397590361446,
      "grad_norm": 6.571315288543701,
      "learning_rate": 1.933012048192771e-05,
      "loss": 0.1904,
      "step": 2780
    },
    {
      "epoch": 0.336144578313253,
      "grad_norm": 6.790152072906494,
      "learning_rate": 1.9327710843373496e-05,
      "loss": 0.1458,
      "step": 2790
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 0.8483447432518005,
      "learning_rate": 1.9325301204819277e-05,
      "loss": 0.183,
      "step": 2800
    },
    {
      "epoch": 0.3385542168674699,
      "grad_norm": 8.287294387817383,
      "learning_rate": 1.9322891566265062e-05,
      "loss": 0.1281,
      "step": 2810
    },
    {
      "epoch": 0.3397590361445783,
      "grad_norm": 16.97709846496582,
      "learning_rate": 1.9320481927710847e-05,
      "loss": 0.1181,
      "step": 2820
    },
    {
      "epoch": 0.3409638554216867,
      "grad_norm": 1.1969772577285767,
      "learning_rate": 1.931807228915663e-05,
      "loss": 0.1709,
      "step": 2830
    },
    {
      "epoch": 0.3421686746987952,
      "grad_norm": 8.773261070251465,
      "learning_rate": 1.931566265060241e-05,
      "loss": 0.1124,
      "step": 2840
    },
    {
      "epoch": 0.3433734939759036,
      "grad_norm": 0.34181034564971924,
      "learning_rate": 1.9313253012048195e-05,
      "loss": 0.2282,
      "step": 2850
    },
    {
      "epoch": 0.344578313253012,
      "grad_norm": 8.809361457824707,
      "learning_rate": 1.9310843373493976e-05,
      "loss": 0.1211,
      "step": 2860
    },
    {
      "epoch": 0.3457831325301205,
      "grad_norm": 1.6715022325515747,
      "learning_rate": 1.930843373493976e-05,
      "loss": 0.2565,
      "step": 2870
    },
    {
      "epoch": 0.3469879518072289,
      "grad_norm": 6.635237216949463,
      "learning_rate": 1.9306024096385543e-05,
      "loss": 0.1333,
      "step": 2880
    },
    {
      "epoch": 0.3481927710843373,
      "grad_norm": 9.3126220703125,
      "learning_rate": 1.9303614457831328e-05,
      "loss": 0.1338,
      "step": 2890
    },
    {
      "epoch": 0.3493975903614458,
      "grad_norm": 7.845859050750732,
      "learning_rate": 1.930120481927711e-05,
      "loss": 0.1523,
      "step": 2900
    },
    {
      "epoch": 0.3506024096385542,
      "grad_norm": 9.777925491333008,
      "learning_rate": 1.9298795180722894e-05,
      "loss": 0.1412,
      "step": 2910
    },
    {
      "epoch": 0.35180722891566263,
      "grad_norm": 5.6489338874816895,
      "learning_rate": 1.9296385542168675e-05,
      "loss": 0.2141,
      "step": 2920
    },
    {
      "epoch": 0.3530120481927711,
      "grad_norm": 8.66394329071045,
      "learning_rate": 1.929397590361446e-05,
      "loss": 0.1229,
      "step": 2930
    },
    {
      "epoch": 0.3542168674698795,
      "grad_norm": 8.170677185058594,
      "learning_rate": 1.9291566265060242e-05,
      "loss": 0.1784,
      "step": 2940
    },
    {
      "epoch": 0.35542168674698793,
      "grad_norm": 6.1673102378845215,
      "learning_rate": 1.9289156626506023e-05,
      "loss": 0.2413,
      "step": 2950
    },
    {
      "epoch": 0.3566265060240964,
      "grad_norm": 2.4554696083068848,
      "learning_rate": 1.928674698795181e-05,
      "loss": 0.1605,
      "step": 2960
    },
    {
      "epoch": 0.3578313253012048,
      "grad_norm": 7.461371421813965,
      "learning_rate": 1.9284337349397593e-05,
      "loss": 0.1327,
      "step": 2970
    },
    {
      "epoch": 0.35903614457831323,
      "grad_norm": 4.832873821258545,
      "learning_rate": 1.9281927710843375e-05,
      "loss": 0.2142,
      "step": 2980
    },
    {
      "epoch": 0.3602409638554217,
      "grad_norm": 3.6374449729919434,
      "learning_rate": 1.927951807228916e-05,
      "loss": 0.1114,
      "step": 2990
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 6.949183464050293,
      "learning_rate": 1.927710843373494e-05,
      "loss": 0.1482,
      "step": 3000
    },
    {
      "epoch": 0.36265060240963853,
      "grad_norm": 5.879427909851074,
      "learning_rate": 1.9274698795180726e-05,
      "loss": 0.1889,
      "step": 3010
    },
    {
      "epoch": 0.363855421686747,
      "grad_norm": 1.411298155784607,
      "learning_rate": 1.9272289156626507e-05,
      "loss": 0.1127,
      "step": 3020
    },
    {
      "epoch": 0.3650602409638554,
      "grad_norm": 2.49006724357605,
      "learning_rate": 1.926987951807229e-05,
      "loss": 0.1578,
      "step": 3030
    },
    {
      "epoch": 0.36626506024096384,
      "grad_norm": 1.5668330192565918,
      "learning_rate": 1.9267469879518074e-05,
      "loss": 0.114,
      "step": 3040
    },
    {
      "epoch": 0.3674698795180723,
      "grad_norm": 2.3262603282928467,
      "learning_rate": 1.926506024096386e-05,
      "loss": 0.1044,
      "step": 3050
    },
    {
      "epoch": 0.3686746987951807,
      "grad_norm": 5.765282154083252,
      "learning_rate": 1.926265060240964e-05,
      "loss": 0.2412,
      "step": 3060
    },
    {
      "epoch": 0.36987951807228914,
      "grad_norm": 4.393538475036621,
      "learning_rate": 1.9260240963855425e-05,
      "loss": 0.1736,
      "step": 3070
    },
    {
      "epoch": 0.3710843373493976,
      "grad_norm": 6.0366668701171875,
      "learning_rate": 1.9257831325301206e-05,
      "loss": 0.2607,
      "step": 3080
    },
    {
      "epoch": 0.372289156626506,
      "grad_norm": 3.695233106613159,
      "learning_rate": 1.9255421686746988e-05,
      "loss": 0.162,
      "step": 3090
    },
    {
      "epoch": 0.37349397590361444,
      "grad_norm": 5.12272834777832,
      "learning_rate": 1.9253012048192773e-05,
      "loss": 0.178,
      "step": 3100
    },
    {
      "epoch": 0.3746987951807229,
      "grad_norm": 2.8470723628997803,
      "learning_rate": 1.9250602409638558e-05,
      "loss": 0.1246,
      "step": 3110
    },
    {
      "epoch": 0.3759036144578313,
      "grad_norm": 2.2872886657714844,
      "learning_rate": 1.924819277108434e-05,
      "loss": 0.131,
      "step": 3120
    },
    {
      "epoch": 0.37710843373493974,
      "grad_norm": 1.137621283531189,
      "learning_rate": 1.9245783132530124e-05,
      "loss": 0.1199,
      "step": 3130
    },
    {
      "epoch": 0.3783132530120482,
      "grad_norm": 14.633459091186523,
      "learning_rate": 1.9243373493975905e-05,
      "loss": 0.1653,
      "step": 3140
    },
    {
      "epoch": 0.3795180722891566,
      "grad_norm": 6.029254913330078,
      "learning_rate": 1.9240963855421687e-05,
      "loss": 0.1365,
      "step": 3150
    },
    {
      "epoch": 0.38072289156626504,
      "grad_norm": 6.238698482513428,
      "learning_rate": 1.9238554216867472e-05,
      "loss": 0.1407,
      "step": 3160
    },
    {
      "epoch": 0.3819277108433735,
      "grad_norm": 5.425461292266846,
      "learning_rate": 1.9236144578313253e-05,
      "loss": 0.1641,
      "step": 3170
    },
    {
      "epoch": 0.38313253012048193,
      "grad_norm": 3.4089372158050537,
      "learning_rate": 1.9233734939759038e-05,
      "loss": 0.2392,
      "step": 3180
    },
    {
      "epoch": 0.38433734939759034,
      "grad_norm": 1.6571323871612549,
      "learning_rate": 1.9231325301204823e-05,
      "loss": 0.112,
      "step": 3190
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 6.614997863769531,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 0.1704,
      "step": 3200
    },
    {
      "epoch": 0.38674698795180723,
      "grad_norm": 6.017977714538574,
      "learning_rate": 1.9226506024096386e-05,
      "loss": 0.1489,
      "step": 3210
    },
    {
      "epoch": 0.38795180722891565,
      "grad_norm": 2.989858865737915,
      "learning_rate": 1.922409638554217e-05,
      "loss": 0.1641,
      "step": 3220
    },
    {
      "epoch": 0.3891566265060241,
      "grad_norm": 3.3851804733276367,
      "learning_rate": 1.9221686746987952e-05,
      "loss": 0.1502,
      "step": 3230
    },
    {
      "epoch": 0.39036144578313253,
      "grad_norm": 6.0906171798706055,
      "learning_rate": 1.9219277108433737e-05,
      "loss": 0.1652,
      "step": 3240
    },
    {
      "epoch": 0.39156626506024095,
      "grad_norm": 4.85234260559082,
      "learning_rate": 1.921686746987952e-05,
      "loss": 0.2008,
      "step": 3250
    },
    {
      "epoch": 0.3927710843373494,
      "grad_norm": 6.74740743637085,
      "learning_rate": 1.9214457831325303e-05,
      "loss": 0.1063,
      "step": 3260
    },
    {
      "epoch": 0.39397590361445783,
      "grad_norm": 7.1081624031066895,
      "learning_rate": 1.921204819277109e-05,
      "loss": 0.1756,
      "step": 3270
    },
    {
      "epoch": 0.39518072289156625,
      "grad_norm": 3.0283288955688477,
      "learning_rate": 1.920963855421687e-05,
      "loss": 0.1399,
      "step": 3280
    },
    {
      "epoch": 0.3963855421686747,
      "grad_norm": 4.283823013305664,
      "learning_rate": 1.920722891566265e-05,
      "loss": 0.1275,
      "step": 3290
    },
    {
      "epoch": 0.39759036144578314,
      "grad_norm": 1.2156603336334229,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 0.1289,
      "step": 3300
    },
    {
      "epoch": 0.39879518072289155,
      "grad_norm": 1.2468175888061523,
      "learning_rate": 1.9202409638554218e-05,
      "loss": 0.0939,
      "step": 3310
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.3024115562438965,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.1787,
      "step": 3320
    },
    {
      "epoch": 0.40120481927710844,
      "grad_norm": 0.37067022919654846,
      "learning_rate": 1.9197590361445784e-05,
      "loss": 0.1289,
      "step": 3330
    },
    {
      "epoch": 0.40240963855421685,
      "grad_norm": 3.901878833770752,
      "learning_rate": 1.919518072289157e-05,
      "loss": 0.1465,
      "step": 3340
    },
    {
      "epoch": 0.4036144578313253,
      "grad_norm": 9.990409851074219,
      "learning_rate": 1.919277108433735e-05,
      "loss": 0.1776,
      "step": 3350
    },
    {
      "epoch": 0.40481927710843374,
      "grad_norm": 6.474090099334717,
      "learning_rate": 1.9190361445783135e-05,
      "loss": 0.2059,
      "step": 3360
    },
    {
      "epoch": 0.40602409638554215,
      "grad_norm": 8.932092666625977,
      "learning_rate": 1.9187951807228917e-05,
      "loss": 0.171,
      "step": 3370
    },
    {
      "epoch": 0.4072289156626506,
      "grad_norm": 4.469496250152588,
      "learning_rate": 1.91855421686747e-05,
      "loss": 0.109,
      "step": 3380
    },
    {
      "epoch": 0.40843373493975904,
      "grad_norm": 0.197481170296669,
      "learning_rate": 1.9183132530120483e-05,
      "loss": 0.08,
      "step": 3390
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 10.042135238647461,
      "learning_rate": 1.9180722891566265e-05,
      "loss": 0.2126,
      "step": 3400
    },
    {
      "epoch": 0.4108433734939759,
      "grad_norm": 4.975799560546875,
      "learning_rate": 1.917831325301205e-05,
      "loss": 0.1737,
      "step": 3410
    },
    {
      "epoch": 0.41204819277108434,
      "grad_norm": 0.8473758697509766,
      "learning_rate": 1.9175903614457834e-05,
      "loss": 0.0867,
      "step": 3420
    },
    {
      "epoch": 0.41325301204819276,
      "grad_norm": 4.776500225067139,
      "learning_rate": 1.9173493975903616e-05,
      "loss": 0.1191,
      "step": 3430
    },
    {
      "epoch": 0.41445783132530123,
      "grad_norm": 7.128292083740234,
      "learning_rate": 1.91710843373494e-05,
      "loss": 0.1922,
      "step": 3440
    },
    {
      "epoch": 0.41566265060240964,
      "grad_norm": 5.925419330596924,
      "learning_rate": 1.9168674698795182e-05,
      "loss": 0.1176,
      "step": 3450
    },
    {
      "epoch": 0.41686746987951806,
      "grad_norm": 8.936776161193848,
      "learning_rate": 1.9166265060240964e-05,
      "loss": 0.1401,
      "step": 3460
    },
    {
      "epoch": 0.41807228915662653,
      "grad_norm": 9.545977592468262,
      "learning_rate": 1.916385542168675e-05,
      "loss": 0.1771,
      "step": 3470
    },
    {
      "epoch": 0.41927710843373495,
      "grad_norm": 5.288257122039795,
      "learning_rate": 1.916144578313253e-05,
      "loss": 0.164,
      "step": 3480
    },
    {
      "epoch": 0.42048192771084336,
      "grad_norm": 6.760628700256348,
      "learning_rate": 1.9159036144578315e-05,
      "loss": 0.1329,
      "step": 3490
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 1.1297738552093506,
      "learning_rate": 1.91566265060241e-05,
      "loss": 0.1015,
      "step": 3500
    },
    {
      "epoch": 0.42289156626506025,
      "grad_norm": 4.756875038146973,
      "learning_rate": 1.915421686746988e-05,
      "loss": 0.1745,
      "step": 3510
    },
    {
      "epoch": 0.42409638554216866,
      "grad_norm": 1.5892890691757202,
      "learning_rate": 1.9151807228915663e-05,
      "loss": 0.1346,
      "step": 3520
    },
    {
      "epoch": 0.42530120481927713,
      "grad_norm": 7.583889484405518,
      "learning_rate": 1.9149397590361448e-05,
      "loss": 0.2099,
      "step": 3530
    },
    {
      "epoch": 0.42650602409638555,
      "grad_norm": 8.795680046081543,
      "learning_rate": 1.914698795180723e-05,
      "loss": 0.1511,
      "step": 3540
    },
    {
      "epoch": 0.42771084337349397,
      "grad_norm": 9.551274299621582,
      "learning_rate": 1.9144578313253014e-05,
      "loss": 0.1417,
      "step": 3550
    },
    {
      "epoch": 0.42891566265060244,
      "grad_norm": 6.202319145202637,
      "learning_rate": 1.91421686746988e-05,
      "loss": 0.1119,
      "step": 3560
    },
    {
      "epoch": 0.43012048192771085,
      "grad_norm": 4.560641765594482,
      "learning_rate": 1.913975903614458e-05,
      "loss": 0.152,
      "step": 3570
    },
    {
      "epoch": 0.43132530120481927,
      "grad_norm": 6.404481887817383,
      "learning_rate": 1.9137349397590365e-05,
      "loss": 0.225,
      "step": 3580
    },
    {
      "epoch": 0.43253012048192774,
      "grad_norm": 7.567647933959961,
      "learning_rate": 1.9134939759036147e-05,
      "loss": 0.1963,
      "step": 3590
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 0.953495442867279,
      "learning_rate": 1.9132530120481928e-05,
      "loss": 0.0994,
      "step": 3600
    },
    {
      "epoch": 0.43493975903614457,
      "grad_norm": 8.044732093811035,
      "learning_rate": 1.9130120481927713e-05,
      "loss": 0.157,
      "step": 3610
    },
    {
      "epoch": 0.43614457831325304,
      "grad_norm": 0.2202860713005066,
      "learning_rate": 1.9127710843373494e-05,
      "loss": 0.135,
      "step": 3620
    },
    {
      "epoch": 0.43734939759036146,
      "grad_norm": 5.56553316116333,
      "learning_rate": 1.912530120481928e-05,
      "loss": 0.1112,
      "step": 3630
    },
    {
      "epoch": 0.43855421686746987,
      "grad_norm": 9.8916597366333,
      "learning_rate": 1.9122891566265064e-05,
      "loss": 0.1857,
      "step": 3640
    },
    {
      "epoch": 0.4397590361445783,
      "grad_norm": 4.46987247467041,
      "learning_rate": 1.9120481927710846e-05,
      "loss": 0.1788,
      "step": 3650
    },
    {
      "epoch": 0.44096385542168676,
      "grad_norm": 3.790076494216919,
      "learning_rate": 1.9118072289156627e-05,
      "loss": 0.1262,
      "step": 3660
    },
    {
      "epoch": 0.44216867469879517,
      "grad_norm": 4.710744380950928,
      "learning_rate": 1.9115662650602412e-05,
      "loss": 0.1663,
      "step": 3670
    },
    {
      "epoch": 0.4433734939759036,
      "grad_norm": 3.4892423152923584,
      "learning_rate": 1.9113253012048193e-05,
      "loss": 0.1014,
      "step": 3680
    },
    {
      "epoch": 0.44457831325301206,
      "grad_norm": 1.9459058046340942,
      "learning_rate": 1.911084337349398e-05,
      "loss": 0.198,
      "step": 3690
    },
    {
      "epoch": 0.4457831325301205,
      "grad_norm": 2.7664852142333984,
      "learning_rate": 1.910843373493976e-05,
      "loss": 0.1032,
      "step": 3700
    },
    {
      "epoch": 0.4469879518072289,
      "grad_norm": 2.183917760848999,
      "learning_rate": 1.9106024096385545e-05,
      "loss": 0.2012,
      "step": 3710
    },
    {
      "epoch": 0.44819277108433736,
      "grad_norm": 0.9908152222633362,
      "learning_rate": 1.9103614457831326e-05,
      "loss": 0.1764,
      "step": 3720
    },
    {
      "epoch": 0.4493975903614458,
      "grad_norm": 8.322821617126465,
      "learning_rate": 1.910120481927711e-05,
      "loss": 0.1774,
      "step": 3730
    },
    {
      "epoch": 0.4506024096385542,
      "grad_norm": 8.774030685424805,
      "learning_rate": 1.9098795180722893e-05,
      "loss": 0.2661,
      "step": 3740
    },
    {
      "epoch": 0.45180722891566266,
      "grad_norm": 2.3262112140655518,
      "learning_rate": 1.9096385542168677e-05,
      "loss": 0.1186,
      "step": 3750
    },
    {
      "epoch": 0.4530120481927711,
      "grad_norm": 6.135867118835449,
      "learning_rate": 1.909397590361446e-05,
      "loss": 0.1656,
      "step": 3760
    },
    {
      "epoch": 0.4542168674698795,
      "grad_norm": 4.904735565185547,
      "learning_rate": 1.909156626506024e-05,
      "loss": 0.1187,
      "step": 3770
    },
    {
      "epoch": 0.45542168674698796,
      "grad_norm": 2.7500598430633545,
      "learning_rate": 1.9089156626506025e-05,
      "loss": 0.1117,
      "step": 3780
    },
    {
      "epoch": 0.4566265060240964,
      "grad_norm": 2.64709734916687,
      "learning_rate": 1.908674698795181e-05,
      "loss": 0.238,
      "step": 3790
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 3.5699188709259033,
      "learning_rate": 1.908433734939759e-05,
      "loss": 0.1218,
      "step": 3800
    },
    {
      "epoch": 0.45903614457831327,
      "grad_norm": 8.127824783325195,
      "learning_rate": 1.9081927710843376e-05,
      "loss": 0.2171,
      "step": 3810
    },
    {
      "epoch": 0.4602409638554217,
      "grad_norm": 1.8329440355300903,
      "learning_rate": 1.9079518072289158e-05,
      "loss": 0.1774,
      "step": 3820
    },
    {
      "epoch": 0.4614457831325301,
      "grad_norm": 8.005314826965332,
      "learning_rate": 1.907710843373494e-05,
      "loss": 0.1388,
      "step": 3830
    },
    {
      "epoch": 0.46265060240963857,
      "grad_norm": 5.189761638641357,
      "learning_rate": 1.9074698795180724e-05,
      "loss": 0.181,
      "step": 3840
    },
    {
      "epoch": 0.463855421686747,
      "grad_norm": 6.037755489349365,
      "learning_rate": 1.9072289156626506e-05,
      "loss": 0.1439,
      "step": 3850
    },
    {
      "epoch": 0.4650602409638554,
      "grad_norm": 2.1217734813690186,
      "learning_rate": 1.906987951807229e-05,
      "loss": 0.0717,
      "step": 3860
    },
    {
      "epoch": 0.46626506024096387,
      "grad_norm": 12.026711463928223,
      "learning_rate": 1.9067469879518076e-05,
      "loss": 0.1503,
      "step": 3870
    },
    {
      "epoch": 0.4674698795180723,
      "grad_norm": 6.784931182861328,
      "learning_rate": 1.9065060240963857e-05,
      "loss": 0.1306,
      "step": 3880
    },
    {
      "epoch": 0.4686746987951807,
      "grad_norm": 4.856891632080078,
      "learning_rate": 1.9062650602409642e-05,
      "loss": 0.1678,
      "step": 3890
    },
    {
      "epoch": 0.46987951807228917,
      "grad_norm": 1.0789295434951782,
      "learning_rate": 1.9060240963855423e-05,
      "loss": 0.1865,
      "step": 3900
    },
    {
      "epoch": 0.4710843373493976,
      "grad_norm": 1.090378999710083,
      "learning_rate": 1.9057831325301205e-05,
      "loss": 0.1393,
      "step": 3910
    },
    {
      "epoch": 0.472289156626506,
      "grad_norm": 0.5879728198051453,
      "learning_rate": 1.905542168674699e-05,
      "loss": 0.1505,
      "step": 3920
    },
    {
      "epoch": 0.4734939759036145,
      "grad_norm": 3.5017054080963135,
      "learning_rate": 1.905301204819277e-05,
      "loss": 0.0944,
      "step": 3930
    },
    {
      "epoch": 0.4746987951807229,
      "grad_norm": 1.0876482725143433,
      "learning_rate": 1.9050602409638556e-05,
      "loss": 0.1175,
      "step": 3940
    },
    {
      "epoch": 0.4759036144578313,
      "grad_norm": 3.292722225189209,
      "learning_rate": 1.904819277108434e-05,
      "loss": 0.1836,
      "step": 3950
    },
    {
      "epoch": 0.4771084337349398,
      "grad_norm": 8.6922607421875,
      "learning_rate": 1.9045783132530122e-05,
      "loss": 0.0982,
      "step": 3960
    },
    {
      "epoch": 0.4783132530120482,
      "grad_norm": 7.024328708648682,
      "learning_rate": 1.9043373493975904e-05,
      "loss": 0.1677,
      "step": 3970
    },
    {
      "epoch": 0.4795180722891566,
      "grad_norm": 5.636570453643799,
      "learning_rate": 1.904096385542169e-05,
      "loss": 0.1703,
      "step": 3980
    },
    {
      "epoch": 0.4807228915662651,
      "grad_norm": 3.1312460899353027,
      "learning_rate": 1.903855421686747e-05,
      "loss": 0.2276,
      "step": 3990
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 6.040818691253662,
      "learning_rate": 1.9036144578313255e-05,
      "loss": 0.1612,
      "step": 4000
    },
    {
      "epoch": 0.4831325301204819,
      "grad_norm": 3.4178764820098877,
      "learning_rate": 1.903373493975904e-05,
      "loss": 0.1039,
      "step": 4010
    },
    {
      "epoch": 0.4843373493975904,
      "grad_norm": 0.5675806999206543,
      "learning_rate": 1.903132530120482e-05,
      "loss": 0.1209,
      "step": 4020
    },
    {
      "epoch": 0.4855421686746988,
      "grad_norm": 3.535818576812744,
      "learning_rate": 1.9028915662650603e-05,
      "loss": 0.124,
      "step": 4030
    },
    {
      "epoch": 0.4867469879518072,
      "grad_norm": 5.923007488250732,
      "learning_rate": 1.9026506024096388e-05,
      "loss": 0.1866,
      "step": 4040
    },
    {
      "epoch": 0.4879518072289157,
      "grad_norm": 3.2324421405792236,
      "learning_rate": 1.902409638554217e-05,
      "loss": 0.2094,
      "step": 4050
    },
    {
      "epoch": 0.4891566265060241,
      "grad_norm": 2.60790753364563,
      "learning_rate": 1.9021686746987954e-05,
      "loss": 0.1333,
      "step": 4060
    },
    {
      "epoch": 0.4903614457831325,
      "grad_norm": 2.081207275390625,
      "learning_rate": 1.9019277108433736e-05,
      "loss": 0.1339,
      "step": 4070
    },
    {
      "epoch": 0.491566265060241,
      "grad_norm": 5.1187357902526855,
      "learning_rate": 1.9016867469879517e-05,
      "loss": 0.1161,
      "step": 4080
    },
    {
      "epoch": 0.4927710843373494,
      "grad_norm": 2.5016229152679443,
      "learning_rate": 1.9014457831325302e-05,
      "loss": 0.1167,
      "step": 4090
    },
    {
      "epoch": 0.4939759036144578,
      "grad_norm": 4.362277984619141,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 0.078,
      "step": 4100
    },
    {
      "epoch": 0.4951807228915663,
      "grad_norm": 6.196329116821289,
      "learning_rate": 1.900963855421687e-05,
      "loss": 0.1074,
      "step": 4110
    },
    {
      "epoch": 0.4963855421686747,
      "grad_norm": 11.002820014953613,
      "learning_rate": 1.9007228915662653e-05,
      "loss": 0.2064,
      "step": 4120
    },
    {
      "epoch": 0.4975903614457831,
      "grad_norm": 11.695943832397461,
      "learning_rate": 1.9004819277108435e-05,
      "loss": 0.1306,
      "step": 4130
    },
    {
      "epoch": 0.4987951807228916,
      "grad_norm": 6.437772750854492,
      "learning_rate": 1.9002409638554216e-05,
      "loss": 0.2161,
      "step": 4140
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2782803773880005,
      "learning_rate": 1.9e-05,
      "loss": 0.1765,
      "step": 4150
    },
    {
      "epoch": 0.5012048192771085,
      "grad_norm": 5.696470260620117,
      "learning_rate": 1.8997590361445786e-05,
      "loss": 0.1071,
      "step": 4160
    },
    {
      "epoch": 0.5024096385542168,
      "grad_norm": 2.4014992713928223,
      "learning_rate": 1.8995180722891567e-05,
      "loss": 0.1095,
      "step": 4170
    },
    {
      "epoch": 0.5036144578313253,
      "grad_norm": 1.4710595607757568,
      "learning_rate": 1.8992771084337352e-05,
      "loss": 0.1178,
      "step": 4180
    },
    {
      "epoch": 0.5048192771084338,
      "grad_norm": 4.833182334899902,
      "learning_rate": 1.8990361445783134e-05,
      "loss": 0.1263,
      "step": 4190
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 2.6607754230499268,
      "learning_rate": 1.898795180722892e-05,
      "loss": 0.1047,
      "step": 4200
    },
    {
      "epoch": 0.5072289156626506,
      "grad_norm": 3.442692279815674,
      "learning_rate": 1.89855421686747e-05,
      "loss": 0.1478,
      "step": 4210
    },
    {
      "epoch": 0.5084337349397591,
      "grad_norm": 1.3435020446777344,
      "learning_rate": 1.898313253012048e-05,
      "loss": 0.0978,
      "step": 4220
    },
    {
      "epoch": 0.5096385542168674,
      "grad_norm": 0.5266106128692627,
      "learning_rate": 1.8980722891566266e-05,
      "loss": 0.1092,
      "step": 4230
    },
    {
      "epoch": 0.5108433734939759,
      "grad_norm": 4.84061861038208,
      "learning_rate": 1.897831325301205e-05,
      "loss": 0.0933,
      "step": 4240
    },
    {
      "epoch": 0.5120481927710844,
      "grad_norm": 1.827586054801941,
      "learning_rate": 1.8975903614457833e-05,
      "loss": 0.1046,
      "step": 4250
    },
    {
      "epoch": 0.5132530120481927,
      "grad_norm": 5.918137073516846,
      "learning_rate": 1.8973493975903618e-05,
      "loss": 0.1367,
      "step": 4260
    },
    {
      "epoch": 0.5144578313253012,
      "grad_norm": 3.8929402828216553,
      "learning_rate": 1.89710843373494e-05,
      "loss": 0.1769,
      "step": 4270
    },
    {
      "epoch": 0.5156626506024097,
      "grad_norm": 4.477790832519531,
      "learning_rate": 1.896867469879518e-05,
      "loss": 0.1531,
      "step": 4280
    },
    {
      "epoch": 0.516867469879518,
      "grad_norm": 6.854531288146973,
      "learning_rate": 1.8966265060240966e-05,
      "loss": 0.1476,
      "step": 4290
    },
    {
      "epoch": 0.5180722891566265,
      "grad_norm": 1.8789902925491333,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 0.2001,
      "step": 4300
    },
    {
      "epoch": 0.519277108433735,
      "grad_norm": 9.847126007080078,
      "learning_rate": 1.8961445783132532e-05,
      "loss": 0.0957,
      "step": 4310
    },
    {
      "epoch": 0.5204819277108433,
      "grad_norm": 5.845399379730225,
      "learning_rate": 1.8959036144578317e-05,
      "loss": 0.1578,
      "step": 4320
    },
    {
      "epoch": 0.5216867469879518,
      "grad_norm": 15.146419525146484,
      "learning_rate": 1.8956626506024098e-05,
      "loss": 0.2705,
      "step": 4330
    },
    {
      "epoch": 0.5228915662650603,
      "grad_norm": 4.702899932861328,
      "learning_rate": 1.895421686746988e-05,
      "loss": 0.0723,
      "step": 4340
    },
    {
      "epoch": 0.5240963855421686,
      "grad_norm": 6.801593780517578,
      "learning_rate": 1.8951807228915665e-05,
      "loss": 0.1474,
      "step": 4350
    },
    {
      "epoch": 0.5253012048192771,
      "grad_norm": 5.523340702056885,
      "learning_rate": 1.8949397590361446e-05,
      "loss": 0.119,
      "step": 4360
    },
    {
      "epoch": 0.5265060240963856,
      "grad_norm": 3.202326774597168,
      "learning_rate": 1.894698795180723e-05,
      "loss": 0.1656,
      "step": 4370
    },
    {
      "epoch": 0.5277108433734939,
      "grad_norm": 2.1192984580993652,
      "learning_rate": 1.8944578313253012e-05,
      "loss": 0.1132,
      "step": 4380
    },
    {
      "epoch": 0.5289156626506024,
      "grad_norm": 7.363406658172607,
      "learning_rate": 1.8942168674698797e-05,
      "loss": 0.1768,
      "step": 4390
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 6.703871250152588,
      "learning_rate": 1.893975903614458e-05,
      "loss": 0.1557,
      "step": 4400
    },
    {
      "epoch": 0.5313253012048192,
      "grad_norm": 5.5242509841918945,
      "learning_rate": 1.8937349397590364e-05,
      "loss": 0.0923,
      "step": 4410
    },
    {
      "epoch": 0.5325301204819277,
      "grad_norm": 4.803158283233643,
      "learning_rate": 1.8934939759036145e-05,
      "loss": 0.0752,
      "step": 4420
    },
    {
      "epoch": 0.5337349397590362,
      "grad_norm": 8.951635360717773,
      "learning_rate": 1.893253012048193e-05,
      "loss": 0.2035,
      "step": 4430
    },
    {
      "epoch": 0.5349397590361445,
      "grad_norm": 9.59864616394043,
      "learning_rate": 1.893012048192771e-05,
      "loss": 0.1209,
      "step": 4440
    },
    {
      "epoch": 0.536144578313253,
      "grad_norm": 2.683983564376831,
      "learning_rate": 1.8927710843373493e-05,
      "loss": 0.1459,
      "step": 4450
    },
    {
      "epoch": 0.5373493975903615,
      "grad_norm": 4.456718921661377,
      "learning_rate": 1.892530120481928e-05,
      "loss": 0.1749,
      "step": 4460
    },
    {
      "epoch": 0.5385542168674698,
      "grad_norm": 4.5058746337890625,
      "learning_rate": 1.8922891566265063e-05,
      "loss": 0.1166,
      "step": 4470
    },
    {
      "epoch": 0.5397590361445783,
      "grad_norm": 5.3510565757751465,
      "learning_rate": 1.8920481927710844e-05,
      "loss": 0.1392,
      "step": 4480
    },
    {
      "epoch": 0.5409638554216868,
      "grad_norm": 8.820420265197754,
      "learning_rate": 1.891807228915663e-05,
      "loss": 0.1182,
      "step": 4490
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 4.028929710388184,
      "learning_rate": 1.891566265060241e-05,
      "loss": 0.1293,
      "step": 4500
    },
    {
      "epoch": 0.5433734939759036,
      "grad_norm": 7.258902549743652,
      "learning_rate": 1.8913253012048195e-05,
      "loss": 0.2162,
      "step": 4510
    },
    {
      "epoch": 0.5445783132530121,
      "grad_norm": 9.301072120666504,
      "learning_rate": 1.8910843373493977e-05,
      "loss": 0.1439,
      "step": 4520
    },
    {
      "epoch": 0.5457831325301205,
      "grad_norm": 8.130938529968262,
      "learning_rate": 1.890843373493976e-05,
      "loss": 0.1196,
      "step": 4530
    },
    {
      "epoch": 0.5469879518072289,
      "grad_norm": 5.9499735832214355,
      "learning_rate": 1.8906024096385543e-05,
      "loss": 0.0929,
      "step": 4540
    },
    {
      "epoch": 0.5481927710843374,
      "grad_norm": 6.327598571777344,
      "learning_rate": 1.8903614457831328e-05,
      "loss": 0.1328,
      "step": 4550
    },
    {
      "epoch": 0.5493975903614458,
      "grad_norm": 5.520823001861572,
      "learning_rate": 1.890120481927711e-05,
      "loss": 0.1892,
      "step": 4560
    },
    {
      "epoch": 0.5506024096385542,
      "grad_norm": 1.0060139894485474,
      "learning_rate": 1.8898795180722894e-05,
      "loss": 0.133,
      "step": 4570
    },
    {
      "epoch": 0.5518072289156627,
      "grad_norm": 2.373734474182129,
      "learning_rate": 1.8896385542168676e-05,
      "loss": 0.1328,
      "step": 4580
    },
    {
      "epoch": 0.553012048192771,
      "grad_norm": 8.465027809143066,
      "learning_rate": 1.8893975903614457e-05,
      "loss": 0.1446,
      "step": 4590
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 3.1231231689453125,
      "learning_rate": 1.8891566265060242e-05,
      "loss": 0.1141,
      "step": 4600
    },
    {
      "epoch": 0.555421686746988,
      "grad_norm": 9.412873268127441,
      "learning_rate": 1.8889156626506027e-05,
      "loss": 0.1596,
      "step": 4610
    },
    {
      "epoch": 0.5566265060240964,
      "grad_norm": 4.724244594573975,
      "learning_rate": 1.888674698795181e-05,
      "loss": 0.1749,
      "step": 4620
    },
    {
      "epoch": 0.5578313253012048,
      "grad_norm": 1.694797158241272,
      "learning_rate": 1.8884337349397593e-05,
      "loss": 0.0668,
      "step": 4630
    },
    {
      "epoch": 0.5590361445783133,
      "grad_norm": 0.6951466798782349,
      "learning_rate": 1.8881927710843375e-05,
      "loss": 0.096,
      "step": 4640
    },
    {
      "epoch": 0.5602409638554217,
      "grad_norm": 3.89206862449646,
      "learning_rate": 1.8879518072289156e-05,
      "loss": 0.1176,
      "step": 4650
    },
    {
      "epoch": 0.5614457831325301,
      "grad_norm": 5.12922477722168,
      "learning_rate": 1.887710843373494e-05,
      "loss": 0.0608,
      "step": 4660
    },
    {
      "epoch": 0.5626506024096386,
      "grad_norm": 5.060561656951904,
      "learning_rate": 1.8874698795180723e-05,
      "loss": 0.186,
      "step": 4670
    },
    {
      "epoch": 0.563855421686747,
      "grad_norm": 1.2866302728652954,
      "learning_rate": 1.8872289156626508e-05,
      "loss": 0.0889,
      "step": 4680
    },
    {
      "epoch": 0.5650602409638554,
      "grad_norm": 6.089291095733643,
      "learning_rate": 1.8869879518072293e-05,
      "loss": 0.2322,
      "step": 4690
    },
    {
      "epoch": 0.5662650602409639,
      "grad_norm": 2.6007981300354004,
      "learning_rate": 1.8867469879518074e-05,
      "loss": 0.1137,
      "step": 4700
    },
    {
      "epoch": 0.5674698795180723,
      "grad_norm": 8.158504486083984,
      "learning_rate": 1.886506024096386e-05,
      "loss": 0.0796,
      "step": 4710
    },
    {
      "epoch": 0.5686746987951807,
      "grad_norm": 7.98458194732666,
      "learning_rate": 1.886265060240964e-05,
      "loss": 0.1155,
      "step": 4720
    },
    {
      "epoch": 0.5698795180722892,
      "grad_norm": 0.7846695780754089,
      "learning_rate": 1.8860240963855422e-05,
      "loss": 0.2128,
      "step": 4730
    },
    {
      "epoch": 0.5710843373493976,
      "grad_norm": 2.6484217643737793,
      "learning_rate": 1.8857831325301207e-05,
      "loss": 0.0889,
      "step": 4740
    },
    {
      "epoch": 0.572289156626506,
      "grad_norm": 1.5403192043304443,
      "learning_rate": 1.8855421686746988e-05,
      "loss": 0.1388,
      "step": 4750
    },
    {
      "epoch": 0.5734939759036145,
      "grad_norm": 0.6755626797676086,
      "learning_rate": 1.8853012048192773e-05,
      "loss": 0.0768,
      "step": 4760
    },
    {
      "epoch": 0.5746987951807229,
      "grad_norm": 2.252408981323242,
      "learning_rate": 1.8850602409638558e-05,
      "loss": 0.1496,
      "step": 4770
    },
    {
      "epoch": 0.5759036144578313,
      "grad_norm": 1.3583630323410034,
      "learning_rate": 1.884819277108434e-05,
      "loss": 0.0607,
      "step": 4780
    },
    {
      "epoch": 0.5771084337349398,
      "grad_norm": 4.299201488494873,
      "learning_rate": 1.884578313253012e-05,
      "loss": 0.1451,
      "step": 4790
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 0.30993422865867615,
      "learning_rate": 1.8843373493975906e-05,
      "loss": 0.0816,
      "step": 4800
    },
    {
      "epoch": 0.5795180722891566,
      "grad_norm": 5.3967976570129395,
      "learning_rate": 1.8840963855421687e-05,
      "loss": 0.1531,
      "step": 4810
    },
    {
      "epoch": 0.5807228915662651,
      "grad_norm": 0.41310885548591614,
      "learning_rate": 1.8838554216867472e-05,
      "loss": 0.1039,
      "step": 4820
    },
    {
      "epoch": 0.5819277108433735,
      "grad_norm": 4.880123138427734,
      "learning_rate": 1.8836144578313254e-05,
      "loss": 0.1141,
      "step": 4830
    },
    {
      "epoch": 0.5831325301204819,
      "grad_norm": 8.136804580688477,
      "learning_rate": 1.883373493975904e-05,
      "loss": 0.1105,
      "step": 4840
    },
    {
      "epoch": 0.5843373493975904,
      "grad_norm": 0.7945200800895691,
      "learning_rate": 1.883132530120482e-05,
      "loss": 0.1176,
      "step": 4850
    },
    {
      "epoch": 0.5855421686746988,
      "grad_norm": 3.8499724864959717,
      "learning_rate": 1.8828915662650605e-05,
      "loss": 0.1398,
      "step": 4860
    },
    {
      "epoch": 0.5867469879518072,
      "grad_norm": 0.7699307203292847,
      "learning_rate": 1.8826506024096386e-05,
      "loss": 0.0736,
      "step": 4870
    },
    {
      "epoch": 0.5879518072289157,
      "grad_norm": 0.29244673252105713,
      "learning_rate": 1.882409638554217e-05,
      "loss": 0.1636,
      "step": 4880
    },
    {
      "epoch": 0.5891566265060241,
      "grad_norm": 0.11993590742349625,
      "learning_rate": 1.8821686746987953e-05,
      "loss": 0.0938,
      "step": 4890
    },
    {
      "epoch": 0.5903614457831325,
      "grad_norm": 1.6524685621261597,
      "learning_rate": 1.8819277108433734e-05,
      "loss": 0.1317,
      "step": 4900
    },
    {
      "epoch": 0.591566265060241,
      "grad_norm": 11.79620361328125,
      "learning_rate": 1.881686746987952e-05,
      "loss": 0.1596,
      "step": 4910
    },
    {
      "epoch": 0.5927710843373494,
      "grad_norm": 0.43797317147254944,
      "learning_rate": 1.8814457831325304e-05,
      "loss": 0.1031,
      "step": 4920
    },
    {
      "epoch": 0.5939759036144578,
      "grad_norm": 4.180967807769775,
      "learning_rate": 1.8812048192771085e-05,
      "loss": 0.1243,
      "step": 4930
    },
    {
      "epoch": 0.5951807228915663,
      "grad_norm": 0.18799881637096405,
      "learning_rate": 1.880963855421687e-05,
      "loss": 0.1311,
      "step": 4940
    },
    {
      "epoch": 0.5963855421686747,
      "grad_norm": 2.2127318382263184,
      "learning_rate": 1.8807228915662652e-05,
      "loss": 0.1437,
      "step": 4950
    },
    {
      "epoch": 0.5975903614457831,
      "grad_norm": 7.21812105178833,
      "learning_rate": 1.8804819277108433e-05,
      "loss": 0.1207,
      "step": 4960
    },
    {
      "epoch": 0.5987951807228916,
      "grad_norm": 5.461978435516357,
      "learning_rate": 1.8802409638554218e-05,
      "loss": 0.0751,
      "step": 4970
    },
    {
      "epoch": 0.6,
      "grad_norm": 11.315877914428711,
      "learning_rate": 1.88e-05,
      "loss": 0.1709,
      "step": 4980
    },
    {
      "epoch": 0.6012048192771084,
      "grad_norm": 0.7876281142234802,
      "learning_rate": 1.8797590361445784e-05,
      "loss": 0.0886,
      "step": 4990
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 9.877077102661133,
      "learning_rate": 1.879518072289157e-05,
      "loss": 0.0791,
      "step": 5000
    },
    {
      "epoch": 0.6036144578313253,
      "grad_norm": 2.1512153148651123,
      "learning_rate": 1.879277108433735e-05,
      "loss": 0.1955,
      "step": 5010
    },
    {
      "epoch": 0.6048192771084338,
      "grad_norm": 2.5126781463623047,
      "learning_rate": 1.8790361445783136e-05,
      "loss": 0.1196,
      "step": 5020
    },
    {
      "epoch": 0.6060240963855422,
      "grad_norm": 3.066344738006592,
      "learning_rate": 1.8787951807228917e-05,
      "loss": 0.1091,
      "step": 5030
    },
    {
      "epoch": 0.6072289156626506,
      "grad_norm": 14.295502662658691,
      "learning_rate": 1.87855421686747e-05,
      "loss": 0.1191,
      "step": 5040
    },
    {
      "epoch": 0.608433734939759,
      "grad_norm": 7.433387756347656,
      "learning_rate": 1.8783132530120483e-05,
      "loss": 0.185,
      "step": 5050
    },
    {
      "epoch": 0.6096385542168675,
      "grad_norm": 6.568281650543213,
      "learning_rate": 1.878072289156627e-05,
      "loss": 0.1085,
      "step": 5060
    },
    {
      "epoch": 0.6108433734939759,
      "grad_norm": 5.006078243255615,
      "learning_rate": 1.877831325301205e-05,
      "loss": 0.112,
      "step": 5070
    },
    {
      "epoch": 0.6120481927710844,
      "grad_norm": 4.044361114501953,
      "learning_rate": 1.8775903614457835e-05,
      "loss": 0.1296,
      "step": 5080
    },
    {
      "epoch": 0.6132530120481928,
      "grad_norm": 3.903991222381592,
      "learning_rate": 1.8773493975903616e-05,
      "loss": 0.088,
      "step": 5090
    },
    {
      "epoch": 0.6144578313253012,
      "grad_norm": 5.961790084838867,
      "learning_rate": 1.8771084337349398e-05,
      "loss": 0.1202,
      "step": 5100
    },
    {
      "epoch": 0.6156626506024097,
      "grad_norm": 6.412744045257568,
      "learning_rate": 1.8768674698795183e-05,
      "loss": 0.1485,
      "step": 5110
    },
    {
      "epoch": 0.6168674698795181,
      "grad_norm": 7.704315662384033,
      "learning_rate": 1.8766265060240964e-05,
      "loss": 0.2404,
      "step": 5120
    },
    {
      "epoch": 0.6180722891566265,
      "grad_norm": 0.883392870426178,
      "learning_rate": 1.876385542168675e-05,
      "loss": 0.158,
      "step": 5130
    },
    {
      "epoch": 0.619277108433735,
      "grad_norm": 6.393237113952637,
      "learning_rate": 1.8761445783132534e-05,
      "loss": 0.1476,
      "step": 5140
    },
    {
      "epoch": 0.6204819277108434,
      "grad_norm": 5.120953559875488,
      "learning_rate": 1.8759036144578315e-05,
      "loss": 0.1419,
      "step": 5150
    },
    {
      "epoch": 0.6216867469879518,
      "grad_norm": 1.5687445402145386,
      "learning_rate": 1.8756626506024097e-05,
      "loss": 0.1318,
      "step": 5160
    },
    {
      "epoch": 0.6228915662650603,
      "grad_norm": 9.60091781616211,
      "learning_rate": 1.875421686746988e-05,
      "loss": 0.1432,
      "step": 5170
    },
    {
      "epoch": 0.6240963855421687,
      "grad_norm": 2.4811577796936035,
      "learning_rate": 1.8751807228915663e-05,
      "loss": 0.0688,
      "step": 5180
    },
    {
      "epoch": 0.6253012048192771,
      "grad_norm": 2.248140811920166,
      "learning_rate": 1.8749397590361448e-05,
      "loss": 0.0883,
      "step": 5190
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 14.323354721069336,
      "learning_rate": 1.874698795180723e-05,
      "loss": 0.1307,
      "step": 5200
    },
    {
      "epoch": 0.6277108433734939,
      "grad_norm": 8.32299518585205,
      "learning_rate": 1.8744578313253014e-05,
      "loss": 0.1423,
      "step": 5210
    },
    {
      "epoch": 0.6289156626506024,
      "grad_norm": 7.701873779296875,
      "learning_rate": 1.8742168674698796e-05,
      "loss": 0.1604,
      "step": 5220
    },
    {
      "epoch": 0.6301204819277109,
      "grad_norm": 4.1247100830078125,
      "learning_rate": 1.873975903614458e-05,
      "loss": 0.1052,
      "step": 5230
    },
    {
      "epoch": 0.6313253012048192,
      "grad_norm": 3.9269003868103027,
      "learning_rate": 1.8737349397590362e-05,
      "loss": 0.1554,
      "step": 5240
    },
    {
      "epoch": 0.6325301204819277,
      "grad_norm": 5.488824367523193,
      "learning_rate": 1.8734939759036147e-05,
      "loss": 0.0622,
      "step": 5250
    },
    {
      "epoch": 0.6337349397590362,
      "grad_norm": 6.724986553192139,
      "learning_rate": 1.873253012048193e-05,
      "loss": 0.0631,
      "step": 5260
    },
    {
      "epoch": 0.6349397590361445,
      "grad_norm": 5.884101390838623,
      "learning_rate": 1.873012048192771e-05,
      "loss": 0.1074,
      "step": 5270
    },
    {
      "epoch": 0.636144578313253,
      "grad_norm": 7.050650596618652,
      "learning_rate": 1.8727710843373495e-05,
      "loss": 0.0676,
      "step": 5280
    },
    {
      "epoch": 0.6373493975903615,
      "grad_norm": 0.982199490070343,
      "learning_rate": 1.872530120481928e-05,
      "loss": 0.1541,
      "step": 5290
    },
    {
      "epoch": 0.6385542168674698,
      "grad_norm": 5.288297653198242,
      "learning_rate": 1.872289156626506e-05,
      "loss": 0.1154,
      "step": 5300
    },
    {
      "epoch": 0.6397590361445783,
      "grad_norm": 7.029851913452148,
      "learning_rate": 1.8720481927710846e-05,
      "loss": 0.1856,
      "step": 5310
    },
    {
      "epoch": 0.6409638554216868,
      "grad_norm": 0.4946400225162506,
      "learning_rate": 1.8718072289156628e-05,
      "loss": 0.1168,
      "step": 5320
    },
    {
      "epoch": 0.6421686746987951,
      "grad_norm": 7.3750152587890625,
      "learning_rate": 1.8715662650602412e-05,
      "loss": 0.149,
      "step": 5330
    },
    {
      "epoch": 0.6433734939759036,
      "grad_norm": 0.22741210460662842,
      "learning_rate": 1.8713253012048194e-05,
      "loss": 0.065,
      "step": 5340
    },
    {
      "epoch": 0.6445783132530121,
      "grad_norm": 9.056489944458008,
      "learning_rate": 1.8710843373493975e-05,
      "loss": 0.1828,
      "step": 5350
    },
    {
      "epoch": 0.6457831325301204,
      "grad_norm": 3.677492141723633,
      "learning_rate": 1.870843373493976e-05,
      "loss": 0.1102,
      "step": 5360
    },
    {
      "epoch": 0.6469879518072289,
      "grad_norm": 8.300512313842773,
      "learning_rate": 1.8706024096385545e-05,
      "loss": 0.1206,
      "step": 5370
    },
    {
      "epoch": 0.6481927710843374,
      "grad_norm": 0.43546977639198303,
      "learning_rate": 1.8703614457831327e-05,
      "loss": 0.0943,
      "step": 5380
    },
    {
      "epoch": 0.6493975903614457,
      "grad_norm": 3.5915420055389404,
      "learning_rate": 1.870120481927711e-05,
      "loss": 0.1004,
      "step": 5390
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 2.030383825302124,
      "learning_rate": 1.8698795180722893e-05,
      "loss": 0.1441,
      "step": 5400
    },
    {
      "epoch": 0.6518072289156627,
      "grad_norm": 0.5086858868598938,
      "learning_rate": 1.8696385542168674e-05,
      "loss": 0.1929,
      "step": 5410
    },
    {
      "epoch": 0.653012048192771,
      "grad_norm": 7.377915859222412,
      "learning_rate": 1.869397590361446e-05,
      "loss": 0.1319,
      "step": 5420
    },
    {
      "epoch": 0.6542168674698795,
      "grad_norm": 12.865543365478516,
      "learning_rate": 1.869156626506024e-05,
      "loss": 0.1813,
      "step": 5430
    },
    {
      "epoch": 0.655421686746988,
      "grad_norm": 3.5688791275024414,
      "learning_rate": 1.8689156626506026e-05,
      "loss": 0.1408,
      "step": 5440
    },
    {
      "epoch": 0.6566265060240963,
      "grad_norm": 6.397617816925049,
      "learning_rate": 1.868674698795181e-05,
      "loss": 0.0981,
      "step": 5450
    },
    {
      "epoch": 0.6578313253012048,
      "grad_norm": 4.718787670135498,
      "learning_rate": 1.8684337349397592e-05,
      "loss": 0.1143,
      "step": 5460
    },
    {
      "epoch": 0.6590361445783133,
      "grad_norm": 0.4595813453197479,
      "learning_rate": 1.8681927710843374e-05,
      "loss": 0.1033,
      "step": 5470
    },
    {
      "epoch": 0.6602409638554216,
      "grad_norm": 3.8233487606048584,
      "learning_rate": 1.867951807228916e-05,
      "loss": 0.1409,
      "step": 5480
    },
    {
      "epoch": 0.6614457831325301,
      "grad_norm": 0.3238898515701294,
      "learning_rate": 1.867710843373494e-05,
      "loss": 0.0892,
      "step": 5490
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 4.759103775024414,
      "learning_rate": 1.8674698795180725e-05,
      "loss": 0.1334,
      "step": 5500
    },
    {
      "epoch": 0.6638554216867469,
      "grad_norm": 3.814723491668701,
      "learning_rate": 1.867228915662651e-05,
      "loss": 0.1767,
      "step": 5510
    },
    {
      "epoch": 0.6650602409638554,
      "grad_norm": 1.0213193893432617,
      "learning_rate": 1.866987951807229e-05,
      "loss": 0.0964,
      "step": 5520
    },
    {
      "epoch": 0.6662650602409639,
      "grad_norm": 19.93436050415039,
      "learning_rate": 1.8667469879518073e-05,
      "loss": 0.1216,
      "step": 5530
    },
    {
      "epoch": 0.6674698795180722,
      "grad_norm": 2.3817951679229736,
      "learning_rate": 1.8665060240963857e-05,
      "loss": 0.1455,
      "step": 5540
    },
    {
      "epoch": 0.6686746987951807,
      "grad_norm": 5.878204345703125,
      "learning_rate": 1.866265060240964e-05,
      "loss": 0.0694,
      "step": 5550
    },
    {
      "epoch": 0.6698795180722892,
      "grad_norm": 9.110698699951172,
      "learning_rate": 1.8660240963855424e-05,
      "loss": 0.1719,
      "step": 5560
    },
    {
      "epoch": 0.6710843373493975,
      "grad_norm": 2.0626580715179443,
      "learning_rate": 1.8657831325301205e-05,
      "loss": 0.047,
      "step": 5570
    },
    {
      "epoch": 0.672289156626506,
      "grad_norm": 5.784809589385986,
      "learning_rate": 1.8655421686746987e-05,
      "loss": 0.1654,
      "step": 5580
    },
    {
      "epoch": 0.6734939759036145,
      "grad_norm": 0.17027148604393005,
      "learning_rate": 1.8653012048192775e-05,
      "loss": 0.1023,
      "step": 5590
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 3.8813796043395996,
      "learning_rate": 1.8650602409638556e-05,
      "loss": 0.1669,
      "step": 5600
    },
    {
      "epoch": 0.6759036144578313,
      "grad_norm": 4.829019546508789,
      "learning_rate": 1.8648192771084338e-05,
      "loss": 0.1577,
      "step": 5610
    },
    {
      "epoch": 0.6771084337349398,
      "grad_norm": 2.0142931938171387,
      "learning_rate": 1.8645783132530123e-05,
      "loss": 0.1097,
      "step": 5620
    },
    {
      "epoch": 0.6783132530120481,
      "grad_norm": 3.684321880340576,
      "learning_rate": 1.8643373493975904e-05,
      "loss": 0.0663,
      "step": 5630
    },
    {
      "epoch": 0.6795180722891566,
      "grad_norm": 1.0180542469024658,
      "learning_rate": 1.864096385542169e-05,
      "loss": 0.1218,
      "step": 5640
    },
    {
      "epoch": 0.6807228915662651,
      "grad_norm": 9.663840293884277,
      "learning_rate": 1.863855421686747e-05,
      "loss": 0.0822,
      "step": 5650
    },
    {
      "epoch": 0.6819277108433734,
      "grad_norm": 2.0397918224334717,
      "learning_rate": 1.8636144578313256e-05,
      "loss": 0.1628,
      "step": 5660
    },
    {
      "epoch": 0.6831325301204819,
      "grad_norm": 2.3289663791656494,
      "learning_rate": 1.8633734939759037e-05,
      "loss": 0.1365,
      "step": 5670
    },
    {
      "epoch": 0.6843373493975904,
      "grad_norm": 5.441011428833008,
      "learning_rate": 1.8631325301204822e-05,
      "loss": 0.1186,
      "step": 5680
    },
    {
      "epoch": 0.6855421686746987,
      "grad_norm": 7.3624982833862305,
      "learning_rate": 1.8628915662650603e-05,
      "loss": 0.0983,
      "step": 5690
    },
    {
      "epoch": 0.6867469879518072,
      "grad_norm": 2.441263198852539,
      "learning_rate": 1.8626506024096388e-05,
      "loss": 0.1349,
      "step": 5700
    },
    {
      "epoch": 0.6879518072289157,
      "grad_norm": 3.4063663482666016,
      "learning_rate": 1.862409638554217e-05,
      "loss": 0.1386,
      "step": 5710
    },
    {
      "epoch": 0.689156626506024,
      "grad_norm": 4.698746681213379,
      "learning_rate": 1.862168674698795e-05,
      "loss": 0.1852,
      "step": 5720
    },
    {
      "epoch": 0.6903614457831325,
      "grad_norm": 4.77507209777832,
      "learning_rate": 1.8619277108433736e-05,
      "loss": 0.1563,
      "step": 5730
    },
    {
      "epoch": 0.691566265060241,
      "grad_norm": 6.560878753662109,
      "learning_rate": 1.861686746987952e-05,
      "loss": 0.0895,
      "step": 5740
    },
    {
      "epoch": 0.6927710843373494,
      "grad_norm": 0.4879531264305115,
      "learning_rate": 1.8614457831325302e-05,
      "loss": 0.0479,
      "step": 5750
    },
    {
      "epoch": 0.6939759036144578,
      "grad_norm": 7.620132923126221,
      "learning_rate": 1.8612048192771087e-05,
      "loss": 0.1342,
      "step": 5760
    },
    {
      "epoch": 0.6951807228915663,
      "grad_norm": 6.175224781036377,
      "learning_rate": 1.860963855421687e-05,
      "loss": 0.1344,
      "step": 5770
    },
    {
      "epoch": 0.6963855421686747,
      "grad_norm": 13.300914764404297,
      "learning_rate": 1.860722891566265e-05,
      "loss": 0.1597,
      "step": 5780
    },
    {
      "epoch": 0.6975903614457831,
      "grad_norm": 2.8737289905548096,
      "learning_rate": 1.8604819277108435e-05,
      "loss": 0.0988,
      "step": 5790
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 4.2178425788879395,
      "learning_rate": 1.8602409638554217e-05,
      "loss": 0.1667,
      "step": 5800
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.8763372898101807,
      "learning_rate": 1.86e-05,
      "loss": 0.1143,
      "step": 5810
    },
    {
      "epoch": 0.7012048192771084,
      "grad_norm": 0.19086503982543945,
      "learning_rate": 1.8597590361445786e-05,
      "loss": 0.0647,
      "step": 5820
    },
    {
      "epoch": 0.7024096385542169,
      "grad_norm": 10.416046142578125,
      "learning_rate": 1.8595180722891568e-05,
      "loss": 0.1145,
      "step": 5830
    },
    {
      "epoch": 0.7036144578313253,
      "grad_norm": 5.682544708251953,
      "learning_rate": 1.859277108433735e-05,
      "loss": 0.1018,
      "step": 5840
    },
    {
      "epoch": 0.7048192771084337,
      "grad_norm": 0.8972011804580688,
      "learning_rate": 1.8590361445783134e-05,
      "loss": 0.1042,
      "step": 5850
    },
    {
      "epoch": 0.7060240963855422,
      "grad_norm": 7.87091588973999,
      "learning_rate": 1.8587951807228916e-05,
      "loss": 0.0845,
      "step": 5860
    },
    {
      "epoch": 0.7072289156626506,
      "grad_norm": 1.9114130735397339,
      "learning_rate": 1.85855421686747e-05,
      "loss": 0.1064,
      "step": 5870
    },
    {
      "epoch": 0.708433734939759,
      "grad_norm": 2.121917724609375,
      "learning_rate": 1.8583132530120482e-05,
      "loss": 0.0606,
      "step": 5880
    },
    {
      "epoch": 0.7096385542168675,
      "grad_norm": 3.208167552947998,
      "learning_rate": 1.8580722891566267e-05,
      "loss": 0.1199,
      "step": 5890
    },
    {
      "epoch": 0.7108433734939759,
      "grad_norm": 3.9258437156677246,
      "learning_rate": 1.8578313253012052e-05,
      "loss": 0.1228,
      "step": 5900
    },
    {
      "epoch": 0.7120481927710843,
      "grad_norm": 10.080450057983398,
      "learning_rate": 1.8575903614457833e-05,
      "loss": 0.1474,
      "step": 5910
    },
    {
      "epoch": 0.7132530120481928,
      "grad_norm": 9.33756160736084,
      "learning_rate": 1.8573493975903615e-05,
      "loss": 0.088,
      "step": 5920
    },
    {
      "epoch": 0.7144578313253012,
      "grad_norm": 0.6205264329910278,
      "learning_rate": 1.85710843373494e-05,
      "loss": 0.0853,
      "step": 5930
    },
    {
      "epoch": 0.7156626506024096,
      "grad_norm": 14.39211368560791,
      "learning_rate": 1.856867469879518e-05,
      "loss": 0.0602,
      "step": 5940
    },
    {
      "epoch": 0.7168674698795181,
      "grad_norm": 2.974841594696045,
      "learning_rate": 1.8566265060240966e-05,
      "loss": 0.1379,
      "step": 5950
    },
    {
      "epoch": 0.7180722891566265,
      "grad_norm": 7.378983974456787,
      "learning_rate": 1.856385542168675e-05,
      "loss": 0.2264,
      "step": 5960
    },
    {
      "epoch": 0.7192771084337349,
      "grad_norm": 0.8216737508773804,
      "learning_rate": 1.8561445783132532e-05,
      "loss": 0.1054,
      "step": 5970
    },
    {
      "epoch": 0.7204819277108434,
      "grad_norm": 0.7061344981193542,
      "learning_rate": 1.8559036144578314e-05,
      "loss": 0.0989,
      "step": 5980
    },
    {
      "epoch": 0.7216867469879518,
      "grad_norm": 4.819334030151367,
      "learning_rate": 1.85566265060241e-05,
      "loss": 0.1285,
      "step": 5990
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 9.680981636047363,
      "learning_rate": 1.855421686746988e-05,
      "loss": 0.0668,
      "step": 6000
    },
    {
      "epoch": 0.7240963855421687,
      "grad_norm": 0.36459529399871826,
      "learning_rate": 1.8551807228915665e-05,
      "loss": 0.0778,
      "step": 6010
    },
    {
      "epoch": 0.7253012048192771,
      "grad_norm": 2.0625898838043213,
      "learning_rate": 1.8549397590361446e-05,
      "loss": 0.0624,
      "step": 6020
    },
    {
      "epoch": 0.7265060240963855,
      "grad_norm": 3.2151684761047363,
      "learning_rate": 1.8546987951807228e-05,
      "loss": 0.1415,
      "step": 6030
    },
    {
      "epoch": 0.727710843373494,
      "grad_norm": 7.872769832611084,
      "learning_rate": 1.8544578313253013e-05,
      "loss": 0.0865,
      "step": 6040
    },
    {
      "epoch": 0.7289156626506024,
      "grad_norm": 4.815021991729736,
      "learning_rate": 1.8542168674698798e-05,
      "loss": 0.1299,
      "step": 6050
    },
    {
      "epoch": 0.7301204819277108,
      "grad_norm": 0.5462462902069092,
      "learning_rate": 1.853975903614458e-05,
      "loss": 0.1211,
      "step": 6060
    },
    {
      "epoch": 0.7313253012048193,
      "grad_norm": 2.0622639656066895,
      "learning_rate": 1.8537349397590364e-05,
      "loss": 0.0785,
      "step": 6070
    },
    {
      "epoch": 0.7325301204819277,
      "grad_norm": 4.590521335601807,
      "learning_rate": 1.8534939759036146e-05,
      "loss": 0.1542,
      "step": 6080
    },
    {
      "epoch": 0.7337349397590361,
      "grad_norm": 8.221961975097656,
      "learning_rate": 1.8532530120481927e-05,
      "loss": 0.1067,
      "step": 6090
    },
    {
      "epoch": 0.7349397590361446,
      "grad_norm": 0.27026429772377014,
      "learning_rate": 1.8530120481927712e-05,
      "loss": 0.0679,
      "step": 6100
    },
    {
      "epoch": 0.736144578313253,
      "grad_norm": 2.749785900115967,
      "learning_rate": 1.8527710843373497e-05,
      "loss": 0.08,
      "step": 6110
    },
    {
      "epoch": 0.7373493975903614,
      "grad_norm": 0.1321742981672287,
      "learning_rate": 1.8525301204819278e-05,
      "loss": 0.092,
      "step": 6120
    },
    {
      "epoch": 0.7385542168674699,
      "grad_norm": 5.215957164764404,
      "learning_rate": 1.8522891566265063e-05,
      "loss": 0.1543,
      "step": 6130
    },
    {
      "epoch": 0.7397590361445783,
      "grad_norm": 5.235121726989746,
      "learning_rate": 1.8520481927710845e-05,
      "loss": 0.1192,
      "step": 6140
    },
    {
      "epoch": 0.7409638554216867,
      "grad_norm": 3.635051727294922,
      "learning_rate": 1.851807228915663e-05,
      "loss": 0.1432,
      "step": 6150
    },
    {
      "epoch": 0.7421686746987952,
      "grad_norm": 1.8527979850769043,
      "learning_rate": 1.851566265060241e-05,
      "loss": 0.2106,
      "step": 6160
    },
    {
      "epoch": 0.7433734939759036,
      "grad_norm": 1.344919204711914,
      "learning_rate": 1.8513253012048192e-05,
      "loss": 0.0794,
      "step": 6170
    },
    {
      "epoch": 0.744578313253012,
      "grad_norm": 4.306054592132568,
      "learning_rate": 1.8510843373493977e-05,
      "loss": 0.0763,
      "step": 6180
    },
    {
      "epoch": 0.7457831325301205,
      "grad_norm": 6.788243293762207,
      "learning_rate": 1.8508433734939762e-05,
      "loss": 0.0794,
      "step": 6190
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 7.005788803100586,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 0.0313,
      "step": 6200
    },
    {
      "epoch": 0.7481927710843373,
      "grad_norm": 4.544755458831787,
      "learning_rate": 1.850361445783133e-05,
      "loss": 0.17,
      "step": 6210
    },
    {
      "epoch": 0.7493975903614458,
      "grad_norm": 3.2821831703186035,
      "learning_rate": 1.850120481927711e-05,
      "loss": 0.1939,
      "step": 6220
    },
    {
      "epoch": 0.7506024096385542,
      "grad_norm": 4.481863498687744,
      "learning_rate": 1.849879518072289e-05,
      "loss": 0.105,
      "step": 6230
    },
    {
      "epoch": 0.7518072289156627,
      "grad_norm": 8.245237350463867,
      "learning_rate": 1.8496385542168676e-05,
      "loss": 0.0941,
      "step": 6240
    },
    {
      "epoch": 0.7530120481927711,
      "grad_norm": 5.520251750946045,
      "learning_rate": 1.8493975903614458e-05,
      "loss": 0.1421,
      "step": 6250
    },
    {
      "epoch": 0.7542168674698795,
      "grad_norm": 3.7459330558776855,
      "learning_rate": 1.8491566265060243e-05,
      "loss": 0.0852,
      "step": 6260
    },
    {
      "epoch": 0.755421686746988,
      "grad_norm": 5.161201477050781,
      "learning_rate": 1.8489156626506028e-05,
      "loss": 0.1144,
      "step": 6270
    },
    {
      "epoch": 0.7566265060240964,
      "grad_norm": 5.0222859382629395,
      "learning_rate": 1.848674698795181e-05,
      "loss": 0.1374,
      "step": 6280
    },
    {
      "epoch": 0.7578313253012048,
      "grad_norm": 1.6963231563568115,
      "learning_rate": 1.848433734939759e-05,
      "loss": 0.0608,
      "step": 6290
    },
    {
      "epoch": 0.7590361445783133,
      "grad_norm": 9.30567741394043,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 0.1233,
      "step": 6300
    },
    {
      "epoch": 0.7602409638554217,
      "grad_norm": 0.8368631601333618,
      "learning_rate": 1.8479518072289157e-05,
      "loss": 0.1193,
      "step": 6310
    },
    {
      "epoch": 0.7614457831325301,
      "grad_norm": 0.1408693790435791,
      "learning_rate": 1.8477108433734942e-05,
      "loss": 0.1344,
      "step": 6320
    },
    {
      "epoch": 0.7626506024096386,
      "grad_norm": 3.549736261367798,
      "learning_rate": 1.8474698795180727e-05,
      "loss": 0.1297,
      "step": 6330
    },
    {
      "epoch": 0.763855421686747,
      "grad_norm": 1.177201747894287,
      "learning_rate": 1.8472289156626508e-05,
      "loss": 0.0641,
      "step": 6340
    },
    {
      "epoch": 0.7650602409638554,
      "grad_norm": 8.12145709991455,
      "learning_rate": 1.846987951807229e-05,
      "loss": 0.1008,
      "step": 6350
    },
    {
      "epoch": 0.7662650602409639,
      "grad_norm": 7.510659694671631,
      "learning_rate": 1.8467469879518074e-05,
      "loss": 0.1471,
      "step": 6360
    },
    {
      "epoch": 0.7674698795180723,
      "grad_norm": 0.27100643515586853,
      "learning_rate": 1.8465060240963856e-05,
      "loss": 0.1038,
      "step": 6370
    },
    {
      "epoch": 0.7686746987951807,
      "grad_norm": 11.528839111328125,
      "learning_rate": 1.846265060240964e-05,
      "loss": 0.155,
      "step": 6380
    },
    {
      "epoch": 0.7698795180722892,
      "grad_norm": 2.2053651809692383,
      "learning_rate": 1.8460240963855422e-05,
      "loss": 0.0694,
      "step": 6390
    },
    {
      "epoch": 0.7710843373493976,
      "grad_norm": 12.180487632751465,
      "learning_rate": 1.8457831325301204e-05,
      "loss": 0.0693,
      "step": 6400
    },
    {
      "epoch": 0.772289156626506,
      "grad_norm": 4.177915573120117,
      "learning_rate": 1.8455421686746992e-05,
      "loss": 0.128,
      "step": 6410
    },
    {
      "epoch": 0.7734939759036145,
      "grad_norm": 2.52829909324646,
      "learning_rate": 1.8453012048192774e-05,
      "loss": 0.0999,
      "step": 6420
    },
    {
      "epoch": 0.7746987951807229,
      "grad_norm": 1.900012731552124,
      "learning_rate": 1.8450602409638555e-05,
      "loss": 0.0859,
      "step": 6430
    },
    {
      "epoch": 0.7759036144578313,
      "grad_norm": 1.532802700996399,
      "learning_rate": 1.844819277108434e-05,
      "loss": 0.1313,
      "step": 6440
    },
    {
      "epoch": 0.7771084337349398,
      "grad_norm": 5.5009613037109375,
      "learning_rate": 1.844578313253012e-05,
      "loss": 0.1488,
      "step": 6450
    },
    {
      "epoch": 0.7783132530120482,
      "grad_norm": 10.86860466003418,
      "learning_rate": 1.8443373493975906e-05,
      "loss": 0.0637,
      "step": 6460
    },
    {
      "epoch": 0.7795180722891566,
      "grad_norm": 4.466026306152344,
      "learning_rate": 1.8440963855421688e-05,
      "loss": 0.1131,
      "step": 6470
    },
    {
      "epoch": 0.7807228915662651,
      "grad_norm": 13.38182544708252,
      "learning_rate": 1.8438554216867473e-05,
      "loss": 0.0833,
      "step": 6480
    },
    {
      "epoch": 0.7819277108433735,
      "grad_norm": 5.039552211761475,
      "learning_rate": 1.8436144578313254e-05,
      "loss": 0.0394,
      "step": 6490
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 5.415034770965576,
      "learning_rate": 1.843373493975904e-05,
      "loss": 0.1195,
      "step": 6500
    },
    {
      "epoch": 0.7843373493975904,
      "grad_norm": 3.70861554145813,
      "learning_rate": 1.843132530120482e-05,
      "loss": 0.076,
      "step": 6510
    },
    {
      "epoch": 0.7855421686746988,
      "grad_norm": 0.18446789681911469,
      "learning_rate": 1.8428915662650605e-05,
      "loss": 0.1012,
      "step": 6520
    },
    {
      "epoch": 0.7867469879518072,
      "grad_norm": 0.7978929281234741,
      "learning_rate": 1.8426506024096387e-05,
      "loss": 0.1219,
      "step": 6530
    },
    {
      "epoch": 0.7879518072289157,
      "grad_norm": 10.201005935668945,
      "learning_rate": 1.8424096385542168e-05,
      "loss": 0.0731,
      "step": 6540
    },
    {
      "epoch": 0.7891566265060241,
      "grad_norm": 2.919398784637451,
      "learning_rate": 1.8421686746987953e-05,
      "loss": 0.0875,
      "step": 6550
    },
    {
      "epoch": 0.7903614457831325,
      "grad_norm": 0.3943372368812561,
      "learning_rate": 1.8419277108433738e-05,
      "loss": 0.0839,
      "step": 6560
    },
    {
      "epoch": 0.791566265060241,
      "grad_norm": 0.05246870964765549,
      "learning_rate": 1.841686746987952e-05,
      "loss": 0.0979,
      "step": 6570
    },
    {
      "epoch": 0.7927710843373494,
      "grad_norm": 3.762648344039917,
      "learning_rate": 1.8414457831325304e-05,
      "loss": 0.112,
      "step": 6580
    },
    {
      "epoch": 0.7939759036144578,
      "grad_norm": 0.4929891526699066,
      "learning_rate": 1.8412048192771086e-05,
      "loss": 0.1563,
      "step": 6590
    },
    {
      "epoch": 0.7951807228915663,
      "grad_norm": 0.5114710927009583,
      "learning_rate": 1.8409638554216867e-05,
      "loss": 0.1288,
      "step": 6600
    },
    {
      "epoch": 0.7963855421686747,
      "grad_norm": 8.673648834228516,
      "learning_rate": 1.8407228915662652e-05,
      "loss": 0.1306,
      "step": 6610
    },
    {
      "epoch": 0.7975903614457831,
      "grad_norm": 8.81501579284668,
      "learning_rate": 1.8404819277108434e-05,
      "loss": 0.1513,
      "step": 6620
    },
    {
      "epoch": 0.7987951807228916,
      "grad_norm": 3.420438766479492,
      "learning_rate": 1.840240963855422e-05,
      "loss": 0.0588,
      "step": 6630
    },
    {
      "epoch": 0.8,
      "grad_norm": 13.30254077911377,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.1896,
      "step": 6640
    },
    {
      "epoch": 0.8012048192771084,
      "grad_norm": 0.21552224457263947,
      "learning_rate": 1.8397590361445785e-05,
      "loss": 0.136,
      "step": 6650
    },
    {
      "epoch": 0.8024096385542169,
      "grad_norm": 3.026980400085449,
      "learning_rate": 1.8395180722891566e-05,
      "loss": 0.1325,
      "step": 6660
    },
    {
      "epoch": 0.8036144578313253,
      "grad_norm": 6.341224193572998,
      "learning_rate": 1.839277108433735e-05,
      "loss": 0.1061,
      "step": 6670
    },
    {
      "epoch": 0.8048192771084337,
      "grad_norm": 1.5196993350982666,
      "learning_rate": 1.8390361445783133e-05,
      "loss": 0.081,
      "step": 6680
    },
    {
      "epoch": 0.8060240963855422,
      "grad_norm": 0.32125189900398254,
      "learning_rate": 1.8387951807228918e-05,
      "loss": 0.0794,
      "step": 6690
    },
    {
      "epoch": 0.8072289156626506,
      "grad_norm": 0.9355881810188293,
      "learning_rate": 1.83855421686747e-05,
      "loss": 0.0232,
      "step": 6700
    },
    {
      "epoch": 0.808433734939759,
      "grad_norm": 0.0878085345029831,
      "learning_rate": 1.8383132530120484e-05,
      "loss": 0.0648,
      "step": 6710
    },
    {
      "epoch": 0.8096385542168675,
      "grad_norm": 1.211658239364624,
      "learning_rate": 1.838072289156627e-05,
      "loss": 0.1338,
      "step": 6720
    },
    {
      "epoch": 0.810843373493976,
      "grad_norm": 0.0615202821791172,
      "learning_rate": 1.837831325301205e-05,
      "loss": 0.1259,
      "step": 6730
    },
    {
      "epoch": 0.8120481927710843,
      "grad_norm": 0.6712436079978943,
      "learning_rate": 1.8375903614457832e-05,
      "loss": 0.138,
      "step": 6740
    },
    {
      "epoch": 0.8132530120481928,
      "grad_norm": 0.903925895690918,
      "learning_rate": 1.8373493975903617e-05,
      "loss": 0.1048,
      "step": 6750
    },
    {
      "epoch": 0.8144578313253013,
      "grad_norm": 3.4716992378234863,
      "learning_rate": 1.8371084337349398e-05,
      "loss": 0.0432,
      "step": 6760
    },
    {
      "epoch": 0.8156626506024096,
      "grad_norm": 7.0055646896362305,
      "learning_rate": 1.8368674698795183e-05,
      "loss": 0.0848,
      "step": 6770
    },
    {
      "epoch": 0.8168674698795181,
      "grad_norm": 1.2328455448150635,
      "learning_rate": 1.8366265060240968e-05,
      "loss": 0.0799,
      "step": 6780
    },
    {
      "epoch": 0.8180722891566266,
      "grad_norm": 7.100626468658447,
      "learning_rate": 1.836385542168675e-05,
      "loss": 0.1405,
      "step": 6790
    },
    {
      "epoch": 0.8192771084337349,
      "grad_norm": 1.6777690649032593,
      "learning_rate": 1.836144578313253e-05,
      "loss": 0.195,
      "step": 6800
    },
    {
      "epoch": 0.8204819277108434,
      "grad_norm": 0.6514610052108765,
      "learning_rate": 1.8359036144578316e-05,
      "loss": 0.0463,
      "step": 6810
    },
    {
      "epoch": 0.8216867469879519,
      "grad_norm": 0.19770342111587524,
      "learning_rate": 1.8356626506024097e-05,
      "loss": 0.1299,
      "step": 6820
    },
    {
      "epoch": 0.8228915662650602,
      "grad_norm": 7.003397464752197,
      "learning_rate": 1.8354216867469882e-05,
      "loss": 0.0616,
      "step": 6830
    },
    {
      "epoch": 0.8240963855421687,
      "grad_norm": 0.09046273678541183,
      "learning_rate": 1.8351807228915664e-05,
      "loss": 0.1092,
      "step": 6840
    },
    {
      "epoch": 0.8253012048192772,
      "grad_norm": 0.4331541955471039,
      "learning_rate": 1.8349397590361445e-05,
      "loss": 0.0669,
      "step": 6850
    },
    {
      "epoch": 0.8265060240963855,
      "grad_norm": 4.517170429229736,
      "learning_rate": 1.834698795180723e-05,
      "loss": 0.1666,
      "step": 6860
    },
    {
      "epoch": 0.827710843373494,
      "grad_norm": 8.614119529724121,
      "learning_rate": 1.8344578313253015e-05,
      "loss": 0.0501,
      "step": 6870
    },
    {
      "epoch": 0.8289156626506025,
      "grad_norm": 0.4018610715866089,
      "learning_rate": 1.8342168674698796e-05,
      "loss": 0.0984,
      "step": 6880
    },
    {
      "epoch": 0.8301204819277108,
      "grad_norm": 9.500507354736328,
      "learning_rate": 1.833975903614458e-05,
      "loss": 0.0908,
      "step": 6890
    },
    {
      "epoch": 0.8313253012048193,
      "grad_norm": 0.4471742510795593,
      "learning_rate": 1.8337349397590363e-05,
      "loss": 0.132,
      "step": 6900
    },
    {
      "epoch": 0.8325301204819278,
      "grad_norm": 0.6054849624633789,
      "learning_rate": 1.8334939759036144e-05,
      "loss": 0.2113,
      "step": 6910
    },
    {
      "epoch": 0.8337349397590361,
      "grad_norm": 0.7590433955192566,
      "learning_rate": 1.833253012048193e-05,
      "loss": 0.0982,
      "step": 6920
    },
    {
      "epoch": 0.8349397590361446,
      "grad_norm": 0.25029391050338745,
      "learning_rate": 1.8330120481927714e-05,
      "loss": 0.0533,
      "step": 6930
    },
    {
      "epoch": 0.8361445783132531,
      "grad_norm": 0.6357793807983398,
      "learning_rate": 1.8327710843373495e-05,
      "loss": 0.1137,
      "step": 6940
    },
    {
      "epoch": 0.8373493975903614,
      "grad_norm": 11.586605072021484,
      "learning_rate": 1.832530120481928e-05,
      "loss": 0.1191,
      "step": 6950
    },
    {
      "epoch": 0.8385542168674699,
      "grad_norm": 7.926976680755615,
      "learning_rate": 1.832289156626506e-05,
      "loss": 0.1341,
      "step": 6960
    },
    {
      "epoch": 0.8397590361445784,
      "grad_norm": 10.306193351745605,
      "learning_rate": 1.8320481927710843e-05,
      "loss": 0.1422,
      "step": 6970
    },
    {
      "epoch": 0.8409638554216867,
      "grad_norm": 3.7082114219665527,
      "learning_rate": 1.8318072289156628e-05,
      "loss": 0.0503,
      "step": 6980
    },
    {
      "epoch": 0.8421686746987952,
      "grad_norm": 3.7494654655456543,
      "learning_rate": 1.831566265060241e-05,
      "loss": 0.1146,
      "step": 6990
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 1.8532941341400146,
      "learning_rate": 1.8313253012048194e-05,
      "loss": 0.0801,
      "step": 7000
    },
    {
      "epoch": 0.844578313253012,
      "grad_norm": 4.514847755432129,
      "learning_rate": 1.831084337349398e-05,
      "loss": 0.1619,
      "step": 7010
    },
    {
      "epoch": 0.8457831325301205,
      "grad_norm": 0.45634210109710693,
      "learning_rate": 1.830843373493976e-05,
      "loss": 0.0654,
      "step": 7020
    },
    {
      "epoch": 0.846987951807229,
      "grad_norm": 2.32778263092041,
      "learning_rate": 1.8306024096385546e-05,
      "loss": 0.1186,
      "step": 7030
    },
    {
      "epoch": 0.8481927710843373,
      "grad_norm": 4.092655181884766,
      "learning_rate": 1.8303614457831327e-05,
      "loss": 0.1063,
      "step": 7040
    },
    {
      "epoch": 0.8493975903614458,
      "grad_norm": 0.7067599296569824,
      "learning_rate": 1.830120481927711e-05,
      "loss": 0.0995,
      "step": 7050
    },
    {
      "epoch": 0.8506024096385543,
      "grad_norm": 12.368833541870117,
      "learning_rate": 1.8298795180722893e-05,
      "loss": 0.1474,
      "step": 7060
    },
    {
      "epoch": 0.8518072289156626,
      "grad_norm": 3.0989718437194824,
      "learning_rate": 1.8296385542168675e-05,
      "loss": 0.1096,
      "step": 7070
    },
    {
      "epoch": 0.8530120481927711,
      "grad_norm": 0.4466911852359772,
      "learning_rate": 1.829397590361446e-05,
      "loss": 0.086,
      "step": 7080
    },
    {
      "epoch": 0.8542168674698796,
      "grad_norm": 4.349891662597656,
      "learning_rate": 1.8291566265060245e-05,
      "loss": 0.0853,
      "step": 7090
    },
    {
      "epoch": 0.8554216867469879,
      "grad_norm": 8.472805976867676,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 0.1006,
      "step": 7100
    },
    {
      "epoch": 0.8566265060240964,
      "grad_norm": 9.025069236755371,
      "learning_rate": 1.8286746987951808e-05,
      "loss": 0.2117,
      "step": 7110
    },
    {
      "epoch": 0.8578313253012049,
      "grad_norm": 3.2188358306884766,
      "learning_rate": 1.8284337349397592e-05,
      "loss": 0.1096,
      "step": 7120
    },
    {
      "epoch": 0.8590361445783132,
      "grad_norm": 0.8553177714347839,
      "learning_rate": 1.8281927710843374e-05,
      "loss": 0.0684,
      "step": 7130
    },
    {
      "epoch": 0.8602409638554217,
      "grad_norm": 6.8544135093688965,
      "learning_rate": 1.827951807228916e-05,
      "loss": 0.0663,
      "step": 7140
    },
    {
      "epoch": 0.8614457831325302,
      "grad_norm": 0.11178545653820038,
      "learning_rate": 1.827710843373494e-05,
      "loss": 0.139,
      "step": 7150
    },
    {
      "epoch": 0.8626506024096385,
      "grad_norm": 5.574953556060791,
      "learning_rate": 1.8274698795180725e-05,
      "loss": 0.1237,
      "step": 7160
    },
    {
      "epoch": 0.863855421686747,
      "grad_norm": 3.328526735305786,
      "learning_rate": 1.8272289156626507e-05,
      "loss": 0.0715,
      "step": 7170
    },
    {
      "epoch": 0.8650602409638555,
      "grad_norm": 9.16709041595459,
      "learning_rate": 1.826987951807229e-05,
      "loss": 0.2041,
      "step": 7180
    },
    {
      "epoch": 0.8662650602409638,
      "grad_norm": 1.3284013271331787,
      "learning_rate": 1.8267469879518073e-05,
      "loss": 0.1244,
      "step": 7190
    },
    {
      "epoch": 0.8674698795180723,
      "grad_norm": 11.873018264770508,
      "learning_rate": 1.8265060240963858e-05,
      "loss": 0.0633,
      "step": 7200
    },
    {
      "epoch": 0.8686746987951808,
      "grad_norm": 0.07228438556194305,
      "learning_rate": 1.826265060240964e-05,
      "loss": 0.0883,
      "step": 7210
    },
    {
      "epoch": 0.8698795180722891,
      "grad_norm": 7.558770179748535,
      "learning_rate": 1.826024096385542e-05,
      "loss": 0.1257,
      "step": 7220
    },
    {
      "epoch": 0.8710843373493976,
      "grad_norm": 5.123583793640137,
      "learning_rate": 1.8257831325301206e-05,
      "loss": 0.086,
      "step": 7230
    },
    {
      "epoch": 0.8722891566265061,
      "grad_norm": 2.729661703109741,
      "learning_rate": 1.825542168674699e-05,
      "loss": 0.1231,
      "step": 7240
    },
    {
      "epoch": 0.8734939759036144,
      "grad_norm": 2.6362178325653076,
      "learning_rate": 1.8253012048192772e-05,
      "loss": 0.0794,
      "step": 7250
    },
    {
      "epoch": 0.8746987951807229,
      "grad_norm": 0.4012054204940796,
      "learning_rate": 1.8250602409638557e-05,
      "loss": 0.0776,
      "step": 7260
    },
    {
      "epoch": 0.8759036144578313,
      "grad_norm": 1.9034501314163208,
      "learning_rate": 1.824819277108434e-05,
      "loss": 0.0761,
      "step": 7270
    },
    {
      "epoch": 0.8771084337349397,
      "grad_norm": 0.2825683355331421,
      "learning_rate": 1.824578313253012e-05,
      "loss": 0.0906,
      "step": 7280
    },
    {
      "epoch": 0.8783132530120482,
      "grad_norm": 0.15151232481002808,
      "learning_rate": 1.8243373493975905e-05,
      "loss": 0.0978,
      "step": 7290
    },
    {
      "epoch": 0.8795180722891566,
      "grad_norm": 6.654364109039307,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 0.0759,
      "step": 7300
    },
    {
      "epoch": 0.880722891566265,
      "grad_norm": 0.5192753076553345,
      "learning_rate": 1.823855421686747e-05,
      "loss": 0.0908,
      "step": 7310
    },
    {
      "epoch": 0.8819277108433735,
      "grad_norm": 0.29768332839012146,
      "learning_rate": 1.8236144578313256e-05,
      "loss": 0.1548,
      "step": 7320
    },
    {
      "epoch": 0.8831325301204819,
      "grad_norm": 8.981476783752441,
      "learning_rate": 1.8233734939759037e-05,
      "loss": 0.1332,
      "step": 7330
    },
    {
      "epoch": 0.8843373493975903,
      "grad_norm": 4.078756332397461,
      "learning_rate": 1.8231325301204822e-05,
      "loss": 0.1194,
      "step": 7340
    },
    {
      "epoch": 0.8855421686746988,
      "grad_norm": 6.089186191558838,
      "learning_rate": 1.8228915662650604e-05,
      "loss": 0.0683,
      "step": 7350
    },
    {
      "epoch": 0.8867469879518072,
      "grad_norm": 3.693246841430664,
      "learning_rate": 1.8226506024096385e-05,
      "loss": 0.1004,
      "step": 7360
    },
    {
      "epoch": 0.8879518072289156,
      "grad_norm": 0.463623583316803,
      "learning_rate": 1.822409638554217e-05,
      "loss": 0.0631,
      "step": 7370
    },
    {
      "epoch": 0.8891566265060241,
      "grad_norm": 4.405972480773926,
      "learning_rate": 1.8221686746987955e-05,
      "loss": 0.0719,
      "step": 7380
    },
    {
      "epoch": 0.8903614457831325,
      "grad_norm": 1.2670042514801025,
      "learning_rate": 1.8219277108433737e-05,
      "loss": 0.0491,
      "step": 7390
    },
    {
      "epoch": 0.891566265060241,
      "grad_norm": 0.05677719786763191,
      "learning_rate": 1.821686746987952e-05,
      "loss": 0.0528,
      "step": 7400
    },
    {
      "epoch": 0.8927710843373494,
      "grad_norm": 0.48763781785964966,
      "learning_rate": 1.8214457831325303e-05,
      "loss": 0.1622,
      "step": 7410
    },
    {
      "epoch": 0.8939759036144578,
      "grad_norm": 0.15047182142734528,
      "learning_rate": 1.8212048192771084e-05,
      "loss": 0.0637,
      "step": 7420
    },
    {
      "epoch": 0.8951807228915662,
      "grad_norm": 6.4843010902404785,
      "learning_rate": 1.820963855421687e-05,
      "loss": 0.2223,
      "step": 7430
    },
    {
      "epoch": 0.8963855421686747,
      "grad_norm": 0.3231193423271179,
      "learning_rate": 1.820722891566265e-05,
      "loss": 0.0905,
      "step": 7440
    },
    {
      "epoch": 0.8975903614457831,
      "grad_norm": 1.1975985765457153,
      "learning_rate": 1.8204819277108436e-05,
      "loss": 0.0889,
      "step": 7450
    },
    {
      "epoch": 0.8987951807228916,
      "grad_norm": 7.23585319519043,
      "learning_rate": 1.820240963855422e-05,
      "loss": 0.0982,
      "step": 7460
    },
    {
      "epoch": 0.9,
      "grad_norm": 9.325684547424316,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.1025,
      "step": 7470
    },
    {
      "epoch": 0.9012048192771084,
      "grad_norm": 2.0108299255371094,
      "learning_rate": 1.8197590361445783e-05,
      "loss": 0.0773,
      "step": 7480
    },
    {
      "epoch": 0.9024096385542169,
      "grad_norm": 2.330500364303589,
      "learning_rate": 1.8195180722891568e-05,
      "loss": 0.0927,
      "step": 7490
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 0.3083098232746124,
      "learning_rate": 1.819277108433735e-05,
      "loss": 0.0427,
      "step": 7500
    },
    {
      "epoch": 0.9048192771084337,
      "grad_norm": 0.026152968406677246,
      "learning_rate": 1.8190361445783135e-05,
      "loss": 0.1138,
      "step": 7510
    },
    {
      "epoch": 0.9060240963855422,
      "grad_norm": 4.126785755157471,
      "learning_rate": 1.8187951807228916e-05,
      "loss": 0.0572,
      "step": 7520
    },
    {
      "epoch": 0.9072289156626506,
      "grad_norm": 2.180158853530884,
      "learning_rate": 1.81855421686747e-05,
      "loss": 0.1207,
      "step": 7530
    },
    {
      "epoch": 0.908433734939759,
      "grad_norm": 7.902340412139893,
      "learning_rate": 1.8183132530120486e-05,
      "loss": 0.1183,
      "step": 7540
    },
    {
      "epoch": 0.9096385542168675,
      "grad_norm": 4.4482221603393555,
      "learning_rate": 1.8180722891566267e-05,
      "loss": 0.1299,
      "step": 7550
    },
    {
      "epoch": 0.9108433734939759,
      "grad_norm": 1.1698318719863892,
      "learning_rate": 1.817831325301205e-05,
      "loss": 0.1076,
      "step": 7560
    },
    {
      "epoch": 0.9120481927710843,
      "grad_norm": 0.42643383145332336,
      "learning_rate": 1.8175903614457834e-05,
      "loss": 0.1046,
      "step": 7570
    },
    {
      "epoch": 0.9132530120481928,
      "grad_norm": 6.320253849029541,
      "learning_rate": 1.8173493975903615e-05,
      "loss": 0.096,
      "step": 7580
    },
    {
      "epoch": 0.9144578313253012,
      "grad_norm": 13.047019958496094,
      "learning_rate": 1.81710843373494e-05,
      "loss": 0.1556,
      "step": 7590
    },
    {
      "epoch": 0.9156626506024096,
      "grad_norm": 0.5938289165496826,
      "learning_rate": 1.816867469879518e-05,
      "loss": 0.071,
      "step": 7600
    },
    {
      "epoch": 0.9168674698795181,
      "grad_norm": 3.4032394886016846,
      "learning_rate": 1.8166265060240966e-05,
      "loss": 0.2095,
      "step": 7610
    },
    {
      "epoch": 0.9180722891566265,
      "grad_norm": 0.9893234372138977,
      "learning_rate": 1.8163855421686748e-05,
      "loss": 0.0839,
      "step": 7620
    },
    {
      "epoch": 0.9192771084337349,
      "grad_norm": 6.828150272369385,
      "learning_rate": 1.8161445783132533e-05,
      "loss": 0.1228,
      "step": 7630
    },
    {
      "epoch": 0.9204819277108434,
      "grad_norm": 0.9798389077186584,
      "learning_rate": 1.8159036144578314e-05,
      "loss": 0.0731,
      "step": 7640
    },
    {
      "epoch": 0.9216867469879518,
      "grad_norm": 1.7420061826705933,
      "learning_rate": 1.81566265060241e-05,
      "loss": 0.1318,
      "step": 7650
    },
    {
      "epoch": 0.9228915662650602,
      "grad_norm": 0.19906294345855713,
      "learning_rate": 1.815421686746988e-05,
      "loss": 0.0943,
      "step": 7660
    },
    {
      "epoch": 0.9240963855421687,
      "grad_norm": 1.3246822357177734,
      "learning_rate": 1.8151807228915662e-05,
      "loss": 0.0807,
      "step": 7670
    },
    {
      "epoch": 0.9253012048192771,
      "grad_norm": 1.3526830673217773,
      "learning_rate": 1.8149397590361447e-05,
      "loss": 0.108,
      "step": 7680
    },
    {
      "epoch": 0.9265060240963855,
      "grad_norm": 8.164016723632812,
      "learning_rate": 1.8146987951807232e-05,
      "loss": 0.0685,
      "step": 7690
    },
    {
      "epoch": 0.927710843373494,
      "grad_norm": 5.339709281921387,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 0.0732,
      "step": 7700
    },
    {
      "epoch": 0.9289156626506024,
      "grad_norm": 4.160068511962891,
      "learning_rate": 1.8142168674698798e-05,
      "loss": 0.0627,
      "step": 7710
    },
    {
      "epoch": 0.9301204819277108,
      "grad_norm": 5.839919567108154,
      "learning_rate": 1.813975903614458e-05,
      "loss": 0.1179,
      "step": 7720
    },
    {
      "epoch": 0.9313253012048193,
      "grad_norm": 6.866109848022461,
      "learning_rate": 1.813734939759036e-05,
      "loss": 0.0969,
      "step": 7730
    },
    {
      "epoch": 0.9325301204819277,
      "grad_norm": 6.380317211151123,
      "learning_rate": 1.8134939759036146e-05,
      "loss": 0.1702,
      "step": 7740
    },
    {
      "epoch": 0.9337349397590361,
      "grad_norm": 1.1898733377456665,
      "learning_rate": 1.8132530120481927e-05,
      "loss": 0.1363,
      "step": 7750
    },
    {
      "epoch": 0.9349397590361446,
      "grad_norm": 5.449572563171387,
      "learning_rate": 1.8130120481927712e-05,
      "loss": 0.0844,
      "step": 7760
    },
    {
      "epoch": 0.936144578313253,
      "grad_norm": 0.8239402770996094,
      "learning_rate": 1.8127710843373497e-05,
      "loss": 0.0709,
      "step": 7770
    },
    {
      "epoch": 0.9373493975903614,
      "grad_norm": 10.32427978515625,
      "learning_rate": 1.812530120481928e-05,
      "loss": 0.1718,
      "step": 7780
    },
    {
      "epoch": 0.9385542168674699,
      "grad_norm": 3.8112223148345947,
      "learning_rate": 1.812289156626506e-05,
      "loss": 0.0862,
      "step": 7790
    },
    {
      "epoch": 0.9397590361445783,
      "grad_norm": 0.6316666007041931,
      "learning_rate": 1.8120481927710845e-05,
      "loss": 0.082,
      "step": 7800
    },
    {
      "epoch": 0.9409638554216867,
      "grad_norm": 4.549667835235596,
      "learning_rate": 1.8118072289156627e-05,
      "loss": 0.0941,
      "step": 7810
    },
    {
      "epoch": 0.9421686746987952,
      "grad_norm": 0.4999639093875885,
      "learning_rate": 1.811566265060241e-05,
      "loss": 0.1072,
      "step": 7820
    },
    {
      "epoch": 0.9433734939759036,
      "grad_norm": 0.7905610799789429,
      "learning_rate": 1.8113253012048196e-05,
      "loss": 0.0581,
      "step": 7830
    },
    {
      "epoch": 0.944578313253012,
      "grad_norm": 9.217782020568848,
      "learning_rate": 1.8110843373493978e-05,
      "loss": 0.096,
      "step": 7840
    },
    {
      "epoch": 0.9457831325301205,
      "grad_norm": 2.1138689517974854,
      "learning_rate": 1.8108433734939763e-05,
      "loss": 0.0664,
      "step": 7850
    },
    {
      "epoch": 0.946987951807229,
      "grad_norm": 16.111042022705078,
      "learning_rate": 1.8106024096385544e-05,
      "loss": 0.0756,
      "step": 7860
    },
    {
      "epoch": 0.9481927710843373,
      "grad_norm": 3.553126096725464,
      "learning_rate": 1.8103614457831326e-05,
      "loss": 0.1466,
      "step": 7870
    },
    {
      "epoch": 0.9493975903614458,
      "grad_norm": 5.506303310394287,
      "learning_rate": 1.810120481927711e-05,
      "loss": 0.0615,
      "step": 7880
    },
    {
      "epoch": 0.9506024096385542,
      "grad_norm": 6.2661004066467285,
      "learning_rate": 1.8098795180722892e-05,
      "loss": 0.1166,
      "step": 7890
    },
    {
      "epoch": 0.9518072289156626,
      "grad_norm": 0.9506586790084839,
      "learning_rate": 1.8096385542168677e-05,
      "loss": 0.1347,
      "step": 7900
    },
    {
      "epoch": 0.9530120481927711,
      "grad_norm": 5.502185821533203,
      "learning_rate": 1.809397590361446e-05,
      "loss": 0.0999,
      "step": 7910
    },
    {
      "epoch": 0.9542168674698795,
      "grad_norm": 14.0248384475708,
      "learning_rate": 1.8091566265060243e-05,
      "loss": 0.0769,
      "step": 7920
    },
    {
      "epoch": 0.9554216867469879,
      "grad_norm": 0.2340938001871109,
      "learning_rate": 1.8089156626506025e-05,
      "loss": 0.1341,
      "step": 7930
    },
    {
      "epoch": 0.9566265060240964,
      "grad_norm": 1.124476671218872,
      "learning_rate": 1.808674698795181e-05,
      "loss": 0.1764,
      "step": 7940
    },
    {
      "epoch": 0.9578313253012049,
      "grad_norm": 1.6391783952713013,
      "learning_rate": 1.808433734939759e-05,
      "loss": 0.0876,
      "step": 7950
    },
    {
      "epoch": 0.9590361445783132,
      "grad_norm": 0.5199963450431824,
      "learning_rate": 1.8081927710843376e-05,
      "loss": 0.0462,
      "step": 7960
    },
    {
      "epoch": 0.9602409638554217,
      "grad_norm": 2.888962984085083,
      "learning_rate": 1.8079518072289157e-05,
      "loss": 0.1441,
      "step": 7970
    },
    {
      "epoch": 0.9614457831325302,
      "grad_norm": 1.0861270427703857,
      "learning_rate": 1.8077108433734942e-05,
      "loss": 0.1181,
      "step": 7980
    },
    {
      "epoch": 0.9626506024096385,
      "grad_norm": 8.195895195007324,
      "learning_rate": 1.8074698795180724e-05,
      "loss": 0.0915,
      "step": 7990
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 2.686840534210205,
      "learning_rate": 1.807228915662651e-05,
      "loss": 0.0576,
      "step": 8000
    },
    {
      "epoch": 0.9650602409638555,
      "grad_norm": 4.066239833831787,
      "learning_rate": 1.806987951807229e-05,
      "loss": 0.0848,
      "step": 8010
    },
    {
      "epoch": 0.9662650602409638,
      "grad_norm": 23.162450790405273,
      "learning_rate": 1.8067469879518075e-05,
      "loss": 0.1934,
      "step": 8020
    },
    {
      "epoch": 0.9674698795180723,
      "grad_norm": 5.079391956329346,
      "learning_rate": 1.8065060240963856e-05,
      "loss": 0.1223,
      "step": 8030
    },
    {
      "epoch": 0.9686746987951808,
      "grad_norm": 6.748106956481934,
      "learning_rate": 1.8062650602409638e-05,
      "loss": 0.1022,
      "step": 8040
    },
    {
      "epoch": 0.9698795180722891,
      "grad_norm": 4.284206390380859,
      "learning_rate": 1.8060240963855423e-05,
      "loss": 0.0702,
      "step": 8050
    },
    {
      "epoch": 0.9710843373493976,
      "grad_norm": 0.2718212306499481,
      "learning_rate": 1.8057831325301208e-05,
      "loss": 0.103,
      "step": 8060
    },
    {
      "epoch": 0.9722891566265061,
      "grad_norm": 5.211602687835693,
      "learning_rate": 1.805542168674699e-05,
      "loss": 0.1104,
      "step": 8070
    },
    {
      "epoch": 0.9734939759036144,
      "grad_norm": 1.042432188987732,
      "learning_rate": 1.8053012048192774e-05,
      "loss": 0.1693,
      "step": 8080
    },
    {
      "epoch": 0.9746987951807229,
      "grad_norm": 0.43211278319358826,
      "learning_rate": 1.8050602409638555e-05,
      "loss": 0.0648,
      "step": 8090
    },
    {
      "epoch": 0.9759036144578314,
      "grad_norm": 4.829944610595703,
      "learning_rate": 1.8048192771084337e-05,
      "loss": 0.0701,
      "step": 8100
    },
    {
      "epoch": 0.9771084337349397,
      "grad_norm": 3.884822368621826,
      "learning_rate": 1.8045783132530122e-05,
      "loss": 0.1367,
      "step": 8110
    },
    {
      "epoch": 0.9783132530120482,
      "grad_norm": 4.868991851806641,
      "learning_rate": 1.8043373493975903e-05,
      "loss": 0.1362,
      "step": 8120
    },
    {
      "epoch": 0.9795180722891567,
      "grad_norm": 13.1246919631958,
      "learning_rate": 1.8040963855421688e-05,
      "loss": 0.0943,
      "step": 8130
    },
    {
      "epoch": 0.980722891566265,
      "grad_norm": 0.7938333749771118,
      "learning_rate": 1.8038554216867473e-05,
      "loss": 0.0798,
      "step": 8140
    },
    {
      "epoch": 0.9819277108433735,
      "grad_norm": 0.5633935928344727,
      "learning_rate": 1.8036144578313255e-05,
      "loss": 0.105,
      "step": 8150
    },
    {
      "epoch": 0.983132530120482,
      "grad_norm": 2.5886635780334473,
      "learning_rate": 1.803373493975904e-05,
      "loss": 0.1161,
      "step": 8160
    },
    {
      "epoch": 0.9843373493975903,
      "grad_norm": 5.135287284851074,
      "learning_rate": 1.803132530120482e-05,
      "loss": 0.1222,
      "step": 8170
    },
    {
      "epoch": 0.9855421686746988,
      "grad_norm": 0.12222586572170258,
      "learning_rate": 1.8028915662650602e-05,
      "loss": 0.1443,
      "step": 8180
    },
    {
      "epoch": 0.9867469879518073,
      "grad_norm": 0.7051990628242493,
      "learning_rate": 1.8026506024096387e-05,
      "loss": 0.1445,
      "step": 8190
    },
    {
      "epoch": 0.9879518072289156,
      "grad_norm": 5.402148723602295,
      "learning_rate": 1.802409638554217e-05,
      "loss": 0.0683,
      "step": 8200
    },
    {
      "epoch": 0.9891566265060241,
      "grad_norm": 2.8782660961151123,
      "learning_rate": 1.8021686746987954e-05,
      "loss": 0.1367,
      "step": 8210
    },
    {
      "epoch": 0.9903614457831326,
      "grad_norm": 9.345417022705078,
      "learning_rate": 1.801927710843374e-05,
      "loss": 0.1607,
      "step": 8220
    },
    {
      "epoch": 0.9915662650602409,
      "grad_norm": 8.360809326171875,
      "learning_rate": 1.801686746987952e-05,
      "loss": 0.1248,
      "step": 8230
    },
    {
      "epoch": 0.9927710843373494,
      "grad_norm": 7.318880081176758,
      "learning_rate": 1.80144578313253e-05,
      "loss": 0.1257,
      "step": 8240
    },
    {
      "epoch": 0.9939759036144579,
      "grad_norm": 5.896146774291992,
      "learning_rate": 1.8012048192771086e-05,
      "loss": 0.1613,
      "step": 8250
    },
    {
      "epoch": 0.9951807228915662,
      "grad_norm": 8.577589988708496,
      "learning_rate": 1.8009638554216868e-05,
      "loss": 0.2151,
      "step": 8260
    },
    {
      "epoch": 0.9963855421686747,
      "grad_norm": 5.046472072601318,
      "learning_rate": 1.8007228915662653e-05,
      "loss": 0.0798,
      "step": 8270
    },
    {
      "epoch": 0.9975903614457832,
      "grad_norm": 8.643893241882324,
      "learning_rate": 1.8004819277108437e-05,
      "loss": 0.065,
      "step": 8280
    },
    {
      "epoch": 0.9987951807228915,
      "grad_norm": 8.3419771194458,
      "learning_rate": 1.800240963855422e-05,
      "loss": 0.1391,
      "step": 8290
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.444108963012695,
      "learning_rate": 1.8e-05,
      "loss": 0.0964,
      "step": 8300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9704958755155606,
      "eval_f1": 0.9211992238843337,
      "eval_loss": 0.09778285026550293,
      "eval_precision": 0.9331727111336546,
      "eval_recall": 0.9095291064145347,
      "eval_runtime": 5050.914,
      "eval_samples_per_second": 8.452,
      "eval_steps_per_second": 0.352,
      "step": 8300
    },
    {
      "epoch": 1.0012048192771084,
      "grad_norm": 4.955513000488281,
      "learning_rate": 1.7997590361445785e-05,
      "loss": 0.0994,
      "step": 8310
    },
    {
      "epoch": 1.002409638554217,
      "grad_norm": 5.368807315826416,
      "learning_rate": 1.7995180722891567e-05,
      "loss": 0.0944,
      "step": 8320
    },
    {
      "epoch": 1.0036144578313253,
      "grad_norm": 1.456709384918213,
      "learning_rate": 1.799277108433735e-05,
      "loss": 0.1095,
      "step": 8330
    },
    {
      "epoch": 1.0048192771084337,
      "grad_norm": 2.291346311569214,
      "learning_rate": 1.7990361445783133e-05,
      "loss": 0.0563,
      "step": 8340
    },
    {
      "epoch": 1.0060240963855422,
      "grad_norm": 6.251614570617676,
      "learning_rate": 1.7987951807228915e-05,
      "loss": 0.0924,
      "step": 8350
    },
    {
      "epoch": 1.0072289156626506,
      "grad_norm": 0.7491552829742432,
      "learning_rate": 1.79855421686747e-05,
      "loss": 0.0557,
      "step": 8360
    },
    {
      "epoch": 1.008433734939759,
      "grad_norm": 11.232553482055664,
      "learning_rate": 1.7983132530120484e-05,
      "loss": 0.0769,
      "step": 8370
    },
    {
      "epoch": 1.0096385542168675,
      "grad_norm": 2.081458806991577,
      "learning_rate": 1.7980722891566266e-05,
      "loss": 0.051,
      "step": 8380
    },
    {
      "epoch": 1.010843373493976,
      "grad_norm": 6.951504707336426,
      "learning_rate": 1.797831325301205e-05,
      "loss": 0.1252,
      "step": 8390
    },
    {
      "epoch": 1.0120481927710843,
      "grad_norm": 2.4965522289276123,
      "learning_rate": 1.7975903614457832e-05,
      "loss": 0.0498,
      "step": 8400
    },
    {
      "epoch": 1.0132530120481928,
      "grad_norm": 0.07868897914886475,
      "learning_rate": 1.7973493975903614e-05,
      "loss": 0.1106,
      "step": 8410
    },
    {
      "epoch": 1.0144578313253012,
      "grad_norm": 0.161456897854805,
      "learning_rate": 1.79710843373494e-05,
      "loss": 0.1314,
      "step": 8420
    },
    {
      "epoch": 1.0156626506024096,
      "grad_norm": 0.5161232948303223,
      "learning_rate": 1.7968674698795183e-05,
      "loss": 0.0301,
      "step": 8430
    },
    {
      "epoch": 1.0168674698795181,
      "grad_norm": 0.1628800481557846,
      "learning_rate": 1.7966265060240965e-05,
      "loss": 0.0924,
      "step": 8440
    },
    {
      "epoch": 1.0180722891566265,
      "grad_norm": 0.7825327515602112,
      "learning_rate": 1.796385542168675e-05,
      "loss": 0.0574,
      "step": 8450
    },
    {
      "epoch": 1.0192771084337349,
      "grad_norm": 0.2664830684661865,
      "learning_rate": 1.796144578313253e-05,
      "loss": 0.1313,
      "step": 8460
    },
    {
      "epoch": 1.0204819277108435,
      "grad_norm": 0.04532027244567871,
      "learning_rate": 1.7959036144578316e-05,
      "loss": 0.0638,
      "step": 8470
    },
    {
      "epoch": 1.0216867469879518,
      "grad_norm": 0.2096177190542221,
      "learning_rate": 1.7956626506024098e-05,
      "loss": 0.1141,
      "step": 8480
    },
    {
      "epoch": 1.0228915662650602,
      "grad_norm": 0.7749112844467163,
      "learning_rate": 1.795421686746988e-05,
      "loss": 0.0747,
      "step": 8490
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 0.014589586295187473,
      "learning_rate": 1.7951807228915664e-05,
      "loss": 0.0372,
      "step": 8500
    },
    {
      "epoch": 1.0253012048192771,
      "grad_norm": 3.289395809173584,
      "learning_rate": 1.794939759036145e-05,
      "loss": 0.0846,
      "step": 8510
    },
    {
      "epoch": 1.0265060240963855,
      "grad_norm": 5.380357265472412,
      "learning_rate": 1.794698795180723e-05,
      "loss": 0.0764,
      "step": 8520
    },
    {
      "epoch": 1.027710843373494,
      "grad_norm": 3.996490955352783,
      "learning_rate": 1.7944578313253015e-05,
      "loss": 0.0837,
      "step": 8530
    },
    {
      "epoch": 1.0289156626506024,
      "grad_norm": 1.7760366201400757,
      "learning_rate": 1.7942168674698797e-05,
      "loss": 0.094,
      "step": 8540
    },
    {
      "epoch": 1.0301204819277108,
      "grad_norm": 17.46188735961914,
      "learning_rate": 1.7939759036144578e-05,
      "loss": 0.0827,
      "step": 8550
    },
    {
      "epoch": 1.0313253012048194,
      "grad_norm": 0.9397729635238647,
      "learning_rate": 1.7937349397590363e-05,
      "loss": 0.0736,
      "step": 8560
    },
    {
      "epoch": 1.0325301204819277,
      "grad_norm": 2.4594852924346924,
      "learning_rate": 1.7934939759036145e-05,
      "loss": 0.0815,
      "step": 8570
    },
    {
      "epoch": 1.033734939759036,
      "grad_norm": 0.15452930331230164,
      "learning_rate": 1.793253012048193e-05,
      "loss": 0.0754,
      "step": 8580
    },
    {
      "epoch": 1.0349397590361447,
      "grad_norm": 0.9898589849472046,
      "learning_rate": 1.7930120481927714e-05,
      "loss": 0.0782,
      "step": 8590
    },
    {
      "epoch": 1.036144578313253,
      "grad_norm": 5.372803211212158,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 0.1165,
      "step": 8600
    },
    {
      "epoch": 1.0373493975903614,
      "grad_norm": 1.5538973808288574,
      "learning_rate": 1.7925301204819277e-05,
      "loss": 0.0848,
      "step": 8610
    },
    {
      "epoch": 1.03855421686747,
      "grad_norm": 14.740387916564941,
      "learning_rate": 1.7922891566265062e-05,
      "loss": 0.0768,
      "step": 8620
    },
    {
      "epoch": 1.0397590361445783,
      "grad_norm": 0.18068885803222656,
      "learning_rate": 1.7920481927710844e-05,
      "loss": 0.0278,
      "step": 8630
    },
    {
      "epoch": 1.0409638554216867,
      "grad_norm": 15.801162719726562,
      "learning_rate": 1.791807228915663e-05,
      "loss": 0.1102,
      "step": 8640
    },
    {
      "epoch": 1.0421686746987953,
      "grad_norm": 9.218527793884277,
      "learning_rate": 1.791566265060241e-05,
      "loss": 0.1233,
      "step": 8650
    },
    {
      "epoch": 1.0433734939759036,
      "grad_norm": 14.927740097045898,
      "learning_rate": 1.7913253012048195e-05,
      "loss": 0.0964,
      "step": 8660
    },
    {
      "epoch": 1.044578313253012,
      "grad_norm": 0.9579917192459106,
      "learning_rate": 1.7910843373493976e-05,
      "loss": 0.0621,
      "step": 8670
    },
    {
      "epoch": 1.0457831325301206,
      "grad_norm": 10.296719551086426,
      "learning_rate": 1.790843373493976e-05,
      "loss": 0.0569,
      "step": 8680
    },
    {
      "epoch": 1.046987951807229,
      "grad_norm": 10.846747398376465,
      "learning_rate": 1.7906024096385543e-05,
      "loss": 0.1096,
      "step": 8690
    },
    {
      "epoch": 1.0481927710843373,
      "grad_norm": 7.116822242736816,
      "learning_rate": 1.7903614457831327e-05,
      "loss": 0.1286,
      "step": 8700
    },
    {
      "epoch": 1.0493975903614459,
      "grad_norm": 0.29715344309806824,
      "learning_rate": 1.790120481927711e-05,
      "loss": 0.0357,
      "step": 8710
    },
    {
      "epoch": 1.0506024096385542,
      "grad_norm": 0.9800049662590027,
      "learning_rate": 1.789879518072289e-05,
      "loss": 0.0843,
      "step": 8720
    },
    {
      "epoch": 1.0518072289156626,
      "grad_norm": 0.3271788954734802,
      "learning_rate": 1.789638554216868e-05,
      "loss": 0.075,
      "step": 8730
    },
    {
      "epoch": 1.0530120481927712,
      "grad_norm": 0.07709433883428574,
      "learning_rate": 1.789397590361446e-05,
      "loss": 0.1242,
      "step": 8740
    },
    {
      "epoch": 1.0542168674698795,
      "grad_norm": 6.472115993499756,
      "learning_rate": 1.789156626506024e-05,
      "loss": 0.0705,
      "step": 8750
    },
    {
      "epoch": 1.0554216867469879,
      "grad_norm": 0.5994231104850769,
      "learning_rate": 1.7889156626506027e-05,
      "loss": 0.0713,
      "step": 8760
    },
    {
      "epoch": 1.0566265060240965,
      "grad_norm": 3.331766128540039,
      "learning_rate": 1.7886746987951808e-05,
      "loss": 0.0867,
      "step": 8770
    },
    {
      "epoch": 1.0578313253012048,
      "grad_norm": 4.473138809204102,
      "learning_rate": 1.7884337349397593e-05,
      "loss": 0.0806,
      "step": 8780
    },
    {
      "epoch": 1.0590361445783132,
      "grad_norm": 0.16556553542613983,
      "learning_rate": 1.7881927710843374e-05,
      "loss": 0.0221,
      "step": 8790
    },
    {
      "epoch": 1.0602409638554218,
      "grad_norm": 24.789518356323242,
      "learning_rate": 1.7879518072289156e-05,
      "loss": 0.0488,
      "step": 8800
    },
    {
      "epoch": 1.0614457831325301,
      "grad_norm": 0.5776450634002686,
      "learning_rate": 1.787710843373494e-05,
      "loss": 0.0523,
      "step": 8810
    },
    {
      "epoch": 1.0626506024096385,
      "grad_norm": 7.655459880828857,
      "learning_rate": 1.7874698795180726e-05,
      "loss": 0.0935,
      "step": 8820
    },
    {
      "epoch": 1.063855421686747,
      "grad_norm": 0.023264804854989052,
      "learning_rate": 1.7872289156626507e-05,
      "loss": 0.0785,
      "step": 8830
    },
    {
      "epoch": 1.0650602409638554,
      "grad_norm": 1.8911662101745605,
      "learning_rate": 1.7869879518072292e-05,
      "loss": 0.0669,
      "step": 8840
    },
    {
      "epoch": 1.0662650602409638,
      "grad_norm": 5.287168979644775,
      "learning_rate": 1.7867469879518073e-05,
      "loss": 0.1777,
      "step": 8850
    },
    {
      "epoch": 1.0674698795180724,
      "grad_norm": 4.49130916595459,
      "learning_rate": 1.7865060240963855e-05,
      "loss": 0.0623,
      "step": 8860
    },
    {
      "epoch": 1.0686746987951807,
      "grad_norm": 4.174593925476074,
      "learning_rate": 1.786265060240964e-05,
      "loss": 0.1511,
      "step": 8870
    },
    {
      "epoch": 1.069879518072289,
      "grad_norm": 0.39423999190330505,
      "learning_rate": 1.7860240963855425e-05,
      "loss": 0.0754,
      "step": 8880
    },
    {
      "epoch": 1.0710843373493977,
      "grad_norm": 3.080720901489258,
      "learning_rate": 1.7857831325301206e-05,
      "loss": 0.1445,
      "step": 8890
    },
    {
      "epoch": 1.072289156626506,
      "grad_norm": 5.595621585845947,
      "learning_rate": 1.785542168674699e-05,
      "loss": 0.0742,
      "step": 8900
    },
    {
      "epoch": 1.0734939759036144,
      "grad_norm": 0.6809824109077454,
      "learning_rate": 1.7853012048192772e-05,
      "loss": 0.0488,
      "step": 8910
    },
    {
      "epoch": 1.074698795180723,
      "grad_norm": 5.156244277954102,
      "learning_rate": 1.7850602409638554e-05,
      "loss": 0.05,
      "step": 8920
    },
    {
      "epoch": 1.0759036144578313,
      "grad_norm": 0.03413260355591774,
      "learning_rate": 1.784819277108434e-05,
      "loss": 0.0953,
      "step": 8930
    },
    {
      "epoch": 1.0771084337349397,
      "grad_norm": 0.6450449228286743,
      "learning_rate": 1.784578313253012e-05,
      "loss": 0.0645,
      "step": 8940
    },
    {
      "epoch": 1.0783132530120483,
      "grad_norm": 2.1808853149414062,
      "learning_rate": 1.7843373493975905e-05,
      "loss": 0.0643,
      "step": 8950
    },
    {
      "epoch": 1.0795180722891566,
      "grad_norm": 4.545913219451904,
      "learning_rate": 1.784096385542169e-05,
      "loss": 0.0737,
      "step": 8960
    },
    {
      "epoch": 1.080722891566265,
      "grad_norm": 2.0875422954559326,
      "learning_rate": 1.783855421686747e-05,
      "loss": 0.1268,
      "step": 8970
    },
    {
      "epoch": 1.0819277108433736,
      "grad_norm": 0.28110018372535706,
      "learning_rate": 1.7836144578313256e-05,
      "loss": 0.0944,
      "step": 8980
    },
    {
      "epoch": 1.083132530120482,
      "grad_norm": 7.305398941040039,
      "learning_rate": 1.7833734939759038e-05,
      "loss": 0.0724,
      "step": 8990
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 8.43801498413086,
      "learning_rate": 1.783132530120482e-05,
      "loss": 0.0817,
      "step": 9000
    },
    {
      "epoch": 1.0855421686746989,
      "grad_norm": 6.2346696853637695,
      "learning_rate": 1.7828915662650604e-05,
      "loss": 0.0927,
      "step": 9010
    },
    {
      "epoch": 1.0867469879518072,
      "grad_norm": 0.5492282509803772,
      "learning_rate": 1.7826506024096386e-05,
      "loss": 0.0371,
      "step": 9020
    },
    {
      "epoch": 1.0879518072289156,
      "grad_norm": 5.335940837860107,
      "learning_rate": 1.782409638554217e-05,
      "loss": 0.0752,
      "step": 9030
    },
    {
      "epoch": 1.0891566265060242,
      "grad_norm": 6.761900424957275,
      "learning_rate": 1.7821686746987955e-05,
      "loss": 0.0441,
      "step": 9040
    },
    {
      "epoch": 1.0903614457831325,
      "grad_norm": 1.710445523262024,
      "learning_rate": 1.7819277108433737e-05,
      "loss": 0.1228,
      "step": 9050
    },
    {
      "epoch": 1.091566265060241,
      "grad_norm": 1.2912009954452515,
      "learning_rate": 1.781686746987952e-05,
      "loss": 0.0889,
      "step": 9060
    },
    {
      "epoch": 1.0927710843373495,
      "grad_norm": 4.812413692474365,
      "learning_rate": 1.7814457831325303e-05,
      "loss": 0.0922,
      "step": 9070
    },
    {
      "epoch": 1.0939759036144578,
      "grad_norm": 4.416125297546387,
      "learning_rate": 1.7812048192771085e-05,
      "loss": 0.1668,
      "step": 9080
    },
    {
      "epoch": 1.0951807228915662,
      "grad_norm": 0.1692097932100296,
      "learning_rate": 1.780963855421687e-05,
      "loss": 0.0781,
      "step": 9090
    },
    {
      "epoch": 1.0963855421686748,
      "grad_norm": 6.208945274353027,
      "learning_rate": 1.780722891566265e-05,
      "loss": 0.0486,
      "step": 9100
    },
    {
      "epoch": 1.0975903614457831,
      "grad_norm": 0.11554969847202301,
      "learning_rate": 1.7804819277108436e-05,
      "loss": 0.0754,
      "step": 9110
    },
    {
      "epoch": 1.0987951807228915,
      "grad_norm": 0.5830897092819214,
      "learning_rate": 1.7802409638554218e-05,
      "loss": 0.0437,
      "step": 9120
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.188709259033203,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 0.065,
      "step": 9130
    },
    {
      "epoch": 1.1012048192771084,
      "grad_norm": 1.9494284391403198,
      "learning_rate": 1.7797590361445784e-05,
      "loss": 0.0436,
      "step": 9140
    },
    {
      "epoch": 1.1024096385542168,
      "grad_norm": 7.194058418273926,
      "learning_rate": 1.779518072289157e-05,
      "loss": 0.0955,
      "step": 9150
    },
    {
      "epoch": 1.1036144578313254,
      "grad_norm": 6.989197731018066,
      "learning_rate": 1.779277108433735e-05,
      "loss": 0.0957,
      "step": 9160
    },
    {
      "epoch": 1.1048192771084338,
      "grad_norm": 0.10876388847827911,
      "learning_rate": 1.779036144578313e-05,
      "loss": 0.1091,
      "step": 9170
    },
    {
      "epoch": 1.106024096385542,
      "grad_norm": 4.246365547180176,
      "learning_rate": 1.7787951807228917e-05,
      "loss": 0.0409,
      "step": 9180
    },
    {
      "epoch": 1.1072289156626507,
      "grad_norm": 0.895855724811554,
      "learning_rate": 1.77855421686747e-05,
      "loss": 0.0829,
      "step": 9190
    },
    {
      "epoch": 1.108433734939759,
      "grad_norm": 0.5914252400398254,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 0.0948,
      "step": 9200
    },
    {
      "epoch": 1.1096385542168674,
      "grad_norm": 9.09078311920166,
      "learning_rate": 1.7780722891566268e-05,
      "loss": 0.1311,
      "step": 9210
    },
    {
      "epoch": 1.110843373493976,
      "grad_norm": 9.652470588684082,
      "learning_rate": 1.777831325301205e-05,
      "loss": 0.1203,
      "step": 9220
    },
    {
      "epoch": 1.1120481927710844,
      "grad_norm": 4.560919284820557,
      "learning_rate": 1.777590361445783e-05,
      "loss": 0.1204,
      "step": 9230
    },
    {
      "epoch": 1.1132530120481927,
      "grad_norm": 2.832474708557129,
      "learning_rate": 1.7773493975903616e-05,
      "loss": 0.1102,
      "step": 9240
    },
    {
      "epoch": 1.1144578313253013,
      "grad_norm": 12.326115608215332,
      "learning_rate": 1.7771084337349397e-05,
      "loss": 0.1103,
      "step": 9250
    },
    {
      "epoch": 1.1156626506024097,
      "grad_norm": 6.890880584716797,
      "learning_rate": 1.7768674698795182e-05,
      "loss": 0.0737,
      "step": 9260
    },
    {
      "epoch": 1.116867469879518,
      "grad_norm": 2.698669195175171,
      "learning_rate": 1.7766265060240967e-05,
      "loss": 0.088,
      "step": 9270
    },
    {
      "epoch": 1.1180722891566266,
      "grad_norm": 3.165966033935547,
      "learning_rate": 1.776385542168675e-05,
      "loss": 0.1149,
      "step": 9280
    },
    {
      "epoch": 1.119277108433735,
      "grad_norm": 0.07250721752643585,
      "learning_rate": 1.7761445783132533e-05,
      "loss": 0.0603,
      "step": 9290
    },
    {
      "epoch": 1.1204819277108433,
      "grad_norm": 4.49114990234375,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 0.102,
      "step": 9300
    },
    {
      "epoch": 1.121686746987952,
      "grad_norm": 0.04642612487077713,
      "learning_rate": 1.7756626506024096e-05,
      "loss": 0.0855,
      "step": 9310
    },
    {
      "epoch": 1.1228915662650603,
      "grad_norm": 4.100534915924072,
      "learning_rate": 1.775421686746988e-05,
      "loss": 0.1136,
      "step": 9320
    },
    {
      "epoch": 1.1240963855421686,
      "grad_norm": 0.9361239671707153,
      "learning_rate": 1.7751807228915666e-05,
      "loss": 0.0886,
      "step": 9330
    },
    {
      "epoch": 1.1253012048192772,
      "grad_norm": 4.450307846069336,
      "learning_rate": 1.7749397590361447e-05,
      "loss": 0.0739,
      "step": 9340
    },
    {
      "epoch": 1.1265060240963856,
      "grad_norm": 1.689347267150879,
      "learning_rate": 1.7746987951807232e-05,
      "loss": 0.0271,
      "step": 9350
    },
    {
      "epoch": 1.127710843373494,
      "grad_norm": 6.385138511657715,
      "learning_rate": 1.7744578313253014e-05,
      "loss": 0.1248,
      "step": 9360
    },
    {
      "epoch": 1.1289156626506025,
      "grad_norm": 2.534811496734619,
      "learning_rate": 1.7742168674698795e-05,
      "loss": 0.0865,
      "step": 9370
    },
    {
      "epoch": 1.1301204819277109,
      "grad_norm": 0.7611947059631348,
      "learning_rate": 1.773975903614458e-05,
      "loss": 0.0199,
      "step": 9380
    },
    {
      "epoch": 1.1313253012048192,
      "grad_norm": 0.8715699315071106,
      "learning_rate": 1.773734939759036e-05,
      "loss": 0.1161,
      "step": 9390
    },
    {
      "epoch": 1.1325301204819278,
      "grad_norm": 4.668374061584473,
      "learning_rate": 1.7734939759036146e-05,
      "loss": 0.1656,
      "step": 9400
    },
    {
      "epoch": 1.1337349397590362,
      "grad_norm": 0.37565332651138306,
      "learning_rate": 1.773253012048193e-05,
      "loss": 0.0549,
      "step": 9410
    },
    {
      "epoch": 1.1349397590361445,
      "grad_norm": 0.16405971348285675,
      "learning_rate": 1.7730120481927713e-05,
      "loss": 0.1112,
      "step": 9420
    },
    {
      "epoch": 1.136144578313253,
      "grad_norm": 6.289435863494873,
      "learning_rate": 1.7727710843373494e-05,
      "loss": 0.1276,
      "step": 9430
    },
    {
      "epoch": 1.1373493975903615,
      "grad_norm": 0.6113232970237732,
      "learning_rate": 1.772530120481928e-05,
      "loss": 0.0406,
      "step": 9440
    },
    {
      "epoch": 1.1385542168674698,
      "grad_norm": 3.8647336959838867,
      "learning_rate": 1.772289156626506e-05,
      "loss": 0.1381,
      "step": 9450
    },
    {
      "epoch": 1.1397590361445784,
      "grad_norm": 3.8851852416992188,
      "learning_rate": 1.7720481927710845e-05,
      "loss": 0.0769,
      "step": 9460
    },
    {
      "epoch": 1.1409638554216868,
      "grad_norm": 0.41194242238998413,
      "learning_rate": 1.7718072289156627e-05,
      "loss": 0.0616,
      "step": 9470
    },
    {
      "epoch": 1.1421686746987951,
      "grad_norm": 8.636032104492188,
      "learning_rate": 1.7715662650602412e-05,
      "loss": 0.1045,
      "step": 9480
    },
    {
      "epoch": 1.1433734939759037,
      "grad_norm": 0.006739186123013496,
      "learning_rate": 1.7713253012048193e-05,
      "loss": 0.0371,
      "step": 9490
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 0.025051739066839218,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 0.1519,
      "step": 9500
    },
    {
      "epoch": 1.1457831325301204,
      "grad_norm": 21.32000160217285,
      "learning_rate": 1.770843373493976e-05,
      "loss": 0.0866,
      "step": 9510
    },
    {
      "epoch": 1.146987951807229,
      "grad_norm": 2.9806435108184814,
      "learning_rate": 1.7706024096385545e-05,
      "loss": 0.1807,
      "step": 9520
    },
    {
      "epoch": 1.1481927710843374,
      "grad_norm": 0.20023499429225922,
      "learning_rate": 1.7703614457831326e-05,
      "loss": 0.0697,
      "step": 9530
    },
    {
      "epoch": 1.1493975903614457,
      "grad_norm": 1.7503701448440552,
      "learning_rate": 1.7701204819277108e-05,
      "loss": 0.0487,
      "step": 9540
    },
    {
      "epoch": 1.1506024096385543,
      "grad_norm": 0.09819909930229187,
      "learning_rate": 1.7698795180722892e-05,
      "loss": 0.1111,
      "step": 9550
    },
    {
      "epoch": 1.1518072289156627,
      "grad_norm": 0.200068861246109,
      "learning_rate": 1.7696385542168677e-05,
      "loss": 0.0381,
      "step": 9560
    },
    {
      "epoch": 1.153012048192771,
      "grad_norm": 4.208478927612305,
      "learning_rate": 1.769397590361446e-05,
      "loss": 0.0834,
      "step": 9570
    },
    {
      "epoch": 1.1542168674698796,
      "grad_norm": 1.7568808794021606,
      "learning_rate": 1.7691566265060244e-05,
      "loss": 0.0778,
      "step": 9580
    },
    {
      "epoch": 1.155421686746988,
      "grad_norm": 11.455442428588867,
      "learning_rate": 1.7689156626506025e-05,
      "loss": 0.0603,
      "step": 9590
    },
    {
      "epoch": 1.1566265060240963,
      "grad_norm": 0.3498821556568146,
      "learning_rate": 1.768674698795181e-05,
      "loss": 0.0323,
      "step": 9600
    },
    {
      "epoch": 1.157831325301205,
      "grad_norm": 0.6288376450538635,
      "learning_rate": 1.768433734939759e-05,
      "loss": 0.0189,
      "step": 9610
    },
    {
      "epoch": 1.1590361445783133,
      "grad_norm": 0.04087104648351669,
      "learning_rate": 1.7681927710843373e-05,
      "loss": 0.0374,
      "step": 9620
    },
    {
      "epoch": 1.1602409638554216,
      "grad_norm": 0.2761029005050659,
      "learning_rate": 1.7679518072289158e-05,
      "loss": 0.1238,
      "step": 9630
    },
    {
      "epoch": 1.16144578313253,
      "grad_norm": 0.2968769967556,
      "learning_rate": 1.7677108433734943e-05,
      "loss": 0.0984,
      "step": 9640
    },
    {
      "epoch": 1.1626506024096386,
      "grad_norm": 3.054619073867798,
      "learning_rate": 1.7674698795180724e-05,
      "loss": 0.0901,
      "step": 9650
    },
    {
      "epoch": 1.163855421686747,
      "grad_norm": 0.16623081266880035,
      "learning_rate": 1.767228915662651e-05,
      "loss": 0.1158,
      "step": 9660
    },
    {
      "epoch": 1.1650602409638555,
      "grad_norm": 0.3137781322002411,
      "learning_rate": 1.766987951807229e-05,
      "loss": 0.0781,
      "step": 9670
    },
    {
      "epoch": 1.1662650602409639,
      "grad_norm": 5.363982200622559,
      "learning_rate": 1.7667469879518072e-05,
      "loss": 0.0867,
      "step": 9680
    },
    {
      "epoch": 1.1674698795180722,
      "grad_norm": 7.031170845031738,
      "learning_rate": 1.7665060240963857e-05,
      "loss": 0.0711,
      "step": 9690
    },
    {
      "epoch": 1.1686746987951806,
      "grad_norm": 0.6465169191360474,
      "learning_rate": 1.766265060240964e-05,
      "loss": 0.0999,
      "step": 9700
    },
    {
      "epoch": 1.1698795180722892,
      "grad_norm": 10.152629852294922,
      "learning_rate": 1.7660240963855423e-05,
      "loss": 0.0943,
      "step": 9710
    },
    {
      "epoch": 1.1710843373493975,
      "grad_norm": 0.19612713158130646,
      "learning_rate": 1.7657831325301208e-05,
      "loss": 0.0876,
      "step": 9720
    },
    {
      "epoch": 1.1722891566265061,
      "grad_norm": 0.2976536452770233,
      "learning_rate": 1.765542168674699e-05,
      "loss": 0.0266,
      "step": 9730
    },
    {
      "epoch": 1.1734939759036145,
      "grad_norm": 1.4507346153259277,
      "learning_rate": 1.765301204819277e-05,
      "loss": 0.0201,
      "step": 9740
    },
    {
      "epoch": 1.1746987951807228,
      "grad_norm": 0.5750323534011841,
      "learning_rate": 1.7650602409638556e-05,
      "loss": 0.0823,
      "step": 9750
    },
    {
      "epoch": 1.1759036144578312,
      "grad_norm": 5.649276256561279,
      "learning_rate": 1.7648192771084337e-05,
      "loss": 0.1034,
      "step": 9760
    },
    {
      "epoch": 1.1771084337349398,
      "grad_norm": 0.3226155638694763,
      "learning_rate": 1.7645783132530122e-05,
      "loss": 0.0409,
      "step": 9770
    },
    {
      "epoch": 1.1783132530120481,
      "grad_norm": 0.20797854661941528,
      "learning_rate": 1.7643373493975907e-05,
      "loss": 0.052,
      "step": 9780
    },
    {
      "epoch": 1.1795180722891567,
      "grad_norm": 0.11818387359380722,
      "learning_rate": 1.764096385542169e-05,
      "loss": 0.0996,
      "step": 9790
    },
    {
      "epoch": 1.180722891566265,
      "grad_norm": 23.34143829345703,
      "learning_rate": 1.763855421686747e-05,
      "loss": 0.0915,
      "step": 9800
    },
    {
      "epoch": 1.1819277108433734,
      "grad_norm": 8.679927825927734,
      "learning_rate": 1.7636144578313255e-05,
      "loss": 0.1454,
      "step": 9810
    },
    {
      "epoch": 1.1831325301204818,
      "grad_norm": 0.29568588733673096,
      "learning_rate": 1.7633734939759036e-05,
      "loss": 0.0794,
      "step": 9820
    },
    {
      "epoch": 1.1843373493975904,
      "grad_norm": 3.2583565711975098,
      "learning_rate": 1.763132530120482e-05,
      "loss": 0.0433,
      "step": 9830
    },
    {
      "epoch": 1.1855421686746987,
      "grad_norm": 10.612709045410156,
      "learning_rate": 1.7628915662650603e-05,
      "loss": 0.0917,
      "step": 9840
    },
    {
      "epoch": 1.1867469879518073,
      "grad_norm": 5.652736186981201,
      "learning_rate": 1.7626506024096384e-05,
      "loss": 0.1487,
      "step": 9850
    },
    {
      "epoch": 1.1879518072289157,
      "grad_norm": 14.539989471435547,
      "learning_rate": 1.7624096385542173e-05,
      "loss": 0.1322,
      "step": 9860
    },
    {
      "epoch": 1.189156626506024,
      "grad_norm": 0.47260311245918274,
      "learning_rate": 1.7621686746987954e-05,
      "loss": 0.1002,
      "step": 9870
    },
    {
      "epoch": 1.1903614457831324,
      "grad_norm": 0.18667863309383392,
      "learning_rate": 1.7619277108433735e-05,
      "loss": 0.0432,
      "step": 9880
    },
    {
      "epoch": 1.191566265060241,
      "grad_norm": 3.6165947914123535,
      "learning_rate": 1.761686746987952e-05,
      "loss": 0.0765,
      "step": 9890
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 0.5374340415000916,
      "learning_rate": 1.7614457831325302e-05,
      "loss": 0.0958,
      "step": 9900
    },
    {
      "epoch": 1.193975903614458,
      "grad_norm": 0.1165413036942482,
      "learning_rate": 1.7612048192771087e-05,
      "loss": 0.0983,
      "step": 9910
    },
    {
      "epoch": 1.1951807228915663,
      "grad_norm": 7.200588703155518,
      "learning_rate": 1.7609638554216868e-05,
      "loss": 0.1027,
      "step": 9920
    },
    {
      "epoch": 1.1963855421686747,
      "grad_norm": 0.35682743787765503,
      "learning_rate": 1.7607228915662653e-05,
      "loss": 0.0902,
      "step": 9930
    },
    {
      "epoch": 1.197590361445783,
      "grad_norm": 1.6171151399612427,
      "learning_rate": 1.7604819277108435e-05,
      "loss": 0.0967,
      "step": 9940
    },
    {
      "epoch": 1.1987951807228916,
      "grad_norm": 5.502331733703613,
      "learning_rate": 1.760240963855422e-05,
      "loss": 0.0773,
      "step": 9950
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.540856122970581,
      "learning_rate": 1.76e-05,
      "loss": 0.062,
      "step": 9960
    },
    {
      "epoch": 1.2012048192771085,
      "grad_norm": 6.107758045196533,
      "learning_rate": 1.7597590361445786e-05,
      "loss": 0.1398,
      "step": 9970
    },
    {
      "epoch": 1.202409638554217,
      "grad_norm": 8.441296577453613,
      "learning_rate": 1.7595180722891567e-05,
      "loss": 0.1613,
      "step": 9980
    },
    {
      "epoch": 1.2036144578313253,
      "grad_norm": 1.2012094259262085,
      "learning_rate": 1.759277108433735e-05,
      "loss": 0.0625,
      "step": 9990
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 5.281999111175537,
      "learning_rate": 1.7590361445783134e-05,
      "loss": 0.13,
      "step": 10000
    },
    {
      "epoch": 1.2060240963855422,
      "grad_norm": 0.5473164319992065,
      "learning_rate": 1.758795180722892e-05,
      "loss": 0.0212,
      "step": 10010
    },
    {
      "epoch": 1.2072289156626506,
      "grad_norm": 0.3149307072162628,
      "learning_rate": 1.75855421686747e-05,
      "loss": 0.0836,
      "step": 10020
    },
    {
      "epoch": 1.2084337349397591,
      "grad_norm": 8.428683280944824,
      "learning_rate": 1.7583132530120485e-05,
      "loss": 0.0785,
      "step": 10030
    },
    {
      "epoch": 1.2096385542168675,
      "grad_norm": 2.504033088684082,
      "learning_rate": 1.7580722891566266e-05,
      "loss": 0.1315,
      "step": 10040
    },
    {
      "epoch": 1.2108433734939759,
      "grad_norm": 0.07770237326622009,
      "learning_rate": 1.7578313253012048e-05,
      "loss": 0.098,
      "step": 10050
    },
    {
      "epoch": 1.2120481927710842,
      "grad_norm": 0.43489545583724976,
      "learning_rate": 1.7575903614457833e-05,
      "loss": 0.0625,
      "step": 10060
    },
    {
      "epoch": 1.2132530120481928,
      "grad_norm": 1.2111538648605347,
      "learning_rate": 1.7573493975903614e-05,
      "loss": 0.1088,
      "step": 10070
    },
    {
      "epoch": 1.2144578313253012,
      "grad_norm": 6.3411545753479,
      "learning_rate": 1.75710843373494e-05,
      "loss": 0.0847,
      "step": 10080
    },
    {
      "epoch": 1.2156626506024097,
      "grad_norm": 0.09835951775312424,
      "learning_rate": 1.7568674698795184e-05,
      "loss": 0.0829,
      "step": 10090
    },
    {
      "epoch": 1.216867469879518,
      "grad_norm": 1.922410011291504,
      "learning_rate": 1.7566265060240965e-05,
      "loss": 0.0706,
      "step": 10100
    },
    {
      "epoch": 1.2180722891566265,
      "grad_norm": 3.2780654430389404,
      "learning_rate": 1.7563855421686747e-05,
      "loss": 0.0344,
      "step": 10110
    },
    {
      "epoch": 1.2192771084337348,
      "grad_norm": 0.06879815459251404,
      "learning_rate": 1.7561445783132532e-05,
      "loss": 0.1428,
      "step": 10120
    },
    {
      "epoch": 1.2204819277108434,
      "grad_norm": 0.6115788221359253,
      "learning_rate": 1.7559036144578313e-05,
      "loss": 0.0577,
      "step": 10130
    },
    {
      "epoch": 1.2216867469879518,
      "grad_norm": 4.721836090087891,
      "learning_rate": 1.7556626506024098e-05,
      "loss": 0.0779,
      "step": 10140
    },
    {
      "epoch": 1.2228915662650603,
      "grad_norm": 1.9769277572631836,
      "learning_rate": 1.755421686746988e-05,
      "loss": 0.0824,
      "step": 10150
    },
    {
      "epoch": 1.2240963855421687,
      "grad_norm": 3.1723756790161133,
      "learning_rate": 1.7551807228915664e-05,
      "loss": 0.1132,
      "step": 10160
    },
    {
      "epoch": 1.225301204819277,
      "grad_norm": 0.1819775551557541,
      "learning_rate": 1.754939759036145e-05,
      "loss": 0.0523,
      "step": 10170
    },
    {
      "epoch": 1.2265060240963854,
      "grad_norm": 1.823872685432434,
      "learning_rate": 1.754698795180723e-05,
      "loss": 0.0942,
      "step": 10180
    },
    {
      "epoch": 1.227710843373494,
      "grad_norm": 3.2331299781799316,
      "learning_rate": 1.7544578313253012e-05,
      "loss": 0.0557,
      "step": 10190
    },
    {
      "epoch": 1.2289156626506024,
      "grad_norm": 3.357534170150757,
      "learning_rate": 1.7542168674698797e-05,
      "loss": 0.0852,
      "step": 10200
    },
    {
      "epoch": 1.230120481927711,
      "grad_norm": 4.773426532745361,
      "learning_rate": 1.753975903614458e-05,
      "loss": 0.1711,
      "step": 10210
    },
    {
      "epoch": 1.2313253012048193,
      "grad_norm": 0.3293136954307556,
      "learning_rate": 1.7537349397590363e-05,
      "loss": 0.0685,
      "step": 10220
    },
    {
      "epoch": 1.2325301204819277,
      "grad_norm": 2.904402732849121,
      "learning_rate": 1.753493975903615e-05,
      "loss": 0.0824,
      "step": 10230
    },
    {
      "epoch": 1.233734939759036,
      "grad_norm": 0.31094834208488464,
      "learning_rate": 1.753253012048193e-05,
      "loss": 0.0499,
      "step": 10240
    },
    {
      "epoch": 1.2349397590361446,
      "grad_norm": 1.8491322994232178,
      "learning_rate": 1.753012048192771e-05,
      "loss": 0.0351,
      "step": 10250
    },
    {
      "epoch": 1.236144578313253,
      "grad_norm": 0.06956540048122406,
      "learning_rate": 1.7527710843373496e-05,
      "loss": 0.0584,
      "step": 10260
    },
    {
      "epoch": 1.2373493975903616,
      "grad_norm": 6.535285949707031,
      "learning_rate": 1.7525301204819278e-05,
      "loss": 0.1483,
      "step": 10270
    },
    {
      "epoch": 1.23855421686747,
      "grad_norm": 3.4770307540893555,
      "learning_rate": 1.7522891566265063e-05,
      "loss": 0.0703,
      "step": 10280
    },
    {
      "epoch": 1.2397590361445783,
      "grad_norm": 8.55228328704834,
      "learning_rate": 1.7520481927710844e-05,
      "loss": 0.0365,
      "step": 10290
    },
    {
      "epoch": 1.2409638554216866,
      "grad_norm": 0.7506315112113953,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 0.0526,
      "step": 10300
    },
    {
      "epoch": 1.2421686746987952,
      "grad_norm": 3.977276086807251,
      "learning_rate": 1.751566265060241e-05,
      "loss": 0.1472,
      "step": 10310
    },
    {
      "epoch": 1.2433734939759036,
      "grad_norm": 3.9207775592803955,
      "learning_rate": 1.7513253012048195e-05,
      "loss": 0.0615,
      "step": 10320
    },
    {
      "epoch": 1.2445783132530122,
      "grad_norm": 0.4059246778488159,
      "learning_rate": 1.7510843373493977e-05,
      "loss": 0.0589,
      "step": 10330
    },
    {
      "epoch": 1.2457831325301205,
      "grad_norm": 1.0394278764724731,
      "learning_rate": 1.750843373493976e-05,
      "loss": 0.0622,
      "step": 10340
    },
    {
      "epoch": 1.2469879518072289,
      "grad_norm": 0.49350878596305847,
      "learning_rate": 1.7506024096385543e-05,
      "loss": 0.0869,
      "step": 10350
    },
    {
      "epoch": 1.2481927710843372,
      "grad_norm": 0.15343093872070312,
      "learning_rate": 1.7503614457831325e-05,
      "loss": 0.0895,
      "step": 10360
    },
    {
      "epoch": 1.2493975903614458,
      "grad_norm": 0.22563740611076355,
      "learning_rate": 1.750120481927711e-05,
      "loss": 0.0494,
      "step": 10370
    },
    {
      "epoch": 1.2506024096385542,
      "grad_norm": 0.08728615194559097,
      "learning_rate": 1.7498795180722894e-05,
      "loss": 0.0435,
      "step": 10380
    },
    {
      "epoch": 1.2518072289156628,
      "grad_norm": 1.2575104236602783,
      "learning_rate": 1.7496385542168676e-05,
      "loss": 0.1087,
      "step": 10390
    },
    {
      "epoch": 1.2530120481927711,
      "grad_norm": 1.147645354270935,
      "learning_rate": 1.749397590361446e-05,
      "loss": 0.0999,
      "step": 10400
    },
    {
      "epoch": 1.2542168674698795,
      "grad_norm": 4.420530319213867,
      "learning_rate": 1.7491566265060242e-05,
      "loss": 0.1406,
      "step": 10410
    },
    {
      "epoch": 1.2554216867469878,
      "grad_norm": 3.2783873081207275,
      "learning_rate": 1.7489156626506027e-05,
      "loss": 0.0643,
      "step": 10420
    },
    {
      "epoch": 1.2566265060240964,
      "grad_norm": 15.196917533874512,
      "learning_rate": 1.748674698795181e-05,
      "loss": 0.0522,
      "step": 10430
    },
    {
      "epoch": 1.2578313253012048,
      "grad_norm": 0.0666046291589737,
      "learning_rate": 1.748433734939759e-05,
      "loss": 0.0606,
      "step": 10440
    },
    {
      "epoch": 1.2590361445783134,
      "grad_norm": 1.8380565643310547,
      "learning_rate": 1.7481927710843375e-05,
      "loss": 0.1043,
      "step": 10450
    },
    {
      "epoch": 1.2602409638554217,
      "grad_norm": 0.9889054298400879,
      "learning_rate": 1.747951807228916e-05,
      "loss": 0.1408,
      "step": 10460
    },
    {
      "epoch": 1.26144578313253,
      "grad_norm": 1.514574646949768,
      "learning_rate": 1.747710843373494e-05,
      "loss": 0.1203,
      "step": 10470
    },
    {
      "epoch": 1.2626506024096384,
      "grad_norm": 1.8816614151000977,
      "learning_rate": 1.7474698795180726e-05,
      "loss": 0.1,
      "step": 10480
    },
    {
      "epoch": 1.263855421686747,
      "grad_norm": 5.673141956329346,
      "learning_rate": 1.7472289156626508e-05,
      "loss": 0.0786,
      "step": 10490
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 0.9174630641937256,
      "learning_rate": 1.746987951807229e-05,
      "loss": 0.0493,
      "step": 10500
    },
    {
      "epoch": 1.266265060240964,
      "grad_norm": 4.212378025054932,
      "learning_rate": 1.7467469879518074e-05,
      "loss": 0.1079,
      "step": 10510
    },
    {
      "epoch": 1.2674698795180723,
      "grad_norm": 0.4035462439060211,
      "learning_rate": 1.7465060240963855e-05,
      "loss": 0.0708,
      "step": 10520
    },
    {
      "epoch": 1.2686746987951807,
      "grad_norm": 3.523946523666382,
      "learning_rate": 1.746265060240964e-05,
      "loss": 0.055,
      "step": 10530
    },
    {
      "epoch": 1.269879518072289,
      "grad_norm": 0.09610650688409805,
      "learning_rate": 1.7460240963855425e-05,
      "loss": 0.0767,
      "step": 10540
    },
    {
      "epoch": 1.2710843373493976,
      "grad_norm": 0.17137101292610168,
      "learning_rate": 1.7457831325301207e-05,
      "loss": 0.0717,
      "step": 10550
    },
    {
      "epoch": 1.272289156626506,
      "grad_norm": 2.339083194732666,
      "learning_rate": 1.7455421686746988e-05,
      "loss": 0.0602,
      "step": 10560
    },
    {
      "epoch": 1.2734939759036146,
      "grad_norm": 8.588424682617188,
      "learning_rate": 1.7453012048192773e-05,
      "loss": 0.0222,
      "step": 10570
    },
    {
      "epoch": 1.274698795180723,
      "grad_norm": 0.10660719871520996,
      "learning_rate": 1.7450602409638554e-05,
      "loss": 0.1065,
      "step": 10580
    },
    {
      "epoch": 1.2759036144578313,
      "grad_norm": 0.6792927980422974,
      "learning_rate": 1.744819277108434e-05,
      "loss": 0.0619,
      "step": 10590
    },
    {
      "epoch": 1.2771084337349397,
      "grad_norm": 0.24984334409236908,
      "learning_rate": 1.7445783132530124e-05,
      "loss": 0.0831,
      "step": 10600
    },
    {
      "epoch": 1.2783132530120482,
      "grad_norm": 1.8684300184249878,
      "learning_rate": 1.7443373493975906e-05,
      "loss": 0.0395,
      "step": 10610
    },
    {
      "epoch": 1.2795180722891566,
      "grad_norm": 0.48807698488235474,
      "learning_rate": 1.7440963855421687e-05,
      "loss": 0.097,
      "step": 10620
    },
    {
      "epoch": 1.2807228915662652,
      "grad_norm": 0.05321093648672104,
      "learning_rate": 1.7438554216867472e-05,
      "loss": 0.0764,
      "step": 10630
    },
    {
      "epoch": 1.2819277108433735,
      "grad_norm": 1.4015463590621948,
      "learning_rate": 1.7436144578313253e-05,
      "loss": 0.074,
      "step": 10640
    },
    {
      "epoch": 1.283132530120482,
      "grad_norm": 0.13278524577617645,
      "learning_rate": 1.743373493975904e-05,
      "loss": 0.0482,
      "step": 10650
    },
    {
      "epoch": 1.2843373493975903,
      "grad_norm": 0.4316082000732422,
      "learning_rate": 1.743132530120482e-05,
      "loss": 0.0796,
      "step": 10660
    },
    {
      "epoch": 1.2855421686746988,
      "grad_norm": 14.830988883972168,
      "learning_rate": 1.74289156626506e-05,
      "loss": 0.1115,
      "step": 10670
    },
    {
      "epoch": 1.2867469879518072,
      "grad_norm": 1.3041307926177979,
      "learning_rate": 1.742650602409639e-05,
      "loss": 0.1494,
      "step": 10680
    },
    {
      "epoch": 1.2879518072289158,
      "grad_norm": 27.12807846069336,
      "learning_rate": 1.742409638554217e-05,
      "loss": 0.1029,
      "step": 10690
    },
    {
      "epoch": 1.2891566265060241,
      "grad_norm": 3.5612056255340576,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 0.1742,
      "step": 10700
    },
    {
      "epoch": 1.2903614457831325,
      "grad_norm": 0.17313627898693085,
      "learning_rate": 1.7419277108433737e-05,
      "loss": 0.0868,
      "step": 10710
    },
    {
      "epoch": 1.2915662650602409,
      "grad_norm": 19.62282371520996,
      "learning_rate": 1.741686746987952e-05,
      "loss": 0.0372,
      "step": 10720
    },
    {
      "epoch": 1.2927710843373494,
      "grad_norm": 0.15609599649906158,
      "learning_rate": 1.7414457831325304e-05,
      "loss": 0.0439,
      "step": 10730
    },
    {
      "epoch": 1.2939759036144578,
      "grad_norm": 0.22384130954742432,
      "learning_rate": 1.7412048192771085e-05,
      "loss": 0.1067,
      "step": 10740
    },
    {
      "epoch": 1.2951807228915664,
      "grad_norm": 0.126190185546875,
      "learning_rate": 1.740963855421687e-05,
      "loss": 0.1175,
      "step": 10750
    },
    {
      "epoch": 1.2963855421686747,
      "grad_norm": 3.039499521255493,
      "learning_rate": 1.740722891566265e-05,
      "loss": 0.0878,
      "step": 10760
    },
    {
      "epoch": 1.297590361445783,
      "grad_norm": 5.8709282875061035,
      "learning_rate": 1.7404819277108436e-05,
      "loss": 0.0778,
      "step": 10770
    },
    {
      "epoch": 1.2987951807228915,
      "grad_norm": 4.874350070953369,
      "learning_rate": 1.7402409638554218e-05,
      "loss": 0.0844,
      "step": 10780
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.06823959201574326,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.086,
      "step": 10790
    },
    {
      "epoch": 1.3012048192771084,
      "grad_norm": 0.2237224280834198,
      "learning_rate": 1.7397590361445784e-05,
      "loss": 0.0686,
      "step": 10800
    },
    {
      "epoch": 1.302409638554217,
      "grad_norm": 3.397007465362549,
      "learning_rate": 1.7395180722891566e-05,
      "loss": 0.0487,
      "step": 10810
    },
    {
      "epoch": 1.3036144578313253,
      "grad_norm": 0.09943709522485733,
      "learning_rate": 1.739277108433735e-05,
      "loss": 0.075,
      "step": 10820
    },
    {
      "epoch": 1.3048192771084337,
      "grad_norm": 16.428720474243164,
      "learning_rate": 1.7390361445783136e-05,
      "loss": 0.0853,
      "step": 10830
    },
    {
      "epoch": 1.306024096385542,
      "grad_norm": 10.78369426727295,
      "learning_rate": 1.7387951807228917e-05,
      "loss": 0.0801,
      "step": 10840
    },
    {
      "epoch": 1.3072289156626506,
      "grad_norm": 4.1147918701171875,
      "learning_rate": 1.7385542168674702e-05,
      "loss": 0.0934,
      "step": 10850
    },
    {
      "epoch": 1.308433734939759,
      "grad_norm": 0.19699178636074066,
      "learning_rate": 1.7383132530120483e-05,
      "loss": 0.0804,
      "step": 10860
    },
    {
      "epoch": 1.3096385542168676,
      "grad_norm": 0.683285117149353,
      "learning_rate": 1.7380722891566265e-05,
      "loss": 0.0625,
      "step": 10870
    },
    {
      "epoch": 1.310843373493976,
      "grad_norm": 5.3359551429748535,
      "learning_rate": 1.737831325301205e-05,
      "loss": 0.0805,
      "step": 10880
    },
    {
      "epoch": 1.3120481927710843,
      "grad_norm": 0.45656120777130127,
      "learning_rate": 1.737590361445783e-05,
      "loss": 0.0744,
      "step": 10890
    },
    {
      "epoch": 1.3132530120481927,
      "grad_norm": 0.14754866063594818,
      "learning_rate": 1.7373493975903616e-05,
      "loss": 0.0537,
      "step": 10900
    },
    {
      "epoch": 1.3144578313253013,
      "grad_norm": 3.843550443649292,
      "learning_rate": 1.73710843373494e-05,
      "loss": 0.0818,
      "step": 10910
    },
    {
      "epoch": 1.3156626506024096,
      "grad_norm": 13.746347427368164,
      "learning_rate": 1.7368674698795182e-05,
      "loss": 0.0507,
      "step": 10920
    },
    {
      "epoch": 1.3168674698795182,
      "grad_norm": 14.418669700622559,
      "learning_rate": 1.7366265060240964e-05,
      "loss": 0.1138,
      "step": 10930
    },
    {
      "epoch": 1.3180722891566266,
      "grad_norm": 5.58109712600708,
      "learning_rate": 1.736385542168675e-05,
      "loss": 0.1028,
      "step": 10940
    },
    {
      "epoch": 1.319277108433735,
      "grad_norm": 9.77371597290039,
      "learning_rate": 1.736144578313253e-05,
      "loss": 0.0514,
      "step": 10950
    },
    {
      "epoch": 1.3204819277108433,
      "grad_norm": 8.331400871276855,
      "learning_rate": 1.7359036144578315e-05,
      "loss": 0.0475,
      "step": 10960
    },
    {
      "epoch": 1.3216867469879519,
      "grad_norm": 0.21187613904476166,
      "learning_rate": 1.7356626506024097e-05,
      "loss": 0.0513,
      "step": 10970
    },
    {
      "epoch": 1.3228915662650602,
      "grad_norm": 4.989753723144531,
      "learning_rate": 1.735421686746988e-05,
      "loss": 0.0404,
      "step": 10980
    },
    {
      "epoch": 1.3240963855421688,
      "grad_norm": 4.354630470275879,
      "learning_rate": 1.7351807228915666e-05,
      "loss": 0.0666,
      "step": 10990
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 31.905254364013672,
      "learning_rate": 1.7349397590361448e-05,
      "loss": 0.104,
      "step": 11000
    },
    {
      "epoch": 1.3265060240963855,
      "grad_norm": 0.29834407567977905,
      "learning_rate": 1.734698795180723e-05,
      "loss": 0.0923,
      "step": 11010
    },
    {
      "epoch": 1.3277108433734939,
      "grad_norm": 0.45893770456314087,
      "learning_rate": 1.7344578313253014e-05,
      "loss": 0.1766,
      "step": 11020
    },
    {
      "epoch": 1.3289156626506025,
      "grad_norm": 1.8752621412277222,
      "learning_rate": 1.7342168674698796e-05,
      "loss": 0.1145,
      "step": 11030
    },
    {
      "epoch": 1.3301204819277108,
      "grad_norm": 0.32570868730545044,
      "learning_rate": 1.733975903614458e-05,
      "loss": 0.0489,
      "step": 11040
    },
    {
      "epoch": 1.3313253012048194,
      "grad_norm": 3.5456008911132812,
      "learning_rate": 1.7337349397590365e-05,
      "loss": 0.0472,
      "step": 11050
    },
    {
      "epoch": 1.3325301204819278,
      "grad_norm": 2.6679999828338623,
      "learning_rate": 1.7334939759036147e-05,
      "loss": 0.0671,
      "step": 11060
    },
    {
      "epoch": 1.3337349397590361,
      "grad_norm": 3.30991530418396,
      "learning_rate": 1.733253012048193e-05,
      "loss": 0.0971,
      "step": 11070
    },
    {
      "epoch": 1.3349397590361445,
      "grad_norm": 0.8525757789611816,
      "learning_rate": 1.7330120481927713e-05,
      "loss": 0.1019,
      "step": 11080
    },
    {
      "epoch": 1.336144578313253,
      "grad_norm": 4.855707168579102,
      "learning_rate": 1.7327710843373495e-05,
      "loss": 0.0607,
      "step": 11090
    },
    {
      "epoch": 1.3373493975903614,
      "grad_norm": 0.16048097610473633,
      "learning_rate": 1.732530120481928e-05,
      "loss": 0.0736,
      "step": 11100
    },
    {
      "epoch": 1.33855421686747,
      "grad_norm": 0.0722377598285675,
      "learning_rate": 1.732289156626506e-05,
      "loss": 0.0609,
      "step": 11110
    },
    {
      "epoch": 1.3397590361445784,
      "grad_norm": 0.2222716063261032,
      "learning_rate": 1.7320481927710843e-05,
      "loss": 0.037,
      "step": 11120
    },
    {
      "epoch": 1.3409638554216867,
      "grad_norm": 3.2542102336883545,
      "learning_rate": 1.7318072289156627e-05,
      "loss": 0.0639,
      "step": 11130
    },
    {
      "epoch": 1.342168674698795,
      "grad_norm": 4.360464096069336,
      "learning_rate": 1.7315662650602412e-05,
      "loss": 0.1075,
      "step": 11140
    },
    {
      "epoch": 1.3433734939759037,
      "grad_norm": 10.360447883605957,
      "learning_rate": 1.7313253012048194e-05,
      "loss": 0.09,
      "step": 11150
    },
    {
      "epoch": 1.344578313253012,
      "grad_norm": 0.4081155061721802,
      "learning_rate": 1.731084337349398e-05,
      "loss": 0.0964,
      "step": 11160
    },
    {
      "epoch": 1.3457831325301206,
      "grad_norm": 0.07067585736513138,
      "learning_rate": 1.730843373493976e-05,
      "loss": 0.0717,
      "step": 11170
    },
    {
      "epoch": 1.346987951807229,
      "grad_norm": 0.06849794834852219,
      "learning_rate": 1.730602409638554e-05,
      "loss": 0.0728,
      "step": 11180
    },
    {
      "epoch": 1.3481927710843373,
      "grad_norm": 5.705291748046875,
      "learning_rate": 1.7303614457831326e-05,
      "loss": 0.0678,
      "step": 11190
    },
    {
      "epoch": 1.3493975903614457,
      "grad_norm": 0.09822899103164673,
      "learning_rate": 1.730120481927711e-05,
      "loss": 0.0122,
      "step": 11200
    },
    {
      "epoch": 1.3506024096385543,
      "grad_norm": 9.308952331542969,
      "learning_rate": 1.7298795180722893e-05,
      "loss": 0.1069,
      "step": 11210
    },
    {
      "epoch": 1.3518072289156626,
      "grad_norm": 3.852910280227661,
      "learning_rate": 1.7296385542168678e-05,
      "loss": 0.0717,
      "step": 11220
    },
    {
      "epoch": 1.3530120481927712,
      "grad_norm": 2.9669032096862793,
      "learning_rate": 1.729397590361446e-05,
      "loss": 0.0954,
      "step": 11230
    },
    {
      "epoch": 1.3542168674698796,
      "grad_norm": 0.43922698497772217,
      "learning_rate": 1.729156626506024e-05,
      "loss": 0.086,
      "step": 11240
    },
    {
      "epoch": 1.355421686746988,
      "grad_norm": 14.746467590332031,
      "learning_rate": 1.7289156626506026e-05,
      "loss": 0.1117,
      "step": 11250
    },
    {
      "epoch": 1.3566265060240963,
      "grad_norm": 0.41495364904403687,
      "learning_rate": 1.7286746987951807e-05,
      "loss": 0.148,
      "step": 11260
    },
    {
      "epoch": 1.3578313253012049,
      "grad_norm": 0.8713266849517822,
      "learning_rate": 1.7284337349397592e-05,
      "loss": 0.1094,
      "step": 11270
    },
    {
      "epoch": 1.3590361445783132,
      "grad_norm": 10.899060249328613,
      "learning_rate": 1.7281927710843377e-05,
      "loss": 0.0642,
      "step": 11280
    },
    {
      "epoch": 1.3602409638554218,
      "grad_norm": 0.06421717256307602,
      "learning_rate": 1.7279518072289158e-05,
      "loss": 0.1022,
      "step": 11290
    },
    {
      "epoch": 1.3614457831325302,
      "grad_norm": 14.195162773132324,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 0.1264,
      "step": 11300
    },
    {
      "epoch": 1.3626506024096385,
      "grad_norm": 0.42362940311431885,
      "learning_rate": 1.7274698795180725e-05,
      "loss": 0.0453,
      "step": 11310
    },
    {
      "epoch": 1.363855421686747,
      "grad_norm": 0.07219148427248001,
      "learning_rate": 1.7272289156626506e-05,
      "loss": 0.0701,
      "step": 11320
    },
    {
      "epoch": 1.3650602409638555,
      "grad_norm": 16.65545654296875,
      "learning_rate": 1.726987951807229e-05,
      "loss": 0.0701,
      "step": 11330
    },
    {
      "epoch": 1.3662650602409638,
      "grad_norm": 4.039283752441406,
      "learning_rate": 1.7267469879518072e-05,
      "loss": 0.1515,
      "step": 11340
    },
    {
      "epoch": 1.3674698795180724,
      "grad_norm": 4.724751949310303,
      "learning_rate": 1.7265060240963857e-05,
      "loss": 0.1057,
      "step": 11350
    },
    {
      "epoch": 1.3686746987951808,
      "grad_norm": 0.8459091186523438,
      "learning_rate": 1.7262650602409642e-05,
      "loss": 0.055,
      "step": 11360
    },
    {
      "epoch": 1.3698795180722891,
      "grad_norm": 3.224447011947632,
      "learning_rate": 1.7260240963855424e-05,
      "loss": 0.0955,
      "step": 11370
    },
    {
      "epoch": 1.3710843373493975,
      "grad_norm": 0.28176045417785645,
      "learning_rate": 1.7257831325301205e-05,
      "loss": 0.054,
      "step": 11380
    },
    {
      "epoch": 1.372289156626506,
      "grad_norm": 0.26606228947639465,
      "learning_rate": 1.725542168674699e-05,
      "loss": 0.0628,
      "step": 11390
    },
    {
      "epoch": 1.3734939759036144,
      "grad_norm": 7.912519454956055,
      "learning_rate": 1.725301204819277e-05,
      "loss": 0.0819,
      "step": 11400
    },
    {
      "epoch": 1.374698795180723,
      "grad_norm": 6.0872979164123535,
      "learning_rate": 1.7250602409638556e-05,
      "loss": 0.0633,
      "step": 11410
    },
    {
      "epoch": 1.3759036144578314,
      "grad_norm": 5.457685947418213,
      "learning_rate": 1.7248192771084338e-05,
      "loss": 0.1037,
      "step": 11420
    },
    {
      "epoch": 1.3771084337349397,
      "grad_norm": 3.737241744995117,
      "learning_rate": 1.7245783132530123e-05,
      "loss": 0.1454,
      "step": 11430
    },
    {
      "epoch": 1.378313253012048,
      "grad_norm": 5.232436656951904,
      "learning_rate": 1.7243373493975904e-05,
      "loss": 0.1374,
      "step": 11440
    },
    {
      "epoch": 1.3795180722891567,
      "grad_norm": 3.1670854091644287,
      "learning_rate": 1.724096385542169e-05,
      "loss": 0.1336,
      "step": 11450
    },
    {
      "epoch": 1.380722891566265,
      "grad_norm": 1.3008207082748413,
      "learning_rate": 1.723855421686747e-05,
      "loss": 0.0692,
      "step": 11460
    },
    {
      "epoch": 1.3819277108433736,
      "grad_norm": 4.1793060302734375,
      "learning_rate": 1.7236144578313255e-05,
      "loss": 0.0845,
      "step": 11470
    },
    {
      "epoch": 1.383132530120482,
      "grad_norm": 4.962939739227295,
      "learning_rate": 1.7233734939759037e-05,
      "loss": 0.0791,
      "step": 11480
    },
    {
      "epoch": 1.3843373493975903,
      "grad_norm": 0.10933806747198105,
      "learning_rate": 1.723132530120482e-05,
      "loss": 0.0718,
      "step": 11490
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 3.877633571624756,
      "learning_rate": 1.7228915662650603e-05,
      "loss": 0.0705,
      "step": 11500
    },
    {
      "epoch": 1.3867469879518073,
      "grad_norm": 0.35348546504974365,
      "learning_rate": 1.7226506024096388e-05,
      "loss": 0.0551,
      "step": 11510
    },
    {
      "epoch": 1.3879518072289156,
      "grad_norm": 4.748460292816162,
      "learning_rate": 1.722409638554217e-05,
      "loss": 0.14,
      "step": 11520
    },
    {
      "epoch": 1.3891566265060242,
      "grad_norm": 4.481184959411621,
      "learning_rate": 1.7221686746987954e-05,
      "loss": 0.0649,
      "step": 11530
    },
    {
      "epoch": 1.3903614457831326,
      "grad_norm": 6.241885662078857,
      "learning_rate": 1.7219277108433736e-05,
      "loss": 0.0927,
      "step": 11540
    },
    {
      "epoch": 1.391566265060241,
      "grad_norm": 4.640196800231934,
      "learning_rate": 1.7216867469879517e-05,
      "loss": 0.0692,
      "step": 11550
    },
    {
      "epoch": 1.3927710843373493,
      "grad_norm": 0.5334892868995667,
      "learning_rate": 1.7214457831325302e-05,
      "loss": 0.1006,
      "step": 11560
    },
    {
      "epoch": 1.393975903614458,
      "grad_norm": 1.5304819345474243,
      "learning_rate": 1.7212048192771084e-05,
      "loss": 0.0691,
      "step": 11570
    },
    {
      "epoch": 1.3951807228915662,
      "grad_norm": 2.5648233890533447,
      "learning_rate": 1.720963855421687e-05,
      "loss": 0.065,
      "step": 11580
    },
    {
      "epoch": 1.3963855421686748,
      "grad_norm": 0.7077022194862366,
      "learning_rate": 1.7207228915662654e-05,
      "loss": 0.0634,
      "step": 11590
    },
    {
      "epoch": 1.3975903614457832,
      "grad_norm": 5.192252159118652,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 0.1147,
      "step": 11600
    },
    {
      "epoch": 1.3987951807228916,
      "grad_norm": 0.15100014209747314,
      "learning_rate": 1.720240963855422e-05,
      "loss": 0.0713,
      "step": 11610
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.5944455862045288,
      "learning_rate": 1.72e-05,
      "loss": 0.0593,
      "step": 11620
    },
    {
      "epoch": 1.4012048192771085,
      "grad_norm": 1.121060848236084,
      "learning_rate": 1.7197590361445783e-05,
      "loss": 0.029,
      "step": 11630
    },
    {
      "epoch": 1.4024096385542169,
      "grad_norm": 2.6985573768615723,
      "learning_rate": 1.7195180722891568e-05,
      "loss": 0.0798,
      "step": 11640
    },
    {
      "epoch": 1.4036144578313254,
      "grad_norm": 3.7270209789276123,
      "learning_rate": 1.7192771084337353e-05,
      "loss": 0.0904,
      "step": 11650
    },
    {
      "epoch": 1.4048192771084338,
      "grad_norm": 0.1102822870016098,
      "learning_rate": 1.7190361445783134e-05,
      "loss": 0.0496,
      "step": 11660
    },
    {
      "epoch": 1.4060240963855422,
      "grad_norm": 2.6802737712860107,
      "learning_rate": 1.718795180722892e-05,
      "loss": 0.0914,
      "step": 11670
    },
    {
      "epoch": 1.4072289156626505,
      "grad_norm": 0.4695228338241577,
      "learning_rate": 1.71855421686747e-05,
      "loss": 0.1661,
      "step": 11680
    },
    {
      "epoch": 1.408433734939759,
      "grad_norm": 1.7191836833953857,
      "learning_rate": 1.7183132530120482e-05,
      "loss": 0.0727,
      "step": 11690
    },
    {
      "epoch": 1.4096385542168675,
      "grad_norm": 3.714956045150757,
      "learning_rate": 1.7180722891566267e-05,
      "loss": 0.1494,
      "step": 11700
    },
    {
      "epoch": 1.410843373493976,
      "grad_norm": 12.513761520385742,
      "learning_rate": 1.7178313253012048e-05,
      "loss": 0.1388,
      "step": 11710
    },
    {
      "epoch": 1.4120481927710844,
      "grad_norm": 0.33560484647750854,
      "learning_rate": 1.7175903614457833e-05,
      "loss": 0.0743,
      "step": 11720
    },
    {
      "epoch": 1.4132530120481928,
      "grad_norm": 1.1272895336151123,
      "learning_rate": 1.7173493975903618e-05,
      "loss": 0.0383,
      "step": 11730
    },
    {
      "epoch": 1.4144578313253011,
      "grad_norm": 0.08553244918584824,
      "learning_rate": 1.71710843373494e-05,
      "loss": 0.0589,
      "step": 11740
    },
    {
      "epoch": 1.4156626506024097,
      "grad_norm": 0.22211629152297974,
      "learning_rate": 1.716867469879518e-05,
      "loss": 0.0784,
      "step": 11750
    },
    {
      "epoch": 1.416867469879518,
      "grad_norm": 0.14445938169956207,
      "learning_rate": 1.7166265060240966e-05,
      "loss": 0.0882,
      "step": 11760
    },
    {
      "epoch": 1.4180722891566266,
      "grad_norm": 0.5414705276489258,
      "learning_rate": 1.7163855421686747e-05,
      "loss": 0.1157,
      "step": 11770
    },
    {
      "epoch": 1.419277108433735,
      "grad_norm": 0.2882883846759796,
      "learning_rate": 1.7161445783132532e-05,
      "loss": 0.0406,
      "step": 11780
    },
    {
      "epoch": 1.4204819277108434,
      "grad_norm": 0.6878353357315063,
      "learning_rate": 1.7159036144578314e-05,
      "loss": 0.0947,
      "step": 11790
    },
    {
      "epoch": 1.4216867469879517,
      "grad_norm": 3.3642213344573975,
      "learning_rate": 1.71566265060241e-05,
      "loss": 0.0498,
      "step": 11800
    },
    {
      "epoch": 1.4228915662650603,
      "grad_norm": 2.8153440952301025,
      "learning_rate": 1.7154216867469883e-05,
      "loss": 0.1061,
      "step": 11810
    },
    {
      "epoch": 1.4240963855421687,
      "grad_norm": 3.7916066646575928,
      "learning_rate": 1.7151807228915665e-05,
      "loss": 0.1523,
      "step": 11820
    },
    {
      "epoch": 1.4253012048192772,
      "grad_norm": 3.4823901653289795,
      "learning_rate": 1.7149397590361446e-05,
      "loss": 0.0499,
      "step": 11830
    },
    {
      "epoch": 1.4265060240963856,
      "grad_norm": 3.7323567867279053,
      "learning_rate": 1.714698795180723e-05,
      "loss": 0.1838,
      "step": 11840
    },
    {
      "epoch": 1.427710843373494,
      "grad_norm": 0.07410210371017456,
      "learning_rate": 1.7144578313253013e-05,
      "loss": 0.0344,
      "step": 11850
    },
    {
      "epoch": 1.4289156626506023,
      "grad_norm": 0.19566456973552704,
      "learning_rate": 1.7142168674698794e-05,
      "loss": 0.0559,
      "step": 11860
    },
    {
      "epoch": 1.430120481927711,
      "grad_norm": 4.236376762390137,
      "learning_rate": 1.713975903614458e-05,
      "loss": 0.1214,
      "step": 11870
    },
    {
      "epoch": 1.4313253012048193,
      "grad_norm": 2.067542552947998,
      "learning_rate": 1.7137349397590364e-05,
      "loss": 0.0544,
      "step": 11880
    },
    {
      "epoch": 1.4325301204819278,
      "grad_norm": 0.06706552952528,
      "learning_rate": 1.7134939759036145e-05,
      "loss": 0.065,
      "step": 11890
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 0.0687178447842598,
      "learning_rate": 1.713253012048193e-05,
      "loss": 0.0657,
      "step": 11900
    },
    {
      "epoch": 1.4349397590361446,
      "grad_norm": 2.801100969314575,
      "learning_rate": 1.7130120481927712e-05,
      "loss": 0.0902,
      "step": 11910
    },
    {
      "epoch": 1.436144578313253,
      "grad_norm": 1.6437171697616577,
      "learning_rate": 1.7127710843373497e-05,
      "loss": 0.0848,
      "step": 11920
    },
    {
      "epoch": 1.4373493975903615,
      "grad_norm": 0.7889189720153809,
      "learning_rate": 1.7125301204819278e-05,
      "loss": 0.0315,
      "step": 11930
    },
    {
      "epoch": 1.4385542168674699,
      "grad_norm": 0.5671380162239075,
      "learning_rate": 1.712289156626506e-05,
      "loss": 0.1073,
      "step": 11940
    },
    {
      "epoch": 1.4397590361445782,
      "grad_norm": 0.8835929036140442,
      "learning_rate": 1.7120481927710844e-05,
      "loss": 0.04,
      "step": 11950
    },
    {
      "epoch": 1.4409638554216868,
      "grad_norm": 6.066786766052246,
      "learning_rate": 1.711807228915663e-05,
      "loss": 0.0696,
      "step": 11960
    },
    {
      "epoch": 1.4421686746987952,
      "grad_norm": 1.269309639930725,
      "learning_rate": 1.711566265060241e-05,
      "loss": 0.0353,
      "step": 11970
    },
    {
      "epoch": 1.4433734939759035,
      "grad_norm": 5.0844197273254395,
      "learning_rate": 1.7113253012048196e-05,
      "loss": 0.1037,
      "step": 11980
    },
    {
      "epoch": 1.4445783132530121,
      "grad_norm": 0.7933349013328552,
      "learning_rate": 1.7110843373493977e-05,
      "loss": 0.113,
      "step": 11990
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 13.639717102050781,
      "learning_rate": 1.710843373493976e-05,
      "loss": 0.0532,
      "step": 12000
    },
    {
      "epoch": 1.4469879518072288,
      "grad_norm": 14.74461555480957,
      "learning_rate": 1.7106024096385544e-05,
      "loss": 0.1366,
      "step": 12010
    },
    {
      "epoch": 1.4481927710843374,
      "grad_norm": 3.2752363681793213,
      "learning_rate": 1.7103614457831325e-05,
      "loss": 0.122,
      "step": 12020
    },
    {
      "epoch": 1.4493975903614458,
      "grad_norm": 0.7454479932785034,
      "learning_rate": 1.710120481927711e-05,
      "loss": 0.0848,
      "step": 12030
    },
    {
      "epoch": 1.4506024096385541,
      "grad_norm": 3.9771742820739746,
      "learning_rate": 1.7098795180722895e-05,
      "loss": 0.1185,
      "step": 12040
    },
    {
      "epoch": 1.4518072289156627,
      "grad_norm": 0.10522884130477905,
      "learning_rate": 1.7096385542168676e-05,
      "loss": 0.0478,
      "step": 12050
    },
    {
      "epoch": 1.453012048192771,
      "grad_norm": 6.972200870513916,
      "learning_rate": 1.7093975903614458e-05,
      "loss": 0.0793,
      "step": 12060
    },
    {
      "epoch": 1.4542168674698794,
      "grad_norm": 0.40579602122306824,
      "learning_rate": 1.7091566265060243e-05,
      "loss": 0.1166,
      "step": 12070
    },
    {
      "epoch": 1.455421686746988,
      "grad_norm": 3.5066299438476562,
      "learning_rate": 1.7089156626506024e-05,
      "loss": 0.0699,
      "step": 12080
    },
    {
      "epoch": 1.4566265060240964,
      "grad_norm": 0.04652421921491623,
      "learning_rate": 1.708674698795181e-05,
      "loss": 0.0504,
      "step": 12090
    },
    {
      "epoch": 1.4578313253012047,
      "grad_norm": 2.9125888347625732,
      "learning_rate": 1.7084337349397594e-05,
      "loss": 0.0746,
      "step": 12100
    },
    {
      "epoch": 1.4590361445783133,
      "grad_norm": 8.031814575195312,
      "learning_rate": 1.7081927710843375e-05,
      "loss": 0.0754,
      "step": 12110
    },
    {
      "epoch": 1.4602409638554217,
      "grad_norm": 3.828099012374878,
      "learning_rate": 1.707951807228916e-05,
      "loss": 0.06,
      "step": 12120
    },
    {
      "epoch": 1.46144578313253,
      "grad_norm": 10.488151550292969,
      "learning_rate": 1.707710843373494e-05,
      "loss": 0.0628,
      "step": 12130
    },
    {
      "epoch": 1.4626506024096386,
      "grad_norm": 1.0823372602462769,
      "learning_rate": 1.7074698795180723e-05,
      "loss": 0.0444,
      "step": 12140
    },
    {
      "epoch": 1.463855421686747,
      "grad_norm": 4.41718864440918,
      "learning_rate": 1.7072289156626508e-05,
      "loss": 0.0945,
      "step": 12150
    },
    {
      "epoch": 1.4650602409638553,
      "grad_norm": 2.174691677093506,
      "learning_rate": 1.706987951807229e-05,
      "loss": 0.043,
      "step": 12160
    },
    {
      "epoch": 1.466265060240964,
      "grad_norm": 2.6074674129486084,
      "learning_rate": 1.7067469879518074e-05,
      "loss": 0.1185,
      "step": 12170
    },
    {
      "epoch": 1.4674698795180723,
      "grad_norm": 8.555282592773438,
      "learning_rate": 1.706506024096386e-05,
      "loss": 0.0701,
      "step": 12180
    },
    {
      "epoch": 1.4686746987951806,
      "grad_norm": 10.732279777526855,
      "learning_rate": 1.706265060240964e-05,
      "loss": 0.0999,
      "step": 12190
    },
    {
      "epoch": 1.4698795180722892,
      "grad_norm": 3.323556423187256,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 0.0966,
      "step": 12200
    },
    {
      "epoch": 1.4710843373493976,
      "grad_norm": 3.1435136795043945,
      "learning_rate": 1.7057831325301207e-05,
      "loss": 0.076,
      "step": 12210
    },
    {
      "epoch": 1.472289156626506,
      "grad_norm": 8.706347465515137,
      "learning_rate": 1.705542168674699e-05,
      "loss": 0.0707,
      "step": 12220
    },
    {
      "epoch": 1.4734939759036145,
      "grad_norm": 0.6293055415153503,
      "learning_rate": 1.7053012048192773e-05,
      "loss": 0.0353,
      "step": 12230
    },
    {
      "epoch": 1.4746987951807229,
      "grad_norm": 0.3864184021949768,
      "learning_rate": 1.7050602409638555e-05,
      "loss": 0.0549,
      "step": 12240
    },
    {
      "epoch": 1.4759036144578312,
      "grad_norm": 4.14009428024292,
      "learning_rate": 1.704819277108434e-05,
      "loss": 0.0919,
      "step": 12250
    },
    {
      "epoch": 1.4771084337349398,
      "grad_norm": 2.7746808528900146,
      "learning_rate": 1.704578313253012e-05,
      "loss": 0.0612,
      "step": 12260
    },
    {
      "epoch": 1.4783132530120482,
      "grad_norm": 2.479144811630249,
      "learning_rate": 1.7043373493975906e-05,
      "loss": 0.0634,
      "step": 12270
    },
    {
      "epoch": 1.4795180722891565,
      "grad_norm": 3.5452077388763428,
      "learning_rate": 1.7040963855421688e-05,
      "loss": 0.1467,
      "step": 12280
    },
    {
      "epoch": 1.4807228915662651,
      "grad_norm": 0.534341037273407,
      "learning_rate": 1.7038554216867472e-05,
      "loss": 0.0722,
      "step": 12290
    },
    {
      "epoch": 1.4819277108433735,
      "grad_norm": 8.017899513244629,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 0.0708,
      "step": 12300
    },
    {
      "epoch": 1.4831325301204819,
      "grad_norm": 3.7694361209869385,
      "learning_rate": 1.7033734939759035e-05,
      "loss": 0.1323,
      "step": 12310
    },
    {
      "epoch": 1.4843373493975904,
      "grad_norm": 2.121121406555176,
      "learning_rate": 1.703132530120482e-05,
      "loss": 0.0293,
      "step": 12320
    },
    {
      "epoch": 1.4855421686746988,
      "grad_norm": 0.4238456189632416,
      "learning_rate": 1.7028915662650605e-05,
      "loss": 0.0994,
      "step": 12330
    },
    {
      "epoch": 1.4867469879518072,
      "grad_norm": 3.3477370738983154,
      "learning_rate": 1.7026506024096387e-05,
      "loss": 0.0699,
      "step": 12340
    },
    {
      "epoch": 1.4879518072289157,
      "grad_norm": 6.68308162689209,
      "learning_rate": 1.702409638554217e-05,
      "loss": 0.0949,
      "step": 12350
    },
    {
      "epoch": 1.489156626506024,
      "grad_norm": 0.7602141499519348,
      "learning_rate": 1.7021686746987953e-05,
      "loss": 0.1006,
      "step": 12360
    },
    {
      "epoch": 1.4903614457831325,
      "grad_norm": 3.7496719360351562,
      "learning_rate": 1.7019277108433734e-05,
      "loss": 0.0841,
      "step": 12370
    },
    {
      "epoch": 1.491566265060241,
      "grad_norm": 0.5156211256980896,
      "learning_rate": 1.701686746987952e-05,
      "loss": 0.0668,
      "step": 12380
    },
    {
      "epoch": 1.4927710843373494,
      "grad_norm": 3.867903709411621,
      "learning_rate": 1.70144578313253e-05,
      "loss": 0.0615,
      "step": 12390
    },
    {
      "epoch": 1.4939759036144578,
      "grad_norm": 0.19405677914619446,
      "learning_rate": 1.7012048192771086e-05,
      "loss": 0.0851,
      "step": 12400
    },
    {
      "epoch": 1.4951807228915663,
      "grad_norm": 0.1910691112279892,
      "learning_rate": 1.700963855421687e-05,
      "loss": 0.1284,
      "step": 12410
    },
    {
      "epoch": 1.4963855421686747,
      "grad_norm": 6.3637261390686035,
      "learning_rate": 1.7007228915662652e-05,
      "loss": 0.0783,
      "step": 12420
    },
    {
      "epoch": 1.497590361445783,
      "grad_norm": 4.698719501495361,
      "learning_rate": 1.7004819277108437e-05,
      "loss": 0.0756,
      "step": 12430
    },
    {
      "epoch": 1.4987951807228916,
      "grad_norm": 0.9685761332511902,
      "learning_rate": 1.700240963855422e-05,
      "loss": 0.0565,
      "step": 12440
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.12290309369564056,
      "learning_rate": 1.7e-05,
      "loss": 0.0371,
      "step": 12450
    },
    {
      "epoch": 1.5012048192771084,
      "grad_norm": 10.570355415344238,
      "learning_rate": 1.6997590361445785e-05,
      "loss": 0.1177,
      "step": 12460
    },
    {
      "epoch": 1.5024096385542167,
      "grad_norm": 0.40198585391044617,
      "learning_rate": 1.6995180722891566e-05,
      "loss": 0.1107,
      "step": 12470
    },
    {
      "epoch": 1.5036144578313253,
      "grad_norm": 0.11564662307500839,
      "learning_rate": 1.699277108433735e-05,
      "loss": 0.0843,
      "step": 12480
    },
    {
      "epoch": 1.5048192771084339,
      "grad_norm": 5.4478230476379395,
      "learning_rate": 1.6990361445783136e-05,
      "loss": 0.0743,
      "step": 12490
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 2.027047872543335,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 0.0833,
      "step": 12500
    },
    {
      "epoch": 1.5072289156626506,
      "grad_norm": 0.07347603887319565,
      "learning_rate": 1.69855421686747e-05,
      "loss": 0.0586,
      "step": 12510
    },
    {
      "epoch": 1.508433734939759,
      "grad_norm": 2.5796022415161133,
      "learning_rate": 1.6983132530120484e-05,
      "loss": 0.122,
      "step": 12520
    },
    {
      "epoch": 1.5096385542168673,
      "grad_norm": 6.790740489959717,
      "learning_rate": 1.6980722891566265e-05,
      "loss": 0.0671,
      "step": 12530
    },
    {
      "epoch": 1.510843373493976,
      "grad_norm": 10.026432991027832,
      "learning_rate": 1.697831325301205e-05,
      "loss": 0.0901,
      "step": 12540
    },
    {
      "epoch": 1.5120481927710845,
      "grad_norm": 3.2333338260650635,
      "learning_rate": 1.6975903614457835e-05,
      "loss": 0.052,
      "step": 12550
    },
    {
      "epoch": 1.5132530120481928,
      "grad_norm": 3.819061517715454,
      "learning_rate": 1.6973493975903616e-05,
      "loss": 0.073,
      "step": 12560
    },
    {
      "epoch": 1.5144578313253012,
      "grad_norm": 0.12500271201133728,
      "learning_rate": 1.6971084337349398e-05,
      "loss": 0.0368,
      "step": 12570
    },
    {
      "epoch": 1.5156626506024096,
      "grad_norm": 1.0770372152328491,
      "learning_rate": 1.6968674698795183e-05,
      "loss": 0.055,
      "step": 12580
    },
    {
      "epoch": 1.516867469879518,
      "grad_norm": 7.252121925354004,
      "learning_rate": 1.6966265060240964e-05,
      "loss": 0.1132,
      "step": 12590
    },
    {
      "epoch": 1.5180722891566265,
      "grad_norm": 8.430649757385254,
      "learning_rate": 1.696385542168675e-05,
      "loss": 0.1234,
      "step": 12600
    },
    {
      "epoch": 1.519277108433735,
      "grad_norm": 0.19022315740585327,
      "learning_rate": 1.696144578313253e-05,
      "loss": 0.0567,
      "step": 12610
    },
    {
      "epoch": 1.5204819277108435,
      "grad_norm": 2.8693559169769287,
      "learning_rate": 1.6959036144578312e-05,
      "loss": 0.0898,
      "step": 12620
    },
    {
      "epoch": 1.5216867469879518,
      "grad_norm": 7.480566501617432,
      "learning_rate": 1.6956626506024097e-05,
      "loss": 0.0543,
      "step": 12630
    },
    {
      "epoch": 1.5228915662650602,
      "grad_norm": 0.3293862044811249,
      "learning_rate": 1.6954216867469882e-05,
      "loss": 0.0309,
      "step": 12640
    },
    {
      "epoch": 1.5240963855421685,
      "grad_norm": 123.75337219238281,
      "learning_rate": 1.6951807228915663e-05,
      "loss": 0.074,
      "step": 12650
    },
    {
      "epoch": 1.5253012048192771,
      "grad_norm": 11.086738586425781,
      "learning_rate": 1.6949397590361448e-05,
      "loss": 0.091,
      "step": 12660
    },
    {
      "epoch": 1.5265060240963857,
      "grad_norm": 6.84292459487915,
      "learning_rate": 1.694698795180723e-05,
      "loss": 0.0463,
      "step": 12670
    },
    {
      "epoch": 1.527710843373494,
      "grad_norm": 0.10485120117664337,
      "learning_rate": 1.694457831325301e-05,
      "loss": 0.1197,
      "step": 12680
    },
    {
      "epoch": 1.5289156626506024,
      "grad_norm": 0.05031358450651169,
      "learning_rate": 1.6942168674698796e-05,
      "loss": 0.0526,
      "step": 12690
    },
    {
      "epoch": 1.5301204819277108,
      "grad_norm": 0.26838693022727966,
      "learning_rate": 1.693975903614458e-05,
      "loss": 0.0693,
      "step": 12700
    },
    {
      "epoch": 1.5313253012048191,
      "grad_norm": 2.4190738201141357,
      "learning_rate": 1.6937349397590362e-05,
      "loss": 0.0763,
      "step": 12710
    },
    {
      "epoch": 1.5325301204819277,
      "grad_norm": 1.1691311597824097,
      "learning_rate": 1.6934939759036147e-05,
      "loss": 0.0514,
      "step": 12720
    },
    {
      "epoch": 1.5337349397590363,
      "grad_norm": 0.03136692941188812,
      "learning_rate": 1.693253012048193e-05,
      "loss": 0.0421,
      "step": 12730
    },
    {
      "epoch": 1.5349397590361447,
      "grad_norm": 2.633593797683716,
      "learning_rate": 1.6930120481927714e-05,
      "loss": 0.0775,
      "step": 12740
    },
    {
      "epoch": 1.536144578313253,
      "grad_norm": 11.334561347961426,
      "learning_rate": 1.6927710843373495e-05,
      "loss": 0.0322,
      "step": 12750
    },
    {
      "epoch": 1.5373493975903614,
      "grad_norm": 0.05425286293029785,
      "learning_rate": 1.6925301204819277e-05,
      "loss": 0.0634,
      "step": 12760
    },
    {
      "epoch": 1.5385542168674697,
      "grad_norm": 3.6156094074249268,
      "learning_rate": 1.692289156626506e-05,
      "loss": 0.0731,
      "step": 12770
    },
    {
      "epoch": 1.5397590361445783,
      "grad_norm": 0.011782794259488583,
      "learning_rate": 1.6920481927710846e-05,
      "loss": 0.0381,
      "step": 12780
    },
    {
      "epoch": 1.540963855421687,
      "grad_norm": 5.669310569763184,
      "learning_rate": 1.6918072289156628e-05,
      "loss": 0.0737,
      "step": 12790
    },
    {
      "epoch": 1.5421686746987953,
      "grad_norm": 0.7514014840126038,
      "learning_rate": 1.6915662650602413e-05,
      "loss": 0.0783,
      "step": 12800
    },
    {
      "epoch": 1.5433734939759036,
      "grad_norm": 0.20736536383628845,
      "learning_rate": 1.6913253012048194e-05,
      "loss": 0.0532,
      "step": 12810
    },
    {
      "epoch": 1.544578313253012,
      "grad_norm": 1.638587236404419,
      "learning_rate": 1.6910843373493976e-05,
      "loss": 0.0518,
      "step": 12820
    },
    {
      "epoch": 1.5457831325301203,
      "grad_norm": 4.29048490524292,
      "learning_rate": 1.690843373493976e-05,
      "loss": 0.1253,
      "step": 12830
    },
    {
      "epoch": 1.546987951807229,
      "grad_norm": 1.5552581548690796,
      "learning_rate": 1.6906024096385542e-05,
      "loss": 0.0915,
      "step": 12840
    },
    {
      "epoch": 1.5481927710843375,
      "grad_norm": 5.3209333419799805,
      "learning_rate": 1.6903614457831327e-05,
      "loss": 0.0829,
      "step": 12850
    },
    {
      "epoch": 1.5493975903614459,
      "grad_norm": 1.113869309425354,
      "learning_rate": 1.6901204819277112e-05,
      "loss": 0.0937,
      "step": 12860
    },
    {
      "epoch": 1.5506024096385542,
      "grad_norm": 3.8720624446868896,
      "learning_rate": 1.6898795180722893e-05,
      "loss": 0.0687,
      "step": 12870
    },
    {
      "epoch": 1.5518072289156626,
      "grad_norm": 22.951862335205078,
      "learning_rate": 1.6896385542168675e-05,
      "loss": 0.0844,
      "step": 12880
    },
    {
      "epoch": 1.553012048192771,
      "grad_norm": 3.0082712173461914,
      "learning_rate": 1.689397590361446e-05,
      "loss": 0.0616,
      "step": 12890
    },
    {
      "epoch": 1.5542168674698795,
      "grad_norm": 3.243955612182617,
      "learning_rate": 1.689156626506024e-05,
      "loss": 0.0661,
      "step": 12900
    },
    {
      "epoch": 1.555421686746988,
      "grad_norm": 0.20858420431613922,
      "learning_rate": 1.6889156626506026e-05,
      "loss": 0.0528,
      "step": 12910
    },
    {
      "epoch": 1.5566265060240965,
      "grad_norm": 1.6147571802139282,
      "learning_rate": 1.6886746987951807e-05,
      "loss": 0.0453,
      "step": 12920
    },
    {
      "epoch": 1.5578313253012048,
      "grad_norm": 4.669886112213135,
      "learning_rate": 1.6884337349397592e-05,
      "loss": 0.0874,
      "step": 12930
    },
    {
      "epoch": 1.5590361445783132,
      "grad_norm": 5.24944543838501,
      "learning_rate": 1.6881927710843374e-05,
      "loss": 0.0303,
      "step": 12940
    },
    {
      "epoch": 1.5602409638554215,
      "grad_norm": 0.1343710869550705,
      "learning_rate": 1.687951807228916e-05,
      "loss": 0.0287,
      "step": 12950
    },
    {
      "epoch": 1.5614457831325301,
      "grad_norm": 2.1648552417755127,
      "learning_rate": 1.687710843373494e-05,
      "loss": 0.1077,
      "step": 12960
    },
    {
      "epoch": 1.5626506024096387,
      "grad_norm": 8.419516563415527,
      "learning_rate": 1.6874698795180725e-05,
      "loss": 0.091,
      "step": 12970
    },
    {
      "epoch": 1.563855421686747,
      "grad_norm": 3.316210985183716,
      "learning_rate": 1.6872289156626507e-05,
      "loss": 0.0287,
      "step": 12980
    },
    {
      "epoch": 1.5650602409638554,
      "grad_norm": 0.40925878286361694,
      "learning_rate": 1.6869879518072288e-05,
      "loss": 0.0507,
      "step": 12990
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 3.9807486534118652,
      "learning_rate": 1.6867469879518076e-05,
      "loss": 0.0786,
      "step": 13000
    },
    {
      "epoch": 1.5674698795180722,
      "grad_norm": 4.357615947723389,
      "learning_rate": 1.6865060240963858e-05,
      "loss": 0.1247,
      "step": 13010
    },
    {
      "epoch": 1.5686746987951807,
      "grad_norm": 7.736245632171631,
      "learning_rate": 1.686265060240964e-05,
      "loss": 0.0919,
      "step": 13020
    },
    {
      "epoch": 1.5698795180722893,
      "grad_norm": 6.102388381958008,
      "learning_rate": 1.6860240963855424e-05,
      "loss": 0.0686,
      "step": 13030
    },
    {
      "epoch": 1.5710843373493977,
      "grad_norm": 10.576308250427246,
      "learning_rate": 1.6857831325301206e-05,
      "loss": 0.0804,
      "step": 13040
    },
    {
      "epoch": 1.572289156626506,
      "grad_norm": 6.404388904571533,
      "learning_rate": 1.685542168674699e-05,
      "loss": 0.066,
      "step": 13050
    },
    {
      "epoch": 1.5734939759036144,
      "grad_norm": 5.848114013671875,
      "learning_rate": 1.6853012048192772e-05,
      "loss": 0.0688,
      "step": 13060
    },
    {
      "epoch": 1.5746987951807228,
      "grad_norm": 0.3030637204647064,
      "learning_rate": 1.6850602409638553e-05,
      "loss": 0.0501,
      "step": 13070
    },
    {
      "epoch": 1.5759036144578313,
      "grad_norm": 0.4746498465538025,
      "learning_rate": 1.6848192771084338e-05,
      "loss": 0.0659,
      "step": 13080
    },
    {
      "epoch": 1.57710843373494,
      "grad_norm": 4.206905364990234,
      "learning_rate": 1.6845783132530123e-05,
      "loss": 0.0473,
      "step": 13090
    },
    {
      "epoch": 1.5783132530120483,
      "grad_norm": 4.124758243560791,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 0.0653,
      "step": 13100
    },
    {
      "epoch": 1.5795180722891566,
      "grad_norm": 5.351534366607666,
      "learning_rate": 1.684096385542169e-05,
      "loss": 0.0785,
      "step": 13110
    },
    {
      "epoch": 1.580722891566265,
      "grad_norm": 0.14299406111240387,
      "learning_rate": 1.683855421686747e-05,
      "loss": 0.0775,
      "step": 13120
    },
    {
      "epoch": 1.5819277108433734,
      "grad_norm": 1.9990946054458618,
      "learning_rate": 1.6836144578313252e-05,
      "loss": 0.1028,
      "step": 13130
    },
    {
      "epoch": 1.583132530120482,
      "grad_norm": 0.23400519788265228,
      "learning_rate": 1.6833734939759037e-05,
      "loss": 0.053,
      "step": 13140
    },
    {
      "epoch": 1.5843373493975905,
      "grad_norm": 0.3238980174064636,
      "learning_rate": 1.6831325301204822e-05,
      "loss": 0.0504,
      "step": 13150
    },
    {
      "epoch": 1.5855421686746989,
      "grad_norm": 4.0808515548706055,
      "learning_rate": 1.6828915662650604e-05,
      "loss": 0.0671,
      "step": 13160
    },
    {
      "epoch": 1.5867469879518072,
      "grad_norm": 0.3698484003543854,
      "learning_rate": 1.682650602409639e-05,
      "loss": 0.0727,
      "step": 13170
    },
    {
      "epoch": 1.5879518072289156,
      "grad_norm": 9.011415481567383,
      "learning_rate": 1.682409638554217e-05,
      "loss": 0.1631,
      "step": 13180
    },
    {
      "epoch": 1.589156626506024,
      "grad_norm": 3.9218757152557373,
      "learning_rate": 1.682168674698795e-05,
      "loss": 0.0691,
      "step": 13190
    },
    {
      "epoch": 1.5903614457831325,
      "grad_norm": 0.24168594181537628,
      "learning_rate": 1.6819277108433736e-05,
      "loss": 0.0422,
      "step": 13200
    },
    {
      "epoch": 1.5915662650602411,
      "grad_norm": 0.20146161317825317,
      "learning_rate": 1.6816867469879518e-05,
      "loss": 0.0833,
      "step": 13210
    },
    {
      "epoch": 1.5927710843373495,
      "grad_norm": 0.8411107659339905,
      "learning_rate": 1.6814457831325303e-05,
      "loss": 0.0582,
      "step": 13220
    },
    {
      "epoch": 1.5939759036144578,
      "grad_norm": 0.19690881669521332,
      "learning_rate": 1.6812048192771088e-05,
      "loss": 0.0553,
      "step": 13230
    },
    {
      "epoch": 1.5951807228915662,
      "grad_norm": 2.2520341873168945,
      "learning_rate": 1.680963855421687e-05,
      "loss": 0.0649,
      "step": 13240
    },
    {
      "epoch": 1.5963855421686746,
      "grad_norm": 0.3284699618816376,
      "learning_rate": 1.680722891566265e-05,
      "loss": 0.0381,
      "step": 13250
    },
    {
      "epoch": 1.5975903614457831,
      "grad_norm": 6.376334190368652,
      "learning_rate": 1.6804819277108435e-05,
      "loss": 0.0625,
      "step": 13260
    },
    {
      "epoch": 1.5987951807228917,
      "grad_norm": 1.4574376344680786,
      "learning_rate": 1.6802409638554217e-05,
      "loss": 0.104,
      "step": 13270
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.25781288743019104,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0861,
      "step": 13280
    },
    {
      "epoch": 1.6012048192771084,
      "grad_norm": 1.6127723455429077,
      "learning_rate": 1.6797590361445783e-05,
      "loss": 0.0461,
      "step": 13290
    },
    {
      "epoch": 1.6024096385542168,
      "grad_norm": 1.7064279317855835,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 0.0315,
      "step": 13300
    },
    {
      "epoch": 1.6036144578313252,
      "grad_norm": 5.053342342376709,
      "learning_rate": 1.6792771084337353e-05,
      "loss": 0.0383,
      "step": 13310
    },
    {
      "epoch": 1.6048192771084338,
      "grad_norm": 3.0974905490875244,
      "learning_rate": 1.6790361445783134e-05,
      "loss": 0.1066,
      "step": 13320
    },
    {
      "epoch": 1.6060240963855423,
      "grad_norm": 6.582582473754883,
      "learning_rate": 1.6787951807228916e-05,
      "loss": 0.1439,
      "step": 13330
    },
    {
      "epoch": 1.6072289156626507,
      "grad_norm": 1.4426237344741821,
      "learning_rate": 1.67855421686747e-05,
      "loss": 0.1639,
      "step": 13340
    },
    {
      "epoch": 1.608433734939759,
      "grad_norm": 0.21540780365467072,
      "learning_rate": 1.6783132530120482e-05,
      "loss": 0.0588,
      "step": 13350
    },
    {
      "epoch": 1.6096385542168674,
      "grad_norm": 1.0632026195526123,
      "learning_rate": 1.6780722891566267e-05,
      "loss": 0.0368,
      "step": 13360
    },
    {
      "epoch": 1.6108433734939758,
      "grad_norm": 1.1307426691055298,
      "learning_rate": 1.677831325301205e-05,
      "loss": 0.0663,
      "step": 13370
    },
    {
      "epoch": 1.6120481927710844,
      "grad_norm": 0.04327063262462616,
      "learning_rate": 1.6775903614457834e-05,
      "loss": 0.0822,
      "step": 13380
    },
    {
      "epoch": 1.613253012048193,
      "grad_norm": 0.4364815652370453,
      "learning_rate": 1.6773493975903615e-05,
      "loss": 0.0636,
      "step": 13390
    },
    {
      "epoch": 1.6144578313253013,
      "grad_norm": 0.037030115723609924,
      "learning_rate": 1.67710843373494e-05,
      "loss": 0.0882,
      "step": 13400
    },
    {
      "epoch": 1.6156626506024097,
      "grad_norm": 0.16646496951580048,
      "learning_rate": 1.676867469879518e-05,
      "loss": 0.0905,
      "step": 13410
    },
    {
      "epoch": 1.616867469879518,
      "grad_norm": 0.0915549248456955,
      "learning_rate": 1.6766265060240966e-05,
      "loss": 0.0678,
      "step": 13420
    },
    {
      "epoch": 1.6180722891566264,
      "grad_norm": 0.20323270559310913,
      "learning_rate": 1.6763855421686748e-05,
      "loss": 0.0612,
      "step": 13430
    },
    {
      "epoch": 1.619277108433735,
      "grad_norm": 5.613821983337402,
      "learning_rate": 1.676144578313253e-05,
      "loss": 0.0664,
      "step": 13440
    },
    {
      "epoch": 1.6204819277108435,
      "grad_norm": 0.6318565011024475,
      "learning_rate": 1.6759036144578314e-05,
      "loss": 0.0935,
      "step": 13450
    },
    {
      "epoch": 1.621686746987952,
      "grad_norm": 0.1147061437368393,
      "learning_rate": 1.67566265060241e-05,
      "loss": 0.1143,
      "step": 13460
    },
    {
      "epoch": 1.6228915662650603,
      "grad_norm": 0.07428404688835144,
      "learning_rate": 1.675421686746988e-05,
      "loss": 0.1321,
      "step": 13470
    },
    {
      "epoch": 1.6240963855421686,
      "grad_norm": 2.035926580429077,
      "learning_rate": 1.6751807228915665e-05,
      "loss": 0.0592,
      "step": 13480
    },
    {
      "epoch": 1.625301204819277,
      "grad_norm": 0.1995851695537567,
      "learning_rate": 1.6749397590361447e-05,
      "loss": 0.0874,
      "step": 13490
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 14.428844451904297,
      "learning_rate": 1.6746987951807228e-05,
      "loss": 0.1136,
      "step": 13500
    },
    {
      "epoch": 1.627710843373494,
      "grad_norm": 0.29383745789527893,
      "learning_rate": 1.6744578313253013e-05,
      "loss": 0.0787,
      "step": 13510
    },
    {
      "epoch": 1.6289156626506025,
      "grad_norm": 0.2441139817237854,
      "learning_rate": 1.6742168674698795e-05,
      "loss": 0.0325,
      "step": 13520
    },
    {
      "epoch": 1.6301204819277109,
      "grad_norm": 2.5642921924591064,
      "learning_rate": 1.673975903614458e-05,
      "loss": 0.0527,
      "step": 13530
    },
    {
      "epoch": 1.6313253012048192,
      "grad_norm": 6.204094409942627,
      "learning_rate": 1.6737349397590364e-05,
      "loss": 0.1259,
      "step": 13540
    },
    {
      "epoch": 1.6325301204819276,
      "grad_norm": 7.830887317657471,
      "learning_rate": 1.6734939759036146e-05,
      "loss": 0.0695,
      "step": 13550
    },
    {
      "epoch": 1.6337349397590362,
      "grad_norm": 0.626717746257782,
      "learning_rate": 1.673253012048193e-05,
      "loss": 0.0729,
      "step": 13560
    },
    {
      "epoch": 1.6349397590361445,
      "grad_norm": 9.271659851074219,
      "learning_rate": 1.6730120481927712e-05,
      "loss": 0.0771,
      "step": 13570
    },
    {
      "epoch": 1.636144578313253,
      "grad_norm": 1.6213006973266602,
      "learning_rate": 1.6727710843373494e-05,
      "loss": 0.0697,
      "step": 13580
    },
    {
      "epoch": 1.6373493975903615,
      "grad_norm": 0.33737972378730774,
      "learning_rate": 1.672530120481928e-05,
      "loss": 0.087,
      "step": 13590
    },
    {
      "epoch": 1.6385542168674698,
      "grad_norm": 9.13697338104248,
      "learning_rate": 1.6722891566265063e-05,
      "loss": 0.1152,
      "step": 13600
    },
    {
      "epoch": 1.6397590361445782,
      "grad_norm": 3.4084694385528564,
      "learning_rate": 1.6720481927710845e-05,
      "loss": 0.0996,
      "step": 13610
    },
    {
      "epoch": 1.6409638554216868,
      "grad_norm": 15.650063514709473,
      "learning_rate": 1.671807228915663e-05,
      "loss": 0.143,
      "step": 13620
    },
    {
      "epoch": 1.6421686746987951,
      "grad_norm": 9.202043533325195,
      "learning_rate": 1.671566265060241e-05,
      "loss": 0.1582,
      "step": 13630
    },
    {
      "epoch": 1.6433734939759037,
      "grad_norm": 2.4421818256378174,
      "learning_rate": 1.6713253012048193e-05,
      "loss": 0.0639,
      "step": 13640
    },
    {
      "epoch": 1.644578313253012,
      "grad_norm": 0.48750534653663635,
      "learning_rate": 1.6710843373493978e-05,
      "loss": 0.0795,
      "step": 13650
    },
    {
      "epoch": 1.6457831325301204,
      "grad_norm": 16.733543395996094,
      "learning_rate": 1.670843373493976e-05,
      "loss": 0.1217,
      "step": 13660
    },
    {
      "epoch": 1.6469879518072288,
      "grad_norm": 5.048027992248535,
      "learning_rate": 1.6706024096385544e-05,
      "loss": 0.0986,
      "step": 13670
    },
    {
      "epoch": 1.6481927710843374,
      "grad_norm": 3.770998239517212,
      "learning_rate": 1.670361445783133e-05,
      "loss": 0.0927,
      "step": 13680
    },
    {
      "epoch": 1.6493975903614457,
      "grad_norm": 0.1692599207162857,
      "learning_rate": 1.670120481927711e-05,
      "loss": 0.078,
      "step": 13690
    },
    {
      "epoch": 1.6506024096385543,
      "grad_norm": 3.057279586791992,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 0.0616,
      "step": 13700
    },
    {
      "epoch": 1.6518072289156627,
      "grad_norm": 8.989458084106445,
      "learning_rate": 1.6696385542168677e-05,
      "loss": 0.0566,
      "step": 13710
    },
    {
      "epoch": 1.653012048192771,
      "grad_norm": 0.051648881286382675,
      "learning_rate": 1.6693975903614458e-05,
      "loss": 0.0494,
      "step": 13720
    },
    {
      "epoch": 1.6542168674698794,
      "grad_norm": 0.20454281568527222,
      "learning_rate": 1.6691566265060243e-05,
      "loss": 0.0823,
      "step": 13730
    },
    {
      "epoch": 1.655421686746988,
      "grad_norm": 0.26155903935432434,
      "learning_rate": 1.6689156626506024e-05,
      "loss": 0.1379,
      "step": 13740
    },
    {
      "epoch": 1.6566265060240963,
      "grad_norm": 6.508974552154541,
      "learning_rate": 1.668674698795181e-05,
      "loss": 0.0776,
      "step": 13750
    },
    {
      "epoch": 1.657831325301205,
      "grad_norm": 1.3636629581451416,
      "learning_rate": 1.668433734939759e-05,
      "loss": 0.0805,
      "step": 13760
    },
    {
      "epoch": 1.6590361445783133,
      "grad_norm": 0.05688220262527466,
      "learning_rate": 1.6681927710843376e-05,
      "loss": 0.0558,
      "step": 13770
    },
    {
      "epoch": 1.6602409638554216,
      "grad_norm": 0.1770302951335907,
      "learning_rate": 1.6679518072289157e-05,
      "loss": 0.1181,
      "step": 13780
    },
    {
      "epoch": 1.66144578313253,
      "grad_norm": 2.9540581703186035,
      "learning_rate": 1.6677108433734942e-05,
      "loss": 0.0616,
      "step": 13790
    },
    {
      "epoch": 1.6626506024096386,
      "grad_norm": 2.0372228622436523,
      "learning_rate": 1.6674698795180724e-05,
      "loss": 0.0773,
      "step": 13800
    },
    {
      "epoch": 1.663855421686747,
      "grad_norm": 4.812376022338867,
      "learning_rate": 1.6672289156626505e-05,
      "loss": 0.0874,
      "step": 13810
    },
    {
      "epoch": 1.6650602409638555,
      "grad_norm": 3.425070285797119,
      "learning_rate": 1.666987951807229e-05,
      "loss": 0.0543,
      "step": 13820
    },
    {
      "epoch": 1.6662650602409639,
      "grad_norm": 0.6297440528869629,
      "learning_rate": 1.6667469879518075e-05,
      "loss": 0.0783,
      "step": 13830
    },
    {
      "epoch": 1.6674698795180722,
      "grad_norm": 0.6968967914581299,
      "learning_rate": 1.6665060240963856e-05,
      "loss": 0.0101,
      "step": 13840
    },
    {
      "epoch": 1.6686746987951806,
      "grad_norm": 0.016723813489079475,
      "learning_rate": 1.666265060240964e-05,
      "loss": 0.0075,
      "step": 13850
    },
    {
      "epoch": 1.6698795180722892,
      "grad_norm": 0.05505166947841644,
      "learning_rate": 1.6660240963855423e-05,
      "loss": 0.1124,
      "step": 13860
    },
    {
      "epoch": 1.6710843373493975,
      "grad_norm": 5.9693403244018555,
      "learning_rate": 1.6657831325301207e-05,
      "loss": 0.1573,
      "step": 13870
    },
    {
      "epoch": 1.6722891566265061,
      "grad_norm": 2.4470646381378174,
      "learning_rate": 1.665542168674699e-05,
      "loss": 0.0394,
      "step": 13880
    },
    {
      "epoch": 1.6734939759036145,
      "grad_norm": 5.2673115730285645,
      "learning_rate": 1.665301204819277e-05,
      "loss": 0.0725,
      "step": 13890
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 0.21584123373031616,
      "learning_rate": 1.6650602409638555e-05,
      "loss": 0.0125,
      "step": 13900
    },
    {
      "epoch": 1.6759036144578312,
      "grad_norm": 0.2474781572818756,
      "learning_rate": 1.664819277108434e-05,
      "loss": 0.0355,
      "step": 13910
    },
    {
      "epoch": 1.6771084337349398,
      "grad_norm": 2.917908191680908,
      "learning_rate": 1.664578313253012e-05,
      "loss": 0.0907,
      "step": 13920
    },
    {
      "epoch": 1.6783132530120481,
      "grad_norm": 11.635692596435547,
      "learning_rate": 1.6643373493975907e-05,
      "loss": 0.0302,
      "step": 13930
    },
    {
      "epoch": 1.6795180722891567,
      "grad_norm": 2.328367233276367,
      "learning_rate": 1.6640963855421688e-05,
      "loss": 0.0527,
      "step": 13940
    },
    {
      "epoch": 1.680722891566265,
      "grad_norm": 6.727846145629883,
      "learning_rate": 1.663855421686747e-05,
      "loss": 0.1113,
      "step": 13950
    },
    {
      "epoch": 1.6819277108433734,
      "grad_norm": 2.5069518089294434,
      "learning_rate": 1.6636144578313254e-05,
      "loss": 0.0899,
      "step": 13960
    },
    {
      "epoch": 1.6831325301204818,
      "grad_norm": 5.766061782836914,
      "learning_rate": 1.6633734939759036e-05,
      "loss": 0.0622,
      "step": 13970
    },
    {
      "epoch": 1.6843373493975904,
      "grad_norm": 0.17139789462089539,
      "learning_rate": 1.663132530120482e-05,
      "loss": 0.0223,
      "step": 13980
    },
    {
      "epoch": 1.6855421686746987,
      "grad_norm": 6.809627532958984,
      "learning_rate": 1.6628915662650606e-05,
      "loss": 0.089,
      "step": 13990
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 0.455314040184021,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 0.0844,
      "step": 14000
    },
    {
      "epoch": 1.6879518072289157,
      "grad_norm": 0.10203349590301514,
      "learning_rate": 1.662409638554217e-05,
      "loss": 0.0872,
      "step": 14010
    },
    {
      "epoch": 1.689156626506024,
      "grad_norm": 10.690291404724121,
      "learning_rate": 1.6621686746987953e-05,
      "loss": 0.0292,
      "step": 14020
    },
    {
      "epoch": 1.6903614457831324,
      "grad_norm": 4.758925437927246,
      "learning_rate": 1.6619277108433735e-05,
      "loss": 0.1074,
      "step": 14030
    },
    {
      "epoch": 1.691566265060241,
      "grad_norm": 0.9963072538375854,
      "learning_rate": 1.661686746987952e-05,
      "loss": 0.0757,
      "step": 14040
    },
    {
      "epoch": 1.6927710843373494,
      "grad_norm": 0.07613024860620499,
      "learning_rate": 1.6614457831325305e-05,
      "loss": 0.046,
      "step": 14050
    },
    {
      "epoch": 1.693975903614458,
      "grad_norm": 0.17065224051475525,
      "learning_rate": 1.6612048192771086e-05,
      "loss": 0.0809,
      "step": 14060
    },
    {
      "epoch": 1.6951807228915663,
      "grad_norm": 4.089873313903809,
      "learning_rate": 1.6609638554216868e-05,
      "loss": 0.0698,
      "step": 14070
    },
    {
      "epoch": 1.6963855421686747,
      "grad_norm": 5.128570079803467,
      "learning_rate": 1.6607228915662652e-05,
      "loss": 0.038,
      "step": 14080
    },
    {
      "epoch": 1.697590361445783,
      "grad_norm": 0.04680367186665535,
      "learning_rate": 1.6604819277108434e-05,
      "loss": 0.1166,
      "step": 14090
    },
    {
      "epoch": 1.6987951807228916,
      "grad_norm": 7.193185806274414,
      "learning_rate": 1.660240963855422e-05,
      "loss": 0.1118,
      "step": 14100
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.10793986171483994,
      "learning_rate": 1.66e-05,
      "loss": 0.0278,
      "step": 14110
    },
    {
      "epoch": 1.7012048192771085,
      "grad_norm": 0.06903433054685593,
      "learning_rate": 1.6597590361445782e-05,
      "loss": 0.0168,
      "step": 14120
    },
    {
      "epoch": 1.702409638554217,
      "grad_norm": 1.8186166286468506,
      "learning_rate": 1.659518072289157e-05,
      "loss": 0.0878,
      "step": 14130
    },
    {
      "epoch": 1.7036144578313253,
      "grad_norm": 1.6684788465499878,
      "learning_rate": 1.659277108433735e-05,
      "loss": 0.0729,
      "step": 14140
    },
    {
      "epoch": 1.7048192771084336,
      "grad_norm": 0.05931627005338669,
      "learning_rate": 1.6590361445783133e-05,
      "loss": 0.1272,
      "step": 14150
    },
    {
      "epoch": 1.7060240963855422,
      "grad_norm": 22.67268180847168,
      "learning_rate": 1.6587951807228918e-05,
      "loss": 0.0681,
      "step": 14160
    },
    {
      "epoch": 1.7072289156626506,
      "grad_norm": 9.926655769348145,
      "learning_rate": 1.65855421686747e-05,
      "loss": 0.1054,
      "step": 14170
    },
    {
      "epoch": 1.7084337349397591,
      "grad_norm": 1.9439637660980225,
      "learning_rate": 1.6583132530120484e-05,
      "loss": 0.0751,
      "step": 14180
    },
    {
      "epoch": 1.7096385542168675,
      "grad_norm": 5.40836763381958,
      "learning_rate": 1.6580722891566266e-05,
      "loss": 0.0958,
      "step": 14190
    },
    {
      "epoch": 1.7108433734939759,
      "grad_norm": 0.7860438227653503,
      "learning_rate": 1.657831325301205e-05,
      "loss": 0.0508,
      "step": 14200
    },
    {
      "epoch": 1.7120481927710842,
      "grad_norm": 5.8780598640441895,
      "learning_rate": 1.6575903614457832e-05,
      "loss": 0.1086,
      "step": 14210
    },
    {
      "epoch": 1.7132530120481928,
      "grad_norm": 0.07829173654317856,
      "learning_rate": 1.6573493975903617e-05,
      "loss": 0.0506,
      "step": 14220
    },
    {
      "epoch": 1.7144578313253012,
      "grad_norm": 3.1413941383361816,
      "learning_rate": 1.65710843373494e-05,
      "loss": 0.1217,
      "step": 14230
    },
    {
      "epoch": 1.7156626506024097,
      "grad_norm": 1.0762742757797241,
      "learning_rate": 1.6568674698795183e-05,
      "loss": 0.0795,
      "step": 14240
    },
    {
      "epoch": 1.716867469879518,
      "grad_norm": 0.5845896005630493,
      "learning_rate": 1.6566265060240965e-05,
      "loss": 0.0402,
      "step": 14250
    },
    {
      "epoch": 1.7180722891566265,
      "grad_norm": 1.1094188690185547,
      "learning_rate": 1.6563855421686746e-05,
      "loss": 0.0623,
      "step": 14260
    },
    {
      "epoch": 1.7192771084337348,
      "grad_norm": 4.383979320526123,
      "learning_rate": 1.656144578313253e-05,
      "loss": 0.0794,
      "step": 14270
    },
    {
      "epoch": 1.7204819277108434,
      "grad_norm": 3.9322400093078613,
      "learning_rate": 1.6559036144578316e-05,
      "loss": 0.0608,
      "step": 14280
    },
    {
      "epoch": 1.7216867469879518,
      "grad_norm": 2.289661169052124,
      "learning_rate": 1.6556626506024097e-05,
      "loss": 0.0852,
      "step": 14290
    },
    {
      "epoch": 1.7228915662650603,
      "grad_norm": 3.8510282039642334,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 0.0871,
      "step": 14300
    },
    {
      "epoch": 1.7240963855421687,
      "grad_norm": 0.5931698679924011,
      "learning_rate": 1.6551807228915664e-05,
      "loss": 0.0775,
      "step": 14310
    },
    {
      "epoch": 1.725301204819277,
      "grad_norm": 0.1809719055891037,
      "learning_rate": 1.6549397590361445e-05,
      "loss": 0.1446,
      "step": 14320
    },
    {
      "epoch": 1.7265060240963854,
      "grad_norm": 0.15645219385623932,
      "learning_rate": 1.654698795180723e-05,
      "loss": 0.1002,
      "step": 14330
    },
    {
      "epoch": 1.727710843373494,
      "grad_norm": 0.04613589867949486,
      "learning_rate": 1.654457831325301e-05,
      "loss": 0.0454,
      "step": 14340
    },
    {
      "epoch": 1.7289156626506024,
      "grad_norm": 3.5414793491363525,
      "learning_rate": 1.6542168674698797e-05,
      "loss": 0.0443,
      "step": 14350
    },
    {
      "epoch": 1.730120481927711,
      "grad_norm": 0.13410405814647675,
      "learning_rate": 1.653975903614458e-05,
      "loss": 0.0463,
      "step": 14360
    },
    {
      "epoch": 1.7313253012048193,
      "grad_norm": 11.249039649963379,
      "learning_rate": 1.6537349397590363e-05,
      "loss": 0.0624,
      "step": 14370
    },
    {
      "epoch": 1.7325301204819277,
      "grad_norm": 0.15165625512599945,
      "learning_rate": 1.6534939759036144e-05,
      "loss": 0.0666,
      "step": 14380
    },
    {
      "epoch": 1.733734939759036,
      "grad_norm": 0.2193208932876587,
      "learning_rate": 1.653253012048193e-05,
      "loss": 0.0842,
      "step": 14390
    },
    {
      "epoch": 1.7349397590361446,
      "grad_norm": 0.7113955020904541,
      "learning_rate": 1.653012048192771e-05,
      "loss": 0.0562,
      "step": 14400
    },
    {
      "epoch": 1.736144578313253,
      "grad_norm": 0.631679117679596,
      "learning_rate": 1.6527710843373496e-05,
      "loss": 0.128,
      "step": 14410
    },
    {
      "epoch": 1.7373493975903616,
      "grad_norm": 3.2826316356658936,
      "learning_rate": 1.6525301204819277e-05,
      "loss": 0.0928,
      "step": 14420
    },
    {
      "epoch": 1.73855421686747,
      "grad_norm": 0.37450921535491943,
      "learning_rate": 1.6522891566265062e-05,
      "loss": 0.0897,
      "step": 14430
    },
    {
      "epoch": 1.7397590361445783,
      "grad_norm": 0.6631794571876526,
      "learning_rate": 1.6520481927710847e-05,
      "loss": 0.0422,
      "step": 14440
    },
    {
      "epoch": 1.7409638554216866,
      "grad_norm": 3.7423436641693115,
      "learning_rate": 1.6518072289156628e-05,
      "loss": 0.0488,
      "step": 14450
    },
    {
      "epoch": 1.7421686746987952,
      "grad_norm": 3.700316905975342,
      "learning_rate": 1.651566265060241e-05,
      "loss": 0.0752,
      "step": 14460
    },
    {
      "epoch": 1.7433734939759036,
      "grad_norm": 6.789209365844727,
      "learning_rate": 1.6513253012048195e-05,
      "loss": 0.124,
      "step": 14470
    },
    {
      "epoch": 1.7445783132530122,
      "grad_norm": 0.1841401606798172,
      "learning_rate": 1.6510843373493976e-05,
      "loss": 0.0256,
      "step": 14480
    },
    {
      "epoch": 1.7457831325301205,
      "grad_norm": 11.890384674072266,
      "learning_rate": 1.650843373493976e-05,
      "loss": 0.1034,
      "step": 14490
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 4.250010013580322,
      "learning_rate": 1.6506024096385546e-05,
      "loss": 0.092,
      "step": 14500
    },
    {
      "epoch": 1.7481927710843372,
      "grad_norm": 1.2344226837158203,
      "learning_rate": 1.6503614457831327e-05,
      "loss": 0.0624,
      "step": 14510
    },
    {
      "epoch": 1.7493975903614458,
      "grad_norm": 0.6397404670715332,
      "learning_rate": 1.650120481927711e-05,
      "loss": 0.0366,
      "step": 14520
    },
    {
      "epoch": 1.7506024096385542,
      "grad_norm": 3.047595500946045,
      "learning_rate": 1.6498795180722894e-05,
      "loss": 0.072,
      "step": 14530
    },
    {
      "epoch": 1.7518072289156628,
      "grad_norm": 0.10875358432531357,
      "learning_rate": 1.6496385542168675e-05,
      "loss": 0.0551,
      "step": 14540
    },
    {
      "epoch": 1.7530120481927711,
      "grad_norm": 3.2029268741607666,
      "learning_rate": 1.649397590361446e-05,
      "loss": 0.0625,
      "step": 14550
    },
    {
      "epoch": 1.7542168674698795,
      "grad_norm": 0.2854131758213043,
      "learning_rate": 1.649156626506024e-05,
      "loss": 0.0861,
      "step": 14560
    },
    {
      "epoch": 1.7554216867469878,
      "grad_norm": 0.04468623921275139,
      "learning_rate": 1.6489156626506026e-05,
      "loss": 0.0373,
      "step": 14570
    },
    {
      "epoch": 1.7566265060240964,
      "grad_norm": 1.7828913927078247,
      "learning_rate": 1.6486746987951808e-05,
      "loss": 0.079,
      "step": 14580
    },
    {
      "epoch": 1.7578313253012048,
      "grad_norm": 0.07240425795316696,
      "learning_rate": 1.6484337349397593e-05,
      "loss": 0.032,
      "step": 14590
    },
    {
      "epoch": 1.7590361445783134,
      "grad_norm": 9.991131782531738,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 0.0947,
      "step": 14600
    },
    {
      "epoch": 1.7602409638554217,
      "grad_norm": 13.83052921295166,
      "learning_rate": 1.647951807228916e-05,
      "loss": 0.0964,
      "step": 14610
    },
    {
      "epoch": 1.76144578313253,
      "grad_norm": 4.608238220214844,
      "learning_rate": 1.647710843373494e-05,
      "loss": 0.1224,
      "step": 14620
    },
    {
      "epoch": 1.7626506024096384,
      "grad_norm": 0.1925918608903885,
      "learning_rate": 1.6474698795180722e-05,
      "loss": 0.0536,
      "step": 14630
    },
    {
      "epoch": 1.763855421686747,
      "grad_norm": 0.07919827103614807,
      "learning_rate": 1.6472289156626507e-05,
      "loss": 0.0391,
      "step": 14640
    },
    {
      "epoch": 1.7650602409638554,
      "grad_norm": 0.49235478043556213,
      "learning_rate": 1.6469879518072292e-05,
      "loss": 0.0967,
      "step": 14650
    },
    {
      "epoch": 1.766265060240964,
      "grad_norm": 0.3255312144756317,
      "learning_rate": 1.6467469879518073e-05,
      "loss": 0.1344,
      "step": 14660
    },
    {
      "epoch": 1.7674698795180723,
      "grad_norm": 3.779953956604004,
      "learning_rate": 1.6465060240963858e-05,
      "loss": 0.063,
      "step": 14670
    },
    {
      "epoch": 1.7686746987951807,
      "grad_norm": 9.834524154663086,
      "learning_rate": 1.646265060240964e-05,
      "loss": 0.055,
      "step": 14680
    },
    {
      "epoch": 1.769879518072289,
      "grad_norm": 0.09981521219015121,
      "learning_rate": 1.646024096385542e-05,
      "loss": 0.0539,
      "step": 14690
    },
    {
      "epoch": 1.7710843373493976,
      "grad_norm": 0.3138377070426941,
      "learning_rate": 1.6457831325301206e-05,
      "loss": 0.0902,
      "step": 14700
    },
    {
      "epoch": 1.772289156626506,
      "grad_norm": 7.954098701477051,
      "learning_rate": 1.6455421686746987e-05,
      "loss": 0.0789,
      "step": 14710
    },
    {
      "epoch": 1.7734939759036146,
      "grad_norm": 30.281293869018555,
      "learning_rate": 1.6453012048192772e-05,
      "loss": 0.0855,
      "step": 14720
    },
    {
      "epoch": 1.774698795180723,
      "grad_norm": 0.13499797880649567,
      "learning_rate": 1.6450602409638557e-05,
      "loss": 0.0333,
      "step": 14730
    },
    {
      "epoch": 1.7759036144578313,
      "grad_norm": 3.676572561264038,
      "learning_rate": 1.644819277108434e-05,
      "loss": 0.0503,
      "step": 14740
    },
    {
      "epoch": 1.7771084337349397,
      "grad_norm": 22.2451171875,
      "learning_rate": 1.6445783132530124e-05,
      "loss": 0.0846,
      "step": 14750
    },
    {
      "epoch": 1.7783132530120482,
      "grad_norm": 3.9520206451416016,
      "learning_rate": 1.6443373493975905e-05,
      "loss": 0.0755,
      "step": 14760
    },
    {
      "epoch": 1.7795180722891566,
      "grad_norm": 0.14648528397083282,
      "learning_rate": 1.6440963855421687e-05,
      "loss": 0.0793,
      "step": 14770
    },
    {
      "epoch": 1.7807228915662652,
      "grad_norm": 0.02291901782155037,
      "learning_rate": 1.643855421686747e-05,
      "loss": 0.0622,
      "step": 14780
    },
    {
      "epoch": 1.7819277108433735,
      "grad_norm": 0.15283529460430145,
      "learning_rate": 1.6436144578313253e-05,
      "loss": 0.0748,
      "step": 14790
    },
    {
      "epoch": 1.783132530120482,
      "grad_norm": 0.03682299330830574,
      "learning_rate": 1.6433734939759038e-05,
      "loss": 0.0668,
      "step": 14800
    },
    {
      "epoch": 1.7843373493975903,
      "grad_norm": 4.746846675872803,
      "learning_rate": 1.6431325301204823e-05,
      "loss": 0.0954,
      "step": 14810
    },
    {
      "epoch": 1.7855421686746988,
      "grad_norm": 0.5207772850990295,
      "learning_rate": 1.6428915662650604e-05,
      "loss": 0.0834,
      "step": 14820
    },
    {
      "epoch": 1.7867469879518072,
      "grad_norm": 7.30808687210083,
      "learning_rate": 1.6426506024096386e-05,
      "loss": 0.1423,
      "step": 14830
    },
    {
      "epoch": 1.7879518072289158,
      "grad_norm": 0.09678108245134354,
      "learning_rate": 1.642409638554217e-05,
      "loss": 0.0677,
      "step": 14840
    },
    {
      "epoch": 1.7891566265060241,
      "grad_norm": 2.4179601669311523,
      "learning_rate": 1.6421686746987952e-05,
      "loss": 0.1182,
      "step": 14850
    },
    {
      "epoch": 1.7903614457831325,
      "grad_norm": 4.438666820526123,
      "learning_rate": 1.6419277108433737e-05,
      "loss": 0.0689,
      "step": 14860
    },
    {
      "epoch": 1.7915662650602409,
      "grad_norm": 0.5142262578010559,
      "learning_rate": 1.641686746987952e-05,
      "loss": 0.0353,
      "step": 14870
    },
    {
      "epoch": 1.7927710843373494,
      "grad_norm": 10.801344871520996,
      "learning_rate": 1.6414457831325303e-05,
      "loss": 0.0577,
      "step": 14880
    },
    {
      "epoch": 1.7939759036144578,
      "grad_norm": 6.639082908630371,
      "learning_rate": 1.6412048192771085e-05,
      "loss": 0.0443,
      "step": 14890
    },
    {
      "epoch": 1.7951807228915664,
      "grad_norm": 7.765749931335449,
      "learning_rate": 1.640963855421687e-05,
      "loss": 0.1155,
      "step": 14900
    },
    {
      "epoch": 1.7963855421686747,
      "grad_norm": 3.613060235977173,
      "learning_rate": 1.640722891566265e-05,
      "loss": 0.054,
      "step": 14910
    },
    {
      "epoch": 1.797590361445783,
      "grad_norm": 9.566155433654785,
      "learning_rate": 1.6404819277108436e-05,
      "loss": 0.0833,
      "step": 14920
    },
    {
      "epoch": 1.7987951807228915,
      "grad_norm": 1.0197033882141113,
      "learning_rate": 1.6402409638554217e-05,
      "loss": 0.093,
      "step": 14930
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.330169200897217,
      "learning_rate": 1.64e-05,
      "loss": 0.1056,
      "step": 14940
    },
    {
      "epoch": 1.8012048192771084,
      "grad_norm": 2.914114236831665,
      "learning_rate": 1.6397590361445787e-05,
      "loss": 0.0641,
      "step": 14950
    },
    {
      "epoch": 1.802409638554217,
      "grad_norm": 10.139073371887207,
      "learning_rate": 1.639518072289157e-05,
      "loss": 0.1025,
      "step": 14960
    },
    {
      "epoch": 1.8036144578313253,
      "grad_norm": 18.445829391479492,
      "learning_rate": 1.639277108433735e-05,
      "loss": 0.111,
      "step": 14970
    },
    {
      "epoch": 1.8048192771084337,
      "grad_norm": 6.633126258850098,
      "learning_rate": 1.6390361445783135e-05,
      "loss": 0.0858,
      "step": 14980
    },
    {
      "epoch": 1.806024096385542,
      "grad_norm": 2.9011144638061523,
      "learning_rate": 1.6387951807228916e-05,
      "loss": 0.154,
      "step": 14990
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 7.996298313140869,
      "learning_rate": 1.63855421686747e-05,
      "loss": 0.0685,
      "step": 15000
    },
    {
      "epoch": 1.808433734939759,
      "grad_norm": 0.11889748275279999,
      "learning_rate": 1.6383132530120483e-05,
      "loss": 0.0355,
      "step": 15010
    },
    {
      "epoch": 1.8096385542168676,
      "grad_norm": 0.025212807580828667,
      "learning_rate": 1.6380722891566268e-05,
      "loss": 0.0601,
      "step": 15020
    },
    {
      "epoch": 1.810843373493976,
      "grad_norm": 2.116569995880127,
      "learning_rate": 1.637831325301205e-05,
      "loss": 0.0817,
      "step": 15030
    },
    {
      "epoch": 1.8120481927710843,
      "grad_norm": 0.2564341425895691,
      "learning_rate": 1.6375903614457834e-05,
      "loss": 0.0518,
      "step": 15040
    },
    {
      "epoch": 1.8132530120481927,
      "grad_norm": 7.812623977661133,
      "learning_rate": 1.6373493975903615e-05,
      "loss": 0.0418,
      "step": 15050
    },
    {
      "epoch": 1.8144578313253013,
      "grad_norm": 5.611397743225098,
      "learning_rate": 1.63710843373494e-05,
      "loss": 0.1526,
      "step": 15060
    },
    {
      "epoch": 1.8156626506024096,
      "grad_norm": 0.021816231310367584,
      "learning_rate": 1.6368674698795182e-05,
      "loss": 0.0595,
      "step": 15070
    },
    {
      "epoch": 1.8168674698795182,
      "grad_norm": 0.13816498219966888,
      "learning_rate": 1.6366265060240963e-05,
      "loss": 0.1372,
      "step": 15080
    },
    {
      "epoch": 1.8180722891566266,
      "grad_norm": 2.4649572372436523,
      "learning_rate": 1.6363855421686748e-05,
      "loss": 0.1145,
      "step": 15090
    },
    {
      "epoch": 1.819277108433735,
      "grad_norm": 1.722196340560913,
      "learning_rate": 1.6361445783132533e-05,
      "loss": 0.0606,
      "step": 15100
    },
    {
      "epoch": 1.8204819277108433,
      "grad_norm": 0.27362060546875,
      "learning_rate": 1.6359036144578315e-05,
      "loss": 0.071,
      "step": 15110
    },
    {
      "epoch": 1.8216867469879519,
      "grad_norm": 0.8320385813713074,
      "learning_rate": 1.63566265060241e-05,
      "loss": 0.0989,
      "step": 15120
    },
    {
      "epoch": 1.8228915662650602,
      "grad_norm": 2.595252275466919,
      "learning_rate": 1.635421686746988e-05,
      "loss": 0.0631,
      "step": 15130
    },
    {
      "epoch": 1.8240963855421688,
      "grad_norm": 0.3670045733451843,
      "learning_rate": 1.6351807228915662e-05,
      "loss": 0.0899,
      "step": 15140
    },
    {
      "epoch": 1.8253012048192772,
      "grad_norm": 26.868757247924805,
      "learning_rate": 1.6349397590361447e-05,
      "loss": 0.1143,
      "step": 15150
    },
    {
      "epoch": 1.8265060240963855,
      "grad_norm": 7.434516429901123,
      "learning_rate": 1.634698795180723e-05,
      "loss": 0.1156,
      "step": 15160
    },
    {
      "epoch": 1.8277108433734939,
      "grad_norm": 4.177367210388184,
      "learning_rate": 1.6344578313253014e-05,
      "loss": 0.0749,
      "step": 15170
    },
    {
      "epoch": 1.8289156626506025,
      "grad_norm": 0.39963605999946594,
      "learning_rate": 1.63421686746988e-05,
      "loss": 0.096,
      "step": 15180
    },
    {
      "epoch": 1.8301204819277108,
      "grad_norm": 0.9698058366775513,
      "learning_rate": 1.633975903614458e-05,
      "loss": 0.0727,
      "step": 15190
    },
    {
      "epoch": 1.8313253012048194,
      "grad_norm": 18.188873291015625,
      "learning_rate": 1.633734939759036e-05,
      "loss": 0.068,
      "step": 15200
    },
    {
      "epoch": 1.8325301204819278,
      "grad_norm": 4.230307579040527,
      "learning_rate": 1.6334939759036146e-05,
      "loss": 0.0769,
      "step": 15210
    },
    {
      "epoch": 1.8337349397590361,
      "grad_norm": 0.7571471333503723,
      "learning_rate": 1.6332530120481928e-05,
      "loss": 0.0967,
      "step": 15220
    },
    {
      "epoch": 1.8349397590361445,
      "grad_norm": 0.1554735153913498,
      "learning_rate": 1.6330120481927713e-05,
      "loss": 0.1046,
      "step": 15230
    },
    {
      "epoch": 1.836144578313253,
      "grad_norm": 0.1418178230524063,
      "learning_rate": 1.6327710843373494e-05,
      "loss": 0.0347,
      "step": 15240
    },
    {
      "epoch": 1.8373493975903614,
      "grad_norm": 0.3395627737045288,
      "learning_rate": 1.632530120481928e-05,
      "loss": 0.0868,
      "step": 15250
    },
    {
      "epoch": 1.83855421686747,
      "grad_norm": 0.10201537609100342,
      "learning_rate": 1.6322891566265064e-05,
      "loss": 0.0947,
      "step": 15260
    },
    {
      "epoch": 1.8397590361445784,
      "grad_norm": 1.5694447755813599,
      "learning_rate": 1.6320481927710845e-05,
      "loss": 0.094,
      "step": 15270
    },
    {
      "epoch": 1.8409638554216867,
      "grad_norm": 5.236122131347656,
      "learning_rate": 1.6318072289156627e-05,
      "loss": 0.0364,
      "step": 15280
    },
    {
      "epoch": 1.842168674698795,
      "grad_norm": 0.3577708899974823,
      "learning_rate": 1.631566265060241e-05,
      "loss": 0.0646,
      "step": 15290
    },
    {
      "epoch": 1.8433734939759037,
      "grad_norm": 5.3803558349609375,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 0.0703,
      "step": 15300
    },
    {
      "epoch": 1.844578313253012,
      "grad_norm": 0.03434198349714279,
      "learning_rate": 1.6310843373493978e-05,
      "loss": 0.0339,
      "step": 15310
    },
    {
      "epoch": 1.8457831325301206,
      "grad_norm": 5.651098728179932,
      "learning_rate": 1.6308433734939763e-05,
      "loss": 0.1636,
      "step": 15320
    },
    {
      "epoch": 1.846987951807229,
      "grad_norm": 0.390089750289917,
      "learning_rate": 1.6306024096385544e-05,
      "loss": 0.0619,
      "step": 15330
    },
    {
      "epoch": 1.8481927710843373,
      "grad_norm": 4.810710430145264,
      "learning_rate": 1.6303614457831326e-05,
      "loss": 0.056,
      "step": 15340
    },
    {
      "epoch": 1.8493975903614457,
      "grad_norm": 2.814389228820801,
      "learning_rate": 1.630120481927711e-05,
      "loss": 0.0338,
      "step": 15350
    },
    {
      "epoch": 1.8506024096385543,
      "grad_norm": 0.020542383193969727,
      "learning_rate": 1.6298795180722892e-05,
      "loss": 0.0594,
      "step": 15360
    },
    {
      "epoch": 1.8518072289156626,
      "grad_norm": 0.22032685577869415,
      "learning_rate": 1.6296385542168677e-05,
      "loss": 0.0926,
      "step": 15370
    },
    {
      "epoch": 1.8530120481927712,
      "grad_norm": 20.822185516357422,
      "learning_rate": 1.629397590361446e-05,
      "loss": 0.1257,
      "step": 15380
    },
    {
      "epoch": 1.8542168674698796,
      "grad_norm": 15.760704040527344,
      "learning_rate": 1.629156626506024e-05,
      "loss": 0.0626,
      "step": 15390
    },
    {
      "epoch": 1.855421686746988,
      "grad_norm": 5.705381870269775,
      "learning_rate": 1.6289156626506025e-05,
      "loss": 0.0809,
      "step": 15400
    },
    {
      "epoch": 1.8566265060240963,
      "grad_norm": 1.5144033432006836,
      "learning_rate": 1.628674698795181e-05,
      "loss": 0.1354,
      "step": 15410
    },
    {
      "epoch": 1.8578313253012049,
      "grad_norm": 0.08624941110610962,
      "learning_rate": 1.628433734939759e-05,
      "loss": 0.103,
      "step": 15420
    },
    {
      "epoch": 1.8590361445783132,
      "grad_norm": 0.1393124759197235,
      "learning_rate": 1.6281927710843376e-05,
      "loss": 0.0809,
      "step": 15430
    },
    {
      "epoch": 1.8602409638554218,
      "grad_norm": 0.12844812870025635,
      "learning_rate": 1.6279518072289158e-05,
      "loss": 0.0436,
      "step": 15440
    },
    {
      "epoch": 1.8614457831325302,
      "grad_norm": 2.9939746856689453,
      "learning_rate": 1.627710843373494e-05,
      "loss": 0.0825,
      "step": 15450
    },
    {
      "epoch": 1.8626506024096385,
      "grad_norm": 3.2229013442993164,
      "learning_rate": 1.6274698795180724e-05,
      "loss": 0.0549,
      "step": 15460
    },
    {
      "epoch": 1.863855421686747,
      "grad_norm": 8.362516403198242,
      "learning_rate": 1.627228915662651e-05,
      "loss": 0.1912,
      "step": 15470
    },
    {
      "epoch": 1.8650602409638555,
      "grad_norm": 0.0893692597746849,
      "learning_rate": 1.626987951807229e-05,
      "loss": 0.0273,
      "step": 15480
    },
    {
      "epoch": 1.8662650602409638,
      "grad_norm": 7.213836669921875,
      "learning_rate": 1.6267469879518075e-05,
      "loss": 0.0526,
      "step": 15490
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 9.572181701660156,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 0.0768,
      "step": 15500
    },
    {
      "epoch": 1.8686746987951808,
      "grad_norm": 0.49679380655288696,
      "learning_rate": 1.6262650602409638e-05,
      "loss": 0.0805,
      "step": 15510
    },
    {
      "epoch": 1.8698795180722891,
      "grad_norm": 4.252769470214844,
      "learning_rate": 1.6260240963855423e-05,
      "loss": 0.0591,
      "step": 15520
    },
    {
      "epoch": 1.8710843373493975,
      "grad_norm": 1.935452938079834,
      "learning_rate": 1.6257831325301205e-05,
      "loss": 0.195,
      "step": 15530
    },
    {
      "epoch": 1.872289156626506,
      "grad_norm": 6.336263179779053,
      "learning_rate": 1.625542168674699e-05,
      "loss": 0.1298,
      "step": 15540
    },
    {
      "epoch": 1.8734939759036144,
      "grad_norm": 5.382197380065918,
      "learning_rate": 1.6253012048192774e-05,
      "loss": 0.0316,
      "step": 15550
    },
    {
      "epoch": 1.874698795180723,
      "grad_norm": 0.28675201535224915,
      "learning_rate": 1.6250602409638556e-05,
      "loss": 0.1504,
      "step": 15560
    },
    {
      "epoch": 1.8759036144578314,
      "grad_norm": 3.98149037361145,
      "learning_rate": 1.624819277108434e-05,
      "loss": 0.0828,
      "step": 15570
    },
    {
      "epoch": 1.8771084337349397,
      "grad_norm": 0.25610750913619995,
      "learning_rate": 1.6245783132530122e-05,
      "loss": 0.0814,
      "step": 15580
    },
    {
      "epoch": 1.878313253012048,
      "grad_norm": 2.412919044494629,
      "learning_rate": 1.6243373493975904e-05,
      "loss": 0.072,
      "step": 15590
    },
    {
      "epoch": 1.8795180722891565,
      "grad_norm": 0.3739004135131836,
      "learning_rate": 1.624096385542169e-05,
      "loss": 0.0448,
      "step": 15600
    },
    {
      "epoch": 1.880722891566265,
      "grad_norm": 3.6758971214294434,
      "learning_rate": 1.623855421686747e-05,
      "loss": 0.0879,
      "step": 15610
    },
    {
      "epoch": 1.8819277108433736,
      "grad_norm": 0.1980297863483429,
      "learning_rate": 1.6236144578313255e-05,
      "loss": 0.1111,
      "step": 15620
    },
    {
      "epoch": 1.883132530120482,
      "grad_norm": 20.984498977661133,
      "learning_rate": 1.623373493975904e-05,
      "loss": 0.0706,
      "step": 15630
    },
    {
      "epoch": 1.8843373493975903,
      "grad_norm": 4.792043209075928,
      "learning_rate": 1.623132530120482e-05,
      "loss": 0.0417,
      "step": 15640
    },
    {
      "epoch": 1.8855421686746987,
      "grad_norm": 3.025284767150879,
      "learning_rate": 1.6228915662650603e-05,
      "loss": 0.0398,
      "step": 15650
    },
    {
      "epoch": 1.886746987951807,
      "grad_norm": 11.324630737304688,
      "learning_rate": 1.6226506024096388e-05,
      "loss": 0.0626,
      "step": 15660
    },
    {
      "epoch": 1.8879518072289156,
      "grad_norm": 0.11353244632482529,
      "learning_rate": 1.622409638554217e-05,
      "loss": 0.0914,
      "step": 15670
    },
    {
      "epoch": 1.8891566265060242,
      "grad_norm": 2.0579240322113037,
      "learning_rate": 1.6221686746987954e-05,
      "loss": 0.0978,
      "step": 15680
    },
    {
      "epoch": 1.8903614457831326,
      "grad_norm": 0.6000937819480896,
      "learning_rate": 1.6219277108433735e-05,
      "loss": 0.1001,
      "step": 15690
    },
    {
      "epoch": 1.891566265060241,
      "grad_norm": 4.236623287200928,
      "learning_rate": 1.621686746987952e-05,
      "loss": 0.057,
      "step": 15700
    },
    {
      "epoch": 1.8927710843373493,
      "grad_norm": 0.0375027097761631,
      "learning_rate": 1.62144578313253e-05,
      "loss": 0.0323,
      "step": 15710
    },
    {
      "epoch": 1.8939759036144577,
      "grad_norm": 15.597602844238281,
      "learning_rate": 1.6212048192771087e-05,
      "loss": 0.0742,
      "step": 15720
    },
    {
      "epoch": 1.8951807228915662,
      "grad_norm": 2.6616594791412354,
      "learning_rate": 1.6209638554216868e-05,
      "loss": 0.0955,
      "step": 15730
    },
    {
      "epoch": 1.8963855421686748,
      "grad_norm": 0.4151332676410675,
      "learning_rate": 1.6207228915662653e-05,
      "loss": 0.0817,
      "step": 15740
    },
    {
      "epoch": 1.8975903614457832,
      "grad_norm": 11.601344108581543,
      "learning_rate": 1.6204819277108434e-05,
      "loss": 0.0683,
      "step": 15750
    },
    {
      "epoch": 1.8987951807228916,
      "grad_norm": 8.413119316101074,
      "learning_rate": 1.6202409638554216e-05,
      "loss": 0.0663,
      "step": 15760
    },
    {
      "epoch": 1.9,
      "grad_norm": 5.790400981903076,
      "learning_rate": 1.62e-05,
      "loss": 0.0366,
      "step": 15770
    },
    {
      "epoch": 1.9012048192771083,
      "grad_norm": 0.035198062658309937,
      "learning_rate": 1.6197590361445786e-05,
      "loss": 0.0977,
      "step": 15780
    },
    {
      "epoch": 1.9024096385542169,
      "grad_norm": 2.7489163875579834,
      "learning_rate": 1.6195180722891567e-05,
      "loss": 0.0474,
      "step": 15790
    },
    {
      "epoch": 1.9036144578313254,
      "grad_norm": 1.0744667053222656,
      "learning_rate": 1.6192771084337352e-05,
      "loss": 0.0613,
      "step": 15800
    },
    {
      "epoch": 1.9048192771084338,
      "grad_norm": 7.306344985961914,
      "learning_rate": 1.6190361445783133e-05,
      "loss": 0.1281,
      "step": 15810
    },
    {
      "epoch": 1.9060240963855422,
      "grad_norm": 0.25799375772476196,
      "learning_rate": 1.6187951807228915e-05,
      "loss": 0.0941,
      "step": 15820
    },
    {
      "epoch": 1.9072289156626505,
      "grad_norm": 8.873872756958008,
      "learning_rate": 1.61855421686747e-05,
      "loss": 0.1498,
      "step": 15830
    },
    {
      "epoch": 1.9084337349397589,
      "grad_norm": 0.21014617383480072,
      "learning_rate": 1.618313253012048e-05,
      "loss": 0.0816,
      "step": 15840
    },
    {
      "epoch": 1.9096385542168675,
      "grad_norm": 0.4398331642150879,
      "learning_rate": 1.6180722891566266e-05,
      "loss": 0.0553,
      "step": 15850
    },
    {
      "epoch": 1.910843373493976,
      "grad_norm": 2.4837801456451416,
      "learning_rate": 1.617831325301205e-05,
      "loss": 0.0224,
      "step": 15860
    },
    {
      "epoch": 1.9120481927710844,
      "grad_norm": 0.239778533577919,
      "learning_rate": 1.6175903614457833e-05,
      "loss": 0.0151,
      "step": 15870
    },
    {
      "epoch": 1.9132530120481928,
      "grad_norm": 8.108928680419922,
      "learning_rate": 1.6173493975903617e-05,
      "loss": 0.0789,
      "step": 15880
    },
    {
      "epoch": 1.9144578313253011,
      "grad_norm": 2.1520726680755615,
      "learning_rate": 1.61710843373494e-05,
      "loss": 0.0688,
      "step": 15890
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 0.22419977188110352,
      "learning_rate": 1.616867469879518e-05,
      "loss": 0.1206,
      "step": 15900
    },
    {
      "epoch": 1.916867469879518,
      "grad_norm": 8.275468826293945,
      "learning_rate": 1.6166265060240965e-05,
      "loss": 0.0732,
      "step": 15910
    },
    {
      "epoch": 1.9180722891566266,
      "grad_norm": 0.7648126482963562,
      "learning_rate": 1.616385542168675e-05,
      "loss": 0.0423,
      "step": 15920
    },
    {
      "epoch": 1.919277108433735,
      "grad_norm": 3.8686277866363525,
      "learning_rate": 1.616144578313253e-05,
      "loss": 0.0974,
      "step": 15930
    },
    {
      "epoch": 1.9204819277108434,
      "grad_norm": 0.04519844800233841,
      "learning_rate": 1.6159036144578316e-05,
      "loss": 0.0449,
      "step": 15940
    },
    {
      "epoch": 1.9216867469879517,
      "grad_norm": 2.14416766166687,
      "learning_rate": 1.6156626506024098e-05,
      "loss": 0.0665,
      "step": 15950
    },
    {
      "epoch": 1.92289156626506,
      "grad_norm": 3.641796588897705,
      "learning_rate": 1.615421686746988e-05,
      "loss": 0.0884,
      "step": 15960
    },
    {
      "epoch": 1.9240963855421687,
      "grad_norm": 0.2865879535675049,
      "learning_rate": 1.6151807228915664e-05,
      "loss": 0.0624,
      "step": 15970
    },
    {
      "epoch": 1.9253012048192772,
      "grad_norm": 0.5616724491119385,
      "learning_rate": 1.6149397590361446e-05,
      "loss": 0.0388,
      "step": 15980
    },
    {
      "epoch": 1.9265060240963856,
      "grad_norm": 1.416289210319519,
      "learning_rate": 1.614698795180723e-05,
      "loss": 0.0962,
      "step": 15990
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 1.7061493396759033,
      "learning_rate": 1.6144578313253015e-05,
      "loss": 0.0641,
      "step": 16000
    },
    {
      "epoch": 1.9289156626506023,
      "grad_norm": 1.8161650896072388,
      "learning_rate": 1.6142168674698797e-05,
      "loss": 0.0434,
      "step": 16010
    },
    {
      "epoch": 1.9301204819277107,
      "grad_norm": 19.73696517944336,
      "learning_rate": 1.613975903614458e-05,
      "loss": 0.0898,
      "step": 16020
    },
    {
      "epoch": 1.9313253012048193,
      "grad_norm": 0.15829725563526154,
      "learning_rate": 1.6137349397590363e-05,
      "loss": 0.0428,
      "step": 16030
    },
    {
      "epoch": 1.9325301204819278,
      "grad_norm": 3.0166075229644775,
      "learning_rate": 1.6134939759036145e-05,
      "loss": 0.1007,
      "step": 16040
    },
    {
      "epoch": 1.9337349397590362,
      "grad_norm": 4.24673318862915,
      "learning_rate": 1.613253012048193e-05,
      "loss": 0.0818,
      "step": 16050
    },
    {
      "epoch": 1.9349397590361446,
      "grad_norm": 0.7669507265090942,
      "learning_rate": 1.613012048192771e-05,
      "loss": 0.0503,
      "step": 16060
    },
    {
      "epoch": 1.936144578313253,
      "grad_norm": 0.9436185956001282,
      "learning_rate": 1.6127710843373496e-05,
      "loss": 0.0325,
      "step": 16070
    },
    {
      "epoch": 1.9373493975903613,
      "grad_norm": 14.429661750793457,
      "learning_rate": 1.6125301204819278e-05,
      "loss": 0.0786,
      "step": 16080
    },
    {
      "epoch": 1.9385542168674699,
      "grad_norm": 5.204189777374268,
      "learning_rate": 1.6122891566265062e-05,
      "loss": 0.0972,
      "step": 16090
    },
    {
      "epoch": 1.9397590361445785,
      "grad_norm": 16.291799545288086,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 0.0871,
      "step": 16100
    },
    {
      "epoch": 1.9409638554216868,
      "grad_norm": 0.2870100438594818,
      "learning_rate": 1.611807228915663e-05,
      "loss": 0.1084,
      "step": 16110
    },
    {
      "epoch": 1.9421686746987952,
      "grad_norm": 0.10929440706968307,
      "learning_rate": 1.611566265060241e-05,
      "loss": 0.0741,
      "step": 16120
    },
    {
      "epoch": 1.9433734939759035,
      "grad_norm": 9.577266693115234,
      "learning_rate": 1.6113253012048192e-05,
      "loss": 0.1431,
      "step": 16130
    },
    {
      "epoch": 1.944578313253012,
      "grad_norm": 0.24372082948684692,
      "learning_rate": 1.6110843373493977e-05,
      "loss": 0.0687,
      "step": 16140
    },
    {
      "epoch": 1.9457831325301205,
      "grad_norm": 0.7012042999267578,
      "learning_rate": 1.610843373493976e-05,
      "loss": 0.0561,
      "step": 16150
    },
    {
      "epoch": 1.946987951807229,
      "grad_norm": 6.695638179779053,
      "learning_rate": 1.6106024096385543e-05,
      "loss": 0.0483,
      "step": 16160
    },
    {
      "epoch": 1.9481927710843374,
      "grad_norm": 0.12287309765815735,
      "learning_rate": 1.6103614457831328e-05,
      "loss": 0.1216,
      "step": 16170
    },
    {
      "epoch": 1.9493975903614458,
      "grad_norm": 5.805700302124023,
      "learning_rate": 1.610120481927711e-05,
      "loss": 0.1122,
      "step": 16180
    },
    {
      "epoch": 1.9506024096385541,
      "grad_norm": 5.066317558288574,
      "learning_rate": 1.6098795180722894e-05,
      "loss": 0.08,
      "step": 16190
    },
    {
      "epoch": 1.9518072289156625,
      "grad_norm": 3.0329902172088623,
      "learning_rate": 1.6096385542168676e-05,
      "loss": 0.0777,
      "step": 16200
    },
    {
      "epoch": 1.953012048192771,
      "grad_norm": 0.2732606530189514,
      "learning_rate": 1.6093975903614457e-05,
      "loss": 0.0939,
      "step": 16210
    },
    {
      "epoch": 1.9542168674698797,
      "grad_norm": 2.8958518505096436,
      "learning_rate": 1.6091566265060242e-05,
      "loss": 0.0663,
      "step": 16220
    },
    {
      "epoch": 1.955421686746988,
      "grad_norm": 0.21945978701114655,
      "learning_rate": 1.6089156626506027e-05,
      "loss": 0.0968,
      "step": 16230
    },
    {
      "epoch": 1.9566265060240964,
      "grad_norm": 0.055775463581085205,
      "learning_rate": 1.608674698795181e-05,
      "loss": 0.0466,
      "step": 16240
    },
    {
      "epoch": 1.9578313253012047,
      "grad_norm": 23.608678817749023,
      "learning_rate": 1.6084337349397593e-05,
      "loss": 0.1432,
      "step": 16250
    },
    {
      "epoch": 1.959036144578313,
      "grad_norm": 3.3366050720214844,
      "learning_rate": 1.6081927710843375e-05,
      "loss": 0.0993,
      "step": 16260
    },
    {
      "epoch": 1.9602409638554217,
      "grad_norm": 0.35025453567504883,
      "learning_rate": 1.6079518072289156e-05,
      "loss": 0.0551,
      "step": 16270
    },
    {
      "epoch": 1.9614457831325303,
      "grad_norm": 6.2322611808776855,
      "learning_rate": 1.607710843373494e-05,
      "loss": 0.0712,
      "step": 16280
    },
    {
      "epoch": 1.9626506024096386,
      "grad_norm": 3.5590484142303467,
      "learning_rate": 1.6074698795180723e-05,
      "loss": 0.0594,
      "step": 16290
    },
    {
      "epoch": 1.963855421686747,
      "grad_norm": 4.358703136444092,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 0.0749,
      "step": 16300
    },
    {
      "epoch": 1.9650602409638553,
      "grad_norm": 0.10526856780052185,
      "learning_rate": 1.6069879518072292e-05,
      "loss": 0.0366,
      "step": 16310
    },
    {
      "epoch": 1.9662650602409637,
      "grad_norm": 0.7245928645133972,
      "learning_rate": 1.6067469879518074e-05,
      "loss": 0.0402,
      "step": 16320
    },
    {
      "epoch": 1.9674698795180723,
      "grad_norm": 0.27162498235702515,
      "learning_rate": 1.6065060240963855e-05,
      "loss": 0.0677,
      "step": 16330
    },
    {
      "epoch": 1.9686746987951809,
      "grad_norm": 0.2850651144981384,
      "learning_rate": 1.606265060240964e-05,
      "loss": 0.0913,
      "step": 16340
    },
    {
      "epoch": 1.9698795180722892,
      "grad_norm": 0.42854827642440796,
      "learning_rate": 1.606024096385542e-05,
      "loss": 0.0636,
      "step": 16350
    },
    {
      "epoch": 1.9710843373493976,
      "grad_norm": 3.2350945472717285,
      "learning_rate": 1.6057831325301206e-05,
      "loss": 0.0438,
      "step": 16360
    },
    {
      "epoch": 1.972289156626506,
      "grad_norm": 1.2465943098068237,
      "learning_rate": 1.605542168674699e-05,
      "loss": 0.0538,
      "step": 16370
    },
    {
      "epoch": 1.9734939759036143,
      "grad_norm": 1.063516616821289,
      "learning_rate": 1.6053012048192773e-05,
      "loss": 0.0545,
      "step": 16380
    },
    {
      "epoch": 1.9746987951807229,
      "grad_norm": 0.1124979704618454,
      "learning_rate": 1.6050602409638558e-05,
      "loss": 0.053,
      "step": 16390
    },
    {
      "epoch": 1.9759036144578315,
      "grad_norm": 10.16447925567627,
      "learning_rate": 1.604819277108434e-05,
      "loss": 0.0535,
      "step": 16400
    },
    {
      "epoch": 1.9771084337349398,
      "grad_norm": 0.02160516194999218,
      "learning_rate": 1.604578313253012e-05,
      "loss": 0.0922,
      "step": 16410
    },
    {
      "epoch": 1.9783132530120482,
      "grad_norm": 2.623539924621582,
      "learning_rate": 1.6043373493975905e-05,
      "loss": 0.0367,
      "step": 16420
    },
    {
      "epoch": 1.9795180722891565,
      "grad_norm": 0.9886607527732849,
      "learning_rate": 1.6040963855421687e-05,
      "loss": 0.0957,
      "step": 16430
    },
    {
      "epoch": 1.980722891566265,
      "grad_norm": 0.7954214215278625,
      "learning_rate": 1.6038554216867472e-05,
      "loss": 0.0633,
      "step": 16440
    },
    {
      "epoch": 1.9819277108433735,
      "grad_norm": 8.034712791442871,
      "learning_rate": 1.6036144578313257e-05,
      "loss": 0.1058,
      "step": 16450
    },
    {
      "epoch": 1.983132530120482,
      "grad_norm": 6.210529804229736,
      "learning_rate": 1.6033734939759038e-05,
      "loss": 0.0435,
      "step": 16460
    },
    {
      "epoch": 1.9843373493975904,
      "grad_norm": 0.17377816140651703,
      "learning_rate": 1.603132530120482e-05,
      "loss": 0.0451,
      "step": 16470
    },
    {
      "epoch": 1.9855421686746988,
      "grad_norm": 0.08703497052192688,
      "learning_rate": 1.6028915662650605e-05,
      "loss": 0.1362,
      "step": 16480
    },
    {
      "epoch": 1.9867469879518072,
      "grad_norm": 0.6810585260391235,
      "learning_rate": 1.6026506024096386e-05,
      "loss": 0.0447,
      "step": 16490
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 2.4699954986572266,
      "learning_rate": 1.602409638554217e-05,
      "loss": 0.1131,
      "step": 16500
    },
    {
      "epoch": 1.989156626506024,
      "grad_norm": 0.572541356086731,
      "learning_rate": 1.6021686746987952e-05,
      "loss": 0.1235,
      "step": 16510
    },
    {
      "epoch": 1.9903614457831327,
      "grad_norm": 2.1860191822052,
      "learning_rate": 1.6019277108433737e-05,
      "loss": 0.0808,
      "step": 16520
    },
    {
      "epoch": 1.991566265060241,
      "grad_norm": 1.2522869110107422,
      "learning_rate": 1.601686746987952e-05,
      "loss": 0.0532,
      "step": 16530
    },
    {
      "epoch": 1.9927710843373494,
      "grad_norm": 8.052783012390137,
      "learning_rate": 1.6014457831325304e-05,
      "loss": 0.1217,
      "step": 16540
    },
    {
      "epoch": 1.9939759036144578,
      "grad_norm": 0.055218275636434555,
      "learning_rate": 1.6012048192771085e-05,
      "loss": 0.1246,
      "step": 16550
    },
    {
      "epoch": 1.9951807228915661,
      "grad_norm": 5.465867042541504,
      "learning_rate": 1.600963855421687e-05,
      "loss": 0.0788,
      "step": 16560
    },
    {
      "epoch": 1.9963855421686747,
      "grad_norm": 0.17472223937511444,
      "learning_rate": 1.600722891566265e-05,
      "loss": 0.074,
      "step": 16570
    },
    {
      "epoch": 1.9975903614457833,
      "grad_norm": 0.9495375752449036,
      "learning_rate": 1.6004819277108433e-05,
      "loss": 0.0447,
      "step": 16580
    },
    {
      "epoch": 1.9987951807228916,
      "grad_norm": 0.20983868837356567,
      "learning_rate": 1.6002409638554218e-05,
      "loss": 0.1127,
      "step": 16590
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.643730640411377,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.084,
      "step": 16600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9759092613423322,
      "eval_f1": 0.9372558593750001,
      "eval_loss": 0.07429800182580948,
      "eval_precision": 0.9258410707825877,
      "eval_recall": 0.9489556297120257,
      "eval_runtime": 4990.188,
      "eval_samples_per_second": 8.555,
      "eval_steps_per_second": 0.356,
      "step": 16600
    },
    {
      "epoch": 2.0012048192771084,
      "grad_norm": 0.3894638419151306,
      "learning_rate": 1.5997590361445784e-05,
      "loss": 0.037,
      "step": 16610
    },
    {
      "epoch": 2.0024096385542167,
      "grad_norm": 0.30526110529899597,
      "learning_rate": 1.599518072289157e-05,
      "loss": 0.0895,
      "step": 16620
    },
    {
      "epoch": 2.003614457831325,
      "grad_norm": 0.5768831372261047,
      "learning_rate": 1.599277108433735e-05,
      "loss": 0.0577,
      "step": 16630
    },
    {
      "epoch": 2.004819277108434,
      "grad_norm": 25.74913215637207,
      "learning_rate": 1.5990361445783132e-05,
      "loss": 0.071,
      "step": 16640
    },
    {
      "epoch": 2.0060240963855422,
      "grad_norm": 1.7208781242370605,
      "learning_rate": 1.5987951807228917e-05,
      "loss": 0.0596,
      "step": 16650
    },
    {
      "epoch": 2.0072289156626506,
      "grad_norm": 0.13779504597187042,
      "learning_rate": 1.59855421686747e-05,
      "loss": 0.1137,
      "step": 16660
    },
    {
      "epoch": 2.008433734939759,
      "grad_norm": 1.8099340200424194,
      "learning_rate": 1.5983132530120483e-05,
      "loss": 0.0664,
      "step": 16670
    },
    {
      "epoch": 2.0096385542168673,
      "grad_norm": 0.4117586016654968,
      "learning_rate": 1.5980722891566268e-05,
      "loss": 0.1115,
      "step": 16680
    },
    {
      "epoch": 2.0108433734939757,
      "grad_norm": 3.686460256576538,
      "learning_rate": 1.597831325301205e-05,
      "loss": 0.078,
      "step": 16690
    },
    {
      "epoch": 2.0120481927710845,
      "grad_norm": 0.1187739446759224,
      "learning_rate": 1.5975903614457834e-05,
      "loss": 0.0157,
      "step": 16700
    },
    {
      "epoch": 2.013253012048193,
      "grad_norm": 2.2702975273132324,
      "learning_rate": 1.5973493975903616e-05,
      "loss": 0.0757,
      "step": 16710
    },
    {
      "epoch": 2.014457831325301,
      "grad_norm": 3.717108726501465,
      "learning_rate": 1.5971084337349397e-05,
      "loss": 0.1122,
      "step": 16720
    },
    {
      "epoch": 2.0156626506024096,
      "grad_norm": 0.06008245423436165,
      "learning_rate": 1.5968674698795182e-05,
      "loss": 0.0084,
      "step": 16730
    },
    {
      "epoch": 2.016867469879518,
      "grad_norm": 2.931434392929077,
      "learning_rate": 1.5966265060240964e-05,
      "loss": 0.0262,
      "step": 16740
    },
    {
      "epoch": 2.0180722891566263,
      "grad_norm": 0.11682131141424179,
      "learning_rate": 1.596385542168675e-05,
      "loss": 0.0426,
      "step": 16750
    },
    {
      "epoch": 2.019277108433735,
      "grad_norm": 0.03847987577319145,
      "learning_rate": 1.5961445783132533e-05,
      "loss": 0.0098,
      "step": 16760
    },
    {
      "epoch": 2.0204819277108435,
      "grad_norm": 0.12042826414108276,
      "learning_rate": 1.5959036144578315e-05,
      "loss": 0.1248,
      "step": 16770
    },
    {
      "epoch": 2.021686746987952,
      "grad_norm": 0.01893622986972332,
      "learning_rate": 1.5956626506024096e-05,
      "loss": 0.0092,
      "step": 16780
    },
    {
      "epoch": 2.02289156626506,
      "grad_norm": 0.10372038930654526,
      "learning_rate": 1.595421686746988e-05,
      "loss": 0.1003,
      "step": 16790
    },
    {
      "epoch": 2.0240963855421685,
      "grad_norm": 9.662907600402832,
      "learning_rate": 1.5951807228915663e-05,
      "loss": 0.017,
      "step": 16800
    },
    {
      "epoch": 2.025301204819277,
      "grad_norm": 0.15665587782859802,
      "learning_rate": 1.5949397590361448e-05,
      "loss": 0.0508,
      "step": 16810
    },
    {
      "epoch": 2.0265060240963857,
      "grad_norm": 0.14098986983299255,
      "learning_rate": 1.5946987951807233e-05,
      "loss": 0.0841,
      "step": 16820
    },
    {
      "epoch": 2.027710843373494,
      "grad_norm": 17.03645896911621,
      "learning_rate": 1.5944578313253014e-05,
      "loss": 0.0814,
      "step": 16830
    },
    {
      "epoch": 2.0289156626506024,
      "grad_norm": 0.018544139340519905,
      "learning_rate": 1.5942168674698796e-05,
      "loss": 0.0516,
      "step": 16840
    },
    {
      "epoch": 2.0301204819277108,
      "grad_norm": 0.14017397165298462,
      "learning_rate": 1.593975903614458e-05,
      "loss": 0.0639,
      "step": 16850
    },
    {
      "epoch": 2.031325301204819,
      "grad_norm": 1.6235486268997192,
      "learning_rate": 1.5937349397590362e-05,
      "loss": 0.0463,
      "step": 16860
    },
    {
      "epoch": 2.0325301204819275,
      "grad_norm": 0.26919811964035034,
      "learning_rate": 1.5934939759036147e-05,
      "loss": 0.0703,
      "step": 16870
    },
    {
      "epoch": 2.0337349397590363,
      "grad_norm": 0.328580379486084,
      "learning_rate": 1.5932530120481928e-05,
      "loss": 0.046,
      "step": 16880
    },
    {
      "epoch": 2.0349397590361447,
      "grad_norm": 6.442861080169678,
      "learning_rate": 1.593012048192771e-05,
      "loss": 0.1232,
      "step": 16890
    },
    {
      "epoch": 2.036144578313253,
      "grad_norm": 0.16709861159324646,
      "learning_rate": 1.5927710843373495e-05,
      "loss": 0.0423,
      "step": 16900
    },
    {
      "epoch": 2.0373493975903614,
      "grad_norm": 2.079282760620117,
      "learning_rate": 1.592530120481928e-05,
      "loss": 0.0465,
      "step": 16910
    },
    {
      "epoch": 2.0385542168674697,
      "grad_norm": 2.309016704559326,
      "learning_rate": 1.592289156626506e-05,
      "loss": 0.0269,
      "step": 16920
    },
    {
      "epoch": 2.039759036144578,
      "grad_norm": 6.014854431152344,
      "learning_rate": 1.5920481927710846e-05,
      "loss": 0.0455,
      "step": 16930
    },
    {
      "epoch": 2.040963855421687,
      "grad_norm": 4.773259162902832,
      "learning_rate": 1.5918072289156627e-05,
      "loss": 0.0704,
      "step": 16940
    },
    {
      "epoch": 2.0421686746987953,
      "grad_norm": 1.713904619216919,
      "learning_rate": 1.591566265060241e-05,
      "loss": 0.0483,
      "step": 16950
    },
    {
      "epoch": 2.0433734939759036,
      "grad_norm": 2.160773277282715,
      "learning_rate": 1.5913253012048194e-05,
      "loss": 0.0752,
      "step": 16960
    },
    {
      "epoch": 2.044578313253012,
      "grad_norm": 0.06962272524833679,
      "learning_rate": 1.591084337349398e-05,
      "loss": 0.108,
      "step": 16970
    },
    {
      "epoch": 2.0457831325301203,
      "grad_norm": 1.3467775583267212,
      "learning_rate": 1.590843373493976e-05,
      "loss": 0.0265,
      "step": 16980
    },
    {
      "epoch": 2.0469879518072287,
      "grad_norm": 5.475727558135986,
      "learning_rate": 1.5906024096385545e-05,
      "loss": 0.0927,
      "step": 16990
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 2.9409093856811523,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 0.0898,
      "step": 17000
    },
    {
      "epoch": 2.049397590361446,
      "grad_norm": 12.11036205291748,
      "learning_rate": 1.590120481927711e-05,
      "loss": 0.0518,
      "step": 17010
    },
    {
      "epoch": 2.0506024096385542,
      "grad_norm": 22.70416259765625,
      "learning_rate": 1.5898795180722893e-05,
      "loss": 0.0448,
      "step": 17020
    },
    {
      "epoch": 2.0518072289156626,
      "grad_norm": 3.1050992012023926,
      "learning_rate": 1.5896385542168674e-05,
      "loss": 0.0461,
      "step": 17030
    },
    {
      "epoch": 2.053012048192771,
      "grad_norm": 0.1048000305891037,
      "learning_rate": 1.589397590361446e-05,
      "loss": 0.0405,
      "step": 17040
    },
    {
      "epoch": 2.0542168674698793,
      "grad_norm": 8.262545585632324,
      "learning_rate": 1.5891566265060244e-05,
      "loss": 0.0761,
      "step": 17050
    },
    {
      "epoch": 2.055421686746988,
      "grad_norm": 0.17508649826049805,
      "learning_rate": 1.5889156626506025e-05,
      "loss": 0.0343,
      "step": 17060
    },
    {
      "epoch": 2.0566265060240965,
      "grad_norm": 4.069357872009277,
      "learning_rate": 1.588674698795181e-05,
      "loss": 0.058,
      "step": 17070
    },
    {
      "epoch": 2.057831325301205,
      "grad_norm": 0.15112091600894928,
      "learning_rate": 1.5884337349397592e-05,
      "loss": 0.0883,
      "step": 17080
    },
    {
      "epoch": 2.059036144578313,
      "grad_norm": 2.9477035999298096,
      "learning_rate": 1.5881927710843373e-05,
      "loss": 0.0781,
      "step": 17090
    },
    {
      "epoch": 2.0602409638554215,
      "grad_norm": 0.044973816722631454,
      "learning_rate": 1.5879518072289158e-05,
      "loss": 0.0283,
      "step": 17100
    },
    {
      "epoch": 2.06144578313253,
      "grad_norm": 12.068140029907227,
      "learning_rate": 1.587710843373494e-05,
      "loss": 0.0487,
      "step": 17110
    },
    {
      "epoch": 2.0626506024096387,
      "grad_norm": 0.8799940347671509,
      "learning_rate": 1.5874698795180724e-05,
      "loss": 0.061,
      "step": 17120
    },
    {
      "epoch": 2.063855421686747,
      "grad_norm": 0.3426835536956787,
      "learning_rate": 1.587228915662651e-05,
      "loss": 0.0454,
      "step": 17130
    },
    {
      "epoch": 2.0650602409638554,
      "grad_norm": 0.12923219799995422,
      "learning_rate": 1.586987951807229e-05,
      "loss": 0.0708,
      "step": 17140
    },
    {
      "epoch": 2.066265060240964,
      "grad_norm": 2.102870464324951,
      "learning_rate": 1.5867469879518072e-05,
      "loss": 0.0953,
      "step": 17150
    },
    {
      "epoch": 2.067469879518072,
      "grad_norm": 10.888029098510742,
      "learning_rate": 1.5865060240963857e-05,
      "loss": 0.08,
      "step": 17160
    },
    {
      "epoch": 2.0686746987951805,
      "grad_norm": 0.03688463568687439,
      "learning_rate": 1.586265060240964e-05,
      "loss": 0.0609,
      "step": 17170
    },
    {
      "epoch": 2.0698795180722893,
      "grad_norm": 12.930180549621582,
      "learning_rate": 1.5860240963855423e-05,
      "loss": 0.0941,
      "step": 17180
    },
    {
      "epoch": 2.0710843373493977,
      "grad_norm": 6.010889530181885,
      "learning_rate": 1.5857831325301205e-05,
      "loss": 0.0582,
      "step": 17190
    },
    {
      "epoch": 2.072289156626506,
      "grad_norm": 0.18249383568763733,
      "learning_rate": 1.585542168674699e-05,
      "loss": 0.0522,
      "step": 17200
    },
    {
      "epoch": 2.0734939759036144,
      "grad_norm": 3.532195806503296,
      "learning_rate": 1.585301204819277e-05,
      "loss": 0.0667,
      "step": 17210
    },
    {
      "epoch": 2.0746987951807228,
      "grad_norm": 0.0721869170665741,
      "learning_rate": 1.5850602409638556e-05,
      "loss": 0.1447,
      "step": 17220
    },
    {
      "epoch": 2.075903614457831,
      "grad_norm": 1.8668462038040161,
      "learning_rate": 1.5848192771084338e-05,
      "loss": 0.0651,
      "step": 17230
    },
    {
      "epoch": 2.07710843373494,
      "grad_norm": 7.661596298217773,
      "learning_rate": 1.5845783132530123e-05,
      "loss": 0.1211,
      "step": 17240
    },
    {
      "epoch": 2.0783132530120483,
      "grad_norm": 0.5034036040306091,
      "learning_rate": 1.5843373493975904e-05,
      "loss": 0.0491,
      "step": 17250
    },
    {
      "epoch": 2.0795180722891566,
      "grad_norm": 2.553676128387451,
      "learning_rate": 1.5840963855421686e-05,
      "loss": 0.0505,
      "step": 17260
    },
    {
      "epoch": 2.080722891566265,
      "grad_norm": 0.9726580381393433,
      "learning_rate": 1.5838554216867474e-05,
      "loss": 0.1045,
      "step": 17270
    },
    {
      "epoch": 2.0819277108433734,
      "grad_norm": 0.18670900166034698,
      "learning_rate": 1.5836144578313255e-05,
      "loss": 0.0851,
      "step": 17280
    },
    {
      "epoch": 2.0831325301204817,
      "grad_norm": 5.221465110778809,
      "learning_rate": 1.5833734939759037e-05,
      "loss": 0.0801,
      "step": 17290
    },
    {
      "epoch": 2.0843373493975905,
      "grad_norm": 0.2710650861263275,
      "learning_rate": 1.583132530120482e-05,
      "loss": 0.0556,
      "step": 17300
    },
    {
      "epoch": 2.085542168674699,
      "grad_norm": 3.132042169570923,
      "learning_rate": 1.5828915662650603e-05,
      "loss": 0.0841,
      "step": 17310
    },
    {
      "epoch": 2.0867469879518072,
      "grad_norm": 4.01413631439209,
      "learning_rate": 1.5826506024096388e-05,
      "loss": 0.0535,
      "step": 17320
    },
    {
      "epoch": 2.0879518072289156,
      "grad_norm": 4.53251314163208,
      "learning_rate": 1.582409638554217e-05,
      "loss": 0.0804,
      "step": 17330
    },
    {
      "epoch": 2.089156626506024,
      "grad_norm": 0.11019433289766312,
      "learning_rate": 1.582168674698795e-05,
      "loss": 0.0615,
      "step": 17340
    },
    {
      "epoch": 2.0903614457831323,
      "grad_norm": 4.942439079284668,
      "learning_rate": 1.5819277108433736e-05,
      "loss": 0.0509,
      "step": 17350
    },
    {
      "epoch": 2.091566265060241,
      "grad_norm": 3.9638023376464844,
      "learning_rate": 1.581686746987952e-05,
      "loss": 0.0377,
      "step": 17360
    },
    {
      "epoch": 2.0927710843373495,
      "grad_norm": 6.0731611251831055,
      "learning_rate": 1.5814457831325302e-05,
      "loss": 0.0691,
      "step": 17370
    },
    {
      "epoch": 2.093975903614458,
      "grad_norm": 17.2623348236084,
      "learning_rate": 1.5812048192771087e-05,
      "loss": 0.0311,
      "step": 17380
    },
    {
      "epoch": 2.095180722891566,
      "grad_norm": 3.6566436290740967,
      "learning_rate": 1.580963855421687e-05,
      "loss": 0.0762,
      "step": 17390
    },
    {
      "epoch": 2.0963855421686746,
      "grad_norm": 0.033338990062475204,
      "learning_rate": 1.580722891566265e-05,
      "loss": 0.0892,
      "step": 17400
    },
    {
      "epoch": 2.097590361445783,
      "grad_norm": 3.057995080947876,
      "learning_rate": 1.5804819277108435e-05,
      "loss": 0.0108,
      "step": 17410
    },
    {
      "epoch": 2.0987951807228917,
      "grad_norm": 1.9064654111862183,
      "learning_rate": 1.580240963855422e-05,
      "loss": 0.0445,
      "step": 17420
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.305279940366745,
      "learning_rate": 1.58e-05,
      "loss": 0.0389,
      "step": 17430
    },
    {
      "epoch": 2.1012048192771084,
      "grad_norm": 1.2890901565551758,
      "learning_rate": 1.5797590361445786e-05,
      "loss": 0.0227,
      "step": 17440
    },
    {
      "epoch": 2.102409638554217,
      "grad_norm": 0.009237471967935562,
      "learning_rate": 1.5795180722891568e-05,
      "loss": 0.0285,
      "step": 17450
    },
    {
      "epoch": 2.103614457831325,
      "grad_norm": 0.1407996416091919,
      "learning_rate": 1.579277108433735e-05,
      "loss": 0.0689,
      "step": 17460
    },
    {
      "epoch": 2.1048192771084335,
      "grad_norm": 3.8777987957000732,
      "learning_rate": 1.5790361445783134e-05,
      "loss": 0.0709,
      "step": 17470
    },
    {
      "epoch": 2.1060240963855423,
      "grad_norm": 2.0633509159088135,
      "learning_rate": 1.5787951807228915e-05,
      "loss": 0.0345,
      "step": 17480
    },
    {
      "epoch": 2.1072289156626507,
      "grad_norm": 0.187534362077713,
      "learning_rate": 1.57855421686747e-05,
      "loss": 0.0443,
      "step": 17490
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 3.0101325511932373,
      "learning_rate": 1.5783132530120485e-05,
      "loss": 0.085,
      "step": 17500
    },
    {
      "epoch": 2.1096385542168674,
      "grad_norm": 0.1591450423002243,
      "learning_rate": 1.5780722891566267e-05,
      "loss": 0.0159,
      "step": 17510
    },
    {
      "epoch": 2.1108433734939758,
      "grad_norm": 1.369444489479065,
      "learning_rate": 1.5778313253012048e-05,
      "loss": 0.042,
      "step": 17520
    },
    {
      "epoch": 2.112048192771084,
      "grad_norm": 0.33875298500061035,
      "learning_rate": 1.5775903614457833e-05,
      "loss": 0.0407,
      "step": 17530
    },
    {
      "epoch": 2.113253012048193,
      "grad_norm": 1.8299483060836792,
      "learning_rate": 1.5773493975903614e-05,
      "loss": 0.0897,
      "step": 17540
    },
    {
      "epoch": 2.1144578313253013,
      "grad_norm": 0.2997608482837677,
      "learning_rate": 1.57710843373494e-05,
      "loss": 0.0504,
      "step": 17550
    },
    {
      "epoch": 2.1156626506024097,
      "grad_norm": 14.846517562866211,
      "learning_rate": 1.576867469879518e-05,
      "loss": 0.0911,
      "step": 17560
    },
    {
      "epoch": 2.116867469879518,
      "grad_norm": 0.12097207456827164,
      "learning_rate": 1.5766265060240966e-05,
      "loss": 0.0471,
      "step": 17570
    },
    {
      "epoch": 2.1180722891566264,
      "grad_norm": 1.4466893672943115,
      "learning_rate": 1.576385542168675e-05,
      "loss": 0.0454,
      "step": 17580
    },
    {
      "epoch": 2.1192771084337347,
      "grad_norm": 3.1273200511932373,
      "learning_rate": 1.5761445783132532e-05,
      "loss": 0.0815,
      "step": 17590
    },
    {
      "epoch": 2.1204819277108435,
      "grad_norm": 1.175204873085022,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 0.0289,
      "step": 17600
    },
    {
      "epoch": 2.121686746987952,
      "grad_norm": 0.06775324046611786,
      "learning_rate": 1.57566265060241e-05,
      "loss": 0.0351,
      "step": 17610
    },
    {
      "epoch": 2.1228915662650603,
      "grad_norm": 0.33076614141464233,
      "learning_rate": 1.575421686746988e-05,
      "loss": 0.0407,
      "step": 17620
    },
    {
      "epoch": 2.1240963855421686,
      "grad_norm": 2.6194159984588623,
      "learning_rate": 1.5751807228915665e-05,
      "loss": 0.1426,
      "step": 17630
    },
    {
      "epoch": 2.125301204819277,
      "grad_norm": 3.427616596221924,
      "learning_rate": 1.5749397590361446e-05,
      "loss": 0.0389,
      "step": 17640
    },
    {
      "epoch": 2.1265060240963853,
      "grad_norm": 15.493291854858398,
      "learning_rate": 1.574698795180723e-05,
      "loss": 0.0375,
      "step": 17650
    },
    {
      "epoch": 2.127710843373494,
      "grad_norm": 3.1302058696746826,
      "learning_rate": 1.5744578313253013e-05,
      "loss": 0.0794,
      "step": 17660
    },
    {
      "epoch": 2.1289156626506025,
      "grad_norm": 0.14644010365009308,
      "learning_rate": 1.5742168674698797e-05,
      "loss": 0.0472,
      "step": 17670
    },
    {
      "epoch": 2.130120481927711,
      "grad_norm": 1.733284592628479,
      "learning_rate": 1.573975903614458e-05,
      "loss": 0.0491,
      "step": 17680
    },
    {
      "epoch": 2.1313253012048192,
      "grad_norm": 0.5745798945426941,
      "learning_rate": 1.5737349397590364e-05,
      "loss": 0.0467,
      "step": 17690
    },
    {
      "epoch": 2.1325301204819276,
      "grad_norm": 4.988761901855469,
      "learning_rate": 1.5734939759036145e-05,
      "loss": 0.0509,
      "step": 17700
    },
    {
      "epoch": 2.133734939759036,
      "grad_norm": 5.002504348754883,
      "learning_rate": 1.5732530120481927e-05,
      "loss": 0.0593,
      "step": 17710
    },
    {
      "epoch": 2.1349397590361447,
      "grad_norm": 5.2780375480651855,
      "learning_rate": 1.573012048192771e-05,
      "loss": 0.0716,
      "step": 17720
    },
    {
      "epoch": 2.136144578313253,
      "grad_norm": 1.4494026899337769,
      "learning_rate": 1.5727710843373496e-05,
      "loss": 0.0795,
      "step": 17730
    },
    {
      "epoch": 2.1373493975903615,
      "grad_norm": 2.0192337036132812,
      "learning_rate": 1.5725301204819278e-05,
      "loss": 0.104,
      "step": 17740
    },
    {
      "epoch": 2.13855421686747,
      "grad_norm": 0.15179480612277985,
      "learning_rate": 1.5722891566265063e-05,
      "loss": 0.0461,
      "step": 17750
    },
    {
      "epoch": 2.139759036144578,
      "grad_norm": 1.9828786849975586,
      "learning_rate": 1.5720481927710844e-05,
      "loss": 0.0563,
      "step": 17760
    },
    {
      "epoch": 2.1409638554216865,
      "grad_norm": 0.017600858584046364,
      "learning_rate": 1.5718072289156626e-05,
      "loss": 0.0213,
      "step": 17770
    },
    {
      "epoch": 2.1421686746987953,
      "grad_norm": 0.03213951736688614,
      "learning_rate": 1.571566265060241e-05,
      "loss": 0.0294,
      "step": 17780
    },
    {
      "epoch": 2.1433734939759037,
      "grad_norm": 0.03653880953788757,
      "learning_rate": 1.5713253012048192e-05,
      "loss": 0.0806,
      "step": 17790
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 0.30124446749687195,
      "learning_rate": 1.5710843373493977e-05,
      "loss": 0.059,
      "step": 17800
    },
    {
      "epoch": 2.1457831325301204,
      "grad_norm": 0.37267524003982544,
      "learning_rate": 1.5708433734939762e-05,
      "loss": 0.078,
      "step": 17810
    },
    {
      "epoch": 2.146987951807229,
      "grad_norm": 0.36775174736976624,
      "learning_rate": 1.5706024096385543e-05,
      "loss": 0.0508,
      "step": 17820
    },
    {
      "epoch": 2.148192771084337,
      "grad_norm": 2.8961665630340576,
      "learning_rate": 1.5703614457831328e-05,
      "loss": 0.051,
      "step": 17830
    },
    {
      "epoch": 2.149397590361446,
      "grad_norm": 0.0902753472328186,
      "learning_rate": 1.570120481927711e-05,
      "loss": 0.0751,
      "step": 17840
    },
    {
      "epoch": 2.1506024096385543,
      "grad_norm": 0.8169421553611755,
      "learning_rate": 1.569879518072289e-05,
      "loss": 0.0385,
      "step": 17850
    },
    {
      "epoch": 2.1518072289156627,
      "grad_norm": 0.15117210149765015,
      "learning_rate": 1.5696385542168676e-05,
      "loss": 0.0215,
      "step": 17860
    },
    {
      "epoch": 2.153012048192771,
      "grad_norm": 0.6879681348800659,
      "learning_rate": 1.569397590361446e-05,
      "loss": 0.0067,
      "step": 17870
    },
    {
      "epoch": 2.1542168674698794,
      "grad_norm": 0.9083660244941711,
      "learning_rate": 1.5691566265060242e-05,
      "loss": 0.0426,
      "step": 17880
    },
    {
      "epoch": 2.1554216867469878,
      "grad_norm": 12.27853775024414,
      "learning_rate": 1.5689156626506027e-05,
      "loss": 0.1283,
      "step": 17890
    },
    {
      "epoch": 2.1566265060240966,
      "grad_norm": 2.0809483528137207,
      "learning_rate": 1.568674698795181e-05,
      "loss": 0.0677,
      "step": 17900
    },
    {
      "epoch": 2.157831325301205,
      "grad_norm": 4.1902546882629395,
      "learning_rate": 1.568433734939759e-05,
      "loss": 0.0782,
      "step": 17910
    },
    {
      "epoch": 2.1590361445783133,
      "grad_norm": 5.8735785484313965,
      "learning_rate": 1.5681927710843375e-05,
      "loss": 0.0628,
      "step": 17920
    },
    {
      "epoch": 2.1602409638554216,
      "grad_norm": 0.4667971134185791,
      "learning_rate": 1.5679518072289157e-05,
      "loss": 0.0418,
      "step": 17930
    },
    {
      "epoch": 2.16144578313253,
      "grad_norm": 0.235774427652359,
      "learning_rate": 1.567710843373494e-05,
      "loss": 0.0171,
      "step": 17940
    },
    {
      "epoch": 2.1626506024096384,
      "grad_norm": 3.5967183113098145,
      "learning_rate": 1.5674698795180726e-05,
      "loss": 0.0896,
      "step": 17950
    },
    {
      "epoch": 2.163855421686747,
      "grad_norm": 0.21928007900714874,
      "learning_rate": 1.5672289156626508e-05,
      "loss": 0.0665,
      "step": 17960
    },
    {
      "epoch": 2.1650602409638555,
      "grad_norm": 0.05321558192372322,
      "learning_rate": 1.566987951807229e-05,
      "loss": 0.0057,
      "step": 17970
    },
    {
      "epoch": 2.166265060240964,
      "grad_norm": 4.954797744750977,
      "learning_rate": 1.5667469879518074e-05,
      "loss": 0.0745,
      "step": 17980
    },
    {
      "epoch": 2.1674698795180722,
      "grad_norm": 0.14973534643650055,
      "learning_rate": 1.5665060240963856e-05,
      "loss": 0.0263,
      "step": 17990
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.04591205716133118,
      "learning_rate": 1.566265060240964e-05,
      "loss": 0.0597,
      "step": 18000
    },
    {
      "epoch": 2.169879518072289,
      "grad_norm": 4.1791768074035645,
      "learning_rate": 1.5660240963855422e-05,
      "loss": 0.0731,
      "step": 18010
    },
    {
      "epoch": 2.1710843373493978,
      "grad_norm": 0.3563775420188904,
      "learning_rate": 1.5657831325301207e-05,
      "loss": 0.0613,
      "step": 18020
    },
    {
      "epoch": 2.172289156626506,
      "grad_norm": 0.1272931843996048,
      "learning_rate": 1.565542168674699e-05,
      "loss": 0.0372,
      "step": 18030
    },
    {
      "epoch": 2.1734939759036145,
      "grad_norm": 0.2267553210258484,
      "learning_rate": 1.5653012048192773e-05,
      "loss": 0.0616,
      "step": 18040
    },
    {
      "epoch": 2.174698795180723,
      "grad_norm": 4.456167221069336,
      "learning_rate": 1.5650602409638555e-05,
      "loss": 0.0586,
      "step": 18050
    },
    {
      "epoch": 2.175903614457831,
      "grad_norm": 0.18612989783287048,
      "learning_rate": 1.564819277108434e-05,
      "loss": 0.0525,
      "step": 18060
    },
    {
      "epoch": 2.1771084337349396,
      "grad_norm": 3.939603805541992,
      "learning_rate": 1.564578313253012e-05,
      "loss": 0.1044,
      "step": 18070
    },
    {
      "epoch": 2.1783132530120484,
      "grad_norm": 0.05134822800755501,
      "learning_rate": 1.5643373493975903e-05,
      "loss": 0.0514,
      "step": 18080
    },
    {
      "epoch": 2.1795180722891567,
      "grad_norm": 10.493877410888672,
      "learning_rate": 1.5640963855421687e-05,
      "loss": 0.0517,
      "step": 18090
    },
    {
      "epoch": 2.180722891566265,
      "grad_norm": 0.7601946592330933,
      "learning_rate": 1.5638554216867472e-05,
      "loss": 0.0391,
      "step": 18100
    },
    {
      "epoch": 2.1819277108433734,
      "grad_norm": 0.031084073707461357,
      "learning_rate": 1.5636144578313254e-05,
      "loss": 0.0123,
      "step": 18110
    },
    {
      "epoch": 2.183132530120482,
      "grad_norm": 0.12456966936588287,
      "learning_rate": 1.563373493975904e-05,
      "loss": 0.0855,
      "step": 18120
    },
    {
      "epoch": 2.18433734939759,
      "grad_norm": 0.3614308834075928,
      "learning_rate": 1.563132530120482e-05,
      "loss": 0.0593,
      "step": 18130
    },
    {
      "epoch": 2.185542168674699,
      "grad_norm": 0.0803166925907135,
      "learning_rate": 1.5628915662650605e-05,
      "loss": 0.0649,
      "step": 18140
    },
    {
      "epoch": 2.1867469879518073,
      "grad_norm": 7.7740254402160645,
      "learning_rate": 1.5626506024096386e-05,
      "loss": 0.0762,
      "step": 18150
    },
    {
      "epoch": 2.1879518072289157,
      "grad_norm": 2.6391117572784424,
      "learning_rate": 1.5624096385542168e-05,
      "loss": 0.1152,
      "step": 18160
    },
    {
      "epoch": 2.189156626506024,
      "grad_norm": 0.2342042624950409,
      "learning_rate": 1.5621686746987953e-05,
      "loss": 0.0803,
      "step": 18170
    },
    {
      "epoch": 2.1903614457831324,
      "grad_norm": 16.792816162109375,
      "learning_rate": 1.5619277108433738e-05,
      "loss": 0.0759,
      "step": 18180
    },
    {
      "epoch": 2.1915662650602408,
      "grad_norm": 0.1611713469028473,
      "learning_rate": 1.561686746987952e-05,
      "loss": 0.0522,
      "step": 18190
    },
    {
      "epoch": 2.1927710843373496,
      "grad_norm": 0.31965509057044983,
      "learning_rate": 1.5614457831325304e-05,
      "loss": 0.0636,
      "step": 18200
    },
    {
      "epoch": 2.193975903614458,
      "grad_norm": 4.65583610534668,
      "learning_rate": 1.5612048192771086e-05,
      "loss": 0.078,
      "step": 18210
    },
    {
      "epoch": 2.1951807228915663,
      "grad_norm": 4.2267045974731445,
      "learning_rate": 1.5609638554216867e-05,
      "loss": 0.0532,
      "step": 18220
    },
    {
      "epoch": 2.1963855421686747,
      "grad_norm": 0.03969650715589523,
      "learning_rate": 1.5607228915662652e-05,
      "loss": 0.0526,
      "step": 18230
    },
    {
      "epoch": 2.197590361445783,
      "grad_norm": 1.2994619607925415,
      "learning_rate": 1.5604819277108433e-05,
      "loss": 0.0871,
      "step": 18240
    },
    {
      "epoch": 2.1987951807228914,
      "grad_norm": 0.3069436252117157,
      "learning_rate": 1.5602409638554218e-05,
      "loss": 0.0893,
      "step": 18250
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.548783779144287,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.06,
      "step": 18260
    },
    {
      "epoch": 2.2012048192771085,
      "grad_norm": 0.05794695019721985,
      "learning_rate": 1.5597590361445785e-05,
      "loss": 0.0152,
      "step": 18270
    },
    {
      "epoch": 2.202409638554217,
      "grad_norm": 0.0593605674803257,
      "learning_rate": 1.5595180722891566e-05,
      "loss": 0.0596,
      "step": 18280
    },
    {
      "epoch": 2.2036144578313253,
      "grad_norm": 5.4602460861206055,
      "learning_rate": 1.559277108433735e-05,
      "loss": 0.0464,
      "step": 18290
    },
    {
      "epoch": 2.2048192771084336,
      "grad_norm": 0.016647590324282646,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 0.0448,
      "step": 18300
    },
    {
      "epoch": 2.206024096385542,
      "grad_norm": 2.6606876850128174,
      "learning_rate": 1.5587951807228917e-05,
      "loss": 0.0989,
      "step": 18310
    },
    {
      "epoch": 2.207228915662651,
      "grad_norm": 0.5156872868537903,
      "learning_rate": 1.5585542168674702e-05,
      "loss": 0.1025,
      "step": 18320
    },
    {
      "epoch": 2.208433734939759,
      "grad_norm": 5.816296100616455,
      "learning_rate": 1.5583132530120484e-05,
      "loss": 0.0375,
      "step": 18330
    },
    {
      "epoch": 2.2096385542168675,
      "grad_norm": 8.454876899719238,
      "learning_rate": 1.5580722891566265e-05,
      "loss": 0.0688,
      "step": 18340
    },
    {
      "epoch": 2.210843373493976,
      "grad_norm": 2.0719618797302246,
      "learning_rate": 1.557831325301205e-05,
      "loss": 0.0656,
      "step": 18350
    },
    {
      "epoch": 2.212048192771084,
      "grad_norm": 0.10189031809568405,
      "learning_rate": 1.557590361445783e-05,
      "loss": 0.1148,
      "step": 18360
    },
    {
      "epoch": 2.2132530120481926,
      "grad_norm": 8.767847061157227,
      "learning_rate": 1.5573493975903616e-05,
      "loss": 0.0665,
      "step": 18370
    },
    {
      "epoch": 2.2144578313253014,
      "grad_norm": 0.6781678795814514,
      "learning_rate": 1.5571084337349398e-05,
      "loss": 0.0608,
      "step": 18380
    },
    {
      "epoch": 2.2156626506024097,
      "grad_norm": 4.796848773956299,
      "learning_rate": 1.556867469879518e-05,
      "loss": 0.0171,
      "step": 18390
    },
    {
      "epoch": 2.216867469879518,
      "grad_norm": 2.6651039123535156,
      "learning_rate": 1.5566265060240968e-05,
      "loss": 0.0702,
      "step": 18400
    },
    {
      "epoch": 2.2180722891566265,
      "grad_norm": 1.2197762727737427,
      "learning_rate": 1.556385542168675e-05,
      "loss": 0.0192,
      "step": 18410
    },
    {
      "epoch": 2.219277108433735,
      "grad_norm": 0.09578925371170044,
      "learning_rate": 1.556144578313253e-05,
      "loss": 0.0834,
      "step": 18420
    },
    {
      "epoch": 2.220481927710843,
      "grad_norm": 3.02773118019104,
      "learning_rate": 1.5559036144578315e-05,
      "loss": 0.1133,
      "step": 18430
    },
    {
      "epoch": 2.221686746987952,
      "grad_norm": 0.514457643032074,
      "learning_rate": 1.5556626506024097e-05,
      "loss": 0.1167,
      "step": 18440
    },
    {
      "epoch": 2.2228915662650603,
      "grad_norm": 6.705136299133301,
      "learning_rate": 1.5554216867469882e-05,
      "loss": 0.0357,
      "step": 18450
    },
    {
      "epoch": 2.2240963855421687,
      "grad_norm": 3.512971878051758,
      "learning_rate": 1.5551807228915663e-05,
      "loss": 0.1282,
      "step": 18460
    },
    {
      "epoch": 2.225301204819277,
      "grad_norm": 0.5305250287055969,
      "learning_rate": 1.5549397590361448e-05,
      "loss": 0.0959,
      "step": 18470
    },
    {
      "epoch": 2.2265060240963854,
      "grad_norm": 0.17394164204597473,
      "learning_rate": 1.554698795180723e-05,
      "loss": 0.0199,
      "step": 18480
    },
    {
      "epoch": 2.227710843373494,
      "grad_norm": 0.05958380177617073,
      "learning_rate": 1.5544578313253014e-05,
      "loss": 0.1655,
      "step": 18490
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 0.8631614446640015,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 0.1033,
      "step": 18500
    },
    {
      "epoch": 2.230120481927711,
      "grad_norm": 0.1262727975845337,
      "learning_rate": 1.553975903614458e-05,
      "loss": 0.0204,
      "step": 18510
    },
    {
      "epoch": 2.2313253012048193,
      "grad_norm": 0.03278832510113716,
      "learning_rate": 1.5537349397590362e-05,
      "loss": 0.0162,
      "step": 18520
    },
    {
      "epoch": 2.2325301204819277,
      "grad_norm": 0.13742084801197052,
      "learning_rate": 1.5534939759036144e-05,
      "loss": 0.0481,
      "step": 18530
    },
    {
      "epoch": 2.233734939759036,
      "grad_norm": 6.737171649932861,
      "learning_rate": 1.553253012048193e-05,
      "loss": 0.0822,
      "step": 18540
    },
    {
      "epoch": 2.2349397590361444,
      "grad_norm": 0.06613346934318542,
      "learning_rate": 1.5530120481927714e-05,
      "loss": 0.0463,
      "step": 18550
    },
    {
      "epoch": 2.236144578313253,
      "grad_norm": 0.5812033414840698,
      "learning_rate": 1.5527710843373495e-05,
      "loss": 0.0671,
      "step": 18560
    },
    {
      "epoch": 2.2373493975903616,
      "grad_norm": 0.06851382553577423,
      "learning_rate": 1.552530120481928e-05,
      "loss": 0.0359,
      "step": 18570
    },
    {
      "epoch": 2.23855421686747,
      "grad_norm": 2.6409294605255127,
      "learning_rate": 1.552289156626506e-05,
      "loss": 0.0921,
      "step": 18580
    },
    {
      "epoch": 2.2397590361445783,
      "grad_norm": 5.657740116119385,
      "learning_rate": 1.5520481927710843e-05,
      "loss": 0.1051,
      "step": 18590
    },
    {
      "epoch": 2.2409638554216866,
      "grad_norm": 0.3899627923965454,
      "learning_rate": 1.5518072289156628e-05,
      "loss": 0.0734,
      "step": 18600
    },
    {
      "epoch": 2.242168674698795,
      "grad_norm": 0.12149098515510559,
      "learning_rate": 1.551566265060241e-05,
      "loss": 0.0144,
      "step": 18610
    },
    {
      "epoch": 2.243373493975904,
      "grad_norm": 0.084515780210495,
      "learning_rate": 1.5513253012048194e-05,
      "loss": 0.0182,
      "step": 18620
    },
    {
      "epoch": 2.244578313253012,
      "grad_norm": 27.008928298950195,
      "learning_rate": 1.551084337349398e-05,
      "loss": 0.0866,
      "step": 18630
    },
    {
      "epoch": 2.2457831325301205,
      "grad_norm": 6.7940473556518555,
      "learning_rate": 1.550843373493976e-05,
      "loss": 0.0499,
      "step": 18640
    },
    {
      "epoch": 2.246987951807229,
      "grad_norm": 0.016248196363449097,
      "learning_rate": 1.5506024096385542e-05,
      "loss": 0.0273,
      "step": 18650
    },
    {
      "epoch": 2.2481927710843372,
      "grad_norm": 0.02510489709675312,
      "learning_rate": 1.5503614457831327e-05,
      "loss": 0.0381,
      "step": 18660
    },
    {
      "epoch": 2.2493975903614456,
      "grad_norm": 0.21682047843933105,
      "learning_rate": 1.5501204819277108e-05,
      "loss": 0.0282,
      "step": 18670
    },
    {
      "epoch": 2.2506024096385544,
      "grad_norm": 0.014113391749560833,
      "learning_rate": 1.5498795180722893e-05,
      "loss": 0.0608,
      "step": 18680
    },
    {
      "epoch": 2.2518072289156628,
      "grad_norm": 2.219543933868408,
      "learning_rate": 1.5496385542168678e-05,
      "loss": 0.068,
      "step": 18690
    },
    {
      "epoch": 2.253012048192771,
      "grad_norm": 2.0816447734832764,
      "learning_rate": 1.549397590361446e-05,
      "loss": 0.0349,
      "step": 18700
    },
    {
      "epoch": 2.2542168674698795,
      "grad_norm": 0.08818165212869644,
      "learning_rate": 1.5491566265060244e-05,
      "loss": 0.055,
      "step": 18710
    },
    {
      "epoch": 2.255421686746988,
      "grad_norm": 7.02516508102417,
      "learning_rate": 1.5489156626506026e-05,
      "loss": 0.0535,
      "step": 18720
    },
    {
      "epoch": 2.256626506024096,
      "grad_norm": 3.469442844390869,
      "learning_rate": 1.5486746987951807e-05,
      "loss": 0.1126,
      "step": 18730
    },
    {
      "epoch": 2.257831325301205,
      "grad_norm": 1.2897722721099854,
      "learning_rate": 1.5484337349397592e-05,
      "loss": 0.0435,
      "step": 18740
    },
    {
      "epoch": 2.2590361445783134,
      "grad_norm": 0.2651737332344055,
      "learning_rate": 1.5481927710843374e-05,
      "loss": 0.0335,
      "step": 18750
    },
    {
      "epoch": 2.2602409638554217,
      "grad_norm": 0.36358773708343506,
      "learning_rate": 1.547951807228916e-05,
      "loss": 0.0567,
      "step": 18760
    },
    {
      "epoch": 2.26144578313253,
      "grad_norm": 0.06333046406507492,
      "learning_rate": 1.5477108433734943e-05,
      "loss": 0.095,
      "step": 18770
    },
    {
      "epoch": 2.2626506024096384,
      "grad_norm": 1.4068629741668701,
      "learning_rate": 1.5474698795180725e-05,
      "loss": 0.0306,
      "step": 18780
    },
    {
      "epoch": 2.263855421686747,
      "grad_norm": 0.5197867155075073,
      "learning_rate": 1.5472289156626506e-05,
      "loss": 0.033,
      "step": 18790
    },
    {
      "epoch": 2.2650602409638556,
      "grad_norm": 0.04130568727850914,
      "learning_rate": 1.546987951807229e-05,
      "loss": 0.0545,
      "step": 18800
    },
    {
      "epoch": 2.266265060240964,
      "grad_norm": 0.07176151871681213,
      "learning_rate": 1.5467469879518073e-05,
      "loss": 0.0288,
      "step": 18810
    },
    {
      "epoch": 2.2674698795180723,
      "grad_norm": 4.2670793533325195,
      "learning_rate": 1.5465060240963858e-05,
      "loss": 0.0622,
      "step": 18820
    },
    {
      "epoch": 2.2686746987951807,
      "grad_norm": 0.10747786611318588,
      "learning_rate": 1.546265060240964e-05,
      "loss": 0.0639,
      "step": 18830
    },
    {
      "epoch": 2.269879518072289,
      "grad_norm": 5.938028335571289,
      "learning_rate": 1.5460240963855424e-05,
      "loss": 0.0777,
      "step": 18840
    },
    {
      "epoch": 2.2710843373493974,
      "grad_norm": 12.915199279785156,
      "learning_rate": 1.5457831325301205e-05,
      "loss": 0.0765,
      "step": 18850
    },
    {
      "epoch": 2.272289156626506,
      "grad_norm": 0.08529143780469894,
      "learning_rate": 1.545542168674699e-05,
      "loss": 0.0422,
      "step": 18860
    },
    {
      "epoch": 2.2734939759036146,
      "grad_norm": 2.9814488887786865,
      "learning_rate": 1.5453012048192772e-05,
      "loss": 0.1123,
      "step": 18870
    },
    {
      "epoch": 2.274698795180723,
      "grad_norm": 0.11622603237628937,
      "learning_rate": 1.5450602409638557e-05,
      "loss": 0.0553,
      "step": 18880
    },
    {
      "epoch": 2.2759036144578313,
      "grad_norm": 1.136940836906433,
      "learning_rate": 1.5448192771084338e-05,
      "loss": 0.041,
      "step": 18890
    },
    {
      "epoch": 2.2771084337349397,
      "grad_norm": 0.1549193412065506,
      "learning_rate": 1.544578313253012e-05,
      "loss": 0.0289,
      "step": 18900
    },
    {
      "epoch": 2.278313253012048,
      "grad_norm": 1.096847653388977,
      "learning_rate": 1.5443373493975904e-05,
      "loss": 0.0847,
      "step": 18910
    },
    {
      "epoch": 2.279518072289157,
      "grad_norm": 2.977287530899048,
      "learning_rate": 1.544096385542169e-05,
      "loss": 0.0632,
      "step": 18920
    },
    {
      "epoch": 2.280722891566265,
      "grad_norm": 9.795968055725098,
      "learning_rate": 1.543855421686747e-05,
      "loss": 0.0367,
      "step": 18930
    },
    {
      "epoch": 2.2819277108433735,
      "grad_norm": 0.9886853694915771,
      "learning_rate": 1.5436144578313256e-05,
      "loss": 0.0499,
      "step": 18940
    },
    {
      "epoch": 2.283132530120482,
      "grad_norm": 0.34908372163772583,
      "learning_rate": 1.5433734939759037e-05,
      "loss": 0.0584,
      "step": 18950
    },
    {
      "epoch": 2.2843373493975903,
      "grad_norm": 3.117990255355835,
      "learning_rate": 1.543132530120482e-05,
      "loss": 0.0598,
      "step": 18960
    },
    {
      "epoch": 2.2855421686746986,
      "grad_norm": 0.03607664257287979,
      "learning_rate": 1.5428915662650604e-05,
      "loss": 0.0358,
      "step": 18970
    },
    {
      "epoch": 2.2867469879518074,
      "grad_norm": 0.03310047835111618,
      "learning_rate": 1.5426506024096385e-05,
      "loss": 0.0701,
      "step": 18980
    },
    {
      "epoch": 2.287951807228916,
      "grad_norm": 0.13202765583992004,
      "learning_rate": 1.542409638554217e-05,
      "loss": 0.0528,
      "step": 18990
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 0.2451935112476349,
      "learning_rate": 1.5421686746987955e-05,
      "loss": 0.1029,
      "step": 19000
    },
    {
      "epoch": 2.2903614457831325,
      "grad_norm": 0.9907532930374146,
      "learning_rate": 1.5419277108433736e-05,
      "loss": 0.0512,
      "step": 19010
    },
    {
      "epoch": 2.291566265060241,
      "grad_norm": 0.029539255425333977,
      "learning_rate": 1.541686746987952e-05,
      "loss": 0.0373,
      "step": 19020
    },
    {
      "epoch": 2.292771084337349,
      "grad_norm": 5.168228626251221,
      "learning_rate": 1.5414457831325303e-05,
      "loss": 0.1194,
      "step": 19030
    },
    {
      "epoch": 2.293975903614458,
      "grad_norm": 1.3933963775634766,
      "learning_rate": 1.5412048192771084e-05,
      "loss": 0.0469,
      "step": 19040
    },
    {
      "epoch": 2.2951807228915664,
      "grad_norm": 7.403902053833008,
      "learning_rate": 1.540963855421687e-05,
      "loss": 0.1071,
      "step": 19050
    },
    {
      "epoch": 2.2963855421686747,
      "grad_norm": 6.286567211151123,
      "learning_rate": 1.540722891566265e-05,
      "loss": 0.0798,
      "step": 19060
    },
    {
      "epoch": 2.297590361445783,
      "grad_norm": 0.692953884601593,
      "learning_rate": 1.5404819277108435e-05,
      "loss": 0.0784,
      "step": 19070
    },
    {
      "epoch": 2.2987951807228915,
      "grad_norm": 10.171123504638672,
      "learning_rate": 1.540240963855422e-05,
      "loss": 0.1036,
      "step": 19080
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.289231300354004,
      "learning_rate": 1.54e-05,
      "loss": 0.0618,
      "step": 19090
    },
    {
      "epoch": 2.3012048192771086,
      "grad_norm": 0.6037204265594482,
      "learning_rate": 1.5397590361445783e-05,
      "loss": 0.0314,
      "step": 19100
    },
    {
      "epoch": 2.302409638554217,
      "grad_norm": 4.179203033447266,
      "learning_rate": 1.5395180722891568e-05,
      "loss": 0.0679,
      "step": 19110
    },
    {
      "epoch": 2.3036144578313253,
      "grad_norm": 5.0658087730407715,
      "learning_rate": 1.539277108433735e-05,
      "loss": 0.0772,
      "step": 19120
    },
    {
      "epoch": 2.3048192771084337,
      "grad_norm": 0.62868332862854,
      "learning_rate": 1.5390361445783134e-05,
      "loss": 0.0792,
      "step": 19130
    },
    {
      "epoch": 2.306024096385542,
      "grad_norm": 0.07743889093399048,
      "learning_rate": 1.538795180722892e-05,
      "loss": 0.0253,
      "step": 19140
    },
    {
      "epoch": 2.3072289156626504,
      "grad_norm": 6.794334888458252,
      "learning_rate": 1.53855421686747e-05,
      "loss": 0.0757,
      "step": 19150
    },
    {
      "epoch": 2.3084337349397592,
      "grad_norm": 4.391676902770996,
      "learning_rate": 1.5383132530120482e-05,
      "loss": 0.0535,
      "step": 19160
    },
    {
      "epoch": 2.3096385542168676,
      "grad_norm": 2.5659070014953613,
      "learning_rate": 1.5380722891566267e-05,
      "loss": 0.0255,
      "step": 19170
    },
    {
      "epoch": 2.310843373493976,
      "grad_norm": 0.7694653868675232,
      "learning_rate": 1.537831325301205e-05,
      "loss": 0.0464,
      "step": 19180
    },
    {
      "epoch": 2.3120481927710843,
      "grad_norm": 1.6844810247421265,
      "learning_rate": 1.5375903614457833e-05,
      "loss": 0.016,
      "step": 19190
    },
    {
      "epoch": 2.3132530120481927,
      "grad_norm": 8.729686737060547,
      "learning_rate": 1.5373493975903615e-05,
      "loss": 0.0641,
      "step": 19200
    },
    {
      "epoch": 2.314457831325301,
      "grad_norm": 3.611737012863159,
      "learning_rate": 1.5371084337349396e-05,
      "loss": 0.0648,
      "step": 19210
    },
    {
      "epoch": 2.31566265060241,
      "grad_norm": 0.49114516377449036,
      "learning_rate": 1.5368674698795185e-05,
      "loss": 0.0773,
      "step": 19220
    },
    {
      "epoch": 2.316867469879518,
      "grad_norm": 3.022864580154419,
      "learning_rate": 1.5366265060240966e-05,
      "loss": 0.0577,
      "step": 19230
    },
    {
      "epoch": 2.3180722891566266,
      "grad_norm": 2.9629106521606445,
      "learning_rate": 1.5363855421686748e-05,
      "loss": 0.0245,
      "step": 19240
    },
    {
      "epoch": 2.319277108433735,
      "grad_norm": 0.0523284450173378,
      "learning_rate": 1.5361445783132532e-05,
      "loss": 0.0584,
      "step": 19250
    },
    {
      "epoch": 2.3204819277108433,
      "grad_norm": 0.0538913756608963,
      "learning_rate": 1.5359036144578314e-05,
      "loss": 0.03,
      "step": 19260
    },
    {
      "epoch": 2.3216867469879516,
      "grad_norm": 3.3538711071014404,
      "learning_rate": 1.5356626506024095e-05,
      "loss": 0.1004,
      "step": 19270
    },
    {
      "epoch": 2.32289156626506,
      "grad_norm": 4.6256256103515625,
      "learning_rate": 1.535421686746988e-05,
      "loss": 0.0581,
      "step": 19280
    },
    {
      "epoch": 2.324096385542169,
      "grad_norm": 8.180669784545898,
      "learning_rate": 1.5351807228915665e-05,
      "loss": 0.0698,
      "step": 19290
    },
    {
      "epoch": 2.325301204819277,
      "grad_norm": 9.349681854248047,
      "learning_rate": 1.5349397590361447e-05,
      "loss": 0.0445,
      "step": 19300
    },
    {
      "epoch": 2.3265060240963855,
      "grad_norm": 0.02701137587428093,
      "learning_rate": 1.534698795180723e-05,
      "loss": 0.1015,
      "step": 19310
    },
    {
      "epoch": 2.327710843373494,
      "grad_norm": 3.7122960090637207,
      "learning_rate": 1.5344578313253013e-05,
      "loss": 0.0484,
      "step": 19320
    },
    {
      "epoch": 2.3289156626506022,
      "grad_norm": 0.09848790615797043,
      "learning_rate": 1.5342168674698798e-05,
      "loss": 0.0633,
      "step": 19330
    },
    {
      "epoch": 2.330120481927711,
      "grad_norm": 0.860954225063324,
      "learning_rate": 1.533975903614458e-05,
      "loss": 0.0565,
      "step": 19340
    },
    {
      "epoch": 2.3313253012048194,
      "grad_norm": 8.440497398376465,
      "learning_rate": 1.533734939759036e-05,
      "loss": 0.1169,
      "step": 19350
    },
    {
      "epoch": 2.3325301204819278,
      "grad_norm": 1.6227388381958008,
      "learning_rate": 1.5334939759036146e-05,
      "loss": 0.0376,
      "step": 19360
    },
    {
      "epoch": 2.333734939759036,
      "grad_norm": 0.5885711908340454,
      "learning_rate": 1.533253012048193e-05,
      "loss": 0.0428,
      "step": 19370
    },
    {
      "epoch": 2.3349397590361445,
      "grad_norm": 0.08975284546613693,
      "learning_rate": 1.5330120481927712e-05,
      "loss": 0.0565,
      "step": 19380
    },
    {
      "epoch": 2.336144578313253,
      "grad_norm": 0.029705990105867386,
      "learning_rate": 1.5327710843373497e-05,
      "loss": 0.0527,
      "step": 19390
    },
    {
      "epoch": 2.337349397590361,
      "grad_norm": 0.022003252059221268,
      "learning_rate": 1.532530120481928e-05,
      "loss": 0.0306,
      "step": 19400
    },
    {
      "epoch": 2.33855421686747,
      "grad_norm": 0.009874272160232067,
      "learning_rate": 1.532289156626506e-05,
      "loss": 0.1193,
      "step": 19410
    },
    {
      "epoch": 2.3397590361445784,
      "grad_norm": 15.678936004638672,
      "learning_rate": 1.5320481927710845e-05,
      "loss": 0.0402,
      "step": 19420
    },
    {
      "epoch": 2.3409638554216867,
      "grad_norm": 0.24779286980628967,
      "learning_rate": 1.5318072289156626e-05,
      "loss": 0.0545,
      "step": 19430
    },
    {
      "epoch": 2.342168674698795,
      "grad_norm": 0.08378369361162186,
      "learning_rate": 1.531566265060241e-05,
      "loss": 0.0742,
      "step": 19440
    },
    {
      "epoch": 2.3433734939759034,
      "grad_norm": 0.19537965953350067,
      "learning_rate": 1.5313253012048196e-05,
      "loss": 0.0029,
      "step": 19450
    },
    {
      "epoch": 2.3445783132530122,
      "grad_norm": 0.11453773826360703,
      "learning_rate": 1.5310843373493977e-05,
      "loss": 0.072,
      "step": 19460
    },
    {
      "epoch": 2.3457831325301206,
      "grad_norm": 3.153109073638916,
      "learning_rate": 1.530843373493976e-05,
      "loss": 0.0888,
      "step": 19470
    },
    {
      "epoch": 2.346987951807229,
      "grad_norm": 5.276531219482422,
      "learning_rate": 1.5306024096385544e-05,
      "loss": 0.1143,
      "step": 19480
    },
    {
      "epoch": 2.3481927710843373,
      "grad_norm": 6.131783962249756,
      "learning_rate": 1.5303614457831325e-05,
      "loss": 0.0859,
      "step": 19490
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 4.855130672454834,
      "learning_rate": 1.530120481927711e-05,
      "loss": 0.0448,
      "step": 19500
    },
    {
      "epoch": 2.350602409638554,
      "grad_norm": 0.21008074283599854,
      "learning_rate": 1.529879518072289e-05,
      "loss": 0.0452,
      "step": 19510
    },
    {
      "epoch": 2.3518072289156624,
      "grad_norm": 1.5606589317321777,
      "learning_rate": 1.5296385542168677e-05,
      "loss": 0.0221,
      "step": 19520
    },
    {
      "epoch": 2.353012048192771,
      "grad_norm": 2.9467921257019043,
      "learning_rate": 1.529397590361446e-05,
      "loss": 0.0318,
      "step": 19530
    },
    {
      "epoch": 2.3542168674698796,
      "grad_norm": 0.09106653928756714,
      "learning_rate": 1.5291566265060243e-05,
      "loss": 0.064,
      "step": 19540
    },
    {
      "epoch": 2.355421686746988,
      "grad_norm": 0.45085787773132324,
      "learning_rate": 1.5289156626506024e-05,
      "loss": 0.0575,
      "step": 19550
    },
    {
      "epoch": 2.3566265060240963,
      "grad_norm": 3.520981788635254,
      "learning_rate": 1.528674698795181e-05,
      "loss": 0.0617,
      "step": 19560
    },
    {
      "epoch": 2.3578313253012047,
      "grad_norm": 1.9868308305740356,
      "learning_rate": 1.528433734939759e-05,
      "loss": 0.0497,
      "step": 19570
    },
    {
      "epoch": 2.3590361445783135,
      "grad_norm": 0.06469681113958359,
      "learning_rate": 1.5281927710843376e-05,
      "loss": 0.0579,
      "step": 19580
    },
    {
      "epoch": 2.360240963855422,
      "grad_norm": 0.3436177968978882,
      "learning_rate": 1.527951807228916e-05,
      "loss": 0.0284,
      "step": 19590
    },
    {
      "epoch": 2.36144578313253,
      "grad_norm": 7.003785133361816,
      "learning_rate": 1.5277108433734942e-05,
      "loss": 0.0979,
      "step": 19600
    },
    {
      "epoch": 2.3626506024096385,
      "grad_norm": 12.304089546203613,
      "learning_rate": 1.5274698795180723e-05,
      "loss": 0.0503,
      "step": 19610
    },
    {
      "epoch": 2.363855421686747,
      "grad_norm": 0.06393823027610779,
      "learning_rate": 1.5272289156626508e-05,
      "loss": 0.1098,
      "step": 19620
    },
    {
      "epoch": 2.3650602409638553,
      "grad_norm": 0.43017157912254333,
      "learning_rate": 1.526987951807229e-05,
      "loss": 0.0963,
      "step": 19630
    },
    {
      "epoch": 2.3662650602409636,
      "grad_norm": 0.0959765613079071,
      "learning_rate": 1.5267469879518075e-05,
      "loss": 0.0474,
      "step": 19640
    },
    {
      "epoch": 2.3674698795180724,
      "grad_norm": 3.9182205200195312,
      "learning_rate": 1.5265060240963856e-05,
      "loss": 0.0535,
      "step": 19650
    },
    {
      "epoch": 2.3686746987951808,
      "grad_norm": 0.11117396503686905,
      "learning_rate": 1.5262650602409638e-05,
      "loss": 0.0272,
      "step": 19660
    },
    {
      "epoch": 2.369879518072289,
      "grad_norm": 2.3721091747283936,
      "learning_rate": 1.5260240963855422e-05,
      "loss": 0.0466,
      "step": 19670
    },
    {
      "epoch": 2.3710843373493975,
      "grad_norm": 7.195432662963867,
      "learning_rate": 1.5257831325301207e-05,
      "loss": 0.0245,
      "step": 19680
    },
    {
      "epoch": 2.372289156626506,
      "grad_norm": 10.691764831542969,
      "learning_rate": 1.5255421686746989e-05,
      "loss": 0.0425,
      "step": 19690
    },
    {
      "epoch": 2.3734939759036147,
      "grad_norm": 3.4522061347961426,
      "learning_rate": 1.5253012048192772e-05,
      "loss": 0.0135,
      "step": 19700
    },
    {
      "epoch": 2.374698795180723,
      "grad_norm": 1.2120295763015747,
      "learning_rate": 1.5250602409638555e-05,
      "loss": 0.0931,
      "step": 19710
    },
    {
      "epoch": 2.3759036144578314,
      "grad_norm": 0.12524060904979706,
      "learning_rate": 1.5248192771084338e-05,
      "loss": 0.0777,
      "step": 19720
    },
    {
      "epoch": 2.3771084337349397,
      "grad_norm": 0.2980371117591858,
      "learning_rate": 1.5245783132530122e-05,
      "loss": 0.0675,
      "step": 19730
    },
    {
      "epoch": 2.378313253012048,
      "grad_norm": 2.578566551208496,
      "learning_rate": 1.5243373493975906e-05,
      "loss": 0.0497,
      "step": 19740
    },
    {
      "epoch": 2.3795180722891565,
      "grad_norm": 3.233039140701294,
      "learning_rate": 1.524096385542169e-05,
      "loss": 0.048,
      "step": 19750
    },
    {
      "epoch": 2.380722891566265,
      "grad_norm": 6.026044845581055,
      "learning_rate": 1.5238554216867471e-05,
      "loss": 0.0427,
      "step": 19760
    },
    {
      "epoch": 2.3819277108433736,
      "grad_norm": 0.25793877243995667,
      "learning_rate": 1.5236144578313254e-05,
      "loss": 0.0449,
      "step": 19770
    },
    {
      "epoch": 2.383132530120482,
      "grad_norm": 4.765401363372803,
      "learning_rate": 1.5233734939759037e-05,
      "loss": 0.0369,
      "step": 19780
    },
    {
      "epoch": 2.3843373493975903,
      "grad_norm": 3.3530094623565674,
      "learning_rate": 1.523132530120482e-05,
      "loss": 0.049,
      "step": 19790
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 0.10832551121711731,
      "learning_rate": 1.5228915662650604e-05,
      "loss": 0.0422,
      "step": 19800
    },
    {
      "epoch": 2.386746987951807,
      "grad_norm": 0.3803729712963104,
      "learning_rate": 1.5226506024096385e-05,
      "loss": 0.0347,
      "step": 19810
    },
    {
      "epoch": 2.387951807228916,
      "grad_norm": 2.284140110015869,
      "learning_rate": 1.522409638554217e-05,
      "loss": 0.038,
      "step": 19820
    },
    {
      "epoch": 2.3891566265060242,
      "grad_norm": 0.046765126287937164,
      "learning_rate": 1.5221686746987953e-05,
      "loss": 0.0934,
      "step": 19830
    },
    {
      "epoch": 2.3903614457831326,
      "grad_norm": 2.3811800479888916,
      "learning_rate": 1.5219277108433736e-05,
      "loss": 0.0763,
      "step": 19840
    },
    {
      "epoch": 2.391566265060241,
      "grad_norm": 0.8047026991844177,
      "learning_rate": 1.521686746987952e-05,
      "loss": 0.0842,
      "step": 19850
    },
    {
      "epoch": 2.3927710843373493,
      "grad_norm": 0.2606673538684845,
      "learning_rate": 1.5214457831325303e-05,
      "loss": 0.0426,
      "step": 19860
    },
    {
      "epoch": 2.3939759036144577,
      "grad_norm": 0.046368736773729324,
      "learning_rate": 1.5212048192771084e-05,
      "loss": 0.0395,
      "step": 19870
    },
    {
      "epoch": 2.395180722891566,
      "grad_norm": 9.404230117797852,
      "learning_rate": 1.5209638554216867e-05,
      "loss": 0.0392,
      "step": 19880
    },
    {
      "epoch": 2.396385542168675,
      "grad_norm": 0.08823947608470917,
      "learning_rate": 1.5207228915662652e-05,
      "loss": 0.0443,
      "step": 19890
    },
    {
      "epoch": 2.397590361445783,
      "grad_norm": 0.028882410377264023,
      "learning_rate": 1.5204819277108436e-05,
      "loss": 0.0667,
      "step": 19900
    },
    {
      "epoch": 2.3987951807228916,
      "grad_norm": 5.402450084686279,
      "learning_rate": 1.5202409638554219e-05,
      "loss": 0.1079,
      "step": 19910
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.18288928270339966,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.0334,
      "step": 19920
    },
    {
      "epoch": 2.4012048192771083,
      "grad_norm": 3.243464231491089,
      "learning_rate": 1.5197590361445785e-05,
      "loss": 0.0769,
      "step": 19930
    },
    {
      "epoch": 2.402409638554217,
      "grad_norm": 0.3364044427871704,
      "learning_rate": 1.5195180722891567e-05,
      "loss": 0.0651,
      "step": 19940
    },
    {
      "epoch": 2.4036144578313254,
      "grad_norm": 0.736463725566864,
      "learning_rate": 1.519277108433735e-05,
      "loss": 0.0293,
      "step": 19950
    },
    {
      "epoch": 2.404819277108434,
      "grad_norm": 2.8208041191101074,
      "learning_rate": 1.5190361445783133e-05,
      "loss": 0.077,
      "step": 19960
    },
    {
      "epoch": 2.406024096385542,
      "grad_norm": 1.0018627643585205,
      "learning_rate": 1.5187951807228918e-05,
      "loss": 0.021,
      "step": 19970
    },
    {
      "epoch": 2.4072289156626505,
      "grad_norm": 6.022798538208008,
      "learning_rate": 1.5185542168674701e-05,
      "loss": 0.033,
      "step": 19980
    },
    {
      "epoch": 2.408433734939759,
      "grad_norm": 0.22098101675510406,
      "learning_rate": 1.5183132530120484e-05,
      "loss": 0.0592,
      "step": 19990
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 2.0491535663604736,
      "learning_rate": 1.5180722891566266e-05,
      "loss": 0.1075,
      "step": 20000
    },
    {
      "epoch": 2.410843373493976,
      "grad_norm": 5.09995698928833,
      "learning_rate": 1.5178313253012049e-05,
      "loss": 0.0408,
      "step": 20010
    },
    {
      "epoch": 2.4120481927710844,
      "grad_norm": 5.047077178955078,
      "learning_rate": 1.5175903614457832e-05,
      "loss": 0.0626,
      "step": 20020
    },
    {
      "epoch": 2.4132530120481928,
      "grad_norm": 4.4757466316223145,
      "learning_rate": 1.5173493975903615e-05,
      "loss": 0.1251,
      "step": 20030
    },
    {
      "epoch": 2.414457831325301,
      "grad_norm": 4.558470726013184,
      "learning_rate": 1.51710843373494e-05,
      "loss": 0.0545,
      "step": 20040
    },
    {
      "epoch": 2.4156626506024095,
      "grad_norm": 10.337174415588379,
      "learning_rate": 1.5168674698795183e-05,
      "loss": 0.057,
      "step": 20050
    },
    {
      "epoch": 2.4168674698795183,
      "grad_norm": 1.4552440643310547,
      "learning_rate": 1.5166265060240966e-05,
      "loss": 0.0517,
      "step": 20060
    },
    {
      "epoch": 2.4180722891566266,
      "grad_norm": 6.038424015045166,
      "learning_rate": 1.5163855421686748e-05,
      "loss": 0.0507,
      "step": 20070
    },
    {
      "epoch": 2.419277108433735,
      "grad_norm": 0.01566331647336483,
      "learning_rate": 1.5161445783132531e-05,
      "loss": 0.0693,
      "step": 20080
    },
    {
      "epoch": 2.4204819277108434,
      "grad_norm": 0.3331558406352997,
      "learning_rate": 1.5159036144578314e-05,
      "loss": 0.0472,
      "step": 20090
    },
    {
      "epoch": 2.4216867469879517,
      "grad_norm": 0.2084539532661438,
      "learning_rate": 1.5156626506024097e-05,
      "loss": 0.1102,
      "step": 20100
    },
    {
      "epoch": 2.42289156626506,
      "grad_norm": 3.7412495613098145,
      "learning_rate": 1.515421686746988e-05,
      "loss": 0.0193,
      "step": 20110
    },
    {
      "epoch": 2.4240963855421684,
      "grad_norm": 0.12472778558731079,
      "learning_rate": 1.5151807228915665e-05,
      "loss": 0.0353,
      "step": 20120
    },
    {
      "epoch": 2.4253012048192772,
      "grad_norm": 13.45036506652832,
      "learning_rate": 1.5149397590361447e-05,
      "loss": 0.0333,
      "step": 20130
    },
    {
      "epoch": 2.4265060240963856,
      "grad_norm": 3.987401247024536,
      "learning_rate": 1.514698795180723e-05,
      "loss": 0.0682,
      "step": 20140
    },
    {
      "epoch": 2.427710843373494,
      "grad_norm": 6.674914360046387,
      "learning_rate": 1.5144578313253013e-05,
      "loss": 0.0689,
      "step": 20150
    },
    {
      "epoch": 2.4289156626506023,
      "grad_norm": 5.497873306274414,
      "learning_rate": 1.5142168674698796e-05,
      "loss": 0.0568,
      "step": 20160
    },
    {
      "epoch": 2.4301204819277107,
      "grad_norm": 4.446752071380615,
      "learning_rate": 1.513975903614458e-05,
      "loss": 0.0414,
      "step": 20170
    },
    {
      "epoch": 2.4313253012048195,
      "grad_norm": 0.0534549281001091,
      "learning_rate": 1.5137349397590361e-05,
      "loss": 0.0784,
      "step": 20180
    },
    {
      "epoch": 2.432530120481928,
      "grad_norm": 0.02937825210392475,
      "learning_rate": 1.5134939759036148e-05,
      "loss": 0.0301,
      "step": 20190
    },
    {
      "epoch": 2.433734939759036,
      "grad_norm": 0.35074931383132935,
      "learning_rate": 1.5132530120481929e-05,
      "loss": 0.0738,
      "step": 20200
    },
    {
      "epoch": 2.4349397590361446,
      "grad_norm": 8.256575584411621,
      "learning_rate": 1.5130120481927712e-05,
      "loss": 0.0805,
      "step": 20210
    },
    {
      "epoch": 2.436144578313253,
      "grad_norm": 0.11682882905006409,
      "learning_rate": 1.5127710843373495e-05,
      "loss": 0.0216,
      "step": 20220
    },
    {
      "epoch": 2.4373493975903613,
      "grad_norm": 3.2995598316192627,
      "learning_rate": 1.5125301204819279e-05,
      "loss": 0.0373,
      "step": 20230
    },
    {
      "epoch": 2.4385542168674696,
      "grad_norm": 0.13362693786621094,
      "learning_rate": 1.5122891566265062e-05,
      "loss": 0.0936,
      "step": 20240
    },
    {
      "epoch": 2.4397590361445785,
      "grad_norm": 5.575793266296387,
      "learning_rate": 1.5120481927710843e-05,
      "loss": 0.0517,
      "step": 20250
    },
    {
      "epoch": 2.440963855421687,
      "grad_norm": 32.765995025634766,
      "learning_rate": 1.5118072289156626e-05,
      "loss": 0.0898,
      "step": 20260
    },
    {
      "epoch": 2.442168674698795,
      "grad_norm": 2.5481626987457275,
      "learning_rate": 1.5115662650602411e-05,
      "loss": 0.0456,
      "step": 20270
    },
    {
      "epoch": 2.4433734939759035,
      "grad_norm": 0.3464494049549103,
      "learning_rate": 1.5113253012048194e-05,
      "loss": 0.0478,
      "step": 20280
    },
    {
      "epoch": 2.444578313253012,
      "grad_norm": 7.070931434631348,
      "learning_rate": 1.5110843373493978e-05,
      "loss": 0.0872,
      "step": 20290
    },
    {
      "epoch": 2.4457831325301207,
      "grad_norm": 2.4142119884490967,
      "learning_rate": 1.5108433734939761e-05,
      "loss": 0.0398,
      "step": 20300
    },
    {
      "epoch": 2.446987951807229,
      "grad_norm": 0.1504652351140976,
      "learning_rate": 1.5106024096385542e-05,
      "loss": 0.0388,
      "step": 20310
    },
    {
      "epoch": 2.4481927710843374,
      "grad_norm": 2.0831120014190674,
      "learning_rate": 1.5103614457831326e-05,
      "loss": 0.0537,
      "step": 20320
    },
    {
      "epoch": 2.4493975903614458,
      "grad_norm": 1.7301276922225952,
      "learning_rate": 1.5101204819277109e-05,
      "loss": 0.0361,
      "step": 20330
    },
    {
      "epoch": 2.450602409638554,
      "grad_norm": 0.03155292570590973,
      "learning_rate": 1.5098795180722894e-05,
      "loss": 0.068,
      "step": 20340
    },
    {
      "epoch": 2.4518072289156625,
      "grad_norm": 2.1303703784942627,
      "learning_rate": 1.5096385542168677e-05,
      "loss": 0.0994,
      "step": 20350
    },
    {
      "epoch": 2.453012048192771,
      "grad_norm": 6.941351890563965,
      "learning_rate": 1.509397590361446e-05,
      "loss": 0.0427,
      "step": 20360
    },
    {
      "epoch": 2.4542168674698797,
      "grad_norm": 0.06992421299219131,
      "learning_rate": 1.5091566265060243e-05,
      "loss": 0.1044,
      "step": 20370
    },
    {
      "epoch": 2.455421686746988,
      "grad_norm": 5.058018207550049,
      "learning_rate": 1.5089156626506025e-05,
      "loss": 0.1438,
      "step": 20380
    },
    {
      "epoch": 2.4566265060240964,
      "grad_norm": 0.42044341564178467,
      "learning_rate": 1.5086746987951808e-05,
      "loss": 0.1146,
      "step": 20390
    },
    {
      "epoch": 2.4578313253012047,
      "grad_norm": 6.741610527038574,
      "learning_rate": 1.5084337349397591e-05,
      "loss": 0.0711,
      "step": 20400
    },
    {
      "epoch": 2.459036144578313,
      "grad_norm": 5.620208740234375,
      "learning_rate": 1.5081927710843374e-05,
      "loss": 0.082,
      "step": 20410
    },
    {
      "epoch": 2.460240963855422,
      "grad_norm": 0.2958245873451233,
      "learning_rate": 1.5079518072289159e-05,
      "loss": 0.0288,
      "step": 20420
    },
    {
      "epoch": 2.4614457831325303,
      "grad_norm": 0.18640518188476562,
      "learning_rate": 1.5077108433734942e-05,
      "loss": 0.0645,
      "step": 20430
    },
    {
      "epoch": 2.4626506024096386,
      "grad_norm": 6.227814674377441,
      "learning_rate": 1.5074698795180724e-05,
      "loss": 0.0545,
      "step": 20440
    },
    {
      "epoch": 2.463855421686747,
      "grad_norm": 0.09913962334394455,
      "learning_rate": 1.5072289156626507e-05,
      "loss": 0.1162,
      "step": 20450
    },
    {
      "epoch": 2.4650602409638553,
      "grad_norm": 4.631453037261963,
      "learning_rate": 1.506987951807229e-05,
      "loss": 0.0479,
      "step": 20460
    },
    {
      "epoch": 2.4662650602409637,
      "grad_norm": 5.4350972175598145,
      "learning_rate": 1.5067469879518073e-05,
      "loss": 0.0563,
      "step": 20470
    },
    {
      "epoch": 2.467469879518072,
      "grad_norm": 0.03701888024806976,
      "learning_rate": 1.5065060240963856e-05,
      "loss": 0.0196,
      "step": 20480
    },
    {
      "epoch": 2.468674698795181,
      "grad_norm": 0.15492568910121918,
      "learning_rate": 1.5062650602409641e-05,
      "loss": 0.0364,
      "step": 20490
    },
    {
      "epoch": 2.4698795180722892,
      "grad_norm": 0.4925316572189331,
      "learning_rate": 1.5060240963855424e-05,
      "loss": 0.0402,
      "step": 20500
    },
    {
      "epoch": 2.4710843373493976,
      "grad_norm": 6.809244632720947,
      "learning_rate": 1.5057831325301206e-05,
      "loss": 0.0539,
      "step": 20510
    },
    {
      "epoch": 2.472289156626506,
      "grad_norm": 4.464419364929199,
      "learning_rate": 1.5055421686746989e-05,
      "loss": 0.0654,
      "step": 20520
    },
    {
      "epoch": 2.4734939759036143,
      "grad_norm": 0.7771166563034058,
      "learning_rate": 1.5053012048192772e-05,
      "loss": 0.0386,
      "step": 20530
    },
    {
      "epoch": 2.474698795180723,
      "grad_norm": 2.6206722259521484,
      "learning_rate": 1.5050602409638555e-05,
      "loss": 0.0418,
      "step": 20540
    },
    {
      "epoch": 2.4759036144578315,
      "grad_norm": 0.03890112414956093,
      "learning_rate": 1.5048192771084339e-05,
      "loss": 0.0302,
      "step": 20550
    },
    {
      "epoch": 2.47710843373494,
      "grad_norm": 11.482769012451172,
      "learning_rate": 1.504578313253012e-05,
      "loss": 0.058,
      "step": 20560
    },
    {
      "epoch": 2.478313253012048,
      "grad_norm": 0.022346338257193565,
      "learning_rate": 1.5043373493975905e-05,
      "loss": 0.0037,
      "step": 20570
    },
    {
      "epoch": 2.4795180722891565,
      "grad_norm": 0.18862567842006683,
      "learning_rate": 1.5040963855421688e-05,
      "loss": 0.0855,
      "step": 20580
    },
    {
      "epoch": 2.480722891566265,
      "grad_norm": 0.00745548028498888,
      "learning_rate": 1.5038554216867471e-05,
      "loss": 0.0193,
      "step": 20590
    },
    {
      "epoch": 2.4819277108433733,
      "grad_norm": 10.201120376586914,
      "learning_rate": 1.5036144578313254e-05,
      "loss": 0.0433,
      "step": 20600
    },
    {
      "epoch": 2.483132530120482,
      "grad_norm": 0.013441323302686214,
      "learning_rate": 1.5033734939759038e-05,
      "loss": 0.0433,
      "step": 20610
    },
    {
      "epoch": 2.4843373493975904,
      "grad_norm": 0.1070772111415863,
      "learning_rate": 1.5031325301204819e-05,
      "loss": 0.0507,
      "step": 20620
    },
    {
      "epoch": 2.485542168674699,
      "grad_norm": 0.015147647820413113,
      "learning_rate": 1.5028915662650602e-05,
      "loss": 0.0606,
      "step": 20630
    },
    {
      "epoch": 2.486746987951807,
      "grad_norm": 0.0108187235891819,
      "learning_rate": 1.5026506024096387e-05,
      "loss": 0.0125,
      "step": 20640
    },
    {
      "epoch": 2.4879518072289155,
      "grad_norm": 1.2320990562438965,
      "learning_rate": 1.502409638554217e-05,
      "loss": 0.1545,
      "step": 20650
    },
    {
      "epoch": 2.4891566265060243,
      "grad_norm": 5.331304550170898,
      "learning_rate": 1.5021686746987953e-05,
      "loss": 0.0574,
      "step": 20660
    },
    {
      "epoch": 2.4903614457831327,
      "grad_norm": 0.023765278980135918,
      "learning_rate": 1.5019277108433737e-05,
      "loss": 0.0189,
      "step": 20670
    },
    {
      "epoch": 2.491566265060241,
      "grad_norm": 0.21906621754169464,
      "learning_rate": 1.501686746987952e-05,
      "loss": 0.0321,
      "step": 20680
    },
    {
      "epoch": 2.4927710843373494,
      "grad_norm": 0.03071720339357853,
      "learning_rate": 1.5014457831325301e-05,
      "loss": 0.0845,
      "step": 20690
    },
    {
      "epoch": 2.4939759036144578,
      "grad_norm": 2.4123096466064453,
      "learning_rate": 1.5012048192771084e-05,
      "loss": 0.0575,
      "step": 20700
    },
    {
      "epoch": 2.495180722891566,
      "grad_norm": 0.13134893774986267,
      "learning_rate": 1.5009638554216868e-05,
      "loss": 0.0333,
      "step": 20710
    },
    {
      "epoch": 2.4963855421686745,
      "grad_norm": 0.03942526876926422,
      "learning_rate": 1.5007228915662653e-05,
      "loss": 0.039,
      "step": 20720
    },
    {
      "epoch": 2.4975903614457833,
      "grad_norm": 0.22595709562301636,
      "learning_rate": 1.5004819277108436e-05,
      "loss": 0.0477,
      "step": 20730
    },
    {
      "epoch": 2.4987951807228916,
      "grad_norm": 0.07992670685052872,
      "learning_rate": 1.5002409638554219e-05,
      "loss": 0.0826,
      "step": 20740
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.09918901324272156,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.1431,
      "step": 20750
    },
    {
      "epoch": 2.5012048192771084,
      "grad_norm": 0.3565191924571991,
      "learning_rate": 1.4997590361445784e-05,
      "loss": 0.0232,
      "step": 20760
    },
    {
      "epoch": 2.5024096385542167,
      "grad_norm": 2.3565726280212402,
      "learning_rate": 1.4995180722891567e-05,
      "loss": 0.0712,
      "step": 20770
    },
    {
      "epoch": 2.5036144578313255,
      "grad_norm": 0.08472669869661331,
      "learning_rate": 1.499277108433735e-05,
      "loss": 0.0471,
      "step": 20780
    },
    {
      "epoch": 2.504819277108434,
      "grad_norm": 0.2180945724248886,
      "learning_rate": 1.4990361445783135e-05,
      "loss": 0.0575,
      "step": 20790
    },
    {
      "epoch": 2.5060240963855422,
      "grad_norm": 0.05304955318570137,
      "learning_rate": 1.4987951807228918e-05,
      "loss": 0.1202,
      "step": 20800
    },
    {
      "epoch": 2.5072289156626506,
      "grad_norm": 1.9304866790771484,
      "learning_rate": 1.4985542168674701e-05,
      "loss": 0.0438,
      "step": 20810
    },
    {
      "epoch": 2.508433734939759,
      "grad_norm": 0.07190293073654175,
      "learning_rate": 1.4983132530120483e-05,
      "loss": 0.0371,
      "step": 20820
    },
    {
      "epoch": 2.5096385542168673,
      "grad_norm": 0.10977748036384583,
      "learning_rate": 1.4980722891566266e-05,
      "loss": 0.0817,
      "step": 20830
    },
    {
      "epoch": 2.5108433734939757,
      "grad_norm": 0.092218317091465,
      "learning_rate": 1.4978313253012049e-05,
      "loss": 0.0114,
      "step": 20840
    },
    {
      "epoch": 2.5120481927710845,
      "grad_norm": 0.2424992471933365,
      "learning_rate": 1.4975903614457832e-05,
      "loss": 0.0063,
      "step": 20850
    },
    {
      "epoch": 2.513253012048193,
      "grad_norm": 0.038782719522714615,
      "learning_rate": 1.4973493975903615e-05,
      "loss": 0.0713,
      "step": 20860
    },
    {
      "epoch": 2.514457831325301,
      "grad_norm": 8.779550552368164,
      "learning_rate": 1.49710843373494e-05,
      "loss": 0.1345,
      "step": 20870
    },
    {
      "epoch": 2.5156626506024096,
      "grad_norm": 0.061804015189409256,
      "learning_rate": 1.4968674698795183e-05,
      "loss": 0.079,
      "step": 20880
    },
    {
      "epoch": 2.516867469879518,
      "grad_norm": 0.12448081374168396,
      "learning_rate": 1.4966265060240965e-05,
      "loss": 0.0791,
      "step": 20890
    },
    {
      "epoch": 2.5180722891566267,
      "grad_norm": 8.235416412353516,
      "learning_rate": 1.4963855421686748e-05,
      "loss": 0.097,
      "step": 20900
    },
    {
      "epoch": 2.519277108433735,
      "grad_norm": 0.04992174729704857,
      "learning_rate": 1.4961445783132531e-05,
      "loss": 0.0599,
      "step": 20910
    },
    {
      "epoch": 2.5204819277108435,
      "grad_norm": 0.13506828248500824,
      "learning_rate": 1.4959036144578314e-05,
      "loss": 0.0541,
      "step": 20920
    },
    {
      "epoch": 2.521686746987952,
      "grad_norm": 0.020284367725253105,
      "learning_rate": 1.4956626506024098e-05,
      "loss": 0.0347,
      "step": 20930
    },
    {
      "epoch": 2.52289156626506,
      "grad_norm": 0.25226572155952454,
      "learning_rate": 1.4954216867469882e-05,
      "loss": 0.0608,
      "step": 20940
    },
    {
      "epoch": 2.5240963855421685,
      "grad_norm": 0.24941955506801605,
      "learning_rate": 1.4951807228915664e-05,
      "loss": 0.165,
      "step": 20950
    },
    {
      "epoch": 2.525301204819277,
      "grad_norm": 0.04199564829468727,
      "learning_rate": 1.4949397590361447e-05,
      "loss": 0.0279,
      "step": 20960
    },
    {
      "epoch": 2.5265060240963857,
      "grad_norm": 0.046497803181409836,
      "learning_rate": 1.494698795180723e-05,
      "loss": 0.0525,
      "step": 20970
    },
    {
      "epoch": 2.527710843373494,
      "grad_norm": 0.39533311128616333,
      "learning_rate": 1.4944578313253013e-05,
      "loss": 0.0568,
      "step": 20980
    },
    {
      "epoch": 2.5289156626506024,
      "grad_norm": 5.503062725067139,
      "learning_rate": 1.4942168674698797e-05,
      "loss": 0.1322,
      "step": 20990
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 2.4474425315856934,
      "learning_rate": 1.4939759036144578e-05,
      "loss": 0.1599,
      "step": 21000
    },
    {
      "epoch": 2.531325301204819,
      "grad_norm": 0.480651319026947,
      "learning_rate": 1.4937349397590361e-05,
      "loss": 0.0187,
      "step": 21010
    },
    {
      "epoch": 2.532530120481928,
      "grad_norm": 0.11019565165042877,
      "learning_rate": 1.4934939759036146e-05,
      "loss": 0.0782,
      "step": 21020
    },
    {
      "epoch": 2.5337349397590363,
      "grad_norm": 1.9369577169418335,
      "learning_rate": 1.493253012048193e-05,
      "loss": 0.0671,
      "step": 21030
    },
    {
      "epoch": 2.5349397590361447,
      "grad_norm": 0.03689133748412132,
      "learning_rate": 1.4930120481927712e-05,
      "loss": 0.0432,
      "step": 21040
    },
    {
      "epoch": 2.536144578313253,
      "grad_norm": 0.940848708152771,
      "learning_rate": 1.4927710843373496e-05,
      "loss": 0.0677,
      "step": 21050
    },
    {
      "epoch": 2.5373493975903614,
      "grad_norm": 6.170387268066406,
      "learning_rate": 1.4925301204819279e-05,
      "loss": 0.1064,
      "step": 21060
    },
    {
      "epoch": 2.5385542168674697,
      "grad_norm": 0.48353469371795654,
      "learning_rate": 1.492289156626506e-05,
      "loss": 0.0314,
      "step": 21070
    },
    {
      "epoch": 2.539759036144578,
      "grad_norm": 1.614828109741211,
      "learning_rate": 1.4920481927710843e-05,
      "loss": 0.0304,
      "step": 21080
    },
    {
      "epoch": 2.540963855421687,
      "grad_norm": 0.02796822600066662,
      "learning_rate": 1.4918072289156628e-05,
      "loss": 0.0742,
      "step": 21090
    },
    {
      "epoch": 2.5421686746987953,
      "grad_norm": 0.1549592912197113,
      "learning_rate": 1.4915662650602412e-05,
      "loss": 0.0196,
      "step": 21100
    },
    {
      "epoch": 2.5433734939759036,
      "grad_norm": 0.4085249602794647,
      "learning_rate": 1.4913253012048195e-05,
      "loss": 0.0575,
      "step": 21110
    },
    {
      "epoch": 2.544578313253012,
      "grad_norm": 0.16545207798480988,
      "learning_rate": 1.4910843373493978e-05,
      "loss": 0.0497,
      "step": 21120
    },
    {
      "epoch": 2.5457831325301203,
      "grad_norm": 0.07158150523900986,
      "learning_rate": 1.490843373493976e-05,
      "loss": 0.0566,
      "step": 21130
    },
    {
      "epoch": 2.546987951807229,
      "grad_norm": 9.671117782592773,
      "learning_rate": 1.4906024096385543e-05,
      "loss": 0.0504,
      "step": 21140
    },
    {
      "epoch": 2.5481927710843375,
      "grad_norm": 2.4663374423980713,
      "learning_rate": 1.4903614457831326e-05,
      "loss": 0.0646,
      "step": 21150
    },
    {
      "epoch": 2.549397590361446,
      "grad_norm": 10.751614570617676,
      "learning_rate": 1.4901204819277109e-05,
      "loss": 0.0688,
      "step": 21160
    },
    {
      "epoch": 2.5506024096385542,
      "grad_norm": 3.1831588745117188,
      "learning_rate": 1.4898795180722894e-05,
      "loss": 0.1144,
      "step": 21170
    },
    {
      "epoch": 2.5518072289156626,
      "grad_norm": 5.074645519256592,
      "learning_rate": 1.4896385542168677e-05,
      "loss": 0.0678,
      "step": 21180
    },
    {
      "epoch": 2.553012048192771,
      "grad_norm": 6.105701923370361,
      "learning_rate": 1.489397590361446e-05,
      "loss": 0.0905,
      "step": 21190
    },
    {
      "epoch": 2.5542168674698793,
      "grad_norm": 0.4186477065086365,
      "learning_rate": 1.4891566265060242e-05,
      "loss": 0.0728,
      "step": 21200
    },
    {
      "epoch": 2.555421686746988,
      "grad_norm": 3.7696964740753174,
      "learning_rate": 1.4889156626506025e-05,
      "loss": 0.0376,
      "step": 21210
    },
    {
      "epoch": 2.5566265060240965,
      "grad_norm": 0.6810622215270996,
      "learning_rate": 1.4886746987951808e-05,
      "loss": 0.1076,
      "step": 21220
    },
    {
      "epoch": 2.557831325301205,
      "grad_norm": 2.796642303466797,
      "learning_rate": 1.4884337349397591e-05,
      "loss": 0.0242,
      "step": 21230
    },
    {
      "epoch": 2.559036144578313,
      "grad_norm": 1.7153007984161377,
      "learning_rate": 1.4881927710843376e-05,
      "loss": 0.0564,
      "step": 21240
    },
    {
      "epoch": 2.5602409638554215,
      "grad_norm": 0.030672850087285042,
      "learning_rate": 1.487951807228916e-05,
      "loss": 0.0839,
      "step": 21250
    },
    {
      "epoch": 2.5614457831325304,
      "grad_norm": 1.831087589263916,
      "learning_rate": 1.487710843373494e-05,
      "loss": 0.0649,
      "step": 21260
    },
    {
      "epoch": 2.5626506024096387,
      "grad_norm": 2.2999515533447266,
      "learning_rate": 1.4874698795180724e-05,
      "loss": 0.0133,
      "step": 21270
    },
    {
      "epoch": 2.563855421686747,
      "grad_norm": 0.3922843635082245,
      "learning_rate": 1.4872289156626507e-05,
      "loss": 0.0413,
      "step": 21280
    },
    {
      "epoch": 2.5650602409638554,
      "grad_norm": 1.0848981142044067,
      "learning_rate": 1.486987951807229e-05,
      "loss": 0.0037,
      "step": 21290
    },
    {
      "epoch": 2.566265060240964,
      "grad_norm": 0.09626787155866623,
      "learning_rate": 1.4867469879518073e-05,
      "loss": 0.0419,
      "step": 21300
    },
    {
      "epoch": 2.567469879518072,
      "grad_norm": 0.018848946318030357,
      "learning_rate": 1.4865060240963855e-05,
      "loss": 0.0778,
      "step": 21310
    },
    {
      "epoch": 2.5686746987951805,
      "grad_norm": 9.027077674865723,
      "learning_rate": 1.4862650602409641e-05,
      "loss": 0.0876,
      "step": 21320
    },
    {
      "epoch": 2.5698795180722893,
      "grad_norm": 0.562655508518219,
      "learning_rate": 1.4860240963855423e-05,
      "loss": 0.0365,
      "step": 21330
    },
    {
      "epoch": 2.5710843373493977,
      "grad_norm": 0.20573854446411133,
      "learning_rate": 1.4857831325301206e-05,
      "loss": 0.093,
      "step": 21340
    },
    {
      "epoch": 2.572289156626506,
      "grad_norm": 2.252319812774658,
      "learning_rate": 1.485542168674699e-05,
      "loss": 0.0941,
      "step": 21350
    },
    {
      "epoch": 2.5734939759036144,
      "grad_norm": 0.33311039209365845,
      "learning_rate": 1.4853012048192772e-05,
      "loss": 0.0549,
      "step": 21360
    },
    {
      "epoch": 2.5746987951807228,
      "grad_norm": 0.014176693744957447,
      "learning_rate": 1.4850602409638556e-05,
      "loss": 0.0304,
      "step": 21370
    },
    {
      "epoch": 2.5759036144578316,
      "grad_norm": 1.3400343656539917,
      "learning_rate": 1.4848192771084337e-05,
      "loss": 0.0485,
      "step": 21380
    },
    {
      "epoch": 2.57710843373494,
      "grad_norm": 3.0645089149475098,
      "learning_rate": 1.4845783132530122e-05,
      "loss": 0.0497,
      "step": 21390
    },
    {
      "epoch": 2.5783132530120483,
      "grad_norm": 0.09568965435028076,
      "learning_rate": 1.4843373493975905e-05,
      "loss": 0.0545,
      "step": 21400
    },
    {
      "epoch": 2.5795180722891566,
      "grad_norm": 4.528745174407959,
      "learning_rate": 1.4840963855421688e-05,
      "loss": 0.0559,
      "step": 21410
    },
    {
      "epoch": 2.580722891566265,
      "grad_norm": 7.030886173248291,
      "learning_rate": 1.4838554216867471e-05,
      "loss": 0.094,
      "step": 21420
    },
    {
      "epoch": 2.5819277108433734,
      "grad_norm": 0.38236233592033386,
      "learning_rate": 1.4836144578313255e-05,
      "loss": 0.0854,
      "step": 21430
    },
    {
      "epoch": 2.5831325301204817,
      "grad_norm": 1.8887054920196533,
      "learning_rate": 1.4833734939759036e-05,
      "loss": 0.0894,
      "step": 21440
    },
    {
      "epoch": 2.5843373493975905,
      "grad_norm": 1.1515177488327026,
      "learning_rate": 1.483132530120482e-05,
      "loss": 0.0372,
      "step": 21450
    },
    {
      "epoch": 2.585542168674699,
      "grad_norm": 4.178260326385498,
      "learning_rate": 1.4828915662650602e-05,
      "loss": 0.0205,
      "step": 21460
    },
    {
      "epoch": 2.5867469879518072,
      "grad_norm": 7.508148670196533,
      "learning_rate": 1.4826506024096387e-05,
      "loss": 0.0275,
      "step": 21470
    },
    {
      "epoch": 2.5879518072289156,
      "grad_norm": 0.08643430471420288,
      "learning_rate": 1.482409638554217e-05,
      "loss": 0.0329,
      "step": 21480
    },
    {
      "epoch": 2.589156626506024,
      "grad_norm": 0.4306037724018097,
      "learning_rate": 1.4821686746987954e-05,
      "loss": 0.0458,
      "step": 21490
    },
    {
      "epoch": 2.5903614457831328,
      "grad_norm": 1.4525036811828613,
      "learning_rate": 1.4819277108433737e-05,
      "loss": 0.0809,
      "step": 21500
    },
    {
      "epoch": 2.591566265060241,
      "grad_norm": 0.062143102288246155,
      "learning_rate": 1.4816867469879518e-05,
      "loss": 0.0558,
      "step": 21510
    },
    {
      "epoch": 2.5927710843373495,
      "grad_norm": 0.3722097873687744,
      "learning_rate": 1.4814457831325302e-05,
      "loss": 0.0111,
      "step": 21520
    },
    {
      "epoch": 2.593975903614458,
      "grad_norm": 2.965034246444702,
      "learning_rate": 1.4812048192771085e-05,
      "loss": 0.0435,
      "step": 21530
    },
    {
      "epoch": 2.595180722891566,
      "grad_norm": 0.0954645425081253,
      "learning_rate": 1.480963855421687e-05,
      "loss": 0.0893,
      "step": 21540
    },
    {
      "epoch": 2.5963855421686746,
      "grad_norm": 0.039413195103406906,
      "learning_rate": 1.4807228915662653e-05,
      "loss": 0.0304,
      "step": 21550
    },
    {
      "epoch": 2.597590361445783,
      "grad_norm": 0.09175867587327957,
      "learning_rate": 1.4804819277108436e-05,
      "loss": 0.0588,
      "step": 21560
    },
    {
      "epoch": 2.5987951807228917,
      "grad_norm": 0.04839380085468292,
      "learning_rate": 1.4802409638554217e-05,
      "loss": 0.0643,
      "step": 21570
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.30799001455307007,
      "learning_rate": 1.48e-05,
      "loss": 0.0929,
      "step": 21580
    },
    {
      "epoch": 2.6012048192771084,
      "grad_norm": 0.10901831835508347,
      "learning_rate": 1.4797590361445784e-05,
      "loss": 0.0131,
      "step": 21590
    },
    {
      "epoch": 2.602409638554217,
      "grad_norm": 0.24603012204170227,
      "learning_rate": 1.4795180722891567e-05,
      "loss": 0.1086,
      "step": 21600
    },
    {
      "epoch": 2.603614457831325,
      "grad_norm": 0.10162226855754852,
      "learning_rate": 1.479277108433735e-05,
      "loss": 0.039,
      "step": 21610
    },
    {
      "epoch": 2.604819277108434,
      "grad_norm": 0.15489090979099274,
      "learning_rate": 1.4790361445783135e-05,
      "loss": 0.0114,
      "step": 21620
    },
    {
      "epoch": 2.6060240963855423,
      "grad_norm": 8.060442924499512,
      "learning_rate": 1.4787951807228918e-05,
      "loss": 0.0515,
      "step": 21630
    },
    {
      "epoch": 2.6072289156626507,
      "grad_norm": 0.01846804842352867,
      "learning_rate": 1.47855421686747e-05,
      "loss": 0.0045,
      "step": 21640
    },
    {
      "epoch": 2.608433734939759,
      "grad_norm": 0.7604618072509766,
      "learning_rate": 1.4783132530120483e-05,
      "loss": 0.059,
      "step": 21650
    },
    {
      "epoch": 2.6096385542168674,
      "grad_norm": 0.057301316410303116,
      "learning_rate": 1.4780722891566266e-05,
      "loss": 0.1405,
      "step": 21660
    },
    {
      "epoch": 2.6108433734939758,
      "grad_norm": 0.30081868171691895,
      "learning_rate": 1.477831325301205e-05,
      "loss": 0.0359,
      "step": 21670
    },
    {
      "epoch": 2.612048192771084,
      "grad_norm": 3.2924020290374756,
      "learning_rate": 1.4775903614457832e-05,
      "loss": 0.0481,
      "step": 21680
    },
    {
      "epoch": 2.613253012048193,
      "grad_norm": 4.558946132659912,
      "learning_rate": 1.4773493975903617e-05,
      "loss": 0.1032,
      "step": 21690
    },
    {
      "epoch": 2.6144578313253013,
      "grad_norm": 0.07951182872056961,
      "learning_rate": 1.4771084337349399e-05,
      "loss": 0.0266,
      "step": 21700
    },
    {
      "epoch": 2.6156626506024097,
      "grad_norm": 4.353614330291748,
      "learning_rate": 1.4768674698795182e-05,
      "loss": 0.0454,
      "step": 21710
    },
    {
      "epoch": 2.616867469879518,
      "grad_norm": 0.1679687350988388,
      "learning_rate": 1.4766265060240965e-05,
      "loss": 0.068,
      "step": 21720
    },
    {
      "epoch": 2.6180722891566264,
      "grad_norm": 6.949646472930908,
      "learning_rate": 1.4763855421686748e-05,
      "loss": 0.0491,
      "step": 21730
    },
    {
      "epoch": 2.619277108433735,
      "grad_norm": 4.6770548820495605,
      "learning_rate": 1.4761445783132531e-05,
      "loss": 0.0841,
      "step": 21740
    },
    {
      "epoch": 2.6204819277108435,
      "grad_norm": 0.7600342631340027,
      "learning_rate": 1.4759036144578313e-05,
      "loss": 0.0708,
      "step": 21750
    },
    {
      "epoch": 2.621686746987952,
      "grad_norm": 1.6177210807800293,
      "learning_rate": 1.4756626506024096e-05,
      "loss": 0.0325,
      "step": 21760
    },
    {
      "epoch": 2.6228915662650603,
      "grad_norm": 5.463284969329834,
      "learning_rate": 1.4754216867469881e-05,
      "loss": 0.0544,
      "step": 21770
    },
    {
      "epoch": 2.6240963855421686,
      "grad_norm": 13.285151481628418,
      "learning_rate": 1.4751807228915664e-05,
      "loss": 0.0364,
      "step": 21780
    },
    {
      "epoch": 2.625301204819277,
      "grad_norm": 2.7888495922088623,
      "learning_rate": 1.4749397590361447e-05,
      "loss": 0.0988,
      "step": 21790
    },
    {
      "epoch": 2.6265060240963853,
      "grad_norm": 6.86105489730835,
      "learning_rate": 1.474698795180723e-05,
      "loss": 0.0809,
      "step": 21800
    },
    {
      "epoch": 2.627710843373494,
      "grad_norm": 7.8886895179748535,
      "learning_rate": 1.4744578313253014e-05,
      "loss": 0.0921,
      "step": 21810
    },
    {
      "epoch": 2.6289156626506025,
      "grad_norm": 8.93016242980957,
      "learning_rate": 1.4742168674698795e-05,
      "loss": 0.0437,
      "step": 21820
    },
    {
      "epoch": 2.630120481927711,
      "grad_norm": 0.23648251593112946,
      "learning_rate": 1.4739759036144578e-05,
      "loss": 0.0215,
      "step": 21830
    },
    {
      "epoch": 2.6313253012048192,
      "grad_norm": 0.42530757188796997,
      "learning_rate": 1.4737349397590363e-05,
      "loss": 0.0432,
      "step": 21840
    },
    {
      "epoch": 2.6325301204819276,
      "grad_norm": 0.7034839987754822,
      "learning_rate": 1.4734939759036146e-05,
      "loss": 0.0716,
      "step": 21850
    },
    {
      "epoch": 2.6337349397590364,
      "grad_norm": 0.3695038855075836,
      "learning_rate": 1.473253012048193e-05,
      "loss": 0.0191,
      "step": 21860
    },
    {
      "epoch": 2.6349397590361443,
      "grad_norm": 0.3977493941783905,
      "learning_rate": 1.4730120481927713e-05,
      "loss": 0.0861,
      "step": 21870
    },
    {
      "epoch": 2.636144578313253,
      "grad_norm": 0.008852130733430386,
      "learning_rate": 1.4727710843373494e-05,
      "loss": 0.0181,
      "step": 21880
    },
    {
      "epoch": 2.6373493975903615,
      "grad_norm": 0.06962064653635025,
      "learning_rate": 1.4725301204819277e-05,
      "loss": 0.0334,
      "step": 21890
    },
    {
      "epoch": 2.63855421686747,
      "grad_norm": 0.10107961297035217,
      "learning_rate": 1.472289156626506e-05,
      "loss": 0.0756,
      "step": 21900
    },
    {
      "epoch": 2.639759036144578,
      "grad_norm": 3.2672159671783447,
      "learning_rate": 1.4720481927710844e-05,
      "loss": 0.0613,
      "step": 21910
    },
    {
      "epoch": 2.6409638554216865,
      "grad_norm": 0.03465854749083519,
      "learning_rate": 1.4718072289156629e-05,
      "loss": 0.0767,
      "step": 21920
    },
    {
      "epoch": 2.6421686746987953,
      "grad_norm": 18.336978912353516,
      "learning_rate": 1.4715662650602412e-05,
      "loss": 0.0657,
      "step": 21930
    },
    {
      "epoch": 2.6433734939759037,
      "grad_norm": 0.07428811490535736,
      "learning_rate": 1.4713253012048195e-05,
      "loss": 0.047,
      "step": 21940
    },
    {
      "epoch": 2.644578313253012,
      "grad_norm": 0.2936285138130188,
      "learning_rate": 1.4710843373493976e-05,
      "loss": 0.0164,
      "step": 21950
    },
    {
      "epoch": 2.6457831325301204,
      "grad_norm": 0.09016196429729462,
      "learning_rate": 1.470843373493976e-05,
      "loss": 0.0673,
      "step": 21960
    },
    {
      "epoch": 2.646987951807229,
      "grad_norm": 0.0710645541548729,
      "learning_rate": 1.4706024096385543e-05,
      "loss": 0.0434,
      "step": 21970
    },
    {
      "epoch": 2.6481927710843376,
      "grad_norm": 0.7103622555732727,
      "learning_rate": 1.4703614457831326e-05,
      "loss": 0.1405,
      "step": 21980
    },
    {
      "epoch": 2.6493975903614455,
      "grad_norm": 0.23730997741222382,
      "learning_rate": 1.470120481927711e-05,
      "loss": 0.0373,
      "step": 21990
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 3.8311314582824707,
      "learning_rate": 1.4698795180722894e-05,
      "loss": 0.0775,
      "step": 22000
    },
    {
      "epoch": 2.6518072289156627,
      "grad_norm": 0.09339580684900284,
      "learning_rate": 1.4696385542168675e-05,
      "loss": 0.0434,
      "step": 22010
    },
    {
      "epoch": 2.653012048192771,
      "grad_norm": 0.09000292420387268,
      "learning_rate": 1.4693975903614459e-05,
      "loss": 0.0508,
      "step": 22020
    },
    {
      "epoch": 2.6542168674698794,
      "grad_norm": 1.280647873878479,
      "learning_rate": 1.4691566265060242e-05,
      "loss": 0.0165,
      "step": 22030
    },
    {
      "epoch": 2.6554216867469878,
      "grad_norm": 19.778125762939453,
      "learning_rate": 1.4689156626506025e-05,
      "loss": 0.1409,
      "step": 22040
    },
    {
      "epoch": 2.6566265060240966,
      "grad_norm": 0.5532951354980469,
      "learning_rate": 1.4686746987951808e-05,
      "loss": 0.0427,
      "step": 22050
    },
    {
      "epoch": 2.657831325301205,
      "grad_norm": 0.6531853079795837,
      "learning_rate": 1.468433734939759e-05,
      "loss": 0.0539,
      "step": 22060
    },
    {
      "epoch": 2.6590361445783133,
      "grad_norm": 4.323037624359131,
      "learning_rate": 1.4681927710843376e-05,
      "loss": 0.0489,
      "step": 22070
    },
    {
      "epoch": 2.6602409638554216,
      "grad_norm": 0.1349894106388092,
      "learning_rate": 1.4679518072289158e-05,
      "loss": 0.0278,
      "step": 22080
    },
    {
      "epoch": 2.66144578313253,
      "grad_norm": 0.1389090120792389,
      "learning_rate": 1.4677108433734941e-05,
      "loss": 0.0824,
      "step": 22090
    },
    {
      "epoch": 2.662650602409639,
      "grad_norm": 5.49479341506958,
      "learning_rate": 1.4674698795180724e-05,
      "loss": 0.0429,
      "step": 22100
    },
    {
      "epoch": 2.6638554216867467,
      "grad_norm": 3.7552785873413086,
      "learning_rate": 1.4672289156626507e-05,
      "loss": 0.0992,
      "step": 22110
    },
    {
      "epoch": 2.6650602409638555,
      "grad_norm": 0.35406702756881714,
      "learning_rate": 1.466987951807229e-05,
      "loss": 0.0658,
      "step": 22120
    },
    {
      "epoch": 2.666265060240964,
      "grad_norm": 0.04324183985590935,
      "learning_rate": 1.4667469879518072e-05,
      "loss": 0.0754,
      "step": 22130
    },
    {
      "epoch": 2.6674698795180722,
      "grad_norm": 6.379125595092773,
      "learning_rate": 1.4665060240963857e-05,
      "loss": 0.0694,
      "step": 22140
    },
    {
      "epoch": 2.6686746987951806,
      "grad_norm": 5.17147970199585,
      "learning_rate": 1.466265060240964e-05,
      "loss": 0.1182,
      "step": 22150
    },
    {
      "epoch": 2.669879518072289,
      "grad_norm": 2.0819263458251953,
      "learning_rate": 1.4660240963855423e-05,
      "loss": 0.0839,
      "step": 22160
    },
    {
      "epoch": 2.6710843373493978,
      "grad_norm": 0.1495857983827591,
      "learning_rate": 1.4657831325301206e-05,
      "loss": 0.0306,
      "step": 22170
    },
    {
      "epoch": 2.672289156626506,
      "grad_norm": 3.572399854660034,
      "learning_rate": 1.465542168674699e-05,
      "loss": 0.1061,
      "step": 22180
    },
    {
      "epoch": 2.6734939759036145,
      "grad_norm": 0.9326916933059692,
      "learning_rate": 1.4653012048192771e-05,
      "loss": 0.0757,
      "step": 22190
    },
    {
      "epoch": 2.674698795180723,
      "grad_norm": 0.28008103370666504,
      "learning_rate": 1.4650602409638554e-05,
      "loss": 0.0937,
      "step": 22200
    },
    {
      "epoch": 2.675903614457831,
      "grad_norm": 0.15879888832569122,
      "learning_rate": 1.4648192771084337e-05,
      "loss": 0.0514,
      "step": 22210
    },
    {
      "epoch": 2.67710843373494,
      "grad_norm": 0.5424056053161621,
      "learning_rate": 1.4645783132530122e-05,
      "loss": 0.0755,
      "step": 22220
    },
    {
      "epoch": 2.678313253012048,
      "grad_norm": 1.5459043979644775,
      "learning_rate": 1.4643373493975905e-05,
      "loss": 0.0158,
      "step": 22230
    },
    {
      "epoch": 2.6795180722891567,
      "grad_norm": 0.045736994594335556,
      "learning_rate": 1.4640963855421689e-05,
      "loss": 0.0589,
      "step": 22240
    },
    {
      "epoch": 2.680722891566265,
      "grad_norm": 0.13277699053287506,
      "learning_rate": 1.4638554216867472e-05,
      "loss": 0.0437,
      "step": 22250
    },
    {
      "epoch": 2.6819277108433734,
      "grad_norm": 0.1355568915605545,
      "learning_rate": 1.4636144578313253e-05,
      "loss": 0.0571,
      "step": 22260
    },
    {
      "epoch": 2.683132530120482,
      "grad_norm": 3.6883962154388428,
      "learning_rate": 1.4633734939759036e-05,
      "loss": 0.0897,
      "step": 22270
    },
    {
      "epoch": 2.68433734939759,
      "grad_norm": 14.779001235961914,
      "learning_rate": 1.463132530120482e-05,
      "loss": 0.0379,
      "step": 22280
    },
    {
      "epoch": 2.685542168674699,
      "grad_norm": 0.164709210395813,
      "learning_rate": 1.4628915662650604e-05,
      "loss": 0.0569,
      "step": 22290
    },
    {
      "epoch": 2.6867469879518073,
      "grad_norm": 9.293941497802734,
      "learning_rate": 1.4626506024096388e-05,
      "loss": 0.1398,
      "step": 22300
    },
    {
      "epoch": 2.6879518072289157,
      "grad_norm": 0.23278027772903442,
      "learning_rate": 1.462409638554217e-05,
      "loss": 0.054,
      "step": 22310
    },
    {
      "epoch": 2.689156626506024,
      "grad_norm": 0.47621023654937744,
      "learning_rate": 1.4621686746987954e-05,
      "loss": 0.0289,
      "step": 22320
    },
    {
      "epoch": 2.6903614457831324,
      "grad_norm": 9.6187162399292,
      "learning_rate": 1.4619277108433735e-05,
      "loss": 0.0648,
      "step": 22330
    },
    {
      "epoch": 2.691566265060241,
      "grad_norm": 0.017910053953528404,
      "learning_rate": 1.4616867469879519e-05,
      "loss": 0.0195,
      "step": 22340
    },
    {
      "epoch": 2.692771084337349,
      "grad_norm": 0.08951102942228317,
      "learning_rate": 1.4614457831325302e-05,
      "loss": 0.0506,
      "step": 22350
    },
    {
      "epoch": 2.693975903614458,
      "grad_norm": 2.9536871910095215,
      "learning_rate": 1.4612048192771085e-05,
      "loss": 0.0219,
      "step": 22360
    },
    {
      "epoch": 2.6951807228915663,
      "grad_norm": 1.070030689239502,
      "learning_rate": 1.460963855421687e-05,
      "loss": 0.0428,
      "step": 22370
    },
    {
      "epoch": 2.6963855421686747,
      "grad_norm": 0.021053887903690338,
      "learning_rate": 1.4607228915662653e-05,
      "loss": 0.0358,
      "step": 22380
    },
    {
      "epoch": 2.697590361445783,
      "grad_norm": 0.20016294717788696,
      "learning_rate": 1.4604819277108434e-05,
      "loss": 0.0743,
      "step": 22390
    },
    {
      "epoch": 2.6987951807228914,
      "grad_norm": 1.979071021080017,
      "learning_rate": 1.4602409638554218e-05,
      "loss": 0.0883,
      "step": 22400
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.127695083618164,
      "learning_rate": 1.46e-05,
      "loss": 0.0274,
      "step": 22410
    },
    {
      "epoch": 2.7012048192771085,
      "grad_norm": 1.5319793224334717,
      "learning_rate": 1.4597590361445784e-05,
      "loss": 0.1126,
      "step": 22420
    },
    {
      "epoch": 2.702409638554217,
      "grad_norm": 0.39343342185020447,
      "learning_rate": 1.4595180722891567e-05,
      "loss": 0.0483,
      "step": 22430
    },
    {
      "epoch": 2.7036144578313253,
      "grad_norm": 3.189838409423828,
      "learning_rate": 1.4592771084337352e-05,
      "loss": 0.0654,
      "step": 22440
    },
    {
      "epoch": 2.7048192771084336,
      "grad_norm": 17.14724349975586,
      "learning_rate": 1.4590361445783135e-05,
      "loss": 0.0562,
      "step": 22450
    },
    {
      "epoch": 2.7060240963855424,
      "grad_norm": 0.040474165230989456,
      "learning_rate": 1.4587951807228917e-05,
      "loss": 0.0686,
      "step": 22460
    },
    {
      "epoch": 2.7072289156626503,
      "grad_norm": 0.07314465939998627,
      "learning_rate": 1.45855421686747e-05,
      "loss": 0.0239,
      "step": 22470
    },
    {
      "epoch": 2.708433734939759,
      "grad_norm": 1.238038182258606,
      "learning_rate": 1.4583132530120483e-05,
      "loss": 0.0259,
      "step": 22480
    },
    {
      "epoch": 2.7096385542168675,
      "grad_norm": 3.869654893875122,
      "learning_rate": 1.4580722891566266e-05,
      "loss": 0.0653,
      "step": 22490
    },
    {
      "epoch": 2.710843373493976,
      "grad_norm": 0.033764079213142395,
      "learning_rate": 1.457831325301205e-05,
      "loss": 0.0589,
      "step": 22500
    },
    {
      "epoch": 2.712048192771084,
      "grad_norm": 0.0862061083316803,
      "learning_rate": 1.4575903614457831e-05,
      "loss": 0.0651,
      "step": 22510
    },
    {
      "epoch": 2.7132530120481926,
      "grad_norm": 0.3480115234851837,
      "learning_rate": 1.4573493975903616e-05,
      "loss": 0.017,
      "step": 22520
    },
    {
      "epoch": 2.7144578313253014,
      "grad_norm": 5.924103260040283,
      "learning_rate": 1.4571084337349399e-05,
      "loss": 0.082,
      "step": 22530
    },
    {
      "epoch": 2.7156626506024097,
      "grad_norm": 0.03420441597700119,
      "learning_rate": 1.4568674698795182e-05,
      "loss": 0.0018,
      "step": 22540
    },
    {
      "epoch": 2.716867469879518,
      "grad_norm": 2.9094436168670654,
      "learning_rate": 1.4566265060240965e-05,
      "loss": 0.083,
      "step": 22550
    },
    {
      "epoch": 2.7180722891566265,
      "grad_norm": 0.639877200126648,
      "learning_rate": 1.4563855421686748e-05,
      "loss": 0.0149,
      "step": 22560
    },
    {
      "epoch": 2.719277108433735,
      "grad_norm": 0.2511262893676758,
      "learning_rate": 1.456144578313253e-05,
      "loss": 0.0457,
      "step": 22570
    },
    {
      "epoch": 2.7204819277108436,
      "grad_norm": 1.0840082168579102,
      "learning_rate": 1.4559036144578313e-05,
      "loss": 0.0669,
      "step": 22580
    },
    {
      "epoch": 2.7216867469879515,
      "grad_norm": 0.7237849235534668,
      "learning_rate": 1.4556626506024098e-05,
      "loss": 0.053,
      "step": 22590
    },
    {
      "epoch": 2.7228915662650603,
      "grad_norm": 2.066776752471924,
      "learning_rate": 1.4554216867469881e-05,
      "loss": 0.0527,
      "step": 22600
    },
    {
      "epoch": 2.7240963855421687,
      "grad_norm": 0.3946264684200287,
      "learning_rate": 1.4551807228915664e-05,
      "loss": 0.0418,
      "step": 22610
    },
    {
      "epoch": 2.725301204819277,
      "grad_norm": 0.335316002368927,
      "learning_rate": 1.4549397590361448e-05,
      "loss": 0.0649,
      "step": 22620
    },
    {
      "epoch": 2.7265060240963854,
      "grad_norm": 25.770401000976562,
      "learning_rate": 1.454698795180723e-05,
      "loss": 0.0744,
      "step": 22630
    },
    {
      "epoch": 2.727710843373494,
      "grad_norm": 5.427835941314697,
      "learning_rate": 1.4544578313253012e-05,
      "loss": 0.0559,
      "step": 22640
    },
    {
      "epoch": 2.7289156626506026,
      "grad_norm": 8.142043113708496,
      "learning_rate": 1.4542168674698795e-05,
      "loss": 0.0207,
      "step": 22650
    },
    {
      "epoch": 2.730120481927711,
      "grad_norm": 2.281578540802002,
      "learning_rate": 1.4539759036144579e-05,
      "loss": 0.0381,
      "step": 22660
    },
    {
      "epoch": 2.7313253012048193,
      "grad_norm": 0.8822686076164246,
      "learning_rate": 1.4537349397590363e-05,
      "loss": 0.0285,
      "step": 22670
    },
    {
      "epoch": 2.7325301204819277,
      "grad_norm": 35.66329574584961,
      "learning_rate": 1.4534939759036147e-05,
      "loss": 0.1012,
      "step": 22680
    },
    {
      "epoch": 2.733734939759036,
      "grad_norm": 0.45045360922813416,
      "learning_rate": 1.453253012048193e-05,
      "loss": 0.0774,
      "step": 22690
    },
    {
      "epoch": 2.734939759036145,
      "grad_norm": 3.2829036712646484,
      "learning_rate": 1.4530120481927711e-05,
      "loss": 0.0443,
      "step": 22700
    },
    {
      "epoch": 2.7361445783132528,
      "grad_norm": 0.30816060304641724,
      "learning_rate": 1.4527710843373494e-05,
      "loss": 0.0495,
      "step": 22710
    },
    {
      "epoch": 2.7373493975903616,
      "grad_norm": 0.032169632613658905,
      "learning_rate": 1.4525301204819278e-05,
      "loss": 0.0733,
      "step": 22720
    },
    {
      "epoch": 2.73855421686747,
      "grad_norm": 0.04867011681199074,
      "learning_rate": 1.452289156626506e-05,
      "loss": 0.0966,
      "step": 22730
    },
    {
      "epoch": 2.7397590361445783,
      "grad_norm": 4.2942609786987305,
      "learning_rate": 1.4520481927710846e-05,
      "loss": 0.0536,
      "step": 22740
    },
    {
      "epoch": 2.7409638554216866,
      "grad_norm": 0.0678168535232544,
      "learning_rate": 1.4518072289156629e-05,
      "loss": 0.0307,
      "step": 22750
    },
    {
      "epoch": 2.742168674698795,
      "grad_norm": 7.801194190979004,
      "learning_rate": 1.4515662650602412e-05,
      "loss": 0.0625,
      "step": 22760
    },
    {
      "epoch": 2.743373493975904,
      "grad_norm": 0.04178701341152191,
      "learning_rate": 1.4513253012048193e-05,
      "loss": 0.0234,
      "step": 22770
    },
    {
      "epoch": 2.744578313253012,
      "grad_norm": 0.9072374701499939,
      "learning_rate": 1.4510843373493977e-05,
      "loss": 0.0553,
      "step": 22780
    },
    {
      "epoch": 2.7457831325301205,
      "grad_norm": 0.02041313424706459,
      "learning_rate": 1.450843373493976e-05,
      "loss": 0.0456,
      "step": 22790
    },
    {
      "epoch": 2.746987951807229,
      "grad_norm": 2.1356236934661865,
      "learning_rate": 1.4506024096385543e-05,
      "loss": 0.0929,
      "step": 22800
    },
    {
      "epoch": 2.7481927710843372,
      "grad_norm": 1.475502610206604,
      "learning_rate": 1.4503614457831326e-05,
      "loss": 0.0274,
      "step": 22810
    },
    {
      "epoch": 2.749397590361446,
      "grad_norm": 2.7133142948150635,
      "learning_rate": 1.4501204819277111e-05,
      "loss": 0.0313,
      "step": 22820
    },
    {
      "epoch": 2.750602409638554,
      "grad_norm": 2.3138234615325928,
      "learning_rate": 1.4498795180722893e-05,
      "loss": 0.0984,
      "step": 22830
    },
    {
      "epoch": 2.7518072289156628,
      "grad_norm": 4.074631214141846,
      "learning_rate": 1.4496385542168676e-05,
      "loss": 0.0501,
      "step": 22840
    },
    {
      "epoch": 2.753012048192771,
      "grad_norm": 0.2684226334095001,
      "learning_rate": 1.4493975903614459e-05,
      "loss": 0.0351,
      "step": 22850
    },
    {
      "epoch": 2.7542168674698795,
      "grad_norm": 0.041252680122852325,
      "learning_rate": 1.4491566265060242e-05,
      "loss": 0.0383,
      "step": 22860
    },
    {
      "epoch": 2.755421686746988,
      "grad_norm": 0.05433829501271248,
      "learning_rate": 1.4489156626506025e-05,
      "loss": 0.0318,
      "step": 22870
    },
    {
      "epoch": 2.756626506024096,
      "grad_norm": 0.9638676047325134,
      "learning_rate": 1.4486746987951807e-05,
      "loss": 0.0852,
      "step": 22880
    },
    {
      "epoch": 2.757831325301205,
      "grad_norm": 0.05549095198512077,
      "learning_rate": 1.4484337349397593e-05,
      "loss": 0.0158,
      "step": 22890
    },
    {
      "epoch": 2.7590361445783134,
      "grad_norm": 1.928725242614746,
      "learning_rate": 1.4481927710843375e-05,
      "loss": 0.0425,
      "step": 22900
    },
    {
      "epoch": 2.7602409638554217,
      "grad_norm": 0.674081027507782,
      "learning_rate": 1.4479518072289158e-05,
      "loss": 0.0317,
      "step": 22910
    },
    {
      "epoch": 2.76144578313253,
      "grad_norm": 0.036915794014930725,
      "learning_rate": 1.4477108433734941e-05,
      "loss": 0.0411,
      "step": 22920
    },
    {
      "epoch": 2.7626506024096384,
      "grad_norm": 6.000967502593994,
      "learning_rate": 1.4474698795180724e-05,
      "loss": 0.0373,
      "step": 22930
    },
    {
      "epoch": 2.7638554216867472,
      "grad_norm": 5.671698093414307,
      "learning_rate": 1.4472289156626507e-05,
      "loss": 0.0732,
      "step": 22940
    },
    {
      "epoch": 2.765060240963855,
      "grad_norm": 2.157101631164551,
      "learning_rate": 1.4469879518072289e-05,
      "loss": 0.0327,
      "step": 22950
    },
    {
      "epoch": 2.766265060240964,
      "grad_norm": 3.892291307449341,
      "learning_rate": 1.4467469879518074e-05,
      "loss": 0.058,
      "step": 22960
    },
    {
      "epoch": 2.7674698795180723,
      "grad_norm": 3.5161936283111572,
      "learning_rate": 1.4465060240963857e-05,
      "loss": 0.0174,
      "step": 22970
    },
    {
      "epoch": 2.7686746987951807,
      "grad_norm": 3.0091521739959717,
      "learning_rate": 1.446265060240964e-05,
      "loss": 0.0731,
      "step": 22980
    },
    {
      "epoch": 2.769879518072289,
      "grad_norm": 0.15504665672779083,
      "learning_rate": 1.4460240963855423e-05,
      "loss": 0.02,
      "step": 22990
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 2.19360089302063,
      "learning_rate": 1.4457831325301207e-05,
      "loss": 0.0327,
      "step": 23000
    },
    {
      "epoch": 2.772289156626506,
      "grad_norm": 0.34625935554504395,
      "learning_rate": 1.4455421686746988e-05,
      "loss": 0.0332,
      "step": 23010
    },
    {
      "epoch": 2.7734939759036146,
      "grad_norm": 0.22928212583065033,
      "learning_rate": 1.4453012048192771e-05,
      "loss": 0.0407,
      "step": 23020
    },
    {
      "epoch": 2.774698795180723,
      "grad_norm": 0.6881234645843506,
      "learning_rate": 1.4450602409638554e-05,
      "loss": 0.0309,
      "step": 23030
    },
    {
      "epoch": 2.7759036144578313,
      "grad_norm": 0.14165516197681427,
      "learning_rate": 1.444819277108434e-05,
      "loss": 0.0787,
      "step": 23040
    },
    {
      "epoch": 2.7771084337349397,
      "grad_norm": 11.457320213317871,
      "learning_rate": 1.4445783132530122e-05,
      "loss": 0.1074,
      "step": 23050
    },
    {
      "epoch": 2.7783132530120485,
      "grad_norm": 4.133077621459961,
      "learning_rate": 1.4443373493975906e-05,
      "loss": 0.0423,
      "step": 23060
    },
    {
      "epoch": 2.7795180722891564,
      "grad_norm": 0.1555696278810501,
      "learning_rate": 1.4440963855421689e-05,
      "loss": 0.0518,
      "step": 23070
    },
    {
      "epoch": 2.780722891566265,
      "grad_norm": 0.10490003973245621,
      "learning_rate": 1.443855421686747e-05,
      "loss": 0.0136,
      "step": 23080
    },
    {
      "epoch": 2.7819277108433735,
      "grad_norm": 0.14143459498882294,
      "learning_rate": 1.4436144578313253e-05,
      "loss": 0.073,
      "step": 23090
    },
    {
      "epoch": 2.783132530120482,
      "grad_norm": 1.398908019065857,
      "learning_rate": 1.4433734939759037e-05,
      "loss": 0.0208,
      "step": 23100
    },
    {
      "epoch": 2.7843373493975903,
      "grad_norm": 0.13290221989154816,
      "learning_rate": 1.4431325301204821e-05,
      "loss": 0.044,
      "step": 23110
    },
    {
      "epoch": 2.7855421686746986,
      "grad_norm": 3.2224538326263428,
      "learning_rate": 1.4428915662650605e-05,
      "loss": 0.0897,
      "step": 23120
    },
    {
      "epoch": 2.7867469879518074,
      "grad_norm": 0.5006158351898193,
      "learning_rate": 1.4426506024096388e-05,
      "loss": 0.036,
      "step": 23130
    },
    {
      "epoch": 2.787951807228916,
      "grad_norm": 0.02617221139371395,
      "learning_rate": 1.442409638554217e-05,
      "loss": 0.0226,
      "step": 23140
    },
    {
      "epoch": 2.789156626506024,
      "grad_norm": 0.013354405760765076,
      "learning_rate": 1.4421686746987952e-05,
      "loss": 0.0543,
      "step": 23150
    },
    {
      "epoch": 2.7903614457831325,
      "grad_norm": 0.2664962112903595,
      "learning_rate": 1.4419277108433736e-05,
      "loss": 0.0185,
      "step": 23160
    },
    {
      "epoch": 2.791566265060241,
      "grad_norm": 0.39303073287010193,
      "learning_rate": 1.4416867469879519e-05,
      "loss": 0.0904,
      "step": 23170
    },
    {
      "epoch": 2.7927710843373497,
      "grad_norm": 53.096282958984375,
      "learning_rate": 1.4414457831325302e-05,
      "loss": 0.0381,
      "step": 23180
    },
    {
      "epoch": 2.7939759036144576,
      "grad_norm": 8.069064140319824,
      "learning_rate": 1.4412048192771087e-05,
      "loss": 0.0519,
      "step": 23190
    },
    {
      "epoch": 2.7951807228915664,
      "grad_norm": 4.965453147888184,
      "learning_rate": 1.440963855421687e-05,
      "loss": 0.0331,
      "step": 23200
    },
    {
      "epoch": 2.7963855421686747,
      "grad_norm": 0.020562654361128807,
      "learning_rate": 1.4407228915662652e-05,
      "loss": 0.0711,
      "step": 23210
    },
    {
      "epoch": 2.797590361445783,
      "grad_norm": 3.0379631519317627,
      "learning_rate": 1.4404819277108435e-05,
      "loss": 0.0151,
      "step": 23220
    },
    {
      "epoch": 2.7987951807228915,
      "grad_norm": 2.3003783226013184,
      "learning_rate": 1.4402409638554218e-05,
      "loss": 0.0352,
      "step": 23230
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.07360909134149551,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0607,
      "step": 23240
    },
    {
      "epoch": 2.8012048192771086,
      "grad_norm": 0.06351493299007416,
      "learning_rate": 1.4397590361445784e-05,
      "loss": 0.0464,
      "step": 23250
    },
    {
      "epoch": 2.802409638554217,
      "grad_norm": 4.078709125518799,
      "learning_rate": 1.4395180722891569e-05,
      "loss": 0.0742,
      "step": 23260
    },
    {
      "epoch": 2.8036144578313253,
      "grad_norm": 5.867684364318848,
      "learning_rate": 1.439277108433735e-05,
      "loss": 0.0303,
      "step": 23270
    },
    {
      "epoch": 2.8048192771084337,
      "grad_norm": 1.7390753030776978,
      "learning_rate": 1.4390361445783134e-05,
      "loss": 0.0677,
      "step": 23280
    },
    {
      "epoch": 2.806024096385542,
      "grad_norm": 0.4950113892555237,
      "learning_rate": 1.4387951807228917e-05,
      "loss": 0.0531,
      "step": 23290
    },
    {
      "epoch": 2.807228915662651,
      "grad_norm": 0.04715677350759506,
      "learning_rate": 1.43855421686747e-05,
      "loss": 0.0299,
      "step": 23300
    },
    {
      "epoch": 2.808433734939759,
      "grad_norm": 26.581674575805664,
      "learning_rate": 1.4383132530120483e-05,
      "loss": 0.0495,
      "step": 23310
    },
    {
      "epoch": 2.8096385542168676,
      "grad_norm": 11.991756439208984,
      "learning_rate": 1.4380722891566265e-05,
      "loss": 0.0156,
      "step": 23320
    },
    {
      "epoch": 2.810843373493976,
      "grad_norm": 1.763420581817627,
      "learning_rate": 1.4378313253012048e-05,
      "loss": 0.0331,
      "step": 23330
    },
    {
      "epoch": 2.8120481927710843,
      "grad_norm": 0.12700793147087097,
      "learning_rate": 1.4375903614457833e-05,
      "loss": 0.0758,
      "step": 23340
    },
    {
      "epoch": 2.8132530120481927,
      "grad_norm": 2.4829564094543457,
      "learning_rate": 1.4373493975903616e-05,
      "loss": 0.1167,
      "step": 23350
    },
    {
      "epoch": 2.814457831325301,
      "grad_norm": 4.174930572509766,
      "learning_rate": 1.43710843373494e-05,
      "loss": 0.0331,
      "step": 23360
    },
    {
      "epoch": 2.81566265060241,
      "grad_norm": 2.2762136459350586,
      "learning_rate": 1.4368674698795182e-05,
      "loss": 0.0627,
      "step": 23370
    },
    {
      "epoch": 2.816867469879518,
      "grad_norm": 0.7015723586082458,
      "learning_rate": 1.4366265060240966e-05,
      "loss": 0.1042,
      "step": 23380
    },
    {
      "epoch": 2.8180722891566266,
      "grad_norm": 0.06323997676372528,
      "learning_rate": 1.4363855421686747e-05,
      "loss": 0.0583,
      "step": 23390
    },
    {
      "epoch": 2.819277108433735,
      "grad_norm": 0.677055299282074,
      "learning_rate": 1.436144578313253e-05,
      "loss": 0.0487,
      "step": 23400
    },
    {
      "epoch": 2.8204819277108433,
      "grad_norm": 5.410481929779053,
      "learning_rate": 1.4359036144578315e-05,
      "loss": 0.0522,
      "step": 23410
    },
    {
      "epoch": 2.821686746987952,
      "grad_norm": 0.05195484682917595,
      "learning_rate": 1.4356626506024098e-05,
      "loss": 0.0647,
      "step": 23420
    },
    {
      "epoch": 2.82289156626506,
      "grad_norm": 2.811990737915039,
      "learning_rate": 1.4354216867469881e-05,
      "loss": 0.0474,
      "step": 23430
    },
    {
      "epoch": 2.824096385542169,
      "grad_norm": 0.05440692976117134,
      "learning_rate": 1.4351807228915665e-05,
      "loss": 0.0381,
      "step": 23440
    },
    {
      "epoch": 2.825301204819277,
      "grad_norm": 1.5781375169754028,
      "learning_rate": 1.4349397590361446e-05,
      "loss": 0.0931,
      "step": 23450
    },
    {
      "epoch": 2.8265060240963855,
      "grad_norm": 0.05412057414650917,
      "learning_rate": 1.434698795180723e-05,
      "loss": 0.0398,
      "step": 23460
    },
    {
      "epoch": 2.827710843373494,
      "grad_norm": 3.4331235885620117,
      "learning_rate": 1.4344578313253012e-05,
      "loss": 0.1032,
      "step": 23470
    },
    {
      "epoch": 2.8289156626506022,
      "grad_norm": 7.120639801025391,
      "learning_rate": 1.4342168674698796e-05,
      "loss": 0.0815,
      "step": 23480
    },
    {
      "epoch": 2.830120481927711,
      "grad_norm": 1.3888128995895386,
      "learning_rate": 1.433975903614458e-05,
      "loss": 0.0582,
      "step": 23490
    },
    {
      "epoch": 2.8313253012048194,
      "grad_norm": 13.228583335876465,
      "learning_rate": 1.4337349397590364e-05,
      "loss": 0.0629,
      "step": 23500
    },
    {
      "epoch": 2.8325301204819278,
      "grad_norm": 1.4096161127090454,
      "learning_rate": 1.4334939759036147e-05,
      "loss": 0.0231,
      "step": 23510
    },
    {
      "epoch": 2.833734939759036,
      "grad_norm": 0.24415899813175201,
      "learning_rate": 1.4332530120481928e-05,
      "loss": 0.0538,
      "step": 23520
    },
    {
      "epoch": 2.8349397590361445,
      "grad_norm": 1.6612738370895386,
      "learning_rate": 1.4330120481927711e-05,
      "loss": 0.0583,
      "step": 23530
    },
    {
      "epoch": 2.8361445783132533,
      "grad_norm": 6.002687454223633,
      "learning_rate": 1.4327710843373495e-05,
      "loss": 0.0756,
      "step": 23540
    },
    {
      "epoch": 2.837349397590361,
      "grad_norm": 0.27071288228034973,
      "learning_rate": 1.4325301204819278e-05,
      "loss": 0.0646,
      "step": 23550
    },
    {
      "epoch": 2.83855421686747,
      "grad_norm": 5.365415096282959,
      "learning_rate": 1.4322891566265063e-05,
      "loss": 0.1226,
      "step": 23560
    },
    {
      "epoch": 2.8397590361445784,
      "grad_norm": 6.2493205070495605,
      "learning_rate": 1.4320481927710846e-05,
      "loss": 0.0762,
      "step": 23570
    },
    {
      "epoch": 2.8409638554216867,
      "grad_norm": 0.16497626900672913,
      "learning_rate": 1.4318072289156627e-05,
      "loss": 0.0649,
      "step": 23580
    },
    {
      "epoch": 2.842168674698795,
      "grad_norm": 0.043640729039907455,
      "learning_rate": 1.431566265060241e-05,
      "loss": 0.0607,
      "step": 23590
    },
    {
      "epoch": 2.8433734939759034,
      "grad_norm": 0.10435537993907928,
      "learning_rate": 1.4313253012048194e-05,
      "loss": 0.0466,
      "step": 23600
    },
    {
      "epoch": 2.8445783132530122,
      "grad_norm": 0.3724498450756073,
      "learning_rate": 1.4310843373493977e-05,
      "loss": 0.0603,
      "step": 23610
    },
    {
      "epoch": 2.8457831325301206,
      "grad_norm": 2.856302261352539,
      "learning_rate": 1.430843373493976e-05,
      "loss": 0.0294,
      "step": 23620
    },
    {
      "epoch": 2.846987951807229,
      "grad_norm": 6.622564315795898,
      "learning_rate": 1.4306024096385542e-05,
      "loss": 0.0464,
      "step": 23630
    },
    {
      "epoch": 2.8481927710843373,
      "grad_norm": 4.5576958656311035,
      "learning_rate": 1.4303614457831328e-05,
      "loss": 0.0836,
      "step": 23640
    },
    {
      "epoch": 2.8493975903614457,
      "grad_norm": 0.12337171286344528,
      "learning_rate": 1.430120481927711e-05,
      "loss": 0.083,
      "step": 23650
    },
    {
      "epoch": 2.8506024096385545,
      "grad_norm": 5.982396125793457,
      "learning_rate": 1.4298795180722893e-05,
      "loss": 0.0396,
      "step": 23660
    },
    {
      "epoch": 2.8518072289156624,
      "grad_norm": 7.711316108703613,
      "learning_rate": 1.4296385542168676e-05,
      "loss": 0.0338,
      "step": 23670
    },
    {
      "epoch": 2.853012048192771,
      "grad_norm": 0.07847341150045395,
      "learning_rate": 1.4293975903614459e-05,
      "loss": 0.0531,
      "step": 23680
    },
    {
      "epoch": 2.8542168674698796,
      "grad_norm": 0.0920783057808876,
      "learning_rate": 1.4291566265060242e-05,
      "loss": 0.0713,
      "step": 23690
    },
    {
      "epoch": 2.855421686746988,
      "grad_norm": 0.17429910600185394,
      "learning_rate": 1.4289156626506024e-05,
      "loss": 0.0726,
      "step": 23700
    },
    {
      "epoch": 2.8566265060240963,
      "grad_norm": 0.14273704588413239,
      "learning_rate": 1.428674698795181e-05,
      "loss": 0.0393,
      "step": 23710
    },
    {
      "epoch": 2.8578313253012047,
      "grad_norm": 0.018633395433425903,
      "learning_rate": 1.4284337349397592e-05,
      "loss": 0.0854,
      "step": 23720
    },
    {
      "epoch": 2.8590361445783135,
      "grad_norm": 0.04650698974728584,
      "learning_rate": 1.4281927710843375e-05,
      "loss": 0.0481,
      "step": 23730
    },
    {
      "epoch": 2.860240963855422,
      "grad_norm": 13.629857063293457,
      "learning_rate": 1.4279518072289158e-05,
      "loss": 0.048,
      "step": 23740
    },
    {
      "epoch": 2.86144578313253,
      "grad_norm": 0.03914084658026695,
      "learning_rate": 1.4277108433734941e-05,
      "loss": 0.08,
      "step": 23750
    },
    {
      "epoch": 2.8626506024096385,
      "grad_norm": 0.07041606307029724,
      "learning_rate": 1.4274698795180725e-05,
      "loss": 0.0511,
      "step": 23760
    },
    {
      "epoch": 2.863855421686747,
      "grad_norm": 0.06745720654726028,
      "learning_rate": 1.4272289156626506e-05,
      "loss": 0.0361,
      "step": 23770
    },
    {
      "epoch": 2.8650602409638557,
      "grad_norm": 0.2862670123577118,
      "learning_rate": 1.426987951807229e-05,
      "loss": 0.0591,
      "step": 23780
    },
    {
      "epoch": 2.8662650602409636,
      "grad_norm": 2.5155041217803955,
      "learning_rate": 1.4267469879518074e-05,
      "loss": 0.0934,
      "step": 23790
    },
    {
      "epoch": 2.8674698795180724,
      "grad_norm": 0.21321026980876923,
      "learning_rate": 1.4265060240963857e-05,
      "loss": 0.0524,
      "step": 23800
    },
    {
      "epoch": 2.8686746987951808,
      "grad_norm": 0.3283914625644684,
      "learning_rate": 1.426265060240964e-05,
      "loss": 0.0636,
      "step": 23810
    },
    {
      "epoch": 2.869879518072289,
      "grad_norm": 0.41564303636550903,
      "learning_rate": 1.4260240963855424e-05,
      "loss": 0.0448,
      "step": 23820
    },
    {
      "epoch": 2.8710843373493975,
      "grad_norm": 12.484969139099121,
      "learning_rate": 1.4257831325301205e-05,
      "loss": 0.1109,
      "step": 23830
    },
    {
      "epoch": 2.872289156626506,
      "grad_norm": 0.8775274157524109,
      "learning_rate": 1.4255421686746988e-05,
      "loss": 0.0514,
      "step": 23840
    },
    {
      "epoch": 2.8734939759036147,
      "grad_norm": 0.7322103977203369,
      "learning_rate": 1.4253012048192771e-05,
      "loss": 0.0161,
      "step": 23850
    },
    {
      "epoch": 2.874698795180723,
      "grad_norm": 0.07956064492464066,
      "learning_rate": 1.4250602409638556e-05,
      "loss": 0.0673,
      "step": 23860
    },
    {
      "epoch": 2.8759036144578314,
      "grad_norm": 0.48167750239372253,
      "learning_rate": 1.424819277108434e-05,
      "loss": 0.0337,
      "step": 23870
    },
    {
      "epoch": 2.8771084337349397,
      "grad_norm": 10.621538162231445,
      "learning_rate": 1.4245783132530123e-05,
      "loss": 0.1199,
      "step": 23880
    },
    {
      "epoch": 2.878313253012048,
      "grad_norm": 7.251730442047119,
      "learning_rate": 1.4243373493975906e-05,
      "loss": 0.0902,
      "step": 23890
    },
    {
      "epoch": 2.8795180722891565,
      "grad_norm": 1.3256691694259644,
      "learning_rate": 1.4240963855421687e-05,
      "loss": 0.1,
      "step": 23900
    },
    {
      "epoch": 2.880722891566265,
      "grad_norm": 1.0337927341461182,
      "learning_rate": 1.423855421686747e-05,
      "loss": 0.0491,
      "step": 23910
    },
    {
      "epoch": 2.8819277108433736,
      "grad_norm": 3.0262436866760254,
      "learning_rate": 1.4236144578313254e-05,
      "loss": 0.0616,
      "step": 23920
    },
    {
      "epoch": 2.883132530120482,
      "grad_norm": 0.21803739666938782,
      "learning_rate": 1.4233734939759037e-05,
      "loss": 0.0517,
      "step": 23930
    },
    {
      "epoch": 2.8843373493975903,
      "grad_norm": 1.319400668144226,
      "learning_rate": 1.4231325301204822e-05,
      "loss": 0.0411,
      "step": 23940
    },
    {
      "epoch": 2.8855421686746987,
      "grad_norm": 4.33029317855835,
      "learning_rate": 1.4228915662650605e-05,
      "loss": 0.0625,
      "step": 23950
    },
    {
      "epoch": 2.886746987951807,
      "grad_norm": 0.5258334875106812,
      "learning_rate": 1.4226506024096386e-05,
      "loss": 0.0403,
      "step": 23960
    },
    {
      "epoch": 2.887951807228916,
      "grad_norm": 0.20460864901542664,
      "learning_rate": 1.422409638554217e-05,
      "loss": 0.0203,
      "step": 23970
    },
    {
      "epoch": 2.8891566265060242,
      "grad_norm": 6.031069278717041,
      "learning_rate": 1.4221686746987953e-05,
      "loss": 0.083,
      "step": 23980
    },
    {
      "epoch": 2.8903614457831326,
      "grad_norm": 18.041641235351562,
      "learning_rate": 1.4219277108433736e-05,
      "loss": 0.0808,
      "step": 23990
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 0.3992096781730652,
      "learning_rate": 1.4216867469879519e-05,
      "loss": 0.0555,
      "step": 24000
    },
    {
      "epoch": 2.8927710843373493,
      "grad_norm": 0.29285144805908203,
      "learning_rate": 1.4214457831325304e-05,
      "loss": 0.0631,
      "step": 24010
    },
    {
      "epoch": 2.8939759036144577,
      "grad_norm": 0.600231409072876,
      "learning_rate": 1.4212048192771087e-05,
      "loss": 0.0307,
      "step": 24020
    },
    {
      "epoch": 2.895180722891566,
      "grad_norm": 3.4613869190216064,
      "learning_rate": 1.4209638554216869e-05,
      "loss": 0.0929,
      "step": 24030
    },
    {
      "epoch": 2.896385542168675,
      "grad_norm": 2.458890438079834,
      "learning_rate": 1.4207228915662652e-05,
      "loss": 0.0699,
      "step": 24040
    },
    {
      "epoch": 2.897590361445783,
      "grad_norm": 10.685416221618652,
      "learning_rate": 1.4204819277108435e-05,
      "loss": 0.0432,
      "step": 24050
    },
    {
      "epoch": 2.8987951807228916,
      "grad_norm": 1.7000081539154053,
      "learning_rate": 1.4202409638554218e-05,
      "loss": 0.0939,
      "step": 24060
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.301436185836792,
      "learning_rate": 1.4200000000000001e-05,
      "loss": 0.0709,
      "step": 24070
    },
    {
      "epoch": 2.9012048192771083,
      "grad_norm": 7.228528022766113,
      "learning_rate": 1.4197590361445783e-05,
      "loss": 0.0541,
      "step": 24080
    },
    {
      "epoch": 2.902409638554217,
      "grad_norm": 0.038003742694854736,
      "learning_rate": 1.4195180722891568e-05,
      "loss": 0.0331,
      "step": 24090
    },
    {
      "epoch": 2.9036144578313254,
      "grad_norm": 0.0812608003616333,
      "learning_rate": 1.419277108433735e-05,
      "loss": 0.0458,
      "step": 24100
    },
    {
      "epoch": 2.904819277108434,
      "grad_norm": 0.6131859421730042,
      "learning_rate": 1.4190361445783134e-05,
      "loss": 0.049,
      "step": 24110
    },
    {
      "epoch": 2.906024096385542,
      "grad_norm": 0.2587795853614807,
      "learning_rate": 1.4187951807228917e-05,
      "loss": 0.089,
      "step": 24120
    },
    {
      "epoch": 2.9072289156626505,
      "grad_norm": 0.7276625037193298,
      "learning_rate": 1.41855421686747e-05,
      "loss": 0.0482,
      "step": 24130
    },
    {
      "epoch": 2.908433734939759,
      "grad_norm": 6.808597564697266,
      "learning_rate": 1.4183132530120482e-05,
      "loss": 0.0367,
      "step": 24140
    },
    {
      "epoch": 2.9096385542168672,
      "grad_norm": 1.7549868822097778,
      "learning_rate": 1.4180722891566265e-05,
      "loss": 0.022,
      "step": 24150
    },
    {
      "epoch": 2.910843373493976,
      "grad_norm": 0.022122029215097427,
      "learning_rate": 1.417831325301205e-05,
      "loss": 0.0382,
      "step": 24160
    },
    {
      "epoch": 2.9120481927710844,
      "grad_norm": 0.116659976541996,
      "learning_rate": 1.4175903614457833e-05,
      "loss": 0.0961,
      "step": 24170
    },
    {
      "epoch": 2.9132530120481928,
      "grad_norm": 0.3092125654220581,
      "learning_rate": 1.4173493975903616e-05,
      "loss": 0.0147,
      "step": 24180
    },
    {
      "epoch": 2.914457831325301,
      "grad_norm": 0.12327445298433304,
      "learning_rate": 1.41710843373494e-05,
      "loss": 0.0595,
      "step": 24190
    },
    {
      "epoch": 2.9156626506024095,
      "grad_norm": 0.2317746877670288,
      "learning_rate": 1.4168674698795183e-05,
      "loss": 0.1059,
      "step": 24200
    },
    {
      "epoch": 2.9168674698795183,
      "grad_norm": 0.6085424423217773,
      "learning_rate": 1.4166265060240964e-05,
      "loss": 0.1019,
      "step": 24210
    },
    {
      "epoch": 2.9180722891566266,
      "grad_norm": 0.09841380268335342,
      "learning_rate": 1.4163855421686747e-05,
      "loss": 0.0623,
      "step": 24220
    },
    {
      "epoch": 2.919277108433735,
      "grad_norm": 0.15818488597869873,
      "learning_rate": 1.416144578313253e-05,
      "loss": 0.0487,
      "step": 24230
    },
    {
      "epoch": 2.9204819277108434,
      "grad_norm": 12.047075271606445,
      "learning_rate": 1.4159036144578315e-05,
      "loss": 0.0215,
      "step": 24240
    },
    {
      "epoch": 2.9216867469879517,
      "grad_norm": 0.037894293665885925,
      "learning_rate": 1.4156626506024098e-05,
      "loss": 0.0825,
      "step": 24250
    },
    {
      "epoch": 2.92289156626506,
      "grad_norm": 5.855659008026123,
      "learning_rate": 1.4154216867469882e-05,
      "loss": 0.0544,
      "step": 24260
    },
    {
      "epoch": 2.9240963855421684,
      "grad_norm": 0.9510691165924072,
      "learning_rate": 1.4151807228915663e-05,
      "loss": 0.0896,
      "step": 24270
    },
    {
      "epoch": 2.9253012048192772,
      "grad_norm": 0.05608418956398964,
      "learning_rate": 1.4149397590361446e-05,
      "loss": 0.0193,
      "step": 24280
    },
    {
      "epoch": 2.9265060240963856,
      "grad_norm": 0.06148023530840874,
      "learning_rate": 1.414698795180723e-05,
      "loss": 0.1067,
      "step": 24290
    },
    {
      "epoch": 2.927710843373494,
      "grad_norm": 2.68782901763916,
      "learning_rate": 1.4144578313253013e-05,
      "loss": 0.0589,
      "step": 24300
    },
    {
      "epoch": 2.9289156626506023,
      "grad_norm": 0.2916373610496521,
      "learning_rate": 1.4142168674698797e-05,
      "loss": 0.0182,
      "step": 24310
    },
    {
      "epoch": 2.9301204819277107,
      "grad_norm": 0.03259464353322983,
      "learning_rate": 1.413975903614458e-05,
      "loss": 0.0393,
      "step": 24320
    },
    {
      "epoch": 2.9313253012048195,
      "grad_norm": 9.516219139099121,
      "learning_rate": 1.4137349397590364e-05,
      "loss": 0.1207,
      "step": 24330
    },
    {
      "epoch": 2.932530120481928,
      "grad_norm": 0.3474343419075012,
      "learning_rate": 1.4134939759036145e-05,
      "loss": 0.0231,
      "step": 24340
    },
    {
      "epoch": 2.933734939759036,
      "grad_norm": 19.70155906677246,
      "learning_rate": 1.4132530120481928e-05,
      "loss": 0.0744,
      "step": 24350
    },
    {
      "epoch": 2.9349397590361446,
      "grad_norm": 0.14300405979156494,
      "learning_rate": 1.4130120481927712e-05,
      "loss": 0.0279,
      "step": 24360
    },
    {
      "epoch": 2.936144578313253,
      "grad_norm": 0.2829834222793579,
      "learning_rate": 1.4127710843373495e-05,
      "loss": 0.072,
      "step": 24370
    },
    {
      "epoch": 2.9373493975903613,
      "grad_norm": 0.5611587762832642,
      "learning_rate": 1.4125301204819278e-05,
      "loss": 0.0581,
      "step": 24380
    },
    {
      "epoch": 2.9385542168674696,
      "grad_norm": 0.5534657835960388,
      "learning_rate": 1.4122891566265063e-05,
      "loss": 0.0903,
      "step": 24390
    },
    {
      "epoch": 2.9397590361445785,
      "grad_norm": 2.82796049118042,
      "learning_rate": 1.4120481927710844e-05,
      "loss": 0.0989,
      "step": 24400
    },
    {
      "epoch": 2.940963855421687,
      "grad_norm": 0.32530003786087036,
      "learning_rate": 1.4118072289156628e-05,
      "loss": 0.0638,
      "step": 24410
    },
    {
      "epoch": 2.942168674698795,
      "grad_norm": 3.1861205101013184,
      "learning_rate": 1.411566265060241e-05,
      "loss": 0.085,
      "step": 24420
    },
    {
      "epoch": 2.9433734939759035,
      "grad_norm": 0.03388999029994011,
      "learning_rate": 1.4113253012048194e-05,
      "loss": 0.0396,
      "step": 24430
    },
    {
      "epoch": 2.944578313253012,
      "grad_norm": 0.07370147109031677,
      "learning_rate": 1.4110843373493977e-05,
      "loss": 0.0243,
      "step": 24440
    },
    {
      "epoch": 2.9457831325301207,
      "grad_norm": 2.499390125274658,
      "learning_rate": 1.4108433734939759e-05,
      "loss": 0.0327,
      "step": 24450
    },
    {
      "epoch": 2.946987951807229,
      "grad_norm": 29.803913116455078,
      "learning_rate": 1.4106024096385545e-05,
      "loss": 0.114,
      "step": 24460
    },
    {
      "epoch": 2.9481927710843374,
      "grad_norm": 7.086298942565918,
      "learning_rate": 1.4103614457831327e-05,
      "loss": 0.0609,
      "step": 24470
    },
    {
      "epoch": 2.9493975903614458,
      "grad_norm": 5.017430782318115,
      "learning_rate": 1.410120481927711e-05,
      "loss": 0.0681,
      "step": 24480
    },
    {
      "epoch": 2.950602409638554,
      "grad_norm": 3.9098763465881348,
      "learning_rate": 1.4098795180722893e-05,
      "loss": 0.0701,
      "step": 24490
    },
    {
      "epoch": 2.9518072289156625,
      "grad_norm": 3.184386730194092,
      "learning_rate": 1.4096385542168676e-05,
      "loss": 0.0644,
      "step": 24500
    },
    {
      "epoch": 2.953012048192771,
      "grad_norm": 6.259719371795654,
      "learning_rate": 1.409397590361446e-05,
      "loss": 0.0524,
      "step": 24510
    },
    {
      "epoch": 2.9542168674698797,
      "grad_norm": 2.5341873168945312,
      "learning_rate": 1.409156626506024e-05,
      "loss": 0.0418,
      "step": 24520
    },
    {
      "epoch": 2.955421686746988,
      "grad_norm": 0.018661970272660255,
      "learning_rate": 1.4089156626506024e-05,
      "loss": 0.0206,
      "step": 24530
    },
    {
      "epoch": 2.9566265060240964,
      "grad_norm": 2.8761773109436035,
      "learning_rate": 1.4086746987951809e-05,
      "loss": 0.0364,
      "step": 24540
    },
    {
      "epoch": 2.9578313253012047,
      "grad_norm": 0.08190590888261795,
      "learning_rate": 1.4084337349397592e-05,
      "loss": 0.062,
      "step": 24550
    },
    {
      "epoch": 2.959036144578313,
      "grad_norm": 2.5574183464050293,
      "learning_rate": 1.4081927710843375e-05,
      "loss": 0.0582,
      "step": 24560
    },
    {
      "epoch": 2.960240963855422,
      "grad_norm": 4.454233169555664,
      "learning_rate": 1.4079518072289158e-05,
      "loss": 0.0641,
      "step": 24570
    },
    {
      "epoch": 2.9614457831325303,
      "grad_norm": 0.07432234287261963,
      "learning_rate": 1.407710843373494e-05,
      "loss": 0.0522,
      "step": 24580
    },
    {
      "epoch": 2.9626506024096386,
      "grad_norm": 2.446823835372925,
      "learning_rate": 1.4074698795180723e-05,
      "loss": 0.0206,
      "step": 24590
    },
    {
      "epoch": 2.963855421686747,
      "grad_norm": 3.1187329292297363,
      "learning_rate": 1.4072289156626506e-05,
      "loss": 0.0728,
      "step": 24600
    },
    {
      "epoch": 2.9650602409638553,
      "grad_norm": 0.17002026736736298,
      "learning_rate": 1.4069879518072291e-05,
      "loss": 0.0587,
      "step": 24610
    },
    {
      "epoch": 2.9662650602409637,
      "grad_norm": 0.12119642645120621,
      "learning_rate": 1.4067469879518074e-05,
      "loss": 0.0064,
      "step": 24620
    },
    {
      "epoch": 2.967469879518072,
      "grad_norm": 2.578322172164917,
      "learning_rate": 1.4065060240963857e-05,
      "loss": 0.0474,
      "step": 24630
    },
    {
      "epoch": 2.968674698795181,
      "grad_norm": 2.2123374938964844,
      "learning_rate": 1.406265060240964e-05,
      "loss": 0.1419,
      "step": 24640
    },
    {
      "epoch": 2.9698795180722892,
      "grad_norm": 4.628003120422363,
      "learning_rate": 1.4060240963855422e-05,
      "loss": 0.1061,
      "step": 24650
    },
    {
      "epoch": 2.9710843373493976,
      "grad_norm": 0.03727056831121445,
      "learning_rate": 1.4057831325301205e-05,
      "loss": 0.0321,
      "step": 24660
    },
    {
      "epoch": 2.972289156626506,
      "grad_norm": 0.3931870460510254,
      "learning_rate": 1.4055421686746988e-05,
      "loss": 0.0337,
      "step": 24670
    },
    {
      "epoch": 2.9734939759036143,
      "grad_norm": 3.9440507888793945,
      "learning_rate": 1.4053012048192772e-05,
      "loss": 0.0752,
      "step": 24680
    },
    {
      "epoch": 2.974698795180723,
      "grad_norm": 2.9957544803619385,
      "learning_rate": 1.4050602409638556e-05,
      "loss": 0.0648,
      "step": 24690
    },
    {
      "epoch": 2.9759036144578315,
      "grad_norm": 0.24748356640338898,
      "learning_rate": 1.404819277108434e-05,
      "loss": 0.0829,
      "step": 24700
    },
    {
      "epoch": 2.97710843373494,
      "grad_norm": 0.04575757309794426,
      "learning_rate": 1.4045783132530121e-05,
      "loss": 0.0322,
      "step": 24710
    },
    {
      "epoch": 2.978313253012048,
      "grad_norm": 5.599154472351074,
      "learning_rate": 1.4043373493975904e-05,
      "loss": 0.1094,
      "step": 24720
    },
    {
      "epoch": 2.9795180722891565,
      "grad_norm": 1.0014859437942505,
      "learning_rate": 1.4040963855421687e-05,
      "loss": 0.0406,
      "step": 24730
    },
    {
      "epoch": 2.980722891566265,
      "grad_norm": 2.2621686458587646,
      "learning_rate": 1.403855421686747e-05,
      "loss": 0.0518,
      "step": 24740
    },
    {
      "epoch": 2.9819277108433733,
      "grad_norm": 5.287951469421387,
      "learning_rate": 1.4036144578313254e-05,
      "loss": 0.0749,
      "step": 24750
    },
    {
      "epoch": 2.983132530120482,
      "grad_norm": 6.808577060699463,
      "learning_rate": 1.4033734939759039e-05,
      "loss": 0.0157,
      "step": 24760
    },
    {
      "epoch": 2.9843373493975904,
      "grad_norm": 3.2372825145721436,
      "learning_rate": 1.4031325301204822e-05,
      "loss": 0.0722,
      "step": 24770
    },
    {
      "epoch": 2.985542168674699,
      "grad_norm": 0.19598156213760376,
      "learning_rate": 1.4028915662650603e-05,
      "loss": 0.0028,
      "step": 24780
    },
    {
      "epoch": 2.986746987951807,
      "grad_norm": 0.0413498729467392,
      "learning_rate": 1.4026506024096387e-05,
      "loss": 0.0387,
      "step": 24790
    },
    {
      "epoch": 2.9879518072289155,
      "grad_norm": 1.7560335397720337,
      "learning_rate": 1.402409638554217e-05,
      "loss": 0.1179,
      "step": 24800
    },
    {
      "epoch": 2.9891566265060243,
      "grad_norm": 0.3115253150463104,
      "learning_rate": 1.4021686746987953e-05,
      "loss": 0.0491,
      "step": 24810
    },
    {
      "epoch": 2.9903614457831327,
      "grad_norm": 0.3418233394622803,
      "learning_rate": 1.4019277108433736e-05,
      "loss": 0.0521,
      "step": 24820
    },
    {
      "epoch": 2.991566265060241,
      "grad_norm": 0.04666902869939804,
      "learning_rate": 1.4016867469879518e-05,
      "loss": 0.0336,
      "step": 24830
    },
    {
      "epoch": 2.9927710843373494,
      "grad_norm": 0.5728190541267395,
      "learning_rate": 1.4014457831325302e-05,
      "loss": 0.067,
      "step": 24840
    },
    {
      "epoch": 2.9939759036144578,
      "grad_norm": 0.590639054775238,
      "learning_rate": 1.4012048192771086e-05,
      "loss": 0.0625,
      "step": 24850
    },
    {
      "epoch": 2.995180722891566,
      "grad_norm": 2.573845386505127,
      "learning_rate": 1.4009638554216869e-05,
      "loss": 0.0474,
      "step": 24860
    },
    {
      "epoch": 2.9963855421686745,
      "grad_norm": 2.6277952194213867,
      "learning_rate": 1.4007228915662652e-05,
      "loss": 0.0807,
      "step": 24870
    },
    {
      "epoch": 2.9975903614457833,
      "grad_norm": 5.743826866149902,
      "learning_rate": 1.4004819277108435e-05,
      "loss": 0.105,
      "step": 24880
    },
    {
      "epoch": 2.9987951807228916,
      "grad_norm": 0.03236236795783043,
      "learning_rate": 1.4002409638554217e-05,
      "loss": 0.0114,
      "step": 24890
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.31380823254585266,
      "learning_rate": 1.4e-05,
      "loss": 0.0585,
      "step": 24900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9807367829021373,
      "eval_f1": 0.9486442584030987,
      "eval_loss": 0.06354331970214844,
      "eval_precision": 0.9591914087176248,
      "eval_recall": 0.9383265356569027,
      "eval_runtime": 5101.9329,
      "eval_samples_per_second": 8.367,
      "eval_steps_per_second": 0.349,
      "step": 24900
    },
    {
      "epoch": 3.0012048192771084,
      "grad_norm": 7.7502899169921875,
      "learning_rate": 1.3997590361445785e-05,
      "loss": 0.0369,
      "step": 24910
    },
    {
      "epoch": 3.0024096385542167,
      "grad_norm": 0.3059990704059601,
      "learning_rate": 1.3995180722891568e-05,
      "loss": 0.0362,
      "step": 24920
    },
    {
      "epoch": 3.003614457831325,
      "grad_norm": 3.299063205718994,
      "learning_rate": 1.3992771084337351e-05,
      "loss": 0.0441,
      "step": 24930
    },
    {
      "epoch": 3.004819277108434,
      "grad_norm": 6.127422332763672,
      "learning_rate": 1.3990361445783134e-05,
      "loss": 0.0664,
      "step": 24940
    },
    {
      "epoch": 3.0060240963855422,
      "grad_norm": 0.28244107961654663,
      "learning_rate": 1.3987951807228917e-05,
      "loss": 0.0663,
      "step": 24950
    },
    {
      "epoch": 3.0072289156626506,
      "grad_norm": 0.405487596988678,
      "learning_rate": 1.3985542168674699e-05,
      "loss": 0.0201,
      "step": 24960
    },
    {
      "epoch": 3.008433734939759,
      "grad_norm": 0.14964014291763306,
      "learning_rate": 1.3983132530120482e-05,
      "loss": 0.0091,
      "step": 24970
    },
    {
      "epoch": 3.0096385542168673,
      "grad_norm": 0.4185253381729126,
      "learning_rate": 1.3980722891566265e-05,
      "loss": 0.018,
      "step": 24980
    },
    {
      "epoch": 3.0108433734939757,
      "grad_norm": 8.991584777832031,
      "learning_rate": 1.397831325301205e-05,
      "loss": 0.0696,
      "step": 24990
    },
    {
      "epoch": 3.0120481927710845,
      "grad_norm": 2.7887086868286133,
      "learning_rate": 1.3975903614457833e-05,
      "loss": 0.0639,
      "step": 25000
    },
    {
      "epoch": 3.013253012048193,
      "grad_norm": 0.14932745695114136,
      "learning_rate": 1.3973493975903616e-05,
      "loss": 0.0024,
      "step": 25010
    },
    {
      "epoch": 3.014457831325301,
      "grad_norm": 0.18924255669116974,
      "learning_rate": 1.3971084337349398e-05,
      "loss": 0.0351,
      "step": 25020
    },
    {
      "epoch": 3.0156626506024096,
      "grad_norm": 0.032420169562101364,
      "learning_rate": 1.3968674698795181e-05,
      "loss": 0.0533,
      "step": 25030
    },
    {
      "epoch": 3.016867469879518,
      "grad_norm": 0.5429943203926086,
      "learning_rate": 1.3966265060240964e-05,
      "loss": 0.0761,
      "step": 25040
    },
    {
      "epoch": 3.0180722891566263,
      "grad_norm": 0.025359636172652245,
      "learning_rate": 1.3963855421686747e-05,
      "loss": 0.0063,
      "step": 25050
    },
    {
      "epoch": 3.019277108433735,
      "grad_norm": 0.00683219451457262,
      "learning_rate": 1.3961445783132532e-05,
      "loss": 0.0336,
      "step": 25060
    },
    {
      "epoch": 3.0204819277108435,
      "grad_norm": 0.0356346033513546,
      "learning_rate": 1.3959036144578315e-05,
      "loss": 0.0239,
      "step": 25070
    },
    {
      "epoch": 3.021686746987952,
      "grad_norm": 7.240160942077637,
      "learning_rate": 1.3956626506024099e-05,
      "loss": 0.017,
      "step": 25080
    },
    {
      "epoch": 3.02289156626506,
      "grad_norm": 0.4506660997867584,
      "learning_rate": 1.395421686746988e-05,
      "loss": 0.048,
      "step": 25090
    },
    {
      "epoch": 3.0240963855421685,
      "grad_norm": 0.7555605173110962,
      "learning_rate": 1.3951807228915663e-05,
      "loss": 0.0541,
      "step": 25100
    },
    {
      "epoch": 3.025301204819277,
      "grad_norm": 5.0462236404418945,
      "learning_rate": 1.3949397590361446e-05,
      "loss": 0.059,
      "step": 25110
    },
    {
      "epoch": 3.0265060240963857,
      "grad_norm": 2.0234053134918213,
      "learning_rate": 1.394698795180723e-05,
      "loss": 0.0922,
      "step": 25120
    },
    {
      "epoch": 3.027710843373494,
      "grad_norm": 0.4804270565509796,
      "learning_rate": 1.3944578313253013e-05,
      "loss": 0.0231,
      "step": 25130
    },
    {
      "epoch": 3.0289156626506024,
      "grad_norm": 2.8809616565704346,
      "learning_rate": 1.3942168674698798e-05,
      "loss": 0.0873,
      "step": 25140
    },
    {
      "epoch": 3.0301204819277108,
      "grad_norm": 0.3884839713573456,
      "learning_rate": 1.393975903614458e-05,
      "loss": 0.0286,
      "step": 25150
    },
    {
      "epoch": 3.031325301204819,
      "grad_norm": 0.6721356511116028,
      "learning_rate": 1.3937349397590362e-05,
      "loss": 0.0264,
      "step": 25160
    },
    {
      "epoch": 3.0325301204819275,
      "grad_norm": 6.049813270568848,
      "learning_rate": 1.3934939759036146e-05,
      "loss": 0.0632,
      "step": 25170
    },
    {
      "epoch": 3.0337349397590363,
      "grad_norm": 0.7534323930740356,
      "learning_rate": 1.3932530120481929e-05,
      "loss": 0.0744,
      "step": 25180
    },
    {
      "epoch": 3.0349397590361447,
      "grad_norm": 0.21439267694950104,
      "learning_rate": 1.3930120481927712e-05,
      "loss": 0.0676,
      "step": 25190
    },
    {
      "epoch": 3.036144578313253,
      "grad_norm": 0.06485984474420547,
      "learning_rate": 1.3927710843373493e-05,
      "loss": 0.108,
      "step": 25200
    },
    {
      "epoch": 3.0373493975903614,
      "grad_norm": 0.481502890586853,
      "learning_rate": 1.392530120481928e-05,
      "loss": 0.0477,
      "step": 25210
    },
    {
      "epoch": 3.0385542168674697,
      "grad_norm": 2.263148784637451,
      "learning_rate": 1.3922891566265061e-05,
      "loss": 0.0423,
      "step": 25220
    },
    {
      "epoch": 3.039759036144578,
      "grad_norm": 0.07344899326562881,
      "learning_rate": 1.3920481927710845e-05,
      "loss": 0.0697,
      "step": 25230
    },
    {
      "epoch": 3.040963855421687,
      "grad_norm": 0.04507175087928772,
      "learning_rate": 1.3918072289156628e-05,
      "loss": 0.0336,
      "step": 25240
    },
    {
      "epoch": 3.0421686746987953,
      "grad_norm": 1.2957351207733154,
      "learning_rate": 1.3915662650602411e-05,
      "loss": 0.0791,
      "step": 25250
    },
    {
      "epoch": 3.0433734939759036,
      "grad_norm": 0.37537670135498047,
      "learning_rate": 1.3913253012048194e-05,
      "loss": 0.0126,
      "step": 25260
    },
    {
      "epoch": 3.044578313253012,
      "grad_norm": 1.1639429330825806,
      "learning_rate": 1.3910843373493976e-05,
      "loss": 0.0485,
      "step": 25270
    },
    {
      "epoch": 3.0457831325301203,
      "grad_norm": 1.1280826330184937,
      "learning_rate": 1.3908433734939759e-05,
      "loss": 0.0343,
      "step": 25280
    },
    {
      "epoch": 3.0469879518072287,
      "grad_norm": 2.5422987937927246,
      "learning_rate": 1.3906024096385544e-05,
      "loss": 0.0296,
      "step": 25290
    },
    {
      "epoch": 3.0481927710843375,
      "grad_norm": 4.0235700607299805,
      "learning_rate": 1.3903614457831327e-05,
      "loss": 0.0678,
      "step": 25300
    },
    {
      "epoch": 3.049397590361446,
      "grad_norm": 1.7044249773025513,
      "learning_rate": 1.390120481927711e-05,
      "loss": 0.0442,
      "step": 25310
    },
    {
      "epoch": 3.0506024096385542,
      "grad_norm": 4.75201416015625,
      "learning_rate": 1.3898795180722893e-05,
      "loss": 0.0518,
      "step": 25320
    },
    {
      "epoch": 3.0518072289156626,
      "grad_norm": 0.039289724081754684,
      "learning_rate": 1.3896385542168676e-05,
      "loss": 0.0365,
      "step": 25330
    },
    {
      "epoch": 3.053012048192771,
      "grad_norm": 0.08792177587747574,
      "learning_rate": 1.3893975903614458e-05,
      "loss": 0.0627,
      "step": 25340
    },
    {
      "epoch": 3.0542168674698793,
      "grad_norm": 2.8970439434051514,
      "learning_rate": 1.3891566265060241e-05,
      "loss": 0.0495,
      "step": 25350
    },
    {
      "epoch": 3.055421686746988,
      "grad_norm": 0.19091983139514923,
      "learning_rate": 1.3889156626506026e-05,
      "loss": 0.0223,
      "step": 25360
    },
    {
      "epoch": 3.0566265060240965,
      "grad_norm": 0.09069047123193741,
      "learning_rate": 1.3886746987951809e-05,
      "loss": 0.0775,
      "step": 25370
    },
    {
      "epoch": 3.057831325301205,
      "grad_norm": 2.544098138809204,
      "learning_rate": 1.3884337349397592e-05,
      "loss": 0.0449,
      "step": 25380
    },
    {
      "epoch": 3.059036144578313,
      "grad_norm": 0.03437412902712822,
      "learning_rate": 1.3881927710843375e-05,
      "loss": 0.0772,
      "step": 25390
    },
    {
      "epoch": 3.0602409638554215,
      "grad_norm": 13.30636978149414,
      "learning_rate": 1.3879518072289157e-05,
      "loss": 0.0453,
      "step": 25400
    },
    {
      "epoch": 3.06144578313253,
      "grad_norm": 7.877742290496826,
      "learning_rate": 1.387710843373494e-05,
      "loss": 0.0949,
      "step": 25410
    },
    {
      "epoch": 3.0626506024096387,
      "grad_norm": 1.5211995840072632,
      "learning_rate": 1.3874698795180723e-05,
      "loss": 0.0961,
      "step": 25420
    },
    {
      "epoch": 3.063855421686747,
      "grad_norm": 0.8430082201957703,
      "learning_rate": 1.3872289156626506e-05,
      "loss": 0.0315,
      "step": 25430
    },
    {
      "epoch": 3.0650602409638554,
      "grad_norm": 0.07101918011903763,
      "learning_rate": 1.3869879518072291e-05,
      "loss": 0.0396,
      "step": 25440
    },
    {
      "epoch": 3.066265060240964,
      "grad_norm": 4.022860527038574,
      "learning_rate": 1.3867469879518074e-05,
      "loss": 0.0471,
      "step": 25450
    },
    {
      "epoch": 3.067469879518072,
      "grad_norm": 0.18855035305023193,
      "learning_rate": 1.3865060240963858e-05,
      "loss": 0.0547,
      "step": 25460
    },
    {
      "epoch": 3.0686746987951805,
      "grad_norm": 0.28701046109199524,
      "learning_rate": 1.3862650602409639e-05,
      "loss": 0.0283,
      "step": 25470
    },
    {
      "epoch": 3.0698795180722893,
      "grad_norm": 0.012437796220183372,
      "learning_rate": 1.3860240963855422e-05,
      "loss": 0.0144,
      "step": 25480
    },
    {
      "epoch": 3.0710843373493977,
      "grad_norm": 1.39333975315094,
      "learning_rate": 1.3857831325301205e-05,
      "loss": 0.063,
      "step": 25490
    },
    {
      "epoch": 3.072289156626506,
      "grad_norm": 9.173179626464844,
      "learning_rate": 1.3855421686746989e-05,
      "loss": 0.0416,
      "step": 25500
    },
    {
      "epoch": 3.0734939759036144,
      "grad_norm": 3.2610623836517334,
      "learning_rate": 1.3853012048192774e-05,
      "loss": 0.0126,
      "step": 25510
    },
    {
      "epoch": 3.0746987951807228,
      "grad_norm": 0.4942874610424042,
      "learning_rate": 1.3850602409638557e-05,
      "loss": 0.0386,
      "step": 25520
    },
    {
      "epoch": 3.075903614457831,
      "grad_norm": 0.23944790661334991,
      "learning_rate": 1.3848192771084338e-05,
      "loss": 0.013,
      "step": 25530
    },
    {
      "epoch": 3.07710843373494,
      "grad_norm": 2.829129219055176,
      "learning_rate": 1.3845783132530121e-05,
      "loss": 0.0602,
      "step": 25540
    },
    {
      "epoch": 3.0783132530120483,
      "grad_norm": 0.10566794872283936,
      "learning_rate": 1.3843373493975905e-05,
      "loss": 0.0243,
      "step": 25550
    },
    {
      "epoch": 3.0795180722891566,
      "grad_norm": 0.004139266908168793,
      "learning_rate": 1.3840963855421688e-05,
      "loss": 0.0137,
      "step": 25560
    },
    {
      "epoch": 3.080722891566265,
      "grad_norm": 0.9911665916442871,
      "learning_rate": 1.3838554216867471e-05,
      "loss": 0.0461,
      "step": 25570
    },
    {
      "epoch": 3.0819277108433734,
      "grad_norm": 0.7856845259666443,
      "learning_rate": 1.3836144578313252e-05,
      "loss": 0.0306,
      "step": 25580
    },
    {
      "epoch": 3.0831325301204817,
      "grad_norm": 0.10210180282592773,
      "learning_rate": 1.3833734939759039e-05,
      "loss": 0.0859,
      "step": 25590
    },
    {
      "epoch": 3.0843373493975905,
      "grad_norm": 0.0208592526614666,
      "learning_rate": 1.383132530120482e-05,
      "loss": 0.022,
      "step": 25600
    },
    {
      "epoch": 3.085542168674699,
      "grad_norm": 0.011548109352588654,
      "learning_rate": 1.3828915662650604e-05,
      "loss": 0.0094,
      "step": 25610
    },
    {
      "epoch": 3.0867469879518072,
      "grad_norm": 3.5607004165649414,
      "learning_rate": 1.3826506024096387e-05,
      "loss": 0.0588,
      "step": 25620
    },
    {
      "epoch": 3.0879518072289156,
      "grad_norm": 0.06269541382789612,
      "learning_rate": 1.382409638554217e-05,
      "loss": 0.0291,
      "step": 25630
    },
    {
      "epoch": 3.089156626506024,
      "grad_norm": 0.7201472520828247,
      "learning_rate": 1.3821686746987953e-05,
      "loss": 0.0474,
      "step": 25640
    },
    {
      "epoch": 3.0903614457831323,
      "grad_norm": 0.8562837839126587,
      "learning_rate": 1.3819277108433735e-05,
      "loss": 0.0117,
      "step": 25650
    },
    {
      "epoch": 3.091566265060241,
      "grad_norm": 0.052588846534490585,
      "learning_rate": 1.381686746987952e-05,
      "loss": 0.0104,
      "step": 25660
    },
    {
      "epoch": 3.0927710843373495,
      "grad_norm": 0.029554590582847595,
      "learning_rate": 1.3814457831325303e-05,
      "loss": 0.1032,
      "step": 25670
    },
    {
      "epoch": 3.093975903614458,
      "grad_norm": 0.014016157016158104,
      "learning_rate": 1.3812048192771086e-05,
      "loss": 0.0609,
      "step": 25680
    },
    {
      "epoch": 3.095180722891566,
      "grad_norm": 3.436171054840088,
      "learning_rate": 1.3809638554216869e-05,
      "loss": 0.0592,
      "step": 25690
    },
    {
      "epoch": 3.0963855421686746,
      "grad_norm": 0.019594838842749596,
      "learning_rate": 1.3807228915662652e-05,
      "loss": 0.0409,
      "step": 25700
    },
    {
      "epoch": 3.097590361445783,
      "grad_norm": 0.2899046838283539,
      "learning_rate": 1.3804819277108434e-05,
      "loss": 0.0296,
      "step": 25710
    },
    {
      "epoch": 3.0987951807228917,
      "grad_norm": 9.954405784606934,
      "learning_rate": 1.3802409638554217e-05,
      "loss": 0.0249,
      "step": 25720
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.13448962569236755,
      "learning_rate": 1.38e-05,
      "loss": 0.0215,
      "step": 25730
    },
    {
      "epoch": 3.1012048192771084,
      "grad_norm": 0.6735941171646118,
      "learning_rate": 1.3797590361445785e-05,
      "loss": 0.0509,
      "step": 25740
    },
    {
      "epoch": 3.102409638554217,
      "grad_norm": 2.729306936264038,
      "learning_rate": 1.3795180722891568e-05,
      "loss": 0.0437,
      "step": 25750
    },
    {
      "epoch": 3.103614457831325,
      "grad_norm": 0.05502955988049507,
      "learning_rate": 1.3792771084337351e-05,
      "loss": 0.0757,
      "step": 25760
    },
    {
      "epoch": 3.1048192771084335,
      "grad_norm": 0.2632880210876465,
      "learning_rate": 1.3790361445783134e-05,
      "loss": 0.0507,
      "step": 25770
    },
    {
      "epoch": 3.1060240963855423,
      "grad_norm": 0.15047138929367065,
      "learning_rate": 1.3787951807228916e-05,
      "loss": 0.0805,
      "step": 25780
    },
    {
      "epoch": 3.1072289156626507,
      "grad_norm": 0.1258806437253952,
      "learning_rate": 1.3785542168674699e-05,
      "loss": 0.045,
      "step": 25790
    },
    {
      "epoch": 3.108433734939759,
      "grad_norm": 0.011837229132652283,
      "learning_rate": 1.3783132530120482e-05,
      "loss": 0.0201,
      "step": 25800
    },
    {
      "epoch": 3.1096385542168674,
      "grad_norm": 13.37006950378418,
      "learning_rate": 1.3780722891566267e-05,
      "loss": 0.0465,
      "step": 25810
    },
    {
      "epoch": 3.1108433734939758,
      "grad_norm": 9.558562278747559,
      "learning_rate": 1.377831325301205e-05,
      "loss": 0.0702,
      "step": 25820
    },
    {
      "epoch": 3.112048192771084,
      "grad_norm": 0.06433942914009094,
      "learning_rate": 1.3775903614457833e-05,
      "loss": 0.0551,
      "step": 25830
    },
    {
      "epoch": 3.113253012048193,
      "grad_norm": 0.057822369039058685,
      "learning_rate": 1.3773493975903615e-05,
      "loss": 0.0309,
      "step": 25840
    },
    {
      "epoch": 3.1144578313253013,
      "grad_norm": 0.10538103431463242,
      "learning_rate": 1.3771084337349398e-05,
      "loss": 0.0279,
      "step": 25850
    },
    {
      "epoch": 3.1156626506024097,
      "grad_norm": 1.932630181312561,
      "learning_rate": 1.3768674698795181e-05,
      "loss": 0.0256,
      "step": 25860
    },
    {
      "epoch": 3.116867469879518,
      "grad_norm": 0.06084250658750534,
      "learning_rate": 1.3766265060240964e-05,
      "loss": 0.0434,
      "step": 25870
    },
    {
      "epoch": 3.1180722891566264,
      "grad_norm": 9.177040100097656,
      "learning_rate": 1.3763855421686748e-05,
      "loss": 0.0178,
      "step": 25880
    },
    {
      "epoch": 3.1192771084337347,
      "grad_norm": 0.02496793307363987,
      "learning_rate": 1.3761445783132533e-05,
      "loss": 0.0121,
      "step": 25890
    },
    {
      "epoch": 3.1204819277108435,
      "grad_norm": 1.516294002532959,
      "learning_rate": 1.3759036144578316e-05,
      "loss": 0.043,
      "step": 25900
    },
    {
      "epoch": 3.121686746987952,
      "grad_norm": 0.053223613649606705,
      "learning_rate": 1.3756626506024097e-05,
      "loss": 0.0112,
      "step": 25910
    },
    {
      "epoch": 3.1228915662650603,
      "grad_norm": 13.508933067321777,
      "learning_rate": 1.375421686746988e-05,
      "loss": 0.0641,
      "step": 25920
    },
    {
      "epoch": 3.1240963855421686,
      "grad_norm": 0.014645825140178204,
      "learning_rate": 1.3751807228915664e-05,
      "loss": 0.0572,
      "step": 25930
    },
    {
      "epoch": 3.125301204819277,
      "grad_norm": 0.7068994045257568,
      "learning_rate": 1.3749397590361447e-05,
      "loss": 0.0431,
      "step": 25940
    },
    {
      "epoch": 3.1265060240963853,
      "grad_norm": 0.007623647805303335,
      "learning_rate": 1.374698795180723e-05,
      "loss": 0.0688,
      "step": 25950
    },
    {
      "epoch": 3.127710843373494,
      "grad_norm": 0.03552957996726036,
      "learning_rate": 1.3744578313253015e-05,
      "loss": 0.0509,
      "step": 25960
    },
    {
      "epoch": 3.1289156626506025,
      "grad_norm": 0.03969867154955864,
      "learning_rate": 1.3742168674698796e-05,
      "loss": 0.0506,
      "step": 25970
    },
    {
      "epoch": 3.130120481927711,
      "grad_norm": 0.22634059190750122,
      "learning_rate": 1.373975903614458e-05,
      "loss": 0.0411,
      "step": 25980
    },
    {
      "epoch": 3.1313253012048192,
      "grad_norm": 2.656096935272217,
      "learning_rate": 1.3737349397590363e-05,
      "loss": 0.0203,
      "step": 25990
    },
    {
      "epoch": 3.1325301204819276,
      "grad_norm": 2.9887595176696777,
      "learning_rate": 1.3734939759036146e-05,
      "loss": 0.0915,
      "step": 26000
    },
    {
      "epoch": 3.133734939759036,
      "grad_norm": 7.922403335571289,
      "learning_rate": 1.3732530120481929e-05,
      "loss": 0.0631,
      "step": 26010
    },
    {
      "epoch": 3.1349397590361447,
      "grad_norm": 18.911766052246094,
      "learning_rate": 1.373012048192771e-05,
      "loss": 0.0504,
      "step": 26020
    },
    {
      "epoch": 3.136144578313253,
      "grad_norm": 0.836220383644104,
      "learning_rate": 1.3727710843373494e-05,
      "loss": 0.0301,
      "step": 26030
    },
    {
      "epoch": 3.1373493975903615,
      "grad_norm": 0.173082634806633,
      "learning_rate": 1.3725301204819278e-05,
      "loss": 0.0654,
      "step": 26040
    },
    {
      "epoch": 3.13855421686747,
      "grad_norm": 0.4004223942756653,
      "learning_rate": 1.3722891566265062e-05,
      "loss": 0.0266,
      "step": 26050
    },
    {
      "epoch": 3.139759036144578,
      "grad_norm": 3.7863664627075195,
      "learning_rate": 1.3720481927710845e-05,
      "loss": 0.0349,
      "step": 26060
    },
    {
      "epoch": 3.1409638554216865,
      "grad_norm": 0.7469165325164795,
      "learning_rate": 1.3718072289156628e-05,
      "loss": 0.0139,
      "step": 26070
    },
    {
      "epoch": 3.1421686746987953,
      "grad_norm": 0.34052619338035583,
      "learning_rate": 1.3715662650602411e-05,
      "loss": 0.0668,
      "step": 26080
    },
    {
      "epoch": 3.1433734939759037,
      "grad_norm": 0.28183335065841675,
      "learning_rate": 1.3713253012048193e-05,
      "loss": 0.0066,
      "step": 26090
    },
    {
      "epoch": 3.144578313253012,
      "grad_norm": 5.158875465393066,
      "learning_rate": 1.3710843373493976e-05,
      "loss": 0.0279,
      "step": 26100
    },
    {
      "epoch": 3.1457831325301204,
      "grad_norm": 0.01972656324505806,
      "learning_rate": 1.370843373493976e-05,
      "loss": 0.0336,
      "step": 26110
    },
    {
      "epoch": 3.146987951807229,
      "grad_norm": 2.122453451156616,
      "learning_rate": 1.3706024096385544e-05,
      "loss": 0.0251,
      "step": 26120
    },
    {
      "epoch": 3.148192771084337,
      "grad_norm": 0.09154552221298218,
      "learning_rate": 1.3703614457831327e-05,
      "loss": 0.0107,
      "step": 26130
    },
    {
      "epoch": 3.149397590361446,
      "grad_norm": 0.007523208856582642,
      "learning_rate": 1.370120481927711e-05,
      "loss": 0.0048,
      "step": 26140
    },
    {
      "epoch": 3.1506024096385543,
      "grad_norm": 3.0251152515411377,
      "learning_rate": 1.3698795180722892e-05,
      "loss": 0.0491,
      "step": 26150
    },
    {
      "epoch": 3.1518072289156627,
      "grad_norm": 0.051654428243637085,
      "learning_rate": 1.3696385542168675e-05,
      "loss": 0.0925,
      "step": 26160
    },
    {
      "epoch": 3.153012048192771,
      "grad_norm": 0.005877938587218523,
      "learning_rate": 1.3693975903614458e-05,
      "loss": 0.0131,
      "step": 26170
    },
    {
      "epoch": 3.1542168674698794,
      "grad_norm": 0.008542117662727833,
      "learning_rate": 1.3691566265060241e-05,
      "loss": 0.164,
      "step": 26180
    },
    {
      "epoch": 3.1554216867469878,
      "grad_norm": 0.3127540946006775,
      "learning_rate": 1.3689156626506026e-05,
      "loss": 0.0656,
      "step": 26190
    },
    {
      "epoch": 3.1566265060240966,
      "grad_norm": 0.03591403365135193,
      "learning_rate": 1.368674698795181e-05,
      "loss": 0.0285,
      "step": 26200
    },
    {
      "epoch": 3.157831325301205,
      "grad_norm": 0.2384219914674759,
      "learning_rate": 1.3684337349397592e-05,
      "loss": 0.0573,
      "step": 26210
    },
    {
      "epoch": 3.1590361445783133,
      "grad_norm": 0.03632922098040581,
      "learning_rate": 1.3681927710843374e-05,
      "loss": 0.0131,
      "step": 26220
    },
    {
      "epoch": 3.1602409638554216,
      "grad_norm": 0.15801793336868286,
      "learning_rate": 1.3679518072289157e-05,
      "loss": 0.1146,
      "step": 26230
    },
    {
      "epoch": 3.16144578313253,
      "grad_norm": 3.7659246921539307,
      "learning_rate": 1.367710843373494e-05,
      "loss": 0.0723,
      "step": 26240
    },
    {
      "epoch": 3.1626506024096384,
      "grad_norm": 0.549693763256073,
      "learning_rate": 1.3674698795180723e-05,
      "loss": 0.0358,
      "step": 26250
    },
    {
      "epoch": 3.163855421686747,
      "grad_norm": 0.13420821726322174,
      "learning_rate": 1.3672289156626508e-05,
      "loss": 0.0691,
      "step": 26260
    },
    {
      "epoch": 3.1650602409638555,
      "grad_norm": 1.0432051420211792,
      "learning_rate": 1.3669879518072292e-05,
      "loss": 0.0161,
      "step": 26270
    },
    {
      "epoch": 3.166265060240964,
      "grad_norm": 0.059619028121232986,
      "learning_rate": 1.3667469879518073e-05,
      "loss": 0.0665,
      "step": 26280
    },
    {
      "epoch": 3.1674698795180722,
      "grad_norm": 2.278078317642212,
      "learning_rate": 1.3665060240963856e-05,
      "loss": 0.0333,
      "step": 26290
    },
    {
      "epoch": 3.1686746987951806,
      "grad_norm": 0.12424615025520325,
      "learning_rate": 1.366265060240964e-05,
      "loss": 0.0527,
      "step": 26300
    },
    {
      "epoch": 3.169879518072289,
      "grad_norm": 0.08519252389669418,
      "learning_rate": 1.3660240963855423e-05,
      "loss": 0.0878,
      "step": 26310
    },
    {
      "epoch": 3.1710843373493978,
      "grad_norm": 0.060290079563856125,
      "learning_rate": 1.3657831325301206e-05,
      "loss": 0.0721,
      "step": 26320
    },
    {
      "epoch": 3.172289156626506,
      "grad_norm": 0.05079098418354988,
      "learning_rate": 1.3655421686746987e-05,
      "loss": 0.0105,
      "step": 26330
    },
    {
      "epoch": 3.1734939759036145,
      "grad_norm": 0.6310327053070068,
      "learning_rate": 1.3653012048192774e-05,
      "loss": 0.0359,
      "step": 26340
    },
    {
      "epoch": 3.174698795180723,
      "grad_norm": 8.268290519714355,
      "learning_rate": 1.3650602409638555e-05,
      "loss": 0.0473,
      "step": 26350
    },
    {
      "epoch": 3.175903614457831,
      "grad_norm": 0.010828918777406216,
      "learning_rate": 1.3648192771084338e-05,
      "loss": 0.0206,
      "step": 26360
    },
    {
      "epoch": 3.1771084337349396,
      "grad_norm": 0.17931297421455383,
      "learning_rate": 1.3645783132530122e-05,
      "loss": 0.03,
      "step": 26370
    },
    {
      "epoch": 3.1783132530120484,
      "grad_norm": 0.09456174820661545,
      "learning_rate": 1.3643373493975905e-05,
      "loss": 0.0227,
      "step": 26380
    },
    {
      "epoch": 3.1795180722891567,
      "grad_norm": 0.22938457131385803,
      "learning_rate": 1.3640963855421688e-05,
      "loss": 0.0657,
      "step": 26390
    },
    {
      "epoch": 3.180722891566265,
      "grad_norm": 0.0323842354118824,
      "learning_rate": 1.363855421686747e-05,
      "loss": 0.0577,
      "step": 26400
    },
    {
      "epoch": 3.1819277108433734,
      "grad_norm": 0.03885187581181526,
      "learning_rate": 1.3636144578313254e-05,
      "loss": 0.0289,
      "step": 26410
    },
    {
      "epoch": 3.183132530120482,
      "grad_norm": 0.7283999919891357,
      "learning_rate": 1.3633734939759037e-05,
      "loss": 0.0823,
      "step": 26420
    },
    {
      "epoch": 3.18433734939759,
      "grad_norm": 0.12311401963233948,
      "learning_rate": 1.363132530120482e-05,
      "loss": 0.0355,
      "step": 26430
    },
    {
      "epoch": 3.185542168674699,
      "grad_norm": 0.43210819363594055,
      "learning_rate": 1.3628915662650604e-05,
      "loss": 0.0183,
      "step": 26440
    },
    {
      "epoch": 3.1867469879518073,
      "grad_norm": 0.19497627019882202,
      "learning_rate": 1.3626506024096387e-05,
      "loss": 0.0444,
      "step": 26450
    },
    {
      "epoch": 3.1879518072289157,
      "grad_norm": 0.9176154136657715,
      "learning_rate": 1.3624096385542168e-05,
      "loss": 0.0262,
      "step": 26460
    },
    {
      "epoch": 3.189156626506024,
      "grad_norm": 0.006689159665256739,
      "learning_rate": 1.3621686746987952e-05,
      "loss": 0.0099,
      "step": 26470
    },
    {
      "epoch": 3.1903614457831324,
      "grad_norm": 0.20405852794647217,
      "learning_rate": 1.3619277108433735e-05,
      "loss": 0.093,
      "step": 26480
    },
    {
      "epoch": 3.1915662650602408,
      "grad_norm": 0.05807860195636749,
      "learning_rate": 1.361686746987952e-05,
      "loss": 0.0162,
      "step": 26490
    },
    {
      "epoch": 3.1927710843373496,
      "grad_norm": 2.7423958778381348,
      "learning_rate": 1.3614457831325303e-05,
      "loss": 0.0561,
      "step": 26500
    },
    {
      "epoch": 3.193975903614458,
      "grad_norm": 4.716823101043701,
      "learning_rate": 1.3612048192771086e-05,
      "loss": 0.0838,
      "step": 26510
    },
    {
      "epoch": 3.1951807228915663,
      "grad_norm": 10.898058891296387,
      "learning_rate": 1.360963855421687e-05,
      "loss": 0.0526,
      "step": 26520
    },
    {
      "epoch": 3.1963855421686747,
      "grad_norm": 0.29755887389183044,
      "learning_rate": 1.360722891566265e-05,
      "loss": 0.0358,
      "step": 26530
    },
    {
      "epoch": 3.197590361445783,
      "grad_norm": 7.916381359100342,
      "learning_rate": 1.3604819277108434e-05,
      "loss": 0.0367,
      "step": 26540
    },
    {
      "epoch": 3.1987951807228914,
      "grad_norm": 2.206554651260376,
      "learning_rate": 1.3602409638554217e-05,
      "loss": 0.0593,
      "step": 26550
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.04742378741502762,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0469,
      "step": 26560
    },
    {
      "epoch": 3.2012048192771085,
      "grad_norm": 4.39724063873291,
      "learning_rate": 1.3597590361445785e-05,
      "loss": 0.041,
      "step": 26570
    },
    {
      "epoch": 3.202409638554217,
      "grad_norm": 0.09136493504047394,
      "learning_rate": 1.3595180722891568e-05,
      "loss": 0.0689,
      "step": 26580
    },
    {
      "epoch": 3.2036144578313253,
      "grad_norm": 0.06728529185056686,
      "learning_rate": 1.359277108433735e-05,
      "loss": 0.0158,
      "step": 26590
    },
    {
      "epoch": 3.2048192771084336,
      "grad_norm": 1.226698398590088,
      "learning_rate": 1.3590361445783133e-05,
      "loss": 0.0857,
      "step": 26600
    },
    {
      "epoch": 3.206024096385542,
      "grad_norm": 0.4438798725605011,
      "learning_rate": 1.3587951807228916e-05,
      "loss": 0.0886,
      "step": 26610
    },
    {
      "epoch": 3.207228915662651,
      "grad_norm": 0.45244738459587097,
      "learning_rate": 1.35855421686747e-05,
      "loss": 0.0663,
      "step": 26620
    },
    {
      "epoch": 3.208433734939759,
      "grad_norm": 0.19284768402576447,
      "learning_rate": 1.3583132530120482e-05,
      "loss": 0.0265,
      "step": 26630
    },
    {
      "epoch": 3.2096385542168675,
      "grad_norm": 2.548626661300659,
      "learning_rate": 1.3580722891566267e-05,
      "loss": 0.0324,
      "step": 26640
    },
    {
      "epoch": 3.210843373493976,
      "grad_norm": 0.13236495852470398,
      "learning_rate": 1.357831325301205e-05,
      "loss": 0.0332,
      "step": 26650
    },
    {
      "epoch": 3.212048192771084,
      "grad_norm": 0.6310986876487732,
      "learning_rate": 1.3575903614457832e-05,
      "loss": 0.0775,
      "step": 26660
    },
    {
      "epoch": 3.2132530120481926,
      "grad_norm": 0.4973377585411072,
      "learning_rate": 1.3573493975903615e-05,
      "loss": 0.0437,
      "step": 26670
    },
    {
      "epoch": 3.2144578313253014,
      "grad_norm": 0.10413563996553421,
      "learning_rate": 1.3571084337349398e-05,
      "loss": 0.0502,
      "step": 26680
    },
    {
      "epoch": 3.2156626506024097,
      "grad_norm": 0.22646434605121613,
      "learning_rate": 1.3568674698795182e-05,
      "loss": 0.0761,
      "step": 26690
    },
    {
      "epoch": 3.216867469879518,
      "grad_norm": 0.08692878484725952,
      "learning_rate": 1.3566265060240965e-05,
      "loss": 0.0234,
      "step": 26700
    },
    {
      "epoch": 3.2180722891566265,
      "grad_norm": 0.18651209771633148,
      "learning_rate": 1.356385542168675e-05,
      "loss": 0.0525,
      "step": 26710
    },
    {
      "epoch": 3.219277108433735,
      "grad_norm": 0.04287020489573479,
      "learning_rate": 1.3561445783132533e-05,
      "loss": 0.0725,
      "step": 26720
    },
    {
      "epoch": 3.220481927710843,
      "grad_norm": 1.1645694971084595,
      "learning_rate": 1.3559036144578314e-05,
      "loss": 0.0357,
      "step": 26730
    },
    {
      "epoch": 3.221686746987952,
      "grad_norm": 2.253847599029541,
      "learning_rate": 1.3556626506024097e-05,
      "loss": 0.071,
      "step": 26740
    },
    {
      "epoch": 3.2228915662650603,
      "grad_norm": 0.059658970683813095,
      "learning_rate": 1.355421686746988e-05,
      "loss": 0.0715,
      "step": 26750
    },
    {
      "epoch": 3.2240963855421687,
      "grad_norm": 0.036171361804008484,
      "learning_rate": 1.3551807228915664e-05,
      "loss": 0.0324,
      "step": 26760
    },
    {
      "epoch": 3.225301204819277,
      "grad_norm": 0.027429640293121338,
      "learning_rate": 1.3549397590361447e-05,
      "loss": 0.0346,
      "step": 26770
    },
    {
      "epoch": 3.2265060240963854,
      "grad_norm": 7.283446788787842,
      "learning_rate": 1.3546987951807228e-05,
      "loss": 0.0908,
      "step": 26780
    },
    {
      "epoch": 3.227710843373494,
      "grad_norm": 4.342841625213623,
      "learning_rate": 1.3544578313253013e-05,
      "loss": 0.0704,
      "step": 26790
    },
    {
      "epoch": 3.2289156626506026,
      "grad_norm": 0.16130419075489044,
      "learning_rate": 1.3542168674698796e-05,
      "loss": 0.034,
      "step": 26800
    },
    {
      "epoch": 3.230120481927711,
      "grad_norm": 2.2463526725769043,
      "learning_rate": 1.353975903614458e-05,
      "loss": 0.0293,
      "step": 26810
    },
    {
      "epoch": 3.2313253012048193,
      "grad_norm": 2.3701038360595703,
      "learning_rate": 1.3537349397590363e-05,
      "loss": 0.0624,
      "step": 26820
    },
    {
      "epoch": 3.2325301204819277,
      "grad_norm": 0.2822176218032837,
      "learning_rate": 1.3534939759036146e-05,
      "loss": 0.0315,
      "step": 26830
    },
    {
      "epoch": 3.233734939759036,
      "grad_norm": 0.968083918094635,
      "learning_rate": 1.3532530120481927e-05,
      "loss": 0.0211,
      "step": 26840
    },
    {
      "epoch": 3.2349397590361444,
      "grad_norm": 7.277352333068848,
      "learning_rate": 1.353012048192771e-05,
      "loss": 0.0503,
      "step": 26850
    },
    {
      "epoch": 3.236144578313253,
      "grad_norm": 2.866535186767578,
      "learning_rate": 1.3527710843373496e-05,
      "loss": 0.0676,
      "step": 26860
    },
    {
      "epoch": 3.2373493975903616,
      "grad_norm": 0.016433943063020706,
      "learning_rate": 1.3525301204819279e-05,
      "loss": 0.0535,
      "step": 26870
    },
    {
      "epoch": 3.23855421686747,
      "grad_norm": 3.899726629257202,
      "learning_rate": 1.3522891566265062e-05,
      "loss": 0.0241,
      "step": 26880
    },
    {
      "epoch": 3.2397590361445783,
      "grad_norm": 0.14812447130680084,
      "learning_rate": 1.3520481927710845e-05,
      "loss": 0.0778,
      "step": 26890
    },
    {
      "epoch": 3.2409638554216866,
      "grad_norm": 0.20280003547668457,
      "learning_rate": 1.3518072289156628e-05,
      "loss": 0.1033,
      "step": 26900
    },
    {
      "epoch": 3.242168674698795,
      "grad_norm": 2.161675453186035,
      "learning_rate": 1.351566265060241e-05,
      "loss": 0.0337,
      "step": 26910
    },
    {
      "epoch": 3.243373493975904,
      "grad_norm": 0.040534570813179016,
      "learning_rate": 1.3513253012048193e-05,
      "loss": 0.0893,
      "step": 26920
    },
    {
      "epoch": 3.244578313253012,
      "grad_norm": 3.1815836429595947,
      "learning_rate": 1.3510843373493976e-05,
      "loss": 0.1309,
      "step": 26930
    },
    {
      "epoch": 3.2457831325301205,
      "grad_norm": 0.10592567175626755,
      "learning_rate": 1.3508433734939761e-05,
      "loss": 0.0369,
      "step": 26940
    },
    {
      "epoch": 3.246987951807229,
      "grad_norm": 3.2851099967956543,
      "learning_rate": 1.3506024096385544e-05,
      "loss": 0.0216,
      "step": 26950
    },
    {
      "epoch": 3.2481927710843372,
      "grad_norm": 1.4148294925689697,
      "learning_rate": 1.3503614457831327e-05,
      "loss": 0.0209,
      "step": 26960
    },
    {
      "epoch": 3.2493975903614456,
      "grad_norm": 0.19248336553573608,
      "learning_rate": 1.3501204819277109e-05,
      "loss": 0.0306,
      "step": 26970
    },
    {
      "epoch": 3.2506024096385544,
      "grad_norm": 7.035338401794434,
      "learning_rate": 1.3498795180722892e-05,
      "loss": 0.1018,
      "step": 26980
    },
    {
      "epoch": 3.2518072289156628,
      "grad_norm": 0.5670058727264404,
      "learning_rate": 1.3496385542168675e-05,
      "loss": 0.0277,
      "step": 26990
    },
    {
      "epoch": 3.253012048192771,
      "grad_norm": 0.2501067519187927,
      "learning_rate": 1.3493975903614458e-05,
      "loss": 0.0184,
      "step": 27000
    },
    {
      "epoch": 3.2542168674698795,
      "grad_norm": 4.150368690490723,
      "learning_rate": 1.3491566265060243e-05,
      "loss": 0.1362,
      "step": 27010
    },
    {
      "epoch": 3.255421686746988,
      "grad_norm": 1.5317597389221191,
      "learning_rate": 1.3489156626506026e-05,
      "loss": 0.0397,
      "step": 27020
    },
    {
      "epoch": 3.256626506024096,
      "grad_norm": 0.027469271793961525,
      "learning_rate": 1.348674698795181e-05,
      "loss": 0.0334,
      "step": 27030
    },
    {
      "epoch": 3.257831325301205,
      "grad_norm": 6.567997932434082,
      "learning_rate": 1.3484337349397591e-05,
      "loss": 0.1135,
      "step": 27040
    },
    {
      "epoch": 3.2590361445783134,
      "grad_norm": 0.27585238218307495,
      "learning_rate": 1.3481927710843374e-05,
      "loss": 0.0079,
      "step": 27050
    },
    {
      "epoch": 3.2602409638554217,
      "grad_norm": 0.3993321657180786,
      "learning_rate": 1.3479518072289157e-05,
      "loss": 0.1179,
      "step": 27060
    },
    {
      "epoch": 3.26144578313253,
      "grad_norm": 2.6083996295928955,
      "learning_rate": 1.347710843373494e-05,
      "loss": 0.047,
      "step": 27070
    },
    {
      "epoch": 3.2626506024096384,
      "grad_norm": 4.65557336807251,
      "learning_rate": 1.3474698795180725e-05,
      "loss": 0.0867,
      "step": 27080
    },
    {
      "epoch": 3.263855421686747,
      "grad_norm": 4.666825294494629,
      "learning_rate": 1.3472289156626509e-05,
      "loss": 0.1082,
      "step": 27090
    },
    {
      "epoch": 3.2650602409638556,
      "grad_norm": 0.30312010645866394,
      "learning_rate": 1.346987951807229e-05,
      "loss": 0.0408,
      "step": 27100
    },
    {
      "epoch": 3.266265060240964,
      "grad_norm": 4.706902980804443,
      "learning_rate": 1.3467469879518073e-05,
      "loss": 0.0292,
      "step": 27110
    },
    {
      "epoch": 3.2674698795180723,
      "grad_norm": 2.378884792327881,
      "learning_rate": 1.3465060240963856e-05,
      "loss": 0.0532,
      "step": 27120
    },
    {
      "epoch": 3.2686746987951807,
      "grad_norm": 0.6820036172866821,
      "learning_rate": 1.346265060240964e-05,
      "loss": 0.041,
      "step": 27130
    },
    {
      "epoch": 3.269879518072289,
      "grad_norm": 6.820865154266357,
      "learning_rate": 1.3460240963855423e-05,
      "loss": 0.0192,
      "step": 27140
    },
    {
      "epoch": 3.2710843373493974,
      "grad_norm": 1.499922752380371,
      "learning_rate": 1.3457831325301204e-05,
      "loss": 0.0135,
      "step": 27150
    },
    {
      "epoch": 3.272289156626506,
      "grad_norm": 0.06089946627616882,
      "learning_rate": 1.345542168674699e-05,
      "loss": 0.1194,
      "step": 27160
    },
    {
      "epoch": 3.2734939759036146,
      "grad_norm": 4.46175479888916,
      "learning_rate": 1.3453012048192772e-05,
      "loss": 0.0603,
      "step": 27170
    },
    {
      "epoch": 3.274698795180723,
      "grad_norm": 1.3739513158798218,
      "learning_rate": 1.3450602409638555e-05,
      "loss": 0.0422,
      "step": 27180
    },
    {
      "epoch": 3.2759036144578313,
      "grad_norm": 0.288923442363739,
      "learning_rate": 1.3448192771084339e-05,
      "loss": 0.022,
      "step": 27190
    },
    {
      "epoch": 3.2771084337349397,
      "grad_norm": 1.6947133541107178,
      "learning_rate": 1.3445783132530122e-05,
      "loss": 0.0527,
      "step": 27200
    },
    {
      "epoch": 3.278313253012048,
      "grad_norm": 1.9310749769210815,
      "learning_rate": 1.3443373493975905e-05,
      "loss": 0.0416,
      "step": 27210
    },
    {
      "epoch": 3.279518072289157,
      "grad_norm": 0.6630548238754272,
      "learning_rate": 1.3440963855421686e-05,
      "loss": 0.0598,
      "step": 27220
    },
    {
      "epoch": 3.280722891566265,
      "grad_norm": 7.434236526489258,
      "learning_rate": 1.3438554216867471e-05,
      "loss": 0.0241,
      "step": 27230
    },
    {
      "epoch": 3.2819277108433735,
      "grad_norm": 0.03566112369298935,
      "learning_rate": 1.3436144578313255e-05,
      "loss": 0.0493,
      "step": 27240
    },
    {
      "epoch": 3.283132530120482,
      "grad_norm": 0.008430599234998226,
      "learning_rate": 1.3433734939759038e-05,
      "loss": 0.0312,
      "step": 27250
    },
    {
      "epoch": 3.2843373493975903,
      "grad_norm": 1.8694250583648682,
      "learning_rate": 1.3431325301204821e-05,
      "loss": 0.0425,
      "step": 27260
    },
    {
      "epoch": 3.2855421686746986,
      "grad_norm": 0.01021650992333889,
      "learning_rate": 1.3428915662650604e-05,
      "loss": 0.0136,
      "step": 27270
    },
    {
      "epoch": 3.2867469879518074,
      "grad_norm": 0.011099628172814846,
      "learning_rate": 1.3426506024096386e-05,
      "loss": 0.0737,
      "step": 27280
    },
    {
      "epoch": 3.287951807228916,
      "grad_norm": 3.056182384490967,
      "learning_rate": 1.3424096385542169e-05,
      "loss": 0.1027,
      "step": 27290
    },
    {
      "epoch": 3.289156626506024,
      "grad_norm": 0.5956525206565857,
      "learning_rate": 1.3421686746987952e-05,
      "loss": 0.0197,
      "step": 27300
    },
    {
      "epoch": 3.2903614457831325,
      "grad_norm": 0.4147258400917053,
      "learning_rate": 1.3419277108433737e-05,
      "loss": 0.0096,
      "step": 27310
    },
    {
      "epoch": 3.291566265060241,
      "grad_norm": 0.025347784161567688,
      "learning_rate": 1.341686746987952e-05,
      "loss": 0.0548,
      "step": 27320
    },
    {
      "epoch": 3.292771084337349,
      "grad_norm": 3.2455196380615234,
      "learning_rate": 1.3414457831325303e-05,
      "loss": 0.0612,
      "step": 27330
    },
    {
      "epoch": 3.293975903614458,
      "grad_norm": 20.741615295410156,
      "learning_rate": 1.3412048192771086e-05,
      "loss": 0.0602,
      "step": 27340
    },
    {
      "epoch": 3.2951807228915664,
      "grad_norm": 5.075718879699707,
      "learning_rate": 1.3409638554216868e-05,
      "loss": 0.0457,
      "step": 27350
    },
    {
      "epoch": 3.2963855421686747,
      "grad_norm": 6.231411457061768,
      "learning_rate": 1.3407228915662651e-05,
      "loss": 0.0718,
      "step": 27360
    },
    {
      "epoch": 3.297590361445783,
      "grad_norm": 10.738019943237305,
      "learning_rate": 1.3404819277108434e-05,
      "loss": 0.0988,
      "step": 27370
    },
    {
      "epoch": 3.2987951807228915,
      "grad_norm": 0.20240718126296997,
      "learning_rate": 1.3402409638554219e-05,
      "loss": 0.0544,
      "step": 27380
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.060265809297561646,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0286,
      "step": 27390
    },
    {
      "epoch": 3.3012048192771086,
      "grad_norm": 0.055377569049596786,
      "learning_rate": 1.3397590361445785e-05,
      "loss": 0.0133,
      "step": 27400
    },
    {
      "epoch": 3.302409638554217,
      "grad_norm": 3.746288776397705,
      "learning_rate": 1.3395180722891567e-05,
      "loss": 0.1113,
      "step": 27410
    },
    {
      "epoch": 3.3036144578313253,
      "grad_norm": 4.454317569732666,
      "learning_rate": 1.339277108433735e-05,
      "loss": 0.0415,
      "step": 27420
    },
    {
      "epoch": 3.3048192771084337,
      "grad_norm": 0.10917440056800842,
      "learning_rate": 1.3390361445783133e-05,
      "loss": 0.0275,
      "step": 27430
    },
    {
      "epoch": 3.306024096385542,
      "grad_norm": 0.06269582360982895,
      "learning_rate": 1.3387951807228916e-05,
      "loss": 0.0072,
      "step": 27440
    },
    {
      "epoch": 3.3072289156626504,
      "grad_norm": 0.02417929284274578,
      "learning_rate": 1.33855421686747e-05,
      "loss": 0.0173,
      "step": 27450
    },
    {
      "epoch": 3.3084337349397592,
      "grad_norm": 1.1239820718765259,
      "learning_rate": 1.3383132530120484e-05,
      "loss": 0.0637,
      "step": 27460
    },
    {
      "epoch": 3.3096385542168676,
      "grad_norm": 10.584339141845703,
      "learning_rate": 1.3380722891566268e-05,
      "loss": 0.1096,
      "step": 27470
    },
    {
      "epoch": 3.310843373493976,
      "grad_norm": 2.5278801918029785,
      "learning_rate": 1.3378313253012049e-05,
      "loss": 0.0266,
      "step": 27480
    },
    {
      "epoch": 3.3120481927710843,
      "grad_norm": 2.205944299697876,
      "learning_rate": 1.3375903614457832e-05,
      "loss": 0.033,
      "step": 27490
    },
    {
      "epoch": 3.3132530120481927,
      "grad_norm": 0.13695938885211945,
      "learning_rate": 1.3373493975903615e-05,
      "loss": 0.0576,
      "step": 27500
    },
    {
      "epoch": 3.314457831325301,
      "grad_norm": 0.014369048178195953,
      "learning_rate": 1.3371084337349399e-05,
      "loss": 0.0777,
      "step": 27510
    },
    {
      "epoch": 3.31566265060241,
      "grad_norm": 0.20042705535888672,
      "learning_rate": 1.3368674698795182e-05,
      "loss": 0.0612,
      "step": 27520
    },
    {
      "epoch": 3.316867469879518,
      "grad_norm": 0.473120778799057,
      "learning_rate": 1.3366265060240967e-05,
      "loss": 0.0447,
      "step": 27530
    },
    {
      "epoch": 3.3180722891566266,
      "grad_norm": 1.457427740097046,
      "learning_rate": 1.3363855421686748e-05,
      "loss": 0.06,
      "step": 27540
    },
    {
      "epoch": 3.319277108433735,
      "grad_norm": 2.5663249492645264,
      "learning_rate": 1.3361445783132531e-05,
      "loss": 0.0754,
      "step": 27550
    },
    {
      "epoch": 3.3204819277108433,
      "grad_norm": 0.06141120567917824,
      "learning_rate": 1.3359036144578314e-05,
      "loss": 0.0023,
      "step": 27560
    },
    {
      "epoch": 3.3216867469879516,
      "grad_norm": 1.1986228227615356,
      "learning_rate": 1.3356626506024098e-05,
      "loss": 0.0736,
      "step": 27570
    },
    {
      "epoch": 3.32289156626506,
      "grad_norm": 0.09512072801589966,
      "learning_rate": 1.335421686746988e-05,
      "loss": 0.0114,
      "step": 27580
    },
    {
      "epoch": 3.324096385542169,
      "grad_norm": 2.7022287845611572,
      "learning_rate": 1.3351807228915662e-05,
      "loss": 0.0185,
      "step": 27590
    },
    {
      "epoch": 3.325301204819277,
      "grad_norm": 0.33604180812835693,
      "learning_rate": 1.3349397590361445e-05,
      "loss": 0.0595,
      "step": 27600
    },
    {
      "epoch": 3.3265060240963855,
      "grad_norm": 2.5476770401000977,
      "learning_rate": 1.334698795180723e-05,
      "loss": 0.033,
      "step": 27610
    },
    {
      "epoch": 3.327710843373494,
      "grad_norm": 5.008864402770996,
      "learning_rate": 1.3344578313253014e-05,
      "loss": 0.0901,
      "step": 27620
    },
    {
      "epoch": 3.3289156626506022,
      "grad_norm": 2.7860982418060303,
      "learning_rate": 1.3342168674698797e-05,
      "loss": 0.093,
      "step": 27630
    },
    {
      "epoch": 3.330120481927711,
      "grad_norm": 9.08265209197998,
      "learning_rate": 1.333975903614458e-05,
      "loss": 0.0223,
      "step": 27640
    },
    {
      "epoch": 3.3313253012048194,
      "grad_norm": 0.14569635689258575,
      "learning_rate": 1.3337349397590363e-05,
      "loss": 0.1193,
      "step": 27650
    },
    {
      "epoch": 3.3325301204819278,
      "grad_norm": 0.03932832181453705,
      "learning_rate": 1.3334939759036145e-05,
      "loss": 0.0465,
      "step": 27660
    },
    {
      "epoch": 3.333734939759036,
      "grad_norm": 8.847935676574707,
      "learning_rate": 1.3332530120481928e-05,
      "loss": 0.0985,
      "step": 27670
    },
    {
      "epoch": 3.3349397590361445,
      "grad_norm": 0.021916426718235016,
      "learning_rate": 1.3330120481927713e-05,
      "loss": 0.054,
      "step": 27680
    },
    {
      "epoch": 3.336144578313253,
      "grad_norm": 5.2242865562438965,
      "learning_rate": 1.3327710843373496e-05,
      "loss": 0.1487,
      "step": 27690
    },
    {
      "epoch": 3.337349397590361,
      "grad_norm": 0.16001634299755096,
      "learning_rate": 1.3325301204819279e-05,
      "loss": 0.0581,
      "step": 27700
    },
    {
      "epoch": 3.33855421686747,
      "grad_norm": 4.955132961273193,
      "learning_rate": 1.3322891566265062e-05,
      "loss": 0.0354,
      "step": 27710
    },
    {
      "epoch": 3.3397590361445784,
      "grad_norm": 2.7153160572052,
      "learning_rate": 1.3320481927710844e-05,
      "loss": 0.0489,
      "step": 27720
    },
    {
      "epoch": 3.3409638554216867,
      "grad_norm": 6.0089850425720215,
      "learning_rate": 1.3318072289156627e-05,
      "loss": 0.0573,
      "step": 27730
    },
    {
      "epoch": 3.342168674698795,
      "grad_norm": 0.042146988213062286,
      "learning_rate": 1.331566265060241e-05,
      "loss": 0.0231,
      "step": 27740
    },
    {
      "epoch": 3.3433734939759034,
      "grad_norm": 5.140133857727051,
      "learning_rate": 1.3313253012048193e-05,
      "loss": 0.0695,
      "step": 27750
    },
    {
      "epoch": 3.3445783132530122,
      "grad_norm": 2.8385558128356934,
      "learning_rate": 1.3310843373493978e-05,
      "loss": 0.0458,
      "step": 27760
    },
    {
      "epoch": 3.3457831325301206,
      "grad_norm": 0.06292776763439178,
      "learning_rate": 1.3308433734939761e-05,
      "loss": 0.0577,
      "step": 27770
    },
    {
      "epoch": 3.346987951807229,
      "grad_norm": 0.7085774540901184,
      "learning_rate": 1.3306024096385544e-05,
      "loss": 0.0181,
      "step": 27780
    },
    {
      "epoch": 3.3481927710843373,
      "grad_norm": 4.903310298919678,
      "learning_rate": 1.3303614457831326e-05,
      "loss": 0.0407,
      "step": 27790
    },
    {
      "epoch": 3.3493975903614457,
      "grad_norm": 4.3823323249816895,
      "learning_rate": 1.3301204819277109e-05,
      "loss": 0.0758,
      "step": 27800
    },
    {
      "epoch": 3.350602409638554,
      "grad_norm": 8.695197105407715,
      "learning_rate": 1.3298795180722892e-05,
      "loss": 0.0582,
      "step": 27810
    },
    {
      "epoch": 3.3518072289156624,
      "grad_norm": 0.6540021300315857,
      "learning_rate": 1.3296385542168675e-05,
      "loss": 0.0059,
      "step": 27820
    },
    {
      "epoch": 3.353012048192771,
      "grad_norm": 3.8478763103485107,
      "learning_rate": 1.329397590361446e-05,
      "loss": 0.0578,
      "step": 27830
    },
    {
      "epoch": 3.3542168674698796,
      "grad_norm": 14.213122367858887,
      "learning_rate": 1.3291566265060243e-05,
      "loss": 0.0737,
      "step": 27840
    },
    {
      "epoch": 3.355421686746988,
      "grad_norm": 2.877701997756958,
      "learning_rate": 1.3289156626506025e-05,
      "loss": 0.0576,
      "step": 27850
    },
    {
      "epoch": 3.3566265060240963,
      "grad_norm": 6.342090606689453,
      "learning_rate": 1.3286746987951808e-05,
      "loss": 0.0466,
      "step": 27860
    },
    {
      "epoch": 3.3578313253012047,
      "grad_norm": 0.35398346185684204,
      "learning_rate": 1.3284337349397591e-05,
      "loss": 0.0368,
      "step": 27870
    },
    {
      "epoch": 3.3590361445783135,
      "grad_norm": 10.288932800292969,
      "learning_rate": 1.3281927710843374e-05,
      "loss": 0.1109,
      "step": 27880
    },
    {
      "epoch": 3.360240963855422,
      "grad_norm": 0.24397839605808258,
      "learning_rate": 1.3279518072289158e-05,
      "loss": 0.041,
      "step": 27890
    },
    {
      "epoch": 3.36144578313253,
      "grad_norm": 5.748706340789795,
      "learning_rate": 1.3277108433734939e-05,
      "loss": 0.0801,
      "step": 27900
    },
    {
      "epoch": 3.3626506024096385,
      "grad_norm": 0.05864256992936134,
      "learning_rate": 1.3274698795180726e-05,
      "loss": 0.0287,
      "step": 27910
    },
    {
      "epoch": 3.363855421686747,
      "grad_norm": 0.05355101823806763,
      "learning_rate": 1.3272289156626507e-05,
      "loss": 0.0526,
      "step": 27920
    },
    {
      "epoch": 3.3650602409638553,
      "grad_norm": 0.17566855251789093,
      "learning_rate": 1.326987951807229e-05,
      "loss": 0.0553,
      "step": 27930
    },
    {
      "epoch": 3.3662650602409636,
      "grad_norm": 8.057514190673828,
      "learning_rate": 1.3267469879518073e-05,
      "loss": 0.0626,
      "step": 27940
    },
    {
      "epoch": 3.3674698795180724,
      "grad_norm": 0.025610921904444695,
      "learning_rate": 1.3265060240963857e-05,
      "loss": 0.0801,
      "step": 27950
    },
    {
      "epoch": 3.3686746987951808,
      "grad_norm": 0.44006112217903137,
      "learning_rate": 1.326265060240964e-05,
      "loss": 0.0569,
      "step": 27960
    },
    {
      "epoch": 3.369879518072289,
      "grad_norm": 3.8527956008911133,
      "learning_rate": 1.3260240963855421e-05,
      "loss": 0.0484,
      "step": 27970
    },
    {
      "epoch": 3.3710843373493975,
      "grad_norm": 0.04063021019101143,
      "learning_rate": 1.3257831325301206e-05,
      "loss": 0.0217,
      "step": 27980
    },
    {
      "epoch": 3.372289156626506,
      "grad_norm": 2.432229995727539,
      "learning_rate": 1.325542168674699e-05,
      "loss": 0.0448,
      "step": 27990
    },
    {
      "epoch": 3.3734939759036147,
      "grad_norm": 0.03794712945818901,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 0.048,
      "step": 28000
    },
    {
      "epoch": 3.374698795180723,
      "grad_norm": 0.7546998858451843,
      "learning_rate": 1.3250602409638556e-05,
      "loss": 0.0409,
      "step": 28010
    },
    {
      "epoch": 3.3759036144578314,
      "grad_norm": 0.20878715813159943,
      "learning_rate": 1.3248192771084339e-05,
      "loss": 0.055,
      "step": 28020
    },
    {
      "epoch": 3.3771084337349397,
      "grad_norm": 5.013060569763184,
      "learning_rate": 1.324578313253012e-05,
      "loss": 0.0908,
      "step": 28030
    },
    {
      "epoch": 3.378313253012048,
      "grad_norm": 3.1717963218688965,
      "learning_rate": 1.3243373493975904e-05,
      "loss": 0.0707,
      "step": 28040
    },
    {
      "epoch": 3.3795180722891565,
      "grad_norm": 0.02852790057659149,
      "learning_rate": 1.3240963855421687e-05,
      "loss": 0.0337,
      "step": 28050
    },
    {
      "epoch": 3.380722891566265,
      "grad_norm": 0.31263992190361023,
      "learning_rate": 1.3238554216867472e-05,
      "loss": 0.0552,
      "step": 28060
    },
    {
      "epoch": 3.3819277108433736,
      "grad_norm": 0.9537206292152405,
      "learning_rate": 1.3236144578313255e-05,
      "loss": 0.0364,
      "step": 28070
    },
    {
      "epoch": 3.383132530120482,
      "grad_norm": 0.06763933598995209,
      "learning_rate": 1.3233734939759038e-05,
      "loss": 0.0549,
      "step": 28080
    },
    {
      "epoch": 3.3843373493975903,
      "grad_norm": 0.17751437425613403,
      "learning_rate": 1.3231325301204821e-05,
      "loss": 0.0215,
      "step": 28090
    },
    {
      "epoch": 3.3855421686746987,
      "grad_norm": 2.858473062515259,
      "learning_rate": 1.3228915662650603e-05,
      "loss": 0.0632,
      "step": 28100
    },
    {
      "epoch": 3.386746987951807,
      "grad_norm": 2.792229413986206,
      "learning_rate": 1.3226506024096386e-05,
      "loss": 0.0124,
      "step": 28110
    },
    {
      "epoch": 3.387951807228916,
      "grad_norm": 10.811553955078125,
      "learning_rate": 1.3224096385542169e-05,
      "loss": 0.0228,
      "step": 28120
    },
    {
      "epoch": 3.3891566265060242,
      "grad_norm": 0.20584358274936676,
      "learning_rate": 1.3221686746987954e-05,
      "loss": 0.0127,
      "step": 28130
    },
    {
      "epoch": 3.3903614457831326,
      "grad_norm": 0.026842860504984856,
      "learning_rate": 1.3219277108433737e-05,
      "loss": 0.005,
      "step": 28140
    },
    {
      "epoch": 3.391566265060241,
      "grad_norm": 3.539597988128662,
      "learning_rate": 1.321686746987952e-05,
      "loss": 0.1098,
      "step": 28150
    },
    {
      "epoch": 3.3927710843373493,
      "grad_norm": 2.7480645179748535,
      "learning_rate": 1.3214457831325303e-05,
      "loss": 0.0705,
      "step": 28160
    },
    {
      "epoch": 3.3939759036144577,
      "grad_norm": 6.809514999389648,
      "learning_rate": 1.3212048192771085e-05,
      "loss": 0.1022,
      "step": 28170
    },
    {
      "epoch": 3.395180722891566,
      "grad_norm": 2.114927053451538,
      "learning_rate": 1.3209638554216868e-05,
      "loss": 0.0369,
      "step": 28180
    },
    {
      "epoch": 3.396385542168675,
      "grad_norm": 0.05293165519833565,
      "learning_rate": 1.3207228915662651e-05,
      "loss": 0.0413,
      "step": 28190
    },
    {
      "epoch": 3.397590361445783,
      "grad_norm": 0.10097458958625793,
      "learning_rate": 1.3204819277108434e-05,
      "loss": 0.1519,
      "step": 28200
    },
    {
      "epoch": 3.3987951807228916,
      "grad_norm": 3.110283374786377,
      "learning_rate": 1.320240963855422e-05,
      "loss": 0.0467,
      "step": 28210
    },
    {
      "epoch": 3.4,
      "grad_norm": 9.602761268615723,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.054,
      "step": 28220
    },
    {
      "epoch": 3.4012048192771083,
      "grad_norm": 4.710716724395752,
      "learning_rate": 1.3197590361445784e-05,
      "loss": 0.0592,
      "step": 28230
    },
    {
      "epoch": 3.402409638554217,
      "grad_norm": 0.09577909111976624,
      "learning_rate": 1.3195180722891567e-05,
      "loss": 0.0513,
      "step": 28240
    },
    {
      "epoch": 3.4036144578313254,
      "grad_norm": 0.0987582579255104,
      "learning_rate": 1.319277108433735e-05,
      "loss": 0.0696,
      "step": 28250
    },
    {
      "epoch": 3.404819277108434,
      "grad_norm": 0.08810993283987045,
      "learning_rate": 1.3190361445783133e-05,
      "loss": 0.0486,
      "step": 28260
    },
    {
      "epoch": 3.406024096385542,
      "grad_norm": 0.4071183502674103,
      "learning_rate": 1.3187951807228917e-05,
      "loss": 0.0598,
      "step": 28270
    },
    {
      "epoch": 3.4072289156626505,
      "grad_norm": 0.17236028611660004,
      "learning_rate": 1.3185542168674701e-05,
      "loss": 0.0373,
      "step": 28280
    },
    {
      "epoch": 3.408433734939759,
      "grad_norm": 4.88460111618042,
      "learning_rate": 1.3183132530120485e-05,
      "loss": 0.0279,
      "step": 28290
    },
    {
      "epoch": 3.4096385542168672,
      "grad_norm": 1.858349323272705,
      "learning_rate": 1.3180722891566266e-05,
      "loss": 0.0985,
      "step": 28300
    },
    {
      "epoch": 3.410843373493976,
      "grad_norm": 0.18978270888328552,
      "learning_rate": 1.317831325301205e-05,
      "loss": 0.0366,
      "step": 28310
    },
    {
      "epoch": 3.4120481927710844,
      "grad_norm": 6.953855514526367,
      "learning_rate": 1.3175903614457832e-05,
      "loss": 0.1406,
      "step": 28320
    },
    {
      "epoch": 3.4132530120481928,
      "grad_norm": 0.5918087959289551,
      "learning_rate": 1.3173493975903616e-05,
      "loss": 0.0225,
      "step": 28330
    },
    {
      "epoch": 3.414457831325301,
      "grad_norm": 0.18980593979358673,
      "learning_rate": 1.3171084337349399e-05,
      "loss": 0.075,
      "step": 28340
    },
    {
      "epoch": 3.4156626506024095,
      "grad_norm": 0.24045492708683014,
      "learning_rate": 1.316867469879518e-05,
      "loss": 0.0062,
      "step": 28350
    },
    {
      "epoch": 3.4168674698795183,
      "grad_norm": 0.02822250686585903,
      "learning_rate": 1.3166265060240965e-05,
      "loss": 0.0392,
      "step": 28360
    },
    {
      "epoch": 3.4180722891566266,
      "grad_norm": 8.569356918334961,
      "learning_rate": 1.3163855421686748e-05,
      "loss": 0.0736,
      "step": 28370
    },
    {
      "epoch": 3.419277108433735,
      "grad_norm": 0.3321896493434906,
      "learning_rate": 1.3161445783132531e-05,
      "loss": 0.0396,
      "step": 28380
    },
    {
      "epoch": 3.4204819277108434,
      "grad_norm": 2.1579527854919434,
      "learning_rate": 1.3159036144578315e-05,
      "loss": 0.0523,
      "step": 28390
    },
    {
      "epoch": 3.4216867469879517,
      "grad_norm": 2.850463390350342,
      "learning_rate": 1.3156626506024098e-05,
      "loss": 0.1092,
      "step": 28400
    },
    {
      "epoch": 3.42289156626506,
      "grad_norm": 0.21605341136455536,
      "learning_rate": 1.315421686746988e-05,
      "loss": 0.0329,
      "step": 28410
    },
    {
      "epoch": 3.4240963855421684,
      "grad_norm": 7.931048393249512,
      "learning_rate": 1.3151807228915662e-05,
      "loss": 0.0391,
      "step": 28420
    },
    {
      "epoch": 3.4253012048192772,
      "grad_norm": 4.026010513305664,
      "learning_rate": 1.3149397590361447e-05,
      "loss": 0.0508,
      "step": 28430
    },
    {
      "epoch": 3.4265060240963856,
      "grad_norm": 0.12982317805290222,
      "learning_rate": 1.314698795180723e-05,
      "loss": 0.0833,
      "step": 28440
    },
    {
      "epoch": 3.427710843373494,
      "grad_norm": 3.340579032897949,
      "learning_rate": 1.3144578313253014e-05,
      "loss": 0.0797,
      "step": 28450
    },
    {
      "epoch": 3.4289156626506023,
      "grad_norm": 1.150297999382019,
      "learning_rate": 1.3142168674698797e-05,
      "loss": 0.0339,
      "step": 28460
    },
    {
      "epoch": 3.4301204819277107,
      "grad_norm": 0.7264005541801453,
      "learning_rate": 1.313975903614458e-05,
      "loss": 0.0495,
      "step": 28470
    },
    {
      "epoch": 3.4313253012048195,
      "grad_norm": 0.5257102251052856,
      "learning_rate": 1.3137349397590362e-05,
      "loss": 0.0498,
      "step": 28480
    },
    {
      "epoch": 3.432530120481928,
      "grad_norm": 9.368149757385254,
      "learning_rate": 1.3134939759036145e-05,
      "loss": 0.0304,
      "step": 28490
    },
    {
      "epoch": 3.433734939759036,
      "grad_norm": 0.15495777130126953,
      "learning_rate": 1.3132530120481928e-05,
      "loss": 0.0341,
      "step": 28500
    },
    {
      "epoch": 3.4349397590361446,
      "grad_norm": 0.014394196681678295,
      "learning_rate": 1.3130120481927713e-05,
      "loss": 0.0164,
      "step": 28510
    },
    {
      "epoch": 3.436144578313253,
      "grad_norm": 13.33344554901123,
      "learning_rate": 1.3127710843373496e-05,
      "loss": 0.0832,
      "step": 28520
    },
    {
      "epoch": 3.4373493975903613,
      "grad_norm": 1.7540682554244995,
      "learning_rate": 1.3125301204819279e-05,
      "loss": 0.0685,
      "step": 28530
    },
    {
      "epoch": 3.4385542168674696,
      "grad_norm": 0.48160746693611145,
      "learning_rate": 1.312289156626506e-05,
      "loss": 0.0415,
      "step": 28540
    },
    {
      "epoch": 3.4397590361445785,
      "grad_norm": 5.60755729675293,
      "learning_rate": 1.3120481927710844e-05,
      "loss": 0.0517,
      "step": 28550
    },
    {
      "epoch": 3.440963855421687,
      "grad_norm": 0.5579643845558167,
      "learning_rate": 1.3118072289156627e-05,
      "loss": 0.0072,
      "step": 28560
    },
    {
      "epoch": 3.442168674698795,
      "grad_norm": 4.517791748046875,
      "learning_rate": 1.311566265060241e-05,
      "loss": 0.08,
      "step": 28570
    },
    {
      "epoch": 3.4433734939759035,
      "grad_norm": 0.014527927152812481,
      "learning_rate": 1.3113253012048195e-05,
      "loss": 0.0688,
      "step": 28580
    },
    {
      "epoch": 3.444578313253012,
      "grad_norm": 29.32523536682129,
      "learning_rate": 1.3110843373493978e-05,
      "loss": 0.0712,
      "step": 28590
    },
    {
      "epoch": 3.4457831325301207,
      "grad_norm": 0.09255505353212357,
      "learning_rate": 1.3108433734939761e-05,
      "loss": 0.0265,
      "step": 28600
    },
    {
      "epoch": 3.446987951807229,
      "grad_norm": 0.5057327151298523,
      "learning_rate": 1.3106024096385543e-05,
      "loss": 0.0535,
      "step": 28610
    },
    {
      "epoch": 3.4481927710843374,
      "grad_norm": 2.2980754375457764,
      "learning_rate": 1.3103614457831326e-05,
      "loss": 0.0276,
      "step": 28620
    },
    {
      "epoch": 3.4493975903614458,
      "grad_norm": 2.107795476913452,
      "learning_rate": 1.310120481927711e-05,
      "loss": 0.0939,
      "step": 28630
    },
    {
      "epoch": 3.450602409638554,
      "grad_norm": 0.017477484419941902,
      "learning_rate": 1.3098795180722892e-05,
      "loss": 0.0192,
      "step": 28640
    },
    {
      "epoch": 3.4518072289156625,
      "grad_norm": 0.008395824581384659,
      "learning_rate": 1.3096385542168676e-05,
      "loss": 0.0533,
      "step": 28650
    },
    {
      "epoch": 3.453012048192771,
      "grad_norm": 0.07256653904914856,
      "learning_rate": 1.309397590361446e-05,
      "loss": 0.0369,
      "step": 28660
    },
    {
      "epoch": 3.4542168674698797,
      "grad_norm": 0.03279595449566841,
      "learning_rate": 1.3091566265060242e-05,
      "loss": 0.0025,
      "step": 28670
    },
    {
      "epoch": 3.455421686746988,
      "grad_norm": 10.536800384521484,
      "learning_rate": 1.3089156626506025e-05,
      "loss": 0.04,
      "step": 28680
    },
    {
      "epoch": 3.4566265060240964,
      "grad_norm": 0.006475245114415884,
      "learning_rate": 1.3086746987951808e-05,
      "loss": 0.0437,
      "step": 28690
    },
    {
      "epoch": 3.4578313253012047,
      "grad_norm": 0.9914683699607849,
      "learning_rate": 1.3084337349397591e-05,
      "loss": 0.0091,
      "step": 28700
    },
    {
      "epoch": 3.459036144578313,
      "grad_norm": 0.07889927923679352,
      "learning_rate": 1.3081927710843375e-05,
      "loss": 0.029,
      "step": 28710
    },
    {
      "epoch": 3.460240963855422,
      "grad_norm": 0.23103496432304382,
      "learning_rate": 1.3079518072289156e-05,
      "loss": 0.1115,
      "step": 28720
    },
    {
      "epoch": 3.4614457831325303,
      "grad_norm": 0.0323849692940712,
      "learning_rate": 1.3077108433734943e-05,
      "loss": 0.0367,
      "step": 28730
    },
    {
      "epoch": 3.4626506024096386,
      "grad_norm": 0.48834073543548584,
      "learning_rate": 1.3074698795180724e-05,
      "loss": 0.0667,
      "step": 28740
    },
    {
      "epoch": 3.463855421686747,
      "grad_norm": 0.49703699350357056,
      "learning_rate": 1.3072289156626507e-05,
      "loss": 0.1053,
      "step": 28750
    },
    {
      "epoch": 3.4650602409638553,
      "grad_norm": 0.11018934100866318,
      "learning_rate": 1.306987951807229e-05,
      "loss": 0.0361,
      "step": 28760
    },
    {
      "epoch": 3.4662650602409637,
      "grad_norm": 2.57981276512146,
      "learning_rate": 1.3067469879518074e-05,
      "loss": 0.0185,
      "step": 28770
    },
    {
      "epoch": 3.467469879518072,
      "grad_norm": 2.226968765258789,
      "learning_rate": 1.3065060240963857e-05,
      "loss": 0.0265,
      "step": 28780
    },
    {
      "epoch": 3.468674698795181,
      "grad_norm": 0.6615661978721619,
      "learning_rate": 1.3062650602409638e-05,
      "loss": 0.0143,
      "step": 28790
    },
    {
      "epoch": 3.4698795180722892,
      "grad_norm": 0.45614829659461975,
      "learning_rate": 1.3060240963855421e-05,
      "loss": 0.0202,
      "step": 28800
    },
    {
      "epoch": 3.4710843373493976,
      "grad_norm": 0.013953101821243763,
      "learning_rate": 1.3057831325301206e-05,
      "loss": 0.0237,
      "step": 28810
    },
    {
      "epoch": 3.472289156626506,
      "grad_norm": 5.256216526031494,
      "learning_rate": 1.305542168674699e-05,
      "loss": 0.029,
      "step": 28820
    },
    {
      "epoch": 3.4734939759036143,
      "grad_norm": 0.046706438064575195,
      "learning_rate": 1.3053012048192773e-05,
      "loss": 0.0325,
      "step": 28830
    },
    {
      "epoch": 3.474698795180723,
      "grad_norm": 2.645825147628784,
      "learning_rate": 1.3050602409638556e-05,
      "loss": 0.0277,
      "step": 28840
    },
    {
      "epoch": 3.4759036144578315,
      "grad_norm": 3.1624574661254883,
      "learning_rate": 1.3048192771084337e-05,
      "loss": 0.0809,
      "step": 28850
    },
    {
      "epoch": 3.47710843373494,
      "grad_norm": 0.23749038577079773,
      "learning_rate": 1.304578313253012e-05,
      "loss": 0.0296,
      "step": 28860
    },
    {
      "epoch": 3.478313253012048,
      "grad_norm": 0.04473428428173065,
      "learning_rate": 1.3043373493975904e-05,
      "loss": 0.0381,
      "step": 28870
    },
    {
      "epoch": 3.4795180722891565,
      "grad_norm": 6.82399320602417,
      "learning_rate": 1.3040963855421689e-05,
      "loss": 0.041,
      "step": 28880
    },
    {
      "epoch": 3.480722891566265,
      "grad_norm": 0.06528705358505249,
      "learning_rate": 1.3038554216867472e-05,
      "loss": 0.0397,
      "step": 28890
    },
    {
      "epoch": 3.4819277108433733,
      "grad_norm": 0.22878874838352203,
      "learning_rate": 1.3036144578313255e-05,
      "loss": 0.0576,
      "step": 28900
    },
    {
      "epoch": 3.483132530120482,
      "grad_norm": 0.10247372090816498,
      "learning_rate": 1.3033734939759038e-05,
      "loss": 0.0449,
      "step": 28910
    },
    {
      "epoch": 3.4843373493975904,
      "grad_norm": 0.1475261002779007,
      "learning_rate": 1.303132530120482e-05,
      "loss": 0.0371,
      "step": 28920
    },
    {
      "epoch": 3.485542168674699,
      "grad_norm": 1.3682401180267334,
      "learning_rate": 1.3028915662650603e-05,
      "loss": 0.0397,
      "step": 28930
    },
    {
      "epoch": 3.486746987951807,
      "grad_norm": 3.3666210174560547,
      "learning_rate": 1.3026506024096386e-05,
      "loss": 0.0288,
      "step": 28940
    },
    {
      "epoch": 3.4879518072289155,
      "grad_norm": 6.789846897125244,
      "learning_rate": 1.3024096385542169e-05,
      "loss": 0.0534,
      "step": 28950
    },
    {
      "epoch": 3.4891566265060243,
      "grad_norm": 4.198945045471191,
      "learning_rate": 1.3021686746987954e-05,
      "loss": 0.0571,
      "step": 28960
    },
    {
      "epoch": 3.4903614457831327,
      "grad_norm": 0.6870998740196228,
      "learning_rate": 1.3019277108433737e-05,
      "loss": 0.0384,
      "step": 28970
    },
    {
      "epoch": 3.491566265060241,
      "grad_norm": 5.6770501136779785,
      "learning_rate": 1.3016867469879519e-05,
      "loss": 0.0303,
      "step": 28980
    },
    {
      "epoch": 3.4927710843373494,
      "grad_norm": 13.758798599243164,
      "learning_rate": 1.3014457831325302e-05,
      "loss": 0.0935,
      "step": 28990
    },
    {
      "epoch": 3.4939759036144578,
      "grad_norm": 0.837769627571106,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 0.0282,
      "step": 29000
    },
    {
      "epoch": 3.495180722891566,
      "grad_norm": 13.028675079345703,
      "learning_rate": 1.3009638554216868e-05,
      "loss": 0.089,
      "step": 29010
    },
    {
      "epoch": 3.4963855421686745,
      "grad_norm": 0.41001856327056885,
      "learning_rate": 1.3007228915662651e-05,
      "loss": 0.0426,
      "step": 29020
    },
    {
      "epoch": 3.4975903614457833,
      "grad_norm": 1.5765936374664307,
      "learning_rate": 1.3004819277108436e-05,
      "loss": 0.0106,
      "step": 29030
    },
    {
      "epoch": 3.4987951807228916,
      "grad_norm": 3.677515983581543,
      "learning_rate": 1.300240963855422e-05,
      "loss": 0.041,
      "step": 29040
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.465993881225586,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0129,
      "step": 29050
    },
    {
      "epoch": 3.5012048192771084,
      "grad_norm": 0.017147138714790344,
      "learning_rate": 1.2997590361445784e-05,
      "loss": 0.0315,
      "step": 29060
    },
    {
      "epoch": 3.5024096385542167,
      "grad_norm": 1.796878695487976,
      "learning_rate": 1.2995180722891567e-05,
      "loss": 0.0415,
      "step": 29070
    },
    {
      "epoch": 3.5036144578313255,
      "grad_norm": 6.765971660614014,
      "learning_rate": 1.299277108433735e-05,
      "loss": 0.1178,
      "step": 29080
    },
    {
      "epoch": 3.504819277108434,
      "grad_norm": 3.535674571990967,
      "learning_rate": 1.2990361445783134e-05,
      "loss": 0.0423,
      "step": 29090
    },
    {
      "epoch": 3.5060240963855422,
      "grad_norm": 0.15032203495502472,
      "learning_rate": 1.2987951807228915e-05,
      "loss": 0.0239,
      "step": 29100
    },
    {
      "epoch": 3.5072289156626506,
      "grad_norm": 3.0801174640655518,
      "learning_rate": 1.29855421686747e-05,
      "loss": 0.026,
      "step": 29110
    },
    {
      "epoch": 3.508433734939759,
      "grad_norm": 0.12987446784973145,
      "learning_rate": 1.2983132530120483e-05,
      "loss": 0.0296,
      "step": 29120
    },
    {
      "epoch": 3.5096385542168673,
      "grad_norm": 0.2527059018611908,
      "learning_rate": 1.2980722891566266e-05,
      "loss": 0.0682,
      "step": 29130
    },
    {
      "epoch": 3.5108433734939757,
      "grad_norm": 0.01053466834127903,
      "learning_rate": 1.297831325301205e-05,
      "loss": 0.017,
      "step": 29140
    },
    {
      "epoch": 3.5120481927710845,
      "grad_norm": 0.7449959516525269,
      "learning_rate": 1.2975903614457833e-05,
      "loss": 0.0375,
      "step": 29150
    },
    {
      "epoch": 3.513253012048193,
      "grad_norm": 0.153865784406662,
      "learning_rate": 1.2973493975903614e-05,
      "loss": 0.0264,
      "step": 29160
    },
    {
      "epoch": 3.514457831325301,
      "grad_norm": 2.473757028579712,
      "learning_rate": 1.2971084337349397e-05,
      "loss": 0.0508,
      "step": 29170
    },
    {
      "epoch": 3.5156626506024096,
      "grad_norm": 0.20135657489299774,
      "learning_rate": 1.2968674698795182e-05,
      "loss": 0.0555,
      "step": 29180
    },
    {
      "epoch": 3.516867469879518,
      "grad_norm": 33.813812255859375,
      "learning_rate": 1.2966265060240965e-05,
      "loss": 0.0424,
      "step": 29190
    },
    {
      "epoch": 3.5180722891566267,
      "grad_norm": 0.15711645781993866,
      "learning_rate": 1.2963855421686749e-05,
      "loss": 0.0426,
      "step": 29200
    },
    {
      "epoch": 3.519277108433735,
      "grad_norm": 4.521958827972412,
      "learning_rate": 1.2961445783132532e-05,
      "loss": 0.0313,
      "step": 29210
    },
    {
      "epoch": 3.5204819277108435,
      "grad_norm": 2.627087116241455,
      "learning_rate": 1.2959036144578315e-05,
      "loss": 0.0321,
      "step": 29220
    },
    {
      "epoch": 3.521686746987952,
      "grad_norm": 0.16430573165416718,
      "learning_rate": 1.2956626506024096e-05,
      "loss": 0.0465,
      "step": 29230
    },
    {
      "epoch": 3.52289156626506,
      "grad_norm": 0.11515837162733078,
      "learning_rate": 1.295421686746988e-05,
      "loss": 0.0161,
      "step": 29240
    },
    {
      "epoch": 3.5240963855421685,
      "grad_norm": 0.005092202685773373,
      "learning_rate": 1.2951807228915663e-05,
      "loss": 0.0319,
      "step": 29250
    },
    {
      "epoch": 3.525301204819277,
      "grad_norm": 2.2699079513549805,
      "learning_rate": 1.2949397590361448e-05,
      "loss": 0.0561,
      "step": 29260
    },
    {
      "epoch": 3.5265060240963857,
      "grad_norm": 0.15299862623214722,
      "learning_rate": 1.294698795180723e-05,
      "loss": 0.0354,
      "step": 29270
    },
    {
      "epoch": 3.527710843373494,
      "grad_norm": 4.046657562255859,
      "learning_rate": 1.2944578313253014e-05,
      "loss": 0.0285,
      "step": 29280
    },
    {
      "epoch": 3.5289156626506024,
      "grad_norm": 2.751422882080078,
      "learning_rate": 1.2942168674698795e-05,
      "loss": 0.095,
      "step": 29290
    },
    {
      "epoch": 3.5301204819277108,
      "grad_norm": 1.009399652481079,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 0.0368,
      "step": 29300
    },
    {
      "epoch": 3.531325301204819,
      "grad_norm": 0.21995770931243896,
      "learning_rate": 1.2937349397590362e-05,
      "loss": 0.0256,
      "step": 29310
    },
    {
      "epoch": 3.532530120481928,
      "grad_norm": 0.09610802680253983,
      "learning_rate": 1.2934939759036145e-05,
      "loss": 0.0473,
      "step": 29320
    },
    {
      "epoch": 3.5337349397590363,
      "grad_norm": 0.3383852243423462,
      "learning_rate": 1.293253012048193e-05,
      "loss": 0.0507,
      "step": 29330
    },
    {
      "epoch": 3.5349397590361447,
      "grad_norm": 0.03534048795700073,
      "learning_rate": 1.2930120481927713e-05,
      "loss": 0.0243,
      "step": 29340
    },
    {
      "epoch": 3.536144578313253,
      "grad_norm": 2.1321017742156982,
      "learning_rate": 1.2927710843373496e-05,
      "loss": 0.0309,
      "step": 29350
    },
    {
      "epoch": 3.5373493975903614,
      "grad_norm": 6.8671393394470215,
      "learning_rate": 1.2925301204819278e-05,
      "loss": 0.055,
      "step": 29360
    },
    {
      "epoch": 3.5385542168674697,
      "grad_norm": 3.8236875534057617,
      "learning_rate": 1.292289156626506e-05,
      "loss": 0.0486,
      "step": 29370
    },
    {
      "epoch": 3.539759036144578,
      "grad_norm": 0.5126006603240967,
      "learning_rate": 1.2920481927710844e-05,
      "loss": 0.0253,
      "step": 29380
    },
    {
      "epoch": 3.540963855421687,
      "grad_norm": 0.03584487363696098,
      "learning_rate": 1.2918072289156627e-05,
      "loss": 0.0342,
      "step": 29390
    },
    {
      "epoch": 3.5421686746987953,
      "grad_norm": 0.6084930896759033,
      "learning_rate": 1.291566265060241e-05,
      "loss": 0.0527,
      "step": 29400
    },
    {
      "epoch": 3.5433734939759036,
      "grad_norm": 0.9261488318443298,
      "learning_rate": 1.2913253012048195e-05,
      "loss": 0.0609,
      "step": 29410
    },
    {
      "epoch": 3.544578313253012,
      "grad_norm": 0.06723439693450928,
      "learning_rate": 1.2910843373493977e-05,
      "loss": 0.0489,
      "step": 29420
    },
    {
      "epoch": 3.5457831325301203,
      "grad_norm": 2.6410112380981445,
      "learning_rate": 1.290843373493976e-05,
      "loss": 0.0443,
      "step": 29430
    },
    {
      "epoch": 3.546987951807229,
      "grad_norm": 0.18351665139198303,
      "learning_rate": 1.2906024096385543e-05,
      "loss": 0.0131,
      "step": 29440
    },
    {
      "epoch": 3.5481927710843375,
      "grad_norm": 0.16700680553913116,
      "learning_rate": 1.2903614457831326e-05,
      "loss": 0.0552,
      "step": 29450
    },
    {
      "epoch": 3.549397590361446,
      "grad_norm": 1.0983433723449707,
      "learning_rate": 1.290120481927711e-05,
      "loss": 0.0384,
      "step": 29460
    },
    {
      "epoch": 3.5506024096385542,
      "grad_norm": 0.0036670141853392124,
      "learning_rate": 1.2898795180722891e-05,
      "loss": 0.0321,
      "step": 29470
    },
    {
      "epoch": 3.5518072289156626,
      "grad_norm": 0.0035576762165874243,
      "learning_rate": 1.2896385542168677e-05,
      "loss": 0.0914,
      "step": 29480
    },
    {
      "epoch": 3.553012048192771,
      "grad_norm": 0.005580055061727762,
      "learning_rate": 1.2893975903614459e-05,
      "loss": 0.0136,
      "step": 29490
    },
    {
      "epoch": 3.5542168674698793,
      "grad_norm": 0.7808820009231567,
      "learning_rate": 1.2891566265060242e-05,
      "loss": 0.0653,
      "step": 29500
    },
    {
      "epoch": 3.555421686746988,
      "grad_norm": 0.006080710794776678,
      "learning_rate": 1.2889156626506025e-05,
      "loss": 0.0121,
      "step": 29510
    },
    {
      "epoch": 3.5566265060240965,
      "grad_norm": 0.008168193511664867,
      "learning_rate": 1.2886746987951808e-05,
      "loss": 0.0341,
      "step": 29520
    },
    {
      "epoch": 3.557831325301205,
      "grad_norm": 1.1672940254211426,
      "learning_rate": 1.2884337349397592e-05,
      "loss": 0.0325,
      "step": 29530
    },
    {
      "epoch": 3.559036144578313,
      "grad_norm": 0.0575682632625103,
      "learning_rate": 1.2881927710843373e-05,
      "loss": 0.0653,
      "step": 29540
    },
    {
      "epoch": 3.5602409638554215,
      "grad_norm": 0.12491843104362488,
      "learning_rate": 1.2879518072289156e-05,
      "loss": 0.036,
      "step": 29550
    },
    {
      "epoch": 3.5614457831325304,
      "grad_norm": 2.2673633098602295,
      "learning_rate": 1.2877108433734941e-05,
      "loss": 0.051,
      "step": 29560
    },
    {
      "epoch": 3.5626506024096387,
      "grad_norm": 2.3435299396514893,
      "learning_rate": 1.2874698795180724e-05,
      "loss": 0.103,
      "step": 29570
    },
    {
      "epoch": 3.563855421686747,
      "grad_norm": 0.08653911203145981,
      "learning_rate": 1.2872289156626508e-05,
      "loss": 0.026,
      "step": 29580
    },
    {
      "epoch": 3.5650602409638554,
      "grad_norm": 0.3321880102157593,
      "learning_rate": 1.286987951807229e-05,
      "loss": 0.041,
      "step": 29590
    },
    {
      "epoch": 3.566265060240964,
      "grad_norm": 0.016587018966674805,
      "learning_rate": 1.2867469879518072e-05,
      "loss": 0.0106,
      "step": 29600
    },
    {
      "epoch": 3.567469879518072,
      "grad_norm": 1.1065722703933716,
      "learning_rate": 1.2865060240963855e-05,
      "loss": 0.0523,
      "step": 29610
    },
    {
      "epoch": 3.5686746987951805,
      "grad_norm": 0.5953445434570312,
      "learning_rate": 1.2862650602409639e-05,
      "loss": 0.0693,
      "step": 29620
    },
    {
      "epoch": 3.5698795180722893,
      "grad_norm": 3.134157657623291,
      "learning_rate": 1.2860240963855423e-05,
      "loss": 0.0953,
      "step": 29630
    },
    {
      "epoch": 3.5710843373493977,
      "grad_norm": 2.5166964530944824,
      "learning_rate": 1.2857831325301207e-05,
      "loss": 0.0573,
      "step": 29640
    },
    {
      "epoch": 3.572289156626506,
      "grad_norm": 0.04398302361369133,
      "learning_rate": 1.285542168674699e-05,
      "loss": 0.007,
      "step": 29650
    },
    {
      "epoch": 3.5734939759036144,
      "grad_norm": 0.10142633318901062,
      "learning_rate": 1.2853012048192773e-05,
      "loss": 0.0107,
      "step": 29660
    },
    {
      "epoch": 3.5746987951807228,
      "grad_norm": 0.08873344212770462,
      "learning_rate": 1.2850602409638554e-05,
      "loss": 0.0517,
      "step": 29670
    },
    {
      "epoch": 3.5759036144578316,
      "grad_norm": 0.9011814594268799,
      "learning_rate": 1.2848192771084338e-05,
      "loss": 0.0078,
      "step": 29680
    },
    {
      "epoch": 3.57710843373494,
      "grad_norm": 3.962221145629883,
      "learning_rate": 1.284578313253012e-05,
      "loss": 0.0522,
      "step": 29690
    },
    {
      "epoch": 3.5783132530120483,
      "grad_norm": 0.17249929904937744,
      "learning_rate": 1.2843373493975904e-05,
      "loss": 0.002,
      "step": 29700
    },
    {
      "epoch": 3.5795180722891566,
      "grad_norm": 0.3422474265098572,
      "learning_rate": 1.2840963855421689e-05,
      "loss": 0.0518,
      "step": 29710
    },
    {
      "epoch": 3.580722891566265,
      "grad_norm": 2.4121549129486084,
      "learning_rate": 1.2838554216867472e-05,
      "loss": 0.0631,
      "step": 29720
    },
    {
      "epoch": 3.5819277108433734,
      "grad_norm": 3.6347532272338867,
      "learning_rate": 1.2836144578313255e-05,
      "loss": 0.0356,
      "step": 29730
    },
    {
      "epoch": 3.5831325301204817,
      "grad_norm": 0.011441345326602459,
      "learning_rate": 1.2833734939759037e-05,
      "loss": 0.0692,
      "step": 29740
    },
    {
      "epoch": 3.5843373493975905,
      "grad_norm": 0.025006860494613647,
      "learning_rate": 1.283132530120482e-05,
      "loss": 0.0429,
      "step": 29750
    },
    {
      "epoch": 3.585542168674699,
      "grad_norm": 0.06916725635528564,
      "learning_rate": 1.2828915662650603e-05,
      "loss": 0.0125,
      "step": 29760
    },
    {
      "epoch": 3.5867469879518072,
      "grad_norm": 2.442188262939453,
      "learning_rate": 1.2826506024096386e-05,
      "loss": 0.0382,
      "step": 29770
    },
    {
      "epoch": 3.5879518072289156,
      "grad_norm": 0.07517705857753754,
      "learning_rate": 1.2824096385542171e-05,
      "loss": 0.0068,
      "step": 29780
    },
    {
      "epoch": 3.589156626506024,
      "grad_norm": 0.9920358657836914,
      "learning_rate": 1.2821686746987954e-05,
      "loss": 0.0665,
      "step": 29790
    },
    {
      "epoch": 3.5903614457831328,
      "grad_norm": 4.477625846862793,
      "learning_rate": 1.2819277108433736e-05,
      "loss": 0.1121,
      "step": 29800
    },
    {
      "epoch": 3.591566265060241,
      "grad_norm": 0.1613232046365738,
      "learning_rate": 1.2816867469879519e-05,
      "loss": 0.0693,
      "step": 29810
    },
    {
      "epoch": 3.5927710843373495,
      "grad_norm": 0.05119059979915619,
      "learning_rate": 1.2814457831325302e-05,
      "loss": 0.0467,
      "step": 29820
    },
    {
      "epoch": 3.593975903614458,
      "grad_norm": 0.16313500702381134,
      "learning_rate": 1.2812048192771085e-05,
      "loss": 0.0215,
      "step": 29830
    },
    {
      "epoch": 3.595180722891566,
      "grad_norm": 3.5774173736572266,
      "learning_rate": 1.2809638554216868e-05,
      "loss": 0.0216,
      "step": 29840
    },
    {
      "epoch": 3.5963855421686746,
      "grad_norm": 2.8617265224456787,
      "learning_rate": 1.280722891566265e-05,
      "loss": 0.044,
      "step": 29850
    },
    {
      "epoch": 3.597590361445783,
      "grad_norm": 3.4531173706054688,
      "learning_rate": 1.2804819277108436e-05,
      "loss": 0.0258,
      "step": 29860
    },
    {
      "epoch": 3.5987951807228917,
      "grad_norm": 0.015408017672598362,
      "learning_rate": 1.2802409638554218e-05,
      "loss": 0.0074,
      "step": 29870
    },
    {
      "epoch": 3.6,
      "grad_norm": 13.637524604797363,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0627,
      "step": 29880
    },
    {
      "epoch": 3.6012048192771084,
      "grad_norm": 0.15080124139785767,
      "learning_rate": 1.2797590361445784e-05,
      "loss": 0.0804,
      "step": 29890
    },
    {
      "epoch": 3.602409638554217,
      "grad_norm": 11.901082038879395,
      "learning_rate": 1.2795180722891567e-05,
      "loss": 0.0715,
      "step": 29900
    },
    {
      "epoch": 3.603614457831325,
      "grad_norm": 11.087753295898438,
      "learning_rate": 1.279277108433735e-05,
      "loss": 0.0445,
      "step": 29910
    },
    {
      "epoch": 3.604819277108434,
      "grad_norm": 0.21469417214393616,
      "learning_rate": 1.2790361445783132e-05,
      "loss": 0.0429,
      "step": 29920
    },
    {
      "epoch": 3.6060240963855423,
      "grad_norm": 6.148303985595703,
      "learning_rate": 1.2787951807228917e-05,
      "loss": 0.0905,
      "step": 29930
    },
    {
      "epoch": 3.6072289156626507,
      "grad_norm": 10.879494667053223,
      "learning_rate": 1.27855421686747e-05,
      "loss": 0.0467,
      "step": 29940
    },
    {
      "epoch": 3.608433734939759,
      "grad_norm": 0.45906150341033936,
      "learning_rate": 1.2783132530120483e-05,
      "loss": 0.0599,
      "step": 29950
    },
    {
      "epoch": 3.6096385542168674,
      "grad_norm": 0.048644084483385086,
      "learning_rate": 1.2780722891566267e-05,
      "loss": 0.0443,
      "step": 29960
    },
    {
      "epoch": 3.6108433734939758,
      "grad_norm": 4.701559543609619,
      "learning_rate": 1.277831325301205e-05,
      "loss": 0.0282,
      "step": 29970
    },
    {
      "epoch": 3.612048192771084,
      "grad_norm": 0.02561434917151928,
      "learning_rate": 1.2775903614457831e-05,
      "loss": 0.0986,
      "step": 29980
    },
    {
      "epoch": 3.613253012048193,
      "grad_norm": 1.376682996749878,
      "learning_rate": 1.2773493975903614e-05,
      "loss": 0.0631,
      "step": 29990
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 1.5606988668441772,
      "learning_rate": 1.2771084337349398e-05,
      "loss": 0.0254,
      "step": 30000
    },
    {
      "epoch": 3.6156626506024097,
      "grad_norm": 0.08686380088329315,
      "learning_rate": 1.2768674698795182e-05,
      "loss": 0.0092,
      "step": 30010
    },
    {
      "epoch": 3.616867469879518,
      "grad_norm": 0.02856595069169998,
      "learning_rate": 1.2766265060240966e-05,
      "loss": 0.0517,
      "step": 30020
    },
    {
      "epoch": 3.6180722891566264,
      "grad_norm": 0.10592100769281387,
      "learning_rate": 1.2763855421686749e-05,
      "loss": 0.034,
      "step": 30030
    },
    {
      "epoch": 3.619277108433735,
      "grad_norm": 0.8143725991249084,
      "learning_rate": 1.2761445783132532e-05,
      "loss": 0.0654,
      "step": 30040
    },
    {
      "epoch": 3.6204819277108435,
      "grad_norm": 0.02759263478219509,
      "learning_rate": 1.2759036144578313e-05,
      "loss": 0.0076,
      "step": 30050
    },
    {
      "epoch": 3.621686746987952,
      "grad_norm": 0.1595657616853714,
      "learning_rate": 1.2756626506024097e-05,
      "loss": 0.039,
      "step": 30060
    },
    {
      "epoch": 3.6228915662650603,
      "grad_norm": 2.7982125282287598,
      "learning_rate": 1.275421686746988e-05,
      "loss": 0.0646,
      "step": 30070
    },
    {
      "epoch": 3.6240963855421686,
      "grad_norm": 0.20528042316436768,
      "learning_rate": 1.2751807228915665e-05,
      "loss": 0.0285,
      "step": 30080
    },
    {
      "epoch": 3.625301204819277,
      "grad_norm": 12.683113098144531,
      "learning_rate": 1.2749397590361448e-05,
      "loss": 0.0655,
      "step": 30090
    },
    {
      "epoch": 3.6265060240963853,
      "grad_norm": 2.604733467102051,
      "learning_rate": 1.2746987951807231e-05,
      "loss": 0.1041,
      "step": 30100
    },
    {
      "epoch": 3.627710843373494,
      "grad_norm": 0.5786763429641724,
      "learning_rate": 1.2744578313253012e-05,
      "loss": 0.0506,
      "step": 30110
    },
    {
      "epoch": 3.6289156626506025,
      "grad_norm": 0.3570641875267029,
      "learning_rate": 1.2742168674698796e-05,
      "loss": 0.0251,
      "step": 30120
    },
    {
      "epoch": 3.630120481927711,
      "grad_norm": 1.016833782196045,
      "learning_rate": 1.2739759036144579e-05,
      "loss": 0.0776,
      "step": 30130
    },
    {
      "epoch": 3.6313253012048192,
      "grad_norm": 10.027488708496094,
      "learning_rate": 1.2737349397590362e-05,
      "loss": 0.0777,
      "step": 30140
    },
    {
      "epoch": 3.6325301204819276,
      "grad_norm": 0.056765347719192505,
      "learning_rate": 1.2734939759036145e-05,
      "loss": 0.0222,
      "step": 30150
    },
    {
      "epoch": 3.6337349397590364,
      "grad_norm": 3.8075456619262695,
      "learning_rate": 1.273253012048193e-05,
      "loss": 0.0765,
      "step": 30160
    },
    {
      "epoch": 3.6349397590361443,
      "grad_norm": 0.8044341206550598,
      "learning_rate": 1.2730120481927713e-05,
      "loss": 0.0566,
      "step": 30170
    },
    {
      "epoch": 3.636144578313253,
      "grad_norm": 0.7502437829971313,
      "learning_rate": 1.2727710843373495e-05,
      "loss": 0.0445,
      "step": 30180
    },
    {
      "epoch": 3.6373493975903615,
      "grad_norm": 8.835349082946777,
      "learning_rate": 1.2725301204819278e-05,
      "loss": 0.0833,
      "step": 30190
    },
    {
      "epoch": 3.63855421686747,
      "grad_norm": 0.3369921147823334,
      "learning_rate": 1.2722891566265061e-05,
      "loss": 0.0286,
      "step": 30200
    },
    {
      "epoch": 3.639759036144578,
      "grad_norm": 0.0191402155905962,
      "learning_rate": 1.2720481927710844e-05,
      "loss": 0.0565,
      "step": 30210
    },
    {
      "epoch": 3.6409638554216865,
      "grad_norm": 0.11835579574108124,
      "learning_rate": 1.2718072289156627e-05,
      "loss": 0.0036,
      "step": 30220
    },
    {
      "epoch": 3.6421686746987953,
      "grad_norm": 0.1940370351076126,
      "learning_rate": 1.2715662650602412e-05,
      "loss": 0.0526,
      "step": 30230
    },
    {
      "epoch": 3.6433734939759037,
      "grad_norm": 0.1607808917760849,
      "learning_rate": 1.2713253012048194e-05,
      "loss": 0.0237,
      "step": 30240
    },
    {
      "epoch": 3.644578313253012,
      "grad_norm": 2.723813533782959,
      "learning_rate": 1.2710843373493977e-05,
      "loss": 0.1358,
      "step": 30250
    },
    {
      "epoch": 3.6457831325301204,
      "grad_norm": 0.17073091864585876,
      "learning_rate": 1.270843373493976e-05,
      "loss": 0.0421,
      "step": 30260
    },
    {
      "epoch": 3.646987951807229,
      "grad_norm": 0.9562657475471497,
      "learning_rate": 1.2706024096385543e-05,
      "loss": 0.0152,
      "step": 30270
    },
    {
      "epoch": 3.6481927710843376,
      "grad_norm": 0.07553742080926895,
      "learning_rate": 1.2703614457831326e-05,
      "loss": 0.0618,
      "step": 30280
    },
    {
      "epoch": 3.6493975903614455,
      "grad_norm": 0.2135021686553955,
      "learning_rate": 1.2701204819277108e-05,
      "loss": 0.0868,
      "step": 30290
    },
    {
      "epoch": 3.6506024096385543,
      "grad_norm": 0.2895267605781555,
      "learning_rate": 1.2698795180722891e-05,
      "loss": 0.0737,
      "step": 30300
    },
    {
      "epoch": 3.6518072289156627,
      "grad_norm": 0.05898325890302658,
      "learning_rate": 1.2696385542168676e-05,
      "loss": 0.0993,
      "step": 30310
    },
    {
      "epoch": 3.653012048192771,
      "grad_norm": 1.999206304550171,
      "learning_rate": 1.269397590361446e-05,
      "loss": 0.0493,
      "step": 30320
    },
    {
      "epoch": 3.6542168674698794,
      "grad_norm": 3.830986976623535,
      "learning_rate": 1.2691566265060242e-05,
      "loss": 0.0404,
      "step": 30330
    },
    {
      "epoch": 3.6554216867469878,
      "grad_norm": 1.9546080827713013,
      "learning_rate": 1.2689156626506026e-05,
      "loss": 0.0393,
      "step": 30340
    },
    {
      "epoch": 3.6566265060240966,
      "grad_norm": 111.3973159790039,
      "learning_rate": 1.2686746987951809e-05,
      "loss": 0.031,
      "step": 30350
    },
    {
      "epoch": 3.657831325301205,
      "grad_norm": 1.232425332069397,
      "learning_rate": 1.268433734939759e-05,
      "loss": 0.0357,
      "step": 30360
    },
    {
      "epoch": 3.6590361445783133,
      "grad_norm": 0.4940764307975769,
      "learning_rate": 1.2681927710843373e-05,
      "loss": 0.0337,
      "step": 30370
    },
    {
      "epoch": 3.6602409638554216,
      "grad_norm": 0.014933842234313488,
      "learning_rate": 1.2679518072289158e-05,
      "loss": 0.0586,
      "step": 30380
    },
    {
      "epoch": 3.66144578313253,
      "grad_norm": 1.4087419509887695,
      "learning_rate": 1.2677108433734941e-05,
      "loss": 0.0281,
      "step": 30390
    },
    {
      "epoch": 3.662650602409639,
      "grad_norm": 19.734230041503906,
      "learning_rate": 1.2674698795180725e-05,
      "loss": 0.0562,
      "step": 30400
    },
    {
      "epoch": 3.6638554216867467,
      "grad_norm": 0.014767739921808243,
      "learning_rate": 1.2672289156626508e-05,
      "loss": 0.0178,
      "step": 30410
    },
    {
      "epoch": 3.6650602409638555,
      "grad_norm": 0.030050603672862053,
      "learning_rate": 1.266987951807229e-05,
      "loss": 0.075,
      "step": 30420
    },
    {
      "epoch": 3.666265060240964,
      "grad_norm": 3.415884494781494,
      "learning_rate": 1.2667469879518072e-05,
      "loss": 0.0592,
      "step": 30430
    },
    {
      "epoch": 3.6674698795180722,
      "grad_norm": 0.05471532419323921,
      "learning_rate": 1.2665060240963856e-05,
      "loss": 0.0233,
      "step": 30440
    },
    {
      "epoch": 3.6686746987951806,
      "grad_norm": 0.36429455876350403,
      "learning_rate": 1.2662650602409639e-05,
      "loss": 0.0221,
      "step": 30450
    },
    {
      "epoch": 3.669879518072289,
      "grad_norm": 2.2762022018432617,
      "learning_rate": 1.2660240963855424e-05,
      "loss": 0.0423,
      "step": 30460
    },
    {
      "epoch": 3.6710843373493978,
      "grad_norm": 5.042620658874512,
      "learning_rate": 1.2657831325301207e-05,
      "loss": 0.057,
      "step": 30470
    },
    {
      "epoch": 3.672289156626506,
      "grad_norm": 1.5365818738937378,
      "learning_rate": 1.265542168674699e-05,
      "loss": 0.018,
      "step": 30480
    },
    {
      "epoch": 3.6734939759036145,
      "grad_norm": 0.009912707842886448,
      "learning_rate": 1.2653012048192771e-05,
      "loss": 0.0955,
      "step": 30490
    },
    {
      "epoch": 3.674698795180723,
      "grad_norm": 10.131604194641113,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 0.0668,
      "step": 30500
    },
    {
      "epoch": 3.675903614457831,
      "grad_norm": 3.1482691764831543,
      "learning_rate": 1.2648192771084338e-05,
      "loss": 0.0424,
      "step": 30510
    },
    {
      "epoch": 3.67710843373494,
      "grad_norm": 6.880150318145752,
      "learning_rate": 1.2645783132530121e-05,
      "loss": 0.0602,
      "step": 30520
    },
    {
      "epoch": 3.678313253012048,
      "grad_norm": 0.1751028150320053,
      "learning_rate": 1.2643373493975906e-05,
      "loss": 0.0356,
      "step": 30530
    },
    {
      "epoch": 3.6795180722891567,
      "grad_norm": 0.827521562576294,
      "learning_rate": 1.2640963855421689e-05,
      "loss": 0.0117,
      "step": 30540
    },
    {
      "epoch": 3.680722891566265,
      "grad_norm": 0.07395023852586746,
      "learning_rate": 1.263855421686747e-05,
      "loss": 0.0174,
      "step": 30550
    },
    {
      "epoch": 3.6819277108433734,
      "grad_norm": 1.701802134513855,
      "learning_rate": 1.2636144578313254e-05,
      "loss": 0.0638,
      "step": 30560
    },
    {
      "epoch": 3.683132530120482,
      "grad_norm": 1.7772364616394043,
      "learning_rate": 1.2633734939759037e-05,
      "loss": 0.0238,
      "step": 30570
    },
    {
      "epoch": 3.68433734939759,
      "grad_norm": 4.647526264190674,
      "learning_rate": 1.263132530120482e-05,
      "loss": 0.0174,
      "step": 30580
    },
    {
      "epoch": 3.685542168674699,
      "grad_norm": 0.015971343964338303,
      "learning_rate": 1.2628915662650603e-05,
      "loss": 0.0275,
      "step": 30590
    },
    {
      "epoch": 3.6867469879518073,
      "grad_norm": 1.7009475231170654,
      "learning_rate": 1.2626506024096385e-05,
      "loss": 0.0547,
      "step": 30600
    },
    {
      "epoch": 3.6879518072289157,
      "grad_norm": 0.054611701518297195,
      "learning_rate": 1.2624096385542171e-05,
      "loss": 0.0162,
      "step": 30610
    },
    {
      "epoch": 3.689156626506024,
      "grad_norm": 0.20133765041828156,
      "learning_rate": 1.2621686746987953e-05,
      "loss": 0.0378,
      "step": 30620
    },
    {
      "epoch": 3.6903614457831324,
      "grad_norm": 3.141580581665039,
      "learning_rate": 1.2619277108433736e-05,
      "loss": 0.0161,
      "step": 30630
    },
    {
      "epoch": 3.691566265060241,
      "grad_norm": 0.01336860191076994,
      "learning_rate": 1.2616867469879519e-05,
      "loss": 0.077,
      "step": 30640
    },
    {
      "epoch": 3.692771084337349,
      "grad_norm": 0.6140432953834534,
      "learning_rate": 1.2614457831325302e-05,
      "loss": 0.0443,
      "step": 30650
    },
    {
      "epoch": 3.693975903614458,
      "grad_norm": 6.345992088317871,
      "learning_rate": 1.2612048192771085e-05,
      "loss": 0.0407,
      "step": 30660
    },
    {
      "epoch": 3.6951807228915663,
      "grad_norm": 0.4215655028820038,
      "learning_rate": 1.2609638554216867e-05,
      "loss": 0.0715,
      "step": 30670
    },
    {
      "epoch": 3.6963855421686747,
      "grad_norm": 6.104097843170166,
      "learning_rate": 1.2607228915662652e-05,
      "loss": 0.035,
      "step": 30680
    },
    {
      "epoch": 3.697590361445783,
      "grad_norm": 3.243023633956909,
      "learning_rate": 1.2604819277108435e-05,
      "loss": 0.0676,
      "step": 30690
    },
    {
      "epoch": 3.6987951807228914,
      "grad_norm": 0.056330859661102295,
      "learning_rate": 1.2602409638554218e-05,
      "loss": 0.0203,
      "step": 30700
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.06549698859453201,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0439,
      "step": 30710
    },
    {
      "epoch": 3.7012048192771085,
      "grad_norm": 0.03413259983062744,
      "learning_rate": 1.2597590361445785e-05,
      "loss": 0.054,
      "step": 30720
    },
    {
      "epoch": 3.702409638554217,
      "grad_norm": 2.7952046394348145,
      "learning_rate": 1.2595180722891566e-05,
      "loss": 0.0425,
      "step": 30730
    },
    {
      "epoch": 3.7036144578313253,
      "grad_norm": 2.1498770713806152,
      "learning_rate": 1.259277108433735e-05,
      "loss": 0.0287,
      "step": 30740
    },
    {
      "epoch": 3.7048192771084336,
      "grad_norm": 0.026375355198979378,
      "learning_rate": 1.2590361445783132e-05,
      "loss": 0.0053,
      "step": 30750
    },
    {
      "epoch": 3.7060240963855424,
      "grad_norm": 0.6706544160842896,
      "learning_rate": 1.2587951807228917e-05,
      "loss": 0.0398,
      "step": 30760
    },
    {
      "epoch": 3.7072289156626503,
      "grad_norm": 0.16422335803508759,
      "learning_rate": 1.25855421686747e-05,
      "loss": 0.0293,
      "step": 30770
    },
    {
      "epoch": 3.708433734939759,
      "grad_norm": 0.3207238018512726,
      "learning_rate": 1.2583132530120484e-05,
      "loss": 0.0085,
      "step": 30780
    },
    {
      "epoch": 3.7096385542168675,
      "grad_norm": 1.8198826313018799,
      "learning_rate": 1.2580722891566267e-05,
      "loss": 0.0573,
      "step": 30790
    },
    {
      "epoch": 3.710843373493976,
      "grad_norm": 0.45082297921180725,
      "learning_rate": 1.2578313253012048e-05,
      "loss": 0.0374,
      "step": 30800
    },
    {
      "epoch": 3.712048192771084,
      "grad_norm": 0.05315296724438667,
      "learning_rate": 1.2575903614457831e-05,
      "loss": 0.0308,
      "step": 30810
    },
    {
      "epoch": 3.7132530120481926,
      "grad_norm": 0.03754911571741104,
      "learning_rate": 1.2573493975903615e-05,
      "loss": 0.0651,
      "step": 30820
    },
    {
      "epoch": 3.7144578313253014,
      "grad_norm": 12.131612777709961,
      "learning_rate": 1.25710843373494e-05,
      "loss": 0.0611,
      "step": 30830
    },
    {
      "epoch": 3.7156626506024097,
      "grad_norm": 0.31405261158943176,
      "learning_rate": 1.2568674698795183e-05,
      "loss": 0.0483,
      "step": 30840
    },
    {
      "epoch": 3.716867469879518,
      "grad_norm": 0.30428799986839294,
      "learning_rate": 1.2566265060240966e-05,
      "loss": 0.0228,
      "step": 30850
    },
    {
      "epoch": 3.7180722891566265,
      "grad_norm": 0.428617388010025,
      "learning_rate": 1.2563855421686747e-05,
      "loss": 0.0635,
      "step": 30860
    },
    {
      "epoch": 3.719277108433735,
      "grad_norm": 2.6500139236450195,
      "learning_rate": 1.256144578313253e-05,
      "loss": 0.0753,
      "step": 30870
    },
    {
      "epoch": 3.7204819277108436,
      "grad_norm": 0.19498446583747864,
      "learning_rate": 1.2559036144578314e-05,
      "loss": 0.0441,
      "step": 30880
    },
    {
      "epoch": 3.7216867469879515,
      "grad_norm": 0.17978450655937195,
      "learning_rate": 1.2556626506024097e-05,
      "loss": 0.0541,
      "step": 30890
    },
    {
      "epoch": 3.7228915662650603,
      "grad_norm": 0.39904698729515076,
      "learning_rate": 1.255421686746988e-05,
      "loss": 0.0377,
      "step": 30900
    },
    {
      "epoch": 3.7240963855421687,
      "grad_norm": 2.590280055999756,
      "learning_rate": 1.2551807228915665e-05,
      "loss": 0.0799,
      "step": 30910
    },
    {
      "epoch": 3.725301204819277,
      "grad_norm": 4.164486408233643,
      "learning_rate": 1.2549397590361448e-05,
      "loss": 0.021,
      "step": 30920
    },
    {
      "epoch": 3.7265060240963854,
      "grad_norm": 0.17744643986225128,
      "learning_rate": 1.254698795180723e-05,
      "loss": 0.0537,
      "step": 30930
    },
    {
      "epoch": 3.727710843373494,
      "grad_norm": 0.2678831219673157,
      "learning_rate": 1.2544578313253013e-05,
      "loss": 0.0698,
      "step": 30940
    },
    {
      "epoch": 3.7289156626506026,
      "grad_norm": 20.564828872680664,
      "learning_rate": 1.2542168674698796e-05,
      "loss": 0.0785,
      "step": 30950
    },
    {
      "epoch": 3.730120481927711,
      "grad_norm": 12.520976066589355,
      "learning_rate": 1.2539759036144579e-05,
      "loss": 0.0522,
      "step": 30960
    },
    {
      "epoch": 3.7313253012048193,
      "grad_norm": 0.06567700207233429,
      "learning_rate": 1.2537349397590362e-05,
      "loss": 0.0477,
      "step": 30970
    },
    {
      "epoch": 3.7325301204819277,
      "grad_norm": 0.04964292049407959,
      "learning_rate": 1.2534939759036147e-05,
      "loss": 0.0333,
      "step": 30980
    },
    {
      "epoch": 3.733734939759036,
      "grad_norm": 0.702260434627533,
      "learning_rate": 1.2532530120481929e-05,
      "loss": 0.0302,
      "step": 30990
    },
    {
      "epoch": 3.734939759036145,
      "grad_norm": 6.755995273590088,
      "learning_rate": 1.2530120481927712e-05,
      "loss": 0.0897,
      "step": 31000
    },
    {
      "epoch": 3.7361445783132528,
      "grad_norm": 0.21964633464813232,
      "learning_rate": 1.2527710843373495e-05,
      "loss": 0.0887,
      "step": 31010
    },
    {
      "epoch": 3.7373493975903616,
      "grad_norm": 0.3826673626899719,
      "learning_rate": 1.2525301204819278e-05,
      "loss": 0.0387,
      "step": 31020
    },
    {
      "epoch": 3.73855421686747,
      "grad_norm": 0.20930427312850952,
      "learning_rate": 1.2522891566265061e-05,
      "loss": 0.1041,
      "step": 31030
    },
    {
      "epoch": 3.7397590361445783,
      "grad_norm": 0.16040760278701782,
      "learning_rate": 1.2520481927710843e-05,
      "loss": 0.0837,
      "step": 31040
    },
    {
      "epoch": 3.7409638554216866,
      "grad_norm": 1.330248236656189,
      "learning_rate": 1.2518072289156626e-05,
      "loss": 0.0542,
      "step": 31050
    },
    {
      "epoch": 3.742168674698795,
      "grad_norm": 1.0077900886535645,
      "learning_rate": 1.251566265060241e-05,
      "loss": 0.0344,
      "step": 31060
    },
    {
      "epoch": 3.743373493975904,
      "grad_norm": 0.0507977269589901,
      "learning_rate": 1.2513253012048194e-05,
      "loss": 0.0436,
      "step": 31070
    },
    {
      "epoch": 3.744578313253012,
      "grad_norm": 0.3629932403564453,
      "learning_rate": 1.2510843373493977e-05,
      "loss": 0.0294,
      "step": 31080
    },
    {
      "epoch": 3.7457831325301205,
      "grad_norm": 2.2849059104919434,
      "learning_rate": 1.250843373493976e-05,
      "loss": 0.0472,
      "step": 31090
    },
    {
      "epoch": 3.746987951807229,
      "grad_norm": 0.025882259011268616,
      "learning_rate": 1.2506024096385544e-05,
      "loss": 0.0104,
      "step": 31100
    },
    {
      "epoch": 3.7481927710843372,
      "grad_norm": 0.1341819018125534,
      "learning_rate": 1.2503614457831325e-05,
      "loss": 0.0549,
      "step": 31110
    },
    {
      "epoch": 3.749397590361446,
      "grad_norm": 0.014949892647564411,
      "learning_rate": 1.2501204819277108e-05,
      "loss": 0.0428,
      "step": 31120
    },
    {
      "epoch": 3.750602409638554,
      "grad_norm": 2.2044413089752197,
      "learning_rate": 1.2498795180722893e-05,
      "loss": 0.0586,
      "step": 31130
    },
    {
      "epoch": 3.7518072289156628,
      "grad_norm": 0.38518115878105164,
      "learning_rate": 1.2496385542168676e-05,
      "loss": 0.0496,
      "step": 31140
    },
    {
      "epoch": 3.753012048192771,
      "grad_norm": 0.25518617033958435,
      "learning_rate": 1.249397590361446e-05,
      "loss": 0.0565,
      "step": 31150
    },
    {
      "epoch": 3.7542168674698795,
      "grad_norm": 2.3311169147491455,
      "learning_rate": 1.2491566265060243e-05,
      "loss": 0.0268,
      "step": 31160
    },
    {
      "epoch": 3.755421686746988,
      "grad_norm": 0.1486572027206421,
      "learning_rate": 1.2489156626506026e-05,
      "loss": 0.0988,
      "step": 31170
    },
    {
      "epoch": 3.756626506024096,
      "grad_norm": 0.2597712576389313,
      "learning_rate": 1.2486746987951807e-05,
      "loss": 0.0171,
      "step": 31180
    },
    {
      "epoch": 3.757831325301205,
      "grad_norm": 0.05490001663565636,
      "learning_rate": 1.248433734939759e-05,
      "loss": 0.0348,
      "step": 31190
    },
    {
      "epoch": 3.7590361445783134,
      "grad_norm": 5.242650508880615,
      "learning_rate": 1.2481927710843375e-05,
      "loss": 0.0174,
      "step": 31200
    },
    {
      "epoch": 3.7602409638554217,
      "grad_norm": 1.2110791206359863,
      "learning_rate": 1.2479518072289158e-05,
      "loss": 0.0795,
      "step": 31210
    },
    {
      "epoch": 3.76144578313253,
      "grad_norm": 10.814657211303711,
      "learning_rate": 1.2477108433734942e-05,
      "loss": 0.0645,
      "step": 31220
    },
    {
      "epoch": 3.7626506024096384,
      "grad_norm": 0.09661451727151871,
      "learning_rate": 1.2474698795180725e-05,
      "loss": 0.0505,
      "step": 31230
    },
    {
      "epoch": 3.7638554216867472,
      "grad_norm": 0.08669871091842651,
      "learning_rate": 1.2472289156626506e-05,
      "loss": 0.0193,
      "step": 31240
    },
    {
      "epoch": 3.765060240963855,
      "grad_norm": 2.585297107696533,
      "learning_rate": 1.246987951807229e-05,
      "loss": 0.0296,
      "step": 31250
    },
    {
      "epoch": 3.766265060240964,
      "grad_norm": 0.16235502064228058,
      "learning_rate": 1.2467469879518073e-05,
      "loss": 0.0748,
      "step": 31260
    },
    {
      "epoch": 3.7674698795180723,
      "grad_norm": 0.055619269609451294,
      "learning_rate": 1.2465060240963856e-05,
      "loss": 0.0787,
      "step": 31270
    },
    {
      "epoch": 3.7686746987951807,
      "grad_norm": 0.5342236757278442,
      "learning_rate": 1.246265060240964e-05,
      "loss": 0.0298,
      "step": 31280
    },
    {
      "epoch": 3.769879518072289,
      "grad_norm": 0.2005188912153244,
      "learning_rate": 1.2460240963855424e-05,
      "loss": 0.0181,
      "step": 31290
    },
    {
      "epoch": 3.7710843373493974,
      "grad_norm": 2.4914772510528564,
      "learning_rate": 1.2457831325301207e-05,
      "loss": 0.0311,
      "step": 31300
    },
    {
      "epoch": 3.772289156626506,
      "grad_norm": 0.019240407273173332,
      "learning_rate": 1.2455421686746989e-05,
      "loss": 0.0071,
      "step": 31310
    },
    {
      "epoch": 3.7734939759036146,
      "grad_norm": 1.0190300941467285,
      "learning_rate": 1.2453012048192772e-05,
      "loss": 0.0835,
      "step": 31320
    },
    {
      "epoch": 3.774698795180723,
      "grad_norm": 0.034375566989183426,
      "learning_rate": 1.2450602409638555e-05,
      "loss": 0.0615,
      "step": 31330
    },
    {
      "epoch": 3.7759036144578313,
      "grad_norm": 5.109671592712402,
      "learning_rate": 1.2448192771084338e-05,
      "loss": 0.0351,
      "step": 31340
    },
    {
      "epoch": 3.7771084337349397,
      "grad_norm": 2.062246322631836,
      "learning_rate": 1.2445783132530123e-05,
      "loss": 0.0398,
      "step": 31350
    },
    {
      "epoch": 3.7783132530120485,
      "grad_norm": 3.1452648639678955,
      "learning_rate": 1.2443373493975906e-05,
      "loss": 0.0587,
      "step": 31360
    },
    {
      "epoch": 3.7795180722891564,
      "grad_norm": 0.3451206088066101,
      "learning_rate": 1.2440963855421688e-05,
      "loss": 0.0643,
      "step": 31370
    },
    {
      "epoch": 3.780722891566265,
      "grad_norm": 1.7192695140838623,
      "learning_rate": 1.243855421686747e-05,
      "loss": 0.0486,
      "step": 31380
    },
    {
      "epoch": 3.7819277108433735,
      "grad_norm": 0.05139877274632454,
      "learning_rate": 1.2436144578313254e-05,
      "loss": 0.0193,
      "step": 31390
    },
    {
      "epoch": 3.783132530120482,
      "grad_norm": 78.54074096679688,
      "learning_rate": 1.2433734939759037e-05,
      "loss": 0.0496,
      "step": 31400
    },
    {
      "epoch": 3.7843373493975903,
      "grad_norm": 0.5871334075927734,
      "learning_rate": 1.243132530120482e-05,
      "loss": 0.0319,
      "step": 31410
    },
    {
      "epoch": 3.7855421686746986,
      "grad_norm": 1.4907259941101074,
      "learning_rate": 1.2428915662650602e-05,
      "loss": 0.0168,
      "step": 31420
    },
    {
      "epoch": 3.7867469879518074,
      "grad_norm": 1.590538501739502,
      "learning_rate": 1.2426506024096388e-05,
      "loss": 0.0425,
      "step": 31430
    },
    {
      "epoch": 3.787951807228916,
      "grad_norm": 4.634463310241699,
      "learning_rate": 1.242409638554217e-05,
      "loss": 0.0777,
      "step": 31440
    },
    {
      "epoch": 3.789156626506024,
      "grad_norm": 0.025927383452653885,
      "learning_rate": 1.2421686746987953e-05,
      "loss": 0.0605,
      "step": 31450
    },
    {
      "epoch": 3.7903614457831325,
      "grad_norm": 0.009506472386419773,
      "learning_rate": 1.2419277108433736e-05,
      "loss": 0.0196,
      "step": 31460
    },
    {
      "epoch": 3.791566265060241,
      "grad_norm": 2.5524473190307617,
      "learning_rate": 1.241686746987952e-05,
      "loss": 0.029,
      "step": 31470
    },
    {
      "epoch": 3.7927710843373497,
      "grad_norm": 2.3653323650360107,
      "learning_rate": 1.2414457831325303e-05,
      "loss": 0.087,
      "step": 31480
    },
    {
      "epoch": 3.7939759036144576,
      "grad_norm": 2.589947462081909,
      "learning_rate": 1.2412048192771084e-05,
      "loss": 0.0714,
      "step": 31490
    },
    {
      "epoch": 3.7951807228915664,
      "grad_norm": 2.5721397399902344,
      "learning_rate": 1.2409638554216869e-05,
      "loss": 0.0274,
      "step": 31500
    },
    {
      "epoch": 3.7963855421686747,
      "grad_norm": 2.6090729236602783,
      "learning_rate": 1.2407228915662652e-05,
      "loss": 0.0248,
      "step": 31510
    },
    {
      "epoch": 3.797590361445783,
      "grad_norm": 8.325260162353516,
      "learning_rate": 1.2404819277108435e-05,
      "loss": 0.0636,
      "step": 31520
    },
    {
      "epoch": 3.7987951807228915,
      "grad_norm": 0.8765319585800171,
      "learning_rate": 1.2402409638554218e-05,
      "loss": 0.0299,
      "step": 31530
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.9842678904533386,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0703,
      "step": 31540
    },
    {
      "epoch": 3.8012048192771086,
      "grad_norm": 0.8380961418151855,
      "learning_rate": 1.2397590361445783e-05,
      "loss": 0.0439,
      "step": 31550
    },
    {
      "epoch": 3.802409638554217,
      "grad_norm": 0.2278265506029129,
      "learning_rate": 1.2395180722891566e-05,
      "loss": 0.0613,
      "step": 31560
    },
    {
      "epoch": 3.8036144578313253,
      "grad_norm": 0.3090575039386749,
      "learning_rate": 1.239277108433735e-05,
      "loss": 0.0265,
      "step": 31570
    },
    {
      "epoch": 3.8048192771084337,
      "grad_norm": 0.049751345068216324,
      "learning_rate": 1.2390361445783134e-05,
      "loss": 0.0255,
      "step": 31580
    },
    {
      "epoch": 3.806024096385542,
      "grad_norm": 0.02874605543911457,
      "learning_rate": 1.2387951807228917e-05,
      "loss": 0.0325,
      "step": 31590
    },
    {
      "epoch": 3.807228915662651,
      "grad_norm": 5.64405632019043,
      "learning_rate": 1.23855421686747e-05,
      "loss": 0.0558,
      "step": 31600
    },
    {
      "epoch": 3.808433734939759,
      "grad_norm": 2.7417984008789062,
      "learning_rate": 1.2383132530120484e-05,
      "loss": 0.0456,
      "step": 31610
    },
    {
      "epoch": 3.8096385542168676,
      "grad_norm": 2.9937632083892822,
      "learning_rate": 1.2380722891566265e-05,
      "loss": 0.0803,
      "step": 31620
    },
    {
      "epoch": 3.810843373493976,
      "grad_norm": 6.0342020988464355,
      "learning_rate": 1.2378313253012048e-05,
      "loss": 0.0375,
      "step": 31630
    },
    {
      "epoch": 3.8120481927710843,
      "grad_norm": 1.8614639043807983,
      "learning_rate": 1.2375903614457832e-05,
      "loss": 0.0445,
      "step": 31640
    },
    {
      "epoch": 3.8132530120481927,
      "grad_norm": 1.6556884050369263,
      "learning_rate": 1.2373493975903616e-05,
      "loss": 0.0295,
      "step": 31650
    },
    {
      "epoch": 3.814457831325301,
      "grad_norm": 0.1640702784061432,
      "learning_rate": 1.23710843373494e-05,
      "loss": 0.1007,
      "step": 31660
    },
    {
      "epoch": 3.81566265060241,
      "grad_norm": 0.07011286169290543,
      "learning_rate": 1.2368674698795183e-05,
      "loss": 0.023,
      "step": 31670
    },
    {
      "epoch": 3.816867469879518,
      "grad_norm": 0.09356748312711716,
      "learning_rate": 1.2366265060240964e-05,
      "loss": 0.0323,
      "step": 31680
    },
    {
      "epoch": 3.8180722891566266,
      "grad_norm": 0.33619529008865356,
      "learning_rate": 1.2363855421686748e-05,
      "loss": 0.0326,
      "step": 31690
    },
    {
      "epoch": 3.819277108433735,
      "grad_norm": 0.06874755769968033,
      "learning_rate": 1.236144578313253e-05,
      "loss": 0.0446,
      "step": 31700
    },
    {
      "epoch": 3.8204819277108433,
      "grad_norm": 0.4234858453273773,
      "learning_rate": 1.2359036144578314e-05,
      "loss": 0.0725,
      "step": 31710
    },
    {
      "epoch": 3.821686746987952,
      "grad_norm": 0.09738433361053467,
      "learning_rate": 1.2356626506024097e-05,
      "loss": 0.0749,
      "step": 31720
    },
    {
      "epoch": 3.82289156626506,
      "grad_norm": 0.03264002501964569,
      "learning_rate": 1.2354216867469882e-05,
      "loss": 0.0352,
      "step": 31730
    },
    {
      "epoch": 3.824096385542169,
      "grad_norm": 0.2808972895145416,
      "learning_rate": 1.2351807228915665e-05,
      "loss": 0.0248,
      "step": 31740
    },
    {
      "epoch": 3.825301204819277,
      "grad_norm": 0.2580079734325409,
      "learning_rate": 1.2349397590361447e-05,
      "loss": 0.0776,
      "step": 31750
    },
    {
      "epoch": 3.8265060240963855,
      "grad_norm": 0.8036161661148071,
      "learning_rate": 1.234698795180723e-05,
      "loss": 0.0435,
      "step": 31760
    },
    {
      "epoch": 3.827710843373494,
      "grad_norm": 4.693047046661377,
      "learning_rate": 1.2344578313253013e-05,
      "loss": 0.0457,
      "step": 31770
    },
    {
      "epoch": 3.8289156626506022,
      "grad_norm": 3.4937517642974854,
      "learning_rate": 1.2342168674698796e-05,
      "loss": 0.0329,
      "step": 31780
    },
    {
      "epoch": 3.830120481927711,
      "grad_norm": 0.10620923340320587,
      "learning_rate": 1.233975903614458e-05,
      "loss": 0.0217,
      "step": 31790
    },
    {
      "epoch": 3.8313253012048194,
      "grad_norm": 0.9718542098999023,
      "learning_rate": 1.2337349397590364e-05,
      "loss": 0.0111,
      "step": 31800
    },
    {
      "epoch": 3.8325301204819278,
      "grad_norm": 4.440647125244141,
      "learning_rate": 1.2334939759036146e-05,
      "loss": 0.0615,
      "step": 31810
    },
    {
      "epoch": 3.833734939759036,
      "grad_norm": 1.2633432149887085,
      "learning_rate": 1.2332530120481929e-05,
      "loss": 0.0405,
      "step": 31820
    },
    {
      "epoch": 3.8349397590361445,
      "grad_norm": 0.057805322110652924,
      "learning_rate": 1.2330120481927712e-05,
      "loss": 0.0457,
      "step": 31830
    },
    {
      "epoch": 3.8361445783132533,
      "grad_norm": 0.7847713232040405,
      "learning_rate": 1.2327710843373495e-05,
      "loss": 0.0382,
      "step": 31840
    },
    {
      "epoch": 3.837349397590361,
      "grad_norm": 0.12586233019828796,
      "learning_rate": 1.2325301204819278e-05,
      "loss": 0.038,
      "step": 31850
    },
    {
      "epoch": 3.83855421686747,
      "grad_norm": 3.0172739028930664,
      "learning_rate": 1.232289156626506e-05,
      "loss": 0.0916,
      "step": 31860
    },
    {
      "epoch": 3.8397590361445784,
      "grad_norm": 2.182915449142456,
      "learning_rate": 1.2320481927710843e-05,
      "loss": 0.0553,
      "step": 31870
    },
    {
      "epoch": 3.8409638554216867,
      "grad_norm": 1.40857994556427,
      "learning_rate": 1.2318072289156628e-05,
      "loss": 0.0523,
      "step": 31880
    },
    {
      "epoch": 3.842168674698795,
      "grad_norm": 0.08266304433345795,
      "learning_rate": 1.2315662650602411e-05,
      "loss": 0.0182,
      "step": 31890
    },
    {
      "epoch": 3.8433734939759034,
      "grad_norm": 0.7301037907600403,
      "learning_rate": 1.2313253012048194e-05,
      "loss": 0.0409,
      "step": 31900
    },
    {
      "epoch": 3.8445783132530122,
      "grad_norm": 0.07258760929107666,
      "learning_rate": 1.2310843373493977e-05,
      "loss": 0.0234,
      "step": 31910
    },
    {
      "epoch": 3.8457831325301206,
      "grad_norm": 0.5001163482666016,
      "learning_rate": 1.230843373493976e-05,
      "loss": 0.0345,
      "step": 31920
    },
    {
      "epoch": 3.846987951807229,
      "grad_norm": 0.033808838576078415,
      "learning_rate": 1.2306024096385542e-05,
      "loss": 0.022,
      "step": 31930
    },
    {
      "epoch": 3.8481927710843373,
      "grad_norm": 0.019642038270831108,
      "learning_rate": 1.2303614457831325e-05,
      "loss": 0.0487,
      "step": 31940
    },
    {
      "epoch": 3.8493975903614457,
      "grad_norm": 0.17684169113636017,
      "learning_rate": 1.230120481927711e-05,
      "loss": 0.0706,
      "step": 31950
    },
    {
      "epoch": 3.8506024096385545,
      "grad_norm": 1.6199740171432495,
      "learning_rate": 1.2298795180722893e-05,
      "loss": 0.0495,
      "step": 31960
    },
    {
      "epoch": 3.8518072289156624,
      "grad_norm": 2.365788698196411,
      "learning_rate": 1.2296385542168676e-05,
      "loss": 0.0386,
      "step": 31970
    },
    {
      "epoch": 3.853012048192771,
      "grad_norm": 1.2986361980438232,
      "learning_rate": 1.229397590361446e-05,
      "loss": 0.0351,
      "step": 31980
    },
    {
      "epoch": 3.8542168674698796,
      "grad_norm": 2.4725472927093506,
      "learning_rate": 1.2291566265060241e-05,
      "loss": 0.0639,
      "step": 31990
    },
    {
      "epoch": 3.855421686746988,
      "grad_norm": 15.145546913146973,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 0.0771,
      "step": 32000
    },
    {
      "epoch": 3.8566265060240963,
      "grad_norm": 0.007727149873971939,
      "learning_rate": 1.2286746987951807e-05,
      "loss": 0.1102,
      "step": 32010
    },
    {
      "epoch": 3.8578313253012047,
      "grad_norm": 17.946535110473633,
      "learning_rate": 1.228433734939759e-05,
      "loss": 0.0269,
      "step": 32020
    },
    {
      "epoch": 3.8590361445783135,
      "grad_norm": 1.6956744194030762,
      "learning_rate": 1.2281927710843375e-05,
      "loss": 0.0255,
      "step": 32030
    },
    {
      "epoch": 3.860240963855422,
      "grad_norm": 0.7515992522239685,
      "learning_rate": 1.2279518072289159e-05,
      "loss": 0.0455,
      "step": 32040
    },
    {
      "epoch": 3.86144578313253,
      "grad_norm": 0.03924405947327614,
      "learning_rate": 1.2277108433734942e-05,
      "loss": 0.0418,
      "step": 32050
    },
    {
      "epoch": 3.8626506024096385,
      "grad_norm": 4.845315456390381,
      "learning_rate": 1.2274698795180723e-05,
      "loss": 0.052,
      "step": 32060
    },
    {
      "epoch": 3.863855421686747,
      "grad_norm": 12.66567611694336,
      "learning_rate": 1.2272289156626506e-05,
      "loss": 0.0373,
      "step": 32070
    },
    {
      "epoch": 3.8650602409638557,
      "grad_norm": 10.585753440856934,
      "learning_rate": 1.226987951807229e-05,
      "loss": 0.0345,
      "step": 32080
    },
    {
      "epoch": 3.8662650602409636,
      "grad_norm": 0.059170570224523544,
      "learning_rate": 1.2267469879518073e-05,
      "loss": 0.0567,
      "step": 32090
    },
    {
      "epoch": 3.8674698795180724,
      "grad_norm": 3.044412612915039,
      "learning_rate": 1.2265060240963858e-05,
      "loss": 0.0567,
      "step": 32100
    },
    {
      "epoch": 3.8686746987951808,
      "grad_norm": 11.493064880371094,
      "learning_rate": 1.2262650602409641e-05,
      "loss": 0.0572,
      "step": 32110
    },
    {
      "epoch": 3.869879518072289,
      "grad_norm": 0.7055834531784058,
      "learning_rate": 1.2260240963855422e-05,
      "loss": 0.0452,
      "step": 32120
    },
    {
      "epoch": 3.8710843373493975,
      "grad_norm": 0.03671816736459732,
      "learning_rate": 1.2257831325301206e-05,
      "loss": 0.0178,
      "step": 32130
    },
    {
      "epoch": 3.872289156626506,
      "grad_norm": 1.231939435005188,
      "learning_rate": 1.2255421686746989e-05,
      "loss": 0.0198,
      "step": 32140
    },
    {
      "epoch": 3.8734939759036147,
      "grad_norm": 0.4894420802593231,
      "learning_rate": 1.2253012048192772e-05,
      "loss": 0.0147,
      "step": 32150
    },
    {
      "epoch": 3.874698795180723,
      "grad_norm": 0.008130042813718319,
      "learning_rate": 1.2250602409638555e-05,
      "loss": 0.0626,
      "step": 32160
    },
    {
      "epoch": 3.8759036144578314,
      "grad_norm": 2.0466458797454834,
      "learning_rate": 1.2248192771084337e-05,
      "loss": 0.0338,
      "step": 32170
    },
    {
      "epoch": 3.8771084337349397,
      "grad_norm": 0.014614108018577099,
      "learning_rate": 1.2245783132530123e-05,
      "loss": 0.0531,
      "step": 32180
    },
    {
      "epoch": 3.878313253012048,
      "grad_norm": 3.3505446910858154,
      "learning_rate": 1.2243373493975905e-05,
      "loss": 0.0082,
      "step": 32190
    },
    {
      "epoch": 3.8795180722891565,
      "grad_norm": 0.3663693070411682,
      "learning_rate": 1.2240963855421688e-05,
      "loss": 0.0221,
      "step": 32200
    },
    {
      "epoch": 3.880722891566265,
      "grad_norm": 0.014167587272822857,
      "learning_rate": 1.2238554216867471e-05,
      "loss": 0.0018,
      "step": 32210
    },
    {
      "epoch": 3.8819277108433736,
      "grad_norm": 0.09624160081148148,
      "learning_rate": 1.2236144578313254e-05,
      "loss": 0.0906,
      "step": 32220
    },
    {
      "epoch": 3.883132530120482,
      "grad_norm": 1.600268006324768,
      "learning_rate": 1.2233734939759037e-05,
      "loss": 0.0362,
      "step": 32230
    },
    {
      "epoch": 3.8843373493975903,
      "grad_norm": 5.609680652618408,
      "learning_rate": 1.2231325301204819e-05,
      "loss": 0.0836,
      "step": 32240
    },
    {
      "epoch": 3.8855421686746987,
      "grad_norm": 0.14430847764015198,
      "learning_rate": 1.2228915662650604e-05,
      "loss": 0.0744,
      "step": 32250
    },
    {
      "epoch": 3.886746987951807,
      "grad_norm": 4.393613815307617,
      "learning_rate": 1.2226506024096387e-05,
      "loss": 0.0738,
      "step": 32260
    },
    {
      "epoch": 3.887951807228916,
      "grad_norm": 4.184561252593994,
      "learning_rate": 1.222409638554217e-05,
      "loss": 0.0467,
      "step": 32270
    },
    {
      "epoch": 3.8891566265060242,
      "grad_norm": 6.080587863922119,
      "learning_rate": 1.2221686746987953e-05,
      "loss": 0.08,
      "step": 32280
    },
    {
      "epoch": 3.8903614457831326,
      "grad_norm": 2.634416341781616,
      "learning_rate": 1.2219277108433736e-05,
      "loss": 0.0581,
      "step": 32290
    },
    {
      "epoch": 3.891566265060241,
      "grad_norm": 2.486043691635132,
      "learning_rate": 1.2216867469879518e-05,
      "loss": 0.0976,
      "step": 32300
    },
    {
      "epoch": 3.8927710843373493,
      "grad_norm": 1.5270984172821045,
      "learning_rate": 1.2214457831325301e-05,
      "loss": 0.0471,
      "step": 32310
    },
    {
      "epoch": 3.8939759036144577,
      "grad_norm": 4.615621566772461,
      "learning_rate": 1.2212048192771084e-05,
      "loss": 0.041,
      "step": 32320
    },
    {
      "epoch": 3.895180722891566,
      "grad_norm": 1.6984697580337524,
      "learning_rate": 1.2209638554216869e-05,
      "loss": 0.0176,
      "step": 32330
    },
    {
      "epoch": 3.896385542168675,
      "grad_norm": 0.7357711791992188,
      "learning_rate": 1.2207228915662652e-05,
      "loss": 0.0317,
      "step": 32340
    },
    {
      "epoch": 3.897590361445783,
      "grad_norm": 0.06156754493713379,
      "learning_rate": 1.2204819277108435e-05,
      "loss": 0.0394,
      "step": 32350
    },
    {
      "epoch": 3.8987951807228916,
      "grad_norm": 0.027822399511933327,
      "learning_rate": 1.2202409638554219e-05,
      "loss": 0.0695,
      "step": 32360
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.04364418238401413,
      "learning_rate": 1.22e-05,
      "loss": 0.052,
      "step": 32370
    },
    {
      "epoch": 3.9012048192771083,
      "grad_norm": 0.07331354171037674,
      "learning_rate": 1.2197590361445783e-05,
      "loss": 0.0207,
      "step": 32380
    },
    {
      "epoch": 3.902409638554217,
      "grad_norm": 0.048504531383514404,
      "learning_rate": 1.2195180722891566e-05,
      "loss": 0.0507,
      "step": 32390
    },
    {
      "epoch": 3.9036144578313254,
      "grad_norm": 0.6347180008888245,
      "learning_rate": 1.2192771084337351e-05,
      "loss": 0.0606,
      "step": 32400
    },
    {
      "epoch": 3.904819277108434,
      "grad_norm": 1.153273105621338,
      "learning_rate": 1.2190361445783134e-05,
      "loss": 0.0302,
      "step": 32410
    },
    {
      "epoch": 3.906024096385542,
      "grad_norm": 0.09502813220024109,
      "learning_rate": 1.2187951807228918e-05,
      "loss": 0.0673,
      "step": 32420
    },
    {
      "epoch": 3.9072289156626505,
      "grad_norm": 1.24855375289917,
      "learning_rate": 1.2185542168674699e-05,
      "loss": 0.0709,
      "step": 32430
    },
    {
      "epoch": 3.908433734939759,
      "grad_norm": 0.41193127632141113,
      "learning_rate": 1.2183132530120482e-05,
      "loss": 0.0362,
      "step": 32440
    },
    {
      "epoch": 3.9096385542168672,
      "grad_norm": 0.6242982745170593,
      "learning_rate": 1.2180722891566265e-05,
      "loss": 0.039,
      "step": 32450
    },
    {
      "epoch": 3.910843373493976,
      "grad_norm": 2.1536104679107666,
      "learning_rate": 1.2178313253012049e-05,
      "loss": 0.047,
      "step": 32460
    },
    {
      "epoch": 3.9120481927710844,
      "grad_norm": 0.17194099724292755,
      "learning_rate": 1.2175903614457832e-05,
      "loss": 0.0472,
      "step": 32470
    },
    {
      "epoch": 3.9132530120481928,
      "grad_norm": 0.16911159455776215,
      "learning_rate": 1.2173493975903617e-05,
      "loss": 0.0518,
      "step": 32480
    },
    {
      "epoch": 3.914457831325301,
      "grad_norm": 0.08323034644126892,
      "learning_rate": 1.21710843373494e-05,
      "loss": 0.0379,
      "step": 32490
    },
    {
      "epoch": 3.9156626506024095,
      "grad_norm": 0.1522504985332489,
      "learning_rate": 1.2168674698795181e-05,
      "loss": 0.019,
      "step": 32500
    },
    {
      "epoch": 3.9168674698795183,
      "grad_norm": 4.236619472503662,
      "learning_rate": 1.2166265060240965e-05,
      "loss": 0.0504,
      "step": 32510
    },
    {
      "epoch": 3.9180722891566266,
      "grad_norm": 0.12981931865215302,
      "learning_rate": 1.2163855421686748e-05,
      "loss": 0.0321,
      "step": 32520
    },
    {
      "epoch": 3.919277108433735,
      "grad_norm": 0.2553243041038513,
      "learning_rate": 1.2161445783132531e-05,
      "loss": 0.014,
      "step": 32530
    },
    {
      "epoch": 3.9204819277108434,
      "grad_norm": 8.265117645263672,
      "learning_rate": 1.2159036144578314e-05,
      "loss": 0.0146,
      "step": 32540
    },
    {
      "epoch": 3.9216867469879517,
      "grad_norm": 5.57414436340332,
      "learning_rate": 1.2156626506024099e-05,
      "loss": 0.0571,
      "step": 32550
    },
    {
      "epoch": 3.92289156626506,
      "grad_norm": 2.7146527767181396,
      "learning_rate": 1.2154216867469882e-05,
      "loss": 0.0554,
      "step": 32560
    },
    {
      "epoch": 3.9240963855421684,
      "grad_norm": 0.9988070726394653,
      "learning_rate": 1.2151807228915664e-05,
      "loss": 0.0198,
      "step": 32570
    },
    {
      "epoch": 3.9253012048192772,
      "grad_norm": 1.1600396633148193,
      "learning_rate": 1.2149397590361447e-05,
      "loss": 0.0628,
      "step": 32580
    },
    {
      "epoch": 3.9265060240963856,
      "grad_norm": 0.014970616437494755,
      "learning_rate": 1.214698795180723e-05,
      "loss": 0.0346,
      "step": 32590
    },
    {
      "epoch": 3.927710843373494,
      "grad_norm": 0.34023013710975647,
      "learning_rate": 1.2144578313253013e-05,
      "loss": 0.05,
      "step": 32600
    },
    {
      "epoch": 3.9289156626506023,
      "grad_norm": 0.35290634632110596,
      "learning_rate": 1.2142168674698795e-05,
      "loss": 0.0563,
      "step": 32610
    },
    {
      "epoch": 3.9301204819277107,
      "grad_norm": 1.3343552350997925,
      "learning_rate": 1.2139759036144578e-05,
      "loss": 0.0243,
      "step": 32620
    },
    {
      "epoch": 3.9313253012048195,
      "grad_norm": 0.030319422483444214,
      "learning_rate": 1.2137349397590363e-05,
      "loss": 0.0613,
      "step": 32630
    },
    {
      "epoch": 3.932530120481928,
      "grad_norm": 1.7373690605163574,
      "learning_rate": 1.2134939759036146e-05,
      "loss": 0.0442,
      "step": 32640
    },
    {
      "epoch": 3.933734939759036,
      "grad_norm": 0.03247043862938881,
      "learning_rate": 1.2132530120481929e-05,
      "loss": 0.0088,
      "step": 32650
    },
    {
      "epoch": 3.9349397590361446,
      "grad_norm": 0.007605165243148804,
      "learning_rate": 1.2130120481927712e-05,
      "loss": 0.0414,
      "step": 32660
    },
    {
      "epoch": 3.936144578313253,
      "grad_norm": 1.5684666633605957,
      "learning_rate": 1.2127710843373495e-05,
      "loss": 0.0606,
      "step": 32670
    },
    {
      "epoch": 3.9373493975903613,
      "grad_norm": 7.304170608520508,
      "learning_rate": 1.2125301204819277e-05,
      "loss": 0.0422,
      "step": 32680
    },
    {
      "epoch": 3.9385542168674696,
      "grad_norm": 0.3049095869064331,
      "learning_rate": 1.212289156626506e-05,
      "loss": 0.0361,
      "step": 32690
    },
    {
      "epoch": 3.9397590361445785,
      "grad_norm": 0.014871060848236084,
      "learning_rate": 1.2120481927710845e-05,
      "loss": 0.0236,
      "step": 32700
    },
    {
      "epoch": 3.940963855421687,
      "grad_norm": 0.254272997379303,
      "learning_rate": 1.2118072289156628e-05,
      "loss": 0.0843,
      "step": 32710
    },
    {
      "epoch": 3.942168674698795,
      "grad_norm": 0.20222340524196625,
      "learning_rate": 1.2115662650602411e-05,
      "loss": 0.0378,
      "step": 32720
    },
    {
      "epoch": 3.9433734939759035,
      "grad_norm": 0.025849290192127228,
      "learning_rate": 1.2113253012048194e-05,
      "loss": 0.0108,
      "step": 32730
    },
    {
      "epoch": 3.944578313253012,
      "grad_norm": 0.12818676233291626,
      "learning_rate": 1.2110843373493978e-05,
      "loss": 0.0492,
      "step": 32740
    },
    {
      "epoch": 3.9457831325301207,
      "grad_norm": 0.016209404915571213,
      "learning_rate": 1.2108433734939759e-05,
      "loss": 0.0328,
      "step": 32750
    },
    {
      "epoch": 3.946987951807229,
      "grad_norm": 0.09678611159324646,
      "learning_rate": 1.2106024096385542e-05,
      "loss": 0.0589,
      "step": 32760
    },
    {
      "epoch": 3.9481927710843374,
      "grad_norm": 5.399908542633057,
      "learning_rate": 1.2103614457831325e-05,
      "loss": 0.0598,
      "step": 32770
    },
    {
      "epoch": 3.9493975903614458,
      "grad_norm": 0.14240500330924988,
      "learning_rate": 1.210120481927711e-05,
      "loss": 0.0607,
      "step": 32780
    },
    {
      "epoch": 3.950602409638554,
      "grad_norm": 1.0533121824264526,
      "learning_rate": 1.2098795180722893e-05,
      "loss": 0.0503,
      "step": 32790
    },
    {
      "epoch": 3.9518072289156625,
      "grad_norm": 0.3930741250514984,
      "learning_rate": 1.2096385542168677e-05,
      "loss": 0.044,
      "step": 32800
    },
    {
      "epoch": 3.953012048192771,
      "grad_norm": 0.19665302336215973,
      "learning_rate": 1.2093975903614458e-05,
      "loss": 0.0365,
      "step": 32810
    },
    {
      "epoch": 3.9542168674698797,
      "grad_norm": 0.06094171106815338,
      "learning_rate": 1.2091566265060241e-05,
      "loss": 0.0634,
      "step": 32820
    },
    {
      "epoch": 3.955421686746988,
      "grad_norm": 0.625827431678772,
      "learning_rate": 1.2089156626506024e-05,
      "loss": 0.025,
      "step": 32830
    },
    {
      "epoch": 3.9566265060240964,
      "grad_norm": 13.629254341125488,
      "learning_rate": 1.2086746987951808e-05,
      "loss": 0.0283,
      "step": 32840
    },
    {
      "epoch": 3.9578313253012047,
      "grad_norm": 1.4140621423721313,
      "learning_rate": 1.2084337349397593e-05,
      "loss": 0.0711,
      "step": 32850
    },
    {
      "epoch": 3.959036144578313,
      "grad_norm": 0.10029205679893494,
      "learning_rate": 1.2081927710843376e-05,
      "loss": 0.0292,
      "step": 32860
    },
    {
      "epoch": 3.960240963855422,
      "grad_norm": 1.8706802129745483,
      "learning_rate": 1.2079518072289159e-05,
      "loss": 0.0693,
      "step": 32870
    },
    {
      "epoch": 3.9614457831325303,
      "grad_norm": 0.02585388533771038,
      "learning_rate": 1.207710843373494e-05,
      "loss": 0.008,
      "step": 32880
    },
    {
      "epoch": 3.9626506024096386,
      "grad_norm": 3.3971030712127686,
      "learning_rate": 1.2074698795180724e-05,
      "loss": 0.0435,
      "step": 32890
    },
    {
      "epoch": 3.963855421686747,
      "grad_norm": 0.2021009474992752,
      "learning_rate": 1.2072289156626507e-05,
      "loss": 0.0767,
      "step": 32900
    },
    {
      "epoch": 3.9650602409638553,
      "grad_norm": 3.5541768074035645,
      "learning_rate": 1.206987951807229e-05,
      "loss": 0.0472,
      "step": 32910
    },
    {
      "epoch": 3.9662650602409637,
      "grad_norm": 2.5428566932678223,
      "learning_rate": 1.2067469879518073e-05,
      "loss": 0.0398,
      "step": 32920
    },
    {
      "epoch": 3.967469879518072,
      "grad_norm": 0.0191787239164114,
      "learning_rate": 1.2065060240963858e-05,
      "loss": 0.0151,
      "step": 32930
    },
    {
      "epoch": 3.968674698795181,
      "grad_norm": 0.4960990846157074,
      "learning_rate": 1.206265060240964e-05,
      "loss": 0.0627,
      "step": 32940
    },
    {
      "epoch": 3.9698795180722892,
      "grad_norm": 2.167590618133545,
      "learning_rate": 1.2060240963855423e-05,
      "loss": 0.0335,
      "step": 32950
    },
    {
      "epoch": 3.9710843373493976,
      "grad_norm": 1.668383002281189,
      "learning_rate": 1.2057831325301206e-05,
      "loss": 0.085,
      "step": 32960
    },
    {
      "epoch": 3.972289156626506,
      "grad_norm": 0.30723825097084045,
      "learning_rate": 1.2055421686746989e-05,
      "loss": 0.0712,
      "step": 32970
    },
    {
      "epoch": 3.9734939759036143,
      "grad_norm": 2.494192123413086,
      "learning_rate": 1.2053012048192772e-05,
      "loss": 0.0235,
      "step": 32980
    },
    {
      "epoch": 3.974698795180723,
      "grad_norm": 1.8960216045379639,
      "learning_rate": 1.2050602409638554e-05,
      "loss": 0.039,
      "step": 32990
    },
    {
      "epoch": 3.9759036144578315,
      "grad_norm": 5.501350402832031,
      "learning_rate": 1.204819277108434e-05,
      "loss": 0.0132,
      "step": 33000
    },
    {
      "epoch": 3.97710843373494,
      "grad_norm": 0.4011233150959015,
      "learning_rate": 1.2045783132530122e-05,
      "loss": 0.0233,
      "step": 33010
    },
    {
      "epoch": 3.978313253012048,
      "grad_norm": 0.7470982074737549,
      "learning_rate": 1.2043373493975905e-05,
      "loss": 0.0646,
      "step": 33020
    },
    {
      "epoch": 3.9795180722891565,
      "grad_norm": 0.05065610259771347,
      "learning_rate": 1.2040963855421688e-05,
      "loss": 0.0255,
      "step": 33030
    },
    {
      "epoch": 3.980722891566265,
      "grad_norm": 3.369680404663086,
      "learning_rate": 1.2038554216867471e-05,
      "loss": 0.0467,
      "step": 33040
    },
    {
      "epoch": 3.9819277108433733,
      "grad_norm": 0.06180240958929062,
      "learning_rate": 1.2036144578313254e-05,
      "loss": 0.0722,
      "step": 33050
    },
    {
      "epoch": 3.983132530120482,
      "grad_norm": 0.5552820563316345,
      "learning_rate": 1.2033734939759036e-05,
      "loss": 0.0334,
      "step": 33060
    },
    {
      "epoch": 3.9843373493975904,
      "grad_norm": 0.024268897250294685,
      "learning_rate": 1.2031325301204819e-05,
      "loss": 0.0452,
      "step": 33070
    },
    {
      "epoch": 3.985542168674699,
      "grad_norm": 0.22573424875736237,
      "learning_rate": 1.2028915662650604e-05,
      "loss": 0.0024,
      "step": 33080
    },
    {
      "epoch": 3.986746987951807,
      "grad_norm": 5.642177104949951,
      "learning_rate": 1.2026506024096387e-05,
      "loss": 0.0152,
      "step": 33090
    },
    {
      "epoch": 3.9879518072289155,
      "grad_norm": 0.09797114878892899,
      "learning_rate": 1.202409638554217e-05,
      "loss": 0.117,
      "step": 33100
    },
    {
      "epoch": 3.9891566265060243,
      "grad_norm": 0.043922409415245056,
      "learning_rate": 1.2021686746987953e-05,
      "loss": 0.0466,
      "step": 33110
    },
    {
      "epoch": 3.9903614457831327,
      "grad_norm": 0.3669458329677582,
      "learning_rate": 1.2019277108433735e-05,
      "loss": 0.076,
      "step": 33120
    },
    {
      "epoch": 3.991566265060241,
      "grad_norm": 2.753718852996826,
      "learning_rate": 1.2016867469879518e-05,
      "loss": 0.0419,
      "step": 33130
    },
    {
      "epoch": 3.9927710843373494,
      "grad_norm": 0.6323294043540955,
      "learning_rate": 1.2014457831325301e-05,
      "loss": 0.0619,
      "step": 33140
    },
    {
      "epoch": 3.9939759036144578,
      "grad_norm": 2.0028812885284424,
      "learning_rate": 1.2012048192771086e-05,
      "loss": 0.0284,
      "step": 33150
    },
    {
      "epoch": 3.995180722891566,
      "grad_norm": 0.017410529777407646,
      "learning_rate": 1.200963855421687e-05,
      "loss": 0.0209,
      "step": 33160
    },
    {
      "epoch": 3.9963855421686745,
      "grad_norm": 3.3150484561920166,
      "learning_rate": 1.2007228915662652e-05,
      "loss": 0.0374,
      "step": 33170
    },
    {
      "epoch": 3.9975903614457833,
      "grad_norm": 0.24115431308746338,
      "learning_rate": 1.2004819277108436e-05,
      "loss": 0.0576,
      "step": 33180
    },
    {
      "epoch": 3.9987951807228916,
      "grad_norm": 0.5653519630432129,
      "learning_rate": 1.2002409638554217e-05,
      "loss": 0.0641,
      "step": 33190
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3062511682510376,
      "learning_rate": 1.2e-05,
      "loss": 0.1007,
      "step": 33200
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9824006374203225,
      "eval_f1": 0.9528946873235902,
      "eval_loss": 0.050814639776945114,
      "eval_precision": 0.9673968415690269,
      "eval_recall": 0.9388209121245829,
      "eval_runtime": 5020.7391,
      "eval_samples_per_second": 8.503,
      "eval_steps_per_second": 0.354,
      "step": 33200
    },
    {
      "epoch": 4.001204819277109,
      "grad_norm": 0.33299705386161804,
      "learning_rate": 1.1997590361445783e-05,
      "loss": 0.0278,
      "step": 33210
    },
    {
      "epoch": 4.002409638554217,
      "grad_norm": 0.05839214101433754,
      "learning_rate": 1.1995180722891567e-05,
      "loss": 0.046,
      "step": 33220
    },
    {
      "epoch": 4.0036144578313255,
      "grad_norm": 3.2983479499816895,
      "learning_rate": 1.1992771084337352e-05,
      "loss": 0.0326,
      "step": 33230
    },
    {
      "epoch": 4.004819277108433,
      "grad_norm": 2.88675594329834,
      "learning_rate": 1.1990361445783135e-05,
      "loss": 0.0461,
      "step": 33240
    },
    {
      "epoch": 4.006024096385542,
      "grad_norm": 0.9298921823501587,
      "learning_rate": 1.1987951807228916e-05,
      "loss": 0.0395,
      "step": 33250
    },
    {
      "epoch": 4.00722891566265,
      "grad_norm": 0.02295425720512867,
      "learning_rate": 1.19855421686747e-05,
      "loss": 0.016,
      "step": 33260
    },
    {
      "epoch": 4.008433734939759,
      "grad_norm": 0.3603512942790985,
      "learning_rate": 1.1983132530120483e-05,
      "loss": 0.0119,
      "step": 33270
    },
    {
      "epoch": 4.009638554216868,
      "grad_norm": 0.01810535229742527,
      "learning_rate": 1.1980722891566266e-05,
      "loss": 0.0231,
      "step": 33280
    },
    {
      "epoch": 4.010843373493976,
      "grad_norm": 0.03973805531859398,
      "learning_rate": 1.1978313253012049e-05,
      "loss": 0.1151,
      "step": 33290
    },
    {
      "epoch": 4.0120481927710845,
      "grad_norm": 18.864744186401367,
      "learning_rate": 1.1975903614457834e-05,
      "loss": 0.0689,
      "step": 33300
    },
    {
      "epoch": 4.013253012048192,
      "grad_norm": 5.062955379486084,
      "learning_rate": 1.1973493975903617e-05,
      "loss": 0.0434,
      "step": 33310
    },
    {
      "epoch": 4.014457831325301,
      "grad_norm": 0.03270383179187775,
      "learning_rate": 1.1971084337349398e-05,
      "loss": 0.0345,
      "step": 33320
    },
    {
      "epoch": 4.01566265060241,
      "grad_norm": 0.7107706069946289,
      "learning_rate": 1.1968674698795182e-05,
      "loss": 0.0106,
      "step": 33330
    },
    {
      "epoch": 4.016867469879518,
      "grad_norm": 0.004909846931695938,
      "learning_rate": 1.1966265060240965e-05,
      "loss": 0.0651,
      "step": 33340
    },
    {
      "epoch": 4.018072289156627,
      "grad_norm": 0.28377699851989746,
      "learning_rate": 1.1963855421686748e-05,
      "loss": 0.0348,
      "step": 33350
    },
    {
      "epoch": 4.019277108433735,
      "grad_norm": 4.882928371429443,
      "learning_rate": 1.1961445783132531e-05,
      "loss": 0.075,
      "step": 33360
    },
    {
      "epoch": 4.0204819277108435,
      "grad_norm": 0.01760687120258808,
      "learning_rate": 1.1959036144578313e-05,
      "loss": 0.0256,
      "step": 33370
    },
    {
      "epoch": 4.021686746987951,
      "grad_norm": 2.0064504146575928,
      "learning_rate": 1.1956626506024097e-05,
      "loss": 0.0198,
      "step": 33380
    },
    {
      "epoch": 4.02289156626506,
      "grad_norm": 0.031185049563646317,
      "learning_rate": 1.195421686746988e-05,
      "loss": 0.026,
      "step": 33390
    },
    {
      "epoch": 4.024096385542169,
      "grad_norm": 0.013273520395159721,
      "learning_rate": 1.1951807228915664e-05,
      "loss": 0.0201,
      "step": 33400
    },
    {
      "epoch": 4.025301204819277,
      "grad_norm": 3.7953357696533203,
      "learning_rate": 1.1949397590361447e-05,
      "loss": 0.032,
      "step": 33410
    },
    {
      "epoch": 4.026506024096386,
      "grad_norm": 0.10478893667459488,
      "learning_rate": 1.194698795180723e-05,
      "loss": 0.0437,
      "step": 33420
    },
    {
      "epoch": 4.027710843373494,
      "grad_norm": 6.079810619354248,
      "learning_rate": 1.1944578313253012e-05,
      "loss": 0.0458,
      "step": 33430
    },
    {
      "epoch": 4.028915662650602,
      "grad_norm": 0.08326464146375656,
      "learning_rate": 1.1942168674698795e-05,
      "loss": 0.038,
      "step": 33440
    },
    {
      "epoch": 4.030120481927711,
      "grad_norm": 2.7298452854156494,
      "learning_rate": 1.193975903614458e-05,
      "loss": 0.0255,
      "step": 33450
    },
    {
      "epoch": 4.031325301204819,
      "grad_norm": 0.23105718195438385,
      "learning_rate": 1.1937349397590363e-05,
      "loss": 0.0405,
      "step": 33460
    },
    {
      "epoch": 4.032530120481928,
      "grad_norm": 2.7734923362731934,
      "learning_rate": 1.1934939759036146e-05,
      "loss": 0.0436,
      "step": 33470
    },
    {
      "epoch": 4.033734939759036,
      "grad_norm": 2.962648630142212,
      "learning_rate": 1.193253012048193e-05,
      "loss": 0.0412,
      "step": 33480
    },
    {
      "epoch": 4.034939759036145,
      "grad_norm": 1.1770780086517334,
      "learning_rate": 1.1930120481927712e-05,
      "loss": 0.0132,
      "step": 33490
    },
    {
      "epoch": 4.036144578313253,
      "grad_norm": 0.0282822847366333,
      "learning_rate": 1.1927710843373494e-05,
      "loss": 0.0437,
      "step": 33500
    },
    {
      "epoch": 4.037349397590361,
      "grad_norm": 0.3803544044494629,
      "learning_rate": 1.1925301204819277e-05,
      "loss": 0.0209,
      "step": 33510
    },
    {
      "epoch": 4.03855421686747,
      "grad_norm": 8.178814888000488,
      "learning_rate": 1.192289156626506e-05,
      "loss": 0.0424,
      "step": 33520
    },
    {
      "epoch": 4.039759036144578,
      "grad_norm": 0.009286451153457165,
      "learning_rate": 1.1920481927710845e-05,
      "loss": 0.0365,
      "step": 33530
    },
    {
      "epoch": 4.040963855421687,
      "grad_norm": 0.005614785943180323,
      "learning_rate": 1.1918072289156628e-05,
      "loss": 0.0313,
      "step": 33540
    },
    {
      "epoch": 4.042168674698795,
      "grad_norm": 0.046356894075870514,
      "learning_rate": 1.1915662650602411e-05,
      "loss": 0.0597,
      "step": 33550
    },
    {
      "epoch": 4.043373493975904,
      "grad_norm": 1.7404488325119019,
      "learning_rate": 1.1913253012048193e-05,
      "loss": 0.0498,
      "step": 33560
    },
    {
      "epoch": 4.044578313253012,
      "grad_norm": 1.0309631824493408,
      "learning_rate": 1.1910843373493976e-05,
      "loss": 0.0641,
      "step": 33570
    },
    {
      "epoch": 4.04578313253012,
      "grad_norm": 3.3102176189422607,
      "learning_rate": 1.190843373493976e-05,
      "loss": 0.0375,
      "step": 33580
    },
    {
      "epoch": 4.046987951807229,
      "grad_norm": 0.15530087053775787,
      "learning_rate": 1.1906024096385542e-05,
      "loss": 0.0312,
      "step": 33590
    },
    {
      "epoch": 4.048192771084337,
      "grad_norm": 1.3064279556274414,
      "learning_rate": 1.1903614457831327e-05,
      "loss": 0.0407,
      "step": 33600
    },
    {
      "epoch": 4.049397590361446,
      "grad_norm": 0.5141127705574036,
      "learning_rate": 1.190120481927711e-05,
      "loss": 0.0363,
      "step": 33610
    },
    {
      "epoch": 4.050602409638554,
      "grad_norm": 6.670036315917969,
      "learning_rate": 1.1898795180722894e-05,
      "loss": 0.0299,
      "step": 33620
    },
    {
      "epoch": 4.051807228915663,
      "grad_norm": 0.05379921570420265,
      "learning_rate": 1.1896385542168675e-05,
      "loss": 0.0236,
      "step": 33630
    },
    {
      "epoch": 4.053012048192771,
      "grad_norm": 0.2843005955219269,
      "learning_rate": 1.1893975903614458e-05,
      "loss": 0.0167,
      "step": 33640
    },
    {
      "epoch": 4.054216867469879,
      "grad_norm": 0.00786387175321579,
      "learning_rate": 1.1891566265060242e-05,
      "loss": 0.0199,
      "step": 33650
    },
    {
      "epoch": 4.055421686746988,
      "grad_norm": 0.004143224097788334,
      "learning_rate": 1.1889156626506025e-05,
      "loss": 0.0172,
      "step": 33660
    },
    {
      "epoch": 4.056626506024096,
      "grad_norm": 0.0043449909426271915,
      "learning_rate": 1.1886746987951808e-05,
      "loss": 0.0015,
      "step": 33670
    },
    {
      "epoch": 4.057831325301205,
      "grad_norm": 0.0024103098548948765,
      "learning_rate": 1.1884337349397593e-05,
      "loss": 0.013,
      "step": 33680
    },
    {
      "epoch": 4.059036144578314,
      "grad_norm": 1.2825701236724854,
      "learning_rate": 1.1881927710843374e-05,
      "loss": 0.0456,
      "step": 33690
    },
    {
      "epoch": 4.0602409638554215,
      "grad_norm": 0.2062496840953827,
      "learning_rate": 1.1879518072289157e-05,
      "loss": 0.0563,
      "step": 33700
    },
    {
      "epoch": 4.06144578313253,
      "grad_norm": 5.544110298156738,
      "learning_rate": 1.187710843373494e-05,
      "loss": 0.042,
      "step": 33710
    },
    {
      "epoch": 4.062650602409638,
      "grad_norm": 0.1895754635334015,
      "learning_rate": 1.1874698795180724e-05,
      "loss": 0.0211,
      "step": 33720
    },
    {
      "epoch": 4.063855421686747,
      "grad_norm": 0.006494319997727871,
      "learning_rate": 1.1872289156626507e-05,
      "loss": 0.014,
      "step": 33730
    },
    {
      "epoch": 4.065060240963855,
      "grad_norm": 0.005501506384462118,
      "learning_rate": 1.1869879518072288e-05,
      "loss": 0.1001,
      "step": 33740
    },
    {
      "epoch": 4.066265060240964,
      "grad_norm": 1.93011474609375,
      "learning_rate": 1.1867469879518075e-05,
      "loss": 0.0094,
      "step": 33750
    },
    {
      "epoch": 4.067469879518073,
      "grad_norm": 0.03039807640016079,
      "learning_rate": 1.1865060240963856e-05,
      "loss": 0.022,
      "step": 33760
    },
    {
      "epoch": 4.0686746987951805,
      "grad_norm": 1.1603333950042725,
      "learning_rate": 1.186265060240964e-05,
      "loss": 0.0585,
      "step": 33770
    },
    {
      "epoch": 4.069879518072289,
      "grad_norm": 0.04212618246674538,
      "learning_rate": 1.1860240963855423e-05,
      "loss": 0.0299,
      "step": 33780
    },
    {
      "epoch": 4.071084337349397,
      "grad_norm": 0.006608272437006235,
      "learning_rate": 1.1857831325301206e-05,
      "loss": 0.0062,
      "step": 33790
    },
    {
      "epoch": 4.072289156626506,
      "grad_norm": 0.46620655059814453,
      "learning_rate": 1.185542168674699e-05,
      "loss": 0.039,
      "step": 33800
    },
    {
      "epoch": 4.073493975903615,
      "grad_norm": 0.005734328646212816,
      "learning_rate": 1.185301204819277e-05,
      "loss": 0.0282,
      "step": 33810
    },
    {
      "epoch": 4.074698795180723,
      "grad_norm": 2.1913645267486572,
      "learning_rate": 1.1850602409638554e-05,
      "loss": 0.0935,
      "step": 33820
    },
    {
      "epoch": 4.075903614457832,
      "grad_norm": 0.02194174937903881,
      "learning_rate": 1.1848192771084339e-05,
      "loss": 0.0092,
      "step": 33830
    },
    {
      "epoch": 4.0771084337349395,
      "grad_norm": 0.23740091919898987,
      "learning_rate": 1.1845783132530122e-05,
      "loss": 0.0675,
      "step": 33840
    },
    {
      "epoch": 4.078313253012048,
      "grad_norm": 0.10195909440517426,
      "learning_rate": 1.1843373493975905e-05,
      "loss": 0.0037,
      "step": 33850
    },
    {
      "epoch": 4.079518072289156,
      "grad_norm": 10.150806427001953,
      "learning_rate": 1.1840963855421688e-05,
      "loss": 0.0281,
      "step": 33860
    },
    {
      "epoch": 4.080722891566265,
      "grad_norm": 0.0038624941371381283,
      "learning_rate": 1.183855421686747e-05,
      "loss": 0.0077,
      "step": 33870
    },
    {
      "epoch": 4.081927710843374,
      "grad_norm": 0.006553497165441513,
      "learning_rate": 1.1836144578313253e-05,
      "loss": 0.0344,
      "step": 33880
    },
    {
      "epoch": 4.083132530120482,
      "grad_norm": 0.27212509512901306,
      "learning_rate": 1.1833734939759036e-05,
      "loss": 0.0359,
      "step": 33890
    },
    {
      "epoch": 4.0843373493975905,
      "grad_norm": 0.05601014941930771,
      "learning_rate": 1.1831325301204821e-05,
      "loss": 0.033,
      "step": 33900
    },
    {
      "epoch": 4.085542168674698,
      "grad_norm": 1.9528234004974365,
      "learning_rate": 1.1828915662650604e-05,
      "loss": 0.0127,
      "step": 33910
    },
    {
      "epoch": 4.086746987951807,
      "grad_norm": 0.003352757543325424,
      "learning_rate": 1.1826506024096387e-05,
      "loss": 0.043,
      "step": 33920
    },
    {
      "epoch": 4.087951807228916,
      "grad_norm": 1.476790428161621,
      "learning_rate": 1.182409638554217e-05,
      "loss": 0.0172,
      "step": 33930
    },
    {
      "epoch": 4.089156626506024,
      "grad_norm": 6.750940322875977,
      "learning_rate": 1.1821686746987952e-05,
      "loss": 0.0656,
      "step": 33940
    },
    {
      "epoch": 4.090361445783133,
      "grad_norm": 0.045780330896377563,
      "learning_rate": 1.1819277108433735e-05,
      "loss": 0.0159,
      "step": 33950
    },
    {
      "epoch": 4.091566265060241,
      "grad_norm": 0.04343307390809059,
      "learning_rate": 1.1816867469879518e-05,
      "loss": 0.0461,
      "step": 33960
    },
    {
      "epoch": 4.0927710843373495,
      "grad_norm": 0.20642942190170288,
      "learning_rate": 1.1814457831325301e-05,
      "loss": 0.033,
      "step": 33970
    },
    {
      "epoch": 4.093975903614457,
      "grad_norm": 1.6301581859588623,
      "learning_rate": 1.1812048192771086e-05,
      "loss": 0.0371,
      "step": 33980
    },
    {
      "epoch": 4.095180722891566,
      "grad_norm": 0.04251353070139885,
      "learning_rate": 1.180963855421687e-05,
      "loss": 0.0553,
      "step": 33990
    },
    {
      "epoch": 4.096385542168675,
      "grad_norm": 1.843674659729004,
      "learning_rate": 1.1807228915662651e-05,
      "loss": 0.0167,
      "step": 34000
    },
    {
      "epoch": 4.097590361445783,
      "grad_norm": 0.03076782450079918,
      "learning_rate": 1.1804819277108434e-05,
      "loss": 0.0815,
      "step": 34010
    },
    {
      "epoch": 4.098795180722892,
      "grad_norm": 0.48127466440200806,
      "learning_rate": 1.1802409638554217e-05,
      "loss": 0.0225,
      "step": 34020
    },
    {
      "epoch": 4.1,
      "grad_norm": 6.008005619049072,
      "learning_rate": 1.18e-05,
      "loss": 0.0274,
      "step": 34030
    },
    {
      "epoch": 4.1012048192771084,
      "grad_norm": 0.02467150054872036,
      "learning_rate": 1.1797590361445784e-05,
      "loss": 0.0717,
      "step": 34040
    },
    {
      "epoch": 4.102409638554217,
      "grad_norm": 0.49772271513938904,
      "learning_rate": 1.1795180722891569e-05,
      "loss": 0.0531,
      "step": 34050
    },
    {
      "epoch": 4.103614457831325,
      "grad_norm": 2.380798578262329,
      "learning_rate": 1.1792771084337352e-05,
      "loss": 0.0393,
      "step": 34060
    },
    {
      "epoch": 4.104819277108434,
      "grad_norm": 7.710791110992432,
      "learning_rate": 1.1790361445783133e-05,
      "loss": 0.0417,
      "step": 34070
    },
    {
      "epoch": 4.106024096385542,
      "grad_norm": 0.06719467043876648,
      "learning_rate": 1.1787951807228916e-05,
      "loss": 0.0455,
      "step": 34080
    },
    {
      "epoch": 4.107228915662651,
      "grad_norm": 1.579750418663025,
      "learning_rate": 1.17855421686747e-05,
      "loss": 0.0689,
      "step": 34090
    },
    {
      "epoch": 4.108433734939759,
      "grad_norm": 2.7645859718322754,
      "learning_rate": 1.1783132530120483e-05,
      "loss": 0.0589,
      "step": 34100
    },
    {
      "epoch": 4.109638554216867,
      "grad_norm": 0.14438830316066742,
      "learning_rate": 1.1780722891566266e-05,
      "loss": 0.0462,
      "step": 34110
    },
    {
      "epoch": 4.110843373493976,
      "grad_norm": 0.14489181339740753,
      "learning_rate": 1.1778313253012047e-05,
      "loss": 0.014,
      "step": 34120
    },
    {
      "epoch": 4.112048192771084,
      "grad_norm": 0.2337266057729721,
      "learning_rate": 1.1775903614457834e-05,
      "loss": 0.0418,
      "step": 34130
    },
    {
      "epoch": 4.113253012048193,
      "grad_norm": 3.071563243865967,
      "learning_rate": 1.1773493975903615e-05,
      "loss": 0.1137,
      "step": 34140
    },
    {
      "epoch": 4.114457831325301,
      "grad_norm": 0.2917781174182892,
      "learning_rate": 1.1771084337349399e-05,
      "loss": 0.0167,
      "step": 34150
    },
    {
      "epoch": 4.11566265060241,
      "grad_norm": 1.5622258186340332,
      "learning_rate": 1.1768674698795182e-05,
      "loss": 0.0625,
      "step": 34160
    },
    {
      "epoch": 4.1168674698795185,
      "grad_norm": 0.6370660662651062,
      "learning_rate": 1.1766265060240965e-05,
      "loss": 0.0107,
      "step": 34170
    },
    {
      "epoch": 4.118072289156626,
      "grad_norm": 0.20729857683181763,
      "learning_rate": 1.1763855421686748e-05,
      "loss": 0.0148,
      "step": 34180
    },
    {
      "epoch": 4.119277108433735,
      "grad_norm": 0.06618524342775345,
      "learning_rate": 1.176144578313253e-05,
      "loss": 0.0209,
      "step": 34190
    },
    {
      "epoch": 4.120481927710843,
      "grad_norm": 10.26236343383789,
      "learning_rate": 1.1759036144578315e-05,
      "loss": 0.0319,
      "step": 34200
    },
    {
      "epoch": 4.121686746987952,
      "grad_norm": 2.1891205310821533,
      "learning_rate": 1.1756626506024098e-05,
      "loss": 0.0091,
      "step": 34210
    },
    {
      "epoch": 4.12289156626506,
      "grad_norm": 2.2388906478881836,
      "learning_rate": 1.1754216867469881e-05,
      "loss": 0.0117,
      "step": 34220
    },
    {
      "epoch": 4.124096385542169,
      "grad_norm": 0.25210845470428467,
      "learning_rate": 1.1751807228915664e-05,
      "loss": 0.0772,
      "step": 34230
    },
    {
      "epoch": 4.125301204819277,
      "grad_norm": 0.1348314732313156,
      "learning_rate": 1.1749397590361447e-05,
      "loss": 0.0489,
      "step": 34240
    },
    {
      "epoch": 4.126506024096385,
      "grad_norm": 0.009359823539853096,
      "learning_rate": 1.1746987951807229e-05,
      "loss": 0.0269,
      "step": 34250
    },
    {
      "epoch": 4.127710843373494,
      "grad_norm": 3.1189517974853516,
      "learning_rate": 1.1744578313253012e-05,
      "loss": 0.028,
      "step": 34260
    },
    {
      "epoch": 4.128915662650602,
      "grad_norm": 2.144608736038208,
      "learning_rate": 1.1742168674698795e-05,
      "loss": 0.0686,
      "step": 34270
    },
    {
      "epoch": 4.130120481927711,
      "grad_norm": 0.08158416301012039,
      "learning_rate": 1.173975903614458e-05,
      "loss": 0.0448,
      "step": 34280
    },
    {
      "epoch": 4.13132530120482,
      "grad_norm": 0.02370283752679825,
      "learning_rate": 1.1737349397590363e-05,
      "loss": 0.0372,
      "step": 34290
    },
    {
      "epoch": 4.132530120481928,
      "grad_norm": 0.49416106939315796,
      "learning_rate": 1.1734939759036146e-05,
      "loss": 0.0376,
      "step": 34300
    },
    {
      "epoch": 4.133734939759036,
      "grad_norm": 2.6023077964782715,
      "learning_rate": 1.173253012048193e-05,
      "loss": 0.0295,
      "step": 34310
    },
    {
      "epoch": 4.134939759036144,
      "grad_norm": 0.5232278108596802,
      "learning_rate": 1.1730120481927711e-05,
      "loss": 0.052,
      "step": 34320
    },
    {
      "epoch": 4.136144578313253,
      "grad_norm": 0.041101016104221344,
      "learning_rate": 1.1727710843373494e-05,
      "loss": 0.0015,
      "step": 34330
    },
    {
      "epoch": 4.137349397590361,
      "grad_norm": 0.024757444858551025,
      "learning_rate": 1.1725301204819277e-05,
      "loss": 0.0451,
      "step": 34340
    },
    {
      "epoch": 4.13855421686747,
      "grad_norm": 4.113788604736328,
      "learning_rate": 1.1722891566265062e-05,
      "loss": 0.0943,
      "step": 34350
    },
    {
      "epoch": 4.139759036144579,
      "grad_norm": 2.921433925628662,
      "learning_rate": 1.1720481927710845e-05,
      "loss": 0.0483,
      "step": 34360
    },
    {
      "epoch": 4.1409638554216865,
      "grad_norm": 0.21882416307926178,
      "learning_rate": 1.1718072289156629e-05,
      "loss": 0.0068,
      "step": 34370
    },
    {
      "epoch": 4.142168674698795,
      "grad_norm": 0.04517621546983719,
      "learning_rate": 1.171566265060241e-05,
      "loss": 0.0381,
      "step": 34380
    },
    {
      "epoch": 4.143373493975903,
      "grad_norm": 7.267587661743164,
      "learning_rate": 1.1713253012048193e-05,
      "loss": 0.0417,
      "step": 34390
    },
    {
      "epoch": 4.144578313253012,
      "grad_norm": 3.3522586822509766,
      "learning_rate": 1.1710843373493976e-05,
      "loss": 0.0419,
      "step": 34400
    },
    {
      "epoch": 4.145783132530121,
      "grad_norm": 0.13151668012142181,
      "learning_rate": 1.170843373493976e-05,
      "loss": 0.0266,
      "step": 34410
    },
    {
      "epoch": 4.146987951807229,
      "grad_norm": 5.2389092445373535,
      "learning_rate": 1.1706024096385543e-05,
      "loss": 0.0669,
      "step": 34420
    },
    {
      "epoch": 4.148192771084338,
      "grad_norm": 0.06183430552482605,
      "learning_rate": 1.1703614457831328e-05,
      "loss": 0.015,
      "step": 34430
    },
    {
      "epoch": 4.1493975903614455,
      "grad_norm": 0.12038160115480423,
      "learning_rate": 1.170120481927711e-05,
      "loss": 0.057,
      "step": 34440
    },
    {
      "epoch": 4.150602409638554,
      "grad_norm": 0.5814661383628845,
      "learning_rate": 1.1698795180722892e-05,
      "loss": 0.0353,
      "step": 34450
    },
    {
      "epoch": 4.151807228915662,
      "grad_norm": 3.836486577987671,
      "learning_rate": 1.1696385542168675e-05,
      "loss": 0.0949,
      "step": 34460
    },
    {
      "epoch": 4.153012048192771,
      "grad_norm": 0.07016213983297348,
      "learning_rate": 1.1693975903614459e-05,
      "loss": 0.0274,
      "step": 34470
    },
    {
      "epoch": 4.15421686746988,
      "grad_norm": 0.7296294569969177,
      "learning_rate": 1.1691566265060242e-05,
      "loss": 0.0296,
      "step": 34480
    },
    {
      "epoch": 4.155421686746988,
      "grad_norm": 0.0178529042750597,
      "learning_rate": 1.1689156626506025e-05,
      "loss": 0.0223,
      "step": 34490
    },
    {
      "epoch": 4.156626506024097,
      "grad_norm": 0.10275407135486603,
      "learning_rate": 1.168674698795181e-05,
      "loss": 0.0152,
      "step": 34500
    },
    {
      "epoch": 4.1578313253012045,
      "grad_norm": 0.0063494304195046425,
      "learning_rate": 1.1684337349397591e-05,
      "loss": 0.0148,
      "step": 34510
    },
    {
      "epoch": 4.159036144578313,
      "grad_norm": 0.02422485686838627,
      "learning_rate": 1.1681927710843374e-05,
      "loss": 0.0779,
      "step": 34520
    },
    {
      "epoch": 4.160240963855422,
      "grad_norm": 0.0035344669595360756,
      "learning_rate": 1.1679518072289158e-05,
      "loss": 0.0047,
      "step": 34530
    },
    {
      "epoch": 4.16144578313253,
      "grad_norm": 2.912324905395508,
      "learning_rate": 1.167710843373494e-05,
      "loss": 0.0329,
      "step": 34540
    },
    {
      "epoch": 4.162650602409639,
      "grad_norm": 6.026942253112793,
      "learning_rate": 1.1674698795180724e-05,
      "loss": 0.0396,
      "step": 34550
    },
    {
      "epoch": 4.163855421686747,
      "grad_norm": 1.9391241073608398,
      "learning_rate": 1.1672289156626505e-05,
      "loss": 0.0615,
      "step": 34560
    },
    {
      "epoch": 4.1650602409638555,
      "grad_norm": 0.0148329958319664,
      "learning_rate": 1.1669879518072289e-05,
      "loss": 0.0284,
      "step": 34570
    },
    {
      "epoch": 4.166265060240963,
      "grad_norm": 0.21027745306491852,
      "learning_rate": 1.1667469879518074e-05,
      "loss": 0.0389,
      "step": 34580
    },
    {
      "epoch": 4.167469879518072,
      "grad_norm": 0.12877590954303741,
      "learning_rate": 1.1665060240963857e-05,
      "loss": 0.0218,
      "step": 34590
    },
    {
      "epoch": 4.168674698795181,
      "grad_norm": 0.05795753747224808,
      "learning_rate": 1.166265060240964e-05,
      "loss": 0.0261,
      "step": 34600
    },
    {
      "epoch": 4.169879518072289,
      "grad_norm": 6.397010326385498,
      "learning_rate": 1.1660240963855423e-05,
      "loss": 0.0116,
      "step": 34610
    },
    {
      "epoch": 4.171084337349398,
      "grad_norm": 0.02419760450720787,
      "learning_rate": 1.1657831325301206e-05,
      "loss": 0.0198,
      "step": 34620
    },
    {
      "epoch": 4.172289156626506,
      "grad_norm": 6.650881290435791,
      "learning_rate": 1.1655421686746988e-05,
      "loss": 0.0491,
      "step": 34630
    },
    {
      "epoch": 4.1734939759036145,
      "grad_norm": 0.04739775136113167,
      "learning_rate": 1.1653012048192771e-05,
      "loss": 0.0654,
      "step": 34640
    },
    {
      "epoch": 4.174698795180723,
      "grad_norm": 0.021952880546450615,
      "learning_rate": 1.1650602409638556e-05,
      "loss": 0.0669,
      "step": 34650
    },
    {
      "epoch": 4.175903614457831,
      "grad_norm": 2.147116184234619,
      "learning_rate": 1.1648192771084339e-05,
      "loss": 0.0213,
      "step": 34660
    },
    {
      "epoch": 4.17710843373494,
      "grad_norm": 0.8307733535766602,
      "learning_rate": 1.1645783132530122e-05,
      "loss": 0.0286,
      "step": 34670
    },
    {
      "epoch": 4.178313253012048,
      "grad_norm": 1.6182862520217896,
      "learning_rate": 1.1643373493975905e-05,
      "loss": 0.0614,
      "step": 34680
    },
    {
      "epoch": 4.179518072289157,
      "grad_norm": 0.029451917856931686,
      "learning_rate": 1.1640963855421687e-05,
      "loss": 0.0533,
      "step": 34690
    },
    {
      "epoch": 4.180722891566265,
      "grad_norm": 0.019604060798883438,
      "learning_rate": 1.163855421686747e-05,
      "loss": 0.0209,
      "step": 34700
    },
    {
      "epoch": 4.1819277108433734,
      "grad_norm": 2.700146436691284,
      "learning_rate": 1.1636144578313253e-05,
      "loss": 0.1204,
      "step": 34710
    },
    {
      "epoch": 4.183132530120482,
      "grad_norm": 0.013177681714296341,
      "learning_rate": 1.1633734939759036e-05,
      "loss": 0.0154,
      "step": 34720
    },
    {
      "epoch": 4.18433734939759,
      "grad_norm": 0.04430808871984482,
      "learning_rate": 1.1631325301204821e-05,
      "loss": 0.0384,
      "step": 34730
    },
    {
      "epoch": 4.185542168674699,
      "grad_norm": 0.013351608999073505,
      "learning_rate": 1.1628915662650604e-05,
      "loss": 0.0475,
      "step": 34740
    },
    {
      "epoch": 4.186746987951807,
      "grad_norm": 0.39389804005622864,
      "learning_rate": 1.1626506024096388e-05,
      "loss": 0.0299,
      "step": 34750
    },
    {
      "epoch": 4.187951807228916,
      "grad_norm": 0.024312350898981094,
      "learning_rate": 1.1624096385542169e-05,
      "loss": 0.0223,
      "step": 34760
    },
    {
      "epoch": 4.1891566265060245,
      "grad_norm": 0.024352438747882843,
      "learning_rate": 1.1621686746987952e-05,
      "loss": 0.0188,
      "step": 34770
    },
    {
      "epoch": 4.190361445783132,
      "grad_norm": 0.007297488395124674,
      "learning_rate": 1.1619277108433735e-05,
      "loss": 0.0222,
      "step": 34780
    },
    {
      "epoch": 4.191566265060241,
      "grad_norm": 0.1632818877696991,
      "learning_rate": 1.1616867469879519e-05,
      "loss": 0.0147,
      "step": 34790
    },
    {
      "epoch": 4.192771084337349,
      "grad_norm": 0.782914936542511,
      "learning_rate": 1.1614457831325303e-05,
      "loss": 0.0734,
      "step": 34800
    },
    {
      "epoch": 4.193975903614458,
      "grad_norm": 0.056206393986940384,
      "learning_rate": 1.1612048192771087e-05,
      "loss": 0.0366,
      "step": 34810
    },
    {
      "epoch": 4.195180722891566,
      "grad_norm": 0.03267103433609009,
      "learning_rate": 1.1609638554216868e-05,
      "loss": 0.0443,
      "step": 34820
    },
    {
      "epoch": 4.196385542168675,
      "grad_norm": 12.13001537322998,
      "learning_rate": 1.1607228915662651e-05,
      "loss": 0.0761,
      "step": 34830
    },
    {
      "epoch": 4.1975903614457835,
      "grad_norm": 2.5967037677764893,
      "learning_rate": 1.1604819277108434e-05,
      "loss": 0.0526,
      "step": 34840
    },
    {
      "epoch": 4.198795180722891,
      "grad_norm": 1.3859220743179321,
      "learning_rate": 1.1602409638554218e-05,
      "loss": 0.0414,
      "step": 34850
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.6395647525787354,
      "learning_rate": 1.16e-05,
      "loss": 0.0457,
      "step": 34860
    },
    {
      "epoch": 4.201204819277108,
      "grad_norm": 0.6531895995140076,
      "learning_rate": 1.1597590361445782e-05,
      "loss": 0.0209,
      "step": 34870
    },
    {
      "epoch": 4.202409638554217,
      "grad_norm": 1.9895439147949219,
      "learning_rate": 1.1595180722891569e-05,
      "loss": 0.0285,
      "step": 34880
    },
    {
      "epoch": 4.203614457831326,
      "grad_norm": 2.011625051498413,
      "learning_rate": 1.159277108433735e-05,
      "loss": 0.0343,
      "step": 34890
    },
    {
      "epoch": 4.204819277108434,
      "grad_norm": 2.0286147594451904,
      "learning_rate": 1.1590361445783133e-05,
      "loss": 0.0276,
      "step": 34900
    },
    {
      "epoch": 4.206024096385542,
      "grad_norm": 0.3906313478946686,
      "learning_rate": 1.1587951807228917e-05,
      "loss": 0.0161,
      "step": 34910
    },
    {
      "epoch": 4.20722891566265,
      "grad_norm": 2.6428894996643066,
      "learning_rate": 1.15855421686747e-05,
      "loss": 0.0327,
      "step": 34920
    },
    {
      "epoch": 4.208433734939759,
      "grad_norm": 1.8228873014450073,
      "learning_rate": 1.1583132530120483e-05,
      "loss": 0.0207,
      "step": 34930
    },
    {
      "epoch": 4.209638554216867,
      "grad_norm": 2.514036178588867,
      "learning_rate": 1.1580722891566264e-05,
      "loss": 0.0537,
      "step": 34940
    },
    {
      "epoch": 4.210843373493976,
      "grad_norm": 1.0926892757415771,
      "learning_rate": 1.157831325301205e-05,
      "loss": 0.0027,
      "step": 34950
    },
    {
      "epoch": 4.212048192771085,
      "grad_norm": 0.01677386462688446,
      "learning_rate": 1.1575903614457833e-05,
      "loss": 0.0673,
      "step": 34960
    },
    {
      "epoch": 4.213253012048193,
      "grad_norm": 1.772929072380066,
      "learning_rate": 1.1573493975903616e-05,
      "loss": 0.026,
      "step": 34970
    },
    {
      "epoch": 4.214457831325301,
      "grad_norm": 0.041553884744644165,
      "learning_rate": 1.1571084337349399e-05,
      "loss": 0.0432,
      "step": 34980
    },
    {
      "epoch": 4.215662650602409,
      "grad_norm": 0.047403521835803986,
      "learning_rate": 1.1568674698795182e-05,
      "loss": 0.0297,
      "step": 34990
    },
    {
      "epoch": 4.216867469879518,
      "grad_norm": 0.4525667428970337,
      "learning_rate": 1.1566265060240964e-05,
      "loss": 0.0213,
      "step": 35000
    },
    {
      "epoch": 4.218072289156627,
      "grad_norm": 0.01586133986711502,
      "learning_rate": 1.1563855421686747e-05,
      "loss": 0.0187,
      "step": 35010
    },
    {
      "epoch": 4.219277108433735,
      "grad_norm": 0.029206018894910812,
      "learning_rate": 1.156144578313253e-05,
      "loss": 0.0554,
      "step": 35020
    },
    {
      "epoch": 4.220481927710844,
      "grad_norm": 0.3225439786911011,
      "learning_rate": 1.1559036144578315e-05,
      "loss": 0.0453,
      "step": 35030
    },
    {
      "epoch": 4.2216867469879515,
      "grad_norm": 0.6362429261207581,
      "learning_rate": 1.1556626506024098e-05,
      "loss": 0.0034,
      "step": 35040
    },
    {
      "epoch": 4.22289156626506,
      "grad_norm": 0.004826461896300316,
      "learning_rate": 1.1554216867469881e-05,
      "loss": 0.0022,
      "step": 35050
    },
    {
      "epoch": 4.224096385542168,
      "grad_norm": 3.0818450450897217,
      "learning_rate": 1.1551807228915664e-05,
      "loss": 0.0919,
      "step": 35060
    },
    {
      "epoch": 4.225301204819277,
      "grad_norm": 2.4948720932006836,
      "learning_rate": 1.1549397590361446e-05,
      "loss": 0.1447,
      "step": 35070
    },
    {
      "epoch": 4.226506024096386,
      "grad_norm": 0.11295514553785324,
      "learning_rate": 1.1546987951807229e-05,
      "loss": 0.028,
      "step": 35080
    },
    {
      "epoch": 4.227710843373494,
      "grad_norm": 0.07644713670015335,
      "learning_rate": 1.1544578313253012e-05,
      "loss": 0.1408,
      "step": 35090
    },
    {
      "epoch": 4.228915662650603,
      "grad_norm": 0.3032827377319336,
      "learning_rate": 1.1542168674698797e-05,
      "loss": 0.0316,
      "step": 35100
    },
    {
      "epoch": 4.2301204819277105,
      "grad_norm": 23.580774307250977,
      "learning_rate": 1.153975903614458e-05,
      "loss": 0.0331,
      "step": 35110
    },
    {
      "epoch": 4.231325301204819,
      "grad_norm": 22.26487159729004,
      "learning_rate": 1.1537349397590363e-05,
      "loss": 0.042,
      "step": 35120
    },
    {
      "epoch": 4.232530120481928,
      "grad_norm": 0.7949813008308411,
      "learning_rate": 1.1534939759036145e-05,
      "loss": 0.0249,
      "step": 35130
    },
    {
      "epoch": 4.233734939759036,
      "grad_norm": 0.2491377890110016,
      "learning_rate": 1.1532530120481928e-05,
      "loss": 0.0333,
      "step": 35140
    },
    {
      "epoch": 4.234939759036145,
      "grad_norm": 0.035215556621551514,
      "learning_rate": 1.1530120481927711e-05,
      "loss": 0.0134,
      "step": 35150
    },
    {
      "epoch": 4.236144578313253,
      "grad_norm": 0.031009700149297714,
      "learning_rate": 1.1527710843373494e-05,
      "loss": 0.0268,
      "step": 35160
    },
    {
      "epoch": 4.2373493975903616,
      "grad_norm": 1.49264657497406,
      "learning_rate": 1.1525301204819278e-05,
      "loss": 0.0153,
      "step": 35170
    },
    {
      "epoch": 4.2385542168674695,
      "grad_norm": 0.1921345740556717,
      "learning_rate": 1.1522891566265062e-05,
      "loss": 0.0883,
      "step": 35180
    },
    {
      "epoch": 4.239759036144578,
      "grad_norm": 0.1281435638666153,
      "learning_rate": 1.1520481927710846e-05,
      "loss": 0.0326,
      "step": 35190
    },
    {
      "epoch": 4.240963855421687,
      "grad_norm": 0.052226871252059937,
      "learning_rate": 1.1518072289156627e-05,
      "loss": 0.0267,
      "step": 35200
    },
    {
      "epoch": 4.242168674698795,
      "grad_norm": 6.80872106552124,
      "learning_rate": 1.151566265060241e-05,
      "loss": 0.0473,
      "step": 35210
    },
    {
      "epoch": 4.243373493975904,
      "grad_norm": 0.1281748265028,
      "learning_rate": 1.1513253012048193e-05,
      "loss": 0.0058,
      "step": 35220
    },
    {
      "epoch": 4.244578313253012,
      "grad_norm": 0.019864246249198914,
      "learning_rate": 1.1510843373493977e-05,
      "loss": 0.0639,
      "step": 35230
    },
    {
      "epoch": 4.2457831325301205,
      "grad_norm": 0.955753743648529,
      "learning_rate": 1.150843373493976e-05,
      "loss": 0.0744,
      "step": 35240
    },
    {
      "epoch": 4.246987951807229,
      "grad_norm": 0.22259573638439178,
      "learning_rate": 1.1506024096385545e-05,
      "loss": 0.0222,
      "step": 35250
    },
    {
      "epoch": 4.248192771084337,
      "grad_norm": 0.16594745218753815,
      "learning_rate": 1.1503614457831326e-05,
      "loss": 0.042,
      "step": 35260
    },
    {
      "epoch": 4.249397590361446,
      "grad_norm": 0.09228655695915222,
      "learning_rate": 1.150120481927711e-05,
      "loss": 0.0091,
      "step": 35270
    },
    {
      "epoch": 4.250602409638554,
      "grad_norm": 1.4387887716293335,
      "learning_rate": 1.1498795180722892e-05,
      "loss": 0.0723,
      "step": 35280
    },
    {
      "epoch": 4.251807228915663,
      "grad_norm": 1.944593071937561,
      "learning_rate": 1.1496385542168676e-05,
      "loss": 0.0212,
      "step": 35290
    },
    {
      "epoch": 4.253012048192771,
      "grad_norm": 0.0316564217209816,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 0.0353,
      "step": 35300
    },
    {
      "epoch": 4.2542168674698795,
      "grad_norm": 0.7045053243637085,
      "learning_rate": 1.149156626506024e-05,
      "loss": 0.0243,
      "step": 35310
    },
    {
      "epoch": 4.255421686746988,
      "grad_norm": 0.08711566776037216,
      "learning_rate": 1.1489156626506027e-05,
      "loss": 0.0287,
      "step": 35320
    },
    {
      "epoch": 4.256626506024096,
      "grad_norm": 0.007401738781481981,
      "learning_rate": 1.1486746987951808e-05,
      "loss": 0.0125,
      "step": 35330
    },
    {
      "epoch": 4.257831325301205,
      "grad_norm": 2.465564489364624,
      "learning_rate": 1.1484337349397592e-05,
      "loss": 0.0515,
      "step": 35340
    },
    {
      "epoch": 4.259036144578313,
      "grad_norm": 0.3953085243701935,
      "learning_rate": 1.1481927710843375e-05,
      "loss": 0.0197,
      "step": 35350
    },
    {
      "epoch": 4.260240963855422,
      "grad_norm": 3.8101589679718018,
      "learning_rate": 1.1479518072289158e-05,
      "loss": 0.0831,
      "step": 35360
    },
    {
      "epoch": 4.2614457831325305,
      "grad_norm": 2.2271080017089844,
      "learning_rate": 1.1477108433734941e-05,
      "loss": 0.0406,
      "step": 35370
    },
    {
      "epoch": 4.2626506024096384,
      "grad_norm": 1.463362693786621,
      "learning_rate": 1.1474698795180723e-05,
      "loss": 0.018,
      "step": 35380
    },
    {
      "epoch": 4.263855421686747,
      "grad_norm": 1.5806989669799805,
      "learning_rate": 1.1472289156626506e-05,
      "loss": 0.0077,
      "step": 35390
    },
    {
      "epoch": 4.265060240963855,
      "grad_norm": 0.0075737303122878075,
      "learning_rate": 1.146987951807229e-05,
      "loss": 0.0414,
      "step": 35400
    },
    {
      "epoch": 4.266265060240964,
      "grad_norm": 0.016893502324819565,
      "learning_rate": 1.1467469879518074e-05,
      "loss": 0.0355,
      "step": 35410
    },
    {
      "epoch": 4.267469879518072,
      "grad_norm": 0.034880153834819794,
      "learning_rate": 1.1465060240963857e-05,
      "loss": 0.0228,
      "step": 35420
    },
    {
      "epoch": 4.268674698795181,
      "grad_norm": 0.05183454602956772,
      "learning_rate": 1.146265060240964e-05,
      "loss": 0.0179,
      "step": 35430
    },
    {
      "epoch": 4.2698795180722895,
      "grad_norm": 1.2856156826019287,
      "learning_rate": 1.1460240963855422e-05,
      "loss": 0.027,
      "step": 35440
    },
    {
      "epoch": 4.271084337349397,
      "grad_norm": 0.13881877064704895,
      "learning_rate": 1.1457831325301205e-05,
      "loss": 0.0361,
      "step": 35450
    },
    {
      "epoch": 4.272289156626506,
      "grad_norm": 1.5407354831695557,
      "learning_rate": 1.1455421686746988e-05,
      "loss": 0.0792,
      "step": 35460
    },
    {
      "epoch": 4.273493975903614,
      "grad_norm": 0.03051663003861904,
      "learning_rate": 1.1453012048192773e-05,
      "loss": 0.0059,
      "step": 35470
    },
    {
      "epoch": 4.274698795180723,
      "grad_norm": 0.08399159461259842,
      "learning_rate": 1.1450602409638556e-05,
      "loss": 0.0357,
      "step": 35480
    },
    {
      "epoch": 4.275903614457832,
      "grad_norm": 0.03905019909143448,
      "learning_rate": 1.1448192771084339e-05,
      "loss": 0.0693,
      "step": 35490
    },
    {
      "epoch": 4.27710843373494,
      "grad_norm": 0.007561404723674059,
      "learning_rate": 1.1445783132530122e-05,
      "loss": 0.0255,
      "step": 35500
    },
    {
      "epoch": 4.2783132530120485,
      "grad_norm": 12.531452178955078,
      "learning_rate": 1.1443373493975904e-05,
      "loss": 0.0504,
      "step": 35510
    },
    {
      "epoch": 4.279518072289156,
      "grad_norm": 0.02762461081147194,
      "learning_rate": 1.1440963855421687e-05,
      "loss": 0.0319,
      "step": 35520
    },
    {
      "epoch": 4.280722891566265,
      "grad_norm": 1.7602348327636719,
      "learning_rate": 1.143855421686747e-05,
      "loss": 0.0612,
      "step": 35530
    },
    {
      "epoch": 4.281927710843373,
      "grad_norm": 1.523000717163086,
      "learning_rate": 1.1436144578313253e-05,
      "loss": 0.0446,
      "step": 35540
    },
    {
      "epoch": 4.283132530120482,
      "grad_norm": 0.029973771423101425,
      "learning_rate": 1.1433734939759038e-05,
      "loss": 0.0159,
      "step": 35550
    },
    {
      "epoch": 4.284337349397591,
      "grad_norm": 0.01947317272424698,
      "learning_rate": 1.1431325301204821e-05,
      "loss": 0.0029,
      "step": 35560
    },
    {
      "epoch": 4.285542168674699,
      "grad_norm": 0.09864387661218643,
      "learning_rate": 1.1428915662650605e-05,
      "loss": 0.0307,
      "step": 35570
    },
    {
      "epoch": 4.286746987951807,
      "grad_norm": 1.548850655555725,
      "learning_rate": 1.1426506024096386e-05,
      "loss": 0.0997,
      "step": 35580
    },
    {
      "epoch": 4.287951807228915,
      "grad_norm": 0.07992888242006302,
      "learning_rate": 1.142409638554217e-05,
      "loss": 0.0299,
      "step": 35590
    },
    {
      "epoch": 4.289156626506024,
      "grad_norm": 0.03990499675273895,
      "learning_rate": 1.1421686746987952e-05,
      "loss": 0.0056,
      "step": 35600
    },
    {
      "epoch": 4.290361445783133,
      "grad_norm": 2.694766044616699,
      "learning_rate": 1.1419277108433736e-05,
      "loss": 0.0586,
      "step": 35610
    },
    {
      "epoch": 4.291566265060241,
      "grad_norm": 0.12448479980230331,
      "learning_rate": 1.141686746987952e-05,
      "loss": 0.0378,
      "step": 35620
    },
    {
      "epoch": 4.29277108433735,
      "grad_norm": 0.020445378497242928,
      "learning_rate": 1.1414457831325304e-05,
      "loss": 0.0408,
      "step": 35630
    },
    {
      "epoch": 4.293975903614458,
      "grad_norm": 0.00830586813390255,
      "learning_rate": 1.1412048192771085e-05,
      "loss": 0.0627,
      "step": 35640
    },
    {
      "epoch": 4.295180722891566,
      "grad_norm": 0.024511035531759262,
      "learning_rate": 1.1409638554216868e-05,
      "loss": 0.0371,
      "step": 35650
    },
    {
      "epoch": 4.296385542168674,
      "grad_norm": 0.9126567840576172,
      "learning_rate": 1.1407228915662651e-05,
      "loss": 0.0459,
      "step": 35660
    },
    {
      "epoch": 4.297590361445783,
      "grad_norm": 0.1081368699669838,
      "learning_rate": 1.1404819277108435e-05,
      "loss": 0.0296,
      "step": 35670
    },
    {
      "epoch": 4.298795180722892,
      "grad_norm": 0.0948498398065567,
      "learning_rate": 1.1402409638554218e-05,
      "loss": 0.0094,
      "step": 35680
    },
    {
      "epoch": 4.3,
      "grad_norm": 5.661877155303955,
      "learning_rate": 1.14e-05,
      "loss": 0.1017,
      "step": 35690
    },
    {
      "epoch": 4.301204819277109,
      "grad_norm": 0.9735411405563354,
      "learning_rate": 1.1397590361445786e-05,
      "loss": 0.0136,
      "step": 35700
    },
    {
      "epoch": 4.3024096385542165,
      "grad_norm": 0.41100677847862244,
      "learning_rate": 1.1395180722891567e-05,
      "loss": 0.0364,
      "step": 35710
    },
    {
      "epoch": 4.303614457831325,
      "grad_norm": 1.5402408838272095,
      "learning_rate": 1.139277108433735e-05,
      "loss": 0.0465,
      "step": 35720
    },
    {
      "epoch": 4.304819277108434,
      "grad_norm": 0.9688615798950195,
      "learning_rate": 1.1390361445783134e-05,
      "loss": 0.0521,
      "step": 35730
    },
    {
      "epoch": 4.306024096385542,
      "grad_norm": 0.6794525384902954,
      "learning_rate": 1.1387951807228917e-05,
      "loss": 0.0222,
      "step": 35740
    },
    {
      "epoch": 4.307228915662651,
      "grad_norm": 1.619186520576477,
      "learning_rate": 1.13855421686747e-05,
      "loss": 0.0333,
      "step": 35750
    },
    {
      "epoch": 4.308433734939759,
      "grad_norm": 0.06702660769224167,
      "learning_rate": 1.1383132530120482e-05,
      "loss": 0.0236,
      "step": 35760
    },
    {
      "epoch": 4.309638554216868,
      "grad_norm": 3.2316019535064697,
      "learning_rate": 1.1380722891566266e-05,
      "loss": 0.0439,
      "step": 35770
    },
    {
      "epoch": 4.3108433734939755,
      "grad_norm": 0.08667787164449692,
      "learning_rate": 1.137831325301205e-05,
      "loss": 0.05,
      "step": 35780
    },
    {
      "epoch": 4.312048192771084,
      "grad_norm": 0.23411428928375244,
      "learning_rate": 1.1375903614457833e-05,
      "loss": 0.007,
      "step": 35790
    },
    {
      "epoch": 4.313253012048193,
      "grad_norm": 0.012614530511200428,
      "learning_rate": 1.1373493975903616e-05,
      "loss": 0.033,
      "step": 35800
    },
    {
      "epoch": 4.314457831325301,
      "grad_norm": 0.01168062910437584,
      "learning_rate": 1.1371084337349399e-05,
      "loss": 0.0205,
      "step": 35810
    },
    {
      "epoch": 4.31566265060241,
      "grad_norm": 0.14062608778476715,
      "learning_rate": 1.136867469879518e-05,
      "loss": 0.0168,
      "step": 35820
    },
    {
      "epoch": 4.316867469879518,
      "grad_norm": 1.4399361610412598,
      "learning_rate": 1.1366265060240964e-05,
      "loss": 0.0234,
      "step": 35830
    },
    {
      "epoch": 4.3180722891566266,
      "grad_norm": 0.16526558995246887,
      "learning_rate": 1.1363855421686747e-05,
      "loss": 0.0369,
      "step": 35840
    },
    {
      "epoch": 4.3192771084337345,
      "grad_norm": 0.011743471957743168,
      "learning_rate": 1.1361445783132532e-05,
      "loss": 0.0805,
      "step": 35850
    },
    {
      "epoch": 4.320481927710843,
      "grad_norm": 2.356337070465088,
      "learning_rate": 1.1359036144578315e-05,
      "loss": 0.0353,
      "step": 35860
    },
    {
      "epoch": 4.321686746987952,
      "grad_norm": 0.02471837028861046,
      "learning_rate": 1.1356626506024098e-05,
      "loss": 0.0596,
      "step": 35870
    },
    {
      "epoch": 4.32289156626506,
      "grad_norm": 25.3900089263916,
      "learning_rate": 1.1354216867469881e-05,
      "loss": 0.0609,
      "step": 35880
    },
    {
      "epoch": 4.324096385542169,
      "grad_norm": 0.8700960874557495,
      "learning_rate": 1.1351807228915663e-05,
      "loss": 0.0176,
      "step": 35890
    },
    {
      "epoch": 4.325301204819277,
      "grad_norm": 0.20148499310016632,
      "learning_rate": 1.1349397590361446e-05,
      "loss": 0.017,
      "step": 35900
    },
    {
      "epoch": 4.3265060240963855,
      "grad_norm": 0.0073554785922169685,
      "learning_rate": 1.1346987951807229e-05,
      "loss": 0.0396,
      "step": 35910
    },
    {
      "epoch": 4.327710843373494,
      "grad_norm": 0.0027175291907042265,
      "learning_rate": 1.1344578313253014e-05,
      "loss": 0.067,
      "step": 35920
    },
    {
      "epoch": 4.328915662650602,
      "grad_norm": 12.2936429977417,
      "learning_rate": 1.1342168674698797e-05,
      "loss": 0.0343,
      "step": 35930
    },
    {
      "epoch": 4.330120481927711,
      "grad_norm": 7.429698467254639,
      "learning_rate": 1.133975903614458e-05,
      "loss": 0.0361,
      "step": 35940
    },
    {
      "epoch": 4.331325301204819,
      "grad_norm": 1.1718363761901855,
      "learning_rate": 1.1337349397590362e-05,
      "loss": 0.0583,
      "step": 35950
    },
    {
      "epoch": 4.332530120481928,
      "grad_norm": 0.14329202473163605,
      "learning_rate": 1.1334939759036145e-05,
      "loss": 0.0381,
      "step": 35960
    },
    {
      "epoch": 4.333734939759037,
      "grad_norm": 0.15436869859695435,
      "learning_rate": 1.1332530120481928e-05,
      "loss": 0.008,
      "step": 35970
    },
    {
      "epoch": 4.3349397590361445,
      "grad_norm": 2.4645557403564453,
      "learning_rate": 1.1330120481927711e-05,
      "loss": 0.0428,
      "step": 35980
    },
    {
      "epoch": 4.336144578313253,
      "grad_norm": 6.410980224609375,
      "learning_rate": 1.1327710843373495e-05,
      "loss": 0.0285,
      "step": 35990
    },
    {
      "epoch": 4.337349397590361,
      "grad_norm": 0.20806869864463806,
      "learning_rate": 1.132530120481928e-05,
      "loss": 0.0402,
      "step": 36000
    },
    {
      "epoch": 4.33855421686747,
      "grad_norm": 0.013198030181229115,
      "learning_rate": 1.1322891566265063e-05,
      "loss": 0.0239,
      "step": 36010
    },
    {
      "epoch": 4.339759036144578,
      "grad_norm": 0.06599025428295135,
      "learning_rate": 1.1320481927710844e-05,
      "loss": 0.0413,
      "step": 36020
    },
    {
      "epoch": 4.340963855421687,
      "grad_norm": 7.1878862380981445,
      "learning_rate": 1.1318072289156627e-05,
      "loss": 0.017,
      "step": 36030
    },
    {
      "epoch": 4.3421686746987955,
      "grad_norm": 2.826817750930786,
      "learning_rate": 1.131566265060241e-05,
      "loss": 0.1244,
      "step": 36040
    },
    {
      "epoch": 4.343373493975903,
      "grad_norm": 0.07565639168024063,
      "learning_rate": 1.1313253012048194e-05,
      "loss": 0.0331,
      "step": 36050
    },
    {
      "epoch": 4.344578313253012,
      "grad_norm": 0.5475121140480042,
      "learning_rate": 1.1310843373493977e-05,
      "loss": 0.0524,
      "step": 36060
    },
    {
      "epoch": 4.34578313253012,
      "grad_norm": 4.438477516174316,
      "learning_rate": 1.1308433734939762e-05,
      "loss": 0.0277,
      "step": 36070
    },
    {
      "epoch": 4.346987951807229,
      "grad_norm": 8.070080757141113,
      "learning_rate": 1.1306024096385543e-05,
      "loss": 0.0622,
      "step": 36080
    },
    {
      "epoch": 4.348192771084337,
      "grad_norm": 3.238508939743042,
      "learning_rate": 1.1303614457831326e-05,
      "loss": 0.0504,
      "step": 36090
    },
    {
      "epoch": 4.349397590361446,
      "grad_norm": 0.6773087382316589,
      "learning_rate": 1.130120481927711e-05,
      "loss": 0.0067,
      "step": 36100
    },
    {
      "epoch": 4.3506024096385545,
      "grad_norm": 4.795936584472656,
      "learning_rate": 1.1298795180722893e-05,
      "loss": 0.0291,
      "step": 36110
    },
    {
      "epoch": 4.351807228915662,
      "grad_norm": 6.614035129547119,
      "learning_rate": 1.1296385542168676e-05,
      "loss": 0.0758,
      "step": 36120
    },
    {
      "epoch": 4.353012048192771,
      "grad_norm": 2.7271218299865723,
      "learning_rate": 1.1293975903614457e-05,
      "loss": 0.0556,
      "step": 36130
    },
    {
      "epoch": 4.354216867469879,
      "grad_norm": 0.1584957242012024,
      "learning_rate": 1.129156626506024e-05,
      "loss": 0.0185,
      "step": 36140
    },
    {
      "epoch": 4.355421686746988,
      "grad_norm": 0.5564175844192505,
      "learning_rate": 1.1289156626506025e-05,
      "loss": 0.0387,
      "step": 36150
    },
    {
      "epoch": 4.356626506024097,
      "grad_norm": 0.005289485678076744,
      "learning_rate": 1.1286746987951809e-05,
      "loss": 0.0264,
      "step": 36160
    },
    {
      "epoch": 4.357831325301205,
      "grad_norm": 1.1808273792266846,
      "learning_rate": 1.1284337349397592e-05,
      "loss": 0.0286,
      "step": 36170
    },
    {
      "epoch": 4.3590361445783135,
      "grad_norm": 0.07091342657804489,
      "learning_rate": 1.1281927710843375e-05,
      "loss": 0.0548,
      "step": 36180
    },
    {
      "epoch": 4.360240963855421,
      "grad_norm": 0.01684872806072235,
      "learning_rate": 1.1279518072289158e-05,
      "loss": 0.01,
      "step": 36190
    },
    {
      "epoch": 4.36144578313253,
      "grad_norm": 2.2690675258636475,
      "learning_rate": 1.127710843373494e-05,
      "loss": 0.0584,
      "step": 36200
    },
    {
      "epoch": 4.362650602409639,
      "grad_norm": 0.005755518563091755,
      "learning_rate": 1.1274698795180723e-05,
      "loss": 0.0809,
      "step": 36210
    },
    {
      "epoch": 4.363855421686747,
      "grad_norm": 0.024498822167515755,
      "learning_rate": 1.1272289156626508e-05,
      "loss": 0.0228,
      "step": 36220
    },
    {
      "epoch": 4.365060240963856,
      "grad_norm": 6.366857528686523,
      "learning_rate": 1.126987951807229e-05,
      "loss": 0.0621,
      "step": 36230
    },
    {
      "epoch": 4.366265060240964,
      "grad_norm": 2.536431074142456,
      "learning_rate": 1.1267469879518074e-05,
      "loss": 0.0693,
      "step": 36240
    },
    {
      "epoch": 4.367469879518072,
      "grad_norm": 0.017884572967886925,
      "learning_rate": 1.1265060240963857e-05,
      "loss": 0.026,
      "step": 36250
    },
    {
      "epoch": 4.36867469879518,
      "grad_norm": 3.040174722671509,
      "learning_rate": 1.1262650602409639e-05,
      "loss": 0.0157,
      "step": 36260
    },
    {
      "epoch": 4.369879518072289,
      "grad_norm": 0.7200090885162354,
      "learning_rate": 1.1260240963855422e-05,
      "loss": 0.0555,
      "step": 36270
    },
    {
      "epoch": 4.371084337349398,
      "grad_norm": 0.6869416236877441,
      "learning_rate": 1.1257831325301205e-05,
      "loss": 0.0766,
      "step": 36280
    },
    {
      "epoch": 4.372289156626506,
      "grad_norm": 0.18696229159832,
      "learning_rate": 1.1255421686746988e-05,
      "loss": 0.0233,
      "step": 36290
    },
    {
      "epoch": 4.373493975903615,
      "grad_norm": 0.534855306148529,
      "learning_rate": 1.1253012048192773e-05,
      "loss": 0.0594,
      "step": 36300
    },
    {
      "epoch": 4.374698795180723,
      "grad_norm": 0.132496178150177,
      "learning_rate": 1.1250602409638556e-05,
      "loss": 0.0108,
      "step": 36310
    },
    {
      "epoch": 4.375903614457831,
      "grad_norm": 0.052985116839408875,
      "learning_rate": 1.124819277108434e-05,
      "loss": 0.0093,
      "step": 36320
    },
    {
      "epoch": 4.377108433734939,
      "grad_norm": 5.129452228546143,
      "learning_rate": 1.124578313253012e-05,
      "loss": 0.0494,
      "step": 36330
    },
    {
      "epoch": 4.378313253012048,
      "grad_norm": 0.20848068594932556,
      "learning_rate": 1.1243373493975904e-05,
      "loss": 0.0313,
      "step": 36340
    },
    {
      "epoch": 4.379518072289157,
      "grad_norm": 0.06301648169755936,
      "learning_rate": 1.1240963855421687e-05,
      "loss": 0.08,
      "step": 36350
    },
    {
      "epoch": 4.380722891566265,
      "grad_norm": 0.47483640909194946,
      "learning_rate": 1.123855421686747e-05,
      "loss": 0.0461,
      "step": 36360
    },
    {
      "epoch": 4.381927710843374,
      "grad_norm": 8.13309383392334,
      "learning_rate": 1.1236144578313255e-05,
      "loss": 0.0212,
      "step": 36370
    },
    {
      "epoch": 4.3831325301204815,
      "grad_norm": 25.33147621154785,
      "learning_rate": 1.1233734939759038e-05,
      "loss": 0.0615,
      "step": 36380
    },
    {
      "epoch": 4.38433734939759,
      "grad_norm": 0.023750733584165573,
      "learning_rate": 1.123132530120482e-05,
      "loss": 0.0323,
      "step": 36390
    },
    {
      "epoch": 4.385542168674699,
      "grad_norm": 0.1662137359380722,
      "learning_rate": 1.1228915662650603e-05,
      "loss": 0.0082,
      "step": 36400
    },
    {
      "epoch": 4.386746987951807,
      "grad_norm": 0.011035416275262833,
      "learning_rate": 1.1226506024096386e-05,
      "loss": 0.0625,
      "step": 36410
    },
    {
      "epoch": 4.387951807228916,
      "grad_norm": 0.5670291185379028,
      "learning_rate": 1.122409638554217e-05,
      "loss": 0.026,
      "step": 36420
    },
    {
      "epoch": 4.389156626506024,
      "grad_norm": 2.7456343173980713,
      "learning_rate": 1.1221686746987953e-05,
      "loss": 0.0461,
      "step": 36430
    },
    {
      "epoch": 4.390361445783133,
      "grad_norm": 7.22164249420166,
      "learning_rate": 1.1219277108433734e-05,
      "loss": 0.0243,
      "step": 36440
    },
    {
      "epoch": 4.391566265060241,
      "grad_norm": 0.029844729229807854,
      "learning_rate": 1.121686746987952e-05,
      "loss": 0.0251,
      "step": 36450
    },
    {
      "epoch": 4.392771084337349,
      "grad_norm": 0.09630735963582993,
      "learning_rate": 1.1214457831325302e-05,
      "loss": 0.02,
      "step": 36460
    },
    {
      "epoch": 4.393975903614458,
      "grad_norm": 0.0276335421949625,
      "learning_rate": 1.1212048192771085e-05,
      "loss": 0.0732,
      "step": 36470
    },
    {
      "epoch": 4.395180722891566,
      "grad_norm": 1.3364659547805786,
      "learning_rate": 1.1209638554216868e-05,
      "loss": 0.0562,
      "step": 36480
    },
    {
      "epoch": 4.396385542168675,
      "grad_norm": 5.016079425811768,
      "learning_rate": 1.1207228915662652e-05,
      "loss": 0.0392,
      "step": 36490
    },
    {
      "epoch": 4.397590361445783,
      "grad_norm": 0.08033552020788193,
      "learning_rate": 1.1204819277108435e-05,
      "loss": 0.0465,
      "step": 36500
    },
    {
      "epoch": 4.3987951807228916,
      "grad_norm": 7.245598793029785,
      "learning_rate": 1.1202409638554216e-05,
      "loss": 0.0462,
      "step": 36510
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.008256478235125542,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0101,
      "step": 36520
    },
    {
      "epoch": 4.401204819277108,
      "grad_norm": 0.05489540100097656,
      "learning_rate": 1.1197590361445784e-05,
      "loss": 0.0385,
      "step": 36530
    },
    {
      "epoch": 4.402409638554217,
      "grad_norm": 0.07913494855165482,
      "learning_rate": 1.1195180722891568e-05,
      "loss": 0.0686,
      "step": 36540
    },
    {
      "epoch": 4.403614457831325,
      "grad_norm": 1.4545842409133911,
      "learning_rate": 1.119277108433735e-05,
      "loss": 0.0761,
      "step": 36550
    },
    {
      "epoch": 4.404819277108434,
      "grad_norm": 2.437040090560913,
      "learning_rate": 1.1190361445783134e-05,
      "loss": 0.0588,
      "step": 36560
    },
    {
      "epoch": 4.406024096385542,
      "grad_norm": 1.0321338176727295,
      "learning_rate": 1.1187951807228915e-05,
      "loss": 0.0138,
      "step": 36570
    },
    {
      "epoch": 4.4072289156626505,
      "grad_norm": 0.11602160334587097,
      "learning_rate": 1.1185542168674699e-05,
      "loss": 0.0281,
      "step": 36580
    },
    {
      "epoch": 4.408433734939759,
      "grad_norm": 2.265288829803467,
      "learning_rate": 1.1183132530120482e-05,
      "loss": 0.0241,
      "step": 36590
    },
    {
      "epoch": 4.409638554216867,
      "grad_norm": 0.014694028533995152,
      "learning_rate": 1.1180722891566267e-05,
      "loss": 0.0639,
      "step": 36600
    },
    {
      "epoch": 4.410843373493976,
      "grad_norm": 0.08951660245656967,
      "learning_rate": 1.117831325301205e-05,
      "loss": 0.0242,
      "step": 36610
    },
    {
      "epoch": 4.412048192771084,
      "grad_norm": 2.424990653991699,
      "learning_rate": 1.1175903614457833e-05,
      "loss": 0.0564,
      "step": 36620
    },
    {
      "epoch": 4.413253012048193,
      "grad_norm": 0.2410111278295517,
      "learning_rate": 1.1173493975903616e-05,
      "loss": 0.0574,
      "step": 36630
    },
    {
      "epoch": 4.414457831325302,
      "grad_norm": 0.3974301517009735,
      "learning_rate": 1.1171084337349398e-05,
      "loss": 0.0096,
      "step": 36640
    },
    {
      "epoch": 4.4156626506024095,
      "grad_norm": 0.1446656882762909,
      "learning_rate": 1.116867469879518e-05,
      "loss": 0.0262,
      "step": 36650
    },
    {
      "epoch": 4.416867469879518,
      "grad_norm": 2.4967691898345947,
      "learning_rate": 1.1166265060240964e-05,
      "loss": 0.0617,
      "step": 36660
    },
    {
      "epoch": 4.418072289156626,
      "grad_norm": 0.19248177111148834,
      "learning_rate": 1.1163855421686749e-05,
      "loss": 0.043,
      "step": 36670
    },
    {
      "epoch": 4.419277108433735,
      "grad_norm": 1.7765188217163086,
      "learning_rate": 1.1161445783132532e-05,
      "loss": 0.0288,
      "step": 36680
    },
    {
      "epoch": 4.420481927710844,
      "grad_norm": 1.4370769262313843,
      "learning_rate": 1.1159036144578315e-05,
      "loss": 0.0048,
      "step": 36690
    },
    {
      "epoch": 4.421686746987952,
      "grad_norm": 0.015711402520537376,
      "learning_rate": 1.1156626506024097e-05,
      "loss": 0.0179,
      "step": 36700
    },
    {
      "epoch": 4.4228915662650605,
      "grad_norm": 0.0734143927693367,
      "learning_rate": 1.115421686746988e-05,
      "loss": 0.0095,
      "step": 36710
    },
    {
      "epoch": 4.424096385542168,
      "grad_norm": 2.325648546218872,
      "learning_rate": 1.1151807228915663e-05,
      "loss": 0.0555,
      "step": 36720
    },
    {
      "epoch": 4.425301204819277,
      "grad_norm": 2.0686793327331543,
      "learning_rate": 1.1149397590361446e-05,
      "loss": 0.0154,
      "step": 36730
    },
    {
      "epoch": 4.426506024096385,
      "grad_norm": 0.407466322183609,
      "learning_rate": 1.114698795180723e-05,
      "loss": 0.0249,
      "step": 36740
    },
    {
      "epoch": 4.427710843373494,
      "grad_norm": 0.014359881170094013,
      "learning_rate": 1.1144578313253014e-05,
      "loss": 0.023,
      "step": 36750
    },
    {
      "epoch": 4.428915662650603,
      "grad_norm": 0.024515226483345032,
      "learning_rate": 1.1142168674698797e-05,
      "loss": 0.0757,
      "step": 36760
    },
    {
      "epoch": 4.430120481927711,
      "grad_norm": 6.220303535461426,
      "learning_rate": 1.1139759036144579e-05,
      "loss": 0.0187,
      "step": 36770
    },
    {
      "epoch": 4.4313253012048195,
      "grad_norm": 0.04002148658037186,
      "learning_rate": 1.1137349397590362e-05,
      "loss": 0.0319,
      "step": 36780
    },
    {
      "epoch": 4.432530120481927,
      "grad_norm": 1.9777435064315796,
      "learning_rate": 1.1134939759036145e-05,
      "loss": 0.0375,
      "step": 36790
    },
    {
      "epoch": 4.433734939759036,
      "grad_norm": 0.06817029416561127,
      "learning_rate": 1.1132530120481928e-05,
      "loss": 0.0354,
      "step": 36800
    },
    {
      "epoch": 4.434939759036144,
      "grad_norm": 0.162787064909935,
      "learning_rate": 1.1130120481927712e-05,
      "loss": 0.016,
      "step": 36810
    },
    {
      "epoch": 4.436144578313253,
      "grad_norm": 0.24252058565616608,
      "learning_rate": 1.1127710843373496e-05,
      "loss": 0.0233,
      "step": 36820
    },
    {
      "epoch": 4.437349397590362,
      "grad_norm": 0.07006202638149261,
      "learning_rate": 1.1125301204819278e-05,
      "loss": 0.0535,
      "step": 36830
    },
    {
      "epoch": 4.43855421686747,
      "grad_norm": 0.26387152075767517,
      "learning_rate": 1.1122891566265061e-05,
      "loss": 0.0764,
      "step": 36840
    },
    {
      "epoch": 4.4397590361445785,
      "grad_norm": 6.155069828033447,
      "learning_rate": 1.1120481927710844e-05,
      "loss": 0.0154,
      "step": 36850
    },
    {
      "epoch": 4.440963855421686,
      "grad_norm": 0.6973130702972412,
      "learning_rate": 1.1118072289156627e-05,
      "loss": 0.0498,
      "step": 36860
    },
    {
      "epoch": 4.442168674698795,
      "grad_norm": 6.058645248413086,
      "learning_rate": 1.111566265060241e-05,
      "loss": 0.0957,
      "step": 36870
    },
    {
      "epoch": 4.443373493975904,
      "grad_norm": 0.11831794679164886,
      "learning_rate": 1.1113253012048192e-05,
      "loss": 0.0237,
      "step": 36880
    },
    {
      "epoch": 4.444578313253012,
      "grad_norm": 0.06218109279870987,
      "learning_rate": 1.1110843373493975e-05,
      "loss": 0.0287,
      "step": 36890
    },
    {
      "epoch": 4.445783132530121,
      "grad_norm": 2.5237624645233154,
      "learning_rate": 1.110843373493976e-05,
      "loss": 0.0203,
      "step": 36900
    },
    {
      "epoch": 4.446987951807229,
      "grad_norm": 0.06361386924982071,
      "learning_rate": 1.1106024096385543e-05,
      "loss": 0.0438,
      "step": 36910
    },
    {
      "epoch": 4.448192771084337,
      "grad_norm": 0.775664210319519,
      "learning_rate": 1.1103614457831327e-05,
      "loss": 0.022,
      "step": 36920
    },
    {
      "epoch": 4.449397590361446,
      "grad_norm": 0.008512302301824093,
      "learning_rate": 1.110120481927711e-05,
      "loss": 0.0078,
      "step": 36930
    },
    {
      "epoch": 4.450602409638554,
      "grad_norm": 0.036520328372716904,
      "learning_rate": 1.1098795180722893e-05,
      "loss": 0.0191,
      "step": 36940
    },
    {
      "epoch": 4.451807228915663,
      "grad_norm": 0.1486143171787262,
      "learning_rate": 1.1096385542168674e-05,
      "loss": 0.0041,
      "step": 36950
    },
    {
      "epoch": 4.453012048192771,
      "grad_norm": 28.552051544189453,
      "learning_rate": 1.1093975903614458e-05,
      "loss": 0.0309,
      "step": 36960
    },
    {
      "epoch": 4.45421686746988,
      "grad_norm": 2.792881965637207,
      "learning_rate": 1.1091566265060242e-05,
      "loss": 0.0938,
      "step": 36970
    },
    {
      "epoch": 4.455421686746988,
      "grad_norm": 0.04672297090291977,
      "learning_rate": 1.1089156626506026e-05,
      "loss": 0.023,
      "step": 36980
    },
    {
      "epoch": 4.456626506024096,
      "grad_norm": 0.17426693439483643,
      "learning_rate": 1.1086746987951809e-05,
      "loss": 0.0088,
      "step": 36990
    },
    {
      "epoch": 4.457831325301205,
      "grad_norm": 0.026391200721263885,
      "learning_rate": 1.1084337349397592e-05,
      "loss": 0.0038,
      "step": 37000
    },
    {
      "epoch": 4.459036144578313,
      "grad_norm": 1.2488429546356201,
      "learning_rate": 1.1081927710843373e-05,
      "loss": 0.046,
      "step": 37010
    },
    {
      "epoch": 4.460240963855422,
      "grad_norm": 4.6324920654296875,
      "learning_rate": 1.1079518072289157e-05,
      "loss": 0.0858,
      "step": 37020
    },
    {
      "epoch": 4.46144578313253,
      "grad_norm": 1.5652986764907837,
      "learning_rate": 1.107710843373494e-05,
      "loss": 0.0677,
      "step": 37030
    },
    {
      "epoch": 4.462650602409639,
      "grad_norm": 0.12049584835767746,
      "learning_rate": 1.1074698795180723e-05,
      "loss": 0.0026,
      "step": 37040
    },
    {
      "epoch": 4.4638554216867465,
      "grad_norm": 0.020887551829218864,
      "learning_rate": 1.1072289156626508e-05,
      "loss": 0.0557,
      "step": 37050
    },
    {
      "epoch": 4.465060240963855,
      "grad_norm": 0.5007632374763489,
      "learning_rate": 1.1069879518072291e-05,
      "loss": 0.0132,
      "step": 37060
    },
    {
      "epoch": 4.466265060240964,
      "grad_norm": 2.00410795211792,
      "learning_rate": 1.1067469879518074e-05,
      "loss": 0.0082,
      "step": 37070
    },
    {
      "epoch": 4.467469879518072,
      "grad_norm": 6.135677814483643,
      "learning_rate": 1.1065060240963856e-05,
      "loss": 0.0921,
      "step": 37080
    },
    {
      "epoch": 4.468674698795181,
      "grad_norm": 2.6937549114227295,
      "learning_rate": 1.1062650602409639e-05,
      "loss": 0.0869,
      "step": 37090
    },
    {
      "epoch": 4.469879518072289,
      "grad_norm": 0.5461273789405823,
      "learning_rate": 1.1060240963855422e-05,
      "loss": 0.0525,
      "step": 37100
    },
    {
      "epoch": 4.471084337349398,
      "grad_norm": 0.05253169313073158,
      "learning_rate": 1.1057831325301205e-05,
      "loss": 0.0346,
      "step": 37110
    },
    {
      "epoch": 4.472289156626506,
      "grad_norm": 1.1626131534576416,
      "learning_rate": 1.105542168674699e-05,
      "loss": 0.0358,
      "step": 37120
    },
    {
      "epoch": 4.473493975903614,
      "grad_norm": 0.25203827023506165,
      "learning_rate": 1.1053012048192773e-05,
      "loss": 0.0236,
      "step": 37130
    },
    {
      "epoch": 4.474698795180723,
      "grad_norm": 0.03485914319753647,
      "learning_rate": 1.1050602409638556e-05,
      "loss": 0.0146,
      "step": 37140
    },
    {
      "epoch": 4.475903614457831,
      "grad_norm": 0.021190345287322998,
      "learning_rate": 1.1048192771084338e-05,
      "loss": 0.0575,
      "step": 37150
    },
    {
      "epoch": 4.47710843373494,
      "grad_norm": 0.26948198676109314,
      "learning_rate": 1.1045783132530121e-05,
      "loss": 0.0368,
      "step": 37160
    },
    {
      "epoch": 4.478313253012049,
      "grad_norm": 0.3195173144340515,
      "learning_rate": 1.1043373493975904e-05,
      "loss": 0.0238,
      "step": 37170
    },
    {
      "epoch": 4.4795180722891565,
      "grad_norm": 32.10833740234375,
      "learning_rate": 1.1040963855421687e-05,
      "loss": 0.0778,
      "step": 37180
    },
    {
      "epoch": 4.480722891566265,
      "grad_norm": 0.15502220392227173,
      "learning_rate": 1.103855421686747e-05,
      "loss": 0.0117,
      "step": 37190
    },
    {
      "epoch": 4.481927710843373,
      "grad_norm": 0.01900775358080864,
      "learning_rate": 1.1036144578313255e-05,
      "loss": 0.0134,
      "step": 37200
    },
    {
      "epoch": 4.483132530120482,
      "grad_norm": 0.011643759906291962,
      "learning_rate": 1.1033734939759037e-05,
      "loss": 0.042,
      "step": 37210
    },
    {
      "epoch": 4.48433734939759,
      "grad_norm": 0.009740609675645828,
      "learning_rate": 1.103132530120482e-05,
      "loss": 0.0382,
      "step": 37220
    },
    {
      "epoch": 4.485542168674699,
      "grad_norm": 1.542536973953247,
      "learning_rate": 1.1028915662650603e-05,
      "loss": 0.0102,
      "step": 37230
    },
    {
      "epoch": 4.486746987951808,
      "grad_norm": 0.09507903456687927,
      "learning_rate": 1.1026506024096386e-05,
      "loss": 0.0535,
      "step": 37240
    },
    {
      "epoch": 4.4879518072289155,
      "grad_norm": 0.009457997046411037,
      "learning_rate": 1.102409638554217e-05,
      "loss": 0.0288,
      "step": 37250
    },
    {
      "epoch": 4.489156626506024,
      "grad_norm": 0.14340612292289734,
      "learning_rate": 1.1021686746987951e-05,
      "loss": 0.01,
      "step": 37260
    },
    {
      "epoch": 4.490361445783132,
      "grad_norm": 0.007715481799095869,
      "learning_rate": 1.1019277108433738e-05,
      "loss": 0.0169,
      "step": 37270
    },
    {
      "epoch": 4.491566265060241,
      "grad_norm": 0.07885781675577164,
      "learning_rate": 1.101686746987952e-05,
      "loss": 0.0022,
      "step": 37280
    },
    {
      "epoch": 4.492771084337349,
      "grad_norm": 3.1978695392608643,
      "learning_rate": 1.1014457831325302e-05,
      "loss": 0.0347,
      "step": 37290
    },
    {
      "epoch": 4.493975903614458,
      "grad_norm": 5.784054756164551,
      "learning_rate": 1.1012048192771086e-05,
      "loss": 0.0829,
      "step": 37300
    },
    {
      "epoch": 4.495180722891567,
      "grad_norm": 2.087658166885376,
      "learning_rate": 1.1009638554216869e-05,
      "loss": 0.1088,
      "step": 37310
    },
    {
      "epoch": 4.4963855421686745,
      "grad_norm": 0.662355363368988,
      "learning_rate": 1.1007228915662652e-05,
      "loss": 0.0264,
      "step": 37320
    },
    {
      "epoch": 4.497590361445783,
      "grad_norm": 2.908665657043457,
      "learning_rate": 1.1004819277108433e-05,
      "loss": 0.0436,
      "step": 37330
    },
    {
      "epoch": 4.498795180722891,
      "grad_norm": 0.24535687267780304,
      "learning_rate": 1.1002409638554217e-05,
      "loss": 0.0315,
      "step": 37340
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.11429106444120407,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0424,
      "step": 37350
    },
    {
      "epoch": 4.501204819277109,
      "grad_norm": 0.23260489106178284,
      "learning_rate": 1.0997590361445785e-05,
      "loss": 0.0301,
      "step": 37360
    },
    {
      "epoch": 4.502409638554217,
      "grad_norm": 4.6709303855896,
      "learning_rate": 1.0995180722891568e-05,
      "loss": 0.0608,
      "step": 37370
    },
    {
      "epoch": 4.5036144578313255,
      "grad_norm": 0.05475228279829025,
      "learning_rate": 1.0992771084337351e-05,
      "loss": 0.0265,
      "step": 37380
    },
    {
      "epoch": 4.504819277108433,
      "grad_norm": 1.0300326347351074,
      "learning_rate": 1.0990361445783132e-05,
      "loss": 0.0286,
      "step": 37390
    },
    {
      "epoch": 4.506024096385542,
      "grad_norm": 0.020968837663531303,
      "learning_rate": 1.0987951807228916e-05,
      "loss": 0.0012,
      "step": 37400
    },
    {
      "epoch": 4.507228915662651,
      "grad_norm": 2.8650412559509277,
      "learning_rate": 1.0985542168674699e-05,
      "loss": 0.0439,
      "step": 37410
    },
    {
      "epoch": 4.508433734939759,
      "grad_norm": 1.1991422176361084,
      "learning_rate": 1.0983132530120484e-05,
      "loss": 0.0198,
      "step": 37420
    },
    {
      "epoch": 4.509638554216868,
      "grad_norm": 0.28200778365135193,
      "learning_rate": 1.0980722891566267e-05,
      "loss": 0.0487,
      "step": 37430
    },
    {
      "epoch": 4.510843373493976,
      "grad_norm": 0.013184811919927597,
      "learning_rate": 1.097831325301205e-05,
      "loss": 0.012,
      "step": 37440
    },
    {
      "epoch": 4.5120481927710845,
      "grad_norm": 0.049860864877700806,
      "learning_rate": 1.0975903614457833e-05,
      "loss": 0.0031,
      "step": 37450
    },
    {
      "epoch": 4.513253012048192,
      "grad_norm": 0.014051488600671291,
      "learning_rate": 1.0973493975903615e-05,
      "loss": 0.0235,
      "step": 37460
    },
    {
      "epoch": 4.514457831325301,
      "grad_norm": 0.010250149294734001,
      "learning_rate": 1.0971084337349398e-05,
      "loss": 0.0291,
      "step": 37470
    },
    {
      "epoch": 4.51566265060241,
      "grad_norm": 0.007205852307379246,
      "learning_rate": 1.0968674698795181e-05,
      "loss": 0.0247,
      "step": 37480
    },
    {
      "epoch": 4.516867469879518,
      "grad_norm": 0.16902406513690948,
      "learning_rate": 1.0966265060240964e-05,
      "loss": 0.0679,
      "step": 37490
    },
    {
      "epoch": 4.518072289156627,
      "grad_norm": 0.07317688316106796,
      "learning_rate": 1.0963855421686749e-05,
      "loss": 0.0121,
      "step": 37500
    },
    {
      "epoch": 4.519277108433735,
      "grad_norm": 0.03411044925451279,
      "learning_rate": 1.0961445783132532e-05,
      "loss": 0.0283,
      "step": 37510
    },
    {
      "epoch": 4.5204819277108435,
      "grad_norm": 0.01907450146973133,
      "learning_rate": 1.0959036144578314e-05,
      "loss": 0.0293,
      "step": 37520
    },
    {
      "epoch": 4.521686746987951,
      "grad_norm": 0.02428908832371235,
      "learning_rate": 1.0956626506024097e-05,
      "loss": 0.03,
      "step": 37530
    },
    {
      "epoch": 4.52289156626506,
      "grad_norm": 1.4491997957229614,
      "learning_rate": 1.095421686746988e-05,
      "loss": 0.0316,
      "step": 37540
    },
    {
      "epoch": 4.524096385542169,
      "grad_norm": 0.05464080721139908,
      "learning_rate": 1.0951807228915663e-05,
      "loss": 0.0102,
      "step": 37550
    },
    {
      "epoch": 4.525301204819277,
      "grad_norm": 0.019008569419384003,
      "learning_rate": 1.0949397590361446e-05,
      "loss": 0.0218,
      "step": 37560
    },
    {
      "epoch": 4.526506024096386,
      "grad_norm": 3.5923385620117188,
      "learning_rate": 1.0946987951807231e-05,
      "loss": 0.0503,
      "step": 37570
    },
    {
      "epoch": 4.527710843373494,
      "grad_norm": 0.009166590869426727,
      "learning_rate": 1.0944578313253014e-05,
      "loss": 0.0325,
      "step": 37580
    },
    {
      "epoch": 4.528915662650602,
      "grad_norm": 0.39708468317985535,
      "learning_rate": 1.0942168674698796e-05,
      "loss": 0.0208,
      "step": 37590
    },
    {
      "epoch": 4.530120481927711,
      "grad_norm": 1.0894297361373901,
      "learning_rate": 1.0939759036144579e-05,
      "loss": 0.0772,
      "step": 37600
    },
    {
      "epoch": 4.531325301204819,
      "grad_norm": 0.04472188279032707,
      "learning_rate": 1.0937349397590362e-05,
      "loss": 0.0346,
      "step": 37610
    },
    {
      "epoch": 4.532530120481928,
      "grad_norm": 0.04992659389972687,
      "learning_rate": 1.0934939759036145e-05,
      "loss": 0.0482,
      "step": 37620
    },
    {
      "epoch": 4.533734939759036,
      "grad_norm": 1.9808931350708008,
      "learning_rate": 1.0932530120481929e-05,
      "loss": 0.0748,
      "step": 37630
    },
    {
      "epoch": 4.534939759036145,
      "grad_norm": 0.388261079788208,
      "learning_rate": 1.093012048192771e-05,
      "loss": 0.0281,
      "step": 37640
    },
    {
      "epoch": 4.5361445783132535,
      "grad_norm": 3.1361687183380127,
      "learning_rate": 1.0927710843373495e-05,
      "loss": 0.0372,
      "step": 37650
    },
    {
      "epoch": 4.537349397590361,
      "grad_norm": 0.007837663404643536,
      "learning_rate": 1.0925301204819278e-05,
      "loss": 0.0093,
      "step": 37660
    },
    {
      "epoch": 4.53855421686747,
      "grad_norm": 0.008466921746730804,
      "learning_rate": 1.0922891566265061e-05,
      "loss": 0.0326,
      "step": 37670
    },
    {
      "epoch": 4.539759036144578,
      "grad_norm": 1.2870080471038818,
      "learning_rate": 1.0920481927710845e-05,
      "loss": 0.0501,
      "step": 37680
    },
    {
      "epoch": 4.540963855421687,
      "grad_norm": 0.33874714374542236,
      "learning_rate": 1.0918072289156628e-05,
      "loss": 0.0175,
      "step": 37690
    },
    {
      "epoch": 4.542168674698795,
      "grad_norm": 0.0112893832847476,
      "learning_rate": 1.091566265060241e-05,
      "loss": 0.0619,
      "step": 37700
    },
    {
      "epoch": 4.543373493975904,
      "grad_norm": 0.6426414251327515,
      "learning_rate": 1.0913253012048192e-05,
      "loss": 0.023,
      "step": 37710
    },
    {
      "epoch": 4.544578313253012,
      "grad_norm": 0.016756953671574593,
      "learning_rate": 1.0910843373493977e-05,
      "loss": 0.0219,
      "step": 37720
    },
    {
      "epoch": 4.54578313253012,
      "grad_norm": 0.06861259043216705,
      "learning_rate": 1.090843373493976e-05,
      "loss": 0.0599,
      "step": 37730
    },
    {
      "epoch": 4.546987951807229,
      "grad_norm": 0.019070835784077644,
      "learning_rate": 1.0906024096385544e-05,
      "loss": 0.0464,
      "step": 37740
    },
    {
      "epoch": 4.548192771084337,
      "grad_norm": 0.0793890729546547,
      "learning_rate": 1.0903614457831327e-05,
      "loss": 0.0258,
      "step": 37750
    },
    {
      "epoch": 4.549397590361446,
      "grad_norm": 0.07326237112283707,
      "learning_rate": 1.090120481927711e-05,
      "loss": 0.0199,
      "step": 37760
    },
    {
      "epoch": 4.550602409638554,
      "grad_norm": 0.036430101841688156,
      "learning_rate": 1.0898795180722891e-05,
      "loss": 0.0181,
      "step": 37770
    },
    {
      "epoch": 4.551807228915663,
      "grad_norm": 0.27348336577415466,
      "learning_rate": 1.0896385542168675e-05,
      "loss": 0.0631,
      "step": 37780
    },
    {
      "epoch": 4.553012048192771,
      "grad_norm": 0.04578223079442978,
      "learning_rate": 1.0893975903614458e-05,
      "loss": 0.0408,
      "step": 37790
    },
    {
      "epoch": 4.554216867469879,
      "grad_norm": 7.58824348449707,
      "learning_rate": 1.0891566265060243e-05,
      "loss": 0.0341,
      "step": 37800
    },
    {
      "epoch": 4.555421686746988,
      "grad_norm": 0.02508465014398098,
      "learning_rate": 1.0889156626506026e-05,
      "loss": 0.0371,
      "step": 37810
    },
    {
      "epoch": 4.556626506024096,
      "grad_norm": 0.42749083042144775,
      "learning_rate": 1.0886746987951809e-05,
      "loss": 0.0276,
      "step": 37820
    },
    {
      "epoch": 4.557831325301205,
      "grad_norm": 0.013777474872767925,
      "learning_rate": 1.088433734939759e-05,
      "loss": 0.0721,
      "step": 37830
    },
    {
      "epoch": 4.559036144578314,
      "grad_norm": 0.01206041406840086,
      "learning_rate": 1.0881927710843374e-05,
      "loss": 0.0185,
      "step": 37840
    },
    {
      "epoch": 4.5602409638554215,
      "grad_norm": 1.2347983121871948,
      "learning_rate": 1.0879518072289157e-05,
      "loss": 0.0317,
      "step": 37850
    },
    {
      "epoch": 4.56144578313253,
      "grad_norm": 0.0037488818634301424,
      "learning_rate": 1.087710843373494e-05,
      "loss": 0.0285,
      "step": 37860
    },
    {
      "epoch": 4.562650602409638,
      "grad_norm": 0.04700327292084694,
      "learning_rate": 1.0874698795180725e-05,
      "loss": 0.0534,
      "step": 37870
    },
    {
      "epoch": 4.563855421686747,
      "grad_norm": 0.01275135762989521,
      "learning_rate": 1.0872289156626508e-05,
      "loss": 0.0502,
      "step": 37880
    },
    {
      "epoch": 4.565060240963856,
      "grad_norm": 4.737666130065918,
      "learning_rate": 1.0869879518072291e-05,
      "loss": 0.0371,
      "step": 37890
    },
    {
      "epoch": 4.566265060240964,
      "grad_norm": 1.7827824354171753,
      "learning_rate": 1.0867469879518073e-05,
      "loss": 0.0358,
      "step": 37900
    },
    {
      "epoch": 4.567469879518073,
      "grad_norm": 2.8202619552612305,
      "learning_rate": 1.0865060240963856e-05,
      "loss": 0.017,
      "step": 37910
    },
    {
      "epoch": 4.5686746987951805,
      "grad_norm": 1.3161789178848267,
      "learning_rate": 1.0862650602409639e-05,
      "loss": 0.0046,
      "step": 37920
    },
    {
      "epoch": 4.569879518072289,
      "grad_norm": 1.9328879117965698,
      "learning_rate": 1.0860240963855422e-05,
      "loss": 0.0521,
      "step": 37930
    },
    {
      "epoch": 4.571084337349397,
      "grad_norm": 5.26064920425415,
      "learning_rate": 1.0857831325301205e-05,
      "loss": 0.0993,
      "step": 37940
    },
    {
      "epoch": 4.572289156626506,
      "grad_norm": 0.23730941116809845,
      "learning_rate": 1.085542168674699e-05,
      "loss": 0.0168,
      "step": 37950
    },
    {
      "epoch": 4.573493975903615,
      "grad_norm": 0.2442476749420166,
      "learning_rate": 1.0853012048192772e-05,
      "loss": 0.0435,
      "step": 37960
    },
    {
      "epoch": 4.574698795180723,
      "grad_norm": 0.676607072353363,
      "learning_rate": 1.0850602409638555e-05,
      "loss": 0.0349,
      "step": 37970
    },
    {
      "epoch": 4.575903614457832,
      "grad_norm": 0.7413174510002136,
      "learning_rate": 1.0848192771084338e-05,
      "loss": 0.0385,
      "step": 37980
    },
    {
      "epoch": 4.5771084337349395,
      "grad_norm": 0.05620650202035904,
      "learning_rate": 1.0845783132530121e-05,
      "loss": 0.0335,
      "step": 37990
    },
    {
      "epoch": 4.578313253012048,
      "grad_norm": 0.15053707361221313,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 0.0617,
      "step": 38000
    },
    {
      "epoch": 4.579518072289156,
      "grad_norm": 1.1708592176437378,
      "learning_rate": 1.0840963855421686e-05,
      "loss": 0.0568,
      "step": 38010
    },
    {
      "epoch": 4.580722891566265,
      "grad_norm": 0.1631985455751419,
      "learning_rate": 1.0838554216867473e-05,
      "loss": 0.0161,
      "step": 38020
    },
    {
      "epoch": 4.581927710843374,
      "grad_norm": 0.026731964200735092,
      "learning_rate": 1.0836144578313254e-05,
      "loss": 0.0504,
      "step": 38030
    },
    {
      "epoch": 4.583132530120482,
      "grad_norm": 0.46108555793762207,
      "learning_rate": 1.0833734939759037e-05,
      "loss": 0.0405,
      "step": 38040
    },
    {
      "epoch": 4.5843373493975905,
      "grad_norm": 4.957821369171143,
      "learning_rate": 1.083132530120482e-05,
      "loss": 0.1039,
      "step": 38050
    },
    {
      "epoch": 4.585542168674698,
      "grad_norm": 0.11603859066963196,
      "learning_rate": 1.0828915662650604e-05,
      "loss": 0.02,
      "step": 38060
    },
    {
      "epoch": 4.586746987951807,
      "grad_norm": 0.006605047266930342,
      "learning_rate": 1.0826506024096387e-05,
      "loss": 0.0343,
      "step": 38070
    },
    {
      "epoch": 4.587951807228916,
      "grad_norm": 3.309366226196289,
      "learning_rate": 1.0824096385542168e-05,
      "loss": 0.0603,
      "step": 38080
    },
    {
      "epoch": 4.589156626506024,
      "grad_norm": 1.8169564008712769,
      "learning_rate": 1.0821686746987951e-05,
      "loss": 0.0377,
      "step": 38090
    },
    {
      "epoch": 4.590361445783133,
      "grad_norm": 0.1405418962240219,
      "learning_rate": 1.0819277108433736e-05,
      "loss": 0.0153,
      "step": 38100
    },
    {
      "epoch": 4.591566265060241,
      "grad_norm": 0.009806284680962563,
      "learning_rate": 1.081686746987952e-05,
      "loss": 0.0334,
      "step": 38110
    },
    {
      "epoch": 4.5927710843373495,
      "grad_norm": 1.0085902214050293,
      "learning_rate": 1.0814457831325303e-05,
      "loss": 0.0286,
      "step": 38120
    },
    {
      "epoch": 4.593975903614458,
      "grad_norm": 0.3285202383995056,
      "learning_rate": 1.0812048192771086e-05,
      "loss": 0.0312,
      "step": 38130
    },
    {
      "epoch": 4.595180722891566,
      "grad_norm": 0.10858338326215744,
      "learning_rate": 1.0809638554216867e-05,
      "loss": 0.0509,
      "step": 38140
    },
    {
      "epoch": 4.596385542168675,
      "grad_norm": 0.6642979383468628,
      "learning_rate": 1.080722891566265e-05,
      "loss": 0.037,
      "step": 38150
    },
    {
      "epoch": 4.597590361445783,
      "grad_norm": 0.021192578598856926,
      "learning_rate": 1.0804819277108434e-05,
      "loss": 0.0195,
      "step": 38160
    },
    {
      "epoch": 4.598795180722892,
      "grad_norm": 0.10105784237384796,
      "learning_rate": 1.0802409638554218e-05,
      "loss": 0.0201,
      "step": 38170
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.00875215046107769,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0711,
      "step": 38180
    },
    {
      "epoch": 4.6012048192771084,
      "grad_norm": 20.222896575927734,
      "learning_rate": 1.0797590361445785e-05,
      "loss": 0.081,
      "step": 38190
    },
    {
      "epoch": 4.602409638554217,
      "grad_norm": 0.1355871856212616,
      "learning_rate": 1.0795180722891568e-05,
      "loss": 0.0223,
      "step": 38200
    },
    {
      "epoch": 4.603614457831325,
      "grad_norm": 0.09736453741788864,
      "learning_rate": 1.079277108433735e-05,
      "loss": 0.0404,
      "step": 38210
    },
    {
      "epoch": 4.604819277108434,
      "grad_norm": 0.0382697768509388,
      "learning_rate": 1.0790361445783133e-05,
      "loss": 0.0404,
      "step": 38220
    },
    {
      "epoch": 4.606024096385542,
      "grad_norm": 2.445575475692749,
      "learning_rate": 1.0787951807228916e-05,
      "loss": 0.0644,
      "step": 38230
    },
    {
      "epoch": 4.607228915662651,
      "grad_norm": 2.1837246417999268,
      "learning_rate": 1.0785542168674699e-05,
      "loss": 0.0434,
      "step": 38240
    },
    {
      "epoch": 4.608433734939759,
      "grad_norm": 4.672415733337402,
      "learning_rate": 1.0783132530120484e-05,
      "loss": 0.0313,
      "step": 38250
    },
    {
      "epoch": 4.609638554216867,
      "grad_norm": 0.046213045716285706,
      "learning_rate": 1.0780722891566267e-05,
      "loss": 0.0209,
      "step": 38260
    },
    {
      "epoch": 4.610843373493976,
      "grad_norm": 0.007385889533907175,
      "learning_rate": 1.0778313253012049e-05,
      "loss": 0.031,
      "step": 38270
    },
    {
      "epoch": 4.612048192771084,
      "grad_norm": 3.286836862564087,
      "learning_rate": 1.0775903614457832e-05,
      "loss": 0.0433,
      "step": 38280
    },
    {
      "epoch": 4.613253012048193,
      "grad_norm": 0.026216913014650345,
      "learning_rate": 1.0773493975903615e-05,
      "loss": 0.0352,
      "step": 38290
    },
    {
      "epoch": 4.614457831325301,
      "grad_norm": 0.6555598974227905,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 0.0137,
      "step": 38300
    },
    {
      "epoch": 4.61566265060241,
      "grad_norm": 0.06332236528396606,
      "learning_rate": 1.0768674698795181e-05,
      "loss": 0.0769,
      "step": 38310
    },
    {
      "epoch": 4.6168674698795185,
      "grad_norm": 0.4113547205924988,
      "learning_rate": 1.0766265060240966e-05,
      "loss": 0.0023,
      "step": 38320
    },
    {
      "epoch": 4.618072289156626,
      "grad_norm": 0.1799921989440918,
      "learning_rate": 1.076385542168675e-05,
      "loss": 0.0431,
      "step": 38330
    },
    {
      "epoch": 4.619277108433735,
      "grad_norm": 0.09915287792682648,
      "learning_rate": 1.076144578313253e-05,
      "loss": 0.0868,
      "step": 38340
    },
    {
      "epoch": 4.620481927710843,
      "grad_norm": 0.0478103905916214,
      "learning_rate": 1.0759036144578314e-05,
      "loss": 0.0157,
      "step": 38350
    },
    {
      "epoch": 4.621686746987952,
      "grad_norm": 2.1274890899658203,
      "learning_rate": 1.0756626506024097e-05,
      "loss": 0.0525,
      "step": 38360
    },
    {
      "epoch": 4.622891566265061,
      "grad_norm": 6.616763591766357,
      "learning_rate": 1.075421686746988e-05,
      "loss": 0.0632,
      "step": 38370
    },
    {
      "epoch": 4.624096385542169,
      "grad_norm": 0.049733903259038925,
      "learning_rate": 1.0751807228915663e-05,
      "loss": 0.0562,
      "step": 38380
    },
    {
      "epoch": 4.625301204819277,
      "grad_norm": 0.34940141439437866,
      "learning_rate": 1.0749397590361445e-05,
      "loss": 0.0344,
      "step": 38390
    },
    {
      "epoch": 4.626506024096385,
      "grad_norm": 1.9440836906433105,
      "learning_rate": 1.074698795180723e-05,
      "loss": 0.0304,
      "step": 38400
    },
    {
      "epoch": 4.627710843373494,
      "grad_norm": 0.0390782468020916,
      "learning_rate": 1.0744578313253013e-05,
      "loss": 0.0401,
      "step": 38410
    },
    {
      "epoch": 4.628915662650602,
      "grad_norm": 0.2503378391265869,
      "learning_rate": 1.0742168674698796e-05,
      "loss": 0.0363,
      "step": 38420
    },
    {
      "epoch": 4.630120481927711,
      "grad_norm": 0.07941870391368866,
      "learning_rate": 1.073975903614458e-05,
      "loss": 0.0457,
      "step": 38430
    },
    {
      "epoch": 4.63132530120482,
      "grad_norm": 0.007302857935428619,
      "learning_rate": 1.0737349397590363e-05,
      "loss": 0.0337,
      "step": 38440
    },
    {
      "epoch": 4.632530120481928,
      "grad_norm": 2.478931427001953,
      "learning_rate": 1.0734939759036144e-05,
      "loss": 0.0326,
      "step": 38450
    },
    {
      "epoch": 4.633734939759036,
      "grad_norm": 0.5769784450531006,
      "learning_rate": 1.0732530120481927e-05,
      "loss": 0.0417,
      "step": 38460
    },
    {
      "epoch": 4.634939759036144,
      "grad_norm": 0.26941820979118347,
      "learning_rate": 1.0730120481927712e-05,
      "loss": 0.0095,
      "step": 38470
    },
    {
      "epoch": 4.636144578313253,
      "grad_norm": 0.1404273509979248,
      "learning_rate": 1.0727710843373495e-05,
      "loss": 0.0506,
      "step": 38480
    },
    {
      "epoch": 4.637349397590361,
      "grad_norm": 0.6109364032745361,
      "learning_rate": 1.0725301204819278e-05,
      "loss": 0.0254,
      "step": 38490
    },
    {
      "epoch": 4.63855421686747,
      "grad_norm": 0.13724790513515472,
      "learning_rate": 1.0722891566265062e-05,
      "loss": 0.0209,
      "step": 38500
    },
    {
      "epoch": 4.639759036144579,
      "grad_norm": 0.03067575767636299,
      "learning_rate": 1.0720481927710845e-05,
      "loss": 0.0671,
      "step": 38510
    },
    {
      "epoch": 4.6409638554216865,
      "grad_norm": 3.0616180896759033,
      "learning_rate": 1.0718072289156626e-05,
      "loss": 0.0071,
      "step": 38520
    },
    {
      "epoch": 4.642168674698795,
      "grad_norm": 2.486454963684082,
      "learning_rate": 1.071566265060241e-05,
      "loss": 0.0192,
      "step": 38530
    },
    {
      "epoch": 4.643373493975903,
      "grad_norm": 3.3409438133239746,
      "learning_rate": 1.0713253012048193e-05,
      "loss": 0.0393,
      "step": 38540
    },
    {
      "epoch": 4.644578313253012,
      "grad_norm": 0.014874951913952827,
      "learning_rate": 1.0710843373493977e-05,
      "loss": 0.0225,
      "step": 38550
    },
    {
      "epoch": 4.64578313253012,
      "grad_norm": 0.0041516004130244255,
      "learning_rate": 1.070843373493976e-05,
      "loss": 0.0862,
      "step": 38560
    },
    {
      "epoch": 4.646987951807229,
      "grad_norm": 0.49849721789360046,
      "learning_rate": 1.0706024096385544e-05,
      "loss": 0.0491,
      "step": 38570
    },
    {
      "epoch": 4.648192771084338,
      "grad_norm": 1.9849051237106323,
      "learning_rate": 1.0703614457831327e-05,
      "loss": 0.0242,
      "step": 38580
    },
    {
      "epoch": 4.6493975903614455,
      "grad_norm": 0.04140707105398178,
      "learning_rate": 1.0701204819277108e-05,
      "loss": 0.0359,
      "step": 38590
    },
    {
      "epoch": 4.650602409638554,
      "grad_norm": 1.8161218166351318,
      "learning_rate": 1.0698795180722892e-05,
      "loss": 0.0418,
      "step": 38600
    },
    {
      "epoch": 4.651807228915663,
      "grad_norm": 0.011151700280606747,
      "learning_rate": 1.0696385542168675e-05,
      "loss": 0.0461,
      "step": 38610
    },
    {
      "epoch": 4.653012048192771,
      "grad_norm": 0.018403612077236176,
      "learning_rate": 1.069397590361446e-05,
      "loss": 0.0137,
      "step": 38620
    },
    {
      "epoch": 4.65421686746988,
      "grad_norm": 0.012321787886321545,
      "learning_rate": 1.0691566265060243e-05,
      "loss": 0.0769,
      "step": 38630
    },
    {
      "epoch": 4.655421686746988,
      "grad_norm": 0.9230923056602478,
      "learning_rate": 1.0689156626506026e-05,
      "loss": 0.0185,
      "step": 38640
    },
    {
      "epoch": 4.656626506024097,
      "grad_norm": 2.4166064262390137,
      "learning_rate": 1.0686746987951808e-05,
      "loss": 0.0377,
      "step": 38650
    },
    {
      "epoch": 4.6578313253012045,
      "grad_norm": 3.25223970413208,
      "learning_rate": 1.068433734939759e-05,
      "loss": 0.0696,
      "step": 38660
    },
    {
      "epoch": 4.659036144578313,
      "grad_norm": 0.2223901003599167,
      "learning_rate": 1.0681927710843374e-05,
      "loss": 0.0416,
      "step": 38670
    },
    {
      "epoch": 4.660240963855422,
      "grad_norm": 0.07399250566959381,
      "learning_rate": 1.0679518072289157e-05,
      "loss": 0.079,
      "step": 38680
    },
    {
      "epoch": 4.66144578313253,
      "grad_norm": 2.2814881801605225,
      "learning_rate": 1.067710843373494e-05,
      "loss": 0.0542,
      "step": 38690
    },
    {
      "epoch": 4.662650602409639,
      "grad_norm": 0.012717028148472309,
      "learning_rate": 1.0674698795180725e-05,
      "loss": 0.0168,
      "step": 38700
    },
    {
      "epoch": 4.663855421686747,
      "grad_norm": 0.11146415024995804,
      "learning_rate": 1.0672289156626508e-05,
      "loss": 0.0031,
      "step": 38710
    },
    {
      "epoch": 4.6650602409638555,
      "grad_norm": 0.8915390968322754,
      "learning_rate": 1.066987951807229e-05,
      "loss": 0.0029,
      "step": 38720
    },
    {
      "epoch": 4.666265060240963,
      "grad_norm": 4.478344440460205,
      "learning_rate": 1.0667469879518073e-05,
      "loss": 0.0611,
      "step": 38730
    },
    {
      "epoch": 4.667469879518072,
      "grad_norm": 6.348888874053955,
      "learning_rate": 1.0665060240963856e-05,
      "loss": 0.0905,
      "step": 38740
    },
    {
      "epoch": 4.668674698795181,
      "grad_norm": 0.18821600079536438,
      "learning_rate": 1.066265060240964e-05,
      "loss": 0.0256,
      "step": 38750
    },
    {
      "epoch": 4.669879518072289,
      "grad_norm": 1.8402479887008667,
      "learning_rate": 1.0660240963855422e-05,
      "loss": 0.0212,
      "step": 38760
    },
    {
      "epoch": 4.671084337349398,
      "grad_norm": 0.3187527656555176,
      "learning_rate": 1.0657831325301207e-05,
      "loss": 0.025,
      "step": 38770
    },
    {
      "epoch": 4.672289156626506,
      "grad_norm": 2.871549129486084,
      "learning_rate": 1.0655421686746989e-05,
      "loss": 0.0523,
      "step": 38780
    },
    {
      "epoch": 4.6734939759036145,
      "grad_norm": 6.502804756164551,
      "learning_rate": 1.0653012048192772e-05,
      "loss": 0.0607,
      "step": 38790
    },
    {
      "epoch": 4.674698795180722,
      "grad_norm": 1.9673559665679932,
      "learning_rate": 1.0650602409638555e-05,
      "loss": 0.0818,
      "step": 38800
    },
    {
      "epoch": 4.675903614457831,
      "grad_norm": 0.05218193680047989,
      "learning_rate": 1.0648192771084338e-05,
      "loss": 0.0032,
      "step": 38810
    },
    {
      "epoch": 4.67710843373494,
      "grad_norm": 0.08829709142446518,
      "learning_rate": 1.0645783132530122e-05,
      "loss": 0.0453,
      "step": 38820
    },
    {
      "epoch": 4.678313253012048,
      "grad_norm": 0.03357119858264923,
      "learning_rate": 1.0643373493975903e-05,
      "loss": 0.0309,
      "step": 38830
    },
    {
      "epoch": 4.679518072289157,
      "grad_norm": 0.8354134559631348,
      "learning_rate": 1.0640963855421686e-05,
      "loss": 0.031,
      "step": 38840
    },
    {
      "epoch": 4.6807228915662655,
      "grad_norm": 4.718934535980225,
      "learning_rate": 1.0638554216867471e-05,
      "loss": 0.074,
      "step": 38850
    },
    {
      "epoch": 4.6819277108433734,
      "grad_norm": 0.025845907628536224,
      "learning_rate": 1.0636144578313254e-05,
      "loss": 0.017,
      "step": 38860
    },
    {
      "epoch": 4.683132530120482,
      "grad_norm": 10.21324348449707,
      "learning_rate": 1.0633734939759037e-05,
      "loss": 0.0687,
      "step": 38870
    },
    {
      "epoch": 4.68433734939759,
      "grad_norm": 0.16981613636016846,
      "learning_rate": 1.063132530120482e-05,
      "loss": 0.0741,
      "step": 38880
    },
    {
      "epoch": 4.685542168674699,
      "grad_norm": 0.1502799242734909,
      "learning_rate": 1.0628915662650604e-05,
      "loss": 0.0532,
      "step": 38890
    },
    {
      "epoch": 4.686746987951807,
      "grad_norm": 0.5407609939575195,
      "learning_rate": 1.0626506024096385e-05,
      "loss": 0.0332,
      "step": 38900
    },
    {
      "epoch": 4.687951807228916,
      "grad_norm": 0.031980257481336594,
      "learning_rate": 1.0624096385542168e-05,
      "loss": 0.0423,
      "step": 38910
    },
    {
      "epoch": 4.6891566265060245,
      "grad_norm": 1.4873985052108765,
      "learning_rate": 1.0621686746987953e-05,
      "loss": 0.0565,
      "step": 38920
    },
    {
      "epoch": 4.690361445783132,
      "grad_norm": 4.242257118225098,
      "learning_rate": 1.0619277108433736e-05,
      "loss": 0.0335,
      "step": 38930
    },
    {
      "epoch": 4.691566265060241,
      "grad_norm": 0.034499071538448334,
      "learning_rate": 1.061686746987952e-05,
      "loss": 0.0343,
      "step": 38940
    },
    {
      "epoch": 4.692771084337349,
      "grad_norm": 4.557447910308838,
      "learning_rate": 1.0614457831325303e-05,
      "loss": 0.0289,
      "step": 38950
    },
    {
      "epoch": 4.693975903614458,
      "grad_norm": 0.5047774314880371,
      "learning_rate": 1.0612048192771084e-05,
      "loss": 0.0488,
      "step": 38960
    },
    {
      "epoch": 4.695180722891566,
      "grad_norm": 0.2254548966884613,
      "learning_rate": 1.0609638554216867e-05,
      "loss": 0.021,
      "step": 38970
    },
    {
      "epoch": 4.696385542168675,
      "grad_norm": 0.21533018350601196,
      "learning_rate": 1.060722891566265e-05,
      "loss": 0.0283,
      "step": 38980
    },
    {
      "epoch": 4.6975903614457835,
      "grad_norm": 0.005896284244954586,
      "learning_rate": 1.0604819277108434e-05,
      "loss": 0.0292,
      "step": 38990
    },
    {
      "epoch": 4.698795180722891,
      "grad_norm": 0.005897646304219961,
      "learning_rate": 1.0602409638554219e-05,
      "loss": 0.0049,
      "step": 39000
    },
    {
      "epoch": 4.7,
      "grad_norm": 16.879253387451172,
      "learning_rate": 1.0600000000000002e-05,
      "loss": 0.0637,
      "step": 39010
    },
    {
      "epoch": 4.701204819277108,
      "grad_norm": 0.033818770200014114,
      "learning_rate": 1.0597590361445785e-05,
      "loss": 0.0632,
      "step": 39020
    },
    {
      "epoch": 4.702409638554217,
      "grad_norm": 4.731877326965332,
      "learning_rate": 1.0595180722891567e-05,
      "loss": 0.0501,
      "step": 39030
    },
    {
      "epoch": 4.703614457831325,
      "grad_norm": 0.9202675223350525,
      "learning_rate": 1.059277108433735e-05,
      "loss": 0.0449,
      "step": 39040
    },
    {
      "epoch": 4.704819277108434,
      "grad_norm": 0.07761155068874359,
      "learning_rate": 1.0590361445783133e-05,
      "loss": 0.0457,
      "step": 39050
    },
    {
      "epoch": 4.706024096385542,
      "grad_norm": 0.10390278697013855,
      "learning_rate": 1.0587951807228916e-05,
      "loss": 0.0352,
      "step": 39060
    },
    {
      "epoch": 4.70722891566265,
      "grad_norm": 0.01565205305814743,
      "learning_rate": 1.0585542168674701e-05,
      "loss": 0.0505,
      "step": 39070
    },
    {
      "epoch": 4.708433734939759,
      "grad_norm": 7.231964588165283,
      "learning_rate": 1.0583132530120484e-05,
      "loss": 0.0443,
      "step": 39080
    },
    {
      "epoch": 4.709638554216868,
      "grad_norm": 0.033100321888923645,
      "learning_rate": 1.0580722891566266e-05,
      "loss": 0.0213,
      "step": 39090
    },
    {
      "epoch": 4.710843373493976,
      "grad_norm": 0.5248777270317078,
      "learning_rate": 1.0578313253012049e-05,
      "loss": 0.0613,
      "step": 39100
    },
    {
      "epoch": 4.712048192771085,
      "grad_norm": 0.6011955738067627,
      "learning_rate": 1.0575903614457832e-05,
      "loss": 0.0033,
      "step": 39110
    },
    {
      "epoch": 4.713253012048193,
      "grad_norm": 0.7425318360328674,
      "learning_rate": 1.0573493975903615e-05,
      "loss": 0.0065,
      "step": 39120
    },
    {
      "epoch": 4.714457831325301,
      "grad_norm": 2.1835434436798096,
      "learning_rate": 1.0571084337349398e-05,
      "loss": 0.0244,
      "step": 39130
    },
    {
      "epoch": 4.715662650602409,
      "grad_norm": 0.042323507368564606,
      "learning_rate": 1.056867469879518e-05,
      "loss": 0.0712,
      "step": 39140
    },
    {
      "epoch": 4.716867469879518,
      "grad_norm": 0.006499543320387602,
      "learning_rate": 1.0566265060240966e-05,
      "loss": 0.0607,
      "step": 39150
    },
    {
      "epoch": 4.718072289156627,
      "grad_norm": 3.127317428588867,
      "learning_rate": 1.0563855421686748e-05,
      "loss": 0.0227,
      "step": 39160
    },
    {
      "epoch": 4.719277108433735,
      "grad_norm": 0.6004565954208374,
      "learning_rate": 1.0561445783132531e-05,
      "loss": 0.0442,
      "step": 39170
    },
    {
      "epoch": 4.720481927710844,
      "grad_norm": 1.167743444442749,
      "learning_rate": 1.0559036144578314e-05,
      "loss": 0.0431,
      "step": 39180
    },
    {
      "epoch": 4.7216867469879515,
      "grad_norm": 0.1006058007478714,
      "learning_rate": 1.0556626506024097e-05,
      "loss": 0.0156,
      "step": 39190
    },
    {
      "epoch": 4.72289156626506,
      "grad_norm": 0.2729656994342804,
      "learning_rate": 1.055421686746988e-05,
      "loss": 0.0175,
      "step": 39200
    },
    {
      "epoch": 4.724096385542168,
      "grad_norm": 4.3354034423828125,
      "learning_rate": 1.0551807228915662e-05,
      "loss": 0.0881,
      "step": 39210
    },
    {
      "epoch": 4.725301204819277,
      "grad_norm": 0.11415867507457733,
      "learning_rate": 1.0549397590361447e-05,
      "loss": 0.0275,
      "step": 39220
    },
    {
      "epoch": 4.726506024096386,
      "grad_norm": 1.398067831993103,
      "learning_rate": 1.054698795180723e-05,
      "loss": 0.0115,
      "step": 39230
    },
    {
      "epoch": 4.727710843373494,
      "grad_norm": 0.9899911284446716,
      "learning_rate": 1.0544578313253013e-05,
      "loss": 0.0786,
      "step": 39240
    },
    {
      "epoch": 4.728915662650603,
      "grad_norm": 1.4308042526245117,
      "learning_rate": 1.0542168674698796e-05,
      "loss": 0.039,
      "step": 39250
    },
    {
      "epoch": 4.7301204819277105,
      "grad_norm": 2.359748363494873,
      "learning_rate": 1.053975903614458e-05,
      "loss": 0.0943,
      "step": 39260
    },
    {
      "epoch": 4.731325301204819,
      "grad_norm": 0.33842700719833374,
      "learning_rate": 1.0537349397590361e-05,
      "loss": 0.028,
      "step": 39270
    },
    {
      "epoch": 4.732530120481927,
      "grad_norm": 0.00547428335994482,
      "learning_rate": 1.0534939759036144e-05,
      "loss": 0.027,
      "step": 39280
    },
    {
      "epoch": 4.733734939759036,
      "grad_norm": 2.2065327167510986,
      "learning_rate": 1.0532530120481927e-05,
      "loss": 0.055,
      "step": 39290
    },
    {
      "epoch": 4.734939759036145,
      "grad_norm": 0.057350583374500275,
      "learning_rate": 1.0530120481927712e-05,
      "loss": 0.0112,
      "step": 39300
    },
    {
      "epoch": 4.736144578313253,
      "grad_norm": 1.6186805963516235,
      "learning_rate": 1.0527710843373495e-05,
      "loss": 0.0116,
      "step": 39310
    },
    {
      "epoch": 4.7373493975903616,
      "grad_norm": 7.4545440673828125,
      "learning_rate": 1.0525301204819279e-05,
      "loss": 0.026,
      "step": 39320
    },
    {
      "epoch": 4.73855421686747,
      "grad_norm": 0.006694949232041836,
      "learning_rate": 1.0522891566265062e-05,
      "loss": 0.0395,
      "step": 39330
    },
    {
      "epoch": 4.739759036144578,
      "grad_norm": 0.13304796814918518,
      "learning_rate": 1.0520481927710843e-05,
      "loss": 0.0624,
      "step": 39340
    },
    {
      "epoch": 4.740963855421687,
      "grad_norm": 1.696628212928772,
      "learning_rate": 1.0518072289156626e-05,
      "loss": 0.0177,
      "step": 39350
    },
    {
      "epoch": 4.742168674698795,
      "grad_norm": 0.21752026677131653,
      "learning_rate": 1.051566265060241e-05,
      "loss": 0.0421,
      "step": 39360
    },
    {
      "epoch": 4.743373493975904,
      "grad_norm": 0.015411186031997204,
      "learning_rate": 1.0513253012048194e-05,
      "loss": 0.0422,
      "step": 39370
    },
    {
      "epoch": 4.744578313253012,
      "grad_norm": 0.018179912120103836,
      "learning_rate": 1.0510843373493978e-05,
      "loss": 0.0236,
      "step": 39380
    },
    {
      "epoch": 4.7457831325301205,
      "grad_norm": 1.5201603174209595,
      "learning_rate": 1.050843373493976e-05,
      "loss": 0.0195,
      "step": 39390
    },
    {
      "epoch": 4.746987951807229,
      "grad_norm": 0.009590135887265205,
      "learning_rate": 1.0506024096385542e-05,
      "loss": 0.0368,
      "step": 39400
    },
    {
      "epoch": 4.748192771084337,
      "grad_norm": 0.007142668589949608,
      "learning_rate": 1.0503614457831326e-05,
      "loss": 0.0738,
      "step": 39410
    },
    {
      "epoch": 4.749397590361446,
      "grad_norm": 0.1809108853340149,
      "learning_rate": 1.0501204819277109e-05,
      "loss": 0.0289,
      "step": 39420
    },
    {
      "epoch": 4.750602409638554,
      "grad_norm": 0.2110164761543274,
      "learning_rate": 1.0498795180722892e-05,
      "loss": 0.0217,
      "step": 39430
    },
    {
      "epoch": 4.751807228915663,
      "grad_norm": 18.726057052612305,
      "learning_rate": 1.0496385542168677e-05,
      "loss": 0.0462,
      "step": 39440
    },
    {
      "epoch": 4.753012048192771,
      "grad_norm": 0.04618244245648384,
      "learning_rate": 1.049397590361446e-05,
      "loss": 0.0548,
      "step": 39450
    },
    {
      "epoch": 4.7542168674698795,
      "grad_norm": 0.04820358753204346,
      "learning_rate": 1.0491566265060243e-05,
      "loss": 0.0336,
      "step": 39460
    },
    {
      "epoch": 4.755421686746988,
      "grad_norm": 0.5343673229217529,
      "learning_rate": 1.0489156626506025e-05,
      "loss": 0.1224,
      "step": 39470
    },
    {
      "epoch": 4.756626506024096,
      "grad_norm": 0.19701839983463287,
      "learning_rate": 1.0486746987951808e-05,
      "loss": 0.0263,
      "step": 39480
    },
    {
      "epoch": 4.757831325301205,
      "grad_norm": 0.20954419672489166,
      "learning_rate": 1.0484337349397591e-05,
      "loss": 0.0233,
      "step": 39490
    },
    {
      "epoch": 4.759036144578313,
      "grad_norm": 0.07030906528234482,
      "learning_rate": 1.0481927710843374e-05,
      "loss": 0.0562,
      "step": 39500
    },
    {
      "epoch": 4.760240963855422,
      "grad_norm": 2.139841318130493,
      "learning_rate": 1.0479518072289157e-05,
      "loss": 0.0119,
      "step": 39510
    },
    {
      "epoch": 4.76144578313253,
      "grad_norm": 0.025643358007073402,
      "learning_rate": 1.0477108433734942e-05,
      "loss": 0.0369,
      "step": 39520
    },
    {
      "epoch": 4.7626506024096384,
      "grad_norm": 12.81035041809082,
      "learning_rate": 1.0474698795180724e-05,
      "loss": 0.0551,
      "step": 39530
    },
    {
      "epoch": 4.763855421686747,
      "grad_norm": 0.3060642182826996,
      "learning_rate": 1.0472289156626507e-05,
      "loss": 0.0048,
      "step": 39540
    },
    {
      "epoch": 4.765060240963855,
      "grad_norm": 0.37761080265045166,
      "learning_rate": 1.046987951807229e-05,
      "loss": 0.0055,
      "step": 39550
    },
    {
      "epoch": 4.766265060240964,
      "grad_norm": 2.2614595890045166,
      "learning_rate": 1.0467469879518073e-05,
      "loss": 0.0426,
      "step": 39560
    },
    {
      "epoch": 4.767469879518073,
      "grad_norm": 0.005943974480032921,
      "learning_rate": 1.0465060240963856e-05,
      "loss": 0.0241,
      "step": 39570
    },
    {
      "epoch": 4.768674698795181,
      "grad_norm": 2.1084768772125244,
      "learning_rate": 1.0462650602409638e-05,
      "loss": 0.0364,
      "step": 39580
    },
    {
      "epoch": 4.7698795180722895,
      "grad_norm": 0.18318438529968262,
      "learning_rate": 1.0460240963855424e-05,
      "loss": 0.0628,
      "step": 39590
    },
    {
      "epoch": 4.771084337349397,
      "grad_norm": 0.021520357578992844,
      "learning_rate": 1.0457831325301206e-05,
      "loss": 0.0386,
      "step": 39600
    },
    {
      "epoch": 4.772289156626506,
      "grad_norm": 7.201131343841553,
      "learning_rate": 1.0455421686746989e-05,
      "loss": 0.0175,
      "step": 39610
    },
    {
      "epoch": 4.773493975903614,
      "grad_norm": 3.4807608127593994,
      "learning_rate": 1.0453012048192772e-05,
      "loss": 0.1008,
      "step": 39620
    },
    {
      "epoch": 4.774698795180723,
      "grad_norm": 0.04039992019534111,
      "learning_rate": 1.0450602409638555e-05,
      "loss": 0.0247,
      "step": 39630
    },
    {
      "epoch": 4.775903614457832,
      "grad_norm": 9.689262390136719,
      "learning_rate": 1.0448192771084339e-05,
      "loss": 0.0618,
      "step": 39640
    },
    {
      "epoch": 4.77710843373494,
      "grad_norm": 2.4203481674194336,
      "learning_rate": 1.044578313253012e-05,
      "loss": 0.0387,
      "step": 39650
    },
    {
      "epoch": 4.7783132530120485,
      "grad_norm": 0.2732323408126831,
      "learning_rate": 1.0443373493975903e-05,
      "loss": 0.0507,
      "step": 39660
    },
    {
      "epoch": 4.779518072289156,
      "grad_norm": 0.2508178651332855,
      "learning_rate": 1.0440963855421688e-05,
      "loss": 0.046,
      "step": 39670
    },
    {
      "epoch": 4.780722891566265,
      "grad_norm": 0.2856907546520233,
      "learning_rate": 1.0438554216867471e-05,
      "loss": 0.0767,
      "step": 39680
    },
    {
      "epoch": 4.781927710843373,
      "grad_norm": 0.10039753466844559,
      "learning_rate": 1.0436144578313254e-05,
      "loss": 0.0226,
      "step": 39690
    },
    {
      "epoch": 4.783132530120482,
      "grad_norm": 0.4108061194419861,
      "learning_rate": 1.0433734939759038e-05,
      "loss": 0.0403,
      "step": 39700
    },
    {
      "epoch": 4.784337349397591,
      "grad_norm": 0.09811143577098846,
      "learning_rate": 1.0431325301204819e-05,
      "loss": 0.0231,
      "step": 39710
    },
    {
      "epoch": 4.785542168674699,
      "grad_norm": 0.022158307954669,
      "learning_rate": 1.0428915662650602e-05,
      "loss": 0.0214,
      "step": 39720
    },
    {
      "epoch": 4.786746987951807,
      "grad_norm": 2.7225544452667236,
      "learning_rate": 1.0426506024096385e-05,
      "loss": 0.0637,
      "step": 39730
    },
    {
      "epoch": 4.787951807228915,
      "grad_norm": 25.01866340637207,
      "learning_rate": 1.042409638554217e-05,
      "loss": 0.0361,
      "step": 39740
    },
    {
      "epoch": 4.789156626506024,
      "grad_norm": 0.024289937689900398,
      "learning_rate": 1.0421686746987953e-05,
      "loss": 0.0704,
      "step": 39750
    },
    {
      "epoch": 4.790361445783132,
      "grad_norm": 0.3643801212310791,
      "learning_rate": 1.0419277108433737e-05,
      "loss": 0.041,
      "step": 39760
    },
    {
      "epoch": 4.791566265060241,
      "grad_norm": 1.5132067203521729,
      "learning_rate": 1.041686746987952e-05,
      "loss": 0.0362,
      "step": 39770
    },
    {
      "epoch": 4.79277108433735,
      "grad_norm": 0.14441242814064026,
      "learning_rate": 1.0414457831325301e-05,
      "loss": 0.0117,
      "step": 39780
    },
    {
      "epoch": 4.793975903614458,
      "grad_norm": 0.14046990871429443,
      "learning_rate": 1.0412048192771084e-05,
      "loss": 0.0272,
      "step": 39790
    },
    {
      "epoch": 4.795180722891566,
      "grad_norm": 0.016311995685100555,
      "learning_rate": 1.0409638554216868e-05,
      "loss": 0.0344,
      "step": 39800
    },
    {
      "epoch": 4.796385542168675,
      "grad_norm": 0.5428651571273804,
      "learning_rate": 1.0407228915662651e-05,
      "loss": 0.0128,
      "step": 39810
    },
    {
      "epoch": 4.797590361445783,
      "grad_norm": 2.0360701084136963,
      "learning_rate": 1.0404819277108436e-05,
      "loss": 0.0225,
      "step": 39820
    },
    {
      "epoch": 4.798795180722892,
      "grad_norm": 1.1229736804962158,
      "learning_rate": 1.0402409638554219e-05,
      "loss": 0.0139,
      "step": 39830
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.05003243312239647,
      "learning_rate": 1.04e-05,
      "loss": 0.0589,
      "step": 39840
    },
    {
      "epoch": 4.801204819277109,
      "grad_norm": 2.2564609050750732,
      "learning_rate": 1.0397590361445784e-05,
      "loss": 0.0276,
      "step": 39850
    },
    {
      "epoch": 4.8024096385542165,
      "grad_norm": 0.6268957257270813,
      "learning_rate": 1.0395180722891567e-05,
      "loss": 0.0258,
      "step": 39860
    },
    {
      "epoch": 4.803614457831325,
      "grad_norm": 2.504326581954956,
      "learning_rate": 1.039277108433735e-05,
      "loss": 0.0644,
      "step": 39870
    },
    {
      "epoch": 4.804819277108434,
      "grad_norm": 1.1960111856460571,
      "learning_rate": 1.0390361445783133e-05,
      "loss": 0.0622,
      "step": 39880
    },
    {
      "epoch": 4.806024096385542,
      "grad_norm": 0.027258064597845078,
      "learning_rate": 1.0387951807228918e-05,
      "loss": 0.0438,
      "step": 39890
    },
    {
      "epoch": 4.807228915662651,
      "grad_norm": 0.37478598952293396,
      "learning_rate": 1.0385542168674701e-05,
      "loss": 0.0403,
      "step": 39900
    },
    {
      "epoch": 4.808433734939759,
      "grad_norm": 0.18403534591197968,
      "learning_rate": 1.0383132530120483e-05,
      "loss": 0.013,
      "step": 39910
    },
    {
      "epoch": 4.809638554216868,
      "grad_norm": 0.09710544347763062,
      "learning_rate": 1.0380722891566266e-05,
      "loss": 0.0392,
      "step": 39920
    },
    {
      "epoch": 4.8108433734939755,
      "grad_norm": 0.034363336861133575,
      "learning_rate": 1.0378313253012049e-05,
      "loss": 0.0577,
      "step": 39930
    },
    {
      "epoch": 4.812048192771084,
      "grad_norm": 0.7401440739631653,
      "learning_rate": 1.0375903614457832e-05,
      "loss": 0.0367,
      "step": 39940
    },
    {
      "epoch": 4.813253012048193,
      "grad_norm": 2.848137140274048,
      "learning_rate": 1.0373493975903615e-05,
      "loss": 0.0427,
      "step": 39950
    },
    {
      "epoch": 4.814457831325301,
      "grad_norm": 0.08169500529766083,
      "learning_rate": 1.0371084337349397e-05,
      "loss": 0.0325,
      "step": 39960
    },
    {
      "epoch": 4.81566265060241,
      "grad_norm": 0.1283251792192459,
      "learning_rate": 1.0368674698795183e-05,
      "loss": 0.0688,
      "step": 39970
    },
    {
      "epoch": 4.816867469879518,
      "grad_norm": 5.54824686050415,
      "learning_rate": 1.0366265060240965e-05,
      "loss": 0.039,
      "step": 39980
    },
    {
      "epoch": 4.8180722891566266,
      "grad_norm": 3.009228467941284,
      "learning_rate": 1.0363855421686748e-05,
      "loss": 0.048,
      "step": 39990
    },
    {
      "epoch": 4.8192771084337345,
      "grad_norm": 0.017564842477440834,
      "learning_rate": 1.0361445783132531e-05,
      "loss": 0.0639,
      "step": 40000
    },
    {
      "epoch": 4.820481927710843,
      "grad_norm": 3.069758415222168,
      "learning_rate": 1.0359036144578314e-05,
      "loss": 0.0191,
      "step": 40010
    },
    {
      "epoch": 4.821686746987952,
      "grad_norm": 0.02480071596801281,
      "learning_rate": 1.0356626506024096e-05,
      "loss": 0.0134,
      "step": 40020
    },
    {
      "epoch": 4.82289156626506,
      "grad_norm": 4.047642230987549,
      "learning_rate": 1.0354216867469879e-05,
      "loss": 0.0486,
      "step": 40030
    },
    {
      "epoch": 4.824096385542169,
      "grad_norm": 0.0059537566266953945,
      "learning_rate": 1.0351807228915664e-05,
      "loss": 0.0349,
      "step": 40040
    },
    {
      "epoch": 4.825301204819278,
      "grad_norm": 0.045375894755125046,
      "learning_rate": 1.0349397590361447e-05,
      "loss": 0.0381,
      "step": 40050
    },
    {
      "epoch": 4.8265060240963855,
      "grad_norm": 0.19716493785381317,
      "learning_rate": 1.034698795180723e-05,
      "loss": 0.0367,
      "step": 40060
    },
    {
      "epoch": 4.827710843373494,
      "grad_norm": 0.7726275324821472,
      "learning_rate": 1.0344578313253013e-05,
      "loss": 0.0466,
      "step": 40070
    },
    {
      "epoch": 4.828915662650602,
      "grad_norm": 0.15523947775363922,
      "learning_rate": 1.0342168674698797e-05,
      "loss": 0.0496,
      "step": 40080
    },
    {
      "epoch": 4.830120481927711,
      "grad_norm": 3.3760955333709717,
      "learning_rate": 1.0339759036144578e-05,
      "loss": 0.014,
      "step": 40090
    },
    {
      "epoch": 4.831325301204819,
      "grad_norm": 12.87696361541748,
      "learning_rate": 1.0337349397590361e-05,
      "loss": 0.0632,
      "step": 40100
    },
    {
      "epoch": 4.832530120481928,
      "grad_norm": 0.028618650510907173,
      "learning_rate": 1.0334939759036144e-05,
      "loss": 0.0116,
      "step": 40110
    },
    {
      "epoch": 4.833734939759037,
      "grad_norm": 0.008887390606105328,
      "learning_rate": 1.033253012048193e-05,
      "loss": 0.0475,
      "step": 40120
    },
    {
      "epoch": 4.8349397590361445,
      "grad_norm": 0.0727434903383255,
      "learning_rate": 1.0330120481927712e-05,
      "loss": 0.0189,
      "step": 40130
    },
    {
      "epoch": 4.836144578313253,
      "grad_norm": 3.0862326622009277,
      "learning_rate": 1.0327710843373496e-05,
      "loss": 0.0635,
      "step": 40140
    },
    {
      "epoch": 4.837349397590361,
      "grad_norm": 0.03162901848554611,
      "learning_rate": 1.0325301204819279e-05,
      "loss": 0.057,
      "step": 40150
    },
    {
      "epoch": 4.83855421686747,
      "grad_norm": 0.17388609051704407,
      "learning_rate": 1.032289156626506e-05,
      "loss": 0.0281,
      "step": 40160
    },
    {
      "epoch": 4.839759036144578,
      "grad_norm": 0.01094177458435297,
      "learning_rate": 1.0320481927710843e-05,
      "loss": 0.0082,
      "step": 40170
    },
    {
      "epoch": 4.840963855421687,
      "grad_norm": 2.411998987197876,
      "learning_rate": 1.0318072289156627e-05,
      "loss": 0.0591,
      "step": 40180
    },
    {
      "epoch": 4.8421686746987955,
      "grad_norm": 0.2628740072250366,
      "learning_rate": 1.0315662650602412e-05,
      "loss": 0.0183,
      "step": 40190
    },
    {
      "epoch": 4.843373493975903,
      "grad_norm": 6.907576560974121,
      "learning_rate": 1.0313253012048195e-05,
      "loss": 0.0818,
      "step": 40200
    },
    {
      "epoch": 4.844578313253012,
      "grad_norm": 0.07655049115419388,
      "learning_rate": 1.0310843373493978e-05,
      "loss": 0.0082,
      "step": 40210
    },
    {
      "epoch": 4.84578313253012,
      "grad_norm": 0.6136143207550049,
      "learning_rate": 1.030843373493976e-05,
      "loss": 0.0281,
      "step": 40220
    },
    {
      "epoch": 4.846987951807229,
      "grad_norm": 0.005108024924993515,
      "learning_rate": 1.0306024096385543e-05,
      "loss": 0.0273,
      "step": 40230
    },
    {
      "epoch": 4.848192771084337,
      "grad_norm": 0.029155822470784187,
      "learning_rate": 1.0303614457831326e-05,
      "loss": 0.0014,
      "step": 40240
    },
    {
      "epoch": 4.849397590361446,
      "grad_norm": 0.0803256705403328,
      "learning_rate": 1.0301204819277109e-05,
      "loss": 0.037,
      "step": 40250
    },
    {
      "epoch": 4.8506024096385545,
      "grad_norm": 0.003976816311478615,
      "learning_rate": 1.0298795180722892e-05,
      "loss": 0.0235,
      "step": 40260
    },
    {
      "epoch": 4.851807228915662,
      "grad_norm": 1.3236515522003174,
      "learning_rate": 1.0296385542168677e-05,
      "loss": 0.05,
      "step": 40270
    },
    {
      "epoch": 4.853012048192771,
      "grad_norm": 0.004925834015011787,
      "learning_rate": 1.029397590361446e-05,
      "loss": 0.0742,
      "step": 40280
    },
    {
      "epoch": 4.85421686746988,
      "grad_norm": 0.07500172406435013,
      "learning_rate": 1.0291566265060242e-05,
      "loss": 0.0733,
      "step": 40290
    },
    {
      "epoch": 4.855421686746988,
      "grad_norm": 19.892040252685547,
      "learning_rate": 1.0289156626506025e-05,
      "loss": 0.0395,
      "step": 40300
    },
    {
      "epoch": 4.856626506024097,
      "grad_norm": 1.4813352823257446,
      "learning_rate": 1.0286746987951808e-05,
      "loss": 0.0361,
      "step": 40310
    },
    {
      "epoch": 4.857831325301205,
      "grad_norm": 0.02835237979888916,
      "learning_rate": 1.0284337349397591e-05,
      "loss": 0.0353,
      "step": 40320
    },
    {
      "epoch": 4.8590361445783135,
      "grad_norm": 0.012570250779390335,
      "learning_rate": 1.0281927710843374e-05,
      "loss": 0.0362,
      "step": 40330
    },
    {
      "epoch": 4.860240963855421,
      "grad_norm": 0.008137565106153488,
      "learning_rate": 1.027951807228916e-05,
      "loss": 0.0217,
      "step": 40340
    },
    {
      "epoch": 4.86144578313253,
      "grad_norm": 2.520674467086792,
      "learning_rate": 1.027710843373494e-05,
      "loss": 0.0601,
      "step": 40350
    },
    {
      "epoch": 4.862650602409639,
      "grad_norm": 1.8206231594085693,
      "learning_rate": 1.0274698795180724e-05,
      "loss": 0.0375,
      "step": 40360
    },
    {
      "epoch": 4.863855421686747,
      "grad_norm": 2.151641368865967,
      "learning_rate": 1.0272289156626507e-05,
      "loss": 0.0272,
      "step": 40370
    },
    {
      "epoch": 4.865060240963856,
      "grad_norm": 0.7427703738212585,
      "learning_rate": 1.026987951807229e-05,
      "loss": 0.0558,
      "step": 40380
    },
    {
      "epoch": 4.866265060240964,
      "grad_norm": 0.00676761707291007,
      "learning_rate": 1.0267469879518073e-05,
      "loss": 0.0791,
      "step": 40390
    },
    {
      "epoch": 4.867469879518072,
      "grad_norm": 0.049892690032720566,
      "learning_rate": 1.0265060240963855e-05,
      "loss": 0.0051,
      "step": 40400
    },
    {
      "epoch": 4.86867469879518,
      "grad_norm": 2.0659470558166504,
      "learning_rate": 1.0262650602409638e-05,
      "loss": 0.0423,
      "step": 40410
    },
    {
      "epoch": 4.869879518072289,
      "grad_norm": 0.008029174990952015,
      "learning_rate": 1.0260240963855423e-05,
      "loss": 0.0406,
      "step": 40420
    },
    {
      "epoch": 4.871084337349398,
      "grad_norm": 3.942964553833008,
      "learning_rate": 1.0257831325301206e-05,
      "loss": 0.0202,
      "step": 40430
    },
    {
      "epoch": 4.872289156626506,
      "grad_norm": 0.678822934627533,
      "learning_rate": 1.025542168674699e-05,
      "loss": 0.0512,
      "step": 40440
    },
    {
      "epoch": 4.873493975903615,
      "grad_norm": 0.02517198957502842,
      "learning_rate": 1.0253012048192772e-05,
      "loss": 0.0216,
      "step": 40450
    },
    {
      "epoch": 4.874698795180723,
      "grad_norm": 0.01667925715446472,
      "learning_rate": 1.0250602409638556e-05,
      "loss": 0.0052,
      "step": 40460
    },
    {
      "epoch": 4.875903614457831,
      "grad_norm": 2.5102410316467285,
      "learning_rate": 1.0248192771084337e-05,
      "loss": 0.0512,
      "step": 40470
    },
    {
      "epoch": 4.877108433734939,
      "grad_norm": 0.010042157024145126,
      "learning_rate": 1.024578313253012e-05,
      "loss": 0.0194,
      "step": 40480
    },
    {
      "epoch": 4.878313253012048,
      "grad_norm": 1.3077671527862549,
      "learning_rate": 1.0243373493975905e-05,
      "loss": 0.0167,
      "step": 40490
    },
    {
      "epoch": 4.879518072289157,
      "grad_norm": 1.2122795581817627,
      "learning_rate": 1.0240963855421688e-05,
      "loss": 0.0241,
      "step": 40500
    },
    {
      "epoch": 4.880722891566265,
      "grad_norm": 0.00628191651776433,
      "learning_rate": 1.0238554216867471e-05,
      "loss": 0.0373,
      "step": 40510
    },
    {
      "epoch": 4.881927710843374,
      "grad_norm": 0.27000150084495544,
      "learning_rate": 1.0236144578313255e-05,
      "loss": 0.0311,
      "step": 40520
    },
    {
      "epoch": 4.8831325301204815,
      "grad_norm": 0.4726022481918335,
      "learning_rate": 1.0233734939759036e-05,
      "loss": 0.0375,
      "step": 40530
    },
    {
      "epoch": 4.88433734939759,
      "grad_norm": 22.351957321166992,
      "learning_rate": 1.023132530120482e-05,
      "loss": 0.0625,
      "step": 40540
    },
    {
      "epoch": 4.885542168674699,
      "grad_norm": 1.7373210191726685,
      "learning_rate": 1.0228915662650602e-05,
      "loss": 0.0131,
      "step": 40550
    },
    {
      "epoch": 4.886746987951807,
      "grad_norm": 0.055671676993370056,
      "learning_rate": 1.0226506024096386e-05,
      "loss": 0.0519,
      "step": 40560
    },
    {
      "epoch": 4.887951807228916,
      "grad_norm": 0.1304498314857483,
      "learning_rate": 1.022409638554217e-05,
      "loss": 0.0138,
      "step": 40570
    },
    {
      "epoch": 4.889156626506024,
      "grad_norm": 0.00663197273388505,
      "learning_rate": 1.0221686746987954e-05,
      "loss": 0.0398,
      "step": 40580
    },
    {
      "epoch": 4.890361445783133,
      "grad_norm": 0.01742052473127842,
      "learning_rate": 1.0219277108433737e-05,
      "loss": 0.0398,
      "step": 40590
    },
    {
      "epoch": 4.891566265060241,
      "grad_norm": 0.008195562288165092,
      "learning_rate": 1.0216867469879518e-05,
      "loss": 0.0195,
      "step": 40600
    },
    {
      "epoch": 4.892771084337349,
      "grad_norm": 0.0183012243360281,
      "learning_rate": 1.0214457831325302e-05,
      "loss": 0.0231,
      "step": 40610
    },
    {
      "epoch": 4.893975903614458,
      "grad_norm": 0.15541790425777435,
      "learning_rate": 1.0212048192771085e-05,
      "loss": 0.0193,
      "step": 40620
    },
    {
      "epoch": 4.895180722891566,
      "grad_norm": 0.005667050834745169,
      "learning_rate": 1.0209638554216868e-05,
      "loss": 0.008,
      "step": 40630
    },
    {
      "epoch": 4.896385542168675,
      "grad_norm": 3.82875394821167,
      "learning_rate": 1.0207228915662653e-05,
      "loss": 0.0536,
      "step": 40640
    },
    {
      "epoch": 4.897590361445783,
      "grad_norm": 0.038317933678627014,
      "learning_rate": 1.0204819277108436e-05,
      "loss": 0.0882,
      "step": 40650
    },
    {
      "epoch": 4.8987951807228916,
      "grad_norm": 1.289568305015564,
      "learning_rate": 1.0202409638554217e-05,
      "loss": 0.0062,
      "step": 40660
    },
    {
      "epoch": 4.9,
      "grad_norm": 4.107856750488281,
      "learning_rate": 1.02e-05,
      "loss": 0.0241,
      "step": 40670
    },
    {
      "epoch": 4.901204819277108,
      "grad_norm": 6.260507583618164,
      "learning_rate": 1.0197590361445784e-05,
      "loss": 0.0354,
      "step": 40680
    },
    {
      "epoch": 4.902409638554217,
      "grad_norm": 1.7364953756332397,
      "learning_rate": 1.0195180722891567e-05,
      "loss": 0.0087,
      "step": 40690
    },
    {
      "epoch": 4.903614457831325,
      "grad_norm": 0.11374901980161667,
      "learning_rate": 1.019277108433735e-05,
      "loss": 0.0181,
      "step": 40700
    },
    {
      "epoch": 4.904819277108434,
      "grad_norm": 0.022755466401576996,
      "learning_rate": 1.0190361445783132e-05,
      "loss": 0.0354,
      "step": 40710
    },
    {
      "epoch": 4.906024096385542,
      "grad_norm": 4.684787750244141,
      "learning_rate": 1.0187951807228918e-05,
      "loss": 0.0648,
      "step": 40720
    },
    {
      "epoch": 4.9072289156626505,
      "grad_norm": 1.6952979564666748,
      "learning_rate": 1.01855421686747e-05,
      "loss": 0.0578,
      "step": 40730
    },
    {
      "epoch": 4.908433734939759,
      "grad_norm": 2.9593849182128906,
      "learning_rate": 1.0183132530120483e-05,
      "loss": 0.0402,
      "step": 40740
    },
    {
      "epoch": 4.909638554216867,
      "grad_norm": 1.6235780715942383,
      "learning_rate": 1.0180722891566266e-05,
      "loss": 0.0213,
      "step": 40750
    },
    {
      "epoch": 4.910843373493976,
      "grad_norm": 0.009117885492742062,
      "learning_rate": 1.017831325301205e-05,
      "loss": 0.0132,
      "step": 40760
    },
    {
      "epoch": 4.912048192771084,
      "grad_norm": 1.749782681465149,
      "learning_rate": 1.0175903614457832e-05,
      "loss": 0.0463,
      "step": 40770
    },
    {
      "epoch": 4.913253012048193,
      "grad_norm": 0.02105574868619442,
      "learning_rate": 1.0173493975903614e-05,
      "loss": 0.0021,
      "step": 40780
    },
    {
      "epoch": 4.914457831325302,
      "grad_norm": 0.10871687531471252,
      "learning_rate": 1.0171084337349399e-05,
      "loss": 0.028,
      "step": 40790
    },
    {
      "epoch": 4.9156626506024095,
      "grad_norm": 0.006388761103153229,
      "learning_rate": 1.0168674698795182e-05,
      "loss": 0.0442,
      "step": 40800
    },
    {
      "epoch": 4.916867469879518,
      "grad_norm": 2.9410042762756348,
      "learning_rate": 1.0166265060240965e-05,
      "loss": 0.011,
      "step": 40810
    },
    {
      "epoch": 4.918072289156626,
      "grad_norm": 3.7346911430358887,
      "learning_rate": 1.0163855421686748e-05,
      "loss": 0.0509,
      "step": 40820
    },
    {
      "epoch": 4.919277108433735,
      "grad_norm": 0.7008975148200989,
      "learning_rate": 1.0161445783132531e-05,
      "loss": 0.0608,
      "step": 40830
    },
    {
      "epoch": 4.920481927710844,
      "grad_norm": 0.004118006676435471,
      "learning_rate": 1.0159036144578313e-05,
      "loss": 0.0381,
      "step": 40840
    },
    {
      "epoch": 4.921686746987952,
      "grad_norm": 3.966592311859131,
      "learning_rate": 1.0156626506024096e-05,
      "loss": 0.0508,
      "step": 40850
    },
    {
      "epoch": 4.9228915662650605,
      "grad_norm": 0.011158770881593227,
      "learning_rate": 1.015421686746988e-05,
      "loss": 0.0204,
      "step": 40860
    },
    {
      "epoch": 4.924096385542168,
      "grad_norm": 0.8027259111404419,
      "learning_rate": 1.0151807228915664e-05,
      "loss": 0.0094,
      "step": 40870
    },
    {
      "epoch": 4.925301204819277,
      "grad_norm": 0.18621794879436493,
      "learning_rate": 1.0149397590361447e-05,
      "loss": 0.0148,
      "step": 40880
    },
    {
      "epoch": 4.926506024096385,
      "grad_norm": 0.6389697790145874,
      "learning_rate": 1.014698795180723e-05,
      "loss": 0.0874,
      "step": 40890
    },
    {
      "epoch": 4.927710843373494,
      "grad_norm": 8.433414459228516,
      "learning_rate": 1.0144578313253014e-05,
      "loss": 0.0634,
      "step": 40900
    },
    {
      "epoch": 4.928915662650603,
      "grad_norm": 0.1888425499200821,
      "learning_rate": 1.0142168674698795e-05,
      "loss": 0.0016,
      "step": 40910
    },
    {
      "epoch": 4.930120481927711,
      "grad_norm": 0.013744431547820568,
      "learning_rate": 1.0139759036144578e-05,
      "loss": 0.1927,
      "step": 40920
    },
    {
      "epoch": 4.9313253012048195,
      "grad_norm": 0.0232734065502882,
      "learning_rate": 1.0137349397590361e-05,
      "loss": 0.0196,
      "step": 40930
    },
    {
      "epoch": 4.932530120481927,
      "grad_norm": 1.585771918296814,
      "learning_rate": 1.0134939759036146e-05,
      "loss": 0.0626,
      "step": 40940
    },
    {
      "epoch": 4.933734939759036,
      "grad_norm": 0.21967177093029022,
      "learning_rate": 1.013253012048193e-05,
      "loss": 0.0357,
      "step": 40950
    },
    {
      "epoch": 4.934939759036144,
      "grad_norm": 0.010022084228694439,
      "learning_rate": 1.0130120481927713e-05,
      "loss": 0.0143,
      "step": 40960
    },
    {
      "epoch": 4.936144578313253,
      "grad_norm": 0.01384731288999319,
      "learning_rate": 1.0127710843373494e-05,
      "loss": 0.0688,
      "step": 40970
    },
    {
      "epoch": 4.937349397590362,
      "grad_norm": 0.015724893659353256,
      "learning_rate": 1.0125301204819277e-05,
      "loss": 0.0055,
      "step": 40980
    },
    {
      "epoch": 4.93855421686747,
      "grad_norm": 0.05176830291748047,
      "learning_rate": 1.012289156626506e-05,
      "loss": 0.0138,
      "step": 40990
    },
    {
      "epoch": 4.9397590361445785,
      "grad_norm": 2.2192165851593018,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 0.0625,
      "step": 41000
    },
    {
      "epoch": 4.940963855421686,
      "grad_norm": 0.6814061999320984,
      "learning_rate": 1.0118072289156627e-05,
      "loss": 0.0445,
      "step": 41010
    },
    {
      "epoch": 4.942168674698795,
      "grad_norm": 0.035822849720716476,
      "learning_rate": 1.0115662650602412e-05,
      "loss": 0.0207,
      "step": 41020
    },
    {
      "epoch": 4.943373493975904,
      "grad_norm": 4.537700176239014,
      "learning_rate": 1.0113253012048195e-05,
      "loss": 0.0476,
      "step": 41030
    },
    {
      "epoch": 4.944578313253012,
      "grad_norm": 1.8469916582107544,
      "learning_rate": 1.0110843373493976e-05,
      "loss": 0.038,
      "step": 41040
    },
    {
      "epoch": 4.945783132530121,
      "grad_norm": 0.05922996625304222,
      "learning_rate": 1.010843373493976e-05,
      "loss": 0.0296,
      "step": 41050
    },
    {
      "epoch": 4.946987951807229,
      "grad_norm": 6.327383518218994,
      "learning_rate": 1.0106024096385543e-05,
      "loss": 0.0223,
      "step": 41060
    },
    {
      "epoch": 4.948192771084337,
      "grad_norm": 1.615261435508728,
      "learning_rate": 1.0103614457831326e-05,
      "loss": 0.0795,
      "step": 41070
    },
    {
      "epoch": 4.949397590361446,
      "grad_norm": 0.4238124489784241,
      "learning_rate": 1.0101204819277109e-05,
      "loss": 0.0361,
      "step": 41080
    },
    {
      "epoch": 4.950602409638554,
      "grad_norm": 2.950267791748047,
      "learning_rate": 1.0098795180722894e-05,
      "loss": 0.0631,
      "step": 41090
    },
    {
      "epoch": 4.951807228915663,
      "grad_norm": 2.1286654472351074,
      "learning_rate": 1.0096385542168675e-05,
      "loss": 0.0647,
      "step": 41100
    },
    {
      "epoch": 4.953012048192771,
      "grad_norm": 0.031068390235304832,
      "learning_rate": 1.0093975903614459e-05,
      "loss": 0.0073,
      "step": 41110
    },
    {
      "epoch": 4.95421686746988,
      "grad_norm": 0.033268820494413376,
      "learning_rate": 1.0091566265060242e-05,
      "loss": 0.0425,
      "step": 41120
    },
    {
      "epoch": 4.955421686746988,
      "grad_norm": 0.05527747422456741,
      "learning_rate": 1.0089156626506025e-05,
      "loss": 0.0282,
      "step": 41130
    },
    {
      "epoch": 4.956626506024096,
      "grad_norm": 1.7114404439926147,
      "learning_rate": 1.0086746987951808e-05,
      "loss": 0.0471,
      "step": 41140
    },
    {
      "epoch": 4.957831325301205,
      "grad_norm": 0.03628821298480034,
      "learning_rate": 1.008433734939759e-05,
      "loss": 0.0171,
      "step": 41150
    },
    {
      "epoch": 4.959036144578313,
      "grad_norm": 1.4927799701690674,
      "learning_rate": 1.0081927710843373e-05,
      "loss": 0.028,
      "step": 41160
    },
    {
      "epoch": 4.960240963855422,
      "grad_norm": 0.6118289828300476,
      "learning_rate": 1.0079518072289158e-05,
      "loss": 0.0322,
      "step": 41170
    },
    {
      "epoch": 4.96144578313253,
      "grad_norm": 1.4515854120254517,
      "learning_rate": 1.0077108433734941e-05,
      "loss": 0.0675,
      "step": 41180
    },
    {
      "epoch": 4.962650602409639,
      "grad_norm": 0.013900984078645706,
      "learning_rate": 1.0074698795180724e-05,
      "loss": 0.019,
      "step": 41190
    },
    {
      "epoch": 4.9638554216867465,
      "grad_norm": 0.0185332540422678,
      "learning_rate": 1.0072289156626507e-05,
      "loss": 0.0275,
      "step": 41200
    },
    {
      "epoch": 4.965060240963855,
      "grad_norm": 3.0816123485565186,
      "learning_rate": 1.006987951807229e-05,
      "loss": 0.0147,
      "step": 41210
    },
    {
      "epoch": 4.966265060240964,
      "grad_norm": 0.05732912942767143,
      "learning_rate": 1.0067469879518072e-05,
      "loss": 0.0027,
      "step": 41220
    },
    {
      "epoch": 4.967469879518072,
      "grad_norm": 4.436956882476807,
      "learning_rate": 1.0065060240963855e-05,
      "loss": 0.0245,
      "step": 41230
    },
    {
      "epoch": 4.968674698795181,
      "grad_norm": 0.00870382972061634,
      "learning_rate": 1.006265060240964e-05,
      "loss": 0.0702,
      "step": 41240
    },
    {
      "epoch": 4.969879518072289,
      "grad_norm": 31.37407875061035,
      "learning_rate": 1.0060240963855423e-05,
      "loss": 0.017,
      "step": 41250
    },
    {
      "epoch": 4.971084337349398,
      "grad_norm": 0.007472849451005459,
      "learning_rate": 1.0057831325301206e-05,
      "loss": 0.0967,
      "step": 41260
    },
    {
      "epoch": 4.972289156626506,
      "grad_norm": 0.8472427129745483,
      "learning_rate": 1.005542168674699e-05,
      "loss": 0.0481,
      "step": 41270
    },
    {
      "epoch": 4.973493975903614,
      "grad_norm": 0.025772228837013245,
      "learning_rate": 1.0053012048192771e-05,
      "loss": 0.0449,
      "step": 41280
    },
    {
      "epoch": 4.974698795180723,
      "grad_norm": 0.09534978121519089,
      "learning_rate": 1.0050602409638554e-05,
      "loss": 0.045,
      "step": 41290
    },
    {
      "epoch": 4.975903614457831,
      "grad_norm": 0.041535839438438416,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 0.0136,
      "step": 41300
    },
    {
      "epoch": 4.97710843373494,
      "grad_norm": 0.014710122719407082,
      "learning_rate": 1.004578313253012e-05,
      "loss": 0.04,
      "step": 41310
    },
    {
      "epoch": 4.978313253012049,
      "grad_norm": 5.391842365264893,
      "learning_rate": 1.0043373493975905e-05,
      "loss": 0.0475,
      "step": 41320
    },
    {
      "epoch": 4.9795180722891565,
      "grad_norm": 0.019275149330496788,
      "learning_rate": 1.0040963855421689e-05,
      "loss": 0.0014,
      "step": 41330
    },
    {
      "epoch": 4.980722891566265,
      "grad_norm": 0.36144936084747314,
      "learning_rate": 1.0038554216867472e-05,
      "loss": 0.0275,
      "step": 41340
    },
    {
      "epoch": 4.981927710843373,
      "grad_norm": 0.11759904772043228,
      "learning_rate": 1.0036144578313253e-05,
      "loss": 0.0363,
      "step": 41350
    },
    {
      "epoch": 4.983132530120482,
      "grad_norm": 0.03595032915472984,
      "learning_rate": 1.0033734939759036e-05,
      "loss": 0.0019,
      "step": 41360
    },
    {
      "epoch": 4.98433734939759,
      "grad_norm": 5.03254508972168,
      "learning_rate": 1.003132530120482e-05,
      "loss": 0.0607,
      "step": 41370
    },
    {
      "epoch": 4.985542168674699,
      "grad_norm": 0.007561847101897001,
      "learning_rate": 1.0028915662650603e-05,
      "loss": 0.0064,
      "step": 41380
    },
    {
      "epoch": 4.986746987951808,
      "grad_norm": 3.674306631088257,
      "learning_rate": 1.0026506024096388e-05,
      "loss": 0.0474,
      "step": 41390
    },
    {
      "epoch": 4.9879518072289155,
      "grad_norm": 0.26385730504989624,
      "learning_rate": 1.002409638554217e-05,
      "loss": 0.0193,
      "step": 41400
    },
    {
      "epoch": 4.989156626506024,
      "grad_norm": 0.02943452261388302,
      "learning_rate": 1.0021686746987952e-05,
      "loss": 0.0233,
      "step": 41410
    },
    {
      "epoch": 4.990361445783132,
      "grad_norm": 0.00816773809492588,
      "learning_rate": 1.0019277108433735e-05,
      "loss": 0.0185,
      "step": 41420
    },
    {
      "epoch": 4.991566265060241,
      "grad_norm": 0.20964036881923676,
      "learning_rate": 1.0016867469879519e-05,
      "loss": 0.0401,
      "step": 41430
    },
    {
      "epoch": 4.992771084337349,
      "grad_norm": 0.00547872856259346,
      "learning_rate": 1.0014457831325302e-05,
      "loss": 0.0185,
      "step": 41440
    },
    {
      "epoch": 4.993975903614458,
      "grad_norm": 0.1554560661315918,
      "learning_rate": 1.0012048192771085e-05,
      "loss": 0.035,
      "step": 41450
    },
    {
      "epoch": 4.995180722891567,
      "grad_norm": 0.10437936335802078,
      "learning_rate": 1.0009638554216866e-05,
      "loss": 0.0237,
      "step": 41460
    },
    {
      "epoch": 4.9963855421686745,
      "grad_norm": 0.24502643942832947,
      "learning_rate": 1.0007228915662653e-05,
      "loss": 0.0376,
      "step": 41470
    },
    {
      "epoch": 4.997590361445783,
      "grad_norm": 0.007192469201982021,
      "learning_rate": 1.0004819277108434e-05,
      "loss": 0.0077,
      "step": 41480
    },
    {
      "epoch": 4.998795180722891,
      "grad_norm": 16.789777755737305,
      "learning_rate": 1.0002409638554218e-05,
      "loss": 0.0225,
      "step": 41490
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.4879993200302124,
      "learning_rate": 1e-05,
      "loss": 0.016,
      "step": 41500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9835958005249343,
      "eval_f1": 0.9555499110998222,
      "eval_loss": 0.06421676278114319,
      "eval_precision": 0.9826302729528535,
      "eval_recall": 0.9299221357063404,
      "eval_runtime": 4965.2003,
      "eval_samples_per_second": 8.598,
      "eval_steps_per_second": 0.358,
      "step": 41500
    },
    {
      "epoch": 5.001204819277109,
      "grad_norm": 0.2070680409669876,
      "learning_rate": 9.997590361445784e-06,
      "loss": 0.0834,
      "step": 41510
    },
    {
      "epoch": 5.002409638554217,
      "grad_norm": 0.04664737731218338,
      "learning_rate": 9.995180722891567e-06,
      "loss": 0.0503,
      "step": 41520
    },
    {
      "epoch": 5.0036144578313255,
      "grad_norm": 2.089219093322754,
      "learning_rate": 9.99277108433735e-06,
      "loss": 0.0181,
      "step": 41530
    },
    {
      "epoch": 5.004819277108433,
      "grad_norm": 0.3196810483932495,
      "learning_rate": 9.990361445783134e-06,
      "loss": 0.0321,
      "step": 41540
    },
    {
      "epoch": 5.006024096385542,
      "grad_norm": 0.7297643423080444,
      "learning_rate": 9.987951807228917e-06,
      "loss": 0.0364,
      "step": 41550
    },
    {
      "epoch": 5.00722891566265,
      "grad_norm": 0.22341319918632507,
      "learning_rate": 9.9855421686747e-06,
      "loss": 0.0711,
      "step": 41560
    },
    {
      "epoch": 5.008433734939759,
      "grad_norm": 0.15463578701019287,
      "learning_rate": 9.983132530120483e-06,
      "loss": 0.0134,
      "step": 41570
    },
    {
      "epoch": 5.009638554216868,
      "grad_norm": 3.3667478561401367,
      "learning_rate": 9.980722891566266e-06,
      "loss": 0.0699,
      "step": 41580
    },
    {
      "epoch": 5.010843373493976,
      "grad_norm": 0.018997009843587875,
      "learning_rate": 9.97831325301205e-06,
      "loss": 0.0148,
      "step": 41590
    },
    {
      "epoch": 5.0120481927710845,
      "grad_norm": 0.2527492642402649,
      "learning_rate": 9.975903614457833e-06,
      "loss": 0.0073,
      "step": 41600
    },
    {
      "epoch": 5.013253012048192,
      "grad_norm": 0.039911746978759766,
      "learning_rate": 9.973493975903616e-06,
      "loss": 0.0418,
      "step": 41610
    },
    {
      "epoch": 5.014457831325301,
      "grad_norm": 0.061417240649461746,
      "learning_rate": 9.971084337349399e-06,
      "loss": 0.0108,
      "step": 41620
    },
    {
      "epoch": 5.01566265060241,
      "grad_norm": 0.21132372319698334,
      "learning_rate": 9.96867469879518e-06,
      "loss": 0.0093,
      "step": 41630
    },
    {
      "epoch": 5.016867469879518,
      "grad_norm": 0.2481038123369217,
      "learning_rate": 9.966265060240965e-06,
      "loss": 0.0008,
      "step": 41640
    },
    {
      "epoch": 5.018072289156627,
      "grad_norm": 0.026752090081572533,
      "learning_rate": 9.963855421686748e-06,
      "loss": 0.0376,
      "step": 41650
    },
    {
      "epoch": 5.019277108433735,
      "grad_norm": 1.5756168365478516,
      "learning_rate": 9.96144578313253e-06,
      "loss": 0.0416,
      "step": 41660
    },
    {
      "epoch": 5.0204819277108435,
      "grad_norm": 0.03654488921165466,
      "learning_rate": 9.959036144578315e-06,
      "loss": 0.0635,
      "step": 41670
    },
    {
      "epoch": 5.021686746987951,
      "grad_norm": 0.20445720851421356,
      "learning_rate": 9.956626506024098e-06,
      "loss": 0.0164,
      "step": 41680
    },
    {
      "epoch": 5.02289156626506,
      "grad_norm": 0.22676561772823334,
      "learning_rate": 9.95421686746988e-06,
      "loss": 0.0722,
      "step": 41690
    },
    {
      "epoch": 5.024096385542169,
      "grad_norm": 1.0792516469955444,
      "learning_rate": 9.951807228915663e-06,
      "loss": 0.0165,
      "step": 41700
    },
    {
      "epoch": 5.025301204819277,
      "grad_norm": 1.5296117067337036,
      "learning_rate": 9.949397590361448e-06,
      "loss": 0.0305,
      "step": 41710
    },
    {
      "epoch": 5.026506024096386,
      "grad_norm": 0.7681556344032288,
      "learning_rate": 9.94698795180723e-06,
      "loss": 0.0576,
      "step": 41720
    },
    {
      "epoch": 5.027710843373494,
      "grad_norm": 2.232795238494873,
      "learning_rate": 9.944578313253012e-06,
      "loss": 0.0978,
      "step": 41730
    },
    {
      "epoch": 5.028915662650602,
      "grad_norm": 0.022010691463947296,
      "learning_rate": 9.942168674698795e-06,
      "loss": 0.0265,
      "step": 41740
    },
    {
      "epoch": 5.030120481927711,
      "grad_norm": 0.5691163539886475,
      "learning_rate": 9.93975903614458e-06,
      "loss": 0.0222,
      "step": 41750
    },
    {
      "epoch": 5.031325301204819,
      "grad_norm": 0.2768738865852356,
      "learning_rate": 9.937349397590362e-06,
      "loss": 0.0194,
      "step": 41760
    },
    {
      "epoch": 5.032530120481928,
      "grad_norm": 50.263587951660156,
      "learning_rate": 9.934939759036145e-06,
      "loss": 0.0522,
      "step": 41770
    },
    {
      "epoch": 5.033734939759036,
      "grad_norm": 0.03223414719104767,
      "learning_rate": 9.932530120481928e-06,
      "loss": 0.0035,
      "step": 41780
    },
    {
      "epoch": 5.034939759036145,
      "grad_norm": 0.03431390970945358,
      "learning_rate": 9.930120481927711e-06,
      "loss": 0.0064,
      "step": 41790
    },
    {
      "epoch": 5.036144578313253,
      "grad_norm": 0.8274597525596619,
      "learning_rate": 9.927710843373494e-06,
      "loss": 0.0103,
      "step": 41800
    },
    {
      "epoch": 5.037349397590361,
      "grad_norm": 0.009093762375414371,
      "learning_rate": 9.925301204819278e-06,
      "loss": 0.0772,
      "step": 41810
    },
    {
      "epoch": 5.03855421686747,
      "grad_norm": 1.8993040323257446,
      "learning_rate": 9.92289156626506e-06,
      "loss": 0.0222,
      "step": 41820
    },
    {
      "epoch": 5.039759036144578,
      "grad_norm": 1.3861044645309448,
      "learning_rate": 9.920481927710844e-06,
      "loss": 0.0204,
      "step": 41830
    },
    {
      "epoch": 5.040963855421687,
      "grad_norm": 0.003944581374526024,
      "learning_rate": 9.918072289156627e-06,
      "loss": 0.0316,
      "step": 41840
    },
    {
      "epoch": 5.042168674698795,
      "grad_norm": 0.058126386255025864,
      "learning_rate": 9.91566265060241e-06,
      "loss": 0.0265,
      "step": 41850
    },
    {
      "epoch": 5.043373493975904,
      "grad_norm": 0.41191065311431885,
      "learning_rate": 9.913253012048193e-06,
      "loss": 0.0307,
      "step": 41860
    },
    {
      "epoch": 5.044578313253012,
      "grad_norm": 0.04077139496803284,
      "learning_rate": 9.910843373493977e-06,
      "loss": 0.0287,
      "step": 41870
    },
    {
      "epoch": 5.04578313253012,
      "grad_norm": 1.0229820013046265,
      "learning_rate": 9.90843373493976e-06,
      "loss": 0.0032,
      "step": 41880
    },
    {
      "epoch": 5.046987951807229,
      "grad_norm": 0.14889073371887207,
      "learning_rate": 9.906024096385543e-06,
      "loss": 0.0214,
      "step": 41890
    },
    {
      "epoch": 5.048192771084337,
      "grad_norm": 0.23339690268039703,
      "learning_rate": 9.903614457831326e-06,
      "loss": 0.0102,
      "step": 41900
    },
    {
      "epoch": 5.049397590361446,
      "grad_norm": 0.002384745981544256,
      "learning_rate": 9.90120481927711e-06,
      "loss": 0.0377,
      "step": 41910
    },
    {
      "epoch": 5.050602409638554,
      "grad_norm": 1.8951690196990967,
      "learning_rate": 9.898795180722893e-06,
      "loss": 0.0053,
      "step": 41920
    },
    {
      "epoch": 5.051807228915663,
      "grad_norm": 0.03530278429389,
      "learning_rate": 9.896385542168676e-06,
      "loss": 0.0798,
      "step": 41930
    },
    {
      "epoch": 5.053012048192771,
      "grad_norm": 0.4208902418613434,
      "learning_rate": 9.893975903614459e-06,
      "loss": 0.0026,
      "step": 41940
    },
    {
      "epoch": 5.054216867469879,
      "grad_norm": 0.015193221159279346,
      "learning_rate": 9.891566265060242e-06,
      "loss": 0.0511,
      "step": 41950
    },
    {
      "epoch": 5.055421686746988,
      "grad_norm": 1.2749760150909424,
      "learning_rate": 9.889156626506025e-06,
      "loss": 0.0254,
      "step": 41960
    },
    {
      "epoch": 5.056626506024096,
      "grad_norm": 0.04124045372009277,
      "learning_rate": 9.886746987951808e-06,
      "loss": 0.0049,
      "step": 41970
    },
    {
      "epoch": 5.057831325301205,
      "grad_norm": 0.02759469486773014,
      "learning_rate": 9.884337349397592e-06,
      "loss": 0.007,
      "step": 41980
    },
    {
      "epoch": 5.059036144578314,
      "grad_norm": 0.010657113045454025,
      "learning_rate": 9.881927710843375e-06,
      "loss": 0.0088,
      "step": 41990
    },
    {
      "epoch": 5.0602409638554215,
      "grad_norm": 4.986264228820801,
      "learning_rate": 9.879518072289156e-06,
      "loss": 0.0449,
      "step": 42000
    },
    {
      "epoch": 5.06144578313253,
      "grad_norm": 0.00499578146263957,
      "learning_rate": 9.877108433734941e-06,
      "loss": 0.0094,
      "step": 42010
    },
    {
      "epoch": 5.062650602409638,
      "grad_norm": 1.382845401763916,
      "learning_rate": 9.874698795180724e-06,
      "loss": 0.0191,
      "step": 42020
    },
    {
      "epoch": 5.063855421686747,
      "grad_norm": 2.886598587036133,
      "learning_rate": 9.872289156626507e-06,
      "loss": 0.0361,
      "step": 42030
    },
    {
      "epoch": 5.065060240963855,
      "grad_norm": 0.03956318646669388,
      "learning_rate": 9.869879518072289e-06,
      "loss": 0.0128,
      "step": 42040
    },
    {
      "epoch": 5.066265060240964,
      "grad_norm": 1.8086867332458496,
      "learning_rate": 9.867469879518074e-06,
      "loss": 0.0195,
      "step": 42050
    },
    {
      "epoch": 5.067469879518073,
      "grad_norm": 0.0034504833165556192,
      "learning_rate": 9.865060240963857e-06,
      "loss": 0.0096,
      "step": 42060
    },
    {
      "epoch": 5.0686746987951805,
      "grad_norm": 0.15998701751232147,
      "learning_rate": 9.862650602409638e-06,
      "loss": 0.0389,
      "step": 42070
    },
    {
      "epoch": 5.069879518072289,
      "grad_norm": 0.0026431288570165634,
      "learning_rate": 9.860240963855422e-06,
      "loss": 0.0375,
      "step": 42080
    },
    {
      "epoch": 5.071084337349397,
      "grad_norm": 1.54654061794281,
      "learning_rate": 9.857831325301207e-06,
      "loss": 0.0217,
      "step": 42090
    },
    {
      "epoch": 5.072289156626506,
      "grad_norm": 0.002416792791336775,
      "learning_rate": 9.855421686746988e-06,
      "loss": 0.0006,
      "step": 42100
    },
    {
      "epoch": 5.073493975903615,
      "grad_norm": 2.3339836597442627,
      "learning_rate": 9.853012048192771e-06,
      "loss": 0.024,
      "step": 42110
    },
    {
      "epoch": 5.074698795180723,
      "grad_norm": 0.0026137286331504583,
      "learning_rate": 9.850602409638556e-06,
      "loss": 0.0272,
      "step": 42120
    },
    {
      "epoch": 5.075903614457832,
      "grad_norm": 0.0015403880970552564,
      "learning_rate": 9.848192771084338e-06,
      "loss": 0.058,
      "step": 42130
    },
    {
      "epoch": 5.0771084337349395,
      "grad_norm": 0.29230546951293945,
      "learning_rate": 9.84578313253012e-06,
      "loss": 0.01,
      "step": 42140
    },
    {
      "epoch": 5.078313253012048,
      "grad_norm": 0.0041710552759468555,
      "learning_rate": 9.843373493975904e-06,
      "loss": 0.0339,
      "step": 42150
    },
    {
      "epoch": 5.079518072289156,
      "grad_norm": 3.9993343353271484,
      "learning_rate": 9.840963855421689e-06,
      "loss": 0.0296,
      "step": 42160
    },
    {
      "epoch": 5.080722891566265,
      "grad_norm": 0.0789937898516655,
      "learning_rate": 9.83855421686747e-06,
      "loss": 0.0444,
      "step": 42170
    },
    {
      "epoch": 5.081927710843374,
      "grad_norm": 0.6866410374641418,
      "learning_rate": 9.836144578313253e-06,
      "loss": 0.0049,
      "step": 42180
    },
    {
      "epoch": 5.083132530120482,
      "grad_norm": 0.018069414421916008,
      "learning_rate": 9.833734939759037e-06,
      "loss": 0.0642,
      "step": 42190
    },
    {
      "epoch": 5.0843373493975905,
      "grad_norm": 1.3298953771591187,
      "learning_rate": 9.83132530120482e-06,
      "loss": 0.0192,
      "step": 42200
    },
    {
      "epoch": 5.085542168674698,
      "grad_norm": 0.002308659953996539,
      "learning_rate": 9.828915662650603e-06,
      "loss": 0.0513,
      "step": 42210
    },
    {
      "epoch": 5.086746987951807,
      "grad_norm": 4.126580238342285,
      "learning_rate": 9.826506024096386e-06,
      "loss": 0.0593,
      "step": 42220
    },
    {
      "epoch": 5.087951807228916,
      "grad_norm": 0.07835500687360764,
      "learning_rate": 9.82409638554217e-06,
      "loss": 0.0278,
      "step": 42230
    },
    {
      "epoch": 5.089156626506024,
      "grad_norm": 0.06480380147695541,
      "learning_rate": 9.821686746987952e-06,
      "loss": 0.0154,
      "step": 42240
    },
    {
      "epoch": 5.090361445783133,
      "grad_norm": 0.13519902527332306,
      "learning_rate": 9.819277108433736e-06,
      "loss": 0.0521,
      "step": 42250
    },
    {
      "epoch": 5.091566265060241,
      "grad_norm": 1.1423357725143433,
      "learning_rate": 9.816867469879519e-06,
      "loss": 0.0171,
      "step": 42260
    },
    {
      "epoch": 5.0927710843373495,
      "grad_norm": 0.0036030588671565056,
      "learning_rate": 9.814457831325302e-06,
      "loss": 0.015,
      "step": 42270
    },
    {
      "epoch": 5.093975903614457,
      "grad_norm": 0.12666237354278564,
      "learning_rate": 9.812048192771085e-06,
      "loss": 0.0059,
      "step": 42280
    },
    {
      "epoch": 5.095180722891566,
      "grad_norm": 0.12331560999155045,
      "learning_rate": 9.809638554216868e-06,
      "loss": 0.0531,
      "step": 42290
    },
    {
      "epoch": 5.096385542168675,
      "grad_norm": 0.1560475081205368,
      "learning_rate": 9.807228915662652e-06,
      "loss": 0.014,
      "step": 42300
    },
    {
      "epoch": 5.097590361445783,
      "grad_norm": 0.28339436650276184,
      "learning_rate": 9.804819277108435e-06,
      "loss": 0.0161,
      "step": 42310
    },
    {
      "epoch": 5.098795180722892,
      "grad_norm": 0.01722460240125656,
      "learning_rate": 9.802409638554218e-06,
      "loss": 0.0261,
      "step": 42320
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.020236875861883163,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0036,
      "step": 42330
    },
    {
      "epoch": 5.1012048192771084,
      "grad_norm": 0.0022787461057305336,
      "learning_rate": 9.797590361445784e-06,
      "loss": 0.0182,
      "step": 42340
    },
    {
      "epoch": 5.102409638554217,
      "grad_norm": 2.4632716178894043,
      "learning_rate": 9.795180722891567e-06,
      "loss": 0.0229,
      "step": 42350
    },
    {
      "epoch": 5.103614457831325,
      "grad_norm": 0.0016187458531931043,
      "learning_rate": 9.79277108433735e-06,
      "loss": 0.0155,
      "step": 42360
    },
    {
      "epoch": 5.104819277108434,
      "grad_norm": 0.11633272469043732,
      "learning_rate": 9.790361445783134e-06,
      "loss": 0.0499,
      "step": 42370
    },
    {
      "epoch": 5.106024096385542,
      "grad_norm": 0.005953709129244089,
      "learning_rate": 9.787951807228915e-06,
      "loss": 0.0067,
      "step": 42380
    },
    {
      "epoch": 5.107228915662651,
      "grad_norm": 0.010133231058716774,
      "learning_rate": 9.7855421686747e-06,
      "loss": 0.0478,
      "step": 42390
    },
    {
      "epoch": 5.108433734939759,
      "grad_norm": 1.918463945388794,
      "learning_rate": 9.783132530120483e-06,
      "loss": 0.0455,
      "step": 42400
    },
    {
      "epoch": 5.109638554216867,
      "grad_norm": 0.8591610789299011,
      "learning_rate": 9.780722891566265e-06,
      "loss": 0.0656,
      "step": 42410
    },
    {
      "epoch": 5.110843373493976,
      "grad_norm": 0.006933809723705053,
      "learning_rate": 9.77831325301205e-06,
      "loss": 0.0083,
      "step": 42420
    },
    {
      "epoch": 5.112048192771084,
      "grad_norm": 0.014714271761476994,
      "learning_rate": 9.775903614457833e-06,
      "loss": 0.0634,
      "step": 42430
    },
    {
      "epoch": 5.113253012048193,
      "grad_norm": 0.005857150536030531,
      "learning_rate": 9.773493975903616e-06,
      "loss": 0.0475,
      "step": 42440
    },
    {
      "epoch": 5.114457831325301,
      "grad_norm": 2.4518826007843018,
      "learning_rate": 9.771084337349397e-06,
      "loss": 0.0404,
      "step": 42450
    },
    {
      "epoch": 5.11566265060241,
      "grad_norm": 0.166575625538826,
      "learning_rate": 9.768674698795182e-06,
      "loss": 0.0137,
      "step": 42460
    },
    {
      "epoch": 5.1168674698795185,
      "grad_norm": 1.7841475009918213,
      "learning_rate": 9.766265060240966e-06,
      "loss": 0.0122,
      "step": 42470
    },
    {
      "epoch": 5.118072289156626,
      "grad_norm": 2.5246829986572266,
      "learning_rate": 9.763855421686747e-06,
      "loss": 0.061,
      "step": 42480
    },
    {
      "epoch": 5.119277108433735,
      "grad_norm": 0.5593494176864624,
      "learning_rate": 9.76144578313253e-06,
      "loss": 0.0633,
      "step": 42490
    },
    {
      "epoch": 5.120481927710843,
      "grad_norm": 0.021751059219241142,
      "learning_rate": 9.759036144578315e-06,
      "loss": 0.1137,
      "step": 42500
    },
    {
      "epoch": 5.121686746987952,
      "grad_norm": 0.12702780961990356,
      "learning_rate": 9.756626506024097e-06,
      "loss": 0.0339,
      "step": 42510
    },
    {
      "epoch": 5.12289156626506,
      "grad_norm": 2.2822654247283936,
      "learning_rate": 9.75421686746988e-06,
      "loss": 0.0084,
      "step": 42520
    },
    {
      "epoch": 5.124096385542169,
      "grad_norm": 0.008561383932828903,
      "learning_rate": 9.751807228915663e-06,
      "loss": 0.0117,
      "step": 42530
    },
    {
      "epoch": 5.125301204819277,
      "grad_norm": 32.718780517578125,
      "learning_rate": 9.749397590361446e-06,
      "loss": 0.0721,
      "step": 42540
    },
    {
      "epoch": 5.126506024096385,
      "grad_norm": 13.539426803588867,
      "learning_rate": 9.74698795180723e-06,
      "loss": 0.0504,
      "step": 42550
    },
    {
      "epoch": 5.127710843373494,
      "grad_norm": 0.05179418623447418,
      "learning_rate": 9.744578313253012e-06,
      "loss": 0.038,
      "step": 42560
    },
    {
      "epoch": 5.128915662650602,
      "grad_norm": 0.9467874765396118,
      "learning_rate": 9.742168674698797e-06,
      "loss": 0.0334,
      "step": 42570
    },
    {
      "epoch": 5.130120481927711,
      "grad_norm": 0.16472826898097992,
      "learning_rate": 9.739759036144579e-06,
      "loss": 0.0099,
      "step": 42580
    },
    {
      "epoch": 5.13132530120482,
      "grad_norm": 2.944556951522827,
      "learning_rate": 9.737349397590362e-06,
      "loss": 0.0533,
      "step": 42590
    },
    {
      "epoch": 5.132530120481928,
      "grad_norm": 0.005462030414491892,
      "learning_rate": 9.734939759036145e-06,
      "loss": 0.0069,
      "step": 42600
    },
    {
      "epoch": 5.133734939759036,
      "grad_norm": 1.46759033203125,
      "learning_rate": 9.732530120481928e-06,
      "loss": 0.0456,
      "step": 42610
    },
    {
      "epoch": 5.134939759036144,
      "grad_norm": 2.1397674083709717,
      "learning_rate": 9.730120481927711e-06,
      "loss": 0.0167,
      "step": 42620
    },
    {
      "epoch": 5.136144578313253,
      "grad_norm": 0.013232352212071419,
      "learning_rate": 9.727710843373495e-06,
      "loss": 0.034,
      "step": 42630
    },
    {
      "epoch": 5.137349397590361,
      "grad_norm": 0.013788076117634773,
      "learning_rate": 9.725301204819278e-06,
      "loss": 0.0043,
      "step": 42640
    },
    {
      "epoch": 5.13855421686747,
      "grad_norm": 2.1912198066711426,
      "learning_rate": 9.722891566265061e-06,
      "loss": 0.0518,
      "step": 42650
    },
    {
      "epoch": 5.139759036144579,
      "grad_norm": 0.010164756327867508,
      "learning_rate": 9.720481927710844e-06,
      "loss": 0.0116,
      "step": 42660
    },
    {
      "epoch": 5.1409638554216865,
      "grad_norm": 0.013737158849835396,
      "learning_rate": 9.718072289156627e-06,
      "loss": 0.0724,
      "step": 42670
    },
    {
      "epoch": 5.142168674698795,
      "grad_norm": 0.02561844140291214,
      "learning_rate": 9.71566265060241e-06,
      "loss": 0.0305,
      "step": 42680
    },
    {
      "epoch": 5.143373493975903,
      "grad_norm": 0.019118916243314743,
      "learning_rate": 9.713253012048194e-06,
      "loss": 0.0279,
      "step": 42690
    },
    {
      "epoch": 5.144578313253012,
      "grad_norm": 0.02317609079182148,
      "learning_rate": 9.710843373493977e-06,
      "loss": 0.0268,
      "step": 42700
    },
    {
      "epoch": 5.145783132530121,
      "grad_norm": 0.0566178560256958,
      "learning_rate": 9.70843373493976e-06,
      "loss": 0.0179,
      "step": 42710
    },
    {
      "epoch": 5.146987951807229,
      "grad_norm": 0.13912078738212585,
      "learning_rate": 9.706024096385543e-06,
      "loss": 0.0055,
      "step": 42720
    },
    {
      "epoch": 5.148192771084338,
      "grad_norm": 0.02062581293284893,
      "learning_rate": 9.703614457831326e-06,
      "loss": 0.0304,
      "step": 42730
    },
    {
      "epoch": 5.1493975903614455,
      "grad_norm": 1.5710697174072266,
      "learning_rate": 9.70120481927711e-06,
      "loss": 0.0744,
      "step": 42740
    },
    {
      "epoch": 5.150602409638554,
      "grad_norm": 0.2118786871433258,
      "learning_rate": 9.698795180722893e-06,
      "loss": 0.0335,
      "step": 42750
    },
    {
      "epoch": 5.151807228915662,
      "grad_norm": 0.04635476693511009,
      "learning_rate": 9.696385542168676e-06,
      "loss": 0.0466,
      "step": 42760
    },
    {
      "epoch": 5.153012048192771,
      "grad_norm": 0.9388453960418701,
      "learning_rate": 9.693975903614459e-06,
      "loss": 0.0203,
      "step": 42770
    },
    {
      "epoch": 5.15421686746988,
      "grad_norm": 0.5893231630325317,
      "learning_rate": 9.691566265060242e-06,
      "loss": 0.0323,
      "step": 42780
    },
    {
      "epoch": 5.155421686746988,
      "grad_norm": 4.995712757110596,
      "learning_rate": 9.689156626506024e-06,
      "loss": 0.0556,
      "step": 42790
    },
    {
      "epoch": 5.156626506024097,
      "grad_norm": 0.10037514567375183,
      "learning_rate": 9.686746987951809e-06,
      "loss": 0.0219,
      "step": 42800
    },
    {
      "epoch": 5.1578313253012045,
      "grad_norm": 0.011841529980301857,
      "learning_rate": 9.684337349397592e-06,
      "loss": 0.022,
      "step": 42810
    },
    {
      "epoch": 5.159036144578313,
      "grad_norm": 0.01434930320829153,
      "learning_rate": 9.681927710843373e-06,
      "loss": 0.0409,
      "step": 42820
    },
    {
      "epoch": 5.160240963855422,
      "grad_norm": 0.10190387070178986,
      "learning_rate": 9.679518072289158e-06,
      "loss": 0.0096,
      "step": 42830
    },
    {
      "epoch": 5.16144578313253,
      "grad_norm": 11.063652992248535,
      "learning_rate": 9.677108433734941e-06,
      "loss": 0.0465,
      "step": 42840
    },
    {
      "epoch": 5.162650602409639,
      "grad_norm": 2.8482437133789062,
      "learning_rate": 9.674698795180723e-06,
      "loss": 0.0624,
      "step": 42850
    },
    {
      "epoch": 5.163855421686747,
      "grad_norm": 0.1338149607181549,
      "learning_rate": 9.672289156626506e-06,
      "loss": 0.0136,
      "step": 42860
    },
    {
      "epoch": 5.1650602409638555,
      "grad_norm": 1.6207267045974731,
      "learning_rate": 9.669879518072291e-06,
      "loss": 0.0163,
      "step": 42870
    },
    {
      "epoch": 5.166265060240963,
      "grad_norm": 0.1187322661280632,
      "learning_rate": 9.667469879518074e-06,
      "loss": 0.0176,
      "step": 42880
    },
    {
      "epoch": 5.167469879518072,
      "grad_norm": 0.012824790552258492,
      "learning_rate": 9.665060240963856e-06,
      "loss": 0.0142,
      "step": 42890
    },
    {
      "epoch": 5.168674698795181,
      "grad_norm": 3.7429778575897217,
      "learning_rate": 9.662650602409639e-06,
      "loss": 0.088,
      "step": 42900
    },
    {
      "epoch": 5.169879518072289,
      "grad_norm": 0.6917750239372253,
      "learning_rate": 9.660240963855424e-06,
      "loss": 0.0171,
      "step": 42910
    },
    {
      "epoch": 5.171084337349398,
      "grad_norm": 0.02360130287706852,
      "learning_rate": 9.657831325301205e-06,
      "loss": 0.0116,
      "step": 42920
    },
    {
      "epoch": 5.172289156626506,
      "grad_norm": 0.017956383526325226,
      "learning_rate": 9.655421686746988e-06,
      "loss": 0.0626,
      "step": 42930
    },
    {
      "epoch": 5.1734939759036145,
      "grad_norm": 0.42803624272346497,
      "learning_rate": 9.653012048192771e-06,
      "loss": 0.0154,
      "step": 42940
    },
    {
      "epoch": 5.174698795180723,
      "grad_norm": 0.3429391384124756,
      "learning_rate": 9.650602409638555e-06,
      "loss": 0.0592,
      "step": 42950
    },
    {
      "epoch": 5.175903614457831,
      "grad_norm": 1.974300503730774,
      "learning_rate": 9.648192771084338e-06,
      "loss": 0.0538,
      "step": 42960
    },
    {
      "epoch": 5.17710843373494,
      "grad_norm": 0.04181293770670891,
      "learning_rate": 9.645783132530121e-06,
      "loss": 0.0077,
      "step": 42970
    },
    {
      "epoch": 5.178313253012048,
      "grad_norm": 1.0713717937469482,
      "learning_rate": 9.643373493975906e-06,
      "loss": 0.0409,
      "step": 42980
    },
    {
      "epoch": 5.179518072289157,
      "grad_norm": 0.017976267263293266,
      "learning_rate": 9.640963855421687e-06,
      "loss": 0.0338,
      "step": 42990
    },
    {
      "epoch": 5.180722891566265,
      "grad_norm": 0.02879433147609234,
      "learning_rate": 9.63855421686747e-06,
      "loss": 0.011,
      "step": 43000
    },
    {
      "epoch": 5.1819277108433734,
      "grad_norm": 0.05006102845072746,
      "learning_rate": 9.636144578313254e-06,
      "loss": 0.0144,
      "step": 43010
    },
    {
      "epoch": 5.183132530120482,
      "grad_norm": 0.41680654883384705,
      "learning_rate": 9.633734939759037e-06,
      "loss": 0.0386,
      "step": 43020
    },
    {
      "epoch": 5.18433734939759,
      "grad_norm": 0.03860832005739212,
      "learning_rate": 9.63132530120482e-06,
      "loss": 0.0289,
      "step": 43030
    },
    {
      "epoch": 5.185542168674699,
      "grad_norm": 0.012425171211361885,
      "learning_rate": 9.628915662650603e-06,
      "loss": 0.0176,
      "step": 43040
    },
    {
      "epoch": 5.186746987951807,
      "grad_norm": 0.04976323992013931,
      "learning_rate": 9.626506024096386e-06,
      "loss": 0.0517,
      "step": 43050
    },
    {
      "epoch": 5.187951807228916,
      "grad_norm": 0.07638747990131378,
      "learning_rate": 9.62409638554217e-06,
      "loss": 0.0187,
      "step": 43060
    },
    {
      "epoch": 5.1891566265060245,
      "grad_norm": 0.003995622508227825,
      "learning_rate": 9.621686746987953e-06,
      "loss": 0.028,
      "step": 43070
    },
    {
      "epoch": 5.190361445783132,
      "grad_norm": 0.1466200202703476,
      "learning_rate": 9.619277108433736e-06,
      "loss": 0.0459,
      "step": 43080
    },
    {
      "epoch": 5.191566265060241,
      "grad_norm": 0.42638951539993286,
      "learning_rate": 9.616867469879519e-06,
      "loss": 0.003,
      "step": 43090
    },
    {
      "epoch": 5.192771084337349,
      "grad_norm": 0.6186073422431946,
      "learning_rate": 9.614457831325302e-06,
      "loss": 0.0113,
      "step": 43100
    },
    {
      "epoch": 5.193975903614458,
      "grad_norm": 0.08742297440767288,
      "learning_rate": 9.612048192771085e-06,
      "loss": 0.0307,
      "step": 43110
    },
    {
      "epoch": 5.195180722891566,
      "grad_norm": 0.012240546755492687,
      "learning_rate": 9.609638554216869e-06,
      "loss": 0.0037,
      "step": 43120
    },
    {
      "epoch": 5.196385542168675,
      "grad_norm": 0.0031637942884117365,
      "learning_rate": 9.607228915662652e-06,
      "loss": 0.0367,
      "step": 43130
    },
    {
      "epoch": 5.1975903614457835,
      "grad_norm": 0.04140828177332878,
      "learning_rate": 9.604819277108435e-06,
      "loss": 0.0197,
      "step": 43140
    },
    {
      "epoch": 5.198795180722891,
      "grad_norm": 0.011598416604101658,
      "learning_rate": 9.602409638554218e-06,
      "loss": 0.0483,
      "step": 43150
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.005606594495475292,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0227,
      "step": 43160
    },
    {
      "epoch": 5.201204819277108,
      "grad_norm": 0.14932942390441895,
      "learning_rate": 9.597590361445784e-06,
      "loss": 0.0252,
      "step": 43170
    },
    {
      "epoch": 5.202409638554217,
      "grad_norm": 0.02130368910729885,
      "learning_rate": 9.595180722891568e-06,
      "loss": 0.0381,
      "step": 43180
    },
    {
      "epoch": 5.203614457831326,
      "grad_norm": 0.01573341339826584,
      "learning_rate": 9.59277108433735e-06,
      "loss": 0.0452,
      "step": 43190
    },
    {
      "epoch": 5.204819277108434,
      "grad_norm": 0.006936998572200537,
      "learning_rate": 9.590361445783132e-06,
      "loss": 0.0022,
      "step": 43200
    },
    {
      "epoch": 5.206024096385542,
      "grad_norm": 0.012599664740264416,
      "learning_rate": 9.587951807228917e-06,
      "loss": 0.0425,
      "step": 43210
    },
    {
      "epoch": 5.20722891566265,
      "grad_norm": 0.027835268527269363,
      "learning_rate": 9.5855421686747e-06,
      "loss": 0.0268,
      "step": 43220
    },
    {
      "epoch": 5.208433734939759,
      "grad_norm": 0.01724131964147091,
      "learning_rate": 9.583132530120482e-06,
      "loss": 0.0304,
      "step": 43230
    },
    {
      "epoch": 5.209638554216867,
      "grad_norm": 0.012564774602651596,
      "learning_rate": 9.580722891566265e-06,
      "loss": 0.0316,
      "step": 43240
    },
    {
      "epoch": 5.210843373493976,
      "grad_norm": 0.018405938521027565,
      "learning_rate": 9.57831325301205e-06,
      "loss": 0.0042,
      "step": 43250
    },
    {
      "epoch": 5.212048192771085,
      "grad_norm": 0.020647181198000908,
      "learning_rate": 9.575903614457831e-06,
      "loss": 0.0863,
      "step": 43260
    },
    {
      "epoch": 5.213253012048193,
      "grad_norm": 2.1915955543518066,
      "learning_rate": 9.573493975903615e-06,
      "loss": 0.0701,
      "step": 43270
    },
    {
      "epoch": 5.214457831325301,
      "grad_norm": 0.5169690251350403,
      "learning_rate": 9.5710843373494e-06,
      "loss": 0.0839,
      "step": 43280
    },
    {
      "epoch": 5.215662650602409,
      "grad_norm": 1.8037939071655273,
      "learning_rate": 9.568674698795183e-06,
      "loss": 0.0249,
      "step": 43290
    },
    {
      "epoch": 5.216867469879518,
      "grad_norm": 0.02051767334342003,
      "learning_rate": 9.566265060240964e-06,
      "loss": 0.033,
      "step": 43300
    },
    {
      "epoch": 5.218072289156627,
      "grad_norm": 0.425837904214859,
      "learning_rate": 9.563855421686747e-06,
      "loss": 0.0103,
      "step": 43310
    },
    {
      "epoch": 5.219277108433735,
      "grad_norm": 0.9286660552024841,
      "learning_rate": 9.561445783132532e-06,
      "loss": 0.041,
      "step": 43320
    },
    {
      "epoch": 5.220481927710844,
      "grad_norm": 0.007664497476071119,
      "learning_rate": 9.559036144578314e-06,
      "loss": 0.0441,
      "step": 43330
    },
    {
      "epoch": 5.2216867469879515,
      "grad_norm": 0.004936595913022757,
      "learning_rate": 9.556626506024097e-06,
      "loss": 0.02,
      "step": 43340
    },
    {
      "epoch": 5.22289156626506,
      "grad_norm": 2.331040859222412,
      "learning_rate": 9.55421686746988e-06,
      "loss": 0.0305,
      "step": 43350
    },
    {
      "epoch": 5.224096385542168,
      "grad_norm": 0.012986214831471443,
      "learning_rate": 9.551807228915663e-06,
      "loss": 0.0037,
      "step": 43360
    },
    {
      "epoch": 5.225301204819277,
      "grad_norm": 0.004953058902174234,
      "learning_rate": 9.549397590361446e-06,
      "loss": 0.0416,
      "step": 43370
    },
    {
      "epoch": 5.226506024096386,
      "grad_norm": 0.02828529104590416,
      "learning_rate": 9.54698795180723e-06,
      "loss": 0.0387,
      "step": 43380
    },
    {
      "epoch": 5.227710843373494,
      "grad_norm": 0.003806514898315072,
      "learning_rate": 9.544578313253013e-06,
      "loss": 0.0278,
      "step": 43390
    },
    {
      "epoch": 5.228915662650603,
      "grad_norm": 0.16724883019924164,
      "learning_rate": 9.542168674698796e-06,
      "loss": 0.0064,
      "step": 43400
    },
    {
      "epoch": 5.2301204819277105,
      "grad_norm": 2.82863187789917,
      "learning_rate": 9.539759036144579e-06,
      "loss": 0.0494,
      "step": 43410
    },
    {
      "epoch": 5.231325301204819,
      "grad_norm": 2.033663034439087,
      "learning_rate": 9.537349397590362e-06,
      "loss": 0.0405,
      "step": 43420
    },
    {
      "epoch": 5.232530120481928,
      "grad_norm": 0.009671012870967388,
      "learning_rate": 9.534939759036145e-06,
      "loss": 0.0289,
      "step": 43430
    },
    {
      "epoch": 5.233734939759036,
      "grad_norm": 0.02575029246509075,
      "learning_rate": 9.532530120481928e-06,
      "loss": 0.0225,
      "step": 43440
    },
    {
      "epoch": 5.234939759036145,
      "grad_norm": 0.041036467999219894,
      "learning_rate": 9.530120481927712e-06,
      "loss": 0.0133,
      "step": 43450
    },
    {
      "epoch": 5.236144578313253,
      "grad_norm": 2.22521710395813,
      "learning_rate": 9.527710843373495e-06,
      "loss": 0.0281,
      "step": 43460
    },
    {
      "epoch": 5.2373493975903616,
      "grad_norm": 0.05140061676502228,
      "learning_rate": 9.525301204819278e-06,
      "loss": 0.0041,
      "step": 43470
    },
    {
      "epoch": 5.2385542168674695,
      "grad_norm": 0.04868471622467041,
      "learning_rate": 9.522891566265061e-06,
      "loss": 0.0311,
      "step": 43480
    },
    {
      "epoch": 5.239759036144578,
      "grad_norm": 0.014854219742119312,
      "learning_rate": 9.520481927710844e-06,
      "loss": 0.0134,
      "step": 43490
    },
    {
      "epoch": 5.240963855421687,
      "grad_norm": 0.01862599141895771,
      "learning_rate": 9.518072289156628e-06,
      "loss": 0.0078,
      "step": 43500
    },
    {
      "epoch": 5.242168674698795,
      "grad_norm": 0.05360282212495804,
      "learning_rate": 9.51566265060241e-06,
      "loss": 0.0186,
      "step": 43510
    },
    {
      "epoch": 5.243373493975904,
      "grad_norm": 3.09995436668396,
      "learning_rate": 9.513253012048194e-06,
      "loss": 0.044,
      "step": 43520
    },
    {
      "epoch": 5.244578313253012,
      "grad_norm": 0.15184511244297028,
      "learning_rate": 9.510843373493977e-06,
      "loss": 0.0155,
      "step": 43530
    },
    {
      "epoch": 5.2457831325301205,
      "grad_norm": 0.43605026602745056,
      "learning_rate": 9.508433734939759e-06,
      "loss": 0.0136,
      "step": 43540
    },
    {
      "epoch": 5.246987951807229,
      "grad_norm": 0.0025399706792086363,
      "learning_rate": 9.506024096385543e-06,
      "loss": 0.0328,
      "step": 43550
    },
    {
      "epoch": 5.248192771084337,
      "grad_norm": 1.93466317653656,
      "learning_rate": 9.503614457831327e-06,
      "loss": 0.0175,
      "step": 43560
    },
    {
      "epoch": 5.249397590361446,
      "grad_norm": 0.005362079478800297,
      "learning_rate": 9.501204819277108e-06,
      "loss": 0.0418,
      "step": 43570
    },
    {
      "epoch": 5.250602409638554,
      "grad_norm": 0.06312136352062225,
      "learning_rate": 9.498795180722893e-06,
      "loss": 0.0135,
      "step": 43580
    },
    {
      "epoch": 5.251807228915663,
      "grad_norm": 0.02167842909693718,
      "learning_rate": 9.496385542168676e-06,
      "loss": 0.0419,
      "step": 43590
    },
    {
      "epoch": 5.253012048192771,
      "grad_norm": 1.5909172296524048,
      "learning_rate": 9.49397590361446e-06,
      "loss": 0.0312,
      "step": 43600
    },
    {
      "epoch": 5.2542168674698795,
      "grad_norm": 0.14411962032318115,
      "learning_rate": 9.49156626506024e-06,
      "loss": 0.0113,
      "step": 43610
    },
    {
      "epoch": 5.255421686746988,
      "grad_norm": 3.926504611968994,
      "learning_rate": 9.489156626506026e-06,
      "loss": 0.0557,
      "step": 43620
    },
    {
      "epoch": 5.256626506024096,
      "grad_norm": 0.02592111937701702,
      "learning_rate": 9.486746987951809e-06,
      "loss": 0.033,
      "step": 43630
    },
    {
      "epoch": 5.257831325301205,
      "grad_norm": 0.011981275863945484,
      "learning_rate": 9.48433734939759e-06,
      "loss": 0.0514,
      "step": 43640
    },
    {
      "epoch": 5.259036144578313,
      "grad_norm": 0.13642618060112,
      "learning_rate": 9.481927710843373e-06,
      "loss": 0.0015,
      "step": 43650
    },
    {
      "epoch": 5.260240963855422,
      "grad_norm": 1.3195854425430298,
      "learning_rate": 9.479518072289158e-06,
      "loss": 0.0348,
      "step": 43660
    },
    {
      "epoch": 5.2614457831325305,
      "grad_norm": 0.32859519124031067,
      "learning_rate": 9.47710843373494e-06,
      "loss": 0.0314,
      "step": 43670
    },
    {
      "epoch": 5.2626506024096384,
      "grad_norm": 0.06789121776819229,
      "learning_rate": 9.474698795180723e-06,
      "loss": 0.0416,
      "step": 43680
    },
    {
      "epoch": 5.263855421686747,
      "grad_norm": 0.16034172475337982,
      "learning_rate": 9.472289156626506e-06,
      "loss": 0.0184,
      "step": 43690
    },
    {
      "epoch": 5.265060240963855,
      "grad_norm": 5.625301837921143,
      "learning_rate": 9.46987951807229e-06,
      "loss": 0.0511,
      "step": 43700
    },
    {
      "epoch": 5.266265060240964,
      "grad_norm": 0.009141214191913605,
      "learning_rate": 9.467469879518073e-06,
      "loss": 0.0116,
      "step": 43710
    },
    {
      "epoch": 5.267469879518072,
      "grad_norm": 0.3361646831035614,
      "learning_rate": 9.465060240963856e-06,
      "loss": 0.0048,
      "step": 43720
    },
    {
      "epoch": 5.268674698795181,
      "grad_norm": 0.0018777955556288362,
      "learning_rate": 9.46265060240964e-06,
      "loss": 0.0273,
      "step": 43730
    },
    {
      "epoch": 5.2698795180722895,
      "grad_norm": 0.11133749037981033,
      "learning_rate": 9.460240963855422e-06,
      "loss": 0.0226,
      "step": 43740
    },
    {
      "epoch": 5.271084337349397,
      "grad_norm": 0.04052666202187538,
      "learning_rate": 9.457831325301205e-06,
      "loss": 0.0589,
      "step": 43750
    },
    {
      "epoch": 5.272289156626506,
      "grad_norm": 0.0033448270987719297,
      "learning_rate": 9.455421686746988e-06,
      "loss": 0.0224,
      "step": 43760
    },
    {
      "epoch": 5.273493975903614,
      "grad_norm": 1.2593353986740112,
      "learning_rate": 9.453012048192772e-06,
      "loss": 0.0059,
      "step": 43770
    },
    {
      "epoch": 5.274698795180723,
      "grad_norm": 0.03514678403735161,
      "learning_rate": 9.450602409638555e-06,
      "loss": 0.0321,
      "step": 43780
    },
    {
      "epoch": 5.275903614457832,
      "grad_norm": 0.026149660348892212,
      "learning_rate": 9.448192771084338e-06,
      "loss": 0.0229,
      "step": 43790
    },
    {
      "epoch": 5.27710843373494,
      "grad_norm": 5.038568019866943,
      "learning_rate": 9.445783132530121e-06,
      "loss": 0.0639,
      "step": 43800
    },
    {
      "epoch": 5.2783132530120485,
      "grad_norm": 105.17958068847656,
      "learning_rate": 9.443373493975904e-06,
      "loss": 0.0322,
      "step": 43810
    },
    {
      "epoch": 5.279518072289156,
      "grad_norm": 1.4336159229278564,
      "learning_rate": 9.440963855421687e-06,
      "loss": 0.0431,
      "step": 43820
    },
    {
      "epoch": 5.280722891566265,
      "grad_norm": 0.14859656989574432,
      "learning_rate": 9.43855421686747e-06,
      "loss": 0.0472,
      "step": 43830
    },
    {
      "epoch": 5.281927710843373,
      "grad_norm": 2.777405261993408,
      "learning_rate": 9.436144578313254e-06,
      "loss": 0.0205,
      "step": 43840
    },
    {
      "epoch": 5.283132530120482,
      "grad_norm": 1.9876692295074463,
      "learning_rate": 9.433734939759037e-06,
      "loss": 0.0175,
      "step": 43850
    },
    {
      "epoch": 5.284337349397591,
      "grad_norm": 0.13297009468078613,
      "learning_rate": 9.43132530120482e-06,
      "loss": 0.0098,
      "step": 43860
    },
    {
      "epoch": 5.285542168674699,
      "grad_norm": 0.37813588976860046,
      "learning_rate": 9.428915662650603e-06,
      "loss": 0.0051,
      "step": 43870
    },
    {
      "epoch": 5.286746987951807,
      "grad_norm": 0.019932283088564873,
      "learning_rate": 9.426506024096387e-06,
      "loss": 0.016,
      "step": 43880
    },
    {
      "epoch": 5.287951807228915,
      "grad_norm": 0.024506494402885437,
      "learning_rate": 9.42409638554217e-06,
      "loss": 0.0017,
      "step": 43890
    },
    {
      "epoch": 5.289156626506024,
      "grad_norm": 0.9547047019004822,
      "learning_rate": 9.421686746987953e-06,
      "loss": 0.0519,
      "step": 43900
    },
    {
      "epoch": 5.290361445783133,
      "grad_norm": 1.6267634630203247,
      "learning_rate": 9.419277108433736e-06,
      "loss": 0.0507,
      "step": 43910
    },
    {
      "epoch": 5.291566265060241,
      "grad_norm": 2.491926908493042,
      "learning_rate": 9.41686746987952e-06,
      "loss": 0.0355,
      "step": 43920
    },
    {
      "epoch": 5.29277108433735,
      "grad_norm": 0.024936996400356293,
      "learning_rate": 9.414457831325302e-06,
      "loss": 0.0266,
      "step": 43930
    },
    {
      "epoch": 5.293975903614458,
      "grad_norm": 0.4835491180419922,
      "learning_rate": 9.412048192771086e-06,
      "loss": 0.0272,
      "step": 43940
    },
    {
      "epoch": 5.295180722891566,
      "grad_norm": 1.1893240213394165,
      "learning_rate": 9.409638554216867e-06,
      "loss": 0.0283,
      "step": 43950
    },
    {
      "epoch": 5.296385542168674,
      "grad_norm": 0.8639465570449829,
      "learning_rate": 9.407228915662652e-06,
      "loss": 0.0175,
      "step": 43960
    },
    {
      "epoch": 5.297590361445783,
      "grad_norm": 1.7930331230163574,
      "learning_rate": 9.404819277108435e-06,
      "loss": 0.0283,
      "step": 43970
    },
    {
      "epoch": 5.298795180722892,
      "grad_norm": 0.0027801182586699724,
      "learning_rate": 9.402409638554217e-06,
      "loss": 0.0293,
      "step": 43980
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.7209712862968445,
      "learning_rate": 9.4e-06,
      "loss": 0.0083,
      "step": 43990
    },
    {
      "epoch": 5.301204819277109,
      "grad_norm": 4.021669864654541,
      "learning_rate": 9.397590361445785e-06,
      "loss": 0.0146,
      "step": 44000
    },
    {
      "epoch": 5.3024096385542165,
      "grad_norm": 5.832511901855469,
      "learning_rate": 9.395180722891568e-06,
      "loss": 0.0394,
      "step": 44010
    },
    {
      "epoch": 5.303614457831325,
      "grad_norm": 0.06465547531843185,
      "learning_rate": 9.39277108433735e-06,
      "loss": 0.0333,
      "step": 44020
    },
    {
      "epoch": 5.304819277108434,
      "grad_norm": 0.4611247479915619,
      "learning_rate": 9.390361445783134e-06,
      "loss": 0.0082,
      "step": 44030
    },
    {
      "epoch": 5.306024096385542,
      "grad_norm": 9.7682523727417,
      "learning_rate": 9.387951807228917e-06,
      "loss": 0.0542,
      "step": 44040
    },
    {
      "epoch": 5.307228915662651,
      "grad_norm": 1.8172142505645752,
      "learning_rate": 9.385542168674699e-06,
      "loss": 0.0291,
      "step": 44050
    },
    {
      "epoch": 5.308433734939759,
      "grad_norm": 0.005107359495013952,
      "learning_rate": 9.383132530120482e-06,
      "loss": 0.0778,
      "step": 44060
    },
    {
      "epoch": 5.309638554216868,
      "grad_norm": 0.5287180542945862,
      "learning_rate": 9.380722891566267e-06,
      "loss": 0.0222,
      "step": 44070
    },
    {
      "epoch": 5.3108433734939755,
      "grad_norm": 0.046763207763433456,
      "learning_rate": 9.378313253012048e-06,
      "loss": 0.0028,
      "step": 44080
    },
    {
      "epoch": 5.312048192771084,
      "grad_norm": 0.5410263538360596,
      "learning_rate": 9.375903614457832e-06,
      "loss": 0.0167,
      "step": 44090
    },
    {
      "epoch": 5.313253012048193,
      "grad_norm": 0.2630751132965088,
      "learning_rate": 9.373493975903615e-06,
      "loss": 0.0216,
      "step": 44100
    },
    {
      "epoch": 5.314457831325301,
      "grad_norm": 5.2986955642700195,
      "learning_rate": 9.371084337349398e-06,
      "loss": 0.0712,
      "step": 44110
    },
    {
      "epoch": 5.31566265060241,
      "grad_norm": 6.955015659332275,
      "learning_rate": 9.368674698795181e-06,
      "loss": 0.0781,
      "step": 44120
    },
    {
      "epoch": 5.316867469879518,
      "grad_norm": 0.03756643086671829,
      "learning_rate": 9.366265060240964e-06,
      "loss": 0.0099,
      "step": 44130
    },
    {
      "epoch": 5.3180722891566266,
      "grad_norm": 1.2580169439315796,
      "learning_rate": 9.363855421686747e-06,
      "loss": 0.0253,
      "step": 44140
    },
    {
      "epoch": 5.3192771084337345,
      "grad_norm": 0.03588106110692024,
      "learning_rate": 9.36144578313253e-06,
      "loss": 0.0427,
      "step": 44150
    },
    {
      "epoch": 5.320481927710843,
      "grad_norm": 0.6770098805427551,
      "learning_rate": 9.359036144578314e-06,
      "loss": 0.0203,
      "step": 44160
    },
    {
      "epoch": 5.321686746987952,
      "grad_norm": 0.11636588722467422,
      "learning_rate": 9.356626506024097e-06,
      "loss": 0.0378,
      "step": 44170
    },
    {
      "epoch": 5.32289156626506,
      "grad_norm": 0.027273118495941162,
      "learning_rate": 9.35421686746988e-06,
      "loss": 0.0517,
      "step": 44180
    },
    {
      "epoch": 5.324096385542169,
      "grad_norm": 0.1663171499967575,
      "learning_rate": 9.351807228915663e-06,
      "loss": 0.0091,
      "step": 44190
    },
    {
      "epoch": 5.325301204819277,
      "grad_norm": 1.3939765691757202,
      "learning_rate": 9.349397590361446e-06,
      "loss": 0.0592,
      "step": 44200
    },
    {
      "epoch": 5.3265060240963855,
      "grad_norm": 21.103343963623047,
      "learning_rate": 9.34698795180723e-06,
      "loss": 0.0497,
      "step": 44210
    },
    {
      "epoch": 5.327710843373494,
      "grad_norm": 0.05023595318198204,
      "learning_rate": 9.344578313253013e-06,
      "loss": 0.0309,
      "step": 44220
    },
    {
      "epoch": 5.328915662650602,
      "grad_norm": 0.08363108336925507,
      "learning_rate": 9.342168674698796e-06,
      "loss": 0.0631,
      "step": 44230
    },
    {
      "epoch": 5.330120481927711,
      "grad_norm": 2.670961380004883,
      "learning_rate": 9.33975903614458e-06,
      "loss": 0.0396,
      "step": 44240
    },
    {
      "epoch": 5.331325301204819,
      "grad_norm": 0.5037531852722168,
      "learning_rate": 9.337349397590362e-06,
      "loss": 0.0357,
      "step": 44250
    },
    {
      "epoch": 5.332530120481928,
      "grad_norm": 0.031044423580169678,
      "learning_rate": 9.334939759036146e-06,
      "loss": 0.031,
      "step": 44260
    },
    {
      "epoch": 5.333734939759037,
      "grad_norm": 0.0657484158873558,
      "learning_rate": 9.332530120481929e-06,
      "loss": 0.0507,
      "step": 44270
    },
    {
      "epoch": 5.3349397590361445,
      "grad_norm": 1.3516204357147217,
      "learning_rate": 9.330120481927712e-06,
      "loss": 0.0065,
      "step": 44280
    },
    {
      "epoch": 5.336144578313253,
      "grad_norm": 0.12709595263004303,
      "learning_rate": 9.327710843373493e-06,
      "loss": 0.0231,
      "step": 44290
    },
    {
      "epoch": 5.337349397590361,
      "grad_norm": 1.2022082805633545,
      "learning_rate": 9.325301204819278e-06,
      "loss": 0.0223,
      "step": 44300
    },
    {
      "epoch": 5.33855421686747,
      "grad_norm": 1.2648649215698242,
      "learning_rate": 9.322891566265061e-06,
      "loss": 0.0218,
      "step": 44310
    },
    {
      "epoch": 5.339759036144578,
      "grad_norm": 0.048361800611019135,
      "learning_rate": 9.320481927710845e-06,
      "loss": 0.0821,
      "step": 44320
    },
    {
      "epoch": 5.340963855421687,
      "grad_norm": 34.111751556396484,
      "learning_rate": 9.318072289156628e-06,
      "loss": 0.0668,
      "step": 44330
    },
    {
      "epoch": 5.3421686746987955,
      "grad_norm": 0.048878975212574005,
      "learning_rate": 9.315662650602411e-06,
      "loss": 0.0112,
      "step": 44340
    },
    {
      "epoch": 5.343373493975903,
      "grad_norm": 0.020975694060325623,
      "learning_rate": 9.313253012048194e-06,
      "loss": 0.0233,
      "step": 44350
    },
    {
      "epoch": 5.344578313253012,
      "grad_norm": 0.06591600179672241,
      "learning_rate": 9.310843373493976e-06,
      "loss": 0.0145,
      "step": 44360
    },
    {
      "epoch": 5.34578313253012,
      "grad_norm": 0.004117139615118504,
      "learning_rate": 9.30843373493976e-06,
      "loss": 0.007,
      "step": 44370
    },
    {
      "epoch": 5.346987951807229,
      "grad_norm": 2.749725580215454,
      "learning_rate": 9.306024096385544e-06,
      "loss": 0.0098,
      "step": 44380
    },
    {
      "epoch": 5.348192771084337,
      "grad_norm": 7.034225940704346,
      "learning_rate": 9.303614457831325e-06,
      "loss": 0.0235,
      "step": 44390
    },
    {
      "epoch": 5.349397590361446,
      "grad_norm": 2.5113472938537598,
      "learning_rate": 9.301204819277108e-06,
      "loss": 0.0819,
      "step": 44400
    },
    {
      "epoch": 5.3506024096385545,
      "grad_norm": 0.01230653002858162,
      "learning_rate": 9.298795180722893e-06,
      "loss": 0.0083,
      "step": 44410
    },
    {
      "epoch": 5.351807228915662,
      "grad_norm": 0.1260618418455124,
      "learning_rate": 9.296385542168675e-06,
      "loss": 0.0519,
      "step": 44420
    },
    {
      "epoch": 5.353012048192771,
      "grad_norm": 1.5045315027236938,
      "learning_rate": 9.293975903614458e-06,
      "loss": 0.0278,
      "step": 44430
    },
    {
      "epoch": 5.354216867469879,
      "grad_norm": 0.2909606993198395,
      "learning_rate": 9.291566265060241e-06,
      "loss": 0.0117,
      "step": 44440
    },
    {
      "epoch": 5.355421686746988,
      "grad_norm": 1.4361168146133423,
      "learning_rate": 9.289156626506026e-06,
      "loss": 0.0099,
      "step": 44450
    },
    {
      "epoch": 5.356626506024097,
      "grad_norm": 0.01309854257851839,
      "learning_rate": 9.286746987951807e-06,
      "loss": 0.0801,
      "step": 44460
    },
    {
      "epoch": 5.357831325301205,
      "grad_norm": 0.015598506666719913,
      "learning_rate": 9.28433734939759e-06,
      "loss": 0.0047,
      "step": 44470
    },
    {
      "epoch": 5.3590361445783135,
      "grad_norm": 0.01430377084761858,
      "learning_rate": 9.281927710843375e-06,
      "loss": 0.0601,
      "step": 44480
    },
    {
      "epoch": 5.360240963855421,
      "grad_norm": 0.652448832988739,
      "learning_rate": 9.279518072289157e-06,
      "loss": 0.0059,
      "step": 44490
    },
    {
      "epoch": 5.36144578313253,
      "grad_norm": 0.028713872656226158,
      "learning_rate": 9.27710843373494e-06,
      "loss": 0.0326,
      "step": 44500
    },
    {
      "epoch": 5.362650602409639,
      "grad_norm": 0.3821159601211548,
      "learning_rate": 9.274698795180723e-06,
      "loss": 0.0508,
      "step": 44510
    },
    {
      "epoch": 5.363855421686747,
      "grad_norm": 2.751535654067993,
      "learning_rate": 9.272289156626506e-06,
      "loss": 0.0638,
      "step": 44520
    },
    {
      "epoch": 5.365060240963856,
      "grad_norm": 1.1092873811721802,
      "learning_rate": 9.26987951807229e-06,
      "loss": 0.0581,
      "step": 44530
    },
    {
      "epoch": 5.366265060240964,
      "grad_norm": 0.2055649757385254,
      "learning_rate": 9.267469879518073e-06,
      "loss": 0.0075,
      "step": 44540
    },
    {
      "epoch": 5.367469879518072,
      "grad_norm": 1.185197353363037,
      "learning_rate": 9.265060240963856e-06,
      "loss": 0.0127,
      "step": 44550
    },
    {
      "epoch": 5.36867469879518,
      "grad_norm": 1.1960214376449585,
      "learning_rate": 9.262650602409639e-06,
      "loss": 0.0492,
      "step": 44560
    },
    {
      "epoch": 5.369879518072289,
      "grad_norm": 0.006294466555118561,
      "learning_rate": 9.260240963855422e-06,
      "loss": 0.1012,
      "step": 44570
    },
    {
      "epoch": 5.371084337349398,
      "grad_norm": 1.2262026071548462,
      "learning_rate": 9.257831325301205e-06,
      "loss": 0.0129,
      "step": 44580
    },
    {
      "epoch": 5.372289156626506,
      "grad_norm": 0.03631322458386421,
      "learning_rate": 9.255421686746989e-06,
      "loss": 0.0332,
      "step": 44590
    },
    {
      "epoch": 5.373493975903615,
      "grad_norm": 0.07783856987953186,
      "learning_rate": 9.253012048192772e-06,
      "loss": 0.0024,
      "step": 44600
    },
    {
      "epoch": 5.374698795180723,
      "grad_norm": 0.015152309089899063,
      "learning_rate": 9.250602409638555e-06,
      "loss": 0.0231,
      "step": 44610
    },
    {
      "epoch": 5.375903614457831,
      "grad_norm": 0.02060846984386444,
      "learning_rate": 9.248192771084338e-06,
      "loss": 0.0321,
      "step": 44620
    },
    {
      "epoch": 5.377108433734939,
      "grad_norm": 0.5977731943130493,
      "learning_rate": 9.245783132530121e-06,
      "loss": 0.057,
      "step": 44630
    },
    {
      "epoch": 5.378313253012048,
      "grad_norm": 0.10652968287467957,
      "learning_rate": 9.243373493975905e-06,
      "loss": 0.0354,
      "step": 44640
    },
    {
      "epoch": 5.379518072289157,
      "grad_norm": 0.05949819087982178,
      "learning_rate": 9.240963855421688e-06,
      "loss": 0.0188,
      "step": 44650
    },
    {
      "epoch": 5.380722891566265,
      "grad_norm": 1.0124269723892212,
      "learning_rate": 9.238554216867471e-06,
      "loss": 0.0345,
      "step": 44660
    },
    {
      "epoch": 5.381927710843374,
      "grad_norm": 0.09901715815067291,
      "learning_rate": 9.236144578313254e-06,
      "loss": 0.0028,
      "step": 44670
    },
    {
      "epoch": 5.3831325301204815,
      "grad_norm": 0.016901927068829536,
      "learning_rate": 9.233734939759037e-06,
      "loss": 0.0361,
      "step": 44680
    },
    {
      "epoch": 5.38433734939759,
      "grad_norm": 0.6633209586143494,
      "learning_rate": 9.23132530120482e-06,
      "loss": 0.0167,
      "step": 44690
    },
    {
      "epoch": 5.385542168674699,
      "grad_norm": 0.006724464241415262,
      "learning_rate": 9.228915662650602e-06,
      "loss": 0.0042,
      "step": 44700
    },
    {
      "epoch": 5.386746987951807,
      "grad_norm": 1.9591023921966553,
      "learning_rate": 9.226506024096387e-06,
      "loss": 0.0207,
      "step": 44710
    },
    {
      "epoch": 5.387951807228916,
      "grad_norm": 1.1807211637496948,
      "learning_rate": 9.22409638554217e-06,
      "loss": 0.082,
      "step": 44720
    },
    {
      "epoch": 5.389156626506024,
      "grad_norm": 0.7969118356704712,
      "learning_rate": 9.221686746987953e-06,
      "loss": 0.0455,
      "step": 44730
    },
    {
      "epoch": 5.390361445783133,
      "grad_norm": 0.1602417677640915,
      "learning_rate": 9.219277108433736e-06,
      "loss": 0.0391,
      "step": 44740
    },
    {
      "epoch": 5.391566265060241,
      "grad_norm": 0.09472404420375824,
      "learning_rate": 9.21686746987952e-06,
      "loss": 0.0541,
      "step": 44750
    },
    {
      "epoch": 5.392771084337349,
      "grad_norm": 0.028989121317863464,
      "learning_rate": 9.214457831325303e-06,
      "loss": 0.0181,
      "step": 44760
    },
    {
      "epoch": 5.393975903614458,
      "grad_norm": 0.008919399231672287,
      "learning_rate": 9.212048192771084e-06,
      "loss": 0.0196,
      "step": 44770
    },
    {
      "epoch": 5.395180722891566,
      "grad_norm": 0.032193660736083984,
      "learning_rate": 9.209638554216869e-06,
      "loss": 0.0745,
      "step": 44780
    },
    {
      "epoch": 5.396385542168675,
      "grad_norm": 1.5659277439117432,
      "learning_rate": 9.207228915662652e-06,
      "loss": 0.0794,
      "step": 44790
    },
    {
      "epoch": 5.397590361445783,
      "grad_norm": 0.12227082252502441,
      "learning_rate": 9.204819277108434e-06,
      "loss": 0.0168,
      "step": 44800
    },
    {
      "epoch": 5.3987951807228916,
      "grad_norm": 0.034846577793359756,
      "learning_rate": 9.202409638554217e-06,
      "loss": 0.0189,
      "step": 44810
    },
    {
      "epoch": 5.4,
      "grad_norm": 3.9130351543426514,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0332,
      "step": 44820
    },
    {
      "epoch": 5.401204819277108,
      "grad_norm": 0.037505071610212326,
      "learning_rate": 9.197590361445783e-06,
      "loss": 0.0156,
      "step": 44830
    },
    {
      "epoch": 5.402409638554217,
      "grad_norm": 0.7477105259895325,
      "learning_rate": 9.195180722891566e-06,
      "loss": 0.021,
      "step": 44840
    },
    {
      "epoch": 5.403614457831325,
      "grad_norm": 0.626535177230835,
      "learning_rate": 9.19277108433735e-06,
      "loss": 0.0264,
      "step": 44850
    },
    {
      "epoch": 5.404819277108434,
      "grad_norm": 1.8388164043426514,
      "learning_rate": 9.190361445783134e-06,
      "loss": 0.0464,
      "step": 44860
    },
    {
      "epoch": 5.406024096385542,
      "grad_norm": 0.013052214868366718,
      "learning_rate": 9.187951807228916e-06,
      "loss": 0.0072,
      "step": 44870
    },
    {
      "epoch": 5.4072289156626505,
      "grad_norm": 5.5399088859558105,
      "learning_rate": 9.185542168674699e-06,
      "loss": 0.0459,
      "step": 44880
    },
    {
      "epoch": 5.408433734939759,
      "grad_norm": 4.125852108001709,
      "learning_rate": 9.183132530120484e-06,
      "loss": 0.0398,
      "step": 44890
    },
    {
      "epoch": 5.409638554216867,
      "grad_norm": 0.8241786360740662,
      "learning_rate": 9.180722891566265e-06,
      "loss": 0.0231,
      "step": 44900
    },
    {
      "epoch": 5.410843373493976,
      "grad_norm": 0.21129857003688812,
      "learning_rate": 9.178313253012049e-06,
      "loss": 0.0534,
      "step": 44910
    },
    {
      "epoch": 5.412048192771084,
      "grad_norm": 1.1891913414001465,
      "learning_rate": 9.175903614457832e-06,
      "loss": 0.0251,
      "step": 44920
    },
    {
      "epoch": 5.413253012048193,
      "grad_norm": 0.11295364052057266,
      "learning_rate": 9.173493975903615e-06,
      "loss": 0.0123,
      "step": 44930
    },
    {
      "epoch": 5.414457831325302,
      "grad_norm": 2.6134891510009766,
      "learning_rate": 9.171084337349398e-06,
      "loss": 0.0626,
      "step": 44940
    },
    {
      "epoch": 5.4156626506024095,
      "grad_norm": 0.5989024639129639,
      "learning_rate": 9.168674698795181e-06,
      "loss": 0.009,
      "step": 44950
    },
    {
      "epoch": 5.416867469879518,
      "grad_norm": 0.029596490785479546,
      "learning_rate": 9.166265060240964e-06,
      "loss": 0.006,
      "step": 44960
    },
    {
      "epoch": 5.418072289156626,
      "grad_norm": 0.47035911679267883,
      "learning_rate": 9.163855421686748e-06,
      "loss": 0.0187,
      "step": 44970
    },
    {
      "epoch": 5.419277108433735,
      "grad_norm": 4.310199737548828,
      "learning_rate": 9.16144578313253e-06,
      "loss": 0.0654,
      "step": 44980
    },
    {
      "epoch": 5.420481927710844,
      "grad_norm": 0.12902188301086426,
      "learning_rate": 9.159036144578314e-06,
      "loss": 0.0094,
      "step": 44990
    },
    {
      "epoch": 5.421686746987952,
      "grad_norm": 2.7466084957122803,
      "learning_rate": 9.156626506024097e-06,
      "loss": 0.0106,
      "step": 45000
    },
    {
      "epoch": 5.4228915662650605,
      "grad_norm": 0.008715933188796043,
      "learning_rate": 9.15421686746988e-06,
      "loss": 0.0224,
      "step": 45010
    },
    {
      "epoch": 5.424096385542168,
      "grad_norm": 0.0020747000817209482,
      "learning_rate": 9.151807228915664e-06,
      "loss": 0.0165,
      "step": 45020
    },
    {
      "epoch": 5.425301204819277,
      "grad_norm": 0.003919057082384825,
      "learning_rate": 9.149397590361447e-06,
      "loss": 0.0228,
      "step": 45030
    },
    {
      "epoch": 5.426506024096385,
      "grad_norm": 0.005603740457445383,
      "learning_rate": 9.14698795180723e-06,
      "loss": 0.0159,
      "step": 45040
    },
    {
      "epoch": 5.427710843373494,
      "grad_norm": 0.001378058921545744,
      "learning_rate": 9.144578313253013e-06,
      "loss": 0.014,
      "step": 45050
    },
    {
      "epoch": 5.428915662650603,
      "grad_norm": 8.610882759094238,
      "learning_rate": 9.142168674698796e-06,
      "loss": 0.0094,
      "step": 45060
    },
    {
      "epoch": 5.430120481927711,
      "grad_norm": 0.005594376940280199,
      "learning_rate": 9.13975903614458e-06,
      "loss": 0.0093,
      "step": 45070
    },
    {
      "epoch": 5.4313253012048195,
      "grad_norm": 1.8394169807434082,
      "learning_rate": 9.137349397590363e-06,
      "loss": 0.0242,
      "step": 45080
    },
    {
      "epoch": 5.432530120481927,
      "grad_norm": 0.2223460078239441,
      "learning_rate": 9.134939759036146e-06,
      "loss": 0.001,
      "step": 45090
    },
    {
      "epoch": 5.433734939759036,
      "grad_norm": 0.7533551454544067,
      "learning_rate": 9.132530120481929e-06,
      "loss": 0.0387,
      "step": 45100
    },
    {
      "epoch": 5.434939759036144,
      "grad_norm": 0.008433204144239426,
      "learning_rate": 9.13012048192771e-06,
      "loss": 0.0323,
      "step": 45110
    },
    {
      "epoch": 5.436144578313253,
      "grad_norm": 0.004036448430269957,
      "learning_rate": 9.127710843373495e-06,
      "loss": 0.0239,
      "step": 45120
    },
    {
      "epoch": 5.437349397590362,
      "grad_norm": 1.5690054893493652,
      "learning_rate": 9.125301204819278e-06,
      "loss": 0.0229,
      "step": 45130
    },
    {
      "epoch": 5.43855421686747,
      "grad_norm": 0.007440352812409401,
      "learning_rate": 9.12289156626506e-06,
      "loss": 0.0281,
      "step": 45140
    },
    {
      "epoch": 5.4397590361445785,
      "grad_norm": 3.671335220336914,
      "learning_rate": 9.120481927710843e-06,
      "loss": 0.0101,
      "step": 45150
    },
    {
      "epoch": 5.440963855421686,
      "grad_norm": 0.0752398893237114,
      "learning_rate": 9.118072289156628e-06,
      "loss": 0.0305,
      "step": 45160
    },
    {
      "epoch": 5.442168674698795,
      "grad_norm": 2.030327796936035,
      "learning_rate": 9.115662650602411e-06,
      "loss": 0.048,
      "step": 45170
    },
    {
      "epoch": 5.443373493975904,
      "grad_norm": 0.03645027428865433,
      "learning_rate": 9.113253012048193e-06,
      "loss": 0.0109,
      "step": 45180
    },
    {
      "epoch": 5.444578313253012,
      "grad_norm": 0.006527771707624197,
      "learning_rate": 9.110843373493978e-06,
      "loss": 0.0487,
      "step": 45190
    },
    {
      "epoch": 5.445783132530121,
      "grad_norm": 0.39845526218414307,
      "learning_rate": 9.10843373493976e-06,
      "loss": 0.0687,
      "step": 45200
    },
    {
      "epoch": 5.446987951807229,
      "grad_norm": 0.06527592986822128,
      "learning_rate": 9.106024096385542e-06,
      "loss": 0.0139,
      "step": 45210
    },
    {
      "epoch": 5.448192771084337,
      "grad_norm": 0.004484972916543484,
      "learning_rate": 9.103614457831325e-06,
      "loss": 0.0293,
      "step": 45220
    },
    {
      "epoch": 5.449397590361446,
      "grad_norm": 0.17165309190750122,
      "learning_rate": 9.10120481927711e-06,
      "loss": 0.0247,
      "step": 45230
    },
    {
      "epoch": 5.450602409638554,
      "grad_norm": 0.018118539825081825,
      "learning_rate": 9.098795180722892e-06,
      "loss": 0.0591,
      "step": 45240
    },
    {
      "epoch": 5.451807228915663,
      "grad_norm": 0.025166215375065804,
      "learning_rate": 9.096385542168675e-06,
      "loss": 0.0312,
      "step": 45250
    },
    {
      "epoch": 5.453012048192771,
      "grad_norm": 0.01211521402001381,
      "learning_rate": 9.093975903614458e-06,
      "loss": 0.009,
      "step": 45260
    },
    {
      "epoch": 5.45421686746988,
      "grad_norm": 0.4865380823612213,
      "learning_rate": 9.091566265060243e-06,
      "loss": 0.0243,
      "step": 45270
    },
    {
      "epoch": 5.455421686746988,
      "grad_norm": 0.6216366291046143,
      "learning_rate": 9.089156626506024e-06,
      "loss": 0.0147,
      "step": 45280
    },
    {
      "epoch": 5.456626506024096,
      "grad_norm": 0.024386243894696236,
      "learning_rate": 9.086746987951808e-06,
      "loss": 0.0243,
      "step": 45290
    },
    {
      "epoch": 5.457831325301205,
      "grad_norm": 0.15829643607139587,
      "learning_rate": 9.08433734939759e-06,
      "loss": 0.0582,
      "step": 45300
    },
    {
      "epoch": 5.459036144578313,
      "grad_norm": 0.19218280911445618,
      "learning_rate": 9.081927710843374e-06,
      "loss": 0.0527,
      "step": 45310
    },
    {
      "epoch": 5.460240963855422,
      "grad_norm": 0.011374861933290958,
      "learning_rate": 9.079518072289157e-06,
      "loss": 0.0384,
      "step": 45320
    },
    {
      "epoch": 5.46144578313253,
      "grad_norm": 25.768184661865234,
      "learning_rate": 9.07710843373494e-06,
      "loss": 0.006,
      "step": 45330
    },
    {
      "epoch": 5.462650602409639,
      "grad_norm": 0.016030626371502876,
      "learning_rate": 9.074698795180723e-06,
      "loss": 0.0728,
      "step": 45340
    },
    {
      "epoch": 5.4638554216867465,
      "grad_norm": 0.03979061543941498,
      "learning_rate": 9.072289156626507e-06,
      "loss": 0.021,
      "step": 45350
    },
    {
      "epoch": 5.465060240963855,
      "grad_norm": 0.023365844041109085,
      "learning_rate": 9.06987951807229e-06,
      "loss": 0.0296,
      "step": 45360
    },
    {
      "epoch": 5.466265060240964,
      "grad_norm": 0.007155736908316612,
      "learning_rate": 9.067469879518073e-06,
      "loss": 0.0252,
      "step": 45370
    },
    {
      "epoch": 5.467469879518072,
      "grad_norm": 0.18904896080493927,
      "learning_rate": 9.065060240963856e-06,
      "loss": 0.0215,
      "step": 45380
    },
    {
      "epoch": 5.468674698795181,
      "grad_norm": 0.04414147138595581,
      "learning_rate": 9.06265060240964e-06,
      "loss": 0.0382,
      "step": 45390
    },
    {
      "epoch": 5.469879518072289,
      "grad_norm": 6.396732807159424,
      "learning_rate": 9.060240963855423e-06,
      "loss": 0.0357,
      "step": 45400
    },
    {
      "epoch": 5.471084337349398,
      "grad_norm": 0.36286500096321106,
      "learning_rate": 9.057831325301206e-06,
      "loss": 0.0162,
      "step": 45410
    },
    {
      "epoch": 5.472289156626506,
      "grad_norm": 0.008414742536842823,
      "learning_rate": 9.055421686746989e-06,
      "loss": 0.0049,
      "step": 45420
    },
    {
      "epoch": 5.473493975903614,
      "grad_norm": 0.006467550061643124,
      "learning_rate": 9.053012048192772e-06,
      "loss": 0.0048,
      "step": 45430
    },
    {
      "epoch": 5.474698795180723,
      "grad_norm": 0.5382176041603088,
      "learning_rate": 9.050602409638555e-06,
      "loss": 0.0112,
      "step": 45440
    },
    {
      "epoch": 5.475903614457831,
      "grad_norm": 5.083261013031006,
      "learning_rate": 9.048192771084338e-06,
      "loss": 0.0237,
      "step": 45450
    },
    {
      "epoch": 5.47710843373494,
      "grad_norm": 1.7709414958953857,
      "learning_rate": 9.045783132530122e-06,
      "loss": 0.0342,
      "step": 45460
    },
    {
      "epoch": 5.478313253012049,
      "grad_norm": 0.004963455721735954,
      "learning_rate": 9.043373493975905e-06,
      "loss": 0.0238,
      "step": 45470
    },
    {
      "epoch": 5.4795180722891565,
      "grad_norm": 0.012322032824158669,
      "learning_rate": 9.040963855421688e-06,
      "loss": 0.0113,
      "step": 45480
    },
    {
      "epoch": 5.480722891566265,
      "grad_norm": 0.312771201133728,
      "learning_rate": 9.038554216867471e-06,
      "loss": 0.0017,
      "step": 45490
    },
    {
      "epoch": 5.481927710843373,
      "grad_norm": 0.0009564944775775075,
      "learning_rate": 9.036144578313254e-06,
      "loss": 0.0743,
      "step": 45500
    },
    {
      "epoch": 5.483132530120482,
      "grad_norm": 0.009080056101083755,
      "learning_rate": 9.033734939759037e-06,
      "loss": 0.0336,
      "step": 45510
    },
    {
      "epoch": 5.48433734939759,
      "grad_norm": 0.04101064056158066,
      "learning_rate": 9.031325301204819e-06,
      "loss": 0.0086,
      "step": 45520
    },
    {
      "epoch": 5.485542168674699,
      "grad_norm": 0.24524328112602234,
      "learning_rate": 9.028915662650604e-06,
      "loss": 0.0597,
      "step": 45530
    },
    {
      "epoch": 5.486746987951808,
      "grad_norm": 0.007390284910798073,
      "learning_rate": 9.026506024096387e-06,
      "loss": 0.0148,
      "step": 45540
    },
    {
      "epoch": 5.4879518072289155,
      "grad_norm": 0.0029395187739282846,
      "learning_rate": 9.024096385542168e-06,
      "loss": 0.0136,
      "step": 45550
    },
    {
      "epoch": 5.489156626506024,
      "grad_norm": 0.02096211165189743,
      "learning_rate": 9.021686746987952e-06,
      "loss": 0.0232,
      "step": 45560
    },
    {
      "epoch": 5.490361445783132,
      "grad_norm": 0.026639968156814575,
      "learning_rate": 9.019277108433737e-06,
      "loss": 0.033,
      "step": 45570
    },
    {
      "epoch": 5.491566265060241,
      "grad_norm": 3.4850411415100098,
      "learning_rate": 9.01686746987952e-06,
      "loss": 0.0496,
      "step": 45580
    },
    {
      "epoch": 5.492771084337349,
      "grad_norm": 0.013645070604979992,
      "learning_rate": 9.014457831325301e-06,
      "loss": 0.0106,
      "step": 45590
    },
    {
      "epoch": 5.493975903614458,
      "grad_norm": 2.3287711143493652,
      "learning_rate": 9.012048192771084e-06,
      "loss": 0.0299,
      "step": 45600
    },
    {
      "epoch": 5.495180722891567,
      "grad_norm": 0.0025447076186537743,
      "learning_rate": 9.00963855421687e-06,
      "loss": 0.0363,
      "step": 45610
    },
    {
      "epoch": 5.4963855421686745,
      "grad_norm": 0.11484470963478088,
      "learning_rate": 9.00722891566265e-06,
      "loss": 0.0127,
      "step": 45620
    },
    {
      "epoch": 5.497590361445783,
      "grad_norm": 0.021424710750579834,
      "learning_rate": 9.004819277108434e-06,
      "loss": 0.0342,
      "step": 45630
    },
    {
      "epoch": 5.498795180722891,
      "grad_norm": 0.006102338433265686,
      "learning_rate": 9.002409638554219e-06,
      "loss": 0.0385,
      "step": 45640
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.027414420619606972,
      "learning_rate": 9e-06,
      "loss": 0.0019,
      "step": 45650
    },
    {
      "epoch": 5.501204819277109,
      "grad_norm": 0.004925257991999388,
      "learning_rate": 8.997590361445783e-06,
      "loss": 0.0066,
      "step": 45660
    },
    {
      "epoch": 5.502409638554217,
      "grad_norm": 5.332937240600586,
      "learning_rate": 8.995180722891567e-06,
      "loss": 0.0724,
      "step": 45670
    },
    {
      "epoch": 5.5036144578313255,
      "grad_norm": 0.016968650743365288,
      "learning_rate": 8.99277108433735e-06,
      "loss": 0.0627,
      "step": 45680
    },
    {
      "epoch": 5.504819277108433,
      "grad_norm": 0.073822982609272,
      "learning_rate": 8.990361445783133e-06,
      "loss": 0.0362,
      "step": 45690
    },
    {
      "epoch": 5.506024096385542,
      "grad_norm": 0.015316631644964218,
      "learning_rate": 8.987951807228916e-06,
      "loss": 0.0104,
      "step": 45700
    },
    {
      "epoch": 5.507228915662651,
      "grad_norm": 0.17842094600200653,
      "learning_rate": 8.9855421686747e-06,
      "loss": 0.0523,
      "step": 45710
    },
    {
      "epoch": 5.508433734939759,
      "grad_norm": 0.18700119853019714,
      "learning_rate": 8.983132530120482e-06,
      "loss": 0.036,
      "step": 45720
    },
    {
      "epoch": 5.509638554216868,
      "grad_norm": 3.818725347518921,
      "learning_rate": 8.980722891566266e-06,
      "loss": 0.0725,
      "step": 45730
    },
    {
      "epoch": 5.510843373493976,
      "grad_norm": 2.0446085929870605,
      "learning_rate": 8.978313253012049e-06,
      "loss": 0.03,
      "step": 45740
    },
    {
      "epoch": 5.5120481927710845,
      "grad_norm": 0.12079513072967529,
      "learning_rate": 8.975903614457832e-06,
      "loss": 0.0112,
      "step": 45750
    },
    {
      "epoch": 5.513253012048192,
      "grad_norm": 0.008242621086537838,
      "learning_rate": 8.973493975903615e-06,
      "loss": 0.0363,
      "step": 45760
    },
    {
      "epoch": 5.514457831325301,
      "grad_norm": 0.04612690210342407,
      "learning_rate": 8.971084337349398e-06,
      "loss": 0.0129,
      "step": 45770
    },
    {
      "epoch": 5.51566265060241,
      "grad_norm": 0.02812487632036209,
      "learning_rate": 8.968674698795182e-06,
      "loss": 0.0149,
      "step": 45780
    },
    {
      "epoch": 5.516867469879518,
      "grad_norm": 0.0036520843859761953,
      "learning_rate": 8.966265060240965e-06,
      "loss": 0.0149,
      "step": 45790
    },
    {
      "epoch": 5.518072289156627,
      "grad_norm": 0.06262947618961334,
      "learning_rate": 8.963855421686748e-06,
      "loss": 0.0401,
      "step": 45800
    },
    {
      "epoch": 5.519277108433735,
      "grad_norm": 2.7305245399475098,
      "learning_rate": 8.961445783132531e-06,
      "loss": 0.0687,
      "step": 45810
    },
    {
      "epoch": 5.5204819277108435,
      "grad_norm": 3.390561819076538,
      "learning_rate": 8.959036144578314e-06,
      "loss": 0.0346,
      "step": 45820
    },
    {
      "epoch": 5.521686746987951,
      "grad_norm": 0.35361212491989136,
      "learning_rate": 8.956626506024097e-06,
      "loss": 0.0186,
      "step": 45830
    },
    {
      "epoch": 5.52289156626506,
      "grad_norm": 0.060750044882297516,
      "learning_rate": 8.95421686746988e-06,
      "loss": 0.0219,
      "step": 45840
    },
    {
      "epoch": 5.524096385542169,
      "grad_norm": 0.0016351091908290982,
      "learning_rate": 8.951807228915664e-06,
      "loss": 0.0311,
      "step": 45850
    },
    {
      "epoch": 5.525301204819277,
      "grad_norm": 3.75355863571167,
      "learning_rate": 8.949397590361445e-06,
      "loss": 0.0187,
      "step": 45860
    },
    {
      "epoch": 5.526506024096386,
      "grad_norm": 0.019728848710656166,
      "learning_rate": 8.94698795180723e-06,
      "loss": 0.0351,
      "step": 45870
    },
    {
      "epoch": 5.527710843373494,
      "grad_norm": 0.044409338384866714,
      "learning_rate": 8.944578313253013e-06,
      "loss": 0.0455,
      "step": 45880
    },
    {
      "epoch": 5.528915662650602,
      "grad_norm": 0.40767908096313477,
      "learning_rate": 8.942168674698796e-06,
      "loss": 0.0204,
      "step": 45890
    },
    {
      "epoch": 5.530120481927711,
      "grad_norm": 0.011095015332102776,
      "learning_rate": 8.939759036144578e-06,
      "loss": 0.0111,
      "step": 45900
    },
    {
      "epoch": 5.531325301204819,
      "grad_norm": 0.517253041267395,
      "learning_rate": 8.937349397590363e-06,
      "loss": 0.0544,
      "step": 45910
    },
    {
      "epoch": 5.532530120481928,
      "grad_norm": 0.002867980394512415,
      "learning_rate": 8.934939759036146e-06,
      "loss": 0.0162,
      "step": 45920
    },
    {
      "epoch": 5.533734939759036,
      "grad_norm": 0.004106275271624327,
      "learning_rate": 8.932530120481927e-06,
      "loss": 0.0209,
      "step": 45930
    },
    {
      "epoch": 5.534939759036145,
      "grad_norm": 0.07005610316991806,
      "learning_rate": 8.930120481927712e-06,
      "loss": 0.0427,
      "step": 45940
    },
    {
      "epoch": 5.5361445783132535,
      "grad_norm": 0.3050542175769806,
      "learning_rate": 8.927710843373496e-06,
      "loss": 0.0538,
      "step": 45950
    },
    {
      "epoch": 5.537349397590361,
      "grad_norm": 0.003699101973325014,
      "learning_rate": 8.925301204819277e-06,
      "loss": 0.0198,
      "step": 45960
    },
    {
      "epoch": 5.53855421686747,
      "grad_norm": 0.017570246011018753,
      "learning_rate": 8.92289156626506e-06,
      "loss": 0.0242,
      "step": 45970
    },
    {
      "epoch": 5.539759036144578,
      "grad_norm": 0.6999732255935669,
      "learning_rate": 8.920481927710845e-06,
      "loss": 0.0043,
      "step": 45980
    },
    {
      "epoch": 5.540963855421687,
      "grad_norm": 0.003623637370765209,
      "learning_rate": 8.918072289156628e-06,
      "loss": 0.0564,
      "step": 45990
    },
    {
      "epoch": 5.542168674698795,
      "grad_norm": 0.06748529523611069,
      "learning_rate": 8.91566265060241e-06,
      "loss": 0.0245,
      "step": 46000
    },
    {
      "epoch": 5.543373493975904,
      "grad_norm": 0.15064366161823273,
      "learning_rate": 8.913253012048193e-06,
      "loss": 0.0259,
      "step": 46010
    },
    {
      "epoch": 5.544578313253012,
      "grad_norm": 0.23832865059375763,
      "learning_rate": 8.910843373493978e-06,
      "loss": 0.0182,
      "step": 46020
    },
    {
      "epoch": 5.54578313253012,
      "grad_norm": 0.04285896569490433,
      "learning_rate": 8.90843373493976e-06,
      "loss": 0.0157,
      "step": 46030
    },
    {
      "epoch": 5.546987951807229,
      "grad_norm": 0.6086339354515076,
      "learning_rate": 8.906024096385542e-06,
      "loss": 0.0606,
      "step": 46040
    },
    {
      "epoch": 5.548192771084337,
      "grad_norm": 0.0447358563542366,
      "learning_rate": 8.903614457831326e-06,
      "loss": 0.0214,
      "step": 46050
    },
    {
      "epoch": 5.549397590361446,
      "grad_norm": 3.912583351135254,
      "learning_rate": 8.901204819277109e-06,
      "loss": 0.0384,
      "step": 46060
    },
    {
      "epoch": 5.550602409638554,
      "grad_norm": 0.040230654180049896,
      "learning_rate": 8.898795180722892e-06,
      "loss": 0.0491,
      "step": 46070
    },
    {
      "epoch": 5.551807228915663,
      "grad_norm": 0.1409846395254135,
      "learning_rate": 8.896385542168675e-06,
      "loss": 0.0461,
      "step": 46080
    },
    {
      "epoch": 5.553012048192771,
      "grad_norm": 0.08370513468980789,
      "learning_rate": 8.893975903614458e-06,
      "loss": 0.0097,
      "step": 46090
    },
    {
      "epoch": 5.554216867469879,
      "grad_norm": 0.296234130859375,
      "learning_rate": 8.891566265060241e-06,
      "loss": 0.0014,
      "step": 46100
    },
    {
      "epoch": 5.555421686746988,
      "grad_norm": 0.4092499315738678,
      "learning_rate": 8.889156626506025e-06,
      "loss": 0.0319,
      "step": 46110
    },
    {
      "epoch": 5.556626506024096,
      "grad_norm": 0.9848158359527588,
      "learning_rate": 8.886746987951808e-06,
      "loss": 0.0045,
      "step": 46120
    },
    {
      "epoch": 5.557831325301205,
      "grad_norm": 0.002928467933088541,
      "learning_rate": 8.884337349397591e-06,
      "loss": 0.0095,
      "step": 46130
    },
    {
      "epoch": 5.559036144578314,
      "grad_norm": 0.0027847206220030785,
      "learning_rate": 8.881927710843374e-06,
      "loss": 0.0873,
      "step": 46140
    },
    {
      "epoch": 5.5602409638554215,
      "grad_norm": 0.10183681547641754,
      "learning_rate": 8.879518072289157e-06,
      "loss": 0.0585,
      "step": 46150
    },
    {
      "epoch": 5.56144578313253,
      "grad_norm": 3.4544286727905273,
      "learning_rate": 8.87710843373494e-06,
      "loss": 0.0338,
      "step": 46160
    },
    {
      "epoch": 5.562650602409638,
      "grad_norm": 0.19364024698734283,
      "learning_rate": 8.874698795180724e-06,
      "loss": 0.0335,
      "step": 46170
    },
    {
      "epoch": 5.563855421686747,
      "grad_norm": 3.620859146118164,
      "learning_rate": 8.872289156626507e-06,
      "loss": 0.0648,
      "step": 46180
    },
    {
      "epoch": 5.565060240963856,
      "grad_norm": 0.030763376504182816,
      "learning_rate": 8.86987951807229e-06,
      "loss": 0.0364,
      "step": 46190
    },
    {
      "epoch": 5.566265060240964,
      "grad_norm": 0.056405290961265564,
      "learning_rate": 8.867469879518073e-06,
      "loss": 0.0096,
      "step": 46200
    },
    {
      "epoch": 5.567469879518073,
      "grad_norm": 1.4079829454421997,
      "learning_rate": 8.865060240963856e-06,
      "loss": 0.0605,
      "step": 46210
    },
    {
      "epoch": 5.5686746987951805,
      "grad_norm": 1.4243067502975464,
      "learning_rate": 8.86265060240964e-06,
      "loss": 0.0312,
      "step": 46220
    },
    {
      "epoch": 5.569879518072289,
      "grad_norm": 13.468918800354004,
      "learning_rate": 8.860240963855423e-06,
      "loss": 0.01,
      "step": 46230
    },
    {
      "epoch": 5.571084337349397,
      "grad_norm": 0.1829102486371994,
      "learning_rate": 8.857831325301206e-06,
      "loss": 0.0469,
      "step": 46240
    },
    {
      "epoch": 5.572289156626506,
      "grad_norm": 6.138064384460449,
      "learning_rate": 8.855421686746989e-06,
      "loss": 0.0234,
      "step": 46250
    },
    {
      "epoch": 5.573493975903615,
      "grad_norm": 0.646626353263855,
      "learning_rate": 8.853012048192772e-06,
      "loss": 0.0034,
      "step": 46260
    },
    {
      "epoch": 5.574698795180723,
      "grad_norm": 0.1571282595396042,
      "learning_rate": 8.850602409638554e-06,
      "loss": 0.0295,
      "step": 46270
    },
    {
      "epoch": 5.575903614457832,
      "grad_norm": 0.09623431414365768,
      "learning_rate": 8.848192771084339e-06,
      "loss": 0.0361,
      "step": 46280
    },
    {
      "epoch": 5.5771084337349395,
      "grad_norm": 0.9924760460853577,
      "learning_rate": 8.845783132530122e-06,
      "loss": 0.0601,
      "step": 46290
    },
    {
      "epoch": 5.578313253012048,
      "grad_norm": 1.1459460258483887,
      "learning_rate": 8.843373493975905e-06,
      "loss": 0.0453,
      "step": 46300
    },
    {
      "epoch": 5.579518072289156,
      "grad_norm": 0.010894686914980412,
      "learning_rate": 8.840963855421686e-06,
      "loss": 0.0079,
      "step": 46310
    },
    {
      "epoch": 5.580722891566265,
      "grad_norm": 0.04483857750892639,
      "learning_rate": 8.838554216867471e-06,
      "loss": 0.0677,
      "step": 46320
    },
    {
      "epoch": 5.581927710843374,
      "grad_norm": 0.010224936529994011,
      "learning_rate": 8.836144578313255e-06,
      "loss": 0.0398,
      "step": 46330
    },
    {
      "epoch": 5.583132530120482,
      "grad_norm": 0.10265523940324783,
      "learning_rate": 8.833734939759036e-06,
      "loss": 0.0321,
      "step": 46340
    },
    {
      "epoch": 5.5843373493975905,
      "grad_norm": 0.12591269612312317,
      "learning_rate": 8.83132530120482e-06,
      "loss": 0.0516,
      "step": 46350
    },
    {
      "epoch": 5.585542168674698,
      "grad_norm": 1.0562872886657715,
      "learning_rate": 8.828915662650604e-06,
      "loss": 0.0251,
      "step": 46360
    },
    {
      "epoch": 5.586746987951807,
      "grad_norm": 0.010196730494499207,
      "learning_rate": 8.826506024096386e-06,
      "loss": 0.0015,
      "step": 46370
    },
    {
      "epoch": 5.587951807228916,
      "grad_norm": 1.129533290863037,
      "learning_rate": 8.824096385542169e-06,
      "loss": 0.0707,
      "step": 46380
    },
    {
      "epoch": 5.589156626506024,
      "grad_norm": 0.007727639749646187,
      "learning_rate": 8.821686746987954e-06,
      "loss": 0.0232,
      "step": 46390
    },
    {
      "epoch": 5.590361445783133,
      "grad_norm": 0.5384418964385986,
      "learning_rate": 8.819277108433735e-06,
      "loss": 0.0448,
      "step": 46400
    },
    {
      "epoch": 5.591566265060241,
      "grad_norm": 0.3349529504776001,
      "learning_rate": 8.816867469879518e-06,
      "loss": 0.0339,
      "step": 46410
    },
    {
      "epoch": 5.5927710843373495,
      "grad_norm": 0.01859401911497116,
      "learning_rate": 8.814457831325301e-06,
      "loss": 0.0032,
      "step": 46420
    },
    {
      "epoch": 5.593975903614458,
      "grad_norm": 3.5811283588409424,
      "learning_rate": 8.812048192771086e-06,
      "loss": 0.0556,
      "step": 46430
    },
    {
      "epoch": 5.595180722891566,
      "grad_norm": 5.941897869110107,
      "learning_rate": 8.809638554216868e-06,
      "loss": 0.0738,
      "step": 46440
    },
    {
      "epoch": 5.596385542168675,
      "grad_norm": 2.884247303009033,
      "learning_rate": 8.807228915662651e-06,
      "loss": 0.0271,
      "step": 46450
    },
    {
      "epoch": 5.597590361445783,
      "grad_norm": 15.027702331542969,
      "learning_rate": 8.804819277108434e-06,
      "loss": 0.0684,
      "step": 46460
    },
    {
      "epoch": 5.598795180722892,
      "grad_norm": 0.6725634336471558,
      "learning_rate": 8.802409638554217e-06,
      "loss": 0.0174,
      "step": 46470
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.25149375200271606,
      "learning_rate": 8.8e-06,
      "loss": 0.0114,
      "step": 46480
    },
    {
      "epoch": 5.6012048192771084,
      "grad_norm": 1.3680342435836792,
      "learning_rate": 8.797590361445784e-06,
      "loss": 0.0414,
      "step": 46490
    },
    {
      "epoch": 5.602409638554217,
      "grad_norm": 0.014851520769298077,
      "learning_rate": 8.795180722891567e-06,
      "loss": 0.0593,
      "step": 46500
    },
    {
      "epoch": 5.603614457831325,
      "grad_norm": 0.8393808603286743,
      "learning_rate": 8.79277108433735e-06,
      "loss": 0.0096,
      "step": 46510
    },
    {
      "epoch": 5.604819277108434,
      "grad_norm": 2.014796733856201,
      "learning_rate": 8.790361445783133e-06,
      "loss": 0.0171,
      "step": 46520
    },
    {
      "epoch": 5.606024096385542,
      "grad_norm": 3.971970796585083,
      "learning_rate": 8.787951807228916e-06,
      "loss": 0.0308,
      "step": 46530
    },
    {
      "epoch": 5.607228915662651,
      "grad_norm": 1.4306422472000122,
      "learning_rate": 8.7855421686747e-06,
      "loss": 0.046,
      "step": 46540
    },
    {
      "epoch": 5.608433734939759,
      "grad_norm": 0.0035917742643505335,
      "learning_rate": 8.783132530120483e-06,
      "loss": 0.0538,
      "step": 46550
    },
    {
      "epoch": 5.609638554216867,
      "grad_norm": 3.424854040145874,
      "learning_rate": 8.780722891566266e-06,
      "loss": 0.0601,
      "step": 46560
    },
    {
      "epoch": 5.610843373493976,
      "grad_norm": 0.0072373258881270885,
      "learning_rate": 8.778313253012049e-06,
      "loss": 0.0312,
      "step": 46570
    },
    {
      "epoch": 5.612048192771084,
      "grad_norm": 1.5337659120559692,
      "learning_rate": 8.775903614457832e-06,
      "loss": 0.009,
      "step": 46580
    },
    {
      "epoch": 5.613253012048193,
      "grad_norm": 11.211605072021484,
      "learning_rate": 8.773493975903615e-06,
      "loss": 0.1014,
      "step": 46590
    },
    {
      "epoch": 5.614457831325301,
      "grad_norm": 0.7240513563156128,
      "learning_rate": 8.771084337349399e-06,
      "loss": 0.0291,
      "step": 46600
    },
    {
      "epoch": 5.61566265060241,
      "grad_norm": 0.0132940374314785,
      "learning_rate": 8.768674698795182e-06,
      "loss": 0.0164,
      "step": 46610
    },
    {
      "epoch": 5.6168674698795185,
      "grad_norm": 2.110616683959961,
      "learning_rate": 8.766265060240965e-06,
      "loss": 0.0176,
      "step": 46620
    },
    {
      "epoch": 5.618072289156626,
      "grad_norm": 0.30379703640937805,
      "learning_rate": 8.763855421686748e-06,
      "loss": 0.0082,
      "step": 46630
    },
    {
      "epoch": 5.619277108433735,
      "grad_norm": 0.041539933532476425,
      "learning_rate": 8.761445783132531e-06,
      "loss": 0.0154,
      "step": 46640
    },
    {
      "epoch": 5.620481927710843,
      "grad_norm": 1.6741094589233398,
      "learning_rate": 8.759036144578313e-06,
      "loss": 0.0273,
      "step": 46650
    },
    {
      "epoch": 5.621686746987952,
      "grad_norm": 0.8821253776550293,
      "learning_rate": 8.756626506024098e-06,
      "loss": 0.0093,
      "step": 46660
    },
    {
      "epoch": 5.622891566265061,
      "grad_norm": 0.00469072675332427,
      "learning_rate": 8.75421686746988e-06,
      "loss": 0.0057,
      "step": 46670
    },
    {
      "epoch": 5.624096385542169,
      "grad_norm": 2.524418830871582,
      "learning_rate": 8.751807228915662e-06,
      "loss": 0.0332,
      "step": 46680
    },
    {
      "epoch": 5.625301204819277,
      "grad_norm": 21.200803756713867,
      "learning_rate": 8.749397590361447e-06,
      "loss": 0.0269,
      "step": 46690
    },
    {
      "epoch": 5.626506024096385,
      "grad_norm": 0.0038899986539036036,
      "learning_rate": 8.74698795180723e-06,
      "loss": 0.0255,
      "step": 46700
    },
    {
      "epoch": 5.627710843373494,
      "grad_norm": 0.005376922432333231,
      "learning_rate": 8.744578313253013e-06,
      "loss": 0.0419,
      "step": 46710
    },
    {
      "epoch": 5.628915662650602,
      "grad_norm": 0.009891475550830364,
      "learning_rate": 8.742168674698795e-06,
      "loss": 0.024,
      "step": 46720
    },
    {
      "epoch": 5.630120481927711,
      "grad_norm": 0.013413171283900738,
      "learning_rate": 8.73975903614458e-06,
      "loss": 0.0688,
      "step": 46730
    },
    {
      "epoch": 5.63132530120482,
      "grad_norm": 1.2080905437469482,
      "learning_rate": 8.737349397590363e-06,
      "loss": 0.0059,
      "step": 46740
    },
    {
      "epoch": 5.632530120481928,
      "grad_norm": 0.9615809917449951,
      "learning_rate": 8.734939759036145e-06,
      "loss": 0.0246,
      "step": 46750
    },
    {
      "epoch": 5.633734939759036,
      "grad_norm": 0.059745851904153824,
      "learning_rate": 8.732530120481928e-06,
      "loss": 0.0149,
      "step": 46760
    },
    {
      "epoch": 5.634939759036144,
      "grad_norm": 0.2835860550403595,
      "learning_rate": 8.730120481927713e-06,
      "loss": 0.0056,
      "step": 46770
    },
    {
      "epoch": 5.636144578313253,
      "grad_norm": 0.0055482457391917706,
      "learning_rate": 8.727710843373494e-06,
      "loss": 0.0083,
      "step": 46780
    },
    {
      "epoch": 5.637349397590361,
      "grad_norm": 0.00585880596190691,
      "learning_rate": 8.725301204819277e-06,
      "loss": 0.0298,
      "step": 46790
    },
    {
      "epoch": 5.63855421686747,
      "grad_norm": 0.6694639325141907,
      "learning_rate": 8.722891566265062e-06,
      "loss": 0.0096,
      "step": 46800
    },
    {
      "epoch": 5.639759036144579,
      "grad_norm": 0.010117079131305218,
      "learning_rate": 8.720481927710844e-06,
      "loss": 0.0495,
      "step": 46810
    },
    {
      "epoch": 5.6409638554216865,
      "grad_norm": 16.255952835083008,
      "learning_rate": 8.718072289156627e-06,
      "loss": 0.0198,
      "step": 46820
    },
    {
      "epoch": 5.642168674698795,
      "grad_norm": 0.07074695825576782,
      "learning_rate": 8.71566265060241e-06,
      "loss": 0.0333,
      "step": 46830
    },
    {
      "epoch": 5.643373493975903,
      "grad_norm": 1.2406916618347168,
      "learning_rate": 8.713253012048195e-06,
      "loss": 0.0215,
      "step": 46840
    },
    {
      "epoch": 5.644578313253012,
      "grad_norm": 1.4309998750686646,
      "learning_rate": 8.710843373493976e-06,
      "loss": 0.0172,
      "step": 46850
    },
    {
      "epoch": 5.64578313253012,
      "grad_norm": 0.7792197465896606,
      "learning_rate": 8.70843373493976e-06,
      "loss": 0.0043,
      "step": 46860
    },
    {
      "epoch": 5.646987951807229,
      "grad_norm": 2.960402727127075,
      "learning_rate": 8.706024096385543e-06,
      "loss": 0.0956,
      "step": 46870
    },
    {
      "epoch": 5.648192771084338,
      "grad_norm": 0.021466050297021866,
      "learning_rate": 8.703614457831326e-06,
      "loss": 0.0226,
      "step": 46880
    },
    {
      "epoch": 5.6493975903614455,
      "grad_norm": 0.3010091781616211,
      "learning_rate": 8.701204819277109e-06,
      "loss": 0.0123,
      "step": 46890
    },
    {
      "epoch": 5.650602409638554,
      "grad_norm": 0.0481032095849514,
      "learning_rate": 8.698795180722892e-06,
      "loss": 0.0212,
      "step": 46900
    },
    {
      "epoch": 5.651807228915663,
      "grad_norm": 0.011229680851101875,
      "learning_rate": 8.696385542168675e-06,
      "loss": 0.0047,
      "step": 46910
    },
    {
      "epoch": 5.653012048192771,
      "grad_norm": 0.05477632209658623,
      "learning_rate": 8.693975903614458e-06,
      "loss": 0.0021,
      "step": 46920
    },
    {
      "epoch": 5.65421686746988,
      "grad_norm": 0.0036402547266334295,
      "learning_rate": 8.691566265060242e-06,
      "loss": 0.0253,
      "step": 46930
    },
    {
      "epoch": 5.655421686746988,
      "grad_norm": 0.06469706445932388,
      "learning_rate": 8.689156626506025e-06,
      "loss": 0.0238,
      "step": 46940
    },
    {
      "epoch": 5.656626506024097,
      "grad_norm": 0.004553828854113817,
      "learning_rate": 8.686746987951808e-06,
      "loss": 0.0231,
      "step": 46950
    },
    {
      "epoch": 5.6578313253012045,
      "grad_norm": 0.03205789625644684,
      "learning_rate": 8.684337349397591e-06,
      "loss": 0.0246,
      "step": 46960
    },
    {
      "epoch": 5.659036144578313,
      "grad_norm": 0.01131153292953968,
      "learning_rate": 8.681927710843374e-06,
      "loss": 0.0478,
      "step": 46970
    },
    {
      "epoch": 5.660240963855422,
      "grad_norm": 0.1365930140018463,
      "learning_rate": 8.679518072289158e-06,
      "loss": 0.0087,
      "step": 46980
    },
    {
      "epoch": 5.66144578313253,
      "grad_norm": 0.039283495396375656,
      "learning_rate": 8.67710843373494e-06,
      "loss": 0.0194,
      "step": 46990
    },
    {
      "epoch": 5.662650602409639,
      "grad_norm": 1.4290608167648315,
      "learning_rate": 8.674698795180724e-06,
      "loss": 0.0164,
      "step": 47000
    },
    {
      "epoch": 5.663855421686747,
      "grad_norm": 0.006716783158481121,
      "learning_rate": 8.672289156626507e-06,
      "loss": 0.0656,
      "step": 47010
    },
    {
      "epoch": 5.6650602409638555,
      "grad_norm": 0.018886582925915718,
      "learning_rate": 8.66987951807229e-06,
      "loss": 0.0423,
      "step": 47020
    },
    {
      "epoch": 5.666265060240963,
      "grad_norm": 2.053856372833252,
      "learning_rate": 8.667469879518073e-06,
      "loss": 0.0233,
      "step": 47030
    },
    {
      "epoch": 5.667469879518072,
      "grad_norm": 0.005271463189274073,
      "learning_rate": 8.665060240963857e-06,
      "loss": 0.0364,
      "step": 47040
    },
    {
      "epoch": 5.668674698795181,
      "grad_norm": 1.3066996335983276,
      "learning_rate": 8.66265060240964e-06,
      "loss": 0.0058,
      "step": 47050
    },
    {
      "epoch": 5.669879518072289,
      "grad_norm": 2.1384060382843018,
      "learning_rate": 8.660240963855421e-06,
      "loss": 0.0839,
      "step": 47060
    },
    {
      "epoch": 5.671084337349398,
      "grad_norm": 0.057190027087926865,
      "learning_rate": 8.657831325301206e-06,
      "loss": 0.0484,
      "step": 47070
    },
    {
      "epoch": 5.672289156626506,
      "grad_norm": 1.6927870512008667,
      "learning_rate": 8.65542168674699e-06,
      "loss": 0.0235,
      "step": 47080
    },
    {
      "epoch": 5.6734939759036145,
      "grad_norm": 4.1980695724487305,
      "learning_rate": 8.65301204819277e-06,
      "loss": 0.0142,
      "step": 47090
    },
    {
      "epoch": 5.674698795180722,
      "grad_norm": 0.2779587507247925,
      "learning_rate": 8.650602409638556e-06,
      "loss": 0.019,
      "step": 47100
    },
    {
      "epoch": 5.675903614457831,
      "grad_norm": 0.0076771872118115425,
      "learning_rate": 8.648192771084339e-06,
      "loss": 0.0071,
      "step": 47110
    },
    {
      "epoch": 5.67710843373494,
      "grad_norm": 1.1494678258895874,
      "learning_rate": 8.64578313253012e-06,
      "loss": 0.0375,
      "step": 47120
    },
    {
      "epoch": 5.678313253012048,
      "grad_norm": 0.38468655943870544,
      "learning_rate": 8.643373493975904e-06,
      "loss": 0.0419,
      "step": 47130
    },
    {
      "epoch": 5.679518072289157,
      "grad_norm": 0.010272342711687088,
      "learning_rate": 8.640963855421688e-06,
      "loss": 0.0047,
      "step": 47140
    },
    {
      "epoch": 5.6807228915662655,
      "grad_norm": 0.022331703454256058,
      "learning_rate": 8.638554216867472e-06,
      "loss": 0.0043,
      "step": 47150
    },
    {
      "epoch": 5.6819277108433734,
      "grad_norm": 0.004429698456078768,
      "learning_rate": 8.636144578313253e-06,
      "loss": 0.0414,
      "step": 47160
    },
    {
      "epoch": 5.683132530120482,
      "grad_norm": 2.2072179317474365,
      "learning_rate": 8.633734939759036e-06,
      "loss": 0.0255,
      "step": 47170
    },
    {
      "epoch": 5.68433734939759,
      "grad_norm": 5.447513580322266,
      "learning_rate": 8.631325301204821e-06,
      "loss": 0.0218,
      "step": 47180
    },
    {
      "epoch": 5.685542168674699,
      "grad_norm": 0.5422533750534058,
      "learning_rate": 8.628915662650603e-06,
      "loss": 0.035,
      "step": 47190
    },
    {
      "epoch": 5.686746987951807,
      "grad_norm": 0.005790965165942907,
      "learning_rate": 8.626506024096386e-06,
      "loss": 0.0444,
      "step": 47200
    },
    {
      "epoch": 5.687951807228916,
      "grad_norm": 0.2893935739994049,
      "learning_rate": 8.624096385542169e-06,
      "loss": 0.0204,
      "step": 47210
    },
    {
      "epoch": 5.6891566265060245,
      "grad_norm": 0.9831055402755737,
      "learning_rate": 8.621686746987952e-06,
      "loss": 0.0424,
      "step": 47220
    },
    {
      "epoch": 5.690361445783132,
      "grad_norm": 1.913949728012085,
      "learning_rate": 8.619277108433735e-06,
      "loss": 0.0177,
      "step": 47230
    },
    {
      "epoch": 5.691566265060241,
      "grad_norm": 0.011274456977844238,
      "learning_rate": 8.616867469879518e-06,
      "loss": 0.0532,
      "step": 47240
    },
    {
      "epoch": 5.692771084337349,
      "grad_norm": 4.488404273986816,
      "learning_rate": 8.614457831325302e-06,
      "loss": 0.0456,
      "step": 47250
    },
    {
      "epoch": 5.693975903614458,
      "grad_norm": 0.023236550390720367,
      "learning_rate": 8.612048192771085e-06,
      "loss": 0.018,
      "step": 47260
    },
    {
      "epoch": 5.695180722891566,
      "grad_norm": 0.011116734705865383,
      "learning_rate": 8.609638554216868e-06,
      "loss": 0.0161,
      "step": 47270
    },
    {
      "epoch": 5.696385542168675,
      "grad_norm": 0.9816447496414185,
      "learning_rate": 8.607228915662651e-06,
      "loss": 0.0231,
      "step": 47280
    },
    {
      "epoch": 5.6975903614457835,
      "grad_norm": 0.0048509701155126095,
      "learning_rate": 8.604819277108434e-06,
      "loss": 0.0161,
      "step": 47290
    },
    {
      "epoch": 5.698795180722891,
      "grad_norm": 0.11335035413503647,
      "learning_rate": 8.602409638554217e-06,
      "loss": 0.014,
      "step": 47300
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.4264843165874481,
      "learning_rate": 8.6e-06,
      "loss": 0.0056,
      "step": 47310
    },
    {
      "epoch": 5.701204819277108,
      "grad_norm": 1.6523215770721436,
      "learning_rate": 8.597590361445784e-06,
      "loss": 0.0146,
      "step": 47320
    },
    {
      "epoch": 5.702409638554217,
      "grad_norm": 0.0030986701603978872,
      "learning_rate": 8.595180722891567e-06,
      "loss": 0.05,
      "step": 47330
    },
    {
      "epoch": 5.703614457831325,
      "grad_norm": 1.8743791580200195,
      "learning_rate": 8.59277108433735e-06,
      "loss": 0.0633,
      "step": 47340
    },
    {
      "epoch": 5.704819277108434,
      "grad_norm": 0.6777193546295166,
      "learning_rate": 8.590361445783133e-06,
      "loss": 0.0513,
      "step": 47350
    },
    {
      "epoch": 5.706024096385542,
      "grad_norm": 2.563608169555664,
      "learning_rate": 8.587951807228917e-06,
      "loss": 0.014,
      "step": 47360
    },
    {
      "epoch": 5.70722891566265,
      "grad_norm": 0.011769982054829597,
      "learning_rate": 8.5855421686747e-06,
      "loss": 0.0332,
      "step": 47370
    },
    {
      "epoch": 5.708433734939759,
      "grad_norm": 0.29686179757118225,
      "learning_rate": 8.583132530120483e-06,
      "loss": 0.0268,
      "step": 47380
    },
    {
      "epoch": 5.709638554216868,
      "grad_norm": 0.01351391151547432,
      "learning_rate": 8.580722891566266e-06,
      "loss": 0.0223,
      "step": 47390
    },
    {
      "epoch": 5.710843373493976,
      "grad_norm": 0.025114774703979492,
      "learning_rate": 8.57831325301205e-06,
      "loss": 0.0322,
      "step": 47400
    },
    {
      "epoch": 5.712048192771085,
      "grad_norm": 3.1705636978149414,
      "learning_rate": 8.575903614457832e-06,
      "loss": 0.0329,
      "step": 47410
    },
    {
      "epoch": 5.713253012048193,
      "grad_norm": 0.03754651919007301,
      "learning_rate": 8.573493975903616e-06,
      "loss": 0.0066,
      "step": 47420
    },
    {
      "epoch": 5.714457831325301,
      "grad_norm": 0.40735623240470886,
      "learning_rate": 8.571084337349397e-06,
      "loss": 0.0148,
      "step": 47430
    },
    {
      "epoch": 5.715662650602409,
      "grad_norm": 1.794057846069336,
      "learning_rate": 8.568674698795182e-06,
      "loss": 0.0557,
      "step": 47440
    },
    {
      "epoch": 5.716867469879518,
      "grad_norm": 2.5292651653289795,
      "learning_rate": 8.566265060240965e-06,
      "loss": 0.0639,
      "step": 47450
    },
    {
      "epoch": 5.718072289156627,
      "grad_norm": 1.912874698638916,
      "learning_rate": 8.563855421686748e-06,
      "loss": 0.0468,
      "step": 47460
    },
    {
      "epoch": 5.719277108433735,
      "grad_norm": 0.07888273894786835,
      "learning_rate": 8.56144578313253e-06,
      "loss": 0.0178,
      "step": 47470
    },
    {
      "epoch": 5.720481927710844,
      "grad_norm": 0.0123216537758708,
      "learning_rate": 8.559036144578315e-06,
      "loss": 0.0463,
      "step": 47480
    },
    {
      "epoch": 5.7216867469879515,
      "grad_norm": 0.20853693783283234,
      "learning_rate": 8.556626506024098e-06,
      "loss": 0.0167,
      "step": 47490
    },
    {
      "epoch": 5.72289156626506,
      "grad_norm": 0.01563367061316967,
      "learning_rate": 8.55421686746988e-06,
      "loss": 0.0162,
      "step": 47500
    },
    {
      "epoch": 5.724096385542168,
      "grad_norm": 1.4727387428283691,
      "learning_rate": 8.551807228915662e-06,
      "loss": 0.0067,
      "step": 47510
    },
    {
      "epoch": 5.725301204819277,
      "grad_norm": 15.735328674316406,
      "learning_rate": 8.549397590361447e-06,
      "loss": 0.0407,
      "step": 47520
    },
    {
      "epoch": 5.726506024096386,
      "grad_norm": 0.7217247486114502,
      "learning_rate": 8.546987951807229e-06,
      "loss": 0.0436,
      "step": 47530
    },
    {
      "epoch": 5.727710843373494,
      "grad_norm": 0.37589824199676514,
      "learning_rate": 8.544578313253012e-06,
      "loss": 0.0038,
      "step": 47540
    },
    {
      "epoch": 5.728915662650603,
      "grad_norm": 0.006529103498905897,
      "learning_rate": 8.542168674698797e-06,
      "loss": 0.0403,
      "step": 47550
    },
    {
      "epoch": 5.7301204819277105,
      "grad_norm": 0.06028364971280098,
      "learning_rate": 8.53975903614458e-06,
      "loss": 0.0121,
      "step": 47560
    },
    {
      "epoch": 5.731325301204819,
      "grad_norm": 0.35418349504470825,
      "learning_rate": 8.537349397590362e-06,
      "loss": 0.1021,
      "step": 47570
    },
    {
      "epoch": 5.732530120481927,
      "grad_norm": 0.027570953592658043,
      "learning_rate": 8.534939759036145e-06,
      "loss": 0.0702,
      "step": 47580
    },
    {
      "epoch": 5.733734939759036,
      "grad_norm": 23.35197639465332,
      "learning_rate": 8.53253012048193e-06,
      "loss": 0.0936,
      "step": 47590
    },
    {
      "epoch": 5.734939759036145,
      "grad_norm": 0.022242911159992218,
      "learning_rate": 8.530120481927711e-06,
      "loss": 0.0219,
      "step": 47600
    },
    {
      "epoch": 5.736144578313253,
      "grad_norm": 0.07566263526678085,
      "learning_rate": 8.527710843373494e-06,
      "loss": 0.0041,
      "step": 47610
    },
    {
      "epoch": 5.7373493975903616,
      "grad_norm": 0.005885754711925983,
      "learning_rate": 8.525301204819277e-06,
      "loss": 0.0228,
      "step": 47620
    },
    {
      "epoch": 5.73855421686747,
      "grad_norm": 0.11109161376953125,
      "learning_rate": 8.52289156626506e-06,
      "loss": 0.0205,
      "step": 47630
    },
    {
      "epoch": 5.739759036144578,
      "grad_norm": 0.005676353350281715,
      "learning_rate": 8.520481927710844e-06,
      "loss": 0.0252,
      "step": 47640
    },
    {
      "epoch": 5.740963855421687,
      "grad_norm": 0.022924747318029404,
      "learning_rate": 8.518072289156627e-06,
      "loss": 0.0302,
      "step": 47650
    },
    {
      "epoch": 5.742168674698795,
      "grad_norm": 16.58026885986328,
      "learning_rate": 8.51566265060241e-06,
      "loss": 0.0267,
      "step": 47660
    },
    {
      "epoch": 5.743373493975904,
      "grad_norm": 0.010421146638691425,
      "learning_rate": 8.513253012048193e-06,
      "loss": 0.0182,
      "step": 47670
    },
    {
      "epoch": 5.744578313253012,
      "grad_norm": 0.01750084199011326,
      "learning_rate": 8.510843373493976e-06,
      "loss": 0.0074,
      "step": 47680
    },
    {
      "epoch": 5.7457831325301205,
      "grad_norm": 1.6728523969650269,
      "learning_rate": 8.50843373493976e-06,
      "loss": 0.0134,
      "step": 47690
    },
    {
      "epoch": 5.746987951807229,
      "grad_norm": 3.332578182220459,
      "learning_rate": 8.506024096385543e-06,
      "loss": 0.027,
      "step": 47700
    },
    {
      "epoch": 5.748192771084337,
      "grad_norm": 0.003666206495836377,
      "learning_rate": 8.503614457831326e-06,
      "loss": 0.0215,
      "step": 47710
    },
    {
      "epoch": 5.749397590361446,
      "grad_norm": 0.0228238794952631,
      "learning_rate": 8.50120481927711e-06,
      "loss": 0.0498,
      "step": 47720
    },
    {
      "epoch": 5.750602409638554,
      "grad_norm": 3.064281702041626,
      "learning_rate": 8.498795180722892e-06,
      "loss": 0.0108,
      "step": 47730
    },
    {
      "epoch": 5.751807228915663,
      "grad_norm": 0.6513490080833435,
      "learning_rate": 8.496385542168676e-06,
      "loss": 0.0166,
      "step": 47740
    },
    {
      "epoch": 5.753012048192771,
      "grad_norm": 0.016872307285666466,
      "learning_rate": 8.493975903614459e-06,
      "loss": 0.0411,
      "step": 47750
    },
    {
      "epoch": 5.7542168674698795,
      "grad_norm": 2.84605073928833,
      "learning_rate": 8.491566265060242e-06,
      "loss": 0.0409,
      "step": 47760
    },
    {
      "epoch": 5.755421686746988,
      "grad_norm": 0.14418722689151764,
      "learning_rate": 8.489156626506025e-06,
      "loss": 0.002,
      "step": 47770
    },
    {
      "epoch": 5.756626506024096,
      "grad_norm": 0.006888872478157282,
      "learning_rate": 8.486746987951808e-06,
      "loss": 0.0427,
      "step": 47780
    },
    {
      "epoch": 5.757831325301205,
      "grad_norm": 0.1048935130238533,
      "learning_rate": 8.484337349397591e-06,
      "loss": 0.0121,
      "step": 47790
    },
    {
      "epoch": 5.759036144578313,
      "grad_norm": 0.004030664451420307,
      "learning_rate": 8.481927710843375e-06,
      "loss": 0.013,
      "step": 47800
    },
    {
      "epoch": 5.760240963855422,
      "grad_norm": 0.29519006609916687,
      "learning_rate": 8.479518072289156e-06,
      "loss": 0.0295,
      "step": 47810
    },
    {
      "epoch": 5.76144578313253,
      "grad_norm": 0.0034331681672483683,
      "learning_rate": 8.477108433734941e-06,
      "loss": 0.0025,
      "step": 47820
    },
    {
      "epoch": 5.7626506024096384,
      "grad_norm": 0.036778081208467484,
      "learning_rate": 8.474698795180724e-06,
      "loss": 0.0501,
      "step": 47830
    },
    {
      "epoch": 5.763855421686747,
      "grad_norm": 0.1362365186214447,
      "learning_rate": 8.472289156626506e-06,
      "loss": 0.0229,
      "step": 47840
    },
    {
      "epoch": 5.765060240963855,
      "grad_norm": 0.018593819811940193,
      "learning_rate": 8.46987951807229e-06,
      "loss": 0.0244,
      "step": 47850
    },
    {
      "epoch": 5.766265060240964,
      "grad_norm": 0.008649027906358242,
      "learning_rate": 8.467469879518074e-06,
      "loss": 0.0189,
      "step": 47860
    },
    {
      "epoch": 5.767469879518073,
      "grad_norm": 0.01777970977127552,
      "learning_rate": 8.465060240963857e-06,
      "loss": 0.0326,
      "step": 47870
    },
    {
      "epoch": 5.768674698795181,
      "grad_norm": 3.8167033195495605,
      "learning_rate": 8.462650602409638e-06,
      "loss": 0.0171,
      "step": 47880
    },
    {
      "epoch": 5.7698795180722895,
      "grad_norm": 2.645359992980957,
      "learning_rate": 8.460240963855423e-06,
      "loss": 0.0629,
      "step": 47890
    },
    {
      "epoch": 5.771084337349397,
      "grad_norm": 1.5292783975601196,
      "learning_rate": 8.457831325301206e-06,
      "loss": 0.0192,
      "step": 47900
    },
    {
      "epoch": 5.772289156626506,
      "grad_norm": 0.05053769797086716,
      "learning_rate": 8.455421686746988e-06,
      "loss": 0.0105,
      "step": 47910
    },
    {
      "epoch": 5.773493975903614,
      "grad_norm": 4.67378044128418,
      "learning_rate": 8.453012048192771e-06,
      "loss": 0.0346,
      "step": 47920
    },
    {
      "epoch": 5.774698795180723,
      "grad_norm": 0.04239751026034355,
      "learning_rate": 8.450602409638556e-06,
      "loss": 0.0089,
      "step": 47930
    },
    {
      "epoch": 5.775903614457832,
      "grad_norm": 1.9378023147583008,
      "learning_rate": 8.448192771084337e-06,
      "loss": 0.0205,
      "step": 47940
    },
    {
      "epoch": 5.77710843373494,
      "grad_norm": 0.3121725916862488,
      "learning_rate": 8.44578313253012e-06,
      "loss": 0.0431,
      "step": 47950
    },
    {
      "epoch": 5.7783132530120485,
      "grad_norm": 1.119677186012268,
      "learning_rate": 8.443373493975904e-06,
      "loss": 0.0434,
      "step": 47960
    },
    {
      "epoch": 5.779518072289156,
      "grad_norm": 0.039430566132068634,
      "learning_rate": 8.440963855421687e-06,
      "loss": 0.0459,
      "step": 47970
    },
    {
      "epoch": 5.780722891566265,
      "grad_norm": 0.02288966439664364,
      "learning_rate": 8.43855421686747e-06,
      "loss": 0.0367,
      "step": 47980
    },
    {
      "epoch": 5.781927710843373,
      "grad_norm": 0.6523217558860779,
      "learning_rate": 8.436144578313253e-06,
      "loss": 0.018,
      "step": 47990
    },
    {
      "epoch": 5.783132530120482,
      "grad_norm": 0.01471326407045126,
      "learning_rate": 8.433734939759038e-06,
      "loss": 0.0099,
      "step": 48000
    },
    {
      "epoch": 5.784337349397591,
      "grad_norm": 0.09768617898225784,
      "learning_rate": 8.43132530120482e-06,
      "loss": 0.0153,
      "step": 48010
    },
    {
      "epoch": 5.785542168674699,
      "grad_norm": 1.5641722679138184,
      "learning_rate": 8.428915662650603e-06,
      "loss": 0.0092,
      "step": 48020
    },
    {
      "epoch": 5.786746987951807,
      "grad_norm": 1.209603190422058,
      "learning_rate": 8.426506024096386e-06,
      "loss": 0.049,
      "step": 48030
    },
    {
      "epoch": 5.787951807228915,
      "grad_norm": 3.107058525085449,
      "learning_rate": 8.424096385542169e-06,
      "loss": 0.0358,
      "step": 48040
    },
    {
      "epoch": 5.789156626506024,
      "grad_norm": 1.0071343183517456,
      "learning_rate": 8.421686746987952e-06,
      "loss": 0.0783,
      "step": 48050
    },
    {
      "epoch": 5.790361445783132,
      "grad_norm": 0.05232318490743637,
      "learning_rate": 8.419277108433735e-06,
      "loss": 0.0176,
      "step": 48060
    },
    {
      "epoch": 5.791566265060241,
      "grad_norm": 0.2980969548225403,
      "learning_rate": 8.416867469879519e-06,
      "loss": 0.0244,
      "step": 48070
    },
    {
      "epoch": 5.79277108433735,
      "grad_norm": 0.04302484914660454,
      "learning_rate": 8.414457831325302e-06,
      "loss": 0.0364,
      "step": 48080
    },
    {
      "epoch": 5.793975903614458,
      "grad_norm": 0.05009222403168678,
      "learning_rate": 8.412048192771085e-06,
      "loss": 0.037,
      "step": 48090
    },
    {
      "epoch": 5.795180722891566,
      "grad_norm": 0.016225198283791542,
      "learning_rate": 8.409638554216868e-06,
      "loss": 0.0156,
      "step": 48100
    },
    {
      "epoch": 5.796385542168675,
      "grad_norm": 1.4729177951812744,
      "learning_rate": 8.407228915662651e-06,
      "loss": 0.0922,
      "step": 48110
    },
    {
      "epoch": 5.797590361445783,
      "grad_norm": 0.028004538267850876,
      "learning_rate": 8.404819277108435e-06,
      "loss": 0.0155,
      "step": 48120
    },
    {
      "epoch": 5.798795180722892,
      "grad_norm": 1.6863858699798584,
      "learning_rate": 8.402409638554218e-06,
      "loss": 0.0269,
      "step": 48130
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.011625918559730053,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0322,
      "step": 48140
    },
    {
      "epoch": 5.801204819277109,
      "grad_norm": 0.4999983608722687,
      "learning_rate": 8.397590361445784e-06,
      "loss": 0.0166,
      "step": 48150
    },
    {
      "epoch": 5.8024096385542165,
      "grad_norm": 0.06512019783258438,
      "learning_rate": 8.395180722891567e-06,
      "loss": 0.0129,
      "step": 48160
    },
    {
      "epoch": 5.803614457831325,
      "grad_norm": 8.575212478637695,
      "learning_rate": 8.39277108433735e-06,
      "loss": 0.0203,
      "step": 48170
    },
    {
      "epoch": 5.804819277108434,
      "grad_norm": 2.1652486324310303,
      "learning_rate": 8.390361445783134e-06,
      "loss": 0.0462,
      "step": 48180
    },
    {
      "epoch": 5.806024096385542,
      "grad_norm": 0.4472469091415405,
      "learning_rate": 8.387951807228917e-06,
      "loss": 0.0075,
      "step": 48190
    },
    {
      "epoch": 5.807228915662651,
      "grad_norm": 0.0042178090661764145,
      "learning_rate": 8.3855421686747e-06,
      "loss": 0.0423,
      "step": 48200
    },
    {
      "epoch": 5.808433734939759,
      "grad_norm": 0.019275173544883728,
      "learning_rate": 8.383132530120483e-06,
      "loss": 0.023,
      "step": 48210
    },
    {
      "epoch": 5.809638554216868,
      "grad_norm": 1.4079567193984985,
      "learning_rate": 8.380722891566265e-06,
      "loss": 0.026,
      "step": 48220
    },
    {
      "epoch": 5.8108433734939755,
      "grad_norm": 0.3094061613082886,
      "learning_rate": 8.37831325301205e-06,
      "loss": 0.016,
      "step": 48230
    },
    {
      "epoch": 5.812048192771084,
      "grad_norm": 0.008724411018192768,
      "learning_rate": 8.375903614457833e-06,
      "loss": 0.0062,
      "step": 48240
    },
    {
      "epoch": 5.813253012048193,
      "grad_norm": 0.12519879639148712,
      "learning_rate": 8.373493975903614e-06,
      "loss": 0.006,
      "step": 48250
    },
    {
      "epoch": 5.814457831325301,
      "grad_norm": 0.35119253396987915,
      "learning_rate": 8.371084337349397e-06,
      "loss": 0.0031,
      "step": 48260
    },
    {
      "epoch": 5.81566265060241,
      "grad_norm": 0.29258301854133606,
      "learning_rate": 8.368674698795182e-06,
      "loss": 0.0457,
      "step": 48270
    },
    {
      "epoch": 5.816867469879518,
      "grad_norm": 0.002214602893218398,
      "learning_rate": 8.366265060240965e-06,
      "loss": 0.0374,
      "step": 48280
    },
    {
      "epoch": 5.8180722891566266,
      "grad_norm": 15.267662048339844,
      "learning_rate": 8.363855421686747e-06,
      "loss": 0.0657,
      "step": 48290
    },
    {
      "epoch": 5.8192771084337345,
      "grad_norm": 3.3616995811462402,
      "learning_rate": 8.361445783132532e-06,
      "loss": 0.0489,
      "step": 48300
    },
    {
      "epoch": 5.820481927710843,
      "grad_norm": 0.028645280748605728,
      "learning_rate": 8.359036144578315e-06,
      "loss": 0.0177,
      "step": 48310
    },
    {
      "epoch": 5.821686746987952,
      "grad_norm": 0.01771179586648941,
      "learning_rate": 8.356626506024096e-06,
      "loss": 0.0276,
      "step": 48320
    },
    {
      "epoch": 5.82289156626506,
      "grad_norm": 0.2932564318180084,
      "learning_rate": 8.35421686746988e-06,
      "loss": 0.0149,
      "step": 48330
    },
    {
      "epoch": 5.824096385542169,
      "grad_norm": 0.01190273743122816,
      "learning_rate": 8.351807228915664e-06,
      "loss": 0.0089,
      "step": 48340
    },
    {
      "epoch": 5.825301204819278,
      "grad_norm": 1.2097654342651367,
      "learning_rate": 8.349397590361446e-06,
      "loss": 0.0319,
      "step": 48350
    },
    {
      "epoch": 5.8265060240963855,
      "grad_norm": 0.003297600895166397,
      "learning_rate": 8.346987951807229e-06,
      "loss": 0.0179,
      "step": 48360
    },
    {
      "epoch": 5.827710843373494,
      "grad_norm": 0.002487043384462595,
      "learning_rate": 8.344578313253012e-06,
      "loss": 0.0096,
      "step": 48370
    },
    {
      "epoch": 5.828915662650602,
      "grad_norm": 1.699125051498413,
      "learning_rate": 8.342168674698795e-06,
      "loss": 0.0244,
      "step": 48380
    },
    {
      "epoch": 5.830120481927711,
      "grad_norm": 0.004834217019379139,
      "learning_rate": 8.339759036144579e-06,
      "loss": 0.0106,
      "step": 48390
    },
    {
      "epoch": 5.831325301204819,
      "grad_norm": 0.0018466839101165533,
      "learning_rate": 8.337349397590362e-06,
      "loss": 0.0201,
      "step": 48400
    },
    {
      "epoch": 5.832530120481928,
      "grad_norm": 0.17914605140686035,
      "learning_rate": 8.334939759036145e-06,
      "loss": 0.0413,
      "step": 48410
    },
    {
      "epoch": 5.833734939759037,
      "grad_norm": 0.0043761227279901505,
      "learning_rate": 8.332530120481928e-06,
      "loss": 0.0368,
      "step": 48420
    },
    {
      "epoch": 5.8349397590361445,
      "grad_norm": 0.014849687926471233,
      "learning_rate": 8.330120481927711e-06,
      "loss": 0.0177,
      "step": 48430
    },
    {
      "epoch": 5.836144578313253,
      "grad_norm": 0.0340304970741272,
      "learning_rate": 8.327710843373494e-06,
      "loss": 0.0595,
      "step": 48440
    },
    {
      "epoch": 5.837349397590361,
      "grad_norm": 1.1995131969451904,
      "learning_rate": 8.325301204819278e-06,
      "loss": 0.022,
      "step": 48450
    },
    {
      "epoch": 5.83855421686747,
      "grad_norm": 0.08328882604837418,
      "learning_rate": 8.32289156626506e-06,
      "loss": 0.0164,
      "step": 48460
    },
    {
      "epoch": 5.839759036144578,
      "grad_norm": 0.0023145040031522512,
      "learning_rate": 8.320481927710844e-06,
      "loss": 0.0356,
      "step": 48470
    },
    {
      "epoch": 5.840963855421687,
      "grad_norm": 0.025355862453579903,
      "learning_rate": 8.318072289156627e-06,
      "loss": 0.0155,
      "step": 48480
    },
    {
      "epoch": 5.8421686746987955,
      "grad_norm": 0.025267427787184715,
      "learning_rate": 8.31566265060241e-06,
      "loss": 0.0292,
      "step": 48490
    },
    {
      "epoch": 5.843373493975903,
      "grad_norm": 0.00968398991972208,
      "learning_rate": 8.313253012048194e-06,
      "loss": 0.0346,
      "step": 48500
    },
    {
      "epoch": 5.844578313253012,
      "grad_norm": 0.002561392495408654,
      "learning_rate": 8.310843373493977e-06,
      "loss": 0.0466,
      "step": 48510
    },
    {
      "epoch": 5.84578313253012,
      "grad_norm": 0.04171791300177574,
      "learning_rate": 8.30843373493976e-06,
      "loss": 0.019,
      "step": 48520
    },
    {
      "epoch": 5.846987951807229,
      "grad_norm": 7.941340923309326,
      "learning_rate": 8.306024096385543e-06,
      "loss": 0.0113,
      "step": 48530
    },
    {
      "epoch": 5.848192771084337,
      "grad_norm": 0.17950057983398438,
      "learning_rate": 8.303614457831326e-06,
      "loss": 0.0167,
      "step": 48540
    },
    {
      "epoch": 5.849397590361446,
      "grad_norm": 3.9377505779266357,
      "learning_rate": 8.30120481927711e-06,
      "loss": 0.0522,
      "step": 48550
    },
    {
      "epoch": 5.8506024096385545,
      "grad_norm": 0.538923978805542,
      "learning_rate": 8.298795180722891e-06,
      "loss": 0.0519,
      "step": 48560
    },
    {
      "epoch": 5.851807228915662,
      "grad_norm": 1.9940334558486938,
      "learning_rate": 8.296385542168676e-06,
      "loss": 0.0579,
      "step": 48570
    },
    {
      "epoch": 5.853012048192771,
      "grad_norm": 0.5393797159194946,
      "learning_rate": 8.293975903614459e-06,
      "loss": 0.0528,
      "step": 48580
    },
    {
      "epoch": 5.85421686746988,
      "grad_norm": 0.008138972334563732,
      "learning_rate": 8.291566265060242e-06,
      "loss": 0.0192,
      "step": 48590
    },
    {
      "epoch": 5.855421686746988,
      "grad_norm": 1.6823725700378418,
      "learning_rate": 8.289156626506025e-06,
      "loss": 0.0279,
      "step": 48600
    },
    {
      "epoch": 5.856626506024097,
      "grad_norm": 0.028611360117793083,
      "learning_rate": 8.286746987951808e-06,
      "loss": 0.0161,
      "step": 48610
    },
    {
      "epoch": 5.857831325301205,
      "grad_norm": 0.0431012287735939,
      "learning_rate": 8.284337349397592e-06,
      "loss": 0.0325,
      "step": 48620
    },
    {
      "epoch": 5.8590361445783135,
      "grad_norm": 0.01652989163994789,
      "learning_rate": 8.281927710843373e-06,
      "loss": 0.1171,
      "step": 48630
    },
    {
      "epoch": 5.860240963855421,
      "grad_norm": 8.473932266235352,
      "learning_rate": 8.279518072289158e-06,
      "loss": 0.0673,
      "step": 48640
    },
    {
      "epoch": 5.86144578313253,
      "grad_norm": 2.6746151447296143,
      "learning_rate": 8.277108433734941e-06,
      "loss": 0.0253,
      "step": 48650
    },
    {
      "epoch": 5.862650602409639,
      "grad_norm": 0.00993273500353098,
      "learning_rate": 8.274698795180723e-06,
      "loss": 0.008,
      "step": 48660
    },
    {
      "epoch": 5.863855421686747,
      "grad_norm": 0.01386320311576128,
      "learning_rate": 8.272289156626506e-06,
      "loss": 0.0228,
      "step": 48670
    },
    {
      "epoch": 5.865060240963856,
      "grad_norm": 1.7176575660705566,
      "learning_rate": 8.26987951807229e-06,
      "loss": 0.049,
      "step": 48680
    },
    {
      "epoch": 5.866265060240964,
      "grad_norm": 0.022489041090011597,
      "learning_rate": 8.267469879518072e-06,
      "loss": 0.0391,
      "step": 48690
    },
    {
      "epoch": 5.867469879518072,
      "grad_norm": 0.022132931277155876,
      "learning_rate": 8.265060240963855e-06,
      "loss": 0.0234,
      "step": 48700
    },
    {
      "epoch": 5.86867469879518,
      "grad_norm": 0.01874908246099949,
      "learning_rate": 8.262650602409639e-06,
      "loss": 0.0126,
      "step": 48710
    },
    {
      "epoch": 5.869879518072289,
      "grad_norm": 0.05679548531770706,
      "learning_rate": 8.260240963855423e-06,
      "loss": 0.0264,
      "step": 48720
    },
    {
      "epoch": 5.871084337349398,
      "grad_norm": 0.016648130491375923,
      "learning_rate": 8.257831325301205e-06,
      "loss": 0.0491,
      "step": 48730
    },
    {
      "epoch": 5.872289156626506,
      "grad_norm": 0.03551068156957626,
      "learning_rate": 8.255421686746988e-06,
      "loss": 0.0277,
      "step": 48740
    },
    {
      "epoch": 5.873493975903615,
      "grad_norm": 0.14596809446811676,
      "learning_rate": 8.253012048192773e-06,
      "loss": 0.0557,
      "step": 48750
    },
    {
      "epoch": 5.874698795180723,
      "grad_norm": 1.384886622428894,
      "learning_rate": 8.250602409638554e-06,
      "loss": 0.0389,
      "step": 48760
    },
    {
      "epoch": 5.875903614457831,
      "grad_norm": 0.8787018656730652,
      "learning_rate": 8.248192771084338e-06,
      "loss": 0.0265,
      "step": 48770
    },
    {
      "epoch": 5.877108433734939,
      "grad_norm": 0.053615935146808624,
      "learning_rate": 8.24578313253012e-06,
      "loss": 0.0366,
      "step": 48780
    },
    {
      "epoch": 5.878313253012048,
      "grad_norm": 0.0152472835034132,
      "learning_rate": 8.243373493975904e-06,
      "loss": 0.0481,
      "step": 48790
    },
    {
      "epoch": 5.879518072289157,
      "grad_norm": 0.1998785436153412,
      "learning_rate": 8.240963855421687e-06,
      "loss": 0.0084,
      "step": 48800
    },
    {
      "epoch": 5.880722891566265,
      "grad_norm": 2.117701768875122,
      "learning_rate": 8.23855421686747e-06,
      "loss": 0.0379,
      "step": 48810
    },
    {
      "epoch": 5.881927710843374,
      "grad_norm": 0.04713580012321472,
      "learning_rate": 8.236144578313253e-06,
      "loss": 0.0307,
      "step": 48820
    },
    {
      "epoch": 5.8831325301204815,
      "grad_norm": 2.613497734069824,
      "learning_rate": 8.233734939759037e-06,
      "loss": 0.039,
      "step": 48830
    },
    {
      "epoch": 5.88433734939759,
      "grad_norm": 1.6724048852920532,
      "learning_rate": 8.23132530120482e-06,
      "loss": 0.0196,
      "step": 48840
    },
    {
      "epoch": 5.885542168674699,
      "grad_norm": 1.0614702701568604,
      "learning_rate": 8.228915662650603e-06,
      "loss": 0.0332,
      "step": 48850
    },
    {
      "epoch": 5.886746987951807,
      "grad_norm": 4.307365894317627,
      "learning_rate": 8.226506024096386e-06,
      "loss": 0.0409,
      "step": 48860
    },
    {
      "epoch": 5.887951807228916,
      "grad_norm": 0.7623603343963623,
      "learning_rate": 8.22409638554217e-06,
      "loss": 0.0229,
      "step": 48870
    },
    {
      "epoch": 5.889156626506024,
      "grad_norm": 3.178990125656128,
      "learning_rate": 8.221686746987953e-06,
      "loss": 0.0324,
      "step": 48880
    },
    {
      "epoch": 5.890361445783133,
      "grad_norm": 0.006237949710339308,
      "learning_rate": 8.219277108433736e-06,
      "loss": 0.0218,
      "step": 48890
    },
    {
      "epoch": 5.891566265060241,
      "grad_norm": 0.025275737047195435,
      "learning_rate": 8.216867469879519e-06,
      "loss": 0.005,
      "step": 48900
    },
    {
      "epoch": 5.892771084337349,
      "grad_norm": 2.0034937858581543,
      "learning_rate": 8.214457831325302e-06,
      "loss": 0.0388,
      "step": 48910
    },
    {
      "epoch": 5.893975903614458,
      "grad_norm": 0.20821748673915863,
      "learning_rate": 8.212048192771085e-06,
      "loss": 0.0225,
      "step": 48920
    },
    {
      "epoch": 5.895180722891566,
      "grad_norm": 0.007388551253825426,
      "learning_rate": 8.209638554216868e-06,
      "loss": 0.0185,
      "step": 48930
    },
    {
      "epoch": 5.896385542168675,
      "grad_norm": 0.0010207804152742028,
      "learning_rate": 8.207228915662652e-06,
      "loss": 0.0132,
      "step": 48940
    },
    {
      "epoch": 5.897590361445783,
      "grad_norm": 0.002041387837380171,
      "learning_rate": 8.204819277108435e-06,
      "loss": 0.0158,
      "step": 48950
    },
    {
      "epoch": 5.8987951807228916,
      "grad_norm": 0.1898319572210312,
      "learning_rate": 8.202409638554218e-06,
      "loss": 0.0195,
      "step": 48960
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.3928009569644928,
      "learning_rate": 8.2e-06,
      "loss": 0.0186,
      "step": 48970
    },
    {
      "epoch": 5.901204819277108,
      "grad_norm": 0.9047455191612244,
      "learning_rate": 8.197590361445784e-06,
      "loss": 0.0531,
      "step": 48980
    },
    {
      "epoch": 5.902409638554217,
      "grad_norm": 0.0009396634413860738,
      "learning_rate": 8.195180722891567e-06,
      "loss": 0.0353,
      "step": 48990
    },
    {
      "epoch": 5.903614457831325,
      "grad_norm": 0.009077844209969044,
      "learning_rate": 8.19277108433735e-06,
      "loss": 0.0184,
      "step": 49000
    },
    {
      "epoch": 5.904819277108434,
      "grad_norm": 2.8410091400146484,
      "learning_rate": 8.190361445783134e-06,
      "loss": 0.0496,
      "step": 49010
    },
    {
      "epoch": 5.906024096385542,
      "grad_norm": 0.7020129561424255,
      "learning_rate": 8.187951807228917e-06,
      "loss": 0.0147,
      "step": 49020
    },
    {
      "epoch": 5.9072289156626505,
      "grad_norm": 0.05418354645371437,
      "learning_rate": 8.1855421686747e-06,
      "loss": 0.0941,
      "step": 49030
    },
    {
      "epoch": 5.908433734939759,
      "grad_norm": 0.03745178133249283,
      "learning_rate": 8.183132530120482e-06,
      "loss": 0.0334,
      "step": 49040
    },
    {
      "epoch": 5.909638554216867,
      "grad_norm": 0.21073657274246216,
      "learning_rate": 8.180722891566267e-06,
      "loss": 0.042,
      "step": 49050
    },
    {
      "epoch": 5.910843373493976,
      "grad_norm": 1.521974802017212,
      "learning_rate": 8.17831325301205e-06,
      "loss": 0.0357,
      "step": 49060
    },
    {
      "epoch": 5.912048192771084,
      "grad_norm": 0.39204198122024536,
      "learning_rate": 8.175903614457831e-06,
      "loss": 0.0473,
      "step": 49070
    },
    {
      "epoch": 5.913253012048193,
      "grad_norm": 0.08550731092691422,
      "learning_rate": 8.173493975903614e-06,
      "loss": 0.0662,
      "step": 49080
    },
    {
      "epoch": 5.914457831325302,
      "grad_norm": 3.000509262084961,
      "learning_rate": 8.1710843373494e-06,
      "loss": 0.044,
      "step": 49090
    },
    {
      "epoch": 5.9156626506024095,
      "grad_norm": 1.5675328969955444,
      "learning_rate": 8.16867469879518e-06,
      "loss": 0.0498,
      "step": 49100
    },
    {
      "epoch": 5.916867469879518,
      "grad_norm": 0.7753409147262573,
      "learning_rate": 8.166265060240964e-06,
      "loss": 0.0083,
      "step": 49110
    },
    {
      "epoch": 5.918072289156626,
      "grad_norm": 2.470479726791382,
      "learning_rate": 8.163855421686747e-06,
      "loss": 0.0265,
      "step": 49120
    },
    {
      "epoch": 5.919277108433735,
      "grad_norm": 2.4742071628570557,
      "learning_rate": 8.161445783132532e-06,
      "loss": 0.0361,
      "step": 49130
    },
    {
      "epoch": 5.920481927710844,
      "grad_norm": 0.006986062042415142,
      "learning_rate": 8.159036144578313e-06,
      "loss": 0.0165,
      "step": 49140
    },
    {
      "epoch": 5.921686746987952,
      "grad_norm": 0.31641483306884766,
      "learning_rate": 8.156626506024097e-06,
      "loss": 0.0366,
      "step": 49150
    },
    {
      "epoch": 5.9228915662650605,
      "grad_norm": 1.242405891418457,
      "learning_rate": 8.154216867469881e-06,
      "loss": 0.0169,
      "step": 49160
    },
    {
      "epoch": 5.924096385542168,
      "grad_norm": 0.6938494443893433,
      "learning_rate": 8.151807228915663e-06,
      "loss": 0.0298,
      "step": 49170
    },
    {
      "epoch": 5.925301204819277,
      "grad_norm": 3.972851276397705,
      "learning_rate": 8.149397590361446e-06,
      "loss": 0.0439,
      "step": 49180
    },
    {
      "epoch": 5.926506024096385,
      "grad_norm": 0.03315157815814018,
      "learning_rate": 8.14698795180723e-06,
      "loss": 0.0192,
      "step": 49190
    },
    {
      "epoch": 5.927710843373494,
      "grad_norm": 0.012597695924341679,
      "learning_rate": 8.144578313253012e-06,
      "loss": 0.0015,
      "step": 49200
    },
    {
      "epoch": 5.928915662650603,
      "grad_norm": 0.007830597460269928,
      "learning_rate": 8.142168674698796e-06,
      "loss": 0.0036,
      "step": 49210
    },
    {
      "epoch": 5.930120481927711,
      "grad_norm": 2.209611177444458,
      "learning_rate": 8.139759036144579e-06,
      "loss": 0.0175,
      "step": 49220
    },
    {
      "epoch": 5.9313253012048195,
      "grad_norm": 0.006000487133860588,
      "learning_rate": 8.137349397590362e-06,
      "loss": 0.0131,
      "step": 49230
    },
    {
      "epoch": 5.932530120481927,
      "grad_norm": 1.468849539756775,
      "learning_rate": 8.134939759036145e-06,
      "loss": 0.0176,
      "step": 49240
    },
    {
      "epoch": 5.933734939759036,
      "grad_norm": 1.052603840827942,
      "learning_rate": 8.132530120481928e-06,
      "loss": 0.0338,
      "step": 49250
    },
    {
      "epoch": 5.934939759036144,
      "grad_norm": 1.3409981727600098,
      "learning_rate": 8.130120481927712e-06,
      "loss": 0.0137,
      "step": 49260
    },
    {
      "epoch": 5.936144578313253,
      "grad_norm": 3.035585880279541,
      "learning_rate": 8.127710843373495e-06,
      "loss": 0.0382,
      "step": 49270
    },
    {
      "epoch": 5.937349397590362,
      "grad_norm": 0.0028397266287356615,
      "learning_rate": 8.125301204819278e-06,
      "loss": 0.003,
      "step": 49280
    },
    {
      "epoch": 5.93855421686747,
      "grad_norm": 0.01777770183980465,
      "learning_rate": 8.122891566265061e-06,
      "loss": 0.0344,
      "step": 49290
    },
    {
      "epoch": 5.9397590361445785,
      "grad_norm": 0.22184990346431732,
      "learning_rate": 8.120481927710844e-06,
      "loss": 0.0052,
      "step": 49300
    },
    {
      "epoch": 5.940963855421686,
      "grad_norm": 0.0008808545535430312,
      "learning_rate": 8.118072289156627e-06,
      "loss": 0.0315,
      "step": 49310
    },
    {
      "epoch": 5.942168674698795,
      "grad_norm": 0.004210574086755514,
      "learning_rate": 8.11566265060241e-06,
      "loss": 0.0531,
      "step": 49320
    },
    {
      "epoch": 5.943373493975904,
      "grad_norm": 0.003977664280682802,
      "learning_rate": 8.113253012048194e-06,
      "loss": 0.0269,
      "step": 49330
    },
    {
      "epoch": 5.944578313253012,
      "grad_norm": 3.819640874862671,
      "learning_rate": 8.110843373493977e-06,
      "loss": 0.0197,
      "step": 49340
    },
    {
      "epoch": 5.945783132530121,
      "grad_norm": 2.0660998821258545,
      "learning_rate": 8.10843373493976e-06,
      "loss": 0.0179,
      "step": 49350
    },
    {
      "epoch": 5.946987951807229,
      "grad_norm": 0.8288884162902832,
      "learning_rate": 8.106024096385543e-06,
      "loss": 0.0633,
      "step": 49360
    },
    {
      "epoch": 5.948192771084337,
      "grad_norm": 0.7301155924797058,
      "learning_rate": 8.103614457831326e-06,
      "loss": 0.0178,
      "step": 49370
    },
    {
      "epoch": 5.949397590361446,
      "grad_norm": 0.03473152965307236,
      "learning_rate": 8.101204819277108e-06,
      "loss": 0.0356,
      "step": 49380
    },
    {
      "epoch": 5.950602409638554,
      "grad_norm": 0.011553267017006874,
      "learning_rate": 8.098795180722893e-06,
      "loss": 0.0712,
      "step": 49390
    },
    {
      "epoch": 5.951807228915663,
      "grad_norm": 0.025748979300260544,
      "learning_rate": 8.096385542168676e-06,
      "loss": 0.0375,
      "step": 49400
    },
    {
      "epoch": 5.953012048192771,
      "grad_norm": 0.0989873856306076,
      "learning_rate": 8.093975903614457e-06,
      "loss": 0.0192,
      "step": 49410
    },
    {
      "epoch": 5.95421686746988,
      "grad_norm": 0.13283205032348633,
      "learning_rate": 8.09156626506024e-06,
      "loss": 0.0074,
      "step": 49420
    },
    {
      "epoch": 5.955421686746988,
      "grad_norm": 0.11572606861591339,
      "learning_rate": 8.089156626506026e-06,
      "loss": 0.0364,
      "step": 49430
    },
    {
      "epoch": 5.956626506024096,
      "grad_norm": 0.1712377965450287,
      "learning_rate": 8.086746987951809e-06,
      "loss": 0.0558,
      "step": 49440
    },
    {
      "epoch": 5.957831325301205,
      "grad_norm": 0.16208618879318237,
      "learning_rate": 8.08433734939759e-06,
      "loss": 0.0098,
      "step": 49450
    },
    {
      "epoch": 5.959036144578313,
      "grad_norm": 0.05602196231484413,
      "learning_rate": 8.081927710843375e-06,
      "loss": 0.0199,
      "step": 49460
    },
    {
      "epoch": 5.960240963855422,
      "grad_norm": 1.207693099975586,
      "learning_rate": 8.079518072289158e-06,
      "loss": 0.0502,
      "step": 49470
    },
    {
      "epoch": 5.96144578313253,
      "grad_norm": 0.1782490760087967,
      "learning_rate": 8.07710843373494e-06,
      "loss": 0.021,
      "step": 49480
    },
    {
      "epoch": 5.962650602409639,
      "grad_norm": 0.08627384901046753,
      "learning_rate": 8.074698795180723e-06,
      "loss": 0.0326,
      "step": 49490
    },
    {
      "epoch": 5.9638554216867465,
      "grad_norm": 0.01912946254014969,
      "learning_rate": 8.072289156626508e-06,
      "loss": 0.0027,
      "step": 49500
    },
    {
      "epoch": 5.965060240963855,
      "grad_norm": 0.006519770249724388,
      "learning_rate": 8.06987951807229e-06,
      "loss": 0.0452,
      "step": 49510
    },
    {
      "epoch": 5.966265060240964,
      "grad_norm": 0.062935471534729,
      "learning_rate": 8.067469879518072e-06,
      "loss": 0.002,
      "step": 49520
    },
    {
      "epoch": 5.967469879518072,
      "grad_norm": 0.006078212987631559,
      "learning_rate": 8.065060240963856e-06,
      "loss": 0.0194,
      "step": 49530
    },
    {
      "epoch": 5.968674698795181,
      "grad_norm": 10.906225204467773,
      "learning_rate": 8.062650602409639e-06,
      "loss": 0.0311,
      "step": 49540
    },
    {
      "epoch": 5.969879518072289,
      "grad_norm": 2.7392845153808594,
      "learning_rate": 8.060240963855422e-06,
      "loss": 0.0215,
      "step": 49550
    },
    {
      "epoch": 5.971084337349398,
      "grad_norm": 1.553210735321045,
      "learning_rate": 8.057831325301205e-06,
      "loss": 0.0218,
      "step": 49560
    },
    {
      "epoch": 5.972289156626506,
      "grad_norm": 0.004458127077668905,
      "learning_rate": 8.055421686746988e-06,
      "loss": 0.0134,
      "step": 49570
    },
    {
      "epoch": 5.973493975903614,
      "grad_norm": 0.004529502242803574,
      "learning_rate": 8.053012048192771e-06,
      "loss": 0.0236,
      "step": 49580
    },
    {
      "epoch": 5.974698795180723,
      "grad_norm": 0.005975861568003893,
      "learning_rate": 8.050602409638555e-06,
      "loss": 0.0262,
      "step": 49590
    },
    {
      "epoch": 5.975903614457831,
      "grad_norm": 0.011554316617548466,
      "learning_rate": 8.048192771084338e-06,
      "loss": 0.0113,
      "step": 49600
    },
    {
      "epoch": 5.97710843373494,
      "grad_norm": 0.008517979644238949,
      "learning_rate": 8.045783132530121e-06,
      "loss": 0.0289,
      "step": 49610
    },
    {
      "epoch": 5.978313253012049,
      "grad_norm": 0.4822293817996979,
      "learning_rate": 8.043373493975904e-06,
      "loss": 0.0291,
      "step": 49620
    },
    {
      "epoch": 5.9795180722891565,
      "grad_norm": 0.007654621731489897,
      "learning_rate": 8.040963855421687e-06,
      "loss": 0.0167,
      "step": 49630
    },
    {
      "epoch": 5.980722891566265,
      "grad_norm": 0.016409415751695633,
      "learning_rate": 8.03855421686747e-06,
      "loss": 0.0145,
      "step": 49640
    },
    {
      "epoch": 5.981927710843373,
      "grad_norm": 0.0057494607754051685,
      "learning_rate": 8.036144578313254e-06,
      "loss": 0.0238,
      "step": 49650
    },
    {
      "epoch": 5.983132530120482,
      "grad_norm": 2.25105881690979,
      "learning_rate": 8.033734939759037e-06,
      "loss": 0.0469,
      "step": 49660
    },
    {
      "epoch": 5.98433734939759,
      "grad_norm": 0.0031480512116104364,
      "learning_rate": 8.03132530120482e-06,
      "loss": 0.0302,
      "step": 49670
    },
    {
      "epoch": 5.985542168674699,
      "grad_norm": 0.006154800299555063,
      "learning_rate": 8.028915662650603e-06,
      "loss": 0.0325,
      "step": 49680
    },
    {
      "epoch": 5.986746987951808,
      "grad_norm": 0.0018880021525546908,
      "learning_rate": 8.026506024096386e-06,
      "loss": 0.0125,
      "step": 49690
    },
    {
      "epoch": 5.9879518072289155,
      "grad_norm": 5.157870769500732,
      "learning_rate": 8.02409638554217e-06,
      "loss": 0.0101,
      "step": 49700
    },
    {
      "epoch": 5.989156626506024,
      "grad_norm": 1.080970048904419,
      "learning_rate": 8.021686746987953e-06,
      "loss": 0.0277,
      "step": 49710
    },
    {
      "epoch": 5.990361445783132,
      "grad_norm": 0.01805628091096878,
      "learning_rate": 8.019277108433736e-06,
      "loss": 0.0252,
      "step": 49720
    },
    {
      "epoch": 5.991566265060241,
      "grad_norm": 7.66793155670166,
      "learning_rate": 8.016867469879519e-06,
      "loss": 0.0711,
      "step": 49730
    },
    {
      "epoch": 5.992771084337349,
      "grad_norm": 1.1014249324798584,
      "learning_rate": 8.014457831325302e-06,
      "loss": 0.0106,
      "step": 49740
    },
    {
      "epoch": 5.993975903614458,
      "grad_norm": 0.379372775554657,
      "learning_rate": 8.012048192771085e-06,
      "loss": 0.024,
      "step": 49750
    },
    {
      "epoch": 5.995180722891567,
      "grad_norm": 0.007376783527433872,
      "learning_rate": 8.009638554216869e-06,
      "loss": 0.0227,
      "step": 49760
    },
    {
      "epoch": 5.9963855421686745,
      "grad_norm": 3.3738293647766113,
      "learning_rate": 8.007228915662652e-06,
      "loss": 0.0254,
      "step": 49770
    },
    {
      "epoch": 5.997590361445783,
      "grad_norm": 3.7697551250457764,
      "learning_rate": 8.004819277108435e-06,
      "loss": 0.0616,
      "step": 49780
    },
    {
      "epoch": 5.998795180722891,
      "grad_norm": 6.303252220153809,
      "learning_rate": 8.002409638554216e-06,
      "loss": 0.0952,
      "step": 49790
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.163161516189575,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0221,
      "step": 49800
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9844863142107236,
      "eval_f1": 0.9592113370301911,
      "eval_loss": 0.048600759357213974,
      "eval_precision": 0.9563828480157267,
      "eval_recall": 0.9620566061055493,
      "eval_runtime": 4973.0004,
      "eval_samples_per_second": 8.584,
      "eval_steps_per_second": 0.358,
      "step": 49800
    },
    {
      "epoch": 6.001204819277109,
      "grad_norm": 0.0118496622890234,
      "learning_rate": 7.997590361445785e-06,
      "loss": 0.0398,
      "step": 49810
    },
    {
      "epoch": 6.002409638554217,
      "grad_norm": 10.566177368164062,
      "learning_rate": 7.995180722891566e-06,
      "loss": 0.028,
      "step": 49820
    },
    {
      "epoch": 6.0036144578313255,
      "grad_norm": 0.009487123228609562,
      "learning_rate": 7.99277108433735e-06,
      "loss": 0.0175,
      "step": 49830
    },
    {
      "epoch": 6.004819277108433,
      "grad_norm": 0.006159656681120396,
      "learning_rate": 7.990361445783134e-06,
      "loss": 0.0026,
      "step": 49840
    },
    {
      "epoch": 6.006024096385542,
      "grad_norm": 0.0556831993162632,
      "learning_rate": 7.987951807228917e-06,
      "loss": 0.0884,
      "step": 49850
    },
    {
      "epoch": 6.00722891566265,
      "grad_norm": 0.2898709177970886,
      "learning_rate": 7.985542168674699e-06,
      "loss": 0.0102,
      "step": 49860
    },
    {
      "epoch": 6.008433734939759,
      "grad_norm": 0.9642548561096191,
      "learning_rate": 7.983132530120482e-06,
      "loss": 0.007,
      "step": 49870
    },
    {
      "epoch": 6.009638554216868,
      "grad_norm": 1.492431402206421,
      "learning_rate": 7.980722891566267e-06,
      "loss": 0.0117,
      "step": 49880
    },
    {
      "epoch": 6.010843373493976,
      "grad_norm": 0.008905350230634212,
      "learning_rate": 7.978313253012048e-06,
      "loss": 0.0172,
      "step": 49890
    },
    {
      "epoch": 6.0120481927710845,
      "grad_norm": 0.8397184610366821,
      "learning_rate": 7.975903614457831e-06,
      "loss": 0.0858,
      "step": 49900
    },
    {
      "epoch": 6.013253012048192,
      "grad_norm": 0.4646715819835663,
      "learning_rate": 7.973493975903616e-06,
      "loss": 0.01,
      "step": 49910
    },
    {
      "epoch": 6.014457831325301,
      "grad_norm": 2.3700361251831055,
      "learning_rate": 7.971084337349398e-06,
      "loss": 0.0523,
      "step": 49920
    },
    {
      "epoch": 6.01566265060241,
      "grad_norm": 0.023203568533062935,
      "learning_rate": 7.968674698795181e-06,
      "loss": 0.0227,
      "step": 49930
    },
    {
      "epoch": 6.016867469879518,
      "grad_norm": 0.005579385440796614,
      "learning_rate": 7.966265060240964e-06,
      "loss": 0.0234,
      "step": 49940
    },
    {
      "epoch": 6.018072289156627,
      "grad_norm": 0.01241985708475113,
      "learning_rate": 7.963855421686747e-06,
      "loss": 0.085,
      "step": 49950
    },
    {
      "epoch": 6.019277108433735,
      "grad_norm": 0.006942178122699261,
      "learning_rate": 7.96144578313253e-06,
      "loss": 0.0083,
      "step": 49960
    },
    {
      "epoch": 6.0204819277108435,
      "grad_norm": 0.003961971495300531,
      "learning_rate": 7.959036144578314e-06,
      "loss": 0.0104,
      "step": 49970
    },
    {
      "epoch": 6.021686746987951,
      "grad_norm": 7.1427483558654785,
      "learning_rate": 7.956626506024097e-06,
      "loss": 0.0196,
      "step": 49980
    },
    {
      "epoch": 6.02289156626506,
      "grad_norm": 0.161455899477005,
      "learning_rate": 7.95421686746988e-06,
      "loss": 0.0268,
      "step": 49990
    },
    {
      "epoch": 6.024096385542169,
      "grad_norm": 0.028289739042520523,
      "learning_rate": 7.951807228915663e-06,
      "loss": 0.0041,
      "step": 50000
    },
    {
      "epoch": 6.025301204819277,
      "grad_norm": 1.847805142402649,
      "learning_rate": 7.949397590361446e-06,
      "loss": 0.0462,
      "step": 50010
    },
    {
      "epoch": 6.026506024096386,
      "grad_norm": 0.0018123869085684419,
      "learning_rate": 7.94698795180723e-06,
      "loss": 0.015,
      "step": 50020
    },
    {
      "epoch": 6.027710843373494,
      "grad_norm": 0.22011414170265198,
      "learning_rate": 7.944578313253013e-06,
      "loss": 0.0212,
      "step": 50030
    },
    {
      "epoch": 6.028915662650602,
      "grad_norm": 0.06056499481201172,
      "learning_rate": 7.942168674698796e-06,
      "loss": 0.0251,
      "step": 50040
    },
    {
      "epoch": 6.030120481927711,
      "grad_norm": 2.8429598808288574,
      "learning_rate": 7.939759036144579e-06,
      "loss": 0.069,
      "step": 50050
    },
    {
      "epoch": 6.031325301204819,
      "grad_norm": 0.5121183395385742,
      "learning_rate": 7.937349397590362e-06,
      "loss": 0.0071,
      "step": 50060
    },
    {
      "epoch": 6.032530120481928,
      "grad_norm": 0.05354234576225281,
      "learning_rate": 7.934939759036145e-06,
      "loss": 0.0229,
      "step": 50070
    },
    {
      "epoch": 6.033734939759036,
      "grad_norm": 0.011527255177497864,
      "learning_rate": 7.932530120481929e-06,
      "loss": 0.0541,
      "step": 50080
    },
    {
      "epoch": 6.034939759036145,
      "grad_norm": 0.7763016819953918,
      "learning_rate": 7.930120481927712e-06,
      "loss": 0.0045,
      "step": 50090
    },
    {
      "epoch": 6.036144578313253,
      "grad_norm": 72.3064193725586,
      "learning_rate": 7.927710843373495e-06,
      "loss": 0.0387,
      "step": 50100
    },
    {
      "epoch": 6.037349397590361,
      "grad_norm": 0.11713159084320068,
      "learning_rate": 7.925301204819278e-06,
      "loss": 0.0087,
      "step": 50110
    },
    {
      "epoch": 6.03855421686747,
      "grad_norm": 0.6070979237556458,
      "learning_rate": 7.922891566265061e-06,
      "loss": 0.0295,
      "step": 50120
    },
    {
      "epoch": 6.039759036144578,
      "grad_norm": 0.525812566280365,
      "learning_rate": 7.920481927710843e-06,
      "loss": 0.0209,
      "step": 50130
    },
    {
      "epoch": 6.040963855421687,
      "grad_norm": 0.7885029315948486,
      "learning_rate": 7.918072289156628e-06,
      "loss": 0.0172,
      "step": 50140
    },
    {
      "epoch": 6.042168674698795,
      "grad_norm": 0.3003087341785431,
      "learning_rate": 7.91566265060241e-06,
      "loss": 0.0226,
      "step": 50150
    },
    {
      "epoch": 6.043373493975904,
      "grad_norm": 3.726154327392578,
      "learning_rate": 7.913253012048194e-06,
      "loss": 0.047,
      "step": 50160
    },
    {
      "epoch": 6.044578313253012,
      "grad_norm": 0.32126104831695557,
      "learning_rate": 7.910843373493975e-06,
      "loss": 0.0198,
      "step": 50170
    },
    {
      "epoch": 6.04578313253012,
      "grad_norm": 0.9248007535934448,
      "learning_rate": 7.90843373493976e-06,
      "loss": 0.0337,
      "step": 50180
    },
    {
      "epoch": 6.046987951807229,
      "grad_norm": 0.005892820190638304,
      "learning_rate": 7.906024096385544e-06,
      "loss": 0.0037,
      "step": 50190
    },
    {
      "epoch": 6.048192771084337,
      "grad_norm": 0.18415997922420502,
      "learning_rate": 7.903614457831325e-06,
      "loss": 0.0454,
      "step": 50200
    },
    {
      "epoch": 6.049397590361446,
      "grad_norm": 0.002472376450896263,
      "learning_rate": 7.90120481927711e-06,
      "loss": 0.0036,
      "step": 50210
    },
    {
      "epoch": 6.050602409638554,
      "grad_norm": 0.03202371299266815,
      "learning_rate": 7.898795180722893e-06,
      "loss": 0.003,
      "step": 50220
    },
    {
      "epoch": 6.051807228915663,
      "grad_norm": 0.0024572093971073627,
      "learning_rate": 7.896385542168675e-06,
      "loss": 0.0301,
      "step": 50230
    },
    {
      "epoch": 6.053012048192771,
      "grad_norm": 0.0353127159178257,
      "learning_rate": 7.893975903614458e-06,
      "loss": 0.001,
      "step": 50240
    },
    {
      "epoch": 6.054216867469879,
      "grad_norm": 0.003602938959375024,
      "learning_rate": 7.891566265060243e-06,
      "loss": 0.0415,
      "step": 50250
    },
    {
      "epoch": 6.055421686746988,
      "grad_norm": 0.009001730009913445,
      "learning_rate": 7.889156626506024e-06,
      "loss": 0.0097,
      "step": 50260
    },
    {
      "epoch": 6.056626506024096,
      "grad_norm": 0.006659959442913532,
      "learning_rate": 7.886746987951807e-06,
      "loss": 0.0008,
      "step": 50270
    },
    {
      "epoch": 6.057831325301205,
      "grad_norm": 1.479622483253479,
      "learning_rate": 7.88433734939759e-06,
      "loss": 0.0084,
      "step": 50280
    },
    {
      "epoch": 6.059036144578314,
      "grad_norm": 0.007475344929844141,
      "learning_rate": 7.881927710843375e-06,
      "loss": 0.0089,
      "step": 50290
    },
    {
      "epoch": 6.0602409638554215,
      "grad_norm": 0.2058470994234085,
      "learning_rate": 7.879518072289157e-06,
      "loss": 0.0131,
      "step": 50300
    },
    {
      "epoch": 6.06144578313253,
      "grad_norm": 0.0018930749502032995,
      "learning_rate": 7.87710843373494e-06,
      "loss": 0.0386,
      "step": 50310
    },
    {
      "epoch": 6.062650602409638,
      "grad_norm": 2.0539042949676514,
      "learning_rate": 7.874698795180723e-06,
      "loss": 0.0113,
      "step": 50320
    },
    {
      "epoch": 6.063855421686747,
      "grad_norm": 0.1390405148267746,
      "learning_rate": 7.872289156626506e-06,
      "loss": 0.0108,
      "step": 50330
    },
    {
      "epoch": 6.065060240963855,
      "grad_norm": 16.631975173950195,
      "learning_rate": 7.86987951807229e-06,
      "loss": 0.0105,
      "step": 50340
    },
    {
      "epoch": 6.066265060240964,
      "grad_norm": 3.2376363277435303,
      "learning_rate": 7.867469879518073e-06,
      "loss": 0.0467,
      "step": 50350
    },
    {
      "epoch": 6.067469879518073,
      "grad_norm": 0.0018546213395893574,
      "learning_rate": 7.865060240963856e-06,
      "loss": 0.0108,
      "step": 50360
    },
    {
      "epoch": 6.0686746987951805,
      "grad_norm": 0.17714105546474457,
      "learning_rate": 7.862650602409639e-06,
      "loss": 0.0413,
      "step": 50370
    },
    {
      "epoch": 6.069879518072289,
      "grad_norm": 1.8615684509277344,
      "learning_rate": 7.860240963855422e-06,
      "loss": 0.0121,
      "step": 50380
    },
    {
      "epoch": 6.071084337349397,
      "grad_norm": 0.0050447252579033375,
      "learning_rate": 7.857831325301205e-06,
      "loss": 0.0141,
      "step": 50390
    },
    {
      "epoch": 6.072289156626506,
      "grad_norm": 0.0037813056260347366,
      "learning_rate": 7.855421686746989e-06,
      "loss": 0.0189,
      "step": 50400
    },
    {
      "epoch": 6.073493975903615,
      "grad_norm": 0.07180146872997284,
      "learning_rate": 7.853012048192772e-06,
      "loss": 0.0164,
      "step": 50410
    },
    {
      "epoch": 6.074698795180723,
      "grad_norm": 0.14100658893585205,
      "learning_rate": 7.850602409638555e-06,
      "loss": 0.042,
      "step": 50420
    },
    {
      "epoch": 6.075903614457832,
      "grad_norm": 1.3779219388961792,
      "learning_rate": 7.848192771084338e-06,
      "loss": 0.0201,
      "step": 50430
    },
    {
      "epoch": 6.0771084337349395,
      "grad_norm": 0.002112734131515026,
      "learning_rate": 7.845783132530121e-06,
      "loss": 0.0051,
      "step": 50440
    },
    {
      "epoch": 6.078313253012048,
      "grad_norm": 0.8597712516784668,
      "learning_rate": 7.843373493975904e-06,
      "loss": 0.004,
      "step": 50450
    },
    {
      "epoch": 6.079518072289156,
      "grad_norm": 0.07770514488220215,
      "learning_rate": 7.840963855421688e-06,
      "loss": 0.0021,
      "step": 50460
    },
    {
      "epoch": 6.080722891566265,
      "grad_norm": 13.077988624572754,
      "learning_rate": 7.83855421686747e-06,
      "loss": 0.0343,
      "step": 50470
    },
    {
      "epoch": 6.081927710843374,
      "grad_norm": 0.13798630237579346,
      "learning_rate": 7.836144578313254e-06,
      "loss": 0.0163,
      "step": 50480
    },
    {
      "epoch": 6.083132530120482,
      "grad_norm": 0.03616349771618843,
      "learning_rate": 7.833734939759037e-06,
      "loss": 0.0032,
      "step": 50490
    },
    {
      "epoch": 6.0843373493975905,
      "grad_norm": 0.0018182963831350207,
      "learning_rate": 7.83132530120482e-06,
      "loss": 0.009,
      "step": 50500
    },
    {
      "epoch": 6.085542168674698,
      "grad_norm": 0.08063983917236328,
      "learning_rate": 7.828915662650603e-06,
      "loss": 0.0279,
      "step": 50510
    },
    {
      "epoch": 6.086746987951807,
      "grad_norm": 0.08447332680225372,
      "learning_rate": 7.826506024096387e-06,
      "loss": 0.0021,
      "step": 50520
    },
    {
      "epoch": 6.087951807228916,
      "grad_norm": 0.0021567957010120153,
      "learning_rate": 7.82409638554217e-06,
      "loss": 0.0023,
      "step": 50530
    },
    {
      "epoch": 6.089156626506024,
      "grad_norm": 0.04747284576296806,
      "learning_rate": 7.821686746987951e-06,
      "loss": 0.0883,
      "step": 50540
    },
    {
      "epoch": 6.090361445783133,
      "grad_norm": 2.4860010147094727,
      "learning_rate": 7.819277108433736e-06,
      "loss": 0.0201,
      "step": 50550
    },
    {
      "epoch": 6.091566265060241,
      "grad_norm": 0.004142968449741602,
      "learning_rate": 7.81686746987952e-06,
      "loss": 0.024,
      "step": 50560
    },
    {
      "epoch": 6.0927710843373495,
      "grad_norm": 0.21328745782375336,
      "learning_rate": 7.814457831325302e-06,
      "loss": 0.0135,
      "step": 50570
    },
    {
      "epoch": 6.093975903614457,
      "grad_norm": 2.9697558879852295,
      "learning_rate": 7.812048192771084e-06,
      "loss": 0.0383,
      "step": 50580
    },
    {
      "epoch": 6.095180722891566,
      "grad_norm": 0.007357385940849781,
      "learning_rate": 7.809638554216869e-06,
      "loss": 0.0442,
      "step": 50590
    },
    {
      "epoch": 6.096385542168675,
      "grad_norm": 0.0399983786046505,
      "learning_rate": 7.807228915662652e-06,
      "loss": 0.0148,
      "step": 50600
    },
    {
      "epoch": 6.097590361445783,
      "grad_norm": 0.8761740922927856,
      "learning_rate": 7.804819277108434e-06,
      "loss": 0.0158,
      "step": 50610
    },
    {
      "epoch": 6.098795180722892,
      "grad_norm": 0.014679989777505398,
      "learning_rate": 7.802409638554217e-06,
      "loss": 0.0225,
      "step": 50620
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.4442384243011475,
      "learning_rate": 7.800000000000002e-06,
      "loss": 0.0143,
      "step": 50630
    },
    {
      "epoch": 6.1012048192771084,
      "grad_norm": 23.176908493041992,
      "learning_rate": 7.797590361445783e-06,
      "loss": 0.0527,
      "step": 50640
    },
    {
      "epoch": 6.102409638554217,
      "grad_norm": 0.00366946030408144,
      "learning_rate": 7.795180722891566e-06,
      "loss": 0.0339,
      "step": 50650
    },
    {
      "epoch": 6.103614457831325,
      "grad_norm": 0.01072181947529316,
      "learning_rate": 7.792771084337351e-06,
      "loss": 0.0317,
      "step": 50660
    },
    {
      "epoch": 6.104819277108434,
      "grad_norm": 0.009540731087327003,
      "learning_rate": 7.790361445783133e-06,
      "loss": 0.0252,
      "step": 50670
    },
    {
      "epoch": 6.106024096385542,
      "grad_norm": 0.10254675149917603,
      "learning_rate": 7.787951807228916e-06,
      "loss": 0.0131,
      "step": 50680
    },
    {
      "epoch": 6.107228915662651,
      "grad_norm": 2.1690359115600586,
      "learning_rate": 7.785542168674699e-06,
      "loss": 0.0423,
      "step": 50690
    },
    {
      "epoch": 6.108433734939759,
      "grad_norm": 0.009831853210926056,
      "learning_rate": 7.783132530120484e-06,
      "loss": 0.0129,
      "step": 50700
    },
    {
      "epoch": 6.109638554216867,
      "grad_norm": 0.01796150766313076,
      "learning_rate": 7.780722891566265e-06,
      "loss": 0.0199,
      "step": 50710
    },
    {
      "epoch": 6.110843373493976,
      "grad_norm": 0.21128630638122559,
      "learning_rate": 7.778313253012048e-06,
      "loss": 0.0028,
      "step": 50720
    },
    {
      "epoch": 6.112048192771084,
      "grad_norm": 0.003645823337137699,
      "learning_rate": 7.775903614457832e-06,
      "loss": 0.0246,
      "step": 50730
    },
    {
      "epoch": 6.113253012048193,
      "grad_norm": 0.0024829539470374584,
      "learning_rate": 7.773493975903615e-06,
      "loss": 0.0226,
      "step": 50740
    },
    {
      "epoch": 6.114457831325301,
      "grad_norm": 0.002753383945673704,
      "learning_rate": 7.771084337349398e-06,
      "loss": 0.0127,
      "step": 50750
    },
    {
      "epoch": 6.11566265060241,
      "grad_norm": 0.009937713854014874,
      "learning_rate": 7.768674698795181e-06,
      "loss": 0.0498,
      "step": 50760
    },
    {
      "epoch": 6.1168674698795185,
      "grad_norm": 0.5271994471549988,
      "learning_rate": 7.766265060240964e-06,
      "loss": 0.0138,
      "step": 50770
    },
    {
      "epoch": 6.118072289156626,
      "grad_norm": 0.737573504447937,
      "learning_rate": 7.763855421686747e-06,
      "loss": 0.0232,
      "step": 50780
    },
    {
      "epoch": 6.119277108433735,
      "grad_norm": 0.0041002193465828896,
      "learning_rate": 7.76144578313253e-06,
      "loss": 0.0023,
      "step": 50790
    },
    {
      "epoch": 6.120481927710843,
      "grad_norm": 0.30561915040016174,
      "learning_rate": 7.759036144578314e-06,
      "loss": 0.058,
      "step": 50800
    },
    {
      "epoch": 6.121686746987952,
      "grad_norm": 0.3722323179244995,
      "learning_rate": 7.756626506024097e-06,
      "loss": 0.0106,
      "step": 50810
    },
    {
      "epoch": 6.12289156626506,
      "grad_norm": 0.0026790830306708813,
      "learning_rate": 7.75421686746988e-06,
      "loss": 0.005,
      "step": 50820
    },
    {
      "epoch": 6.124096385542169,
      "grad_norm": 0.0010804319754242897,
      "learning_rate": 7.751807228915663e-06,
      "loss": 0.0557,
      "step": 50830
    },
    {
      "epoch": 6.125301204819277,
      "grad_norm": 1.706965684890747,
      "learning_rate": 7.749397590361447e-06,
      "loss": 0.0432,
      "step": 50840
    },
    {
      "epoch": 6.126506024096385,
      "grad_norm": 0.002942433813586831,
      "learning_rate": 7.74698795180723e-06,
      "loss": 0.0154,
      "step": 50850
    },
    {
      "epoch": 6.127710843373494,
      "grad_norm": 2.0416817665100098,
      "learning_rate": 7.744578313253013e-06,
      "loss": 0.0282,
      "step": 50860
    },
    {
      "epoch": 6.128915662650602,
      "grad_norm": 1.8231784105300903,
      "learning_rate": 7.742168674698796e-06,
      "loss": 0.0067,
      "step": 50870
    },
    {
      "epoch": 6.130120481927711,
      "grad_norm": 0.0033098075073212385,
      "learning_rate": 7.73975903614458e-06,
      "loss": 0.0011,
      "step": 50880
    },
    {
      "epoch": 6.13132530120482,
      "grad_norm": 0.15391990542411804,
      "learning_rate": 7.737349397590362e-06,
      "loss": 0.0235,
      "step": 50890
    },
    {
      "epoch": 6.132530120481928,
      "grad_norm": 0.02847248502075672,
      "learning_rate": 7.734939759036146e-06,
      "loss": 0.0119,
      "step": 50900
    },
    {
      "epoch": 6.133734939759036,
      "grad_norm": 5.0050272941589355,
      "learning_rate": 7.732530120481929e-06,
      "loss": 0.0417,
      "step": 50910
    },
    {
      "epoch": 6.134939759036144,
      "grad_norm": 1.120589256286621,
      "learning_rate": 7.730120481927712e-06,
      "loss": 0.0115,
      "step": 50920
    },
    {
      "epoch": 6.136144578313253,
      "grad_norm": 9.48997974395752,
      "learning_rate": 7.727710843373495e-06,
      "loss": 0.0367,
      "step": 50930
    },
    {
      "epoch": 6.137349397590361,
      "grad_norm": 0.006298859138041735,
      "learning_rate": 7.725301204819278e-06,
      "loss": 0.0275,
      "step": 50940
    },
    {
      "epoch": 6.13855421686747,
      "grad_norm": 0.00374565995298326,
      "learning_rate": 7.72289156626506e-06,
      "loss": 0.0059,
      "step": 50950
    },
    {
      "epoch": 6.139759036144579,
      "grad_norm": 0.023750798776745796,
      "learning_rate": 7.720481927710845e-06,
      "loss": 0.0392,
      "step": 50960
    },
    {
      "epoch": 6.1409638554216865,
      "grad_norm": 0.034324295818805695,
      "learning_rate": 7.718072289156628e-06,
      "loss": 0.0296,
      "step": 50970
    },
    {
      "epoch": 6.142168674698795,
      "grad_norm": 0.004483634606003761,
      "learning_rate": 7.71566265060241e-06,
      "loss": 0.016,
      "step": 50980
    },
    {
      "epoch": 6.143373493975903,
      "grad_norm": 0.18836499750614166,
      "learning_rate": 7.713253012048193e-06,
      "loss": 0.0113,
      "step": 50990
    },
    {
      "epoch": 6.144578313253012,
      "grad_norm": 0.5381330251693726,
      "learning_rate": 7.710843373493977e-06,
      "loss": 0.0397,
      "step": 51000
    },
    {
      "epoch": 6.145783132530121,
      "grad_norm": 0.10654011368751526,
      "learning_rate": 7.70843373493976e-06,
      "loss": 0.0173,
      "step": 51010
    },
    {
      "epoch": 6.146987951807229,
      "grad_norm": 1.9925976991653442,
      "learning_rate": 7.706024096385542e-06,
      "loss": 0.0118,
      "step": 51020
    },
    {
      "epoch": 6.148192771084338,
      "grad_norm": 2.6120152473449707,
      "learning_rate": 7.703614457831325e-06,
      "loss": 0.0371,
      "step": 51030
    },
    {
      "epoch": 6.1493975903614455,
      "grad_norm": 0.6722556948661804,
      "learning_rate": 7.70120481927711e-06,
      "loss": 0.0154,
      "step": 51040
    },
    {
      "epoch": 6.150602409638554,
      "grad_norm": 1.0486565828323364,
      "learning_rate": 7.698795180722892e-06,
      "loss": 0.0319,
      "step": 51050
    },
    {
      "epoch": 6.151807228915662,
      "grad_norm": 0.02187497541308403,
      "learning_rate": 7.696385542168675e-06,
      "loss": 0.0087,
      "step": 51060
    },
    {
      "epoch": 6.153012048192771,
      "grad_norm": 0.024481942877173424,
      "learning_rate": 7.69397590361446e-06,
      "loss": 0.0238,
      "step": 51070
    },
    {
      "epoch": 6.15421686746988,
      "grad_norm": 4.106807708740234,
      "learning_rate": 7.691566265060241e-06,
      "loss": 0.036,
      "step": 51080
    },
    {
      "epoch": 6.155421686746988,
      "grad_norm": 0.0020528181921690702,
      "learning_rate": 7.689156626506024e-06,
      "loss": 0.0073,
      "step": 51090
    },
    {
      "epoch": 6.156626506024097,
      "grad_norm": 0.2450661063194275,
      "learning_rate": 7.686746987951807e-06,
      "loss": 0.0431,
      "step": 51100
    },
    {
      "epoch": 6.1578313253012045,
      "grad_norm": 1.044844150543213,
      "learning_rate": 7.684337349397592e-06,
      "loss": 0.0041,
      "step": 51110
    },
    {
      "epoch": 6.159036144578313,
      "grad_norm": 3.159734010696411,
      "learning_rate": 7.681927710843374e-06,
      "loss": 0.0341,
      "step": 51120
    },
    {
      "epoch": 6.160240963855422,
      "grad_norm": 1.0726205110549927,
      "learning_rate": 7.679518072289157e-06,
      "loss": 0.0346,
      "step": 51130
    },
    {
      "epoch": 6.16144578313253,
      "grad_norm": 0.04919157922267914,
      "learning_rate": 7.67710843373494e-06,
      "loss": 0.024,
      "step": 51140
    },
    {
      "epoch": 6.162650602409639,
      "grad_norm": 0.003697281936183572,
      "learning_rate": 7.674698795180723e-06,
      "loss": 0.0618,
      "step": 51150
    },
    {
      "epoch": 6.163855421686747,
      "grad_norm": 0.006935608107596636,
      "learning_rate": 7.672289156626506e-06,
      "loss": 0.0497,
      "step": 51160
    },
    {
      "epoch": 6.1650602409638555,
      "grad_norm": 0.008395196869969368,
      "learning_rate": 7.66987951807229e-06,
      "loss": 0.0057,
      "step": 51170
    },
    {
      "epoch": 6.166265060240963,
      "grad_norm": 0.006183879915624857,
      "learning_rate": 7.667469879518073e-06,
      "loss": 0.0141,
      "step": 51180
    },
    {
      "epoch": 6.167469879518072,
      "grad_norm": 0.2614097595214844,
      "learning_rate": 7.665060240963856e-06,
      "loss": 0.0014,
      "step": 51190
    },
    {
      "epoch": 6.168674698795181,
      "grad_norm": 0.006098530720919371,
      "learning_rate": 7.66265060240964e-06,
      "loss": 0.0058,
      "step": 51200
    },
    {
      "epoch": 6.169879518072289,
      "grad_norm": 0.02480471134185791,
      "learning_rate": 7.660240963855422e-06,
      "loss": 0.0204,
      "step": 51210
    },
    {
      "epoch": 6.171084337349398,
      "grad_norm": 0.7384420037269592,
      "learning_rate": 7.657831325301206e-06,
      "loss": 0.0262,
      "step": 51220
    },
    {
      "epoch": 6.172289156626506,
      "grad_norm": 2.4182145595550537,
      "learning_rate": 7.655421686746989e-06,
      "loss": 0.0439,
      "step": 51230
    },
    {
      "epoch": 6.1734939759036145,
      "grad_norm": 2.0886762142181396,
      "learning_rate": 7.653012048192772e-06,
      "loss": 0.0467,
      "step": 51240
    },
    {
      "epoch": 6.174698795180723,
      "grad_norm": 3.8861284255981445,
      "learning_rate": 7.650602409638555e-06,
      "loss": 0.0265,
      "step": 51250
    },
    {
      "epoch": 6.175903614457831,
      "grad_norm": 0.018854977563023567,
      "learning_rate": 7.648192771084338e-06,
      "loss": 0.0126,
      "step": 51260
    },
    {
      "epoch": 6.17710843373494,
      "grad_norm": 0.08954330533742905,
      "learning_rate": 7.645783132530121e-06,
      "loss": 0.0026,
      "step": 51270
    },
    {
      "epoch": 6.178313253012048,
      "grad_norm": 2.494847297668457,
      "learning_rate": 7.643373493975905e-06,
      "loss": 0.0154,
      "step": 51280
    },
    {
      "epoch": 6.179518072289157,
      "grad_norm": 0.007596017327159643,
      "learning_rate": 7.640963855421688e-06,
      "loss": 0.0119,
      "step": 51290
    },
    {
      "epoch": 6.180722891566265,
      "grad_norm": 0.22766228020191193,
      "learning_rate": 7.638554216867471e-06,
      "loss": 0.0107,
      "step": 51300
    },
    {
      "epoch": 6.1819277108433734,
      "grad_norm": 4.9803924560546875,
      "learning_rate": 7.636144578313254e-06,
      "loss": 0.0158,
      "step": 51310
    },
    {
      "epoch": 6.183132530120482,
      "grad_norm": 1.1750141382217407,
      "learning_rate": 7.633734939759037e-06,
      "loss": 0.0084,
      "step": 51320
    },
    {
      "epoch": 6.18433734939759,
      "grad_norm": 12.47486686706543,
      "learning_rate": 7.631325301204819e-06,
      "loss": 0.0172,
      "step": 51330
    },
    {
      "epoch": 6.185542168674699,
      "grad_norm": 0.004302273038774729,
      "learning_rate": 7.628915662650604e-06,
      "loss": 0.0356,
      "step": 51340
    },
    {
      "epoch": 6.186746987951807,
      "grad_norm": 0.10173489898443222,
      "learning_rate": 7.626506024096386e-06,
      "loss": 0.0112,
      "step": 51350
    },
    {
      "epoch": 6.187951807228916,
      "grad_norm": 0.007309645880013704,
      "learning_rate": 7.624096385542169e-06,
      "loss": 0.046,
      "step": 51360
    },
    {
      "epoch": 6.1891566265060245,
      "grad_norm": 0.043481431901454926,
      "learning_rate": 7.621686746987953e-06,
      "loss": 0.0176,
      "step": 51370
    },
    {
      "epoch": 6.190361445783132,
      "grad_norm": 0.005098773632198572,
      "learning_rate": 7.6192771084337355e-06,
      "loss": 0.0389,
      "step": 51380
    },
    {
      "epoch": 6.191566265060241,
      "grad_norm": 0.7018319368362427,
      "learning_rate": 7.616867469879519e-06,
      "loss": 0.0418,
      "step": 51390
    },
    {
      "epoch": 6.192771084337349,
      "grad_norm": 0.344897598028183,
      "learning_rate": 7.614457831325302e-06,
      "loss": 0.0066,
      "step": 51400
    },
    {
      "epoch": 6.193975903614458,
      "grad_norm": 0.036245036870241165,
      "learning_rate": 7.612048192771085e-06,
      "loss": 0.0171,
      "step": 51410
    },
    {
      "epoch": 6.195180722891566,
      "grad_norm": 1.9122449159622192,
      "learning_rate": 7.609638554216868e-06,
      "loss": 0.0335,
      "step": 51420
    },
    {
      "epoch": 6.196385542168675,
      "grad_norm": 0.0637911930680275,
      "learning_rate": 7.607228915662651e-06,
      "loss": 0.0111,
      "step": 51430
    },
    {
      "epoch": 6.1975903614457835,
      "grad_norm": 1.4149128198623657,
      "learning_rate": 7.604819277108434e-06,
      "loss": 0.0433,
      "step": 51440
    },
    {
      "epoch": 6.198795180722891,
      "grad_norm": 1.8130933046340942,
      "learning_rate": 7.602409638554218e-06,
      "loss": 0.0268,
      "step": 51450
    },
    {
      "epoch": 6.2,
      "grad_norm": 4.489210605621338,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0121,
      "step": 51460
    },
    {
      "epoch": 6.201204819277108,
      "grad_norm": 0.020733479410409927,
      "learning_rate": 7.597590361445783e-06,
      "loss": 0.03,
      "step": 51470
    },
    {
      "epoch": 6.202409638554217,
      "grad_norm": 0.012752154842019081,
      "learning_rate": 7.5951807228915664e-06,
      "loss": 0.0047,
      "step": 51480
    },
    {
      "epoch": 6.203614457831326,
      "grad_norm": 2.0530450344085693,
      "learning_rate": 7.5927710843373505e-06,
      "loss": 0.0098,
      "step": 51490
    },
    {
      "epoch": 6.204819277108434,
      "grad_norm": 0.09384623169898987,
      "learning_rate": 7.590361445783133e-06,
      "loss": 0.0518,
      "step": 51500
    },
    {
      "epoch": 6.206024096385542,
      "grad_norm": 0.010787739418447018,
      "learning_rate": 7.587951807228916e-06,
      "loss": 0.0275,
      "step": 51510
    },
    {
      "epoch": 6.20722891566265,
      "grad_norm": 0.9710880517959595,
      "learning_rate": 7.5855421686747e-06,
      "loss": 0.0079,
      "step": 51520
    },
    {
      "epoch": 6.208433734939759,
      "grad_norm": 0.17450588941574097,
      "learning_rate": 7.583132530120483e-06,
      "loss": 0.0243,
      "step": 51530
    },
    {
      "epoch": 6.209638554216867,
      "grad_norm": 2.9610025882720947,
      "learning_rate": 7.5807228915662655e-06,
      "loss": 0.0577,
      "step": 51540
    },
    {
      "epoch": 6.210843373493976,
      "grad_norm": 0.03474048525094986,
      "learning_rate": 7.578313253012049e-06,
      "loss": 0.0438,
      "step": 51550
    },
    {
      "epoch": 6.212048192771085,
      "grad_norm": 0.8698733448982239,
      "learning_rate": 7.575903614457833e-06,
      "loss": 0.0152,
      "step": 51560
    },
    {
      "epoch": 6.213253012048193,
      "grad_norm": 0.09681527316570282,
      "learning_rate": 7.573493975903615e-06,
      "loss": 0.0064,
      "step": 51570
    },
    {
      "epoch": 6.214457831325301,
      "grad_norm": 0.057887863367795944,
      "learning_rate": 7.571084337349398e-06,
      "loss": 0.0061,
      "step": 51580
    },
    {
      "epoch": 6.215662650602409,
      "grad_norm": 3.179680109024048,
      "learning_rate": 7.5686746987951805e-06,
      "loss": 0.0624,
      "step": 51590
    },
    {
      "epoch": 6.216867469879518,
      "grad_norm": 0.5763927698135376,
      "learning_rate": 7.5662650602409645e-06,
      "loss": 0.033,
      "step": 51600
    },
    {
      "epoch": 6.218072289156627,
      "grad_norm": 1.6469722986221313,
      "learning_rate": 7.563855421686748e-06,
      "loss": 0.0389,
      "step": 51610
    },
    {
      "epoch": 6.219277108433735,
      "grad_norm": 0.007516297046095133,
      "learning_rate": 7.561445783132531e-06,
      "loss": 0.0218,
      "step": 51620
    },
    {
      "epoch": 6.220481927710844,
      "grad_norm": 0.5304377675056458,
      "learning_rate": 7.559036144578313e-06,
      "loss": 0.0057,
      "step": 51630
    },
    {
      "epoch": 6.2216867469879515,
      "grad_norm": 0.11418180912733078,
      "learning_rate": 7.556626506024097e-06,
      "loss": 0.0393,
      "step": 51640
    },
    {
      "epoch": 6.22289156626506,
      "grad_norm": 0.2215658575296402,
      "learning_rate": 7.5542168674698804e-06,
      "loss": 0.1086,
      "step": 51650
    },
    {
      "epoch": 6.224096385542168,
      "grad_norm": 0.013585454784333706,
      "learning_rate": 7.551807228915663e-06,
      "loss": 0.0041,
      "step": 51660
    },
    {
      "epoch": 6.225301204819277,
      "grad_norm": 2.423231363296509,
      "learning_rate": 7.549397590361447e-06,
      "loss": 0.018,
      "step": 51670
    },
    {
      "epoch": 6.226506024096386,
      "grad_norm": 1.715786099433899,
      "learning_rate": 7.54698795180723e-06,
      "loss": 0.0419,
      "step": 51680
    },
    {
      "epoch": 6.227710843373494,
      "grad_norm": 2.0981805324554443,
      "learning_rate": 7.544578313253012e-06,
      "loss": 0.0268,
      "step": 51690
    },
    {
      "epoch": 6.228915662650603,
      "grad_norm": 2.117213726043701,
      "learning_rate": 7.5421686746987955e-06,
      "loss": 0.0128,
      "step": 51700
    },
    {
      "epoch": 6.2301204819277105,
      "grad_norm": 2.6149404048919678,
      "learning_rate": 7.5397590361445795e-06,
      "loss": 0.0263,
      "step": 51710
    },
    {
      "epoch": 6.231325301204819,
      "grad_norm": 0.048032086342573166,
      "learning_rate": 7.537349397590362e-06,
      "loss": 0.0182,
      "step": 51720
    },
    {
      "epoch": 6.232530120481928,
      "grad_norm": 0.6375202536582947,
      "learning_rate": 7.534939759036145e-06,
      "loss": 0.0094,
      "step": 51730
    },
    {
      "epoch": 6.233734939759036,
      "grad_norm": 4.136595249176025,
      "learning_rate": 7.532530120481928e-06,
      "loss": 0.0364,
      "step": 51740
    },
    {
      "epoch": 6.234939759036145,
      "grad_norm": 0.7749234437942505,
      "learning_rate": 7.530120481927712e-06,
      "loss": 0.0245,
      "step": 51750
    },
    {
      "epoch": 6.236144578313253,
      "grad_norm": 4.286324501037598,
      "learning_rate": 7.5277108433734945e-06,
      "loss": 0.0488,
      "step": 51760
    },
    {
      "epoch": 6.2373493975903616,
      "grad_norm": 1.0990499258041382,
      "learning_rate": 7.525301204819278e-06,
      "loss": 0.0221,
      "step": 51770
    },
    {
      "epoch": 6.2385542168674695,
      "grad_norm": 0.49948787689208984,
      "learning_rate": 7.52289156626506e-06,
      "loss": 0.0244,
      "step": 51780
    },
    {
      "epoch": 6.239759036144578,
      "grad_norm": 0.02532818540930748,
      "learning_rate": 7.520481927710844e-06,
      "loss": 0.0034,
      "step": 51790
    },
    {
      "epoch": 6.240963855421687,
      "grad_norm": 0.017905302345752716,
      "learning_rate": 7.518072289156627e-06,
      "loss": 0.0112,
      "step": 51800
    },
    {
      "epoch": 6.242168674698795,
      "grad_norm": 0.010717639699578285,
      "learning_rate": 7.5156626506024095e-06,
      "loss": 0.0201,
      "step": 51810
    },
    {
      "epoch": 6.243373493975904,
      "grad_norm": 13.522395133972168,
      "learning_rate": 7.5132530120481936e-06,
      "loss": 0.0534,
      "step": 51820
    },
    {
      "epoch": 6.244578313253012,
      "grad_norm": 0.6595765352249146,
      "learning_rate": 7.510843373493977e-06,
      "loss": 0.0226,
      "step": 51830
    },
    {
      "epoch": 6.2457831325301205,
      "grad_norm": 0.00833461806178093,
      "learning_rate": 7.50843373493976e-06,
      "loss": 0.0268,
      "step": 51840
    },
    {
      "epoch": 6.246987951807229,
      "grad_norm": 0.13309992849826813,
      "learning_rate": 7.506024096385542e-06,
      "loss": 0.0065,
      "step": 51850
    },
    {
      "epoch": 6.248192771084337,
      "grad_norm": 0.0112202949821949,
      "learning_rate": 7.503614457831326e-06,
      "loss": 0.0166,
      "step": 51860
    },
    {
      "epoch": 6.249397590361446,
      "grad_norm": 0.005922525655478239,
      "learning_rate": 7.5012048192771094e-06,
      "loss": 0.0333,
      "step": 51870
    },
    {
      "epoch": 6.250602409638554,
      "grad_norm": 5.46877908706665,
      "learning_rate": 7.498795180722892e-06,
      "loss": 0.0336,
      "step": 51880
    },
    {
      "epoch": 6.251807228915663,
      "grad_norm": 0.02913615293800831,
      "learning_rate": 7.496385542168675e-06,
      "loss": 0.0143,
      "step": 51890
    },
    {
      "epoch": 6.253012048192771,
      "grad_norm": 1.2199865579605103,
      "learning_rate": 7.493975903614459e-06,
      "loss": 0.0491,
      "step": 51900
    },
    {
      "epoch": 6.2542168674698795,
      "grad_norm": 0.011079346761107445,
      "learning_rate": 7.491566265060241e-06,
      "loss": 0.0088,
      "step": 51910
    },
    {
      "epoch": 6.255421686746988,
      "grad_norm": 0.2903177738189697,
      "learning_rate": 7.4891566265060245e-06,
      "loss": 0.0405,
      "step": 51920
    },
    {
      "epoch": 6.256626506024096,
      "grad_norm": 0.013537023216485977,
      "learning_rate": 7.486746987951808e-06,
      "loss": 0.0214,
      "step": 51930
    },
    {
      "epoch": 6.257831325301205,
      "grad_norm": 2.087097644805908,
      "learning_rate": 7.484337349397592e-06,
      "loss": 0.0205,
      "step": 51940
    },
    {
      "epoch": 6.259036144578313,
      "grad_norm": 0.012196937575936317,
      "learning_rate": 7.481927710843374e-06,
      "loss": 0.0044,
      "step": 51950
    },
    {
      "epoch": 6.260240963855422,
      "grad_norm": 0.008238231763243675,
      "learning_rate": 7.479518072289157e-06,
      "loss": 0.1161,
      "step": 51960
    },
    {
      "epoch": 6.2614457831325305,
      "grad_norm": 1.7909908294677734,
      "learning_rate": 7.477108433734941e-06,
      "loss": 0.0284,
      "step": 51970
    },
    {
      "epoch": 6.2626506024096384,
      "grad_norm": 0.013085971586406231,
      "learning_rate": 7.4746987951807235e-06,
      "loss": 0.0044,
      "step": 51980
    },
    {
      "epoch": 6.263855421686747,
      "grad_norm": 0.11238210648298264,
      "learning_rate": 7.472289156626507e-06,
      "loss": 0.0249,
      "step": 51990
    },
    {
      "epoch": 6.265060240963855,
      "grad_norm": 0.5505248308181763,
      "learning_rate": 7.469879518072289e-06,
      "loss": 0.0238,
      "step": 52000
    },
    {
      "epoch": 6.266265060240964,
      "grad_norm": 0.4057728946208954,
      "learning_rate": 7.467469879518073e-06,
      "loss": 0.0269,
      "step": 52010
    },
    {
      "epoch": 6.267469879518072,
      "grad_norm": 0.011561350896954536,
      "learning_rate": 7.465060240963856e-06,
      "loss": 0.0078,
      "step": 52020
    },
    {
      "epoch": 6.268674698795181,
      "grad_norm": 3.209425687789917,
      "learning_rate": 7.462650602409639e-06,
      "loss": 0.0686,
      "step": 52030
    },
    {
      "epoch": 6.2698795180722895,
      "grad_norm": 2.3419463634490967,
      "learning_rate": 7.460240963855422e-06,
      "loss": 0.0252,
      "step": 52040
    },
    {
      "epoch": 6.271084337349397,
      "grad_norm": 28.094980239868164,
      "learning_rate": 7.457831325301206e-06,
      "loss": 0.0193,
      "step": 52050
    },
    {
      "epoch": 6.272289156626506,
      "grad_norm": 0.005598203279078007,
      "learning_rate": 7.455421686746989e-06,
      "loss": 0.0083,
      "step": 52060
    },
    {
      "epoch": 6.273493975903614,
      "grad_norm": 0.007886683568358421,
      "learning_rate": 7.453012048192771e-06,
      "loss": 0.0213,
      "step": 52070
    },
    {
      "epoch": 6.274698795180723,
      "grad_norm": 0.03438286855816841,
      "learning_rate": 7.4506024096385545e-06,
      "loss": 0.0356,
      "step": 52080
    },
    {
      "epoch": 6.275903614457832,
      "grad_norm": 1.8602266311645508,
      "learning_rate": 7.4481927710843385e-06,
      "loss": 0.0111,
      "step": 52090
    },
    {
      "epoch": 6.27710843373494,
      "grad_norm": 0.004989492241293192,
      "learning_rate": 7.445783132530121e-06,
      "loss": 0.0014,
      "step": 52100
    },
    {
      "epoch": 6.2783132530120485,
      "grad_norm": 5.155793190002441,
      "learning_rate": 7.443373493975904e-06,
      "loss": 0.0162,
      "step": 52110
    },
    {
      "epoch": 6.279518072289156,
      "grad_norm": 0.010545263066887856,
      "learning_rate": 7.440963855421688e-06,
      "loss": 0.0051,
      "step": 52120
    },
    {
      "epoch": 6.280722891566265,
      "grad_norm": 4.838670253753662,
      "learning_rate": 7.43855421686747e-06,
      "loss": 0.041,
      "step": 52130
    },
    {
      "epoch": 6.281927710843373,
      "grad_norm": 0.011778546497225761,
      "learning_rate": 7.4361445783132535e-06,
      "loss": 0.0085,
      "step": 52140
    },
    {
      "epoch": 6.283132530120482,
      "grad_norm": 0.005330436397343874,
      "learning_rate": 7.433734939759037e-06,
      "loss": 0.0179,
      "step": 52150
    },
    {
      "epoch": 6.284337349397591,
      "grad_norm": 0.652331531047821,
      "learning_rate": 7.431325301204821e-06,
      "loss": 0.016,
      "step": 52160
    },
    {
      "epoch": 6.285542168674699,
      "grad_norm": 0.008058547973632812,
      "learning_rate": 7.428915662650603e-06,
      "loss": 0.0258,
      "step": 52170
    },
    {
      "epoch": 6.286746987951807,
      "grad_norm": 0.10887966305017471,
      "learning_rate": 7.426506024096386e-06,
      "loss": 0.0313,
      "step": 52180
    },
    {
      "epoch": 6.287951807228915,
      "grad_norm": 0.0043345061130821705,
      "learning_rate": 7.4240963855421685e-06,
      "loss": 0.0351,
      "step": 52190
    },
    {
      "epoch": 6.289156626506024,
      "grad_norm": 0.004030311945825815,
      "learning_rate": 7.4216867469879526e-06,
      "loss": 0.0108,
      "step": 52200
    },
    {
      "epoch": 6.290361445783133,
      "grad_norm": 0.014771856367588043,
      "learning_rate": 7.419277108433736e-06,
      "loss": 0.0306,
      "step": 52210
    },
    {
      "epoch": 6.291566265060241,
      "grad_norm": 2.011469841003418,
      "learning_rate": 7.416867469879518e-06,
      "loss": 0.0391,
      "step": 52220
    },
    {
      "epoch": 6.29277108433735,
      "grad_norm": 2.4806768894195557,
      "learning_rate": 7.414457831325301e-06,
      "loss": 0.0443,
      "step": 52230
    },
    {
      "epoch": 6.293975903614458,
      "grad_norm": 2.4148874282836914,
      "learning_rate": 7.412048192771085e-06,
      "loss": 0.0168,
      "step": 52240
    },
    {
      "epoch": 6.295180722891566,
      "grad_norm": 0.9196505546569824,
      "learning_rate": 7.4096385542168684e-06,
      "loss": 0.0978,
      "step": 52250
    },
    {
      "epoch": 6.296385542168674,
      "grad_norm": 0.0069357906468212605,
      "learning_rate": 7.407228915662651e-06,
      "loss": 0.0191,
      "step": 52260
    },
    {
      "epoch": 6.297590361445783,
      "grad_norm": 0.9216721653938293,
      "learning_rate": 7.404819277108435e-06,
      "loss": 0.0138,
      "step": 52270
    },
    {
      "epoch": 6.298795180722892,
      "grad_norm": 1.0315730571746826,
      "learning_rate": 7.402409638554218e-06,
      "loss": 0.0204,
      "step": 52280
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.004662132356315851,
      "learning_rate": 7.4e-06,
      "loss": 0.0392,
      "step": 52290
    },
    {
      "epoch": 6.301204819277109,
      "grad_norm": 0.4806041717529297,
      "learning_rate": 7.3975903614457835e-06,
      "loss": 0.0042,
      "step": 52300
    },
    {
      "epoch": 6.3024096385542165,
      "grad_norm": 0.002009975491091609,
      "learning_rate": 7.3951807228915675e-06,
      "loss": 0.0114,
      "step": 52310
    },
    {
      "epoch": 6.303614457831325,
      "grad_norm": 0.3868563175201416,
      "learning_rate": 7.39277108433735e-06,
      "loss": 0.0141,
      "step": 52320
    },
    {
      "epoch": 6.304819277108434,
      "grad_norm": 0.02184818498790264,
      "learning_rate": 7.390361445783133e-06,
      "loss": 0.0057,
      "step": 52330
    },
    {
      "epoch": 6.306024096385542,
      "grad_norm": 0.002614216413348913,
      "learning_rate": 7.387951807228916e-06,
      "loss": 0.0008,
      "step": 52340
    },
    {
      "epoch": 6.307228915662651,
      "grad_norm": 3.7671847343444824,
      "learning_rate": 7.385542168674699e-06,
      "loss": 0.0182,
      "step": 52350
    },
    {
      "epoch": 6.308433734939759,
      "grad_norm": 3.7803635597229004,
      "learning_rate": 7.3831325301204825e-06,
      "loss": 0.025,
      "step": 52360
    },
    {
      "epoch": 6.309638554216868,
      "grad_norm": 0.14222410321235657,
      "learning_rate": 7.380722891566266e-06,
      "loss": 0.0383,
      "step": 52370
    },
    {
      "epoch": 6.3108433734939755,
      "grad_norm": 0.0044388785026967525,
      "learning_rate": 7.378313253012048e-06,
      "loss": 0.0437,
      "step": 52380
    },
    {
      "epoch": 6.312048192771084,
      "grad_norm": 0.3121582269668579,
      "learning_rate": 7.375903614457832e-06,
      "loss": 0.0159,
      "step": 52390
    },
    {
      "epoch": 6.313253012048193,
      "grad_norm": 0.49425962567329407,
      "learning_rate": 7.373493975903615e-06,
      "loss": 0.0542,
      "step": 52400
    },
    {
      "epoch": 6.314457831325301,
      "grad_norm": 2.0000388622283936,
      "learning_rate": 7.3710843373493976e-06,
      "loss": 0.0271,
      "step": 52410
    },
    {
      "epoch": 6.31566265060241,
      "grad_norm": 8.15397834777832,
      "learning_rate": 7.368674698795182e-06,
      "loss": 0.0384,
      "step": 52420
    },
    {
      "epoch": 6.316867469879518,
      "grad_norm": 0.019404739141464233,
      "learning_rate": 7.366265060240965e-06,
      "loss": 0.0181,
      "step": 52430
    },
    {
      "epoch": 6.3180722891566266,
      "grad_norm": 0.009150628000497818,
      "learning_rate": 7.363855421686747e-06,
      "loss": 0.0258,
      "step": 52440
    },
    {
      "epoch": 6.3192771084337345,
      "grad_norm": 1.1401346921920776,
      "learning_rate": 7.36144578313253e-06,
      "loss": 0.0325,
      "step": 52450
    },
    {
      "epoch": 6.320481927710843,
      "grad_norm": 0.505709707736969,
      "learning_rate": 7.359036144578314e-06,
      "loss": 0.0177,
      "step": 52460
    },
    {
      "epoch": 6.321686746987952,
      "grad_norm": 0.4423731565475464,
      "learning_rate": 7.3566265060240975e-06,
      "loss": 0.0433,
      "step": 52470
    },
    {
      "epoch": 6.32289156626506,
      "grad_norm": 1.8494997024536133,
      "learning_rate": 7.35421686746988e-06,
      "loss": 0.0352,
      "step": 52480
    },
    {
      "epoch": 6.324096385542169,
      "grad_norm": 0.2379075437784195,
      "learning_rate": 7.351807228915663e-06,
      "loss": 0.0358,
      "step": 52490
    },
    {
      "epoch": 6.325301204819277,
      "grad_norm": 0.9737770557403564,
      "learning_rate": 7.349397590361447e-06,
      "loss": 0.046,
      "step": 52500
    },
    {
      "epoch": 6.3265060240963855,
      "grad_norm": 0.7038037180900574,
      "learning_rate": 7.346987951807229e-06,
      "loss": 0.006,
      "step": 52510
    },
    {
      "epoch": 6.327710843373494,
      "grad_norm": 0.2391085922718048,
      "learning_rate": 7.3445783132530125e-06,
      "loss": 0.0053,
      "step": 52520
    },
    {
      "epoch": 6.328915662650602,
      "grad_norm": 1.7953264713287354,
      "learning_rate": 7.342168674698795e-06,
      "loss": 0.0172,
      "step": 52530
    },
    {
      "epoch": 6.330120481927711,
      "grad_norm": 0.23070836067199707,
      "learning_rate": 7.339759036144579e-06,
      "loss": 0.0189,
      "step": 52540
    },
    {
      "epoch": 6.331325301204819,
      "grad_norm": 0.006926466710865498,
      "learning_rate": 7.337349397590362e-06,
      "loss": 0.0573,
      "step": 52550
    },
    {
      "epoch": 6.332530120481928,
      "grad_norm": 0.003501785220578313,
      "learning_rate": 7.334939759036145e-06,
      "loss": 0.0246,
      "step": 52560
    },
    {
      "epoch": 6.333734939759037,
      "grad_norm": 0.98265540599823,
      "learning_rate": 7.332530120481928e-06,
      "loss": 0.0225,
      "step": 52570
    },
    {
      "epoch": 6.3349397590361445,
      "grad_norm": 0.005551721900701523,
      "learning_rate": 7.3301204819277116e-06,
      "loss": 0.0272,
      "step": 52580
    },
    {
      "epoch": 6.336144578313253,
      "grad_norm": 0.5395757555961609,
      "learning_rate": 7.327710843373495e-06,
      "loss": 0.0062,
      "step": 52590
    },
    {
      "epoch": 6.337349397590361,
      "grad_norm": 0.9202814102172852,
      "learning_rate": 7.325301204819277e-06,
      "loss": 0.0285,
      "step": 52600
    },
    {
      "epoch": 6.33855421686747,
      "grad_norm": 1.6045825481414795,
      "learning_rate": 7.322891566265061e-06,
      "loss": 0.0083,
      "step": 52610
    },
    {
      "epoch": 6.339759036144578,
      "grad_norm": 0.006266068667173386,
      "learning_rate": 7.320481927710844e-06,
      "loss": 0.0256,
      "step": 52620
    },
    {
      "epoch": 6.340963855421687,
      "grad_norm": 0.07220331579446793,
      "learning_rate": 7.318072289156627e-06,
      "loss": 0.0185,
      "step": 52630
    },
    {
      "epoch": 6.3421686746987955,
      "grad_norm": 0.2662765681743622,
      "learning_rate": 7.31566265060241e-06,
      "loss": 0.0171,
      "step": 52640
    },
    {
      "epoch": 6.343373493975903,
      "grad_norm": 0.005820804741233587,
      "learning_rate": 7.313253012048194e-06,
      "loss": 0.0144,
      "step": 52650
    },
    {
      "epoch": 6.344578313253012,
      "grad_norm": 0.002488408936187625,
      "learning_rate": 7.310843373493977e-06,
      "loss": 0.0194,
      "step": 52660
    },
    {
      "epoch": 6.34578313253012,
      "grad_norm": 0.00458110123872757,
      "learning_rate": 7.308433734939759e-06,
      "loss": 0.0562,
      "step": 52670
    },
    {
      "epoch": 6.346987951807229,
      "grad_norm": 0.013019454665482044,
      "learning_rate": 7.3060240963855425e-06,
      "loss": 0.0443,
      "step": 52680
    },
    {
      "epoch": 6.348192771084337,
      "grad_norm": 0.0032074004411697388,
      "learning_rate": 7.3036144578313265e-06,
      "loss": 0.0105,
      "step": 52690
    },
    {
      "epoch": 6.349397590361446,
      "grad_norm": 0.41416293382644653,
      "learning_rate": 7.301204819277109e-06,
      "loss": 0.0325,
      "step": 52700
    },
    {
      "epoch": 6.3506024096385545,
      "grad_norm": 0.7917501330375671,
      "learning_rate": 7.298795180722892e-06,
      "loss": 0.0204,
      "step": 52710
    },
    {
      "epoch": 6.351807228915662,
      "grad_norm": 1.6964114904403687,
      "learning_rate": 7.296385542168676e-06,
      "loss": 0.032,
      "step": 52720
    },
    {
      "epoch": 6.353012048192771,
      "grad_norm": 0.4951411187648773,
      "learning_rate": 7.293975903614458e-06,
      "loss": 0.0185,
      "step": 52730
    },
    {
      "epoch": 6.354216867469879,
      "grad_norm": 1.882051944732666,
      "learning_rate": 7.2915662650602415e-06,
      "loss": 0.0235,
      "step": 52740
    },
    {
      "epoch": 6.355421686746988,
      "grad_norm": 1.8890316486358643,
      "learning_rate": 7.289156626506025e-06,
      "loss": 0.0165,
      "step": 52750
    },
    {
      "epoch": 6.356626506024097,
      "grad_norm": 0.006339101120829582,
      "learning_rate": 7.286746987951808e-06,
      "loss": 0.0233,
      "step": 52760
    },
    {
      "epoch": 6.357831325301205,
      "grad_norm": 3.796313762664795,
      "learning_rate": 7.284337349397591e-06,
      "loss": 0.018,
      "step": 52770
    },
    {
      "epoch": 6.3590361445783135,
      "grad_norm": 1.565453290939331,
      "learning_rate": 7.281927710843374e-06,
      "loss": 0.0117,
      "step": 52780
    },
    {
      "epoch": 6.360240963855421,
      "grad_norm": 0.1567808836698532,
      "learning_rate": 7.2795180722891566e-06,
      "loss": 0.0035,
      "step": 52790
    },
    {
      "epoch": 6.36144578313253,
      "grad_norm": 0.06376426666975021,
      "learning_rate": 7.277108433734941e-06,
      "loss": 0.014,
      "step": 52800
    },
    {
      "epoch": 6.362650602409639,
      "grad_norm": 3.158869981765747,
      "learning_rate": 7.274698795180724e-06,
      "loss": 0.023,
      "step": 52810
    },
    {
      "epoch": 6.363855421686747,
      "grad_norm": 4.085079669952393,
      "learning_rate": 7.272289156626506e-06,
      "loss": 0.0809,
      "step": 52820
    },
    {
      "epoch": 6.365060240963856,
      "grad_norm": 0.0028925363440066576,
      "learning_rate": 7.269879518072289e-06,
      "loss": 0.0387,
      "step": 52830
    },
    {
      "epoch": 6.366265060240964,
      "grad_norm": 0.003316944232210517,
      "learning_rate": 7.267469879518073e-06,
      "loss": 0.0034,
      "step": 52840
    },
    {
      "epoch": 6.367469879518072,
      "grad_norm": 0.0180787555873394,
      "learning_rate": 7.265060240963856e-06,
      "loss": 0.0122,
      "step": 52850
    },
    {
      "epoch": 6.36867469879518,
      "grad_norm": 3.552642583847046,
      "learning_rate": 7.262650602409639e-06,
      "loss": 0.0525,
      "step": 52860
    },
    {
      "epoch": 6.369879518072289,
      "grad_norm": 0.0028041047044098377,
      "learning_rate": 7.260240963855423e-06,
      "loss": 0.0601,
      "step": 52870
    },
    {
      "epoch": 6.371084337349398,
      "grad_norm": 0.07768478244543076,
      "learning_rate": 7.257831325301206e-06,
      "loss": 0.0096,
      "step": 52880
    },
    {
      "epoch": 6.372289156626506,
      "grad_norm": 1.0616101026535034,
      "learning_rate": 7.255421686746988e-06,
      "loss": 0.0265,
      "step": 52890
    },
    {
      "epoch": 6.373493975903615,
      "grad_norm": 0.06797362864017487,
      "learning_rate": 7.2530120481927715e-06,
      "loss": 0.0052,
      "step": 52900
    },
    {
      "epoch": 6.374698795180723,
      "grad_norm": 0.04657995328307152,
      "learning_rate": 7.2506024096385555e-06,
      "loss": 0.0351,
      "step": 52910
    },
    {
      "epoch": 6.375903614457831,
      "grad_norm": 0.02113780379295349,
      "learning_rate": 7.248192771084338e-06,
      "loss": 0.0226,
      "step": 52920
    },
    {
      "epoch": 6.377108433734939,
      "grad_norm": 0.3565642833709717,
      "learning_rate": 7.245783132530121e-06,
      "loss": 0.0574,
      "step": 52930
    },
    {
      "epoch": 6.378313253012048,
      "grad_norm": 0.006451278924942017,
      "learning_rate": 7.243373493975903e-06,
      "loss": 0.0294,
      "step": 52940
    },
    {
      "epoch": 6.379518072289157,
      "grad_norm": 0.009862508624792099,
      "learning_rate": 7.240963855421687e-06,
      "loss": 0.008,
      "step": 52950
    },
    {
      "epoch": 6.380722891566265,
      "grad_norm": 0.005801557097584009,
      "learning_rate": 7.2385542168674706e-06,
      "loss": 0.0047,
      "step": 52960
    },
    {
      "epoch": 6.381927710843374,
      "grad_norm": 0.1591523438692093,
      "learning_rate": 7.236144578313254e-06,
      "loss": 0.0123,
      "step": 52970
    },
    {
      "epoch": 6.3831325301204815,
      "grad_norm": 0.009418187662959099,
      "learning_rate": 7.233734939759037e-06,
      "loss": 0.0105,
      "step": 52980
    },
    {
      "epoch": 6.38433734939759,
      "grad_norm": 0.011773803271353245,
      "learning_rate": 7.23132530120482e-06,
      "loss": 0.0122,
      "step": 52990
    },
    {
      "epoch": 6.385542168674699,
      "grad_norm": 0.17713207006454468,
      "learning_rate": 7.228915662650603e-06,
      "loss": 0.0176,
      "step": 53000
    },
    {
      "epoch": 6.386746987951807,
      "grad_norm": 0.009368978440761566,
      "learning_rate": 7.226506024096386e-06,
      "loss": 0.0442,
      "step": 53010
    },
    {
      "epoch": 6.387951807228916,
      "grad_norm": 0.009966427460312843,
      "learning_rate": 7.22409638554217e-06,
      "loss": 0.0254,
      "step": 53020
    },
    {
      "epoch": 6.389156626506024,
      "grad_norm": 0.0022926745004951954,
      "learning_rate": 7.221686746987953e-06,
      "loss": 0.0184,
      "step": 53030
    },
    {
      "epoch": 6.390361445783133,
      "grad_norm": 0.2083415538072586,
      "learning_rate": 7.219277108433735e-06,
      "loss": 0.0098,
      "step": 53040
    },
    {
      "epoch": 6.391566265060241,
      "grad_norm": 0.004651983268558979,
      "learning_rate": 7.216867469879518e-06,
      "loss": 0.0062,
      "step": 53050
    },
    {
      "epoch": 6.392771084337349,
      "grad_norm": 0.13673461973667145,
      "learning_rate": 7.214457831325302e-06,
      "loss": 0.028,
      "step": 53060
    },
    {
      "epoch": 6.393975903614458,
      "grad_norm": 0.004201969597488642,
      "learning_rate": 7.212048192771085e-06,
      "loss": 0.0081,
      "step": 53070
    },
    {
      "epoch": 6.395180722891566,
      "grad_norm": 2.138430595397949,
      "learning_rate": 7.209638554216868e-06,
      "loss": 0.0277,
      "step": 53080
    },
    {
      "epoch": 6.396385542168675,
      "grad_norm": 0.027423067018389702,
      "learning_rate": 7.207228915662651e-06,
      "loss": 0.0093,
      "step": 53090
    },
    {
      "epoch": 6.397590361445783,
      "grad_norm": 0.1496480107307434,
      "learning_rate": 7.204819277108435e-06,
      "loss": 0.013,
      "step": 53100
    },
    {
      "epoch": 6.3987951807228916,
      "grad_norm": 0.002054321812465787,
      "learning_rate": 7.202409638554217e-06,
      "loss": 0.039,
      "step": 53110
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.8683799505233765,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0322,
      "step": 53120
    },
    {
      "epoch": 6.401204819277108,
      "grad_norm": 0.017992880195379257,
      "learning_rate": 7.1975903614457845e-06,
      "loss": 0.012,
      "step": 53130
    },
    {
      "epoch": 6.402409638554217,
      "grad_norm": 0.0024503229651600122,
      "learning_rate": 7.195180722891567e-06,
      "loss": 0.0157,
      "step": 53140
    },
    {
      "epoch": 6.403614457831325,
      "grad_norm": 0.0022540355566889048,
      "learning_rate": 7.19277108433735e-06,
      "loss": 0.0138,
      "step": 53150
    },
    {
      "epoch": 6.404819277108434,
      "grad_norm": 0.18503472208976746,
      "learning_rate": 7.190361445783132e-06,
      "loss": 0.0294,
      "step": 53160
    },
    {
      "epoch": 6.406024096385542,
      "grad_norm": 0.003149991389364004,
      "learning_rate": 7.187951807228916e-06,
      "loss": 0.026,
      "step": 53170
    },
    {
      "epoch": 6.4072289156626505,
      "grad_norm": 1.978115200996399,
      "learning_rate": 7.1855421686747e-06,
      "loss": 0.0308,
      "step": 53180
    },
    {
      "epoch": 6.408433734939759,
      "grad_norm": 0.7784947752952576,
      "learning_rate": 7.183132530120483e-06,
      "loss": 0.0594,
      "step": 53190
    },
    {
      "epoch": 6.409638554216867,
      "grad_norm": 0.0015802737325429916,
      "learning_rate": 7.180722891566265e-06,
      "loss": 0.0145,
      "step": 53200
    },
    {
      "epoch": 6.410843373493976,
      "grad_norm": 0.0025817982386797667,
      "learning_rate": 7.178313253012049e-06,
      "loss": 0.0226,
      "step": 53210
    },
    {
      "epoch": 6.412048192771084,
      "grad_norm": 0.3422391414642334,
      "learning_rate": 7.175903614457832e-06,
      "loss": 0.004,
      "step": 53220
    },
    {
      "epoch": 6.413253012048193,
      "grad_norm": 0.012125193141400814,
      "learning_rate": 7.173493975903615e-06,
      "loss": 0.0342,
      "step": 53230
    },
    {
      "epoch": 6.414457831325302,
      "grad_norm": 2.139023542404175,
      "learning_rate": 7.171084337349398e-06,
      "loss": 0.0073,
      "step": 53240
    },
    {
      "epoch": 6.4156626506024095,
      "grad_norm": 0.0021366558503359556,
      "learning_rate": 7.168674698795182e-06,
      "loss": 0.0533,
      "step": 53250
    },
    {
      "epoch": 6.416867469879518,
      "grad_norm": 0.0017587781185284257,
      "learning_rate": 7.166265060240964e-06,
      "loss": 0.0435,
      "step": 53260
    },
    {
      "epoch": 6.418072289156626,
      "grad_norm": 0.006784810684621334,
      "learning_rate": 7.163855421686747e-06,
      "loss": 0.0447,
      "step": 53270
    },
    {
      "epoch": 6.419277108433735,
      "grad_norm": 0.0050947098061442375,
      "learning_rate": 7.161445783132531e-06,
      "loss": 0.0099,
      "step": 53280
    },
    {
      "epoch": 6.420481927710844,
      "grad_norm": 1.489044427871704,
      "learning_rate": 7.159036144578314e-06,
      "loss": 0.0104,
      "step": 53290
    },
    {
      "epoch": 6.421686746987952,
      "grad_norm": 0.0048156664706766605,
      "learning_rate": 7.156626506024097e-06,
      "loss": 0.0025,
      "step": 53300
    },
    {
      "epoch": 6.4228915662650605,
      "grad_norm": 0.004049001727253199,
      "learning_rate": 7.15421686746988e-06,
      "loss": 0.025,
      "step": 53310
    },
    {
      "epoch": 6.424096385542168,
      "grad_norm": 0.3327287435531616,
      "learning_rate": 7.151807228915664e-06,
      "loss": 0.0249,
      "step": 53320
    },
    {
      "epoch": 6.425301204819277,
      "grad_norm": 0.8013609647750854,
      "learning_rate": 7.149397590361446e-06,
      "loss": 0.0077,
      "step": 53330
    },
    {
      "epoch": 6.426506024096385,
      "grad_norm": 0.002809397876262665,
      "learning_rate": 7.1469879518072295e-06,
      "loss": 0.0358,
      "step": 53340
    },
    {
      "epoch": 6.427710843373494,
      "grad_norm": 0.0036670842673629522,
      "learning_rate": 7.144578313253012e-06,
      "loss": 0.0572,
      "step": 53350
    },
    {
      "epoch": 6.428915662650603,
      "grad_norm": 0.0076194945722818375,
      "learning_rate": 7.142168674698796e-06,
      "loss": 0.0724,
      "step": 53360
    },
    {
      "epoch": 6.430120481927711,
      "grad_norm": 2.096113443374634,
      "learning_rate": 7.139759036144579e-06,
      "loss": 0.0743,
      "step": 53370
    },
    {
      "epoch": 6.4313253012048195,
      "grad_norm": 0.008821341209113598,
      "learning_rate": 7.137349397590362e-06,
      "loss": 0.0116,
      "step": 53380
    },
    {
      "epoch": 6.432530120481927,
      "grad_norm": 0.26641538739204407,
      "learning_rate": 7.134939759036145e-06,
      "loss": 0.049,
      "step": 53390
    },
    {
      "epoch": 6.433734939759036,
      "grad_norm": 0.01346113346517086,
      "learning_rate": 7.132530120481929e-06,
      "loss": 0.0377,
      "step": 53400
    },
    {
      "epoch": 6.434939759036144,
      "grad_norm": 0.02460857480764389,
      "learning_rate": 7.130120481927712e-06,
      "loss": 0.0119,
      "step": 53410
    },
    {
      "epoch": 6.436144578313253,
      "grad_norm": 2.2994964122772217,
      "learning_rate": 7.127710843373494e-06,
      "loss": 0.0337,
      "step": 53420
    },
    {
      "epoch": 6.437349397590362,
      "grad_norm": 0.012893978506326675,
      "learning_rate": 7.125301204819278e-06,
      "loss": 0.0136,
      "step": 53430
    },
    {
      "epoch": 6.43855421686747,
      "grad_norm": 1.0545125007629395,
      "learning_rate": 7.122891566265061e-06,
      "loss": 0.0089,
      "step": 53440
    },
    {
      "epoch": 6.4397590361445785,
      "grad_norm": 0.013633668422698975,
      "learning_rate": 7.120481927710844e-06,
      "loss": 0.0047,
      "step": 53450
    },
    {
      "epoch": 6.440963855421686,
      "grad_norm": 0.012269149534404278,
      "learning_rate": 7.118072289156627e-06,
      "loss": 0.0378,
      "step": 53460
    },
    {
      "epoch": 6.442168674698795,
      "grad_norm": 2.0118346214294434,
      "learning_rate": 7.115662650602411e-06,
      "loss": 0.0289,
      "step": 53470
    },
    {
      "epoch": 6.443373493975904,
      "grad_norm": 0.015618235804140568,
      "learning_rate": 7.113253012048193e-06,
      "loss": 0.0094,
      "step": 53480
    },
    {
      "epoch": 6.444578313253012,
      "grad_norm": 0.012144804932177067,
      "learning_rate": 7.110843373493976e-06,
      "loss": 0.0192,
      "step": 53490
    },
    {
      "epoch": 6.445783132530121,
      "grad_norm": 0.007898891344666481,
      "learning_rate": 7.1084337349397595e-06,
      "loss": 0.0361,
      "step": 53500
    },
    {
      "epoch": 6.446987951807229,
      "grad_norm": 0.024879494681954384,
      "learning_rate": 7.1060240963855435e-06,
      "loss": 0.051,
      "step": 53510
    },
    {
      "epoch": 6.448192771084337,
      "grad_norm": 0.005940741393715143,
      "learning_rate": 7.103614457831326e-06,
      "loss": 0.0598,
      "step": 53520
    },
    {
      "epoch": 6.449397590361446,
      "grad_norm": 0.13992337882518768,
      "learning_rate": 7.101204819277109e-06,
      "loss": 0.0106,
      "step": 53530
    },
    {
      "epoch": 6.450602409638554,
      "grad_norm": 0.014189102686941624,
      "learning_rate": 7.098795180722891e-06,
      "loss": 0.0083,
      "step": 53540
    },
    {
      "epoch": 6.451807228915663,
      "grad_norm": 0.018323374912142754,
      "learning_rate": 7.096385542168675e-06,
      "loss": 0.0439,
      "step": 53550
    },
    {
      "epoch": 6.453012048192771,
      "grad_norm": 0.007204421795904636,
      "learning_rate": 7.0939759036144586e-06,
      "loss": 0.0023,
      "step": 53560
    },
    {
      "epoch": 6.45421686746988,
      "grad_norm": 0.007152726408094168,
      "learning_rate": 7.091566265060241e-06,
      "loss": 0.0545,
      "step": 53570
    },
    {
      "epoch": 6.455421686746988,
      "grad_norm": 0.6234007477760315,
      "learning_rate": 7.089156626506025e-06,
      "loss": 0.0158,
      "step": 53580
    },
    {
      "epoch": 6.456626506024096,
      "grad_norm": 0.06369836628437042,
      "learning_rate": 7.086746987951808e-06,
      "loss": 0.0063,
      "step": 53590
    },
    {
      "epoch": 6.457831325301205,
      "grad_norm": 0.0042274086736142635,
      "learning_rate": 7.084337349397591e-06,
      "loss": 0.004,
      "step": 53600
    },
    {
      "epoch": 6.459036144578313,
      "grad_norm": 0.004131673369556665,
      "learning_rate": 7.081927710843374e-06,
      "loss": 0.0444,
      "step": 53610
    },
    {
      "epoch": 6.460240963855422,
      "grad_norm": 0.005498615093529224,
      "learning_rate": 7.079518072289158e-06,
      "loss": 0.0092,
      "step": 53620
    },
    {
      "epoch": 6.46144578313253,
      "grad_norm": 0.8641817569732666,
      "learning_rate": 7.077108433734941e-06,
      "loss": 0.012,
      "step": 53630
    },
    {
      "epoch": 6.462650602409639,
      "grad_norm": 0.05156862735748291,
      "learning_rate": 7.074698795180723e-06,
      "loss": 0.0191,
      "step": 53640
    },
    {
      "epoch": 6.4638554216867465,
      "grad_norm": 2.8173882961273193,
      "learning_rate": 7.072289156626506e-06,
      "loss": 0.0142,
      "step": 53650
    },
    {
      "epoch": 6.465060240963855,
      "grad_norm": 0.007418050430715084,
      "learning_rate": 7.06987951807229e-06,
      "loss": 0.0004,
      "step": 53660
    },
    {
      "epoch": 6.466265060240964,
      "grad_norm": 0.002287863986566663,
      "learning_rate": 7.067469879518073e-06,
      "loss": 0.0264,
      "step": 53670
    },
    {
      "epoch": 6.467469879518072,
      "grad_norm": 3.699495553970337,
      "learning_rate": 7.065060240963856e-06,
      "loss": 0.0151,
      "step": 53680
    },
    {
      "epoch": 6.468674698795181,
      "grad_norm": 0.926278829574585,
      "learning_rate": 7.062650602409639e-06,
      "loss": 0.0293,
      "step": 53690
    },
    {
      "epoch": 6.469879518072289,
      "grad_norm": 0.0046404581516981125,
      "learning_rate": 7.060240963855422e-06,
      "loss": 0.0446,
      "step": 53700
    },
    {
      "epoch": 6.471084337349398,
      "grad_norm": 0.22821708023548126,
      "learning_rate": 7.057831325301205e-06,
      "loss": 0.0445,
      "step": 53710
    },
    {
      "epoch": 6.472289156626506,
      "grad_norm": 0.011467206291854382,
      "learning_rate": 7.0554216867469885e-06,
      "loss": 0.013,
      "step": 53720
    },
    {
      "epoch": 6.473493975903614,
      "grad_norm": 0.15707267820835114,
      "learning_rate": 7.0530120481927726e-06,
      "loss": 0.0126,
      "step": 53730
    },
    {
      "epoch": 6.474698795180723,
      "grad_norm": 2.6038060188293457,
      "learning_rate": 7.050602409638555e-06,
      "loss": 0.0632,
      "step": 53740
    },
    {
      "epoch": 6.475903614457831,
      "grad_norm": 0.08580021560192108,
      "learning_rate": 7.048192771084338e-06,
      "loss": 0.0018,
      "step": 53750
    },
    {
      "epoch": 6.47710843373494,
      "grad_norm": 2.770864486694336,
      "learning_rate": 7.04578313253012e-06,
      "loss": 0.0168,
      "step": 53760
    },
    {
      "epoch": 6.478313253012049,
      "grad_norm": 0.005485855974256992,
      "learning_rate": 7.043373493975904e-06,
      "loss": 0.0139,
      "step": 53770
    },
    {
      "epoch": 6.4795180722891565,
      "grad_norm": 0.0037697074003517628,
      "learning_rate": 7.040963855421688e-06,
      "loss": 0.0371,
      "step": 53780
    },
    {
      "epoch": 6.480722891566265,
      "grad_norm": 0.43628954887390137,
      "learning_rate": 7.03855421686747e-06,
      "loss": 0.0016,
      "step": 53790
    },
    {
      "epoch": 6.481927710843373,
      "grad_norm": 0.010653817094862461,
      "learning_rate": 7.036144578313253e-06,
      "loss": 0.0303,
      "step": 53800
    },
    {
      "epoch": 6.483132530120482,
      "grad_norm": 3.4152472019195557,
      "learning_rate": 7.033734939759037e-06,
      "loss": 0.0242,
      "step": 53810
    },
    {
      "epoch": 6.48433734939759,
      "grad_norm": 2.1171348094940186,
      "learning_rate": 7.03132530120482e-06,
      "loss": 0.0223,
      "step": 53820
    },
    {
      "epoch": 6.485542168674699,
      "grad_norm": 2.860363006591797,
      "learning_rate": 7.028915662650603e-06,
      "loss": 0.0202,
      "step": 53830
    },
    {
      "epoch": 6.486746987951808,
      "grad_norm": 4.211809158325195,
      "learning_rate": 7.026506024096386e-06,
      "loss": 0.0248,
      "step": 53840
    },
    {
      "epoch": 6.4879518072289155,
      "grad_norm": 2.3604886531829834,
      "learning_rate": 7.02409638554217e-06,
      "loss": 0.0264,
      "step": 53850
    },
    {
      "epoch": 6.489156626506024,
      "grad_norm": 0.0064530749805271626,
      "learning_rate": 7.021686746987952e-06,
      "loss": 0.0175,
      "step": 53860
    },
    {
      "epoch": 6.490361445783132,
      "grad_norm": 0.02469458244740963,
      "learning_rate": 7.019277108433735e-06,
      "loss": 0.0331,
      "step": 53870
    },
    {
      "epoch": 6.491566265060241,
      "grad_norm": 2.7838335037231445,
      "learning_rate": 7.016867469879519e-06,
      "loss": 0.0136,
      "step": 53880
    },
    {
      "epoch": 6.492771084337349,
      "grad_norm": 1.2034200429916382,
      "learning_rate": 7.014457831325302e-06,
      "loss": 0.0189,
      "step": 53890
    },
    {
      "epoch": 6.493975903614458,
      "grad_norm": 0.31471121311187744,
      "learning_rate": 7.012048192771085e-06,
      "loss": 0.0409,
      "step": 53900
    },
    {
      "epoch": 6.495180722891567,
      "grad_norm": 0.004415211733430624,
      "learning_rate": 7.009638554216868e-06,
      "loss": 0.0228,
      "step": 53910
    },
    {
      "epoch": 6.4963855421686745,
      "grad_norm": 2.6372663974761963,
      "learning_rate": 7.007228915662651e-06,
      "loss": 0.0317,
      "step": 53920
    },
    {
      "epoch": 6.497590361445783,
      "grad_norm": 0.06553920358419418,
      "learning_rate": 7.004819277108434e-06,
      "loss": 0.017,
      "step": 53930
    },
    {
      "epoch": 6.498795180722891,
      "grad_norm": 0.9062584042549133,
      "learning_rate": 7.0024096385542176e-06,
      "loss": 0.0277,
      "step": 53940
    },
    {
      "epoch": 6.5,
      "grad_norm": 10.041605949401855,
      "learning_rate": 7e-06,
      "loss": 0.0233,
      "step": 53950
    },
    {
      "epoch": 6.501204819277109,
      "grad_norm": 7.229929447174072,
      "learning_rate": 6.997590361445784e-06,
      "loss": 0.0103,
      "step": 53960
    },
    {
      "epoch": 6.502409638554217,
      "grad_norm": 0.19378890097141266,
      "learning_rate": 6.995180722891567e-06,
      "loss": 0.0334,
      "step": 53970
    },
    {
      "epoch": 6.5036144578313255,
      "grad_norm": 0.004193749278783798,
      "learning_rate": 6.992771084337349e-06,
      "loss": 0.0068,
      "step": 53980
    },
    {
      "epoch": 6.504819277108433,
      "grad_norm": 0.0022499600891023874,
      "learning_rate": 6.990361445783133e-06,
      "loss": 0.0086,
      "step": 53990
    },
    {
      "epoch": 6.506024096385542,
      "grad_norm": 0.0015403785509988666,
      "learning_rate": 6.987951807228917e-06,
      "loss": 0.0098,
      "step": 54000
    },
    {
      "epoch": 6.507228915662651,
      "grad_norm": 0.3626674711704254,
      "learning_rate": 6.985542168674699e-06,
      "loss": 0.0073,
      "step": 54010
    },
    {
      "epoch": 6.508433734939759,
      "grad_norm": 0.0022400766611099243,
      "learning_rate": 6.983132530120482e-06,
      "loss": 0.0113,
      "step": 54020
    },
    {
      "epoch": 6.509638554216868,
      "grad_norm": 1.9421309232711792,
      "learning_rate": 6.980722891566266e-06,
      "loss": 0.0604,
      "step": 54030
    },
    {
      "epoch": 6.510843373493976,
      "grad_norm": 0.0074750278145074844,
      "learning_rate": 6.978313253012049e-06,
      "loss": 0.0173,
      "step": 54040
    },
    {
      "epoch": 6.5120481927710845,
      "grad_norm": 0.005133500788360834,
      "learning_rate": 6.975903614457832e-06,
      "loss": 0.0024,
      "step": 54050
    },
    {
      "epoch": 6.513253012048192,
      "grad_norm": 0.006813634652644396,
      "learning_rate": 6.973493975903615e-06,
      "loss": 0.0288,
      "step": 54060
    },
    {
      "epoch": 6.514457831325301,
      "grad_norm": 0.0025136475451290607,
      "learning_rate": 6.971084337349399e-06,
      "loss": 0.0133,
      "step": 54070
    },
    {
      "epoch": 6.51566265060241,
      "grad_norm": 0.026344407349824905,
      "learning_rate": 6.968674698795181e-06,
      "loss": 0.0553,
      "step": 54080
    },
    {
      "epoch": 6.516867469879518,
      "grad_norm": 4.257281303405762,
      "learning_rate": 6.966265060240964e-06,
      "loss": 0.0198,
      "step": 54090
    },
    {
      "epoch": 6.518072289156627,
      "grad_norm": 0.002976100193336606,
      "learning_rate": 6.963855421686747e-06,
      "loss": 0.0188,
      "step": 54100
    },
    {
      "epoch": 6.519277108433735,
      "grad_norm": 0.9277450442314148,
      "learning_rate": 6.961445783132531e-06,
      "loss": 0.0158,
      "step": 54110
    },
    {
      "epoch": 6.5204819277108435,
      "grad_norm": 0.0018416863167658448,
      "learning_rate": 6.959036144578314e-06,
      "loss": 0.0444,
      "step": 54120
    },
    {
      "epoch": 6.521686746987951,
      "grad_norm": 0.4408656358718872,
      "learning_rate": 6.956626506024097e-06,
      "loss": 0.0182,
      "step": 54130
    },
    {
      "epoch": 6.52289156626506,
      "grad_norm": 1.9778060913085938,
      "learning_rate": 6.954216867469879e-06,
      "loss": 0.0254,
      "step": 54140
    },
    {
      "epoch": 6.524096385542169,
      "grad_norm": 1.3196885585784912,
      "learning_rate": 6.951807228915663e-06,
      "loss": 0.0334,
      "step": 54150
    },
    {
      "epoch": 6.525301204819277,
      "grad_norm": 10.911908149719238,
      "learning_rate": 6.949397590361447e-06,
      "loss": 0.0307,
      "step": 54160
    },
    {
      "epoch": 6.526506024096386,
      "grad_norm": 0.012446625158190727,
      "learning_rate": 6.946987951807229e-06,
      "loss": 0.006,
      "step": 54170
    },
    {
      "epoch": 6.527710843373494,
      "grad_norm": 0.02309866063296795,
      "learning_rate": 6.944578313253013e-06,
      "loss": 0.0213,
      "step": 54180
    },
    {
      "epoch": 6.528915662650602,
      "grad_norm": 0.3632708191871643,
      "learning_rate": 6.942168674698796e-06,
      "loss": 0.1065,
      "step": 54190
    },
    {
      "epoch": 6.530120481927711,
      "grad_norm": 0.3055844306945801,
      "learning_rate": 6.9397590361445784e-06,
      "loss": 0.0272,
      "step": 54200
    },
    {
      "epoch": 6.531325301204819,
      "grad_norm": 1.123409628868103,
      "learning_rate": 6.937349397590362e-06,
      "loss": 0.0392,
      "step": 54210
    },
    {
      "epoch": 6.532530120481928,
      "grad_norm": 0.44363364577293396,
      "learning_rate": 6.934939759036146e-06,
      "loss": 0.0213,
      "step": 54220
    },
    {
      "epoch": 6.533734939759036,
      "grad_norm": 0.07895995676517487,
      "learning_rate": 6.932530120481929e-06,
      "loss": 0.0066,
      "step": 54230
    },
    {
      "epoch": 6.534939759036145,
      "grad_norm": 0.009259245358407497,
      "learning_rate": 6.930120481927711e-06,
      "loss": 0.0103,
      "step": 54240
    },
    {
      "epoch": 6.5361445783132535,
      "grad_norm": 1.8797467947006226,
      "learning_rate": 6.927710843373494e-06,
      "loss": 0.0267,
      "step": 54250
    },
    {
      "epoch": 6.537349397590361,
      "grad_norm": 0.5698407888412476,
      "learning_rate": 6.925301204819278e-06,
      "loss": 0.0133,
      "step": 54260
    },
    {
      "epoch": 6.53855421686747,
      "grad_norm": 0.008867030963301659,
      "learning_rate": 6.922891566265061e-06,
      "loss": 0.0081,
      "step": 54270
    },
    {
      "epoch": 6.539759036144578,
      "grad_norm": 0.04540257900953293,
      "learning_rate": 6.920481927710844e-06,
      "loss": 0.0313,
      "step": 54280
    },
    {
      "epoch": 6.540963855421687,
      "grad_norm": 0.8552881479263306,
      "learning_rate": 6.918072289156626e-06,
      "loss": 0.0106,
      "step": 54290
    },
    {
      "epoch": 6.542168674698795,
      "grad_norm": 0.03932856023311615,
      "learning_rate": 6.91566265060241e-06,
      "loss": 0.0203,
      "step": 54300
    },
    {
      "epoch": 6.543373493975904,
      "grad_norm": 0.006820326205343008,
      "learning_rate": 6.913253012048193e-06,
      "loss": 0.0204,
      "step": 54310
    },
    {
      "epoch": 6.544578313253012,
      "grad_norm": 0.013722877018153667,
      "learning_rate": 6.9108433734939766e-06,
      "loss": 0.0159,
      "step": 54320
    },
    {
      "epoch": 6.54578313253012,
      "grad_norm": 0.0032527290750294924,
      "learning_rate": 6.90843373493976e-06,
      "loss": 0.0158,
      "step": 54330
    },
    {
      "epoch": 6.546987951807229,
      "grad_norm": 0.2537875771522522,
      "learning_rate": 6.906024096385543e-06,
      "loss": 0.0043,
      "step": 54340
    },
    {
      "epoch": 6.548192771084337,
      "grad_norm": 2.0421485900878906,
      "learning_rate": 6.903614457831326e-06,
      "loss": 0.0212,
      "step": 54350
    },
    {
      "epoch": 6.549397590361446,
      "grad_norm": 0.00837483536452055,
      "learning_rate": 6.901204819277108e-06,
      "loss": 0.0475,
      "step": 54360
    },
    {
      "epoch": 6.550602409638554,
      "grad_norm": 1.4006330966949463,
      "learning_rate": 6.8987951807228924e-06,
      "loss": 0.027,
      "step": 54370
    },
    {
      "epoch": 6.551807228915663,
      "grad_norm": 0.005305484868586063,
      "learning_rate": 6.896385542168676e-06,
      "loss": 0.0046,
      "step": 54380
    },
    {
      "epoch": 6.553012048192771,
      "grad_norm": 0.30554211139678955,
      "learning_rate": 6.893975903614458e-06,
      "loss": 0.0247,
      "step": 54390
    },
    {
      "epoch": 6.554216867469879,
      "grad_norm": 0.60406893491745,
      "learning_rate": 6.891566265060241e-06,
      "loss": 0.0083,
      "step": 54400
    },
    {
      "epoch": 6.555421686746988,
      "grad_norm": 0.026766614988446236,
      "learning_rate": 6.889156626506025e-06,
      "loss": 0.0289,
      "step": 54410
    },
    {
      "epoch": 6.556626506024096,
      "grad_norm": 0.011888626031577587,
      "learning_rate": 6.8867469879518075e-06,
      "loss": 0.0452,
      "step": 54420
    },
    {
      "epoch": 6.557831325301205,
      "grad_norm": 0.2126166969537735,
      "learning_rate": 6.884337349397591e-06,
      "loss": 0.0017,
      "step": 54430
    },
    {
      "epoch": 6.559036144578314,
      "grad_norm": 0.005938676185905933,
      "learning_rate": 6.881927710843374e-06,
      "loss": 0.0472,
      "step": 54440
    },
    {
      "epoch": 6.5602409638554215,
      "grad_norm": 0.019880415871739388,
      "learning_rate": 6.879518072289158e-06,
      "loss": 0.0239,
      "step": 54450
    },
    {
      "epoch": 6.56144578313253,
      "grad_norm": 0.08694535493850708,
      "learning_rate": 6.87710843373494e-06,
      "loss": 0.022,
      "step": 54460
    },
    {
      "epoch": 6.562650602409638,
      "grad_norm": 10.138593673706055,
      "learning_rate": 6.874698795180723e-06,
      "loss": 0.069,
      "step": 54470
    },
    {
      "epoch": 6.563855421686747,
      "grad_norm": 2.816833972930908,
      "learning_rate": 6.872289156626507e-06,
      "loss": 0.0352,
      "step": 54480
    },
    {
      "epoch": 6.565060240963856,
      "grad_norm": 0.20935340225696564,
      "learning_rate": 6.86987951807229e-06,
      "loss": 0.0088,
      "step": 54490
    },
    {
      "epoch": 6.566265060240964,
      "grad_norm": 0.003728436538949609,
      "learning_rate": 6.867469879518073e-06,
      "loss": 0.017,
      "step": 54500
    },
    {
      "epoch": 6.567469879518073,
      "grad_norm": 0.004336334299296141,
      "learning_rate": 6.865060240963855e-06,
      "loss": 0.0012,
      "step": 54510
    },
    {
      "epoch": 6.5686746987951805,
      "grad_norm": 1.7479251623153687,
      "learning_rate": 6.862650602409639e-06,
      "loss": 0.0368,
      "step": 54520
    },
    {
      "epoch": 6.569879518072289,
      "grad_norm": 0.008965237066149712,
      "learning_rate": 6.860240963855422e-06,
      "loss": 0.0341,
      "step": 54530
    },
    {
      "epoch": 6.571084337349397,
      "grad_norm": 0.0050245774909853935,
      "learning_rate": 6.857831325301206e-06,
      "loss": 0.0567,
      "step": 54540
    },
    {
      "epoch": 6.572289156626506,
      "grad_norm": 0.0719008669257164,
      "learning_rate": 6.855421686746988e-06,
      "loss": 0.0267,
      "step": 54550
    },
    {
      "epoch": 6.573493975903615,
      "grad_norm": 0.0055349450558424,
      "learning_rate": 6.853012048192772e-06,
      "loss": 0.0308,
      "step": 54560
    },
    {
      "epoch": 6.574698795180723,
      "grad_norm": 0.47261545062065125,
      "learning_rate": 6.850602409638555e-06,
      "loss": 0.0181,
      "step": 54570
    },
    {
      "epoch": 6.575903614457832,
      "grad_norm": 1.0873794555664062,
      "learning_rate": 6.8481927710843374e-06,
      "loss": 0.0515,
      "step": 54580
    },
    {
      "epoch": 6.5771084337349395,
      "grad_norm": 0.016700919717550278,
      "learning_rate": 6.845783132530121e-06,
      "loss": 0.0219,
      "step": 54590
    },
    {
      "epoch": 6.578313253012048,
      "grad_norm": 0.01867356151342392,
      "learning_rate": 6.843373493975905e-06,
      "loss": 0.0099,
      "step": 54600
    },
    {
      "epoch": 6.579518072289156,
      "grad_norm": 0.34883204102516174,
      "learning_rate": 6.840963855421687e-06,
      "loss": 0.0266,
      "step": 54610
    },
    {
      "epoch": 6.580722891566265,
      "grad_norm": 0.004569443874061108,
      "learning_rate": 6.83855421686747e-06,
      "loss": 0.059,
      "step": 54620
    },
    {
      "epoch": 6.581927710843374,
      "grad_norm": 0.2598242461681366,
      "learning_rate": 6.836144578313254e-06,
      "loss": 0.0047,
      "step": 54630
    },
    {
      "epoch": 6.583132530120482,
      "grad_norm": 2.07651424407959,
      "learning_rate": 6.8337349397590365e-06,
      "loss": 0.0098,
      "step": 54640
    },
    {
      "epoch": 6.5843373493975905,
      "grad_norm": 0.6344901323318481,
      "learning_rate": 6.83132530120482e-06,
      "loss": 0.0041,
      "step": 54650
    },
    {
      "epoch": 6.585542168674698,
      "grad_norm": 0.007507451809942722,
      "learning_rate": 6.828915662650603e-06,
      "loss": 0.0163,
      "step": 54660
    },
    {
      "epoch": 6.586746987951807,
      "grad_norm": 0.006046423222869635,
      "learning_rate": 6.826506024096387e-06,
      "loss": 0.0493,
      "step": 54670
    },
    {
      "epoch": 6.587951807228916,
      "grad_norm": 0.006870595272630453,
      "learning_rate": 6.824096385542169e-06,
      "loss": 0.0423,
      "step": 54680
    },
    {
      "epoch": 6.589156626506024,
      "grad_norm": 0.0191678237169981,
      "learning_rate": 6.821686746987952e-06,
      "loss": 0.0128,
      "step": 54690
    },
    {
      "epoch": 6.590361445783133,
      "grad_norm": 14.873014450073242,
      "learning_rate": 6.819277108433735e-06,
      "loss": 0.0172,
      "step": 54700
    },
    {
      "epoch": 6.591566265060241,
      "grad_norm": 0.08238158375024796,
      "learning_rate": 6.816867469879519e-06,
      "loss": 0.0192,
      "step": 54710
    },
    {
      "epoch": 6.5927710843373495,
      "grad_norm": 1.6883528232574463,
      "learning_rate": 6.814457831325302e-06,
      "loss": 0.0353,
      "step": 54720
    },
    {
      "epoch": 6.593975903614458,
      "grad_norm": 1.8023207187652588,
      "learning_rate": 6.812048192771084e-06,
      "loss": 0.0522,
      "step": 54730
    },
    {
      "epoch": 6.595180722891566,
      "grad_norm": 0.0077690319158136845,
      "learning_rate": 6.809638554216867e-06,
      "loss": 0.0167,
      "step": 54740
    },
    {
      "epoch": 6.596385542168675,
      "grad_norm": 0.019248051568865776,
      "learning_rate": 6.8072289156626514e-06,
      "loss": 0.0295,
      "step": 54750
    },
    {
      "epoch": 6.597590361445783,
      "grad_norm": 0.043564166873693466,
      "learning_rate": 6.804819277108435e-06,
      "loss": 0.02,
      "step": 54760
    },
    {
      "epoch": 6.598795180722892,
      "grad_norm": 0.01159717794507742,
      "learning_rate": 6.802409638554217e-06,
      "loss": 0.0162,
      "step": 54770
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.0956196784973145,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0203,
      "step": 54780
    },
    {
      "epoch": 6.6012048192771084,
      "grad_norm": 0.1991187036037445,
      "learning_rate": 6.797590361445784e-06,
      "loss": 0.0104,
      "step": 54790
    },
    {
      "epoch": 6.602409638554217,
      "grad_norm": 2.5822601318359375,
      "learning_rate": 6.7951807228915665e-06,
      "loss": 0.0545,
      "step": 54800
    },
    {
      "epoch": 6.603614457831325,
      "grad_norm": 0.0092941178008914,
      "learning_rate": 6.79277108433735e-06,
      "loss": 0.0224,
      "step": 54810
    },
    {
      "epoch": 6.604819277108434,
      "grad_norm": 0.007187460549175739,
      "learning_rate": 6.790361445783134e-06,
      "loss": 0.0172,
      "step": 54820
    },
    {
      "epoch": 6.606024096385542,
      "grad_norm": 1.2682667970657349,
      "learning_rate": 6.787951807228916e-06,
      "loss": 0.0097,
      "step": 54830
    },
    {
      "epoch": 6.607228915662651,
      "grad_norm": 0.00234753405675292,
      "learning_rate": 6.785542168674699e-06,
      "loss": 0.0214,
      "step": 54840
    },
    {
      "epoch": 6.608433734939759,
      "grad_norm": 0.007990343496203423,
      "learning_rate": 6.783132530120482e-06,
      "loss": 0.0115,
      "step": 54850
    },
    {
      "epoch": 6.609638554216867,
      "grad_norm": 0.002506555989384651,
      "learning_rate": 6.780722891566266e-06,
      "loss": 0.021,
      "step": 54860
    },
    {
      "epoch": 6.610843373493976,
      "grad_norm": 0.003951976075768471,
      "learning_rate": 6.778313253012049e-06,
      "loss": 0.0226,
      "step": 54870
    },
    {
      "epoch": 6.612048192771084,
      "grad_norm": 0.011049222201108932,
      "learning_rate": 6.775903614457832e-06,
      "loss": 0.0794,
      "step": 54880
    },
    {
      "epoch": 6.613253012048193,
      "grad_norm": 0.19691956043243408,
      "learning_rate": 6.773493975903614e-06,
      "loss": 0.0109,
      "step": 54890
    },
    {
      "epoch": 6.614457831325301,
      "grad_norm": 2.0755233764648438,
      "learning_rate": 6.771084337349398e-06,
      "loss": 0.038,
      "step": 54900
    },
    {
      "epoch": 6.61566265060241,
      "grad_norm": 0.004864571150392294,
      "learning_rate": 6.768674698795181e-06,
      "loss": 0.0261,
      "step": 54910
    },
    {
      "epoch": 6.6168674698795185,
      "grad_norm": 0.00886381883174181,
      "learning_rate": 6.766265060240964e-06,
      "loss": 0.0195,
      "step": 54920
    },
    {
      "epoch": 6.618072289156626,
      "grad_norm": 1.0001330375671387,
      "learning_rate": 6.763855421686748e-06,
      "loss": 0.0551,
      "step": 54930
    },
    {
      "epoch": 6.619277108433735,
      "grad_norm": 0.22197650372982025,
      "learning_rate": 6.761445783132531e-06,
      "loss": 0.0247,
      "step": 54940
    },
    {
      "epoch": 6.620481927710843,
      "grad_norm": 0.011183750815689564,
      "learning_rate": 6.759036144578314e-06,
      "loss": 0.0203,
      "step": 54950
    },
    {
      "epoch": 6.621686746987952,
      "grad_norm": 0.6068817377090454,
      "learning_rate": 6.7566265060240964e-06,
      "loss": 0.0075,
      "step": 54960
    },
    {
      "epoch": 6.622891566265061,
      "grad_norm": 0.005832187831401825,
      "learning_rate": 6.7542168674698805e-06,
      "loss": 0.0051,
      "step": 54970
    },
    {
      "epoch": 6.624096385542169,
      "grad_norm": 0.048864562064409256,
      "learning_rate": 6.751807228915664e-06,
      "loss": 0.0064,
      "step": 54980
    },
    {
      "epoch": 6.625301204819277,
      "grad_norm": 0.014010556042194366,
      "learning_rate": 6.749397590361446e-06,
      "loss": 0.0386,
      "step": 54990
    },
    {
      "epoch": 6.626506024096385,
      "grad_norm": 0.03367742523550987,
      "learning_rate": 6.746987951807229e-06,
      "loss": 0.0189,
      "step": 55000
    },
    {
      "epoch": 6.627710843373494,
      "grad_norm": 0.006063200533390045,
      "learning_rate": 6.744578313253013e-06,
      "loss": 0.0191,
      "step": 55010
    },
    {
      "epoch": 6.628915662650602,
      "grad_norm": 3.0952415466308594,
      "learning_rate": 6.7421686746987955e-06,
      "loss": 0.0353,
      "step": 55020
    },
    {
      "epoch": 6.630120481927711,
      "grad_norm": 0.144844189286232,
      "learning_rate": 6.739759036144579e-06,
      "loss": 0.0157,
      "step": 55030
    },
    {
      "epoch": 6.63132530120482,
      "grad_norm": 0.008532105945050716,
      "learning_rate": 6.737349397590363e-06,
      "loss": 0.0074,
      "step": 55040
    },
    {
      "epoch": 6.632530120481928,
      "grad_norm": 0.03384539857506752,
      "learning_rate": 6.734939759036145e-06,
      "loss": 0.0088,
      "step": 55050
    },
    {
      "epoch": 6.633734939759036,
      "grad_norm": 0.02086755447089672,
      "learning_rate": 6.732530120481928e-06,
      "loss": 0.0288,
      "step": 55060
    },
    {
      "epoch": 6.634939759036144,
      "grad_norm": 0.40070515871047974,
      "learning_rate": 6.730120481927711e-06,
      "loss": 0.0505,
      "step": 55070
    },
    {
      "epoch": 6.636144578313253,
      "grad_norm": 0.003943693824112415,
      "learning_rate": 6.727710843373495e-06,
      "loss": 0.0045,
      "step": 55080
    },
    {
      "epoch": 6.637349397590361,
      "grad_norm": 3.3713483810424805,
      "learning_rate": 6.725301204819278e-06,
      "loss": 0.0422,
      "step": 55090
    },
    {
      "epoch": 6.63855421686747,
      "grad_norm": 0.0019504521042108536,
      "learning_rate": 6.722891566265061e-06,
      "loss": 0.0369,
      "step": 55100
    },
    {
      "epoch": 6.639759036144579,
      "grad_norm": 0.3268693685531616,
      "learning_rate": 6.720481927710843e-06,
      "loss": 0.0238,
      "step": 55110
    },
    {
      "epoch": 6.6409638554216865,
      "grad_norm": 0.1668686866760254,
      "learning_rate": 6.718072289156627e-06,
      "loss": 0.0299,
      "step": 55120
    },
    {
      "epoch": 6.642168674698795,
      "grad_norm": 0.007973006926476955,
      "learning_rate": 6.7156626506024104e-06,
      "loss": 0.0002,
      "step": 55130
    },
    {
      "epoch": 6.643373493975903,
      "grad_norm": 0.004590434953570366,
      "learning_rate": 6.713253012048193e-06,
      "loss": 0.013,
      "step": 55140
    },
    {
      "epoch": 6.644578313253012,
      "grad_norm": 0.04002837836742401,
      "learning_rate": 6.710843373493976e-06,
      "loss": 0.0049,
      "step": 55150
    },
    {
      "epoch": 6.64578313253012,
      "grad_norm": 0.055207520723342896,
      "learning_rate": 6.70843373493976e-06,
      "loss": 0.0077,
      "step": 55160
    },
    {
      "epoch": 6.646987951807229,
      "grad_norm": 0.08844151347875595,
      "learning_rate": 6.706024096385543e-06,
      "loss": 0.0291,
      "step": 55170
    },
    {
      "epoch": 6.648192771084338,
      "grad_norm": 0.9495292901992798,
      "learning_rate": 6.7036144578313255e-06,
      "loss": 0.0076,
      "step": 55180
    },
    {
      "epoch": 6.6493975903614455,
      "grad_norm": 4.525375843048096,
      "learning_rate": 6.7012048192771095e-06,
      "loss": 0.0231,
      "step": 55190
    },
    {
      "epoch": 6.650602409638554,
      "grad_norm": 0.009557375684380531,
      "learning_rate": 6.698795180722893e-06,
      "loss": 0.0145,
      "step": 55200
    },
    {
      "epoch": 6.651807228915663,
      "grad_norm": 0.002610329771414399,
      "learning_rate": 6.696385542168675e-06,
      "loss": 0.0314,
      "step": 55210
    },
    {
      "epoch": 6.653012048192771,
      "grad_norm": 1.375792145729065,
      "learning_rate": 6.693975903614458e-06,
      "loss": 0.0236,
      "step": 55220
    },
    {
      "epoch": 6.65421686746988,
      "grad_norm": 0.13816896080970764,
      "learning_rate": 6.691566265060242e-06,
      "loss": 0.0234,
      "step": 55230
    },
    {
      "epoch": 6.655421686746988,
      "grad_norm": 0.004377508535981178,
      "learning_rate": 6.6891566265060245e-06,
      "loss": 0.0108,
      "step": 55240
    },
    {
      "epoch": 6.656626506024097,
      "grad_norm": 0.34817034006118774,
      "learning_rate": 6.686746987951808e-06,
      "loss": 0.0098,
      "step": 55250
    },
    {
      "epoch": 6.6578313253012045,
      "grad_norm": 0.015118898823857307,
      "learning_rate": 6.684337349397591e-06,
      "loss": 0.0457,
      "step": 55260
    },
    {
      "epoch": 6.659036144578313,
      "grad_norm": 0.41276973485946655,
      "learning_rate": 6.681927710843374e-06,
      "loss": 0.0322,
      "step": 55270
    },
    {
      "epoch": 6.660240963855422,
      "grad_norm": 1.0163679122924805,
      "learning_rate": 6.679518072289157e-06,
      "loss": 0.0483,
      "step": 55280
    },
    {
      "epoch": 6.66144578313253,
      "grad_norm": 5.838742256164551,
      "learning_rate": 6.67710843373494e-06,
      "loss": 0.011,
      "step": 55290
    },
    {
      "epoch": 6.662650602409639,
      "grad_norm": 0.0033060950227081776,
      "learning_rate": 6.674698795180723e-06,
      "loss": 0.0039,
      "step": 55300
    },
    {
      "epoch": 6.663855421686747,
      "grad_norm": 9.756660461425781,
      "learning_rate": 6.672289156626507e-06,
      "loss": 0.0529,
      "step": 55310
    },
    {
      "epoch": 6.6650602409638555,
      "grad_norm": 0.17612099647521973,
      "learning_rate": 6.66987951807229e-06,
      "loss": 0.02,
      "step": 55320
    },
    {
      "epoch": 6.666265060240963,
      "grad_norm": 0.23617221415042877,
      "learning_rate": 6.667469879518072e-06,
      "loss": 0.0513,
      "step": 55330
    },
    {
      "epoch": 6.667469879518072,
      "grad_norm": 1.4292974472045898,
      "learning_rate": 6.665060240963856e-06,
      "loss": 0.0168,
      "step": 55340
    },
    {
      "epoch": 6.668674698795181,
      "grad_norm": 0.032633863389492035,
      "learning_rate": 6.6626506024096395e-06,
      "loss": 0.0245,
      "step": 55350
    },
    {
      "epoch": 6.669879518072289,
      "grad_norm": 0.047960568219423294,
      "learning_rate": 6.660240963855422e-06,
      "loss": 0.0097,
      "step": 55360
    },
    {
      "epoch": 6.671084337349398,
      "grad_norm": 0.0022830485831946135,
      "learning_rate": 6.657831325301205e-06,
      "loss": 0.0667,
      "step": 55370
    },
    {
      "epoch": 6.672289156626506,
      "grad_norm": 0.9258292317390442,
      "learning_rate": 6.655421686746989e-06,
      "loss": 0.009,
      "step": 55380
    },
    {
      "epoch": 6.6734939759036145,
      "grad_norm": 0.002814304316416383,
      "learning_rate": 6.653012048192772e-06,
      "loss": 0.0533,
      "step": 55390
    },
    {
      "epoch": 6.674698795180722,
      "grad_norm": 0.0021292672026902437,
      "learning_rate": 6.6506024096385545e-06,
      "loss": 0.0443,
      "step": 55400
    },
    {
      "epoch": 6.675903614457831,
      "grad_norm": 0.05280733481049538,
      "learning_rate": 6.648192771084338e-06,
      "loss": 0.0377,
      "step": 55410
    },
    {
      "epoch": 6.67710843373494,
      "grad_norm": 0.011612983420491219,
      "learning_rate": 6.645783132530122e-06,
      "loss": 0.0326,
      "step": 55420
    },
    {
      "epoch": 6.678313253012048,
      "grad_norm": 0.06529397517442703,
      "learning_rate": 6.643373493975904e-06,
      "loss": 0.0121,
      "step": 55430
    },
    {
      "epoch": 6.679518072289157,
      "grad_norm": 0.2878235876560211,
      "learning_rate": 6.640963855421687e-06,
      "loss": 0.0132,
      "step": 55440
    },
    {
      "epoch": 6.6807228915662655,
      "grad_norm": 0.5870286822319031,
      "learning_rate": 6.6385542168674695e-06,
      "loss": 0.0207,
      "step": 55450
    },
    {
      "epoch": 6.6819277108433734,
      "grad_norm": 2.1308770179748535,
      "learning_rate": 6.6361445783132535e-06,
      "loss": 0.0316,
      "step": 55460
    },
    {
      "epoch": 6.683132530120482,
      "grad_norm": 0.004688952583819628,
      "learning_rate": 6.633734939759037e-06,
      "loss": 0.0157,
      "step": 55470
    },
    {
      "epoch": 6.68433734939759,
      "grad_norm": 0.0027599665336310863,
      "learning_rate": 6.63132530120482e-06,
      "loss": 0.0157,
      "step": 55480
    },
    {
      "epoch": 6.685542168674699,
      "grad_norm": 1.3744220733642578,
      "learning_rate": 6.628915662650603e-06,
      "loss": 0.0196,
      "step": 55490
    },
    {
      "epoch": 6.686746987951807,
      "grad_norm": 0.0033721879590302706,
      "learning_rate": 6.626506024096386e-06,
      "loss": 0.0238,
      "step": 55500
    },
    {
      "epoch": 6.687951807228916,
      "grad_norm": 4.132802963256836,
      "learning_rate": 6.6240963855421694e-06,
      "loss": 0.0434,
      "step": 55510
    },
    {
      "epoch": 6.6891566265060245,
      "grad_norm": 0.0030552276875823736,
      "learning_rate": 6.621686746987952e-06,
      "loss": 0.0217,
      "step": 55520
    },
    {
      "epoch": 6.690361445783132,
      "grad_norm": 4.123324871063232,
      "learning_rate": 6.619277108433736e-06,
      "loss": 0.0273,
      "step": 55530
    },
    {
      "epoch": 6.691566265060241,
      "grad_norm": 0.029423534870147705,
      "learning_rate": 6.616867469879519e-06,
      "loss": 0.0525,
      "step": 55540
    },
    {
      "epoch": 6.692771084337349,
      "grad_norm": 0.009120466187596321,
      "learning_rate": 6.614457831325301e-06,
      "loss": 0.029,
      "step": 55550
    },
    {
      "epoch": 6.693975903614458,
      "grad_norm": 0.348590224981308,
      "learning_rate": 6.6120481927710845e-06,
      "loss": 0.0077,
      "step": 55560
    },
    {
      "epoch": 6.695180722891566,
      "grad_norm": 3.1442863941192627,
      "learning_rate": 6.6096385542168685e-06,
      "loss": 0.075,
      "step": 55570
    },
    {
      "epoch": 6.696385542168675,
      "grad_norm": 0.4727703928947449,
      "learning_rate": 6.607228915662652e-06,
      "loss": 0.0188,
      "step": 55580
    },
    {
      "epoch": 6.6975903614457835,
      "grad_norm": 0.005463719367980957,
      "learning_rate": 6.604819277108434e-06,
      "loss": 0.0371,
      "step": 55590
    },
    {
      "epoch": 6.698795180722891,
      "grad_norm": 1.1552060842514038,
      "learning_rate": 6.602409638554217e-06,
      "loss": 0.0221,
      "step": 55600
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.01234615221619606,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.0108,
      "step": 55610
    },
    {
      "epoch": 6.701204819277108,
      "grad_norm": 3.451948881149292,
      "learning_rate": 6.5975903614457835e-06,
      "loss": 0.0087,
      "step": 55620
    },
    {
      "epoch": 6.702409638554217,
      "grad_norm": 0.15798832476139069,
      "learning_rate": 6.595180722891567e-06,
      "loss": 0.014,
      "step": 55630
    },
    {
      "epoch": 6.703614457831325,
      "grad_norm": 8.469499588012695,
      "learning_rate": 6.592771084337351e-06,
      "loss": 0.0395,
      "step": 55640
    },
    {
      "epoch": 6.704819277108434,
      "grad_norm": 0.7960748076438904,
      "learning_rate": 6.590361445783133e-06,
      "loss": 0.0075,
      "step": 55650
    },
    {
      "epoch": 6.706024096385542,
      "grad_norm": 0.0017165456665679812,
      "learning_rate": 6.587951807228916e-06,
      "loss": 0.0856,
      "step": 55660
    },
    {
      "epoch": 6.70722891566265,
      "grad_norm": 0.015975406393408775,
      "learning_rate": 6.585542168674699e-06,
      "loss": 0.041,
      "step": 55670
    },
    {
      "epoch": 6.708433734939759,
      "grad_norm": 0.024066586047410965,
      "learning_rate": 6.5831325301204826e-06,
      "loss": 0.028,
      "step": 55680
    },
    {
      "epoch": 6.709638554216868,
      "grad_norm": 0.06526350229978561,
      "learning_rate": 6.580722891566266e-06,
      "loss": 0.0186,
      "step": 55690
    },
    {
      "epoch": 6.710843373493976,
      "grad_norm": 0.14466917514801025,
      "learning_rate": 6.578313253012049e-06,
      "loss": 0.0342,
      "step": 55700
    },
    {
      "epoch": 6.712048192771085,
      "grad_norm": 0.00915932934731245,
      "learning_rate": 6.575903614457831e-06,
      "loss": 0.0325,
      "step": 55710
    },
    {
      "epoch": 6.713253012048193,
      "grad_norm": 0.014794357120990753,
      "learning_rate": 6.573493975903615e-06,
      "loss": 0.0165,
      "step": 55720
    },
    {
      "epoch": 6.714457831325301,
      "grad_norm": 0.10144513100385666,
      "learning_rate": 6.5710843373493984e-06,
      "loss": 0.0056,
      "step": 55730
    },
    {
      "epoch": 6.715662650602409,
      "grad_norm": 2.8806347846984863,
      "learning_rate": 6.568674698795181e-06,
      "loss": 0.0351,
      "step": 55740
    },
    {
      "epoch": 6.716867469879518,
      "grad_norm": 1.5586795806884766,
      "learning_rate": 6.566265060240964e-06,
      "loss": 0.0575,
      "step": 55750
    },
    {
      "epoch": 6.718072289156627,
      "grad_norm": 0.04341564327478409,
      "learning_rate": 6.563855421686748e-06,
      "loss": 0.0158,
      "step": 55760
    },
    {
      "epoch": 6.719277108433735,
      "grad_norm": 0.02837105095386505,
      "learning_rate": 6.56144578313253e-06,
      "loss": 0.0004,
      "step": 55770
    },
    {
      "epoch": 6.720481927710844,
      "grad_norm": 0.009152136743068695,
      "learning_rate": 6.5590361445783135e-06,
      "loss": 0.0127,
      "step": 55780
    },
    {
      "epoch": 6.7216867469879515,
      "grad_norm": 0.014728936366736889,
      "learning_rate": 6.5566265060240975e-06,
      "loss": 0.0462,
      "step": 55790
    },
    {
      "epoch": 6.72289156626506,
      "grad_norm": 0.005471802782267332,
      "learning_rate": 6.554216867469881e-06,
      "loss": 0.045,
      "step": 55800
    },
    {
      "epoch": 6.724096385542168,
      "grad_norm": 0.006142930593341589,
      "learning_rate": 6.551807228915663e-06,
      "loss": 0.0048,
      "step": 55810
    },
    {
      "epoch": 6.725301204819277,
      "grad_norm": 0.003210614435374737,
      "learning_rate": 6.549397590361446e-06,
      "loss": 0.0245,
      "step": 55820
    },
    {
      "epoch": 6.726506024096386,
      "grad_norm": 0.7789115905761719,
      "learning_rate": 6.54698795180723e-06,
      "loss": 0.0062,
      "step": 55830
    },
    {
      "epoch": 6.727710843373494,
      "grad_norm": 2.090055465698242,
      "learning_rate": 6.5445783132530125e-06,
      "loss": 0.011,
      "step": 55840
    },
    {
      "epoch": 6.728915662650603,
      "grad_norm": 0.28769972920417786,
      "learning_rate": 6.542168674698796e-06,
      "loss": 0.0265,
      "step": 55850
    },
    {
      "epoch": 6.7301204819277105,
      "grad_norm": 0.0792698785662651,
      "learning_rate": 6.539759036144578e-06,
      "loss": 0.0114,
      "step": 55860
    },
    {
      "epoch": 6.731325301204819,
      "grad_norm": 3.6582534313201904,
      "learning_rate": 6.537349397590362e-06,
      "loss": 0.0335,
      "step": 55870
    },
    {
      "epoch": 6.732530120481927,
      "grad_norm": 1.158522129058838,
      "learning_rate": 6.534939759036145e-06,
      "loss": 0.0051,
      "step": 55880
    },
    {
      "epoch": 6.733734939759036,
      "grad_norm": 0.3583807647228241,
      "learning_rate": 6.532530120481928e-06,
      "loss": 0.0042,
      "step": 55890
    },
    {
      "epoch": 6.734939759036145,
      "grad_norm": 0.004298610612750053,
      "learning_rate": 6.530120481927711e-06,
      "loss": 0.0117,
      "step": 55900
    },
    {
      "epoch": 6.736144578313253,
      "grad_norm": 0.5131872892379761,
      "learning_rate": 6.527710843373495e-06,
      "loss": 0.0442,
      "step": 55910
    },
    {
      "epoch": 6.7373493975903616,
      "grad_norm": 0.16415584087371826,
      "learning_rate": 6.525301204819278e-06,
      "loss": 0.012,
      "step": 55920
    },
    {
      "epoch": 6.73855421686747,
      "grad_norm": 0.024894598871469498,
      "learning_rate": 6.52289156626506e-06,
      "loss": 0.0129,
      "step": 55930
    },
    {
      "epoch": 6.739759036144578,
      "grad_norm": 0.00927465409040451,
      "learning_rate": 6.520481927710844e-06,
      "loss": 0.0383,
      "step": 55940
    },
    {
      "epoch": 6.740963855421687,
      "grad_norm": 2.9308133125305176,
      "learning_rate": 6.5180722891566275e-06,
      "loss": 0.0693,
      "step": 55950
    },
    {
      "epoch": 6.742168674698795,
      "grad_norm": 0.006843362934887409,
      "learning_rate": 6.51566265060241e-06,
      "loss": 0.0019,
      "step": 55960
    },
    {
      "epoch": 6.743373493975904,
      "grad_norm": 0.0036263924557715654,
      "learning_rate": 6.513253012048193e-06,
      "loss": 0.0025,
      "step": 55970
    },
    {
      "epoch": 6.744578313253012,
      "grad_norm": 1.511616587638855,
      "learning_rate": 6.510843373493977e-06,
      "loss": 0.041,
      "step": 55980
    },
    {
      "epoch": 6.7457831325301205,
      "grad_norm": 2.9949543476104736,
      "learning_rate": 6.508433734939759e-06,
      "loss": 0.1065,
      "step": 55990
    },
    {
      "epoch": 6.746987951807229,
      "grad_norm": 0.16018632054328918,
      "learning_rate": 6.5060240963855425e-06,
      "loss": 0.0312,
      "step": 56000
    },
    {
      "epoch": 6.748192771084337,
      "grad_norm": 0.00829034298658371,
      "learning_rate": 6.503614457831326e-06,
      "loss": 0.0425,
      "step": 56010
    },
    {
      "epoch": 6.749397590361446,
      "grad_norm": 0.07020832598209381,
      "learning_rate": 6.50120481927711e-06,
      "loss": 0.0396,
      "step": 56020
    },
    {
      "epoch": 6.750602409638554,
      "grad_norm": 0.12613172829151154,
      "learning_rate": 6.498795180722892e-06,
      "loss": 0.022,
      "step": 56030
    },
    {
      "epoch": 6.751807228915663,
      "grad_norm": 2.192467212677002,
      "learning_rate": 6.496385542168675e-06,
      "loss": 0.0211,
      "step": 56040
    },
    {
      "epoch": 6.753012048192771,
      "grad_norm": 0.09797084331512451,
      "learning_rate": 6.4939759036144575e-06,
      "loss": 0.021,
      "step": 56050
    },
    {
      "epoch": 6.7542168674698795,
      "grad_norm": 0.07232793420553207,
      "learning_rate": 6.4915662650602416e-06,
      "loss": 0.0344,
      "step": 56060
    },
    {
      "epoch": 6.755421686746988,
      "grad_norm": 0.013151197694242,
      "learning_rate": 6.489156626506025e-06,
      "loss": 0.0298,
      "step": 56070
    },
    {
      "epoch": 6.756626506024096,
      "grad_norm": 1.9645105600357056,
      "learning_rate": 6.486746987951807e-06,
      "loss": 0.0273,
      "step": 56080
    },
    {
      "epoch": 6.757831325301205,
      "grad_norm": 0.3457697927951813,
      "learning_rate": 6.484337349397591e-06,
      "loss": 0.0279,
      "step": 56090
    },
    {
      "epoch": 6.759036144578313,
      "grad_norm": 0.6161938905715942,
      "learning_rate": 6.481927710843374e-06,
      "loss": 0.0159,
      "step": 56100
    },
    {
      "epoch": 6.760240963855422,
      "grad_norm": 17.177316665649414,
      "learning_rate": 6.4795180722891574e-06,
      "loss": 0.0213,
      "step": 56110
    },
    {
      "epoch": 6.76144578313253,
      "grad_norm": 1.362802505493164,
      "learning_rate": 6.47710843373494e-06,
      "loss": 0.0344,
      "step": 56120
    },
    {
      "epoch": 6.7626506024096384,
      "grad_norm": 0.0055924067273736,
      "learning_rate": 6.474698795180724e-06,
      "loss": 0.0117,
      "step": 56130
    },
    {
      "epoch": 6.763855421686747,
      "grad_norm": 0.0056841326877474785,
      "learning_rate": 6.472289156626507e-06,
      "loss": 0.0363,
      "step": 56140
    },
    {
      "epoch": 6.765060240963855,
      "grad_norm": 0.005890554282814264,
      "learning_rate": 6.469879518072289e-06,
      "loss": 0.0103,
      "step": 56150
    },
    {
      "epoch": 6.766265060240964,
      "grad_norm": 0.046858374029397964,
      "learning_rate": 6.4674698795180725e-06,
      "loss": 0.0416,
      "step": 56160
    },
    {
      "epoch": 6.767469879518073,
      "grad_norm": 0.0016447423258796334,
      "learning_rate": 6.4650602409638565e-06,
      "loss": 0.0244,
      "step": 56170
    },
    {
      "epoch": 6.768674698795181,
      "grad_norm": 4.463921546936035,
      "learning_rate": 6.462650602409639e-06,
      "loss": 0.0612,
      "step": 56180
    },
    {
      "epoch": 6.7698795180722895,
      "grad_norm": 0.12996481359004974,
      "learning_rate": 6.460240963855422e-06,
      "loss": 0.0254,
      "step": 56190
    },
    {
      "epoch": 6.771084337349397,
      "grad_norm": 0.0020057172514498234,
      "learning_rate": 6.457831325301205e-06,
      "loss": 0.0417,
      "step": 56200
    },
    {
      "epoch": 6.772289156626506,
      "grad_norm": 0.9288244843482971,
      "learning_rate": 6.455421686746988e-06,
      "loss": 0.0183,
      "step": 56210
    },
    {
      "epoch": 6.773493975903614,
      "grad_norm": 0.7137022018432617,
      "learning_rate": 6.4530120481927715e-06,
      "loss": 0.0354,
      "step": 56220
    },
    {
      "epoch": 6.774698795180723,
      "grad_norm": 0.00667216582223773,
      "learning_rate": 6.450602409638555e-06,
      "loss": 0.0393,
      "step": 56230
    },
    {
      "epoch": 6.775903614457832,
      "grad_norm": 1.8893656730651855,
      "learning_rate": 6.448192771084339e-06,
      "loss": 0.0524,
      "step": 56240
    },
    {
      "epoch": 6.77710843373494,
      "grad_norm": 4.7189764976501465,
      "learning_rate": 6.445783132530121e-06,
      "loss": 0.0142,
      "step": 56250
    },
    {
      "epoch": 6.7783132530120485,
      "grad_norm": 0.038469742983579636,
      "learning_rate": 6.443373493975904e-06,
      "loss": 0.0121,
      "step": 56260
    },
    {
      "epoch": 6.779518072289156,
      "grad_norm": 0.00317828799597919,
      "learning_rate": 6.4409638554216866e-06,
      "loss": 0.0103,
      "step": 56270
    },
    {
      "epoch": 6.780722891566265,
      "grad_norm": 1.349455714225769,
      "learning_rate": 6.438554216867471e-06,
      "loss": 0.005,
      "step": 56280
    },
    {
      "epoch": 6.781927710843373,
      "grad_norm": 0.0067939781583845615,
      "learning_rate": 6.436144578313254e-06,
      "loss": 0.0316,
      "step": 56290
    },
    {
      "epoch": 6.783132530120482,
      "grad_norm": 0.28601035475730896,
      "learning_rate": 6.433734939759036e-06,
      "loss": 0.0013,
      "step": 56300
    },
    {
      "epoch": 6.784337349397591,
      "grad_norm": 0.6557908654212952,
      "learning_rate": 6.431325301204819e-06,
      "loss": 0.034,
      "step": 56310
    },
    {
      "epoch": 6.785542168674699,
      "grad_norm": 0.6087279319763184,
      "learning_rate": 6.428915662650603e-06,
      "loss": 0.0504,
      "step": 56320
    },
    {
      "epoch": 6.786746987951807,
      "grad_norm": 1.98226797580719,
      "learning_rate": 6.4265060240963865e-06,
      "loss": 0.0157,
      "step": 56330
    },
    {
      "epoch": 6.787951807228915,
      "grad_norm": 0.7737102508544922,
      "learning_rate": 6.424096385542169e-06,
      "loss": 0.0374,
      "step": 56340
    },
    {
      "epoch": 6.789156626506024,
      "grad_norm": 0.023632202297449112,
      "learning_rate": 6.421686746987952e-06,
      "loss": 0.0054,
      "step": 56350
    },
    {
      "epoch": 6.790361445783132,
      "grad_norm": 0.6539363861083984,
      "learning_rate": 6.419277108433736e-06,
      "loss": 0.024,
      "step": 56360
    },
    {
      "epoch": 6.791566265060241,
      "grad_norm": 0.019172165542840958,
      "learning_rate": 6.416867469879518e-06,
      "loss": 0.0449,
      "step": 56370
    },
    {
      "epoch": 6.79277108433735,
      "grad_norm": 0.014431154355406761,
      "learning_rate": 6.4144578313253015e-06,
      "loss": 0.0288,
      "step": 56380
    },
    {
      "epoch": 6.793975903614458,
      "grad_norm": 1.9933806657791138,
      "learning_rate": 6.4120481927710855e-06,
      "loss": 0.0526,
      "step": 56390
    },
    {
      "epoch": 6.795180722891566,
      "grad_norm": 1.0162062644958496,
      "learning_rate": 6.409638554216868e-06,
      "loss": 0.0091,
      "step": 56400
    },
    {
      "epoch": 6.796385542168675,
      "grad_norm": 0.03250854089856148,
      "learning_rate": 6.407228915662651e-06,
      "loss": 0.0274,
      "step": 56410
    },
    {
      "epoch": 6.797590361445783,
      "grad_norm": 0.029007837176322937,
      "learning_rate": 6.404819277108434e-06,
      "loss": 0.0162,
      "step": 56420
    },
    {
      "epoch": 6.798795180722892,
      "grad_norm": 0.014440493658185005,
      "learning_rate": 6.402409638554218e-06,
      "loss": 0.0344,
      "step": 56430
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.008817696012556553,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0066,
      "step": 56440
    },
    {
      "epoch": 6.801204819277109,
      "grad_norm": 0.1311149001121521,
      "learning_rate": 6.397590361445784e-06,
      "loss": 0.0203,
      "step": 56450
    },
    {
      "epoch": 6.8024096385542165,
      "grad_norm": 0.2836713194847107,
      "learning_rate": 6.395180722891566e-06,
      "loss": 0.0107,
      "step": 56460
    },
    {
      "epoch": 6.803614457831325,
      "grad_norm": 0.00704434048384428,
      "learning_rate": 6.39277108433735e-06,
      "loss": 0.0171,
      "step": 56470
    },
    {
      "epoch": 6.804819277108434,
      "grad_norm": 0.22402545809745789,
      "learning_rate": 6.390361445783133e-06,
      "loss": 0.0235,
      "step": 56480
    },
    {
      "epoch": 6.806024096385542,
      "grad_norm": 0.025536971166729927,
      "learning_rate": 6.387951807228916e-06,
      "loss": 0.0336,
      "step": 56490
    },
    {
      "epoch": 6.807228915662651,
      "grad_norm": 2.5007529258728027,
      "learning_rate": 6.385542168674699e-06,
      "loss": 0.0595,
      "step": 56500
    },
    {
      "epoch": 6.808433734939759,
      "grad_norm": 2.158972978591919,
      "learning_rate": 6.383132530120483e-06,
      "loss": 0.0381,
      "step": 56510
    },
    {
      "epoch": 6.809638554216868,
      "grad_norm": 1.3423147201538086,
      "learning_rate": 6.380722891566266e-06,
      "loss": 0.0187,
      "step": 56520
    },
    {
      "epoch": 6.8108433734939755,
      "grad_norm": 0.3678305149078369,
      "learning_rate": 6.378313253012048e-06,
      "loss": 0.0086,
      "step": 56530
    },
    {
      "epoch": 6.812048192771084,
      "grad_norm": 0.019549164921045303,
      "learning_rate": 6.375903614457832e-06,
      "loss": 0.0245,
      "step": 56540
    },
    {
      "epoch": 6.813253012048193,
      "grad_norm": 0.02270716242492199,
      "learning_rate": 6.3734939759036155e-06,
      "loss": 0.0042,
      "step": 56550
    },
    {
      "epoch": 6.814457831325301,
      "grad_norm": 1.64907705783844,
      "learning_rate": 6.371084337349398e-06,
      "loss": 0.0093,
      "step": 56560
    },
    {
      "epoch": 6.81566265060241,
      "grad_norm": 0.028960613533854485,
      "learning_rate": 6.368674698795181e-06,
      "loss": 0.0369,
      "step": 56570
    },
    {
      "epoch": 6.816867469879518,
      "grad_norm": 0.009766307659447193,
      "learning_rate": 6.366265060240965e-06,
      "loss": 0.022,
      "step": 56580
    },
    {
      "epoch": 6.8180722891566266,
      "grad_norm": 0.49942469596862793,
      "learning_rate": 6.363855421686747e-06,
      "loss": 0.0163,
      "step": 56590
    },
    {
      "epoch": 6.8192771084337345,
      "grad_norm": 3.9667670726776123,
      "learning_rate": 6.3614457831325305e-06,
      "loss": 0.0229,
      "step": 56600
    },
    {
      "epoch": 6.820481927710843,
      "grad_norm": 0.0076888492330908775,
      "learning_rate": 6.359036144578314e-06,
      "loss": 0.007,
      "step": 56610
    },
    {
      "epoch": 6.821686746987952,
      "grad_norm": 0.03995082527399063,
      "learning_rate": 6.356626506024097e-06,
      "loss": 0.0195,
      "step": 56620
    },
    {
      "epoch": 6.82289156626506,
      "grad_norm": 1.407099962234497,
      "learning_rate": 6.35421686746988e-06,
      "loss": 0.0181,
      "step": 56630
    },
    {
      "epoch": 6.824096385542169,
      "grad_norm": 0.01001656986773014,
      "learning_rate": 6.351807228915663e-06,
      "loss": 0.018,
      "step": 56640
    },
    {
      "epoch": 6.825301204819278,
      "grad_norm": 0.008420281112194061,
      "learning_rate": 6.3493975903614456e-06,
      "loss": 0.0198,
      "step": 56650
    },
    {
      "epoch": 6.8265060240963855,
      "grad_norm": 0.3464699685573578,
      "learning_rate": 6.34698795180723e-06,
      "loss": 0.046,
      "step": 56660
    },
    {
      "epoch": 6.827710843373494,
      "grad_norm": 0.009367764927446842,
      "learning_rate": 6.344578313253013e-06,
      "loss": 0.0347,
      "step": 56670
    },
    {
      "epoch": 6.828915662650602,
      "grad_norm": 0.25071385502815247,
      "learning_rate": 6.342168674698795e-06,
      "loss": 0.0252,
      "step": 56680
    },
    {
      "epoch": 6.830120481927711,
      "grad_norm": 0.07832389324903488,
      "learning_rate": 6.339759036144579e-06,
      "loss": 0.0187,
      "step": 56690
    },
    {
      "epoch": 6.831325301204819,
      "grad_norm": 0.0032862478401511908,
      "learning_rate": 6.337349397590362e-06,
      "loss": 0.0072,
      "step": 56700
    },
    {
      "epoch": 6.832530120481928,
      "grad_norm": 0.5674276351928711,
      "learning_rate": 6.334939759036145e-06,
      "loss": 0.0171,
      "step": 56710
    },
    {
      "epoch": 6.833734939759037,
      "grad_norm": 0.3322296738624573,
      "learning_rate": 6.332530120481928e-06,
      "loss": 0.0167,
      "step": 56720
    },
    {
      "epoch": 6.8349397590361445,
      "grad_norm": 0.2382100373506546,
      "learning_rate": 6.330120481927712e-06,
      "loss": 0.0102,
      "step": 56730
    },
    {
      "epoch": 6.836144578313253,
      "grad_norm": 1.9403210878372192,
      "learning_rate": 6.327710843373495e-06,
      "loss": 0.0371,
      "step": 56740
    },
    {
      "epoch": 6.837349397590361,
      "grad_norm": 0.047756776213645935,
      "learning_rate": 6.325301204819277e-06,
      "loss": 0.0294,
      "step": 56750
    },
    {
      "epoch": 6.83855421686747,
      "grad_norm": 0.013221567496657372,
      "learning_rate": 6.3228915662650605e-06,
      "loss": 0.0234,
      "step": 56760
    },
    {
      "epoch": 6.839759036144578,
      "grad_norm": 2.672477960586548,
      "learning_rate": 6.3204819277108445e-06,
      "loss": 0.0247,
      "step": 56770
    },
    {
      "epoch": 6.840963855421687,
      "grad_norm": 0.008424299769103527,
      "learning_rate": 6.318072289156627e-06,
      "loss": 0.0577,
      "step": 56780
    },
    {
      "epoch": 6.8421686746987955,
      "grad_norm": 0.4738183319568634,
      "learning_rate": 6.31566265060241e-06,
      "loss": 0.0176,
      "step": 56790
    },
    {
      "epoch": 6.843373493975903,
      "grad_norm": 0.858217179775238,
      "learning_rate": 6.313253012048192e-06,
      "loss": 0.0213,
      "step": 56800
    },
    {
      "epoch": 6.844578313253012,
      "grad_norm": 8.457275390625,
      "learning_rate": 6.310843373493976e-06,
      "loss": 0.0145,
      "step": 56810
    },
    {
      "epoch": 6.84578313253012,
      "grad_norm": 0.0026434939354658127,
      "learning_rate": 6.3084337349397596e-06,
      "loss": 0.0707,
      "step": 56820
    },
    {
      "epoch": 6.846987951807229,
      "grad_norm": 1.9881576299667358,
      "learning_rate": 6.306024096385543e-06,
      "loss": 0.0503,
      "step": 56830
    },
    {
      "epoch": 6.848192771084337,
      "grad_norm": 0.022286279127001762,
      "learning_rate": 6.303614457831326e-06,
      "loss": 0.0305,
      "step": 56840
    },
    {
      "epoch": 6.849397590361446,
      "grad_norm": 1.189862847328186,
      "learning_rate": 6.301204819277109e-06,
      "loss": 0.0158,
      "step": 56850
    },
    {
      "epoch": 6.8506024096385545,
      "grad_norm": 0.05576062947511673,
      "learning_rate": 6.298795180722892e-06,
      "loss": 0.0485,
      "step": 56860
    },
    {
      "epoch": 6.851807228915662,
      "grad_norm": 1.7506800889968872,
      "learning_rate": 6.296385542168675e-06,
      "loss": 0.0163,
      "step": 56870
    },
    {
      "epoch": 6.853012048192771,
      "grad_norm": 0.01263097207993269,
      "learning_rate": 6.293975903614459e-06,
      "loss": 0.0285,
      "step": 56880
    },
    {
      "epoch": 6.85421686746988,
      "grad_norm": 0.4921792447566986,
      "learning_rate": 6.291566265060242e-06,
      "loss": 0.0336,
      "step": 56890
    },
    {
      "epoch": 6.855421686746988,
      "grad_norm": 0.003010710934177041,
      "learning_rate": 6.289156626506024e-06,
      "loss": 0.0586,
      "step": 56900
    },
    {
      "epoch": 6.856626506024097,
      "grad_norm": 0.3272058367729187,
      "learning_rate": 6.286746987951807e-06,
      "loss": 0.0145,
      "step": 56910
    },
    {
      "epoch": 6.857831325301205,
      "grad_norm": 0.0036806154530495405,
      "learning_rate": 6.284337349397591e-06,
      "loss": 0.0246,
      "step": 56920
    },
    {
      "epoch": 6.8590361445783135,
      "grad_norm": 0.0183184165507555,
      "learning_rate": 6.281927710843374e-06,
      "loss": 0.0185,
      "step": 56930
    },
    {
      "epoch": 6.860240963855421,
      "grad_norm": 0.006125185173004866,
      "learning_rate": 6.279518072289157e-06,
      "loss": 0.029,
      "step": 56940
    },
    {
      "epoch": 6.86144578313253,
      "grad_norm": 0.24295522272586823,
      "learning_rate": 6.27710843373494e-06,
      "loss": 0.0345,
      "step": 56950
    },
    {
      "epoch": 6.862650602409639,
      "grad_norm": 0.006890999618917704,
      "learning_rate": 6.274698795180724e-06,
      "loss": 0.0231,
      "step": 56960
    },
    {
      "epoch": 6.863855421686747,
      "grad_norm": 1.626790165901184,
      "learning_rate": 6.272289156626506e-06,
      "loss": 0.021,
      "step": 56970
    },
    {
      "epoch": 6.865060240963856,
      "grad_norm": 0.0083079282194376,
      "learning_rate": 6.2698795180722895e-06,
      "loss": 0.0019,
      "step": 56980
    },
    {
      "epoch": 6.866265060240964,
      "grad_norm": 0.12067124992609024,
      "learning_rate": 6.2674698795180735e-06,
      "loss": 0.0214,
      "step": 56990
    },
    {
      "epoch": 6.867469879518072,
      "grad_norm": 0.08522855490446091,
      "learning_rate": 6.265060240963856e-06,
      "loss": 0.0177,
      "step": 57000
    },
    {
      "epoch": 6.86867469879518,
      "grad_norm": 0.01768898032605648,
      "learning_rate": 6.262650602409639e-06,
      "loss": 0.012,
      "step": 57010
    },
    {
      "epoch": 6.869879518072289,
      "grad_norm": 0.026084963232278824,
      "learning_rate": 6.260240963855421e-06,
      "loss": 0.0147,
      "step": 57020
    },
    {
      "epoch": 6.871084337349398,
      "grad_norm": 0.04250437393784523,
      "learning_rate": 6.257831325301205e-06,
      "loss": 0.0076,
      "step": 57030
    },
    {
      "epoch": 6.872289156626506,
      "grad_norm": 0.6790842413902283,
      "learning_rate": 6.255421686746989e-06,
      "loss": 0.0078,
      "step": 57040
    },
    {
      "epoch": 6.873493975903615,
      "grad_norm": 0.048766642808914185,
      "learning_rate": 6.253012048192772e-06,
      "loss": 0.0323,
      "step": 57050
    },
    {
      "epoch": 6.874698795180723,
      "grad_norm": 0.010997956618666649,
      "learning_rate": 6.250602409638554e-06,
      "loss": 0.0213,
      "step": 57060
    },
    {
      "epoch": 6.875903614457831,
      "grad_norm": 0.0035648795310407877,
      "learning_rate": 6.248192771084338e-06,
      "loss": 0.0305,
      "step": 57070
    },
    {
      "epoch": 6.877108433734939,
      "grad_norm": 2.28495192527771,
      "learning_rate": 6.245783132530121e-06,
      "loss": 0.0075,
      "step": 57080
    },
    {
      "epoch": 6.878313253012048,
      "grad_norm": 0.0052558728493750095,
      "learning_rate": 6.243373493975904e-06,
      "loss": 0.0107,
      "step": 57090
    },
    {
      "epoch": 6.879518072289157,
      "grad_norm": 0.022792883217334747,
      "learning_rate": 6.240963855421688e-06,
      "loss": 0.0386,
      "step": 57100
    },
    {
      "epoch": 6.880722891566265,
      "grad_norm": 0.06445006281137466,
      "learning_rate": 6.238554216867471e-06,
      "loss": 0.0477,
      "step": 57110
    },
    {
      "epoch": 6.881927710843374,
      "grad_norm": 0.017166094854474068,
      "learning_rate": 6.236144578313253e-06,
      "loss": 0.013,
      "step": 57120
    },
    {
      "epoch": 6.8831325301204815,
      "grad_norm": 5.932474136352539,
      "learning_rate": 6.233734939759036e-06,
      "loss": 0.0406,
      "step": 57130
    },
    {
      "epoch": 6.88433734939759,
      "grad_norm": 0.0638483315706253,
      "learning_rate": 6.23132530120482e-06,
      "loss": 0.0043,
      "step": 57140
    },
    {
      "epoch": 6.885542168674699,
      "grad_norm": 0.006790435407310724,
      "learning_rate": 6.2289156626506035e-06,
      "loss": 0.0315,
      "step": 57150
    },
    {
      "epoch": 6.886746987951807,
      "grad_norm": 0.5615086555480957,
      "learning_rate": 6.226506024096386e-06,
      "loss": 0.0211,
      "step": 57160
    },
    {
      "epoch": 6.887951807228916,
      "grad_norm": 0.06938239932060242,
      "learning_rate": 6.224096385542169e-06,
      "loss": 0.0299,
      "step": 57170
    },
    {
      "epoch": 6.889156626506024,
      "grad_norm": 0.005292127840220928,
      "learning_rate": 6.221686746987953e-06,
      "loss": 0.0077,
      "step": 57180
    },
    {
      "epoch": 6.890361445783133,
      "grad_norm": 0.015257620252668858,
      "learning_rate": 6.219277108433735e-06,
      "loss": 0.0475,
      "step": 57190
    },
    {
      "epoch": 6.891566265060241,
      "grad_norm": 0.44582173228263855,
      "learning_rate": 6.2168674698795185e-06,
      "loss": 0.0149,
      "step": 57200
    },
    {
      "epoch": 6.892771084337349,
      "grad_norm": 0.22143243253231049,
      "learning_rate": 6.214457831325301e-06,
      "loss": 0.0124,
      "step": 57210
    },
    {
      "epoch": 6.893975903614458,
      "grad_norm": 2.266043186187744,
      "learning_rate": 6.212048192771085e-06,
      "loss": 0.0167,
      "step": 57220
    },
    {
      "epoch": 6.895180722891566,
      "grad_norm": 0.020244749262928963,
      "learning_rate": 6.209638554216868e-06,
      "loss": 0.0431,
      "step": 57230
    },
    {
      "epoch": 6.896385542168675,
      "grad_norm": 0.03859764710068703,
      "learning_rate": 6.207228915662651e-06,
      "loss": 0.0004,
      "step": 57240
    },
    {
      "epoch": 6.897590361445783,
      "grad_norm": 3.1343376636505127,
      "learning_rate": 6.2048192771084344e-06,
      "loss": 0.0232,
      "step": 57250
    },
    {
      "epoch": 6.8987951807228916,
      "grad_norm": 0.11317276209592819,
      "learning_rate": 6.202409638554218e-06,
      "loss": 0.0091,
      "step": 57260
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.008859687484800816,
      "learning_rate": 6.200000000000001e-06,
      "loss": 0.0244,
      "step": 57270
    },
    {
      "epoch": 6.901204819277108,
      "grad_norm": 0.04036472365260124,
      "learning_rate": 6.197590361445783e-06,
      "loss": 0.0059,
      "step": 57280
    },
    {
      "epoch": 6.902409638554217,
      "grad_norm": 0.023364808410406113,
      "learning_rate": 6.195180722891567e-06,
      "loss": 0.0158,
      "step": 57290
    },
    {
      "epoch": 6.903614457831325,
      "grad_norm": 0.012859605252742767,
      "learning_rate": 6.19277108433735e-06,
      "loss": 0.0014,
      "step": 57300
    },
    {
      "epoch": 6.904819277108434,
      "grad_norm": 0.007187258452177048,
      "learning_rate": 6.190361445783133e-06,
      "loss": 0.0131,
      "step": 57310
    },
    {
      "epoch": 6.906024096385542,
      "grad_norm": 0.0020057314541190863,
      "learning_rate": 6.187951807228916e-06,
      "loss": 0.0049,
      "step": 57320
    },
    {
      "epoch": 6.9072289156626505,
      "grad_norm": 0.001850996632128954,
      "learning_rate": 6.1855421686747e-06,
      "loss": 0.0112,
      "step": 57330
    },
    {
      "epoch": 6.908433734939759,
      "grad_norm": 0.0017042811959981918,
      "learning_rate": 6.183132530120482e-06,
      "loss": 0.0016,
      "step": 57340
    },
    {
      "epoch": 6.909638554216867,
      "grad_norm": 0.012449151836335659,
      "learning_rate": 6.180722891566265e-06,
      "loss": 0.0111,
      "step": 57350
    },
    {
      "epoch": 6.910843373493976,
      "grad_norm": 1.6731572151184082,
      "learning_rate": 6.1783132530120485e-06,
      "loss": 0.0475,
      "step": 57360
    },
    {
      "epoch": 6.912048192771084,
      "grad_norm": 0.0007593688205815852,
      "learning_rate": 6.1759036144578325e-06,
      "loss": 0.0129,
      "step": 57370
    },
    {
      "epoch": 6.913253012048193,
      "grad_norm": 1.6773051023483276,
      "learning_rate": 6.173493975903615e-06,
      "loss": 0.0025,
      "step": 57380
    },
    {
      "epoch": 6.914457831325302,
      "grad_norm": 0.5787338018417358,
      "learning_rate": 6.171084337349398e-06,
      "loss": 0.0034,
      "step": 57390
    },
    {
      "epoch": 6.9156626506024095,
      "grad_norm": 0.008185240440070629,
      "learning_rate": 6.168674698795182e-06,
      "loss": 0.01,
      "step": 57400
    },
    {
      "epoch": 6.916867469879518,
      "grad_norm": 0.0012767778243869543,
      "learning_rate": 6.166265060240964e-06,
      "loss": 0.0295,
      "step": 57410
    },
    {
      "epoch": 6.918072289156626,
      "grad_norm": 0.0007372047402895987,
      "learning_rate": 6.1638554216867476e-06,
      "loss": 0.0225,
      "step": 57420
    },
    {
      "epoch": 6.919277108433735,
      "grad_norm": 0.0012250104919075966,
      "learning_rate": 6.16144578313253e-06,
      "loss": 0.0228,
      "step": 57430
    },
    {
      "epoch": 6.920481927710844,
      "grad_norm": 2.0558180809020996,
      "learning_rate": 6.159036144578314e-06,
      "loss": 0.0189,
      "step": 57440
    },
    {
      "epoch": 6.921686746987952,
      "grad_norm": 1.4813426733016968,
      "learning_rate": 6.156626506024097e-06,
      "loss": 0.0477,
      "step": 57450
    },
    {
      "epoch": 6.9228915662650605,
      "grad_norm": 0.002848898060619831,
      "learning_rate": 6.15421686746988e-06,
      "loss": 0.0425,
      "step": 57460
    },
    {
      "epoch": 6.924096385542168,
      "grad_norm": 0.002054878044873476,
      "learning_rate": 6.151807228915663e-06,
      "loss": 0.0206,
      "step": 57470
    },
    {
      "epoch": 6.925301204819277,
      "grad_norm": 0.2239496111869812,
      "learning_rate": 6.149397590361447e-06,
      "loss": 0.0139,
      "step": 57480
    },
    {
      "epoch": 6.926506024096385,
      "grad_norm": 5.9191484451293945,
      "learning_rate": 6.14698795180723e-06,
      "loss": 0.0366,
      "step": 57490
    },
    {
      "epoch": 6.927710843373494,
      "grad_norm": 0.018214192241430283,
      "learning_rate": 6.144578313253012e-06,
      "loss": 0.0167,
      "step": 57500
    },
    {
      "epoch": 6.928915662650603,
      "grad_norm": 2.1206846237182617,
      "learning_rate": 6.142168674698795e-06,
      "loss": 0.0325,
      "step": 57510
    },
    {
      "epoch": 6.930120481927711,
      "grad_norm": 0.06520117819309235,
      "learning_rate": 6.139759036144579e-06,
      "loss": 0.0336,
      "step": 57520
    },
    {
      "epoch": 6.9313253012048195,
      "grad_norm": 0.03373740613460541,
      "learning_rate": 6.137349397590362e-06,
      "loss": 0.0104,
      "step": 57530
    },
    {
      "epoch": 6.932530120481927,
      "grad_norm": 11.780647277832031,
      "learning_rate": 6.134939759036145e-06,
      "loss": 0.0495,
      "step": 57540
    },
    {
      "epoch": 6.933734939759036,
      "grad_norm": 0.3222452700138092,
      "learning_rate": 6.132530120481929e-06,
      "loss": 0.0261,
      "step": 57550
    },
    {
      "epoch": 6.934939759036144,
      "grad_norm": 2.3285598754882812,
      "learning_rate": 6.130120481927711e-06,
      "loss": 0.039,
      "step": 57560
    },
    {
      "epoch": 6.936144578313253,
      "grad_norm": 0.9947154521942139,
      "learning_rate": 6.127710843373494e-06,
      "loss": 0.0118,
      "step": 57570
    },
    {
      "epoch": 6.937349397590362,
      "grad_norm": 0.0033075199462473392,
      "learning_rate": 6.1253012048192775e-06,
      "loss": 0.0129,
      "step": 57580
    },
    {
      "epoch": 6.93855421686747,
      "grad_norm": 0.045051731169223785,
      "learning_rate": 6.1228915662650616e-06,
      "loss": 0.0473,
      "step": 57590
    },
    {
      "epoch": 6.9397590361445785,
      "grad_norm": 2.2682600021362305,
      "learning_rate": 6.120481927710844e-06,
      "loss": 0.0387,
      "step": 57600
    },
    {
      "epoch": 6.940963855421686,
      "grad_norm": 2.241802215576172,
      "learning_rate": 6.118072289156627e-06,
      "loss": 0.0205,
      "step": 57610
    },
    {
      "epoch": 6.942168674698795,
      "grad_norm": 0.5995467901229858,
      "learning_rate": 6.115662650602409e-06,
      "loss": 0.0217,
      "step": 57620
    },
    {
      "epoch": 6.943373493975904,
      "grad_norm": 0.003375814761966467,
      "learning_rate": 6.113253012048193e-06,
      "loss": 0.0202,
      "step": 57630
    },
    {
      "epoch": 6.944578313253012,
      "grad_norm": 0.010539649985730648,
      "learning_rate": 6.110843373493977e-06,
      "loss": 0.0512,
      "step": 57640
    },
    {
      "epoch": 6.945783132530121,
      "grad_norm": 0.15578797459602356,
      "learning_rate": 6.108433734939759e-06,
      "loss": 0.0183,
      "step": 57650
    },
    {
      "epoch": 6.946987951807229,
      "grad_norm": 0.0463334321975708,
      "learning_rate": 6.106024096385542e-06,
      "loss": 0.0153,
      "step": 57660
    },
    {
      "epoch": 6.948192771084337,
      "grad_norm": 0.007021294441074133,
      "learning_rate": 6.103614457831326e-06,
      "loss": 0.036,
      "step": 57670
    },
    {
      "epoch": 6.949397590361446,
      "grad_norm": 0.081819087266922,
      "learning_rate": 6.101204819277109e-06,
      "loss": 0.0114,
      "step": 57680
    },
    {
      "epoch": 6.950602409638554,
      "grad_norm": 0.1192934513092041,
      "learning_rate": 6.098795180722892e-06,
      "loss": 0.021,
      "step": 57690
    },
    {
      "epoch": 6.951807228915663,
      "grad_norm": 0.3987753987312317,
      "learning_rate": 6.096385542168676e-06,
      "loss": 0.0538,
      "step": 57700
    },
    {
      "epoch": 6.953012048192771,
      "grad_norm": 0.12258564680814743,
      "learning_rate": 6.093975903614459e-06,
      "loss": 0.0036,
      "step": 57710
    },
    {
      "epoch": 6.95421686746988,
      "grad_norm": 2.6635329723358154,
      "learning_rate": 6.091566265060241e-06,
      "loss": 0.0299,
      "step": 57720
    },
    {
      "epoch": 6.955421686746988,
      "grad_norm": 0.04794265702366829,
      "learning_rate": 6.089156626506024e-06,
      "loss": 0.0047,
      "step": 57730
    },
    {
      "epoch": 6.956626506024096,
      "grad_norm": 0.01493917591869831,
      "learning_rate": 6.086746987951808e-06,
      "loss": 0.0424,
      "step": 57740
    },
    {
      "epoch": 6.957831325301205,
      "grad_norm": 6.53955078125,
      "learning_rate": 6.084337349397591e-06,
      "loss": 0.0251,
      "step": 57750
    },
    {
      "epoch": 6.959036144578313,
      "grad_norm": 0.0041038584895431995,
      "learning_rate": 6.081927710843374e-06,
      "loss": 0.0104,
      "step": 57760
    },
    {
      "epoch": 6.960240963855422,
      "grad_norm": 0.09110424667596817,
      "learning_rate": 6.079518072289157e-06,
      "loss": 0.0072,
      "step": 57770
    },
    {
      "epoch": 6.96144578313253,
      "grad_norm": 0.017102902755141258,
      "learning_rate": 6.077108433734941e-06,
      "loss": 0.0231,
      "step": 57780
    },
    {
      "epoch": 6.962650602409639,
      "grad_norm": 0.04788970947265625,
      "learning_rate": 6.074698795180723e-06,
      "loss": 0.04,
      "step": 57790
    },
    {
      "epoch": 6.9638554216867465,
      "grad_norm": 0.810478687286377,
      "learning_rate": 6.0722891566265066e-06,
      "loss": 0.0111,
      "step": 57800
    },
    {
      "epoch": 6.965060240963855,
      "grad_norm": 0.008464695885777473,
      "learning_rate": 6.069879518072289e-06,
      "loss": 0.0102,
      "step": 57810
    },
    {
      "epoch": 6.966265060240964,
      "grad_norm": 0.04913310334086418,
      "learning_rate": 6.067469879518073e-06,
      "loss": 0.0058,
      "step": 57820
    },
    {
      "epoch": 6.967469879518072,
      "grad_norm": 0.2992384433746338,
      "learning_rate": 6.065060240963856e-06,
      "loss": 0.0399,
      "step": 57830
    },
    {
      "epoch": 6.968674698795181,
      "grad_norm": 0.00320146675221622,
      "learning_rate": 6.062650602409638e-06,
      "loss": 0.023,
      "step": 57840
    },
    {
      "epoch": 6.969879518072289,
      "grad_norm": 1.2924073934555054,
      "learning_rate": 6.0602409638554224e-06,
      "loss": 0.0204,
      "step": 57850
    },
    {
      "epoch": 6.971084337349398,
      "grad_norm": 2.1690633296966553,
      "learning_rate": 6.057831325301206e-06,
      "loss": 0.0274,
      "step": 57860
    },
    {
      "epoch": 6.972289156626506,
      "grad_norm": 0.49037015438079834,
      "learning_rate": 6.055421686746989e-06,
      "loss": 0.008,
      "step": 57870
    },
    {
      "epoch": 6.973493975903614,
      "grad_norm": 0.01570909284055233,
      "learning_rate": 6.053012048192771e-06,
      "loss": 0.0013,
      "step": 57880
    },
    {
      "epoch": 6.974698795180723,
      "grad_norm": 0.2318168729543686,
      "learning_rate": 6.050602409638555e-06,
      "loss": 0.0059,
      "step": 57890
    },
    {
      "epoch": 6.975903614457831,
      "grad_norm": 0.003211377188563347,
      "learning_rate": 6.048192771084338e-06,
      "loss": 0.044,
      "step": 57900
    },
    {
      "epoch": 6.97710843373494,
      "grad_norm": 0.04297637194395065,
      "learning_rate": 6.045783132530121e-06,
      "loss": 0.0041,
      "step": 57910
    },
    {
      "epoch": 6.978313253012049,
      "grad_norm": 2.4645614624023438,
      "learning_rate": 6.043373493975904e-06,
      "loss": 0.0681,
      "step": 57920
    },
    {
      "epoch": 6.9795180722891565,
      "grad_norm": 0.01483733020722866,
      "learning_rate": 6.040963855421688e-06,
      "loss": 0.0123,
      "step": 57930
    },
    {
      "epoch": 6.980722891566265,
      "grad_norm": 0.39614468812942505,
      "learning_rate": 6.03855421686747e-06,
      "loss": 0.0306,
      "step": 57940
    },
    {
      "epoch": 6.981927710843373,
      "grad_norm": 0.619575023651123,
      "learning_rate": 6.036144578313253e-06,
      "loss": 0.0502,
      "step": 57950
    },
    {
      "epoch": 6.983132530120482,
      "grad_norm": 0.00419392017647624,
      "learning_rate": 6.0337349397590365e-06,
      "loss": 0.0515,
      "step": 57960
    },
    {
      "epoch": 6.98433734939759,
      "grad_norm": 2.030285358428955,
      "learning_rate": 6.03132530120482e-06,
      "loss": 0.0141,
      "step": 57970
    },
    {
      "epoch": 6.985542168674699,
      "grad_norm": 3.7237110137939453,
      "learning_rate": 6.028915662650603e-06,
      "loss": 0.0286,
      "step": 57980
    },
    {
      "epoch": 6.986746987951808,
      "grad_norm": 1.0139074325561523,
      "learning_rate": 6.026506024096386e-06,
      "loss": 0.0183,
      "step": 57990
    },
    {
      "epoch": 6.9879518072289155,
      "grad_norm": 1.7213764190673828,
      "learning_rate": 6.02409638554217e-06,
      "loss": 0.0226,
      "step": 58000
    },
    {
      "epoch": 6.989156626506024,
      "grad_norm": 12.155173301696777,
      "learning_rate": 6.021686746987952e-06,
      "loss": 0.0162,
      "step": 58010
    },
    {
      "epoch": 6.990361445783132,
      "grad_norm": 0.0014366449322551489,
      "learning_rate": 6.019277108433736e-06,
      "loss": 0.0247,
      "step": 58020
    },
    {
      "epoch": 6.991566265060241,
      "grad_norm": 2.57956862449646,
      "learning_rate": 6.016867469879518e-06,
      "loss": 0.0229,
      "step": 58030
    },
    {
      "epoch": 6.992771084337349,
      "grad_norm": 0.006806559395045042,
      "learning_rate": 6.014457831325302e-06,
      "loss": 0.0285,
      "step": 58040
    },
    {
      "epoch": 6.993975903614458,
      "grad_norm": 0.002495796186849475,
      "learning_rate": 6.012048192771085e-06,
      "loss": 0.0034,
      "step": 58050
    },
    {
      "epoch": 6.995180722891567,
      "grad_norm": 1.3579204082489014,
      "learning_rate": 6.0096385542168674e-06,
      "loss": 0.0215,
      "step": 58060
    },
    {
      "epoch": 6.9963855421686745,
      "grad_norm": 0.1164894625544548,
      "learning_rate": 6.007228915662651e-06,
      "loss": 0.025,
      "step": 58070
    },
    {
      "epoch": 6.997590361445783,
      "grad_norm": 0.6422733664512634,
      "learning_rate": 6.004819277108435e-06,
      "loss": 0.009,
      "step": 58080
    },
    {
      "epoch": 6.998795180722891,
      "grad_norm": 4.0820512771606445,
      "learning_rate": 6.002409638554218e-06,
      "loss": 0.0301,
      "step": 58090
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0038573918864130974,
      "learning_rate": 6e-06,
      "loss": 0.0036,
      "step": 58100
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9870172478440195,
      "eval_f1": 0.9655086539658821,
      "eval_loss": 0.04757790267467499,
      "eval_precision": 0.972776314138753,
      "eval_recall": 0.9583487825979483,
      "eval_runtime": 4977.2821,
      "eval_samples_per_second": 8.577,
      "eval_steps_per_second": 0.357,
      "step": 58100
    },
    {
      "epoch": 7.001204819277109,
      "grad_norm": 0.00464779045432806,
      "learning_rate": 5.997590361445783e-06,
      "loss": 0.0146,
      "step": 58110
    },
    {
      "epoch": 7.002409638554217,
      "grad_norm": 1.1264623403549194,
      "learning_rate": 5.995180722891567e-06,
      "loss": 0.0287,
      "step": 58120
    },
    {
      "epoch": 7.0036144578313255,
      "grad_norm": 0.5405458211898804,
      "learning_rate": 5.99277108433735e-06,
      "loss": 0.0175,
      "step": 58130
    },
    {
      "epoch": 7.004819277108433,
      "grad_norm": 0.0010171154281124473,
      "learning_rate": 5.990361445783133e-06,
      "loss": 0.0167,
      "step": 58140
    },
    {
      "epoch": 7.006024096385542,
      "grad_norm": 0.032232217490673065,
      "learning_rate": 5.987951807228917e-06,
      "loss": 0.0007,
      "step": 58150
    },
    {
      "epoch": 7.00722891566265,
      "grad_norm": 0.003722950117662549,
      "learning_rate": 5.985542168674699e-06,
      "loss": 0.0107,
      "step": 58160
    },
    {
      "epoch": 7.008433734939759,
      "grad_norm": 0.0010433479910716414,
      "learning_rate": 5.983132530120482e-06,
      "loss": 0.0122,
      "step": 58170
    },
    {
      "epoch": 7.009638554216868,
      "grad_norm": 0.006503554992377758,
      "learning_rate": 5.9807228915662656e-06,
      "loss": 0.0438,
      "step": 58180
    },
    {
      "epoch": 7.010843373493976,
      "grad_norm": 0.7511632442474365,
      "learning_rate": 5.978313253012049e-06,
      "loss": 0.0043,
      "step": 58190
    },
    {
      "epoch": 7.0120481927710845,
      "grad_norm": 0.01189081184566021,
      "learning_rate": 5.975903614457832e-06,
      "loss": 0.0387,
      "step": 58200
    },
    {
      "epoch": 7.013253012048192,
      "grad_norm": 1.4002647399902344,
      "learning_rate": 5.973493975903615e-06,
      "loss": 0.0357,
      "step": 58210
    },
    {
      "epoch": 7.014457831325301,
      "grad_norm": 1.8420326709747314,
      "learning_rate": 5.971084337349397e-06,
      "loss": 0.0514,
      "step": 58220
    },
    {
      "epoch": 7.01566265060241,
      "grad_norm": 0.03419089317321777,
      "learning_rate": 5.9686746987951814e-06,
      "loss": 0.0057,
      "step": 58230
    },
    {
      "epoch": 7.016867469879518,
      "grad_norm": 0.016684258356690407,
      "learning_rate": 5.966265060240965e-06,
      "loss": 0.0146,
      "step": 58240
    },
    {
      "epoch": 7.018072289156627,
      "grad_norm": 0.003019588300958276,
      "learning_rate": 5.963855421686747e-06,
      "loss": 0.0039,
      "step": 58250
    },
    {
      "epoch": 7.019277108433735,
      "grad_norm": 1.1240346431732178,
      "learning_rate": 5.96144578313253e-06,
      "loss": 0.0115,
      "step": 58260
    },
    {
      "epoch": 7.0204819277108435,
      "grad_norm": 2.654831886291504,
      "learning_rate": 5.959036144578314e-06,
      "loss": 0.0343,
      "step": 58270
    },
    {
      "epoch": 7.021686746987951,
      "grad_norm": 0.0024641654454171658,
      "learning_rate": 5.9566265060240965e-06,
      "loss": 0.0045,
      "step": 58280
    },
    {
      "epoch": 7.02289156626506,
      "grad_norm": 0.0007096657645888627,
      "learning_rate": 5.95421686746988e-06,
      "loss": 0.0262,
      "step": 58290
    },
    {
      "epoch": 7.024096385542169,
      "grad_norm": 0.012059744447469711,
      "learning_rate": 5.951807228915664e-06,
      "loss": 0.0057,
      "step": 58300
    },
    {
      "epoch": 7.025301204819277,
      "grad_norm": 0.0019104370148852468,
      "learning_rate": 5.949397590361447e-06,
      "loss": 0.0119,
      "step": 58310
    },
    {
      "epoch": 7.026506024096386,
      "grad_norm": 1.1527575254440308,
      "learning_rate": 5.946987951807229e-06,
      "loss": 0.01,
      "step": 58320
    },
    {
      "epoch": 7.027710843373494,
      "grad_norm": 0.0009319806704297662,
      "learning_rate": 5.944578313253012e-06,
      "loss": 0.0337,
      "step": 58330
    },
    {
      "epoch": 7.028915662650602,
      "grad_norm": 0.045384254306554794,
      "learning_rate": 5.942168674698796e-06,
      "loss": 0.0125,
      "step": 58340
    },
    {
      "epoch": 7.030120481927711,
      "grad_norm": 0.2655925750732422,
      "learning_rate": 5.939759036144579e-06,
      "loss": 0.0157,
      "step": 58350
    },
    {
      "epoch": 7.031325301204819,
      "grad_norm": 0.008753008209168911,
      "learning_rate": 5.937349397590362e-06,
      "loss": 0.0211,
      "step": 58360
    },
    {
      "epoch": 7.032530120481928,
      "grad_norm": 0.0020911493338644505,
      "learning_rate": 5.934939759036144e-06,
      "loss": 0.0315,
      "step": 58370
    },
    {
      "epoch": 7.033734939759036,
      "grad_norm": 0.031198907643556595,
      "learning_rate": 5.932530120481928e-06,
      "loss": 0.0023,
      "step": 58380
    },
    {
      "epoch": 7.034939759036145,
      "grad_norm": 0.0030286330729722977,
      "learning_rate": 5.930120481927711e-06,
      "loss": 0.0418,
      "step": 58390
    },
    {
      "epoch": 7.036144578313253,
      "grad_norm": 0.008977781049907207,
      "learning_rate": 5.927710843373495e-06,
      "loss": 0.0227,
      "step": 58400
    },
    {
      "epoch": 7.037349397590361,
      "grad_norm": 0.07806304842233658,
      "learning_rate": 5.925301204819277e-06,
      "loss": 0.0352,
      "step": 58410
    },
    {
      "epoch": 7.03855421686747,
      "grad_norm": 0.0076018585823476315,
      "learning_rate": 5.922891566265061e-06,
      "loss": 0.0028,
      "step": 58420
    },
    {
      "epoch": 7.039759036144578,
      "grad_norm": 0.04995690658688545,
      "learning_rate": 5.920481927710844e-06,
      "loss": 0.0009,
      "step": 58430
    },
    {
      "epoch": 7.040963855421687,
      "grad_norm": 1.4457629919052124,
      "learning_rate": 5.9180722891566264e-06,
      "loss": 0.0712,
      "step": 58440
    },
    {
      "epoch": 7.042168674698795,
      "grad_norm": 0.009614145383238792,
      "learning_rate": 5.9156626506024105e-06,
      "loss": 0.0316,
      "step": 58450
    },
    {
      "epoch": 7.043373493975904,
      "grad_norm": 0.07491164654493332,
      "learning_rate": 5.913253012048194e-06,
      "loss": 0.0068,
      "step": 58460
    },
    {
      "epoch": 7.044578313253012,
      "grad_norm": 0.004299267660826445,
      "learning_rate": 5.910843373493976e-06,
      "loss": 0.0288,
      "step": 58470
    },
    {
      "epoch": 7.04578313253012,
      "grad_norm": 0.12677767872810364,
      "learning_rate": 5.908433734939759e-06,
      "loss": 0.02,
      "step": 58480
    },
    {
      "epoch": 7.046987951807229,
      "grad_norm": 0.44989287853240967,
      "learning_rate": 5.906024096385543e-06,
      "loss": 0.0309,
      "step": 58490
    },
    {
      "epoch": 7.048192771084337,
      "grad_norm": 0.9622644186019897,
      "learning_rate": 5.9036144578313255e-06,
      "loss": 0.0096,
      "step": 58500
    },
    {
      "epoch": 7.049397590361446,
      "grad_norm": 0.027407556772232056,
      "learning_rate": 5.901204819277109e-06,
      "loss": 0.0184,
      "step": 58510
    },
    {
      "epoch": 7.050602409638554,
      "grad_norm": 0.08304242044687271,
      "learning_rate": 5.898795180722892e-06,
      "loss": 0.0368,
      "step": 58520
    },
    {
      "epoch": 7.051807228915663,
      "grad_norm": 0.0037210944574326277,
      "learning_rate": 5.896385542168676e-06,
      "loss": 0.002,
      "step": 58530
    },
    {
      "epoch": 7.053012048192771,
      "grad_norm": 0.010856878943741322,
      "learning_rate": 5.893975903614458e-06,
      "loss": 0.0175,
      "step": 58540
    },
    {
      "epoch": 7.054216867469879,
      "grad_norm": 0.010723692364990711,
      "learning_rate": 5.891566265060241e-06,
      "loss": 0.0201,
      "step": 58550
    },
    {
      "epoch": 7.055421686746988,
      "grad_norm": 0.00652770372107625,
      "learning_rate": 5.889156626506024e-06,
      "loss": 0.0059,
      "step": 58560
    },
    {
      "epoch": 7.056626506024096,
      "grad_norm": 0.9322814345359802,
      "learning_rate": 5.886746987951808e-06,
      "loss": 0.0111,
      "step": 58570
    },
    {
      "epoch": 7.057831325301205,
      "grad_norm": 4.4401350021362305,
      "learning_rate": 5.884337349397591e-06,
      "loss": 0.023,
      "step": 58580
    },
    {
      "epoch": 7.059036144578314,
      "grad_norm": 0.02288597822189331,
      "learning_rate": 5.881927710843374e-06,
      "loss": 0.0017,
      "step": 58590
    },
    {
      "epoch": 7.0602409638554215,
      "grad_norm": 0.002566487994045019,
      "learning_rate": 5.879518072289157e-06,
      "loss": 0.0347,
      "step": 58600
    },
    {
      "epoch": 7.06144578313253,
      "grad_norm": 0.0034859217703342438,
      "learning_rate": 5.8771084337349404e-06,
      "loss": 0.0048,
      "step": 58610
    },
    {
      "epoch": 7.062650602409638,
      "grad_norm": 0.002694740192964673,
      "learning_rate": 5.874698795180724e-06,
      "loss": 0.0128,
      "step": 58620
    },
    {
      "epoch": 7.063855421686747,
      "grad_norm": 1.090638518333435,
      "learning_rate": 5.872289156626506e-06,
      "loss": 0.0335,
      "step": 58630
    },
    {
      "epoch": 7.065060240963855,
      "grad_norm": 0.0012189788976684213,
      "learning_rate": 5.86987951807229e-06,
      "loss": 0.0134,
      "step": 58640
    },
    {
      "epoch": 7.066265060240964,
      "grad_norm": 3.8732211589813232,
      "learning_rate": 5.867469879518073e-06,
      "loss": 0.0403,
      "step": 58650
    },
    {
      "epoch": 7.067469879518073,
      "grad_norm": 0.08973617106676102,
      "learning_rate": 5.8650602409638555e-06,
      "loss": 0.0034,
      "step": 58660
    },
    {
      "epoch": 7.0686746987951805,
      "grad_norm": 0.00498303072527051,
      "learning_rate": 5.862650602409639e-06,
      "loss": 0.0155,
      "step": 58670
    },
    {
      "epoch": 7.069879518072289,
      "grad_norm": 0.0023156804963946342,
      "learning_rate": 5.860240963855423e-06,
      "loss": 0.0352,
      "step": 58680
    },
    {
      "epoch": 7.071084337349397,
      "grad_norm": 2.753246307373047,
      "learning_rate": 5.857831325301205e-06,
      "loss": 0.0418,
      "step": 58690
    },
    {
      "epoch": 7.072289156626506,
      "grad_norm": 0.01228753849864006,
      "learning_rate": 5.855421686746988e-06,
      "loss": 0.0148,
      "step": 58700
    },
    {
      "epoch": 7.073493975903615,
      "grad_norm": 1.7875009775161743,
      "learning_rate": 5.853012048192771e-06,
      "loss": 0.0107,
      "step": 58710
    },
    {
      "epoch": 7.074698795180723,
      "grad_norm": 0.5180738568305969,
      "learning_rate": 5.850602409638555e-06,
      "loss": 0.044,
      "step": 58720
    },
    {
      "epoch": 7.075903614457832,
      "grad_norm": 0.004744756501168013,
      "learning_rate": 5.848192771084338e-06,
      "loss": 0.046,
      "step": 58730
    },
    {
      "epoch": 7.0771084337349395,
      "grad_norm": 87.015380859375,
      "learning_rate": 5.845783132530121e-06,
      "loss": 0.0162,
      "step": 58740
    },
    {
      "epoch": 7.078313253012048,
      "grad_norm": 0.7385025024414062,
      "learning_rate": 5.843373493975905e-06,
      "loss": 0.0057,
      "step": 58750
    },
    {
      "epoch": 7.079518072289156,
      "grad_norm": 2.02890944480896,
      "learning_rate": 5.840963855421687e-06,
      "loss": 0.0118,
      "step": 58760
    },
    {
      "epoch": 7.080722891566265,
      "grad_norm": 0.0361059308052063,
      "learning_rate": 5.83855421686747e-06,
      "loss": 0.0197,
      "step": 58770
    },
    {
      "epoch": 7.081927710843374,
      "grad_norm": 0.008460037410259247,
      "learning_rate": 5.836144578313253e-06,
      "loss": 0.0043,
      "step": 58780
    },
    {
      "epoch": 7.083132530120482,
      "grad_norm": 0.010962041094899178,
      "learning_rate": 5.833734939759037e-06,
      "loss": 0.0266,
      "step": 58790
    },
    {
      "epoch": 7.0843373493975905,
      "grad_norm": 0.5661713480949402,
      "learning_rate": 5.83132530120482e-06,
      "loss": 0.0267,
      "step": 58800
    },
    {
      "epoch": 7.085542168674698,
      "grad_norm": 0.012357463128864765,
      "learning_rate": 5.828915662650603e-06,
      "loss": 0.0047,
      "step": 58810
    },
    {
      "epoch": 7.086746987951807,
      "grad_norm": 0.39956995844841003,
      "learning_rate": 5.8265060240963854e-06,
      "loss": 0.0159,
      "step": 58820
    },
    {
      "epoch": 7.087951807228916,
      "grad_norm": 0.1659148633480072,
      "learning_rate": 5.8240963855421695e-06,
      "loss": 0.0184,
      "step": 58830
    },
    {
      "epoch": 7.089156626506024,
      "grad_norm": 0.0032739078160375357,
      "learning_rate": 5.821686746987953e-06,
      "loss": 0.0089,
      "step": 58840
    },
    {
      "epoch": 7.090361445783133,
      "grad_norm": 1.3452528715133667,
      "learning_rate": 5.819277108433735e-06,
      "loss": 0.0136,
      "step": 58850
    },
    {
      "epoch": 7.091566265060241,
      "grad_norm": 2.0766451358795166,
      "learning_rate": 5.816867469879518e-06,
      "loss": 0.0194,
      "step": 58860
    },
    {
      "epoch": 7.0927710843373495,
      "grad_norm": 0.000881096872035414,
      "learning_rate": 5.814457831325302e-06,
      "loss": 0.0399,
      "step": 58870
    },
    {
      "epoch": 7.093975903614457,
      "grad_norm": 0.0018467934569343925,
      "learning_rate": 5.8120481927710845e-06,
      "loss": 0.0096,
      "step": 58880
    },
    {
      "epoch": 7.095180722891566,
      "grad_norm": 0.0019750173669308424,
      "learning_rate": 5.809638554216868e-06,
      "loss": 0.0253,
      "step": 58890
    },
    {
      "epoch": 7.096385542168675,
      "grad_norm": 0.0033153260592371225,
      "learning_rate": 5.807228915662652e-06,
      "loss": 0.0014,
      "step": 58900
    },
    {
      "epoch": 7.097590361445783,
      "grad_norm": 0.0400690920650959,
      "learning_rate": 5.804819277108434e-06,
      "loss": 0.0173,
      "step": 58910
    },
    {
      "epoch": 7.098795180722892,
      "grad_norm": 0.0017581225838512182,
      "learning_rate": 5.802409638554217e-06,
      "loss": 0.005,
      "step": 58920
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.001296641188673675,
      "learning_rate": 5.8e-06,
      "loss": 0.008,
      "step": 58930
    },
    {
      "epoch": 7.1012048192771084,
      "grad_norm": 0.9361958503723145,
      "learning_rate": 5.797590361445784e-06,
      "loss": 0.0285,
      "step": 58940
    },
    {
      "epoch": 7.102409638554217,
      "grad_norm": 1.3885900974273682,
      "learning_rate": 5.795180722891567e-06,
      "loss": 0.0136,
      "step": 58950
    },
    {
      "epoch": 7.103614457831325,
      "grad_norm": 0.0023262756876647472,
      "learning_rate": 5.79277108433735e-06,
      "loss": 0.0466,
      "step": 58960
    },
    {
      "epoch": 7.104819277108434,
      "grad_norm": 0.0362992063164711,
      "learning_rate": 5.790361445783132e-06,
      "loss": 0.0039,
      "step": 58970
    },
    {
      "epoch": 7.106024096385542,
      "grad_norm": 0.0063539911061525345,
      "learning_rate": 5.787951807228916e-06,
      "loss": 0.0057,
      "step": 58980
    },
    {
      "epoch": 7.107228915662651,
      "grad_norm": 1.0491242408752441,
      "learning_rate": 5.7855421686746994e-06,
      "loss": 0.0115,
      "step": 58990
    },
    {
      "epoch": 7.108433734939759,
      "grad_norm": 0.025832969695329666,
      "learning_rate": 5.783132530120482e-06,
      "loss": 0.0153,
      "step": 59000
    },
    {
      "epoch": 7.109638554216867,
      "grad_norm": 0.0014315900625661016,
      "learning_rate": 5.780722891566265e-06,
      "loss": 0.0338,
      "step": 59010
    },
    {
      "epoch": 7.110843373493976,
      "grad_norm": 0.09963741898536682,
      "learning_rate": 5.778313253012049e-06,
      "loss": 0.0133,
      "step": 59020
    },
    {
      "epoch": 7.112048192771084,
      "grad_norm": 0.045363765209913254,
      "learning_rate": 5.775903614457832e-06,
      "loss": 0.0078,
      "step": 59030
    },
    {
      "epoch": 7.113253012048193,
      "grad_norm": 0.9287425875663757,
      "learning_rate": 5.7734939759036145e-06,
      "loss": 0.013,
      "step": 59040
    },
    {
      "epoch": 7.114457831325301,
      "grad_norm": 2.120867967605591,
      "learning_rate": 5.7710843373493985e-06,
      "loss": 0.057,
      "step": 59050
    },
    {
      "epoch": 7.11566265060241,
      "grad_norm": 0.0014561284333467484,
      "learning_rate": 5.768674698795182e-06,
      "loss": 0.02,
      "step": 59060
    },
    {
      "epoch": 7.1168674698795185,
      "grad_norm": 0.0027327928692102432,
      "learning_rate": 5.766265060240964e-06,
      "loss": 0.021,
      "step": 59070
    },
    {
      "epoch": 7.118072289156626,
      "grad_norm": 3.5988285541534424,
      "learning_rate": 5.763855421686747e-06,
      "loss": 0.0174,
      "step": 59080
    },
    {
      "epoch": 7.119277108433735,
      "grad_norm": 2.3675217628479004,
      "learning_rate": 5.761445783132531e-06,
      "loss": 0.0246,
      "step": 59090
    },
    {
      "epoch": 7.120481927710843,
      "grad_norm": 1.2711089849472046,
      "learning_rate": 5.7590361445783135e-06,
      "loss": 0.0236,
      "step": 59100
    },
    {
      "epoch": 7.121686746987952,
      "grad_norm": 0.020317422226071358,
      "learning_rate": 5.756626506024097e-06,
      "loss": 0.0248,
      "step": 59110
    },
    {
      "epoch": 7.12289156626506,
      "grad_norm": 0.0011607285123318434,
      "learning_rate": 5.75421686746988e-06,
      "loss": 0.0265,
      "step": 59120
    },
    {
      "epoch": 7.124096385542169,
      "grad_norm": 22.446969985961914,
      "learning_rate": 5.751807228915663e-06,
      "loss": 0.0242,
      "step": 59130
    },
    {
      "epoch": 7.125301204819277,
      "grad_norm": 0.009098921902477741,
      "learning_rate": 5.749397590361446e-06,
      "loss": 0.0195,
      "step": 59140
    },
    {
      "epoch": 7.126506024096385,
      "grad_norm": 0.8954815864562988,
      "learning_rate": 5.746987951807229e-06,
      "loss": 0.017,
      "step": 59150
    },
    {
      "epoch": 7.127710843373494,
      "grad_norm": 0.2146633118391037,
      "learning_rate": 5.744578313253013e-06,
      "loss": 0.0137,
      "step": 59160
    },
    {
      "epoch": 7.128915662650602,
      "grad_norm": 0.002270026132464409,
      "learning_rate": 5.742168674698796e-06,
      "loss": 0.032,
      "step": 59170
    },
    {
      "epoch": 7.130120481927711,
      "grad_norm": 0.0264122411608696,
      "learning_rate": 5.739759036144579e-06,
      "loss": 0.0236,
      "step": 59180
    },
    {
      "epoch": 7.13132530120482,
      "grad_norm": 0.20444560050964355,
      "learning_rate": 5.737349397590361e-06,
      "loss": 0.01,
      "step": 59190
    },
    {
      "epoch": 7.132530120481928,
      "grad_norm": 0.35047584772109985,
      "learning_rate": 5.734939759036145e-06,
      "loss": 0.0337,
      "step": 59200
    },
    {
      "epoch": 7.133734939759036,
      "grad_norm": 0.9023749232292175,
      "learning_rate": 5.7325301204819285e-06,
      "loss": 0.0057,
      "step": 59210
    },
    {
      "epoch": 7.134939759036144,
      "grad_norm": 0.23956428468227386,
      "learning_rate": 5.730120481927711e-06,
      "loss": 0.0082,
      "step": 59220
    },
    {
      "epoch": 7.136144578313253,
      "grad_norm": 0.0033434198703616858,
      "learning_rate": 5.727710843373494e-06,
      "loss": 0.0173,
      "step": 59230
    },
    {
      "epoch": 7.137349397590361,
      "grad_norm": 0.002293829107657075,
      "learning_rate": 5.725301204819278e-06,
      "loss": 0.0067,
      "step": 59240
    },
    {
      "epoch": 7.13855421686747,
      "grad_norm": 0.001460934872739017,
      "learning_rate": 5.722891566265061e-06,
      "loss": 0.0044,
      "step": 59250
    },
    {
      "epoch": 7.139759036144579,
      "grad_norm": 0.005186351016163826,
      "learning_rate": 5.7204819277108435e-06,
      "loss": 0.0399,
      "step": 59260
    },
    {
      "epoch": 7.1409638554216865,
      "grad_norm": 0.2532373368740082,
      "learning_rate": 5.718072289156627e-06,
      "loss": 0.0094,
      "step": 59270
    },
    {
      "epoch": 7.142168674698795,
      "grad_norm": 0.12729711830615997,
      "learning_rate": 5.715662650602411e-06,
      "loss": 0.0068,
      "step": 59280
    },
    {
      "epoch": 7.143373493975903,
      "grad_norm": 0.006638593040406704,
      "learning_rate": 5.713253012048193e-06,
      "loss": 0.0125,
      "step": 59290
    },
    {
      "epoch": 7.144578313253012,
      "grad_norm": 0.00473793176934123,
      "learning_rate": 5.710843373493976e-06,
      "loss": 0.025,
      "step": 59300
    },
    {
      "epoch": 7.145783132530121,
      "grad_norm": 0.0008841511444188654,
      "learning_rate": 5.70843373493976e-06,
      "loss": 0.0225,
      "step": 59310
    },
    {
      "epoch": 7.146987951807229,
      "grad_norm": 0.8472663760185242,
      "learning_rate": 5.7060240963855425e-06,
      "loss": 0.0432,
      "step": 59320
    },
    {
      "epoch": 7.148192771084338,
      "grad_norm": 0.0007458814070560038,
      "learning_rate": 5.703614457831326e-06,
      "loss": 0.0104,
      "step": 59330
    },
    {
      "epoch": 7.1493975903614455,
      "grad_norm": 0.0013109322171658278,
      "learning_rate": 5.701204819277109e-06,
      "loss": 0.0244,
      "step": 59340
    },
    {
      "epoch": 7.150602409638554,
      "grad_norm": 0.7106509804725647,
      "learning_rate": 5.698795180722893e-06,
      "loss": 0.0039,
      "step": 59350
    },
    {
      "epoch": 7.151807228915662,
      "grad_norm": 0.001458983519114554,
      "learning_rate": 5.696385542168675e-06,
      "loss": 0.0184,
      "step": 59360
    },
    {
      "epoch": 7.153012048192771,
      "grad_norm": 0.015356122516095638,
      "learning_rate": 5.693975903614458e-06,
      "loss": 0.0333,
      "step": 59370
    },
    {
      "epoch": 7.15421686746988,
      "grad_norm": 0.44483324885368347,
      "learning_rate": 5.691566265060241e-06,
      "loss": 0.0023,
      "step": 59380
    },
    {
      "epoch": 7.155421686746988,
      "grad_norm": 0.011395862326025963,
      "learning_rate": 5.689156626506025e-06,
      "loss": 0.0041,
      "step": 59390
    },
    {
      "epoch": 7.156626506024097,
      "grad_norm": 0.004505142103880644,
      "learning_rate": 5.686746987951808e-06,
      "loss": 0.0055,
      "step": 59400
    },
    {
      "epoch": 7.1578313253012045,
      "grad_norm": 0.02127383090555668,
      "learning_rate": 5.68433734939759e-06,
      "loss": 0.0091,
      "step": 59410
    },
    {
      "epoch": 7.159036144578313,
      "grad_norm": 0.01942971535027027,
      "learning_rate": 5.6819277108433735e-06,
      "loss": 0.0034,
      "step": 59420
    },
    {
      "epoch": 7.160240963855422,
      "grad_norm": 0.0006357083329930902,
      "learning_rate": 5.6795180722891575e-06,
      "loss": 0.0352,
      "step": 59430
    },
    {
      "epoch": 7.16144578313253,
      "grad_norm": 0.002362125786021352,
      "learning_rate": 5.677108433734941e-06,
      "loss": 0.0041,
      "step": 59440
    },
    {
      "epoch": 7.162650602409639,
      "grad_norm": 2.8359479904174805,
      "learning_rate": 5.674698795180723e-06,
      "loss": 0.0232,
      "step": 59450
    },
    {
      "epoch": 7.163855421686747,
      "grad_norm": 0.25679880380630493,
      "learning_rate": 5.672289156626507e-06,
      "loss": 0.0167,
      "step": 59460
    },
    {
      "epoch": 7.1650602409638555,
      "grad_norm": 7.06538724899292,
      "learning_rate": 5.66987951807229e-06,
      "loss": 0.0399,
      "step": 59470
    },
    {
      "epoch": 7.166265060240963,
      "grad_norm": 0.1786200851202011,
      "learning_rate": 5.6674698795180725e-06,
      "loss": 0.0208,
      "step": 59480
    },
    {
      "epoch": 7.167469879518072,
      "grad_norm": 0.0014848089776933193,
      "learning_rate": 5.665060240963856e-06,
      "loss": 0.0432,
      "step": 59490
    },
    {
      "epoch": 7.168674698795181,
      "grad_norm": 0.013951633125543594,
      "learning_rate": 5.66265060240964e-06,
      "loss": 0.0101,
      "step": 59500
    },
    {
      "epoch": 7.169879518072289,
      "grad_norm": 0.0010766612831503153,
      "learning_rate": 5.660240963855422e-06,
      "loss": 0.0261,
      "step": 59510
    },
    {
      "epoch": 7.171084337349398,
      "grad_norm": 0.08604803681373596,
      "learning_rate": 5.657831325301205e-06,
      "loss": 0.0097,
      "step": 59520
    },
    {
      "epoch": 7.172289156626506,
      "grad_norm": 0.7109196186065674,
      "learning_rate": 5.655421686746988e-06,
      "loss": 0.0284,
      "step": 59530
    },
    {
      "epoch": 7.1734939759036145,
      "grad_norm": 2.082094669342041,
      "learning_rate": 5.6530120481927716e-06,
      "loss": 0.0093,
      "step": 59540
    },
    {
      "epoch": 7.174698795180723,
      "grad_norm": 1.2183042764663696,
      "learning_rate": 5.650602409638555e-06,
      "loss": 0.0246,
      "step": 59550
    },
    {
      "epoch": 7.175903614457831,
      "grad_norm": 0.10668831318616867,
      "learning_rate": 5.648192771084338e-06,
      "loss": 0.0125,
      "step": 59560
    },
    {
      "epoch": 7.17710843373494,
      "grad_norm": 0.0014447601279243827,
      "learning_rate": 5.64578313253012e-06,
      "loss": 0.0129,
      "step": 59570
    },
    {
      "epoch": 7.178313253012048,
      "grad_norm": 0.001604020711965859,
      "learning_rate": 5.643373493975904e-06,
      "loss": 0.0208,
      "step": 59580
    },
    {
      "epoch": 7.179518072289157,
      "grad_norm": 0.003877764567732811,
      "learning_rate": 5.6409638554216874e-06,
      "loss": 0.0918,
      "step": 59590
    },
    {
      "epoch": 7.180722891566265,
      "grad_norm": 0.006073968950659037,
      "learning_rate": 5.63855421686747e-06,
      "loss": 0.0164,
      "step": 59600
    },
    {
      "epoch": 7.1819277108433734,
      "grad_norm": 0.0008771793218329549,
      "learning_rate": 5.636144578313254e-06,
      "loss": 0.0011,
      "step": 59610
    },
    {
      "epoch": 7.183132530120482,
      "grad_norm": 0.004221794661134481,
      "learning_rate": 5.633734939759037e-06,
      "loss": 0.0354,
      "step": 59620
    },
    {
      "epoch": 7.18433734939759,
      "grad_norm": 1.1501259803771973,
      "learning_rate": 5.631325301204819e-06,
      "loss": 0.0287,
      "step": 59630
    },
    {
      "epoch": 7.185542168674699,
      "grad_norm": 1.8419386148452759,
      "learning_rate": 5.6289156626506025e-06,
      "loss": 0.0046,
      "step": 59640
    },
    {
      "epoch": 7.186746987951807,
      "grad_norm": 0.0025077543687075377,
      "learning_rate": 5.6265060240963865e-06,
      "loss": 0.0603,
      "step": 59650
    },
    {
      "epoch": 7.187951807228916,
      "grad_norm": 0.0019945178646594286,
      "learning_rate": 5.62409638554217e-06,
      "loss": 0.0152,
      "step": 59660
    },
    {
      "epoch": 7.1891566265060245,
      "grad_norm": 0.008479067124426365,
      "learning_rate": 5.621686746987952e-06,
      "loss": 0.0075,
      "step": 59670
    },
    {
      "epoch": 7.190361445783132,
      "grad_norm": 0.019855517894029617,
      "learning_rate": 5.619277108433735e-06,
      "loss": 0.0194,
      "step": 59680
    },
    {
      "epoch": 7.191566265060241,
      "grad_norm": 0.012939346954226494,
      "learning_rate": 5.616867469879519e-06,
      "loss": 0.008,
      "step": 59690
    },
    {
      "epoch": 7.192771084337349,
      "grad_norm": 0.8077332973480225,
      "learning_rate": 5.6144578313253015e-06,
      "loss": 0.029,
      "step": 59700
    },
    {
      "epoch": 7.193975903614458,
      "grad_norm": 0.014423346146941185,
      "learning_rate": 5.612048192771085e-06,
      "loss": 0.0091,
      "step": 59710
    },
    {
      "epoch": 7.195180722891566,
      "grad_norm": 0.005645657889544964,
      "learning_rate": 5.609638554216867e-06,
      "loss": 0.0038,
      "step": 59720
    },
    {
      "epoch": 7.196385542168675,
      "grad_norm": 0.0041212099604308605,
      "learning_rate": 5.607228915662651e-06,
      "loss": 0.0001,
      "step": 59730
    },
    {
      "epoch": 7.1975903614457835,
      "grad_norm": 0.001752351294271648,
      "learning_rate": 5.604819277108434e-06,
      "loss": 0.0286,
      "step": 59740
    },
    {
      "epoch": 7.198795180722891,
      "grad_norm": 0.0027978955768048763,
      "learning_rate": 5.602409638554217e-06,
      "loss": 0.0206,
      "step": 59750
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.7070242166519165,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0292,
      "step": 59760
    },
    {
      "epoch": 7.201204819277108,
      "grad_norm": 0.035371288657188416,
      "learning_rate": 5.597590361445784e-06,
      "loss": 0.0237,
      "step": 59770
    },
    {
      "epoch": 7.202409638554217,
      "grad_norm": 1.5235176086425781,
      "learning_rate": 5.595180722891567e-06,
      "loss": 0.033,
      "step": 59780
    },
    {
      "epoch": 7.203614457831326,
      "grad_norm": 1.1437383890151978,
      "learning_rate": 5.592771084337349e-06,
      "loss": 0.0062,
      "step": 59790
    },
    {
      "epoch": 7.204819277108434,
      "grad_norm": 2.110992193222046,
      "learning_rate": 5.590361445783133e-06,
      "loss": 0.0244,
      "step": 59800
    },
    {
      "epoch": 7.206024096385542,
      "grad_norm": 2.801995277404785,
      "learning_rate": 5.5879518072289165e-06,
      "loss": 0.0268,
      "step": 59810
    },
    {
      "epoch": 7.20722891566265,
      "grad_norm": 0.00044418033212423325,
      "learning_rate": 5.585542168674699e-06,
      "loss": 0.0133,
      "step": 59820
    },
    {
      "epoch": 7.208433734939759,
      "grad_norm": 0.0010030376724898815,
      "learning_rate": 5.583132530120482e-06,
      "loss": 0.0197,
      "step": 59830
    },
    {
      "epoch": 7.209638554216867,
      "grad_norm": 0.001135522616095841,
      "learning_rate": 5.580722891566266e-06,
      "loss": 0.0115,
      "step": 59840
    },
    {
      "epoch": 7.210843373493976,
      "grad_norm": 0.9312419295310974,
      "learning_rate": 5.578313253012048e-06,
      "loss": 0.0161,
      "step": 59850
    },
    {
      "epoch": 7.212048192771085,
      "grad_norm": 2.564711093902588,
      "learning_rate": 5.5759036144578315e-06,
      "loss": 0.0341,
      "step": 59860
    },
    {
      "epoch": 7.213253012048193,
      "grad_norm": 1.6558868885040283,
      "learning_rate": 5.573493975903615e-06,
      "loss": 0.022,
      "step": 59870
    },
    {
      "epoch": 7.214457831325301,
      "grad_norm": 0.0007107702549546957,
      "learning_rate": 5.571084337349399e-06,
      "loss": 0.0149,
      "step": 59880
    },
    {
      "epoch": 7.215662650602409,
      "grad_norm": 0.0007848661043681204,
      "learning_rate": 5.568674698795181e-06,
      "loss": 0.0033,
      "step": 59890
    },
    {
      "epoch": 7.216867469879518,
      "grad_norm": 0.0008735942537896335,
      "learning_rate": 5.566265060240964e-06,
      "loss": 0.0039,
      "step": 59900
    },
    {
      "epoch": 7.218072289156627,
      "grad_norm": 0.18138891458511353,
      "learning_rate": 5.563855421686748e-06,
      "loss": 0.0118,
      "step": 59910
    },
    {
      "epoch": 7.219277108433735,
      "grad_norm": 1.9059292078018188,
      "learning_rate": 5.5614457831325306e-06,
      "loss": 0.0419,
      "step": 59920
    },
    {
      "epoch": 7.220481927710844,
      "grad_norm": 0.24400047957897186,
      "learning_rate": 5.559036144578314e-06,
      "loss": 0.0025,
      "step": 59930
    },
    {
      "epoch": 7.2216867469879515,
      "grad_norm": 0.0008436130010522902,
      "learning_rate": 5.556626506024096e-06,
      "loss": 0.0207,
      "step": 59940
    },
    {
      "epoch": 7.22289156626506,
      "grad_norm": 0.0010449341498315334,
      "learning_rate": 5.55421686746988e-06,
      "loss": 0.0003,
      "step": 59950
    },
    {
      "epoch": 7.224096385542168,
      "grad_norm": 0.00099443388171494,
      "learning_rate": 5.551807228915663e-06,
      "loss": 0.0532,
      "step": 59960
    },
    {
      "epoch": 7.225301204819277,
      "grad_norm": 0.0013509043492376804,
      "learning_rate": 5.5493975903614464e-06,
      "loss": 0.0056,
      "step": 59970
    },
    {
      "epoch": 7.226506024096386,
      "grad_norm": 5.0238142013549805,
      "learning_rate": 5.546987951807229e-06,
      "loss": 0.0437,
      "step": 59980
    },
    {
      "epoch": 7.227710843373494,
      "grad_norm": 0.589706301689148,
      "learning_rate": 5.544578313253013e-06,
      "loss": 0.0122,
      "step": 59990
    },
    {
      "epoch": 7.228915662650603,
      "grad_norm": 0.0010341579327359796,
      "learning_rate": 5.542168674698796e-06,
      "loss": 0.0097,
      "step": 60000
    },
    {
      "epoch": 7.2301204819277105,
      "grad_norm": 0.0034485645592212677,
      "learning_rate": 5.539759036144578e-06,
      "loss": 0.0048,
      "step": 60010
    },
    {
      "epoch": 7.231325301204819,
      "grad_norm": 0.26217585802078247,
      "learning_rate": 5.5373493975903615e-06,
      "loss": 0.0211,
      "step": 60020
    },
    {
      "epoch": 7.232530120481928,
      "grad_norm": 0.015106447041034698,
      "learning_rate": 5.5349397590361455e-06,
      "loss": 0.0074,
      "step": 60030
    },
    {
      "epoch": 7.233734939759036,
      "grad_norm": 0.005622141994535923,
      "learning_rate": 5.532530120481928e-06,
      "loss": 0.013,
      "step": 60040
    },
    {
      "epoch": 7.234939759036145,
      "grad_norm": 0.0006186370155774057,
      "learning_rate": 5.530120481927711e-06,
      "loss": 0.0072,
      "step": 60050
    },
    {
      "epoch": 7.236144578313253,
      "grad_norm": 1.9736157655715942,
      "learning_rate": 5.527710843373495e-06,
      "loss": 0.0224,
      "step": 60060
    },
    {
      "epoch": 7.2373493975903616,
      "grad_norm": 1.3256042003631592,
      "learning_rate": 5.525301204819278e-06,
      "loss": 0.0152,
      "step": 60070
    },
    {
      "epoch": 7.2385542168674695,
      "grad_norm": 0.0012516751885414124,
      "learning_rate": 5.5228915662650605e-06,
      "loss": 0.0508,
      "step": 60080
    },
    {
      "epoch": 7.239759036144578,
      "grad_norm": 0.14526355266571045,
      "learning_rate": 5.520481927710844e-06,
      "loss": 0.0269,
      "step": 60090
    },
    {
      "epoch": 7.240963855421687,
      "grad_norm": 0.01418309286236763,
      "learning_rate": 5.518072289156628e-06,
      "loss": 0.0212,
      "step": 60100
    },
    {
      "epoch": 7.242168674698795,
      "grad_norm": 0.007213981356471777,
      "learning_rate": 5.51566265060241e-06,
      "loss": 0.0014,
      "step": 60110
    },
    {
      "epoch": 7.243373493975904,
      "grad_norm": 0.005840418394654989,
      "learning_rate": 5.513253012048193e-06,
      "loss": 0.0433,
      "step": 60120
    },
    {
      "epoch": 7.244578313253012,
      "grad_norm": 0.6262971758842468,
      "learning_rate": 5.5108433734939756e-06,
      "loss": 0.0088,
      "step": 60130
    },
    {
      "epoch": 7.2457831325301205,
      "grad_norm": 0.010109055787324905,
      "learning_rate": 5.50843373493976e-06,
      "loss": 0.0362,
      "step": 60140
    },
    {
      "epoch": 7.246987951807229,
      "grad_norm": 0.0025534185115247965,
      "learning_rate": 5.506024096385543e-06,
      "loss": 0.0317,
      "step": 60150
    },
    {
      "epoch": 7.248192771084337,
      "grad_norm": 2.016387462615967,
      "learning_rate": 5.503614457831326e-06,
      "loss": 0.0316,
      "step": 60160
    },
    {
      "epoch": 7.249397590361446,
      "grad_norm": 0.001958751119673252,
      "learning_rate": 5.501204819277108e-06,
      "loss": 0.0204,
      "step": 60170
    },
    {
      "epoch": 7.250602409638554,
      "grad_norm": 0.0637417584657669,
      "learning_rate": 5.498795180722892e-06,
      "loss": 0.0114,
      "step": 60180
    },
    {
      "epoch": 7.251807228915663,
      "grad_norm": 0.005877112038433552,
      "learning_rate": 5.4963855421686755e-06,
      "loss": 0.0078,
      "step": 60190
    },
    {
      "epoch": 7.253012048192771,
      "grad_norm": 5.185661315917969,
      "learning_rate": 5.493975903614458e-06,
      "loss": 0.0353,
      "step": 60200
    },
    {
      "epoch": 7.2542168674698795,
      "grad_norm": 1.2163829803466797,
      "learning_rate": 5.491566265060242e-06,
      "loss": 0.0371,
      "step": 60210
    },
    {
      "epoch": 7.255421686746988,
      "grad_norm": 0.4777577519416809,
      "learning_rate": 5.489156626506025e-06,
      "loss": 0.0055,
      "step": 60220
    },
    {
      "epoch": 7.256626506024096,
      "grad_norm": 0.001650680205784738,
      "learning_rate": 5.486746987951807e-06,
      "loss": 0.0108,
      "step": 60230
    },
    {
      "epoch": 7.257831325301205,
      "grad_norm": 0.0021864748559892178,
      "learning_rate": 5.4843373493975905e-06,
      "loss": 0.0087,
      "step": 60240
    },
    {
      "epoch": 7.259036144578313,
      "grad_norm": 0.4870187044143677,
      "learning_rate": 5.4819277108433745e-06,
      "loss": 0.0187,
      "step": 60250
    },
    {
      "epoch": 7.260240963855422,
      "grad_norm": 0.052458081394433975,
      "learning_rate": 5.479518072289157e-06,
      "loss": 0.0319,
      "step": 60260
    },
    {
      "epoch": 7.2614457831325305,
      "grad_norm": 3.925682544708252,
      "learning_rate": 5.47710843373494e-06,
      "loss": 0.0435,
      "step": 60270
    },
    {
      "epoch": 7.2626506024096384,
      "grad_norm": 0.0013580408412963152,
      "learning_rate": 5.474698795180723e-06,
      "loss": 0.0011,
      "step": 60280
    },
    {
      "epoch": 7.263855421686747,
      "grad_norm": 0.10093636810779572,
      "learning_rate": 5.472289156626507e-06,
      "loss": 0.0402,
      "step": 60290
    },
    {
      "epoch": 7.265060240963855,
      "grad_norm": 0.0008936352096498013,
      "learning_rate": 5.4698795180722896e-06,
      "loss": 0.0099,
      "step": 60300
    },
    {
      "epoch": 7.266265060240964,
      "grad_norm": 0.009887343272566795,
      "learning_rate": 5.467469879518073e-06,
      "loss": 0.0044,
      "step": 60310
    },
    {
      "epoch": 7.267469879518072,
      "grad_norm": 0.11647262424230576,
      "learning_rate": 5.465060240963855e-06,
      "loss": 0.0215,
      "step": 60320
    },
    {
      "epoch": 7.268674698795181,
      "grad_norm": 0.0047487253323197365,
      "learning_rate": 5.462650602409639e-06,
      "loss": 0.0191,
      "step": 60330
    },
    {
      "epoch": 7.2698795180722895,
      "grad_norm": 0.0010127343703061342,
      "learning_rate": 5.460240963855422e-06,
      "loss": 0.0276,
      "step": 60340
    },
    {
      "epoch": 7.271084337349397,
      "grad_norm": 0.36856311559677124,
      "learning_rate": 5.457831325301205e-06,
      "loss": 0.0168,
      "step": 60350
    },
    {
      "epoch": 7.272289156626506,
      "grad_norm": 4.399930477142334,
      "learning_rate": 5.455421686746989e-06,
      "loss": 0.0194,
      "step": 60360
    },
    {
      "epoch": 7.273493975903614,
      "grad_norm": 0.006387665402144194,
      "learning_rate": 5.453012048192772e-06,
      "loss": 0.005,
      "step": 60370
    },
    {
      "epoch": 7.274698795180723,
      "grad_norm": 0.02158655971288681,
      "learning_rate": 5.450602409638555e-06,
      "loss": 0.0015,
      "step": 60380
    },
    {
      "epoch": 7.275903614457832,
      "grad_norm": 1.7861666679382324,
      "learning_rate": 5.448192771084337e-06,
      "loss": 0.0183,
      "step": 60390
    },
    {
      "epoch": 7.27710843373494,
      "grad_norm": 0.0017728692619130015,
      "learning_rate": 5.445783132530121e-06,
      "loss": 0.0245,
      "step": 60400
    },
    {
      "epoch": 7.2783132530120485,
      "grad_norm": 0.00383660476654768,
      "learning_rate": 5.4433734939759045e-06,
      "loss": 0.0333,
      "step": 60410
    },
    {
      "epoch": 7.279518072289156,
      "grad_norm": 1.8462169170379639,
      "learning_rate": 5.440963855421687e-06,
      "loss": 0.0131,
      "step": 60420
    },
    {
      "epoch": 7.280722891566265,
      "grad_norm": 0.5605445504188538,
      "learning_rate": 5.43855421686747e-06,
      "loss": 0.0245,
      "step": 60430
    },
    {
      "epoch": 7.281927710843373,
      "grad_norm": 2.34602952003479,
      "learning_rate": 5.436144578313254e-06,
      "loss": 0.0213,
      "step": 60440
    },
    {
      "epoch": 7.283132530120482,
      "grad_norm": 0.19532403349876404,
      "learning_rate": 5.433734939759036e-06,
      "loss": 0.048,
      "step": 60450
    },
    {
      "epoch": 7.284337349397591,
      "grad_norm": 0.001916448469273746,
      "learning_rate": 5.4313253012048195e-06,
      "loss": 0.0102,
      "step": 60460
    },
    {
      "epoch": 7.285542168674699,
      "grad_norm": 1.3498358726501465,
      "learning_rate": 5.428915662650603e-06,
      "loss": 0.0217,
      "step": 60470
    },
    {
      "epoch": 7.286746987951807,
      "grad_norm": 1.9402854442596436,
      "learning_rate": 5.426506024096386e-06,
      "loss": 0.0311,
      "step": 60480
    },
    {
      "epoch": 7.287951807228915,
      "grad_norm": 1.1885439157485962,
      "learning_rate": 5.424096385542169e-06,
      "loss": 0.0388,
      "step": 60490
    },
    {
      "epoch": 7.289156626506024,
      "grad_norm": 0.9523829817771912,
      "learning_rate": 5.421686746987952e-06,
      "loss": 0.0085,
      "step": 60500
    },
    {
      "epoch": 7.290361445783133,
      "grad_norm": 0.0012853206135332584,
      "learning_rate": 5.419277108433736e-06,
      "loss": 0.0137,
      "step": 60510
    },
    {
      "epoch": 7.291566265060241,
      "grad_norm": 0.5419250726699829,
      "learning_rate": 5.416867469879519e-06,
      "loss": 0.0173,
      "step": 60520
    },
    {
      "epoch": 7.29277108433735,
      "grad_norm": 0.0015888904454186559,
      "learning_rate": 5.414457831325302e-06,
      "loss": 0.0447,
      "step": 60530
    },
    {
      "epoch": 7.293975903614458,
      "grad_norm": 0.14108602702617645,
      "learning_rate": 5.412048192771084e-06,
      "loss": 0.0187,
      "step": 60540
    },
    {
      "epoch": 7.295180722891566,
      "grad_norm": 0.0012083104811608791,
      "learning_rate": 5.409638554216868e-06,
      "loss": 0.0331,
      "step": 60550
    },
    {
      "epoch": 7.296385542168674,
      "grad_norm": 1.952214002609253,
      "learning_rate": 5.407228915662651e-06,
      "loss": 0.0187,
      "step": 60560
    },
    {
      "epoch": 7.297590361445783,
      "grad_norm": 0.022935418412089348,
      "learning_rate": 5.404819277108434e-06,
      "loss": 0.0068,
      "step": 60570
    },
    {
      "epoch": 7.298795180722892,
      "grad_norm": 1.3268616199493408,
      "learning_rate": 5.402409638554217e-06,
      "loss": 0.0044,
      "step": 60580
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.0012377030216157436,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.0467,
      "step": 60590
    },
    {
      "epoch": 7.301204819277109,
      "grad_norm": 5.117131233215332,
      "learning_rate": 5.397590361445784e-06,
      "loss": 0.0251,
      "step": 60600
    },
    {
      "epoch": 7.3024096385542165,
      "grad_norm": 0.0024745273403823376,
      "learning_rate": 5.395180722891566e-06,
      "loss": 0.0226,
      "step": 60610
    },
    {
      "epoch": 7.303614457831325,
      "grad_norm": 0.001051065162755549,
      "learning_rate": 5.3927710843373495e-06,
      "loss": 0.0187,
      "step": 60620
    },
    {
      "epoch": 7.304819277108434,
      "grad_norm": 0.4779062867164612,
      "learning_rate": 5.3903614457831335e-06,
      "loss": 0.0206,
      "step": 60630
    },
    {
      "epoch": 7.306024096385542,
      "grad_norm": 5.143645763397217,
      "learning_rate": 5.387951807228916e-06,
      "loss": 0.0339,
      "step": 60640
    },
    {
      "epoch": 7.307228915662651,
      "grad_norm": 0.0018807068699970841,
      "learning_rate": 5.385542168674699e-06,
      "loss": 0.0328,
      "step": 60650
    },
    {
      "epoch": 7.308433734939759,
      "grad_norm": 0.45830971002578735,
      "learning_rate": 5.383132530120483e-06,
      "loss": 0.0206,
      "step": 60660
    },
    {
      "epoch": 7.309638554216868,
      "grad_norm": 0.10374961048364639,
      "learning_rate": 5.380722891566265e-06,
      "loss": 0.0001,
      "step": 60670
    },
    {
      "epoch": 7.3108433734939755,
      "grad_norm": 0.4332669973373413,
      "learning_rate": 5.3783132530120486e-06,
      "loss": 0.046,
      "step": 60680
    },
    {
      "epoch": 7.312048192771084,
      "grad_norm": 1.689154863357544,
      "learning_rate": 5.375903614457832e-06,
      "loss": 0.0327,
      "step": 60690
    },
    {
      "epoch": 7.313253012048193,
      "grad_norm": 0.0025760317221283913,
      "learning_rate": 5.373493975903615e-06,
      "loss": 0.0224,
      "step": 60700
    },
    {
      "epoch": 7.314457831325301,
      "grad_norm": 3.154092788696289,
      "learning_rate": 5.371084337349398e-06,
      "loss": 0.0188,
      "step": 60710
    },
    {
      "epoch": 7.31566265060241,
      "grad_norm": 0.0015466271433979273,
      "learning_rate": 5.368674698795181e-06,
      "loss": 0.021,
      "step": 60720
    },
    {
      "epoch": 7.316867469879518,
      "grad_norm": 0.15448929369449615,
      "learning_rate": 5.366265060240964e-06,
      "loss": 0.0039,
      "step": 60730
    },
    {
      "epoch": 7.3180722891566266,
      "grad_norm": 0.014466368593275547,
      "learning_rate": 5.363855421686748e-06,
      "loss": 0.0679,
      "step": 60740
    },
    {
      "epoch": 7.3192771084337345,
      "grad_norm": 0.8837148547172546,
      "learning_rate": 5.361445783132531e-06,
      "loss": 0.0051,
      "step": 60750
    },
    {
      "epoch": 7.320481927710843,
      "grad_norm": 0.0021629740949720144,
      "learning_rate": 5.359036144578313e-06,
      "loss": 0.0034,
      "step": 60760
    },
    {
      "epoch": 7.321686746987952,
      "grad_norm": 0.0019476342713460326,
      "learning_rate": 5.356626506024096e-06,
      "loss": 0.0049,
      "step": 60770
    },
    {
      "epoch": 7.32289156626506,
      "grad_norm": 4.726046085357666,
      "learning_rate": 5.35421686746988e-06,
      "loss": 0.0357,
      "step": 60780
    },
    {
      "epoch": 7.324096385542169,
      "grad_norm": 0.015129612758755684,
      "learning_rate": 5.3518072289156635e-06,
      "loss": 0.0204,
      "step": 60790
    },
    {
      "epoch": 7.325301204819277,
      "grad_norm": 0.18504974246025085,
      "learning_rate": 5.349397590361446e-06,
      "loss": 0.0135,
      "step": 60800
    },
    {
      "epoch": 7.3265060240963855,
      "grad_norm": 0.00350550445728004,
      "learning_rate": 5.34698795180723e-06,
      "loss": 0.044,
      "step": 60810
    },
    {
      "epoch": 7.327710843373494,
      "grad_norm": 0.005589662119746208,
      "learning_rate": 5.344578313253013e-06,
      "loss": 0.029,
      "step": 60820
    },
    {
      "epoch": 7.328915662650602,
      "grad_norm": 0.3973468840122223,
      "learning_rate": 5.342168674698795e-06,
      "loss": 0.0531,
      "step": 60830
    },
    {
      "epoch": 7.330120481927711,
      "grad_norm": 0.007228554226458073,
      "learning_rate": 5.3397590361445785e-06,
      "loss": 0.0258,
      "step": 60840
    },
    {
      "epoch": 7.331325301204819,
      "grad_norm": 0.04118447005748749,
      "learning_rate": 5.3373493975903625e-06,
      "loss": 0.0496,
      "step": 60850
    },
    {
      "epoch": 7.332530120481928,
      "grad_norm": 0.05178101360797882,
      "learning_rate": 5.334939759036145e-06,
      "loss": 0.0345,
      "step": 60860
    },
    {
      "epoch": 7.333734939759037,
      "grad_norm": 2.0492501258850098,
      "learning_rate": 5.332530120481928e-06,
      "loss": 0.0133,
      "step": 60870
    },
    {
      "epoch": 7.3349397590361445,
      "grad_norm": 0.054857075214385986,
      "learning_rate": 5.330120481927711e-06,
      "loss": 0.0123,
      "step": 60880
    },
    {
      "epoch": 7.336144578313253,
      "grad_norm": 0.0020745655056089163,
      "learning_rate": 5.327710843373494e-06,
      "loss": 0.0117,
      "step": 60890
    },
    {
      "epoch": 7.337349397590361,
      "grad_norm": 2.2704601287841797,
      "learning_rate": 5.325301204819278e-06,
      "loss": 0.0235,
      "step": 60900
    },
    {
      "epoch": 7.33855421686747,
      "grad_norm": 1.0602350234985352,
      "learning_rate": 5.322891566265061e-06,
      "loss": 0.0343,
      "step": 60910
    },
    {
      "epoch": 7.339759036144578,
      "grad_norm": 0.03385072201490402,
      "learning_rate": 5.320481927710843e-06,
      "loss": 0.0303,
      "step": 60920
    },
    {
      "epoch": 7.340963855421687,
      "grad_norm": 3.7881195545196533,
      "learning_rate": 5.318072289156627e-06,
      "loss": 0.0624,
      "step": 60930
    },
    {
      "epoch": 7.3421686746987955,
      "grad_norm": 2.842357873916626,
      "learning_rate": 5.31566265060241e-06,
      "loss": 0.0184,
      "step": 60940
    },
    {
      "epoch": 7.343373493975903,
      "grad_norm": 0.01483946293592453,
      "learning_rate": 5.313253012048193e-06,
      "loss": 0.016,
      "step": 60950
    },
    {
      "epoch": 7.344578313253012,
      "grad_norm": 0.03179412707686424,
      "learning_rate": 5.310843373493977e-06,
      "loss": 0.0191,
      "step": 60960
    },
    {
      "epoch": 7.34578313253012,
      "grad_norm": 0.033917345106601715,
      "learning_rate": 5.30843373493976e-06,
      "loss": 0.0222,
      "step": 60970
    },
    {
      "epoch": 7.346987951807229,
      "grad_norm": 0.004665869753807783,
      "learning_rate": 5.306024096385542e-06,
      "loss": 0.0152,
      "step": 60980
    },
    {
      "epoch": 7.348192771084337,
      "grad_norm": 0.030207348987460136,
      "learning_rate": 5.303614457831325e-06,
      "loss": 0.0252,
      "step": 60990
    },
    {
      "epoch": 7.349397590361446,
      "grad_norm": 0.13121306896209717,
      "learning_rate": 5.301204819277109e-06,
      "loss": 0.0104,
      "step": 61000
    },
    {
      "epoch": 7.3506024096385545,
      "grad_norm": 1.958459734916687,
      "learning_rate": 5.2987951807228925e-06,
      "loss": 0.0347,
      "step": 61010
    },
    {
      "epoch": 7.351807228915662,
      "grad_norm": 0.004414406139403582,
      "learning_rate": 5.296385542168675e-06,
      "loss": 0.025,
      "step": 61020
    },
    {
      "epoch": 7.353012048192771,
      "grad_norm": 0.008337873965501785,
      "learning_rate": 5.293975903614458e-06,
      "loss": 0.0015,
      "step": 61030
    },
    {
      "epoch": 7.354216867469879,
      "grad_norm": 0.1029026061296463,
      "learning_rate": 5.291566265060242e-06,
      "loss": 0.0467,
      "step": 61040
    },
    {
      "epoch": 7.355421686746988,
      "grad_norm": 0.03566863015294075,
      "learning_rate": 5.289156626506024e-06,
      "loss": 0.0369,
      "step": 61050
    },
    {
      "epoch": 7.356626506024097,
      "grad_norm": 6.811162948608398,
      "learning_rate": 5.2867469879518075e-06,
      "loss": 0.0332,
      "step": 61060
    },
    {
      "epoch": 7.357831325301205,
      "grad_norm": 0.03389730304479599,
      "learning_rate": 5.28433734939759e-06,
      "loss": 0.0188,
      "step": 61070
    },
    {
      "epoch": 7.3590361445783135,
      "grad_norm": 0.8374112248420715,
      "learning_rate": 5.281927710843374e-06,
      "loss": 0.0099,
      "step": 61080
    },
    {
      "epoch": 7.360240963855421,
      "grad_norm": 2.4593701362609863,
      "learning_rate": 5.279518072289157e-06,
      "loss": 0.0186,
      "step": 61090
    },
    {
      "epoch": 7.36144578313253,
      "grad_norm": 0.1152537390589714,
      "learning_rate": 5.27710843373494e-06,
      "loss": 0.0137,
      "step": 61100
    },
    {
      "epoch": 7.362650602409639,
      "grad_norm": 0.012541336007416248,
      "learning_rate": 5.2746987951807234e-06,
      "loss": 0.0129,
      "step": 61110
    },
    {
      "epoch": 7.363855421686747,
      "grad_norm": 2.448298215866089,
      "learning_rate": 5.272289156626507e-06,
      "loss": 0.0483,
      "step": 61120
    },
    {
      "epoch": 7.365060240963856,
      "grad_norm": 0.968468427658081,
      "learning_rate": 5.26987951807229e-06,
      "loss": 0.003,
      "step": 61130
    },
    {
      "epoch": 7.366265060240964,
      "grad_norm": 0.02513008564710617,
      "learning_rate": 5.267469879518072e-06,
      "loss": 0.0169,
      "step": 61140
    },
    {
      "epoch": 7.367469879518072,
      "grad_norm": 2.188117027282715,
      "learning_rate": 5.265060240963856e-06,
      "loss": 0.03,
      "step": 61150
    },
    {
      "epoch": 7.36867469879518,
      "grad_norm": 0.015393412671983242,
      "learning_rate": 5.262650602409639e-06,
      "loss": 0.0238,
      "step": 61160
    },
    {
      "epoch": 7.369879518072289,
      "grad_norm": 0.047459814697504044,
      "learning_rate": 5.260240963855422e-06,
      "loss": 0.0046,
      "step": 61170
    },
    {
      "epoch": 7.371084337349398,
      "grad_norm": 0.021589109674096107,
      "learning_rate": 5.257831325301205e-06,
      "loss": 0.0354,
      "step": 61180
    },
    {
      "epoch": 7.372289156626506,
      "grad_norm": 0.019668057560920715,
      "learning_rate": 5.255421686746989e-06,
      "loss": 0.0006,
      "step": 61190
    },
    {
      "epoch": 7.373493975903615,
      "grad_norm": 0.003986145835369825,
      "learning_rate": 5.253012048192771e-06,
      "loss": 0.0138,
      "step": 61200
    },
    {
      "epoch": 7.374698795180723,
      "grad_norm": 0.4000520706176758,
      "learning_rate": 5.250602409638554e-06,
      "loss": 0.0163,
      "step": 61210
    },
    {
      "epoch": 7.375903614457831,
      "grad_norm": 0.005917545408010483,
      "learning_rate": 5.248192771084338e-06,
      "loss": 0.0188,
      "step": 61220
    },
    {
      "epoch": 7.377108433734939,
      "grad_norm": 1.8292841911315918,
      "learning_rate": 5.2457831325301215e-06,
      "loss": 0.02,
      "step": 61230
    },
    {
      "epoch": 7.378313253012048,
      "grad_norm": 2.2351245880126953,
      "learning_rate": 5.243373493975904e-06,
      "loss": 0.0286,
      "step": 61240
    },
    {
      "epoch": 7.379518072289157,
      "grad_norm": 0.003296059789136052,
      "learning_rate": 5.240963855421687e-06,
      "loss": 0.0155,
      "step": 61250
    },
    {
      "epoch": 7.380722891566265,
      "grad_norm": 0.001465262146666646,
      "learning_rate": 5.238554216867471e-06,
      "loss": 0.0043,
      "step": 61260
    },
    {
      "epoch": 7.381927710843374,
      "grad_norm": 0.004229886922985315,
      "learning_rate": 5.236144578313253e-06,
      "loss": 0.0024,
      "step": 61270
    },
    {
      "epoch": 7.3831325301204815,
      "grad_norm": 1.3408294916152954,
      "learning_rate": 5.2337349397590366e-06,
      "loss": 0.0278,
      "step": 61280
    },
    {
      "epoch": 7.38433734939759,
      "grad_norm": 0.27716904878616333,
      "learning_rate": 5.231325301204819e-06,
      "loss": 0.0471,
      "step": 61290
    },
    {
      "epoch": 7.385542168674699,
      "grad_norm": 11.394965171813965,
      "learning_rate": 5.228915662650603e-06,
      "loss": 0.0228,
      "step": 61300
    },
    {
      "epoch": 7.386746987951807,
      "grad_norm": 4.686629772186279,
      "learning_rate": 5.226506024096386e-06,
      "loss": 0.0144,
      "step": 61310
    },
    {
      "epoch": 7.387951807228916,
      "grad_norm": 0.2561948895454407,
      "learning_rate": 5.224096385542169e-06,
      "loss": 0.0086,
      "step": 61320
    },
    {
      "epoch": 7.389156626506024,
      "grad_norm": 0.016922658309340477,
      "learning_rate": 5.221686746987952e-06,
      "loss": 0.0168,
      "step": 61330
    },
    {
      "epoch": 7.390361445783133,
      "grad_norm": 0.0013111559674143791,
      "learning_rate": 5.219277108433736e-06,
      "loss": 0.0219,
      "step": 61340
    },
    {
      "epoch": 7.391566265060241,
      "grad_norm": 0.001790946931578219,
      "learning_rate": 5.216867469879519e-06,
      "loss": 0.0006,
      "step": 61350
    },
    {
      "epoch": 7.392771084337349,
      "grad_norm": 0.014467215165495872,
      "learning_rate": 5.214457831325301e-06,
      "loss": 0.0134,
      "step": 61360
    },
    {
      "epoch": 7.393975903614458,
      "grad_norm": 0.12107013165950775,
      "learning_rate": 5.212048192771085e-06,
      "loss": 0.032,
      "step": 61370
    },
    {
      "epoch": 7.395180722891566,
      "grad_norm": 0.0013248430332168937,
      "learning_rate": 5.209638554216868e-06,
      "loss": 0.0002,
      "step": 61380
    },
    {
      "epoch": 7.396385542168675,
      "grad_norm": 6.3412957191467285,
      "learning_rate": 5.207228915662651e-06,
      "loss": 0.027,
      "step": 61390
    },
    {
      "epoch": 7.397590361445783,
      "grad_norm": 0.0026729342062026262,
      "learning_rate": 5.204819277108434e-06,
      "loss": 0.0114,
      "step": 61400
    },
    {
      "epoch": 7.3987951807228916,
      "grad_norm": 0.013454945757985115,
      "learning_rate": 5.202409638554218e-06,
      "loss": 0.0578,
      "step": 61410
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.002155288588255644,
      "learning_rate": 5.2e-06,
      "loss": 0.016,
      "step": 61420
    },
    {
      "epoch": 7.401204819277108,
      "grad_norm": 0.005231942515820265,
      "learning_rate": 5.197590361445783e-06,
      "loss": 0.0063,
      "step": 61430
    },
    {
      "epoch": 7.402409638554217,
      "grad_norm": 0.017480768263339996,
      "learning_rate": 5.1951807228915665e-06,
      "loss": 0.0446,
      "step": 61440
    },
    {
      "epoch": 7.403614457831325,
      "grad_norm": 0.021219272166490555,
      "learning_rate": 5.1927710843373506e-06,
      "loss": 0.0121,
      "step": 61450
    },
    {
      "epoch": 7.404819277108434,
      "grad_norm": 0.005162115208804607,
      "learning_rate": 5.190361445783133e-06,
      "loss": 0.0392,
      "step": 61460
    },
    {
      "epoch": 7.406024096385542,
      "grad_norm": 0.3253818154335022,
      "learning_rate": 5.187951807228916e-06,
      "loss": 0.015,
      "step": 61470
    },
    {
      "epoch": 7.4072289156626505,
      "grad_norm": 3.771106481552124,
      "learning_rate": 5.185542168674698e-06,
      "loss": 0.0347,
      "step": 61480
    },
    {
      "epoch": 7.408433734939759,
      "grad_norm": 1.3132909536361694,
      "learning_rate": 5.183132530120482e-06,
      "loss": 0.0109,
      "step": 61490
    },
    {
      "epoch": 7.409638554216867,
      "grad_norm": 0.04937291145324707,
      "learning_rate": 5.180722891566266e-06,
      "loss": 0.0238,
      "step": 61500
    },
    {
      "epoch": 7.410843373493976,
      "grad_norm": 0.0018854427617043257,
      "learning_rate": 5.178313253012048e-06,
      "loss": 0.0018,
      "step": 61510
    },
    {
      "epoch": 7.412048192771084,
      "grad_norm": 0.005773807410150766,
      "learning_rate": 5.175903614457832e-06,
      "loss": 0.0177,
      "step": 61520
    },
    {
      "epoch": 7.413253012048193,
      "grad_norm": 0.0076085957698524,
      "learning_rate": 5.173493975903615e-06,
      "loss": 0.0581,
      "step": 61530
    },
    {
      "epoch": 7.414457831325302,
      "grad_norm": 0.0076952604576945305,
      "learning_rate": 5.171084337349398e-06,
      "loss": 0.0062,
      "step": 61540
    },
    {
      "epoch": 7.4156626506024095,
      "grad_norm": 2.047975778579712,
      "learning_rate": 5.168674698795181e-06,
      "loss": 0.0251,
      "step": 61550
    },
    {
      "epoch": 7.416867469879518,
      "grad_norm": 0.0046589914709329605,
      "learning_rate": 5.166265060240965e-06,
      "loss": 0.0369,
      "step": 61560
    },
    {
      "epoch": 7.418072289156626,
      "grad_norm": 0.01979864574968815,
      "learning_rate": 5.163855421686748e-06,
      "loss": 0.0145,
      "step": 61570
    },
    {
      "epoch": 7.419277108433735,
      "grad_norm": 0.01496097445487976,
      "learning_rate": 5.16144578313253e-06,
      "loss": 0.0358,
      "step": 61580
    },
    {
      "epoch": 7.420481927710844,
      "grad_norm": 0.2306571751832962,
      "learning_rate": 5.159036144578313e-06,
      "loss": 0.0139,
      "step": 61590
    },
    {
      "epoch": 7.421686746987952,
      "grad_norm": 1.9027961492538452,
      "learning_rate": 5.156626506024097e-06,
      "loss": 0.0225,
      "step": 61600
    },
    {
      "epoch": 7.4228915662650605,
      "grad_norm": 0.14736612141132355,
      "learning_rate": 5.15421686746988e-06,
      "loss": 0.018,
      "step": 61610
    },
    {
      "epoch": 7.424096385542168,
      "grad_norm": 6.267617225646973,
      "learning_rate": 5.151807228915663e-06,
      "loss": 0.0512,
      "step": 61620
    },
    {
      "epoch": 7.425301204819277,
      "grad_norm": 8.121644020080566,
      "learning_rate": 5.149397590361446e-06,
      "loss": 0.014,
      "step": 61630
    },
    {
      "epoch": 7.426506024096385,
      "grad_norm": 0.30430740118026733,
      "learning_rate": 5.14698795180723e-06,
      "loss": 0.0218,
      "step": 61640
    },
    {
      "epoch": 7.427710843373494,
      "grad_norm": 0.472626656293869,
      "learning_rate": 5.144578313253012e-06,
      "loss": 0.0115,
      "step": 61650
    },
    {
      "epoch": 7.428915662650603,
      "grad_norm": 3.6195807456970215,
      "learning_rate": 5.1421686746987956e-06,
      "loss": 0.0302,
      "step": 61660
    },
    {
      "epoch": 7.430120481927711,
      "grad_norm": 0.5684589147567749,
      "learning_rate": 5.13975903614458e-06,
      "loss": 0.0243,
      "step": 61670
    },
    {
      "epoch": 7.4313253012048195,
      "grad_norm": 0.010967675596475601,
      "learning_rate": 5.137349397590362e-06,
      "loss": 0.0017,
      "step": 61680
    },
    {
      "epoch": 7.432530120481927,
      "grad_norm": 1.9816460609436035,
      "learning_rate": 5.134939759036145e-06,
      "loss": 0.0203,
      "step": 61690
    },
    {
      "epoch": 7.433734939759036,
      "grad_norm": 0.3969421982765198,
      "learning_rate": 5.132530120481927e-06,
      "loss": 0.0103,
      "step": 61700
    },
    {
      "epoch": 7.434939759036144,
      "grad_norm": 0.023016732186079025,
      "learning_rate": 5.1301204819277114e-06,
      "loss": 0.0148,
      "step": 61710
    },
    {
      "epoch": 7.436144578313253,
      "grad_norm": 3.8559458255767822,
      "learning_rate": 5.127710843373495e-06,
      "loss": 0.023,
      "step": 61720
    },
    {
      "epoch": 7.437349397590362,
      "grad_norm": 0.004459467716515064,
      "learning_rate": 5.125301204819278e-06,
      "loss": 0.0486,
      "step": 61730
    },
    {
      "epoch": 7.43855421686747,
      "grad_norm": 0.0064480979926884174,
      "learning_rate": 5.12289156626506e-06,
      "loss": 0.0501,
      "step": 61740
    },
    {
      "epoch": 7.4397590361445785,
      "grad_norm": 1.4993915557861328,
      "learning_rate": 5.120481927710844e-06,
      "loss": 0.0321,
      "step": 61750
    },
    {
      "epoch": 7.440963855421686,
      "grad_norm": 1.3020212650299072,
      "learning_rate": 5.118072289156627e-06,
      "loss": 0.0104,
      "step": 61760
    },
    {
      "epoch": 7.442168674698795,
      "grad_norm": 0.32006195187568665,
      "learning_rate": 5.11566265060241e-06,
      "loss": 0.0174,
      "step": 61770
    },
    {
      "epoch": 7.443373493975904,
      "grad_norm": 0.038585953414440155,
      "learning_rate": 5.113253012048193e-06,
      "loss": 0.0031,
      "step": 61780
    },
    {
      "epoch": 7.444578313253012,
      "grad_norm": 0.031429316848516464,
      "learning_rate": 5.110843373493977e-06,
      "loss": 0.0012,
      "step": 61790
    },
    {
      "epoch": 7.445783132530121,
      "grad_norm": 0.023213185369968414,
      "learning_rate": 5.108433734939759e-06,
      "loss": 0.0066,
      "step": 61800
    },
    {
      "epoch": 7.446987951807229,
      "grad_norm": 0.002623161766678095,
      "learning_rate": 5.106024096385542e-06,
      "loss": 0.0164,
      "step": 61810
    },
    {
      "epoch": 7.448192771084337,
      "grad_norm": 0.014316254295408726,
      "learning_rate": 5.103614457831326e-06,
      "loss": 0.0177,
      "step": 61820
    },
    {
      "epoch": 7.449397590361446,
      "grad_norm": 1.4430948495864868,
      "learning_rate": 5.101204819277109e-06,
      "loss": 0.0105,
      "step": 61830
    },
    {
      "epoch": 7.450602409638554,
      "grad_norm": 1.5842578411102295,
      "learning_rate": 5.098795180722892e-06,
      "loss": 0.0098,
      "step": 61840
    },
    {
      "epoch": 7.451807228915663,
      "grad_norm": 0.04675311967730522,
      "learning_rate": 5.096385542168675e-06,
      "loss": 0.0049,
      "step": 61850
    },
    {
      "epoch": 7.453012048192771,
      "grad_norm": 0.002487592166289687,
      "learning_rate": 5.093975903614459e-06,
      "loss": 0.0301,
      "step": 61860
    },
    {
      "epoch": 7.45421686746988,
      "grad_norm": 1.8077291250228882,
      "learning_rate": 5.091566265060241e-06,
      "loss": 0.0136,
      "step": 61870
    },
    {
      "epoch": 7.455421686746988,
      "grad_norm": 1.6359678506851196,
      "learning_rate": 5.089156626506025e-06,
      "loss": 0.0078,
      "step": 61880
    },
    {
      "epoch": 7.456626506024096,
      "grad_norm": 0.0414419062435627,
      "learning_rate": 5.086746987951807e-06,
      "loss": 0.0014,
      "step": 61890
    },
    {
      "epoch": 7.457831325301205,
      "grad_norm": 0.002351572271436453,
      "learning_rate": 5.084337349397591e-06,
      "loss": 0.0157,
      "step": 61900
    },
    {
      "epoch": 7.459036144578313,
      "grad_norm": 6.431338787078857,
      "learning_rate": 5.081927710843374e-06,
      "loss": 0.0113,
      "step": 61910
    },
    {
      "epoch": 7.460240963855422,
      "grad_norm": 1.138753890991211,
      "learning_rate": 5.0795180722891564e-06,
      "loss": 0.0382,
      "step": 61920
    },
    {
      "epoch": 7.46144578313253,
      "grad_norm": 7.532820701599121,
      "learning_rate": 5.07710843373494e-06,
      "loss": 0.0182,
      "step": 61930
    },
    {
      "epoch": 7.462650602409639,
      "grad_norm": 0.2903655767440796,
      "learning_rate": 5.074698795180724e-06,
      "loss": 0.0115,
      "step": 61940
    },
    {
      "epoch": 7.4638554216867465,
      "grad_norm": 0.0035770032554864883,
      "learning_rate": 5.072289156626507e-06,
      "loss": 0.0129,
      "step": 61950
    },
    {
      "epoch": 7.465060240963855,
      "grad_norm": 0.24611875414848328,
      "learning_rate": 5.069879518072289e-06,
      "loss": 0.0112,
      "step": 61960
    },
    {
      "epoch": 7.466265060240964,
      "grad_norm": 3.2683212757110596,
      "learning_rate": 5.067469879518073e-06,
      "loss": 0.0868,
      "step": 61970
    },
    {
      "epoch": 7.467469879518072,
      "grad_norm": 0.001917260349728167,
      "learning_rate": 5.065060240963856e-06,
      "loss": 0.0061,
      "step": 61980
    },
    {
      "epoch": 7.468674698795181,
      "grad_norm": 0.5372126698493958,
      "learning_rate": 5.062650602409639e-06,
      "loss": 0.0122,
      "step": 61990
    },
    {
      "epoch": 7.469879518072289,
      "grad_norm": 0.007960268296301365,
      "learning_rate": 5.060240963855422e-06,
      "loss": 0.0235,
      "step": 62000
    },
    {
      "epoch": 7.471084337349398,
      "grad_norm": 0.0019954105373471975,
      "learning_rate": 5.057831325301206e-06,
      "loss": 0.0131,
      "step": 62010
    },
    {
      "epoch": 7.472289156626506,
      "grad_norm": 0.011310344561934471,
      "learning_rate": 5.055421686746988e-06,
      "loss": 0.0021,
      "step": 62020
    },
    {
      "epoch": 7.473493975903614,
      "grad_norm": 0.009718379937112331,
      "learning_rate": 5.053012048192771e-06,
      "loss": 0.0349,
      "step": 62030
    },
    {
      "epoch": 7.474698795180723,
      "grad_norm": 0.003535317489877343,
      "learning_rate": 5.0506024096385546e-06,
      "loss": 0.0078,
      "step": 62040
    },
    {
      "epoch": 7.475903614457831,
      "grad_norm": 0.003634077263996005,
      "learning_rate": 5.048192771084338e-06,
      "loss": 0.0039,
      "step": 62050
    },
    {
      "epoch": 7.47710843373494,
      "grad_norm": 2.1872506141662598,
      "learning_rate": 5.045783132530121e-06,
      "loss": 0.0249,
      "step": 62060
    },
    {
      "epoch": 7.478313253012049,
      "grad_norm": 0.41745468974113464,
      "learning_rate": 5.043373493975904e-06,
      "loss": 0.0119,
      "step": 62070
    },
    {
      "epoch": 7.4795180722891565,
      "grad_norm": 1.70167875289917,
      "learning_rate": 5.040963855421686e-06,
      "loss": 0.0142,
      "step": 62080
    },
    {
      "epoch": 7.480722891566265,
      "grad_norm": 1.3804486989974976,
      "learning_rate": 5.0385542168674704e-06,
      "loss": 0.0209,
      "step": 62090
    },
    {
      "epoch": 7.481927710843373,
      "grad_norm": 0.045647185295820236,
      "learning_rate": 5.036144578313254e-06,
      "loss": 0.0106,
      "step": 62100
    },
    {
      "epoch": 7.483132530120482,
      "grad_norm": 0.010947275906801224,
      "learning_rate": 5.033734939759036e-06,
      "loss": 0.018,
      "step": 62110
    },
    {
      "epoch": 7.48433734939759,
      "grad_norm": 1.5934514999389648,
      "learning_rate": 5.03132530120482e-06,
      "loss": 0.014,
      "step": 62120
    },
    {
      "epoch": 7.485542168674699,
      "grad_norm": 0.044325754046440125,
      "learning_rate": 5.028915662650603e-06,
      "loss": 0.0147,
      "step": 62130
    },
    {
      "epoch": 7.486746987951808,
      "grad_norm": 0.0022204695269465446,
      "learning_rate": 5.0265060240963855e-06,
      "loss": 0.0241,
      "step": 62140
    },
    {
      "epoch": 7.4879518072289155,
      "grad_norm": 0.0018640902126207948,
      "learning_rate": 5.024096385542169e-06,
      "loss": 0.0048,
      "step": 62150
    },
    {
      "epoch": 7.489156626506024,
      "grad_norm": 0.0011930784676223993,
      "learning_rate": 5.021686746987953e-06,
      "loss": 0.0056,
      "step": 62160
    },
    {
      "epoch": 7.490361445783132,
      "grad_norm": 0.8041971921920776,
      "learning_rate": 5.019277108433736e-06,
      "loss": 0.0079,
      "step": 62170
    },
    {
      "epoch": 7.491566265060241,
      "grad_norm": 0.009039701893925667,
      "learning_rate": 5.016867469879518e-06,
      "loss": 0.0146,
      "step": 62180
    },
    {
      "epoch": 7.492771084337349,
      "grad_norm": 0.0009173064026981592,
      "learning_rate": 5.014457831325301e-06,
      "loss": 0.0042,
      "step": 62190
    },
    {
      "epoch": 7.493975903614458,
      "grad_norm": 63.645050048828125,
      "learning_rate": 5.012048192771085e-06,
      "loss": 0.0269,
      "step": 62200
    },
    {
      "epoch": 7.495180722891567,
      "grad_norm": 2.3066587448120117,
      "learning_rate": 5.009638554216868e-06,
      "loss": 0.0134,
      "step": 62210
    },
    {
      "epoch": 7.4963855421686745,
      "grad_norm": 0.031014006584882736,
      "learning_rate": 5.007228915662651e-06,
      "loss": 0.0119,
      "step": 62220
    },
    {
      "epoch": 7.497590361445783,
      "grad_norm": 0.6178232431411743,
      "learning_rate": 5.004819277108433e-06,
      "loss": 0.0139,
      "step": 62230
    },
    {
      "epoch": 7.498795180722891,
      "grad_norm": 0.1300441026687622,
      "learning_rate": 5.002409638554217e-06,
      "loss": 0.0011,
      "step": 62240
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.011791335418820381,
      "learning_rate": 5e-06,
      "loss": 0.0109,
      "step": 62250
    },
    {
      "epoch": 7.501204819277109,
      "grad_norm": 4.497748374938965,
      "learning_rate": 4.997590361445784e-06,
      "loss": 0.016,
      "step": 62260
    },
    {
      "epoch": 7.502409638554217,
      "grad_norm": 0.0008464368875138462,
      "learning_rate": 4.995180722891567e-06,
      "loss": 0.0092,
      "step": 62270
    },
    {
      "epoch": 7.5036144578313255,
      "grad_norm": 24.300058364868164,
      "learning_rate": 4.99277108433735e-06,
      "loss": 0.0528,
      "step": 62280
    },
    {
      "epoch": 7.504819277108433,
      "grad_norm": 0.19000643491744995,
      "learning_rate": 4.990361445783133e-06,
      "loss": 0.008,
      "step": 62290
    },
    {
      "epoch": 7.506024096385542,
      "grad_norm": 0.023946605622768402,
      "learning_rate": 4.987951807228916e-06,
      "loss": 0.0039,
      "step": 62300
    },
    {
      "epoch": 7.507228915662651,
      "grad_norm": 0.0008674353011883795,
      "learning_rate": 4.9855421686746995e-06,
      "loss": 0.0174,
      "step": 62310
    },
    {
      "epoch": 7.508433734939759,
      "grad_norm": 0.12249013036489487,
      "learning_rate": 4.983132530120483e-06,
      "loss": 0.0146,
      "step": 62320
    },
    {
      "epoch": 7.509638554216868,
      "grad_norm": 0.015733635053038597,
      "learning_rate": 4.980722891566265e-06,
      "loss": 0.0111,
      "step": 62330
    },
    {
      "epoch": 7.510843373493976,
      "grad_norm": 0.027209294959902763,
      "learning_rate": 4.978313253012049e-06,
      "loss": 0.0098,
      "step": 62340
    },
    {
      "epoch": 7.5120481927710845,
      "grad_norm": 0.0012880121357738972,
      "learning_rate": 4.975903614457831e-06,
      "loss": 0.0101,
      "step": 62350
    },
    {
      "epoch": 7.513253012048192,
      "grad_norm": 1.6056019067764282,
      "learning_rate": 4.973493975903615e-06,
      "loss": 0.0279,
      "step": 62360
    },
    {
      "epoch": 7.514457831325301,
      "grad_norm": 0.00658752117305994,
      "learning_rate": 4.971084337349398e-06,
      "loss": 0.0127,
      "step": 62370
    },
    {
      "epoch": 7.51566265060241,
      "grad_norm": 1.00863516330719,
      "learning_rate": 4.968674698795181e-06,
      "loss": 0.0162,
      "step": 62380
    },
    {
      "epoch": 7.516867469879518,
      "grad_norm": 1.3129147291183472,
      "learning_rate": 4.966265060240964e-06,
      "loss": 0.0172,
      "step": 62390
    },
    {
      "epoch": 7.518072289156627,
      "grad_norm": 0.37352225184440613,
      "learning_rate": 4.963855421686747e-06,
      "loss": 0.0068,
      "step": 62400
    },
    {
      "epoch": 7.519277108433735,
      "grad_norm": 0.970943033695221,
      "learning_rate": 4.96144578313253e-06,
      "loss": 0.0171,
      "step": 62410
    },
    {
      "epoch": 7.5204819277108435,
      "grad_norm": 0.0010135904885828495,
      "learning_rate": 4.9590361445783136e-06,
      "loss": 0.0007,
      "step": 62420
    },
    {
      "epoch": 7.521686746987951,
      "grad_norm": 0.0013847131049260497,
      "learning_rate": 4.956626506024097e-06,
      "loss": 0.0111,
      "step": 62430
    },
    {
      "epoch": 7.52289156626506,
      "grad_norm": 0.0009804932633414865,
      "learning_rate": 4.95421686746988e-06,
      "loss": 0.0031,
      "step": 62440
    },
    {
      "epoch": 7.524096385542169,
      "grad_norm": 0.0008490488980896771,
      "learning_rate": 4.951807228915663e-06,
      "loss": 0.0071,
      "step": 62450
    },
    {
      "epoch": 7.525301204819277,
      "grad_norm": 3.0547289848327637,
      "learning_rate": 4.949397590361446e-06,
      "loss": 0.0426,
      "step": 62460
    },
    {
      "epoch": 7.526506024096386,
      "grad_norm": 0.0006356131052598357,
      "learning_rate": 4.9469879518072294e-06,
      "loss": 0.0243,
      "step": 62470
    },
    {
      "epoch": 7.527710843373494,
      "grad_norm": 0.00600071344524622,
      "learning_rate": 4.944578313253013e-06,
      "loss": 0.0738,
      "step": 62480
    },
    {
      "epoch": 7.528915662650602,
      "grad_norm": 3.013160467147827,
      "learning_rate": 4.942168674698796e-06,
      "loss": 0.0543,
      "step": 62490
    },
    {
      "epoch": 7.530120481927711,
      "grad_norm": 0.0007967168348841369,
      "learning_rate": 4.939759036144578e-06,
      "loss": 0.0056,
      "step": 62500
    },
    {
      "epoch": 7.531325301204819,
      "grad_norm": 0.15913338959217072,
      "learning_rate": 4.937349397590362e-06,
      "loss": 0.0173,
      "step": 62510
    },
    {
      "epoch": 7.532530120481928,
      "grad_norm": 0.11372990906238556,
      "learning_rate": 4.9349397590361445e-06,
      "loss": 0.0195,
      "step": 62520
    },
    {
      "epoch": 7.533734939759036,
      "grad_norm": 0.40138643980026245,
      "learning_rate": 4.9325301204819285e-06,
      "loss": 0.0438,
      "step": 62530
    },
    {
      "epoch": 7.534939759036145,
      "grad_norm": 2.2758688926696777,
      "learning_rate": 4.930120481927711e-06,
      "loss": 0.0157,
      "step": 62540
    },
    {
      "epoch": 7.5361445783132535,
      "grad_norm": 0.3923064172267914,
      "learning_rate": 4.927710843373494e-06,
      "loss": 0.0042,
      "step": 62550
    },
    {
      "epoch": 7.537349397590361,
      "grad_norm": 0.014701982028782368,
      "learning_rate": 4.925301204819278e-06,
      "loss": 0.0054,
      "step": 62560
    },
    {
      "epoch": 7.53855421686747,
      "grad_norm": 0.016663551330566406,
      "learning_rate": 4.92289156626506e-06,
      "loss": 0.015,
      "step": 62570
    },
    {
      "epoch": 7.539759036144578,
      "grad_norm": 0.2496332824230194,
      "learning_rate": 4.920481927710844e-06,
      "loss": 0.0204,
      "step": 62580
    },
    {
      "epoch": 7.540963855421687,
      "grad_norm": 0.00158238026779145,
      "learning_rate": 4.918072289156627e-06,
      "loss": 0.0177,
      "step": 62590
    },
    {
      "epoch": 7.542168674698795,
      "grad_norm": 1.3034942150115967,
      "learning_rate": 4.91566265060241e-06,
      "loss": 0.0334,
      "step": 62600
    },
    {
      "epoch": 7.543373493975904,
      "grad_norm": 0.0030803943518549204,
      "learning_rate": 4.913253012048193e-06,
      "loss": 0.0195,
      "step": 62610
    },
    {
      "epoch": 7.544578313253012,
      "grad_norm": 0.004360445309430361,
      "learning_rate": 4.910843373493976e-06,
      "loss": 0.0161,
      "step": 62620
    },
    {
      "epoch": 7.54578313253012,
      "grad_norm": 0.0020845201797783375,
      "learning_rate": 4.908433734939759e-06,
      "loss": 0.0289,
      "step": 62630
    },
    {
      "epoch": 7.546987951807229,
      "grad_norm": 0.05954008176922798,
      "learning_rate": 4.906024096385543e-06,
      "loss": 0.0202,
      "step": 62640
    },
    {
      "epoch": 7.548192771084337,
      "grad_norm": 0.017713159322738647,
      "learning_rate": 4.903614457831326e-06,
      "loss": 0.0005,
      "step": 62650
    },
    {
      "epoch": 7.549397590361446,
      "grad_norm": 0.005514699965715408,
      "learning_rate": 4.901204819277109e-06,
      "loss": 0.0195,
      "step": 62660
    },
    {
      "epoch": 7.550602409638554,
      "grad_norm": 3.536104917526245,
      "learning_rate": 4.898795180722892e-06,
      "loss": 0.0061,
      "step": 62670
    },
    {
      "epoch": 7.551807228915663,
      "grad_norm": 1.9680253267288208,
      "learning_rate": 4.896385542168675e-06,
      "loss": 0.0211,
      "step": 62680
    },
    {
      "epoch": 7.553012048192771,
      "grad_norm": 0.0017191246151924133,
      "learning_rate": 4.893975903614458e-06,
      "loss": 0.018,
      "step": 62690
    },
    {
      "epoch": 7.554216867469879,
      "grad_norm": 1.3413302898406982,
      "learning_rate": 4.891566265060242e-06,
      "loss": 0.0065,
      "step": 62700
    },
    {
      "epoch": 7.555421686746988,
      "grad_norm": 1.9292335510253906,
      "learning_rate": 4.889156626506025e-06,
      "loss": 0.0179,
      "step": 62710
    },
    {
      "epoch": 7.556626506024096,
      "grad_norm": 0.0013692189240828156,
      "learning_rate": 4.886746987951808e-06,
      "loss": 0.0053,
      "step": 62720
    },
    {
      "epoch": 7.557831325301205,
      "grad_norm": 0.43788328766822815,
      "learning_rate": 4.884337349397591e-06,
      "loss": 0.0467,
      "step": 62730
    },
    {
      "epoch": 7.559036144578314,
      "grad_norm": 2.418771505355835,
      "learning_rate": 4.8819277108433735e-06,
      "loss": 0.0292,
      "step": 62740
    },
    {
      "epoch": 7.5602409638554215,
      "grad_norm": 1.3630990982055664,
      "learning_rate": 4.8795180722891575e-06,
      "loss": 0.029,
      "step": 62750
    },
    {
      "epoch": 7.56144578313253,
      "grad_norm": 0.0025109273847192526,
      "learning_rate": 4.87710843373494e-06,
      "loss": 0.0227,
      "step": 62760
    },
    {
      "epoch": 7.562650602409638,
      "grad_norm": 0.28436630964279175,
      "learning_rate": 4.874698795180723e-06,
      "loss": 0.0087,
      "step": 62770
    },
    {
      "epoch": 7.563855421686747,
      "grad_norm": 0.02247771807014942,
      "learning_rate": 4.872289156626506e-06,
      "loss": 0.0078,
      "step": 62780
    },
    {
      "epoch": 7.565060240963856,
      "grad_norm": 0.0031577793415635824,
      "learning_rate": 4.869879518072289e-06,
      "loss": 0.0017,
      "step": 62790
    },
    {
      "epoch": 7.566265060240964,
      "grad_norm": 0.03150572255253792,
      "learning_rate": 4.8674698795180725e-06,
      "loss": 0.0163,
      "step": 62800
    },
    {
      "epoch": 7.567469879518073,
      "grad_norm": 0.0011297150049358606,
      "learning_rate": 4.865060240963856e-06,
      "loss": 0.0217,
      "step": 62810
    },
    {
      "epoch": 7.5686746987951805,
      "grad_norm": 0.003947646357119083,
      "learning_rate": 4.862650602409639e-06,
      "loss": 0.0002,
      "step": 62820
    },
    {
      "epoch": 7.569879518072289,
      "grad_norm": 0.0017909840680658817,
      "learning_rate": 4.860240963855422e-06,
      "loss": 0.0002,
      "step": 62830
    },
    {
      "epoch": 7.571084337349397,
      "grad_norm": 2.050886392593384,
      "learning_rate": 4.857831325301205e-06,
      "loss": 0.0201,
      "step": 62840
    },
    {
      "epoch": 7.572289156626506,
      "grad_norm": 0.002313365461304784,
      "learning_rate": 4.8554216867469884e-06,
      "loss": 0.0535,
      "step": 62850
    },
    {
      "epoch": 7.573493975903615,
      "grad_norm": 0.9057863354682922,
      "learning_rate": 4.853012048192772e-06,
      "loss": 0.0028,
      "step": 62860
    },
    {
      "epoch": 7.574698795180723,
      "grad_norm": 0.0024307440035045147,
      "learning_rate": 4.850602409638555e-06,
      "loss": 0.015,
      "step": 62870
    },
    {
      "epoch": 7.575903614457832,
      "grad_norm": 0.0019270529737696052,
      "learning_rate": 4.848192771084338e-06,
      "loss": 0.035,
      "step": 62880
    },
    {
      "epoch": 7.5771084337349395,
      "grad_norm": 0.024684039875864983,
      "learning_rate": 4.845783132530121e-06,
      "loss": 0.013,
      "step": 62890
    },
    {
      "epoch": 7.578313253012048,
      "grad_norm": 0.006823945324867964,
      "learning_rate": 4.843373493975904e-06,
      "loss": 0.0445,
      "step": 62900
    },
    {
      "epoch": 7.579518072289156,
      "grad_norm": 0.6554780006408691,
      "learning_rate": 4.840963855421687e-06,
      "loss": 0.0185,
      "step": 62910
    },
    {
      "epoch": 7.580722891566265,
      "grad_norm": 2.1676998138427734,
      "learning_rate": 4.838554216867471e-06,
      "loss": 0.0223,
      "step": 62920
    },
    {
      "epoch": 7.581927710843374,
      "grad_norm": 0.004046233836561441,
      "learning_rate": 4.836144578313253e-06,
      "loss": 0.0168,
      "step": 62930
    },
    {
      "epoch": 7.583132530120482,
      "grad_norm": 0.005980961956083775,
      "learning_rate": 4.833734939759037e-06,
      "loss": 0.0261,
      "step": 62940
    },
    {
      "epoch": 7.5843373493975905,
      "grad_norm": 0.0032671198714524508,
      "learning_rate": 4.831325301204819e-06,
      "loss": 0.0011,
      "step": 62950
    },
    {
      "epoch": 7.585542168674698,
      "grad_norm": 2.9952280521392822,
      "learning_rate": 4.8289156626506025e-06,
      "loss": 0.016,
      "step": 62960
    },
    {
      "epoch": 7.586746987951807,
      "grad_norm": 0.02243349701166153,
      "learning_rate": 4.826506024096386e-06,
      "loss": 0.0467,
      "step": 62970
    },
    {
      "epoch": 7.587951807228916,
      "grad_norm": 0.014372061938047409,
      "learning_rate": 4.824096385542169e-06,
      "loss": 0.0217,
      "step": 62980
    },
    {
      "epoch": 7.589156626506024,
      "grad_norm": 11.000718116760254,
      "learning_rate": 4.821686746987953e-06,
      "loss": 0.0204,
      "step": 62990
    },
    {
      "epoch": 7.590361445783133,
      "grad_norm": 0.0058685424737632275,
      "learning_rate": 4.819277108433735e-06,
      "loss": 0.0043,
      "step": 63000
    },
    {
      "epoch": 7.591566265060241,
      "grad_norm": 2.140472173690796,
      "learning_rate": 4.816867469879518e-06,
      "loss": 0.0207,
      "step": 63010
    },
    {
      "epoch": 7.5927710843373495,
      "grad_norm": 0.2658580541610718,
      "learning_rate": 4.8144578313253016e-06,
      "loss": 0.0142,
      "step": 63020
    },
    {
      "epoch": 7.593975903614458,
      "grad_norm": 0.1189241111278534,
      "learning_rate": 4.812048192771085e-06,
      "loss": 0.0218,
      "step": 63030
    },
    {
      "epoch": 7.595180722891566,
      "grad_norm": 0.4929560422897339,
      "learning_rate": 4.809638554216868e-06,
      "loss": 0.0112,
      "step": 63040
    },
    {
      "epoch": 7.596385542168675,
      "grad_norm": 0.002424490638077259,
      "learning_rate": 4.807228915662651e-06,
      "loss": 0.0382,
      "step": 63050
    },
    {
      "epoch": 7.597590361445783,
      "grad_norm": 2.1965994834899902,
      "learning_rate": 4.804819277108434e-06,
      "loss": 0.0151,
      "step": 63060
    },
    {
      "epoch": 7.598795180722892,
      "grad_norm": 0.5551819205284119,
      "learning_rate": 4.8024096385542175e-06,
      "loss": 0.0031,
      "step": 63070
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.003939254209399223,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0458,
      "step": 63080
    },
    {
      "epoch": 7.6012048192771084,
      "grad_norm": 0.897671103477478,
      "learning_rate": 4.797590361445784e-06,
      "loss": 0.0303,
      "step": 63090
    },
    {
      "epoch": 7.602409638554217,
      "grad_norm": 1.2174137830734253,
      "learning_rate": 4.795180722891566e-06,
      "loss": 0.0076,
      "step": 63100
    },
    {
      "epoch": 7.603614457831325,
      "grad_norm": 0.003091593971475959,
      "learning_rate": 4.79277108433735e-06,
      "loss": 0.0084,
      "step": 63110
    },
    {
      "epoch": 7.604819277108434,
      "grad_norm": 2.7915735244750977,
      "learning_rate": 4.7903614457831325e-06,
      "loss": 0.0155,
      "step": 63120
    },
    {
      "epoch": 7.606024096385542,
      "grad_norm": 0.0028442060574889183,
      "learning_rate": 4.787951807228916e-06,
      "loss": 0.0657,
      "step": 63130
    },
    {
      "epoch": 7.607228915662651,
      "grad_norm": 0.0023672953248023987,
      "learning_rate": 4.7855421686747e-06,
      "loss": 0.0022,
      "step": 63140
    },
    {
      "epoch": 7.608433734939759,
      "grad_norm": 6.4606804847717285,
      "learning_rate": 4.783132530120482e-06,
      "loss": 0.0445,
      "step": 63150
    },
    {
      "epoch": 7.609638554216867,
      "grad_norm": 3.4427099227905273,
      "learning_rate": 4.780722891566266e-06,
      "loss": 0.0302,
      "step": 63160
    },
    {
      "epoch": 7.610843373493976,
      "grad_norm": 0.9942617416381836,
      "learning_rate": 4.778313253012048e-06,
      "loss": 0.0326,
      "step": 63170
    },
    {
      "epoch": 7.612048192771084,
      "grad_norm": 0.06028423085808754,
      "learning_rate": 4.7759036144578315e-06,
      "loss": 0.0252,
      "step": 63180
    },
    {
      "epoch": 7.613253012048193,
      "grad_norm": 1.5890997648239136,
      "learning_rate": 4.773493975903615e-06,
      "loss": 0.0258,
      "step": 63190
    },
    {
      "epoch": 7.614457831325301,
      "grad_norm": 1.483673095703125,
      "learning_rate": 4.771084337349398e-06,
      "loss": 0.0102,
      "step": 63200
    },
    {
      "epoch": 7.61566265060241,
      "grad_norm": 0.03924272954463959,
      "learning_rate": 4.768674698795181e-06,
      "loss": 0.05,
      "step": 63210
    },
    {
      "epoch": 7.6168674698795185,
      "grad_norm": 1.043033242225647,
      "learning_rate": 4.766265060240964e-06,
      "loss": 0.04,
      "step": 63220
    },
    {
      "epoch": 7.618072289156626,
      "grad_norm": 0.09851246327161789,
      "learning_rate": 4.763855421686747e-06,
      "loss": 0.0402,
      "step": 63230
    },
    {
      "epoch": 7.619277108433735,
      "grad_norm": 0.003244823543354869,
      "learning_rate": 4.761445783132531e-06,
      "loss": 0.0081,
      "step": 63240
    },
    {
      "epoch": 7.620481927710843,
      "grad_norm": 0.024140624329447746,
      "learning_rate": 4.759036144578314e-06,
      "loss": 0.0067,
      "step": 63250
    },
    {
      "epoch": 7.621686746987952,
      "grad_norm": 0.006565429270267487,
      "learning_rate": 4.756626506024097e-06,
      "loss": 0.047,
      "step": 63260
    },
    {
      "epoch": 7.622891566265061,
      "grad_norm": 0.11568877846002579,
      "learning_rate": 4.754216867469879e-06,
      "loss": 0.0351,
      "step": 63270
    },
    {
      "epoch": 7.624096385542169,
      "grad_norm": 0.27937307953834534,
      "learning_rate": 4.751807228915663e-06,
      "loss": 0.0038,
      "step": 63280
    },
    {
      "epoch": 7.625301204819277,
      "grad_norm": 0.007515294477343559,
      "learning_rate": 4.7493975903614465e-06,
      "loss": 0.0209,
      "step": 63290
    },
    {
      "epoch": 7.626506024096385,
      "grad_norm": 0.01238634530454874,
      "learning_rate": 4.74698795180723e-06,
      "loss": 0.0029,
      "step": 63300
    },
    {
      "epoch": 7.627710843373494,
      "grad_norm": 1.3549758195877075,
      "learning_rate": 4.744578313253013e-06,
      "loss": 0.0108,
      "step": 63310
    },
    {
      "epoch": 7.628915662650602,
      "grad_norm": 0.0045107281766831875,
      "learning_rate": 4.742168674698795e-06,
      "loss": 0.0086,
      "step": 63320
    },
    {
      "epoch": 7.630120481927711,
      "grad_norm": 26.167631149291992,
      "learning_rate": 4.739759036144579e-06,
      "loss": 0.0259,
      "step": 63330
    },
    {
      "epoch": 7.63132530120482,
      "grad_norm": 1.8224929571151733,
      "learning_rate": 4.7373493975903615e-06,
      "loss": 0.0186,
      "step": 63340
    },
    {
      "epoch": 7.632530120481928,
      "grad_norm": 0.028149917721748352,
      "learning_rate": 4.734939759036145e-06,
      "loss": 0.0026,
      "step": 63350
    },
    {
      "epoch": 7.633734939759036,
      "grad_norm": 0.10604029893875122,
      "learning_rate": 4.732530120481928e-06,
      "loss": 0.001,
      "step": 63360
    },
    {
      "epoch": 7.634939759036144,
      "grad_norm": 1.1885898113250732,
      "learning_rate": 4.730120481927711e-06,
      "loss": 0.0264,
      "step": 63370
    },
    {
      "epoch": 7.636144578313253,
      "grad_norm": 0.011620516888797283,
      "learning_rate": 4.727710843373494e-06,
      "loss": 0.0285,
      "step": 63380
    },
    {
      "epoch": 7.637349397590361,
      "grad_norm": 0.0026141402777284384,
      "learning_rate": 4.725301204819277e-06,
      "loss": 0.0078,
      "step": 63390
    },
    {
      "epoch": 7.63855421686747,
      "grad_norm": 0.0015622097998857498,
      "learning_rate": 4.7228915662650606e-06,
      "loss": 0.0318,
      "step": 63400
    },
    {
      "epoch": 7.639759036144579,
      "grad_norm": 0.34061554074287415,
      "learning_rate": 4.720481927710844e-06,
      "loss": 0.0174,
      "step": 63410
    },
    {
      "epoch": 7.6409638554216865,
      "grad_norm": 0.00444826390594244,
      "learning_rate": 4.718072289156627e-06,
      "loss": 0.024,
      "step": 63420
    },
    {
      "epoch": 7.642168674698795,
      "grad_norm": 0.0035726202186197042,
      "learning_rate": 4.71566265060241e-06,
      "loss": 0.016,
      "step": 63430
    },
    {
      "epoch": 7.643373493975903,
      "grad_norm": 2.151440143585205,
      "learning_rate": 4.713253012048193e-06,
      "loss": 0.0134,
      "step": 63440
    },
    {
      "epoch": 7.644578313253012,
      "grad_norm": 0.0013158476212993264,
      "learning_rate": 4.7108433734939764e-06,
      "loss": 0.0058,
      "step": 63450
    },
    {
      "epoch": 7.64578313253012,
      "grad_norm": 0.2770184278488159,
      "learning_rate": 4.70843373493976e-06,
      "loss": 0.0142,
      "step": 63460
    },
    {
      "epoch": 7.646987951807229,
      "grad_norm": 0.0015029804781079292,
      "learning_rate": 4.706024096385543e-06,
      "loss": 0.0089,
      "step": 63470
    },
    {
      "epoch": 7.648192771084338,
      "grad_norm": 0.0051238820888102055,
      "learning_rate": 4.703614457831326e-06,
      "loss": 0.0119,
      "step": 63480
    },
    {
      "epoch": 7.6493975903614455,
      "grad_norm": 0.001348062651231885,
      "learning_rate": 4.701204819277108e-06,
      "loss": 0.0468,
      "step": 63490
    },
    {
      "epoch": 7.650602409638554,
      "grad_norm": 0.002173652406781912,
      "learning_rate": 4.698795180722892e-06,
      "loss": 0.0272,
      "step": 63500
    },
    {
      "epoch": 7.651807228915663,
      "grad_norm": 0.0051075792871415615,
      "learning_rate": 4.696385542168675e-06,
      "loss": 0.0218,
      "step": 63510
    },
    {
      "epoch": 7.653012048192771,
      "grad_norm": 1.409577488899231,
      "learning_rate": 4.693975903614459e-06,
      "loss": 0.0258,
      "step": 63520
    },
    {
      "epoch": 7.65421686746988,
      "grad_norm": 0.0025259454268962145,
      "learning_rate": 4.691566265060241e-06,
      "loss": 0.01,
      "step": 63530
    },
    {
      "epoch": 7.655421686746988,
      "grad_norm": 0.14081232249736786,
      "learning_rate": 4.689156626506024e-06,
      "loss": 0.01,
      "step": 63540
    },
    {
      "epoch": 7.656626506024097,
      "grad_norm": 0.010334466584026814,
      "learning_rate": 4.686746987951807e-06,
      "loss": 0.0002,
      "step": 63550
    },
    {
      "epoch": 7.6578313253012045,
      "grad_norm": 1.722485065460205,
      "learning_rate": 4.6843373493975905e-06,
      "loss": 0.0142,
      "step": 63560
    },
    {
      "epoch": 7.659036144578313,
      "grad_norm": 0.02548420988023281,
      "learning_rate": 4.681927710843374e-06,
      "loss": 0.0094,
      "step": 63570
    },
    {
      "epoch": 7.660240963855422,
      "grad_norm": 0.0032266410999000072,
      "learning_rate": 4.679518072289157e-06,
      "loss": 0.0083,
      "step": 63580
    },
    {
      "epoch": 7.66144578313253,
      "grad_norm": 0.004602504428476095,
      "learning_rate": 4.67710843373494e-06,
      "loss": 0.0045,
      "step": 63590
    },
    {
      "epoch": 7.662650602409639,
      "grad_norm": 0.0015158792957663536,
      "learning_rate": 4.674698795180723e-06,
      "loss": 0.008,
      "step": 63600
    },
    {
      "epoch": 7.663855421686747,
      "grad_norm": 0.002001819433644414,
      "learning_rate": 4.672289156626506e-06,
      "loss": 0.021,
      "step": 63610
    },
    {
      "epoch": 7.6650602409638555,
      "grad_norm": 0.0046654678881168365,
      "learning_rate": 4.66987951807229e-06,
      "loss": 0.0062,
      "step": 63620
    },
    {
      "epoch": 7.666265060240963,
      "grad_norm": 0.20600934326648712,
      "learning_rate": 4.667469879518073e-06,
      "loss": 0.0206,
      "step": 63630
    },
    {
      "epoch": 7.667469879518072,
      "grad_norm": 2.1675384044647217,
      "learning_rate": 4.665060240963856e-06,
      "loss": 0.0239,
      "step": 63640
    },
    {
      "epoch": 7.668674698795181,
      "grad_norm": 0.003661439521238208,
      "learning_rate": 4.662650602409639e-06,
      "loss": 0.0045,
      "step": 63650
    },
    {
      "epoch": 7.669879518072289,
      "grad_norm": 2.0074942111968994,
      "learning_rate": 4.660240963855422e-06,
      "loss": 0.0261,
      "step": 63660
    },
    {
      "epoch": 7.671084337349398,
      "grad_norm": 0.0012573781423270702,
      "learning_rate": 4.6578313253012055e-06,
      "loss": 0.0181,
      "step": 63670
    },
    {
      "epoch": 7.672289156626506,
      "grad_norm": 3.2115354537963867,
      "learning_rate": 4.655421686746988e-06,
      "loss": 0.0442,
      "step": 63680
    },
    {
      "epoch": 7.6734939759036145,
      "grad_norm": 0.24379123747348785,
      "learning_rate": 4.653012048192772e-06,
      "loss": 0.0027,
      "step": 63690
    },
    {
      "epoch": 7.674698795180722,
      "grad_norm": 0.0015096660936251283,
      "learning_rate": 4.650602409638554e-06,
      "loss": 0.0421,
      "step": 63700
    },
    {
      "epoch": 7.675903614457831,
      "grad_norm": 1.6126203536987305,
      "learning_rate": 4.648192771084337e-06,
      "loss": 0.0096,
      "step": 63710
    },
    {
      "epoch": 7.67710843373494,
      "grad_norm": 0.0014653452672064304,
      "learning_rate": 4.6457831325301205e-06,
      "loss": 0.0278,
      "step": 63720
    },
    {
      "epoch": 7.678313253012048,
      "grad_norm": 0.002109159715473652,
      "learning_rate": 4.643373493975904e-06,
      "loss": 0.0096,
      "step": 63730
    },
    {
      "epoch": 7.679518072289157,
      "grad_norm": 0.03667767345905304,
      "learning_rate": 4.640963855421688e-06,
      "loss": 0.0003,
      "step": 63740
    },
    {
      "epoch": 7.6807228915662655,
      "grad_norm": 0.0015920385485514998,
      "learning_rate": 4.63855421686747e-06,
      "loss": 0.017,
      "step": 63750
    },
    {
      "epoch": 7.6819277108433734,
      "grad_norm": 0.013171982020139694,
      "learning_rate": 4.636144578313253e-06,
      "loss": 0.0317,
      "step": 63760
    },
    {
      "epoch": 7.683132530120482,
      "grad_norm": 0.007627418730407953,
      "learning_rate": 4.633734939759036e-06,
      "loss": 0.0532,
      "step": 63770
    },
    {
      "epoch": 7.68433734939759,
      "grad_norm": 0.010093716904520988,
      "learning_rate": 4.6313253012048196e-06,
      "loss": 0.0163,
      "step": 63780
    },
    {
      "epoch": 7.685542168674699,
      "grad_norm": 0.0034986527170985937,
      "learning_rate": 4.628915662650603e-06,
      "loss": 0.0192,
      "step": 63790
    },
    {
      "epoch": 7.686746987951807,
      "grad_norm": 0.038771770894527435,
      "learning_rate": 4.626506024096386e-06,
      "loss": 0.0453,
      "step": 63800
    },
    {
      "epoch": 7.687951807228916,
      "grad_norm": 0.9300075173377991,
      "learning_rate": 4.624096385542169e-06,
      "loss": 0.0136,
      "step": 63810
    },
    {
      "epoch": 7.6891566265060245,
      "grad_norm": 0.2230640947818756,
      "learning_rate": 4.621686746987952e-06,
      "loss": 0.0017,
      "step": 63820
    },
    {
      "epoch": 7.690361445783132,
      "grad_norm": 1.4786725044250488,
      "learning_rate": 4.6192771084337354e-06,
      "loss": 0.0186,
      "step": 63830
    },
    {
      "epoch": 7.691566265060241,
      "grad_norm": 1.9345378875732422,
      "learning_rate": 4.616867469879519e-06,
      "loss": 0.0273,
      "step": 63840
    },
    {
      "epoch": 7.692771084337349,
      "grad_norm": 0.9167017936706543,
      "learning_rate": 4.614457831325301e-06,
      "loss": 0.0142,
      "step": 63850
    },
    {
      "epoch": 7.693975903614458,
      "grad_norm": 1.3787508010864258,
      "learning_rate": 4.612048192771085e-06,
      "loss": 0.0102,
      "step": 63860
    },
    {
      "epoch": 7.695180722891566,
      "grad_norm": 0.002259899629279971,
      "learning_rate": 4.609638554216868e-06,
      "loss": 0.0277,
      "step": 63870
    },
    {
      "epoch": 7.696385542168675,
      "grad_norm": 0.1390199065208435,
      "learning_rate": 4.607228915662651e-06,
      "loss": 0.0092,
      "step": 63880
    },
    {
      "epoch": 7.6975903614457835,
      "grad_norm": 0.0028492023702710867,
      "learning_rate": 4.6048192771084345e-06,
      "loss": 0.014,
      "step": 63890
    },
    {
      "epoch": 7.698795180722891,
      "grad_norm": 1.6630529165267944,
      "learning_rate": 4.602409638554217e-06,
      "loss": 0.0653,
      "step": 63900
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.033679526299238205,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.0197,
      "step": 63910
    },
    {
      "epoch": 7.701204819277108,
      "grad_norm": 3.2560770511627197,
      "learning_rate": 4.597590361445783e-06,
      "loss": 0.0272,
      "step": 63920
    },
    {
      "epoch": 7.702409638554217,
      "grad_norm": 1.9768770933151245,
      "learning_rate": 4.595180722891567e-06,
      "loss": 0.0451,
      "step": 63930
    },
    {
      "epoch": 7.703614457831325,
      "grad_norm": 0.03525335341691971,
      "learning_rate": 4.5927710843373495e-06,
      "loss": 0.0146,
      "step": 63940
    },
    {
      "epoch": 7.704819277108434,
      "grad_norm": 0.0026422985829412937,
      "learning_rate": 4.590361445783133e-06,
      "loss": 0.0231,
      "step": 63950
    },
    {
      "epoch": 7.706024096385542,
      "grad_norm": 0.002981883939355612,
      "learning_rate": 4.587951807228916e-06,
      "loss": 0.011,
      "step": 63960
    },
    {
      "epoch": 7.70722891566265,
      "grad_norm": 0.026276644319295883,
      "learning_rate": 4.585542168674699e-06,
      "loss": 0.0503,
      "step": 63970
    },
    {
      "epoch": 7.708433734939759,
      "grad_norm": 0.00850176252424717,
      "learning_rate": 4.583132530120482e-06,
      "loss": 0.0097,
      "step": 63980
    },
    {
      "epoch": 7.709638554216868,
      "grad_norm": 0.007072226144373417,
      "learning_rate": 4.580722891566265e-06,
      "loss": 0.0164,
      "step": 63990
    },
    {
      "epoch": 7.710843373493976,
      "grad_norm": 1.9188343286514282,
      "learning_rate": 4.578313253012049e-06,
      "loss": 0.0207,
      "step": 64000
    },
    {
      "epoch": 7.712048192771085,
      "grad_norm": 0.008004351519048214,
      "learning_rate": 4.575903614457832e-06,
      "loss": 0.002,
      "step": 64010
    },
    {
      "epoch": 7.713253012048193,
      "grad_norm": 0.0240988340228796,
      "learning_rate": 4.573493975903615e-06,
      "loss": 0.025,
      "step": 64020
    },
    {
      "epoch": 7.714457831325301,
      "grad_norm": 0.011111688800156116,
      "learning_rate": 4.571084337349398e-06,
      "loss": 0.01,
      "step": 64030
    },
    {
      "epoch": 7.715662650602409,
      "grad_norm": 0.17517472803592682,
      "learning_rate": 4.568674698795181e-06,
      "loss": 0.0126,
      "step": 64040
    },
    {
      "epoch": 7.716867469879518,
      "grad_norm": 0.5415759086608887,
      "learning_rate": 4.5662650602409645e-06,
      "loss": 0.0442,
      "step": 64050
    },
    {
      "epoch": 7.718072289156627,
      "grad_norm": 1.6635401248931885,
      "learning_rate": 4.563855421686748e-06,
      "loss": 0.0571,
      "step": 64060
    },
    {
      "epoch": 7.719277108433735,
      "grad_norm": 0.005557010881602764,
      "learning_rate": 4.56144578313253e-06,
      "loss": 0.0006,
      "step": 64070
    },
    {
      "epoch": 7.720481927710844,
      "grad_norm": 0.5201243758201599,
      "learning_rate": 4.559036144578314e-06,
      "loss": 0.0452,
      "step": 64080
    },
    {
      "epoch": 7.7216867469879515,
      "grad_norm": 1.3095407485961914,
      "learning_rate": 4.556626506024096e-06,
      "loss": 0.0122,
      "step": 64090
    },
    {
      "epoch": 7.72289156626506,
      "grad_norm": 0.0013984722318127751,
      "learning_rate": 4.55421686746988e-06,
      "loss": 0.0256,
      "step": 64100
    },
    {
      "epoch": 7.724096385542168,
      "grad_norm": 0.01153573114424944,
      "learning_rate": 4.551807228915663e-06,
      "loss": 0.0383,
      "step": 64110
    },
    {
      "epoch": 7.725301204819277,
      "grad_norm": 0.17008988559246063,
      "learning_rate": 4.549397590361446e-06,
      "loss": 0.0082,
      "step": 64120
    },
    {
      "epoch": 7.726506024096386,
      "grad_norm": 0.00663509638980031,
      "learning_rate": 4.546987951807229e-06,
      "loss": 0.0053,
      "step": 64130
    },
    {
      "epoch": 7.727710843373494,
      "grad_norm": 0.016323354095220566,
      "learning_rate": 4.544578313253012e-06,
      "loss": 0.023,
      "step": 64140
    },
    {
      "epoch": 7.728915662650603,
      "grad_norm": 2.927849292755127,
      "learning_rate": 4.542168674698795e-06,
      "loss": 0.0347,
      "step": 64150
    },
    {
      "epoch": 7.7301204819277105,
      "grad_norm": 0.030642332509160042,
      "learning_rate": 4.5397590361445786e-06,
      "loss": 0.0064,
      "step": 64160
    },
    {
      "epoch": 7.731325301204819,
      "grad_norm": 0.0028321975842118263,
      "learning_rate": 4.537349397590362e-06,
      "loss": 0.0032,
      "step": 64170
    },
    {
      "epoch": 7.732530120481927,
      "grad_norm": 0.0012796010123565793,
      "learning_rate": 4.534939759036145e-06,
      "loss": 0.0223,
      "step": 64180
    },
    {
      "epoch": 7.733734939759036,
      "grad_norm": 0.017273474484682083,
      "learning_rate": 4.532530120481928e-06,
      "loss": 0.013,
      "step": 64190
    },
    {
      "epoch": 7.734939759036145,
      "grad_norm": 0.9502039551734924,
      "learning_rate": 4.530120481927711e-06,
      "loss": 0.0031,
      "step": 64200
    },
    {
      "epoch": 7.736144578313253,
      "grad_norm": 1.9747495651245117,
      "learning_rate": 4.5277108433734944e-06,
      "loss": 0.0081,
      "step": 64210
    },
    {
      "epoch": 7.7373493975903616,
      "grad_norm": 0.001768817426636815,
      "learning_rate": 4.525301204819278e-06,
      "loss": 0.0053,
      "step": 64220
    },
    {
      "epoch": 7.73855421686747,
      "grad_norm": 1.3350633382797241,
      "learning_rate": 4.522891566265061e-06,
      "loss": 0.0303,
      "step": 64230
    },
    {
      "epoch": 7.739759036144578,
      "grad_norm": 0.0045419614762067795,
      "learning_rate": 4.520481927710844e-06,
      "loss": 0.0551,
      "step": 64240
    },
    {
      "epoch": 7.740963855421687,
      "grad_norm": 1.3094511032104492,
      "learning_rate": 4.518072289156627e-06,
      "loss": 0.0436,
      "step": 64250
    },
    {
      "epoch": 7.742168674698795,
      "grad_norm": 0.006439709570258856,
      "learning_rate": 4.5156626506024095e-06,
      "loss": 0.0066,
      "step": 64260
    },
    {
      "epoch": 7.743373493975904,
      "grad_norm": 0.014086304232478142,
      "learning_rate": 4.5132530120481935e-06,
      "loss": 0.0433,
      "step": 64270
    },
    {
      "epoch": 7.744578313253012,
      "grad_norm": 1.2716577053070068,
      "learning_rate": 4.510843373493976e-06,
      "loss": 0.0247,
      "step": 64280
    },
    {
      "epoch": 7.7457831325301205,
      "grad_norm": 2.828883647918701,
      "learning_rate": 4.50843373493976e-06,
      "loss": 0.0157,
      "step": 64290
    },
    {
      "epoch": 7.746987951807229,
      "grad_norm": 0.02400674670934677,
      "learning_rate": 4.506024096385542e-06,
      "loss": 0.0399,
      "step": 64300
    },
    {
      "epoch": 7.748192771084337,
      "grad_norm": 0.012079925276339054,
      "learning_rate": 4.503614457831325e-06,
      "loss": 0.0229,
      "step": 64310
    },
    {
      "epoch": 7.749397590361446,
      "grad_norm": 0.010906497947871685,
      "learning_rate": 4.501204819277109e-06,
      "loss": 0.0081,
      "step": 64320
    },
    {
      "epoch": 7.750602409638554,
      "grad_norm": 0.004316713195294142,
      "learning_rate": 4.498795180722892e-06,
      "loss": 0.0136,
      "step": 64330
    },
    {
      "epoch": 7.751807228915663,
      "grad_norm": 0.016370879486203194,
      "learning_rate": 4.496385542168675e-06,
      "loss": 0.0089,
      "step": 64340
    },
    {
      "epoch": 7.753012048192771,
      "grad_norm": 0.020885847508907318,
      "learning_rate": 4.493975903614458e-06,
      "loss": 0.0163,
      "step": 64350
    },
    {
      "epoch": 7.7542168674698795,
      "grad_norm": 0.003264931496232748,
      "learning_rate": 4.491566265060241e-06,
      "loss": 0.021,
      "step": 64360
    },
    {
      "epoch": 7.755421686746988,
      "grad_norm": 0.011302946135401726,
      "learning_rate": 4.489156626506024e-06,
      "loss": 0.0148,
      "step": 64370
    },
    {
      "epoch": 7.756626506024096,
      "grad_norm": 0.004788394086062908,
      "learning_rate": 4.486746987951808e-06,
      "loss": 0.0158,
      "step": 64380
    },
    {
      "epoch": 7.757831325301205,
      "grad_norm": 0.003225824097171426,
      "learning_rate": 4.484337349397591e-06,
      "loss": 0.0014,
      "step": 64390
    },
    {
      "epoch": 7.759036144578313,
      "grad_norm": 0.012213408015668392,
      "learning_rate": 4.481927710843374e-06,
      "loss": 0.0187,
      "step": 64400
    },
    {
      "epoch": 7.760240963855422,
      "grad_norm": 1.514382004737854,
      "learning_rate": 4.479518072289157e-06,
      "loss": 0.0081,
      "step": 64410
    },
    {
      "epoch": 7.76144578313253,
      "grad_norm": 0.010623417794704437,
      "learning_rate": 4.47710843373494e-06,
      "loss": 0.0135,
      "step": 64420
    },
    {
      "epoch": 7.7626506024096384,
      "grad_norm": 1.3865889310836792,
      "learning_rate": 4.474698795180723e-06,
      "loss": 0.0419,
      "step": 64430
    },
    {
      "epoch": 7.763855421686747,
      "grad_norm": 3.2017714977264404,
      "learning_rate": 4.472289156626507e-06,
      "loss": 0.014,
      "step": 64440
    },
    {
      "epoch": 7.765060240963855,
      "grad_norm": 0.0022750943899154663,
      "learning_rate": 4.469879518072289e-06,
      "loss": 0.017,
      "step": 64450
    },
    {
      "epoch": 7.766265060240964,
      "grad_norm": 3.273710250854492,
      "learning_rate": 4.467469879518073e-06,
      "loss": 0.0116,
      "step": 64460
    },
    {
      "epoch": 7.767469879518073,
      "grad_norm": 0.002820218214765191,
      "learning_rate": 4.465060240963856e-06,
      "loss": 0.0173,
      "step": 64470
    },
    {
      "epoch": 7.768674698795181,
      "grad_norm": 0.002528522163629532,
      "learning_rate": 4.4626506024096385e-06,
      "loss": 0.0053,
      "step": 64480
    },
    {
      "epoch": 7.7698795180722895,
      "grad_norm": 1.7982207536697388,
      "learning_rate": 4.4602409638554225e-06,
      "loss": 0.0396,
      "step": 64490
    },
    {
      "epoch": 7.771084337349397,
      "grad_norm": 0.003411508398130536,
      "learning_rate": 4.457831325301205e-06,
      "loss": 0.0204,
      "step": 64500
    },
    {
      "epoch": 7.772289156626506,
      "grad_norm": 2.256342649459839,
      "learning_rate": 4.455421686746989e-06,
      "loss": 0.0291,
      "step": 64510
    },
    {
      "epoch": 7.773493975903614,
      "grad_norm": 0.01895844005048275,
      "learning_rate": 4.453012048192771e-06,
      "loss": 0.0314,
      "step": 64520
    },
    {
      "epoch": 7.774698795180723,
      "grad_norm": 0.765828013420105,
      "learning_rate": 4.450602409638554e-06,
      "loss": 0.0055,
      "step": 64530
    },
    {
      "epoch": 7.775903614457832,
      "grad_norm": 0.0031905192881822586,
      "learning_rate": 4.4481927710843376e-06,
      "loss": 0.0063,
      "step": 64540
    },
    {
      "epoch": 7.77710843373494,
      "grad_norm": 0.002689181827008724,
      "learning_rate": 4.445783132530121e-06,
      "loss": 0.0126,
      "step": 64550
    },
    {
      "epoch": 7.7783132530120485,
      "grad_norm": 0.00309043494053185,
      "learning_rate": 4.443373493975904e-06,
      "loss": 0.0144,
      "step": 64560
    },
    {
      "epoch": 7.779518072289156,
      "grad_norm": 0.0032989936880767345,
      "learning_rate": 4.440963855421687e-06,
      "loss": 0.0059,
      "step": 64570
    },
    {
      "epoch": 7.780722891566265,
      "grad_norm": 2.199467658996582,
      "learning_rate": 4.43855421686747e-06,
      "loss": 0.0176,
      "step": 64580
    },
    {
      "epoch": 7.781927710843373,
      "grad_norm": 0.02932113967835903,
      "learning_rate": 4.4361445783132534e-06,
      "loss": 0.0001,
      "step": 64590
    },
    {
      "epoch": 7.783132530120482,
      "grad_norm": 0.0039002415724098682,
      "learning_rate": 4.433734939759037e-06,
      "loss": 0.0219,
      "step": 64600
    },
    {
      "epoch": 7.784337349397591,
      "grad_norm": 0.006349695846438408,
      "learning_rate": 4.43132530120482e-06,
      "loss": 0.0049,
      "step": 64610
    },
    {
      "epoch": 7.785542168674699,
      "grad_norm": 0.0026828525587916374,
      "learning_rate": 4.428915662650603e-06,
      "loss": 0.0064,
      "step": 64620
    },
    {
      "epoch": 7.786746987951807,
      "grad_norm": 0.00903655681759119,
      "learning_rate": 4.426506024096386e-06,
      "loss": 0.0045,
      "step": 64630
    },
    {
      "epoch": 7.787951807228915,
      "grad_norm": 0.0018069252837449312,
      "learning_rate": 4.424096385542169e-06,
      "loss": 0.0033,
      "step": 64640
    },
    {
      "epoch": 7.789156626506024,
      "grad_norm": 0.01551948394626379,
      "learning_rate": 4.4216867469879525e-06,
      "loss": 0.0197,
      "step": 64650
    },
    {
      "epoch": 7.790361445783132,
      "grad_norm": 0.0028362281154841185,
      "learning_rate": 4.419277108433736e-06,
      "loss": 0.0001,
      "step": 64660
    },
    {
      "epoch": 7.791566265060241,
      "grad_norm": 1.3060563802719116,
      "learning_rate": 4.416867469879518e-06,
      "loss": 0.0337,
      "step": 64670
    },
    {
      "epoch": 7.79277108433735,
      "grad_norm": 0.0024561178870499134,
      "learning_rate": 4.414457831325302e-06,
      "loss": 0.0179,
      "step": 64680
    },
    {
      "epoch": 7.793975903614458,
      "grad_norm": 0.0018010592320933938,
      "learning_rate": 4.412048192771084e-06,
      "loss": 0.0067,
      "step": 64690
    },
    {
      "epoch": 7.795180722891566,
      "grad_norm": 0.001120789791457355,
      "learning_rate": 4.4096385542168675e-06,
      "loss": 0.0118,
      "step": 64700
    },
    {
      "epoch": 7.796385542168675,
      "grad_norm": 0.005877699702978134,
      "learning_rate": 4.407228915662651e-06,
      "loss": 0.0583,
      "step": 64710
    },
    {
      "epoch": 7.797590361445783,
      "grad_norm": 0.01062805950641632,
      "learning_rate": 4.404819277108434e-06,
      "loss": 0.0233,
      "step": 64720
    },
    {
      "epoch": 7.798795180722892,
      "grad_norm": 1.363020420074463,
      "learning_rate": 4.402409638554217e-06,
      "loss": 0.0219,
      "step": 64730
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.995293140411377,
      "learning_rate": 4.4e-06,
      "loss": 0.0156,
      "step": 64740
    },
    {
      "epoch": 7.801204819277109,
      "grad_norm": 0.04371661692857742,
      "learning_rate": 4.397590361445783e-06,
      "loss": 0.0417,
      "step": 64750
    },
    {
      "epoch": 7.8024096385542165,
      "grad_norm": 2.4118449687957764,
      "learning_rate": 4.3951807228915666e-06,
      "loss": 0.0234,
      "step": 64760
    },
    {
      "epoch": 7.803614457831325,
      "grad_norm": 0.0946580097079277,
      "learning_rate": 4.39277108433735e-06,
      "loss": 0.0455,
      "step": 64770
    },
    {
      "epoch": 7.804819277108434,
      "grad_norm": 1.5128892660140991,
      "learning_rate": 4.390361445783133e-06,
      "loss": 0.0441,
      "step": 64780
    },
    {
      "epoch": 7.806024096385542,
      "grad_norm": 0.021071719005703926,
      "learning_rate": 4.387951807228916e-06,
      "loss": 0.045,
      "step": 64790
    },
    {
      "epoch": 7.807228915662651,
      "grad_norm": 4.925550937652588,
      "learning_rate": 4.385542168674699e-06,
      "loss": 0.034,
      "step": 64800
    },
    {
      "epoch": 7.808433734939759,
      "grad_norm": 3.1838440895080566,
      "learning_rate": 4.3831325301204825e-06,
      "loss": 0.0124,
      "step": 64810
    },
    {
      "epoch": 7.809638554216868,
      "grad_norm": 0.03048541583120823,
      "learning_rate": 4.380722891566266e-06,
      "loss": 0.0301,
      "step": 64820
    },
    {
      "epoch": 7.8108433734939755,
      "grad_norm": 0.005425920709967613,
      "learning_rate": 4.378313253012049e-06,
      "loss": 0.0092,
      "step": 64830
    },
    {
      "epoch": 7.812048192771084,
      "grad_norm": 0.650943398475647,
      "learning_rate": 4.375903614457831e-06,
      "loss": 0.0206,
      "step": 64840
    },
    {
      "epoch": 7.813253012048193,
      "grad_norm": 0.005803585983812809,
      "learning_rate": 4.373493975903615e-06,
      "loss": 0.0154,
      "step": 64850
    },
    {
      "epoch": 7.814457831325301,
      "grad_norm": 0.8055785298347473,
      "learning_rate": 4.3710843373493975e-06,
      "loss": 0.0077,
      "step": 64860
    },
    {
      "epoch": 7.81566265060241,
      "grad_norm": 1.5003803968429565,
      "learning_rate": 4.3686746987951815e-06,
      "loss": 0.0117,
      "step": 64870
    },
    {
      "epoch": 7.816867469879518,
      "grad_norm": 0.006809503771364689,
      "learning_rate": 4.366265060240964e-06,
      "loss": 0.0152,
      "step": 64880
    },
    {
      "epoch": 7.8180722891566266,
      "grad_norm": 0.7158381938934326,
      "learning_rate": 4.363855421686747e-06,
      "loss": 0.0163,
      "step": 64890
    },
    {
      "epoch": 7.8192771084337345,
      "grad_norm": 0.4727954864501953,
      "learning_rate": 4.361445783132531e-06,
      "loss": 0.013,
      "step": 64900
    },
    {
      "epoch": 7.820481927710843,
      "grad_norm": 2.083087682723999,
      "learning_rate": 4.359036144578313e-06,
      "loss": 0.0204,
      "step": 64910
    },
    {
      "epoch": 7.821686746987952,
      "grad_norm": 0.004361877217888832,
      "learning_rate": 4.356626506024097e-06,
      "loss": 0.0219,
      "step": 64920
    },
    {
      "epoch": 7.82289156626506,
      "grad_norm": 0.017167704179883003,
      "learning_rate": 4.35421686746988e-06,
      "loss": 0.0333,
      "step": 64930
    },
    {
      "epoch": 7.824096385542169,
      "grad_norm": 3.280371904373169,
      "learning_rate": 4.351807228915663e-06,
      "loss": 0.047,
      "step": 64940
    },
    {
      "epoch": 7.825301204819278,
      "grad_norm": 1.8400135040283203,
      "learning_rate": 4.349397590361446e-06,
      "loss": 0.0189,
      "step": 64950
    },
    {
      "epoch": 7.8265060240963855,
      "grad_norm": 0.012371079996228218,
      "learning_rate": 4.346987951807229e-06,
      "loss": 0.0192,
      "step": 64960
    },
    {
      "epoch": 7.827710843373494,
      "grad_norm": 1.4916437864303589,
      "learning_rate": 4.3445783132530124e-06,
      "loss": 0.0132,
      "step": 64970
    },
    {
      "epoch": 7.828915662650602,
      "grad_norm": 0.011868568137288094,
      "learning_rate": 4.342168674698796e-06,
      "loss": 0.0083,
      "step": 64980
    },
    {
      "epoch": 7.830120481927711,
      "grad_norm": 0.19023670256137848,
      "learning_rate": 4.339759036144579e-06,
      "loss": 0.0084,
      "step": 64990
    },
    {
      "epoch": 7.831325301204819,
      "grad_norm": 1.6175116300582886,
      "learning_rate": 4.337349397590362e-06,
      "loss": 0.0249,
      "step": 65000
    },
    {
      "epoch": 7.832530120481928,
      "grad_norm": 0.008348962292075157,
      "learning_rate": 4.334939759036145e-06,
      "loss": 0.0002,
      "step": 65010
    },
    {
      "epoch": 7.833734939759037,
      "grad_norm": 0.5312955379486084,
      "learning_rate": 4.332530120481928e-06,
      "loss": 0.0026,
      "step": 65020
    },
    {
      "epoch": 7.8349397590361445,
      "grad_norm": 0.9266738295555115,
      "learning_rate": 4.330120481927711e-06,
      "loss": 0.0187,
      "step": 65030
    },
    {
      "epoch": 7.836144578313253,
      "grad_norm": 0.0015396949602290988,
      "learning_rate": 4.327710843373495e-06,
      "loss": 0.0099,
      "step": 65040
    },
    {
      "epoch": 7.837349397590361,
      "grad_norm": 8.923724174499512,
      "learning_rate": 4.325301204819278e-06,
      "loss": 0.0263,
      "step": 65050
    },
    {
      "epoch": 7.83855421686747,
      "grad_norm": 0.04879721626639366,
      "learning_rate": 4.32289156626506e-06,
      "loss": 0.0224,
      "step": 65060
    },
    {
      "epoch": 7.839759036144578,
      "grad_norm": 1.6529269218444824,
      "learning_rate": 4.320481927710844e-06,
      "loss": 0.0236,
      "step": 65070
    },
    {
      "epoch": 7.840963855421687,
      "grad_norm": 0.0015623150393366814,
      "learning_rate": 4.3180722891566265e-06,
      "loss": 0.0274,
      "step": 65080
    },
    {
      "epoch": 7.8421686746987955,
      "grad_norm": 0.6048627495765686,
      "learning_rate": 4.3156626506024105e-06,
      "loss": 0.0445,
      "step": 65090
    },
    {
      "epoch": 7.843373493975903,
      "grad_norm": 0.29674145579338074,
      "learning_rate": 4.313253012048193e-06,
      "loss": 0.0321,
      "step": 65100
    },
    {
      "epoch": 7.844578313253012,
      "grad_norm": 3.4559497833251953,
      "learning_rate": 4.310843373493976e-06,
      "loss": 0.0158,
      "step": 65110
    },
    {
      "epoch": 7.84578313253012,
      "grad_norm": 0.0029126694425940514,
      "learning_rate": 4.308433734939759e-06,
      "loss": 0.0005,
      "step": 65120
    },
    {
      "epoch": 7.846987951807229,
      "grad_norm": 1.3426896333694458,
      "learning_rate": 4.306024096385542e-06,
      "loss": 0.0088,
      "step": 65130
    },
    {
      "epoch": 7.848192771084337,
      "grad_norm": 0.008503495715558529,
      "learning_rate": 4.3036144578313256e-06,
      "loss": 0.0052,
      "step": 65140
    },
    {
      "epoch": 7.849397590361446,
      "grad_norm": 0.019768286496400833,
      "learning_rate": 4.301204819277109e-06,
      "loss": 0.0243,
      "step": 65150
    },
    {
      "epoch": 7.8506024096385545,
      "grad_norm": 1.469021201133728,
      "learning_rate": 4.298795180722892e-06,
      "loss": 0.0351,
      "step": 65160
    },
    {
      "epoch": 7.851807228915662,
      "grad_norm": 0.0010816561989486217,
      "learning_rate": 4.296385542168675e-06,
      "loss": 0.008,
      "step": 65170
    },
    {
      "epoch": 7.853012048192771,
      "grad_norm": 0.18982496857643127,
      "learning_rate": 4.293975903614458e-06,
      "loss": 0.0193,
      "step": 65180
    },
    {
      "epoch": 7.85421686746988,
      "grad_norm": 0.008492792025208473,
      "learning_rate": 4.2915662650602415e-06,
      "loss": 0.0149,
      "step": 65190
    },
    {
      "epoch": 7.855421686746988,
      "grad_norm": 1.9594569206237793,
      "learning_rate": 4.289156626506025e-06,
      "loss": 0.0324,
      "step": 65200
    },
    {
      "epoch": 7.856626506024097,
      "grad_norm": 1.5192670822143555,
      "learning_rate": 4.286746987951808e-06,
      "loss": 0.0155,
      "step": 65210
    },
    {
      "epoch": 7.857831325301205,
      "grad_norm": 0.008064039051532745,
      "learning_rate": 4.284337349397591e-06,
      "loss": 0.0286,
      "step": 65220
    },
    {
      "epoch": 7.8590361445783135,
      "grad_norm": 0.005030143074691296,
      "learning_rate": 4.281927710843374e-06,
      "loss": 0.0308,
      "step": 65230
    },
    {
      "epoch": 7.860240963855421,
      "grad_norm": 0.0015022377483546734,
      "learning_rate": 4.279518072289157e-06,
      "loss": 0.016,
      "step": 65240
    },
    {
      "epoch": 7.86144578313253,
      "grad_norm": 3.489328145980835,
      "learning_rate": 4.27710843373494e-06,
      "loss": 0.019,
      "step": 65250
    },
    {
      "epoch": 7.862650602409639,
      "grad_norm": 2.5489773750305176,
      "learning_rate": 4.274698795180724e-06,
      "loss": 0.0449,
      "step": 65260
    },
    {
      "epoch": 7.863855421686747,
      "grad_norm": 1.4586495161056519,
      "learning_rate": 4.272289156626506e-06,
      "loss": 0.0104,
      "step": 65270
    },
    {
      "epoch": 7.865060240963856,
      "grad_norm": 0.007296551950275898,
      "learning_rate": 4.26987951807229e-06,
      "loss": 0.0194,
      "step": 65280
    },
    {
      "epoch": 7.866265060240964,
      "grad_norm": 0.11468299478292465,
      "learning_rate": 4.267469879518072e-06,
      "loss": 0.0003,
      "step": 65290
    },
    {
      "epoch": 7.867469879518072,
      "grad_norm": 0.021318767219781876,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.0148,
      "step": 65300
    },
    {
      "epoch": 7.86867469879518,
      "grad_norm": 0.001966389361768961,
      "learning_rate": 4.262650602409639e-06,
      "loss": 0.0048,
      "step": 65310
    },
    {
      "epoch": 7.869879518072289,
      "grad_norm": 0.0012230525026097894,
      "learning_rate": 4.260240963855422e-06,
      "loss": 0.0125,
      "step": 65320
    },
    {
      "epoch": 7.871084337349398,
      "grad_norm": 0.0011637361021712422,
      "learning_rate": 4.257831325301205e-06,
      "loss": 0.0286,
      "step": 65330
    },
    {
      "epoch": 7.872289156626506,
      "grad_norm": 2.2908334732055664,
      "learning_rate": 4.255421686746988e-06,
      "loss": 0.0319,
      "step": 65340
    },
    {
      "epoch": 7.873493975903615,
      "grad_norm": 0.32574212551116943,
      "learning_rate": 4.253012048192771e-06,
      "loss": 0.0196,
      "step": 65350
    },
    {
      "epoch": 7.874698795180723,
      "grad_norm": 0.0008101970888674259,
      "learning_rate": 4.250602409638555e-06,
      "loss": 0.0349,
      "step": 65360
    },
    {
      "epoch": 7.875903614457831,
      "grad_norm": 0.0009486995404586196,
      "learning_rate": 4.248192771084338e-06,
      "loss": 0.0046,
      "step": 65370
    },
    {
      "epoch": 7.877108433734939,
      "grad_norm": 0.004225505981594324,
      "learning_rate": 4.245783132530121e-06,
      "loss": 0.0355,
      "step": 65380
    },
    {
      "epoch": 7.878313253012048,
      "grad_norm": 11.153382301330566,
      "learning_rate": 4.243373493975904e-06,
      "loss": 0.0538,
      "step": 65390
    },
    {
      "epoch": 7.879518072289157,
      "grad_norm": 0.03922376409173012,
      "learning_rate": 4.240963855421687e-06,
      "loss": 0.0078,
      "step": 65400
    },
    {
      "epoch": 7.880722891566265,
      "grad_norm": 0.014507143758237362,
      "learning_rate": 4.2385542168674705e-06,
      "loss": 0.0088,
      "step": 65410
    },
    {
      "epoch": 7.881927710843374,
      "grad_norm": 0.13167624175548553,
      "learning_rate": 4.236144578313253e-06,
      "loss": 0.0148,
      "step": 65420
    },
    {
      "epoch": 7.8831325301204815,
      "grad_norm": 0.621895968914032,
      "learning_rate": 4.233734939759037e-06,
      "loss": 0.009,
      "step": 65430
    },
    {
      "epoch": 7.88433734939759,
      "grad_norm": 0.004298473708331585,
      "learning_rate": 4.231325301204819e-06,
      "loss": 0.017,
      "step": 65440
    },
    {
      "epoch": 7.885542168674699,
      "grad_norm": 1.6373921632766724,
      "learning_rate": 4.228915662650603e-06,
      "loss": 0.0138,
      "step": 65450
    },
    {
      "epoch": 7.886746987951807,
      "grad_norm": 1.3594639301300049,
      "learning_rate": 4.2265060240963855e-06,
      "loss": 0.02,
      "step": 65460
    },
    {
      "epoch": 7.887951807228916,
      "grad_norm": 0.22649894654750824,
      "learning_rate": 4.224096385542169e-06,
      "loss": 0.0261,
      "step": 65470
    },
    {
      "epoch": 7.889156626506024,
      "grad_norm": 2.2756364345550537,
      "learning_rate": 4.221686746987952e-06,
      "loss": 0.0128,
      "step": 65480
    },
    {
      "epoch": 7.890361445783133,
      "grad_norm": 0.14147748053073883,
      "learning_rate": 4.219277108433735e-06,
      "loss": 0.0101,
      "step": 65490
    },
    {
      "epoch": 7.891566265060241,
      "grad_norm": 0.0031450968235731125,
      "learning_rate": 4.216867469879519e-06,
      "loss": 0.0133,
      "step": 65500
    },
    {
      "epoch": 7.892771084337349,
      "grad_norm": 0.24321310222148895,
      "learning_rate": 4.214457831325301e-06,
      "loss": 0.0324,
      "step": 65510
    },
    {
      "epoch": 7.893975903614458,
      "grad_norm": 0.42672911286354065,
      "learning_rate": 4.2120481927710846e-06,
      "loss": 0.001,
      "step": 65520
    },
    {
      "epoch": 7.895180722891566,
      "grad_norm": 0.0007348498911596835,
      "learning_rate": 4.209638554216868e-06,
      "loss": 0.0158,
      "step": 65530
    },
    {
      "epoch": 7.896385542168675,
      "grad_norm": 0.8909345865249634,
      "learning_rate": 4.207228915662651e-06,
      "loss": 0.0485,
      "step": 65540
    },
    {
      "epoch": 7.897590361445783,
      "grad_norm": 5.2619147300720215,
      "learning_rate": 4.204819277108434e-06,
      "loss": 0.0233,
      "step": 65550
    },
    {
      "epoch": 7.8987951807228916,
      "grad_norm": 0.001879687188193202,
      "learning_rate": 4.202409638554217e-06,
      "loss": 0.0149,
      "step": 65560
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.2156573086977005,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0168,
      "step": 65570
    },
    {
      "epoch": 7.901204819277108,
      "grad_norm": 0.0109226293861866,
      "learning_rate": 4.197590361445784e-06,
      "loss": 0.013,
      "step": 65580
    },
    {
      "epoch": 7.902409638554217,
      "grad_norm": 2.350269079208374,
      "learning_rate": 4.195180722891567e-06,
      "loss": 0.0284,
      "step": 65590
    },
    {
      "epoch": 7.903614457831325,
      "grad_norm": 0.0064207022078335285,
      "learning_rate": 4.19277108433735e-06,
      "loss": 0.0517,
      "step": 65600
    },
    {
      "epoch": 7.904819277108434,
      "grad_norm": 0.43813711404800415,
      "learning_rate": 4.190361445783132e-06,
      "loss": 0.0031,
      "step": 65610
    },
    {
      "epoch": 7.906024096385542,
      "grad_norm": 2.946589708328247,
      "learning_rate": 4.187951807228916e-06,
      "loss": 0.0312,
      "step": 65620
    },
    {
      "epoch": 7.9072289156626505,
      "grad_norm": 0.045255910605192184,
      "learning_rate": 4.185542168674699e-06,
      "loss": 0.026,
      "step": 65630
    },
    {
      "epoch": 7.908433734939759,
      "grad_norm": 0.23347750306129456,
      "learning_rate": 4.183132530120483e-06,
      "loss": 0.0098,
      "step": 65640
    },
    {
      "epoch": 7.909638554216867,
      "grad_norm": 0.25618135929107666,
      "learning_rate": 4.180722891566266e-06,
      "loss": 0.0009,
      "step": 65650
    },
    {
      "epoch": 7.910843373493976,
      "grad_norm": 0.0009866508189588785,
      "learning_rate": 4.178313253012048e-06,
      "loss": 0.0011,
      "step": 65660
    },
    {
      "epoch": 7.912048192771084,
      "grad_norm": 4.020814418792725,
      "learning_rate": 4.175903614457832e-06,
      "loss": 0.0347,
      "step": 65670
    },
    {
      "epoch": 7.913253012048193,
      "grad_norm": 0.0029764133505523205,
      "learning_rate": 4.1734939759036145e-06,
      "loss": 0.0063,
      "step": 65680
    },
    {
      "epoch": 7.914457831325302,
      "grad_norm": 0.008171195164322853,
      "learning_rate": 4.171084337349398e-06,
      "loss": 0.0042,
      "step": 65690
    },
    {
      "epoch": 7.9156626506024095,
      "grad_norm": 3.3201704025268555,
      "learning_rate": 4.168674698795181e-06,
      "loss": 0.0132,
      "step": 65700
    },
    {
      "epoch": 7.916867469879518,
      "grad_norm": 1.7820448875427246,
      "learning_rate": 4.166265060240964e-06,
      "loss": 0.0427,
      "step": 65710
    },
    {
      "epoch": 7.918072289156626,
      "grad_norm": 0.17781446874141693,
      "learning_rate": 4.163855421686747e-06,
      "loss": 0.0183,
      "step": 65720
    },
    {
      "epoch": 7.919277108433735,
      "grad_norm": 0.027461843565106392,
      "learning_rate": 4.16144578313253e-06,
      "loss": 0.0086,
      "step": 65730
    },
    {
      "epoch": 7.920481927710844,
      "grad_norm": 0.006891731172800064,
      "learning_rate": 4.159036144578314e-06,
      "loss": 0.0076,
      "step": 65740
    },
    {
      "epoch": 7.921686746987952,
      "grad_norm": 0.004524845164269209,
      "learning_rate": 4.156626506024097e-06,
      "loss": 0.0067,
      "step": 65750
    },
    {
      "epoch": 7.9228915662650605,
      "grad_norm": 0.0016376094426959753,
      "learning_rate": 4.15421686746988e-06,
      "loss": 0.0592,
      "step": 65760
    },
    {
      "epoch": 7.924096385542168,
      "grad_norm": 3.824094772338867,
      "learning_rate": 4.151807228915663e-06,
      "loss": 0.0191,
      "step": 65770
    },
    {
      "epoch": 7.925301204819277,
      "grad_norm": 0.00047703328891657293,
      "learning_rate": 4.1493975903614454e-06,
      "loss": 0.0073,
      "step": 65780
    },
    {
      "epoch": 7.926506024096385,
      "grad_norm": 0.7484727501869202,
      "learning_rate": 4.1469879518072295e-06,
      "loss": 0.0047,
      "step": 65790
    },
    {
      "epoch": 7.927710843373494,
      "grad_norm": 2.00801420211792,
      "learning_rate": 4.144578313253013e-06,
      "loss": 0.0388,
      "step": 65800
    },
    {
      "epoch": 7.928915662650603,
      "grad_norm": 0.26082268357276917,
      "learning_rate": 4.142168674698796e-06,
      "loss": 0.0152,
      "step": 65810
    },
    {
      "epoch": 7.930120481927711,
      "grad_norm": 0.062879778444767,
      "learning_rate": 4.139759036144579e-06,
      "loss": 0.0146,
      "step": 65820
    },
    {
      "epoch": 7.9313253012048195,
      "grad_norm": 0.0009313510963693261,
      "learning_rate": 4.137349397590361e-06,
      "loss": 0.0011,
      "step": 65830
    },
    {
      "epoch": 7.932530120481927,
      "grad_norm": 3.7303600311279297,
      "learning_rate": 4.134939759036145e-06,
      "loss": 0.0328,
      "step": 65840
    },
    {
      "epoch": 7.933734939759036,
      "grad_norm": 0.000968205917160958,
      "learning_rate": 4.132530120481928e-06,
      "loss": 0.0177,
      "step": 65850
    },
    {
      "epoch": 7.934939759036144,
      "grad_norm": 2.2592453956604004,
      "learning_rate": 4.130120481927712e-06,
      "loss": 0.0184,
      "step": 65860
    },
    {
      "epoch": 7.936144578313253,
      "grad_norm": 2.091142177581787,
      "learning_rate": 4.127710843373494e-06,
      "loss": 0.0131,
      "step": 65870
    },
    {
      "epoch": 7.937349397590362,
      "grad_norm": 1.6711076498031616,
      "learning_rate": 4.125301204819277e-06,
      "loss": 0.0154,
      "step": 65880
    },
    {
      "epoch": 7.93855421686747,
      "grad_norm": 4.300918102264404,
      "learning_rate": 4.12289156626506e-06,
      "loss": 0.0354,
      "step": 65890
    },
    {
      "epoch": 7.9397590361445785,
      "grad_norm": 0.001035804976709187,
      "learning_rate": 4.1204819277108436e-06,
      "loss": 0.0206,
      "step": 65900
    },
    {
      "epoch": 7.940963855421686,
      "grad_norm": 0.07760723680257797,
      "learning_rate": 4.118072289156627e-06,
      "loss": 0.037,
      "step": 65910
    },
    {
      "epoch": 7.942168674698795,
      "grad_norm": 0.02164132334291935,
      "learning_rate": 4.11566265060241e-06,
      "loss": 0.0009,
      "step": 65920
    },
    {
      "epoch": 7.943373493975904,
      "grad_norm": 0.0010240698466077447,
      "learning_rate": 4.113253012048193e-06,
      "loss": 0.0199,
      "step": 65930
    },
    {
      "epoch": 7.944578313253012,
      "grad_norm": 8.333137512207031,
      "learning_rate": 4.110843373493976e-06,
      "loss": 0.0123,
      "step": 65940
    },
    {
      "epoch": 7.945783132530121,
      "grad_norm": 0.005953907035291195,
      "learning_rate": 4.1084337349397594e-06,
      "loss": 0.0016,
      "step": 65950
    },
    {
      "epoch": 7.946987951807229,
      "grad_norm": 0.006265638861805201,
      "learning_rate": 4.106024096385543e-06,
      "loss": 0.039,
      "step": 65960
    },
    {
      "epoch": 7.948192771084337,
      "grad_norm": 15.704852104187012,
      "learning_rate": 4.103614457831326e-06,
      "loss": 0.0162,
      "step": 65970
    },
    {
      "epoch": 7.949397590361446,
      "grad_norm": 0.5464769601821899,
      "learning_rate": 4.101204819277109e-06,
      "loss": 0.016,
      "step": 65980
    },
    {
      "epoch": 7.950602409638554,
      "grad_norm": 0.002604267094284296,
      "learning_rate": 4.098795180722892e-06,
      "loss": 0.0133,
      "step": 65990
    },
    {
      "epoch": 7.951807228915663,
      "grad_norm": 0.02840091846883297,
      "learning_rate": 4.096385542168675e-06,
      "loss": 0.0192,
      "step": 66000
    },
    {
      "epoch": 7.953012048192771,
      "grad_norm": 1.0928382873535156,
      "learning_rate": 4.0939759036144585e-06,
      "loss": 0.0047,
      "step": 66010
    },
    {
      "epoch": 7.95421686746988,
      "grad_norm": 1.088610053062439,
      "learning_rate": 4.091566265060241e-06,
      "loss": 0.0277,
      "step": 66020
    },
    {
      "epoch": 7.955421686746988,
      "grad_norm": 0.12381532043218613,
      "learning_rate": 4.089156626506025e-06,
      "loss": 0.0105,
      "step": 66030
    },
    {
      "epoch": 7.956626506024096,
      "grad_norm": 0.0022890723776072264,
      "learning_rate": 4.086746987951807e-06,
      "loss": 0.0187,
      "step": 66040
    },
    {
      "epoch": 7.957831325301205,
      "grad_norm": 0.0006561705959029496,
      "learning_rate": 4.08433734939759e-06,
      "loss": 0.0107,
      "step": 66050
    },
    {
      "epoch": 7.959036144578313,
      "grad_norm": 0.0008212407701648772,
      "learning_rate": 4.0819277108433735e-06,
      "loss": 0.0206,
      "step": 66060
    },
    {
      "epoch": 7.960240963855422,
      "grad_norm": 1.638700246810913,
      "learning_rate": 4.079518072289157e-06,
      "loss": 0.016,
      "step": 66070
    },
    {
      "epoch": 7.96144578313253,
      "grad_norm": 0.29260364174842834,
      "learning_rate": 4.077108433734941e-06,
      "loss": 0.0479,
      "step": 66080
    },
    {
      "epoch": 7.962650602409639,
      "grad_norm": 0.09677232056856155,
      "learning_rate": 4.074698795180723e-06,
      "loss": 0.0125,
      "step": 66090
    },
    {
      "epoch": 7.9638554216867465,
      "grad_norm": 0.002869026968255639,
      "learning_rate": 4.072289156626506e-06,
      "loss": 0.0015,
      "step": 66100
    },
    {
      "epoch": 7.965060240963855,
      "grad_norm": 0.0008709832327440381,
      "learning_rate": 4.069879518072289e-06,
      "loss": 0.016,
      "step": 66110
    },
    {
      "epoch": 7.966265060240964,
      "grad_norm": 2.631924867630005,
      "learning_rate": 4.067469879518073e-06,
      "loss": 0.0133,
      "step": 66120
    },
    {
      "epoch": 7.967469879518072,
      "grad_norm": 0.005603039171546698,
      "learning_rate": 4.065060240963856e-06,
      "loss": 0.012,
      "step": 66130
    },
    {
      "epoch": 7.968674698795181,
      "grad_norm": 0.033461716026067734,
      "learning_rate": 4.062650602409639e-06,
      "loss": 0.0344,
      "step": 66140
    },
    {
      "epoch": 7.969879518072289,
      "grad_norm": 1.2668520212173462,
      "learning_rate": 4.060240963855422e-06,
      "loss": 0.02,
      "step": 66150
    },
    {
      "epoch": 7.971084337349398,
      "grad_norm": 0.0006384009029716253,
      "learning_rate": 4.057831325301205e-06,
      "loss": 0.0202,
      "step": 66160
    },
    {
      "epoch": 7.972289156626506,
      "grad_norm": 0.013551905751228333,
      "learning_rate": 4.0554216867469885e-06,
      "loss": 0.0106,
      "step": 66170
    },
    {
      "epoch": 7.973493975903614,
      "grad_norm": 0.004769161343574524,
      "learning_rate": 4.053012048192772e-06,
      "loss": 0.0026,
      "step": 66180
    },
    {
      "epoch": 7.974698795180723,
      "grad_norm": 0.000688717991579324,
      "learning_rate": 4.050602409638554e-06,
      "loss": 0.0053,
      "step": 66190
    },
    {
      "epoch": 7.975903614457831,
      "grad_norm": 0.478523313999176,
      "learning_rate": 4.048192771084338e-06,
      "loss": 0.0023,
      "step": 66200
    },
    {
      "epoch": 7.97710843373494,
      "grad_norm": 0.000846695969812572,
      "learning_rate": 4.04578313253012e-06,
      "loss": 0.0146,
      "step": 66210
    },
    {
      "epoch": 7.978313253012049,
      "grad_norm": 0.000726949016097933,
      "learning_rate": 4.043373493975904e-06,
      "loss": 0.0542,
      "step": 66220
    },
    {
      "epoch": 7.9795180722891565,
      "grad_norm": 0.001783417072147131,
      "learning_rate": 4.0409638554216875e-06,
      "loss": 0.0079,
      "step": 66230
    },
    {
      "epoch": 7.980722891566265,
      "grad_norm": 0.0014326715609058738,
      "learning_rate": 4.03855421686747e-06,
      "loss": 0.0224,
      "step": 66240
    },
    {
      "epoch": 7.981927710843373,
      "grad_norm": 2.6483023166656494,
      "learning_rate": 4.036144578313254e-06,
      "loss": 0.0492,
      "step": 66250
    },
    {
      "epoch": 7.983132530120482,
      "grad_norm": 0.18568849563598633,
      "learning_rate": 4.033734939759036e-06,
      "loss": 0.0007,
      "step": 66260
    },
    {
      "epoch": 7.98433734939759,
      "grad_norm": 2.017401695251465,
      "learning_rate": 4.031325301204819e-06,
      "loss": 0.0198,
      "step": 66270
    },
    {
      "epoch": 7.985542168674699,
      "grad_norm": 1.186816692352295,
      "learning_rate": 4.0289156626506026e-06,
      "loss": 0.0102,
      "step": 66280
    },
    {
      "epoch": 7.986746987951808,
      "grad_norm": 0.17180120944976807,
      "learning_rate": 4.026506024096386e-06,
      "loss": 0.0011,
      "step": 66290
    },
    {
      "epoch": 7.9879518072289155,
      "grad_norm": 1.1385470628738403,
      "learning_rate": 4.024096385542169e-06,
      "loss": 0.0111,
      "step": 66300
    },
    {
      "epoch": 7.989156626506024,
      "grad_norm": 1.1067396402359009,
      "learning_rate": 4.021686746987952e-06,
      "loss": 0.009,
      "step": 66310
    },
    {
      "epoch": 7.990361445783132,
      "grad_norm": 0.0025234839413315058,
      "learning_rate": 4.019277108433735e-06,
      "loss": 0.0282,
      "step": 66320
    },
    {
      "epoch": 7.991566265060241,
      "grad_norm": 0.001326736412011087,
      "learning_rate": 4.0168674698795184e-06,
      "loss": 0.0012,
      "step": 66330
    },
    {
      "epoch": 7.992771084337349,
      "grad_norm": 0.0033460718113929033,
      "learning_rate": 4.014457831325302e-06,
      "loss": 0.0249,
      "step": 66340
    },
    {
      "epoch": 7.993975903614458,
      "grad_norm": 7.334352493286133,
      "learning_rate": 4.012048192771085e-06,
      "loss": 0.0224,
      "step": 66350
    },
    {
      "epoch": 7.995180722891567,
      "grad_norm": 0.001444293069653213,
      "learning_rate": 4.009638554216868e-06,
      "loss": 0.0555,
      "step": 66360
    },
    {
      "epoch": 7.9963855421686745,
      "grad_norm": 0.009109685197472572,
      "learning_rate": 4.007228915662651e-06,
      "loss": 0.0169,
      "step": 66370
    },
    {
      "epoch": 7.997590361445783,
      "grad_norm": 1.423164963722229,
      "learning_rate": 4.004819277108434e-06,
      "loss": 0.0204,
      "step": 66380
    },
    {
      "epoch": 7.998795180722891,
      "grad_norm": 0.006369919050484896,
      "learning_rate": 4.0024096385542175e-06,
      "loss": 0.0225,
      "step": 66390
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.0057958755642175674,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0127,
      "step": 66400
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9876031121109862,
      "eval_f1": 0.9667859609468199,
      "eval_loss": 0.04399208351969719,
      "eval_precision": 0.9825165900969882,
      "eval_recall": 0.9515511061673464,
      "eval_runtime": 4967.4997,
      "eval_samples_per_second": 8.594,
      "eval_steps_per_second": 0.358,
      "step": 66400
    },
    {
      "epoch": 8.001204819277108,
      "grad_norm": 0.28279924392700195,
      "learning_rate": 3.997590361445783e-06,
      "loss": 0.0117,
      "step": 66410
    },
    {
      "epoch": 8.002409638554218,
      "grad_norm": 0.009818319231271744,
      "learning_rate": 3.995180722891567e-06,
      "loss": 0.016,
      "step": 66420
    },
    {
      "epoch": 8.003614457831326,
      "grad_norm": 0.0047102440148591995,
      "learning_rate": 3.992771084337349e-06,
      "loss": 0.0054,
      "step": 66430
    },
    {
      "epoch": 8.004819277108433,
      "grad_norm": 0.0014688031515106559,
      "learning_rate": 3.990361445783133e-06,
      "loss": 0.0043,
      "step": 66440
    },
    {
      "epoch": 8.006024096385541,
      "grad_norm": 0.0010409385431557894,
      "learning_rate": 3.987951807228916e-06,
      "loss": 0.0034,
      "step": 66450
    },
    {
      "epoch": 8.007228915662651,
      "grad_norm": 1.1599808931350708,
      "learning_rate": 3.985542168674699e-06,
      "loss": 0.0531,
      "step": 66460
    },
    {
      "epoch": 8.008433734939759,
      "grad_norm": 1.5964951515197754,
      "learning_rate": 3.983132530120482e-06,
      "loss": 0.0322,
      "step": 66470
    },
    {
      "epoch": 8.009638554216867,
      "grad_norm": 0.028761107474565506,
      "learning_rate": 3.980722891566265e-06,
      "loss": 0.0095,
      "step": 66480
    },
    {
      "epoch": 8.010843373493977,
      "grad_norm": 0.0010828477097675204,
      "learning_rate": 3.978313253012048e-06,
      "loss": 0.0287,
      "step": 66490
    },
    {
      "epoch": 8.012048192771084,
      "grad_norm": 0.0178851168602705,
      "learning_rate": 3.975903614457832e-06,
      "loss": 0.0172,
      "step": 66500
    },
    {
      "epoch": 8.013253012048192,
      "grad_norm": 1.4739491939544678,
      "learning_rate": 3.973493975903615e-06,
      "loss": 0.0143,
      "step": 66510
    },
    {
      "epoch": 8.0144578313253,
      "grad_norm": 2.891854763031006,
      "learning_rate": 3.971084337349398e-06,
      "loss": 0.0231,
      "step": 66520
    },
    {
      "epoch": 8.01566265060241,
      "grad_norm": 0.3692130744457245,
      "learning_rate": 3.968674698795181e-06,
      "loss": 0.0091,
      "step": 66530
    },
    {
      "epoch": 8.016867469879518,
      "grad_norm": 0.010255826637148857,
      "learning_rate": 3.966265060240964e-06,
      "loss": 0.0191,
      "step": 66540
    },
    {
      "epoch": 8.018072289156626,
      "grad_norm": 0.00253760302439332,
      "learning_rate": 3.9638554216867475e-06,
      "loss": 0.0136,
      "step": 66550
    },
    {
      "epoch": 8.019277108433736,
      "grad_norm": 0.0009477892890572548,
      "learning_rate": 3.961445783132531e-06,
      "loss": 0.0069,
      "step": 66560
    },
    {
      "epoch": 8.020481927710843,
      "grad_norm": 0.007394158281385899,
      "learning_rate": 3.959036144578314e-06,
      "loss": 0.0065,
      "step": 66570
    },
    {
      "epoch": 8.021686746987951,
      "grad_norm": 6.132783889770508,
      "learning_rate": 3.956626506024097e-06,
      "loss": 0.0192,
      "step": 66580
    },
    {
      "epoch": 8.022891566265061,
      "grad_norm": 0.0021244583185762167,
      "learning_rate": 3.95421686746988e-06,
      "loss": 0.0016,
      "step": 66590
    },
    {
      "epoch": 8.024096385542169,
      "grad_norm": 0.0006923929904587567,
      "learning_rate": 3.9518072289156625e-06,
      "loss": 0.0224,
      "step": 66600
    },
    {
      "epoch": 8.025301204819277,
      "grad_norm": 0.20329293608665466,
      "learning_rate": 3.9493975903614465e-06,
      "loss": 0.0672,
      "step": 66610
    },
    {
      "epoch": 8.026506024096385,
      "grad_norm": 0.8253031373023987,
      "learning_rate": 3.946987951807229e-06,
      "loss": 0.0046,
      "step": 66620
    },
    {
      "epoch": 8.027710843373494,
      "grad_norm": 0.6265567541122437,
      "learning_rate": 3.944578313253012e-06,
      "loss": 0.017,
      "step": 66630
    },
    {
      "epoch": 8.028915662650602,
      "grad_norm": 0.003532504430040717,
      "learning_rate": 3.942168674698795e-06,
      "loss": 0.0296,
      "step": 66640
    },
    {
      "epoch": 8.03012048192771,
      "grad_norm": 0.36815929412841797,
      "learning_rate": 3.939759036144578e-06,
      "loss": 0.0076,
      "step": 66650
    },
    {
      "epoch": 8.03132530120482,
      "grad_norm": 0.008751832880079746,
      "learning_rate": 3.9373493975903615e-06,
      "loss": 0.0328,
      "step": 66660
    },
    {
      "epoch": 8.032530120481928,
      "grad_norm": 10.459626197814941,
      "learning_rate": 3.934939759036145e-06,
      "loss": 0.0461,
      "step": 66670
    },
    {
      "epoch": 8.033734939759036,
      "grad_norm": 0.2101246416568756,
      "learning_rate": 3.932530120481928e-06,
      "loss": 0.0211,
      "step": 66680
    },
    {
      "epoch": 8.034939759036144,
      "grad_norm": 1.3269163370132446,
      "learning_rate": 3.930120481927711e-06,
      "loss": 0.0237,
      "step": 66690
    },
    {
      "epoch": 8.036144578313253,
      "grad_norm": 0.8773228526115417,
      "learning_rate": 3.927710843373494e-06,
      "loss": 0.0053,
      "step": 66700
    },
    {
      "epoch": 8.037349397590361,
      "grad_norm": 1.116053819656372,
      "learning_rate": 3.9253012048192774e-06,
      "loss": 0.0177,
      "step": 66710
    },
    {
      "epoch": 8.03855421686747,
      "grad_norm": 0.006450970191508532,
      "learning_rate": 3.922891566265061e-06,
      "loss": 0.009,
      "step": 66720
    },
    {
      "epoch": 8.039759036144579,
      "grad_norm": 0.657124936580658,
      "learning_rate": 3.920481927710844e-06,
      "loss": 0.008,
      "step": 66730
    },
    {
      "epoch": 8.040963855421687,
      "grad_norm": 0.0033705425448715687,
      "learning_rate": 3.918072289156627e-06,
      "loss": 0.0331,
      "step": 66740
    },
    {
      "epoch": 8.042168674698795,
      "grad_norm": 0.8800917267799377,
      "learning_rate": 3.91566265060241e-06,
      "loss": 0.0175,
      "step": 66750
    },
    {
      "epoch": 8.043373493975903,
      "grad_norm": 0.018161913380026817,
      "learning_rate": 3.913253012048193e-06,
      "loss": 0.0011,
      "step": 66760
    },
    {
      "epoch": 8.044578313253012,
      "grad_norm": 0.0014978654216974974,
      "learning_rate": 3.910843373493976e-06,
      "loss": 0.0136,
      "step": 66770
    },
    {
      "epoch": 8.04578313253012,
      "grad_norm": 0.0013392504770308733,
      "learning_rate": 3.90843373493976e-06,
      "loss": 0.0044,
      "step": 66780
    },
    {
      "epoch": 8.046987951807228,
      "grad_norm": 1.1737984418869019,
      "learning_rate": 3.906024096385542e-06,
      "loss": 0.0086,
      "step": 66790
    },
    {
      "epoch": 8.048192771084338,
      "grad_norm": 1.2303292751312256,
      "learning_rate": 3.903614457831326e-06,
      "loss": 0.0144,
      "step": 66800
    },
    {
      "epoch": 8.049397590361446,
      "grad_norm": 0.0024662085343152285,
      "learning_rate": 3.901204819277108e-06,
      "loss": 0.0159,
      "step": 66810
    },
    {
      "epoch": 8.050602409638554,
      "grad_norm": 0.0018872783984988928,
      "learning_rate": 3.8987951807228915e-06,
      "loss": 0.026,
      "step": 66820
    },
    {
      "epoch": 8.051807228915663,
      "grad_norm": 0.7830106616020203,
      "learning_rate": 3.8963855421686755e-06,
      "loss": 0.0198,
      "step": 66830
    },
    {
      "epoch": 8.053012048192771,
      "grad_norm": 0.329393595457077,
      "learning_rate": 3.893975903614458e-06,
      "loss": 0.0027,
      "step": 66840
    },
    {
      "epoch": 8.05421686746988,
      "grad_norm": 1.7850204706192017,
      "learning_rate": 3.891566265060242e-06,
      "loss": 0.0077,
      "step": 66850
    },
    {
      "epoch": 8.055421686746987,
      "grad_norm": 0.0011846048291772604,
      "learning_rate": 3.889156626506024e-06,
      "loss": 0.0176,
      "step": 66860
    },
    {
      "epoch": 8.056626506024097,
      "grad_norm": 0.0008543066214770079,
      "learning_rate": 3.886746987951807e-06,
      "loss": 0.0236,
      "step": 66870
    },
    {
      "epoch": 8.057831325301205,
      "grad_norm": 1.0860726833343506,
      "learning_rate": 3.8843373493975906e-06,
      "loss": 0.0438,
      "step": 66880
    },
    {
      "epoch": 8.059036144578313,
      "grad_norm": 0.19602154195308685,
      "learning_rate": 3.881927710843374e-06,
      "loss": 0.0072,
      "step": 66890
    },
    {
      "epoch": 8.060240963855422,
      "grad_norm": 0.0016662025591358542,
      "learning_rate": 3.879518072289157e-06,
      "loss": 0.0155,
      "step": 66900
    },
    {
      "epoch": 8.06144578313253,
      "grad_norm": 2.3582351207733154,
      "learning_rate": 3.87710843373494e-06,
      "loss": 0.0269,
      "step": 66910
    },
    {
      "epoch": 8.062650602409638,
      "grad_norm": 0.7738903760910034,
      "learning_rate": 3.874698795180723e-06,
      "loss": 0.0288,
      "step": 66920
    },
    {
      "epoch": 8.063855421686746,
      "grad_norm": 2.3447797298431396,
      "learning_rate": 3.8722891566265065e-06,
      "loss": 0.0383,
      "step": 66930
    },
    {
      "epoch": 8.065060240963856,
      "grad_norm": 0.8004823923110962,
      "learning_rate": 3.86987951807229e-06,
      "loss": 0.0194,
      "step": 66940
    },
    {
      "epoch": 8.066265060240964,
      "grad_norm": 0.003766872687265277,
      "learning_rate": 3.867469879518073e-06,
      "loss": 0.0288,
      "step": 66950
    },
    {
      "epoch": 8.067469879518072,
      "grad_norm": 0.0015524171758443117,
      "learning_rate": 3.865060240963856e-06,
      "loss": 0.0104,
      "step": 66960
    },
    {
      "epoch": 8.068674698795181,
      "grad_norm": 0.0024930955842137337,
      "learning_rate": 3.862650602409639e-06,
      "loss": 0.0078,
      "step": 66970
    },
    {
      "epoch": 8.06987951807229,
      "grad_norm": 0.24281220138072968,
      "learning_rate": 3.860240963855422e-06,
      "loss": 0.0391,
      "step": 66980
    },
    {
      "epoch": 8.071084337349397,
      "grad_norm": 0.007979141548275948,
      "learning_rate": 3.857831325301205e-06,
      "loss": 0.0147,
      "step": 66990
    },
    {
      "epoch": 8.072289156626505,
      "grad_norm": 0.015899188816547394,
      "learning_rate": 3.855421686746989e-06,
      "loss": 0.0151,
      "step": 67000
    },
    {
      "epoch": 8.073493975903615,
      "grad_norm": 0.013088508509099483,
      "learning_rate": 3.853012048192771e-06,
      "loss": 0.002,
      "step": 67010
    },
    {
      "epoch": 8.074698795180723,
      "grad_norm": 0.004443296231329441,
      "learning_rate": 3.850602409638555e-06,
      "loss": 0.0062,
      "step": 67020
    },
    {
      "epoch": 8.07590361445783,
      "grad_norm": 0.9236980676651001,
      "learning_rate": 3.848192771084337e-06,
      "loss": 0.0027,
      "step": 67030
    },
    {
      "epoch": 8.07710843373494,
      "grad_norm": 0.007380950730293989,
      "learning_rate": 3.8457831325301205e-06,
      "loss": 0.0023,
      "step": 67040
    },
    {
      "epoch": 8.078313253012048,
      "grad_norm": 1.6433264017105103,
      "learning_rate": 3.843373493975904e-06,
      "loss": 0.0129,
      "step": 67050
    },
    {
      "epoch": 8.079518072289156,
      "grad_norm": 0.0014176617842167616,
      "learning_rate": 3.840963855421687e-06,
      "loss": 0.0029,
      "step": 67060
    },
    {
      "epoch": 8.080722891566266,
      "grad_norm": 0.24716201424598694,
      "learning_rate": 3.83855421686747e-06,
      "loss": 0.0024,
      "step": 67070
    },
    {
      "epoch": 8.081927710843374,
      "grad_norm": 0.04344303160905838,
      "learning_rate": 3.836144578313253e-06,
      "loss": 0.0138,
      "step": 67080
    },
    {
      "epoch": 8.083132530120482,
      "grad_norm": 0.00131865160074085,
      "learning_rate": 3.833734939759036e-06,
      "loss": 0.008,
      "step": 67090
    },
    {
      "epoch": 8.08433734939759,
      "grad_norm": 0.0010833737906068563,
      "learning_rate": 3.83132530120482e-06,
      "loss": 0.0179,
      "step": 67100
    },
    {
      "epoch": 8.0855421686747,
      "grad_norm": 0.0030849443282932043,
      "learning_rate": 3.828915662650603e-06,
      "loss": 0.0104,
      "step": 67110
    },
    {
      "epoch": 8.086746987951807,
      "grad_norm": 0.0018045066390186548,
      "learning_rate": 3.826506024096386e-06,
      "loss": 0.001,
      "step": 67120
    },
    {
      "epoch": 8.087951807228915,
      "grad_norm": 0.31874921917915344,
      "learning_rate": 3.824096385542169e-06,
      "loss": 0.0186,
      "step": 67130
    },
    {
      "epoch": 8.089156626506025,
      "grad_norm": 4.599441051483154,
      "learning_rate": 3.821686746987952e-06,
      "loss": 0.0234,
      "step": 67140
    },
    {
      "epoch": 8.090361445783133,
      "grad_norm": 0.0070083262398839,
      "learning_rate": 3.8192771084337355e-06,
      "loss": 0.0064,
      "step": 67150
    },
    {
      "epoch": 8.09156626506024,
      "grad_norm": 0.0009690760634839535,
      "learning_rate": 3.816867469879519e-06,
      "loss": 0.0082,
      "step": 67160
    },
    {
      "epoch": 8.092771084337349,
      "grad_norm": 0.002169884042814374,
      "learning_rate": 3.814457831325302e-06,
      "loss": 0.0153,
      "step": 67170
    },
    {
      "epoch": 8.093975903614458,
      "grad_norm": 0.003284999867901206,
      "learning_rate": 3.8120481927710846e-06,
      "loss": 0.0117,
      "step": 67180
    },
    {
      "epoch": 8.095180722891566,
      "grad_norm": 0.8436072468757629,
      "learning_rate": 3.8096385542168678e-06,
      "loss": 0.0154,
      "step": 67190
    },
    {
      "epoch": 8.096385542168674,
      "grad_norm": 0.0006439302233047783,
      "learning_rate": 3.807228915662651e-06,
      "loss": 0.0269,
      "step": 67200
    },
    {
      "epoch": 8.097590361445784,
      "grad_norm": 0.007943126372992992,
      "learning_rate": 3.804819277108434e-06,
      "loss": 0.0182,
      "step": 67210
    },
    {
      "epoch": 8.098795180722892,
      "grad_norm": 2.1402339935302734,
      "learning_rate": 3.802409638554217e-06,
      "loss": 0.0142,
      "step": 67220
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.0008576022810302675,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.0042,
      "step": 67230
    },
    {
      "epoch": 8.101204819277108,
      "grad_norm": 1.1840224266052246,
      "learning_rate": 3.7975903614457832e-06,
      "loss": 0.0163,
      "step": 67240
    },
    {
      "epoch": 8.102409638554217,
      "grad_norm": 0.16051052510738373,
      "learning_rate": 3.7951807228915664e-06,
      "loss": 0.0362,
      "step": 67250
    },
    {
      "epoch": 8.103614457831325,
      "grad_norm": 0.0039664264768362045,
      "learning_rate": 3.79277108433735e-06,
      "loss": 0.0292,
      "step": 67260
    },
    {
      "epoch": 8.104819277108433,
      "grad_norm": 0.005134064704179764,
      "learning_rate": 3.7903614457831327e-06,
      "loss": 0.0027,
      "step": 67270
    },
    {
      "epoch": 8.106024096385543,
      "grad_norm": 1.2023156881332397,
      "learning_rate": 3.7879518072289163e-06,
      "loss": 0.0167,
      "step": 67280
    },
    {
      "epoch": 8.10722891566265,
      "grad_norm": 0.19672200083732605,
      "learning_rate": 3.785542168674699e-06,
      "loss": 0.0062,
      "step": 67290
    },
    {
      "epoch": 8.108433734939759,
      "grad_norm": 0.1792910248041153,
      "learning_rate": 3.7831325301204823e-06,
      "loss": 0.0185,
      "step": 67300
    },
    {
      "epoch": 8.109638554216868,
      "grad_norm": 0.007933610118925571,
      "learning_rate": 3.7807228915662654e-06,
      "loss": 0.0376,
      "step": 67310
    },
    {
      "epoch": 8.110843373493976,
      "grad_norm": 0.017020968720316887,
      "learning_rate": 3.7783132530120486e-06,
      "loss": 0.0229,
      "step": 67320
    },
    {
      "epoch": 8.112048192771084,
      "grad_norm": 0.0010856761364266276,
      "learning_rate": 3.7759036144578314e-06,
      "loss": 0.0102,
      "step": 67330
    },
    {
      "epoch": 8.113253012048192,
      "grad_norm": 1.044198751449585,
      "learning_rate": 3.773493975903615e-06,
      "loss": 0.0289,
      "step": 67340
    },
    {
      "epoch": 8.114457831325302,
      "grad_norm": 0.007307280320674181,
      "learning_rate": 3.7710843373493977e-06,
      "loss": 0.0356,
      "step": 67350
    },
    {
      "epoch": 8.11566265060241,
      "grad_norm": 0.20419424772262573,
      "learning_rate": 3.768674698795181e-06,
      "loss": 0.0047,
      "step": 67360
    },
    {
      "epoch": 8.116867469879518,
      "grad_norm": 1.8376821279525757,
      "learning_rate": 3.766265060240964e-06,
      "loss": 0.0478,
      "step": 67370
    },
    {
      "epoch": 8.118072289156627,
      "grad_norm": 0.00041954219341278076,
      "learning_rate": 3.7638554216867473e-06,
      "loss": 0.0024,
      "step": 67380
    },
    {
      "epoch": 8.119277108433735,
      "grad_norm": 0.0022742385044693947,
      "learning_rate": 3.76144578313253e-06,
      "loss": 0.0128,
      "step": 67390
    },
    {
      "epoch": 8.120481927710843,
      "grad_norm": 0.0010724443709477782,
      "learning_rate": 3.7590361445783136e-06,
      "loss": 0.0198,
      "step": 67400
    },
    {
      "epoch": 8.121686746987951,
      "grad_norm": 0.0009161687921732664,
      "learning_rate": 3.7566265060240968e-06,
      "loss": 0.0019,
      "step": 67410
    },
    {
      "epoch": 8.12289156626506,
      "grad_norm": 0.001155208912678063,
      "learning_rate": 3.75421686746988e-06,
      "loss": 0.0235,
      "step": 67420
    },
    {
      "epoch": 8.124096385542169,
      "grad_norm": 0.22433947026729584,
      "learning_rate": 3.751807228915663e-06,
      "loss": 0.0143,
      "step": 67430
    },
    {
      "epoch": 8.125301204819277,
      "grad_norm": 1.065854549407959,
      "learning_rate": 3.749397590361446e-06,
      "loss": 0.027,
      "step": 67440
    },
    {
      "epoch": 8.126506024096386,
      "grad_norm": 0.000586383044719696,
      "learning_rate": 3.7469879518072295e-06,
      "loss": 0.0212,
      "step": 67450
    },
    {
      "epoch": 8.127710843373494,
      "grad_norm": 0.0012482673628255725,
      "learning_rate": 3.7445783132530122e-06,
      "loss": 0.0303,
      "step": 67460
    },
    {
      "epoch": 8.128915662650602,
      "grad_norm": 0.8810485005378723,
      "learning_rate": 3.742168674698796e-06,
      "loss": 0.0343,
      "step": 67470
    },
    {
      "epoch": 8.13012048192771,
      "grad_norm": 0.0013493163278326392,
      "learning_rate": 3.7397590361445786e-06,
      "loss": 0.0322,
      "step": 67480
    },
    {
      "epoch": 8.13132530120482,
      "grad_norm": 0.0009091668762266636,
      "learning_rate": 3.7373493975903618e-06,
      "loss": 0.0134,
      "step": 67490
    },
    {
      "epoch": 8.132530120481928,
      "grad_norm": 0.001199993770569563,
      "learning_rate": 3.7349397590361445e-06,
      "loss": 0.0039,
      "step": 67500
    },
    {
      "epoch": 8.133734939759035,
      "grad_norm": 0.1449514925479889,
      "learning_rate": 3.732530120481928e-06,
      "loss": 0.001,
      "step": 67510
    },
    {
      "epoch": 8.134939759036145,
      "grad_norm": 0.4254106283187866,
      "learning_rate": 3.730120481927711e-06,
      "loss": 0.0185,
      "step": 67520
    },
    {
      "epoch": 8.136144578313253,
      "grad_norm": 1.2108042240142822,
      "learning_rate": 3.7277108433734945e-06,
      "loss": 0.0126,
      "step": 67530
    },
    {
      "epoch": 8.137349397590361,
      "grad_norm": 0.0028951175045222044,
      "learning_rate": 3.7253012048192772e-06,
      "loss": 0.0,
      "step": 67540
    },
    {
      "epoch": 8.13855421686747,
      "grad_norm": 0.0008411704329773784,
      "learning_rate": 3.7228915662650604e-06,
      "loss": 0.014,
      "step": 67550
    },
    {
      "epoch": 8.139759036144579,
      "grad_norm": 0.0007389378151856363,
      "learning_rate": 3.720481927710844e-06,
      "loss": 0.007,
      "step": 67560
    },
    {
      "epoch": 8.140963855421687,
      "grad_norm": 0.0008884223643690348,
      "learning_rate": 3.7180722891566268e-06,
      "loss": 0.0214,
      "step": 67570
    },
    {
      "epoch": 8.142168674698794,
      "grad_norm": 0.0006027371273376048,
      "learning_rate": 3.7156626506024104e-06,
      "loss": 0.0468,
      "step": 67580
    },
    {
      "epoch": 8.143373493975904,
      "grad_norm": 0.0011082054115831852,
      "learning_rate": 3.713253012048193e-06,
      "loss": 0.0112,
      "step": 67590
    },
    {
      "epoch": 8.144578313253012,
      "grad_norm": 2.0247373580932617,
      "learning_rate": 3.7108433734939763e-06,
      "loss": 0.0156,
      "step": 67600
    },
    {
      "epoch": 8.14578313253012,
      "grad_norm": 0.23202435672283173,
      "learning_rate": 3.708433734939759e-06,
      "loss": 0.0172,
      "step": 67610
    },
    {
      "epoch": 8.14698795180723,
      "grad_norm": 0.0011467495933175087,
      "learning_rate": 3.7060240963855426e-06,
      "loss": 0.0469,
      "step": 67620
    },
    {
      "epoch": 8.148192771084338,
      "grad_norm": 1.0530048608779907,
      "learning_rate": 3.7036144578313254e-06,
      "loss": 0.0137,
      "step": 67630
    },
    {
      "epoch": 8.149397590361446,
      "grad_norm": 42.046810150146484,
      "learning_rate": 3.701204819277109e-06,
      "loss": 0.008,
      "step": 67640
    },
    {
      "epoch": 8.150602409638553,
      "grad_norm": 0.0013470927951857448,
      "learning_rate": 3.6987951807228917e-06,
      "loss": 0.0615,
      "step": 67650
    },
    {
      "epoch": 8.151807228915663,
      "grad_norm": 0.0013511033030226827,
      "learning_rate": 3.696385542168675e-06,
      "loss": 0.0047,
      "step": 67660
    },
    {
      "epoch": 8.153012048192771,
      "grad_norm": 0.003056552726775408,
      "learning_rate": 3.693975903614458e-06,
      "loss": 0.0103,
      "step": 67670
    },
    {
      "epoch": 8.154216867469879,
      "grad_norm": 0.0008138160337693989,
      "learning_rate": 3.6915662650602413e-06,
      "loss": 0.0055,
      "step": 67680
    },
    {
      "epoch": 8.155421686746989,
      "grad_norm": 0.0023200539872050285,
      "learning_rate": 3.689156626506024e-06,
      "loss": 0.0248,
      "step": 67690
    },
    {
      "epoch": 8.156626506024097,
      "grad_norm": 2.406292200088501,
      "learning_rate": 3.6867469879518076e-06,
      "loss": 0.0293,
      "step": 67700
    },
    {
      "epoch": 8.157831325301204,
      "grad_norm": 0.005414016544818878,
      "learning_rate": 3.684337349397591e-06,
      "loss": 0.007,
      "step": 67710
    },
    {
      "epoch": 8.159036144578312,
      "grad_norm": 2.0675199031829834,
      "learning_rate": 3.6819277108433735e-06,
      "loss": 0.0235,
      "step": 67720
    },
    {
      "epoch": 8.160240963855422,
      "grad_norm": 0.0025867577642202377,
      "learning_rate": 3.679518072289157e-06,
      "loss": 0.0012,
      "step": 67730
    },
    {
      "epoch": 8.16144578313253,
      "grad_norm": 0.0058488487266004086,
      "learning_rate": 3.67710843373494e-06,
      "loss": 0.0095,
      "step": 67740
    },
    {
      "epoch": 8.162650602409638,
      "grad_norm": 0.0016938337357714772,
      "learning_rate": 3.6746987951807235e-06,
      "loss": 0.0008,
      "step": 67750
    },
    {
      "epoch": 8.163855421686748,
      "grad_norm": 0.0013172292383387685,
      "learning_rate": 3.6722891566265063e-06,
      "loss": 0.0112,
      "step": 67760
    },
    {
      "epoch": 8.165060240963856,
      "grad_norm": 0.002876639598980546,
      "learning_rate": 3.6698795180722894e-06,
      "loss": 0.0028,
      "step": 67770
    },
    {
      "epoch": 8.166265060240963,
      "grad_norm": 0.3039686679840088,
      "learning_rate": 3.6674698795180726e-06,
      "loss": 0.0348,
      "step": 67780
    },
    {
      "epoch": 8.167469879518073,
      "grad_norm": 0.122322678565979,
      "learning_rate": 3.6650602409638558e-06,
      "loss": 0.0119,
      "step": 67790
    },
    {
      "epoch": 8.168674698795181,
      "grad_norm": 0.0007204670691862702,
      "learning_rate": 3.6626506024096385e-06,
      "loss": 0.006,
      "step": 67800
    },
    {
      "epoch": 8.169879518072289,
      "grad_norm": 0.005083044059574604,
      "learning_rate": 3.660240963855422e-06,
      "loss": 0.0498,
      "step": 67810
    },
    {
      "epoch": 8.171084337349397,
      "grad_norm": 0.7229157090187073,
      "learning_rate": 3.657831325301205e-06,
      "loss": 0.0036,
      "step": 67820
    },
    {
      "epoch": 8.172289156626507,
      "grad_norm": 0.008038370870053768,
      "learning_rate": 3.6554216867469885e-06,
      "loss": 0.0005,
      "step": 67830
    },
    {
      "epoch": 8.173493975903614,
      "grad_norm": 1.5401175022125244,
      "learning_rate": 3.6530120481927712e-06,
      "loss": 0.0052,
      "step": 67840
    },
    {
      "epoch": 8.174698795180722,
      "grad_norm": 0.006883387453854084,
      "learning_rate": 3.6506024096385544e-06,
      "loss": 0.0069,
      "step": 67850
    },
    {
      "epoch": 8.175903614457832,
      "grad_norm": 0.009434551931917667,
      "learning_rate": 3.648192771084338e-06,
      "loss": 0.0356,
      "step": 67860
    },
    {
      "epoch": 8.17710843373494,
      "grad_norm": 0.001141275279223919,
      "learning_rate": 3.6457831325301208e-06,
      "loss": 0.0367,
      "step": 67870
    },
    {
      "epoch": 8.178313253012048,
      "grad_norm": 0.0036081348080188036,
      "learning_rate": 3.643373493975904e-06,
      "loss": 0.0003,
      "step": 67880
    },
    {
      "epoch": 8.179518072289156,
      "grad_norm": 0.009125998243689537,
      "learning_rate": 3.640963855421687e-06,
      "loss": 0.0209,
      "step": 67890
    },
    {
      "epoch": 8.180722891566266,
      "grad_norm": 6.809463977813721,
      "learning_rate": 3.6385542168674703e-06,
      "loss": 0.023,
      "step": 67900
    },
    {
      "epoch": 8.181927710843373,
      "grad_norm": 0.0036350791342556477,
      "learning_rate": 3.636144578313253e-06,
      "loss": 0.0032,
      "step": 67910
    },
    {
      "epoch": 8.183132530120481,
      "grad_norm": 0.0016227241139858961,
      "learning_rate": 3.6337349397590366e-06,
      "loss": 0.0008,
      "step": 67920
    },
    {
      "epoch": 8.184337349397591,
      "grad_norm": 0.004252993036061525,
      "learning_rate": 3.6313253012048194e-06,
      "loss": 0.0091,
      "step": 67930
    },
    {
      "epoch": 8.185542168674699,
      "grad_norm": 0.02397121489048004,
      "learning_rate": 3.628915662650603e-06,
      "loss": 0.0007,
      "step": 67940
    },
    {
      "epoch": 8.186746987951807,
      "grad_norm": 0.003442071843892336,
      "learning_rate": 3.6265060240963857e-06,
      "loss": 0.0147,
      "step": 67950
    },
    {
      "epoch": 8.187951807228915,
      "grad_norm": 0.0018639623885974288,
      "learning_rate": 3.624096385542169e-06,
      "loss": 0.0224,
      "step": 67960
    },
    {
      "epoch": 8.189156626506024,
      "grad_norm": 0.10514391958713531,
      "learning_rate": 3.6216867469879517e-06,
      "loss": 0.0003,
      "step": 67970
    },
    {
      "epoch": 8.190361445783132,
      "grad_norm": 0.003769846400246024,
      "learning_rate": 3.6192771084337353e-06,
      "loss": 0.0116,
      "step": 67980
    },
    {
      "epoch": 8.19156626506024,
      "grad_norm": 0.010583973489701748,
      "learning_rate": 3.6168674698795185e-06,
      "loss": 0.0049,
      "step": 67990
    },
    {
      "epoch": 8.19277108433735,
      "grad_norm": 2.544401168823242,
      "learning_rate": 3.6144578313253016e-06,
      "loss": 0.0361,
      "step": 68000
    },
    {
      "epoch": 8.193975903614458,
      "grad_norm": 0.0009080752497538924,
      "learning_rate": 3.612048192771085e-06,
      "loss": 0.0092,
      "step": 68010
    },
    {
      "epoch": 8.195180722891566,
      "grad_norm": 0.0009111163089983165,
      "learning_rate": 3.6096385542168676e-06,
      "loss": 0.0609,
      "step": 68020
    },
    {
      "epoch": 8.196385542168676,
      "grad_norm": 0.0015716420020908117,
      "learning_rate": 3.607228915662651e-06,
      "loss": 0.0228,
      "step": 68030
    },
    {
      "epoch": 8.197590361445783,
      "grad_norm": 2.4605700969696045,
      "learning_rate": 3.604819277108434e-06,
      "loss": 0.0237,
      "step": 68040
    },
    {
      "epoch": 8.198795180722891,
      "grad_norm": 5.079934120178223,
      "learning_rate": 3.6024096385542175e-06,
      "loss": 0.0559,
      "step": 68050
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.2139683961868286,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.0292,
      "step": 68060
    },
    {
      "epoch": 8.201204819277109,
      "grad_norm": 2.256594181060791,
      "learning_rate": 3.5975903614457834e-06,
      "loss": 0.0387,
      "step": 68070
    },
    {
      "epoch": 8.202409638554217,
      "grad_norm": 1.791480541229248,
      "learning_rate": 3.595180722891566e-06,
      "loss": 0.0126,
      "step": 68080
    },
    {
      "epoch": 8.203614457831325,
      "grad_norm": 0.038136932998895645,
      "learning_rate": 3.59277108433735e-06,
      "loss": 0.0155,
      "step": 68090
    },
    {
      "epoch": 8.204819277108435,
      "grad_norm": 2.156450033187866,
      "learning_rate": 3.5903614457831325e-06,
      "loss": 0.0262,
      "step": 68100
    },
    {
      "epoch": 8.206024096385542,
      "grad_norm": 0.1899128407239914,
      "learning_rate": 3.587951807228916e-06,
      "loss": 0.0194,
      "step": 68110
    },
    {
      "epoch": 8.20722891566265,
      "grad_norm": 0.002472391352057457,
      "learning_rate": 3.585542168674699e-06,
      "loss": 0.0147,
      "step": 68120
    },
    {
      "epoch": 8.208433734939758,
      "grad_norm": 8.701395988464355,
      "learning_rate": 3.583132530120482e-06,
      "loss": 0.0364,
      "step": 68130
    },
    {
      "epoch": 8.209638554216868,
      "grad_norm": 0.14633356034755707,
      "learning_rate": 3.5807228915662657e-06,
      "loss": 0.0008,
      "step": 68140
    },
    {
      "epoch": 8.210843373493976,
      "grad_norm": 0.0033640756737440825,
      "learning_rate": 3.5783132530120484e-06,
      "loss": 0.0089,
      "step": 68150
    },
    {
      "epoch": 8.212048192771084,
      "grad_norm": 2.013934850692749,
      "learning_rate": 3.575903614457832e-06,
      "loss": 0.0215,
      "step": 68160
    },
    {
      "epoch": 8.213253012048193,
      "grad_norm": 0.014661996625363827,
      "learning_rate": 3.5734939759036148e-06,
      "loss": 0.0227,
      "step": 68170
    },
    {
      "epoch": 8.214457831325301,
      "grad_norm": 0.03678460791707039,
      "learning_rate": 3.571084337349398e-06,
      "loss": 0.0182,
      "step": 68180
    },
    {
      "epoch": 8.21566265060241,
      "grad_norm": 0.047925569117069244,
      "learning_rate": 3.568674698795181e-06,
      "loss": 0.0163,
      "step": 68190
    },
    {
      "epoch": 8.216867469879517,
      "grad_norm": 1.4310736656188965,
      "learning_rate": 3.5662650602409643e-06,
      "loss": 0.0275,
      "step": 68200
    },
    {
      "epoch": 8.218072289156627,
      "grad_norm": 0.745675802230835,
      "learning_rate": 3.563855421686747e-06,
      "loss": 0.0379,
      "step": 68210
    },
    {
      "epoch": 8.219277108433735,
      "grad_norm": 0.09678752720355988,
      "learning_rate": 3.5614457831325307e-06,
      "loss": 0.022,
      "step": 68220
    },
    {
      "epoch": 8.220481927710843,
      "grad_norm": 0.003864442929625511,
      "learning_rate": 3.5590361445783134e-06,
      "loss": 0.013,
      "step": 68230
    },
    {
      "epoch": 8.221686746987952,
      "grad_norm": 0.013323741964995861,
      "learning_rate": 3.5566265060240966e-06,
      "loss": 0.0182,
      "step": 68240
    },
    {
      "epoch": 8.22289156626506,
      "grad_norm": 1.5075117349624634,
      "learning_rate": 3.5542168674698798e-06,
      "loss": 0.0143,
      "step": 68250
    },
    {
      "epoch": 8.224096385542168,
      "grad_norm": 0.0025845111813396215,
      "learning_rate": 3.551807228915663e-06,
      "loss": 0.0077,
      "step": 68260
    },
    {
      "epoch": 8.225301204819278,
      "grad_norm": 0.4582977592945099,
      "learning_rate": 3.5493975903614457e-06,
      "loss": 0.0073,
      "step": 68270
    },
    {
      "epoch": 8.226506024096386,
      "grad_norm": 0.34165945649147034,
      "learning_rate": 3.5469879518072293e-06,
      "loss": 0.0312,
      "step": 68280
    },
    {
      "epoch": 8.227710843373494,
      "grad_norm": 0.781821072101593,
      "learning_rate": 3.5445783132530125e-06,
      "loss": 0.0047,
      "step": 68290
    },
    {
      "epoch": 8.228915662650602,
      "grad_norm": 2.5778017044067383,
      "learning_rate": 3.5421686746987956e-06,
      "loss": 0.0442,
      "step": 68300
    },
    {
      "epoch": 8.230120481927711,
      "grad_norm": 0.015493272803723812,
      "learning_rate": 3.539759036144579e-06,
      "loss": 0.007,
      "step": 68310
    },
    {
      "epoch": 8.23132530120482,
      "grad_norm": 0.0015451268991455436,
      "learning_rate": 3.5373493975903616e-06,
      "loss": 0.0503,
      "step": 68320
    },
    {
      "epoch": 8.232530120481927,
      "grad_norm": 0.02458225004374981,
      "learning_rate": 3.534939759036145e-06,
      "loss": 0.0026,
      "step": 68330
    },
    {
      "epoch": 8.233734939759037,
      "grad_norm": 0.046464670449495316,
      "learning_rate": 3.532530120481928e-06,
      "loss": 0.0382,
      "step": 68340
    },
    {
      "epoch": 8.234939759036145,
      "grad_norm": 2.137721061706543,
      "learning_rate": 3.530120481927711e-06,
      "loss": 0.0116,
      "step": 68350
    },
    {
      "epoch": 8.236144578313253,
      "grad_norm": 0.012435142882168293,
      "learning_rate": 3.5277108433734943e-06,
      "loss": 0.0032,
      "step": 68360
    },
    {
      "epoch": 8.23734939759036,
      "grad_norm": 2.302232503890991,
      "learning_rate": 3.5253012048192774e-06,
      "loss": 0.0162,
      "step": 68370
    },
    {
      "epoch": 8.23855421686747,
      "grad_norm": 0.2692420780658722,
      "learning_rate": 3.52289156626506e-06,
      "loss": 0.0122,
      "step": 68380
    },
    {
      "epoch": 8.239759036144578,
      "grad_norm": 0.001997890882194042,
      "learning_rate": 3.520481927710844e-06,
      "loss": 0.0049,
      "step": 68390
    },
    {
      "epoch": 8.240963855421686,
      "grad_norm": 0.0025382498279213905,
      "learning_rate": 3.5180722891566266e-06,
      "loss": 0.003,
      "step": 68400
    },
    {
      "epoch": 8.242168674698796,
      "grad_norm": 0.0017643674509599805,
      "learning_rate": 3.51566265060241e-06,
      "loss": 0.004,
      "step": 68410
    },
    {
      "epoch": 8.243373493975904,
      "grad_norm": 0.05009251832962036,
      "learning_rate": 3.513253012048193e-06,
      "loss": 0.0371,
      "step": 68420
    },
    {
      "epoch": 8.244578313253012,
      "grad_norm": 1.6187992095947266,
      "learning_rate": 3.510843373493976e-06,
      "loss": 0.0105,
      "step": 68430
    },
    {
      "epoch": 8.24578313253012,
      "grad_norm": 0.7788544297218323,
      "learning_rate": 3.5084337349397597e-06,
      "loss": 0.0274,
      "step": 68440
    },
    {
      "epoch": 8.24698795180723,
      "grad_norm": 0.025110747665166855,
      "learning_rate": 3.5060240963855424e-06,
      "loss": 0.0159,
      "step": 68450
    },
    {
      "epoch": 8.248192771084337,
      "grad_norm": 0.05900610610842705,
      "learning_rate": 3.5036144578313256e-06,
      "loss": 0.0158,
      "step": 68460
    },
    {
      "epoch": 8.249397590361445,
      "grad_norm": 0.0036365671548992395,
      "learning_rate": 3.5012048192771088e-06,
      "loss": 0.0096,
      "step": 68470
    },
    {
      "epoch": 8.250602409638555,
      "grad_norm": 0.0074283224530518055,
      "learning_rate": 3.498795180722892e-06,
      "loss": 0.0125,
      "step": 68480
    },
    {
      "epoch": 8.251807228915663,
      "grad_norm": 0.0007523905369453132,
      "learning_rate": 3.4963855421686747e-06,
      "loss": 0.0029,
      "step": 68490
    },
    {
      "epoch": 8.25301204819277,
      "grad_norm": 0.002738177077844739,
      "learning_rate": 3.4939759036144583e-06,
      "loss": 0.0193,
      "step": 68500
    },
    {
      "epoch": 8.25421686746988,
      "grad_norm": 0.012920187786221504,
      "learning_rate": 3.491566265060241e-06,
      "loss": 0.0032,
      "step": 68510
    },
    {
      "epoch": 8.255421686746988,
      "grad_norm": 1.7734454870224,
      "learning_rate": 3.4891566265060247e-06,
      "loss": 0.0063,
      "step": 68520
    },
    {
      "epoch": 8.256626506024096,
      "grad_norm": 0.0007912698783911765,
      "learning_rate": 3.4867469879518074e-06,
      "loss": 0.0252,
      "step": 68530
    },
    {
      "epoch": 8.257831325301204,
      "grad_norm": 9.517416000366211,
      "learning_rate": 3.4843373493975906e-06,
      "loss": 0.0386,
      "step": 68540
    },
    {
      "epoch": 8.259036144578314,
      "grad_norm": 0.006395512260496616,
      "learning_rate": 3.4819277108433733e-06,
      "loss": 0.0268,
      "step": 68550
    },
    {
      "epoch": 8.260240963855422,
      "grad_norm": 0.0031706991139799356,
      "learning_rate": 3.479518072289157e-06,
      "loss": 0.0161,
      "step": 68560
    },
    {
      "epoch": 8.26144578313253,
      "grad_norm": 0.0021125408820807934,
      "learning_rate": 3.4771084337349397e-06,
      "loss": 0.0242,
      "step": 68570
    },
    {
      "epoch": 8.26265060240964,
      "grad_norm": 0.0013862509513273835,
      "learning_rate": 3.4746987951807233e-06,
      "loss": 0.0284,
      "step": 68580
    },
    {
      "epoch": 8.263855421686747,
      "grad_norm": 0.01800594851374626,
      "learning_rate": 3.4722891566265065e-06,
      "loss": 0.0161,
      "step": 68590
    },
    {
      "epoch": 8.265060240963855,
      "grad_norm": 0.0033660067711025476,
      "learning_rate": 3.4698795180722892e-06,
      "loss": 0.0385,
      "step": 68600
    },
    {
      "epoch": 8.266265060240963,
      "grad_norm": 0.009940331801772118,
      "learning_rate": 3.467469879518073e-06,
      "loss": 0.0029,
      "step": 68610
    },
    {
      "epoch": 8.267469879518073,
      "grad_norm": 0.00205752020701766,
      "learning_rate": 3.4650602409638556e-06,
      "loss": 0.0194,
      "step": 68620
    },
    {
      "epoch": 8.26867469879518,
      "grad_norm": 2.972028970718384,
      "learning_rate": 3.462650602409639e-06,
      "loss": 0.0257,
      "step": 68630
    },
    {
      "epoch": 8.269879518072289,
      "grad_norm": 11.404129028320312,
      "learning_rate": 3.460240963855422e-06,
      "loss": 0.0039,
      "step": 68640
    },
    {
      "epoch": 8.271084337349398,
      "grad_norm": 0.8769717216491699,
      "learning_rate": 3.457831325301205e-06,
      "loss": 0.018,
      "step": 68650
    },
    {
      "epoch": 8.272289156626506,
      "grad_norm": 0.5157662034034729,
      "learning_rate": 3.4554216867469883e-06,
      "loss": 0.009,
      "step": 68660
    },
    {
      "epoch": 8.273493975903614,
      "grad_norm": 2.0911154747009277,
      "learning_rate": 3.4530120481927715e-06,
      "loss": 0.026,
      "step": 68670
    },
    {
      "epoch": 8.274698795180722,
      "grad_norm": 0.00896498840302229,
      "learning_rate": 3.450602409638554e-06,
      "loss": 0.0004,
      "step": 68680
    },
    {
      "epoch": 8.275903614457832,
      "grad_norm": 0.3714040219783783,
      "learning_rate": 3.448192771084338e-06,
      "loss": 0.0182,
      "step": 68690
    },
    {
      "epoch": 8.27710843373494,
      "grad_norm": 0.0058489530347287655,
      "learning_rate": 3.4457831325301206e-06,
      "loss": 0.0272,
      "step": 68700
    },
    {
      "epoch": 8.278313253012048,
      "grad_norm": 0.009364602155983448,
      "learning_rate": 3.4433734939759037e-06,
      "loss": 0.005,
      "step": 68710
    },
    {
      "epoch": 8.279518072289157,
      "grad_norm": 0.008076672442257404,
      "learning_rate": 3.440963855421687e-06,
      "loss": 0.0131,
      "step": 68720
    },
    {
      "epoch": 8.280722891566265,
      "grad_norm": 0.004457874223589897,
      "learning_rate": 3.43855421686747e-06,
      "loss": 0.0178,
      "step": 68730
    },
    {
      "epoch": 8.281927710843373,
      "grad_norm": 2.1666946411132812,
      "learning_rate": 3.4361445783132537e-06,
      "loss": 0.0435,
      "step": 68740
    },
    {
      "epoch": 8.283132530120483,
      "grad_norm": 0.004046435467898846,
      "learning_rate": 3.4337349397590364e-06,
      "loss": 0.0134,
      "step": 68750
    },
    {
      "epoch": 8.28433734939759,
      "grad_norm": 0.2420325130224228,
      "learning_rate": 3.4313253012048196e-06,
      "loss": 0.02,
      "step": 68760
    },
    {
      "epoch": 8.285542168674699,
      "grad_norm": 15.218395233154297,
      "learning_rate": 3.428915662650603e-06,
      "loss": 0.03,
      "step": 68770
    },
    {
      "epoch": 8.286746987951807,
      "grad_norm": 0.032915834337472916,
      "learning_rate": 3.426506024096386e-06,
      "loss": 0.0052,
      "step": 68780
    },
    {
      "epoch": 8.287951807228916,
      "grad_norm": 0.9129104614257812,
      "learning_rate": 3.4240963855421687e-06,
      "loss": 0.0107,
      "step": 68790
    },
    {
      "epoch": 8.289156626506024,
      "grad_norm": 0.004615303128957748,
      "learning_rate": 3.4216867469879523e-06,
      "loss": 0.0028,
      "step": 68800
    },
    {
      "epoch": 8.290361445783132,
      "grad_norm": 0.0018193606520071626,
      "learning_rate": 3.419277108433735e-06,
      "loss": 0.0015,
      "step": 68810
    },
    {
      "epoch": 8.291566265060242,
      "grad_norm": 0.5304901599884033,
      "learning_rate": 3.4168674698795182e-06,
      "loss": 0.0093,
      "step": 68820
    },
    {
      "epoch": 8.29277108433735,
      "grad_norm": 0.01756603643298149,
      "learning_rate": 3.4144578313253014e-06,
      "loss": 0.0117,
      "step": 68830
    },
    {
      "epoch": 8.293975903614458,
      "grad_norm": 2.1267240047454834,
      "learning_rate": 3.4120481927710846e-06,
      "loss": 0.0143,
      "step": 68840
    },
    {
      "epoch": 8.295180722891565,
      "grad_norm": 5.51439094543457,
      "learning_rate": 3.4096385542168674e-06,
      "loss": 0.0314,
      "step": 68850
    },
    {
      "epoch": 8.296385542168675,
      "grad_norm": 0.0019067650428041816,
      "learning_rate": 3.407228915662651e-06,
      "loss": 0.014,
      "step": 68860
    },
    {
      "epoch": 8.297590361445783,
      "grad_norm": 0.781670093536377,
      "learning_rate": 3.4048192771084337e-06,
      "loss": 0.0237,
      "step": 68870
    },
    {
      "epoch": 8.298795180722891,
      "grad_norm": 0.9284569025039673,
      "learning_rate": 3.4024096385542173e-06,
      "loss": 0.0126,
      "step": 68880
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.15072393417358398,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0201,
      "step": 68890
    },
    {
      "epoch": 8.301204819277109,
      "grad_norm": 0.9446389675140381,
      "learning_rate": 3.3975903614457832e-06,
      "loss": 0.0339,
      "step": 68900
    },
    {
      "epoch": 8.302409638554217,
      "grad_norm": 0.0009705598349682987,
      "learning_rate": 3.395180722891567e-06,
      "loss": 0.0183,
      "step": 68910
    },
    {
      "epoch": 8.303614457831324,
      "grad_norm": 1.3132495880126953,
      "learning_rate": 3.3927710843373496e-06,
      "loss": 0.0517,
      "step": 68920
    },
    {
      "epoch": 8.304819277108434,
      "grad_norm": 0.0030122133903205395,
      "learning_rate": 3.390361445783133e-06,
      "loss": 0.0021,
      "step": 68930
    },
    {
      "epoch": 8.306024096385542,
      "grad_norm": 0.0017322736093774438,
      "learning_rate": 3.387951807228916e-06,
      "loss": 0.0288,
      "step": 68940
    },
    {
      "epoch": 8.30722891566265,
      "grad_norm": 0.13115867972373962,
      "learning_rate": 3.385542168674699e-06,
      "loss": 0.0138,
      "step": 68950
    },
    {
      "epoch": 8.30843373493976,
      "grad_norm": 0.26525184512138367,
      "learning_rate": 3.383132530120482e-06,
      "loss": 0.0089,
      "step": 68960
    },
    {
      "epoch": 8.309638554216868,
      "grad_norm": 0.002143366262316704,
      "learning_rate": 3.3807228915662655e-06,
      "loss": 0.0055,
      "step": 68970
    },
    {
      "epoch": 8.310843373493976,
      "grad_norm": 0.8450101613998413,
      "learning_rate": 3.3783132530120482e-06,
      "loss": 0.0103,
      "step": 68980
    },
    {
      "epoch": 8.312048192771085,
      "grad_norm": 0.0022629115264862776,
      "learning_rate": 3.375903614457832e-06,
      "loss": 0.009,
      "step": 68990
    },
    {
      "epoch": 8.313253012048193,
      "grad_norm": 0.6179739832878113,
      "learning_rate": 3.3734939759036146e-06,
      "loss": 0.011,
      "step": 69000
    },
    {
      "epoch": 8.314457831325301,
      "grad_norm": 0.002048658672720194,
      "learning_rate": 3.3710843373493977e-06,
      "loss": 0.0634,
      "step": 69010
    },
    {
      "epoch": 8.315662650602409,
      "grad_norm": 0.003775537246838212,
      "learning_rate": 3.3686746987951813e-06,
      "loss": 0.0384,
      "step": 69020
    },
    {
      "epoch": 8.316867469879519,
      "grad_norm": 0.007070969324558973,
      "learning_rate": 3.366265060240964e-06,
      "loss": 0.0061,
      "step": 69030
    },
    {
      "epoch": 8.318072289156627,
      "grad_norm": 0.0015311279566958547,
      "learning_rate": 3.3638554216867477e-06,
      "loss": 0.0216,
      "step": 69040
    },
    {
      "epoch": 8.319277108433734,
      "grad_norm": 0.0031230018939822912,
      "learning_rate": 3.3614457831325305e-06,
      "loss": 0.0058,
      "step": 69050
    },
    {
      "epoch": 8.320481927710844,
      "grad_norm": 0.2969253361225128,
      "learning_rate": 3.3590361445783136e-06,
      "loss": 0.019,
      "step": 69060
    },
    {
      "epoch": 8.321686746987952,
      "grad_norm": 3.2566421031951904,
      "learning_rate": 3.3566265060240964e-06,
      "loss": 0.0171,
      "step": 69070
    },
    {
      "epoch": 8.32289156626506,
      "grad_norm": 0.391293466091156,
      "learning_rate": 3.35421686746988e-06,
      "loss": 0.0146,
      "step": 69080
    },
    {
      "epoch": 8.324096385542168,
      "grad_norm": 0.8506900072097778,
      "learning_rate": 3.3518072289156627e-06,
      "loss": 0.0107,
      "step": 69090
    },
    {
      "epoch": 8.325301204819278,
      "grad_norm": 0.0029083555564284325,
      "learning_rate": 3.3493975903614463e-06,
      "loss": 0.0067,
      "step": 69100
    },
    {
      "epoch": 8.326506024096386,
      "grad_norm": 0.17526189982891083,
      "learning_rate": 3.346987951807229e-06,
      "loss": 0.0498,
      "step": 69110
    },
    {
      "epoch": 8.327710843373493,
      "grad_norm": 1.0645084381103516,
      "learning_rate": 3.3445783132530123e-06,
      "loss": 0.0637,
      "step": 69120
    },
    {
      "epoch": 8.328915662650603,
      "grad_norm": 0.003995619248598814,
      "learning_rate": 3.3421686746987954e-06,
      "loss": 0.0117,
      "step": 69130
    },
    {
      "epoch": 8.330120481927711,
      "grad_norm": 1.4375499486923218,
      "learning_rate": 3.3397590361445786e-06,
      "loss": 0.0061,
      "step": 69140
    },
    {
      "epoch": 8.331325301204819,
      "grad_norm": 0.00573149835690856,
      "learning_rate": 3.3373493975903614e-06,
      "loss": 0.0135,
      "step": 69150
    },
    {
      "epoch": 8.332530120481927,
      "grad_norm": 0.017557987943291664,
      "learning_rate": 3.334939759036145e-06,
      "loss": 0.0219,
      "step": 69160
    },
    {
      "epoch": 8.333734939759037,
      "grad_norm": 0.06645628064870834,
      "learning_rate": 3.332530120481928e-06,
      "loss": 0.0153,
      "step": 69170
    },
    {
      "epoch": 8.334939759036144,
      "grad_norm": 0.005758879706263542,
      "learning_rate": 3.330120481927711e-06,
      "loss": 0.0104,
      "step": 69180
    },
    {
      "epoch": 8.336144578313252,
      "grad_norm": 0.12457803636789322,
      "learning_rate": 3.3277108433734945e-06,
      "loss": 0.0014,
      "step": 69190
    },
    {
      "epoch": 8.337349397590362,
      "grad_norm": 0.11725165694952011,
      "learning_rate": 3.3253012048192772e-06,
      "loss": 0.012,
      "step": 69200
    },
    {
      "epoch": 8.33855421686747,
      "grad_norm": 0.010871951468288898,
      "learning_rate": 3.322891566265061e-06,
      "loss": 0.0068,
      "step": 69210
    },
    {
      "epoch": 8.339759036144578,
      "grad_norm": 1.5868955850601196,
      "learning_rate": 3.3204819277108436e-06,
      "loss": 0.0094,
      "step": 69220
    },
    {
      "epoch": 8.340963855421688,
      "grad_norm": 0.005392004270106554,
      "learning_rate": 3.3180722891566268e-06,
      "loss": 0.0319,
      "step": 69230
    },
    {
      "epoch": 8.342168674698796,
      "grad_norm": 0.0021386065054684877,
      "learning_rate": 3.31566265060241e-06,
      "loss": 0.0333,
      "step": 69240
    },
    {
      "epoch": 8.343373493975903,
      "grad_norm": 2.1012420654296875,
      "learning_rate": 3.313253012048193e-06,
      "loss": 0.0275,
      "step": 69250
    },
    {
      "epoch": 8.344578313253011,
      "grad_norm": 0.0022477663587778807,
      "learning_rate": 3.310843373493976e-06,
      "loss": 0.0073,
      "step": 69260
    },
    {
      "epoch": 8.345783132530121,
      "grad_norm": 1.9638763666152954,
      "learning_rate": 3.3084337349397595e-06,
      "loss": 0.0196,
      "step": 69270
    },
    {
      "epoch": 8.346987951807229,
      "grad_norm": 0.0021609636023640633,
      "learning_rate": 3.3060240963855422e-06,
      "loss": 0.0233,
      "step": 69280
    },
    {
      "epoch": 8.348192771084337,
      "grad_norm": 0.031223369762301445,
      "learning_rate": 3.303614457831326e-06,
      "loss": 0.0115,
      "step": 69290
    },
    {
      "epoch": 8.349397590361447,
      "grad_norm": 1.319657802581787,
      "learning_rate": 3.3012048192771086e-06,
      "loss": 0.0194,
      "step": 69300
    },
    {
      "epoch": 8.350602409638554,
      "grad_norm": 0.0036313808523118496,
      "learning_rate": 3.2987951807228918e-06,
      "loss": 0.0076,
      "step": 69310
    },
    {
      "epoch": 8.351807228915662,
      "grad_norm": 2.863407850265503,
      "learning_rate": 3.2963855421686754e-06,
      "loss": 0.0349,
      "step": 69320
    },
    {
      "epoch": 8.35301204819277,
      "grad_norm": 0.0045896233059465885,
      "learning_rate": 3.293975903614458e-06,
      "loss": 0.0282,
      "step": 69330
    },
    {
      "epoch": 8.35421686746988,
      "grad_norm": 1.888723611831665,
      "learning_rate": 3.2915662650602413e-06,
      "loss": 0.0119,
      "step": 69340
    },
    {
      "epoch": 8.355421686746988,
      "grad_norm": 0.0018120239255949855,
      "learning_rate": 3.2891566265060245e-06,
      "loss": 0.0203,
      "step": 69350
    },
    {
      "epoch": 8.356626506024096,
      "grad_norm": 0.003153175814077258,
      "learning_rate": 3.2867469879518076e-06,
      "loss": 0.0424,
      "step": 69360
    },
    {
      "epoch": 8.357831325301206,
      "grad_norm": 0.002479078248143196,
      "learning_rate": 3.2843373493975904e-06,
      "loss": 0.01,
      "step": 69370
    },
    {
      "epoch": 8.359036144578313,
      "grad_norm": 5.5397233963012695,
      "learning_rate": 3.281927710843374e-06,
      "loss": 0.0355,
      "step": 69380
    },
    {
      "epoch": 8.360240963855421,
      "grad_norm": 0.09366601705551147,
      "learning_rate": 3.2795180722891567e-06,
      "loss": 0.003,
      "step": 69390
    },
    {
      "epoch": 8.36144578313253,
      "grad_norm": 0.0030888172332197428,
      "learning_rate": 3.2771084337349403e-06,
      "loss": 0.0161,
      "step": 69400
    },
    {
      "epoch": 8.362650602409639,
      "grad_norm": 0.864151120185852,
      "learning_rate": 3.274698795180723e-06,
      "loss": 0.004,
      "step": 69410
    },
    {
      "epoch": 8.363855421686747,
      "grad_norm": 0.04185686632990837,
      "learning_rate": 3.2722891566265063e-06,
      "loss": 0.0023,
      "step": 69420
    },
    {
      "epoch": 8.365060240963855,
      "grad_norm": 1.833085536956787,
      "learning_rate": 3.269879518072289e-06,
      "loss": 0.0113,
      "step": 69430
    },
    {
      "epoch": 8.366265060240965,
      "grad_norm": 1.6910741329193115,
      "learning_rate": 3.2674698795180726e-06,
      "loss": 0.0185,
      "step": 69440
    },
    {
      "epoch": 8.367469879518072,
      "grad_norm": 0.008924638852477074,
      "learning_rate": 3.2650602409638554e-06,
      "loss": 0.0062,
      "step": 69450
    },
    {
      "epoch": 8.36867469879518,
      "grad_norm": 1.0556492805480957,
      "learning_rate": 3.262650602409639e-06,
      "loss": 0.0082,
      "step": 69460
    },
    {
      "epoch": 8.369879518072288,
      "grad_norm": 0.0033020609989762306,
      "learning_rate": 3.260240963855422e-06,
      "loss": 0.0095,
      "step": 69470
    },
    {
      "epoch": 8.371084337349398,
      "grad_norm": 0.0014109369367361069,
      "learning_rate": 3.257831325301205e-06,
      "loss": 0.0201,
      "step": 69480
    },
    {
      "epoch": 8.372289156626506,
      "grad_norm": 0.0019819927401840687,
      "learning_rate": 3.2554216867469885e-06,
      "loss": 0.0066,
      "step": 69490
    },
    {
      "epoch": 8.373493975903614,
      "grad_norm": 0.0016082366928458214,
      "learning_rate": 3.2530120481927713e-06,
      "loss": 0.0316,
      "step": 69500
    },
    {
      "epoch": 8.374698795180723,
      "grad_norm": 0.0018565942300483584,
      "learning_rate": 3.250602409638555e-06,
      "loss": 0.0132,
      "step": 69510
    },
    {
      "epoch": 8.375903614457831,
      "grad_norm": 3.530797243118286,
      "learning_rate": 3.2481927710843376e-06,
      "loss": 0.0206,
      "step": 69520
    },
    {
      "epoch": 8.37710843373494,
      "grad_norm": 0.0015990518731996417,
      "learning_rate": 3.2457831325301208e-06,
      "loss": 0.006,
      "step": 69530
    },
    {
      "epoch": 8.378313253012049,
      "grad_norm": 0.9756616353988647,
      "learning_rate": 3.2433734939759035e-06,
      "loss": 0.0118,
      "step": 69540
    },
    {
      "epoch": 8.379518072289157,
      "grad_norm": 0.003268931061029434,
      "learning_rate": 3.240963855421687e-06,
      "loss": 0.0023,
      "step": 69550
    },
    {
      "epoch": 8.380722891566265,
      "grad_norm": 2.0504443645477295,
      "learning_rate": 3.23855421686747e-06,
      "loss": 0.0243,
      "step": 69560
    },
    {
      "epoch": 8.381927710843373,
      "grad_norm": 0.0245821513235569,
      "learning_rate": 3.2361445783132535e-06,
      "loss": 0.0057,
      "step": 69570
    },
    {
      "epoch": 8.383132530120482,
      "grad_norm": 0.002854878082871437,
      "learning_rate": 3.2337349397590362e-06,
      "loss": 0.0236,
      "step": 69580
    },
    {
      "epoch": 8.38433734939759,
      "grad_norm": 0.005314786918461323,
      "learning_rate": 3.2313253012048194e-06,
      "loss": 0.0267,
      "step": 69590
    },
    {
      "epoch": 8.385542168674698,
      "grad_norm": 0.06080620363354683,
      "learning_rate": 3.2289156626506026e-06,
      "loss": 0.0108,
      "step": 69600
    },
    {
      "epoch": 8.386746987951808,
      "grad_norm": 0.0134438993409276,
      "learning_rate": 3.2265060240963858e-06,
      "loss": 0.0177,
      "step": 69610
    },
    {
      "epoch": 8.387951807228916,
      "grad_norm": 0.07648184895515442,
      "learning_rate": 3.2240963855421694e-06,
      "loss": 0.0593,
      "step": 69620
    },
    {
      "epoch": 8.389156626506024,
      "grad_norm": 2.238715887069702,
      "learning_rate": 3.221686746987952e-06,
      "loss": 0.0211,
      "step": 69630
    },
    {
      "epoch": 8.390361445783132,
      "grad_norm": 0.012266413308680058,
      "learning_rate": 3.2192771084337353e-06,
      "loss": 0.0344,
      "step": 69640
    },
    {
      "epoch": 8.391566265060241,
      "grad_norm": 0.27347332239151,
      "learning_rate": 3.216867469879518e-06,
      "loss": 0.0155,
      "step": 69650
    },
    {
      "epoch": 8.39277108433735,
      "grad_norm": 0.003273656591773033,
      "learning_rate": 3.2144578313253016e-06,
      "loss": 0.0187,
      "step": 69660
    },
    {
      "epoch": 8.393975903614457,
      "grad_norm": 0.008429339155554771,
      "learning_rate": 3.2120481927710844e-06,
      "loss": 0.0036,
      "step": 69670
    },
    {
      "epoch": 8.395180722891567,
      "grad_norm": 0.9471176862716675,
      "learning_rate": 3.209638554216868e-06,
      "loss": 0.0073,
      "step": 69680
    },
    {
      "epoch": 8.396385542168675,
      "grad_norm": 2.46736741065979,
      "learning_rate": 3.2072289156626508e-06,
      "loss": 0.0063,
      "step": 69690
    },
    {
      "epoch": 8.397590361445783,
      "grad_norm": 1.3117611408233643,
      "learning_rate": 3.204819277108434e-06,
      "loss": 0.0298,
      "step": 69700
    },
    {
      "epoch": 8.398795180722892,
      "grad_norm": 0.0021425948943942785,
      "learning_rate": 3.202409638554217e-06,
      "loss": 0.0339,
      "step": 69710
    },
    {
      "epoch": 8.4,
      "grad_norm": 2.7681572437286377,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.009,
      "step": 69720
    },
    {
      "epoch": 8.401204819277108,
      "grad_norm": 0.0010117307538166642,
      "learning_rate": 3.197590361445783e-06,
      "loss": 0.0073,
      "step": 69730
    },
    {
      "epoch": 8.402409638554216,
      "grad_norm": 0.23218625783920288,
      "learning_rate": 3.1951807228915666e-06,
      "loss": 0.0038,
      "step": 69740
    },
    {
      "epoch": 8.403614457831326,
      "grad_norm": 0.000792604754678905,
      "learning_rate": 3.1927710843373494e-06,
      "loss": 0.0144,
      "step": 69750
    },
    {
      "epoch": 8.404819277108434,
      "grad_norm": 0.9582287073135376,
      "learning_rate": 3.190361445783133e-06,
      "loss": 0.0384,
      "step": 69760
    },
    {
      "epoch": 8.406024096385542,
      "grad_norm": 0.0012545555364340544,
      "learning_rate": 3.187951807228916e-06,
      "loss": 0.0102,
      "step": 69770
    },
    {
      "epoch": 8.407228915662651,
      "grad_norm": 1.0822763442993164,
      "learning_rate": 3.185542168674699e-06,
      "loss": 0.0099,
      "step": 69780
    },
    {
      "epoch": 8.40843373493976,
      "grad_norm": 0.010298345237970352,
      "learning_rate": 3.1831325301204825e-06,
      "loss": 0.0113,
      "step": 69790
    },
    {
      "epoch": 8.409638554216867,
      "grad_norm": 0.2673465609550476,
      "learning_rate": 3.1807228915662653e-06,
      "loss": 0.0093,
      "step": 69800
    },
    {
      "epoch": 8.410843373493975,
      "grad_norm": 1.6732616424560547,
      "learning_rate": 3.1783132530120484e-06,
      "loss": 0.0069,
      "step": 69810
    },
    {
      "epoch": 8.412048192771085,
      "grad_norm": 1.5226935148239136,
      "learning_rate": 3.1759036144578316e-06,
      "loss": 0.0219,
      "step": 69820
    },
    {
      "epoch": 8.413253012048193,
      "grad_norm": 0.0024552089162170887,
      "learning_rate": 3.173493975903615e-06,
      "loss": 0.0059,
      "step": 69830
    },
    {
      "epoch": 8.4144578313253,
      "grad_norm": 0.01157666277140379,
      "learning_rate": 3.1710843373493975e-06,
      "loss": 0.0096,
      "step": 69840
    },
    {
      "epoch": 8.41566265060241,
      "grad_norm": 0.464054137468338,
      "learning_rate": 3.168674698795181e-06,
      "loss": 0.0297,
      "step": 69850
    },
    {
      "epoch": 8.416867469879518,
      "grad_norm": 2.96708345413208,
      "learning_rate": 3.166265060240964e-06,
      "loss": 0.0235,
      "step": 69860
    },
    {
      "epoch": 8.418072289156626,
      "grad_norm": 0.001152004930190742,
      "learning_rate": 3.1638554216867475e-06,
      "loss": 0.0226,
      "step": 69870
    },
    {
      "epoch": 8.419277108433734,
      "grad_norm": 0.009791299700737,
      "learning_rate": 3.1614457831325302e-06,
      "loss": 0.0074,
      "step": 69880
    },
    {
      "epoch": 8.420481927710844,
      "grad_norm": 0.0032731613609939814,
      "learning_rate": 3.1590361445783134e-06,
      "loss": 0.0238,
      "step": 69890
    },
    {
      "epoch": 8.421686746987952,
      "grad_norm": 0.0008340118802152574,
      "learning_rate": 3.156626506024096e-06,
      "loss": 0.0084,
      "step": 69900
    },
    {
      "epoch": 8.42289156626506,
      "grad_norm": 0.000702294462826103,
      "learning_rate": 3.1542168674698798e-06,
      "loss": 0.0402,
      "step": 69910
    },
    {
      "epoch": 8.42409638554217,
      "grad_norm": 0.26668912172317505,
      "learning_rate": 3.151807228915663e-06,
      "loss": 0.0136,
      "step": 69920
    },
    {
      "epoch": 8.425301204819277,
      "grad_norm": 0.00415434455499053,
      "learning_rate": 3.149397590361446e-06,
      "loss": 0.0123,
      "step": 69930
    },
    {
      "epoch": 8.426506024096385,
      "grad_norm": 0.0017659624572843313,
      "learning_rate": 3.1469879518072293e-06,
      "loss": 0.0275,
      "step": 69940
    },
    {
      "epoch": 8.427710843373493,
      "grad_norm": 0.3320026695728302,
      "learning_rate": 3.144578313253012e-06,
      "loss": 0.0121,
      "step": 69950
    },
    {
      "epoch": 8.428915662650603,
      "grad_norm": 0.003495241980999708,
      "learning_rate": 3.1421686746987957e-06,
      "loss": 0.0159,
      "step": 69960
    },
    {
      "epoch": 8.43012048192771,
      "grad_norm": 0.21345067024230957,
      "learning_rate": 3.1397590361445784e-06,
      "loss": 0.0013,
      "step": 69970
    },
    {
      "epoch": 8.431325301204819,
      "grad_norm": 0.0041357241570949554,
      "learning_rate": 3.137349397590362e-06,
      "loss": 0.0077,
      "step": 69980
    },
    {
      "epoch": 8.432530120481928,
      "grad_norm": 0.03896084427833557,
      "learning_rate": 3.1349397590361448e-06,
      "loss": 0.0387,
      "step": 69990
    },
    {
      "epoch": 8.433734939759036,
      "grad_norm": 0.002565747359767556,
      "learning_rate": 3.132530120481928e-06,
      "loss": 0.0176,
      "step": 70000
    },
    {
      "epoch": 8.434939759036144,
      "grad_norm": 0.8965075016021729,
      "learning_rate": 3.1301204819277107e-06,
      "loss": 0.0116,
      "step": 70010
    },
    {
      "epoch": 8.436144578313254,
      "grad_norm": 0.6039766073226929,
      "learning_rate": 3.1277108433734943e-06,
      "loss": 0.0043,
      "step": 70020
    },
    {
      "epoch": 8.437349397590362,
      "grad_norm": 0.0012122791958972812,
      "learning_rate": 3.125301204819277e-06,
      "loss": 0.0185,
      "step": 70030
    },
    {
      "epoch": 8.43855421686747,
      "grad_norm": 0.014601176604628563,
      "learning_rate": 3.1228915662650606e-06,
      "loss": 0.0181,
      "step": 70040
    },
    {
      "epoch": 8.439759036144578,
      "grad_norm": 0.0036887587048113346,
      "learning_rate": 3.120481927710844e-06,
      "loss": 0.0098,
      "step": 70050
    },
    {
      "epoch": 8.440963855421687,
      "grad_norm": 0.08945763856172562,
      "learning_rate": 3.1180722891566266e-06,
      "loss": 0.0099,
      "step": 70060
    },
    {
      "epoch": 8.442168674698795,
      "grad_norm": 0.015499132685363293,
      "learning_rate": 3.11566265060241e-06,
      "loss": 0.0107,
      "step": 70070
    },
    {
      "epoch": 8.443373493975903,
      "grad_norm": 5.060671806335449,
      "learning_rate": 3.113253012048193e-06,
      "loss": 0.019,
      "step": 70080
    },
    {
      "epoch": 8.444578313253013,
      "grad_norm": 0.6040019989013672,
      "learning_rate": 3.1108433734939765e-06,
      "loss": 0.0093,
      "step": 70090
    },
    {
      "epoch": 8.44578313253012,
      "grad_norm": 1.061516284942627,
      "learning_rate": 3.1084337349397593e-06,
      "loss": 0.0158,
      "step": 70100
    },
    {
      "epoch": 8.446987951807229,
      "grad_norm": 4.296062469482422,
      "learning_rate": 3.1060240963855424e-06,
      "loss": 0.045,
      "step": 70110
    },
    {
      "epoch": 8.448192771084337,
      "grad_norm": 0.016153495758771896,
      "learning_rate": 3.1036144578313256e-06,
      "loss": 0.0037,
      "step": 70120
    },
    {
      "epoch": 8.449397590361446,
      "grad_norm": 0.00443660281598568,
      "learning_rate": 3.101204819277109e-06,
      "loss": 0.0055,
      "step": 70130
    },
    {
      "epoch": 8.450602409638554,
      "grad_norm": 0.0010969340801239014,
      "learning_rate": 3.0987951807228916e-06,
      "loss": 0.0078,
      "step": 70140
    },
    {
      "epoch": 8.451807228915662,
      "grad_norm": 0.13461589813232422,
      "learning_rate": 3.096385542168675e-06,
      "loss": 0.0064,
      "step": 70150
    },
    {
      "epoch": 8.453012048192772,
      "grad_norm": 0.0007918281480669975,
      "learning_rate": 3.093975903614458e-06,
      "loss": 0.0021,
      "step": 70160
    },
    {
      "epoch": 8.45421686746988,
      "grad_norm": 0.0021078730933368206,
      "learning_rate": 3.091566265060241e-06,
      "loss": 0.0282,
      "step": 70170
    },
    {
      "epoch": 8.455421686746988,
      "grad_norm": 0.29581543803215027,
      "learning_rate": 3.0891566265060243e-06,
      "loss": 0.0207,
      "step": 70180
    },
    {
      "epoch": 8.456626506024097,
      "grad_norm": 0.00042019374086521566,
      "learning_rate": 3.0867469879518074e-06,
      "loss": 0.0015,
      "step": 70190
    },
    {
      "epoch": 8.457831325301205,
      "grad_norm": 0.0014895425410941243,
      "learning_rate": 3.084337349397591e-06,
      "loss": 0.0146,
      "step": 70200
    },
    {
      "epoch": 8.459036144578313,
      "grad_norm": 0.0007618251838721335,
      "learning_rate": 3.0819277108433738e-06,
      "loss": 0.0295,
      "step": 70210
    },
    {
      "epoch": 8.460240963855421,
      "grad_norm": 0.0009122710907831788,
      "learning_rate": 3.079518072289157e-06,
      "loss": 0.0177,
      "step": 70220
    },
    {
      "epoch": 8.46144578313253,
      "grad_norm": 0.0010922454530373216,
      "learning_rate": 3.07710843373494e-06,
      "loss": 0.0081,
      "step": 70230
    },
    {
      "epoch": 8.462650602409639,
      "grad_norm": 0.0005764351808466017,
      "learning_rate": 3.0746987951807233e-06,
      "loss": 0.0018,
      "step": 70240
    },
    {
      "epoch": 8.463855421686747,
      "grad_norm": 1.3232733011245728,
      "learning_rate": 3.072289156626506e-06,
      "loss": 0.0169,
      "step": 70250
    },
    {
      "epoch": 8.465060240963856,
      "grad_norm": 0.007496255915611982,
      "learning_rate": 3.0698795180722897e-06,
      "loss": 0.0182,
      "step": 70260
    },
    {
      "epoch": 8.466265060240964,
      "grad_norm": 0.0033252353314310312,
      "learning_rate": 3.0674698795180724e-06,
      "loss": 0.0022,
      "step": 70270
    },
    {
      "epoch": 8.467469879518072,
      "grad_norm": 0.0012624236987903714,
      "learning_rate": 3.0650602409638556e-06,
      "loss": 0.0161,
      "step": 70280
    },
    {
      "epoch": 8.46867469879518,
      "grad_norm": 0.7960432171821594,
      "learning_rate": 3.0626506024096388e-06,
      "loss": 0.0114,
      "step": 70290
    },
    {
      "epoch": 8.46987951807229,
      "grad_norm": 0.015915803611278534,
      "learning_rate": 3.060240963855422e-06,
      "loss": 0.0054,
      "step": 70300
    },
    {
      "epoch": 8.471084337349398,
      "grad_norm": 1.964951753616333,
      "learning_rate": 3.0578313253012047e-06,
      "loss": 0.0208,
      "step": 70310
    },
    {
      "epoch": 8.472289156626506,
      "grad_norm": 1.4839130640029907,
      "learning_rate": 3.0554216867469883e-06,
      "loss": 0.0326,
      "step": 70320
    },
    {
      "epoch": 8.473493975903615,
      "grad_norm": 0.04161554202437401,
      "learning_rate": 3.053012048192771e-06,
      "loss": 0.0177,
      "step": 70330
    },
    {
      "epoch": 8.474698795180723,
      "grad_norm": 0.013127775862812996,
      "learning_rate": 3.0506024096385547e-06,
      "loss": 0.0044,
      "step": 70340
    },
    {
      "epoch": 8.475903614457831,
      "grad_norm": 0.007266814820468426,
      "learning_rate": 3.048192771084338e-06,
      "loss": 0.0146,
      "step": 70350
    },
    {
      "epoch": 8.477108433734939,
      "grad_norm": 1.0908019542694092,
      "learning_rate": 3.0457831325301206e-06,
      "loss": 0.0048,
      "step": 70360
    },
    {
      "epoch": 8.478313253012049,
      "grad_norm": 0.04492006078362465,
      "learning_rate": 3.043373493975904e-06,
      "loss": 0.0389,
      "step": 70370
    },
    {
      "epoch": 8.479518072289157,
      "grad_norm": 2.3374946117401123,
      "learning_rate": 3.040963855421687e-06,
      "loss": 0.0337,
      "step": 70380
    },
    {
      "epoch": 8.480722891566264,
      "grad_norm": 0.0008397689671255648,
      "learning_rate": 3.0385542168674705e-06,
      "loss": 0.04,
      "step": 70390
    },
    {
      "epoch": 8.481927710843374,
      "grad_norm": 0.003989412449300289,
      "learning_rate": 3.0361445783132533e-06,
      "loss": 0.0135,
      "step": 70400
    },
    {
      "epoch": 8.483132530120482,
      "grad_norm": 0.04120798036456108,
      "learning_rate": 3.0337349397590365e-06,
      "loss": 0.03,
      "step": 70410
    },
    {
      "epoch": 8.48433734939759,
      "grad_norm": 4.551701068878174,
      "learning_rate": 3.031325301204819e-06,
      "loss": 0.0518,
      "step": 70420
    },
    {
      "epoch": 8.485542168674698,
      "grad_norm": 2.3419227600097656,
      "learning_rate": 3.028915662650603e-06,
      "loss": 0.0111,
      "step": 70430
    },
    {
      "epoch": 8.486746987951808,
      "grad_norm": 5.938187122344971,
      "learning_rate": 3.0265060240963856e-06,
      "loss": 0.0263,
      "step": 70440
    },
    {
      "epoch": 8.487951807228916,
      "grad_norm": 0.0010488986736163497,
      "learning_rate": 3.024096385542169e-06,
      "loss": 0.002,
      "step": 70450
    },
    {
      "epoch": 8.489156626506023,
      "grad_norm": 1.115692377090454,
      "learning_rate": 3.021686746987952e-06,
      "loss": 0.0213,
      "step": 70460
    },
    {
      "epoch": 8.490361445783133,
      "grad_norm": 6.22473669052124,
      "learning_rate": 3.019277108433735e-06,
      "loss": 0.0592,
      "step": 70470
    },
    {
      "epoch": 8.491566265060241,
      "grad_norm": 0.5142280459403992,
      "learning_rate": 3.0168674698795183e-06,
      "loss": 0.0084,
      "step": 70480
    },
    {
      "epoch": 8.492771084337349,
      "grad_norm": 0.03354807570576668,
      "learning_rate": 3.0144578313253014e-06,
      "loss": 0.008,
      "step": 70490
    },
    {
      "epoch": 8.493975903614459,
      "grad_norm": 0.0012400028062984347,
      "learning_rate": 3.012048192771085e-06,
      "loss": 0.0298,
      "step": 70500
    },
    {
      "epoch": 8.495180722891567,
      "grad_norm": 0.0007606441504321992,
      "learning_rate": 3.009638554216868e-06,
      "loss": 0.0112,
      "step": 70510
    },
    {
      "epoch": 8.496385542168674,
      "grad_norm": 0.6104311943054199,
      "learning_rate": 3.007228915662651e-06,
      "loss": 0.0131,
      "step": 70520
    },
    {
      "epoch": 8.497590361445782,
      "grad_norm": 1.8623689413070679,
      "learning_rate": 3.0048192771084337e-06,
      "loss": 0.0194,
      "step": 70530
    },
    {
      "epoch": 8.498795180722892,
      "grad_norm": 0.010413496755063534,
      "learning_rate": 3.0024096385542173e-06,
      "loss": 0.0087,
      "step": 70540
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.00253217457793653,
      "learning_rate": 3e-06,
      "loss": 0.0019,
      "step": 70550
    },
    {
      "epoch": 8.501204819277108,
      "grad_norm": 1.6235027313232422,
      "learning_rate": 2.9975903614457837e-06,
      "loss": 0.0198,
      "step": 70560
    },
    {
      "epoch": 8.502409638554218,
      "grad_norm": 0.05181396007537842,
      "learning_rate": 2.9951807228915664e-06,
      "loss": 0.02,
      "step": 70570
    },
    {
      "epoch": 8.503614457831326,
      "grad_norm": 0.3455578684806824,
      "learning_rate": 2.9927710843373496e-06,
      "loss": 0.0102,
      "step": 70580
    },
    {
      "epoch": 8.504819277108433,
      "grad_norm": 0.0043918052688241005,
      "learning_rate": 2.9903614457831328e-06,
      "loss": 0.0005,
      "step": 70590
    },
    {
      "epoch": 8.506024096385541,
      "grad_norm": 0.0013933758018538356,
      "learning_rate": 2.987951807228916e-06,
      "loss": 0.0083,
      "step": 70600
    },
    {
      "epoch": 8.507228915662651,
      "grad_norm": 0.0008951043128035963,
      "learning_rate": 2.9855421686746987e-06,
      "loss": 0.0043,
      "step": 70610
    },
    {
      "epoch": 8.508433734939759,
      "grad_norm": 0.0008560159476473927,
      "learning_rate": 2.9831325301204823e-06,
      "loss": 0.0033,
      "step": 70620
    },
    {
      "epoch": 8.509638554216867,
      "grad_norm": 1.7493529319763184,
      "learning_rate": 2.980722891566265e-06,
      "loss": 0.025,
      "step": 70630
    },
    {
      "epoch": 8.510843373493977,
      "grad_norm": 0.10957761108875275,
      "learning_rate": 2.9783132530120482e-06,
      "loss": 0.0123,
      "step": 70640
    },
    {
      "epoch": 8.512048192771084,
      "grad_norm": 0.004318020306527615,
      "learning_rate": 2.975903614457832e-06,
      "loss": 0.0097,
      "step": 70650
    },
    {
      "epoch": 8.513253012048192,
      "grad_norm": 0.19138440489768982,
      "learning_rate": 2.9734939759036146e-06,
      "loss": 0.0023,
      "step": 70660
    },
    {
      "epoch": 8.514457831325302,
      "grad_norm": 0.0011108239414170384,
      "learning_rate": 2.971084337349398e-06,
      "loss": 0.0116,
      "step": 70670
    },
    {
      "epoch": 8.51566265060241,
      "grad_norm": 1.5799425840377808,
      "learning_rate": 2.968674698795181e-06,
      "loss": 0.0064,
      "step": 70680
    },
    {
      "epoch": 8.516867469879518,
      "grad_norm": 0.0004752716631628573,
      "learning_rate": 2.966265060240964e-06,
      "loss": 0.0013,
      "step": 70690
    },
    {
      "epoch": 8.518072289156626,
      "grad_norm": 0.0039373962208628654,
      "learning_rate": 2.9638554216867473e-06,
      "loss": 0.0093,
      "step": 70700
    },
    {
      "epoch": 8.519277108433736,
      "grad_norm": 0.0009659329080022871,
      "learning_rate": 2.9614457831325305e-06,
      "loss": 0.0081,
      "step": 70710
    },
    {
      "epoch": 8.520481927710843,
      "grad_norm": 0.0012354047503322363,
      "learning_rate": 2.9590361445783132e-06,
      "loss": 0.0054,
      "step": 70720
    },
    {
      "epoch": 8.521686746987951,
      "grad_norm": 0.4943017065525055,
      "learning_rate": 2.956626506024097e-06,
      "loss": 0.011,
      "step": 70730
    },
    {
      "epoch": 8.522891566265061,
      "grad_norm": 0.000947502558119595,
      "learning_rate": 2.9542168674698796e-06,
      "loss": 0.0043,
      "step": 70740
    },
    {
      "epoch": 8.524096385542169,
      "grad_norm": 0.0006308025913313031,
      "learning_rate": 2.9518072289156627e-06,
      "loss": 0.0006,
      "step": 70750
    },
    {
      "epoch": 8.525301204819277,
      "grad_norm": 0.8037334680557251,
      "learning_rate": 2.949397590361446e-06,
      "loss": 0.0024,
      "step": 70760
    },
    {
      "epoch": 8.526506024096385,
      "grad_norm": 0.10304930806159973,
      "learning_rate": 2.946987951807229e-06,
      "loss": 0.01,
      "step": 70770
    },
    {
      "epoch": 8.527710843373494,
      "grad_norm": 0.02047623135149479,
      "learning_rate": 2.944578313253012e-06,
      "loss": 0.0062,
      "step": 70780
    },
    {
      "epoch": 8.528915662650602,
      "grad_norm": 0.0012223782250657678,
      "learning_rate": 2.9421686746987955e-06,
      "loss": 0.0042,
      "step": 70790
    },
    {
      "epoch": 8.53012048192771,
      "grad_norm": 0.00539076142013073,
      "learning_rate": 2.9397590361445786e-06,
      "loss": 0.0358,
      "step": 70800
    },
    {
      "epoch": 8.53132530120482,
      "grad_norm": 0.00127673230599612,
      "learning_rate": 2.937349397590362e-06,
      "loss": 0.0115,
      "step": 70810
    },
    {
      "epoch": 8.532530120481928,
      "grad_norm": 0.0006875746767036617,
      "learning_rate": 2.934939759036145e-06,
      "loss": 0.0029,
      "step": 70820
    },
    {
      "epoch": 8.533734939759036,
      "grad_norm": 7.613539695739746,
      "learning_rate": 2.9325301204819277e-06,
      "loss": 0.0191,
      "step": 70830
    },
    {
      "epoch": 8.534939759036144,
      "grad_norm": 0.0006241738446988165,
      "learning_rate": 2.9301204819277113e-06,
      "loss": 0.0071,
      "step": 70840
    },
    {
      "epoch": 8.536144578313253,
      "grad_norm": 0.0013153543695807457,
      "learning_rate": 2.927710843373494e-06,
      "loss": 0.0105,
      "step": 70850
    },
    {
      "epoch": 8.537349397590361,
      "grad_norm": 0.000890191353391856,
      "learning_rate": 2.9253012048192777e-06,
      "loss": 0.0428,
      "step": 70860
    },
    {
      "epoch": 8.53855421686747,
      "grad_norm": 0.026687869802117348,
      "learning_rate": 2.9228915662650604e-06,
      "loss": 0.0044,
      "step": 70870
    },
    {
      "epoch": 8.539759036144579,
      "grad_norm": 0.16095325350761414,
      "learning_rate": 2.9204819277108436e-06,
      "loss": 0.0071,
      "step": 70880
    },
    {
      "epoch": 8.540963855421687,
      "grad_norm": 0.0017570988275110722,
      "learning_rate": 2.9180722891566264e-06,
      "loss": 0.0091,
      "step": 70890
    },
    {
      "epoch": 8.542168674698795,
      "grad_norm": 18.750993728637695,
      "learning_rate": 2.91566265060241e-06,
      "loss": 0.0412,
      "step": 70900
    },
    {
      "epoch": 8.543373493975903,
      "grad_norm": 1.6993441581726074,
      "learning_rate": 2.9132530120481927e-06,
      "loss": 0.0133,
      "step": 70910
    },
    {
      "epoch": 8.544578313253012,
      "grad_norm": 0.0039427680894732475,
      "learning_rate": 2.9108433734939763e-06,
      "loss": 0.0299,
      "step": 70920
    },
    {
      "epoch": 8.54578313253012,
      "grad_norm": 0.0008786193211562932,
      "learning_rate": 2.908433734939759e-06,
      "loss": 0.038,
      "step": 70930
    },
    {
      "epoch": 8.546987951807228,
      "grad_norm": 2.383629083633423,
      "learning_rate": 2.9060240963855422e-06,
      "loss": 0.0249,
      "step": 70940
    },
    {
      "epoch": 8.548192771084338,
      "grad_norm": 0.0022981888614594936,
      "learning_rate": 2.903614457831326e-06,
      "loss": 0.008,
      "step": 70950
    },
    {
      "epoch": 8.549397590361446,
      "grad_norm": 0.5841947793960571,
      "learning_rate": 2.9012048192771086e-06,
      "loss": 0.0145,
      "step": 70960
    },
    {
      "epoch": 8.550602409638554,
      "grad_norm": 0.004379319492727518,
      "learning_rate": 2.898795180722892e-06,
      "loss": 0.0563,
      "step": 70970
    },
    {
      "epoch": 8.551807228915663,
      "grad_norm": 0.19414791464805603,
      "learning_rate": 2.896385542168675e-06,
      "loss": 0.0113,
      "step": 70980
    },
    {
      "epoch": 8.553012048192771,
      "grad_norm": 0.0042564645409584045,
      "learning_rate": 2.893975903614458e-06,
      "loss": 0.0229,
      "step": 70990
    },
    {
      "epoch": 8.55421686746988,
      "grad_norm": 1.3055912256240845,
      "learning_rate": 2.891566265060241e-06,
      "loss": 0.0151,
      "step": 71000
    },
    {
      "epoch": 8.555421686746987,
      "grad_norm": 2.217482805252075,
      "learning_rate": 2.8891566265060245e-06,
      "loss": 0.0182,
      "step": 71010
    },
    {
      "epoch": 8.556626506024097,
      "grad_norm": 0.000742248201277107,
      "learning_rate": 2.8867469879518072e-06,
      "loss": 0.0081,
      "step": 71020
    },
    {
      "epoch": 8.557831325301205,
      "grad_norm": 2.5195257663726807,
      "learning_rate": 2.884337349397591e-06,
      "loss": 0.0108,
      "step": 71030
    },
    {
      "epoch": 8.559036144578313,
      "grad_norm": 0.0038971994072198868,
      "learning_rate": 2.8819277108433736e-06,
      "loss": 0.0085,
      "step": 71040
    },
    {
      "epoch": 8.560240963855422,
      "grad_norm": 0.0008615079568699002,
      "learning_rate": 2.8795180722891568e-06,
      "loss": 0.004,
      "step": 71050
    },
    {
      "epoch": 8.56144578313253,
      "grad_norm": 0.007033323869109154,
      "learning_rate": 2.87710843373494e-06,
      "loss": 0.0152,
      "step": 71060
    },
    {
      "epoch": 8.562650602409638,
      "grad_norm": 0.019557775929570198,
      "learning_rate": 2.874698795180723e-06,
      "loss": 0.0041,
      "step": 71070
    },
    {
      "epoch": 8.563855421686746,
      "grad_norm": 1.9765899181365967,
      "learning_rate": 2.8722891566265067e-06,
      "loss": 0.0121,
      "step": 71080
    },
    {
      "epoch": 8.565060240963856,
      "grad_norm": 0.004143161699175835,
      "learning_rate": 2.8698795180722895e-06,
      "loss": 0.0048,
      "step": 71090
    },
    {
      "epoch": 8.566265060240964,
      "grad_norm": 0.0003975035797338933,
      "learning_rate": 2.8674698795180726e-06,
      "loss": 0.0083,
      "step": 71100
    },
    {
      "epoch": 8.567469879518072,
      "grad_norm": 3.326788902282715,
      "learning_rate": 2.8650602409638554e-06,
      "loss": 0.0245,
      "step": 71110
    },
    {
      "epoch": 8.568674698795181,
      "grad_norm": 0.0008102007559500635,
      "learning_rate": 2.862650602409639e-06,
      "loss": 0.0011,
      "step": 71120
    },
    {
      "epoch": 8.56987951807229,
      "grad_norm": 0.0009117366280406713,
      "learning_rate": 2.8602409638554217e-06,
      "loss": 0.0281,
      "step": 71130
    },
    {
      "epoch": 8.571084337349397,
      "grad_norm": 0.011234375648200512,
      "learning_rate": 2.8578313253012053e-06,
      "loss": 0.0398,
      "step": 71140
    },
    {
      "epoch": 8.572289156626507,
      "grad_norm": 3.076432228088379,
      "learning_rate": 2.855421686746988e-06,
      "loss": 0.0089,
      "step": 71150
    },
    {
      "epoch": 8.573493975903615,
      "grad_norm": 9.65343952178955,
      "learning_rate": 2.8530120481927713e-06,
      "loss": 0.0459,
      "step": 71160
    },
    {
      "epoch": 8.574698795180723,
      "grad_norm": 0.002219238318502903,
      "learning_rate": 2.8506024096385544e-06,
      "loss": 0.0176,
      "step": 71170
    },
    {
      "epoch": 8.57590361445783,
      "grad_norm": 0.0490344800055027,
      "learning_rate": 2.8481927710843376e-06,
      "loss": 0.0247,
      "step": 71180
    },
    {
      "epoch": 8.57710843373494,
      "grad_norm": 0.0027845718432217836,
      "learning_rate": 2.8457831325301204e-06,
      "loss": 0.0242,
      "step": 71190
    },
    {
      "epoch": 8.578313253012048,
      "grad_norm": 0.0030305006075650454,
      "learning_rate": 2.843373493975904e-06,
      "loss": 0.027,
      "step": 71200
    },
    {
      "epoch": 8.579518072289156,
      "grad_norm": 0.004639543127268553,
      "learning_rate": 2.8409638554216867e-06,
      "loss": 0.0354,
      "step": 71210
    },
    {
      "epoch": 8.580722891566266,
      "grad_norm": 1.9765695333480835,
      "learning_rate": 2.8385542168674703e-06,
      "loss": 0.02,
      "step": 71220
    },
    {
      "epoch": 8.581927710843374,
      "grad_norm": 0.050702691078186035,
      "learning_rate": 2.8361445783132535e-06,
      "loss": 0.0066,
      "step": 71230
    },
    {
      "epoch": 8.583132530120482,
      "grad_norm": 2.1248779296875,
      "learning_rate": 2.8337349397590363e-06,
      "loss": 0.0122,
      "step": 71240
    },
    {
      "epoch": 8.58433734939759,
      "grad_norm": 0.033412542194128036,
      "learning_rate": 2.83132530120482e-06,
      "loss": 0.0525,
      "step": 71250
    },
    {
      "epoch": 8.5855421686747,
      "grad_norm": 1.0384323596954346,
      "learning_rate": 2.8289156626506026e-06,
      "loss": 0.0173,
      "step": 71260
    },
    {
      "epoch": 8.586746987951807,
      "grad_norm": 0.3864712715148926,
      "learning_rate": 2.8265060240963858e-06,
      "loss": 0.0258,
      "step": 71270
    },
    {
      "epoch": 8.587951807228915,
      "grad_norm": 0.005261131562292576,
      "learning_rate": 2.824096385542169e-06,
      "loss": 0.002,
      "step": 71280
    },
    {
      "epoch": 8.589156626506025,
      "grad_norm": 0.3024612069129944,
      "learning_rate": 2.821686746987952e-06,
      "loss": 0.0118,
      "step": 71290
    },
    {
      "epoch": 8.590361445783133,
      "grad_norm": 0.0029968679882586002,
      "learning_rate": 2.819277108433735e-06,
      "loss": 0.0153,
      "step": 71300
    },
    {
      "epoch": 8.59156626506024,
      "grad_norm": 0.14461474120616913,
      "learning_rate": 2.8168674698795185e-06,
      "loss": 0.0332,
      "step": 71310
    },
    {
      "epoch": 8.592771084337349,
      "grad_norm": 1.1453471183776855,
      "learning_rate": 2.8144578313253012e-06,
      "loss": 0.0042,
      "step": 71320
    },
    {
      "epoch": 8.593975903614458,
      "grad_norm": 1.4066438674926758,
      "learning_rate": 2.812048192771085e-06,
      "loss": 0.0081,
      "step": 71330
    },
    {
      "epoch": 8.595180722891566,
      "grad_norm": 2.4440112113952637,
      "learning_rate": 2.8096385542168676e-06,
      "loss": 0.045,
      "step": 71340
    },
    {
      "epoch": 8.596385542168674,
      "grad_norm": 0.02739209681749344,
      "learning_rate": 2.8072289156626508e-06,
      "loss": 0.0091,
      "step": 71350
    },
    {
      "epoch": 8.597590361445784,
      "grad_norm": 0.0013176124775782228,
      "learning_rate": 2.8048192771084335e-06,
      "loss": 0.0088,
      "step": 71360
    },
    {
      "epoch": 8.598795180722892,
      "grad_norm": 0.0009607617976143956,
      "learning_rate": 2.802409638554217e-06,
      "loss": 0.0256,
      "step": 71370
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.0150551795959473,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0128,
      "step": 71380
    },
    {
      "epoch": 8.601204819277108,
      "grad_norm": 0.0021996265277266502,
      "learning_rate": 2.7975903614457835e-06,
      "loss": 0.0027,
      "step": 71390
    },
    {
      "epoch": 8.602409638554217,
      "grad_norm": 0.22361892461776733,
      "learning_rate": 2.7951807228915666e-06,
      "loss": 0.0021,
      "step": 71400
    },
    {
      "epoch": 8.603614457831325,
      "grad_norm": 2.6952366828918457,
      "learning_rate": 2.7927710843373494e-06,
      "loss": 0.0228,
      "step": 71410
    },
    {
      "epoch": 8.604819277108433,
      "grad_norm": 2.3045406341552734,
      "learning_rate": 2.790361445783133e-06,
      "loss": 0.0152,
      "step": 71420
    },
    {
      "epoch": 8.606024096385543,
      "grad_norm": 1.8861883878707886,
      "learning_rate": 2.7879518072289158e-06,
      "loss": 0.0281,
      "step": 71430
    },
    {
      "epoch": 8.60722891566265,
      "grad_norm": 0.008504670113325119,
      "learning_rate": 2.7855421686746994e-06,
      "loss": 0.0189,
      "step": 71440
    },
    {
      "epoch": 8.608433734939759,
      "grad_norm": 1.150327444076538,
      "learning_rate": 2.783132530120482e-06,
      "loss": 0.0129,
      "step": 71450
    },
    {
      "epoch": 8.609638554216868,
      "grad_norm": 0.005840086843818426,
      "learning_rate": 2.7807228915662653e-06,
      "loss": 0.0005,
      "step": 71460
    },
    {
      "epoch": 8.610843373493976,
      "grad_norm": 0.016388986259698868,
      "learning_rate": 2.778313253012048e-06,
      "loss": 0.0193,
      "step": 71470
    },
    {
      "epoch": 8.612048192771084,
      "grad_norm": 2.1295323371887207,
      "learning_rate": 2.7759036144578316e-06,
      "loss": 0.0203,
      "step": 71480
    },
    {
      "epoch": 8.613253012048192,
      "grad_norm": 0.0019493565196171403,
      "learning_rate": 2.7734939759036144e-06,
      "loss": 0.0022,
      "step": 71490
    },
    {
      "epoch": 8.614457831325302,
      "grad_norm": 0.0012035127729177475,
      "learning_rate": 2.771084337349398e-06,
      "loss": 0.0038,
      "step": 71500
    },
    {
      "epoch": 8.61566265060241,
      "grad_norm": 0.04196765273809433,
      "learning_rate": 2.7686746987951807e-06,
      "loss": 0.0209,
      "step": 71510
    },
    {
      "epoch": 8.616867469879518,
      "grad_norm": 0.00046604458475485444,
      "learning_rate": 2.766265060240964e-06,
      "loss": 0.0134,
      "step": 71520
    },
    {
      "epoch": 8.618072289156627,
      "grad_norm": 0.0006480275187641382,
      "learning_rate": 2.7638554216867475e-06,
      "loss": 0.0005,
      "step": 71530
    },
    {
      "epoch": 8.619277108433735,
      "grad_norm": 0.0004912097938358784,
      "learning_rate": 2.7614457831325303e-06,
      "loss": 0.004,
      "step": 71540
    },
    {
      "epoch": 8.620481927710843,
      "grad_norm": 0.0008215704583562911,
      "learning_rate": 2.759036144578314e-06,
      "loss": 0.0272,
      "step": 71550
    },
    {
      "epoch": 8.621686746987951,
      "grad_norm": 4.825232982635498,
      "learning_rate": 2.7566265060240966e-06,
      "loss": 0.0271,
      "step": 71560
    },
    {
      "epoch": 8.62289156626506,
      "grad_norm": 1.6889631748199463,
      "learning_rate": 2.75421686746988e-06,
      "loss": 0.0117,
      "step": 71570
    },
    {
      "epoch": 8.624096385542169,
      "grad_norm": 0.026564188301563263,
      "learning_rate": 2.751807228915663e-06,
      "loss": 0.0229,
      "step": 71580
    },
    {
      "epoch": 8.625301204819277,
      "grad_norm": 0.8864817023277283,
      "learning_rate": 2.749397590361446e-06,
      "loss": 0.0018,
      "step": 71590
    },
    {
      "epoch": 8.626506024096386,
      "grad_norm": 0.0014703595079481602,
      "learning_rate": 2.746987951807229e-06,
      "loss": 0.0014,
      "step": 71600
    },
    {
      "epoch": 8.627710843373494,
      "grad_norm": 0.03478047251701355,
      "learning_rate": 2.7445783132530125e-06,
      "loss": 0.0124,
      "step": 71610
    },
    {
      "epoch": 8.628915662650602,
      "grad_norm": 0.0006703095277771354,
      "learning_rate": 2.7421686746987953e-06,
      "loss": 0.0064,
      "step": 71620
    },
    {
      "epoch": 8.630120481927712,
      "grad_norm": 0.0008279854664579034,
      "learning_rate": 2.7397590361445784e-06,
      "loss": 0.0153,
      "step": 71630
    },
    {
      "epoch": 8.63132530120482,
      "grad_norm": 0.0027404397260397673,
      "learning_rate": 2.7373493975903616e-06,
      "loss": 0.0166,
      "step": 71640
    },
    {
      "epoch": 8.632530120481928,
      "grad_norm": 0.00038005749229341745,
      "learning_rate": 2.7349397590361448e-06,
      "loss": 0.0004,
      "step": 71650
    },
    {
      "epoch": 8.633734939759035,
      "grad_norm": 0.704270601272583,
      "learning_rate": 2.7325301204819275e-06,
      "loss": 0.0058,
      "step": 71660
    },
    {
      "epoch": 8.634939759036145,
      "grad_norm": 0.002660403260961175,
      "learning_rate": 2.730120481927711e-06,
      "loss": 0.0175,
      "step": 71670
    },
    {
      "epoch": 8.636144578313253,
      "grad_norm": 0.0005160841392353177,
      "learning_rate": 2.7277108433734943e-06,
      "loss": 0.0012,
      "step": 71680
    },
    {
      "epoch": 8.637349397590361,
      "grad_norm": 0.5551820397377014,
      "learning_rate": 2.7253012048192775e-06,
      "loss": 0.0066,
      "step": 71690
    },
    {
      "epoch": 8.638554216867469,
      "grad_norm": 0.0006906786584295332,
      "learning_rate": 2.7228915662650607e-06,
      "loss": 0.0072,
      "step": 71700
    },
    {
      "epoch": 8.639759036144579,
      "grad_norm": 0.0015101040480658412,
      "learning_rate": 2.7204819277108434e-06,
      "loss": 0.0058,
      "step": 71710
    },
    {
      "epoch": 8.640963855421687,
      "grad_norm": 0.0004341353487689048,
      "learning_rate": 2.718072289156627e-06,
      "loss": 0.0168,
      "step": 71720
    },
    {
      "epoch": 8.642168674698794,
      "grad_norm": 0.0178971029818058,
      "learning_rate": 2.7156626506024098e-06,
      "loss": 0.0223,
      "step": 71730
    },
    {
      "epoch": 8.643373493975904,
      "grad_norm": 1.8516353368759155,
      "learning_rate": 2.713253012048193e-06,
      "loss": 0.0831,
      "step": 71740
    },
    {
      "epoch": 8.644578313253012,
      "grad_norm": 1.6800479888916016,
      "learning_rate": 2.710843373493976e-06,
      "loss": 0.0068,
      "step": 71750
    },
    {
      "epoch": 8.64578313253012,
      "grad_norm": 3.7010860443115234,
      "learning_rate": 2.7084337349397593e-06,
      "loss": 0.0483,
      "step": 71760
    },
    {
      "epoch": 8.64698795180723,
      "grad_norm": 0.1323326826095581,
      "learning_rate": 2.706024096385542e-06,
      "loss": 0.0103,
      "step": 71770
    },
    {
      "epoch": 8.648192771084338,
      "grad_norm": 0.0011114260414615273,
      "learning_rate": 2.7036144578313256e-06,
      "loss": 0.004,
      "step": 71780
    },
    {
      "epoch": 8.649397590361446,
      "grad_norm": 1.0471506118774414,
      "learning_rate": 2.7012048192771084e-06,
      "loss": 0.015,
      "step": 71790
    },
    {
      "epoch": 8.650602409638553,
      "grad_norm": 0.0006038128049112856,
      "learning_rate": 2.698795180722892e-06,
      "loss": 0.0064,
      "step": 71800
    },
    {
      "epoch": 8.651807228915663,
      "grad_norm": 0.0007918077753856778,
      "learning_rate": 2.6963855421686747e-06,
      "loss": 0.0107,
      "step": 71810
    },
    {
      "epoch": 8.653012048192771,
      "grad_norm": 0.000627289293333888,
      "learning_rate": 2.693975903614458e-06,
      "loss": 0.01,
      "step": 71820
    },
    {
      "epoch": 8.654216867469879,
      "grad_norm": 1.2892711162567139,
      "learning_rate": 2.6915662650602415e-06,
      "loss": 0.0054,
      "step": 71830
    },
    {
      "epoch": 8.655421686746989,
      "grad_norm": 0.00282316654920578,
      "learning_rate": 2.6891566265060243e-06,
      "loss": 0.0037,
      "step": 71840
    },
    {
      "epoch": 8.656626506024097,
      "grad_norm": 0.0007782239699736238,
      "learning_rate": 2.6867469879518075e-06,
      "loss": 0.002,
      "step": 71850
    },
    {
      "epoch": 8.657831325301204,
      "grad_norm": 1.0344208478927612,
      "learning_rate": 2.6843373493975906e-06,
      "loss": 0.0156,
      "step": 71860
    },
    {
      "epoch": 8.659036144578312,
      "grad_norm": 0.0009047977509908378,
      "learning_rate": 2.681927710843374e-06,
      "loss": 0.034,
      "step": 71870
    },
    {
      "epoch": 8.660240963855422,
      "grad_norm": 0.11984947323799133,
      "learning_rate": 2.6795180722891566e-06,
      "loss": 0.0695,
      "step": 71880
    },
    {
      "epoch": 8.66144578313253,
      "grad_norm": 0.8045725226402283,
      "learning_rate": 2.67710843373494e-06,
      "loss": 0.0286,
      "step": 71890
    },
    {
      "epoch": 8.662650602409638,
      "grad_norm": 0.001428054878488183,
      "learning_rate": 2.674698795180723e-06,
      "loss": 0.0251,
      "step": 71900
    },
    {
      "epoch": 8.663855421686748,
      "grad_norm": 5.0173492431640625,
      "learning_rate": 2.6722891566265065e-06,
      "loss": 0.0137,
      "step": 71910
    },
    {
      "epoch": 8.665060240963856,
      "grad_norm": 0.8394070863723755,
      "learning_rate": 2.6698795180722893e-06,
      "loss": 0.0105,
      "step": 71920
    },
    {
      "epoch": 8.666265060240963,
      "grad_norm": 0.6373295783996582,
      "learning_rate": 2.6674698795180724e-06,
      "loss": 0.0138,
      "step": 71930
    },
    {
      "epoch": 8.667469879518073,
      "grad_norm": 0.02444501407444477,
      "learning_rate": 2.6650602409638556e-06,
      "loss": 0.0026,
      "step": 71940
    },
    {
      "epoch": 8.668674698795181,
      "grad_norm": 0.0008062176057137549,
      "learning_rate": 2.662650602409639e-06,
      "loss": 0.0125,
      "step": 71950
    },
    {
      "epoch": 8.669879518072289,
      "grad_norm": 0.0006967788795009255,
      "learning_rate": 2.6602409638554215e-06,
      "loss": 0.0106,
      "step": 71960
    },
    {
      "epoch": 8.671084337349397,
      "grad_norm": 0.2318805456161499,
      "learning_rate": 2.657831325301205e-06,
      "loss": 0.0098,
      "step": 71970
    },
    {
      "epoch": 8.672289156626507,
      "grad_norm": 0.0007158349617384374,
      "learning_rate": 2.6554216867469883e-06,
      "loss": 0.0009,
      "step": 71980
    },
    {
      "epoch": 8.673493975903614,
      "grad_norm": 0.014815399423241615,
      "learning_rate": 2.653012048192771e-06,
      "loss": 0.0054,
      "step": 71990
    },
    {
      "epoch": 8.674698795180722,
      "grad_norm": 7.2774529457092285,
      "learning_rate": 2.6506024096385547e-06,
      "loss": 0.0262,
      "step": 72000
    },
    {
      "epoch": 8.675903614457832,
      "grad_norm": 0.0021618239115923643,
      "learning_rate": 2.6481927710843374e-06,
      "loss": 0.0052,
      "step": 72010
    },
    {
      "epoch": 8.67710843373494,
      "grad_norm": 0.000513318635057658,
      "learning_rate": 2.645783132530121e-06,
      "loss": 0.0321,
      "step": 72020
    },
    {
      "epoch": 8.678313253012048,
      "grad_norm": 3.757298469543457,
      "learning_rate": 2.6433734939759038e-06,
      "loss": 0.0233,
      "step": 72030
    },
    {
      "epoch": 8.679518072289156,
      "grad_norm": 0.2739350497722626,
      "learning_rate": 2.640963855421687e-06,
      "loss": 0.0234,
      "step": 72040
    },
    {
      "epoch": 8.680722891566266,
      "grad_norm": 0.0008882437250576913,
      "learning_rate": 2.63855421686747e-06,
      "loss": 0.0036,
      "step": 72050
    },
    {
      "epoch": 8.681927710843373,
      "grad_norm": 0.006828553508967161,
      "learning_rate": 2.6361445783132533e-06,
      "loss": 0.0248,
      "step": 72060
    },
    {
      "epoch": 8.683132530120481,
      "grad_norm": 0.004758751485496759,
      "learning_rate": 2.633734939759036e-06,
      "loss": 0.034,
      "step": 72070
    },
    {
      "epoch": 8.684337349397591,
      "grad_norm": 0.4648568630218506,
      "learning_rate": 2.6313253012048197e-06,
      "loss": 0.0131,
      "step": 72080
    },
    {
      "epoch": 8.685542168674699,
      "grad_norm": 0.0008274066494777799,
      "learning_rate": 2.6289156626506024e-06,
      "loss": 0.0222,
      "step": 72090
    },
    {
      "epoch": 8.686746987951807,
      "grad_norm": 0.00038342855987139046,
      "learning_rate": 2.6265060240963856e-06,
      "loss": 0.0235,
      "step": 72100
    },
    {
      "epoch": 8.687951807228917,
      "grad_norm": 0.00034456682624295354,
      "learning_rate": 2.624096385542169e-06,
      "loss": 0.0422,
      "step": 72110
    },
    {
      "epoch": 8.689156626506024,
      "grad_norm": 0.0009607925312593579,
      "learning_rate": 2.621686746987952e-06,
      "loss": 0.0011,
      "step": 72120
    },
    {
      "epoch": 8.690361445783132,
      "grad_norm": 0.00048608731594868004,
      "learning_rate": 2.6192771084337355e-06,
      "loss": 0.006,
      "step": 72130
    },
    {
      "epoch": 8.69156626506024,
      "grad_norm": 0.6881176829338074,
      "learning_rate": 2.6168674698795183e-06,
      "loss": 0.0085,
      "step": 72140
    },
    {
      "epoch": 8.69277108433735,
      "grad_norm": 0.0012450816575437784,
      "learning_rate": 2.6144578313253015e-06,
      "loss": 0.0364,
      "step": 72150
    },
    {
      "epoch": 8.693975903614458,
      "grad_norm": 0.0005988397751934826,
      "learning_rate": 2.6120481927710846e-06,
      "loss": 0.0258,
      "step": 72160
    },
    {
      "epoch": 8.695180722891566,
      "grad_norm": 0.47854921221733093,
      "learning_rate": 2.609638554216868e-06,
      "loss": 0.007,
      "step": 72170
    },
    {
      "epoch": 8.696385542168674,
      "grad_norm": 7.447251319885254,
      "learning_rate": 2.6072289156626506e-06,
      "loss": 0.03,
      "step": 72180
    },
    {
      "epoch": 8.697590361445783,
      "grad_norm": 0.01448059268295765,
      "learning_rate": 2.604819277108434e-06,
      "loss": 0.0145,
      "step": 72190
    },
    {
      "epoch": 8.698795180722891,
      "grad_norm": 0.004188349936157465,
      "learning_rate": 2.602409638554217e-06,
      "loss": 0.0191,
      "step": 72200
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.11741354316473007,
      "learning_rate": 2.6e-06,
      "loss": 0.0022,
      "step": 72210
    },
    {
      "epoch": 8.701204819277109,
      "grad_norm": 0.0011819518404081464,
      "learning_rate": 2.5975903614457833e-06,
      "loss": 0.0487,
      "step": 72220
    },
    {
      "epoch": 8.702409638554217,
      "grad_norm": 0.00868707150220871,
      "learning_rate": 2.5951807228915664e-06,
      "loss": 0.0105,
      "step": 72230
    },
    {
      "epoch": 8.703614457831325,
      "grad_norm": 0.0009214107994921505,
      "learning_rate": 2.592771084337349e-06,
      "loss": 0.0077,
      "step": 72240
    },
    {
      "epoch": 8.704819277108435,
      "grad_norm": 0.0009374884539283812,
      "learning_rate": 2.590361445783133e-06,
      "loss": 0.0039,
      "step": 72250
    },
    {
      "epoch": 8.706024096385542,
      "grad_norm": 5.335383415222168,
      "learning_rate": 2.587951807228916e-06,
      "loss": 0.0558,
      "step": 72260
    },
    {
      "epoch": 8.70722891566265,
      "grad_norm": 1.2715452909469604,
      "learning_rate": 2.585542168674699e-06,
      "loss": 0.0111,
      "step": 72270
    },
    {
      "epoch": 8.708433734939758,
      "grad_norm": 1.4883804321289062,
      "learning_rate": 2.5831325301204823e-06,
      "loss": 0.013,
      "step": 72280
    },
    {
      "epoch": 8.709638554216868,
      "grad_norm": 1.172714352607727,
      "learning_rate": 2.580722891566265e-06,
      "loss": 0.0041,
      "step": 72290
    },
    {
      "epoch": 8.710843373493976,
      "grad_norm": 0.0004531513841357082,
      "learning_rate": 2.5783132530120487e-06,
      "loss": 0.0062,
      "step": 72300
    },
    {
      "epoch": 8.712048192771084,
      "grad_norm": 0.0003885070909745991,
      "learning_rate": 2.5759036144578314e-06,
      "loss": 0.0045,
      "step": 72310
    },
    {
      "epoch": 8.713253012048193,
      "grad_norm": 0.04593122750520706,
      "learning_rate": 2.573493975903615e-06,
      "loss": 0.0001,
      "step": 72320
    },
    {
      "epoch": 8.714457831325301,
      "grad_norm": 0.010157722048461437,
      "learning_rate": 2.5710843373493978e-06,
      "loss": 0.0111,
      "step": 72330
    },
    {
      "epoch": 8.71566265060241,
      "grad_norm": 0.001584666664712131,
      "learning_rate": 2.568674698795181e-06,
      "loss": 0.0059,
      "step": 72340
    },
    {
      "epoch": 8.716867469879517,
      "grad_norm": 0.0048369066789746284,
      "learning_rate": 2.5662650602409637e-06,
      "loss": 0.0118,
      "step": 72350
    },
    {
      "epoch": 8.718072289156627,
      "grad_norm": 1.9346121549606323,
      "learning_rate": 2.5638554216867473e-06,
      "loss": 0.0476,
      "step": 72360
    },
    {
      "epoch": 8.719277108433735,
      "grad_norm": 0.023260371759533882,
      "learning_rate": 2.56144578313253e-06,
      "loss": 0.0193,
      "step": 72370
    },
    {
      "epoch": 8.720481927710843,
      "grad_norm": 0.00903143361210823,
      "learning_rate": 2.5590361445783137e-06,
      "loss": 0.0219,
      "step": 72380
    },
    {
      "epoch": 8.721686746987952,
      "grad_norm": 0.0670403316617012,
      "learning_rate": 2.5566265060240964e-06,
      "loss": 0.0038,
      "step": 72390
    },
    {
      "epoch": 8.72289156626506,
      "grad_norm": 1.70441472530365,
      "learning_rate": 2.5542168674698796e-06,
      "loss": 0.025,
      "step": 72400
    },
    {
      "epoch": 8.724096385542168,
      "grad_norm": 0.0037855072878301144,
      "learning_rate": 2.551807228915663e-06,
      "loss": 0.0052,
      "step": 72410
    },
    {
      "epoch": 8.725301204819278,
      "grad_norm": 2.1948704719543457,
      "learning_rate": 2.549397590361446e-06,
      "loss": 0.0165,
      "step": 72420
    },
    {
      "epoch": 8.726506024096386,
      "grad_norm": 0.0032913305331021547,
      "learning_rate": 2.5469879518072295e-06,
      "loss": 0.0368,
      "step": 72430
    },
    {
      "epoch": 8.727710843373494,
      "grad_norm": 0.0009206639369949698,
      "learning_rate": 2.5445783132530123e-06,
      "loss": 0.0015,
      "step": 72440
    },
    {
      "epoch": 8.728915662650602,
      "grad_norm": 0.004746459424495697,
      "learning_rate": 2.5421686746987955e-06,
      "loss": 0.0101,
      "step": 72450
    },
    {
      "epoch": 8.730120481927711,
      "grad_norm": 1.1157875061035156,
      "learning_rate": 2.5397590361445782e-06,
      "loss": 0.0232,
      "step": 72460
    },
    {
      "epoch": 8.73132530120482,
      "grad_norm": 0.004651639144867659,
      "learning_rate": 2.537349397590362e-06,
      "loss": 0.0086,
      "step": 72470
    },
    {
      "epoch": 8.732530120481927,
      "grad_norm": 1.7305113077163696,
      "learning_rate": 2.5349397590361446e-06,
      "loss": 0.023,
      "step": 72480
    },
    {
      "epoch": 8.733734939759037,
      "grad_norm": 0.009918472729623318,
      "learning_rate": 2.532530120481928e-06,
      "loss": 0.0244,
      "step": 72490
    },
    {
      "epoch": 8.734939759036145,
      "grad_norm": 0.001143303932622075,
      "learning_rate": 2.530120481927711e-06,
      "loss": 0.0083,
      "step": 72500
    },
    {
      "epoch": 8.736144578313253,
      "grad_norm": 0.04249480739235878,
      "learning_rate": 2.527710843373494e-06,
      "loss": 0.0104,
      "step": 72510
    },
    {
      "epoch": 8.73734939759036,
      "grad_norm": 0.018889890983700752,
      "learning_rate": 2.5253012048192773e-06,
      "loss": 0.0086,
      "step": 72520
    },
    {
      "epoch": 8.73855421686747,
      "grad_norm": 0.0007379469461739063,
      "learning_rate": 2.5228915662650605e-06,
      "loss": 0.0236,
      "step": 72530
    },
    {
      "epoch": 8.739759036144578,
      "grad_norm": 0.008020147681236267,
      "learning_rate": 2.520481927710843e-06,
      "loss": 0.0107,
      "step": 72540
    },
    {
      "epoch": 8.740963855421686,
      "grad_norm": 1.212774395942688,
      "learning_rate": 2.518072289156627e-06,
      "loss": 0.0117,
      "step": 72550
    },
    {
      "epoch": 8.742168674698796,
      "grad_norm": 0.00116814486682415,
      "learning_rate": 2.51566265060241e-06,
      "loss": 0.014,
      "step": 72560
    },
    {
      "epoch": 8.743373493975904,
      "grad_norm": 0.42151057720184326,
      "learning_rate": 2.5132530120481927e-06,
      "loss": 0.0215,
      "step": 72570
    },
    {
      "epoch": 8.744578313253012,
      "grad_norm": 0.00048491181223653257,
      "learning_rate": 2.5108433734939763e-06,
      "loss": 0.0091,
      "step": 72580
    },
    {
      "epoch": 8.745783132530121,
      "grad_norm": 0.012805529870092869,
      "learning_rate": 2.508433734939759e-06,
      "loss": 0.0179,
      "step": 72590
    },
    {
      "epoch": 8.74698795180723,
      "grad_norm": 0.0010010325349867344,
      "learning_rate": 2.5060240963855427e-06,
      "loss": 0.0044,
      "step": 72600
    },
    {
      "epoch": 8.748192771084337,
      "grad_norm": 11.968315124511719,
      "learning_rate": 2.5036144578313254e-06,
      "loss": 0.0393,
      "step": 72610
    },
    {
      "epoch": 8.749397590361445,
      "grad_norm": 0.012621906585991383,
      "learning_rate": 2.5012048192771086e-06,
      "loss": 0.0037,
      "step": 72620
    },
    {
      "epoch": 8.750602409638555,
      "grad_norm": 0.00033326700213365257,
      "learning_rate": 2.498795180722892e-06,
      "loss": 0.0086,
      "step": 72630
    },
    {
      "epoch": 8.751807228915663,
      "grad_norm": 0.0011332168942317367,
      "learning_rate": 2.496385542168675e-06,
      "loss": 0.022,
      "step": 72640
    },
    {
      "epoch": 8.75301204819277,
      "grad_norm": 0.008072052150964737,
      "learning_rate": 2.493975903614458e-06,
      "loss": 0.0015,
      "step": 72650
    },
    {
      "epoch": 8.754216867469879,
      "grad_norm": 0.6429426074028015,
      "learning_rate": 2.4915662650602413e-06,
      "loss": 0.0297,
      "step": 72660
    },
    {
      "epoch": 8.755421686746988,
      "grad_norm": 0.3775816261768341,
      "learning_rate": 2.4891566265060245e-06,
      "loss": 0.0082,
      "step": 72670
    },
    {
      "epoch": 8.756626506024096,
      "grad_norm": 0.0004867887473665178,
      "learning_rate": 2.4867469879518077e-06,
      "loss": 0.0008,
      "step": 72680
    },
    {
      "epoch": 8.757831325301204,
      "grad_norm": 0.002090315567329526,
      "learning_rate": 2.4843373493975904e-06,
      "loss": 0.0086,
      "step": 72690
    },
    {
      "epoch": 8.759036144578314,
      "grad_norm": 0.7546021938323975,
      "learning_rate": 2.4819277108433736e-06,
      "loss": 0.0254,
      "step": 72700
    },
    {
      "epoch": 8.760240963855422,
      "grad_norm": 0.0009567868546582758,
      "learning_rate": 2.4795180722891568e-06,
      "loss": 0.0354,
      "step": 72710
    },
    {
      "epoch": 8.76144578313253,
      "grad_norm": 0.0008070975309237838,
      "learning_rate": 2.47710843373494e-06,
      "loss": 0.0206,
      "step": 72720
    },
    {
      "epoch": 8.76265060240964,
      "grad_norm": 3.0550544261932373,
      "learning_rate": 2.474698795180723e-06,
      "loss": 0.0258,
      "step": 72730
    },
    {
      "epoch": 8.763855421686747,
      "grad_norm": 0.305095911026001,
      "learning_rate": 2.4722891566265063e-06,
      "loss": 0.003,
      "step": 72740
    },
    {
      "epoch": 8.765060240963855,
      "grad_norm": 0.0024793052580207586,
      "learning_rate": 2.469879518072289e-06,
      "loss": 0.0082,
      "step": 72750
    },
    {
      "epoch": 8.766265060240963,
      "grad_norm": 0.016666041687130928,
      "learning_rate": 2.4674698795180722e-06,
      "loss": 0.0064,
      "step": 72760
    },
    {
      "epoch": 8.767469879518073,
      "grad_norm": 0.004187508020550013,
      "learning_rate": 2.4650602409638554e-06,
      "loss": 0.0179,
      "step": 72770
    },
    {
      "epoch": 8.76867469879518,
      "grad_norm": 0.0009983401978388429,
      "learning_rate": 2.462650602409639e-06,
      "loss": 0.0134,
      "step": 72780
    },
    {
      "epoch": 8.769879518072289,
      "grad_norm": 0.0015925075858831406,
      "learning_rate": 2.460240963855422e-06,
      "loss": 0.0196,
      "step": 72790
    },
    {
      "epoch": 8.771084337349398,
      "grad_norm": 0.41541755199432373,
      "learning_rate": 2.457831325301205e-06,
      "loss": 0.0045,
      "step": 72800
    },
    {
      "epoch": 8.772289156626506,
      "grad_norm": 0.0006757213268429041,
      "learning_rate": 2.455421686746988e-06,
      "loss": 0.0222,
      "step": 72810
    },
    {
      "epoch": 8.773493975903614,
      "grad_norm": 1.2128379344940186,
      "learning_rate": 2.4530120481927713e-06,
      "loss": 0.0126,
      "step": 72820
    },
    {
      "epoch": 8.774698795180722,
      "grad_norm": 1.375023365020752,
      "learning_rate": 2.4506024096385545e-06,
      "loss": 0.0228,
      "step": 72830
    },
    {
      "epoch": 8.775903614457832,
      "grad_norm": 7.1462602615356445,
      "learning_rate": 2.4481927710843376e-06,
      "loss": 0.0298,
      "step": 72840
    },
    {
      "epoch": 8.77710843373494,
      "grad_norm": 0.0004303734749555588,
      "learning_rate": 2.445783132530121e-06,
      "loss": 0.0381,
      "step": 72850
    },
    {
      "epoch": 8.778313253012048,
      "grad_norm": 0.003176990430802107,
      "learning_rate": 2.443373493975904e-06,
      "loss": 0.0304,
      "step": 72860
    },
    {
      "epoch": 8.779518072289157,
      "grad_norm": 0.000865677313413471,
      "learning_rate": 2.4409638554216867e-06,
      "loss": 0.0049,
      "step": 72870
    },
    {
      "epoch": 8.780722891566265,
      "grad_norm": 0.6368686556816101,
      "learning_rate": 2.43855421686747e-06,
      "loss": 0.0474,
      "step": 72880
    },
    {
      "epoch": 8.781927710843373,
      "grad_norm": 0.005645615980029106,
      "learning_rate": 2.436144578313253e-06,
      "loss": 0.0022,
      "step": 72890
    },
    {
      "epoch": 8.783132530120483,
      "grad_norm": 0.0010891634738072753,
      "learning_rate": 2.4337349397590363e-06,
      "loss": 0.0265,
      "step": 72900
    },
    {
      "epoch": 8.78433734939759,
      "grad_norm": 0.001282123033888638,
      "learning_rate": 2.4313253012048195e-06,
      "loss": 0.0384,
      "step": 72910
    },
    {
      "epoch": 8.785542168674699,
      "grad_norm": 0.0005478020175360143,
      "learning_rate": 2.4289156626506026e-06,
      "loss": 0.0282,
      "step": 72920
    },
    {
      "epoch": 8.786746987951807,
      "grad_norm": 1.2768349647521973,
      "learning_rate": 2.426506024096386e-06,
      "loss": 0.0318,
      "step": 72930
    },
    {
      "epoch": 8.787951807228916,
      "grad_norm": 0.012019914574921131,
      "learning_rate": 2.424096385542169e-06,
      "loss": 0.0015,
      "step": 72940
    },
    {
      "epoch": 8.789156626506024,
      "grad_norm": 0.002037501661106944,
      "learning_rate": 2.421686746987952e-06,
      "loss": 0.0267,
      "step": 72950
    },
    {
      "epoch": 8.790361445783132,
      "grad_norm": 0.006364705041050911,
      "learning_rate": 2.4192771084337353e-06,
      "loss": 0.016,
      "step": 72960
    },
    {
      "epoch": 8.791566265060242,
      "grad_norm": 0.0014154401142150164,
      "learning_rate": 2.4168674698795185e-06,
      "loss": 0.0108,
      "step": 72970
    },
    {
      "epoch": 8.79277108433735,
      "grad_norm": 0.0006127837696112692,
      "learning_rate": 2.4144578313253013e-06,
      "loss": 0.0096,
      "step": 72980
    },
    {
      "epoch": 8.793975903614458,
      "grad_norm": 0.02720094472169876,
      "learning_rate": 2.4120481927710844e-06,
      "loss": 0.0248,
      "step": 72990
    },
    {
      "epoch": 8.795180722891565,
      "grad_norm": 1.0308847427368164,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 0.0201,
      "step": 73000
    },
    {
      "epoch": 8.796385542168675,
      "grad_norm": 0.1579805463552475,
      "learning_rate": 2.4072289156626508e-06,
      "loss": 0.0078,
      "step": 73010
    },
    {
      "epoch": 8.797590361445783,
      "grad_norm": 0.005052209831774235,
      "learning_rate": 2.404819277108434e-06,
      "loss": 0.0011,
      "step": 73020
    },
    {
      "epoch": 8.798795180722891,
      "grad_norm": 0.05155690014362335,
      "learning_rate": 2.402409638554217e-06,
      "loss": 0.0085,
      "step": 73030
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.6421633958816528,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0143,
      "step": 73040
    },
    {
      "epoch": 8.801204819277109,
      "grad_norm": 0.17422953248023987,
      "learning_rate": 2.397590361445783e-06,
      "loss": 0.0068,
      "step": 73050
    },
    {
      "epoch": 8.802409638554217,
      "grad_norm": 0.13816897571086884,
      "learning_rate": 2.3951807228915662e-06,
      "loss": 0.0042,
      "step": 73060
    },
    {
      "epoch": 8.803614457831326,
      "grad_norm": 0.00023585601593367755,
      "learning_rate": 2.39277108433735e-06,
      "loss": 0.0154,
      "step": 73070
    },
    {
      "epoch": 8.804819277108434,
      "grad_norm": 0.011830541305243969,
      "learning_rate": 2.390361445783133e-06,
      "loss": 0.0071,
      "step": 73080
    },
    {
      "epoch": 8.806024096385542,
      "grad_norm": 0.8787726163864136,
      "learning_rate": 2.3879518072289158e-06,
      "loss": 0.0148,
      "step": 73090
    },
    {
      "epoch": 8.80722891566265,
      "grad_norm": 1.090531587600708,
      "learning_rate": 2.385542168674699e-06,
      "loss": 0.015,
      "step": 73100
    },
    {
      "epoch": 8.80843373493976,
      "grad_norm": 0.1585533171892166,
      "learning_rate": 2.383132530120482e-06,
      "loss": 0.0237,
      "step": 73110
    },
    {
      "epoch": 8.809638554216868,
      "grad_norm": 0.02255813218653202,
      "learning_rate": 2.3807228915662653e-06,
      "loss": 0.0091,
      "step": 73120
    },
    {
      "epoch": 8.810843373493976,
      "grad_norm": 0.00032528548035770655,
      "learning_rate": 2.3783132530120485e-06,
      "loss": 0.0112,
      "step": 73130
    },
    {
      "epoch": 8.812048192771083,
      "grad_norm": 0.0002976265095639974,
      "learning_rate": 2.3759036144578317e-06,
      "loss": 0.0257,
      "step": 73140
    },
    {
      "epoch": 8.813253012048193,
      "grad_norm": 0.008826917968690395,
      "learning_rate": 2.373493975903615e-06,
      "loss": 0.0052,
      "step": 73150
    },
    {
      "epoch": 8.814457831325301,
      "grad_norm": 0.00030548463109880686,
      "learning_rate": 2.3710843373493976e-06,
      "loss": 0.0177,
      "step": 73160
    },
    {
      "epoch": 8.815662650602409,
      "grad_norm": 0.0008029661839827895,
      "learning_rate": 2.3686746987951808e-06,
      "loss": 0.0008,
      "step": 73170
    },
    {
      "epoch": 8.816867469879519,
      "grad_norm": 1.3724955320358276,
      "learning_rate": 2.366265060240964e-06,
      "loss": 0.0235,
      "step": 73180
    },
    {
      "epoch": 8.818072289156627,
      "grad_norm": 0.0011315057054162025,
      "learning_rate": 2.363855421686747e-06,
      "loss": 0.0121,
      "step": 73190
    },
    {
      "epoch": 8.819277108433734,
      "grad_norm": 0.0007347861537709832,
      "learning_rate": 2.3614457831325303e-06,
      "loss": 0.0146,
      "step": 73200
    },
    {
      "epoch": 8.820481927710844,
      "grad_norm": 0.0005204883054830134,
      "learning_rate": 2.3590361445783135e-06,
      "loss": 0.0073,
      "step": 73210
    },
    {
      "epoch": 8.821686746987952,
      "grad_norm": 0.24585233628749847,
      "learning_rate": 2.3566265060240966e-06,
      "loss": 0.0033,
      "step": 73220
    },
    {
      "epoch": 8.82289156626506,
      "grad_norm": 0.6882461309432983,
      "learning_rate": 2.35421686746988e-06,
      "loss": 0.0251,
      "step": 73230
    },
    {
      "epoch": 8.824096385542168,
      "grad_norm": 0.0005863013211637735,
      "learning_rate": 2.351807228915663e-06,
      "loss": 0.0021,
      "step": 73240
    },
    {
      "epoch": 8.825301204819278,
      "grad_norm": 0.0017571732169017196,
      "learning_rate": 2.349397590361446e-06,
      "loss": 0.0338,
      "step": 73250
    },
    {
      "epoch": 8.826506024096386,
      "grad_norm": 0.0007530538132414222,
      "learning_rate": 2.3469879518072293e-06,
      "loss": 0.0079,
      "step": 73260
    },
    {
      "epoch": 8.827710843373493,
      "grad_norm": 0.0009028370259329677,
      "learning_rate": 2.344578313253012e-06,
      "loss": 0.0008,
      "step": 73270
    },
    {
      "epoch": 8.828915662650603,
      "grad_norm": 0.0007071169675327837,
      "learning_rate": 2.3421686746987953e-06,
      "loss": 0.0138,
      "step": 73280
    },
    {
      "epoch": 8.830120481927711,
      "grad_norm": 0.6521170735359192,
      "learning_rate": 2.3397590361445784e-06,
      "loss": 0.0218,
      "step": 73290
    },
    {
      "epoch": 8.831325301204819,
      "grad_norm": 0.0003185850800946355,
      "learning_rate": 2.3373493975903616e-06,
      "loss": 0.006,
      "step": 73300
    },
    {
      "epoch": 8.832530120481927,
      "grad_norm": 0.0003754434874281287,
      "learning_rate": 2.334939759036145e-06,
      "loss": 0.0283,
      "step": 73310
    },
    {
      "epoch": 8.833734939759037,
      "grad_norm": 0.00038472545566037297,
      "learning_rate": 2.332530120481928e-06,
      "loss": 0.0459,
      "step": 73320
    },
    {
      "epoch": 8.834939759036144,
      "grad_norm": 0.0005294586881063879,
      "learning_rate": 2.330120481927711e-06,
      "loss": 0.0116,
      "step": 73330
    },
    {
      "epoch": 8.836144578313252,
      "grad_norm": 2.4715330600738525,
      "learning_rate": 2.327710843373494e-06,
      "loss": 0.0252,
      "step": 73340
    },
    {
      "epoch": 8.837349397590362,
      "grad_norm": 0.0011715315049514174,
      "learning_rate": 2.325301204819277e-06,
      "loss": 0.0321,
      "step": 73350
    },
    {
      "epoch": 8.83855421686747,
      "grad_norm": 0.0007093519670888782,
      "learning_rate": 2.3228915662650603e-06,
      "loss": 0.002,
      "step": 73360
    },
    {
      "epoch": 8.839759036144578,
      "grad_norm": 0.000916129385586828,
      "learning_rate": 2.320481927710844e-06,
      "loss": 0.0083,
      "step": 73370
    },
    {
      "epoch": 8.840963855421688,
      "grad_norm": 0.00046177851618267596,
      "learning_rate": 2.3180722891566266e-06,
      "loss": 0.0059,
      "step": 73380
    },
    {
      "epoch": 8.842168674698796,
      "grad_norm": 0.0006380218546837568,
      "learning_rate": 2.3156626506024098e-06,
      "loss": 0.0091,
      "step": 73390
    },
    {
      "epoch": 8.843373493975903,
      "grad_norm": 0.0013708017067983747,
      "learning_rate": 2.313253012048193e-06,
      "loss": 0.015,
      "step": 73400
    },
    {
      "epoch": 8.844578313253011,
      "grad_norm": 2.027364730834961,
      "learning_rate": 2.310843373493976e-06,
      "loss": 0.0053,
      "step": 73410
    },
    {
      "epoch": 8.845783132530121,
      "grad_norm": 0.0005184430629014969,
      "learning_rate": 2.3084337349397593e-06,
      "loss": 0.0058,
      "step": 73420
    },
    {
      "epoch": 8.846987951807229,
      "grad_norm": 0.0003695770283229649,
      "learning_rate": 2.3060240963855425e-06,
      "loss": 0.011,
      "step": 73430
    },
    {
      "epoch": 8.848192771084337,
      "grad_norm": 0.00041921177762560546,
      "learning_rate": 2.3036144578313257e-06,
      "loss": 0.0116,
      "step": 73440
    },
    {
      "epoch": 8.849397590361447,
      "grad_norm": 0.0009907718049362302,
      "learning_rate": 2.3012048192771084e-06,
      "loss": 0.0091,
      "step": 73450
    },
    {
      "epoch": 8.850602409638554,
      "grad_norm": 0.0007416303851641715,
      "learning_rate": 2.2987951807228916e-06,
      "loss": 0.029,
      "step": 73460
    },
    {
      "epoch": 8.851807228915662,
      "grad_norm": 0.0028795755933970213,
      "learning_rate": 2.2963855421686748e-06,
      "loss": 0.0217,
      "step": 73470
    },
    {
      "epoch": 8.85301204819277,
      "grad_norm": 0.4002233147621155,
      "learning_rate": 2.293975903614458e-06,
      "loss": 0.0139,
      "step": 73480
    },
    {
      "epoch": 8.85421686746988,
      "grad_norm": 0.2673715054988861,
      "learning_rate": 2.291566265060241e-06,
      "loss": 0.0199,
      "step": 73490
    },
    {
      "epoch": 8.855421686746988,
      "grad_norm": 0.21109646558761597,
      "learning_rate": 2.2891566265060243e-06,
      "loss": 0.005,
      "step": 73500
    },
    {
      "epoch": 8.856626506024096,
      "grad_norm": 0.910205602645874,
      "learning_rate": 2.2867469879518075e-06,
      "loss": 0.016,
      "step": 73510
    },
    {
      "epoch": 8.857831325301206,
      "grad_norm": 0.0022856988944113255,
      "learning_rate": 2.2843373493975906e-06,
      "loss": 0.0305,
      "step": 73520
    },
    {
      "epoch": 8.859036144578313,
      "grad_norm": 0.0005283237551338971,
      "learning_rate": 2.281927710843374e-06,
      "loss": 0.0179,
      "step": 73530
    },
    {
      "epoch": 8.860240963855421,
      "grad_norm": 0.004991214722394943,
      "learning_rate": 2.279518072289157e-06,
      "loss": 0.0149,
      "step": 73540
    },
    {
      "epoch": 8.861445783132531,
      "grad_norm": 1.0391244888305664,
      "learning_rate": 2.27710843373494e-06,
      "loss": 0.0233,
      "step": 73550
    },
    {
      "epoch": 8.862650602409639,
      "grad_norm": 0.00446324935182929,
      "learning_rate": 2.274698795180723e-06,
      "loss": 0.0028,
      "step": 73560
    },
    {
      "epoch": 8.863855421686747,
      "grad_norm": 0.0015996501315385103,
      "learning_rate": 2.272289156626506e-06,
      "loss": 0.0031,
      "step": 73570
    },
    {
      "epoch": 8.865060240963855,
      "grad_norm": 0.46692997217178345,
      "learning_rate": 2.2698795180722893e-06,
      "loss": 0.0138,
      "step": 73580
    },
    {
      "epoch": 8.866265060240965,
      "grad_norm": 0.005260366015136242,
      "learning_rate": 2.2674698795180725e-06,
      "loss": 0.0104,
      "step": 73590
    },
    {
      "epoch": 8.867469879518072,
      "grad_norm": 2.4543681144714355,
      "learning_rate": 2.2650602409638556e-06,
      "loss": 0.02,
      "step": 73600
    },
    {
      "epoch": 8.86867469879518,
      "grad_norm": 0.40488287806510925,
      "learning_rate": 2.262650602409639e-06,
      "loss": 0.0147,
      "step": 73610
    },
    {
      "epoch": 8.869879518072288,
      "grad_norm": 2.275991439819336,
      "learning_rate": 2.260240963855422e-06,
      "loss": 0.0173,
      "step": 73620
    },
    {
      "epoch": 8.871084337349398,
      "grad_norm": 0.0005866388091817498,
      "learning_rate": 2.2578313253012047e-06,
      "loss": 0.0622,
      "step": 73630
    },
    {
      "epoch": 8.872289156626506,
      "grad_norm": 1.8811389207839966,
      "learning_rate": 2.255421686746988e-06,
      "loss": 0.015,
      "step": 73640
    },
    {
      "epoch": 8.873493975903614,
      "grad_norm": 0.0006273272447288036,
      "learning_rate": 2.253012048192771e-06,
      "loss": 0.0401,
      "step": 73650
    },
    {
      "epoch": 8.874698795180723,
      "grad_norm": 0.0014816828770563006,
      "learning_rate": 2.2506024096385547e-06,
      "loss": 0.0026,
      "step": 73660
    },
    {
      "epoch": 8.875903614457831,
      "grad_norm": 0.00040603242814540863,
      "learning_rate": 2.2481927710843374e-06,
      "loss": 0.0157,
      "step": 73670
    },
    {
      "epoch": 8.87710843373494,
      "grad_norm": 0.0017240646993741393,
      "learning_rate": 2.2457831325301206e-06,
      "loss": 0.0295,
      "step": 73680
    },
    {
      "epoch": 8.878313253012049,
      "grad_norm": 0.015247748233377934,
      "learning_rate": 2.243373493975904e-06,
      "loss": 0.0101,
      "step": 73690
    },
    {
      "epoch": 8.879518072289157,
      "grad_norm": 1.6116881370544434,
      "learning_rate": 2.240963855421687e-06,
      "loss": 0.0246,
      "step": 73700
    },
    {
      "epoch": 8.880722891566265,
      "grad_norm": 0.015276022255420685,
      "learning_rate": 2.23855421686747e-06,
      "loss": 0.0113,
      "step": 73710
    },
    {
      "epoch": 8.881927710843373,
      "grad_norm": 0.17549097537994385,
      "learning_rate": 2.2361445783132533e-06,
      "loss": 0.0149,
      "step": 73720
    },
    {
      "epoch": 8.883132530120482,
      "grad_norm": 0.005166237708181143,
      "learning_rate": 2.2337349397590365e-06,
      "loss": 0.0059,
      "step": 73730
    },
    {
      "epoch": 8.88433734939759,
      "grad_norm": 35.197425842285156,
      "learning_rate": 2.2313253012048192e-06,
      "loss": 0.0135,
      "step": 73740
    },
    {
      "epoch": 8.885542168674698,
      "grad_norm": 0.0005688704550266266,
      "learning_rate": 2.2289156626506024e-06,
      "loss": 0.0041,
      "step": 73750
    },
    {
      "epoch": 8.886746987951808,
      "grad_norm": 0.002676762407645583,
      "learning_rate": 2.2265060240963856e-06,
      "loss": 0.0084,
      "step": 73760
    },
    {
      "epoch": 8.887951807228916,
      "grad_norm": 0.7578771114349365,
      "learning_rate": 2.2240963855421688e-06,
      "loss": 0.0026,
      "step": 73770
    },
    {
      "epoch": 8.889156626506024,
      "grad_norm": 0.0008089839247986674,
      "learning_rate": 2.221686746987952e-06,
      "loss": 0.0215,
      "step": 73780
    },
    {
      "epoch": 8.890361445783132,
      "grad_norm": 0.002244160044938326,
      "learning_rate": 2.219277108433735e-06,
      "loss": 0.0095,
      "step": 73790
    },
    {
      "epoch": 8.891566265060241,
      "grad_norm": 0.0007107429555617273,
      "learning_rate": 2.2168674698795183e-06,
      "loss": 0.0142,
      "step": 73800
    },
    {
      "epoch": 8.89277108433735,
      "grad_norm": 0.0014365854440256953,
      "learning_rate": 2.2144578313253015e-06,
      "loss": 0.0027,
      "step": 73810
    },
    {
      "epoch": 8.893975903614457,
      "grad_norm": 0.012798360548913479,
      "learning_rate": 2.2120481927710847e-06,
      "loss": 0.0353,
      "step": 73820
    },
    {
      "epoch": 8.895180722891567,
      "grad_norm": 0.9560711979866028,
      "learning_rate": 2.209638554216868e-06,
      "loss": 0.0241,
      "step": 73830
    },
    {
      "epoch": 8.896385542168675,
      "grad_norm": 0.24315401911735535,
      "learning_rate": 2.207228915662651e-06,
      "loss": 0.0067,
      "step": 73840
    },
    {
      "epoch": 8.897590361445783,
      "grad_norm": 0.020395202562212944,
      "learning_rate": 2.2048192771084338e-06,
      "loss": 0.0425,
      "step": 73850
    },
    {
      "epoch": 8.898795180722892,
      "grad_norm": 0.3216914236545563,
      "learning_rate": 2.202409638554217e-06,
      "loss": 0.0013,
      "step": 73860
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.017327960580587387,
      "learning_rate": 2.2e-06,
      "loss": 0.0062,
      "step": 73870
    },
    {
      "epoch": 8.901204819277108,
      "grad_norm": 0.012380361557006836,
      "learning_rate": 2.1975903614457833e-06,
      "loss": 0.0057,
      "step": 73880
    },
    {
      "epoch": 8.902409638554216,
      "grad_norm": 0.0004356327117420733,
      "learning_rate": 2.1951807228915665e-06,
      "loss": 0.0002,
      "step": 73890
    },
    {
      "epoch": 8.903614457831326,
      "grad_norm": 6.364442825317383,
      "learning_rate": 2.1927710843373496e-06,
      "loss": 0.0233,
      "step": 73900
    },
    {
      "epoch": 8.904819277108434,
      "grad_norm": 1.7025972604751587,
      "learning_rate": 2.190361445783133e-06,
      "loss": 0.0073,
      "step": 73910
    },
    {
      "epoch": 8.906024096385542,
      "grad_norm": 0.6730543971061707,
      "learning_rate": 2.1879518072289156e-06,
      "loss": 0.0216,
      "step": 73920
    },
    {
      "epoch": 8.907228915662651,
      "grad_norm": 0.0010229067411273718,
      "learning_rate": 2.1855421686746987e-06,
      "loss": 0.0093,
      "step": 73930
    },
    {
      "epoch": 8.90843373493976,
      "grad_norm": 0.0006333363708108664,
      "learning_rate": 2.183132530120482e-06,
      "loss": 0.001,
      "step": 73940
    },
    {
      "epoch": 8.909638554216867,
      "grad_norm": 1.5510199069976807,
      "learning_rate": 2.1807228915662655e-06,
      "loss": 0.0141,
      "step": 73950
    },
    {
      "epoch": 8.910843373493975,
      "grad_norm": 0.00045298048644326627,
      "learning_rate": 2.1783132530120487e-06,
      "loss": 0.058,
      "step": 73960
    },
    {
      "epoch": 8.912048192771085,
      "grad_norm": 0.0010497255716472864,
      "learning_rate": 2.1759036144578314e-06,
      "loss": 0.0244,
      "step": 73970
    },
    {
      "epoch": 8.913253012048193,
      "grad_norm": 2.9057302474975586,
      "learning_rate": 2.1734939759036146e-06,
      "loss": 0.0768,
      "step": 73980
    },
    {
      "epoch": 8.9144578313253,
      "grad_norm": 0.013390198349952698,
      "learning_rate": 2.171084337349398e-06,
      "loss": 0.0001,
      "step": 73990
    },
    {
      "epoch": 8.91566265060241,
      "grad_norm": 0.016247576102614403,
      "learning_rate": 2.168674698795181e-06,
      "loss": 0.0344,
      "step": 74000
    },
    {
      "epoch": 8.916867469879518,
      "grad_norm": 2.33479380607605,
      "learning_rate": 2.166265060240964e-06,
      "loss": 0.0037,
      "step": 74010
    },
    {
      "epoch": 8.918072289156626,
      "grad_norm": 0.9586748480796814,
      "learning_rate": 2.1638554216867473e-06,
      "loss": 0.0422,
      "step": 74020
    },
    {
      "epoch": 8.919277108433734,
      "grad_norm": 0.0007236349629238248,
      "learning_rate": 2.16144578313253e-06,
      "loss": 0.0099,
      "step": 74030
    },
    {
      "epoch": 8.920481927710844,
      "grad_norm": 0.0005239149322733283,
      "learning_rate": 2.1590361445783133e-06,
      "loss": 0.0133,
      "step": 74040
    },
    {
      "epoch": 8.921686746987952,
      "grad_norm": 0.503544270992279,
      "learning_rate": 2.1566265060240964e-06,
      "loss": 0.016,
      "step": 74050
    },
    {
      "epoch": 8.92289156626506,
      "grad_norm": 0.005456926766782999,
      "learning_rate": 2.1542168674698796e-06,
      "loss": 0.0374,
      "step": 74060
    },
    {
      "epoch": 8.92409638554217,
      "grad_norm": 0.0016227657906711102,
      "learning_rate": 2.1518072289156628e-06,
      "loss": 0.0027,
      "step": 74070
    },
    {
      "epoch": 8.925301204819277,
      "grad_norm": 1.8315767049789429,
      "learning_rate": 2.149397590361446e-06,
      "loss": 0.0094,
      "step": 74080
    },
    {
      "epoch": 8.926506024096385,
      "grad_norm": 0.0005024565034545958,
      "learning_rate": 2.146987951807229e-06,
      "loss": 0.0066,
      "step": 74090
    },
    {
      "epoch": 8.927710843373493,
      "grad_norm": 0.24450060725212097,
      "learning_rate": 2.1445783132530123e-06,
      "loss": 0.0107,
      "step": 74100
    },
    {
      "epoch": 8.928915662650603,
      "grad_norm": 0.0006090787355788052,
      "learning_rate": 2.1421686746987955e-06,
      "loss": 0.0053,
      "step": 74110
    },
    {
      "epoch": 8.93012048192771,
      "grad_norm": 0.0003620298230089247,
      "learning_rate": 2.1397590361445787e-06,
      "loss": 0.0085,
      "step": 74120
    },
    {
      "epoch": 8.931325301204819,
      "grad_norm": 0.0008555743261240423,
      "learning_rate": 2.137349397590362e-06,
      "loss": 0.0177,
      "step": 74130
    },
    {
      "epoch": 8.932530120481928,
      "grad_norm": 0.006143669132143259,
      "learning_rate": 2.134939759036145e-06,
      "loss": 0.0296,
      "step": 74140
    },
    {
      "epoch": 8.933734939759036,
      "grad_norm": 0.34565258026123047,
      "learning_rate": 2.1325301204819278e-06,
      "loss": 0.0203,
      "step": 74150
    },
    {
      "epoch": 8.934939759036144,
      "grad_norm": 4.377795696258545,
      "learning_rate": 2.130120481927711e-06,
      "loss": 0.0476,
      "step": 74160
    },
    {
      "epoch": 8.936144578313254,
      "grad_norm": 0.0050924778915941715,
      "learning_rate": 2.127710843373494e-06,
      "loss": 0.0061,
      "step": 74170
    },
    {
      "epoch": 8.937349397590362,
      "grad_norm": 0.14748968183994293,
      "learning_rate": 2.1253012048192773e-06,
      "loss": 0.0322,
      "step": 74180
    },
    {
      "epoch": 8.93855421686747,
      "grad_norm": 0.8125168085098267,
      "learning_rate": 2.1228915662650605e-06,
      "loss": 0.0067,
      "step": 74190
    },
    {
      "epoch": 8.939759036144578,
      "grad_norm": 0.0007799871382303536,
      "learning_rate": 2.1204819277108437e-06,
      "loss": 0.0101,
      "step": 74200
    },
    {
      "epoch": 8.940963855421687,
      "grad_norm": 0.1656685471534729,
      "learning_rate": 2.1180722891566264e-06,
      "loss": 0.001,
      "step": 74210
    },
    {
      "epoch": 8.942168674698795,
      "grad_norm": 0.00041996315121650696,
      "learning_rate": 2.1156626506024096e-06,
      "loss": 0.0052,
      "step": 74220
    },
    {
      "epoch": 8.943373493975903,
      "grad_norm": 1.248603343963623,
      "learning_rate": 2.1132530120481928e-06,
      "loss": 0.0218,
      "step": 74230
    },
    {
      "epoch": 8.944578313253013,
      "grad_norm": 6.613401412963867,
      "learning_rate": 2.110843373493976e-06,
      "loss": 0.023,
      "step": 74240
    },
    {
      "epoch": 8.94578313253012,
      "grad_norm": 0.0012431662762537599,
      "learning_rate": 2.1084337349397595e-06,
      "loss": 0.0016,
      "step": 74250
    },
    {
      "epoch": 8.946987951807229,
      "grad_norm": 0.05665832385420799,
      "learning_rate": 2.1060240963855423e-06,
      "loss": 0.0161,
      "step": 74260
    },
    {
      "epoch": 8.948192771084337,
      "grad_norm": 0.012308378703892231,
      "learning_rate": 2.1036144578313255e-06,
      "loss": 0.0406,
      "step": 74270
    },
    {
      "epoch": 8.949397590361446,
      "grad_norm": 0.00033809602609835565,
      "learning_rate": 2.1012048192771086e-06,
      "loss": 0.0036,
      "step": 74280
    },
    {
      "epoch": 8.950602409638554,
      "grad_norm": 0.0144432308152318,
      "learning_rate": 2.098795180722892e-06,
      "loss": 0.0187,
      "step": 74290
    },
    {
      "epoch": 8.951807228915662,
      "grad_norm": 1.1670856475830078,
      "learning_rate": 2.096385542168675e-06,
      "loss": 0.016,
      "step": 74300
    },
    {
      "epoch": 8.953012048192772,
      "grad_norm": 0.00682962266728282,
      "learning_rate": 2.093975903614458e-06,
      "loss": 0.0117,
      "step": 74310
    },
    {
      "epoch": 8.95421686746988,
      "grad_norm": 0.003860217286273837,
      "learning_rate": 2.0915662650602413e-06,
      "loss": 0.0004,
      "step": 74320
    },
    {
      "epoch": 8.955421686746988,
      "grad_norm": 1.6951638460159302,
      "learning_rate": 2.089156626506024e-06,
      "loss": 0.0239,
      "step": 74330
    },
    {
      "epoch": 8.956626506024097,
      "grad_norm": 0.0006612113211303949,
      "learning_rate": 2.0867469879518073e-06,
      "loss": 0.0087,
      "step": 74340
    },
    {
      "epoch": 8.957831325301205,
      "grad_norm": 0.0005872921901755035,
      "learning_rate": 2.0843373493975904e-06,
      "loss": 0.0112,
      "step": 74350
    },
    {
      "epoch": 8.959036144578313,
      "grad_norm": 0.0006486881757155061,
      "learning_rate": 2.0819277108433736e-06,
      "loss": 0.018,
      "step": 74360
    },
    {
      "epoch": 8.960240963855421,
      "grad_norm": 2.562297821044922,
      "learning_rate": 2.079518072289157e-06,
      "loss": 0.0101,
      "step": 74370
    },
    {
      "epoch": 8.96144578313253,
      "grad_norm": 0.0005617321585305035,
      "learning_rate": 2.07710843373494e-06,
      "loss": 0.0025,
      "step": 74380
    },
    {
      "epoch": 8.962650602409639,
      "grad_norm": 0.0004502638475969434,
      "learning_rate": 2.0746987951807227e-06,
      "loss": 0.0286,
      "step": 74390
    },
    {
      "epoch": 8.963855421686747,
      "grad_norm": 0.26024460792541504,
      "learning_rate": 2.0722891566265063e-06,
      "loss": 0.0183,
      "step": 74400
    },
    {
      "epoch": 8.965060240963856,
      "grad_norm": 0.0010745878098532557,
      "learning_rate": 2.0698795180722895e-06,
      "loss": 0.0059,
      "step": 74410
    },
    {
      "epoch": 8.966265060240964,
      "grad_norm": 0.0005732694990001619,
      "learning_rate": 2.0674698795180727e-06,
      "loss": 0.0318,
      "step": 74420
    },
    {
      "epoch": 8.967469879518072,
      "grad_norm": 2.4867637157440186,
      "learning_rate": 2.065060240963856e-06,
      "loss": 0.0346,
      "step": 74430
    },
    {
      "epoch": 8.96867469879518,
      "grad_norm": 0.45552897453308105,
      "learning_rate": 2.0626506024096386e-06,
      "loss": 0.0264,
      "step": 74440
    },
    {
      "epoch": 8.96987951807229,
      "grad_norm": 0.002150258980691433,
      "learning_rate": 2.0602409638554218e-06,
      "loss": 0.0174,
      "step": 74450
    },
    {
      "epoch": 8.971084337349398,
      "grad_norm": 0.0006858690176159143,
      "learning_rate": 2.057831325301205e-06,
      "loss": 0.0009,
      "step": 74460
    },
    {
      "epoch": 8.972289156626506,
      "grad_norm": 2.892646312713623,
      "learning_rate": 2.055421686746988e-06,
      "loss": 0.0199,
      "step": 74470
    },
    {
      "epoch": 8.973493975903615,
      "grad_norm": 2.410942554473877,
      "learning_rate": 2.0530120481927713e-06,
      "loss": 0.0214,
      "step": 74480
    },
    {
      "epoch": 8.974698795180723,
      "grad_norm": 0.4355892837047577,
      "learning_rate": 2.0506024096385545e-06,
      "loss": 0.0076,
      "step": 74490
    },
    {
      "epoch": 8.975903614457831,
      "grad_norm": 0.0004363033513072878,
      "learning_rate": 2.0481927710843377e-06,
      "loss": 0.0128,
      "step": 74500
    },
    {
      "epoch": 8.977108433734939,
      "grad_norm": 2.2705307006835938,
      "learning_rate": 2.0457831325301204e-06,
      "loss": 0.0148,
      "step": 74510
    },
    {
      "epoch": 8.978313253012049,
      "grad_norm": 2.733043909072876,
      "learning_rate": 2.0433734939759036e-06,
      "loss": 0.0201,
      "step": 74520
    },
    {
      "epoch": 8.979518072289157,
      "grad_norm": 0.518684446811676,
      "learning_rate": 2.0409638554216868e-06,
      "loss": 0.0035,
      "step": 74530
    },
    {
      "epoch": 8.980722891566264,
      "grad_norm": 7.1681227684021,
      "learning_rate": 2.0385542168674704e-06,
      "loss": 0.0153,
      "step": 74540
    },
    {
      "epoch": 8.981927710843374,
      "grad_norm": 0.0037822930607944727,
      "learning_rate": 2.036144578313253e-06,
      "loss": 0.0028,
      "step": 74550
    },
    {
      "epoch": 8.983132530120482,
      "grad_norm": 0.0002716139715630561,
      "learning_rate": 2.0337349397590363e-06,
      "loss": 0.0125,
      "step": 74560
    },
    {
      "epoch": 8.98433734939759,
      "grad_norm": 1.5842242240905762,
      "learning_rate": 2.0313253012048195e-06,
      "loss": 0.019,
      "step": 74570
    },
    {
      "epoch": 8.985542168674698,
      "grad_norm": 3.164806365966797,
      "learning_rate": 2.0289156626506026e-06,
      "loss": 0.0235,
      "step": 74580
    },
    {
      "epoch": 8.986746987951808,
      "grad_norm": 0.0019898544996976852,
      "learning_rate": 2.026506024096386e-06,
      "loss": 0.0184,
      "step": 74590
    },
    {
      "epoch": 8.987951807228916,
      "grad_norm": 0.00031907143420539796,
      "learning_rate": 2.024096385542169e-06,
      "loss": 0.0252,
      "step": 74600
    },
    {
      "epoch": 8.989156626506023,
      "grad_norm": 0.0006408296176232398,
      "learning_rate": 2.021686746987952e-06,
      "loss": 0.0257,
      "step": 74610
    },
    {
      "epoch": 8.990361445783133,
      "grad_norm": 0.001964170951396227,
      "learning_rate": 2.019277108433735e-06,
      "loss": 0.0005,
      "step": 74620
    },
    {
      "epoch": 8.991566265060241,
      "grad_norm": 0.0005617448478005826,
      "learning_rate": 2.016867469879518e-06,
      "loss": 0.0012,
      "step": 74630
    },
    {
      "epoch": 8.992771084337349,
      "grad_norm": 0.0003409148775972426,
      "learning_rate": 2.0144578313253013e-06,
      "loss": 0.0186,
      "step": 74640
    },
    {
      "epoch": 8.993975903614459,
      "grad_norm": 0.0032564529683440924,
      "learning_rate": 2.0120481927710845e-06,
      "loss": 0.002,
      "step": 74650
    },
    {
      "epoch": 8.995180722891567,
      "grad_norm": 0.7108469605445862,
      "learning_rate": 2.0096385542168676e-06,
      "loss": 0.0164,
      "step": 74660
    },
    {
      "epoch": 8.996385542168674,
      "grad_norm": 0.17037265002727509,
      "learning_rate": 2.007228915662651e-06,
      "loss": 0.0245,
      "step": 74670
    },
    {
      "epoch": 8.997590361445782,
      "grad_norm": 0.532747209072113,
      "learning_rate": 2.004819277108434e-06,
      "loss": 0.0126,
      "step": 74680
    },
    {
      "epoch": 8.998795180722892,
      "grad_norm": 0.00431648176163435,
      "learning_rate": 2.002409638554217e-06,
      "loss": 0.0339,
      "step": 74690
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.0008351144497282803,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0067,
      "step": 74700
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9873687664041995,
      "eval_f1": 0.966511338925132,
      "eval_loss": 0.04740466549992561,
      "eval_precision": 0.9717641179410295,
      "eval_recall": 0.9613150414040291,
      "eval_runtime": 4964.4667,
      "eval_samples_per_second": 8.599,
      "eval_steps_per_second": 0.358,
      "step": 74700
    },
    {
      "epoch": 9.001204819277108,
      "grad_norm": 0.0021804349962621927,
      "learning_rate": 1.9975903614457835e-06,
      "loss": 0.0118,
      "step": 74710
    },
    {
      "epoch": 9.002409638554218,
      "grad_norm": 0.0006441806326620281,
      "learning_rate": 1.9951807228915667e-06,
      "loss": 0.0123,
      "step": 74720
    },
    {
      "epoch": 9.003614457831326,
      "grad_norm": 0.0015545785427093506,
      "learning_rate": 1.9927710843373494e-06,
      "loss": 0.0096,
      "step": 74730
    },
    {
      "epoch": 9.004819277108433,
      "grad_norm": 0.0004325484624132514,
      "learning_rate": 1.9903614457831326e-06,
      "loss": 0.0086,
      "step": 74740
    },
    {
      "epoch": 9.006024096385541,
      "grad_norm": 0.009912830777466297,
      "learning_rate": 1.987951807228916e-06,
      "loss": 0.0032,
      "step": 74750
    },
    {
      "epoch": 9.007228915662651,
      "grad_norm": 1.5621757507324219,
      "learning_rate": 1.985542168674699e-06,
      "loss": 0.0205,
      "step": 74760
    },
    {
      "epoch": 9.008433734939759,
      "grad_norm": 0.44491663575172424,
      "learning_rate": 1.983132530120482e-06,
      "loss": 0.0101,
      "step": 74770
    },
    {
      "epoch": 9.009638554216867,
      "grad_norm": 0.00042569730430841446,
      "learning_rate": 1.9807228915662653e-06,
      "loss": 0.0228,
      "step": 74780
    },
    {
      "epoch": 9.010843373493977,
      "grad_norm": 0.0007144613773562014,
      "learning_rate": 1.9783132530120485e-06,
      "loss": 0.0046,
      "step": 74790
    },
    {
      "epoch": 9.012048192771084,
      "grad_norm": 2.7260890007019043,
      "learning_rate": 1.9759036144578312e-06,
      "loss": 0.0326,
      "step": 74800
    },
    {
      "epoch": 9.013253012048192,
      "grad_norm": 0.000341725826729089,
      "learning_rate": 1.9734939759036144e-06,
      "loss": 0.0277,
      "step": 74810
    },
    {
      "epoch": 9.0144578313253,
      "grad_norm": 0.0028563907835632563,
      "learning_rate": 1.9710843373493976e-06,
      "loss": 0.0297,
      "step": 74820
    },
    {
      "epoch": 9.01566265060241,
      "grad_norm": 0.005511261522769928,
      "learning_rate": 1.9686746987951808e-06,
      "loss": 0.051,
      "step": 74830
    },
    {
      "epoch": 9.016867469879518,
      "grad_norm": 0.027864063158631325,
      "learning_rate": 1.966265060240964e-06,
      "loss": 0.0032,
      "step": 74840
    },
    {
      "epoch": 9.018072289156626,
      "grad_norm": 0.00426518777385354,
      "learning_rate": 1.963855421686747e-06,
      "loss": 0.0083,
      "step": 74850
    },
    {
      "epoch": 9.019277108433736,
      "grad_norm": 0.1864927113056183,
      "learning_rate": 1.9614457831325303e-06,
      "loss": 0.0034,
      "step": 74860
    },
    {
      "epoch": 9.020481927710843,
      "grad_norm": 0.0005856255884282291,
      "learning_rate": 1.9590361445783135e-06,
      "loss": 0.0026,
      "step": 74870
    },
    {
      "epoch": 9.021686746987951,
      "grad_norm": 0.03370935842394829,
      "learning_rate": 1.9566265060240967e-06,
      "loss": 0.0165,
      "step": 74880
    },
    {
      "epoch": 9.022891566265061,
      "grad_norm": 0.00035592724452726543,
      "learning_rate": 1.95421686746988e-06,
      "loss": 0.008,
      "step": 74890
    },
    {
      "epoch": 9.024096385542169,
      "grad_norm": 0.011341149918735027,
      "learning_rate": 1.951807228915663e-06,
      "loss": 0.0243,
      "step": 74900
    },
    {
      "epoch": 9.025301204819277,
      "grad_norm": 0.8956791758537292,
      "learning_rate": 1.9493975903614458e-06,
      "loss": 0.0034,
      "step": 74910
    },
    {
      "epoch": 9.026506024096385,
      "grad_norm": 0.0011768590193241835,
      "learning_rate": 1.946987951807229e-06,
      "loss": 0.0186,
      "step": 74920
    },
    {
      "epoch": 9.027710843373494,
      "grad_norm": 0.0006827976321801543,
      "learning_rate": 1.944578313253012e-06,
      "loss": 0.0134,
      "step": 74930
    },
    {
      "epoch": 9.028915662650602,
      "grad_norm": 0.0018759064842015505,
      "learning_rate": 1.9421686746987953e-06,
      "loss": 0.0152,
      "step": 74940
    },
    {
      "epoch": 9.03012048192771,
      "grad_norm": 0.004463404417037964,
      "learning_rate": 1.9397590361445785e-06,
      "loss": 0.0139,
      "step": 74950
    },
    {
      "epoch": 9.03132530120482,
      "grad_norm": 0.7088657021522522,
      "learning_rate": 1.9373493975903616e-06,
      "loss": 0.0158,
      "step": 74960
    },
    {
      "epoch": 9.032530120481928,
      "grad_norm": 0.0004040769999846816,
      "learning_rate": 1.934939759036145e-06,
      "loss": 0.0074,
      "step": 74970
    },
    {
      "epoch": 9.033734939759036,
      "grad_norm": 0.00045712938299402595,
      "learning_rate": 1.932530120481928e-06,
      "loss": 0.0196,
      "step": 74980
    },
    {
      "epoch": 9.034939759036144,
      "grad_norm": 0.0008740111370570958,
      "learning_rate": 1.930120481927711e-06,
      "loss": 0.011,
      "step": 74990
    },
    {
      "epoch": 9.036144578313253,
      "grad_norm": 7.46713399887085,
      "learning_rate": 1.9277108433734943e-06,
      "loss": 0.0028,
      "step": 75000
    },
    {
      "epoch": 9.037349397590361,
      "grad_norm": 0.0003543431230355054,
      "learning_rate": 1.9253012048192775e-06,
      "loss": 0.0309,
      "step": 75010
    },
    {
      "epoch": 9.03855421686747,
      "grad_norm": 0.3371560275554657,
      "learning_rate": 1.9228915662650603e-06,
      "loss": 0.0137,
      "step": 75020
    },
    {
      "epoch": 9.039759036144579,
      "grad_norm": 2.0599453449249268,
      "learning_rate": 1.9204819277108434e-06,
      "loss": 0.0332,
      "step": 75030
    },
    {
      "epoch": 9.040963855421687,
      "grad_norm": 0.0004911012947559357,
      "learning_rate": 1.9180722891566266e-06,
      "loss": 0.0012,
      "step": 75040
    },
    {
      "epoch": 9.042168674698795,
      "grad_norm": 0.16432642936706543,
      "learning_rate": 1.91566265060241e-06,
      "loss": 0.0146,
      "step": 75050
    },
    {
      "epoch": 9.043373493975903,
      "grad_norm": 0.0042726825922727585,
      "learning_rate": 1.913253012048193e-06,
      "loss": 0.0053,
      "step": 75060
    },
    {
      "epoch": 9.044578313253012,
      "grad_norm": 0.9668664932250977,
      "learning_rate": 1.910843373493976e-06,
      "loss": 0.0193,
      "step": 75070
    },
    {
      "epoch": 9.04578313253012,
      "grad_norm": 0.05961452051997185,
      "learning_rate": 1.9084337349397593e-06,
      "loss": 0.0185,
      "step": 75080
    },
    {
      "epoch": 9.046987951807228,
      "grad_norm": 0.6854556202888489,
      "learning_rate": 1.9060240963855423e-06,
      "loss": 0.0021,
      "step": 75090
    },
    {
      "epoch": 9.048192771084338,
      "grad_norm": 1.205972671508789,
      "learning_rate": 1.9036144578313255e-06,
      "loss": 0.02,
      "step": 75100
    },
    {
      "epoch": 9.049397590361446,
      "grad_norm": 0.0074011338874697685,
      "learning_rate": 1.9012048192771084e-06,
      "loss": 0.0196,
      "step": 75110
    },
    {
      "epoch": 9.050602409638554,
      "grad_norm": 0.0009374342625960708,
      "learning_rate": 1.8987951807228916e-06,
      "loss": 0.0044,
      "step": 75120
    },
    {
      "epoch": 9.051807228915663,
      "grad_norm": 0.0012013015802949667,
      "learning_rate": 1.896385542168675e-06,
      "loss": 0.0109,
      "step": 75130
    },
    {
      "epoch": 9.053012048192771,
      "grad_norm": 0.000887454894836992,
      "learning_rate": 1.8939759036144582e-06,
      "loss": 0.0261,
      "step": 75140
    },
    {
      "epoch": 9.05421686746988,
      "grad_norm": 0.001003536395728588,
      "learning_rate": 1.8915662650602411e-06,
      "loss": 0.0092,
      "step": 75150
    },
    {
      "epoch": 9.055421686746987,
      "grad_norm": 0.000797151355072856,
      "learning_rate": 1.8891566265060243e-06,
      "loss": 0.0087,
      "step": 75160
    },
    {
      "epoch": 9.056626506024097,
      "grad_norm": 0.0004847597738262266,
      "learning_rate": 1.8867469879518075e-06,
      "loss": 0.0037,
      "step": 75170
    },
    {
      "epoch": 9.057831325301205,
      "grad_norm": 0.0004436453164089471,
      "learning_rate": 1.8843373493975905e-06,
      "loss": 0.0082,
      "step": 75180
    },
    {
      "epoch": 9.059036144578313,
      "grad_norm": 2.1781976222991943,
      "learning_rate": 1.8819277108433736e-06,
      "loss": 0.0161,
      "step": 75190
    },
    {
      "epoch": 9.060240963855422,
      "grad_norm": 1.9093613624572754,
      "learning_rate": 1.8795180722891568e-06,
      "loss": 0.0116,
      "step": 75200
    },
    {
      "epoch": 9.06144578313253,
      "grad_norm": 0.18362250924110413,
      "learning_rate": 1.87710843373494e-06,
      "loss": 0.0059,
      "step": 75210
    },
    {
      "epoch": 9.062650602409638,
      "grad_norm": 0.1483139544725418,
      "learning_rate": 1.874698795180723e-06,
      "loss": 0.013,
      "step": 75220
    },
    {
      "epoch": 9.063855421686746,
      "grad_norm": 0.0005038082017563283,
      "learning_rate": 1.8722891566265061e-06,
      "loss": 0.0105,
      "step": 75230
    },
    {
      "epoch": 9.065060240963856,
      "grad_norm": 2.5334126949310303,
      "learning_rate": 1.8698795180722893e-06,
      "loss": 0.0198,
      "step": 75240
    },
    {
      "epoch": 9.066265060240964,
      "grad_norm": 0.0003170460695400834,
      "learning_rate": 1.8674698795180723e-06,
      "loss": 0.0061,
      "step": 75250
    },
    {
      "epoch": 9.067469879518072,
      "grad_norm": 0.0007862180355004966,
      "learning_rate": 1.8650602409638554e-06,
      "loss": 0.018,
      "step": 75260
    },
    {
      "epoch": 9.068674698795181,
      "grad_norm": 0.884541392326355,
      "learning_rate": 1.8626506024096386e-06,
      "loss": 0.0363,
      "step": 75270
    },
    {
      "epoch": 9.06987951807229,
      "grad_norm": 0.004923315718770027,
      "learning_rate": 1.860240963855422e-06,
      "loss": 0.0024,
      "step": 75280
    },
    {
      "epoch": 9.071084337349397,
      "grad_norm": 1.5313012599945068,
      "learning_rate": 1.8578313253012052e-06,
      "loss": 0.0178,
      "step": 75290
    },
    {
      "epoch": 9.072289156626505,
      "grad_norm": 0.0004490259743761271,
      "learning_rate": 1.8554216867469881e-06,
      "loss": 0.0032,
      "step": 75300
    },
    {
      "epoch": 9.073493975903615,
      "grad_norm": 0.00034100687480531633,
      "learning_rate": 1.8530120481927713e-06,
      "loss": 0.0109,
      "step": 75310
    },
    {
      "epoch": 9.074698795180723,
      "grad_norm": 0.7329614758491516,
      "learning_rate": 1.8506024096385545e-06,
      "loss": 0.0046,
      "step": 75320
    },
    {
      "epoch": 9.07590361445783,
      "grad_norm": 1.0306906700134277,
      "learning_rate": 1.8481927710843375e-06,
      "loss": 0.0033,
      "step": 75330
    },
    {
      "epoch": 9.07710843373494,
      "grad_norm": 0.6299620866775513,
      "learning_rate": 1.8457831325301206e-06,
      "loss": 0.0393,
      "step": 75340
    },
    {
      "epoch": 9.078313253012048,
      "grad_norm": 0.00522799976170063,
      "learning_rate": 1.8433734939759038e-06,
      "loss": 0.0051,
      "step": 75350
    },
    {
      "epoch": 9.079518072289156,
      "grad_norm": 0.002046096371486783,
      "learning_rate": 1.8409638554216868e-06,
      "loss": 0.0082,
      "step": 75360
    },
    {
      "epoch": 9.080722891566266,
      "grad_norm": 0.00022502771753352135,
      "learning_rate": 1.83855421686747e-06,
      "loss": 0.0063,
      "step": 75370
    },
    {
      "epoch": 9.081927710843374,
      "grad_norm": 2.383937358856201,
      "learning_rate": 1.8361445783132531e-06,
      "loss": 0.0206,
      "step": 75380
    },
    {
      "epoch": 9.083132530120482,
      "grad_norm": 0.7129003405570984,
      "learning_rate": 1.8337349397590363e-06,
      "loss": 0.0189,
      "step": 75390
    },
    {
      "epoch": 9.08433734939759,
      "grad_norm": 0.00026630715001374483,
      "learning_rate": 1.8313253012048193e-06,
      "loss": 0.0159,
      "step": 75400
    },
    {
      "epoch": 9.0855421686747,
      "grad_norm": 0.0002483230200596154,
      "learning_rate": 1.8289156626506024e-06,
      "loss": 0.015,
      "step": 75410
    },
    {
      "epoch": 9.086746987951807,
      "grad_norm": 0.00040728808380663395,
      "learning_rate": 1.8265060240963856e-06,
      "loss": 0.0041,
      "step": 75420
    },
    {
      "epoch": 9.087951807228915,
      "grad_norm": 0.00029898533830419183,
      "learning_rate": 1.824096385542169e-06,
      "loss": 0.0056,
      "step": 75430
    },
    {
      "epoch": 9.089156626506025,
      "grad_norm": 0.0003206927503924817,
      "learning_rate": 1.821686746987952e-06,
      "loss": 0.0017,
      "step": 75440
    },
    {
      "epoch": 9.090361445783133,
      "grad_norm": 0.9632124304771423,
      "learning_rate": 1.8192771084337351e-06,
      "loss": 0.0156,
      "step": 75450
    },
    {
      "epoch": 9.09156626506024,
      "grad_norm": 1.8101767301559448,
      "learning_rate": 1.8168674698795183e-06,
      "loss": 0.0116,
      "step": 75460
    },
    {
      "epoch": 9.092771084337349,
      "grad_norm": 0.0027052550576627254,
      "learning_rate": 1.8144578313253015e-06,
      "loss": 0.0306,
      "step": 75470
    },
    {
      "epoch": 9.093975903614458,
      "grad_norm": 0.0002830630401149392,
      "learning_rate": 1.8120481927710845e-06,
      "loss": 0.0011,
      "step": 75480
    },
    {
      "epoch": 9.095180722891566,
      "grad_norm": 0.32203900814056396,
      "learning_rate": 1.8096385542168676e-06,
      "loss": 0.0048,
      "step": 75490
    },
    {
      "epoch": 9.096385542168674,
      "grad_norm": 0.00080720434198156,
      "learning_rate": 1.8072289156626508e-06,
      "loss": 0.0329,
      "step": 75500
    },
    {
      "epoch": 9.097590361445784,
      "grad_norm": 0.0004986998392269015,
      "learning_rate": 1.8048192771084338e-06,
      "loss": 0.0115,
      "step": 75510
    },
    {
      "epoch": 9.098795180722892,
      "grad_norm": 0.00023265265917871147,
      "learning_rate": 1.802409638554217e-06,
      "loss": 0.025,
      "step": 75520
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.37121981382369995,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 0.0023,
      "step": 75530
    },
    {
      "epoch": 9.101204819277108,
      "grad_norm": 0.37431779503822327,
      "learning_rate": 1.797590361445783e-06,
      "loss": 0.0035,
      "step": 75540
    },
    {
      "epoch": 9.102409638554217,
      "grad_norm": 0.00047656986862421036,
      "learning_rate": 1.7951807228915663e-06,
      "loss": 0.0164,
      "step": 75550
    },
    {
      "epoch": 9.103614457831325,
      "grad_norm": 0.0012304492993280292,
      "learning_rate": 1.7927710843373494e-06,
      "loss": 0.0233,
      "step": 75560
    },
    {
      "epoch": 9.104819277108433,
      "grad_norm": 0.00135708914604038,
      "learning_rate": 1.7903614457831328e-06,
      "loss": 0.0173,
      "step": 75570
    },
    {
      "epoch": 9.106024096385543,
      "grad_norm": 0.0003925583732780069,
      "learning_rate": 1.787951807228916e-06,
      "loss": 0.0097,
      "step": 75580
    },
    {
      "epoch": 9.10722891566265,
      "grad_norm": 0.2702661156654358,
      "learning_rate": 1.785542168674699e-06,
      "loss": 0.0025,
      "step": 75590
    },
    {
      "epoch": 9.108433734939759,
      "grad_norm": 0.33139336109161377,
      "learning_rate": 1.7831325301204822e-06,
      "loss": 0.0121,
      "step": 75600
    },
    {
      "epoch": 9.109638554216868,
      "grad_norm": 0.00019254436483606696,
      "learning_rate": 1.7807228915662653e-06,
      "loss": 0.0068,
      "step": 75610
    },
    {
      "epoch": 9.110843373493976,
      "grad_norm": 0.001102125272154808,
      "learning_rate": 1.7783132530120483e-06,
      "loss": 0.0184,
      "step": 75620
    },
    {
      "epoch": 9.112048192771084,
      "grad_norm": 0.001271584304049611,
      "learning_rate": 1.7759036144578315e-06,
      "loss": 0.0223,
      "step": 75630
    },
    {
      "epoch": 9.113253012048192,
      "grad_norm": 0.0005308282561600208,
      "learning_rate": 1.7734939759036146e-06,
      "loss": 0.0022,
      "step": 75640
    },
    {
      "epoch": 9.114457831325302,
      "grad_norm": 0.0030795230995863676,
      "learning_rate": 1.7710843373493978e-06,
      "loss": 0.0054,
      "step": 75650
    },
    {
      "epoch": 9.11566265060241,
      "grad_norm": 0.0004914405872114003,
      "learning_rate": 1.7686746987951808e-06,
      "loss": 0.0126,
      "step": 75660
    },
    {
      "epoch": 9.116867469879518,
      "grad_norm": 0.0004110323789063841,
      "learning_rate": 1.766265060240964e-06,
      "loss": 0.0015,
      "step": 75670
    },
    {
      "epoch": 9.118072289156627,
      "grad_norm": 0.0010501877404749393,
      "learning_rate": 1.7638554216867471e-06,
      "loss": 0.0087,
      "step": 75680
    },
    {
      "epoch": 9.119277108433735,
      "grad_norm": 0.16805344820022583,
      "learning_rate": 1.76144578313253e-06,
      "loss": 0.0012,
      "step": 75690
    },
    {
      "epoch": 9.120481927710843,
      "grad_norm": 0.000343724008416757,
      "learning_rate": 1.7590361445783133e-06,
      "loss": 0.0013,
      "step": 75700
    },
    {
      "epoch": 9.121686746987951,
      "grad_norm": 0.08697265386581421,
      "learning_rate": 1.7566265060240965e-06,
      "loss": 0.0074,
      "step": 75710
    },
    {
      "epoch": 9.12289156626506,
      "grad_norm": 0.03777051344513893,
      "learning_rate": 1.7542168674698798e-06,
      "loss": 0.034,
      "step": 75720
    },
    {
      "epoch": 9.124096385542169,
      "grad_norm": 0.0008282599155791104,
      "learning_rate": 1.7518072289156628e-06,
      "loss": 0.0012,
      "step": 75730
    },
    {
      "epoch": 9.125301204819277,
      "grad_norm": 0.00047908100532367826,
      "learning_rate": 1.749397590361446e-06,
      "loss": 0.0338,
      "step": 75740
    },
    {
      "epoch": 9.126506024096386,
      "grad_norm": 0.002027236856520176,
      "learning_rate": 1.7469879518072292e-06,
      "loss": 0.0006,
      "step": 75750
    },
    {
      "epoch": 9.127710843373494,
      "grad_norm": 0.0006638811901211739,
      "learning_rate": 1.7445783132530123e-06,
      "loss": 0.0044,
      "step": 75760
    },
    {
      "epoch": 9.128915662650602,
      "grad_norm": 1.4706192016601562,
      "learning_rate": 1.7421686746987953e-06,
      "loss": 0.0357,
      "step": 75770
    },
    {
      "epoch": 9.13012048192771,
      "grad_norm": 0.0010128632420673966,
      "learning_rate": 1.7397590361445785e-06,
      "loss": 0.0029,
      "step": 75780
    },
    {
      "epoch": 9.13132530120482,
      "grad_norm": 0.0004222278075758368,
      "learning_rate": 1.7373493975903616e-06,
      "loss": 0.0372,
      "step": 75790
    },
    {
      "epoch": 9.132530120481928,
      "grad_norm": 1.6320884227752686,
      "learning_rate": 1.7349397590361446e-06,
      "loss": 0.017,
      "step": 75800
    },
    {
      "epoch": 9.133734939759035,
      "grad_norm": 6.6930928230285645,
      "learning_rate": 1.7325301204819278e-06,
      "loss": 0.0391,
      "step": 75810
    },
    {
      "epoch": 9.134939759036145,
      "grad_norm": 0.9162373542785645,
      "learning_rate": 1.730120481927711e-06,
      "loss": 0.0017,
      "step": 75820
    },
    {
      "epoch": 9.136144578313253,
      "grad_norm": 1.5582810640335083,
      "learning_rate": 1.7277108433734941e-06,
      "loss": 0.0279,
      "step": 75830
    },
    {
      "epoch": 9.137349397590361,
      "grad_norm": 0.27408820390701294,
      "learning_rate": 1.725301204819277e-06,
      "loss": 0.0189,
      "step": 75840
    },
    {
      "epoch": 9.13855421686747,
      "grad_norm": 2.0811827182769775,
      "learning_rate": 1.7228915662650603e-06,
      "loss": 0.0184,
      "step": 75850
    },
    {
      "epoch": 9.139759036144579,
      "grad_norm": 0.2187744826078415,
      "learning_rate": 1.7204819277108435e-06,
      "loss": 0.0023,
      "step": 75860
    },
    {
      "epoch": 9.140963855421687,
      "grad_norm": 0.0005942471907474101,
      "learning_rate": 1.7180722891566268e-06,
      "loss": 0.007,
      "step": 75870
    },
    {
      "epoch": 9.142168674698794,
      "grad_norm": 0.651913046836853,
      "learning_rate": 1.7156626506024098e-06,
      "loss": 0.0026,
      "step": 75880
    },
    {
      "epoch": 9.143373493975904,
      "grad_norm": 0.1603975147008896,
      "learning_rate": 1.713253012048193e-06,
      "loss": 0.0095,
      "step": 75890
    },
    {
      "epoch": 9.144578313253012,
      "grad_norm": 0.0010550953447818756,
      "learning_rate": 1.7108433734939762e-06,
      "loss": 0.0027,
      "step": 75900
    },
    {
      "epoch": 9.14578313253012,
      "grad_norm": 2.1533141136169434,
      "learning_rate": 1.7084337349397591e-06,
      "loss": 0.0309,
      "step": 75910
    },
    {
      "epoch": 9.14698795180723,
      "grad_norm": 0.014151808805763721,
      "learning_rate": 1.7060240963855423e-06,
      "loss": 0.0114,
      "step": 75920
    },
    {
      "epoch": 9.148192771084338,
      "grad_norm": 0.009347761981189251,
      "learning_rate": 1.7036144578313255e-06,
      "loss": 0.0013,
      "step": 75930
    },
    {
      "epoch": 9.149397590361446,
      "grad_norm": 0.05465329810976982,
      "learning_rate": 1.7012048192771087e-06,
      "loss": 0.0104,
      "step": 75940
    },
    {
      "epoch": 9.150602409638553,
      "grad_norm": 2.2896957397460938,
      "learning_rate": 1.6987951807228916e-06,
      "loss": 0.0199,
      "step": 75950
    },
    {
      "epoch": 9.151807228915663,
      "grad_norm": 0.0020834440365433693,
      "learning_rate": 1.6963855421686748e-06,
      "loss": 0.0052,
      "step": 75960
    },
    {
      "epoch": 9.153012048192771,
      "grad_norm": 0.0005600444274023175,
      "learning_rate": 1.693975903614458e-06,
      "loss": 0.0017,
      "step": 75970
    },
    {
      "epoch": 9.154216867469879,
      "grad_norm": 0.0005047993618063629,
      "learning_rate": 1.691566265060241e-06,
      "loss": 0.0083,
      "step": 75980
    },
    {
      "epoch": 9.155421686746989,
      "grad_norm": 0.037083547562360764,
      "learning_rate": 1.6891566265060241e-06,
      "loss": 0.0095,
      "step": 75990
    },
    {
      "epoch": 9.156626506024097,
      "grad_norm": 0.0022849594242870808,
      "learning_rate": 1.6867469879518073e-06,
      "loss": 0.0089,
      "step": 76000
    },
    {
      "epoch": 9.157831325301204,
      "grad_norm": 2.25404691696167,
      "learning_rate": 1.6843373493975907e-06,
      "loss": 0.0123,
      "step": 76010
    },
    {
      "epoch": 9.159036144578312,
      "grad_norm": 0.07064422219991684,
      "learning_rate": 1.6819277108433738e-06,
      "loss": 0.0051,
      "step": 76020
    },
    {
      "epoch": 9.160240963855422,
      "grad_norm": 0.0011714688735082746,
      "learning_rate": 1.6795180722891568e-06,
      "loss": 0.0035,
      "step": 76030
    },
    {
      "epoch": 9.16144578313253,
      "grad_norm": 2.4546430110931396,
      "learning_rate": 1.67710843373494e-06,
      "loss": 0.0216,
      "step": 76040
    },
    {
      "epoch": 9.162650602409638,
      "grad_norm": 0.0003662521776277572,
      "learning_rate": 1.6746987951807232e-06,
      "loss": 0.0095,
      "step": 76050
    },
    {
      "epoch": 9.163855421686748,
      "grad_norm": 0.0002911679621320218,
      "learning_rate": 1.6722891566265061e-06,
      "loss": 0.0125,
      "step": 76060
    },
    {
      "epoch": 9.165060240963856,
      "grad_norm": 2.494187593460083,
      "learning_rate": 1.6698795180722893e-06,
      "loss": 0.0327,
      "step": 76070
    },
    {
      "epoch": 9.166265060240963,
      "grad_norm": 0.0003318121307529509,
      "learning_rate": 1.6674698795180725e-06,
      "loss": 0.0042,
      "step": 76080
    },
    {
      "epoch": 9.167469879518073,
      "grad_norm": 0.00038158270763233304,
      "learning_rate": 1.6650602409638554e-06,
      "loss": 0.0255,
      "step": 76090
    },
    {
      "epoch": 9.168674698795181,
      "grad_norm": 2.1071205139160156,
      "learning_rate": 1.6626506024096386e-06,
      "loss": 0.0207,
      "step": 76100
    },
    {
      "epoch": 9.169879518072289,
      "grad_norm": 0.0014866391429677606,
      "learning_rate": 1.6602409638554218e-06,
      "loss": 0.0026,
      "step": 76110
    },
    {
      "epoch": 9.171084337349397,
      "grad_norm": 0.15292806923389435,
      "learning_rate": 1.657831325301205e-06,
      "loss": 0.0252,
      "step": 76120
    },
    {
      "epoch": 9.172289156626507,
      "grad_norm": 0.3104361891746521,
      "learning_rate": 1.655421686746988e-06,
      "loss": 0.0064,
      "step": 76130
    },
    {
      "epoch": 9.173493975903614,
      "grad_norm": 0.00036563308094628155,
      "learning_rate": 1.6530120481927711e-06,
      "loss": 0.002,
      "step": 76140
    },
    {
      "epoch": 9.174698795180722,
      "grad_norm": 0.05744704604148865,
      "learning_rate": 1.6506024096385543e-06,
      "loss": 0.0096,
      "step": 76150
    },
    {
      "epoch": 9.175903614457832,
      "grad_norm": 1.5766041278839111,
      "learning_rate": 1.6481927710843377e-06,
      "loss": 0.0065,
      "step": 76160
    },
    {
      "epoch": 9.17710843373494,
      "grad_norm": 0.002671407302841544,
      "learning_rate": 1.6457831325301206e-06,
      "loss": 0.002,
      "step": 76170
    },
    {
      "epoch": 9.178313253012048,
      "grad_norm": 0.775925874710083,
      "learning_rate": 1.6433734939759038e-06,
      "loss": 0.0571,
      "step": 76180
    },
    {
      "epoch": 9.179518072289156,
      "grad_norm": 0.00039199585444293916,
      "learning_rate": 1.640963855421687e-06,
      "loss": 0.0004,
      "step": 76190
    },
    {
      "epoch": 9.180722891566266,
      "grad_norm": 0.0027388997841626406,
      "learning_rate": 1.6385542168674702e-06,
      "loss": 0.0189,
      "step": 76200
    },
    {
      "epoch": 9.181927710843373,
      "grad_norm": 0.0005053948843851686,
      "learning_rate": 1.6361445783132531e-06,
      "loss": 0.0306,
      "step": 76210
    },
    {
      "epoch": 9.183132530120481,
      "grad_norm": 0.20837974548339844,
      "learning_rate": 1.6337349397590363e-06,
      "loss": 0.0004,
      "step": 76220
    },
    {
      "epoch": 9.184337349397591,
      "grad_norm": 2.0599541664123535,
      "learning_rate": 1.6313253012048195e-06,
      "loss": 0.0209,
      "step": 76230
    },
    {
      "epoch": 9.185542168674699,
      "grad_norm": 11.541304588317871,
      "learning_rate": 1.6289156626506025e-06,
      "loss": 0.02,
      "step": 76240
    },
    {
      "epoch": 9.186746987951807,
      "grad_norm": 0.0008353909943252802,
      "learning_rate": 1.6265060240963856e-06,
      "loss": 0.009,
      "step": 76250
    },
    {
      "epoch": 9.187951807228915,
      "grad_norm": 0.5656545162200928,
      "learning_rate": 1.6240963855421688e-06,
      "loss": 0.0028,
      "step": 76260
    },
    {
      "epoch": 9.189156626506024,
      "grad_norm": 0.8826214075088501,
      "learning_rate": 1.6216867469879518e-06,
      "loss": 0.0047,
      "step": 76270
    },
    {
      "epoch": 9.190361445783132,
      "grad_norm": 0.06805519759654999,
      "learning_rate": 1.619277108433735e-06,
      "loss": 0.0135,
      "step": 76280
    },
    {
      "epoch": 9.19156626506024,
      "grad_norm": 0.0008744187070988119,
      "learning_rate": 1.6168674698795181e-06,
      "loss": 0.0185,
      "step": 76290
    },
    {
      "epoch": 9.19277108433735,
      "grad_norm": 0.8353629112243652,
      "learning_rate": 1.6144578313253013e-06,
      "loss": 0.0085,
      "step": 76300
    },
    {
      "epoch": 9.193975903614458,
      "grad_norm": 0.0013802599860355258,
      "learning_rate": 1.6120481927710847e-06,
      "loss": 0.0201,
      "step": 76310
    },
    {
      "epoch": 9.195180722891566,
      "grad_norm": 0.11250989139080048,
      "learning_rate": 1.6096385542168676e-06,
      "loss": 0.0055,
      "step": 76320
    },
    {
      "epoch": 9.196385542168676,
      "grad_norm": 0.0013978640781715512,
      "learning_rate": 1.6072289156626508e-06,
      "loss": 0.0096,
      "step": 76330
    },
    {
      "epoch": 9.197590361445783,
      "grad_norm": 2.350672483444214,
      "learning_rate": 1.604819277108434e-06,
      "loss": 0.0026,
      "step": 76340
    },
    {
      "epoch": 9.198795180722891,
      "grad_norm": 0.05150822922587395,
      "learning_rate": 1.602409638554217e-06,
      "loss": 0.0012,
      "step": 76350
    },
    {
      "epoch": 9.2,
      "grad_norm": 1.9173600673675537,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0202,
      "step": 76360
    },
    {
      "epoch": 9.201204819277109,
      "grad_norm": 0.00632356945425272,
      "learning_rate": 1.5975903614457833e-06,
      "loss": 0.0115,
      "step": 76370
    },
    {
      "epoch": 9.202409638554217,
      "grad_norm": 0.0010251094354316592,
      "learning_rate": 1.5951807228915665e-06,
      "loss": 0.002,
      "step": 76380
    },
    {
      "epoch": 9.203614457831325,
      "grad_norm": 0.0003494155826047063,
      "learning_rate": 1.5927710843373495e-06,
      "loss": 0.0015,
      "step": 76390
    },
    {
      "epoch": 9.204819277108435,
      "grad_norm": 2.19943904876709,
      "learning_rate": 1.5903614457831326e-06,
      "loss": 0.0194,
      "step": 76400
    },
    {
      "epoch": 9.206024096385542,
      "grad_norm": 0.00024615603615529835,
      "learning_rate": 1.5879518072289158e-06,
      "loss": 0.0104,
      "step": 76410
    },
    {
      "epoch": 9.20722891566265,
      "grad_norm": 0.10259514302015305,
      "learning_rate": 1.5855421686746988e-06,
      "loss": 0.003,
      "step": 76420
    },
    {
      "epoch": 9.208433734939758,
      "grad_norm": 0.0006993106799200177,
      "learning_rate": 1.583132530120482e-06,
      "loss": 0.0102,
      "step": 76430
    },
    {
      "epoch": 9.209638554216868,
      "grad_norm": 0.8322586417198181,
      "learning_rate": 1.5807228915662651e-06,
      "loss": 0.0183,
      "step": 76440
    },
    {
      "epoch": 9.210843373493976,
      "grad_norm": 0.05759518966078758,
      "learning_rate": 1.578313253012048e-06,
      "loss": 0.0115,
      "step": 76450
    },
    {
      "epoch": 9.212048192771084,
      "grad_norm": 2.876563310623169,
      "learning_rate": 1.5759036144578315e-06,
      "loss": 0.0327,
      "step": 76460
    },
    {
      "epoch": 9.213253012048193,
      "grad_norm": 0.2185065597295761,
      "learning_rate": 1.5734939759036147e-06,
      "loss": 0.0294,
      "step": 76470
    },
    {
      "epoch": 9.214457831325301,
      "grad_norm": 0.0006847677868790925,
      "learning_rate": 1.5710843373493978e-06,
      "loss": 0.0179,
      "step": 76480
    },
    {
      "epoch": 9.21566265060241,
      "grad_norm": 0.6502451300621033,
      "learning_rate": 1.568674698795181e-06,
      "loss": 0.0161,
      "step": 76490
    },
    {
      "epoch": 9.216867469879517,
      "grad_norm": 0.9540002346038818,
      "learning_rate": 1.566265060240964e-06,
      "loss": 0.0185,
      "step": 76500
    },
    {
      "epoch": 9.218072289156627,
      "grad_norm": 2.2897989749908447,
      "learning_rate": 1.5638554216867471e-06,
      "loss": 0.027,
      "step": 76510
    },
    {
      "epoch": 9.219277108433735,
      "grad_norm": 0.04660534858703613,
      "learning_rate": 1.5614457831325303e-06,
      "loss": 0.0112,
      "step": 76520
    },
    {
      "epoch": 9.220481927710843,
      "grad_norm": 0.0006352400523610413,
      "learning_rate": 1.5590361445783133e-06,
      "loss": 0.0167,
      "step": 76530
    },
    {
      "epoch": 9.221686746987952,
      "grad_norm": 8.793583869934082,
      "learning_rate": 1.5566265060240965e-06,
      "loss": 0.0122,
      "step": 76540
    },
    {
      "epoch": 9.22289156626506,
      "grad_norm": 0.18187597393989563,
      "learning_rate": 1.5542168674698796e-06,
      "loss": 0.0034,
      "step": 76550
    },
    {
      "epoch": 9.224096385542168,
      "grad_norm": 0.032910507172346115,
      "learning_rate": 1.5518072289156628e-06,
      "loss": 0.0052,
      "step": 76560
    },
    {
      "epoch": 9.225301204819278,
      "grad_norm": 0.06808554381132126,
      "learning_rate": 1.5493975903614458e-06,
      "loss": 0.0105,
      "step": 76570
    },
    {
      "epoch": 9.226506024096386,
      "grad_norm": 0.0003050258383154869,
      "learning_rate": 1.546987951807229e-06,
      "loss": 0.0188,
      "step": 76580
    },
    {
      "epoch": 9.227710843373494,
      "grad_norm": 0.6726301908493042,
      "learning_rate": 1.5445783132530121e-06,
      "loss": 0.0127,
      "step": 76590
    },
    {
      "epoch": 9.228915662650602,
      "grad_norm": 0.9608694911003113,
      "learning_rate": 1.5421686746987955e-06,
      "loss": 0.0147,
      "step": 76600
    },
    {
      "epoch": 9.230120481927711,
      "grad_norm": 0.2034950852394104,
      "learning_rate": 1.5397590361445785e-06,
      "loss": 0.0038,
      "step": 76610
    },
    {
      "epoch": 9.23132530120482,
      "grad_norm": 9.431640625,
      "learning_rate": 1.5373493975903617e-06,
      "loss": 0.0339,
      "step": 76620
    },
    {
      "epoch": 9.232530120481927,
      "grad_norm": 0.0004967303830198944,
      "learning_rate": 1.5349397590361448e-06,
      "loss": 0.0285,
      "step": 76630
    },
    {
      "epoch": 9.233734939759037,
      "grad_norm": 1.622287631034851,
      "learning_rate": 1.5325301204819278e-06,
      "loss": 0.0164,
      "step": 76640
    },
    {
      "epoch": 9.234939759036145,
      "grad_norm": 0.0005242216284386814,
      "learning_rate": 1.530120481927711e-06,
      "loss": 0.0082,
      "step": 76650
    },
    {
      "epoch": 9.236144578313253,
      "grad_norm": 1.8787682056427002,
      "learning_rate": 1.5277108433734941e-06,
      "loss": 0.0199,
      "step": 76660
    },
    {
      "epoch": 9.23734939759036,
      "grad_norm": 0.00024982503964565694,
      "learning_rate": 1.5253012048192773e-06,
      "loss": 0.0135,
      "step": 76670
    },
    {
      "epoch": 9.23855421686747,
      "grad_norm": 0.0028979063499718904,
      "learning_rate": 1.5228915662650603e-06,
      "loss": 0.0175,
      "step": 76680
    },
    {
      "epoch": 9.239759036144578,
      "grad_norm": 0.0015502662863582373,
      "learning_rate": 1.5204819277108435e-06,
      "loss": 0.0173,
      "step": 76690
    },
    {
      "epoch": 9.240963855421686,
      "grad_norm": 3.9766781330108643,
      "learning_rate": 1.5180722891566266e-06,
      "loss": 0.023,
      "step": 76700
    },
    {
      "epoch": 9.242168674698796,
      "grad_norm": 0.0005627766950055957,
      "learning_rate": 1.5156626506024096e-06,
      "loss": 0.0186,
      "step": 76710
    },
    {
      "epoch": 9.243373493975904,
      "grad_norm": 0.01828683912754059,
      "learning_rate": 1.5132530120481928e-06,
      "loss": 0.0028,
      "step": 76720
    },
    {
      "epoch": 9.244578313253012,
      "grad_norm": 1.2272676229476929,
      "learning_rate": 1.510843373493976e-06,
      "loss": 0.0082,
      "step": 76730
    },
    {
      "epoch": 9.24578313253012,
      "grad_norm": 0.00043130305130034685,
      "learning_rate": 1.5084337349397591e-06,
      "loss": 0.0276,
      "step": 76740
    },
    {
      "epoch": 9.24698795180723,
      "grad_norm": 2.490697145462036,
      "learning_rate": 1.5060240963855425e-06,
      "loss": 0.0614,
      "step": 76750
    },
    {
      "epoch": 9.248192771084337,
      "grad_norm": 6.494232177734375,
      "learning_rate": 1.5036144578313255e-06,
      "loss": 0.0069,
      "step": 76760
    },
    {
      "epoch": 9.249397590361445,
      "grad_norm": 0.002140525495633483,
      "learning_rate": 1.5012048192771087e-06,
      "loss": 0.0165,
      "step": 76770
    },
    {
      "epoch": 9.250602409638555,
      "grad_norm": 0.19936755299568176,
      "learning_rate": 1.4987951807228918e-06,
      "loss": 0.0006,
      "step": 76780
    },
    {
      "epoch": 9.251807228915663,
      "grad_norm": 0.0005538950208574533,
      "learning_rate": 1.4963855421686748e-06,
      "loss": 0.0069,
      "step": 76790
    },
    {
      "epoch": 9.25301204819277,
      "grad_norm": 0.17234395444393158,
      "learning_rate": 1.493975903614458e-06,
      "loss": 0.0164,
      "step": 76800
    },
    {
      "epoch": 9.25421686746988,
      "grad_norm": 5.245448589324951,
      "learning_rate": 1.4915662650602412e-06,
      "loss": 0.055,
      "step": 76810
    },
    {
      "epoch": 9.255421686746988,
      "grad_norm": 1.9767359495162964,
      "learning_rate": 1.4891566265060241e-06,
      "loss": 0.0148,
      "step": 76820
    },
    {
      "epoch": 9.256626506024096,
      "grad_norm": 1.914907693862915,
      "learning_rate": 1.4867469879518073e-06,
      "loss": 0.0264,
      "step": 76830
    },
    {
      "epoch": 9.257831325301204,
      "grad_norm": 0.0002562811423558742,
      "learning_rate": 1.4843373493975905e-06,
      "loss": 0.0074,
      "step": 76840
    },
    {
      "epoch": 9.259036144578314,
      "grad_norm": 0.006472915410995483,
      "learning_rate": 1.4819277108433736e-06,
      "loss": 0.0185,
      "step": 76850
    },
    {
      "epoch": 9.260240963855422,
      "grad_norm": 0.8158155083656311,
      "learning_rate": 1.4795180722891566e-06,
      "loss": 0.0239,
      "step": 76860
    },
    {
      "epoch": 9.26144578313253,
      "grad_norm": 2.2042226791381836,
      "learning_rate": 1.4771084337349398e-06,
      "loss": 0.0195,
      "step": 76870
    },
    {
      "epoch": 9.26265060240964,
      "grad_norm": 0.004517636727541685,
      "learning_rate": 1.474698795180723e-06,
      "loss": 0.0341,
      "step": 76880
    },
    {
      "epoch": 9.263855421686747,
      "grad_norm": 1.099724292755127,
      "learning_rate": 1.472289156626506e-06,
      "loss": 0.0043,
      "step": 76890
    },
    {
      "epoch": 9.265060240963855,
      "grad_norm": 0.07258390635251999,
      "learning_rate": 1.4698795180722893e-06,
      "loss": 0.0158,
      "step": 76900
    },
    {
      "epoch": 9.266265060240963,
      "grad_norm": 0.8704895377159119,
      "learning_rate": 1.4674698795180725e-06,
      "loss": 0.0066,
      "step": 76910
    },
    {
      "epoch": 9.267469879518073,
      "grad_norm": 0.00025608387659303844,
      "learning_rate": 1.4650602409638557e-06,
      "loss": 0.0238,
      "step": 76920
    },
    {
      "epoch": 9.26867469879518,
      "grad_norm": 0.003295148489996791,
      "learning_rate": 1.4626506024096388e-06,
      "loss": 0.0033,
      "step": 76930
    },
    {
      "epoch": 9.269879518072289,
      "grad_norm": 0.25109168887138367,
      "learning_rate": 1.4602409638554218e-06,
      "loss": 0.0199,
      "step": 76940
    },
    {
      "epoch": 9.271084337349398,
      "grad_norm": 0.01748284511268139,
      "learning_rate": 1.457831325301205e-06,
      "loss": 0.0016,
      "step": 76950
    },
    {
      "epoch": 9.272289156626506,
      "grad_norm": 0.0006402709987014532,
      "learning_rate": 1.4554216867469882e-06,
      "loss": 0.02,
      "step": 76960
    },
    {
      "epoch": 9.273493975903614,
      "grad_norm": 0.002008453942835331,
      "learning_rate": 1.4530120481927711e-06,
      "loss": 0.0073,
      "step": 76970
    },
    {
      "epoch": 9.274698795180722,
      "grad_norm": 0.7475860714912415,
      "learning_rate": 1.4506024096385543e-06,
      "loss": 0.0374,
      "step": 76980
    },
    {
      "epoch": 9.275903614457832,
      "grad_norm": 0.23772457242012024,
      "learning_rate": 1.4481927710843375e-06,
      "loss": 0.0274,
      "step": 76990
    },
    {
      "epoch": 9.27710843373494,
      "grad_norm": 1.2305635213851929,
      "learning_rate": 1.4457831325301204e-06,
      "loss": 0.0031,
      "step": 77000
    },
    {
      "epoch": 9.278313253012048,
      "grad_norm": 0.3738197386264801,
      "learning_rate": 1.4433734939759036e-06,
      "loss": 0.0206,
      "step": 77010
    },
    {
      "epoch": 9.279518072289157,
      "grad_norm": 0.8677653670310974,
      "learning_rate": 1.4409638554216868e-06,
      "loss": 0.0257,
      "step": 77020
    },
    {
      "epoch": 9.280722891566265,
      "grad_norm": 0.3149377703666687,
      "learning_rate": 1.43855421686747e-06,
      "loss": 0.0025,
      "step": 77030
    },
    {
      "epoch": 9.281927710843373,
      "grad_norm": 0.21919064223766327,
      "learning_rate": 1.4361445783132534e-06,
      "loss": 0.0067,
      "step": 77040
    },
    {
      "epoch": 9.283132530120483,
      "grad_norm": 0.0006714920746162534,
      "learning_rate": 1.4337349397590363e-06,
      "loss": 0.0035,
      "step": 77050
    },
    {
      "epoch": 9.28433734939759,
      "grad_norm": 0.0005708137177862227,
      "learning_rate": 1.4313253012048195e-06,
      "loss": 0.0058,
      "step": 77060
    },
    {
      "epoch": 9.285542168674699,
      "grad_norm": 3.3983490467071533,
      "learning_rate": 1.4289156626506027e-06,
      "loss": 0.0243,
      "step": 77070
    },
    {
      "epoch": 9.286746987951807,
      "grad_norm": 0.0008307211101055145,
      "learning_rate": 1.4265060240963856e-06,
      "loss": 0.0183,
      "step": 77080
    },
    {
      "epoch": 9.287951807228916,
      "grad_norm": 0.013108749873936176,
      "learning_rate": 1.4240963855421688e-06,
      "loss": 0.0108,
      "step": 77090
    },
    {
      "epoch": 9.289156626506024,
      "grad_norm": 0.20412886142730713,
      "learning_rate": 1.421686746987952e-06,
      "loss": 0.0278,
      "step": 77100
    },
    {
      "epoch": 9.290361445783132,
      "grad_norm": 0.17630566656589508,
      "learning_rate": 1.4192771084337352e-06,
      "loss": 0.0409,
      "step": 77110
    },
    {
      "epoch": 9.291566265060242,
      "grad_norm": 0.0007024866063147783,
      "learning_rate": 1.4168674698795181e-06,
      "loss": 0.0106,
      "step": 77120
    },
    {
      "epoch": 9.29277108433735,
      "grad_norm": 0.0009665197576396167,
      "learning_rate": 1.4144578313253013e-06,
      "loss": 0.0067,
      "step": 77130
    },
    {
      "epoch": 9.293975903614458,
      "grad_norm": 0.0002711576235014945,
      "learning_rate": 1.4120481927710845e-06,
      "loss": 0.0121,
      "step": 77140
    },
    {
      "epoch": 9.295180722891565,
      "grad_norm": 0.00040897668804973364,
      "learning_rate": 1.4096385542168674e-06,
      "loss": 0.0162,
      "step": 77150
    },
    {
      "epoch": 9.296385542168675,
      "grad_norm": 0.0006024642498232424,
      "learning_rate": 1.4072289156626506e-06,
      "loss": 0.0059,
      "step": 77160
    },
    {
      "epoch": 9.297590361445783,
      "grad_norm": 0.0004911426804028451,
      "learning_rate": 1.4048192771084338e-06,
      "loss": 0.0238,
      "step": 77170
    },
    {
      "epoch": 9.298795180722891,
      "grad_norm": 0.0003506364591885358,
      "learning_rate": 1.4024096385542168e-06,
      "loss": 0.0194,
      "step": 77180
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.5971023440361023,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.0184,
      "step": 77190
    },
    {
      "epoch": 9.301204819277109,
      "grad_norm": 0.01562521606683731,
      "learning_rate": 1.3975903614457833e-06,
      "loss": 0.0241,
      "step": 77200
    },
    {
      "epoch": 9.302409638554217,
      "grad_norm": 0.0005343059310689569,
      "learning_rate": 1.3951807228915665e-06,
      "loss": 0.0029,
      "step": 77210
    },
    {
      "epoch": 9.303614457831324,
      "grad_norm": 0.0010233588982373476,
      "learning_rate": 1.3927710843373497e-06,
      "loss": 0.0085,
      "step": 77220
    },
    {
      "epoch": 9.304819277108434,
      "grad_norm": 1.2926002740859985,
      "learning_rate": 1.3903614457831326e-06,
      "loss": 0.0061,
      "step": 77230
    },
    {
      "epoch": 9.306024096385542,
      "grad_norm": 0.000590712355915457,
      "learning_rate": 1.3879518072289158e-06,
      "loss": 0.0215,
      "step": 77240
    },
    {
      "epoch": 9.30722891566265,
      "grad_norm": 0.3662763237953186,
      "learning_rate": 1.385542168674699e-06,
      "loss": 0.0194,
      "step": 77250
    },
    {
      "epoch": 9.30843373493976,
      "grad_norm": 0.0004550076264422387,
      "learning_rate": 1.383132530120482e-06,
      "loss": 0.0106,
      "step": 77260
    },
    {
      "epoch": 9.309638554216868,
      "grad_norm": 0.0009373261127620935,
      "learning_rate": 1.3807228915662651e-06,
      "loss": 0.0106,
      "step": 77270
    },
    {
      "epoch": 9.310843373493976,
      "grad_norm": 0.15468022227287292,
      "learning_rate": 1.3783132530120483e-06,
      "loss": 0.0101,
      "step": 77280
    },
    {
      "epoch": 9.312048192771085,
      "grad_norm": 0.002395389601588249,
      "learning_rate": 1.3759036144578315e-06,
      "loss": 0.0066,
      "step": 77290
    },
    {
      "epoch": 9.313253012048193,
      "grad_norm": 0.0007985527627170086,
      "learning_rate": 1.3734939759036144e-06,
      "loss": 0.0044,
      "step": 77300
    },
    {
      "epoch": 9.314457831325301,
      "grad_norm": 0.0008600529981777072,
      "learning_rate": 1.3710843373493976e-06,
      "loss": 0.0007,
      "step": 77310
    },
    {
      "epoch": 9.315662650602409,
      "grad_norm": 0.0004689438792411238,
      "learning_rate": 1.3686746987951808e-06,
      "loss": 0.0118,
      "step": 77320
    },
    {
      "epoch": 9.316867469879519,
      "grad_norm": 0.25669246912002563,
      "learning_rate": 1.3662650602409638e-06,
      "loss": 0.0109,
      "step": 77330
    },
    {
      "epoch": 9.318072289156627,
      "grad_norm": 0.00047651887871325016,
      "learning_rate": 1.3638554216867472e-06,
      "loss": 0.001,
      "step": 77340
    },
    {
      "epoch": 9.319277108433734,
      "grad_norm": 0.0015649832785129547,
      "learning_rate": 1.3614457831325303e-06,
      "loss": 0.0173,
      "step": 77350
    },
    {
      "epoch": 9.320481927710844,
      "grad_norm": 0.002004827605560422,
      "learning_rate": 1.3590361445783135e-06,
      "loss": 0.0104,
      "step": 77360
    },
    {
      "epoch": 9.321686746987952,
      "grad_norm": 0.010391422547399998,
      "learning_rate": 1.3566265060240965e-06,
      "loss": 0.0063,
      "step": 77370
    },
    {
      "epoch": 9.32289156626506,
      "grad_norm": 0.36565297842025757,
      "learning_rate": 1.3542168674698796e-06,
      "loss": 0.0067,
      "step": 77380
    },
    {
      "epoch": 9.324096385542168,
      "grad_norm": 0.00035478733479976654,
      "learning_rate": 1.3518072289156628e-06,
      "loss": 0.0266,
      "step": 77390
    },
    {
      "epoch": 9.325301204819278,
      "grad_norm": 0.00036027817986905575,
      "learning_rate": 1.349397590361446e-06,
      "loss": 0.0078,
      "step": 77400
    },
    {
      "epoch": 9.326506024096386,
      "grad_norm": 0.004440091550350189,
      "learning_rate": 1.346987951807229e-06,
      "loss": 0.0102,
      "step": 77410
    },
    {
      "epoch": 9.327710843373493,
      "grad_norm": 1.260878562927246,
      "learning_rate": 1.3445783132530121e-06,
      "loss": 0.0146,
      "step": 77420
    },
    {
      "epoch": 9.328915662650603,
      "grad_norm": 0.00024773224140517414,
      "learning_rate": 1.3421686746987953e-06,
      "loss": 0.0144,
      "step": 77430
    },
    {
      "epoch": 9.330120481927711,
      "grad_norm": 0.0017209475627169013,
      "learning_rate": 1.3397590361445783e-06,
      "loss": 0.0109,
      "step": 77440
    },
    {
      "epoch": 9.331325301204819,
      "grad_norm": 0.0009501002496108413,
      "learning_rate": 1.3373493975903615e-06,
      "loss": 0.0116,
      "step": 77450
    },
    {
      "epoch": 9.332530120481927,
      "grad_norm": 0.000744758581276983,
      "learning_rate": 1.3349397590361446e-06,
      "loss": 0.0091,
      "step": 77460
    },
    {
      "epoch": 9.333734939759037,
      "grad_norm": 0.0007083238451741636,
      "learning_rate": 1.3325301204819278e-06,
      "loss": 0.0131,
      "step": 77470
    },
    {
      "epoch": 9.334939759036144,
      "grad_norm": 0.0002431778993923217,
      "learning_rate": 1.3301204819277108e-06,
      "loss": 0.0247,
      "step": 77480
    },
    {
      "epoch": 9.336144578313252,
      "grad_norm": 1.4095462560653687,
      "learning_rate": 1.3277108433734942e-06,
      "loss": 0.0221,
      "step": 77490
    },
    {
      "epoch": 9.337349397590362,
      "grad_norm": 0.00035968213342130184,
      "learning_rate": 1.3253012048192773e-06,
      "loss": 0.0055,
      "step": 77500
    },
    {
      "epoch": 9.33855421686747,
      "grad_norm": 0.0028281479608267546,
      "learning_rate": 1.3228915662650605e-06,
      "loss": 0.0011,
      "step": 77510
    },
    {
      "epoch": 9.339759036144578,
      "grad_norm": 0.00036894119693897665,
      "learning_rate": 1.3204819277108435e-06,
      "loss": 0.0198,
      "step": 77520
    },
    {
      "epoch": 9.340963855421688,
      "grad_norm": 0.11093340069055557,
      "learning_rate": 1.3180722891566267e-06,
      "loss": 0.0032,
      "step": 77530
    },
    {
      "epoch": 9.342168674698796,
      "grad_norm": 0.000525628449395299,
      "learning_rate": 1.3156626506024098e-06,
      "loss": 0.0042,
      "step": 77540
    },
    {
      "epoch": 9.343373493975903,
      "grad_norm": 0.0020825706887990236,
      "learning_rate": 1.3132530120481928e-06,
      "loss": 0.0124,
      "step": 77550
    },
    {
      "epoch": 9.344578313253011,
      "grad_norm": 0.00032667568302713335,
      "learning_rate": 1.310843373493976e-06,
      "loss": 0.0124,
      "step": 77560
    },
    {
      "epoch": 9.345783132530121,
      "grad_norm": 0.0009310059831477702,
      "learning_rate": 1.3084337349397591e-06,
      "loss": 0.0047,
      "step": 77570
    },
    {
      "epoch": 9.346987951807229,
      "grad_norm": 0.0006394367665052414,
      "learning_rate": 1.3060240963855423e-06,
      "loss": 0.0108,
      "step": 77580
    },
    {
      "epoch": 9.348192771084337,
      "grad_norm": 0.33966344594955444,
      "learning_rate": 1.3036144578313253e-06,
      "loss": 0.0105,
      "step": 77590
    },
    {
      "epoch": 9.349397590361447,
      "grad_norm": 0.0009548233356326818,
      "learning_rate": 1.3012048192771085e-06,
      "loss": 0.0568,
      "step": 77600
    },
    {
      "epoch": 9.350602409638554,
      "grad_norm": 0.0005083666183054447,
      "learning_rate": 1.2987951807228916e-06,
      "loss": 0.0081,
      "step": 77610
    },
    {
      "epoch": 9.351807228915662,
      "grad_norm": 0.0007532789022661746,
      "learning_rate": 1.2963855421686746e-06,
      "loss": 0.0032,
      "step": 77620
    },
    {
      "epoch": 9.35301204819277,
      "grad_norm": 2.096773386001587,
      "learning_rate": 1.293975903614458e-06,
      "loss": 0.0357,
      "step": 77630
    },
    {
      "epoch": 9.35421686746988,
      "grad_norm": 1.2664669752120972,
      "learning_rate": 1.2915662650602412e-06,
      "loss": 0.0234,
      "step": 77640
    },
    {
      "epoch": 9.355421686746988,
      "grad_norm": 0.0008968036854639649,
      "learning_rate": 1.2891566265060243e-06,
      "loss": 0.0168,
      "step": 77650
    },
    {
      "epoch": 9.356626506024096,
      "grad_norm": 0.20101697742938995,
      "learning_rate": 1.2867469879518075e-06,
      "loss": 0.0167,
      "step": 77660
    },
    {
      "epoch": 9.357831325301206,
      "grad_norm": 0.001258533331565559,
      "learning_rate": 1.2843373493975905e-06,
      "loss": 0.0369,
      "step": 77670
    },
    {
      "epoch": 9.359036144578313,
      "grad_norm": 0.0007641088450327516,
      "learning_rate": 1.2819277108433737e-06,
      "loss": 0.0025,
      "step": 77680
    },
    {
      "epoch": 9.360240963855421,
      "grad_norm": 0.0012310190359130502,
      "learning_rate": 1.2795180722891568e-06,
      "loss": 0.0239,
      "step": 77690
    },
    {
      "epoch": 9.36144578313253,
      "grad_norm": 0.0710424855351448,
      "learning_rate": 1.2771084337349398e-06,
      "loss": 0.0137,
      "step": 77700
    },
    {
      "epoch": 9.362650602409639,
      "grad_norm": 0.0014390322612598538,
      "learning_rate": 1.274698795180723e-06,
      "loss": 0.0096,
      "step": 77710
    },
    {
      "epoch": 9.363855421686747,
      "grad_norm": 0.0003364357689861208,
      "learning_rate": 1.2722891566265061e-06,
      "loss": 0.0235,
      "step": 77720
    },
    {
      "epoch": 9.365060240963855,
      "grad_norm": 0.033506132662296295,
      "learning_rate": 1.2698795180722891e-06,
      "loss": 0.015,
      "step": 77730
    },
    {
      "epoch": 9.366265060240965,
      "grad_norm": 0.0022042328491806984,
      "learning_rate": 1.2674698795180723e-06,
      "loss": 0.0238,
      "step": 77740
    },
    {
      "epoch": 9.367469879518072,
      "grad_norm": 1.6110783815383911,
      "learning_rate": 1.2650602409638555e-06,
      "loss": 0.0144,
      "step": 77750
    },
    {
      "epoch": 9.36867469879518,
      "grad_norm": 0.29620057344436646,
      "learning_rate": 1.2626506024096386e-06,
      "loss": 0.0079,
      "step": 77760
    },
    {
      "epoch": 9.369879518072288,
      "grad_norm": 0.00026406682445667684,
      "learning_rate": 1.2602409638554216e-06,
      "loss": 0.0092,
      "step": 77770
    },
    {
      "epoch": 9.371084337349398,
      "grad_norm": 1.382826328277588,
      "learning_rate": 1.257831325301205e-06,
      "loss": 0.0042,
      "step": 77780
    },
    {
      "epoch": 9.372289156626506,
      "grad_norm": 0.00041491255979053676,
      "learning_rate": 1.2554216867469882e-06,
      "loss": 0.035,
      "step": 77790
    },
    {
      "epoch": 9.373493975903614,
      "grad_norm": 1.3058592081069946,
      "learning_rate": 1.2530120481927713e-06,
      "loss": 0.0127,
      "step": 77800
    },
    {
      "epoch": 9.374698795180723,
      "grad_norm": 0.0015577239682897925,
      "learning_rate": 1.2506024096385543e-06,
      "loss": 0.0092,
      "step": 77810
    },
    {
      "epoch": 9.375903614457831,
      "grad_norm": 0.42822590470314026,
      "learning_rate": 1.2481927710843375e-06,
      "loss": 0.016,
      "step": 77820
    },
    {
      "epoch": 9.37710843373494,
      "grad_norm": 0.0013170819729566574,
      "learning_rate": 1.2457831325301207e-06,
      "loss": 0.0083,
      "step": 77830
    },
    {
      "epoch": 9.378313253012049,
      "grad_norm": 0.9169655442237854,
      "learning_rate": 1.2433734939759038e-06,
      "loss": 0.0163,
      "step": 77840
    },
    {
      "epoch": 9.379518072289157,
      "grad_norm": 0.0003364397562108934,
      "learning_rate": 1.2409638554216868e-06,
      "loss": 0.0077,
      "step": 77850
    },
    {
      "epoch": 9.380722891566265,
      "grad_norm": 0.0005032479530200362,
      "learning_rate": 1.23855421686747e-06,
      "loss": 0.0041,
      "step": 77860
    },
    {
      "epoch": 9.381927710843373,
      "grad_norm": 1.4451658725738525,
      "learning_rate": 1.2361445783132532e-06,
      "loss": 0.007,
      "step": 77870
    },
    {
      "epoch": 9.383132530120482,
      "grad_norm": 0.2758300006389618,
      "learning_rate": 1.2337349397590361e-06,
      "loss": 0.0023,
      "step": 77880
    },
    {
      "epoch": 9.38433734939759,
      "grad_norm": 1.4970464706420898,
      "learning_rate": 1.2313253012048195e-06,
      "loss": 0.016,
      "step": 77890
    },
    {
      "epoch": 9.385542168674698,
      "grad_norm": 0.000594671699218452,
      "learning_rate": 1.2289156626506025e-06,
      "loss": 0.0053,
      "step": 77900
    },
    {
      "epoch": 9.386746987951808,
      "grad_norm": 0.0014367218827828765,
      "learning_rate": 1.2265060240963856e-06,
      "loss": 0.0065,
      "step": 77910
    },
    {
      "epoch": 9.387951807228916,
      "grad_norm": 0.1797262579202652,
      "learning_rate": 1.2240963855421688e-06,
      "loss": 0.0074,
      "step": 77920
    },
    {
      "epoch": 9.389156626506024,
      "grad_norm": 0.7404875159263611,
      "learning_rate": 1.221686746987952e-06,
      "loss": 0.0026,
      "step": 77930
    },
    {
      "epoch": 9.390361445783132,
      "grad_norm": 0.021311277523636818,
      "learning_rate": 1.219277108433735e-06,
      "loss": 0.0034,
      "step": 77940
    },
    {
      "epoch": 9.391566265060241,
      "grad_norm": 0.0002938922552857548,
      "learning_rate": 1.2168674698795181e-06,
      "loss": 0.0055,
      "step": 77950
    },
    {
      "epoch": 9.39277108433735,
      "grad_norm": 0.0004963018000125885,
      "learning_rate": 1.2144578313253013e-06,
      "loss": 0.0018,
      "step": 77960
    },
    {
      "epoch": 9.393975903614457,
      "grad_norm": 0.8493528962135315,
      "learning_rate": 1.2120481927710845e-06,
      "loss": 0.0097,
      "step": 77970
    },
    {
      "epoch": 9.395180722891567,
      "grad_norm": 2.1528866291046143,
      "learning_rate": 1.2096385542168677e-06,
      "loss": 0.0332,
      "step": 77980
    },
    {
      "epoch": 9.396385542168675,
      "grad_norm": 2.0995235443115234,
      "learning_rate": 1.2072289156626506e-06,
      "loss": 0.0346,
      "step": 77990
    },
    {
      "epoch": 9.397590361445783,
      "grad_norm": 0.001625867560505867,
      "learning_rate": 1.2048192771084338e-06,
      "loss": 0.027,
      "step": 78000
    },
    {
      "epoch": 9.398795180722892,
      "grad_norm": 0.0004583285772241652,
      "learning_rate": 1.202409638554217e-06,
      "loss": 0.0015,
      "step": 78010
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.9557121992111206,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0125,
      "step": 78020
    },
    {
      "epoch": 9.401204819277108,
      "grad_norm": 0.378485769033432,
      "learning_rate": 1.1975903614457831e-06,
      "loss": 0.0108,
      "step": 78030
    },
    {
      "epoch": 9.402409638554216,
      "grad_norm": 0.0013756109401583672,
      "learning_rate": 1.1951807228915665e-06,
      "loss": 0.0128,
      "step": 78040
    },
    {
      "epoch": 9.403614457831326,
      "grad_norm": 0.709650993347168,
      "learning_rate": 1.1927710843373495e-06,
      "loss": 0.0151,
      "step": 78050
    },
    {
      "epoch": 9.404819277108434,
      "grad_norm": 0.004426573868840933,
      "learning_rate": 1.1903614457831326e-06,
      "loss": 0.0144,
      "step": 78060
    },
    {
      "epoch": 9.406024096385542,
      "grad_norm": 0.8580555319786072,
      "learning_rate": 1.1879518072289158e-06,
      "loss": 0.0021,
      "step": 78070
    },
    {
      "epoch": 9.407228915662651,
      "grad_norm": 2.2847647666931152,
      "learning_rate": 1.1855421686746988e-06,
      "loss": 0.0074,
      "step": 78080
    },
    {
      "epoch": 9.40843373493976,
      "grad_norm": 0.0001868328545242548,
      "learning_rate": 1.183132530120482e-06,
      "loss": 0.0158,
      "step": 78090
    },
    {
      "epoch": 9.409638554216867,
      "grad_norm": 0.5364336967468262,
      "learning_rate": 1.1807228915662651e-06,
      "loss": 0.0218,
      "step": 78100
    },
    {
      "epoch": 9.410843373493975,
      "grad_norm": 0.0009547229274176061,
      "learning_rate": 1.1783132530120483e-06,
      "loss": 0.0091,
      "step": 78110
    },
    {
      "epoch": 9.412048192771085,
      "grad_norm": 0.388482004404068,
      "learning_rate": 1.1759036144578315e-06,
      "loss": 0.006,
      "step": 78120
    },
    {
      "epoch": 9.413253012048193,
      "grad_norm": 5.450460433959961,
      "learning_rate": 1.1734939759036147e-06,
      "loss": 0.0339,
      "step": 78130
    },
    {
      "epoch": 9.4144578313253,
      "grad_norm": 0.3506109118461609,
      "learning_rate": 1.1710843373493976e-06,
      "loss": 0.0019,
      "step": 78140
    },
    {
      "epoch": 9.41566265060241,
      "grad_norm": 0.000659820856526494,
      "learning_rate": 1.1686746987951808e-06,
      "loss": 0.0214,
      "step": 78150
    },
    {
      "epoch": 9.416867469879518,
      "grad_norm": 0.1656695157289505,
      "learning_rate": 1.166265060240964e-06,
      "loss": 0.0088,
      "step": 78160
    },
    {
      "epoch": 9.418072289156626,
      "grad_norm": 0.011229378171265125,
      "learning_rate": 1.163855421686747e-06,
      "loss": 0.0026,
      "step": 78170
    },
    {
      "epoch": 9.419277108433734,
      "grad_norm": 0.0004767423088196665,
      "learning_rate": 1.1614457831325301e-06,
      "loss": 0.0143,
      "step": 78180
    },
    {
      "epoch": 9.420481927710844,
      "grad_norm": 0.008054397068917751,
      "learning_rate": 1.1590361445783133e-06,
      "loss": 0.0071,
      "step": 78190
    },
    {
      "epoch": 9.421686746987952,
      "grad_norm": 0.006473139859735966,
      "learning_rate": 1.1566265060240965e-06,
      "loss": 0.0113,
      "step": 78200
    },
    {
      "epoch": 9.42289156626506,
      "grad_norm": 10.185766220092773,
      "learning_rate": 1.1542168674698797e-06,
      "loss": 0.0173,
      "step": 78210
    },
    {
      "epoch": 9.42409638554217,
      "grad_norm": 0.0002856173668988049,
      "learning_rate": 1.1518072289156628e-06,
      "loss": 0.0133,
      "step": 78220
    },
    {
      "epoch": 9.425301204819277,
      "grad_norm": 0.0007670506602153182,
      "learning_rate": 1.1493975903614458e-06,
      "loss": 0.004,
      "step": 78230
    },
    {
      "epoch": 9.426506024096385,
      "grad_norm": 0.0007121208473108709,
      "learning_rate": 1.146987951807229e-06,
      "loss": 0.0067,
      "step": 78240
    },
    {
      "epoch": 9.427710843373493,
      "grad_norm": 0.5786865949630737,
      "learning_rate": 1.1445783132530121e-06,
      "loss": 0.0291,
      "step": 78250
    },
    {
      "epoch": 9.428915662650603,
      "grad_norm": 0.008441104553639889,
      "learning_rate": 1.1421686746987953e-06,
      "loss": 0.0092,
      "step": 78260
    },
    {
      "epoch": 9.43012048192771,
      "grad_norm": 2.5380094051361084,
      "learning_rate": 1.1397590361445785e-06,
      "loss": 0.0235,
      "step": 78270
    },
    {
      "epoch": 9.431325301204819,
      "grad_norm": 0.4306202530860901,
      "learning_rate": 1.1373493975903615e-06,
      "loss": 0.0126,
      "step": 78280
    },
    {
      "epoch": 9.432530120481928,
      "grad_norm": 0.1773778349161148,
      "learning_rate": 1.1349397590361446e-06,
      "loss": 0.0269,
      "step": 78290
    },
    {
      "epoch": 9.433734939759036,
      "grad_norm": 0.0005192176322452724,
      "learning_rate": 1.1325301204819278e-06,
      "loss": 0.023,
      "step": 78300
    },
    {
      "epoch": 9.434939759036144,
      "grad_norm": 3.6387717723846436,
      "learning_rate": 1.130120481927711e-06,
      "loss": 0.0162,
      "step": 78310
    },
    {
      "epoch": 9.436144578313254,
      "grad_norm": 0.0002208542136941105,
      "learning_rate": 1.127710843373494e-06,
      "loss": 0.0082,
      "step": 78320
    },
    {
      "epoch": 9.437349397590362,
      "grad_norm": 0.0004117194621358067,
      "learning_rate": 1.1253012048192773e-06,
      "loss": 0.0199,
      "step": 78330
    },
    {
      "epoch": 9.43855421686747,
      "grad_norm": 0.31958699226379395,
      "learning_rate": 1.1228915662650603e-06,
      "loss": 0.0047,
      "step": 78340
    },
    {
      "epoch": 9.439759036144578,
      "grad_norm": 3.162959098815918,
      "learning_rate": 1.1204819277108435e-06,
      "loss": 0.0259,
      "step": 78350
    },
    {
      "epoch": 9.440963855421687,
      "grad_norm": 1.1184971332550049,
      "learning_rate": 1.1180722891566267e-06,
      "loss": 0.0075,
      "step": 78360
    },
    {
      "epoch": 9.442168674698795,
      "grad_norm": 0.0003478366124909371,
      "learning_rate": 1.1156626506024096e-06,
      "loss": 0.0209,
      "step": 78370
    },
    {
      "epoch": 9.443373493975903,
      "grad_norm": 0.9300349950790405,
      "learning_rate": 1.1132530120481928e-06,
      "loss": 0.0267,
      "step": 78380
    },
    {
      "epoch": 9.444578313253013,
      "grad_norm": 0.0004358740116003901,
      "learning_rate": 1.110843373493976e-06,
      "loss": 0.0377,
      "step": 78390
    },
    {
      "epoch": 9.44578313253012,
      "grad_norm": 2.6473793983459473,
      "learning_rate": 1.1084337349397592e-06,
      "loss": 0.0017,
      "step": 78400
    },
    {
      "epoch": 9.446987951807229,
      "grad_norm": 0.0001675448875175789,
      "learning_rate": 1.1060240963855423e-06,
      "loss": 0.0121,
      "step": 78410
    },
    {
      "epoch": 9.448192771084337,
      "grad_norm": 1.6739869117736816,
      "learning_rate": 1.1036144578313255e-06,
      "loss": 0.0205,
      "step": 78420
    },
    {
      "epoch": 9.449397590361446,
      "grad_norm": 2.519843816757202,
      "learning_rate": 1.1012048192771085e-06,
      "loss": 0.0327,
      "step": 78430
    },
    {
      "epoch": 9.450602409638554,
      "grad_norm": 0.0003705806448124349,
      "learning_rate": 1.0987951807228916e-06,
      "loss": 0.0078,
      "step": 78440
    },
    {
      "epoch": 9.451807228915662,
      "grad_norm": 1.1833481788635254,
      "learning_rate": 1.0963855421686748e-06,
      "loss": 0.0175,
      "step": 78450
    },
    {
      "epoch": 9.453012048192772,
      "grad_norm": 0.008430415764451027,
      "learning_rate": 1.0939759036144578e-06,
      "loss": 0.0001,
      "step": 78460
    },
    {
      "epoch": 9.45421686746988,
      "grad_norm": 0.00044494259054772556,
      "learning_rate": 1.091566265060241e-06,
      "loss": 0.014,
      "step": 78470
    },
    {
      "epoch": 9.455421686746988,
      "grad_norm": 0.0007118381327018142,
      "learning_rate": 1.0891566265060243e-06,
      "loss": 0.0005,
      "step": 78480
    },
    {
      "epoch": 9.456626506024097,
      "grad_norm": 0.007704892661422491,
      "learning_rate": 1.0867469879518073e-06,
      "loss": 0.0121,
      "step": 78490
    },
    {
      "epoch": 9.457831325301205,
      "grad_norm": 0.0010851109400391579,
      "learning_rate": 1.0843373493975905e-06,
      "loss": 0.0026,
      "step": 78500
    },
    {
      "epoch": 9.459036144578313,
      "grad_norm": 0.0003730302560143173,
      "learning_rate": 1.0819277108433737e-06,
      "loss": 0.0119,
      "step": 78510
    },
    {
      "epoch": 9.460240963855421,
      "grad_norm": 0.011155846528708935,
      "learning_rate": 1.0795180722891566e-06,
      "loss": 0.0089,
      "step": 78520
    },
    {
      "epoch": 9.46144578313253,
      "grad_norm": 2.525038719177246,
      "learning_rate": 1.0771084337349398e-06,
      "loss": 0.0147,
      "step": 78530
    },
    {
      "epoch": 9.462650602409639,
      "grad_norm": 0.00094308250118047,
      "learning_rate": 1.074698795180723e-06,
      "loss": 0.0273,
      "step": 78540
    },
    {
      "epoch": 9.463855421686747,
      "grad_norm": 4.685944080352783,
      "learning_rate": 1.0722891566265062e-06,
      "loss": 0.0035,
      "step": 78550
    },
    {
      "epoch": 9.465060240963856,
      "grad_norm": 0.0003110510588157922,
      "learning_rate": 1.0698795180722893e-06,
      "loss": 0.0155,
      "step": 78560
    },
    {
      "epoch": 9.466265060240964,
      "grad_norm": 0.00016398417938034981,
      "learning_rate": 1.0674698795180725e-06,
      "loss": 0.0124,
      "step": 78570
    },
    {
      "epoch": 9.467469879518072,
      "grad_norm": 2.411992073059082,
      "learning_rate": 1.0650602409638555e-06,
      "loss": 0.0224,
      "step": 78580
    },
    {
      "epoch": 9.46867469879518,
      "grad_norm": 0.0035424507223069668,
      "learning_rate": 1.0626506024096386e-06,
      "loss": 0.0051,
      "step": 78590
    },
    {
      "epoch": 9.46987951807229,
      "grad_norm": 1.8728986978530884,
      "learning_rate": 1.0602409638554218e-06,
      "loss": 0.0219,
      "step": 78600
    },
    {
      "epoch": 9.471084337349398,
      "grad_norm": 0.005911715794354677,
      "learning_rate": 1.0578313253012048e-06,
      "loss": 0.0125,
      "step": 78610
    },
    {
      "epoch": 9.472289156626506,
      "grad_norm": 0.0002476875961292535,
      "learning_rate": 1.055421686746988e-06,
      "loss": 0.0034,
      "step": 78620
    },
    {
      "epoch": 9.473493975903615,
      "grad_norm": 0.0005366883124224842,
      "learning_rate": 1.0530120481927711e-06,
      "loss": 0.0074,
      "step": 78630
    },
    {
      "epoch": 9.474698795180723,
      "grad_norm": 0.0009344904101453722,
      "learning_rate": 1.0506024096385543e-06,
      "loss": 0.0036,
      "step": 78640
    },
    {
      "epoch": 9.475903614457831,
      "grad_norm": 0.00048662401968613267,
      "learning_rate": 1.0481927710843375e-06,
      "loss": 0.0176,
      "step": 78650
    },
    {
      "epoch": 9.477108433734939,
      "grad_norm": 0.0025791244115680456,
      "learning_rate": 1.0457831325301207e-06,
      "loss": 0.021,
      "step": 78660
    },
    {
      "epoch": 9.478313253012049,
      "grad_norm": 0.00021417201787699014,
      "learning_rate": 1.0433734939759036e-06,
      "loss": 0.0055,
      "step": 78670
    },
    {
      "epoch": 9.479518072289157,
      "grad_norm": 0.0002577232080511749,
      "learning_rate": 1.0409638554216868e-06,
      "loss": 0.0208,
      "step": 78680
    },
    {
      "epoch": 9.480722891566264,
      "grad_norm": 1.687180995941162,
      "learning_rate": 1.03855421686747e-06,
      "loss": 0.0064,
      "step": 78690
    },
    {
      "epoch": 9.481927710843374,
      "grad_norm": 2.4828882217407227,
      "learning_rate": 1.0361445783132532e-06,
      "loss": 0.0205,
      "step": 78700
    },
    {
      "epoch": 9.483132530120482,
      "grad_norm": 0.006686709821224213,
      "learning_rate": 1.0337349397590363e-06,
      "loss": 0.0082,
      "step": 78710
    },
    {
      "epoch": 9.48433734939759,
      "grad_norm": 1.8449496030807495,
      "learning_rate": 1.0313253012048193e-06,
      "loss": 0.0165,
      "step": 78720
    },
    {
      "epoch": 9.485542168674698,
      "grad_norm": 1.322802186012268,
      "learning_rate": 1.0289156626506025e-06,
      "loss": 0.0265,
      "step": 78730
    },
    {
      "epoch": 9.486746987951808,
      "grad_norm": 0.00045209843665361404,
      "learning_rate": 1.0265060240963857e-06,
      "loss": 0.0115,
      "step": 78740
    },
    {
      "epoch": 9.487951807228916,
      "grad_norm": 0.00039518464473076165,
      "learning_rate": 1.0240963855421688e-06,
      "loss": 0.0141,
      "step": 78750
    },
    {
      "epoch": 9.489156626506023,
      "grad_norm": 0.0004832180857192725,
      "learning_rate": 1.0216867469879518e-06,
      "loss": 0.0125,
      "step": 78760
    },
    {
      "epoch": 9.490361445783133,
      "grad_norm": 0.09534097462892532,
      "learning_rate": 1.0192771084337352e-06,
      "loss": 0.0154,
      "step": 78770
    },
    {
      "epoch": 9.491566265060241,
      "grad_norm": 0.007253865245729685,
      "learning_rate": 1.0168674698795181e-06,
      "loss": 0.0192,
      "step": 78780
    },
    {
      "epoch": 9.492771084337349,
      "grad_norm": 0.14235487580299377,
      "learning_rate": 1.0144578313253013e-06,
      "loss": 0.0066,
      "step": 78790
    },
    {
      "epoch": 9.493975903614459,
      "grad_norm": 0.0007177467923611403,
      "learning_rate": 1.0120481927710845e-06,
      "loss": 0.0036,
      "step": 78800
    },
    {
      "epoch": 9.495180722891567,
      "grad_norm": 0.005126478616148233,
      "learning_rate": 1.0096385542168675e-06,
      "loss": 0.0075,
      "step": 78810
    },
    {
      "epoch": 9.496385542168674,
      "grad_norm": 0.00031258189119398594,
      "learning_rate": 1.0072289156626506e-06,
      "loss": 0.0208,
      "step": 78820
    },
    {
      "epoch": 9.497590361445782,
      "grad_norm": 2.5012283325195312,
      "learning_rate": 1.0048192771084338e-06,
      "loss": 0.0284,
      "step": 78830
    },
    {
      "epoch": 9.498795180722892,
      "grad_norm": 0.0003511738032102585,
      "learning_rate": 1.002409638554217e-06,
      "loss": 0.0077,
      "step": 78840
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.01111381035298109,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0063,
      "step": 78850
    },
    {
      "epoch": 9.501204819277108,
      "grad_norm": 0.8772047162055969,
      "learning_rate": 9.975903614457833e-07,
      "loss": 0.015,
      "step": 78860
    },
    {
      "epoch": 9.502409638554218,
      "grad_norm": 0.2411452680826187,
      "learning_rate": 9.951807228915663e-07,
      "loss": 0.0051,
      "step": 78870
    },
    {
      "epoch": 9.503614457831326,
      "grad_norm": 0.9185097813606262,
      "learning_rate": 9.927710843373495e-07,
      "loss": 0.0059,
      "step": 78880
    },
    {
      "epoch": 9.504819277108433,
      "grad_norm": 0.0005631744861602783,
      "learning_rate": 9.903614457831327e-07,
      "loss": 0.0014,
      "step": 78890
    },
    {
      "epoch": 9.506024096385541,
      "grad_norm": 0.0007656963425688446,
      "learning_rate": 9.879518072289156e-07,
      "loss": 0.0253,
      "step": 78900
    },
    {
      "epoch": 9.507228915662651,
      "grad_norm": 0.00048207491636276245,
      "learning_rate": 9.855421686746988e-07,
      "loss": 0.0152,
      "step": 78910
    },
    {
      "epoch": 9.508433734939759,
      "grad_norm": 0.0004047795955557376,
      "learning_rate": 9.83132530120482e-07,
      "loss": 0.0235,
      "step": 78920
    },
    {
      "epoch": 9.509638554216867,
      "grad_norm": 0.8275308012962341,
      "learning_rate": 9.807228915662652e-07,
      "loss": 0.0044,
      "step": 78930
    },
    {
      "epoch": 9.510843373493977,
      "grad_norm": 0.0005849666777066886,
      "learning_rate": 9.783132530120483e-07,
      "loss": 0.0068,
      "step": 78940
    },
    {
      "epoch": 9.512048192771084,
      "grad_norm": 0.0002946068125311285,
      "learning_rate": 9.759036144578315e-07,
      "loss": 0.0321,
      "step": 78950
    },
    {
      "epoch": 9.513253012048192,
      "grad_norm": 0.0005207095528021455,
      "learning_rate": 9.734939759036145e-07,
      "loss": 0.0111,
      "step": 78960
    },
    {
      "epoch": 9.514457831325302,
      "grad_norm": 0.00038763173506595194,
      "learning_rate": 9.710843373493976e-07,
      "loss": 0.0124,
      "step": 78970
    },
    {
      "epoch": 9.51566265060241,
      "grad_norm": 2.4315381050109863,
      "learning_rate": 9.686746987951808e-07,
      "loss": 0.0138,
      "step": 78980
    },
    {
      "epoch": 9.516867469879518,
      "grad_norm": 0.8970270156860352,
      "learning_rate": 9.66265060240964e-07,
      "loss": 0.015,
      "step": 78990
    },
    {
      "epoch": 9.518072289156626,
      "grad_norm": 0.005262812599539757,
      "learning_rate": 9.638554216867472e-07,
      "loss": 0.0256,
      "step": 79000
    },
    {
      "epoch": 9.519277108433736,
      "grad_norm": 0.00017504596326034516,
      "learning_rate": 9.614457831325301e-07,
      "loss": 0.0093,
      "step": 79010
    },
    {
      "epoch": 9.520481927710843,
      "grad_norm": 0.24801859259605408,
      "learning_rate": 9.590361445783133e-07,
      "loss": 0.012,
      "step": 79020
    },
    {
      "epoch": 9.521686746987951,
      "grad_norm": 2.9150819778442383,
      "learning_rate": 9.566265060240965e-07,
      "loss": 0.0089,
      "step": 79030
    },
    {
      "epoch": 9.522891566265061,
      "grad_norm": 0.00031875711283646524,
      "learning_rate": 9.542168674698797e-07,
      "loss": 0.0175,
      "step": 79040
    },
    {
      "epoch": 9.524096385542169,
      "grad_norm": 0.02299068681895733,
      "learning_rate": 9.518072289156627e-07,
      "loss": 0.0188,
      "step": 79050
    },
    {
      "epoch": 9.525301204819277,
      "grad_norm": 0.014148744754493237,
      "learning_rate": 9.493975903614458e-07,
      "loss": 0.0122,
      "step": 79060
    },
    {
      "epoch": 9.526506024096385,
      "grad_norm": 0.5229944586753845,
      "learning_rate": 9.469879518072291e-07,
      "loss": 0.0255,
      "step": 79070
    },
    {
      "epoch": 9.527710843373494,
      "grad_norm": 0.0006393421208485961,
      "learning_rate": 9.445783132530122e-07,
      "loss": 0.0224,
      "step": 79080
    },
    {
      "epoch": 9.528915662650602,
      "grad_norm": 2.2630085945129395,
      "learning_rate": 9.421686746987952e-07,
      "loss": 0.0198,
      "step": 79090
    },
    {
      "epoch": 9.53012048192771,
      "grad_norm": 2.2747769355773926,
      "learning_rate": 9.397590361445784e-07,
      "loss": 0.011,
      "step": 79100
    },
    {
      "epoch": 9.53132530120482,
      "grad_norm": 0.17903822660446167,
      "learning_rate": 9.373493975903615e-07,
      "loss": 0.0159,
      "step": 79110
    },
    {
      "epoch": 9.532530120481928,
      "grad_norm": 2.1582887172698975,
      "learning_rate": 9.349397590361446e-07,
      "loss": 0.0162,
      "step": 79120
    },
    {
      "epoch": 9.533734939759036,
      "grad_norm": 0.2920636236667633,
      "learning_rate": 9.325301204819277e-07,
      "loss": 0.0029,
      "step": 79130
    },
    {
      "epoch": 9.534939759036144,
      "grad_norm": 0.5532093644142151,
      "learning_rate": 9.30120481927711e-07,
      "loss": 0.0082,
      "step": 79140
    },
    {
      "epoch": 9.536144578313253,
      "grad_norm": 0.0018860509153455496,
      "learning_rate": 9.277108433734941e-07,
      "loss": 0.0045,
      "step": 79150
    },
    {
      "epoch": 9.537349397590361,
      "grad_norm": 0.00025323504814878106,
      "learning_rate": 9.253012048192772e-07,
      "loss": 0.0121,
      "step": 79160
    },
    {
      "epoch": 9.53855421686747,
      "grad_norm": 0.0002819676592480391,
      "learning_rate": 9.228915662650603e-07,
      "loss": 0.0085,
      "step": 79170
    },
    {
      "epoch": 9.539759036144579,
      "grad_norm": 1.1940274238586426,
      "learning_rate": 9.204819277108434e-07,
      "loss": 0.0163,
      "step": 79180
    },
    {
      "epoch": 9.540963855421687,
      "grad_norm": 0.00310803996399045,
      "learning_rate": 9.180722891566266e-07,
      "loss": 0.0032,
      "step": 79190
    },
    {
      "epoch": 9.542168674698795,
      "grad_norm": 0.00023266901553142816,
      "learning_rate": 9.156626506024096e-07,
      "loss": 0.0006,
      "step": 79200
    },
    {
      "epoch": 9.543373493975903,
      "grad_norm": 0.0004339468141552061,
      "learning_rate": 9.132530120481928e-07,
      "loss": 0.0179,
      "step": 79210
    },
    {
      "epoch": 9.544578313253012,
      "grad_norm": 0.0015289775328710675,
      "learning_rate": 9.10843373493976e-07,
      "loss": 0.0095,
      "step": 79220
    },
    {
      "epoch": 9.54578313253012,
      "grad_norm": 2.420320510864258,
      "learning_rate": 9.084337349397592e-07,
      "loss": 0.0117,
      "step": 79230
    },
    {
      "epoch": 9.546987951807228,
      "grad_norm": 1.7547835111618042,
      "learning_rate": 9.060240963855422e-07,
      "loss": 0.0193,
      "step": 79240
    },
    {
      "epoch": 9.548192771084338,
      "grad_norm": 0.19026115536689758,
      "learning_rate": 9.036144578313254e-07,
      "loss": 0.0133,
      "step": 79250
    },
    {
      "epoch": 9.549397590361446,
      "grad_norm": 0.0003004865429829806,
      "learning_rate": 9.012048192771085e-07,
      "loss": 0.0035,
      "step": 79260
    },
    {
      "epoch": 9.550602409638554,
      "grad_norm": 1.7379372119903564,
      "learning_rate": 8.987951807228915e-07,
      "loss": 0.0089,
      "step": 79270
    },
    {
      "epoch": 9.551807228915663,
      "grad_norm": 2.3966455459594727,
      "learning_rate": 8.963855421686747e-07,
      "loss": 0.0163,
      "step": 79280
    },
    {
      "epoch": 9.553012048192771,
      "grad_norm": 0.05756049603223801,
      "learning_rate": 8.93975903614458e-07,
      "loss": 0.002,
      "step": 79290
    },
    {
      "epoch": 9.55421686746988,
      "grad_norm": 0.000897450721822679,
      "learning_rate": 8.915662650602411e-07,
      "loss": 0.0054,
      "step": 79300
    },
    {
      "epoch": 9.555421686746987,
      "grad_norm": 0.0022460881154984236,
      "learning_rate": 8.891566265060241e-07,
      "loss": 0.0187,
      "step": 79310
    },
    {
      "epoch": 9.556626506024097,
      "grad_norm": 0.00036129876389168203,
      "learning_rate": 8.867469879518073e-07,
      "loss": 0.0261,
      "step": 79320
    },
    {
      "epoch": 9.557831325301205,
      "grad_norm": 0.00027799111558124423,
      "learning_rate": 8.843373493975904e-07,
      "loss": 0.0052,
      "step": 79330
    },
    {
      "epoch": 9.559036144578313,
      "grad_norm": 1.3101658821105957,
      "learning_rate": 8.819277108433736e-07,
      "loss": 0.0111,
      "step": 79340
    },
    {
      "epoch": 9.560240963855422,
      "grad_norm": 0.001953868195414543,
      "learning_rate": 8.795180722891566e-07,
      "loss": 0.0011,
      "step": 79350
    },
    {
      "epoch": 9.56144578313253,
      "grad_norm": 0.0067675416357815266,
      "learning_rate": 8.771084337349399e-07,
      "loss": 0.0061,
      "step": 79360
    },
    {
      "epoch": 9.562650602409638,
      "grad_norm": 0.002135644666850567,
      "learning_rate": 8.74698795180723e-07,
      "loss": 0.0091,
      "step": 79370
    },
    {
      "epoch": 9.563855421686746,
      "grad_norm": 2.7874271869659424,
      "learning_rate": 8.722891566265062e-07,
      "loss": 0.0209,
      "step": 79380
    },
    {
      "epoch": 9.565060240963856,
      "grad_norm": 0.0035778807941824198,
      "learning_rate": 8.698795180722892e-07,
      "loss": 0.0039,
      "step": 79390
    },
    {
      "epoch": 9.566265060240964,
      "grad_norm": 0.00030403572600334883,
      "learning_rate": 8.674698795180723e-07,
      "loss": 0.0449,
      "step": 79400
    },
    {
      "epoch": 9.567469879518072,
      "grad_norm": 0.0004589975578710437,
      "learning_rate": 8.650602409638555e-07,
      "loss": 0.0208,
      "step": 79410
    },
    {
      "epoch": 9.568674698795181,
      "grad_norm": 2.7842330932617188,
      "learning_rate": 8.626506024096386e-07,
      "loss": 0.0027,
      "step": 79420
    },
    {
      "epoch": 9.56987951807229,
      "grad_norm": 0.0021878511179238558,
      "learning_rate": 8.602409638554217e-07,
      "loss": 0.0001,
      "step": 79430
    },
    {
      "epoch": 9.571084337349397,
      "grad_norm": 0.0022312093060463667,
      "learning_rate": 8.578313253012049e-07,
      "loss": 0.0211,
      "step": 79440
    },
    {
      "epoch": 9.572289156626507,
      "grad_norm": 0.0003628361155278981,
      "learning_rate": 8.554216867469881e-07,
      "loss": 0.0147,
      "step": 79450
    },
    {
      "epoch": 9.573493975903615,
      "grad_norm": 2.6421079635620117,
      "learning_rate": 8.530120481927712e-07,
      "loss": 0.0221,
      "step": 79460
    },
    {
      "epoch": 9.574698795180723,
      "grad_norm": 1.645280361175537,
      "learning_rate": 8.506024096385543e-07,
      "loss": 0.0094,
      "step": 79470
    },
    {
      "epoch": 9.57590361445783,
      "grad_norm": 0.0003133727586828172,
      "learning_rate": 8.481927710843374e-07,
      "loss": 0.0232,
      "step": 79480
    },
    {
      "epoch": 9.57710843373494,
      "grad_norm": 0.3604651391506195,
      "learning_rate": 8.457831325301205e-07,
      "loss": 0.0249,
      "step": 79490
    },
    {
      "epoch": 9.578313253012048,
      "grad_norm": 0.0008486449951305985,
      "learning_rate": 8.433734939759036e-07,
      "loss": 0.0135,
      "step": 79500
    },
    {
      "epoch": 9.579518072289156,
      "grad_norm": 0.000292971235467121,
      "learning_rate": 8.409638554216869e-07,
      "loss": 0.0008,
      "step": 79510
    },
    {
      "epoch": 9.580722891566266,
      "grad_norm": 0.009729618206620216,
      "learning_rate": 8.3855421686747e-07,
      "loss": 0.0152,
      "step": 79520
    },
    {
      "epoch": 9.581927710843374,
      "grad_norm": 0.004416127223521471,
      "learning_rate": 8.361445783132531e-07,
      "loss": 0.0081,
      "step": 79530
    },
    {
      "epoch": 9.583132530120482,
      "grad_norm": 0.0023688320070505142,
      "learning_rate": 8.337349397590362e-07,
      "loss": 0.0177,
      "step": 79540
    },
    {
      "epoch": 9.58433734939759,
      "grad_norm": 0.0003104190400335938,
      "learning_rate": 8.313253012048193e-07,
      "loss": 0.0433,
      "step": 79550
    },
    {
      "epoch": 9.5855421686747,
      "grad_norm": 0.02301863767206669,
      "learning_rate": 8.289156626506025e-07,
      "loss": 0.0088,
      "step": 79560
    },
    {
      "epoch": 9.586746987951807,
      "grad_norm": 0.0006570262485183775,
      "learning_rate": 8.265060240963856e-07,
      "loss": 0.0621,
      "step": 79570
    },
    {
      "epoch": 9.587951807228915,
      "grad_norm": 0.0003782068088185042,
      "learning_rate": 8.240963855421688e-07,
      "loss": 0.0013,
      "step": 79580
    },
    {
      "epoch": 9.589156626506025,
      "grad_norm": 1.386083960533142,
      "learning_rate": 8.216867469879519e-07,
      "loss": 0.013,
      "step": 79590
    },
    {
      "epoch": 9.590361445783133,
      "grad_norm": 1.817762851715088,
      "learning_rate": 8.192771084337351e-07,
      "loss": 0.0218,
      "step": 79600
    },
    {
      "epoch": 9.59156626506024,
      "grad_norm": 0.0013670992339029908,
      "learning_rate": 8.168674698795182e-07,
      "loss": 0.0333,
      "step": 79610
    },
    {
      "epoch": 9.592771084337349,
      "grad_norm": 4.5002923011779785,
      "learning_rate": 8.144578313253012e-07,
      "loss": 0.0351,
      "step": 79620
    },
    {
      "epoch": 9.593975903614458,
      "grad_norm": 2.4689204692840576,
      "learning_rate": 8.120481927710844e-07,
      "loss": 0.0063,
      "step": 79630
    },
    {
      "epoch": 9.595180722891566,
      "grad_norm": 0.00019134633475914598,
      "learning_rate": 8.096385542168675e-07,
      "loss": 0.0112,
      "step": 79640
    },
    {
      "epoch": 9.596385542168674,
      "grad_norm": 1.4115842580795288,
      "learning_rate": 8.072289156626506e-07,
      "loss": 0.0212,
      "step": 79650
    },
    {
      "epoch": 9.597590361445784,
      "grad_norm": 0.00044199309195391834,
      "learning_rate": 8.048192771084338e-07,
      "loss": 0.0136,
      "step": 79660
    },
    {
      "epoch": 9.598795180722892,
      "grad_norm": 0.003577045165002346,
      "learning_rate": 8.02409638554217e-07,
      "loss": 0.0065,
      "step": 79670
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.03382059931755066,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0142,
      "step": 79680
    },
    {
      "epoch": 9.601204819277108,
      "grad_norm": 0.00038034067256376147,
      "learning_rate": 7.975903614457832e-07,
      "loss": 0.0037,
      "step": 79690
    },
    {
      "epoch": 9.602409638554217,
      "grad_norm": 0.0004921634099446237,
      "learning_rate": 7.951807228915663e-07,
      "loss": 0.0105,
      "step": 79700
    },
    {
      "epoch": 9.603614457831325,
      "grad_norm": 1.2492576837539673,
      "learning_rate": 7.927710843373494e-07,
      "loss": 0.0047,
      "step": 79710
    },
    {
      "epoch": 9.604819277108433,
      "grad_norm": 0.6032444834709167,
      "learning_rate": 7.903614457831326e-07,
      "loss": 0.005,
      "step": 79720
    },
    {
      "epoch": 9.606024096385543,
      "grad_norm": 0.0004279272397980094,
      "learning_rate": 7.879518072289157e-07,
      "loss": 0.0169,
      "step": 79730
    },
    {
      "epoch": 9.60722891566265,
      "grad_norm": 1.0260696411132812,
      "learning_rate": 7.855421686746989e-07,
      "loss": 0.0085,
      "step": 79740
    },
    {
      "epoch": 9.608433734939759,
      "grad_norm": 0.001957345986738801,
      "learning_rate": 7.83132530120482e-07,
      "loss": 0.0206,
      "step": 79750
    },
    {
      "epoch": 9.609638554216868,
      "grad_norm": 0.7341403365135193,
      "learning_rate": 7.807228915662652e-07,
      "loss": 0.0049,
      "step": 79760
    },
    {
      "epoch": 9.610843373493976,
      "grad_norm": 0.0005722034256905317,
      "learning_rate": 7.783132530120482e-07,
      "loss": 0.0042,
      "step": 79770
    },
    {
      "epoch": 9.612048192771084,
      "grad_norm": 0.0003433998499531299,
      "learning_rate": 7.759036144578314e-07,
      "loss": 0.0581,
      "step": 79780
    },
    {
      "epoch": 9.613253012048192,
      "grad_norm": 0.00029381440253928304,
      "learning_rate": 7.734939759036145e-07,
      "loss": 0.0142,
      "step": 79790
    },
    {
      "epoch": 9.614457831325302,
      "grad_norm": 5.285378456115723,
      "learning_rate": 7.710843373493978e-07,
      "loss": 0.0144,
      "step": 79800
    },
    {
      "epoch": 9.61566265060241,
      "grad_norm": 0.6245478391647339,
      "learning_rate": 7.686746987951808e-07,
      "loss": 0.0496,
      "step": 79810
    },
    {
      "epoch": 9.616867469879518,
      "grad_norm": 0.6756066679954529,
      "learning_rate": 7.662650602409639e-07,
      "loss": 0.0055,
      "step": 79820
    },
    {
      "epoch": 9.618072289156627,
      "grad_norm": 0.0005836762138642371,
      "learning_rate": 7.638554216867471e-07,
      "loss": 0.0198,
      "step": 79830
    },
    {
      "epoch": 9.619277108433735,
      "grad_norm": 1.8262971639633179,
      "learning_rate": 7.614457831325301e-07,
      "loss": 0.022,
      "step": 79840
    },
    {
      "epoch": 9.620481927710843,
      "grad_norm": 0.0025072458665817976,
      "learning_rate": 7.590361445783133e-07,
      "loss": 0.025,
      "step": 79850
    },
    {
      "epoch": 9.621686746987951,
      "grad_norm": 0.0005337423062883317,
      "learning_rate": 7.566265060240964e-07,
      "loss": 0.006,
      "step": 79860
    },
    {
      "epoch": 9.62289156626506,
      "grad_norm": 0.0001923365780385211,
      "learning_rate": 7.542168674698796e-07,
      "loss": 0.0244,
      "step": 79870
    },
    {
      "epoch": 9.624096385542169,
      "grad_norm": 0.0006220309878699481,
      "learning_rate": 7.518072289156627e-07,
      "loss": 0.0163,
      "step": 79880
    },
    {
      "epoch": 9.625301204819277,
      "grad_norm": 0.00038718170253559947,
      "learning_rate": 7.493975903614459e-07,
      "loss": 0.0062,
      "step": 79890
    },
    {
      "epoch": 9.626506024096386,
      "grad_norm": 0.00033661347697488964,
      "learning_rate": 7.46987951807229e-07,
      "loss": 0.022,
      "step": 79900
    },
    {
      "epoch": 9.627710843373494,
      "grad_norm": 0.001573071931488812,
      "learning_rate": 7.445783132530121e-07,
      "loss": 0.0453,
      "step": 79910
    },
    {
      "epoch": 9.628915662650602,
      "grad_norm": 0.0006279987283051014,
      "learning_rate": 7.421686746987952e-07,
      "loss": 0.0399,
      "step": 79920
    },
    {
      "epoch": 9.630120481927712,
      "grad_norm": 14.849166870117188,
      "learning_rate": 7.397590361445783e-07,
      "loss": 0.0165,
      "step": 79930
    },
    {
      "epoch": 9.63132530120482,
      "grad_norm": 0.00024566278443671763,
      "learning_rate": 7.373493975903615e-07,
      "loss": 0.0129,
      "step": 79940
    },
    {
      "epoch": 9.632530120481928,
      "grad_norm": 0.0006442681769840419,
      "learning_rate": 7.349397590361447e-07,
      "loss": 0.019,
      "step": 79950
    },
    {
      "epoch": 9.633734939759035,
      "grad_norm": 0.0003016063419636339,
      "learning_rate": 7.325301204819278e-07,
      "loss": 0.028,
      "step": 79960
    },
    {
      "epoch": 9.634939759036145,
      "grad_norm": 0.0003848245833069086,
      "learning_rate": 7.301204819277109e-07,
      "loss": 0.0064,
      "step": 79970
    },
    {
      "epoch": 9.636144578313253,
      "grad_norm": 0.0002952809154521674,
      "learning_rate": 7.277108433734941e-07,
      "loss": 0.016,
      "step": 79980
    },
    {
      "epoch": 9.637349397590361,
      "grad_norm": 2.5505318641662598,
      "learning_rate": 7.253012048192771e-07,
      "loss": 0.0142,
      "step": 79990
    },
    {
      "epoch": 9.638554216867469,
      "grad_norm": 0.00048245186917483807,
      "learning_rate": 7.228915662650602e-07,
      "loss": 0.0062,
      "step": 80000
    },
    {
      "epoch": 9.639759036144579,
      "grad_norm": 0.0002298556501045823,
      "learning_rate": 7.204819277108434e-07,
      "loss": 0.0179,
      "step": 80010
    },
    {
      "epoch": 9.640963855421687,
      "grad_norm": 1.6471120119094849,
      "learning_rate": 7.180722891566267e-07,
      "loss": 0.0207,
      "step": 80020
    },
    {
      "epoch": 9.642168674698794,
      "grad_norm": 0.0007944372482597828,
      "learning_rate": 7.156626506024097e-07,
      "loss": 0.0245,
      "step": 80030
    },
    {
      "epoch": 9.643373493975904,
      "grad_norm": 0.0004475507594179362,
      "learning_rate": 7.132530120481928e-07,
      "loss": 0.0067,
      "step": 80040
    },
    {
      "epoch": 9.644578313253012,
      "grad_norm": 0.0006176130846142769,
      "learning_rate": 7.10843373493976e-07,
      "loss": 0.0153,
      "step": 80050
    },
    {
      "epoch": 9.64578313253012,
      "grad_norm": 0.0002861508692149073,
      "learning_rate": 7.084337349397591e-07,
      "loss": 0.0041,
      "step": 80060
    },
    {
      "epoch": 9.64698795180723,
      "grad_norm": 0.0002551503130234778,
      "learning_rate": 7.060240963855422e-07,
      "loss": 0.0204,
      "step": 80070
    },
    {
      "epoch": 9.648192771084338,
      "grad_norm": 0.0002694962022360414,
      "learning_rate": 7.036144578313253e-07,
      "loss": 0.0132,
      "step": 80080
    },
    {
      "epoch": 9.649397590361446,
      "grad_norm": 0.004338271915912628,
      "learning_rate": 7.012048192771084e-07,
      "loss": 0.0011,
      "step": 80090
    },
    {
      "epoch": 9.650602409638553,
      "grad_norm": 0.000688822939991951,
      "learning_rate": 6.987951807228917e-07,
      "loss": 0.0,
      "step": 80100
    },
    {
      "epoch": 9.651807228915663,
      "grad_norm": 0.0006821147981099784,
      "learning_rate": 6.963855421686748e-07,
      "loss": 0.007,
      "step": 80110
    },
    {
      "epoch": 9.653012048192771,
      "grad_norm": 0.0005013701738789678,
      "learning_rate": 6.939759036144579e-07,
      "loss": 0.0059,
      "step": 80120
    },
    {
      "epoch": 9.654216867469879,
      "grad_norm": 0.20763038098812103,
      "learning_rate": 6.91566265060241e-07,
      "loss": 0.0184,
      "step": 80130
    },
    {
      "epoch": 9.655421686746989,
      "grad_norm": 0.005713806487619877,
      "learning_rate": 6.891566265060242e-07,
      "loss": 0.0222,
      "step": 80140
    },
    {
      "epoch": 9.656626506024097,
      "grad_norm": 0.005979929585009813,
      "learning_rate": 6.867469879518072e-07,
      "loss": 0.0091,
      "step": 80150
    },
    {
      "epoch": 9.657831325301204,
      "grad_norm": 0.00025795839610509574,
      "learning_rate": 6.843373493975904e-07,
      "loss": 0.01,
      "step": 80160
    },
    {
      "epoch": 9.659036144578312,
      "grad_norm": 0.0014375862665474415,
      "learning_rate": 6.819277108433736e-07,
      "loss": 0.0137,
      "step": 80170
    },
    {
      "epoch": 9.660240963855422,
      "grad_norm": 0.00019029081158805639,
      "learning_rate": 6.795180722891568e-07,
      "loss": 0.0027,
      "step": 80180
    },
    {
      "epoch": 9.66144578313253,
      "grad_norm": 0.005226485431194305,
      "learning_rate": 6.771084337349398e-07,
      "loss": 0.0107,
      "step": 80190
    },
    {
      "epoch": 9.662650602409638,
      "grad_norm": 0.21368944644927979,
      "learning_rate": 6.74698795180723e-07,
      "loss": 0.0214,
      "step": 80200
    },
    {
      "epoch": 9.663855421686748,
      "grad_norm": 0.26493340730667114,
      "learning_rate": 6.722891566265061e-07,
      "loss": 0.003,
      "step": 80210
    },
    {
      "epoch": 9.665060240963856,
      "grad_norm": 0.0029926535207778215,
      "learning_rate": 6.698795180722891e-07,
      "loss": 0.0188,
      "step": 80220
    },
    {
      "epoch": 9.666265060240963,
      "grad_norm": 2.1166718006134033,
      "learning_rate": 6.674698795180723e-07,
      "loss": 0.0295,
      "step": 80230
    },
    {
      "epoch": 9.667469879518073,
      "grad_norm": 0.23684349656105042,
      "learning_rate": 6.650602409638554e-07,
      "loss": 0.021,
      "step": 80240
    },
    {
      "epoch": 9.668674698795181,
      "grad_norm": 0.005237969569861889,
      "learning_rate": 6.626506024096387e-07,
      "loss": 0.0054,
      "step": 80250
    },
    {
      "epoch": 9.669879518072289,
      "grad_norm": 0.0004954246687702835,
      "learning_rate": 6.602409638554217e-07,
      "loss": 0.0305,
      "step": 80260
    },
    {
      "epoch": 9.671084337349397,
      "grad_norm": 0.00025684721185825765,
      "learning_rate": 6.578313253012049e-07,
      "loss": 0.0068,
      "step": 80270
    },
    {
      "epoch": 9.672289156626507,
      "grad_norm": 0.0003430669894441962,
      "learning_rate": 6.55421686746988e-07,
      "loss": 0.0302,
      "step": 80280
    },
    {
      "epoch": 9.673493975903614,
      "grad_norm": 0.0002567289338912815,
      "learning_rate": 6.530120481927712e-07,
      "loss": 0.0125,
      "step": 80290
    },
    {
      "epoch": 9.674698795180722,
      "grad_norm": 0.00035720932646654546,
      "learning_rate": 6.506024096385542e-07,
      "loss": 0.0058,
      "step": 80300
    },
    {
      "epoch": 9.675903614457832,
      "grad_norm": 0.00029375593294389546,
      "learning_rate": 6.481927710843373e-07,
      "loss": 0.0104,
      "step": 80310
    },
    {
      "epoch": 9.67710843373494,
      "grad_norm": 0.4460076093673706,
      "learning_rate": 6.457831325301206e-07,
      "loss": 0.0046,
      "step": 80320
    },
    {
      "epoch": 9.678313253012048,
      "grad_norm": 0.00047982114483602345,
      "learning_rate": 6.433734939759038e-07,
      "loss": 0.0039,
      "step": 80330
    },
    {
      "epoch": 9.679518072289156,
      "grad_norm": 0.0003308637242298573,
      "learning_rate": 6.409638554216868e-07,
      "loss": 0.0054,
      "step": 80340
    },
    {
      "epoch": 9.680722891566266,
      "grad_norm": 0.0005600649164989591,
      "learning_rate": 6.385542168674699e-07,
      "loss": 0.0118,
      "step": 80350
    },
    {
      "epoch": 9.681927710843373,
      "grad_norm": 0.40847328305244446,
      "learning_rate": 6.361445783132531e-07,
      "loss": 0.0165,
      "step": 80360
    },
    {
      "epoch": 9.683132530120481,
      "grad_norm": 0.5975245833396912,
      "learning_rate": 6.337349397590361e-07,
      "loss": 0.0335,
      "step": 80370
    },
    {
      "epoch": 9.684337349397591,
      "grad_norm": 0.26524946093559265,
      "learning_rate": 6.313253012048193e-07,
      "loss": 0.0006,
      "step": 80380
    },
    {
      "epoch": 9.685542168674699,
      "grad_norm": 0.0002030826435657218,
      "learning_rate": 6.289156626506025e-07,
      "loss": 0.0034,
      "step": 80390
    },
    {
      "epoch": 9.686746987951807,
      "grad_norm": 0.0004426199884619564,
      "learning_rate": 6.265060240963857e-07,
      "loss": 0.0212,
      "step": 80400
    },
    {
      "epoch": 9.687951807228917,
      "grad_norm": 0.5712384581565857,
      "learning_rate": 6.240963855421687e-07,
      "loss": 0.0114,
      "step": 80410
    },
    {
      "epoch": 9.689156626506024,
      "grad_norm": 1.9722199440002441,
      "learning_rate": 6.216867469879519e-07,
      "loss": 0.0244,
      "step": 80420
    },
    {
      "epoch": 9.690361445783132,
      "grad_norm": 0.00027773441979661584,
      "learning_rate": 6.19277108433735e-07,
      "loss": 0.029,
      "step": 80430
    },
    {
      "epoch": 9.69156626506024,
      "grad_norm": 0.919713020324707,
      "learning_rate": 6.168674698795181e-07,
      "loss": 0.0191,
      "step": 80440
    },
    {
      "epoch": 9.69277108433735,
      "grad_norm": 0.00026489884476177394,
      "learning_rate": 6.144578313253012e-07,
      "loss": 0.0014,
      "step": 80450
    },
    {
      "epoch": 9.693975903614458,
      "grad_norm": 0.00019548645650502294,
      "learning_rate": 6.120481927710844e-07,
      "loss": 0.0012,
      "step": 80460
    },
    {
      "epoch": 9.695180722891566,
      "grad_norm": 0.0002861317479982972,
      "learning_rate": 6.096385542168675e-07,
      "loss": 0.0134,
      "step": 80470
    },
    {
      "epoch": 9.696385542168674,
      "grad_norm": 0.8188261389732361,
      "learning_rate": 6.072289156626507e-07,
      "loss": 0.0161,
      "step": 80480
    },
    {
      "epoch": 9.697590361445783,
      "grad_norm": 1.3758283853530884,
      "learning_rate": 6.048192771084338e-07,
      "loss": 0.0276,
      "step": 80490
    },
    {
      "epoch": 9.698795180722891,
      "grad_norm": 0.4281472861766815,
      "learning_rate": 6.024096385542169e-07,
      "loss": 0.0099,
      "step": 80500
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.0006749074091203511,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.0247,
      "step": 80510
    },
    {
      "epoch": 9.701204819277109,
      "grad_norm": 0.9526066184043884,
      "learning_rate": 5.975903614457833e-07,
      "loss": 0.0166,
      "step": 80520
    },
    {
      "epoch": 9.702409638554217,
      "grad_norm": 0.0005362865631468594,
      "learning_rate": 5.951807228915663e-07,
      "loss": 0.0041,
      "step": 80530
    },
    {
      "epoch": 9.703614457831325,
      "grad_norm": 11.958740234375,
      "learning_rate": 5.927710843373494e-07,
      "loss": 0.0334,
      "step": 80540
    },
    {
      "epoch": 9.704819277108435,
      "grad_norm": 0.00038888846756890416,
      "learning_rate": 5.903614457831326e-07,
      "loss": 0.0267,
      "step": 80550
    },
    {
      "epoch": 9.706024096385542,
      "grad_norm": 0.000985770020633936,
      "learning_rate": 5.879518072289157e-07,
      "loss": 0.0041,
      "step": 80560
    },
    {
      "epoch": 9.70722891566265,
      "grad_norm": 0.00036543994792737067,
      "learning_rate": 5.855421686746988e-07,
      "loss": 0.0039,
      "step": 80570
    },
    {
      "epoch": 9.708433734939758,
      "grad_norm": 3.175748348236084,
      "learning_rate": 5.83132530120482e-07,
      "loss": 0.0219,
      "step": 80580
    },
    {
      "epoch": 9.709638554216868,
      "grad_norm": 0.5335386991500854,
      "learning_rate": 5.807228915662651e-07,
      "loss": 0.0153,
      "step": 80590
    },
    {
      "epoch": 9.710843373493976,
      "grad_norm": 0.0002781435032375157,
      "learning_rate": 5.783132530120482e-07,
      "loss": 0.0107,
      "step": 80600
    },
    {
      "epoch": 9.712048192771084,
      "grad_norm": 0.0032796866726130247,
      "learning_rate": 5.759036144578314e-07,
      "loss": 0.0318,
      "step": 80610
    },
    {
      "epoch": 9.713253012048193,
      "grad_norm": 0.67279452085495,
      "learning_rate": 5.734939759036145e-07,
      "loss": 0.0066,
      "step": 80620
    },
    {
      "epoch": 9.714457831325301,
      "grad_norm": 0.0003884255711454898,
      "learning_rate": 5.710843373493977e-07,
      "loss": 0.0069,
      "step": 80630
    },
    {
      "epoch": 9.71566265060241,
      "grad_norm": 0.0002372812305111438,
      "learning_rate": 5.686746987951807e-07,
      "loss": 0.0208,
      "step": 80640
    },
    {
      "epoch": 9.716867469879517,
      "grad_norm": 0.00148679967969656,
      "learning_rate": 5.662650602409639e-07,
      "loss": 0.0073,
      "step": 80650
    },
    {
      "epoch": 9.718072289156627,
      "grad_norm": 0.0003458542050793767,
      "learning_rate": 5.63855421686747e-07,
      "loss": 0.0004,
      "step": 80660
    },
    {
      "epoch": 9.719277108433735,
      "grad_norm": 0.009026248939335346,
      "learning_rate": 5.614457831325302e-07,
      "loss": 0.0047,
      "step": 80670
    },
    {
      "epoch": 9.720481927710843,
      "grad_norm": 0.0002319755731150508,
      "learning_rate": 5.590361445783133e-07,
      "loss": 0.018,
      "step": 80680
    },
    {
      "epoch": 9.721686746987952,
      "grad_norm": 0.0011837967904284596,
      "learning_rate": 5.566265060240964e-07,
      "loss": 0.024,
      "step": 80690
    },
    {
      "epoch": 9.72289156626506,
      "grad_norm": 0.7803455591201782,
      "learning_rate": 5.542168674698796e-07,
      "loss": 0.005,
      "step": 80700
    },
    {
      "epoch": 9.724096385542168,
      "grad_norm": 0.00031877588480710983,
      "learning_rate": 5.518072289156628e-07,
      "loss": 0.0036,
      "step": 80710
    },
    {
      "epoch": 9.725301204819278,
      "grad_norm": 0.0004990758607164025,
      "learning_rate": 5.493975903614458e-07,
      "loss": 0.0209,
      "step": 80720
    },
    {
      "epoch": 9.726506024096386,
      "grad_norm": 0.00035421873326413333,
      "learning_rate": 5.469879518072289e-07,
      "loss": 0.0086,
      "step": 80730
    },
    {
      "epoch": 9.727710843373494,
      "grad_norm": 0.43808111548423767,
      "learning_rate": 5.445783132530122e-07,
      "loss": 0.0089,
      "step": 80740
    },
    {
      "epoch": 9.728915662650602,
      "grad_norm": 1.679428219795227,
      "learning_rate": 5.421686746987952e-07,
      "loss": 0.0067,
      "step": 80750
    },
    {
      "epoch": 9.730120481927711,
      "grad_norm": 0.00034281337866559625,
      "learning_rate": 5.397590361445783e-07,
      "loss": 0.0198,
      "step": 80760
    },
    {
      "epoch": 9.73132530120482,
      "grad_norm": 2.6374683380126953,
      "learning_rate": 5.373493975903615e-07,
      "loss": 0.0186,
      "step": 80770
    },
    {
      "epoch": 9.732530120481927,
      "grad_norm": 0.0022580267395824194,
      "learning_rate": 5.349397590361447e-07,
      "loss": 0.0036,
      "step": 80780
    },
    {
      "epoch": 9.733734939759037,
      "grad_norm": 0.34952428936958313,
      "learning_rate": 5.325301204819277e-07,
      "loss": 0.0102,
      "step": 80790
    },
    {
      "epoch": 9.734939759036145,
      "grad_norm": 2.3641843795776367,
      "learning_rate": 5.301204819277109e-07,
      "loss": 0.0223,
      "step": 80800
    },
    {
      "epoch": 9.736144578313253,
      "grad_norm": 0.026560790836811066,
      "learning_rate": 5.27710843373494e-07,
      "loss": 0.0015,
      "step": 80810
    },
    {
      "epoch": 9.73734939759036,
      "grad_norm": 1.302545189857483,
      "learning_rate": 5.253012048192772e-07,
      "loss": 0.0096,
      "step": 80820
    },
    {
      "epoch": 9.73855421686747,
      "grad_norm": 0.3701637089252472,
      "learning_rate": 5.228915662650603e-07,
      "loss": 0.0065,
      "step": 80830
    },
    {
      "epoch": 9.739759036144578,
      "grad_norm": 0.3916892111301422,
      "learning_rate": 5.204819277108434e-07,
      "loss": 0.0125,
      "step": 80840
    },
    {
      "epoch": 9.740963855421686,
      "grad_norm": 0.00021951108647044748,
      "learning_rate": 5.180722891566266e-07,
      "loss": 0.0031,
      "step": 80850
    },
    {
      "epoch": 9.742168674698796,
      "grad_norm": 2.185330867767334,
      "learning_rate": 5.156626506024097e-07,
      "loss": 0.0119,
      "step": 80860
    },
    {
      "epoch": 9.743373493975904,
      "grad_norm": 0.00035163387656211853,
      "learning_rate": 5.132530120481928e-07,
      "loss": 0.0079,
      "step": 80870
    },
    {
      "epoch": 9.744578313253012,
      "grad_norm": 3.028346538543701,
      "learning_rate": 5.108433734939759e-07,
      "loss": 0.0242,
      "step": 80880
    },
    {
      "epoch": 9.745783132530121,
      "grad_norm": 0.0004601692489814013,
      "learning_rate": 5.084337349397591e-07,
      "loss": 0.001,
      "step": 80890
    },
    {
      "epoch": 9.74698795180723,
      "grad_norm": 1.5148696899414062,
      "learning_rate": 5.060240963855422e-07,
      "loss": 0.0175,
      "step": 80900
    },
    {
      "epoch": 9.748192771084337,
      "grad_norm": 0.00040581717621535063,
      "learning_rate": 5.036144578313253e-07,
      "loss": 0.0087,
      "step": 80910
    },
    {
      "epoch": 9.749397590361445,
      "grad_norm": 3.498403549194336,
      "learning_rate": 5.012048192771085e-07,
      "loss": 0.012,
      "step": 80920
    },
    {
      "epoch": 9.750602409638555,
      "grad_norm": 0.9540916681289673,
      "learning_rate": 4.987951807228917e-07,
      "loss": 0.0195,
      "step": 80930
    },
    {
      "epoch": 9.751807228915663,
      "grad_norm": 0.0003039689327124506,
      "learning_rate": 4.963855421686747e-07,
      "loss": 0.0045,
      "step": 80940
    },
    {
      "epoch": 9.75301204819277,
      "grad_norm": 0.0006013978854753077,
      "learning_rate": 4.939759036144578e-07,
      "loss": 0.0096,
      "step": 80950
    },
    {
      "epoch": 9.754216867469879,
      "grad_norm": 0.001244371640495956,
      "learning_rate": 4.91566265060241e-07,
      "loss": 0.0018,
      "step": 80960
    },
    {
      "epoch": 9.755421686746988,
      "grad_norm": 0.014759855344891548,
      "learning_rate": 4.891566265060242e-07,
      "loss": 0.003,
      "step": 80970
    },
    {
      "epoch": 9.756626506024096,
      "grad_norm": 0.0009301207610405982,
      "learning_rate": 4.867469879518072e-07,
      "loss": 0.0053,
      "step": 80980
    },
    {
      "epoch": 9.757831325301204,
      "grad_norm": 0.7560244798660278,
      "learning_rate": 4.843373493975904e-07,
      "loss": 0.0177,
      "step": 80990
    },
    {
      "epoch": 9.759036144578314,
      "grad_norm": 0.0002824642579071224,
      "learning_rate": 4.819277108433736e-07,
      "loss": 0.0203,
      "step": 81000
    },
    {
      "epoch": 9.760240963855422,
      "grad_norm": 0.0004014918813481927,
      "learning_rate": 4.795180722891567e-07,
      "loss": 0.0,
      "step": 81010
    },
    {
      "epoch": 9.76144578313253,
      "grad_norm": 0.0013820043532177806,
      "learning_rate": 4.771084337349398e-07,
      "loss": 0.0125,
      "step": 81020
    },
    {
      "epoch": 9.76265060240964,
      "grad_norm": 0.0003342025156598538,
      "learning_rate": 4.746987951807229e-07,
      "loss": 0.0111,
      "step": 81030
    },
    {
      "epoch": 9.763855421686747,
      "grad_norm": 0.000358044751919806,
      "learning_rate": 4.722891566265061e-07,
      "loss": 0.0017,
      "step": 81040
    },
    {
      "epoch": 9.765060240963855,
      "grad_norm": 0.25757887959480286,
      "learning_rate": 4.698795180722892e-07,
      "loss": 0.0137,
      "step": 81050
    },
    {
      "epoch": 9.766265060240963,
      "grad_norm": 0.0001682797010289505,
      "learning_rate": 4.674698795180723e-07,
      "loss": 0.0056,
      "step": 81060
    },
    {
      "epoch": 9.767469879518073,
      "grad_norm": 0.27769091725349426,
      "learning_rate": 4.650602409638555e-07,
      "loss": 0.0057,
      "step": 81070
    },
    {
      "epoch": 9.76867469879518,
      "grad_norm": 0.00031635575578548014,
      "learning_rate": 4.626506024096386e-07,
      "loss": 0.0156,
      "step": 81080
    },
    {
      "epoch": 9.769879518072289,
      "grad_norm": 0.0003926628560293466,
      "learning_rate": 4.602409638554217e-07,
      "loss": 0.0083,
      "step": 81090
    },
    {
      "epoch": 9.771084337349398,
      "grad_norm": 0.3195165693759918,
      "learning_rate": 4.578313253012048e-07,
      "loss": 0.0251,
      "step": 81100
    },
    {
      "epoch": 9.772289156626506,
      "grad_norm": 0.00039544401806779206,
      "learning_rate": 4.55421686746988e-07,
      "loss": 0.0265,
      "step": 81110
    },
    {
      "epoch": 9.773493975903614,
      "grad_norm": 0.25971847772598267,
      "learning_rate": 4.530120481927711e-07,
      "loss": 0.0013,
      "step": 81120
    },
    {
      "epoch": 9.774698795180722,
      "grad_norm": 0.0002959074918180704,
      "learning_rate": 4.5060240963855424e-07,
      "loss": 0.0053,
      "step": 81130
    },
    {
      "epoch": 9.775903614457832,
      "grad_norm": 2.829587697982788,
      "learning_rate": 4.4819277108433736e-07,
      "loss": 0.0096,
      "step": 81140
    },
    {
      "epoch": 9.77710843373494,
      "grad_norm": 1.2947852611541748,
      "learning_rate": 4.4578313253012054e-07,
      "loss": 0.0039,
      "step": 81150
    },
    {
      "epoch": 9.778313253012048,
      "grad_norm": 0.0003886149206664413,
      "learning_rate": 4.4337349397590366e-07,
      "loss": 0.0074,
      "step": 81160
    },
    {
      "epoch": 9.779518072289157,
      "grad_norm": 0.00029588217148557305,
      "learning_rate": 4.409638554216868e-07,
      "loss": 0.0021,
      "step": 81170
    },
    {
      "epoch": 9.780722891566265,
      "grad_norm": 0.000579956395085901,
      "learning_rate": 4.3855421686746996e-07,
      "loss": 0.0221,
      "step": 81180
    },
    {
      "epoch": 9.781927710843373,
      "grad_norm": 0.18322783708572388,
      "learning_rate": 4.361445783132531e-07,
      "loss": 0.0081,
      "step": 81190
    },
    {
      "epoch": 9.783132530120483,
      "grad_norm": 5.551505088806152,
      "learning_rate": 4.3373493975903615e-07,
      "loss": 0.038,
      "step": 81200
    },
    {
      "epoch": 9.78433734939759,
      "grad_norm": 0.0008628695504739881,
      "learning_rate": 4.313253012048193e-07,
      "loss": 0.0102,
      "step": 81210
    },
    {
      "epoch": 9.785542168674699,
      "grad_norm": 0.0004701396101154387,
      "learning_rate": 4.2891566265060245e-07,
      "loss": 0.0038,
      "step": 81220
    },
    {
      "epoch": 9.786746987951807,
      "grad_norm": 0.0017181321745738387,
      "learning_rate": 4.265060240963856e-07,
      "loss": 0.0153,
      "step": 81230
    },
    {
      "epoch": 9.787951807228916,
      "grad_norm": 0.000490903272293508,
      "learning_rate": 4.240963855421687e-07,
      "loss": 0.0107,
      "step": 81240
    },
    {
      "epoch": 9.789156626506024,
      "grad_norm": 0.010682890191674232,
      "learning_rate": 4.216867469879518e-07,
      "loss": 0.0174,
      "step": 81250
    },
    {
      "epoch": 9.790361445783132,
      "grad_norm": 0.9489472508430481,
      "learning_rate": 4.19277108433735e-07,
      "loss": 0.0152,
      "step": 81260
    },
    {
      "epoch": 9.791566265060242,
      "grad_norm": 0.0002822541573550552,
      "learning_rate": 4.168674698795181e-07,
      "loss": 0.0183,
      "step": 81270
    },
    {
      "epoch": 9.79277108433735,
      "grad_norm": 0.00032429653219878674,
      "learning_rate": 4.1445783132530124e-07,
      "loss": 0.0173,
      "step": 81280
    },
    {
      "epoch": 9.793975903614458,
      "grad_norm": 0.0002981239522341639,
      "learning_rate": 4.120481927710844e-07,
      "loss": 0.0121,
      "step": 81290
    },
    {
      "epoch": 9.795180722891565,
      "grad_norm": 0.0017002554377540946,
      "learning_rate": 4.0963855421686754e-07,
      "loss": 0.0046,
      "step": 81300
    },
    {
      "epoch": 9.796385542168675,
      "grad_norm": 0.05136419087648392,
      "learning_rate": 4.072289156626506e-07,
      "loss": 0.0128,
      "step": 81310
    },
    {
      "epoch": 9.797590361445783,
      "grad_norm": 0.0034736236557364464,
      "learning_rate": 4.0481927710843374e-07,
      "loss": 0.0166,
      "step": 81320
    },
    {
      "epoch": 9.798795180722891,
      "grad_norm": 0.18045386672019958,
      "learning_rate": 4.024096385542169e-07,
      "loss": 0.0185,
      "step": 81330
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.2479654550552368,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.0385,
      "step": 81340
    },
    {
      "epoch": 9.801204819277109,
      "grad_norm": 0.3901686668395996,
      "learning_rate": 3.9759036144578316e-07,
      "loss": 0.002,
      "step": 81350
    },
    {
      "epoch": 9.802409638554217,
      "grad_norm": 0.00023111875634640455,
      "learning_rate": 3.951807228915663e-07,
      "loss": 0.0066,
      "step": 81360
    },
    {
      "epoch": 9.803614457831326,
      "grad_norm": 0.0007057390757836401,
      "learning_rate": 3.9277108433734946e-07,
      "loss": 0.0182,
      "step": 81370
    },
    {
      "epoch": 9.804819277108434,
      "grad_norm": 0.243345707654953,
      "learning_rate": 3.903614457831326e-07,
      "loss": 0.0256,
      "step": 81380
    },
    {
      "epoch": 9.806024096385542,
      "grad_norm": 0.002685819985345006,
      "learning_rate": 3.879518072289157e-07,
      "loss": 0.0156,
      "step": 81390
    },
    {
      "epoch": 9.80722891566265,
      "grad_norm": 0.04158734902739525,
      "learning_rate": 3.855421686746989e-07,
      "loss": 0.0073,
      "step": 81400
    },
    {
      "epoch": 9.80843373493976,
      "grad_norm": 0.00075198506237939,
      "learning_rate": 3.8313253012048195e-07,
      "loss": 0.0277,
      "step": 81410
    },
    {
      "epoch": 9.809638554216868,
      "grad_norm": 0.004681890830397606,
      "learning_rate": 3.8072289156626507e-07,
      "loss": 0.0077,
      "step": 81420
    },
    {
      "epoch": 9.810843373493976,
      "grad_norm": 0.029836202040314674,
      "learning_rate": 3.783132530120482e-07,
      "loss": 0.011,
      "step": 81430
    },
    {
      "epoch": 9.812048192771083,
      "grad_norm": 0.00046445950283668935,
      "learning_rate": 3.7590361445783137e-07,
      "loss": 0.008,
      "step": 81440
    },
    {
      "epoch": 9.813253012048193,
      "grad_norm": 0.002347770845517516,
      "learning_rate": 3.734939759036145e-07,
      "loss": 0.0332,
      "step": 81450
    },
    {
      "epoch": 9.814457831325301,
      "grad_norm": 0.0001878554467111826,
      "learning_rate": 3.710843373493976e-07,
      "loss": 0.0012,
      "step": 81460
    },
    {
      "epoch": 9.815662650602409,
      "grad_norm": 0.00037114889710210264,
      "learning_rate": 3.6867469879518074e-07,
      "loss": 0.0223,
      "step": 81470
    },
    {
      "epoch": 9.816867469879519,
      "grad_norm": 0.0003529242821969092,
      "learning_rate": 3.662650602409639e-07,
      "loss": 0.0129,
      "step": 81480
    },
    {
      "epoch": 9.818072289156627,
      "grad_norm": 0.00040002449532039464,
      "learning_rate": 3.6385542168674704e-07,
      "loss": 0.0058,
      "step": 81490
    },
    {
      "epoch": 9.819277108433734,
      "grad_norm": 0.001104423077777028,
      "learning_rate": 3.614457831325301e-07,
      "loss": 0.0166,
      "step": 81500
    },
    {
      "epoch": 9.820481927710844,
      "grad_norm": 0.3180222809314728,
      "learning_rate": 3.5903614457831334e-07,
      "loss": 0.0066,
      "step": 81510
    },
    {
      "epoch": 9.821686746987952,
      "grad_norm": 0.00043923285556957126,
      "learning_rate": 3.566265060240964e-07,
      "loss": 0.007,
      "step": 81520
    },
    {
      "epoch": 9.82289156626506,
      "grad_norm": 0.0004950427683070302,
      "learning_rate": 3.5421686746987953e-07,
      "loss": 0.0103,
      "step": 81530
    },
    {
      "epoch": 9.824096385542168,
      "grad_norm": 0.0002795148466248065,
      "learning_rate": 3.5180722891566266e-07,
      "loss": 0.0104,
      "step": 81540
    },
    {
      "epoch": 9.825301204819278,
      "grad_norm": 0.0017217565327882767,
      "learning_rate": 3.4939759036144583e-07,
      "loss": 0.0021,
      "step": 81550
    },
    {
      "epoch": 9.826506024096386,
      "grad_norm": 4.629028797149658,
      "learning_rate": 3.4698795180722895e-07,
      "loss": 0.0212,
      "step": 81560
    },
    {
      "epoch": 9.827710843373493,
      "grad_norm": 0.0004761161108035594,
      "learning_rate": 3.445783132530121e-07,
      "loss": 0.0239,
      "step": 81570
    },
    {
      "epoch": 9.828915662650603,
      "grad_norm": 0.0012156728189438581,
      "learning_rate": 3.421686746987952e-07,
      "loss": 0.0174,
      "step": 81580
    },
    {
      "epoch": 9.830120481927711,
      "grad_norm": 1.6783828735351562,
      "learning_rate": 3.397590361445784e-07,
      "loss": 0.0063,
      "step": 81590
    },
    {
      "epoch": 9.831325301204819,
      "grad_norm": 0.0007499189232476056,
      "learning_rate": 3.373493975903615e-07,
      "loss": 0.0093,
      "step": 81600
    },
    {
      "epoch": 9.832530120481927,
      "grad_norm": 0.00026951346080750227,
      "learning_rate": 3.3493975903614457e-07,
      "loss": 0.0082,
      "step": 81610
    },
    {
      "epoch": 9.833734939759037,
      "grad_norm": 0.0005018708761781454,
      "learning_rate": 3.325301204819277e-07,
      "loss": 0.0083,
      "step": 81620
    },
    {
      "epoch": 9.834939759036144,
      "grad_norm": 0.0064744302071630955,
      "learning_rate": 3.3012048192771087e-07,
      "loss": 0.0097,
      "step": 81630
    },
    {
      "epoch": 9.836144578313252,
      "grad_norm": 0.00014081885456107557,
      "learning_rate": 3.27710843373494e-07,
      "loss": 0.0018,
      "step": 81640
    },
    {
      "epoch": 9.837349397590362,
      "grad_norm": 0.000441393960500136,
      "learning_rate": 3.253012048192771e-07,
      "loss": 0.0006,
      "step": 81650
    },
    {
      "epoch": 9.83855421686747,
      "grad_norm": 0.006414199247956276,
      "learning_rate": 3.228915662650603e-07,
      "loss": 0.0163,
      "step": 81660
    },
    {
      "epoch": 9.839759036144578,
      "grad_norm": 2.0778648853302,
      "learning_rate": 3.204819277108434e-07,
      "loss": 0.027,
      "step": 81670
    },
    {
      "epoch": 9.840963855421688,
      "grad_norm": 0.0006773248896934092,
      "learning_rate": 3.1807228915662654e-07,
      "loss": 0.0158,
      "step": 81680
    },
    {
      "epoch": 9.842168674698796,
      "grad_norm": 0.002505160868167877,
      "learning_rate": 3.1566265060240966e-07,
      "loss": 0.013,
      "step": 81690
    },
    {
      "epoch": 9.843373493975903,
      "grad_norm": 0.00044806156074628234,
      "learning_rate": 3.1325301204819284e-07,
      "loss": 0.0324,
      "step": 81700
    },
    {
      "epoch": 9.844578313253011,
      "grad_norm": 0.0005521591519936919,
      "learning_rate": 3.1084337349397596e-07,
      "loss": 0.0121,
      "step": 81710
    },
    {
      "epoch": 9.845783132530121,
      "grad_norm": 2.167393207550049,
      "learning_rate": 3.0843373493975903e-07,
      "loss": 0.0199,
      "step": 81720
    },
    {
      "epoch": 9.846987951807229,
      "grad_norm": 0.0007456326857209206,
      "learning_rate": 3.060240963855422e-07,
      "loss": 0.0022,
      "step": 81730
    },
    {
      "epoch": 9.848192771084337,
      "grad_norm": 0.0012992387637495995,
      "learning_rate": 3.0361445783132533e-07,
      "loss": 0.0163,
      "step": 81740
    },
    {
      "epoch": 9.849397590361447,
      "grad_norm": 0.0004926827386952937,
      "learning_rate": 3.0120481927710845e-07,
      "loss": 0.0069,
      "step": 81750
    },
    {
      "epoch": 9.850602409638554,
      "grad_norm": 0.0003411056532058865,
      "learning_rate": 2.9879518072289163e-07,
      "loss": 0.0339,
      "step": 81760
    },
    {
      "epoch": 9.851807228915662,
      "grad_norm": 0.002313836244866252,
      "learning_rate": 2.963855421686747e-07,
      "loss": 0.0167,
      "step": 81770
    },
    {
      "epoch": 9.85301204819277,
      "grad_norm": 0.0002069981856038794,
      "learning_rate": 2.9397590361445787e-07,
      "loss": 0.0164,
      "step": 81780
    },
    {
      "epoch": 9.85421686746988,
      "grad_norm": 0.0002361525985179469,
      "learning_rate": 2.91566265060241e-07,
      "loss": 0.0102,
      "step": 81790
    },
    {
      "epoch": 9.855421686746988,
      "grad_norm": 0.0007007407257333398,
      "learning_rate": 2.891566265060241e-07,
      "loss": 0.0119,
      "step": 81800
    },
    {
      "epoch": 9.856626506024096,
      "grad_norm": 0.0002482270065229386,
      "learning_rate": 2.8674698795180724e-07,
      "loss": 0.0049,
      "step": 81810
    },
    {
      "epoch": 9.857831325301206,
      "grad_norm": 0.0006877983105368912,
      "learning_rate": 2.8433734939759037e-07,
      "loss": 0.0092,
      "step": 81820
    },
    {
      "epoch": 9.859036144578313,
      "grad_norm": 0.0006467113271355629,
      "learning_rate": 2.819277108433735e-07,
      "loss": 0.011,
      "step": 81830
    },
    {
      "epoch": 9.860240963855421,
      "grad_norm": 0.00041414733277633786,
      "learning_rate": 2.7951807228915666e-07,
      "loss": 0.0105,
      "step": 81840
    },
    {
      "epoch": 9.861445783132531,
      "grad_norm": 2.256458044052124,
      "learning_rate": 2.771084337349398e-07,
      "loss": 0.0248,
      "step": 81850
    },
    {
      "epoch": 9.862650602409639,
      "grad_norm": 0.00027862240676768124,
      "learning_rate": 2.746987951807229e-07,
      "loss": 0.0297,
      "step": 81860
    },
    {
      "epoch": 9.863855421686747,
      "grad_norm": 0.0024109231308102608,
      "learning_rate": 2.722891566265061e-07,
      "loss": 0.0218,
      "step": 81870
    },
    {
      "epoch": 9.865060240963855,
      "grad_norm": 0.16262193024158478,
      "learning_rate": 2.6987951807228916e-07,
      "loss": 0.0009,
      "step": 81880
    },
    {
      "epoch": 9.866265060240965,
      "grad_norm": 0.000950079585891217,
      "learning_rate": 2.6746987951807233e-07,
      "loss": 0.0133,
      "step": 81890
    },
    {
      "epoch": 9.867469879518072,
      "grad_norm": 0.26929762959480286,
      "learning_rate": 2.6506024096385546e-07,
      "loss": 0.0041,
      "step": 81900
    },
    {
      "epoch": 9.86867469879518,
      "grad_norm": 3.072763681411743,
      "learning_rate": 2.626506024096386e-07,
      "loss": 0.0246,
      "step": 81910
    },
    {
      "epoch": 9.869879518072288,
      "grad_norm": 0.0017755741719156504,
      "learning_rate": 2.602409638554217e-07,
      "loss": 0.0,
      "step": 81920
    },
    {
      "epoch": 9.871084337349398,
      "grad_norm": 0.050231534987688065,
      "learning_rate": 2.578313253012048e-07,
      "loss": 0.0012,
      "step": 81930
    },
    {
      "epoch": 9.872289156626506,
      "grad_norm": 0.00026425212854519486,
      "learning_rate": 2.5542168674698795e-07,
      "loss": 0.0001,
      "step": 81940
    },
    {
      "epoch": 9.873493975903614,
      "grad_norm": 0.0005734286387450993,
      "learning_rate": 2.530120481927711e-07,
      "loss": 0.0205,
      "step": 81950
    },
    {
      "epoch": 9.874698795180723,
      "grad_norm": 0.0016508406260982156,
      "learning_rate": 2.5060240963855425e-07,
      "loss": 0.021,
      "step": 81960
    },
    {
      "epoch": 9.875903614457831,
      "grad_norm": 0.5545445680618286,
      "learning_rate": 2.4819277108433737e-07,
      "loss": 0.0031,
      "step": 81970
    },
    {
      "epoch": 9.87710843373494,
      "grad_norm": 0.6356186866760254,
      "learning_rate": 2.457831325301205e-07,
      "loss": 0.0122,
      "step": 81980
    },
    {
      "epoch": 9.878313253012049,
      "grad_norm": 2.2296860218048096,
      "learning_rate": 2.433734939759036e-07,
      "loss": 0.0183,
      "step": 81990
    },
    {
      "epoch": 9.879518072289157,
      "grad_norm": 2.1256821155548096,
      "learning_rate": 2.409638554216868e-07,
      "loss": 0.0275,
      "step": 82000
    },
    {
      "epoch": 9.880722891566265,
      "grad_norm": 0.0004675383388530463,
      "learning_rate": 2.385542168674699e-07,
      "loss": 0.0111,
      "step": 82010
    },
    {
      "epoch": 9.881927710843373,
      "grad_norm": 0.017844107002019882,
      "learning_rate": 2.3614457831325304e-07,
      "loss": 0.0076,
      "step": 82020
    },
    {
      "epoch": 9.883132530120482,
      "grad_norm": 2.467578649520874,
      "learning_rate": 2.3373493975903616e-07,
      "loss": 0.0339,
      "step": 82030
    },
    {
      "epoch": 9.88433734939759,
      "grad_norm": 0.003602989250794053,
      "learning_rate": 2.313253012048193e-07,
      "loss": 0.0107,
      "step": 82040
    },
    {
      "epoch": 9.885542168674698,
      "grad_norm": 0.0003942272160202265,
      "learning_rate": 2.289156626506024e-07,
      "loss": 0.0043,
      "step": 82050
    },
    {
      "epoch": 9.886746987951808,
      "grad_norm": 2.0193161964416504,
      "learning_rate": 2.2650602409638556e-07,
      "loss": 0.0246,
      "step": 82060
    },
    {
      "epoch": 9.887951807228916,
      "grad_norm": 0.8820515275001526,
      "learning_rate": 2.2409638554216868e-07,
      "loss": 0.0376,
      "step": 82070
    },
    {
      "epoch": 9.889156626506024,
      "grad_norm": 0.00016274608788080513,
      "learning_rate": 2.2168674698795183e-07,
      "loss": 0.0132,
      "step": 82080
    },
    {
      "epoch": 9.890361445783132,
      "grad_norm": 0.267760694026947,
      "learning_rate": 2.1927710843373498e-07,
      "loss": 0.0039,
      "step": 82090
    },
    {
      "epoch": 9.891566265060241,
      "grad_norm": 0.00024685965036042035,
      "learning_rate": 2.1686746987951808e-07,
      "loss": 0.0137,
      "step": 82100
    },
    {
      "epoch": 9.89277108433735,
      "grad_norm": 0.00043205561814829707,
      "learning_rate": 2.1445783132530123e-07,
      "loss": 0.0015,
      "step": 82110
    },
    {
      "epoch": 9.893975903614457,
      "grad_norm": 0.00029210097272880375,
      "learning_rate": 2.1204819277108435e-07,
      "loss": 0.0299,
      "step": 82120
    },
    {
      "epoch": 9.895180722891567,
      "grad_norm": 0.00023157222312875092,
      "learning_rate": 2.096385542168675e-07,
      "loss": 0.0039,
      "step": 82130
    },
    {
      "epoch": 9.896385542168675,
      "grad_norm": 0.00083062524208799,
      "learning_rate": 2.0722891566265062e-07,
      "loss": 0.0457,
      "step": 82140
    },
    {
      "epoch": 9.897590361445783,
      "grad_norm": 0.007470505777746439,
      "learning_rate": 2.0481927710843377e-07,
      "loss": 0.0066,
      "step": 82150
    },
    {
      "epoch": 9.898795180722892,
      "grad_norm": 0.0002706638188101351,
      "learning_rate": 2.0240963855421687e-07,
      "loss": 0.0021,
      "step": 82160
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.0007154183695092797,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 0.0159,
      "step": 82170
    },
    {
      "epoch": 9.901204819277108,
      "grad_norm": 0.00025314619415439665,
      "learning_rate": 1.9759036144578314e-07,
      "loss": 0.0197,
      "step": 82180
    },
    {
      "epoch": 9.902409638554216,
      "grad_norm": 0.4887334406375885,
      "learning_rate": 1.951807228915663e-07,
      "loss": 0.0045,
      "step": 82190
    },
    {
      "epoch": 9.903614457831326,
      "grad_norm": 0.00046657753409817815,
      "learning_rate": 1.9277108433734944e-07,
      "loss": 0.0091,
      "step": 82200
    },
    {
      "epoch": 9.904819277108434,
      "grad_norm": 0.0016852309927344322,
      "learning_rate": 1.9036144578313254e-07,
      "loss": 0.0122,
      "step": 82210
    },
    {
      "epoch": 9.906024096385542,
      "grad_norm": 0.0005916754016652703,
      "learning_rate": 1.8795180722891569e-07,
      "loss": 0.0261,
      "step": 82220
    },
    {
      "epoch": 9.907228915662651,
      "grad_norm": 0.00038526224670931697,
      "learning_rate": 1.855421686746988e-07,
      "loss": 0.0163,
      "step": 82230
    },
    {
      "epoch": 9.90843373493976,
      "grad_norm": 0.000371317146345973,
      "learning_rate": 1.8313253012048196e-07,
      "loss": 0.0125,
      "step": 82240
    },
    {
      "epoch": 9.909638554216867,
      "grad_norm": 0.012476657517254353,
      "learning_rate": 1.8072289156626505e-07,
      "loss": 0.0204,
      "step": 82250
    },
    {
      "epoch": 9.910843373493975,
      "grad_norm": 1.3982293605804443,
      "learning_rate": 1.783132530120482e-07,
      "loss": 0.0067,
      "step": 82260
    },
    {
      "epoch": 9.912048192771085,
      "grad_norm": 0.0002384829131187871,
      "learning_rate": 1.7590361445783133e-07,
      "loss": 0.0168,
      "step": 82270
    },
    {
      "epoch": 9.913253012048193,
      "grad_norm": 2.8630754947662354,
      "learning_rate": 1.7349397590361448e-07,
      "loss": 0.0596,
      "step": 82280
    },
    {
      "epoch": 9.9144578313253,
      "grad_norm": 1.9711363315582275,
      "learning_rate": 1.710843373493976e-07,
      "loss": 0.0095,
      "step": 82290
    },
    {
      "epoch": 9.91566265060241,
      "grad_norm": 1.8367501497268677,
      "learning_rate": 1.6867469879518075e-07,
      "loss": 0.0063,
      "step": 82300
    },
    {
      "epoch": 9.916867469879518,
      "grad_norm": 0.40382814407348633,
      "learning_rate": 1.6626506024096385e-07,
      "loss": 0.003,
      "step": 82310
    },
    {
      "epoch": 9.918072289156626,
      "grad_norm": 0.00725321751087904,
      "learning_rate": 1.63855421686747e-07,
      "loss": 0.0054,
      "step": 82320
    },
    {
      "epoch": 9.919277108433734,
      "grad_norm": 3.884970188140869,
      "learning_rate": 1.6144578313253015e-07,
      "loss": 0.0263,
      "step": 82330
    },
    {
      "epoch": 9.920481927710844,
      "grad_norm": 2.039445400238037,
      "learning_rate": 1.5903614457831327e-07,
      "loss": 0.0169,
      "step": 82340
    },
    {
      "epoch": 9.921686746987952,
      "grad_norm": 0.008329293690621853,
      "learning_rate": 1.5662650602409642e-07,
      "loss": 0.0263,
      "step": 82350
    },
    {
      "epoch": 9.92289156626506,
      "grad_norm": 0.002794721396639943,
      "learning_rate": 1.5421686746987951e-07,
      "loss": 0.0044,
      "step": 82360
    },
    {
      "epoch": 9.92409638554217,
      "grad_norm": 0.0001692338119028136,
      "learning_rate": 1.5180722891566266e-07,
      "loss": 0.0177,
      "step": 82370
    },
    {
      "epoch": 9.925301204819277,
      "grad_norm": 0.00029032613383606076,
      "learning_rate": 1.4939759036144581e-07,
      "loss": 0.0065,
      "step": 82380
    },
    {
      "epoch": 9.926506024096385,
      "grad_norm": 0.0004846067458856851,
      "learning_rate": 1.4698795180722894e-07,
      "loss": 0.0071,
      "step": 82390
    },
    {
      "epoch": 9.927710843373493,
      "grad_norm": 0.0002913868520408869,
      "learning_rate": 1.4457831325301206e-07,
      "loss": 0.0117,
      "step": 82400
    },
    {
      "epoch": 9.928915662650603,
      "grad_norm": 0.007219816092401743,
      "learning_rate": 1.4216867469879518e-07,
      "loss": 0.0215,
      "step": 82410
    },
    {
      "epoch": 9.93012048192771,
      "grad_norm": 0.5661932229995728,
      "learning_rate": 1.3975903614457833e-07,
      "loss": 0.011,
      "step": 82420
    },
    {
      "epoch": 9.931325301204819,
      "grad_norm": 0.00017960777040570974,
      "learning_rate": 1.3734939759036146e-07,
      "loss": 0.0071,
      "step": 82430
    },
    {
      "epoch": 9.932530120481928,
      "grad_norm": 0.20202703773975372,
      "learning_rate": 1.3493975903614458e-07,
      "loss": 0.0055,
      "step": 82440
    },
    {
      "epoch": 9.933734939759036,
      "grad_norm": 1.3196001052856445,
      "learning_rate": 1.3253012048192773e-07,
      "loss": 0.01,
      "step": 82450
    },
    {
      "epoch": 9.934939759036144,
      "grad_norm": 0.000264002475887537,
      "learning_rate": 1.3012048192771085e-07,
      "loss": 0.0009,
      "step": 82460
    },
    {
      "epoch": 9.936144578313254,
      "grad_norm": 1.986584186553955,
      "learning_rate": 1.2771084337349397e-07,
      "loss": 0.0157,
      "step": 82470
    },
    {
      "epoch": 9.937349397590362,
      "grad_norm": 0.2843879461288452,
      "learning_rate": 1.2530120481927712e-07,
      "loss": 0.0197,
      "step": 82480
    },
    {
      "epoch": 9.93855421686747,
      "grad_norm": 1.1409010887145996,
      "learning_rate": 1.2289156626506025e-07,
      "loss": 0.0112,
      "step": 82490
    },
    {
      "epoch": 9.939759036144578,
      "grad_norm": 0.011027799919247627,
      "learning_rate": 1.204819277108434e-07,
      "loss": 0.0248,
      "step": 82500
    },
    {
      "epoch": 9.940963855421687,
      "grad_norm": 0.00032858093618415296,
      "learning_rate": 1.1807228915662652e-07,
      "loss": 0.0008,
      "step": 82510
    },
    {
      "epoch": 9.942168674698795,
      "grad_norm": 0.0004066449764650315,
      "learning_rate": 1.1566265060240966e-07,
      "loss": 0.0138,
      "step": 82520
    },
    {
      "epoch": 9.943373493975903,
      "grad_norm": 0.00027011893689632416,
      "learning_rate": 1.1325301204819278e-07,
      "loss": 0.009,
      "step": 82530
    },
    {
      "epoch": 9.944578313253013,
      "grad_norm": 0.0036064181476831436,
      "learning_rate": 1.1084337349397592e-07,
      "loss": 0.0009,
      "step": 82540
    },
    {
      "epoch": 9.94578313253012,
      "grad_norm": 0.4451313316822052,
      "learning_rate": 1.0843373493975904e-07,
      "loss": 0.0014,
      "step": 82550
    },
    {
      "epoch": 9.946987951807229,
      "grad_norm": 0.00041580377728678286,
      "learning_rate": 1.0602409638554217e-07,
      "loss": 0.0219,
      "step": 82560
    },
    {
      "epoch": 9.948192771084337,
      "grad_norm": 4.033102035522461,
      "learning_rate": 1.0361445783132531e-07,
      "loss": 0.0328,
      "step": 82570
    },
    {
      "epoch": 9.949397590361446,
      "grad_norm": 0.00037302603595890105,
      "learning_rate": 1.0120481927710843e-07,
      "loss": 0.0215,
      "step": 82580
    },
    {
      "epoch": 9.950602409638554,
      "grad_norm": 1.4980868101119995,
      "learning_rate": 9.879518072289157e-08,
      "loss": 0.0289,
      "step": 82590
    },
    {
      "epoch": 9.951807228915662,
      "grad_norm": 0.01102488487958908,
      "learning_rate": 9.638554216867472e-08,
      "loss": 0.0009,
      "step": 82600
    },
    {
      "epoch": 9.953012048192772,
      "grad_norm": 0.00040205608820542693,
      "learning_rate": 9.397590361445784e-08,
      "loss": 0.0203,
      "step": 82610
    },
    {
      "epoch": 9.95421686746988,
      "grad_norm": 0.0002417810173938051,
      "learning_rate": 9.156626506024098e-08,
      "loss": 0.0285,
      "step": 82620
    },
    {
      "epoch": 9.955421686746988,
      "grad_norm": 0.0025728815235197544,
      "learning_rate": 8.91566265060241e-08,
      "loss": 0.0043,
      "step": 82630
    },
    {
      "epoch": 9.956626506024097,
      "grad_norm": 0.0002465616853442043,
      "learning_rate": 8.674698795180724e-08,
      "loss": 0.0041,
      "step": 82640
    },
    {
      "epoch": 9.957831325301205,
      "grad_norm": 0.22296598553657532,
      "learning_rate": 8.433734939759037e-08,
      "loss": 0.022,
      "step": 82650
    },
    {
      "epoch": 9.959036144578313,
      "grad_norm": 0.0010834994027391076,
      "learning_rate": 8.19277108433735e-08,
      "loss": 0.0005,
      "step": 82660
    },
    {
      "epoch": 9.960240963855421,
      "grad_norm": 0.9346736073493958,
      "learning_rate": 7.951807228915663e-08,
      "loss": 0.058,
      "step": 82670
    },
    {
      "epoch": 9.96144578313253,
      "grad_norm": 0.0014923840062692761,
      "learning_rate": 7.710843373493976e-08,
      "loss": 0.0134,
      "step": 82680
    },
    {
      "epoch": 9.962650602409639,
      "grad_norm": 0.001844980288296938,
      "learning_rate": 7.469879518072291e-08,
      "loss": 0.02,
      "step": 82690
    },
    {
      "epoch": 9.963855421686747,
      "grad_norm": 0.22775927186012268,
      "learning_rate": 7.228915662650603e-08,
      "loss": 0.0012,
      "step": 82700
    },
    {
      "epoch": 9.965060240963856,
      "grad_norm": 0.0006127312663011253,
      "learning_rate": 6.987951807228917e-08,
      "loss": 0.0024,
      "step": 82710
    },
    {
      "epoch": 9.966265060240964,
      "grad_norm": 0.003685710020363331,
      "learning_rate": 6.746987951807229e-08,
      "loss": 0.0162,
      "step": 82720
    },
    {
      "epoch": 9.967469879518072,
      "grad_norm": 0.0002736095048021525,
      "learning_rate": 6.506024096385543e-08,
      "loss": 0.0,
      "step": 82730
    },
    {
      "epoch": 9.96867469879518,
      "grad_norm": 0.0004267330514267087,
      "learning_rate": 6.265060240963856e-08,
      "loss": 0.0088,
      "step": 82740
    },
    {
      "epoch": 9.96987951807229,
      "grad_norm": 2.14997935295105,
      "learning_rate": 6.02409638554217e-08,
      "loss": 0.0149,
      "step": 82750
    },
    {
      "epoch": 9.971084337349398,
      "grad_norm": 0.0008209082880057395,
      "learning_rate": 5.783132530120483e-08,
      "loss": 0.0054,
      "step": 82760
    },
    {
      "epoch": 9.972289156626506,
      "grad_norm": 0.0002944057050626725,
      "learning_rate": 5.542168674698796e-08,
      "loss": 0.0024,
      "step": 82770
    },
    {
      "epoch": 9.973493975903615,
      "grad_norm": 3.792393922805786,
      "learning_rate": 5.301204819277109e-08,
      "loss": 0.0369,
      "step": 82780
    },
    {
      "epoch": 9.974698795180723,
      "grad_norm": 2.1490066051483154,
      "learning_rate": 5.060240963855422e-08,
      "loss": 0.0261,
      "step": 82790
    },
    {
      "epoch": 9.975903614457831,
      "grad_norm": 0.00025695981457829475,
      "learning_rate": 4.819277108433736e-08,
      "loss": 0.0099,
      "step": 82800
    },
    {
      "epoch": 9.977108433734939,
      "grad_norm": 3.4632160663604736,
      "learning_rate": 4.578313253012049e-08,
      "loss": 0.0233,
      "step": 82810
    },
    {
      "epoch": 9.978313253012049,
      "grad_norm": 0.0005021847318857908,
      "learning_rate": 4.337349397590362e-08,
      "loss": 0.0186,
      "step": 82820
    },
    {
      "epoch": 9.979518072289157,
      "grad_norm": 0.0028213607147336006,
      "learning_rate": 4.096385542168675e-08,
      "loss": 0.0,
      "step": 82830
    },
    {
      "epoch": 9.980722891566264,
      "grad_norm": 0.1852409392595291,
      "learning_rate": 3.855421686746988e-08,
      "loss": 0.0119,
      "step": 82840
    },
    {
      "epoch": 9.981927710843374,
      "grad_norm": 1.1083524227142334,
      "learning_rate": 3.6144578313253015e-08,
      "loss": 0.0093,
      "step": 82850
    },
    {
      "epoch": 9.983132530120482,
      "grad_norm": 3.4924285411834717,
      "learning_rate": 3.3734939759036145e-08,
      "loss": 0.0132,
      "step": 82860
    },
    {
      "epoch": 9.98433734939759,
      "grad_norm": 2.0701582431793213,
      "learning_rate": 3.132530120481928e-08,
      "loss": 0.021,
      "step": 82870
    },
    {
      "epoch": 9.985542168674698,
      "grad_norm": 2.2471425533294678,
      "learning_rate": 2.8915662650602414e-08,
      "loss": 0.0309,
      "step": 82880
    },
    {
      "epoch": 9.986746987951808,
      "grad_norm": 2.3321051597595215,
      "learning_rate": 2.6506024096385544e-08,
      "loss": 0.0277,
      "step": 82890
    },
    {
      "epoch": 9.987951807228916,
      "grad_norm": 0.0007245417218655348,
      "learning_rate": 2.409638554216868e-08,
      "loss": 0.0082,
      "step": 82900
    },
    {
      "epoch": 9.989156626506023,
      "grad_norm": 0.042360030114650726,
      "learning_rate": 2.168674698795181e-08,
      "loss": 0.0164,
      "step": 82910
    },
    {
      "epoch": 9.990361445783133,
      "grad_norm": 1.0388771295547485,
      "learning_rate": 1.927710843373494e-08,
      "loss": 0.0067,
      "step": 82920
    },
    {
      "epoch": 9.991566265060241,
      "grad_norm": 0.2761412560939789,
      "learning_rate": 1.6867469879518072e-08,
      "loss": 0.0151,
      "step": 82930
    },
    {
      "epoch": 9.992771084337349,
      "grad_norm": 0.2190612107515335,
      "learning_rate": 1.4457831325301207e-08,
      "loss": 0.0141,
      "step": 82940
    },
    {
      "epoch": 9.993975903614459,
      "grad_norm": 0.004777567461133003,
      "learning_rate": 1.204819277108434e-08,
      "loss": 0.0074,
      "step": 82950
    },
    {
      "epoch": 9.995180722891567,
      "grad_norm": 0.00038651697104796767,
      "learning_rate": 9.63855421686747e-09,
      "loss": 0.0092,
      "step": 82960
    },
    {
      "epoch": 9.996385542168674,
      "grad_norm": 1.9875681400299072,
      "learning_rate": 7.2289156626506035e-09,
      "loss": 0.018,
      "step": 82970
    },
    {
      "epoch": 9.997590361445782,
      "grad_norm": 0.00020590191707015038,
      "learning_rate": 4.819277108433735e-09,
      "loss": 0.0033,
      "step": 82980
    },
    {
      "epoch": 9.998795180722892,
      "grad_norm": 1.5974887609481812,
      "learning_rate": 2.4096385542168674e-09,
      "loss": 0.0292,
      "step": 82990
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0014621592126786709,
      "learning_rate": 0.0,
      "loss": 0.0162,
      "step": 83000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9876734158230221,
      "eval_f1": 0.9672355799177774,
      "eval_loss": 0.04935436323285103,
      "eval_precision": 0.9750094185608439,
      "eval_recall": 0.9595847237671487,
      "eval_runtime": 4958.9253,
      "eval_samples_per_second": 8.609,
      "eval_steps_per_second": 0.359,
      "step": 83000
    }
  ],
  "logging_steps": 10,
  "max_steps": 83000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.744034811197671e+18,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
