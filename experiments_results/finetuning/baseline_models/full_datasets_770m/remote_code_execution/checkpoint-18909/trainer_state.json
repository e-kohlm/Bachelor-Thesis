{
  "best_metric": 0.9894815927873778,
  "best_model_checkpoint": "../saved_models/remote_code_execution/checkpoint-18909",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 18909,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00047596382674916705,
      "grad_norm": 20.426565170288086,
      "learning_rate": 1.9999048072346504e-05,
      "loss": 0.3797,
      "step": 1
    },
    {
      "epoch": 0.00475963826749167,
      "grad_norm": 8.233383178710938,
      "learning_rate": 1.999048072346502e-05,
      "loss": 0.3743,
      "step": 10
    },
    {
      "epoch": 0.00951927653498334,
      "grad_norm": 19.16537857055664,
      "learning_rate": 1.9980961446930034e-05,
      "loss": 0.4242,
      "step": 20
    },
    {
      "epoch": 0.014278914802475012,
      "grad_norm": 34.893367767333984,
      "learning_rate": 1.997144217039505e-05,
      "loss": 0.3033,
      "step": 30
    },
    {
      "epoch": 0.01903855306996668,
      "grad_norm": 13.364913940429688,
      "learning_rate": 1.996192289386007e-05,
      "loss": 0.3558,
      "step": 40
    },
    {
      "epoch": 0.023798191337458353,
      "grad_norm": 9.338088035583496,
      "learning_rate": 1.9952403617325083e-05,
      "loss": 0.2789,
      "step": 50
    },
    {
      "epoch": 0.028557829604950024,
      "grad_norm": 35.79775619506836,
      "learning_rate": 1.99428843407901e-05,
      "loss": 0.3471,
      "step": 60
    },
    {
      "epoch": 0.03331746787244169,
      "grad_norm": 11.565353393554688,
      "learning_rate": 1.993336506425512e-05,
      "loss": 0.2755,
      "step": 70
    },
    {
      "epoch": 0.03807710613993336,
      "grad_norm": 14.84524154663086,
      "learning_rate": 1.9923845787720136e-05,
      "loss": 0.3524,
      "step": 80
    },
    {
      "epoch": 0.042836744407425034,
      "grad_norm": 7.119421005249023,
      "learning_rate": 1.991432651118515e-05,
      "loss": 0.2578,
      "step": 90
    },
    {
      "epoch": 0.047596382674916705,
      "grad_norm": 14.029598236083984,
      "learning_rate": 1.9904807234650168e-05,
      "loss": 0.276,
      "step": 100
    },
    {
      "epoch": 0.05235602094240838,
      "grad_norm": 20.43478775024414,
      "learning_rate": 1.9895287958115186e-05,
      "loss": 0.31,
      "step": 110
    },
    {
      "epoch": 0.05711565920990005,
      "grad_norm": 13.176980018615723,
      "learning_rate": 1.9885768681580204e-05,
      "loss": 0.3131,
      "step": 120
    },
    {
      "epoch": 0.06187529747739172,
      "grad_norm": 9.93670654296875,
      "learning_rate": 1.9876249405045218e-05,
      "loss": 0.3157,
      "step": 130
    },
    {
      "epoch": 0.06663493574488338,
      "grad_norm": 14.834284782409668,
      "learning_rate": 1.9866730128510236e-05,
      "loss": 0.2789,
      "step": 140
    },
    {
      "epoch": 0.07139457401237506,
      "grad_norm": 5.102933883666992,
      "learning_rate": 1.985721085197525e-05,
      "loss": 0.2862,
      "step": 150
    },
    {
      "epoch": 0.07615421227986673,
      "grad_norm": 7.253842353820801,
      "learning_rate": 1.9847691575440268e-05,
      "loss": 0.3128,
      "step": 160
    },
    {
      "epoch": 0.0809138505473584,
      "grad_norm": 9.22539234161377,
      "learning_rate": 1.9838172298905285e-05,
      "loss": 0.2318,
      "step": 170
    },
    {
      "epoch": 0.08567348881485007,
      "grad_norm": 7.435792446136475,
      "learning_rate": 1.98286530223703e-05,
      "loss": 0.2439,
      "step": 180
    },
    {
      "epoch": 0.09043312708234175,
      "grad_norm": 8.33331298828125,
      "learning_rate": 1.9819133745835317e-05,
      "loss": 0.2522,
      "step": 190
    },
    {
      "epoch": 0.09519276534983341,
      "grad_norm": 10.156473159790039,
      "learning_rate": 1.9809614469300335e-05,
      "loss": 0.271,
      "step": 200
    },
    {
      "epoch": 0.09995240361732509,
      "grad_norm": 3.118269681930542,
      "learning_rate": 1.9800095192765353e-05,
      "loss": 0.208,
      "step": 210
    },
    {
      "epoch": 0.10471204188481675,
      "grad_norm": 8.889638900756836,
      "learning_rate": 1.9790575916230367e-05,
      "loss": 0.2458,
      "step": 220
    },
    {
      "epoch": 0.10947168015230842,
      "grad_norm": 5.756976127624512,
      "learning_rate": 1.9781056639695385e-05,
      "loss": 0.2033,
      "step": 230
    },
    {
      "epoch": 0.1142313184198001,
      "grad_norm": 7.99808931350708,
      "learning_rate": 1.9771537363160402e-05,
      "loss": 0.2301,
      "step": 240
    },
    {
      "epoch": 0.11899095668729176,
      "grad_norm": 17.767658233642578,
      "learning_rate": 1.976201808662542e-05,
      "loss": 0.2826,
      "step": 250
    },
    {
      "epoch": 0.12375059495478344,
      "grad_norm": 9.544404029846191,
      "learning_rate": 1.9752498810090434e-05,
      "loss": 0.3017,
      "step": 260
    },
    {
      "epoch": 0.12851023322227512,
      "grad_norm": 12.53736686706543,
      "learning_rate": 1.9742979533555452e-05,
      "loss": 0.3062,
      "step": 270
    },
    {
      "epoch": 0.13326987148976677,
      "grad_norm": 9.34451961517334,
      "learning_rate": 1.9733460257020466e-05,
      "loss": 0.2703,
      "step": 280
    },
    {
      "epoch": 0.13802950975725845,
      "grad_norm": 6.368675708770752,
      "learning_rate": 1.9723940980485484e-05,
      "loss": 0.2519,
      "step": 290
    },
    {
      "epoch": 0.14278914802475012,
      "grad_norm": 9.44444465637207,
      "learning_rate": 1.97144217039505e-05,
      "loss": 0.2453,
      "step": 300
    },
    {
      "epoch": 0.1475487862922418,
      "grad_norm": 8.448036193847656,
      "learning_rate": 1.970490242741552e-05,
      "loss": 0.2408,
      "step": 310
    },
    {
      "epoch": 0.15230842455973345,
      "grad_norm": 5.7774834632873535,
      "learning_rate": 1.9695383150880534e-05,
      "loss": 0.252,
      "step": 320
    },
    {
      "epoch": 0.15706806282722513,
      "grad_norm": 10.034741401672363,
      "learning_rate": 1.968586387434555e-05,
      "loss": 0.1865,
      "step": 330
    },
    {
      "epoch": 0.1618277010947168,
      "grad_norm": 6.737947463989258,
      "learning_rate": 1.967634459781057e-05,
      "loss": 0.2125,
      "step": 340
    },
    {
      "epoch": 0.16658733936220846,
      "grad_norm": 8.239679336547852,
      "learning_rate": 1.9666825321275583e-05,
      "loss": 0.2113,
      "step": 350
    },
    {
      "epoch": 0.17134697762970014,
      "grad_norm": 9.043699264526367,
      "learning_rate": 1.96573060447406e-05,
      "loss": 0.2076,
      "step": 360
    },
    {
      "epoch": 0.17610661589719181,
      "grad_norm": 5.96127462387085,
      "learning_rate": 1.964778676820562e-05,
      "loss": 0.221,
      "step": 370
    },
    {
      "epoch": 0.1808662541646835,
      "grad_norm": 4.991061210632324,
      "learning_rate": 1.9638267491670636e-05,
      "loss": 0.2646,
      "step": 380
    },
    {
      "epoch": 0.18562589243217514,
      "grad_norm": 14.635380744934082,
      "learning_rate": 1.962874821513565e-05,
      "loss": 0.3407,
      "step": 390
    },
    {
      "epoch": 0.19038553069966682,
      "grad_norm": 8.727096557617188,
      "learning_rate": 1.9619228938600668e-05,
      "loss": 0.2028,
      "step": 400
    },
    {
      "epoch": 0.1951451689671585,
      "grad_norm": 7.356293201446533,
      "learning_rate": 1.9609709662065686e-05,
      "loss": 0.2057,
      "step": 410
    },
    {
      "epoch": 0.19990480723465018,
      "grad_norm": 3.9431281089782715,
      "learning_rate": 1.96001903855307e-05,
      "loss": 0.1749,
      "step": 420
    },
    {
      "epoch": 0.20466444550214183,
      "grad_norm": 3.57685923576355,
      "learning_rate": 1.9590671108995718e-05,
      "loss": 0.239,
      "step": 430
    },
    {
      "epoch": 0.2094240837696335,
      "grad_norm": 6.663967132568359,
      "learning_rate": 1.9581151832460736e-05,
      "loss": 0.1604,
      "step": 440
    },
    {
      "epoch": 0.21418372203712518,
      "grad_norm": 6.861172199249268,
      "learning_rate": 1.957163255592575e-05,
      "loss": 0.199,
      "step": 450
    },
    {
      "epoch": 0.21894336030461684,
      "grad_norm": 7.577284812927246,
      "learning_rate": 1.9562113279390767e-05,
      "loss": 0.1387,
      "step": 460
    },
    {
      "epoch": 0.2237029985721085,
      "grad_norm": 2.6310856342315674,
      "learning_rate": 1.9552594002855785e-05,
      "loss": 0.1543,
      "step": 470
    },
    {
      "epoch": 0.2284626368396002,
      "grad_norm": 1.8978197574615479,
      "learning_rate": 1.95430747263208e-05,
      "loss": 0.1518,
      "step": 480
    },
    {
      "epoch": 0.23322227510709187,
      "grad_norm": 3.549494981765747,
      "learning_rate": 1.9533555449785817e-05,
      "loss": 0.2113,
      "step": 490
    },
    {
      "epoch": 0.23798191337458352,
      "grad_norm": 7.317713737487793,
      "learning_rate": 1.9524036173250835e-05,
      "loss": 0.1887,
      "step": 500
    },
    {
      "epoch": 0.2427415516420752,
      "grad_norm": 2.734276533126831,
      "learning_rate": 1.9514516896715853e-05,
      "loss": 0.1272,
      "step": 510
    },
    {
      "epoch": 0.24750118990956688,
      "grad_norm": 4.785052299499512,
      "learning_rate": 1.9504997620180867e-05,
      "loss": 0.1319,
      "step": 520
    },
    {
      "epoch": 0.2522608281770585,
      "grad_norm": 6.704850196838379,
      "learning_rate": 1.9495478343645884e-05,
      "loss": 0.152,
      "step": 530
    },
    {
      "epoch": 0.25702046644455023,
      "grad_norm": 8.91479206085205,
      "learning_rate": 1.9485959067110902e-05,
      "loss": 0.1857,
      "step": 540
    },
    {
      "epoch": 0.2617801047120419,
      "grad_norm": 9.422462463378906,
      "learning_rate": 1.947643979057592e-05,
      "loss": 0.1734,
      "step": 550
    },
    {
      "epoch": 0.26653974297953353,
      "grad_norm": 10.499189376831055,
      "learning_rate": 1.9466920514040934e-05,
      "loss": 0.1917,
      "step": 560
    },
    {
      "epoch": 0.27129938124702524,
      "grad_norm": 10.438728332519531,
      "learning_rate": 1.9457401237505952e-05,
      "loss": 0.1621,
      "step": 570
    },
    {
      "epoch": 0.2760590195145169,
      "grad_norm": 5.925408840179443,
      "learning_rate": 1.9447881960970966e-05,
      "loss": 0.1614,
      "step": 580
    },
    {
      "epoch": 0.28081865778200854,
      "grad_norm": 6.042722702026367,
      "learning_rate": 1.9438362684435984e-05,
      "loss": 0.197,
      "step": 590
    },
    {
      "epoch": 0.28557829604950025,
      "grad_norm": 3.429298162460327,
      "learning_rate": 1.9428843407901e-05,
      "loss": 0.0862,
      "step": 600
    },
    {
      "epoch": 0.2903379343169919,
      "grad_norm": 5.86060905456543,
      "learning_rate": 1.941932413136602e-05,
      "loss": 0.1455,
      "step": 610
    },
    {
      "epoch": 0.2950975725844836,
      "grad_norm": 18.583141326904297,
      "learning_rate": 1.9409804854831033e-05,
      "loss": 0.2193,
      "step": 620
    },
    {
      "epoch": 0.29985721085197525,
      "grad_norm": 7.587121486663818,
      "learning_rate": 1.940028557829605e-05,
      "loss": 0.1926,
      "step": 630
    },
    {
      "epoch": 0.3046168491194669,
      "grad_norm": 3.7720463275909424,
      "learning_rate": 1.939076630176107e-05,
      "loss": 0.1206,
      "step": 640
    },
    {
      "epoch": 0.3093764873869586,
      "grad_norm": 2.9921557903289795,
      "learning_rate": 1.9381247025226083e-05,
      "loss": 0.1805,
      "step": 650
    },
    {
      "epoch": 0.31413612565445026,
      "grad_norm": 8.361166954040527,
      "learning_rate": 1.93717277486911e-05,
      "loss": 0.1272,
      "step": 660
    },
    {
      "epoch": 0.3188957639219419,
      "grad_norm": 0.2668336033821106,
      "learning_rate": 1.936220847215612e-05,
      "loss": 0.1476,
      "step": 670
    },
    {
      "epoch": 0.3236554021894336,
      "grad_norm": 10.584582328796387,
      "learning_rate": 1.9352689195621136e-05,
      "loss": 0.1695,
      "step": 680
    },
    {
      "epoch": 0.32841504045692527,
      "grad_norm": 3.254096746444702,
      "learning_rate": 1.934316991908615e-05,
      "loss": 0.115,
      "step": 690
    },
    {
      "epoch": 0.3331746787244169,
      "grad_norm": 6.385738372802734,
      "learning_rate": 1.9333650642551168e-05,
      "loss": 0.1357,
      "step": 700
    },
    {
      "epoch": 0.3379343169919086,
      "grad_norm": 10.341033935546875,
      "learning_rate": 1.9324131366016182e-05,
      "loss": 0.1628,
      "step": 710
    },
    {
      "epoch": 0.3426939552594003,
      "grad_norm": 8.177336692810059,
      "learning_rate": 1.93146120894812e-05,
      "loss": 0.1049,
      "step": 720
    },
    {
      "epoch": 0.347453593526892,
      "grad_norm": 5.2476325035095215,
      "learning_rate": 1.9305092812946218e-05,
      "loss": 0.1446,
      "step": 730
    },
    {
      "epoch": 0.35221323179438363,
      "grad_norm": 8.968722343444824,
      "learning_rate": 1.9295573536411235e-05,
      "loss": 0.1503,
      "step": 740
    },
    {
      "epoch": 0.3569728700618753,
      "grad_norm": 11.120299339294434,
      "learning_rate": 1.928605425987625e-05,
      "loss": 0.1111,
      "step": 750
    },
    {
      "epoch": 0.361732508329367,
      "grad_norm": 4.561288833618164,
      "learning_rate": 1.9276534983341267e-05,
      "loss": 0.0944,
      "step": 760
    },
    {
      "epoch": 0.36649214659685864,
      "grad_norm": 5.014176845550537,
      "learning_rate": 1.9267015706806285e-05,
      "loss": 0.1283,
      "step": 770
    },
    {
      "epoch": 0.3712517848643503,
      "grad_norm": 4.83650016784668,
      "learning_rate": 1.92574964302713e-05,
      "loss": 0.1213,
      "step": 780
    },
    {
      "epoch": 0.376011423131842,
      "grad_norm": 1.8390711545944214,
      "learning_rate": 1.9247977153736317e-05,
      "loss": 0.1152,
      "step": 790
    },
    {
      "epoch": 0.38077106139933364,
      "grad_norm": 1.0958259105682373,
      "learning_rate": 1.9238457877201335e-05,
      "loss": 0.1256,
      "step": 800
    },
    {
      "epoch": 0.3855306996668253,
      "grad_norm": 0.7465857863426208,
      "learning_rate": 1.9228938600666352e-05,
      "loss": 0.0945,
      "step": 810
    },
    {
      "epoch": 0.390290337934317,
      "grad_norm": 2.3235976696014404,
      "learning_rate": 1.9219419324131367e-05,
      "loss": 0.1257,
      "step": 820
    },
    {
      "epoch": 0.39504997620180865,
      "grad_norm": 9.311980247497559,
      "learning_rate": 1.9209900047596384e-05,
      "loss": 0.1285,
      "step": 830
    },
    {
      "epoch": 0.39980961446930036,
      "grad_norm": 9.49450969696045,
      "learning_rate": 1.92003807710614e-05,
      "loss": 0.0799,
      "step": 840
    },
    {
      "epoch": 0.404569252736792,
      "grad_norm": 4.626832008361816,
      "learning_rate": 1.919086149452642e-05,
      "loss": 0.1586,
      "step": 850
    },
    {
      "epoch": 0.40932889100428366,
      "grad_norm": 2.7976222038269043,
      "learning_rate": 1.9181342217991434e-05,
      "loss": 0.1013,
      "step": 860
    },
    {
      "epoch": 0.41408852927177536,
      "grad_norm": 7.521962642669678,
      "learning_rate": 1.9171822941456452e-05,
      "loss": 0.1355,
      "step": 870
    },
    {
      "epoch": 0.418848167539267,
      "grad_norm": 7.4484171867370605,
      "learning_rate": 1.9162303664921466e-05,
      "loss": 0.1295,
      "step": 880
    },
    {
      "epoch": 0.42360780580675866,
      "grad_norm": 7.886628150939941,
      "learning_rate": 1.9152784388386484e-05,
      "loss": 0.1959,
      "step": 890
    },
    {
      "epoch": 0.42836744407425037,
      "grad_norm": 1.959330439567566,
      "learning_rate": 1.91432651118515e-05,
      "loss": 0.0627,
      "step": 900
    },
    {
      "epoch": 0.433127082341742,
      "grad_norm": 6.141878604888916,
      "learning_rate": 1.9133745835316516e-05,
      "loss": 0.1049,
      "step": 910
    },
    {
      "epoch": 0.43788672060923367,
      "grad_norm": 2.9870922565460205,
      "learning_rate": 1.9124226558781533e-05,
      "loss": 0.0855,
      "step": 920
    },
    {
      "epoch": 0.4426463588767254,
      "grad_norm": 7.11819314956665,
      "learning_rate": 1.911470728224655e-05,
      "loss": 0.0973,
      "step": 930
    },
    {
      "epoch": 0.447405997144217,
      "grad_norm": 7.175349235534668,
      "learning_rate": 1.910518800571157e-05,
      "loss": 0.1058,
      "step": 940
    },
    {
      "epoch": 0.45216563541170873,
      "grad_norm": 5.121578693389893,
      "learning_rate": 1.9095668729176583e-05,
      "loss": 0.0857,
      "step": 950
    },
    {
      "epoch": 0.4569252736792004,
      "grad_norm": 9.837711334228516,
      "learning_rate": 1.90861494526416e-05,
      "loss": 0.1387,
      "step": 960
    },
    {
      "epoch": 0.46168491194669203,
      "grad_norm": 6.997428894042969,
      "learning_rate": 1.9076630176106615e-05,
      "loss": 0.0998,
      "step": 970
    },
    {
      "epoch": 0.46644455021418374,
      "grad_norm": 2.5691418647766113,
      "learning_rate": 1.9067110899571636e-05,
      "loss": 0.0386,
      "step": 980
    },
    {
      "epoch": 0.4712041884816754,
      "grad_norm": 10.580703735351562,
      "learning_rate": 1.905759162303665e-05,
      "loss": 0.1437,
      "step": 990
    },
    {
      "epoch": 0.47596382674916704,
      "grad_norm": 5.443087100982666,
      "learning_rate": 1.9048072346501668e-05,
      "loss": 0.1176,
      "step": 1000
    },
    {
      "epoch": 0.48072346501665875,
      "grad_norm": 1.2020809650421143,
      "learning_rate": 1.9038553069966682e-05,
      "loss": 0.071,
      "step": 1010
    },
    {
      "epoch": 0.4854831032841504,
      "grad_norm": 6.024742126464844,
      "learning_rate": 1.90290337934317e-05,
      "loss": 0.1007,
      "step": 1020
    },
    {
      "epoch": 0.4902427415516421,
      "grad_norm": 8.456338882446289,
      "learning_rate": 1.9019514516896718e-05,
      "loss": 0.1224,
      "step": 1030
    },
    {
      "epoch": 0.49500237981913375,
      "grad_norm": 6.085452556610107,
      "learning_rate": 1.9009995240361735e-05,
      "loss": 0.0819,
      "step": 1040
    },
    {
      "epoch": 0.4997620180866254,
      "grad_norm": 1.6763825416564941,
      "learning_rate": 1.900047596382675e-05,
      "loss": 0.0697,
      "step": 1050
    },
    {
      "epoch": 0.504521656354117,
      "grad_norm": 3.2203686237335205,
      "learning_rate": 1.8990956687291767e-05,
      "loss": 0.06,
      "step": 1060
    },
    {
      "epoch": 0.5092812946216088,
      "grad_norm": 1.770505428314209,
      "learning_rate": 1.8981437410756785e-05,
      "loss": 0.0668,
      "step": 1070
    },
    {
      "epoch": 0.5140409328891005,
      "grad_norm": 11.905993461608887,
      "learning_rate": 1.89719181342218e-05,
      "loss": 0.0664,
      "step": 1080
    },
    {
      "epoch": 0.5188005711565921,
      "grad_norm": 0.6049123406410217,
      "learning_rate": 1.8962398857686817e-05,
      "loss": 0.0396,
      "step": 1090
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 7.682715892791748,
      "learning_rate": 1.895287958115183e-05,
      "loss": 0.0484,
      "step": 1100
    },
    {
      "epoch": 0.5283198476915755,
      "grad_norm": 14.3787202835083,
      "learning_rate": 1.8943360304616852e-05,
      "loss": 0.058,
      "step": 1110
    },
    {
      "epoch": 0.5330794859590671,
      "grad_norm": 5.538417816162109,
      "learning_rate": 1.8933841028081867e-05,
      "loss": 0.0834,
      "step": 1120
    },
    {
      "epoch": 0.5378391242265588,
      "grad_norm": 5.633417129516602,
      "learning_rate": 1.8924321751546884e-05,
      "loss": 0.082,
      "step": 1130
    },
    {
      "epoch": 0.5425987624940505,
      "grad_norm": 0.800858199596405,
      "learning_rate": 1.89148024750119e-05,
      "loss": 0.0686,
      "step": 1140
    },
    {
      "epoch": 0.5473584007615421,
      "grad_norm": 4.297537326812744,
      "learning_rate": 1.890528319847692e-05,
      "loss": 0.0533,
      "step": 1150
    },
    {
      "epoch": 0.5521180390290338,
      "grad_norm": 5.188434600830078,
      "learning_rate": 1.8895763921941934e-05,
      "loss": 0.0828,
      "step": 1160
    },
    {
      "epoch": 0.5568776772965255,
      "grad_norm": 0.3931879699230194,
      "learning_rate": 1.888624464540695e-05,
      "loss": 0.0722,
      "step": 1170
    },
    {
      "epoch": 0.5616373155640171,
      "grad_norm": 0.3526560068130493,
      "learning_rate": 1.8876725368871966e-05,
      "loss": 0.0837,
      "step": 1180
    },
    {
      "epoch": 0.5663969538315088,
      "grad_norm": 11.690861701965332,
      "learning_rate": 1.8867206092336984e-05,
      "loss": 0.1072,
      "step": 1190
    },
    {
      "epoch": 0.5711565920990005,
      "grad_norm": 0.10322704911231995,
      "learning_rate": 1.8857686815802e-05,
      "loss": 0.0572,
      "step": 1200
    },
    {
      "epoch": 0.5759162303664922,
      "grad_norm": 0.2519431710243225,
      "learning_rate": 1.8848167539267016e-05,
      "loss": 0.042,
      "step": 1210
    },
    {
      "epoch": 0.5806758686339838,
      "grad_norm": 1.807456374168396,
      "learning_rate": 1.8838648262732033e-05,
      "loss": 0.0743,
      "step": 1220
    },
    {
      "epoch": 0.5854355069014755,
      "grad_norm": 8.143840789794922,
      "learning_rate": 1.882912898619705e-05,
      "loss": 0.0686,
      "step": 1230
    },
    {
      "epoch": 0.5901951451689672,
      "grad_norm": 6.782211780548096,
      "learning_rate": 1.881960970966207e-05,
      "loss": 0.0548,
      "step": 1240
    },
    {
      "epoch": 0.5949547834364588,
      "grad_norm": 7.081929683685303,
      "learning_rate": 1.8810090433127083e-05,
      "loss": 0.1406,
      "step": 1250
    },
    {
      "epoch": 0.5997144217039505,
      "grad_norm": 0.08400973677635193,
      "learning_rate": 1.88005711565921e-05,
      "loss": 0.0693,
      "step": 1260
    },
    {
      "epoch": 0.6044740599714422,
      "grad_norm": 0.13371239602565765,
      "learning_rate": 1.8791051880057115e-05,
      "loss": 0.0764,
      "step": 1270
    },
    {
      "epoch": 0.6092336982389338,
      "grad_norm": 0.16761229932308197,
      "learning_rate": 1.8781532603522136e-05,
      "loss": 0.0503,
      "step": 1280
    },
    {
      "epoch": 0.6139933365064255,
      "grad_norm": 2.094480514526367,
      "learning_rate": 1.877201332698715e-05,
      "loss": 0.0584,
      "step": 1290
    },
    {
      "epoch": 0.6187529747739172,
      "grad_norm": 0.049593713134527206,
      "learning_rate": 1.8762494050452168e-05,
      "loss": 0.0564,
      "step": 1300
    },
    {
      "epoch": 0.6235126130414088,
      "grad_norm": 9.126139640808105,
      "learning_rate": 1.8752974773917182e-05,
      "loss": 0.0735,
      "step": 1310
    },
    {
      "epoch": 0.6282722513089005,
      "grad_norm": 7.6366777420043945,
      "learning_rate": 1.87434554973822e-05,
      "loss": 0.1027,
      "step": 1320
    },
    {
      "epoch": 0.6330318895763922,
      "grad_norm": 1.9013285636901855,
      "learning_rate": 1.8733936220847218e-05,
      "loss": 0.0457,
      "step": 1330
    },
    {
      "epoch": 0.6377915278438838,
      "grad_norm": 0.35753366351127625,
      "learning_rate": 1.8724416944312235e-05,
      "loss": 0.0795,
      "step": 1340
    },
    {
      "epoch": 0.6425511661113755,
      "grad_norm": 6.208566665649414,
      "learning_rate": 1.871489766777725e-05,
      "loss": 0.0628,
      "step": 1350
    },
    {
      "epoch": 0.6473108043788672,
      "grad_norm": 1.945827841758728,
      "learning_rate": 1.8705378391242267e-05,
      "loss": 0.0327,
      "step": 1360
    },
    {
      "epoch": 0.6520704426463588,
      "grad_norm": 0.1763821244239807,
      "learning_rate": 1.8695859114707285e-05,
      "loss": 0.0771,
      "step": 1370
    },
    {
      "epoch": 0.6568300809138505,
      "grad_norm": 8.186120986938477,
      "learning_rate": 1.86863398381723e-05,
      "loss": 0.0888,
      "step": 1380
    },
    {
      "epoch": 0.6615897191813422,
      "grad_norm": 5.149529457092285,
      "learning_rate": 1.8676820561637317e-05,
      "loss": 0.0459,
      "step": 1390
    },
    {
      "epoch": 0.6663493574488338,
      "grad_norm": 1.9058339595794678,
      "learning_rate": 1.866730128510233e-05,
      "loss": 0.1068,
      "step": 1400
    },
    {
      "epoch": 0.6711089957163255,
      "grad_norm": 16.281618118286133,
      "learning_rate": 1.8657782008567352e-05,
      "loss": 0.124,
      "step": 1410
    },
    {
      "epoch": 0.6758686339838172,
      "grad_norm": 1.1942133903503418,
      "learning_rate": 1.8648262732032367e-05,
      "loss": 0.0358,
      "step": 1420
    },
    {
      "epoch": 0.680628272251309,
      "grad_norm": 0.2073732167482376,
      "learning_rate": 1.8638743455497384e-05,
      "loss": 0.1122,
      "step": 1430
    },
    {
      "epoch": 0.6853879105188005,
      "grad_norm": 0.2231609970331192,
      "learning_rate": 1.86292241789624e-05,
      "loss": 0.01,
      "step": 1440
    },
    {
      "epoch": 0.6901475487862923,
      "grad_norm": 3.9158754348754883,
      "learning_rate": 1.861970490242742e-05,
      "loss": 0.0871,
      "step": 1450
    },
    {
      "epoch": 0.694907187053784,
      "grad_norm": 2.8274552822113037,
      "learning_rate": 1.8610185625892434e-05,
      "loss": 0.0248,
      "step": 1460
    },
    {
      "epoch": 0.6996668253212756,
      "grad_norm": 12.123893737792969,
      "learning_rate": 1.860066634935745e-05,
      "loss": 0.0408,
      "step": 1470
    },
    {
      "epoch": 0.7044264635887673,
      "grad_norm": 0.6963351368904114,
      "learning_rate": 1.8591147072822466e-05,
      "loss": 0.1116,
      "step": 1480
    },
    {
      "epoch": 0.709186101856259,
      "grad_norm": 10.138849258422852,
      "learning_rate": 1.8581627796287484e-05,
      "loss": 0.0304,
      "step": 1490
    },
    {
      "epoch": 0.7139457401237506,
      "grad_norm": 12.456388473510742,
      "learning_rate": 1.85721085197525e-05,
      "loss": 0.0328,
      "step": 1500
    },
    {
      "epoch": 0.7187053783912423,
      "grad_norm": 0.6385719180107117,
      "learning_rate": 1.8562589243217516e-05,
      "loss": 0.0786,
      "step": 1510
    },
    {
      "epoch": 0.723465016658734,
      "grad_norm": 0.04685574769973755,
      "learning_rate": 1.8553069966682533e-05,
      "loss": 0.0458,
      "step": 1520
    },
    {
      "epoch": 0.7282246549262256,
      "grad_norm": 12.272624015808105,
      "learning_rate": 1.854355069014755e-05,
      "loss": 0.0567,
      "step": 1530
    },
    {
      "epoch": 0.7329842931937173,
      "grad_norm": 0.14013399183750153,
      "learning_rate": 1.853403141361257e-05,
      "loss": 0.0459,
      "step": 1540
    },
    {
      "epoch": 0.737743931461209,
      "grad_norm": 4.8597917556762695,
      "learning_rate": 1.8524512137077583e-05,
      "loss": 0.0313,
      "step": 1550
    },
    {
      "epoch": 0.7425035697287006,
      "grad_norm": 0.07188109308481216,
      "learning_rate": 1.85149928605426e-05,
      "loss": 0.0757,
      "step": 1560
    },
    {
      "epoch": 0.7472632079961923,
      "grad_norm": 0.7828643918037415,
      "learning_rate": 1.8505473584007615e-05,
      "loss": 0.0072,
      "step": 1570
    },
    {
      "epoch": 0.752022846263684,
      "grad_norm": 7.2902913093566895,
      "learning_rate": 1.8495954307472636e-05,
      "loss": 0.0622,
      "step": 1580
    },
    {
      "epoch": 0.7567824845311756,
      "grad_norm": 1.418222427368164,
      "learning_rate": 1.848643503093765e-05,
      "loss": 0.0618,
      "step": 1590
    },
    {
      "epoch": 0.7615421227986673,
      "grad_norm": 1.3571045398712158,
      "learning_rate": 1.8476915754402668e-05,
      "loss": 0.0088,
      "step": 1600
    },
    {
      "epoch": 0.766301761066159,
      "grad_norm": 6.156682014465332,
      "learning_rate": 1.8467396477867682e-05,
      "loss": 0.0688,
      "step": 1610
    },
    {
      "epoch": 0.7710613993336506,
      "grad_norm": 7.704473972320557,
      "learning_rate": 1.84578772013327e-05,
      "loss": 0.0198,
      "step": 1620
    },
    {
      "epoch": 0.7758210376011423,
      "grad_norm": 0.21758033335208893,
      "learning_rate": 1.8448357924797718e-05,
      "loss": 0.083,
      "step": 1630
    },
    {
      "epoch": 0.780580675868634,
      "grad_norm": 1.3394982814788818,
      "learning_rate": 1.8438838648262735e-05,
      "loss": 0.1165,
      "step": 1640
    },
    {
      "epoch": 0.7853403141361257,
      "grad_norm": 7.9693403244018555,
      "learning_rate": 1.842931937172775e-05,
      "loss": 0.046,
      "step": 1650
    },
    {
      "epoch": 0.7900999524036173,
      "grad_norm": 4.453137397766113,
      "learning_rate": 1.8419800095192767e-05,
      "loss": 0.0297,
      "step": 1660
    },
    {
      "epoch": 0.794859590671109,
      "grad_norm": 8.559115409851074,
      "learning_rate": 1.8410280818657785e-05,
      "loss": 0.0179,
      "step": 1670
    },
    {
      "epoch": 0.7996192289386007,
      "grad_norm": 5.933816909790039,
      "learning_rate": 1.84007615421228e-05,
      "loss": 0.0255,
      "step": 1680
    },
    {
      "epoch": 0.8043788672060923,
      "grad_norm": 0.8883364796638489,
      "learning_rate": 1.8391242265587817e-05,
      "loss": 0.1181,
      "step": 1690
    },
    {
      "epoch": 0.809138505473584,
      "grad_norm": 0.11848689615726471,
      "learning_rate": 1.838172298905283e-05,
      "loss": 0.0218,
      "step": 1700
    },
    {
      "epoch": 0.8138981437410757,
      "grad_norm": 6.462547302246094,
      "learning_rate": 1.8372203712517852e-05,
      "loss": 0.1221,
      "step": 1710
    },
    {
      "epoch": 0.8186577820085673,
      "grad_norm": 8.054834365844727,
      "learning_rate": 1.8362684435982866e-05,
      "loss": 0.0591,
      "step": 1720
    },
    {
      "epoch": 0.823417420276059,
      "grad_norm": 0.5197932124137878,
      "learning_rate": 1.8353165159447884e-05,
      "loss": 0.0506,
      "step": 1730
    },
    {
      "epoch": 0.8281770585435507,
      "grad_norm": 0.146458700299263,
      "learning_rate": 1.83436458829129e-05,
      "loss": 0.0546,
      "step": 1740
    },
    {
      "epoch": 0.8329366968110423,
      "grad_norm": 0.3599088490009308,
      "learning_rate": 1.8334126606377916e-05,
      "loss": 0.049,
      "step": 1750
    },
    {
      "epoch": 0.837696335078534,
      "grad_norm": 0.15824533998966217,
      "learning_rate": 1.8324607329842934e-05,
      "loss": 0.0179,
      "step": 1760
    },
    {
      "epoch": 0.8424559733460257,
      "grad_norm": 7.412420272827148,
      "learning_rate": 1.831508805330795e-05,
      "loss": 0.0355,
      "step": 1770
    },
    {
      "epoch": 0.8472156116135173,
      "grad_norm": 6.1254801750183105,
      "learning_rate": 1.8305568776772966e-05,
      "loss": 0.0485,
      "step": 1780
    },
    {
      "epoch": 0.851975249881009,
      "grad_norm": 6.241573333740234,
      "learning_rate": 1.8296049500237983e-05,
      "loss": 0.0483,
      "step": 1790
    },
    {
      "epoch": 0.8567348881485007,
      "grad_norm": 1.7041212320327759,
      "learning_rate": 1.8286530223703e-05,
      "loss": 0.0817,
      "step": 1800
    },
    {
      "epoch": 0.8614945264159923,
      "grad_norm": 0.07280989736318588,
      "learning_rate": 1.8277010947168015e-05,
      "loss": 0.007,
      "step": 1810
    },
    {
      "epoch": 0.866254164683484,
      "grad_norm": 0.05833396315574646,
      "learning_rate": 1.8267491670633033e-05,
      "loss": 0.0129,
      "step": 1820
    },
    {
      "epoch": 0.8710138029509757,
      "grad_norm": 7.640000820159912,
      "learning_rate": 1.825797239409805e-05,
      "loss": 0.0386,
      "step": 1830
    },
    {
      "epoch": 0.8757734412184673,
      "grad_norm": 7.542502403259277,
      "learning_rate": 1.824845311756307e-05,
      "loss": 0.0373,
      "step": 1840
    },
    {
      "epoch": 0.880533079485959,
      "grad_norm": 0.46279287338256836,
      "learning_rate": 1.8238933841028083e-05,
      "loss": 0.0686,
      "step": 1850
    },
    {
      "epoch": 0.8852927177534508,
      "grad_norm": 6.736272811889648,
      "learning_rate": 1.82294145644931e-05,
      "loss": 0.078,
      "step": 1860
    },
    {
      "epoch": 0.8900523560209425,
      "grad_norm": 9.709525108337402,
      "learning_rate": 1.8219895287958115e-05,
      "loss": 0.053,
      "step": 1870
    },
    {
      "epoch": 0.894811994288434,
      "grad_norm": 0.021410785615444183,
      "learning_rate": 1.8210376011423136e-05,
      "loss": 0.086,
      "step": 1880
    },
    {
      "epoch": 0.8995716325559258,
      "grad_norm": 3.4866487979888916,
      "learning_rate": 1.820085673488815e-05,
      "loss": 0.0132,
      "step": 1890
    },
    {
      "epoch": 0.9043312708234175,
      "grad_norm": 5.8707356452941895,
      "learning_rate": 1.8191337458353168e-05,
      "loss": 0.0459,
      "step": 1900
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.9544387459754944,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.0499,
      "step": 1910
    },
    {
      "epoch": 0.9138505473584008,
      "grad_norm": 0.1796829104423523,
      "learning_rate": 1.81722989052832e-05,
      "loss": 0.029,
      "step": 1920
    },
    {
      "epoch": 0.9186101856258925,
      "grad_norm": 4.347356796264648,
      "learning_rate": 1.8162779628748217e-05,
      "loss": 0.0225,
      "step": 1930
    },
    {
      "epoch": 0.9233698238933841,
      "grad_norm": 0.42183175683021545,
      "learning_rate": 1.8153260352213232e-05,
      "loss": 0.0538,
      "step": 1940
    },
    {
      "epoch": 0.9281294621608758,
      "grad_norm": 26.743005752563477,
      "learning_rate": 1.814374107567825e-05,
      "loss": 0.0785,
      "step": 1950
    },
    {
      "epoch": 0.9328891004283675,
      "grad_norm": 6.704461574554443,
      "learning_rate": 1.8134221799143267e-05,
      "loss": 0.0609,
      "step": 1960
    },
    {
      "epoch": 0.9376487386958591,
      "grad_norm": 6.250698089599609,
      "learning_rate": 1.8124702522608285e-05,
      "loss": 0.0558,
      "step": 1970
    },
    {
      "epoch": 0.9424083769633508,
      "grad_norm": 11.543437957763672,
      "learning_rate": 1.81151832460733e-05,
      "loss": 0.0269,
      "step": 1980
    },
    {
      "epoch": 0.9471680152308425,
      "grad_norm": 7.491771221160889,
      "learning_rate": 1.8105663969538317e-05,
      "loss": 0.0648,
      "step": 1990
    },
    {
      "epoch": 0.9519276534983341,
      "grad_norm": 6.063005447387695,
      "learning_rate": 1.809614469300333e-05,
      "loss": 0.035,
      "step": 2000
    },
    {
      "epoch": 0.9566872917658258,
      "grad_norm": 0.02655620500445366,
      "learning_rate": 1.8086625416468352e-05,
      "loss": 0.0503,
      "step": 2010
    },
    {
      "epoch": 0.9614469300333175,
      "grad_norm": 2.1235482692718506,
      "learning_rate": 1.8077106139933366e-05,
      "loss": 0.061,
      "step": 2020
    },
    {
      "epoch": 0.9662065683008091,
      "grad_norm": 0.342022180557251,
      "learning_rate": 1.8067586863398384e-05,
      "loss": 0.0317,
      "step": 2030
    },
    {
      "epoch": 0.9709662065683008,
      "grad_norm": 0.1984626054763794,
      "learning_rate": 1.80580675868634e-05,
      "loss": 0.1332,
      "step": 2040
    },
    {
      "epoch": 0.9757258448357925,
      "grad_norm": 0.04468391090631485,
      "learning_rate": 1.8048548310328416e-05,
      "loss": 0.029,
      "step": 2050
    },
    {
      "epoch": 0.9804854831032842,
      "grad_norm": 0.0933765396475792,
      "learning_rate": 1.8039029033793434e-05,
      "loss": 0.0058,
      "step": 2060
    },
    {
      "epoch": 0.9852451213707758,
      "grad_norm": 0.5516830086708069,
      "learning_rate": 1.802950975725845e-05,
      "loss": 0.0299,
      "step": 2070
    },
    {
      "epoch": 0.9900047596382675,
      "grad_norm": 0.8106223344802856,
      "learning_rate": 1.8019990480723466e-05,
      "loss": 0.0629,
      "step": 2080
    },
    {
      "epoch": 0.9947643979057592,
      "grad_norm": 0.06064290553331375,
      "learning_rate": 1.8010471204188483e-05,
      "loss": 0.0224,
      "step": 2090
    },
    {
      "epoch": 0.9995240361732508,
      "grad_norm": 0.16735364496707916,
      "learning_rate": 1.80009519276535e-05,
      "loss": 0.0609,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9890277777777777,
      "eval_f1": 0.9404672192916352,
      "eval_loss": 0.04582549259066582,
      "eval_precision": 0.9440242057488654,
      "eval_recall": 0.9369369369369369,
      "eval_runtime": 338.0184,
      "eval_samples_per_second": 42.634,
      "eval_steps_per_second": 1.334,
      "step": 2101
    },
    {
      "epoch": 1.0042836744407424,
      "grad_norm": 0.05438486859202385,
      "learning_rate": 1.7991432651118515e-05,
      "loss": 0.0159,
      "step": 2110
    },
    {
      "epoch": 1.009043312708234,
      "grad_norm": 2.999058246612549,
      "learning_rate": 1.7981913374583533e-05,
      "loss": 0.0268,
      "step": 2120
    },
    {
      "epoch": 1.0138029509757258,
      "grad_norm": 0.21358288824558258,
      "learning_rate": 1.7972394098048547e-05,
      "loss": 0.0221,
      "step": 2130
    },
    {
      "epoch": 1.0185625892432175,
      "grad_norm": 14.151302337646484,
      "learning_rate": 1.796287482151357e-05,
      "loss": 0.0162,
      "step": 2140
    },
    {
      "epoch": 1.0233222275107092,
      "grad_norm": 0.10411284118890762,
      "learning_rate": 1.7953355544978583e-05,
      "loss": 0.0075,
      "step": 2150
    },
    {
      "epoch": 1.028081865778201,
      "grad_norm": 0.1570763885974884,
      "learning_rate": 1.79438362684436e-05,
      "loss": 0.0211,
      "step": 2160
    },
    {
      "epoch": 1.0328415040456926,
      "grad_norm": 0.1060548797249794,
      "learning_rate": 1.7934316991908615e-05,
      "loss": 0.0379,
      "step": 2170
    },
    {
      "epoch": 1.0376011423131841,
      "grad_norm": 0.027754656970500946,
      "learning_rate": 1.7924797715373636e-05,
      "loss": 0.0071,
      "step": 2180
    },
    {
      "epoch": 1.0423607805806758,
      "grad_norm": 0.022455018013715744,
      "learning_rate": 1.791527843883865e-05,
      "loss": 0.0312,
      "step": 2190
    },
    {
      "epoch": 1.0471204188481675,
      "grad_norm": 0.012447240762412548,
      "learning_rate": 1.7905759162303668e-05,
      "loss": 0.0525,
      "step": 2200
    },
    {
      "epoch": 1.0518800571156592,
      "grad_norm": 0.17840592563152313,
      "learning_rate": 1.7896239885768682e-05,
      "loss": 0.071,
      "step": 2210
    },
    {
      "epoch": 1.056639695383151,
      "grad_norm": 1.095605492591858,
      "learning_rate": 1.78867206092337e-05,
      "loss": 0.0219,
      "step": 2220
    },
    {
      "epoch": 1.0613993336506427,
      "grad_norm": 9.602060317993164,
      "learning_rate": 1.7877201332698717e-05,
      "loss": 0.0144,
      "step": 2230
    },
    {
      "epoch": 1.0661589719181341,
      "grad_norm": 15.371715545654297,
      "learning_rate": 1.786768205616373e-05,
      "loss": 0.0385,
      "step": 2240
    },
    {
      "epoch": 1.0709186101856258,
      "grad_norm": 0.08875781297683716,
      "learning_rate": 1.785816277962875e-05,
      "loss": 0.0455,
      "step": 2250
    },
    {
      "epoch": 1.0756782484531175,
      "grad_norm": 0.03766893595457077,
      "learning_rate": 1.7848643503093767e-05,
      "loss": 0.0658,
      "step": 2260
    },
    {
      "epoch": 1.0804378867206093,
      "grad_norm": 0.05081348121166229,
      "learning_rate": 1.7839124226558785e-05,
      "loss": 0.0306,
      "step": 2270
    },
    {
      "epoch": 1.085197524988101,
      "grad_norm": 0.2326928675174713,
      "learning_rate": 1.78296049500238e-05,
      "loss": 0.0406,
      "step": 2280
    },
    {
      "epoch": 1.0899571632555927,
      "grad_norm": 0.3234311044216156,
      "learning_rate": 1.7820085673488817e-05,
      "loss": 0.0308,
      "step": 2290
    },
    {
      "epoch": 1.0947168015230841,
      "grad_norm": 0.005922593176364899,
      "learning_rate": 1.781056639695383e-05,
      "loss": 0.0029,
      "step": 2300
    },
    {
      "epoch": 1.0994764397905759,
      "grad_norm": 0.3904206454753876,
      "learning_rate": 1.7801047120418852e-05,
      "loss": 0.0741,
      "step": 2310
    },
    {
      "epoch": 1.1042360780580676,
      "grad_norm": 1.1167001724243164,
      "learning_rate": 1.7791527843883866e-05,
      "loss": 0.0691,
      "step": 2320
    },
    {
      "epoch": 1.1089957163255593,
      "grad_norm": 1.0705500841140747,
      "learning_rate": 1.7782008567348884e-05,
      "loss": 0.0244,
      "step": 2330
    },
    {
      "epoch": 1.113755354593051,
      "grad_norm": 0.3791522681713104,
      "learning_rate": 1.7772489290813898e-05,
      "loss": 0.0276,
      "step": 2340
    },
    {
      "epoch": 1.1185149928605427,
      "grad_norm": 0.29526859521865845,
      "learning_rate": 1.7762970014278916e-05,
      "loss": 0.0657,
      "step": 2350
    },
    {
      "epoch": 1.1232746311280342,
      "grad_norm": 0.3847700357437134,
      "learning_rate": 1.7753450737743934e-05,
      "loss": 0.0324,
      "step": 2360
    },
    {
      "epoch": 1.1280342693955259,
      "grad_norm": 1.7133584022521973,
      "learning_rate": 1.774393146120895e-05,
      "loss": 0.0039,
      "step": 2370
    },
    {
      "epoch": 1.1327939076630176,
      "grad_norm": 6.488652229309082,
      "learning_rate": 1.7734412184673966e-05,
      "loss": 0.0671,
      "step": 2380
    },
    {
      "epoch": 1.1375535459305093,
      "grad_norm": 0.021629666909575462,
      "learning_rate": 1.7724892908138983e-05,
      "loss": 0.0196,
      "step": 2390
    },
    {
      "epoch": 1.142313184198001,
      "grad_norm": 0.17493318021297455,
      "learning_rate": 1.7715373631604e-05,
      "loss": 0.0419,
      "step": 2400
    },
    {
      "epoch": 1.1470728224654927,
      "grad_norm": 0.026004090905189514,
      "learning_rate": 1.7705854355069015e-05,
      "loss": 0.0296,
      "step": 2410
    },
    {
      "epoch": 1.1518324607329844,
      "grad_norm": 9.023839950561523,
      "learning_rate": 1.7696335078534033e-05,
      "loss": 0.0366,
      "step": 2420
    },
    {
      "epoch": 1.1565920990004759,
      "grad_norm": 0.2551549971103668,
      "learning_rate": 1.7686815801999047e-05,
      "loss": 0.0122,
      "step": 2430
    },
    {
      "epoch": 1.1613517372679676,
      "grad_norm": 3.0320773124694824,
      "learning_rate": 1.767729652546407e-05,
      "loss": 0.0115,
      "step": 2440
    },
    {
      "epoch": 1.1661113755354593,
      "grad_norm": 1.3204708099365234,
      "learning_rate": 1.7667777248929083e-05,
      "loss": 0.0061,
      "step": 2450
    },
    {
      "epoch": 1.170871013802951,
      "grad_norm": 0.06463730335235596,
      "learning_rate": 1.76582579723941e-05,
      "loss": 0.0314,
      "step": 2460
    },
    {
      "epoch": 1.1756306520704427,
      "grad_norm": 0.024383192881941795,
      "learning_rate": 1.7648738695859115e-05,
      "loss": 0.0312,
      "step": 2470
    },
    {
      "epoch": 1.1803902903379344,
      "grad_norm": 0.029850073158740997,
      "learning_rate": 1.7639219419324132e-05,
      "loss": 0.0461,
      "step": 2480
    },
    {
      "epoch": 1.185149928605426,
      "grad_norm": 0.002220715396106243,
      "learning_rate": 1.762970014278915e-05,
      "loss": 0.043,
      "step": 2490
    },
    {
      "epoch": 1.1899095668729176,
      "grad_norm": 0.7789414525032043,
      "learning_rate": 1.7620180866254168e-05,
      "loss": 0.0467,
      "step": 2500
    },
    {
      "epoch": 1.1946692051404093,
      "grad_norm": 31.149438858032227,
      "learning_rate": 1.7610661589719182e-05,
      "loss": 0.1025,
      "step": 2510
    },
    {
      "epoch": 1.199428843407901,
      "grad_norm": 0.010081778280436993,
      "learning_rate": 1.76011423131842e-05,
      "loss": 0.0022,
      "step": 2520
    },
    {
      "epoch": 1.2041884816753927,
      "grad_norm": 13.328339576721191,
      "learning_rate": 1.7591623036649217e-05,
      "loss": 0.1098,
      "step": 2530
    },
    {
      "epoch": 1.2089481199428844,
      "grad_norm": 0.007359990384429693,
      "learning_rate": 1.758210376011423e-05,
      "loss": 0.0848,
      "step": 2540
    },
    {
      "epoch": 1.2137077582103761,
      "grad_norm": 0.18906885385513306,
      "learning_rate": 1.757258448357925e-05,
      "loss": 0.0018,
      "step": 2550
    },
    {
      "epoch": 1.2184673964778676,
      "grad_norm": 3.531651020050049,
      "learning_rate": 1.7563065207044267e-05,
      "loss": 0.0393,
      "step": 2560
    },
    {
      "epoch": 1.2232270347453593,
      "grad_norm": 5.669546127319336,
      "learning_rate": 1.7553545930509285e-05,
      "loss": 0.0257,
      "step": 2570
    },
    {
      "epoch": 1.227986673012851,
      "grad_norm": 0.058339864015579224,
      "learning_rate": 1.75440266539743e-05,
      "loss": 0.0019,
      "step": 2580
    },
    {
      "epoch": 1.2327463112803427,
      "grad_norm": 0.01020191702991724,
      "learning_rate": 1.7534507377439317e-05,
      "loss": 0.0132,
      "step": 2590
    },
    {
      "epoch": 1.2375059495478344,
      "grad_norm": 0.47549968957901,
      "learning_rate": 1.752498810090433e-05,
      "loss": 0.0062,
      "step": 2600
    },
    {
      "epoch": 1.242265587815326,
      "grad_norm": 0.015518012456595898,
      "learning_rate": 1.751546882436935e-05,
      "loss": 0.0047,
      "step": 2610
    },
    {
      "epoch": 1.2470252260828176,
      "grad_norm": 0.12038449943065643,
      "learning_rate": 1.7505949547834366e-05,
      "loss": 0.0013,
      "step": 2620
    },
    {
      "epoch": 1.2517848643503093,
      "grad_norm": 17.385093688964844,
      "learning_rate": 1.7496430271299384e-05,
      "loss": 0.0298,
      "step": 2630
    },
    {
      "epoch": 1.256544502617801,
      "grad_norm": 7.362735271453857,
      "learning_rate": 1.7486910994764398e-05,
      "loss": 0.0804,
      "step": 2640
    },
    {
      "epoch": 1.2613041408852927,
      "grad_norm": 0.02911381796002388,
      "learning_rate": 1.7477391718229416e-05,
      "loss": 0.026,
      "step": 2650
    },
    {
      "epoch": 1.2660637791527845,
      "grad_norm": 0.004460329655557871,
      "learning_rate": 1.7467872441694434e-05,
      "loss": 0.0496,
      "step": 2660
    },
    {
      "epoch": 1.2708234174202762,
      "grad_norm": 0.010190386325120926,
      "learning_rate": 1.745835316515945e-05,
      "loss": 0.0206,
      "step": 2670
    },
    {
      "epoch": 1.2755830556877679,
      "grad_norm": 0.05997207760810852,
      "learning_rate": 1.7448833888624466e-05,
      "loss": 0.0104,
      "step": 2680
    },
    {
      "epoch": 1.2803426939552593,
      "grad_norm": 0.007869310677051544,
      "learning_rate": 1.7439314612089483e-05,
      "loss": 0.0287,
      "step": 2690
    },
    {
      "epoch": 1.285102332222751,
      "grad_norm": 5.504199981689453,
      "learning_rate": 1.74297953355545e-05,
      "loss": 0.0096,
      "step": 2700
    },
    {
      "epoch": 1.2898619704902428,
      "grad_norm": 0.0029661310836672783,
      "learning_rate": 1.7420276059019515e-05,
      "loss": 0.0331,
      "step": 2710
    },
    {
      "epoch": 1.2946216087577345,
      "grad_norm": 0.034940849989652634,
      "learning_rate": 1.7410756782484533e-05,
      "loss": 0.0351,
      "step": 2720
    },
    {
      "epoch": 1.299381247025226,
      "grad_norm": 0.29617950320243835,
      "learning_rate": 1.7401237505949547e-05,
      "loss": 0.0302,
      "step": 2730
    },
    {
      "epoch": 1.3041408852927177,
      "grad_norm": 0.048047903925180435,
      "learning_rate": 1.7391718229414568e-05,
      "loss": 0.0237,
      "step": 2740
    },
    {
      "epoch": 1.3089005235602094,
      "grad_norm": 0.029634427279233932,
      "learning_rate": 1.7382198952879583e-05,
      "loss": 0.024,
      "step": 2750
    },
    {
      "epoch": 1.313660161827701,
      "grad_norm": 0.16428282856941223,
      "learning_rate": 1.73726796763446e-05,
      "loss": 0.0069,
      "step": 2760
    },
    {
      "epoch": 1.3184198000951928,
      "grad_norm": 0.058748431503772736,
      "learning_rate": 1.7363160399809614e-05,
      "loss": 0.032,
      "step": 2770
    },
    {
      "epoch": 1.3231794383626845,
      "grad_norm": 0.25099146366119385,
      "learning_rate": 1.7353641123274632e-05,
      "loss": 0.0239,
      "step": 2780
    },
    {
      "epoch": 1.3279390766301762,
      "grad_norm": 0.008392120711505413,
      "learning_rate": 1.734412184673965e-05,
      "loss": 0.0602,
      "step": 2790
    },
    {
      "epoch": 1.332698714897668,
      "grad_norm": 0.0026688792277127504,
      "learning_rate": 1.7334602570204668e-05,
      "loss": 0.003,
      "step": 2800
    },
    {
      "epoch": 1.3374583531651594,
      "grad_norm": 0.2077026665210724,
      "learning_rate": 1.7325083293669682e-05,
      "loss": 0.0427,
      "step": 2810
    },
    {
      "epoch": 1.342217991432651,
      "grad_norm": 0.008049293421208858,
      "learning_rate": 1.73155640171347e-05,
      "loss": 0.0233,
      "step": 2820
    },
    {
      "epoch": 1.3469776297001428,
      "grad_norm": 0.7288013696670532,
      "learning_rate": 1.7306044740599717e-05,
      "loss": 0.0278,
      "step": 2830
    },
    {
      "epoch": 1.3517372679676345,
      "grad_norm": 0.021660232916474342,
      "learning_rate": 1.729652546406473e-05,
      "loss": 0.0199,
      "step": 2840
    },
    {
      "epoch": 1.3564969062351262,
      "grad_norm": 4.652676582336426,
      "learning_rate": 1.728700618752975e-05,
      "loss": 0.0541,
      "step": 2850
    },
    {
      "epoch": 1.3612565445026177,
      "grad_norm": 0.2432832270860672,
      "learning_rate": 1.7277486910994767e-05,
      "loss": 0.0063,
      "step": 2860
    },
    {
      "epoch": 1.3660161827701094,
      "grad_norm": 9.794720649719238,
      "learning_rate": 1.7267967634459785e-05,
      "loss": 0.0541,
      "step": 2870
    },
    {
      "epoch": 1.370775821037601,
      "grad_norm": 0.8689139485359192,
      "learning_rate": 1.72584483579248e-05,
      "loss": 0.0264,
      "step": 2880
    },
    {
      "epoch": 1.3755354593050928,
      "grad_norm": 0.007423905190080404,
      "learning_rate": 1.7248929081389816e-05,
      "loss": 0.0442,
      "step": 2890
    },
    {
      "epoch": 1.3802950975725845,
      "grad_norm": 0.059376060962677,
      "learning_rate": 1.723940980485483e-05,
      "loss": 0.0131,
      "step": 2900
    },
    {
      "epoch": 1.3850547358400762,
      "grad_norm": 0.016324231401085854,
      "learning_rate": 1.722989052831985e-05,
      "loss": 0.0178,
      "step": 2910
    },
    {
      "epoch": 1.389814374107568,
      "grad_norm": 0.00303660542704165,
      "learning_rate": 1.7220371251784866e-05,
      "loss": 0.0177,
      "step": 2920
    },
    {
      "epoch": 1.3945740123750596,
      "grad_norm": 7.5739312171936035,
      "learning_rate": 1.7210851975249884e-05,
      "loss": 0.0373,
      "step": 2930
    },
    {
      "epoch": 1.399333650642551,
      "grad_norm": 1.7304017543792725,
      "learning_rate": 1.7201332698714898e-05,
      "loss": 0.001,
      "step": 2940
    },
    {
      "epoch": 1.4040932889100428,
      "grad_norm": 0.027870379388332367,
      "learning_rate": 1.7191813422179916e-05,
      "loss": 0.0203,
      "step": 2950
    },
    {
      "epoch": 1.4088529271775345,
      "grad_norm": 0.047623470425605774,
      "learning_rate": 1.7182294145644933e-05,
      "loss": 0.0802,
      "step": 2960
    },
    {
      "epoch": 1.4136125654450262,
      "grad_norm": 0.017684493213891983,
      "learning_rate": 1.7172774869109948e-05,
      "loss": 0.045,
      "step": 2970
    },
    {
      "epoch": 1.418372203712518,
      "grad_norm": 0.007768215611577034,
      "learning_rate": 1.7163255592574965e-05,
      "loss": 0.0118,
      "step": 2980
    },
    {
      "epoch": 1.4231318419800094,
      "grad_norm": 0.12129693478345871,
      "learning_rate": 1.7153736316039983e-05,
      "loss": 0.024,
      "step": 2990
    },
    {
      "epoch": 1.4278914802475011,
      "grad_norm": 0.07679541409015656,
      "learning_rate": 1.7144217039505e-05,
      "loss": 0.0265,
      "step": 3000
    },
    {
      "epoch": 1.4326511185149928,
      "grad_norm": 0.021906603127717972,
      "learning_rate": 1.7134697762970015e-05,
      "loss": 0.0266,
      "step": 3010
    },
    {
      "epoch": 1.4374107567824845,
      "grad_norm": 0.40537768602371216,
      "learning_rate": 1.7125178486435033e-05,
      "loss": 0.0068,
      "step": 3020
    },
    {
      "epoch": 1.4421703950499762,
      "grad_norm": 6.045482635498047,
      "learning_rate": 1.7115659209900047e-05,
      "loss": 0.0449,
      "step": 3030
    },
    {
      "epoch": 1.446930033317468,
      "grad_norm": 0.027648573741316795,
      "learning_rate": 1.7106139933365065e-05,
      "loss": 0.0331,
      "step": 3040
    },
    {
      "epoch": 1.4516896715849597,
      "grad_norm": 0.015101036056876183,
      "learning_rate": 1.7096620656830082e-05,
      "loss": 0.0371,
      "step": 3050
    },
    {
      "epoch": 1.4564493098524511,
      "grad_norm": 0.02341952919960022,
      "learning_rate": 1.70871013802951e-05,
      "loss": 0.0363,
      "step": 3060
    },
    {
      "epoch": 1.4612089481199428,
      "grad_norm": 1.850764513015747,
      "learning_rate": 1.7077582103760114e-05,
      "loss": 0.0465,
      "step": 3070
    },
    {
      "epoch": 1.4659685863874345,
      "grad_norm": 0.11008060723543167,
      "learning_rate": 1.7068062827225132e-05,
      "loss": 0.0481,
      "step": 3080
    },
    {
      "epoch": 1.4707282246549263,
      "grad_norm": 0.17618627846240997,
      "learning_rate": 1.705854355069015e-05,
      "loss": 0.0202,
      "step": 3090
    },
    {
      "epoch": 1.475487862922418,
      "grad_norm": 1.735573410987854,
      "learning_rate": 1.7049024274155167e-05,
      "loss": 0.0175,
      "step": 3100
    },
    {
      "epoch": 1.4802475011899094,
      "grad_norm": 0.02127869613468647,
      "learning_rate": 1.7039504997620182e-05,
      "loss": 0.0283,
      "step": 3110
    },
    {
      "epoch": 1.4850071394574011,
      "grad_norm": 4.414459228515625,
      "learning_rate": 1.70299857210852e-05,
      "loss": 0.0205,
      "step": 3120
    },
    {
      "epoch": 1.4897667777248929,
      "grad_norm": 2.104881525039673,
      "learning_rate": 1.7020466444550217e-05,
      "loss": 0.0193,
      "step": 3130
    },
    {
      "epoch": 1.4945264159923846,
      "grad_norm": 0.3337547481060028,
      "learning_rate": 1.701094716801523e-05,
      "loss": 0.0008,
      "step": 3140
    },
    {
      "epoch": 1.4992860542598763,
      "grad_norm": 1.9887750148773193,
      "learning_rate": 1.700142789148025e-05,
      "loss": 0.0019,
      "step": 3150
    },
    {
      "epoch": 1.504045692527368,
      "grad_norm": 14.336126327514648,
      "learning_rate": 1.6991908614945263e-05,
      "loss": 0.0104,
      "step": 3160
    },
    {
      "epoch": 1.5088053307948597,
      "grad_norm": 10.04374885559082,
      "learning_rate": 1.698238933841028e-05,
      "loss": 0.0341,
      "step": 3170
    },
    {
      "epoch": 1.5135649690623514,
      "grad_norm": 0.09750846028327942,
      "learning_rate": 1.69728700618753e-05,
      "loss": 0.0226,
      "step": 3180
    },
    {
      "epoch": 1.518324607329843,
      "grad_norm": 0.31990674138069153,
      "learning_rate": 1.6963350785340316e-05,
      "loss": 0.0436,
      "step": 3190
    },
    {
      "epoch": 1.5230842455973346,
      "grad_norm": 0.21698729693889618,
      "learning_rate": 1.695383150880533e-05,
      "loss": 0.0014,
      "step": 3200
    },
    {
      "epoch": 1.5278438838648263,
      "grad_norm": 0.005702973809093237,
      "learning_rate": 1.694431223227035e-05,
      "loss": 0.0177,
      "step": 3210
    },
    {
      "epoch": 1.532603522132318,
      "grad_norm": 8.127224922180176,
      "learning_rate": 1.6934792955735366e-05,
      "loss": 0.0193,
      "step": 3220
    },
    {
      "epoch": 1.5373631603998095,
      "grad_norm": 0.004581486340612173,
      "learning_rate": 1.6925273679200384e-05,
      "loss": 0.0259,
      "step": 3230
    },
    {
      "epoch": 1.5421227986673012,
      "grad_norm": 0.000884090200997889,
      "learning_rate": 1.6915754402665398e-05,
      "loss": 0.0008,
      "step": 3240
    },
    {
      "epoch": 1.5468824369347929,
      "grad_norm": 0.5827223062515259,
      "learning_rate": 1.6906235126130416e-05,
      "loss": 0.0075,
      "step": 3250
    },
    {
      "epoch": 1.5516420752022846,
      "grad_norm": 0.035938166081905365,
      "learning_rate": 1.6896715849595433e-05,
      "loss": 0.0254,
      "step": 3260
    },
    {
      "epoch": 1.5564017134697763,
      "grad_norm": 0.001198625541292131,
      "learning_rate": 1.6887196573060448e-05,
      "loss": 0.0028,
      "step": 3270
    },
    {
      "epoch": 1.561161351737268,
      "grad_norm": 8.120851516723633,
      "learning_rate": 1.6877677296525465e-05,
      "loss": 0.0635,
      "step": 3280
    },
    {
      "epoch": 1.5659209900047597,
      "grad_norm": 9.702478408813477,
      "learning_rate": 1.6868158019990483e-05,
      "loss": 0.0126,
      "step": 3290
    },
    {
      "epoch": 1.5706806282722514,
      "grad_norm": 0.016930019482970238,
      "learning_rate": 1.6858638743455497e-05,
      "loss": 0.0369,
      "step": 3300
    },
    {
      "epoch": 1.5754402665397431,
      "grad_norm": 0.3794877231121063,
      "learning_rate": 1.6849119466920515e-05,
      "loss": 0.0165,
      "step": 3310
    },
    {
      "epoch": 1.5801999048072346,
      "grad_norm": 0.03123338147997856,
      "learning_rate": 1.6839600190385533e-05,
      "loss": 0.0414,
      "step": 3320
    },
    {
      "epoch": 1.5849595430747263,
      "grad_norm": 0.006366607267409563,
      "learning_rate": 1.6830080913850547e-05,
      "loss": 0.0266,
      "step": 3330
    },
    {
      "epoch": 1.589719181342218,
      "grad_norm": 0.01656199060380459,
      "learning_rate": 1.6820561637315565e-05,
      "loss": 0.0548,
      "step": 3340
    },
    {
      "epoch": 1.5944788196097095,
      "grad_norm": 0.023218587040901184,
      "learning_rate": 1.6811042360780582e-05,
      "loss": 0.01,
      "step": 3350
    },
    {
      "epoch": 1.5992384578772012,
      "grad_norm": 1.413880705833435,
      "learning_rate": 1.68015230842456e-05,
      "loss": 0.0066,
      "step": 3360
    },
    {
      "epoch": 1.603998096144693,
      "grad_norm": 8.042641639709473,
      "learning_rate": 1.6792003807710614e-05,
      "loss": 0.055,
      "step": 3370
    },
    {
      "epoch": 1.6087577344121846,
      "grad_norm": 0.5633682608604431,
      "learning_rate": 1.6782484531175632e-05,
      "loss": 0.0393,
      "step": 3380
    },
    {
      "epoch": 1.6135173726796763,
      "grad_norm": 7.874083042144775,
      "learning_rate": 1.677296525464065e-05,
      "loss": 0.0446,
      "step": 3390
    },
    {
      "epoch": 1.618277010947168,
      "grad_norm": 0.010589339770376682,
      "learning_rate": 1.6763445978105667e-05,
      "loss": 0.0409,
      "step": 3400
    },
    {
      "epoch": 1.6230366492146597,
      "grad_norm": 0.09858754277229309,
      "learning_rate": 1.675392670157068e-05,
      "loss": 0.0103,
      "step": 3410
    },
    {
      "epoch": 1.6277962874821514,
      "grad_norm": 3.445622205734253,
      "learning_rate": 1.67444074250357e-05,
      "loss": 0.0014,
      "step": 3420
    },
    {
      "epoch": 1.6325559257496431,
      "grad_norm": 0.057701434940099716,
      "learning_rate": 1.6734888148500717e-05,
      "loss": 0.0263,
      "step": 3430
    },
    {
      "epoch": 1.6373155640171349,
      "grad_norm": 0.02753497287631035,
      "learning_rate": 1.672536887196573e-05,
      "loss": 0.0297,
      "step": 3440
    },
    {
      "epoch": 1.6420752022846263,
      "grad_norm": 2.1111152172088623,
      "learning_rate": 1.671584959543075e-05,
      "loss": 0.0144,
      "step": 3450
    },
    {
      "epoch": 1.646834840552118,
      "grad_norm": 7.308213710784912,
      "learning_rate": 1.6706330318895763e-05,
      "loss": 0.0795,
      "step": 3460
    },
    {
      "epoch": 1.6515944788196097,
      "grad_norm": 0.0027862454298883677,
      "learning_rate": 1.669681104236078e-05,
      "loss": 0.0143,
      "step": 3470
    },
    {
      "epoch": 1.6563541170871012,
      "grad_norm": 0.00863543339073658,
      "learning_rate": 1.66872917658258e-05,
      "loss": 0.0212,
      "step": 3480
    },
    {
      "epoch": 1.661113755354593,
      "grad_norm": 5.95438289642334,
      "learning_rate": 1.6677772489290816e-05,
      "loss": 0.0209,
      "step": 3490
    },
    {
      "epoch": 1.6658733936220846,
      "grad_norm": 0.01284133829176426,
      "learning_rate": 1.666825321275583e-05,
      "loss": 0.0325,
      "step": 3500
    },
    {
      "epoch": 1.6706330318895763,
      "grad_norm": 0.00622060289606452,
      "learning_rate": 1.6658733936220848e-05,
      "loss": 0.0034,
      "step": 3510
    },
    {
      "epoch": 1.675392670157068,
      "grad_norm": 3.5162060260772705,
      "learning_rate": 1.6649214659685866e-05,
      "loss": 0.0143,
      "step": 3520
    },
    {
      "epoch": 1.6801523084245598,
      "grad_norm": 0.015495427884161472,
      "learning_rate": 1.6639695383150884e-05,
      "loss": 0.0123,
      "step": 3530
    },
    {
      "epoch": 1.6849119466920515,
      "grad_norm": 9.10948371887207,
      "learning_rate": 1.6630176106615898e-05,
      "loss": 0.0354,
      "step": 3540
    },
    {
      "epoch": 1.6896715849595432,
      "grad_norm": 0.946681559085846,
      "learning_rate": 1.6620656830080916e-05,
      "loss": 0.0055,
      "step": 3550
    },
    {
      "epoch": 1.6944312232270349,
      "grad_norm": 0.024180138483643532,
      "learning_rate": 1.6611137553545933e-05,
      "loss": 0.0004,
      "step": 3560
    },
    {
      "epoch": 1.6991908614945264,
      "grad_norm": 0.13952495157718658,
      "learning_rate": 1.6601618277010948e-05,
      "loss": 0.0074,
      "step": 3570
    },
    {
      "epoch": 1.703950499762018,
      "grad_norm": 0.00301263015717268,
      "learning_rate": 1.6592099000475965e-05,
      "loss": 0.0176,
      "step": 3580
    },
    {
      "epoch": 1.7087101380295098,
      "grad_norm": 0.06360751390457153,
      "learning_rate": 1.6582579723940983e-05,
      "loss": 0.0013,
      "step": 3590
    },
    {
      "epoch": 1.7134697762970015,
      "grad_norm": 0.0015591303817927837,
      "learning_rate": 1.6573060447405997e-05,
      "loss": 0.0228,
      "step": 3600
    },
    {
      "epoch": 1.718229414564493,
      "grad_norm": 0.010659188032150269,
      "learning_rate": 1.6563541170871015e-05,
      "loss": 0.0004,
      "step": 3610
    },
    {
      "epoch": 1.7229890528319847,
      "grad_norm": 0.18112608790397644,
      "learning_rate": 1.6554021894336033e-05,
      "loss": 0.0605,
      "step": 3620
    },
    {
      "epoch": 1.7277486910994764,
      "grad_norm": 0.18521396815776825,
      "learning_rate": 1.6544502617801047e-05,
      "loss": 0.0437,
      "step": 3630
    },
    {
      "epoch": 1.732508329366968,
      "grad_norm": 0.027486275881528854,
      "learning_rate": 1.6534983341266065e-05,
      "loss": 0.0495,
      "step": 3640
    },
    {
      "epoch": 1.7372679676344598,
      "grad_norm": 0.0018850828055292368,
      "learning_rate": 1.6525464064731082e-05,
      "loss": 0.0102,
      "step": 3650
    },
    {
      "epoch": 1.7420276059019515,
      "grad_norm": 0.5048877596855164,
      "learning_rate": 1.65159447881961e-05,
      "loss": 0.0154,
      "step": 3660
    },
    {
      "epoch": 1.7467872441694432,
      "grad_norm": 0.007003649603575468,
      "learning_rate": 1.6506425511661114e-05,
      "loss": 0.0404,
      "step": 3670
    },
    {
      "epoch": 1.751546882436935,
      "grad_norm": 0.039046697318553925,
      "learning_rate": 1.6496906235126132e-05,
      "loss": 0.0068,
      "step": 3680
    },
    {
      "epoch": 1.7563065207044266,
      "grad_norm": 0.004296480678021908,
      "learning_rate": 1.648738695859115e-05,
      "loss": 0.014,
      "step": 3690
    },
    {
      "epoch": 1.761066158971918,
      "grad_norm": 2.3690683841705322,
      "learning_rate": 1.6477867682056167e-05,
      "loss": 0.0322,
      "step": 3700
    },
    {
      "epoch": 1.7658257972394098,
      "grad_norm": 0.5519030690193176,
      "learning_rate": 1.646834840552118e-05,
      "loss": 0.024,
      "step": 3710
    },
    {
      "epoch": 1.7705854355069015,
      "grad_norm": 0.03441722318530083,
      "learning_rate": 1.64588291289862e-05,
      "loss": 0.0066,
      "step": 3720
    },
    {
      "epoch": 1.775345073774393,
      "grad_norm": 0.17409569025039673,
      "learning_rate": 1.6449309852451214e-05,
      "loss": 0.0231,
      "step": 3730
    },
    {
      "epoch": 1.7801047120418847,
      "grad_norm": 0.014359367080032825,
      "learning_rate": 1.643979057591623e-05,
      "loss": 0.0005,
      "step": 3740
    },
    {
      "epoch": 1.7848643503093764,
      "grad_norm": 10.344931602478027,
      "learning_rate": 1.643027129938125e-05,
      "loss": 0.0497,
      "step": 3750
    },
    {
      "epoch": 1.789623988576868,
      "grad_norm": 0.01732346974313259,
      "learning_rate": 1.6420752022846263e-05,
      "loss": 0.0149,
      "step": 3760
    },
    {
      "epoch": 1.7943836268443598,
      "grad_norm": 0.020639566704630852,
      "learning_rate": 1.641123274631128e-05,
      "loss": 0.0113,
      "step": 3770
    },
    {
      "epoch": 1.7991432651118515,
      "grad_norm": 0.116676464676857,
      "learning_rate": 1.64017134697763e-05,
      "loss": 0.0116,
      "step": 3780
    },
    {
      "epoch": 1.8039029033793432,
      "grad_norm": 0.09921343624591827,
      "learning_rate": 1.6392194193241316e-05,
      "loss": 0.023,
      "step": 3790
    },
    {
      "epoch": 1.808662541646835,
      "grad_norm": 0.40868696570396423,
      "learning_rate": 1.638267491670633e-05,
      "loss": 0.0088,
      "step": 3800
    },
    {
      "epoch": 1.8134221799143266,
      "grad_norm": 0.001134163816459477,
      "learning_rate": 1.6373155640171348e-05,
      "loss": 0.0319,
      "step": 3810
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.00045249497634358704,
      "learning_rate": 1.6363636363636366e-05,
      "loss": 0.0008,
      "step": 3820
    },
    {
      "epoch": 1.8229414564493098,
      "grad_norm": 0.0008214695262722671,
      "learning_rate": 1.6354117087101384e-05,
      "loss": 0.0293,
      "step": 3830
    },
    {
      "epoch": 1.8277010947168015,
      "grad_norm": 0.0031051128171384335,
      "learning_rate": 1.6344597810566398e-05,
      "loss": 0.0422,
      "step": 3840
    },
    {
      "epoch": 1.8324607329842932,
      "grad_norm": 0.01603873446583748,
      "learning_rate": 1.6335078534031416e-05,
      "loss": 0.0417,
      "step": 3850
    },
    {
      "epoch": 1.8372203712517847,
      "grad_norm": 0.44973787665367126,
      "learning_rate": 1.632555925749643e-05,
      "loss": 0.0369,
      "step": 3860
    },
    {
      "epoch": 1.8419800095192764,
      "grad_norm": 0.06598569452762604,
      "learning_rate": 1.6316039980961448e-05,
      "loss": 0.0425,
      "step": 3870
    },
    {
      "epoch": 1.8467396477867681,
      "grad_norm": 0.010306889191269875,
      "learning_rate": 1.6306520704426465e-05,
      "loss": 0.0041,
      "step": 3880
    },
    {
      "epoch": 1.8514992860542598,
      "grad_norm": 4.799066543579102,
      "learning_rate": 1.6297001427891483e-05,
      "loss": 0.0319,
      "step": 3890
    },
    {
      "epoch": 1.8562589243217515,
      "grad_norm": 26.484546661376953,
      "learning_rate": 1.6287482151356497e-05,
      "loss": 0.0205,
      "step": 3900
    },
    {
      "epoch": 1.8610185625892433,
      "grad_norm": 0.014418479055166245,
      "learning_rate": 1.6277962874821515e-05,
      "loss": 0.0249,
      "step": 3910
    },
    {
      "epoch": 1.865778200856735,
      "grad_norm": 0.01302367728203535,
      "learning_rate": 1.6268443598286533e-05,
      "loss": 0.0047,
      "step": 3920
    },
    {
      "epoch": 1.8705378391242267,
      "grad_norm": 0.0209514107555151,
      "learning_rate": 1.6258924321751547e-05,
      "loss": 0.0121,
      "step": 3930
    },
    {
      "epoch": 1.8752974773917184,
      "grad_norm": 2.129045009613037,
      "learning_rate": 1.6249405045216565e-05,
      "loss": 0.0367,
      "step": 3940
    },
    {
      "epoch": 1.8800571156592099,
      "grad_norm": 0.010674774646759033,
      "learning_rate": 1.6239885768681582e-05,
      "loss": 0.0496,
      "step": 3950
    },
    {
      "epoch": 1.8848167539267016,
      "grad_norm": 0.04558743163943291,
      "learning_rate": 1.62303664921466e-05,
      "loss": 0.0523,
      "step": 3960
    },
    {
      "epoch": 1.8895763921941933,
      "grad_norm": 0.42141881585121155,
      "learning_rate": 1.6220847215611614e-05,
      "loss": 0.0394,
      "step": 3970
    },
    {
      "epoch": 1.8943360304616848,
      "grad_norm": 0.01456391904503107,
      "learning_rate": 1.6211327939076632e-05,
      "loss": 0.0375,
      "step": 3980
    },
    {
      "epoch": 1.8990956687291765,
      "grad_norm": 2.5146710872650146,
      "learning_rate": 1.6201808662541646e-05,
      "loss": 0.0423,
      "step": 3990
    },
    {
      "epoch": 1.9038553069966682,
      "grad_norm": 0.09938240051269531,
      "learning_rate": 1.6192289386006664e-05,
      "loss": 0.0382,
      "step": 4000
    },
    {
      "epoch": 1.9086149452641599,
      "grad_norm": 5.439007759094238,
      "learning_rate": 1.618277010947168e-05,
      "loss": 0.0748,
      "step": 4010
    },
    {
      "epoch": 1.9133745835316516,
      "grad_norm": 0.5397865772247314,
      "learning_rate": 1.61732508329367e-05,
      "loss": 0.0047,
      "step": 4020
    },
    {
      "epoch": 1.9181342217991433,
      "grad_norm": 7.518881797790527,
      "learning_rate": 1.6163731556401713e-05,
      "loss": 0.0407,
      "step": 4030
    },
    {
      "epoch": 1.922893860066635,
      "grad_norm": 0.22930073738098145,
      "learning_rate": 1.615421227986673e-05,
      "loss": 0.0294,
      "step": 4040
    },
    {
      "epoch": 1.9276534983341267,
      "grad_norm": 0.06471747905015945,
      "learning_rate": 1.614469300333175e-05,
      "loss": 0.054,
      "step": 4050
    },
    {
      "epoch": 1.9324131366016184,
      "grad_norm": 3.5736587047576904,
      "learning_rate": 1.6135173726796763e-05,
      "loss": 0.0071,
      "step": 4060
    },
    {
      "epoch": 1.93717277486911,
      "grad_norm": 2.92161226272583,
      "learning_rate": 1.612565445026178e-05,
      "loss": 0.007,
      "step": 4070
    },
    {
      "epoch": 1.9419324131366016,
      "grad_norm": 0.013363040052354336,
      "learning_rate": 1.61161351737268e-05,
      "loss": 0.01,
      "step": 4080
    },
    {
      "epoch": 1.9466920514040933,
      "grad_norm": 0.04648473858833313,
      "learning_rate": 1.6106615897191816e-05,
      "loss": 0.0656,
      "step": 4090
    },
    {
      "epoch": 1.951451689671585,
      "grad_norm": 14.959131240844727,
      "learning_rate": 1.609709662065683e-05,
      "loss": 0.0403,
      "step": 4100
    },
    {
      "epoch": 1.9562113279390765,
      "grad_norm": 0.01278958935290575,
      "learning_rate": 1.6087577344121848e-05,
      "loss": 0.0212,
      "step": 4110
    },
    {
      "epoch": 1.9609709662065682,
      "grad_norm": 0.02688404731452465,
      "learning_rate": 1.6078058067586862e-05,
      "loss": 0.0002,
      "step": 4120
    },
    {
      "epoch": 1.96573060447406,
      "grad_norm": 3.909334659576416,
      "learning_rate": 1.6068538791051883e-05,
      "loss": 0.0023,
      "step": 4130
    },
    {
      "epoch": 1.9704902427415516,
      "grad_norm": 0.012972941622138023,
      "learning_rate": 1.6059019514516898e-05,
      "loss": 0.0141,
      "step": 4140
    },
    {
      "epoch": 1.9752498810090433,
      "grad_norm": 0.4561885595321655,
      "learning_rate": 1.6049500237981915e-05,
      "loss": 0.0315,
      "step": 4150
    },
    {
      "epoch": 1.980009519276535,
      "grad_norm": 0.005862798076122999,
      "learning_rate": 1.603998096144693e-05,
      "loss": 0.0006,
      "step": 4160
    },
    {
      "epoch": 1.9847691575440267,
      "grad_norm": 0.004867431707680225,
      "learning_rate": 1.6030461684911947e-05,
      "loss": 0.0008,
      "step": 4170
    },
    {
      "epoch": 1.9895287958115184,
      "grad_norm": 12.140314102172852,
      "learning_rate": 1.6020942408376965e-05,
      "loss": 0.0196,
      "step": 4180
    },
    {
      "epoch": 1.9942884340790101,
      "grad_norm": 0.018640493974089622,
      "learning_rate": 1.601142313184198e-05,
      "loss": 0.0359,
      "step": 4190
    },
    {
      "epoch": 1.9990480723465016,
      "grad_norm": 14.949722290039062,
      "learning_rate": 1.6001903855306997e-05,
      "loss": 0.0412,
      "step": 4200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9942361111111111,
      "eval_f1": 0.9685962920923192,
      "eval_loss": 0.02494698390364647,
      "eval_precision": 0.9763539282990084,
      "eval_recall": 0.960960960960961,
      "eval_runtime": 336.7748,
      "eval_samples_per_second": 42.791,
      "eval_steps_per_second": 1.339,
      "step": 4202
    },
    {
      "epoch": 2.0038077106139935,
      "grad_norm": 0.07681022584438324,
      "learning_rate": 1.5992384578772015e-05,
      "loss": 0.0007,
      "step": 4210
    },
    {
      "epoch": 2.008567348881485,
      "grad_norm": 0.013725784607231617,
      "learning_rate": 1.5982865302237032e-05,
      "loss": 0.0072,
      "step": 4220
    },
    {
      "epoch": 2.0133269871489765,
      "grad_norm": 0.05097142606973648,
      "learning_rate": 1.5973346025702047e-05,
      "loss": 0.0084,
      "step": 4230
    },
    {
      "epoch": 2.018086625416468,
      "grad_norm": 5.102477550506592,
      "learning_rate": 1.5963826749167064e-05,
      "loss": 0.0329,
      "step": 4240
    },
    {
      "epoch": 2.02284626368396,
      "grad_norm": 0.004439414944499731,
      "learning_rate": 1.5954307472632082e-05,
      "loss": 0.0199,
      "step": 4250
    },
    {
      "epoch": 2.0276059019514516,
      "grad_norm": 0.007108118385076523,
      "learning_rate": 1.59447881960971e-05,
      "loss": 0.0046,
      "step": 4260
    },
    {
      "epoch": 2.0323655402189433,
      "grad_norm": 0.03542080894112587,
      "learning_rate": 1.5935268919562114e-05,
      "loss": 0.0028,
      "step": 4270
    },
    {
      "epoch": 2.037125178486435,
      "grad_norm": 0.017537744715809822,
      "learning_rate": 1.5925749643027132e-05,
      "loss": 0.0341,
      "step": 4280
    },
    {
      "epoch": 2.0418848167539267,
      "grad_norm": 3.277435064315796,
      "learning_rate": 1.5916230366492146e-05,
      "loss": 0.0081,
      "step": 4290
    },
    {
      "epoch": 2.0466444550214185,
      "grad_norm": 1.8854917287826538,
      "learning_rate": 1.5906711089957164e-05,
      "loss": 0.0012,
      "step": 4300
    },
    {
      "epoch": 2.05140409328891,
      "grad_norm": 0.07311420887708664,
      "learning_rate": 1.589719181342218e-05,
      "loss": 0.0008,
      "step": 4310
    },
    {
      "epoch": 2.056163731556402,
      "grad_norm": 0.009451169520616531,
      "learning_rate": 1.58876725368872e-05,
      "loss": 0.008,
      "step": 4320
    },
    {
      "epoch": 2.0609233698238936,
      "grad_norm": 0.16013918817043304,
      "learning_rate": 1.5878153260352213e-05,
      "loss": 0.0245,
      "step": 4330
    },
    {
      "epoch": 2.0656830080913853,
      "grad_norm": 0.14314024150371552,
      "learning_rate": 1.586863398381723e-05,
      "loss": 0.0002,
      "step": 4340
    },
    {
      "epoch": 2.0704426463588765,
      "grad_norm": 0.045630697160959244,
      "learning_rate": 1.585911470728225e-05,
      "loss": 0.018,
      "step": 4350
    },
    {
      "epoch": 2.0752022846263682,
      "grad_norm": 0.03656235709786415,
      "learning_rate": 1.5849595430747263e-05,
      "loss": 0.0076,
      "step": 4360
    },
    {
      "epoch": 2.07996192289386,
      "grad_norm": 0.008484436199069023,
      "learning_rate": 1.584007615421228e-05,
      "loss": 0.0289,
      "step": 4370
    },
    {
      "epoch": 2.0847215611613517,
      "grad_norm": 0.060307156294584274,
      "learning_rate": 1.58305568776773e-05,
      "loss": 0.0389,
      "step": 4380
    },
    {
      "epoch": 2.0894811994288434,
      "grad_norm": 0.017334187403321266,
      "learning_rate": 1.5821037601142316e-05,
      "loss": 0.0198,
      "step": 4390
    },
    {
      "epoch": 2.094240837696335,
      "grad_norm": 0.02447885274887085,
      "learning_rate": 1.581151832460733e-05,
      "loss": 0.0018,
      "step": 4400
    },
    {
      "epoch": 2.0990004759638268,
      "grad_norm": 0.014792210422456264,
      "learning_rate": 1.5801999048072348e-05,
      "loss": 0.0004,
      "step": 4410
    },
    {
      "epoch": 2.1037601142313185,
      "grad_norm": 0.02657587267458439,
      "learning_rate": 1.5792479771537362e-05,
      "loss": 0.0003,
      "step": 4420
    },
    {
      "epoch": 2.10851975249881,
      "grad_norm": 0.0035939388908445835,
      "learning_rate": 1.5782960495002383e-05,
      "loss": 0.0168,
      "step": 4430
    },
    {
      "epoch": 2.113279390766302,
      "grad_norm": 0.00586711335927248,
      "learning_rate": 1.5773441218467398e-05,
      "loss": 0.0268,
      "step": 4440
    },
    {
      "epoch": 2.1180390290337936,
      "grad_norm": 0.009817948564887047,
      "learning_rate": 1.5763921941932415e-05,
      "loss": 0.0178,
      "step": 4450
    },
    {
      "epoch": 2.1227986673012853,
      "grad_norm": 0.06049734354019165,
      "learning_rate": 1.575440266539743e-05,
      "loss": 0.0037,
      "step": 4460
    },
    {
      "epoch": 2.127558305568777,
      "grad_norm": 8.0244140625,
      "learning_rate": 1.5744883388862447e-05,
      "loss": 0.0153,
      "step": 4470
    },
    {
      "epoch": 2.1323179438362683,
      "grad_norm": 0.03233499079942703,
      "learning_rate": 1.5735364112327465e-05,
      "loss": 0.0113,
      "step": 4480
    },
    {
      "epoch": 2.13707758210376,
      "grad_norm": 0.17561496794223785,
      "learning_rate": 1.572584483579248e-05,
      "loss": 0.0267,
      "step": 4490
    },
    {
      "epoch": 2.1418372203712517,
      "grad_norm": 0.003818198572844267,
      "learning_rate": 1.5716325559257497e-05,
      "loss": 0.0347,
      "step": 4500
    },
    {
      "epoch": 2.1465968586387434,
      "grad_norm": 0.0052559529431164265,
      "learning_rate": 1.5706806282722515e-05,
      "loss": 0.0007,
      "step": 4510
    },
    {
      "epoch": 2.151356496906235,
      "grad_norm": 0.007220067083835602,
      "learning_rate": 1.5697287006187532e-05,
      "loss": 0.0461,
      "step": 4520
    },
    {
      "epoch": 2.156116135173727,
      "grad_norm": 0.0017813334707170725,
      "learning_rate": 1.5687767729652547e-05,
      "loss": 0.0004,
      "step": 4530
    },
    {
      "epoch": 2.1608757734412185,
      "grad_norm": 0.014142153784632683,
      "learning_rate": 1.5678248453117564e-05,
      "loss": 0.052,
      "step": 4540
    },
    {
      "epoch": 2.16563541170871,
      "grad_norm": 0.9440646767616272,
      "learning_rate": 1.566872917658258e-05,
      "loss": 0.0194,
      "step": 4550
    },
    {
      "epoch": 2.170395049976202,
      "grad_norm": 1.016788363456726,
      "learning_rate": 1.56592099000476e-05,
      "loss": 0.0303,
      "step": 4560
    },
    {
      "epoch": 2.1751546882436936,
      "grad_norm": 0.00262212916277349,
      "learning_rate": 1.5649690623512614e-05,
      "loss": 0.0023,
      "step": 4570
    },
    {
      "epoch": 2.1799143265111853,
      "grad_norm": 0.011509875766932964,
      "learning_rate": 1.564017134697763e-05,
      "loss": 0.0015,
      "step": 4580
    },
    {
      "epoch": 2.1846739647786766,
      "grad_norm": 4.727528095245361,
      "learning_rate": 1.5630652070442646e-05,
      "loss": 0.0318,
      "step": 4590
    },
    {
      "epoch": 2.1894336030461683,
      "grad_norm": 0.007280151359736919,
      "learning_rate": 1.5621132793907664e-05,
      "loss": 0.0054,
      "step": 4600
    },
    {
      "epoch": 2.19419324131366,
      "grad_norm": 1.2632650136947632,
      "learning_rate": 1.561161351737268e-05,
      "loss": 0.0921,
      "step": 4610
    },
    {
      "epoch": 2.1989528795811517,
      "grad_norm": 0.01568128913640976,
      "learning_rate": 1.56020942408377e-05,
      "loss": 0.0034,
      "step": 4620
    },
    {
      "epoch": 2.2037125178486434,
      "grad_norm": 0.06355202198028564,
      "learning_rate": 1.5592574964302713e-05,
      "loss": 0.0054,
      "step": 4630
    },
    {
      "epoch": 2.208472156116135,
      "grad_norm": 0.0057923272252082825,
      "learning_rate": 1.558305568776773e-05,
      "loss": 0.0293,
      "step": 4640
    },
    {
      "epoch": 2.213231794383627,
      "grad_norm": 8.298868179321289,
      "learning_rate": 1.557353641123275e-05,
      "loss": 0.0308,
      "step": 4650
    },
    {
      "epoch": 2.2179914326511185,
      "grad_norm": 0.007720001973211765,
      "learning_rate": 1.5564017134697763e-05,
      "loss": 0.0096,
      "step": 4660
    },
    {
      "epoch": 2.2227510709186102,
      "grad_norm": 0.010454213246703148,
      "learning_rate": 1.555449785816278e-05,
      "loss": 0.0349,
      "step": 4670
    },
    {
      "epoch": 2.227510709186102,
      "grad_norm": 0.024839526042342186,
      "learning_rate": 1.5544978581627795e-05,
      "loss": 0.0044,
      "step": 4680
    },
    {
      "epoch": 2.2322703474535937,
      "grad_norm": 2.6073968410491943,
      "learning_rate": 1.5535459305092816e-05,
      "loss": 0.001,
      "step": 4690
    },
    {
      "epoch": 2.2370299857210854,
      "grad_norm": 0.007180220913141966,
      "learning_rate": 1.552594002855783e-05,
      "loss": 0.002,
      "step": 4700
    },
    {
      "epoch": 2.241789623988577,
      "grad_norm": 0.050902582705020905,
      "learning_rate": 1.5516420752022848e-05,
      "loss": 0.0455,
      "step": 4710
    },
    {
      "epoch": 2.2465492622560683,
      "grad_norm": 0.12157653272151947,
      "learning_rate": 1.5506901475487862e-05,
      "loss": 0.0128,
      "step": 4720
    },
    {
      "epoch": 2.25130890052356,
      "grad_norm": 0.014900729060173035,
      "learning_rate": 1.5497382198952883e-05,
      "loss": 0.0232,
      "step": 4730
    },
    {
      "epoch": 2.2560685387910517,
      "grad_norm": 7.601785659790039,
      "learning_rate": 1.5487862922417898e-05,
      "loss": 0.0016,
      "step": 4740
    },
    {
      "epoch": 2.2608281770585434,
      "grad_norm": 0.027139587327837944,
      "learning_rate": 1.5478343645882915e-05,
      "loss": 0.0013,
      "step": 4750
    },
    {
      "epoch": 2.265587815326035,
      "grad_norm": 0.002964112674817443,
      "learning_rate": 1.546882436934793e-05,
      "loss": 0.0012,
      "step": 4760
    },
    {
      "epoch": 2.270347453593527,
      "grad_norm": 0.4448472857475281,
      "learning_rate": 1.5459305092812947e-05,
      "loss": 0.011,
      "step": 4770
    },
    {
      "epoch": 2.2751070918610186,
      "grad_norm": 0.0011259643360972404,
      "learning_rate": 1.5449785816277965e-05,
      "loss": 0.0001,
      "step": 4780
    },
    {
      "epoch": 2.2798667301285103,
      "grad_norm": 0.006081963423639536,
      "learning_rate": 1.544026653974298e-05,
      "loss": 0.0002,
      "step": 4790
    },
    {
      "epoch": 2.284626368396002,
      "grad_norm": 0.0013317313278093934,
      "learning_rate": 1.5430747263207997e-05,
      "loss": 0.0238,
      "step": 4800
    },
    {
      "epoch": 2.2893860066634937,
      "grad_norm": 0.0011405495461076498,
      "learning_rate": 1.5421227986673015e-05,
      "loss": 0.0244,
      "step": 4810
    },
    {
      "epoch": 2.2941456449309854,
      "grad_norm": 0.0024017062969505787,
      "learning_rate": 1.5411708710138032e-05,
      "loss": 0.0301,
      "step": 4820
    },
    {
      "epoch": 2.298905283198477,
      "grad_norm": 0.0041159698739647865,
      "learning_rate": 1.5402189433603047e-05,
      "loss": 0.0017,
      "step": 4830
    },
    {
      "epoch": 2.303664921465969,
      "grad_norm": 0.048877835273742676,
      "learning_rate": 1.5392670157068064e-05,
      "loss": 0.0403,
      "step": 4840
    },
    {
      "epoch": 2.30842455973346,
      "grad_norm": 0.01711835339665413,
      "learning_rate": 1.538315088053308e-05,
      "loss": 0.0289,
      "step": 4850
    },
    {
      "epoch": 2.3131841980009518,
      "grad_norm": 0.0068265823647379875,
      "learning_rate": 1.53736316039981e-05,
      "loss": 0.0027,
      "step": 4860
    },
    {
      "epoch": 2.3179438362684435,
      "grad_norm": 0.016409751027822495,
      "learning_rate": 1.5364112327463114e-05,
      "loss": 0.0107,
      "step": 4870
    },
    {
      "epoch": 2.322703474535935,
      "grad_norm": 0.057998161762952805,
      "learning_rate": 1.535459305092813e-05,
      "loss": 0.0155,
      "step": 4880
    },
    {
      "epoch": 2.327463112803427,
      "grad_norm": 0.007888220250606537,
      "learning_rate": 1.5345073774393146e-05,
      "loss": 0.0034,
      "step": 4890
    },
    {
      "epoch": 2.3322227510709186,
      "grad_norm": 0.012820580042898655,
      "learning_rate": 1.5335554497858164e-05,
      "loss": 0.0379,
      "step": 4900
    },
    {
      "epoch": 2.3369823893384103,
      "grad_norm": 0.016237439587712288,
      "learning_rate": 1.532603522132318e-05,
      "loss": 0.0296,
      "step": 4910
    },
    {
      "epoch": 2.341742027605902,
      "grad_norm": 0.01408627349883318,
      "learning_rate": 1.53165159447882e-05,
      "loss": 0.0111,
      "step": 4920
    },
    {
      "epoch": 2.3465016658733937,
      "grad_norm": 0.005931472405791283,
      "learning_rate": 1.5306996668253213e-05,
      "loss": 0.0055,
      "step": 4930
    },
    {
      "epoch": 2.3512613041408854,
      "grad_norm": 0.017806844785809517,
      "learning_rate": 1.529747739171823e-05,
      "loss": 0.0054,
      "step": 4940
    },
    {
      "epoch": 2.356020942408377,
      "grad_norm": 0.00784607045352459,
      "learning_rate": 1.528795811518325e-05,
      "loss": 0.0039,
      "step": 4950
    },
    {
      "epoch": 2.360780580675869,
      "grad_norm": 0.012492021545767784,
      "learning_rate": 1.5278438838648263e-05,
      "loss": 0.0025,
      "step": 4960
    },
    {
      "epoch": 2.3655402189433605,
      "grad_norm": 0.004252854734659195,
      "learning_rate": 1.526891956211328e-05,
      "loss": 0.018,
      "step": 4970
    },
    {
      "epoch": 2.370299857210852,
      "grad_norm": 0.0009522207546979189,
      "learning_rate": 1.5259400285578295e-05,
      "loss": 0.0016,
      "step": 4980
    },
    {
      "epoch": 2.3750594954783435,
      "grad_norm": 0.01618332974612713,
      "learning_rate": 1.5249881009043314e-05,
      "loss": 0.0001,
      "step": 4990
    },
    {
      "epoch": 2.379819133745835,
      "grad_norm": 12.480738639831543,
      "learning_rate": 1.524036173250833e-05,
      "loss": 0.0588,
      "step": 5000
    },
    {
      "epoch": 2.384578772013327,
      "grad_norm": 0.016800861805677414,
      "learning_rate": 1.5230842455973346e-05,
      "loss": 0.071,
      "step": 5010
    },
    {
      "epoch": 2.3893384102808186,
      "grad_norm": 13.398048400878906,
      "learning_rate": 1.5221323179438364e-05,
      "loss": 0.0078,
      "step": 5020
    },
    {
      "epoch": 2.3940980485483103,
      "grad_norm": 0.14023329317569733,
      "learning_rate": 1.5211803902903382e-05,
      "loss": 0.0008,
      "step": 5030
    },
    {
      "epoch": 2.398857686815802,
      "grad_norm": 0.003471244126558304,
      "learning_rate": 1.5202284626368398e-05,
      "loss": 0.0085,
      "step": 5040
    },
    {
      "epoch": 2.4036173250832937,
      "grad_norm": 0.0024177180603146553,
      "learning_rate": 1.5192765349833414e-05,
      "loss": 0.0039,
      "step": 5050
    },
    {
      "epoch": 2.4083769633507854,
      "grad_norm": 0.004934551194310188,
      "learning_rate": 1.518324607329843e-05,
      "loss": 0.0435,
      "step": 5060
    },
    {
      "epoch": 2.413136601618277,
      "grad_norm": 0.007524383720010519,
      "learning_rate": 1.5173726796763449e-05,
      "loss": 0.0209,
      "step": 5070
    },
    {
      "epoch": 2.417896239885769,
      "grad_norm": 0.002104988554492593,
      "learning_rate": 1.5164207520228465e-05,
      "loss": 0.0199,
      "step": 5080
    },
    {
      "epoch": 2.42265587815326,
      "grad_norm": 0.12446433305740356,
      "learning_rate": 1.5154688243693481e-05,
      "loss": 0.0026,
      "step": 5090
    },
    {
      "epoch": 2.4274155164207523,
      "grad_norm": 0.006231680046766996,
      "learning_rate": 1.5145168967158497e-05,
      "loss": 0.0082,
      "step": 5100
    },
    {
      "epoch": 2.4321751546882435,
      "grad_norm": 13.108795166015625,
      "learning_rate": 1.5135649690623513e-05,
      "loss": 0.0383,
      "step": 5110
    },
    {
      "epoch": 2.4369347929557352,
      "grad_norm": 0.20471057295799255,
      "learning_rate": 1.512613041408853e-05,
      "loss": 0.0003,
      "step": 5120
    },
    {
      "epoch": 2.441694431223227,
      "grad_norm": 0.06400719285011292,
      "learning_rate": 1.5116611137553548e-05,
      "loss": 0.0016,
      "step": 5130
    },
    {
      "epoch": 2.4464540694907186,
      "grad_norm": 0.6588037610054016,
      "learning_rate": 1.5107091861018564e-05,
      "loss": 0.0106,
      "step": 5140
    },
    {
      "epoch": 2.4512137077582103,
      "grad_norm": 0.0020964830182492733,
      "learning_rate": 1.509757258448358e-05,
      "loss": 0.005,
      "step": 5150
    },
    {
      "epoch": 2.455973346025702,
      "grad_norm": 10.345178604125977,
      "learning_rate": 1.5088053307948598e-05,
      "loss": 0.0286,
      "step": 5160
    },
    {
      "epoch": 2.4607329842931938,
      "grad_norm": 0.0014006269630044699,
      "learning_rate": 1.5078534031413614e-05,
      "loss": 0.0376,
      "step": 5170
    },
    {
      "epoch": 2.4654926225606855,
      "grad_norm": 0.002114091534167528,
      "learning_rate": 1.506901475487863e-05,
      "loss": 0.0097,
      "step": 5180
    },
    {
      "epoch": 2.470252260828177,
      "grad_norm": 0.0033033096697181463,
      "learning_rate": 1.5059495478343646e-05,
      "loss": 0.0317,
      "step": 5190
    },
    {
      "epoch": 2.475011899095669,
      "grad_norm": 0.009823376312851906,
      "learning_rate": 1.5049976201808665e-05,
      "loss": 0.0004,
      "step": 5200
    },
    {
      "epoch": 2.4797715373631606,
      "grad_norm": 0.03416627272963524,
      "learning_rate": 1.5040456925273681e-05,
      "loss": 0.0258,
      "step": 5210
    },
    {
      "epoch": 2.484531175630652,
      "grad_norm": 14.177628517150879,
      "learning_rate": 1.5030937648738697e-05,
      "loss": 0.0309,
      "step": 5220
    },
    {
      "epoch": 2.4892908138981436,
      "grad_norm": 0.008978133089840412,
      "learning_rate": 1.5021418372203713e-05,
      "loss": 0.0033,
      "step": 5230
    },
    {
      "epoch": 2.4940504521656353,
      "grad_norm": 0.756194531917572,
      "learning_rate": 1.5011899095668729e-05,
      "loss": 0.0287,
      "step": 5240
    },
    {
      "epoch": 2.498810090433127,
      "grad_norm": 0.007742404472082853,
      "learning_rate": 1.5002379819133749e-05,
      "loss": 0.0021,
      "step": 5250
    },
    {
      "epoch": 2.5035697287006187,
      "grad_norm": 1.8560981750488281,
      "learning_rate": 1.4992860542598764e-05,
      "loss": 0.0359,
      "step": 5260
    },
    {
      "epoch": 2.5083293669681104,
      "grad_norm": 0.005951140075922012,
      "learning_rate": 1.498334126606378e-05,
      "loss": 0.0161,
      "step": 5270
    },
    {
      "epoch": 2.513089005235602,
      "grad_norm": 0.004762440454214811,
      "learning_rate": 1.4973821989528796e-05,
      "loss": 0.035,
      "step": 5280
    },
    {
      "epoch": 2.517848643503094,
      "grad_norm": 3.5016393661499023,
      "learning_rate": 1.4964302712993814e-05,
      "loss": 0.0396,
      "step": 5290
    },
    {
      "epoch": 2.5226082817705855,
      "grad_norm": 0.45570847392082214,
      "learning_rate": 1.495478343645883e-05,
      "loss": 0.0379,
      "step": 5300
    },
    {
      "epoch": 2.527367920038077,
      "grad_norm": 0.028635460883378983,
      "learning_rate": 1.4945264159923846e-05,
      "loss": 0.0026,
      "step": 5310
    },
    {
      "epoch": 2.532127558305569,
      "grad_norm": 13.02126407623291,
      "learning_rate": 1.4935744883388864e-05,
      "loss": 0.0045,
      "step": 5320
    },
    {
      "epoch": 2.5368871965730606,
      "grad_norm": 0.006323843728750944,
      "learning_rate": 1.4926225606853881e-05,
      "loss": 0.0076,
      "step": 5330
    },
    {
      "epoch": 2.5416468348405523,
      "grad_norm": 0.00794199574738741,
      "learning_rate": 1.4916706330318897e-05,
      "loss": 0.0096,
      "step": 5340
    },
    {
      "epoch": 2.5464064731080436,
      "grad_norm": 0.07385560870170593,
      "learning_rate": 1.4907187053783913e-05,
      "loss": 0.0054,
      "step": 5350
    },
    {
      "epoch": 2.5511661113755357,
      "grad_norm": 0.008644611574709415,
      "learning_rate": 1.489766777724893e-05,
      "loss": 0.0141,
      "step": 5360
    },
    {
      "epoch": 2.555925749643027,
      "grad_norm": 0.024127550423145294,
      "learning_rate": 1.4888148500713945e-05,
      "loss": 0.0122,
      "step": 5370
    },
    {
      "epoch": 2.5606853879105187,
      "grad_norm": 0.011296682991087437,
      "learning_rate": 1.4878629224178965e-05,
      "loss": 0.0482,
      "step": 5380
    },
    {
      "epoch": 2.5654450261780104,
      "grad_norm": 8.492900848388672,
      "learning_rate": 1.486910994764398e-05,
      "loss": 0.0406,
      "step": 5390
    },
    {
      "epoch": 2.570204664445502,
      "grad_norm": 0.012006131000816822,
      "learning_rate": 1.4859590671108997e-05,
      "loss": 0.0199,
      "step": 5400
    },
    {
      "epoch": 2.574964302712994,
      "grad_norm": 0.03175310790538788,
      "learning_rate": 1.4850071394574013e-05,
      "loss": 0.0236,
      "step": 5410
    },
    {
      "epoch": 2.5797239409804855,
      "grad_norm": 0.03772789239883423,
      "learning_rate": 1.484055211803903e-05,
      "loss": 0.0022,
      "step": 5420
    },
    {
      "epoch": 2.5844835792479772,
      "grad_norm": 0.0442085787653923,
      "learning_rate": 1.4831032841504046e-05,
      "loss": 0.0239,
      "step": 5430
    },
    {
      "epoch": 2.589243217515469,
      "grad_norm": 0.7399950623512268,
      "learning_rate": 1.4821513564969064e-05,
      "loss": 0.0221,
      "step": 5440
    },
    {
      "epoch": 2.5940028557829606,
      "grad_norm": 0.01563747227191925,
      "learning_rate": 1.481199428843408e-05,
      "loss": 0.0353,
      "step": 5450
    },
    {
      "epoch": 2.598762494050452,
      "grad_norm": 8.130390167236328,
      "learning_rate": 1.4802475011899098e-05,
      "loss": 0.0037,
      "step": 5460
    },
    {
      "epoch": 2.603522132317944,
      "grad_norm": 4.1800217628479,
      "learning_rate": 1.4792955735364114e-05,
      "loss": 0.0015,
      "step": 5470
    },
    {
      "epoch": 2.6082817705854353,
      "grad_norm": 1.2862509489059448,
      "learning_rate": 1.478343645882913e-05,
      "loss": 0.0018,
      "step": 5480
    },
    {
      "epoch": 2.613041408852927,
      "grad_norm": 0.24455009400844574,
      "learning_rate": 1.4773917182294146e-05,
      "loss": 0.0179,
      "step": 5490
    },
    {
      "epoch": 2.6178010471204187,
      "grad_norm": 0.0024528279900550842,
      "learning_rate": 1.4764397905759162e-05,
      "loss": 0.0014,
      "step": 5500
    },
    {
      "epoch": 2.6225606853879104,
      "grad_norm": 0.004900657571852207,
      "learning_rate": 1.4754878629224181e-05,
      "loss": 0.009,
      "step": 5510
    },
    {
      "epoch": 2.627320323655402,
      "grad_norm": 0.00783128384500742,
      "learning_rate": 1.4745359352689197e-05,
      "loss": 0.0024,
      "step": 5520
    },
    {
      "epoch": 2.632079961922894,
      "grad_norm": 0.005068945698440075,
      "learning_rate": 1.4735840076154213e-05,
      "loss": 0.0327,
      "step": 5530
    },
    {
      "epoch": 2.6368396001903855,
      "grad_norm": 0.08890741318464279,
      "learning_rate": 1.4726320799619229e-05,
      "loss": 0.0031,
      "step": 5540
    },
    {
      "epoch": 2.6415992384578773,
      "grad_norm": 0.2569676339626312,
      "learning_rate": 1.4716801523084248e-05,
      "loss": 0.0002,
      "step": 5550
    },
    {
      "epoch": 2.646358876725369,
      "grad_norm": 13.635313987731934,
      "learning_rate": 1.4707282246549264e-05,
      "loss": 0.0387,
      "step": 5560
    },
    {
      "epoch": 2.6511185149928607,
      "grad_norm": 0.00263157207518816,
      "learning_rate": 1.469776297001428e-05,
      "loss": 0.0002,
      "step": 5570
    },
    {
      "epoch": 2.6558781532603524,
      "grad_norm": 0.0066191949881613255,
      "learning_rate": 1.4688243693479296e-05,
      "loss": 0.0093,
      "step": 5580
    },
    {
      "epoch": 2.6606377915278436,
      "grad_norm": 0.015339745208621025,
      "learning_rate": 1.4678724416944314e-05,
      "loss": 0.0385,
      "step": 5590
    },
    {
      "epoch": 2.665397429795336,
      "grad_norm": 0.02427814155817032,
      "learning_rate": 1.466920514040933e-05,
      "loss": 0.0001,
      "step": 5600
    },
    {
      "epoch": 2.670157068062827,
      "grad_norm": 0.0010705451713874936,
      "learning_rate": 1.4659685863874346e-05,
      "loss": 0.0009,
      "step": 5610
    },
    {
      "epoch": 2.6749167063303187,
      "grad_norm": 0.200480654835701,
      "learning_rate": 1.4650166587339362e-05,
      "loss": 0.0682,
      "step": 5620
    },
    {
      "epoch": 2.6796763445978105,
      "grad_norm": 6.565079689025879,
      "learning_rate": 1.4640647310804381e-05,
      "loss": 0.0203,
      "step": 5630
    },
    {
      "epoch": 2.684435982865302,
      "grad_norm": 0.0032697028946131468,
      "learning_rate": 1.4631128034269397e-05,
      "loss": 0.0123,
      "step": 5640
    },
    {
      "epoch": 2.689195621132794,
      "grad_norm": 0.0030078766867518425,
      "learning_rate": 1.4621608757734413e-05,
      "loss": 0.0185,
      "step": 5650
    },
    {
      "epoch": 2.6939552594002856,
      "grad_norm": 0.006365729495882988,
      "learning_rate": 1.461208948119943e-05,
      "loss": 0.0011,
      "step": 5660
    },
    {
      "epoch": 2.6987148976677773,
      "grad_norm": 1.0228087902069092,
      "learning_rate": 1.4602570204664445e-05,
      "loss": 0.0027,
      "step": 5670
    },
    {
      "epoch": 2.703474535935269,
      "grad_norm": 0.011321362107992172,
      "learning_rate": 1.4593050928129465e-05,
      "loss": 0.0165,
      "step": 5680
    },
    {
      "epoch": 2.7082341742027607,
      "grad_norm": 0.0046654739417135715,
      "learning_rate": 1.458353165159448e-05,
      "loss": 0.0118,
      "step": 5690
    },
    {
      "epoch": 2.7129938124702524,
      "grad_norm": 0.003721521934494376,
      "learning_rate": 1.4574012375059497e-05,
      "loss": 0.0027,
      "step": 5700
    },
    {
      "epoch": 2.717753450737744,
      "grad_norm": 0.004720995668321848,
      "learning_rate": 1.4564493098524513e-05,
      "loss": 0.0011,
      "step": 5710
    },
    {
      "epoch": 2.7225130890052354,
      "grad_norm": 0.011557945981621742,
      "learning_rate": 1.455497382198953e-05,
      "loss": 0.0103,
      "step": 5720
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 4.319119930267334,
      "learning_rate": 1.4545454545454546e-05,
      "loss": 0.0184,
      "step": 5730
    },
    {
      "epoch": 2.7320323655402188,
      "grad_norm": 0.022542843595147133,
      "learning_rate": 1.4535935268919564e-05,
      "loss": 0.0001,
      "step": 5740
    },
    {
      "epoch": 2.7367920038077105,
      "grad_norm": 7.358269691467285,
      "learning_rate": 1.452641599238458e-05,
      "loss": 0.0172,
      "step": 5750
    },
    {
      "epoch": 2.741551642075202,
      "grad_norm": 0.030277475714683533,
      "learning_rate": 1.4516896715849598e-05,
      "loss": 0.0001,
      "step": 5760
    },
    {
      "epoch": 2.746311280342694,
      "grad_norm": 0.16261020302772522,
      "learning_rate": 1.4507377439314614e-05,
      "loss": 0.0179,
      "step": 5770
    },
    {
      "epoch": 2.7510709186101856,
      "grad_norm": 4.136451721191406,
      "learning_rate": 1.449785816277963e-05,
      "loss": 0.015,
      "step": 5780
    },
    {
      "epoch": 2.7558305568776773,
      "grad_norm": 0.0053537157364189625,
      "learning_rate": 1.4488338886244646e-05,
      "loss": 0.0468,
      "step": 5790
    },
    {
      "epoch": 2.760590195145169,
      "grad_norm": 0.015219452790915966,
      "learning_rate": 1.4478819609709662e-05,
      "loss": 0.0101,
      "step": 5800
    },
    {
      "epoch": 2.7653498334126607,
      "grad_norm": 0.02407015673816204,
      "learning_rate": 1.4469300333174681e-05,
      "loss": 0.0007,
      "step": 5810
    },
    {
      "epoch": 2.7701094716801524,
      "grad_norm": 5.542986869812012,
      "learning_rate": 1.4459781056639697e-05,
      "loss": 0.0147,
      "step": 5820
    },
    {
      "epoch": 2.774869109947644,
      "grad_norm": 0.012973942793905735,
      "learning_rate": 1.4450261780104713e-05,
      "loss": 0.0315,
      "step": 5830
    },
    {
      "epoch": 2.779628748215136,
      "grad_norm": 0.007600222248584032,
      "learning_rate": 1.4440742503569729e-05,
      "loss": 0.0003,
      "step": 5840
    },
    {
      "epoch": 2.784388386482627,
      "grad_norm": 8.657949447631836,
      "learning_rate": 1.4431223227034747e-05,
      "loss": 0.0356,
      "step": 5850
    },
    {
      "epoch": 2.7891480247501192,
      "grad_norm": 0.042203862220048904,
      "learning_rate": 1.4421703950499764e-05,
      "loss": 0.0166,
      "step": 5860
    },
    {
      "epoch": 2.7939076630176105,
      "grad_norm": 0.006828194949775934,
      "learning_rate": 1.441218467396478e-05,
      "loss": 0.0002,
      "step": 5870
    },
    {
      "epoch": 2.798667301285102,
      "grad_norm": 0.03132002055644989,
      "learning_rate": 1.4402665397429796e-05,
      "loss": 0.0317,
      "step": 5880
    },
    {
      "epoch": 2.803426939552594,
      "grad_norm": 0.07154642790555954,
      "learning_rate": 1.4393146120894814e-05,
      "loss": 0.0459,
      "step": 5890
    },
    {
      "epoch": 2.8081865778200856,
      "grad_norm": 0.02177337184548378,
      "learning_rate": 1.438362684435983e-05,
      "loss": 0.0207,
      "step": 5900
    },
    {
      "epoch": 2.8129462160875773,
      "grad_norm": 0.0036525395698845387,
      "learning_rate": 1.4374107567824846e-05,
      "loss": 0.0003,
      "step": 5910
    },
    {
      "epoch": 2.817705854355069,
      "grad_norm": 0.019345354288816452,
      "learning_rate": 1.4364588291289862e-05,
      "loss": 0.0003,
      "step": 5920
    },
    {
      "epoch": 2.8224654926225607,
      "grad_norm": 0.07472347468137741,
      "learning_rate": 1.435506901475488e-05,
      "loss": 0.001,
      "step": 5930
    },
    {
      "epoch": 2.8272251308900525,
      "grad_norm": 0.2765924036502838,
      "learning_rate": 1.4345549738219897e-05,
      "loss": 0.0388,
      "step": 5940
    },
    {
      "epoch": 2.831984769157544,
      "grad_norm": 1.8313062191009521,
      "learning_rate": 1.4336030461684913e-05,
      "loss": 0.0103,
      "step": 5950
    },
    {
      "epoch": 2.836744407425036,
      "grad_norm": 0.010540581308305264,
      "learning_rate": 1.432651118514993e-05,
      "loss": 0.0223,
      "step": 5960
    },
    {
      "epoch": 2.8415040456925276,
      "grad_norm": 0.10484415292739868,
      "learning_rate": 1.4316991908614945e-05,
      "loss": 0.0002,
      "step": 5970
    },
    {
      "epoch": 2.846263683960019,
      "grad_norm": 0.08102424442768097,
      "learning_rate": 1.4307472632079965e-05,
      "loss": 0.0063,
      "step": 5980
    },
    {
      "epoch": 2.851023322227511,
      "grad_norm": 0.008524040691554546,
      "learning_rate": 1.429795335554498e-05,
      "loss": 0.0233,
      "step": 5990
    },
    {
      "epoch": 2.8557829604950022,
      "grad_norm": 0.013017755001783371,
      "learning_rate": 1.4288434079009997e-05,
      "loss": 0.002,
      "step": 6000
    },
    {
      "epoch": 2.860542598762494,
      "grad_norm": 0.011988557875156403,
      "learning_rate": 1.4278914802475013e-05,
      "loss": 0.084,
      "step": 6010
    },
    {
      "epoch": 2.8653022370299857,
      "grad_norm": 0.014161125756800175,
      "learning_rate": 1.426939552594003e-05,
      "loss": 0.0005,
      "step": 6020
    },
    {
      "epoch": 2.8700618752974774,
      "grad_norm": 0.026375358924269676,
      "learning_rate": 1.4259876249405046e-05,
      "loss": 0.0182,
      "step": 6030
    },
    {
      "epoch": 2.874821513564969,
      "grad_norm": 0.00909929908812046,
      "learning_rate": 1.4250356972870062e-05,
      "loss": 0.0002,
      "step": 6040
    },
    {
      "epoch": 2.8795811518324608,
      "grad_norm": 0.020370926707983017,
      "learning_rate": 1.424083769633508e-05,
      "loss": 0.0031,
      "step": 6050
    },
    {
      "epoch": 2.8843407900999525,
      "grad_norm": 2.398617744445801,
      "learning_rate": 1.4231318419800096e-05,
      "loss": 0.0206,
      "step": 6060
    },
    {
      "epoch": 2.889100428367444,
      "grad_norm": 0.3534643352031708,
      "learning_rate": 1.4221799143265114e-05,
      "loss": 0.0288,
      "step": 6070
    },
    {
      "epoch": 2.893860066634936,
      "grad_norm": 0.3288028836250305,
      "learning_rate": 1.421227986673013e-05,
      "loss": 0.0005,
      "step": 6080
    },
    {
      "epoch": 2.898619704902427,
      "grad_norm": 0.008216621354222298,
      "learning_rate": 1.4202760590195146e-05,
      "loss": 0.0003,
      "step": 6090
    },
    {
      "epoch": 2.9033793431699193,
      "grad_norm": 0.009968840517103672,
      "learning_rate": 1.4193241313660162e-05,
      "loss": 0.0147,
      "step": 6100
    },
    {
      "epoch": 2.9081389814374106,
      "grad_norm": 0.040144313126802444,
      "learning_rate": 1.4183722037125181e-05,
      "loss": 0.0289,
      "step": 6110
    },
    {
      "epoch": 2.9128986197049023,
      "grad_norm": 2.3031764030456543,
      "learning_rate": 1.4174202760590197e-05,
      "loss": 0.0011,
      "step": 6120
    },
    {
      "epoch": 2.917658257972394,
      "grad_norm": 0.010811462998390198,
      "learning_rate": 1.4164683484055213e-05,
      "loss": 0.0309,
      "step": 6130
    },
    {
      "epoch": 2.9224178962398857,
      "grad_norm": 0.007696149405092001,
      "learning_rate": 1.4155164207520229e-05,
      "loss": 0.0009,
      "step": 6140
    },
    {
      "epoch": 2.9271775345073774,
      "grad_norm": 5.093725681304932,
      "learning_rate": 1.4145644930985247e-05,
      "loss": 0.0273,
      "step": 6150
    },
    {
      "epoch": 2.931937172774869,
      "grad_norm": 0.015602282248437405,
      "learning_rate": 1.4136125654450264e-05,
      "loss": 0.0001,
      "step": 6160
    },
    {
      "epoch": 2.936696811042361,
      "grad_norm": 0.05836258828639984,
      "learning_rate": 1.412660637791528e-05,
      "loss": 0.0034,
      "step": 6170
    },
    {
      "epoch": 2.9414564493098525,
      "grad_norm": 0.005250235553830862,
      "learning_rate": 1.4117087101380296e-05,
      "loss": 0.0079,
      "step": 6180
    },
    {
      "epoch": 2.946216087577344,
      "grad_norm": 0.0030710226856172085,
      "learning_rate": 1.4107567824845312e-05,
      "loss": 0.0001,
      "step": 6190
    },
    {
      "epoch": 2.950975725844836,
      "grad_norm": 0.0014811072032898664,
      "learning_rate": 1.409804854831033e-05,
      "loss": 0.0001,
      "step": 6200
    },
    {
      "epoch": 2.9557353641123276,
      "grad_norm": 0.005222203675657511,
      "learning_rate": 1.4088529271775346e-05,
      "loss": 0.0531,
      "step": 6210
    },
    {
      "epoch": 2.960495002379819,
      "grad_norm": 0.012059568427503109,
      "learning_rate": 1.4079009995240362e-05,
      "loss": 0.0121,
      "step": 6220
    },
    {
      "epoch": 2.965254640647311,
      "grad_norm": 0.010965530760586262,
      "learning_rate": 1.4069490718705378e-05,
      "loss": 0.0022,
      "step": 6230
    },
    {
      "epoch": 2.9700142789148023,
      "grad_norm": 0.008430135436356068,
      "learning_rate": 1.4059971442170397e-05,
      "loss": 0.0013,
      "step": 6240
    },
    {
      "epoch": 2.974773917182294,
      "grad_norm": 0.010301326401531696,
      "learning_rate": 1.4050452165635413e-05,
      "loss": 0.0382,
      "step": 6250
    },
    {
      "epoch": 2.9795335554497857,
      "grad_norm": 0.0025582953821867704,
      "learning_rate": 1.404093288910043e-05,
      "loss": 0.0012,
      "step": 6260
    },
    {
      "epoch": 2.9842931937172774,
      "grad_norm": 0.00567513657733798,
      "learning_rate": 1.4031413612565445e-05,
      "loss": 0.0136,
      "step": 6270
    },
    {
      "epoch": 2.989052831984769,
      "grad_norm": 0.004398616496473551,
      "learning_rate": 1.4021894336030465e-05,
      "loss": 0.0003,
      "step": 6280
    },
    {
      "epoch": 2.993812470252261,
      "grad_norm": 0.0031878880690783262,
      "learning_rate": 1.401237505949548e-05,
      "loss": 0.0202,
      "step": 6290
    },
    {
      "epoch": 2.9985721085197525,
      "grad_norm": 0.010122240521013737,
      "learning_rate": 1.4002855782960497e-05,
      "loss": 0.0003,
      "step": 6300
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9964583333333333,
      "eval_f1": 0.9809060277049795,
      "eval_loss": 0.017824606969952583,
      "eval_precision": 0.9783420463032113,
      "eval_recall": 0.9834834834834835,
      "eval_runtime": 335.4061,
      "eval_samples_per_second": 42.966,
      "eval_steps_per_second": 1.345,
      "step": 6303
    },
    {
      "epoch": 3.0033317467872442,
      "grad_norm": 0.010468007065355778,
      "learning_rate": 1.3993336506425513e-05,
      "loss": 0.0001,
      "step": 6310
    },
    {
      "epoch": 3.008091385054736,
      "grad_norm": 0.01563195511698723,
      "learning_rate": 1.3983817229890528e-05,
      "loss": 0.0138,
      "step": 6320
    },
    {
      "epoch": 3.0128510233222277,
      "grad_norm": 0.021825619041919708,
      "learning_rate": 1.3974297953355546e-05,
      "loss": 0.0012,
      "step": 6330
    },
    {
      "epoch": 3.0176106615897194,
      "grad_norm": 0.15800915658473969,
      "learning_rate": 1.3964778676820562e-05,
      "loss": 0.0003,
      "step": 6340
    },
    {
      "epoch": 3.022370299857211,
      "grad_norm": 0.0021073147654533386,
      "learning_rate": 1.395525940028558e-05,
      "loss": 0.0005,
      "step": 6350
    },
    {
      "epoch": 3.0271299381247023,
      "grad_norm": 0.0026558542158454657,
      "learning_rate": 1.3945740123750596e-05,
      "loss": 0.0001,
      "step": 6360
    },
    {
      "epoch": 3.031889576392194,
      "grad_norm": 0.008990943431854248,
      "learning_rate": 1.3936220847215614e-05,
      "loss": 0.0087,
      "step": 6370
    },
    {
      "epoch": 3.0366492146596857,
      "grad_norm": 0.008416165597736835,
      "learning_rate": 1.392670157068063e-05,
      "loss": 0.0002,
      "step": 6380
    },
    {
      "epoch": 3.0414088529271774,
      "grad_norm": 0.007422228809446096,
      "learning_rate": 1.3917182294145645e-05,
      "loss": 0.0233,
      "step": 6390
    },
    {
      "epoch": 3.046168491194669,
      "grad_norm": 0.0036408361047506332,
      "learning_rate": 1.3907663017610661e-05,
      "loss": 0.0001,
      "step": 6400
    },
    {
      "epoch": 3.050928129462161,
      "grad_norm": 0.0037832127418369055,
      "learning_rate": 1.389814374107568e-05,
      "loss": 0.0263,
      "step": 6410
    },
    {
      "epoch": 3.0556877677296526,
      "grad_norm": 0.003999606240540743,
      "learning_rate": 1.3888624464540697e-05,
      "loss": 0.0001,
      "step": 6420
    },
    {
      "epoch": 3.0604474059971443,
      "grad_norm": 0.13477210700511932,
      "learning_rate": 1.3879105188005713e-05,
      "loss": 0.0015,
      "step": 6430
    },
    {
      "epoch": 3.065207044264636,
      "grad_norm": 0.03385348618030548,
      "learning_rate": 1.3869585911470729e-05,
      "loss": 0.0248,
      "step": 6440
    },
    {
      "epoch": 3.0699666825321277,
      "grad_norm": 0.16704712808132172,
      "learning_rate": 1.3860066634935746e-05,
      "loss": 0.0011,
      "step": 6450
    },
    {
      "epoch": 3.0747263207996194,
      "grad_norm": 0.0009118568268604577,
      "learning_rate": 1.3850547358400762e-05,
      "loss": 0.0001,
      "step": 6460
    },
    {
      "epoch": 3.079485959067111,
      "grad_norm": 0.008688297122716904,
      "learning_rate": 1.384102808186578e-05,
      "loss": 0.0003,
      "step": 6470
    },
    {
      "epoch": 3.0842455973346024,
      "grad_norm": 5.711660385131836,
      "learning_rate": 1.3831508805330796e-05,
      "loss": 0.0292,
      "step": 6480
    },
    {
      "epoch": 3.089005235602094,
      "grad_norm": 0.1889239102602005,
      "learning_rate": 1.3821989528795812e-05,
      "loss": 0.0011,
      "step": 6490
    },
    {
      "epoch": 3.0937648738695858,
      "grad_norm": 0.004828686825931072,
      "learning_rate": 1.381247025226083e-05,
      "loss": 0.0323,
      "step": 6500
    },
    {
      "epoch": 3.0985245121370775,
      "grad_norm": 0.022425595670938492,
      "learning_rate": 1.3802950975725846e-05,
      "loss": 0.006,
      "step": 6510
    },
    {
      "epoch": 3.103284150404569,
      "grad_norm": 0.004340273328125477,
      "learning_rate": 1.3793431699190862e-05,
      "loss": 0.0001,
      "step": 6520
    },
    {
      "epoch": 3.108043788672061,
      "grad_norm": 0.003104020841419697,
      "learning_rate": 1.3783912422655878e-05,
      "loss": 0.0026,
      "step": 6530
    },
    {
      "epoch": 3.1128034269395526,
      "grad_norm": 0.003166608279570937,
      "learning_rate": 1.3774393146120897e-05,
      "loss": 0.0202,
      "step": 6540
    },
    {
      "epoch": 3.1175630652070443,
      "grad_norm": 0.00399612495675683,
      "learning_rate": 1.3764873869585913e-05,
      "loss": 0.0002,
      "step": 6550
    },
    {
      "epoch": 3.122322703474536,
      "grad_norm": 0.0018865260062739253,
      "learning_rate": 1.3755354593050929e-05,
      "loss": 0.0031,
      "step": 6560
    },
    {
      "epoch": 3.1270823417420277,
      "grad_norm": 0.013393009081482887,
      "learning_rate": 1.3745835316515945e-05,
      "loss": 0.0001,
      "step": 6570
    },
    {
      "epoch": 3.1318419800095194,
      "grad_norm": 0.15424926578998566,
      "learning_rate": 1.3736316039980964e-05,
      "loss": 0.0001,
      "step": 6580
    },
    {
      "epoch": 3.136601618277011,
      "grad_norm": 0.007676557172089815,
      "learning_rate": 1.372679676344598e-05,
      "loss": 0.0269,
      "step": 6590
    },
    {
      "epoch": 3.141361256544503,
      "grad_norm": 0.030996790155768394,
      "learning_rate": 1.3717277486910996e-05,
      "loss": 0.0002,
      "step": 6600
    },
    {
      "epoch": 3.146120894811994,
      "grad_norm": 0.004872897174209356,
      "learning_rate": 1.3707758210376012e-05,
      "loss": 0.0099,
      "step": 6610
    },
    {
      "epoch": 3.150880533079486,
      "grad_norm": 0.005169274751096964,
      "learning_rate": 1.3698238933841028e-05,
      "loss": 0.0004,
      "step": 6620
    },
    {
      "epoch": 3.1556401713469775,
      "grad_norm": 0.006336444057524204,
      "learning_rate": 1.3688719657306046e-05,
      "loss": 0.0266,
      "step": 6630
    },
    {
      "epoch": 3.160399809614469,
      "grad_norm": 0.6932306289672852,
      "learning_rate": 1.3679200380771062e-05,
      "loss": 0.0003,
      "step": 6640
    },
    {
      "epoch": 3.165159447881961,
      "grad_norm": 0.2063014805316925,
      "learning_rate": 1.3669681104236078e-05,
      "loss": 0.0002,
      "step": 6650
    },
    {
      "epoch": 3.1699190861494526,
      "grad_norm": 0.0028639703523367643,
      "learning_rate": 1.3660161827701096e-05,
      "loss": 0.0104,
      "step": 6660
    },
    {
      "epoch": 3.1746787244169443,
      "grad_norm": 0.014044715091586113,
      "learning_rate": 1.3650642551166113e-05,
      "loss": 0.001,
      "step": 6670
    },
    {
      "epoch": 3.179438362684436,
      "grad_norm": 0.0062719122506678104,
      "learning_rate": 1.364112327463113e-05,
      "loss": 0.0196,
      "step": 6680
    },
    {
      "epoch": 3.1841980009519277,
      "grad_norm": 0.0040017422288656235,
      "learning_rate": 1.3631603998096145e-05,
      "loss": 0.0003,
      "step": 6690
    },
    {
      "epoch": 3.1889576392194194,
      "grad_norm": 0.003998446743935347,
      "learning_rate": 1.3622084721561161e-05,
      "loss": 0.0078,
      "step": 6700
    },
    {
      "epoch": 3.193717277486911,
      "grad_norm": 0.0013418487505987287,
      "learning_rate": 1.361256544502618e-05,
      "loss": 0.0002,
      "step": 6710
    },
    {
      "epoch": 3.198476915754403,
      "grad_norm": 0.0041251168586313725,
      "learning_rate": 1.3603046168491197e-05,
      "loss": 0.0196,
      "step": 6720
    },
    {
      "epoch": 3.2032365540218946,
      "grad_norm": 0.0013401976320892572,
      "learning_rate": 1.3593526891956213e-05,
      "loss": 0.0019,
      "step": 6730
    },
    {
      "epoch": 3.207996192289386,
      "grad_norm": 0.000895672885235399,
      "learning_rate": 1.3584007615421229e-05,
      "loss": 0.0,
      "step": 6740
    },
    {
      "epoch": 3.2127558305568775,
      "grad_norm": 0.08629631996154785,
      "learning_rate": 1.3574488338886245e-05,
      "loss": 0.0002,
      "step": 6750
    },
    {
      "epoch": 3.2175154688243692,
      "grad_norm": 0.0005477157537825406,
      "learning_rate": 1.3564969062351262e-05,
      "loss": 0.0011,
      "step": 6760
    },
    {
      "epoch": 3.222275107091861,
      "grad_norm": 0.00981761422008276,
      "learning_rate": 1.355544978581628e-05,
      "loss": 0.013,
      "step": 6770
    },
    {
      "epoch": 3.2270347453593526,
      "grad_norm": 0.004846060648560524,
      "learning_rate": 1.3545930509281296e-05,
      "loss": 0.0236,
      "step": 6780
    },
    {
      "epoch": 3.2317943836268443,
      "grad_norm": 5.0144476890563965,
      "learning_rate": 1.3536411232746312e-05,
      "loss": 0.0015,
      "step": 6790
    },
    {
      "epoch": 3.236554021894336,
      "grad_norm": 0.039719853550195694,
      "learning_rate": 1.352689195621133e-05,
      "loss": 0.0002,
      "step": 6800
    },
    {
      "epoch": 3.2413136601618278,
      "grad_norm": 0.0034486535005271435,
      "learning_rate": 1.3517372679676346e-05,
      "loss": 0.0002,
      "step": 6810
    },
    {
      "epoch": 3.2460732984293195,
      "grad_norm": 0.0012663559755310416,
      "learning_rate": 1.3507853403141362e-05,
      "loss": 0.0008,
      "step": 6820
    },
    {
      "epoch": 3.250832936696811,
      "grad_norm": 0.0018318024231120944,
      "learning_rate": 1.3498334126606378e-05,
      "loss": 0.0,
      "step": 6830
    },
    {
      "epoch": 3.255592574964303,
      "grad_norm": 13.09379768371582,
      "learning_rate": 1.3488814850071397e-05,
      "loss": 0.0252,
      "step": 6840
    },
    {
      "epoch": 3.260352213231794,
      "grad_norm": 0.0018836860544979572,
      "learning_rate": 1.3479295573536413e-05,
      "loss": 0.0001,
      "step": 6850
    },
    {
      "epoch": 3.2651118514992863,
      "grad_norm": 0.002584214322268963,
      "learning_rate": 1.3469776297001429e-05,
      "loss": 0.0284,
      "step": 6860
    },
    {
      "epoch": 3.2698714897667776,
      "grad_norm": 0.017672747373580933,
      "learning_rate": 1.3460257020466445e-05,
      "loss": 0.0021,
      "step": 6870
    },
    {
      "epoch": 3.2746311280342693,
      "grad_norm": 0.6414177417755127,
      "learning_rate": 1.3450737743931461e-05,
      "loss": 0.0011,
      "step": 6880
    },
    {
      "epoch": 3.279390766301761,
      "grad_norm": 0.0020491343457251787,
      "learning_rate": 1.344121846739648e-05,
      "loss": 0.0202,
      "step": 6890
    },
    {
      "epoch": 3.2841504045692527,
      "grad_norm": 0.011547657661139965,
      "learning_rate": 1.3431699190861496e-05,
      "loss": 0.0125,
      "step": 6900
    },
    {
      "epoch": 3.2889100428367444,
      "grad_norm": 0.007235067896544933,
      "learning_rate": 1.3422179914326512e-05,
      "loss": 0.0392,
      "step": 6910
    },
    {
      "epoch": 3.293669681104236,
      "grad_norm": 0.016785848885774612,
      "learning_rate": 1.3412660637791528e-05,
      "loss": 0.0227,
      "step": 6920
    },
    {
      "epoch": 3.298429319371728,
      "grad_norm": 0.05863379314541817,
      "learning_rate": 1.3403141361256546e-05,
      "loss": 0.0004,
      "step": 6930
    },
    {
      "epoch": 3.3031889576392195,
      "grad_norm": 0.04554830119013786,
      "learning_rate": 1.3393622084721562e-05,
      "loss": 0.0049,
      "step": 6940
    },
    {
      "epoch": 3.307948595906711,
      "grad_norm": 7.7009196281433105,
      "learning_rate": 1.3384102808186578e-05,
      "loss": 0.013,
      "step": 6950
    },
    {
      "epoch": 3.312708234174203,
      "grad_norm": 0.0026278735604137182,
      "learning_rate": 1.3374583531651596e-05,
      "loss": 0.0001,
      "step": 6960
    },
    {
      "epoch": 3.3174678724416946,
      "grad_norm": 0.003915353212505579,
      "learning_rate": 1.3365064255116613e-05,
      "loss": 0.0308,
      "step": 6970
    },
    {
      "epoch": 3.322227510709186,
      "grad_norm": 0.004743850789964199,
      "learning_rate": 1.335554497858163e-05,
      "loss": 0.0039,
      "step": 6980
    },
    {
      "epoch": 3.326987148976678,
      "grad_norm": 0.004690165165811777,
      "learning_rate": 1.3346025702046645e-05,
      "loss": 0.0055,
      "step": 6990
    },
    {
      "epoch": 3.3317467872441693,
      "grad_norm": 0.05646294355392456,
      "learning_rate": 1.3336506425511661e-05,
      "loss": 0.0005,
      "step": 7000
    },
    {
      "epoch": 3.336506425511661,
      "grad_norm": 0.0012757302029058337,
      "learning_rate": 1.3326987148976677e-05,
      "loss": 0.0033,
      "step": 7010
    },
    {
      "epoch": 3.3412660637791527,
      "grad_norm": 0.09135844558477402,
      "learning_rate": 1.3317467872441697e-05,
      "loss": 0.0002,
      "step": 7020
    },
    {
      "epoch": 3.3460257020466444,
      "grad_norm": 0.04793873056769371,
      "learning_rate": 1.3307948595906713e-05,
      "loss": 0.0212,
      "step": 7030
    },
    {
      "epoch": 3.350785340314136,
      "grad_norm": 0.00554579496383667,
      "learning_rate": 1.3298429319371729e-05,
      "loss": 0.0002,
      "step": 7040
    },
    {
      "epoch": 3.355544978581628,
      "grad_norm": 0.0021268350537866354,
      "learning_rate": 1.3288910042836745e-05,
      "loss": 0.0001,
      "step": 7050
    },
    {
      "epoch": 3.3603046168491195,
      "grad_norm": 15.82487964630127,
      "learning_rate": 1.3279390766301762e-05,
      "loss": 0.0111,
      "step": 7060
    },
    {
      "epoch": 3.3650642551166112,
      "grad_norm": 0.013001229614019394,
      "learning_rate": 1.3269871489766778e-05,
      "loss": 0.0316,
      "step": 7070
    },
    {
      "epoch": 3.369823893384103,
      "grad_norm": 0.005308249033987522,
      "learning_rate": 1.3260352213231796e-05,
      "loss": 0.0058,
      "step": 7080
    },
    {
      "epoch": 3.3745835316515946,
      "grad_norm": 1.118725061416626,
      "learning_rate": 1.3250832936696812e-05,
      "loss": 0.0006,
      "step": 7090
    },
    {
      "epoch": 3.3793431699190863,
      "grad_norm": 0.004976542200893164,
      "learning_rate": 1.324131366016183e-05,
      "loss": 0.0082,
      "step": 7100
    },
    {
      "epoch": 3.3841028081865776,
      "grad_norm": 0.001516996300779283,
      "learning_rate": 1.3231794383626846e-05,
      "loss": 0.0001,
      "step": 7110
    },
    {
      "epoch": 3.3888624464540693,
      "grad_norm": 0.0013080312637612224,
      "learning_rate": 1.3222275107091862e-05,
      "loss": 0.0001,
      "step": 7120
    },
    {
      "epoch": 3.393622084721561,
      "grad_norm": 0.0011679093586280942,
      "learning_rate": 1.3212755830556878e-05,
      "loss": 0.0008,
      "step": 7130
    },
    {
      "epoch": 3.3983817229890527,
      "grad_norm": 0.252370685338974,
      "learning_rate": 1.3203236554021897e-05,
      "loss": 0.0001,
      "step": 7140
    },
    {
      "epoch": 3.4031413612565444,
      "grad_norm": 0.07680155336856842,
      "learning_rate": 1.3193717277486913e-05,
      "loss": 0.0001,
      "step": 7150
    },
    {
      "epoch": 3.407900999524036,
      "grad_norm": 0.0010488537373021245,
      "learning_rate": 1.3184198000951929e-05,
      "loss": 0.0002,
      "step": 7160
    },
    {
      "epoch": 3.412660637791528,
      "grad_norm": 0.001471649156883359,
      "learning_rate": 1.3174678724416945e-05,
      "loss": 0.0224,
      "step": 7170
    },
    {
      "epoch": 3.4174202760590195,
      "grad_norm": 0.004040994215756655,
      "learning_rate": 1.3165159447881961e-05,
      "loss": 0.0003,
      "step": 7180
    },
    {
      "epoch": 3.4221799143265113,
      "grad_norm": 0.002044509630650282,
      "learning_rate": 1.315564017134698e-05,
      "loss": 0.0,
      "step": 7190
    },
    {
      "epoch": 3.426939552594003,
      "grad_norm": 0.007152257487177849,
      "learning_rate": 1.3146120894811996e-05,
      "loss": 0.0093,
      "step": 7200
    },
    {
      "epoch": 3.4316991908614947,
      "grad_norm": 0.002128011081367731,
      "learning_rate": 1.3136601618277012e-05,
      "loss": 0.0113,
      "step": 7210
    },
    {
      "epoch": 3.4364588291289864,
      "grad_norm": 0.0010856655426323414,
      "learning_rate": 1.3127082341742028e-05,
      "loss": 0.0002,
      "step": 7220
    },
    {
      "epoch": 3.441218467396478,
      "grad_norm": 0.0025201914831995964,
      "learning_rate": 1.3117563065207046e-05,
      "loss": 0.0211,
      "step": 7230
    },
    {
      "epoch": 3.4459781056639693,
      "grad_norm": 0.003747869050130248,
      "learning_rate": 1.3108043788672062e-05,
      "loss": 0.0021,
      "step": 7240
    },
    {
      "epoch": 3.450737743931461,
      "grad_norm": 0.003720194799825549,
      "learning_rate": 1.3098524512137078e-05,
      "loss": 0.0003,
      "step": 7250
    },
    {
      "epoch": 3.4554973821989527,
      "grad_norm": 0.0015738573856651783,
      "learning_rate": 1.3089005235602094e-05,
      "loss": 0.0018,
      "step": 7260
    },
    {
      "epoch": 3.4602570204664445,
      "grad_norm": 0.005453886464238167,
      "learning_rate": 1.3079485959067113e-05,
      "loss": 0.0054,
      "step": 7270
    },
    {
      "epoch": 3.465016658733936,
      "grad_norm": 0.005791331175714731,
      "learning_rate": 1.306996668253213e-05,
      "loss": 0.0088,
      "step": 7280
    },
    {
      "epoch": 3.469776297001428,
      "grad_norm": 0.0008826100965961814,
      "learning_rate": 1.3060447405997145e-05,
      "loss": 0.0325,
      "step": 7290
    },
    {
      "epoch": 3.4745359352689196,
      "grad_norm": 3.721761465072632,
      "learning_rate": 1.3050928129462161e-05,
      "loss": 0.0047,
      "step": 7300
    },
    {
      "epoch": 3.4792955735364113,
      "grad_norm": 0.0014254816342145205,
      "learning_rate": 1.3041408852927177e-05,
      "loss": 0.021,
      "step": 7310
    },
    {
      "epoch": 3.484055211803903,
      "grad_norm": 0.0011881440877914429,
      "learning_rate": 1.3031889576392197e-05,
      "loss": 0.0021,
      "step": 7320
    },
    {
      "epoch": 3.4888148500713947,
      "grad_norm": 10.312649726867676,
      "learning_rate": 1.3022370299857213e-05,
      "loss": 0.018,
      "step": 7330
    },
    {
      "epoch": 3.4935744883388864,
      "grad_norm": 0.009595171548426151,
      "learning_rate": 1.3012851023322229e-05,
      "loss": 0.0123,
      "step": 7340
    },
    {
      "epoch": 3.498334126606378,
      "grad_norm": 0.008706378750503063,
      "learning_rate": 1.3003331746787245e-05,
      "loss": 0.0001,
      "step": 7350
    },
    {
      "epoch": 3.50309376487387,
      "grad_norm": 0.056812845170497894,
      "learning_rate": 1.2993812470252262e-05,
      "loss": 0.0003,
      "step": 7360
    },
    {
      "epoch": 3.507853403141361,
      "grad_norm": 0.008832831867039204,
      "learning_rate": 1.2984293193717278e-05,
      "loss": 0.0005,
      "step": 7370
    },
    {
      "epoch": 3.5126130414088528,
      "grad_norm": 0.010338186286389828,
      "learning_rate": 1.2974773917182296e-05,
      "loss": 0.0013,
      "step": 7380
    },
    {
      "epoch": 3.5173726796763445,
      "grad_norm": 0.3841133117675781,
      "learning_rate": 1.2965254640647312e-05,
      "loss": 0.0226,
      "step": 7390
    },
    {
      "epoch": 3.522132317943836,
      "grad_norm": 0.0006283114198595285,
      "learning_rate": 1.295573536411233e-05,
      "loss": 0.0003,
      "step": 7400
    },
    {
      "epoch": 3.526891956211328,
      "grad_norm": 0.0006974790594540536,
      "learning_rate": 1.2946216087577346e-05,
      "loss": 0.0434,
      "step": 7410
    },
    {
      "epoch": 3.5316515944788196,
      "grad_norm": 0.02050844021141529,
      "learning_rate": 1.2936696811042362e-05,
      "loss": 0.0017,
      "step": 7420
    },
    {
      "epoch": 3.5364112327463113,
      "grad_norm": 1.4931919574737549,
      "learning_rate": 1.2927177534507378e-05,
      "loss": 0.0252,
      "step": 7430
    },
    {
      "epoch": 3.541170871013803,
      "grad_norm": 0.0011906417785212398,
      "learning_rate": 1.2917658257972393e-05,
      "loss": 0.0428,
      "step": 7440
    },
    {
      "epoch": 3.5459305092812947,
      "grad_norm": 0.01177381444722414,
      "learning_rate": 1.2908138981437413e-05,
      "loss": 0.0302,
      "step": 7450
    },
    {
      "epoch": 3.5506901475487864,
      "grad_norm": 0.05941857025027275,
      "learning_rate": 1.2898619704902429e-05,
      "loss": 0.0021,
      "step": 7460
    },
    {
      "epoch": 3.555449785816278,
      "grad_norm": 0.005374974571168423,
      "learning_rate": 1.2889100428367445e-05,
      "loss": 0.0001,
      "step": 7470
    },
    {
      "epoch": 3.5602094240837694,
      "grad_norm": 0.0027155340649187565,
      "learning_rate": 1.287958115183246e-05,
      "loss": 0.0001,
      "step": 7480
    },
    {
      "epoch": 3.5649690623512615,
      "grad_norm": 0.008947941474616528,
      "learning_rate": 1.2870061875297479e-05,
      "loss": 0.0002,
      "step": 7490
    },
    {
      "epoch": 3.569728700618753,
      "grad_norm": 0.34980088472366333,
      "learning_rate": 1.2860542598762496e-05,
      "loss": 0.0091,
      "step": 7500
    },
    {
      "epoch": 3.5744883388862445,
      "grad_norm": 0.0031974297016859055,
      "learning_rate": 1.2851023322227512e-05,
      "loss": 0.0001,
      "step": 7510
    },
    {
      "epoch": 3.579247977153736,
      "grad_norm": 0.0025371199008077383,
      "learning_rate": 1.2841504045692528e-05,
      "loss": 0.0007,
      "step": 7520
    },
    {
      "epoch": 3.584007615421228,
      "grad_norm": 0.0030093477107584476,
      "learning_rate": 1.2831984769157546e-05,
      "loss": 0.0001,
      "step": 7530
    },
    {
      "epoch": 3.5887672536887196,
      "grad_norm": 0.0022915208246558905,
      "learning_rate": 1.2822465492622562e-05,
      "loss": 0.0136,
      "step": 7540
    },
    {
      "epoch": 3.5935268919562113,
      "grad_norm": 0.0019800812005996704,
      "learning_rate": 1.2812946216087578e-05,
      "loss": 0.0081,
      "step": 7550
    },
    {
      "epoch": 3.598286530223703,
      "grad_norm": 0.009386060759425163,
      "learning_rate": 1.2803426939552594e-05,
      "loss": 0.044,
      "step": 7560
    },
    {
      "epoch": 3.6030461684911947,
      "grad_norm": 0.4532001316547394,
      "learning_rate": 1.2793907663017611e-05,
      "loss": 0.0019,
      "step": 7570
    },
    {
      "epoch": 3.6078058067586865,
      "grad_norm": 0.0014896276406943798,
      "learning_rate": 1.278438838648263e-05,
      "loss": 0.0002,
      "step": 7580
    },
    {
      "epoch": 3.612565445026178,
      "grad_norm": 0.003259034128859639,
      "learning_rate": 1.2774869109947645e-05,
      "loss": 0.0294,
      "step": 7590
    },
    {
      "epoch": 3.61732508329367,
      "grad_norm": 0.01406821422278881,
      "learning_rate": 1.2765349833412661e-05,
      "loss": 0.0027,
      "step": 7600
    },
    {
      "epoch": 3.622084721561161,
      "grad_norm": 0.0014401150401681662,
      "learning_rate": 1.2755830556877677e-05,
      "loss": 0.0004,
      "step": 7610
    },
    {
      "epoch": 3.6268443598286533,
      "grad_norm": 0.0011039377423003316,
      "learning_rate": 1.2746311280342696e-05,
      "loss": 0.0131,
      "step": 7620
    },
    {
      "epoch": 3.6316039980961445,
      "grad_norm": 0.0020840782672166824,
      "learning_rate": 1.2736792003807712e-05,
      "loss": 0.0061,
      "step": 7630
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 0.025930237025022507,
      "learning_rate": 1.2727272727272728e-05,
      "loss": 0.0451,
      "step": 7640
    },
    {
      "epoch": 3.641123274631128,
      "grad_norm": 0.006888149306178093,
      "learning_rate": 1.2717753450737744e-05,
      "loss": 0.0004,
      "step": 7650
    },
    {
      "epoch": 3.6458829128986197,
      "grad_norm": 2.578704357147217,
      "learning_rate": 1.2708234174202762e-05,
      "loss": 0.0363,
      "step": 7660
    },
    {
      "epoch": 3.6506425511661114,
      "grad_norm": 0.008459450677037239,
      "learning_rate": 1.2698714897667778e-05,
      "loss": 0.0004,
      "step": 7670
    },
    {
      "epoch": 3.655402189433603,
      "grad_norm": 0.01741703785955906,
      "learning_rate": 1.2689195621132794e-05,
      "loss": 0.0238,
      "step": 7680
    },
    {
      "epoch": 3.6601618277010948,
      "grad_norm": 0.2683805227279663,
      "learning_rate": 1.2679676344597812e-05,
      "loss": 0.0288,
      "step": 7690
    },
    {
      "epoch": 3.6649214659685865,
      "grad_norm": 0.005499137565493584,
      "learning_rate": 1.2670157068062828e-05,
      "loss": 0.0045,
      "step": 7700
    },
    {
      "epoch": 3.669681104236078,
      "grad_norm": 0.005815957207232714,
      "learning_rate": 1.2660637791527845e-05,
      "loss": 0.0004,
      "step": 7710
    },
    {
      "epoch": 3.67444074250357,
      "grad_norm": 0.006627297960221767,
      "learning_rate": 1.2651118514992861e-05,
      "loss": 0.0003,
      "step": 7720
    },
    {
      "epoch": 3.6792003807710616,
      "grad_norm": 0.009510590694844723,
      "learning_rate": 1.2641599238457877e-05,
      "loss": 0.0156,
      "step": 7730
    },
    {
      "epoch": 3.683960019038553,
      "grad_norm": 0.0032356958836317062,
      "learning_rate": 1.2632079961922893e-05,
      "loss": 0.0002,
      "step": 7740
    },
    {
      "epoch": 3.688719657306045,
      "grad_norm": 0.5079785585403442,
      "learning_rate": 1.2622560685387913e-05,
      "loss": 0.0008,
      "step": 7750
    },
    {
      "epoch": 3.6934792955735363,
      "grad_norm": 0.0017371197463944554,
      "learning_rate": 1.2613041408852929e-05,
      "loss": 0.0001,
      "step": 7760
    },
    {
      "epoch": 3.698238933841028,
      "grad_norm": 0.003081838134676218,
      "learning_rate": 1.2603522132317945e-05,
      "loss": 0.0095,
      "step": 7770
    },
    {
      "epoch": 3.7029985721085197,
      "grad_norm": 0.021789684891700745,
      "learning_rate": 1.259400285578296e-05,
      "loss": 0.0013,
      "step": 7780
    },
    {
      "epoch": 3.7077582103760114,
      "grad_norm": 0.01130316685885191,
      "learning_rate": 1.2584483579247978e-05,
      "loss": 0.058,
      "step": 7790
    },
    {
      "epoch": 3.712517848643503,
      "grad_norm": 0.06445467472076416,
      "learning_rate": 1.2574964302712996e-05,
      "loss": 0.0321,
      "step": 7800
    },
    {
      "epoch": 3.717277486910995,
      "grad_norm": 0.04523635655641556,
      "learning_rate": 1.2565445026178012e-05,
      "loss": 0.001,
      "step": 7810
    },
    {
      "epoch": 3.7220371251784865,
      "grad_norm": 0.008035901933908463,
      "learning_rate": 1.2555925749643028e-05,
      "loss": 0.0193,
      "step": 7820
    },
    {
      "epoch": 3.726796763445978,
      "grad_norm": 0.3632906973361969,
      "learning_rate": 1.2546406473108044e-05,
      "loss": 0.0008,
      "step": 7830
    },
    {
      "epoch": 3.73155640171347,
      "grad_norm": 0.07845690101385117,
      "learning_rate": 1.2536887196573062e-05,
      "loss": 0.0003,
      "step": 7840
    },
    {
      "epoch": 3.736316039980961,
      "grad_norm": 0.003074134001508355,
      "learning_rate": 1.2527367920038078e-05,
      "loss": 0.0198,
      "step": 7850
    },
    {
      "epoch": 3.7410756782484533,
      "grad_norm": 0.002674924209713936,
      "learning_rate": 1.2517848643503094e-05,
      "loss": 0.0024,
      "step": 7860
    },
    {
      "epoch": 3.7458353165159446,
      "grad_norm": 0.003478777827695012,
      "learning_rate": 1.250832936696811e-05,
      "loss": 0.0373,
      "step": 7870
    },
    {
      "epoch": 3.7505949547834363,
      "grad_norm": 0.004244554787874222,
      "learning_rate": 1.2498810090433129e-05,
      "loss": 0.0003,
      "step": 7880
    },
    {
      "epoch": 3.755354593050928,
      "grad_norm": 0.004512883257120848,
      "learning_rate": 1.2489290813898145e-05,
      "loss": 0.0074,
      "step": 7890
    },
    {
      "epoch": 3.7601142313184197,
      "grad_norm": 0.0029020097572356462,
      "learning_rate": 1.2479771537363161e-05,
      "loss": 0.016,
      "step": 7900
    },
    {
      "epoch": 3.7648738695859114,
      "grad_norm": 0.20009860396385193,
      "learning_rate": 1.2470252260828177e-05,
      "loss": 0.003,
      "step": 7910
    },
    {
      "epoch": 3.769633507853403,
      "grad_norm": 0.007441846653819084,
      "learning_rate": 1.2460732984293196e-05,
      "loss": 0.0001,
      "step": 7920
    },
    {
      "epoch": 3.774393146120895,
      "grad_norm": 0.01467998418956995,
      "learning_rate": 1.2451213707758212e-05,
      "loss": 0.027,
      "step": 7930
    },
    {
      "epoch": 3.7791527843883865,
      "grad_norm": 0.02240392379462719,
      "learning_rate": 1.2441694431223228e-05,
      "loss": 0.0001,
      "step": 7940
    },
    {
      "epoch": 3.7839124226558782,
      "grad_norm": 0.004522072151303291,
      "learning_rate": 1.2432175154688244e-05,
      "loss": 0.0012,
      "step": 7950
    },
    {
      "epoch": 3.78867206092337,
      "grad_norm": 0.005766504909843206,
      "learning_rate": 1.2422655878153262e-05,
      "loss": 0.0188,
      "step": 7960
    },
    {
      "epoch": 3.7934316991908617,
      "grad_norm": 0.008336961269378662,
      "learning_rate": 1.2413136601618278e-05,
      "loss": 0.0002,
      "step": 7970
    },
    {
      "epoch": 3.798191337458353,
      "grad_norm": 0.058982834219932556,
      "learning_rate": 1.2403617325083294e-05,
      "loss": 0.0611,
      "step": 7980
    },
    {
      "epoch": 3.802950975725845,
      "grad_norm": 0.10046067088842392,
      "learning_rate": 1.2394098048548312e-05,
      "loss": 0.0035,
      "step": 7990
    },
    {
      "epoch": 3.8077106139933363,
      "grad_norm": 0.011747569777071476,
      "learning_rate": 1.2384578772013328e-05,
      "loss": 0.0006,
      "step": 8000
    },
    {
      "epoch": 3.812470252260828,
      "grad_norm": 0.006597642321139574,
      "learning_rate": 1.2375059495478345e-05,
      "loss": 0.0013,
      "step": 8010
    },
    {
      "epoch": 3.8172298905283197,
      "grad_norm": 0.027477608993649483,
      "learning_rate": 1.2365540218943361e-05,
      "loss": 0.0008,
      "step": 8020
    },
    {
      "epoch": 3.8219895287958114,
      "grad_norm": 0.003919606097042561,
      "learning_rate": 1.2356020942408377e-05,
      "loss": 0.0006,
      "step": 8030
    },
    {
      "epoch": 3.826749167063303,
      "grad_norm": 0.015083776786923409,
      "learning_rate": 1.2346501665873393e-05,
      "loss": 0.0014,
      "step": 8040
    },
    {
      "epoch": 3.831508805330795,
      "grad_norm": 5.976426124572754,
      "learning_rate": 1.2336982389338413e-05,
      "loss": 0.007,
      "step": 8050
    },
    {
      "epoch": 3.8362684435982866,
      "grad_norm": 0.01605086401104927,
      "learning_rate": 1.2327463112803429e-05,
      "loss": 0.0069,
      "step": 8060
    },
    {
      "epoch": 3.8410280818657783,
      "grad_norm": 0.06671462953090668,
      "learning_rate": 1.2317943836268445e-05,
      "loss": 0.0242,
      "step": 8070
    },
    {
      "epoch": 3.84578772013327,
      "grad_norm": 0.0030177519656717777,
      "learning_rate": 1.230842455973346e-05,
      "loss": 0.0013,
      "step": 8080
    },
    {
      "epoch": 3.8505473584007617,
      "grad_norm": 0.5154538154602051,
      "learning_rate": 1.2298905283198478e-05,
      "loss": 0.048,
      "step": 8090
    },
    {
      "epoch": 3.8553069966682534,
      "grad_norm": 0.004214059095829725,
      "learning_rate": 1.2289386006663494e-05,
      "loss": 0.0002,
      "step": 8100
    },
    {
      "epoch": 3.8600666349357446,
      "grad_norm": 0.0036254595033824444,
      "learning_rate": 1.2279866730128512e-05,
      "loss": 0.0014,
      "step": 8110
    },
    {
      "epoch": 3.864826273203237,
      "grad_norm": 0.0022605927661061287,
      "learning_rate": 1.2270347453593528e-05,
      "loss": 0.0115,
      "step": 8120
    },
    {
      "epoch": 3.869585911470728,
      "grad_norm": 0.0028093697037547827,
      "learning_rate": 1.2260828177058544e-05,
      "loss": 0.0235,
      "step": 8130
    },
    {
      "epoch": 3.8743455497382198,
      "grad_norm": 0.0038036643527448177,
      "learning_rate": 1.2251308900523562e-05,
      "loss": 0.0343,
      "step": 8140
    },
    {
      "epoch": 3.8791051880057115,
      "grad_norm": 0.004446062259376049,
      "learning_rate": 1.2241789623988578e-05,
      "loss": 0.0002,
      "step": 8150
    },
    {
      "epoch": 3.883864826273203,
      "grad_norm": 0.004131389316171408,
      "learning_rate": 1.2232270347453594e-05,
      "loss": 0.0052,
      "step": 8160
    },
    {
      "epoch": 3.888624464540695,
      "grad_norm": 0.05102705955505371,
      "learning_rate": 1.222275107091861e-05,
      "loss": 0.0021,
      "step": 8170
    },
    {
      "epoch": 3.8933841028081866,
      "grad_norm": 0.009273042902350426,
      "learning_rate": 1.2213231794383629e-05,
      "loss": 0.0018,
      "step": 8180
    },
    {
      "epoch": 3.8981437410756783,
      "grad_norm": 0.013233370147645473,
      "learning_rate": 1.2203712517848645e-05,
      "loss": 0.0002,
      "step": 8190
    },
    {
      "epoch": 3.90290337934317,
      "grad_norm": 0.023086048662662506,
      "learning_rate": 1.2194193241313661e-05,
      "loss": 0.0412,
      "step": 8200
    },
    {
      "epoch": 3.9076630176106617,
      "grad_norm": 0.008013051003217697,
      "learning_rate": 1.2184673964778677e-05,
      "loss": 0.0025,
      "step": 8210
    },
    {
      "epoch": 3.9124226558781534,
      "grad_norm": 0.009677397087216377,
      "learning_rate": 1.2175154688243696e-05,
      "loss": 0.0002,
      "step": 8220
    },
    {
      "epoch": 3.917182294145645,
      "grad_norm": 0.002674882533028722,
      "learning_rate": 1.2165635411708712e-05,
      "loss": 0.0001,
      "step": 8230
    },
    {
      "epoch": 3.9219419324131364,
      "grad_norm": 0.004311648663133383,
      "learning_rate": 1.2156116135173728e-05,
      "loss": 0.0001,
      "step": 8240
    },
    {
      "epoch": 3.9267015706806285,
      "grad_norm": 3.704137086868286,
      "learning_rate": 1.2146596858638744e-05,
      "loss": 0.0014,
      "step": 8250
    },
    {
      "epoch": 3.93146120894812,
      "grad_norm": 0.027263004332780838,
      "learning_rate": 1.213707758210376e-05,
      "loss": 0.0001,
      "step": 8260
    },
    {
      "epoch": 3.9362208472156115,
      "grad_norm": 0.0017854593461379409,
      "learning_rate": 1.2127558305568778e-05,
      "loss": 0.0007,
      "step": 8270
    },
    {
      "epoch": 3.940980485483103,
      "grad_norm": 0.000859486754052341,
      "learning_rate": 1.2118039029033794e-05,
      "loss": 0.0225,
      "step": 8280
    },
    {
      "epoch": 3.945740123750595,
      "grad_norm": 0.005822767503559589,
      "learning_rate": 1.210851975249881e-05,
      "loss": 0.0068,
      "step": 8290
    },
    {
      "epoch": 3.9504997620180866,
      "grad_norm": 0.012198870070278645,
      "learning_rate": 1.2099000475963828e-05,
      "loss": 0.0027,
      "step": 8300
    },
    {
      "epoch": 3.9552594002855783,
      "grad_norm": 0.0015164365759119391,
      "learning_rate": 1.2089481199428845e-05,
      "loss": 0.0024,
      "step": 8310
    },
    {
      "epoch": 3.96001903855307,
      "grad_norm": 0.002837624168023467,
      "learning_rate": 1.2079961922893861e-05,
      "loss": 0.0096,
      "step": 8320
    },
    {
      "epoch": 3.9647786768205617,
      "grad_norm": 0.009517712518572807,
      "learning_rate": 1.2070442646358877e-05,
      "loss": 0.0038,
      "step": 8330
    },
    {
      "epoch": 3.9695383150880534,
      "grad_norm": 0.23455063998699188,
      "learning_rate": 1.2060923369823893e-05,
      "loss": 0.002,
      "step": 8340
    },
    {
      "epoch": 3.974297953355545,
      "grad_norm": 0.004982504062354565,
      "learning_rate": 1.2051404093288913e-05,
      "loss": 0.0214,
      "step": 8350
    },
    {
      "epoch": 3.979057591623037,
      "grad_norm": 3.078997850418091,
      "learning_rate": 1.2041884816753929e-05,
      "loss": 0.0017,
      "step": 8360
    },
    {
      "epoch": 3.983817229890528,
      "grad_norm": 0.0012226261897012591,
      "learning_rate": 1.2032365540218945e-05,
      "loss": 0.0071,
      "step": 8370
    },
    {
      "epoch": 3.9885768681580203,
      "grad_norm": 0.0032822287175804377,
      "learning_rate": 1.202284626368396e-05,
      "loss": 0.0242,
      "step": 8380
    },
    {
      "epoch": 3.9933365064255115,
      "grad_norm": 0.01420797873288393,
      "learning_rate": 1.2013326987148977e-05,
      "loss": 0.008,
      "step": 8390
    },
    {
      "epoch": 3.9980961446930032,
      "grad_norm": 0.006446337327361107,
      "learning_rate": 1.2003807710613994e-05,
      "loss": 0.0134,
      "step": 8400
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9955555555555555,
      "eval_f1": 0.9760299625468164,
      "eval_loss": 0.02183443494141102,
      "eval_precision": 0.9738415545590433,
      "eval_recall": 0.9782282282282282,
      "eval_runtime": 338.3613,
      "eval_samples_per_second": 42.591,
      "eval_steps_per_second": 1.333,
      "step": 8404
    },
    {
      "epoch": 4.002855782960495,
      "grad_norm": 0.007533705793321133,
      "learning_rate": 1.1994288434079012e-05,
      "loss": 0.0001,
      "step": 8410
    },
    {
      "epoch": 4.007615421227987,
      "grad_norm": 0.024449480697512627,
      "learning_rate": 1.1984769157544028e-05,
      "loss": 0.0001,
      "step": 8420
    },
    {
      "epoch": 4.012375059495478,
      "grad_norm": 0.003013610141351819,
      "learning_rate": 1.1975249881009044e-05,
      "loss": 0.0001,
      "step": 8430
    },
    {
      "epoch": 4.01713469776297,
      "grad_norm": 0.00101709202863276,
      "learning_rate": 1.1965730604474062e-05,
      "loss": 0.0016,
      "step": 8440
    },
    {
      "epoch": 4.021894336030462,
      "grad_norm": 0.0007068394916132092,
      "learning_rate": 1.1956211327939078e-05,
      "loss": 0.0007,
      "step": 8450
    },
    {
      "epoch": 4.026653974297953,
      "grad_norm": 0.00038638486876152456,
      "learning_rate": 1.1946692051404094e-05,
      "loss": 0.001,
      "step": 8460
    },
    {
      "epoch": 4.031413612565445,
      "grad_norm": 0.002558188745751977,
      "learning_rate": 1.193717277486911e-05,
      "loss": 0.0131,
      "step": 8470
    },
    {
      "epoch": 4.036173250832936,
      "grad_norm": 0.02940506488084793,
      "learning_rate": 1.1927653498334129e-05,
      "loss": 0.0018,
      "step": 8480
    },
    {
      "epoch": 4.040932889100429,
      "grad_norm": 0.001555432565510273,
      "learning_rate": 1.1918134221799145e-05,
      "loss": 0.0001,
      "step": 8490
    },
    {
      "epoch": 4.04569252736792,
      "grad_norm": 0.008825005032122135,
      "learning_rate": 1.1908614945264161e-05,
      "loss": 0.0112,
      "step": 8500
    },
    {
      "epoch": 4.050452165635412,
      "grad_norm": 0.04189186543226242,
      "learning_rate": 1.1899095668729177e-05,
      "loss": 0.0,
      "step": 8510
    },
    {
      "epoch": 4.055211803902903,
      "grad_norm": 0.018358519300818443,
      "learning_rate": 1.1889576392194193e-05,
      "loss": 0.0001,
      "step": 8520
    },
    {
      "epoch": 4.059971442170395,
      "grad_norm": 0.0005513557698577642,
      "learning_rate": 1.1880057115659212e-05,
      "loss": 0.0001,
      "step": 8530
    },
    {
      "epoch": 4.064731080437887,
      "grad_norm": 0.004088149406015873,
      "learning_rate": 1.1870537839124228e-05,
      "loss": 0.0004,
      "step": 8540
    },
    {
      "epoch": 4.069490718705379,
      "grad_norm": 0.0025532259605824947,
      "learning_rate": 1.1861018562589244e-05,
      "loss": 0.001,
      "step": 8550
    },
    {
      "epoch": 4.07425035697287,
      "grad_norm": 0.0015560687752440572,
      "learning_rate": 1.185149928605426e-05,
      "loss": 0.0001,
      "step": 8560
    },
    {
      "epoch": 4.079009995240361,
      "grad_norm": 0.0005018958472646773,
      "learning_rate": 1.1841980009519278e-05,
      "loss": 0.0001,
      "step": 8570
    },
    {
      "epoch": 4.0837696335078535,
      "grad_norm": 0.0016572983004152775,
      "learning_rate": 1.1832460732984294e-05,
      "loss": 0.0168,
      "step": 8580
    },
    {
      "epoch": 4.088529271775345,
      "grad_norm": 0.00039792750612832606,
      "learning_rate": 1.182294145644931e-05,
      "loss": 0.0001,
      "step": 8590
    },
    {
      "epoch": 4.093288910042837,
      "grad_norm": 0.0018044528551399708,
      "learning_rate": 1.1813422179914328e-05,
      "loss": 0.0006,
      "step": 8600
    },
    {
      "epoch": 4.098048548310328,
      "grad_norm": 0.0015635190065950155,
      "learning_rate": 1.1803902903379345e-05,
      "loss": 0.0032,
      "step": 8610
    },
    {
      "epoch": 4.10280818657782,
      "grad_norm": 4.644535064697266,
      "learning_rate": 1.1794383626844361e-05,
      "loss": 0.0222,
      "step": 8620
    },
    {
      "epoch": 4.107567824845312,
      "grad_norm": 0.0017609635833650827,
      "learning_rate": 1.1784864350309377e-05,
      "loss": 0.0003,
      "step": 8630
    },
    {
      "epoch": 4.112327463112804,
      "grad_norm": 0.0214828047901392,
      "learning_rate": 1.1775345073774393e-05,
      "loss": 0.0002,
      "step": 8640
    },
    {
      "epoch": 4.117087101380295,
      "grad_norm": 0.019194655120372772,
      "learning_rate": 1.1765825797239413e-05,
      "loss": 0.0,
      "step": 8650
    },
    {
      "epoch": 4.121846739647787,
      "grad_norm": 0.017963429912924767,
      "learning_rate": 1.1756306520704429e-05,
      "loss": 0.0107,
      "step": 8660
    },
    {
      "epoch": 4.126606377915278,
      "grad_norm": 0.002270047552883625,
      "learning_rate": 1.1746787244169445e-05,
      "loss": 0.022,
      "step": 8670
    },
    {
      "epoch": 4.1313660161827706,
      "grad_norm": 0.020186256617307663,
      "learning_rate": 1.173726796763446e-05,
      "loss": 0.0296,
      "step": 8680
    },
    {
      "epoch": 4.136125654450262,
      "grad_norm": 0.0026017792988568544,
      "learning_rate": 1.1727748691099476e-05,
      "loss": 0.0004,
      "step": 8690
    },
    {
      "epoch": 4.140885292717753,
      "grad_norm": 0.000790307589340955,
      "learning_rate": 1.1718229414564494e-05,
      "loss": 0.0004,
      "step": 8700
    },
    {
      "epoch": 4.145644930985245,
      "grad_norm": 0.000754911859985441,
      "learning_rate": 1.170871013802951e-05,
      "loss": 0.0019,
      "step": 8710
    },
    {
      "epoch": 4.1504045692527365,
      "grad_norm": 7.520400524139404,
      "learning_rate": 1.1699190861494528e-05,
      "loss": 0.0127,
      "step": 8720
    },
    {
      "epoch": 4.155164207520229,
      "grad_norm": 0.004615319427102804,
      "learning_rate": 1.1689671584959544e-05,
      "loss": 0.0,
      "step": 8730
    },
    {
      "epoch": 4.15992384578772,
      "grad_norm": 0.0019286514725536108,
      "learning_rate": 1.1680152308424561e-05,
      "loss": 0.0,
      "step": 8740
    },
    {
      "epoch": 4.164683484055212,
      "grad_norm": 0.0016564844409003854,
      "learning_rate": 1.1670633031889577e-05,
      "loss": 0.0003,
      "step": 8750
    },
    {
      "epoch": 4.169443122322703,
      "grad_norm": 0.0032911605667322874,
      "learning_rate": 1.1661113755354593e-05,
      "loss": 0.0065,
      "step": 8760
    },
    {
      "epoch": 4.1742027605901955,
      "grad_norm": 0.0009220726205967367,
      "learning_rate": 1.165159447881961e-05,
      "loss": 0.0001,
      "step": 8770
    },
    {
      "epoch": 4.178962398857687,
      "grad_norm": 0.0015746729914098978,
      "learning_rate": 1.1642075202284629e-05,
      "loss": 0.0001,
      "step": 8780
    },
    {
      "epoch": 4.183722037125179,
      "grad_norm": 0.010483439080417156,
      "learning_rate": 1.1632555925749645e-05,
      "loss": 0.0,
      "step": 8790
    },
    {
      "epoch": 4.18848167539267,
      "grad_norm": 0.0026816159952431917,
      "learning_rate": 1.162303664921466e-05,
      "loss": 0.0002,
      "step": 8800
    },
    {
      "epoch": 4.193241313660161,
      "grad_norm": 0.0005746902315877378,
      "learning_rate": 1.1613517372679677e-05,
      "loss": 0.0001,
      "step": 8810
    },
    {
      "epoch": 4.1980009519276535,
      "grad_norm": 0.003560597775503993,
      "learning_rate": 1.1603998096144693e-05,
      "loss": 0.0002,
      "step": 8820
    },
    {
      "epoch": 4.202760590195145,
      "grad_norm": 0.0073263924568891525,
      "learning_rate": 1.1594478819609712e-05,
      "loss": 0.0001,
      "step": 8830
    },
    {
      "epoch": 4.207520228462637,
      "grad_norm": 0.0029819488991051912,
      "learning_rate": 1.1584959543074728e-05,
      "loss": 0.0547,
      "step": 8840
    },
    {
      "epoch": 4.212279866730128,
      "grad_norm": 0.014401816762983799,
      "learning_rate": 1.1575440266539744e-05,
      "loss": 0.0002,
      "step": 8850
    },
    {
      "epoch": 4.21703950499762,
      "grad_norm": 0.2049894481897354,
      "learning_rate": 1.156592099000476e-05,
      "loss": 0.0028,
      "step": 8860
    },
    {
      "epoch": 4.221799143265112,
      "grad_norm": 0.00035584051511250436,
      "learning_rate": 1.1556401713469778e-05,
      "loss": 0.0,
      "step": 8870
    },
    {
      "epoch": 4.226558781532604,
      "grad_norm": 0.0009164145449176431,
      "learning_rate": 1.1546882436934794e-05,
      "loss": 0.0,
      "step": 8880
    },
    {
      "epoch": 4.231318419800095,
      "grad_norm": 0.0002310339332325384,
      "learning_rate": 1.153736316039981e-05,
      "loss": 0.0001,
      "step": 8890
    },
    {
      "epoch": 4.236078058067587,
      "grad_norm": 0.0032344218343496323,
      "learning_rate": 1.1527843883864826e-05,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 4.2408376963350785,
      "grad_norm": 0.0008215190609917045,
      "learning_rate": 1.1518324607329845e-05,
      "loss": 0.0005,
      "step": 8910
    },
    {
      "epoch": 4.245597334602571,
      "grad_norm": 0.15791936218738556,
      "learning_rate": 1.1508805330794861e-05,
      "loss": 0.0001,
      "step": 8920
    },
    {
      "epoch": 4.250356972870062,
      "grad_norm": 0.0006617194740101695,
      "learning_rate": 1.1499286054259877e-05,
      "loss": 0.0,
      "step": 8930
    },
    {
      "epoch": 4.255116611137554,
      "grad_norm": 6.167481899261475,
      "learning_rate": 1.1489766777724893e-05,
      "loss": 0.0229,
      "step": 8940
    },
    {
      "epoch": 4.259876249405045,
      "grad_norm": 0.0006291312747634947,
      "learning_rate": 1.1480247501189909e-05,
      "loss": 0.0223,
      "step": 8950
    },
    {
      "epoch": 4.2646358876725365,
      "grad_norm": 0.006044947542250156,
      "learning_rate": 1.1470728224654928e-05,
      "loss": 0.0001,
      "step": 8960
    },
    {
      "epoch": 4.269395525940029,
      "grad_norm": 0.0032496624626219273,
      "learning_rate": 1.1461208948119944e-05,
      "loss": 0.0001,
      "step": 8970
    },
    {
      "epoch": 4.27415516420752,
      "grad_norm": 0.006286927964538336,
      "learning_rate": 1.145168967158496e-05,
      "loss": 0.0001,
      "step": 8980
    },
    {
      "epoch": 4.278914802475012,
      "grad_norm": 0.21624751389026642,
      "learning_rate": 1.1442170395049976e-05,
      "loss": 0.0111,
      "step": 8990
    },
    {
      "epoch": 4.283674440742503,
      "grad_norm": 0.0011045433348044753,
      "learning_rate": 1.1432651118514994e-05,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 4.2884340790099955,
      "grad_norm": 0.0008879081578925252,
      "learning_rate": 1.142313184198001e-05,
      "loss": 0.01,
      "step": 9010
    },
    {
      "epoch": 4.293193717277487,
      "grad_norm": 0.0010559791699051857,
      "learning_rate": 1.1413612565445028e-05,
      "loss": 0.0,
      "step": 9020
    },
    {
      "epoch": 4.297953355544979,
      "grad_norm": 0.000920998805668205,
      "learning_rate": 1.1404093288910044e-05,
      "loss": 0.004,
      "step": 9030
    },
    {
      "epoch": 4.30271299381247,
      "grad_norm": 0.0010282729053869843,
      "learning_rate": 1.1394574012375061e-05,
      "loss": 0.0006,
      "step": 9040
    },
    {
      "epoch": 4.307472632079962,
      "grad_norm": 0.0021935496479272842,
      "learning_rate": 1.1385054735840077e-05,
      "loss": 0.0,
      "step": 9050
    },
    {
      "epoch": 4.312232270347454,
      "grad_norm": 0.0007474554586224258,
      "learning_rate": 1.1375535459305093e-05,
      "loss": 0.0006,
      "step": 9060
    },
    {
      "epoch": 4.316991908614945,
      "grad_norm": 0.005051352083683014,
      "learning_rate": 1.136601618277011e-05,
      "loss": 0.0012,
      "step": 9070
    },
    {
      "epoch": 4.321751546882437,
      "grad_norm": 0.5706655383110046,
      "learning_rate": 1.1356496906235125e-05,
      "loss": 0.0221,
      "step": 9080
    },
    {
      "epoch": 4.326511185149928,
      "grad_norm": 0.0060414825566112995,
      "learning_rate": 1.1346977629700145e-05,
      "loss": 0.021,
      "step": 9090
    },
    {
      "epoch": 4.33127082341742,
      "grad_norm": 0.003767850110307336,
      "learning_rate": 1.133745835316516e-05,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 4.336030461684912,
      "grad_norm": 0.0006282784743234515,
      "learning_rate": 1.1327939076630177e-05,
      "loss": 0.0,
      "step": 9110
    },
    {
      "epoch": 4.340790099952404,
      "grad_norm": 0.0032492561731487513,
      "learning_rate": 1.1318419800095193e-05,
      "loss": 0.0001,
      "step": 9120
    },
    {
      "epoch": 4.345549738219895,
      "grad_norm": 0.0012548385420814157,
      "learning_rate": 1.130890052356021e-05,
      "loss": 0.0015,
      "step": 9130
    },
    {
      "epoch": 4.350309376487387,
      "grad_norm": 0.0018437884282320738,
      "learning_rate": 1.1299381247025228e-05,
      "loss": 0.0241,
      "step": 9140
    },
    {
      "epoch": 4.3550690147548785,
      "grad_norm": 5.288732051849365,
      "learning_rate": 1.1289861970490244e-05,
      "loss": 0.0008,
      "step": 9150
    },
    {
      "epoch": 4.359828653022371,
      "grad_norm": 0.27200743556022644,
      "learning_rate": 1.128034269395526e-05,
      "loss": 0.0001,
      "step": 9160
    },
    {
      "epoch": 4.364588291289862,
      "grad_norm": 0.018516365438699722,
      "learning_rate": 1.1270823417420278e-05,
      "loss": 0.0001,
      "step": 9170
    },
    {
      "epoch": 4.369347929557353,
      "grad_norm": 0.0004044755478389561,
      "learning_rate": 1.1261304140885294e-05,
      "loss": 0.0,
      "step": 9180
    },
    {
      "epoch": 4.374107567824845,
      "grad_norm": 14.364730834960938,
      "learning_rate": 1.125178486435031e-05,
      "loss": 0.004,
      "step": 9190
    },
    {
      "epoch": 4.378867206092337,
      "grad_norm": 0.0016346729826182127,
      "learning_rate": 1.1242265587815326e-05,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 4.383626844359829,
      "grad_norm": 0.0008674539858475327,
      "learning_rate": 1.1232746311280343e-05,
      "loss": 0.0,
      "step": 9210
    },
    {
      "epoch": 4.38838648262732,
      "grad_norm": 0.001264526043087244,
      "learning_rate": 1.1223227034745361e-05,
      "loss": 0.0021,
      "step": 9220
    },
    {
      "epoch": 4.393146120894812,
      "grad_norm": 0.01982704922556877,
      "learning_rate": 1.1213707758210377e-05,
      "loss": 0.0,
      "step": 9230
    },
    {
      "epoch": 4.397905759162303,
      "grad_norm": 0.0009565247455611825,
      "learning_rate": 1.1204188481675393e-05,
      "loss": 0.0018,
      "step": 9240
    },
    {
      "epoch": 4.402665397429796,
      "grad_norm": 0.0010307526681572199,
      "learning_rate": 1.1194669205140409e-05,
      "loss": 0.0001,
      "step": 9250
    },
    {
      "epoch": 4.407425035697287,
      "grad_norm": 0.001993484329432249,
      "learning_rate": 1.1185149928605428e-05,
      "loss": 0.0015,
      "step": 9260
    },
    {
      "epoch": 4.412184673964779,
      "grad_norm": 0.002617489779368043,
      "learning_rate": 1.1175630652070444e-05,
      "loss": 0.0101,
      "step": 9270
    },
    {
      "epoch": 4.41694431223227,
      "grad_norm": 0.0003894041001331061,
      "learning_rate": 1.116611137553546e-05,
      "loss": 0.0004,
      "step": 9280
    },
    {
      "epoch": 4.421703950499762,
      "grad_norm": 0.0023962731938809156,
      "learning_rate": 1.1156592099000476e-05,
      "loss": 0.0044,
      "step": 9290
    },
    {
      "epoch": 4.426463588767254,
      "grad_norm": 0.0011208807118237019,
      "learning_rate": 1.1147072822465494e-05,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 4.431223227034746,
      "grad_norm": 0.0012117483420297503,
      "learning_rate": 1.113755354593051e-05,
      "loss": 0.0,
      "step": 9310
    },
    {
      "epoch": 4.435982865302237,
      "grad_norm": 0.00030190052348189056,
      "learning_rate": 1.1128034269395526e-05,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 4.440742503569728,
      "grad_norm": 0.0011996043613180518,
      "learning_rate": 1.1118514992860544e-05,
      "loss": 0.0,
      "step": 9330
    },
    {
      "epoch": 4.4455021418372205,
      "grad_norm": 0.0006175845628604293,
      "learning_rate": 1.110899571632556e-05,
      "loss": 0.0001,
      "step": 9340
    },
    {
      "epoch": 4.450261780104712,
      "grad_norm": 0.0026946940924972296,
      "learning_rate": 1.1099476439790577e-05,
      "loss": 0.0,
      "step": 9350
    },
    {
      "epoch": 4.455021418372204,
      "grad_norm": 0.009894954971969128,
      "learning_rate": 1.1089957163255593e-05,
      "loss": 0.0,
      "step": 9360
    },
    {
      "epoch": 4.459781056639695,
      "grad_norm": 0.0020488661248236895,
      "learning_rate": 1.108043788672061e-05,
      "loss": 0.0002,
      "step": 9370
    },
    {
      "epoch": 4.464540694907187,
      "grad_norm": 0.001109928241930902,
      "learning_rate": 1.1070918610185625e-05,
      "loss": 0.0004,
      "step": 9380
    },
    {
      "epoch": 4.469300333174679,
      "grad_norm": 0.0005526954773813486,
      "learning_rate": 1.1061399333650645e-05,
      "loss": 0.004,
      "step": 9390
    },
    {
      "epoch": 4.474059971442171,
      "grad_norm": 0.007486946880817413,
      "learning_rate": 1.105188005711566e-05,
      "loss": 0.0001,
      "step": 9400
    },
    {
      "epoch": 4.478819609709662,
      "grad_norm": 5.975259304046631,
      "learning_rate": 1.1042360780580677e-05,
      "loss": 0.0137,
      "step": 9410
    },
    {
      "epoch": 4.483579247977154,
      "grad_norm": 0.0005279955803416669,
      "learning_rate": 1.1032841504045693e-05,
      "loss": 0.008,
      "step": 9420
    },
    {
      "epoch": 4.488338886244645,
      "grad_norm": 0.006133076269179583,
      "learning_rate": 1.102332222751071e-05,
      "loss": 0.0105,
      "step": 9430
    },
    {
      "epoch": 4.493098524512137,
      "grad_norm": 0.0006606252281926572,
      "learning_rate": 1.1013802950975728e-05,
      "loss": 0.0001,
      "step": 9440
    },
    {
      "epoch": 4.497858162779629,
      "grad_norm": 0.0017082698177546263,
      "learning_rate": 1.1004283674440744e-05,
      "loss": 0.0,
      "step": 9450
    },
    {
      "epoch": 4.50261780104712,
      "grad_norm": 0.07282451540231705,
      "learning_rate": 1.099476439790576e-05,
      "loss": 0.0007,
      "step": 9460
    },
    {
      "epoch": 4.507377439314612,
      "grad_norm": 0.23274977505207062,
      "learning_rate": 1.0985245121370778e-05,
      "loss": 0.0138,
      "step": 9470
    },
    {
      "epoch": 4.5121370775821035,
      "grad_norm": 9.938533782958984,
      "learning_rate": 1.0975725844835794e-05,
      "loss": 0.062,
      "step": 9480
    },
    {
      "epoch": 4.516896715849596,
      "grad_norm": 0.0012372750788927078,
      "learning_rate": 1.096620656830081e-05,
      "loss": 0.0002,
      "step": 9490
    },
    {
      "epoch": 4.521656354117087,
      "grad_norm": 0.028951892629265785,
      "learning_rate": 1.0956687291765826e-05,
      "loss": 0.0001,
      "step": 9500
    },
    {
      "epoch": 4.526415992384579,
      "grad_norm": 0.0007254869560711086,
      "learning_rate": 1.0947168015230842e-05,
      "loss": 0.0001,
      "step": 9510
    },
    {
      "epoch": 4.53117563065207,
      "grad_norm": 0.00692457752302289,
      "learning_rate": 1.0937648738695861e-05,
      "loss": 0.0001,
      "step": 9520
    },
    {
      "epoch": 4.5359352689195624,
      "grad_norm": 0.00033375047496519983,
      "learning_rate": 1.0928129462160877e-05,
      "loss": 0.0,
      "step": 9530
    },
    {
      "epoch": 4.540694907187054,
      "grad_norm": 0.0020890082232654095,
      "learning_rate": 1.0918610185625893e-05,
      "loss": 0.0013,
      "step": 9540
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.000495220476295799,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.0013,
      "step": 9550
    },
    {
      "epoch": 4.550214183722037,
      "grad_norm": 0.0006140679470263422,
      "learning_rate": 1.0899571632555928e-05,
      "loss": 0.0,
      "step": 9560
    },
    {
      "epoch": 4.554973821989529,
      "grad_norm": 0.0004615127691067755,
      "learning_rate": 1.0890052356020944e-05,
      "loss": 0.0108,
      "step": 9570
    },
    {
      "epoch": 4.5597334602570205,
      "grad_norm": 0.002747809048742056,
      "learning_rate": 1.088053307948596e-05,
      "loss": 0.0194,
      "step": 9580
    },
    {
      "epoch": 4.564493098524512,
      "grad_norm": 6.7545976638793945,
      "learning_rate": 1.0871013802950976e-05,
      "loss": 0.0627,
      "step": 9590
    },
    {
      "epoch": 4.569252736792004,
      "grad_norm": 0.02923966757953167,
      "learning_rate": 1.0861494526415994e-05,
      "loss": 0.0005,
      "step": 9600
    },
    {
      "epoch": 4.574012375059495,
      "grad_norm": 0.009656702168285847,
      "learning_rate": 1.085197524988101e-05,
      "loss": 0.0029,
      "step": 9610
    },
    {
      "epoch": 4.578772013326987,
      "grad_norm": 0.007583829574286938,
      "learning_rate": 1.0842455973346026e-05,
      "loss": 0.0137,
      "step": 9620
    },
    {
      "epoch": 4.583531651594479,
      "grad_norm": 0.01834310218691826,
      "learning_rate": 1.0832936696811044e-05,
      "loss": 0.0007,
      "step": 9630
    },
    {
      "epoch": 4.588291289861971,
      "grad_norm": 0.0047731176018714905,
      "learning_rate": 1.082341742027606e-05,
      "loss": 0.0002,
      "step": 9640
    },
    {
      "epoch": 4.593050928129462,
      "grad_norm": 0.026735734194517136,
      "learning_rate": 1.0813898143741077e-05,
      "loss": 0.0019,
      "step": 9650
    },
    {
      "epoch": 4.597810566396954,
      "grad_norm": 0.0014225626364350319,
      "learning_rate": 1.0804378867206093e-05,
      "loss": 0.0135,
      "step": 9660
    },
    {
      "epoch": 4.602570204664445,
      "grad_norm": 16.19977569580078,
      "learning_rate": 1.079485959067111e-05,
      "loss": 0.0117,
      "step": 9670
    },
    {
      "epoch": 4.607329842931938,
      "grad_norm": 0.0004629257891792804,
      "learning_rate": 1.0785340314136125e-05,
      "loss": 0.0155,
      "step": 9680
    },
    {
      "epoch": 4.612089481199429,
      "grad_norm": 0.00046697279321961105,
      "learning_rate": 1.0775821037601145e-05,
      "loss": 0.0,
      "step": 9690
    },
    {
      "epoch": 4.61684911946692,
      "grad_norm": 0.0006665998371317983,
      "learning_rate": 1.076630176106616e-05,
      "loss": 0.0005,
      "step": 9700
    },
    {
      "epoch": 4.621608757734412,
      "grad_norm": 4.249361991882324,
      "learning_rate": 1.0756782484531177e-05,
      "loss": 0.0144,
      "step": 9710
    },
    {
      "epoch": 4.6263683960019035,
      "grad_norm": 12.073176383972168,
      "learning_rate": 1.0747263207996193e-05,
      "loss": 0.0161,
      "step": 9720
    },
    {
      "epoch": 4.631128034269396,
      "grad_norm": 0.0016898206667974591,
      "learning_rate": 1.073774393146121e-05,
      "loss": 0.0039,
      "step": 9730
    },
    {
      "epoch": 4.635887672536887,
      "grad_norm": 0.04711408540606499,
      "learning_rate": 1.0728224654926226e-05,
      "loss": 0.0001,
      "step": 9740
    },
    {
      "epoch": 4.640647310804379,
      "grad_norm": 0.006105236243456602,
      "learning_rate": 1.0718705378391244e-05,
      "loss": 0.0002,
      "step": 9750
    },
    {
      "epoch": 4.64540694907187,
      "grad_norm": 0.02539237216114998,
      "learning_rate": 1.070918610185626e-05,
      "loss": 0.0001,
      "step": 9760
    },
    {
      "epoch": 4.6501665873393625,
      "grad_norm": 0.004001453053206205,
      "learning_rate": 1.0699666825321276e-05,
      "loss": 0.0001,
      "step": 9770
    },
    {
      "epoch": 4.654926225606854,
      "grad_norm": 0.0006762819248251617,
      "learning_rate": 1.0690147548786294e-05,
      "loss": 0.002,
      "step": 9780
    },
    {
      "epoch": 4.659685863874346,
      "grad_norm": 0.005754642654210329,
      "learning_rate": 1.068062827225131e-05,
      "loss": 0.0001,
      "step": 9790
    },
    {
      "epoch": 4.664445502141837,
      "grad_norm": 0.007862572558224201,
      "learning_rate": 1.0671108995716326e-05,
      "loss": 0.0001,
      "step": 9800
    },
    {
      "epoch": 4.669205140409328,
      "grad_norm": 2.092984199523926,
      "learning_rate": 1.0661589719181341e-05,
      "loss": 0.0358,
      "step": 9810
    },
    {
      "epoch": 4.673964778676821,
      "grad_norm": 0.0029754876159131527,
      "learning_rate": 1.0652070442646361e-05,
      "loss": 0.0001,
      "step": 9820
    },
    {
      "epoch": 4.678724416944312,
      "grad_norm": 1.1721934080123901,
      "learning_rate": 1.0642551166111377e-05,
      "loss": 0.0013,
      "step": 9830
    },
    {
      "epoch": 4.683484055211804,
      "grad_norm": 0.0006692314054816961,
      "learning_rate": 1.0633031889576393e-05,
      "loss": 0.0023,
      "step": 9840
    },
    {
      "epoch": 4.688243693479295,
      "grad_norm": 0.00236652884632349,
      "learning_rate": 1.0623512613041409e-05,
      "loss": 0.0085,
      "step": 9850
    },
    {
      "epoch": 4.693003331746787,
      "grad_norm": 5.867001533508301,
      "learning_rate": 1.0613993336506428e-05,
      "loss": 0.0181,
      "step": 9860
    },
    {
      "epoch": 4.697762970014279,
      "grad_norm": 0.004990188870579004,
      "learning_rate": 1.0604474059971444e-05,
      "loss": 0.0001,
      "step": 9870
    },
    {
      "epoch": 4.702522608281771,
      "grad_norm": 0.0037344496231526136,
      "learning_rate": 1.059495478343646e-05,
      "loss": 0.0001,
      "step": 9880
    },
    {
      "epoch": 4.707282246549262,
      "grad_norm": 0.007451718207448721,
      "learning_rate": 1.0585435506901476e-05,
      "loss": 0.0036,
      "step": 9890
    },
    {
      "epoch": 4.712041884816754,
      "grad_norm": 0.003487137844786048,
      "learning_rate": 1.0575916230366492e-05,
      "loss": 0.0001,
      "step": 9900
    },
    {
      "epoch": 4.7168015230842455,
      "grad_norm": 0.0009905484039336443,
      "learning_rate": 1.056639695383151e-05,
      "loss": 0.0077,
      "step": 9910
    },
    {
      "epoch": 4.721561161351738,
      "grad_norm": 0.0007220026454888284,
      "learning_rate": 1.0556877677296526e-05,
      "loss": 0.0002,
      "step": 9920
    },
    {
      "epoch": 4.726320799619229,
      "grad_norm": 0.0034933395218104124,
      "learning_rate": 1.0547358400761542e-05,
      "loss": 0.0,
      "step": 9930
    },
    {
      "epoch": 4.731080437886721,
      "grad_norm": 0.0034993067383766174,
      "learning_rate": 1.053783912422656e-05,
      "loss": 0.0001,
      "step": 9940
    },
    {
      "epoch": 4.735840076154212,
      "grad_norm": 0.0007663404103368521,
      "learning_rate": 1.0528319847691577e-05,
      "loss": 0.0,
      "step": 9950
    },
    {
      "epoch": 4.740599714421704,
      "grad_norm": 0.3164615035057068,
      "learning_rate": 1.0518800571156593e-05,
      "loss": 0.0482,
      "step": 9960
    },
    {
      "epoch": 4.745359352689196,
      "grad_norm": 0.00030916804098524153,
      "learning_rate": 1.0509281294621609e-05,
      "loss": 0.0001,
      "step": 9970
    },
    {
      "epoch": 4.750118990956687,
      "grad_norm": 0.008217909373342991,
      "learning_rate": 1.0499762018086625e-05,
      "loss": 0.0009,
      "step": 9980
    },
    {
      "epoch": 4.754878629224179,
      "grad_norm": 0.00044236131361685693,
      "learning_rate": 1.0490242741551644e-05,
      "loss": 0.02,
      "step": 9990
    },
    {
      "epoch": 4.75963826749167,
      "grad_norm": 0.0004018713370896876,
      "learning_rate": 1.048072346501666e-05,
      "loss": 0.0004,
      "step": 10000
    },
    {
      "epoch": 4.7643979057591626,
      "grad_norm": 8.292057037353516,
      "learning_rate": 1.0471204188481676e-05,
      "loss": 0.0167,
      "step": 10010
    },
    {
      "epoch": 4.769157544026654,
      "grad_norm": 0.0007605704595334828,
      "learning_rate": 1.0461684911946692e-05,
      "loss": 0.0006,
      "step": 10020
    },
    {
      "epoch": 4.773917182294146,
      "grad_norm": 0.0005349001730792224,
      "learning_rate": 1.0452165635411708e-05,
      "loss": 0.005,
      "step": 10030
    },
    {
      "epoch": 4.778676820561637,
      "grad_norm": 0.5601047277450562,
      "learning_rate": 1.0442646358876726e-05,
      "loss": 0.0005,
      "step": 10040
    },
    {
      "epoch": 4.783436458829129,
      "grad_norm": 0.023789657279849052,
      "learning_rate": 1.0433127082341744e-05,
      "loss": 0.0001,
      "step": 10050
    },
    {
      "epoch": 4.788196097096621,
      "grad_norm": 0.016559302806854248,
      "learning_rate": 1.042360780580676e-05,
      "loss": 0.022,
      "step": 10060
    },
    {
      "epoch": 4.792955735364112,
      "grad_norm": 0.0024805034045130014,
      "learning_rate": 1.0414088529271776e-05,
      "loss": 0.0178,
      "step": 10070
    },
    {
      "epoch": 4.797715373631604,
      "grad_norm": 0.0008534718072041869,
      "learning_rate": 1.0404569252736793e-05,
      "loss": 0.0,
      "step": 10080
    },
    {
      "epoch": 4.802475011899095,
      "grad_norm": 0.0017385404789820313,
      "learning_rate": 1.039504997620181e-05,
      "loss": 0.0002,
      "step": 10090
    },
    {
      "epoch": 4.8072346501665875,
      "grad_norm": 0.0012536168796941638,
      "learning_rate": 1.0385530699666825e-05,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 4.811994288434079,
      "grad_norm": 0.000449540326371789,
      "learning_rate": 1.0376011423131841e-05,
      "loss": 0.0002,
      "step": 10110
    },
    {
      "epoch": 4.816753926701571,
      "grad_norm": 0.001975923776626587,
      "learning_rate": 1.036649214659686e-05,
      "loss": 0.0102,
      "step": 10120
    },
    {
      "epoch": 4.821513564969062,
      "grad_norm": 0.010187716223299503,
      "learning_rate": 1.0356972870061877e-05,
      "loss": 0.0,
      "step": 10130
    },
    {
      "epoch": 4.826273203236554,
      "grad_norm": 0.0004998735967092216,
      "learning_rate": 1.0347453593526893e-05,
      "loss": 0.0,
      "step": 10140
    },
    {
      "epoch": 4.8310328415040455,
      "grad_norm": 0.0005152960075065494,
      "learning_rate": 1.0337934316991909e-05,
      "loss": 0.0039,
      "step": 10150
    },
    {
      "epoch": 4.835792479771538,
      "grad_norm": 0.0002778539201244712,
      "learning_rate": 1.0328415040456926e-05,
      "loss": 0.0019,
      "step": 10160
    },
    {
      "epoch": 4.840552118039029,
      "grad_norm": 0.16792231798171997,
      "learning_rate": 1.0318895763921944e-05,
      "loss": 0.0362,
      "step": 10170
    },
    {
      "epoch": 4.84531175630652,
      "grad_norm": 0.0006742059485986829,
      "learning_rate": 1.030937648738696e-05,
      "loss": 0.0136,
      "step": 10180
    },
    {
      "epoch": 4.850071394574012,
      "grad_norm": 0.004985985811799765,
      "learning_rate": 1.0299857210851976e-05,
      "loss": 0.0772,
      "step": 10190
    },
    {
      "epoch": 4.8548310328415045,
      "grad_norm": 0.005373517517000437,
      "learning_rate": 1.0290337934316992e-05,
      "loss": 0.0054,
      "step": 10200
    },
    {
      "epoch": 4.859590671108996,
      "grad_norm": 0.0009646356920711696,
      "learning_rate": 1.028081865778201e-05,
      "loss": 0.0269,
      "step": 10210
    },
    {
      "epoch": 4.864350309376487,
      "grad_norm": 0.011059826239943504,
      "learning_rate": 1.0271299381247026e-05,
      "loss": 0.0002,
      "step": 10220
    },
    {
      "epoch": 4.869109947643979,
      "grad_norm": 0.008336419239640236,
      "learning_rate": 1.0261780104712042e-05,
      "loss": 0.0002,
      "step": 10230
    },
    {
      "epoch": 4.8738695859114705,
      "grad_norm": 0.007554154377430677,
      "learning_rate": 1.025226082817706e-05,
      "loss": 0.0002,
      "step": 10240
    },
    {
      "epoch": 4.878629224178963,
      "grad_norm": 0.004876438062638044,
      "learning_rate": 1.0242741551642077e-05,
      "loss": 0.001,
      "step": 10250
    },
    {
      "epoch": 4.883388862446454,
      "grad_norm": 0.003075163345783949,
      "learning_rate": 1.0233222275107093e-05,
      "loss": 0.0073,
      "step": 10260
    },
    {
      "epoch": 4.888148500713946,
      "grad_norm": 7.420732498168945,
      "learning_rate": 1.0223702998572109e-05,
      "loss": 0.0276,
      "step": 10270
    },
    {
      "epoch": 4.892908138981437,
      "grad_norm": 0.0019272578647360206,
      "learning_rate": 1.0214183722037125e-05,
      "loss": 0.0001,
      "step": 10280
    },
    {
      "epoch": 4.897667777248929,
      "grad_norm": 3.8476176261901855,
      "learning_rate": 1.0204664445502144e-05,
      "loss": 0.0253,
      "step": 10290
    },
    {
      "epoch": 4.902427415516421,
      "grad_norm": 0.007273493800312281,
      "learning_rate": 1.019514516896716e-05,
      "loss": 0.0009,
      "step": 10300
    },
    {
      "epoch": 4.907187053783913,
      "grad_norm": 0.006317471154034138,
      "learning_rate": 1.0185625892432176e-05,
      "loss": 0.02,
      "step": 10310
    },
    {
      "epoch": 4.911946692051404,
      "grad_norm": 0.013088110834360123,
      "learning_rate": 1.0176106615897192e-05,
      "loss": 0.0001,
      "step": 10320
    },
    {
      "epoch": 4.916706330318895,
      "grad_norm": 0.00820895005017519,
      "learning_rate": 1.0166587339362208e-05,
      "loss": 0.0003,
      "step": 10330
    },
    {
      "epoch": 4.9214659685863875,
      "grad_norm": 0.005940871313214302,
      "learning_rate": 1.0157068062827226e-05,
      "loss": 0.0063,
      "step": 10340
    },
    {
      "epoch": 4.926225606853879,
      "grad_norm": 0.005172170698642731,
      "learning_rate": 1.0147548786292242e-05,
      "loss": 0.0059,
      "step": 10350
    },
    {
      "epoch": 4.930985245121371,
      "grad_norm": 0.005250263027846813,
      "learning_rate": 1.013802950975726e-05,
      "loss": 0.0004,
      "step": 10360
    },
    {
      "epoch": 4.935744883388862,
      "grad_norm": 0.03677545115351677,
      "learning_rate": 1.0128510233222276e-05,
      "loss": 0.0001,
      "step": 10370
    },
    {
      "epoch": 4.940504521656354,
      "grad_norm": 0.7993491291999817,
      "learning_rate": 1.0118990956687293e-05,
      "loss": 0.0094,
      "step": 10380
    },
    {
      "epoch": 4.945264159923846,
      "grad_norm": 0.0117318881675601,
      "learning_rate": 1.010947168015231e-05,
      "loss": 0.0314,
      "step": 10390
    },
    {
      "epoch": 4.950023798191338,
      "grad_norm": 0.009269855916500092,
      "learning_rate": 1.0099952403617325e-05,
      "loss": 0.0108,
      "step": 10400
    },
    {
      "epoch": 4.954783436458829,
      "grad_norm": 0.005409519653767347,
      "learning_rate": 1.0090433127082341e-05,
      "loss": 0.0001,
      "step": 10410
    },
    {
      "epoch": 4.959543074726321,
      "grad_norm": 0.0017208250937983394,
      "learning_rate": 1.008091385054736e-05,
      "loss": 0.0128,
      "step": 10420
    },
    {
      "epoch": 4.964302712993812,
      "grad_norm": 0.00046460190787911415,
      "learning_rate": 1.0071394574012377e-05,
      "loss": 0.0001,
      "step": 10430
    },
    {
      "epoch": 4.969062351261304,
      "grad_norm": 0.0014301905175670981,
      "learning_rate": 1.0061875297477393e-05,
      "loss": 0.0001,
      "step": 10440
    },
    {
      "epoch": 4.973821989528796,
      "grad_norm": 0.006228215526789427,
      "learning_rate": 1.0052356020942409e-05,
      "loss": 0.0139,
      "step": 10450
    },
    {
      "epoch": 4.978581627796287,
      "grad_norm": 0.0014142352156341076,
      "learning_rate": 1.0042836744407425e-05,
      "loss": 0.0002,
      "step": 10460
    },
    {
      "epoch": 4.983341266063779,
      "grad_norm": 13.407495498657227,
      "learning_rate": 1.0033317467872444e-05,
      "loss": 0.017,
      "step": 10470
    },
    {
      "epoch": 4.9881009043312705,
      "grad_norm": 0.01527160033583641,
      "learning_rate": 1.002379819133746e-05,
      "loss": 0.0001,
      "step": 10480
    },
    {
      "epoch": 4.992860542598763,
      "grad_norm": 0.0030217997264117002,
      "learning_rate": 1.0014278914802476e-05,
      "loss": 0.0033,
      "step": 10490
    },
    {
      "epoch": 4.997620180866254,
      "grad_norm": 0.011761831119656563,
      "learning_rate": 1.0004759638267492e-05,
      "loss": 0.0001,
      "step": 10500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9969444444444444,
      "eval_f1": 0.9835698282300224,
      "eval_loss": 0.014664404094219208,
      "eval_precision": 0.9784546805349182,
      "eval_recall": 0.9887387387387387,
      "eval_runtime": 336.8682,
      "eval_samples_per_second": 42.779,
      "eval_steps_per_second": 1.339,
      "step": 10505
    },
    {
      "epoch": 5.002379819133746,
      "grad_norm": 0.004796565975993872,
      "learning_rate": 9.99524036173251e-06,
      "loss": 0.0104,
      "step": 10510
    },
    {
      "epoch": 5.007139457401237,
      "grad_norm": 0.20672975480556488,
      "learning_rate": 9.985721085197526e-06,
      "loss": 0.0001,
      "step": 10520
    },
    {
      "epoch": 5.0118990956687295,
      "grad_norm": 0.01308582816272974,
      "learning_rate": 9.976201808662542e-06,
      "loss": 0.0001,
      "step": 10530
    },
    {
      "epoch": 5.016658733936221,
      "grad_norm": 0.9862107038497925,
      "learning_rate": 9.96668253212756e-06,
      "loss": 0.0206,
      "step": 10540
    },
    {
      "epoch": 5.021418372203713,
      "grad_norm": 0.0014570840867236257,
      "learning_rate": 9.957163255592575e-06,
      "loss": 0.0002,
      "step": 10550
    },
    {
      "epoch": 5.026178010471204,
      "grad_norm": 0.7928550839424133,
      "learning_rate": 9.947643979057593e-06,
      "loss": 0.0003,
      "step": 10560
    },
    {
      "epoch": 5.030937648738695,
      "grad_norm": 0.0011063399724662304,
      "learning_rate": 9.938124702522609e-06,
      "loss": 0.0001,
      "step": 10570
    },
    {
      "epoch": 5.035697287006188,
      "grad_norm": 0.0016704053850844502,
      "learning_rate": 9.928605425987625e-06,
      "loss": 0.0001,
      "step": 10580
    },
    {
      "epoch": 5.040456925273679,
      "grad_norm": 0.004308032803237438,
      "learning_rate": 9.919086149452643e-06,
      "loss": 0.0196,
      "step": 10590
    },
    {
      "epoch": 5.045216563541171,
      "grad_norm": 0.003023372497409582,
      "learning_rate": 9.909566872917659e-06,
      "loss": 0.0,
      "step": 10600
    },
    {
      "epoch": 5.049976201808662,
      "grad_norm": 0.011950028128921986,
      "learning_rate": 9.900047596382676e-06,
      "loss": 0.0004,
      "step": 10610
    },
    {
      "epoch": 5.054735840076154,
      "grad_norm": 0.0034202029928565025,
      "learning_rate": 9.890528319847692e-06,
      "loss": 0.0007,
      "step": 10620
    },
    {
      "epoch": 5.059495478343646,
      "grad_norm": 0.06121790036559105,
      "learning_rate": 9.88100904331271e-06,
      "loss": 0.0001,
      "step": 10630
    },
    {
      "epoch": 5.064255116611138,
      "grad_norm": 0.001073501305654645,
      "learning_rate": 9.871489766777726e-06,
      "loss": 0.0092,
      "step": 10640
    },
    {
      "epoch": 5.069014754878629,
      "grad_norm": 0.00031894483254291117,
      "learning_rate": 9.861970490242742e-06,
      "loss": 0.0,
      "step": 10650
    },
    {
      "epoch": 5.073774393146121,
      "grad_norm": 0.00026360159972682595,
      "learning_rate": 9.85245121370776e-06,
      "loss": 0.0475,
      "step": 10660
    },
    {
      "epoch": 5.0785340314136125,
      "grad_norm": 0.0003379278932698071,
      "learning_rate": 9.842931937172776e-06,
      "loss": 0.0,
      "step": 10670
    },
    {
      "epoch": 5.083293669681105,
      "grad_norm": 0.0006315588834695518,
      "learning_rate": 9.833412660637792e-06,
      "loss": 0.0178,
      "step": 10680
    },
    {
      "epoch": 5.088053307948596,
      "grad_norm": 0.0021275258623063564,
      "learning_rate": 9.82389338410281e-06,
      "loss": 0.0002,
      "step": 10690
    },
    {
      "epoch": 5.092812946216087,
      "grad_norm": 0.01858905702829361,
      "learning_rate": 9.814374107567825e-06,
      "loss": 0.0001,
      "step": 10700
    },
    {
      "epoch": 5.097572584483579,
      "grad_norm": 0.005240400321781635,
      "learning_rate": 9.804854831032843e-06,
      "loss": 0.0,
      "step": 10710
    },
    {
      "epoch": 5.102332222751071,
      "grad_norm": 0.0002208162477472797,
      "learning_rate": 9.795335554497859e-06,
      "loss": 0.0002,
      "step": 10720
    },
    {
      "epoch": 5.107091861018563,
      "grad_norm": 0.00083884660853073,
      "learning_rate": 9.785816277962875e-06,
      "loss": 0.0,
      "step": 10730
    },
    {
      "epoch": 5.111851499286054,
      "grad_norm": 0.00014232401736080647,
      "learning_rate": 9.776297001427893e-06,
      "loss": 0.0,
      "step": 10740
    },
    {
      "epoch": 5.116611137553546,
      "grad_norm": 0.0004633965145330876,
      "learning_rate": 9.766777724892909e-06,
      "loss": 0.0,
      "step": 10750
    },
    {
      "epoch": 5.121370775821037,
      "grad_norm": 0.009497190825641155,
      "learning_rate": 9.757258448357926e-06,
      "loss": 0.0,
      "step": 10760
    },
    {
      "epoch": 5.1261304140885295,
      "grad_norm": 12.366254806518555,
      "learning_rate": 9.747739171822942e-06,
      "loss": 0.0123,
      "step": 10770
    },
    {
      "epoch": 5.130890052356021,
      "grad_norm": 0.0003996067971456796,
      "learning_rate": 9.73821989528796e-06,
      "loss": 0.0,
      "step": 10780
    },
    {
      "epoch": 5.135649690623513,
      "grad_norm": 0.0001517185301054269,
      "learning_rate": 9.728700618752976e-06,
      "loss": 0.0,
      "step": 10790
    },
    {
      "epoch": 5.140409328891004,
      "grad_norm": 0.0002107539912685752,
      "learning_rate": 9.719181342217992e-06,
      "loss": 0.0001,
      "step": 10800
    },
    {
      "epoch": 5.145168967158496,
      "grad_norm": 0.001213347539305687,
      "learning_rate": 9.70966206568301e-06,
      "loss": 0.0,
      "step": 10810
    },
    {
      "epoch": 5.149928605425988,
      "grad_norm": 0.0007172952755354345,
      "learning_rate": 9.700142789148026e-06,
      "loss": 0.0,
      "step": 10820
    },
    {
      "epoch": 5.154688243693479,
      "grad_norm": 0.008794493041932583,
      "learning_rate": 9.690623512613042e-06,
      "loss": 0.0,
      "step": 10830
    },
    {
      "epoch": 5.159447881960971,
      "grad_norm": 64.14188385009766,
      "learning_rate": 9.68110423607806e-06,
      "loss": 0.0143,
      "step": 10840
    },
    {
      "epoch": 5.164207520228462,
      "grad_norm": 0.003022919176146388,
      "learning_rate": 9.671584959543075e-06,
      "loss": 0.0048,
      "step": 10850
    },
    {
      "epoch": 5.1689671584959545,
      "grad_norm": 0.00047923208330757916,
      "learning_rate": 9.662065683008091e-06,
      "loss": 0.0,
      "step": 10860
    },
    {
      "epoch": 5.173726796763446,
      "grad_norm": 0.0619964674115181,
      "learning_rate": 9.652546406473109e-06,
      "loss": 0.004,
      "step": 10870
    },
    {
      "epoch": 5.178486435030938,
      "grad_norm": 0.00020407643751241267,
      "learning_rate": 9.643027129938125e-06,
      "loss": 0.0001,
      "step": 10880
    },
    {
      "epoch": 5.183246073298429,
      "grad_norm": 0.00036892149364575744,
      "learning_rate": 9.633507853403143e-06,
      "loss": 0.0,
      "step": 10890
    },
    {
      "epoch": 5.188005711565921,
      "grad_norm": 0.0013553376775234938,
      "learning_rate": 9.623988576868159e-06,
      "loss": 0.0001,
      "step": 10900
    },
    {
      "epoch": 5.1927653498334125,
      "grad_norm": 0.00023004978720564395,
      "learning_rate": 9.614469300333176e-06,
      "loss": 0.0,
      "step": 10910
    },
    {
      "epoch": 5.197524988100905,
      "grad_norm": 0.02672366052865982,
      "learning_rate": 9.604950023798192e-06,
      "loss": 0.0,
      "step": 10920
    },
    {
      "epoch": 5.202284626368396,
      "grad_norm": 0.004517714958637953,
      "learning_rate": 9.59543074726321e-06,
      "loss": 0.0,
      "step": 10930
    },
    {
      "epoch": 5.207044264635888,
      "grad_norm": 0.0003548884124029428,
      "learning_rate": 9.585911470728226e-06,
      "loss": 0.0,
      "step": 10940
    },
    {
      "epoch": 5.211803902903379,
      "grad_norm": 27.37339973449707,
      "learning_rate": 9.576392194193242e-06,
      "loss": 0.0058,
      "step": 10950
    },
    {
      "epoch": 5.216563541170871,
      "grad_norm": 0.0013856999576091766,
      "learning_rate": 9.566872917658258e-06,
      "loss": 0.0001,
      "step": 10960
    },
    {
      "epoch": 5.221323179438363,
      "grad_norm": 1.0869081020355225,
      "learning_rate": 9.557353641123276e-06,
      "loss": 0.0002,
      "step": 10970
    },
    {
      "epoch": 5.226082817705854,
      "grad_norm": 0.0005796458572149277,
      "learning_rate": 9.547834364588292e-06,
      "loss": 0.0031,
      "step": 10980
    },
    {
      "epoch": 5.230842455973346,
      "grad_norm": 0.010967972688376904,
      "learning_rate": 9.538315088053307e-06,
      "loss": 0.0029,
      "step": 10990
    },
    {
      "epoch": 5.2356020942408374,
      "grad_norm": 0.08666479587554932,
      "learning_rate": 9.528795811518325e-06,
      "loss": 0.0001,
      "step": 11000
    },
    {
      "epoch": 5.24036173250833,
      "grad_norm": 0.05276047810912132,
      "learning_rate": 9.519276534983341e-06,
      "loss": 0.0001,
      "step": 11010
    },
    {
      "epoch": 5.245121370775821,
      "grad_norm": 0.0011330707930028439,
      "learning_rate": 9.509757258448359e-06,
      "loss": 0.0007,
      "step": 11020
    },
    {
      "epoch": 5.249881009043313,
      "grad_norm": 0.0009105948847718537,
      "learning_rate": 9.500237981913375e-06,
      "loss": 0.009,
      "step": 11030
    },
    {
      "epoch": 5.254640647310804,
      "grad_norm": 0.0012954215053468943,
      "learning_rate": 9.490718705378393e-06,
      "loss": 0.0011,
      "step": 11040
    },
    {
      "epoch": 5.259400285578296,
      "grad_norm": 0.00023484720441047102,
      "learning_rate": 9.481199428843408e-06,
      "loss": 0.0003,
      "step": 11050
    },
    {
      "epoch": 5.264159923845788,
      "grad_norm": 0.0006691697635687888,
      "learning_rate": 9.471680152308426e-06,
      "loss": 0.0,
      "step": 11060
    },
    {
      "epoch": 5.268919562113279,
      "grad_norm": 0.0006109694368205965,
      "learning_rate": 9.462160875773442e-06,
      "loss": 0.0,
      "step": 11070
    },
    {
      "epoch": 5.273679200380771,
      "grad_norm": 0.0015302508836612105,
      "learning_rate": 9.45264159923846e-06,
      "loss": 0.0,
      "step": 11080
    },
    {
      "epoch": 5.278438838648262,
      "grad_norm": 0.0009388815378770232,
      "learning_rate": 9.443122322703476e-06,
      "loss": 0.0018,
      "step": 11090
    },
    {
      "epoch": 5.2831984769157545,
      "grad_norm": 0.00019267492461949587,
      "learning_rate": 9.433603046168492e-06,
      "loss": 0.0108,
      "step": 11100
    },
    {
      "epoch": 5.287958115183246,
      "grad_norm": 0.0003668803256005049,
      "learning_rate": 9.424083769633508e-06,
      "loss": 0.0298,
      "step": 11110
    },
    {
      "epoch": 5.292717753450738,
      "grad_norm": 0.0008855144260451198,
      "learning_rate": 9.414564493098525e-06,
      "loss": 0.0007,
      "step": 11120
    },
    {
      "epoch": 5.297477391718229,
      "grad_norm": 0.0007661182316951454,
      "learning_rate": 9.405045216563541e-06,
      "loss": 0.0,
      "step": 11130
    },
    {
      "epoch": 5.302237029985721,
      "grad_norm": 0.0003622838412411511,
      "learning_rate": 9.395525940028557e-06,
      "loss": 0.0,
      "step": 11140
    },
    {
      "epoch": 5.306996668253213,
      "grad_norm": 0.00020022888202220201,
      "learning_rate": 9.386006663493575e-06,
      "loss": 0.0,
      "step": 11150
    },
    {
      "epoch": 5.311756306520705,
      "grad_norm": 0.00010361718159401789,
      "learning_rate": 9.376487386958591e-06,
      "loss": 0.0,
      "step": 11160
    },
    {
      "epoch": 5.316515944788196,
      "grad_norm": 0.005345070268958807,
      "learning_rate": 9.366968110423609e-06,
      "loss": 0.0,
      "step": 11170
    },
    {
      "epoch": 5.321275583055688,
      "grad_norm": 0.00010335047409171239,
      "learning_rate": 9.357448833888625e-06,
      "loss": 0.0005,
      "step": 11180
    },
    {
      "epoch": 5.326035221323179,
      "grad_norm": 1.0733345746994019,
      "learning_rate": 9.347929557353642e-06,
      "loss": 0.0019,
      "step": 11190
    },
    {
      "epoch": 5.330794859590672,
      "grad_norm": 0.28093427419662476,
      "learning_rate": 9.338410280818658e-06,
      "loss": 0.0041,
      "step": 11200
    },
    {
      "epoch": 5.335554497858163,
      "grad_norm": 0.0007188760209828615,
      "learning_rate": 9.328891004283676e-06,
      "loss": 0.0116,
      "step": 11210
    },
    {
      "epoch": 5.340314136125654,
      "grad_norm": 0.0007470524869859219,
      "learning_rate": 9.319371727748692e-06,
      "loss": 0.0,
      "step": 11220
    },
    {
      "epoch": 5.345073774393146,
      "grad_norm": 0.2669542133808136,
      "learning_rate": 9.30985245121371e-06,
      "loss": 0.005,
      "step": 11230
    },
    {
      "epoch": 5.3498334126606375,
      "grad_norm": 0.023026861250400543,
      "learning_rate": 9.300333174678726e-06,
      "loss": 0.0005,
      "step": 11240
    },
    {
      "epoch": 5.35459305092813,
      "grad_norm": 0.0018765927525237203,
      "learning_rate": 9.290813898143742e-06,
      "loss": 0.0011,
      "step": 11250
    },
    {
      "epoch": 5.359352689195621,
      "grad_norm": 0.0001314575638389215,
      "learning_rate": 9.281294621608758e-06,
      "loss": 0.0,
      "step": 11260
    },
    {
      "epoch": 5.364112327463113,
      "grad_norm": 0.00016213090566452593,
      "learning_rate": 9.271775345073775e-06,
      "loss": 0.0347,
      "step": 11270
    },
    {
      "epoch": 5.368871965730604,
      "grad_norm": 0.0010037660831585526,
      "learning_rate": 9.262256068538791e-06,
      "loss": 0.0002,
      "step": 11280
    },
    {
      "epoch": 5.3736316039980965,
      "grad_norm": 13.10817813873291,
      "learning_rate": 9.252736792003807e-06,
      "loss": 0.0037,
      "step": 11290
    },
    {
      "epoch": 5.378391242265588,
      "grad_norm": 0.0009617520263418555,
      "learning_rate": 9.243217515468825e-06,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 5.38315088053308,
      "grad_norm": 0.024118436500430107,
      "learning_rate": 9.233698238933841e-06,
      "loss": 0.0007,
      "step": 11310
    },
    {
      "epoch": 5.387910518800571,
      "grad_norm": 0.003050411120057106,
      "learning_rate": 9.224178962398859e-06,
      "loss": 0.0,
      "step": 11320
    },
    {
      "epoch": 5.392670157068062,
      "grad_norm": 0.008388725109398365,
      "learning_rate": 9.214659685863875e-06,
      "loss": 0.0,
      "step": 11330
    },
    {
      "epoch": 5.397429795335555,
      "grad_norm": 0.0002485053555574268,
      "learning_rate": 9.205140409328892e-06,
      "loss": 0.0155,
      "step": 11340
    },
    {
      "epoch": 5.402189433603046,
      "grad_norm": 0.0009576924494467676,
      "learning_rate": 9.195621132793908e-06,
      "loss": 0.0,
      "step": 11350
    },
    {
      "epoch": 5.406949071870538,
      "grad_norm": 0.0050785052590072155,
      "learning_rate": 9.186101856258926e-06,
      "loss": 0.0,
      "step": 11360
    },
    {
      "epoch": 5.411708710138029,
      "grad_norm": 0.019859544932842255,
      "learning_rate": 9.176582579723942e-06,
      "loss": 0.0,
      "step": 11370
    },
    {
      "epoch": 5.416468348405521,
      "grad_norm": 0.0010774737456813455,
      "learning_rate": 9.167063303188958e-06,
      "loss": 0.0001,
      "step": 11380
    },
    {
      "epoch": 5.421227986673013,
      "grad_norm": 6.363824844360352,
      "learning_rate": 9.157544026653976e-06,
      "loss": 0.0375,
      "step": 11390
    },
    {
      "epoch": 5.425987624940505,
      "grad_norm": 0.0008451294852420688,
      "learning_rate": 9.148024750118992e-06,
      "loss": 0.013,
      "step": 11400
    },
    {
      "epoch": 5.430747263207996,
      "grad_norm": 0.002471878193318844,
      "learning_rate": 9.138505473584008e-06,
      "loss": 0.011,
      "step": 11410
    },
    {
      "epoch": 5.435506901475488,
      "grad_norm": 0.003138948930427432,
      "learning_rate": 9.128986197049025e-06,
      "loss": 0.0,
      "step": 11420
    },
    {
      "epoch": 5.4402665397429795,
      "grad_norm": 0.0021380961406975985,
      "learning_rate": 9.119466920514041e-06,
      "loss": 0.0131,
      "step": 11430
    },
    {
      "epoch": 5.445026178010472,
      "grad_norm": 0.00466626463457942,
      "learning_rate": 9.109947643979057e-06,
      "loss": 0.0002,
      "step": 11440
    },
    {
      "epoch": 5.449785816277963,
      "grad_norm": 0.022839602082967758,
      "learning_rate": 9.100428367444075e-06,
      "loss": 0.0005,
      "step": 11450
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 0.17712926864624023,
      "learning_rate": 9.090909090909091e-06,
      "loss": 0.0001,
      "step": 11460
    },
    {
      "epoch": 5.459305092812946,
      "grad_norm": 0.0011256529251113534,
      "learning_rate": 9.081389814374109e-06,
      "loss": 0.0022,
      "step": 11470
    },
    {
      "epoch": 5.4640647310804376,
      "grad_norm": 0.006790320388972759,
      "learning_rate": 9.071870537839125e-06,
      "loss": 0.0,
      "step": 11480
    },
    {
      "epoch": 5.46882436934793,
      "grad_norm": 0.003523015882819891,
      "learning_rate": 9.062351261304142e-06,
      "loss": 0.0004,
      "step": 11490
    },
    {
      "epoch": 5.473584007615421,
      "grad_norm": 0.02889023907482624,
      "learning_rate": 9.052831984769158e-06,
      "loss": 0.0003,
      "step": 11500
    },
    {
      "epoch": 5.478343645882913,
      "grad_norm": 0.00044148959568701684,
      "learning_rate": 9.043312708234176e-06,
      "loss": 0.015,
      "step": 11510
    },
    {
      "epoch": 5.483103284150404,
      "grad_norm": 0.0003225019609089941,
      "learning_rate": 9.033793431699192e-06,
      "loss": 0.0,
      "step": 11520
    },
    {
      "epoch": 5.4878629224178965,
      "grad_norm": 0.000521830515936017,
      "learning_rate": 9.024274155164208e-06,
      "loss": 0.0,
      "step": 11530
    },
    {
      "epoch": 5.492622560685388,
      "grad_norm": 0.0006311282049864531,
      "learning_rate": 9.014754878629226e-06,
      "loss": 0.0299,
      "step": 11540
    },
    {
      "epoch": 5.49738219895288,
      "grad_norm": 0.0004482882213778794,
      "learning_rate": 9.005235602094242e-06,
      "loss": 0.0003,
      "step": 11550
    },
    {
      "epoch": 5.502141837220371,
      "grad_norm": 0.0003887393686454743,
      "learning_rate": 8.995716325559258e-06,
      "loss": 0.0,
      "step": 11560
    },
    {
      "epoch": 5.506901475487863,
      "grad_norm": 0.00023079177481122315,
      "learning_rate": 8.986197049024274e-06,
      "loss": 0.0011,
      "step": 11570
    },
    {
      "epoch": 5.511661113755355,
      "grad_norm": 0.0036708649713546038,
      "learning_rate": 8.976677772489291e-06,
      "loss": 0.0002,
      "step": 11580
    },
    {
      "epoch": 5.516420752022846,
      "grad_norm": 0.00027202299679629505,
      "learning_rate": 8.967158495954307e-06,
      "loss": 0.0,
      "step": 11590
    },
    {
      "epoch": 5.521180390290338,
      "grad_norm": 0.0005622316966764629,
      "learning_rate": 8.957639219419325e-06,
      "loss": 0.0001,
      "step": 11600
    },
    {
      "epoch": 5.525940028557829,
      "grad_norm": 0.0003010567743331194,
      "learning_rate": 8.948119942884341e-06,
      "loss": 0.0,
      "step": 11610
    },
    {
      "epoch": 5.530699666825321,
      "grad_norm": 0.0007556076161563396,
      "learning_rate": 8.938600666349359e-06,
      "loss": 0.0,
      "step": 11620
    },
    {
      "epoch": 5.535459305092813,
      "grad_norm": 0.0002513302897568792,
      "learning_rate": 8.929081389814375e-06,
      "loss": 0.0002,
      "step": 11630
    },
    {
      "epoch": 5.540218943360305,
      "grad_norm": 0.001105353469029069,
      "learning_rate": 8.919562113279392e-06,
      "loss": 0.0127,
      "step": 11640
    },
    {
      "epoch": 5.544978581627796,
      "grad_norm": 0.009694422595202923,
      "learning_rate": 8.910042836744408e-06,
      "loss": 0.0123,
      "step": 11650
    },
    {
      "epoch": 5.549738219895288,
      "grad_norm": 0.03199407085776329,
      "learning_rate": 8.900523560209426e-06,
      "loss": 0.0013,
      "step": 11660
    },
    {
      "epoch": 5.5544978581627795,
      "grad_norm": 0.0011173570528626442,
      "learning_rate": 8.891004283674442e-06,
      "loss": 0.0008,
      "step": 11670
    },
    {
      "epoch": 5.559257496430272,
      "grad_norm": 0.0012145115761086345,
      "learning_rate": 8.881485007139458e-06,
      "loss": 0.0001,
      "step": 11680
    },
    {
      "epoch": 5.564017134697763,
      "grad_norm": 0.0008893171325325966,
      "learning_rate": 8.871965730604476e-06,
      "loss": 0.0,
      "step": 11690
    },
    {
      "epoch": 5.568776772965254,
      "grad_norm": 0.0005607020575553179,
      "learning_rate": 8.862446454069492e-06,
      "loss": 0.0008,
      "step": 11700
    },
    {
      "epoch": 5.573536411232746,
      "grad_norm": 0.0016349505167454481,
      "learning_rate": 8.852927177534508e-06,
      "loss": 0.0,
      "step": 11710
    },
    {
      "epoch": 5.578296049500238,
      "grad_norm": 0.008391404524445534,
      "learning_rate": 8.843407900999524e-06,
      "loss": 0.0,
      "step": 11720
    },
    {
      "epoch": 5.58305568776773,
      "grad_norm": 0.00022432759578805417,
      "learning_rate": 8.833888624464541e-06,
      "loss": 0.0006,
      "step": 11730
    },
    {
      "epoch": 5.587815326035221,
      "grad_norm": 0.007208580616861582,
      "learning_rate": 8.824369347929557e-06,
      "loss": 0.0193,
      "step": 11740
    },
    {
      "epoch": 5.592574964302713,
      "grad_norm": 0.0019060588674619794,
      "learning_rate": 8.814850071394575e-06,
      "loss": 0.001,
      "step": 11750
    },
    {
      "epoch": 5.597334602570204,
      "grad_norm": 0.0010318441782146692,
      "learning_rate": 8.805330794859591e-06,
      "loss": 0.0,
      "step": 11760
    },
    {
      "epoch": 5.602094240837697,
      "grad_norm": 0.0004634942742995918,
      "learning_rate": 8.795811518324609e-06,
      "loss": 0.0001,
      "step": 11770
    },
    {
      "epoch": 5.606853879105188,
      "grad_norm": 0.00036216460284776986,
      "learning_rate": 8.786292241789625e-06,
      "loss": 0.0322,
      "step": 11780
    },
    {
      "epoch": 5.61161351737268,
      "grad_norm": 0.0004450397682376206,
      "learning_rate": 8.776772965254642e-06,
      "loss": 0.0,
      "step": 11790
    },
    {
      "epoch": 5.616373155640171,
      "grad_norm": 0.003467804053798318,
      "learning_rate": 8.767253688719658e-06,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 5.621132793907663,
      "grad_norm": 0.0004530561272986233,
      "learning_rate": 8.757734412184674e-06,
      "loss": 0.0,
      "step": 11810
    },
    {
      "epoch": 5.625892432175155,
      "grad_norm": 0.006213481072336435,
      "learning_rate": 8.748215135649692e-06,
      "loss": 0.0,
      "step": 11820
    },
    {
      "epoch": 5.630652070442647,
      "grad_norm": 0.0006393138319253922,
      "learning_rate": 8.738695859114708e-06,
      "loss": 0.0,
      "step": 11830
    },
    {
      "epoch": 5.635411708710138,
      "grad_norm": 0.00038576964288949966,
      "learning_rate": 8.729176582579726e-06,
      "loss": 0.001,
      "step": 11840
    },
    {
      "epoch": 5.640171346977629,
      "grad_norm": 0.00037886129575781524,
      "learning_rate": 8.719657306044742e-06,
      "loss": 0.0206,
      "step": 11850
    },
    {
      "epoch": 5.6449309852451215,
      "grad_norm": 0.0006781000411137938,
      "learning_rate": 8.710138029509758e-06,
      "loss": 0.0007,
      "step": 11860
    },
    {
      "epoch": 5.649690623512613,
      "grad_norm": 0.00021089252550154924,
      "learning_rate": 8.700618752974774e-06,
      "loss": 0.0,
      "step": 11870
    },
    {
      "epoch": 5.654450261780105,
      "grad_norm": 0.00014313006249722093,
      "learning_rate": 8.691099476439791e-06,
      "loss": 0.0,
      "step": 11880
    },
    {
      "epoch": 5.659209900047596,
      "grad_norm": 0.00024768622824922204,
      "learning_rate": 8.681580199904807e-06,
      "loss": 0.0048,
      "step": 11890
    },
    {
      "epoch": 5.663969538315088,
      "grad_norm": 0.0006420154822990298,
      "learning_rate": 8.672060923369825e-06,
      "loss": 0.0,
      "step": 11900
    },
    {
      "epoch": 5.66872917658258,
      "grad_norm": 0.0004388116067275405,
      "learning_rate": 8.662541646834841e-06,
      "loss": 0.0,
      "step": 11910
    },
    {
      "epoch": 5.673488814850072,
      "grad_norm": 0.00035616388777270913,
      "learning_rate": 8.653022370299859e-06,
      "loss": 0.0,
      "step": 11920
    },
    {
      "epoch": 5.678248453117563,
      "grad_norm": 0.00011044700659113005,
      "learning_rate": 8.643503093764875e-06,
      "loss": 0.0,
      "step": 11930
    },
    {
      "epoch": 5.683008091385055,
      "grad_norm": 0.002568040508776903,
      "learning_rate": 8.633983817229892e-06,
      "loss": 0.0,
      "step": 11940
    },
    {
      "epoch": 5.687767729652546,
      "grad_norm": 0.0006492226966656744,
      "learning_rate": 8.624464540694908e-06,
      "loss": 0.0,
      "step": 11950
    },
    {
      "epoch": 5.692527367920038,
      "grad_norm": 0.002396266208961606,
      "learning_rate": 8.614945264159924e-06,
      "loss": 0.0166,
      "step": 11960
    },
    {
      "epoch": 5.69728700618753,
      "grad_norm": 0.0006831006030552089,
      "learning_rate": 8.605425987624942e-06,
      "loss": 0.0,
      "step": 11970
    },
    {
      "epoch": 5.702046644455021,
      "grad_norm": 0.0013772051315754652,
      "learning_rate": 8.595906711089958e-06,
      "loss": 0.0,
      "step": 11980
    },
    {
      "epoch": 5.706806282722513,
      "grad_norm": 0.0005148909403942525,
      "learning_rate": 8.586387434554974e-06,
      "loss": 0.0,
      "step": 11990
    },
    {
      "epoch": 5.7115659209900045,
      "grad_norm": 0.0005712292622774839,
      "learning_rate": 8.576868158019992e-06,
      "loss": 0.0413,
      "step": 12000
    },
    {
      "epoch": 5.716325559257497,
      "grad_norm": 0.0013946439139544964,
      "learning_rate": 8.567348881485008e-06,
      "loss": 0.0,
      "step": 12010
    },
    {
      "epoch": 5.721085197524988,
      "grad_norm": 0.06596212089061737,
      "learning_rate": 8.557829604950024e-06,
      "loss": 0.0001,
      "step": 12020
    },
    {
      "epoch": 5.72584483579248,
      "grad_norm": 0.005526992958039045,
      "learning_rate": 8.548310328415041e-06,
      "loss": 0.0098,
      "step": 12030
    },
    {
      "epoch": 5.730604474059971,
      "grad_norm": 0.007691461592912674,
      "learning_rate": 8.538791051880057e-06,
      "loss": 0.0002,
      "step": 12040
    },
    {
      "epoch": 5.7353641123274635,
      "grad_norm": 0.0033259924966841936,
      "learning_rate": 8.529271775345075e-06,
      "loss": 0.0006,
      "step": 12050
    },
    {
      "epoch": 5.740123750594955,
      "grad_norm": 0.007694223430007696,
      "learning_rate": 8.519752498810091e-06,
      "loss": 0.0008,
      "step": 12060
    },
    {
      "epoch": 5.744883388862446,
      "grad_norm": 0.0003983544884249568,
      "learning_rate": 8.510233222275109e-06,
      "loss": 0.0008,
      "step": 12070
    },
    {
      "epoch": 5.749643027129938,
      "grad_norm": 0.002427154453471303,
      "learning_rate": 8.500713945740125e-06,
      "loss": 0.0,
      "step": 12080
    },
    {
      "epoch": 5.75440266539743,
      "grad_norm": 0.0004389316600281745,
      "learning_rate": 8.49119466920514e-06,
      "loss": 0.0002,
      "step": 12090
    },
    {
      "epoch": 5.7591623036649215,
      "grad_norm": 0.0033720845822244883,
      "learning_rate": 8.481675392670158e-06,
      "loss": 0.0001,
      "step": 12100
    },
    {
      "epoch": 5.763921941932413,
      "grad_norm": 0.00043986126547679305,
      "learning_rate": 8.472156116135174e-06,
      "loss": 0.0,
      "step": 12110
    },
    {
      "epoch": 5.768681580199905,
      "grad_norm": 0.0002745207748375833,
      "learning_rate": 8.462636839600192e-06,
      "loss": 0.0,
      "step": 12120
    },
    {
      "epoch": 5.773441218467396,
      "grad_norm": 0.00036489652120508254,
      "learning_rate": 8.453117563065208e-06,
      "loss": 0.0009,
      "step": 12130
    },
    {
      "epoch": 5.778200856734888,
      "grad_norm": 0.00032815244048833847,
      "learning_rate": 8.443598286530224e-06,
      "loss": 0.0,
      "step": 12140
    },
    {
      "epoch": 5.78296049500238,
      "grad_norm": 0.011989397928118706,
      "learning_rate": 8.434079009995242e-06,
      "loss": 0.0,
      "step": 12150
    },
    {
      "epoch": 5.787720133269872,
      "grad_norm": 0.0006439759745262563,
      "learning_rate": 8.424559733460258e-06,
      "loss": 0.0,
      "step": 12160
    },
    {
      "epoch": 5.792479771537363,
      "grad_norm": 0.0015332174953073263,
      "learning_rate": 8.415040456925273e-06,
      "loss": 0.0,
      "step": 12170
    },
    {
      "epoch": 5.797239409804855,
      "grad_norm": 0.0005659768939949572,
      "learning_rate": 8.405521180390291e-06,
      "loss": 0.0,
      "step": 12180
    },
    {
      "epoch": 5.8019990480723465,
      "grad_norm": 0.012914218008518219,
      "learning_rate": 8.396001903855307e-06,
      "loss": 0.0001,
      "step": 12190
    },
    {
      "epoch": 5.806758686339839,
      "grad_norm": 0.0005423951079137623,
      "learning_rate": 8.386482627320325e-06,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 5.81151832460733,
      "grad_norm": 0.00027131696697324514,
      "learning_rate": 8.37696335078534e-06,
      "loss": 0.0,
      "step": 12210
    },
    {
      "epoch": 5.816277962874821,
      "grad_norm": 0.0002891666372306645,
      "learning_rate": 8.367444074250359e-06,
      "loss": 0.0101,
      "step": 12220
    },
    {
      "epoch": 5.821037601142313,
      "grad_norm": 0.0010272229555994272,
      "learning_rate": 8.357924797715374e-06,
      "loss": 0.0,
      "step": 12230
    },
    {
      "epoch": 5.8257972394098045,
      "grad_norm": 0.0003093891718890518,
      "learning_rate": 8.34840552118039e-06,
      "loss": 0.0001,
      "step": 12240
    },
    {
      "epoch": 5.830556877677297,
      "grad_norm": 0.00035130325704813004,
      "learning_rate": 8.338886244645408e-06,
      "loss": 0.0061,
      "step": 12250
    },
    {
      "epoch": 5.835316515944788,
      "grad_norm": 0.00029162471764720976,
      "learning_rate": 8.329366968110424e-06,
      "loss": 0.0001,
      "step": 12260
    },
    {
      "epoch": 5.84007615421228,
      "grad_norm": 0.00041935750050470233,
      "learning_rate": 8.319847691575442e-06,
      "loss": 0.0,
      "step": 12270
    },
    {
      "epoch": 5.844835792479771,
      "grad_norm": 0.0014999575214460492,
      "learning_rate": 8.310328415040458e-06,
      "loss": 0.0293,
      "step": 12280
    },
    {
      "epoch": 5.8495954307472635,
      "grad_norm": 0.0004644801374524832,
      "learning_rate": 8.300809138505474e-06,
      "loss": 0.0,
      "step": 12290
    },
    {
      "epoch": 5.854355069014755,
      "grad_norm": 0.23388975858688354,
      "learning_rate": 8.291289861970491e-06,
      "loss": 0.0001,
      "step": 12300
    },
    {
      "epoch": 5.859114707282247,
      "grad_norm": 0.0017817690968513489,
      "learning_rate": 8.281770585435507e-06,
      "loss": 0.0,
      "step": 12310
    },
    {
      "epoch": 5.863874345549738,
      "grad_norm": 0.03024502471089363,
      "learning_rate": 8.272251308900523e-06,
      "loss": 0.0,
      "step": 12320
    },
    {
      "epoch": 5.8686339838172294,
      "grad_norm": 0.0022932973224669695,
      "learning_rate": 8.262732032365541e-06,
      "loss": 0.0,
      "step": 12330
    },
    {
      "epoch": 5.873393622084722,
      "grad_norm": 0.00041078877984546125,
      "learning_rate": 8.253212755830557e-06,
      "loss": 0.0001,
      "step": 12340
    },
    {
      "epoch": 5.878153260352213,
      "grad_norm": 0.02092314325273037,
      "learning_rate": 8.243693479295575e-06,
      "loss": 0.0,
      "step": 12350
    },
    {
      "epoch": 5.882912898619705,
      "grad_norm": 0.004398203454911709,
      "learning_rate": 8.23417420276059e-06,
      "loss": 0.0004,
      "step": 12360
    },
    {
      "epoch": 5.887672536887196,
      "grad_norm": 0.007587485481053591,
      "learning_rate": 8.224654926225607e-06,
      "loss": 0.0001,
      "step": 12370
    },
    {
      "epoch": 5.892432175154688,
      "grad_norm": 0.03159192577004433,
      "learning_rate": 8.215135649690624e-06,
      "loss": 0.0158,
      "step": 12380
    },
    {
      "epoch": 5.89719181342218,
      "grad_norm": 0.0006560995243489742,
      "learning_rate": 8.20561637315564e-06,
      "loss": 0.0001,
      "step": 12390
    },
    {
      "epoch": 5.901951451689672,
      "grad_norm": 0.0006776308291591704,
      "learning_rate": 8.196097096620658e-06,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 5.906711089957163,
      "grad_norm": 0.0008542583091184497,
      "learning_rate": 8.186577820085674e-06,
      "loss": 0.0,
      "step": 12410
    },
    {
      "epoch": 5.911470728224655,
      "grad_norm": 0.0024382618721574545,
      "learning_rate": 8.177058543550692e-06,
      "loss": 0.0,
      "step": 12420
    },
    {
      "epoch": 5.9162303664921465,
      "grad_norm": 0.001907832338474691,
      "learning_rate": 8.167539267015708e-06,
      "loss": 0.0095,
      "step": 12430
    },
    {
      "epoch": 5.920990004759638,
      "grad_norm": 0.01393075194209814,
      "learning_rate": 8.158019990480724e-06,
      "loss": 0.0,
      "step": 12440
    },
    {
      "epoch": 5.92574964302713,
      "grad_norm": 0.006451242603361607,
      "learning_rate": 8.148500713945741e-06,
      "loss": 0.0,
      "step": 12450
    },
    {
      "epoch": 5.930509281294622,
      "grad_norm": 0.00035807242966257036,
      "learning_rate": 8.138981437410757e-06,
      "loss": 0.0,
      "step": 12460
    },
    {
      "epoch": 5.935268919562113,
      "grad_norm": 3.9155728816986084,
      "learning_rate": 8.129462160875773e-06,
      "loss": 0.004,
      "step": 12470
    },
    {
      "epoch": 5.940028557829605,
      "grad_norm": 0.00010529174323892221,
      "learning_rate": 8.119942884340791e-06,
      "loss": 0.0,
      "step": 12480
    },
    {
      "epoch": 5.944788196097097,
      "grad_norm": 1.9838759899139404,
      "learning_rate": 8.110423607805807e-06,
      "loss": 0.0041,
      "step": 12490
    },
    {
      "epoch": 5.949547834364588,
      "grad_norm": 0.0003600766649469733,
      "learning_rate": 8.100904331270823e-06,
      "loss": 0.0007,
      "step": 12500
    },
    {
      "epoch": 5.95430747263208,
      "grad_norm": 0.00039863798883743584,
      "learning_rate": 8.09138505473584e-06,
      "loss": 0.0001,
      "step": 12510
    },
    {
      "epoch": 5.959067110899571,
      "grad_norm": 0.00047796277794986963,
      "learning_rate": 8.081865778200857e-06,
      "loss": 0.0002,
      "step": 12520
    },
    {
      "epoch": 5.963826749167064,
      "grad_norm": 8.714308205526322e-05,
      "learning_rate": 8.072346501665874e-06,
      "loss": 0.0014,
      "step": 12530
    },
    {
      "epoch": 5.968586387434555,
      "grad_norm": 0.00012701321975328028,
      "learning_rate": 8.06282722513089e-06,
      "loss": 0.0,
      "step": 12540
    },
    {
      "epoch": 5.973346025702047,
      "grad_norm": 0.0022666030563414097,
      "learning_rate": 8.053307948595908e-06,
      "loss": 0.0228,
      "step": 12550
    },
    {
      "epoch": 5.978105663969538,
      "grad_norm": 0.00015888763300608844,
      "learning_rate": 8.043788672060924e-06,
      "loss": 0.0004,
      "step": 12560
    },
    {
      "epoch": 5.98286530223703,
      "grad_norm": 0.00020246337226126343,
      "learning_rate": 8.034269395525942e-06,
      "loss": 0.0,
      "step": 12570
    },
    {
      "epoch": 5.987624940504522,
      "grad_norm": 0.00019543056259863079,
      "learning_rate": 8.024750118990958e-06,
      "loss": 0.004,
      "step": 12580
    },
    {
      "epoch": 5.992384578772013,
      "grad_norm": 0.09704342484474182,
      "learning_rate": 8.015230842455974e-06,
      "loss": 0.0002,
      "step": 12590
    },
    {
      "epoch": 5.997144217039505,
      "grad_norm": 1.0824624300003052,
      "learning_rate": 8.00571156592099e-06,
      "loss": 0.0027,
      "step": 12600
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9973611111111111,
      "eval_f1": 0.9857464366091523,
      "eval_loss": 0.02204287238419056,
      "eval_precision": 0.9850074962518741,
      "eval_recall": 0.9864864864864865,
      "eval_runtime": 344.4418,
      "eval_samples_per_second": 41.839,
      "eval_steps_per_second": 1.309,
      "step": 12606
    },
    {
      "epoch": 6.001903855306996,
      "grad_norm": 0.00013006989320274442,
      "learning_rate": 7.996192289386007e-06,
      "loss": 0.0002,
      "step": 12610
    },
    {
      "epoch": 6.0066634935744885,
      "grad_norm": 0.0003015688853338361,
      "learning_rate": 7.986673012851023e-06,
      "loss": 0.0,
      "step": 12620
    },
    {
      "epoch": 6.01142313184198,
      "grad_norm": 3.578867108444683e-05,
      "learning_rate": 7.977153736316041e-06,
      "loss": 0.0004,
      "step": 12630
    },
    {
      "epoch": 6.016182770109472,
      "grad_norm": 0.00018588917737361044,
      "learning_rate": 7.967634459781057e-06,
      "loss": 0.0075,
      "step": 12640
    },
    {
      "epoch": 6.020942408376963,
      "grad_norm": 0.0010775524424389005,
      "learning_rate": 7.958115183246073e-06,
      "loss": 0.0033,
      "step": 12650
    },
    {
      "epoch": 6.025702046644455,
      "grad_norm": 0.1841280609369278,
      "learning_rate": 7.94859590671109e-06,
      "loss": 0.0001,
      "step": 12660
    },
    {
      "epoch": 6.030461684911947,
      "grad_norm": 16.314559936523438,
      "learning_rate": 7.939076630176107e-06,
      "loss": 0.0349,
      "step": 12670
    },
    {
      "epoch": 6.035221323179439,
      "grad_norm": 0.0002906996523961425,
      "learning_rate": 7.929557353641124e-06,
      "loss": 0.0096,
      "step": 12680
    },
    {
      "epoch": 6.03998096144693,
      "grad_norm": 0.00016284971206914634,
      "learning_rate": 7.92003807710614e-06,
      "loss": 0.0,
      "step": 12690
    },
    {
      "epoch": 6.044740599714422,
      "grad_norm": 0.0025154210161417723,
      "learning_rate": 7.910518800571158e-06,
      "loss": 0.0006,
      "step": 12700
    },
    {
      "epoch": 6.049500237981913,
      "grad_norm": 10.013777732849121,
      "learning_rate": 7.900999524036174e-06,
      "loss": 0.0013,
      "step": 12710
    },
    {
      "epoch": 6.054259876249405,
      "grad_norm": 0.005308715160936117,
      "learning_rate": 7.891480247501192e-06,
      "loss": 0.0001,
      "step": 12720
    },
    {
      "epoch": 6.059019514516897,
      "grad_norm": 0.0010355833219364285,
      "learning_rate": 7.881960970966208e-06,
      "loss": 0.0074,
      "step": 12730
    },
    {
      "epoch": 6.063779152784388,
      "grad_norm": 0.0001405648363288492,
      "learning_rate": 7.872441694431224e-06,
      "loss": 0.0,
      "step": 12740
    },
    {
      "epoch": 6.06853879105188,
      "grad_norm": 0.00032021314837038517,
      "learning_rate": 7.86292241789624e-06,
      "loss": 0.0,
      "step": 12750
    },
    {
      "epoch": 6.0732984293193715,
      "grad_norm": 0.00021726515842601657,
      "learning_rate": 7.853403141361257e-06,
      "loss": 0.0001,
      "step": 12760
    },
    {
      "epoch": 6.078058067586864,
      "grad_norm": 0.0004126621934119612,
      "learning_rate": 7.843883864826273e-06,
      "loss": 0.0,
      "step": 12770
    },
    {
      "epoch": 6.082817705854355,
      "grad_norm": 0.003169279545545578,
      "learning_rate": 7.83436458829129e-06,
      "loss": 0.0,
      "step": 12780
    },
    {
      "epoch": 6.087577344121847,
      "grad_norm": 0.0006266031414270401,
      "learning_rate": 7.824845311756307e-06,
      "loss": 0.0,
      "step": 12790
    },
    {
      "epoch": 6.092336982389338,
      "grad_norm": 0.00022658768284600228,
      "learning_rate": 7.815326035221323e-06,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 6.0970966206568304,
      "grad_norm": 0.00015669864660594612,
      "learning_rate": 7.80580675868634e-06,
      "loss": 0.0058,
      "step": 12810
    },
    {
      "epoch": 6.101856258924322,
      "grad_norm": 6.394716183422133e-05,
      "learning_rate": 7.796287482151357e-06,
      "loss": 0.0,
      "step": 12820
    },
    {
      "epoch": 6.106615897191814,
      "grad_norm": 4.116031414014287e-05,
      "learning_rate": 7.786768205616374e-06,
      "loss": 0.0,
      "step": 12830
    },
    {
      "epoch": 6.111375535459305,
      "grad_norm": 0.0006230277940630913,
      "learning_rate": 7.77724892908139e-06,
      "loss": 0.0,
      "step": 12840
    },
    {
      "epoch": 6.116135173726796,
      "grad_norm": 0.00014250203093979508,
      "learning_rate": 7.767729652546408e-06,
      "loss": 0.0,
      "step": 12850
    },
    {
      "epoch": 6.1208948119942885,
      "grad_norm": 0.0002418987569399178,
      "learning_rate": 7.758210376011424e-06,
      "loss": 0.0,
      "step": 12860
    },
    {
      "epoch": 6.12565445026178,
      "grad_norm": 0.00015042285667732358,
      "learning_rate": 7.748691099476442e-06,
      "loss": 0.0,
      "step": 12870
    },
    {
      "epoch": 6.130414088529272,
      "grad_norm": 0.00016105073154903948,
      "learning_rate": 7.739171822941458e-06,
      "loss": 0.0,
      "step": 12880
    },
    {
      "epoch": 6.135173726796763,
      "grad_norm": 0.00013887570821680129,
      "learning_rate": 7.729652546406474e-06,
      "loss": 0.0,
      "step": 12890
    },
    {
      "epoch": 6.139933365064255,
      "grad_norm": 0.00011031503527192399,
      "learning_rate": 7.72013326987149e-06,
      "loss": 0.027,
      "step": 12900
    },
    {
      "epoch": 6.144693003331747,
      "grad_norm": 0.00017063453560695052,
      "learning_rate": 7.710613993336507e-06,
      "loss": 0.0,
      "step": 12910
    },
    {
      "epoch": 6.149452641599239,
      "grad_norm": 0.0013384681660681963,
      "learning_rate": 7.701094716801523e-06,
      "loss": 0.0,
      "step": 12920
    },
    {
      "epoch": 6.15421227986673,
      "grad_norm": 8.155353862093762e-05,
      "learning_rate": 7.69157544026654e-06,
      "loss": 0.0,
      "step": 12930
    },
    {
      "epoch": 6.158971918134222,
      "grad_norm": 0.006155303213745356,
      "learning_rate": 7.682056163731557e-06,
      "loss": 0.0,
      "step": 12940
    },
    {
      "epoch": 6.163731556401713,
      "grad_norm": 0.002315002493560314,
      "learning_rate": 7.672536887196573e-06,
      "loss": 0.0,
      "step": 12950
    },
    {
      "epoch": 6.168491194669205,
      "grad_norm": 0.005433926358819008,
      "learning_rate": 7.66301761066159e-06,
      "loss": 0.0,
      "step": 12960
    },
    {
      "epoch": 6.173250832936697,
      "grad_norm": 0.0009655284229665995,
      "learning_rate": 7.653498334126607e-06,
      "loss": 0.0,
      "step": 12970
    },
    {
      "epoch": 6.178010471204188,
      "grad_norm": 5.03310511703603e-05,
      "learning_rate": 7.643979057591624e-06,
      "loss": 0.0003,
      "step": 12980
    },
    {
      "epoch": 6.18277010947168,
      "grad_norm": 0.00029735075077041984,
      "learning_rate": 7.63445978105664e-06,
      "loss": 0.0,
      "step": 12990
    },
    {
      "epoch": 6.1875297477391715,
      "grad_norm": 0.0017054942436516285,
      "learning_rate": 7.624940504521657e-06,
      "loss": 0.0009,
      "step": 13000
    },
    {
      "epoch": 6.192289386006664,
      "grad_norm": 6.368698086589575e-05,
      "learning_rate": 7.615421227986673e-06,
      "loss": 0.0,
      "step": 13010
    },
    {
      "epoch": 6.197049024274155,
      "grad_norm": 0.008249897509813309,
      "learning_rate": 7.605901951451691e-06,
      "loss": 0.0004,
      "step": 13020
    },
    {
      "epoch": 6.201808662541647,
      "grad_norm": 0.00023169946507550776,
      "learning_rate": 7.596382674916707e-06,
      "loss": 0.0,
      "step": 13030
    },
    {
      "epoch": 6.206568300809138,
      "grad_norm": 0.00019935090676881373,
      "learning_rate": 7.5868633983817244e-06,
      "loss": 0.0,
      "step": 13040
    },
    {
      "epoch": 6.2113279390766305,
      "grad_norm": 0.0005801762454211712,
      "learning_rate": 7.5773441218467404e-06,
      "loss": 0.0,
      "step": 13050
    },
    {
      "epoch": 6.216087577344122,
      "grad_norm": 9.478525316808373e-05,
      "learning_rate": 7.567824845311756e-06,
      "loss": 0.0,
      "step": 13060
    },
    {
      "epoch": 6.220847215611614,
      "grad_norm": 1.3665341138839722,
      "learning_rate": 7.558305568776774e-06,
      "loss": 0.0003,
      "step": 13070
    },
    {
      "epoch": 6.225606853879105,
      "grad_norm": 0.001113729435019195,
      "learning_rate": 7.54878629224179e-06,
      "loss": 0.0,
      "step": 13080
    },
    {
      "epoch": 6.230366492146596,
      "grad_norm": 0.00010148994624614716,
      "learning_rate": 7.539267015706807e-06,
      "loss": 0.0,
      "step": 13090
    },
    {
      "epoch": 6.235126130414089,
      "grad_norm": 0.0001677614782238379,
      "learning_rate": 7.529747739171823e-06,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 6.23988576868158,
      "grad_norm": 0.00013475959713105112,
      "learning_rate": 7.520228462636841e-06,
      "loss": 0.0,
      "step": 13110
    },
    {
      "epoch": 6.244645406949072,
      "grad_norm": 0.00015029181668069214,
      "learning_rate": 7.5107091861018566e-06,
      "loss": 0.0,
      "step": 13120
    },
    {
      "epoch": 6.249405045216563,
      "grad_norm": 0.0002655283024068922,
      "learning_rate": 7.501189909566874e-06,
      "loss": 0.0316,
      "step": 13130
    },
    {
      "epoch": 6.254164683484055,
      "grad_norm": 0.028230126947164536,
      "learning_rate": 7.49167063303189e-06,
      "loss": 0.0,
      "step": 13140
    },
    {
      "epoch": 6.258924321751547,
      "grad_norm": 0.001042485237121582,
      "learning_rate": 7.482151356496907e-06,
      "loss": 0.0,
      "step": 13150
    },
    {
      "epoch": 6.263683960019039,
      "grad_norm": 0.0010109551949426532,
      "learning_rate": 7.472632079961923e-06,
      "loss": 0.0,
      "step": 13160
    },
    {
      "epoch": 6.26844359828653,
      "grad_norm": 0.00016685950686223805,
      "learning_rate": 7.463112803426941e-06,
      "loss": 0.0,
      "step": 13170
    },
    {
      "epoch": 6.273203236554022,
      "grad_norm": 0.0014428908471018076,
      "learning_rate": 7.453593526891957e-06,
      "loss": 0.0,
      "step": 13180
    },
    {
      "epoch": 6.2779628748215135,
      "grad_norm": 0.0004928451962769032,
      "learning_rate": 7.444074250356973e-06,
      "loss": 0.0,
      "step": 13190
    },
    {
      "epoch": 6.282722513089006,
      "grad_norm": 0.0009963185293599963,
      "learning_rate": 7.43455497382199e-06,
      "loss": 0.0,
      "step": 13200
    },
    {
      "epoch": 6.287482151356497,
      "grad_norm": 0.0003688956785481423,
      "learning_rate": 7.425035697287006e-06,
      "loss": 0.0,
      "step": 13210
    },
    {
      "epoch": 6.292241789623988,
      "grad_norm": 0.001518245437182486,
      "learning_rate": 7.415516420752023e-06,
      "loss": 0.0,
      "step": 13220
    },
    {
      "epoch": 6.29700142789148,
      "grad_norm": 0.00019782113668043166,
      "learning_rate": 7.40599714421704e-06,
      "loss": 0.0,
      "step": 13230
    },
    {
      "epoch": 6.301761066158972,
      "grad_norm": 0.0003527867083903402,
      "learning_rate": 7.396477867682057e-06,
      "loss": 0.0,
      "step": 13240
    },
    {
      "epoch": 6.306520704426464,
      "grad_norm": 0.0003830201749224216,
      "learning_rate": 7.386958591147073e-06,
      "loss": 0.0,
      "step": 13250
    },
    {
      "epoch": 6.311280342693955,
      "grad_norm": 0.0005000781384296715,
      "learning_rate": 7.3774393146120905e-06,
      "loss": 0.0075,
      "step": 13260
    },
    {
      "epoch": 6.316039980961447,
      "grad_norm": 0.002160911448299885,
      "learning_rate": 7.3679200380771065e-06,
      "loss": 0.0079,
      "step": 13270
    },
    {
      "epoch": 6.320799619228938,
      "grad_norm": 0.0032045876141637564,
      "learning_rate": 7.358400761542124e-06,
      "loss": 0.0,
      "step": 13280
    },
    {
      "epoch": 6.3255592574964306,
      "grad_norm": 0.00045500564738176763,
      "learning_rate": 7.34888148500714e-06,
      "loss": 0.0267,
      "step": 13290
    },
    {
      "epoch": 6.330318895763922,
      "grad_norm": 0.0008954753866419196,
      "learning_rate": 7.339362208472157e-06,
      "loss": 0.0011,
      "step": 13300
    },
    {
      "epoch": 6.335078534031414,
      "grad_norm": 0.0006388734327629209,
      "learning_rate": 7.329842931937173e-06,
      "loss": 0.0,
      "step": 13310
    },
    {
      "epoch": 6.339838172298905,
      "grad_norm": 0.0008087924215942621,
      "learning_rate": 7.320323655402191e-06,
      "loss": 0.0,
      "step": 13320
    },
    {
      "epoch": 6.3445978105663965,
      "grad_norm": 0.002742505632340908,
      "learning_rate": 7.310804378867207e-06,
      "loss": 0.0,
      "step": 13330
    },
    {
      "epoch": 6.349357448833889,
      "grad_norm": 0.0023002864327281713,
      "learning_rate": 7.301285102332223e-06,
      "loss": 0.0152,
      "step": 13340
    },
    {
      "epoch": 6.35411708710138,
      "grad_norm": 0.0019462808268144727,
      "learning_rate": 7.29176582579724e-06,
      "loss": 0.0065,
      "step": 13350
    },
    {
      "epoch": 6.358876725368872,
      "grad_norm": 0.0006524767959490418,
      "learning_rate": 7.282246549262256e-06,
      "loss": 0.0,
      "step": 13360
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 0.45836737751960754,
      "learning_rate": 7.272727272727273e-06,
      "loss": 0.0005,
      "step": 13370
    },
    {
      "epoch": 6.3683960019038555,
      "grad_norm": 0.0005285472143441439,
      "learning_rate": 7.26320799619229e-06,
      "loss": 0.0233,
      "step": 13380
    },
    {
      "epoch": 6.373155640171347,
      "grad_norm": 0.0014516108203679323,
      "learning_rate": 7.253688719657307e-06,
      "loss": 0.0,
      "step": 13390
    },
    {
      "epoch": 6.377915278438839,
      "grad_norm": 0.00011552395153557882,
      "learning_rate": 7.244169443122323e-06,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 6.38267491670633,
      "grad_norm": 0.0015069013461470604,
      "learning_rate": 7.2346501665873405e-06,
      "loss": 0.0,
      "step": 13410
    },
    {
      "epoch": 6.387434554973822,
      "grad_norm": 0.0005265454528853297,
      "learning_rate": 7.2251308900523565e-06,
      "loss": 0.0,
      "step": 13420
    },
    {
      "epoch": 6.3921941932413135,
      "grad_norm": 0.000235858911764808,
      "learning_rate": 7.215611613517373e-06,
      "loss": 0.0,
      "step": 13430
    },
    {
      "epoch": 6.396953831508806,
      "grad_norm": 3.1449079513549805,
      "learning_rate": 7.20609233698239e-06,
      "loss": 0.0004,
      "step": 13440
    },
    {
      "epoch": 6.401713469776297,
      "grad_norm": 0.00034077485906891525,
      "learning_rate": 7.196573060447407e-06,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 6.406473108043789,
      "grad_norm": 0.0018358966335654259,
      "learning_rate": 7.187053783912423e-06,
      "loss": 0.0063,
      "step": 13460
    },
    {
      "epoch": 6.41123274631128,
      "grad_norm": 0.0008897263905964792,
      "learning_rate": 7.17753450737744e-06,
      "loss": 0.0049,
      "step": 13470
    },
    {
      "epoch": 6.415992384578772,
      "grad_norm": 0.0008569805650040507,
      "learning_rate": 7.168015230842457e-06,
      "loss": 0.0049,
      "step": 13480
    },
    {
      "epoch": 6.420752022846264,
      "grad_norm": 0.0007537443307228386,
      "learning_rate": 7.158495954307473e-06,
      "loss": 0.0008,
      "step": 13490
    },
    {
      "epoch": 6.425511661113755,
      "grad_norm": 0.003960144706070423,
      "learning_rate": 7.14897667777249e-06,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 6.430271299381247,
      "grad_norm": 3.7884776247665286e-05,
      "learning_rate": 7.139457401237506e-06,
      "loss": 0.0,
      "step": 13510
    },
    {
      "epoch": 6.4350309376487385,
      "grad_norm": 0.0008520145784132183,
      "learning_rate": 7.129938124702523e-06,
      "loss": 0.0001,
      "step": 13520
    },
    {
      "epoch": 6.439790575916231,
      "grad_norm": 0.0008684397325851023,
      "learning_rate": 7.12041884816754e-06,
      "loss": 0.0,
      "step": 13530
    },
    {
      "epoch": 6.444550214183722,
      "grad_norm": 0.00020313500135671347,
      "learning_rate": 7.110899571632557e-06,
      "loss": 0.0001,
      "step": 13540
    },
    {
      "epoch": 6.449309852451214,
      "grad_norm": 1.6481962203979492,
      "learning_rate": 7.101380295097573e-06,
      "loss": 0.0034,
      "step": 13550
    },
    {
      "epoch": 6.454069490718705,
      "grad_norm": 0.0006034089019522071,
      "learning_rate": 7.0918610185625905e-06,
      "loss": 0.0001,
      "step": 13560
    },
    {
      "epoch": 6.458829128986197,
      "grad_norm": 0.00015778151282574981,
      "learning_rate": 7.0823417420276064e-06,
      "loss": 0.0,
      "step": 13570
    },
    {
      "epoch": 6.463588767253689,
      "grad_norm": 0.00034973424044437706,
      "learning_rate": 7.072822465492623e-06,
      "loss": 0.0,
      "step": 13580
    },
    {
      "epoch": 6.46834840552118,
      "grad_norm": 0.00028455848223529756,
      "learning_rate": 7.06330318895764e-06,
      "loss": 0.0,
      "step": 13590
    },
    {
      "epoch": 6.473108043788672,
      "grad_norm": 0.0008202046738006175,
      "learning_rate": 7.053783912422656e-06,
      "loss": 0.0,
      "step": 13600
    },
    {
      "epoch": 6.477867682056163,
      "grad_norm": 9.89071631920524e-05,
      "learning_rate": 7.044264635887673e-06,
      "loss": 0.0,
      "step": 13610
    },
    {
      "epoch": 6.4826273203236555,
      "grad_norm": 3.747771739959717,
      "learning_rate": 7.034745359352689e-06,
      "loss": 0.0215,
      "step": 13620
    },
    {
      "epoch": 6.487386958591147,
      "grad_norm": 0.00014222433674149215,
      "learning_rate": 7.025226082817707e-06,
      "loss": 0.0,
      "step": 13630
    },
    {
      "epoch": 6.492146596858639,
      "grad_norm": 0.00037098414031788707,
      "learning_rate": 7.015706806282723e-06,
      "loss": 0.0001,
      "step": 13640
    },
    {
      "epoch": 6.49690623512613,
      "grad_norm": 0.0003568343527149409,
      "learning_rate": 7.00618752974774e-06,
      "loss": 0.0,
      "step": 13650
    },
    {
      "epoch": 6.501665873393622,
      "grad_norm": 0.001386839197948575,
      "learning_rate": 6.996668253212756e-06,
      "loss": 0.0,
      "step": 13660
    },
    {
      "epoch": 6.506425511661114,
      "grad_norm": 0.0001375603023916483,
      "learning_rate": 6.987148976677773e-06,
      "loss": 0.0,
      "step": 13670
    },
    {
      "epoch": 6.511185149928606,
      "grad_norm": 0.000172397616552189,
      "learning_rate": 6.97762970014279e-06,
      "loss": 0.0003,
      "step": 13680
    },
    {
      "epoch": 6.515944788196097,
      "grad_norm": 0.0005464800051413476,
      "learning_rate": 6.968110423607807e-06,
      "loss": 0.0,
      "step": 13690
    },
    {
      "epoch": 6.520704426463588,
      "grad_norm": 0.000246298557613045,
      "learning_rate": 6.958591147072823e-06,
      "loss": 0.0117,
      "step": 13700
    },
    {
      "epoch": 6.52546406473108,
      "grad_norm": 0.00441341008991003,
      "learning_rate": 6.94907187053784e-06,
      "loss": 0.0,
      "step": 13710
    },
    {
      "epoch": 6.530223702998573,
      "grad_norm": 0.0004700874269474298,
      "learning_rate": 6.939552594002856e-06,
      "loss": 0.0,
      "step": 13720
    },
    {
      "epoch": 6.534983341266064,
      "grad_norm": 0.025218263268470764,
      "learning_rate": 6.930033317467873e-06,
      "loss": 0.0009,
      "step": 13730
    },
    {
      "epoch": 6.539742979533555,
      "grad_norm": 0.03659280762076378,
      "learning_rate": 6.92051404093289e-06,
      "loss": 0.0,
      "step": 13740
    },
    {
      "epoch": 6.544502617801047,
      "grad_norm": 0.00032846099929884076,
      "learning_rate": 6.910994764397906e-06,
      "loss": 0.0003,
      "step": 13750
    },
    {
      "epoch": 6.5492622560685385,
      "grad_norm": 0.00018519532750360668,
      "learning_rate": 6.901475487862923e-06,
      "loss": 0.0133,
      "step": 13760
    },
    {
      "epoch": 6.554021894336031,
      "grad_norm": 0.0007688615005463362,
      "learning_rate": 6.891956211327939e-06,
      "loss": 0.0,
      "step": 13770
    },
    {
      "epoch": 6.558781532603522,
      "grad_norm": 0.0009133218554779887,
      "learning_rate": 6.8824369347929566e-06,
      "loss": 0.0003,
      "step": 13780
    },
    {
      "epoch": 6.563541170871014,
      "grad_norm": 0.00042280659545212984,
      "learning_rate": 6.8729176582579725e-06,
      "loss": 0.0,
      "step": 13790
    },
    {
      "epoch": 6.568300809138505,
      "grad_norm": 0.00017900587408803403,
      "learning_rate": 6.86339838172299e-06,
      "loss": 0.0,
      "step": 13800
    },
    {
      "epoch": 6.5730604474059975,
      "grad_norm": 0.00014457471843343228,
      "learning_rate": 6.853879105188006e-06,
      "loss": 0.0002,
      "step": 13810
    },
    {
      "epoch": 6.577820085673489,
      "grad_norm": 0.00044201238779351115,
      "learning_rate": 6.844359828653023e-06,
      "loss": 0.0,
      "step": 13820
    },
    {
      "epoch": 6.582579723940981,
      "grad_norm": 0.00039711830322630703,
      "learning_rate": 6.834840552118039e-06,
      "loss": 0.0,
      "step": 13830
    },
    {
      "epoch": 6.587339362208472,
      "grad_norm": 0.0005853732000105083,
      "learning_rate": 6.825321275583057e-06,
      "loss": 0.0,
      "step": 13840
    },
    {
      "epoch": 6.592099000475963,
      "grad_norm": 0.004826551303267479,
      "learning_rate": 6.815801999048073e-06,
      "loss": 0.0,
      "step": 13850
    },
    {
      "epoch": 6.596858638743456,
      "grad_norm": 0.0002144218742614612,
      "learning_rate": 6.80628272251309e-06,
      "loss": 0.0,
      "step": 13860
    },
    {
      "epoch": 6.601618277010947,
      "grad_norm": 0.00010417510202387348,
      "learning_rate": 6.796763445978106e-06,
      "loss": 0.0004,
      "step": 13870
    },
    {
      "epoch": 6.606377915278439,
      "grad_norm": 0.002355922246351838,
      "learning_rate": 6.787244169443122e-06,
      "loss": 0.0,
      "step": 13880
    },
    {
      "epoch": 6.61113755354593,
      "grad_norm": 0.00046931373071856797,
      "learning_rate": 6.77772489290814e-06,
      "loss": 0.0,
      "step": 13890
    },
    {
      "epoch": 6.615897191813422,
      "grad_norm": 0.0006055629928596318,
      "learning_rate": 6.768205616373156e-06,
      "loss": 0.0,
      "step": 13900
    },
    {
      "epoch": 6.620656830080914,
      "grad_norm": 0.00046067286166362464,
      "learning_rate": 6.758686339838173e-06,
      "loss": 0.0458,
      "step": 13910
    },
    {
      "epoch": 6.625416468348406,
      "grad_norm": 0.00991093274205923,
      "learning_rate": 6.749167063303189e-06,
      "loss": 0.0,
      "step": 13920
    },
    {
      "epoch": 6.630176106615897,
      "grad_norm": 0.0010230359621345997,
      "learning_rate": 6.7396477867682065e-06,
      "loss": 0.0,
      "step": 13930
    },
    {
      "epoch": 6.634935744883389,
      "grad_norm": 0.00048788366257213056,
      "learning_rate": 6.7301285102332225e-06,
      "loss": 0.0014,
      "step": 13940
    },
    {
      "epoch": 6.6396953831508805,
      "grad_norm": 0.0011592297814786434,
      "learning_rate": 6.72060923369824e-06,
      "loss": 0.0,
      "step": 13950
    },
    {
      "epoch": 6.644455021418372,
      "grad_norm": 0.0001448523544240743,
      "learning_rate": 6.711089957163256e-06,
      "loss": 0.0,
      "step": 13960
    },
    {
      "epoch": 6.649214659685864,
      "grad_norm": 5.101803779602051,
      "learning_rate": 6.701570680628273e-06,
      "loss": 0.0291,
      "step": 13970
    },
    {
      "epoch": 6.653974297953356,
      "grad_norm": 0.0007122819079086185,
      "learning_rate": 6.692051404093289e-06,
      "loss": 0.0,
      "step": 13980
    },
    {
      "epoch": 6.658733936220847,
      "grad_norm": 0.00045015272917225957,
      "learning_rate": 6.682532127558307e-06,
      "loss": 0.0,
      "step": 13990
    },
    {
      "epoch": 6.663493574488339,
      "grad_norm": 0.000263714580796659,
      "learning_rate": 6.673012851023323e-06,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 6.668253212755831,
      "grad_norm": 0.00040969677502289414,
      "learning_rate": 6.663493574488339e-06,
      "loss": 0.0,
      "step": 14010
    },
    {
      "epoch": 6.673012851023322,
      "grad_norm": 0.00031325730378739536,
      "learning_rate": 6.653974297953356e-06,
      "loss": 0.0,
      "step": 14020
    },
    {
      "epoch": 6.677772489290814,
      "grad_norm": 0.004000475164502859,
      "learning_rate": 6.644455021418372e-06,
      "loss": 0.0,
      "step": 14030
    },
    {
      "epoch": 6.682532127558305,
      "grad_norm": 0.00020227312052156776,
      "learning_rate": 6.634935744883389e-06,
      "loss": 0.0,
      "step": 14040
    },
    {
      "epoch": 6.6872917658257975,
      "grad_norm": 0.0005975075764581561,
      "learning_rate": 6.625416468348406e-06,
      "loss": 0.0,
      "step": 14050
    },
    {
      "epoch": 6.692051404093289,
      "grad_norm": 0.0010113322641700506,
      "learning_rate": 6.615897191813423e-06,
      "loss": 0.0,
      "step": 14060
    },
    {
      "epoch": 6.696811042360781,
      "grad_norm": 0.0004896270111203194,
      "learning_rate": 6.606377915278439e-06,
      "loss": 0.0,
      "step": 14070
    },
    {
      "epoch": 6.701570680628272,
      "grad_norm": 0.0008445747080259025,
      "learning_rate": 6.5968586387434565e-06,
      "loss": 0.0,
      "step": 14080
    },
    {
      "epoch": 6.706330318895764,
      "grad_norm": 0.0003644342068582773,
      "learning_rate": 6.5873393622084725e-06,
      "loss": 0.0,
      "step": 14090
    },
    {
      "epoch": 6.711089957163256,
      "grad_norm": 0.000456724053947255,
      "learning_rate": 6.57782008567349e-06,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 6.715849595430747,
      "grad_norm": 0.00030451169004663825,
      "learning_rate": 6.568300809138506e-06,
      "loss": 0.0,
      "step": 14110
    },
    {
      "epoch": 6.720609233698239,
      "grad_norm": 0.000749522412661463,
      "learning_rate": 6.558781532603523e-06,
      "loss": 0.0001,
      "step": 14120
    },
    {
      "epoch": 6.72536887196573,
      "grad_norm": 0.00020092834893148392,
      "learning_rate": 6.549262256068539e-06,
      "loss": 0.0,
      "step": 14130
    },
    {
      "epoch": 6.7301285102332224,
      "grad_norm": 0.0003312721091788262,
      "learning_rate": 6.539742979533557e-06,
      "loss": 0.0,
      "step": 14140
    },
    {
      "epoch": 6.734888148500714,
      "grad_norm": 0.0003389901539776474,
      "learning_rate": 6.530223702998573e-06,
      "loss": 0.0,
      "step": 14150
    },
    {
      "epoch": 6.739647786768206,
      "grad_norm": 0.001010047155432403,
      "learning_rate": 6.520704426463589e-06,
      "loss": 0.0,
      "step": 14160
    },
    {
      "epoch": 6.744407425035697,
      "grad_norm": 0.0027042371220886707,
      "learning_rate": 6.511185149928606e-06,
      "loss": 0.0,
      "step": 14170
    },
    {
      "epoch": 6.749167063303189,
      "grad_norm": 0.00015198039181996137,
      "learning_rate": 6.501665873393622e-06,
      "loss": 0.0,
      "step": 14180
    },
    {
      "epoch": 6.7539267015706805,
      "grad_norm": 0.00019322446314617991,
      "learning_rate": 6.492146596858639e-06,
      "loss": 0.0,
      "step": 14190
    },
    {
      "epoch": 6.758686339838173,
      "grad_norm": 0.0018807516898959875,
      "learning_rate": 6.482627320323656e-06,
      "loss": 0.0,
      "step": 14200
    },
    {
      "epoch": 6.763445978105664,
      "grad_norm": 0.006826568860560656,
      "learning_rate": 6.473108043788673e-06,
      "loss": 0.0032,
      "step": 14210
    },
    {
      "epoch": 6.768205616373155,
      "grad_norm": 0.0013357772259041667,
      "learning_rate": 6.463588767253689e-06,
      "loss": 0.0,
      "step": 14220
    },
    {
      "epoch": 6.772965254640647,
      "grad_norm": 0.0008036477374844253,
      "learning_rate": 6.4540694907187064e-06,
      "loss": 0.0,
      "step": 14230
    },
    {
      "epoch": 6.777724892908139,
      "grad_norm": 0.00377448252402246,
      "learning_rate": 6.444550214183722e-06,
      "loss": 0.0,
      "step": 14240
    },
    {
      "epoch": 6.782484531175631,
      "grad_norm": 0.0008911977056413889,
      "learning_rate": 6.435030937648739e-06,
      "loss": 0.0096,
      "step": 14250
    },
    {
      "epoch": 6.787244169443122,
      "grad_norm": 0.004456992261111736,
      "learning_rate": 6.425511661113756e-06,
      "loss": 0.0013,
      "step": 14260
    },
    {
      "epoch": 6.792003807710614,
      "grad_norm": 0.00034297924139536917,
      "learning_rate": 6.415992384578773e-06,
      "loss": 0.0021,
      "step": 14270
    },
    {
      "epoch": 6.7967634459781054,
      "grad_norm": 0.001083403592929244,
      "learning_rate": 6.406473108043789e-06,
      "loss": 0.0013,
      "step": 14280
    },
    {
      "epoch": 6.801523084245598,
      "grad_norm": 0.0001255768584087491,
      "learning_rate": 6.396953831508806e-06,
      "loss": 0.0,
      "step": 14290
    },
    {
      "epoch": 6.806282722513089,
      "grad_norm": 0.07093401998281479,
      "learning_rate": 6.3874345549738226e-06,
      "loss": 0.0,
      "step": 14300
    },
    {
      "epoch": 6.811042360780581,
      "grad_norm": 0.00010575565102044493,
      "learning_rate": 6.3779152784388386e-06,
      "loss": 0.0,
      "step": 14310
    },
    {
      "epoch": 6.815801999048072,
      "grad_norm": 0.009823690168559551,
      "learning_rate": 6.368396001903856e-06,
      "loss": 0.0,
      "step": 14320
    },
    {
      "epoch": 6.8205616373155635,
      "grad_norm": 0.00030062481528148055,
      "learning_rate": 6.358876725368872e-06,
      "loss": 0.0001,
      "step": 14330
    },
    {
      "epoch": 6.825321275583056,
      "grad_norm": 0.0019645087886601686,
      "learning_rate": 6.349357448833889e-06,
      "loss": 0.0001,
      "step": 14340
    },
    {
      "epoch": 6.830080913850548,
      "grad_norm": 0.00032014906173571944,
      "learning_rate": 6.339838172298906e-06,
      "loss": 0.0,
      "step": 14350
    },
    {
      "epoch": 6.834840552118039,
      "grad_norm": 0.00011973149230470881,
      "learning_rate": 6.330318895763923e-06,
      "loss": 0.0002,
      "step": 14360
    },
    {
      "epoch": 6.83960019038553,
      "grad_norm": 0.00016940241039264947,
      "learning_rate": 6.320799619228939e-06,
      "loss": 0.0,
      "step": 14370
    },
    {
      "epoch": 6.8443598286530225,
      "grad_norm": 0.00041925732512027025,
      "learning_rate": 6.311280342693956e-06,
      "loss": 0.0,
      "step": 14380
    },
    {
      "epoch": 6.849119466920514,
      "grad_norm": 0.0006591782439500093,
      "learning_rate": 6.301761066158972e-06,
      "loss": 0.0001,
      "step": 14390
    },
    {
      "epoch": 6.853879105188006,
      "grad_norm": 0.0005281609483063221,
      "learning_rate": 6.292241789623989e-06,
      "loss": 0.0,
      "step": 14400
    },
    {
      "epoch": 6.858638743455497,
      "grad_norm": 0.0002302282809978351,
      "learning_rate": 6.282722513089006e-06,
      "loss": 0.0186,
      "step": 14410
    },
    {
      "epoch": 6.863398381722989,
      "grad_norm": 0.0003265965497121215,
      "learning_rate": 6.273203236554022e-06,
      "loss": 0.0135,
      "step": 14420
    },
    {
      "epoch": 6.868158019990481,
      "grad_norm": 0.006144614424556494,
      "learning_rate": 6.263683960019039e-06,
      "loss": 0.0222,
      "step": 14430
    },
    {
      "epoch": 6.872917658257973,
      "grad_norm": 0.0003176005557179451,
      "learning_rate": 6.254164683484055e-06,
      "loss": 0.0,
      "step": 14440
    },
    {
      "epoch": 6.877677296525464,
      "grad_norm": 0.0011974605731666088,
      "learning_rate": 6.2446454069490725e-06,
      "loss": 0.0,
      "step": 14450
    },
    {
      "epoch": 6.882436934792956,
      "grad_norm": 0.00047419656766578555,
      "learning_rate": 6.2351261304140885e-06,
      "loss": 0.0,
      "step": 14460
    },
    {
      "epoch": 6.887196573060447,
      "grad_norm": 0.0004999276716262102,
      "learning_rate": 6.225606853879106e-06,
      "loss": 0.0,
      "step": 14470
    },
    {
      "epoch": 6.891956211327939,
      "grad_norm": 0.0017285511130467057,
      "learning_rate": 6.216087577344122e-06,
      "loss": 0.0,
      "step": 14480
    },
    {
      "epoch": 6.896715849595431,
      "grad_norm": 0.000436845381045714,
      "learning_rate": 6.206568300809139e-06,
      "loss": 0.014,
      "step": 14490
    },
    {
      "epoch": 6.901475487862922,
      "grad_norm": 0.030207691714167595,
      "learning_rate": 6.197049024274156e-06,
      "loss": 0.0001,
      "step": 14500
    },
    {
      "epoch": 6.906235126130414,
      "grad_norm": 0.0004522608360275626,
      "learning_rate": 6.187529747739173e-06,
      "loss": 0.0,
      "step": 14510
    },
    {
      "epoch": 6.9109947643979055,
      "grad_norm": 0.0029041531961411238,
      "learning_rate": 6.178010471204189e-06,
      "loss": 0.0,
      "step": 14520
    },
    {
      "epoch": 6.915754402665398,
      "grad_norm": 0.0005414920160546899,
      "learning_rate": 6.168491194669206e-06,
      "loss": 0.0084,
      "step": 14530
    },
    {
      "epoch": 6.920514040932889,
      "grad_norm": 0.003447277005761862,
      "learning_rate": 6.158971918134222e-06,
      "loss": 0.0006,
      "step": 14540
    },
    {
      "epoch": 6.925273679200381,
      "grad_norm": 0.0012731421738862991,
      "learning_rate": 6.149452641599239e-06,
      "loss": 0.0001,
      "step": 14550
    },
    {
      "epoch": 6.930033317467872,
      "grad_norm": 0.0016138198552653193,
      "learning_rate": 6.139933365064256e-06,
      "loss": 0.0,
      "step": 14560
    },
    {
      "epoch": 6.9347929557353645,
      "grad_norm": 0.0017376671312376857,
      "learning_rate": 6.130414088529272e-06,
      "loss": 0.0,
      "step": 14570
    },
    {
      "epoch": 6.939552594002856,
      "grad_norm": 0.0005072557833045721,
      "learning_rate": 6.120894811994289e-06,
      "loss": 0.0,
      "step": 14580
    },
    {
      "epoch": 6.944312232270347,
      "grad_norm": 1.4593719244003296,
      "learning_rate": 6.111375535459305e-06,
      "loss": 0.001,
      "step": 14590
    },
    {
      "epoch": 6.949071870537839,
      "grad_norm": 0.00034103821963071823,
      "learning_rate": 6.1018562589243225e-06,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 6.95383150880533,
      "grad_norm": 0.0007266181637533009,
      "learning_rate": 6.0923369823893385e-06,
      "loss": 0.0,
      "step": 14610
    },
    {
      "epoch": 6.958591147072823,
      "grad_norm": 0.0003106811491306871,
      "learning_rate": 6.082817705854356e-06,
      "loss": 0.0,
      "step": 14620
    },
    {
      "epoch": 6.963350785340314,
      "grad_norm": 0.0021021023858338594,
      "learning_rate": 6.073298429319372e-06,
      "loss": 0.0,
      "step": 14630
    },
    {
      "epoch": 6.968110423607806,
      "grad_norm": 0.0008084725704975426,
      "learning_rate": 6.063779152784389e-06,
      "loss": 0.0003,
      "step": 14640
    },
    {
      "epoch": 6.972870061875297,
      "grad_norm": 0.0020754176657646894,
      "learning_rate": 6.054259876249405e-06,
      "loss": 0.0,
      "step": 14650
    },
    {
      "epoch": 6.977629700142789,
      "grad_norm": 0.0011907878797501326,
      "learning_rate": 6.044740599714423e-06,
      "loss": 0.0,
      "step": 14660
    },
    {
      "epoch": 6.982389338410281,
      "grad_norm": 0.005297841038554907,
      "learning_rate": 6.035221323179439e-06,
      "loss": 0.0021,
      "step": 14670
    },
    {
      "epoch": 6.987148976677773,
      "grad_norm": 0.00027702798251993954,
      "learning_rate": 6.025702046644456e-06,
      "loss": 0.005,
      "step": 14680
    },
    {
      "epoch": 6.991908614945264,
      "grad_norm": 0.00035362414200790226,
      "learning_rate": 6.016182770109472e-06,
      "loss": 0.0,
      "step": 14690
    },
    {
      "epoch": 6.996668253212756,
      "grad_norm": 0.0005097751272842288,
      "learning_rate": 6.006663493574488e-06,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9974305555555556,
      "eval_f1": 0.9860745201354911,
      "eval_loss": 0.017426516860723495,
      "eval_precision": 0.9886792452830189,
      "eval_recall": 0.9834834834834835,
      "eval_runtime": 343.1669,
      "eval_samples_per_second": 41.994,
      "eval_steps_per_second": 1.314,
      "step": 14707
    },
    {
      "epoch": 7.0014278914802475,
      "grad_norm": 0.00038582453271374106,
      "learning_rate": 5.997144217039506e-06,
      "loss": 0.0022,
      "step": 14710
    },
    {
      "epoch": 7.006187529747739,
      "grad_norm": 0.00010601121903164312,
      "learning_rate": 5.987624940504522e-06,
      "loss": 0.0,
      "step": 14720
    },
    {
      "epoch": 7.010947168015231,
      "grad_norm": 0.0003505807544570416,
      "learning_rate": 5.978105663969539e-06,
      "loss": 0.0,
      "step": 14730
    },
    {
      "epoch": 7.015706806282722,
      "grad_norm": 0.0001556218630867079,
      "learning_rate": 5.968586387434555e-06,
      "loss": 0.0,
      "step": 14740
    },
    {
      "epoch": 7.020466444550214,
      "grad_norm": 0.32775652408599854,
      "learning_rate": 5.9590671108995725e-06,
      "loss": 0.0005,
      "step": 14750
    },
    {
      "epoch": 7.0252260828177056,
      "grad_norm": 0.00033899975824169815,
      "learning_rate": 5.9495478343645884e-06,
      "loss": 0.0,
      "step": 14760
    },
    {
      "epoch": 7.029985721085198,
      "grad_norm": 0.00018139250460080802,
      "learning_rate": 5.940028557829606e-06,
      "loss": 0.0,
      "step": 14770
    },
    {
      "epoch": 7.034745359352689,
      "grad_norm": 0.00041524236439727247,
      "learning_rate": 5.930509281294622e-06,
      "loss": 0.0,
      "step": 14780
    },
    {
      "epoch": 7.039504997620181,
      "grad_norm": 0.0002230779209639877,
      "learning_rate": 5.920990004759639e-06,
      "loss": 0.0,
      "step": 14790
    },
    {
      "epoch": 7.044264635887672,
      "grad_norm": 0.00011084107973147184,
      "learning_rate": 5.911470728224655e-06,
      "loss": 0.0074,
      "step": 14800
    },
    {
      "epoch": 7.0490242741551645,
      "grad_norm": 0.00015108489606063813,
      "learning_rate": 5.901951451689673e-06,
      "loss": 0.0,
      "step": 14810
    },
    {
      "epoch": 7.053783912422656,
      "grad_norm": 0.00014840993389952928,
      "learning_rate": 5.892432175154689e-06,
      "loss": 0.0,
      "step": 14820
    },
    {
      "epoch": 7.058543550690148,
      "grad_norm": 0.0001717422273941338,
      "learning_rate": 5.882912898619706e-06,
      "loss": 0.0,
      "step": 14830
    },
    {
      "epoch": 7.063303188957639,
      "grad_norm": 0.00020968529861420393,
      "learning_rate": 5.873393622084722e-06,
      "loss": 0.0,
      "step": 14840
    },
    {
      "epoch": 7.0680628272251305,
      "grad_norm": 0.00013380592281464487,
      "learning_rate": 5.863874345549738e-06,
      "loss": 0.0,
      "step": 14850
    },
    {
      "epoch": 7.072822465492623,
      "grad_norm": 9.537705773254856e-05,
      "learning_rate": 5.854355069014755e-06,
      "loss": 0.002,
      "step": 14860
    },
    {
      "epoch": 7.077582103760114,
      "grad_norm": 0.0003758757666219026,
      "learning_rate": 5.844835792479772e-06,
      "loss": 0.0,
      "step": 14870
    },
    {
      "epoch": 7.082341742027606,
      "grad_norm": 0.002126381266862154,
      "learning_rate": 5.835316515944789e-06,
      "loss": 0.0,
      "step": 14880
    },
    {
      "epoch": 7.087101380295097,
      "grad_norm": 0.000747141195461154,
      "learning_rate": 5.825797239409805e-06,
      "loss": 0.0,
      "step": 14890
    },
    {
      "epoch": 7.091861018562589,
      "grad_norm": 0.0001336934365099296,
      "learning_rate": 5.816277962874822e-06,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 7.096620656830081,
      "grad_norm": 0.0002794413303490728,
      "learning_rate": 5.806758686339838e-06,
      "loss": 0.0001,
      "step": 14910
    },
    {
      "epoch": 7.101380295097573,
      "grad_norm": 0.00011859619553433731,
      "learning_rate": 5.797239409804856e-06,
      "loss": 0.0,
      "step": 14920
    },
    {
      "epoch": 7.106139933365064,
      "grad_norm": 0.0001721788285067305,
      "learning_rate": 5.787720133269872e-06,
      "loss": 0.0042,
      "step": 14930
    },
    {
      "epoch": 7.110899571632556,
      "grad_norm": 0.0006599155603908002,
      "learning_rate": 5.778200856734889e-06,
      "loss": 0.0,
      "step": 14940
    },
    {
      "epoch": 7.1156592099000475,
      "grad_norm": 0.0003493094118312001,
      "learning_rate": 5.768681580199905e-06,
      "loss": 0.0001,
      "step": 14950
    },
    {
      "epoch": 7.12041884816754,
      "grad_norm": 0.000808647193480283,
      "learning_rate": 5.7591623036649226e-06,
      "loss": 0.0002,
      "step": 14960
    },
    {
      "epoch": 7.125178486435031,
      "grad_norm": 0.000506221316754818,
      "learning_rate": 5.7496430271299385e-06,
      "loss": 0.0,
      "step": 14970
    },
    {
      "epoch": 7.129938124702522,
      "grad_norm": 0.00016721579595468938,
      "learning_rate": 5.7401237505949545e-06,
      "loss": 0.0,
      "step": 14980
    },
    {
      "epoch": 7.134697762970014,
      "grad_norm": 0.0004382692277431488,
      "learning_rate": 5.730604474059972e-06,
      "loss": 0.0,
      "step": 14990
    },
    {
      "epoch": 7.139457401237506,
      "grad_norm": 0.0001126886490965262,
      "learning_rate": 5.721085197524988e-06,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 7.144217039504998,
      "grad_norm": 0.0008493876666761935,
      "learning_rate": 5.711565920990005e-06,
      "loss": 0.0,
      "step": 15010
    },
    {
      "epoch": 7.148976677772489,
      "grad_norm": 0.0005888864980079234,
      "learning_rate": 5.702046644455022e-06,
      "loss": 0.0007,
      "step": 15020
    },
    {
      "epoch": 7.153736316039981,
      "grad_norm": 0.0006276439526118338,
      "learning_rate": 5.692527367920039e-06,
      "loss": 0.0,
      "step": 15030
    },
    {
      "epoch": 7.158495954307472,
      "grad_norm": 0.0001401593181071803,
      "learning_rate": 5.683008091385055e-06,
      "loss": 0.0,
      "step": 15040
    },
    {
      "epoch": 7.163255592574965,
      "grad_norm": 0.00010929337440757081,
      "learning_rate": 5.673488814850072e-06,
      "loss": 0.0158,
      "step": 15050
    },
    {
      "epoch": 7.168015230842456,
      "grad_norm": 0.00011752277350751683,
      "learning_rate": 5.663969538315088e-06,
      "loss": 0.0035,
      "step": 15060
    },
    {
      "epoch": 7.172774869109948,
      "grad_norm": 0.002096383133903146,
      "learning_rate": 5.654450261780105e-06,
      "loss": 0.0,
      "step": 15070
    },
    {
      "epoch": 7.177534507377439,
      "grad_norm": 0.0004643370339181274,
      "learning_rate": 5.644930985245122e-06,
      "loss": 0.0,
      "step": 15080
    },
    {
      "epoch": 7.182294145644931,
      "grad_norm": 0.013668308034539223,
      "learning_rate": 5.635411708710139e-06,
      "loss": 0.0,
      "step": 15090
    },
    {
      "epoch": 7.187053783912423,
      "grad_norm": 0.00018772136536426842,
      "learning_rate": 5.625892432175155e-06,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 7.191813422179914,
      "grad_norm": 0.0001237344549736008,
      "learning_rate": 5.616373155640172e-06,
      "loss": 0.0003,
      "step": 15110
    },
    {
      "epoch": 7.196573060447406,
      "grad_norm": 0.0002462571719661355,
      "learning_rate": 5.6068538791051885e-06,
      "loss": 0.0,
      "step": 15120
    },
    {
      "epoch": 7.201332698714897,
      "grad_norm": 0.0004164764832239598,
      "learning_rate": 5.5973346025702045e-06,
      "loss": 0.0,
      "step": 15130
    },
    {
      "epoch": 7.2060923369823895,
      "grad_norm": 0.0011680213501676917,
      "learning_rate": 5.587815326035222e-06,
      "loss": 0.0,
      "step": 15140
    },
    {
      "epoch": 7.210851975249881,
      "grad_norm": 0.0005917281378060579,
      "learning_rate": 5.578296049500238e-06,
      "loss": 0.0,
      "step": 15150
    },
    {
      "epoch": 7.215611613517373,
      "grad_norm": 0.00042831344762817025,
      "learning_rate": 5.568776772965255e-06,
      "loss": 0.0,
      "step": 15160
    },
    {
      "epoch": 7.220371251784864,
      "grad_norm": 0.000317665544571355,
      "learning_rate": 5.559257496430272e-06,
      "loss": 0.0,
      "step": 15170
    },
    {
      "epoch": 7.225130890052356,
      "grad_norm": 0.002673883456736803,
      "learning_rate": 5.549738219895289e-06,
      "loss": 0.0,
      "step": 15180
    },
    {
      "epoch": 7.229890528319848,
      "grad_norm": 0.004932476207613945,
      "learning_rate": 5.540218943360305e-06,
      "loss": 0.0,
      "step": 15190
    },
    {
      "epoch": 7.23465016658734,
      "grad_norm": 0.00017495907377451658,
      "learning_rate": 5.530699666825322e-06,
      "loss": 0.0062,
      "step": 15200
    },
    {
      "epoch": 7.239409804854831,
      "grad_norm": 0.0003667263954412192,
      "learning_rate": 5.521180390290338e-06,
      "loss": 0.0,
      "step": 15210
    },
    {
      "epoch": 7.244169443122322,
      "grad_norm": 7.182169065345079e-05,
      "learning_rate": 5.511661113755355e-06,
      "loss": 0.0005,
      "step": 15220
    },
    {
      "epoch": 7.248929081389814,
      "grad_norm": 0.00018445737077854574,
      "learning_rate": 5.502141837220372e-06,
      "loss": 0.0004,
      "step": 15230
    },
    {
      "epoch": 7.253688719657306,
      "grad_norm": 0.001100730849429965,
      "learning_rate": 5.492622560685389e-06,
      "loss": 0.0,
      "step": 15240
    },
    {
      "epoch": 7.258448357924798,
      "grad_norm": 8.614959369879216e-05,
      "learning_rate": 5.483103284150405e-06,
      "loss": 0.0,
      "step": 15250
    },
    {
      "epoch": 7.263207996192289,
      "grad_norm": 0.00037510073161683977,
      "learning_rate": 5.473584007615421e-06,
      "loss": 0.0,
      "step": 15260
    },
    {
      "epoch": 7.267967634459781,
      "grad_norm": 0.00014023270341567695,
      "learning_rate": 5.4640647310804385e-06,
      "loss": 0.0,
      "step": 15270
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.00010683484288165346,
      "learning_rate": 5.4545454545454545e-06,
      "loss": 0.0071,
      "step": 15280
    },
    {
      "epoch": 7.277486910994765,
      "grad_norm": 7.751577504677698e-05,
      "learning_rate": 5.445026178010472e-06,
      "loss": 0.0,
      "step": 15290
    },
    {
      "epoch": 7.282246549262256,
      "grad_norm": 0.00013608901645056903,
      "learning_rate": 5.435506901475488e-06,
      "loss": 0.0,
      "step": 15300
    },
    {
      "epoch": 7.287006187529748,
      "grad_norm": 0.00010745664621936157,
      "learning_rate": 5.425987624940505e-06,
      "loss": 0.0,
      "step": 15310
    },
    {
      "epoch": 7.291765825797239,
      "grad_norm": 0.00020158113329671323,
      "learning_rate": 5.416468348405522e-06,
      "loss": 0.0008,
      "step": 15320
    },
    {
      "epoch": 7.2965254640647315,
      "grad_norm": 0.002144420985132456,
      "learning_rate": 5.406949071870539e-06,
      "loss": 0.0007,
      "step": 15330
    },
    {
      "epoch": 7.301285102332223,
      "grad_norm": 0.000240143810515292,
      "learning_rate": 5.397429795335555e-06,
      "loss": 0.0,
      "step": 15340
    },
    {
      "epoch": 7.306044740599715,
      "grad_norm": 0.00021116658172104508,
      "learning_rate": 5.387910518800572e-06,
      "loss": 0.0,
      "step": 15350
    },
    {
      "epoch": 7.310804378867206,
      "grad_norm": 0.00011359687778167427,
      "learning_rate": 5.378391242265588e-06,
      "loss": 0.0,
      "step": 15360
    },
    {
      "epoch": 7.315564017134697,
      "grad_norm": 0.00017180400027427822,
      "learning_rate": 5.368871965730605e-06,
      "loss": 0.0,
      "step": 15370
    },
    {
      "epoch": 7.3203236554021895,
      "grad_norm": 0.0002965143939945847,
      "learning_rate": 5.359352689195622e-06,
      "loss": 0.0,
      "step": 15380
    },
    {
      "epoch": 7.325083293669681,
      "grad_norm": 0.0003097944427281618,
      "learning_rate": 5.349833412660638e-06,
      "loss": 0.0,
      "step": 15390
    },
    {
      "epoch": 7.329842931937173,
      "grad_norm": 0.00012159698962932453,
      "learning_rate": 5.340314136125655e-06,
      "loss": 0.0,
      "step": 15400
    },
    {
      "epoch": 7.334602570204664,
      "grad_norm": 0.0003604921221267432,
      "learning_rate": 5.330794859590671e-06,
      "loss": 0.0,
      "step": 15410
    },
    {
      "epoch": 7.339362208472156,
      "grad_norm": 0.00012656187755055726,
      "learning_rate": 5.3212755830556884e-06,
      "loss": 0.0,
      "step": 15420
    },
    {
      "epoch": 7.344121846739648,
      "grad_norm": 0.00029185417224653065,
      "learning_rate": 5.311756306520704e-06,
      "loss": 0.0,
      "step": 15430
    },
    {
      "epoch": 7.34888148500714,
      "grad_norm": 1.4984568357467651,
      "learning_rate": 5.302237029985722e-06,
      "loss": 0.0086,
      "step": 15440
    },
    {
      "epoch": 7.353641123274631,
      "grad_norm": 0.00011430809536250308,
      "learning_rate": 5.292717753450738e-06,
      "loss": 0.0,
      "step": 15450
    },
    {
      "epoch": 7.358400761542123,
      "grad_norm": 0.00025498142349533737,
      "learning_rate": 5.283198476915755e-06,
      "loss": 0.0,
      "step": 15460
    },
    {
      "epoch": 7.3631603998096145,
      "grad_norm": 0.00016764418978709728,
      "learning_rate": 5.273679200380771e-06,
      "loss": 0.0,
      "step": 15470
    },
    {
      "epoch": 7.367920038077106,
      "grad_norm": 0.0001285807666135952,
      "learning_rate": 5.264159923845789e-06,
      "loss": 0.0,
      "step": 15480
    },
    {
      "epoch": 7.372679676344598,
      "grad_norm": 0.00010235776426270604,
      "learning_rate": 5.2546406473108046e-06,
      "loss": 0.0,
      "step": 15490
    },
    {
      "epoch": 7.377439314612089,
      "grad_norm": 9.474309626966715e-05,
      "learning_rate": 5.245121370775822e-06,
      "loss": 0.0,
      "step": 15500
    },
    {
      "epoch": 7.382198952879581,
      "grad_norm": 0.0021217353641986847,
      "learning_rate": 5.235602094240838e-06,
      "loss": 0.0,
      "step": 15510
    },
    {
      "epoch": 7.3869585911470725,
      "grad_norm": 0.0005596530972979963,
      "learning_rate": 5.226082817705854e-06,
      "loss": 0.0,
      "step": 15520
    },
    {
      "epoch": 7.391718229414565,
      "grad_norm": 4.6849057980580255e-05,
      "learning_rate": 5.216563541170872e-06,
      "loss": 0.0,
      "step": 15530
    },
    {
      "epoch": 7.396477867682056,
      "grad_norm": 0.00029194250237196684,
      "learning_rate": 5.207044264635888e-06,
      "loss": 0.0166,
      "step": 15540
    },
    {
      "epoch": 7.401237505949548,
      "grad_norm": 0.00025883869966492057,
      "learning_rate": 5.197524988100905e-06,
      "loss": 0.0,
      "step": 15550
    },
    {
      "epoch": 7.405997144217039,
      "grad_norm": 0.00013941185898147523,
      "learning_rate": 5.188005711565921e-06,
      "loss": 0.0,
      "step": 15560
    },
    {
      "epoch": 7.4107567824845315,
      "grad_norm": 0.00012621376663446426,
      "learning_rate": 5.178486435030938e-06,
      "loss": 0.0007,
      "step": 15570
    },
    {
      "epoch": 7.415516420752023,
      "grad_norm": 0.00022426187933888286,
      "learning_rate": 5.168967158495954e-06,
      "loss": 0.0,
      "step": 15580
    },
    {
      "epoch": 7.420276059019515,
      "grad_norm": 0.0016809472581371665,
      "learning_rate": 5.159447881960972e-06,
      "loss": 0.0,
      "step": 15590
    },
    {
      "epoch": 7.425035697287006,
      "grad_norm": 0.00015234349120873958,
      "learning_rate": 5.149928605425988e-06,
      "loss": 0.0,
      "step": 15600
    },
    {
      "epoch": 7.4297953355544974,
      "grad_norm": 0.0006613805890083313,
      "learning_rate": 5.140409328891005e-06,
      "loss": 0.0,
      "step": 15610
    },
    {
      "epoch": 7.43455497382199,
      "grad_norm": 0.00013968185521662235,
      "learning_rate": 5.130890052356021e-06,
      "loss": 0.0,
      "step": 15620
    },
    {
      "epoch": 7.439314612089481,
      "grad_norm": 0.00010941638902295381,
      "learning_rate": 5.1213707758210385e-06,
      "loss": 0.0001,
      "step": 15630
    },
    {
      "epoch": 7.444074250356973,
      "grad_norm": 4.4743468606611714e-05,
      "learning_rate": 5.1118514992860545e-06,
      "loss": 0.0,
      "step": 15640
    },
    {
      "epoch": 7.448833888624464,
      "grad_norm": 0.00010751501395134255,
      "learning_rate": 5.102332222751072e-06,
      "loss": 0.0,
      "step": 15650
    },
    {
      "epoch": 7.453593526891956,
      "grad_norm": 6.050994124962017e-05,
      "learning_rate": 5.092812946216088e-06,
      "loss": 0.0,
      "step": 15660
    },
    {
      "epoch": 7.458353165159448,
      "grad_norm": 0.00025667628506198525,
      "learning_rate": 5.083293669681104e-06,
      "loss": 0.0,
      "step": 15670
    },
    {
      "epoch": 7.46311280342694,
      "grad_norm": 0.00019460677867755294,
      "learning_rate": 5.073774393146121e-06,
      "loss": 0.0,
      "step": 15680
    },
    {
      "epoch": 7.467872441694431,
      "grad_norm": 8.593725215177983e-05,
      "learning_rate": 5.064255116611138e-06,
      "loss": 0.0,
      "step": 15690
    },
    {
      "epoch": 7.472632079961923,
      "grad_norm": 0.0006816266104578972,
      "learning_rate": 5.054735840076155e-06,
      "loss": 0.0,
      "step": 15700
    },
    {
      "epoch": 7.4773917182294145,
      "grad_norm": 0.00017183393356390297,
      "learning_rate": 5.045216563541171e-06,
      "loss": 0.0,
      "step": 15710
    },
    {
      "epoch": 7.482151356496907,
      "grad_norm": 0.0006719129160046577,
      "learning_rate": 5.035697287006188e-06,
      "loss": 0.0017,
      "step": 15720
    },
    {
      "epoch": 7.486910994764398,
      "grad_norm": 0.00010290093632647768,
      "learning_rate": 5.026178010471204e-06,
      "loss": 0.0005,
      "step": 15730
    },
    {
      "epoch": 7.491670633031889,
      "grad_norm": 0.00021874652884434909,
      "learning_rate": 5.016658733936222e-06,
      "loss": 0.0,
      "step": 15740
    },
    {
      "epoch": 7.496430271299381,
      "grad_norm": 5.486695226863958e-05,
      "learning_rate": 5.007139457401238e-06,
      "loss": 0.0,
      "step": 15750
    },
    {
      "epoch": 7.501189909566873,
      "grad_norm": 6.594717706320807e-05,
      "learning_rate": 4.997620180866255e-06,
      "loss": 0.0,
      "step": 15760
    },
    {
      "epoch": 7.505949547834365,
      "grad_norm": 0.00014280692266765982,
      "learning_rate": 4.988100904331271e-06,
      "loss": 0.0,
      "step": 15770
    },
    {
      "epoch": 7.510709186101856,
      "grad_norm": 0.00010797310096677393,
      "learning_rate": 4.978581627796288e-06,
      "loss": 0.0,
      "step": 15780
    },
    {
      "epoch": 7.515468824369348,
      "grad_norm": 0.006674617528915405,
      "learning_rate": 4.9690623512613045e-06,
      "loss": 0.0,
      "step": 15790
    },
    {
      "epoch": 7.520228462636839,
      "grad_norm": 4.148589141550474e-05,
      "learning_rate": 4.959543074726321e-06,
      "loss": 0.0,
      "step": 15800
    },
    {
      "epoch": 7.524988100904332,
      "grad_norm": 0.0002730968699324876,
      "learning_rate": 4.950023798191338e-06,
      "loss": 0.0,
      "step": 15810
    },
    {
      "epoch": 7.529747739171823,
      "grad_norm": 0.0009211998549290001,
      "learning_rate": 4.940504521656355e-06,
      "loss": 0.0,
      "step": 15820
    },
    {
      "epoch": 7.534507377439315,
      "grad_norm": 3.324035060359165e-05,
      "learning_rate": 4.930985245121371e-06,
      "loss": 0.0,
      "step": 15830
    },
    {
      "epoch": 7.539267015706806,
      "grad_norm": 0.0015463419258594513,
      "learning_rate": 4.921465968586388e-06,
      "loss": 0.0001,
      "step": 15840
    },
    {
      "epoch": 7.5440266539742975,
      "grad_norm": 0.00023600035638082772,
      "learning_rate": 4.911946692051405e-06,
      "loss": 0.0065,
      "step": 15850
    },
    {
      "epoch": 7.54878629224179,
      "grad_norm": 0.0001250575587619096,
      "learning_rate": 4.9024274155164215e-06,
      "loss": 0.0,
      "step": 15860
    },
    {
      "epoch": 7.553545930509281,
      "grad_norm": 3.618309710873291e-05,
      "learning_rate": 4.8929081389814375e-06,
      "loss": 0.0001,
      "step": 15870
    },
    {
      "epoch": 7.558305568776773,
      "grad_norm": 0.00023699550365563482,
      "learning_rate": 4.883388862446454e-06,
      "loss": 0.0,
      "step": 15880
    },
    {
      "epoch": 7.563065207044264,
      "grad_norm": 0.0004886817187070847,
      "learning_rate": 4.873869585911471e-06,
      "loss": 0.0,
      "step": 15890
    },
    {
      "epoch": 7.5678248453117565,
      "grad_norm": 0.00011387871199985966,
      "learning_rate": 4.864350309376488e-06,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 7.572584483579248,
      "grad_norm": 0.00030118945869617164,
      "learning_rate": 4.854831032841505e-06,
      "loss": 0.0,
      "step": 15910
    },
    {
      "epoch": 7.57734412184674,
      "grad_norm": 0.0011365721002221107,
      "learning_rate": 4.845311756306521e-06,
      "loss": 0.0,
      "step": 15920
    },
    {
      "epoch": 7.582103760114231,
      "grad_norm": 8.876385254552588e-05,
      "learning_rate": 4.835792479771538e-06,
      "loss": 0.0295,
      "step": 15930
    },
    {
      "epoch": 7.586863398381723,
      "grad_norm": 8.694818097865209e-05,
      "learning_rate": 4.8262732032365544e-06,
      "loss": 0.0,
      "step": 15940
    },
    {
      "epoch": 7.591623036649215,
      "grad_norm": 0.00040273185004480183,
      "learning_rate": 4.816753926701571e-06,
      "loss": 0.0,
      "step": 15950
    },
    {
      "epoch": 7.596382674916707,
      "grad_norm": 4.60143419331871e-05,
      "learning_rate": 4.807234650166588e-06,
      "loss": 0.0001,
      "step": 15960
    },
    {
      "epoch": 7.601142313184198,
      "grad_norm": 0.0001747001224430278,
      "learning_rate": 4.797715373631605e-06,
      "loss": 0.0,
      "step": 15970
    },
    {
      "epoch": 7.60590195145169,
      "grad_norm": 0.0024097294081002474,
      "learning_rate": 4.788196097096621e-06,
      "loss": 0.0001,
      "step": 15980
    },
    {
      "epoch": 7.610661589719181,
      "grad_norm": 0.0013282328145578504,
      "learning_rate": 4.778676820561638e-06,
      "loss": 0.0,
      "step": 15990
    },
    {
      "epoch": 7.615421227986673,
      "grad_norm": 6.120142643339932e-05,
      "learning_rate": 4.769157544026654e-06,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 7.620180866254165,
      "grad_norm": 7.568168803118169e-05,
      "learning_rate": 4.759638267491671e-06,
      "loss": 0.0,
      "step": 16010
    },
    {
      "epoch": 7.624940504521656,
      "grad_norm": 6.237130583031103e-05,
      "learning_rate": 4.750118990956687e-06,
      "loss": 0.0,
      "step": 16020
    },
    {
      "epoch": 7.629700142789148,
      "grad_norm": 0.00034421629970893264,
      "learning_rate": 4.740599714421704e-06,
      "loss": 0.0,
      "step": 16030
    },
    {
      "epoch": 7.6344597810566395,
      "grad_norm": 0.00016768599743954837,
      "learning_rate": 4.731080437886721e-06,
      "loss": 0.0,
      "step": 16040
    },
    {
      "epoch": 7.639219419324132,
      "grad_norm": 4.224798976792954e-05,
      "learning_rate": 4.721561161351738e-06,
      "loss": 0.0,
      "step": 16050
    },
    {
      "epoch": 7.643979057591623,
      "grad_norm": 1.9626199007034302,
      "learning_rate": 4.712041884816754e-06,
      "loss": 0.0083,
      "step": 16060
    },
    {
      "epoch": 7.648738695859115,
      "grad_norm": 0.00010783233301481232,
      "learning_rate": 4.702522608281771e-06,
      "loss": 0.0,
      "step": 16070
    },
    {
      "epoch": 7.653498334126606,
      "grad_norm": 3.613279841374606e-05,
      "learning_rate": 4.6930033317467876e-06,
      "loss": 0.0,
      "step": 16080
    },
    {
      "epoch": 7.6582579723940984,
      "grad_norm": 7.177987572504207e-05,
      "learning_rate": 4.683484055211804e-06,
      "loss": 0.0,
      "step": 16090
    },
    {
      "epoch": 7.66301761066159,
      "grad_norm": 0.00011407975398469716,
      "learning_rate": 4.673964778676821e-06,
      "loss": 0.0,
      "step": 16100
    },
    {
      "epoch": 7.667777248929081,
      "grad_norm": 4.2941996071022004e-05,
      "learning_rate": 4.664445502141838e-06,
      "loss": 0.0,
      "step": 16110
    },
    {
      "epoch": 7.672536887196573,
      "grad_norm": 8.773330773692578e-05,
      "learning_rate": 4.654926225606855e-06,
      "loss": 0.0,
      "step": 16120
    },
    {
      "epoch": 7.677296525464064,
      "grad_norm": 4.724393511423841e-05,
      "learning_rate": 4.645406949071871e-06,
      "loss": 0.0042,
      "step": 16130
    },
    {
      "epoch": 7.6820561637315565,
      "grad_norm": 5.027115548728034e-05,
      "learning_rate": 4.635887672536888e-06,
      "loss": 0.0,
      "step": 16140
    },
    {
      "epoch": 7.686815801999048,
      "grad_norm": 0.007155491970479488,
      "learning_rate": 4.626368396001904e-06,
      "loss": 0.0,
      "step": 16150
    },
    {
      "epoch": 7.69157544026654,
      "grad_norm": 6.530219252454117e-05,
      "learning_rate": 4.6168491194669205e-06,
      "loss": 0.0,
      "step": 16160
    },
    {
      "epoch": 7.696335078534031,
      "grad_norm": 0.00011220327724004164,
      "learning_rate": 4.607329842931937e-06,
      "loss": 0.0,
      "step": 16170
    },
    {
      "epoch": 7.701094716801523,
      "grad_norm": 7.468242256436497e-05,
      "learning_rate": 4.597810566396954e-06,
      "loss": 0.0,
      "step": 16180
    },
    {
      "epoch": 7.705854355069015,
      "grad_norm": 0.000108293243101798,
      "learning_rate": 4.588291289861971e-06,
      "loss": 0.0,
      "step": 16190
    },
    {
      "epoch": 7.710613993336507,
      "grad_norm": 5.5593118304386735e-05,
      "learning_rate": 4.578772013326988e-06,
      "loss": 0.0001,
      "step": 16200
    },
    {
      "epoch": 7.715373631603998,
      "grad_norm": 3.132657527923584,
      "learning_rate": 4.569252736792004e-06,
      "loss": 0.0045,
      "step": 16210
    },
    {
      "epoch": 7.720133269871489,
      "grad_norm": 7.478484621969983e-05,
      "learning_rate": 4.559733460257021e-06,
      "loss": 0.0,
      "step": 16220
    },
    {
      "epoch": 7.724892908138981,
      "grad_norm": 0.0027009465266019106,
      "learning_rate": 4.5502141837220375e-06,
      "loss": 0.0,
      "step": 16230
    },
    {
      "epoch": 7.729652546406474,
      "grad_norm": 3.583327270462178e-05,
      "learning_rate": 4.540694907187054e-06,
      "loss": 0.0,
      "step": 16240
    },
    {
      "epoch": 7.734412184673965,
      "grad_norm": 4.430107583175413e-05,
      "learning_rate": 4.531175630652071e-06,
      "loss": 0.0007,
      "step": 16250
    },
    {
      "epoch": 7.739171822941456,
      "grad_norm": 9.939057053998113e-05,
      "learning_rate": 4.521656354117088e-06,
      "loss": 0.0,
      "step": 16260
    },
    {
      "epoch": 7.743931461208948,
      "grad_norm": 4.771065869135782e-05,
      "learning_rate": 4.512137077582104e-06,
      "loss": 0.0,
      "step": 16270
    },
    {
      "epoch": 7.7486910994764395,
      "grad_norm": 6.705194391543046e-05,
      "learning_rate": 4.502617801047121e-06,
      "loss": 0.0,
      "step": 16280
    },
    {
      "epoch": 7.753450737743932,
      "grad_norm": 0.00013277331891003996,
      "learning_rate": 4.493098524512137e-06,
      "loss": 0.0006,
      "step": 16290
    },
    {
      "epoch": 7.758210376011423,
      "grad_norm": 7.170122989919037e-05,
      "learning_rate": 4.483579247977154e-06,
      "loss": 0.0,
      "step": 16300
    },
    {
      "epoch": 7.762970014278915,
      "grad_norm": 7.586848369101062e-05,
      "learning_rate": 4.4740599714421705e-06,
      "loss": 0.0,
      "step": 16310
    },
    {
      "epoch": 7.767729652546406,
      "grad_norm": 8.842993702273816e-05,
      "learning_rate": 4.464540694907187e-06,
      "loss": 0.0,
      "step": 16320
    },
    {
      "epoch": 7.7724892908138985,
      "grad_norm": 0.00017183601448778063,
      "learning_rate": 4.455021418372204e-06,
      "loss": 0.0,
      "step": 16330
    },
    {
      "epoch": 7.77724892908139,
      "grad_norm": 0.0007075993344187737,
      "learning_rate": 4.445502141837221e-06,
      "loss": 0.0,
      "step": 16340
    },
    {
      "epoch": 7.782008567348882,
      "grad_norm": 1.3332611160876695e-05,
      "learning_rate": 4.435982865302238e-06,
      "loss": 0.0,
      "step": 16350
    },
    {
      "epoch": 7.786768205616373,
      "grad_norm": 4.487284240894951e-05,
      "learning_rate": 4.426463588767254e-06,
      "loss": 0.0,
      "step": 16360
    },
    {
      "epoch": 7.791527843883864,
      "grad_norm": 1.150279877037974e-05,
      "learning_rate": 4.416944312232271e-06,
      "loss": 0.0,
      "step": 16370
    },
    {
      "epoch": 7.796287482151357,
      "grad_norm": 0.0003189743438269943,
      "learning_rate": 4.4074250356972875e-06,
      "loss": 0.0,
      "step": 16380
    },
    {
      "epoch": 7.801047120418848,
      "grad_norm": 0.0005286663072183728,
      "learning_rate": 4.397905759162304e-06,
      "loss": 0.0,
      "step": 16390
    },
    {
      "epoch": 7.80580675868634,
      "grad_norm": 0.000113016547402367,
      "learning_rate": 4.388386482627321e-06,
      "loss": 0.0,
      "step": 16400
    },
    {
      "epoch": 7.810566396953831,
      "grad_norm": 0.0022613201290369034,
      "learning_rate": 4.378867206092337e-06,
      "loss": 0.0,
      "step": 16410
    },
    {
      "epoch": 7.815326035221323,
      "grad_norm": 6.806669262005016e-05,
      "learning_rate": 4.369347929557354e-06,
      "loss": 0.0,
      "step": 16420
    },
    {
      "epoch": 7.820085673488815,
      "grad_norm": 3.6908499168930575e-05,
      "learning_rate": 4.359828653022371e-06,
      "loss": 0.0,
      "step": 16430
    },
    {
      "epoch": 7.824845311756307,
      "grad_norm": 1.4316772649181075e-05,
      "learning_rate": 4.350309376487387e-06,
      "loss": 0.0,
      "step": 16440
    },
    {
      "epoch": 7.829604950023798,
      "grad_norm": 0.008372904732823372,
      "learning_rate": 4.340790099952404e-06,
      "loss": 0.0342,
      "step": 16450
    },
    {
      "epoch": 7.83436458829129,
      "grad_norm": 0.00015043978055473417,
      "learning_rate": 4.3312708234174205e-06,
      "loss": 0.0,
      "step": 16460
    },
    {
      "epoch": 7.8391242265587815,
      "grad_norm": 0.00018157566955778748,
      "learning_rate": 4.321751546882437e-06,
      "loss": 0.0009,
      "step": 16470
    },
    {
      "epoch": 7.843883864826273,
      "grad_norm": 4.077492485521361e-05,
      "learning_rate": 4.312232270347454e-06,
      "loss": 0.0001,
      "step": 16480
    },
    {
      "epoch": 7.848643503093765,
      "grad_norm": 0.00017550226766616106,
      "learning_rate": 4.302712993812471e-06,
      "loss": 0.0002,
      "step": 16490
    },
    {
      "epoch": 7.853403141361256,
      "grad_norm": 6.819557165727019e-05,
      "learning_rate": 4.293193717277487e-06,
      "loss": 0.03,
      "step": 16500
    },
    {
      "epoch": 7.858162779628748,
      "grad_norm": 18.345949172973633,
      "learning_rate": 4.283674440742504e-06,
      "loss": 0.0062,
      "step": 16510
    },
    {
      "epoch": 7.86292241789624,
      "grad_norm": 2.644162654876709,
      "learning_rate": 4.274155164207521e-06,
      "loss": 0.0026,
      "step": 16520
    },
    {
      "epoch": 7.867682056163732,
      "grad_norm": 0.00027414914802648127,
      "learning_rate": 4.2646358876725374e-06,
      "loss": 0.0,
      "step": 16530
    },
    {
      "epoch": 7.872441694431223,
      "grad_norm": 0.0006015228573232889,
      "learning_rate": 4.255116611137554e-06,
      "loss": 0.0,
      "step": 16540
    },
    {
      "epoch": 7.877201332698715,
      "grad_norm": 0.0005211519310250878,
      "learning_rate": 4.24559733460257e-06,
      "loss": 0.0,
      "step": 16550
    },
    {
      "epoch": 7.881960970966206,
      "grad_norm": 0.0001944213581737131,
      "learning_rate": 4.236078058067587e-06,
      "loss": 0.0102,
      "step": 16560
    },
    {
      "epoch": 7.8867206092336986,
      "grad_norm": 0.00031550522544421256,
      "learning_rate": 4.226558781532604e-06,
      "loss": 0.0,
      "step": 16570
    },
    {
      "epoch": 7.89148024750119,
      "grad_norm": 0.00012051516387145966,
      "learning_rate": 4.217039504997621e-06,
      "loss": 0.0,
      "step": 16580
    },
    {
      "epoch": 7.896239885768682,
      "grad_norm": 0.00017949726316146553,
      "learning_rate": 4.207520228462637e-06,
      "loss": 0.0074,
      "step": 16590
    },
    {
      "epoch": 7.900999524036173,
      "grad_norm": 0.00032797447056509554,
      "learning_rate": 4.198000951927654e-06,
      "loss": 0.0038,
      "step": 16600
    },
    {
      "epoch": 7.905759162303665,
      "grad_norm": 0.00023767257516738027,
      "learning_rate": 4.18848167539267e-06,
      "loss": 0.0336,
      "step": 16610
    },
    {
      "epoch": 7.910518800571157,
      "grad_norm": 0.0005925876321271062,
      "learning_rate": 4.178962398857687e-06,
      "loss": 0.0,
      "step": 16620
    },
    {
      "epoch": 7.915278438838648,
      "grad_norm": 0.00030341485398821533,
      "learning_rate": 4.169443122322704e-06,
      "loss": 0.0002,
      "step": 16630
    },
    {
      "epoch": 7.92003807710614,
      "grad_norm": 0.00026877617347054183,
      "learning_rate": 4.159923845787721e-06,
      "loss": 0.0,
      "step": 16640
    },
    {
      "epoch": 7.924797715373631,
      "grad_norm": 0.0004672782670240849,
      "learning_rate": 4.150404569252737e-06,
      "loss": 0.0,
      "step": 16650
    },
    {
      "epoch": 7.9295573536411235,
      "grad_norm": 0.007380607537925243,
      "learning_rate": 4.140885292717754e-06,
      "loss": 0.0,
      "step": 16660
    },
    {
      "epoch": 7.934316991908615,
      "grad_norm": 0.0003316941438242793,
      "learning_rate": 4.1313660161827706e-06,
      "loss": 0.0152,
      "step": 16670
    },
    {
      "epoch": 7.939076630176107,
      "grad_norm": 0.00037019577575847507,
      "learning_rate": 4.121846739647787e-06,
      "loss": 0.0,
      "step": 16680
    },
    {
      "epoch": 7.943836268443598,
      "grad_norm": 0.00872121099382639,
      "learning_rate": 4.112327463112803e-06,
      "loss": 0.0042,
      "step": 16690
    },
    {
      "epoch": 7.94859590671109,
      "grad_norm": 0.00025684197316877544,
      "learning_rate": 4.10280818657782e-06,
      "loss": 0.0004,
      "step": 16700
    },
    {
      "epoch": 7.9533555449785815,
      "grad_norm": 0.0008513735956512392,
      "learning_rate": 4.093288910042837e-06,
      "loss": 0.0,
      "step": 16710
    },
    {
      "epoch": 7.958115183246074,
      "grad_norm": 0.0006620986969210207,
      "learning_rate": 4.083769633507854e-06,
      "loss": 0.0,
      "step": 16720
    },
    {
      "epoch": 7.962874821513565,
      "grad_norm": 0.00017102120909839869,
      "learning_rate": 4.074250356972871e-06,
      "loss": 0.0,
      "step": 16730
    },
    {
      "epoch": 7.967634459781056,
      "grad_norm": 0.001056885696016252,
      "learning_rate": 4.064731080437887e-06,
      "loss": 0.0,
      "step": 16740
    },
    {
      "epoch": 7.972394098048548,
      "grad_norm": 0.00013873922580387443,
      "learning_rate": 4.0552118039029035e-06,
      "loss": 0.0,
      "step": 16750
    },
    {
      "epoch": 7.97715373631604,
      "grad_norm": 0.00036839625681750476,
      "learning_rate": 4.04569252736792e-06,
      "loss": 0.0051,
      "step": 16760
    },
    {
      "epoch": 7.981913374583532,
      "grad_norm": 0.00030738976784050465,
      "learning_rate": 4.036173250832937e-06,
      "loss": 0.0,
      "step": 16770
    },
    {
      "epoch": 7.986673012851023,
      "grad_norm": 0.00012099300511181355,
      "learning_rate": 4.026653974297954e-06,
      "loss": 0.0002,
      "step": 16780
    },
    {
      "epoch": 7.991432651118515,
      "grad_norm": 0.0012160209007561207,
      "learning_rate": 4.017134697762971e-06,
      "loss": 0.0,
      "step": 16790
    },
    {
      "epoch": 7.9961922893860065,
      "grad_norm": 0.00016133321332745254,
      "learning_rate": 4.007615421227987e-06,
      "loss": 0.0,
      "step": 16800
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9979166666666667,
      "eval_f1": 0.9887640449438202,
      "eval_loss": 0.019013846293091774,
      "eval_precision": 0.9865470852017937,
      "eval_recall": 0.990990990990991,
      "eval_runtime": 343.3675,
      "eval_samples_per_second": 41.97,
      "eval_steps_per_second": 1.313,
      "step": 16808
    },
    {
      "epoch": 8.000951927653498,
      "grad_norm": 0.00022354687098413706,
      "learning_rate": 3.998096144693004e-06,
      "loss": 0.0,
      "step": 16810
    },
    {
      "epoch": 8.00571156592099,
      "grad_norm": 0.00016747201152611524,
      "learning_rate": 3.9885768681580205e-06,
      "loss": 0.0,
      "step": 16820
    },
    {
      "epoch": 8.010471204188482,
      "grad_norm": 3.11773943901062,
      "learning_rate": 3.9790575916230365e-06,
      "loss": 0.0106,
      "step": 16830
    },
    {
      "epoch": 8.015230842455974,
      "grad_norm": 0.00031721495906822383,
      "learning_rate": 3.969538315088053e-06,
      "loss": 0.0,
      "step": 16840
    },
    {
      "epoch": 8.019990480723465,
      "grad_norm": 0.0005198026774451137,
      "learning_rate": 3.96001903855307e-06,
      "loss": 0.0,
      "step": 16850
    },
    {
      "epoch": 8.024750118990957,
      "grad_norm": 0.0001108332653529942,
      "learning_rate": 3.950499762018087e-06,
      "loss": 0.0017,
      "step": 16860
    },
    {
      "epoch": 8.029509757258449,
      "grad_norm": 0.00010707785259000957,
      "learning_rate": 3.940980485483104e-06,
      "loss": 0.0156,
      "step": 16870
    },
    {
      "epoch": 8.03426939552594,
      "grad_norm": 0.00012987077934667468,
      "learning_rate": 3.93146120894812e-06,
      "loss": 0.0001,
      "step": 16880
    },
    {
      "epoch": 8.039029033793431,
      "grad_norm": 0.0138235529884696,
      "learning_rate": 3.921941932413137e-06,
      "loss": 0.0,
      "step": 16890
    },
    {
      "epoch": 8.043788672060924,
      "grad_norm": 0.00036346749402582645,
      "learning_rate": 3.9124226558781535e-06,
      "loss": 0.0,
      "step": 16900
    },
    {
      "epoch": 8.048548310328416,
      "grad_norm": 0.0005467796581797302,
      "learning_rate": 3.90290337934317e-06,
      "loss": 0.0,
      "step": 16910
    },
    {
      "epoch": 8.053307948595906,
      "grad_norm": 0.000255894468864426,
      "learning_rate": 3.893384102808187e-06,
      "loss": 0.0,
      "step": 16920
    },
    {
      "epoch": 8.058067586863398,
      "grad_norm": 0.00016566706472076476,
      "learning_rate": 3.883864826273204e-06,
      "loss": 0.0,
      "step": 16930
    },
    {
      "epoch": 8.06282722513089,
      "grad_norm": 0.00025504204677417874,
      "learning_rate": 3.874345549738221e-06,
      "loss": 0.0001,
      "step": 16940
    },
    {
      "epoch": 8.067586863398382,
      "grad_norm": 0.00015874773089308292,
      "learning_rate": 3.864826273203237e-06,
      "loss": 0.0108,
      "step": 16950
    },
    {
      "epoch": 8.072346501665873,
      "grad_norm": 0.04265957698225975,
      "learning_rate": 3.855306996668254e-06,
      "loss": 0.0,
      "step": 16960
    },
    {
      "epoch": 8.077106139933365,
      "grad_norm": 0.00010943060624413192,
      "learning_rate": 3.84578772013327e-06,
      "loss": 0.0,
      "step": 16970
    },
    {
      "epoch": 8.081865778200857,
      "grad_norm": 0.00020919412781950086,
      "learning_rate": 3.8362684435982865e-06,
      "loss": 0.0,
      "step": 16980
    },
    {
      "epoch": 8.086625416468348,
      "grad_norm": 4.7358476876979694e-05,
      "learning_rate": 3.826749167063303e-06,
      "loss": 0.0001,
      "step": 16990
    },
    {
      "epoch": 8.09138505473584,
      "grad_norm": 0.0008564157760702074,
      "learning_rate": 3.81722989052832e-06,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 8.096144693003332,
      "grad_norm": 0.0001221707061631605,
      "learning_rate": 3.8077106139933365e-06,
      "loss": 0.0087,
      "step": 17010
    },
    {
      "epoch": 8.100904331270824,
      "grad_norm": 0.19168667495250702,
      "learning_rate": 3.7981913374583534e-06,
      "loss": 0.0,
      "step": 17020
    },
    {
      "epoch": 8.105663969538314,
      "grad_norm": 0.00015867377805989236,
      "learning_rate": 3.7886720609233702e-06,
      "loss": 0.0,
      "step": 17030
    },
    {
      "epoch": 8.110423607805807,
      "grad_norm": 0.003524156054481864,
      "learning_rate": 3.779152784388387e-06,
      "loss": 0.0,
      "step": 17040
    },
    {
      "epoch": 8.115183246073299,
      "grad_norm": 0.00012490608787629753,
      "learning_rate": 3.7696335078534035e-06,
      "loss": 0.0006,
      "step": 17050
    },
    {
      "epoch": 8.11994288434079,
      "grad_norm": 0.0003877924755215645,
      "learning_rate": 3.7601142313184203e-06,
      "loss": 0.0226,
      "step": 17060
    },
    {
      "epoch": 8.124702522608281,
      "grad_norm": 0.2301194667816162,
      "learning_rate": 3.750594954783437e-06,
      "loss": 0.0002,
      "step": 17070
    },
    {
      "epoch": 8.129462160875773,
      "grad_norm": 0.0002520607376936823,
      "learning_rate": 3.7410756782484535e-06,
      "loss": 0.0,
      "step": 17080
    },
    {
      "epoch": 8.134221799143265,
      "grad_norm": 0.4331137239933014,
      "learning_rate": 3.7315564017134704e-06,
      "loss": 0.0001,
      "step": 17090
    },
    {
      "epoch": 8.138981437410758,
      "grad_norm": 0.0024763986002653837,
      "learning_rate": 3.7220371251784864e-06,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 8.143741075678248,
      "grad_norm": 0.0004565629060380161,
      "learning_rate": 3.712517848643503e-06,
      "loss": 0.0,
      "step": 17110
    },
    {
      "epoch": 8.14850071394574,
      "grad_norm": 0.00023263022012542933,
      "learning_rate": 3.70299857210852e-06,
      "loss": 0.0,
      "step": 17120
    },
    {
      "epoch": 8.153260352213232,
      "grad_norm": 0.00013233136269263923,
      "learning_rate": 3.6934792955735364e-06,
      "loss": 0.0,
      "step": 17130
    },
    {
      "epoch": 8.158019990480723,
      "grad_norm": 0.00014810853463131934,
      "learning_rate": 3.6839600190385533e-06,
      "loss": 0.0101,
      "step": 17140
    },
    {
      "epoch": 8.162779628748215,
      "grad_norm": 0.0008739873883314431,
      "learning_rate": 3.67444074250357e-06,
      "loss": 0.0002,
      "step": 17150
    },
    {
      "epoch": 8.167539267015707,
      "grad_norm": 0.0025011813268065453,
      "learning_rate": 3.6649214659685865e-06,
      "loss": 0.0,
      "step": 17160
    },
    {
      "epoch": 8.1722989052832,
      "grad_norm": 0.00010685263987397775,
      "learning_rate": 3.6554021894336033e-06,
      "loss": 0.0,
      "step": 17170
    },
    {
      "epoch": 8.17705854355069,
      "grad_norm": 0.016184350475668907,
      "learning_rate": 3.64588291289862e-06,
      "loss": 0.0,
      "step": 17180
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 0.00028758065309375525,
      "learning_rate": 3.6363636363636366e-06,
      "loss": 0.0,
      "step": 17190
    },
    {
      "epoch": 8.186577820085674,
      "grad_norm": 0.0006413193186745048,
      "learning_rate": 3.6268443598286534e-06,
      "loss": 0.0,
      "step": 17200
    },
    {
      "epoch": 8.191337458353166,
      "grad_norm": 0.0008433585171587765,
      "learning_rate": 3.6173250832936703e-06,
      "loss": 0.0,
      "step": 17210
    },
    {
      "epoch": 8.196097096620656,
      "grad_norm": 0.00043890593224205077,
      "learning_rate": 3.6078058067586867e-06,
      "loss": 0.0,
      "step": 17220
    },
    {
      "epoch": 8.200856734888148,
      "grad_norm": 0.0001564129051985219,
      "learning_rate": 3.5982865302237035e-06,
      "loss": 0.0,
      "step": 17230
    },
    {
      "epoch": 8.20561637315564,
      "grad_norm": 0.00018325011478736997,
      "learning_rate": 3.58876725368872e-06,
      "loss": 0.0,
      "step": 17240
    },
    {
      "epoch": 8.210376011423131,
      "grad_norm": 0.00018230944988317788,
      "learning_rate": 3.5792479771537363e-06,
      "loss": 0.0,
      "step": 17250
    },
    {
      "epoch": 8.215135649690623,
      "grad_norm": 0.0014734917785972357,
      "learning_rate": 3.569728700618753e-06,
      "loss": 0.0072,
      "step": 17260
    },
    {
      "epoch": 8.219895287958115,
      "grad_norm": 0.0006099960883148015,
      "learning_rate": 3.56020942408377e-06,
      "loss": 0.0,
      "step": 17270
    },
    {
      "epoch": 8.224654926225607,
      "grad_norm": 0.003905910300090909,
      "learning_rate": 3.5506901475487864e-06,
      "loss": 0.0,
      "step": 17280
    },
    {
      "epoch": 8.229414564493098,
      "grad_norm": 0.0009933834662660956,
      "learning_rate": 3.5411708710138032e-06,
      "loss": 0.0,
      "step": 17290
    },
    {
      "epoch": 8.23417420276059,
      "grad_norm": 0.00018811198242474347,
      "learning_rate": 3.53165159447882e-06,
      "loss": 0.0,
      "step": 17300
    },
    {
      "epoch": 8.238933841028082,
      "grad_norm": 0.001311602769419551,
      "learning_rate": 3.5221323179438365e-06,
      "loss": 0.0,
      "step": 17310
    },
    {
      "epoch": 8.243693479295574,
      "grad_norm": 0.019995642825961113,
      "learning_rate": 3.5126130414088533e-06,
      "loss": 0.0,
      "step": 17320
    },
    {
      "epoch": 8.248453117563065,
      "grad_norm": 0.0003118096210528165,
      "learning_rate": 3.50309376487387e-06,
      "loss": 0.0,
      "step": 17330
    },
    {
      "epoch": 8.253212755830557,
      "grad_norm": 0.0001754957775119692,
      "learning_rate": 3.4935744883388865e-06,
      "loss": 0.0,
      "step": 17340
    },
    {
      "epoch": 8.257972394098049,
      "grad_norm": 0.00040922078187577426,
      "learning_rate": 3.4840552118039034e-06,
      "loss": 0.0,
      "step": 17350
    },
    {
      "epoch": 8.262732032365541,
      "grad_norm": 0.003045588731765747,
      "learning_rate": 3.47453593526892e-06,
      "loss": 0.0,
      "step": 17360
    },
    {
      "epoch": 8.267491670633031,
      "grad_norm": 0.0031066848896443844,
      "learning_rate": 3.4650166587339366e-06,
      "loss": 0.0009,
      "step": 17370
    },
    {
      "epoch": 8.272251308900524,
      "grad_norm": 0.00016599528316874057,
      "learning_rate": 3.455497382198953e-06,
      "loss": 0.0,
      "step": 17380
    },
    {
      "epoch": 8.277010947168016,
      "grad_norm": 0.0015018476406112313,
      "learning_rate": 3.4459781056639694e-06,
      "loss": 0.0,
      "step": 17390
    },
    {
      "epoch": 8.281770585435506,
      "grad_norm": 0.0013448131503537297,
      "learning_rate": 3.4364588291289863e-06,
      "loss": 0.0,
      "step": 17400
    },
    {
      "epoch": 8.286530223702998,
      "grad_norm": 0.00011341071513015777,
      "learning_rate": 3.426939552594003e-06,
      "loss": 0.0,
      "step": 17410
    },
    {
      "epoch": 8.29128986197049,
      "grad_norm": 0.000549584103282541,
      "learning_rate": 3.4174202760590195e-06,
      "loss": 0.0,
      "step": 17420
    },
    {
      "epoch": 8.296049500237983,
      "grad_norm": 9.02884712559171e-05,
      "learning_rate": 3.4079009995240363e-06,
      "loss": 0.0,
      "step": 17430
    },
    {
      "epoch": 8.300809138505473,
      "grad_norm": 3.6452194763114676e-05,
      "learning_rate": 3.398381722989053e-06,
      "loss": 0.0,
      "step": 17440
    },
    {
      "epoch": 8.305568776772965,
      "grad_norm": 0.00021478330017998815,
      "learning_rate": 3.38886244645407e-06,
      "loss": 0.0,
      "step": 17450
    },
    {
      "epoch": 8.310328415040457,
      "grad_norm": 1.7001783847808838,
      "learning_rate": 3.3793431699190864e-06,
      "loss": 0.0039,
      "step": 17460
    },
    {
      "epoch": 8.31508805330795,
      "grad_norm": 0.00010701741121010855,
      "learning_rate": 3.3698238933841033e-06,
      "loss": 0.0,
      "step": 17470
    },
    {
      "epoch": 8.31984769157544,
      "grad_norm": 7.173162885010242e-05,
      "learning_rate": 3.36030461684912e-06,
      "loss": 0.0,
      "step": 17480
    },
    {
      "epoch": 8.324607329842932,
      "grad_norm": 4.458603143575601e-05,
      "learning_rate": 3.3507853403141365e-06,
      "loss": 0.0,
      "step": 17490
    },
    {
      "epoch": 8.329366968110424,
      "grad_norm": 0.0004410943074617535,
      "learning_rate": 3.3412660637791533e-06,
      "loss": 0.0,
      "step": 17500
    },
    {
      "epoch": 8.334126606377914,
      "grad_norm": 0.0002007242146646604,
      "learning_rate": 3.3317467872441693e-06,
      "loss": 0.0,
      "step": 17510
    },
    {
      "epoch": 8.338886244645407,
      "grad_norm": 8.4629726188723e-05,
      "learning_rate": 3.322227510709186e-06,
      "loss": 0.0109,
      "step": 17520
    },
    {
      "epoch": 8.343645882912899,
      "grad_norm": 4.197990710963495e-05,
      "learning_rate": 3.312708234174203e-06,
      "loss": 0.0002,
      "step": 17530
    },
    {
      "epoch": 8.348405521180391,
      "grad_norm": 0.0005844458937644958,
      "learning_rate": 3.3031889576392194e-06,
      "loss": 0.0008,
      "step": 17540
    },
    {
      "epoch": 8.353165159447881,
      "grad_norm": 0.0004391579714138061,
      "learning_rate": 3.2936696811042362e-06,
      "loss": 0.0,
      "step": 17550
    },
    {
      "epoch": 8.357924797715373,
      "grad_norm": 0.0014971859054639935,
      "learning_rate": 3.284150404569253e-06,
      "loss": 0.0,
      "step": 17560
    },
    {
      "epoch": 8.362684435982866,
      "grad_norm": 0.000157311704242602,
      "learning_rate": 3.2746311280342695e-06,
      "loss": 0.0095,
      "step": 17570
    },
    {
      "epoch": 8.367444074250358,
      "grad_norm": 0.00011194021499250084,
      "learning_rate": 3.2651118514992863e-06,
      "loss": 0.0,
      "step": 17580
    },
    {
      "epoch": 8.372203712517848,
      "grad_norm": 0.0008065823349170387,
      "learning_rate": 3.255592574964303e-06,
      "loss": 0.0,
      "step": 17590
    },
    {
      "epoch": 8.37696335078534,
      "grad_norm": 0.0003396984830033034,
      "learning_rate": 3.2460732984293196e-06,
      "loss": 0.0,
      "step": 17600
    },
    {
      "epoch": 8.381722989052832,
      "grad_norm": 0.0034809960052371025,
      "learning_rate": 3.2365540218943364e-06,
      "loss": 0.0,
      "step": 17610
    },
    {
      "epoch": 8.386482627320323,
      "grad_norm": 0.0002401254023425281,
      "learning_rate": 3.2270347453593532e-06,
      "loss": 0.0,
      "step": 17620
    },
    {
      "epoch": 8.391242265587815,
      "grad_norm": 0.00014004527474753559,
      "learning_rate": 3.2175154688243696e-06,
      "loss": 0.0016,
      "step": 17630
    },
    {
      "epoch": 8.396001903855307,
      "grad_norm": 0.004966470878571272,
      "learning_rate": 3.2079961922893865e-06,
      "loss": 0.0,
      "step": 17640
    },
    {
      "epoch": 8.4007615421228,
      "grad_norm": 9.962507465388626e-05,
      "learning_rate": 3.198476915754403e-06,
      "loss": 0.0,
      "step": 17650
    },
    {
      "epoch": 8.40552118039029,
      "grad_norm": 0.000168924467288889,
      "learning_rate": 3.1889576392194193e-06,
      "loss": 0.0,
      "step": 17660
    },
    {
      "epoch": 8.410280818657782,
      "grad_norm": 0.0001595756330061704,
      "learning_rate": 3.179438362684436e-06,
      "loss": 0.0013,
      "step": 17670
    },
    {
      "epoch": 8.415040456925274,
      "grad_norm": 0.0001838827010942623,
      "learning_rate": 3.169919086149453e-06,
      "loss": 0.0,
      "step": 17680
    },
    {
      "epoch": 8.419800095192766,
      "grad_norm": 0.0002998331910930574,
      "learning_rate": 3.1603998096144694e-06,
      "loss": 0.0,
      "step": 17690
    },
    {
      "epoch": 8.424559733460256,
      "grad_norm": 0.001818688353523612,
      "learning_rate": 3.150880533079486e-06,
      "loss": 0.0,
      "step": 17700
    },
    {
      "epoch": 8.429319371727749,
      "grad_norm": 0.00043793575605377555,
      "learning_rate": 3.141361256544503e-06,
      "loss": 0.0,
      "step": 17710
    },
    {
      "epoch": 8.43407900999524,
      "grad_norm": 0.0008396183256991208,
      "learning_rate": 3.1318419800095194e-06,
      "loss": 0.0,
      "step": 17720
    },
    {
      "epoch": 8.438838648262733,
      "grad_norm": 0.0002105720341205597,
      "learning_rate": 3.1223227034745363e-06,
      "loss": 0.0,
      "step": 17730
    },
    {
      "epoch": 8.443598286530223,
      "grad_norm": 0.012254971079528332,
      "learning_rate": 3.112803426939553e-06,
      "loss": 0.0,
      "step": 17740
    },
    {
      "epoch": 8.448357924797715,
      "grad_norm": 0.0016702518332749605,
      "learning_rate": 3.1032841504045695e-06,
      "loss": 0.0,
      "step": 17750
    },
    {
      "epoch": 8.453117563065208,
      "grad_norm": 9.778823732631281e-05,
      "learning_rate": 3.0937648738695863e-06,
      "loss": 0.0031,
      "step": 17760
    },
    {
      "epoch": 8.457877201332698,
      "grad_norm": 0.0006038609426468611,
      "learning_rate": 3.084245597334603e-06,
      "loss": 0.0,
      "step": 17770
    },
    {
      "epoch": 8.46263683960019,
      "grad_norm": 0.0005203665350563824,
      "learning_rate": 3.0747263207996196e-06,
      "loss": 0.0079,
      "step": 17780
    },
    {
      "epoch": 8.467396477867682,
      "grad_norm": 0.002277204766869545,
      "learning_rate": 3.065207044264636e-06,
      "loss": 0.0,
      "step": 17790
    },
    {
      "epoch": 8.472156116135174,
      "grad_norm": 0.017380163073539734,
      "learning_rate": 3.0556877677296524e-06,
      "loss": 0.0,
      "step": 17800
    },
    {
      "epoch": 8.476915754402665,
      "grad_norm": 0.00015951041132211685,
      "learning_rate": 3.0461684911946692e-06,
      "loss": 0.0,
      "step": 17810
    },
    {
      "epoch": 8.481675392670157,
      "grad_norm": 0.0018450275529175997,
      "learning_rate": 3.036649214659686e-06,
      "loss": 0.0,
      "step": 17820
    },
    {
      "epoch": 8.486435030937649,
      "grad_norm": 0.0001222032296936959,
      "learning_rate": 3.0271299381247025e-06,
      "loss": 0.0,
      "step": 17830
    },
    {
      "epoch": 8.491194669205141,
      "grad_norm": 0.001673990860581398,
      "learning_rate": 3.0176106615897193e-06,
      "loss": 0.0,
      "step": 17840
    },
    {
      "epoch": 8.495954307472632,
      "grad_norm": 0.00015362144040409476,
      "learning_rate": 3.008091385054736e-06,
      "loss": 0.0,
      "step": 17850
    },
    {
      "epoch": 8.500713945740124,
      "grad_norm": 0.000402337231207639,
      "learning_rate": 2.998572108519753e-06,
      "loss": 0.0036,
      "step": 17860
    },
    {
      "epoch": 8.505473584007616,
      "grad_norm": 0.00013300236605573446,
      "learning_rate": 2.9890528319847694e-06,
      "loss": 0.0,
      "step": 17870
    },
    {
      "epoch": 8.510233222275108,
      "grad_norm": 8.680006430950016e-05,
      "learning_rate": 2.9795335554497862e-06,
      "loss": 0.0,
      "step": 17880
    },
    {
      "epoch": 8.514992860542598,
      "grad_norm": 0.2874428927898407,
      "learning_rate": 2.970014278914803e-06,
      "loss": 0.0004,
      "step": 17890
    },
    {
      "epoch": 8.51975249881009,
      "grad_norm": 9.76451046881266e-05,
      "learning_rate": 2.9604950023798195e-06,
      "loss": 0.0,
      "step": 17900
    },
    {
      "epoch": 8.524512137077583,
      "grad_norm": 0.00024347916769329458,
      "learning_rate": 2.9509757258448363e-06,
      "loss": 0.0,
      "step": 17910
    },
    {
      "epoch": 8.529271775345073,
      "grad_norm": 6.75189439789392e-05,
      "learning_rate": 2.941456449309853e-06,
      "loss": 0.0,
      "step": 17920
    },
    {
      "epoch": 8.534031413612565,
      "grad_norm": 0.00010116248449776322,
      "learning_rate": 2.931937172774869e-06,
      "loss": 0.0028,
      "step": 17930
    },
    {
      "epoch": 8.538791051880057,
      "grad_norm": 8.953250653576106e-05,
      "learning_rate": 2.922417896239886e-06,
      "loss": 0.0001,
      "step": 17940
    },
    {
      "epoch": 8.54355069014755,
      "grad_norm": 8.306666131829843e-05,
      "learning_rate": 2.9128986197049024e-06,
      "loss": 0.0,
      "step": 17950
    },
    {
      "epoch": 8.54831032841504,
      "grad_norm": 0.00025767876650206745,
      "learning_rate": 2.903379343169919e-06,
      "loss": 0.0004,
      "step": 17960
    },
    {
      "epoch": 8.553069966682532,
      "grad_norm": 0.00013909325934946537,
      "learning_rate": 2.893860066634936e-06,
      "loss": 0.0166,
      "step": 17970
    },
    {
      "epoch": 8.557829604950024,
      "grad_norm": 0.000314319011522457,
      "learning_rate": 2.8843407900999524e-06,
      "loss": 0.0,
      "step": 17980
    },
    {
      "epoch": 8.562589243217516,
      "grad_norm": 0.0018001481657847762,
      "learning_rate": 2.8748215135649693e-06,
      "loss": 0.0,
      "step": 17990
    },
    {
      "epoch": 8.567348881485007,
      "grad_norm": 0.008160506375133991,
      "learning_rate": 2.865302237029986e-06,
      "loss": 0.0,
      "step": 18000
    },
    {
      "epoch": 8.572108519752499,
      "grad_norm": 0.00047576750512234867,
      "learning_rate": 2.8557829604950025e-06,
      "loss": 0.0,
      "step": 18010
    },
    {
      "epoch": 8.576868158019991,
      "grad_norm": 0.0012279513757675886,
      "learning_rate": 2.8462636839600194e-06,
      "loss": 0.0,
      "step": 18020
    },
    {
      "epoch": 8.581627796287481,
      "grad_norm": 0.00020765885710716248,
      "learning_rate": 2.836744407425036e-06,
      "loss": 0.0,
      "step": 18030
    },
    {
      "epoch": 8.586387434554974,
      "grad_norm": 0.00018975400598719716,
      "learning_rate": 2.8272251308900526e-06,
      "loss": 0.0,
      "step": 18040
    },
    {
      "epoch": 8.591147072822466,
      "grad_norm": 0.00581738818436861,
      "learning_rate": 2.8177058543550694e-06,
      "loss": 0.0,
      "step": 18050
    },
    {
      "epoch": 8.595906711089958,
      "grad_norm": 0.00014153473603073508,
      "learning_rate": 2.808186577820086e-06,
      "loss": 0.0,
      "step": 18060
    },
    {
      "epoch": 8.600666349357448,
      "grad_norm": 0.0001713394740363583,
      "learning_rate": 2.7986673012851022e-06,
      "loss": 0.0,
      "step": 18070
    },
    {
      "epoch": 8.60542598762494,
      "grad_norm": 0.00030834911740384996,
      "learning_rate": 2.789148024750119e-06,
      "loss": 0.0,
      "step": 18080
    },
    {
      "epoch": 8.610185625892433,
      "grad_norm": 9.263952233595774e-05,
      "learning_rate": 2.779628748215136e-06,
      "loss": 0.0,
      "step": 18090
    },
    {
      "epoch": 8.614945264159925,
      "grad_norm": 0.00011276370059931651,
      "learning_rate": 2.7701094716801523e-06,
      "loss": 0.0,
      "step": 18100
    },
    {
      "epoch": 8.619704902427415,
      "grad_norm": 0.000282545224763453,
      "learning_rate": 2.760590195145169e-06,
      "loss": 0.0,
      "step": 18110
    },
    {
      "epoch": 8.624464540694907,
      "grad_norm": 0.00163622060790658,
      "learning_rate": 2.751070918610186e-06,
      "loss": 0.0,
      "step": 18120
    },
    {
      "epoch": 8.6292241789624,
      "grad_norm": 0.0008024148410186172,
      "learning_rate": 2.7415516420752024e-06,
      "loss": 0.0002,
      "step": 18130
    },
    {
      "epoch": 8.63398381722989,
      "grad_norm": 9.776859951671213e-05,
      "learning_rate": 2.7320323655402192e-06,
      "loss": 0.018,
      "step": 18140
    },
    {
      "epoch": 8.638743455497382,
      "grad_norm": 0.00017001763626467437,
      "learning_rate": 2.722513089005236e-06,
      "loss": 0.0,
      "step": 18150
    },
    {
      "epoch": 8.643503093764874,
      "grad_norm": 0.0002407297579338774,
      "learning_rate": 2.7129938124702525e-06,
      "loss": 0.0,
      "step": 18160
    },
    {
      "epoch": 8.648262732032366,
      "grad_norm": 0.0018507420318201184,
      "learning_rate": 2.7034745359352693e-06,
      "loss": 0.0,
      "step": 18170
    },
    {
      "epoch": 8.653022370299857,
      "grad_norm": 9.246334957424551e-05,
      "learning_rate": 2.693955259400286e-06,
      "loss": 0.0,
      "step": 18180
    },
    {
      "epoch": 8.657782008567349,
      "grad_norm": 8.13831138657406e-05,
      "learning_rate": 2.6844359828653026e-06,
      "loss": 0.0,
      "step": 18190
    },
    {
      "epoch": 8.66254164683484,
      "grad_norm": 0.0001808771921787411,
      "learning_rate": 2.674916706330319e-06,
      "loss": 0.0,
      "step": 18200
    },
    {
      "epoch": 8.667301285102333,
      "grad_norm": 8.293248538393527e-05,
      "learning_rate": 2.6653974297953354e-06,
      "loss": 0.0,
      "step": 18210
    },
    {
      "epoch": 8.672060923369823,
      "grad_norm": 0.00023253692779690027,
      "learning_rate": 2.655878153260352e-06,
      "loss": 0.0,
      "step": 18220
    },
    {
      "epoch": 8.676820561637316,
      "grad_norm": 0.0007299062563106418,
      "learning_rate": 2.646358876725369e-06,
      "loss": 0.0032,
      "step": 18230
    },
    {
      "epoch": 8.681580199904808,
      "grad_norm": 0.0004470749117899686,
      "learning_rate": 2.6368396001903854e-06,
      "loss": 0.0,
      "step": 18240
    },
    {
      "epoch": 8.686339838172298,
      "grad_norm": 0.0003319669922348112,
      "learning_rate": 2.6273203236554023e-06,
      "loss": 0.0,
      "step": 18250
    },
    {
      "epoch": 8.69109947643979,
      "grad_norm": 0.0003070787061005831,
      "learning_rate": 2.617801047120419e-06,
      "loss": 0.0,
      "step": 18260
    },
    {
      "epoch": 8.695859114707282,
      "grad_norm": 0.0009634137386456132,
      "learning_rate": 2.608281770585436e-06,
      "loss": 0.0,
      "step": 18270
    },
    {
      "epoch": 8.700618752974774,
      "grad_norm": 6.318671512417495e-05,
      "learning_rate": 2.5987624940504524e-06,
      "loss": 0.0,
      "step": 18280
    },
    {
      "epoch": 8.705378391242265,
      "grad_norm": 0.0001586791331646964,
      "learning_rate": 2.589243217515469e-06,
      "loss": 0.0,
      "step": 18290
    },
    {
      "epoch": 8.710138029509757,
      "grad_norm": 6.856519030407071e-05,
      "learning_rate": 2.579723940980486e-06,
      "loss": 0.0,
      "step": 18300
    },
    {
      "epoch": 8.71489766777725,
      "grad_norm": 6.327311712084338e-05,
      "learning_rate": 2.5702046644455024e-06,
      "loss": 0.0,
      "step": 18310
    },
    {
      "epoch": 8.719657306044741,
      "grad_norm": 0.0006279016961343586,
      "learning_rate": 2.5606853879105193e-06,
      "loss": 0.0,
      "step": 18320
    },
    {
      "epoch": 8.724416944312232,
      "grad_norm": 0.020524611696600914,
      "learning_rate": 2.551166111375536e-06,
      "loss": 0.0,
      "step": 18330
    },
    {
      "epoch": 8.729176582579724,
      "grad_norm": 0.00021309596195351332,
      "learning_rate": 2.541646834840552e-06,
      "loss": 0.0011,
      "step": 18340
    },
    {
      "epoch": 8.733936220847216,
      "grad_norm": 3.33627249347046e-05,
      "learning_rate": 2.532127558305569e-06,
      "loss": 0.0,
      "step": 18350
    },
    {
      "epoch": 8.738695859114706,
      "grad_norm": 0.00020246233907528222,
      "learning_rate": 2.5226082817705853e-06,
      "loss": 0.0,
      "step": 18360
    },
    {
      "epoch": 8.743455497382199,
      "grad_norm": 9.080732706934214e-05,
      "learning_rate": 2.513089005235602e-06,
      "loss": 0.0,
      "step": 18370
    },
    {
      "epoch": 8.74821513564969,
      "grad_norm": 0.00011700943286996335,
      "learning_rate": 2.503569728700619e-06,
      "loss": 0.0072,
      "step": 18380
    },
    {
      "epoch": 8.752974773917183,
      "grad_norm": 0.00012841761054005474,
      "learning_rate": 2.4940504521656354e-06,
      "loss": 0.0,
      "step": 18390
    },
    {
      "epoch": 8.757734412184673,
      "grad_norm": 9.126231452682987e-05,
      "learning_rate": 2.4845311756306522e-06,
      "loss": 0.0006,
      "step": 18400
    },
    {
      "epoch": 8.762494050452165,
      "grad_norm": 0.0015989616513252258,
      "learning_rate": 2.475011899095669e-06,
      "loss": 0.0,
      "step": 18410
    },
    {
      "epoch": 8.767253688719657,
      "grad_norm": 0.0005730471457354724,
      "learning_rate": 2.4654926225606855e-06,
      "loss": 0.0,
      "step": 18420
    },
    {
      "epoch": 8.77201332698715,
      "grad_norm": 8.760218042880297e-05,
      "learning_rate": 2.4559733460257023e-06,
      "loss": 0.0,
      "step": 18430
    },
    {
      "epoch": 8.77677296525464,
      "grad_norm": 5.5555417930008844e-05,
      "learning_rate": 2.4464540694907187e-06,
      "loss": 0.0,
      "step": 18440
    },
    {
      "epoch": 8.781532603522132,
      "grad_norm": 0.000386224826797843,
      "learning_rate": 2.4369347929557356e-06,
      "loss": 0.0,
      "step": 18450
    },
    {
      "epoch": 8.786292241789624,
      "grad_norm": 4.519430149230175e-05,
      "learning_rate": 2.4274155164207524e-06,
      "loss": 0.0,
      "step": 18460
    },
    {
      "epoch": 8.791051880057116,
      "grad_norm": 5.185283225728199e-05,
      "learning_rate": 2.417896239885769e-06,
      "loss": 0.0,
      "step": 18470
    },
    {
      "epoch": 8.795811518324607,
      "grad_norm": 0.001577639952301979,
      "learning_rate": 2.4083769633507856e-06,
      "loss": 0.0004,
      "step": 18480
    },
    {
      "epoch": 8.800571156592099,
      "grad_norm": 0.00010501305951038375,
      "learning_rate": 2.3988576868158025e-06,
      "loss": 0.0,
      "step": 18490
    },
    {
      "epoch": 8.805330794859591,
      "grad_norm": 0.00011219448788324371,
      "learning_rate": 2.389338410280819e-06,
      "loss": 0.0,
      "step": 18500
    },
    {
      "epoch": 8.810090433127082,
      "grad_norm": 0.0003324052086099982,
      "learning_rate": 2.3798191337458353e-06,
      "loss": 0.0,
      "step": 18510
    },
    {
      "epoch": 8.814850071394574,
      "grad_norm": 0.00110459397546947,
      "learning_rate": 2.370299857210852e-06,
      "loss": 0.0,
      "step": 18520
    },
    {
      "epoch": 8.819609709662066,
      "grad_norm": 8.094513032119721e-05,
      "learning_rate": 2.360780580675869e-06,
      "loss": 0.0,
      "step": 18530
    },
    {
      "epoch": 8.824369347929558,
      "grad_norm": 0.0027977158315479755,
      "learning_rate": 2.3512613041408854e-06,
      "loss": 0.0,
      "step": 18540
    },
    {
      "epoch": 8.829128986197048,
      "grad_norm": 5.627873179037124e-05,
      "learning_rate": 2.341742027605902e-06,
      "loss": 0.0002,
      "step": 18550
    },
    {
      "epoch": 8.83388862446454,
      "grad_norm": 0.0009366725571453571,
      "learning_rate": 2.332222751070919e-06,
      "loss": 0.0,
      "step": 18560
    },
    {
      "epoch": 8.838648262732033,
      "grad_norm": 7.722017471678555e-05,
      "learning_rate": 2.3227034745359354e-06,
      "loss": 0.0004,
      "step": 18570
    },
    {
      "epoch": 8.843407900999525,
      "grad_norm": 5.540741767617874e-05,
      "learning_rate": 2.313184198000952e-06,
      "loss": 0.0006,
      "step": 18580
    },
    {
      "epoch": 8.848167539267015,
      "grad_norm": 0.0001386486110277474,
      "learning_rate": 2.3036649214659687e-06,
      "loss": 0.0,
      "step": 18590
    },
    {
      "epoch": 8.852927177534507,
      "grad_norm": 5.223774496698752e-05,
      "learning_rate": 2.2941456449309855e-06,
      "loss": 0.0,
      "step": 18600
    },
    {
      "epoch": 8.857686815802,
      "grad_norm": 0.00182649539783597,
      "learning_rate": 2.284626368396002e-06,
      "loss": 0.0001,
      "step": 18610
    },
    {
      "epoch": 8.862446454069492,
      "grad_norm": 4.997784708393738e-05,
      "learning_rate": 2.2751070918610188e-06,
      "loss": 0.0004,
      "step": 18620
    },
    {
      "epoch": 8.867206092336982,
      "grad_norm": 0.00016742234583944082,
      "learning_rate": 2.2655878153260356e-06,
      "loss": 0.0,
      "step": 18630
    },
    {
      "epoch": 8.871965730604474,
      "grad_norm": 0.00010256782843498513,
      "learning_rate": 2.256068538791052e-06,
      "loss": 0.0,
      "step": 18640
    },
    {
      "epoch": 8.876725368871966,
      "grad_norm": 0.0008118758560158312,
      "learning_rate": 2.2465492622560684e-06,
      "loss": 0.0,
      "step": 18650
    },
    {
      "epoch": 8.881485007139457,
      "grad_norm": 5.900354517507367e-05,
      "learning_rate": 2.2370299857210852e-06,
      "loss": 0.0109,
      "step": 18660
    },
    {
      "epoch": 8.886244645406949,
      "grad_norm": 0.0005001336103305221,
      "learning_rate": 2.227510709186102e-06,
      "loss": 0.0,
      "step": 18670
    },
    {
      "epoch": 8.891004283674441,
      "grad_norm": 0.00014863251999486238,
      "learning_rate": 2.217991432651119e-06,
      "loss": 0.0,
      "step": 18680
    },
    {
      "epoch": 8.895763921941933,
      "grad_norm": 4.838768290937878e-05,
      "learning_rate": 2.2084721561161353e-06,
      "loss": 0.0001,
      "step": 18690
    },
    {
      "epoch": 8.900523560209423,
      "grad_norm": 8.12710786703974e-05,
      "learning_rate": 2.198952879581152e-06,
      "loss": 0.0,
      "step": 18700
    },
    {
      "epoch": 8.905283198476916,
      "grad_norm": 0.00011334299051668495,
      "learning_rate": 2.1894336030461686e-06,
      "loss": 0.0,
      "step": 18710
    },
    {
      "epoch": 8.910042836744408,
      "grad_norm": 0.0010775348637253046,
      "learning_rate": 2.1799143265111854e-06,
      "loss": 0.0007,
      "step": 18720
    },
    {
      "epoch": 8.9148024750119,
      "grad_norm": 6.903545727254823e-05,
      "learning_rate": 2.170395049976202e-06,
      "loss": 0.0027,
      "step": 18730
    },
    {
      "epoch": 8.91956211327939,
      "grad_norm": 0.0002273917052662,
      "learning_rate": 2.1608757734412186e-06,
      "loss": 0.0,
      "step": 18740
    },
    {
      "epoch": 8.924321751546882,
      "grad_norm": 0.00022089756384957582,
      "learning_rate": 2.1513564969062355e-06,
      "loss": 0.0,
      "step": 18750
    },
    {
      "epoch": 8.929081389814375,
      "grad_norm": 6.742448749719188e-05,
      "learning_rate": 2.141837220371252e-06,
      "loss": 0.0,
      "step": 18760
    },
    {
      "epoch": 8.933841028081865,
      "grad_norm": 0.00015397548850160092,
      "learning_rate": 2.1323179438362687e-06,
      "loss": 0.0,
      "step": 18770
    },
    {
      "epoch": 8.938600666349357,
      "grad_norm": 0.0003961046750191599,
      "learning_rate": 2.122798667301285e-06,
      "loss": 0.0,
      "step": 18780
    },
    {
      "epoch": 8.94336030461685,
      "grad_norm": 0.00022442483168561012,
      "learning_rate": 2.113279390766302e-06,
      "loss": 0.0,
      "step": 18790
    },
    {
      "epoch": 8.948119942884341,
      "grad_norm": 0.000183910655323416,
      "learning_rate": 2.1037601142313184e-06,
      "loss": 0.0,
      "step": 18800
    },
    {
      "epoch": 8.952879581151832,
      "grad_norm": 0.0002500823466107249,
      "learning_rate": 2.094240837696335e-06,
      "loss": 0.0,
      "step": 18810
    },
    {
      "epoch": 8.957639219419324,
      "grad_norm": 0.0008711544796824455,
      "learning_rate": 2.084721561161352e-06,
      "loss": 0.0,
      "step": 18820
    },
    {
      "epoch": 8.962398857686816,
      "grad_norm": 0.000194672989891842,
      "learning_rate": 2.0752022846263685e-06,
      "loss": 0.0,
      "step": 18830
    },
    {
      "epoch": 8.967158495954308,
      "grad_norm": 5.1970047934446484e-05,
      "learning_rate": 2.0656830080913853e-06,
      "loss": 0.0,
      "step": 18840
    },
    {
      "epoch": 8.971918134221799,
      "grad_norm": 6.541053153341636e-05,
      "learning_rate": 2.0561637315564017e-06,
      "loss": 0.0,
      "step": 18850
    },
    {
      "epoch": 8.97667777248929,
      "grad_norm": 8.54302998050116e-05,
      "learning_rate": 2.0466444550214185e-06,
      "loss": 0.0235,
      "step": 18860
    },
    {
      "epoch": 8.981437410756783,
      "grad_norm": 3.8151796616148204e-05,
      "learning_rate": 2.0371251784864354e-06,
      "loss": 0.0,
      "step": 18870
    },
    {
      "epoch": 8.986197049024273,
      "grad_norm": 0.00015269062714651227,
      "learning_rate": 2.0276059019514518e-06,
      "loss": 0.0,
      "step": 18880
    },
    {
      "epoch": 8.990956687291765,
      "grad_norm": 0.00020533503266051412,
      "learning_rate": 2.0180866254164686e-06,
      "loss": 0.0003,
      "step": 18890
    },
    {
      "epoch": 8.995716325559258,
      "grad_norm": 2.7910211086273193,
      "learning_rate": 2.0085673488814854e-06,
      "loss": 0.0107,
      "step": 18900
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9980555555555556,
      "eval_f1": 0.9894815927873778,
      "eval_loss": 0.016931775957345963,
      "eval_precision": 0.9902255639097745,
      "eval_recall": 0.9887387387387387,
      "eval_runtime": 342.3558,
      "eval_samples_per_second": 42.094,
      "eval_steps_per_second": 1.317,
      "step": 18909
    }
  ],
  "logging_steps": 10,
  "max_steps": 21010,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.775924623847584e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
