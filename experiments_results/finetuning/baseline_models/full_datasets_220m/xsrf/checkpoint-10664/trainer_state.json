{
  "best_metric": 0.9715964740450538,
  "best_model_checkpoint": "../saved_models/xsrf/checkpoint-10664",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 10664,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0007501875468867217,
      "grad_norm": 31.10957145690918,
      "learning_rate": 1.999849962490623e-05,
      "loss": 1.0199,
      "step": 1
    },
    {
      "epoch": 0.007501875468867217,
      "grad_norm": 13.679360389709473,
      "learning_rate": 1.9984996249062267e-05,
      "loss": 0.4968,
      "step": 10
    },
    {
      "epoch": 0.015003750937734433,
      "grad_norm": 16.71454620361328,
      "learning_rate": 1.9969992498124533e-05,
      "loss": 0.4419,
      "step": 20
    },
    {
      "epoch": 0.02250562640660165,
      "grad_norm": 131.0998077392578,
      "learning_rate": 1.99549887471868e-05,
      "loss": 0.4474,
      "step": 30
    },
    {
      "epoch": 0.030007501875468866,
      "grad_norm": 17.550771713256836,
      "learning_rate": 1.9939984996249065e-05,
      "loss": 0.4547,
      "step": 40
    },
    {
      "epoch": 0.037509377344336084,
      "grad_norm": 12.972543716430664,
      "learning_rate": 1.992498124531133e-05,
      "loss": 0.4012,
      "step": 50
    },
    {
      "epoch": 0.0450112528132033,
      "grad_norm": 13.510334014892578,
      "learning_rate": 1.9909977494373596e-05,
      "loss": 0.4395,
      "step": 60
    },
    {
      "epoch": 0.05251312828207052,
      "grad_norm": 14.257552146911621,
      "learning_rate": 1.9894973743435862e-05,
      "loss": 0.4089,
      "step": 70
    },
    {
      "epoch": 0.06001500375093773,
      "grad_norm": 11.522927284240723,
      "learning_rate": 1.9879969992498128e-05,
      "loss": 0.3969,
      "step": 80
    },
    {
      "epoch": 0.06751687921980495,
      "grad_norm": 30.16496467590332,
      "learning_rate": 1.9864966241560394e-05,
      "loss": 0.4558,
      "step": 90
    },
    {
      "epoch": 0.07501875468867217,
      "grad_norm": 14.465660095214844,
      "learning_rate": 1.9849962490622656e-05,
      "loss": 0.3991,
      "step": 100
    },
    {
      "epoch": 0.08252063015753938,
      "grad_norm": 18.336910247802734,
      "learning_rate": 1.9834958739684922e-05,
      "loss": 0.4178,
      "step": 110
    },
    {
      "epoch": 0.0900225056264066,
      "grad_norm": 11.267930030822754,
      "learning_rate": 1.9819954988747188e-05,
      "loss": 0.3956,
      "step": 120
    },
    {
      "epoch": 0.09752438109527382,
      "grad_norm": 12.859804153442383,
      "learning_rate": 1.9804951237809454e-05,
      "loss": 0.3839,
      "step": 130
    },
    {
      "epoch": 0.10502625656414104,
      "grad_norm": 13.142898559570312,
      "learning_rate": 1.978994748687172e-05,
      "loss": 0.3963,
      "step": 140
    },
    {
      "epoch": 0.11252813203300825,
      "grad_norm": 39.614261627197266,
      "learning_rate": 1.9774943735933985e-05,
      "loss": 0.3468,
      "step": 150
    },
    {
      "epoch": 0.12003000750187547,
      "grad_norm": 7.649240493774414,
      "learning_rate": 1.975993998499625e-05,
      "loss": 0.3634,
      "step": 160
    },
    {
      "epoch": 0.1275318829707427,
      "grad_norm": 7.407997131347656,
      "learning_rate": 1.9744936234058517e-05,
      "loss": 0.3719,
      "step": 170
    },
    {
      "epoch": 0.1350337584396099,
      "grad_norm": 12.116242408752441,
      "learning_rate": 1.9729932483120783e-05,
      "loss": 0.4511,
      "step": 180
    },
    {
      "epoch": 0.14253563390847712,
      "grad_norm": 8.519949913024902,
      "learning_rate": 1.971492873218305e-05,
      "loss": 0.3244,
      "step": 190
    },
    {
      "epoch": 0.15003750937734434,
      "grad_norm": 13.410453796386719,
      "learning_rate": 1.9699924981245314e-05,
      "loss": 0.3734,
      "step": 200
    },
    {
      "epoch": 0.15753938484621155,
      "grad_norm": 8.35759449005127,
      "learning_rate": 1.968492123030758e-05,
      "loss": 0.3496,
      "step": 210
    },
    {
      "epoch": 0.16504126031507876,
      "grad_norm": 15.495706558227539,
      "learning_rate": 1.9669917479369846e-05,
      "loss": 0.362,
      "step": 220
    },
    {
      "epoch": 0.17254313578394598,
      "grad_norm": 5.898176193237305,
      "learning_rate": 1.965491372843211e-05,
      "loss": 0.3671,
      "step": 230
    },
    {
      "epoch": 0.1800450112528132,
      "grad_norm": 6.611067771911621,
      "learning_rate": 1.9639909977494377e-05,
      "loss": 0.3283,
      "step": 240
    },
    {
      "epoch": 0.18754688672168043,
      "grad_norm": 6.407571792602539,
      "learning_rate": 1.962490622655664e-05,
      "loss": 0.3289,
      "step": 250
    },
    {
      "epoch": 0.19504876219054765,
      "grad_norm": 5.772417068481445,
      "learning_rate": 1.9609902475618906e-05,
      "loss": 0.3246,
      "step": 260
    },
    {
      "epoch": 0.20255063765941486,
      "grad_norm": 12.376871109008789,
      "learning_rate": 1.959489872468117e-05,
      "loss": 0.3598,
      "step": 270
    },
    {
      "epoch": 0.21005251312828208,
      "grad_norm": 16.179155349731445,
      "learning_rate": 1.9579894973743437e-05,
      "loss": 0.3164,
      "step": 280
    },
    {
      "epoch": 0.2175543885971493,
      "grad_norm": 4.423884391784668,
      "learning_rate": 1.9564891222805703e-05,
      "loss": 0.3029,
      "step": 290
    },
    {
      "epoch": 0.2250562640660165,
      "grad_norm": 7.397552013397217,
      "learning_rate": 1.954988747186797e-05,
      "loss": 0.346,
      "step": 300
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 6.504641056060791,
      "learning_rate": 1.9534883720930235e-05,
      "loss": 0.3395,
      "step": 310
    },
    {
      "epoch": 0.24006001500375093,
      "grad_norm": 5.679107666015625,
      "learning_rate": 1.95198799699925e-05,
      "loss": 0.3549,
      "step": 320
    },
    {
      "epoch": 0.24756189047261815,
      "grad_norm": 16.09000587463379,
      "learning_rate": 1.9504876219054766e-05,
      "loss": 0.3336,
      "step": 330
    },
    {
      "epoch": 0.2550637659414854,
      "grad_norm": 6.223254680633545,
      "learning_rate": 1.9489872468117032e-05,
      "loss": 0.3318,
      "step": 340
    },
    {
      "epoch": 0.2625656414103526,
      "grad_norm": 4.100397109985352,
      "learning_rate": 1.9474868717179294e-05,
      "loss": 0.3128,
      "step": 350
    },
    {
      "epoch": 0.2700675168792198,
      "grad_norm": 4.930309772491455,
      "learning_rate": 1.945986496624156e-05,
      "loss": 0.2937,
      "step": 360
    },
    {
      "epoch": 0.27756939234808703,
      "grad_norm": 5.459259033203125,
      "learning_rate": 1.9444861215303826e-05,
      "loss": 0.3006,
      "step": 370
    },
    {
      "epoch": 0.28507126781695424,
      "grad_norm": 10.8352689743042,
      "learning_rate": 1.9429857464366092e-05,
      "loss": 0.3461,
      "step": 380
    },
    {
      "epoch": 0.29257314328582146,
      "grad_norm": 3.913658857345581,
      "learning_rate": 1.9414853713428358e-05,
      "loss": 0.2844,
      "step": 390
    },
    {
      "epoch": 0.30007501875468867,
      "grad_norm": 3.29331111907959,
      "learning_rate": 1.9399849962490623e-05,
      "loss": 0.2884,
      "step": 400
    },
    {
      "epoch": 0.3075768942235559,
      "grad_norm": 4.978085517883301,
      "learning_rate": 1.938484621155289e-05,
      "loss": 0.2627,
      "step": 410
    },
    {
      "epoch": 0.3150787696924231,
      "grad_norm": 3.8797688484191895,
      "learning_rate": 1.9369842460615155e-05,
      "loss": 0.2774,
      "step": 420
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 7.514165878295898,
      "learning_rate": 1.935483870967742e-05,
      "loss": 0.2812,
      "step": 430
    },
    {
      "epoch": 0.3300825206301575,
      "grad_norm": 4.924623966217041,
      "learning_rate": 1.9339834958739687e-05,
      "loss": 0.2679,
      "step": 440
    },
    {
      "epoch": 0.33758439609902474,
      "grad_norm": 5.840272426605225,
      "learning_rate": 1.9324831207801952e-05,
      "loss": 0.3143,
      "step": 450
    },
    {
      "epoch": 0.34508627156789196,
      "grad_norm": 4.810577869415283,
      "learning_rate": 1.9309827456864218e-05,
      "loss": 0.3259,
      "step": 460
    },
    {
      "epoch": 0.35258814703675917,
      "grad_norm": 4.924947261810303,
      "learning_rate": 1.9294823705926484e-05,
      "loss": 0.2535,
      "step": 470
    },
    {
      "epoch": 0.3600900225056264,
      "grad_norm": 4.94481086730957,
      "learning_rate": 1.9279819954988746e-05,
      "loss": 0.2457,
      "step": 480
    },
    {
      "epoch": 0.3675918979744936,
      "grad_norm": 4.252846717834473,
      "learning_rate": 1.9264816204051012e-05,
      "loss": 0.2608,
      "step": 490
    },
    {
      "epoch": 0.37509377344336087,
      "grad_norm": 4.254063129425049,
      "learning_rate": 1.9249812453113278e-05,
      "loss": 0.2462,
      "step": 500
    },
    {
      "epoch": 0.3825956489122281,
      "grad_norm": 4.524024486541748,
      "learning_rate": 1.9234808702175544e-05,
      "loss": 0.2352,
      "step": 510
    },
    {
      "epoch": 0.3900975243810953,
      "grad_norm": 6.8294243812561035,
      "learning_rate": 1.921980495123781e-05,
      "loss": 0.2503,
      "step": 520
    },
    {
      "epoch": 0.3975993998499625,
      "grad_norm": 9.113696098327637,
      "learning_rate": 1.9204801200300075e-05,
      "loss": 0.2598,
      "step": 530
    },
    {
      "epoch": 0.4051012753188297,
      "grad_norm": 24.809431076049805,
      "learning_rate": 1.918979744936234e-05,
      "loss": 0.2123,
      "step": 540
    },
    {
      "epoch": 0.41260315078769694,
      "grad_norm": 6.227845668792725,
      "learning_rate": 1.9174793698424607e-05,
      "loss": 0.2213,
      "step": 550
    },
    {
      "epoch": 0.42010502625656415,
      "grad_norm": 5.5706000328063965,
      "learning_rate": 1.9159789947486873e-05,
      "loss": 0.2107,
      "step": 560
    },
    {
      "epoch": 0.42760690172543137,
      "grad_norm": 6.402333736419678,
      "learning_rate": 1.914478619654914e-05,
      "loss": 0.2229,
      "step": 570
    },
    {
      "epoch": 0.4351087771942986,
      "grad_norm": 3.237215280532837,
      "learning_rate": 1.9129782445611404e-05,
      "loss": 0.1987,
      "step": 580
    },
    {
      "epoch": 0.4426106526631658,
      "grad_norm": 6.9528985023498535,
      "learning_rate": 1.911477869467367e-05,
      "loss": 0.2195,
      "step": 590
    },
    {
      "epoch": 0.450112528132033,
      "grad_norm": 5.277055740356445,
      "learning_rate": 1.9099774943735936e-05,
      "loss": 0.2114,
      "step": 600
    },
    {
      "epoch": 0.4576144036009002,
      "grad_norm": 3.974461317062378,
      "learning_rate": 1.9084771192798202e-05,
      "loss": 0.224,
      "step": 610
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 5.272946834564209,
      "learning_rate": 1.9069767441860468e-05,
      "loss": 0.1924,
      "step": 620
    },
    {
      "epoch": 0.47261815453863465,
      "grad_norm": 5.765068531036377,
      "learning_rate": 1.9054763690922733e-05,
      "loss": 0.1972,
      "step": 630
    },
    {
      "epoch": 0.48012003000750186,
      "grad_norm": 13.11230754852295,
      "learning_rate": 1.9039759939985e-05,
      "loss": 0.2066,
      "step": 640
    },
    {
      "epoch": 0.4876219054763691,
      "grad_norm": 4.177552223205566,
      "learning_rate": 1.9024756189047265e-05,
      "loss": 0.2105,
      "step": 650
    },
    {
      "epoch": 0.4951237809452363,
      "grad_norm": 5.967896461486816,
      "learning_rate": 1.900975243810953e-05,
      "loss": 0.1741,
      "step": 660
    },
    {
      "epoch": 0.5026256564141035,
      "grad_norm": 8.023238182067871,
      "learning_rate": 1.8994748687171793e-05,
      "loss": 0.1811,
      "step": 670
    },
    {
      "epoch": 0.5101275318829708,
      "grad_norm": 4.108067989349365,
      "learning_rate": 1.897974493623406e-05,
      "loss": 0.1854,
      "step": 680
    },
    {
      "epoch": 0.5176294073518379,
      "grad_norm": 3.1973609924316406,
      "learning_rate": 1.8964741185296325e-05,
      "loss": 0.2043,
      "step": 690
    },
    {
      "epoch": 0.5251312828207052,
      "grad_norm": 5.72205924987793,
      "learning_rate": 1.894973743435859e-05,
      "loss": 0.1827,
      "step": 700
    },
    {
      "epoch": 0.5326331582895724,
      "grad_norm": 7.552395820617676,
      "learning_rate": 1.8934733683420856e-05,
      "loss": 0.2175,
      "step": 710
    },
    {
      "epoch": 0.5401350337584396,
      "grad_norm": 2.6709344387054443,
      "learning_rate": 1.8919729932483122e-05,
      "loss": 0.1867,
      "step": 720
    },
    {
      "epoch": 0.5476369092273068,
      "grad_norm": 7.6903977394104,
      "learning_rate": 1.8904726181545388e-05,
      "loss": 0.1845,
      "step": 730
    },
    {
      "epoch": 0.5551387846961741,
      "grad_norm": 4.277793884277344,
      "learning_rate": 1.8889722430607654e-05,
      "loss": 0.1729,
      "step": 740
    },
    {
      "epoch": 0.5626406601650412,
      "grad_norm": 6.106494426727295,
      "learning_rate": 1.887471867966992e-05,
      "loss": 0.1824,
      "step": 750
    },
    {
      "epoch": 0.5701425356339085,
      "grad_norm": 2.41951060295105,
      "learning_rate": 1.8859714928732185e-05,
      "loss": 0.1754,
      "step": 760
    },
    {
      "epoch": 0.5776444111027756,
      "grad_norm": 3.657646656036377,
      "learning_rate": 1.884471117779445e-05,
      "loss": 0.1416,
      "step": 770
    },
    {
      "epoch": 0.5851462865716429,
      "grad_norm": 4.895589828491211,
      "learning_rate": 1.8829707426856717e-05,
      "loss": 0.1425,
      "step": 780
    },
    {
      "epoch": 0.5926481620405101,
      "grad_norm": 2.9261388778686523,
      "learning_rate": 1.8814703675918983e-05,
      "loss": 0.1614,
      "step": 790
    },
    {
      "epoch": 0.6001500375093773,
      "grad_norm": 4.08211612701416,
      "learning_rate": 1.879969992498125e-05,
      "loss": 0.1524,
      "step": 800
    },
    {
      "epoch": 0.6076519129782446,
      "grad_norm": 2.943544864654541,
      "learning_rate": 1.8784696174043514e-05,
      "loss": 0.1677,
      "step": 810
    },
    {
      "epoch": 0.6151537884471118,
      "grad_norm": 4.21165657043457,
      "learning_rate": 1.876969242310578e-05,
      "loss": 0.143,
      "step": 820
    },
    {
      "epoch": 0.622655663915979,
      "grad_norm": 3.7603049278259277,
      "learning_rate": 1.8754688672168046e-05,
      "loss": 0.1156,
      "step": 830
    },
    {
      "epoch": 0.6301575393848462,
      "grad_norm": 4.195806980133057,
      "learning_rate": 1.873968492123031e-05,
      "loss": 0.1515,
      "step": 840
    },
    {
      "epoch": 0.6376594148537135,
      "grad_norm": 4.331838607788086,
      "learning_rate": 1.8724681170292574e-05,
      "loss": 0.1263,
      "step": 850
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 16.74220848083496,
      "learning_rate": 1.870967741935484e-05,
      "loss": 0.1591,
      "step": 860
    },
    {
      "epoch": 0.6526631657914479,
      "grad_norm": 7.805340766906738,
      "learning_rate": 1.8694673668417106e-05,
      "loss": 0.1288,
      "step": 870
    },
    {
      "epoch": 0.660165041260315,
      "grad_norm": 4.542103290557861,
      "learning_rate": 1.867966991747937e-05,
      "loss": 0.166,
      "step": 880
    },
    {
      "epoch": 0.6676669167291823,
      "grad_norm": 6.063998222351074,
      "learning_rate": 1.8664666166541637e-05,
      "loss": 0.1377,
      "step": 890
    },
    {
      "epoch": 0.6751687921980495,
      "grad_norm": 5.1190104484558105,
      "learning_rate": 1.8649662415603903e-05,
      "loss": 0.149,
      "step": 900
    },
    {
      "epoch": 0.6826706676669168,
      "grad_norm": 4.629572868347168,
      "learning_rate": 1.863465866466617e-05,
      "loss": 0.1317,
      "step": 910
    },
    {
      "epoch": 0.6901725431357839,
      "grad_norm": 5.126471042633057,
      "learning_rate": 1.8619654913728435e-05,
      "loss": 0.1301,
      "step": 920
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 12.23802661895752,
      "learning_rate": 1.86046511627907e-05,
      "loss": 0.1324,
      "step": 930
    },
    {
      "epoch": 0.7051762940735183,
      "grad_norm": 3.396343469619751,
      "learning_rate": 1.8589647411852963e-05,
      "loss": 0.1353,
      "step": 940
    },
    {
      "epoch": 0.7126781695423856,
      "grad_norm": 7.7948079109191895,
      "learning_rate": 1.857464366091523e-05,
      "loss": 0.1105,
      "step": 950
    },
    {
      "epoch": 0.7201800450112528,
      "grad_norm": 9.166193962097168,
      "learning_rate": 1.8559639909977495e-05,
      "loss": 0.1128,
      "step": 960
    },
    {
      "epoch": 0.72768192048012,
      "grad_norm": 64.02686309814453,
      "learning_rate": 1.854463615903976e-05,
      "loss": 0.1231,
      "step": 970
    },
    {
      "epoch": 0.7351837959489872,
      "grad_norm": 5.184946060180664,
      "learning_rate": 1.8529632408102026e-05,
      "loss": 0.1066,
      "step": 980
    },
    {
      "epoch": 0.7426856714178545,
      "grad_norm": 4.957901954650879,
      "learning_rate": 1.8514628657164292e-05,
      "loss": 0.1447,
      "step": 990
    },
    {
      "epoch": 0.7501875468867217,
      "grad_norm": 5.492155075073242,
      "learning_rate": 1.8499624906226558e-05,
      "loss": 0.1078,
      "step": 1000
    },
    {
      "epoch": 0.7576894223555889,
      "grad_norm": 12.815702438354492,
      "learning_rate": 1.8484621155288824e-05,
      "loss": 0.1228,
      "step": 1010
    },
    {
      "epoch": 0.7651912978244562,
      "grad_norm": 10.0615873336792,
      "learning_rate": 1.846961740435109e-05,
      "loss": 0.1283,
      "step": 1020
    },
    {
      "epoch": 0.7726931732933233,
      "grad_norm": 6.18033504486084,
      "learning_rate": 1.8454613653413355e-05,
      "loss": 0.1153,
      "step": 1030
    },
    {
      "epoch": 0.7801950487621906,
      "grad_norm": 3.7186169624328613,
      "learning_rate": 1.843960990247562e-05,
      "loss": 0.1108,
      "step": 1040
    },
    {
      "epoch": 0.7876969242310577,
      "grad_norm": 5.933471202850342,
      "learning_rate": 1.8424606151537883e-05,
      "loss": 0.102,
      "step": 1050
    },
    {
      "epoch": 0.795198799699925,
      "grad_norm": 4.18847131729126,
      "learning_rate": 1.840960240060015e-05,
      "loss": 0.1603,
      "step": 1060
    },
    {
      "epoch": 0.8027006751687922,
      "grad_norm": 4.975616931915283,
      "learning_rate": 1.8394598649662415e-05,
      "loss": 0.1245,
      "step": 1070
    },
    {
      "epoch": 0.8102025506376594,
      "grad_norm": 4.368872165679932,
      "learning_rate": 1.837959489872468e-05,
      "loss": 0.0889,
      "step": 1080
    },
    {
      "epoch": 0.8177044261065266,
      "grad_norm": 3.178255319595337,
      "learning_rate": 1.8364591147786947e-05,
      "loss": 0.1064,
      "step": 1090
    },
    {
      "epoch": 0.8252063015753939,
      "grad_norm": 5.375457763671875,
      "learning_rate": 1.8349587396849212e-05,
      "loss": 0.1494,
      "step": 1100
    },
    {
      "epoch": 0.832708177044261,
      "grad_norm": 3.936135768890381,
      "learning_rate": 1.8334583645911478e-05,
      "loss": 0.114,
      "step": 1110
    },
    {
      "epoch": 0.8402100525131283,
      "grad_norm": 3.203282594680786,
      "learning_rate": 1.8319579894973744e-05,
      "loss": 0.1083,
      "step": 1120
    },
    {
      "epoch": 0.8477119279819955,
      "grad_norm": 4.626305103302002,
      "learning_rate": 1.830457614403601e-05,
      "loss": 0.1006,
      "step": 1130
    },
    {
      "epoch": 0.8552138034508627,
      "grad_norm": 9.406176567077637,
      "learning_rate": 1.8289572393098276e-05,
      "loss": 0.1815,
      "step": 1140
    },
    {
      "epoch": 0.8627156789197299,
      "grad_norm": 3.107713222503662,
      "learning_rate": 1.827456864216054e-05,
      "loss": 0.1059,
      "step": 1150
    },
    {
      "epoch": 0.8702175543885972,
      "grad_norm": 4.321774482727051,
      "learning_rate": 1.8259564891222807e-05,
      "loss": 0.0893,
      "step": 1160
    },
    {
      "epoch": 0.8777194298574643,
      "grad_norm": 2.615156888961792,
      "learning_rate": 1.8244561140285073e-05,
      "loss": 0.0881,
      "step": 1170
    },
    {
      "epoch": 0.8852213053263316,
      "grad_norm": 3.700068235397339,
      "learning_rate": 1.822955738934734e-05,
      "loss": 0.1043,
      "step": 1180
    },
    {
      "epoch": 0.8927231807951987,
      "grad_norm": 5.98863410949707,
      "learning_rate": 1.8214553638409605e-05,
      "loss": 0.0897,
      "step": 1190
    },
    {
      "epoch": 0.900225056264066,
      "grad_norm": 0.5074944496154785,
      "learning_rate": 1.819954988747187e-05,
      "loss": 0.0648,
      "step": 1200
    },
    {
      "epoch": 0.9077269317329333,
      "grad_norm": 3.116053819656372,
      "learning_rate": 1.8184546136534136e-05,
      "loss": 0.127,
      "step": 1210
    },
    {
      "epoch": 0.9152288072018004,
      "grad_norm": 4.749785423278809,
      "learning_rate": 1.8169542385596402e-05,
      "loss": 0.1051,
      "step": 1220
    },
    {
      "epoch": 0.9227306826706677,
      "grad_norm": 2.8611085414886475,
      "learning_rate": 1.8154538634658668e-05,
      "loss": 0.094,
      "step": 1230
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 7.7666335105896,
      "learning_rate": 1.813953488372093e-05,
      "loss": 0.0971,
      "step": 1240
    },
    {
      "epoch": 0.9377344336084021,
      "grad_norm": 4.662586688995361,
      "learning_rate": 1.8124531132783196e-05,
      "loss": 0.1203,
      "step": 1250
    },
    {
      "epoch": 0.9452363090772693,
      "grad_norm": 3.3979926109313965,
      "learning_rate": 1.8109527381845462e-05,
      "loss": 0.0722,
      "step": 1260
    },
    {
      "epoch": 0.9527381845461366,
      "grad_norm": 5.8766703605651855,
      "learning_rate": 1.8094523630907728e-05,
      "loss": 0.1148,
      "step": 1270
    },
    {
      "epoch": 0.9602400600150037,
      "grad_norm": 4.106454849243164,
      "learning_rate": 1.8079519879969993e-05,
      "loss": 0.0981,
      "step": 1280
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 3.4160306453704834,
      "learning_rate": 1.806451612903226e-05,
      "loss": 0.0883,
      "step": 1290
    },
    {
      "epoch": 0.9752438109527382,
      "grad_norm": 4.183581352233887,
      "learning_rate": 1.8049512378094525e-05,
      "loss": 0.0861,
      "step": 1300
    },
    {
      "epoch": 0.9827456864216054,
      "grad_norm": 3.190356969833374,
      "learning_rate": 1.803450862715679e-05,
      "loss": 0.103,
      "step": 1310
    },
    {
      "epoch": 0.9902475618904726,
      "grad_norm": 5.9658894538879395,
      "learning_rate": 1.8019504876219057e-05,
      "loss": 0.1157,
      "step": 1320
    },
    {
      "epoch": 0.9977494373593399,
      "grad_norm": 4.613246917724609,
      "learning_rate": 1.8004501125281322e-05,
      "loss": 0.0951,
      "step": 1330
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9757946923301254,
      "eval_f1": 0.904377880184332,
      "eval_loss": 0.0656341090798378,
      "eval_precision": 0.9270741068792442,
      "eval_recall": 0.8827663761596851,
      "eval_runtime": 392.9823,
      "eval_samples_per_second": 69.807,
      "eval_steps_per_second": 2.911,
      "step": 1333
    },
    {
      "epoch": 1.005251312828207,
      "grad_norm": 2.257199764251709,
      "learning_rate": 1.7989497374343588e-05,
      "loss": 0.0664,
      "step": 1340
    },
    {
      "epoch": 1.0127531882970742,
      "grad_norm": 3.4144814014434814,
      "learning_rate": 1.7974493623405854e-05,
      "loss": 0.0679,
      "step": 1350
    },
    {
      "epoch": 1.0202550637659416,
      "grad_norm": 3.6640069484710693,
      "learning_rate": 1.795948987246812e-05,
      "loss": 0.0937,
      "step": 1360
    },
    {
      "epoch": 1.0277569392348087,
      "grad_norm": 2.478095293045044,
      "learning_rate": 1.7944486121530386e-05,
      "loss": 0.0697,
      "step": 1370
    },
    {
      "epoch": 1.0352588147036759,
      "grad_norm": 1.654502272605896,
      "learning_rate": 1.792948237059265e-05,
      "loss": 0.0566,
      "step": 1380
    },
    {
      "epoch": 1.042760690172543,
      "grad_norm": 1.9998669624328613,
      "learning_rate": 1.7914478619654917e-05,
      "loss": 0.0799,
      "step": 1390
    },
    {
      "epoch": 1.0502625656414104,
      "grad_norm": 3.788346767425537,
      "learning_rate": 1.7899474868717183e-05,
      "loss": 0.0978,
      "step": 1400
    },
    {
      "epoch": 1.0577644411102776,
      "grad_norm": 4.886257171630859,
      "learning_rate": 1.788447111777945e-05,
      "loss": 0.1029,
      "step": 1410
    },
    {
      "epoch": 1.0652663165791447,
      "grad_norm": 3.6782021522521973,
      "learning_rate": 1.786946736684171e-05,
      "loss": 0.0795,
      "step": 1420
    },
    {
      "epoch": 1.072768192048012,
      "grad_norm": 4.307087421417236,
      "learning_rate": 1.7854463615903977e-05,
      "loss": 0.0773,
      "step": 1430
    },
    {
      "epoch": 1.0802700675168793,
      "grad_norm": 1.056494116783142,
      "learning_rate": 1.7839459864966243e-05,
      "loss": 0.0586,
      "step": 1440
    },
    {
      "epoch": 1.0877719429857464,
      "grad_norm": 4.143092632293701,
      "learning_rate": 1.782445611402851e-05,
      "loss": 0.0935,
      "step": 1450
    },
    {
      "epoch": 1.0952738184546136,
      "grad_norm": 5.025961399078369,
      "learning_rate": 1.7809452363090774e-05,
      "loss": 0.0706,
      "step": 1460
    },
    {
      "epoch": 1.102775693923481,
      "grad_norm": 2.684518575668335,
      "learning_rate": 1.779444861215304e-05,
      "loss": 0.0599,
      "step": 1470
    },
    {
      "epoch": 1.1102775693923481,
      "grad_norm": 3.662763833999634,
      "learning_rate": 1.7779444861215306e-05,
      "loss": 0.0489,
      "step": 1480
    },
    {
      "epoch": 1.1177794448612153,
      "grad_norm": 7.154195785522461,
      "learning_rate": 1.7764441110277572e-05,
      "loss": 0.1185,
      "step": 1490
    },
    {
      "epoch": 1.1252813203300824,
      "grad_norm": 1.6322078704833984,
      "learning_rate": 1.7749437359339838e-05,
      "loss": 0.078,
      "step": 1500
    },
    {
      "epoch": 1.1327831957989498,
      "grad_norm": 3.3522186279296875,
      "learning_rate": 1.7734433608402103e-05,
      "loss": 0.0498,
      "step": 1510
    },
    {
      "epoch": 1.140285071267817,
      "grad_norm": 2.5604166984558105,
      "learning_rate": 1.7719429857464366e-05,
      "loss": 0.0609,
      "step": 1520
    },
    {
      "epoch": 1.1477869467366841,
      "grad_norm": 1.5620876550674438,
      "learning_rate": 1.770442610652663e-05,
      "loss": 0.0925,
      "step": 1530
    },
    {
      "epoch": 1.1552888222055513,
      "grad_norm": 3.1906607151031494,
      "learning_rate": 1.7689422355588897e-05,
      "loss": 0.0655,
      "step": 1540
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 5.64335298538208,
      "learning_rate": 1.7674418604651163e-05,
      "loss": 0.0797,
      "step": 1550
    },
    {
      "epoch": 1.1702925731432858,
      "grad_norm": 4.873159408569336,
      "learning_rate": 1.765941485371343e-05,
      "loss": 0.0617,
      "step": 1560
    },
    {
      "epoch": 1.177794448612153,
      "grad_norm": 11.303723335266113,
      "learning_rate": 1.7644411102775695e-05,
      "loss": 0.1113,
      "step": 1570
    },
    {
      "epoch": 1.1852963240810204,
      "grad_norm": 2.1062233448028564,
      "learning_rate": 1.762940735183796e-05,
      "loss": 0.0766,
      "step": 1580
    },
    {
      "epoch": 1.1927981995498875,
      "grad_norm": 3.5365490913391113,
      "learning_rate": 1.7614403600900226e-05,
      "loss": 0.062,
      "step": 1590
    },
    {
      "epoch": 1.2003000750187547,
      "grad_norm": 1.1032243967056274,
      "learning_rate": 1.7599399849962492e-05,
      "loss": 0.0568,
      "step": 1600
    },
    {
      "epoch": 1.2078019504876218,
      "grad_norm": 5.920080184936523,
      "learning_rate": 1.7584396099024758e-05,
      "loss": 0.0679,
      "step": 1610
    },
    {
      "epoch": 1.215303825956489,
      "grad_norm": 4.3207502365112305,
      "learning_rate": 1.756939234808702e-05,
      "loss": 0.1111,
      "step": 1620
    },
    {
      "epoch": 1.2228057014253564,
      "grad_norm": 3.154801368713379,
      "learning_rate": 1.7554388597149286e-05,
      "loss": 0.0743,
      "step": 1630
    },
    {
      "epoch": 1.2303075768942235,
      "grad_norm": 3.233940601348877,
      "learning_rate": 1.7539384846211552e-05,
      "loss": 0.0703,
      "step": 1640
    },
    {
      "epoch": 1.2378094523630907,
      "grad_norm": 2.941723585128784,
      "learning_rate": 1.7524381095273818e-05,
      "loss": 0.0744,
      "step": 1650
    },
    {
      "epoch": 1.245311327831958,
      "grad_norm": 4.7081804275512695,
      "learning_rate": 1.7509377344336084e-05,
      "loss": 0.0686,
      "step": 1660
    },
    {
      "epoch": 1.2528132033008252,
      "grad_norm": 3.2203218936920166,
      "learning_rate": 1.749437359339835e-05,
      "loss": 0.0671,
      "step": 1670
    },
    {
      "epoch": 1.2603150787696924,
      "grad_norm": 3.0739152431488037,
      "learning_rate": 1.7479369842460615e-05,
      "loss": 0.0686,
      "step": 1680
    },
    {
      "epoch": 1.2678169542385596,
      "grad_norm": 4.1256489753723145,
      "learning_rate": 1.746436609152288e-05,
      "loss": 0.0534,
      "step": 1690
    },
    {
      "epoch": 1.275318829707427,
      "grad_norm": 22.378820419311523,
      "learning_rate": 1.7449362340585147e-05,
      "loss": 0.0528,
      "step": 1700
    },
    {
      "epoch": 1.282820705176294,
      "grad_norm": 3.0261943340301514,
      "learning_rate": 1.7434358589647413e-05,
      "loss": 0.0494,
      "step": 1710
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 5.33815860748291,
      "learning_rate": 1.741935483870968e-05,
      "loss": 0.068,
      "step": 1720
    },
    {
      "epoch": 1.2978244561140286,
      "grad_norm": 2.4400246143341064,
      "learning_rate": 1.7404351087771944e-05,
      "loss": 0.0455,
      "step": 1730
    },
    {
      "epoch": 1.3053263315828958,
      "grad_norm": 2.643137216567993,
      "learning_rate": 1.738934733683421e-05,
      "loss": 0.0629,
      "step": 1740
    },
    {
      "epoch": 1.312828207051763,
      "grad_norm": 0.50428706407547,
      "learning_rate": 1.7374343585896476e-05,
      "loss": 0.0412,
      "step": 1750
    },
    {
      "epoch": 1.32033008252063,
      "grad_norm": 4.86476993560791,
      "learning_rate": 1.735933983495874e-05,
      "loss": 0.0791,
      "step": 1760
    },
    {
      "epoch": 1.3278319579894973,
      "grad_norm": 4.460862636566162,
      "learning_rate": 1.7344336084021007e-05,
      "loss": 0.0759,
      "step": 1770
    },
    {
      "epoch": 1.3353338334583646,
      "grad_norm": 0.3991100490093231,
      "learning_rate": 1.7329332333083273e-05,
      "loss": 0.0702,
      "step": 1780
    },
    {
      "epoch": 1.3428357089272318,
      "grad_norm": 5.831174850463867,
      "learning_rate": 1.731432858214554e-05,
      "loss": 0.0876,
      "step": 1790
    },
    {
      "epoch": 1.350337584396099,
      "grad_norm": 4.0094685554504395,
      "learning_rate": 1.7299324831207805e-05,
      "loss": 0.0754,
      "step": 1800
    },
    {
      "epoch": 1.3578394598649663,
      "grad_norm": 3.1468796730041504,
      "learning_rate": 1.7284321080270067e-05,
      "loss": 0.0428,
      "step": 1810
    },
    {
      "epoch": 1.3653413353338335,
      "grad_norm": 3.8464691638946533,
      "learning_rate": 1.7269317329332333e-05,
      "loss": 0.0546,
      "step": 1820
    },
    {
      "epoch": 1.3728432108027007,
      "grad_norm": 2.9275577068328857,
      "learning_rate": 1.72543135783946e-05,
      "loss": 0.0483,
      "step": 1830
    },
    {
      "epoch": 1.3803450862715678,
      "grad_norm": 2.1705305576324463,
      "learning_rate": 1.7239309827456865e-05,
      "loss": 0.0612,
      "step": 1840
    },
    {
      "epoch": 1.387846961740435,
      "grad_norm": 2.916278839111328,
      "learning_rate": 1.722430607651913e-05,
      "loss": 0.0451,
      "step": 1850
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 8.580583572387695,
      "learning_rate": 1.7209302325581396e-05,
      "loss": 0.0534,
      "step": 1860
    },
    {
      "epoch": 1.4028507126781695,
      "grad_norm": 5.650308609008789,
      "learning_rate": 1.7194298574643662e-05,
      "loss": 0.0813,
      "step": 1870
    },
    {
      "epoch": 1.4103525881470367,
      "grad_norm": 7.865400314331055,
      "learning_rate": 1.7179294823705928e-05,
      "loss": 0.0522,
      "step": 1880
    },
    {
      "epoch": 1.417854463615904,
      "grad_norm": 5.426770210266113,
      "learning_rate": 1.7164291072768194e-05,
      "loss": 0.067,
      "step": 1890
    },
    {
      "epoch": 1.4253563390847712,
      "grad_norm": 4.796453475952148,
      "learning_rate": 1.714928732183046e-05,
      "loss": 0.0632,
      "step": 1900
    },
    {
      "epoch": 1.4328582145536384,
      "grad_norm": 1.9359153509140015,
      "learning_rate": 1.7134283570892725e-05,
      "loss": 0.0689,
      "step": 1910
    },
    {
      "epoch": 1.4403600900225055,
      "grad_norm": 2.4312682151794434,
      "learning_rate": 1.711927981995499e-05,
      "loss": 0.0858,
      "step": 1920
    },
    {
      "epoch": 1.447861965491373,
      "grad_norm": 3.2157094478607178,
      "learning_rate": 1.7104276069017257e-05,
      "loss": 0.0599,
      "step": 1930
    },
    {
      "epoch": 1.45536384096024,
      "grad_norm": 2.105703830718994,
      "learning_rate": 1.7089272318079523e-05,
      "loss": 0.053,
      "step": 1940
    },
    {
      "epoch": 1.4628657164291072,
      "grad_norm": 3.269526481628418,
      "learning_rate": 1.707426856714179e-05,
      "loss": 0.0598,
      "step": 1950
    },
    {
      "epoch": 1.4703675918979746,
      "grad_norm": 4.968238830566406,
      "learning_rate": 1.7059264816204054e-05,
      "loss": 0.0643,
      "step": 1960
    },
    {
      "epoch": 1.4778694673668418,
      "grad_norm": 1.1080296039581299,
      "learning_rate": 1.704426106526632e-05,
      "loss": 0.0461,
      "step": 1970
    },
    {
      "epoch": 1.485371342835709,
      "grad_norm": 4.598200798034668,
      "learning_rate": 1.7029257314328586e-05,
      "loss": 0.0568,
      "step": 1980
    },
    {
      "epoch": 1.492873218304576,
      "grad_norm": 1.717808723449707,
      "learning_rate": 1.701425356339085e-05,
      "loss": 0.0558,
      "step": 1990
    },
    {
      "epoch": 1.5003750937734432,
      "grad_norm": 1.8591411113739014,
      "learning_rate": 1.6999249812453114e-05,
      "loss": 0.0665,
      "step": 2000
    },
    {
      "epoch": 1.5078769692423106,
      "grad_norm": 3.963150978088379,
      "learning_rate": 1.698424606151538e-05,
      "loss": 0.0733,
      "step": 2010
    },
    {
      "epoch": 1.5153788447111778,
      "grad_norm": 2.099220037460327,
      "learning_rate": 1.6969242310577646e-05,
      "loss": 0.0532,
      "step": 2020
    },
    {
      "epoch": 1.5228807201800452,
      "grad_norm": 8.520631790161133,
      "learning_rate": 1.695423855963991e-05,
      "loss": 0.0716,
      "step": 2030
    },
    {
      "epoch": 1.5303825956489123,
      "grad_norm": 1.640923023223877,
      "learning_rate": 1.6939234808702177e-05,
      "loss": 0.0643,
      "step": 2040
    },
    {
      "epoch": 1.5378844711177795,
      "grad_norm": 3.6174156665802,
      "learning_rate": 1.6924231057764443e-05,
      "loss": 0.055,
      "step": 2050
    },
    {
      "epoch": 1.5453863465866466,
      "grad_norm": 5.82867956161499,
      "learning_rate": 1.690922730682671e-05,
      "loss": 0.053,
      "step": 2060
    },
    {
      "epoch": 1.5528882220555138,
      "grad_norm": 6.699929714202881,
      "learning_rate": 1.6894223555888975e-05,
      "loss": 0.0711,
      "step": 2070
    },
    {
      "epoch": 1.560390097524381,
      "grad_norm": 3.6484696865081787,
      "learning_rate": 1.687921980495124e-05,
      "loss": 0.072,
      "step": 2080
    },
    {
      "epoch": 1.5678919729932483,
      "grad_norm": 2.783562660217285,
      "learning_rate": 1.6864216054013506e-05,
      "loss": 0.0542,
      "step": 2090
    },
    {
      "epoch": 1.5753938484621155,
      "grad_norm": 6.622731685638428,
      "learning_rate": 1.6849212303075772e-05,
      "loss": 0.0567,
      "step": 2100
    },
    {
      "epoch": 1.5828957239309829,
      "grad_norm": 2.29415225982666,
      "learning_rate": 1.6834208552138034e-05,
      "loss": 0.0488,
      "step": 2110
    },
    {
      "epoch": 1.59039759939985,
      "grad_norm": 7.2385334968566895,
      "learning_rate": 1.68192048012003e-05,
      "loss": 0.0653,
      "step": 2120
    },
    {
      "epoch": 1.5978994748687172,
      "grad_norm": 2.8382980823516846,
      "learning_rate": 1.6804201050262566e-05,
      "loss": 0.0465,
      "step": 2130
    },
    {
      "epoch": 1.6054013503375844,
      "grad_norm": 1.422294020652771,
      "learning_rate": 1.6789197299324832e-05,
      "loss": 0.0563,
      "step": 2140
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 4.374312877655029,
      "learning_rate": 1.6774193548387098e-05,
      "loss": 0.0612,
      "step": 2150
    },
    {
      "epoch": 1.6204051012753187,
      "grad_norm": 3.5240464210510254,
      "learning_rate": 1.6759189797449363e-05,
      "loss": 0.0449,
      "step": 2160
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 3.1072006225585938,
      "learning_rate": 1.674418604651163e-05,
      "loss": 0.0718,
      "step": 2170
    },
    {
      "epoch": 1.6354088522130532,
      "grad_norm": 3.3682684898376465,
      "learning_rate": 1.6729182295573895e-05,
      "loss": 0.0735,
      "step": 2180
    },
    {
      "epoch": 1.6429107276819206,
      "grad_norm": 4.4664788246154785,
      "learning_rate": 1.671417854463616e-05,
      "loss": 0.0466,
      "step": 2190
    },
    {
      "epoch": 1.6504126031507877,
      "grad_norm": 2.34631085395813,
      "learning_rate": 1.6699174793698427e-05,
      "loss": 0.0554,
      "step": 2200
    },
    {
      "epoch": 1.657914478619655,
      "grad_norm": 2.168363571166992,
      "learning_rate": 1.668417104276069e-05,
      "loss": 0.0553,
      "step": 2210
    },
    {
      "epoch": 1.665416354088522,
      "grad_norm": 1.717777967453003,
      "learning_rate": 1.6669167291822955e-05,
      "loss": 0.0456,
      "step": 2220
    },
    {
      "epoch": 1.6729182295573892,
      "grad_norm": 2.1542458534240723,
      "learning_rate": 1.665416354088522e-05,
      "loss": 0.0728,
      "step": 2230
    },
    {
      "epoch": 1.6804201050262566,
      "grad_norm": 3.2531049251556396,
      "learning_rate": 1.6639159789947486e-05,
      "loss": 0.0579,
      "step": 2240
    },
    {
      "epoch": 1.6879219804951238,
      "grad_norm": 2.8546931743621826,
      "learning_rate": 1.6624156039009752e-05,
      "loss": 0.0456,
      "step": 2250
    },
    {
      "epoch": 1.6954238559639911,
      "grad_norm": 3.6310579776763916,
      "learning_rate": 1.6609152288072018e-05,
      "loss": 0.0793,
      "step": 2260
    },
    {
      "epoch": 1.7029257314328583,
      "grad_norm": 3.5184197425842285,
      "learning_rate": 1.6594148537134284e-05,
      "loss": 0.0504,
      "step": 2270
    },
    {
      "epoch": 1.7104276069017255,
      "grad_norm": 4.244894504547119,
      "learning_rate": 1.657914478619655e-05,
      "loss": 0.0704,
      "step": 2280
    },
    {
      "epoch": 1.7179294823705926,
      "grad_norm": 5.727385520935059,
      "learning_rate": 1.6564141035258815e-05,
      "loss": 0.0367,
      "step": 2290
    },
    {
      "epoch": 1.7254313578394598,
      "grad_norm": 6.8373212814331055,
      "learning_rate": 1.654913728432108e-05,
      "loss": 0.0455,
      "step": 2300
    },
    {
      "epoch": 1.732933233308327,
      "grad_norm": 3.1095550060272217,
      "learning_rate": 1.6534133533383347e-05,
      "loss": 0.0621,
      "step": 2310
    },
    {
      "epoch": 1.7404351087771943,
      "grad_norm": 1.6344630718231201,
      "learning_rate": 1.6519129782445613e-05,
      "loss": 0.0429,
      "step": 2320
    },
    {
      "epoch": 1.7479369842460615,
      "grad_norm": 1.7587016820907593,
      "learning_rate": 1.650412603150788e-05,
      "loss": 0.0505,
      "step": 2330
    },
    {
      "epoch": 1.7554388597149289,
      "grad_norm": 0.4090918302536011,
      "learning_rate": 1.6489122280570144e-05,
      "loss": 0.0466,
      "step": 2340
    },
    {
      "epoch": 1.762940735183796,
      "grad_norm": 1.6428382396697998,
      "learning_rate": 1.647411852963241e-05,
      "loss": 0.0513,
      "step": 2350
    },
    {
      "epoch": 1.7704426106526632,
      "grad_norm": 5.545330047607422,
      "learning_rate": 1.6459114778694676e-05,
      "loss": 0.0426,
      "step": 2360
    },
    {
      "epoch": 1.7779444861215303,
      "grad_norm": 3.1342597007751465,
      "learning_rate": 1.6444111027756942e-05,
      "loss": 0.084,
      "step": 2370
    },
    {
      "epoch": 1.7854463615903975,
      "grad_norm": 2.842000722885132,
      "learning_rate": 1.6429107276819208e-05,
      "loss": 0.0379,
      "step": 2380
    },
    {
      "epoch": 1.7929482370592649,
      "grad_norm": 5.224008083343506,
      "learning_rate": 1.641410352588147e-05,
      "loss": 0.0503,
      "step": 2390
    },
    {
      "epoch": 1.800450112528132,
      "grad_norm": 4.288313865661621,
      "learning_rate": 1.6399099774943736e-05,
      "loss": 0.0607,
      "step": 2400
    },
    {
      "epoch": 1.8079519879969994,
      "grad_norm": 2.1991372108459473,
      "learning_rate": 1.6384096024006e-05,
      "loss": 0.0502,
      "step": 2410
    },
    {
      "epoch": 1.8154538634658666,
      "grad_norm": 0.860702633857727,
      "learning_rate": 1.6369092273068267e-05,
      "loss": 0.0382,
      "step": 2420
    },
    {
      "epoch": 1.8229557389347337,
      "grad_norm": 3.057110071182251,
      "learning_rate": 1.6354088522130533e-05,
      "loss": 0.0458,
      "step": 2430
    },
    {
      "epoch": 1.8304576144036009,
      "grad_norm": 4.508167266845703,
      "learning_rate": 1.63390847711928e-05,
      "loss": 0.0401,
      "step": 2440
    },
    {
      "epoch": 1.837959489872468,
      "grad_norm": 3.2822999954223633,
      "learning_rate": 1.6324081020255065e-05,
      "loss": 0.0702,
      "step": 2450
    },
    {
      "epoch": 1.8454613653413352,
      "grad_norm": 1.0416830778121948,
      "learning_rate": 1.630907726931733e-05,
      "loss": 0.0408,
      "step": 2460
    },
    {
      "epoch": 1.8529632408102026,
      "grad_norm": 1.7645167112350464,
      "learning_rate": 1.6294073518379596e-05,
      "loss": 0.0384,
      "step": 2470
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 4.9940385818481445,
      "learning_rate": 1.6279069767441862e-05,
      "loss": 0.0531,
      "step": 2480
    },
    {
      "epoch": 1.8679669917479371,
      "grad_norm": 1.9746897220611572,
      "learning_rate": 1.6264066016504128e-05,
      "loss": 0.0545,
      "step": 2490
    },
    {
      "epoch": 1.8754688672168043,
      "grad_norm": 4.362417697906494,
      "learning_rate": 1.6249062265566394e-05,
      "loss": 0.0523,
      "step": 2500
    },
    {
      "epoch": 1.8829707426856714,
      "grad_norm": 3.161147356033325,
      "learning_rate": 1.623405851462866e-05,
      "loss": 0.0323,
      "step": 2510
    },
    {
      "epoch": 1.8904726181545386,
      "grad_norm": 0.4782065451145172,
      "learning_rate": 1.6219054763690925e-05,
      "loss": 0.0464,
      "step": 2520
    },
    {
      "epoch": 1.8979744936234058,
      "grad_norm": 0.5347327589988708,
      "learning_rate": 1.620405101275319e-05,
      "loss": 0.0513,
      "step": 2530
    },
    {
      "epoch": 1.905476369092273,
      "grad_norm": 3.871838331222534,
      "learning_rate": 1.6189047261815457e-05,
      "loss": 0.0699,
      "step": 2540
    },
    {
      "epoch": 1.9129782445611403,
      "grad_norm": 1.9557117223739624,
      "learning_rate": 1.6174043510877723e-05,
      "loss": 0.0522,
      "step": 2550
    },
    {
      "epoch": 1.9204801200300075,
      "grad_norm": 4.518356800079346,
      "learning_rate": 1.615903975993999e-05,
      "loss": 0.0365,
      "step": 2560
    },
    {
      "epoch": 1.9279819954988748,
      "grad_norm": 1.8230513334274292,
      "learning_rate": 1.6144036009002254e-05,
      "loss": 0.0397,
      "step": 2570
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.13715751469135284,
      "learning_rate": 1.6129032258064517e-05,
      "loss": 0.0328,
      "step": 2580
    },
    {
      "epoch": 1.9429857464366092,
      "grad_norm": 4.212172031402588,
      "learning_rate": 1.6114028507126783e-05,
      "loss": 0.0434,
      "step": 2590
    },
    {
      "epoch": 1.9504876219054763,
      "grad_norm": 3.279669761657715,
      "learning_rate": 1.609902475618905e-05,
      "loss": 0.0473,
      "step": 2600
    },
    {
      "epoch": 1.9579894973743435,
      "grad_norm": 2.1795878410339355,
      "learning_rate": 1.6084021005251314e-05,
      "loss": 0.0512,
      "step": 2610
    },
    {
      "epoch": 1.9654913728432108,
      "grad_norm": 1.9604406356811523,
      "learning_rate": 1.606901725431358e-05,
      "loss": 0.0552,
      "step": 2620
    },
    {
      "epoch": 1.972993248312078,
      "grad_norm": 3.8537368774414062,
      "learning_rate": 1.6054013503375846e-05,
      "loss": 0.0388,
      "step": 2630
    },
    {
      "epoch": 1.9804951237809454,
      "grad_norm": 1.4465796947479248,
      "learning_rate": 1.603900975243811e-05,
      "loss": 0.0453,
      "step": 2640
    },
    {
      "epoch": 1.9879969992498125,
      "grad_norm": 1.629640817642212,
      "learning_rate": 1.6024006001500377e-05,
      "loss": 0.056,
      "step": 2650
    },
    {
      "epoch": 1.9954988747186797,
      "grad_norm": 2.7116377353668213,
      "learning_rate": 1.6009002250562643e-05,
      "loss": 0.0521,
      "step": 2660
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9845800524934383,
      "eval_f1": 0.9406648898863795,
      "eval_loss": 0.0386236235499382,
      "eval_precision": 0.9386898096304591,
      "eval_recall": 0.942648299128479,
      "eval_runtime": 464.1867,
      "eval_samples_per_second": 59.099,
      "eval_steps_per_second": 2.465,
      "step": 2666
    },
    {
      "epoch": 2.003000750187547,
      "grad_norm": 10.316216468811035,
      "learning_rate": 1.599399849962491e-05,
      "loss": 0.0516,
      "step": 2670
    },
    {
      "epoch": 2.010502625656414,
      "grad_norm": 0.6382861733436584,
      "learning_rate": 1.5978994748687175e-05,
      "loss": 0.0326,
      "step": 2680
    },
    {
      "epoch": 2.018004501125281,
      "grad_norm": 5.7916765213012695,
      "learning_rate": 1.596399099774944e-05,
      "loss": 0.0345,
      "step": 2690
    },
    {
      "epoch": 2.0255063765941483,
      "grad_norm": 6.5475921630859375,
      "learning_rate": 1.5948987246811703e-05,
      "loss": 0.0411,
      "step": 2700
    },
    {
      "epoch": 2.033008252063016,
      "grad_norm": 5.435701847076416,
      "learning_rate": 1.593398349587397e-05,
      "loss": 0.0259,
      "step": 2710
    },
    {
      "epoch": 2.040510127531883,
      "grad_norm": 2.82680344581604,
      "learning_rate": 1.5918979744936235e-05,
      "loss": 0.048,
      "step": 2720
    },
    {
      "epoch": 2.0480120030007503,
      "grad_norm": 2.5833687782287598,
      "learning_rate": 1.59039759939985e-05,
      "loss": 0.0435,
      "step": 2730
    },
    {
      "epoch": 2.0555138784696174,
      "grad_norm": 7.082991123199463,
      "learning_rate": 1.5888972243060766e-05,
      "loss": 0.0459,
      "step": 2740
    },
    {
      "epoch": 2.0630157539384846,
      "grad_norm": 1.681162714958191,
      "learning_rate": 1.5873968492123032e-05,
      "loss": 0.0369,
      "step": 2750
    },
    {
      "epoch": 2.0705176294073517,
      "grad_norm": 2.6380279064178467,
      "learning_rate": 1.5858964741185298e-05,
      "loss": 0.027,
      "step": 2760
    },
    {
      "epoch": 2.078019504876219,
      "grad_norm": 2.321885108947754,
      "learning_rate": 1.5843960990247564e-05,
      "loss": 0.0516,
      "step": 2770
    },
    {
      "epoch": 2.085521380345086,
      "grad_norm": 5.645909786224365,
      "learning_rate": 1.582895723930983e-05,
      "loss": 0.0514,
      "step": 2780
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 2.36405348777771,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 0.0336,
      "step": 2790
    },
    {
      "epoch": 2.100525131282821,
      "grad_norm": 1.4971758127212524,
      "learning_rate": 1.5798949737434358e-05,
      "loss": 0.0409,
      "step": 2800
    },
    {
      "epoch": 2.108027006751688,
      "grad_norm": 1.0770702362060547,
      "learning_rate": 1.5783945986496623e-05,
      "loss": 0.0344,
      "step": 2810
    },
    {
      "epoch": 2.115528882220555,
      "grad_norm": 2.4305810928344727,
      "learning_rate": 1.576894223555889e-05,
      "loss": 0.0273,
      "step": 2820
    },
    {
      "epoch": 2.1230307576894223,
      "grad_norm": 1.814011573791504,
      "learning_rate": 1.5753938484621155e-05,
      "loss": 0.0478,
      "step": 2830
    },
    {
      "epoch": 2.1305326331582894,
      "grad_norm": 1.1323615312576294,
      "learning_rate": 1.573893473368342e-05,
      "loss": 0.0272,
      "step": 2840
    },
    {
      "epoch": 2.1380345086271566,
      "grad_norm": 2.357553243637085,
      "learning_rate": 1.5723930982745687e-05,
      "loss": 0.032,
      "step": 2850
    },
    {
      "epoch": 2.145536384096024,
      "grad_norm": 1.4704302549362183,
      "learning_rate": 1.5708927231807952e-05,
      "loss": 0.0405,
      "step": 2860
    },
    {
      "epoch": 2.1530382595648914,
      "grad_norm": 1.662302017211914,
      "learning_rate": 1.5693923480870218e-05,
      "loss": 0.049,
      "step": 2870
    },
    {
      "epoch": 2.1605401350337585,
      "grad_norm": 2.389399290084839,
      "learning_rate": 1.5678919729932484e-05,
      "loss": 0.0634,
      "step": 2880
    },
    {
      "epoch": 2.1680420105026257,
      "grad_norm": 1.1935491561889648,
      "learning_rate": 1.566391597899475e-05,
      "loss": 0.0438,
      "step": 2890
    },
    {
      "epoch": 2.175543885971493,
      "grad_norm": 2.1335082054138184,
      "learning_rate": 1.5648912228057016e-05,
      "loss": 0.0291,
      "step": 2900
    },
    {
      "epoch": 2.18304576144036,
      "grad_norm": 2.186204433441162,
      "learning_rate": 1.563390847711928e-05,
      "loss": 0.0595,
      "step": 2910
    },
    {
      "epoch": 2.190547636909227,
      "grad_norm": 2.132183313369751,
      "learning_rate": 1.5618904726181547e-05,
      "loss": 0.0409,
      "step": 2920
    },
    {
      "epoch": 2.1980495123780943,
      "grad_norm": 2.5386884212493896,
      "learning_rate": 1.5603900975243813e-05,
      "loss": 0.0554,
      "step": 2930
    },
    {
      "epoch": 2.205551387846962,
      "grad_norm": 1.6704049110412598,
      "learning_rate": 1.558889722430608e-05,
      "loss": 0.0361,
      "step": 2940
    },
    {
      "epoch": 2.213053263315829,
      "grad_norm": 0.23065906763076782,
      "learning_rate": 1.5573893473368345e-05,
      "loss": 0.0306,
      "step": 2950
    },
    {
      "epoch": 2.2205551387846962,
      "grad_norm": 0.364637166261673,
      "learning_rate": 1.5558889722430607e-05,
      "loss": 0.0196,
      "step": 2960
    },
    {
      "epoch": 2.2280570142535634,
      "grad_norm": 9.004663467407227,
      "learning_rate": 1.5543885971492873e-05,
      "loss": 0.0444,
      "step": 2970
    },
    {
      "epoch": 2.2355588897224306,
      "grad_norm": 0.27901390194892883,
      "learning_rate": 1.552888222055514e-05,
      "loss": 0.037,
      "step": 2980
    },
    {
      "epoch": 2.2430607651912977,
      "grad_norm": 1.8426580429077148,
      "learning_rate": 1.5513878469617404e-05,
      "loss": 0.0386,
      "step": 2990
    },
    {
      "epoch": 2.250562640660165,
      "grad_norm": 0.7636155486106873,
      "learning_rate": 1.549887471867967e-05,
      "loss": 0.0417,
      "step": 3000
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 1.2907603979110718,
      "learning_rate": 1.5483870967741936e-05,
      "loss": 0.0329,
      "step": 3010
    },
    {
      "epoch": 2.2655663915978996,
      "grad_norm": 2.058093786239624,
      "learning_rate": 1.5468867216804202e-05,
      "loss": 0.0437,
      "step": 3020
    },
    {
      "epoch": 2.273068267066767,
      "grad_norm": 1.9033123254776,
      "learning_rate": 1.5453863465866468e-05,
      "loss": 0.034,
      "step": 3030
    },
    {
      "epoch": 2.280570142535634,
      "grad_norm": 0.7539263367652893,
      "learning_rate": 1.5438859714928733e-05,
      "loss": 0.0297,
      "step": 3040
    },
    {
      "epoch": 2.288072018004501,
      "grad_norm": 2.687439203262329,
      "learning_rate": 1.5423855963991e-05,
      "loss": 0.0285,
      "step": 3050
    },
    {
      "epoch": 2.2955738934733683,
      "grad_norm": 2.541773557662964,
      "learning_rate": 1.5408852213053265e-05,
      "loss": 0.0273,
      "step": 3060
    },
    {
      "epoch": 2.3030757689422354,
      "grad_norm": 4.174377918243408,
      "learning_rate": 1.539384846211553e-05,
      "loss": 0.0326,
      "step": 3070
    },
    {
      "epoch": 2.3105776444111026,
      "grad_norm": 1.1864453554153442,
      "learning_rate": 1.5378844711177797e-05,
      "loss": 0.0305,
      "step": 3080
    },
    {
      "epoch": 2.31807951987997,
      "grad_norm": 2.0533175468444824,
      "learning_rate": 1.5363840960240062e-05,
      "loss": 0.0397,
      "step": 3090
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 3.5559213161468506,
      "learning_rate": 1.5348837209302328e-05,
      "loss": 0.0385,
      "step": 3100
    },
    {
      "epoch": 2.3330832708177045,
      "grad_norm": 2.636235237121582,
      "learning_rate": 1.5333833458364594e-05,
      "loss": 0.0393,
      "step": 3110
    },
    {
      "epoch": 2.3405851462865717,
      "grad_norm": 1.6041643619537354,
      "learning_rate": 1.531882970742686e-05,
      "loss": 0.0296,
      "step": 3120
    },
    {
      "epoch": 2.348087021755439,
      "grad_norm": 1.2112478017807007,
      "learning_rate": 1.5303825956489126e-05,
      "loss": 0.0267,
      "step": 3130
    },
    {
      "epoch": 2.355588897224306,
      "grad_norm": 1.3638675212860107,
      "learning_rate": 1.528882220555139e-05,
      "loss": 0.0325,
      "step": 3140
    },
    {
      "epoch": 2.363090772693173,
      "grad_norm": 1.6249136924743652,
      "learning_rate": 1.5273818454613654e-05,
      "loss": 0.0488,
      "step": 3150
    },
    {
      "epoch": 2.3705926481620407,
      "grad_norm": 0.23571844398975372,
      "learning_rate": 1.525881470367592e-05,
      "loss": 0.0338,
      "step": 3160
    },
    {
      "epoch": 2.378094523630908,
      "grad_norm": 1.4596682786941528,
      "learning_rate": 1.5243810952738185e-05,
      "loss": 0.0366,
      "step": 3170
    },
    {
      "epoch": 2.385596399099775,
      "grad_norm": 2.315741539001465,
      "learning_rate": 1.5228807201800451e-05,
      "loss": 0.0347,
      "step": 3180
    },
    {
      "epoch": 2.393098274568642,
      "grad_norm": 0.5073005557060242,
      "learning_rate": 1.5213803450862717e-05,
      "loss": 0.0219,
      "step": 3190
    },
    {
      "epoch": 2.4006001500375094,
      "grad_norm": 0.29408398270606995,
      "learning_rate": 1.5198799699924983e-05,
      "loss": 0.0286,
      "step": 3200
    },
    {
      "epoch": 2.4081020255063765,
      "grad_norm": 1.8134431838989258,
      "learning_rate": 1.5183795948987249e-05,
      "loss": 0.0158,
      "step": 3210
    },
    {
      "epoch": 2.4156039009752437,
      "grad_norm": 3.5414960384368896,
      "learning_rate": 1.5168792198049513e-05,
      "loss": 0.0359,
      "step": 3220
    },
    {
      "epoch": 2.423105776444111,
      "grad_norm": 0.5239112973213196,
      "learning_rate": 1.5153788447111778e-05,
      "loss": 0.0296,
      "step": 3230
    },
    {
      "epoch": 2.430607651912978,
      "grad_norm": 6.8237624168396,
      "learning_rate": 1.5138784696174044e-05,
      "loss": 0.0318,
      "step": 3240
    },
    {
      "epoch": 2.4381095273818456,
      "grad_norm": 2.3364388942718506,
      "learning_rate": 1.512378094523631e-05,
      "loss": 0.0478,
      "step": 3250
    },
    {
      "epoch": 2.4456114028507128,
      "grad_norm": 0.5904058814048767,
      "learning_rate": 1.5108777194298576e-05,
      "loss": 0.0196,
      "step": 3260
    },
    {
      "epoch": 2.45311327831958,
      "grad_norm": 3.1844606399536133,
      "learning_rate": 1.5093773443360842e-05,
      "loss": 0.0235,
      "step": 3270
    },
    {
      "epoch": 2.460615153788447,
      "grad_norm": 0.8868354558944702,
      "learning_rate": 1.5078769692423107e-05,
      "loss": 0.0341,
      "step": 3280
    },
    {
      "epoch": 2.4681170292573142,
      "grad_norm": 0.2761109173297882,
      "learning_rate": 1.5063765941485373e-05,
      "loss": 0.0343,
      "step": 3290
    },
    {
      "epoch": 2.4756189047261814,
      "grad_norm": 1.606582760810852,
      "learning_rate": 1.5048762190547639e-05,
      "loss": 0.0359,
      "step": 3300
    },
    {
      "epoch": 2.4831207801950486,
      "grad_norm": 3.5566964149475098,
      "learning_rate": 1.5033758439609905e-05,
      "loss": 0.0302,
      "step": 3310
    },
    {
      "epoch": 2.490622655663916,
      "grad_norm": 3.5205085277557373,
      "learning_rate": 1.501875468867217e-05,
      "loss": 0.0221,
      "step": 3320
    },
    {
      "epoch": 2.4981245311327833,
      "grad_norm": 1.5221970081329346,
      "learning_rate": 1.5003750937734436e-05,
      "loss": 0.0447,
      "step": 3330
    },
    {
      "epoch": 2.5056264066016505,
      "grad_norm": 4.347322940826416,
      "learning_rate": 1.4988747186796699e-05,
      "loss": 0.0345,
      "step": 3340
    },
    {
      "epoch": 2.5131282820705176,
      "grad_norm": 2.4958817958831787,
      "learning_rate": 1.4973743435858965e-05,
      "loss": 0.0291,
      "step": 3350
    },
    {
      "epoch": 2.520630157539385,
      "grad_norm": 2.0172359943389893,
      "learning_rate": 1.495873968492123e-05,
      "loss": 0.0322,
      "step": 3360
    },
    {
      "epoch": 2.528132033008252,
      "grad_norm": 0.8929703235626221,
      "learning_rate": 1.4943735933983496e-05,
      "loss": 0.0286,
      "step": 3370
    },
    {
      "epoch": 2.535633908477119,
      "grad_norm": 0.7499428987503052,
      "learning_rate": 1.4928732183045762e-05,
      "loss": 0.0436,
      "step": 3380
    },
    {
      "epoch": 2.5431357839459867,
      "grad_norm": 4.541411876678467,
      "learning_rate": 1.4913728432108028e-05,
      "loss": 0.0521,
      "step": 3390
    },
    {
      "epoch": 2.550637659414854,
      "grad_norm": 2.4147183895111084,
      "learning_rate": 1.4898724681170294e-05,
      "loss": 0.0663,
      "step": 3400
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 9.47775650024414,
      "learning_rate": 1.488372093023256e-05,
      "loss": 0.0498,
      "step": 3410
    },
    {
      "epoch": 2.565641410352588,
      "grad_norm": 1.876120686531067,
      "learning_rate": 1.4868717179294825e-05,
      "loss": 0.0335,
      "step": 3420
    },
    {
      "epoch": 2.5731432858214554,
      "grad_norm": 9.591005325317383,
      "learning_rate": 1.4853713428357091e-05,
      "loss": 0.0348,
      "step": 3430
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 2.70548677444458,
      "learning_rate": 1.4838709677419357e-05,
      "loss": 0.0321,
      "step": 3440
    },
    {
      "epoch": 2.5881470367591897,
      "grad_norm": 1.6923613548278809,
      "learning_rate": 1.4823705926481623e-05,
      "loss": 0.0429,
      "step": 3450
    },
    {
      "epoch": 2.5956489122280573,
      "grad_norm": 3.495720624923706,
      "learning_rate": 1.4808702175543887e-05,
      "loss": 0.0348,
      "step": 3460
    },
    {
      "epoch": 2.603150787696924,
      "grad_norm": 5.349932670593262,
      "learning_rate": 1.4793698424606153e-05,
      "loss": 0.0201,
      "step": 3470
    },
    {
      "epoch": 2.6106526631657916,
      "grad_norm": 2.130025625228882,
      "learning_rate": 1.4778694673668418e-05,
      "loss": 0.0336,
      "step": 3480
    },
    {
      "epoch": 2.6181545386346587,
      "grad_norm": 1.6102367639541626,
      "learning_rate": 1.4763690922730684e-05,
      "loss": 0.0483,
      "step": 3490
    },
    {
      "epoch": 2.625656414103526,
      "grad_norm": 4.139683723449707,
      "learning_rate": 1.474868717179295e-05,
      "loss": 0.0266,
      "step": 3500
    },
    {
      "epoch": 2.633158289572393,
      "grad_norm": 2.3025901317596436,
      "learning_rate": 1.4733683420855216e-05,
      "loss": 0.0491,
      "step": 3510
    },
    {
      "epoch": 2.64066016504126,
      "grad_norm": 0.5024149417877197,
      "learning_rate": 1.4718679669917482e-05,
      "loss": 0.0177,
      "step": 3520
    },
    {
      "epoch": 2.6481620405101274,
      "grad_norm": 1.1645863056182861,
      "learning_rate": 1.4703675918979746e-05,
      "loss": 0.0208,
      "step": 3530
    },
    {
      "epoch": 2.6556639159789945,
      "grad_norm": 5.232676029205322,
      "learning_rate": 1.4688672168042011e-05,
      "loss": 0.0251,
      "step": 3540
    },
    {
      "epoch": 2.663165791447862,
      "grad_norm": 2.669278621673584,
      "learning_rate": 1.4673668417104277e-05,
      "loss": 0.0296,
      "step": 3550
    },
    {
      "epoch": 2.6706676669167293,
      "grad_norm": 0.2045401781797409,
      "learning_rate": 1.4658664666166541e-05,
      "loss": 0.0363,
      "step": 3560
    },
    {
      "epoch": 2.6781695423855965,
      "grad_norm": 3.3679609298706055,
      "learning_rate": 1.4643660915228807e-05,
      "loss": 0.0439,
      "step": 3570
    },
    {
      "epoch": 2.6856714178544636,
      "grad_norm": 5.376452445983887,
      "learning_rate": 1.4628657164291073e-05,
      "loss": 0.0267,
      "step": 3580
    },
    {
      "epoch": 2.6931732933233308,
      "grad_norm": 3.7379279136657715,
      "learning_rate": 1.4613653413353339e-05,
      "loss": 0.0659,
      "step": 3590
    },
    {
      "epoch": 2.700675168792198,
      "grad_norm": 2.092829465866089,
      "learning_rate": 1.4598649662415605e-05,
      "loss": 0.0287,
      "step": 3600
    },
    {
      "epoch": 2.708177044261065,
      "grad_norm": 0.3663555979728699,
      "learning_rate": 1.458364591147787e-05,
      "loss": 0.0384,
      "step": 3610
    },
    {
      "epoch": 2.7156789197299327,
      "grad_norm": 4.6582865715026855,
      "learning_rate": 1.4568642160540136e-05,
      "loss": 0.0284,
      "step": 3620
    },
    {
      "epoch": 2.7231807951988,
      "grad_norm": 2.565427541732788,
      "learning_rate": 1.4553638409602402e-05,
      "loss": 0.0412,
      "step": 3630
    },
    {
      "epoch": 2.730682670667667,
      "grad_norm": 3.3835208415985107,
      "learning_rate": 1.4538634658664668e-05,
      "loss": 0.0451,
      "step": 3640
    },
    {
      "epoch": 2.738184546136534,
      "grad_norm": 2.50637149810791,
      "learning_rate": 1.4523630907726934e-05,
      "loss": 0.0449,
      "step": 3650
    },
    {
      "epoch": 2.7456864216054013,
      "grad_norm": 5.735208988189697,
      "learning_rate": 1.45086271567892e-05,
      "loss": 0.0631,
      "step": 3660
    },
    {
      "epoch": 2.7531882970742685,
      "grad_norm": 3.3424575328826904,
      "learning_rate": 1.4493623405851465e-05,
      "loss": 0.024,
      "step": 3670
    },
    {
      "epoch": 2.7606901725431356,
      "grad_norm": 0.13104330003261566,
      "learning_rate": 1.4478619654913731e-05,
      "loss": 0.0325,
      "step": 3680
    },
    {
      "epoch": 2.7681920480120032,
      "grad_norm": 0.411119282245636,
      "learning_rate": 1.4463615903975997e-05,
      "loss": 0.0315,
      "step": 3690
    },
    {
      "epoch": 2.77569392348087,
      "grad_norm": 1.7853392362594604,
      "learning_rate": 1.4448612153038261e-05,
      "loss": 0.036,
      "step": 3700
    },
    {
      "epoch": 2.7831957989497376,
      "grad_norm": 3.8511810302734375,
      "learning_rate": 1.4433608402100527e-05,
      "loss": 0.0558,
      "step": 3710
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 4.9929609298706055,
      "learning_rate": 1.441860465116279e-05,
      "loss": 0.0271,
      "step": 3720
    },
    {
      "epoch": 2.798199549887472,
      "grad_norm": 1.766451358795166,
      "learning_rate": 1.4403600900225057e-05,
      "loss": 0.0391,
      "step": 3730
    },
    {
      "epoch": 2.805701425356339,
      "grad_norm": 0.751970648765564,
      "learning_rate": 1.4388597149287322e-05,
      "loss": 0.0325,
      "step": 3740
    },
    {
      "epoch": 2.813203300825206,
      "grad_norm": 2.9737775325775146,
      "learning_rate": 1.4373593398349588e-05,
      "loss": 0.0284,
      "step": 3750
    },
    {
      "epoch": 2.8207051762940734,
      "grad_norm": 2.7168073654174805,
      "learning_rate": 1.4358589647411854e-05,
      "loss": 0.0213,
      "step": 3760
    },
    {
      "epoch": 2.8282070517629405,
      "grad_norm": 3.0097734928131104,
      "learning_rate": 1.434358589647412e-05,
      "loss": 0.0542,
      "step": 3770
    },
    {
      "epoch": 2.835708927231808,
      "grad_norm": 5.119475841522217,
      "learning_rate": 1.4328582145536386e-05,
      "loss": 0.0432,
      "step": 3780
    },
    {
      "epoch": 2.8432108027006753,
      "grad_norm": 2.132486343383789,
      "learning_rate": 1.4313578394598651e-05,
      "loss": 0.033,
      "step": 3790
    },
    {
      "epoch": 2.8507126781695424,
      "grad_norm": 4.556999206542969,
      "learning_rate": 1.4298574643660915e-05,
      "loss": 0.04,
      "step": 3800
    },
    {
      "epoch": 2.8582145536384096,
      "grad_norm": 1.5105379819869995,
      "learning_rate": 1.4283570892723181e-05,
      "loss": 0.0569,
      "step": 3810
    },
    {
      "epoch": 2.8657164291072768,
      "grad_norm": 6.098326683044434,
      "learning_rate": 1.4268567141785447e-05,
      "loss": 0.0377,
      "step": 3820
    },
    {
      "epoch": 2.873218304576144,
      "grad_norm": 5.1313796043396,
      "learning_rate": 1.4253563390847713e-05,
      "loss": 0.03,
      "step": 3830
    },
    {
      "epoch": 2.880720180045011,
      "grad_norm": 2.4393577575683594,
      "learning_rate": 1.4238559639909979e-05,
      "loss": 0.0495,
      "step": 3840
    },
    {
      "epoch": 2.8882220555138787,
      "grad_norm": 13.598173141479492,
      "learning_rate": 1.4223555888972244e-05,
      "loss": 0.0423,
      "step": 3850
    },
    {
      "epoch": 2.895723930982746,
      "grad_norm": 0.34143853187561035,
      "learning_rate": 1.420855213803451e-05,
      "loss": 0.0196,
      "step": 3860
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.4366679787635803,
      "learning_rate": 1.4193548387096776e-05,
      "loss": 0.0209,
      "step": 3870
    },
    {
      "epoch": 2.91072768192048,
      "grad_norm": 7.564846515655518,
      "learning_rate": 1.4178544636159042e-05,
      "loss": 0.0438,
      "step": 3880
    },
    {
      "epoch": 2.9182295573893473,
      "grad_norm": 1.499192237854004,
      "learning_rate": 1.4163540885221308e-05,
      "loss": 0.0298,
      "step": 3890
    },
    {
      "epoch": 2.9257314328582145,
      "grad_norm": 1.2739264965057373,
      "learning_rate": 1.4148537134283573e-05,
      "loss": 0.0359,
      "step": 3900
    },
    {
      "epoch": 2.9332333083270816,
      "grad_norm": 2.110804796218872,
      "learning_rate": 1.4133533383345836e-05,
      "loss": 0.023,
      "step": 3910
    },
    {
      "epoch": 2.9407351837959492,
      "grad_norm": 4.363667011260986,
      "learning_rate": 1.4118529632408102e-05,
      "loss": 0.0278,
      "step": 3920
    },
    {
      "epoch": 2.948237059264816,
      "grad_norm": 1.8865182399749756,
      "learning_rate": 1.4103525881470367e-05,
      "loss": 0.0424,
      "step": 3930
    },
    {
      "epoch": 2.9557389347336835,
      "grad_norm": 0.8304610252380371,
      "learning_rate": 1.4088522130532633e-05,
      "loss": 0.0284,
      "step": 3940
    },
    {
      "epoch": 2.9632408102025507,
      "grad_norm": 2.2770888805389404,
      "learning_rate": 1.4073518379594899e-05,
      "loss": 0.0463,
      "step": 3950
    },
    {
      "epoch": 2.970742685671418,
      "grad_norm": 0.8960526585578918,
      "learning_rate": 1.4058514628657165e-05,
      "loss": 0.0274,
      "step": 3960
    },
    {
      "epoch": 2.978244561140285,
      "grad_norm": 0.6716572046279907,
      "learning_rate": 1.404351087771943e-05,
      "loss": 0.0321,
      "step": 3970
    },
    {
      "epoch": 2.985746436609152,
      "grad_norm": 7.389084339141846,
      "learning_rate": 1.4028507126781696e-05,
      "loss": 0.0323,
      "step": 3980
    },
    {
      "epoch": 2.99324831207802,
      "grad_norm": 0.8055776357650757,
      "learning_rate": 1.4013503375843962e-05,
      "loss": 0.027,
      "step": 3990
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9887357830271216,
      "eval_f1": 0.9568977542195565,
      "eval_loss": 0.0312141552567482,
      "eval_precision": 0.9496124031007752,
      "eval_recall": 0.9642957548495924,
      "eval_runtime": 467.054,
      "eval_samples_per_second": 58.736,
      "eval_steps_per_second": 2.449,
      "step": 3999
    },
    {
      "epoch": 3.000750187546887,
      "grad_norm": 0.7391763925552368,
      "learning_rate": 1.3998499624906228e-05,
      "loss": 0.0307,
      "step": 4000
    },
    {
      "epoch": 3.008252063015754,
      "grad_norm": 0.7178274393081665,
      "learning_rate": 1.3983495873968494e-05,
      "loss": 0.0155,
      "step": 4010
    },
    {
      "epoch": 3.0157539384846213,
      "grad_norm": 0.12303858995437622,
      "learning_rate": 1.396849212303076e-05,
      "loss": 0.0337,
      "step": 4020
    },
    {
      "epoch": 3.0232558139534884,
      "grad_norm": 6.810923099517822,
      "learning_rate": 1.3953488372093025e-05,
      "loss": 0.0282,
      "step": 4030
    },
    {
      "epoch": 3.0307576894223556,
      "grad_norm": 2.087679386138916,
      "learning_rate": 1.3938484621155291e-05,
      "loss": 0.0469,
      "step": 4040
    },
    {
      "epoch": 3.0382595648912227,
      "grad_norm": 5.3263163566589355,
      "learning_rate": 1.3923480870217555e-05,
      "loss": 0.0527,
      "step": 4050
    },
    {
      "epoch": 3.04576144036009,
      "grad_norm": 1.5169341564178467,
      "learning_rate": 1.3908477119279821e-05,
      "loss": 0.0179,
      "step": 4060
    },
    {
      "epoch": 3.053263315828957,
      "grad_norm": 1.5043017864227295,
      "learning_rate": 1.3893473368342087e-05,
      "loss": 0.0335,
      "step": 4070
    },
    {
      "epoch": 3.0607651912978247,
      "grad_norm": 2.1653995513916016,
      "learning_rate": 1.3878469617404353e-05,
      "loss": 0.0399,
      "step": 4080
    },
    {
      "epoch": 3.068267066766692,
      "grad_norm": 2.901643991470337,
      "learning_rate": 1.3863465866466619e-05,
      "loss": 0.032,
      "step": 4090
    },
    {
      "epoch": 3.075768942235559,
      "grad_norm": 1.1421496868133545,
      "learning_rate": 1.3848462115528883e-05,
      "loss": 0.0212,
      "step": 4100
    },
    {
      "epoch": 3.083270817704426,
      "grad_norm": 0.954883337020874,
      "learning_rate": 1.3833458364591148e-05,
      "loss": 0.0255,
      "step": 4110
    },
    {
      "epoch": 3.0907726931732933,
      "grad_norm": 0.3420669734477997,
      "learning_rate": 1.3818454613653414e-05,
      "loss": 0.0245,
      "step": 4120
    },
    {
      "epoch": 3.0982745686421604,
      "grad_norm": 5.26275634765625,
      "learning_rate": 1.380345086271568e-05,
      "loss": 0.02,
      "step": 4130
    },
    {
      "epoch": 3.1057764441110276,
      "grad_norm": 0.5868914723396301,
      "learning_rate": 1.3788447111777946e-05,
      "loss": 0.0227,
      "step": 4140
    },
    {
      "epoch": 3.1132783195798948,
      "grad_norm": 1.319393277168274,
      "learning_rate": 1.377344336084021e-05,
      "loss": 0.0182,
      "step": 4150
    },
    {
      "epoch": 3.1207801950487624,
      "grad_norm": 0.47139760851860046,
      "learning_rate": 1.3758439609902476e-05,
      "loss": 0.0295,
      "step": 4160
    },
    {
      "epoch": 3.1282820705176295,
      "grad_norm": 0.7834799289703369,
      "learning_rate": 1.3743435858964742e-05,
      "loss": 0.0169,
      "step": 4170
    },
    {
      "epoch": 3.1357839459864967,
      "grad_norm": 4.343301773071289,
      "learning_rate": 1.3728432108027007e-05,
      "loss": 0.0193,
      "step": 4180
    },
    {
      "epoch": 3.143285821455364,
      "grad_norm": 1.6963359117507935,
      "learning_rate": 1.3713428357089273e-05,
      "loss": 0.032,
      "step": 4190
    },
    {
      "epoch": 3.150787696924231,
      "grad_norm": 7.042456150054932,
      "learning_rate": 1.3698424606151539e-05,
      "loss": 0.0447,
      "step": 4200
    },
    {
      "epoch": 3.158289572393098,
      "grad_norm": 0.2494286298751831,
      "learning_rate": 1.3683420855213805e-05,
      "loss": 0.0114,
      "step": 4210
    },
    {
      "epoch": 3.1657914478619653,
      "grad_norm": 4.979002952575684,
      "learning_rate": 1.366841710427607e-05,
      "loss": 0.0295,
      "step": 4220
    },
    {
      "epoch": 3.173293323330833,
      "grad_norm": 0.4785902500152588,
      "learning_rate": 1.3653413353338336e-05,
      "loss": 0.0281,
      "step": 4230
    },
    {
      "epoch": 3.1807951987997,
      "grad_norm": 0.47747504711151123,
      "learning_rate": 1.3638409602400602e-05,
      "loss": 0.0182,
      "step": 4240
    },
    {
      "epoch": 3.1882970742685672,
      "grad_norm": 1.2891414165496826,
      "learning_rate": 1.3623405851462868e-05,
      "loss": 0.0293,
      "step": 4250
    },
    {
      "epoch": 3.1957989497374344,
      "grad_norm": 3.0585756301879883,
      "learning_rate": 1.3608402100525134e-05,
      "loss": 0.0205,
      "step": 4260
    },
    {
      "epoch": 3.2033008252063015,
      "grad_norm": 2.112379789352417,
      "learning_rate": 1.35933983495874e-05,
      "loss": 0.0183,
      "step": 4270
    },
    {
      "epoch": 3.2108027006751687,
      "grad_norm": 0.02882533334195614,
      "learning_rate": 1.3578394598649665e-05,
      "loss": 0.0455,
      "step": 4280
    },
    {
      "epoch": 3.218304576144036,
      "grad_norm": 0.4727350175380707,
      "learning_rate": 1.3563390847711928e-05,
      "loss": 0.0222,
      "step": 4290
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 1.0748785734176636,
      "learning_rate": 1.3548387096774194e-05,
      "loss": 0.0263,
      "step": 4300
    },
    {
      "epoch": 3.2333083270817706,
      "grad_norm": 0.23571538925170898,
      "learning_rate": 1.353338334583646e-05,
      "loss": 0.0237,
      "step": 4310
    },
    {
      "epoch": 3.240810202550638,
      "grad_norm": 2.0714566707611084,
      "learning_rate": 1.3518379594898725e-05,
      "loss": 0.0244,
      "step": 4320
    },
    {
      "epoch": 3.248312078019505,
      "grad_norm": 2.083897352218628,
      "learning_rate": 1.3503375843960991e-05,
      "loss": 0.0289,
      "step": 4330
    },
    {
      "epoch": 3.255813953488372,
      "grad_norm": 0.6049959659576416,
      "learning_rate": 1.3488372093023257e-05,
      "loss": 0.0263,
      "step": 4340
    },
    {
      "epoch": 3.2633158289572393,
      "grad_norm": 4.355706214904785,
      "learning_rate": 1.3473368342085523e-05,
      "loss": 0.0273,
      "step": 4350
    },
    {
      "epoch": 3.2708177044261064,
      "grad_norm": 4.280598163604736,
      "learning_rate": 1.3458364591147788e-05,
      "loss": 0.0344,
      "step": 4360
    },
    {
      "epoch": 3.2783195798949736,
      "grad_norm": 1.1553282737731934,
      "learning_rate": 1.3443360840210054e-05,
      "loss": 0.0263,
      "step": 4370
    },
    {
      "epoch": 3.285821455363841,
      "grad_norm": 0.13519152998924255,
      "learning_rate": 1.342835708927232e-05,
      "loss": 0.0206,
      "step": 4380
    },
    {
      "epoch": 3.2933233308327083,
      "grad_norm": 1.5635348558425903,
      "learning_rate": 1.3413353338334584e-05,
      "loss": 0.0278,
      "step": 4390
    },
    {
      "epoch": 3.3008252063015755,
      "grad_norm": 2.0563864707946777,
      "learning_rate": 1.339834958739685e-05,
      "loss": 0.0365,
      "step": 4400
    },
    {
      "epoch": 3.3083270817704427,
      "grad_norm": 4.935530185699463,
      "learning_rate": 1.3383345836459116e-05,
      "loss": 0.0365,
      "step": 4410
    },
    {
      "epoch": 3.31582895723931,
      "grad_norm": 6.421379089355469,
      "learning_rate": 1.3368342085521381e-05,
      "loss": 0.0318,
      "step": 4420
    },
    {
      "epoch": 3.323330832708177,
      "grad_norm": 0.8245556950569153,
      "learning_rate": 1.3353338334583647e-05,
      "loss": 0.0265,
      "step": 4430
    },
    {
      "epoch": 3.330832708177044,
      "grad_norm": 1.0180925130844116,
      "learning_rate": 1.3338334583645913e-05,
      "loss": 0.0184,
      "step": 4440
    },
    {
      "epoch": 3.3383345836459113,
      "grad_norm": 1.162093162536621,
      "learning_rate": 1.3323330832708179e-05,
      "loss": 0.0413,
      "step": 4450
    },
    {
      "epoch": 3.3458364591147784,
      "grad_norm": 1.6220325231552124,
      "learning_rate": 1.3308327081770445e-05,
      "loss": 0.0214,
      "step": 4460
    },
    {
      "epoch": 3.353338334583646,
      "grad_norm": 0.34346845746040344,
      "learning_rate": 1.329332333083271e-05,
      "loss": 0.0114,
      "step": 4470
    },
    {
      "epoch": 3.360840210052513,
      "grad_norm": 0.5781481266021729,
      "learning_rate": 1.3278319579894975e-05,
      "loss": 0.0159,
      "step": 4480
    },
    {
      "epoch": 3.3683420855213804,
      "grad_norm": 5.959458827972412,
      "learning_rate": 1.3263315828957239e-05,
      "loss": 0.0345,
      "step": 4490
    },
    {
      "epoch": 3.3758439609902475,
      "grad_norm": 1.9757219552993774,
      "learning_rate": 1.3248312078019504e-05,
      "loss": 0.0256,
      "step": 4500
    },
    {
      "epoch": 3.3833458364591147,
      "grad_norm": 0.4965682923793793,
      "learning_rate": 1.323330832708177e-05,
      "loss": 0.032,
      "step": 4510
    },
    {
      "epoch": 3.390847711927982,
      "grad_norm": 0.985678493976593,
      "learning_rate": 1.3218304576144036e-05,
      "loss": 0.0241,
      "step": 4520
    },
    {
      "epoch": 3.398349587396849,
      "grad_norm": 3.658435344696045,
      "learning_rate": 1.3203300825206302e-05,
      "loss": 0.0265,
      "step": 4530
    },
    {
      "epoch": 3.4058514628657166,
      "grad_norm": 0.8362749218940735,
      "learning_rate": 1.3188297074268568e-05,
      "loss": 0.038,
      "step": 4540
    },
    {
      "epoch": 3.4133533383345838,
      "grad_norm": 2.050825595855713,
      "learning_rate": 1.3173293323330833e-05,
      "loss": 0.0255,
      "step": 4550
    },
    {
      "epoch": 3.420855213803451,
      "grad_norm": 0.05051032453775406,
      "learning_rate": 1.31582895723931e-05,
      "loss": 0.0265,
      "step": 4560
    },
    {
      "epoch": 3.428357089272318,
      "grad_norm": 1.9069242477416992,
      "learning_rate": 1.3143285821455365e-05,
      "loss": 0.0221,
      "step": 4570
    },
    {
      "epoch": 3.4358589647411852,
      "grad_norm": 3.507193088531494,
      "learning_rate": 1.3128282070517631e-05,
      "loss": 0.0356,
      "step": 4580
    },
    {
      "epoch": 3.4433608402100524,
      "grad_norm": 1.9726524353027344,
      "learning_rate": 1.3113278319579897e-05,
      "loss": 0.0182,
      "step": 4590
    },
    {
      "epoch": 3.4508627156789196,
      "grad_norm": 4.263561725616455,
      "learning_rate": 1.3098274568642162e-05,
      "loss": 0.015,
      "step": 4600
    },
    {
      "epoch": 3.458364591147787,
      "grad_norm": 0.22127531468868256,
      "learning_rate": 1.3083270817704428e-05,
      "loss": 0.0135,
      "step": 4610
    },
    {
      "epoch": 3.4658664666166543,
      "grad_norm": 1.0579315423965454,
      "learning_rate": 1.3068267066766694e-05,
      "loss": 0.0168,
      "step": 4620
    },
    {
      "epoch": 3.4733683420855215,
      "grad_norm": 0.36329007148742676,
      "learning_rate": 1.305326331582896e-05,
      "loss": 0.0287,
      "step": 4630
    },
    {
      "epoch": 3.4808702175543886,
      "grad_norm": 3.767866849899292,
      "learning_rate": 1.3038259564891224e-05,
      "loss": 0.0171,
      "step": 4640
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 2.4712958335876465,
      "learning_rate": 1.302325581395349e-05,
      "loss": 0.0247,
      "step": 4650
    },
    {
      "epoch": 3.495873968492123,
      "grad_norm": 0.06258342415094376,
      "learning_rate": 1.3008252063015756e-05,
      "loss": 0.0303,
      "step": 4660
    },
    {
      "epoch": 3.50337584396099,
      "grad_norm": 1.2487634420394897,
      "learning_rate": 1.299324831207802e-05,
      "loss": 0.028,
      "step": 4670
    },
    {
      "epoch": 3.5108777194298577,
      "grad_norm": 10.13052749633789,
      "learning_rate": 1.2978244561140285e-05,
      "loss": 0.0265,
      "step": 4680
    },
    {
      "epoch": 3.5183795948987244,
      "grad_norm": 4.038212776184082,
      "learning_rate": 1.2963240810202551e-05,
      "loss": 0.0182,
      "step": 4690
    },
    {
      "epoch": 3.525881470367592,
      "grad_norm": 0.24301306903362274,
      "learning_rate": 1.2948237059264817e-05,
      "loss": 0.0147,
      "step": 4700
    },
    {
      "epoch": 3.533383345836459,
      "grad_norm": 4.9341654777526855,
      "learning_rate": 1.2933233308327083e-05,
      "loss": 0.0385,
      "step": 4710
    },
    {
      "epoch": 3.5408852213053263,
      "grad_norm": 3.461432456970215,
      "learning_rate": 1.2918229557389349e-05,
      "loss": 0.0346,
      "step": 4720
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 5.803363800048828,
      "learning_rate": 1.2903225806451613e-05,
      "loss": 0.0156,
      "step": 4730
    },
    {
      "epoch": 3.5558889722430607,
      "grad_norm": 1.1978157758712769,
      "learning_rate": 1.2888222055513879e-05,
      "loss": 0.0243,
      "step": 4740
    },
    {
      "epoch": 3.563390847711928,
      "grad_norm": 0.6719341278076172,
      "learning_rate": 1.2873218304576144e-05,
      "loss": 0.0207,
      "step": 4750
    },
    {
      "epoch": 3.570892723180795,
      "grad_norm": 0.8111952543258667,
      "learning_rate": 1.285821455363841e-05,
      "loss": 0.029,
      "step": 4760
    },
    {
      "epoch": 3.5783945986496626,
      "grad_norm": 3.383415699005127,
      "learning_rate": 1.2843210802700676e-05,
      "loss": 0.0397,
      "step": 4770
    },
    {
      "epoch": 3.5858964741185297,
      "grad_norm": 2.1218416690826416,
      "learning_rate": 1.2828207051762942e-05,
      "loss": 0.0203,
      "step": 4780
    },
    {
      "epoch": 3.593398349587397,
      "grad_norm": 0.5372712016105652,
      "learning_rate": 1.2813203300825208e-05,
      "loss": 0.0195,
      "step": 4790
    },
    {
      "epoch": 3.600900225056264,
      "grad_norm": 2.669233798980713,
      "learning_rate": 1.2798199549887473e-05,
      "loss": 0.0197,
      "step": 4800
    },
    {
      "epoch": 3.608402100525131,
      "grad_norm": 0.9685710072517395,
      "learning_rate": 1.2783195798949739e-05,
      "loss": 0.0278,
      "step": 4810
    },
    {
      "epoch": 3.6159039759939984,
      "grad_norm": 1.8014509677886963,
      "learning_rate": 1.2768192048012005e-05,
      "loss": 0.0284,
      "step": 4820
    },
    {
      "epoch": 3.6234058514628655,
      "grad_norm": 2.3047115802764893,
      "learning_rate": 1.275318829707427e-05,
      "loss": 0.0299,
      "step": 4830
    },
    {
      "epoch": 3.630907726931733,
      "grad_norm": 3.323502779006958,
      "learning_rate": 1.2738184546136537e-05,
      "loss": 0.0343,
      "step": 4840
    },
    {
      "epoch": 3.6384096024006003,
      "grad_norm": 1.9886765480041504,
      "learning_rate": 1.2723180795198802e-05,
      "loss": 0.0193,
      "step": 4850
    },
    {
      "epoch": 3.6459114778694675,
      "grad_norm": 0.49566781520843506,
      "learning_rate": 1.2708177044261065e-05,
      "loss": 0.0274,
      "step": 4860
    },
    {
      "epoch": 3.6534133533383346,
      "grad_norm": 0.5407921671867371,
      "learning_rate": 1.269317329332333e-05,
      "loss": 0.0216,
      "step": 4870
    },
    {
      "epoch": 3.6609152288072018,
      "grad_norm": 0.4712190330028534,
      "learning_rate": 1.2678169542385596e-05,
      "loss": 0.04,
      "step": 4880
    },
    {
      "epoch": 3.668417104276069,
      "grad_norm": 1.6578457355499268,
      "learning_rate": 1.2663165791447862e-05,
      "loss": 0.0178,
      "step": 4890
    },
    {
      "epoch": 3.675918979744936,
      "grad_norm": 0.0236144308000803,
      "learning_rate": 1.2648162040510128e-05,
      "loss": 0.0164,
      "step": 4900
    },
    {
      "epoch": 3.6834208552138037,
      "grad_norm": 1.3896241188049316,
      "learning_rate": 1.2633158289572394e-05,
      "loss": 0.041,
      "step": 4910
    },
    {
      "epoch": 3.6909227306826704,
      "grad_norm": 0.41933926939964294,
      "learning_rate": 1.261815453863466e-05,
      "loss": 0.0248,
      "step": 4920
    },
    {
      "epoch": 3.698424606151538,
      "grad_norm": 2.1530933380126953,
      "learning_rate": 1.2603150787696925e-05,
      "loss": 0.0283,
      "step": 4930
    },
    {
      "epoch": 3.705926481620405,
      "grad_norm": 1.4871448278427124,
      "learning_rate": 1.2588147036759191e-05,
      "loss": 0.0207,
      "step": 4940
    },
    {
      "epoch": 3.7134283570892723,
      "grad_norm": 6.832113742828369,
      "learning_rate": 1.2573143285821457e-05,
      "loss": 0.0321,
      "step": 4950
    },
    {
      "epoch": 3.7209302325581395,
      "grad_norm": 1.4223344326019287,
      "learning_rate": 1.2558139534883723e-05,
      "loss": 0.0315,
      "step": 4960
    },
    {
      "epoch": 3.7284321080270066,
      "grad_norm": 2.6537022590637207,
      "learning_rate": 1.2543135783945989e-05,
      "loss": 0.0173,
      "step": 4970
    },
    {
      "epoch": 3.7359339834958742,
      "grad_norm": 2.6268362998962402,
      "learning_rate": 1.2528132033008253e-05,
      "loss": 0.0256,
      "step": 4980
    },
    {
      "epoch": 3.743435858964741,
      "grad_norm": 1.3909674882888794,
      "learning_rate": 1.2513128282070518e-05,
      "loss": 0.022,
      "step": 4990
    },
    {
      "epoch": 3.7509377344336086,
      "grad_norm": 0.8381865620613098,
      "learning_rate": 1.2498124531132784e-05,
      "loss": 0.0144,
      "step": 5000
    },
    {
      "epoch": 3.7584396099024757,
      "grad_norm": 0.30972611904144287,
      "learning_rate": 1.248312078019505e-05,
      "loss": 0.0161,
      "step": 5010
    },
    {
      "epoch": 3.765941485371343,
      "grad_norm": 0.6371182203292847,
      "learning_rate": 1.2468117029257316e-05,
      "loss": 0.0315,
      "step": 5020
    },
    {
      "epoch": 3.77344336084021,
      "grad_norm": 0.26482751965522766,
      "learning_rate": 1.2453113278319582e-05,
      "loss": 0.0201,
      "step": 5030
    },
    {
      "epoch": 3.780945236309077,
      "grad_norm": 4.292201995849609,
      "learning_rate": 1.2438109527381847e-05,
      "loss": 0.0274,
      "step": 5040
    },
    {
      "epoch": 3.7884471117779444,
      "grad_norm": 1.6550040245056152,
      "learning_rate": 1.2423105776444112e-05,
      "loss": 0.0253,
      "step": 5050
    },
    {
      "epoch": 3.7959489872468115,
      "grad_norm": 3.799600124359131,
      "learning_rate": 1.2408102025506377e-05,
      "loss": 0.0401,
      "step": 5060
    },
    {
      "epoch": 3.803450862715679,
      "grad_norm": 0.7751877307891846,
      "learning_rate": 1.2393098274568643e-05,
      "loss": 0.0174,
      "step": 5070
    },
    {
      "epoch": 3.8109527381845463,
      "grad_norm": 2.31467604637146,
      "learning_rate": 1.2378094523630907e-05,
      "loss": 0.0217,
      "step": 5080
    },
    {
      "epoch": 3.8184546136534134,
      "grad_norm": 0.07717731595039368,
      "learning_rate": 1.2363090772693173e-05,
      "loss": 0.0198,
      "step": 5090
    },
    {
      "epoch": 3.8259564891222806,
      "grad_norm": 1.4039071798324585,
      "learning_rate": 1.2348087021755439e-05,
      "loss": 0.0236,
      "step": 5100
    },
    {
      "epoch": 3.8334583645911477,
      "grad_norm": 1.4886720180511475,
      "learning_rate": 1.2333083270817705e-05,
      "loss": 0.0297,
      "step": 5110
    },
    {
      "epoch": 3.840960240060015,
      "grad_norm": 2.1532578468322754,
      "learning_rate": 1.231807951987997e-05,
      "loss": 0.028,
      "step": 5120
    },
    {
      "epoch": 3.848462115528882,
      "grad_norm": 0.8647743463516235,
      "learning_rate": 1.2303075768942236e-05,
      "loss": 0.0282,
      "step": 5130
    },
    {
      "epoch": 3.8559639909977497,
      "grad_norm": 2.7254772186279297,
      "learning_rate": 1.2288072018004502e-05,
      "loss": 0.0291,
      "step": 5140
    },
    {
      "epoch": 3.8634658664666164,
      "grad_norm": 1.2337051630020142,
      "learning_rate": 1.2273068267066768e-05,
      "loss": 0.0203,
      "step": 5150
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.09550992399454117,
      "learning_rate": 1.2258064516129034e-05,
      "loss": 0.0139,
      "step": 5160
    },
    {
      "epoch": 3.878469617404351,
      "grad_norm": 0.17184332013130188,
      "learning_rate": 1.22430607651913e-05,
      "loss": 0.0153,
      "step": 5170
    },
    {
      "epoch": 3.8859714928732183,
      "grad_norm": 0.8926874995231628,
      "learning_rate": 1.2228057014253565e-05,
      "loss": 0.0255,
      "step": 5180
    },
    {
      "epoch": 3.8934733683420855,
      "grad_norm": 1.167085886001587,
      "learning_rate": 1.2213053263315831e-05,
      "loss": 0.0279,
      "step": 5190
    },
    {
      "epoch": 3.9009752438109526,
      "grad_norm": 0.8966463804244995,
      "learning_rate": 1.2198049512378097e-05,
      "loss": 0.0405,
      "step": 5200
    },
    {
      "epoch": 3.9084771192798202,
      "grad_norm": 0.3374271094799042,
      "learning_rate": 1.2183045761440363e-05,
      "loss": 0.0298,
      "step": 5210
    },
    {
      "epoch": 3.915978994748687,
      "grad_norm": 3.3908281326293945,
      "learning_rate": 1.2168042010502627e-05,
      "loss": 0.0249,
      "step": 5220
    },
    {
      "epoch": 3.9234808702175545,
      "grad_norm": 0.784525990486145,
      "learning_rate": 1.2153038259564893e-05,
      "loss": 0.0139,
      "step": 5230
    },
    {
      "epoch": 3.9309827456864217,
      "grad_norm": 1.9618382453918457,
      "learning_rate": 1.2138034508627157e-05,
      "loss": 0.0253,
      "step": 5240
    },
    {
      "epoch": 3.938484621155289,
      "grad_norm": 2.0868921279907227,
      "learning_rate": 1.2123030757689422e-05,
      "loss": 0.023,
      "step": 5250
    },
    {
      "epoch": 3.945986496624156,
      "grad_norm": 2.065075159072876,
      "learning_rate": 1.2108027006751688e-05,
      "loss": 0.0182,
      "step": 5260
    },
    {
      "epoch": 3.953488372093023,
      "grad_norm": 1.561424732208252,
      "learning_rate": 1.2093023255813954e-05,
      "loss": 0.0279,
      "step": 5270
    },
    {
      "epoch": 3.9609902475618903,
      "grad_norm": 0.803708016872406,
      "learning_rate": 1.207801950487622e-05,
      "loss": 0.0076,
      "step": 5280
    },
    {
      "epoch": 3.9684921230307575,
      "grad_norm": 1.0379701852798462,
      "learning_rate": 1.2063015753938486e-05,
      "loss": 0.0088,
      "step": 5290
    },
    {
      "epoch": 3.975993998499625,
      "grad_norm": 2.6787326335906982,
      "learning_rate": 1.2048012003000751e-05,
      "loss": 0.0218,
      "step": 5300
    },
    {
      "epoch": 3.9834958739684923,
      "grad_norm": 4.1856770515441895,
      "learning_rate": 1.2033008252063017e-05,
      "loss": 0.0346,
      "step": 5310
    },
    {
      "epoch": 3.9909977494373594,
      "grad_norm": 5.4926557540893555,
      "learning_rate": 1.2018004501125281e-05,
      "loss": 0.0285,
      "step": 5320
    },
    {
      "epoch": 3.9984996249062266,
      "grad_norm": 2.1187753677368164,
      "learning_rate": 1.2003000750187547e-05,
      "loss": 0.0215,
      "step": 5330
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.990631379410907,
      "eval_f1": 0.9638892791906702,
      "eval_loss": 0.028781576082110405,
      "eval_precision": 0.9634831460674157,
      "eval_recall": 0.9642957548495924,
      "eval_runtime": 478.0912,
      "eval_samples_per_second": 57.38,
      "eval_steps_per_second": 2.393,
      "step": 5332
    },
    {
      "epoch": 4.006001500375094,
      "grad_norm": 5.8656229972839355,
      "learning_rate": 1.1987996999249813e-05,
      "loss": 0.0163,
      "step": 5340
    },
    {
      "epoch": 4.013503375843961,
      "grad_norm": 2.9918570518493652,
      "learning_rate": 1.1972993248312079e-05,
      "loss": 0.0183,
      "step": 5350
    },
    {
      "epoch": 4.021005251312828,
      "grad_norm": 3.184314727783203,
      "learning_rate": 1.1957989497374345e-05,
      "loss": 0.0263,
      "step": 5360
    },
    {
      "epoch": 4.028507126781696,
      "grad_norm": 0.9074637293815613,
      "learning_rate": 1.194298574643661e-05,
      "loss": 0.0139,
      "step": 5370
    },
    {
      "epoch": 4.036009002250562,
      "grad_norm": 0.12306881695985794,
      "learning_rate": 1.1927981995498876e-05,
      "loss": 0.0204,
      "step": 5380
    },
    {
      "epoch": 4.04351087771943,
      "grad_norm": 2.9312214851379395,
      "learning_rate": 1.1912978244561142e-05,
      "loss": 0.0293,
      "step": 5390
    },
    {
      "epoch": 4.051012753188297,
      "grad_norm": 0.2007106989622116,
      "learning_rate": 1.1897974493623408e-05,
      "loss": 0.0077,
      "step": 5400
    },
    {
      "epoch": 4.058514628657164,
      "grad_norm": 6.543030738830566,
      "learning_rate": 1.1882970742685674e-05,
      "loss": 0.0181,
      "step": 5410
    },
    {
      "epoch": 4.066016504126032,
      "grad_norm": 0.6728121638298035,
      "learning_rate": 1.186796699174794e-05,
      "loss": 0.0306,
      "step": 5420
    },
    {
      "epoch": 4.073518379594899,
      "grad_norm": 0.2936738133430481,
      "learning_rate": 1.1852963240810202e-05,
      "loss": 0.0059,
      "step": 5430
    },
    {
      "epoch": 4.081020255063766,
      "grad_norm": 2.0061960220336914,
      "learning_rate": 1.1837959489872468e-05,
      "loss": 0.0381,
      "step": 5440
    },
    {
      "epoch": 4.088522130532633,
      "grad_norm": 0.08382946997880936,
      "learning_rate": 1.1822955738934733e-05,
      "loss": 0.007,
      "step": 5450
    },
    {
      "epoch": 4.0960240060015005,
      "grad_norm": 0.09563746303319931,
      "learning_rate": 1.1807951987996999e-05,
      "loss": 0.0315,
      "step": 5460
    },
    {
      "epoch": 4.103525881470367,
      "grad_norm": 2.9820010662078857,
      "learning_rate": 1.1792948237059265e-05,
      "loss": 0.0228,
      "step": 5470
    },
    {
      "epoch": 4.111027756939235,
      "grad_norm": 0.4989458918571472,
      "learning_rate": 1.177794448612153e-05,
      "loss": 0.011,
      "step": 5480
    },
    {
      "epoch": 4.118529632408102,
      "grad_norm": 1.0677151679992676,
      "learning_rate": 1.1762940735183797e-05,
      "loss": 0.0234,
      "step": 5490
    },
    {
      "epoch": 4.126031507876969,
      "grad_norm": 13.975175857543945,
      "learning_rate": 1.1747936984246062e-05,
      "loss": 0.0218,
      "step": 5500
    },
    {
      "epoch": 4.133533383345837,
      "grad_norm": 0.5938546657562256,
      "learning_rate": 1.1732933233308328e-05,
      "loss": 0.02,
      "step": 5510
    },
    {
      "epoch": 4.1410352588147035,
      "grad_norm": 1.870257019996643,
      "learning_rate": 1.1717929482370594e-05,
      "loss": 0.0329,
      "step": 5520
    },
    {
      "epoch": 4.148537134283571,
      "grad_norm": 0.7315450310707092,
      "learning_rate": 1.170292573143286e-05,
      "loss": 0.0285,
      "step": 5530
    },
    {
      "epoch": 4.156039009752438,
      "grad_norm": 2.2022461891174316,
      "learning_rate": 1.1687921980495126e-05,
      "loss": 0.0131,
      "step": 5540
    },
    {
      "epoch": 4.163540885221305,
      "grad_norm": 3.509673833847046,
      "learning_rate": 1.1672918229557391e-05,
      "loss": 0.0201,
      "step": 5550
    },
    {
      "epoch": 4.171042760690172,
      "grad_norm": 1.5243638753890991,
      "learning_rate": 1.1657914478619657e-05,
      "loss": 0.0184,
      "step": 5560
    },
    {
      "epoch": 4.17854463615904,
      "grad_norm": 0.044837888330221176,
      "learning_rate": 1.1642910727681921e-05,
      "loss": 0.02,
      "step": 5570
    },
    {
      "epoch": 4.186046511627907,
      "grad_norm": 1.5008008480072021,
      "learning_rate": 1.1627906976744187e-05,
      "loss": 0.0153,
      "step": 5580
    },
    {
      "epoch": 4.193548387096774,
      "grad_norm": 0.16547802090644836,
      "learning_rate": 1.1612903225806453e-05,
      "loss": 0.0218,
      "step": 5590
    },
    {
      "epoch": 4.201050262565642,
      "grad_norm": 0.1899731606245041,
      "learning_rate": 1.1597899474868719e-05,
      "loss": 0.0323,
      "step": 5600
    },
    {
      "epoch": 4.208552138034508,
      "grad_norm": 3.252514362335205,
      "learning_rate": 1.1582895723930984e-05,
      "loss": 0.0192,
      "step": 5610
    },
    {
      "epoch": 4.216054013503376,
      "grad_norm": 0.7600777745246887,
      "learning_rate": 1.1567891972993249e-05,
      "loss": 0.0193,
      "step": 5620
    },
    {
      "epoch": 4.223555888972243,
      "grad_norm": 0.14792399108409882,
      "learning_rate": 1.1552888222055514e-05,
      "loss": 0.0308,
      "step": 5630
    },
    {
      "epoch": 4.23105776444111,
      "grad_norm": 0.9133340120315552,
      "learning_rate": 1.153788447111778e-05,
      "loss": 0.0351,
      "step": 5640
    },
    {
      "epoch": 4.238559639909978,
      "grad_norm": 1.1051194667816162,
      "learning_rate": 1.1522880720180046e-05,
      "loss": 0.0178,
      "step": 5650
    },
    {
      "epoch": 4.246061515378845,
      "grad_norm": 1.556027889251709,
      "learning_rate": 1.1507876969242312e-05,
      "loss": 0.017,
      "step": 5660
    },
    {
      "epoch": 4.253563390847712,
      "grad_norm": 0.8212790489196777,
      "learning_rate": 1.1492873218304576e-05,
      "loss": 0.0155,
      "step": 5670
    },
    {
      "epoch": 4.261065266316579,
      "grad_norm": 0.7338146567344666,
      "learning_rate": 1.1477869467366842e-05,
      "loss": 0.0084,
      "step": 5680
    },
    {
      "epoch": 4.2685671417854465,
      "grad_norm": 1.0893217325210571,
      "learning_rate": 1.1462865716429107e-05,
      "loss": 0.0347,
      "step": 5690
    },
    {
      "epoch": 4.276069017254313,
      "grad_norm": 0.07290421426296234,
      "learning_rate": 1.1447861965491373e-05,
      "loss": 0.0324,
      "step": 5700
    },
    {
      "epoch": 4.283570892723181,
      "grad_norm": 0.7489897012710571,
      "learning_rate": 1.1432858214553639e-05,
      "loss": 0.0174,
      "step": 5710
    },
    {
      "epoch": 4.291072768192048,
      "grad_norm": 0.2619989812374115,
      "learning_rate": 1.1417854463615905e-05,
      "loss": 0.013,
      "step": 5720
    },
    {
      "epoch": 4.298574643660915,
      "grad_norm": 2.753554105758667,
      "learning_rate": 1.140285071267817e-05,
      "loss": 0.0105,
      "step": 5730
    },
    {
      "epoch": 4.306076519129783,
      "grad_norm": 0.46813341975212097,
      "learning_rate": 1.1387846961740436e-05,
      "loss": 0.0216,
      "step": 5740
    },
    {
      "epoch": 4.3135783945986494,
      "grad_norm": 21.598663330078125,
      "learning_rate": 1.1372843210802702e-05,
      "loss": 0.0092,
      "step": 5750
    },
    {
      "epoch": 4.321080270067517,
      "grad_norm": 1.0859977006912231,
      "learning_rate": 1.1357839459864968e-05,
      "loss": 0.0215,
      "step": 5760
    },
    {
      "epoch": 4.328582145536384,
      "grad_norm": 0.635750412940979,
      "learning_rate": 1.1342835708927234e-05,
      "loss": 0.0171,
      "step": 5770
    },
    {
      "epoch": 4.336084021005251,
      "grad_norm": 0.33494865894317627,
      "learning_rate": 1.13278319579895e-05,
      "loss": 0.006,
      "step": 5780
    },
    {
      "epoch": 4.343585896474119,
      "grad_norm": 0.03955020010471344,
      "learning_rate": 1.1312828207051765e-05,
      "loss": 0.0115,
      "step": 5790
    },
    {
      "epoch": 4.351087771942986,
      "grad_norm": 0.4015432894229889,
      "learning_rate": 1.1297824456114031e-05,
      "loss": 0.0222,
      "step": 5800
    },
    {
      "epoch": 4.358589647411853,
      "grad_norm": 0.48751863837242126,
      "learning_rate": 1.1282820705176294e-05,
      "loss": 0.0143,
      "step": 5810
    },
    {
      "epoch": 4.36609152288072,
      "grad_norm": 15.726997375488281,
      "learning_rate": 1.126781695423856e-05,
      "loss": 0.0189,
      "step": 5820
    },
    {
      "epoch": 4.373593398349588,
      "grad_norm": 9.818975448608398,
      "learning_rate": 1.1252813203300825e-05,
      "loss": 0.024,
      "step": 5830
    },
    {
      "epoch": 4.381095273818454,
      "grad_norm": 0.10582965612411499,
      "learning_rate": 1.1237809452363091e-05,
      "loss": 0.0071,
      "step": 5840
    },
    {
      "epoch": 4.388597149287322,
      "grad_norm": 7.828433990478516,
      "learning_rate": 1.1222805701425357e-05,
      "loss": 0.0241,
      "step": 5850
    },
    {
      "epoch": 4.396099024756189,
      "grad_norm": 4.816997528076172,
      "learning_rate": 1.1207801950487623e-05,
      "loss": 0.0296,
      "step": 5860
    },
    {
      "epoch": 4.403600900225056,
      "grad_norm": 1.5779765844345093,
      "learning_rate": 1.1192798199549888e-05,
      "loss": 0.0119,
      "step": 5870
    },
    {
      "epoch": 4.411102775693924,
      "grad_norm": 0.6563888788223267,
      "learning_rate": 1.1177794448612154e-05,
      "loss": 0.0236,
      "step": 5880
    },
    {
      "epoch": 4.4186046511627906,
      "grad_norm": 0.6216431260108948,
      "learning_rate": 1.116279069767442e-05,
      "loss": 0.0186,
      "step": 5890
    },
    {
      "epoch": 4.426106526631658,
      "grad_norm": 0.06535572558641434,
      "learning_rate": 1.1147786946736686e-05,
      "loss": 0.0216,
      "step": 5900
    },
    {
      "epoch": 4.433608402100525,
      "grad_norm": 0.33384445309638977,
      "learning_rate": 1.113278319579895e-05,
      "loss": 0.008,
      "step": 5910
    },
    {
      "epoch": 4.4411102775693925,
      "grad_norm": 0.4925054907798767,
      "learning_rate": 1.1117779444861216e-05,
      "loss": 0.0159,
      "step": 5920
    },
    {
      "epoch": 4.448612153038259,
      "grad_norm": 0.7588352560997009,
      "learning_rate": 1.1102775693923482e-05,
      "loss": 0.019,
      "step": 5930
    },
    {
      "epoch": 4.456114028507127,
      "grad_norm": 0.8980154395103455,
      "learning_rate": 1.1087771942985747e-05,
      "loss": 0.0315,
      "step": 5940
    },
    {
      "epoch": 4.463615903975994,
      "grad_norm": 2.1843013763427734,
      "learning_rate": 1.1072768192048013e-05,
      "loss": 0.0173,
      "step": 5950
    },
    {
      "epoch": 4.471117779444861,
      "grad_norm": 0.008711729198694229,
      "learning_rate": 1.1057764441110279e-05,
      "loss": 0.017,
      "step": 5960
    },
    {
      "epoch": 4.478619654913729,
      "grad_norm": 0.2562221586704254,
      "learning_rate": 1.1042760690172545e-05,
      "loss": 0.0187,
      "step": 5970
    },
    {
      "epoch": 4.486121530382595,
      "grad_norm": 1.0716710090637207,
      "learning_rate": 1.102775693923481e-05,
      "loss": 0.0336,
      "step": 5980
    },
    {
      "epoch": 4.493623405851463,
      "grad_norm": 1.2520480155944824,
      "learning_rate": 1.1012753188297076e-05,
      "loss": 0.0143,
      "step": 5990
    },
    {
      "epoch": 4.50112528132033,
      "grad_norm": 0.019616132602095604,
      "learning_rate": 1.099774943735934e-05,
      "loss": 0.0198,
      "step": 6000
    },
    {
      "epoch": 4.508627156789197,
      "grad_norm": 0.37215861678123474,
      "learning_rate": 1.0982745686421605e-05,
      "loss": 0.0291,
      "step": 6010
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 0.432209312915802,
      "learning_rate": 1.096774193548387e-05,
      "loss": 0.019,
      "step": 6020
    },
    {
      "epoch": 4.523630907726932,
      "grad_norm": 0.21123643219470978,
      "learning_rate": 1.0952738184546136e-05,
      "loss": 0.0129,
      "step": 6030
    },
    {
      "epoch": 4.531132783195799,
      "grad_norm": 0.34182479977607727,
      "learning_rate": 1.0937734433608402e-05,
      "loss": 0.0152,
      "step": 6040
    },
    {
      "epoch": 4.538634658664666,
      "grad_norm": 0.7899886965751648,
      "learning_rate": 1.0922730682670668e-05,
      "loss": 0.0169,
      "step": 6050
    },
    {
      "epoch": 4.546136534133534,
      "grad_norm": 0.027303151786327362,
      "learning_rate": 1.0907726931732934e-05,
      "loss": 0.0199,
      "step": 6060
    },
    {
      "epoch": 4.5536384096024,
      "grad_norm": 0.5188800096511841,
      "learning_rate": 1.08927231807952e-05,
      "loss": 0.0131,
      "step": 6070
    },
    {
      "epoch": 4.561140285071268,
      "grad_norm": 0.9013378620147705,
      "learning_rate": 1.0877719429857465e-05,
      "loss": 0.0221,
      "step": 6080
    },
    {
      "epoch": 4.568642160540135,
      "grad_norm": 1.2769153118133545,
      "learning_rate": 1.0862715678919731e-05,
      "loss": 0.0278,
      "step": 6090
    },
    {
      "epoch": 4.576144036009002,
      "grad_norm": 0.5652931928634644,
      "learning_rate": 1.0847711927981997e-05,
      "loss": 0.0143,
      "step": 6100
    },
    {
      "epoch": 4.58364591147787,
      "grad_norm": 3.844367027282715,
      "learning_rate": 1.0832708177044263e-05,
      "loss": 0.0258,
      "step": 6110
    },
    {
      "epoch": 4.5911477869467365,
      "grad_norm": 0.33814674615859985,
      "learning_rate": 1.0817704426106528e-05,
      "loss": 0.0269,
      "step": 6120
    },
    {
      "epoch": 4.598649662415604,
      "grad_norm": 0.05690901726484299,
      "learning_rate": 1.0802700675168794e-05,
      "loss": 0.0181,
      "step": 6130
    },
    {
      "epoch": 4.606151537884471,
      "grad_norm": 3.6357953548431396,
      "learning_rate": 1.078769692423106e-05,
      "loss": 0.0282,
      "step": 6140
    },
    {
      "epoch": 4.6136534133533385,
      "grad_norm": 1.2187820672988892,
      "learning_rate": 1.0772693173293324e-05,
      "loss": 0.0176,
      "step": 6150
    },
    {
      "epoch": 4.621155288822205,
      "grad_norm": 4.460461139678955,
      "learning_rate": 1.075768942235559e-05,
      "loss": 0.0354,
      "step": 6160
    },
    {
      "epoch": 4.628657164291073,
      "grad_norm": 1.6429656744003296,
      "learning_rate": 1.0742685671417856e-05,
      "loss": 0.0121,
      "step": 6170
    },
    {
      "epoch": 4.63615903975994,
      "grad_norm": 3.284912347793579,
      "learning_rate": 1.0727681920480121e-05,
      "loss": 0.0274,
      "step": 6180
    },
    {
      "epoch": 4.643660915228807,
      "grad_norm": 0.3590315580368042,
      "learning_rate": 1.0712678169542386e-05,
      "loss": 0.0083,
      "step": 6190
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 1.6743766069412231,
      "learning_rate": 1.0697674418604651e-05,
      "loss": 0.0178,
      "step": 6200
    },
    {
      "epoch": 4.658664666166541,
      "grad_norm": 0.38858649134635925,
      "learning_rate": 1.0682670667666917e-05,
      "loss": 0.0371,
      "step": 6210
    },
    {
      "epoch": 4.666166541635409,
      "grad_norm": 2.0252089500427246,
      "learning_rate": 1.0667666916729183e-05,
      "loss": 0.0144,
      "step": 6220
    },
    {
      "epoch": 4.673668417104276,
      "grad_norm": 2.379772663116455,
      "learning_rate": 1.0652663165791449e-05,
      "loss": 0.0193,
      "step": 6230
    },
    {
      "epoch": 4.681170292573143,
      "grad_norm": 1.9280461072921753,
      "learning_rate": 1.0637659414853715e-05,
      "loss": 0.0256,
      "step": 6240
    },
    {
      "epoch": 4.688672168042011,
      "grad_norm": 0.11881276220083237,
      "learning_rate": 1.0622655663915979e-05,
      "loss": 0.0142,
      "step": 6250
    },
    {
      "epoch": 4.696174043510878,
      "grad_norm": 1.0088452100753784,
      "learning_rate": 1.0607651912978244e-05,
      "loss": 0.0133,
      "step": 6260
    },
    {
      "epoch": 4.703675918979745,
      "grad_norm": 0.7908015847206116,
      "learning_rate": 1.059264816204051e-05,
      "loss": 0.023,
      "step": 6270
    },
    {
      "epoch": 4.711177794448612,
      "grad_norm": 1.9108428955078125,
      "learning_rate": 1.0577644411102776e-05,
      "loss": 0.0104,
      "step": 6280
    },
    {
      "epoch": 4.71867966991748,
      "grad_norm": 2.8439152240753174,
      "learning_rate": 1.0562640660165042e-05,
      "loss": 0.0212,
      "step": 6290
    },
    {
      "epoch": 4.726181545386346,
      "grad_norm": 0.02009880356490612,
      "learning_rate": 1.0547636909227308e-05,
      "loss": 0.0107,
      "step": 6300
    },
    {
      "epoch": 4.733683420855214,
      "grad_norm": 4.174278259277344,
      "learning_rate": 1.0532633158289573e-05,
      "loss": 0.0137,
      "step": 6310
    },
    {
      "epoch": 4.7411852963240815,
      "grad_norm": 1.1983399391174316,
      "learning_rate": 1.051762940735184e-05,
      "loss": 0.0162,
      "step": 6320
    },
    {
      "epoch": 4.748687171792948,
      "grad_norm": 2.3701982498168945,
      "learning_rate": 1.0502625656414105e-05,
      "loss": 0.023,
      "step": 6330
    },
    {
      "epoch": 4.756189047261816,
      "grad_norm": 0.17404824495315552,
      "learning_rate": 1.048762190547637e-05,
      "loss": 0.0266,
      "step": 6340
    },
    {
      "epoch": 4.7636909227306825,
      "grad_norm": 1.0162279605865479,
      "learning_rate": 1.0472618154538637e-05,
      "loss": 0.0146,
      "step": 6350
    },
    {
      "epoch": 4.77119279819955,
      "grad_norm": 1.9357898235321045,
      "learning_rate": 1.0457614403600902e-05,
      "loss": 0.0127,
      "step": 6360
    },
    {
      "epoch": 4.778694673668417,
      "grad_norm": 2.1694023609161377,
      "learning_rate": 1.0442610652663168e-05,
      "loss": 0.027,
      "step": 6370
    },
    {
      "epoch": 4.786196549137284,
      "grad_norm": 2.415163040161133,
      "learning_rate": 1.042760690172543e-05,
      "loss": 0.0285,
      "step": 6380
    },
    {
      "epoch": 4.793698424606152,
      "grad_norm": 4.162988185882568,
      "learning_rate": 1.0412603150787696e-05,
      "loss": 0.019,
      "step": 6390
    },
    {
      "epoch": 4.801200300075019,
      "grad_norm": 1.0246708393096924,
      "learning_rate": 1.0397599399849962e-05,
      "loss": 0.0243,
      "step": 6400
    },
    {
      "epoch": 4.808702175543886,
      "grad_norm": 0.9217038154602051,
      "learning_rate": 1.0382595648912228e-05,
      "loss": 0.0192,
      "step": 6410
    },
    {
      "epoch": 4.816204051012753,
      "grad_norm": 1.391075611114502,
      "learning_rate": 1.0367591897974494e-05,
      "loss": 0.0226,
      "step": 6420
    },
    {
      "epoch": 4.823705926481621,
      "grad_norm": 5.495765686035156,
      "learning_rate": 1.035258814703676e-05,
      "loss": 0.0148,
      "step": 6430
    },
    {
      "epoch": 4.831207801950487,
      "grad_norm": 0.8685269951820374,
      "learning_rate": 1.0337584396099025e-05,
      "loss": 0.0116,
      "step": 6440
    },
    {
      "epoch": 4.838709677419355,
      "grad_norm": 0.576021134853363,
      "learning_rate": 1.0322580645161291e-05,
      "loss": 0.0215,
      "step": 6450
    },
    {
      "epoch": 4.846211552888222,
      "grad_norm": 0.8269794583320618,
      "learning_rate": 1.0307576894223557e-05,
      "loss": 0.0183,
      "step": 6460
    },
    {
      "epoch": 4.853713428357089,
      "grad_norm": 0.5418882966041565,
      "learning_rate": 1.0292573143285823e-05,
      "loss": 0.0253,
      "step": 6470
    },
    {
      "epoch": 4.861215303825956,
      "grad_norm": 4.494358539581299,
      "learning_rate": 1.0277569392348089e-05,
      "loss": 0.0177,
      "step": 6480
    },
    {
      "epoch": 4.868717179294824,
      "grad_norm": 0.45910805463790894,
      "learning_rate": 1.0262565641410354e-05,
      "loss": 0.0134,
      "step": 6490
    },
    {
      "epoch": 4.876219054763691,
      "grad_norm": 5.3455891609191895,
      "learning_rate": 1.0247561890472619e-05,
      "loss": 0.0197,
      "step": 6500
    },
    {
      "epoch": 4.883720930232558,
      "grad_norm": 0.7067117691040039,
      "learning_rate": 1.0232558139534884e-05,
      "loss": 0.0141,
      "step": 6510
    },
    {
      "epoch": 4.8912228057014255,
      "grad_norm": 2.3374063968658447,
      "learning_rate": 1.021755438859715e-05,
      "loss": 0.0286,
      "step": 6520
    },
    {
      "epoch": 4.898724681170292,
      "grad_norm": 0.04584416374564171,
      "learning_rate": 1.0202550637659416e-05,
      "loss": 0.0096,
      "step": 6530
    },
    {
      "epoch": 4.90622655663916,
      "grad_norm": 0.7467648386955261,
      "learning_rate": 1.0187546886721682e-05,
      "loss": 0.0216,
      "step": 6540
    },
    {
      "epoch": 4.913728432108027,
      "grad_norm": 0.8605882525444031,
      "learning_rate": 1.0172543135783948e-05,
      "loss": 0.0279,
      "step": 6550
    },
    {
      "epoch": 4.921230307576894,
      "grad_norm": 2.698751449584961,
      "learning_rate": 1.0157539384846213e-05,
      "loss": 0.0177,
      "step": 6560
    },
    {
      "epoch": 4.928732183045762,
      "grad_norm": 1.9259463548660278,
      "learning_rate": 1.0142535633908477e-05,
      "loss": 0.0084,
      "step": 6570
    },
    {
      "epoch": 4.9362340585146285,
      "grad_norm": 0.46730169653892517,
      "learning_rate": 1.0127531882970743e-05,
      "loss": 0.0099,
      "step": 6580
    },
    {
      "epoch": 4.943735933983496,
      "grad_norm": 0.5765056014060974,
      "learning_rate": 1.0112528132033009e-05,
      "loss": 0.015,
      "step": 6590
    },
    {
      "epoch": 4.951237809452363,
      "grad_norm": 2.023949384689331,
      "learning_rate": 1.0097524381095273e-05,
      "loss": 0.0419,
      "step": 6600
    },
    {
      "epoch": 4.95873968492123,
      "grad_norm": 0.035627253353595734,
      "learning_rate": 1.0082520630157539e-05,
      "loss": 0.0234,
      "step": 6610
    },
    {
      "epoch": 4.966241560390097,
      "grad_norm": 1.9039416313171387,
      "learning_rate": 1.0067516879219805e-05,
      "loss": 0.0101,
      "step": 6620
    },
    {
      "epoch": 4.973743435858965,
      "grad_norm": 15.38515853881836,
      "learning_rate": 1.005251312828207e-05,
      "loss": 0.0157,
      "step": 6630
    },
    {
      "epoch": 4.981245311327832,
      "grad_norm": 3.53482723236084,
      "learning_rate": 1.0037509377344336e-05,
      "loss": 0.037,
      "step": 6640
    },
    {
      "epoch": 4.988747186796699,
      "grad_norm": 0.14614883065223694,
      "learning_rate": 1.0022505626406602e-05,
      "loss": 0.02,
      "step": 6650
    },
    {
      "epoch": 4.996249062265567,
      "grad_norm": 2.2801170349121094,
      "learning_rate": 1.0007501875468868e-05,
      "loss": 0.027,
      "step": 6660
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9913969087197434,
      "eval_f1": 0.9673491975650248,
      "eval_loss": 0.023232709616422653,
      "eval_precision": 0.9523290656496868,
      "eval_recall": 0.9828507168962609,
      "eval_runtime": 441.8565,
      "eval_samples_per_second": 62.086,
      "eval_steps_per_second": 2.589,
      "step": 6665
    },
    {
      "epoch": 5.003750937734433,
      "grad_norm": 0.6843820810317993,
      "learning_rate": 9.992498124531134e-06,
      "loss": 0.0231,
      "step": 6670
    },
    {
      "epoch": 5.011252813203301,
      "grad_norm": 1.3804633617401123,
      "learning_rate": 9.9774943735934e-06,
      "loss": 0.0205,
      "step": 6680
    },
    {
      "epoch": 5.018754688672168,
      "grad_norm": 0.27325814962387085,
      "learning_rate": 9.962490622655665e-06,
      "loss": 0.0225,
      "step": 6690
    },
    {
      "epoch": 5.026256564141035,
      "grad_norm": 0.4099308252334595,
      "learning_rate": 9.947486871717931e-06,
      "loss": 0.0036,
      "step": 6700
    },
    {
      "epoch": 5.033758439609903,
      "grad_norm": 0.007122700568288565,
      "learning_rate": 9.932483120780197e-06,
      "loss": 0.0163,
      "step": 6710
    },
    {
      "epoch": 5.04126031507877,
      "grad_norm": 1.4962280988693237,
      "learning_rate": 9.917479369842461e-06,
      "loss": 0.0273,
      "step": 6720
    },
    {
      "epoch": 5.048762190547637,
      "grad_norm": 1.0769057273864746,
      "learning_rate": 9.902475618904727e-06,
      "loss": 0.0199,
      "step": 6730
    },
    {
      "epoch": 5.056264066016504,
      "grad_norm": 0.24017435312271118,
      "learning_rate": 9.887471867966993e-06,
      "loss": 0.0188,
      "step": 6740
    },
    {
      "epoch": 5.0637659414853715,
      "grad_norm": 0.21277226507663727,
      "learning_rate": 9.872468117029258e-06,
      "loss": 0.0217,
      "step": 6750
    },
    {
      "epoch": 5.071267816954238,
      "grad_norm": 1.7944049835205078,
      "learning_rate": 9.857464366091524e-06,
      "loss": 0.0238,
      "step": 6760
    },
    {
      "epoch": 5.078769692423106,
      "grad_norm": 0.7173084616661072,
      "learning_rate": 9.84246061515379e-06,
      "loss": 0.0258,
      "step": 6770
    },
    {
      "epoch": 5.086271567891973,
      "grad_norm": 0.15635068714618683,
      "learning_rate": 9.827456864216056e-06,
      "loss": 0.0185,
      "step": 6780
    },
    {
      "epoch": 5.09377344336084,
      "grad_norm": 0.023386826738715172,
      "learning_rate": 9.81245311327832e-06,
      "loss": 0.0081,
      "step": 6790
    },
    {
      "epoch": 5.101275318829708,
      "grad_norm": 2.1005184650421143,
      "learning_rate": 9.797449362340586e-06,
      "loss": 0.0139,
      "step": 6800
    },
    {
      "epoch": 5.1087771942985745,
      "grad_norm": 1.5834699869155884,
      "learning_rate": 9.782445611402852e-06,
      "loss": 0.0286,
      "step": 6810
    },
    {
      "epoch": 5.116279069767442,
      "grad_norm": 0.38535594940185547,
      "learning_rate": 9.767441860465117e-06,
      "loss": 0.0159,
      "step": 6820
    },
    {
      "epoch": 5.123780945236309,
      "grad_norm": 2.063889741897583,
      "learning_rate": 9.752438109527383e-06,
      "loss": 0.02,
      "step": 6830
    },
    {
      "epoch": 5.131282820705176,
      "grad_norm": 1.0665067434310913,
      "learning_rate": 9.737434358589647e-06,
      "loss": 0.0152,
      "step": 6840
    },
    {
      "epoch": 5.138784696174043,
      "grad_norm": 0.1957554966211319,
      "learning_rate": 9.722430607651913e-06,
      "loss": 0.008,
      "step": 6850
    },
    {
      "epoch": 5.146286571642911,
      "grad_norm": 2.829498529434204,
      "learning_rate": 9.707426856714179e-06,
      "loss": 0.012,
      "step": 6860
    },
    {
      "epoch": 5.153788447111778,
      "grad_norm": 1.4224199056625366,
      "learning_rate": 9.692423105776445e-06,
      "loss": 0.0189,
      "step": 6870
    },
    {
      "epoch": 5.161290322580645,
      "grad_norm": 0.6301153898239136,
      "learning_rate": 9.67741935483871e-06,
      "loss": 0.012,
      "step": 6880
    },
    {
      "epoch": 5.168792198049513,
      "grad_norm": 1.6793149709701538,
      "learning_rate": 9.662415603900976e-06,
      "loss": 0.0111,
      "step": 6890
    },
    {
      "epoch": 5.176294073518379,
      "grad_norm": 4.744447708129883,
      "learning_rate": 9.647411852963242e-06,
      "loss": 0.0109,
      "step": 6900
    },
    {
      "epoch": 5.183795948987247,
      "grad_norm": 0.07325619459152222,
      "learning_rate": 9.632408102025506e-06,
      "loss": 0.0224,
      "step": 6910
    },
    {
      "epoch": 5.191297824456114,
      "grad_norm": 6.867615699768066,
      "learning_rate": 9.617404351087772e-06,
      "loss": 0.0175,
      "step": 6920
    },
    {
      "epoch": 5.198799699924981,
      "grad_norm": 0.9183434844017029,
      "learning_rate": 9.602400600150038e-06,
      "loss": 0.0112,
      "step": 6930
    },
    {
      "epoch": 5.206301575393849,
      "grad_norm": 0.6267644762992859,
      "learning_rate": 9.587396849212304e-06,
      "loss": 0.0093,
      "step": 6940
    },
    {
      "epoch": 5.213803450862716,
      "grad_norm": 1.666344404220581,
      "learning_rate": 9.57239309827457e-06,
      "loss": 0.0192,
      "step": 6950
    },
    {
      "epoch": 5.221305326331583,
      "grad_norm": 3.06713604927063,
      "learning_rate": 9.557389347336835e-06,
      "loss": 0.0079,
      "step": 6960
    },
    {
      "epoch": 5.22880720180045,
      "grad_norm": 0.19688373804092407,
      "learning_rate": 9.542385596399101e-06,
      "loss": 0.0169,
      "step": 6970
    },
    {
      "epoch": 5.2363090772693175,
      "grad_norm": 1.2388875484466553,
      "learning_rate": 9.527381845461367e-06,
      "loss": 0.0194,
      "step": 6980
    },
    {
      "epoch": 5.243810952738184,
      "grad_norm": 2.3080649375915527,
      "learning_rate": 9.512378094523633e-06,
      "loss": 0.015,
      "step": 6990
    },
    {
      "epoch": 5.251312828207052,
      "grad_norm": 0.5779333710670471,
      "learning_rate": 9.497374343585897e-06,
      "loss": 0.0127,
      "step": 7000
    },
    {
      "epoch": 5.2588147036759185,
      "grad_norm": 0.8864016532897949,
      "learning_rate": 9.482370592648162e-06,
      "loss": 0.0174,
      "step": 7010
    },
    {
      "epoch": 5.266316579144786,
      "grad_norm": 1.622900366783142,
      "learning_rate": 9.467366841710428e-06,
      "loss": 0.0363,
      "step": 7020
    },
    {
      "epoch": 5.273818454613654,
      "grad_norm": 0.275901198387146,
      "learning_rate": 9.452363090772694e-06,
      "loss": 0.0218,
      "step": 7030
    },
    {
      "epoch": 5.28132033008252,
      "grad_norm": 0.38052186369895935,
      "learning_rate": 9.43735933983496e-06,
      "loss": 0.0114,
      "step": 7040
    },
    {
      "epoch": 5.288822205551388,
      "grad_norm": 0.9902605414390564,
      "learning_rate": 9.422355588897226e-06,
      "loss": 0.015,
      "step": 7050
    },
    {
      "epoch": 5.296324081020255,
      "grad_norm": 0.33959200978279114,
      "learning_rate": 9.407351837959491e-06,
      "loss": 0.0178,
      "step": 7060
    },
    {
      "epoch": 5.303825956489122,
      "grad_norm": 0.17563703656196594,
      "learning_rate": 9.392348087021757e-06,
      "loss": 0.0082,
      "step": 7070
    },
    {
      "epoch": 5.311327831957989,
      "grad_norm": 0.09489338845014572,
      "learning_rate": 9.377344336084023e-06,
      "loss": 0.0086,
      "step": 7080
    },
    {
      "epoch": 5.318829707426857,
      "grad_norm": 0.523934543132782,
      "learning_rate": 9.362340585146287e-06,
      "loss": 0.0221,
      "step": 7090
    },
    {
      "epoch": 5.326331582895724,
      "grad_norm": 0.4680638611316681,
      "learning_rate": 9.347336834208553e-06,
      "loss": 0.0218,
      "step": 7100
    },
    {
      "epoch": 5.333833458364591,
      "grad_norm": 1.3970096111297607,
      "learning_rate": 9.332333083270819e-06,
      "loss": 0.021,
      "step": 7110
    },
    {
      "epoch": 5.341335333833459,
      "grad_norm": 0.9084944725036621,
      "learning_rate": 9.317329332333085e-06,
      "loss": 0.0137,
      "step": 7120
    },
    {
      "epoch": 5.348837209302325,
      "grad_norm": 0.28881192207336426,
      "learning_rate": 9.30232558139535e-06,
      "loss": 0.019,
      "step": 7130
    },
    {
      "epoch": 5.356339084771193,
      "grad_norm": 2.3035480976104736,
      "learning_rate": 9.287321830457614e-06,
      "loss": 0.0276,
      "step": 7140
    },
    {
      "epoch": 5.36384096024006,
      "grad_norm": 0.03641386330127716,
      "learning_rate": 9.27231807951988e-06,
      "loss": 0.0106,
      "step": 7150
    },
    {
      "epoch": 5.371342835708927,
      "grad_norm": 0.5047634243965149,
      "learning_rate": 9.257314328582146e-06,
      "loss": 0.0297,
      "step": 7160
    },
    {
      "epoch": 5.378844711177795,
      "grad_norm": 0.2776052951812744,
      "learning_rate": 9.242310577644412e-06,
      "loss": 0.0113,
      "step": 7170
    },
    {
      "epoch": 5.3863465866466615,
      "grad_norm": 3.3462460041046143,
      "learning_rate": 9.227306826706678e-06,
      "loss": 0.0176,
      "step": 7180
    },
    {
      "epoch": 5.393848462115529,
      "grad_norm": 0.7703537940979004,
      "learning_rate": 9.212303075768942e-06,
      "loss": 0.0112,
      "step": 7190
    },
    {
      "epoch": 5.401350337584396,
      "grad_norm": 0.0054065571166574955,
      "learning_rate": 9.197299324831208e-06,
      "loss": 0.0066,
      "step": 7200
    },
    {
      "epoch": 5.4088522130532635,
      "grad_norm": 0.16904394328594208,
      "learning_rate": 9.182295573893473e-06,
      "loss": 0.0133,
      "step": 7210
    },
    {
      "epoch": 5.41635408852213,
      "grad_norm": 4.030717372894287,
      "learning_rate": 9.167291822955739e-06,
      "loss": 0.0188,
      "step": 7220
    },
    {
      "epoch": 5.423855963990998,
      "grad_norm": 0.060154080390930176,
      "learning_rate": 9.152288072018005e-06,
      "loss": 0.0113,
      "step": 7230
    },
    {
      "epoch": 5.431357839459865,
      "grad_norm": 0.20209643244743347,
      "learning_rate": 9.13728432108027e-06,
      "loss": 0.0205,
      "step": 7240
    },
    {
      "epoch": 5.438859714928732,
      "grad_norm": 1.4164412021636963,
      "learning_rate": 9.122280570142537e-06,
      "loss": 0.0247,
      "step": 7250
    },
    {
      "epoch": 5.4463615903976,
      "grad_norm": 2.5932321548461914,
      "learning_rate": 9.107276819204802e-06,
      "loss": 0.0275,
      "step": 7260
    },
    {
      "epoch": 5.453863465866466,
      "grad_norm": 1.2561348676681519,
      "learning_rate": 9.092273068267068e-06,
      "loss": 0.0181,
      "step": 7270
    },
    {
      "epoch": 5.461365341335334,
      "grad_norm": 0.33375462889671326,
      "learning_rate": 9.077269317329334e-06,
      "loss": 0.0165,
      "step": 7280
    },
    {
      "epoch": 5.468867216804201,
      "grad_norm": 0.186562642455101,
      "learning_rate": 9.062265566391598e-06,
      "loss": 0.0086,
      "step": 7290
    },
    {
      "epoch": 5.476369092273068,
      "grad_norm": 0.21261197328567505,
      "learning_rate": 9.047261815453864e-06,
      "loss": 0.0117,
      "step": 7300
    },
    {
      "epoch": 5.483870967741936,
      "grad_norm": 0.6756537556648254,
      "learning_rate": 9.03225806451613e-06,
      "loss": 0.0173,
      "step": 7310
    },
    {
      "epoch": 5.491372843210803,
      "grad_norm": 3.6710498332977295,
      "learning_rate": 9.017254313578395e-06,
      "loss": 0.0131,
      "step": 7320
    },
    {
      "epoch": 5.49887471867967,
      "grad_norm": 0.6688714027404785,
      "learning_rate": 9.002250562640661e-06,
      "loss": 0.0244,
      "step": 7330
    },
    {
      "epoch": 5.506376594148537,
      "grad_norm": 0.6331638693809509,
      "learning_rate": 8.987246811702927e-06,
      "loss": 0.0145,
      "step": 7340
    },
    {
      "epoch": 5.513878469617405,
      "grad_norm": 0.042706385254859924,
      "learning_rate": 8.972243060765193e-06,
      "loss": 0.0079,
      "step": 7350
    },
    {
      "epoch": 5.521380345086271,
      "grad_norm": 0.7027637362480164,
      "learning_rate": 8.957239309827459e-06,
      "loss": 0.0098,
      "step": 7360
    },
    {
      "epoch": 5.528882220555139,
      "grad_norm": 0.038749806582927704,
      "learning_rate": 8.942235558889724e-06,
      "loss": 0.0156,
      "step": 7370
    },
    {
      "epoch": 5.5363840960240065,
      "grad_norm": 0.49382734298706055,
      "learning_rate": 8.927231807951989e-06,
      "loss": 0.0161,
      "step": 7380
    },
    {
      "epoch": 5.543885971492873,
      "grad_norm": 1.1367141008377075,
      "learning_rate": 8.912228057014254e-06,
      "loss": 0.0139,
      "step": 7390
    },
    {
      "epoch": 5.551387846961741,
      "grad_norm": 2.2637948989868164,
      "learning_rate": 8.89722430607652e-06,
      "loss": 0.0179,
      "step": 7400
    },
    {
      "epoch": 5.5588897224306075,
      "grad_norm": 0.5520293116569519,
      "learning_rate": 8.882220555138786e-06,
      "loss": 0.018,
      "step": 7410
    },
    {
      "epoch": 5.566391597899475,
      "grad_norm": 1.5502103567123413,
      "learning_rate": 8.867216804201052e-06,
      "loss": 0.0168,
      "step": 7420
    },
    {
      "epoch": 5.573893473368342,
      "grad_norm": 0.556863009929657,
      "learning_rate": 8.852213053263316e-06,
      "loss": 0.0228,
      "step": 7430
    },
    {
      "epoch": 5.5813953488372094,
      "grad_norm": 0.4857875108718872,
      "learning_rate": 8.837209302325582e-06,
      "loss": 0.0099,
      "step": 7440
    },
    {
      "epoch": 5.588897224306076,
      "grad_norm": 2.414990186691284,
      "learning_rate": 8.822205551387847e-06,
      "loss": 0.0116,
      "step": 7450
    },
    {
      "epoch": 5.596399099774944,
      "grad_norm": 1.4067000150680542,
      "learning_rate": 8.807201800450113e-06,
      "loss": 0.0114,
      "step": 7460
    },
    {
      "epoch": 5.6039009752438105,
      "grad_norm": 2.8254940509796143,
      "learning_rate": 8.792198049512379e-06,
      "loss": 0.0151,
      "step": 7470
    },
    {
      "epoch": 5.611402850712678,
      "grad_norm": 5.978091716766357,
      "learning_rate": 8.777194298574643e-06,
      "loss": 0.0165,
      "step": 7480
    },
    {
      "epoch": 5.618904726181546,
      "grad_norm": 0.864497721195221,
      "learning_rate": 8.762190547636909e-06,
      "loss": 0.0071,
      "step": 7490
    },
    {
      "epoch": 5.626406601650412,
      "grad_norm": 0.19637049734592438,
      "learning_rate": 8.747186796699175e-06,
      "loss": 0.0186,
      "step": 7500
    },
    {
      "epoch": 5.63390847711928,
      "grad_norm": 1.036144495010376,
      "learning_rate": 8.73218304576144e-06,
      "loss": 0.007,
      "step": 7510
    },
    {
      "epoch": 5.641410352588147,
      "grad_norm": 0.031106529757380486,
      "learning_rate": 8.717179294823706e-06,
      "loss": 0.0037,
      "step": 7520
    },
    {
      "epoch": 5.648912228057014,
      "grad_norm": 0.009638072922825813,
      "learning_rate": 8.702175543885972e-06,
      "loss": 0.025,
      "step": 7530
    },
    {
      "epoch": 5.656414103525881,
      "grad_norm": 0.07346833497285843,
      "learning_rate": 8.687171792948238e-06,
      "loss": 0.0101,
      "step": 7540
    },
    {
      "epoch": 5.663915978994749,
      "grad_norm": 0.4930172264575958,
      "learning_rate": 8.672168042010504e-06,
      "loss": 0.0228,
      "step": 7550
    },
    {
      "epoch": 5.671417854463616,
      "grad_norm": 14.156291961669922,
      "learning_rate": 8.65716429107277e-06,
      "loss": 0.0248,
      "step": 7560
    },
    {
      "epoch": 5.678919729932483,
      "grad_norm": 1.2284820079803467,
      "learning_rate": 8.642160540135034e-06,
      "loss": 0.017,
      "step": 7570
    },
    {
      "epoch": 5.6864216054013506,
      "grad_norm": 0.23353716731071472,
      "learning_rate": 8.6271567891973e-06,
      "loss": 0.0201,
      "step": 7580
    },
    {
      "epoch": 5.693923480870217,
      "grad_norm": 1.5924581289291382,
      "learning_rate": 8.612153038259565e-06,
      "loss": 0.0156,
      "step": 7590
    },
    {
      "epoch": 5.701425356339085,
      "grad_norm": 0.9386159777641296,
      "learning_rate": 8.597149287321831e-06,
      "loss": 0.0081,
      "step": 7600
    },
    {
      "epoch": 5.708927231807952,
      "grad_norm": 0.25510627031326294,
      "learning_rate": 8.582145536384097e-06,
      "loss": 0.0051,
      "step": 7610
    },
    {
      "epoch": 5.716429107276819,
      "grad_norm": 0.48756372928619385,
      "learning_rate": 8.567141785446363e-06,
      "loss": 0.0114,
      "step": 7620
    },
    {
      "epoch": 5.723930982745687,
      "grad_norm": 0.8916178345680237,
      "learning_rate": 8.552138034508628e-06,
      "loss": 0.0037,
      "step": 7630
    },
    {
      "epoch": 5.7314328582145535,
      "grad_norm": 1.847934603691101,
      "learning_rate": 8.537134283570894e-06,
      "loss": 0.0136,
      "step": 7640
    },
    {
      "epoch": 5.738934733683421,
      "grad_norm": 0.025219600647687912,
      "learning_rate": 8.52213053263316e-06,
      "loss": 0.004,
      "step": 7650
    },
    {
      "epoch": 5.746436609152288,
      "grad_norm": 2.966593027114868,
      "learning_rate": 8.507126781695426e-06,
      "loss": 0.0173,
      "step": 7660
    },
    {
      "epoch": 5.753938484621155,
      "grad_norm": 0.2396276593208313,
      "learning_rate": 8.49212303075769e-06,
      "loss": 0.0114,
      "step": 7670
    },
    {
      "epoch": 5.761440360090022,
      "grad_norm": 0.1636045277118683,
      "learning_rate": 8.477119279819956e-06,
      "loss": 0.0262,
      "step": 7680
    },
    {
      "epoch": 5.76894223555889,
      "grad_norm": 1.2216665744781494,
      "learning_rate": 8.462115528882221e-06,
      "loss": 0.0241,
      "step": 7690
    },
    {
      "epoch": 5.776444111027757,
      "grad_norm": 3.1487059593200684,
      "learning_rate": 8.447111777944487e-06,
      "loss": 0.0281,
      "step": 7700
    },
    {
      "epoch": 5.783945986496624,
      "grad_norm": 1.0583244562149048,
      "learning_rate": 8.432108027006753e-06,
      "loss": 0.0221,
      "step": 7710
    },
    {
      "epoch": 5.791447861965492,
      "grad_norm": 0.3732219636440277,
      "learning_rate": 8.417104276069017e-06,
      "loss": 0.0169,
      "step": 7720
    },
    {
      "epoch": 5.798949737434358,
      "grad_norm": 0.6134173274040222,
      "learning_rate": 8.402100525131283e-06,
      "loss": 0.0072,
      "step": 7730
    },
    {
      "epoch": 5.806451612903226,
      "grad_norm": 0.7023488283157349,
      "learning_rate": 8.387096774193549e-06,
      "loss": 0.0095,
      "step": 7740
    },
    {
      "epoch": 5.813953488372093,
      "grad_norm": 0.24229180812835693,
      "learning_rate": 8.372093023255815e-06,
      "loss": 0.0051,
      "step": 7750
    },
    {
      "epoch": 5.82145536384096,
      "grad_norm": 0.6435655951499939,
      "learning_rate": 8.35708927231808e-06,
      "loss": 0.0185,
      "step": 7760
    },
    {
      "epoch": 5.828957239309828,
      "grad_norm": 0.0256499033421278,
      "learning_rate": 8.342085521380345e-06,
      "loss": 0.0114,
      "step": 7770
    },
    {
      "epoch": 5.836459114778695,
      "grad_norm": 1.5857853889465332,
      "learning_rate": 8.32708177044261e-06,
      "loss": 0.0208,
      "step": 7780
    },
    {
      "epoch": 5.843960990247562,
      "grad_norm": 0.6703242063522339,
      "learning_rate": 8.312078019504876e-06,
      "loss": 0.0143,
      "step": 7790
    },
    {
      "epoch": 5.851462865716429,
      "grad_norm": 1.058132290840149,
      "learning_rate": 8.297074268567142e-06,
      "loss": 0.0198,
      "step": 7800
    },
    {
      "epoch": 5.8589647411852965,
      "grad_norm": 1.1834160089492798,
      "learning_rate": 8.282070517629408e-06,
      "loss": 0.009,
      "step": 7810
    },
    {
      "epoch": 5.866466616654163,
      "grad_norm": 1.499916434288025,
      "learning_rate": 8.267066766691673e-06,
      "loss": 0.0119,
      "step": 7820
    },
    {
      "epoch": 5.873968492123031,
      "grad_norm": 0.6205196976661682,
      "learning_rate": 8.25206301575394e-06,
      "loss": 0.0257,
      "step": 7830
    },
    {
      "epoch": 5.8814703675918985,
      "grad_norm": 0.010891400277614594,
      "learning_rate": 8.237059264816205e-06,
      "loss": 0.0287,
      "step": 7840
    },
    {
      "epoch": 5.888972243060765,
      "grad_norm": 0.13017846643924713,
      "learning_rate": 8.222055513878471e-06,
      "loss": 0.0122,
      "step": 7850
    },
    {
      "epoch": 5.896474118529633,
      "grad_norm": 0.5989749431610107,
      "learning_rate": 8.207051762940735e-06,
      "loss": 0.0094,
      "step": 7860
    },
    {
      "epoch": 5.9039759939984995,
      "grad_norm": 1.2399687767028809,
      "learning_rate": 8.192048012003e-06,
      "loss": 0.038,
      "step": 7870
    },
    {
      "epoch": 5.911477869467367,
      "grad_norm": 0.5249791741371155,
      "learning_rate": 8.177044261065267e-06,
      "loss": 0.0064,
      "step": 7880
    },
    {
      "epoch": 5.918979744936234,
      "grad_norm": 0.29486748576164246,
      "learning_rate": 8.162040510127532e-06,
      "loss": 0.0115,
      "step": 7890
    },
    {
      "epoch": 5.926481620405101,
      "grad_norm": 0.16032174229621887,
      "learning_rate": 8.147036759189798e-06,
      "loss": 0.0281,
      "step": 7900
    },
    {
      "epoch": 5.933983495873968,
      "grad_norm": 0.6070472002029419,
      "learning_rate": 8.132033008252064e-06,
      "loss": 0.02,
      "step": 7910
    },
    {
      "epoch": 5.941485371342836,
      "grad_norm": 1.3604869842529297,
      "learning_rate": 8.11702925731433e-06,
      "loss": 0.0212,
      "step": 7920
    },
    {
      "epoch": 5.948987246811702,
      "grad_norm": 0.3030192255973816,
      "learning_rate": 8.102025506376596e-06,
      "loss": 0.0101,
      "step": 7930
    },
    {
      "epoch": 5.95648912228057,
      "grad_norm": 1.0047978162765503,
      "learning_rate": 8.087021755438861e-06,
      "loss": 0.0069,
      "step": 7940
    },
    {
      "epoch": 5.963990997749438,
      "grad_norm": 1.4790068864822388,
      "learning_rate": 8.072018004501127e-06,
      "loss": 0.0164,
      "step": 7950
    },
    {
      "epoch": 5.971492873218304,
      "grad_norm": 0.03269492834806442,
      "learning_rate": 8.057014253563391e-06,
      "loss": 0.0234,
      "step": 7960
    },
    {
      "epoch": 5.978994748687172,
      "grad_norm": 3.757476806640625,
      "learning_rate": 8.042010502625657e-06,
      "loss": 0.025,
      "step": 7970
    },
    {
      "epoch": 5.986496624156039,
      "grad_norm": 0.0090371984988451,
      "learning_rate": 8.027006751687923e-06,
      "loss": 0.0106,
      "step": 7980
    },
    {
      "epoch": 5.993998499624906,
      "grad_norm": 0.09273230284452438,
      "learning_rate": 8.012003000750189e-06,
      "loss": 0.0201,
      "step": 7990
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9919801691455234,
      "eval_f1": 0.9693763919821826,
      "eval_loss": 0.023734604939818382,
      "eval_precision": 0.9600220567962503,
      "eval_recall": 0.9789148158560584,
      "eval_runtime": 477.4722,
      "eval_samples_per_second": 57.455,
      "eval_steps_per_second": 2.396,
      "step": 7998
    },
    {
      "epoch": 6.001500375093774,
      "grad_norm": 0.8572689890861511,
      "learning_rate": 7.996999249812454e-06,
      "loss": 0.022,
      "step": 8000
    },
    {
      "epoch": 6.009002250562641,
      "grad_norm": 0.0880383551120758,
      "learning_rate": 7.98199549887472e-06,
      "loss": 0.0087,
      "step": 8010
    },
    {
      "epoch": 6.016504126031508,
      "grad_norm": 0.015542167238891125,
      "learning_rate": 7.966991747936984e-06,
      "loss": 0.014,
      "step": 8020
    },
    {
      "epoch": 6.024006001500375,
      "grad_norm": 0.8478063344955444,
      "learning_rate": 7.95198799699925e-06,
      "loss": 0.006,
      "step": 8030
    },
    {
      "epoch": 6.0315078769692425,
      "grad_norm": 0.9186273813247681,
      "learning_rate": 7.936984246061516e-06,
      "loss": 0.014,
      "step": 8040
    },
    {
      "epoch": 6.039009752438109,
      "grad_norm": 3.10849666595459,
      "learning_rate": 7.921980495123782e-06,
      "loss": 0.0089,
      "step": 8050
    },
    {
      "epoch": 6.046511627906977,
      "grad_norm": 0.5563107132911682,
      "learning_rate": 7.906976744186048e-06,
      "loss": 0.0196,
      "step": 8060
    },
    {
      "epoch": 6.0540135033758435,
      "grad_norm": 0.10057302564382553,
      "learning_rate": 7.891972993248312e-06,
      "loss": 0.0169,
      "step": 8070
    },
    {
      "epoch": 6.061515378844711,
      "grad_norm": 0.4775540828704834,
      "learning_rate": 7.876969242310577e-06,
      "loss": 0.0106,
      "step": 8080
    },
    {
      "epoch": 6.069017254313579,
      "grad_norm": 0.16983294486999512,
      "learning_rate": 7.861965491372843e-06,
      "loss": 0.012,
      "step": 8090
    },
    {
      "epoch": 6.0765191297824455,
      "grad_norm": 0.5349739789962769,
      "learning_rate": 7.846961740435109e-06,
      "loss": 0.0162,
      "step": 8100
    },
    {
      "epoch": 6.084021005251313,
      "grad_norm": 0.22463922202587128,
      "learning_rate": 7.831957989497375e-06,
      "loss": 0.0116,
      "step": 8110
    },
    {
      "epoch": 6.09152288072018,
      "grad_norm": 0.8439858555793762,
      "learning_rate": 7.81695423855964e-06,
      "loss": 0.015,
      "step": 8120
    },
    {
      "epoch": 6.099024756189047,
      "grad_norm": 0.012616588734090328,
      "learning_rate": 7.801950487621906e-06,
      "loss": 0.0058,
      "step": 8130
    },
    {
      "epoch": 6.106526631657914,
      "grad_norm": 1.9172656536102295,
      "learning_rate": 7.786946736684172e-06,
      "loss": 0.013,
      "step": 8140
    },
    {
      "epoch": 6.114028507126782,
      "grad_norm": 0.05499524995684624,
      "learning_rate": 7.771942985746436e-06,
      "loss": 0.0061,
      "step": 8150
    },
    {
      "epoch": 6.121530382595649,
      "grad_norm": 4.279514312744141,
      "learning_rate": 7.756939234808702e-06,
      "loss": 0.0104,
      "step": 8160
    },
    {
      "epoch": 6.129032258064516,
      "grad_norm": 5.9417595863342285,
      "learning_rate": 7.741935483870968e-06,
      "loss": 0.0088,
      "step": 8170
    },
    {
      "epoch": 6.136534133533384,
      "grad_norm": 0.21056057512760162,
      "learning_rate": 7.726931732933234e-06,
      "loss": 0.0066,
      "step": 8180
    },
    {
      "epoch": 6.14403600900225,
      "grad_norm": 0.0013738832203671336,
      "learning_rate": 7.7119279819955e-06,
      "loss": 0.0177,
      "step": 8190
    },
    {
      "epoch": 6.151537884471118,
      "grad_norm": 0.16842059791088104,
      "learning_rate": 7.696924231057765e-06,
      "loss": 0.0247,
      "step": 8200
    },
    {
      "epoch": 6.159039759939985,
      "grad_norm": 0.2508373260498047,
      "learning_rate": 7.681920480120031e-06,
      "loss": 0.0083,
      "step": 8210
    },
    {
      "epoch": 6.166541635408852,
      "grad_norm": 0.22568100690841675,
      "learning_rate": 7.666916729182297e-06,
      "loss": 0.0104,
      "step": 8220
    },
    {
      "epoch": 6.17404351087772,
      "grad_norm": 0.23590333759784698,
      "learning_rate": 7.651912978244563e-06,
      "loss": 0.0125,
      "step": 8230
    },
    {
      "epoch": 6.181545386346587,
      "grad_norm": 1.578940510749817,
      "learning_rate": 7.636909227306827e-06,
      "loss": 0.0244,
      "step": 8240
    },
    {
      "epoch": 6.189047261815454,
      "grad_norm": 1.0062484741210938,
      "learning_rate": 7.621905476369093e-06,
      "loss": 0.0126,
      "step": 8250
    },
    {
      "epoch": 6.196549137284321,
      "grad_norm": 0.37716394662857056,
      "learning_rate": 7.6069017254313585e-06,
      "loss": 0.0118,
      "step": 8260
    },
    {
      "epoch": 6.2040510127531885,
      "grad_norm": 0.4116375148296356,
      "learning_rate": 7.591897974493624e-06,
      "loss": 0.0147,
      "step": 8270
    },
    {
      "epoch": 6.211552888222055,
      "grad_norm": 0.01253750454634428,
      "learning_rate": 7.576894223555889e-06,
      "loss": 0.0123,
      "step": 8280
    },
    {
      "epoch": 6.219054763690923,
      "grad_norm": 0.037620436400175095,
      "learning_rate": 7.561890472618155e-06,
      "loss": 0.0097,
      "step": 8290
    },
    {
      "epoch": 6.2265566391597895,
      "grad_norm": 1.2426785230636597,
      "learning_rate": 7.546886721680421e-06,
      "loss": 0.0132,
      "step": 8300
    },
    {
      "epoch": 6.234058514628657,
      "grad_norm": 9.372685432434082,
      "learning_rate": 7.531882970742687e-06,
      "loss": 0.0096,
      "step": 8310
    },
    {
      "epoch": 6.241560390097525,
      "grad_norm": 0.6230764389038086,
      "learning_rate": 7.5168792198049524e-06,
      "loss": 0.0188,
      "step": 8320
    },
    {
      "epoch": 6.249062265566391,
      "grad_norm": 0.2678833603858948,
      "learning_rate": 7.501875468867218e-06,
      "loss": 0.0089,
      "step": 8330
    },
    {
      "epoch": 6.256564141035259,
      "grad_norm": 0.1434633582830429,
      "learning_rate": 7.486871717929482e-06,
      "loss": 0.0118,
      "step": 8340
    },
    {
      "epoch": 6.264066016504126,
      "grad_norm": 0.15946613252162933,
      "learning_rate": 7.471867966991748e-06,
      "loss": 0.0034,
      "step": 8350
    },
    {
      "epoch": 6.271567891972993,
      "grad_norm": 0.46373116970062256,
      "learning_rate": 7.456864216054014e-06,
      "loss": 0.01,
      "step": 8360
    },
    {
      "epoch": 6.27906976744186,
      "grad_norm": 0.8507311940193176,
      "learning_rate": 7.44186046511628e-06,
      "loss": 0.013,
      "step": 8370
    },
    {
      "epoch": 6.286571642910728,
      "grad_norm": 0.30558326840400696,
      "learning_rate": 7.4268567141785455e-06,
      "loss": 0.0098,
      "step": 8380
    },
    {
      "epoch": 6.294073518379595,
      "grad_norm": 0.5215631723403931,
      "learning_rate": 7.411852963240811e-06,
      "loss": 0.016,
      "step": 8390
    },
    {
      "epoch": 6.301575393848462,
      "grad_norm": 0.5163683295249939,
      "learning_rate": 7.396849212303076e-06,
      "loss": 0.0161,
      "step": 8400
    },
    {
      "epoch": 6.30907726931733,
      "grad_norm": 0.0554833747446537,
      "learning_rate": 7.381845461365342e-06,
      "loss": 0.0077,
      "step": 8410
    },
    {
      "epoch": 6.316579144786196,
      "grad_norm": 1.0709465742111206,
      "learning_rate": 7.366841710427608e-06,
      "loss": 0.0211,
      "step": 8420
    },
    {
      "epoch": 6.324081020255064,
      "grad_norm": 1.2530936002731323,
      "learning_rate": 7.351837959489873e-06,
      "loss": 0.0069,
      "step": 8430
    },
    {
      "epoch": 6.331582895723931,
      "grad_norm": 0.5161892771720886,
      "learning_rate": 7.336834208552139e-06,
      "loss": 0.0122,
      "step": 8440
    },
    {
      "epoch": 6.339084771192798,
      "grad_norm": 0.24551904201507568,
      "learning_rate": 7.321830457614404e-06,
      "loss": 0.0328,
      "step": 8450
    },
    {
      "epoch": 6.346586646661666,
      "grad_norm": 0.3369613289833069,
      "learning_rate": 7.306826706676669e-06,
      "loss": 0.0104,
      "step": 8460
    },
    {
      "epoch": 6.3540885221305325,
      "grad_norm": 0.7302138805389404,
      "learning_rate": 7.291822955738935e-06,
      "loss": 0.0101,
      "step": 8470
    },
    {
      "epoch": 6.3615903975994,
      "grad_norm": 0.46106162667274475,
      "learning_rate": 7.276819204801201e-06,
      "loss": 0.016,
      "step": 8480
    },
    {
      "epoch": 6.369092273068267,
      "grad_norm": 0.3103927969932556,
      "learning_rate": 7.261815453863467e-06,
      "loss": 0.0065,
      "step": 8490
    },
    {
      "epoch": 6.3765941485371345,
      "grad_norm": 1.3442169427871704,
      "learning_rate": 7.246811702925733e-06,
      "loss": 0.009,
      "step": 8500
    },
    {
      "epoch": 6.384096024006001,
      "grad_norm": 2.589019775390625,
      "learning_rate": 7.231807951987998e-06,
      "loss": 0.0085,
      "step": 8510
    },
    {
      "epoch": 6.391597899474869,
      "grad_norm": 1.1690059900283813,
      "learning_rate": 7.216804201050263e-06,
      "loss": 0.0039,
      "step": 8520
    },
    {
      "epoch": 6.3990997749437355,
      "grad_norm": 6.084981918334961,
      "learning_rate": 7.201800450112528e-06,
      "loss": 0.0302,
      "step": 8530
    },
    {
      "epoch": 6.406601650412603,
      "grad_norm": 14.75325870513916,
      "learning_rate": 7.186796699174794e-06,
      "loss": 0.0188,
      "step": 8540
    },
    {
      "epoch": 6.414103525881471,
      "grad_norm": 0.7033135294914246,
      "learning_rate": 7.17179294823706e-06,
      "loss": 0.0142,
      "step": 8550
    },
    {
      "epoch": 6.421605401350337,
      "grad_norm": 0.005647351499646902,
      "learning_rate": 7.156789197299326e-06,
      "loss": 0.0062,
      "step": 8560
    },
    {
      "epoch": 6.429107276819205,
      "grad_norm": 1.13090181350708,
      "learning_rate": 7.141785446361591e-06,
      "loss": 0.0101,
      "step": 8570
    },
    {
      "epoch": 6.436609152288072,
      "grad_norm": 0.30665168166160583,
      "learning_rate": 7.1267816954238564e-06,
      "loss": 0.0112,
      "step": 8580
    },
    {
      "epoch": 6.444111027756939,
      "grad_norm": 0.6828718781471252,
      "learning_rate": 7.111777944486122e-06,
      "loss": 0.0092,
      "step": 8590
    },
    {
      "epoch": 6.451612903225806,
      "grad_norm": 1.0372320413589478,
      "learning_rate": 7.096774193548388e-06,
      "loss": 0.0141,
      "step": 8600
    },
    {
      "epoch": 6.459114778694674,
      "grad_norm": 0.5075889825820923,
      "learning_rate": 7.081770442610654e-06,
      "loss": 0.0301,
      "step": 8610
    },
    {
      "epoch": 6.466616654163541,
      "grad_norm": 0.5959883332252502,
      "learning_rate": 7.066766691672918e-06,
      "loss": 0.0039,
      "step": 8620
    },
    {
      "epoch": 6.474118529632408,
      "grad_norm": 0.33980923891067505,
      "learning_rate": 7.051762940735184e-06,
      "loss": 0.0139,
      "step": 8630
    },
    {
      "epoch": 6.481620405101276,
      "grad_norm": 8.359621047973633,
      "learning_rate": 7.0367591897974495e-06,
      "loss": 0.0092,
      "step": 8640
    },
    {
      "epoch": 6.489122280570142,
      "grad_norm": 0.011591335758566856,
      "learning_rate": 7.021755438859715e-06,
      "loss": 0.0063,
      "step": 8650
    },
    {
      "epoch": 6.49662415603901,
      "grad_norm": 0.03090842440724373,
      "learning_rate": 7.006751687921981e-06,
      "loss": 0.0164,
      "step": 8660
    },
    {
      "epoch": 6.504126031507877,
      "grad_norm": 0.7824774980545044,
      "learning_rate": 6.991747936984247e-06,
      "loss": 0.014,
      "step": 8670
    },
    {
      "epoch": 6.511627906976744,
      "grad_norm": 0.7311086058616638,
      "learning_rate": 6.976744186046513e-06,
      "loss": 0.011,
      "step": 8680
    },
    {
      "epoch": 6.519129782445612,
      "grad_norm": 0.6390825510025024,
      "learning_rate": 6.961740435108778e-06,
      "loss": 0.0167,
      "step": 8690
    },
    {
      "epoch": 6.5266316579144785,
      "grad_norm": 1.3894864320755005,
      "learning_rate": 6.9467366841710435e-06,
      "loss": 0.0173,
      "step": 8700
    },
    {
      "epoch": 6.534133533383346,
      "grad_norm": 0.022245438769459724,
      "learning_rate": 6.931732933233309e-06,
      "loss": 0.0103,
      "step": 8710
    },
    {
      "epoch": 6.541635408852213,
      "grad_norm": 0.026639480143785477,
      "learning_rate": 6.916729182295574e-06,
      "loss": 0.0139,
      "step": 8720
    },
    {
      "epoch": 6.54913728432108,
      "grad_norm": 0.2721894383430481,
      "learning_rate": 6.90172543135784e-06,
      "loss": 0.0072,
      "step": 8730
    },
    {
      "epoch": 6.556639159789947,
      "grad_norm": 0.08022715151309967,
      "learning_rate": 6.886721680420105e-06,
      "loss": 0.0169,
      "step": 8740
    },
    {
      "epoch": 6.564141035258815,
      "grad_norm": 1.3743218183517456,
      "learning_rate": 6.871717929482371e-06,
      "loss": 0.0111,
      "step": 8750
    },
    {
      "epoch": 6.571642910727682,
      "grad_norm": 0.6145231127738953,
      "learning_rate": 6.856714178544637e-06,
      "loss": 0.022,
      "step": 8760
    },
    {
      "epoch": 6.579144786196549,
      "grad_norm": 0.009750806726515293,
      "learning_rate": 6.841710427606902e-06,
      "loss": 0.0197,
      "step": 8770
    },
    {
      "epoch": 6.586646661665417,
      "grad_norm": 2.4465603828430176,
      "learning_rate": 6.826706676669168e-06,
      "loss": 0.0055,
      "step": 8780
    },
    {
      "epoch": 6.594148537134283,
      "grad_norm": 0.0191001296043396,
      "learning_rate": 6.811702925731434e-06,
      "loss": 0.008,
      "step": 8790
    },
    {
      "epoch": 6.601650412603151,
      "grad_norm": 0.8634167909622192,
      "learning_rate": 6.7966991747937e-06,
      "loss": 0.0083,
      "step": 8800
    },
    {
      "epoch": 6.609152288072018,
      "grad_norm": 0.3180955946445465,
      "learning_rate": 6.781695423855964e-06,
      "loss": 0.0103,
      "step": 8810
    },
    {
      "epoch": 6.616654163540885,
      "grad_norm": 1.2752654552459717,
      "learning_rate": 6.76669167291823e-06,
      "loss": 0.0098,
      "step": 8820
    },
    {
      "epoch": 6.624156039009753,
      "grad_norm": 0.37650275230407715,
      "learning_rate": 6.7516879219804955e-06,
      "loss": 0.0138,
      "step": 8830
    },
    {
      "epoch": 6.63165791447862,
      "grad_norm": 2.4271979331970215,
      "learning_rate": 6.736684171042761e-06,
      "loss": 0.0193,
      "step": 8840
    },
    {
      "epoch": 6.639159789947487,
      "grad_norm": 7.869349002838135,
      "learning_rate": 6.721680420105027e-06,
      "loss": 0.0227,
      "step": 8850
    },
    {
      "epoch": 6.646661665416354,
      "grad_norm": 0.45285677909851074,
      "learning_rate": 6.706676669167292e-06,
      "loss": 0.0111,
      "step": 8860
    },
    {
      "epoch": 6.6541635408852216,
      "grad_norm": 0.40506240725517273,
      "learning_rate": 6.691672918229558e-06,
      "loss": 0.0182,
      "step": 8870
    },
    {
      "epoch": 6.661665416354088,
      "grad_norm": 1.9276806116104126,
      "learning_rate": 6.676669167291824e-06,
      "loss": 0.0028,
      "step": 8880
    },
    {
      "epoch": 6.669167291822956,
      "grad_norm": 1.2342218160629272,
      "learning_rate": 6.6616654163540894e-06,
      "loss": 0.0046,
      "step": 8890
    },
    {
      "epoch": 6.676669167291823,
      "grad_norm": 1.7314696311950684,
      "learning_rate": 6.646661665416355e-06,
      "loss": 0.0142,
      "step": 8900
    },
    {
      "epoch": 6.68417104276069,
      "grad_norm": 0.01857243850827217,
      "learning_rate": 6.631657914478619e-06,
      "loss": 0.0107,
      "step": 8910
    },
    {
      "epoch": 6.691672918229557,
      "grad_norm": 0.08472782373428345,
      "learning_rate": 6.616654163540885e-06,
      "loss": 0.0144,
      "step": 8920
    },
    {
      "epoch": 6.6991747936984245,
      "grad_norm": 0.6309853792190552,
      "learning_rate": 6.601650412603151e-06,
      "loss": 0.0039,
      "step": 8930
    },
    {
      "epoch": 6.706676669167292,
      "grad_norm": 0.002167702419683337,
      "learning_rate": 6.586646661665417e-06,
      "loss": 0.0112,
      "step": 8940
    },
    {
      "epoch": 6.714178544636159,
      "grad_norm": 1.575758695602417,
      "learning_rate": 6.5716429107276825e-06,
      "loss": 0.0131,
      "step": 8950
    },
    {
      "epoch": 6.721680420105026,
      "grad_norm": 0.013012910261750221,
      "learning_rate": 6.556639159789948e-06,
      "loss": 0.0099,
      "step": 8960
    },
    {
      "epoch": 6.729182295573893,
      "grad_norm": 1.7518237829208374,
      "learning_rate": 6.541635408852214e-06,
      "loss": 0.0126,
      "step": 8970
    },
    {
      "epoch": 6.736684171042761,
      "grad_norm": 0.21363778412342072,
      "learning_rate": 6.52663165791448e-06,
      "loss": 0.0261,
      "step": 8980
    },
    {
      "epoch": 6.7441860465116275,
      "grad_norm": 0.3860974609851837,
      "learning_rate": 6.511627906976745e-06,
      "loss": 0.0117,
      "step": 8990
    },
    {
      "epoch": 6.751687921980495,
      "grad_norm": 0.8135884404182434,
      "learning_rate": 6.49662415603901e-06,
      "loss": 0.0061,
      "step": 9000
    },
    {
      "epoch": 6.759189797449363,
      "grad_norm": 0.038087308406829834,
      "learning_rate": 6.481620405101276e-06,
      "loss": 0.0132,
      "step": 9010
    },
    {
      "epoch": 6.766691672918229,
      "grad_norm": 0.17073707282543182,
      "learning_rate": 6.4666166541635414e-06,
      "loss": 0.0089,
      "step": 9020
    },
    {
      "epoch": 6.774193548387097,
      "grad_norm": 0.3931600749492645,
      "learning_rate": 6.451612903225806e-06,
      "loss": 0.0158,
      "step": 9030
    },
    {
      "epoch": 6.781695423855964,
      "grad_norm": 0.010953778401017189,
      "learning_rate": 6.436609152288072e-06,
      "loss": 0.036,
      "step": 9040
    },
    {
      "epoch": 6.789197299324831,
      "grad_norm": 1.0095179080963135,
      "learning_rate": 6.421605401350338e-06,
      "loss": 0.014,
      "step": 9050
    },
    {
      "epoch": 6.796699174793698,
      "grad_norm": 0.17615285515785217,
      "learning_rate": 6.406601650412604e-06,
      "loss": 0.0101,
      "step": 9060
    },
    {
      "epoch": 6.804201050262566,
      "grad_norm": 14.614900588989258,
      "learning_rate": 6.3915978994748696e-06,
      "loss": 0.0164,
      "step": 9070
    },
    {
      "epoch": 6.811702925731433,
      "grad_norm": 0.9673625826835632,
      "learning_rate": 6.376594148537135e-06,
      "loss": 0.0065,
      "step": 9080
    },
    {
      "epoch": 6.8192048012003,
      "grad_norm": 3.4259915351867676,
      "learning_rate": 6.361590397599401e-06,
      "loss": 0.0105,
      "step": 9090
    },
    {
      "epoch": 6.8267066766691675,
      "grad_norm": 4.4688520431518555,
      "learning_rate": 6.346586646661665e-06,
      "loss": 0.0193,
      "step": 9100
    },
    {
      "epoch": 6.834208552138034,
      "grad_norm": 0.012848244979977608,
      "learning_rate": 6.331582895723931e-06,
      "loss": 0.0068,
      "step": 9110
    },
    {
      "epoch": 6.841710427606902,
      "grad_norm": 0.1449248343706131,
      "learning_rate": 6.316579144786197e-06,
      "loss": 0.0088,
      "step": 9120
    },
    {
      "epoch": 6.849212303075769,
      "grad_norm": 1.3312294483184814,
      "learning_rate": 6.301575393848463e-06,
      "loss": 0.0195,
      "step": 9130
    },
    {
      "epoch": 6.856714178544636,
      "grad_norm": 1.0031871795654297,
      "learning_rate": 6.2865716429107285e-06,
      "loss": 0.0043,
      "step": 9140
    },
    {
      "epoch": 6.864216054013504,
      "grad_norm": 0.5775558948516846,
      "learning_rate": 6.271567891972994e-06,
      "loss": 0.0157,
      "step": 9150
    },
    {
      "epoch": 6.8717179294823705,
      "grad_norm": 14.699256896972656,
      "learning_rate": 6.256564141035259e-06,
      "loss": 0.027,
      "step": 9160
    },
    {
      "epoch": 6.879219804951238,
      "grad_norm": 0.2909764051437378,
      "learning_rate": 6.241560390097525e-06,
      "loss": 0.0164,
      "step": 9170
    },
    {
      "epoch": 6.886721680420105,
      "grad_norm": 0.462617427110672,
      "learning_rate": 6.226556639159791e-06,
      "loss": 0.0083,
      "step": 9180
    },
    {
      "epoch": 6.894223555888972,
      "grad_norm": 0.08855272829532623,
      "learning_rate": 6.211552888222056e-06,
      "loss": 0.0056,
      "step": 9190
    },
    {
      "epoch": 6.901725431357839,
      "grad_norm": 1.1075770854949951,
      "learning_rate": 6.1965491372843216e-06,
      "loss": 0.0094,
      "step": 9200
    },
    {
      "epoch": 6.909227306826707,
      "grad_norm": 0.20205210149288177,
      "learning_rate": 6.1815453863465865e-06,
      "loss": 0.0075,
      "step": 9210
    },
    {
      "epoch": 6.916729182295574,
      "grad_norm": 0.003621831303462386,
      "learning_rate": 6.166541635408852e-06,
      "loss": 0.0092,
      "step": 9220
    },
    {
      "epoch": 6.924231057764441,
      "grad_norm": 0.6414679884910583,
      "learning_rate": 6.151537884471118e-06,
      "loss": 0.007,
      "step": 9230
    },
    {
      "epoch": 6.931732933233309,
      "grad_norm": 1.0138760805130005,
      "learning_rate": 6.136534133533384e-06,
      "loss": 0.0196,
      "step": 9240
    },
    {
      "epoch": 6.939234808702175,
      "grad_norm": 0.007510245777666569,
      "learning_rate": 6.12153038259565e-06,
      "loss": 0.0103,
      "step": 9250
    },
    {
      "epoch": 6.946736684171043,
      "grad_norm": 0.4648078978061676,
      "learning_rate": 6.1065266316579155e-06,
      "loss": 0.0107,
      "step": 9260
    },
    {
      "epoch": 6.95423855963991,
      "grad_norm": 0.9683881998062134,
      "learning_rate": 6.091522880720181e-06,
      "loss": 0.0079,
      "step": 9270
    },
    {
      "epoch": 6.961740435108777,
      "grad_norm": 0.25733932852745056,
      "learning_rate": 6.076519129782446e-06,
      "loss": 0.0084,
      "step": 9280
    },
    {
      "epoch": 6.969242310577645,
      "grad_norm": 0.15615250170230865,
      "learning_rate": 6.061515378844711e-06,
      "loss": 0.0072,
      "step": 9290
    },
    {
      "epoch": 6.976744186046512,
      "grad_norm": 0.1332801878452301,
      "learning_rate": 6.046511627906977e-06,
      "loss": 0.0105,
      "step": 9300
    },
    {
      "epoch": 6.984246061515379,
      "grad_norm": 2.8088021278381348,
      "learning_rate": 6.031507876969243e-06,
      "loss": 0.0137,
      "step": 9310
    },
    {
      "epoch": 6.991747936984246,
      "grad_norm": 0.006942637264728546,
      "learning_rate": 6.016504126031509e-06,
      "loss": 0.007,
      "step": 9320
    },
    {
      "epoch": 6.9992498124531135,
      "grad_norm": 2.1022605895996094,
      "learning_rate": 6.0015003750937736e-06,
      "loss": 0.0134,
      "step": 9330
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9924905220180811,
      "eval_f1": 0.9711322869955157,
      "eval_loss": 0.02390284650027752,
      "eval_precision": 0.9681475272422464,
      "eval_recall": 0.9741355074500984,
      "eval_runtime": 458.213,
      "eval_samples_per_second": 59.87,
      "eval_steps_per_second": 2.497,
      "step": 9331
    },
    {
      "epoch": 7.00675168792198,
      "grad_norm": 0.29935675859451294,
      "learning_rate": 5.986496624156039e-06,
      "loss": 0.0135,
      "step": 9340
    },
    {
      "epoch": 7.014253563390848,
      "grad_norm": 0.39182668924331665,
      "learning_rate": 5.971492873218305e-06,
      "loss": 0.0096,
      "step": 9350
    },
    {
      "epoch": 7.0217554388597145,
      "grad_norm": 0.6404193043708801,
      "learning_rate": 5.956489122280571e-06,
      "loss": 0.0159,
      "step": 9360
    },
    {
      "epoch": 7.029257314328582,
      "grad_norm": 0.7475326061248779,
      "learning_rate": 5.941485371342837e-06,
      "loss": 0.0098,
      "step": 9370
    },
    {
      "epoch": 7.03675918979745,
      "grad_norm": 0.7915890216827393,
      "learning_rate": 5.926481620405101e-06,
      "loss": 0.0093,
      "step": 9380
    },
    {
      "epoch": 7.0442610652663165,
      "grad_norm": 0.7308824062347412,
      "learning_rate": 5.911477869467367e-06,
      "loss": 0.0088,
      "step": 9390
    },
    {
      "epoch": 7.051762940735184,
      "grad_norm": 1.8285281658172607,
      "learning_rate": 5.8964741185296325e-06,
      "loss": 0.015,
      "step": 9400
    },
    {
      "epoch": 7.059264816204051,
      "grad_norm": 0.7136027216911316,
      "learning_rate": 5.881470367591898e-06,
      "loss": 0.0135,
      "step": 9410
    },
    {
      "epoch": 7.066766691672918,
      "grad_norm": 1.167222261428833,
      "learning_rate": 5.866466616654164e-06,
      "loss": 0.0318,
      "step": 9420
    },
    {
      "epoch": 7.074268567141785,
      "grad_norm": 0.9877155423164368,
      "learning_rate": 5.85146286571643e-06,
      "loss": 0.0118,
      "step": 9430
    },
    {
      "epoch": 7.081770442610653,
      "grad_norm": 0.5067634582519531,
      "learning_rate": 5.836459114778696e-06,
      "loss": 0.013,
      "step": 9440
    },
    {
      "epoch": 7.08927231807952,
      "grad_norm": 0.6582052111625671,
      "learning_rate": 5.821455363840961e-06,
      "loss": 0.0151,
      "step": 9450
    },
    {
      "epoch": 7.096774193548387,
      "grad_norm": 0.8259608149528503,
      "learning_rate": 5.806451612903226e-06,
      "loss": 0.0114,
      "step": 9460
    },
    {
      "epoch": 7.104276069017255,
      "grad_norm": 0.9183349013328552,
      "learning_rate": 5.791447861965492e-06,
      "loss": 0.0142,
      "step": 9470
    },
    {
      "epoch": 7.111777944486121,
      "grad_norm": 0.6276143193244934,
      "learning_rate": 5.776444111027757e-06,
      "loss": 0.0076,
      "step": 9480
    },
    {
      "epoch": 7.119279819954989,
      "grad_norm": 0.7460201978683472,
      "learning_rate": 5.761440360090023e-06,
      "loss": 0.0128,
      "step": 9490
    },
    {
      "epoch": 7.126781695423856,
      "grad_norm": 0.21062223613262177,
      "learning_rate": 5.746436609152288e-06,
      "loss": 0.0167,
      "step": 9500
    },
    {
      "epoch": 7.134283570892723,
      "grad_norm": 0.8921486735343933,
      "learning_rate": 5.731432858214554e-06,
      "loss": 0.0164,
      "step": 9510
    },
    {
      "epoch": 7.14178544636159,
      "grad_norm": 0.6237091422080994,
      "learning_rate": 5.7164291072768195e-06,
      "loss": 0.0099,
      "step": 9520
    },
    {
      "epoch": 7.149287321830458,
      "grad_norm": 1.273788571357727,
      "learning_rate": 5.701425356339085e-06,
      "loss": 0.0142,
      "step": 9530
    },
    {
      "epoch": 7.156789197299325,
      "grad_norm": 0.0702342540025711,
      "learning_rate": 5.686421605401351e-06,
      "loss": 0.008,
      "step": 9540
    },
    {
      "epoch": 7.164291072768192,
      "grad_norm": 0.20920899510383606,
      "learning_rate": 5.671417854463617e-06,
      "loss": 0.0122,
      "step": 9550
    },
    {
      "epoch": 7.1717929482370595,
      "grad_norm": 0.15165625512599945,
      "learning_rate": 5.656414103525883e-06,
      "loss": 0.0077,
      "step": 9560
    },
    {
      "epoch": 7.179294823705926,
      "grad_norm": 0.08064892143011093,
      "learning_rate": 5.641410352588147e-06,
      "loss": 0.004,
      "step": 9570
    },
    {
      "epoch": 7.186796699174794,
      "grad_norm": 0.19735127687454224,
      "learning_rate": 5.626406601650413e-06,
      "loss": 0.0087,
      "step": 9580
    },
    {
      "epoch": 7.1942985746436605,
      "grad_norm": 0.2508382499217987,
      "learning_rate": 5.611402850712678e-06,
      "loss": 0.0043,
      "step": 9590
    },
    {
      "epoch": 7.201800450112528,
      "grad_norm": 0.2319820523262024,
      "learning_rate": 5.596399099774944e-06,
      "loss": 0.0082,
      "step": 9600
    },
    {
      "epoch": 7.209302325581396,
      "grad_norm": 0.8702706098556519,
      "learning_rate": 5.58139534883721e-06,
      "loss": 0.0052,
      "step": 9610
    },
    {
      "epoch": 7.216804201050262,
      "grad_norm": 16.865802764892578,
      "learning_rate": 5.566391597899475e-06,
      "loss": 0.0092,
      "step": 9620
    },
    {
      "epoch": 7.22430607651913,
      "grad_norm": 0.0387459322810173,
      "learning_rate": 5.551387846961741e-06,
      "loss": 0.0078,
      "step": 9630
    },
    {
      "epoch": 7.231807951987997,
      "grad_norm": 0.11381720751523972,
      "learning_rate": 5.5363840960240066e-06,
      "loss": 0.0073,
      "step": 9640
    },
    {
      "epoch": 7.239309827456864,
      "grad_norm": 0.6915527582168579,
      "learning_rate": 5.521380345086272e-06,
      "loss": 0.0102,
      "step": 9650
    },
    {
      "epoch": 7.246811702925731,
      "grad_norm": 0.003102569142356515,
      "learning_rate": 5.506376594148538e-06,
      "loss": 0.0117,
      "step": 9660
    },
    {
      "epoch": 7.254313578394599,
      "grad_norm": 2.6091580390930176,
      "learning_rate": 5.491372843210802e-06,
      "loss": 0.0101,
      "step": 9670
    },
    {
      "epoch": 7.261815453863466,
      "grad_norm": 0.6661621332168579,
      "learning_rate": 5.476369092273068e-06,
      "loss": 0.0143,
      "step": 9680
    },
    {
      "epoch": 7.269317329332333,
      "grad_norm": 0.0022161637898534536,
      "learning_rate": 5.461365341335334e-06,
      "loss": 0.0177,
      "step": 9690
    },
    {
      "epoch": 7.276819204801201,
      "grad_norm": 0.20118345320224762,
      "learning_rate": 5.4463615903976e-06,
      "loss": 0.0067,
      "step": 9700
    },
    {
      "epoch": 7.284321080270067,
      "grad_norm": 0.7254260778427124,
      "learning_rate": 5.4313578394598655e-06,
      "loss": 0.0061,
      "step": 9710
    },
    {
      "epoch": 7.291822955738935,
      "grad_norm": 0.2781420350074768,
      "learning_rate": 5.416354088522131e-06,
      "loss": 0.0115,
      "step": 9720
    },
    {
      "epoch": 7.299324831207802,
      "grad_norm": 0.008328877389431,
      "learning_rate": 5.401350337584397e-06,
      "loss": 0.0154,
      "step": 9730
    },
    {
      "epoch": 7.306826706676669,
      "grad_norm": 0.04333092272281647,
      "learning_rate": 5.386346586646662e-06,
      "loss": 0.004,
      "step": 9740
    },
    {
      "epoch": 7.314328582145537,
      "grad_norm": 0.03136695548892021,
      "learning_rate": 5.371342835708928e-06,
      "loss": 0.0106,
      "step": 9750
    },
    {
      "epoch": 7.3218304576144035,
      "grad_norm": 0.8143454790115356,
      "learning_rate": 5.356339084771193e-06,
      "loss": 0.0183,
      "step": 9760
    },
    {
      "epoch": 7.329332333083271,
      "grad_norm": 0.3254280388355255,
      "learning_rate": 5.3413353338334586e-06,
      "loss": 0.0157,
      "step": 9770
    },
    {
      "epoch": 7.336834208552138,
      "grad_norm": 0.003713640384376049,
      "learning_rate": 5.326331582895724e-06,
      "loss": 0.0158,
      "step": 9780
    },
    {
      "epoch": 7.3443360840210055,
      "grad_norm": 0.005570314358919859,
      "learning_rate": 5.311327831957989e-06,
      "loss": 0.0132,
      "step": 9790
    },
    {
      "epoch": 7.351837959489872,
      "grad_norm": 0.6920429468154907,
      "learning_rate": 5.296324081020255e-06,
      "loss": 0.0163,
      "step": 9800
    },
    {
      "epoch": 7.35933983495874,
      "grad_norm": 0.4735810458660126,
      "learning_rate": 5.281320330082521e-06,
      "loss": 0.0064,
      "step": 9810
    },
    {
      "epoch": 7.3668417104276065,
      "grad_norm": 1.9155062437057495,
      "learning_rate": 5.266316579144787e-06,
      "loss": 0.0074,
      "step": 9820
    },
    {
      "epoch": 7.374343585896474,
      "grad_norm": 0.007747788913547993,
      "learning_rate": 5.2513128282070525e-06,
      "loss": 0.0019,
      "step": 9830
    },
    {
      "epoch": 7.381845461365342,
      "grad_norm": 1.2569561004638672,
      "learning_rate": 5.236309077269318e-06,
      "loss": 0.0094,
      "step": 9840
    },
    {
      "epoch": 7.389347336834208,
      "grad_norm": 1.0726730823516846,
      "learning_rate": 5.221305326331584e-06,
      "loss": 0.0157,
      "step": 9850
    },
    {
      "epoch": 7.396849212303076,
      "grad_norm": 0.249763622879982,
      "learning_rate": 5.206301575393848e-06,
      "loss": 0.0076,
      "step": 9860
    },
    {
      "epoch": 7.404351087771943,
      "grad_norm": 0.6247074604034424,
      "learning_rate": 5.191297824456114e-06,
      "loss": 0.0039,
      "step": 9870
    },
    {
      "epoch": 7.41185296324081,
      "grad_norm": 0.03724082559347153,
      "learning_rate": 5.17629407351838e-06,
      "loss": 0.0157,
      "step": 9880
    },
    {
      "epoch": 7.419354838709677,
      "grad_norm": 0.11390846967697144,
      "learning_rate": 5.161290322580646e-06,
      "loss": 0.0213,
      "step": 9890
    },
    {
      "epoch": 7.426856714178545,
      "grad_norm": 3.155641794204712,
      "learning_rate": 5.146286571642911e-06,
      "loss": 0.0232,
      "step": 9900
    },
    {
      "epoch": 7.434358589647412,
      "grad_norm": 0.1584741324186325,
      "learning_rate": 5.131282820705177e-06,
      "loss": 0.0096,
      "step": 9910
    },
    {
      "epoch": 7.441860465116279,
      "grad_norm": 1.7022879123687744,
      "learning_rate": 5.116279069767442e-06,
      "loss": 0.0113,
      "step": 9920
    },
    {
      "epoch": 7.449362340585147,
      "grad_norm": 0.00568060576915741,
      "learning_rate": 5.101275318829708e-06,
      "loss": 0.0114,
      "step": 9930
    },
    {
      "epoch": 7.456864216054013,
      "grad_norm": 0.5143412351608276,
      "learning_rate": 5.086271567891974e-06,
      "loss": 0.0031,
      "step": 9940
    },
    {
      "epoch": 7.464366091522881,
      "grad_norm": 0.010665583424270153,
      "learning_rate": 5.071267816954239e-06,
      "loss": 0.0051,
      "step": 9950
    },
    {
      "epoch": 7.471867966991748,
      "grad_norm": 0.897291362285614,
      "learning_rate": 5.0562640660165045e-06,
      "loss": 0.0114,
      "step": 9960
    },
    {
      "epoch": 7.479369842460615,
      "grad_norm": 0.5488364100456238,
      "learning_rate": 5.0412603150787695e-06,
      "loss": 0.0175,
      "step": 9970
    },
    {
      "epoch": 7.486871717929482,
      "grad_norm": 2.7302191257476807,
      "learning_rate": 5.026256564141035e-06,
      "loss": 0.0161,
      "step": 9980
    },
    {
      "epoch": 7.4943735933983495,
      "grad_norm": 0.006409092806279659,
      "learning_rate": 5.011252813203301e-06,
      "loss": 0.0116,
      "step": 9990
    },
    {
      "epoch": 7.501875468867217,
      "grad_norm": 0.5875623226165771,
      "learning_rate": 4.996249062265567e-06,
      "loss": 0.0148,
      "step": 10000
    },
    {
      "epoch": 7.509377344336084,
      "grad_norm": 0.6156027317047119,
      "learning_rate": 4.981245311327833e-06,
      "loss": 0.0074,
      "step": 10010
    },
    {
      "epoch": 7.516879219804951,
      "grad_norm": 0.6075912714004517,
      "learning_rate": 4.9662415603900985e-06,
      "loss": 0.0112,
      "step": 10020
    },
    {
      "epoch": 7.524381095273818,
      "grad_norm": 0.023309413343667984,
      "learning_rate": 4.951237809452363e-06,
      "loss": 0.0037,
      "step": 10030
    },
    {
      "epoch": 7.531882970742686,
      "grad_norm": 0.6592370867729187,
      "learning_rate": 4.936234058514629e-06,
      "loss": 0.0064,
      "step": 10040
    },
    {
      "epoch": 7.5393848462115525,
      "grad_norm": 1.1463027000427246,
      "learning_rate": 4.921230307576895e-06,
      "loss": 0.0197,
      "step": 10050
    },
    {
      "epoch": 7.54688672168042,
      "grad_norm": 0.006439154036343098,
      "learning_rate": 4.90622655663916e-06,
      "loss": 0.0076,
      "step": 10060
    },
    {
      "epoch": 7.554388597149288,
      "grad_norm": 0.026448093354701996,
      "learning_rate": 4.891222805701426e-06,
      "loss": 0.0097,
      "step": 10070
    },
    {
      "epoch": 7.561890472618154,
      "grad_norm": 0.2719235122203827,
      "learning_rate": 4.8762190547636916e-06,
      "loss": 0.0111,
      "step": 10080
    },
    {
      "epoch": 7.569392348087022,
      "grad_norm": 0.481847882270813,
      "learning_rate": 4.8612153038259565e-06,
      "loss": 0.0031,
      "step": 10090
    },
    {
      "epoch": 7.576894223555889,
      "grad_norm": 0.7928556203842163,
      "learning_rate": 4.846211552888222e-06,
      "loss": 0.0111,
      "step": 10100
    },
    {
      "epoch": 7.584396099024756,
      "grad_norm": 0.6552680134773254,
      "learning_rate": 4.831207801950488e-06,
      "loss": 0.0058,
      "step": 10110
    },
    {
      "epoch": 7.591897974493623,
      "grad_norm": 0.11684921383857727,
      "learning_rate": 4.816204051012753e-06,
      "loss": 0.0018,
      "step": 10120
    },
    {
      "epoch": 7.599399849962491,
      "grad_norm": 0.005337784066796303,
      "learning_rate": 4.801200300075019e-06,
      "loss": 0.0074,
      "step": 10130
    },
    {
      "epoch": 7.606901725431358,
      "grad_norm": 0.1874663233757019,
      "learning_rate": 4.786196549137285e-06,
      "loss": 0.0137,
      "step": 10140
    },
    {
      "epoch": 7.614403600900225,
      "grad_norm": 0.9004878401756287,
      "learning_rate": 4.7711927981995505e-06,
      "loss": 0.0107,
      "step": 10150
    },
    {
      "epoch": 7.6219054763690925,
      "grad_norm": 0.8317239880561829,
      "learning_rate": 4.756189047261816e-06,
      "loss": 0.0104,
      "step": 10160
    },
    {
      "epoch": 7.629407351837959,
      "grad_norm": 0.03744100406765938,
      "learning_rate": 4.741185296324081e-06,
      "loss": 0.0117,
      "step": 10170
    },
    {
      "epoch": 7.636909227306827,
      "grad_norm": 0.4175102412700653,
      "learning_rate": 4.726181545386347e-06,
      "loss": 0.0154,
      "step": 10180
    },
    {
      "epoch": 7.644411102775694,
      "grad_norm": 0.42489826679229736,
      "learning_rate": 4.711177794448613e-06,
      "loss": 0.0089,
      "step": 10190
    },
    {
      "epoch": 7.651912978244561,
      "grad_norm": 0.7945109605789185,
      "learning_rate": 4.696174043510879e-06,
      "loss": 0.0102,
      "step": 10200
    },
    {
      "epoch": 7.659414853713429,
      "grad_norm": 3.0396480560302734,
      "learning_rate": 4.6811702925731436e-06,
      "loss": 0.0165,
      "step": 10210
    },
    {
      "epoch": 7.6669167291822955,
      "grad_norm": 0.7221439480781555,
      "learning_rate": 4.666166541635409e-06,
      "loss": 0.0099,
      "step": 10220
    },
    {
      "epoch": 7.674418604651163,
      "grad_norm": 1.4063318967819214,
      "learning_rate": 4.651162790697675e-06,
      "loss": 0.0067,
      "step": 10230
    },
    {
      "epoch": 7.68192048012003,
      "grad_norm": 0.9949857592582703,
      "learning_rate": 4.63615903975994e-06,
      "loss": 0.0157,
      "step": 10240
    },
    {
      "epoch": 7.689422355588897,
      "grad_norm": 0.003714531660079956,
      "learning_rate": 4.621155288822206e-06,
      "loss": 0.0075,
      "step": 10250
    },
    {
      "epoch": 7.696924231057764,
      "grad_norm": 0.4895258843898773,
      "learning_rate": 4.606151537884471e-06,
      "loss": 0.0162,
      "step": 10260
    },
    {
      "epoch": 7.704426106526632,
      "grad_norm": 0.5703362226486206,
      "learning_rate": 4.591147786946737e-06,
      "loss": 0.0236,
      "step": 10270
    },
    {
      "epoch": 7.711927981995499,
      "grad_norm": 0.5499668717384338,
      "learning_rate": 4.5761440360090025e-06,
      "loss": 0.014,
      "step": 10280
    },
    {
      "epoch": 7.719429857464366,
      "grad_norm": 0.4953390061855316,
      "learning_rate": 4.561140285071268e-06,
      "loss": 0.01,
      "step": 10290
    },
    {
      "epoch": 7.726931732933234,
      "grad_norm": 0.007466485258191824,
      "learning_rate": 4.546136534133534e-06,
      "loss": 0.0128,
      "step": 10300
    },
    {
      "epoch": 7.7344336084021,
      "grad_norm": 3.7065908908843994,
      "learning_rate": 4.531132783195799e-06,
      "loss": 0.0162,
      "step": 10310
    },
    {
      "epoch": 7.741935483870968,
      "grad_norm": 0.48073339462280273,
      "learning_rate": 4.516129032258065e-06,
      "loss": 0.0031,
      "step": 10320
    },
    {
      "epoch": 7.749437359339835,
      "grad_norm": 0.9247625470161438,
      "learning_rate": 4.501125281320331e-06,
      "loss": 0.0141,
      "step": 10330
    },
    {
      "epoch": 7.756939234808702,
      "grad_norm": 6.042189598083496,
      "learning_rate": 4.486121530382596e-06,
      "loss": 0.0105,
      "step": 10340
    },
    {
      "epoch": 7.76444111027757,
      "grad_norm": 1.0510878562927246,
      "learning_rate": 4.471117779444862e-06,
      "loss": 0.008,
      "step": 10350
    },
    {
      "epoch": 7.771942985746437,
      "grad_norm": 1.3441081047058105,
      "learning_rate": 4.456114028507127e-06,
      "loss": 0.0109,
      "step": 10360
    },
    {
      "epoch": 7.779444861215304,
      "grad_norm": 0.3508199453353882,
      "learning_rate": 4.441110277569393e-06,
      "loss": 0.0187,
      "step": 10370
    },
    {
      "epoch": 7.786946736684171,
      "grad_norm": 0.0181904174387455,
      "learning_rate": 4.426106526631658e-06,
      "loss": 0.0107,
      "step": 10380
    },
    {
      "epoch": 7.7944486121530385,
      "grad_norm": 0.5550413727760315,
      "learning_rate": 4.411102775693924e-06,
      "loss": 0.0084,
      "step": 10390
    },
    {
      "epoch": 7.801950487621905,
      "grad_norm": 0.7237007021903992,
      "learning_rate": 4.3960990247561895e-06,
      "loss": 0.0095,
      "step": 10400
    },
    {
      "epoch": 7.809452363090773,
      "grad_norm": 0.018400393426418304,
      "learning_rate": 4.3810952738184545e-06,
      "loss": 0.0062,
      "step": 10410
    },
    {
      "epoch": 7.81695423855964,
      "grad_norm": 0.7045944333076477,
      "learning_rate": 4.36609152288072e-06,
      "loss": 0.0064,
      "step": 10420
    },
    {
      "epoch": 7.824456114028507,
      "grad_norm": 0.7183197736740112,
      "learning_rate": 4.351087771942986e-06,
      "loss": 0.0129,
      "step": 10430
    },
    {
      "epoch": 7.831957989497374,
      "grad_norm": 13.1843843460083,
      "learning_rate": 4.336084021005252e-06,
      "loss": 0.0084,
      "step": 10440
    },
    {
      "epoch": 7.8394598649662415,
      "grad_norm": 0.017611417919397354,
      "learning_rate": 4.321080270067517e-06,
      "loss": 0.0104,
      "step": 10450
    },
    {
      "epoch": 7.846961740435109,
      "grad_norm": 0.5244371891021729,
      "learning_rate": 4.306076519129783e-06,
      "loss": 0.0047,
      "step": 10460
    },
    {
      "epoch": 7.854463615903976,
      "grad_norm": 0.11635297536849976,
      "learning_rate": 4.291072768192048e-06,
      "loss": 0.0119,
      "step": 10470
    },
    {
      "epoch": 7.861965491372843,
      "grad_norm": 0.393608421087265,
      "learning_rate": 4.276069017254314e-06,
      "loss": 0.0111,
      "step": 10480
    },
    {
      "epoch": 7.86946736684171,
      "grad_norm": 0.05155593156814575,
      "learning_rate": 4.26106526631658e-06,
      "loss": 0.0085,
      "step": 10490
    },
    {
      "epoch": 7.876969242310578,
      "grad_norm": 1.4293172359466553,
      "learning_rate": 4.246061515378845e-06,
      "loss": 0.0088,
      "step": 10500
    },
    {
      "epoch": 7.884471117779444,
      "grad_norm": 0.4544096291065216,
      "learning_rate": 4.231057764441111e-06,
      "loss": 0.0069,
      "step": 10510
    },
    {
      "epoch": 7.891972993248312,
      "grad_norm": 0.616399884223938,
      "learning_rate": 4.2160540135033765e-06,
      "loss": 0.0059,
      "step": 10520
    },
    {
      "epoch": 7.89947486871718,
      "grad_norm": 0.004467526450753212,
      "learning_rate": 4.2010502625656415e-06,
      "loss": 0.0087,
      "step": 10530
    },
    {
      "epoch": 7.906976744186046,
      "grad_norm": 2.4970059394836426,
      "learning_rate": 4.186046511627907e-06,
      "loss": 0.0081,
      "step": 10540
    },
    {
      "epoch": 7.914478619654914,
      "grad_norm": 0.8976947069168091,
      "learning_rate": 4.171042760690172e-06,
      "loss": 0.0139,
      "step": 10550
    },
    {
      "epoch": 7.921980495123781,
      "grad_norm": 0.0874042734503746,
      "learning_rate": 4.156039009752438e-06,
      "loss": 0.0163,
      "step": 10560
    },
    {
      "epoch": 7.929482370592648,
      "grad_norm": 0.01984957791864872,
      "learning_rate": 4.141035258814704e-06,
      "loss": 0.0101,
      "step": 10570
    },
    {
      "epoch": 7.936984246061515,
      "grad_norm": 0.23203887045383453,
      "learning_rate": 4.12603150787697e-06,
      "loss": 0.0089,
      "step": 10580
    },
    {
      "epoch": 7.944486121530383,
      "grad_norm": 0.3905419111251831,
      "learning_rate": 4.1110277569392354e-06,
      "loss": 0.0188,
      "step": 10590
    },
    {
      "epoch": 7.95198799699925,
      "grad_norm": 0.03202289715409279,
      "learning_rate": 4.0960240060015e-06,
      "loss": 0.0091,
      "step": 10600
    },
    {
      "epoch": 7.959489872468117,
      "grad_norm": 1.1256301403045654,
      "learning_rate": 4.081020255063766e-06,
      "loss": 0.0054,
      "step": 10610
    },
    {
      "epoch": 7.9669917479369845,
      "grad_norm": 0.6697853803634644,
      "learning_rate": 4.066016504126032e-06,
      "loss": 0.0046,
      "step": 10620
    },
    {
      "epoch": 7.974493623405851,
      "grad_norm": 6.357245445251465,
      "learning_rate": 4.051012753188298e-06,
      "loss": 0.0067,
      "step": 10630
    },
    {
      "epoch": 7.981995498874719,
      "grad_norm": 1.0506813526153564,
      "learning_rate": 4.036009002250564e-06,
      "loss": 0.0215,
      "step": 10640
    },
    {
      "epoch": 7.9894973743435855,
      "grad_norm": 0.2963888645172119,
      "learning_rate": 4.0210052513128285e-06,
      "loss": 0.0143,
      "step": 10650
    },
    {
      "epoch": 7.996999249812453,
      "grad_norm": 3.385266065597534,
      "learning_rate": 4.006001500375094e-06,
      "loss": 0.0242,
      "step": 10660
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9925998833479148,
      "eval_f1": 0.9715964740450538,
      "eval_loss": 0.023070862516760826,
      "eval_precision": 0.9671309192200557,
      "eval_recall": 0.9761034579701996,
      "eval_runtime": 482.9208,
      "eval_samples_per_second": 56.806,
      "eval_steps_per_second": 2.369,
      "step": 10664
    }
  ],
  "logging_steps": 10,
  "max_steps": 13330,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.362649859422835e+17,
  "train_batch_size": 96,
  "trial_name": null,
  "trial_params": null
}
