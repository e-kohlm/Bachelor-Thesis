{
  "best_metric": 0.9425221618530168,
  "best_model_checkpoint": "../saved_models/open_redirect/checkpoint-3712",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 3712,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0021551724137931034,
      "grad_norm": 44.142940521240234,
      "learning_rate": 1.9995689655172415e-05,
      "loss": 0.7439,
      "step": 1
    },
    {
      "epoch": 0.021551724137931036,
      "grad_norm": 13.882362365722656,
      "learning_rate": 1.9956896551724137e-05,
      "loss": 0.5297,
      "step": 10
    },
    {
      "epoch": 0.04310344827586207,
      "grad_norm": 10.46764087677002,
      "learning_rate": 1.991379310344828e-05,
      "loss": 0.4575,
      "step": 20
    },
    {
      "epoch": 0.06465517241379311,
      "grad_norm": 15.749137878417969,
      "learning_rate": 1.9870689655172415e-05,
      "loss": 0.4278,
      "step": 30
    },
    {
      "epoch": 0.08620689655172414,
      "grad_norm": 9.00157642364502,
      "learning_rate": 1.9827586206896554e-05,
      "loss": 0.4709,
      "step": 40
    },
    {
      "epoch": 0.10775862068965517,
      "grad_norm": 10.67427921295166,
      "learning_rate": 1.9784482758620693e-05,
      "loss": 0.4318,
      "step": 50
    },
    {
      "epoch": 0.12931034482758622,
      "grad_norm": 13.375914573669434,
      "learning_rate": 1.9741379310344828e-05,
      "loss": 0.4558,
      "step": 60
    },
    {
      "epoch": 0.15086206896551724,
      "grad_norm": 8.206633567810059,
      "learning_rate": 1.9698275862068967e-05,
      "loss": 0.4287,
      "step": 70
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 7.420380592346191,
      "learning_rate": 1.9655172413793106e-05,
      "loss": 0.369,
      "step": 80
    },
    {
      "epoch": 0.1939655172413793,
      "grad_norm": 40.81239318847656,
      "learning_rate": 1.9612068965517245e-05,
      "loss": 0.4087,
      "step": 90
    },
    {
      "epoch": 0.21551724137931033,
      "grad_norm": 8.30517578125,
      "learning_rate": 1.956896551724138e-05,
      "loss": 0.3922,
      "step": 100
    },
    {
      "epoch": 0.23706896551724138,
      "grad_norm": 7.485233306884766,
      "learning_rate": 1.952586206896552e-05,
      "loss": 0.3758,
      "step": 110
    },
    {
      "epoch": 0.25862068965517243,
      "grad_norm": 7.239657402038574,
      "learning_rate": 1.9482758620689658e-05,
      "loss": 0.4139,
      "step": 120
    },
    {
      "epoch": 0.2801724137931034,
      "grad_norm": 8.71871566772461,
      "learning_rate": 1.9439655172413793e-05,
      "loss": 0.3989,
      "step": 130
    },
    {
      "epoch": 0.3017241379310345,
      "grad_norm": 6.880522727966309,
      "learning_rate": 1.9396551724137932e-05,
      "loss": 0.3576,
      "step": 140
    },
    {
      "epoch": 0.3232758620689655,
      "grad_norm": 5.436368942260742,
      "learning_rate": 1.935344827586207e-05,
      "loss": 0.3445,
      "step": 150
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 5.3440070152282715,
      "learning_rate": 1.931034482758621e-05,
      "loss": 0.3447,
      "step": 160
    },
    {
      "epoch": 0.36637931034482757,
      "grad_norm": 10.102776527404785,
      "learning_rate": 1.9267241379310345e-05,
      "loss": 0.3814,
      "step": 170
    },
    {
      "epoch": 0.3879310344827586,
      "grad_norm": 6.208913803100586,
      "learning_rate": 1.9224137931034484e-05,
      "loss": 0.3407,
      "step": 180
    },
    {
      "epoch": 0.40948275862068967,
      "grad_norm": 5.459676265716553,
      "learning_rate": 1.9181034482758623e-05,
      "loss": 0.3496,
      "step": 190
    },
    {
      "epoch": 0.43103448275862066,
      "grad_norm": 4.3873066902160645,
      "learning_rate": 1.913793103448276e-05,
      "loss": 0.3632,
      "step": 200
    },
    {
      "epoch": 0.4525862068965517,
      "grad_norm": 7.979644775390625,
      "learning_rate": 1.9094827586206898e-05,
      "loss": 0.3072,
      "step": 210
    },
    {
      "epoch": 0.47413793103448276,
      "grad_norm": 6.02789306640625,
      "learning_rate": 1.9051724137931036e-05,
      "loss": 0.322,
      "step": 220
    },
    {
      "epoch": 0.4956896551724138,
      "grad_norm": 3.497509002685547,
      "learning_rate": 1.9008620689655175e-05,
      "loss": 0.3288,
      "step": 230
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 3.629101276397705,
      "learning_rate": 1.896551724137931e-05,
      "loss": 0.3089,
      "step": 240
    },
    {
      "epoch": 0.5387931034482759,
      "grad_norm": 4.531296730041504,
      "learning_rate": 1.892241379310345e-05,
      "loss": 0.3315,
      "step": 250
    },
    {
      "epoch": 0.5603448275862069,
      "grad_norm": 4.24749755859375,
      "learning_rate": 1.887931034482759e-05,
      "loss": 0.2722,
      "step": 260
    },
    {
      "epoch": 0.5818965517241379,
      "grad_norm": 4.902090549468994,
      "learning_rate": 1.8836206896551724e-05,
      "loss": 0.2754,
      "step": 270
    },
    {
      "epoch": 0.603448275862069,
      "grad_norm": 5.110723972320557,
      "learning_rate": 1.8793103448275863e-05,
      "loss": 0.3223,
      "step": 280
    },
    {
      "epoch": 0.625,
      "grad_norm": 4.690613269805908,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.285,
      "step": 290
    },
    {
      "epoch": 0.646551724137931,
      "grad_norm": 3.9228150844573975,
      "learning_rate": 1.8706896551724137e-05,
      "loss": 0.2688,
      "step": 300
    },
    {
      "epoch": 0.6681034482758621,
      "grad_norm": 3.777127981185913,
      "learning_rate": 1.8663793103448276e-05,
      "loss": 0.2556,
      "step": 310
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 5.256263732910156,
      "learning_rate": 1.8620689655172415e-05,
      "loss": 0.2618,
      "step": 320
    },
    {
      "epoch": 0.7112068965517241,
      "grad_norm": 10.672235488891602,
      "learning_rate": 1.8577586206896554e-05,
      "loss": 0.2533,
      "step": 330
    },
    {
      "epoch": 0.7327586206896551,
      "grad_norm": 3.3339643478393555,
      "learning_rate": 1.8534482758620693e-05,
      "loss": 0.309,
      "step": 340
    },
    {
      "epoch": 0.7543103448275862,
      "grad_norm": 5.021992206573486,
      "learning_rate": 1.8491379310344828e-05,
      "loss": 0.2677,
      "step": 350
    },
    {
      "epoch": 0.7758620689655172,
      "grad_norm": 5.104833602905273,
      "learning_rate": 1.8448275862068967e-05,
      "loss": 0.2728,
      "step": 360
    },
    {
      "epoch": 0.7974137931034483,
      "grad_norm": 6.083566665649414,
      "learning_rate": 1.8405172413793106e-05,
      "loss": 0.23,
      "step": 370
    },
    {
      "epoch": 0.8189655172413793,
      "grad_norm": 4.434750556945801,
      "learning_rate": 1.8362068965517245e-05,
      "loss": 0.1968,
      "step": 380
    },
    {
      "epoch": 0.8405172413793104,
      "grad_norm": 6.631886005401611,
      "learning_rate": 1.831896551724138e-05,
      "loss": 0.2108,
      "step": 390
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 5.361013889312744,
      "learning_rate": 1.827586206896552e-05,
      "loss": 0.2216,
      "step": 400
    },
    {
      "epoch": 0.8836206896551724,
      "grad_norm": 5.038382053375244,
      "learning_rate": 1.8232758620689658e-05,
      "loss": 0.2113,
      "step": 410
    },
    {
      "epoch": 0.9051724137931034,
      "grad_norm": 4.00974178314209,
      "learning_rate": 1.8189655172413793e-05,
      "loss": 0.2096,
      "step": 420
    },
    {
      "epoch": 0.9267241379310345,
      "grad_norm": 3.6792290210723877,
      "learning_rate": 1.8146551724137932e-05,
      "loss": 0.2235,
      "step": 430
    },
    {
      "epoch": 0.9482758620689655,
      "grad_norm": 4.96739387512207,
      "learning_rate": 1.810344827586207e-05,
      "loss": 0.1924,
      "step": 440
    },
    {
      "epoch": 0.9698275862068966,
      "grad_norm": 5.876891136169434,
      "learning_rate": 1.806034482758621e-05,
      "loss": 0.1982,
      "step": 450
    },
    {
      "epoch": 0.9913793103448276,
      "grad_norm": 5.17507791519165,
      "learning_rate": 1.8017241379310346e-05,
      "loss": 0.2146,
      "step": 460
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9359296482412061,
      "eval_f1": 0.7258064516129032,
      "eval_loss": 0.1571483165025711,
      "eval_precision": 0.8737864077669902,
      "eval_recall": 0.6206896551724138,
      "eval_runtime": 164.012,
      "eval_samples_per_second": 77.677,
      "eval_steps_per_second": 2.433,
      "step": 464
    },
    {
      "epoch": 1.0129310344827587,
      "grad_norm": 3.514587879180908,
      "learning_rate": 1.7974137931034484e-05,
      "loss": 0.1552,
      "step": 470
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 6.4964799880981445,
      "learning_rate": 1.7931034482758623e-05,
      "loss": 0.172,
      "step": 480
    },
    {
      "epoch": 1.0560344827586208,
      "grad_norm": 18.793899536132812,
      "learning_rate": 1.788793103448276e-05,
      "loss": 0.181,
      "step": 490
    },
    {
      "epoch": 1.0775862068965518,
      "grad_norm": 3.309688091278076,
      "learning_rate": 1.7844827586206898e-05,
      "loss": 0.143,
      "step": 500
    },
    {
      "epoch": 1.0991379310344827,
      "grad_norm": 4.826387882232666,
      "learning_rate": 1.7801724137931037e-05,
      "loss": 0.1414,
      "step": 510
    },
    {
      "epoch": 1.1206896551724137,
      "grad_norm": 3.8748762607574463,
      "learning_rate": 1.7758620689655175e-05,
      "loss": 0.1218,
      "step": 520
    },
    {
      "epoch": 1.1422413793103448,
      "grad_norm": 3.8867428302764893,
      "learning_rate": 1.771551724137931e-05,
      "loss": 0.1505,
      "step": 530
    },
    {
      "epoch": 1.1637931034482758,
      "grad_norm": 5.254979610443115,
      "learning_rate": 1.767241379310345e-05,
      "loss": 0.1588,
      "step": 540
    },
    {
      "epoch": 1.1853448275862069,
      "grad_norm": 5.529809474945068,
      "learning_rate": 1.762931034482759e-05,
      "loss": 0.1343,
      "step": 550
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 5.60078763961792,
      "learning_rate": 1.7586206896551724e-05,
      "loss": 0.1671,
      "step": 560
    },
    {
      "epoch": 1.228448275862069,
      "grad_norm": 3.8275976181030273,
      "learning_rate": 1.7543103448275863e-05,
      "loss": 0.1817,
      "step": 570
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.469022274017334,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.1655,
      "step": 580
    },
    {
      "epoch": 1.271551724137931,
      "grad_norm": 7.15920352935791,
      "learning_rate": 1.7456896551724137e-05,
      "loss": 0.1453,
      "step": 590
    },
    {
      "epoch": 1.293103448275862,
      "grad_norm": 3.6788647174835205,
      "learning_rate": 1.7413793103448276e-05,
      "loss": 0.1379,
      "step": 600
    },
    {
      "epoch": 1.3146551724137931,
      "grad_norm": 4.212189674377441,
      "learning_rate": 1.7370689655172415e-05,
      "loss": 0.1245,
      "step": 610
    },
    {
      "epoch": 1.3362068965517242,
      "grad_norm": 3.7374117374420166,
      "learning_rate": 1.7327586206896554e-05,
      "loss": 0.1472,
      "step": 620
    },
    {
      "epoch": 1.3577586206896552,
      "grad_norm": 3.8859612941741943,
      "learning_rate": 1.728448275862069e-05,
      "loss": 0.1135,
      "step": 630
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 4.3170976638793945,
      "learning_rate": 1.7241379310344828e-05,
      "loss": 0.1169,
      "step": 640
    },
    {
      "epoch": 1.4008620689655173,
      "grad_norm": 3.9262990951538086,
      "learning_rate": 1.7198275862068967e-05,
      "loss": 0.1388,
      "step": 650
    },
    {
      "epoch": 1.4224137931034484,
      "grad_norm": 3.845048666000366,
      "learning_rate": 1.7155172413793103e-05,
      "loss": 0.1098,
      "step": 660
    },
    {
      "epoch": 1.4439655172413794,
      "grad_norm": 5.03438138961792,
      "learning_rate": 1.7112068965517245e-05,
      "loss": 0.0951,
      "step": 670
    },
    {
      "epoch": 1.4655172413793103,
      "grad_norm": 5.4413251876831055,
      "learning_rate": 1.706896551724138e-05,
      "loss": 0.1108,
      "step": 680
    },
    {
      "epoch": 1.4870689655172413,
      "grad_norm": 3.696474552154541,
      "learning_rate": 1.702586206896552e-05,
      "loss": 0.1081,
      "step": 690
    },
    {
      "epoch": 1.5086206896551724,
      "grad_norm": 5.7262420654296875,
      "learning_rate": 1.6982758620689658e-05,
      "loss": 0.1041,
      "step": 700
    },
    {
      "epoch": 1.5301724137931034,
      "grad_norm": 4.199761390686035,
      "learning_rate": 1.6939655172413794e-05,
      "loss": 0.1374,
      "step": 710
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 3.3378005027770996,
      "learning_rate": 1.6896551724137932e-05,
      "loss": 0.0946,
      "step": 720
    },
    {
      "epoch": 1.5732758620689655,
      "grad_norm": 5.167525768280029,
      "learning_rate": 1.685344827586207e-05,
      "loss": 0.0998,
      "step": 730
    },
    {
      "epoch": 1.5948275862068966,
      "grad_norm": 2.346400022506714,
      "learning_rate": 1.681034482758621e-05,
      "loss": 0.0944,
      "step": 740
    },
    {
      "epoch": 1.6163793103448276,
      "grad_norm": 15.844947814941406,
      "learning_rate": 1.6767241379310346e-05,
      "loss": 0.0773,
      "step": 750
    },
    {
      "epoch": 1.6379310344827587,
      "grad_norm": 3.295586109161377,
      "learning_rate": 1.6724137931034485e-05,
      "loss": 0.1152,
      "step": 760
    },
    {
      "epoch": 1.6594827586206895,
      "grad_norm": 5.607438564300537,
      "learning_rate": 1.6681034482758623e-05,
      "loss": 0.1262,
      "step": 770
    },
    {
      "epoch": 1.6810344827586206,
      "grad_norm": 3.2515041828155518,
      "learning_rate": 1.663793103448276e-05,
      "loss": 0.0993,
      "step": 780
    },
    {
      "epoch": 1.7025862068965516,
      "grad_norm": 3.9763004779815674,
      "learning_rate": 1.6594827586206898e-05,
      "loss": 0.0999,
      "step": 790
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 4.118649482727051,
      "learning_rate": 1.6551724137931037e-05,
      "loss": 0.1056,
      "step": 800
    },
    {
      "epoch": 1.7456896551724137,
      "grad_norm": 4.066799640655518,
      "learning_rate": 1.6508620689655176e-05,
      "loss": 0.1145,
      "step": 810
    },
    {
      "epoch": 1.7672413793103448,
      "grad_norm": 3.385085105895996,
      "learning_rate": 1.646551724137931e-05,
      "loss": 0.0842,
      "step": 820
    },
    {
      "epoch": 1.7887931034482758,
      "grad_norm": 3.181624174118042,
      "learning_rate": 1.642241379310345e-05,
      "loss": 0.0854,
      "step": 830
    },
    {
      "epoch": 1.8103448275862069,
      "grad_norm": 3.698427438735962,
      "learning_rate": 1.637931034482759e-05,
      "loss": 0.0978,
      "step": 840
    },
    {
      "epoch": 1.831896551724138,
      "grad_norm": 3.6118783950805664,
      "learning_rate": 1.6336206896551724e-05,
      "loss": 0.0694,
      "step": 850
    },
    {
      "epoch": 1.853448275862069,
      "grad_norm": 3.5563900470733643,
      "learning_rate": 1.6293103448275863e-05,
      "loss": 0.0912,
      "step": 860
    },
    {
      "epoch": 1.875,
      "grad_norm": 2.064704656600952,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0805,
      "step": 870
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 3.3351707458496094,
      "learning_rate": 1.6206896551724137e-05,
      "loss": 0.092,
      "step": 880
    },
    {
      "epoch": 1.918103448275862,
      "grad_norm": 3.9139952659606934,
      "learning_rate": 1.6163793103448276e-05,
      "loss": 0.0892,
      "step": 890
    },
    {
      "epoch": 1.9396551724137931,
      "grad_norm": 3.4315829277038574,
      "learning_rate": 1.6120689655172415e-05,
      "loss": 0.0658,
      "step": 900
    },
    {
      "epoch": 1.9612068965517242,
      "grad_norm": 4.158437728881836,
      "learning_rate": 1.6077586206896554e-05,
      "loss": 0.0932,
      "step": 910
    },
    {
      "epoch": 1.9827586206896552,
      "grad_norm": 3.0431532859802246,
      "learning_rate": 1.603448275862069e-05,
      "loss": 0.089,
      "step": 920
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9705559045226131,
      "eval_f1": 0.8966657481399836,
      "eval_loss": 0.07886648923158646,
      "eval_precision": 0.8613022763366861,
      "eval_recall": 0.9350574712643678,
      "eval_runtime": 167.6899,
      "eval_samples_per_second": 75.974,
      "eval_steps_per_second": 2.379,
      "step": 928
    },
    {
      "epoch": 2.0043103448275863,
      "grad_norm": 3.5105743408203125,
      "learning_rate": 1.599137931034483e-05,
      "loss": 0.0878,
      "step": 930
    },
    {
      "epoch": 2.0258620689655173,
      "grad_norm": 2.9270386695861816,
      "learning_rate": 1.5948275862068967e-05,
      "loss": 0.0736,
      "step": 940
    },
    {
      "epoch": 2.0474137931034484,
      "grad_norm": 2.1445212364196777,
      "learning_rate": 1.5905172413793103e-05,
      "loss": 0.0657,
      "step": 950
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 4.909611701965332,
      "learning_rate": 1.586206896551724e-05,
      "loss": 0.0768,
      "step": 960
    },
    {
      "epoch": 2.0905172413793105,
      "grad_norm": 4.580548286437988,
      "learning_rate": 1.581896551724138e-05,
      "loss": 0.0695,
      "step": 970
    },
    {
      "epoch": 2.1120689655172415,
      "grad_norm": 3.4002654552459717,
      "learning_rate": 1.577586206896552e-05,
      "loss": 0.0629,
      "step": 980
    },
    {
      "epoch": 2.1336206896551726,
      "grad_norm": 3.333847761154175,
      "learning_rate": 1.5732758620689655e-05,
      "loss": 0.0771,
      "step": 990
    },
    {
      "epoch": 2.1551724137931036,
      "grad_norm": 3.544174909591675,
      "learning_rate": 1.5689655172413794e-05,
      "loss": 0.0642,
      "step": 1000
    },
    {
      "epoch": 2.1767241379310347,
      "grad_norm": 4.739099025726318,
      "learning_rate": 1.5646551724137933e-05,
      "loss": 0.0768,
      "step": 1010
    },
    {
      "epoch": 2.1982758620689653,
      "grad_norm": 3.738828420639038,
      "learning_rate": 1.560344827586207e-05,
      "loss": 0.0665,
      "step": 1020
    },
    {
      "epoch": 2.2198275862068964,
      "grad_norm": 3.1426193714141846,
      "learning_rate": 1.556034482758621e-05,
      "loss": 0.0769,
      "step": 1030
    },
    {
      "epoch": 2.2413793103448274,
      "grad_norm": 3.3568296432495117,
      "learning_rate": 1.5517241379310346e-05,
      "loss": 0.0779,
      "step": 1040
    },
    {
      "epoch": 2.2629310344827585,
      "grad_norm": 3.619417428970337,
      "learning_rate": 1.5474137931034485e-05,
      "loss": 0.0516,
      "step": 1050
    },
    {
      "epoch": 2.2844827586206895,
      "grad_norm": 5.101478576660156,
      "learning_rate": 1.5431034482758624e-05,
      "loss": 0.0714,
      "step": 1060
    },
    {
      "epoch": 2.3060344827586206,
      "grad_norm": 2.756770372390747,
      "learning_rate": 1.538793103448276e-05,
      "loss": 0.0545,
      "step": 1070
    },
    {
      "epoch": 2.3275862068965516,
      "grad_norm": 1.050678014755249,
      "learning_rate": 1.5344827586206898e-05,
      "loss": 0.0521,
      "step": 1080
    },
    {
      "epoch": 2.3491379310344827,
      "grad_norm": 63.99267578125,
      "learning_rate": 1.5301724137931037e-05,
      "loss": 0.0978,
      "step": 1090
    },
    {
      "epoch": 2.3706896551724137,
      "grad_norm": 2.911770820617676,
      "learning_rate": 1.5258620689655174e-05,
      "loss": 0.0672,
      "step": 1100
    },
    {
      "epoch": 2.3922413793103448,
      "grad_norm": 2.2114667892456055,
      "learning_rate": 1.5215517241379311e-05,
      "loss": 0.0506,
      "step": 1110
    },
    {
      "epoch": 2.413793103448276,
      "grad_norm": 3.903748035430908,
      "learning_rate": 1.5172413793103448e-05,
      "loss": 0.0602,
      "step": 1120
    },
    {
      "epoch": 2.435344827586207,
      "grad_norm": 1.517892599105835,
      "learning_rate": 1.5129310344827587e-05,
      "loss": 0.0437,
      "step": 1130
    },
    {
      "epoch": 2.456896551724138,
      "grad_norm": 3.176299571990967,
      "learning_rate": 1.5086206896551724e-05,
      "loss": 0.0545,
      "step": 1140
    },
    {
      "epoch": 2.478448275862069,
      "grad_norm": 2.9675450325012207,
      "learning_rate": 1.5043103448275865e-05,
      "loss": 0.0608,
      "step": 1150
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.3115177154541016,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.0604,
      "step": 1160
    },
    {
      "epoch": 2.521551724137931,
      "grad_norm": 5.9098124504089355,
      "learning_rate": 1.4956896551724138e-05,
      "loss": 0.0494,
      "step": 1170
    },
    {
      "epoch": 2.543103448275862,
      "grad_norm": 3.6688036918640137,
      "learning_rate": 1.4913793103448278e-05,
      "loss": 0.0645,
      "step": 1180
    },
    {
      "epoch": 2.564655172413793,
      "grad_norm": 2.753126621246338,
      "learning_rate": 1.4870689655172415e-05,
      "loss": 0.0678,
      "step": 1190
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 4.548475742340088,
      "learning_rate": 1.4827586206896554e-05,
      "loss": 0.056,
      "step": 1200
    },
    {
      "epoch": 2.6077586206896552,
      "grad_norm": 3.2423346042633057,
      "learning_rate": 1.4784482758620691e-05,
      "loss": 0.0646,
      "step": 1210
    },
    {
      "epoch": 2.6293103448275863,
      "grad_norm": 3.1072998046875,
      "learning_rate": 1.4741379310344829e-05,
      "loss": 0.0556,
      "step": 1220
    },
    {
      "epoch": 2.6508620689655173,
      "grad_norm": 12.102705955505371,
      "learning_rate": 1.4698275862068967e-05,
      "loss": 0.0601,
      "step": 1230
    },
    {
      "epoch": 2.6724137931034484,
      "grad_norm": 10.750532150268555,
      "learning_rate": 1.4655172413793105e-05,
      "loss": 0.0661,
      "step": 1240
    },
    {
      "epoch": 2.6939655172413794,
      "grad_norm": 3.5477347373962402,
      "learning_rate": 1.4612068965517243e-05,
      "loss": 0.0534,
      "step": 1250
    },
    {
      "epoch": 2.7155172413793105,
      "grad_norm": 4.7889885902404785,
      "learning_rate": 1.456896551724138e-05,
      "loss": 0.0805,
      "step": 1260
    },
    {
      "epoch": 2.737068965517241,
      "grad_norm": 2.658804178237915,
      "learning_rate": 1.452586206896552e-05,
      "loss": 0.0506,
      "step": 1270
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 4.890280723571777,
      "learning_rate": 1.4482758620689657e-05,
      "loss": 0.0578,
      "step": 1280
    },
    {
      "epoch": 2.780172413793103,
      "grad_norm": 3.5288195610046387,
      "learning_rate": 1.4439655172413794e-05,
      "loss": 0.0504,
      "step": 1290
    },
    {
      "epoch": 2.8017241379310347,
      "grad_norm": 2.5248944759368896,
      "learning_rate": 1.4396551724137933e-05,
      "loss": 0.0676,
      "step": 1300
    },
    {
      "epoch": 2.8232758620689653,
      "grad_norm": 2.677278995513916,
      "learning_rate": 1.435344827586207e-05,
      "loss": 0.0485,
      "step": 1310
    },
    {
      "epoch": 2.844827586206897,
      "grad_norm": 4.0639848709106445,
      "learning_rate": 1.4310344827586209e-05,
      "loss": 0.0411,
      "step": 1320
    },
    {
      "epoch": 2.8663793103448274,
      "grad_norm": 3.2739768028259277,
      "learning_rate": 1.4267241379310346e-05,
      "loss": 0.0535,
      "step": 1330
    },
    {
      "epoch": 2.887931034482759,
      "grad_norm": 1.7350271940231323,
      "learning_rate": 1.4224137931034483e-05,
      "loss": 0.0511,
      "step": 1340
    },
    {
      "epoch": 2.9094827586206895,
      "grad_norm": 3.24626088142395,
      "learning_rate": 1.4181034482758622e-05,
      "loss": 0.0617,
      "step": 1350
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 2.1957783699035645,
      "learning_rate": 1.4137931034482759e-05,
      "loss": 0.049,
      "step": 1360
    },
    {
      "epoch": 2.9525862068965516,
      "grad_norm": 2.534510850906372,
      "learning_rate": 1.4094827586206898e-05,
      "loss": 0.039,
      "step": 1370
    },
    {
      "epoch": 2.9741379310344827,
      "grad_norm": 2.020798444747925,
      "learning_rate": 1.4051724137931035e-05,
      "loss": 0.054,
      "step": 1380
    },
    {
      "epoch": 2.9956896551724137,
      "grad_norm": 0.4499149024486542,
      "learning_rate": 1.4008620689655174e-05,
      "loss": 0.0411,
      "step": 1390
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9799780150753769,
      "eval_f1": 0.9278642149929278,
      "eval_loss": 0.05511792004108429,
      "eval_precision": 0.9136490250696379,
      "eval_recall": 0.9425287356321839,
      "eval_runtime": 187.6931,
      "eval_samples_per_second": 67.877,
      "eval_steps_per_second": 2.126,
      "step": 1392
    },
    {
      "epoch": 3.0172413793103448,
      "grad_norm": 3.5604023933410645,
      "learning_rate": 1.3965517241379311e-05,
      "loss": 0.0411,
      "step": 1400
    },
    {
      "epoch": 3.038793103448276,
      "grad_norm": 1.9279119968414307,
      "learning_rate": 1.3922413793103448e-05,
      "loss": 0.0337,
      "step": 1410
    },
    {
      "epoch": 3.060344827586207,
      "grad_norm": 0.7549704313278198,
      "learning_rate": 1.3879310344827587e-05,
      "loss": 0.0319,
      "step": 1420
    },
    {
      "epoch": 3.081896551724138,
      "grad_norm": 3.570627450942993,
      "learning_rate": 1.3836206896551724e-05,
      "loss": 0.0599,
      "step": 1430
    },
    {
      "epoch": 3.103448275862069,
      "grad_norm": 3.2543745040893555,
      "learning_rate": 1.3793103448275863e-05,
      "loss": 0.0411,
      "step": 1440
    },
    {
      "epoch": 3.125,
      "grad_norm": 1.818987250328064,
      "learning_rate": 1.375e-05,
      "loss": 0.038,
      "step": 1450
    },
    {
      "epoch": 3.146551724137931,
      "grad_norm": 2.2013158798217773,
      "learning_rate": 1.3706896551724138e-05,
      "loss": 0.041,
      "step": 1460
    },
    {
      "epoch": 3.168103448275862,
      "grad_norm": 2.348339319229126,
      "learning_rate": 1.3663793103448277e-05,
      "loss": 0.0307,
      "step": 1470
    },
    {
      "epoch": 3.189655172413793,
      "grad_norm": 2.4560208320617676,
      "learning_rate": 1.3620689655172414e-05,
      "loss": 0.0454,
      "step": 1480
    },
    {
      "epoch": 3.211206896551724,
      "grad_norm": 1.1391671895980835,
      "learning_rate": 1.3577586206896554e-05,
      "loss": 0.0504,
      "step": 1490
    },
    {
      "epoch": 3.2327586206896552,
      "grad_norm": 3.084869623184204,
      "learning_rate": 1.3534482758620691e-05,
      "loss": 0.0566,
      "step": 1500
    },
    {
      "epoch": 3.2543103448275863,
      "grad_norm": 2.3447425365448,
      "learning_rate": 1.3491379310344827e-05,
      "loss": 0.0502,
      "step": 1510
    },
    {
      "epoch": 3.2758620689655173,
      "grad_norm": 2.6239418983459473,
      "learning_rate": 1.3448275862068967e-05,
      "loss": 0.0581,
      "step": 1520
    },
    {
      "epoch": 3.2974137931034484,
      "grad_norm": 3.4798974990844727,
      "learning_rate": 1.3405172413793105e-05,
      "loss": 0.0437,
      "step": 1530
    },
    {
      "epoch": 3.3189655172413794,
      "grad_norm": 2.047884941101074,
      "learning_rate": 1.3362068965517244e-05,
      "loss": 0.0459,
      "step": 1540
    },
    {
      "epoch": 3.3405172413793105,
      "grad_norm": 0.6667267680168152,
      "learning_rate": 1.331896551724138e-05,
      "loss": 0.0367,
      "step": 1550
    },
    {
      "epoch": 3.3620689655172415,
      "grad_norm": 3.4264094829559326,
      "learning_rate": 1.327586206896552e-05,
      "loss": 0.0445,
      "step": 1560
    },
    {
      "epoch": 3.3836206896551726,
      "grad_norm": 2.071505308151245,
      "learning_rate": 1.3232758620689657e-05,
      "loss": 0.0377,
      "step": 1570
    },
    {
      "epoch": 3.405172413793103,
      "grad_norm": 3.8951778411865234,
      "learning_rate": 1.3189655172413794e-05,
      "loss": 0.04,
      "step": 1580
    },
    {
      "epoch": 3.4267241379310347,
      "grad_norm": 3.3136978149414062,
      "learning_rate": 1.3146551724137933e-05,
      "loss": 0.0414,
      "step": 1590
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 2.375314950942993,
      "learning_rate": 1.310344827586207e-05,
      "loss": 0.0647,
      "step": 1600
    },
    {
      "epoch": 3.469827586206897,
      "grad_norm": 2.6467528343200684,
      "learning_rate": 1.3060344827586209e-05,
      "loss": 0.0349,
      "step": 1610
    },
    {
      "epoch": 3.4913793103448274,
      "grad_norm": 2.573564052581787,
      "learning_rate": 1.3017241379310346e-05,
      "loss": 0.0594,
      "step": 1620
    },
    {
      "epoch": 3.512931034482759,
      "grad_norm": 2.7347614765167236,
      "learning_rate": 1.2974137931034483e-05,
      "loss": 0.0544,
      "step": 1630
    },
    {
      "epoch": 3.5344827586206895,
      "grad_norm": 2.9604074954986572,
      "learning_rate": 1.2931034482758622e-05,
      "loss": 0.0486,
      "step": 1640
    },
    {
      "epoch": 3.5560344827586206,
      "grad_norm": 1.7177098989486694,
      "learning_rate": 1.288793103448276e-05,
      "loss": 0.046,
      "step": 1650
    },
    {
      "epoch": 3.5775862068965516,
      "grad_norm": 0.8167074918746948,
      "learning_rate": 1.2844827586206898e-05,
      "loss": 0.0398,
      "step": 1660
    },
    {
      "epoch": 3.5991379310344827,
      "grad_norm": 3.6759591102600098,
      "learning_rate": 1.2801724137931035e-05,
      "loss": 0.0437,
      "step": 1670
    },
    {
      "epoch": 3.6206896551724137,
      "grad_norm": 2.3878984451293945,
      "learning_rate": 1.2758620689655174e-05,
      "loss": 0.0412,
      "step": 1680
    },
    {
      "epoch": 3.6422413793103448,
      "grad_norm": 5.294444561004639,
      "learning_rate": 1.2715517241379311e-05,
      "loss": 0.0442,
      "step": 1690
    },
    {
      "epoch": 3.663793103448276,
      "grad_norm": 2.0365307331085205,
      "learning_rate": 1.2672413793103449e-05,
      "loss": 0.0507,
      "step": 1700
    },
    {
      "epoch": 3.685344827586207,
      "grad_norm": 1.2381707429885864,
      "learning_rate": 1.2629310344827587e-05,
      "loss": 0.0513,
      "step": 1710
    },
    {
      "epoch": 3.706896551724138,
      "grad_norm": 3.418092727661133,
      "learning_rate": 1.2586206896551725e-05,
      "loss": 0.0418,
      "step": 1720
    },
    {
      "epoch": 3.728448275862069,
      "grad_norm": 3.121145725250244,
      "learning_rate": 1.2543103448275863e-05,
      "loss": 0.0358,
      "step": 1730
    },
    {
      "epoch": 3.75,
      "grad_norm": 3.226900577545166,
      "learning_rate": 1.25e-05,
      "loss": 0.0254,
      "step": 1740
    },
    {
      "epoch": 3.771551724137931,
      "grad_norm": 3.311173915863037,
      "learning_rate": 1.2456896551724138e-05,
      "loss": 0.0336,
      "step": 1750
    },
    {
      "epoch": 3.793103448275862,
      "grad_norm": 2.747840642929077,
      "learning_rate": 1.2413793103448277e-05,
      "loss": 0.0429,
      "step": 1760
    },
    {
      "epoch": 3.814655172413793,
      "grad_norm": 2.9874606132507324,
      "learning_rate": 1.2370689655172414e-05,
      "loss": 0.0422,
      "step": 1770
    },
    {
      "epoch": 3.836206896551724,
      "grad_norm": 1.6118295192718506,
      "learning_rate": 1.2327586206896553e-05,
      "loss": 0.0508,
      "step": 1780
    },
    {
      "epoch": 3.8577586206896552,
      "grad_norm": 0.6161671876907349,
      "learning_rate": 1.228448275862069e-05,
      "loss": 0.0307,
      "step": 1790
    },
    {
      "epoch": 3.8793103448275863,
      "grad_norm": 3.497880220413208,
      "learning_rate": 1.2241379310344827e-05,
      "loss": 0.0534,
      "step": 1800
    },
    {
      "epoch": 3.9008620689655173,
      "grad_norm": 2.752901315689087,
      "learning_rate": 1.2198275862068966e-05,
      "loss": 0.0316,
      "step": 1810
    },
    {
      "epoch": 3.9224137931034484,
      "grad_norm": 2.746805429458618,
      "learning_rate": 1.2155172413793103e-05,
      "loss": 0.0506,
      "step": 1820
    },
    {
      "epoch": 3.9439655172413794,
      "grad_norm": 1.1242650747299194,
      "learning_rate": 1.2112068965517244e-05,
      "loss": 0.0373,
      "step": 1830
    },
    {
      "epoch": 3.9655172413793105,
      "grad_norm": 1.490382432937622,
      "learning_rate": 1.206896551724138e-05,
      "loss": 0.0395,
      "step": 1840
    },
    {
      "epoch": 3.987068965517241,
      "grad_norm": 2.352771520614624,
      "learning_rate": 1.202586206896552e-05,
      "loss": 0.0448,
      "step": 1850
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9816268844221105,
      "eval_f1": 0.9322916666666669,
      "eval_loss": 0.05261583626270294,
      "eval_precision": 0.9388111888111889,
      "eval_recall": 0.9258620689655173,
      "eval_runtime": 187.3939,
      "eval_samples_per_second": 67.985,
      "eval_steps_per_second": 2.129,
      "step": 1856
    },
    {
      "epoch": 4.008620689655173,
      "grad_norm": 3.6084601879119873,
      "learning_rate": 1.1982758620689657e-05,
      "loss": 0.0351,
      "step": 1860
    },
    {
      "epoch": 4.030172413793103,
      "grad_norm": 0.4915590286254883,
      "learning_rate": 1.1939655172413794e-05,
      "loss": 0.016,
      "step": 1870
    },
    {
      "epoch": 4.051724137931035,
      "grad_norm": 2.491093873977661,
      "learning_rate": 1.1896551724137933e-05,
      "loss": 0.0254,
      "step": 1880
    },
    {
      "epoch": 4.073275862068965,
      "grad_norm": 2.1102731227874756,
      "learning_rate": 1.185344827586207e-05,
      "loss": 0.0258,
      "step": 1890
    },
    {
      "epoch": 4.094827586206897,
      "grad_norm": 2.4102442264556885,
      "learning_rate": 1.1810344827586209e-05,
      "loss": 0.0337,
      "step": 1900
    },
    {
      "epoch": 4.116379310344827,
      "grad_norm": 0.8398198485374451,
      "learning_rate": 1.1767241379310346e-05,
      "loss": 0.02,
      "step": 1910
    },
    {
      "epoch": 4.137931034482759,
      "grad_norm": 2.433189630508423,
      "learning_rate": 1.1724137931034483e-05,
      "loss": 0.0337,
      "step": 1920
    },
    {
      "epoch": 4.1594827586206895,
      "grad_norm": 2.4474587440490723,
      "learning_rate": 1.1681034482758622e-05,
      "loss": 0.0349,
      "step": 1930
    },
    {
      "epoch": 4.181034482758621,
      "grad_norm": 2.6748268604278564,
      "learning_rate": 1.163793103448276e-05,
      "loss": 0.0287,
      "step": 1940
    },
    {
      "epoch": 4.202586206896552,
      "grad_norm": 1.558143973350525,
      "learning_rate": 1.1594827586206898e-05,
      "loss": 0.0426,
      "step": 1950
    },
    {
      "epoch": 4.224137931034483,
      "grad_norm": 1.2359474897384644,
      "learning_rate": 1.1551724137931035e-05,
      "loss": 0.0354,
      "step": 1960
    },
    {
      "epoch": 4.245689655172414,
      "grad_norm": 4.1441144943237305,
      "learning_rate": 1.1508620689655174e-05,
      "loss": 0.0305,
      "step": 1970
    },
    {
      "epoch": 4.267241379310345,
      "grad_norm": 0.13825465738773346,
      "learning_rate": 1.1465517241379311e-05,
      "loss": 0.0261,
      "step": 1980
    },
    {
      "epoch": 4.288793103448276,
      "grad_norm": 0.930543065071106,
      "learning_rate": 1.1422413793103449e-05,
      "loss": 0.0285,
      "step": 1990
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 3.114635944366455,
      "learning_rate": 1.1379310344827587e-05,
      "loss": 0.034,
      "step": 2000
    },
    {
      "epoch": 4.331896551724138,
      "grad_norm": 1.8803975582122803,
      "learning_rate": 1.1336206896551725e-05,
      "loss": 0.0518,
      "step": 2010
    },
    {
      "epoch": 4.353448275862069,
      "grad_norm": 2.152343988418579,
      "learning_rate": 1.1293103448275864e-05,
      "loss": 0.0224,
      "step": 2020
    },
    {
      "epoch": 4.375,
      "grad_norm": 1.6945881843566895,
      "learning_rate": 1.125e-05,
      "loss": 0.0373,
      "step": 2030
    },
    {
      "epoch": 4.396551724137931,
      "grad_norm": 2.1309666633605957,
      "learning_rate": 1.1206896551724138e-05,
      "loss": 0.0452,
      "step": 2040
    },
    {
      "epoch": 4.418103448275862,
      "grad_norm": 3.110076904296875,
      "learning_rate": 1.1163793103448277e-05,
      "loss": 0.0465,
      "step": 2050
    },
    {
      "epoch": 4.439655172413793,
      "grad_norm": 1.409849762916565,
      "learning_rate": 1.1120689655172414e-05,
      "loss": 0.0353,
      "step": 2060
    },
    {
      "epoch": 4.461206896551724,
      "grad_norm": 3.267057180404663,
      "learning_rate": 1.1077586206896553e-05,
      "loss": 0.0329,
      "step": 2070
    },
    {
      "epoch": 4.482758620689655,
      "grad_norm": 2.3185057640075684,
      "learning_rate": 1.103448275862069e-05,
      "loss": 0.0355,
      "step": 2080
    },
    {
      "epoch": 4.504310344827586,
      "grad_norm": 3.745549201965332,
      "learning_rate": 1.0991379310344827e-05,
      "loss": 0.0234,
      "step": 2090
    },
    {
      "epoch": 4.525862068965517,
      "grad_norm": 3.4477009773254395,
      "learning_rate": 1.0948275862068966e-05,
      "loss": 0.042,
      "step": 2100
    },
    {
      "epoch": 4.547413793103448,
      "grad_norm": 2.0182044506073,
      "learning_rate": 1.0905172413793103e-05,
      "loss": 0.0319,
      "step": 2110
    },
    {
      "epoch": 4.568965517241379,
      "grad_norm": 12.627917289733887,
      "learning_rate": 1.0862068965517242e-05,
      "loss": 0.0494,
      "step": 2120
    },
    {
      "epoch": 4.5905172413793105,
      "grad_norm": 1.9316965341567993,
      "learning_rate": 1.081896551724138e-05,
      "loss": 0.0373,
      "step": 2130
    },
    {
      "epoch": 4.612068965517241,
      "grad_norm": 0.9617478251457214,
      "learning_rate": 1.077586206896552e-05,
      "loss": 0.0274,
      "step": 2140
    },
    {
      "epoch": 4.633620689655173,
      "grad_norm": 4.416582107543945,
      "learning_rate": 1.0732758620689655e-05,
      "loss": 0.028,
      "step": 2150
    },
    {
      "epoch": 4.655172413793103,
      "grad_norm": 2.246854782104492,
      "learning_rate": 1.0689655172413792e-05,
      "loss": 0.0416,
      "step": 2160
    },
    {
      "epoch": 4.676724137931035,
      "grad_norm": 6.804887294769287,
      "learning_rate": 1.0646551724137933e-05,
      "loss": 0.0325,
      "step": 2170
    },
    {
      "epoch": 4.698275862068965,
      "grad_norm": 1.3499815464019775,
      "learning_rate": 1.060344827586207e-05,
      "loss": 0.0261,
      "step": 2180
    },
    {
      "epoch": 4.719827586206897,
      "grad_norm": 4.529250621795654,
      "learning_rate": 1.0560344827586209e-05,
      "loss": 0.0348,
      "step": 2190
    },
    {
      "epoch": 4.741379310344827,
      "grad_norm": 2.785308837890625,
      "learning_rate": 1.0517241379310346e-05,
      "loss": 0.0237,
      "step": 2200
    },
    {
      "epoch": 4.762931034482759,
      "grad_norm": 3.108433246612549,
      "learning_rate": 1.0474137931034483e-05,
      "loss": 0.0426,
      "step": 2210
    },
    {
      "epoch": 4.7844827586206895,
      "grad_norm": 2.441436529159546,
      "learning_rate": 1.0431034482758622e-05,
      "loss": 0.0241,
      "step": 2220
    },
    {
      "epoch": 4.806034482758621,
      "grad_norm": 1.1614443063735962,
      "learning_rate": 1.038793103448276e-05,
      "loss": 0.0339,
      "step": 2230
    },
    {
      "epoch": 4.827586206896552,
      "grad_norm": 2.6070058345794678,
      "learning_rate": 1.0344827586206898e-05,
      "loss": 0.038,
      "step": 2240
    },
    {
      "epoch": 4.849137931034483,
      "grad_norm": 1.4773619174957275,
      "learning_rate": 1.0301724137931036e-05,
      "loss": 0.0258,
      "step": 2250
    },
    {
      "epoch": 4.870689655172414,
      "grad_norm": 3.3063013553619385,
      "learning_rate": 1.0258620689655174e-05,
      "loss": 0.0381,
      "step": 2260
    },
    {
      "epoch": 4.892241379310345,
      "grad_norm": 3.023223400115967,
      "learning_rate": 1.0215517241379312e-05,
      "loss": 0.0444,
      "step": 2270
    },
    {
      "epoch": 4.913793103448276,
      "grad_norm": 1.855804204940796,
      "learning_rate": 1.0172413793103449e-05,
      "loss": 0.0326,
      "step": 2280
    },
    {
      "epoch": 4.935344827586206,
      "grad_norm": 2.0995795726776123,
      "learning_rate": 1.0129310344827588e-05,
      "loss": 0.0323,
      "step": 2290
    },
    {
      "epoch": 4.956896551724138,
      "grad_norm": 1.248413324356079,
      "learning_rate": 1.0086206896551725e-05,
      "loss": 0.0304,
      "step": 2300
    },
    {
      "epoch": 4.978448275862069,
      "grad_norm": 3.243049383163452,
      "learning_rate": 1.0043103448275864e-05,
      "loss": 0.0257,
      "step": 2310
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.46519148349761963,
      "learning_rate": 1e-05,
      "loss": 0.037,
      "step": 2320
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9836683417085427,
      "eval_f1": 0.9403327596098681,
      "eval_loss": 0.047493595629930496,
      "eval_precision": 0.938717067583047,
      "eval_recall": 0.9419540229885057,
      "eval_runtime": 186.2685,
      "eval_samples_per_second": 68.396,
      "eval_steps_per_second": 2.142,
      "step": 2320
    },
    {
      "epoch": 5.021551724137931,
      "grad_norm": 3.5933375358581543,
      "learning_rate": 9.95689655172414e-06,
      "loss": 0.027,
      "step": 2330
    },
    {
      "epoch": 5.043103448275862,
      "grad_norm": 1.440618634223938,
      "learning_rate": 9.913793103448277e-06,
      "loss": 0.0239,
      "step": 2340
    },
    {
      "epoch": 5.064655172413793,
      "grad_norm": 0.34253188967704773,
      "learning_rate": 9.870689655172414e-06,
      "loss": 0.0115,
      "step": 2350
    },
    {
      "epoch": 5.086206896551724,
      "grad_norm": 12.105886459350586,
      "learning_rate": 9.827586206896553e-06,
      "loss": 0.0261,
      "step": 2360
    },
    {
      "epoch": 5.107758620689655,
      "grad_norm": 0.746895432472229,
      "learning_rate": 9.78448275862069e-06,
      "loss": 0.0209,
      "step": 2370
    },
    {
      "epoch": 5.129310344827586,
      "grad_norm": 1.8411943912506104,
      "learning_rate": 9.741379310344829e-06,
      "loss": 0.0218,
      "step": 2380
    },
    {
      "epoch": 5.150862068965517,
      "grad_norm": 2.541330337524414,
      "learning_rate": 9.698275862068966e-06,
      "loss": 0.0302,
      "step": 2390
    },
    {
      "epoch": 5.172413793103448,
      "grad_norm": 0.39333197474479675,
      "learning_rate": 9.655172413793105e-06,
      "loss": 0.0155,
      "step": 2400
    },
    {
      "epoch": 5.193965517241379,
      "grad_norm": 4.175014972686768,
      "learning_rate": 9.612068965517242e-06,
      "loss": 0.0259,
      "step": 2410
    },
    {
      "epoch": 5.2155172413793105,
      "grad_norm": 2.1385273933410645,
      "learning_rate": 9.56896551724138e-06,
      "loss": 0.0148,
      "step": 2420
    },
    {
      "epoch": 5.237068965517241,
      "grad_norm": 0.47481751441955566,
      "learning_rate": 9.525862068965518e-06,
      "loss": 0.0233,
      "step": 2430
    },
    {
      "epoch": 5.258620689655173,
      "grad_norm": 0.43637847900390625,
      "learning_rate": 9.482758620689655e-06,
      "loss": 0.0223,
      "step": 2440
    },
    {
      "epoch": 5.280172413793103,
      "grad_norm": 3.5750181674957275,
      "learning_rate": 9.439655172413794e-06,
      "loss": 0.0221,
      "step": 2450
    },
    {
      "epoch": 5.301724137931035,
      "grad_norm": 0.6436356902122498,
      "learning_rate": 9.396551724137931e-06,
      "loss": 0.0287,
      "step": 2460
    },
    {
      "epoch": 5.323275862068965,
      "grad_norm": 0.7693791389465332,
      "learning_rate": 9.353448275862069e-06,
      "loss": 0.0203,
      "step": 2470
    },
    {
      "epoch": 5.344827586206897,
      "grad_norm": 4.497655391693115,
      "learning_rate": 9.310344827586207e-06,
      "loss": 0.0275,
      "step": 2480
    },
    {
      "epoch": 5.366379310344827,
      "grad_norm": 0.35921594500541687,
      "learning_rate": 9.267241379310346e-06,
      "loss": 0.0291,
      "step": 2490
    },
    {
      "epoch": 5.387931034482759,
      "grad_norm": 1.803369402885437,
      "learning_rate": 9.224137931034484e-06,
      "loss": 0.0238,
      "step": 2500
    },
    {
      "epoch": 5.4094827586206895,
      "grad_norm": 0.8428569436073303,
      "learning_rate": 9.181034482758622e-06,
      "loss": 0.0173,
      "step": 2510
    },
    {
      "epoch": 5.431034482758621,
      "grad_norm": 3.7300121784210205,
      "learning_rate": 9.13793103448276e-06,
      "loss": 0.0461,
      "step": 2520
    },
    {
      "epoch": 5.452586206896552,
      "grad_norm": 2.1277453899383545,
      "learning_rate": 9.094827586206897e-06,
      "loss": 0.0307,
      "step": 2530
    },
    {
      "epoch": 5.474137931034483,
      "grad_norm": 6.341113090515137,
      "learning_rate": 9.051724137931036e-06,
      "loss": 0.0294,
      "step": 2540
    },
    {
      "epoch": 5.495689655172414,
      "grad_norm": 3.6374576091766357,
      "learning_rate": 9.008620689655173e-06,
      "loss": 0.0301,
      "step": 2550
    },
    {
      "epoch": 5.517241379310345,
      "grad_norm": 1.570549488067627,
      "learning_rate": 8.965517241379312e-06,
      "loss": 0.0283,
      "step": 2560
    },
    {
      "epoch": 5.538793103448276,
      "grad_norm": 0.1510823369026184,
      "learning_rate": 8.922413793103449e-06,
      "loss": 0.0264,
      "step": 2570
    },
    {
      "epoch": 5.560344827586206,
      "grad_norm": 4.412818431854248,
      "learning_rate": 8.879310344827588e-06,
      "loss": 0.0269,
      "step": 2580
    },
    {
      "epoch": 5.581896551724138,
      "grad_norm": 1.9703744649887085,
      "learning_rate": 8.836206896551725e-06,
      "loss": 0.0281,
      "step": 2590
    },
    {
      "epoch": 5.603448275862069,
      "grad_norm": 1.762082576751709,
      "learning_rate": 8.793103448275862e-06,
      "loss": 0.0257,
      "step": 2600
    },
    {
      "epoch": 5.625,
      "grad_norm": 0.912419855594635,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.016,
      "step": 2610
    },
    {
      "epoch": 5.646551724137931,
      "grad_norm": 1.1027361154556274,
      "learning_rate": 8.706896551724138e-06,
      "loss": 0.0236,
      "step": 2620
    },
    {
      "epoch": 5.668103448275862,
      "grad_norm": 0.4614408612251282,
      "learning_rate": 8.663793103448277e-06,
      "loss": 0.0165,
      "step": 2630
    },
    {
      "epoch": 5.689655172413794,
      "grad_norm": 2.5742931365966797,
      "learning_rate": 8.620689655172414e-06,
      "loss": 0.0338,
      "step": 2640
    },
    {
      "epoch": 5.711206896551724,
      "grad_norm": 3.360673427581787,
      "learning_rate": 8.577586206896551e-06,
      "loss": 0.0267,
      "step": 2650
    },
    {
      "epoch": 5.732758620689655,
      "grad_norm": 0.9865211844444275,
      "learning_rate": 8.53448275862069e-06,
      "loss": 0.0358,
      "step": 2660
    },
    {
      "epoch": 5.754310344827586,
      "grad_norm": 0.7461268305778503,
      "learning_rate": 8.491379310344829e-06,
      "loss": 0.0205,
      "step": 2670
    },
    {
      "epoch": 5.775862068965517,
      "grad_norm": 12.9265718460083,
      "learning_rate": 8.448275862068966e-06,
      "loss": 0.0315,
      "step": 2680
    },
    {
      "epoch": 5.797413793103448,
      "grad_norm": 0.8667619824409485,
      "learning_rate": 8.405172413793105e-06,
      "loss": 0.0289,
      "step": 2690
    },
    {
      "epoch": 5.818965517241379,
      "grad_norm": 3.317379951477051,
      "learning_rate": 8.362068965517242e-06,
      "loss": 0.0217,
      "step": 2700
    },
    {
      "epoch": 5.8405172413793105,
      "grad_norm": 1.8810398578643799,
      "learning_rate": 8.31896551724138e-06,
      "loss": 0.0213,
      "step": 2710
    },
    {
      "epoch": 5.862068965517241,
      "grad_norm": 5.658819198608398,
      "learning_rate": 8.275862068965518e-06,
      "loss": 0.0196,
      "step": 2720
    },
    {
      "epoch": 5.883620689655173,
      "grad_norm": 2.3989431858062744,
      "learning_rate": 8.232758620689656e-06,
      "loss": 0.0198,
      "step": 2730
    },
    {
      "epoch": 5.905172413793103,
      "grad_norm": 2.1304986476898193,
      "learning_rate": 8.189655172413794e-06,
      "loss": 0.0237,
      "step": 2740
    },
    {
      "epoch": 5.926724137931035,
      "grad_norm": 1.0412722826004028,
      "learning_rate": 8.146551724137932e-06,
      "loss": 0.0228,
      "step": 2750
    },
    {
      "epoch": 5.948275862068965,
      "grad_norm": 1.7486495971679688,
      "learning_rate": 8.103448275862069e-06,
      "loss": 0.022,
      "step": 2760
    },
    {
      "epoch": 5.969827586206897,
      "grad_norm": 1.4645706415176392,
      "learning_rate": 8.060344827586208e-06,
      "loss": 0.0338,
      "step": 2770
    },
    {
      "epoch": 5.991379310344827,
      "grad_norm": 1.5401504039764404,
      "learning_rate": 8.017241379310345e-06,
      "loss": 0.0395,
      "step": 2780
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9833542713567839,
      "eval_f1": 0.9394631639063392,
      "eval_loss": 0.04892001301050186,
      "eval_precision": 0.9335981838819524,
      "eval_recall": 0.9454022988505747,
      "eval_runtime": 188.6501,
      "eval_samples_per_second": 67.532,
      "eval_steps_per_second": 2.115,
      "step": 2784
    },
    {
      "epoch": 6.012931034482759,
      "grad_norm": 0.9626176357269287,
      "learning_rate": 7.974137931034484e-06,
      "loss": 0.0256,
      "step": 2790
    },
    {
      "epoch": 6.0344827586206895,
      "grad_norm": 0.5540505051612854,
      "learning_rate": 7.93103448275862e-06,
      "loss": 0.0147,
      "step": 2800
    },
    {
      "epoch": 6.056034482758621,
      "grad_norm": 1.2109562158584595,
      "learning_rate": 7.88793103448276e-06,
      "loss": 0.0214,
      "step": 2810
    },
    {
      "epoch": 6.077586206896552,
      "grad_norm": 0.06620626151561737,
      "learning_rate": 7.844827586206897e-06,
      "loss": 0.0098,
      "step": 2820
    },
    {
      "epoch": 6.099137931034483,
      "grad_norm": 0.8534511923789978,
      "learning_rate": 7.801724137931036e-06,
      "loss": 0.0235,
      "step": 2830
    },
    {
      "epoch": 6.120689655172414,
      "grad_norm": 1.507228970527649,
      "learning_rate": 7.758620689655173e-06,
      "loss": 0.0313,
      "step": 2840
    },
    {
      "epoch": 6.142241379310345,
      "grad_norm": 0.46537548303604126,
      "learning_rate": 7.715517241379312e-06,
      "loss": 0.0279,
      "step": 2850
    },
    {
      "epoch": 6.163793103448276,
      "grad_norm": 1.656235694885254,
      "learning_rate": 7.672413793103449e-06,
      "loss": 0.019,
      "step": 2860
    },
    {
      "epoch": 6.185344827586207,
      "grad_norm": 2.4212214946746826,
      "learning_rate": 7.629310344827587e-06,
      "loss": 0.017,
      "step": 2870
    },
    {
      "epoch": 6.206896551724138,
      "grad_norm": 5.727665901184082,
      "learning_rate": 7.586206896551724e-06,
      "loss": 0.019,
      "step": 2880
    },
    {
      "epoch": 6.228448275862069,
      "grad_norm": 2.052987575531006,
      "learning_rate": 7.543103448275862e-06,
      "loss": 0.0172,
      "step": 2890
    },
    {
      "epoch": 6.25,
      "grad_norm": 1.5704816579818726,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0206,
      "step": 2900
    },
    {
      "epoch": 6.271551724137931,
      "grad_norm": 2.2415080070495605,
      "learning_rate": 7.456896551724139e-06,
      "loss": 0.0088,
      "step": 2910
    },
    {
      "epoch": 6.293103448275862,
      "grad_norm": 2.5197646617889404,
      "learning_rate": 7.413793103448277e-06,
      "loss": 0.0331,
      "step": 2920
    },
    {
      "epoch": 6.314655172413793,
      "grad_norm": 1.8083209991455078,
      "learning_rate": 7.370689655172414e-06,
      "loss": 0.0221,
      "step": 2930
    },
    {
      "epoch": 6.336206896551724,
      "grad_norm": 0.969619870185852,
      "learning_rate": 7.327586206896552e-06,
      "loss": 0.0208,
      "step": 2940
    },
    {
      "epoch": 6.357758620689655,
      "grad_norm": 2.87617564201355,
      "learning_rate": 7.28448275862069e-06,
      "loss": 0.0164,
      "step": 2950
    },
    {
      "epoch": 6.379310344827586,
      "grad_norm": 1.0153316259384155,
      "learning_rate": 7.241379310344828e-06,
      "loss": 0.0201,
      "step": 2960
    },
    {
      "epoch": 6.400862068965517,
      "grad_norm": 0.1559891253709793,
      "learning_rate": 7.198275862068966e-06,
      "loss": 0.0174,
      "step": 2970
    },
    {
      "epoch": 6.422413793103448,
      "grad_norm": 11.299744606018066,
      "learning_rate": 7.155172413793104e-06,
      "loss": 0.0253,
      "step": 2980
    },
    {
      "epoch": 6.443965517241379,
      "grad_norm": 0.6253938674926758,
      "learning_rate": 7.1120689655172415e-06,
      "loss": 0.0145,
      "step": 2990
    },
    {
      "epoch": 6.4655172413793105,
      "grad_norm": 1.84230637550354,
      "learning_rate": 7.0689655172413796e-06,
      "loss": 0.0245,
      "step": 3000
    },
    {
      "epoch": 6.487068965517241,
      "grad_norm": 0.17697246372699738,
      "learning_rate": 7.025862068965518e-06,
      "loss": 0.0188,
      "step": 3010
    },
    {
      "epoch": 6.508620689655173,
      "grad_norm": 0.7529864311218262,
      "learning_rate": 6.982758620689656e-06,
      "loss": 0.0318,
      "step": 3020
    },
    {
      "epoch": 6.530172413793103,
      "grad_norm": 1.0482299327850342,
      "learning_rate": 6.939655172413794e-06,
      "loss": 0.0195,
      "step": 3030
    },
    {
      "epoch": 6.551724137931035,
      "grad_norm": 2.5218636989593506,
      "learning_rate": 6.896551724137932e-06,
      "loss": 0.0261,
      "step": 3040
    },
    {
      "epoch": 6.573275862068965,
      "grad_norm": 7.511842250823975,
      "learning_rate": 6.853448275862069e-06,
      "loss": 0.0314,
      "step": 3050
    },
    {
      "epoch": 6.594827586206897,
      "grad_norm": 1.832723617553711,
      "learning_rate": 6.810344827586207e-06,
      "loss": 0.0302,
      "step": 3060
    },
    {
      "epoch": 6.616379310344827,
      "grad_norm": 1.1213124990463257,
      "learning_rate": 6.767241379310346e-06,
      "loss": 0.0258,
      "step": 3070
    },
    {
      "epoch": 6.637931034482759,
      "grad_norm": 1.3605647087097168,
      "learning_rate": 6.724137931034484e-06,
      "loss": 0.0175,
      "step": 3080
    },
    {
      "epoch": 6.6594827586206895,
      "grad_norm": 1.052027702331543,
      "learning_rate": 6.681034482758622e-06,
      "loss": 0.0214,
      "step": 3090
    },
    {
      "epoch": 6.681034482758621,
      "grad_norm": 1.2089413404464722,
      "learning_rate": 6.63793103448276e-06,
      "loss": 0.0204,
      "step": 3100
    },
    {
      "epoch": 6.702586206896552,
      "grad_norm": 0.9673755168914795,
      "learning_rate": 6.594827586206897e-06,
      "loss": 0.0214,
      "step": 3110
    },
    {
      "epoch": 6.724137931034483,
      "grad_norm": 0.6625115275382996,
      "learning_rate": 6.551724137931035e-06,
      "loss": 0.0177,
      "step": 3120
    },
    {
      "epoch": 6.745689655172414,
      "grad_norm": 1.6144824028015137,
      "learning_rate": 6.508620689655173e-06,
      "loss": 0.0264,
      "step": 3130
    },
    {
      "epoch": 6.767241379310345,
      "grad_norm": 0.9451417326927185,
      "learning_rate": 6.465517241379311e-06,
      "loss": 0.0203,
      "step": 3140
    },
    {
      "epoch": 6.788793103448276,
      "grad_norm": 1.6594997644424438,
      "learning_rate": 6.422413793103449e-06,
      "loss": 0.0276,
      "step": 3150
    },
    {
      "epoch": 6.810344827586206,
      "grad_norm": 0.5865522623062134,
      "learning_rate": 6.379310344827587e-06,
      "loss": 0.0178,
      "step": 3160
    },
    {
      "epoch": 6.831896551724138,
      "grad_norm": 1.179133415222168,
      "learning_rate": 6.336206896551724e-06,
      "loss": 0.0183,
      "step": 3170
    },
    {
      "epoch": 6.853448275862069,
      "grad_norm": 1.5682510137557983,
      "learning_rate": 6.293103448275862e-06,
      "loss": 0.0133,
      "step": 3180
    },
    {
      "epoch": 6.875,
      "grad_norm": 0.7731850147247314,
      "learning_rate": 6.25e-06,
      "loss": 0.0227,
      "step": 3190
    },
    {
      "epoch": 6.896551724137931,
      "grad_norm": 0.7877598404884338,
      "learning_rate": 6.206896551724138e-06,
      "loss": 0.0172,
      "step": 3200
    },
    {
      "epoch": 6.918103448275862,
      "grad_norm": 1.5854806900024414,
      "learning_rate": 6.163793103448276e-06,
      "loss": 0.0312,
      "step": 3210
    },
    {
      "epoch": 6.939655172413794,
      "grad_norm": 1.3261128664016724,
      "learning_rate": 6.1206896551724135e-06,
      "loss": 0.0233,
      "step": 3220
    },
    {
      "epoch": 6.961206896551724,
      "grad_norm": 2.460426092147827,
      "learning_rate": 6.0775862068965515e-06,
      "loss": 0.0157,
      "step": 3230
    },
    {
      "epoch": 6.982758620689655,
      "grad_norm": 0.4315794110298157,
      "learning_rate": 6.03448275862069e-06,
      "loss": 0.0325,
      "step": 3240
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9828046482412061,
      "eval_f1": 0.9375890567113138,
      "eval_loss": 0.04990853741765022,
      "eval_precision": 0.929903900508762,
      "eval_recall": 0.9454022988505747,
      "eval_runtime": 199.9239,
      "eval_samples_per_second": 63.724,
      "eval_steps_per_second": 1.996,
      "step": 3248
    },
    {
      "epoch": 7.004310344827586,
      "grad_norm": 1.0555819272994995,
      "learning_rate": 5.9913793103448284e-06,
      "loss": 0.0153,
      "step": 3250
    },
    {
      "epoch": 7.025862068965517,
      "grad_norm": 2.3908939361572266,
      "learning_rate": 5.9482758620689665e-06,
      "loss": 0.0173,
      "step": 3260
    },
    {
      "epoch": 7.047413793103448,
      "grad_norm": 0.3036678433418274,
      "learning_rate": 5.9051724137931045e-06,
      "loss": 0.0129,
      "step": 3270
    },
    {
      "epoch": 7.068965517241379,
      "grad_norm": 0.9115192890167236,
      "learning_rate": 5.862068965517242e-06,
      "loss": 0.017,
      "step": 3280
    },
    {
      "epoch": 7.0905172413793105,
      "grad_norm": 0.9069733619689941,
      "learning_rate": 5.81896551724138e-06,
      "loss": 0.0211,
      "step": 3290
    },
    {
      "epoch": 7.112068965517241,
      "grad_norm": 4.679051399230957,
      "learning_rate": 5.775862068965518e-06,
      "loss": 0.021,
      "step": 3300
    },
    {
      "epoch": 7.133620689655173,
      "grad_norm": 0.7362701892852783,
      "learning_rate": 5.732758620689656e-06,
      "loss": 0.0137,
      "step": 3310
    },
    {
      "epoch": 7.155172413793103,
      "grad_norm": 1.7514092922210693,
      "learning_rate": 5.689655172413794e-06,
      "loss": 0.0161,
      "step": 3320
    },
    {
      "epoch": 7.176724137931035,
      "grad_norm": 1.425854206085205,
      "learning_rate": 5.646551724137932e-06,
      "loss": 0.0245,
      "step": 3330
    },
    {
      "epoch": 7.198275862068965,
      "grad_norm": 1.862707257270813,
      "learning_rate": 5.603448275862069e-06,
      "loss": 0.0119,
      "step": 3340
    },
    {
      "epoch": 7.219827586206897,
      "grad_norm": 1.00973379611969,
      "learning_rate": 5.560344827586207e-06,
      "loss": 0.0279,
      "step": 3350
    },
    {
      "epoch": 7.241379310344827,
      "grad_norm": 0.8074701428413391,
      "learning_rate": 5.517241379310345e-06,
      "loss": 0.0218,
      "step": 3360
    },
    {
      "epoch": 7.262931034482759,
      "grad_norm": 1.4474265575408936,
      "learning_rate": 5.474137931034483e-06,
      "loss": 0.0107,
      "step": 3370
    },
    {
      "epoch": 7.2844827586206895,
      "grad_norm": 0.1185133159160614,
      "learning_rate": 5.431034482758621e-06,
      "loss": 0.0114,
      "step": 3380
    },
    {
      "epoch": 7.306034482758621,
      "grad_norm": 0.6999907493591309,
      "learning_rate": 5.38793103448276e-06,
      "loss": 0.0141,
      "step": 3390
    },
    {
      "epoch": 7.327586206896552,
      "grad_norm": 2.756993055343628,
      "learning_rate": 5.344827586206896e-06,
      "loss": 0.0255,
      "step": 3400
    },
    {
      "epoch": 7.349137931034483,
      "grad_norm": 0.9063241481781006,
      "learning_rate": 5.301724137931035e-06,
      "loss": 0.016,
      "step": 3410
    },
    {
      "epoch": 7.370689655172414,
      "grad_norm": 2.227069854736328,
      "learning_rate": 5.258620689655173e-06,
      "loss": 0.0204,
      "step": 3420
    },
    {
      "epoch": 7.392241379310345,
      "grad_norm": 1.6784803867340088,
      "learning_rate": 5.215517241379311e-06,
      "loss": 0.0191,
      "step": 3430
    },
    {
      "epoch": 7.413793103448276,
      "grad_norm": 0.3822944164276123,
      "learning_rate": 5.172413793103449e-06,
      "loss": 0.0113,
      "step": 3440
    },
    {
      "epoch": 7.435344827586207,
      "grad_norm": 3.499077558517456,
      "learning_rate": 5.129310344827587e-06,
      "loss": 0.0148,
      "step": 3450
    },
    {
      "epoch": 7.456896551724138,
      "grad_norm": 2.937068223953247,
      "learning_rate": 5.086206896551724e-06,
      "loss": 0.0181,
      "step": 3460
    },
    {
      "epoch": 7.478448275862069,
      "grad_norm": 1.6945364475250244,
      "learning_rate": 5.043103448275862e-06,
      "loss": 0.0128,
      "step": 3470
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.040658362209796906,
      "learning_rate": 5e-06,
      "loss": 0.0176,
      "step": 3480
    },
    {
      "epoch": 7.521551724137931,
      "grad_norm": 1.9118878841400146,
      "learning_rate": 4.9568965517241384e-06,
      "loss": 0.0184,
      "step": 3490
    },
    {
      "epoch": 7.543103448275862,
      "grad_norm": 2.323486804962158,
      "learning_rate": 4.9137931034482765e-06,
      "loss": 0.0113,
      "step": 3500
    },
    {
      "epoch": 7.564655172413794,
      "grad_norm": 0.1268223226070404,
      "learning_rate": 4.8706896551724145e-06,
      "loss": 0.0184,
      "step": 3510
    },
    {
      "epoch": 7.586206896551724,
      "grad_norm": 1.7930606603622437,
      "learning_rate": 4.8275862068965525e-06,
      "loss": 0.022,
      "step": 3520
    },
    {
      "epoch": 7.607758620689655,
      "grad_norm": 1.571582317352295,
      "learning_rate": 4.78448275862069e-06,
      "loss": 0.0133,
      "step": 3530
    },
    {
      "epoch": 7.629310344827586,
      "grad_norm": 1.4191100597381592,
      "learning_rate": 4.741379310344828e-06,
      "loss": 0.0106,
      "step": 3540
    },
    {
      "epoch": 7.650862068965517,
      "grad_norm": 2.815643548965454,
      "learning_rate": 4.698275862068966e-06,
      "loss": 0.0166,
      "step": 3550
    },
    {
      "epoch": 7.672413793103448,
      "grad_norm": 4.036159992218018,
      "learning_rate": 4.655172413793104e-06,
      "loss": 0.0326,
      "step": 3560
    },
    {
      "epoch": 7.693965517241379,
      "grad_norm": 2.658205270767212,
      "learning_rate": 4.612068965517242e-06,
      "loss": 0.0182,
      "step": 3570
    },
    {
      "epoch": 7.7155172413793105,
      "grad_norm": 3.7445168495178223,
      "learning_rate": 4.56896551724138e-06,
      "loss": 0.0157,
      "step": 3580
    },
    {
      "epoch": 7.737068965517241,
      "grad_norm": 2.3810486793518066,
      "learning_rate": 4.525862068965518e-06,
      "loss": 0.0126,
      "step": 3590
    },
    {
      "epoch": 7.758620689655173,
      "grad_norm": 0.8724552989006042,
      "learning_rate": 4.482758620689656e-06,
      "loss": 0.017,
      "step": 3600
    },
    {
      "epoch": 7.780172413793103,
      "grad_norm": 2.7633519172668457,
      "learning_rate": 4.439655172413794e-06,
      "loss": 0.024,
      "step": 3610
    },
    {
      "epoch": 7.801724137931035,
      "grad_norm": 2.8950138092041016,
      "learning_rate": 4.396551724137931e-06,
      "loss": 0.0195,
      "step": 3620
    },
    {
      "epoch": 7.823275862068965,
      "grad_norm": 0.8904532790184021,
      "learning_rate": 4.353448275862069e-06,
      "loss": 0.0145,
      "step": 3630
    },
    {
      "epoch": 7.844827586206897,
      "grad_norm": 3.192753314971924,
      "learning_rate": 4.310344827586207e-06,
      "loss": 0.0217,
      "step": 3640
    },
    {
      "epoch": 7.866379310344827,
      "grad_norm": 0.17908558249473572,
      "learning_rate": 4.267241379310345e-06,
      "loss": 0.0129,
      "step": 3650
    },
    {
      "epoch": 7.887931034482759,
      "grad_norm": 1.1411596536636353,
      "learning_rate": 4.224137931034483e-06,
      "loss": 0.0148,
      "step": 3660
    },
    {
      "epoch": 7.9094827586206895,
      "grad_norm": 0.9304266571998596,
      "learning_rate": 4.181034482758621e-06,
      "loss": 0.0224,
      "step": 3670
    },
    {
      "epoch": 7.931034482758621,
      "grad_norm": 1.508751630783081,
      "learning_rate": 4.137931034482759e-06,
      "loss": 0.0189,
      "step": 3680
    },
    {
      "epoch": 7.952586206896552,
      "grad_norm": 1.366671085357666,
      "learning_rate": 4.094827586206897e-06,
      "loss": 0.0148,
      "step": 3690
    },
    {
      "epoch": 7.974137931034483,
      "grad_norm": 1.0101521015167236,
      "learning_rate": 4.051724137931034e-06,
      "loss": 0.02,
      "step": 3700
    },
    {
      "epoch": 7.995689655172414,
      "grad_norm": 0.8643706440925598,
      "learning_rate": 4.008620689655172e-06,
      "loss": 0.0166,
      "step": 3710
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9842179648241206,
      "eval_f1": 0.9425221618530168,
      "eval_loss": 0.04912933334708214,
      "eval_precision": 0.9379624359704041,
      "eval_recall": 0.9471264367816092,
      "eval_runtime": 185.1284,
      "eval_samples_per_second": 68.817,
      "eval_steps_per_second": 2.155,
      "step": 3712
    }
  ],
  "logging_steps": 10,
  "max_steps": 4640,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1932153059763968e+17,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
