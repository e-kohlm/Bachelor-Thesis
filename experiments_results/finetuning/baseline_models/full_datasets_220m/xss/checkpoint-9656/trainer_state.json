{
  "best_metric": 0.962059620596206,
  "best_model_checkpoint": "../saved_models/xss/checkpoint-9656",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 9656,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008285004142502071,
      "grad_norm": 40.9356689453125,
      "learning_rate": 1.9998895332781002e-05,
      "loss": 0.918,
      "step": 1
    },
    {
      "epoch": 0.008285004142502071,
      "grad_norm": 24.057191848754883,
      "learning_rate": 1.998895332781e-05,
      "loss": 0.465,
      "step": 10
    },
    {
      "epoch": 0.016570008285004142,
      "grad_norm": 13.28881549835205,
      "learning_rate": 1.9977906655619995e-05,
      "loss": 0.3866,
      "step": 20
    },
    {
      "epoch": 0.024855012427506214,
      "grad_norm": 17.14455223083496,
      "learning_rate": 1.9966859983429993e-05,
      "loss": 0.3936,
      "step": 30
    },
    {
      "epoch": 0.033140016570008285,
      "grad_norm": 14.248673439025879,
      "learning_rate": 1.995581331123999e-05,
      "loss": 0.2828,
      "step": 40
    },
    {
      "epoch": 0.041425020712510356,
      "grad_norm": 12.09715747833252,
      "learning_rate": 1.994476663904999e-05,
      "loss": 0.2995,
      "step": 50
    },
    {
      "epoch": 0.04971002485501243,
      "grad_norm": 17.1845645904541,
      "learning_rate": 1.9933719966859985e-05,
      "loss": 0.2772,
      "step": 60
    },
    {
      "epoch": 0.0579950289975145,
      "grad_norm": 15.394867897033691,
      "learning_rate": 1.9922673294669983e-05,
      "loss": 0.3166,
      "step": 70
    },
    {
      "epoch": 0.06628003314001657,
      "grad_norm": 20.66329574584961,
      "learning_rate": 1.991162662247998e-05,
      "loss": 0.2629,
      "step": 80
    },
    {
      "epoch": 0.07456503728251865,
      "grad_norm": 11.359898567199707,
      "learning_rate": 1.9900579950289977e-05,
      "loss": 0.2462,
      "step": 90
    },
    {
      "epoch": 0.08285004142502071,
      "grad_norm": 15.956480979919434,
      "learning_rate": 1.9889533278099975e-05,
      "loss": 0.3309,
      "step": 100
    },
    {
      "epoch": 0.09113504556752279,
      "grad_norm": 13.477375030517578,
      "learning_rate": 1.987848660590997e-05,
      "loss": 0.2381,
      "step": 110
    },
    {
      "epoch": 0.09942004971002485,
      "grad_norm": 23.129371643066406,
      "learning_rate": 1.986743993371997e-05,
      "loss": 0.3492,
      "step": 120
    },
    {
      "epoch": 0.10770505385252693,
      "grad_norm": 9.029038429260254,
      "learning_rate": 1.9856393261529963e-05,
      "loss": 0.278,
      "step": 130
    },
    {
      "epoch": 0.115990057995029,
      "grad_norm": 20.31867027282715,
      "learning_rate": 1.984534658933996e-05,
      "loss": 0.2763,
      "step": 140
    },
    {
      "epoch": 0.12427506213753108,
      "grad_norm": 9.777968406677246,
      "learning_rate": 1.983429991714996e-05,
      "loss": 0.2841,
      "step": 150
    },
    {
      "epoch": 0.13256006628003314,
      "grad_norm": 8.45468521118164,
      "learning_rate": 1.982325324495996e-05,
      "loss": 0.2664,
      "step": 160
    },
    {
      "epoch": 0.14084507042253522,
      "grad_norm": 10.465753555297852,
      "learning_rate": 1.9812206572769953e-05,
      "loss": 0.2341,
      "step": 170
    },
    {
      "epoch": 0.1491300745650373,
      "grad_norm": 9.755812644958496,
      "learning_rate": 1.980115990057995e-05,
      "loss": 0.2873,
      "step": 180
    },
    {
      "epoch": 0.15741507870753935,
      "grad_norm": 9.762984275817871,
      "learning_rate": 1.979011322838995e-05,
      "loss": 0.2172,
      "step": 190
    },
    {
      "epoch": 0.16570008285004142,
      "grad_norm": 7.728188514709473,
      "learning_rate": 1.9779066556199945e-05,
      "loss": 0.1867,
      "step": 200
    },
    {
      "epoch": 0.1739850869925435,
      "grad_norm": 7.6427812576293945,
      "learning_rate": 1.9768019884009943e-05,
      "loss": 0.2384,
      "step": 210
    },
    {
      "epoch": 0.18227009113504558,
      "grad_norm": 0.6899476051330566,
      "learning_rate": 1.975697321181994e-05,
      "loss": 0.1412,
      "step": 220
    },
    {
      "epoch": 0.19055509527754763,
      "grad_norm": 9.487068176269531,
      "learning_rate": 1.9745926539629937e-05,
      "loss": 0.2717,
      "step": 230
    },
    {
      "epoch": 0.1988400994200497,
      "grad_norm": 7.761163234710693,
      "learning_rate": 1.9734879867439935e-05,
      "loss": 0.233,
      "step": 240
    },
    {
      "epoch": 0.2071251035625518,
      "grad_norm": 3.5154011249542236,
      "learning_rate": 1.9723833195249933e-05,
      "loss": 0.2336,
      "step": 250
    },
    {
      "epoch": 0.21541010770505387,
      "grad_norm": 3.756645441055298,
      "learning_rate": 1.9712786523059932e-05,
      "loss": 0.2314,
      "step": 260
    },
    {
      "epoch": 0.22369511184755592,
      "grad_norm": 2.7574303150177,
      "learning_rate": 1.9701739850869927e-05,
      "loss": 0.1548,
      "step": 270
    },
    {
      "epoch": 0.231980115990058,
      "grad_norm": 3.593751907348633,
      "learning_rate": 1.9690693178679925e-05,
      "loss": 0.1847,
      "step": 280
    },
    {
      "epoch": 0.24026512013256007,
      "grad_norm": 6.521420478820801,
      "learning_rate": 1.9679646506489923e-05,
      "loss": 0.184,
      "step": 290
    },
    {
      "epoch": 0.24855012427506215,
      "grad_norm": 6.338006019592285,
      "learning_rate": 1.966859983429992e-05,
      "loss": 0.179,
      "step": 300
    },
    {
      "epoch": 0.25683512841756423,
      "grad_norm": 4.443591594696045,
      "learning_rate": 1.9657553162109917e-05,
      "loss": 0.1172,
      "step": 310
    },
    {
      "epoch": 0.2651201325600663,
      "grad_norm": 10.361894607543945,
      "learning_rate": 1.9646506489919915e-05,
      "loss": 0.2878,
      "step": 320
    },
    {
      "epoch": 0.27340513670256833,
      "grad_norm": 6.275602340698242,
      "learning_rate": 1.963545981772991e-05,
      "loss": 0.2053,
      "step": 330
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 3.7338078022003174,
      "learning_rate": 1.962441314553991e-05,
      "loss": 0.1444,
      "step": 340
    },
    {
      "epoch": 0.2899751449875725,
      "grad_norm": 4.656810283660889,
      "learning_rate": 1.9613366473349903e-05,
      "loss": 0.1776,
      "step": 350
    },
    {
      "epoch": 0.2982601491300746,
      "grad_norm": 5.390077114105225,
      "learning_rate": 1.96023198011599e-05,
      "loss": 0.2235,
      "step": 360
    },
    {
      "epoch": 0.30654515327257664,
      "grad_norm": 3.4178519248962402,
      "learning_rate": 1.95912731289699e-05,
      "loss": 0.1282,
      "step": 370
    },
    {
      "epoch": 0.3148301574150787,
      "grad_norm": 10.336859703063965,
      "learning_rate": 1.9580226456779895e-05,
      "loss": 0.1847,
      "step": 380
    },
    {
      "epoch": 0.3231151615575808,
      "grad_norm": 2.9235665798187256,
      "learning_rate": 1.9569179784589893e-05,
      "loss": 0.1644,
      "step": 390
    },
    {
      "epoch": 0.33140016570008285,
      "grad_norm": 4.0619120597839355,
      "learning_rate": 1.9558133112399892e-05,
      "loss": 0.2118,
      "step": 400
    },
    {
      "epoch": 0.3396851698425849,
      "grad_norm": 10.11812686920166,
      "learning_rate": 1.9547086440209887e-05,
      "loss": 0.1408,
      "step": 410
    },
    {
      "epoch": 0.347970173985087,
      "grad_norm": 1.1726428270339966,
      "learning_rate": 1.9536039768019885e-05,
      "loss": 0.1298,
      "step": 420
    },
    {
      "epoch": 0.35625517812758906,
      "grad_norm": 3.8978867530822754,
      "learning_rate": 1.9524993095829883e-05,
      "loss": 0.1493,
      "step": 430
    },
    {
      "epoch": 0.36454018227009116,
      "grad_norm": 3.888669490814209,
      "learning_rate": 1.9513946423639882e-05,
      "loss": 0.1785,
      "step": 440
    },
    {
      "epoch": 0.3728251864125932,
      "grad_norm": 3.4045393466949463,
      "learning_rate": 1.9502899751449877e-05,
      "loss": 0.1363,
      "step": 450
    },
    {
      "epoch": 0.38111019055509526,
      "grad_norm": 3.6998045444488525,
      "learning_rate": 1.9491853079259875e-05,
      "loss": 0.1361,
      "step": 460
    },
    {
      "epoch": 0.38939519469759737,
      "grad_norm": 2.582923412322998,
      "learning_rate": 1.9480806407069873e-05,
      "loss": 0.1057,
      "step": 470
    },
    {
      "epoch": 0.3976801988400994,
      "grad_norm": 5.3834052085876465,
      "learning_rate": 1.946975973487987e-05,
      "loss": 0.1708,
      "step": 480
    },
    {
      "epoch": 0.40596520298260147,
      "grad_norm": 4.553287982940674,
      "learning_rate": 1.9458713062689867e-05,
      "loss": 0.1504,
      "step": 490
    },
    {
      "epoch": 0.4142502071251036,
      "grad_norm": 8.360977172851562,
      "learning_rate": 1.9447666390499865e-05,
      "loss": 0.1391,
      "step": 500
    },
    {
      "epoch": 0.4225352112676056,
      "grad_norm": 4.848458766937256,
      "learning_rate": 1.943661971830986e-05,
      "loss": 0.0956,
      "step": 510
    },
    {
      "epoch": 0.43082021541010773,
      "grad_norm": 7.863483905792236,
      "learning_rate": 1.942557304611986e-05,
      "loss": 0.1626,
      "step": 520
    },
    {
      "epoch": 0.4391052195526098,
      "grad_norm": 5.903984546661377,
      "learning_rate": 1.9414526373929857e-05,
      "loss": 0.1189,
      "step": 530
    },
    {
      "epoch": 0.44739022369511183,
      "grad_norm": 6.025343418121338,
      "learning_rate": 1.9403479701739855e-05,
      "loss": 0.0974,
      "step": 540
    },
    {
      "epoch": 0.45567522783761394,
      "grad_norm": 2.0616402626037598,
      "learning_rate": 1.939243302954985e-05,
      "loss": 0.1078,
      "step": 550
    },
    {
      "epoch": 0.463960231980116,
      "grad_norm": 2.549851894378662,
      "learning_rate": 1.9381386357359845e-05,
      "loss": 0.0846,
      "step": 560
    },
    {
      "epoch": 0.47224523612261804,
      "grad_norm": 6.229568958282471,
      "learning_rate": 1.9370339685169843e-05,
      "loss": 0.086,
      "step": 570
    },
    {
      "epoch": 0.48053024026512015,
      "grad_norm": 3.5469584465026855,
      "learning_rate": 1.9359293012979842e-05,
      "loss": 0.0688,
      "step": 580
    },
    {
      "epoch": 0.4888152444076222,
      "grad_norm": 10.047462463378906,
      "learning_rate": 1.9348246340789837e-05,
      "loss": 0.1316,
      "step": 590
    },
    {
      "epoch": 0.4971002485501243,
      "grad_norm": 7.982063293457031,
      "learning_rate": 1.9337199668599835e-05,
      "loss": 0.1156,
      "step": 600
    },
    {
      "epoch": 0.5053852526926264,
      "grad_norm": 8.990020751953125,
      "learning_rate": 1.9326152996409833e-05,
      "loss": 0.1356,
      "step": 610
    },
    {
      "epoch": 0.5136702568351285,
      "grad_norm": 8.60301399230957,
      "learning_rate": 1.931510632421983e-05,
      "loss": 0.1001,
      "step": 620
    },
    {
      "epoch": 0.5219552609776305,
      "grad_norm": 5.4846415519714355,
      "learning_rate": 1.9304059652029827e-05,
      "loss": 0.1031,
      "step": 630
    },
    {
      "epoch": 0.5302402651201326,
      "grad_norm": 2.2533905506134033,
      "learning_rate": 1.9293012979839825e-05,
      "loss": 0.0745,
      "step": 640
    },
    {
      "epoch": 0.5385252692626347,
      "grad_norm": 7.206902027130127,
      "learning_rate": 1.9281966307649823e-05,
      "loss": 0.0757,
      "step": 650
    },
    {
      "epoch": 0.5468102734051367,
      "grad_norm": 0.4273029863834381,
      "learning_rate": 1.927091963545982e-05,
      "loss": 0.1945,
      "step": 660
    },
    {
      "epoch": 0.5550952775476388,
      "grad_norm": 6.321726322174072,
      "learning_rate": 1.9259872963269817e-05,
      "loss": 0.1222,
      "step": 670
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 0.7329262495040894,
      "learning_rate": 1.9248826291079815e-05,
      "loss": 0.0688,
      "step": 680
    },
    {
      "epoch": 0.5716652858326429,
      "grad_norm": 6.827511787414551,
      "learning_rate": 1.923777961888981e-05,
      "loss": 0.1044,
      "step": 690
    },
    {
      "epoch": 0.579950289975145,
      "grad_norm": 3.8344688415527344,
      "learning_rate": 1.922673294669981e-05,
      "loss": 0.1015,
      "step": 700
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.5237940549850464,
      "learning_rate": 1.9215686274509807e-05,
      "loss": 0.1247,
      "step": 710
    },
    {
      "epoch": 0.5965202982601492,
      "grad_norm": 4.12179708480835,
      "learning_rate": 1.9204639602319802e-05,
      "loss": 0.1225,
      "step": 720
    },
    {
      "epoch": 0.6048053024026512,
      "grad_norm": 9.204798698425293,
      "learning_rate": 1.91935929301298e-05,
      "loss": 0.1253,
      "step": 730
    },
    {
      "epoch": 0.6130903065451533,
      "grad_norm": 3.0473475456237793,
      "learning_rate": 1.91825462579398e-05,
      "loss": 0.0675,
      "step": 740
    },
    {
      "epoch": 0.6213753106876554,
      "grad_norm": 3.39955997467041,
      "learning_rate": 1.9171499585749797e-05,
      "loss": 0.1147,
      "step": 750
    },
    {
      "epoch": 0.6296603148301574,
      "grad_norm": 13.111238479614258,
      "learning_rate": 1.9160452913559792e-05,
      "loss": 0.1208,
      "step": 760
    },
    {
      "epoch": 0.6379453189726595,
      "grad_norm": 7.034548282623291,
      "learning_rate": 1.9149406241369787e-05,
      "loss": 0.1516,
      "step": 770
    },
    {
      "epoch": 0.6462303231151616,
      "grad_norm": 9.184460639953613,
      "learning_rate": 1.9138359569179785e-05,
      "loss": 0.1432,
      "step": 780
    },
    {
      "epoch": 0.6545153272576636,
      "grad_norm": 3.042652130126953,
      "learning_rate": 1.9127312896989783e-05,
      "loss": 0.1363,
      "step": 790
    },
    {
      "epoch": 0.6628003314001657,
      "grad_norm": 6.276401042938232,
      "learning_rate": 1.911626622479978e-05,
      "loss": 0.153,
      "step": 800
    },
    {
      "epoch": 0.6710853355426678,
      "grad_norm": 42.191341400146484,
      "learning_rate": 1.9105219552609777e-05,
      "loss": 0.0725,
      "step": 810
    },
    {
      "epoch": 0.6793703396851698,
      "grad_norm": 3.227045774459839,
      "learning_rate": 1.9094172880419775e-05,
      "loss": 0.0353,
      "step": 820
    },
    {
      "epoch": 0.6876553438276719,
      "grad_norm": 6.4007182121276855,
      "learning_rate": 1.9083126208229773e-05,
      "loss": 0.0832,
      "step": 830
    },
    {
      "epoch": 0.695940347970174,
      "grad_norm": 3.6633782386779785,
      "learning_rate": 1.907207953603977e-05,
      "loss": 0.076,
      "step": 840
    },
    {
      "epoch": 0.704225352112676,
      "grad_norm": 0.09870956838130951,
      "learning_rate": 1.9061032863849767e-05,
      "loss": 0.0691,
      "step": 850
    },
    {
      "epoch": 0.7125103562551781,
      "grad_norm": 5.5800981521606445,
      "learning_rate": 1.9049986191659765e-05,
      "loss": 0.0905,
      "step": 860
    },
    {
      "epoch": 0.7207953603976802,
      "grad_norm": 0.6052784323692322,
      "learning_rate": 1.903893951946976e-05,
      "loss": 0.074,
      "step": 870
    },
    {
      "epoch": 0.7290803645401823,
      "grad_norm": 0.033475082367658615,
      "learning_rate": 1.902789284727976e-05,
      "loss": 0.1115,
      "step": 880
    },
    {
      "epoch": 0.7373653686826843,
      "grad_norm": 5.269953727722168,
      "learning_rate": 1.9016846175089757e-05,
      "loss": 0.0768,
      "step": 890
    },
    {
      "epoch": 0.7456503728251864,
      "grad_norm": 5.939884185791016,
      "learning_rate": 1.9005799502899752e-05,
      "loss": 0.085,
      "step": 900
    },
    {
      "epoch": 0.7539353769676885,
      "grad_norm": 8.553988456726074,
      "learning_rate": 1.899475283070975e-05,
      "loss": 0.1385,
      "step": 910
    },
    {
      "epoch": 0.7622203811101905,
      "grad_norm": 3.402977705001831,
      "learning_rate": 1.898370615851975e-05,
      "loss": 0.0211,
      "step": 920
    },
    {
      "epoch": 0.7705053852526926,
      "grad_norm": 1.1860980987548828,
      "learning_rate": 1.8972659486329747e-05,
      "loss": 0.0986,
      "step": 930
    },
    {
      "epoch": 0.7787903893951947,
      "grad_norm": 2.922214984893799,
      "learning_rate": 1.8961612814139742e-05,
      "loss": 0.0777,
      "step": 940
    },
    {
      "epoch": 0.7870753935376967,
      "grad_norm": 0.28031399846076965,
      "learning_rate": 1.895056614194974e-05,
      "loss": 0.0644,
      "step": 950
    },
    {
      "epoch": 0.7953603976801988,
      "grad_norm": 1.8242300748825073,
      "learning_rate": 1.893951946975974e-05,
      "loss": 0.042,
      "step": 960
    },
    {
      "epoch": 0.8036454018227009,
      "grad_norm": 5.39662504196167,
      "learning_rate": 1.8928472797569733e-05,
      "loss": 0.0622,
      "step": 970
    },
    {
      "epoch": 0.8119304059652029,
      "grad_norm": 8.09764575958252,
      "learning_rate": 1.8917426125379732e-05,
      "loss": 0.1406,
      "step": 980
    },
    {
      "epoch": 0.820215410107705,
      "grad_norm": 4.057199478149414,
      "learning_rate": 1.8906379453189727e-05,
      "loss": 0.079,
      "step": 990
    },
    {
      "epoch": 0.8285004142502072,
      "grad_norm": 6.119179725646973,
      "learning_rate": 1.8895332780999725e-05,
      "loss": 0.0821,
      "step": 1000
    },
    {
      "epoch": 0.8367854183927091,
      "grad_norm": 7.671385288238525,
      "learning_rate": 1.8884286108809723e-05,
      "loss": 0.0769,
      "step": 1010
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 0.6573753356933594,
      "learning_rate": 1.887323943661972e-05,
      "loss": 0.0446,
      "step": 1020
    },
    {
      "epoch": 0.8533554266777134,
      "grad_norm": 6.3917317390441895,
      "learning_rate": 1.8862192764429717e-05,
      "loss": 0.1456,
      "step": 1030
    },
    {
      "epoch": 0.8616404308202155,
      "grad_norm": 1.0168542861938477,
      "learning_rate": 1.8851146092239715e-05,
      "loss": 0.0468,
      "step": 1040
    },
    {
      "epoch": 0.8699254349627175,
      "grad_norm": 6.8088698387146,
      "learning_rate": 1.884009942004971e-05,
      "loss": 0.0757,
      "step": 1050
    },
    {
      "epoch": 0.8782104391052196,
      "grad_norm": 0.18016384541988373,
      "learning_rate": 1.882905274785971e-05,
      "loss": 0.0594,
      "step": 1060
    },
    {
      "epoch": 0.8864954432477217,
      "grad_norm": 3.3725271224975586,
      "learning_rate": 1.8818006075669707e-05,
      "loss": 0.0626,
      "step": 1070
    },
    {
      "epoch": 0.8947804473902237,
      "grad_norm": 5.6734795570373535,
      "learning_rate": 1.8806959403479702e-05,
      "loss": 0.1359,
      "step": 1080
    },
    {
      "epoch": 0.9030654515327258,
      "grad_norm": 5.3450822830200195,
      "learning_rate": 1.87959127312897e-05,
      "loss": 0.041,
      "step": 1090
    },
    {
      "epoch": 0.9113504556752279,
      "grad_norm": 0.8300871253013611,
      "learning_rate": 1.87848660590997e-05,
      "loss": 0.0307,
      "step": 1100
    },
    {
      "epoch": 0.9196354598177299,
      "grad_norm": 0.17656168341636658,
      "learning_rate": 1.8773819386909697e-05,
      "loss": 0.0372,
      "step": 1110
    },
    {
      "epoch": 0.927920463960232,
      "grad_norm": 0.08763860911130905,
      "learning_rate": 1.8762772714719692e-05,
      "loss": 0.0605,
      "step": 1120
    },
    {
      "epoch": 0.9362054681027341,
      "grad_norm": 0.1919660121202469,
      "learning_rate": 1.875172604252969e-05,
      "loss": 0.0365,
      "step": 1130
    },
    {
      "epoch": 0.9444904722452361,
      "grad_norm": 24.178428649902344,
      "learning_rate": 1.874067937033969e-05,
      "loss": 0.0323,
      "step": 1140
    },
    {
      "epoch": 0.9527754763877382,
      "grad_norm": 2.2877190113067627,
      "learning_rate": 1.8729632698149683e-05,
      "loss": 0.0432,
      "step": 1150
    },
    {
      "epoch": 0.9610604805302403,
      "grad_norm": 5.2003021240234375,
      "learning_rate": 1.8718586025959682e-05,
      "loss": 0.1001,
      "step": 1160
    },
    {
      "epoch": 0.9693454846727423,
      "grad_norm": 6.149951457977295,
      "learning_rate": 1.870753935376968e-05,
      "loss": 0.0554,
      "step": 1170
    },
    {
      "epoch": 0.9776304888152444,
      "grad_norm": 8.066476821899414,
      "learning_rate": 1.8696492681579675e-05,
      "loss": 0.0801,
      "step": 1180
    },
    {
      "epoch": 0.9859154929577465,
      "grad_norm": 0.10924118757247925,
      "learning_rate": 1.8685446009389673e-05,
      "loss": 0.0495,
      "step": 1190
    },
    {
      "epoch": 0.9942004971002486,
      "grad_norm": 6.0811967849731445,
      "learning_rate": 1.867439933719967e-05,
      "loss": 0.0744,
      "step": 1200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9841634429400387,
      "eval_f1": 0.9130723291307233,
      "eval_loss": 0.05028315261006355,
      "eval_precision": 0.9148936170212766,
      "eval_recall": 0.9112582781456954,
      "eval_runtime": 1391.5341,
      "eval_samples_per_second": 5.948,
      "eval_steps_per_second": 0.744,
      "step": 1207
    },
    {
      "epoch": 1.0024855012427507,
      "grad_norm": 0.2721763551235199,
      "learning_rate": 1.8663352665009667e-05,
      "loss": 0.0259,
      "step": 1210
    },
    {
      "epoch": 1.0107705053852527,
      "grad_norm": 0.088661327958107,
      "learning_rate": 1.8652305992819665e-05,
      "loss": 0.04,
      "step": 1220
    },
    {
      "epoch": 1.0190555095277547,
      "grad_norm": 4.64642858505249,
      "learning_rate": 1.864125932062966e-05,
      "loss": 0.0529,
      "step": 1230
    },
    {
      "epoch": 1.027340513670257,
      "grad_norm": 4.089938640594482,
      "learning_rate": 1.863021264843966e-05,
      "loss": 0.0383,
      "step": 1240
    },
    {
      "epoch": 1.035625517812759,
      "grad_norm": 0.501867949962616,
      "learning_rate": 1.8619165976249657e-05,
      "loss": 0.0308,
      "step": 1250
    },
    {
      "epoch": 1.043910521955261,
      "grad_norm": 6.702101230621338,
      "learning_rate": 1.8608119304059652e-05,
      "loss": 0.0778,
      "step": 1260
    },
    {
      "epoch": 1.0521955260977631,
      "grad_norm": 0.1767108291387558,
      "learning_rate": 1.859707263186965e-05,
      "loss": 0.0087,
      "step": 1270
    },
    {
      "epoch": 1.0604805302402651,
      "grad_norm": 5.668511390686035,
      "learning_rate": 1.858602595967965e-05,
      "loss": 0.0471,
      "step": 1280
    },
    {
      "epoch": 1.0687655343827671,
      "grad_norm": 0.35134026408195496,
      "learning_rate": 1.8574979287489643e-05,
      "loss": 0.0163,
      "step": 1290
    },
    {
      "epoch": 1.0770505385252693,
      "grad_norm": 3.814051628112793,
      "learning_rate": 1.8563932615299642e-05,
      "loss": 0.0675,
      "step": 1300
    },
    {
      "epoch": 1.0853355426677713,
      "grad_norm": 0.660521388053894,
      "learning_rate": 1.855288594310964e-05,
      "loss": 0.0535,
      "step": 1310
    },
    {
      "epoch": 1.0936205468102733,
      "grad_norm": 3.178804636001587,
      "learning_rate": 1.854183927091964e-05,
      "loss": 0.0559,
      "step": 1320
    },
    {
      "epoch": 1.1019055509527755,
      "grad_norm": 7.742392063140869,
      "learning_rate": 1.8530792598729633e-05,
      "loss": 0.0485,
      "step": 1330
    },
    {
      "epoch": 1.1101905550952775,
      "grad_norm": 0.014764237217605114,
      "learning_rate": 1.8519745926539632e-05,
      "loss": 0.0199,
      "step": 1340
    },
    {
      "epoch": 1.1184755592377795,
      "grad_norm": 0.4254348874092102,
      "learning_rate": 1.850869925434963e-05,
      "loss": 0.0626,
      "step": 1350
    },
    {
      "epoch": 1.1267605633802817,
      "grad_norm": 1.8391648530960083,
      "learning_rate": 1.8497652582159625e-05,
      "loss": 0.0519,
      "step": 1360
    },
    {
      "epoch": 1.1350455675227837,
      "grad_norm": 0.045830823481082916,
      "learning_rate": 1.8486605909969623e-05,
      "loss": 0.0335,
      "step": 1370
    },
    {
      "epoch": 1.143330571665286,
      "grad_norm": 0.002857932122424245,
      "learning_rate": 1.8475559237779622e-05,
      "loss": 0.0609,
      "step": 1380
    },
    {
      "epoch": 1.151615575807788,
      "grad_norm": 106.55497741699219,
      "learning_rate": 1.8464512565589617e-05,
      "loss": 0.0447,
      "step": 1390
    },
    {
      "epoch": 1.15990057995029,
      "grad_norm": 0.796990156173706,
      "learning_rate": 1.8453465893399615e-05,
      "loss": 0.0285,
      "step": 1400
    },
    {
      "epoch": 1.1681855840927922,
      "grad_norm": 0.01831899583339691,
      "learning_rate": 1.8442419221209614e-05,
      "loss": 0.01,
      "step": 1410
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 7.370285987854004,
      "learning_rate": 1.843137254901961e-05,
      "loss": 0.0399,
      "step": 1420
    },
    {
      "epoch": 1.1847555923777962,
      "grad_norm": 0.1209753230214119,
      "learning_rate": 1.8420325876829607e-05,
      "loss": 0.0226,
      "step": 1430
    },
    {
      "epoch": 1.1930405965202984,
      "grad_norm": 3.518021821975708,
      "learning_rate": 1.8409279204639602e-05,
      "loss": 0.0191,
      "step": 1440
    },
    {
      "epoch": 1.2013256006628004,
      "grad_norm": 4.868402004241943,
      "learning_rate": 1.83982325324496e-05,
      "loss": 0.0541,
      "step": 1450
    },
    {
      "epoch": 1.2096106048053024,
      "grad_norm": 1.5247981548309326,
      "learning_rate": 1.83871858602596e-05,
      "loss": 0.1983,
      "step": 1460
    },
    {
      "epoch": 1.2178956089478046,
      "grad_norm": 0.9539051055908203,
      "learning_rate": 1.8376139188069593e-05,
      "loss": 0.0296,
      "step": 1470
    },
    {
      "epoch": 1.2261806130903066,
      "grad_norm": 5.716655731201172,
      "learning_rate": 1.8365092515879592e-05,
      "loss": 0.0638,
      "step": 1480
    },
    {
      "epoch": 1.2344656172328086,
      "grad_norm": 0.36119934916496277,
      "learning_rate": 1.835404584368959e-05,
      "loss": 0.0159,
      "step": 1490
    },
    {
      "epoch": 1.2427506213753108,
      "grad_norm": 6.5749664306640625,
      "learning_rate": 1.834299917149959e-05,
      "loss": 0.0323,
      "step": 1500
    },
    {
      "epoch": 1.2510356255178128,
      "grad_norm": 0.2011006772518158,
      "learning_rate": 1.8331952499309583e-05,
      "loss": 0.0404,
      "step": 1510
    },
    {
      "epoch": 1.2593206296603148,
      "grad_norm": 0.060211554169654846,
      "learning_rate": 1.8320905827119582e-05,
      "loss": 0.0284,
      "step": 1520
    },
    {
      "epoch": 1.267605633802817,
      "grad_norm": 2.622967481613159,
      "learning_rate": 1.830985915492958e-05,
      "loss": 0.061,
      "step": 1530
    },
    {
      "epoch": 1.275890637945319,
      "grad_norm": 0.3347269892692566,
      "learning_rate": 1.8298812482739575e-05,
      "loss": 0.0891,
      "step": 1540
    },
    {
      "epoch": 1.284175642087821,
      "grad_norm": 3.2464118003845215,
      "learning_rate": 1.8287765810549574e-05,
      "loss": 0.0677,
      "step": 1550
    },
    {
      "epoch": 1.2924606462303232,
      "grad_norm": 0.42254510521888733,
      "learning_rate": 1.8276719138359572e-05,
      "loss": 0.0377,
      "step": 1560
    },
    {
      "epoch": 1.3007456503728252,
      "grad_norm": 5.77013635635376,
      "learning_rate": 1.8265672466169567e-05,
      "loss": 0.0523,
      "step": 1570
    },
    {
      "epoch": 1.3090306545153272,
      "grad_norm": 3.7702760696411133,
      "learning_rate": 1.8254625793979565e-05,
      "loss": 0.056,
      "step": 1580
    },
    {
      "epoch": 1.3173156586578294,
      "grad_norm": 0.044154077768325806,
      "learning_rate": 1.8243579121789564e-05,
      "loss": 0.0645,
      "step": 1590
    },
    {
      "epoch": 1.3256006628003314,
      "grad_norm": 0.14698384702205658,
      "learning_rate": 1.8232532449599562e-05,
      "loss": 0.0797,
      "step": 1600
    },
    {
      "epoch": 1.3338856669428334,
      "grad_norm": 0.6200771331787109,
      "learning_rate": 1.8221485777409557e-05,
      "loss": 0.068,
      "step": 1610
    },
    {
      "epoch": 1.3421706710853356,
      "grad_norm": 1.049156904220581,
      "learning_rate": 1.8210439105219555e-05,
      "loss": 0.0554,
      "step": 1620
    },
    {
      "epoch": 1.3504556752278376,
      "grad_norm": 0.2570551633834839,
      "learning_rate": 1.8199392433029554e-05,
      "loss": 0.0598,
      "step": 1630
    },
    {
      "epoch": 1.3587406793703396,
      "grad_norm": 0.5325201749801636,
      "learning_rate": 1.818834576083955e-05,
      "loss": 0.0237,
      "step": 1640
    },
    {
      "epoch": 1.3670256835128418,
      "grad_norm": 0.3535290062427521,
      "learning_rate": 1.8177299088649543e-05,
      "loss": 0.0276,
      "step": 1650
    },
    {
      "epoch": 1.3753106876553438,
      "grad_norm": 0.1411619782447815,
      "learning_rate": 1.8166252416459542e-05,
      "loss": 0.0208,
      "step": 1660
    },
    {
      "epoch": 1.3835956917978458,
      "grad_norm": 0.5529652237892151,
      "learning_rate": 1.815520574426954e-05,
      "loss": 0.034,
      "step": 1670
    },
    {
      "epoch": 1.391880695940348,
      "grad_norm": 8.603205680847168,
      "learning_rate": 1.814415907207954e-05,
      "loss": 0.1132,
      "step": 1680
    },
    {
      "epoch": 1.40016570008285,
      "grad_norm": 5.506992816925049,
      "learning_rate": 1.8133112399889534e-05,
      "loss": 0.0431,
      "step": 1690
    },
    {
      "epoch": 1.408450704225352,
      "grad_norm": 54.82271194458008,
      "learning_rate": 1.8122065727699532e-05,
      "loss": 0.0498,
      "step": 1700
    },
    {
      "epoch": 1.4167357083678542,
      "grad_norm": 0.4566658139228821,
      "learning_rate": 1.811101905550953e-05,
      "loss": 0.0671,
      "step": 1710
    },
    {
      "epoch": 1.4250207125103562,
      "grad_norm": 0.8854947090148926,
      "learning_rate": 1.8099972383319525e-05,
      "loss": 0.0495,
      "step": 1720
    },
    {
      "epoch": 1.4333057166528582,
      "grad_norm": 1.1561521291732788,
      "learning_rate": 1.8088925711129524e-05,
      "loss": 0.0214,
      "step": 1730
    },
    {
      "epoch": 1.4415907207953604,
      "grad_norm": 0.14874114096164703,
      "learning_rate": 1.8077879038939522e-05,
      "loss": 0.0115,
      "step": 1740
    },
    {
      "epoch": 1.4498757249378624,
      "grad_norm": 0.14555254578590393,
      "learning_rate": 1.8066832366749517e-05,
      "loss": 0.0525,
      "step": 1750
    },
    {
      "epoch": 1.4581607290803644,
      "grad_norm": 6.04415225982666,
      "learning_rate": 1.8055785694559515e-05,
      "loss": 0.073,
      "step": 1760
    },
    {
      "epoch": 1.4664457332228666,
      "grad_norm": 0.08395994454622269,
      "learning_rate": 1.8044739022369514e-05,
      "loss": 0.054,
      "step": 1770
    },
    {
      "epoch": 1.4747307373653686,
      "grad_norm": 0.26329052448272705,
      "learning_rate": 1.8033692350179512e-05,
      "loss": 0.0822,
      "step": 1780
    },
    {
      "epoch": 1.4830157415078706,
      "grad_norm": 0.6335886120796204,
      "learning_rate": 1.8022645677989507e-05,
      "loss": 0.0536,
      "step": 1790
    },
    {
      "epoch": 1.4913007456503728,
      "grad_norm": 0.7112382650375366,
      "learning_rate": 1.8011599005799505e-05,
      "loss": 0.0613,
      "step": 1800
    },
    {
      "epoch": 1.4995857497928748,
      "grad_norm": 3.752511739730835,
      "learning_rate": 1.8000552333609504e-05,
      "loss": 0.0484,
      "step": 1810
    },
    {
      "epoch": 1.5078707539353768,
      "grad_norm": 9.638740539550781,
      "learning_rate": 1.79895056614195e-05,
      "loss": 0.0531,
      "step": 1820
    },
    {
      "epoch": 1.516155758077879,
      "grad_norm": 0.1871626079082489,
      "learning_rate": 1.7978458989229497e-05,
      "loss": 0.063,
      "step": 1830
    },
    {
      "epoch": 1.5244407622203813,
      "grad_norm": 8.254920959472656,
      "learning_rate": 1.7967412317039495e-05,
      "loss": 0.0795,
      "step": 1840
    },
    {
      "epoch": 1.532725766362883,
      "grad_norm": 1.9725409746170044,
      "learning_rate": 1.795636564484949e-05,
      "loss": 0.0477,
      "step": 1850
    },
    {
      "epoch": 1.5410107705053853,
      "grad_norm": 0.36023855209350586,
      "learning_rate": 1.7945318972659485e-05,
      "loss": 0.0719,
      "step": 1860
    },
    {
      "epoch": 1.5492957746478875,
      "grad_norm": 0.35399577021598816,
      "learning_rate": 1.7934272300469484e-05,
      "loss": 0.0477,
      "step": 1870
    },
    {
      "epoch": 1.5575807787903893,
      "grad_norm": 4.9433770179748535,
      "learning_rate": 1.7923225628279482e-05,
      "loss": 0.068,
      "step": 1880
    },
    {
      "epoch": 1.5658657829328915,
      "grad_norm": 5.355448246002197,
      "learning_rate": 1.791217895608948e-05,
      "loss": 0.0456,
      "step": 1890
    },
    {
      "epoch": 1.5741507870753937,
      "grad_norm": 4.4518723487854,
      "learning_rate": 1.7901132283899475e-05,
      "loss": 0.0414,
      "step": 1900
    },
    {
      "epoch": 1.5824357912178955,
      "grad_norm": 0.17968986928462982,
      "learning_rate": 1.7890085611709474e-05,
      "loss": 0.0386,
      "step": 1910
    },
    {
      "epoch": 1.5907207953603977,
      "grad_norm": 0.42393141984939575,
      "learning_rate": 1.7879038939519472e-05,
      "loss": 0.0113,
      "step": 1920
    },
    {
      "epoch": 1.5990057995029,
      "grad_norm": 0.9264864921569824,
      "learning_rate": 1.7867992267329467e-05,
      "loss": 0.0064,
      "step": 1930
    },
    {
      "epoch": 1.6072908036454017,
      "grad_norm": 0.008084631524980068,
      "learning_rate": 1.7856945595139465e-05,
      "loss": 0.029,
      "step": 1940
    },
    {
      "epoch": 1.6155758077879039,
      "grad_norm": 0.013169193640351295,
      "learning_rate": 1.7845898922949464e-05,
      "loss": 0.0548,
      "step": 1950
    },
    {
      "epoch": 1.623860811930406,
      "grad_norm": 3.836695909500122,
      "learning_rate": 1.783485225075946e-05,
      "loss": 0.0209,
      "step": 1960
    },
    {
      "epoch": 1.6321458160729079,
      "grad_norm": 2.166525363922119,
      "learning_rate": 1.7823805578569457e-05,
      "loss": 0.0511,
      "step": 1970
    },
    {
      "epoch": 1.64043082021541,
      "grad_norm": 0.028482811525464058,
      "learning_rate": 1.7812758906379455e-05,
      "loss": 0.0581,
      "step": 1980
    },
    {
      "epoch": 1.6487158243579123,
      "grad_norm": 10.059854507446289,
      "learning_rate": 1.7801712234189454e-05,
      "loss": 0.0324,
      "step": 1990
    },
    {
      "epoch": 1.6570008285004143,
      "grad_norm": 2.8110578060150146,
      "learning_rate": 1.779066556199945e-05,
      "loss": 0.0327,
      "step": 2000
    },
    {
      "epoch": 1.6652858326429163,
      "grad_norm": 5.903904438018799,
      "learning_rate": 1.7779618889809447e-05,
      "loss": 0.053,
      "step": 2010
    },
    {
      "epoch": 1.6735708367854185,
      "grad_norm": 7.222329139709473,
      "learning_rate": 1.7768572217619445e-05,
      "loss": 0.0118,
      "step": 2020
    },
    {
      "epoch": 1.6818558409279205,
      "grad_norm": 0.6725964546203613,
      "learning_rate": 1.775752554542944e-05,
      "loss": 0.05,
      "step": 2030
    },
    {
      "epoch": 1.6901408450704225,
      "grad_norm": 0.013502785935997963,
      "learning_rate": 1.774647887323944e-05,
      "loss": 0.0306,
      "step": 2040
    },
    {
      "epoch": 1.6984258492129247,
      "grad_norm": 0.015568850561976433,
      "learning_rate": 1.7735432201049437e-05,
      "loss": 0.0645,
      "step": 2050
    },
    {
      "epoch": 1.7067108533554267,
      "grad_norm": 3.445744514465332,
      "learning_rate": 1.7724385528859432e-05,
      "loss": 0.0351,
      "step": 2060
    },
    {
      "epoch": 1.7149958574979287,
      "grad_norm": 0.0682874396443367,
      "learning_rate": 1.771333885666943e-05,
      "loss": 0.0422,
      "step": 2070
    },
    {
      "epoch": 1.723280861640431,
      "grad_norm": 3.2454826831817627,
      "learning_rate": 1.7702292184479425e-05,
      "loss": 0.0891,
      "step": 2080
    },
    {
      "epoch": 1.731565865782933,
      "grad_norm": 0.07970868051052094,
      "learning_rate": 1.7691245512289424e-05,
      "loss": 0.029,
      "step": 2090
    },
    {
      "epoch": 1.739850869925435,
      "grad_norm": 5.766803741455078,
      "learning_rate": 1.7680198840099422e-05,
      "loss": 0.0552,
      "step": 2100
    },
    {
      "epoch": 1.7481358740679371,
      "grad_norm": 4.243529319763184,
      "learning_rate": 1.7669152167909417e-05,
      "loss": 0.0157,
      "step": 2110
    },
    {
      "epoch": 1.7564208782104391,
      "grad_norm": 2.8678431510925293,
      "learning_rate": 1.7658105495719415e-05,
      "loss": 0.0307,
      "step": 2120
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.04911605268716812,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 0.0118,
      "step": 2130
    },
    {
      "epoch": 1.7729908864954433,
      "grad_norm": 0.8872483372688293,
      "learning_rate": 1.763601215133941e-05,
      "loss": 0.0397,
      "step": 2140
    },
    {
      "epoch": 1.7812758906379453,
      "grad_norm": 7.687012672424316,
      "learning_rate": 1.7624965479149407e-05,
      "loss": 0.0403,
      "step": 2150
    },
    {
      "epoch": 1.7895608947804473,
      "grad_norm": 0.28267166018486023,
      "learning_rate": 1.7613918806959405e-05,
      "loss": 0.0089,
      "step": 2160
    },
    {
      "epoch": 1.7978458989229495,
      "grad_norm": 0.007381834555417299,
      "learning_rate": 1.7602872134769404e-05,
      "loss": 0.0068,
      "step": 2170
    },
    {
      "epoch": 1.8061309030654515,
      "grad_norm": 0.03704723343253136,
      "learning_rate": 1.75918254625794e-05,
      "loss": 0.0076,
      "step": 2180
    },
    {
      "epoch": 1.8144159072079535,
      "grad_norm": 6.207010269165039,
      "learning_rate": 1.7580778790389397e-05,
      "loss": 0.0449,
      "step": 2190
    },
    {
      "epoch": 1.8227009113504558,
      "grad_norm": 0.7882577776908875,
      "learning_rate": 1.7569732118199395e-05,
      "loss": 0.0235,
      "step": 2200
    },
    {
      "epoch": 1.8309859154929577,
      "grad_norm": 2.550128221511841,
      "learning_rate": 1.755868544600939e-05,
      "loss": 0.0402,
      "step": 2210
    },
    {
      "epoch": 1.8392709196354597,
      "grad_norm": 4.565611362457275,
      "learning_rate": 1.754763877381939e-05,
      "loss": 0.079,
      "step": 2220
    },
    {
      "epoch": 1.847555923777962,
      "grad_norm": 5.483495712280273,
      "learning_rate": 1.7536592101629387e-05,
      "loss": 0.064,
      "step": 2230
    },
    {
      "epoch": 1.855840927920464,
      "grad_norm": 4.22836971282959,
      "learning_rate": 1.7525545429439382e-05,
      "loss": 0.0775,
      "step": 2240
    },
    {
      "epoch": 1.864125932062966,
      "grad_norm": 0.003925811033695936,
      "learning_rate": 1.751449875724938e-05,
      "loss": 0.0342,
      "step": 2250
    },
    {
      "epoch": 1.8724109362054682,
      "grad_norm": 4.240581512451172,
      "learning_rate": 1.750345208505938e-05,
      "loss": 0.0248,
      "step": 2260
    },
    {
      "epoch": 1.8806959403479702,
      "grad_norm": 1.7654588222503662,
      "learning_rate": 1.7492405412869377e-05,
      "loss": 0.0116,
      "step": 2270
    },
    {
      "epoch": 1.8889809444904722,
      "grad_norm": 0.004582198802381754,
      "learning_rate": 1.7481358740679372e-05,
      "loss": 0.0139,
      "step": 2280
    },
    {
      "epoch": 1.8972659486329744,
      "grad_norm": 0.6079590320587158,
      "learning_rate": 1.747031206848937e-05,
      "loss": 0.0582,
      "step": 2290
    },
    {
      "epoch": 1.9055509527754764,
      "grad_norm": 2.339315891265869,
      "learning_rate": 1.7459265396299365e-05,
      "loss": 0.0489,
      "step": 2300
    },
    {
      "epoch": 1.9138359569179784,
      "grad_norm": 3.6832940578460693,
      "learning_rate": 1.7448218724109364e-05,
      "loss": 0.0361,
      "step": 2310
    },
    {
      "epoch": 1.9221209610604806,
      "grad_norm": 0.018268780782818794,
      "learning_rate": 1.743717205191936e-05,
      "loss": 0.0333,
      "step": 2320
    },
    {
      "epoch": 1.9304059652029826,
      "grad_norm": 0.18655899167060852,
      "learning_rate": 1.7426125379729357e-05,
      "loss": 0.039,
      "step": 2330
    },
    {
      "epoch": 1.9386909693454846,
      "grad_norm": 4.456225872039795,
      "learning_rate": 1.7415078707539355e-05,
      "loss": 0.0262,
      "step": 2340
    },
    {
      "epoch": 1.9469759734879868,
      "grad_norm": 3.7465884685516357,
      "learning_rate": 1.740403203534935e-05,
      "loss": 0.0122,
      "step": 2350
    },
    {
      "epoch": 1.9552609776304888,
      "grad_norm": 0.36689257621765137,
      "learning_rate": 1.739298536315935e-05,
      "loss": 0.0242,
      "step": 2360
    },
    {
      "epoch": 1.9635459817729908,
      "grad_norm": 0.1576869785785675,
      "learning_rate": 1.7381938690969347e-05,
      "loss": 0.0805,
      "step": 2370
    },
    {
      "epoch": 1.971830985915493,
      "grad_norm": 0.029918920248746872,
      "learning_rate": 1.7370892018779345e-05,
      "loss": 0.0094,
      "step": 2380
    },
    {
      "epoch": 1.980115990057995,
      "grad_norm": 0.027533672749996185,
      "learning_rate": 1.735984534658934e-05,
      "loss": 0.0312,
      "step": 2390
    },
    {
      "epoch": 1.988400994200497,
      "grad_norm": 0.09988482296466827,
      "learning_rate": 1.734879867439934e-05,
      "loss": 0.0342,
      "step": 2400
    },
    {
      "epoch": 1.9966859983429992,
      "grad_norm": 5.7140655517578125,
      "learning_rate": 1.7337752002209337e-05,
      "loss": 0.0439,
      "step": 2410
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9893617021276596,
      "eval_f1": 0.9401360544217687,
      "eval_loss": 0.03834151849150658,
      "eval_precision": 0.9664335664335665,
      "eval_recall": 0.9152317880794701,
      "eval_runtime": 1133.5694,
      "eval_samples_per_second": 7.302,
      "eval_steps_per_second": 0.913,
      "step": 2414
    },
    {
      "epoch": 2.0049710024855014,
      "grad_norm": 0.01665310189127922,
      "learning_rate": 1.7326705330019332e-05,
      "loss": 0.0658,
      "step": 2420
    },
    {
      "epoch": 2.013256006628003,
      "grad_norm": 3.705397605895996,
      "learning_rate": 1.731565865782933e-05,
      "loss": 0.0403,
      "step": 2430
    },
    {
      "epoch": 2.0215410107705054,
      "grad_norm": 0.032184191048145294,
      "learning_rate": 1.730461198563933e-05,
      "loss": 0.0323,
      "step": 2440
    },
    {
      "epoch": 2.0298260149130076,
      "grad_norm": 0.2274104505777359,
      "learning_rate": 1.7293565313449327e-05,
      "loss": 0.0298,
      "step": 2450
    },
    {
      "epoch": 2.0381110190555094,
      "grad_norm": 0.024444138631224632,
      "learning_rate": 1.7282518641259322e-05,
      "loss": 0.029,
      "step": 2460
    },
    {
      "epoch": 2.0463960231980116,
      "grad_norm": 0.9689447283744812,
      "learning_rate": 1.727147196906932e-05,
      "loss": 0.0703,
      "step": 2470
    },
    {
      "epoch": 2.054681027340514,
      "grad_norm": 3.2819206714630127,
      "learning_rate": 1.726042529687932e-05,
      "loss": 0.0349,
      "step": 2480
    },
    {
      "epoch": 2.0629660314830156,
      "grad_norm": 3.8048644065856934,
      "learning_rate": 1.7249378624689314e-05,
      "loss": 0.0114,
      "step": 2490
    },
    {
      "epoch": 2.071251035625518,
      "grad_norm": 0.6903166770935059,
      "learning_rate": 1.7238331952499312e-05,
      "loss": 0.0037,
      "step": 2500
    },
    {
      "epoch": 2.07953603976802,
      "grad_norm": 0.0022467963863164186,
      "learning_rate": 1.7227285280309307e-05,
      "loss": 0.0019,
      "step": 2510
    },
    {
      "epoch": 2.087821043910522,
      "grad_norm": 5.184483051300049,
      "learning_rate": 1.7216238608119305e-05,
      "loss": 0.0424,
      "step": 2520
    },
    {
      "epoch": 2.096106048053024,
      "grad_norm": 0.14395660161972046,
      "learning_rate": 1.72051919359293e-05,
      "loss": 0.0153,
      "step": 2530
    },
    {
      "epoch": 2.1043910521955262,
      "grad_norm": 0.019642790779471397,
      "learning_rate": 1.71941452637393e-05,
      "loss": 0.0099,
      "step": 2540
    },
    {
      "epoch": 2.112676056338028,
      "grad_norm": 0.008112824521958828,
      "learning_rate": 1.7183098591549297e-05,
      "loss": 0.0365,
      "step": 2550
    },
    {
      "epoch": 2.1209610604805302,
      "grad_norm": 0.044918593019247055,
      "learning_rate": 1.7172051919359295e-05,
      "loss": 0.0031,
      "step": 2560
    },
    {
      "epoch": 2.1292460646230325,
      "grad_norm": 4.09920072555542,
      "learning_rate": 1.716100524716929e-05,
      "loss": 0.0684,
      "step": 2570
    },
    {
      "epoch": 2.1375310687655342,
      "grad_norm": 0.44443488121032715,
      "learning_rate": 1.714995857497929e-05,
      "loss": 0.0138,
      "step": 2580
    },
    {
      "epoch": 2.1458160729080364,
      "grad_norm": 0.03258252888917923,
      "learning_rate": 1.7138911902789287e-05,
      "loss": 0.0171,
      "step": 2590
    },
    {
      "epoch": 2.1541010770505387,
      "grad_norm": 0.024504171684384346,
      "learning_rate": 1.7127865230599282e-05,
      "loss": 0.0022,
      "step": 2600
    },
    {
      "epoch": 2.1623860811930404,
      "grad_norm": 6.098658084869385,
      "learning_rate": 1.711681855840928e-05,
      "loss": 0.0691,
      "step": 2610
    },
    {
      "epoch": 2.1706710853355426,
      "grad_norm": 0.02289588190615177,
      "learning_rate": 1.710577188621928e-05,
      "loss": 0.009,
      "step": 2620
    },
    {
      "epoch": 2.178956089478045,
      "grad_norm": 3.6352267265319824,
      "learning_rate": 1.7094725214029274e-05,
      "loss": 0.0277,
      "step": 2630
    },
    {
      "epoch": 2.1872410936205466,
      "grad_norm": 0.003663210663944483,
      "learning_rate": 1.7083678541839272e-05,
      "loss": 0.0908,
      "step": 2640
    },
    {
      "epoch": 2.195526097763049,
      "grad_norm": 4.6216206550598145,
      "learning_rate": 1.707263186964927e-05,
      "loss": 0.0256,
      "step": 2650
    },
    {
      "epoch": 2.203811101905551,
      "grad_norm": 0.01790132001042366,
      "learning_rate": 1.706158519745927e-05,
      "loss": 0.0107,
      "step": 2660
    },
    {
      "epoch": 2.212096106048053,
      "grad_norm": 1.6578017473220825,
      "learning_rate": 1.7050538525269264e-05,
      "loss": 0.0568,
      "step": 2670
    },
    {
      "epoch": 2.220381110190555,
      "grad_norm": 0.12373266369104385,
      "learning_rate": 1.7039491853079262e-05,
      "loss": 0.0022,
      "step": 2680
    },
    {
      "epoch": 2.2286661143330573,
      "grad_norm": 0.22926542162895203,
      "learning_rate": 1.702844518088926e-05,
      "loss": 0.0123,
      "step": 2690
    },
    {
      "epoch": 2.236951118475559,
      "grad_norm": 0.12420554459095001,
      "learning_rate": 1.7017398508699255e-05,
      "loss": 0.0388,
      "step": 2700
    },
    {
      "epoch": 2.2452361226180613,
      "grad_norm": 0.020875632762908936,
      "learning_rate": 1.7006351836509254e-05,
      "loss": 0.0519,
      "step": 2710
    },
    {
      "epoch": 2.2535211267605635,
      "grad_norm": 0.027208693325519562,
      "learning_rate": 1.6995305164319252e-05,
      "loss": 0.0031,
      "step": 2720
    },
    {
      "epoch": 2.2618061309030653,
      "grad_norm": 0.5314380526542664,
      "learning_rate": 1.6984258492129247e-05,
      "loss": 0.001,
      "step": 2730
    },
    {
      "epoch": 2.2700911350455675,
      "grad_norm": 0.0021484149619936943,
      "learning_rate": 1.6973211819939245e-05,
      "loss": 0.0475,
      "step": 2740
    },
    {
      "epoch": 2.2783761391880697,
      "grad_norm": 2.639817714691162,
      "learning_rate": 1.696216514774924e-05,
      "loss": 0.035,
      "step": 2750
    },
    {
      "epoch": 2.286661143330572,
      "grad_norm": 0.10334792733192444,
      "learning_rate": 1.695111847555924e-05,
      "loss": 0.0082,
      "step": 2760
    },
    {
      "epoch": 2.2949461474730737,
      "grad_norm": 0.06267572194337845,
      "learning_rate": 1.6940071803369237e-05,
      "loss": 0.0045,
      "step": 2770
    },
    {
      "epoch": 2.303231151615576,
      "grad_norm": 0.07045581191778183,
      "learning_rate": 1.6929025131179232e-05,
      "loss": 0.0152,
      "step": 2780
    },
    {
      "epoch": 2.3115161557580777,
      "grad_norm": 0.010299460031092167,
      "learning_rate": 1.691797845898923e-05,
      "loss": 0.0492,
      "step": 2790
    },
    {
      "epoch": 2.31980115990058,
      "grad_norm": 0.14130905270576477,
      "learning_rate": 1.690693178679923e-05,
      "loss": 0.0252,
      "step": 2800
    },
    {
      "epoch": 2.328086164043082,
      "grad_norm": 4.252547264099121,
      "learning_rate": 1.6895885114609224e-05,
      "loss": 0.0269,
      "step": 2810
    },
    {
      "epoch": 2.3363711681855843,
      "grad_norm": 0.8216039538383484,
      "learning_rate": 1.6884838442419222e-05,
      "loss": 0.0441,
      "step": 2820
    },
    {
      "epoch": 2.344656172328086,
      "grad_norm": 5.47669792175293,
      "learning_rate": 1.687379177022922e-05,
      "loss": 0.0715,
      "step": 2830
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.026679906994104385,
      "learning_rate": 1.686274509803922e-05,
      "loss": 0.0023,
      "step": 2840
    },
    {
      "epoch": 2.36122618061309,
      "grad_norm": 0.01926913484930992,
      "learning_rate": 1.6851698425849214e-05,
      "loss": 0.0171,
      "step": 2850
    },
    {
      "epoch": 2.3695111847555923,
      "grad_norm": 3.8591418266296387,
      "learning_rate": 1.6840651753659212e-05,
      "loss": 0.0442,
      "step": 2860
    },
    {
      "epoch": 2.3777961888980945,
      "grad_norm": 0.18316255509853363,
      "learning_rate": 1.682960508146921e-05,
      "loss": 0.0142,
      "step": 2870
    },
    {
      "epoch": 2.3860811930405967,
      "grad_norm": 0.018746711313724518,
      "learning_rate": 1.6818558409279205e-05,
      "loss": 0.0184,
      "step": 2880
    },
    {
      "epoch": 2.3943661971830985,
      "grad_norm": 0.031261689960956573,
      "learning_rate": 1.6807511737089204e-05,
      "loss": 0.0303,
      "step": 2890
    },
    {
      "epoch": 2.4026512013256007,
      "grad_norm": 4.094938278198242,
      "learning_rate": 1.6796465064899202e-05,
      "loss": 0.0276,
      "step": 2900
    },
    {
      "epoch": 2.4109362054681025,
      "grad_norm": 0.04196135327219963,
      "learning_rate": 1.6785418392709197e-05,
      "loss": 0.0384,
      "step": 2910
    },
    {
      "epoch": 2.4192212096106047,
      "grad_norm": 0.06421317160129547,
      "learning_rate": 1.6774371720519195e-05,
      "loss": 0.0121,
      "step": 2920
    },
    {
      "epoch": 2.427506213753107,
      "grad_norm": 0.06244895979762077,
      "learning_rate": 1.6763325048329194e-05,
      "loss": 0.0014,
      "step": 2930
    },
    {
      "epoch": 2.435791217895609,
      "grad_norm": 0.14392586052417755,
      "learning_rate": 1.6752278376139192e-05,
      "loss": 0.0022,
      "step": 2940
    },
    {
      "epoch": 2.444076222038111,
      "grad_norm": 0.02047073096036911,
      "learning_rate": 1.6741231703949187e-05,
      "loss": 0.0234,
      "step": 2950
    },
    {
      "epoch": 2.452361226180613,
      "grad_norm": 0.0703338012099266,
      "learning_rate": 1.6730185031759182e-05,
      "loss": 0.0363,
      "step": 2960
    },
    {
      "epoch": 2.460646230323115,
      "grad_norm": 0.11484276503324509,
      "learning_rate": 1.671913835956918e-05,
      "loss": 0.0241,
      "step": 2970
    },
    {
      "epoch": 2.468931234465617,
      "grad_norm": 0.015553637407720089,
      "learning_rate": 1.670809168737918e-05,
      "loss": 0.019,
      "step": 2980
    },
    {
      "epoch": 2.4772162386081193,
      "grad_norm": 0.05418394133448601,
      "learning_rate": 1.6697045015189174e-05,
      "loss": 0.0545,
      "step": 2990
    },
    {
      "epoch": 2.4855012427506216,
      "grad_norm": 0.053715769201517105,
      "learning_rate": 1.6685998342999172e-05,
      "loss": 0.0325,
      "step": 3000
    },
    {
      "epoch": 2.4937862468931233,
      "grad_norm": 6.359131336212158,
      "learning_rate": 1.667495167080917e-05,
      "loss": 0.0498,
      "step": 3010
    },
    {
      "epoch": 2.5020712510356256,
      "grad_norm": 5.85668420791626,
      "learning_rate": 1.6663904998619165e-05,
      "loss": 0.0295,
      "step": 3020
    },
    {
      "epoch": 2.5103562551781273,
      "grad_norm": 3.9727694988250732,
      "learning_rate": 1.6652858326429164e-05,
      "loss": 0.0164,
      "step": 3030
    },
    {
      "epoch": 2.5186412593206295,
      "grad_norm": 7.681591510772705,
      "learning_rate": 1.6641811654239162e-05,
      "loss": 0.0382,
      "step": 3040
    },
    {
      "epoch": 2.5269262634631318,
      "grad_norm": 0.9954151511192322,
      "learning_rate": 1.663076498204916e-05,
      "loss": 0.0136,
      "step": 3050
    },
    {
      "epoch": 2.535211267605634,
      "grad_norm": 0.010898943059146404,
      "learning_rate": 1.6619718309859155e-05,
      "loss": 0.0264,
      "step": 3060
    },
    {
      "epoch": 2.5434962717481358,
      "grad_norm": 0.01793796196579933,
      "learning_rate": 1.6608671637669154e-05,
      "loss": 0.0247,
      "step": 3070
    },
    {
      "epoch": 2.551781275890638,
      "grad_norm": 5.045830726623535,
      "learning_rate": 1.6597624965479152e-05,
      "loss": 0.0637,
      "step": 3080
    },
    {
      "epoch": 2.5600662800331397,
      "grad_norm": 0.22114716470241547,
      "learning_rate": 1.6586578293289147e-05,
      "loss": 0.055,
      "step": 3090
    },
    {
      "epoch": 2.568351284175642,
      "grad_norm": 0.37663963437080383,
      "learning_rate": 1.6575531621099145e-05,
      "loss": 0.0033,
      "step": 3100
    },
    {
      "epoch": 2.576636288318144,
      "grad_norm": 0.023439329117536545,
      "learning_rate": 1.6564484948909144e-05,
      "loss": 0.0099,
      "step": 3110
    },
    {
      "epoch": 2.5849212924606464,
      "grad_norm": 0.0364522747695446,
      "learning_rate": 1.655343827671914e-05,
      "loss": 0.0231,
      "step": 3120
    },
    {
      "epoch": 2.593206296603148,
      "grad_norm": 6.007471561431885,
      "learning_rate": 1.6542391604529137e-05,
      "loss": 0.0471,
      "step": 3130
    },
    {
      "epoch": 2.6014913007456504,
      "grad_norm": 0.0516766682267189,
      "learning_rate": 1.6531344932339135e-05,
      "loss": 0.0019,
      "step": 3140
    },
    {
      "epoch": 2.6097763048881526,
      "grad_norm": 0.20358958840370178,
      "learning_rate": 1.6520298260149134e-05,
      "loss": 0.0188,
      "step": 3150
    },
    {
      "epoch": 2.6180613090306544,
      "grad_norm": 0.10212886333465576,
      "learning_rate": 1.650925158795913e-05,
      "loss": 0.0355,
      "step": 3160
    },
    {
      "epoch": 2.6263463131731566,
      "grad_norm": 0.01268177479505539,
      "learning_rate": 1.6498204915769124e-05,
      "loss": 0.0028,
      "step": 3170
    },
    {
      "epoch": 2.634631317315659,
      "grad_norm": 0.004182748030871153,
      "learning_rate": 1.6487158243579122e-05,
      "loss": 0.0192,
      "step": 3180
    },
    {
      "epoch": 2.6429163214581606,
      "grad_norm": 0.01424336526542902,
      "learning_rate": 1.647611157138912e-05,
      "loss": 0.0244,
      "step": 3190
    },
    {
      "epoch": 2.651201325600663,
      "grad_norm": 3.5879249572753906,
      "learning_rate": 1.6465064899199115e-05,
      "loss": 0.0445,
      "step": 3200
    },
    {
      "epoch": 2.659486329743165,
      "grad_norm": 21.167356491088867,
      "learning_rate": 1.6454018227009114e-05,
      "loss": 0.0297,
      "step": 3210
    },
    {
      "epoch": 2.667771333885667,
      "grad_norm": 0.02984333224594593,
      "learning_rate": 1.6442971554819112e-05,
      "loss": 0.0167,
      "step": 3220
    },
    {
      "epoch": 2.676056338028169,
      "grad_norm": 0.016137199476361275,
      "learning_rate": 1.643192488262911e-05,
      "loss": 0.0327,
      "step": 3230
    },
    {
      "epoch": 2.684341342170671,
      "grad_norm": 0.01802348904311657,
      "learning_rate": 1.6420878210439105e-05,
      "loss": 0.0138,
      "step": 3240
    },
    {
      "epoch": 2.692626346313173,
      "grad_norm": 0.02379121445119381,
      "learning_rate": 1.6409831538249104e-05,
      "loss": 0.0122,
      "step": 3250
    },
    {
      "epoch": 2.700911350455675,
      "grad_norm": 0.09893622994422913,
      "learning_rate": 1.6398784866059102e-05,
      "loss": 0.035,
      "step": 3260
    },
    {
      "epoch": 2.7091963545981774,
      "grad_norm": 6.262203693389893,
      "learning_rate": 1.6387738193869097e-05,
      "loss": 0.0404,
      "step": 3270
    },
    {
      "epoch": 2.717481358740679,
      "grad_norm": 0.04945976287126541,
      "learning_rate": 1.6376691521679095e-05,
      "loss": 0.0239,
      "step": 3280
    },
    {
      "epoch": 2.7257663628831814,
      "grad_norm": 0.007202361710369587,
      "learning_rate": 1.6365644849489094e-05,
      "loss": 0.0007,
      "step": 3290
    },
    {
      "epoch": 2.7340513670256836,
      "grad_norm": 2.59710693359375,
      "learning_rate": 1.635459817729909e-05,
      "loss": 0.0398,
      "step": 3300
    },
    {
      "epoch": 2.742336371168186,
      "grad_norm": 1.470621943473816,
      "learning_rate": 1.6343551505109087e-05,
      "loss": 0.0506,
      "step": 3310
    },
    {
      "epoch": 2.7506213753106876,
      "grad_norm": 0.024638520553708076,
      "learning_rate": 1.6332504832919085e-05,
      "loss": 0.0142,
      "step": 3320
    },
    {
      "epoch": 2.75890637945319,
      "grad_norm": 0.04165250435471535,
      "learning_rate": 1.6321458160729084e-05,
      "loss": 0.0038,
      "step": 3330
    },
    {
      "epoch": 2.7671913835956916,
      "grad_norm": 2.323779582977295,
      "learning_rate": 1.631041148853908e-05,
      "loss": 0.0244,
      "step": 3340
    },
    {
      "epoch": 2.775476387738194,
      "grad_norm": 0.4203523099422455,
      "learning_rate": 1.6299364816349077e-05,
      "loss": 0.0508,
      "step": 3350
    },
    {
      "epoch": 2.783761391880696,
      "grad_norm": 0.22961267828941345,
      "learning_rate": 1.6288318144159075e-05,
      "loss": 0.0037,
      "step": 3360
    },
    {
      "epoch": 2.7920463960231983,
      "grad_norm": 5.890905857086182,
      "learning_rate": 1.627727147196907e-05,
      "loss": 0.0572,
      "step": 3370
    },
    {
      "epoch": 2.8003314001657,
      "grad_norm": 0.0023939679376780987,
      "learning_rate": 1.626622479977907e-05,
      "loss": 0.0366,
      "step": 3380
    },
    {
      "epoch": 2.8086164043082023,
      "grad_norm": 0.3105999231338501,
      "learning_rate": 1.6255178127589064e-05,
      "loss": 0.0142,
      "step": 3390
    },
    {
      "epoch": 2.816901408450704,
      "grad_norm": 0.08796500414609909,
      "learning_rate": 1.6244131455399062e-05,
      "loss": 0.0584,
      "step": 3400
    },
    {
      "epoch": 2.8251864125932062,
      "grad_norm": 0.8468886613845825,
      "learning_rate": 1.623308478320906e-05,
      "loss": 0.0293,
      "step": 3410
    },
    {
      "epoch": 2.8334714167357085,
      "grad_norm": 0.015183767303824425,
      "learning_rate": 1.6222038111019055e-05,
      "loss": 0.0543,
      "step": 3420
    },
    {
      "epoch": 2.8417564208782107,
      "grad_norm": 0.0380406379699707,
      "learning_rate": 1.6210991438829054e-05,
      "loss": 0.0145,
      "step": 3430
    },
    {
      "epoch": 2.8500414250207124,
      "grad_norm": 1.6923960447311401,
      "learning_rate": 1.6199944766639052e-05,
      "loss": 0.0239,
      "step": 3440
    },
    {
      "epoch": 2.8583264291632147,
      "grad_norm": 0.012279298156499863,
      "learning_rate": 1.6188898094449047e-05,
      "loss": 0.0316,
      "step": 3450
    },
    {
      "epoch": 2.8666114333057164,
      "grad_norm": 0.23835289478302002,
      "learning_rate": 1.6177851422259045e-05,
      "loss": 0.0219,
      "step": 3460
    },
    {
      "epoch": 2.8748964374482187,
      "grad_norm": 0.05948561057448387,
      "learning_rate": 1.6166804750069044e-05,
      "loss": 0.0582,
      "step": 3470
    },
    {
      "epoch": 2.883181441590721,
      "grad_norm": 0.007235509809106588,
      "learning_rate": 1.615575807787904e-05,
      "loss": 0.0122,
      "step": 3480
    },
    {
      "epoch": 2.891466445733223,
      "grad_norm": 0.015601160936057568,
      "learning_rate": 1.6144711405689037e-05,
      "loss": 0.0251,
      "step": 3490
    },
    {
      "epoch": 2.899751449875725,
      "grad_norm": 1.0671533346176147,
      "learning_rate": 1.6133664733499035e-05,
      "loss": 0.0408,
      "step": 3500
    },
    {
      "epoch": 2.908036454018227,
      "grad_norm": 0.09948045760393143,
      "learning_rate": 1.6122618061309034e-05,
      "loss": 0.0309,
      "step": 3510
    },
    {
      "epoch": 2.916321458160729,
      "grad_norm": 3.6365158557891846,
      "learning_rate": 1.611157138911903e-05,
      "loss": 0.021,
      "step": 3520
    },
    {
      "epoch": 2.924606462303231,
      "grad_norm": 0.03345692902803421,
      "learning_rate": 1.6100524716929027e-05,
      "loss": 0.007,
      "step": 3530
    },
    {
      "epoch": 2.9328914664457333,
      "grad_norm": 4.259924411773682,
      "learning_rate": 1.6089478044739025e-05,
      "loss": 0.1402,
      "step": 3540
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.12500886619091034,
      "learning_rate": 1.607843137254902e-05,
      "loss": 0.0038,
      "step": 3550
    },
    {
      "epoch": 2.9494614747307373,
      "grad_norm": 0.23881293833255768,
      "learning_rate": 1.606738470035902e-05,
      "loss": 0.0232,
      "step": 3560
    },
    {
      "epoch": 2.9577464788732395,
      "grad_norm": 0.04845048114657402,
      "learning_rate": 1.6056338028169017e-05,
      "loss": 0.0372,
      "step": 3570
    },
    {
      "epoch": 2.9660314830157413,
      "grad_norm": 4.450745582580566,
      "learning_rate": 1.6045291355979012e-05,
      "loss": 0.0376,
      "step": 3580
    },
    {
      "epoch": 2.9743164871582435,
      "grad_norm": 3.67562198638916,
      "learning_rate": 1.603424468378901e-05,
      "loss": 0.0121,
      "step": 3590
    },
    {
      "epoch": 2.9826014913007457,
      "grad_norm": 5.054569721221924,
      "learning_rate": 1.6023198011599005e-05,
      "loss": 0.0687,
      "step": 3600
    },
    {
      "epoch": 2.990886495443248,
      "grad_norm": 0.02181999757885933,
      "learning_rate": 1.6012151339409004e-05,
      "loss": 0.0356,
      "step": 3610
    },
    {
      "epoch": 2.9991714995857497,
      "grad_norm": 22.240947723388672,
      "learning_rate": 1.6001104667219002e-05,
      "loss": 0.0116,
      "step": 3620
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9891199226305609,
      "eval_f1": 0.9389416553595659,
      "eval_loss": 0.04020969197154045,
      "eval_precision": 0.9624478442280946,
      "eval_recall": 0.9165562913907285,
      "eval_runtime": 1656.0624,
      "eval_samples_per_second": 4.998,
      "eval_steps_per_second": 0.625,
      "step": 3621
    },
    {
      "epoch": 3.007456503728252,
      "grad_norm": 0.12331822514533997,
      "learning_rate": 1.5990057995028997e-05,
      "loss": 0.0118,
      "step": 3630
    },
    {
      "epoch": 3.015741507870754,
      "grad_norm": 6.887385845184326,
      "learning_rate": 1.5979011322838995e-05,
      "loss": 0.0238,
      "step": 3640
    },
    {
      "epoch": 3.024026512013256,
      "grad_norm": 0.19899989664554596,
      "learning_rate": 1.5967964650648994e-05,
      "loss": 0.0185,
      "step": 3650
    },
    {
      "epoch": 3.032311516155758,
      "grad_norm": 0.017181994393467903,
      "learning_rate": 1.595691797845899e-05,
      "loss": 0.028,
      "step": 3660
    },
    {
      "epoch": 3.0405965202982603,
      "grad_norm": 0.08034030348062515,
      "learning_rate": 1.5945871306268987e-05,
      "loss": 0.0167,
      "step": 3670
    },
    {
      "epoch": 3.048881524440762,
      "grad_norm": 0.07248985022306442,
      "learning_rate": 1.5934824634078985e-05,
      "loss": 0.0056,
      "step": 3680
    },
    {
      "epoch": 3.0571665285832643,
      "grad_norm": 0.0271073617041111,
      "learning_rate": 1.592377796188898e-05,
      "loss": 0.0195,
      "step": 3690
    },
    {
      "epoch": 3.0654515327257665,
      "grad_norm": 0.0054039787501096725,
      "learning_rate": 1.591273128969898e-05,
      "loss": 0.0125,
      "step": 3700
    },
    {
      "epoch": 3.0737365368682683,
      "grad_norm": 0.34651684761047363,
      "learning_rate": 1.5901684617508977e-05,
      "loss": 0.0554,
      "step": 3710
    },
    {
      "epoch": 3.0820215410107705,
      "grad_norm": 0.05218135565519333,
      "learning_rate": 1.5890637945318976e-05,
      "loss": 0.0412,
      "step": 3720
    },
    {
      "epoch": 3.0903065451532727,
      "grad_norm": 0.055122651159763336,
      "learning_rate": 1.587959127312897e-05,
      "loss": 0.008,
      "step": 3730
    },
    {
      "epoch": 3.0985915492957745,
      "grad_norm": 0.009133943356573582,
      "learning_rate": 1.586854460093897e-05,
      "loss": 0.0159,
      "step": 3740
    },
    {
      "epoch": 3.1068765534382767,
      "grad_norm": 0.013672984205186367,
      "learning_rate": 1.5857497928748967e-05,
      "loss": 0.0212,
      "step": 3750
    },
    {
      "epoch": 3.115161557580779,
      "grad_norm": 0.004368704278022051,
      "learning_rate": 1.5846451256558962e-05,
      "loss": 0.0057,
      "step": 3760
    },
    {
      "epoch": 3.1234465617232807,
      "grad_norm": 0.06303489953279495,
      "learning_rate": 1.583540458436896e-05,
      "loss": 0.0097,
      "step": 3770
    },
    {
      "epoch": 3.131731565865783,
      "grad_norm": 0.058397334069013596,
      "learning_rate": 1.582435791217896e-05,
      "loss": 0.0075,
      "step": 3780
    },
    {
      "epoch": 3.140016570008285,
      "grad_norm": 0.0056908936239778996,
      "learning_rate": 1.5813311239988954e-05,
      "loss": 0.0413,
      "step": 3790
    },
    {
      "epoch": 3.148301574150787,
      "grad_norm": 0.17005139589309692,
      "learning_rate": 1.5802264567798952e-05,
      "loss": 0.0171,
      "step": 3800
    },
    {
      "epoch": 3.156586578293289,
      "grad_norm": 0.20264095067977905,
      "learning_rate": 1.579121789560895e-05,
      "loss": 0.0249,
      "step": 3810
    },
    {
      "epoch": 3.1648715824357914,
      "grad_norm": 1.6245759725570679,
      "learning_rate": 1.5780171223418945e-05,
      "loss": 0.0346,
      "step": 3820
    },
    {
      "epoch": 3.173156586578293,
      "grad_norm": 0.13954782485961914,
      "learning_rate": 1.5769124551228944e-05,
      "loss": 0.0029,
      "step": 3830
    },
    {
      "epoch": 3.1814415907207954,
      "grad_norm": 0.48685726523399353,
      "learning_rate": 1.575807787903894e-05,
      "loss": 0.0339,
      "step": 3840
    },
    {
      "epoch": 3.1897265948632976,
      "grad_norm": 1.2582248449325562,
      "learning_rate": 1.5747031206848937e-05,
      "loss": 0.0088,
      "step": 3850
    },
    {
      "epoch": 3.1980115990057993,
      "grad_norm": 6.815035343170166,
      "learning_rate": 1.5735984534658936e-05,
      "loss": 0.0065,
      "step": 3860
    },
    {
      "epoch": 3.2062966031483016,
      "grad_norm": 0.09692292660474777,
      "learning_rate": 1.572493786246893e-05,
      "loss": 0.0013,
      "step": 3870
    },
    {
      "epoch": 3.2145816072908038,
      "grad_norm": 0.013715257868170738,
      "learning_rate": 1.571389119027893e-05,
      "loss": 0.0202,
      "step": 3880
    },
    {
      "epoch": 3.2228666114333056,
      "grad_norm": 0.010103431530296803,
      "learning_rate": 1.5702844518088927e-05,
      "loss": 0.0357,
      "step": 3890
    },
    {
      "epoch": 3.2311516155758078,
      "grad_norm": 0.01912030391395092,
      "learning_rate": 1.5691797845898926e-05,
      "loss": 0.0217,
      "step": 3900
    },
    {
      "epoch": 3.23943661971831,
      "grad_norm": 4.405252456665039,
      "learning_rate": 1.568075117370892e-05,
      "loss": 0.0347,
      "step": 3910
    },
    {
      "epoch": 3.2477216238608118,
      "grad_norm": 8.739030838012695,
      "learning_rate": 1.566970450151892e-05,
      "loss": 0.0474,
      "step": 3920
    },
    {
      "epoch": 3.256006628003314,
      "grad_norm": 0.005240301135927439,
      "learning_rate": 1.5658657829328917e-05,
      "loss": 0.0052,
      "step": 3930
    },
    {
      "epoch": 3.264291632145816,
      "grad_norm": 2.626544952392578,
      "learning_rate": 1.5647611157138912e-05,
      "loss": 0.0313,
      "step": 3940
    },
    {
      "epoch": 3.272576636288318,
      "grad_norm": 0.007104604505002499,
      "learning_rate": 1.563656448494891e-05,
      "loss": 0.0414,
      "step": 3950
    },
    {
      "epoch": 3.28086164043082,
      "grad_norm": 3.3618900775909424,
      "learning_rate": 1.562551781275891e-05,
      "loss": 0.0124,
      "step": 3960
    },
    {
      "epoch": 3.2891466445733224,
      "grad_norm": 0.042484693229198456,
      "learning_rate": 1.5614471140568904e-05,
      "loss": 0.0205,
      "step": 3970
    },
    {
      "epoch": 3.297431648715824,
      "grad_norm": 5.441576957702637,
      "learning_rate": 1.5603424468378902e-05,
      "loss": 0.0258,
      "step": 3980
    },
    {
      "epoch": 3.3057166528583264,
      "grad_norm": 0.3441542387008667,
      "learning_rate": 1.55923777961889e-05,
      "loss": 0.0342,
      "step": 3990
    },
    {
      "epoch": 3.3140016570008286,
      "grad_norm": 0.2700125277042389,
      "learning_rate": 1.55813311239989e-05,
      "loss": 0.0013,
      "step": 4000
    },
    {
      "epoch": 3.3222866611433304,
      "grad_norm": 2.07350754737854,
      "learning_rate": 1.5570284451808894e-05,
      "loss": 0.0533,
      "step": 4010
    },
    {
      "epoch": 3.3305716652858326,
      "grad_norm": 0.22484207153320312,
      "learning_rate": 1.5559237779618892e-05,
      "loss": 0.0063,
      "step": 4020
    },
    {
      "epoch": 3.338856669428335,
      "grad_norm": 0.022801030427217484,
      "learning_rate": 1.554819110742889e-05,
      "loss": 0.0353,
      "step": 4030
    },
    {
      "epoch": 3.347141673570837,
      "grad_norm": 1.864977478981018,
      "learning_rate": 1.5537144435238886e-05,
      "loss": 0.0153,
      "step": 4040
    },
    {
      "epoch": 3.355426677713339,
      "grad_norm": 0.006200229283422232,
      "learning_rate": 1.552609776304888e-05,
      "loss": 0.0268,
      "step": 4050
    },
    {
      "epoch": 3.363711681855841,
      "grad_norm": 0.8932906985282898,
      "learning_rate": 1.551505109085888e-05,
      "loss": 0.0253,
      "step": 4060
    },
    {
      "epoch": 3.371996685998343,
      "grad_norm": 0.9171794056892395,
      "learning_rate": 1.5504004418668877e-05,
      "loss": 0.0131,
      "step": 4070
    },
    {
      "epoch": 3.380281690140845,
      "grad_norm": 3.175502061843872,
      "learning_rate": 1.5492957746478872e-05,
      "loss": 0.0356,
      "step": 4080
    },
    {
      "epoch": 3.3885666942833472,
      "grad_norm": 12.03591537475586,
      "learning_rate": 1.548191107428887e-05,
      "loss": 0.0505,
      "step": 4090
    },
    {
      "epoch": 3.3968516984258494,
      "grad_norm": 5.372775554656982,
      "learning_rate": 1.547086440209887e-05,
      "loss": 0.0316,
      "step": 4100
    },
    {
      "epoch": 3.405136702568351,
      "grad_norm": 0.08255580812692642,
      "learning_rate": 1.5459817729908867e-05,
      "loss": 0.0014,
      "step": 4110
    },
    {
      "epoch": 3.4134217067108534,
      "grad_norm": 0.11635090410709381,
      "learning_rate": 1.5448771057718862e-05,
      "loss": 0.0043,
      "step": 4120
    },
    {
      "epoch": 3.421706710853355,
      "grad_norm": 0.03395954146981239,
      "learning_rate": 1.543772438552886e-05,
      "loss": 0.0172,
      "step": 4130
    },
    {
      "epoch": 3.4299917149958574,
      "grad_norm": 0.008446881547570229,
      "learning_rate": 1.542667771333886e-05,
      "loss": 0.0176,
      "step": 4140
    },
    {
      "epoch": 3.4382767191383596,
      "grad_norm": 3.10343599319458,
      "learning_rate": 1.5415631041148854e-05,
      "loss": 0.024,
      "step": 4150
    },
    {
      "epoch": 3.446561723280862,
      "grad_norm": 0.5234495401382446,
      "learning_rate": 1.5404584368958852e-05,
      "loss": 0.0116,
      "step": 4160
    },
    {
      "epoch": 3.4548467274233636,
      "grad_norm": 0.006886572577059269,
      "learning_rate": 1.539353769676885e-05,
      "loss": 0.0039,
      "step": 4170
    },
    {
      "epoch": 3.463131731565866,
      "grad_norm": 2.3318049907684326,
      "learning_rate": 1.538249102457885e-05,
      "loss": 0.0102,
      "step": 4180
    },
    {
      "epoch": 3.4714167357083676,
      "grad_norm": 0.09490568190813065,
      "learning_rate": 1.5371444352388844e-05,
      "loss": 0.0316,
      "step": 4190
    },
    {
      "epoch": 3.47970173985087,
      "grad_norm": 0.939605712890625,
      "learning_rate": 1.5360397680198842e-05,
      "loss": 0.011,
      "step": 4200
    },
    {
      "epoch": 3.487986743993372,
      "grad_norm": 7.392505168914795,
      "learning_rate": 1.534935100800884e-05,
      "loss": 0.0198,
      "step": 4210
    },
    {
      "epoch": 3.4962717481358743,
      "grad_norm": 2.793405294418335,
      "learning_rate": 1.5338304335818836e-05,
      "loss": 0.0438,
      "step": 4220
    },
    {
      "epoch": 3.504556752278376,
      "grad_norm": 0.044201407581567764,
      "learning_rate": 1.5327257663628834e-05,
      "loss": 0.029,
      "step": 4230
    },
    {
      "epoch": 3.5128417564208783,
      "grad_norm": 4.23534631729126,
      "learning_rate": 1.5316210991438832e-05,
      "loss": 0.0376,
      "step": 4240
    },
    {
      "epoch": 3.52112676056338,
      "grad_norm": 6.687717914581299,
      "learning_rate": 1.5305164319248827e-05,
      "loss": 0.0179,
      "step": 4250
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.06409979611635208,
      "learning_rate": 1.5294117647058822e-05,
      "loss": 0.0268,
      "step": 4260
    },
    {
      "epoch": 3.5376967688483845,
      "grad_norm": 8.135344505310059,
      "learning_rate": 1.528307097486882e-05,
      "loss": 0.0274,
      "step": 4270
    },
    {
      "epoch": 3.5459817729908867,
      "grad_norm": 0.009935438632965088,
      "learning_rate": 1.527202430267882e-05,
      "loss": 0.0131,
      "step": 4280
    },
    {
      "epoch": 3.5542667771333885,
      "grad_norm": 0.20897988975048065,
      "learning_rate": 1.5260977630488817e-05,
      "loss": 0.0244,
      "step": 4290
    },
    {
      "epoch": 3.5625517812758907,
      "grad_norm": 0.057611558586359024,
      "learning_rate": 1.5249930958298814e-05,
      "loss": 0.0266,
      "step": 4300
    },
    {
      "epoch": 3.5708367854183924,
      "grad_norm": 0.8721708059310913,
      "learning_rate": 1.523888428610881e-05,
      "loss": 0.0098,
      "step": 4310
    },
    {
      "epoch": 3.5791217895608947,
      "grad_norm": 1.4842013120651245,
      "learning_rate": 1.5227837613918807e-05,
      "loss": 0.0393,
      "step": 4320
    },
    {
      "epoch": 3.587406793703397,
      "grad_norm": 6.058824062347412,
      "learning_rate": 1.5216790941728806e-05,
      "loss": 0.0153,
      "step": 4330
    },
    {
      "epoch": 3.595691797845899,
      "grad_norm": 0.039489030838012695,
      "learning_rate": 1.5205744269538802e-05,
      "loss": 0.048,
      "step": 4340
    },
    {
      "epoch": 3.603976801988401,
      "grad_norm": 0.007960611023008823,
      "learning_rate": 1.51946975973488e-05,
      "loss": 0.0183,
      "step": 4350
    },
    {
      "epoch": 3.612261806130903,
      "grad_norm": 0.05676499754190445,
      "learning_rate": 1.5183650925158797e-05,
      "loss": 0.0066,
      "step": 4360
    },
    {
      "epoch": 3.6205468102734053,
      "grad_norm": 0.01950938068330288,
      "learning_rate": 1.5172604252968794e-05,
      "loss": 0.007,
      "step": 4370
    },
    {
      "epoch": 3.628831814415907,
      "grad_norm": 1.1471751928329468,
      "learning_rate": 1.5161557580778792e-05,
      "loss": 0.0219,
      "step": 4380
    },
    {
      "epoch": 3.6371168185584093,
      "grad_norm": 4.748904705047607,
      "learning_rate": 1.5150510908588789e-05,
      "loss": 0.0159,
      "step": 4390
    },
    {
      "epoch": 3.6454018227009115,
      "grad_norm": 9.96557903289795,
      "learning_rate": 1.5139464236398787e-05,
      "loss": 0.0211,
      "step": 4400
    },
    {
      "epoch": 3.6536868268434133,
      "grad_norm": 1.9623230695724487,
      "learning_rate": 1.5128417564208784e-05,
      "loss": 0.0165,
      "step": 4410
    },
    {
      "epoch": 3.6619718309859155,
      "grad_norm": 8.64255142211914,
      "learning_rate": 1.511737089201878e-05,
      "loss": 0.0083,
      "step": 4420
    },
    {
      "epoch": 3.6702568351284177,
      "grad_norm": 0.303642213344574,
      "learning_rate": 1.5106324219828779e-05,
      "loss": 0.0298,
      "step": 4430
    },
    {
      "epoch": 3.6785418392709195,
      "grad_norm": 1.6159838438034058,
      "learning_rate": 1.5095277547638776e-05,
      "loss": 0.0074,
      "step": 4440
    },
    {
      "epoch": 3.6868268434134217,
      "grad_norm": 0.003408064367249608,
      "learning_rate": 1.5084230875448774e-05,
      "loss": 0.0011,
      "step": 4450
    },
    {
      "epoch": 3.695111847555924,
      "grad_norm": 0.020481489598751068,
      "learning_rate": 1.507318420325877e-05,
      "loss": 0.0027,
      "step": 4460
    },
    {
      "epoch": 3.7033968516984257,
      "grad_norm": 1.6160868406295776,
      "learning_rate": 1.5062137531068767e-05,
      "loss": 0.0181,
      "step": 4470
    },
    {
      "epoch": 3.711681855840928,
      "grad_norm": 0.07763705402612686,
      "learning_rate": 1.5051090858878762e-05,
      "loss": 0.0027,
      "step": 4480
    },
    {
      "epoch": 3.71996685998343,
      "grad_norm": 0.20016224682331085,
      "learning_rate": 1.504004418668876e-05,
      "loss": 0.0286,
      "step": 4490
    },
    {
      "epoch": 3.728251864125932,
      "grad_norm": 0.03340291976928711,
      "learning_rate": 1.5028997514498757e-05,
      "loss": 0.0527,
      "step": 4500
    },
    {
      "epoch": 3.736536868268434,
      "grad_norm": 1.6455193758010864,
      "learning_rate": 1.5017950842308756e-05,
      "loss": 0.0207,
      "step": 4510
    },
    {
      "epoch": 3.7448218724109363,
      "grad_norm": 1.4688372611999512,
      "learning_rate": 1.5006904170118752e-05,
      "loss": 0.0132,
      "step": 4520
    },
    {
      "epoch": 3.7531068765534386,
      "grad_norm": 1.2851086854934692,
      "learning_rate": 1.4995857497928749e-05,
      "loss": 0.0117,
      "step": 4530
    },
    {
      "epoch": 3.7613918806959403,
      "grad_norm": 0.458810031414032,
      "learning_rate": 1.4984810825738747e-05,
      "loss": 0.0435,
      "step": 4540
    },
    {
      "epoch": 3.7696768848384425,
      "grad_norm": 0.004485069774091244,
      "learning_rate": 1.4973764153548744e-05,
      "loss": 0.0311,
      "step": 4550
    },
    {
      "epoch": 3.7779618889809443,
      "grad_norm": 1.3668856620788574,
      "learning_rate": 1.4962717481358742e-05,
      "loss": 0.0509,
      "step": 4560
    },
    {
      "epoch": 3.7862468931234465,
      "grad_norm": 0.06982897222042084,
      "learning_rate": 1.4951670809168739e-05,
      "loss": 0.0158,
      "step": 4570
    },
    {
      "epoch": 3.7945318972659487,
      "grad_norm": 0.033169250935316086,
      "learning_rate": 1.4940624136978736e-05,
      "loss": 0.0241,
      "step": 4580
    },
    {
      "epoch": 3.802816901408451,
      "grad_norm": 0.3532473146915436,
      "learning_rate": 1.4929577464788734e-05,
      "loss": 0.0137,
      "step": 4590
    },
    {
      "epoch": 3.8111019055509527,
      "grad_norm": 0.0035663607995957136,
      "learning_rate": 1.491853079259873e-05,
      "loss": 0.0072,
      "step": 4600
    },
    {
      "epoch": 3.819386909693455,
      "grad_norm": 1.5707401037216187,
      "learning_rate": 1.4907484120408729e-05,
      "loss": 0.0409,
      "step": 4610
    },
    {
      "epoch": 3.8276719138359567,
      "grad_norm": 0.03985465690493584,
      "learning_rate": 1.4896437448218726e-05,
      "loss": 0.0554,
      "step": 4620
    },
    {
      "epoch": 3.835956917978459,
      "grad_norm": 0.056228965520858765,
      "learning_rate": 1.4885390776028722e-05,
      "loss": 0.0522,
      "step": 4630
    },
    {
      "epoch": 3.844241922120961,
      "grad_norm": 6.954285144805908,
      "learning_rate": 1.487434410383872e-05,
      "loss": 0.0252,
      "step": 4640
    },
    {
      "epoch": 3.8525269262634634,
      "grad_norm": 0.05941278114914894,
      "learning_rate": 1.4863297431648717e-05,
      "loss": 0.0082,
      "step": 4650
    },
    {
      "epoch": 3.860811930405965,
      "grad_norm": 0.012582371942698956,
      "learning_rate": 1.4852250759458716e-05,
      "loss": 0.0041,
      "step": 4660
    },
    {
      "epoch": 3.8690969345484674,
      "grad_norm": 7.055722236633301,
      "learning_rate": 1.4841204087268712e-05,
      "loss": 0.029,
      "step": 4670
    },
    {
      "epoch": 3.877381938690969,
      "grad_norm": 0.004477978218346834,
      "learning_rate": 1.4830157415078709e-05,
      "loss": 0.0055,
      "step": 4680
    },
    {
      "epoch": 3.8856669428334714,
      "grad_norm": 0.048649903386831284,
      "learning_rate": 1.4819110742888706e-05,
      "loss": 0.0049,
      "step": 4690
    },
    {
      "epoch": 3.8939519469759736,
      "grad_norm": 2.4811503887176514,
      "learning_rate": 1.4808064070698702e-05,
      "loss": 0.0194,
      "step": 4700
    },
    {
      "epoch": 3.902236951118476,
      "grad_norm": 0.11164901405572891,
      "learning_rate": 1.4797017398508699e-05,
      "loss": 0.006,
      "step": 4710
    },
    {
      "epoch": 3.9105219552609776,
      "grad_norm": 0.36227312684059143,
      "learning_rate": 1.4785970726318697e-05,
      "loss": 0.02,
      "step": 4720
    },
    {
      "epoch": 3.91880695940348,
      "grad_norm": 0.01785099506378174,
      "learning_rate": 1.4774924054128694e-05,
      "loss": 0.0337,
      "step": 4730
    },
    {
      "epoch": 3.9270919635459816,
      "grad_norm": 0.05342938378453255,
      "learning_rate": 1.4763877381938692e-05,
      "loss": 0.0235,
      "step": 4740
    },
    {
      "epoch": 3.9353769676884838,
      "grad_norm": 1.3333148956298828,
      "learning_rate": 1.4752830709748689e-05,
      "loss": 0.031,
      "step": 4750
    },
    {
      "epoch": 3.943661971830986,
      "grad_norm": 0.032995495945215225,
      "learning_rate": 1.4741784037558686e-05,
      "loss": 0.0188,
      "step": 4760
    },
    {
      "epoch": 3.951946975973488,
      "grad_norm": 0.03696264699101448,
      "learning_rate": 1.4730737365368684e-05,
      "loss": 0.0163,
      "step": 4770
    },
    {
      "epoch": 3.96023198011599,
      "grad_norm": 0.040316808968782425,
      "learning_rate": 1.471969069317868e-05,
      "loss": 0.0273,
      "step": 4780
    },
    {
      "epoch": 3.968516984258492,
      "grad_norm": 2.6499688625335693,
      "learning_rate": 1.4708644020988679e-05,
      "loss": 0.0338,
      "step": 4790
    },
    {
      "epoch": 3.976801988400994,
      "grad_norm": 0.015111645683646202,
      "learning_rate": 1.4697597348798676e-05,
      "loss": 0.0405,
      "step": 4800
    },
    {
      "epoch": 3.985086992543496,
      "grad_norm": 0.9680711627006531,
      "learning_rate": 1.4686550676608672e-05,
      "loss": 0.031,
      "step": 4810
    },
    {
      "epoch": 3.9933719966859984,
      "grad_norm": 0.5594142079353333,
      "learning_rate": 1.467550400441867e-05,
      "loss": 0.0097,
      "step": 4820
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9912959381044487,
      "eval_f1": 0.9510869565217391,
      "eval_loss": 0.027355926111340523,
      "eval_precision": 0.9762900976290098,
      "eval_recall": 0.9271523178807947,
      "eval_runtime": 1602.1739,
      "eval_samples_per_second": 5.166,
      "eval_steps_per_second": 0.646,
      "step": 4828
    },
    {
      "epoch": 4.001657000828501,
      "grad_norm": 0.03663191571831703,
      "learning_rate": 1.4664457332228667e-05,
      "loss": 0.0004,
      "step": 4830
    },
    {
      "epoch": 4.009942004971003,
      "grad_norm": 0.504006028175354,
      "learning_rate": 1.4653410660038666e-05,
      "loss": 0.0013,
      "step": 4840
    },
    {
      "epoch": 4.018227009113504,
      "grad_norm": 0.011006657965481281,
      "learning_rate": 1.4642363987848662e-05,
      "loss": 0.0521,
      "step": 4850
    },
    {
      "epoch": 4.026512013256006,
      "grad_norm": 0.06170528382062912,
      "learning_rate": 1.4631317315658659e-05,
      "loss": 0.0267,
      "step": 4860
    },
    {
      "epoch": 4.034797017398509,
      "grad_norm": 6.2259135246276855,
      "learning_rate": 1.4620270643468657e-05,
      "loss": 0.0106,
      "step": 4870
    },
    {
      "epoch": 4.043082021541011,
      "grad_norm": 0.05379904806613922,
      "learning_rate": 1.4609223971278654e-05,
      "loss": 0.0076,
      "step": 4880
    },
    {
      "epoch": 4.051367025683513,
      "grad_norm": 0.0023926643189042807,
      "learning_rate": 1.4598177299088652e-05,
      "loss": 0.0158,
      "step": 4890
    },
    {
      "epoch": 4.059652029826015,
      "grad_norm": 0.00538167217746377,
      "learning_rate": 1.4587130626898649e-05,
      "loss": 0.0047,
      "step": 4900
    },
    {
      "epoch": 4.067937033968517,
      "grad_norm": 0.08812814205884933,
      "learning_rate": 1.4576083954708644e-05,
      "loss": 0.0137,
      "step": 4910
    },
    {
      "epoch": 4.076222038111019,
      "grad_norm": 0.03684037923812866,
      "learning_rate": 1.456503728251864e-05,
      "loss": 0.0136,
      "step": 4920
    },
    {
      "epoch": 4.084507042253521,
      "grad_norm": 0.013421411626040936,
      "learning_rate": 1.4553990610328639e-05,
      "loss": 0.014,
      "step": 4930
    },
    {
      "epoch": 4.092792046396023,
      "grad_norm": 0.026337075978517532,
      "learning_rate": 1.4542943938138636e-05,
      "loss": 0.0369,
      "step": 4940
    },
    {
      "epoch": 4.1010770505385254,
      "grad_norm": 0.08680639415979385,
      "learning_rate": 1.4531897265948634e-05,
      "loss": 0.036,
      "step": 4950
    },
    {
      "epoch": 4.109362054681028,
      "grad_norm": 0.008183727972209454,
      "learning_rate": 1.452085059375863e-05,
      "loss": 0.0101,
      "step": 4960
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.027937617152929306,
      "learning_rate": 1.4509803921568629e-05,
      "loss": 0.0055,
      "step": 4970
    },
    {
      "epoch": 4.125932062966031,
      "grad_norm": 0.05898706987500191,
      "learning_rate": 1.4498757249378626e-05,
      "loss": 0.0133,
      "step": 4980
    },
    {
      "epoch": 4.134217067108533,
      "grad_norm": 0.9199988842010498,
      "learning_rate": 1.4487710577188622e-05,
      "loss": 0.0671,
      "step": 4990
    },
    {
      "epoch": 4.142502071251036,
      "grad_norm": 0.013893171213567257,
      "learning_rate": 1.447666390499862e-05,
      "loss": 0.0198,
      "step": 5000
    },
    {
      "epoch": 4.150787075393538,
      "grad_norm": 0.04408414661884308,
      "learning_rate": 1.4465617232808617e-05,
      "loss": 0.0021,
      "step": 5010
    },
    {
      "epoch": 4.15907207953604,
      "grad_norm": 0.01324773021042347,
      "learning_rate": 1.4454570560618616e-05,
      "loss": 0.0269,
      "step": 5020
    },
    {
      "epoch": 4.167357083678542,
      "grad_norm": 2.7832610607147217,
      "learning_rate": 1.4443523888428612e-05,
      "loss": 0.022,
      "step": 5030
    },
    {
      "epoch": 4.175642087821044,
      "grad_norm": 0.038652434945106506,
      "learning_rate": 1.4432477216238609e-05,
      "loss": 0.0004,
      "step": 5040
    },
    {
      "epoch": 4.183927091963546,
      "grad_norm": 0.7828264832496643,
      "learning_rate": 1.4421430544048607e-05,
      "loss": 0.0165,
      "step": 5050
    },
    {
      "epoch": 4.192212096106048,
      "grad_norm": 0.19054310023784637,
      "learning_rate": 1.4410383871858604e-05,
      "loss": 0.0048,
      "step": 5060
    },
    {
      "epoch": 4.20049710024855,
      "grad_norm": 0.3600989878177643,
      "learning_rate": 1.4399337199668602e-05,
      "loss": 0.0266,
      "step": 5070
    },
    {
      "epoch": 4.2087821043910525,
      "grad_norm": 0.00391694251447916,
      "learning_rate": 1.4388290527478599e-05,
      "loss": 0.0108,
      "step": 5080
    },
    {
      "epoch": 4.217067108533554,
      "grad_norm": 2.1821041107177734,
      "learning_rate": 1.4377243855288596e-05,
      "loss": 0.011,
      "step": 5090
    },
    {
      "epoch": 4.225352112676056,
      "grad_norm": 9.140658378601074,
      "learning_rate": 1.4366197183098594e-05,
      "loss": 0.0383,
      "step": 5100
    },
    {
      "epoch": 4.233637116818558,
      "grad_norm": 2.764561414718628,
      "learning_rate": 1.435515051090859e-05,
      "loss": 0.0377,
      "step": 5110
    },
    {
      "epoch": 4.2419221209610605,
      "grad_norm": 0.007838568650186062,
      "learning_rate": 1.4344103838718589e-05,
      "loss": 0.0005,
      "step": 5120
    },
    {
      "epoch": 4.250207125103563,
      "grad_norm": 0.05151573196053505,
      "learning_rate": 1.4333057166528584e-05,
      "loss": 0.0079,
      "step": 5130
    },
    {
      "epoch": 4.258492129246065,
      "grad_norm": 2.875231981277466,
      "learning_rate": 1.432201049433858e-05,
      "loss": 0.0198,
      "step": 5140
    },
    {
      "epoch": 4.266777133388567,
      "grad_norm": 0.6583256721496582,
      "learning_rate": 1.4310963822148577e-05,
      "loss": 0.0444,
      "step": 5150
    },
    {
      "epoch": 4.2750621375310685,
      "grad_norm": 0.021569903939962387,
      "learning_rate": 1.4299917149958576e-05,
      "loss": 0.0247,
      "step": 5160
    },
    {
      "epoch": 4.283347141673571,
      "grad_norm": 3.066228151321411,
      "learning_rate": 1.4288870477768572e-05,
      "loss": 0.032,
      "step": 5170
    },
    {
      "epoch": 4.291632145816073,
      "grad_norm": 0.006013619247823954,
      "learning_rate": 1.427782380557857e-05,
      "loss": 0.0071,
      "step": 5180
    },
    {
      "epoch": 4.299917149958575,
      "grad_norm": 8.065308570861816,
      "learning_rate": 1.4266777133388567e-05,
      "loss": 0.0183,
      "step": 5190
    },
    {
      "epoch": 4.308202154101077,
      "grad_norm": 0.08137563616037369,
      "learning_rate": 1.4255730461198564e-05,
      "loss": 0.0113,
      "step": 5200
    },
    {
      "epoch": 4.3164871582435795,
      "grad_norm": 0.13726933300495148,
      "learning_rate": 1.4244683789008562e-05,
      "loss": 0.0086,
      "step": 5210
    },
    {
      "epoch": 4.324772162386081,
      "grad_norm": 0.01169488113373518,
      "learning_rate": 1.4233637116818559e-05,
      "loss": 0.0031,
      "step": 5220
    },
    {
      "epoch": 4.333057166528583,
      "grad_norm": 0.003349937265738845,
      "learning_rate": 1.4222590444628557e-05,
      "loss": 0.0007,
      "step": 5230
    },
    {
      "epoch": 4.341342170671085,
      "grad_norm": 0.033418431878089905,
      "learning_rate": 1.4211543772438554e-05,
      "loss": 0.0087,
      "step": 5240
    },
    {
      "epoch": 4.3496271748135875,
      "grad_norm": 3.6226158142089844,
      "learning_rate": 1.420049710024855e-05,
      "loss": 0.0648,
      "step": 5250
    },
    {
      "epoch": 4.35791217895609,
      "grad_norm": 0.2192496359348297,
      "learning_rate": 1.4189450428058549e-05,
      "loss": 0.0015,
      "step": 5260
    },
    {
      "epoch": 4.366197183098592,
      "grad_norm": 1.701759696006775,
      "learning_rate": 1.4178403755868546e-05,
      "loss": 0.0092,
      "step": 5270
    },
    {
      "epoch": 4.374482187241093,
      "grad_norm": 0.045949675142765045,
      "learning_rate": 1.4167357083678544e-05,
      "loss": 0.0211,
      "step": 5280
    },
    {
      "epoch": 4.3827671913835955,
      "grad_norm": 7.9612860679626465,
      "learning_rate": 1.415631041148854e-05,
      "loss": 0.0156,
      "step": 5290
    },
    {
      "epoch": 4.391052195526098,
      "grad_norm": 0.024265900254249573,
      "learning_rate": 1.4145263739298537e-05,
      "loss": 0.0227,
      "step": 5300
    },
    {
      "epoch": 4.3993371996686,
      "grad_norm": 3.0408711433410645,
      "learning_rate": 1.4134217067108536e-05,
      "loss": 0.0209,
      "step": 5310
    },
    {
      "epoch": 4.407622203811102,
      "grad_norm": 0.00731175672262907,
      "learning_rate": 1.4123170394918532e-05,
      "loss": 0.0102,
      "step": 5320
    },
    {
      "epoch": 4.415907207953604,
      "grad_norm": 0.01060243509709835,
      "learning_rate": 1.411212372272853e-05,
      "loss": 0.0149,
      "step": 5330
    },
    {
      "epoch": 4.424192212096106,
      "grad_norm": 3.515143394470215,
      "learning_rate": 1.4101077050538527e-05,
      "loss": 0.038,
      "step": 5340
    },
    {
      "epoch": 4.432477216238608,
      "grad_norm": 0.4557549059391022,
      "learning_rate": 1.4090030378348522e-05,
      "loss": 0.0039,
      "step": 5350
    },
    {
      "epoch": 4.44076222038111,
      "grad_norm": 0.005229966249316931,
      "learning_rate": 1.407898370615852e-05,
      "loss": 0.0029,
      "step": 5360
    },
    {
      "epoch": 4.449047224523612,
      "grad_norm": 0.012975634075701237,
      "learning_rate": 1.4067937033968517e-05,
      "loss": 0.0156,
      "step": 5370
    },
    {
      "epoch": 4.457332228666115,
      "grad_norm": 0.21628133952617645,
      "learning_rate": 1.4056890361778514e-05,
      "loss": 0.0393,
      "step": 5380
    },
    {
      "epoch": 4.465617232808617,
      "grad_norm": 0.474282443523407,
      "learning_rate": 1.4045843689588512e-05,
      "loss": 0.014,
      "step": 5390
    },
    {
      "epoch": 4.473902236951118,
      "grad_norm": 0.006783296819776297,
      "learning_rate": 1.4034797017398509e-05,
      "loss": 0.0243,
      "step": 5400
    },
    {
      "epoch": 4.48218724109362,
      "grad_norm": 3.257739782333374,
      "learning_rate": 1.4023750345208507e-05,
      "loss": 0.0138,
      "step": 5410
    },
    {
      "epoch": 4.4904722452361225,
      "grad_norm": 0.00434902124106884,
      "learning_rate": 1.4012703673018504e-05,
      "loss": 0.0111,
      "step": 5420
    },
    {
      "epoch": 4.498757249378625,
      "grad_norm": 0.003636216279119253,
      "learning_rate": 1.40016570008285e-05,
      "loss": 0.0163,
      "step": 5430
    },
    {
      "epoch": 4.507042253521127,
      "grad_norm": 0.07455780357122421,
      "learning_rate": 1.3990610328638499e-05,
      "loss": 0.0064,
      "step": 5440
    },
    {
      "epoch": 4.515327257663629,
      "grad_norm": 0.016702929511666298,
      "learning_rate": 1.3979563656448496e-05,
      "loss": 0.0044,
      "step": 5450
    },
    {
      "epoch": 4.5236122618061305,
      "grad_norm": 0.001376958331093192,
      "learning_rate": 1.3968516984258494e-05,
      "loss": 0.0146,
      "step": 5460
    },
    {
      "epoch": 4.531897265948633,
      "grad_norm": 0.031103450804948807,
      "learning_rate": 1.395747031206849e-05,
      "loss": 0.0273,
      "step": 5470
    },
    {
      "epoch": 4.540182270091135,
      "grad_norm": 0.0048693581484258175,
      "learning_rate": 1.3946423639878487e-05,
      "loss": 0.024,
      "step": 5480
    },
    {
      "epoch": 4.548467274233637,
      "grad_norm": 1.059967279434204,
      "learning_rate": 1.3935376967688486e-05,
      "loss": 0.0392,
      "step": 5490
    },
    {
      "epoch": 4.556752278376139,
      "grad_norm": 0.006077297497540712,
      "learning_rate": 1.3924330295498482e-05,
      "loss": 0.016,
      "step": 5500
    },
    {
      "epoch": 4.565037282518642,
      "grad_norm": 0.004451119806617498,
      "learning_rate": 1.391328362330848e-05,
      "loss": 0.0098,
      "step": 5510
    },
    {
      "epoch": 4.573322286661144,
      "grad_norm": 0.07361747324466705,
      "learning_rate": 1.3902236951118477e-05,
      "loss": 0.0057,
      "step": 5520
    },
    {
      "epoch": 4.581607290803645,
      "grad_norm": 0.0035993449855595827,
      "learning_rate": 1.3891190278928474e-05,
      "loss": 0.0198,
      "step": 5530
    },
    {
      "epoch": 4.589892294946147,
      "grad_norm": 0.01591658964753151,
      "learning_rate": 1.3880143606738472e-05,
      "loss": 0.0048,
      "step": 5540
    },
    {
      "epoch": 4.59817729908865,
      "grad_norm": 0.023173552006483078,
      "learning_rate": 1.3869096934548469e-05,
      "loss": 0.0022,
      "step": 5550
    },
    {
      "epoch": 4.606462303231152,
      "grad_norm": 0.015898969024419785,
      "learning_rate": 1.3858050262358467e-05,
      "loss": 0.0086,
      "step": 5560
    },
    {
      "epoch": 4.614747307373654,
      "grad_norm": 0.0060588703490793705,
      "learning_rate": 1.3847003590168462e-05,
      "loss": 0.0359,
      "step": 5570
    },
    {
      "epoch": 4.623032311516155,
      "grad_norm": 0.8230471611022949,
      "learning_rate": 1.3835956917978459e-05,
      "loss": 0.034,
      "step": 5580
    },
    {
      "epoch": 4.631317315658658,
      "grad_norm": 0.7904737591743469,
      "learning_rate": 1.3824910245788456e-05,
      "loss": 0.0177,
      "step": 5590
    },
    {
      "epoch": 4.63960231980116,
      "grad_norm": 2.0562374591827393,
      "learning_rate": 1.3813863573598454e-05,
      "loss": 0.0136,
      "step": 5600
    },
    {
      "epoch": 4.647887323943662,
      "grad_norm": 1.4835667610168457,
      "learning_rate": 1.380281690140845e-05,
      "loss": 0.0151,
      "step": 5610
    },
    {
      "epoch": 4.656172328086164,
      "grad_norm": 0.009511752054095268,
      "learning_rate": 1.3791770229218449e-05,
      "loss": 0.009,
      "step": 5620
    },
    {
      "epoch": 4.664457332228666,
      "grad_norm": 0.004171891137957573,
      "learning_rate": 1.3780723557028446e-05,
      "loss": 0.0005,
      "step": 5630
    },
    {
      "epoch": 4.672742336371169,
      "grad_norm": 3.5780818462371826,
      "learning_rate": 1.3769676884838442e-05,
      "loss": 0.0271,
      "step": 5640
    },
    {
      "epoch": 4.68102734051367,
      "grad_norm": 1.2177274227142334,
      "learning_rate": 1.375863021264844e-05,
      "loss": 0.019,
      "step": 5650
    },
    {
      "epoch": 4.689312344656172,
      "grad_norm": 0.07966155558824539,
      "learning_rate": 1.3747583540458437e-05,
      "loss": 0.0039,
      "step": 5660
    },
    {
      "epoch": 4.697597348798674,
      "grad_norm": 0.03488834947347641,
      "learning_rate": 1.3736536868268436e-05,
      "loss": 0.023,
      "step": 5670
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 1.0334851741790771,
      "learning_rate": 1.3725490196078432e-05,
      "loss": 0.0013,
      "step": 5680
    },
    {
      "epoch": 4.714167357083679,
      "grad_norm": 0.004576990380883217,
      "learning_rate": 1.3714443523888429e-05,
      "loss": 0.0096,
      "step": 5690
    },
    {
      "epoch": 4.72245236122618,
      "grad_norm": 5.882516860961914,
      "learning_rate": 1.3703396851698427e-05,
      "loss": 0.0201,
      "step": 5700
    },
    {
      "epoch": 4.730737365368682,
      "grad_norm": 0.0875043123960495,
      "learning_rate": 1.3692350179508424e-05,
      "loss": 0.0198,
      "step": 5710
    },
    {
      "epoch": 4.739022369511185,
      "grad_norm": 2.3368124961853027,
      "learning_rate": 1.3681303507318422e-05,
      "loss": 0.0424,
      "step": 5720
    },
    {
      "epoch": 4.747307373653687,
      "grad_norm": 0.007281435187906027,
      "learning_rate": 1.3670256835128419e-05,
      "loss": 0.0064,
      "step": 5730
    },
    {
      "epoch": 4.755592377796189,
      "grad_norm": 0.2320936620235443,
      "learning_rate": 1.3659210162938417e-05,
      "loss": 0.0089,
      "step": 5740
    },
    {
      "epoch": 4.763877381938691,
      "grad_norm": 0.045994833111763,
      "learning_rate": 1.3648163490748414e-05,
      "loss": 0.0077,
      "step": 5750
    },
    {
      "epoch": 4.7721623860811935,
      "grad_norm": 0.004791093524545431,
      "learning_rate": 1.363711681855841e-05,
      "loss": 0.0054,
      "step": 5760
    },
    {
      "epoch": 4.780447390223695,
      "grad_norm": 0.29531654715538025,
      "learning_rate": 1.3626070146368409e-05,
      "loss": 0.0389,
      "step": 5770
    },
    {
      "epoch": 4.788732394366197,
      "grad_norm": 0.0035380986519157887,
      "learning_rate": 1.3615023474178406e-05,
      "loss": 0.0008,
      "step": 5780
    },
    {
      "epoch": 4.797017398508699,
      "grad_norm": 0.17488080263137817,
      "learning_rate": 1.36039768019884e-05,
      "loss": 0.0259,
      "step": 5790
    },
    {
      "epoch": 4.8053024026512015,
      "grad_norm": 5.075324058532715,
      "learning_rate": 1.3592930129798399e-05,
      "loss": 0.0192,
      "step": 5800
    },
    {
      "epoch": 4.813587406793704,
      "grad_norm": 0.23069874942302704,
      "learning_rate": 1.3581883457608396e-05,
      "loss": 0.0157,
      "step": 5810
    },
    {
      "epoch": 4.821872410936205,
      "grad_norm": 0.002114021684974432,
      "learning_rate": 1.3570836785418392e-05,
      "loss": 0.0303,
      "step": 5820
    },
    {
      "epoch": 4.830157415078707,
      "grad_norm": 0.29769137501716614,
      "learning_rate": 1.355979011322839e-05,
      "loss": 0.0188,
      "step": 5830
    },
    {
      "epoch": 4.838442419221209,
      "grad_norm": 15.993078231811523,
      "learning_rate": 1.3548743441038387e-05,
      "loss": 0.0554,
      "step": 5840
    },
    {
      "epoch": 4.846727423363712,
      "grad_norm": 0.04511521756649017,
      "learning_rate": 1.3537696768848386e-05,
      "loss": 0.0035,
      "step": 5850
    },
    {
      "epoch": 4.855012427506214,
      "grad_norm": 0.011709078215062618,
      "learning_rate": 1.3526650096658382e-05,
      "loss": 0.0281,
      "step": 5860
    },
    {
      "epoch": 4.863297431648716,
      "grad_norm": 0.011101768352091312,
      "learning_rate": 1.3515603424468379e-05,
      "loss": 0.0179,
      "step": 5870
    },
    {
      "epoch": 4.871582435791218,
      "grad_norm": 0.006218323018401861,
      "learning_rate": 1.3504556752278377e-05,
      "loss": 0.0241,
      "step": 5880
    },
    {
      "epoch": 4.87986743993372,
      "grad_norm": 0.036034148186445236,
      "learning_rate": 1.3493510080088374e-05,
      "loss": 0.0155,
      "step": 5890
    },
    {
      "epoch": 4.888152444076222,
      "grad_norm": 0.003232588991522789,
      "learning_rate": 1.3482463407898372e-05,
      "loss": 0.0019,
      "step": 5900
    },
    {
      "epoch": 4.896437448218724,
      "grad_norm": 2.364365816116333,
      "learning_rate": 1.3471416735708369e-05,
      "loss": 0.0323,
      "step": 5910
    },
    {
      "epoch": 4.904722452361226,
      "grad_norm": 0.08208910375833511,
      "learning_rate": 1.3460370063518366e-05,
      "loss": 0.0072,
      "step": 5920
    },
    {
      "epoch": 4.9130074565037285,
      "grad_norm": 0.009573351591825485,
      "learning_rate": 1.3449323391328364e-05,
      "loss": 0.0099,
      "step": 5930
    },
    {
      "epoch": 4.92129246064623,
      "grad_norm": 2.8121676445007324,
      "learning_rate": 1.343827671913836e-05,
      "loss": 0.0475,
      "step": 5940
    },
    {
      "epoch": 4.929577464788732,
      "grad_norm": 0.003101687179878354,
      "learning_rate": 1.342723004694836e-05,
      "loss": 0.0002,
      "step": 5950
    },
    {
      "epoch": 4.937862468931234,
      "grad_norm": 0.002572912722826004,
      "learning_rate": 1.3416183374758356e-05,
      "loss": 0.0137,
      "step": 5960
    },
    {
      "epoch": 4.9461474730737365,
      "grad_norm": 0.001647060620598495,
      "learning_rate": 1.3405136702568352e-05,
      "loss": 0.0353,
      "step": 5970
    },
    {
      "epoch": 4.954432477216239,
      "grad_norm": 0.0024338506627827883,
      "learning_rate": 1.339409003037835e-05,
      "loss": 0.0428,
      "step": 5980
    },
    {
      "epoch": 4.962717481358741,
      "grad_norm": 0.020288292318582535,
      "learning_rate": 1.3383043358188347e-05,
      "loss": 0.0257,
      "step": 5990
    },
    {
      "epoch": 4.971002485501243,
      "grad_norm": 0.6139925718307495,
      "learning_rate": 1.3371996685998342e-05,
      "loss": 0.003,
      "step": 6000
    },
    {
      "epoch": 4.9792874896437445,
      "grad_norm": 0.32022625207901,
      "learning_rate": 1.336095001380834e-05,
      "loss": 0.0061,
      "step": 6010
    },
    {
      "epoch": 4.987572493786247,
      "grad_norm": 0.0016817504074424505,
      "learning_rate": 1.3349903341618337e-05,
      "loss": 0.0126,
      "step": 6020
    },
    {
      "epoch": 4.995857497928749,
      "grad_norm": 0.04165281355381012,
      "learning_rate": 1.3338856669428336e-05,
      "loss": 0.0172,
      "step": 6030
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.991779497098646,
      "eval_f1": 0.9539918809201624,
      "eval_loss": 0.03255438059568405,
      "eval_precision": 0.975103734439834,
      "eval_recall": 0.9337748344370861,
      "eval_runtime": 1585.7209,
      "eval_samples_per_second": 5.22,
      "eval_steps_per_second": 0.653,
      "step": 6035
    },
    {
      "epoch": 5.004142502071251,
      "grad_norm": 0.8459243774414062,
      "learning_rate": 1.3327809997238332e-05,
      "loss": 0.0113,
      "step": 6040
    },
    {
      "epoch": 5.012427506213753,
      "grad_norm": 0.7758604884147644,
      "learning_rate": 1.3316763325048329e-05,
      "loss": 0.0294,
      "step": 6050
    },
    {
      "epoch": 5.0207125103562555,
      "grad_norm": 0.006826395634561777,
      "learning_rate": 1.3305716652858327e-05,
      "loss": 0.0003,
      "step": 6060
    },
    {
      "epoch": 5.028997514498757,
      "grad_norm": 0.01772291027009487,
      "learning_rate": 1.3294669980668324e-05,
      "loss": 0.0007,
      "step": 6070
    },
    {
      "epoch": 5.037282518641259,
      "grad_norm": 0.05290769785642624,
      "learning_rate": 1.3283623308478322e-05,
      "loss": 0.0014,
      "step": 6080
    },
    {
      "epoch": 5.045567522783761,
      "grad_norm": 0.0609092190861702,
      "learning_rate": 1.3272576636288319e-05,
      "loss": 0.0088,
      "step": 6090
    },
    {
      "epoch": 5.0538525269262635,
      "grad_norm": 9.552888870239258,
      "learning_rate": 1.3261529964098316e-05,
      "loss": 0.0071,
      "step": 6100
    },
    {
      "epoch": 5.062137531068766,
      "grad_norm": 0.006266433745622635,
      "learning_rate": 1.3250483291908314e-05,
      "loss": 0.0448,
      "step": 6110
    },
    {
      "epoch": 5.070422535211268,
      "grad_norm": 0.018515560775995255,
      "learning_rate": 1.323943661971831e-05,
      "loss": 0.0062,
      "step": 6120
    },
    {
      "epoch": 5.078707539353769,
      "grad_norm": 0.014883969910442829,
      "learning_rate": 1.322838994752831e-05,
      "loss": 0.0214,
      "step": 6130
    },
    {
      "epoch": 5.0869925434962715,
      "grad_norm": 0.5570080876350403,
      "learning_rate": 1.3217343275338306e-05,
      "loss": 0.0217,
      "step": 6140
    },
    {
      "epoch": 5.095277547638774,
      "grad_norm": 0.008592518977820873,
      "learning_rate": 1.3206296603148302e-05,
      "loss": 0.0236,
      "step": 6150
    },
    {
      "epoch": 5.103562551781276,
      "grad_norm": 0.04735369235277176,
      "learning_rate": 1.31952499309583e-05,
      "loss": 0.0142,
      "step": 6160
    },
    {
      "epoch": 5.111847555923778,
      "grad_norm": 4.442836761474609,
      "learning_rate": 1.3184203258768298e-05,
      "loss": 0.0497,
      "step": 6170
    },
    {
      "epoch": 5.12013256006628,
      "grad_norm": 0.39688095450401306,
      "learning_rate": 1.3173156586578296e-05,
      "loss": 0.0134,
      "step": 6180
    },
    {
      "epoch": 5.128417564208782,
      "grad_norm": 0.2633598744869232,
      "learning_rate": 1.3162109914388293e-05,
      "loss": 0.0021,
      "step": 6190
    },
    {
      "epoch": 5.136702568351284,
      "grad_norm": 0.9672006964683533,
      "learning_rate": 1.315106324219829e-05,
      "loss": 0.0158,
      "step": 6200
    },
    {
      "epoch": 5.144987572493786,
      "grad_norm": 0.049242060631513596,
      "learning_rate": 1.3140016570008288e-05,
      "loss": 0.0015,
      "step": 6210
    },
    {
      "epoch": 5.153272576636288,
      "grad_norm": 0.0040589747950434685,
      "learning_rate": 1.3128969897818282e-05,
      "loss": 0.0155,
      "step": 6220
    },
    {
      "epoch": 5.161557580778791,
      "grad_norm": 0.00298105925321579,
      "learning_rate": 1.3117923225628279e-05,
      "loss": 0.0004,
      "step": 6230
    },
    {
      "epoch": 5.169842584921293,
      "grad_norm": 0.0002900681574828923,
      "learning_rate": 1.3106876553438278e-05,
      "loss": 0.0001,
      "step": 6240
    },
    {
      "epoch": 5.178127589063794,
      "grad_norm": 0.0013549748109653592,
      "learning_rate": 1.3095829881248274e-05,
      "loss": 0.0082,
      "step": 6250
    },
    {
      "epoch": 5.186412593206296,
      "grad_norm": 0.006354502867907286,
      "learning_rate": 1.308478320905827e-05,
      "loss": 0.0138,
      "step": 6260
    },
    {
      "epoch": 5.1946975973487985,
      "grad_norm": 0.046200353652238846,
      "learning_rate": 1.307373653686827e-05,
      "loss": 0.0093,
      "step": 6270
    },
    {
      "epoch": 5.202982601491301,
      "grad_norm": 0.010132329538464546,
      "learning_rate": 1.3062689864678266e-05,
      "loss": 0.0152,
      "step": 6280
    },
    {
      "epoch": 5.211267605633803,
      "grad_norm": 0.5920605659484863,
      "learning_rate": 1.3051643192488264e-05,
      "loss": 0.0284,
      "step": 6290
    },
    {
      "epoch": 5.219552609776305,
      "grad_norm": 0.011253055185079575,
      "learning_rate": 1.304059652029826e-05,
      "loss": 0.0247,
      "step": 6300
    },
    {
      "epoch": 5.2278376139188065,
      "grad_norm": 0.01565730758011341,
      "learning_rate": 1.3029549848108258e-05,
      "loss": 0.0138,
      "step": 6310
    },
    {
      "epoch": 5.236122618061309,
      "grad_norm": 0.0031477678567171097,
      "learning_rate": 1.3018503175918256e-05,
      "loss": 0.0134,
      "step": 6320
    },
    {
      "epoch": 5.244407622203811,
      "grad_norm": 2.9611852169036865,
      "learning_rate": 1.3007456503728253e-05,
      "loss": 0.0183,
      "step": 6330
    },
    {
      "epoch": 5.252692626346313,
      "grad_norm": 16.467676162719727,
      "learning_rate": 1.2996409831538251e-05,
      "loss": 0.0446,
      "step": 6340
    },
    {
      "epoch": 5.260977630488815,
      "grad_norm": 0.006929419934749603,
      "learning_rate": 1.2985363159348248e-05,
      "loss": 0.0018,
      "step": 6350
    },
    {
      "epoch": 5.269262634631318,
      "grad_norm": 0.07648176699876785,
      "learning_rate": 1.2974316487158244e-05,
      "loss": 0.0005,
      "step": 6360
    },
    {
      "epoch": 5.27754763877382,
      "grad_norm": 0.004760177806019783,
      "learning_rate": 1.2963269814968243e-05,
      "loss": 0.0077,
      "step": 6370
    },
    {
      "epoch": 5.285832642916321,
      "grad_norm": 0.0023331777192652225,
      "learning_rate": 1.295222314277824e-05,
      "loss": 0.0102,
      "step": 6380
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.0026902942918241024,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 0.0037,
      "step": 6390
    },
    {
      "epoch": 5.302402651201326,
      "grad_norm": 0.011803637258708477,
      "learning_rate": 1.2930129798398234e-05,
      "loss": 0.0167,
      "step": 6400
    },
    {
      "epoch": 5.310687655343828,
      "grad_norm": 2.291012763977051,
      "learning_rate": 1.2919083126208231e-05,
      "loss": 0.0176,
      "step": 6410
    },
    {
      "epoch": 5.31897265948633,
      "grad_norm": 0.0036710347048938274,
      "learning_rate": 1.290803645401823e-05,
      "loss": 0.0045,
      "step": 6420
    },
    {
      "epoch": 5.327257663628831,
      "grad_norm": 0.6767212152481079,
      "learning_rate": 1.2896989781828226e-05,
      "loss": 0.007,
      "step": 6430
    },
    {
      "epoch": 5.335542667771334,
      "grad_norm": 2.703946590423584,
      "learning_rate": 1.288594310963822e-05,
      "loss": 0.0066,
      "step": 6440
    },
    {
      "epoch": 5.343827671913836,
      "grad_norm": 0.02235995978116989,
      "learning_rate": 1.287489643744822e-05,
      "loss": 0.0041,
      "step": 6450
    },
    {
      "epoch": 5.352112676056338,
      "grad_norm": 0.6398312449455261,
      "learning_rate": 1.2863849765258216e-05,
      "loss": 0.0126,
      "step": 6460
    },
    {
      "epoch": 5.36039768019884,
      "grad_norm": 0.01866842433810234,
      "learning_rate": 1.2852803093068214e-05,
      "loss": 0.004,
      "step": 6470
    },
    {
      "epoch": 5.368682684341342,
      "grad_norm": 0.0027420027181506157,
      "learning_rate": 1.2841756420878211e-05,
      "loss": 0.0075,
      "step": 6480
    },
    {
      "epoch": 5.376967688483845,
      "grad_norm": 0.0009919082513079047,
      "learning_rate": 1.2830709748688208e-05,
      "loss": 0.0067,
      "step": 6490
    },
    {
      "epoch": 5.385252692626346,
      "grad_norm": 0.0009672286687418818,
      "learning_rate": 1.2819663076498206e-05,
      "loss": 0.0012,
      "step": 6500
    },
    {
      "epoch": 5.393537696768848,
      "grad_norm": 0.006322592031210661,
      "learning_rate": 1.2808616404308203e-05,
      "loss": 0.038,
      "step": 6510
    },
    {
      "epoch": 5.40182270091135,
      "grad_norm": 0.00033884900039993227,
      "learning_rate": 1.2797569732118201e-05,
      "loss": 0.0052,
      "step": 6520
    },
    {
      "epoch": 5.410107705053853,
      "grad_norm": 0.9674416780471802,
      "learning_rate": 1.2786523059928198e-05,
      "loss": 0.0033,
      "step": 6530
    },
    {
      "epoch": 5.418392709196355,
      "grad_norm": 0.0020502961706370115,
      "learning_rate": 1.2775476387738194e-05,
      "loss": 0.0165,
      "step": 6540
    },
    {
      "epoch": 5.426677713338857,
      "grad_norm": 0.004612002056092024,
      "learning_rate": 1.2764429715548193e-05,
      "loss": 0.0121,
      "step": 6550
    },
    {
      "epoch": 5.434962717481358,
      "grad_norm": 0.003240481950342655,
      "learning_rate": 1.275338304335819e-05,
      "loss": 0.0046,
      "step": 6560
    },
    {
      "epoch": 5.443247721623861,
      "grad_norm": 0.0024280298966914415,
      "learning_rate": 1.2742336371168188e-05,
      "loss": 0.0075,
      "step": 6570
    },
    {
      "epoch": 5.451532725766363,
      "grad_norm": 1.485467553138733,
      "learning_rate": 1.2731289698978184e-05,
      "loss": 0.0041,
      "step": 6580
    },
    {
      "epoch": 5.459817729908865,
      "grad_norm": 0.009510580450296402,
      "learning_rate": 1.2720243026788181e-05,
      "loss": 0.0053,
      "step": 6590
    },
    {
      "epoch": 5.468102734051367,
      "grad_norm": 0.0012762121623381972,
      "learning_rate": 1.270919635459818e-05,
      "loss": 0.0017,
      "step": 6600
    },
    {
      "epoch": 5.4763877381938695,
      "grad_norm": 0.0005526827881112695,
      "learning_rate": 1.2698149682408176e-05,
      "loss": 0.0335,
      "step": 6610
    },
    {
      "epoch": 5.484672742336371,
      "grad_norm": 11.65034294128418,
      "learning_rate": 1.2687103010218174e-05,
      "loss": 0.03,
      "step": 6620
    },
    {
      "epoch": 5.492957746478873,
      "grad_norm": 10.380755424499512,
      "learning_rate": 1.2676056338028171e-05,
      "loss": 0.0315,
      "step": 6630
    },
    {
      "epoch": 5.501242750621375,
      "grad_norm": 0.0060652680695056915,
      "learning_rate": 1.2665009665838168e-05,
      "loss": 0.0038,
      "step": 6640
    },
    {
      "epoch": 5.5095277547638775,
      "grad_norm": 0.06351975351572037,
      "learning_rate": 1.2653962993648166e-05,
      "loss": 0.0251,
      "step": 6650
    },
    {
      "epoch": 5.51781275890638,
      "grad_norm": 0.02950197085738182,
      "learning_rate": 1.2642916321458161e-05,
      "loss": 0.0227,
      "step": 6660
    },
    {
      "epoch": 5.526097763048882,
      "grad_norm": 0.7687336206436157,
      "learning_rate": 1.2631869649268158e-05,
      "loss": 0.0019,
      "step": 6670
    },
    {
      "epoch": 5.534382767191383,
      "grad_norm": 0.0034023115877062082,
      "learning_rate": 1.2620822977078156e-05,
      "loss": 0.0119,
      "step": 6680
    },
    {
      "epoch": 5.542667771333885,
      "grad_norm": 0.9649685621261597,
      "learning_rate": 1.2609776304888153e-05,
      "loss": 0.0064,
      "step": 6690
    },
    {
      "epoch": 5.550952775476388,
      "grad_norm": 0.018647752702236176,
      "learning_rate": 1.2598729632698151e-05,
      "loss": 0.0012,
      "step": 6700
    },
    {
      "epoch": 5.55923777961889,
      "grad_norm": 0.0006696557393297553,
      "learning_rate": 1.2587682960508148e-05,
      "loss": 0.0091,
      "step": 6710
    },
    {
      "epoch": 5.567522783761392,
      "grad_norm": 0.0008886848809197545,
      "learning_rate": 1.2576636288318144e-05,
      "loss": 0.0195,
      "step": 6720
    },
    {
      "epoch": 5.575807787903894,
      "grad_norm": 0.0014041451504454017,
      "learning_rate": 1.2565589616128143e-05,
      "loss": 0.0005,
      "step": 6730
    },
    {
      "epoch": 5.584092792046396,
      "grad_norm": 0.0006324713467620313,
      "learning_rate": 1.255454294393814e-05,
      "loss": 0.0055,
      "step": 6740
    },
    {
      "epoch": 5.592377796188898,
      "grad_norm": 4.076600074768066,
      "learning_rate": 1.2543496271748138e-05,
      "loss": 0.0438,
      "step": 6750
    },
    {
      "epoch": 5.6006628003314,
      "grad_norm": 0.008725682273507118,
      "learning_rate": 1.2532449599558134e-05,
      "loss": 0.0033,
      "step": 6760
    },
    {
      "epoch": 5.608947804473902,
      "grad_norm": 0.002985405270010233,
      "learning_rate": 1.2521402927368131e-05,
      "loss": 0.0239,
      "step": 6770
    },
    {
      "epoch": 5.6172328086164045,
      "grad_norm": 0.10793229937553406,
      "learning_rate": 1.251035625517813e-05,
      "loss": 0.0098,
      "step": 6780
    },
    {
      "epoch": 5.625517812758907,
      "grad_norm": 0.002968158572912216,
      "learning_rate": 1.2499309582988126e-05,
      "loss": 0.023,
      "step": 6790
    },
    {
      "epoch": 5.633802816901408,
      "grad_norm": 0.003313037334010005,
      "learning_rate": 1.2488262910798124e-05,
      "loss": 0.0082,
      "step": 6800
    },
    {
      "epoch": 5.64208782104391,
      "grad_norm": 0.14154890179634094,
      "learning_rate": 1.2477216238608121e-05,
      "loss": 0.0058,
      "step": 6810
    },
    {
      "epoch": 5.6503728251864125,
      "grad_norm": 2.736039161682129,
      "learning_rate": 1.2466169566418118e-05,
      "loss": 0.0101,
      "step": 6820
    },
    {
      "epoch": 5.658657829328915,
      "grad_norm": 0.01089269295334816,
      "learning_rate": 1.2455122894228116e-05,
      "loss": 0.0008,
      "step": 6830
    },
    {
      "epoch": 5.666942833471417,
      "grad_norm": 0.15366119146347046,
      "learning_rate": 1.2444076222038113e-05,
      "loss": 0.0053,
      "step": 6840
    },
    {
      "epoch": 5.675227837613919,
      "grad_norm": 2.694037914276123,
      "learning_rate": 1.2433029549848111e-05,
      "loss": 0.0169,
      "step": 6850
    },
    {
      "epoch": 5.683512841756421,
      "grad_norm": 0.4103010594844818,
      "learning_rate": 1.2421982877658108e-05,
      "loss": 0.0223,
      "step": 6860
    },
    {
      "epoch": 5.691797845898923,
      "grad_norm": 0.24503089487552643,
      "learning_rate": 1.2410936205468104e-05,
      "loss": 0.0029,
      "step": 6870
    },
    {
      "epoch": 5.700082850041425,
      "grad_norm": 5.5091552734375,
      "learning_rate": 1.23998895332781e-05,
      "loss": 0.0192,
      "step": 6880
    },
    {
      "epoch": 5.708367854183927,
      "grad_norm": 1.3909717798233032,
      "learning_rate": 1.2388842861088098e-05,
      "loss": 0.0058,
      "step": 6890
    },
    {
      "epoch": 5.716652858326429,
      "grad_norm": 0.012086787261068821,
      "learning_rate": 1.2377796188898094e-05,
      "loss": 0.03,
      "step": 6900
    },
    {
      "epoch": 5.7249378624689315,
      "grad_norm": 0.0684058740735054,
      "learning_rate": 1.2366749516708093e-05,
      "loss": 0.0081,
      "step": 6910
    },
    {
      "epoch": 5.733222866611433,
      "grad_norm": 0.053096577525138855,
      "learning_rate": 1.235570284451809e-05,
      "loss": 0.0059,
      "step": 6920
    },
    {
      "epoch": 5.741507870753935,
      "grad_norm": 0.09605834633111954,
      "learning_rate": 1.2344656172328086e-05,
      "loss": 0.0025,
      "step": 6930
    },
    {
      "epoch": 5.749792874896437,
      "grad_norm": 0.002082455437630415,
      "learning_rate": 1.2333609500138084e-05,
      "loss": 0.0092,
      "step": 6940
    },
    {
      "epoch": 5.7580778790389395,
      "grad_norm": 2.861496686935425,
      "learning_rate": 1.2322562827948081e-05,
      "loss": 0.0243,
      "step": 6950
    },
    {
      "epoch": 5.766362883181442,
      "grad_norm": 0.00808535423129797,
      "learning_rate": 1.231151615575808e-05,
      "loss": 0.0077,
      "step": 6960
    },
    {
      "epoch": 5.774647887323944,
      "grad_norm": 0.0018534704577177763,
      "learning_rate": 1.2300469483568076e-05,
      "loss": 0.0169,
      "step": 6970
    },
    {
      "epoch": 5.782932891466446,
      "grad_norm": 0.0003974127466790378,
      "learning_rate": 1.2289422811378073e-05,
      "loss": 0.0211,
      "step": 6980
    },
    {
      "epoch": 5.7912178956089475,
      "grad_norm": 0.02026025950908661,
      "learning_rate": 1.2278376139188071e-05,
      "loss": 0.0058,
      "step": 6990
    },
    {
      "epoch": 5.79950289975145,
      "grad_norm": 2.9731035232543945,
      "learning_rate": 1.2267329466998068e-05,
      "loss": 0.02,
      "step": 7000
    },
    {
      "epoch": 5.807787903893952,
      "grad_norm": 1.4591752290725708,
      "learning_rate": 1.2256282794808066e-05,
      "loss": 0.0035,
      "step": 7010
    },
    {
      "epoch": 5.816072908036454,
      "grad_norm": 0.021679045632481575,
      "learning_rate": 1.2245236122618063e-05,
      "loss": 0.0183,
      "step": 7020
    },
    {
      "epoch": 5.824357912178956,
      "grad_norm": 0.01108827069401741,
      "learning_rate": 1.223418945042806e-05,
      "loss": 0.024,
      "step": 7030
    },
    {
      "epoch": 5.832642916321458,
      "grad_norm": 0.006830577738583088,
      "learning_rate": 1.2223142778238058e-05,
      "loss": 0.0074,
      "step": 7040
    },
    {
      "epoch": 5.84092792046396,
      "grad_norm": 0.006071663461625576,
      "learning_rate": 1.2212096106048054e-05,
      "loss": 0.0254,
      "step": 7050
    },
    {
      "epoch": 5.849212924606462,
      "grad_norm": 2.0829319953918457,
      "learning_rate": 1.2201049433858053e-05,
      "loss": 0.0163,
      "step": 7060
    },
    {
      "epoch": 5.857497928748964,
      "grad_norm": 0.01658364199101925,
      "learning_rate": 1.219000276166805e-05,
      "loss": 0.0002,
      "step": 7070
    },
    {
      "epoch": 5.865782932891467,
      "grad_norm": 0.01884557493031025,
      "learning_rate": 1.2178956089478046e-05,
      "loss": 0.022,
      "step": 7080
    },
    {
      "epoch": 5.874067937033969,
      "grad_norm": 2.0257692337036133,
      "learning_rate": 1.2167909417288043e-05,
      "loss": 0.0106,
      "step": 7090
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 1.4702709913253784,
      "learning_rate": 1.215686274509804e-05,
      "loss": 0.008,
      "step": 7100
    },
    {
      "epoch": 5.890637945318972,
      "grad_norm": 0.005985980853438377,
      "learning_rate": 1.2145816072908036e-05,
      "loss": 0.0367,
      "step": 7110
    },
    {
      "epoch": 5.8989229494614746,
      "grad_norm": 0.0035265455953776836,
      "learning_rate": 1.2134769400718034e-05,
      "loss": 0.0292,
      "step": 7120
    },
    {
      "epoch": 5.907207953603977,
      "grad_norm": 0.5958788990974426,
      "learning_rate": 1.2123722728528031e-05,
      "loss": 0.0113,
      "step": 7130
    },
    {
      "epoch": 5.915492957746479,
      "grad_norm": 0.0016541152726858854,
      "learning_rate": 1.211267605633803e-05,
      "loss": 0.0031,
      "step": 7140
    },
    {
      "epoch": 5.923777961888981,
      "grad_norm": 0.09081588685512543,
      "learning_rate": 1.2101629384148026e-05,
      "loss": 0.0043,
      "step": 7150
    },
    {
      "epoch": 5.9320629660314825,
      "grad_norm": 0.03236109018325806,
      "learning_rate": 1.2090582711958023e-05,
      "loss": 0.0018,
      "step": 7160
    },
    {
      "epoch": 5.940347970173985,
      "grad_norm": 0.01278949249535799,
      "learning_rate": 1.2079536039768021e-05,
      "loss": 0.0198,
      "step": 7170
    },
    {
      "epoch": 5.948632974316487,
      "grad_norm": 0.06562470644712448,
      "learning_rate": 1.2068489367578018e-05,
      "loss": 0.0031,
      "step": 7180
    },
    {
      "epoch": 5.956917978458989,
      "grad_norm": 0.4762289524078369,
      "learning_rate": 1.2057442695388016e-05,
      "loss": 0.0025,
      "step": 7190
    },
    {
      "epoch": 5.965202982601491,
      "grad_norm": 0.0021021824795752764,
      "learning_rate": 1.2046396023198013e-05,
      "loss": 0.0133,
      "step": 7200
    },
    {
      "epoch": 5.973487986743994,
      "grad_norm": 2.9493069648742676,
      "learning_rate": 1.203534935100801e-05,
      "loss": 0.0098,
      "step": 7210
    },
    {
      "epoch": 5.981772990886496,
      "grad_norm": 0.0009760019602254033,
      "learning_rate": 1.2024302678818008e-05,
      "loss": 0.0039,
      "step": 7220
    },
    {
      "epoch": 5.990057995028997,
      "grad_norm": 0.00658892747014761,
      "learning_rate": 1.2013256006628004e-05,
      "loss": 0.0198,
      "step": 7230
    },
    {
      "epoch": 5.998342999171499,
      "grad_norm": 0.007057336624711752,
      "learning_rate": 1.2002209334438003e-05,
      "loss": 0.0193,
      "step": 7240
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9928675048355899,
      "eval_f1": 0.9605351170568561,
      "eval_loss": 0.027956197038292885,
      "eval_precision": 0.9702702702702702,
      "eval_recall": 0.9509933774834437,
      "eval_runtime": 1597.4379,
      "eval_samples_per_second": 5.181,
      "eval_steps_per_second": 0.648,
      "step": 7242
    },
    {
      "epoch": 6.006628003314002,
      "grad_norm": 0.021782580763101578,
      "learning_rate": 1.1991162662248e-05,
      "loss": 0.0106,
      "step": 7250
    },
    {
      "epoch": 6.014913007456504,
      "grad_norm": 0.01913587376475334,
      "learning_rate": 1.1980115990057996e-05,
      "loss": 0.0021,
      "step": 7260
    },
    {
      "epoch": 6.023198011599006,
      "grad_norm": 0.005151490680873394,
      "learning_rate": 1.1969069317867994e-05,
      "loss": 0.0191,
      "step": 7270
    },
    {
      "epoch": 6.031483015741508,
      "grad_norm": 0.017064470797777176,
      "learning_rate": 1.1958022645677991e-05,
      "loss": 0.0191,
      "step": 7280
    },
    {
      "epoch": 6.03976801988401,
      "grad_norm": 0.0039894431829452515,
      "learning_rate": 1.194697597348799e-05,
      "loss": 0.0049,
      "step": 7290
    },
    {
      "epoch": 6.048053024026512,
      "grad_norm": 0.03094734065234661,
      "learning_rate": 1.1935929301297986e-05,
      "loss": 0.005,
      "step": 7300
    },
    {
      "epoch": 6.056338028169014,
      "grad_norm": 0.00519974809139967,
      "learning_rate": 1.1924882629107981e-05,
      "loss": 0.0127,
      "step": 7310
    },
    {
      "epoch": 6.064623032311516,
      "grad_norm": 2.2024471759796143,
      "learning_rate": 1.1913835956917978e-05,
      "loss": 0.0099,
      "step": 7320
    },
    {
      "epoch": 6.072908036454018,
      "grad_norm": 0.001116928062401712,
      "learning_rate": 1.1902789284727976e-05,
      "loss": 0.0001,
      "step": 7330
    },
    {
      "epoch": 6.081193040596521,
      "grad_norm": 8.229785919189453,
      "learning_rate": 1.1891742612537973e-05,
      "loss": 0.0213,
      "step": 7340
    },
    {
      "epoch": 6.089478044739022,
      "grad_norm": 0.6997846364974976,
      "learning_rate": 1.1880695940347971e-05,
      "loss": 0.0315,
      "step": 7350
    },
    {
      "epoch": 6.097763048881524,
      "grad_norm": 0.001766653498634696,
      "learning_rate": 1.1869649268157968e-05,
      "loss": 0.0099,
      "step": 7360
    },
    {
      "epoch": 6.106048053024026,
      "grad_norm": 3.016007900238037,
      "learning_rate": 1.1858602595967964e-05,
      "loss": 0.0071,
      "step": 7370
    },
    {
      "epoch": 6.114333057166529,
      "grad_norm": 0.003959637600928545,
      "learning_rate": 1.1847555923777963e-05,
      "loss": 0.0221,
      "step": 7380
    },
    {
      "epoch": 6.122618061309031,
      "grad_norm": 0.0008644376648589969,
      "learning_rate": 1.183650925158796e-05,
      "loss": 0.0496,
      "step": 7390
    },
    {
      "epoch": 6.130903065451533,
      "grad_norm": 1.2238342761993408,
      "learning_rate": 1.1825462579397958e-05,
      "loss": 0.0053,
      "step": 7400
    },
    {
      "epoch": 6.139188069594034,
      "grad_norm": 0.0012508906656876206,
      "learning_rate": 1.1814415907207954e-05,
      "loss": 0.0001,
      "step": 7410
    },
    {
      "epoch": 6.147473073736537,
      "grad_norm": 0.6594371199607849,
      "learning_rate": 1.1803369235017953e-05,
      "loss": 0.0104,
      "step": 7420
    },
    {
      "epoch": 6.155758077879039,
      "grad_norm": 11.079987525939941,
      "learning_rate": 1.179232256282795e-05,
      "loss": 0.0177,
      "step": 7430
    },
    {
      "epoch": 6.164043082021541,
      "grad_norm": 0.0006225827964954078,
      "learning_rate": 1.1781275890637946e-05,
      "loss": 0.015,
      "step": 7440
    },
    {
      "epoch": 6.172328086164043,
      "grad_norm": 0.004568113014101982,
      "learning_rate": 1.1770229218447944e-05,
      "loss": 0.0033,
      "step": 7450
    },
    {
      "epoch": 6.1806130903065455,
      "grad_norm": 0.942859947681427,
      "learning_rate": 1.1759182546257941e-05,
      "loss": 0.0075,
      "step": 7460
    },
    {
      "epoch": 6.188898094449047,
      "grad_norm": 1.6483612060546875,
      "learning_rate": 1.174813587406794e-05,
      "loss": 0.0178,
      "step": 7470
    },
    {
      "epoch": 6.197183098591549,
      "grad_norm": 0.03593786433339119,
      "learning_rate": 1.1737089201877936e-05,
      "loss": 0.0001,
      "step": 7480
    },
    {
      "epoch": 6.205468102734051,
      "grad_norm": 0.09790816903114319,
      "learning_rate": 1.1726042529687933e-05,
      "loss": 0.0004,
      "step": 7490
    },
    {
      "epoch": 6.2137531068765535,
      "grad_norm": 0.003826707834377885,
      "learning_rate": 1.1714995857497931e-05,
      "loss": 0.0272,
      "step": 7500
    },
    {
      "epoch": 6.222038111019056,
      "grad_norm": 0.003299868432804942,
      "learning_rate": 1.1703949185307928e-05,
      "loss": 0.0068,
      "step": 7510
    },
    {
      "epoch": 6.230323115161558,
      "grad_norm": 0.13437233865261078,
      "learning_rate": 1.1692902513117926e-05,
      "loss": 0.008,
      "step": 7520
    },
    {
      "epoch": 6.238608119304059,
      "grad_norm": 0.001800714060664177,
      "learning_rate": 1.1681855840927921e-05,
      "loss": 0.0008,
      "step": 7530
    },
    {
      "epoch": 6.2468931234465614,
      "grad_norm": 4.400130748748779,
      "learning_rate": 1.1670809168737918e-05,
      "loss": 0.0015,
      "step": 7540
    },
    {
      "epoch": 6.255178127589064,
      "grad_norm": 0.0006523929187096655,
      "learning_rate": 1.1659762496547914e-05,
      "loss": 0.0091,
      "step": 7550
    },
    {
      "epoch": 6.263463131731566,
      "grad_norm": 2.145325183868408,
      "learning_rate": 1.1648715824357913e-05,
      "loss": 0.0092,
      "step": 7560
    },
    {
      "epoch": 6.271748135874068,
      "grad_norm": 0.11062244325876236,
      "learning_rate": 1.163766915216791e-05,
      "loss": 0.0155,
      "step": 7570
    },
    {
      "epoch": 6.28003314001657,
      "grad_norm": 0.01328319776803255,
      "learning_rate": 1.1626622479977908e-05,
      "loss": 0.0323,
      "step": 7580
    },
    {
      "epoch": 6.2883181441590725,
      "grad_norm": 4.493060111999512,
      "learning_rate": 1.1615575807787904e-05,
      "loss": 0.021,
      "step": 7590
    },
    {
      "epoch": 6.296603148301574,
      "grad_norm": 0.007102759554982185,
      "learning_rate": 1.1604529135597901e-05,
      "loss": 0.0152,
      "step": 7600
    },
    {
      "epoch": 6.304888152444076,
      "grad_norm": 0.018454553559422493,
      "learning_rate": 1.15934824634079e-05,
      "loss": 0.0061,
      "step": 7610
    },
    {
      "epoch": 6.313173156586578,
      "grad_norm": 0.21062584221363068,
      "learning_rate": 1.1582435791217896e-05,
      "loss": 0.0065,
      "step": 7620
    },
    {
      "epoch": 6.3214581607290805,
      "grad_norm": 0.0005433934857137501,
      "learning_rate": 1.1571389119027894e-05,
      "loss": 0.0151,
      "step": 7630
    },
    {
      "epoch": 6.329743164871583,
      "grad_norm": 0.005102638155221939,
      "learning_rate": 1.1560342446837891e-05,
      "loss": 0.0241,
      "step": 7640
    },
    {
      "epoch": 6.338028169014084,
      "grad_norm": 0.00810302421450615,
      "learning_rate": 1.1549295774647888e-05,
      "loss": 0.0223,
      "step": 7650
    },
    {
      "epoch": 6.346313173156586,
      "grad_norm": 1.9330410957336426,
      "learning_rate": 1.1538249102457886e-05,
      "loss": 0.0306,
      "step": 7660
    },
    {
      "epoch": 6.3545981772990885,
      "grad_norm": 3.9277398586273193,
      "learning_rate": 1.1527202430267883e-05,
      "loss": 0.0087,
      "step": 7670
    },
    {
      "epoch": 6.362883181441591,
      "grad_norm": 0.00561182014644146,
      "learning_rate": 1.1516155758077881e-05,
      "loss": 0.0069,
      "step": 7680
    },
    {
      "epoch": 6.371168185584093,
      "grad_norm": 0.0022516511380672455,
      "learning_rate": 1.1505109085887878e-05,
      "loss": 0.0199,
      "step": 7690
    },
    {
      "epoch": 6.379453189726595,
      "grad_norm": 0.008901450783014297,
      "learning_rate": 1.1494062413697874e-05,
      "loss": 0.0334,
      "step": 7700
    },
    {
      "epoch": 6.387738193869097,
      "grad_norm": 1.0737909078598022,
      "learning_rate": 1.1483015741507873e-05,
      "loss": 0.0113,
      "step": 7710
    },
    {
      "epoch": 6.396023198011599,
      "grad_norm": 1.8760994672775269,
      "learning_rate": 1.147196906931787e-05,
      "loss": 0.0113,
      "step": 7720
    },
    {
      "epoch": 6.404308202154101,
      "grad_norm": 1.0203020572662354,
      "learning_rate": 1.1460922397127868e-05,
      "loss": 0.0214,
      "step": 7730
    },
    {
      "epoch": 6.412593206296603,
      "grad_norm": 0.0009546881774440408,
      "learning_rate": 1.1449875724937864e-05,
      "loss": 0.0018,
      "step": 7740
    },
    {
      "epoch": 6.420878210439105,
      "grad_norm": 0.3618398606777191,
      "learning_rate": 1.143882905274786e-05,
      "loss": 0.0087,
      "step": 7750
    },
    {
      "epoch": 6.4291632145816076,
      "grad_norm": 0.003372321603819728,
      "learning_rate": 1.1427782380557858e-05,
      "loss": 0.0252,
      "step": 7760
    },
    {
      "epoch": 6.43744821872411,
      "grad_norm": 0.2534334063529968,
      "learning_rate": 1.1416735708367854e-05,
      "loss": 0.0026,
      "step": 7770
    },
    {
      "epoch": 6.445733222866611,
      "grad_norm": 0.01298636943101883,
      "learning_rate": 1.1405689036177851e-05,
      "loss": 0.0003,
      "step": 7780
    },
    {
      "epoch": 6.454018227009113,
      "grad_norm": 0.1652010977268219,
      "learning_rate": 1.139464236398785e-05,
      "loss": 0.0229,
      "step": 7790
    },
    {
      "epoch": 6.4623032311516155,
      "grad_norm": 0.08070636540651321,
      "learning_rate": 1.1383595691797846e-05,
      "loss": 0.0001,
      "step": 7800
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.018602078780531883,
      "learning_rate": 1.1372549019607844e-05,
      "loss": 0.0127,
      "step": 7810
    },
    {
      "epoch": 6.47887323943662,
      "grad_norm": 0.31722837686538696,
      "learning_rate": 1.1361502347417841e-05,
      "loss": 0.0102,
      "step": 7820
    },
    {
      "epoch": 6.487158243579122,
      "grad_norm": 0.0009547693771310151,
      "learning_rate": 1.1350455675227838e-05,
      "loss": 0.0033,
      "step": 7830
    },
    {
      "epoch": 6.4954432477216235,
      "grad_norm": 0.009587080217897892,
      "learning_rate": 1.1339409003037836e-05,
      "loss": 0.009,
      "step": 7840
    },
    {
      "epoch": 6.503728251864126,
      "grad_norm": 0.000757479399908334,
      "learning_rate": 1.1328362330847833e-05,
      "loss": 0.0059,
      "step": 7850
    },
    {
      "epoch": 6.512013256006628,
      "grad_norm": 0.0006286643329076469,
      "learning_rate": 1.1317315658657831e-05,
      "loss": 0.0021,
      "step": 7860
    },
    {
      "epoch": 6.52029826014913,
      "grad_norm": 0.002361712511628866,
      "learning_rate": 1.1306268986467828e-05,
      "loss": 0.0188,
      "step": 7870
    },
    {
      "epoch": 6.528583264291632,
      "grad_norm": 0.0016695685917511582,
      "learning_rate": 1.1295222314277824e-05,
      "loss": 0.021,
      "step": 7880
    },
    {
      "epoch": 6.536868268434135,
      "grad_norm": 0.19931769371032715,
      "learning_rate": 1.1284175642087823e-05,
      "loss": 0.0196,
      "step": 7890
    },
    {
      "epoch": 6.545153272576636,
      "grad_norm": 0.004769510123878717,
      "learning_rate": 1.127312896989782e-05,
      "loss": 0.0005,
      "step": 7900
    },
    {
      "epoch": 6.553438276719138,
      "grad_norm": 2.12935733795166,
      "learning_rate": 1.1262082297707818e-05,
      "loss": 0.0019,
      "step": 7910
    },
    {
      "epoch": 6.56172328086164,
      "grad_norm": 0.0026482325047254562,
      "learning_rate": 1.1251035625517814e-05,
      "loss": 0.0095,
      "step": 7920
    },
    {
      "epoch": 6.570008285004143,
      "grad_norm": 0.3940953314304352,
      "learning_rate": 1.1239988953327811e-05,
      "loss": 0.0003,
      "step": 7930
    },
    {
      "epoch": 6.578293289146645,
      "grad_norm": 0.36912915110588074,
      "learning_rate": 1.122894228113781e-05,
      "loss": 0.0071,
      "step": 7940
    },
    {
      "epoch": 6.586578293289147,
      "grad_norm": 2.2619762420654297,
      "learning_rate": 1.1217895608947806e-05,
      "loss": 0.0108,
      "step": 7950
    },
    {
      "epoch": 6.594863297431648,
      "grad_norm": 0.004276134539395571,
      "learning_rate": 1.1206848936757804e-05,
      "loss": 0.0344,
      "step": 7960
    },
    {
      "epoch": 6.603148301574151,
      "grad_norm": 0.001623611431568861,
      "learning_rate": 1.11958022645678e-05,
      "loss": 0.0713,
      "step": 7970
    },
    {
      "epoch": 6.611433305716653,
      "grad_norm": 0.0031017372384667397,
      "learning_rate": 1.1184755592377796e-05,
      "loss": 0.001,
      "step": 7980
    },
    {
      "epoch": 6.619718309859155,
      "grad_norm": 0.2868071496486664,
      "learning_rate": 1.1173708920187793e-05,
      "loss": 0.0055,
      "step": 7990
    },
    {
      "epoch": 6.628003314001657,
      "grad_norm": 0.018654493615031242,
      "learning_rate": 1.1162662247997791e-05,
      "loss": 0.0008,
      "step": 8000
    },
    {
      "epoch": 6.636288318144159,
      "grad_norm": 0.22909092903137207,
      "learning_rate": 1.1151615575807788e-05,
      "loss": 0.0131,
      "step": 8010
    },
    {
      "epoch": 6.644573322286661,
      "grad_norm": 2.297427177429199,
      "learning_rate": 1.1140568903617786e-05,
      "loss": 0.0138,
      "step": 8020
    },
    {
      "epoch": 6.652858326429163,
      "grad_norm": 0.0009060828015208244,
      "learning_rate": 1.1129522231427783e-05,
      "loss": 0.0176,
      "step": 8030
    },
    {
      "epoch": 6.661143330571665,
      "grad_norm": 1.4106788635253906,
      "learning_rate": 1.111847555923778e-05,
      "loss": 0.016,
      "step": 8040
    },
    {
      "epoch": 6.669428334714167,
      "grad_norm": 0.02876260317862034,
      "learning_rate": 1.1107428887047778e-05,
      "loss": 0.0217,
      "step": 8050
    },
    {
      "epoch": 6.67771333885667,
      "grad_norm": 7.436220645904541,
      "learning_rate": 1.1096382214857774e-05,
      "loss": 0.0013,
      "step": 8060
    },
    {
      "epoch": 6.685998342999172,
      "grad_norm": 0.013261609710752964,
      "learning_rate": 1.1085335542667773e-05,
      "loss": 0.0044,
      "step": 8070
    },
    {
      "epoch": 6.694283347141674,
      "grad_norm": 0.00553558673709631,
      "learning_rate": 1.107428887047777e-05,
      "loss": 0.0047,
      "step": 8080
    },
    {
      "epoch": 6.702568351284175,
      "grad_norm": 0.004159965086728334,
      "learning_rate": 1.1063242198287766e-05,
      "loss": 0.0129,
      "step": 8090
    },
    {
      "epoch": 6.710853355426678,
      "grad_norm": 0.0013099941425025463,
      "learning_rate": 1.1052195526097764e-05,
      "loss": 0.0013,
      "step": 8100
    },
    {
      "epoch": 6.71913835956918,
      "grad_norm": 0.002902346896007657,
      "learning_rate": 1.1041148853907761e-05,
      "loss": 0.0248,
      "step": 8110
    },
    {
      "epoch": 6.727423363711682,
      "grad_norm": 0.009705917909741402,
      "learning_rate": 1.103010218171776e-05,
      "loss": 0.0197,
      "step": 8120
    },
    {
      "epoch": 6.735708367854184,
      "grad_norm": 0.0753585696220398,
      "learning_rate": 1.1019055509527756e-05,
      "loss": 0.02,
      "step": 8130
    },
    {
      "epoch": 6.743993371996686,
      "grad_norm": 0.05794583633542061,
      "learning_rate": 1.1008008837337753e-05,
      "loss": 0.0003,
      "step": 8140
    },
    {
      "epoch": 6.752278376139188,
      "grad_norm": 0.0036050223279744387,
      "learning_rate": 1.0996962165147751e-05,
      "loss": 0.0016,
      "step": 8150
    },
    {
      "epoch": 6.76056338028169,
      "grad_norm": 0.06590963155031204,
      "learning_rate": 1.0985915492957748e-05,
      "loss": 0.0227,
      "step": 8160
    },
    {
      "epoch": 6.768848384424192,
      "grad_norm": 0.02909708581864834,
      "learning_rate": 1.0974868820767746e-05,
      "loss": 0.0271,
      "step": 8170
    },
    {
      "epoch": 6.7771333885666944,
      "grad_norm": 0.6165719628334045,
      "learning_rate": 1.0963822148577741e-05,
      "loss": 0.0193,
      "step": 8180
    },
    {
      "epoch": 6.785418392709197,
      "grad_norm": 0.025503873825073242,
      "learning_rate": 1.0952775476387738e-05,
      "loss": 0.0029,
      "step": 8190
    },
    {
      "epoch": 6.793703396851699,
      "grad_norm": 1.9585034847259521,
      "learning_rate": 1.0941728804197736e-05,
      "loss": 0.0433,
      "step": 8200
    },
    {
      "epoch": 6.8019884009942,
      "grad_norm": 0.37799909710884094,
      "learning_rate": 1.0930682132007733e-05,
      "loss": 0.0085,
      "step": 8210
    },
    {
      "epoch": 6.810273405136702,
      "grad_norm": 0.0013595467898994684,
      "learning_rate": 1.091963545981773e-05,
      "loss": 0.008,
      "step": 8220
    },
    {
      "epoch": 6.818558409279205,
      "grad_norm": 0.04271155968308449,
      "learning_rate": 1.0908588787627728e-05,
      "loss": 0.0031,
      "step": 8230
    },
    {
      "epoch": 6.826843413421707,
      "grad_norm": 3.266832113265991,
      "learning_rate": 1.0897542115437724e-05,
      "loss": 0.0206,
      "step": 8240
    },
    {
      "epoch": 6.835128417564209,
      "grad_norm": 0.012775576673448086,
      "learning_rate": 1.0886495443247723e-05,
      "loss": 0.0125,
      "step": 8250
    },
    {
      "epoch": 6.84341342170671,
      "grad_norm": 0.0025385331828147173,
      "learning_rate": 1.087544877105772e-05,
      "loss": 0.0006,
      "step": 8260
    },
    {
      "epoch": 6.851698425849213,
      "grad_norm": 0.0036303140223026276,
      "learning_rate": 1.0864402098867716e-05,
      "loss": 0.0089,
      "step": 8270
    },
    {
      "epoch": 6.859983429991715,
      "grad_norm": 0.0022803363390266895,
      "learning_rate": 1.0853355426677714e-05,
      "loss": 0.0033,
      "step": 8280
    },
    {
      "epoch": 6.868268434134217,
      "grad_norm": 7.212008953094482,
      "learning_rate": 1.0842308754487711e-05,
      "loss": 0.0082,
      "step": 8290
    },
    {
      "epoch": 6.876553438276719,
      "grad_norm": 0.021601801738142967,
      "learning_rate": 1.083126208229771e-05,
      "loss": 0.0041,
      "step": 8300
    },
    {
      "epoch": 6.8848384424192215,
      "grad_norm": 0.005168486852198839,
      "learning_rate": 1.0820215410107706e-05,
      "loss": 0.0002,
      "step": 8310
    },
    {
      "epoch": 6.893123446561724,
      "grad_norm": 0.868605375289917,
      "learning_rate": 1.0809168737917703e-05,
      "loss": 0.0043,
      "step": 8320
    },
    {
      "epoch": 6.901408450704225,
      "grad_norm": 0.0006164585356600583,
      "learning_rate": 1.0798122065727701e-05,
      "loss": 0.0043,
      "step": 8330
    },
    {
      "epoch": 6.909693454846727,
      "grad_norm": 0.1721317023038864,
      "learning_rate": 1.0787075393537698e-05,
      "loss": 0.0044,
      "step": 8340
    },
    {
      "epoch": 6.9179784589892295,
      "grad_norm": 0.038297366350889206,
      "learning_rate": 1.0776028721347696e-05,
      "loss": 0.0148,
      "step": 8350
    },
    {
      "epoch": 6.926263463131732,
      "grad_norm": 0.003681507892906666,
      "learning_rate": 1.0764982049157693e-05,
      "loss": 0.0018,
      "step": 8360
    },
    {
      "epoch": 6.934548467274234,
      "grad_norm": 0.6435602307319641,
      "learning_rate": 1.075393537696769e-05,
      "loss": 0.001,
      "step": 8370
    },
    {
      "epoch": 6.942833471416735,
      "grad_norm": 0.002011075848713517,
      "learning_rate": 1.0742888704777688e-05,
      "loss": 0.0321,
      "step": 8380
    },
    {
      "epoch": 6.9511184755592375,
      "grad_norm": 1.1509974002838135,
      "learning_rate": 1.0731842032587684e-05,
      "loss": 0.0227,
      "step": 8390
    },
    {
      "epoch": 6.95940347970174,
      "grad_norm": 0.002194428350776434,
      "learning_rate": 1.072079536039768e-05,
      "loss": 0.0155,
      "step": 8400
    },
    {
      "epoch": 6.967688483844242,
      "grad_norm": 2.320633888244629,
      "learning_rate": 1.0709748688207678e-05,
      "loss": 0.0083,
      "step": 8410
    },
    {
      "epoch": 6.975973487986744,
      "grad_norm": 0.005804430693387985,
      "learning_rate": 1.0698702016017674e-05,
      "loss": 0.0284,
      "step": 8420
    },
    {
      "epoch": 6.984258492129246,
      "grad_norm": 1.8921223878860474,
      "learning_rate": 1.0687655343827673e-05,
      "loss": 0.0071,
      "step": 8430
    },
    {
      "epoch": 6.9925434962717485,
      "grad_norm": 0.0026836527977138758,
      "learning_rate": 1.067660867163767e-05,
      "loss": 0.0032,
      "step": 8440
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9927466150870407,
      "eval_f1": 0.9598393574297188,
      "eval_loss": 0.029440967366099358,
      "eval_precision": 0.9702300405953992,
      "eval_recall": 0.9496688741721855,
      "eval_runtime": 1432.3275,
      "eval_samples_per_second": 5.779,
      "eval_steps_per_second": 0.723,
      "step": 8449
    },
    {
      "epoch": 7.00082850041425,
      "grad_norm": 0.001968619879335165,
      "learning_rate": 1.0665561999447666e-05,
      "loss": 0.0021,
      "step": 8450
    },
    {
      "epoch": 7.009113504556752,
      "grad_norm": 1.1745622158050537,
      "learning_rate": 1.0654515327257664e-05,
      "loss": 0.0066,
      "step": 8460
    },
    {
      "epoch": 7.017398508699254,
      "grad_norm": 0.0009522067266516387,
      "learning_rate": 1.0643468655067661e-05,
      "loss": 0.0002,
      "step": 8470
    },
    {
      "epoch": 7.0256835128417565,
      "grad_norm": 0.0008048543240875006,
      "learning_rate": 1.063242198287766e-05,
      "loss": 0.0002,
      "step": 8480
    },
    {
      "epoch": 7.033968516984259,
      "grad_norm": 0.046652521938085556,
      "learning_rate": 1.0621375310687656e-05,
      "loss": 0.0005,
      "step": 8490
    },
    {
      "epoch": 7.042253521126761,
      "grad_norm": 0.002705581020563841,
      "learning_rate": 1.0610328638497653e-05,
      "loss": 0.0179,
      "step": 8500
    },
    {
      "epoch": 7.050538525269262,
      "grad_norm": 0.020308157429099083,
      "learning_rate": 1.0599281966307651e-05,
      "loss": 0.0164,
      "step": 8510
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.03825836628675461,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 0.002,
      "step": 8520
    },
    {
      "epoch": 7.067108533554267,
      "grad_norm": 0.009173017926514149,
      "learning_rate": 1.0577188621927646e-05,
      "loss": 0.0038,
      "step": 8530
    },
    {
      "epoch": 7.075393537696769,
      "grad_norm": 0.004629732109606266,
      "learning_rate": 1.0566141949737643e-05,
      "loss": 0.0042,
      "step": 8540
    },
    {
      "epoch": 7.083678541839271,
      "grad_norm": 0.03780721500515938,
      "learning_rate": 1.055509527754764e-05,
      "loss": 0.0083,
      "step": 8550
    },
    {
      "epoch": 7.091963545981773,
      "grad_norm": 3.298734426498413,
      "learning_rate": 1.0544048605357638e-05,
      "loss": 0.0096,
      "step": 8560
    },
    {
      "epoch": 7.100248550124275,
      "grad_norm": 0.0009309881716035306,
      "learning_rate": 1.0533001933167635e-05,
      "loss": 0.0003,
      "step": 8570
    },
    {
      "epoch": 7.108533554266777,
      "grad_norm": 0.9055296182632446,
      "learning_rate": 1.0521955260977633e-05,
      "loss": 0.0094,
      "step": 8580
    },
    {
      "epoch": 7.116818558409279,
      "grad_norm": 0.0021018614061176777,
      "learning_rate": 1.051090858878763e-05,
      "loss": 0.0021,
      "step": 8590
    },
    {
      "epoch": 7.125103562551781,
      "grad_norm": 0.0004919162020087242,
      "learning_rate": 1.0499861916597626e-05,
      "loss": 0.0018,
      "step": 8600
    },
    {
      "epoch": 7.133388566694284,
      "grad_norm": 0.0003754746285267174,
      "learning_rate": 1.0488815244407625e-05,
      "loss": 0.0088,
      "step": 8610
    },
    {
      "epoch": 7.141673570836786,
      "grad_norm": 0.001454032608307898,
      "learning_rate": 1.047776857221762e-05,
      "loss": 0.0161,
      "step": 8620
    },
    {
      "epoch": 7.149958574979287,
      "grad_norm": 0.00048732224968262017,
      "learning_rate": 1.0466721900027616e-05,
      "loss": 0.0054,
      "step": 8630
    },
    {
      "epoch": 7.158243579121789,
      "grad_norm": 2.6112823486328125,
      "learning_rate": 1.0455675227837615e-05,
      "loss": 0.003,
      "step": 8640
    },
    {
      "epoch": 7.1665285832642915,
      "grad_norm": 0.014102947898209095,
      "learning_rate": 1.0444628555647611e-05,
      "loss": 0.0021,
      "step": 8650
    },
    {
      "epoch": 7.174813587406794,
      "grad_norm": 1.2449826002120972,
      "learning_rate": 1.0433581883457608e-05,
      "loss": 0.0071,
      "step": 8660
    },
    {
      "epoch": 7.183098591549296,
      "grad_norm": 0.08837883174419403,
      "learning_rate": 1.0422535211267606e-05,
      "loss": 0.0001,
      "step": 8670
    },
    {
      "epoch": 7.191383595691798,
      "grad_norm": 0.01250769104808569,
      "learning_rate": 1.0411488539077603e-05,
      "loss": 0.018,
      "step": 8680
    },
    {
      "epoch": 7.1996685998342995,
      "grad_norm": 0.03162870928645134,
      "learning_rate": 1.0400441866887601e-05,
      "loss": 0.0004,
      "step": 8690
    },
    {
      "epoch": 7.207953603976802,
      "grad_norm": 0.0003520440950524062,
      "learning_rate": 1.0389395194697598e-05,
      "loss": 0.01,
      "step": 8700
    },
    {
      "epoch": 7.216238608119304,
      "grad_norm": 0.00024820282123982906,
      "learning_rate": 1.0378348522507595e-05,
      "loss": 0.0155,
      "step": 8710
    },
    {
      "epoch": 7.224523612261806,
      "grad_norm": 0.023493962362408638,
      "learning_rate": 1.0367301850317593e-05,
      "loss": 0.0061,
      "step": 8720
    },
    {
      "epoch": 7.232808616404308,
      "grad_norm": 0.000836615392472595,
      "learning_rate": 1.035625517812759e-05,
      "loss": 0.0049,
      "step": 8730
    },
    {
      "epoch": 7.241093620546811,
      "grad_norm": 0.00449069868773222,
      "learning_rate": 1.0345208505937588e-05,
      "loss": 0.0158,
      "step": 8740
    },
    {
      "epoch": 7.249378624689312,
      "grad_norm": 0.003061849856749177,
      "learning_rate": 1.0334161833747585e-05,
      "loss": 0.0353,
      "step": 8750
    },
    {
      "epoch": 7.257663628831814,
      "grad_norm": 0.0005645312485285103,
      "learning_rate": 1.0323115161557581e-05,
      "loss": 0.0199,
      "step": 8760
    },
    {
      "epoch": 7.265948632974316,
      "grad_norm": 0.002623572712764144,
      "learning_rate": 1.031206848936758e-05,
      "loss": 0.0089,
      "step": 8770
    },
    {
      "epoch": 7.274233637116819,
      "grad_norm": 0.651980996131897,
      "learning_rate": 1.0301021817177576e-05,
      "loss": 0.0185,
      "step": 8780
    },
    {
      "epoch": 7.282518641259321,
      "grad_norm": 0.016197122633457184,
      "learning_rate": 1.0289975144987575e-05,
      "loss": 0.0003,
      "step": 8790
    },
    {
      "epoch": 7.290803645401823,
      "grad_norm": 0.007419751025736332,
      "learning_rate": 1.0278928472797571e-05,
      "loss": 0.0103,
      "step": 8800
    },
    {
      "epoch": 7.299088649544325,
      "grad_norm": 0.013425661250948906,
      "learning_rate": 1.0267881800607568e-05,
      "loss": 0.0001,
      "step": 8810
    },
    {
      "epoch": 7.307373653686827,
      "grad_norm": 1.6944810152053833,
      "learning_rate": 1.0256835128417566e-05,
      "loss": 0.0073,
      "step": 8820
    },
    {
      "epoch": 7.315658657829329,
      "grad_norm": 0.005981686525046825,
      "learning_rate": 1.0245788456227563e-05,
      "loss": 0.0152,
      "step": 8830
    },
    {
      "epoch": 7.323943661971831,
      "grad_norm": 0.0025020919274538755,
      "learning_rate": 1.0234741784037558e-05,
      "loss": 0.007,
      "step": 8840
    },
    {
      "epoch": 7.332228666114333,
      "grad_norm": 0.0025277764070779085,
      "learning_rate": 1.0223695111847556e-05,
      "loss": 0.0105,
      "step": 8850
    },
    {
      "epoch": 7.340513670256835,
      "grad_norm": 1.1856136322021484,
      "learning_rate": 1.0212648439657553e-05,
      "loss": 0.0099,
      "step": 8860
    },
    {
      "epoch": 7.348798674399337,
      "grad_norm": 0.001272871857509017,
      "learning_rate": 1.0201601767467551e-05,
      "loss": 0.01,
      "step": 8870
    },
    {
      "epoch": 7.357083678541839,
      "grad_norm": 0.052087053656578064,
      "learning_rate": 1.0190555095277548e-05,
      "loss": 0.0099,
      "step": 8880
    },
    {
      "epoch": 7.365368682684341,
      "grad_norm": 0.015601692721247673,
      "learning_rate": 1.0179508423087545e-05,
      "loss": 0.0207,
      "step": 8890
    },
    {
      "epoch": 7.373653686826843,
      "grad_norm": 0.0359051413834095,
      "learning_rate": 1.0168461750897543e-05,
      "loss": 0.008,
      "step": 8900
    },
    {
      "epoch": 7.381938690969346,
      "grad_norm": 0.006450996268540621,
      "learning_rate": 1.015741507870754e-05,
      "loss": 0.0069,
      "step": 8910
    },
    {
      "epoch": 7.390223695111848,
      "grad_norm": 0.00203814753331244,
      "learning_rate": 1.0146368406517538e-05,
      "loss": 0.011,
      "step": 8920
    },
    {
      "epoch": 7.39850869925435,
      "grad_norm": 0.0038742795586586,
      "learning_rate": 1.0135321734327535e-05,
      "loss": 0.0061,
      "step": 8930
    },
    {
      "epoch": 7.406793703396851,
      "grad_norm": 0.00035552060580812395,
      "learning_rate": 1.0124275062137531e-05,
      "loss": 0.0003,
      "step": 8940
    },
    {
      "epoch": 7.415078707539354,
      "grad_norm": 0.0003822875733021647,
      "learning_rate": 1.011322838994753e-05,
      "loss": 0.0016,
      "step": 8950
    },
    {
      "epoch": 7.423363711681856,
      "grad_norm": 3.124784469604492,
      "learning_rate": 1.0102181717757526e-05,
      "loss": 0.0065,
      "step": 8960
    },
    {
      "epoch": 7.431648715824358,
      "grad_norm": 0.0011874105548486114,
      "learning_rate": 1.0091135045567525e-05,
      "loss": 0.0004,
      "step": 8970
    },
    {
      "epoch": 7.43993371996686,
      "grad_norm": 1.0902912616729736,
      "learning_rate": 1.0080088373377521e-05,
      "loss": 0.0259,
      "step": 8980
    },
    {
      "epoch": 7.448218724109362,
      "grad_norm": 0.00029814260778948665,
      "learning_rate": 1.0069041701187518e-05,
      "loss": 0.0011,
      "step": 8990
    },
    {
      "epoch": 7.456503728251864,
      "grad_norm": 0.00035016299807466567,
      "learning_rate": 1.0057995028997516e-05,
      "loss": 0.0003,
      "step": 9000
    },
    {
      "epoch": 7.464788732394366,
      "grad_norm": 0.6504855751991272,
      "learning_rate": 1.0046948356807513e-05,
      "loss": 0.024,
      "step": 9010
    },
    {
      "epoch": 7.473073736536868,
      "grad_norm": 0.0003258608339820057,
      "learning_rate": 1.0035901684617511e-05,
      "loss": 0.0027,
      "step": 9020
    },
    {
      "epoch": 7.4813587406793705,
      "grad_norm": 0.04693160951137543,
      "learning_rate": 1.0024855012427508e-05,
      "loss": 0.0007,
      "step": 9030
    },
    {
      "epoch": 7.489643744821873,
      "grad_norm": 0.0013828827068209648,
      "learning_rate": 1.0013808340237505e-05,
      "loss": 0.0151,
      "step": 9040
    },
    {
      "epoch": 7.497928748964375,
      "grad_norm": 0.0003021358570549637,
      "learning_rate": 1.0002761668047503e-05,
      "loss": 0.0,
      "step": 9050
    },
    {
      "epoch": 7.506213753106876,
      "grad_norm": 0.0005240367609076202,
      "learning_rate": 9.9917149958575e-06,
      "loss": 0.005,
      "step": 9060
    },
    {
      "epoch": 7.514498757249378,
      "grad_norm": 0.00036479730624705553,
      "learning_rate": 9.980668323667496e-06,
      "loss": 0.0002,
      "step": 9070
    },
    {
      "epoch": 7.522783761391881,
      "grad_norm": 0.0006580121698789299,
      "learning_rate": 9.969621651477493e-06,
      "loss": 0.023,
      "step": 9080
    },
    {
      "epoch": 7.531068765534383,
      "grad_norm": 0.0014251876855269074,
      "learning_rate": 9.958574979287491e-06,
      "loss": 0.0034,
      "step": 9090
    },
    {
      "epoch": 7.539353769676885,
      "grad_norm": 1.7768067121505737,
      "learning_rate": 9.947528307097488e-06,
      "loss": 0.0368,
      "step": 9100
    },
    {
      "epoch": 7.547638773819386,
      "grad_norm": 2.2979576587677,
      "learning_rate": 9.936481634907485e-06,
      "loss": 0.0024,
      "step": 9110
    },
    {
      "epoch": 7.555923777961889,
      "grad_norm": 0.004270120989531279,
      "learning_rate": 9.925434962717481e-06,
      "loss": 0.0362,
      "step": 9120
    },
    {
      "epoch": 7.564208782104391,
      "grad_norm": 0.00036345640546642244,
      "learning_rate": 9.91438829052748e-06,
      "loss": 0.01,
      "step": 9130
    },
    {
      "epoch": 7.572493786246893,
      "grad_norm": 0.0012894656974822283,
      "learning_rate": 9.903341618337476e-06,
      "loss": 0.0102,
      "step": 9140
    },
    {
      "epoch": 7.580778790389395,
      "grad_norm": 0.002220720052719116,
      "learning_rate": 9.892294946147475e-06,
      "loss": 0.0123,
      "step": 9150
    },
    {
      "epoch": 7.5890637945318975,
      "grad_norm": 0.00042048553586937487,
      "learning_rate": 9.881248273957471e-06,
      "loss": 0.0089,
      "step": 9160
    },
    {
      "epoch": 7.5973487986744,
      "grad_norm": 0.0018048296915367246,
      "learning_rate": 9.870201601767468e-06,
      "loss": 0.005,
      "step": 9170
    },
    {
      "epoch": 7.605633802816901,
      "grad_norm": 0.0031646285206079483,
      "learning_rate": 9.859154929577466e-06,
      "loss": 0.0142,
      "step": 9180
    },
    {
      "epoch": 7.613918806959403,
      "grad_norm": 0.06151941046118736,
      "learning_rate": 9.848108257387463e-06,
      "loss": 0.0046,
      "step": 9190
    },
    {
      "epoch": 7.6222038111019055,
      "grad_norm": 0.0038337234873324633,
      "learning_rate": 9.837061585197461e-06,
      "loss": 0.0308,
      "step": 9200
    },
    {
      "epoch": 7.630488815244408,
      "grad_norm": 0.2960240840911865,
      "learning_rate": 9.826014913007458e-06,
      "loss": 0.0191,
      "step": 9210
    },
    {
      "epoch": 7.63877381938691,
      "grad_norm": 2.0456016063690186,
      "learning_rate": 9.814968240817455e-06,
      "loss": 0.0064,
      "step": 9220
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.004045736510306597,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.001,
      "step": 9230
    },
    {
      "epoch": 7.6553438276719135,
      "grad_norm": 0.0010932994773611426,
      "learning_rate": 9.792874896437448e-06,
      "loss": 0.0103,
      "step": 9240
    },
    {
      "epoch": 7.663628831814416,
      "grad_norm": 0.005506066605448723,
      "learning_rate": 9.781828224247446e-06,
      "loss": 0.0145,
      "step": 9250
    },
    {
      "epoch": 7.671913835956918,
      "grad_norm": 0.0008084838627837598,
      "learning_rate": 9.770781552057443e-06,
      "loss": 0.0032,
      "step": 9260
    },
    {
      "epoch": 7.68019884009942,
      "grad_norm": 1.9084949493408203,
      "learning_rate": 9.759734879867441e-06,
      "loss": 0.0053,
      "step": 9270
    },
    {
      "epoch": 7.688483844241922,
      "grad_norm": 0.005668797995895147,
      "learning_rate": 9.748688207677438e-06,
      "loss": 0.0082,
      "step": 9280
    },
    {
      "epoch": 7.6967688483844245,
      "grad_norm": 0.0023608629126101732,
      "learning_rate": 9.737641535487435e-06,
      "loss": 0.0068,
      "step": 9290
    },
    {
      "epoch": 7.705053852526927,
      "grad_norm": 2.2933597564697266,
      "learning_rate": 9.726594863297433e-06,
      "loss": 0.0211,
      "step": 9300
    },
    {
      "epoch": 7.713338856669428,
      "grad_norm": 0.003973595332354307,
      "learning_rate": 9.71554819110743e-06,
      "loss": 0.0056,
      "step": 9310
    },
    {
      "epoch": 7.72162386081193,
      "grad_norm": 0.6252752542495728,
      "learning_rate": 9.704501518917428e-06,
      "loss": 0.0017,
      "step": 9320
    },
    {
      "epoch": 7.7299088649544325,
      "grad_norm": 0.0012129655806347728,
      "learning_rate": 9.693454846727423e-06,
      "loss": 0.0214,
      "step": 9330
    },
    {
      "epoch": 7.738193869096935,
      "grad_norm": 0.2615039050579071,
      "learning_rate": 9.682408174537421e-06,
      "loss": 0.0131,
      "step": 9340
    },
    {
      "epoch": 7.746478873239437,
      "grad_norm": 0.013426641002297401,
      "learning_rate": 9.671361502347418e-06,
      "loss": 0.0036,
      "step": 9350
    },
    {
      "epoch": 7.754763877381938,
      "grad_norm": 0.972679615020752,
      "learning_rate": 9.660314830157416e-06,
      "loss": 0.0131,
      "step": 9360
    },
    {
      "epoch": 7.7630488815244405,
      "grad_norm": 0.009475931525230408,
      "learning_rate": 9.649268157967413e-06,
      "loss": 0.0191,
      "step": 9370
    },
    {
      "epoch": 7.771333885666943,
      "grad_norm": 0.0006148837856017053,
      "learning_rate": 9.63822148577741e-06,
      "loss": 0.0004,
      "step": 9380
    },
    {
      "epoch": 7.779618889809445,
      "grad_norm": 0.002341874875128269,
      "learning_rate": 9.627174813587408e-06,
      "loss": 0.0117,
      "step": 9390
    },
    {
      "epoch": 7.787903893951947,
      "grad_norm": 0.002648013411089778,
      "learning_rate": 9.616128141397405e-06,
      "loss": 0.0069,
      "step": 9400
    },
    {
      "epoch": 7.796188898094449,
      "grad_norm": 0.7468060255050659,
      "learning_rate": 9.605081469207403e-06,
      "loss": 0.0211,
      "step": 9410
    },
    {
      "epoch": 7.804473902236952,
      "grad_norm": 0.05978328362107277,
      "learning_rate": 9.5940347970174e-06,
      "loss": 0.0068,
      "step": 9420
    },
    {
      "epoch": 7.812758906379453,
      "grad_norm": 0.0008904144051484764,
      "learning_rate": 9.582988124827396e-06,
      "loss": 0.0051,
      "step": 9430
    },
    {
      "epoch": 7.821043910521955,
      "grad_norm": 2.988884687423706,
      "learning_rate": 9.571941452637393e-06,
      "loss": 0.0124,
      "step": 9440
    },
    {
      "epoch": 7.829328914664457,
      "grad_norm": 0.002648848108947277,
      "learning_rate": 9.560894780447391e-06,
      "loss": 0.0029,
      "step": 9450
    },
    {
      "epoch": 7.83761391880696,
      "grad_norm": 0.004245683550834656,
      "learning_rate": 9.549848108257388e-06,
      "loss": 0.0034,
      "step": 9460
    },
    {
      "epoch": 7.845898922949462,
      "grad_norm": 0.005430006422102451,
      "learning_rate": 9.538801436067385e-06,
      "loss": 0.0022,
      "step": 9470
    },
    {
      "epoch": 7.854183927091963,
      "grad_norm": 0.0009234768222086132,
      "learning_rate": 9.527754763877383e-06,
      "loss": 0.0001,
      "step": 9480
    },
    {
      "epoch": 7.862468931234465,
      "grad_norm": 0.009331444278359413,
      "learning_rate": 9.51670809168738e-06,
      "loss": 0.0008,
      "step": 9490
    },
    {
      "epoch": 7.8707539353769675,
      "grad_norm": 0.03892500698566437,
      "learning_rate": 9.505661419497378e-06,
      "loss": 0.0001,
      "step": 9500
    },
    {
      "epoch": 7.87903893951947,
      "grad_norm": 0.0007997981738299131,
      "learning_rate": 9.494614747307375e-06,
      "loss": 0.0141,
      "step": 9510
    },
    {
      "epoch": 7.887323943661972,
      "grad_norm": 0.014318003319203854,
      "learning_rate": 9.483568075117371e-06,
      "loss": 0.0092,
      "step": 9520
    },
    {
      "epoch": 7.895608947804474,
      "grad_norm": 1.4905561208724976,
      "learning_rate": 9.47252140292737e-06,
      "loss": 0.0066,
      "step": 9530
    },
    {
      "epoch": 7.903893951946976,
      "grad_norm": 0.0008994191302917898,
      "learning_rate": 9.461474730737366e-06,
      "loss": 0.0083,
      "step": 9540
    },
    {
      "epoch": 7.912178956089478,
      "grad_norm": 0.04892880842089653,
      "learning_rate": 9.450428058547363e-06,
      "loss": 0.0002,
      "step": 9550
    },
    {
      "epoch": 7.92046396023198,
      "grad_norm": 0.0006294549675658345,
      "learning_rate": 9.43938138635736e-06,
      "loss": 0.0078,
      "step": 9560
    },
    {
      "epoch": 7.928748964374482,
      "grad_norm": 0.049398407340049744,
      "learning_rate": 9.428334714167358e-06,
      "loss": 0.0104,
      "step": 9570
    },
    {
      "epoch": 7.937033968516984,
      "grad_norm": 0.5041434168815613,
      "learning_rate": 9.417288041977355e-06,
      "loss": 0.0052,
      "step": 9580
    },
    {
      "epoch": 7.945318972659487,
      "grad_norm": 0.0017059081001207232,
      "learning_rate": 9.406241369787353e-06,
      "loss": 0.0302,
      "step": 9590
    },
    {
      "epoch": 7.953603976801988,
      "grad_norm": 0.010903242975473404,
      "learning_rate": 9.39519469759735e-06,
      "loss": 0.0084,
      "step": 9600
    },
    {
      "epoch": 7.96188898094449,
      "grad_norm": 0.0013547935523092747,
      "learning_rate": 9.384148025407346e-06,
      "loss": 0.0068,
      "step": 9610
    },
    {
      "epoch": 7.970173985086992,
      "grad_norm": 7.463657855987549,
      "learning_rate": 9.373101353217345e-06,
      "loss": 0.0083,
      "step": 9620
    },
    {
      "epoch": 7.978458989229495,
      "grad_norm": 0.0007820720202289522,
      "learning_rate": 9.362054681027341e-06,
      "loss": 0.0115,
      "step": 9630
    },
    {
      "epoch": 7.986743993371997,
      "grad_norm": 0.0042063994333148,
      "learning_rate": 9.35100800883734e-06,
      "loss": 0.0203,
      "step": 9640
    },
    {
      "epoch": 7.995028997514499,
      "grad_norm": 0.07908199727535248,
      "learning_rate": 9.339961336647336e-06,
      "loss": 0.0049,
      "step": 9650
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9932301740812379,
      "eval_f1": 0.962059620596206,
      "eval_loss": 0.030278103426098824,
      "eval_precision": 0.984743411927878,
      "eval_recall": 0.9403973509933775,
      "eval_runtime": 1612.7004,
      "eval_samples_per_second": 5.132,
      "eval_steps_per_second": 0.642,
      "step": 9656
    }
  ],
  "logging_steps": 10,
  "max_steps": 18105,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.94231944495744e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
