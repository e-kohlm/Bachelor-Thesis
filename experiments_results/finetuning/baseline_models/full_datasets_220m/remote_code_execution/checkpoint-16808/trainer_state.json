{
  "best_metric": 0.9890854347007905,
  "best_model_checkpoint": "../saved_models/remote_code_execution/checkpoint-16808",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 16808,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00047596382674916705,
      "grad_norm": 34.976295471191406,
      "learning_rate": 1.9999048072346504e-05,
      "loss": 0.5923,
      "step": 1
    },
    {
      "epoch": 0.00475963826749167,
      "grad_norm": 10.369417190551758,
      "learning_rate": 1.999048072346502e-05,
      "loss": 0.3653,
      "step": 10
    },
    {
      "epoch": 0.00951927653498334,
      "grad_norm": 22.37224006652832,
      "learning_rate": 1.9980961446930034e-05,
      "loss": 0.4012,
      "step": 20
    },
    {
      "epoch": 0.014278914802475012,
      "grad_norm": 12.583932876586914,
      "learning_rate": 1.997144217039505e-05,
      "loss": 0.3486,
      "step": 30
    },
    {
      "epoch": 0.01903855306996668,
      "grad_norm": 12.578253746032715,
      "learning_rate": 1.996192289386007e-05,
      "loss": 0.3423,
      "step": 40
    },
    {
      "epoch": 0.023798191337458353,
      "grad_norm": 9.536176681518555,
      "learning_rate": 1.9952403617325083e-05,
      "loss": 0.2906,
      "step": 50
    },
    {
      "epoch": 0.028557829604950024,
      "grad_norm": 137.4424591064453,
      "learning_rate": 1.99428843407901e-05,
      "loss": 0.3513,
      "step": 60
    },
    {
      "epoch": 0.03331746787244169,
      "grad_norm": 18.056039810180664,
      "learning_rate": 1.993336506425512e-05,
      "loss": 0.2938,
      "step": 70
    },
    {
      "epoch": 0.03807710613993336,
      "grad_norm": 15.781106948852539,
      "learning_rate": 1.9923845787720136e-05,
      "loss": 0.3295,
      "step": 80
    },
    {
      "epoch": 0.042836744407425034,
      "grad_norm": 8.167695999145508,
      "learning_rate": 1.991432651118515e-05,
      "loss": 0.2847,
      "step": 90
    },
    {
      "epoch": 0.047596382674916705,
      "grad_norm": 15.734013557434082,
      "learning_rate": 1.9904807234650168e-05,
      "loss": 0.3106,
      "step": 100
    },
    {
      "epoch": 0.05235602094240838,
      "grad_norm": 39.907264709472656,
      "learning_rate": 1.9895287958115186e-05,
      "loss": 0.3349,
      "step": 110
    },
    {
      "epoch": 0.05711565920990005,
      "grad_norm": 16.854598999023438,
      "learning_rate": 1.9885768681580204e-05,
      "loss": 0.3316,
      "step": 120
    },
    {
      "epoch": 0.06187529747739172,
      "grad_norm": 12.1062650680542,
      "learning_rate": 1.9876249405045218e-05,
      "loss": 0.2935,
      "step": 130
    },
    {
      "epoch": 0.06663493574488338,
      "grad_norm": 15.22258472442627,
      "learning_rate": 1.9866730128510236e-05,
      "loss": 0.2733,
      "step": 140
    },
    {
      "epoch": 0.07139457401237506,
      "grad_norm": 6.964229106903076,
      "learning_rate": 1.985721085197525e-05,
      "loss": 0.2968,
      "step": 150
    },
    {
      "epoch": 0.07615421227986673,
      "grad_norm": 17.8483943939209,
      "learning_rate": 1.9847691575440268e-05,
      "loss": 0.3471,
      "step": 160
    },
    {
      "epoch": 0.0809138505473584,
      "grad_norm": 12.124957084655762,
      "learning_rate": 1.9838172298905285e-05,
      "loss": 0.2359,
      "step": 170
    },
    {
      "epoch": 0.08567348881485007,
      "grad_norm": 11.558414459228516,
      "learning_rate": 1.98286530223703e-05,
      "loss": 0.2779,
      "step": 180
    },
    {
      "epoch": 0.09043312708234175,
      "grad_norm": 11.787956237792969,
      "learning_rate": 1.9819133745835317e-05,
      "loss": 0.2733,
      "step": 190
    },
    {
      "epoch": 0.09519276534983341,
      "grad_norm": 10.515005111694336,
      "learning_rate": 1.9809614469300335e-05,
      "loss": 0.2887,
      "step": 200
    },
    {
      "epoch": 0.09995240361732509,
      "grad_norm": 3.6122586727142334,
      "learning_rate": 1.9800095192765353e-05,
      "loss": 0.2314,
      "step": 210
    },
    {
      "epoch": 0.10471204188481675,
      "grad_norm": 9.788477897644043,
      "learning_rate": 1.9790575916230367e-05,
      "loss": 0.2958,
      "step": 220
    },
    {
      "epoch": 0.10947168015230842,
      "grad_norm": 3.309199333190918,
      "learning_rate": 1.9781056639695385e-05,
      "loss": 0.207,
      "step": 230
    },
    {
      "epoch": 0.1142313184198001,
      "grad_norm": 6.270515441894531,
      "learning_rate": 1.9771537363160402e-05,
      "loss": 0.2898,
      "step": 240
    },
    {
      "epoch": 0.11899095668729176,
      "grad_norm": 17.42824935913086,
      "learning_rate": 1.976201808662542e-05,
      "loss": 0.2908,
      "step": 250
    },
    {
      "epoch": 0.12375059495478344,
      "grad_norm": 9.222346305847168,
      "learning_rate": 1.9752498810090434e-05,
      "loss": 0.3273,
      "step": 260
    },
    {
      "epoch": 0.12851023322227512,
      "grad_norm": 9.942266464233398,
      "learning_rate": 1.9742979533555452e-05,
      "loss": 0.3375,
      "step": 270
    },
    {
      "epoch": 0.13326987148976677,
      "grad_norm": 16.66539764404297,
      "learning_rate": 1.9733460257020466e-05,
      "loss": 0.2991,
      "step": 280
    },
    {
      "epoch": 0.13802950975725845,
      "grad_norm": 9.856025695800781,
      "learning_rate": 1.9723940980485484e-05,
      "loss": 0.2919,
      "step": 290
    },
    {
      "epoch": 0.14278914802475012,
      "grad_norm": 12.01872730255127,
      "learning_rate": 1.97144217039505e-05,
      "loss": 0.34,
      "step": 300
    },
    {
      "epoch": 0.1475487862922418,
      "grad_norm": 19.207048416137695,
      "learning_rate": 1.970490242741552e-05,
      "loss": 0.261,
      "step": 310
    },
    {
      "epoch": 0.15230842455973345,
      "grad_norm": 5.636131763458252,
      "learning_rate": 1.9695383150880534e-05,
      "loss": 0.3346,
      "step": 320
    },
    {
      "epoch": 0.15706806282722513,
      "grad_norm": 13.79474925994873,
      "learning_rate": 1.968586387434555e-05,
      "loss": 0.26,
      "step": 330
    },
    {
      "epoch": 0.1618277010947168,
      "grad_norm": 19.864736557006836,
      "learning_rate": 1.967634459781057e-05,
      "loss": 0.2738,
      "step": 340
    },
    {
      "epoch": 0.16658733936220846,
      "grad_norm": 21.406152725219727,
      "learning_rate": 1.9666825321275583e-05,
      "loss": 0.2636,
      "step": 350
    },
    {
      "epoch": 0.17134697762970014,
      "grad_norm": 9.817720413208008,
      "learning_rate": 1.96573060447406e-05,
      "loss": 0.2766,
      "step": 360
    },
    {
      "epoch": 0.17610661589719181,
      "grad_norm": 32.94038391113281,
      "learning_rate": 1.964778676820562e-05,
      "loss": 0.2539,
      "step": 370
    },
    {
      "epoch": 0.1808662541646835,
      "grad_norm": 7.286331653594971,
      "learning_rate": 1.9638267491670636e-05,
      "loss": 0.3004,
      "step": 380
    },
    {
      "epoch": 0.18562589243217514,
      "grad_norm": 15.634285926818848,
      "learning_rate": 1.962874821513565e-05,
      "loss": 0.3592,
      "step": 390
    },
    {
      "epoch": 0.19038553069966682,
      "grad_norm": 35.35746383666992,
      "learning_rate": 1.9619228938600668e-05,
      "loss": 0.2476,
      "step": 400
    },
    {
      "epoch": 0.1951451689671585,
      "grad_norm": 11.617997169494629,
      "learning_rate": 1.9609709662065686e-05,
      "loss": 0.3073,
      "step": 410
    },
    {
      "epoch": 0.19990480723465018,
      "grad_norm": 4.465804100036621,
      "learning_rate": 1.96001903855307e-05,
      "loss": 0.2567,
      "step": 420
    },
    {
      "epoch": 0.20466444550214183,
      "grad_norm": 9.909407615661621,
      "learning_rate": 1.9590671108995718e-05,
      "loss": 0.3322,
      "step": 430
    },
    {
      "epoch": 0.2094240837696335,
      "grad_norm": 7.159360408782959,
      "learning_rate": 1.9581151832460736e-05,
      "loss": 0.2211,
      "step": 440
    },
    {
      "epoch": 0.21418372203712518,
      "grad_norm": 5.675317287445068,
      "learning_rate": 1.957163255592575e-05,
      "loss": 0.2525,
      "step": 450
    },
    {
      "epoch": 0.21894336030461684,
      "grad_norm": 11.100854873657227,
      "learning_rate": 1.9562113279390767e-05,
      "loss": 0.2267,
      "step": 460
    },
    {
      "epoch": 0.2237029985721085,
      "grad_norm": 5.0031046867370605,
      "learning_rate": 1.9552594002855785e-05,
      "loss": 0.2167,
      "step": 470
    },
    {
      "epoch": 0.2284626368396002,
      "grad_norm": 5.343658447265625,
      "learning_rate": 1.95430747263208e-05,
      "loss": 0.2325,
      "step": 480
    },
    {
      "epoch": 0.23322227510709187,
      "grad_norm": 8.470596313476562,
      "learning_rate": 1.9533555449785817e-05,
      "loss": 0.2497,
      "step": 490
    },
    {
      "epoch": 0.23798191337458352,
      "grad_norm": 43.593719482421875,
      "learning_rate": 1.9524036173250835e-05,
      "loss": 0.252,
      "step": 500
    },
    {
      "epoch": 0.2427415516420752,
      "grad_norm": 3.5851078033447266,
      "learning_rate": 1.9514516896715853e-05,
      "loss": 0.2381,
      "step": 510
    },
    {
      "epoch": 0.24750118990956688,
      "grad_norm": 9.797242164611816,
      "learning_rate": 1.9504997620180867e-05,
      "loss": 0.2387,
      "step": 520
    },
    {
      "epoch": 0.2522608281770585,
      "grad_norm": 4.641597747802734,
      "learning_rate": 1.9495478343645884e-05,
      "loss": 0.2547,
      "step": 530
    },
    {
      "epoch": 0.25702046644455023,
      "grad_norm": 6.825216293334961,
      "learning_rate": 1.9485959067110902e-05,
      "loss": 0.3269,
      "step": 540
    },
    {
      "epoch": 0.2617801047120419,
      "grad_norm": 7.160143852233887,
      "learning_rate": 1.947643979057592e-05,
      "loss": 0.2586,
      "step": 550
    },
    {
      "epoch": 0.26653974297953353,
      "grad_norm": 13.991551399230957,
      "learning_rate": 1.9466920514040934e-05,
      "loss": 0.2927,
      "step": 560
    },
    {
      "epoch": 0.27129938124702524,
      "grad_norm": 9.39244270324707,
      "learning_rate": 1.9457401237505952e-05,
      "loss": 0.2461,
      "step": 570
    },
    {
      "epoch": 0.2760590195145169,
      "grad_norm": 4.4197282791137695,
      "learning_rate": 1.9447881960970966e-05,
      "loss": 0.2339,
      "step": 580
    },
    {
      "epoch": 0.28081865778200854,
      "grad_norm": 10.309286117553711,
      "learning_rate": 1.9438362684435984e-05,
      "loss": 0.3372,
      "step": 590
    },
    {
      "epoch": 0.28557829604950025,
      "grad_norm": 4.952186107635498,
      "learning_rate": 1.9428843407901e-05,
      "loss": 0.1464,
      "step": 600
    },
    {
      "epoch": 0.2903379343169919,
      "grad_norm": 4.555415630340576,
      "learning_rate": 1.941932413136602e-05,
      "loss": 0.2219,
      "step": 610
    },
    {
      "epoch": 0.2950975725844836,
      "grad_norm": 5.253595352172852,
      "learning_rate": 1.9409804854831033e-05,
      "loss": 0.2532,
      "step": 620
    },
    {
      "epoch": 0.29985721085197525,
      "grad_norm": 6.817275047302246,
      "learning_rate": 1.940028557829605e-05,
      "loss": 0.2386,
      "step": 630
    },
    {
      "epoch": 0.3046168491194669,
      "grad_norm": 9.516148567199707,
      "learning_rate": 1.939076630176107e-05,
      "loss": 0.1783,
      "step": 640
    },
    {
      "epoch": 0.3093764873869586,
      "grad_norm": 7.712341785430908,
      "learning_rate": 1.9381247025226083e-05,
      "loss": 0.2443,
      "step": 650
    },
    {
      "epoch": 0.31413612565445026,
      "grad_norm": 12.329648971557617,
      "learning_rate": 1.93717277486911e-05,
      "loss": 0.2153,
      "step": 660
    },
    {
      "epoch": 0.3188957639219419,
      "grad_norm": 0.7856594324111938,
      "learning_rate": 1.936220847215612e-05,
      "loss": 0.2121,
      "step": 670
    },
    {
      "epoch": 0.3236554021894336,
      "grad_norm": 10.25110912322998,
      "learning_rate": 1.9352689195621136e-05,
      "loss": 0.2394,
      "step": 680
    },
    {
      "epoch": 0.32841504045692527,
      "grad_norm": 5.747597694396973,
      "learning_rate": 1.934316991908615e-05,
      "loss": 0.1802,
      "step": 690
    },
    {
      "epoch": 0.3331746787244169,
      "grad_norm": 5.4879150390625,
      "learning_rate": 1.9333650642551168e-05,
      "loss": 0.2171,
      "step": 700
    },
    {
      "epoch": 0.3379343169919086,
      "grad_norm": 5.801612854003906,
      "learning_rate": 1.9324131366016182e-05,
      "loss": 0.2382,
      "step": 710
    },
    {
      "epoch": 0.3426939552594003,
      "grad_norm": 8.634415626525879,
      "learning_rate": 1.93146120894812e-05,
      "loss": 0.1747,
      "step": 720
    },
    {
      "epoch": 0.347453593526892,
      "grad_norm": 8.150080680847168,
      "learning_rate": 1.9305092812946218e-05,
      "loss": 0.1855,
      "step": 730
    },
    {
      "epoch": 0.35221323179438363,
      "grad_norm": 12.816476821899414,
      "learning_rate": 1.9295573536411235e-05,
      "loss": 0.2094,
      "step": 740
    },
    {
      "epoch": 0.3569728700618753,
      "grad_norm": 17.312313079833984,
      "learning_rate": 1.928605425987625e-05,
      "loss": 0.2195,
      "step": 750
    },
    {
      "epoch": 0.361732508329367,
      "grad_norm": 6.538700580596924,
      "learning_rate": 1.9276534983341267e-05,
      "loss": 0.1922,
      "step": 760
    },
    {
      "epoch": 0.36649214659685864,
      "grad_norm": 4.3304362297058105,
      "learning_rate": 1.9267015706806285e-05,
      "loss": 0.2375,
      "step": 770
    },
    {
      "epoch": 0.3712517848643503,
      "grad_norm": 10.76061725616455,
      "learning_rate": 1.92574964302713e-05,
      "loss": 0.1845,
      "step": 780
    },
    {
      "epoch": 0.376011423131842,
      "grad_norm": 5.912248611450195,
      "learning_rate": 1.9247977153736317e-05,
      "loss": 0.2035,
      "step": 790
    },
    {
      "epoch": 0.38077106139933364,
      "grad_norm": 5.1463422775268555,
      "learning_rate": 1.9238457877201335e-05,
      "loss": 0.1998,
      "step": 800
    },
    {
      "epoch": 0.3855306996668253,
      "grad_norm": 5.657236099243164,
      "learning_rate": 1.9228938600666352e-05,
      "loss": 0.175,
      "step": 810
    },
    {
      "epoch": 0.390290337934317,
      "grad_norm": 9.430632591247559,
      "learning_rate": 1.9219419324131367e-05,
      "loss": 0.1709,
      "step": 820
    },
    {
      "epoch": 0.39504997620180865,
      "grad_norm": 9.477826118469238,
      "learning_rate": 1.9209900047596384e-05,
      "loss": 0.1897,
      "step": 830
    },
    {
      "epoch": 0.39980961446930036,
      "grad_norm": 11.950916290283203,
      "learning_rate": 1.92003807710614e-05,
      "loss": 0.1639,
      "step": 840
    },
    {
      "epoch": 0.404569252736792,
      "grad_norm": 8.189937591552734,
      "learning_rate": 1.919086149452642e-05,
      "loss": 0.172,
      "step": 850
    },
    {
      "epoch": 0.40932889100428366,
      "grad_norm": 2.735847234725952,
      "learning_rate": 1.9181342217991434e-05,
      "loss": 0.147,
      "step": 860
    },
    {
      "epoch": 0.41408852927177536,
      "grad_norm": 12.363999366760254,
      "learning_rate": 1.9171822941456452e-05,
      "loss": 0.1782,
      "step": 870
    },
    {
      "epoch": 0.418848167539267,
      "grad_norm": 8.131397247314453,
      "learning_rate": 1.9162303664921466e-05,
      "loss": 0.2243,
      "step": 880
    },
    {
      "epoch": 0.42360780580675866,
      "grad_norm": 4.65041971206665,
      "learning_rate": 1.9152784388386484e-05,
      "loss": 0.1829,
      "step": 890
    },
    {
      "epoch": 0.42836744407425037,
      "grad_norm": 8.466279029846191,
      "learning_rate": 1.91432651118515e-05,
      "loss": 0.2014,
      "step": 900
    },
    {
      "epoch": 0.433127082341742,
      "grad_norm": 4.350707530975342,
      "learning_rate": 1.9133745835316516e-05,
      "loss": 0.138,
      "step": 910
    },
    {
      "epoch": 0.43788672060923367,
      "grad_norm": 2.042541742324829,
      "learning_rate": 1.9124226558781533e-05,
      "loss": 0.1314,
      "step": 920
    },
    {
      "epoch": 0.4426463588767254,
      "grad_norm": 6.667825222015381,
      "learning_rate": 1.911470728224655e-05,
      "loss": 0.1258,
      "step": 930
    },
    {
      "epoch": 0.447405997144217,
      "grad_norm": 11.2006196975708,
      "learning_rate": 1.910518800571157e-05,
      "loss": 0.1563,
      "step": 940
    },
    {
      "epoch": 0.45216563541170873,
      "grad_norm": 10.587263107299805,
      "learning_rate": 1.9095668729176583e-05,
      "loss": 0.1905,
      "step": 950
    },
    {
      "epoch": 0.4569252736792004,
      "grad_norm": 11.041661262512207,
      "learning_rate": 1.90861494526416e-05,
      "loss": 0.1739,
      "step": 960
    },
    {
      "epoch": 0.46168491194669203,
      "grad_norm": 3.8148062229156494,
      "learning_rate": 1.9076630176106615e-05,
      "loss": 0.1777,
      "step": 970
    },
    {
      "epoch": 0.46644455021418374,
      "grad_norm": 2.8834359645843506,
      "learning_rate": 1.9067110899571636e-05,
      "loss": 0.0653,
      "step": 980
    },
    {
      "epoch": 0.4712041884816754,
      "grad_norm": 8.440713882446289,
      "learning_rate": 1.905759162303665e-05,
      "loss": 0.1686,
      "step": 990
    },
    {
      "epoch": 0.47596382674916704,
      "grad_norm": 9.668069839477539,
      "learning_rate": 1.9048072346501668e-05,
      "loss": 0.1869,
      "step": 1000
    },
    {
      "epoch": 0.48072346501665875,
      "grad_norm": 6.211161136627197,
      "learning_rate": 1.9038553069966682e-05,
      "loss": 0.0804,
      "step": 1010
    },
    {
      "epoch": 0.4854831032841504,
      "grad_norm": 8.72601318359375,
      "learning_rate": 1.90290337934317e-05,
      "loss": 0.1363,
      "step": 1020
    },
    {
      "epoch": 0.4902427415516421,
      "grad_norm": 12.581269264221191,
      "learning_rate": 1.9019514516896718e-05,
      "loss": 0.1474,
      "step": 1030
    },
    {
      "epoch": 0.49500237981913375,
      "grad_norm": 9.196656227111816,
      "learning_rate": 1.9009995240361735e-05,
      "loss": 0.1163,
      "step": 1040
    },
    {
      "epoch": 0.4997620180866254,
      "grad_norm": 12.092450141906738,
      "learning_rate": 1.900047596382675e-05,
      "loss": 0.1123,
      "step": 1050
    },
    {
      "epoch": 0.504521656354117,
      "grad_norm": 6.858646869659424,
      "learning_rate": 1.8990956687291767e-05,
      "loss": 0.1234,
      "step": 1060
    },
    {
      "epoch": 0.5092812946216088,
      "grad_norm": 8.915950775146484,
      "learning_rate": 1.8981437410756785e-05,
      "loss": 0.1066,
      "step": 1070
    },
    {
      "epoch": 0.5140409328891005,
      "grad_norm": 10.244101524353027,
      "learning_rate": 1.89719181342218e-05,
      "loss": 0.1183,
      "step": 1080
    },
    {
      "epoch": 0.5188005711565921,
      "grad_norm": 11.3446626663208,
      "learning_rate": 1.8962398857686817e-05,
      "loss": 0.0949,
      "step": 1090
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 12.968877792358398,
      "learning_rate": 1.895287958115183e-05,
      "loss": 0.1266,
      "step": 1100
    },
    {
      "epoch": 0.5283198476915755,
      "grad_norm": 10.59428596496582,
      "learning_rate": 1.8943360304616852e-05,
      "loss": 0.1791,
      "step": 1110
    },
    {
      "epoch": 0.5330794859590671,
      "grad_norm": 11.47877311706543,
      "learning_rate": 1.8933841028081867e-05,
      "loss": 0.1817,
      "step": 1120
    },
    {
      "epoch": 0.5378391242265588,
      "grad_norm": 5.373650550842285,
      "learning_rate": 1.8924321751546884e-05,
      "loss": 0.1076,
      "step": 1130
    },
    {
      "epoch": 0.5425987624940505,
      "grad_norm": 13.12940788269043,
      "learning_rate": 1.89148024750119e-05,
      "loss": 0.1283,
      "step": 1140
    },
    {
      "epoch": 0.5473584007615421,
      "grad_norm": 5.505524635314941,
      "learning_rate": 1.890528319847692e-05,
      "loss": 0.076,
      "step": 1150
    },
    {
      "epoch": 0.5521180390290338,
      "grad_norm": 5.757888317108154,
      "learning_rate": 1.8895763921941934e-05,
      "loss": 0.1635,
      "step": 1160
    },
    {
      "epoch": 0.5568776772965255,
      "grad_norm": 0.5800634026527405,
      "learning_rate": 1.888624464540695e-05,
      "loss": 0.134,
      "step": 1170
    },
    {
      "epoch": 0.5616373155640171,
      "grad_norm": 2.896449089050293,
      "learning_rate": 1.8876725368871966e-05,
      "loss": 0.0717,
      "step": 1180
    },
    {
      "epoch": 0.5663969538315088,
      "grad_norm": 13.112378120422363,
      "learning_rate": 1.8867206092336984e-05,
      "loss": 0.1379,
      "step": 1190
    },
    {
      "epoch": 0.5711565920990005,
      "grad_norm": 0.6080319881439209,
      "learning_rate": 1.8857686815802e-05,
      "loss": 0.1229,
      "step": 1200
    },
    {
      "epoch": 0.5759162303664922,
      "grad_norm": 2.7205874919891357,
      "learning_rate": 1.8848167539267016e-05,
      "loss": 0.1137,
      "step": 1210
    },
    {
      "epoch": 0.5806758686339838,
      "grad_norm": 2.9999537467956543,
      "learning_rate": 1.8838648262732033e-05,
      "loss": 0.091,
      "step": 1220
    },
    {
      "epoch": 0.5854355069014755,
      "grad_norm": 9.349294662475586,
      "learning_rate": 1.882912898619705e-05,
      "loss": 0.0758,
      "step": 1230
    },
    {
      "epoch": 0.5901951451689672,
      "grad_norm": 10.98283863067627,
      "learning_rate": 1.881960970966207e-05,
      "loss": 0.1109,
      "step": 1240
    },
    {
      "epoch": 0.5949547834364588,
      "grad_norm": 6.941901206970215,
      "learning_rate": 1.8810090433127083e-05,
      "loss": 0.1619,
      "step": 1250
    },
    {
      "epoch": 0.5997144217039505,
      "grad_norm": 1.1730775833129883,
      "learning_rate": 1.88005711565921e-05,
      "loss": 0.0681,
      "step": 1260
    },
    {
      "epoch": 0.6044740599714422,
      "grad_norm": 3.883370876312256,
      "learning_rate": 1.8791051880057115e-05,
      "loss": 0.1199,
      "step": 1270
    },
    {
      "epoch": 0.6092336982389338,
      "grad_norm": 0.6330426931381226,
      "learning_rate": 1.8781532603522136e-05,
      "loss": 0.1083,
      "step": 1280
    },
    {
      "epoch": 0.6139933365064255,
      "grad_norm": 8.27392864227295,
      "learning_rate": 1.877201332698715e-05,
      "loss": 0.0664,
      "step": 1290
    },
    {
      "epoch": 0.6187529747739172,
      "grad_norm": 5.692694664001465,
      "learning_rate": 1.8762494050452168e-05,
      "loss": 0.0824,
      "step": 1300
    },
    {
      "epoch": 0.6235126130414088,
      "grad_norm": 4.721786975860596,
      "learning_rate": 1.8752974773917182e-05,
      "loss": 0.0914,
      "step": 1310
    },
    {
      "epoch": 0.6282722513089005,
      "grad_norm": 14.8663969039917,
      "learning_rate": 1.87434554973822e-05,
      "loss": 0.1798,
      "step": 1320
    },
    {
      "epoch": 0.6330318895763922,
      "grad_norm": 1.5275232791900635,
      "learning_rate": 1.8733936220847218e-05,
      "loss": 0.1081,
      "step": 1330
    },
    {
      "epoch": 0.6377915278438838,
      "grad_norm": 10.245059967041016,
      "learning_rate": 1.8724416944312235e-05,
      "loss": 0.0778,
      "step": 1340
    },
    {
      "epoch": 0.6425511661113755,
      "grad_norm": 6.876585483551025,
      "learning_rate": 1.871489766777725e-05,
      "loss": 0.0415,
      "step": 1350
    },
    {
      "epoch": 0.6473108043788672,
      "grad_norm": 9.371718406677246,
      "learning_rate": 1.8705378391242267e-05,
      "loss": 0.0924,
      "step": 1360
    },
    {
      "epoch": 0.6520704426463588,
      "grad_norm": 1.714665174484253,
      "learning_rate": 1.8695859114707285e-05,
      "loss": 0.1688,
      "step": 1370
    },
    {
      "epoch": 0.6568300809138505,
      "grad_norm": 7.364060878753662,
      "learning_rate": 1.86863398381723e-05,
      "loss": 0.087,
      "step": 1380
    },
    {
      "epoch": 0.6615897191813422,
      "grad_norm": 0.9769901037216187,
      "learning_rate": 1.8676820561637317e-05,
      "loss": 0.0913,
      "step": 1390
    },
    {
      "epoch": 0.6663493574488338,
      "grad_norm": 1.2286951541900635,
      "learning_rate": 1.866730128510233e-05,
      "loss": 0.1228,
      "step": 1400
    },
    {
      "epoch": 0.6711089957163255,
      "grad_norm": 9.41564655303955,
      "learning_rate": 1.8657782008567352e-05,
      "loss": 0.0795,
      "step": 1410
    },
    {
      "epoch": 0.6758686339838172,
      "grad_norm": 2.986741781234741,
      "learning_rate": 1.8648262732032367e-05,
      "loss": 0.0549,
      "step": 1420
    },
    {
      "epoch": 0.680628272251309,
      "grad_norm": 2.1767847537994385,
      "learning_rate": 1.8638743455497384e-05,
      "loss": 0.1804,
      "step": 1430
    },
    {
      "epoch": 0.6853879105188005,
      "grad_norm": 2.262586832046509,
      "learning_rate": 1.86292241789624e-05,
      "loss": 0.0756,
      "step": 1440
    },
    {
      "epoch": 0.6901475487862923,
      "grad_norm": 1.0621342658996582,
      "learning_rate": 1.861970490242742e-05,
      "loss": 0.1195,
      "step": 1450
    },
    {
      "epoch": 0.694907187053784,
      "grad_norm": 4.580076217651367,
      "learning_rate": 1.8610185625892434e-05,
      "loss": 0.0807,
      "step": 1460
    },
    {
      "epoch": 0.6996668253212756,
      "grad_norm": 6.723893165588379,
      "learning_rate": 1.860066634935745e-05,
      "loss": 0.0262,
      "step": 1470
    },
    {
      "epoch": 0.7044264635887673,
      "grad_norm": 6.2333903312683105,
      "learning_rate": 1.8591147072822466e-05,
      "loss": 0.1033,
      "step": 1480
    },
    {
      "epoch": 0.709186101856259,
      "grad_norm": 6.545727729797363,
      "learning_rate": 1.8581627796287484e-05,
      "loss": 0.0739,
      "step": 1490
    },
    {
      "epoch": 0.7139457401237506,
      "grad_norm": 1.5384306907653809,
      "learning_rate": 1.85721085197525e-05,
      "loss": 0.0598,
      "step": 1500
    },
    {
      "epoch": 0.7187053783912423,
      "grad_norm": 3.579221248626709,
      "learning_rate": 1.8562589243217516e-05,
      "loss": 0.0856,
      "step": 1510
    },
    {
      "epoch": 0.723465016658734,
      "grad_norm": 0.16384980082511902,
      "learning_rate": 1.8553069966682533e-05,
      "loss": 0.0792,
      "step": 1520
    },
    {
      "epoch": 0.7282246549262256,
      "grad_norm": 11.499221801757812,
      "learning_rate": 1.854355069014755e-05,
      "loss": 0.0449,
      "step": 1530
    },
    {
      "epoch": 0.7329842931937173,
      "grad_norm": 12.415029525756836,
      "learning_rate": 1.853403141361257e-05,
      "loss": 0.1204,
      "step": 1540
    },
    {
      "epoch": 0.737743931461209,
      "grad_norm": 4.387063980102539,
      "learning_rate": 1.8524512137077583e-05,
      "loss": 0.0991,
      "step": 1550
    },
    {
      "epoch": 0.7425035697287006,
      "grad_norm": 0.8602635860443115,
      "learning_rate": 1.85149928605426e-05,
      "loss": 0.0961,
      "step": 1560
    },
    {
      "epoch": 0.7472632079961923,
      "grad_norm": 4.070426940917969,
      "learning_rate": 1.8505473584007615e-05,
      "loss": 0.0278,
      "step": 1570
    },
    {
      "epoch": 0.752022846263684,
      "grad_norm": 17.401914596557617,
      "learning_rate": 1.8495954307472636e-05,
      "loss": 0.087,
      "step": 1580
    },
    {
      "epoch": 0.7567824845311756,
      "grad_norm": 9.272643089294434,
      "learning_rate": 1.848643503093765e-05,
      "loss": 0.0531,
      "step": 1590
    },
    {
      "epoch": 0.7615421227986673,
      "grad_norm": 4.829195499420166,
      "learning_rate": 1.8476915754402668e-05,
      "loss": 0.0275,
      "step": 1600
    },
    {
      "epoch": 0.766301761066159,
      "grad_norm": 2.032701253890991,
      "learning_rate": 1.8467396477867682e-05,
      "loss": 0.0869,
      "step": 1610
    },
    {
      "epoch": 0.7710613993336506,
      "grad_norm": 8.805901527404785,
      "learning_rate": 1.84578772013327e-05,
      "loss": 0.0996,
      "step": 1620
    },
    {
      "epoch": 0.7758210376011423,
      "grad_norm": 8.537580490112305,
      "learning_rate": 1.8448357924797718e-05,
      "loss": 0.1777,
      "step": 1630
    },
    {
      "epoch": 0.780580675868634,
      "grad_norm": 10.508255958557129,
      "learning_rate": 1.8438838648262735e-05,
      "loss": 0.114,
      "step": 1640
    },
    {
      "epoch": 0.7853403141361257,
      "grad_norm": 2.9628872871398926,
      "learning_rate": 1.842931937172775e-05,
      "loss": 0.0391,
      "step": 1650
    },
    {
      "epoch": 0.7900999524036173,
      "grad_norm": 2.045708417892456,
      "learning_rate": 1.8419800095192767e-05,
      "loss": 0.0687,
      "step": 1660
    },
    {
      "epoch": 0.794859590671109,
      "grad_norm": 4.941407680511475,
      "learning_rate": 1.8410280818657785e-05,
      "loss": 0.0204,
      "step": 1670
    },
    {
      "epoch": 0.7996192289386007,
      "grad_norm": 13.388554573059082,
      "learning_rate": 1.84007615421228e-05,
      "loss": 0.0814,
      "step": 1680
    },
    {
      "epoch": 0.8043788672060923,
      "grad_norm": 3.8873136043548584,
      "learning_rate": 1.8391242265587817e-05,
      "loss": 0.0713,
      "step": 1690
    },
    {
      "epoch": 0.809138505473584,
      "grad_norm": 0.39830365777015686,
      "learning_rate": 1.838172298905283e-05,
      "loss": 0.0373,
      "step": 1700
    },
    {
      "epoch": 0.8138981437410757,
      "grad_norm": 6.117661476135254,
      "learning_rate": 1.8372203712517852e-05,
      "loss": 0.1738,
      "step": 1710
    },
    {
      "epoch": 0.8186577820085673,
      "grad_norm": 6.3898606300354,
      "learning_rate": 1.8362684435982866e-05,
      "loss": 0.0693,
      "step": 1720
    },
    {
      "epoch": 0.823417420276059,
      "grad_norm": 0.5001547336578369,
      "learning_rate": 1.8353165159447884e-05,
      "loss": 0.0795,
      "step": 1730
    },
    {
      "epoch": 0.8281770585435507,
      "grad_norm": 0.2622721493244171,
      "learning_rate": 1.83436458829129e-05,
      "loss": 0.0742,
      "step": 1740
    },
    {
      "epoch": 0.8329366968110423,
      "grad_norm": 14.416882514953613,
      "learning_rate": 1.8334126606377916e-05,
      "loss": 0.0568,
      "step": 1750
    },
    {
      "epoch": 0.837696335078534,
      "grad_norm": 4.11686897277832,
      "learning_rate": 1.8324607329842934e-05,
      "loss": 0.0767,
      "step": 1760
    },
    {
      "epoch": 0.8424559733460257,
      "grad_norm": 9.795757293701172,
      "learning_rate": 1.831508805330795e-05,
      "loss": 0.0887,
      "step": 1770
    },
    {
      "epoch": 0.8472156116135173,
      "grad_norm": 8.744407653808594,
      "learning_rate": 1.8305568776772966e-05,
      "loss": 0.0441,
      "step": 1780
    },
    {
      "epoch": 0.851975249881009,
      "grad_norm": 0.2717302441596985,
      "learning_rate": 1.8296049500237983e-05,
      "loss": 0.0608,
      "step": 1790
    },
    {
      "epoch": 0.8567348881485007,
      "grad_norm": 4.286605358123779,
      "learning_rate": 1.8286530223703e-05,
      "loss": 0.0484,
      "step": 1800
    },
    {
      "epoch": 0.8614945264159923,
      "grad_norm": 4.997014999389648,
      "learning_rate": 1.8277010947168015e-05,
      "loss": 0.0429,
      "step": 1810
    },
    {
      "epoch": 0.866254164683484,
      "grad_norm": 0.0587678886950016,
      "learning_rate": 1.8267491670633033e-05,
      "loss": 0.1251,
      "step": 1820
    },
    {
      "epoch": 0.8710138029509757,
      "grad_norm": 6.538022994995117,
      "learning_rate": 1.825797239409805e-05,
      "loss": 0.037,
      "step": 1830
    },
    {
      "epoch": 0.8757734412184673,
      "grad_norm": 6.360406875610352,
      "learning_rate": 1.824845311756307e-05,
      "loss": 0.0422,
      "step": 1840
    },
    {
      "epoch": 0.880533079485959,
      "grad_norm": 0.062473852187395096,
      "learning_rate": 1.8238933841028083e-05,
      "loss": 0.0282,
      "step": 1850
    },
    {
      "epoch": 0.8852927177534508,
      "grad_norm": 10.55709457397461,
      "learning_rate": 1.82294145644931e-05,
      "loss": 0.047,
      "step": 1860
    },
    {
      "epoch": 0.8900523560209425,
      "grad_norm": 7.464521408081055,
      "learning_rate": 1.8219895287958115e-05,
      "loss": 0.0505,
      "step": 1870
    },
    {
      "epoch": 0.894811994288434,
      "grad_norm": 6.081567287445068,
      "learning_rate": 1.8210376011423136e-05,
      "loss": 0.0345,
      "step": 1880
    },
    {
      "epoch": 0.8995716325559258,
      "grad_norm": 5.273220539093018,
      "learning_rate": 1.820085673488815e-05,
      "loss": 0.0683,
      "step": 1890
    },
    {
      "epoch": 0.9043312708234175,
      "grad_norm": 0.06190189719200134,
      "learning_rate": 1.8191337458353168e-05,
      "loss": 0.0385,
      "step": 1900
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 7.560173034667969,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.0281,
      "step": 1910
    },
    {
      "epoch": 0.9138505473584008,
      "grad_norm": 12.995540618896484,
      "learning_rate": 1.81722989052832e-05,
      "loss": 0.0282,
      "step": 1920
    },
    {
      "epoch": 0.9186101856258925,
      "grad_norm": 0.03393641114234924,
      "learning_rate": 1.8162779628748217e-05,
      "loss": 0.055,
      "step": 1930
    },
    {
      "epoch": 0.9233698238933841,
      "grad_norm": 4.010807991027832,
      "learning_rate": 1.8153260352213232e-05,
      "loss": 0.0827,
      "step": 1940
    },
    {
      "epoch": 0.9281294621608758,
      "grad_norm": 7.589725494384766,
      "learning_rate": 1.814374107567825e-05,
      "loss": 0.0637,
      "step": 1950
    },
    {
      "epoch": 0.9328891004283675,
      "grad_norm": 6.268659591674805,
      "learning_rate": 1.8134221799143267e-05,
      "loss": 0.1213,
      "step": 1960
    },
    {
      "epoch": 0.9376487386958591,
      "grad_norm": 2.1807467937469482,
      "learning_rate": 1.8124702522608285e-05,
      "loss": 0.0964,
      "step": 1970
    },
    {
      "epoch": 0.9424083769633508,
      "grad_norm": 8.372084617614746,
      "learning_rate": 1.81151832460733e-05,
      "loss": 0.0493,
      "step": 1980
    },
    {
      "epoch": 0.9471680152308425,
      "grad_norm": 5.557323932647705,
      "learning_rate": 1.8105663969538317e-05,
      "loss": 0.0708,
      "step": 1990
    },
    {
      "epoch": 0.9519276534983341,
      "grad_norm": 4.241034984588623,
      "learning_rate": 1.809614469300333e-05,
      "loss": 0.0671,
      "step": 2000
    },
    {
      "epoch": 0.9566872917658258,
      "grad_norm": 0.37831196188926697,
      "learning_rate": 1.8086625416468352e-05,
      "loss": 0.0535,
      "step": 2010
    },
    {
      "epoch": 0.9614469300333175,
      "grad_norm": 5.908089637756348,
      "learning_rate": 1.8077106139933366e-05,
      "loss": 0.0542,
      "step": 2020
    },
    {
      "epoch": 0.9662065683008091,
      "grad_norm": 0.04894794896245003,
      "learning_rate": 1.8067586863398384e-05,
      "loss": 0.0809,
      "step": 2030
    },
    {
      "epoch": 0.9709662065683008,
      "grad_norm": 0.6857137680053711,
      "learning_rate": 1.80580675868634e-05,
      "loss": 0.0677,
      "step": 2040
    },
    {
      "epoch": 0.9757258448357925,
      "grad_norm": 1.8791842460632324,
      "learning_rate": 1.8048548310328416e-05,
      "loss": 0.0448,
      "step": 2050
    },
    {
      "epoch": 0.9804854831032842,
      "grad_norm": 8.128249168395996,
      "learning_rate": 1.8039029033793434e-05,
      "loss": 0.0476,
      "step": 2060
    },
    {
      "epoch": 0.9852451213707758,
      "grad_norm": 0.08850836008787155,
      "learning_rate": 1.802950975725845e-05,
      "loss": 0.0363,
      "step": 2070
    },
    {
      "epoch": 0.9900047596382675,
      "grad_norm": 1.3701727390289307,
      "learning_rate": 1.8019990480723466e-05,
      "loss": 0.078,
      "step": 2080
    },
    {
      "epoch": 0.9947643979057592,
      "grad_norm": 0.7740893959999084,
      "learning_rate": 1.8010471204188483e-05,
      "loss": 0.0375,
      "step": 2090
    },
    {
      "epoch": 0.9995240361732508,
      "grad_norm": 0.11549653857946396,
      "learning_rate": 1.80009519276535e-05,
      "loss": 0.0834,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9834813992226541,
      "eval_f1": 0.908672294704528,
      "eval_loss": 0.05829838663339615,
      "eval_precision": 0.9293563579277865,
      "eval_recall": 0.8888888888888888,
      "eval_runtime": 2097.8916,
      "eval_samples_per_second": 6.869,
      "eval_steps_per_second": 0.859,
      "step": 2101
    },
    {
      "epoch": 1.0042836744407424,
      "grad_norm": 0.11271949857473373,
      "learning_rate": 1.7991432651118515e-05,
      "loss": 0.0198,
      "step": 2110
    },
    {
      "epoch": 1.009043312708234,
      "grad_norm": 0.05204743891954422,
      "learning_rate": 1.7981913374583533e-05,
      "loss": 0.0623,
      "step": 2120
    },
    {
      "epoch": 1.0138029509757258,
      "grad_norm": 9.664225578308105,
      "learning_rate": 1.7972394098048547e-05,
      "loss": 0.0144,
      "step": 2130
    },
    {
      "epoch": 1.0185625892432175,
      "grad_norm": 9.496969223022461,
      "learning_rate": 1.796287482151357e-05,
      "loss": 0.1177,
      "step": 2140
    },
    {
      "epoch": 1.0233222275107092,
      "grad_norm": 0.10735820978879929,
      "learning_rate": 1.7953355544978583e-05,
      "loss": 0.0215,
      "step": 2150
    },
    {
      "epoch": 1.028081865778201,
      "grad_norm": 1.1223819255828857,
      "learning_rate": 1.79438362684436e-05,
      "loss": 0.0656,
      "step": 2160
    },
    {
      "epoch": 1.0328415040456926,
      "grad_norm": 1.679848313331604,
      "learning_rate": 1.7934316991908615e-05,
      "loss": 0.0548,
      "step": 2170
    },
    {
      "epoch": 1.0376011423131841,
      "grad_norm": 0.164136603474617,
      "learning_rate": 1.7924797715373636e-05,
      "loss": 0.025,
      "step": 2180
    },
    {
      "epoch": 1.0423607805806758,
      "grad_norm": 0.08134394139051437,
      "learning_rate": 1.791527843883865e-05,
      "loss": 0.0674,
      "step": 2190
    },
    {
      "epoch": 1.0471204188481675,
      "grad_norm": 0.27672168612480164,
      "learning_rate": 1.7905759162303668e-05,
      "loss": 0.0498,
      "step": 2200
    },
    {
      "epoch": 1.0518800571156592,
      "grad_norm": 3.9480795860290527,
      "learning_rate": 1.7896239885768682e-05,
      "loss": 0.0737,
      "step": 2210
    },
    {
      "epoch": 1.056639695383151,
      "grad_norm": 3.0407369136810303,
      "learning_rate": 1.78867206092337e-05,
      "loss": 0.0353,
      "step": 2220
    },
    {
      "epoch": 1.0613993336506427,
      "grad_norm": 8.18970012664795,
      "learning_rate": 1.7877201332698717e-05,
      "loss": 0.055,
      "step": 2230
    },
    {
      "epoch": 1.0661589719181341,
      "grad_norm": 14.423070907592773,
      "learning_rate": 1.786768205616373e-05,
      "loss": 0.0807,
      "step": 2240
    },
    {
      "epoch": 1.0709186101856258,
      "grad_norm": 0.09814825654029846,
      "learning_rate": 1.785816277962875e-05,
      "loss": 0.0659,
      "step": 2250
    },
    {
      "epoch": 1.0756782484531175,
      "grad_norm": 0.1480841040611267,
      "learning_rate": 1.7848643503093767e-05,
      "loss": 0.0339,
      "step": 2260
    },
    {
      "epoch": 1.0804378867206093,
      "grad_norm": 0.589041531085968,
      "learning_rate": 1.7839124226558785e-05,
      "loss": 0.0419,
      "step": 2270
    },
    {
      "epoch": 1.085197524988101,
      "grad_norm": 2.9425837993621826,
      "learning_rate": 1.78296049500238e-05,
      "loss": 0.014,
      "step": 2280
    },
    {
      "epoch": 1.0899571632555927,
      "grad_norm": 0.029340092092752457,
      "learning_rate": 1.7820085673488817e-05,
      "loss": 0.0425,
      "step": 2290
    },
    {
      "epoch": 1.0947168015230841,
      "grad_norm": 0.028293047100305557,
      "learning_rate": 1.781056639695383e-05,
      "loss": 0.0384,
      "step": 2300
    },
    {
      "epoch": 1.0994764397905759,
      "grad_norm": 2.3891232013702393,
      "learning_rate": 1.7801047120418852e-05,
      "loss": 0.0673,
      "step": 2310
    },
    {
      "epoch": 1.1042360780580676,
      "grad_norm": 10.81521987915039,
      "learning_rate": 1.7791527843883866e-05,
      "loss": 0.0526,
      "step": 2320
    },
    {
      "epoch": 1.1089957163255593,
      "grad_norm": 10.809622764587402,
      "learning_rate": 1.7782008567348884e-05,
      "loss": 0.0168,
      "step": 2330
    },
    {
      "epoch": 1.113755354593051,
      "grad_norm": 2.7816081047058105,
      "learning_rate": 1.7772489290813898e-05,
      "loss": 0.0355,
      "step": 2340
    },
    {
      "epoch": 1.1185149928605427,
      "grad_norm": 0.031612079590559006,
      "learning_rate": 1.7762970014278916e-05,
      "loss": 0.0376,
      "step": 2350
    },
    {
      "epoch": 1.1232746311280342,
      "grad_norm": 0.05269588157534599,
      "learning_rate": 1.7753450737743934e-05,
      "loss": 0.0324,
      "step": 2360
    },
    {
      "epoch": 1.1280342693955259,
      "grad_norm": 4.236595630645752,
      "learning_rate": 1.774393146120895e-05,
      "loss": 0.0587,
      "step": 2370
    },
    {
      "epoch": 1.1327939076630176,
      "grad_norm": 12.616250991821289,
      "learning_rate": 1.7734412184673966e-05,
      "loss": 0.0472,
      "step": 2380
    },
    {
      "epoch": 1.1375535459305093,
      "grad_norm": 13.512287139892578,
      "learning_rate": 1.7724892908138983e-05,
      "loss": 0.0616,
      "step": 2390
    },
    {
      "epoch": 1.142313184198001,
      "grad_norm": 13.414149284362793,
      "learning_rate": 1.7715373631604e-05,
      "loss": 0.0294,
      "step": 2400
    },
    {
      "epoch": 1.1470728224654927,
      "grad_norm": 5.358880519866943,
      "learning_rate": 1.7705854355069015e-05,
      "loss": 0.0461,
      "step": 2410
    },
    {
      "epoch": 1.1518324607329844,
      "grad_norm": 8.876961708068848,
      "learning_rate": 1.7696335078534033e-05,
      "loss": 0.0607,
      "step": 2420
    },
    {
      "epoch": 1.1565920990004759,
      "grad_norm": 5.825039863586426,
      "learning_rate": 1.7686815801999047e-05,
      "loss": 0.0385,
      "step": 2430
    },
    {
      "epoch": 1.1613517372679676,
      "grad_norm": 2.235405206680298,
      "learning_rate": 1.767729652546407e-05,
      "loss": 0.007,
      "step": 2440
    },
    {
      "epoch": 1.1661113755354593,
      "grad_norm": 0.4963850975036621,
      "learning_rate": 1.7667777248929083e-05,
      "loss": 0.0385,
      "step": 2450
    },
    {
      "epoch": 1.170871013802951,
      "grad_norm": 1.716356873512268,
      "learning_rate": 1.76582579723941e-05,
      "loss": 0.0475,
      "step": 2460
    },
    {
      "epoch": 1.1756306520704427,
      "grad_norm": 0.12258227914571762,
      "learning_rate": 1.7648738695859115e-05,
      "loss": 0.041,
      "step": 2470
    },
    {
      "epoch": 1.1803902903379344,
      "grad_norm": 6.597509860992432,
      "learning_rate": 1.7639219419324132e-05,
      "loss": 0.0359,
      "step": 2480
    },
    {
      "epoch": 1.185149928605426,
      "grad_norm": 0.021243130788207054,
      "learning_rate": 1.762970014278915e-05,
      "loss": 0.037,
      "step": 2490
    },
    {
      "epoch": 1.1899095668729176,
      "grad_norm": 4.082324028015137,
      "learning_rate": 1.7620180866254168e-05,
      "loss": 0.0547,
      "step": 2500
    },
    {
      "epoch": 1.1946692051404093,
      "grad_norm": 11.074426651000977,
      "learning_rate": 1.7610661589719182e-05,
      "loss": 0.0745,
      "step": 2510
    },
    {
      "epoch": 1.199428843407901,
      "grad_norm": 0.014179902151226997,
      "learning_rate": 1.76011423131842e-05,
      "loss": 0.0385,
      "step": 2520
    },
    {
      "epoch": 1.2041884816753927,
      "grad_norm": 5.970277309417725,
      "learning_rate": 1.7591623036649217e-05,
      "loss": 0.0821,
      "step": 2530
    },
    {
      "epoch": 1.2089481199428844,
      "grad_norm": 0.014822101220488548,
      "learning_rate": 1.758210376011423e-05,
      "loss": 0.0809,
      "step": 2540
    },
    {
      "epoch": 1.2137077582103761,
      "grad_norm": 0.016849005594849586,
      "learning_rate": 1.757258448357925e-05,
      "loss": 0.0097,
      "step": 2550
    },
    {
      "epoch": 1.2184673964778676,
      "grad_norm": 9.641029357910156,
      "learning_rate": 1.7563065207044267e-05,
      "loss": 0.0461,
      "step": 2560
    },
    {
      "epoch": 1.2232270347453593,
      "grad_norm": 0.7854403257369995,
      "learning_rate": 1.7553545930509285e-05,
      "loss": 0.0489,
      "step": 2570
    },
    {
      "epoch": 1.227986673012851,
      "grad_norm": 0.053466327488422394,
      "learning_rate": 1.75440266539743e-05,
      "loss": 0.0085,
      "step": 2580
    },
    {
      "epoch": 1.2327463112803427,
      "grad_norm": 0.33948442339897156,
      "learning_rate": 1.7534507377439317e-05,
      "loss": 0.015,
      "step": 2590
    },
    {
      "epoch": 1.2375059495478344,
      "grad_norm": 15.475770950317383,
      "learning_rate": 1.752498810090433e-05,
      "loss": 0.0693,
      "step": 2600
    },
    {
      "epoch": 1.242265587815326,
      "grad_norm": 4.558818340301514,
      "learning_rate": 1.751546882436935e-05,
      "loss": 0.0451,
      "step": 2610
    },
    {
      "epoch": 1.2470252260828176,
      "grad_norm": 0.019386082887649536,
      "learning_rate": 1.7505949547834366e-05,
      "loss": 0.021,
      "step": 2620
    },
    {
      "epoch": 1.2517848643503093,
      "grad_norm": 25.269575119018555,
      "learning_rate": 1.7496430271299384e-05,
      "loss": 0.0367,
      "step": 2630
    },
    {
      "epoch": 1.256544502617801,
      "grad_norm": 7.499607563018799,
      "learning_rate": 1.7486910994764398e-05,
      "loss": 0.0294,
      "step": 2640
    },
    {
      "epoch": 1.2613041408852927,
      "grad_norm": 3.3241167068481445,
      "learning_rate": 1.7477391718229416e-05,
      "loss": 0.0427,
      "step": 2650
    },
    {
      "epoch": 1.2660637791527845,
      "grad_norm": 1.2802292108535767,
      "learning_rate": 1.7467872441694434e-05,
      "loss": 0.0424,
      "step": 2660
    },
    {
      "epoch": 1.2708234174202762,
      "grad_norm": 0.011531379073858261,
      "learning_rate": 1.745835316515945e-05,
      "loss": 0.0402,
      "step": 2670
    },
    {
      "epoch": 1.2755830556877679,
      "grad_norm": 0.011086961254477501,
      "learning_rate": 1.7448833888624466e-05,
      "loss": 0.0336,
      "step": 2680
    },
    {
      "epoch": 1.2803426939552593,
      "grad_norm": 0.013518390245735645,
      "learning_rate": 1.7439314612089483e-05,
      "loss": 0.0589,
      "step": 2690
    },
    {
      "epoch": 1.285102332222751,
      "grad_norm": 18.626144409179688,
      "learning_rate": 1.74297953355545e-05,
      "loss": 0.0333,
      "step": 2700
    },
    {
      "epoch": 1.2898619704902428,
      "grad_norm": 6.261401176452637,
      "learning_rate": 1.7420276059019515e-05,
      "loss": 0.0218,
      "step": 2710
    },
    {
      "epoch": 1.2946216087577345,
      "grad_norm": 1.0734986066818237,
      "learning_rate": 1.7410756782484533e-05,
      "loss": 0.0514,
      "step": 2720
    },
    {
      "epoch": 1.299381247025226,
      "grad_norm": 0.3545148968696594,
      "learning_rate": 1.7401237505949547e-05,
      "loss": 0.0278,
      "step": 2730
    },
    {
      "epoch": 1.3041408852927177,
      "grad_norm": 7.767757415771484,
      "learning_rate": 1.7391718229414568e-05,
      "loss": 0.0168,
      "step": 2740
    },
    {
      "epoch": 1.3089005235602094,
      "grad_norm": 0.23948660492897034,
      "learning_rate": 1.7382198952879583e-05,
      "loss": 0.0194,
      "step": 2750
    },
    {
      "epoch": 1.313660161827701,
      "grad_norm": 0.06454723328351974,
      "learning_rate": 1.73726796763446e-05,
      "loss": 0.0125,
      "step": 2760
    },
    {
      "epoch": 1.3184198000951928,
      "grad_norm": 0.19032587110996246,
      "learning_rate": 1.7363160399809614e-05,
      "loss": 0.0315,
      "step": 2770
    },
    {
      "epoch": 1.3231794383626845,
      "grad_norm": 72.15591430664062,
      "learning_rate": 1.7353641123274632e-05,
      "loss": 0.0343,
      "step": 2780
    },
    {
      "epoch": 1.3279390766301762,
      "grad_norm": 12.852803230285645,
      "learning_rate": 1.734412184673965e-05,
      "loss": 0.0757,
      "step": 2790
    },
    {
      "epoch": 1.332698714897668,
      "grad_norm": 0.012274621054530144,
      "learning_rate": 1.7334602570204668e-05,
      "loss": 0.0262,
      "step": 2800
    },
    {
      "epoch": 1.3374583531651594,
      "grad_norm": 0.03856063634157181,
      "learning_rate": 1.7325083293669682e-05,
      "loss": 0.0326,
      "step": 2810
    },
    {
      "epoch": 1.342217991432651,
      "grad_norm": 3.74580454826355,
      "learning_rate": 1.73155640171347e-05,
      "loss": 0.0578,
      "step": 2820
    },
    {
      "epoch": 1.3469776297001428,
      "grad_norm": 0.06378761678934097,
      "learning_rate": 1.7306044740599717e-05,
      "loss": 0.0776,
      "step": 2830
    },
    {
      "epoch": 1.3517372679676345,
      "grad_norm": 0.27209895849227905,
      "learning_rate": 1.729652546406473e-05,
      "loss": 0.0406,
      "step": 2840
    },
    {
      "epoch": 1.3564969062351262,
      "grad_norm": 10.36189079284668,
      "learning_rate": 1.728700618752975e-05,
      "loss": 0.0369,
      "step": 2850
    },
    {
      "epoch": 1.3612565445026177,
      "grad_norm": 0.0778898075222969,
      "learning_rate": 1.7277486910994767e-05,
      "loss": 0.0452,
      "step": 2860
    },
    {
      "epoch": 1.3660161827701094,
      "grad_norm": 13.138031005859375,
      "learning_rate": 1.7267967634459785e-05,
      "loss": 0.0718,
      "step": 2870
    },
    {
      "epoch": 1.370775821037601,
      "grad_norm": 3.860842704772949,
      "learning_rate": 1.72584483579248e-05,
      "loss": 0.0061,
      "step": 2880
    },
    {
      "epoch": 1.3755354593050928,
      "grad_norm": 0.01563156582415104,
      "learning_rate": 1.7248929081389816e-05,
      "loss": 0.1003,
      "step": 2890
    },
    {
      "epoch": 1.3802950975725845,
      "grad_norm": 0.12155959755182266,
      "learning_rate": 1.723940980485483e-05,
      "loss": 0.006,
      "step": 2900
    },
    {
      "epoch": 1.3850547358400762,
      "grad_norm": 3.5844974517822266,
      "learning_rate": 1.722989052831985e-05,
      "loss": 0.0243,
      "step": 2910
    },
    {
      "epoch": 1.389814374107568,
      "grad_norm": 0.08051934838294983,
      "learning_rate": 1.7220371251784866e-05,
      "loss": 0.0332,
      "step": 2920
    },
    {
      "epoch": 1.3945740123750596,
      "grad_norm": 5.334224224090576,
      "learning_rate": 1.7210851975249884e-05,
      "loss": 0.0327,
      "step": 2930
    },
    {
      "epoch": 1.399333650642551,
      "grad_norm": 8.45775318145752,
      "learning_rate": 1.7201332698714898e-05,
      "loss": 0.0238,
      "step": 2940
    },
    {
      "epoch": 1.4040932889100428,
      "grad_norm": 0.015045231208205223,
      "learning_rate": 1.7191813422179916e-05,
      "loss": 0.0162,
      "step": 2950
    },
    {
      "epoch": 1.4088529271775345,
      "grad_norm": 0.007870025001466274,
      "learning_rate": 1.7182294145644933e-05,
      "loss": 0.0316,
      "step": 2960
    },
    {
      "epoch": 1.4136125654450262,
      "grad_norm": 0.004092398565262556,
      "learning_rate": 1.7172774869109948e-05,
      "loss": 0.0446,
      "step": 2970
    },
    {
      "epoch": 1.418372203712518,
      "grad_norm": 0.9498487710952759,
      "learning_rate": 1.7163255592574965e-05,
      "loss": 0.031,
      "step": 2980
    },
    {
      "epoch": 1.4231318419800094,
      "grad_norm": 0.017453547567129135,
      "learning_rate": 1.7153736316039983e-05,
      "loss": 0.0321,
      "step": 2990
    },
    {
      "epoch": 1.4278914802475011,
      "grad_norm": 4.207852840423584,
      "learning_rate": 1.7144217039505e-05,
      "loss": 0.0665,
      "step": 3000
    },
    {
      "epoch": 1.4326511185149928,
      "grad_norm": 0.4343067705631256,
      "learning_rate": 1.7134697762970015e-05,
      "loss": 0.0249,
      "step": 3010
    },
    {
      "epoch": 1.4374107567824845,
      "grad_norm": 4.685281276702881,
      "learning_rate": 1.7125178486435033e-05,
      "loss": 0.0203,
      "step": 3020
    },
    {
      "epoch": 1.4421703950499762,
      "grad_norm": 4.052454948425293,
      "learning_rate": 1.7115659209900047e-05,
      "loss": 0.0698,
      "step": 3030
    },
    {
      "epoch": 1.446930033317468,
      "grad_norm": 0.06260048598051071,
      "learning_rate": 1.7106139933365065e-05,
      "loss": 0.0409,
      "step": 3040
    },
    {
      "epoch": 1.4516896715849597,
      "grad_norm": 0.011647152714431286,
      "learning_rate": 1.7096620656830082e-05,
      "loss": 0.0209,
      "step": 3050
    },
    {
      "epoch": 1.4564493098524511,
      "grad_norm": 0.04868408665060997,
      "learning_rate": 1.70871013802951e-05,
      "loss": 0.0014,
      "step": 3060
    },
    {
      "epoch": 1.4612089481199428,
      "grad_norm": 0.14080044627189636,
      "learning_rate": 1.7077582103760114e-05,
      "loss": 0.0562,
      "step": 3070
    },
    {
      "epoch": 1.4659685863874345,
      "grad_norm": 5.288638114929199,
      "learning_rate": 1.7068062827225132e-05,
      "loss": 0.0489,
      "step": 3080
    },
    {
      "epoch": 1.4707282246549263,
      "grad_norm": 2.3065154552459717,
      "learning_rate": 1.705854355069015e-05,
      "loss": 0.0235,
      "step": 3090
    },
    {
      "epoch": 1.475487862922418,
      "grad_norm": 0.007916592992842197,
      "learning_rate": 1.7049024274155167e-05,
      "loss": 0.031,
      "step": 3100
    },
    {
      "epoch": 1.4802475011899094,
      "grad_norm": 0.020168237388134003,
      "learning_rate": 1.7039504997620182e-05,
      "loss": 0.0416,
      "step": 3110
    },
    {
      "epoch": 1.4850071394574011,
      "grad_norm": 2.462646245956421,
      "learning_rate": 1.70299857210852e-05,
      "loss": 0.0251,
      "step": 3120
    },
    {
      "epoch": 1.4897667777248929,
      "grad_norm": 5.933987140655518,
      "learning_rate": 1.7020466444550217e-05,
      "loss": 0.0054,
      "step": 3130
    },
    {
      "epoch": 1.4945264159923846,
      "grad_norm": 0.17551152408123016,
      "learning_rate": 1.701094716801523e-05,
      "loss": 0.0095,
      "step": 3140
    },
    {
      "epoch": 1.4992860542598763,
      "grad_norm": 7.5503363609313965,
      "learning_rate": 1.700142789148025e-05,
      "loss": 0.0381,
      "step": 3150
    },
    {
      "epoch": 1.504045692527368,
      "grad_norm": 0.16594330966472626,
      "learning_rate": 1.6991908614945263e-05,
      "loss": 0.022,
      "step": 3160
    },
    {
      "epoch": 1.5088053307948597,
      "grad_norm": 0.47873029112815857,
      "learning_rate": 1.698238933841028e-05,
      "loss": 0.019,
      "step": 3170
    },
    {
      "epoch": 1.5135649690623514,
      "grad_norm": 0.024034852162003517,
      "learning_rate": 1.69728700618753e-05,
      "loss": 0.0222,
      "step": 3180
    },
    {
      "epoch": 1.518324607329843,
      "grad_norm": 0.01785522885620594,
      "learning_rate": 1.6963350785340316e-05,
      "loss": 0.0282,
      "step": 3190
    },
    {
      "epoch": 1.5230842455973346,
      "grad_norm": 0.0135260708630085,
      "learning_rate": 1.695383150880533e-05,
      "loss": 0.0106,
      "step": 3200
    },
    {
      "epoch": 1.5278438838648263,
      "grad_norm": 0.1698230654001236,
      "learning_rate": 1.694431223227035e-05,
      "loss": 0.0278,
      "step": 3210
    },
    {
      "epoch": 1.532603522132318,
      "grad_norm": 0.07336530089378357,
      "learning_rate": 1.6934792955735366e-05,
      "loss": 0.0242,
      "step": 3220
    },
    {
      "epoch": 1.5373631603998095,
      "grad_norm": 0.13205212354660034,
      "learning_rate": 1.6925273679200384e-05,
      "loss": 0.0877,
      "step": 3230
    },
    {
      "epoch": 1.5421227986673012,
      "grad_norm": 0.2109367847442627,
      "learning_rate": 1.6915754402665398e-05,
      "loss": 0.0228,
      "step": 3240
    },
    {
      "epoch": 1.5468824369347929,
      "grad_norm": 0.20594534277915955,
      "learning_rate": 1.6906235126130416e-05,
      "loss": 0.0059,
      "step": 3250
    },
    {
      "epoch": 1.5516420752022846,
      "grad_norm": 0.15817703306674957,
      "learning_rate": 1.6896715849595433e-05,
      "loss": 0.0574,
      "step": 3260
    },
    {
      "epoch": 1.5564017134697763,
      "grad_norm": 0.009275685995817184,
      "learning_rate": 1.6887196573060448e-05,
      "loss": 0.0178,
      "step": 3270
    },
    {
      "epoch": 1.561161351737268,
      "grad_norm": 7.203000545501709,
      "learning_rate": 1.6877677296525465e-05,
      "loss": 0.0548,
      "step": 3280
    },
    {
      "epoch": 1.5659209900047597,
      "grad_norm": 7.190640926361084,
      "learning_rate": 1.6868158019990483e-05,
      "loss": 0.0609,
      "step": 3290
    },
    {
      "epoch": 1.5706806282722514,
      "grad_norm": 0.04780232906341553,
      "learning_rate": 1.6858638743455497e-05,
      "loss": 0.0504,
      "step": 3300
    },
    {
      "epoch": 1.5754402665397431,
      "grad_norm": 10.68448257446289,
      "learning_rate": 1.6849119466920515e-05,
      "loss": 0.0087,
      "step": 3310
    },
    {
      "epoch": 1.5801999048072346,
      "grad_norm": 0.5025708079338074,
      "learning_rate": 1.6839600190385533e-05,
      "loss": 0.0512,
      "step": 3320
    },
    {
      "epoch": 1.5849595430747263,
      "grad_norm": 1.2186412811279297,
      "learning_rate": 1.6830080913850547e-05,
      "loss": 0.0046,
      "step": 3330
    },
    {
      "epoch": 1.589719181342218,
      "grad_norm": 8.16167163848877,
      "learning_rate": 1.6820561637315565e-05,
      "loss": 0.0518,
      "step": 3340
    },
    {
      "epoch": 1.5944788196097095,
      "grad_norm": 0.13072752952575684,
      "learning_rate": 1.6811042360780582e-05,
      "loss": 0.0479,
      "step": 3350
    },
    {
      "epoch": 1.5992384578772012,
      "grad_norm": 4.599093437194824,
      "learning_rate": 1.68015230842456e-05,
      "loss": 0.0176,
      "step": 3360
    },
    {
      "epoch": 1.603998096144693,
      "grad_norm": 13.654175758361816,
      "learning_rate": 1.6792003807710614e-05,
      "loss": 0.0805,
      "step": 3370
    },
    {
      "epoch": 1.6087577344121846,
      "grad_norm": 7.488414764404297,
      "learning_rate": 1.6782484531175632e-05,
      "loss": 0.0378,
      "step": 3380
    },
    {
      "epoch": 1.6135173726796763,
      "grad_norm": 8.502325057983398,
      "learning_rate": 1.677296525464065e-05,
      "loss": 0.0264,
      "step": 3390
    },
    {
      "epoch": 1.618277010947168,
      "grad_norm": 0.044379767030477524,
      "learning_rate": 1.6763445978105667e-05,
      "loss": 0.0478,
      "step": 3400
    },
    {
      "epoch": 1.6230366492146597,
      "grad_norm": 0.10754481703042984,
      "learning_rate": 1.675392670157068e-05,
      "loss": 0.027,
      "step": 3410
    },
    {
      "epoch": 1.6277962874821514,
      "grad_norm": 0.04318791255354881,
      "learning_rate": 1.67444074250357e-05,
      "loss": 0.0007,
      "step": 3420
    },
    {
      "epoch": 1.6325559257496431,
      "grad_norm": 0.1393500566482544,
      "learning_rate": 1.6734888148500717e-05,
      "loss": 0.0469,
      "step": 3430
    },
    {
      "epoch": 1.6373155640171349,
      "grad_norm": 0.050414904952049255,
      "learning_rate": 1.672536887196573e-05,
      "loss": 0.0056,
      "step": 3440
    },
    {
      "epoch": 1.6420752022846263,
      "grad_norm": 0.3733612298965454,
      "learning_rate": 1.671584959543075e-05,
      "loss": 0.0301,
      "step": 3450
    },
    {
      "epoch": 1.646834840552118,
      "grad_norm": 22.183469772338867,
      "learning_rate": 1.6706330318895763e-05,
      "loss": 0.0806,
      "step": 3460
    },
    {
      "epoch": 1.6515944788196097,
      "grad_norm": 0.0038167349994182587,
      "learning_rate": 1.669681104236078e-05,
      "loss": 0.0159,
      "step": 3470
    },
    {
      "epoch": 1.6563541170871012,
      "grad_norm": 0.06774680316448212,
      "learning_rate": 1.66872917658258e-05,
      "loss": 0.021,
      "step": 3480
    },
    {
      "epoch": 1.661113755354593,
      "grad_norm": 2.882654905319214,
      "learning_rate": 1.6677772489290816e-05,
      "loss": 0.0253,
      "step": 3490
    },
    {
      "epoch": 1.6658733936220846,
      "grad_norm": 0.18557484447956085,
      "learning_rate": 1.666825321275583e-05,
      "loss": 0.0112,
      "step": 3500
    },
    {
      "epoch": 1.6706330318895763,
      "grad_norm": 0.008141700178384781,
      "learning_rate": 1.6658733936220848e-05,
      "loss": 0.0291,
      "step": 3510
    },
    {
      "epoch": 1.675392670157068,
      "grad_norm": 0.035392288118600845,
      "learning_rate": 1.6649214659685866e-05,
      "loss": 0.0343,
      "step": 3520
    },
    {
      "epoch": 1.6801523084245598,
      "grad_norm": 0.11870324611663818,
      "learning_rate": 1.6639695383150884e-05,
      "loss": 0.0332,
      "step": 3530
    },
    {
      "epoch": 1.6849119466920515,
      "grad_norm": 1.1657068729400635,
      "learning_rate": 1.6630176106615898e-05,
      "loss": 0.03,
      "step": 3540
    },
    {
      "epoch": 1.6896715849595432,
      "grad_norm": 0.00468467315658927,
      "learning_rate": 1.6620656830080916e-05,
      "loss": 0.0629,
      "step": 3550
    },
    {
      "epoch": 1.6944312232270349,
      "grad_norm": 16.438077926635742,
      "learning_rate": 1.6611137553545933e-05,
      "loss": 0.0465,
      "step": 3560
    },
    {
      "epoch": 1.6991908614945264,
      "grad_norm": 0.011178752407431602,
      "learning_rate": 1.6601618277010948e-05,
      "loss": 0.0244,
      "step": 3570
    },
    {
      "epoch": 1.703950499762018,
      "grad_norm": 0.00983483251184225,
      "learning_rate": 1.6592099000475965e-05,
      "loss": 0.0195,
      "step": 3580
    },
    {
      "epoch": 1.7087101380295098,
      "grad_norm": 0.6344114542007446,
      "learning_rate": 1.6582579723940983e-05,
      "loss": 0.002,
      "step": 3590
    },
    {
      "epoch": 1.7134697762970015,
      "grad_norm": 0.007057092618197203,
      "learning_rate": 1.6573060447405997e-05,
      "loss": 0.0298,
      "step": 3600
    },
    {
      "epoch": 1.718229414564493,
      "grad_norm": 0.028344742953777313,
      "learning_rate": 1.6563541170871015e-05,
      "loss": 0.075,
      "step": 3610
    },
    {
      "epoch": 1.7229890528319847,
      "grad_norm": 0.15787193179130554,
      "learning_rate": 1.6554021894336033e-05,
      "loss": 0.0325,
      "step": 3620
    },
    {
      "epoch": 1.7277486910994764,
      "grad_norm": 1.6012505292892456,
      "learning_rate": 1.6544502617801047e-05,
      "loss": 0.0011,
      "step": 3630
    },
    {
      "epoch": 1.732508329366968,
      "grad_norm": 0.24573133885860443,
      "learning_rate": 1.6534983341266065e-05,
      "loss": 0.0492,
      "step": 3640
    },
    {
      "epoch": 1.7372679676344598,
      "grad_norm": 0.012514255940914154,
      "learning_rate": 1.6525464064731082e-05,
      "loss": 0.026,
      "step": 3650
    },
    {
      "epoch": 1.7420276059019515,
      "grad_norm": 10.424042701721191,
      "learning_rate": 1.65159447881961e-05,
      "loss": 0.0244,
      "step": 3660
    },
    {
      "epoch": 1.7467872441694432,
      "grad_norm": 0.02966209687292576,
      "learning_rate": 1.6506425511661114e-05,
      "loss": 0.0238,
      "step": 3670
    },
    {
      "epoch": 1.751546882436935,
      "grad_norm": 17.093130111694336,
      "learning_rate": 1.6496906235126132e-05,
      "loss": 0.0325,
      "step": 3680
    },
    {
      "epoch": 1.7563065207044266,
      "grad_norm": 0.04796610400080681,
      "learning_rate": 1.648738695859115e-05,
      "loss": 0.022,
      "step": 3690
    },
    {
      "epoch": 1.761066158971918,
      "grad_norm": 0.48154085874557495,
      "learning_rate": 1.6477867682056167e-05,
      "loss": 0.0101,
      "step": 3700
    },
    {
      "epoch": 1.7658257972394098,
      "grad_norm": 0.018836339935660362,
      "learning_rate": 1.646834840552118e-05,
      "loss": 0.077,
      "step": 3710
    },
    {
      "epoch": 1.7705854355069015,
      "grad_norm": 0.009223704226315022,
      "learning_rate": 1.64588291289862e-05,
      "loss": 0.0239,
      "step": 3720
    },
    {
      "epoch": 1.775345073774393,
      "grad_norm": 0.0306189376860857,
      "learning_rate": 1.6449309852451214e-05,
      "loss": 0.0378,
      "step": 3730
    },
    {
      "epoch": 1.7801047120418847,
      "grad_norm": 0.4532524049282074,
      "learning_rate": 1.643979057591623e-05,
      "loss": 0.0093,
      "step": 3740
    },
    {
      "epoch": 1.7848643503093764,
      "grad_norm": 8.10573959350586,
      "learning_rate": 1.643027129938125e-05,
      "loss": 0.0183,
      "step": 3750
    },
    {
      "epoch": 1.789623988576868,
      "grad_norm": 0.026446258649230003,
      "learning_rate": 1.6420752022846263e-05,
      "loss": 0.0193,
      "step": 3760
    },
    {
      "epoch": 1.7943836268443598,
      "grad_norm": 0.024220526218414307,
      "learning_rate": 1.641123274631128e-05,
      "loss": 0.0013,
      "step": 3770
    },
    {
      "epoch": 1.7991432651118515,
      "grad_norm": 0.23937200009822845,
      "learning_rate": 1.64017134697763e-05,
      "loss": 0.0183,
      "step": 3780
    },
    {
      "epoch": 1.8039029033793432,
      "grad_norm": 11.40485954284668,
      "learning_rate": 1.6392194193241316e-05,
      "loss": 0.0484,
      "step": 3790
    },
    {
      "epoch": 1.808662541646835,
      "grad_norm": 8.186749458312988,
      "learning_rate": 1.638267491670633e-05,
      "loss": 0.0316,
      "step": 3800
    },
    {
      "epoch": 1.8134221799143266,
      "grad_norm": 0.00533039728179574,
      "learning_rate": 1.6373155640171348e-05,
      "loss": 0.0447,
      "step": 3810
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.008946407586336136,
      "learning_rate": 1.6363636363636366e-05,
      "loss": 0.0184,
      "step": 3820
    },
    {
      "epoch": 1.8229414564493098,
      "grad_norm": 0.008619353175163269,
      "learning_rate": 1.6354117087101384e-05,
      "loss": 0.1024,
      "step": 3830
    },
    {
      "epoch": 1.8277010947168015,
      "grad_norm": 0.028480663895606995,
      "learning_rate": 1.6344597810566398e-05,
      "loss": 0.034,
      "step": 3840
    },
    {
      "epoch": 1.8324607329842932,
      "grad_norm": 0.012606735341250896,
      "learning_rate": 1.6335078534031416e-05,
      "loss": 0.0466,
      "step": 3850
    },
    {
      "epoch": 1.8372203712517847,
      "grad_norm": 18.14491844177246,
      "learning_rate": 1.632555925749643e-05,
      "loss": 0.097,
      "step": 3860
    },
    {
      "epoch": 1.8419800095192764,
      "grad_norm": 0.37816712260246277,
      "learning_rate": 1.6316039980961448e-05,
      "loss": 0.0115,
      "step": 3870
    },
    {
      "epoch": 1.8467396477867681,
      "grad_norm": 0.020207876339554787,
      "learning_rate": 1.6306520704426465e-05,
      "loss": 0.0237,
      "step": 3880
    },
    {
      "epoch": 1.8514992860542598,
      "grad_norm": 0.4175219237804413,
      "learning_rate": 1.6297001427891483e-05,
      "loss": 0.0414,
      "step": 3890
    },
    {
      "epoch": 1.8562589243217515,
      "grad_norm": 11.005008697509766,
      "learning_rate": 1.6287482151356497e-05,
      "loss": 0.0053,
      "step": 3900
    },
    {
      "epoch": 1.8610185625892433,
      "grad_norm": 0.0052430215291678905,
      "learning_rate": 1.6277962874821515e-05,
      "loss": 0.0483,
      "step": 3910
    },
    {
      "epoch": 1.865778200856735,
      "grad_norm": 4.263613700866699,
      "learning_rate": 1.6268443598286533e-05,
      "loss": 0.005,
      "step": 3920
    },
    {
      "epoch": 1.8705378391242267,
      "grad_norm": 0.004902676213532686,
      "learning_rate": 1.6258924321751547e-05,
      "loss": 0.0224,
      "step": 3930
    },
    {
      "epoch": 1.8752974773917184,
      "grad_norm": 0.006696660537272692,
      "learning_rate": 1.6249405045216565e-05,
      "loss": 0.0208,
      "step": 3940
    },
    {
      "epoch": 1.8800571156592099,
      "grad_norm": 0.2523289620876312,
      "learning_rate": 1.6239885768681582e-05,
      "loss": 0.0387,
      "step": 3950
    },
    {
      "epoch": 1.8848167539267016,
      "grad_norm": 0.017071258276700974,
      "learning_rate": 1.62303664921466e-05,
      "loss": 0.0222,
      "step": 3960
    },
    {
      "epoch": 1.8895763921941933,
      "grad_norm": 0.2732132077217102,
      "learning_rate": 1.6220847215611614e-05,
      "loss": 0.0039,
      "step": 3970
    },
    {
      "epoch": 1.8943360304616848,
      "grad_norm": 0.0015328130684792995,
      "learning_rate": 1.6211327939076632e-05,
      "loss": 0.032,
      "step": 3980
    },
    {
      "epoch": 1.8990956687291765,
      "grad_norm": 14.826995849609375,
      "learning_rate": 1.6201808662541646e-05,
      "loss": 0.0371,
      "step": 3990
    },
    {
      "epoch": 1.9038553069966682,
      "grad_norm": 0.026627035811543465,
      "learning_rate": 1.6192289386006664e-05,
      "loss": 0.0553,
      "step": 4000
    },
    {
      "epoch": 1.9086149452641599,
      "grad_norm": 1.898193120956421,
      "learning_rate": 1.618277010947168e-05,
      "loss": 0.0579,
      "step": 4010
    },
    {
      "epoch": 1.9133745835316516,
      "grad_norm": 0.011976993642747402,
      "learning_rate": 1.61732508329367e-05,
      "loss": 0.0538,
      "step": 4020
    },
    {
      "epoch": 1.9181342217991433,
      "grad_norm": 6.260443210601807,
      "learning_rate": 1.6163731556401713e-05,
      "loss": 0.0221,
      "step": 4030
    },
    {
      "epoch": 1.922893860066635,
      "grad_norm": 9.00403881072998,
      "learning_rate": 1.615421227986673e-05,
      "loss": 0.0289,
      "step": 4040
    },
    {
      "epoch": 1.9276534983341267,
      "grad_norm": 0.0318891666829586,
      "learning_rate": 1.614469300333175e-05,
      "loss": 0.0181,
      "step": 4050
    },
    {
      "epoch": 1.9324131366016184,
      "grad_norm": 10.657448768615723,
      "learning_rate": 1.6135173726796763e-05,
      "loss": 0.0166,
      "step": 4060
    },
    {
      "epoch": 1.93717277486911,
      "grad_norm": 0.060509782284498215,
      "learning_rate": 1.612565445026178e-05,
      "loss": 0.0009,
      "step": 4070
    },
    {
      "epoch": 1.9419324131366016,
      "grad_norm": 3.8934831619262695,
      "learning_rate": 1.61161351737268e-05,
      "loss": 0.0165,
      "step": 4080
    },
    {
      "epoch": 1.9466920514040933,
      "grad_norm": 13.897228240966797,
      "learning_rate": 1.6106615897191816e-05,
      "loss": 0.0448,
      "step": 4090
    },
    {
      "epoch": 1.951451689671585,
      "grad_norm": 0.581180214881897,
      "learning_rate": 1.609709662065683e-05,
      "loss": 0.0744,
      "step": 4100
    },
    {
      "epoch": 1.9562113279390765,
      "grad_norm": 0.045047905296087265,
      "learning_rate": 1.6087577344121848e-05,
      "loss": 0.0285,
      "step": 4110
    },
    {
      "epoch": 1.9609709662065682,
      "grad_norm": 0.13946270942687988,
      "learning_rate": 1.6078058067586862e-05,
      "loss": 0.0047,
      "step": 4120
    },
    {
      "epoch": 1.96573060447406,
      "grad_norm": 10.278953552246094,
      "learning_rate": 1.6068538791051883e-05,
      "loss": 0.0224,
      "step": 4130
    },
    {
      "epoch": 1.9704902427415516,
      "grad_norm": 0.020424693822860718,
      "learning_rate": 1.6059019514516898e-05,
      "loss": 0.034,
      "step": 4140
    },
    {
      "epoch": 1.9752498810090433,
      "grad_norm": 2.2393903732299805,
      "learning_rate": 1.6049500237981915e-05,
      "loss": 0.0761,
      "step": 4150
    },
    {
      "epoch": 1.980009519276535,
      "grad_norm": 0.05288364738225937,
      "learning_rate": 1.603998096144693e-05,
      "loss": 0.0084,
      "step": 4160
    },
    {
      "epoch": 1.9847691575440267,
      "grad_norm": 5.059597015380859,
      "learning_rate": 1.6030461684911947e-05,
      "loss": 0.0221,
      "step": 4170
    },
    {
      "epoch": 1.9895287958115184,
      "grad_norm": 5.95952033996582,
      "learning_rate": 1.6020942408376965e-05,
      "loss": 0.034,
      "step": 4180
    },
    {
      "epoch": 1.9942884340790101,
      "grad_norm": 0.25983089208602905,
      "learning_rate": 1.601142313184198e-05,
      "loss": 0.0112,
      "step": 4190
    },
    {
      "epoch": 1.9990480723465016,
      "grad_norm": 1.170892596244812,
      "learning_rate": 1.6001903855306997e-05,
      "loss": 0.0315,
      "step": 4200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9935452526374237,
      "eval_f1": 0.9651554889471713,
      "eval_loss": 0.02665022574365139,
      "eval_precision": 0.9633507853403142,
      "eval_recall": 0.9669669669669669,
      "eval_runtime": 2388.8611,
      "eval_samples_per_second": 6.033,
      "eval_steps_per_second": 0.754,
      "step": 4202
    },
    {
      "epoch": 2.0038077106139935,
      "grad_norm": 0.013513053767383099,
      "learning_rate": 1.5992384578772015e-05,
      "loss": 0.0249,
      "step": 4210
    },
    {
      "epoch": 2.008567348881485,
      "grad_norm": 0.048596758395433426,
      "learning_rate": 1.5982865302237032e-05,
      "loss": 0.0071,
      "step": 4220
    },
    {
      "epoch": 2.0133269871489765,
      "grad_norm": 0.0070387800224125385,
      "learning_rate": 1.5973346025702047e-05,
      "loss": 0.0028,
      "step": 4230
    },
    {
      "epoch": 2.018086625416468,
      "grad_norm": 10.481876373291016,
      "learning_rate": 1.5963826749167064e-05,
      "loss": 0.0159,
      "step": 4240
    },
    {
      "epoch": 2.02284626368396,
      "grad_norm": 0.02343904785811901,
      "learning_rate": 1.5954307472632082e-05,
      "loss": 0.0643,
      "step": 4250
    },
    {
      "epoch": 2.0276059019514516,
      "grad_norm": 0.34945693612098694,
      "learning_rate": 1.59447881960971e-05,
      "loss": 0.0011,
      "step": 4260
    },
    {
      "epoch": 2.0323655402189433,
      "grad_norm": 0.12941671907901764,
      "learning_rate": 1.5935268919562114e-05,
      "loss": 0.0005,
      "step": 4270
    },
    {
      "epoch": 2.037125178486435,
      "grad_norm": 0.013893195427954197,
      "learning_rate": 1.5925749643027132e-05,
      "loss": 0.033,
      "step": 4280
    },
    {
      "epoch": 2.0418848167539267,
      "grad_norm": 0.051912229508161545,
      "learning_rate": 1.5916230366492146e-05,
      "loss": 0.0008,
      "step": 4290
    },
    {
      "epoch": 2.0466444550214185,
      "grad_norm": 1.8613051176071167,
      "learning_rate": 1.5906711089957164e-05,
      "loss": 0.0277,
      "step": 4300
    },
    {
      "epoch": 2.05140409328891,
      "grad_norm": 0.0027162590995430946,
      "learning_rate": 1.589719181342218e-05,
      "loss": 0.047,
      "step": 4310
    },
    {
      "epoch": 2.056163731556402,
      "grad_norm": 0.02327641472220421,
      "learning_rate": 1.58876725368872e-05,
      "loss": 0.0218,
      "step": 4320
    },
    {
      "epoch": 2.0609233698238936,
      "grad_norm": 4.752787113189697,
      "learning_rate": 1.5878153260352213e-05,
      "loss": 0.0479,
      "step": 4330
    },
    {
      "epoch": 2.0656830080913853,
      "grad_norm": 10.635416984558105,
      "learning_rate": 1.586863398381723e-05,
      "loss": 0.0174,
      "step": 4340
    },
    {
      "epoch": 2.0704426463588765,
      "grad_norm": 2.2365152835845947,
      "learning_rate": 1.585911470728225e-05,
      "loss": 0.0321,
      "step": 4350
    },
    {
      "epoch": 2.0752022846263682,
      "grad_norm": 0.024117348715662956,
      "learning_rate": 1.5849595430747263e-05,
      "loss": 0.0085,
      "step": 4360
    },
    {
      "epoch": 2.07996192289386,
      "grad_norm": 0.0437224917113781,
      "learning_rate": 1.584007615421228e-05,
      "loss": 0.0309,
      "step": 4370
    },
    {
      "epoch": 2.0847215611613517,
      "grad_norm": 0.007086465135216713,
      "learning_rate": 1.58305568776773e-05,
      "loss": 0.0007,
      "step": 4380
    },
    {
      "epoch": 2.0894811994288434,
      "grad_norm": 9.362578392028809,
      "learning_rate": 1.5821037601142316e-05,
      "loss": 0.0284,
      "step": 4390
    },
    {
      "epoch": 2.094240837696335,
      "grad_norm": 2.5902204513549805,
      "learning_rate": 1.581151832460733e-05,
      "loss": 0.0453,
      "step": 4400
    },
    {
      "epoch": 2.0990004759638268,
      "grad_norm": 0.056220635771751404,
      "learning_rate": 1.5801999048072348e-05,
      "loss": 0.0221,
      "step": 4410
    },
    {
      "epoch": 2.1037601142313185,
      "grad_norm": 0.0176027100533247,
      "learning_rate": 1.5792479771537362e-05,
      "loss": 0.0015,
      "step": 4420
    },
    {
      "epoch": 2.10851975249881,
      "grad_norm": 0.004358846228569746,
      "learning_rate": 1.5782960495002383e-05,
      "loss": 0.0034,
      "step": 4430
    },
    {
      "epoch": 2.113279390766302,
      "grad_norm": 0.008874218910932541,
      "learning_rate": 1.5773441218467398e-05,
      "loss": 0.0444,
      "step": 4440
    },
    {
      "epoch": 2.1180390290337936,
      "grad_norm": 0.6038219928741455,
      "learning_rate": 1.5763921941932415e-05,
      "loss": 0.0361,
      "step": 4450
    },
    {
      "epoch": 2.1227986673012853,
      "grad_norm": 0.004510495811700821,
      "learning_rate": 1.575440266539743e-05,
      "loss": 0.0009,
      "step": 4460
    },
    {
      "epoch": 2.127558305568777,
      "grad_norm": 22.910898208618164,
      "learning_rate": 1.5744883388862447e-05,
      "loss": 0.0113,
      "step": 4470
    },
    {
      "epoch": 2.1323179438362683,
      "grad_norm": 0.0228545144200325,
      "learning_rate": 1.5735364112327465e-05,
      "loss": 0.0082,
      "step": 4480
    },
    {
      "epoch": 2.13707758210376,
      "grad_norm": 2.801678419113159,
      "learning_rate": 1.572584483579248e-05,
      "loss": 0.0511,
      "step": 4490
    },
    {
      "epoch": 2.1418372203712517,
      "grad_norm": 0.0282997228205204,
      "learning_rate": 1.5716325559257497e-05,
      "loss": 0.01,
      "step": 4500
    },
    {
      "epoch": 2.1465968586387434,
      "grad_norm": 4.972823143005371,
      "learning_rate": 1.5706806282722515e-05,
      "loss": 0.0232,
      "step": 4510
    },
    {
      "epoch": 2.151356496906235,
      "grad_norm": 0.010892077349126339,
      "learning_rate": 1.5697287006187532e-05,
      "loss": 0.0057,
      "step": 4520
    },
    {
      "epoch": 2.156116135173727,
      "grad_norm": 0.03274889662861824,
      "learning_rate": 1.5687767729652547e-05,
      "loss": 0.0235,
      "step": 4530
    },
    {
      "epoch": 2.1608757734412185,
      "grad_norm": 0.018925966694951057,
      "learning_rate": 1.5678248453117564e-05,
      "loss": 0.0139,
      "step": 4540
    },
    {
      "epoch": 2.16563541170871,
      "grad_norm": 12.627802848815918,
      "learning_rate": 1.566872917658258e-05,
      "loss": 0.0183,
      "step": 4550
    },
    {
      "epoch": 2.170395049976202,
      "grad_norm": 0.008516726084053516,
      "learning_rate": 1.56592099000476e-05,
      "loss": 0.0317,
      "step": 4560
    },
    {
      "epoch": 2.1751546882436936,
      "grad_norm": 0.016543444246053696,
      "learning_rate": 1.5649690623512614e-05,
      "loss": 0.0209,
      "step": 4570
    },
    {
      "epoch": 2.1799143265111853,
      "grad_norm": 0.004740230739116669,
      "learning_rate": 1.564017134697763e-05,
      "loss": 0.0097,
      "step": 4580
    },
    {
      "epoch": 2.1846739647786766,
      "grad_norm": 0.030044544488191605,
      "learning_rate": 1.5630652070442646e-05,
      "loss": 0.0086,
      "step": 4590
    },
    {
      "epoch": 2.1894336030461683,
      "grad_norm": 7.58803129196167,
      "learning_rate": 1.5621132793907664e-05,
      "loss": 0.0334,
      "step": 4600
    },
    {
      "epoch": 2.19419324131366,
      "grad_norm": 0.7030178904533386,
      "learning_rate": 1.561161351737268e-05,
      "loss": 0.0549,
      "step": 4610
    },
    {
      "epoch": 2.1989528795811517,
      "grad_norm": 0.004889278672635555,
      "learning_rate": 1.56020942408377e-05,
      "loss": 0.0057,
      "step": 4620
    },
    {
      "epoch": 2.2037125178486434,
      "grad_norm": 0.024536963552236557,
      "learning_rate": 1.5592574964302713e-05,
      "loss": 0.0361,
      "step": 4630
    },
    {
      "epoch": 2.208472156116135,
      "grad_norm": 0.11263357102870941,
      "learning_rate": 1.558305568776773e-05,
      "loss": 0.041,
      "step": 4640
    },
    {
      "epoch": 2.213231794383627,
      "grad_norm": 2.406123161315918,
      "learning_rate": 1.557353641123275e-05,
      "loss": 0.028,
      "step": 4650
    },
    {
      "epoch": 2.2179914326511185,
      "grad_norm": 0.0748470276594162,
      "learning_rate": 1.5564017134697763e-05,
      "loss": 0.0411,
      "step": 4660
    },
    {
      "epoch": 2.2227510709186102,
      "grad_norm": 5.490732669830322,
      "learning_rate": 1.555449785816278e-05,
      "loss": 0.0163,
      "step": 4670
    },
    {
      "epoch": 2.227510709186102,
      "grad_norm": 0.610303521156311,
      "learning_rate": 1.5544978581627795e-05,
      "loss": 0.033,
      "step": 4680
    },
    {
      "epoch": 2.2322703474535937,
      "grad_norm": 0.3371213972568512,
      "learning_rate": 1.5535459305092816e-05,
      "loss": 0.0058,
      "step": 4690
    },
    {
      "epoch": 2.2370299857210854,
      "grad_norm": 0.8424600958824158,
      "learning_rate": 1.552594002855783e-05,
      "loss": 0.0591,
      "step": 4700
    },
    {
      "epoch": 2.241789623988577,
      "grad_norm": 0.09857605397701263,
      "learning_rate": 1.5516420752022848e-05,
      "loss": 0.0622,
      "step": 4710
    },
    {
      "epoch": 2.2465492622560683,
      "grad_norm": 0.11466550827026367,
      "learning_rate": 1.5506901475487862e-05,
      "loss": 0.0217,
      "step": 4720
    },
    {
      "epoch": 2.25130890052356,
      "grad_norm": 0.010227474384009838,
      "learning_rate": 1.5497382198952883e-05,
      "loss": 0.0156,
      "step": 4730
    },
    {
      "epoch": 2.2560685387910517,
      "grad_norm": 0.057750504463911057,
      "learning_rate": 1.5487862922417898e-05,
      "loss": 0.0062,
      "step": 4740
    },
    {
      "epoch": 2.2608281770585434,
      "grad_norm": 9.500530242919922,
      "learning_rate": 1.5478343645882915e-05,
      "loss": 0.0107,
      "step": 4750
    },
    {
      "epoch": 2.265587815326035,
      "grad_norm": 0.21838633716106415,
      "learning_rate": 1.546882436934793e-05,
      "loss": 0.0206,
      "step": 4760
    },
    {
      "epoch": 2.270347453593527,
      "grad_norm": 2.0284008979797363,
      "learning_rate": 1.5459305092812947e-05,
      "loss": 0.0166,
      "step": 4770
    },
    {
      "epoch": 2.2751070918610186,
      "grad_norm": 1.400766372680664,
      "learning_rate": 1.5449785816277965e-05,
      "loss": 0.0101,
      "step": 4780
    },
    {
      "epoch": 2.2798667301285103,
      "grad_norm": 0.009623374789953232,
      "learning_rate": 1.544026653974298e-05,
      "loss": 0.0004,
      "step": 4790
    },
    {
      "epoch": 2.284626368396002,
      "grad_norm": 0.003911182284355164,
      "learning_rate": 1.5430747263207997e-05,
      "loss": 0.0069,
      "step": 4800
    },
    {
      "epoch": 2.2893860066634937,
      "grad_norm": 0.0023161389399319887,
      "learning_rate": 1.5421227986673015e-05,
      "loss": 0.0078,
      "step": 4810
    },
    {
      "epoch": 2.2941456449309854,
      "grad_norm": 0.003162383334711194,
      "learning_rate": 1.5411708710138032e-05,
      "loss": 0.0001,
      "step": 4820
    },
    {
      "epoch": 2.298905283198477,
      "grad_norm": 0.0034088476095348597,
      "learning_rate": 1.5402189433603047e-05,
      "loss": 0.0059,
      "step": 4830
    },
    {
      "epoch": 2.303664921465969,
      "grad_norm": 0.0010242306161671877,
      "learning_rate": 1.5392670157068064e-05,
      "loss": 0.0346,
      "step": 4840
    },
    {
      "epoch": 2.30842455973346,
      "grad_norm": 9.913378715515137,
      "learning_rate": 1.538315088053308e-05,
      "loss": 0.0888,
      "step": 4850
    },
    {
      "epoch": 2.3131841980009518,
      "grad_norm": 0.029820801690220833,
      "learning_rate": 1.53736316039981e-05,
      "loss": 0.0003,
      "step": 4860
    },
    {
      "epoch": 2.3179438362684435,
      "grad_norm": 12.860549926757812,
      "learning_rate": 1.5364112327463114e-05,
      "loss": 0.0461,
      "step": 4870
    },
    {
      "epoch": 2.322703474535935,
      "grad_norm": 0.03044111654162407,
      "learning_rate": 1.535459305092813e-05,
      "loss": 0.0047,
      "step": 4880
    },
    {
      "epoch": 2.327463112803427,
      "grad_norm": 0.007781559135764837,
      "learning_rate": 1.5345073774393146e-05,
      "loss": 0.0244,
      "step": 4890
    },
    {
      "epoch": 2.3322227510709186,
      "grad_norm": 0.49483421444892883,
      "learning_rate": 1.5335554497858164e-05,
      "loss": 0.0528,
      "step": 4900
    },
    {
      "epoch": 2.3369823893384103,
      "grad_norm": 0.051161572337150574,
      "learning_rate": 1.532603522132318e-05,
      "loss": 0.024,
      "step": 4910
    },
    {
      "epoch": 2.341742027605902,
      "grad_norm": 7.078289985656738,
      "learning_rate": 1.53165159447882e-05,
      "loss": 0.0256,
      "step": 4920
    },
    {
      "epoch": 2.3465016658733937,
      "grad_norm": 0.0025316793471574783,
      "learning_rate": 1.5306996668253213e-05,
      "loss": 0.0058,
      "step": 4930
    },
    {
      "epoch": 2.3512613041408854,
      "grad_norm": 0.06603668630123138,
      "learning_rate": 1.529747739171823e-05,
      "loss": 0.0238,
      "step": 4940
    },
    {
      "epoch": 2.356020942408377,
      "grad_norm": 0.1486385464668274,
      "learning_rate": 1.528795811518325e-05,
      "loss": 0.009,
      "step": 4950
    },
    {
      "epoch": 2.360780580675869,
      "grad_norm": 0.01638270728290081,
      "learning_rate": 1.5278438838648263e-05,
      "loss": 0.0174,
      "step": 4960
    },
    {
      "epoch": 2.3655402189433605,
      "grad_norm": 0.0046646734699606895,
      "learning_rate": 1.526891956211328e-05,
      "loss": 0.0065,
      "step": 4970
    },
    {
      "epoch": 2.370299857210852,
      "grad_norm": 0.2767618000507355,
      "learning_rate": 1.5259400285578295e-05,
      "loss": 0.0309,
      "step": 4980
    },
    {
      "epoch": 2.3750594954783435,
      "grad_norm": 0.01054638996720314,
      "learning_rate": 1.5249881009043314e-05,
      "loss": 0.0062,
      "step": 4990
    },
    {
      "epoch": 2.379819133745835,
      "grad_norm": 10.090455055236816,
      "learning_rate": 1.524036173250833e-05,
      "loss": 0.0446,
      "step": 5000
    },
    {
      "epoch": 2.384578772013327,
      "grad_norm": 0.033755283802747726,
      "learning_rate": 1.5230842455973346e-05,
      "loss": 0.049,
      "step": 5010
    },
    {
      "epoch": 2.3893384102808186,
      "grad_norm": 11.59467601776123,
      "learning_rate": 1.5221323179438364e-05,
      "loss": 0.0295,
      "step": 5020
    },
    {
      "epoch": 2.3940980485483103,
      "grad_norm": 1.0912954807281494,
      "learning_rate": 1.5211803902903382e-05,
      "loss": 0.0016,
      "step": 5030
    },
    {
      "epoch": 2.398857686815802,
      "grad_norm": 0.0044832294806838036,
      "learning_rate": 1.5202284626368398e-05,
      "loss": 0.0164,
      "step": 5040
    },
    {
      "epoch": 2.4036173250832937,
      "grad_norm": 0.004374154843389988,
      "learning_rate": 1.5192765349833414e-05,
      "loss": 0.0065,
      "step": 5050
    },
    {
      "epoch": 2.4083769633507854,
      "grad_norm": 0.21681341528892517,
      "learning_rate": 1.518324607329843e-05,
      "loss": 0.0909,
      "step": 5060
    },
    {
      "epoch": 2.413136601618277,
      "grad_norm": 0.04504404962062836,
      "learning_rate": 1.5173726796763449e-05,
      "loss": 0.0125,
      "step": 5070
    },
    {
      "epoch": 2.417896239885769,
      "grad_norm": 0.05574890971183777,
      "learning_rate": 1.5164207520228465e-05,
      "loss": 0.0305,
      "step": 5080
    },
    {
      "epoch": 2.42265587815326,
      "grad_norm": 0.019406108185648918,
      "learning_rate": 1.5154688243693481e-05,
      "loss": 0.0293,
      "step": 5090
    },
    {
      "epoch": 2.4274155164207523,
      "grad_norm": 0.033674877136945724,
      "learning_rate": 1.5145168967158497e-05,
      "loss": 0.0026,
      "step": 5100
    },
    {
      "epoch": 2.4321751546882435,
      "grad_norm": 14.579761505126953,
      "learning_rate": 1.5135649690623513e-05,
      "loss": 0.0266,
      "step": 5110
    },
    {
      "epoch": 2.4369347929557352,
      "grad_norm": 11.728202819824219,
      "learning_rate": 1.512613041408853e-05,
      "loss": 0.0199,
      "step": 5120
    },
    {
      "epoch": 2.441694431223227,
      "grad_norm": 0.8669358491897583,
      "learning_rate": 1.5116611137553548e-05,
      "loss": 0.0023,
      "step": 5130
    },
    {
      "epoch": 2.4464540694907186,
      "grad_norm": 7.645219326019287,
      "learning_rate": 1.5107091861018564e-05,
      "loss": 0.0215,
      "step": 5140
    },
    {
      "epoch": 2.4512137077582103,
      "grad_norm": 0.002642484148964286,
      "learning_rate": 1.509757258448358e-05,
      "loss": 0.0299,
      "step": 5150
    },
    {
      "epoch": 2.455973346025702,
      "grad_norm": 4.305262565612793,
      "learning_rate": 1.5088053307948598e-05,
      "loss": 0.0056,
      "step": 5160
    },
    {
      "epoch": 2.4607329842931938,
      "grad_norm": 14.923569679260254,
      "learning_rate": 1.5078534031413614e-05,
      "loss": 0.0288,
      "step": 5170
    },
    {
      "epoch": 2.4654926225606855,
      "grad_norm": 0.022288896143436432,
      "learning_rate": 1.506901475487863e-05,
      "loss": 0.0059,
      "step": 5180
    },
    {
      "epoch": 2.470252260828177,
      "grad_norm": 0.009198782034218311,
      "learning_rate": 1.5059495478343646e-05,
      "loss": 0.0097,
      "step": 5190
    },
    {
      "epoch": 2.475011899095669,
      "grad_norm": 6.019191265106201,
      "learning_rate": 1.5049976201808665e-05,
      "loss": 0.0034,
      "step": 5200
    },
    {
      "epoch": 2.4797715373631606,
      "grad_norm": 0.02334980107843876,
      "learning_rate": 1.5040456925273681e-05,
      "loss": 0.0244,
      "step": 5210
    },
    {
      "epoch": 2.484531175630652,
      "grad_norm": 2.3720569610595703,
      "learning_rate": 1.5030937648738697e-05,
      "loss": 0.0131,
      "step": 5220
    },
    {
      "epoch": 2.4892908138981436,
      "grad_norm": 0.0018647763645276427,
      "learning_rate": 1.5021418372203713e-05,
      "loss": 0.0069,
      "step": 5230
    },
    {
      "epoch": 2.4940504521656353,
      "grad_norm": 14.420498847961426,
      "learning_rate": 1.5011899095668729e-05,
      "loss": 0.0335,
      "step": 5240
    },
    {
      "epoch": 2.498810090433127,
      "grad_norm": 31.228179931640625,
      "learning_rate": 1.5002379819133749e-05,
      "loss": 0.0466,
      "step": 5250
    },
    {
      "epoch": 2.5035697287006187,
      "grad_norm": 0.06455197185277939,
      "learning_rate": 1.4992860542598764e-05,
      "loss": 0.075,
      "step": 5260
    },
    {
      "epoch": 2.5083293669681104,
      "grad_norm": 4.8719916343688965,
      "learning_rate": 1.498334126606378e-05,
      "loss": 0.0036,
      "step": 5270
    },
    {
      "epoch": 2.513089005235602,
      "grad_norm": 0.06184130162000656,
      "learning_rate": 1.4973821989528796e-05,
      "loss": 0.0624,
      "step": 5280
    },
    {
      "epoch": 2.517848643503094,
      "grad_norm": 7.352843761444092,
      "learning_rate": 1.4964302712993814e-05,
      "loss": 0.0086,
      "step": 5290
    },
    {
      "epoch": 2.5226082817705855,
      "grad_norm": 4.071541786193848,
      "learning_rate": 1.495478343645883e-05,
      "loss": 0.0304,
      "step": 5300
    },
    {
      "epoch": 2.527367920038077,
      "grad_norm": 0.48448896408081055,
      "learning_rate": 1.4945264159923846e-05,
      "loss": 0.0101,
      "step": 5310
    },
    {
      "epoch": 2.532127558305569,
      "grad_norm": 2.540665626525879,
      "learning_rate": 1.4935744883388864e-05,
      "loss": 0.0017,
      "step": 5320
    },
    {
      "epoch": 2.5368871965730606,
      "grad_norm": 10.542820930480957,
      "learning_rate": 1.4926225606853881e-05,
      "loss": 0.0129,
      "step": 5330
    },
    {
      "epoch": 2.5416468348405523,
      "grad_norm": 19.82818031311035,
      "learning_rate": 1.4916706330318897e-05,
      "loss": 0.0069,
      "step": 5340
    },
    {
      "epoch": 2.5464064731080436,
      "grad_norm": 0.04405786842107773,
      "learning_rate": 1.4907187053783913e-05,
      "loss": 0.0361,
      "step": 5350
    },
    {
      "epoch": 2.5511661113755357,
      "grad_norm": 0.34315577149391174,
      "learning_rate": 1.489766777724893e-05,
      "loss": 0.005,
      "step": 5360
    },
    {
      "epoch": 2.555925749643027,
      "grad_norm": 0.14120641350746155,
      "learning_rate": 1.4888148500713945e-05,
      "loss": 0.0088,
      "step": 5370
    },
    {
      "epoch": 2.5606853879105187,
      "grad_norm": 0.020142538473010063,
      "learning_rate": 1.4878629224178965e-05,
      "loss": 0.0794,
      "step": 5380
    },
    {
      "epoch": 2.5654450261780104,
      "grad_norm": 0.005986219737678766,
      "learning_rate": 1.486910994764398e-05,
      "loss": 0.0056,
      "step": 5390
    },
    {
      "epoch": 2.570204664445502,
      "grad_norm": 0.022679559886455536,
      "learning_rate": 1.4859590671108997e-05,
      "loss": 0.0431,
      "step": 5400
    },
    {
      "epoch": 2.574964302712994,
      "grad_norm": 0.2223614752292633,
      "learning_rate": 1.4850071394574013e-05,
      "loss": 0.021,
      "step": 5410
    },
    {
      "epoch": 2.5797239409804855,
      "grad_norm": 0.061534054577350616,
      "learning_rate": 1.484055211803903e-05,
      "loss": 0.0003,
      "step": 5420
    },
    {
      "epoch": 2.5844835792479772,
      "grad_norm": 0.39343756437301636,
      "learning_rate": 1.4831032841504046e-05,
      "loss": 0.0548,
      "step": 5430
    },
    {
      "epoch": 2.589243217515469,
      "grad_norm": 0.049101345241069794,
      "learning_rate": 1.4821513564969064e-05,
      "loss": 0.0199,
      "step": 5440
    },
    {
      "epoch": 2.5940028557829606,
      "grad_norm": 0.02644714154303074,
      "learning_rate": 1.481199428843408e-05,
      "loss": 0.0021,
      "step": 5450
    },
    {
      "epoch": 2.598762494050452,
      "grad_norm": 0.01577918417751789,
      "learning_rate": 1.4802475011899098e-05,
      "loss": 0.0005,
      "step": 5460
    },
    {
      "epoch": 2.603522132317944,
      "grad_norm": 1.7151998281478882,
      "learning_rate": 1.4792955735364114e-05,
      "loss": 0.0236,
      "step": 5470
    },
    {
      "epoch": 2.6082817705854353,
      "grad_norm": 6.684831619262695,
      "learning_rate": 1.478343645882913e-05,
      "loss": 0.0063,
      "step": 5480
    },
    {
      "epoch": 2.613041408852927,
      "grad_norm": 0.00521434610709548,
      "learning_rate": 1.4773917182294146e-05,
      "loss": 0.0235,
      "step": 5490
    },
    {
      "epoch": 2.6178010471204187,
      "grad_norm": 0.025134384632110596,
      "learning_rate": 1.4764397905759162e-05,
      "loss": 0.0367,
      "step": 5500
    },
    {
      "epoch": 2.6225606853879104,
      "grad_norm": 0.02559892274439335,
      "learning_rate": 1.4754878629224181e-05,
      "loss": 0.0175,
      "step": 5510
    },
    {
      "epoch": 2.627320323655402,
      "grad_norm": 0.043351490050554276,
      "learning_rate": 1.4745359352689197e-05,
      "loss": 0.0079,
      "step": 5520
    },
    {
      "epoch": 2.632079961922894,
      "grad_norm": 0.010318185202777386,
      "learning_rate": 1.4735840076154213e-05,
      "loss": 0.0376,
      "step": 5530
    },
    {
      "epoch": 2.6368396001903855,
      "grad_norm": 2.0158002376556396,
      "learning_rate": 1.4726320799619229e-05,
      "loss": 0.0158,
      "step": 5540
    },
    {
      "epoch": 2.6415992384578773,
      "grad_norm": 0.008372836746275425,
      "learning_rate": 1.4716801523084248e-05,
      "loss": 0.0001,
      "step": 5550
    },
    {
      "epoch": 2.646358876725369,
      "grad_norm": 5.9356184005737305,
      "learning_rate": 1.4707282246549264e-05,
      "loss": 0.0467,
      "step": 5560
    },
    {
      "epoch": 2.6511185149928607,
      "grad_norm": 0.004591368138790131,
      "learning_rate": 1.469776297001428e-05,
      "loss": 0.0153,
      "step": 5570
    },
    {
      "epoch": 2.6558781532603524,
      "grad_norm": 0.00398235721513629,
      "learning_rate": 1.4688243693479296e-05,
      "loss": 0.0018,
      "step": 5580
    },
    {
      "epoch": 2.6606377915278436,
      "grad_norm": 0.011228409595787525,
      "learning_rate": 1.4678724416944314e-05,
      "loss": 0.0102,
      "step": 5590
    },
    {
      "epoch": 2.665397429795336,
      "grad_norm": 0.0995892733335495,
      "learning_rate": 1.466920514040933e-05,
      "loss": 0.0004,
      "step": 5600
    },
    {
      "epoch": 2.670157068062827,
      "grad_norm": 0.010941383428871632,
      "learning_rate": 1.4659685863874346e-05,
      "loss": 0.0006,
      "step": 5610
    },
    {
      "epoch": 2.6749167063303187,
      "grad_norm": 0.011106908321380615,
      "learning_rate": 1.4650166587339362e-05,
      "loss": 0.0433,
      "step": 5620
    },
    {
      "epoch": 2.6796763445978105,
      "grad_norm": 0.25316518545150757,
      "learning_rate": 1.4640647310804381e-05,
      "loss": 0.0243,
      "step": 5630
    },
    {
      "epoch": 2.684435982865302,
      "grad_norm": 0.005858111660927534,
      "learning_rate": 1.4631128034269397e-05,
      "loss": 0.0106,
      "step": 5640
    },
    {
      "epoch": 2.689195621132794,
      "grad_norm": 0.006929299328476191,
      "learning_rate": 1.4621608757734413e-05,
      "loss": 0.0297,
      "step": 5650
    },
    {
      "epoch": 2.6939552594002856,
      "grad_norm": 0.017604786902666092,
      "learning_rate": 1.461208948119943e-05,
      "loss": 0.0018,
      "step": 5660
    },
    {
      "epoch": 2.6987148976677773,
      "grad_norm": 0.012490569613873959,
      "learning_rate": 1.4602570204664445e-05,
      "loss": 0.019,
      "step": 5670
    },
    {
      "epoch": 2.703474535935269,
      "grad_norm": 0.03426335006952286,
      "learning_rate": 1.4593050928129465e-05,
      "loss": 0.0085,
      "step": 5680
    },
    {
      "epoch": 2.7082341742027607,
      "grad_norm": 0.0038146390579640865,
      "learning_rate": 1.458353165159448e-05,
      "loss": 0.0003,
      "step": 5690
    },
    {
      "epoch": 2.7129938124702524,
      "grad_norm": 0.0035130330361425877,
      "learning_rate": 1.4574012375059497e-05,
      "loss": 0.0007,
      "step": 5700
    },
    {
      "epoch": 2.717753450737744,
      "grad_norm": 0.00893355906009674,
      "learning_rate": 1.4564493098524513e-05,
      "loss": 0.0025,
      "step": 5710
    },
    {
      "epoch": 2.7225130890052354,
      "grad_norm": 0.045076966285705566,
      "learning_rate": 1.455497382198953e-05,
      "loss": 0.0236,
      "step": 5720
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 5.207112789154053,
      "learning_rate": 1.4545454545454546e-05,
      "loss": 0.0017,
      "step": 5730
    },
    {
      "epoch": 2.7320323655402188,
      "grad_norm": 0.021618489176034927,
      "learning_rate": 1.4535935268919564e-05,
      "loss": 0.0261,
      "step": 5740
    },
    {
      "epoch": 2.7367920038077105,
      "grad_norm": 2.977238416671753,
      "learning_rate": 1.452641599238458e-05,
      "loss": 0.0186,
      "step": 5750
    },
    {
      "epoch": 2.741551642075202,
      "grad_norm": 0.1672554463148117,
      "learning_rate": 1.4516896715849598e-05,
      "loss": 0.0014,
      "step": 5760
    },
    {
      "epoch": 2.746311280342694,
      "grad_norm": 0.2173294574022293,
      "learning_rate": 1.4507377439314614e-05,
      "loss": 0.0251,
      "step": 5770
    },
    {
      "epoch": 2.7510709186101856,
      "grad_norm": 0.6375943422317505,
      "learning_rate": 1.449785816277963e-05,
      "loss": 0.0012,
      "step": 5780
    },
    {
      "epoch": 2.7558305568776773,
      "grad_norm": 0.017024483531713486,
      "learning_rate": 1.4488338886244646e-05,
      "loss": 0.0261,
      "step": 5790
    },
    {
      "epoch": 2.760590195145169,
      "grad_norm": 0.15886878967285156,
      "learning_rate": 1.4478819609709662e-05,
      "loss": 0.0056,
      "step": 5800
    },
    {
      "epoch": 2.7653498334126607,
      "grad_norm": 0.005722469184547663,
      "learning_rate": 1.4469300333174681e-05,
      "loss": 0.0139,
      "step": 5810
    },
    {
      "epoch": 2.7701094716801524,
      "grad_norm": 0.021610518917441368,
      "learning_rate": 1.4459781056639697e-05,
      "loss": 0.0066,
      "step": 5820
    },
    {
      "epoch": 2.774869109947644,
      "grad_norm": 0.01595836877822876,
      "learning_rate": 1.4450261780104713e-05,
      "loss": 0.0358,
      "step": 5830
    },
    {
      "epoch": 2.779628748215136,
      "grad_norm": 0.011307775974273682,
      "learning_rate": 1.4440742503569729e-05,
      "loss": 0.0027,
      "step": 5840
    },
    {
      "epoch": 2.784388386482627,
      "grad_norm": 7.955530643463135,
      "learning_rate": 1.4431223227034747e-05,
      "loss": 0.0088,
      "step": 5850
    },
    {
      "epoch": 2.7891480247501192,
      "grad_norm": 0.006602211389690638,
      "learning_rate": 1.4421703950499764e-05,
      "loss": 0.0163,
      "step": 5860
    },
    {
      "epoch": 2.7939076630176105,
      "grad_norm": 0.002106413245201111,
      "learning_rate": 1.441218467396478e-05,
      "loss": 0.0001,
      "step": 5870
    },
    {
      "epoch": 2.798667301285102,
      "grad_norm": 0.03255641087889671,
      "learning_rate": 1.4402665397429796e-05,
      "loss": 0.0201,
      "step": 5880
    },
    {
      "epoch": 2.803426939552594,
      "grad_norm": 0.001735855475999415,
      "learning_rate": 1.4393146120894814e-05,
      "loss": 0.042,
      "step": 5890
    },
    {
      "epoch": 2.8081865778200856,
      "grad_norm": 0.045489855110645294,
      "learning_rate": 1.438362684435983e-05,
      "loss": 0.0096,
      "step": 5900
    },
    {
      "epoch": 2.8129462160875773,
      "grad_norm": 0.004102695267647505,
      "learning_rate": 1.4374107567824846e-05,
      "loss": 0.0448,
      "step": 5910
    },
    {
      "epoch": 2.817705854355069,
      "grad_norm": 0.006396767683327198,
      "learning_rate": 1.4364588291289862e-05,
      "loss": 0.0004,
      "step": 5920
    },
    {
      "epoch": 2.8224654926225607,
      "grad_norm": 2.486239194869995,
      "learning_rate": 1.435506901475488e-05,
      "loss": 0.0105,
      "step": 5930
    },
    {
      "epoch": 2.8272251308900525,
      "grad_norm": 0.008997468277812004,
      "learning_rate": 1.4345549738219897e-05,
      "loss": 0.0472,
      "step": 5940
    },
    {
      "epoch": 2.831984769157544,
      "grad_norm": 5.951140880584717,
      "learning_rate": 1.4336030461684913e-05,
      "loss": 0.019,
      "step": 5950
    },
    {
      "epoch": 2.836744407425036,
      "grad_norm": 0.026009976863861084,
      "learning_rate": 1.432651118514993e-05,
      "loss": 0.0002,
      "step": 5960
    },
    {
      "epoch": 2.8415040456925276,
      "grad_norm": 4.828779697418213,
      "learning_rate": 1.4316991908614945e-05,
      "loss": 0.0278,
      "step": 5970
    },
    {
      "epoch": 2.846263683960019,
      "grad_norm": 1.2130045890808105,
      "learning_rate": 1.4307472632079965e-05,
      "loss": 0.0047,
      "step": 5980
    },
    {
      "epoch": 2.851023322227511,
      "grad_norm": 0.02283848449587822,
      "learning_rate": 1.429795335554498e-05,
      "loss": 0.0231,
      "step": 5990
    },
    {
      "epoch": 2.8557829604950022,
      "grad_norm": 0.01150465477257967,
      "learning_rate": 1.4288434079009997e-05,
      "loss": 0.0003,
      "step": 6000
    },
    {
      "epoch": 2.860542598762494,
      "grad_norm": 0.022821469232439995,
      "learning_rate": 1.4278914802475013e-05,
      "loss": 0.0189,
      "step": 6010
    },
    {
      "epoch": 2.8653022370299857,
      "grad_norm": 0.03382418304681778,
      "learning_rate": 1.426939552594003e-05,
      "loss": 0.0005,
      "step": 6020
    },
    {
      "epoch": 2.8700618752974774,
      "grad_norm": 0.010517638176679611,
      "learning_rate": 1.4259876249405046e-05,
      "loss": 0.03,
      "step": 6030
    },
    {
      "epoch": 2.874821513564969,
      "grad_norm": 0.007901642471551895,
      "learning_rate": 1.4250356972870062e-05,
      "loss": 0.0175,
      "step": 6040
    },
    {
      "epoch": 2.8795811518324608,
      "grad_norm": 0.005415911786258221,
      "learning_rate": 1.424083769633508e-05,
      "loss": 0.0002,
      "step": 6050
    },
    {
      "epoch": 2.8843407900999525,
      "grad_norm": 10.982464790344238,
      "learning_rate": 1.4231318419800096e-05,
      "loss": 0.0262,
      "step": 6060
    },
    {
      "epoch": 2.889100428367444,
      "grad_norm": 6.433587551116943,
      "learning_rate": 1.4221799143265114e-05,
      "loss": 0.0217,
      "step": 6070
    },
    {
      "epoch": 2.893860066634936,
      "grad_norm": 0.04580358415842056,
      "learning_rate": 1.421227986673013e-05,
      "loss": 0.0004,
      "step": 6080
    },
    {
      "epoch": 2.898619704902427,
      "grad_norm": 0.003064425429329276,
      "learning_rate": 1.4202760590195146e-05,
      "loss": 0.0008,
      "step": 6090
    },
    {
      "epoch": 2.9033793431699193,
      "grad_norm": 0.07991587370634079,
      "learning_rate": 1.4193241313660162e-05,
      "loss": 0.0055,
      "step": 6100
    },
    {
      "epoch": 2.9081389814374106,
      "grad_norm": 15.883405685424805,
      "learning_rate": 1.4183722037125181e-05,
      "loss": 0.0046,
      "step": 6110
    },
    {
      "epoch": 2.9128986197049023,
      "grad_norm": 11.210646629333496,
      "learning_rate": 1.4174202760590197e-05,
      "loss": 0.0037,
      "step": 6120
    },
    {
      "epoch": 2.917658257972394,
      "grad_norm": 0.010685315355658531,
      "learning_rate": 1.4164683484055213e-05,
      "loss": 0.0277,
      "step": 6130
    },
    {
      "epoch": 2.9224178962398857,
      "grad_norm": 0.7174044251441956,
      "learning_rate": 1.4155164207520229e-05,
      "loss": 0.0005,
      "step": 6140
    },
    {
      "epoch": 2.9271775345073774,
      "grad_norm": 7.043503761291504,
      "learning_rate": 1.4145644930985247e-05,
      "loss": 0.0112,
      "step": 6150
    },
    {
      "epoch": 2.931937172774869,
      "grad_norm": 0.23605304956436157,
      "learning_rate": 1.4136125654450264e-05,
      "loss": 0.0003,
      "step": 6160
    },
    {
      "epoch": 2.936696811042361,
      "grad_norm": 0.07476834952831268,
      "learning_rate": 1.412660637791528e-05,
      "loss": 0.0041,
      "step": 6170
    },
    {
      "epoch": 2.9414564493098525,
      "grad_norm": 0.003691856050863862,
      "learning_rate": 1.4117087101380296e-05,
      "loss": 0.0055,
      "step": 6180
    },
    {
      "epoch": 2.946216087577344,
      "grad_norm": 0.08866707235574722,
      "learning_rate": 1.4107567824845312e-05,
      "loss": 0.0452,
      "step": 6190
    },
    {
      "epoch": 2.950975725844836,
      "grad_norm": 0.0043175858445465565,
      "learning_rate": 1.409804854831033e-05,
      "loss": 0.0269,
      "step": 6200
    },
    {
      "epoch": 2.9557353641123276,
      "grad_norm": 0.6459680199623108,
      "learning_rate": 1.4088529271775346e-05,
      "loss": 0.0767,
      "step": 6210
    },
    {
      "epoch": 2.960495002379819,
      "grad_norm": 0.013630981557071209,
      "learning_rate": 1.4079009995240362e-05,
      "loss": 0.0317,
      "step": 6220
    },
    {
      "epoch": 2.965254640647311,
      "grad_norm": 0.0163857564330101,
      "learning_rate": 1.4069490718705378e-05,
      "loss": 0.0032,
      "step": 6230
    },
    {
      "epoch": 2.9700142789148023,
      "grad_norm": 0.05222779139876366,
      "learning_rate": 1.4059971442170397e-05,
      "loss": 0.0165,
      "step": 6240
    },
    {
      "epoch": 2.974773917182294,
      "grad_norm": 0.026931211352348328,
      "learning_rate": 1.4050452165635413e-05,
      "loss": 0.0234,
      "step": 6250
    },
    {
      "epoch": 2.9795335554497857,
      "grad_norm": 0.2027709037065506,
      "learning_rate": 1.404093288910043e-05,
      "loss": 0.0202,
      "step": 6260
    },
    {
      "epoch": 2.9842931937172774,
      "grad_norm": 0.04337935894727707,
      "learning_rate": 1.4031413612565445e-05,
      "loss": 0.0039,
      "step": 6270
    },
    {
      "epoch": 2.989052831984769,
      "grad_norm": 0.00865599513053894,
      "learning_rate": 1.4021894336030465e-05,
      "loss": 0.0132,
      "step": 6280
    },
    {
      "epoch": 2.993812470252261,
      "grad_norm": 0.012191328220069408,
      "learning_rate": 1.401237505949548e-05,
      "loss": 0.0221,
      "step": 6290
    },
    {
      "epoch": 2.9985721085197525,
      "grad_norm": 0.06260666251182556,
      "learning_rate": 1.4002855782960497e-05,
      "loss": 0.0003,
      "step": 6300
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9957662409772349,
      "eval_f1": 0.9771278590176228,
      "eval_loss": 0.021108852699398994,
      "eval_precision": 0.9760299625468165,
      "eval_recall": 0.9782282282282282,
      "eval_runtime": 2013.0972,
      "eval_samples_per_second": 7.159,
      "eval_steps_per_second": 0.895,
      "step": 6303
    },
    {
      "epoch": 3.0033317467872442,
      "grad_norm": 0.030105721205472946,
      "learning_rate": 1.3993336506425513e-05,
      "loss": 0.0083,
      "step": 6310
    },
    {
      "epoch": 3.008091385054736,
      "grad_norm": 0.0034435815177857876,
      "learning_rate": 1.3983817229890528e-05,
      "loss": 0.0014,
      "step": 6320
    },
    {
      "epoch": 3.0128510233222277,
      "grad_norm": 0.004204518627375364,
      "learning_rate": 1.3974297953355546e-05,
      "loss": 0.0001,
      "step": 6330
    },
    {
      "epoch": 3.0176106615897194,
      "grad_norm": 0.010549011640250683,
      "learning_rate": 1.3964778676820562e-05,
      "loss": 0.0003,
      "step": 6340
    },
    {
      "epoch": 3.022370299857211,
      "grad_norm": 0.005190382245928049,
      "learning_rate": 1.395525940028558e-05,
      "loss": 0.0025,
      "step": 6350
    },
    {
      "epoch": 3.0271299381247023,
      "grad_norm": 0.005429656710475683,
      "learning_rate": 1.3945740123750596e-05,
      "loss": 0.0001,
      "step": 6360
    },
    {
      "epoch": 3.031889576392194,
      "grad_norm": 16.57465171813965,
      "learning_rate": 1.3936220847215614e-05,
      "loss": 0.0157,
      "step": 6370
    },
    {
      "epoch": 3.0366492146596857,
      "grad_norm": 0.002984528196975589,
      "learning_rate": 1.392670157068063e-05,
      "loss": 0.0058,
      "step": 6380
    },
    {
      "epoch": 3.0414088529271774,
      "grad_norm": 0.10668221116065979,
      "learning_rate": 1.3917182294145645e-05,
      "loss": 0.0154,
      "step": 6390
    },
    {
      "epoch": 3.046168491194669,
      "grad_norm": 0.010667362250387669,
      "learning_rate": 1.3907663017610661e-05,
      "loss": 0.0001,
      "step": 6400
    },
    {
      "epoch": 3.050928129462161,
      "grad_norm": 0.0031958178151398897,
      "learning_rate": 1.389814374107568e-05,
      "loss": 0.0006,
      "step": 6410
    },
    {
      "epoch": 3.0556877677296526,
      "grad_norm": 0.001965004950761795,
      "learning_rate": 1.3888624464540697e-05,
      "loss": 0.0004,
      "step": 6420
    },
    {
      "epoch": 3.0604474059971443,
      "grad_norm": 0.10370060056447983,
      "learning_rate": 1.3879105188005713e-05,
      "loss": 0.0251,
      "step": 6430
    },
    {
      "epoch": 3.065207044264636,
      "grad_norm": 0.3343065679073334,
      "learning_rate": 1.3869585911470729e-05,
      "loss": 0.0184,
      "step": 6440
    },
    {
      "epoch": 3.0699666825321277,
      "grad_norm": 0.09211423993110657,
      "learning_rate": 1.3860066634935746e-05,
      "loss": 0.0001,
      "step": 6450
    },
    {
      "epoch": 3.0747263207996194,
      "grad_norm": 0.0014723899075761437,
      "learning_rate": 1.3850547358400762e-05,
      "loss": 0.014,
      "step": 6460
    },
    {
      "epoch": 3.079485959067111,
      "grad_norm": 0.00721277529373765,
      "learning_rate": 1.384102808186578e-05,
      "loss": 0.032,
      "step": 6470
    },
    {
      "epoch": 3.0842455973346024,
      "grad_norm": 5.410787105560303,
      "learning_rate": 1.3831508805330796e-05,
      "loss": 0.0075,
      "step": 6480
    },
    {
      "epoch": 3.089005235602094,
      "grad_norm": 0.10958697646856308,
      "learning_rate": 1.3821989528795812e-05,
      "loss": 0.0222,
      "step": 6490
    },
    {
      "epoch": 3.0937648738695858,
      "grad_norm": 0.02141549438238144,
      "learning_rate": 1.381247025226083e-05,
      "loss": 0.0206,
      "step": 6500
    },
    {
      "epoch": 3.0985245121370775,
      "grad_norm": 0.013912172056734562,
      "learning_rate": 1.3802950975725846e-05,
      "loss": 0.0007,
      "step": 6510
    },
    {
      "epoch": 3.103284150404569,
      "grad_norm": 0.009328139945864677,
      "learning_rate": 1.3793431699190862e-05,
      "loss": 0.0289,
      "step": 6520
    },
    {
      "epoch": 3.108043788672061,
      "grad_norm": 0.2923974096775055,
      "learning_rate": 1.3783912422655878e-05,
      "loss": 0.0002,
      "step": 6530
    },
    {
      "epoch": 3.1128034269395526,
      "grad_norm": 0.0049899579025805,
      "learning_rate": 1.3774393146120897e-05,
      "loss": 0.016,
      "step": 6540
    },
    {
      "epoch": 3.1175630652070443,
      "grad_norm": 0.3693944811820984,
      "learning_rate": 1.3764873869585913e-05,
      "loss": 0.0011,
      "step": 6550
    },
    {
      "epoch": 3.122322703474536,
      "grad_norm": 0.006272574421018362,
      "learning_rate": 1.3755354593050929e-05,
      "loss": 0.003,
      "step": 6560
    },
    {
      "epoch": 3.1270823417420277,
      "grad_norm": 0.06185339763760567,
      "learning_rate": 1.3745835316515945e-05,
      "loss": 0.0002,
      "step": 6570
    },
    {
      "epoch": 3.1318419800095194,
      "grad_norm": 12.000998497009277,
      "learning_rate": 1.3736316039980964e-05,
      "loss": 0.0077,
      "step": 6580
    },
    {
      "epoch": 3.136601618277011,
      "grad_norm": 0.005635618697851896,
      "learning_rate": 1.372679676344598e-05,
      "loss": 0.0035,
      "step": 6590
    },
    {
      "epoch": 3.141361256544503,
      "grad_norm": 0.1360616683959961,
      "learning_rate": 1.3717277486910996e-05,
      "loss": 0.0052,
      "step": 6600
    },
    {
      "epoch": 3.146120894811994,
      "grad_norm": 29.333364486694336,
      "learning_rate": 1.3707758210376012e-05,
      "loss": 0.0167,
      "step": 6610
    },
    {
      "epoch": 3.150880533079486,
      "grad_norm": 0.009969577193260193,
      "learning_rate": 1.3698238933841028e-05,
      "loss": 0.0009,
      "step": 6620
    },
    {
      "epoch": 3.1556401713469775,
      "grad_norm": 15.243005752563477,
      "learning_rate": 1.3688719657306046e-05,
      "loss": 0.0341,
      "step": 6630
    },
    {
      "epoch": 3.160399809614469,
      "grad_norm": 0.18427106738090515,
      "learning_rate": 1.3679200380771062e-05,
      "loss": 0.0002,
      "step": 6640
    },
    {
      "epoch": 3.165159447881961,
      "grad_norm": 0.354791522026062,
      "learning_rate": 1.3669681104236078e-05,
      "loss": 0.0008,
      "step": 6650
    },
    {
      "epoch": 3.1699190861494526,
      "grad_norm": 0.005384162999689579,
      "learning_rate": 1.3660161827701096e-05,
      "loss": 0.0006,
      "step": 6660
    },
    {
      "epoch": 3.1746787244169443,
      "grad_norm": 0.0052653029561042786,
      "learning_rate": 1.3650642551166113e-05,
      "loss": 0.0064,
      "step": 6670
    },
    {
      "epoch": 3.179438362684436,
      "grad_norm": 0.0025069601833820343,
      "learning_rate": 1.364112327463113e-05,
      "loss": 0.0127,
      "step": 6680
    },
    {
      "epoch": 3.1841980009519277,
      "grad_norm": 0.09616829454898834,
      "learning_rate": 1.3631603998096145e-05,
      "loss": 0.0001,
      "step": 6690
    },
    {
      "epoch": 3.1889576392194194,
      "grad_norm": 0.0032206992618739605,
      "learning_rate": 1.3622084721561161e-05,
      "loss": 0.0082,
      "step": 6700
    },
    {
      "epoch": 3.193717277486911,
      "grad_norm": 0.0015008783666417003,
      "learning_rate": 1.361256544502618e-05,
      "loss": 0.0103,
      "step": 6710
    },
    {
      "epoch": 3.198476915754403,
      "grad_norm": 0.009670110419392586,
      "learning_rate": 1.3603046168491197e-05,
      "loss": 0.0021,
      "step": 6720
    },
    {
      "epoch": 3.2032365540218946,
      "grad_norm": 0.0030721933580935,
      "learning_rate": 1.3593526891956213e-05,
      "loss": 0.0018,
      "step": 6730
    },
    {
      "epoch": 3.207996192289386,
      "grad_norm": 0.001052828156389296,
      "learning_rate": 1.3584007615421229e-05,
      "loss": 0.0107,
      "step": 6740
    },
    {
      "epoch": 3.2127558305568775,
      "grad_norm": 3.8083224296569824,
      "learning_rate": 1.3574488338886245e-05,
      "loss": 0.0012,
      "step": 6750
    },
    {
      "epoch": 3.2175154688243692,
      "grad_norm": 0.0008141033467836678,
      "learning_rate": 1.3564969062351262e-05,
      "loss": 0.0004,
      "step": 6760
    },
    {
      "epoch": 3.222275107091861,
      "grad_norm": 0.0012289037695154548,
      "learning_rate": 1.355544978581628e-05,
      "loss": 0.013,
      "step": 6770
    },
    {
      "epoch": 3.2270347453593526,
      "grad_norm": 0.013582088984549046,
      "learning_rate": 1.3545930509281296e-05,
      "loss": 0.002,
      "step": 6780
    },
    {
      "epoch": 3.2317943836268443,
      "grad_norm": 40.61377716064453,
      "learning_rate": 1.3536411232746312e-05,
      "loss": 0.0057,
      "step": 6790
    },
    {
      "epoch": 3.236554021894336,
      "grad_norm": 0.0012738036457449198,
      "learning_rate": 1.352689195621133e-05,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 3.2413136601618278,
      "grad_norm": 0.00030438945395871997,
      "learning_rate": 1.3517372679676346e-05,
      "loss": 0.0081,
      "step": 6810
    },
    {
      "epoch": 3.2460732984293195,
      "grad_norm": 14.517717361450195,
      "learning_rate": 1.3507853403141362e-05,
      "loss": 0.0233,
      "step": 6820
    },
    {
      "epoch": 3.250832936696811,
      "grad_norm": 0.00028790123178623617,
      "learning_rate": 1.3498334126606378e-05,
      "loss": 0.0032,
      "step": 6830
    },
    {
      "epoch": 3.255592574964303,
      "grad_norm": 1.3513097763061523,
      "learning_rate": 1.3488814850071397e-05,
      "loss": 0.0012,
      "step": 6840
    },
    {
      "epoch": 3.260352213231794,
      "grad_norm": 0.0015707758720964193,
      "learning_rate": 1.3479295573536413e-05,
      "loss": 0.0223,
      "step": 6850
    },
    {
      "epoch": 3.2651118514992863,
      "grad_norm": 0.006129879038780928,
      "learning_rate": 1.3469776297001429e-05,
      "loss": 0.0004,
      "step": 6860
    },
    {
      "epoch": 3.2698714897667776,
      "grad_norm": 0.010016141459345818,
      "learning_rate": 1.3460257020466445e-05,
      "loss": 0.002,
      "step": 6870
    },
    {
      "epoch": 3.2746311280342693,
      "grad_norm": 0.011090822517871857,
      "learning_rate": 1.3450737743931461e-05,
      "loss": 0.0052,
      "step": 6880
    },
    {
      "epoch": 3.279390766301761,
      "grad_norm": 0.42565661668777466,
      "learning_rate": 1.344121846739648e-05,
      "loss": 0.0737,
      "step": 6890
    },
    {
      "epoch": 3.2841504045692527,
      "grad_norm": 0.040022239089012146,
      "learning_rate": 1.3431699190861496e-05,
      "loss": 0.0008,
      "step": 6900
    },
    {
      "epoch": 3.2889100428367444,
      "grad_norm": 0.01391532551497221,
      "learning_rate": 1.3422179914326512e-05,
      "loss": 0.0166,
      "step": 6910
    },
    {
      "epoch": 3.293669681104236,
      "grad_norm": 18.578062057495117,
      "learning_rate": 1.3412660637791528e-05,
      "loss": 0.0027,
      "step": 6920
    },
    {
      "epoch": 3.298429319371728,
      "grad_norm": 1.5689268112182617,
      "learning_rate": 1.3403141361256546e-05,
      "loss": 0.015,
      "step": 6930
    },
    {
      "epoch": 3.3031889576392195,
      "grad_norm": 1.8153152465820312,
      "learning_rate": 1.3393622084721562e-05,
      "loss": 0.0295,
      "step": 6940
    },
    {
      "epoch": 3.307948595906711,
      "grad_norm": 0.1064777821302414,
      "learning_rate": 1.3384102808186578e-05,
      "loss": 0.0003,
      "step": 6950
    },
    {
      "epoch": 3.312708234174203,
      "grad_norm": 0.03475354611873627,
      "learning_rate": 1.3374583531651596e-05,
      "loss": 0.0015,
      "step": 6960
    },
    {
      "epoch": 3.3174678724416946,
      "grad_norm": 0.000747481535654515,
      "learning_rate": 1.3365064255116613e-05,
      "loss": 0.0233,
      "step": 6970
    },
    {
      "epoch": 3.322227510709186,
      "grad_norm": 0.001252025249414146,
      "learning_rate": 1.335554497858163e-05,
      "loss": 0.0047,
      "step": 6980
    },
    {
      "epoch": 3.326987148976678,
      "grad_norm": 4.97389554977417,
      "learning_rate": 1.3346025702046645e-05,
      "loss": 0.013,
      "step": 6990
    },
    {
      "epoch": 3.3317467872441693,
      "grad_norm": 0.0032250629737973213,
      "learning_rate": 1.3336506425511661e-05,
      "loss": 0.018,
      "step": 7000
    },
    {
      "epoch": 3.336506425511661,
      "grad_norm": 0.03502678498625755,
      "learning_rate": 1.3326987148976677e-05,
      "loss": 0.0321,
      "step": 7010
    },
    {
      "epoch": 3.3412660637791527,
      "grad_norm": 8.413627624511719,
      "learning_rate": 1.3317467872441697e-05,
      "loss": 0.0348,
      "step": 7020
    },
    {
      "epoch": 3.3460257020466444,
      "grad_norm": 0.01930810883641243,
      "learning_rate": 1.3307948595906713e-05,
      "loss": 0.0155,
      "step": 7030
    },
    {
      "epoch": 3.350785340314136,
      "grad_norm": 0.06738368421792984,
      "learning_rate": 1.3298429319371729e-05,
      "loss": 0.0287,
      "step": 7040
    },
    {
      "epoch": 3.355544978581628,
      "grad_norm": 0.005761443171650171,
      "learning_rate": 1.3288910042836745e-05,
      "loss": 0.0001,
      "step": 7050
    },
    {
      "epoch": 3.3603046168491195,
      "grad_norm": 3.4794845581054688,
      "learning_rate": 1.3279390766301762e-05,
      "loss": 0.0023,
      "step": 7060
    },
    {
      "epoch": 3.3650642551166112,
      "grad_norm": 0.0036076437681913376,
      "learning_rate": 1.3269871489766778e-05,
      "loss": 0.026,
      "step": 7070
    },
    {
      "epoch": 3.369823893384103,
      "grad_norm": 0.0023801401257514954,
      "learning_rate": 1.3260352213231796e-05,
      "loss": 0.0042,
      "step": 7080
    },
    {
      "epoch": 3.3745835316515946,
      "grad_norm": 8.815452575683594,
      "learning_rate": 1.3250832936696812e-05,
      "loss": 0.0097,
      "step": 7090
    },
    {
      "epoch": 3.3793431699190863,
      "grad_norm": 0.03816743195056915,
      "learning_rate": 1.324131366016183e-05,
      "loss": 0.0207,
      "step": 7100
    },
    {
      "epoch": 3.3841028081865776,
      "grad_norm": 0.002825062023475766,
      "learning_rate": 1.3231794383626846e-05,
      "loss": 0.004,
      "step": 7110
    },
    {
      "epoch": 3.3888624464540693,
      "grad_norm": 0.044063154608011246,
      "learning_rate": 1.3222275107091862e-05,
      "loss": 0.0009,
      "step": 7120
    },
    {
      "epoch": 3.393622084721561,
      "grad_norm": 0.0024754581972956657,
      "learning_rate": 1.3212755830556878e-05,
      "loss": 0.0001,
      "step": 7130
    },
    {
      "epoch": 3.3983817229890527,
      "grad_norm": 0.030034899711608887,
      "learning_rate": 1.3203236554021897e-05,
      "loss": 0.0009,
      "step": 7140
    },
    {
      "epoch": 3.4031413612565444,
      "grad_norm": 0.10945533961057663,
      "learning_rate": 1.3193717277486913e-05,
      "loss": 0.0182,
      "step": 7150
    },
    {
      "epoch": 3.407900999524036,
      "grad_norm": 0.2615092694759369,
      "learning_rate": 1.3184198000951929e-05,
      "loss": 0.0235,
      "step": 7160
    },
    {
      "epoch": 3.412660637791528,
      "grad_norm": 0.040464673191308975,
      "learning_rate": 1.3174678724416945e-05,
      "loss": 0.0136,
      "step": 7170
    },
    {
      "epoch": 3.4174202760590195,
      "grad_norm": 14.604565620422363,
      "learning_rate": 1.3165159447881961e-05,
      "loss": 0.027,
      "step": 7180
    },
    {
      "epoch": 3.4221799143265113,
      "grad_norm": 0.07834860682487488,
      "learning_rate": 1.315564017134698e-05,
      "loss": 0.0001,
      "step": 7190
    },
    {
      "epoch": 3.426939552594003,
      "grad_norm": 2.170691728591919,
      "learning_rate": 1.3146120894811996e-05,
      "loss": 0.015,
      "step": 7200
    },
    {
      "epoch": 3.4316991908614947,
      "grad_norm": 0.0010670709889382124,
      "learning_rate": 1.3136601618277012e-05,
      "loss": 0.0514,
      "step": 7210
    },
    {
      "epoch": 3.4364588291289864,
      "grad_norm": 0.002226158045232296,
      "learning_rate": 1.3127082341742028e-05,
      "loss": 0.0062,
      "step": 7220
    },
    {
      "epoch": 3.441218467396478,
      "grad_norm": 0.026363180950284004,
      "learning_rate": 1.3117563065207046e-05,
      "loss": 0.0249,
      "step": 7230
    },
    {
      "epoch": 3.4459781056639693,
      "grad_norm": 12.096841812133789,
      "learning_rate": 1.3108043788672062e-05,
      "loss": 0.0131,
      "step": 7240
    },
    {
      "epoch": 3.450737743931461,
      "grad_norm": 0.15197354555130005,
      "learning_rate": 1.3098524512137078e-05,
      "loss": 0.0005,
      "step": 7250
    },
    {
      "epoch": 3.4554973821989527,
      "grad_norm": 0.004110252484679222,
      "learning_rate": 1.3089005235602094e-05,
      "loss": 0.0362,
      "step": 7260
    },
    {
      "epoch": 3.4602570204664445,
      "grad_norm": 6.0137481689453125,
      "learning_rate": 1.3079485959067113e-05,
      "loss": 0.0295,
      "step": 7270
    },
    {
      "epoch": 3.465016658733936,
      "grad_norm": 15.039586067199707,
      "learning_rate": 1.306996668253213e-05,
      "loss": 0.0184,
      "step": 7280
    },
    {
      "epoch": 3.469776297001428,
      "grad_norm": 0.004919839091598988,
      "learning_rate": 1.3060447405997145e-05,
      "loss": 0.0127,
      "step": 7290
    },
    {
      "epoch": 3.4745359352689196,
      "grad_norm": 0.01257744338363409,
      "learning_rate": 1.3050928129462161e-05,
      "loss": 0.049,
      "step": 7300
    },
    {
      "epoch": 3.4792955735364113,
      "grad_norm": 0.009877518750727177,
      "learning_rate": 1.3041408852927177e-05,
      "loss": 0.0115,
      "step": 7310
    },
    {
      "epoch": 3.484055211803903,
      "grad_norm": 0.004052065312862396,
      "learning_rate": 1.3031889576392197e-05,
      "loss": 0.0031,
      "step": 7320
    },
    {
      "epoch": 3.4888148500713947,
      "grad_norm": 10.866605758666992,
      "learning_rate": 1.3022370299857213e-05,
      "loss": 0.0259,
      "step": 7330
    },
    {
      "epoch": 3.4935744883388864,
      "grad_norm": 0.008171193301677704,
      "learning_rate": 1.3012851023322229e-05,
      "loss": 0.012,
      "step": 7340
    },
    {
      "epoch": 3.498334126606378,
      "grad_norm": 0.0022767812479287386,
      "learning_rate": 1.3003331746787245e-05,
      "loss": 0.0005,
      "step": 7350
    },
    {
      "epoch": 3.50309376487387,
      "grad_norm": 0.004755851346999407,
      "learning_rate": 1.2993812470252262e-05,
      "loss": 0.0004,
      "step": 7360
    },
    {
      "epoch": 3.507853403141361,
      "grad_norm": 0.4414517283439636,
      "learning_rate": 1.2984293193717278e-05,
      "loss": 0.0184,
      "step": 7370
    },
    {
      "epoch": 3.5126130414088528,
      "grad_norm": 0.21517109870910645,
      "learning_rate": 1.2974773917182296e-05,
      "loss": 0.0276,
      "step": 7380
    },
    {
      "epoch": 3.5173726796763445,
      "grad_norm": 0.07318076491355896,
      "learning_rate": 1.2965254640647312e-05,
      "loss": 0.0005,
      "step": 7390
    },
    {
      "epoch": 3.522132317943836,
      "grad_norm": 0.025697151198983192,
      "learning_rate": 1.295573536411233e-05,
      "loss": 0.0019,
      "step": 7400
    },
    {
      "epoch": 3.526891956211328,
      "grad_norm": 0.024647323414683342,
      "learning_rate": 1.2946216087577346e-05,
      "loss": 0.0368,
      "step": 7410
    },
    {
      "epoch": 3.5316515944788196,
      "grad_norm": 0.5325888991355896,
      "learning_rate": 1.2936696811042362e-05,
      "loss": 0.0198,
      "step": 7420
    },
    {
      "epoch": 3.5364112327463113,
      "grad_norm": 0.007909056730568409,
      "learning_rate": 1.2927177534507378e-05,
      "loss": 0.0338,
      "step": 7430
    },
    {
      "epoch": 3.541170871013803,
      "grad_norm": 0.02235410548746586,
      "learning_rate": 1.2917658257972393e-05,
      "loss": 0.0153,
      "step": 7440
    },
    {
      "epoch": 3.5459305092812947,
      "grad_norm": 0.01709180325269699,
      "learning_rate": 1.2908138981437413e-05,
      "loss": 0.0201,
      "step": 7450
    },
    {
      "epoch": 3.5506901475487864,
      "grad_norm": 0.5733432769775391,
      "learning_rate": 1.2898619704902429e-05,
      "loss": 0.0656,
      "step": 7460
    },
    {
      "epoch": 3.555449785816278,
      "grad_norm": 7.148250102996826,
      "learning_rate": 1.2889100428367445e-05,
      "loss": 0.0192,
      "step": 7470
    },
    {
      "epoch": 3.5602094240837694,
      "grad_norm": 0.03819978982210159,
      "learning_rate": 1.287958115183246e-05,
      "loss": 0.0212,
      "step": 7480
    },
    {
      "epoch": 3.5649690623512615,
      "grad_norm": 0.017639746889472008,
      "learning_rate": 1.2870061875297479e-05,
      "loss": 0.0013,
      "step": 7490
    },
    {
      "epoch": 3.569728700618753,
      "grad_norm": 1.3109852075576782,
      "learning_rate": 1.2860542598762496e-05,
      "loss": 0.042,
      "step": 7500
    },
    {
      "epoch": 3.5744883388862445,
      "grad_norm": 0.03721051663160324,
      "learning_rate": 1.2851023322227512e-05,
      "loss": 0.0052,
      "step": 7510
    },
    {
      "epoch": 3.579247977153736,
      "grad_norm": 0.024830752983689308,
      "learning_rate": 1.2841504045692528e-05,
      "loss": 0.0227,
      "step": 7520
    },
    {
      "epoch": 3.584007615421228,
      "grad_norm": 0.06253325939178467,
      "learning_rate": 1.2831984769157546e-05,
      "loss": 0.0012,
      "step": 7530
    },
    {
      "epoch": 3.5887672536887196,
      "grad_norm": 0.005863407626748085,
      "learning_rate": 1.2822465492622562e-05,
      "loss": 0.0146,
      "step": 7540
    },
    {
      "epoch": 3.5935268919562113,
      "grad_norm": 0.013907080516219139,
      "learning_rate": 1.2812946216087578e-05,
      "loss": 0.0092,
      "step": 7550
    },
    {
      "epoch": 3.598286530223703,
      "grad_norm": 0.003939482383430004,
      "learning_rate": 1.2803426939552594e-05,
      "loss": 0.0174,
      "step": 7560
    },
    {
      "epoch": 3.6030461684911947,
      "grad_norm": 0.07281782478094101,
      "learning_rate": 1.2793907663017611e-05,
      "loss": 0.0025,
      "step": 7570
    },
    {
      "epoch": 3.6078058067586865,
      "grad_norm": 0.20203612744808197,
      "learning_rate": 1.278438838648263e-05,
      "loss": 0.0257,
      "step": 7580
    },
    {
      "epoch": 3.612565445026178,
      "grad_norm": 0.0022040826734155416,
      "learning_rate": 1.2774869109947645e-05,
      "loss": 0.0115,
      "step": 7590
    },
    {
      "epoch": 3.61732508329367,
      "grad_norm": 0.005692906212061644,
      "learning_rate": 1.2765349833412661e-05,
      "loss": 0.0012,
      "step": 7600
    },
    {
      "epoch": 3.622084721561161,
      "grad_norm": 0.014820219948887825,
      "learning_rate": 1.2755830556877677e-05,
      "loss": 0.002,
      "step": 7610
    },
    {
      "epoch": 3.6268443598286533,
      "grad_norm": 0.006232328247278929,
      "learning_rate": 1.2746311280342696e-05,
      "loss": 0.0018,
      "step": 7620
    },
    {
      "epoch": 3.6316039980961445,
      "grad_norm": 0.007410967722535133,
      "learning_rate": 1.2736792003807712e-05,
      "loss": 0.0299,
      "step": 7630
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 0.03418318182229996,
      "learning_rate": 1.2727272727272728e-05,
      "loss": 0.0438,
      "step": 7640
    },
    {
      "epoch": 3.641123274631128,
      "grad_norm": 0.004309851676225662,
      "learning_rate": 1.2717753450737744e-05,
      "loss": 0.0239,
      "step": 7650
    },
    {
      "epoch": 3.6458829128986197,
      "grad_norm": 0.007942535914480686,
      "learning_rate": 1.2708234174202762e-05,
      "loss": 0.0066,
      "step": 7660
    },
    {
      "epoch": 3.6506425511661114,
      "grad_norm": 0.05018588528037071,
      "learning_rate": 1.2698714897667778e-05,
      "loss": 0.0208,
      "step": 7670
    },
    {
      "epoch": 3.655402189433603,
      "grad_norm": 0.003068501129746437,
      "learning_rate": 1.2689195621132794e-05,
      "loss": 0.0179,
      "step": 7680
    },
    {
      "epoch": 3.6601618277010948,
      "grad_norm": 6.377876281738281,
      "learning_rate": 1.2679676344597812e-05,
      "loss": 0.0198,
      "step": 7690
    },
    {
      "epoch": 3.6649214659685865,
      "grad_norm": 0.12619271874427795,
      "learning_rate": 1.2670157068062828e-05,
      "loss": 0.0003,
      "step": 7700
    },
    {
      "epoch": 3.669681104236078,
      "grad_norm": 0.004094826057553291,
      "learning_rate": 1.2660637791527845e-05,
      "loss": 0.0003,
      "step": 7710
    },
    {
      "epoch": 3.67444074250357,
      "grad_norm": 0.004433813970535994,
      "learning_rate": 1.2651118514992861e-05,
      "loss": 0.0027,
      "step": 7720
    },
    {
      "epoch": 3.6792003807710616,
      "grad_norm": 0.022969314828515053,
      "learning_rate": 1.2641599238457877e-05,
      "loss": 0.0356,
      "step": 7730
    },
    {
      "epoch": 3.683960019038553,
      "grad_norm": 0.2097654938697815,
      "learning_rate": 1.2632079961922893e-05,
      "loss": 0.0003,
      "step": 7740
    },
    {
      "epoch": 3.688719657306045,
      "grad_norm": 0.0051744244992733,
      "learning_rate": 1.2622560685387913e-05,
      "loss": 0.0025,
      "step": 7750
    },
    {
      "epoch": 3.6934792955735363,
      "grad_norm": 11.798990249633789,
      "learning_rate": 1.2613041408852929e-05,
      "loss": 0.004,
      "step": 7760
    },
    {
      "epoch": 3.698238933841028,
      "grad_norm": 0.009383352473378181,
      "learning_rate": 1.2603522132317945e-05,
      "loss": 0.0121,
      "step": 7770
    },
    {
      "epoch": 3.7029985721085197,
      "grad_norm": 3.8101139068603516,
      "learning_rate": 1.259400285578296e-05,
      "loss": 0.0022,
      "step": 7780
    },
    {
      "epoch": 3.7077582103760114,
      "grad_norm": 0.019055161625146866,
      "learning_rate": 1.2584483579247978e-05,
      "loss": 0.0629,
      "step": 7790
    },
    {
      "epoch": 3.712517848643503,
      "grad_norm": 0.0041009532287716866,
      "learning_rate": 1.2574964302712996e-05,
      "loss": 0.0004,
      "step": 7800
    },
    {
      "epoch": 3.717277486910995,
      "grad_norm": 0.024941664189100266,
      "learning_rate": 1.2565445026178012e-05,
      "loss": 0.0102,
      "step": 7810
    },
    {
      "epoch": 3.7220371251784865,
      "grad_norm": 10.393890380859375,
      "learning_rate": 1.2555925749643028e-05,
      "loss": 0.0215,
      "step": 7820
    },
    {
      "epoch": 3.726796763445978,
      "grad_norm": 11.789511680603027,
      "learning_rate": 1.2546406473108044e-05,
      "loss": 0.0294,
      "step": 7830
    },
    {
      "epoch": 3.73155640171347,
      "grad_norm": 0.3556721806526184,
      "learning_rate": 1.2536887196573062e-05,
      "loss": 0.0003,
      "step": 7840
    },
    {
      "epoch": 3.736316039980961,
      "grad_norm": 0.07054849714040756,
      "learning_rate": 1.2527367920038078e-05,
      "loss": 0.0004,
      "step": 7850
    },
    {
      "epoch": 3.7410756782484533,
      "grad_norm": 0.002210931619629264,
      "learning_rate": 1.2517848643503094e-05,
      "loss": 0.0021,
      "step": 7860
    },
    {
      "epoch": 3.7458353165159446,
      "grad_norm": 0.665264904499054,
      "learning_rate": 1.250832936696811e-05,
      "loss": 0.0305,
      "step": 7870
    },
    {
      "epoch": 3.7505949547834363,
      "grad_norm": 0.033519335091114044,
      "learning_rate": 1.2498810090433129e-05,
      "loss": 0.0003,
      "step": 7880
    },
    {
      "epoch": 3.755354593050928,
      "grad_norm": 0.001242775353603065,
      "learning_rate": 1.2489290813898145e-05,
      "loss": 0.0001,
      "step": 7890
    },
    {
      "epoch": 3.7601142313184197,
      "grad_norm": 0.003308678977191448,
      "learning_rate": 1.2479771537363161e-05,
      "loss": 0.0005,
      "step": 7900
    },
    {
      "epoch": 3.7648738695859114,
      "grad_norm": 0.02975483238697052,
      "learning_rate": 1.2470252260828177e-05,
      "loss": 0.0096,
      "step": 7910
    },
    {
      "epoch": 3.769633507853403,
      "grad_norm": 0.0024958259891718626,
      "learning_rate": 1.2460732984293196e-05,
      "loss": 0.0001,
      "step": 7920
    },
    {
      "epoch": 3.774393146120895,
      "grad_norm": 0.43695539236068726,
      "learning_rate": 1.2451213707758212e-05,
      "loss": 0.0304,
      "step": 7930
    },
    {
      "epoch": 3.7791527843883865,
      "grad_norm": 0.03937592729926109,
      "learning_rate": 1.2441694431223228e-05,
      "loss": 0.0112,
      "step": 7940
    },
    {
      "epoch": 3.7839124226558782,
      "grad_norm": 0.011237859725952148,
      "learning_rate": 1.2432175154688244e-05,
      "loss": 0.0201,
      "step": 7950
    },
    {
      "epoch": 3.78867206092337,
      "grad_norm": 0.36073246598243713,
      "learning_rate": 1.2422655878153262e-05,
      "loss": 0.0002,
      "step": 7960
    },
    {
      "epoch": 3.7934316991908617,
      "grad_norm": 0.006000625900924206,
      "learning_rate": 1.2413136601618278e-05,
      "loss": 0.0012,
      "step": 7970
    },
    {
      "epoch": 3.798191337458353,
      "grad_norm": 4.201514720916748,
      "learning_rate": 1.2403617325083294e-05,
      "loss": 0.0031,
      "step": 7980
    },
    {
      "epoch": 3.802950975725845,
      "grad_norm": 0.004118908662348986,
      "learning_rate": 1.2394098048548312e-05,
      "loss": 0.0112,
      "step": 7990
    },
    {
      "epoch": 3.8077106139933363,
      "grad_norm": 0.029548274353146553,
      "learning_rate": 1.2384578772013328e-05,
      "loss": 0.0065,
      "step": 8000
    },
    {
      "epoch": 3.812470252260828,
      "grad_norm": 0.002920775441452861,
      "learning_rate": 1.2375059495478345e-05,
      "loss": 0.0005,
      "step": 8010
    },
    {
      "epoch": 3.8172298905283197,
      "grad_norm": 0.0737488716840744,
      "learning_rate": 1.2365540218943361e-05,
      "loss": 0.0246,
      "step": 8020
    },
    {
      "epoch": 3.8219895287958114,
      "grad_norm": 0.00396273098886013,
      "learning_rate": 1.2356020942408377e-05,
      "loss": 0.0002,
      "step": 8030
    },
    {
      "epoch": 3.826749167063303,
      "grad_norm": 13.378512382507324,
      "learning_rate": 1.2346501665873393e-05,
      "loss": 0.0352,
      "step": 8040
    },
    {
      "epoch": 3.831508805330795,
      "grad_norm": 0.005727251525968313,
      "learning_rate": 1.2336982389338413e-05,
      "loss": 0.0003,
      "step": 8050
    },
    {
      "epoch": 3.8362684435982866,
      "grad_norm": 0.31319937109947205,
      "learning_rate": 1.2327463112803429e-05,
      "loss": 0.0127,
      "step": 8060
    },
    {
      "epoch": 3.8410280818657783,
      "grad_norm": 0.02838038094341755,
      "learning_rate": 1.2317943836268445e-05,
      "loss": 0.0219,
      "step": 8070
    },
    {
      "epoch": 3.84578772013327,
      "grad_norm": 0.0017442293465137482,
      "learning_rate": 1.230842455973346e-05,
      "loss": 0.0132,
      "step": 8080
    },
    {
      "epoch": 3.8505473584007617,
      "grad_norm": 0.005799439270049334,
      "learning_rate": 1.2298905283198478e-05,
      "loss": 0.0241,
      "step": 8090
    },
    {
      "epoch": 3.8553069966682534,
      "grad_norm": 0.040021978318691254,
      "learning_rate": 1.2289386006663494e-05,
      "loss": 0.0335,
      "step": 8100
    },
    {
      "epoch": 3.8600666349357446,
      "grad_norm": 0.009747649542987347,
      "learning_rate": 1.2279866730128512e-05,
      "loss": 0.0007,
      "step": 8110
    },
    {
      "epoch": 3.864826273203237,
      "grad_norm": 0.03483176603913307,
      "learning_rate": 1.2270347453593528e-05,
      "loss": 0.0007,
      "step": 8120
    },
    {
      "epoch": 3.869585911470728,
      "grad_norm": 0.014555675908923149,
      "learning_rate": 1.2260828177058544e-05,
      "loss": 0.0028,
      "step": 8130
    },
    {
      "epoch": 3.8743455497382198,
      "grad_norm": 16.054771423339844,
      "learning_rate": 1.2251308900523562e-05,
      "loss": 0.0394,
      "step": 8140
    },
    {
      "epoch": 3.8791051880057115,
      "grad_norm": 0.2684064507484436,
      "learning_rate": 1.2241789623988578e-05,
      "loss": 0.0169,
      "step": 8150
    },
    {
      "epoch": 3.883864826273203,
      "grad_norm": 0.17943167686462402,
      "learning_rate": 1.2232270347453594e-05,
      "loss": 0.0006,
      "step": 8160
    },
    {
      "epoch": 3.888624464540695,
      "grad_norm": 0.002728433348238468,
      "learning_rate": 1.222275107091861e-05,
      "loss": 0.0138,
      "step": 8170
    },
    {
      "epoch": 3.8933841028081866,
      "grad_norm": 0.012406612746417522,
      "learning_rate": 1.2213231794383629e-05,
      "loss": 0.0002,
      "step": 8180
    },
    {
      "epoch": 3.8981437410756783,
      "grad_norm": 0.002728276653215289,
      "learning_rate": 1.2203712517848645e-05,
      "loss": 0.0001,
      "step": 8190
    },
    {
      "epoch": 3.90290337934317,
      "grad_norm": 0.013434763066470623,
      "learning_rate": 1.2194193241313661e-05,
      "loss": 0.0033,
      "step": 8200
    },
    {
      "epoch": 3.9076630176106617,
      "grad_norm": 0.0031227434519678354,
      "learning_rate": 1.2184673964778677e-05,
      "loss": 0.0181,
      "step": 8210
    },
    {
      "epoch": 3.9124226558781534,
      "grad_norm": 0.00940810889005661,
      "learning_rate": 1.2175154688243696e-05,
      "loss": 0.0001,
      "step": 8220
    },
    {
      "epoch": 3.917182294145645,
      "grad_norm": 0.0017295816214755177,
      "learning_rate": 1.2165635411708712e-05,
      "loss": 0.0,
      "step": 8230
    },
    {
      "epoch": 3.9219419324131364,
      "grad_norm": 0.0017457948997616768,
      "learning_rate": 1.2156116135173728e-05,
      "loss": 0.0008,
      "step": 8240
    },
    {
      "epoch": 3.9267015706806285,
      "grad_norm": 7.810976982116699,
      "learning_rate": 1.2146596858638744e-05,
      "loss": 0.0253,
      "step": 8250
    },
    {
      "epoch": 3.93146120894812,
      "grad_norm": 20.36722755432129,
      "learning_rate": 1.213707758210376e-05,
      "loss": 0.0411,
      "step": 8260
    },
    {
      "epoch": 3.9362208472156115,
      "grad_norm": 0.009615300223231316,
      "learning_rate": 1.2127558305568778e-05,
      "loss": 0.0232,
      "step": 8270
    },
    {
      "epoch": 3.940980485483103,
      "grad_norm": 0.0020289337262511253,
      "learning_rate": 1.2118039029033794e-05,
      "loss": 0.0313,
      "step": 8280
    },
    {
      "epoch": 3.945740123750595,
      "grad_norm": 0.004683906678110361,
      "learning_rate": 1.210851975249881e-05,
      "loss": 0.0204,
      "step": 8290
    },
    {
      "epoch": 3.9504997620180866,
      "grad_norm": 0.008816106244921684,
      "learning_rate": 1.2099000475963828e-05,
      "loss": 0.0007,
      "step": 8300
    },
    {
      "epoch": 3.9552594002855783,
      "grad_norm": 0.007095153909176588,
      "learning_rate": 1.2089481199428845e-05,
      "loss": 0.0012,
      "step": 8310
    },
    {
      "epoch": 3.96001903855307,
      "grad_norm": 0.5138961672782898,
      "learning_rate": 1.2079961922893861e-05,
      "loss": 0.0258,
      "step": 8320
    },
    {
      "epoch": 3.9647786768205617,
      "grad_norm": 24.0828914642334,
      "learning_rate": 1.2070442646358877e-05,
      "loss": 0.0077,
      "step": 8330
    },
    {
      "epoch": 3.9695383150880534,
      "grad_norm": 0.014326531440019608,
      "learning_rate": 1.2060923369823893e-05,
      "loss": 0.0003,
      "step": 8340
    },
    {
      "epoch": 3.974297953355545,
      "grad_norm": 0.007168007083237171,
      "learning_rate": 1.2051404093288913e-05,
      "loss": 0.0194,
      "step": 8350
    },
    {
      "epoch": 3.979057591623037,
      "grad_norm": 0.03438271954655647,
      "learning_rate": 1.2041884816753929e-05,
      "loss": 0.0005,
      "step": 8360
    },
    {
      "epoch": 3.983817229890528,
      "grad_norm": 0.029347406700253487,
      "learning_rate": 1.2032365540218945e-05,
      "loss": 0.0021,
      "step": 8370
    },
    {
      "epoch": 3.9885768681580203,
      "grad_norm": 0.0007283619488589466,
      "learning_rate": 1.202284626368396e-05,
      "loss": 0.0002,
      "step": 8380
    },
    {
      "epoch": 3.9933365064255115,
      "grad_norm": 0.0015436599496752024,
      "learning_rate": 1.2013326987148977e-05,
      "loss": 0.0256,
      "step": 8390
    },
    {
      "epoch": 3.9980961446930032,
      "grad_norm": 0.10435787588357925,
      "learning_rate": 1.2003807710613994e-05,
      "loss": 0.0039,
      "step": 8400
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9950027762354248,
      "eval_f1": 0.9725400457665903,
      "eval_loss": 0.03222404047846794,
      "eval_precision": 0.9883720930232558,
      "eval_recall": 0.9572072072072072,
      "eval_runtime": 1879.018,
      "eval_samples_per_second": 7.669,
      "eval_steps_per_second": 0.959,
      "step": 8404
    },
    {
      "epoch": 4.002855782960495,
      "grad_norm": 3.8595011234283447,
      "learning_rate": 1.1994288434079012e-05,
      "loss": 0.0194,
      "step": 8410
    },
    {
      "epoch": 4.007615421227987,
      "grad_norm": 0.0013211778132244945,
      "learning_rate": 1.1984769157544028e-05,
      "loss": 0.0077,
      "step": 8420
    },
    {
      "epoch": 4.012375059495478,
      "grad_norm": 0.0022985332179814577,
      "learning_rate": 1.1975249881009044e-05,
      "loss": 0.0001,
      "step": 8430
    },
    {
      "epoch": 4.01713469776297,
      "grad_norm": 0.0010431193513795733,
      "learning_rate": 1.1965730604474062e-05,
      "loss": 0.0235,
      "step": 8440
    },
    {
      "epoch": 4.021894336030462,
      "grad_norm": 0.0008115649106912315,
      "learning_rate": 1.1956211327939078e-05,
      "loss": 0.0002,
      "step": 8450
    },
    {
      "epoch": 4.026653974297953,
      "grad_norm": 0.009639658033847809,
      "learning_rate": 1.1946692051404094e-05,
      "loss": 0.0,
      "step": 8460
    },
    {
      "epoch": 4.031413612565445,
      "grad_norm": 0.006298245396465063,
      "learning_rate": 1.193717277486911e-05,
      "loss": 0.0138,
      "step": 8470
    },
    {
      "epoch": 4.036173250832936,
      "grad_norm": 0.0015762759139761329,
      "learning_rate": 1.1927653498334129e-05,
      "loss": 0.0001,
      "step": 8480
    },
    {
      "epoch": 4.040932889100429,
      "grad_norm": 0.026669520884752274,
      "learning_rate": 1.1918134221799145e-05,
      "loss": 0.0031,
      "step": 8490
    },
    {
      "epoch": 4.04569252736792,
      "grad_norm": 0.010826898738741875,
      "learning_rate": 1.1908614945264161e-05,
      "loss": 0.0001,
      "step": 8500
    },
    {
      "epoch": 4.050452165635412,
      "grad_norm": 0.012142508290708065,
      "learning_rate": 1.1899095668729177e-05,
      "loss": 0.0,
      "step": 8510
    },
    {
      "epoch": 4.055211803902903,
      "grad_norm": 8.74916934967041,
      "learning_rate": 1.1889576392194193e-05,
      "loss": 0.0031,
      "step": 8520
    },
    {
      "epoch": 4.059971442170395,
      "grad_norm": 0.0008178048301488161,
      "learning_rate": 1.1880057115659212e-05,
      "loss": 0.0,
      "step": 8530
    },
    {
      "epoch": 4.064731080437887,
      "grad_norm": 1.8462748527526855,
      "learning_rate": 1.1870537839124228e-05,
      "loss": 0.0003,
      "step": 8540
    },
    {
      "epoch": 4.069490718705379,
      "grad_norm": 0.0017035045893862844,
      "learning_rate": 1.1861018562589244e-05,
      "loss": 0.0251,
      "step": 8550
    },
    {
      "epoch": 4.07425035697287,
      "grad_norm": 0.001576747396029532,
      "learning_rate": 1.185149928605426e-05,
      "loss": 0.0001,
      "step": 8560
    },
    {
      "epoch": 4.079009995240361,
      "grad_norm": 0.0022876972798258066,
      "learning_rate": 1.1841980009519278e-05,
      "loss": 0.0,
      "step": 8570
    },
    {
      "epoch": 4.0837696335078535,
      "grad_norm": 0.01901392452418804,
      "learning_rate": 1.1832460732984294e-05,
      "loss": 0.0183,
      "step": 8580
    },
    {
      "epoch": 4.088529271775345,
      "grad_norm": 0.0011683261254802346,
      "learning_rate": 1.182294145644931e-05,
      "loss": 0.0234,
      "step": 8590
    },
    {
      "epoch": 4.093288910042837,
      "grad_norm": 0.02871273085474968,
      "learning_rate": 1.1813422179914328e-05,
      "loss": 0.0206,
      "step": 8600
    },
    {
      "epoch": 4.098048548310328,
      "grad_norm": 0.009850171394646168,
      "learning_rate": 1.1803902903379345e-05,
      "loss": 0.0108,
      "step": 8610
    },
    {
      "epoch": 4.10280818657782,
      "grad_norm": 4.419723033905029,
      "learning_rate": 1.1794383626844361e-05,
      "loss": 0.0292,
      "step": 8620
    },
    {
      "epoch": 4.107567824845312,
      "grad_norm": 0.0026117844972759485,
      "learning_rate": 1.1784864350309377e-05,
      "loss": 0.01,
      "step": 8630
    },
    {
      "epoch": 4.112327463112804,
      "grad_norm": 0.0028021461330354214,
      "learning_rate": 1.1775345073774393e-05,
      "loss": 0.0,
      "step": 8640
    },
    {
      "epoch": 4.117087101380295,
      "grad_norm": 0.017008410766720772,
      "learning_rate": 1.1765825797239413e-05,
      "loss": 0.0102,
      "step": 8650
    },
    {
      "epoch": 4.121846739647787,
      "grad_norm": 6.179506778717041,
      "learning_rate": 1.1756306520704429e-05,
      "loss": 0.0059,
      "step": 8660
    },
    {
      "epoch": 4.126606377915278,
      "grad_norm": 0.002344821346923709,
      "learning_rate": 1.1746787244169445e-05,
      "loss": 0.003,
      "step": 8670
    },
    {
      "epoch": 4.1313660161827706,
      "grad_norm": 0.006110441405326128,
      "learning_rate": 1.173726796763446e-05,
      "loss": 0.0002,
      "step": 8680
    },
    {
      "epoch": 4.136125654450262,
      "grad_norm": 0.0032902047969400883,
      "learning_rate": 1.1727748691099476e-05,
      "loss": 0.0257,
      "step": 8690
    },
    {
      "epoch": 4.140885292717753,
      "grad_norm": 0.010031227022409439,
      "learning_rate": 1.1718229414564494e-05,
      "loss": 0.0414,
      "step": 8700
    },
    {
      "epoch": 4.145644930985245,
      "grad_norm": 0.025311175733804703,
      "learning_rate": 1.170871013802951e-05,
      "loss": 0.0153,
      "step": 8710
    },
    {
      "epoch": 4.1504045692527365,
      "grad_norm": 15.791009902954102,
      "learning_rate": 1.1699190861494528e-05,
      "loss": 0.0081,
      "step": 8720
    },
    {
      "epoch": 4.155164207520229,
      "grad_norm": 0.04387795552611351,
      "learning_rate": 1.1689671584959544e-05,
      "loss": 0.0001,
      "step": 8730
    },
    {
      "epoch": 4.15992384578772,
      "grad_norm": 0.06115804240107536,
      "learning_rate": 1.1680152308424561e-05,
      "loss": 0.0001,
      "step": 8740
    },
    {
      "epoch": 4.164683484055212,
      "grad_norm": 0.005303187761455774,
      "learning_rate": 1.1670633031889577e-05,
      "loss": 0.0001,
      "step": 8750
    },
    {
      "epoch": 4.169443122322703,
      "grad_norm": 0.005448049400001764,
      "learning_rate": 1.1661113755354593e-05,
      "loss": 0.0002,
      "step": 8760
    },
    {
      "epoch": 4.1742027605901955,
      "grad_norm": 0.0118638314306736,
      "learning_rate": 1.165159447881961e-05,
      "loss": 0.0139,
      "step": 8770
    },
    {
      "epoch": 4.178962398857687,
      "grad_norm": 0.001100791385397315,
      "learning_rate": 1.1642075202284629e-05,
      "loss": 0.009,
      "step": 8780
    },
    {
      "epoch": 4.183722037125179,
      "grad_norm": 0.0024635805748403072,
      "learning_rate": 1.1632555925749645e-05,
      "loss": 0.0178,
      "step": 8790
    },
    {
      "epoch": 4.18848167539267,
      "grad_norm": 0.004046890884637833,
      "learning_rate": 1.162303664921466e-05,
      "loss": 0.0169,
      "step": 8800
    },
    {
      "epoch": 4.193241313660161,
      "grad_norm": 0.0014071043115109205,
      "learning_rate": 1.1613517372679677e-05,
      "loss": 0.0004,
      "step": 8810
    },
    {
      "epoch": 4.1980009519276535,
      "grad_norm": 0.006936713121831417,
      "learning_rate": 1.1603998096144693e-05,
      "loss": 0.0049,
      "step": 8820
    },
    {
      "epoch": 4.202760590195145,
      "grad_norm": 0.005359055008739233,
      "learning_rate": 1.1594478819609712e-05,
      "loss": 0.0002,
      "step": 8830
    },
    {
      "epoch": 4.207520228462637,
      "grad_norm": 0.002692520385608077,
      "learning_rate": 1.1584959543074728e-05,
      "loss": 0.0366,
      "step": 8840
    },
    {
      "epoch": 4.212279866730128,
      "grad_norm": 1.1890002489089966,
      "learning_rate": 1.1575440266539744e-05,
      "loss": 0.0004,
      "step": 8850
    },
    {
      "epoch": 4.21703950499762,
      "grad_norm": 0.00957288034260273,
      "learning_rate": 1.156592099000476e-05,
      "loss": 0.0083,
      "step": 8860
    },
    {
      "epoch": 4.221799143265112,
      "grad_norm": 20.33417510986328,
      "learning_rate": 1.1556401713469778e-05,
      "loss": 0.0045,
      "step": 8870
    },
    {
      "epoch": 4.226558781532604,
      "grad_norm": 0.00176980288233608,
      "learning_rate": 1.1546882436934794e-05,
      "loss": 0.0077,
      "step": 8880
    },
    {
      "epoch": 4.231318419800095,
      "grad_norm": 0.001241908990778029,
      "learning_rate": 1.153736316039981e-05,
      "loss": 0.0001,
      "step": 8890
    },
    {
      "epoch": 4.236078058067587,
      "grad_norm": 0.013470606878399849,
      "learning_rate": 1.1527843883864826e-05,
      "loss": 0.0002,
      "step": 8900
    },
    {
      "epoch": 4.2408376963350785,
      "grad_norm": 0.006772700231522322,
      "learning_rate": 1.1518324607329845e-05,
      "loss": 0.0067,
      "step": 8910
    },
    {
      "epoch": 4.245597334602571,
      "grad_norm": 0.003181550884619355,
      "learning_rate": 1.1508805330794861e-05,
      "loss": 0.0156,
      "step": 8920
    },
    {
      "epoch": 4.250356972870062,
      "grad_norm": 0.0038491361774504185,
      "learning_rate": 1.1499286054259877e-05,
      "loss": 0.0074,
      "step": 8930
    },
    {
      "epoch": 4.255116611137554,
      "grad_norm": 7.186438083648682,
      "learning_rate": 1.1489766777724893e-05,
      "loss": 0.0048,
      "step": 8940
    },
    {
      "epoch": 4.259876249405045,
      "grad_norm": 0.016104143112897873,
      "learning_rate": 1.1480247501189909e-05,
      "loss": 0.0015,
      "step": 8950
    },
    {
      "epoch": 4.2646358876725365,
      "grad_norm": 0.013659598305821419,
      "learning_rate": 1.1470728224654928e-05,
      "loss": 0.0363,
      "step": 8960
    },
    {
      "epoch": 4.269395525940029,
      "grad_norm": 0.0032819409389048815,
      "learning_rate": 1.1461208948119944e-05,
      "loss": 0.0289,
      "step": 8970
    },
    {
      "epoch": 4.27415516420752,
      "grad_norm": 0.001711467164568603,
      "learning_rate": 1.145168967158496e-05,
      "loss": 0.0009,
      "step": 8980
    },
    {
      "epoch": 4.278914802475012,
      "grad_norm": 0.004355022218078375,
      "learning_rate": 1.1442170395049976e-05,
      "loss": 0.0158,
      "step": 8990
    },
    {
      "epoch": 4.283674440742503,
      "grad_norm": 0.0017075298819690943,
      "learning_rate": 1.1432651118514994e-05,
      "loss": 0.0006,
      "step": 9000
    },
    {
      "epoch": 4.2884340790099955,
      "grad_norm": 0.002303760265931487,
      "learning_rate": 1.142313184198001e-05,
      "loss": 0.0013,
      "step": 9010
    },
    {
      "epoch": 4.293193717277487,
      "grad_norm": 0.006339920684695244,
      "learning_rate": 1.1413612565445028e-05,
      "loss": 0.0052,
      "step": 9020
    },
    {
      "epoch": 4.297953355544979,
      "grad_norm": 0.0032461623195558786,
      "learning_rate": 1.1404093288910044e-05,
      "loss": 0.0209,
      "step": 9030
    },
    {
      "epoch": 4.30271299381247,
      "grad_norm": 0.007699735462665558,
      "learning_rate": 1.1394574012375061e-05,
      "loss": 0.0006,
      "step": 9040
    },
    {
      "epoch": 4.307472632079962,
      "grad_norm": 0.0023776108864694834,
      "learning_rate": 1.1385054735840077e-05,
      "loss": 0.0118,
      "step": 9050
    },
    {
      "epoch": 4.312232270347454,
      "grad_norm": 0.26019468903541565,
      "learning_rate": 1.1375535459305093e-05,
      "loss": 0.0137,
      "step": 9060
    },
    {
      "epoch": 4.316991908614945,
      "grad_norm": 0.021432051435112953,
      "learning_rate": 1.136601618277011e-05,
      "loss": 0.0042,
      "step": 9070
    },
    {
      "epoch": 4.321751546882437,
      "grad_norm": 2.214313507080078,
      "learning_rate": 1.1356496906235125e-05,
      "loss": 0.0405,
      "step": 9080
    },
    {
      "epoch": 4.326511185149928,
      "grad_norm": 0.059161555022001266,
      "learning_rate": 1.1346977629700145e-05,
      "loss": 0.0002,
      "step": 9090
    },
    {
      "epoch": 4.33127082341742,
      "grad_norm": 0.003014025976881385,
      "learning_rate": 1.133745835316516e-05,
      "loss": 0.0001,
      "step": 9100
    },
    {
      "epoch": 4.336030461684912,
      "grad_norm": 0.005640833172947168,
      "learning_rate": 1.1327939076630177e-05,
      "loss": 0.0006,
      "step": 9110
    },
    {
      "epoch": 4.340790099952404,
      "grad_norm": 0.18208518624305725,
      "learning_rate": 1.1318419800095193e-05,
      "loss": 0.0062,
      "step": 9120
    },
    {
      "epoch": 4.345549738219895,
      "grad_norm": 0.020300373435020447,
      "learning_rate": 1.130890052356021e-05,
      "loss": 0.0001,
      "step": 9130
    },
    {
      "epoch": 4.350309376487387,
      "grad_norm": 2.4727132320404053,
      "learning_rate": 1.1299381247025228e-05,
      "loss": 0.0061,
      "step": 9140
    },
    {
      "epoch": 4.3550690147548785,
      "grad_norm": 0.009679400362074375,
      "learning_rate": 1.1289861970490244e-05,
      "loss": 0.0067,
      "step": 9150
    },
    {
      "epoch": 4.359828653022371,
      "grad_norm": 0.000996304675936699,
      "learning_rate": 1.128034269395526e-05,
      "loss": 0.0002,
      "step": 9160
    },
    {
      "epoch": 4.364588291289862,
      "grad_norm": 0.002619420178234577,
      "learning_rate": 1.1270823417420278e-05,
      "loss": 0.0001,
      "step": 9170
    },
    {
      "epoch": 4.369347929557353,
      "grad_norm": 0.002627173438668251,
      "learning_rate": 1.1261304140885294e-05,
      "loss": 0.0001,
      "step": 9180
    },
    {
      "epoch": 4.374107567824845,
      "grad_norm": 1.8951928615570068,
      "learning_rate": 1.125178486435031e-05,
      "loss": 0.002,
      "step": 9190
    },
    {
      "epoch": 4.378867206092337,
      "grad_norm": 0.000979918404482305,
      "learning_rate": 1.1242265587815326e-05,
      "loss": 0.0032,
      "step": 9200
    },
    {
      "epoch": 4.383626844359829,
      "grad_norm": 0.0007358783041127026,
      "learning_rate": 1.1232746311280343e-05,
      "loss": 0.0,
      "step": 9210
    },
    {
      "epoch": 4.38838648262732,
      "grad_norm": 0.0005966246244497597,
      "learning_rate": 1.1223227034745361e-05,
      "loss": 0.0076,
      "step": 9220
    },
    {
      "epoch": 4.393146120894812,
      "grad_norm": 0.006868176627904177,
      "learning_rate": 1.1213707758210377e-05,
      "loss": 0.0,
      "step": 9230
    },
    {
      "epoch": 4.397905759162303,
      "grad_norm": 0.0007836650474928319,
      "learning_rate": 1.1204188481675393e-05,
      "loss": 0.0115,
      "step": 9240
    },
    {
      "epoch": 4.402665397429796,
      "grad_norm": 0.0006660846411250532,
      "learning_rate": 1.1194669205140409e-05,
      "loss": 0.0001,
      "step": 9250
    },
    {
      "epoch": 4.407425035697287,
      "grad_norm": 0.0007779141305945814,
      "learning_rate": 1.1185149928605428e-05,
      "loss": 0.0001,
      "step": 9260
    },
    {
      "epoch": 4.412184673964779,
      "grad_norm": 0.018735043704509735,
      "learning_rate": 1.1175630652070444e-05,
      "loss": 0.0067,
      "step": 9270
    },
    {
      "epoch": 4.41694431223227,
      "grad_norm": 0.009671901352703571,
      "learning_rate": 1.116611137553546e-05,
      "loss": 0.0022,
      "step": 9280
    },
    {
      "epoch": 4.421703950499762,
      "grad_norm": 0.0004373954434413463,
      "learning_rate": 1.1156592099000476e-05,
      "loss": 0.0,
      "step": 9290
    },
    {
      "epoch": 4.426463588767254,
      "grad_norm": 0.020499756559729576,
      "learning_rate": 1.1147072822465494e-05,
      "loss": 0.0003,
      "step": 9300
    },
    {
      "epoch": 4.431223227034746,
      "grad_norm": 0.0021988586522638798,
      "learning_rate": 1.113755354593051e-05,
      "loss": 0.0,
      "step": 9310
    },
    {
      "epoch": 4.435982865302237,
      "grad_norm": 0.0029459844809025526,
      "learning_rate": 1.1128034269395526e-05,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 4.440742503569728,
      "grad_norm": 0.0015604058280587196,
      "learning_rate": 1.1118514992860544e-05,
      "loss": 0.0001,
      "step": 9330
    },
    {
      "epoch": 4.4455021418372205,
      "grad_norm": 0.0023074650671333075,
      "learning_rate": 1.110899571632556e-05,
      "loss": 0.0001,
      "step": 9340
    },
    {
      "epoch": 4.450261780104712,
      "grad_norm": 0.0014947883319109678,
      "learning_rate": 1.1099476439790577e-05,
      "loss": 0.0152,
      "step": 9350
    },
    {
      "epoch": 4.455021418372204,
      "grad_norm": 0.003521163482218981,
      "learning_rate": 1.1089957163255593e-05,
      "loss": 0.0015,
      "step": 9360
    },
    {
      "epoch": 4.459781056639695,
      "grad_norm": 0.0026658931747078896,
      "learning_rate": 1.108043788672061e-05,
      "loss": 0.0117,
      "step": 9370
    },
    {
      "epoch": 4.464540694907187,
      "grad_norm": 0.007449553348124027,
      "learning_rate": 1.1070918610185625e-05,
      "loss": 0.0283,
      "step": 9380
    },
    {
      "epoch": 4.469300333174679,
      "grad_norm": 0.002243895549327135,
      "learning_rate": 1.1061399333650645e-05,
      "loss": 0.0003,
      "step": 9390
    },
    {
      "epoch": 4.474059971442171,
      "grad_norm": 0.0007166263530962169,
      "learning_rate": 1.105188005711566e-05,
      "loss": 0.0012,
      "step": 9400
    },
    {
      "epoch": 4.478819609709662,
      "grad_norm": 0.0023841820657253265,
      "learning_rate": 1.1042360780580677e-05,
      "loss": 0.0061,
      "step": 9410
    },
    {
      "epoch": 4.483579247977154,
      "grad_norm": 0.005235065706074238,
      "learning_rate": 1.1032841504045693e-05,
      "loss": 0.0006,
      "step": 9420
    },
    {
      "epoch": 4.488338886244645,
      "grad_norm": 5.270046234130859,
      "learning_rate": 1.102332222751071e-05,
      "loss": 0.0014,
      "step": 9430
    },
    {
      "epoch": 4.493098524512137,
      "grad_norm": 0.002422621240839362,
      "learning_rate": 1.1013802950975728e-05,
      "loss": 0.0136,
      "step": 9440
    },
    {
      "epoch": 4.497858162779629,
      "grad_norm": 0.0015870288480073214,
      "learning_rate": 1.1004283674440744e-05,
      "loss": 0.0002,
      "step": 9450
    },
    {
      "epoch": 4.50261780104712,
      "grad_norm": 0.004594095516949892,
      "learning_rate": 1.099476439790576e-05,
      "loss": 0.0081,
      "step": 9460
    },
    {
      "epoch": 4.507377439314612,
      "grad_norm": 0.07632920891046524,
      "learning_rate": 1.0985245121370778e-05,
      "loss": 0.0002,
      "step": 9470
    },
    {
      "epoch": 4.5121370775821035,
      "grad_norm": 0.014824711717665195,
      "learning_rate": 1.0975725844835794e-05,
      "loss": 0.0119,
      "step": 9480
    },
    {
      "epoch": 4.516896715849596,
      "grad_norm": 0.0031281437259167433,
      "learning_rate": 1.096620656830081e-05,
      "loss": 0.0015,
      "step": 9490
    },
    {
      "epoch": 4.521656354117087,
      "grad_norm": 22.219743728637695,
      "learning_rate": 1.0956687291765826e-05,
      "loss": 0.0025,
      "step": 9500
    },
    {
      "epoch": 4.526415992384579,
      "grad_norm": 0.0009658081689849496,
      "learning_rate": 1.0947168015230842e-05,
      "loss": 0.0186,
      "step": 9510
    },
    {
      "epoch": 4.53117563065207,
      "grad_norm": 0.08566202968358994,
      "learning_rate": 1.0937648738695861e-05,
      "loss": 0.0001,
      "step": 9520
    },
    {
      "epoch": 4.5359352689195624,
      "grad_norm": 0.00026105932192876935,
      "learning_rate": 1.0928129462160877e-05,
      "loss": 0.0001,
      "step": 9530
    },
    {
      "epoch": 4.540694907187054,
      "grad_norm": 0.0005986884934827685,
      "learning_rate": 1.0918610185625893e-05,
      "loss": 0.0134,
      "step": 9540
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.001006562844850123,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 4.550214183722037,
      "grad_norm": 0.0009990102844312787,
      "learning_rate": 1.0899571632555928e-05,
      "loss": 0.0007,
      "step": 9560
    },
    {
      "epoch": 4.554973821989529,
      "grad_norm": 0.0017817881889641285,
      "learning_rate": 1.0890052356020944e-05,
      "loss": 0.0331,
      "step": 9570
    },
    {
      "epoch": 4.5597334602570205,
      "grad_norm": 0.08107022941112518,
      "learning_rate": 1.088053307948596e-05,
      "loss": 0.0,
      "step": 9580
    },
    {
      "epoch": 4.564493098524512,
      "grad_norm": 0.0038608007598668337,
      "learning_rate": 1.0871013802950976e-05,
      "loss": 0.0248,
      "step": 9590
    },
    {
      "epoch": 4.569252736792004,
      "grad_norm": 0.0014492294285446405,
      "learning_rate": 1.0861494526415994e-05,
      "loss": 0.0047,
      "step": 9600
    },
    {
      "epoch": 4.574012375059495,
      "grad_norm": 0.0007291439105756581,
      "learning_rate": 1.085197524988101e-05,
      "loss": 0.0195,
      "step": 9610
    },
    {
      "epoch": 4.578772013326987,
      "grad_norm": 0.007619983982294798,
      "learning_rate": 1.0842455973346026e-05,
      "loss": 0.0363,
      "step": 9620
    },
    {
      "epoch": 4.583531651594479,
      "grad_norm": 0.008853216655552387,
      "learning_rate": 1.0832936696811044e-05,
      "loss": 0.037,
      "step": 9630
    },
    {
      "epoch": 4.588291289861971,
      "grad_norm": 0.02303246781229973,
      "learning_rate": 1.082341742027606e-05,
      "loss": 0.0006,
      "step": 9640
    },
    {
      "epoch": 4.593050928129462,
      "grad_norm": 0.0018066667253151536,
      "learning_rate": 1.0813898143741077e-05,
      "loss": 0.0062,
      "step": 9650
    },
    {
      "epoch": 4.597810566396954,
      "grad_norm": 0.005639717914164066,
      "learning_rate": 1.0804378867206093e-05,
      "loss": 0.0092,
      "step": 9660
    },
    {
      "epoch": 4.602570204664445,
      "grad_norm": 0.0014792310539633036,
      "learning_rate": 1.079485959067111e-05,
      "loss": 0.0001,
      "step": 9670
    },
    {
      "epoch": 4.607329842931938,
      "grad_norm": 2.4384829998016357,
      "learning_rate": 1.0785340314136125e-05,
      "loss": 0.0231,
      "step": 9680
    },
    {
      "epoch": 4.612089481199429,
      "grad_norm": 0.008329545147716999,
      "learning_rate": 1.0775821037601145e-05,
      "loss": 0.0001,
      "step": 9690
    },
    {
      "epoch": 4.61684911946692,
      "grad_norm": 0.15720517933368683,
      "learning_rate": 1.076630176106616e-05,
      "loss": 0.0091,
      "step": 9700
    },
    {
      "epoch": 4.621608757734412,
      "grad_norm": 13.411598205566406,
      "learning_rate": 1.0756782484531177e-05,
      "loss": 0.003,
      "step": 9710
    },
    {
      "epoch": 4.6263683960019035,
      "grad_norm": 0.01321492437273264,
      "learning_rate": 1.0747263207996193e-05,
      "loss": 0.0023,
      "step": 9720
    },
    {
      "epoch": 4.631128034269396,
      "grad_norm": 0.2940724492073059,
      "learning_rate": 1.073774393146121e-05,
      "loss": 0.0003,
      "step": 9730
    },
    {
      "epoch": 4.635887672536887,
      "grad_norm": 0.022048739716410637,
      "learning_rate": 1.0728224654926226e-05,
      "loss": 0.024,
      "step": 9740
    },
    {
      "epoch": 4.640647310804379,
      "grad_norm": 0.009819255210459232,
      "learning_rate": 1.0718705378391244e-05,
      "loss": 0.0,
      "step": 9750
    },
    {
      "epoch": 4.64540694907187,
      "grad_norm": 0.000987229053862393,
      "learning_rate": 1.070918610185626e-05,
      "loss": 0.0001,
      "step": 9760
    },
    {
      "epoch": 4.6501665873393625,
      "grad_norm": 0.0034614396281540394,
      "learning_rate": 1.0699666825321276e-05,
      "loss": 0.0,
      "step": 9770
    },
    {
      "epoch": 4.654926225606854,
      "grad_norm": 0.0010162931866943836,
      "learning_rate": 1.0690147548786294e-05,
      "loss": 0.0064,
      "step": 9780
    },
    {
      "epoch": 4.659685863874346,
      "grad_norm": 16.683551788330078,
      "learning_rate": 1.068062827225131e-05,
      "loss": 0.0053,
      "step": 9790
    },
    {
      "epoch": 4.664445502141837,
      "grad_norm": 0.0018946155905723572,
      "learning_rate": 1.0671108995716326e-05,
      "loss": 0.0004,
      "step": 9800
    },
    {
      "epoch": 4.669205140409328,
      "grad_norm": 0.06023728847503662,
      "learning_rate": 1.0661589719181341e-05,
      "loss": 0.0388,
      "step": 9810
    },
    {
      "epoch": 4.673964778676821,
      "grad_norm": 0.0010276881512254477,
      "learning_rate": 1.0652070442646361e-05,
      "loss": 0.011,
      "step": 9820
    },
    {
      "epoch": 4.678724416944312,
      "grad_norm": 1.326535701751709,
      "learning_rate": 1.0642551166111377e-05,
      "loss": 0.0078,
      "step": 9830
    },
    {
      "epoch": 4.683484055211804,
      "grad_norm": 0.0006159695331007242,
      "learning_rate": 1.0633031889576393e-05,
      "loss": 0.0115,
      "step": 9840
    },
    {
      "epoch": 4.688243693479295,
      "grad_norm": 0.012878421694040298,
      "learning_rate": 1.0623512613041409e-05,
      "loss": 0.0006,
      "step": 9850
    },
    {
      "epoch": 4.693003331746787,
      "grad_norm": 9.660787582397461,
      "learning_rate": 1.0613993336506428e-05,
      "loss": 0.0055,
      "step": 9860
    },
    {
      "epoch": 4.697762970014279,
      "grad_norm": 6.529067516326904,
      "learning_rate": 1.0604474059971444e-05,
      "loss": 0.0145,
      "step": 9870
    },
    {
      "epoch": 4.702522608281771,
      "grad_norm": 0.013402106240391731,
      "learning_rate": 1.059495478343646e-05,
      "loss": 0.0001,
      "step": 9880
    },
    {
      "epoch": 4.707282246549262,
      "grad_norm": 0.0030922023579478264,
      "learning_rate": 1.0585435506901476e-05,
      "loss": 0.0061,
      "step": 9890
    },
    {
      "epoch": 4.712041884816754,
      "grad_norm": 0.0020838496275246143,
      "learning_rate": 1.0575916230366492e-05,
      "loss": 0.0196,
      "step": 9900
    },
    {
      "epoch": 4.7168015230842455,
      "grad_norm": 0.0034333281219005585,
      "learning_rate": 1.056639695383151e-05,
      "loss": 0.0073,
      "step": 9910
    },
    {
      "epoch": 4.721561161351738,
      "grad_norm": 0.0006220781360752881,
      "learning_rate": 1.0556877677296526e-05,
      "loss": 0.0,
      "step": 9920
    },
    {
      "epoch": 4.726320799619229,
      "grad_norm": 0.002930693794041872,
      "learning_rate": 1.0547358400761542e-05,
      "loss": 0.0,
      "step": 9930
    },
    {
      "epoch": 4.731080437886721,
      "grad_norm": 0.001603645971044898,
      "learning_rate": 1.053783912422656e-05,
      "loss": 0.0176,
      "step": 9940
    },
    {
      "epoch": 4.735840076154212,
      "grad_norm": 0.008211242966353893,
      "learning_rate": 1.0528319847691577e-05,
      "loss": 0.0254,
      "step": 9950
    },
    {
      "epoch": 4.740599714421704,
      "grad_norm": 0.00216719345189631,
      "learning_rate": 1.0518800571156593e-05,
      "loss": 0.0235,
      "step": 9960
    },
    {
      "epoch": 4.745359352689196,
      "grad_norm": 0.003097045933827758,
      "learning_rate": 1.0509281294621609e-05,
      "loss": 0.0083,
      "step": 9970
    },
    {
      "epoch": 4.750118990956687,
      "grad_norm": 2.645565986633301,
      "learning_rate": 1.0499762018086625e-05,
      "loss": 0.0211,
      "step": 9980
    },
    {
      "epoch": 4.754878629224179,
      "grad_norm": 0.00277474382892251,
      "learning_rate": 1.0490242741551644e-05,
      "loss": 0.0002,
      "step": 9990
    },
    {
      "epoch": 4.75963826749167,
      "grad_norm": 0.004431603010743856,
      "learning_rate": 1.048072346501666e-05,
      "loss": 0.0012,
      "step": 10000
    },
    {
      "epoch": 4.7643979057591626,
      "grad_norm": 0.03117780201137066,
      "learning_rate": 1.0471204188481676e-05,
      "loss": 0.0046,
      "step": 10010
    },
    {
      "epoch": 4.769157544026654,
      "grad_norm": 0.004778959322720766,
      "learning_rate": 1.0461684911946692e-05,
      "loss": 0.0001,
      "step": 10020
    },
    {
      "epoch": 4.773917182294146,
      "grad_norm": 0.0040741595439612865,
      "learning_rate": 1.0452165635411708e-05,
      "loss": 0.0004,
      "step": 10030
    },
    {
      "epoch": 4.778676820561637,
      "grad_norm": 0.1829497069120407,
      "learning_rate": 1.0442646358876726e-05,
      "loss": 0.0001,
      "step": 10040
    },
    {
      "epoch": 4.783436458829129,
      "grad_norm": 0.002224401105195284,
      "learning_rate": 1.0433127082341744e-05,
      "loss": 0.0002,
      "step": 10050
    },
    {
      "epoch": 4.788196097096621,
      "grad_norm": 0.0009381938725709915,
      "learning_rate": 1.042360780580676e-05,
      "loss": 0.0138,
      "step": 10060
    },
    {
      "epoch": 4.792955735364112,
      "grad_norm": 0.008786181919276714,
      "learning_rate": 1.0414088529271776e-05,
      "loss": 0.0001,
      "step": 10070
    },
    {
      "epoch": 4.797715373631604,
      "grad_norm": 0.0004725443141069263,
      "learning_rate": 1.0404569252736793e-05,
      "loss": 0.0001,
      "step": 10080
    },
    {
      "epoch": 4.802475011899095,
      "grad_norm": 0.0020431175362318754,
      "learning_rate": 1.039504997620181e-05,
      "loss": 0.0001,
      "step": 10090
    },
    {
      "epoch": 4.8072346501665875,
      "grad_norm": 0.0031718637328594923,
      "learning_rate": 1.0385530699666825e-05,
      "loss": 0.0001,
      "step": 10100
    },
    {
      "epoch": 4.811994288434079,
      "grad_norm": 0.0005149927455931902,
      "learning_rate": 1.0376011423131841e-05,
      "loss": 0.0079,
      "step": 10110
    },
    {
      "epoch": 4.816753926701571,
      "grad_norm": 0.017098059877753258,
      "learning_rate": 1.036649214659686e-05,
      "loss": 0.0001,
      "step": 10120
    },
    {
      "epoch": 4.821513564969062,
      "grad_norm": 0.002335286233574152,
      "learning_rate": 1.0356972870061877e-05,
      "loss": 0.0079,
      "step": 10130
    },
    {
      "epoch": 4.826273203236554,
      "grad_norm": 0.0015757022192701697,
      "learning_rate": 1.0347453593526893e-05,
      "loss": 0.0001,
      "step": 10140
    },
    {
      "epoch": 4.8310328415040455,
      "grad_norm": 0.0009655983885750175,
      "learning_rate": 1.0337934316991909e-05,
      "loss": 0.0033,
      "step": 10150
    },
    {
      "epoch": 4.835792479771538,
      "grad_norm": 0.1255073845386505,
      "learning_rate": 1.0328415040456926e-05,
      "loss": 0.0001,
      "step": 10160
    },
    {
      "epoch": 4.840552118039029,
      "grad_norm": 0.0020041894167661667,
      "learning_rate": 1.0318895763921944e-05,
      "loss": 0.0,
      "step": 10170
    },
    {
      "epoch": 4.84531175630652,
      "grad_norm": 0.0004081611696165055,
      "learning_rate": 1.030937648738696e-05,
      "loss": 0.0139,
      "step": 10180
    },
    {
      "epoch": 4.850071394574012,
      "grad_norm": 0.0008568305056542158,
      "learning_rate": 1.0299857210851976e-05,
      "loss": 0.0005,
      "step": 10190
    },
    {
      "epoch": 4.8548310328415045,
      "grad_norm": 0.0006574327708221972,
      "learning_rate": 1.0290337934316992e-05,
      "loss": 0.0004,
      "step": 10200
    },
    {
      "epoch": 4.859590671108996,
      "grad_norm": 0.00028527845279313624,
      "learning_rate": 1.028081865778201e-05,
      "loss": 0.0075,
      "step": 10210
    },
    {
      "epoch": 4.864350309376487,
      "grad_norm": 0.0019293093355372548,
      "learning_rate": 1.0271299381247026e-05,
      "loss": 0.0003,
      "step": 10220
    },
    {
      "epoch": 4.869109947643979,
      "grad_norm": 0.011886170133948326,
      "learning_rate": 1.0261780104712042e-05,
      "loss": 0.0194,
      "step": 10230
    },
    {
      "epoch": 4.8738695859114705,
      "grad_norm": 0.0009205608512274921,
      "learning_rate": 1.025226082817706e-05,
      "loss": 0.0,
      "step": 10240
    },
    {
      "epoch": 4.878629224178963,
      "grad_norm": 0.0006652413867413998,
      "learning_rate": 1.0242741551642077e-05,
      "loss": 0.0287,
      "step": 10250
    },
    {
      "epoch": 4.883388862446454,
      "grad_norm": 0.002083452884107828,
      "learning_rate": 1.0233222275107093e-05,
      "loss": 0.0027,
      "step": 10260
    },
    {
      "epoch": 4.888148500713946,
      "grad_norm": 3.6534321308135986,
      "learning_rate": 1.0223702998572109e-05,
      "loss": 0.0006,
      "step": 10270
    },
    {
      "epoch": 4.892908138981437,
      "grad_norm": 0.0008886106661520898,
      "learning_rate": 1.0214183722037125e-05,
      "loss": 0.0026,
      "step": 10280
    },
    {
      "epoch": 4.897667777248929,
      "grad_norm": 0.0009328803862445056,
      "learning_rate": 1.0204664445502144e-05,
      "loss": 0.0001,
      "step": 10290
    },
    {
      "epoch": 4.902427415516421,
      "grad_norm": 0.00098048138897866,
      "learning_rate": 1.019514516896716e-05,
      "loss": 0.0002,
      "step": 10300
    },
    {
      "epoch": 4.907187053783913,
      "grad_norm": 0.000952785718254745,
      "learning_rate": 1.0185625892432176e-05,
      "loss": 0.0263,
      "step": 10310
    },
    {
      "epoch": 4.911946692051404,
      "grad_norm": 0.013974026776850224,
      "learning_rate": 1.0176106615897192e-05,
      "loss": 0.0027,
      "step": 10320
    },
    {
      "epoch": 4.916706330318895,
      "grad_norm": 0.0031591926235705614,
      "learning_rate": 1.0166587339362208e-05,
      "loss": 0.0009,
      "step": 10330
    },
    {
      "epoch": 4.9214659685863875,
      "grad_norm": 0.001017994130961597,
      "learning_rate": 1.0157068062827226e-05,
      "loss": 0.0012,
      "step": 10340
    },
    {
      "epoch": 4.926225606853879,
      "grad_norm": 0.0008237325237132609,
      "learning_rate": 1.0147548786292242e-05,
      "loss": 0.0349,
      "step": 10350
    },
    {
      "epoch": 4.930985245121371,
      "grad_norm": 0.00256494153290987,
      "learning_rate": 1.013802950975726e-05,
      "loss": 0.0027,
      "step": 10360
    },
    {
      "epoch": 4.935744883388862,
      "grad_norm": 0.00397893413901329,
      "learning_rate": 1.0128510233222276e-05,
      "loss": 0.0,
      "step": 10370
    },
    {
      "epoch": 4.940504521656354,
      "grad_norm": 0.02297157421708107,
      "learning_rate": 1.0118990956687293e-05,
      "loss": 0.0235,
      "step": 10380
    },
    {
      "epoch": 4.945264159923846,
      "grad_norm": 0.0029310735408216715,
      "learning_rate": 1.010947168015231e-05,
      "loss": 0.0157,
      "step": 10390
    },
    {
      "epoch": 4.950023798191338,
      "grad_norm": 0.03345330059528351,
      "learning_rate": 1.0099952403617325e-05,
      "loss": 0.0124,
      "step": 10400
    },
    {
      "epoch": 4.954783436458829,
      "grad_norm": 0.0999411940574646,
      "learning_rate": 1.0090433127082341e-05,
      "loss": 0.001,
      "step": 10410
    },
    {
      "epoch": 4.959543074726321,
      "grad_norm": 0.006173628382384777,
      "learning_rate": 1.008091385054736e-05,
      "loss": 0.0006,
      "step": 10420
    },
    {
      "epoch": 4.964302712993812,
      "grad_norm": 0.0017360018100589514,
      "learning_rate": 1.0071394574012377e-05,
      "loss": 0.0,
      "step": 10430
    },
    {
      "epoch": 4.969062351261304,
      "grad_norm": 0.003968261182308197,
      "learning_rate": 1.0061875297477393e-05,
      "loss": 0.0014,
      "step": 10440
    },
    {
      "epoch": 4.973821989528796,
      "grad_norm": 0.0007777153514325619,
      "learning_rate": 1.0052356020942409e-05,
      "loss": 0.0,
      "step": 10450
    },
    {
      "epoch": 4.978581627796287,
      "grad_norm": 12.469155311584473,
      "learning_rate": 1.0042836744407425e-05,
      "loss": 0.0088,
      "step": 10460
    },
    {
      "epoch": 4.983341266063779,
      "grad_norm": 0.0013966538244858384,
      "learning_rate": 1.0033317467872444e-05,
      "loss": 0.0,
      "step": 10470
    },
    {
      "epoch": 4.9881009043312705,
      "grad_norm": 0.0013519917847588658,
      "learning_rate": 1.002379819133746e-05,
      "loss": 0.0,
      "step": 10480
    },
    {
      "epoch": 4.992860542598763,
      "grad_norm": 0.0019877415616065264,
      "learning_rate": 1.0014278914802476e-05,
      "loss": 0.0,
      "step": 10490
    },
    {
      "epoch": 4.997620180866254,
      "grad_norm": 1.40325927734375,
      "learning_rate": 1.0004759638267492e-05,
      "loss": 0.0003,
      "step": 10500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9978484175458079,
      "eval_f1": 0.9883502442690718,
      "eval_loss": 0.012534664943814278,
      "eval_precision": 0.9894657637321295,
      "eval_recall": 0.9872372372372372,
      "eval_runtime": 2199.3467,
      "eval_samples_per_second": 6.552,
      "eval_steps_per_second": 0.819,
      "step": 10505
    },
    {
      "epoch": 5.002379819133746,
      "grad_norm": 0.014891272410750389,
      "learning_rate": 9.99524036173251e-06,
      "loss": 0.0038,
      "step": 10510
    },
    {
      "epoch": 5.007139457401237,
      "grad_norm": 0.000649432186037302,
      "learning_rate": 9.985721085197526e-06,
      "loss": 0.0001,
      "step": 10520
    },
    {
      "epoch": 5.0118990956687295,
      "grad_norm": 0.0010840566828846931,
      "learning_rate": 9.976201808662542e-06,
      "loss": 0.0151,
      "step": 10530
    },
    {
      "epoch": 5.016658733936221,
      "grad_norm": 28.284038543701172,
      "learning_rate": 9.96668253212756e-06,
      "loss": 0.0411,
      "step": 10540
    },
    {
      "epoch": 5.021418372203713,
      "grad_norm": 0.0010257865069434047,
      "learning_rate": 9.957163255592575e-06,
      "loss": 0.0,
      "step": 10550
    },
    {
      "epoch": 5.026178010471204,
      "grad_norm": 0.0014770223060622811,
      "learning_rate": 9.947643979057593e-06,
      "loss": 0.0,
      "step": 10560
    },
    {
      "epoch": 5.030937648738695,
      "grad_norm": 0.001970121404156089,
      "learning_rate": 9.938124702522609e-06,
      "loss": 0.0,
      "step": 10570
    },
    {
      "epoch": 5.035697287006188,
      "grad_norm": 0.00597812794148922,
      "learning_rate": 9.928605425987625e-06,
      "loss": 0.0007,
      "step": 10580
    },
    {
      "epoch": 5.040456925273679,
      "grad_norm": 0.0017282693879678845,
      "learning_rate": 9.919086149452643e-06,
      "loss": 0.016,
      "step": 10590
    },
    {
      "epoch": 5.045216563541171,
      "grad_norm": 0.003002806566655636,
      "learning_rate": 9.909566872917659e-06,
      "loss": 0.0002,
      "step": 10600
    },
    {
      "epoch": 5.049976201808662,
      "grad_norm": 0.001955053536221385,
      "learning_rate": 9.900047596382676e-06,
      "loss": 0.0,
      "step": 10610
    },
    {
      "epoch": 5.054735840076154,
      "grad_norm": 0.0005745502421632409,
      "learning_rate": 9.890528319847692e-06,
      "loss": 0.0004,
      "step": 10620
    },
    {
      "epoch": 5.059495478343646,
      "grad_norm": 0.0007629310130141675,
      "learning_rate": 9.88100904331271e-06,
      "loss": 0.0,
      "step": 10630
    },
    {
      "epoch": 5.064255116611138,
      "grad_norm": 0.0007271390641108155,
      "learning_rate": 9.871489766777726e-06,
      "loss": 0.0149,
      "step": 10640
    },
    {
      "epoch": 5.069014754878629,
      "grad_norm": 0.0007629191968590021,
      "learning_rate": 9.861970490242742e-06,
      "loss": 0.0,
      "step": 10650
    },
    {
      "epoch": 5.073774393146121,
      "grad_norm": 0.0004225384909659624,
      "learning_rate": 9.85245121370776e-06,
      "loss": 0.0,
      "step": 10660
    },
    {
      "epoch": 5.0785340314136125,
      "grad_norm": 0.04826279729604721,
      "learning_rate": 9.842931937172776e-06,
      "loss": 0.0,
      "step": 10670
    },
    {
      "epoch": 5.083293669681105,
      "grad_norm": 0.0007716407999396324,
      "learning_rate": 9.833412660637792e-06,
      "loss": 0.0001,
      "step": 10680
    },
    {
      "epoch": 5.088053307948596,
      "grad_norm": 0.0012534140842035413,
      "learning_rate": 9.82389338410281e-06,
      "loss": 0.0,
      "step": 10690
    },
    {
      "epoch": 5.092812946216087,
      "grad_norm": 0.0014834408648312092,
      "learning_rate": 9.814374107567825e-06,
      "loss": 0.0,
      "step": 10700
    },
    {
      "epoch": 5.097572584483579,
      "grad_norm": 0.08721831440925598,
      "learning_rate": 9.804854831032843e-06,
      "loss": 0.0096,
      "step": 10710
    },
    {
      "epoch": 5.102332222751071,
      "grad_norm": 0.07007557898759842,
      "learning_rate": 9.795335554497859e-06,
      "loss": 0.0009,
      "step": 10720
    },
    {
      "epoch": 5.107091861018563,
      "grad_norm": 0.0031873583793640137,
      "learning_rate": 9.785816277962875e-06,
      "loss": 0.0001,
      "step": 10730
    },
    {
      "epoch": 5.111851499286054,
      "grad_norm": 0.008095736615359783,
      "learning_rate": 9.776297001427893e-06,
      "loss": 0.0,
      "step": 10740
    },
    {
      "epoch": 5.116611137553546,
      "grad_norm": 0.0004697130061686039,
      "learning_rate": 9.766777724892909e-06,
      "loss": 0.0,
      "step": 10750
    },
    {
      "epoch": 5.121370775821037,
      "grad_norm": 0.023342791944742203,
      "learning_rate": 9.757258448357926e-06,
      "loss": 0.0,
      "step": 10760
    },
    {
      "epoch": 5.1261304140885295,
      "grad_norm": 0.0026221019215881824,
      "learning_rate": 9.747739171822942e-06,
      "loss": 0.0,
      "step": 10770
    },
    {
      "epoch": 5.130890052356021,
      "grad_norm": 0.0005120671703480184,
      "learning_rate": 9.73821989528796e-06,
      "loss": 0.0,
      "step": 10780
    },
    {
      "epoch": 5.135649690623513,
      "grad_norm": 0.0007408554083667696,
      "learning_rate": 9.728700618752976e-06,
      "loss": 0.0,
      "step": 10790
    },
    {
      "epoch": 5.140409328891004,
      "grad_norm": 0.0006485907360911369,
      "learning_rate": 9.719181342217992e-06,
      "loss": 0.0007,
      "step": 10800
    },
    {
      "epoch": 5.145168967158496,
      "grad_norm": 0.0010555523913353682,
      "learning_rate": 9.70966206568301e-06,
      "loss": 0.0,
      "step": 10810
    },
    {
      "epoch": 5.149928605425988,
      "grad_norm": 0.006548450328409672,
      "learning_rate": 9.700142789148026e-06,
      "loss": 0.0,
      "step": 10820
    },
    {
      "epoch": 5.154688243693479,
      "grad_norm": 0.010609349235892296,
      "learning_rate": 9.690623512613042e-06,
      "loss": 0.0122,
      "step": 10830
    },
    {
      "epoch": 5.159447881960971,
      "grad_norm": 5.2769622802734375,
      "learning_rate": 9.68110423607806e-06,
      "loss": 0.0021,
      "step": 10840
    },
    {
      "epoch": 5.164207520228462,
      "grad_norm": 0.013531021773815155,
      "learning_rate": 9.671584959543075e-06,
      "loss": 0.0,
      "step": 10850
    },
    {
      "epoch": 5.1689671584959545,
      "grad_norm": 0.0016747096087783575,
      "learning_rate": 9.662065683008091e-06,
      "loss": 0.0004,
      "step": 10860
    },
    {
      "epoch": 5.173726796763446,
      "grad_norm": 0.0005182570894248784,
      "learning_rate": 9.652546406473109e-06,
      "loss": 0.0,
      "step": 10870
    },
    {
      "epoch": 5.178486435030938,
      "grad_norm": 0.0019939260091632605,
      "learning_rate": 9.643027129938125e-06,
      "loss": 0.0148,
      "step": 10880
    },
    {
      "epoch": 5.183246073298429,
      "grad_norm": 0.0005774673772975802,
      "learning_rate": 9.633507853403143e-06,
      "loss": 0.0001,
      "step": 10890
    },
    {
      "epoch": 5.188005711565921,
      "grad_norm": 0.004327452275902033,
      "learning_rate": 9.623988576868159e-06,
      "loss": 0.0173,
      "step": 10900
    },
    {
      "epoch": 5.1927653498334125,
      "grad_norm": 0.0006422980804927647,
      "learning_rate": 9.614469300333176e-06,
      "loss": 0.0006,
      "step": 10910
    },
    {
      "epoch": 5.197524988100905,
      "grad_norm": 0.008447450585663319,
      "learning_rate": 9.604950023798192e-06,
      "loss": 0.0,
      "step": 10920
    },
    {
      "epoch": 5.202284626368396,
      "grad_norm": 0.0013025399530306458,
      "learning_rate": 9.59543074726321e-06,
      "loss": 0.002,
      "step": 10930
    },
    {
      "epoch": 5.207044264635888,
      "grad_norm": 0.0015501560410484672,
      "learning_rate": 9.585911470728226e-06,
      "loss": 0.0001,
      "step": 10940
    },
    {
      "epoch": 5.211803902903379,
      "grad_norm": 0.00039088292396627367,
      "learning_rate": 9.576392194193242e-06,
      "loss": 0.0,
      "step": 10950
    },
    {
      "epoch": 5.216563541170871,
      "grad_norm": 0.0006609682459384203,
      "learning_rate": 9.566872917658258e-06,
      "loss": 0.0001,
      "step": 10960
    },
    {
      "epoch": 5.221323179438363,
      "grad_norm": 0.0010764275211840868,
      "learning_rate": 9.557353641123276e-06,
      "loss": 0.0,
      "step": 10970
    },
    {
      "epoch": 5.226082817705854,
      "grad_norm": 0.00788976065814495,
      "learning_rate": 9.547834364588292e-06,
      "loss": 0.0174,
      "step": 10980
    },
    {
      "epoch": 5.230842455973346,
      "grad_norm": 21.207439422607422,
      "learning_rate": 9.538315088053307e-06,
      "loss": 0.0363,
      "step": 10990
    },
    {
      "epoch": 5.2356020942408374,
      "grad_norm": 0.00506770983338356,
      "learning_rate": 9.528795811518325e-06,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 5.24036173250833,
      "grad_norm": 0.0018878827104344964,
      "learning_rate": 9.519276534983341e-06,
      "loss": 0.0002,
      "step": 11010
    },
    {
      "epoch": 5.245121370775821,
      "grad_norm": 0.0005231687100604177,
      "learning_rate": 9.509757258448359e-06,
      "loss": 0.0,
      "step": 11020
    },
    {
      "epoch": 5.249881009043313,
      "grad_norm": 1.106058120727539,
      "learning_rate": 9.500237981913375e-06,
      "loss": 0.0053,
      "step": 11030
    },
    {
      "epoch": 5.254640647310804,
      "grad_norm": 0.0011923916172236204,
      "learning_rate": 9.490718705378393e-06,
      "loss": 0.0001,
      "step": 11040
    },
    {
      "epoch": 5.259400285578296,
      "grad_norm": 0.0005427699652500451,
      "learning_rate": 9.481199428843408e-06,
      "loss": 0.0,
      "step": 11050
    },
    {
      "epoch": 5.264159923845788,
      "grad_norm": 0.0020815208554267883,
      "learning_rate": 9.471680152308426e-06,
      "loss": 0.0316,
      "step": 11060
    },
    {
      "epoch": 5.268919562113279,
      "grad_norm": 0.001258690608665347,
      "learning_rate": 9.462160875773442e-06,
      "loss": 0.0001,
      "step": 11070
    },
    {
      "epoch": 5.273679200380771,
      "grad_norm": 0.03428267315030098,
      "learning_rate": 9.45264159923846e-06,
      "loss": 0.0169,
      "step": 11080
    },
    {
      "epoch": 5.278438838648262,
      "grad_norm": 0.000784360512625426,
      "learning_rate": 9.443122322703476e-06,
      "loss": 0.0003,
      "step": 11090
    },
    {
      "epoch": 5.2831984769157545,
      "grad_norm": 0.0010705022141337395,
      "learning_rate": 9.433603046168492e-06,
      "loss": 0.0,
      "step": 11100
    },
    {
      "epoch": 5.287958115183246,
      "grad_norm": 0.0031118234619498253,
      "learning_rate": 9.424083769633508e-06,
      "loss": 0.035,
      "step": 11110
    },
    {
      "epoch": 5.292717753450738,
      "grad_norm": 0.005934762302786112,
      "learning_rate": 9.414564493098525e-06,
      "loss": 0.0017,
      "step": 11120
    },
    {
      "epoch": 5.297477391718229,
      "grad_norm": 0.0011955543886870146,
      "learning_rate": 9.405045216563541e-06,
      "loss": 0.0008,
      "step": 11130
    },
    {
      "epoch": 5.302237029985721,
      "grad_norm": 0.0011406298726797104,
      "learning_rate": 9.395525940028557e-06,
      "loss": 0.0,
      "step": 11140
    },
    {
      "epoch": 5.306996668253213,
      "grad_norm": 0.001111102057620883,
      "learning_rate": 9.386006663493575e-06,
      "loss": 0.0008,
      "step": 11150
    },
    {
      "epoch": 5.311756306520705,
      "grad_norm": 0.0008815122419036925,
      "learning_rate": 9.376487386958591e-06,
      "loss": 0.0002,
      "step": 11160
    },
    {
      "epoch": 5.316515944788196,
      "grad_norm": 0.0006265122210606933,
      "learning_rate": 9.366968110423609e-06,
      "loss": 0.0,
      "step": 11170
    },
    {
      "epoch": 5.321275583055688,
      "grad_norm": 0.00034239309024997056,
      "learning_rate": 9.357448833888625e-06,
      "loss": 0.0002,
      "step": 11180
    },
    {
      "epoch": 5.326035221323179,
      "grad_norm": 0.0010257444810122252,
      "learning_rate": 9.347929557353642e-06,
      "loss": 0.0001,
      "step": 11190
    },
    {
      "epoch": 5.330794859590672,
      "grad_norm": 0.0010792723624035716,
      "learning_rate": 9.338410280818658e-06,
      "loss": 0.0001,
      "step": 11200
    },
    {
      "epoch": 5.335554497858163,
      "grad_norm": 0.006261785980314016,
      "learning_rate": 9.328891004283676e-06,
      "loss": 0.0132,
      "step": 11210
    },
    {
      "epoch": 5.340314136125654,
      "grad_norm": 0.17756256461143494,
      "learning_rate": 9.319371727748692e-06,
      "loss": 0.0001,
      "step": 11220
    },
    {
      "epoch": 5.345073774393146,
      "grad_norm": 0.00259728217497468,
      "learning_rate": 9.30985245121371e-06,
      "loss": 0.0102,
      "step": 11230
    },
    {
      "epoch": 5.3498334126606375,
      "grad_norm": 0.008585367351770401,
      "learning_rate": 9.300333174678726e-06,
      "loss": 0.0002,
      "step": 11240
    },
    {
      "epoch": 5.35459305092813,
      "grad_norm": 0.0009972304105758667,
      "learning_rate": 9.290813898143742e-06,
      "loss": 0.0001,
      "step": 11250
    },
    {
      "epoch": 5.359352689195621,
      "grad_norm": 0.0003727806906681508,
      "learning_rate": 9.281294621608758e-06,
      "loss": 0.0,
      "step": 11260
    },
    {
      "epoch": 5.364112327463113,
      "grad_norm": 0.00031611687154509127,
      "learning_rate": 9.271775345073775e-06,
      "loss": 0.0001,
      "step": 11270
    },
    {
      "epoch": 5.368871965730604,
      "grad_norm": 0.0005539513658732176,
      "learning_rate": 9.262256068538791e-06,
      "loss": 0.0,
      "step": 11280
    },
    {
      "epoch": 5.3736316039980965,
      "grad_norm": 0.015527363866567612,
      "learning_rate": 9.252736792003807e-06,
      "loss": 0.0,
      "step": 11290
    },
    {
      "epoch": 5.378391242265588,
      "grad_norm": 0.0002806468110065907,
      "learning_rate": 9.243217515468825e-06,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 5.38315088053308,
      "grad_norm": 0.0015364583814516664,
      "learning_rate": 9.233698238933841e-06,
      "loss": 0.0,
      "step": 11310
    },
    {
      "epoch": 5.387910518800571,
      "grad_norm": 0.0207908246666193,
      "learning_rate": 9.224178962398859e-06,
      "loss": 0.0,
      "step": 11320
    },
    {
      "epoch": 5.392670157068062,
      "grad_norm": 2.4352242946624756,
      "learning_rate": 9.214659685863875e-06,
      "loss": 0.0014,
      "step": 11330
    },
    {
      "epoch": 5.397429795335555,
      "grad_norm": 0.0006000998546369374,
      "learning_rate": 9.205140409328892e-06,
      "loss": 0.007,
      "step": 11340
    },
    {
      "epoch": 5.402189433603046,
      "grad_norm": 0.0005465081776492298,
      "learning_rate": 9.195621132793908e-06,
      "loss": 0.0001,
      "step": 11350
    },
    {
      "epoch": 5.406949071870538,
      "grad_norm": 0.0029054994229227304,
      "learning_rate": 9.186101856258926e-06,
      "loss": 0.0,
      "step": 11360
    },
    {
      "epoch": 5.411708710138029,
      "grad_norm": 0.0005295557202771306,
      "learning_rate": 9.176582579723942e-06,
      "loss": 0.0001,
      "step": 11370
    },
    {
      "epoch": 5.416468348405521,
      "grad_norm": 0.0005510874325409532,
      "learning_rate": 9.167063303188958e-06,
      "loss": 0.0001,
      "step": 11380
    },
    {
      "epoch": 5.421227986673013,
      "grad_norm": 10.63304615020752,
      "learning_rate": 9.157544026653976e-06,
      "loss": 0.0142,
      "step": 11390
    },
    {
      "epoch": 5.425987624940505,
      "grad_norm": 0.0039491369388997555,
      "learning_rate": 9.148024750118992e-06,
      "loss": 0.0363,
      "step": 11400
    },
    {
      "epoch": 5.430747263207996,
      "grad_norm": 9.57559585571289,
      "learning_rate": 9.138505473584008e-06,
      "loss": 0.0018,
      "step": 11410
    },
    {
      "epoch": 5.435506901475488,
      "grad_norm": 0.0012460018042474985,
      "learning_rate": 9.128986197049025e-06,
      "loss": 0.0002,
      "step": 11420
    },
    {
      "epoch": 5.4402665397429795,
      "grad_norm": 0.001316988724283874,
      "learning_rate": 9.119466920514041e-06,
      "loss": 0.0004,
      "step": 11430
    },
    {
      "epoch": 5.445026178010472,
      "grad_norm": 0.0008813153253868222,
      "learning_rate": 9.109947643979057e-06,
      "loss": 0.0,
      "step": 11440
    },
    {
      "epoch": 5.449785816277963,
      "grad_norm": 0.006272728089243174,
      "learning_rate": 9.100428367444075e-06,
      "loss": 0.0001,
      "step": 11450
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 0.0007602277910336852,
      "learning_rate": 9.090909090909091e-06,
      "loss": 0.0076,
      "step": 11460
    },
    {
      "epoch": 5.459305092812946,
      "grad_norm": 0.0009716051281429827,
      "learning_rate": 9.081389814374109e-06,
      "loss": 0.0009,
      "step": 11470
    },
    {
      "epoch": 5.4640647310804376,
      "grad_norm": 0.0038211108185350895,
      "learning_rate": 9.071870537839125e-06,
      "loss": 0.0,
      "step": 11480
    },
    {
      "epoch": 5.46882436934793,
      "grad_norm": 0.005055502522736788,
      "learning_rate": 9.062351261304142e-06,
      "loss": 0.0,
      "step": 11490
    },
    {
      "epoch": 5.473584007615421,
      "grad_norm": 0.0005801006336696446,
      "learning_rate": 9.052831984769158e-06,
      "loss": 0.0037,
      "step": 11500
    },
    {
      "epoch": 5.478343645882913,
      "grad_norm": 0.01086959894746542,
      "learning_rate": 9.043312708234176e-06,
      "loss": 0.0,
      "step": 11510
    },
    {
      "epoch": 5.483103284150404,
      "grad_norm": 0.00040270123281516135,
      "learning_rate": 9.033793431699192e-06,
      "loss": 0.0,
      "step": 11520
    },
    {
      "epoch": 5.4878629224178965,
      "grad_norm": 0.00032353377901017666,
      "learning_rate": 9.024274155164208e-06,
      "loss": 0.0005,
      "step": 11530
    },
    {
      "epoch": 5.492622560685388,
      "grad_norm": 0.0006503454642370343,
      "learning_rate": 9.014754878629226e-06,
      "loss": 0.0001,
      "step": 11540
    },
    {
      "epoch": 5.49738219895288,
      "grad_norm": 0.0005177106941118836,
      "learning_rate": 9.005235602094242e-06,
      "loss": 0.0,
      "step": 11550
    },
    {
      "epoch": 5.502141837220371,
      "grad_norm": 0.00010340917651774362,
      "learning_rate": 8.995716325559258e-06,
      "loss": 0.0289,
      "step": 11560
    },
    {
      "epoch": 5.506901475487863,
      "grad_norm": 0.0002553158556111157,
      "learning_rate": 8.986197049024274e-06,
      "loss": 0.0052,
      "step": 11570
    },
    {
      "epoch": 5.511661113755355,
      "grad_norm": 0.0010909769916906953,
      "learning_rate": 8.976677772489291e-06,
      "loss": 0.0003,
      "step": 11580
    },
    {
      "epoch": 5.516420752022846,
      "grad_norm": 0.00020569932530634105,
      "learning_rate": 8.967158495954307e-06,
      "loss": 0.0,
      "step": 11590
    },
    {
      "epoch": 5.521180390290338,
      "grad_norm": 0.0004680953861679882,
      "learning_rate": 8.957639219419325e-06,
      "loss": 0.0055,
      "step": 11600
    },
    {
      "epoch": 5.525940028557829,
      "grad_norm": 0.0030133482068777084,
      "learning_rate": 8.948119942884341e-06,
      "loss": 0.0002,
      "step": 11610
    },
    {
      "epoch": 5.530699666825321,
      "grad_norm": 0.014678845182061195,
      "learning_rate": 8.938600666349359e-06,
      "loss": 0.0,
      "step": 11620
    },
    {
      "epoch": 5.535459305092813,
      "grad_norm": 0.0004336633428465575,
      "learning_rate": 8.929081389814375e-06,
      "loss": 0.0,
      "step": 11630
    },
    {
      "epoch": 5.540218943360305,
      "grad_norm": 0.0009160152403637767,
      "learning_rate": 8.919562113279392e-06,
      "loss": 0.0027,
      "step": 11640
    },
    {
      "epoch": 5.544978581627796,
      "grad_norm": 0.003552739042788744,
      "learning_rate": 8.910042836744408e-06,
      "loss": 0.0098,
      "step": 11650
    },
    {
      "epoch": 5.549738219895288,
      "grad_norm": 0.002996688475832343,
      "learning_rate": 8.900523560209426e-06,
      "loss": 0.013,
      "step": 11660
    },
    {
      "epoch": 5.5544978581627795,
      "grad_norm": 0.0021610832773149014,
      "learning_rate": 8.891004283674442e-06,
      "loss": 0.0002,
      "step": 11670
    },
    {
      "epoch": 5.559257496430272,
      "grad_norm": 0.0008727264939807355,
      "learning_rate": 8.881485007139458e-06,
      "loss": 0.0,
      "step": 11680
    },
    {
      "epoch": 5.564017134697763,
      "grad_norm": 0.7528260946273804,
      "learning_rate": 8.871965730604476e-06,
      "loss": 0.0036,
      "step": 11690
    },
    {
      "epoch": 5.568776772965254,
      "grad_norm": 0.011473455466330051,
      "learning_rate": 8.862446454069492e-06,
      "loss": 0.0016,
      "step": 11700
    },
    {
      "epoch": 5.573536411232746,
      "grad_norm": 0.007703614886850119,
      "learning_rate": 8.852927177534508e-06,
      "loss": 0.0045,
      "step": 11710
    },
    {
      "epoch": 5.578296049500238,
      "grad_norm": 0.00044872277067042887,
      "learning_rate": 8.843407900999524e-06,
      "loss": 0.0001,
      "step": 11720
    },
    {
      "epoch": 5.58305568776773,
      "grad_norm": 0.0001978926156880334,
      "learning_rate": 8.833888624464541e-06,
      "loss": 0.0251,
      "step": 11730
    },
    {
      "epoch": 5.587815326035221,
      "grad_norm": 0.0003461088926997036,
      "learning_rate": 8.824369347929557e-06,
      "loss": 0.0452,
      "step": 11740
    },
    {
      "epoch": 5.592574964302713,
      "grad_norm": 0.01719295233488083,
      "learning_rate": 8.814850071394575e-06,
      "loss": 0.0081,
      "step": 11750
    },
    {
      "epoch": 5.597334602570204,
      "grad_norm": 0.980745255947113,
      "learning_rate": 8.805330794859591e-06,
      "loss": 0.0005,
      "step": 11760
    },
    {
      "epoch": 5.602094240837697,
      "grad_norm": 0.0006204462260939181,
      "learning_rate": 8.795811518324609e-06,
      "loss": 0.0006,
      "step": 11770
    },
    {
      "epoch": 5.606853879105188,
      "grad_norm": 0.0003431356162764132,
      "learning_rate": 8.786292241789625e-06,
      "loss": 0.0036,
      "step": 11780
    },
    {
      "epoch": 5.61161351737268,
      "grad_norm": 0.0023040894884616137,
      "learning_rate": 8.776772965254642e-06,
      "loss": 0.0001,
      "step": 11790
    },
    {
      "epoch": 5.616373155640171,
      "grad_norm": 0.008852737955749035,
      "learning_rate": 8.767253688719658e-06,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 5.621132793907663,
      "grad_norm": 0.0010056119645014405,
      "learning_rate": 8.757734412184674e-06,
      "loss": 0.0,
      "step": 11810
    },
    {
      "epoch": 5.625892432175155,
      "grad_norm": 19.61166763305664,
      "learning_rate": 8.748215135649692e-06,
      "loss": 0.0109,
      "step": 11820
    },
    {
      "epoch": 5.630652070442647,
      "grad_norm": 0.362805038690567,
      "learning_rate": 8.738695859114708e-06,
      "loss": 0.0092,
      "step": 11830
    },
    {
      "epoch": 5.635411708710138,
      "grad_norm": 0.0028344483580440283,
      "learning_rate": 8.729176582579726e-06,
      "loss": 0.0013,
      "step": 11840
    },
    {
      "epoch": 5.640171346977629,
      "grad_norm": 0.0010148825822398067,
      "learning_rate": 8.719657306044742e-06,
      "loss": 0.0003,
      "step": 11850
    },
    {
      "epoch": 5.6449309852451215,
      "grad_norm": 0.00029023384558968246,
      "learning_rate": 8.710138029509758e-06,
      "loss": 0.0002,
      "step": 11860
    },
    {
      "epoch": 5.649690623512613,
      "grad_norm": 0.009527585469186306,
      "learning_rate": 8.700618752974774e-06,
      "loss": 0.0143,
      "step": 11870
    },
    {
      "epoch": 5.654450261780105,
      "grad_norm": 0.0009877474512904882,
      "learning_rate": 8.691099476439791e-06,
      "loss": 0.0001,
      "step": 11880
    },
    {
      "epoch": 5.659209900047596,
      "grad_norm": 0.0014824445825070143,
      "learning_rate": 8.681580199904807e-06,
      "loss": 0.0,
      "step": 11890
    },
    {
      "epoch": 5.663969538315088,
      "grad_norm": 0.0006675785407423973,
      "learning_rate": 8.672060923369825e-06,
      "loss": 0.0,
      "step": 11900
    },
    {
      "epoch": 5.66872917658258,
      "grad_norm": 0.0003411527432035655,
      "learning_rate": 8.662541646834841e-06,
      "loss": 0.0001,
      "step": 11910
    },
    {
      "epoch": 5.673488814850072,
      "grad_norm": 0.00017592469521332532,
      "learning_rate": 8.653022370299859e-06,
      "loss": 0.0003,
      "step": 11920
    },
    {
      "epoch": 5.678248453117563,
      "grad_norm": 0.0019542647060006857,
      "learning_rate": 8.643503093764875e-06,
      "loss": 0.0005,
      "step": 11930
    },
    {
      "epoch": 5.683008091385055,
      "grad_norm": 0.007585331331938505,
      "learning_rate": 8.633983817229892e-06,
      "loss": 0.0327,
      "step": 11940
    },
    {
      "epoch": 5.687767729652546,
      "grad_norm": 0.0018600969342514873,
      "learning_rate": 8.624464540694908e-06,
      "loss": 0.0002,
      "step": 11950
    },
    {
      "epoch": 5.692527367920038,
      "grad_norm": 0.36556845903396606,
      "learning_rate": 8.614945264159924e-06,
      "loss": 0.0435,
      "step": 11960
    },
    {
      "epoch": 5.69728700618753,
      "grad_norm": 0.0013220988912507892,
      "learning_rate": 8.605425987624942e-06,
      "loss": 0.015,
      "step": 11970
    },
    {
      "epoch": 5.702046644455021,
      "grad_norm": 5.0703349113464355,
      "learning_rate": 8.595906711089958e-06,
      "loss": 0.0027,
      "step": 11980
    },
    {
      "epoch": 5.706806282722513,
      "grad_norm": 0.0009111289400607347,
      "learning_rate": 8.586387434554974e-06,
      "loss": 0.0255,
      "step": 11990
    },
    {
      "epoch": 5.7115659209900045,
      "grad_norm": 0.0027580352034419775,
      "learning_rate": 8.576868158019992e-06,
      "loss": 0.042,
      "step": 12000
    },
    {
      "epoch": 5.716325559257497,
      "grad_norm": 0.002385140163823962,
      "learning_rate": 8.567348881485008e-06,
      "loss": 0.0153,
      "step": 12010
    },
    {
      "epoch": 5.721085197524988,
      "grad_norm": 0.07240555435419083,
      "learning_rate": 8.557829604950024e-06,
      "loss": 0.0002,
      "step": 12020
    },
    {
      "epoch": 5.72584483579248,
      "grad_norm": 0.003408184740692377,
      "learning_rate": 8.548310328415041e-06,
      "loss": 0.0099,
      "step": 12030
    },
    {
      "epoch": 5.730604474059971,
      "grad_norm": 0.011722392402589321,
      "learning_rate": 8.538791051880057e-06,
      "loss": 0.0092,
      "step": 12040
    },
    {
      "epoch": 5.7353641123274635,
      "grad_norm": 7.60674524307251,
      "learning_rate": 8.529271775345075e-06,
      "loss": 0.0693,
      "step": 12050
    },
    {
      "epoch": 5.740123750594955,
      "grad_norm": 0.042837999761104584,
      "learning_rate": 8.519752498810091e-06,
      "loss": 0.0001,
      "step": 12060
    },
    {
      "epoch": 5.744883388862446,
      "grad_norm": 0.003517042612656951,
      "learning_rate": 8.510233222275109e-06,
      "loss": 0.0005,
      "step": 12070
    },
    {
      "epoch": 5.749643027129938,
      "grad_norm": 0.0091942073777318,
      "learning_rate": 8.500713945740125e-06,
      "loss": 0.0096,
      "step": 12080
    },
    {
      "epoch": 5.75440266539743,
      "grad_norm": 0.0030225988011807203,
      "learning_rate": 8.49119466920514e-06,
      "loss": 0.0128,
      "step": 12090
    },
    {
      "epoch": 5.7591623036649215,
      "grad_norm": 0.005623385775834322,
      "learning_rate": 8.481675392670158e-06,
      "loss": 0.0001,
      "step": 12100
    },
    {
      "epoch": 5.763921941932413,
      "grad_norm": 0.0038173701614141464,
      "learning_rate": 8.472156116135174e-06,
      "loss": 0.0028,
      "step": 12110
    },
    {
      "epoch": 5.768681580199905,
      "grad_norm": 0.000742485688533634,
      "learning_rate": 8.462636839600192e-06,
      "loss": 0.0102,
      "step": 12120
    },
    {
      "epoch": 5.773441218467396,
      "grad_norm": 0.027503538876771927,
      "learning_rate": 8.453117563065208e-06,
      "loss": 0.032,
      "step": 12130
    },
    {
      "epoch": 5.778200856734888,
      "grad_norm": 0.0002107704058289528,
      "learning_rate": 8.443598286530224e-06,
      "loss": 0.0,
      "step": 12140
    },
    {
      "epoch": 5.78296049500238,
      "grad_norm": 165.32815551757812,
      "learning_rate": 8.434079009995242e-06,
      "loss": 0.0011,
      "step": 12150
    },
    {
      "epoch": 5.787720133269872,
      "grad_norm": 0.009889940731227398,
      "learning_rate": 8.424559733460258e-06,
      "loss": 0.0,
      "step": 12160
    },
    {
      "epoch": 5.792479771537363,
      "grad_norm": 0.000800156150944531,
      "learning_rate": 8.415040456925273e-06,
      "loss": 0.0,
      "step": 12170
    },
    {
      "epoch": 5.797239409804855,
      "grad_norm": 0.0009072090615518391,
      "learning_rate": 8.405521180390291e-06,
      "loss": 0.0143,
      "step": 12180
    },
    {
      "epoch": 5.8019990480723465,
      "grad_norm": 0.0017936225049197674,
      "learning_rate": 8.396001903855307e-06,
      "loss": 0.0175,
      "step": 12190
    },
    {
      "epoch": 5.806758686339839,
      "grad_norm": 0.001917825429700315,
      "learning_rate": 8.386482627320325e-06,
      "loss": 0.0077,
      "step": 12200
    },
    {
      "epoch": 5.81151832460733,
      "grad_norm": 0.0003794620279222727,
      "learning_rate": 8.37696335078534e-06,
      "loss": 0.0129,
      "step": 12210
    },
    {
      "epoch": 5.816277962874821,
      "grad_norm": 0.0017201961018145084,
      "learning_rate": 8.367444074250359e-06,
      "loss": 0.0,
      "step": 12220
    },
    {
      "epoch": 5.821037601142313,
      "grad_norm": 0.0014276023721322417,
      "learning_rate": 8.357924797715374e-06,
      "loss": 0.0,
      "step": 12230
    },
    {
      "epoch": 5.8257972394098045,
      "grad_norm": 0.0007417604792863131,
      "learning_rate": 8.34840552118039e-06,
      "loss": 0.0252,
      "step": 12240
    },
    {
      "epoch": 5.830556877677297,
      "grad_norm": 0.0003607659600675106,
      "learning_rate": 8.338886244645408e-06,
      "loss": 0.0058,
      "step": 12250
    },
    {
      "epoch": 5.835316515944788,
      "grad_norm": 0.00039453976205550134,
      "learning_rate": 8.329366968110424e-06,
      "loss": 0.0241,
      "step": 12260
    },
    {
      "epoch": 5.84007615421228,
      "grad_norm": 0.000958306307438761,
      "learning_rate": 8.319847691575442e-06,
      "loss": 0.0001,
      "step": 12270
    },
    {
      "epoch": 5.844835792479771,
      "grad_norm": 0.44328874349594116,
      "learning_rate": 8.310328415040458e-06,
      "loss": 0.0096,
      "step": 12280
    },
    {
      "epoch": 5.8495954307472635,
      "grad_norm": 0.032475247979164124,
      "learning_rate": 8.300809138505474e-06,
      "loss": 0.0022,
      "step": 12290
    },
    {
      "epoch": 5.854355069014755,
      "grad_norm": 0.0005671910475939512,
      "learning_rate": 8.291289861970491e-06,
      "loss": 0.0065,
      "step": 12300
    },
    {
      "epoch": 5.859114707282247,
      "grad_norm": 0.001364626339636743,
      "learning_rate": 8.281770585435507e-06,
      "loss": 0.0,
      "step": 12310
    },
    {
      "epoch": 5.863874345549738,
      "grad_norm": 0.0011294868309050798,
      "learning_rate": 8.272251308900523e-06,
      "loss": 0.007,
      "step": 12320
    },
    {
      "epoch": 5.8686339838172294,
      "grad_norm": 10.007884979248047,
      "learning_rate": 8.262732032365541e-06,
      "loss": 0.0191,
      "step": 12330
    },
    {
      "epoch": 5.873393622084722,
      "grad_norm": 0.0015431500505656004,
      "learning_rate": 8.253212755830557e-06,
      "loss": 0.0473,
      "step": 12340
    },
    {
      "epoch": 5.878153260352213,
      "grad_norm": 0.0008479416137561202,
      "learning_rate": 8.243693479295575e-06,
      "loss": 0.0,
      "step": 12350
    },
    {
      "epoch": 5.882912898619705,
      "grad_norm": 0.0005657376023009419,
      "learning_rate": 8.23417420276059e-06,
      "loss": 0.0002,
      "step": 12360
    },
    {
      "epoch": 5.887672536887196,
      "grad_norm": 0.07018677890300751,
      "learning_rate": 8.224654926225607e-06,
      "loss": 0.0,
      "step": 12370
    },
    {
      "epoch": 5.892432175154688,
      "grad_norm": 3.560338258743286,
      "learning_rate": 8.215135649690624e-06,
      "loss": 0.021,
      "step": 12380
    },
    {
      "epoch": 5.89719181342218,
      "grad_norm": 0.005197639111429453,
      "learning_rate": 8.20561637315564e-06,
      "loss": 0.0001,
      "step": 12390
    },
    {
      "epoch": 5.901951451689672,
      "grad_norm": 0.007417302578687668,
      "learning_rate": 8.196097096620658e-06,
      "loss": 0.009,
      "step": 12400
    },
    {
      "epoch": 5.906711089957163,
      "grad_norm": 0.002268741140142083,
      "learning_rate": 8.186577820085674e-06,
      "loss": 0.0001,
      "step": 12410
    },
    {
      "epoch": 5.911470728224655,
      "grad_norm": 0.015255342237651348,
      "learning_rate": 8.177058543550692e-06,
      "loss": 0.0001,
      "step": 12420
    },
    {
      "epoch": 5.9162303664921465,
      "grad_norm": 0.024062026292085648,
      "learning_rate": 8.167539267015708e-06,
      "loss": 0.0083,
      "step": 12430
    },
    {
      "epoch": 5.920990004759638,
      "grad_norm": 0.005118040833622217,
      "learning_rate": 8.158019990480724e-06,
      "loss": 0.0001,
      "step": 12440
    },
    {
      "epoch": 5.92574964302713,
      "grad_norm": 0.00565351452678442,
      "learning_rate": 8.148500713945741e-06,
      "loss": 0.0038,
      "step": 12450
    },
    {
      "epoch": 5.930509281294622,
      "grad_norm": 0.0013191266916692257,
      "learning_rate": 8.138981437410757e-06,
      "loss": 0.0,
      "step": 12460
    },
    {
      "epoch": 5.935268919562113,
      "grad_norm": 0.007049019914120436,
      "learning_rate": 8.129462160875773e-06,
      "loss": 0.0241,
      "step": 12470
    },
    {
      "epoch": 5.940028557829605,
      "grad_norm": 0.0038474220782518387,
      "learning_rate": 8.119942884340791e-06,
      "loss": 0.0001,
      "step": 12480
    },
    {
      "epoch": 5.944788196097097,
      "grad_norm": 3.4744110107421875,
      "learning_rate": 8.110423607805807e-06,
      "loss": 0.0024,
      "step": 12490
    },
    {
      "epoch": 5.949547834364588,
      "grad_norm": 0.0011151856742799282,
      "learning_rate": 8.100904331270823e-06,
      "loss": 0.0003,
      "step": 12500
    },
    {
      "epoch": 5.95430747263208,
      "grad_norm": 0.0023983167484402657,
      "learning_rate": 8.09138505473584e-06,
      "loss": 0.0241,
      "step": 12510
    },
    {
      "epoch": 5.959067110899571,
      "grad_norm": 0.0021886362228542566,
      "learning_rate": 8.081865778200857e-06,
      "loss": 0.0006,
      "step": 12520
    },
    {
      "epoch": 5.963826749167064,
      "grad_norm": 0.00344443810172379,
      "learning_rate": 8.072346501665874e-06,
      "loss": 0.0001,
      "step": 12530
    },
    {
      "epoch": 5.968586387434555,
      "grad_norm": 0.0014993533259257674,
      "learning_rate": 8.06282722513089e-06,
      "loss": 0.0001,
      "step": 12540
    },
    {
      "epoch": 5.973346025702047,
      "grad_norm": 0.022583898156881332,
      "learning_rate": 8.053307948595908e-06,
      "loss": 0.0157,
      "step": 12550
    },
    {
      "epoch": 5.978105663969538,
      "grad_norm": 0.01149127259850502,
      "learning_rate": 8.043788672060924e-06,
      "loss": 0.0006,
      "step": 12560
    },
    {
      "epoch": 5.98286530223703,
      "grad_norm": 0.002887440612539649,
      "learning_rate": 8.034269395525942e-06,
      "loss": 0.0029,
      "step": 12570
    },
    {
      "epoch": 5.987624940504522,
      "grad_norm": 0.0007520540384575725,
      "learning_rate": 8.024750118990958e-06,
      "loss": 0.0006,
      "step": 12580
    },
    {
      "epoch": 5.992384578772013,
      "grad_norm": 6.57841157913208,
      "learning_rate": 8.015230842455974e-06,
      "loss": 0.0313,
      "step": 12590
    },
    {
      "epoch": 5.997144217039505,
      "grad_norm": 0.5708749890327454,
      "learning_rate": 8.00571156592099e-06,
      "loss": 0.0015,
      "step": 12600
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9978484175458079,
      "eval_f1": 0.9883151149641916,
      "eval_loss": 0.01351406890898943,
      "eval_precision": 0.9924299772899319,
      "eval_recall": 0.9842342342342343,
      "eval_runtime": 1896.6594,
      "eval_samples_per_second": 7.598,
      "eval_steps_per_second": 0.95,
      "step": 12606
    },
    {
      "epoch": 6.001903855306996,
      "grad_norm": 0.0022328048944473267,
      "learning_rate": 7.996192289386007e-06,
      "loss": 0.0193,
      "step": 12610
    },
    {
      "epoch": 6.0066634935744885,
      "grad_norm": 0.0005005429848097265,
      "learning_rate": 7.986673012851023e-06,
      "loss": 0.0001,
      "step": 12620
    },
    {
      "epoch": 6.01142313184198,
      "grad_norm": 0.0009711700258776546,
      "learning_rate": 7.977153736316041e-06,
      "loss": 0.0026,
      "step": 12630
    },
    {
      "epoch": 6.016182770109472,
      "grad_norm": 0.0029264953918755054,
      "learning_rate": 7.967634459781057e-06,
      "loss": 0.0193,
      "step": 12640
    },
    {
      "epoch": 6.020942408376963,
      "grad_norm": 0.002533698221668601,
      "learning_rate": 7.958115183246073e-06,
      "loss": 0.0001,
      "step": 12650
    },
    {
      "epoch": 6.025702046644455,
      "grad_norm": 0.001494932221248746,
      "learning_rate": 7.94859590671109e-06,
      "loss": 0.0015,
      "step": 12660
    },
    {
      "epoch": 6.030461684911947,
      "grad_norm": 0.12778335809707642,
      "learning_rate": 7.939076630176107e-06,
      "loss": 0.0005,
      "step": 12670
    },
    {
      "epoch": 6.035221323179439,
      "grad_norm": 0.2238575965166092,
      "learning_rate": 7.929557353641124e-06,
      "loss": 0.0005,
      "step": 12680
    },
    {
      "epoch": 6.03998096144693,
      "grad_norm": 0.0006431881338357925,
      "learning_rate": 7.92003807710614e-06,
      "loss": 0.0141,
      "step": 12690
    },
    {
      "epoch": 6.044740599714422,
      "grad_norm": 0.0008982676081359386,
      "learning_rate": 7.910518800571158e-06,
      "loss": 0.0001,
      "step": 12700
    },
    {
      "epoch": 6.049500237981913,
      "grad_norm": 11.369296073913574,
      "learning_rate": 7.900999524036174e-06,
      "loss": 0.011,
      "step": 12710
    },
    {
      "epoch": 6.054259876249405,
      "grad_norm": 0.1256909817457199,
      "learning_rate": 7.891480247501192e-06,
      "loss": 0.0002,
      "step": 12720
    },
    {
      "epoch": 6.059019514516897,
      "grad_norm": 0.0014135768869891763,
      "learning_rate": 7.881960970966208e-06,
      "loss": 0.0151,
      "step": 12730
    },
    {
      "epoch": 6.063779152784388,
      "grad_norm": 0.0036978910211473703,
      "learning_rate": 7.872441694431224e-06,
      "loss": 0.0001,
      "step": 12740
    },
    {
      "epoch": 6.06853879105188,
      "grad_norm": 0.00838487222790718,
      "learning_rate": 7.86292241789624e-06,
      "loss": 0.0,
      "step": 12750
    },
    {
      "epoch": 6.0732984293193715,
      "grad_norm": 0.0006863780436106026,
      "learning_rate": 7.853403141361257e-06,
      "loss": 0.0004,
      "step": 12760
    },
    {
      "epoch": 6.078058067586864,
      "grad_norm": 0.006980671547353268,
      "learning_rate": 7.843883864826273e-06,
      "loss": 0.0004,
      "step": 12770
    },
    {
      "epoch": 6.082817705854355,
      "grad_norm": 0.0005146824405528605,
      "learning_rate": 7.83436458829129e-06,
      "loss": 0.0003,
      "step": 12780
    },
    {
      "epoch": 6.087577344121847,
      "grad_norm": 0.0016627042787149549,
      "learning_rate": 7.824845311756307e-06,
      "loss": 0.0002,
      "step": 12790
    },
    {
      "epoch": 6.092336982389338,
      "grad_norm": 0.00044115347554907203,
      "learning_rate": 7.815326035221323e-06,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 6.0970966206568304,
      "grad_norm": 0.0007383533520624042,
      "learning_rate": 7.80580675868634e-06,
      "loss": 0.0,
      "step": 12810
    },
    {
      "epoch": 6.101856258924322,
      "grad_norm": 0.0006064311601221561,
      "learning_rate": 7.796287482151357e-06,
      "loss": 0.0001,
      "step": 12820
    },
    {
      "epoch": 6.106615897191814,
      "grad_norm": 0.00048061663983389735,
      "learning_rate": 7.786768205616374e-06,
      "loss": 0.0,
      "step": 12830
    },
    {
      "epoch": 6.111375535459305,
      "grad_norm": 0.0036330337170511484,
      "learning_rate": 7.77724892908139e-06,
      "loss": 0.0003,
      "step": 12840
    },
    {
      "epoch": 6.116135173726796,
      "grad_norm": 0.0019367380300536752,
      "learning_rate": 7.767729652546408e-06,
      "loss": 0.0,
      "step": 12850
    },
    {
      "epoch": 6.1208948119942885,
      "grad_norm": 0.0005136216641403735,
      "learning_rate": 7.758210376011424e-06,
      "loss": 0.0004,
      "step": 12860
    },
    {
      "epoch": 6.12565445026178,
      "grad_norm": 0.0014188067289069295,
      "learning_rate": 7.748691099476442e-06,
      "loss": 0.0001,
      "step": 12870
    },
    {
      "epoch": 6.130414088529272,
      "grad_norm": 148.1688690185547,
      "learning_rate": 7.739171822941458e-06,
      "loss": 0.0093,
      "step": 12880
    },
    {
      "epoch": 6.135173726796763,
      "grad_norm": 0.00013125619443599135,
      "learning_rate": 7.729652546406474e-06,
      "loss": 0.0,
      "step": 12890
    },
    {
      "epoch": 6.139933365064255,
      "grad_norm": 0.0002730117703322321,
      "learning_rate": 7.72013326987149e-06,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 6.144693003331747,
      "grad_norm": 0.014073419384658337,
      "learning_rate": 7.710613993336507e-06,
      "loss": 0.0,
      "step": 12910
    },
    {
      "epoch": 6.149452641599239,
      "grad_norm": 32.53739547729492,
      "learning_rate": 7.701094716801523e-06,
      "loss": 0.0037,
      "step": 12920
    },
    {
      "epoch": 6.15421227986673,
      "grad_norm": 0.0005877609364688396,
      "learning_rate": 7.69157544026654e-06,
      "loss": 0.0,
      "step": 12930
    },
    {
      "epoch": 6.158971918134222,
      "grad_norm": 0.08628979325294495,
      "learning_rate": 7.682056163731557e-06,
      "loss": 0.0001,
      "step": 12940
    },
    {
      "epoch": 6.163731556401713,
      "grad_norm": 11.695170402526855,
      "learning_rate": 7.672536887196573e-06,
      "loss": 0.0003,
      "step": 12950
    },
    {
      "epoch": 6.168491194669205,
      "grad_norm": 10.55416488647461,
      "learning_rate": 7.66301761066159e-06,
      "loss": 0.0019,
      "step": 12960
    },
    {
      "epoch": 6.173250832936697,
      "grad_norm": 0.00617534015327692,
      "learning_rate": 7.653498334126607e-06,
      "loss": 0.0,
      "step": 12970
    },
    {
      "epoch": 6.178010471204188,
      "grad_norm": 0.0002334930468350649,
      "learning_rate": 7.643979057591624e-06,
      "loss": 0.0004,
      "step": 12980
    },
    {
      "epoch": 6.18277010947168,
      "grad_norm": 0.001242743106558919,
      "learning_rate": 7.63445978105664e-06,
      "loss": 0.0001,
      "step": 12990
    },
    {
      "epoch": 6.1875297477391715,
      "grad_norm": 0.0006013868842273951,
      "learning_rate": 7.624940504521657e-06,
      "loss": 0.0001,
      "step": 13000
    },
    {
      "epoch": 6.192289386006664,
      "grad_norm": 0.0003965176874771714,
      "learning_rate": 7.615421227986673e-06,
      "loss": 0.0,
      "step": 13010
    },
    {
      "epoch": 6.197049024274155,
      "grad_norm": 0.0013513313606381416,
      "learning_rate": 7.605901951451691e-06,
      "loss": 0.0039,
      "step": 13020
    },
    {
      "epoch": 6.201808662541647,
      "grad_norm": 0.00030670128762722015,
      "learning_rate": 7.596382674916707e-06,
      "loss": 0.0,
      "step": 13030
    },
    {
      "epoch": 6.206568300809138,
      "grad_norm": 0.0009105114731937647,
      "learning_rate": 7.5868633983817244e-06,
      "loss": 0.0,
      "step": 13040
    },
    {
      "epoch": 6.2113279390766305,
      "grad_norm": 0.00031759400735609233,
      "learning_rate": 7.5773441218467404e-06,
      "loss": 0.0048,
      "step": 13050
    },
    {
      "epoch": 6.216087577344122,
      "grad_norm": 0.004988223779946566,
      "learning_rate": 7.567824845311756e-06,
      "loss": 0.0011,
      "step": 13060
    },
    {
      "epoch": 6.220847215611614,
      "grad_norm": 0.002069185022264719,
      "learning_rate": 7.558305568776774e-06,
      "loss": 0.0,
      "step": 13070
    },
    {
      "epoch": 6.225606853879105,
      "grad_norm": 0.010903936810791492,
      "learning_rate": 7.54878629224179e-06,
      "loss": 0.0,
      "step": 13080
    },
    {
      "epoch": 6.230366492146596,
      "grad_norm": 8.352027893066406,
      "learning_rate": 7.539267015706807e-06,
      "loss": 0.0027,
      "step": 13090
    },
    {
      "epoch": 6.235126130414089,
      "grad_norm": 0.0006705487030558288,
      "learning_rate": 7.529747739171823e-06,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 6.23988576868158,
      "grad_norm": 0.00010475900489836931,
      "learning_rate": 7.520228462636841e-06,
      "loss": 0.0,
      "step": 13110
    },
    {
      "epoch": 6.244645406949072,
      "grad_norm": 0.00016843742923811078,
      "learning_rate": 7.5107091861018566e-06,
      "loss": 0.0003,
      "step": 13120
    },
    {
      "epoch": 6.249405045216563,
      "grad_norm": 0.0007176807266660035,
      "learning_rate": 7.501189909566874e-06,
      "loss": 0.0067,
      "step": 13130
    },
    {
      "epoch": 6.254164683484055,
      "grad_norm": 0.010783626697957516,
      "learning_rate": 7.49167063303189e-06,
      "loss": 0.0,
      "step": 13140
    },
    {
      "epoch": 6.258924321751547,
      "grad_norm": 0.010508723556995392,
      "learning_rate": 7.482151356496907e-06,
      "loss": 0.0,
      "step": 13150
    },
    {
      "epoch": 6.263683960019039,
      "grad_norm": 0.000234099046792835,
      "learning_rate": 7.472632079961923e-06,
      "loss": 0.0,
      "step": 13160
    },
    {
      "epoch": 6.26844359828653,
      "grad_norm": 0.0003652154700830579,
      "learning_rate": 7.463112803426941e-06,
      "loss": 0.0,
      "step": 13170
    },
    {
      "epoch": 6.273203236554022,
      "grad_norm": 0.00030908966436982155,
      "learning_rate": 7.453593526891957e-06,
      "loss": 0.0014,
      "step": 13180
    },
    {
      "epoch": 6.2779628748215135,
      "grad_norm": 0.00017185510660056025,
      "learning_rate": 7.444074250356973e-06,
      "loss": 0.0001,
      "step": 13190
    },
    {
      "epoch": 6.282722513089006,
      "grad_norm": 9.049430847167969,
      "learning_rate": 7.43455497382199e-06,
      "loss": 0.0134,
      "step": 13200
    },
    {
      "epoch": 6.287482151356497,
      "grad_norm": 0.001219567027874291,
      "learning_rate": 7.425035697287006e-06,
      "loss": 0.0,
      "step": 13210
    },
    {
      "epoch": 6.292241789623988,
      "grad_norm": 0.01604512520134449,
      "learning_rate": 7.415516420752023e-06,
      "loss": 0.0012,
      "step": 13220
    },
    {
      "epoch": 6.29700142789148,
      "grad_norm": 0.0004908933187834918,
      "learning_rate": 7.40599714421704e-06,
      "loss": 0.0,
      "step": 13230
    },
    {
      "epoch": 6.301761066158972,
      "grad_norm": 0.015971748158335686,
      "learning_rate": 7.396477867682057e-06,
      "loss": 0.0,
      "step": 13240
    },
    {
      "epoch": 6.306520704426464,
      "grad_norm": 0.0004623825952876359,
      "learning_rate": 7.386958591147073e-06,
      "loss": 0.0,
      "step": 13250
    },
    {
      "epoch": 6.311280342693955,
      "grad_norm": 0.000740299466997385,
      "learning_rate": 7.3774393146120905e-06,
      "loss": 0.0,
      "step": 13260
    },
    {
      "epoch": 6.316039980961447,
      "grad_norm": 0.00041239961865358055,
      "learning_rate": 7.3679200380771065e-06,
      "loss": 0.0044,
      "step": 13270
    },
    {
      "epoch": 6.320799619228938,
      "grad_norm": 0.0014838604256510735,
      "learning_rate": 7.358400761542124e-06,
      "loss": 0.0096,
      "step": 13280
    },
    {
      "epoch": 6.3255592574964306,
      "grad_norm": 0.0009423696319572628,
      "learning_rate": 7.34888148500714e-06,
      "loss": 0.0,
      "step": 13290
    },
    {
      "epoch": 6.330318895763922,
      "grad_norm": 0.006456887815147638,
      "learning_rate": 7.339362208472157e-06,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 6.335078534031414,
      "grad_norm": 0.00033198308665305376,
      "learning_rate": 7.329842931937173e-06,
      "loss": 0.0,
      "step": 13310
    },
    {
      "epoch": 6.339838172298905,
      "grad_norm": 0.0037047152873128653,
      "learning_rate": 7.320323655402191e-06,
      "loss": 0.0001,
      "step": 13320
    },
    {
      "epoch": 6.3445978105663965,
      "grad_norm": 8.831816673278809,
      "learning_rate": 7.310804378867207e-06,
      "loss": 0.0021,
      "step": 13330
    },
    {
      "epoch": 6.349357448833889,
      "grad_norm": 0.0009089056984521449,
      "learning_rate": 7.301285102332223e-06,
      "loss": 0.0162,
      "step": 13340
    },
    {
      "epoch": 6.35411708710138,
      "grad_norm": 0.0032445513643324375,
      "learning_rate": 7.29176582579724e-06,
      "loss": 0.0066,
      "step": 13350
    },
    {
      "epoch": 6.358876725368872,
      "grad_norm": 0.0004661893181037158,
      "learning_rate": 7.282246549262256e-06,
      "loss": 0.0003,
      "step": 13360
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 1.813606858253479,
      "learning_rate": 7.272727272727273e-06,
      "loss": 0.0018,
      "step": 13370
    },
    {
      "epoch": 6.3683960019038555,
      "grad_norm": 0.0014774497831240296,
      "learning_rate": 7.26320799619229e-06,
      "loss": 0.0001,
      "step": 13380
    },
    {
      "epoch": 6.373155640171347,
      "grad_norm": 0.0005749334231950343,
      "learning_rate": 7.253688719657307e-06,
      "loss": 0.0001,
      "step": 13390
    },
    {
      "epoch": 6.377915278438839,
      "grad_norm": 0.00026561020058579743,
      "learning_rate": 7.244169443122323e-06,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 6.38267491670633,
      "grad_norm": 0.0013622166588902473,
      "learning_rate": 7.2346501665873405e-06,
      "loss": 0.0143,
      "step": 13410
    },
    {
      "epoch": 6.387434554973822,
      "grad_norm": 0.0004400835314299911,
      "learning_rate": 7.2251308900523565e-06,
      "loss": 0.006,
      "step": 13420
    },
    {
      "epoch": 6.3921941932413135,
      "grad_norm": 0.002781145740300417,
      "learning_rate": 7.215611613517373e-06,
      "loss": 0.0,
      "step": 13430
    },
    {
      "epoch": 6.396953831508806,
      "grad_norm": 0.0004989533335901797,
      "learning_rate": 7.20609233698239e-06,
      "loss": 0.0002,
      "step": 13440
    },
    {
      "epoch": 6.401713469776297,
      "grad_norm": 0.0002832369355019182,
      "learning_rate": 7.196573060447407e-06,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 6.406473108043789,
      "grad_norm": 0.04940886050462723,
      "learning_rate": 7.187053783912423e-06,
      "loss": 0.0551,
      "step": 13460
    },
    {
      "epoch": 6.41123274631128,
      "grad_norm": 0.0007113628089427948,
      "learning_rate": 7.17753450737744e-06,
      "loss": 0.0,
      "step": 13470
    },
    {
      "epoch": 6.415992384578772,
      "grad_norm": 0.0020300871692597866,
      "learning_rate": 7.168015230842457e-06,
      "loss": 0.0,
      "step": 13480
    },
    {
      "epoch": 6.420752022846264,
      "grad_norm": 0.0010954178869724274,
      "learning_rate": 7.158495954307473e-06,
      "loss": 0.0069,
      "step": 13490
    },
    {
      "epoch": 6.425511661113755,
      "grad_norm": 0.0012867266777902842,
      "learning_rate": 7.14897667777249e-06,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 6.430271299381247,
      "grad_norm": 0.00034089176915585995,
      "learning_rate": 7.139457401237506e-06,
      "loss": 0.0006,
      "step": 13510
    },
    {
      "epoch": 6.4350309376487385,
      "grad_norm": 0.0004237770044710487,
      "learning_rate": 7.129938124702523e-06,
      "loss": 0.0001,
      "step": 13520
    },
    {
      "epoch": 6.439790575916231,
      "grad_norm": 0.0006690667360089719,
      "learning_rate": 7.12041884816754e-06,
      "loss": 0.0,
      "step": 13530
    },
    {
      "epoch": 6.444550214183722,
      "grad_norm": 0.010025628842413425,
      "learning_rate": 7.110899571632557e-06,
      "loss": 0.0,
      "step": 13540
    },
    {
      "epoch": 6.449309852451214,
      "grad_norm": 18.022823333740234,
      "learning_rate": 7.101380295097573e-06,
      "loss": 0.0138,
      "step": 13550
    },
    {
      "epoch": 6.454069490718705,
      "grad_norm": 0.0004176233778707683,
      "learning_rate": 7.0918610185625905e-06,
      "loss": 0.0,
      "step": 13560
    },
    {
      "epoch": 6.458829128986197,
      "grad_norm": 0.012983745895326138,
      "learning_rate": 7.0823417420276064e-06,
      "loss": 0.0002,
      "step": 13570
    },
    {
      "epoch": 6.463588767253689,
      "grad_norm": 0.0012506735511124134,
      "learning_rate": 7.072822465492623e-06,
      "loss": 0.0,
      "step": 13580
    },
    {
      "epoch": 6.46834840552118,
      "grad_norm": 0.00358497048728168,
      "learning_rate": 7.06330318895764e-06,
      "loss": 0.0011,
      "step": 13590
    },
    {
      "epoch": 6.473108043788672,
      "grad_norm": 0.002422099467366934,
      "learning_rate": 7.053783912422656e-06,
      "loss": 0.0,
      "step": 13600
    },
    {
      "epoch": 6.477867682056163,
      "grad_norm": 0.0015411099884659052,
      "learning_rate": 7.044264635887673e-06,
      "loss": 0.0001,
      "step": 13610
    },
    {
      "epoch": 6.4826273203236555,
      "grad_norm": 3.342698335647583,
      "learning_rate": 7.034745359352689e-06,
      "loss": 0.0155,
      "step": 13620
    },
    {
      "epoch": 6.487386958591147,
      "grad_norm": 0.012815464287996292,
      "learning_rate": 7.025226082817707e-06,
      "loss": 0.0,
      "step": 13630
    },
    {
      "epoch": 6.492146596858639,
      "grad_norm": 0.005509966518729925,
      "learning_rate": 7.015706806282723e-06,
      "loss": 0.0001,
      "step": 13640
    },
    {
      "epoch": 6.49690623512613,
      "grad_norm": 0.004673170857131481,
      "learning_rate": 7.00618752974774e-06,
      "loss": 0.0,
      "step": 13650
    },
    {
      "epoch": 6.501665873393622,
      "grad_norm": 0.007501741871237755,
      "learning_rate": 6.996668253212756e-06,
      "loss": 0.0001,
      "step": 13660
    },
    {
      "epoch": 6.506425511661114,
      "grad_norm": 0.0007693199440836906,
      "learning_rate": 6.987148976677773e-06,
      "loss": 0.0058,
      "step": 13670
    },
    {
      "epoch": 6.511185149928606,
      "grad_norm": 0.0002082483988488093,
      "learning_rate": 6.97762970014279e-06,
      "loss": 0.0,
      "step": 13680
    },
    {
      "epoch": 6.515944788196097,
      "grad_norm": 6.745457649230957,
      "learning_rate": 6.968110423607807e-06,
      "loss": 0.0024,
      "step": 13690
    },
    {
      "epoch": 6.520704426463588,
      "grad_norm": 0.005297047086060047,
      "learning_rate": 6.958591147072823e-06,
      "loss": 0.0033,
      "step": 13700
    },
    {
      "epoch": 6.52546406473108,
      "grad_norm": 0.00040480640018358827,
      "learning_rate": 6.94907187053784e-06,
      "loss": 0.0,
      "step": 13710
    },
    {
      "epoch": 6.530223702998573,
      "grad_norm": 0.001114749233238399,
      "learning_rate": 6.939552594002856e-06,
      "loss": 0.0002,
      "step": 13720
    },
    {
      "epoch": 6.534983341266064,
      "grad_norm": 0.01011195033788681,
      "learning_rate": 6.930033317467873e-06,
      "loss": 0.0088,
      "step": 13730
    },
    {
      "epoch": 6.539742979533555,
      "grad_norm": 0.02015969343483448,
      "learning_rate": 6.92051404093289e-06,
      "loss": 0.0001,
      "step": 13740
    },
    {
      "epoch": 6.544502617801047,
      "grad_norm": 0.003923842683434486,
      "learning_rate": 6.910994764397906e-06,
      "loss": 0.002,
      "step": 13750
    },
    {
      "epoch": 6.5492622560685385,
      "grad_norm": 0.0006359562394209206,
      "learning_rate": 6.901475487862923e-06,
      "loss": 0.0326,
      "step": 13760
    },
    {
      "epoch": 6.554021894336031,
      "grad_norm": 0.0011199762811884284,
      "learning_rate": 6.891956211327939e-06,
      "loss": 0.0,
      "step": 13770
    },
    {
      "epoch": 6.558781532603522,
      "grad_norm": 0.2200881987810135,
      "learning_rate": 6.8824369347929566e-06,
      "loss": 0.0124,
      "step": 13780
    },
    {
      "epoch": 6.563541170871014,
      "grad_norm": 0.000727039878256619,
      "learning_rate": 6.8729176582579725e-06,
      "loss": 0.0,
      "step": 13790
    },
    {
      "epoch": 6.568300809138505,
      "grad_norm": 0.01188874151557684,
      "learning_rate": 6.86339838172299e-06,
      "loss": 0.0001,
      "step": 13800
    },
    {
      "epoch": 6.5730604474059975,
      "grad_norm": 0.0015403161523863673,
      "learning_rate": 6.853879105188006e-06,
      "loss": 0.0004,
      "step": 13810
    },
    {
      "epoch": 6.577820085673489,
      "grad_norm": 0.003530950518324971,
      "learning_rate": 6.844359828653023e-06,
      "loss": 0.0,
      "step": 13820
    },
    {
      "epoch": 6.582579723940981,
      "grad_norm": 0.0029497845098376274,
      "learning_rate": 6.834840552118039e-06,
      "loss": 0.0,
      "step": 13830
    },
    {
      "epoch": 6.587339362208472,
      "grad_norm": 0.00033573497785255313,
      "learning_rate": 6.825321275583057e-06,
      "loss": 0.0001,
      "step": 13840
    },
    {
      "epoch": 6.592099000475963,
      "grad_norm": 0.049575988203287125,
      "learning_rate": 6.815801999048073e-06,
      "loss": 0.0001,
      "step": 13850
    },
    {
      "epoch": 6.596858638743456,
      "grad_norm": 0.049755264073610306,
      "learning_rate": 6.80628272251309e-06,
      "loss": 0.0017,
      "step": 13860
    },
    {
      "epoch": 6.601618277010947,
      "grad_norm": 0.00028929486870765686,
      "learning_rate": 6.796763445978106e-06,
      "loss": 0.023,
      "step": 13870
    },
    {
      "epoch": 6.606377915278439,
      "grad_norm": 0.002759150229394436,
      "learning_rate": 6.787244169443122e-06,
      "loss": 0.0001,
      "step": 13880
    },
    {
      "epoch": 6.61113755354593,
      "grad_norm": 0.00047935330076143146,
      "learning_rate": 6.77772489290814e-06,
      "loss": 0.0,
      "step": 13890
    },
    {
      "epoch": 6.615897191813422,
      "grad_norm": 0.0005058208480477333,
      "learning_rate": 6.768205616373156e-06,
      "loss": 0.0,
      "step": 13900
    },
    {
      "epoch": 6.620656830080914,
      "grad_norm": 0.001201437320560217,
      "learning_rate": 6.758686339838173e-06,
      "loss": 0.0001,
      "step": 13910
    },
    {
      "epoch": 6.625416468348406,
      "grad_norm": 0.0025774689856916666,
      "learning_rate": 6.749167063303189e-06,
      "loss": 0.0,
      "step": 13920
    },
    {
      "epoch": 6.630176106615897,
      "grad_norm": 0.002206337871029973,
      "learning_rate": 6.7396477867682065e-06,
      "loss": 0.0,
      "step": 13930
    },
    {
      "epoch": 6.634935744883389,
      "grad_norm": 0.0012041007867082953,
      "learning_rate": 6.7301285102332225e-06,
      "loss": 0.0,
      "step": 13940
    },
    {
      "epoch": 6.6396953831508805,
      "grad_norm": 0.0016205403953790665,
      "learning_rate": 6.72060923369824e-06,
      "loss": 0.0,
      "step": 13950
    },
    {
      "epoch": 6.644455021418372,
      "grad_norm": 0.0011959366966038942,
      "learning_rate": 6.711089957163256e-06,
      "loss": 0.0001,
      "step": 13960
    },
    {
      "epoch": 6.649214659685864,
      "grad_norm": 8.375174522399902,
      "learning_rate": 6.701570680628273e-06,
      "loss": 0.0102,
      "step": 13970
    },
    {
      "epoch": 6.653974297953356,
      "grad_norm": 0.0017963395221158862,
      "learning_rate": 6.692051404093289e-06,
      "loss": 0.0,
      "step": 13980
    },
    {
      "epoch": 6.658733936220847,
      "grad_norm": 0.0008792454609647393,
      "learning_rate": 6.682532127558307e-06,
      "loss": 0.0,
      "step": 13990
    },
    {
      "epoch": 6.663493574488339,
      "grad_norm": 0.000779054535087198,
      "learning_rate": 6.673012851023323e-06,
      "loss": 0.0067,
      "step": 14000
    },
    {
      "epoch": 6.668253212755831,
      "grad_norm": 0.0010544394608587027,
      "learning_rate": 6.663493574488339e-06,
      "loss": 0.0,
      "step": 14010
    },
    {
      "epoch": 6.673012851023322,
      "grad_norm": 0.00028088901308365166,
      "learning_rate": 6.653974297953356e-06,
      "loss": 0.0,
      "step": 14020
    },
    {
      "epoch": 6.677772489290814,
      "grad_norm": 0.0008962972788140178,
      "learning_rate": 6.644455021418372e-06,
      "loss": 0.0,
      "step": 14030
    },
    {
      "epoch": 6.682532127558305,
      "grad_norm": 0.0005268094828352332,
      "learning_rate": 6.634935744883389e-06,
      "loss": 0.0206,
      "step": 14040
    },
    {
      "epoch": 6.6872917658257975,
      "grad_norm": 0.0004859560285694897,
      "learning_rate": 6.625416468348406e-06,
      "loss": 0.0,
      "step": 14050
    },
    {
      "epoch": 6.692051404093289,
      "grad_norm": 0.00032882479717954993,
      "learning_rate": 6.615897191813423e-06,
      "loss": 0.0001,
      "step": 14060
    },
    {
      "epoch": 6.696811042360781,
      "grad_norm": 0.00017802469665184617,
      "learning_rate": 6.606377915278439e-06,
      "loss": 0.0028,
      "step": 14070
    },
    {
      "epoch": 6.701570680628272,
      "grad_norm": 0.0021418514661490917,
      "learning_rate": 6.5968586387434565e-06,
      "loss": 0.0,
      "step": 14080
    },
    {
      "epoch": 6.706330318895764,
      "grad_norm": 0.44121885299682617,
      "learning_rate": 6.5873393622084725e-06,
      "loss": 0.0002,
      "step": 14090
    },
    {
      "epoch": 6.711089957163256,
      "grad_norm": 0.00034471575054340065,
      "learning_rate": 6.57782008567349e-06,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 6.715849595430747,
      "grad_norm": 0.00037172125303186476,
      "learning_rate": 6.568300809138506e-06,
      "loss": 0.0,
      "step": 14110
    },
    {
      "epoch": 6.720609233698239,
      "grad_norm": 0.0006474566180258989,
      "learning_rate": 6.558781532603523e-06,
      "loss": 0.0,
      "step": 14120
    },
    {
      "epoch": 6.72536887196573,
      "grad_norm": 0.00027961176238022745,
      "learning_rate": 6.549262256068539e-06,
      "loss": 0.0,
      "step": 14130
    },
    {
      "epoch": 6.7301285102332224,
      "grad_norm": 0.00528306420892477,
      "learning_rate": 6.539742979533557e-06,
      "loss": 0.0,
      "step": 14140
    },
    {
      "epoch": 6.734888148500714,
      "grad_norm": 0.00016509000852238387,
      "learning_rate": 6.530223702998573e-06,
      "loss": 0.0,
      "step": 14150
    },
    {
      "epoch": 6.739647786768206,
      "grad_norm": 0.0005742929643020034,
      "learning_rate": 6.520704426463589e-06,
      "loss": 0.0003,
      "step": 14160
    },
    {
      "epoch": 6.744407425035697,
      "grad_norm": 0.0004671902861446142,
      "learning_rate": 6.511185149928606e-06,
      "loss": 0.0,
      "step": 14170
    },
    {
      "epoch": 6.749167063303189,
      "grad_norm": 0.002057989127933979,
      "learning_rate": 6.501665873393622e-06,
      "loss": 0.017,
      "step": 14180
    },
    {
      "epoch": 6.7539267015706805,
      "grad_norm": 0.00010853817366296425,
      "learning_rate": 6.492146596858639e-06,
      "loss": 0.0,
      "step": 14190
    },
    {
      "epoch": 6.758686339838173,
      "grad_norm": 3.5485570430755615,
      "learning_rate": 6.482627320323656e-06,
      "loss": 0.0228,
      "step": 14200
    },
    {
      "epoch": 6.763445978105664,
      "grad_norm": 0.0012796036899089813,
      "learning_rate": 6.473108043788673e-06,
      "loss": 0.0,
      "step": 14210
    },
    {
      "epoch": 6.768205616373155,
      "grad_norm": 0.0005676631699316204,
      "learning_rate": 6.463588767253689e-06,
      "loss": 0.0,
      "step": 14220
    },
    {
      "epoch": 6.772965254640647,
      "grad_norm": 0.0006551825790666044,
      "learning_rate": 6.4540694907187064e-06,
      "loss": 0.0001,
      "step": 14230
    },
    {
      "epoch": 6.777724892908139,
      "grad_norm": 0.0019790909718722105,
      "learning_rate": 6.444550214183722e-06,
      "loss": 0.0,
      "step": 14240
    },
    {
      "epoch": 6.782484531175631,
      "grad_norm": 0.0051929764449596405,
      "learning_rate": 6.435030937648739e-06,
      "loss": 0.016,
      "step": 14250
    },
    {
      "epoch": 6.787244169443122,
      "grad_norm": 0.0026626894250512123,
      "learning_rate": 6.425511661113756e-06,
      "loss": 0.0004,
      "step": 14260
    },
    {
      "epoch": 6.792003807710614,
      "grad_norm": 0.0017603301675990224,
      "learning_rate": 6.415992384578773e-06,
      "loss": 0.0,
      "step": 14270
    },
    {
      "epoch": 6.7967634459781054,
      "grad_norm": 0.0022645583376288414,
      "learning_rate": 6.406473108043789e-06,
      "loss": 0.001,
      "step": 14280
    },
    {
      "epoch": 6.801523084245598,
      "grad_norm": 0.04229262098670006,
      "learning_rate": 6.396953831508806e-06,
      "loss": 0.0001,
      "step": 14290
    },
    {
      "epoch": 6.806282722513089,
      "grad_norm": 0.003146510571241379,
      "learning_rate": 6.3874345549738226e-06,
      "loss": 0.0018,
      "step": 14300
    },
    {
      "epoch": 6.811042360780581,
      "grad_norm": 0.007071383763104677,
      "learning_rate": 6.3779152784388386e-06,
      "loss": 0.001,
      "step": 14310
    },
    {
      "epoch": 6.815801999048072,
      "grad_norm": 0.0038919737562537193,
      "learning_rate": 6.368396001903856e-06,
      "loss": 0.0066,
      "step": 14320
    },
    {
      "epoch": 6.8205616373155635,
      "grad_norm": 0.004297128412872553,
      "learning_rate": 6.358876725368872e-06,
      "loss": 0.0,
      "step": 14330
    },
    {
      "epoch": 6.825321275583056,
      "grad_norm": 0.00020563005818985403,
      "learning_rate": 6.349357448833889e-06,
      "loss": 0.0001,
      "step": 14340
    },
    {
      "epoch": 6.830080913850548,
      "grad_norm": 0.0003043483884539455,
      "learning_rate": 6.339838172298906e-06,
      "loss": 0.0,
      "step": 14350
    },
    {
      "epoch": 6.834840552118039,
      "grad_norm": 0.16396485269069672,
      "learning_rate": 6.330318895763923e-06,
      "loss": 0.0001,
      "step": 14360
    },
    {
      "epoch": 6.83960019038553,
      "grad_norm": 14.30813217163086,
      "learning_rate": 6.320799619228939e-06,
      "loss": 0.0018,
      "step": 14370
    },
    {
      "epoch": 6.8443598286530225,
      "grad_norm": 0.0005646943463943899,
      "learning_rate": 6.311280342693956e-06,
      "loss": 0.0,
      "step": 14380
    },
    {
      "epoch": 6.849119466920514,
      "grad_norm": 20.312042236328125,
      "learning_rate": 6.301761066158972e-06,
      "loss": 0.0022,
      "step": 14390
    },
    {
      "epoch": 6.853879105188006,
      "grad_norm": 0.008557816036045551,
      "learning_rate": 6.292241789623989e-06,
      "loss": 0.0181,
      "step": 14400
    },
    {
      "epoch": 6.858638743455497,
      "grad_norm": 0.00014700776955578476,
      "learning_rate": 6.282722513089006e-06,
      "loss": 0.0226,
      "step": 14410
    },
    {
      "epoch": 6.863398381722989,
      "grad_norm": 0.0002953773073386401,
      "learning_rate": 6.273203236554022e-06,
      "loss": 0.0448,
      "step": 14420
    },
    {
      "epoch": 6.868158019990481,
      "grad_norm": 0.009746850468218327,
      "learning_rate": 6.263683960019039e-06,
      "loss": 0.017,
      "step": 14430
    },
    {
      "epoch": 6.872917658257973,
      "grad_norm": 0.0008129216148518026,
      "learning_rate": 6.254164683484055e-06,
      "loss": 0.0,
      "step": 14440
    },
    {
      "epoch": 6.877677296525464,
      "grad_norm": 0.00035334471613168716,
      "learning_rate": 6.2446454069490725e-06,
      "loss": 0.0295,
      "step": 14450
    },
    {
      "epoch": 6.882436934792956,
      "grad_norm": 0.0045640612952411175,
      "learning_rate": 6.2351261304140885e-06,
      "loss": 0.0002,
      "step": 14460
    },
    {
      "epoch": 6.887196573060447,
      "grad_norm": 0.005212769843637943,
      "learning_rate": 6.225606853879106e-06,
      "loss": 0.0003,
      "step": 14470
    },
    {
      "epoch": 6.891956211327939,
      "grad_norm": 1.409096360206604,
      "learning_rate": 6.216087577344122e-06,
      "loss": 0.0212,
      "step": 14480
    },
    {
      "epoch": 6.896715849595431,
      "grad_norm": 0.0010318647837266326,
      "learning_rate": 6.206568300809139e-06,
      "loss": 0.0001,
      "step": 14490
    },
    {
      "epoch": 6.901475487862922,
      "grad_norm": 0.4174953103065491,
      "learning_rate": 6.197049024274156e-06,
      "loss": 0.0002,
      "step": 14500
    },
    {
      "epoch": 6.906235126130414,
      "grad_norm": 0.0005626727943308651,
      "learning_rate": 6.187529747739173e-06,
      "loss": 0.0001,
      "step": 14510
    },
    {
      "epoch": 6.9109947643979055,
      "grad_norm": 0.00832909531891346,
      "learning_rate": 6.178010471204189e-06,
      "loss": 0.0001,
      "step": 14520
    },
    {
      "epoch": 6.915754402665398,
      "grad_norm": 0.0008736915769986808,
      "learning_rate": 6.168491194669206e-06,
      "loss": 0.0056,
      "step": 14530
    },
    {
      "epoch": 6.920514040932889,
      "grad_norm": 0.001282888581044972,
      "learning_rate": 6.158971918134222e-06,
      "loss": 0.0046,
      "step": 14540
    },
    {
      "epoch": 6.925273679200381,
      "grad_norm": 0.0014198737917467952,
      "learning_rate": 6.149452641599239e-06,
      "loss": 0.0,
      "step": 14550
    },
    {
      "epoch": 6.930033317467872,
      "grad_norm": 0.0006847194745205343,
      "learning_rate": 6.139933365064256e-06,
      "loss": 0.0,
      "step": 14560
    },
    {
      "epoch": 6.9347929557353645,
      "grad_norm": 0.00016716170648578554,
      "learning_rate": 6.130414088529272e-06,
      "loss": 0.0156,
      "step": 14570
    },
    {
      "epoch": 6.939552594002856,
      "grad_norm": 0.006544036790728569,
      "learning_rate": 6.120894811994289e-06,
      "loss": 0.0,
      "step": 14580
    },
    {
      "epoch": 6.944312232270347,
      "grad_norm": 0.010746360756456852,
      "learning_rate": 6.111375535459305e-06,
      "loss": 0.0001,
      "step": 14590
    },
    {
      "epoch": 6.949071870537839,
      "grad_norm": 0.00014782366633880883,
      "learning_rate": 6.1018562589243225e-06,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 6.95383150880533,
      "grad_norm": 0.0021075448021292686,
      "learning_rate": 6.0923369823893385e-06,
      "loss": 0.0,
      "step": 14610
    },
    {
      "epoch": 6.958591147072823,
      "grad_norm": 0.00034589137067086995,
      "learning_rate": 6.082817705854356e-06,
      "loss": 0.0,
      "step": 14620
    },
    {
      "epoch": 6.963350785340314,
      "grad_norm": 0.010717342607676983,
      "learning_rate": 6.073298429319372e-06,
      "loss": 0.0,
      "step": 14630
    },
    {
      "epoch": 6.968110423607806,
      "grad_norm": 0.0012795482762157917,
      "learning_rate": 6.063779152784389e-06,
      "loss": 0.0009,
      "step": 14640
    },
    {
      "epoch": 6.972870061875297,
      "grad_norm": 0.0008435286581516266,
      "learning_rate": 6.054259876249405e-06,
      "loss": 0.0,
      "step": 14650
    },
    {
      "epoch": 6.977629700142789,
      "grad_norm": 0.00031147737172432244,
      "learning_rate": 6.044740599714423e-06,
      "loss": 0.0,
      "step": 14660
    },
    {
      "epoch": 6.982389338410281,
      "grad_norm": 0.0012835492379963398,
      "learning_rate": 6.035221323179439e-06,
      "loss": 0.0021,
      "step": 14670
    },
    {
      "epoch": 6.987148976677773,
      "grad_norm": 0.0004884488298557699,
      "learning_rate": 6.025702046644456e-06,
      "loss": 0.0015,
      "step": 14680
    },
    {
      "epoch": 6.991908614945264,
      "grad_norm": 0.0002355172036914155,
      "learning_rate": 6.016182770109472e-06,
      "loss": 0.0,
      "step": 14690
    },
    {
      "epoch": 6.996668253212756,
      "grad_norm": 0.0005053243949078023,
      "learning_rate": 6.006663493574488e-06,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9978484175458079,
      "eval_f1": 0.9883764529433821,
      "eval_loss": 0.014639031141996384,
      "eval_precision": 0.9872659176029962,
      "eval_recall": 0.9894894894894894,
      "eval_runtime": 1909.938,
      "eval_samples_per_second": 7.545,
      "eval_steps_per_second": 0.943,
      "step": 14707
    },
    {
      "epoch": 7.0014278914802475,
      "grad_norm": 0.00030272649019025266,
      "learning_rate": 5.997144217039506e-06,
      "loss": 0.0,
      "step": 14710
    },
    {
      "epoch": 7.006187529747739,
      "grad_norm": 0.0003163234796375036,
      "learning_rate": 5.987624940504522e-06,
      "loss": 0.0013,
      "step": 14720
    },
    {
      "epoch": 7.010947168015231,
      "grad_norm": 0.0004463390214368701,
      "learning_rate": 5.978105663969539e-06,
      "loss": 0.0,
      "step": 14730
    },
    {
      "epoch": 7.015706806282722,
      "grad_norm": 0.006197923328727484,
      "learning_rate": 5.968586387434555e-06,
      "loss": 0.0,
      "step": 14740
    },
    {
      "epoch": 7.020466444550214,
      "grad_norm": 0.8445272445678711,
      "learning_rate": 5.9590671108995725e-06,
      "loss": 0.0003,
      "step": 14750
    },
    {
      "epoch": 7.0252260828177056,
      "grad_norm": 0.0012726705754175782,
      "learning_rate": 5.9495478343645884e-06,
      "loss": 0.0004,
      "step": 14760
    },
    {
      "epoch": 7.029985721085198,
      "grad_norm": 0.0072973622009158134,
      "learning_rate": 5.940028557829606e-06,
      "loss": 0.0,
      "step": 14770
    },
    {
      "epoch": 7.034745359352689,
      "grad_norm": 0.0001826753286877647,
      "learning_rate": 5.930509281294622e-06,
      "loss": 0.0,
      "step": 14780
    },
    {
      "epoch": 7.039504997620181,
      "grad_norm": 0.0006706363055855036,
      "learning_rate": 5.920990004759639e-06,
      "loss": 0.0089,
      "step": 14790
    },
    {
      "epoch": 7.044264635887672,
      "grad_norm": 0.0006892228848300874,
      "learning_rate": 5.911470728224655e-06,
      "loss": 0.0115,
      "step": 14800
    },
    {
      "epoch": 7.0490242741551645,
      "grad_norm": 0.0001566940627526492,
      "learning_rate": 5.901951451689673e-06,
      "loss": 0.0,
      "step": 14810
    },
    {
      "epoch": 7.053783912422656,
      "grad_norm": 0.0003128287789877504,
      "learning_rate": 5.892432175154689e-06,
      "loss": 0.0001,
      "step": 14820
    },
    {
      "epoch": 7.058543550690148,
      "grad_norm": 0.0005836850614286959,
      "learning_rate": 5.882912898619706e-06,
      "loss": 0.0,
      "step": 14830
    },
    {
      "epoch": 7.063303188957639,
      "grad_norm": 0.000356269913027063,
      "learning_rate": 5.873393622084722e-06,
      "loss": 0.0,
      "step": 14840
    },
    {
      "epoch": 7.0680628272251305,
      "grad_norm": 0.00016546373080927879,
      "learning_rate": 5.863874345549738e-06,
      "loss": 0.0,
      "step": 14850
    },
    {
      "epoch": 7.072822465492623,
      "grad_norm": 0.001889269333332777,
      "learning_rate": 5.854355069014755e-06,
      "loss": 0.0051,
      "step": 14860
    },
    {
      "epoch": 7.077582103760114,
      "grad_norm": 0.003995228558778763,
      "learning_rate": 5.844835792479772e-06,
      "loss": 0.0001,
      "step": 14870
    },
    {
      "epoch": 7.082341742027606,
      "grad_norm": 0.07328414916992188,
      "learning_rate": 5.835316515944789e-06,
      "loss": 0.0,
      "step": 14880
    },
    {
      "epoch": 7.087101380295097,
      "grad_norm": 0.006289684679359198,
      "learning_rate": 5.825797239409805e-06,
      "loss": 0.0,
      "step": 14890
    },
    {
      "epoch": 7.091861018562589,
      "grad_norm": 0.005823574960231781,
      "learning_rate": 5.816277962874822e-06,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 7.096620656830081,
      "grad_norm": 0.0003320164978504181,
      "learning_rate": 5.806758686339838e-06,
      "loss": 0.0,
      "step": 14910
    },
    {
      "epoch": 7.101380295097573,
      "grad_norm": 0.000428786181146279,
      "learning_rate": 5.797239409804856e-06,
      "loss": 0.0,
      "step": 14920
    },
    {
      "epoch": 7.106139933365064,
      "grad_norm": 0.00046781511628068984,
      "learning_rate": 5.787720133269872e-06,
      "loss": 0.0022,
      "step": 14930
    },
    {
      "epoch": 7.110899571632556,
      "grad_norm": 0.00020894809858873487,
      "learning_rate": 5.778200856734889e-06,
      "loss": 0.0,
      "step": 14940
    },
    {
      "epoch": 7.1156592099000475,
      "grad_norm": 38.51622009277344,
      "learning_rate": 5.768681580199905e-06,
      "loss": 0.0122,
      "step": 14950
    },
    {
      "epoch": 7.12041884816754,
      "grad_norm": 0.0038857823237776756,
      "learning_rate": 5.7591623036649226e-06,
      "loss": 0.0,
      "step": 14960
    },
    {
      "epoch": 7.125178486435031,
      "grad_norm": 0.0005669075762853026,
      "learning_rate": 5.7496430271299385e-06,
      "loss": 0.0,
      "step": 14970
    },
    {
      "epoch": 7.129938124702522,
      "grad_norm": 0.00030492807854898274,
      "learning_rate": 5.7401237505949545e-06,
      "loss": 0.0,
      "step": 14980
    },
    {
      "epoch": 7.134697762970014,
      "grad_norm": 0.00037592192529700696,
      "learning_rate": 5.730604474059972e-06,
      "loss": 0.0,
      "step": 14990
    },
    {
      "epoch": 7.139457401237506,
      "grad_norm": 0.0015858215047046542,
      "learning_rate": 5.721085197524988e-06,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 7.144217039504998,
      "grad_norm": 0.00019999642972834408,
      "learning_rate": 5.711565920990005e-06,
      "loss": 0.0,
      "step": 15010
    },
    {
      "epoch": 7.148976677772489,
      "grad_norm": 0.0002798688365146518,
      "learning_rate": 5.702046644455022e-06,
      "loss": 0.0004,
      "step": 15020
    },
    {
      "epoch": 7.153736316039981,
      "grad_norm": 0.0002748910046648234,
      "learning_rate": 5.692527367920039e-06,
      "loss": 0.0001,
      "step": 15030
    },
    {
      "epoch": 7.158495954307472,
      "grad_norm": 0.00030636496376246214,
      "learning_rate": 5.683008091385055e-06,
      "loss": 0.026,
      "step": 15040
    },
    {
      "epoch": 7.163255592574965,
      "grad_norm": 0.00022400061425287277,
      "learning_rate": 5.673488814850072e-06,
      "loss": 0.0001,
      "step": 15050
    },
    {
      "epoch": 7.168015230842456,
      "grad_norm": 0.00017376933828927577,
      "learning_rate": 5.663969538315088e-06,
      "loss": 0.0,
      "step": 15060
    },
    {
      "epoch": 7.172774869109948,
      "grad_norm": 0.0003034457331523299,
      "learning_rate": 5.654450261780105e-06,
      "loss": 0.0002,
      "step": 15070
    },
    {
      "epoch": 7.177534507377439,
      "grad_norm": 0.0001593706983840093,
      "learning_rate": 5.644930985245122e-06,
      "loss": 0.0,
      "step": 15080
    },
    {
      "epoch": 7.182294145644931,
      "grad_norm": 0.0009780103573575616,
      "learning_rate": 5.635411708710139e-06,
      "loss": 0.0,
      "step": 15090
    },
    {
      "epoch": 7.187053783912423,
      "grad_norm": 0.00015928382345009595,
      "learning_rate": 5.625892432175155e-06,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 7.191813422179914,
      "grad_norm": 8.58163257362321e-05,
      "learning_rate": 5.616373155640172e-06,
      "loss": 0.0003,
      "step": 15110
    },
    {
      "epoch": 7.196573060447406,
      "grad_norm": 0.00011460631503723562,
      "learning_rate": 5.6068538791051885e-06,
      "loss": 0.0001,
      "step": 15120
    },
    {
      "epoch": 7.201332698714897,
      "grad_norm": 0.00023368287656921893,
      "learning_rate": 5.5973346025702045e-06,
      "loss": 0.0,
      "step": 15130
    },
    {
      "epoch": 7.2060923369823895,
      "grad_norm": 0.0003862300654873252,
      "learning_rate": 5.587815326035222e-06,
      "loss": 0.0,
      "step": 15140
    },
    {
      "epoch": 7.210851975249881,
      "grad_norm": 0.00040953513234853745,
      "learning_rate": 5.578296049500238e-06,
      "loss": 0.0001,
      "step": 15150
    },
    {
      "epoch": 7.215611613517373,
      "grad_norm": 0.00024588112137280405,
      "learning_rate": 5.568776772965255e-06,
      "loss": 0.0,
      "step": 15160
    },
    {
      "epoch": 7.220371251784864,
      "grad_norm": 0.0026958752423524857,
      "learning_rate": 5.559257496430272e-06,
      "loss": 0.0,
      "step": 15170
    },
    {
      "epoch": 7.225130890052356,
      "grad_norm": 0.010666713118553162,
      "learning_rate": 5.549738219895289e-06,
      "loss": 0.0001,
      "step": 15180
    },
    {
      "epoch": 7.229890528319848,
      "grad_norm": 0.0002464798162691295,
      "learning_rate": 5.540218943360305e-06,
      "loss": 0.0,
      "step": 15190
    },
    {
      "epoch": 7.23465016658734,
      "grad_norm": 0.000702585035469383,
      "learning_rate": 5.530699666825322e-06,
      "loss": 0.0104,
      "step": 15200
    },
    {
      "epoch": 7.239409804854831,
      "grad_norm": 15.893345832824707,
      "learning_rate": 5.521180390290338e-06,
      "loss": 0.0155,
      "step": 15210
    },
    {
      "epoch": 7.244169443122322,
      "grad_norm": 0.00010893238504650071,
      "learning_rate": 5.511661113755355e-06,
      "loss": 0.0,
      "step": 15220
    },
    {
      "epoch": 7.248929081389814,
      "grad_norm": 0.00016126390255521983,
      "learning_rate": 5.502141837220372e-06,
      "loss": 0.0046,
      "step": 15230
    },
    {
      "epoch": 7.253688719657306,
      "grad_norm": 0.0019904200453311205,
      "learning_rate": 5.492622560685389e-06,
      "loss": 0.0,
      "step": 15240
    },
    {
      "epoch": 7.258448357924798,
      "grad_norm": 0.00011235189595026895,
      "learning_rate": 5.483103284150405e-06,
      "loss": 0.0002,
      "step": 15250
    },
    {
      "epoch": 7.263207996192289,
      "grad_norm": 0.000153940127347596,
      "learning_rate": 5.473584007615421e-06,
      "loss": 0.0,
      "step": 15260
    },
    {
      "epoch": 7.267967634459781,
      "grad_norm": 0.0019954328890889883,
      "learning_rate": 5.4640647310804385e-06,
      "loss": 0.0,
      "step": 15270
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.0006254654726944864,
      "learning_rate": 5.4545454545454545e-06,
      "loss": 0.0332,
      "step": 15280
    },
    {
      "epoch": 7.277486910994765,
      "grad_norm": 0.0001299174764426425,
      "learning_rate": 5.445026178010472e-06,
      "loss": 0.0,
      "step": 15290
    },
    {
      "epoch": 7.282246549262256,
      "grad_norm": 0.000548981421161443,
      "learning_rate": 5.435506901475488e-06,
      "loss": 0.0,
      "step": 15300
    },
    {
      "epoch": 7.287006187529748,
      "grad_norm": 0.019554834812879562,
      "learning_rate": 5.425987624940505e-06,
      "loss": 0.0,
      "step": 15310
    },
    {
      "epoch": 7.291765825797239,
      "grad_norm": 0.00030970355146564543,
      "learning_rate": 5.416468348405522e-06,
      "loss": 0.002,
      "step": 15320
    },
    {
      "epoch": 7.2965254640647315,
      "grad_norm": 0.00030244089430198073,
      "learning_rate": 5.406949071870539e-06,
      "loss": 0.0049,
      "step": 15330
    },
    {
      "epoch": 7.301285102332223,
      "grad_norm": 0.0008603259921073914,
      "learning_rate": 5.397429795335555e-06,
      "loss": 0.0051,
      "step": 15340
    },
    {
      "epoch": 7.306044740599715,
      "grad_norm": 0.0006175097078084946,
      "learning_rate": 5.387910518800572e-06,
      "loss": 0.0,
      "step": 15350
    },
    {
      "epoch": 7.310804378867206,
      "grad_norm": 0.00012454480747692287,
      "learning_rate": 5.378391242265588e-06,
      "loss": 0.0,
      "step": 15360
    },
    {
      "epoch": 7.315564017134697,
      "grad_norm": 0.025409139692783356,
      "learning_rate": 5.368871965730605e-06,
      "loss": 0.0,
      "step": 15370
    },
    {
      "epoch": 7.3203236554021895,
      "grad_norm": 0.0003361220587976277,
      "learning_rate": 5.359352689195622e-06,
      "loss": 0.0,
      "step": 15380
    },
    {
      "epoch": 7.325083293669681,
      "grad_norm": 0.003467078087851405,
      "learning_rate": 5.349833412660638e-06,
      "loss": 0.0,
      "step": 15390
    },
    {
      "epoch": 7.329842931937173,
      "grad_norm": 0.006083416286855936,
      "learning_rate": 5.340314136125655e-06,
      "loss": 0.0,
      "step": 15400
    },
    {
      "epoch": 7.334602570204664,
      "grad_norm": 0.04413449019193649,
      "learning_rate": 5.330794859590671e-06,
      "loss": 0.0,
      "step": 15410
    },
    {
      "epoch": 7.339362208472156,
      "grad_norm": 0.0007817510631866753,
      "learning_rate": 5.3212755830556884e-06,
      "loss": 0.0005,
      "step": 15420
    },
    {
      "epoch": 7.344121846739648,
      "grad_norm": 0.0004513294552452862,
      "learning_rate": 5.311756306520704e-06,
      "loss": 0.0,
      "step": 15430
    },
    {
      "epoch": 7.34888148500714,
      "grad_norm": 0.0007043706718832254,
      "learning_rate": 5.302237029985722e-06,
      "loss": 0.0237,
      "step": 15440
    },
    {
      "epoch": 7.353641123274631,
      "grad_norm": 0.00019476551096886396,
      "learning_rate": 5.292717753450738e-06,
      "loss": 0.0,
      "step": 15450
    },
    {
      "epoch": 7.358400761542123,
      "grad_norm": 0.010417472571134567,
      "learning_rate": 5.283198476915755e-06,
      "loss": 0.0056,
      "step": 15460
    },
    {
      "epoch": 7.3631603998096145,
      "grad_norm": 0.00362490676343441,
      "learning_rate": 5.273679200380771e-06,
      "loss": 0.0048,
      "step": 15470
    },
    {
      "epoch": 7.367920038077106,
      "grad_norm": 0.0002505605516489595,
      "learning_rate": 5.264159923845789e-06,
      "loss": 0.0001,
      "step": 15480
    },
    {
      "epoch": 7.372679676344598,
      "grad_norm": 0.0007870456320233643,
      "learning_rate": 5.2546406473108046e-06,
      "loss": 0.0,
      "step": 15490
    },
    {
      "epoch": 7.377439314612089,
      "grad_norm": 0.4098604917526245,
      "learning_rate": 5.245121370775822e-06,
      "loss": 0.0001,
      "step": 15500
    },
    {
      "epoch": 7.382198952879581,
      "grad_norm": 0.0045901513658463955,
      "learning_rate": 5.235602094240838e-06,
      "loss": 0.0,
      "step": 15510
    },
    {
      "epoch": 7.3869585911470725,
      "grad_norm": 0.0002741976932156831,
      "learning_rate": 5.226082817705854e-06,
      "loss": 0.0,
      "step": 15520
    },
    {
      "epoch": 7.391718229414565,
      "grad_norm": 0.00025655675563029945,
      "learning_rate": 5.216563541170872e-06,
      "loss": 0.0,
      "step": 15530
    },
    {
      "epoch": 7.396477867682056,
      "grad_norm": 0.0008207842474803329,
      "learning_rate": 5.207044264635888e-06,
      "loss": 0.0018,
      "step": 15540
    },
    {
      "epoch": 7.401237505949548,
      "grad_norm": 0.001589439227245748,
      "learning_rate": 5.197524988100905e-06,
      "loss": 0.0004,
      "step": 15550
    },
    {
      "epoch": 7.405997144217039,
      "grad_norm": 0.0005066983285360038,
      "learning_rate": 5.188005711565921e-06,
      "loss": 0.0,
      "step": 15560
    },
    {
      "epoch": 7.4107567824845315,
      "grad_norm": 0.0015650440473109484,
      "learning_rate": 5.178486435030938e-06,
      "loss": 0.0002,
      "step": 15570
    },
    {
      "epoch": 7.415516420752023,
      "grad_norm": 0.0005287100793793797,
      "learning_rate": 5.168967158495954e-06,
      "loss": 0.0,
      "step": 15580
    },
    {
      "epoch": 7.420276059019515,
      "grad_norm": 0.00011458403605502099,
      "learning_rate": 5.159447881960972e-06,
      "loss": 0.0,
      "step": 15590
    },
    {
      "epoch": 7.425035697287006,
      "grad_norm": 0.00036658538738265634,
      "learning_rate": 5.149928605425988e-06,
      "loss": 0.0028,
      "step": 15600
    },
    {
      "epoch": 7.4297953355544974,
      "grad_norm": 0.0003304139827378094,
      "learning_rate": 5.140409328891005e-06,
      "loss": 0.0,
      "step": 15610
    },
    {
      "epoch": 7.43455497382199,
      "grad_norm": 0.0007210887270048261,
      "learning_rate": 5.130890052356021e-06,
      "loss": 0.0,
      "step": 15620
    },
    {
      "epoch": 7.439314612089481,
      "grad_norm": 0.009870974346995354,
      "learning_rate": 5.1213707758210385e-06,
      "loss": 0.0002,
      "step": 15630
    },
    {
      "epoch": 7.444074250356973,
      "grad_norm": 0.00016231324116233736,
      "learning_rate": 5.1118514992860545e-06,
      "loss": 0.0,
      "step": 15640
    },
    {
      "epoch": 7.448833888624464,
      "grad_norm": 0.0005797696067020297,
      "learning_rate": 5.102332222751072e-06,
      "loss": 0.0,
      "step": 15650
    },
    {
      "epoch": 7.453593526891956,
      "grad_norm": 0.0005338210612535477,
      "learning_rate": 5.092812946216088e-06,
      "loss": 0.0,
      "step": 15660
    },
    {
      "epoch": 7.458353165159448,
      "grad_norm": 0.00031548613333143294,
      "learning_rate": 5.083293669681104e-06,
      "loss": 0.0,
      "step": 15670
    },
    {
      "epoch": 7.46311280342694,
      "grad_norm": 0.006301175802946091,
      "learning_rate": 5.073774393146121e-06,
      "loss": 0.0,
      "step": 15680
    },
    {
      "epoch": 7.467872441694431,
      "grad_norm": 0.0074876584112644196,
      "learning_rate": 5.064255116611138e-06,
      "loss": 0.0,
      "step": 15690
    },
    {
      "epoch": 7.472632079961923,
      "grad_norm": 0.0002785834367386997,
      "learning_rate": 5.054735840076155e-06,
      "loss": 0.0001,
      "step": 15700
    },
    {
      "epoch": 7.4773917182294145,
      "grad_norm": 0.0003049532533623278,
      "learning_rate": 5.045216563541171e-06,
      "loss": 0.0,
      "step": 15710
    },
    {
      "epoch": 7.482151356496907,
      "grad_norm": 0.0004264718445483595,
      "learning_rate": 5.035697287006188e-06,
      "loss": 0.0002,
      "step": 15720
    },
    {
      "epoch": 7.486910994764398,
      "grad_norm": 0.0006173259462229908,
      "learning_rate": 5.026178010471204e-06,
      "loss": 0.0002,
      "step": 15730
    },
    {
      "epoch": 7.491670633031889,
      "grad_norm": 0.0011641595046967268,
      "learning_rate": 5.016658733936222e-06,
      "loss": 0.0,
      "step": 15740
    },
    {
      "epoch": 7.496430271299381,
      "grad_norm": 0.06210479512810707,
      "learning_rate": 5.007139457401238e-06,
      "loss": 0.0,
      "step": 15750
    },
    {
      "epoch": 7.501189909566873,
      "grad_norm": 0.00017656768613960594,
      "learning_rate": 4.997620180866255e-06,
      "loss": 0.0,
      "step": 15760
    },
    {
      "epoch": 7.505949547834365,
      "grad_norm": 0.005494602490216494,
      "learning_rate": 4.988100904331271e-06,
      "loss": 0.0,
      "step": 15770
    },
    {
      "epoch": 7.510709186101856,
      "grad_norm": 5.138571941643022e-05,
      "learning_rate": 4.978581627796288e-06,
      "loss": 0.0,
      "step": 15780
    },
    {
      "epoch": 7.515468824369348,
      "grad_norm": 0.00027486024191603065,
      "learning_rate": 4.9690623512613045e-06,
      "loss": 0.0,
      "step": 15790
    },
    {
      "epoch": 7.520228462636839,
      "grad_norm": 0.00020948756719008088,
      "learning_rate": 4.959543074726321e-06,
      "loss": 0.0,
      "step": 15800
    },
    {
      "epoch": 7.524988100904332,
      "grad_norm": 0.00010984182881657034,
      "learning_rate": 4.950023798191338e-06,
      "loss": 0.0,
      "step": 15810
    },
    {
      "epoch": 7.529747739171823,
      "grad_norm": 0.030486680567264557,
      "learning_rate": 4.940504521656355e-06,
      "loss": 0.0,
      "step": 15820
    },
    {
      "epoch": 7.534507377439315,
      "grad_norm": 6.320750253507867e-05,
      "learning_rate": 4.930985245121371e-06,
      "loss": 0.0,
      "step": 15830
    },
    {
      "epoch": 7.539267015706806,
      "grad_norm": 0.0002481232222635299,
      "learning_rate": 4.921465968586388e-06,
      "loss": 0.0002,
      "step": 15840
    },
    {
      "epoch": 7.5440266539742975,
      "grad_norm": 0.0002065501903416589,
      "learning_rate": 4.911946692051405e-06,
      "loss": 0.012,
      "step": 15850
    },
    {
      "epoch": 7.54878629224179,
      "grad_norm": 0.0007499620551243424,
      "learning_rate": 4.9024274155164215e-06,
      "loss": 0.0,
      "step": 15860
    },
    {
      "epoch": 7.553545930509281,
      "grad_norm": 0.00015778491797391325,
      "learning_rate": 4.8929081389814375e-06,
      "loss": 0.0012,
      "step": 15870
    },
    {
      "epoch": 7.558305568776773,
      "grad_norm": 0.0011178096756339073,
      "learning_rate": 4.883388862446454e-06,
      "loss": 0.0,
      "step": 15880
    },
    {
      "epoch": 7.563065207044264,
      "grad_norm": 0.0005157490377314389,
      "learning_rate": 4.873869585911471e-06,
      "loss": 0.0,
      "step": 15890
    },
    {
      "epoch": 7.5678248453117565,
      "grad_norm": 0.00010834651766344905,
      "learning_rate": 4.864350309376488e-06,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 7.572584483579248,
      "grad_norm": 16.434524536132812,
      "learning_rate": 4.854831032841505e-06,
      "loss": 0.0304,
      "step": 15910
    },
    {
      "epoch": 7.57734412184674,
      "grad_norm": 0.005000958684831858,
      "learning_rate": 4.845311756306521e-06,
      "loss": 0.0,
      "step": 15920
    },
    {
      "epoch": 7.582103760114231,
      "grad_norm": 0.0036159183364361525,
      "learning_rate": 4.835792479771538e-06,
      "loss": 0.0143,
      "step": 15930
    },
    {
      "epoch": 7.586863398381723,
      "grad_norm": 0.0010159059893339872,
      "learning_rate": 4.8262732032365544e-06,
      "loss": 0.0,
      "step": 15940
    },
    {
      "epoch": 7.591623036649215,
      "grad_norm": 0.0010278221452608705,
      "learning_rate": 4.816753926701571e-06,
      "loss": 0.0,
      "step": 15950
    },
    {
      "epoch": 7.596382674916707,
      "grad_norm": 0.0006986875087022781,
      "learning_rate": 4.807234650166588e-06,
      "loss": 0.0096,
      "step": 15960
    },
    {
      "epoch": 7.601142313184198,
      "grad_norm": 0.0003327085287310183,
      "learning_rate": 4.797715373631605e-06,
      "loss": 0.0,
      "step": 15970
    },
    {
      "epoch": 7.60590195145169,
      "grad_norm": 0.0006132886628620327,
      "learning_rate": 4.788196097096621e-06,
      "loss": 0.0257,
      "step": 15980
    },
    {
      "epoch": 7.610661589719181,
      "grad_norm": 0.0014227097854018211,
      "learning_rate": 4.778676820561638e-06,
      "loss": 0.0,
      "step": 15990
    },
    {
      "epoch": 7.615421227986673,
      "grad_norm": 0.0008906602161005139,
      "learning_rate": 4.769157544026654e-06,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 7.620180866254165,
      "grad_norm": 0.002242517890408635,
      "learning_rate": 4.759638267491671e-06,
      "loss": 0.0008,
      "step": 16010
    },
    {
      "epoch": 7.624940504521656,
      "grad_norm": 0.021273119375109673,
      "learning_rate": 4.750118990956687e-06,
      "loss": 0.0001,
      "step": 16020
    },
    {
      "epoch": 7.629700142789148,
      "grad_norm": 0.0004822201153729111,
      "learning_rate": 4.740599714421704e-06,
      "loss": 0.0,
      "step": 16030
    },
    {
      "epoch": 7.6344597810566395,
      "grad_norm": 0.0033785002306103706,
      "learning_rate": 4.731080437886721e-06,
      "loss": 0.0,
      "step": 16040
    },
    {
      "epoch": 7.639219419324132,
      "grad_norm": 0.0013325730105862021,
      "learning_rate": 4.721561161351738e-06,
      "loss": 0.0004,
      "step": 16050
    },
    {
      "epoch": 7.643979057591623,
      "grad_norm": 3.2220475673675537,
      "learning_rate": 4.712041884816754e-06,
      "loss": 0.0043,
      "step": 16060
    },
    {
      "epoch": 7.648738695859115,
      "grad_norm": 0.029981397092342377,
      "learning_rate": 4.702522608281771e-06,
      "loss": 0.0001,
      "step": 16070
    },
    {
      "epoch": 7.653498334126606,
      "grad_norm": 0.057946909219026566,
      "learning_rate": 4.6930033317467876e-06,
      "loss": 0.0001,
      "step": 16080
    },
    {
      "epoch": 7.6582579723940984,
      "grad_norm": 0.00015432905638590455,
      "learning_rate": 4.683484055211804e-06,
      "loss": 0.0,
      "step": 16090
    },
    {
      "epoch": 7.66301761066159,
      "grad_norm": 0.0026149090845137835,
      "learning_rate": 4.673964778676821e-06,
      "loss": 0.0013,
      "step": 16100
    },
    {
      "epoch": 7.667777248929081,
      "grad_norm": 0.01655968837440014,
      "learning_rate": 4.664445502141838e-06,
      "loss": 0.0001,
      "step": 16110
    },
    {
      "epoch": 7.672536887196573,
      "grad_norm": 0.02092907577753067,
      "learning_rate": 4.654926225606855e-06,
      "loss": 0.0,
      "step": 16120
    },
    {
      "epoch": 7.677296525464064,
      "grad_norm": 0.0015588341047987342,
      "learning_rate": 4.645406949071871e-06,
      "loss": 0.0003,
      "step": 16130
    },
    {
      "epoch": 7.6820561637315565,
      "grad_norm": 0.00041578232776373625,
      "learning_rate": 4.635887672536888e-06,
      "loss": 0.0,
      "step": 16140
    },
    {
      "epoch": 7.686815801999048,
      "grad_norm": 0.002162155695259571,
      "learning_rate": 4.626368396001904e-06,
      "loss": 0.0,
      "step": 16150
    },
    {
      "epoch": 7.69157544026654,
      "grad_norm": 0.000594796787481755,
      "learning_rate": 4.6168491194669205e-06,
      "loss": 0.0,
      "step": 16160
    },
    {
      "epoch": 7.696335078534031,
      "grad_norm": 0.0005307670217007399,
      "learning_rate": 4.607329842931937e-06,
      "loss": 0.0,
      "step": 16170
    },
    {
      "epoch": 7.701094716801523,
      "grad_norm": 0.00018073184764944017,
      "learning_rate": 4.597810566396954e-06,
      "loss": 0.0,
      "step": 16180
    },
    {
      "epoch": 7.705854355069015,
      "grad_norm": 0.00027515977853909135,
      "learning_rate": 4.588291289861971e-06,
      "loss": 0.0,
      "step": 16190
    },
    {
      "epoch": 7.710613993336507,
      "grad_norm": 0.03134968876838684,
      "learning_rate": 4.578772013326988e-06,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 7.715373631603998,
      "grad_norm": 2.4439854621887207,
      "learning_rate": 4.569252736792004e-06,
      "loss": 0.0147,
      "step": 16210
    },
    {
      "epoch": 7.720133269871489,
      "grad_norm": 0.0004926644614897668,
      "learning_rate": 4.559733460257021e-06,
      "loss": 0.0,
      "step": 16220
    },
    {
      "epoch": 7.724892908138981,
      "grad_norm": 2.592207908630371,
      "learning_rate": 4.5502141837220375e-06,
      "loss": 0.0007,
      "step": 16230
    },
    {
      "epoch": 7.729652546406474,
      "grad_norm": 0.00032848058617673814,
      "learning_rate": 4.540694907187054e-06,
      "loss": 0.0,
      "step": 16240
    },
    {
      "epoch": 7.734412184673965,
      "grad_norm": 0.0005340980715118349,
      "learning_rate": 4.531175630652071e-06,
      "loss": 0.015,
      "step": 16250
    },
    {
      "epoch": 7.739171822941456,
      "grad_norm": 0.015521405264735222,
      "learning_rate": 4.521656354117088e-06,
      "loss": 0.0,
      "step": 16260
    },
    {
      "epoch": 7.743931461208948,
      "grad_norm": 0.00011078775423811749,
      "learning_rate": 4.512137077582104e-06,
      "loss": 0.0,
      "step": 16270
    },
    {
      "epoch": 7.7486910994764395,
      "grad_norm": 0.00014118551916908473,
      "learning_rate": 4.502617801047121e-06,
      "loss": 0.0,
      "step": 16280
    },
    {
      "epoch": 7.753450737743932,
      "grad_norm": 0.0027696965262293816,
      "learning_rate": 4.493098524512137e-06,
      "loss": 0.0022,
      "step": 16290
    },
    {
      "epoch": 7.758210376011423,
      "grad_norm": 0.0010225741425529122,
      "learning_rate": 4.483579247977154e-06,
      "loss": 0.0,
      "step": 16300
    },
    {
      "epoch": 7.762970014278915,
      "grad_norm": 0.0004268751945346594,
      "learning_rate": 4.4740599714421705e-06,
      "loss": 0.0,
      "step": 16310
    },
    {
      "epoch": 7.767729652546406,
      "grad_norm": 0.000340731639880687,
      "learning_rate": 4.464540694907187e-06,
      "loss": 0.0,
      "step": 16320
    },
    {
      "epoch": 7.7724892908138985,
      "grad_norm": 0.22464320063591003,
      "learning_rate": 4.455021418372204e-06,
      "loss": 0.0001,
      "step": 16330
    },
    {
      "epoch": 7.77724892908139,
      "grad_norm": 0.0005125821335241199,
      "learning_rate": 4.445502141837221e-06,
      "loss": 0.0001,
      "step": 16340
    },
    {
      "epoch": 7.782008567348882,
      "grad_norm": 0.0009471792145632207,
      "learning_rate": 4.435982865302238e-06,
      "loss": 0.0,
      "step": 16350
    },
    {
      "epoch": 7.786768205616373,
      "grad_norm": 0.00022500692284666002,
      "learning_rate": 4.426463588767254e-06,
      "loss": 0.0178,
      "step": 16360
    },
    {
      "epoch": 7.791527843883864,
      "grad_norm": 0.0003587077371776104,
      "learning_rate": 4.416944312232271e-06,
      "loss": 0.0,
      "step": 16370
    },
    {
      "epoch": 7.796287482151357,
      "grad_norm": 0.0006434970418922603,
      "learning_rate": 4.4074250356972875e-06,
      "loss": 0.0005,
      "step": 16380
    },
    {
      "epoch": 7.801047120418848,
      "grad_norm": 0.007921246811747551,
      "learning_rate": 4.397905759162304e-06,
      "loss": 0.0,
      "step": 16390
    },
    {
      "epoch": 7.80580675868634,
      "grad_norm": 0.00015057239215821028,
      "learning_rate": 4.388386482627321e-06,
      "loss": 0.0,
      "step": 16400
    },
    {
      "epoch": 7.810566396953831,
      "grad_norm": 0.00538972020149231,
      "learning_rate": 4.378867206092337e-06,
      "loss": 0.0,
      "step": 16410
    },
    {
      "epoch": 7.815326035221323,
      "grad_norm": 0.00021405234292615205,
      "learning_rate": 4.369347929557354e-06,
      "loss": 0.0001,
      "step": 16420
    },
    {
      "epoch": 7.820085673488815,
      "grad_norm": 0.00044158505625091493,
      "learning_rate": 4.359828653022371e-06,
      "loss": 0.0,
      "step": 16430
    },
    {
      "epoch": 7.824845311756307,
      "grad_norm": 0.0003375915694050491,
      "learning_rate": 4.350309376487387e-06,
      "loss": 0.0,
      "step": 16440
    },
    {
      "epoch": 7.829604950023798,
      "grad_norm": 0.0009443770977668464,
      "learning_rate": 4.340790099952404e-06,
      "loss": 0.0388,
      "step": 16450
    },
    {
      "epoch": 7.83436458829129,
      "grad_norm": 0.00048332547885365784,
      "learning_rate": 4.3312708234174205e-06,
      "loss": 0.0,
      "step": 16460
    },
    {
      "epoch": 7.8391242265587815,
      "grad_norm": 0.00023225716722663492,
      "learning_rate": 4.321751546882437e-06,
      "loss": 0.0009,
      "step": 16470
    },
    {
      "epoch": 7.843883864826273,
      "grad_norm": 6.458539428422228e-05,
      "learning_rate": 4.312232270347454e-06,
      "loss": 0.0001,
      "step": 16480
    },
    {
      "epoch": 7.848643503093765,
      "grad_norm": 0.00022808504581917077,
      "learning_rate": 4.302712993812471e-06,
      "loss": 0.0,
      "step": 16490
    },
    {
      "epoch": 7.853403141361256,
      "grad_norm": 0.00012805857113562524,
      "learning_rate": 4.293193717277487e-06,
      "loss": 0.0073,
      "step": 16500
    },
    {
      "epoch": 7.858162779628748,
      "grad_norm": 0.0019955597817897797,
      "learning_rate": 4.283674440742504e-06,
      "loss": 0.0,
      "step": 16510
    },
    {
      "epoch": 7.86292241789624,
      "grad_norm": 6.961923122406006,
      "learning_rate": 4.274155164207521e-06,
      "loss": 0.0468,
      "step": 16520
    },
    {
      "epoch": 7.867682056163732,
      "grad_norm": 0.0013290703063830733,
      "learning_rate": 4.2646358876725374e-06,
      "loss": 0.0,
      "step": 16530
    },
    {
      "epoch": 7.872441694431223,
      "grad_norm": 0.0009213375160470605,
      "learning_rate": 4.255116611137554e-06,
      "loss": 0.0,
      "step": 16540
    },
    {
      "epoch": 7.877201332698715,
      "grad_norm": 0.0006611103308387101,
      "learning_rate": 4.24559733460257e-06,
      "loss": 0.0,
      "step": 16550
    },
    {
      "epoch": 7.881960970966206,
      "grad_norm": 0.004767317790538073,
      "learning_rate": 4.236078058067587e-06,
      "loss": 0.0101,
      "step": 16560
    },
    {
      "epoch": 7.8867206092336986,
      "grad_norm": 0.0002701111661735922,
      "learning_rate": 4.226558781532604e-06,
      "loss": 0.0,
      "step": 16570
    },
    {
      "epoch": 7.89148024750119,
      "grad_norm": 0.002991668414324522,
      "learning_rate": 4.217039504997621e-06,
      "loss": 0.0,
      "step": 16580
    },
    {
      "epoch": 7.896239885768682,
      "grad_norm": 0.002167529659345746,
      "learning_rate": 4.207520228462637e-06,
      "loss": 0.0048,
      "step": 16590
    },
    {
      "epoch": 7.900999524036173,
      "grad_norm": 0.0001681479625403881,
      "learning_rate": 4.198000951927654e-06,
      "loss": 0.0009,
      "step": 16600
    },
    {
      "epoch": 7.905759162303665,
      "grad_norm": 0.0003284816921222955,
      "learning_rate": 4.18848167539267e-06,
      "loss": 0.0,
      "step": 16610
    },
    {
      "epoch": 7.910518800571157,
      "grad_norm": 0.006180450785905123,
      "learning_rate": 4.178962398857687e-06,
      "loss": 0.0036,
      "step": 16620
    },
    {
      "epoch": 7.915278438838648,
      "grad_norm": 0.0006251789745874703,
      "learning_rate": 4.169443122322704e-06,
      "loss": 0.0001,
      "step": 16630
    },
    {
      "epoch": 7.92003807710614,
      "grad_norm": 0.0008631307282485068,
      "learning_rate": 4.159923845787721e-06,
      "loss": 0.0,
      "step": 16640
    },
    {
      "epoch": 7.924797715373631,
      "grad_norm": 0.0005979846464470029,
      "learning_rate": 4.150404569252737e-06,
      "loss": 0.0,
      "step": 16650
    },
    {
      "epoch": 7.9295573536411235,
      "grad_norm": 0.00025313731748610735,
      "learning_rate": 4.140885292717754e-06,
      "loss": 0.0,
      "step": 16660
    },
    {
      "epoch": 7.934316991908615,
      "grad_norm": 0.00027422638959251344,
      "learning_rate": 4.1313660161827706e-06,
      "loss": 0.0323,
      "step": 16670
    },
    {
      "epoch": 7.939076630176107,
      "grad_norm": 0.0002839737571775913,
      "learning_rate": 4.121846739647787e-06,
      "loss": 0.0,
      "step": 16680
    },
    {
      "epoch": 7.943836268443598,
      "grad_norm": 0.0003777702513616532,
      "learning_rate": 4.112327463112803e-06,
      "loss": 0.0351,
      "step": 16690
    },
    {
      "epoch": 7.94859590671109,
      "grad_norm": 0.00026589763001538813,
      "learning_rate": 4.10280818657782e-06,
      "loss": 0.0,
      "step": 16700
    },
    {
      "epoch": 7.9533555449785815,
      "grad_norm": 0.0005779389757663012,
      "learning_rate": 4.093288910042837e-06,
      "loss": 0.0,
      "step": 16710
    },
    {
      "epoch": 7.958115183246074,
      "grad_norm": 0.002907332731410861,
      "learning_rate": 4.083769633507854e-06,
      "loss": 0.0097,
      "step": 16720
    },
    {
      "epoch": 7.962874821513565,
      "grad_norm": 0.002342097694054246,
      "learning_rate": 4.074250356972871e-06,
      "loss": 0.0,
      "step": 16730
    },
    {
      "epoch": 7.967634459781056,
      "grad_norm": 0.00026302310288883746,
      "learning_rate": 4.064731080437887e-06,
      "loss": 0.0,
      "step": 16740
    },
    {
      "epoch": 7.972394098048548,
      "grad_norm": 0.0005002262187190354,
      "learning_rate": 4.0552118039029035e-06,
      "loss": 0.0,
      "step": 16750
    },
    {
      "epoch": 7.97715373631604,
      "grad_norm": 0.002129876520484686,
      "learning_rate": 4.04569252736792e-06,
      "loss": 0.0,
      "step": 16760
    },
    {
      "epoch": 7.981913374583532,
      "grad_norm": 0.0005741720669902861,
      "learning_rate": 4.036173250832937e-06,
      "loss": 0.0,
      "step": 16770
    },
    {
      "epoch": 7.986673012851023,
      "grad_norm": 0.0007185530848801136,
      "learning_rate": 4.026653974297954e-06,
      "loss": 0.0002,
      "step": 16780
    },
    {
      "epoch": 7.991432651118515,
      "grad_norm": 0.000499261193908751,
      "learning_rate": 4.017134697762971e-06,
      "loss": 0.0,
      "step": 16790
    },
    {
      "epoch": 7.9961922893860065,
      "grad_norm": 0.0003929722588509321,
      "learning_rate": 4.007615421227987e-06,
      "loss": 0.0,
      "step": 16800
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9979872293170461,
      "eval_f1": 0.9890854347007905,
      "eval_loss": 0.014390227384865284,
      "eval_precision": 0.9916981132075472,
      "eval_recall": 0.9864864864864865,
      "eval_runtime": 1908.8479,
      "eval_samples_per_second": 7.55,
      "eval_steps_per_second": 0.944,
      "step": 16808
    }
  ],
  "logging_steps": 10,
  "max_steps": 21010,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.454372362151872e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
