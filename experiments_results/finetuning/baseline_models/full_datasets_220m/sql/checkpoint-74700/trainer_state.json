{
  "best_metric": 0.9666770476487075,
  "best_model_checkpoint": "../saved_models/gruenau9_sql/checkpoint-74700",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 74700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00012048192771084337,
      "grad_norm": 1.0676921606063843,
      "learning_rate": 1.999975903614458e-05,
      "loss": 0.0191,
      "step": 1
    },
    {
      "epoch": 0.0012048192771084338,
      "grad_norm": 0.0630418062210083,
      "learning_rate": 1.9997590361445783e-05,
      "loss": 0.0008,
      "step": 10
    },
    {
      "epoch": 0.0024096385542168677,
      "grad_norm": 0.005161529406905174,
      "learning_rate": 1.9995180722891568e-05,
      "loss": 0.0481,
      "step": 20
    },
    {
      "epoch": 0.0036144578313253013,
      "grad_norm": 1.3860775232315063,
      "learning_rate": 1.999277108433735e-05,
      "loss": 0.053,
      "step": 30
    },
    {
      "epoch": 0.004819277108433735,
      "grad_norm": 0.049288004636764526,
      "learning_rate": 1.9990361445783134e-05,
      "loss": 0.0213,
      "step": 40
    },
    {
      "epoch": 0.006024096385542169,
      "grad_norm": 0.0009889740031212568,
      "learning_rate": 1.998795180722892e-05,
      "loss": 0.0325,
      "step": 50
    },
    {
      "epoch": 0.007228915662650603,
      "grad_norm": 0.5248504281044006,
      "learning_rate": 1.99855421686747e-05,
      "loss": 0.052,
      "step": 60
    },
    {
      "epoch": 0.008433734939759036,
      "grad_norm": 0.0012022911105304956,
      "learning_rate": 1.9983132530120482e-05,
      "loss": 0.0302,
      "step": 70
    },
    {
      "epoch": 0.00963855421686747,
      "grad_norm": 2.702286720275879,
      "learning_rate": 1.9980722891566267e-05,
      "loss": 0.0093,
      "step": 80
    },
    {
      "epoch": 0.010843373493975903,
      "grad_norm": 0.077176034450531,
      "learning_rate": 1.997831325301205e-05,
      "loss": 0.0123,
      "step": 90
    },
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 7.3428730964660645,
      "learning_rate": 1.9975903614457833e-05,
      "loss": 0.1201,
      "step": 100
    },
    {
      "epoch": 0.01325301204819277,
      "grad_norm": 11.861882209777832,
      "learning_rate": 1.9973493975903615e-05,
      "loss": 0.0327,
      "step": 110
    },
    {
      "epoch": 0.014457831325301205,
      "grad_norm": 0.0019745982717722654,
      "learning_rate": 1.99710843373494e-05,
      "loss": 0.0388,
      "step": 120
    },
    {
      "epoch": 0.01566265060240964,
      "grad_norm": 0.6585139632225037,
      "learning_rate": 1.9968674698795185e-05,
      "loss": 0.0023,
      "step": 130
    },
    {
      "epoch": 0.016867469879518072,
      "grad_norm": 0.016490815207362175,
      "learning_rate": 1.9966265060240966e-05,
      "loss": 0.0263,
      "step": 140
    },
    {
      "epoch": 0.018072289156626505,
      "grad_norm": 0.0007323601748794317,
      "learning_rate": 1.9963855421686748e-05,
      "loss": 0.0151,
      "step": 150
    },
    {
      "epoch": 0.01927710843373494,
      "grad_norm": 12.954727172851562,
      "learning_rate": 1.9961445783132532e-05,
      "loss": 0.0278,
      "step": 160
    },
    {
      "epoch": 0.020481927710843374,
      "grad_norm": 0.0965971052646637,
      "learning_rate": 1.9959036144578314e-05,
      "loss": 0.0457,
      "step": 170
    },
    {
      "epoch": 0.021686746987951807,
      "grad_norm": 33.48600387573242,
      "learning_rate": 1.99566265060241e-05,
      "loss": 0.0821,
      "step": 180
    },
    {
      "epoch": 0.02289156626506024,
      "grad_norm": 0.036751165986061096,
      "learning_rate": 1.9954216867469884e-05,
      "loss": 0.0513,
      "step": 190
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 1.7081228494644165,
      "learning_rate": 1.9951807228915665e-05,
      "loss": 0.0435,
      "step": 200
    },
    {
      "epoch": 0.02530120481927711,
      "grad_norm": 0.1145932525396347,
      "learning_rate": 1.9949397590361447e-05,
      "loss": 0.0681,
      "step": 210
    },
    {
      "epoch": 0.02650602409638554,
      "grad_norm": 8.073564529418945,
      "learning_rate": 1.994698795180723e-05,
      "loss": 0.0706,
      "step": 220
    },
    {
      "epoch": 0.027710843373493974,
      "grad_norm": 0.16382023692131042,
      "learning_rate": 1.9944578313253013e-05,
      "loss": 0.0268,
      "step": 230
    },
    {
      "epoch": 0.02891566265060241,
      "grad_norm": 8.600852966308594,
      "learning_rate": 1.9942168674698798e-05,
      "loss": 0.0221,
      "step": 240
    },
    {
      "epoch": 0.030120481927710843,
      "grad_norm": 20.9041748046875,
      "learning_rate": 1.993975903614458e-05,
      "loss": 0.1551,
      "step": 250
    },
    {
      "epoch": 0.03132530120481928,
      "grad_norm": 3.082825183868408,
      "learning_rate": 1.993734939759036e-05,
      "loss": 0.0565,
      "step": 260
    },
    {
      "epoch": 0.03253012048192771,
      "grad_norm": 0.18210887908935547,
      "learning_rate": 1.9934939759036146e-05,
      "loss": 0.0065,
      "step": 270
    },
    {
      "epoch": 0.033734939759036145,
      "grad_norm": 0.0074482872150838375,
      "learning_rate": 1.993253012048193e-05,
      "loss": 0.0058,
      "step": 280
    },
    {
      "epoch": 0.03493975903614458,
      "grad_norm": 0.7585814595222473,
      "learning_rate": 1.9930120481927712e-05,
      "loss": 0.0294,
      "step": 290
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 0.06359322369098663,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 0.0061,
      "step": 300
    },
    {
      "epoch": 0.03734939759036145,
      "grad_norm": 0.004707694984972477,
      "learning_rate": 1.992530120481928e-05,
      "loss": 0.0635,
      "step": 310
    },
    {
      "epoch": 0.03855421686746988,
      "grad_norm": 0.0016017653979361057,
      "learning_rate": 1.992289156626506e-05,
      "loss": 0.0051,
      "step": 320
    },
    {
      "epoch": 0.03975903614457831,
      "grad_norm": 0.46708497405052185,
      "learning_rate": 1.9920481927710845e-05,
      "loss": 0.0091,
      "step": 330
    },
    {
      "epoch": 0.04096385542168675,
      "grad_norm": 26.635879516601562,
      "learning_rate": 1.991807228915663e-05,
      "loss": 0.145,
      "step": 340
    },
    {
      "epoch": 0.04216867469879518,
      "grad_norm": 7.850912570953369,
      "learning_rate": 1.991566265060241e-05,
      "loss": 0.1098,
      "step": 350
    },
    {
      "epoch": 0.043373493975903614,
      "grad_norm": 9.188575744628906,
      "learning_rate": 1.9913253012048196e-05,
      "loss": 0.0788,
      "step": 360
    },
    {
      "epoch": 0.04457831325301205,
      "grad_norm": 0.014051390811800957,
      "learning_rate": 1.9910843373493977e-05,
      "loss": 0.0854,
      "step": 370
    },
    {
      "epoch": 0.04578313253012048,
      "grad_norm": 0.36130598187446594,
      "learning_rate": 1.990843373493976e-05,
      "loss": 0.0423,
      "step": 380
    },
    {
      "epoch": 0.046987951807228916,
      "grad_norm": 5.318009853363037,
      "learning_rate": 1.9906024096385544e-05,
      "loss": 0.0288,
      "step": 390
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 28.22545623779297,
      "learning_rate": 1.9903614457831325e-05,
      "loss": 0.0457,
      "step": 400
    },
    {
      "epoch": 0.04939759036144578,
      "grad_norm": 11.944011688232422,
      "learning_rate": 1.990120481927711e-05,
      "loss": 0.0938,
      "step": 410
    },
    {
      "epoch": 0.05060240963855422,
      "grad_norm": 22.22849464416504,
      "learning_rate": 1.9898795180722895e-05,
      "loss": 0.0228,
      "step": 420
    },
    {
      "epoch": 0.051807228915662654,
      "grad_norm": 0.007074194494634867,
      "learning_rate": 1.9896385542168677e-05,
      "loss": 0.0297,
      "step": 430
    },
    {
      "epoch": 0.05301204819277108,
      "grad_norm": 0.0755094587802887,
      "learning_rate": 1.989397590361446e-05,
      "loss": 0.0624,
      "step": 440
    },
    {
      "epoch": 0.05421686746987952,
      "grad_norm": 55.796119689941406,
      "learning_rate": 1.9891566265060243e-05,
      "loss": 0.0636,
      "step": 450
    },
    {
      "epoch": 0.05542168674698795,
      "grad_norm": 12.678533554077148,
      "learning_rate": 1.9889156626506024e-05,
      "loss": 0.071,
      "step": 460
    },
    {
      "epoch": 0.056626506024096385,
      "grad_norm": 0.317498117685318,
      "learning_rate": 1.988674698795181e-05,
      "loss": 0.0246,
      "step": 470
    },
    {
      "epoch": 0.05783132530120482,
      "grad_norm": 2.9365532398223877,
      "learning_rate": 1.988433734939759e-05,
      "loss": 0.0266,
      "step": 480
    },
    {
      "epoch": 0.05903614457831325,
      "grad_norm": 0.005419608671218157,
      "learning_rate": 1.9881927710843376e-05,
      "loss": 0.109,
      "step": 490
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 0.043715700507164,
      "learning_rate": 1.987951807228916e-05,
      "loss": 0.0428,
      "step": 500
    },
    {
      "epoch": 0.06144578313253012,
      "grad_norm": 7.1087822914123535,
      "learning_rate": 1.9877108433734942e-05,
      "loss": 0.1001,
      "step": 510
    },
    {
      "epoch": 0.06265060240963856,
      "grad_norm": 0.02074236236512661,
      "learning_rate": 1.9874698795180723e-05,
      "loss": 0.0475,
      "step": 520
    },
    {
      "epoch": 0.06385542168674699,
      "grad_norm": 0.8210789561271667,
      "learning_rate": 1.9872289156626508e-05,
      "loss": 0.0368,
      "step": 530
    },
    {
      "epoch": 0.06506024096385542,
      "grad_norm": 0.09984613209962845,
      "learning_rate": 1.986987951807229e-05,
      "loss": 0.0328,
      "step": 540
    },
    {
      "epoch": 0.06626506024096386,
      "grad_norm": 4.0261993408203125,
      "learning_rate": 1.9867469879518075e-05,
      "loss": 0.0554,
      "step": 550
    },
    {
      "epoch": 0.06746987951807229,
      "grad_norm": 17.398395538330078,
      "learning_rate": 1.9865060240963856e-05,
      "loss": 0.0908,
      "step": 560
    },
    {
      "epoch": 0.06867469879518072,
      "grad_norm": 0.13865847885608673,
      "learning_rate": 1.986265060240964e-05,
      "loss": 0.0496,
      "step": 570
    },
    {
      "epoch": 0.06987951807228916,
      "grad_norm": 3.1132614612579346,
      "learning_rate": 1.9860240963855422e-05,
      "loss": 0.0455,
      "step": 580
    },
    {
      "epoch": 0.07108433734939759,
      "grad_norm": 3.276750326156616,
      "learning_rate": 1.9857831325301207e-05,
      "loss": 0.0973,
      "step": 590
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 0.7493292093276978,
      "learning_rate": 1.985542168674699e-05,
      "loss": 0.0481,
      "step": 600
    },
    {
      "epoch": 0.07349397590361446,
      "grad_norm": 0.3226926922798157,
      "learning_rate": 1.9853012048192774e-05,
      "loss": 0.0498,
      "step": 610
    },
    {
      "epoch": 0.0746987951807229,
      "grad_norm": 6.337377071380615,
      "learning_rate": 1.9850602409638555e-05,
      "loss": 0.0533,
      "step": 620
    },
    {
      "epoch": 0.07590361445783132,
      "grad_norm": 2.4474291801452637,
      "learning_rate": 1.9848192771084337e-05,
      "loss": 0.0835,
      "step": 630
    },
    {
      "epoch": 0.07710843373493977,
      "grad_norm": 33.52765655517578,
      "learning_rate": 1.984578313253012e-05,
      "loss": 0.0447,
      "step": 640
    },
    {
      "epoch": 0.0783132530120482,
      "grad_norm": 2.038445472717285,
      "learning_rate": 1.9843373493975906e-05,
      "loss": 0.0138,
      "step": 650
    },
    {
      "epoch": 0.07951807228915662,
      "grad_norm": 18.47559356689453,
      "learning_rate": 1.9840963855421688e-05,
      "loss": 0.0312,
      "step": 660
    },
    {
      "epoch": 0.08072289156626505,
      "grad_norm": 2.2424378395080566,
      "learning_rate": 1.9838554216867473e-05,
      "loss": 0.0582,
      "step": 670
    },
    {
      "epoch": 0.0819277108433735,
      "grad_norm": 13.005438804626465,
      "learning_rate": 1.9836144578313254e-05,
      "loss": 0.0328,
      "step": 680
    },
    {
      "epoch": 0.08313253012048193,
      "grad_norm": 0.011155308224260807,
      "learning_rate": 1.9833734939759036e-05,
      "loss": 0.0656,
      "step": 690
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 22.83738136291504,
      "learning_rate": 1.983132530120482e-05,
      "loss": 0.0553,
      "step": 700
    },
    {
      "epoch": 0.0855421686746988,
      "grad_norm": 0.4474642872810364,
      "learning_rate": 1.9828915662650602e-05,
      "loss": 0.1193,
      "step": 710
    },
    {
      "epoch": 0.08674698795180723,
      "grad_norm": 7.08859920501709,
      "learning_rate": 1.9826506024096387e-05,
      "loss": 0.072,
      "step": 720
    },
    {
      "epoch": 0.08795180722891566,
      "grad_norm": 7.543206691741943,
      "learning_rate": 1.9824096385542172e-05,
      "loss": 0.0694,
      "step": 730
    },
    {
      "epoch": 0.0891566265060241,
      "grad_norm": 0.5647410154342651,
      "learning_rate": 1.9821686746987953e-05,
      "loss": 0.0535,
      "step": 740
    },
    {
      "epoch": 0.09036144578313253,
      "grad_norm": 0.8581933975219727,
      "learning_rate": 1.9819277108433738e-05,
      "loss": 0.0497,
      "step": 750
    },
    {
      "epoch": 0.09156626506024096,
      "grad_norm": 0.7215510606765747,
      "learning_rate": 1.981686746987952e-05,
      "loss": 0.0505,
      "step": 760
    },
    {
      "epoch": 0.0927710843373494,
      "grad_norm": 0.1041170284152031,
      "learning_rate": 1.98144578313253e-05,
      "loss": 0.1012,
      "step": 770
    },
    {
      "epoch": 0.09397590361445783,
      "grad_norm": 0.019397590309381485,
      "learning_rate": 1.9812048192771086e-05,
      "loss": 0.007,
      "step": 780
    },
    {
      "epoch": 0.09518072289156626,
      "grad_norm": 0.058294013142585754,
      "learning_rate": 1.980963855421687e-05,
      "loss": 0.0374,
      "step": 790
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 0.5805474519729614,
      "learning_rate": 1.9807228915662652e-05,
      "loss": 0.0361,
      "step": 800
    },
    {
      "epoch": 0.09759036144578313,
      "grad_norm": 0.015474368818104267,
      "learning_rate": 1.9804819277108437e-05,
      "loss": 0.0587,
      "step": 810
    },
    {
      "epoch": 0.09879518072289156,
      "grad_norm": 0.010961484163999557,
      "learning_rate": 1.980240963855422e-05,
      "loss": 0.022,
      "step": 820
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.006247297395020723,
      "learning_rate": 1.98e-05,
      "loss": 0.0485,
      "step": 830
    },
    {
      "epoch": 0.10120481927710843,
      "grad_norm": 17.58745765686035,
      "learning_rate": 1.9797590361445785e-05,
      "loss": 0.0653,
      "step": 840
    },
    {
      "epoch": 0.10240963855421686,
      "grad_norm": 42.989524841308594,
      "learning_rate": 1.9795180722891567e-05,
      "loss": 0.1326,
      "step": 850
    },
    {
      "epoch": 0.10361445783132531,
      "grad_norm": 6.957388401031494,
      "learning_rate": 1.979277108433735e-05,
      "loss": 0.0752,
      "step": 860
    },
    {
      "epoch": 0.10481927710843374,
      "grad_norm": 0.1331411600112915,
      "learning_rate": 1.9790361445783136e-05,
      "loss": 0.0484,
      "step": 870
    },
    {
      "epoch": 0.10602409638554217,
      "grad_norm": 1.4075957536697388,
      "learning_rate": 1.9787951807228918e-05,
      "loss": 0.0587,
      "step": 880
    },
    {
      "epoch": 0.10722891566265061,
      "grad_norm": 14.392932891845703,
      "learning_rate": 1.97855421686747e-05,
      "loss": 0.2104,
      "step": 890
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 4.744557857513428,
      "learning_rate": 1.9783132530120484e-05,
      "loss": 0.1112,
      "step": 900
    },
    {
      "epoch": 0.10963855421686747,
      "grad_norm": 0.04229762405157089,
      "learning_rate": 1.9780722891566266e-05,
      "loss": 0.0403,
      "step": 910
    },
    {
      "epoch": 0.1108433734939759,
      "grad_norm": 6.327059268951416,
      "learning_rate": 1.977831325301205e-05,
      "loss": 0.1444,
      "step": 920
    },
    {
      "epoch": 0.11204819277108434,
      "grad_norm": 0.8334522843360901,
      "learning_rate": 1.9775903614457832e-05,
      "loss": 0.0183,
      "step": 930
    },
    {
      "epoch": 0.11325301204819277,
      "grad_norm": 0.7617449760437012,
      "learning_rate": 1.9773493975903617e-05,
      "loss": 0.0474,
      "step": 940
    },
    {
      "epoch": 0.1144578313253012,
      "grad_norm": 0.07946079224348068,
      "learning_rate": 1.9771084337349398e-05,
      "loss": 0.1139,
      "step": 950
    },
    {
      "epoch": 0.11566265060240964,
      "grad_norm": 0.09466751664876938,
      "learning_rate": 1.9768674698795183e-05,
      "loss": 0.0755,
      "step": 960
    },
    {
      "epoch": 0.11686746987951807,
      "grad_norm": 2.419642448425293,
      "learning_rate": 1.9766265060240965e-05,
      "loss": 0.0375,
      "step": 970
    },
    {
      "epoch": 0.1180722891566265,
      "grad_norm": 41.67605972290039,
      "learning_rate": 1.976385542168675e-05,
      "loss": 0.0358,
      "step": 980
    },
    {
      "epoch": 0.11927710843373494,
      "grad_norm": 51.42661666870117,
      "learning_rate": 1.976144578313253e-05,
      "loss": 0.0553,
      "step": 990
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 4.484254360198975,
      "learning_rate": 1.9759036144578312e-05,
      "loss": 0.1255,
      "step": 1000
    },
    {
      "epoch": 0.1216867469879518,
      "grad_norm": 10.596835136413574,
      "learning_rate": 1.9756626506024097e-05,
      "loss": 0.135,
      "step": 1010
    },
    {
      "epoch": 0.12289156626506025,
      "grad_norm": 0.1985747218132019,
      "learning_rate": 1.9754216867469882e-05,
      "loss": 0.0394,
      "step": 1020
    },
    {
      "epoch": 0.12409638554216867,
      "grad_norm": 6.505924224853516,
      "learning_rate": 1.9751807228915664e-05,
      "loss": 0.1229,
      "step": 1030
    },
    {
      "epoch": 0.12530120481927712,
      "grad_norm": 0.7559118270874023,
      "learning_rate": 1.974939759036145e-05,
      "loss": 0.1129,
      "step": 1040
    },
    {
      "epoch": 0.12650602409638553,
      "grad_norm": 11.826333045959473,
      "learning_rate": 1.974698795180723e-05,
      "loss": 0.1628,
      "step": 1050
    },
    {
      "epoch": 0.12771084337349398,
      "grad_norm": 0.2794400453567505,
      "learning_rate": 1.9744578313253015e-05,
      "loss": 0.062,
      "step": 1060
    },
    {
      "epoch": 0.12891566265060242,
      "grad_norm": 1.570600986480713,
      "learning_rate": 1.9742168674698796e-05,
      "loss": 0.0583,
      "step": 1070
    },
    {
      "epoch": 0.13012048192771083,
      "grad_norm": 0.0860070139169693,
      "learning_rate": 1.9739759036144578e-05,
      "loss": 0.0189,
      "step": 1080
    },
    {
      "epoch": 0.13132530120481928,
      "grad_norm": 2.8905436992645264,
      "learning_rate": 1.9737349397590363e-05,
      "loss": 0.0919,
      "step": 1090
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 18.946260452270508,
      "learning_rate": 1.9734939759036148e-05,
      "loss": 0.136,
      "step": 1100
    },
    {
      "epoch": 0.13373493975903614,
      "grad_norm": 19.966007232666016,
      "learning_rate": 1.973253012048193e-05,
      "loss": 0.044,
      "step": 1110
    },
    {
      "epoch": 0.13493975903614458,
      "grad_norm": 2.245476722717285,
      "learning_rate": 1.9730120481927714e-05,
      "loss": 0.0698,
      "step": 1120
    },
    {
      "epoch": 0.13614457831325302,
      "grad_norm": 2.3837287425994873,
      "learning_rate": 1.9727710843373495e-05,
      "loss": 0.043,
      "step": 1130
    },
    {
      "epoch": 0.13734939759036144,
      "grad_norm": 0.17182104289531708,
      "learning_rate": 1.9725301204819277e-05,
      "loss": 0.0237,
      "step": 1140
    },
    {
      "epoch": 0.13855421686746988,
      "grad_norm": 1.0670537948608398,
      "learning_rate": 1.9722891566265062e-05,
      "loss": 0.0322,
      "step": 1150
    },
    {
      "epoch": 0.13975903614457832,
      "grad_norm": 0.02907044254243374,
      "learning_rate": 1.9720481927710843e-05,
      "loss": 0.0517,
      "step": 1160
    },
    {
      "epoch": 0.14096385542168674,
      "grad_norm": 1.7190665006637573,
      "learning_rate": 1.9718072289156628e-05,
      "loss": 0.1343,
      "step": 1170
    },
    {
      "epoch": 0.14216867469879518,
      "grad_norm": 9.018661499023438,
      "learning_rate": 1.9715662650602413e-05,
      "loss": 0.0382,
      "step": 1180
    },
    {
      "epoch": 0.14337349397590363,
      "grad_norm": 2.938389301300049,
      "learning_rate": 1.9713253012048194e-05,
      "loss": 0.0948,
      "step": 1190
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 1.8925257921218872,
      "learning_rate": 1.9710843373493976e-05,
      "loss": 0.0038,
      "step": 1200
    },
    {
      "epoch": 0.14578313253012049,
      "grad_norm": 0.20975381135940552,
      "learning_rate": 1.970843373493976e-05,
      "loss": 0.0603,
      "step": 1210
    },
    {
      "epoch": 0.14698795180722893,
      "grad_norm": 0.044527411460876465,
      "learning_rate": 1.9706024096385542e-05,
      "loss": 0.0585,
      "step": 1220
    },
    {
      "epoch": 0.14819277108433734,
      "grad_norm": 0.3229822814464569,
      "learning_rate": 1.9703614457831327e-05,
      "loss": 0.0326,
      "step": 1230
    },
    {
      "epoch": 0.1493975903614458,
      "grad_norm": 0.01851360872387886,
      "learning_rate": 1.9701204819277112e-05,
      "loss": 0.0765,
      "step": 1240
    },
    {
      "epoch": 0.15060240963855423,
      "grad_norm": 3.3234944343566895,
      "learning_rate": 1.9698795180722894e-05,
      "loss": 0.0473,
      "step": 1250
    },
    {
      "epoch": 0.15180722891566265,
      "grad_norm": 10.791415214538574,
      "learning_rate": 1.9696385542168675e-05,
      "loss": 0.0952,
      "step": 1260
    },
    {
      "epoch": 0.1530120481927711,
      "grad_norm": 5.171274185180664,
      "learning_rate": 1.969397590361446e-05,
      "loss": 0.1363,
      "step": 1270
    },
    {
      "epoch": 0.15421686746987953,
      "grad_norm": 2.326442241668701,
      "learning_rate": 1.969156626506024e-05,
      "loss": 0.1267,
      "step": 1280
    },
    {
      "epoch": 0.15542168674698795,
      "grad_norm": 0.04440613463521004,
      "learning_rate": 1.9689156626506026e-05,
      "loss": 0.0744,
      "step": 1290
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 0.5752750635147095,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 0.1191,
      "step": 1300
    },
    {
      "epoch": 0.1578313253012048,
      "grad_norm": 0.256570428609848,
      "learning_rate": 1.968433734939759e-05,
      "loss": 0.0125,
      "step": 1310
    },
    {
      "epoch": 0.15903614457831325,
      "grad_norm": 0.0916207805275917,
      "learning_rate": 1.9681927710843377e-05,
      "loss": 0.0362,
      "step": 1320
    },
    {
      "epoch": 0.1602409638554217,
      "grad_norm": 0.9271917939186096,
      "learning_rate": 1.967951807228916e-05,
      "loss": 0.0299,
      "step": 1330
    },
    {
      "epoch": 0.1614457831325301,
      "grad_norm": 0.15435464680194855,
      "learning_rate": 1.967710843373494e-05,
      "loss": 0.0444,
      "step": 1340
    },
    {
      "epoch": 0.16265060240963855,
      "grad_norm": 0.010555521585047245,
      "learning_rate": 1.9674698795180725e-05,
      "loss": 0.03,
      "step": 1350
    },
    {
      "epoch": 0.163855421686747,
      "grad_norm": 0.04475846141576767,
      "learning_rate": 1.9672289156626507e-05,
      "loss": 0.0908,
      "step": 1360
    },
    {
      "epoch": 0.1650602409638554,
      "grad_norm": 0.010265094228088856,
      "learning_rate": 1.966987951807229e-05,
      "loss": 0.092,
      "step": 1370
    },
    {
      "epoch": 0.16626506024096385,
      "grad_norm": 1.0001620054244995,
      "learning_rate": 1.9667469879518073e-05,
      "loss": 0.1791,
      "step": 1380
    },
    {
      "epoch": 0.1674698795180723,
      "grad_norm": 3.4080867767333984,
      "learning_rate": 1.9665060240963858e-05,
      "loss": 0.053,
      "step": 1390
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 3.674497604370117,
      "learning_rate": 1.966265060240964e-05,
      "loss": 0.0318,
      "step": 1400
    },
    {
      "epoch": 0.16987951807228915,
      "grad_norm": 28.751365661621094,
      "learning_rate": 1.9660240963855424e-05,
      "loss": 0.0867,
      "step": 1410
    },
    {
      "epoch": 0.1710843373493976,
      "grad_norm": 23.835988998413086,
      "learning_rate": 1.9657831325301206e-05,
      "loss": 0.1061,
      "step": 1420
    },
    {
      "epoch": 0.172289156626506,
      "grad_norm": 0.8412630558013916,
      "learning_rate": 1.965542168674699e-05,
      "loss": 0.0644,
      "step": 1430
    },
    {
      "epoch": 0.17349397590361446,
      "grad_norm": 0.03353562951087952,
      "learning_rate": 1.9653012048192772e-05,
      "loss": 0.077,
      "step": 1440
    },
    {
      "epoch": 0.1746987951807229,
      "grad_norm": 3.590996742248535,
      "learning_rate": 1.9650602409638554e-05,
      "loss": 0.0449,
      "step": 1450
    },
    {
      "epoch": 0.17590361445783131,
      "grad_norm": 0.04979826882481575,
      "learning_rate": 1.964819277108434e-05,
      "loss": 0.0323,
      "step": 1460
    },
    {
      "epoch": 0.17710843373493976,
      "grad_norm": 45.599021911621094,
      "learning_rate": 1.9645783132530123e-05,
      "loss": 0.065,
      "step": 1470
    },
    {
      "epoch": 0.1783132530120482,
      "grad_norm": 0.021048814058303833,
      "learning_rate": 1.9643373493975905e-05,
      "loss": 0.109,
      "step": 1480
    },
    {
      "epoch": 0.17951807228915662,
      "grad_norm": 0.17611099779605865,
      "learning_rate": 1.964096385542169e-05,
      "loss": 0.0693,
      "step": 1490
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 0.1483219861984253,
      "learning_rate": 1.963855421686747e-05,
      "loss": 0.0444,
      "step": 1500
    },
    {
      "epoch": 0.1819277108433735,
      "grad_norm": 0.08519861847162247,
      "learning_rate": 1.9636144578313253e-05,
      "loss": 0.0634,
      "step": 1510
    },
    {
      "epoch": 0.18313253012048192,
      "grad_norm": 0.027871085330843925,
      "learning_rate": 1.9633734939759038e-05,
      "loss": 0.1299,
      "step": 1520
    },
    {
      "epoch": 0.18433734939759036,
      "grad_norm": 0.6914747357368469,
      "learning_rate": 1.963132530120482e-05,
      "loss": 0.072,
      "step": 1530
    },
    {
      "epoch": 0.1855421686746988,
      "grad_norm": 18.45435905456543,
      "learning_rate": 1.9628915662650604e-05,
      "loss": 0.0943,
      "step": 1540
    },
    {
      "epoch": 0.18674698795180722,
      "grad_norm": 0.0664215236902237,
      "learning_rate": 1.962650602409639e-05,
      "loss": 0.0812,
      "step": 1550
    },
    {
      "epoch": 0.18795180722891566,
      "grad_norm": 0.059960268437862396,
      "learning_rate": 1.962409638554217e-05,
      "loss": 0.0562,
      "step": 1560
    },
    {
      "epoch": 0.1891566265060241,
      "grad_norm": 14.10126781463623,
      "learning_rate": 1.9621686746987955e-05,
      "loss": 0.1414,
      "step": 1570
    },
    {
      "epoch": 0.19036144578313252,
      "grad_norm": 6.279026031494141,
      "learning_rate": 1.9619277108433737e-05,
      "loss": 0.0678,
      "step": 1580
    },
    {
      "epoch": 0.19156626506024096,
      "grad_norm": 9.65520191192627,
      "learning_rate": 1.9616867469879518e-05,
      "loss": 0.0967,
      "step": 1590
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 0.6250571608543396,
      "learning_rate": 1.9614457831325303e-05,
      "loss": 0.0199,
      "step": 1600
    },
    {
      "epoch": 0.19397590361445782,
      "grad_norm": 0.12393807619810104,
      "learning_rate": 1.9612048192771085e-05,
      "loss": 0.0586,
      "step": 1610
    },
    {
      "epoch": 0.19518072289156627,
      "grad_norm": 4.5018720626831055,
      "learning_rate": 1.960963855421687e-05,
      "loss": 0.0244,
      "step": 1620
    },
    {
      "epoch": 0.1963855421686747,
      "grad_norm": 0.17959459125995636,
      "learning_rate": 1.9607228915662654e-05,
      "loss": 0.0315,
      "step": 1630
    },
    {
      "epoch": 0.19759036144578312,
      "grad_norm": 9.164306640625,
      "learning_rate": 1.9604819277108436e-05,
      "loss": 0.0415,
      "step": 1640
    },
    {
      "epoch": 0.19879518072289157,
      "grad_norm": 0.192024365067482,
      "learning_rate": 1.9602409638554217e-05,
      "loss": 0.0941,
      "step": 1650
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.05375034734606743,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0286,
      "step": 1660
    },
    {
      "epoch": 0.20120481927710843,
      "grad_norm": 0.25154125690460205,
      "learning_rate": 1.9597590361445784e-05,
      "loss": 0.1205,
      "step": 1670
    },
    {
      "epoch": 0.20240963855421687,
      "grad_norm": 0.05196891352534294,
      "learning_rate": 1.959518072289157e-05,
      "loss": 0.0414,
      "step": 1680
    },
    {
      "epoch": 0.2036144578313253,
      "grad_norm": 0.6411587595939636,
      "learning_rate": 1.9592771084337353e-05,
      "loss": 0.0661,
      "step": 1690
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 0.6062492728233337,
      "learning_rate": 1.9590361445783135e-05,
      "loss": 0.0869,
      "step": 1700
    },
    {
      "epoch": 0.20602409638554217,
      "grad_norm": 17.401424407958984,
      "learning_rate": 1.9587951807228916e-05,
      "loss": 0.1004,
      "step": 1710
    },
    {
      "epoch": 0.20722891566265061,
      "grad_norm": 0.09594041854143143,
      "learning_rate": 1.95855421686747e-05,
      "loss": 0.0296,
      "step": 1720
    },
    {
      "epoch": 0.20843373493975903,
      "grad_norm": 7.0362982749938965,
      "learning_rate": 1.9583132530120483e-05,
      "loss": 0.0797,
      "step": 1730
    },
    {
      "epoch": 0.20963855421686747,
      "grad_norm": 0.9552391171455383,
      "learning_rate": 1.9580722891566267e-05,
      "loss": 0.0392,
      "step": 1740
    },
    {
      "epoch": 0.21084337349397592,
      "grad_norm": 9.871099472045898,
      "learning_rate": 1.957831325301205e-05,
      "loss": 0.0312,
      "step": 1750
    },
    {
      "epoch": 0.21204819277108433,
      "grad_norm": 0.027031460776925087,
      "learning_rate": 1.957590361445783e-05,
      "loss": 0.0126,
      "step": 1760
    },
    {
      "epoch": 0.21325301204819277,
      "grad_norm": 0.06408663094043732,
      "learning_rate": 1.9573493975903615e-05,
      "loss": 0.0275,
      "step": 1770
    },
    {
      "epoch": 0.21445783132530122,
      "grad_norm": 0.0072606410831213,
      "learning_rate": 1.95710843373494e-05,
      "loss": 0.0285,
      "step": 1780
    },
    {
      "epoch": 0.21566265060240963,
      "grad_norm": 0.07741442322731018,
      "learning_rate": 1.956867469879518e-05,
      "loss": 0.035,
      "step": 1790
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 30.91686248779297,
      "learning_rate": 1.9566265060240967e-05,
      "loss": 0.0582,
      "step": 1800
    },
    {
      "epoch": 0.21807228915662652,
      "grad_norm": 0.08087003231048584,
      "learning_rate": 1.9563855421686748e-05,
      "loss": 0.0465,
      "step": 1810
    },
    {
      "epoch": 0.21927710843373494,
      "grad_norm": 12.091015815734863,
      "learning_rate": 1.956144578313253e-05,
      "loss": 0.05,
      "step": 1820
    },
    {
      "epoch": 0.22048192771084338,
      "grad_norm": 0.7296205163002014,
      "learning_rate": 1.9559036144578314e-05,
      "loss": 0.0396,
      "step": 1830
    },
    {
      "epoch": 0.2216867469879518,
      "grad_norm": 9.80526065826416,
      "learning_rate": 1.95566265060241e-05,
      "loss": 0.0468,
      "step": 1840
    },
    {
      "epoch": 0.22289156626506024,
      "grad_norm": 0.0868869200348854,
      "learning_rate": 1.955421686746988e-05,
      "loss": 0.0551,
      "step": 1850
    },
    {
      "epoch": 0.22409638554216868,
      "grad_norm": 6.399654865264893,
      "learning_rate": 1.9551807228915666e-05,
      "loss": 0.0434,
      "step": 1860
    },
    {
      "epoch": 0.2253012048192771,
      "grad_norm": 0.8132861256599426,
      "learning_rate": 1.9549397590361447e-05,
      "loss": 0.0363,
      "step": 1870
    },
    {
      "epoch": 0.22650602409638554,
      "grad_norm": 18.104476928710938,
      "learning_rate": 1.9546987951807232e-05,
      "loss": 0.1037,
      "step": 1880
    },
    {
      "epoch": 0.22771084337349398,
      "grad_norm": 1.0855915546417236,
      "learning_rate": 1.9544578313253013e-05,
      "loss": 0.0421,
      "step": 1890
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 0.6247907876968384,
      "learning_rate": 1.9542168674698795e-05,
      "loss": 0.054,
      "step": 1900
    },
    {
      "epoch": 0.23012048192771084,
      "grad_norm": 8.35359001159668,
      "learning_rate": 1.953975903614458e-05,
      "loss": 0.0787,
      "step": 1910
    },
    {
      "epoch": 0.23132530120481928,
      "grad_norm": 59.44721984863281,
      "learning_rate": 1.9537349397590365e-05,
      "loss": 0.0718,
      "step": 1920
    },
    {
      "epoch": 0.2325301204819277,
      "grad_norm": 2.6557910442352295,
      "learning_rate": 1.9534939759036146e-05,
      "loss": 0.0944,
      "step": 1930
    },
    {
      "epoch": 0.23373493975903614,
      "grad_norm": 0.2149408608675003,
      "learning_rate": 1.953253012048193e-05,
      "loss": 0.0528,
      "step": 1940
    },
    {
      "epoch": 0.23493975903614459,
      "grad_norm": 9.305922508239746,
      "learning_rate": 1.9530120481927712e-05,
      "loss": 0.0916,
      "step": 1950
    },
    {
      "epoch": 0.236144578313253,
      "grad_norm": 0.7099151015281677,
      "learning_rate": 1.9527710843373494e-05,
      "loss": 0.0598,
      "step": 1960
    },
    {
      "epoch": 0.23734939759036144,
      "grad_norm": 3.706789016723633,
      "learning_rate": 1.952530120481928e-05,
      "loss": 0.019,
      "step": 1970
    },
    {
      "epoch": 0.2385542168674699,
      "grad_norm": 0.687386691570282,
      "learning_rate": 1.952289156626506e-05,
      "loss": 0.0538,
      "step": 1980
    },
    {
      "epoch": 0.2397590361445783,
      "grad_norm": 13.03518009185791,
      "learning_rate": 1.9520481927710845e-05,
      "loss": 0.0985,
      "step": 1990
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 1.6361353397369385,
      "learning_rate": 1.951807228915663e-05,
      "loss": 0.045,
      "step": 2000
    },
    {
      "epoch": 0.2421686746987952,
      "grad_norm": 4.651998996734619,
      "learning_rate": 1.951566265060241e-05,
      "loss": 0.0854,
      "step": 2010
    },
    {
      "epoch": 0.2433734939759036,
      "grad_norm": 0.07954512536525726,
      "learning_rate": 1.9513253012048193e-05,
      "loss": 0.049,
      "step": 2020
    },
    {
      "epoch": 0.24457831325301205,
      "grad_norm": 0.015021570026874542,
      "learning_rate": 1.9510843373493978e-05,
      "loss": 0.0257,
      "step": 2030
    },
    {
      "epoch": 0.2457831325301205,
      "grad_norm": 0.04816645011305809,
      "learning_rate": 1.950843373493976e-05,
      "loss": 0.0911,
      "step": 2040
    },
    {
      "epoch": 0.2469879518072289,
      "grad_norm": 6.329817295074463,
      "learning_rate": 1.9506024096385544e-05,
      "loss": 0.0919,
      "step": 2050
    },
    {
      "epoch": 0.24819277108433735,
      "grad_norm": 0.04794050753116608,
      "learning_rate": 1.9503614457831326e-05,
      "loss": 0.1084,
      "step": 2060
    },
    {
      "epoch": 0.2493975903614458,
      "grad_norm": 0.022428082302212715,
      "learning_rate": 1.950120481927711e-05,
      "loss": 0.0915,
      "step": 2070
    },
    {
      "epoch": 0.25060240963855424,
      "grad_norm": 19.930700302124023,
      "learning_rate": 1.9498795180722892e-05,
      "loss": 0.1384,
      "step": 2080
    },
    {
      "epoch": 0.25180722891566265,
      "grad_norm": 0.0790543407201767,
      "learning_rate": 1.9496385542168677e-05,
      "loss": 0.0817,
      "step": 2090
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 0.0822211503982544,
      "learning_rate": 1.949397590361446e-05,
      "loss": 0.0765,
      "step": 2100
    },
    {
      "epoch": 0.25421686746987954,
      "grad_norm": 1.1543227434158325,
      "learning_rate": 1.9491566265060243e-05,
      "loss": 0.0815,
      "step": 2110
    },
    {
      "epoch": 0.25542168674698795,
      "grad_norm": 0.29254257678985596,
      "learning_rate": 1.9489156626506025e-05,
      "loss": 0.0157,
      "step": 2120
    },
    {
      "epoch": 0.25662650602409637,
      "grad_norm": 12.748311042785645,
      "learning_rate": 1.9486746987951806e-05,
      "loss": 0.1135,
      "step": 2130
    },
    {
      "epoch": 0.25783132530120484,
      "grad_norm": 11.355597496032715,
      "learning_rate": 1.9484337349397595e-05,
      "loss": 0.0527,
      "step": 2140
    },
    {
      "epoch": 0.25903614457831325,
      "grad_norm": 0.13509488105773926,
      "learning_rate": 1.9481927710843376e-05,
      "loss": 0.1005,
      "step": 2150
    },
    {
      "epoch": 0.26024096385542167,
      "grad_norm": 24.653648376464844,
      "learning_rate": 1.9479518072289157e-05,
      "loss": 0.1095,
      "step": 2160
    },
    {
      "epoch": 0.26144578313253014,
      "grad_norm": 19.686017990112305,
      "learning_rate": 1.9477108433734942e-05,
      "loss": 0.073,
      "step": 2170
    },
    {
      "epoch": 0.26265060240963856,
      "grad_norm": 24.2109375,
      "learning_rate": 1.9474698795180724e-05,
      "loss": 0.0918,
      "step": 2180
    },
    {
      "epoch": 0.26385542168674697,
      "grad_norm": 7.45470666885376,
      "learning_rate": 1.947228915662651e-05,
      "loss": 0.13,
      "step": 2190
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 0.7977562546730042,
      "learning_rate": 1.946987951807229e-05,
      "loss": 0.024,
      "step": 2200
    },
    {
      "epoch": 0.26626506024096386,
      "grad_norm": 1.1153022050857544,
      "learning_rate": 1.9467469879518075e-05,
      "loss": 0.0707,
      "step": 2210
    },
    {
      "epoch": 0.2674698795180723,
      "grad_norm": 2.8978917598724365,
      "learning_rate": 1.9465060240963857e-05,
      "loss": 0.1052,
      "step": 2220
    },
    {
      "epoch": 0.26867469879518074,
      "grad_norm": 5.564830303192139,
      "learning_rate": 1.946265060240964e-05,
      "loss": 0.0923,
      "step": 2230
    },
    {
      "epoch": 0.26987951807228916,
      "grad_norm": 3.7806015014648438,
      "learning_rate": 1.9460240963855423e-05,
      "loss": 0.1343,
      "step": 2240
    },
    {
      "epoch": 0.2710843373493976,
      "grad_norm": 0.49034926295280457,
      "learning_rate": 1.9457831325301208e-05,
      "loss": 0.0402,
      "step": 2250
    },
    {
      "epoch": 0.27228915662650605,
      "grad_norm": 11.838278770446777,
      "learning_rate": 1.945542168674699e-05,
      "loss": 0.0619,
      "step": 2260
    },
    {
      "epoch": 0.27349397590361446,
      "grad_norm": 38.11509323120117,
      "learning_rate": 1.945301204819277e-05,
      "loss": 0.0969,
      "step": 2270
    },
    {
      "epoch": 0.2746987951807229,
      "grad_norm": 0.44659167528152466,
      "learning_rate": 1.9450602409638556e-05,
      "loss": 0.084,
      "step": 2280
    },
    {
      "epoch": 0.27590361445783135,
      "grad_norm": 0.016055230051279068,
      "learning_rate": 1.944819277108434e-05,
      "loss": 0.0306,
      "step": 2290
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 8.026139259338379,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 0.1109,
      "step": 2300
    },
    {
      "epoch": 0.2783132530120482,
      "grad_norm": 18.251386642456055,
      "learning_rate": 1.9443373493975907e-05,
      "loss": 0.1012,
      "step": 2310
    },
    {
      "epoch": 0.27951807228915665,
      "grad_norm": 14.92487621307373,
      "learning_rate": 1.944096385542169e-05,
      "loss": 0.1149,
      "step": 2320
    },
    {
      "epoch": 0.28072289156626506,
      "grad_norm": 2.05462908744812,
      "learning_rate": 1.943855421686747e-05,
      "loss": 0.0945,
      "step": 2330
    },
    {
      "epoch": 0.2819277108433735,
      "grad_norm": 2.2596943378448486,
      "learning_rate": 1.9436144578313255e-05,
      "loss": 0.0968,
      "step": 2340
    },
    {
      "epoch": 0.28313253012048195,
      "grad_norm": 0.09227266162633896,
      "learning_rate": 1.9433734939759036e-05,
      "loss": 0.0705,
      "step": 2350
    },
    {
      "epoch": 0.28433734939759037,
      "grad_norm": 35.68656539916992,
      "learning_rate": 1.943132530120482e-05,
      "loss": 0.0584,
      "step": 2360
    },
    {
      "epoch": 0.2855421686746988,
      "grad_norm": 1.8721191883087158,
      "learning_rate": 1.9428915662650606e-05,
      "loss": 0.115,
      "step": 2370
    },
    {
      "epoch": 0.28674698795180725,
      "grad_norm": 0.3699067533016205,
      "learning_rate": 1.9426506024096387e-05,
      "loss": 0.0976,
      "step": 2380
    },
    {
      "epoch": 0.28795180722891567,
      "grad_norm": 0.09341226518154144,
      "learning_rate": 1.942409638554217e-05,
      "loss": 0.0735,
      "step": 2390
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 0.015895506367087364,
      "learning_rate": 1.9421686746987954e-05,
      "loss": 0.1011,
      "step": 2400
    },
    {
      "epoch": 0.29036144578313255,
      "grad_norm": 10.368722915649414,
      "learning_rate": 1.9419277108433735e-05,
      "loss": 0.0555,
      "step": 2410
    },
    {
      "epoch": 0.29156626506024097,
      "grad_norm": 6.869401454925537,
      "learning_rate": 1.941686746987952e-05,
      "loss": 0.0971,
      "step": 2420
    },
    {
      "epoch": 0.2927710843373494,
      "grad_norm": 0.2935580015182495,
      "learning_rate": 1.94144578313253e-05,
      "loss": 0.093,
      "step": 2430
    },
    {
      "epoch": 0.29397590361445786,
      "grad_norm": 0.4656560719013214,
      "learning_rate": 1.9412048192771086e-05,
      "loss": 0.0732,
      "step": 2440
    },
    {
      "epoch": 0.29518072289156627,
      "grad_norm": 0.09323760122060776,
      "learning_rate": 1.940963855421687e-05,
      "loss": 0.0198,
      "step": 2450
    },
    {
      "epoch": 0.2963855421686747,
      "grad_norm": 0.6083870530128479,
      "learning_rate": 1.9407228915662653e-05,
      "loss": 0.0557,
      "step": 2460
    },
    {
      "epoch": 0.29759036144578316,
      "grad_norm": 12.325492858886719,
      "learning_rate": 1.9404819277108434e-05,
      "loss": 0.0152,
      "step": 2470
    },
    {
      "epoch": 0.2987951807228916,
      "grad_norm": 0.6983661651611328,
      "learning_rate": 1.940240963855422e-05,
      "loss": 0.0955,
      "step": 2480
    },
    {
      "epoch": 0.3,
      "grad_norm": 14.107294082641602,
      "learning_rate": 1.94e-05,
      "loss": 0.1324,
      "step": 2490
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 2.3867876529693604,
      "learning_rate": 1.9397590361445785e-05,
      "loss": 0.0539,
      "step": 2500
    },
    {
      "epoch": 0.3024096385542169,
      "grad_norm": 0.9969824552536011,
      "learning_rate": 1.939518072289157e-05,
      "loss": 0.0492,
      "step": 2510
    },
    {
      "epoch": 0.3036144578313253,
      "grad_norm": 0.08446008712053299,
      "learning_rate": 1.9392771084337352e-05,
      "loss": 0.0338,
      "step": 2520
    },
    {
      "epoch": 0.30481927710843376,
      "grad_norm": 0.2304878979921341,
      "learning_rate": 1.9390361445783133e-05,
      "loss": 0.1223,
      "step": 2530
    },
    {
      "epoch": 0.3060240963855422,
      "grad_norm": 5.4718427658081055,
      "learning_rate": 1.9387951807228918e-05,
      "loss": 0.0915,
      "step": 2540
    },
    {
      "epoch": 0.3072289156626506,
      "grad_norm": 0.70661461353302,
      "learning_rate": 1.93855421686747e-05,
      "loss": 0.0452,
      "step": 2550
    },
    {
      "epoch": 0.30843373493975906,
      "grad_norm": 13.03199291229248,
      "learning_rate": 1.9383132530120485e-05,
      "loss": 0.0288,
      "step": 2560
    },
    {
      "epoch": 0.3096385542168675,
      "grad_norm": 0.13020168244838715,
      "learning_rate": 1.9380722891566266e-05,
      "loss": 0.0418,
      "step": 2570
    },
    {
      "epoch": 0.3108433734939759,
      "grad_norm": 0.06090359389781952,
      "learning_rate": 1.9378313253012047e-05,
      "loss": 0.0588,
      "step": 2580
    },
    {
      "epoch": 0.31204819277108437,
      "grad_norm": 2.4777090549468994,
      "learning_rate": 1.9375903614457832e-05,
      "loss": 0.1577,
      "step": 2590
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 0.11776229739189148,
      "learning_rate": 1.9373493975903617e-05,
      "loss": 0.0788,
      "step": 2600
    },
    {
      "epoch": 0.3144578313253012,
      "grad_norm": 7.344180583953857,
      "learning_rate": 1.93710843373494e-05,
      "loss": 0.0555,
      "step": 2610
    },
    {
      "epoch": 0.3156626506024096,
      "grad_norm": 0.12266907840967178,
      "learning_rate": 1.9368674698795184e-05,
      "loss": 0.0673,
      "step": 2620
    },
    {
      "epoch": 0.3168674698795181,
      "grad_norm": 17.371809005737305,
      "learning_rate": 1.9366265060240965e-05,
      "loss": 0.1142,
      "step": 2630
    },
    {
      "epoch": 0.3180722891566265,
      "grad_norm": 1.2411741018295288,
      "learning_rate": 1.9363855421686747e-05,
      "loss": 0.0906,
      "step": 2640
    },
    {
      "epoch": 0.3192771084337349,
      "grad_norm": 2.156848669052124,
      "learning_rate": 1.936144578313253e-05,
      "loss": 0.0498,
      "step": 2650
    },
    {
      "epoch": 0.3204819277108434,
      "grad_norm": 5.38276481628418,
      "learning_rate": 1.9359036144578316e-05,
      "loss": 0.0585,
      "step": 2660
    },
    {
      "epoch": 0.3216867469879518,
      "grad_norm": 10.266105651855469,
      "learning_rate": 1.9356626506024098e-05,
      "loss": 0.1254,
      "step": 2670
    },
    {
      "epoch": 0.3228915662650602,
      "grad_norm": 0.15787212550640106,
      "learning_rate": 1.9354216867469883e-05,
      "loss": 0.0339,
      "step": 2680
    },
    {
      "epoch": 0.3240963855421687,
      "grad_norm": 21.5075626373291,
      "learning_rate": 1.9351807228915664e-05,
      "loss": 0.0664,
      "step": 2690
    },
    {
      "epoch": 0.3253012048192771,
      "grad_norm": 0.5040901899337769,
      "learning_rate": 1.9349397590361446e-05,
      "loss": 0.1128,
      "step": 2700
    },
    {
      "epoch": 0.3265060240963855,
      "grad_norm": 0.06470294296741486,
      "learning_rate": 1.934698795180723e-05,
      "loss": 0.0797,
      "step": 2710
    },
    {
      "epoch": 0.327710843373494,
      "grad_norm": 0.28448572754859924,
      "learning_rate": 1.9344578313253012e-05,
      "loss": 0.0262,
      "step": 2720
    },
    {
      "epoch": 0.3289156626506024,
      "grad_norm": 0.07168038189411163,
      "learning_rate": 1.9342168674698797e-05,
      "loss": 0.1184,
      "step": 2730
    },
    {
      "epoch": 0.3301204819277108,
      "grad_norm": 1.1658515930175781,
      "learning_rate": 1.9339759036144582e-05,
      "loss": 0.0621,
      "step": 2740
    },
    {
      "epoch": 0.3313253012048193,
      "grad_norm": 14.079418182373047,
      "learning_rate": 1.9337349397590363e-05,
      "loss": 0.0634,
      "step": 2750
    },
    {
      "epoch": 0.3325301204819277,
      "grad_norm": 0.09638035297393799,
      "learning_rate": 1.9334939759036148e-05,
      "loss": 0.0263,
      "step": 2760
    },
    {
      "epoch": 0.3337349397590361,
      "grad_norm": 29.89488983154297,
      "learning_rate": 1.933253012048193e-05,
      "loss": 0.0378,
      "step": 2770
    },
    {
      "epoch": 0.3349397590361446,
      "grad_norm": 1.9333770275115967,
      "learning_rate": 1.933012048192771e-05,
      "loss": 0.075,
      "step": 2780
    },
    {
      "epoch": 0.336144578313253,
      "grad_norm": 29.623619079589844,
      "learning_rate": 1.9327710843373496e-05,
      "loss": 0.0206,
      "step": 2790
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 56.98529052734375,
      "learning_rate": 1.9325301204819277e-05,
      "loss": 0.0516,
      "step": 2800
    },
    {
      "epoch": 0.3385542168674699,
      "grad_norm": 23.007204055786133,
      "learning_rate": 1.9322891566265062e-05,
      "loss": 0.121,
      "step": 2810
    },
    {
      "epoch": 0.3397590361445783,
      "grad_norm": 0.018138807266950607,
      "learning_rate": 1.9320481927710847e-05,
      "loss": 0.048,
      "step": 2820
    },
    {
      "epoch": 0.3409638554216867,
      "grad_norm": 42.50257110595703,
      "learning_rate": 1.931807228915663e-05,
      "loss": 0.1031,
      "step": 2830
    },
    {
      "epoch": 0.3421686746987952,
      "grad_norm": 8.78053092956543,
      "learning_rate": 1.931566265060241e-05,
      "loss": 0.1127,
      "step": 2840
    },
    {
      "epoch": 0.3433734939759036,
      "grad_norm": 0.05523684620857239,
      "learning_rate": 1.9313253012048195e-05,
      "loss": 0.0794,
      "step": 2850
    },
    {
      "epoch": 0.344578313253012,
      "grad_norm": 19.66023063659668,
      "learning_rate": 1.9310843373493976e-05,
      "loss": 0.0578,
      "step": 2860
    },
    {
      "epoch": 0.3457831325301205,
      "grad_norm": 0.03415500000119209,
      "learning_rate": 1.930843373493976e-05,
      "loss": 0.0711,
      "step": 2870
    },
    {
      "epoch": 0.3469879518072289,
      "grad_norm": 10.644222259521484,
      "learning_rate": 1.9306024096385543e-05,
      "loss": 0.0504,
      "step": 2880
    },
    {
      "epoch": 0.3481927710843373,
      "grad_norm": 32.10071563720703,
      "learning_rate": 1.9303614457831328e-05,
      "loss": 0.0869,
      "step": 2890
    },
    {
      "epoch": 0.3493975903614458,
      "grad_norm": 3.6118686199188232,
      "learning_rate": 1.930120481927711e-05,
      "loss": 0.064,
      "step": 2900
    },
    {
      "epoch": 0.3506024096385542,
      "grad_norm": 3.185777425765991,
      "learning_rate": 1.9298795180722894e-05,
      "loss": 0.0606,
      "step": 2910
    },
    {
      "epoch": 0.35180722891566263,
      "grad_norm": 0.2904292345046997,
      "learning_rate": 1.9296385542168675e-05,
      "loss": 0.0949,
      "step": 2920
    },
    {
      "epoch": 0.3530120481927711,
      "grad_norm": 28.004207611083984,
      "learning_rate": 1.929397590361446e-05,
      "loss": 0.0572,
      "step": 2930
    },
    {
      "epoch": 0.3542168674698795,
      "grad_norm": 0.04987732693552971,
      "learning_rate": 1.9291566265060242e-05,
      "loss": 0.0547,
      "step": 2940
    },
    {
      "epoch": 0.35542168674698793,
      "grad_norm": 2.571103811264038,
      "learning_rate": 1.9289156626506023e-05,
      "loss": 0.0768,
      "step": 2950
    },
    {
      "epoch": 0.3566265060240964,
      "grad_norm": 0.025062745437026024,
      "learning_rate": 1.928674698795181e-05,
      "loss": 0.1256,
      "step": 2960
    },
    {
      "epoch": 0.3578313253012048,
      "grad_norm": 13.96843147277832,
      "learning_rate": 1.9284337349397593e-05,
      "loss": 0.1338,
      "step": 2970
    },
    {
      "epoch": 0.35903614457831323,
      "grad_norm": 1.2234967947006226,
      "learning_rate": 1.9281927710843375e-05,
      "loss": 0.0319,
      "step": 2980
    },
    {
      "epoch": 0.3602409638554217,
      "grad_norm": 0.16402652859687805,
      "learning_rate": 1.927951807228916e-05,
      "loss": 0.0524,
      "step": 2990
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 10.788106918334961,
      "learning_rate": 1.927710843373494e-05,
      "loss": 0.0181,
      "step": 3000
    },
    {
      "epoch": 0.36265060240963853,
      "grad_norm": 4.26856803894043,
      "learning_rate": 1.9274698795180726e-05,
      "loss": 0.0902,
      "step": 3010
    },
    {
      "epoch": 0.363855421686747,
      "grad_norm": 0.09854338318109512,
      "learning_rate": 1.9272289156626507e-05,
      "loss": 0.0465,
      "step": 3020
    },
    {
      "epoch": 0.3650602409638554,
      "grad_norm": 33.16463088989258,
      "learning_rate": 1.926987951807229e-05,
      "loss": 0.0586,
      "step": 3030
    },
    {
      "epoch": 0.36626506024096384,
      "grad_norm": 3.102067708969116,
      "learning_rate": 1.9267469879518074e-05,
      "loss": 0.0357,
      "step": 3040
    },
    {
      "epoch": 0.3674698795180723,
      "grad_norm": 0.11630212515592575,
      "learning_rate": 1.926506024096386e-05,
      "loss": 0.0638,
      "step": 3050
    },
    {
      "epoch": 0.3686746987951807,
      "grad_norm": 4.354757308959961,
      "learning_rate": 1.926265060240964e-05,
      "loss": 0.1311,
      "step": 3060
    },
    {
      "epoch": 0.36987951807228914,
      "grad_norm": 0.9316901564598083,
      "learning_rate": 1.9260240963855425e-05,
      "loss": 0.0428,
      "step": 3070
    },
    {
      "epoch": 0.3710843373493976,
      "grad_norm": 1.8961385488510132,
      "learning_rate": 1.9257831325301206e-05,
      "loss": 0.085,
      "step": 3080
    },
    {
      "epoch": 0.372289156626506,
      "grad_norm": 0.17034417390823364,
      "learning_rate": 1.9255421686746988e-05,
      "loss": 0.0289,
      "step": 3090
    },
    {
      "epoch": 0.37349397590361444,
      "grad_norm": 2.044316053390503,
      "learning_rate": 1.9253012048192773e-05,
      "loss": 0.1155,
      "step": 3100
    },
    {
      "epoch": 0.3746987951807229,
      "grad_norm": 0.029034608975052834,
      "learning_rate": 1.9250602409638558e-05,
      "loss": 0.0792,
      "step": 3110
    },
    {
      "epoch": 0.3759036144578313,
      "grad_norm": 1.3428531885147095,
      "learning_rate": 1.924819277108434e-05,
      "loss": 0.0553,
      "step": 3120
    },
    {
      "epoch": 0.37710843373493974,
      "grad_norm": 1.7399693727493286,
      "learning_rate": 1.9245783132530124e-05,
      "loss": 0.0682,
      "step": 3130
    },
    {
      "epoch": 0.3783132530120482,
      "grad_norm": 6.204606533050537,
      "learning_rate": 1.9243373493975905e-05,
      "loss": 0.0528,
      "step": 3140
    },
    {
      "epoch": 0.3795180722891566,
      "grad_norm": 0.044480353593826294,
      "learning_rate": 1.9240963855421687e-05,
      "loss": 0.011,
      "step": 3150
    },
    {
      "epoch": 0.38072289156626504,
      "grad_norm": 0.44878023862838745,
      "learning_rate": 1.9238554216867472e-05,
      "loss": 0.1086,
      "step": 3160
    },
    {
      "epoch": 0.3819277108433735,
      "grad_norm": 0.03926319628953934,
      "learning_rate": 1.9236144578313253e-05,
      "loss": 0.0756,
      "step": 3170
    },
    {
      "epoch": 0.38313253012048193,
      "grad_norm": 0.5672562122344971,
      "learning_rate": 1.9233734939759038e-05,
      "loss": 0.0893,
      "step": 3180
    },
    {
      "epoch": 0.38433734939759034,
      "grad_norm": 0.18316397070884705,
      "learning_rate": 1.9231325301204823e-05,
      "loss": 0.0387,
      "step": 3190
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 0.6828485131263733,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 0.0659,
      "step": 3200
    },
    {
      "epoch": 0.38674698795180723,
      "grad_norm": 0.9455665946006775,
      "learning_rate": 1.9226506024096386e-05,
      "loss": 0.0343,
      "step": 3210
    },
    {
      "epoch": 0.38795180722891565,
      "grad_norm": 0.030247915536165237,
      "learning_rate": 1.922409638554217e-05,
      "loss": 0.0563,
      "step": 3220
    },
    {
      "epoch": 0.3891566265060241,
      "grad_norm": 0.31866776943206787,
      "learning_rate": 1.9221686746987952e-05,
      "loss": 0.0762,
      "step": 3230
    },
    {
      "epoch": 0.39036144578313253,
      "grad_norm": 46.058895111083984,
      "learning_rate": 1.9219277108433737e-05,
      "loss": 0.0612,
      "step": 3240
    },
    {
      "epoch": 0.39156626506024095,
      "grad_norm": 0.15311360359191895,
      "learning_rate": 1.921686746987952e-05,
      "loss": 0.1044,
      "step": 3250
    },
    {
      "epoch": 0.3927710843373494,
      "grad_norm": 6.229424953460693,
      "learning_rate": 1.9214457831325303e-05,
      "loss": 0.0584,
      "step": 3260
    },
    {
      "epoch": 0.39397590361445783,
      "grad_norm": 3.0180249214172363,
      "learning_rate": 1.921204819277109e-05,
      "loss": 0.04,
      "step": 3270
    },
    {
      "epoch": 0.39518072289156625,
      "grad_norm": 0.06735216826200485,
      "learning_rate": 1.920963855421687e-05,
      "loss": 0.0697,
      "step": 3280
    },
    {
      "epoch": 0.3963855421686747,
      "grad_norm": 18.693397521972656,
      "learning_rate": 1.920722891566265e-05,
      "loss": 0.0797,
      "step": 3290
    },
    {
      "epoch": 0.39759036144578314,
      "grad_norm": 0.01821775920689106,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 0.0353,
      "step": 3300
    },
    {
      "epoch": 0.39879518072289155,
      "grad_norm": 0.11005064845085144,
      "learning_rate": 1.9202409638554218e-05,
      "loss": 0.0365,
      "step": 3310
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.850198268890381,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.1419,
      "step": 3320
    },
    {
      "epoch": 0.40120481927710844,
      "grad_norm": 2.0876877307891846,
      "learning_rate": 1.9197590361445784e-05,
      "loss": 0.0725,
      "step": 3330
    },
    {
      "epoch": 0.40240963855421685,
      "grad_norm": 4.424130439758301,
      "learning_rate": 1.919518072289157e-05,
      "loss": 0.0738,
      "step": 3340
    },
    {
      "epoch": 0.4036144578313253,
      "grad_norm": 26.874841690063477,
      "learning_rate": 1.919277108433735e-05,
      "loss": 0.1079,
      "step": 3350
    },
    {
      "epoch": 0.40481927710843374,
      "grad_norm": 5.361222267150879,
      "learning_rate": 1.9190361445783135e-05,
      "loss": 0.1506,
      "step": 3360
    },
    {
      "epoch": 0.40602409638554215,
      "grad_norm": 3.05513596534729,
      "learning_rate": 1.9187951807228917e-05,
      "loss": 0.0428,
      "step": 3370
    },
    {
      "epoch": 0.4072289156626506,
      "grad_norm": 18.30824089050293,
      "learning_rate": 1.91855421686747e-05,
      "loss": 0.0273,
      "step": 3380
    },
    {
      "epoch": 0.40843373493975904,
      "grad_norm": 0.05726975202560425,
      "learning_rate": 1.9183132530120483e-05,
      "loss": 0.0873,
      "step": 3390
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 3.922478675842285,
      "learning_rate": 1.9180722891566265e-05,
      "loss": 0.0654,
      "step": 3400
    },
    {
      "epoch": 0.4108433734939759,
      "grad_norm": 2.8870530128479004,
      "learning_rate": 1.917831325301205e-05,
      "loss": 0.0865,
      "step": 3410
    },
    {
      "epoch": 0.41204819277108434,
      "grad_norm": 0.7010897994041443,
      "learning_rate": 1.9175903614457834e-05,
      "loss": 0.0563,
      "step": 3420
    },
    {
      "epoch": 0.41325301204819276,
      "grad_norm": 7.141938209533691,
      "learning_rate": 1.9173493975903616e-05,
      "loss": 0.1125,
      "step": 3430
    },
    {
      "epoch": 0.41445783132530123,
      "grad_norm": 0.6542326211929321,
      "learning_rate": 1.91710843373494e-05,
      "loss": 0.0275,
      "step": 3440
    },
    {
      "epoch": 0.41566265060240964,
      "grad_norm": 3.7384302616119385,
      "learning_rate": 1.9168674698795182e-05,
      "loss": 0.0456,
      "step": 3450
    },
    {
      "epoch": 0.41686746987951806,
      "grad_norm": 3.3463399410247803,
      "learning_rate": 1.9166265060240964e-05,
      "loss": 0.0594,
      "step": 3460
    },
    {
      "epoch": 0.41807228915662653,
      "grad_norm": 1.2292677164077759,
      "learning_rate": 1.916385542168675e-05,
      "loss": 0.1012,
      "step": 3470
    },
    {
      "epoch": 0.41927710843373495,
      "grad_norm": 0.365243524312973,
      "learning_rate": 1.916144578313253e-05,
      "loss": 0.0847,
      "step": 3480
    },
    {
      "epoch": 0.42048192771084336,
      "grad_norm": 0.30894431471824646,
      "learning_rate": 1.9159036144578315e-05,
      "loss": 0.0551,
      "step": 3490
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 11.95938491821289,
      "learning_rate": 1.91566265060241e-05,
      "loss": 0.1016,
      "step": 3500
    },
    {
      "epoch": 0.42289156626506025,
      "grad_norm": 5.1232380867004395,
      "learning_rate": 1.915421686746988e-05,
      "loss": 0.036,
      "step": 3510
    },
    {
      "epoch": 0.42409638554216866,
      "grad_norm": 0.052929360419511795,
      "learning_rate": 1.9151807228915663e-05,
      "loss": 0.0113,
      "step": 3520
    },
    {
      "epoch": 0.42530120481927713,
      "grad_norm": 19.088293075561523,
      "learning_rate": 1.9149397590361448e-05,
      "loss": 0.0741,
      "step": 3530
    },
    {
      "epoch": 0.42650602409638555,
      "grad_norm": 8.908629417419434,
      "learning_rate": 1.914698795180723e-05,
      "loss": 0.1147,
      "step": 3540
    },
    {
      "epoch": 0.42771084337349397,
      "grad_norm": 0.31336531043052673,
      "learning_rate": 1.9144578313253014e-05,
      "loss": 0.0165,
      "step": 3550
    },
    {
      "epoch": 0.42891566265060244,
      "grad_norm": 0.025067821145057678,
      "learning_rate": 1.91421686746988e-05,
      "loss": 0.0515,
      "step": 3560
    },
    {
      "epoch": 0.43012048192771085,
      "grad_norm": 5.464756965637207,
      "learning_rate": 1.913975903614458e-05,
      "loss": 0.1534,
      "step": 3570
    },
    {
      "epoch": 0.43132530120481927,
      "grad_norm": 0.6143504977226257,
      "learning_rate": 1.9137349397590365e-05,
      "loss": 0.116,
      "step": 3580
    },
    {
      "epoch": 0.43253012048192774,
      "grad_norm": 19.174291610717773,
      "learning_rate": 1.9134939759036147e-05,
      "loss": 0.0968,
      "step": 3590
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 0.15136508643627167,
      "learning_rate": 1.9132530120481928e-05,
      "loss": 0.0272,
      "step": 3600
    },
    {
      "epoch": 0.43493975903614457,
      "grad_norm": 7.4606709480285645,
      "learning_rate": 1.9130120481927713e-05,
      "loss": 0.1471,
      "step": 3610
    },
    {
      "epoch": 0.43614457831325304,
      "grad_norm": 0.39733442664146423,
      "learning_rate": 1.9127710843373494e-05,
      "loss": 0.081,
      "step": 3620
    },
    {
      "epoch": 0.43734939759036146,
      "grad_norm": 7.8652472496032715,
      "learning_rate": 1.912530120481928e-05,
      "loss": 0.0612,
      "step": 3630
    },
    {
      "epoch": 0.43855421686746987,
      "grad_norm": 0.8356185555458069,
      "learning_rate": 1.9122891566265064e-05,
      "loss": 0.0485,
      "step": 3640
    },
    {
      "epoch": 0.4397590361445783,
      "grad_norm": 0.14353583753108978,
      "learning_rate": 1.9120481927710846e-05,
      "loss": 0.0892,
      "step": 3650
    },
    {
      "epoch": 0.44096385542168676,
      "grad_norm": 0.05781203880906105,
      "learning_rate": 1.9118072289156627e-05,
      "loss": 0.1163,
      "step": 3660
    },
    {
      "epoch": 0.44216867469879517,
      "grad_norm": 1.5472544431686401,
      "learning_rate": 1.9115662650602412e-05,
      "loss": 0.0711,
      "step": 3670
    },
    {
      "epoch": 0.4433734939759036,
      "grad_norm": 0.4837677776813507,
      "learning_rate": 1.9113253012048193e-05,
      "loss": 0.0443,
      "step": 3680
    },
    {
      "epoch": 0.44457831325301206,
      "grad_norm": 0.36459848284721375,
      "learning_rate": 1.911084337349398e-05,
      "loss": 0.1116,
      "step": 3690
    },
    {
      "epoch": 0.4457831325301205,
      "grad_norm": 1.353410243988037,
      "learning_rate": 1.910843373493976e-05,
      "loss": 0.0299,
      "step": 3700
    },
    {
      "epoch": 0.4469879518072289,
      "grad_norm": 3.0992352962493896,
      "learning_rate": 1.9106024096385545e-05,
      "loss": 0.0526,
      "step": 3710
    },
    {
      "epoch": 0.44819277108433736,
      "grad_norm": 0.04755965620279312,
      "learning_rate": 1.9103614457831326e-05,
      "loss": 0.053,
      "step": 3720
    },
    {
      "epoch": 0.4493975903614458,
      "grad_norm": 24.790267944335938,
      "learning_rate": 1.910120481927711e-05,
      "loss": 0.134,
      "step": 3730
    },
    {
      "epoch": 0.4506024096385542,
      "grad_norm": 1.7033525705337524,
      "learning_rate": 1.9098795180722893e-05,
      "loss": 0.104,
      "step": 3740
    },
    {
      "epoch": 0.45180722891566266,
      "grad_norm": 4.770602703094482,
      "learning_rate": 1.9096385542168677e-05,
      "loss": 0.0747,
      "step": 3750
    },
    {
      "epoch": 0.4530120481927711,
      "grad_norm": 0.0904846116900444,
      "learning_rate": 1.909397590361446e-05,
      "loss": 0.0552,
      "step": 3760
    },
    {
      "epoch": 0.4542168674698795,
      "grad_norm": 2.65899395942688,
      "learning_rate": 1.909156626506024e-05,
      "loss": 0.0793,
      "step": 3770
    },
    {
      "epoch": 0.45542168674698796,
      "grad_norm": 2.924339771270752,
      "learning_rate": 1.9089156626506025e-05,
      "loss": 0.0383,
      "step": 3780
    },
    {
      "epoch": 0.4566265060240964,
      "grad_norm": 1.6018600463867188,
      "learning_rate": 1.908674698795181e-05,
      "loss": 0.0871,
      "step": 3790
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 0.3870445191860199,
      "learning_rate": 1.908433734939759e-05,
      "loss": 0.0146,
      "step": 3800
    },
    {
      "epoch": 0.45903614457831327,
      "grad_norm": 10.206639289855957,
      "learning_rate": 1.9081927710843376e-05,
      "loss": 0.0355,
      "step": 3810
    },
    {
      "epoch": 0.4602409638554217,
      "grad_norm": 32.14969253540039,
      "learning_rate": 1.9079518072289158e-05,
      "loss": 0.0794,
      "step": 3820
    },
    {
      "epoch": 0.4614457831325301,
      "grad_norm": 0.07502707093954086,
      "learning_rate": 1.907710843373494e-05,
      "loss": 0.0527,
      "step": 3830
    },
    {
      "epoch": 0.46265060240963857,
      "grad_norm": 0.06790155917406082,
      "learning_rate": 1.9074698795180724e-05,
      "loss": 0.0533,
      "step": 3840
    },
    {
      "epoch": 0.463855421686747,
      "grad_norm": 0.0244880523532629,
      "learning_rate": 1.9072289156626506e-05,
      "loss": 0.0755,
      "step": 3850
    },
    {
      "epoch": 0.4650602409638554,
      "grad_norm": 150.74081420898438,
      "learning_rate": 1.906987951807229e-05,
      "loss": 0.0429,
      "step": 3860
    },
    {
      "epoch": 0.46626506024096387,
      "grad_norm": 40.24496078491211,
      "learning_rate": 1.9067469879518076e-05,
      "loss": 0.0923,
      "step": 3870
    },
    {
      "epoch": 0.4674698795180723,
      "grad_norm": 0.3817615807056427,
      "learning_rate": 1.9065060240963857e-05,
      "loss": 0.0661,
      "step": 3880
    },
    {
      "epoch": 0.4686746987951807,
      "grad_norm": 2.403313159942627,
      "learning_rate": 1.9062650602409642e-05,
      "loss": 0.0236,
      "step": 3890
    },
    {
      "epoch": 0.46987951807228917,
      "grad_norm": 0.013571977615356445,
      "learning_rate": 1.9060240963855423e-05,
      "loss": 0.0818,
      "step": 3900
    },
    {
      "epoch": 0.4710843373493976,
      "grad_norm": 0.6830381155014038,
      "learning_rate": 1.9057831325301205e-05,
      "loss": 0.041,
      "step": 3910
    },
    {
      "epoch": 0.472289156626506,
      "grad_norm": 0.24892105162143707,
      "learning_rate": 1.905542168674699e-05,
      "loss": 0.0705,
      "step": 3920
    },
    {
      "epoch": 0.4734939759036145,
      "grad_norm": 0.7898445129394531,
      "learning_rate": 1.905301204819277e-05,
      "loss": 0.0848,
      "step": 3930
    },
    {
      "epoch": 0.4746987951807229,
      "grad_norm": 0.01963665336370468,
      "learning_rate": 1.9050602409638556e-05,
      "loss": 0.0549,
      "step": 3940
    },
    {
      "epoch": 0.4759036144578313,
      "grad_norm": 0.2830783426761627,
      "learning_rate": 1.904819277108434e-05,
      "loss": 0.0548,
      "step": 3950
    },
    {
      "epoch": 0.4771084337349398,
      "grad_norm": 0.06206648424267769,
      "learning_rate": 1.9045783132530122e-05,
      "loss": 0.0193,
      "step": 3960
    },
    {
      "epoch": 0.4783132530120482,
      "grad_norm": 7.495548725128174,
      "learning_rate": 1.9043373493975904e-05,
      "loss": 0.0809,
      "step": 3970
    },
    {
      "epoch": 0.4795180722891566,
      "grad_norm": 7.198241233825684,
      "learning_rate": 1.904096385542169e-05,
      "loss": 0.1182,
      "step": 3980
    },
    {
      "epoch": 0.4807228915662651,
      "grad_norm": 10.473042488098145,
      "learning_rate": 1.903855421686747e-05,
      "loss": 0.1753,
      "step": 3990
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 0.13805653154850006,
      "learning_rate": 1.9036144578313255e-05,
      "loss": 0.0207,
      "step": 4000
    },
    {
      "epoch": 0.4831325301204819,
      "grad_norm": 32.086551666259766,
      "learning_rate": 1.903373493975904e-05,
      "loss": 0.0284,
      "step": 4010
    },
    {
      "epoch": 0.4843373493975904,
      "grad_norm": 3.1085681915283203,
      "learning_rate": 1.903132530120482e-05,
      "loss": 0.0639,
      "step": 4020
    },
    {
      "epoch": 0.4855421686746988,
      "grad_norm": 0.14133648574352264,
      "learning_rate": 1.9028915662650603e-05,
      "loss": 0.1206,
      "step": 4030
    },
    {
      "epoch": 0.4867469879518072,
      "grad_norm": 0.07690797746181488,
      "learning_rate": 1.9026506024096388e-05,
      "loss": 0.1127,
      "step": 4040
    },
    {
      "epoch": 0.4879518072289157,
      "grad_norm": 3.224555015563965,
      "learning_rate": 1.902409638554217e-05,
      "loss": 0.0643,
      "step": 4050
    },
    {
      "epoch": 0.4891566265060241,
      "grad_norm": 0.0966104045510292,
      "learning_rate": 1.9021686746987954e-05,
      "loss": 0.0328,
      "step": 4060
    },
    {
      "epoch": 0.4903614457831325,
      "grad_norm": 2.2778353691101074,
      "learning_rate": 1.9019277108433736e-05,
      "loss": 0.0422,
      "step": 4070
    },
    {
      "epoch": 0.491566265060241,
      "grad_norm": 24.40949058532715,
      "learning_rate": 1.9016867469879517e-05,
      "loss": 0.0573,
      "step": 4080
    },
    {
      "epoch": 0.4927710843373494,
      "grad_norm": 0.8745643496513367,
      "learning_rate": 1.9014457831325302e-05,
      "loss": 0.0755,
      "step": 4090
    },
    {
      "epoch": 0.4939759036144578,
      "grad_norm": 8.782662391662598,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 0.0851,
      "step": 4100
    },
    {
      "epoch": 0.4951807228915663,
      "grad_norm": 5.967099666595459,
      "learning_rate": 1.900963855421687e-05,
      "loss": 0.0581,
      "step": 4110
    },
    {
      "epoch": 0.4963855421686747,
      "grad_norm": 3.8845057487487793,
      "learning_rate": 1.9007228915662653e-05,
      "loss": 0.0946,
      "step": 4120
    },
    {
      "epoch": 0.4975903614457831,
      "grad_norm": 8.805510520935059,
      "learning_rate": 1.9004819277108435e-05,
      "loss": 0.0279,
      "step": 4130
    },
    {
      "epoch": 0.4987951807228916,
      "grad_norm": 4.18714714050293,
      "learning_rate": 1.9002409638554216e-05,
      "loss": 0.0816,
      "step": 4140
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.31960856914520264,
      "learning_rate": 1.9e-05,
      "loss": 0.0365,
      "step": 4150
    },
    {
      "epoch": 0.5012048192771085,
      "grad_norm": 0.4157007932662964,
      "learning_rate": 1.8997590361445786e-05,
      "loss": 0.0861,
      "step": 4160
    },
    {
      "epoch": 0.5024096385542168,
      "grad_norm": 9.578490257263184,
      "learning_rate": 1.8995180722891567e-05,
      "loss": 0.1296,
      "step": 4170
    },
    {
      "epoch": 0.5036144578313253,
      "grad_norm": 19.791948318481445,
      "learning_rate": 1.8992771084337352e-05,
      "loss": 0.0389,
      "step": 4180
    },
    {
      "epoch": 0.5048192771084338,
      "grad_norm": 13.18766975402832,
      "learning_rate": 1.8990361445783134e-05,
      "loss": 0.1062,
      "step": 4190
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 0.3656158149242401,
      "learning_rate": 1.898795180722892e-05,
      "loss": 0.0047,
      "step": 4200
    },
    {
      "epoch": 0.5072289156626506,
      "grad_norm": 6.212550640106201,
      "learning_rate": 1.89855421686747e-05,
      "loss": 0.0695,
      "step": 4210
    },
    {
      "epoch": 0.5084337349397591,
      "grad_norm": 0.07876860350370407,
      "learning_rate": 1.898313253012048e-05,
      "loss": 0.0458,
      "step": 4220
    },
    {
      "epoch": 0.5096385542168674,
      "grad_norm": 0.4037993252277374,
      "learning_rate": 1.8980722891566266e-05,
      "loss": 0.1059,
      "step": 4230
    },
    {
      "epoch": 0.5108433734939759,
      "grad_norm": 0.9497854113578796,
      "learning_rate": 1.897831325301205e-05,
      "loss": 0.0308,
      "step": 4240
    },
    {
      "epoch": 0.5120481927710844,
      "grad_norm": 8.694026947021484,
      "learning_rate": 1.8975903614457833e-05,
      "loss": 0.1029,
      "step": 4250
    },
    {
      "epoch": 0.5132530120481927,
      "grad_norm": 0.10905691981315613,
      "learning_rate": 1.8973493975903618e-05,
      "loss": 0.077,
      "step": 4260
    },
    {
      "epoch": 0.5144578313253012,
      "grad_norm": 8.973443984985352,
      "learning_rate": 1.89710843373494e-05,
      "loss": 0.1658,
      "step": 4270
    },
    {
      "epoch": 0.5156626506024097,
      "grad_norm": 0.28638553619384766,
      "learning_rate": 1.896867469879518e-05,
      "loss": 0.0437,
      "step": 4280
    },
    {
      "epoch": 0.516867469879518,
      "grad_norm": 12.549148559570312,
      "learning_rate": 1.8966265060240966e-05,
      "loss": 0.0392,
      "step": 4290
    },
    {
      "epoch": 0.5180722891566265,
      "grad_norm": 6.8495025634765625,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 0.1949,
      "step": 4300
    },
    {
      "epoch": 0.519277108433735,
      "grad_norm": 11.045568466186523,
      "learning_rate": 1.8961445783132532e-05,
      "loss": 0.0438,
      "step": 4310
    },
    {
      "epoch": 0.5204819277108433,
      "grad_norm": 1.3078503608703613,
      "learning_rate": 1.8959036144578317e-05,
      "loss": 0.079,
      "step": 4320
    },
    {
      "epoch": 0.5216867469879518,
      "grad_norm": 4.254634857177734,
      "learning_rate": 1.8956626506024098e-05,
      "loss": 0.1045,
      "step": 4330
    },
    {
      "epoch": 0.5228915662650603,
      "grad_norm": 0.3725050985813141,
      "learning_rate": 1.895421686746988e-05,
      "loss": 0.0356,
      "step": 4340
    },
    {
      "epoch": 0.5240963855421686,
      "grad_norm": 23.994728088378906,
      "learning_rate": 1.8951807228915665e-05,
      "loss": 0.0526,
      "step": 4350
    },
    {
      "epoch": 0.5253012048192771,
      "grad_norm": 28.46581268310547,
      "learning_rate": 1.8949397590361446e-05,
      "loss": 0.0768,
      "step": 4360
    },
    {
      "epoch": 0.5265060240963856,
      "grad_norm": 28.655746459960938,
      "learning_rate": 1.894698795180723e-05,
      "loss": 0.1099,
      "step": 4370
    },
    {
      "epoch": 0.5277108433734939,
      "grad_norm": 5.401169776916504,
      "learning_rate": 1.8944578313253012e-05,
      "loss": 0.0606,
      "step": 4380
    },
    {
      "epoch": 0.5289156626506024,
      "grad_norm": 10.460898399353027,
      "learning_rate": 1.8942168674698797e-05,
      "loss": 0.0903,
      "step": 4390
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 10.411161422729492,
      "learning_rate": 1.893975903614458e-05,
      "loss": 0.1019,
      "step": 4400
    },
    {
      "epoch": 0.5313253012048192,
      "grad_norm": 6.579194068908691,
      "learning_rate": 1.8937349397590364e-05,
      "loss": 0.0917,
      "step": 4410
    },
    {
      "epoch": 0.5325301204819277,
      "grad_norm": 0.0577106699347496,
      "learning_rate": 1.8934939759036145e-05,
      "loss": 0.0688,
      "step": 4420
    },
    {
      "epoch": 0.5337349397590362,
      "grad_norm": 0.4575566053390503,
      "learning_rate": 1.893253012048193e-05,
      "loss": 0.0986,
      "step": 4430
    },
    {
      "epoch": 0.5349397590361445,
      "grad_norm": 0.19481417536735535,
      "learning_rate": 1.893012048192771e-05,
      "loss": 0.0357,
      "step": 4440
    },
    {
      "epoch": 0.536144578313253,
      "grad_norm": 0.9693426489830017,
      "learning_rate": 1.8927710843373493e-05,
      "loss": 0.0943,
      "step": 4450
    },
    {
      "epoch": 0.5373493975903615,
      "grad_norm": 0.08967938274145126,
      "learning_rate": 1.892530120481928e-05,
      "loss": 0.0592,
      "step": 4460
    },
    {
      "epoch": 0.5385542168674698,
      "grad_norm": 4.060465335845947,
      "learning_rate": 1.8922891566265063e-05,
      "loss": 0.1248,
      "step": 4470
    },
    {
      "epoch": 0.5397590361445783,
      "grad_norm": 6.6776533126831055,
      "learning_rate": 1.8920481927710844e-05,
      "loss": 0.0392,
      "step": 4480
    },
    {
      "epoch": 0.5409638554216868,
      "grad_norm": 14.169410705566406,
      "learning_rate": 1.891807228915663e-05,
      "loss": 0.0889,
      "step": 4490
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 5.544861793518066,
      "learning_rate": 1.891566265060241e-05,
      "loss": 0.082,
      "step": 4500
    },
    {
      "epoch": 0.5433734939759036,
      "grad_norm": 6.925840854644775,
      "learning_rate": 1.8913253012048195e-05,
      "loss": 0.105,
      "step": 4510
    },
    {
      "epoch": 0.5445783132530121,
      "grad_norm": 8.013726234436035,
      "learning_rate": 1.8910843373493977e-05,
      "loss": 0.1136,
      "step": 4520
    },
    {
      "epoch": 0.5457831325301205,
      "grad_norm": 12.416471481323242,
      "learning_rate": 1.890843373493976e-05,
      "loss": 0.0394,
      "step": 4530
    },
    {
      "epoch": 0.5469879518072289,
      "grad_norm": 2.7867774963378906,
      "learning_rate": 1.8906024096385543e-05,
      "loss": 0.0105,
      "step": 4540
    },
    {
      "epoch": 0.5481927710843374,
      "grad_norm": 5.435275554656982,
      "learning_rate": 1.8903614457831328e-05,
      "loss": 0.0928,
      "step": 4550
    },
    {
      "epoch": 0.5493975903614458,
      "grad_norm": 8.5032958984375,
      "learning_rate": 1.890120481927711e-05,
      "loss": 0.1115,
      "step": 4560
    },
    {
      "epoch": 0.5506024096385542,
      "grad_norm": 4.865397930145264,
      "learning_rate": 1.8898795180722894e-05,
      "loss": 0.1191,
      "step": 4570
    },
    {
      "epoch": 0.5518072289156627,
      "grad_norm": 0.18501156568527222,
      "learning_rate": 1.8896385542168676e-05,
      "loss": 0.1002,
      "step": 4580
    },
    {
      "epoch": 0.553012048192771,
      "grad_norm": 3.2400076389312744,
      "learning_rate": 1.8893975903614457e-05,
      "loss": 0.0728,
      "step": 4590
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 0.36002784967422485,
      "learning_rate": 1.8891566265060242e-05,
      "loss": 0.0381,
      "step": 4600
    },
    {
      "epoch": 0.555421686746988,
      "grad_norm": 11.91073226928711,
      "learning_rate": 1.8889156626506027e-05,
      "loss": 0.0975,
      "step": 4610
    },
    {
      "epoch": 0.5566265060240964,
      "grad_norm": 7.229229927062988,
      "learning_rate": 1.888674698795181e-05,
      "loss": 0.071,
      "step": 4620
    },
    {
      "epoch": 0.5578313253012048,
      "grad_norm": 0.0407736711204052,
      "learning_rate": 1.8884337349397593e-05,
      "loss": 0.0512,
      "step": 4630
    },
    {
      "epoch": 0.5590361445783133,
      "grad_norm": 0.2469913512468338,
      "learning_rate": 1.8881927710843375e-05,
      "loss": 0.0947,
      "step": 4640
    },
    {
      "epoch": 0.5602409638554217,
      "grad_norm": 51.69271469116211,
      "learning_rate": 1.8879518072289156e-05,
      "loss": 0.0546,
      "step": 4650
    },
    {
      "epoch": 0.5614457831325301,
      "grad_norm": 9.477707862854004,
      "learning_rate": 1.887710843373494e-05,
      "loss": 0.0135,
      "step": 4660
    },
    {
      "epoch": 0.5626506024096386,
      "grad_norm": 4.357265949249268,
      "learning_rate": 1.8874698795180723e-05,
      "loss": 0.1182,
      "step": 4670
    },
    {
      "epoch": 0.563855421686747,
      "grad_norm": 5.429626941680908,
      "learning_rate": 1.8872289156626508e-05,
      "loss": 0.0765,
      "step": 4680
    },
    {
      "epoch": 0.5650602409638554,
      "grad_norm": 199.46469116210938,
      "learning_rate": 1.8869879518072293e-05,
      "loss": 0.1085,
      "step": 4690
    },
    {
      "epoch": 0.5662650602409639,
      "grad_norm": 1.4201147556304932,
      "learning_rate": 1.8867469879518074e-05,
      "loss": 0.1087,
      "step": 4700
    },
    {
      "epoch": 0.5674698795180723,
      "grad_norm": 2.6211307048797607,
      "learning_rate": 1.886506024096386e-05,
      "loss": 0.0559,
      "step": 4710
    },
    {
      "epoch": 0.5686746987951807,
      "grad_norm": 0.11000506579875946,
      "learning_rate": 1.886265060240964e-05,
      "loss": 0.0395,
      "step": 4720
    },
    {
      "epoch": 0.5698795180722892,
      "grad_norm": 1.8811330795288086,
      "learning_rate": 1.8860240963855422e-05,
      "loss": 0.0571,
      "step": 4730
    },
    {
      "epoch": 0.5710843373493976,
      "grad_norm": 4.63735294342041,
      "learning_rate": 1.8857831325301207e-05,
      "loss": 0.0292,
      "step": 4740
    },
    {
      "epoch": 0.572289156626506,
      "grad_norm": 43.43156051635742,
      "learning_rate": 1.8855421686746988e-05,
      "loss": 0.0612,
      "step": 4750
    },
    {
      "epoch": 0.5734939759036145,
      "grad_norm": 14.144058227539062,
      "learning_rate": 1.8853012048192773e-05,
      "loss": 0.0856,
      "step": 4760
    },
    {
      "epoch": 0.5746987951807229,
      "grad_norm": 16.61579704284668,
      "learning_rate": 1.8850602409638558e-05,
      "loss": 0.0333,
      "step": 4770
    },
    {
      "epoch": 0.5759036144578313,
      "grad_norm": 0.42789971828460693,
      "learning_rate": 1.884819277108434e-05,
      "loss": 0.0493,
      "step": 4780
    },
    {
      "epoch": 0.5771084337349398,
      "grad_norm": 53.34697723388672,
      "learning_rate": 1.884578313253012e-05,
      "loss": 0.0601,
      "step": 4790
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 0.08782034367322922,
      "learning_rate": 1.8843373493975906e-05,
      "loss": 0.0696,
      "step": 4800
    },
    {
      "epoch": 0.5795180722891566,
      "grad_norm": 5.89714241027832,
      "learning_rate": 1.8840963855421687e-05,
      "loss": 0.0976,
      "step": 4810
    },
    {
      "epoch": 0.5807228915662651,
      "grad_norm": 22.143062591552734,
      "learning_rate": 1.8838554216867472e-05,
      "loss": 0.0271,
      "step": 4820
    },
    {
      "epoch": 0.5819277108433735,
      "grad_norm": 1.2187421321868896,
      "learning_rate": 1.8836144578313254e-05,
      "loss": 0.0797,
      "step": 4830
    },
    {
      "epoch": 0.5831325301204819,
      "grad_norm": 0.8835422396659851,
      "learning_rate": 1.883373493975904e-05,
      "loss": 0.0829,
      "step": 4840
    },
    {
      "epoch": 0.5843373493975904,
      "grad_norm": 2.6586973667144775,
      "learning_rate": 1.883132530120482e-05,
      "loss": 0.044,
      "step": 4850
    },
    {
      "epoch": 0.5855421686746988,
      "grad_norm": 1.6548699140548706,
      "learning_rate": 1.8828915662650605e-05,
      "loss": 0.0444,
      "step": 4860
    },
    {
      "epoch": 0.5867469879518072,
      "grad_norm": 0.39568254351615906,
      "learning_rate": 1.8826506024096386e-05,
      "loss": 0.0698,
      "step": 4870
    },
    {
      "epoch": 0.5879518072289157,
      "grad_norm": 0.09714744240045547,
      "learning_rate": 1.882409638554217e-05,
      "loss": 0.1289,
      "step": 4880
    },
    {
      "epoch": 0.5891566265060241,
      "grad_norm": 0.8321428298950195,
      "learning_rate": 1.8821686746987953e-05,
      "loss": 0.0386,
      "step": 4890
    },
    {
      "epoch": 0.5903614457831325,
      "grad_norm": 27.937904357910156,
      "learning_rate": 1.8819277108433734e-05,
      "loss": 0.1221,
      "step": 4900
    },
    {
      "epoch": 0.591566265060241,
      "grad_norm": 5.963125228881836,
      "learning_rate": 1.881686746987952e-05,
      "loss": 0.0855,
      "step": 4910
    },
    {
      "epoch": 0.5927710843373494,
      "grad_norm": 0.7891167402267456,
      "learning_rate": 1.8814457831325304e-05,
      "loss": 0.0277,
      "step": 4920
    },
    {
      "epoch": 0.5939759036144578,
      "grad_norm": 3.3654322624206543,
      "learning_rate": 1.8812048192771085e-05,
      "loss": 0.0527,
      "step": 4930
    },
    {
      "epoch": 0.5951807228915663,
      "grad_norm": 1.480942726135254,
      "learning_rate": 1.880963855421687e-05,
      "loss": 0.0963,
      "step": 4940
    },
    {
      "epoch": 0.5963855421686747,
      "grad_norm": 0.4192911982536316,
      "learning_rate": 1.8807228915662652e-05,
      "loss": 0.0484,
      "step": 4950
    },
    {
      "epoch": 0.5975903614457831,
      "grad_norm": 36.709964752197266,
      "learning_rate": 1.8804819277108433e-05,
      "loss": 0.0197,
      "step": 4960
    },
    {
      "epoch": 0.5987951807228916,
      "grad_norm": 0.03941871225833893,
      "learning_rate": 1.8802409638554218e-05,
      "loss": 0.0284,
      "step": 4970
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.617220401763916,
      "learning_rate": 1.88e-05,
      "loss": 0.099,
      "step": 4980
    },
    {
      "epoch": 0.6012048192771084,
      "grad_norm": 0.04127354547381401,
      "learning_rate": 1.8797590361445784e-05,
      "loss": 0.1103,
      "step": 4990
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 9.586132049560547,
      "learning_rate": 1.879518072289157e-05,
      "loss": 0.0625,
      "step": 5000
    },
    {
      "epoch": 0.6036144578313253,
      "grad_norm": 0.13760364055633545,
      "learning_rate": 1.879277108433735e-05,
      "loss": 0.1037,
      "step": 5010
    },
    {
      "epoch": 0.6048192771084338,
      "grad_norm": 10.764167785644531,
      "learning_rate": 1.8790361445783136e-05,
      "loss": 0.011,
      "step": 5020
    },
    {
      "epoch": 0.6060240963855422,
      "grad_norm": 4.640018939971924,
      "learning_rate": 1.8787951807228917e-05,
      "loss": 0.0268,
      "step": 5030
    },
    {
      "epoch": 0.6072289156626506,
      "grad_norm": 0.12581677734851837,
      "learning_rate": 1.87855421686747e-05,
      "loss": 0.0219,
      "step": 5040
    },
    {
      "epoch": 0.608433734939759,
      "grad_norm": 0.06286516040563583,
      "learning_rate": 1.8783132530120483e-05,
      "loss": 0.0983,
      "step": 5050
    },
    {
      "epoch": 0.6096385542168675,
      "grad_norm": 0.19651883840560913,
      "learning_rate": 1.878072289156627e-05,
      "loss": 0.0494,
      "step": 5060
    },
    {
      "epoch": 0.6108433734939759,
      "grad_norm": 14.289841651916504,
      "learning_rate": 1.877831325301205e-05,
      "loss": 0.0754,
      "step": 5070
    },
    {
      "epoch": 0.6120481927710844,
      "grad_norm": 0.03205079585313797,
      "learning_rate": 1.8775903614457835e-05,
      "loss": 0.0804,
      "step": 5080
    },
    {
      "epoch": 0.6132530120481928,
      "grad_norm": 0.14452823996543884,
      "learning_rate": 1.8773493975903616e-05,
      "loss": 0.0426,
      "step": 5090
    },
    {
      "epoch": 0.6144578313253012,
      "grad_norm": 0.2721010446548462,
      "learning_rate": 1.8771084337349398e-05,
      "loss": 0.1312,
      "step": 5100
    },
    {
      "epoch": 0.6156626506024097,
      "grad_norm": 2.908076763153076,
      "learning_rate": 1.8768674698795183e-05,
      "loss": 0.0481,
      "step": 5110
    },
    {
      "epoch": 0.6168674698795181,
      "grad_norm": 27.332752227783203,
      "learning_rate": 1.8766265060240964e-05,
      "loss": 0.0885,
      "step": 5120
    },
    {
      "epoch": 0.6180722891566265,
      "grad_norm": 7.3542399406433105,
      "learning_rate": 1.876385542168675e-05,
      "loss": 0.0947,
      "step": 5130
    },
    {
      "epoch": 0.619277108433735,
      "grad_norm": 4.603604793548584,
      "learning_rate": 1.8761445783132534e-05,
      "loss": 0.1156,
      "step": 5140
    },
    {
      "epoch": 0.6204819277108434,
      "grad_norm": 0.5254230499267578,
      "learning_rate": 1.8759036144578315e-05,
      "loss": 0.0929,
      "step": 5150
    },
    {
      "epoch": 0.6216867469879518,
      "grad_norm": 0.3669930696487427,
      "learning_rate": 1.8756626506024097e-05,
      "loss": 0.0721,
      "step": 5160
    },
    {
      "epoch": 0.6228915662650603,
      "grad_norm": 2.6772758960723877,
      "learning_rate": 1.875421686746988e-05,
      "loss": 0.0525,
      "step": 5170
    },
    {
      "epoch": 0.6240963855421687,
      "grad_norm": 0.03013969585299492,
      "learning_rate": 1.8751807228915663e-05,
      "loss": 0.0298,
      "step": 5180
    },
    {
      "epoch": 0.6253012048192771,
      "grad_norm": 10.659236907958984,
      "learning_rate": 1.8749397590361448e-05,
      "loss": 0.0724,
      "step": 5190
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 12.77163028717041,
      "learning_rate": 1.874698795180723e-05,
      "loss": 0.1291,
      "step": 5200
    },
    {
      "epoch": 0.6277108433734939,
      "grad_norm": 7.5159173011779785,
      "learning_rate": 1.8744578313253014e-05,
      "loss": 0.0336,
      "step": 5210
    },
    {
      "epoch": 0.6289156626506024,
      "grad_norm": 2.3142635822296143,
      "learning_rate": 1.8742168674698796e-05,
      "loss": 0.0881,
      "step": 5220
    },
    {
      "epoch": 0.6301204819277109,
      "grad_norm": 9.7084321975708,
      "learning_rate": 1.873975903614458e-05,
      "loss": 0.044,
      "step": 5230
    },
    {
      "epoch": 0.6313253012048192,
      "grad_norm": 2.3118226528167725,
      "learning_rate": 1.8737349397590362e-05,
      "loss": 0.0838,
      "step": 5240
    },
    {
      "epoch": 0.6325301204819277,
      "grad_norm": 0.010887031443417072,
      "learning_rate": 1.8734939759036147e-05,
      "loss": 0.0356,
      "step": 5250
    },
    {
      "epoch": 0.6337349397590362,
      "grad_norm": 7.27818489074707,
      "learning_rate": 1.873253012048193e-05,
      "loss": 0.0531,
      "step": 5260
    },
    {
      "epoch": 0.6349397590361445,
      "grad_norm": 8.997214317321777,
      "learning_rate": 1.873012048192771e-05,
      "loss": 0.0571,
      "step": 5270
    },
    {
      "epoch": 0.636144578313253,
      "grad_norm": 3.344991445541382,
      "learning_rate": 1.8727710843373495e-05,
      "loss": 0.0041,
      "step": 5280
    },
    {
      "epoch": 0.6373493975903615,
      "grad_norm": 10.278743743896484,
      "learning_rate": 1.872530120481928e-05,
      "loss": 0.0849,
      "step": 5290
    },
    {
      "epoch": 0.6385542168674698,
      "grad_norm": 12.961173057556152,
      "learning_rate": 1.872289156626506e-05,
      "loss": 0.0566,
      "step": 5300
    },
    {
      "epoch": 0.6397590361445783,
      "grad_norm": 2.4736428260803223,
      "learning_rate": 1.8720481927710846e-05,
      "loss": 0.0771,
      "step": 5310
    },
    {
      "epoch": 0.6409638554216868,
      "grad_norm": 6.282693862915039,
      "learning_rate": 1.8718072289156628e-05,
      "loss": 0.115,
      "step": 5320
    },
    {
      "epoch": 0.6421686746987951,
      "grad_norm": 20.723434448242188,
      "learning_rate": 1.8715662650602412e-05,
      "loss": 0.1014,
      "step": 5330
    },
    {
      "epoch": 0.6433734939759036,
      "grad_norm": 0.06132809445261955,
      "learning_rate": 1.8713253012048194e-05,
      "loss": 0.0813,
      "step": 5340
    },
    {
      "epoch": 0.6445783132530121,
      "grad_norm": 14.284207344055176,
      "learning_rate": 1.8710843373493975e-05,
      "loss": 0.1631,
      "step": 5350
    },
    {
      "epoch": 0.6457831325301204,
      "grad_norm": 2.8533427715301514,
      "learning_rate": 1.870843373493976e-05,
      "loss": 0.104,
      "step": 5360
    },
    {
      "epoch": 0.6469879518072289,
      "grad_norm": 2.2210586071014404,
      "learning_rate": 1.8706024096385545e-05,
      "loss": 0.0183,
      "step": 5370
    },
    {
      "epoch": 0.6481927710843374,
      "grad_norm": 0.713135838508606,
      "learning_rate": 1.8703614457831327e-05,
      "loss": 0.0295,
      "step": 5380
    },
    {
      "epoch": 0.6493975903614457,
      "grad_norm": 0.084527887403965,
      "learning_rate": 1.870120481927711e-05,
      "loss": 0.0934,
      "step": 5390
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 0.08134579658508301,
      "learning_rate": 1.8698795180722893e-05,
      "loss": 0.1129,
      "step": 5400
    },
    {
      "epoch": 0.6518072289156627,
      "grad_norm": 0.3781006634235382,
      "learning_rate": 1.8696385542168674e-05,
      "loss": 0.0559,
      "step": 5410
    },
    {
      "epoch": 0.653012048192771,
      "grad_norm": 5.16672945022583,
      "learning_rate": 1.869397590361446e-05,
      "loss": 0.075,
      "step": 5420
    },
    {
      "epoch": 0.6542168674698795,
      "grad_norm": 20.640762329101562,
      "learning_rate": 1.869156626506024e-05,
      "loss": 0.0431,
      "step": 5430
    },
    {
      "epoch": 0.655421686746988,
      "grad_norm": 6.412456035614014,
      "learning_rate": 1.8689156626506026e-05,
      "loss": 0.1193,
      "step": 5440
    },
    {
      "epoch": 0.6566265060240963,
      "grad_norm": 8.629283905029297,
      "learning_rate": 1.868674698795181e-05,
      "loss": 0.0977,
      "step": 5450
    },
    {
      "epoch": 0.6578313253012048,
      "grad_norm": 0.15486004948616028,
      "learning_rate": 1.8684337349397592e-05,
      "loss": 0.0475,
      "step": 5460
    },
    {
      "epoch": 0.6590361445783133,
      "grad_norm": 0.019515931606292725,
      "learning_rate": 1.8681927710843374e-05,
      "loss": 0.0955,
      "step": 5470
    },
    {
      "epoch": 0.6602409638554216,
      "grad_norm": 5.258112907409668,
      "learning_rate": 1.867951807228916e-05,
      "loss": 0.129,
      "step": 5480
    },
    {
      "epoch": 0.6614457831325301,
      "grad_norm": 0.07833553850650787,
      "learning_rate": 1.867710843373494e-05,
      "loss": 0.0598,
      "step": 5490
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 3.943742036819458,
      "learning_rate": 1.8674698795180725e-05,
      "loss": 0.0572,
      "step": 5500
    },
    {
      "epoch": 0.6638554216867469,
      "grad_norm": 1.3949416875839233,
      "learning_rate": 1.867228915662651e-05,
      "loss": 0.0708,
      "step": 5510
    },
    {
      "epoch": 0.6650602409638554,
      "grad_norm": 36.99532699584961,
      "learning_rate": 1.866987951807229e-05,
      "loss": 0.0658,
      "step": 5520
    },
    {
      "epoch": 0.6662650602409639,
      "grad_norm": 0.6655372977256775,
      "learning_rate": 1.8667469879518073e-05,
      "loss": 0.0839,
      "step": 5530
    },
    {
      "epoch": 0.6674698795180722,
      "grad_norm": 3.4809515476226807,
      "learning_rate": 1.8665060240963857e-05,
      "loss": 0.1148,
      "step": 5540
    },
    {
      "epoch": 0.6686746987951807,
      "grad_norm": 6.670950412750244,
      "learning_rate": 1.866265060240964e-05,
      "loss": 0.0235,
      "step": 5550
    },
    {
      "epoch": 0.6698795180722892,
      "grad_norm": 0.1755136400461197,
      "learning_rate": 1.8660240963855424e-05,
      "loss": 0.0571,
      "step": 5560
    },
    {
      "epoch": 0.6710843373493975,
      "grad_norm": 0.09488312900066376,
      "learning_rate": 1.8657831325301205e-05,
      "loss": 0.0373,
      "step": 5570
    },
    {
      "epoch": 0.672289156626506,
      "grad_norm": 11.3756103515625,
      "learning_rate": 1.8655421686746987e-05,
      "loss": 0.1158,
      "step": 5580
    },
    {
      "epoch": 0.6734939759036145,
      "grad_norm": 0.161897212266922,
      "learning_rate": 1.8653012048192775e-05,
      "loss": 0.0667,
      "step": 5590
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 0.8092383742332458,
      "learning_rate": 1.8650602409638556e-05,
      "loss": 0.0853,
      "step": 5600
    },
    {
      "epoch": 0.6759036144578313,
      "grad_norm": 10.662418365478516,
      "learning_rate": 1.8648192771084338e-05,
      "loss": 0.0716,
      "step": 5610
    },
    {
      "epoch": 0.6771084337349398,
      "grad_norm": 0.21226423978805542,
      "learning_rate": 1.8645783132530123e-05,
      "loss": 0.0368,
      "step": 5620
    },
    {
      "epoch": 0.6783132530120481,
      "grad_norm": 0.15841923654079437,
      "learning_rate": 1.8643373493975904e-05,
      "loss": 0.0687,
      "step": 5630
    },
    {
      "epoch": 0.6795180722891566,
      "grad_norm": 0.39048898220062256,
      "learning_rate": 1.864096385542169e-05,
      "loss": 0.0365,
      "step": 5640
    },
    {
      "epoch": 0.6807228915662651,
      "grad_norm": 12.512289047241211,
      "learning_rate": 1.863855421686747e-05,
      "loss": 0.0611,
      "step": 5650
    },
    {
      "epoch": 0.6819277108433734,
      "grad_norm": 17.146379470825195,
      "learning_rate": 1.8636144578313256e-05,
      "loss": 0.0993,
      "step": 5660
    },
    {
      "epoch": 0.6831325301204819,
      "grad_norm": 1.0719741582870483,
      "learning_rate": 1.8633734939759037e-05,
      "loss": 0.068,
      "step": 5670
    },
    {
      "epoch": 0.6843373493975904,
      "grad_norm": 0.4519712030887604,
      "learning_rate": 1.8631325301204822e-05,
      "loss": 0.0523,
      "step": 5680
    },
    {
      "epoch": 0.6855421686746987,
      "grad_norm": 0.45607414841651917,
      "learning_rate": 1.8628915662650603e-05,
      "loss": 0.0569,
      "step": 5690
    },
    {
      "epoch": 0.6867469879518072,
      "grad_norm": 0.07118264585733414,
      "learning_rate": 1.8626506024096388e-05,
      "loss": 0.1318,
      "step": 5700
    },
    {
      "epoch": 0.6879518072289157,
      "grad_norm": 8.307985305786133,
      "learning_rate": 1.862409638554217e-05,
      "loss": 0.126,
      "step": 5710
    },
    {
      "epoch": 0.689156626506024,
      "grad_norm": 12.8042573928833,
      "learning_rate": 1.862168674698795e-05,
      "loss": 0.1089,
      "step": 5720
    },
    {
      "epoch": 0.6903614457831325,
      "grad_norm": 0.12329966574907303,
      "learning_rate": 1.8619277108433736e-05,
      "loss": 0.0359,
      "step": 5730
    },
    {
      "epoch": 0.691566265060241,
      "grad_norm": 5.007514476776123,
      "learning_rate": 1.861686746987952e-05,
      "loss": 0.1119,
      "step": 5740
    },
    {
      "epoch": 0.6927710843373494,
      "grad_norm": 0.21546530723571777,
      "learning_rate": 1.8614457831325302e-05,
      "loss": 0.0669,
      "step": 5750
    },
    {
      "epoch": 0.6939759036144578,
      "grad_norm": 13.639079093933105,
      "learning_rate": 1.8612048192771087e-05,
      "loss": 0.0468,
      "step": 5760
    },
    {
      "epoch": 0.6951807228915663,
      "grad_norm": 12.479893684387207,
      "learning_rate": 1.860963855421687e-05,
      "loss": 0.0462,
      "step": 5770
    },
    {
      "epoch": 0.6963855421686747,
      "grad_norm": 14.343881607055664,
      "learning_rate": 1.860722891566265e-05,
      "loss": 0.1696,
      "step": 5780
    },
    {
      "epoch": 0.6975903614457831,
      "grad_norm": 8.747323989868164,
      "learning_rate": 1.8604819277108435e-05,
      "loss": 0.0805,
      "step": 5790
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 0.2656528353691101,
      "learning_rate": 1.8602409638554217e-05,
      "loss": 0.0877,
      "step": 5800
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6268747448921204,
      "learning_rate": 1.86e-05,
      "loss": 0.0494,
      "step": 5810
    },
    {
      "epoch": 0.7012048192771084,
      "grad_norm": 0.015069697052240372,
      "learning_rate": 1.8597590361445786e-05,
      "loss": 0.0346,
      "step": 5820
    },
    {
      "epoch": 0.7024096385542169,
      "grad_norm": 0.5088197588920593,
      "learning_rate": 1.8595180722891568e-05,
      "loss": 0.0794,
      "step": 5830
    },
    {
      "epoch": 0.7036144578313253,
      "grad_norm": 18.71815299987793,
      "learning_rate": 1.859277108433735e-05,
      "loss": 0.0427,
      "step": 5840
    },
    {
      "epoch": 0.7048192771084337,
      "grad_norm": 1.3118873834609985,
      "learning_rate": 1.8590361445783134e-05,
      "loss": 0.0467,
      "step": 5850
    },
    {
      "epoch": 0.7060240963855422,
      "grad_norm": 0.9780089259147644,
      "learning_rate": 1.8587951807228916e-05,
      "loss": 0.066,
      "step": 5860
    },
    {
      "epoch": 0.7072289156626506,
      "grad_norm": 1.173561930656433,
      "learning_rate": 1.85855421686747e-05,
      "loss": 0.0782,
      "step": 5870
    },
    {
      "epoch": 0.708433734939759,
      "grad_norm": 2.195128917694092,
      "learning_rate": 1.8583132530120482e-05,
      "loss": 0.0748,
      "step": 5880
    },
    {
      "epoch": 0.7096385542168675,
      "grad_norm": 0.06883873790502548,
      "learning_rate": 1.8580722891566267e-05,
      "loss": 0.0771,
      "step": 5890
    },
    {
      "epoch": 0.7108433734939759,
      "grad_norm": 3.517131805419922,
      "learning_rate": 1.8578313253012052e-05,
      "loss": 0.1108,
      "step": 5900
    },
    {
      "epoch": 0.7120481927710843,
      "grad_norm": 3.931574821472168,
      "learning_rate": 1.8575903614457833e-05,
      "loss": 0.0814,
      "step": 5910
    },
    {
      "epoch": 0.7132530120481928,
      "grad_norm": 44.03802490234375,
      "learning_rate": 1.8573493975903615e-05,
      "loss": 0.0274,
      "step": 5920
    },
    {
      "epoch": 0.7144578313253012,
      "grad_norm": 0.06308671832084656,
      "learning_rate": 1.85710843373494e-05,
      "loss": 0.0292,
      "step": 5930
    },
    {
      "epoch": 0.7156626506024096,
      "grad_norm": 1.0705922842025757,
      "learning_rate": 1.856867469879518e-05,
      "loss": 0.0108,
      "step": 5940
    },
    {
      "epoch": 0.7168674698795181,
      "grad_norm": 0.05173946171998978,
      "learning_rate": 1.8566265060240966e-05,
      "loss": 0.0703,
      "step": 5950
    },
    {
      "epoch": 0.7180722891566265,
      "grad_norm": 0.58756023645401,
      "learning_rate": 1.856385542168675e-05,
      "loss": 0.1393,
      "step": 5960
    },
    {
      "epoch": 0.7192771084337349,
      "grad_norm": 0.356578528881073,
      "learning_rate": 1.8561445783132532e-05,
      "loss": 0.0901,
      "step": 5970
    },
    {
      "epoch": 0.7204819277108434,
      "grad_norm": 0.1269201785326004,
      "learning_rate": 1.8559036144578314e-05,
      "loss": 0.0697,
      "step": 5980
    },
    {
      "epoch": 0.7216867469879518,
      "grad_norm": 4.154855251312256,
      "learning_rate": 1.85566265060241e-05,
      "loss": 0.0777,
      "step": 5990
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 12.647357940673828,
      "learning_rate": 1.855421686746988e-05,
      "loss": 0.0645,
      "step": 6000
    },
    {
      "epoch": 0.7240963855421687,
      "grad_norm": 0.8823636770248413,
      "learning_rate": 1.8551807228915665e-05,
      "loss": 0.0318,
      "step": 6010
    },
    {
      "epoch": 0.7253012048192771,
      "grad_norm": 0.05732009932398796,
      "learning_rate": 1.8549397590361446e-05,
      "loss": 0.045,
      "step": 6020
    },
    {
      "epoch": 0.7265060240963855,
      "grad_norm": 1.9853824377059937,
      "learning_rate": 1.8546987951807228e-05,
      "loss": 0.0681,
      "step": 6030
    },
    {
      "epoch": 0.727710843373494,
      "grad_norm": 0.21901056170463562,
      "learning_rate": 1.8544578313253013e-05,
      "loss": 0.036,
      "step": 6040
    },
    {
      "epoch": 0.7289156626506024,
      "grad_norm": 15.609800338745117,
      "learning_rate": 1.8542168674698798e-05,
      "loss": 0.0554,
      "step": 6050
    },
    {
      "epoch": 0.7301204819277108,
      "grad_norm": 0.059518132358789444,
      "learning_rate": 1.853975903614458e-05,
      "loss": 0.0653,
      "step": 6060
    },
    {
      "epoch": 0.7313253012048193,
      "grad_norm": 5.5099310874938965,
      "learning_rate": 1.8537349397590364e-05,
      "loss": 0.0631,
      "step": 6070
    },
    {
      "epoch": 0.7325301204819277,
      "grad_norm": 7.535940170288086,
      "learning_rate": 1.8534939759036146e-05,
      "loss": 0.1424,
      "step": 6080
    },
    {
      "epoch": 0.7337349397590361,
      "grad_norm": 0.06115720421075821,
      "learning_rate": 1.8532530120481927e-05,
      "loss": 0.0359,
      "step": 6090
    },
    {
      "epoch": 0.7349397590361446,
      "grad_norm": 0.02714415267109871,
      "learning_rate": 1.8530120481927712e-05,
      "loss": 0.0701,
      "step": 6100
    },
    {
      "epoch": 0.736144578313253,
      "grad_norm": 0.047345422208309174,
      "learning_rate": 1.8527710843373497e-05,
      "loss": 0.0361,
      "step": 6110
    },
    {
      "epoch": 0.7373493975903614,
      "grad_norm": 0.03515351936221123,
      "learning_rate": 1.8525301204819278e-05,
      "loss": 0.0711,
      "step": 6120
    },
    {
      "epoch": 0.7385542168674699,
      "grad_norm": 3.7782835960388184,
      "learning_rate": 1.8522891566265063e-05,
      "loss": 0.0849,
      "step": 6130
    },
    {
      "epoch": 0.7397590361445783,
      "grad_norm": 3.8563597202301025,
      "learning_rate": 1.8520481927710845e-05,
      "loss": 0.0143,
      "step": 6140
    },
    {
      "epoch": 0.7409638554216867,
      "grad_norm": 1.4130605459213257,
      "learning_rate": 1.851807228915663e-05,
      "loss": 0.1034,
      "step": 6150
    },
    {
      "epoch": 0.7421686746987952,
      "grad_norm": 0.04211839661002159,
      "learning_rate": 1.851566265060241e-05,
      "loss": 0.046,
      "step": 6160
    },
    {
      "epoch": 0.7433734939759036,
      "grad_norm": 0.18120437860488892,
      "learning_rate": 1.8513253012048192e-05,
      "loss": 0.0079,
      "step": 6170
    },
    {
      "epoch": 0.744578313253012,
      "grad_norm": 8.043597221374512,
      "learning_rate": 1.8510843373493977e-05,
      "loss": 0.0941,
      "step": 6180
    },
    {
      "epoch": 0.7457831325301205,
      "grad_norm": 0.8347971439361572,
      "learning_rate": 1.8508433734939762e-05,
      "loss": 0.0433,
      "step": 6190
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 1.6013950109481812,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 0.0025,
      "step": 6200
    },
    {
      "epoch": 0.7481927710843373,
      "grad_norm": 0.20594285428524017,
      "learning_rate": 1.850361445783133e-05,
      "loss": 0.0196,
      "step": 6210
    },
    {
      "epoch": 0.7493975903614458,
      "grad_norm": 5.677413463592529,
      "learning_rate": 1.850120481927711e-05,
      "loss": 0.0754,
      "step": 6220
    },
    {
      "epoch": 0.7506024096385542,
      "grad_norm": 26.47346305847168,
      "learning_rate": 1.849879518072289e-05,
      "loss": 0.0766,
      "step": 6230
    },
    {
      "epoch": 0.7518072289156627,
      "grad_norm": 0.1911473125219345,
      "learning_rate": 1.8496385542168676e-05,
      "loss": 0.0339,
      "step": 6240
    },
    {
      "epoch": 0.7530120481927711,
      "grad_norm": 2.4572384357452393,
      "learning_rate": 1.8493975903614458e-05,
      "loss": 0.0594,
      "step": 6250
    },
    {
      "epoch": 0.7542168674698795,
      "grad_norm": 6.273158073425293,
      "learning_rate": 1.8491566265060243e-05,
      "loss": 0.0549,
      "step": 6260
    },
    {
      "epoch": 0.755421686746988,
      "grad_norm": 2.69136643409729,
      "learning_rate": 1.8489156626506028e-05,
      "loss": 0.0792,
      "step": 6270
    },
    {
      "epoch": 0.7566265060240964,
      "grad_norm": 17.117233276367188,
      "learning_rate": 1.848674698795181e-05,
      "loss": 0.0794,
      "step": 6280
    },
    {
      "epoch": 0.7578313253012048,
      "grad_norm": 0.09696631878614426,
      "learning_rate": 1.848433734939759e-05,
      "loss": 0.0042,
      "step": 6290
    },
    {
      "epoch": 0.7590361445783133,
      "grad_norm": 0.012490210123360157,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 0.1521,
      "step": 6300
    },
    {
      "epoch": 0.7602409638554217,
      "grad_norm": 0.06073200702667236,
      "learning_rate": 1.8479518072289157e-05,
      "loss": 0.1011,
      "step": 6310
    },
    {
      "epoch": 0.7614457831325301,
      "grad_norm": 0.17248284816741943,
      "learning_rate": 1.8477108433734942e-05,
      "loss": 0.0735,
      "step": 6320
    },
    {
      "epoch": 0.7626506024096386,
      "grad_norm": 2.8714284896850586,
      "learning_rate": 1.8474698795180727e-05,
      "loss": 0.05,
      "step": 6330
    },
    {
      "epoch": 0.763855421686747,
      "grad_norm": 0.2914513051509857,
      "learning_rate": 1.8472289156626508e-05,
      "loss": 0.0725,
      "step": 6340
    },
    {
      "epoch": 0.7650602409638554,
      "grad_norm": 12.01244831085205,
      "learning_rate": 1.846987951807229e-05,
      "loss": 0.0465,
      "step": 6350
    },
    {
      "epoch": 0.7662650602409639,
      "grad_norm": 0.08445332944393158,
      "learning_rate": 1.8467469879518074e-05,
      "loss": 0.0484,
      "step": 6360
    },
    {
      "epoch": 0.7674698795180723,
      "grad_norm": 16.424888610839844,
      "learning_rate": 1.8465060240963856e-05,
      "loss": 0.0778,
      "step": 6370
    },
    {
      "epoch": 0.7686746987951807,
      "grad_norm": 14.551756858825684,
      "learning_rate": 1.846265060240964e-05,
      "loss": 0.0461,
      "step": 6380
    },
    {
      "epoch": 0.7698795180722892,
      "grad_norm": 0.13880115747451782,
      "learning_rate": 1.8460240963855422e-05,
      "loss": 0.0253,
      "step": 6390
    },
    {
      "epoch": 0.7710843373493976,
      "grad_norm": 0.22526158392429352,
      "learning_rate": 1.8457831325301204e-05,
      "loss": 0.0528,
      "step": 6400
    },
    {
      "epoch": 0.772289156626506,
      "grad_norm": 0.027864405885338783,
      "learning_rate": 1.8455421686746992e-05,
      "loss": 0.0721,
      "step": 6410
    },
    {
      "epoch": 0.7734939759036145,
      "grad_norm": 66.25728607177734,
      "learning_rate": 1.8453012048192774e-05,
      "loss": 0.1111,
      "step": 6420
    },
    {
      "epoch": 0.7746987951807229,
      "grad_norm": 11.212754249572754,
      "learning_rate": 1.8450602409638555e-05,
      "loss": 0.0461,
      "step": 6430
    },
    {
      "epoch": 0.7759036144578313,
      "grad_norm": 0.0282963328063488,
      "learning_rate": 1.844819277108434e-05,
      "loss": 0.1122,
      "step": 6440
    },
    {
      "epoch": 0.7771084337349398,
      "grad_norm": 0.03628813102841377,
      "learning_rate": 1.844578313253012e-05,
      "loss": 0.0676,
      "step": 6450
    },
    {
      "epoch": 0.7783132530120482,
      "grad_norm": 0.024076713249087334,
      "learning_rate": 1.8443373493975906e-05,
      "loss": 0.0082,
      "step": 6460
    },
    {
      "epoch": 0.7795180722891566,
      "grad_norm": 56.0579833984375,
      "learning_rate": 1.8440963855421688e-05,
      "loss": 0.0711,
      "step": 6470
    },
    {
      "epoch": 0.7807228915662651,
      "grad_norm": 7.6595988273620605,
      "learning_rate": 1.8438554216867473e-05,
      "loss": 0.0226,
      "step": 6480
    },
    {
      "epoch": 0.7819277108433735,
      "grad_norm": 0.38698580861091614,
      "learning_rate": 1.8436144578313254e-05,
      "loss": 0.0453,
      "step": 6490
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 3.127385377883911,
      "learning_rate": 1.843373493975904e-05,
      "loss": 0.0766,
      "step": 6500
    },
    {
      "epoch": 0.7843373493975904,
      "grad_norm": 1.9556329250335693,
      "learning_rate": 1.843132530120482e-05,
      "loss": 0.0414,
      "step": 6510
    },
    {
      "epoch": 0.7855421686746988,
      "grad_norm": 1.2255655527114868,
      "learning_rate": 1.8428915662650605e-05,
      "loss": 0.0796,
      "step": 6520
    },
    {
      "epoch": 0.7867469879518072,
      "grad_norm": 0.08633343875408173,
      "learning_rate": 1.8426506024096387e-05,
      "loss": 0.1367,
      "step": 6530
    },
    {
      "epoch": 0.7879518072289157,
      "grad_norm": 12.365469932556152,
      "learning_rate": 1.8424096385542168e-05,
      "loss": 0.0257,
      "step": 6540
    },
    {
      "epoch": 0.7891566265060241,
      "grad_norm": 2.914175271987915,
      "learning_rate": 1.8421686746987953e-05,
      "loss": 0.0618,
      "step": 6550
    },
    {
      "epoch": 0.7903614457831325,
      "grad_norm": 1.3443621397018433,
      "learning_rate": 1.8419277108433738e-05,
      "loss": 0.0347,
      "step": 6560
    },
    {
      "epoch": 0.791566265060241,
      "grad_norm": 4.803246021270752,
      "learning_rate": 1.841686746987952e-05,
      "loss": 0.0154,
      "step": 6570
    },
    {
      "epoch": 0.7927710843373494,
      "grad_norm": 13.884220123291016,
      "learning_rate": 1.8414457831325304e-05,
      "loss": 0.062,
      "step": 6580
    },
    {
      "epoch": 0.7939759036144578,
      "grad_norm": 0.1360430121421814,
      "learning_rate": 1.8412048192771086e-05,
      "loss": 0.0033,
      "step": 6590
    },
    {
      "epoch": 0.7951807228915663,
      "grad_norm": 0.06879274547100067,
      "learning_rate": 1.8409638554216867e-05,
      "loss": 0.1428,
      "step": 6600
    },
    {
      "epoch": 0.7963855421686747,
      "grad_norm": 6.227417469024658,
      "learning_rate": 1.8407228915662652e-05,
      "loss": 0.1403,
      "step": 6610
    },
    {
      "epoch": 0.7975903614457831,
      "grad_norm": 19.65031623840332,
      "learning_rate": 1.8404819277108434e-05,
      "loss": 0.0756,
      "step": 6620
    },
    {
      "epoch": 0.7987951807228916,
      "grad_norm": 0.10778142511844635,
      "learning_rate": 1.840240963855422e-05,
      "loss": 0.0419,
      "step": 6630
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2645001411437988,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.0497,
      "step": 6640
    },
    {
      "epoch": 0.8012048192771084,
      "grad_norm": 2.55356502532959,
      "learning_rate": 1.8397590361445785e-05,
      "loss": 0.1035,
      "step": 6650
    },
    {
      "epoch": 0.8024096385542169,
      "grad_norm": 2.3889107704162598,
      "learning_rate": 1.8395180722891566e-05,
      "loss": 0.0658,
      "step": 6660
    },
    {
      "epoch": 0.8036144578313253,
      "grad_norm": 3.3763928413391113,
      "learning_rate": 1.839277108433735e-05,
      "loss": 0.0227,
      "step": 6670
    },
    {
      "epoch": 0.8048192771084337,
      "grad_norm": 0.20599640905857086,
      "learning_rate": 1.8390361445783133e-05,
      "loss": 0.0502,
      "step": 6680
    },
    {
      "epoch": 0.8060240963855422,
      "grad_norm": 0.1479814648628235,
      "learning_rate": 1.8387951807228918e-05,
      "loss": 0.0761,
      "step": 6690
    },
    {
      "epoch": 0.8072289156626506,
      "grad_norm": 0.09605603665113449,
      "learning_rate": 1.83855421686747e-05,
      "loss": 0.0293,
      "step": 6700
    },
    {
      "epoch": 0.808433734939759,
      "grad_norm": 0.015183312818408012,
      "learning_rate": 1.8383132530120484e-05,
      "loss": 0.0539,
      "step": 6710
    },
    {
      "epoch": 0.8096385542168675,
      "grad_norm": 2.0932388305664062,
      "learning_rate": 1.838072289156627e-05,
      "loss": 0.0672,
      "step": 6720
    },
    {
      "epoch": 0.810843373493976,
      "grad_norm": 0.2753429710865021,
      "learning_rate": 1.837831325301205e-05,
      "loss": 0.0553,
      "step": 6730
    },
    {
      "epoch": 0.8120481927710843,
      "grad_norm": 0.040621403604745865,
      "learning_rate": 1.8375903614457832e-05,
      "loss": 0.0798,
      "step": 6740
    },
    {
      "epoch": 0.8132530120481928,
      "grad_norm": 0.10054922848939896,
      "learning_rate": 1.8373493975903617e-05,
      "loss": 0.0241,
      "step": 6750
    },
    {
      "epoch": 0.8144578313253013,
      "grad_norm": 6.035674571990967,
      "learning_rate": 1.8371084337349398e-05,
      "loss": 0.0997,
      "step": 6760
    },
    {
      "epoch": 0.8156626506024096,
      "grad_norm": 0.03986305743455887,
      "learning_rate": 1.8368674698795183e-05,
      "loss": 0.0406,
      "step": 6770
    },
    {
      "epoch": 0.8168674698795181,
      "grad_norm": 11.431596755981445,
      "learning_rate": 1.8366265060240968e-05,
      "loss": 0.0536,
      "step": 6780
    },
    {
      "epoch": 0.8180722891566266,
      "grad_norm": 1.9602792263031006,
      "learning_rate": 1.836385542168675e-05,
      "loss": 0.0767,
      "step": 6790
    },
    {
      "epoch": 0.8192771084337349,
      "grad_norm": 0.10524170100688934,
      "learning_rate": 1.836144578313253e-05,
      "loss": 0.0665,
      "step": 6800
    },
    {
      "epoch": 0.8204819277108434,
      "grad_norm": 1.1696122884750366,
      "learning_rate": 1.8359036144578316e-05,
      "loss": 0.0261,
      "step": 6810
    },
    {
      "epoch": 0.8216867469879519,
      "grad_norm": 0.06886212527751923,
      "learning_rate": 1.8356626506024097e-05,
      "loss": 0.0424,
      "step": 6820
    },
    {
      "epoch": 0.8228915662650602,
      "grad_norm": 20.058706283569336,
      "learning_rate": 1.8354216867469882e-05,
      "loss": 0.0685,
      "step": 6830
    },
    {
      "epoch": 0.8240963855421687,
      "grad_norm": 0.04060295969247818,
      "learning_rate": 1.8351807228915664e-05,
      "loss": 0.0531,
      "step": 6840
    },
    {
      "epoch": 0.8253012048192772,
      "grad_norm": 29.090688705444336,
      "learning_rate": 1.8349397590361445e-05,
      "loss": 0.0627,
      "step": 6850
    },
    {
      "epoch": 0.8265060240963855,
      "grad_norm": 3.448434591293335,
      "learning_rate": 1.834698795180723e-05,
      "loss": 0.1416,
      "step": 6860
    },
    {
      "epoch": 0.827710843373494,
      "grad_norm": 15.116633415222168,
      "learning_rate": 1.8344578313253015e-05,
      "loss": 0.0469,
      "step": 6870
    },
    {
      "epoch": 0.8289156626506025,
      "grad_norm": 0.6498023867607117,
      "learning_rate": 1.8342168674698796e-05,
      "loss": 0.1065,
      "step": 6880
    },
    {
      "epoch": 0.8301204819277108,
      "grad_norm": 5.899216175079346,
      "learning_rate": 1.833975903614458e-05,
      "loss": 0.0471,
      "step": 6890
    },
    {
      "epoch": 0.8313253012048193,
      "grad_norm": 0.18265502154827118,
      "learning_rate": 1.8337349397590363e-05,
      "loss": 0.0329,
      "step": 6900
    },
    {
      "epoch": 0.8325301204819278,
      "grad_norm": 0.013453536666929722,
      "learning_rate": 1.8334939759036144e-05,
      "loss": 0.0912,
      "step": 6910
    },
    {
      "epoch": 0.8337349397590361,
      "grad_norm": 0.12773695588111877,
      "learning_rate": 1.833253012048193e-05,
      "loss": 0.0356,
      "step": 6920
    },
    {
      "epoch": 0.8349397590361446,
      "grad_norm": 0.02369503676891327,
      "learning_rate": 1.8330120481927714e-05,
      "loss": 0.0718,
      "step": 6930
    },
    {
      "epoch": 0.8361445783132531,
      "grad_norm": 1.5132323503494263,
      "learning_rate": 1.8327710843373495e-05,
      "loss": 0.0468,
      "step": 6940
    },
    {
      "epoch": 0.8373493975903614,
      "grad_norm": 19.337051391601562,
      "learning_rate": 1.832530120481928e-05,
      "loss": 0.1084,
      "step": 6950
    },
    {
      "epoch": 0.8385542168674699,
      "grad_norm": 1.8773705959320068,
      "learning_rate": 1.832289156626506e-05,
      "loss": 0.1174,
      "step": 6960
    },
    {
      "epoch": 0.8397590361445784,
      "grad_norm": 11.986834526062012,
      "learning_rate": 1.8320481927710843e-05,
      "loss": 0.0851,
      "step": 6970
    },
    {
      "epoch": 0.8409638554216867,
      "grad_norm": 1.7512770891189575,
      "learning_rate": 1.8318072289156628e-05,
      "loss": 0.0218,
      "step": 6980
    },
    {
      "epoch": 0.8421686746987952,
      "grad_norm": 0.1839735060930252,
      "learning_rate": 1.831566265060241e-05,
      "loss": 0.0445,
      "step": 6990
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 3.597428321838379,
      "learning_rate": 1.8313253012048194e-05,
      "loss": 0.1126,
      "step": 7000
    },
    {
      "epoch": 0.844578313253012,
      "grad_norm": 0.06584770977497101,
      "learning_rate": 1.831084337349398e-05,
      "loss": 0.1544,
      "step": 7010
    },
    {
      "epoch": 0.8457831325301205,
      "grad_norm": 0.2598741352558136,
      "learning_rate": 1.830843373493976e-05,
      "loss": 0.0507,
      "step": 7020
    },
    {
      "epoch": 0.846987951807229,
      "grad_norm": 0.441567599773407,
      "learning_rate": 1.8306024096385546e-05,
      "loss": 0.0974,
      "step": 7030
    },
    {
      "epoch": 0.8481927710843373,
      "grad_norm": 0.05620858445763588,
      "learning_rate": 1.8303614457831327e-05,
      "loss": 0.0311,
      "step": 7040
    },
    {
      "epoch": 0.8493975903614458,
      "grad_norm": 0.029620544984936714,
      "learning_rate": 1.830120481927711e-05,
      "loss": 0.0192,
      "step": 7050
    },
    {
      "epoch": 0.8506024096385543,
      "grad_norm": 5.267446517944336,
      "learning_rate": 1.8298795180722893e-05,
      "loss": 0.0817,
      "step": 7060
    },
    {
      "epoch": 0.8518072289156626,
      "grad_norm": 1.7902734279632568,
      "learning_rate": 1.8296385542168675e-05,
      "loss": 0.0447,
      "step": 7070
    },
    {
      "epoch": 0.8530120481927711,
      "grad_norm": 0.12548145651817322,
      "learning_rate": 1.829397590361446e-05,
      "loss": 0.043,
      "step": 7080
    },
    {
      "epoch": 0.8542168674698796,
      "grad_norm": 4.366673946380615,
      "learning_rate": 1.8291566265060245e-05,
      "loss": 0.038,
      "step": 7090
    },
    {
      "epoch": 0.8554216867469879,
      "grad_norm": 13.821609497070312,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 0.1632,
      "step": 7100
    },
    {
      "epoch": 0.8566265060240964,
      "grad_norm": 4.67619514465332,
      "learning_rate": 1.8286746987951808e-05,
      "loss": 0.0592,
      "step": 7110
    },
    {
      "epoch": 0.8578313253012049,
      "grad_norm": 10.79973316192627,
      "learning_rate": 1.8284337349397592e-05,
      "loss": 0.1085,
      "step": 7120
    },
    {
      "epoch": 0.8590361445783132,
      "grad_norm": 1.1131187677383423,
      "learning_rate": 1.8281927710843374e-05,
      "loss": 0.0139,
      "step": 7130
    },
    {
      "epoch": 0.8602409638554217,
      "grad_norm": 7.635936737060547,
      "learning_rate": 1.827951807228916e-05,
      "loss": 0.067,
      "step": 7140
    },
    {
      "epoch": 0.8614457831325302,
      "grad_norm": 0.03118804655969143,
      "learning_rate": 1.827710843373494e-05,
      "loss": 0.0116,
      "step": 7150
    },
    {
      "epoch": 0.8626506024096385,
      "grad_norm": 0.16109131276607513,
      "learning_rate": 1.8274698795180725e-05,
      "loss": 0.031,
      "step": 7160
    },
    {
      "epoch": 0.863855421686747,
      "grad_norm": 2.56244158744812,
      "learning_rate": 1.8272289156626507e-05,
      "loss": 0.0763,
      "step": 7170
    },
    {
      "epoch": 0.8650602409638555,
      "grad_norm": 0.12109069526195526,
      "learning_rate": 1.826987951807229e-05,
      "loss": 0.1278,
      "step": 7180
    },
    {
      "epoch": 0.8662650602409638,
      "grad_norm": 0.2957717776298523,
      "learning_rate": 1.8267469879518073e-05,
      "loss": 0.1091,
      "step": 7190
    },
    {
      "epoch": 0.8674698795180723,
      "grad_norm": 0.43071821331977844,
      "learning_rate": 1.8265060240963858e-05,
      "loss": 0.0496,
      "step": 7200
    },
    {
      "epoch": 0.8686746987951808,
      "grad_norm": 11.196775436401367,
      "learning_rate": 1.826265060240964e-05,
      "loss": 0.0306,
      "step": 7210
    },
    {
      "epoch": 0.8698795180722891,
      "grad_norm": 0.23276667296886444,
      "learning_rate": 1.826024096385542e-05,
      "loss": 0.0416,
      "step": 7220
    },
    {
      "epoch": 0.8710843373493976,
      "grad_norm": 13.129030227661133,
      "learning_rate": 1.8257831325301206e-05,
      "loss": 0.0964,
      "step": 7230
    },
    {
      "epoch": 0.8722891566265061,
      "grad_norm": 0.994471549987793,
      "learning_rate": 1.825542168674699e-05,
      "loss": 0.0778,
      "step": 7240
    },
    {
      "epoch": 0.8734939759036144,
      "grad_norm": 1.054405689239502,
      "learning_rate": 1.8253012048192772e-05,
      "loss": 0.0341,
      "step": 7250
    },
    {
      "epoch": 0.8746987951807229,
      "grad_norm": 0.3785322308540344,
      "learning_rate": 1.8250602409638557e-05,
      "loss": 0.0604,
      "step": 7260
    },
    {
      "epoch": 0.8759036144578313,
      "grad_norm": 0.1710824966430664,
      "learning_rate": 1.824819277108434e-05,
      "loss": 0.0756,
      "step": 7270
    },
    {
      "epoch": 0.8771084337349397,
      "grad_norm": 1.9895844459533691,
      "learning_rate": 1.824578313253012e-05,
      "loss": 0.0653,
      "step": 7280
    },
    {
      "epoch": 0.8783132530120482,
      "grad_norm": 0.11078851670026779,
      "learning_rate": 1.8243373493975905e-05,
      "loss": 0.121,
      "step": 7290
    },
    {
      "epoch": 0.8795180722891566,
      "grad_norm": 9.426015853881836,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 0.0306,
      "step": 7300
    },
    {
      "epoch": 0.880722891566265,
      "grad_norm": 0.08400370180606842,
      "learning_rate": 1.823855421686747e-05,
      "loss": 0.0694,
      "step": 7310
    },
    {
      "epoch": 0.8819277108433735,
      "grad_norm": 0.11478874832391739,
      "learning_rate": 1.8236144578313256e-05,
      "loss": 0.0824,
      "step": 7320
    },
    {
      "epoch": 0.8831325301204819,
      "grad_norm": 0.1325208991765976,
      "learning_rate": 1.8233734939759037e-05,
      "loss": 0.068,
      "step": 7330
    },
    {
      "epoch": 0.8843373493975903,
      "grad_norm": 28.64508056640625,
      "learning_rate": 1.8231325301204822e-05,
      "loss": 0.0571,
      "step": 7340
    },
    {
      "epoch": 0.8855421686746988,
      "grad_norm": 1.2248821258544922,
      "learning_rate": 1.8228915662650604e-05,
      "loss": 0.0458,
      "step": 7350
    },
    {
      "epoch": 0.8867469879518072,
      "grad_norm": 2.5150344371795654,
      "learning_rate": 1.8226506024096385e-05,
      "loss": 0.0878,
      "step": 7360
    },
    {
      "epoch": 0.8879518072289156,
      "grad_norm": 14.904451370239258,
      "learning_rate": 1.822409638554217e-05,
      "loss": 0.1112,
      "step": 7370
    },
    {
      "epoch": 0.8891566265060241,
      "grad_norm": 12.581685066223145,
      "learning_rate": 1.8221686746987955e-05,
      "loss": 0.0418,
      "step": 7380
    },
    {
      "epoch": 0.8903614457831325,
      "grad_norm": 0.15593284368515015,
      "learning_rate": 1.8219277108433737e-05,
      "loss": 0.0227,
      "step": 7390
    },
    {
      "epoch": 0.891566265060241,
      "grad_norm": 0.05376297980546951,
      "learning_rate": 1.821686746987952e-05,
      "loss": 0.0562,
      "step": 7400
    },
    {
      "epoch": 0.8927710843373494,
      "grad_norm": 3.714595079421997,
      "learning_rate": 1.8214457831325303e-05,
      "loss": 0.1144,
      "step": 7410
    },
    {
      "epoch": 0.8939759036144578,
      "grad_norm": 0.08108126372098923,
      "learning_rate": 1.8212048192771084e-05,
      "loss": 0.0744,
      "step": 7420
    },
    {
      "epoch": 0.8951807228915662,
      "grad_norm": 0.8154006600379944,
      "learning_rate": 1.820963855421687e-05,
      "loss": 0.0559,
      "step": 7430
    },
    {
      "epoch": 0.8963855421686747,
      "grad_norm": 12.38422679901123,
      "learning_rate": 1.820722891566265e-05,
      "loss": 0.0363,
      "step": 7440
    },
    {
      "epoch": 0.8975903614457831,
      "grad_norm": 0.3890780806541443,
      "learning_rate": 1.8204819277108436e-05,
      "loss": 0.1088,
      "step": 7450
    },
    {
      "epoch": 0.8987951807228916,
      "grad_norm": 1.7418500185012817,
      "learning_rate": 1.820240963855422e-05,
      "loss": 0.0651,
      "step": 7460
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.174935340881348,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0798,
      "step": 7470
    },
    {
      "epoch": 0.9012048192771084,
      "grad_norm": 5.052565097808838,
      "learning_rate": 1.8197590361445783e-05,
      "loss": 0.115,
      "step": 7480
    },
    {
      "epoch": 0.9024096385542169,
      "grad_norm": 15.419001579284668,
      "learning_rate": 1.8195180722891568e-05,
      "loss": 0.0888,
      "step": 7490
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 0.4233185946941376,
      "learning_rate": 1.819277108433735e-05,
      "loss": 0.0683,
      "step": 7500
    },
    {
      "epoch": 0.9048192771084337,
      "grad_norm": 0.08453721553087234,
      "learning_rate": 1.8190361445783135e-05,
      "loss": 0.0317,
      "step": 7510
    },
    {
      "epoch": 0.9060240963855422,
      "grad_norm": 6.32284688949585,
      "learning_rate": 1.8187951807228916e-05,
      "loss": 0.0513,
      "step": 7520
    },
    {
      "epoch": 0.9072289156626506,
      "grad_norm": 16.284542083740234,
      "learning_rate": 1.81855421686747e-05,
      "loss": 0.0773,
      "step": 7530
    },
    {
      "epoch": 0.908433734939759,
      "grad_norm": 8.99147891998291,
      "learning_rate": 1.8183132530120486e-05,
      "loss": 0.0383,
      "step": 7540
    },
    {
      "epoch": 0.9096385542168675,
      "grad_norm": 7.657818794250488,
      "learning_rate": 1.8180722891566267e-05,
      "loss": 0.1095,
      "step": 7550
    },
    {
      "epoch": 0.9108433734939759,
      "grad_norm": 0.44415783882141113,
      "learning_rate": 1.817831325301205e-05,
      "loss": 0.0852,
      "step": 7560
    },
    {
      "epoch": 0.9120481927710843,
      "grad_norm": 0.1781511902809143,
      "learning_rate": 1.8175903614457834e-05,
      "loss": 0.0468,
      "step": 7570
    },
    {
      "epoch": 0.9132530120481928,
      "grad_norm": 3.292872667312622,
      "learning_rate": 1.8173493975903615e-05,
      "loss": 0.0653,
      "step": 7580
    },
    {
      "epoch": 0.9144578313253012,
      "grad_norm": 0.2257971465587616,
      "learning_rate": 1.81710843373494e-05,
      "loss": 0.0559,
      "step": 7590
    },
    {
      "epoch": 0.9156626506024096,
      "grad_norm": 1.55734121799469,
      "learning_rate": 1.816867469879518e-05,
      "loss": 0.1089,
      "step": 7600
    },
    {
      "epoch": 0.9168674698795181,
      "grad_norm": 0.2575453817844391,
      "learning_rate": 1.8166265060240966e-05,
      "loss": 0.1496,
      "step": 7610
    },
    {
      "epoch": 0.9180722891566265,
      "grad_norm": 6.516826629638672,
      "learning_rate": 1.8163855421686748e-05,
      "loss": 0.0378,
      "step": 7620
    },
    {
      "epoch": 0.9192771084337349,
      "grad_norm": 4.0555195808410645,
      "learning_rate": 1.8161445783132533e-05,
      "loss": 0.0416,
      "step": 7630
    },
    {
      "epoch": 0.9204819277108434,
      "grad_norm": 0.08690311014652252,
      "learning_rate": 1.8159036144578314e-05,
      "loss": 0.0509,
      "step": 7640
    },
    {
      "epoch": 0.9216867469879518,
      "grad_norm": 10.841232299804688,
      "learning_rate": 1.81566265060241e-05,
      "loss": 0.0736,
      "step": 7650
    },
    {
      "epoch": 0.9228915662650602,
      "grad_norm": 0.012135722674429417,
      "learning_rate": 1.815421686746988e-05,
      "loss": 0.0576,
      "step": 7660
    },
    {
      "epoch": 0.9240963855421687,
      "grad_norm": 0.18553175032138824,
      "learning_rate": 1.8151807228915662e-05,
      "loss": 0.0067,
      "step": 7670
    },
    {
      "epoch": 0.9253012048192771,
      "grad_norm": 0.025301840156316757,
      "learning_rate": 1.8149397590361447e-05,
      "loss": 0.065,
      "step": 7680
    },
    {
      "epoch": 0.9265060240963855,
      "grad_norm": 0.08616632968187332,
      "learning_rate": 1.8146987951807232e-05,
      "loss": 0.0602,
      "step": 7690
    },
    {
      "epoch": 0.927710843373494,
      "grad_norm": 2.508099317550659,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 0.0334,
      "step": 7700
    },
    {
      "epoch": 0.9289156626506024,
      "grad_norm": 3.936577558517456,
      "learning_rate": 1.8142168674698798e-05,
      "loss": 0.0253,
      "step": 7710
    },
    {
      "epoch": 0.9301204819277108,
      "grad_norm": 0.35655146837234497,
      "learning_rate": 1.813975903614458e-05,
      "loss": 0.0787,
      "step": 7720
    },
    {
      "epoch": 0.9313253012048193,
      "grad_norm": 42.66510772705078,
      "learning_rate": 1.813734939759036e-05,
      "loss": 0.0284,
      "step": 7730
    },
    {
      "epoch": 0.9325301204819277,
      "grad_norm": 14.389334678649902,
      "learning_rate": 1.8134939759036146e-05,
      "loss": 0.1178,
      "step": 7740
    },
    {
      "epoch": 0.9337349397590361,
      "grad_norm": 0.08053667098283768,
      "learning_rate": 1.8132530120481927e-05,
      "loss": 0.0403,
      "step": 7750
    },
    {
      "epoch": 0.9349397590361446,
      "grad_norm": 3.821843385696411,
      "learning_rate": 1.8130120481927712e-05,
      "loss": 0.1048,
      "step": 7760
    },
    {
      "epoch": 0.936144578313253,
      "grad_norm": 0.3293715715408325,
      "learning_rate": 1.8127710843373497e-05,
      "loss": 0.0804,
      "step": 7770
    },
    {
      "epoch": 0.9373493975903614,
      "grad_norm": 2.4502434730529785,
      "learning_rate": 1.812530120481928e-05,
      "loss": 0.0478,
      "step": 7780
    },
    {
      "epoch": 0.9385542168674699,
      "grad_norm": 0.09711223095655441,
      "learning_rate": 1.812289156626506e-05,
      "loss": 0.047,
      "step": 7790
    },
    {
      "epoch": 0.9397590361445783,
      "grad_norm": 0.36053207516670227,
      "learning_rate": 1.8120481927710845e-05,
      "loss": 0.0594,
      "step": 7800
    },
    {
      "epoch": 0.9409638554216867,
      "grad_norm": 0.8627225756645203,
      "learning_rate": 1.8118072289156627e-05,
      "loss": 0.0152,
      "step": 7810
    },
    {
      "epoch": 0.9421686746987952,
      "grad_norm": 0.07944147288799286,
      "learning_rate": 1.811566265060241e-05,
      "loss": 0.06,
      "step": 7820
    },
    {
      "epoch": 0.9433734939759036,
      "grad_norm": 0.2880033850669861,
      "learning_rate": 1.8113253012048196e-05,
      "loss": 0.0179,
      "step": 7830
    },
    {
      "epoch": 0.944578313253012,
      "grad_norm": 4.23698091506958,
      "learning_rate": 1.8110843373493978e-05,
      "loss": 0.0713,
      "step": 7840
    },
    {
      "epoch": 0.9457831325301205,
      "grad_norm": 0.7944905161857605,
      "learning_rate": 1.8108433734939763e-05,
      "loss": 0.0128,
      "step": 7850
    },
    {
      "epoch": 0.946987951807229,
      "grad_norm": 0.031313925981521606,
      "learning_rate": 1.8106024096385544e-05,
      "loss": 0.0318,
      "step": 7860
    },
    {
      "epoch": 0.9481927710843373,
      "grad_norm": 4.758140563964844,
      "learning_rate": 1.8103614457831326e-05,
      "loss": 0.0863,
      "step": 7870
    },
    {
      "epoch": 0.9493975903614458,
      "grad_norm": 0.022900784388184547,
      "learning_rate": 1.810120481927711e-05,
      "loss": 0.0688,
      "step": 7880
    },
    {
      "epoch": 0.9506024096385542,
      "grad_norm": 0.29128381609916687,
      "learning_rate": 1.8098795180722892e-05,
      "loss": 0.0576,
      "step": 7890
    },
    {
      "epoch": 0.9518072289156626,
      "grad_norm": 0.03609472140669823,
      "learning_rate": 1.8096385542168677e-05,
      "loss": 0.0921,
      "step": 7900
    },
    {
      "epoch": 0.9530120481927711,
      "grad_norm": 4.53046989440918,
      "learning_rate": 1.809397590361446e-05,
      "loss": 0.0776,
      "step": 7910
    },
    {
      "epoch": 0.9542168674698795,
      "grad_norm": 0.9700274467468262,
      "learning_rate": 1.8091566265060243e-05,
      "loss": 0.0436,
      "step": 7920
    },
    {
      "epoch": 0.9554216867469879,
      "grad_norm": 0.20322929322719574,
      "learning_rate": 1.8089156626506025e-05,
      "loss": 0.0622,
      "step": 7930
    },
    {
      "epoch": 0.9566265060240964,
      "grad_norm": 0.21138224005699158,
      "learning_rate": 1.808674698795181e-05,
      "loss": 0.0187,
      "step": 7940
    },
    {
      "epoch": 0.9578313253012049,
      "grad_norm": 31.860668182373047,
      "learning_rate": 1.808433734939759e-05,
      "loss": 0.0975,
      "step": 7950
    },
    {
      "epoch": 0.9590361445783132,
      "grad_norm": 0.35759297013282776,
      "learning_rate": 1.8081927710843376e-05,
      "loss": 0.0179,
      "step": 7960
    },
    {
      "epoch": 0.9602409638554217,
      "grad_norm": 0.3936178684234619,
      "learning_rate": 1.8079518072289157e-05,
      "loss": 0.0897,
      "step": 7970
    },
    {
      "epoch": 0.9614457831325302,
      "grad_norm": 0.48442983627319336,
      "learning_rate": 1.8077108433734942e-05,
      "loss": 0.0263,
      "step": 7980
    },
    {
      "epoch": 0.9626506024096385,
      "grad_norm": 13.876100540161133,
      "learning_rate": 1.8074698795180724e-05,
      "loss": 0.0618,
      "step": 7990
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 2.8311569690704346,
      "learning_rate": 1.807228915662651e-05,
      "loss": 0.0362,
      "step": 8000
    },
    {
      "epoch": 0.9650602409638555,
      "grad_norm": 5.07774543762207,
      "learning_rate": 1.806987951807229e-05,
      "loss": 0.1193,
      "step": 8010
    },
    {
      "epoch": 0.9662650602409638,
      "grad_norm": 4.847685813903809,
      "learning_rate": 1.8067469879518075e-05,
      "loss": 0.1369,
      "step": 8020
    },
    {
      "epoch": 0.9674698795180723,
      "grad_norm": 2.264892816543579,
      "learning_rate": 1.8065060240963856e-05,
      "loss": 0.0483,
      "step": 8030
    },
    {
      "epoch": 0.9686746987951808,
      "grad_norm": 3.0864017009735107,
      "learning_rate": 1.8062650602409638e-05,
      "loss": 0.0677,
      "step": 8040
    },
    {
      "epoch": 0.9698795180722891,
      "grad_norm": 5.361974716186523,
      "learning_rate": 1.8060240963855423e-05,
      "loss": 0.0091,
      "step": 8050
    },
    {
      "epoch": 0.9710843373493976,
      "grad_norm": 0.12917202711105347,
      "learning_rate": 1.8057831325301208e-05,
      "loss": 0.0414,
      "step": 8060
    },
    {
      "epoch": 0.9722891566265061,
      "grad_norm": 0.07521948218345642,
      "learning_rate": 1.805542168674699e-05,
      "loss": 0.0962,
      "step": 8070
    },
    {
      "epoch": 0.9734939759036144,
      "grad_norm": 0.26777347922325134,
      "learning_rate": 1.8053012048192774e-05,
      "loss": 0.0773,
      "step": 8080
    },
    {
      "epoch": 0.9746987951807229,
      "grad_norm": 0.4206024706363678,
      "learning_rate": 1.8050602409638555e-05,
      "loss": 0.0903,
      "step": 8090
    },
    {
      "epoch": 0.9759036144578314,
      "grad_norm": 12.033708572387695,
      "learning_rate": 1.8048192771084337e-05,
      "loss": 0.0614,
      "step": 8100
    },
    {
      "epoch": 0.9771084337349397,
      "grad_norm": 31.248598098754883,
      "learning_rate": 1.8045783132530122e-05,
      "loss": 0.1213,
      "step": 8110
    },
    {
      "epoch": 0.9783132530120482,
      "grad_norm": 0.5669931173324585,
      "learning_rate": 1.8043373493975903e-05,
      "loss": 0.0755,
      "step": 8120
    },
    {
      "epoch": 0.9795180722891567,
      "grad_norm": 7.631187438964844,
      "learning_rate": 1.8040963855421688e-05,
      "loss": 0.0212,
      "step": 8130
    },
    {
      "epoch": 0.980722891566265,
      "grad_norm": 1.5911871194839478,
      "learning_rate": 1.8038554216867473e-05,
      "loss": 0.0652,
      "step": 8140
    },
    {
      "epoch": 0.9819277108433735,
      "grad_norm": 0.8982902765274048,
      "learning_rate": 1.8036144578313255e-05,
      "loss": 0.0908,
      "step": 8150
    },
    {
      "epoch": 0.983132530120482,
      "grad_norm": 17.19093132019043,
      "learning_rate": 1.803373493975904e-05,
      "loss": 0.1037,
      "step": 8160
    },
    {
      "epoch": 0.9843373493975903,
      "grad_norm": 18.44454002380371,
      "learning_rate": 1.803132530120482e-05,
      "loss": 0.1289,
      "step": 8170
    },
    {
      "epoch": 0.9855421686746988,
      "grad_norm": 0.027721261605620384,
      "learning_rate": 1.8028915662650602e-05,
      "loss": 0.0571,
      "step": 8180
    },
    {
      "epoch": 0.9867469879518073,
      "grad_norm": 0.02797529846429825,
      "learning_rate": 1.8026506024096387e-05,
      "loss": 0.0989,
      "step": 8190
    },
    {
      "epoch": 0.9879518072289156,
      "grad_norm": 7.197722434997559,
      "learning_rate": 1.802409638554217e-05,
      "loss": 0.0819,
      "step": 8200
    },
    {
      "epoch": 0.9891566265060241,
      "grad_norm": 0.06982110440731049,
      "learning_rate": 1.8021686746987954e-05,
      "loss": 0.0633,
      "step": 8210
    },
    {
      "epoch": 0.9903614457831326,
      "grad_norm": 22.73323631286621,
      "learning_rate": 1.801927710843374e-05,
      "loss": 0.0574,
      "step": 8220
    },
    {
      "epoch": 0.9915662650602409,
      "grad_norm": 1.0574463605880737,
      "learning_rate": 1.801686746987952e-05,
      "loss": 0.0612,
      "step": 8230
    },
    {
      "epoch": 0.9927710843373494,
      "grad_norm": 5.547861576080322,
      "learning_rate": 1.80144578313253e-05,
      "loss": 0.0635,
      "step": 8240
    },
    {
      "epoch": 0.9939759036144579,
      "grad_norm": 11.899737358093262,
      "learning_rate": 1.8012048192771086e-05,
      "loss": 0.114,
      "step": 8250
    },
    {
      "epoch": 0.9951807228915662,
      "grad_norm": 10.464584350585938,
      "learning_rate": 1.8009638554216868e-05,
      "loss": 0.1138,
      "step": 8260
    },
    {
      "epoch": 0.9963855421686747,
      "grad_norm": 0.3590559661388397,
      "learning_rate": 1.8007228915662653e-05,
      "loss": 0.0351,
      "step": 8270
    },
    {
      "epoch": 0.9975903614457832,
      "grad_norm": 0.4222937822341919,
      "learning_rate": 1.8004819277108437e-05,
      "loss": 0.0427,
      "step": 8280
    },
    {
      "epoch": 0.9987951807228915,
      "grad_norm": 0.5150004029273987,
      "learning_rate": 1.800240963855422e-05,
      "loss": 0.0363,
      "step": 8290
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.516811370849609,
      "learning_rate": 1.8e-05,
      "loss": 0.0558,
      "step": 8300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9799634420697413,
      "eval_f1": 0.9467389273033079,
      "eval_loss": 0.07056093961000443,
      "eval_precision": 0.9544084400904296,
      "eval_recall": 0.939191694475343,
      "eval_runtime": 3565.6677,
      "eval_samples_per_second": 11.973,
      "eval_steps_per_second": 0.499,
      "step": 8300
    },
    {
      "epoch": 1.0012048192771084,
      "grad_norm": 0.04263442009687424,
      "learning_rate": 1.7997590361445785e-05,
      "loss": 0.0202,
      "step": 8310
    },
    {
      "epoch": 1.002409638554217,
      "grad_norm": 0.8471524715423584,
      "learning_rate": 1.7995180722891567e-05,
      "loss": 0.0354,
      "step": 8320
    },
    {
      "epoch": 1.0036144578313253,
      "grad_norm": 22.8156681060791,
      "learning_rate": 1.799277108433735e-05,
      "loss": 0.1339,
      "step": 8330
    },
    {
      "epoch": 1.0048192771084337,
      "grad_norm": 5.1928300857543945,
      "learning_rate": 1.7990361445783133e-05,
      "loss": 0.0461,
      "step": 8340
    },
    {
      "epoch": 1.0060240963855422,
      "grad_norm": 0.11118225008249283,
      "learning_rate": 1.7987951807228915e-05,
      "loss": 0.0825,
      "step": 8350
    },
    {
      "epoch": 1.0072289156626506,
      "grad_norm": 0.2905580997467041,
      "learning_rate": 1.79855421686747e-05,
      "loss": 0.0275,
      "step": 8360
    },
    {
      "epoch": 1.008433734939759,
      "grad_norm": 2.9022419452667236,
      "learning_rate": 1.7983132530120484e-05,
      "loss": 0.0436,
      "step": 8370
    },
    {
      "epoch": 1.0096385542168675,
      "grad_norm": 2.9360790252685547,
      "learning_rate": 1.7980722891566266e-05,
      "loss": 0.0155,
      "step": 8380
    },
    {
      "epoch": 1.010843373493976,
      "grad_norm": 29.486635208129883,
      "learning_rate": 1.797831325301205e-05,
      "loss": 0.0577,
      "step": 8390
    },
    {
      "epoch": 1.0120481927710843,
      "grad_norm": 1.5007884502410889,
      "learning_rate": 1.7975903614457832e-05,
      "loss": 0.0188,
      "step": 8400
    },
    {
      "epoch": 1.0132530120481928,
      "grad_norm": 0.029564201831817627,
      "learning_rate": 1.7973493975903614e-05,
      "loss": 0.0952,
      "step": 8410
    },
    {
      "epoch": 1.0144578313253012,
      "grad_norm": 0.060352880507707596,
      "learning_rate": 1.79710843373494e-05,
      "loss": 0.0794,
      "step": 8420
    },
    {
      "epoch": 1.0156626506024096,
      "grad_norm": 0.04024665430188179,
      "learning_rate": 1.7968674698795183e-05,
      "loss": 0.0696,
      "step": 8430
    },
    {
      "epoch": 1.0168674698795181,
      "grad_norm": 0.049242109060287476,
      "learning_rate": 1.7966265060240965e-05,
      "loss": 0.0201,
      "step": 8440
    },
    {
      "epoch": 1.0180722891566265,
      "grad_norm": 0.20793898403644562,
      "learning_rate": 1.796385542168675e-05,
      "loss": 0.0875,
      "step": 8450
    },
    {
      "epoch": 1.0192771084337349,
      "grad_norm": 0.28506654500961304,
      "learning_rate": 1.796144578313253e-05,
      "loss": 0.0054,
      "step": 8460
    },
    {
      "epoch": 1.0204819277108435,
      "grad_norm": 0.04676082730293274,
      "learning_rate": 1.7959036144578316e-05,
      "loss": 0.0571,
      "step": 8470
    },
    {
      "epoch": 1.0216867469879518,
      "grad_norm": 0.049327924847602844,
      "learning_rate": 1.7956626506024098e-05,
      "loss": 0.0488,
      "step": 8480
    },
    {
      "epoch": 1.0228915662650602,
      "grad_norm": 3.0811002254486084,
      "learning_rate": 1.795421686746988e-05,
      "loss": 0.0263,
      "step": 8490
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 0.08255354315042496,
      "learning_rate": 1.7951807228915664e-05,
      "loss": 0.0319,
      "step": 8500
    },
    {
      "epoch": 1.0253012048192771,
      "grad_norm": 0.015305228531360626,
      "learning_rate": 1.794939759036145e-05,
      "loss": 0.0201,
      "step": 8510
    },
    {
      "epoch": 1.0265060240963855,
      "grad_norm": 0.18760567903518677,
      "learning_rate": 1.794698795180723e-05,
      "loss": 0.0262,
      "step": 8520
    },
    {
      "epoch": 1.027710843373494,
      "grad_norm": 0.07498887926340103,
      "learning_rate": 1.7944578313253015e-05,
      "loss": 0.073,
      "step": 8530
    },
    {
      "epoch": 1.0289156626506024,
      "grad_norm": 0.1521688848733902,
      "learning_rate": 1.7942168674698797e-05,
      "loss": 0.0752,
      "step": 8540
    },
    {
      "epoch": 1.0301204819277108,
      "grad_norm": 13.413827896118164,
      "learning_rate": 1.7939759036144578e-05,
      "loss": 0.1053,
      "step": 8550
    },
    {
      "epoch": 1.0313253012048194,
      "grad_norm": 0.021346746012568474,
      "learning_rate": 1.7937349397590363e-05,
      "loss": 0.0648,
      "step": 8560
    },
    {
      "epoch": 1.0325301204819277,
      "grad_norm": 0.25597691535949707,
      "learning_rate": 1.7934939759036145e-05,
      "loss": 0.0904,
      "step": 8570
    },
    {
      "epoch": 1.033734939759036,
      "grad_norm": 0.07023288309574127,
      "learning_rate": 1.793253012048193e-05,
      "loss": 0.0655,
      "step": 8580
    },
    {
      "epoch": 1.0349397590361447,
      "grad_norm": 0.11620287597179413,
      "learning_rate": 1.7930120481927714e-05,
      "loss": 0.0244,
      "step": 8590
    },
    {
      "epoch": 1.036144578313253,
      "grad_norm": 0.09547455608844757,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 0.0943,
      "step": 8600
    },
    {
      "epoch": 1.0373493975903614,
      "grad_norm": 0.04793223738670349,
      "learning_rate": 1.7925301204819277e-05,
      "loss": 0.0564,
      "step": 8610
    },
    {
      "epoch": 1.03855421686747,
      "grad_norm": 1.8206756114959717,
      "learning_rate": 1.7922891566265062e-05,
      "loss": 0.0651,
      "step": 8620
    },
    {
      "epoch": 1.0397590361445783,
      "grad_norm": 0.31395483016967773,
      "learning_rate": 1.7920481927710844e-05,
      "loss": 0.0296,
      "step": 8630
    },
    {
      "epoch": 1.0409638554216867,
      "grad_norm": 7.267261981964111,
      "learning_rate": 1.791807228915663e-05,
      "loss": 0.0634,
      "step": 8640
    },
    {
      "epoch": 1.0421686746987953,
      "grad_norm": 3.670818567276001,
      "learning_rate": 1.791566265060241e-05,
      "loss": 0.1293,
      "step": 8650
    },
    {
      "epoch": 1.0433734939759036,
      "grad_norm": 0.5090587735176086,
      "learning_rate": 1.7913253012048195e-05,
      "loss": 0.029,
      "step": 8660
    },
    {
      "epoch": 1.044578313253012,
      "grad_norm": 2.6350650787353516,
      "learning_rate": 1.7910843373493976e-05,
      "loss": 0.0833,
      "step": 8670
    },
    {
      "epoch": 1.0457831325301206,
      "grad_norm": 14.780839920043945,
      "learning_rate": 1.790843373493976e-05,
      "loss": 0.048,
      "step": 8680
    },
    {
      "epoch": 1.046987951807229,
      "grad_norm": 4.303904056549072,
      "learning_rate": 1.7906024096385543e-05,
      "loss": 0.0288,
      "step": 8690
    },
    {
      "epoch": 1.0481927710843373,
      "grad_norm": 0.3163380026817322,
      "learning_rate": 1.7903614457831327e-05,
      "loss": 0.0561,
      "step": 8700
    },
    {
      "epoch": 1.0493975903614459,
      "grad_norm": 0.018517648801207542,
      "learning_rate": 1.790120481927711e-05,
      "loss": 0.0068,
      "step": 8710
    },
    {
      "epoch": 1.0506024096385542,
      "grad_norm": 0.014535647816956043,
      "learning_rate": 1.789879518072289e-05,
      "loss": 0.0506,
      "step": 8720
    },
    {
      "epoch": 1.0518072289156626,
      "grad_norm": 1.1854524612426758,
      "learning_rate": 1.789638554216868e-05,
      "loss": 0.0873,
      "step": 8730
    },
    {
      "epoch": 1.0530120481927712,
      "grad_norm": 0.4547482132911682,
      "learning_rate": 1.789397590361446e-05,
      "loss": 0.0745,
      "step": 8740
    },
    {
      "epoch": 1.0542168674698795,
      "grad_norm": 0.9273072481155396,
      "learning_rate": 1.789156626506024e-05,
      "loss": 0.0871,
      "step": 8750
    },
    {
      "epoch": 1.0554216867469879,
      "grad_norm": 0.38798782229423523,
      "learning_rate": 1.7889156626506027e-05,
      "loss": 0.0837,
      "step": 8760
    },
    {
      "epoch": 1.0566265060240965,
      "grad_norm": 1.901289701461792,
      "learning_rate": 1.7886746987951808e-05,
      "loss": 0.0708,
      "step": 8770
    },
    {
      "epoch": 1.0578313253012048,
      "grad_norm": 2.288339853286743,
      "learning_rate": 1.7884337349397593e-05,
      "loss": 0.046,
      "step": 8780
    },
    {
      "epoch": 1.0590361445783132,
      "grad_norm": 0.1592932641506195,
      "learning_rate": 1.7881927710843374e-05,
      "loss": 0.031,
      "step": 8790
    },
    {
      "epoch": 1.0602409638554218,
      "grad_norm": 15.696284294128418,
      "learning_rate": 1.7879518072289156e-05,
      "loss": 0.0218,
      "step": 8800
    },
    {
      "epoch": 1.0614457831325301,
      "grad_norm": 1.6749993562698364,
      "learning_rate": 1.787710843373494e-05,
      "loss": 0.033,
      "step": 8810
    },
    {
      "epoch": 1.0626506024096385,
      "grad_norm": 4.230451583862305,
      "learning_rate": 1.7874698795180726e-05,
      "loss": 0.0778,
      "step": 8820
    },
    {
      "epoch": 1.063855421686747,
      "grad_norm": 0.03495277464389801,
      "learning_rate": 1.7872289156626507e-05,
      "loss": 0.0355,
      "step": 8830
    },
    {
      "epoch": 1.0650602409638554,
      "grad_norm": 4.705786228179932,
      "learning_rate": 1.7869879518072292e-05,
      "loss": 0.0633,
      "step": 8840
    },
    {
      "epoch": 1.0662650602409638,
      "grad_norm": 13.787447929382324,
      "learning_rate": 1.7867469879518073e-05,
      "loss": 0.133,
      "step": 8850
    },
    {
      "epoch": 1.0674698795180724,
      "grad_norm": 4.6052937507629395,
      "learning_rate": 1.7865060240963855e-05,
      "loss": 0.052,
      "step": 8860
    },
    {
      "epoch": 1.0686746987951807,
      "grad_norm": 4.5571088790893555,
      "learning_rate": 1.786265060240964e-05,
      "loss": 0.1115,
      "step": 8870
    },
    {
      "epoch": 1.069879518072289,
      "grad_norm": 0.7205978631973267,
      "learning_rate": 1.7860240963855425e-05,
      "loss": 0.0278,
      "step": 8880
    },
    {
      "epoch": 1.0710843373493977,
      "grad_norm": 0.06015786528587341,
      "learning_rate": 1.7857831325301206e-05,
      "loss": 0.0923,
      "step": 8890
    },
    {
      "epoch": 1.072289156626506,
      "grad_norm": 0.19503945112228394,
      "learning_rate": 1.785542168674699e-05,
      "loss": 0.0548,
      "step": 8900
    },
    {
      "epoch": 1.0734939759036144,
      "grad_norm": 0.09053132683038712,
      "learning_rate": 1.7853012048192772e-05,
      "loss": 0.0457,
      "step": 8910
    },
    {
      "epoch": 1.074698795180723,
      "grad_norm": 5.64591646194458,
      "learning_rate": 1.7850602409638554e-05,
      "loss": 0.087,
      "step": 8920
    },
    {
      "epoch": 1.0759036144578313,
      "grad_norm": 1.795422077178955,
      "learning_rate": 1.784819277108434e-05,
      "loss": 0.0972,
      "step": 8930
    },
    {
      "epoch": 1.0771084337349397,
      "grad_norm": 0.21119530498981476,
      "learning_rate": 1.784578313253012e-05,
      "loss": 0.0519,
      "step": 8940
    },
    {
      "epoch": 1.0783132530120483,
      "grad_norm": 14.151951789855957,
      "learning_rate": 1.7843373493975905e-05,
      "loss": 0.0646,
      "step": 8950
    },
    {
      "epoch": 1.0795180722891566,
      "grad_norm": 0.4967665374279022,
      "learning_rate": 1.784096385542169e-05,
      "loss": 0.0783,
      "step": 8960
    },
    {
      "epoch": 1.080722891566265,
      "grad_norm": 5.734614372253418,
      "learning_rate": 1.783855421686747e-05,
      "loss": 0.124,
      "step": 8970
    },
    {
      "epoch": 1.0819277108433736,
      "grad_norm": 0.40662652254104614,
      "learning_rate": 1.7836144578313256e-05,
      "loss": 0.0437,
      "step": 8980
    },
    {
      "epoch": 1.083132530120482,
      "grad_norm": 0.20031607151031494,
      "learning_rate": 1.7833734939759038e-05,
      "loss": 0.0389,
      "step": 8990
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 0.18784864246845245,
      "learning_rate": 1.783132530120482e-05,
      "loss": 0.1198,
      "step": 9000
    },
    {
      "epoch": 1.0855421686746989,
      "grad_norm": 51.87340545654297,
      "learning_rate": 1.7828915662650604e-05,
      "loss": 0.1729,
      "step": 9010
    },
    {
      "epoch": 1.0867469879518072,
      "grad_norm": 13.81423568725586,
      "learning_rate": 1.7826506024096386e-05,
      "loss": 0.0608,
      "step": 9020
    },
    {
      "epoch": 1.0879518072289156,
      "grad_norm": 2.443110942840576,
      "learning_rate": 1.782409638554217e-05,
      "loss": 0.0275,
      "step": 9030
    },
    {
      "epoch": 1.0891566265060242,
      "grad_norm": 0.3291020691394806,
      "learning_rate": 1.7821686746987955e-05,
      "loss": 0.0419,
      "step": 9040
    },
    {
      "epoch": 1.0903614457831325,
      "grad_norm": 0.9320626854896545,
      "learning_rate": 1.7819277108433737e-05,
      "loss": 0.0592,
      "step": 9050
    },
    {
      "epoch": 1.091566265060241,
      "grad_norm": 31.92787742614746,
      "learning_rate": 1.781686746987952e-05,
      "loss": 0.054,
      "step": 9060
    },
    {
      "epoch": 1.0927710843373495,
      "grad_norm": 6.119903564453125,
      "learning_rate": 1.7814457831325303e-05,
      "loss": 0.0551,
      "step": 9070
    },
    {
      "epoch": 1.0939759036144578,
      "grad_norm": 9.751004219055176,
      "learning_rate": 1.7812048192771085e-05,
      "loss": 0.0705,
      "step": 9080
    },
    {
      "epoch": 1.0951807228915662,
      "grad_norm": 6.741332530975342,
      "learning_rate": 1.780963855421687e-05,
      "loss": 0.0217,
      "step": 9090
    },
    {
      "epoch": 1.0963855421686748,
      "grad_norm": 0.06517569720745087,
      "learning_rate": 1.780722891566265e-05,
      "loss": 0.0252,
      "step": 9100
    },
    {
      "epoch": 1.0975903614457831,
      "grad_norm": 0.021449986845254898,
      "learning_rate": 1.7804819277108436e-05,
      "loss": 0.0796,
      "step": 9110
    },
    {
      "epoch": 1.0987951807228915,
      "grad_norm": 0.027268148958683014,
      "learning_rate": 1.7802409638554218e-05,
      "loss": 0.0232,
      "step": 9120
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.804734706878662,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 0.0536,
      "step": 9130
    },
    {
      "epoch": 1.1012048192771084,
      "grad_norm": 0.9013496041297913,
      "learning_rate": 1.7797590361445784e-05,
      "loss": 0.0158,
      "step": 9140
    },
    {
      "epoch": 1.1024096385542168,
      "grad_norm": 0.9676570892333984,
      "learning_rate": 1.779518072289157e-05,
      "loss": 0.0394,
      "step": 9150
    },
    {
      "epoch": 1.1036144578313254,
      "grad_norm": 4.783898830413818,
      "learning_rate": 1.779277108433735e-05,
      "loss": 0.0899,
      "step": 9160
    },
    {
      "epoch": 1.1048192771084338,
      "grad_norm": 0.01254954282194376,
      "learning_rate": 1.779036144578313e-05,
      "loss": 0.0572,
      "step": 9170
    },
    {
      "epoch": 1.106024096385542,
      "grad_norm": 5.234808921813965,
      "learning_rate": 1.7787951807228917e-05,
      "loss": 0.0647,
      "step": 9180
    },
    {
      "epoch": 1.1072289156626507,
      "grad_norm": 0.032504331320524216,
      "learning_rate": 1.77855421686747e-05,
      "loss": 0.0163,
      "step": 9190
    },
    {
      "epoch": 1.108433734939759,
      "grad_norm": 8.645243644714355,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 0.0788,
      "step": 9200
    },
    {
      "epoch": 1.1096385542168674,
      "grad_norm": 19.40375328063965,
      "learning_rate": 1.7780722891566268e-05,
      "loss": 0.0334,
      "step": 9210
    },
    {
      "epoch": 1.110843373493976,
      "grad_norm": 10.025708198547363,
      "learning_rate": 1.777831325301205e-05,
      "loss": 0.1033,
      "step": 9220
    },
    {
      "epoch": 1.1120481927710844,
      "grad_norm": 2.2061660289764404,
      "learning_rate": 1.777590361445783e-05,
      "loss": 0.0688,
      "step": 9230
    },
    {
      "epoch": 1.1132530120481927,
      "grad_norm": 0.4532669186592102,
      "learning_rate": 1.7773493975903616e-05,
      "loss": 0.0691,
      "step": 9240
    },
    {
      "epoch": 1.1144578313253013,
      "grad_norm": 0.02884742058813572,
      "learning_rate": 1.7771084337349397e-05,
      "loss": 0.0846,
      "step": 9250
    },
    {
      "epoch": 1.1156626506024097,
      "grad_norm": 1.7938803434371948,
      "learning_rate": 1.7768674698795182e-05,
      "loss": 0.0439,
      "step": 9260
    },
    {
      "epoch": 1.116867469879518,
      "grad_norm": 2.897596597671509,
      "learning_rate": 1.7766265060240967e-05,
      "loss": 0.0598,
      "step": 9270
    },
    {
      "epoch": 1.1180722891566266,
      "grad_norm": 1.1978200674057007,
      "learning_rate": 1.776385542168675e-05,
      "loss": 0.0546,
      "step": 9280
    },
    {
      "epoch": 1.119277108433735,
      "grad_norm": 0.0649748146533966,
      "learning_rate": 1.7761445783132533e-05,
      "loss": 0.0626,
      "step": 9290
    },
    {
      "epoch": 1.1204819277108433,
      "grad_norm": 4.195751190185547,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 0.0767,
      "step": 9300
    },
    {
      "epoch": 1.121686746987952,
      "grad_norm": 0.012626620940864086,
      "learning_rate": 1.7756626506024096e-05,
      "loss": 0.0771,
      "step": 9310
    },
    {
      "epoch": 1.1228915662650603,
      "grad_norm": 2.1813104152679443,
      "learning_rate": 1.775421686746988e-05,
      "loss": 0.0116,
      "step": 9320
    },
    {
      "epoch": 1.1240963855421686,
      "grad_norm": 0.44210121035575867,
      "learning_rate": 1.7751807228915666e-05,
      "loss": 0.0734,
      "step": 9330
    },
    {
      "epoch": 1.1253012048192772,
      "grad_norm": 0.3207263648509979,
      "learning_rate": 1.7749397590361447e-05,
      "loss": 0.0908,
      "step": 9340
    },
    {
      "epoch": 1.1265060240963856,
      "grad_norm": 0.028858762234449387,
      "learning_rate": 1.7746987951807232e-05,
      "loss": 0.0179,
      "step": 9350
    },
    {
      "epoch": 1.127710843373494,
      "grad_norm": 0.17256051301956177,
      "learning_rate": 1.7744578313253014e-05,
      "loss": 0.1307,
      "step": 9360
    },
    {
      "epoch": 1.1289156626506025,
      "grad_norm": 0.05278174579143524,
      "learning_rate": 1.7742168674698795e-05,
      "loss": 0.1214,
      "step": 9370
    },
    {
      "epoch": 1.1301204819277109,
      "grad_norm": 11.875151634216309,
      "learning_rate": 1.773975903614458e-05,
      "loss": 0.0388,
      "step": 9380
    },
    {
      "epoch": 1.1313253012048192,
      "grad_norm": 0.30023524165153503,
      "learning_rate": 1.773734939759036e-05,
      "loss": 0.0809,
      "step": 9390
    },
    {
      "epoch": 1.1325301204819278,
      "grad_norm": 3.858175039291382,
      "learning_rate": 1.7734939759036146e-05,
      "loss": 0.054,
      "step": 9400
    },
    {
      "epoch": 1.1337349397590362,
      "grad_norm": 12.463860511779785,
      "learning_rate": 1.773253012048193e-05,
      "loss": 0.0575,
      "step": 9410
    },
    {
      "epoch": 1.1349397590361445,
      "grad_norm": 0.019722016528248787,
      "learning_rate": 1.7730120481927713e-05,
      "loss": 0.1075,
      "step": 9420
    },
    {
      "epoch": 1.136144578313253,
      "grad_norm": 3.949244260787964,
      "learning_rate": 1.7727710843373494e-05,
      "loss": 0.0747,
      "step": 9430
    },
    {
      "epoch": 1.1373493975903615,
      "grad_norm": 0.07861902564764023,
      "learning_rate": 1.772530120481928e-05,
      "loss": 0.0705,
      "step": 9440
    },
    {
      "epoch": 1.1385542168674698,
      "grad_norm": 0.12047655135393143,
      "learning_rate": 1.772289156626506e-05,
      "loss": 0.0346,
      "step": 9450
    },
    {
      "epoch": 1.1397590361445784,
      "grad_norm": 3.1828813552856445,
      "learning_rate": 1.7720481927710845e-05,
      "loss": 0.0604,
      "step": 9460
    },
    {
      "epoch": 1.1409638554216868,
      "grad_norm": 0.47149521112442017,
      "learning_rate": 1.7718072289156627e-05,
      "loss": 0.0761,
      "step": 9470
    },
    {
      "epoch": 1.1421686746987951,
      "grad_norm": 0.09110575914382935,
      "learning_rate": 1.7715662650602412e-05,
      "loss": 0.0621,
      "step": 9480
    },
    {
      "epoch": 1.1433734939759037,
      "grad_norm": 0.034380484372377396,
      "learning_rate": 1.7713253012048193e-05,
      "loss": 0.0442,
      "step": 9490
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 0.4178677797317505,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 0.0531,
      "step": 9500
    },
    {
      "epoch": 1.1457831325301204,
      "grad_norm": 5.607483863830566,
      "learning_rate": 1.770843373493976e-05,
      "loss": 0.0771,
      "step": 9510
    },
    {
      "epoch": 1.146987951807229,
      "grad_norm": 1.5986813306808472,
      "learning_rate": 1.7706024096385545e-05,
      "loss": 0.1265,
      "step": 9520
    },
    {
      "epoch": 1.1481927710843374,
      "grad_norm": 0.04300132393836975,
      "learning_rate": 1.7703614457831326e-05,
      "loss": 0.0266,
      "step": 9530
    },
    {
      "epoch": 1.1493975903614457,
      "grad_norm": 0.13912244141101837,
      "learning_rate": 1.7701204819277108e-05,
      "loss": 0.0834,
      "step": 9540
    },
    {
      "epoch": 1.1506024096385543,
      "grad_norm": 0.046842657029628754,
      "learning_rate": 1.7698795180722892e-05,
      "loss": 0.0381,
      "step": 9550
    },
    {
      "epoch": 1.1518072289156627,
      "grad_norm": 0.302588552236557,
      "learning_rate": 1.7696385542168677e-05,
      "loss": 0.0327,
      "step": 9560
    },
    {
      "epoch": 1.153012048192771,
      "grad_norm": 1.8100035190582275,
      "learning_rate": 1.769397590361446e-05,
      "loss": 0.1098,
      "step": 9570
    },
    {
      "epoch": 1.1542168674698796,
      "grad_norm": 2.0817954540252686,
      "learning_rate": 1.7691566265060244e-05,
      "loss": 0.0337,
      "step": 9580
    },
    {
      "epoch": 1.155421686746988,
      "grad_norm": 0.08982765674591064,
      "learning_rate": 1.7689156626506025e-05,
      "loss": 0.0312,
      "step": 9590
    },
    {
      "epoch": 1.1566265060240963,
      "grad_norm": 0.011339648626744747,
      "learning_rate": 1.768674698795181e-05,
      "loss": 0.0175,
      "step": 9600
    },
    {
      "epoch": 1.157831325301205,
      "grad_norm": 3.7376255989074707,
      "learning_rate": 1.768433734939759e-05,
      "loss": 0.088,
      "step": 9610
    },
    {
      "epoch": 1.1590361445783133,
      "grad_norm": 27.837581634521484,
      "learning_rate": 1.7681927710843373e-05,
      "loss": 0.0453,
      "step": 9620
    },
    {
      "epoch": 1.1602409638554216,
      "grad_norm": 3.971424102783203,
      "learning_rate": 1.7679518072289158e-05,
      "loss": 0.1093,
      "step": 9630
    },
    {
      "epoch": 1.16144578313253,
      "grad_norm": 6.652427673339844,
      "learning_rate": 1.7677108433734943e-05,
      "loss": 0.0773,
      "step": 9640
    },
    {
      "epoch": 1.1626506024096386,
      "grad_norm": 0.7947818040847778,
      "learning_rate": 1.7674698795180724e-05,
      "loss": 0.1149,
      "step": 9650
    },
    {
      "epoch": 1.163855421686747,
      "grad_norm": 0.10749167948961258,
      "learning_rate": 1.767228915662651e-05,
      "loss": 0.0557,
      "step": 9660
    },
    {
      "epoch": 1.1650602409638555,
      "grad_norm": 0.1519334614276886,
      "learning_rate": 1.766987951807229e-05,
      "loss": 0.0301,
      "step": 9670
    },
    {
      "epoch": 1.1662650602409639,
      "grad_norm": 4.451364040374756,
      "learning_rate": 1.7667469879518072e-05,
      "loss": 0.0716,
      "step": 9680
    },
    {
      "epoch": 1.1674698795180722,
      "grad_norm": 2.045534610748291,
      "learning_rate": 1.7665060240963857e-05,
      "loss": 0.0643,
      "step": 9690
    },
    {
      "epoch": 1.1686746987951806,
      "grad_norm": 0.11095459014177322,
      "learning_rate": 1.766265060240964e-05,
      "loss": 0.0695,
      "step": 9700
    },
    {
      "epoch": 1.1698795180722892,
      "grad_norm": 7.639885425567627,
      "learning_rate": 1.7660240963855423e-05,
      "loss": 0.0912,
      "step": 9710
    },
    {
      "epoch": 1.1710843373493975,
      "grad_norm": 0.5669119954109192,
      "learning_rate": 1.7657831325301208e-05,
      "loss": 0.0877,
      "step": 9720
    },
    {
      "epoch": 1.1722891566265061,
      "grad_norm": 0.37978971004486084,
      "learning_rate": 1.765542168674699e-05,
      "loss": 0.0341,
      "step": 9730
    },
    {
      "epoch": 1.1734939759036145,
      "grad_norm": 38.5218505859375,
      "learning_rate": 1.765301204819277e-05,
      "loss": 0.0805,
      "step": 9740
    },
    {
      "epoch": 1.1746987951807228,
      "grad_norm": 0.03706361725926399,
      "learning_rate": 1.7650602409638556e-05,
      "loss": 0.0526,
      "step": 9750
    },
    {
      "epoch": 1.1759036144578312,
      "grad_norm": 21.560546875,
      "learning_rate": 1.7648192771084337e-05,
      "loss": 0.1395,
      "step": 9760
    },
    {
      "epoch": 1.1771084337349398,
      "grad_norm": 0.10627513378858566,
      "learning_rate": 1.7645783132530122e-05,
      "loss": 0.0569,
      "step": 9770
    },
    {
      "epoch": 1.1783132530120481,
      "grad_norm": 1.6494712829589844,
      "learning_rate": 1.7643373493975907e-05,
      "loss": 0.0251,
      "step": 9780
    },
    {
      "epoch": 1.1795180722891567,
      "grad_norm": 0.00969557836651802,
      "learning_rate": 1.764096385542169e-05,
      "loss": 0.0379,
      "step": 9790
    },
    {
      "epoch": 1.180722891566265,
      "grad_norm": 11.686159133911133,
      "learning_rate": 1.763855421686747e-05,
      "loss": 0.0816,
      "step": 9800
    },
    {
      "epoch": 1.1819277108433734,
      "grad_norm": 0.2865637540817261,
      "learning_rate": 1.7636144578313255e-05,
      "loss": 0.0977,
      "step": 9810
    },
    {
      "epoch": 1.1831325301204818,
      "grad_norm": 0.9801673293113708,
      "learning_rate": 1.7633734939759036e-05,
      "loss": 0.0624,
      "step": 9820
    },
    {
      "epoch": 1.1843373493975904,
      "grad_norm": 10.861432075500488,
      "learning_rate": 1.763132530120482e-05,
      "loss": 0.0472,
      "step": 9830
    },
    {
      "epoch": 1.1855421686746987,
      "grad_norm": 0.4787543714046478,
      "learning_rate": 1.7628915662650603e-05,
      "loss": 0.0521,
      "step": 9840
    },
    {
      "epoch": 1.1867469879518073,
      "grad_norm": 8.5889310836792,
      "learning_rate": 1.7626506024096384e-05,
      "loss": 0.1304,
      "step": 9850
    },
    {
      "epoch": 1.1879518072289157,
      "grad_norm": 11.049651145935059,
      "learning_rate": 1.7624096385542173e-05,
      "loss": 0.0885,
      "step": 9860
    },
    {
      "epoch": 1.189156626506024,
      "grad_norm": 0.2704319953918457,
      "learning_rate": 1.7621686746987954e-05,
      "loss": 0.0599,
      "step": 9870
    },
    {
      "epoch": 1.1903614457831324,
      "grad_norm": 3.5168874263763428,
      "learning_rate": 1.7619277108433735e-05,
      "loss": 0.0422,
      "step": 9880
    },
    {
      "epoch": 1.191566265060241,
      "grad_norm": 3.4447617530822754,
      "learning_rate": 1.761686746987952e-05,
      "loss": 0.0451,
      "step": 9890
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 0.016733109951019287,
      "learning_rate": 1.7614457831325302e-05,
      "loss": 0.0916,
      "step": 9900
    },
    {
      "epoch": 1.193975903614458,
      "grad_norm": 0.014773274771869183,
      "learning_rate": 1.7612048192771087e-05,
      "loss": 0.0611,
      "step": 9910
    },
    {
      "epoch": 1.1951807228915663,
      "grad_norm": 6.16058874130249,
      "learning_rate": 1.7609638554216868e-05,
      "loss": 0.0764,
      "step": 9920
    },
    {
      "epoch": 1.1963855421686747,
      "grad_norm": 0.12414900958538055,
      "learning_rate": 1.7607228915662653e-05,
      "loss": 0.0827,
      "step": 9930
    },
    {
      "epoch": 1.197590361445783,
      "grad_norm": 0.54425048828125,
      "learning_rate": 1.7604819277108435e-05,
      "loss": 0.0271,
      "step": 9940
    },
    {
      "epoch": 1.1987951807228916,
      "grad_norm": 14.175719261169434,
      "learning_rate": 1.760240963855422e-05,
      "loss": 0.1029,
      "step": 9950
    },
    {
      "epoch": 1.2,
      "grad_norm": 4.936562538146973,
      "learning_rate": 1.76e-05,
      "loss": 0.0351,
      "step": 9960
    },
    {
      "epoch": 1.2012048192771085,
      "grad_norm": 1.7156850099563599,
      "learning_rate": 1.7597590361445786e-05,
      "loss": 0.044,
      "step": 9970
    },
    {
      "epoch": 1.202409638554217,
      "grad_norm": 0.07784266024827957,
      "learning_rate": 1.7595180722891567e-05,
      "loss": 0.0433,
      "step": 9980
    },
    {
      "epoch": 1.2036144578313253,
      "grad_norm": 1.1425598859786987,
      "learning_rate": 1.759277108433735e-05,
      "loss": 0.0961,
      "step": 9990
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 0.8016011118888855,
      "learning_rate": 1.7590361445783134e-05,
      "loss": 0.0883,
      "step": 10000
    },
    {
      "epoch": 1.2060240963855422,
      "grad_norm": 0.08491089940071106,
      "learning_rate": 1.758795180722892e-05,
      "loss": 0.0417,
      "step": 10010
    },
    {
      "epoch": 1.2072289156626506,
      "grad_norm": 0.4423653483390808,
      "learning_rate": 1.75855421686747e-05,
      "loss": 0.0715,
      "step": 10020
    },
    {
      "epoch": 1.2084337349397591,
      "grad_norm": 1.8895809650421143,
      "learning_rate": 1.7583132530120485e-05,
      "loss": 0.0231,
      "step": 10030
    },
    {
      "epoch": 1.2096385542168675,
      "grad_norm": 3.582592010498047,
      "learning_rate": 1.7580722891566266e-05,
      "loss": 0.1181,
      "step": 10040
    },
    {
      "epoch": 1.2108433734939759,
      "grad_norm": 0.0910077691078186,
      "learning_rate": 1.7578313253012048e-05,
      "loss": 0.0539,
      "step": 10050
    },
    {
      "epoch": 1.2120481927710842,
      "grad_norm": 3.164793014526367,
      "learning_rate": 1.7575903614457833e-05,
      "loss": 0.0395,
      "step": 10060
    },
    {
      "epoch": 1.2132530120481928,
      "grad_norm": 0.4995759427547455,
      "learning_rate": 1.7573493975903614e-05,
      "loss": 0.0148,
      "step": 10070
    },
    {
      "epoch": 1.2144578313253012,
      "grad_norm": 17.16942024230957,
      "learning_rate": 1.75710843373494e-05,
      "loss": 0.0252,
      "step": 10080
    },
    {
      "epoch": 1.2156626506024097,
      "grad_norm": 6.3285980224609375,
      "learning_rate": 1.7568674698795184e-05,
      "loss": 0.0538,
      "step": 10090
    },
    {
      "epoch": 1.216867469879518,
      "grad_norm": 30.841663360595703,
      "learning_rate": 1.7566265060240965e-05,
      "loss": 0.0769,
      "step": 10100
    },
    {
      "epoch": 1.2180722891566265,
      "grad_norm": 4.266582489013672,
      "learning_rate": 1.7563855421686747e-05,
      "loss": 0.0794,
      "step": 10110
    },
    {
      "epoch": 1.2192771084337348,
      "grad_norm": 0.6429986357688904,
      "learning_rate": 1.7561445783132532e-05,
      "loss": 0.0652,
      "step": 10120
    },
    {
      "epoch": 1.2204819277108434,
      "grad_norm": 0.02924434468150139,
      "learning_rate": 1.7559036144578313e-05,
      "loss": 0.0371,
      "step": 10130
    },
    {
      "epoch": 1.2216867469879518,
      "grad_norm": 0.06004161760210991,
      "learning_rate": 1.7556626506024098e-05,
      "loss": 0.0313,
      "step": 10140
    },
    {
      "epoch": 1.2228915662650603,
      "grad_norm": 0.9885525703430176,
      "learning_rate": 1.755421686746988e-05,
      "loss": 0.0477,
      "step": 10150
    },
    {
      "epoch": 1.2240963855421687,
      "grad_norm": 14.172868728637695,
      "learning_rate": 1.7551807228915664e-05,
      "loss": 0.1097,
      "step": 10160
    },
    {
      "epoch": 1.225301204819277,
      "grad_norm": 1.284524917602539,
      "learning_rate": 1.754939759036145e-05,
      "loss": 0.0514,
      "step": 10170
    },
    {
      "epoch": 1.2265060240963854,
      "grad_norm": 0.13230036199092865,
      "learning_rate": 1.754698795180723e-05,
      "loss": 0.0958,
      "step": 10180
    },
    {
      "epoch": 1.227710843373494,
      "grad_norm": 0.43689286708831787,
      "learning_rate": 1.7544578313253012e-05,
      "loss": 0.0266,
      "step": 10190
    },
    {
      "epoch": 1.2289156626506024,
      "grad_norm": 5.179139614105225,
      "learning_rate": 1.7542168674698797e-05,
      "loss": 0.0857,
      "step": 10200
    },
    {
      "epoch": 1.230120481927711,
      "grad_norm": 3.2787814140319824,
      "learning_rate": 1.753975903614458e-05,
      "loss": 0.0878,
      "step": 10210
    },
    {
      "epoch": 1.2313253012048193,
      "grad_norm": 0.09680260717868805,
      "learning_rate": 1.7537349397590363e-05,
      "loss": 0.0261,
      "step": 10220
    },
    {
      "epoch": 1.2325301204819277,
      "grad_norm": 21.85249900817871,
      "learning_rate": 1.753493975903615e-05,
      "loss": 0.0794,
      "step": 10230
    },
    {
      "epoch": 1.233734939759036,
      "grad_norm": 0.2453385293483734,
      "learning_rate": 1.753253012048193e-05,
      "loss": 0.0191,
      "step": 10240
    },
    {
      "epoch": 1.2349397590361446,
      "grad_norm": 0.5905119776725769,
      "learning_rate": 1.753012048192771e-05,
      "loss": 0.0392,
      "step": 10250
    },
    {
      "epoch": 1.236144578313253,
      "grad_norm": 0.043273329734802246,
      "learning_rate": 1.7527710843373496e-05,
      "loss": 0.0258,
      "step": 10260
    },
    {
      "epoch": 1.2373493975903616,
      "grad_norm": 12.07910442352295,
      "learning_rate": 1.7525301204819278e-05,
      "loss": 0.1802,
      "step": 10270
    },
    {
      "epoch": 1.23855421686747,
      "grad_norm": 11.9879150390625,
      "learning_rate": 1.7522891566265063e-05,
      "loss": 0.0376,
      "step": 10280
    },
    {
      "epoch": 1.2397590361445783,
      "grad_norm": 16.961301803588867,
      "learning_rate": 1.7520481927710844e-05,
      "loss": 0.059,
      "step": 10290
    },
    {
      "epoch": 1.2409638554216866,
      "grad_norm": 0.6515614986419678,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 0.0531,
      "step": 10300
    },
    {
      "epoch": 1.2421686746987952,
      "grad_norm": 4.987651348114014,
      "learning_rate": 1.751566265060241e-05,
      "loss": 0.0872,
      "step": 10310
    },
    {
      "epoch": 1.2433734939759036,
      "grad_norm": 2.4277327060699463,
      "learning_rate": 1.7513253012048195e-05,
      "loss": 0.0552,
      "step": 10320
    },
    {
      "epoch": 1.2445783132530122,
      "grad_norm": 0.08933177590370178,
      "learning_rate": 1.7510843373493977e-05,
      "loss": 0.0501,
      "step": 10330
    },
    {
      "epoch": 1.2457831325301205,
      "grad_norm": 16.687814712524414,
      "learning_rate": 1.750843373493976e-05,
      "loss": 0.0412,
      "step": 10340
    },
    {
      "epoch": 1.2469879518072289,
      "grad_norm": 0.47151023149490356,
      "learning_rate": 1.7506024096385543e-05,
      "loss": 0.1085,
      "step": 10350
    },
    {
      "epoch": 1.2481927710843372,
      "grad_norm": 0.03175288811326027,
      "learning_rate": 1.7503614457831325e-05,
      "loss": 0.0349,
      "step": 10360
    },
    {
      "epoch": 1.2493975903614458,
      "grad_norm": 0.12225323915481567,
      "learning_rate": 1.750120481927711e-05,
      "loss": 0.0233,
      "step": 10370
    },
    {
      "epoch": 1.2506024096385542,
      "grad_norm": 0.05312872305512428,
      "learning_rate": 1.7498795180722894e-05,
      "loss": 0.0192,
      "step": 10380
    },
    {
      "epoch": 1.2518072289156628,
      "grad_norm": 0.3638615608215332,
      "learning_rate": 1.7496385542168676e-05,
      "loss": 0.0387,
      "step": 10390
    },
    {
      "epoch": 1.2530120481927711,
      "grad_norm": 0.1219014972448349,
      "learning_rate": 1.749397590361446e-05,
      "loss": 0.0649,
      "step": 10400
    },
    {
      "epoch": 1.2542168674698795,
      "grad_norm": 16.435108184814453,
      "learning_rate": 1.7491566265060242e-05,
      "loss": 0.0271,
      "step": 10410
    },
    {
      "epoch": 1.2554216867469878,
      "grad_norm": 0.1561826467514038,
      "learning_rate": 1.7489156626506027e-05,
      "loss": 0.0177,
      "step": 10420
    },
    {
      "epoch": 1.2566265060240964,
      "grad_norm": 4.140707492828369,
      "learning_rate": 1.748674698795181e-05,
      "loss": 0.1502,
      "step": 10430
    },
    {
      "epoch": 1.2578313253012048,
      "grad_norm": 11.967597007751465,
      "learning_rate": 1.748433734939759e-05,
      "loss": 0.0199,
      "step": 10440
    },
    {
      "epoch": 1.2590361445783134,
      "grad_norm": 2.2454423904418945,
      "learning_rate": 1.7481927710843375e-05,
      "loss": 0.0954,
      "step": 10450
    },
    {
      "epoch": 1.2602409638554217,
      "grad_norm": 0.3320407271385193,
      "learning_rate": 1.747951807228916e-05,
      "loss": 0.0979,
      "step": 10460
    },
    {
      "epoch": 1.26144578313253,
      "grad_norm": 4.396557331085205,
      "learning_rate": 1.747710843373494e-05,
      "loss": 0.0816,
      "step": 10470
    },
    {
      "epoch": 1.2626506024096384,
      "grad_norm": 0.09031447023153305,
      "learning_rate": 1.7474698795180726e-05,
      "loss": 0.0635,
      "step": 10480
    },
    {
      "epoch": 1.263855421686747,
      "grad_norm": 9.96272087097168,
      "learning_rate": 1.7472289156626508e-05,
      "loss": 0.0685,
      "step": 10490
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 22.96045684814453,
      "learning_rate": 1.746987951807229e-05,
      "loss": 0.0548,
      "step": 10500
    },
    {
      "epoch": 1.266265060240964,
      "grad_norm": 6.1819682121276855,
      "learning_rate": 1.7467469879518074e-05,
      "loss": 0.0966,
      "step": 10510
    },
    {
      "epoch": 1.2674698795180723,
      "grad_norm": 26.432395935058594,
      "learning_rate": 1.7465060240963855e-05,
      "loss": 0.0578,
      "step": 10520
    },
    {
      "epoch": 1.2686746987951807,
      "grad_norm": 9.251382827758789,
      "learning_rate": 1.746265060240964e-05,
      "loss": 0.0683,
      "step": 10530
    },
    {
      "epoch": 1.269879518072289,
      "grad_norm": 0.042068079113960266,
      "learning_rate": 1.7460240963855425e-05,
      "loss": 0.0238,
      "step": 10540
    },
    {
      "epoch": 1.2710843373493976,
      "grad_norm": 0.17758598923683167,
      "learning_rate": 1.7457831325301207e-05,
      "loss": 0.0181,
      "step": 10550
    },
    {
      "epoch": 1.272289156626506,
      "grad_norm": 2.330706834793091,
      "learning_rate": 1.7455421686746988e-05,
      "loss": 0.0882,
      "step": 10560
    },
    {
      "epoch": 1.2734939759036146,
      "grad_norm": 4.404286861419678,
      "learning_rate": 1.7453012048192773e-05,
      "loss": 0.0406,
      "step": 10570
    },
    {
      "epoch": 1.274698795180723,
      "grad_norm": 0.07447699457406998,
      "learning_rate": 1.7450602409638554e-05,
      "loss": 0.0266,
      "step": 10580
    },
    {
      "epoch": 1.2759036144578313,
      "grad_norm": 0.43496912717819214,
      "learning_rate": 1.744819277108434e-05,
      "loss": 0.0373,
      "step": 10590
    },
    {
      "epoch": 1.2771084337349397,
      "grad_norm": 0.03872277960181236,
      "learning_rate": 1.7445783132530124e-05,
      "loss": 0.0349,
      "step": 10600
    },
    {
      "epoch": 1.2783132530120482,
      "grad_norm": 0.009549799375236034,
      "learning_rate": 1.7443373493975906e-05,
      "loss": 0.0171,
      "step": 10610
    },
    {
      "epoch": 1.2795180722891566,
      "grad_norm": 2.0397050380706787,
      "learning_rate": 1.7440963855421687e-05,
      "loss": 0.1156,
      "step": 10620
    },
    {
      "epoch": 1.2807228915662652,
      "grad_norm": 0.30381685495376587,
      "learning_rate": 1.7438554216867472e-05,
      "loss": 0.0363,
      "step": 10630
    },
    {
      "epoch": 1.2819277108433735,
      "grad_norm": 12.302042007446289,
      "learning_rate": 1.7436144578313253e-05,
      "loss": 0.0555,
      "step": 10640
    },
    {
      "epoch": 1.283132530120482,
      "grad_norm": 0.18652942776679993,
      "learning_rate": 1.743373493975904e-05,
      "loss": 0.0368,
      "step": 10650
    },
    {
      "epoch": 1.2843373493975903,
      "grad_norm": 0.12971358001232147,
      "learning_rate": 1.743132530120482e-05,
      "loss": 0.0541,
      "step": 10660
    },
    {
      "epoch": 1.2855421686746988,
      "grad_norm": 0.1959693282842636,
      "learning_rate": 1.74289156626506e-05,
      "loss": 0.0414,
      "step": 10670
    },
    {
      "epoch": 1.2867469879518072,
      "grad_norm": 0.1518002152442932,
      "learning_rate": 1.742650602409639e-05,
      "loss": 0.0624,
      "step": 10680
    },
    {
      "epoch": 1.2879518072289158,
      "grad_norm": 1.194593071937561,
      "learning_rate": 1.742409638554217e-05,
      "loss": 0.0598,
      "step": 10690
    },
    {
      "epoch": 1.2891566265060241,
      "grad_norm": 1.7960762977600098,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 0.1065,
      "step": 10700
    },
    {
      "epoch": 1.2903614457831325,
      "grad_norm": 13.713366508483887,
      "learning_rate": 1.7419277108433737e-05,
      "loss": 0.0742,
      "step": 10710
    },
    {
      "epoch": 1.2915662650602409,
      "grad_norm": 0.19859282672405243,
      "learning_rate": 1.741686746987952e-05,
      "loss": 0.0287,
      "step": 10720
    },
    {
      "epoch": 1.2927710843373494,
      "grad_norm": 2.2501556873321533,
      "learning_rate": 1.7414457831325304e-05,
      "loss": 0.0848,
      "step": 10730
    },
    {
      "epoch": 1.2939759036144578,
      "grad_norm": 3.478266477584839,
      "learning_rate": 1.7412048192771085e-05,
      "loss": 0.0637,
      "step": 10740
    },
    {
      "epoch": 1.2951807228915664,
      "grad_norm": 0.007508666720241308,
      "learning_rate": 1.740963855421687e-05,
      "loss": 0.0244,
      "step": 10750
    },
    {
      "epoch": 1.2963855421686747,
      "grad_norm": 0.055932193994522095,
      "learning_rate": 1.740722891566265e-05,
      "loss": 0.016,
      "step": 10760
    },
    {
      "epoch": 1.297590361445783,
      "grad_norm": 0.03805018588900566,
      "learning_rate": 1.7404819277108436e-05,
      "loss": 0.1236,
      "step": 10770
    },
    {
      "epoch": 1.2987951807228915,
      "grad_norm": 0.4093848764896393,
      "learning_rate": 1.7402409638554218e-05,
      "loss": 0.0394,
      "step": 10780
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.028113167732954025,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.1097,
      "step": 10790
    },
    {
      "epoch": 1.3012048192771084,
      "grad_norm": 0.06326765567064285,
      "learning_rate": 1.7397590361445784e-05,
      "loss": 0.0564,
      "step": 10800
    },
    {
      "epoch": 1.302409638554217,
      "grad_norm": 7.9044084548950195,
      "learning_rate": 1.7395180722891566e-05,
      "loss": 0.0581,
      "step": 10810
    },
    {
      "epoch": 1.3036144578313253,
      "grad_norm": 0.14051492512226105,
      "learning_rate": 1.739277108433735e-05,
      "loss": 0.0346,
      "step": 10820
    },
    {
      "epoch": 1.3048192771084337,
      "grad_norm": 11.145047187805176,
      "learning_rate": 1.7390361445783136e-05,
      "loss": 0.0601,
      "step": 10830
    },
    {
      "epoch": 1.306024096385542,
      "grad_norm": 1.814772129058838,
      "learning_rate": 1.7387951807228917e-05,
      "loss": 0.0591,
      "step": 10840
    },
    {
      "epoch": 1.3072289156626506,
      "grad_norm": 0.4348803460597992,
      "learning_rate": 1.7385542168674702e-05,
      "loss": 0.0234,
      "step": 10850
    },
    {
      "epoch": 1.308433734939759,
      "grad_norm": 1.4673694372177124,
      "learning_rate": 1.7383132530120483e-05,
      "loss": 0.0233,
      "step": 10860
    },
    {
      "epoch": 1.3096385542168676,
      "grad_norm": 3.655771255493164,
      "learning_rate": 1.7380722891566265e-05,
      "loss": 0.0225,
      "step": 10870
    },
    {
      "epoch": 1.310843373493976,
      "grad_norm": 5.9523186683654785,
      "learning_rate": 1.737831325301205e-05,
      "loss": 0.0601,
      "step": 10880
    },
    {
      "epoch": 1.3120481927710843,
      "grad_norm": 0.5805758833885193,
      "learning_rate": 1.737590361445783e-05,
      "loss": 0.0596,
      "step": 10890
    },
    {
      "epoch": 1.3132530120481927,
      "grad_norm": 2.8892202377319336,
      "learning_rate": 1.7373493975903616e-05,
      "loss": 0.0292,
      "step": 10900
    },
    {
      "epoch": 1.3144578313253013,
      "grad_norm": 1.1199835538864136,
      "learning_rate": 1.73710843373494e-05,
      "loss": 0.0374,
      "step": 10910
    },
    {
      "epoch": 1.3156626506024096,
      "grad_norm": 0.018969958648085594,
      "learning_rate": 1.7368674698795182e-05,
      "loss": 0.0574,
      "step": 10920
    },
    {
      "epoch": 1.3168674698795182,
      "grad_norm": 1.8050296306610107,
      "learning_rate": 1.7366265060240964e-05,
      "loss": 0.0506,
      "step": 10930
    },
    {
      "epoch": 1.3180722891566266,
      "grad_norm": 8.765832901000977,
      "learning_rate": 1.736385542168675e-05,
      "loss": 0.0912,
      "step": 10940
    },
    {
      "epoch": 1.319277108433735,
      "grad_norm": 0.05580183491110802,
      "learning_rate": 1.736144578313253e-05,
      "loss": 0.0324,
      "step": 10950
    },
    {
      "epoch": 1.3204819277108433,
      "grad_norm": 8.31375789642334,
      "learning_rate": 1.7359036144578315e-05,
      "loss": 0.0116,
      "step": 10960
    },
    {
      "epoch": 1.3216867469879519,
      "grad_norm": 0.033636029809713364,
      "learning_rate": 1.7356626506024097e-05,
      "loss": 0.0469,
      "step": 10970
    },
    {
      "epoch": 1.3228915662650602,
      "grad_norm": 16.266103744506836,
      "learning_rate": 1.735421686746988e-05,
      "loss": 0.0466,
      "step": 10980
    },
    {
      "epoch": 1.3240963855421688,
      "grad_norm": 8.585158348083496,
      "learning_rate": 1.7351807228915666e-05,
      "loss": 0.0771,
      "step": 10990
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 10.40235710144043,
      "learning_rate": 1.7349397590361448e-05,
      "loss": 0.0423,
      "step": 11000
    },
    {
      "epoch": 1.3265060240963855,
      "grad_norm": 0.04213913157582283,
      "learning_rate": 1.734698795180723e-05,
      "loss": 0.0572,
      "step": 11010
    },
    {
      "epoch": 1.3277108433734939,
      "grad_norm": 0.8262351155281067,
      "learning_rate": 1.7344578313253014e-05,
      "loss": 0.0765,
      "step": 11020
    },
    {
      "epoch": 1.3289156626506025,
      "grad_norm": 0.8861360549926758,
      "learning_rate": 1.7342168674698796e-05,
      "loss": 0.1121,
      "step": 11030
    },
    {
      "epoch": 1.3301204819277108,
      "grad_norm": 0.26166874170303345,
      "learning_rate": 1.733975903614458e-05,
      "loss": 0.0572,
      "step": 11040
    },
    {
      "epoch": 1.3313253012048194,
      "grad_norm": 1.2745277881622314,
      "learning_rate": 1.7337349397590365e-05,
      "loss": 0.0447,
      "step": 11050
    },
    {
      "epoch": 1.3325301204819278,
      "grad_norm": 2.235929250717163,
      "learning_rate": 1.7334939759036147e-05,
      "loss": 0.05,
      "step": 11060
    },
    {
      "epoch": 1.3337349397590361,
      "grad_norm": 7.493353366851807,
      "learning_rate": 1.733253012048193e-05,
      "loss": 0.0308,
      "step": 11070
    },
    {
      "epoch": 1.3349397590361445,
      "grad_norm": 0.3110562562942505,
      "learning_rate": 1.7330120481927713e-05,
      "loss": 0.1028,
      "step": 11080
    },
    {
      "epoch": 1.336144578313253,
      "grad_norm": 3.138702154159546,
      "learning_rate": 1.7327710843373495e-05,
      "loss": 0.0486,
      "step": 11090
    },
    {
      "epoch": 1.3373493975903614,
      "grad_norm": 0.04484085366129875,
      "learning_rate": 1.732530120481928e-05,
      "loss": 0.0643,
      "step": 11100
    },
    {
      "epoch": 1.33855421686747,
      "grad_norm": 0.6731392741203308,
      "learning_rate": 1.732289156626506e-05,
      "loss": 0.0766,
      "step": 11110
    },
    {
      "epoch": 1.3397590361445784,
      "grad_norm": 0.017024826258420944,
      "learning_rate": 1.7320481927710843e-05,
      "loss": 0.0282,
      "step": 11120
    },
    {
      "epoch": 1.3409638554216867,
      "grad_norm": 2.088423490524292,
      "learning_rate": 1.7318072289156627e-05,
      "loss": 0.0216,
      "step": 11130
    },
    {
      "epoch": 1.342168674698795,
      "grad_norm": 6.514408111572266,
      "learning_rate": 1.7315662650602412e-05,
      "loss": 0.0904,
      "step": 11140
    },
    {
      "epoch": 1.3433734939759037,
      "grad_norm": 0.7511228322982788,
      "learning_rate": 1.7313253012048194e-05,
      "loss": 0.0631,
      "step": 11150
    },
    {
      "epoch": 1.344578313253012,
      "grad_norm": 0.12297774106264114,
      "learning_rate": 1.731084337349398e-05,
      "loss": 0.0695,
      "step": 11160
    },
    {
      "epoch": 1.3457831325301206,
      "grad_norm": 0.4986593425273895,
      "learning_rate": 1.730843373493976e-05,
      "loss": 0.0808,
      "step": 11170
    },
    {
      "epoch": 1.346987951807229,
      "grad_norm": 9.956259727478027,
      "learning_rate": 1.730602409638554e-05,
      "loss": 0.0623,
      "step": 11180
    },
    {
      "epoch": 1.3481927710843373,
      "grad_norm": 3.9549858570098877,
      "learning_rate": 1.7303614457831326e-05,
      "loss": 0.0545,
      "step": 11190
    },
    {
      "epoch": 1.3493975903614457,
      "grad_norm": 8.147675514221191,
      "learning_rate": 1.730120481927711e-05,
      "loss": 0.0047,
      "step": 11200
    },
    {
      "epoch": 1.3506024096385543,
      "grad_norm": 2.941399335861206,
      "learning_rate": 1.7298795180722893e-05,
      "loss": 0.0618,
      "step": 11210
    },
    {
      "epoch": 1.3518072289156626,
      "grad_norm": 0.0510791577398777,
      "learning_rate": 1.7296385542168678e-05,
      "loss": 0.0417,
      "step": 11220
    },
    {
      "epoch": 1.3530120481927712,
      "grad_norm": 3.191027879714966,
      "learning_rate": 1.729397590361446e-05,
      "loss": 0.0881,
      "step": 11230
    },
    {
      "epoch": 1.3542168674698796,
      "grad_norm": 4.37720251083374,
      "learning_rate": 1.729156626506024e-05,
      "loss": 0.0669,
      "step": 11240
    },
    {
      "epoch": 1.355421686746988,
      "grad_norm": 22.98888397216797,
      "learning_rate": 1.7289156626506026e-05,
      "loss": 0.09,
      "step": 11250
    },
    {
      "epoch": 1.3566265060240963,
      "grad_norm": 0.5868768692016602,
      "learning_rate": 1.7286746987951807e-05,
      "loss": 0.09,
      "step": 11260
    },
    {
      "epoch": 1.3578313253012049,
      "grad_norm": 0.8849974274635315,
      "learning_rate": 1.7284337349397592e-05,
      "loss": 0.0955,
      "step": 11270
    },
    {
      "epoch": 1.3590361445783132,
      "grad_norm": 3.84877610206604,
      "learning_rate": 1.7281927710843377e-05,
      "loss": 0.0532,
      "step": 11280
    },
    {
      "epoch": 1.3602409638554218,
      "grad_norm": 0.2657839059829712,
      "learning_rate": 1.7279518072289158e-05,
      "loss": 0.0273,
      "step": 11290
    },
    {
      "epoch": 1.3614457831325302,
      "grad_norm": 0.2292645424604416,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 0.0701,
      "step": 11300
    },
    {
      "epoch": 1.3626506024096385,
      "grad_norm": 0.3578823506832123,
      "learning_rate": 1.7274698795180725e-05,
      "loss": 0.0388,
      "step": 11310
    },
    {
      "epoch": 1.363855421686747,
      "grad_norm": 0.014899469912052155,
      "learning_rate": 1.7272289156626506e-05,
      "loss": 0.0697,
      "step": 11320
    },
    {
      "epoch": 1.3650602409638555,
      "grad_norm": 2.6536073684692383,
      "learning_rate": 1.726987951807229e-05,
      "loss": 0.049,
      "step": 11330
    },
    {
      "epoch": 1.3662650602409638,
      "grad_norm": 10.151068687438965,
      "learning_rate": 1.7267469879518072e-05,
      "loss": 0.066,
      "step": 11340
    },
    {
      "epoch": 1.3674698795180724,
      "grad_norm": 8.040630340576172,
      "learning_rate": 1.7265060240963857e-05,
      "loss": 0.0709,
      "step": 11350
    },
    {
      "epoch": 1.3686746987951808,
      "grad_norm": 0.4718926250934601,
      "learning_rate": 1.7262650602409642e-05,
      "loss": 0.0433,
      "step": 11360
    },
    {
      "epoch": 1.3698795180722891,
      "grad_norm": 5.925187587738037,
      "learning_rate": 1.7260240963855424e-05,
      "loss": 0.1232,
      "step": 11370
    },
    {
      "epoch": 1.3710843373493975,
      "grad_norm": 1.2904503345489502,
      "learning_rate": 1.7257831325301205e-05,
      "loss": 0.0872,
      "step": 11380
    },
    {
      "epoch": 1.372289156626506,
      "grad_norm": 0.6356748938560486,
      "learning_rate": 1.725542168674699e-05,
      "loss": 0.0315,
      "step": 11390
    },
    {
      "epoch": 1.3734939759036144,
      "grad_norm": 4.236047267913818,
      "learning_rate": 1.725301204819277e-05,
      "loss": 0.0395,
      "step": 11400
    },
    {
      "epoch": 1.374698795180723,
      "grad_norm": 3.6954305171966553,
      "learning_rate": 1.7250602409638556e-05,
      "loss": 0.0427,
      "step": 11410
    },
    {
      "epoch": 1.3759036144578314,
      "grad_norm": 3.8586039543151855,
      "learning_rate": 1.7248192771084338e-05,
      "loss": 0.0363,
      "step": 11420
    },
    {
      "epoch": 1.3771084337349397,
      "grad_norm": 0.11373622715473175,
      "learning_rate": 1.7245783132530123e-05,
      "loss": 0.0598,
      "step": 11430
    },
    {
      "epoch": 1.378313253012048,
      "grad_norm": 0.4559521973133087,
      "learning_rate": 1.7243373493975904e-05,
      "loss": 0.1579,
      "step": 11440
    },
    {
      "epoch": 1.3795180722891567,
      "grad_norm": 3.7884299755096436,
      "learning_rate": 1.724096385542169e-05,
      "loss": 0.0515,
      "step": 11450
    },
    {
      "epoch": 1.380722891566265,
      "grad_norm": 1.378316879272461,
      "learning_rate": 1.723855421686747e-05,
      "loss": 0.1055,
      "step": 11460
    },
    {
      "epoch": 1.3819277108433736,
      "grad_norm": 1.4963940382003784,
      "learning_rate": 1.7236144578313255e-05,
      "loss": 0.0398,
      "step": 11470
    },
    {
      "epoch": 1.383132530120482,
      "grad_norm": 0.044266145676374435,
      "learning_rate": 1.7233734939759037e-05,
      "loss": 0.0666,
      "step": 11480
    },
    {
      "epoch": 1.3843373493975903,
      "grad_norm": 0.03360247611999512,
      "learning_rate": 1.723132530120482e-05,
      "loss": 0.0649,
      "step": 11490
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 2.1241371631622314,
      "learning_rate": 1.7228915662650603e-05,
      "loss": 0.038,
      "step": 11500
    },
    {
      "epoch": 1.3867469879518073,
      "grad_norm": 16.631608963012695,
      "learning_rate": 1.7226506024096388e-05,
      "loss": 0.0624,
      "step": 11510
    },
    {
      "epoch": 1.3879518072289156,
      "grad_norm": 0.2924773097038269,
      "learning_rate": 1.722409638554217e-05,
      "loss": 0.0652,
      "step": 11520
    },
    {
      "epoch": 1.3891566265060242,
      "grad_norm": 26.474815368652344,
      "learning_rate": 1.7221686746987954e-05,
      "loss": 0.0406,
      "step": 11530
    },
    {
      "epoch": 1.3903614457831326,
      "grad_norm": 16.874521255493164,
      "learning_rate": 1.7219277108433736e-05,
      "loss": 0.0372,
      "step": 11540
    },
    {
      "epoch": 1.391566265060241,
      "grad_norm": 1.6431007385253906,
      "learning_rate": 1.7216867469879517e-05,
      "loss": 0.0071,
      "step": 11550
    },
    {
      "epoch": 1.3927710843373493,
      "grad_norm": 0.9776045680046082,
      "learning_rate": 1.7214457831325302e-05,
      "loss": 0.0813,
      "step": 11560
    },
    {
      "epoch": 1.393975903614458,
      "grad_norm": 0.19352851808071136,
      "learning_rate": 1.7212048192771084e-05,
      "loss": 0.0477,
      "step": 11570
    },
    {
      "epoch": 1.3951807228915662,
      "grad_norm": 1.725322961807251,
      "learning_rate": 1.720963855421687e-05,
      "loss": 0.0228,
      "step": 11580
    },
    {
      "epoch": 1.3963855421686748,
      "grad_norm": 0.033186230808496475,
      "learning_rate": 1.7207228915662654e-05,
      "loss": 0.0658,
      "step": 11590
    },
    {
      "epoch": 1.3975903614457832,
      "grad_norm": 8.686838150024414,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 0.0972,
      "step": 11600
    },
    {
      "epoch": 1.3987951807228916,
      "grad_norm": 0.018728068098425865,
      "learning_rate": 1.720240963855422e-05,
      "loss": 0.0436,
      "step": 11610
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.35967493057251,
      "learning_rate": 1.72e-05,
      "loss": 0.0422,
      "step": 11620
    },
    {
      "epoch": 1.4012048192771085,
      "grad_norm": 25.497446060180664,
      "learning_rate": 1.7197590361445783e-05,
      "loss": 0.0323,
      "step": 11630
    },
    {
      "epoch": 1.4024096385542169,
      "grad_norm": 13.722792625427246,
      "learning_rate": 1.7195180722891568e-05,
      "loss": 0.0614,
      "step": 11640
    },
    {
      "epoch": 1.4036144578313254,
      "grad_norm": 0.5635253190994263,
      "learning_rate": 1.7192771084337353e-05,
      "loss": 0.0767,
      "step": 11650
    },
    {
      "epoch": 1.4048192771084338,
      "grad_norm": 0.03281239792704582,
      "learning_rate": 1.7190361445783134e-05,
      "loss": 0.0619,
      "step": 11660
    },
    {
      "epoch": 1.4060240963855422,
      "grad_norm": 5.285350322723389,
      "learning_rate": 1.718795180722892e-05,
      "loss": 0.0552,
      "step": 11670
    },
    {
      "epoch": 1.4072289156626505,
      "grad_norm": 0.1797821819782257,
      "learning_rate": 1.71855421686747e-05,
      "loss": 0.0548,
      "step": 11680
    },
    {
      "epoch": 1.408433734939759,
      "grad_norm": 3.8172073364257812,
      "learning_rate": 1.7183132530120482e-05,
      "loss": 0.0752,
      "step": 11690
    },
    {
      "epoch": 1.4096385542168675,
      "grad_norm": 5.8750128746032715,
      "learning_rate": 1.7180722891566267e-05,
      "loss": 0.0709,
      "step": 11700
    },
    {
      "epoch": 1.410843373493976,
      "grad_norm": 2.347099542617798,
      "learning_rate": 1.7178313253012048e-05,
      "loss": 0.0394,
      "step": 11710
    },
    {
      "epoch": 1.4120481927710844,
      "grad_norm": 0.030101150274276733,
      "learning_rate": 1.7175903614457833e-05,
      "loss": 0.0623,
      "step": 11720
    },
    {
      "epoch": 1.4132530120481928,
      "grad_norm": 2.684262752532959,
      "learning_rate": 1.7173493975903618e-05,
      "loss": 0.0209,
      "step": 11730
    },
    {
      "epoch": 1.4144578313253011,
      "grad_norm": 0.09111253917217255,
      "learning_rate": 1.71710843373494e-05,
      "loss": 0.0705,
      "step": 11740
    },
    {
      "epoch": 1.4156626506024097,
      "grad_norm": 35.715694427490234,
      "learning_rate": 1.716867469879518e-05,
      "loss": 0.0616,
      "step": 11750
    },
    {
      "epoch": 1.416867469879518,
      "grad_norm": 0.291390597820282,
      "learning_rate": 1.7166265060240966e-05,
      "loss": 0.0486,
      "step": 11760
    },
    {
      "epoch": 1.4180722891566266,
      "grad_norm": 0.07331223040819168,
      "learning_rate": 1.7163855421686747e-05,
      "loss": 0.0175,
      "step": 11770
    },
    {
      "epoch": 1.419277108433735,
      "grad_norm": 0.4066182076931,
      "learning_rate": 1.7161445783132532e-05,
      "loss": 0.0316,
      "step": 11780
    },
    {
      "epoch": 1.4204819277108434,
      "grad_norm": 132.70408630371094,
      "learning_rate": 1.7159036144578314e-05,
      "loss": 0.0411,
      "step": 11790
    },
    {
      "epoch": 1.4216867469879517,
      "grad_norm": 0.33930230140686035,
      "learning_rate": 1.71566265060241e-05,
      "loss": 0.0505,
      "step": 11800
    },
    {
      "epoch": 1.4228915662650603,
      "grad_norm": 2.3325963020324707,
      "learning_rate": 1.7154216867469883e-05,
      "loss": 0.0906,
      "step": 11810
    },
    {
      "epoch": 1.4240963855421687,
      "grad_norm": 14.136990547180176,
      "learning_rate": 1.7151807228915665e-05,
      "loss": 0.1196,
      "step": 11820
    },
    {
      "epoch": 1.4253012048192772,
      "grad_norm": 0.2926194965839386,
      "learning_rate": 1.7149397590361446e-05,
      "loss": 0.0222,
      "step": 11830
    },
    {
      "epoch": 1.4265060240963856,
      "grad_norm": 0.22459840774536133,
      "learning_rate": 1.714698795180723e-05,
      "loss": 0.0491,
      "step": 11840
    },
    {
      "epoch": 1.427710843373494,
      "grad_norm": 0.04192596673965454,
      "learning_rate": 1.7144578313253013e-05,
      "loss": 0.0075,
      "step": 11850
    },
    {
      "epoch": 1.4289156626506023,
      "grad_norm": 0.04321989044547081,
      "learning_rate": 1.7142168674698794e-05,
      "loss": 0.0921,
      "step": 11860
    },
    {
      "epoch": 1.430120481927711,
      "grad_norm": 4.132840633392334,
      "learning_rate": 1.713975903614458e-05,
      "loss": 0.0368,
      "step": 11870
    },
    {
      "epoch": 1.4313253012048193,
      "grad_norm": 0.8518697619438171,
      "learning_rate": 1.7137349397590364e-05,
      "loss": 0.023,
      "step": 11880
    },
    {
      "epoch": 1.4325301204819278,
      "grad_norm": 0.026309847831726074,
      "learning_rate": 1.7134939759036145e-05,
      "loss": 0.0052,
      "step": 11890
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 0.04379487782716751,
      "learning_rate": 1.713253012048193e-05,
      "loss": 0.0311,
      "step": 11900
    },
    {
      "epoch": 1.4349397590361446,
      "grad_norm": 1.4598923921585083,
      "learning_rate": 1.7130120481927712e-05,
      "loss": 0.0365,
      "step": 11910
    },
    {
      "epoch": 1.436144578313253,
      "grad_norm": 0.035421401262283325,
      "learning_rate": 1.7127710843373497e-05,
      "loss": 0.0294,
      "step": 11920
    },
    {
      "epoch": 1.4373493975903615,
      "grad_norm": 0.247695654630661,
      "learning_rate": 1.7125301204819278e-05,
      "loss": 0.022,
      "step": 11930
    },
    {
      "epoch": 1.4385542168674699,
      "grad_norm": 7.277079105377197,
      "learning_rate": 1.712289156626506e-05,
      "loss": 0.0803,
      "step": 11940
    },
    {
      "epoch": 1.4397590361445782,
      "grad_norm": 6.742773056030273,
      "learning_rate": 1.7120481927710844e-05,
      "loss": 0.0781,
      "step": 11950
    },
    {
      "epoch": 1.4409638554216868,
      "grad_norm": 10.155372619628906,
      "learning_rate": 1.711807228915663e-05,
      "loss": 0.0446,
      "step": 11960
    },
    {
      "epoch": 1.4421686746987952,
      "grad_norm": 0.8756031394004822,
      "learning_rate": 1.711566265060241e-05,
      "loss": 0.0288,
      "step": 11970
    },
    {
      "epoch": 1.4433734939759035,
      "grad_norm": 0.2076568305492401,
      "learning_rate": 1.7113253012048196e-05,
      "loss": 0.0082,
      "step": 11980
    },
    {
      "epoch": 1.4445783132530121,
      "grad_norm": 0.04560418426990509,
      "learning_rate": 1.7110843373493977e-05,
      "loss": 0.0804,
      "step": 11990
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 0.19770844280719757,
      "learning_rate": 1.710843373493976e-05,
      "loss": 0.0444,
      "step": 12000
    },
    {
      "epoch": 1.4469879518072288,
      "grad_norm": 15.072955131530762,
      "learning_rate": 1.7106024096385544e-05,
      "loss": 0.0644,
      "step": 12010
    },
    {
      "epoch": 1.4481927710843374,
      "grad_norm": 1.3124479055404663,
      "learning_rate": 1.7103614457831325e-05,
      "loss": 0.0526,
      "step": 12020
    },
    {
      "epoch": 1.4493975903614458,
      "grad_norm": 0.9167325496673584,
      "learning_rate": 1.710120481927711e-05,
      "loss": 0.0926,
      "step": 12030
    },
    {
      "epoch": 1.4506024096385541,
      "grad_norm": 12.640159606933594,
      "learning_rate": 1.7098795180722895e-05,
      "loss": 0.0669,
      "step": 12040
    },
    {
      "epoch": 1.4518072289156627,
      "grad_norm": 0.044589899480342865,
      "learning_rate": 1.7096385542168676e-05,
      "loss": 0.014,
      "step": 12050
    },
    {
      "epoch": 1.453012048192771,
      "grad_norm": 0.3504701852798462,
      "learning_rate": 1.7093975903614458e-05,
      "loss": 0.0095,
      "step": 12060
    },
    {
      "epoch": 1.4542168674698794,
      "grad_norm": 1.9049394130706787,
      "learning_rate": 1.7091566265060243e-05,
      "loss": 0.043,
      "step": 12070
    },
    {
      "epoch": 1.455421686746988,
      "grad_norm": 4.121738910675049,
      "learning_rate": 1.7089156626506024e-05,
      "loss": 0.0238,
      "step": 12080
    },
    {
      "epoch": 1.4566265060240964,
      "grad_norm": 0.10953421890735626,
      "learning_rate": 1.708674698795181e-05,
      "loss": 0.0054,
      "step": 12090
    },
    {
      "epoch": 1.4578313253012047,
      "grad_norm": 8.033965110778809,
      "learning_rate": 1.7084337349397594e-05,
      "loss": 0.1356,
      "step": 12100
    },
    {
      "epoch": 1.4590361445783133,
      "grad_norm": 0.6834083199501038,
      "learning_rate": 1.7081927710843375e-05,
      "loss": 0.0973,
      "step": 12110
    },
    {
      "epoch": 1.4602409638554217,
      "grad_norm": 0.0183324683457613,
      "learning_rate": 1.707951807228916e-05,
      "loss": 0.0091,
      "step": 12120
    },
    {
      "epoch": 1.46144578313253,
      "grad_norm": 0.6231195330619812,
      "learning_rate": 1.707710843373494e-05,
      "loss": 0.0043,
      "step": 12130
    },
    {
      "epoch": 1.4626506024096386,
      "grad_norm": 0.570250928401947,
      "learning_rate": 1.7074698795180723e-05,
      "loss": 0.0553,
      "step": 12140
    },
    {
      "epoch": 1.463855421686747,
      "grad_norm": 2.344015598297119,
      "learning_rate": 1.7072289156626508e-05,
      "loss": 0.0345,
      "step": 12150
    },
    {
      "epoch": 1.4650602409638553,
      "grad_norm": 3.1459765434265137,
      "learning_rate": 1.706987951807229e-05,
      "loss": 0.0307,
      "step": 12160
    },
    {
      "epoch": 1.466265060240964,
      "grad_norm": 7.1217780113220215,
      "learning_rate": 1.7067469879518074e-05,
      "loss": 0.0695,
      "step": 12170
    },
    {
      "epoch": 1.4674698795180723,
      "grad_norm": 0.07976849377155304,
      "learning_rate": 1.706506024096386e-05,
      "loss": 0.0329,
      "step": 12180
    },
    {
      "epoch": 1.4686746987951806,
      "grad_norm": 10.203957557678223,
      "learning_rate": 1.706265060240964e-05,
      "loss": 0.0932,
      "step": 12190
    },
    {
      "epoch": 1.4698795180722892,
      "grad_norm": 2.0516722202301025,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 0.0622,
      "step": 12200
    },
    {
      "epoch": 1.4710843373493976,
      "grad_norm": 1.796218991279602,
      "learning_rate": 1.7057831325301207e-05,
      "loss": 0.0353,
      "step": 12210
    },
    {
      "epoch": 1.472289156626506,
      "grad_norm": 0.508510410785675,
      "learning_rate": 1.705542168674699e-05,
      "loss": 0.0365,
      "step": 12220
    },
    {
      "epoch": 1.4734939759036145,
      "grad_norm": 36.46024703979492,
      "learning_rate": 1.7053012048192773e-05,
      "loss": 0.074,
      "step": 12230
    },
    {
      "epoch": 1.4746987951807229,
      "grad_norm": 0.16962574422359467,
      "learning_rate": 1.7050602409638555e-05,
      "loss": 0.0805,
      "step": 12240
    },
    {
      "epoch": 1.4759036144578312,
      "grad_norm": 12.29088020324707,
      "learning_rate": 1.704819277108434e-05,
      "loss": 0.107,
      "step": 12250
    },
    {
      "epoch": 1.4771084337349398,
      "grad_norm": 46.06120300292969,
      "learning_rate": 1.704578313253012e-05,
      "loss": 0.0412,
      "step": 12260
    },
    {
      "epoch": 1.4783132530120482,
      "grad_norm": 0.2577607333660126,
      "learning_rate": 1.7043373493975906e-05,
      "loss": 0.0297,
      "step": 12270
    },
    {
      "epoch": 1.4795180722891565,
      "grad_norm": 4.744605541229248,
      "learning_rate": 1.7040963855421688e-05,
      "loss": 0.0727,
      "step": 12280
    },
    {
      "epoch": 1.4807228915662651,
      "grad_norm": 0.04183688014745712,
      "learning_rate": 1.7038554216867472e-05,
      "loss": 0.0465,
      "step": 12290
    },
    {
      "epoch": 1.4819277108433735,
      "grad_norm": 0.17817626893520355,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 0.0842,
      "step": 12300
    },
    {
      "epoch": 1.4831325301204819,
      "grad_norm": 13.286065101623535,
      "learning_rate": 1.7033734939759035e-05,
      "loss": 0.0772,
      "step": 12310
    },
    {
      "epoch": 1.4843373493975904,
      "grad_norm": 0.8518804907798767,
      "learning_rate": 1.703132530120482e-05,
      "loss": 0.0061,
      "step": 12320
    },
    {
      "epoch": 1.4855421686746988,
      "grad_norm": 0.3241739273071289,
      "learning_rate": 1.7028915662650605e-05,
      "loss": 0.1203,
      "step": 12330
    },
    {
      "epoch": 1.4867469879518072,
      "grad_norm": 9.011568069458008,
      "learning_rate": 1.7026506024096387e-05,
      "loss": 0.043,
      "step": 12340
    },
    {
      "epoch": 1.4879518072289157,
      "grad_norm": 0.4116341471672058,
      "learning_rate": 1.702409638554217e-05,
      "loss": 0.0597,
      "step": 12350
    },
    {
      "epoch": 1.489156626506024,
      "grad_norm": 0.2076440006494522,
      "learning_rate": 1.7021686746987953e-05,
      "loss": 0.1076,
      "step": 12360
    },
    {
      "epoch": 1.4903614457831325,
      "grad_norm": 1.8799411058425903,
      "learning_rate": 1.7019277108433734e-05,
      "loss": 0.0959,
      "step": 12370
    },
    {
      "epoch": 1.491566265060241,
      "grad_norm": 0.04119429737329483,
      "learning_rate": 1.701686746987952e-05,
      "loss": 0.0216,
      "step": 12380
    },
    {
      "epoch": 1.4927710843373494,
      "grad_norm": 0.5883403420448303,
      "learning_rate": 1.70144578313253e-05,
      "loss": 0.0166,
      "step": 12390
    },
    {
      "epoch": 1.4939759036144578,
      "grad_norm": 7.300731658935547,
      "learning_rate": 1.7012048192771086e-05,
      "loss": 0.0946,
      "step": 12400
    },
    {
      "epoch": 1.4951807228915663,
      "grad_norm": 0.09390855580568314,
      "learning_rate": 1.700963855421687e-05,
      "loss": 0.0428,
      "step": 12410
    },
    {
      "epoch": 1.4963855421686747,
      "grad_norm": 0.23063074052333832,
      "learning_rate": 1.7007228915662652e-05,
      "loss": 0.0183,
      "step": 12420
    },
    {
      "epoch": 1.497590361445783,
      "grad_norm": 26.487730026245117,
      "learning_rate": 1.7004819277108437e-05,
      "loss": 0.0534,
      "step": 12430
    },
    {
      "epoch": 1.4987951807228916,
      "grad_norm": 0.12823082506656647,
      "learning_rate": 1.700240963855422e-05,
      "loss": 0.098,
      "step": 12440
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.06615555286407471,
      "learning_rate": 1.7e-05,
      "loss": 0.0062,
      "step": 12450
    },
    {
      "epoch": 1.5012048192771084,
      "grad_norm": 6.828333377838135,
      "learning_rate": 1.6997590361445785e-05,
      "loss": 0.075,
      "step": 12460
    },
    {
      "epoch": 1.5024096385542167,
      "grad_norm": 0.032948192209005356,
      "learning_rate": 1.6995180722891566e-05,
      "loss": 0.1091,
      "step": 12470
    },
    {
      "epoch": 1.5036144578313253,
      "grad_norm": 0.12287372350692749,
      "learning_rate": 1.699277108433735e-05,
      "loss": 0.0628,
      "step": 12480
    },
    {
      "epoch": 1.5048192771084339,
      "grad_norm": 1.1094516515731812,
      "learning_rate": 1.6990361445783136e-05,
      "loss": 0.0787,
      "step": 12490
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 6.93703031539917,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 0.0813,
      "step": 12500
    },
    {
      "epoch": 1.5072289156626506,
      "grad_norm": 0.069442979991436,
      "learning_rate": 1.69855421686747e-05,
      "loss": 0.0371,
      "step": 12510
    },
    {
      "epoch": 1.508433734939759,
      "grad_norm": 1.9056694507598877,
      "learning_rate": 1.6983132530120484e-05,
      "loss": 0.0826,
      "step": 12520
    },
    {
      "epoch": 1.5096385542168673,
      "grad_norm": 2.016170024871826,
      "learning_rate": 1.6980722891566265e-05,
      "loss": 0.0577,
      "step": 12530
    },
    {
      "epoch": 1.510843373493976,
      "grad_norm": 0.11721008270978928,
      "learning_rate": 1.697831325301205e-05,
      "loss": 0.054,
      "step": 12540
    },
    {
      "epoch": 1.5120481927710845,
      "grad_norm": 1.927017331123352,
      "learning_rate": 1.6975903614457835e-05,
      "loss": 0.0386,
      "step": 12550
    },
    {
      "epoch": 1.5132530120481928,
      "grad_norm": 7.116977214813232,
      "learning_rate": 1.6973493975903616e-05,
      "loss": 0.1261,
      "step": 12560
    },
    {
      "epoch": 1.5144578313253012,
      "grad_norm": 0.05030778422951698,
      "learning_rate": 1.6971084337349398e-05,
      "loss": 0.0153,
      "step": 12570
    },
    {
      "epoch": 1.5156626506024096,
      "grad_norm": 0.5003196001052856,
      "learning_rate": 1.6968674698795183e-05,
      "loss": 0.036,
      "step": 12580
    },
    {
      "epoch": 1.516867469879518,
      "grad_norm": 5.917121887207031,
      "learning_rate": 1.6966265060240964e-05,
      "loss": 0.1581,
      "step": 12590
    },
    {
      "epoch": 1.5180722891566265,
      "grad_norm": 2.181929588317871,
      "learning_rate": 1.696385542168675e-05,
      "loss": 0.0352,
      "step": 12600
    },
    {
      "epoch": 1.519277108433735,
      "grad_norm": 0.11984149366617203,
      "learning_rate": 1.696144578313253e-05,
      "loss": 0.0769,
      "step": 12610
    },
    {
      "epoch": 1.5204819277108435,
      "grad_norm": 6.696780681610107,
      "learning_rate": 1.6959036144578312e-05,
      "loss": 0.0737,
      "step": 12620
    },
    {
      "epoch": 1.5216867469879518,
      "grad_norm": 0.11401572823524475,
      "learning_rate": 1.6956626506024097e-05,
      "loss": 0.0234,
      "step": 12630
    },
    {
      "epoch": 1.5228915662650602,
      "grad_norm": 0.0573430098593235,
      "learning_rate": 1.6954216867469882e-05,
      "loss": 0.0287,
      "step": 12640
    },
    {
      "epoch": 1.5240963855421685,
      "grad_norm": 0.1184995174407959,
      "learning_rate": 1.6951807228915663e-05,
      "loss": 0.0617,
      "step": 12650
    },
    {
      "epoch": 1.5253012048192771,
      "grad_norm": 0.8364184498786926,
      "learning_rate": 1.6949397590361448e-05,
      "loss": 0.0262,
      "step": 12660
    },
    {
      "epoch": 1.5265060240963857,
      "grad_norm": 0.008701631799340248,
      "learning_rate": 1.694698795180723e-05,
      "loss": 0.0358,
      "step": 12670
    },
    {
      "epoch": 1.527710843373494,
      "grad_norm": 0.0664069876074791,
      "learning_rate": 1.694457831325301e-05,
      "loss": 0.0524,
      "step": 12680
    },
    {
      "epoch": 1.5289156626506024,
      "grad_norm": 0.008559283800423145,
      "learning_rate": 1.6942168674698796e-05,
      "loss": 0.0094,
      "step": 12690
    },
    {
      "epoch": 1.5301204819277108,
      "grad_norm": 1.539335012435913,
      "learning_rate": 1.693975903614458e-05,
      "loss": 0.1658,
      "step": 12700
    },
    {
      "epoch": 1.5313253012048191,
      "grad_norm": 0.5883111953735352,
      "learning_rate": 1.6937349397590362e-05,
      "loss": 0.0735,
      "step": 12710
    },
    {
      "epoch": 1.5325301204819277,
      "grad_norm": 1.3004087209701538,
      "learning_rate": 1.6934939759036147e-05,
      "loss": 0.1365,
      "step": 12720
    },
    {
      "epoch": 1.5337349397590363,
      "grad_norm": 0.06944765895605087,
      "learning_rate": 1.693253012048193e-05,
      "loss": 0.0324,
      "step": 12730
    },
    {
      "epoch": 1.5349397590361447,
      "grad_norm": 5.023954391479492,
      "learning_rate": 1.6930120481927714e-05,
      "loss": 0.0254,
      "step": 12740
    },
    {
      "epoch": 1.536144578313253,
      "grad_norm": 0.10701912641525269,
      "learning_rate": 1.6927710843373495e-05,
      "loss": 0.0772,
      "step": 12750
    },
    {
      "epoch": 1.5373493975903614,
      "grad_norm": 0.016951382160186768,
      "learning_rate": 1.6925301204819277e-05,
      "loss": 0.0269,
      "step": 12760
    },
    {
      "epoch": 1.5385542168674697,
      "grad_norm": 0.6542968153953552,
      "learning_rate": 1.692289156626506e-05,
      "loss": 0.0889,
      "step": 12770
    },
    {
      "epoch": 1.5397590361445783,
      "grad_norm": 0.08171457052230835,
      "learning_rate": 1.6920481927710846e-05,
      "loss": 0.0018,
      "step": 12780
    },
    {
      "epoch": 1.540963855421687,
      "grad_norm": 0.3826140761375427,
      "learning_rate": 1.6918072289156628e-05,
      "loss": 0.0223,
      "step": 12790
    },
    {
      "epoch": 1.5421686746987953,
      "grad_norm": 2.309386968612671,
      "learning_rate": 1.6915662650602413e-05,
      "loss": 0.1044,
      "step": 12800
    },
    {
      "epoch": 1.5433734939759036,
      "grad_norm": 0.49200868606567383,
      "learning_rate": 1.6913253012048194e-05,
      "loss": 0.0792,
      "step": 12810
    },
    {
      "epoch": 1.544578313253012,
      "grad_norm": 14.985289573669434,
      "learning_rate": 1.6910843373493976e-05,
      "loss": 0.0364,
      "step": 12820
    },
    {
      "epoch": 1.5457831325301203,
      "grad_norm": 0.08168669044971466,
      "learning_rate": 1.690843373493976e-05,
      "loss": 0.0749,
      "step": 12830
    },
    {
      "epoch": 1.546987951807229,
      "grad_norm": 0.19125571846961975,
      "learning_rate": 1.6906024096385542e-05,
      "loss": 0.0952,
      "step": 12840
    },
    {
      "epoch": 1.5481927710843375,
      "grad_norm": 0.17336776852607727,
      "learning_rate": 1.6903614457831327e-05,
      "loss": 0.0711,
      "step": 12850
    },
    {
      "epoch": 1.5493975903614459,
      "grad_norm": 5.087619781494141,
      "learning_rate": 1.6901204819277112e-05,
      "loss": 0.069,
      "step": 12860
    },
    {
      "epoch": 1.5506024096385542,
      "grad_norm": 0.9195934534072876,
      "learning_rate": 1.6898795180722893e-05,
      "loss": 0.0245,
      "step": 12870
    },
    {
      "epoch": 1.5518072289156626,
      "grad_norm": 0.03265925124287605,
      "learning_rate": 1.6896385542168675e-05,
      "loss": 0.0506,
      "step": 12880
    },
    {
      "epoch": 1.553012048192771,
      "grad_norm": 0.20232972502708435,
      "learning_rate": 1.689397590361446e-05,
      "loss": 0.0524,
      "step": 12890
    },
    {
      "epoch": 1.5542168674698795,
      "grad_norm": 54.96311950683594,
      "learning_rate": 1.689156626506024e-05,
      "loss": 0.0633,
      "step": 12900
    },
    {
      "epoch": 1.555421686746988,
      "grad_norm": 0.7661701440811157,
      "learning_rate": 1.6889156626506026e-05,
      "loss": 0.0209,
      "step": 12910
    },
    {
      "epoch": 1.5566265060240965,
      "grad_norm": 1.267256498336792,
      "learning_rate": 1.6886746987951807e-05,
      "loss": 0.1066,
      "step": 12920
    },
    {
      "epoch": 1.5578313253012048,
      "grad_norm": 3.83843994140625,
      "learning_rate": 1.6884337349397592e-05,
      "loss": 0.1044,
      "step": 12930
    },
    {
      "epoch": 1.5590361445783132,
      "grad_norm": 27.862438201904297,
      "learning_rate": 1.6881927710843374e-05,
      "loss": 0.0313,
      "step": 12940
    },
    {
      "epoch": 1.5602409638554215,
      "grad_norm": 1.497863531112671,
      "learning_rate": 1.687951807228916e-05,
      "loss": 0.0188,
      "step": 12950
    },
    {
      "epoch": 1.5614457831325301,
      "grad_norm": 3.0542781352996826,
      "learning_rate": 1.687710843373494e-05,
      "loss": 0.0334,
      "step": 12960
    },
    {
      "epoch": 1.5626506024096387,
      "grad_norm": 0.03028806857764721,
      "learning_rate": 1.6874698795180725e-05,
      "loss": 0.051,
      "step": 12970
    },
    {
      "epoch": 1.563855421686747,
      "grad_norm": 0.24217364192008972,
      "learning_rate": 1.6872289156626507e-05,
      "loss": 0.0543,
      "step": 12980
    },
    {
      "epoch": 1.5650602409638554,
      "grad_norm": 26.65331268310547,
      "learning_rate": 1.6869879518072288e-05,
      "loss": 0.0656,
      "step": 12990
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 0.9635260105133057,
      "learning_rate": 1.6867469879518076e-05,
      "loss": 0.046,
      "step": 13000
    },
    {
      "epoch": 1.5674698795180722,
      "grad_norm": 0.06933225691318512,
      "learning_rate": 1.6865060240963858e-05,
      "loss": 0.0178,
      "step": 13010
    },
    {
      "epoch": 1.5686746987951807,
      "grad_norm": 0.7773358225822449,
      "learning_rate": 1.686265060240964e-05,
      "loss": 0.0459,
      "step": 13020
    },
    {
      "epoch": 1.5698795180722893,
      "grad_norm": 0.026736846193671227,
      "learning_rate": 1.6860240963855424e-05,
      "loss": 0.0251,
      "step": 13030
    },
    {
      "epoch": 1.5710843373493977,
      "grad_norm": 0.035321563482284546,
      "learning_rate": 1.6857831325301206e-05,
      "loss": 0.0395,
      "step": 13040
    },
    {
      "epoch": 1.572289156626506,
      "grad_norm": 0.12433183193206787,
      "learning_rate": 1.685542168674699e-05,
      "loss": 0.0176,
      "step": 13050
    },
    {
      "epoch": 1.5734939759036144,
      "grad_norm": 8.058934211730957,
      "learning_rate": 1.6853012048192772e-05,
      "loss": 0.0727,
      "step": 13060
    },
    {
      "epoch": 1.5746987951807228,
      "grad_norm": 9.002181053161621,
      "learning_rate": 1.6850602409638553e-05,
      "loss": 0.0568,
      "step": 13070
    },
    {
      "epoch": 1.5759036144578313,
      "grad_norm": 0.02549971640110016,
      "learning_rate": 1.6848192771084338e-05,
      "loss": 0.0664,
      "step": 13080
    },
    {
      "epoch": 1.57710843373494,
      "grad_norm": 22.928586959838867,
      "learning_rate": 1.6845783132530123e-05,
      "loss": 0.0519,
      "step": 13090
    },
    {
      "epoch": 1.5783132530120483,
      "grad_norm": 0.4187566041946411,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 0.0195,
      "step": 13100
    },
    {
      "epoch": 1.5795180722891566,
      "grad_norm": 4.5805745124816895,
      "learning_rate": 1.684096385542169e-05,
      "loss": 0.1128,
      "step": 13110
    },
    {
      "epoch": 1.580722891566265,
      "grad_norm": 0.10935160517692566,
      "learning_rate": 1.683855421686747e-05,
      "loss": 0.0185,
      "step": 13120
    },
    {
      "epoch": 1.5819277108433734,
      "grad_norm": 0.0778231993317604,
      "learning_rate": 1.6836144578313252e-05,
      "loss": 0.043,
      "step": 13130
    },
    {
      "epoch": 1.583132530120482,
      "grad_norm": 0.023418214172124863,
      "learning_rate": 1.6833734939759037e-05,
      "loss": 0.0189,
      "step": 13140
    },
    {
      "epoch": 1.5843373493975905,
      "grad_norm": 0.07507465034723282,
      "learning_rate": 1.6831325301204822e-05,
      "loss": 0.0351,
      "step": 13150
    },
    {
      "epoch": 1.5855421686746989,
      "grad_norm": 0.04571249708533287,
      "learning_rate": 1.6828915662650604e-05,
      "loss": 0.0948,
      "step": 13160
    },
    {
      "epoch": 1.5867469879518072,
      "grad_norm": 18.244775772094727,
      "learning_rate": 1.682650602409639e-05,
      "loss": 0.0428,
      "step": 13170
    },
    {
      "epoch": 1.5879518072289156,
      "grad_norm": 0.9710360765457153,
      "learning_rate": 1.682409638554217e-05,
      "loss": 0.0525,
      "step": 13180
    },
    {
      "epoch": 1.589156626506024,
      "grad_norm": 2.0997025966644287,
      "learning_rate": 1.682168674698795e-05,
      "loss": 0.1039,
      "step": 13190
    },
    {
      "epoch": 1.5903614457831325,
      "grad_norm": 0.10307687520980835,
      "learning_rate": 1.6819277108433736e-05,
      "loss": 0.0351,
      "step": 13200
    },
    {
      "epoch": 1.5915662650602411,
      "grad_norm": 32.75083541870117,
      "learning_rate": 1.6816867469879518e-05,
      "loss": 0.0363,
      "step": 13210
    },
    {
      "epoch": 1.5927710843373495,
      "grad_norm": 0.03770849108695984,
      "learning_rate": 1.6814457831325303e-05,
      "loss": 0.0358,
      "step": 13220
    },
    {
      "epoch": 1.5939759036144578,
      "grad_norm": 0.011731764301657677,
      "learning_rate": 1.6812048192771088e-05,
      "loss": 0.0208,
      "step": 13230
    },
    {
      "epoch": 1.5951807228915662,
      "grad_norm": 0.17192214727401733,
      "learning_rate": 1.680963855421687e-05,
      "loss": 0.0512,
      "step": 13240
    },
    {
      "epoch": 1.5963855421686746,
      "grad_norm": 0.02644577994942665,
      "learning_rate": 1.680722891566265e-05,
      "loss": 0.037,
      "step": 13250
    },
    {
      "epoch": 1.5975903614457831,
      "grad_norm": 1.1300469636917114,
      "learning_rate": 1.6804819277108435e-05,
      "loss": 0.0501,
      "step": 13260
    },
    {
      "epoch": 1.5987951807228917,
      "grad_norm": 0.04443349316716194,
      "learning_rate": 1.6802409638554217e-05,
      "loss": 0.0391,
      "step": 13270
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2734234035015106,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.047,
      "step": 13280
    },
    {
      "epoch": 1.6012048192771084,
      "grad_norm": 7.122837543487549,
      "learning_rate": 1.6797590361445783e-05,
      "loss": 0.0243,
      "step": 13290
    },
    {
      "epoch": 1.6024096385542168,
      "grad_norm": 16.534299850463867,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 0.0981,
      "step": 13300
    },
    {
      "epoch": 1.6036144578313252,
      "grad_norm": 0.03992162272334099,
      "learning_rate": 1.6792771084337353e-05,
      "loss": 0.0364,
      "step": 13310
    },
    {
      "epoch": 1.6048192771084338,
      "grad_norm": 5.049218654632568,
      "learning_rate": 1.6790361445783134e-05,
      "loss": 0.1763,
      "step": 13320
    },
    {
      "epoch": 1.6060240963855423,
      "grad_norm": 7.168239593505859,
      "learning_rate": 1.6787951807228916e-05,
      "loss": 0.1322,
      "step": 13330
    },
    {
      "epoch": 1.6072289156626507,
      "grad_norm": 1.2589259147644043,
      "learning_rate": 1.67855421686747e-05,
      "loss": 0.0546,
      "step": 13340
    },
    {
      "epoch": 1.608433734939759,
      "grad_norm": 0.053878430277109146,
      "learning_rate": 1.6783132530120482e-05,
      "loss": 0.0228,
      "step": 13350
    },
    {
      "epoch": 1.6096385542168674,
      "grad_norm": 11.329604148864746,
      "learning_rate": 1.6780722891566267e-05,
      "loss": 0.0821,
      "step": 13360
    },
    {
      "epoch": 1.6108433734939758,
      "grad_norm": 0.4355858266353607,
      "learning_rate": 1.677831325301205e-05,
      "loss": 0.0288,
      "step": 13370
    },
    {
      "epoch": 1.6120481927710844,
      "grad_norm": 0.030097121372818947,
      "learning_rate": 1.6775903614457834e-05,
      "loss": 0.0066,
      "step": 13380
    },
    {
      "epoch": 1.613253012048193,
      "grad_norm": 0.385338693857193,
      "learning_rate": 1.6773493975903615e-05,
      "loss": 0.1023,
      "step": 13390
    },
    {
      "epoch": 1.6144578313253013,
      "grad_norm": 0.028270872309803963,
      "learning_rate": 1.67710843373494e-05,
      "loss": 0.0548,
      "step": 13400
    },
    {
      "epoch": 1.6156626506024097,
      "grad_norm": 0.451648473739624,
      "learning_rate": 1.676867469879518e-05,
      "loss": 0.0222,
      "step": 13410
    },
    {
      "epoch": 1.616867469879518,
      "grad_norm": 0.08394913375377655,
      "learning_rate": 1.6766265060240966e-05,
      "loss": 0.0293,
      "step": 13420
    },
    {
      "epoch": 1.6180722891566264,
      "grad_norm": 0.031763799488544464,
      "learning_rate": 1.6763855421686748e-05,
      "loss": 0.0765,
      "step": 13430
    },
    {
      "epoch": 1.619277108433735,
      "grad_norm": 13.097594261169434,
      "learning_rate": 1.676144578313253e-05,
      "loss": 0.0834,
      "step": 13440
    },
    {
      "epoch": 1.6204819277108435,
      "grad_norm": 11.642600059509277,
      "learning_rate": 1.6759036144578314e-05,
      "loss": 0.045,
      "step": 13450
    },
    {
      "epoch": 1.621686746987952,
      "grad_norm": 0.14830844104290009,
      "learning_rate": 1.67566265060241e-05,
      "loss": 0.0575,
      "step": 13460
    },
    {
      "epoch": 1.6228915662650603,
      "grad_norm": 4.78174352645874,
      "learning_rate": 1.675421686746988e-05,
      "loss": 0.0948,
      "step": 13470
    },
    {
      "epoch": 1.6240963855421686,
      "grad_norm": 0.1420639008283615,
      "learning_rate": 1.6751807228915665e-05,
      "loss": 0.043,
      "step": 13480
    },
    {
      "epoch": 1.625301204819277,
      "grad_norm": 0.24088051915168762,
      "learning_rate": 1.6749397590361447e-05,
      "loss": 0.0806,
      "step": 13490
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 0.8739490509033203,
      "learning_rate": 1.6746987951807228e-05,
      "loss": 0.0706,
      "step": 13500
    },
    {
      "epoch": 1.627710843373494,
      "grad_norm": 0.5830209255218506,
      "learning_rate": 1.6744578313253013e-05,
      "loss": 0.0393,
      "step": 13510
    },
    {
      "epoch": 1.6289156626506025,
      "grad_norm": 0.017658846452832222,
      "learning_rate": 1.6742168674698795e-05,
      "loss": 0.0063,
      "step": 13520
    },
    {
      "epoch": 1.6301204819277109,
      "grad_norm": 0.015935508534312248,
      "learning_rate": 1.673975903614458e-05,
      "loss": 0.0236,
      "step": 13530
    },
    {
      "epoch": 1.6313253012048192,
      "grad_norm": 10.203858375549316,
      "learning_rate": 1.6737349397590364e-05,
      "loss": 0.0288,
      "step": 13540
    },
    {
      "epoch": 1.6325301204819276,
      "grad_norm": 6.8627095222473145,
      "learning_rate": 1.6734939759036146e-05,
      "loss": 0.0352,
      "step": 13550
    },
    {
      "epoch": 1.6337349397590362,
      "grad_norm": 0.016482247039675713,
      "learning_rate": 1.673253012048193e-05,
      "loss": 0.0853,
      "step": 13560
    },
    {
      "epoch": 1.6349397590361445,
      "grad_norm": 6.851584434509277,
      "learning_rate": 1.6730120481927712e-05,
      "loss": 0.0463,
      "step": 13570
    },
    {
      "epoch": 1.636144578313253,
      "grad_norm": 0.18460749089717865,
      "learning_rate": 1.6727710843373494e-05,
      "loss": 0.0932,
      "step": 13580
    },
    {
      "epoch": 1.6373493975903615,
      "grad_norm": 2.0618364810943604,
      "learning_rate": 1.672530120481928e-05,
      "loss": 0.0305,
      "step": 13590
    },
    {
      "epoch": 1.6385542168674698,
      "grad_norm": 1.9284789562225342,
      "learning_rate": 1.6722891566265063e-05,
      "loss": 0.0435,
      "step": 13600
    },
    {
      "epoch": 1.6397590361445782,
      "grad_norm": 0.529089629650116,
      "learning_rate": 1.6720481927710845e-05,
      "loss": 0.0597,
      "step": 13610
    },
    {
      "epoch": 1.6409638554216868,
      "grad_norm": 3.853302001953125,
      "learning_rate": 1.671807228915663e-05,
      "loss": 0.0845,
      "step": 13620
    },
    {
      "epoch": 1.6421686746987951,
      "grad_norm": 0.44770920276641846,
      "learning_rate": 1.671566265060241e-05,
      "loss": 0.0305,
      "step": 13630
    },
    {
      "epoch": 1.6433734939759037,
      "grad_norm": 0.14855900406837463,
      "learning_rate": 1.6713253012048193e-05,
      "loss": 0.0588,
      "step": 13640
    },
    {
      "epoch": 1.644578313253012,
      "grad_norm": 0.08416835963726044,
      "learning_rate": 1.6710843373493978e-05,
      "loss": 0.0788,
      "step": 13650
    },
    {
      "epoch": 1.6457831325301204,
      "grad_norm": 3.515059471130371,
      "learning_rate": 1.670843373493976e-05,
      "loss": 0.0896,
      "step": 13660
    },
    {
      "epoch": 1.6469879518072288,
      "grad_norm": 2.567629814147949,
      "learning_rate": 1.6706024096385544e-05,
      "loss": 0.0434,
      "step": 13670
    },
    {
      "epoch": 1.6481927710843374,
      "grad_norm": 2.2675814628601074,
      "learning_rate": 1.670361445783133e-05,
      "loss": 0.0424,
      "step": 13680
    },
    {
      "epoch": 1.6493975903614457,
      "grad_norm": 0.03544347360730171,
      "learning_rate": 1.670120481927711e-05,
      "loss": 0.073,
      "step": 13690
    },
    {
      "epoch": 1.6506024096385543,
      "grad_norm": 2.5685465335845947,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 0.03,
      "step": 13700
    },
    {
      "epoch": 1.6518072289156627,
      "grad_norm": 30.43498420715332,
      "learning_rate": 1.6696385542168677e-05,
      "loss": 0.0594,
      "step": 13710
    },
    {
      "epoch": 1.653012048192771,
      "grad_norm": 24.755224227905273,
      "learning_rate": 1.6693975903614458e-05,
      "loss": 0.0394,
      "step": 13720
    },
    {
      "epoch": 1.6542168674698794,
      "grad_norm": 0.05968766659498215,
      "learning_rate": 1.6691566265060243e-05,
      "loss": 0.0594,
      "step": 13730
    },
    {
      "epoch": 1.655421686746988,
      "grad_norm": 0.4788542687892914,
      "learning_rate": 1.6689156626506024e-05,
      "loss": 0.0736,
      "step": 13740
    },
    {
      "epoch": 1.6566265060240963,
      "grad_norm": 0.3335447609424591,
      "learning_rate": 1.668674698795181e-05,
      "loss": 0.0443,
      "step": 13750
    },
    {
      "epoch": 1.657831325301205,
      "grad_norm": 0.3170815110206604,
      "learning_rate": 1.668433734939759e-05,
      "loss": 0.0445,
      "step": 13760
    },
    {
      "epoch": 1.6590361445783133,
      "grad_norm": 1.4570488929748535,
      "learning_rate": 1.6681927710843376e-05,
      "loss": 0.1108,
      "step": 13770
    },
    {
      "epoch": 1.6602409638554216,
      "grad_norm": 0.028437502682209015,
      "learning_rate": 1.6679518072289157e-05,
      "loss": 0.0167,
      "step": 13780
    },
    {
      "epoch": 1.66144578313253,
      "grad_norm": 16.188127517700195,
      "learning_rate": 1.6677108433734942e-05,
      "loss": 0.0467,
      "step": 13790
    },
    {
      "epoch": 1.6626506024096386,
      "grad_norm": 0.043630752712488174,
      "learning_rate": 1.6674698795180724e-05,
      "loss": 0.0265,
      "step": 13800
    },
    {
      "epoch": 1.663855421686747,
      "grad_norm": 14.593069076538086,
      "learning_rate": 1.6672289156626505e-05,
      "loss": 0.1101,
      "step": 13810
    },
    {
      "epoch": 1.6650602409638555,
      "grad_norm": 3.514092206954956,
      "learning_rate": 1.666987951807229e-05,
      "loss": 0.0698,
      "step": 13820
    },
    {
      "epoch": 1.6662650602409639,
      "grad_norm": 3.5051727294921875,
      "learning_rate": 1.6667469879518075e-05,
      "loss": 0.0704,
      "step": 13830
    },
    {
      "epoch": 1.6674698795180722,
      "grad_norm": 18.808883666992188,
      "learning_rate": 1.6665060240963856e-05,
      "loss": 0.0458,
      "step": 13840
    },
    {
      "epoch": 1.6686746987951806,
      "grad_norm": 0.10909692198038101,
      "learning_rate": 1.666265060240964e-05,
      "loss": 0.0189,
      "step": 13850
    },
    {
      "epoch": 1.6698795180722892,
      "grad_norm": 3.6544408798217773,
      "learning_rate": 1.6660240963855423e-05,
      "loss": 0.0959,
      "step": 13860
    },
    {
      "epoch": 1.6710843373493975,
      "grad_norm": 14.462106704711914,
      "learning_rate": 1.6657831325301207e-05,
      "loss": 0.0357,
      "step": 13870
    },
    {
      "epoch": 1.6722891566265061,
      "grad_norm": 2.3974668979644775,
      "learning_rate": 1.665542168674699e-05,
      "loss": 0.053,
      "step": 13880
    },
    {
      "epoch": 1.6734939759036145,
      "grad_norm": 3.823103189468384,
      "learning_rate": 1.665301204819277e-05,
      "loss": 0.0503,
      "step": 13890
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 0.14495228230953217,
      "learning_rate": 1.6650602409638555e-05,
      "loss": 0.0084,
      "step": 13900
    },
    {
      "epoch": 1.6759036144578312,
      "grad_norm": 0.033211156725883484,
      "learning_rate": 1.664819277108434e-05,
      "loss": 0.0103,
      "step": 13910
    },
    {
      "epoch": 1.6771084337349398,
      "grad_norm": 4.646039962768555,
      "learning_rate": 1.664578313253012e-05,
      "loss": 0.0634,
      "step": 13920
    },
    {
      "epoch": 1.6783132530120481,
      "grad_norm": 0.2647572457790375,
      "learning_rate": 1.6643373493975907e-05,
      "loss": 0.0541,
      "step": 13930
    },
    {
      "epoch": 1.6795180722891567,
      "grad_norm": 0.032893262803554535,
      "learning_rate": 1.6640963855421688e-05,
      "loss": 0.0282,
      "step": 13940
    },
    {
      "epoch": 1.680722891566265,
      "grad_norm": 4.755746841430664,
      "learning_rate": 1.663855421686747e-05,
      "loss": 0.0956,
      "step": 13950
    },
    {
      "epoch": 1.6819277108433734,
      "grad_norm": 0.27083587646484375,
      "learning_rate": 1.6636144578313254e-05,
      "loss": 0.0596,
      "step": 13960
    },
    {
      "epoch": 1.6831325301204818,
      "grad_norm": 0.5157225131988525,
      "learning_rate": 1.6633734939759036e-05,
      "loss": 0.0056,
      "step": 13970
    },
    {
      "epoch": 1.6843373493975904,
      "grad_norm": 0.04249933734536171,
      "learning_rate": 1.663132530120482e-05,
      "loss": 0.0291,
      "step": 13980
    },
    {
      "epoch": 1.6855421686746987,
      "grad_norm": 0.8374727964401245,
      "learning_rate": 1.6628915662650606e-05,
      "loss": 0.0314,
      "step": 13990
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 0.017359914258122444,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 0.0509,
      "step": 14000
    },
    {
      "epoch": 1.6879518072289157,
      "grad_norm": 0.3564283847808838,
      "learning_rate": 1.662409638554217e-05,
      "loss": 0.0788,
      "step": 14010
    },
    {
      "epoch": 1.689156626506024,
      "grad_norm": 0.013893667608499527,
      "learning_rate": 1.6621686746987953e-05,
      "loss": 0.0245,
      "step": 14020
    },
    {
      "epoch": 1.6903614457831324,
      "grad_norm": 1.8087408542633057,
      "learning_rate": 1.6619277108433735e-05,
      "loss": 0.0916,
      "step": 14030
    },
    {
      "epoch": 1.691566265060241,
      "grad_norm": 2.4986016750335693,
      "learning_rate": 1.661686746987952e-05,
      "loss": 0.0696,
      "step": 14040
    },
    {
      "epoch": 1.6927710843373494,
      "grad_norm": 2.9668848514556885,
      "learning_rate": 1.6614457831325305e-05,
      "loss": 0.0562,
      "step": 14050
    },
    {
      "epoch": 1.693975903614458,
      "grad_norm": 0.07941973954439163,
      "learning_rate": 1.6612048192771086e-05,
      "loss": 0.0238,
      "step": 14060
    },
    {
      "epoch": 1.6951807228915663,
      "grad_norm": 4.575194358825684,
      "learning_rate": 1.6609638554216868e-05,
      "loss": 0.0347,
      "step": 14070
    },
    {
      "epoch": 1.6963855421686747,
      "grad_norm": 0.9999217987060547,
      "learning_rate": 1.6607228915662652e-05,
      "loss": 0.0208,
      "step": 14080
    },
    {
      "epoch": 1.697590361445783,
      "grad_norm": 0.05573583394289017,
      "learning_rate": 1.6604819277108434e-05,
      "loss": 0.056,
      "step": 14090
    },
    {
      "epoch": 1.6987951807228916,
      "grad_norm": 17.419723510742188,
      "learning_rate": 1.660240963855422e-05,
      "loss": 0.0134,
      "step": 14100
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.28859996795654297,
      "learning_rate": 1.66e-05,
      "loss": 0.0402,
      "step": 14110
    },
    {
      "epoch": 1.7012048192771085,
      "grad_norm": 0.06265696883201599,
      "learning_rate": 1.6597590361445782e-05,
      "loss": 0.0159,
      "step": 14120
    },
    {
      "epoch": 1.702409638554217,
      "grad_norm": 0.06240459531545639,
      "learning_rate": 1.659518072289157e-05,
      "loss": 0.0405,
      "step": 14130
    },
    {
      "epoch": 1.7036144578313253,
      "grad_norm": 0.24819537997245789,
      "learning_rate": 1.659277108433735e-05,
      "loss": 0.0835,
      "step": 14140
    },
    {
      "epoch": 1.7048192771084336,
      "grad_norm": 2.636211395263672,
      "learning_rate": 1.6590361445783133e-05,
      "loss": 0.1074,
      "step": 14150
    },
    {
      "epoch": 1.7060240963855422,
      "grad_norm": 0.19012585282325745,
      "learning_rate": 1.6587951807228918e-05,
      "loss": 0.0778,
      "step": 14160
    },
    {
      "epoch": 1.7072289156626506,
      "grad_norm": 1.61593496799469,
      "learning_rate": 1.65855421686747e-05,
      "loss": 0.1218,
      "step": 14170
    },
    {
      "epoch": 1.7084337349397591,
      "grad_norm": 2.114633321762085,
      "learning_rate": 1.6583132530120484e-05,
      "loss": 0.0407,
      "step": 14180
    },
    {
      "epoch": 1.7096385542168675,
      "grad_norm": 0.5012485980987549,
      "learning_rate": 1.6580722891566266e-05,
      "loss": 0.06,
      "step": 14190
    },
    {
      "epoch": 1.7108433734939759,
      "grad_norm": 5.382534503936768,
      "learning_rate": 1.657831325301205e-05,
      "loss": 0.0372,
      "step": 14200
    },
    {
      "epoch": 1.7120481927710842,
      "grad_norm": 6.958710193634033,
      "learning_rate": 1.6575903614457832e-05,
      "loss": 0.1036,
      "step": 14210
    },
    {
      "epoch": 1.7132530120481928,
      "grad_norm": 0.17583215236663818,
      "learning_rate": 1.6573493975903617e-05,
      "loss": 0.0798,
      "step": 14220
    },
    {
      "epoch": 1.7144578313253012,
      "grad_norm": 33.99644470214844,
      "learning_rate": 1.65710843373494e-05,
      "loss": 0.074,
      "step": 14230
    },
    {
      "epoch": 1.7156626506024097,
      "grad_norm": 0.9693090319633484,
      "learning_rate": 1.6568674698795183e-05,
      "loss": 0.0455,
      "step": 14240
    },
    {
      "epoch": 1.716867469879518,
      "grad_norm": 0.07331318408250809,
      "learning_rate": 1.6566265060240965e-05,
      "loss": 0.0074,
      "step": 14250
    },
    {
      "epoch": 1.7180722891566265,
      "grad_norm": 1.1558243036270142,
      "learning_rate": 1.6563855421686746e-05,
      "loss": 0.0498,
      "step": 14260
    },
    {
      "epoch": 1.7192771084337348,
      "grad_norm": 10.778019905090332,
      "learning_rate": 1.656144578313253e-05,
      "loss": 0.0916,
      "step": 14270
    },
    {
      "epoch": 1.7204819277108434,
      "grad_norm": 0.07389524579048157,
      "learning_rate": 1.6559036144578316e-05,
      "loss": 0.0448,
      "step": 14280
    },
    {
      "epoch": 1.7216867469879518,
      "grad_norm": 0.11448124796152115,
      "learning_rate": 1.6556626506024097e-05,
      "loss": 0.0657,
      "step": 14290
    },
    {
      "epoch": 1.7228915662650603,
      "grad_norm": 6.544312000274658,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 0.0793,
      "step": 14300
    },
    {
      "epoch": 1.7240963855421687,
      "grad_norm": 0.2937898635864258,
      "learning_rate": 1.6551807228915664e-05,
      "loss": 0.0937,
      "step": 14310
    },
    {
      "epoch": 1.725301204819277,
      "grad_norm": 0.29505255818367004,
      "learning_rate": 1.6549397590361445e-05,
      "loss": 0.0551,
      "step": 14320
    },
    {
      "epoch": 1.7265060240963854,
      "grad_norm": 0.06395228207111359,
      "learning_rate": 1.654698795180723e-05,
      "loss": 0.1169,
      "step": 14330
    },
    {
      "epoch": 1.727710843373494,
      "grad_norm": 0.041964512318372726,
      "learning_rate": 1.654457831325301e-05,
      "loss": 0.0935,
      "step": 14340
    },
    {
      "epoch": 1.7289156626506024,
      "grad_norm": 0.9886308312416077,
      "learning_rate": 1.6542168674698797e-05,
      "loss": 0.0669,
      "step": 14350
    },
    {
      "epoch": 1.730120481927711,
      "grad_norm": 0.2260720431804657,
      "learning_rate": 1.653975903614458e-05,
      "loss": 0.0187,
      "step": 14360
    },
    {
      "epoch": 1.7313253012048193,
      "grad_norm": 7.46948766708374,
      "learning_rate": 1.6537349397590363e-05,
      "loss": 0.0466,
      "step": 14370
    },
    {
      "epoch": 1.7325301204819277,
      "grad_norm": 0.2571835517883301,
      "learning_rate": 1.6534939759036144e-05,
      "loss": 0.0338,
      "step": 14380
    },
    {
      "epoch": 1.733734939759036,
      "grad_norm": 3.9814510345458984,
      "learning_rate": 1.653253012048193e-05,
      "loss": 0.0614,
      "step": 14390
    },
    {
      "epoch": 1.7349397590361446,
      "grad_norm": 7.043523788452148,
      "learning_rate": 1.653012048192771e-05,
      "loss": 0.0329,
      "step": 14400
    },
    {
      "epoch": 1.736144578313253,
      "grad_norm": 0.07494035363197327,
      "learning_rate": 1.6527710843373496e-05,
      "loss": 0.1055,
      "step": 14410
    },
    {
      "epoch": 1.7373493975903616,
      "grad_norm": 1.177748203277588,
      "learning_rate": 1.6525301204819277e-05,
      "loss": 0.0776,
      "step": 14420
    },
    {
      "epoch": 1.73855421686747,
      "grad_norm": 3.517573356628418,
      "learning_rate": 1.6522891566265062e-05,
      "loss": 0.1129,
      "step": 14430
    },
    {
      "epoch": 1.7397590361445783,
      "grad_norm": 20.948007583618164,
      "learning_rate": 1.6520481927710847e-05,
      "loss": 0.0297,
      "step": 14440
    },
    {
      "epoch": 1.7409638554216866,
      "grad_norm": 1.1160106658935547,
      "learning_rate": 1.6518072289156628e-05,
      "loss": 0.0619,
      "step": 14450
    },
    {
      "epoch": 1.7421686746987952,
      "grad_norm": 29.8599796295166,
      "learning_rate": 1.651566265060241e-05,
      "loss": 0.1301,
      "step": 14460
    },
    {
      "epoch": 1.7433734939759036,
      "grad_norm": 0.5387232303619385,
      "learning_rate": 1.6513253012048195e-05,
      "loss": 0.0435,
      "step": 14470
    },
    {
      "epoch": 1.7445783132530122,
      "grad_norm": 0.49013441801071167,
      "learning_rate": 1.6510843373493976e-05,
      "loss": 0.051,
      "step": 14480
    },
    {
      "epoch": 1.7457831325301205,
      "grad_norm": 3.7885141372680664,
      "learning_rate": 1.650843373493976e-05,
      "loss": 0.0898,
      "step": 14490
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 0.17435958981513977,
      "learning_rate": 1.6506024096385546e-05,
      "loss": 0.0161,
      "step": 14500
    },
    {
      "epoch": 1.7481927710843372,
      "grad_norm": 2.4067087173461914,
      "learning_rate": 1.6503614457831327e-05,
      "loss": 0.0976,
      "step": 14510
    },
    {
      "epoch": 1.7493975903614458,
      "grad_norm": 22.214189529418945,
      "learning_rate": 1.650120481927711e-05,
      "loss": 0.0735,
      "step": 14520
    },
    {
      "epoch": 1.7506024096385542,
      "grad_norm": 18.222009658813477,
      "learning_rate": 1.6498795180722894e-05,
      "loss": 0.1416,
      "step": 14530
    },
    {
      "epoch": 1.7518072289156628,
      "grad_norm": 0.2541094422340393,
      "learning_rate": 1.6496385542168675e-05,
      "loss": 0.0735,
      "step": 14540
    },
    {
      "epoch": 1.7530120481927711,
      "grad_norm": 9.407480239868164,
      "learning_rate": 1.649397590361446e-05,
      "loss": 0.0898,
      "step": 14550
    },
    {
      "epoch": 1.7542168674698795,
      "grad_norm": 0.990619957447052,
      "learning_rate": 1.649156626506024e-05,
      "loss": 0.041,
      "step": 14560
    },
    {
      "epoch": 1.7554216867469878,
      "grad_norm": 1.002044916152954,
      "learning_rate": 1.6489156626506026e-05,
      "loss": 0.0195,
      "step": 14570
    },
    {
      "epoch": 1.7566265060240964,
      "grad_norm": 13.610323905944824,
      "learning_rate": 1.6486746987951808e-05,
      "loss": 0.0977,
      "step": 14580
    },
    {
      "epoch": 1.7578313253012048,
      "grad_norm": 2.3099122047424316,
      "learning_rate": 1.6484337349397593e-05,
      "loss": 0.0143,
      "step": 14590
    },
    {
      "epoch": 1.7590361445783134,
      "grad_norm": 0.6238057613372803,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 0.0862,
      "step": 14600
    },
    {
      "epoch": 1.7602409638554217,
      "grad_norm": 8.089193344116211,
      "learning_rate": 1.647951807228916e-05,
      "loss": 0.0683,
      "step": 14610
    },
    {
      "epoch": 1.76144578313253,
      "grad_norm": 6.630978584289551,
      "learning_rate": 1.647710843373494e-05,
      "loss": 0.05,
      "step": 14620
    },
    {
      "epoch": 1.7626506024096384,
      "grad_norm": 0.049959342926740646,
      "learning_rate": 1.6474698795180722e-05,
      "loss": 0.0116,
      "step": 14630
    },
    {
      "epoch": 1.763855421686747,
      "grad_norm": 7.018287181854248,
      "learning_rate": 1.6472289156626507e-05,
      "loss": 0.0876,
      "step": 14640
    },
    {
      "epoch": 1.7650602409638554,
      "grad_norm": 1.629267930984497,
      "learning_rate": 1.6469879518072292e-05,
      "loss": 0.0486,
      "step": 14650
    },
    {
      "epoch": 1.766265060240964,
      "grad_norm": 0.47455301880836487,
      "learning_rate": 1.6467469879518073e-05,
      "loss": 0.0997,
      "step": 14660
    },
    {
      "epoch": 1.7674698795180723,
      "grad_norm": 6.278972625732422,
      "learning_rate": 1.6465060240963858e-05,
      "loss": 0.0645,
      "step": 14670
    },
    {
      "epoch": 1.7686746987951807,
      "grad_norm": 5.061389446258545,
      "learning_rate": 1.646265060240964e-05,
      "loss": 0.0395,
      "step": 14680
    },
    {
      "epoch": 1.769879518072289,
      "grad_norm": 0.11410430818796158,
      "learning_rate": 1.646024096385542e-05,
      "loss": 0.045,
      "step": 14690
    },
    {
      "epoch": 1.7710843373493976,
      "grad_norm": 0.24834907054901123,
      "learning_rate": 1.6457831325301206e-05,
      "loss": 0.0121,
      "step": 14700
    },
    {
      "epoch": 1.772289156626506,
      "grad_norm": 3.3105409145355225,
      "learning_rate": 1.6455421686746987e-05,
      "loss": 0.0683,
      "step": 14710
    },
    {
      "epoch": 1.7734939759036146,
      "grad_norm": 0.6701492667198181,
      "learning_rate": 1.6453012048192772e-05,
      "loss": 0.0555,
      "step": 14720
    },
    {
      "epoch": 1.774698795180723,
      "grad_norm": 0.24003176391124725,
      "learning_rate": 1.6450602409638557e-05,
      "loss": 0.0414,
      "step": 14730
    },
    {
      "epoch": 1.7759036144578313,
      "grad_norm": 4.002082347869873,
      "learning_rate": 1.644819277108434e-05,
      "loss": 0.0443,
      "step": 14740
    },
    {
      "epoch": 1.7771084337349397,
      "grad_norm": 32.21514129638672,
      "learning_rate": 1.6445783132530124e-05,
      "loss": 0.0549,
      "step": 14750
    },
    {
      "epoch": 1.7783132530120482,
      "grad_norm": 3.571439266204834,
      "learning_rate": 1.6443373493975905e-05,
      "loss": 0.0574,
      "step": 14760
    },
    {
      "epoch": 1.7795180722891566,
      "grad_norm": 0.27119696140289307,
      "learning_rate": 1.6440963855421687e-05,
      "loss": 0.0683,
      "step": 14770
    },
    {
      "epoch": 1.7807228915662652,
      "grad_norm": 0.14045220613479614,
      "learning_rate": 1.643855421686747e-05,
      "loss": 0.0237,
      "step": 14780
    },
    {
      "epoch": 1.7819277108433735,
      "grad_norm": 1.069930911064148,
      "learning_rate": 1.6436144578313253e-05,
      "loss": 0.0761,
      "step": 14790
    },
    {
      "epoch": 1.783132530120482,
      "grad_norm": 0.15834325551986694,
      "learning_rate": 1.6433734939759038e-05,
      "loss": 0.0238,
      "step": 14800
    },
    {
      "epoch": 1.7843373493975903,
      "grad_norm": 6.098823070526123,
      "learning_rate": 1.6431325301204823e-05,
      "loss": 0.0733,
      "step": 14810
    },
    {
      "epoch": 1.7855421686746988,
      "grad_norm": 0.2726646661758423,
      "learning_rate": 1.6428915662650604e-05,
      "loss": 0.0628,
      "step": 14820
    },
    {
      "epoch": 1.7867469879518072,
      "grad_norm": 0.06420809775590897,
      "learning_rate": 1.6426506024096386e-05,
      "loss": 0.1059,
      "step": 14830
    },
    {
      "epoch": 1.7879518072289158,
      "grad_norm": 0.11609067767858505,
      "learning_rate": 1.642409638554217e-05,
      "loss": 0.0599,
      "step": 14840
    },
    {
      "epoch": 1.7891566265060241,
      "grad_norm": 8.767024993896484,
      "learning_rate": 1.6421686746987952e-05,
      "loss": 0.0778,
      "step": 14850
    },
    {
      "epoch": 1.7903614457831325,
      "grad_norm": 19.305477142333984,
      "learning_rate": 1.6419277108433737e-05,
      "loss": 0.0389,
      "step": 14860
    },
    {
      "epoch": 1.7915662650602409,
      "grad_norm": 0.0891469419002533,
      "learning_rate": 1.641686746987952e-05,
      "loss": 0.0066,
      "step": 14870
    },
    {
      "epoch": 1.7927710843373494,
      "grad_norm": 39.5124626159668,
      "learning_rate": 1.6414457831325303e-05,
      "loss": 0.0564,
      "step": 14880
    },
    {
      "epoch": 1.7939759036144578,
      "grad_norm": 2.1522867679595947,
      "learning_rate": 1.6412048192771085e-05,
      "loss": 0.0092,
      "step": 14890
    },
    {
      "epoch": 1.7951807228915664,
      "grad_norm": 0.039599012583494186,
      "learning_rate": 1.640963855421687e-05,
      "loss": 0.0688,
      "step": 14900
    },
    {
      "epoch": 1.7963855421686747,
      "grad_norm": 2.9738476276397705,
      "learning_rate": 1.640722891566265e-05,
      "loss": 0.0319,
      "step": 14910
    },
    {
      "epoch": 1.797590361445783,
      "grad_norm": 14.073233604431152,
      "learning_rate": 1.6404819277108436e-05,
      "loss": 0.0999,
      "step": 14920
    },
    {
      "epoch": 1.7987951807228915,
      "grad_norm": 0.09961040318012238,
      "learning_rate": 1.6402409638554217e-05,
      "loss": 0.012,
      "step": 14930
    },
    {
      "epoch": 1.8,
      "grad_norm": 11.715291976928711,
      "learning_rate": 1.64e-05,
      "loss": 0.0697,
      "step": 14940
    },
    {
      "epoch": 1.8012048192771084,
      "grad_norm": 1.3195092678070068,
      "learning_rate": 1.6397590361445787e-05,
      "loss": 0.0774,
      "step": 14950
    },
    {
      "epoch": 1.802409638554217,
      "grad_norm": 0.40939861536026,
      "learning_rate": 1.639518072289157e-05,
      "loss": 0.0819,
      "step": 14960
    },
    {
      "epoch": 1.8036144578313253,
      "grad_norm": 2.257657289505005,
      "learning_rate": 1.639277108433735e-05,
      "loss": 0.0409,
      "step": 14970
    },
    {
      "epoch": 1.8048192771084337,
      "grad_norm": 0.49690863490104675,
      "learning_rate": 1.6390361445783135e-05,
      "loss": 0.0496,
      "step": 14980
    },
    {
      "epoch": 1.806024096385542,
      "grad_norm": 0.2448137104511261,
      "learning_rate": 1.6387951807228916e-05,
      "loss": 0.0469,
      "step": 14990
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 0.06490745395421982,
      "learning_rate": 1.63855421686747e-05,
      "loss": 0.0636,
      "step": 15000
    },
    {
      "epoch": 1.808433734939759,
      "grad_norm": 0.04558630660176277,
      "learning_rate": 1.6383132530120483e-05,
      "loss": 0.0405,
      "step": 15010
    },
    {
      "epoch": 1.8096385542168676,
      "grad_norm": 7.317164897918701,
      "learning_rate": 1.6380722891566268e-05,
      "loss": 0.0529,
      "step": 15020
    },
    {
      "epoch": 1.810843373493976,
      "grad_norm": 0.0149926096200943,
      "learning_rate": 1.637831325301205e-05,
      "loss": 0.0521,
      "step": 15030
    },
    {
      "epoch": 1.8120481927710843,
      "grad_norm": 0.4012855589389801,
      "learning_rate": 1.6375903614457834e-05,
      "loss": 0.0348,
      "step": 15040
    },
    {
      "epoch": 1.8132530120481927,
      "grad_norm": 0.06003314629197121,
      "learning_rate": 1.6373493975903615e-05,
      "loss": 0.0135,
      "step": 15050
    },
    {
      "epoch": 1.8144578313253013,
      "grad_norm": 8.57124137878418,
      "learning_rate": 1.63710843373494e-05,
      "loss": 0.145,
      "step": 15060
    },
    {
      "epoch": 1.8156626506024096,
      "grad_norm": 0.16381968557834625,
      "learning_rate": 1.6368674698795182e-05,
      "loss": 0.0325,
      "step": 15070
    },
    {
      "epoch": 1.8168674698795182,
      "grad_norm": 0.2299491912126541,
      "learning_rate": 1.6366265060240963e-05,
      "loss": 0.0468,
      "step": 15080
    },
    {
      "epoch": 1.8180722891566266,
      "grad_norm": 2.31352162361145,
      "learning_rate": 1.6363855421686748e-05,
      "loss": 0.0979,
      "step": 15090
    },
    {
      "epoch": 1.819277108433735,
      "grad_norm": 0.8488830327987671,
      "learning_rate": 1.6361445783132533e-05,
      "loss": 0.0556,
      "step": 15100
    },
    {
      "epoch": 1.8204819277108433,
      "grad_norm": 0.02115810662508011,
      "learning_rate": 1.6359036144578315e-05,
      "loss": 0.0586,
      "step": 15110
    },
    {
      "epoch": 1.8216867469879519,
      "grad_norm": 0.5959231853485107,
      "learning_rate": 1.63566265060241e-05,
      "loss": 0.1126,
      "step": 15120
    },
    {
      "epoch": 1.8228915662650602,
      "grad_norm": 0.04721430689096451,
      "learning_rate": 1.635421686746988e-05,
      "loss": 0.0176,
      "step": 15130
    },
    {
      "epoch": 1.8240963855421688,
      "grad_norm": 22.864707946777344,
      "learning_rate": 1.6351807228915662e-05,
      "loss": 0.0825,
      "step": 15140
    },
    {
      "epoch": 1.8253012048192772,
      "grad_norm": 2.1096339225769043,
      "learning_rate": 1.6349397590361447e-05,
      "loss": 0.0373,
      "step": 15150
    },
    {
      "epoch": 1.8265060240963855,
      "grad_norm": 2.920504570007324,
      "learning_rate": 1.634698795180723e-05,
      "loss": 0.0475,
      "step": 15160
    },
    {
      "epoch": 1.8277108433734939,
      "grad_norm": 10.651074409484863,
      "learning_rate": 1.6344578313253014e-05,
      "loss": 0.0651,
      "step": 15170
    },
    {
      "epoch": 1.8289156626506025,
      "grad_norm": 4.626917839050293,
      "learning_rate": 1.63421686746988e-05,
      "loss": 0.0643,
      "step": 15180
    },
    {
      "epoch": 1.8301204819277108,
      "grad_norm": 6.898553848266602,
      "learning_rate": 1.633975903614458e-05,
      "loss": 0.0546,
      "step": 15190
    },
    {
      "epoch": 1.8313253012048194,
      "grad_norm": 0.12463880330324173,
      "learning_rate": 1.633734939759036e-05,
      "loss": 0.0627,
      "step": 15200
    },
    {
      "epoch": 1.8325301204819278,
      "grad_norm": 0.42317911982536316,
      "learning_rate": 1.6334939759036146e-05,
      "loss": 0.0319,
      "step": 15210
    },
    {
      "epoch": 1.8337349397590361,
      "grad_norm": 0.042364124208688736,
      "learning_rate": 1.6332530120481928e-05,
      "loss": 0.0665,
      "step": 15220
    },
    {
      "epoch": 1.8349397590361445,
      "grad_norm": 0.02005373127758503,
      "learning_rate": 1.6330120481927713e-05,
      "loss": 0.0808,
      "step": 15230
    },
    {
      "epoch": 1.836144578313253,
      "grad_norm": 0.16725260019302368,
      "learning_rate": 1.6327710843373494e-05,
      "loss": 0.0324,
      "step": 15240
    },
    {
      "epoch": 1.8373493975903614,
      "grad_norm": 0.011424930766224861,
      "learning_rate": 1.632530120481928e-05,
      "loss": 0.0549,
      "step": 15250
    },
    {
      "epoch": 1.83855421686747,
      "grad_norm": 0.018437273800373077,
      "learning_rate": 1.6322891566265064e-05,
      "loss": 0.0613,
      "step": 15260
    },
    {
      "epoch": 1.8397590361445784,
      "grad_norm": 0.12641453742980957,
      "learning_rate": 1.6320481927710845e-05,
      "loss": 0.0294,
      "step": 15270
    },
    {
      "epoch": 1.8409638554216867,
      "grad_norm": 1.8003965616226196,
      "learning_rate": 1.6318072289156627e-05,
      "loss": 0.0371,
      "step": 15280
    },
    {
      "epoch": 1.842168674698795,
      "grad_norm": 0.10002445429563522,
      "learning_rate": 1.631566265060241e-05,
      "loss": 0.0346,
      "step": 15290
    },
    {
      "epoch": 1.8433734939759037,
      "grad_norm": 4.4683756828308105,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 0.0724,
      "step": 15300
    },
    {
      "epoch": 1.844578313253012,
      "grad_norm": 0.009763947688043118,
      "learning_rate": 1.6310843373493978e-05,
      "loss": 0.0467,
      "step": 15310
    },
    {
      "epoch": 1.8457831325301206,
      "grad_norm": 2.3143248558044434,
      "learning_rate": 1.6308433734939763e-05,
      "loss": 0.1024,
      "step": 15320
    },
    {
      "epoch": 1.846987951807229,
      "grad_norm": 7.212233543395996,
      "learning_rate": 1.6306024096385544e-05,
      "loss": 0.0524,
      "step": 15330
    },
    {
      "epoch": 1.8481927710843373,
      "grad_norm": 29.929466247558594,
      "learning_rate": 1.6303614457831326e-05,
      "loss": 0.0556,
      "step": 15340
    },
    {
      "epoch": 1.8493975903614457,
      "grad_norm": 13.414068222045898,
      "learning_rate": 1.630120481927711e-05,
      "loss": 0.0269,
      "step": 15350
    },
    {
      "epoch": 1.8506024096385543,
      "grad_norm": 4.757722854614258,
      "learning_rate": 1.6298795180722892e-05,
      "loss": 0.0198,
      "step": 15360
    },
    {
      "epoch": 1.8518072289156626,
      "grad_norm": 0.03579781949520111,
      "learning_rate": 1.6296385542168677e-05,
      "loss": 0.0485,
      "step": 15370
    },
    {
      "epoch": 1.8530120481927712,
      "grad_norm": 5.366162300109863,
      "learning_rate": 1.629397590361446e-05,
      "loss": 0.0286,
      "step": 15380
    },
    {
      "epoch": 1.8542168674698796,
      "grad_norm": 0.06470735371112823,
      "learning_rate": 1.629156626506024e-05,
      "loss": 0.064,
      "step": 15390
    },
    {
      "epoch": 1.855421686746988,
      "grad_norm": 0.47096437215805054,
      "learning_rate": 1.6289156626506025e-05,
      "loss": 0.0181,
      "step": 15400
    },
    {
      "epoch": 1.8566265060240963,
      "grad_norm": 12.977572441101074,
      "learning_rate": 1.628674698795181e-05,
      "loss": 0.1434,
      "step": 15410
    },
    {
      "epoch": 1.8578313253012049,
      "grad_norm": 0.015331819653511047,
      "learning_rate": 1.628433734939759e-05,
      "loss": 0.0834,
      "step": 15420
    },
    {
      "epoch": 1.8590361445783132,
      "grad_norm": 0.6423218846321106,
      "learning_rate": 1.6281927710843376e-05,
      "loss": 0.0497,
      "step": 15430
    },
    {
      "epoch": 1.8602409638554218,
      "grad_norm": 31.97392463684082,
      "learning_rate": 1.6279518072289158e-05,
      "loss": 0.0327,
      "step": 15440
    },
    {
      "epoch": 1.8614457831325302,
      "grad_norm": 5.81317663192749,
      "learning_rate": 1.627710843373494e-05,
      "loss": 0.0878,
      "step": 15450
    },
    {
      "epoch": 1.8626506024096385,
      "grad_norm": 1.675637125968933,
      "learning_rate": 1.6274698795180724e-05,
      "loss": 0.0605,
      "step": 15460
    },
    {
      "epoch": 1.863855421686747,
      "grad_norm": 2.331191301345825,
      "learning_rate": 1.627228915662651e-05,
      "loss": 0.0336,
      "step": 15470
    },
    {
      "epoch": 1.8650602409638555,
      "grad_norm": 0.024097904562950134,
      "learning_rate": 1.626987951807229e-05,
      "loss": 0.0531,
      "step": 15480
    },
    {
      "epoch": 1.8662650602409638,
      "grad_norm": 5.8632941246032715,
      "learning_rate": 1.6267469879518075e-05,
      "loss": 0.088,
      "step": 15490
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 3.1558780670166016,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 0.0585,
      "step": 15500
    },
    {
      "epoch": 1.8686746987951808,
      "grad_norm": 51.932952880859375,
      "learning_rate": 1.6262650602409638e-05,
      "loss": 0.0513,
      "step": 15510
    },
    {
      "epoch": 1.8698795180722891,
      "grad_norm": 3.87966251373291,
      "learning_rate": 1.6260240963855423e-05,
      "loss": 0.0506,
      "step": 15520
    },
    {
      "epoch": 1.8710843373493975,
      "grad_norm": 25.442293167114258,
      "learning_rate": 1.6257831325301205e-05,
      "loss": 0.087,
      "step": 15530
    },
    {
      "epoch": 1.872289156626506,
      "grad_norm": 5.261068344116211,
      "learning_rate": 1.625542168674699e-05,
      "loss": 0.1337,
      "step": 15540
    },
    {
      "epoch": 1.8734939759036144,
      "grad_norm": 10.238334655761719,
      "learning_rate": 1.6253012048192774e-05,
      "loss": 0.0455,
      "step": 15550
    },
    {
      "epoch": 1.874698795180723,
      "grad_norm": 0.10240644961595535,
      "learning_rate": 1.6250602409638556e-05,
      "loss": 0.0536,
      "step": 15560
    },
    {
      "epoch": 1.8759036144578314,
      "grad_norm": 0.38671281933784485,
      "learning_rate": 1.624819277108434e-05,
      "loss": 0.0421,
      "step": 15570
    },
    {
      "epoch": 1.8771084337349397,
      "grad_norm": 5.792988300323486,
      "learning_rate": 1.6245783132530122e-05,
      "loss": 0.0727,
      "step": 15580
    },
    {
      "epoch": 1.878313253012048,
      "grad_norm": 0.14195549488067627,
      "learning_rate": 1.6243373493975904e-05,
      "loss": 0.0414,
      "step": 15590
    },
    {
      "epoch": 1.8795180722891565,
      "grad_norm": 0.07533536106348038,
      "learning_rate": 1.624096385542169e-05,
      "loss": 0.014,
      "step": 15600
    },
    {
      "epoch": 1.880722891566265,
      "grad_norm": 21.811233520507812,
      "learning_rate": 1.623855421686747e-05,
      "loss": 0.0537,
      "step": 15610
    },
    {
      "epoch": 1.8819277108433736,
      "grad_norm": 0.041154105216264725,
      "learning_rate": 1.6236144578313255e-05,
      "loss": 0.0473,
      "step": 15620
    },
    {
      "epoch": 1.883132530120482,
      "grad_norm": 20.259910583496094,
      "learning_rate": 1.623373493975904e-05,
      "loss": 0.0757,
      "step": 15630
    },
    {
      "epoch": 1.8843373493975903,
      "grad_norm": 3.6858017444610596,
      "learning_rate": 1.623132530120482e-05,
      "loss": 0.1415,
      "step": 15640
    },
    {
      "epoch": 1.8855421686746987,
      "grad_norm": 0.7372012734413147,
      "learning_rate": 1.6228915662650603e-05,
      "loss": 0.037,
      "step": 15650
    },
    {
      "epoch": 1.886746987951807,
      "grad_norm": 0.9407022595405579,
      "learning_rate": 1.6226506024096388e-05,
      "loss": 0.0385,
      "step": 15660
    },
    {
      "epoch": 1.8879518072289156,
      "grad_norm": 0.037395574152469635,
      "learning_rate": 1.622409638554217e-05,
      "loss": 0.0528,
      "step": 15670
    },
    {
      "epoch": 1.8891566265060242,
      "grad_norm": 11.027541160583496,
      "learning_rate": 1.6221686746987954e-05,
      "loss": 0.0993,
      "step": 15680
    },
    {
      "epoch": 1.8903614457831326,
      "grad_norm": 0.13889732956886292,
      "learning_rate": 1.6219277108433735e-05,
      "loss": 0.0636,
      "step": 15690
    },
    {
      "epoch": 1.891566265060241,
      "grad_norm": 22.100069046020508,
      "learning_rate": 1.621686746987952e-05,
      "loss": 0.0573,
      "step": 15700
    },
    {
      "epoch": 1.8927710843373493,
      "grad_norm": 0.4001227617263794,
      "learning_rate": 1.62144578313253e-05,
      "loss": 0.0556,
      "step": 15710
    },
    {
      "epoch": 1.8939759036144577,
      "grad_norm": 0.6471309065818787,
      "learning_rate": 1.6212048192771087e-05,
      "loss": 0.1006,
      "step": 15720
    },
    {
      "epoch": 1.8951807228915662,
      "grad_norm": 0.20732900500297546,
      "learning_rate": 1.6209638554216868e-05,
      "loss": 0.0807,
      "step": 15730
    },
    {
      "epoch": 1.8963855421686748,
      "grad_norm": 0.13170218467712402,
      "learning_rate": 1.6207228915662653e-05,
      "loss": 0.0824,
      "step": 15740
    },
    {
      "epoch": 1.8975903614457832,
      "grad_norm": 3.7003438472747803,
      "learning_rate": 1.6204819277108434e-05,
      "loss": 0.0219,
      "step": 15750
    },
    {
      "epoch": 1.8987951807228916,
      "grad_norm": 12.494640350341797,
      "learning_rate": 1.6202409638554216e-05,
      "loss": 0.0476,
      "step": 15760
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.26870328187942505,
      "learning_rate": 1.62e-05,
      "loss": 0.0727,
      "step": 15770
    },
    {
      "epoch": 1.9012048192771083,
      "grad_norm": 0.05840909481048584,
      "learning_rate": 1.6197590361445786e-05,
      "loss": 0.0493,
      "step": 15780
    },
    {
      "epoch": 1.9024096385542169,
      "grad_norm": 0.049325358122587204,
      "learning_rate": 1.6195180722891567e-05,
      "loss": 0.051,
      "step": 15790
    },
    {
      "epoch": 1.9036144578313254,
      "grad_norm": 4.056490421295166,
      "learning_rate": 1.6192771084337352e-05,
      "loss": 0.0165,
      "step": 15800
    },
    {
      "epoch": 1.9048192771084338,
      "grad_norm": 4.574377059936523,
      "learning_rate": 1.6190361445783133e-05,
      "loss": 0.0908,
      "step": 15810
    },
    {
      "epoch": 1.9060240963855422,
      "grad_norm": 14.713818550109863,
      "learning_rate": 1.6187951807228915e-05,
      "loss": 0.1708,
      "step": 15820
    },
    {
      "epoch": 1.9072289156626505,
      "grad_norm": 5.672247409820557,
      "learning_rate": 1.61855421686747e-05,
      "loss": 0.0717,
      "step": 15830
    },
    {
      "epoch": 1.9084337349397589,
      "grad_norm": 0.03922209143638611,
      "learning_rate": 1.618313253012048e-05,
      "loss": 0.0634,
      "step": 15840
    },
    {
      "epoch": 1.9096385542168675,
      "grad_norm": 2.271822929382324,
      "learning_rate": 1.6180722891566266e-05,
      "loss": 0.038,
      "step": 15850
    },
    {
      "epoch": 1.910843373493976,
      "grad_norm": 1.7815290689468384,
      "learning_rate": 1.617831325301205e-05,
      "loss": 0.0272,
      "step": 15860
    },
    {
      "epoch": 1.9120481927710844,
      "grad_norm": 0.053475335240364075,
      "learning_rate": 1.6175903614457833e-05,
      "loss": 0.0336,
      "step": 15870
    },
    {
      "epoch": 1.9132530120481928,
      "grad_norm": 23.46004295349121,
      "learning_rate": 1.6173493975903617e-05,
      "loss": 0.0828,
      "step": 15880
    },
    {
      "epoch": 1.9144578313253011,
      "grad_norm": 0.09717023372650146,
      "learning_rate": 1.61710843373494e-05,
      "loss": 0.0569,
      "step": 15890
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 0.28729867935180664,
      "learning_rate": 1.616867469879518e-05,
      "loss": 0.0797,
      "step": 15900
    },
    {
      "epoch": 1.916867469879518,
      "grad_norm": 5.542536735534668,
      "learning_rate": 1.6166265060240965e-05,
      "loss": 0.0397,
      "step": 15910
    },
    {
      "epoch": 1.9180722891566266,
      "grad_norm": 0.08715998381376266,
      "learning_rate": 1.616385542168675e-05,
      "loss": 0.0551,
      "step": 15920
    },
    {
      "epoch": 1.919277108433735,
      "grad_norm": 10.229029655456543,
      "learning_rate": 1.616144578313253e-05,
      "loss": 0.0668,
      "step": 15930
    },
    {
      "epoch": 1.9204819277108434,
      "grad_norm": 7.433996200561523,
      "learning_rate": 1.6159036144578316e-05,
      "loss": 0.024,
      "step": 15940
    },
    {
      "epoch": 1.9216867469879517,
      "grad_norm": 2.8247921466827393,
      "learning_rate": 1.6156626506024098e-05,
      "loss": 0.0754,
      "step": 15950
    },
    {
      "epoch": 1.92289156626506,
      "grad_norm": 1.2576115131378174,
      "learning_rate": 1.615421686746988e-05,
      "loss": 0.0804,
      "step": 15960
    },
    {
      "epoch": 1.9240963855421687,
      "grad_norm": 1.1050740480422974,
      "learning_rate": 1.6151807228915664e-05,
      "loss": 0.0327,
      "step": 15970
    },
    {
      "epoch": 1.9253012048192772,
      "grad_norm": 23.513566970825195,
      "learning_rate": 1.6149397590361446e-05,
      "loss": 0.1002,
      "step": 15980
    },
    {
      "epoch": 1.9265060240963856,
      "grad_norm": 0.5142925977706909,
      "learning_rate": 1.614698795180723e-05,
      "loss": 0.1093,
      "step": 15990
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 3.9373841285705566,
      "learning_rate": 1.6144578313253015e-05,
      "loss": 0.0811,
      "step": 16000
    },
    {
      "epoch": 1.9289156626506023,
      "grad_norm": 5.988649845123291,
      "learning_rate": 1.6142168674698797e-05,
      "loss": 0.0608,
      "step": 16010
    },
    {
      "epoch": 1.9301204819277107,
      "grad_norm": 0.6372482180595398,
      "learning_rate": 1.613975903614458e-05,
      "loss": 0.0625,
      "step": 16020
    },
    {
      "epoch": 1.9313253012048193,
      "grad_norm": 0.5705800652503967,
      "learning_rate": 1.6137349397590363e-05,
      "loss": 0.0595,
      "step": 16030
    },
    {
      "epoch": 1.9325301204819278,
      "grad_norm": 2.662156581878662,
      "learning_rate": 1.6134939759036145e-05,
      "loss": 0.0442,
      "step": 16040
    },
    {
      "epoch": 1.9337349397590362,
      "grad_norm": 5.61121129989624,
      "learning_rate": 1.613253012048193e-05,
      "loss": 0.0852,
      "step": 16050
    },
    {
      "epoch": 1.9349397590361446,
      "grad_norm": 0.23850877583026886,
      "learning_rate": 1.613012048192771e-05,
      "loss": 0.0276,
      "step": 16060
    },
    {
      "epoch": 1.936144578313253,
      "grad_norm": 3.641685724258423,
      "learning_rate": 1.6127710843373496e-05,
      "loss": 0.0277,
      "step": 16070
    },
    {
      "epoch": 1.9373493975903613,
      "grad_norm": 4.667630195617676,
      "learning_rate": 1.6125301204819278e-05,
      "loss": 0.1117,
      "step": 16080
    },
    {
      "epoch": 1.9385542168674699,
      "grad_norm": 0.5578436851501465,
      "learning_rate": 1.6122891566265062e-05,
      "loss": 0.0836,
      "step": 16090
    },
    {
      "epoch": 1.9397590361445785,
      "grad_norm": 11.126879692077637,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 0.0596,
      "step": 16100
    },
    {
      "epoch": 1.9409638554216868,
      "grad_norm": 7.129012107849121,
      "learning_rate": 1.611807228915663e-05,
      "loss": 0.1085,
      "step": 16110
    },
    {
      "epoch": 1.9421686746987952,
      "grad_norm": 0.3166109025478363,
      "learning_rate": 1.611566265060241e-05,
      "loss": 0.0682,
      "step": 16120
    },
    {
      "epoch": 1.9433734939759035,
      "grad_norm": 4.47923469543457,
      "learning_rate": 1.6113253012048192e-05,
      "loss": 0.0543,
      "step": 16130
    },
    {
      "epoch": 1.944578313253012,
      "grad_norm": 0.058792516589164734,
      "learning_rate": 1.6110843373493977e-05,
      "loss": 0.0359,
      "step": 16140
    },
    {
      "epoch": 1.9457831325301205,
      "grad_norm": 1.2496955394744873,
      "learning_rate": 1.610843373493976e-05,
      "loss": 0.0206,
      "step": 16150
    },
    {
      "epoch": 1.946987951807229,
      "grad_norm": 10.677783966064453,
      "learning_rate": 1.6106024096385543e-05,
      "loss": 0.05,
      "step": 16160
    },
    {
      "epoch": 1.9481927710843374,
      "grad_norm": 0.6436176896095276,
      "learning_rate": 1.6103614457831328e-05,
      "loss": 0.0345,
      "step": 16170
    },
    {
      "epoch": 1.9493975903614458,
      "grad_norm": 1.7973566055297852,
      "learning_rate": 1.610120481927711e-05,
      "loss": 0.0651,
      "step": 16180
    },
    {
      "epoch": 1.9506024096385541,
      "grad_norm": 2.9178755283355713,
      "learning_rate": 1.6098795180722894e-05,
      "loss": 0.0103,
      "step": 16190
    },
    {
      "epoch": 1.9518072289156625,
      "grad_norm": 1.0414116382598877,
      "learning_rate": 1.6096385542168676e-05,
      "loss": 0.0476,
      "step": 16200
    },
    {
      "epoch": 1.953012048192771,
      "grad_norm": 1.7733702659606934,
      "learning_rate": 1.6093975903614457e-05,
      "loss": 0.0729,
      "step": 16210
    },
    {
      "epoch": 1.9542168674698797,
      "grad_norm": 3.9941446781158447,
      "learning_rate": 1.6091566265060242e-05,
      "loss": 0.0884,
      "step": 16220
    },
    {
      "epoch": 1.955421686746988,
      "grad_norm": 7.390434741973877,
      "learning_rate": 1.6089156626506027e-05,
      "loss": 0.0322,
      "step": 16230
    },
    {
      "epoch": 1.9566265060240964,
      "grad_norm": 0.02304026111960411,
      "learning_rate": 1.608674698795181e-05,
      "loss": 0.003,
      "step": 16240
    },
    {
      "epoch": 1.9578313253012047,
      "grad_norm": 13.936795234680176,
      "learning_rate": 1.6084337349397593e-05,
      "loss": 0.0776,
      "step": 16250
    },
    {
      "epoch": 1.959036144578313,
      "grad_norm": 4.324171543121338,
      "learning_rate": 1.6081927710843375e-05,
      "loss": 0.0963,
      "step": 16260
    },
    {
      "epoch": 1.9602409638554217,
      "grad_norm": 0.13863222301006317,
      "learning_rate": 1.6079518072289156e-05,
      "loss": 0.0539,
      "step": 16270
    },
    {
      "epoch": 1.9614457831325303,
      "grad_norm": 1.8521599769592285,
      "learning_rate": 1.607710843373494e-05,
      "loss": 0.0698,
      "step": 16280
    },
    {
      "epoch": 1.9626506024096386,
      "grad_norm": 18.06621551513672,
      "learning_rate": 1.6074698795180723e-05,
      "loss": 0.0387,
      "step": 16290
    },
    {
      "epoch": 1.963855421686747,
      "grad_norm": 6.231488227844238,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 0.0914,
      "step": 16300
    },
    {
      "epoch": 1.9650602409638553,
      "grad_norm": 0.36339470744132996,
      "learning_rate": 1.6069879518072292e-05,
      "loss": 0.0084,
      "step": 16310
    },
    {
      "epoch": 1.9662650602409637,
      "grad_norm": 9.67548942565918,
      "learning_rate": 1.6067469879518074e-05,
      "loss": 0.0685,
      "step": 16320
    },
    {
      "epoch": 1.9674698795180723,
      "grad_norm": 7.750781536102295,
      "learning_rate": 1.6065060240963855e-05,
      "loss": 0.0848,
      "step": 16330
    },
    {
      "epoch": 1.9686746987951809,
      "grad_norm": 2.5326409339904785,
      "learning_rate": 1.606265060240964e-05,
      "loss": 0.0417,
      "step": 16340
    },
    {
      "epoch": 1.9698795180722892,
      "grad_norm": 0.3766997158527374,
      "learning_rate": 1.606024096385542e-05,
      "loss": 0.054,
      "step": 16350
    },
    {
      "epoch": 1.9710843373493976,
      "grad_norm": 0.01630469225347042,
      "learning_rate": 1.6057831325301206e-05,
      "loss": 0.0252,
      "step": 16360
    },
    {
      "epoch": 1.972289156626506,
      "grad_norm": 4.2164692878723145,
      "learning_rate": 1.605542168674699e-05,
      "loss": 0.0752,
      "step": 16370
    },
    {
      "epoch": 1.9734939759036143,
      "grad_norm": 3.421431064605713,
      "learning_rate": 1.6053012048192773e-05,
      "loss": 0.1126,
      "step": 16380
    },
    {
      "epoch": 1.9746987951807229,
      "grad_norm": 2.329296827316284,
      "learning_rate": 1.6050602409638558e-05,
      "loss": 0.0354,
      "step": 16390
    },
    {
      "epoch": 1.9759036144578315,
      "grad_norm": 0.3755740821361542,
      "learning_rate": 1.604819277108434e-05,
      "loss": 0.0339,
      "step": 16400
    },
    {
      "epoch": 1.9771084337349398,
      "grad_norm": 6.07857084274292,
      "learning_rate": 1.604578313253012e-05,
      "loss": 0.0885,
      "step": 16410
    },
    {
      "epoch": 1.9783132530120482,
      "grad_norm": 1.2190606594085693,
      "learning_rate": 1.6043373493975905e-05,
      "loss": 0.0195,
      "step": 16420
    },
    {
      "epoch": 1.9795180722891565,
      "grad_norm": 0.9740121364593506,
      "learning_rate": 1.6040963855421687e-05,
      "loss": 0.0807,
      "step": 16430
    },
    {
      "epoch": 1.980722891566265,
      "grad_norm": 0.7647107243537903,
      "learning_rate": 1.6038554216867472e-05,
      "loss": 0.0199,
      "step": 16440
    },
    {
      "epoch": 1.9819277108433735,
      "grad_norm": 12.805428504943848,
      "learning_rate": 1.6036144578313257e-05,
      "loss": 0.0978,
      "step": 16450
    },
    {
      "epoch": 1.983132530120482,
      "grad_norm": 90.49214172363281,
      "learning_rate": 1.6033734939759038e-05,
      "loss": 0.0751,
      "step": 16460
    },
    {
      "epoch": 1.9843373493975904,
      "grad_norm": 0.10719934105873108,
      "learning_rate": 1.603132530120482e-05,
      "loss": 0.0491,
      "step": 16470
    },
    {
      "epoch": 1.9855421686746988,
      "grad_norm": 1.675371527671814,
      "learning_rate": 1.6028915662650605e-05,
      "loss": 0.0353,
      "step": 16480
    },
    {
      "epoch": 1.9867469879518072,
      "grad_norm": 0.24843256175518036,
      "learning_rate": 1.6026506024096386e-05,
      "loss": 0.0147,
      "step": 16490
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 10.52074146270752,
      "learning_rate": 1.602409638554217e-05,
      "loss": 0.1141,
      "step": 16500
    },
    {
      "epoch": 1.989156626506024,
      "grad_norm": 0.5906100273132324,
      "learning_rate": 1.6021686746987952e-05,
      "loss": 0.0707,
      "step": 16510
    },
    {
      "epoch": 1.9903614457831327,
      "grad_norm": 0.07207585871219635,
      "learning_rate": 1.6019277108433737e-05,
      "loss": 0.0676,
      "step": 16520
    },
    {
      "epoch": 1.991566265060241,
      "grad_norm": 0.3458329141139984,
      "learning_rate": 1.601686746987952e-05,
      "loss": 0.0512,
      "step": 16530
    },
    {
      "epoch": 1.9927710843373494,
      "grad_norm": 6.1003737449646,
      "learning_rate": 1.6014457831325304e-05,
      "loss": 0.0828,
      "step": 16540
    },
    {
      "epoch": 1.9939759036144578,
      "grad_norm": 0.1501116305589676,
      "learning_rate": 1.6012048192771085e-05,
      "loss": 0.0563,
      "step": 16550
    },
    {
      "epoch": 1.9951807228915661,
      "grad_norm": 6.083964824676514,
      "learning_rate": 1.600963855421687e-05,
      "loss": 0.0402,
      "step": 16560
    },
    {
      "epoch": 1.9963855421686747,
      "grad_norm": 0.30630022287368774,
      "learning_rate": 1.600722891566265e-05,
      "loss": 0.0345,
      "step": 16570
    },
    {
      "epoch": 1.9975903614457833,
      "grad_norm": 1.9726035594940186,
      "learning_rate": 1.6004819277108433e-05,
      "loss": 0.0438,
      "step": 16580
    },
    {
      "epoch": 1.9987951807228916,
      "grad_norm": 0.09456817060709,
      "learning_rate": 1.6002409638554218e-05,
      "loss": 0.1641,
      "step": 16590
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4720734655857086,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0267,
      "step": 16600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9794010123734533,
      "eval_f1": 0.9460040543030898,
      "eval_loss": 0.0676678866147995,
      "eval_precision": 0.940400586223742,
      "eval_recall": 0.9516747002842665,
      "eval_runtime": 3544.7626,
      "eval_samples_per_second": 12.043,
      "eval_steps_per_second": 0.502,
      "step": 16600
    },
    {
      "epoch": 2.0012048192771084,
      "grad_norm": 16.322216033935547,
      "learning_rate": 1.5997590361445784e-05,
      "loss": 0.1461,
      "step": 16610
    },
    {
      "epoch": 2.0024096385542167,
      "grad_norm": 0.11047092825174332,
      "learning_rate": 1.599518072289157e-05,
      "loss": 0.0365,
      "step": 16620
    },
    {
      "epoch": 2.003614457831325,
      "grad_norm": 0.2371962070465088,
      "learning_rate": 1.599277108433735e-05,
      "loss": 0.0418,
      "step": 16630
    },
    {
      "epoch": 2.004819277108434,
      "grad_norm": 5.843567371368408,
      "learning_rate": 1.5990361445783132e-05,
      "loss": 0.0651,
      "step": 16640
    },
    {
      "epoch": 2.0060240963855422,
      "grad_norm": 0.6619075536727905,
      "learning_rate": 1.5987951807228917e-05,
      "loss": 0.0645,
      "step": 16650
    },
    {
      "epoch": 2.0072289156626506,
      "grad_norm": 0.27489763498306274,
      "learning_rate": 1.59855421686747e-05,
      "loss": 0.022,
      "step": 16660
    },
    {
      "epoch": 2.008433734939759,
      "grad_norm": 0.3003963530063629,
      "learning_rate": 1.5983132530120483e-05,
      "loss": 0.036,
      "step": 16670
    },
    {
      "epoch": 2.0096385542168673,
      "grad_norm": 0.05346264690160751,
      "learning_rate": 1.5980722891566268e-05,
      "loss": 0.036,
      "step": 16680
    },
    {
      "epoch": 2.0108433734939757,
      "grad_norm": 8.861183166503906,
      "learning_rate": 1.597831325301205e-05,
      "loss": 0.0343,
      "step": 16690
    },
    {
      "epoch": 2.0120481927710845,
      "grad_norm": 0.44691377878189087,
      "learning_rate": 1.5975903614457834e-05,
      "loss": 0.0175,
      "step": 16700
    },
    {
      "epoch": 2.013253012048193,
      "grad_norm": 0.015499621629714966,
      "learning_rate": 1.5973493975903616e-05,
      "loss": 0.0386,
      "step": 16710
    },
    {
      "epoch": 2.014457831325301,
      "grad_norm": 0.1788794845342636,
      "learning_rate": 1.5971084337349397e-05,
      "loss": 0.0266,
      "step": 16720
    },
    {
      "epoch": 2.0156626506024096,
      "grad_norm": 0.076701320707798,
      "learning_rate": 1.5968674698795182e-05,
      "loss": 0.029,
      "step": 16730
    },
    {
      "epoch": 2.016867469879518,
      "grad_norm": 0.13402165472507477,
      "learning_rate": 1.5966265060240964e-05,
      "loss": 0.0232,
      "step": 16740
    },
    {
      "epoch": 2.0180722891566263,
      "grad_norm": 0.29736337065696716,
      "learning_rate": 1.596385542168675e-05,
      "loss": 0.0272,
      "step": 16750
    },
    {
      "epoch": 2.019277108433735,
      "grad_norm": 0.007899262011051178,
      "learning_rate": 1.5961445783132533e-05,
      "loss": 0.027,
      "step": 16760
    },
    {
      "epoch": 2.0204819277108435,
      "grad_norm": 0.06219865381717682,
      "learning_rate": 1.5959036144578315e-05,
      "loss": 0.0424,
      "step": 16770
    },
    {
      "epoch": 2.021686746987952,
      "grad_norm": 0.04214403033256531,
      "learning_rate": 1.5956626506024096e-05,
      "loss": 0.0426,
      "step": 16780
    },
    {
      "epoch": 2.02289156626506,
      "grad_norm": 0.015105893835425377,
      "learning_rate": 1.595421686746988e-05,
      "loss": 0.0259,
      "step": 16790
    },
    {
      "epoch": 2.0240963855421685,
      "grad_norm": 2.1815996170043945,
      "learning_rate": 1.5951807228915663e-05,
      "loss": 0.0201,
      "step": 16800
    },
    {
      "epoch": 2.025301204819277,
      "grad_norm": 0.15971551835536957,
      "learning_rate": 1.5949397590361448e-05,
      "loss": 0.0106,
      "step": 16810
    },
    {
      "epoch": 2.0265060240963857,
      "grad_norm": 0.0636994019150734,
      "learning_rate": 1.5946987951807233e-05,
      "loss": 0.0352,
      "step": 16820
    },
    {
      "epoch": 2.027710843373494,
      "grad_norm": 0.4087863266468048,
      "learning_rate": 1.5944578313253014e-05,
      "loss": 0.0669,
      "step": 16830
    },
    {
      "epoch": 2.0289156626506024,
      "grad_norm": 0.01465736422687769,
      "learning_rate": 1.5942168674698796e-05,
      "loss": 0.0654,
      "step": 16840
    },
    {
      "epoch": 2.0301204819277108,
      "grad_norm": 1.816697597503662,
      "learning_rate": 1.593975903614458e-05,
      "loss": 0.0427,
      "step": 16850
    },
    {
      "epoch": 2.031325301204819,
      "grad_norm": 0.22247087955474854,
      "learning_rate": 1.5937349397590362e-05,
      "loss": 0.0843,
      "step": 16860
    },
    {
      "epoch": 2.0325301204819275,
      "grad_norm": 0.644568681716919,
      "learning_rate": 1.5934939759036147e-05,
      "loss": 0.0359,
      "step": 16870
    },
    {
      "epoch": 2.0337349397590363,
      "grad_norm": 0.6913138031959534,
      "learning_rate": 1.5932530120481928e-05,
      "loss": 0.0459,
      "step": 16880
    },
    {
      "epoch": 2.0349397590361447,
      "grad_norm": 7.111151218414307,
      "learning_rate": 1.593012048192771e-05,
      "loss": 0.0461,
      "step": 16890
    },
    {
      "epoch": 2.036144578313253,
      "grad_norm": 0.011258671060204506,
      "learning_rate": 1.5927710843373495e-05,
      "loss": 0.0099,
      "step": 16900
    },
    {
      "epoch": 2.0373493975903614,
      "grad_norm": 12.3499174118042,
      "learning_rate": 1.592530120481928e-05,
      "loss": 0.0613,
      "step": 16910
    },
    {
      "epoch": 2.0385542168674697,
      "grad_norm": 1.906049370765686,
      "learning_rate": 1.592289156626506e-05,
      "loss": 0.0384,
      "step": 16920
    },
    {
      "epoch": 2.039759036144578,
      "grad_norm": 0.005304924678057432,
      "learning_rate": 1.5920481927710846e-05,
      "loss": 0.0163,
      "step": 16930
    },
    {
      "epoch": 2.040963855421687,
      "grad_norm": 2.51678466796875,
      "learning_rate": 1.5918072289156627e-05,
      "loss": 0.0943,
      "step": 16940
    },
    {
      "epoch": 2.0421686746987953,
      "grad_norm": 7.573979377746582,
      "learning_rate": 1.591566265060241e-05,
      "loss": 0.036,
      "step": 16950
    },
    {
      "epoch": 2.0433734939759036,
      "grad_norm": 0.011314768344163895,
      "learning_rate": 1.5913253012048194e-05,
      "loss": 0.0629,
      "step": 16960
    },
    {
      "epoch": 2.044578313253012,
      "grad_norm": 0.06453000009059906,
      "learning_rate": 1.591084337349398e-05,
      "loss": 0.0523,
      "step": 16970
    },
    {
      "epoch": 2.0457831325301203,
      "grad_norm": 0.4164089858531952,
      "learning_rate": 1.590843373493976e-05,
      "loss": 0.0039,
      "step": 16980
    },
    {
      "epoch": 2.0469879518072287,
      "grad_norm": 0.018681062385439873,
      "learning_rate": 1.5906024096385545e-05,
      "loss": 0.0299,
      "step": 16990
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 1.9705595970153809,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 0.0675,
      "step": 17000
    },
    {
      "epoch": 2.049397590361446,
      "grad_norm": 18.50404930114746,
      "learning_rate": 1.590120481927711e-05,
      "loss": 0.0795,
      "step": 17010
    },
    {
      "epoch": 2.0506024096385542,
      "grad_norm": 3.351486921310425,
      "learning_rate": 1.5898795180722893e-05,
      "loss": 0.0916,
      "step": 17020
    },
    {
      "epoch": 2.0518072289156626,
      "grad_norm": 0.2594956159591675,
      "learning_rate": 1.5896385542168674e-05,
      "loss": 0.0246,
      "step": 17030
    },
    {
      "epoch": 2.053012048192771,
      "grad_norm": 0.0369114950299263,
      "learning_rate": 1.589397590361446e-05,
      "loss": 0.0345,
      "step": 17040
    },
    {
      "epoch": 2.0542168674698793,
      "grad_norm": 0.16463275253772736,
      "learning_rate": 1.5891566265060244e-05,
      "loss": 0.0699,
      "step": 17050
    },
    {
      "epoch": 2.055421686746988,
      "grad_norm": 8.88198471069336,
      "learning_rate": 1.5889156626506025e-05,
      "loss": 0.0343,
      "step": 17060
    },
    {
      "epoch": 2.0566265060240965,
      "grad_norm": 0.0455787219107151,
      "learning_rate": 1.588674698795181e-05,
      "loss": 0.0738,
      "step": 17070
    },
    {
      "epoch": 2.057831325301205,
      "grad_norm": 0.08092571794986725,
      "learning_rate": 1.5884337349397592e-05,
      "loss": 0.0525,
      "step": 17080
    },
    {
      "epoch": 2.059036144578313,
      "grad_norm": 3.9480316638946533,
      "learning_rate": 1.5881927710843373e-05,
      "loss": 0.0364,
      "step": 17090
    },
    {
      "epoch": 2.0602409638554215,
      "grad_norm": 0.01831710711121559,
      "learning_rate": 1.5879518072289158e-05,
      "loss": 0.0022,
      "step": 17100
    },
    {
      "epoch": 2.06144578313253,
      "grad_norm": 19.05172348022461,
      "learning_rate": 1.587710843373494e-05,
      "loss": 0.0643,
      "step": 17110
    },
    {
      "epoch": 2.0626506024096387,
      "grad_norm": 0.03222181275486946,
      "learning_rate": 1.5874698795180724e-05,
      "loss": 0.0057,
      "step": 17120
    },
    {
      "epoch": 2.063855421686747,
      "grad_norm": 0.15374992787837982,
      "learning_rate": 1.587228915662651e-05,
      "loss": 0.0394,
      "step": 17130
    },
    {
      "epoch": 2.0650602409638554,
      "grad_norm": 0.23089085519313812,
      "learning_rate": 1.586987951807229e-05,
      "loss": 0.0759,
      "step": 17140
    },
    {
      "epoch": 2.066265060240964,
      "grad_norm": 0.45782265067100525,
      "learning_rate": 1.5867469879518072e-05,
      "loss": 0.0466,
      "step": 17150
    },
    {
      "epoch": 2.067469879518072,
      "grad_norm": 5.219851970672607,
      "learning_rate": 1.5865060240963857e-05,
      "loss": 0.0667,
      "step": 17160
    },
    {
      "epoch": 2.0686746987951805,
      "grad_norm": 0.023405833169817924,
      "learning_rate": 1.586265060240964e-05,
      "loss": 0.0018,
      "step": 17170
    },
    {
      "epoch": 2.0698795180722893,
      "grad_norm": 0.04666481912136078,
      "learning_rate": 1.5860240963855423e-05,
      "loss": 0.0514,
      "step": 17180
    },
    {
      "epoch": 2.0710843373493977,
      "grad_norm": 0.6810988783836365,
      "learning_rate": 1.5857831325301205e-05,
      "loss": 0.0261,
      "step": 17190
    },
    {
      "epoch": 2.072289156626506,
      "grad_norm": 0.02915765717625618,
      "learning_rate": 1.585542168674699e-05,
      "loss": 0.0537,
      "step": 17200
    },
    {
      "epoch": 2.0734939759036144,
      "grad_norm": 0.08771577477455139,
      "learning_rate": 1.585301204819277e-05,
      "loss": 0.0596,
      "step": 17210
    },
    {
      "epoch": 2.0746987951807228,
      "grad_norm": 0.02780875191092491,
      "learning_rate": 1.5850602409638556e-05,
      "loss": 0.1036,
      "step": 17220
    },
    {
      "epoch": 2.075903614457831,
      "grad_norm": 1.8713070154190063,
      "learning_rate": 1.5848192771084338e-05,
      "loss": 0.0278,
      "step": 17230
    },
    {
      "epoch": 2.07710843373494,
      "grad_norm": 1.941057562828064,
      "learning_rate": 1.5845783132530123e-05,
      "loss": 0.0908,
      "step": 17240
    },
    {
      "epoch": 2.0783132530120483,
      "grad_norm": 0.2944168150424957,
      "learning_rate": 1.5843373493975904e-05,
      "loss": 0.004,
      "step": 17250
    },
    {
      "epoch": 2.0795180722891566,
      "grad_norm": 2.794487714767456,
      "learning_rate": 1.5840963855421686e-05,
      "loss": 0.0499,
      "step": 17260
    },
    {
      "epoch": 2.080722891566265,
      "grad_norm": 22.507078170776367,
      "learning_rate": 1.5838554216867474e-05,
      "loss": 0.0823,
      "step": 17270
    },
    {
      "epoch": 2.0819277108433734,
      "grad_norm": 24.88763999938965,
      "learning_rate": 1.5836144578313255e-05,
      "loss": 0.0935,
      "step": 17280
    },
    {
      "epoch": 2.0831325301204817,
      "grad_norm": 9.017354965209961,
      "learning_rate": 1.5833734939759037e-05,
      "loss": 0.0629,
      "step": 17290
    },
    {
      "epoch": 2.0843373493975905,
      "grad_norm": 18.39604949951172,
      "learning_rate": 1.583132530120482e-05,
      "loss": 0.0481,
      "step": 17300
    },
    {
      "epoch": 2.085542168674699,
      "grad_norm": 12.445364952087402,
      "learning_rate": 1.5828915662650603e-05,
      "loss": 0.0615,
      "step": 17310
    },
    {
      "epoch": 2.0867469879518072,
      "grad_norm": 0.0755334198474884,
      "learning_rate": 1.5826506024096388e-05,
      "loss": 0.0279,
      "step": 17320
    },
    {
      "epoch": 2.0879518072289156,
      "grad_norm": 0.02742774412035942,
      "learning_rate": 1.582409638554217e-05,
      "loss": 0.0304,
      "step": 17330
    },
    {
      "epoch": 2.089156626506024,
      "grad_norm": 0.03759229555726051,
      "learning_rate": 1.582168674698795e-05,
      "loss": 0.0814,
      "step": 17340
    },
    {
      "epoch": 2.0903614457831323,
      "grad_norm": 0.0756964161992073,
      "learning_rate": 1.5819277108433736e-05,
      "loss": 0.0188,
      "step": 17350
    },
    {
      "epoch": 2.091566265060241,
      "grad_norm": 0.875156819820404,
      "learning_rate": 1.581686746987952e-05,
      "loss": 0.0327,
      "step": 17360
    },
    {
      "epoch": 2.0927710843373495,
      "grad_norm": 3.032289505004883,
      "learning_rate": 1.5814457831325302e-05,
      "loss": 0.0234,
      "step": 17370
    },
    {
      "epoch": 2.093975903614458,
      "grad_norm": 0.04592854529619217,
      "learning_rate": 1.5812048192771087e-05,
      "loss": 0.0281,
      "step": 17380
    },
    {
      "epoch": 2.095180722891566,
      "grad_norm": 0.4402883052825928,
      "learning_rate": 1.580963855421687e-05,
      "loss": 0.0824,
      "step": 17390
    },
    {
      "epoch": 2.0963855421686746,
      "grad_norm": 0.06483746320009232,
      "learning_rate": 1.580722891566265e-05,
      "loss": 0.0851,
      "step": 17400
    },
    {
      "epoch": 2.097590361445783,
      "grad_norm": 0.5068902373313904,
      "learning_rate": 1.5804819277108435e-05,
      "loss": 0.0197,
      "step": 17410
    },
    {
      "epoch": 2.0987951807228917,
      "grad_norm": 0.020125722512602806,
      "learning_rate": 1.580240963855422e-05,
      "loss": 0.032,
      "step": 17420
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.049418602138757706,
      "learning_rate": 1.58e-05,
      "loss": 0.0321,
      "step": 17430
    },
    {
      "epoch": 2.1012048192771084,
      "grad_norm": 0.41654786467552185,
      "learning_rate": 1.5797590361445786e-05,
      "loss": 0.042,
      "step": 17440
    },
    {
      "epoch": 2.102409638554217,
      "grad_norm": 0.013010974042117596,
      "learning_rate": 1.5795180722891568e-05,
      "loss": 0.0326,
      "step": 17450
    },
    {
      "epoch": 2.103614457831325,
      "grad_norm": 0.006607506889849901,
      "learning_rate": 1.579277108433735e-05,
      "loss": 0.0392,
      "step": 17460
    },
    {
      "epoch": 2.1048192771084335,
      "grad_norm": 0.2419569194316864,
      "learning_rate": 1.5790361445783134e-05,
      "loss": 0.0063,
      "step": 17470
    },
    {
      "epoch": 2.1060240963855423,
      "grad_norm": 9.695046424865723,
      "learning_rate": 1.5787951807228915e-05,
      "loss": 0.0335,
      "step": 17480
    },
    {
      "epoch": 2.1072289156626507,
      "grad_norm": 0.15859170258045197,
      "learning_rate": 1.57855421686747e-05,
      "loss": 0.0071,
      "step": 17490
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 1.5966484546661377,
      "learning_rate": 1.5783132530120485e-05,
      "loss": 0.1001,
      "step": 17500
    },
    {
      "epoch": 2.1096385542168674,
      "grad_norm": 0.1642560362815857,
      "learning_rate": 1.5780722891566267e-05,
      "loss": 0.0339,
      "step": 17510
    },
    {
      "epoch": 2.1108433734939758,
      "grad_norm": 1.944714903831482,
      "learning_rate": 1.5778313253012048e-05,
      "loss": 0.0162,
      "step": 17520
    },
    {
      "epoch": 2.112048192771084,
      "grad_norm": 19.642824172973633,
      "learning_rate": 1.5775903614457833e-05,
      "loss": 0.03,
      "step": 17530
    },
    {
      "epoch": 2.113253012048193,
      "grad_norm": 9.672100067138672,
      "learning_rate": 1.5773493975903614e-05,
      "loss": 0.141,
      "step": 17540
    },
    {
      "epoch": 2.1144578313253013,
      "grad_norm": 0.1196698397397995,
      "learning_rate": 1.57710843373494e-05,
      "loss": 0.0623,
      "step": 17550
    },
    {
      "epoch": 2.1156626506024097,
      "grad_norm": 10.887983322143555,
      "learning_rate": 1.576867469879518e-05,
      "loss": 0.0565,
      "step": 17560
    },
    {
      "epoch": 2.116867469879518,
      "grad_norm": 0.10909458994865417,
      "learning_rate": 1.5766265060240966e-05,
      "loss": 0.0602,
      "step": 17570
    },
    {
      "epoch": 2.1180722891566264,
      "grad_norm": 6.787346363067627,
      "learning_rate": 1.576385542168675e-05,
      "loss": 0.0351,
      "step": 17580
    },
    {
      "epoch": 2.1192771084337347,
      "grad_norm": 1.6248345375061035,
      "learning_rate": 1.5761445783132532e-05,
      "loss": 0.0406,
      "step": 17590
    },
    {
      "epoch": 2.1204819277108435,
      "grad_norm": 0.06182296201586723,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 0.0304,
      "step": 17600
    },
    {
      "epoch": 2.121686746987952,
      "grad_norm": 68.28369903564453,
      "learning_rate": 1.57566265060241e-05,
      "loss": 0.0337,
      "step": 17610
    },
    {
      "epoch": 2.1228915662650603,
      "grad_norm": 0.019463445991277695,
      "learning_rate": 1.575421686746988e-05,
      "loss": 0.0738,
      "step": 17620
    },
    {
      "epoch": 2.1240963855421686,
      "grad_norm": 4.88891077041626,
      "learning_rate": 1.5751807228915665e-05,
      "loss": 0.088,
      "step": 17630
    },
    {
      "epoch": 2.125301204819277,
      "grad_norm": 0.09601902961730957,
      "learning_rate": 1.5749397590361446e-05,
      "loss": 0.0045,
      "step": 17640
    },
    {
      "epoch": 2.1265060240963853,
      "grad_norm": 0.15523502230644226,
      "learning_rate": 1.574698795180723e-05,
      "loss": 0.0074,
      "step": 17650
    },
    {
      "epoch": 2.127710843373494,
      "grad_norm": 1.0425580739974976,
      "learning_rate": 1.5744578313253013e-05,
      "loss": 0.0474,
      "step": 17660
    },
    {
      "epoch": 2.1289156626506025,
      "grad_norm": 0.06257950514554977,
      "learning_rate": 1.5742168674698797e-05,
      "loss": 0.01,
      "step": 17670
    },
    {
      "epoch": 2.130120481927711,
      "grad_norm": 0.32421383261680603,
      "learning_rate": 1.573975903614458e-05,
      "loss": 0.0456,
      "step": 17680
    },
    {
      "epoch": 2.1313253012048192,
      "grad_norm": 1.3288778066635132,
      "learning_rate": 1.5737349397590364e-05,
      "loss": 0.1197,
      "step": 17690
    },
    {
      "epoch": 2.1325301204819276,
      "grad_norm": 4.8800201416015625,
      "learning_rate": 1.5734939759036145e-05,
      "loss": 0.0897,
      "step": 17700
    },
    {
      "epoch": 2.133734939759036,
      "grad_norm": 0.03629690036177635,
      "learning_rate": 1.5732530120481927e-05,
      "loss": 0.001,
      "step": 17710
    },
    {
      "epoch": 2.1349397590361447,
      "grad_norm": 0.207060769200325,
      "learning_rate": 1.573012048192771e-05,
      "loss": 0.047,
      "step": 17720
    },
    {
      "epoch": 2.136144578313253,
      "grad_norm": 5.23060417175293,
      "learning_rate": 1.5727710843373496e-05,
      "loss": 0.0294,
      "step": 17730
    },
    {
      "epoch": 2.1373493975903615,
      "grad_norm": 2.0067496299743652,
      "learning_rate": 1.5725301204819278e-05,
      "loss": 0.0557,
      "step": 17740
    },
    {
      "epoch": 2.13855421686747,
      "grad_norm": 0.6718122959136963,
      "learning_rate": 1.5722891566265063e-05,
      "loss": 0.046,
      "step": 17750
    },
    {
      "epoch": 2.139759036144578,
      "grad_norm": 49.93018341064453,
      "learning_rate": 1.5720481927710844e-05,
      "loss": 0.0641,
      "step": 17760
    },
    {
      "epoch": 2.1409638554216865,
      "grad_norm": 0.027212049812078476,
      "learning_rate": 1.5718072289156626e-05,
      "loss": 0.0244,
      "step": 17770
    },
    {
      "epoch": 2.1421686746987953,
      "grad_norm": 0.03426140546798706,
      "learning_rate": 1.571566265060241e-05,
      "loss": 0.0416,
      "step": 17780
    },
    {
      "epoch": 2.1433734939759037,
      "grad_norm": 0.010537227615714073,
      "learning_rate": 1.5713253012048192e-05,
      "loss": 0.0444,
      "step": 17790
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 0.644603431224823,
      "learning_rate": 1.5710843373493977e-05,
      "loss": 0.0613,
      "step": 17800
    },
    {
      "epoch": 2.1457831325301204,
      "grad_norm": 0.3051297962665558,
      "learning_rate": 1.5708433734939762e-05,
      "loss": 0.0264,
      "step": 17810
    },
    {
      "epoch": 2.146987951807229,
      "grad_norm": 3.842799186706543,
      "learning_rate": 1.5706024096385543e-05,
      "loss": 0.0382,
      "step": 17820
    },
    {
      "epoch": 2.148192771084337,
      "grad_norm": 2.6193583011627197,
      "learning_rate": 1.5703614457831328e-05,
      "loss": 0.0353,
      "step": 17830
    },
    {
      "epoch": 2.149397590361446,
      "grad_norm": 0.057366710156202316,
      "learning_rate": 1.570120481927711e-05,
      "loss": 0.051,
      "step": 17840
    },
    {
      "epoch": 2.1506024096385543,
      "grad_norm": 11.198958396911621,
      "learning_rate": 1.569879518072289e-05,
      "loss": 0.0298,
      "step": 17850
    },
    {
      "epoch": 2.1518072289156627,
      "grad_norm": 0.4917672872543335,
      "learning_rate": 1.5696385542168676e-05,
      "loss": 0.0335,
      "step": 17860
    },
    {
      "epoch": 2.153012048192771,
      "grad_norm": 0.1617424190044403,
      "learning_rate": 1.569397590361446e-05,
      "loss": 0.0051,
      "step": 17870
    },
    {
      "epoch": 2.1542168674698794,
      "grad_norm": 0.1689557433128357,
      "learning_rate": 1.5691566265060242e-05,
      "loss": 0.0245,
      "step": 17880
    },
    {
      "epoch": 2.1554216867469878,
      "grad_norm": 0.04547901451587677,
      "learning_rate": 1.5689156626506027e-05,
      "loss": 0.0477,
      "step": 17890
    },
    {
      "epoch": 2.1566265060240966,
      "grad_norm": 12.105725288391113,
      "learning_rate": 1.568674698795181e-05,
      "loss": 0.0629,
      "step": 17900
    },
    {
      "epoch": 2.157831325301205,
      "grad_norm": 0.21324002742767334,
      "learning_rate": 1.568433734939759e-05,
      "loss": 0.0337,
      "step": 17910
    },
    {
      "epoch": 2.1590361445783133,
      "grad_norm": 0.05275958403944969,
      "learning_rate": 1.5681927710843375e-05,
      "loss": 0.025,
      "step": 17920
    },
    {
      "epoch": 2.1602409638554216,
      "grad_norm": 0.9642434120178223,
      "learning_rate": 1.5679518072289157e-05,
      "loss": 0.0189,
      "step": 17930
    },
    {
      "epoch": 2.16144578313253,
      "grad_norm": 4.21919059753418,
      "learning_rate": 1.567710843373494e-05,
      "loss": 0.0883,
      "step": 17940
    },
    {
      "epoch": 2.1626506024096384,
      "grad_norm": 0.01924554444849491,
      "learning_rate": 1.5674698795180726e-05,
      "loss": 0.0553,
      "step": 17950
    },
    {
      "epoch": 2.163855421686747,
      "grad_norm": 0.12011626362800598,
      "learning_rate": 1.5672289156626508e-05,
      "loss": 0.0877,
      "step": 17960
    },
    {
      "epoch": 2.1650602409638555,
      "grad_norm": 5.096433162689209,
      "learning_rate": 1.566987951807229e-05,
      "loss": 0.0342,
      "step": 17970
    },
    {
      "epoch": 2.166265060240964,
      "grad_norm": 1.8492850065231323,
      "learning_rate": 1.5667469879518074e-05,
      "loss": 0.02,
      "step": 17980
    },
    {
      "epoch": 2.1674698795180722,
      "grad_norm": 4.559432029724121,
      "learning_rate": 1.5665060240963856e-05,
      "loss": 0.0908,
      "step": 17990
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.0391155406832695,
      "learning_rate": 1.566265060240964e-05,
      "loss": 0.0472,
      "step": 18000
    },
    {
      "epoch": 2.169879518072289,
      "grad_norm": 10.67910099029541,
      "learning_rate": 1.5660240963855422e-05,
      "loss": 0.0753,
      "step": 18010
    },
    {
      "epoch": 2.1710843373493978,
      "grad_norm": 0.7174159288406372,
      "learning_rate": 1.5657831325301207e-05,
      "loss": 0.089,
      "step": 18020
    },
    {
      "epoch": 2.172289156626506,
      "grad_norm": 0.1954207867383957,
      "learning_rate": 1.565542168674699e-05,
      "loss": 0.056,
      "step": 18030
    },
    {
      "epoch": 2.1734939759036145,
      "grad_norm": 0.08886163681745529,
      "learning_rate": 1.5653012048192773e-05,
      "loss": 0.0054,
      "step": 18040
    },
    {
      "epoch": 2.174698795180723,
      "grad_norm": 5.551998615264893,
      "learning_rate": 1.5650602409638555e-05,
      "loss": 0.0387,
      "step": 18050
    },
    {
      "epoch": 2.175903614457831,
      "grad_norm": 0.05847359076142311,
      "learning_rate": 1.564819277108434e-05,
      "loss": 0.0101,
      "step": 18060
    },
    {
      "epoch": 2.1771084337349396,
      "grad_norm": 11.3493070602417,
      "learning_rate": 1.564578313253012e-05,
      "loss": 0.0759,
      "step": 18070
    },
    {
      "epoch": 2.1783132530120484,
      "grad_norm": 0.05813904479146004,
      "learning_rate": 1.5643373493975903e-05,
      "loss": 0.0558,
      "step": 18080
    },
    {
      "epoch": 2.1795180722891567,
      "grad_norm": 0.03516077250242233,
      "learning_rate": 1.5640963855421687e-05,
      "loss": 0.0301,
      "step": 18090
    },
    {
      "epoch": 2.180722891566265,
      "grad_norm": 0.292906254529953,
      "learning_rate": 1.5638554216867472e-05,
      "loss": 0.0652,
      "step": 18100
    },
    {
      "epoch": 2.1819277108433734,
      "grad_norm": 0.030774138867855072,
      "learning_rate": 1.5636144578313254e-05,
      "loss": 0.0372,
      "step": 18110
    },
    {
      "epoch": 2.183132530120482,
      "grad_norm": 0.07019796222448349,
      "learning_rate": 1.563373493975904e-05,
      "loss": 0.0256,
      "step": 18120
    },
    {
      "epoch": 2.18433734939759,
      "grad_norm": 0.3933214247226715,
      "learning_rate": 1.563132530120482e-05,
      "loss": 0.0868,
      "step": 18130
    },
    {
      "epoch": 2.185542168674699,
      "grad_norm": 2.510333776473999,
      "learning_rate": 1.5628915662650605e-05,
      "loss": 0.0261,
      "step": 18140
    },
    {
      "epoch": 2.1867469879518073,
      "grad_norm": 0.9026312232017517,
      "learning_rate": 1.5626506024096386e-05,
      "loss": 0.076,
      "step": 18150
    },
    {
      "epoch": 2.1879518072289157,
      "grad_norm": 0.09763818234205246,
      "learning_rate": 1.5624096385542168e-05,
      "loss": 0.0278,
      "step": 18160
    },
    {
      "epoch": 2.189156626506024,
      "grad_norm": 4.997682571411133,
      "learning_rate": 1.5621686746987953e-05,
      "loss": 0.049,
      "step": 18170
    },
    {
      "epoch": 2.1903614457831324,
      "grad_norm": 0.026904774829745293,
      "learning_rate": 1.5619277108433738e-05,
      "loss": 0.0415,
      "step": 18180
    },
    {
      "epoch": 2.1915662650602408,
      "grad_norm": 0.01652848720550537,
      "learning_rate": 1.561686746987952e-05,
      "loss": 0.0239,
      "step": 18190
    },
    {
      "epoch": 2.1927710843373496,
      "grad_norm": 0.038011595606803894,
      "learning_rate": 1.5614457831325304e-05,
      "loss": 0.0528,
      "step": 18200
    },
    {
      "epoch": 2.193975903614458,
      "grad_norm": 2.399338722229004,
      "learning_rate": 1.5612048192771086e-05,
      "loss": 0.0792,
      "step": 18210
    },
    {
      "epoch": 2.1951807228915663,
      "grad_norm": 43.12931442260742,
      "learning_rate": 1.5609638554216867e-05,
      "loss": 0.0534,
      "step": 18220
    },
    {
      "epoch": 2.1963855421686747,
      "grad_norm": 0.03056955710053444,
      "learning_rate": 1.5607228915662652e-05,
      "loss": 0.0319,
      "step": 18230
    },
    {
      "epoch": 2.197590361445783,
      "grad_norm": 0.05938466638326645,
      "learning_rate": 1.5604819277108433e-05,
      "loss": 0.0466,
      "step": 18240
    },
    {
      "epoch": 2.1987951807228914,
      "grad_norm": 0.060646653175354004,
      "learning_rate": 1.5602409638554218e-05,
      "loss": 0.062,
      "step": 18250
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.03533902019262314,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.056,
      "step": 18260
    },
    {
      "epoch": 2.2012048192771085,
      "grad_norm": 0.0273631289601326,
      "learning_rate": 1.5597590361445785e-05,
      "loss": 0.0291,
      "step": 18270
    },
    {
      "epoch": 2.202409638554217,
      "grad_norm": 0.012480535544455051,
      "learning_rate": 1.5595180722891566e-05,
      "loss": 0.0557,
      "step": 18280
    },
    {
      "epoch": 2.2036144578313253,
      "grad_norm": 14.56928539276123,
      "learning_rate": 1.559277108433735e-05,
      "loss": 0.0166,
      "step": 18290
    },
    {
      "epoch": 2.2048192771084336,
      "grad_norm": 0.049365751445293427,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 0.067,
      "step": 18300
    },
    {
      "epoch": 2.206024096385542,
      "grad_norm": 37.34370040893555,
      "learning_rate": 1.5587951807228917e-05,
      "loss": 0.0295,
      "step": 18310
    },
    {
      "epoch": 2.207228915662651,
      "grad_norm": 3.2209997177124023,
      "learning_rate": 1.5585542168674702e-05,
      "loss": 0.0753,
      "step": 18320
    },
    {
      "epoch": 2.208433734939759,
      "grad_norm": 2.2966315746307373,
      "learning_rate": 1.5583132530120484e-05,
      "loss": 0.0356,
      "step": 18330
    },
    {
      "epoch": 2.2096385542168675,
      "grad_norm": 6.480925559997559,
      "learning_rate": 1.5580722891566265e-05,
      "loss": 0.0771,
      "step": 18340
    },
    {
      "epoch": 2.210843373493976,
      "grad_norm": 0.06792597472667694,
      "learning_rate": 1.557831325301205e-05,
      "loss": 0.0433,
      "step": 18350
    },
    {
      "epoch": 2.212048192771084,
      "grad_norm": 0.23665153980255127,
      "learning_rate": 1.557590361445783e-05,
      "loss": 0.0718,
      "step": 18360
    },
    {
      "epoch": 2.2132530120481926,
      "grad_norm": 0.09656774997711182,
      "learning_rate": 1.5573493975903616e-05,
      "loss": 0.0914,
      "step": 18370
    },
    {
      "epoch": 2.2144578313253014,
      "grad_norm": 0.22380080819129944,
      "learning_rate": 1.5571084337349398e-05,
      "loss": 0.0654,
      "step": 18380
    },
    {
      "epoch": 2.2156626506024097,
      "grad_norm": 0.383124977350235,
      "learning_rate": 1.556867469879518e-05,
      "loss": 0.0053,
      "step": 18390
    },
    {
      "epoch": 2.216867469879518,
      "grad_norm": 1.847133755683899,
      "learning_rate": 1.5566265060240968e-05,
      "loss": 0.0361,
      "step": 18400
    },
    {
      "epoch": 2.2180722891566265,
      "grad_norm": 4.339328289031982,
      "learning_rate": 1.556385542168675e-05,
      "loss": 0.0479,
      "step": 18410
    },
    {
      "epoch": 2.219277108433735,
      "grad_norm": 0.5349238514900208,
      "learning_rate": 1.556144578313253e-05,
      "loss": 0.0977,
      "step": 18420
    },
    {
      "epoch": 2.220481927710843,
      "grad_norm": 0.22364109754562378,
      "learning_rate": 1.5559036144578315e-05,
      "loss": 0.0867,
      "step": 18430
    },
    {
      "epoch": 2.221686746987952,
      "grad_norm": 5.848369121551514,
      "learning_rate": 1.5556626506024097e-05,
      "loss": 0.088,
      "step": 18440
    },
    {
      "epoch": 2.2228915662650603,
      "grad_norm": 1.3688044548034668,
      "learning_rate": 1.5554216867469882e-05,
      "loss": 0.0121,
      "step": 18450
    },
    {
      "epoch": 2.2240963855421687,
      "grad_norm": 0.09909098595380783,
      "learning_rate": 1.5551807228915663e-05,
      "loss": 0.061,
      "step": 18460
    },
    {
      "epoch": 2.225301204819277,
      "grad_norm": 0.4176724851131439,
      "learning_rate": 1.5549397590361448e-05,
      "loss": 0.0573,
      "step": 18470
    },
    {
      "epoch": 2.2265060240963854,
      "grad_norm": 0.022582409903407097,
      "learning_rate": 1.554698795180723e-05,
      "loss": 0.0315,
      "step": 18480
    },
    {
      "epoch": 2.227710843373494,
      "grad_norm": 0.014749542810022831,
      "learning_rate": 1.5544578313253014e-05,
      "loss": 0.0672,
      "step": 18490
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 0.03498752415180206,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 0.0778,
      "step": 18500
    },
    {
      "epoch": 2.230120481927711,
      "grad_norm": 0.08216886967420578,
      "learning_rate": 1.553975903614458e-05,
      "loss": 0.0167,
      "step": 18510
    },
    {
      "epoch": 2.2313253012048193,
      "grad_norm": 2.8511557579040527,
      "learning_rate": 1.5537349397590362e-05,
      "loss": 0.0157,
      "step": 18520
    },
    {
      "epoch": 2.2325301204819277,
      "grad_norm": 0.0946880355477333,
      "learning_rate": 1.5534939759036144e-05,
      "loss": 0.0058,
      "step": 18530
    },
    {
      "epoch": 2.233734939759036,
      "grad_norm": 7.048194408416748,
      "learning_rate": 1.553253012048193e-05,
      "loss": 0.0512,
      "step": 18540
    },
    {
      "epoch": 2.2349397590361444,
      "grad_norm": 0.0689951553940773,
      "learning_rate": 1.5530120481927714e-05,
      "loss": 0.1008,
      "step": 18550
    },
    {
      "epoch": 2.236144578313253,
      "grad_norm": 0.32286760210990906,
      "learning_rate": 1.5527710843373495e-05,
      "loss": 0.002,
      "step": 18560
    },
    {
      "epoch": 2.2373493975903616,
      "grad_norm": 0.01544336136430502,
      "learning_rate": 1.552530120481928e-05,
      "loss": 0.0835,
      "step": 18570
    },
    {
      "epoch": 2.23855421686747,
      "grad_norm": 6.611727237701416,
      "learning_rate": 1.552289156626506e-05,
      "loss": 0.0609,
      "step": 18580
    },
    {
      "epoch": 2.2397590361445783,
      "grad_norm": 3.189826488494873,
      "learning_rate": 1.5520481927710843e-05,
      "loss": 0.0535,
      "step": 18590
    },
    {
      "epoch": 2.2409638554216866,
      "grad_norm": 0.2548753619194031,
      "learning_rate": 1.5518072289156628e-05,
      "loss": 0.0912,
      "step": 18600
    },
    {
      "epoch": 2.242168674698795,
      "grad_norm": 0.23917874693870544,
      "learning_rate": 1.551566265060241e-05,
      "loss": 0.0184,
      "step": 18610
    },
    {
      "epoch": 2.243373493975904,
      "grad_norm": 0.024154474958777428,
      "learning_rate": 1.5513253012048194e-05,
      "loss": 0.0241,
      "step": 18620
    },
    {
      "epoch": 2.244578313253012,
      "grad_norm": 1.6062995195388794,
      "learning_rate": 1.551084337349398e-05,
      "loss": 0.081,
      "step": 18630
    },
    {
      "epoch": 2.2457831325301205,
      "grad_norm": 2.9453439712524414,
      "learning_rate": 1.550843373493976e-05,
      "loss": 0.0823,
      "step": 18640
    },
    {
      "epoch": 2.246987951807229,
      "grad_norm": 0.013869905844330788,
      "learning_rate": 1.5506024096385542e-05,
      "loss": 0.0204,
      "step": 18650
    },
    {
      "epoch": 2.2481927710843372,
      "grad_norm": 0.1019010916352272,
      "learning_rate": 1.5503614457831327e-05,
      "loss": 0.0384,
      "step": 18660
    },
    {
      "epoch": 2.2493975903614456,
      "grad_norm": 5.660611629486084,
      "learning_rate": 1.5501204819277108e-05,
      "loss": 0.0538,
      "step": 18670
    },
    {
      "epoch": 2.2506024096385544,
      "grad_norm": 0.027742207050323486,
      "learning_rate": 1.5498795180722893e-05,
      "loss": 0.0719,
      "step": 18680
    },
    {
      "epoch": 2.2518072289156628,
      "grad_norm": 0.5568872094154358,
      "learning_rate": 1.5496385542168678e-05,
      "loss": 0.0382,
      "step": 18690
    },
    {
      "epoch": 2.253012048192771,
      "grad_norm": 1.3697847127914429,
      "learning_rate": 1.549397590361446e-05,
      "loss": 0.0093,
      "step": 18700
    },
    {
      "epoch": 2.2542168674698795,
      "grad_norm": 0.5285983681678772,
      "learning_rate": 1.5491566265060244e-05,
      "loss": 0.0258,
      "step": 18710
    },
    {
      "epoch": 2.255421686746988,
      "grad_norm": 1.3494548797607422,
      "learning_rate": 1.5489156626506026e-05,
      "loss": 0.0268,
      "step": 18720
    },
    {
      "epoch": 2.256626506024096,
      "grad_norm": 20.475696563720703,
      "learning_rate": 1.5486746987951807e-05,
      "loss": 0.0776,
      "step": 18730
    },
    {
      "epoch": 2.257831325301205,
      "grad_norm": 0.07208244502544403,
      "learning_rate": 1.5484337349397592e-05,
      "loss": 0.067,
      "step": 18740
    },
    {
      "epoch": 2.2590361445783134,
      "grad_norm": 0.24544790387153625,
      "learning_rate": 1.5481927710843374e-05,
      "loss": 0.0354,
      "step": 18750
    },
    {
      "epoch": 2.2602409638554217,
      "grad_norm": 2.8443996906280518,
      "learning_rate": 1.547951807228916e-05,
      "loss": 0.0604,
      "step": 18760
    },
    {
      "epoch": 2.26144578313253,
      "grad_norm": 0.11382787674665451,
      "learning_rate": 1.5477108433734943e-05,
      "loss": 0.0741,
      "step": 18770
    },
    {
      "epoch": 2.2626506024096384,
      "grad_norm": 0.5975822806358337,
      "learning_rate": 1.5474698795180725e-05,
      "loss": 0.0353,
      "step": 18780
    },
    {
      "epoch": 2.263855421686747,
      "grad_norm": 17.457977294921875,
      "learning_rate": 1.5472289156626506e-05,
      "loss": 0.0221,
      "step": 18790
    },
    {
      "epoch": 2.2650602409638556,
      "grad_norm": 0.0704881027340889,
      "learning_rate": 1.546987951807229e-05,
      "loss": 0.0451,
      "step": 18800
    },
    {
      "epoch": 2.266265060240964,
      "grad_norm": 0.0574599951505661,
      "learning_rate": 1.5467469879518073e-05,
      "loss": 0.0307,
      "step": 18810
    },
    {
      "epoch": 2.2674698795180723,
      "grad_norm": 2.207260847091675,
      "learning_rate": 1.5465060240963858e-05,
      "loss": 0.0811,
      "step": 18820
    },
    {
      "epoch": 2.2686746987951807,
      "grad_norm": 21.95671272277832,
      "learning_rate": 1.546265060240964e-05,
      "loss": 0.0766,
      "step": 18830
    },
    {
      "epoch": 2.269879518072289,
      "grad_norm": 3.376953363418579,
      "learning_rate": 1.5460240963855424e-05,
      "loss": 0.0215,
      "step": 18840
    },
    {
      "epoch": 2.2710843373493974,
      "grad_norm": 0.5046723484992981,
      "learning_rate": 1.5457831325301205e-05,
      "loss": 0.0189,
      "step": 18850
    },
    {
      "epoch": 2.272289156626506,
      "grad_norm": 0.36477407813072205,
      "learning_rate": 1.545542168674699e-05,
      "loss": 0.0635,
      "step": 18860
    },
    {
      "epoch": 2.2734939759036146,
      "grad_norm": 2.7427592277526855,
      "learning_rate": 1.5453012048192772e-05,
      "loss": 0.056,
      "step": 18870
    },
    {
      "epoch": 2.274698795180723,
      "grad_norm": 0.06419041752815247,
      "learning_rate": 1.5450602409638557e-05,
      "loss": 0.0243,
      "step": 18880
    },
    {
      "epoch": 2.2759036144578313,
      "grad_norm": 0.13384859263896942,
      "learning_rate": 1.5448192771084338e-05,
      "loss": 0.0473,
      "step": 18890
    },
    {
      "epoch": 2.2771084337349397,
      "grad_norm": 0.0638674944639206,
      "learning_rate": 1.544578313253012e-05,
      "loss": 0.0302,
      "step": 18900
    },
    {
      "epoch": 2.278313253012048,
      "grad_norm": 0.34413138031959534,
      "learning_rate": 1.5443373493975904e-05,
      "loss": 0.0595,
      "step": 18910
    },
    {
      "epoch": 2.279518072289157,
      "grad_norm": 1.654144287109375,
      "learning_rate": 1.544096385542169e-05,
      "loss": 0.0337,
      "step": 18920
    },
    {
      "epoch": 2.280722891566265,
      "grad_norm": 4.64686918258667,
      "learning_rate": 1.543855421686747e-05,
      "loss": 0.0396,
      "step": 18930
    },
    {
      "epoch": 2.2819277108433735,
      "grad_norm": 0.08026634156703949,
      "learning_rate": 1.5436144578313256e-05,
      "loss": 0.07,
      "step": 18940
    },
    {
      "epoch": 2.283132530120482,
      "grad_norm": 0.06761256605386734,
      "learning_rate": 1.5433734939759037e-05,
      "loss": 0.0449,
      "step": 18950
    },
    {
      "epoch": 2.2843373493975903,
      "grad_norm": 0.0924745500087738,
      "learning_rate": 1.543132530120482e-05,
      "loss": 0.0299,
      "step": 18960
    },
    {
      "epoch": 2.2855421686746986,
      "grad_norm": 0.0704922080039978,
      "learning_rate": 1.5428915662650604e-05,
      "loss": 0.0971,
      "step": 18970
    },
    {
      "epoch": 2.2867469879518074,
      "grad_norm": 0.5328838229179382,
      "learning_rate": 1.5426506024096385e-05,
      "loss": 0.0268,
      "step": 18980
    },
    {
      "epoch": 2.287951807228916,
      "grad_norm": 16.642475128173828,
      "learning_rate": 1.542409638554217e-05,
      "loss": 0.0224,
      "step": 18990
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 0.3008752167224884,
      "learning_rate": 1.5421686746987955e-05,
      "loss": 0.0355,
      "step": 19000
    },
    {
      "epoch": 2.2903614457831325,
      "grad_norm": 1.232703685760498,
      "learning_rate": 1.5419277108433736e-05,
      "loss": 0.0307,
      "step": 19010
    },
    {
      "epoch": 2.291566265060241,
      "grad_norm": 0.012504749931395054,
      "learning_rate": 1.541686746987952e-05,
      "loss": 0.0383,
      "step": 19020
    },
    {
      "epoch": 2.292771084337349,
      "grad_norm": 0.0545828603208065,
      "learning_rate": 1.5414457831325303e-05,
      "loss": 0.0309,
      "step": 19030
    },
    {
      "epoch": 2.293975903614458,
      "grad_norm": 1.3243464231491089,
      "learning_rate": 1.5412048192771084e-05,
      "loss": 0.0488,
      "step": 19040
    },
    {
      "epoch": 2.2951807228915664,
      "grad_norm": 7.03938102722168,
      "learning_rate": 1.540963855421687e-05,
      "loss": 0.0456,
      "step": 19050
    },
    {
      "epoch": 2.2963855421686747,
      "grad_norm": 3.6834170818328857,
      "learning_rate": 1.540722891566265e-05,
      "loss": 0.0501,
      "step": 19060
    },
    {
      "epoch": 2.297590361445783,
      "grad_norm": 0.07426626235246658,
      "learning_rate": 1.5404819277108435e-05,
      "loss": 0.0898,
      "step": 19070
    },
    {
      "epoch": 2.2987951807228915,
      "grad_norm": 14.015830039978027,
      "learning_rate": 1.540240963855422e-05,
      "loss": 0.1035,
      "step": 19080
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.727219581604004,
      "learning_rate": 1.54e-05,
      "loss": 0.0349,
      "step": 19090
    },
    {
      "epoch": 2.3012048192771086,
      "grad_norm": 0.5635730028152466,
      "learning_rate": 1.5397590361445783e-05,
      "loss": 0.0309,
      "step": 19100
    },
    {
      "epoch": 2.302409638554217,
      "grad_norm": 1.5944708585739136,
      "learning_rate": 1.5395180722891568e-05,
      "loss": 0.0167,
      "step": 19110
    },
    {
      "epoch": 2.3036144578313253,
      "grad_norm": 0.23302266001701355,
      "learning_rate": 1.539277108433735e-05,
      "loss": 0.01,
      "step": 19120
    },
    {
      "epoch": 2.3048192771084337,
      "grad_norm": 0.20816905796527863,
      "learning_rate": 1.5390361445783134e-05,
      "loss": 0.0649,
      "step": 19130
    },
    {
      "epoch": 2.306024096385542,
      "grad_norm": 0.09680935740470886,
      "learning_rate": 1.538795180722892e-05,
      "loss": 0.0279,
      "step": 19140
    },
    {
      "epoch": 2.3072289156626504,
      "grad_norm": 0.03167988732457161,
      "learning_rate": 1.53855421686747e-05,
      "loss": 0.0657,
      "step": 19150
    },
    {
      "epoch": 2.3084337349397592,
      "grad_norm": 0.1274867057800293,
      "learning_rate": 1.5383132530120482e-05,
      "loss": 0.1672,
      "step": 19160
    },
    {
      "epoch": 2.3096385542168676,
      "grad_norm": 0.05143487825989723,
      "learning_rate": 1.5380722891566267e-05,
      "loss": 0.0235,
      "step": 19170
    },
    {
      "epoch": 2.310843373493976,
      "grad_norm": 0.07508594542741776,
      "learning_rate": 1.537831325301205e-05,
      "loss": 0.0377,
      "step": 19180
    },
    {
      "epoch": 2.3120481927710843,
      "grad_norm": 0.0645282119512558,
      "learning_rate": 1.5375903614457833e-05,
      "loss": 0.0212,
      "step": 19190
    },
    {
      "epoch": 2.3132530120481927,
      "grad_norm": 3.708580493927002,
      "learning_rate": 1.5373493975903615e-05,
      "loss": 0.0166,
      "step": 19200
    },
    {
      "epoch": 2.314457831325301,
      "grad_norm": 16.471832275390625,
      "learning_rate": 1.5371084337349396e-05,
      "loss": 0.0524,
      "step": 19210
    },
    {
      "epoch": 2.31566265060241,
      "grad_norm": 4.058849334716797,
      "learning_rate": 1.5368674698795185e-05,
      "loss": 0.0472,
      "step": 19220
    },
    {
      "epoch": 2.316867469879518,
      "grad_norm": 1.979910135269165,
      "learning_rate": 1.5366265060240966e-05,
      "loss": 0.0573,
      "step": 19230
    },
    {
      "epoch": 2.3180722891566266,
      "grad_norm": 14.446126937866211,
      "learning_rate": 1.5363855421686748e-05,
      "loss": 0.0726,
      "step": 19240
    },
    {
      "epoch": 2.319277108433735,
      "grad_norm": 0.05027787759900093,
      "learning_rate": 1.5361445783132532e-05,
      "loss": 0.0867,
      "step": 19250
    },
    {
      "epoch": 2.3204819277108433,
      "grad_norm": 0.06824208796024323,
      "learning_rate": 1.5359036144578314e-05,
      "loss": 0.0192,
      "step": 19260
    },
    {
      "epoch": 2.3216867469879516,
      "grad_norm": 2.7083897590637207,
      "learning_rate": 1.5356626506024095e-05,
      "loss": 0.0385,
      "step": 19270
    },
    {
      "epoch": 2.32289156626506,
      "grad_norm": 0.8975114226341248,
      "learning_rate": 1.535421686746988e-05,
      "loss": 0.0452,
      "step": 19280
    },
    {
      "epoch": 2.324096385542169,
      "grad_norm": 1.8149250745773315,
      "learning_rate": 1.5351807228915665e-05,
      "loss": 0.0752,
      "step": 19290
    },
    {
      "epoch": 2.325301204819277,
      "grad_norm": 0.2650284171104431,
      "learning_rate": 1.5349397590361447e-05,
      "loss": 0.0317,
      "step": 19300
    },
    {
      "epoch": 2.3265060240963855,
      "grad_norm": 0.05350155383348465,
      "learning_rate": 1.534698795180723e-05,
      "loss": 0.0033,
      "step": 19310
    },
    {
      "epoch": 2.327710843373494,
      "grad_norm": 0.12089300155639648,
      "learning_rate": 1.5344578313253013e-05,
      "loss": 0.0272,
      "step": 19320
    },
    {
      "epoch": 2.3289156626506022,
      "grad_norm": 0.21995076537132263,
      "learning_rate": 1.5342168674698798e-05,
      "loss": 0.0251,
      "step": 19330
    },
    {
      "epoch": 2.330120481927711,
      "grad_norm": 0.02654178999364376,
      "learning_rate": 1.533975903614458e-05,
      "loss": 0.0427,
      "step": 19340
    },
    {
      "epoch": 2.3313253012048194,
      "grad_norm": 0.42025625705718994,
      "learning_rate": 1.533734939759036e-05,
      "loss": 0.0616,
      "step": 19350
    },
    {
      "epoch": 2.3325301204819278,
      "grad_norm": 0.9182648062705994,
      "learning_rate": 1.5334939759036146e-05,
      "loss": 0.0386,
      "step": 19360
    },
    {
      "epoch": 2.333734939759036,
      "grad_norm": 0.027694428339600563,
      "learning_rate": 1.533253012048193e-05,
      "loss": 0.0415,
      "step": 19370
    },
    {
      "epoch": 2.3349397590361445,
      "grad_norm": 0.036656033247709274,
      "learning_rate": 1.5330120481927712e-05,
      "loss": 0.0505,
      "step": 19380
    },
    {
      "epoch": 2.336144578313253,
      "grad_norm": 0.5293044447898865,
      "learning_rate": 1.5327710843373497e-05,
      "loss": 0.0303,
      "step": 19390
    },
    {
      "epoch": 2.337349397590361,
      "grad_norm": 0.052361976355314255,
      "learning_rate": 1.532530120481928e-05,
      "loss": 0.0125,
      "step": 19400
    },
    {
      "epoch": 2.33855421686747,
      "grad_norm": 0.03558463230729103,
      "learning_rate": 1.532289156626506e-05,
      "loss": 0.0154,
      "step": 19410
    },
    {
      "epoch": 2.3397590361445784,
      "grad_norm": 1.9116852283477783,
      "learning_rate": 1.5320481927710845e-05,
      "loss": 0.0262,
      "step": 19420
    },
    {
      "epoch": 2.3409638554216867,
      "grad_norm": 0.045657962560653687,
      "learning_rate": 1.5318072289156626e-05,
      "loss": 0.0241,
      "step": 19430
    },
    {
      "epoch": 2.342168674698795,
      "grad_norm": 0.15841789543628693,
      "learning_rate": 1.531566265060241e-05,
      "loss": 0.0852,
      "step": 19440
    },
    {
      "epoch": 2.3433734939759034,
      "grad_norm": 0.02241593599319458,
      "learning_rate": 1.5313253012048196e-05,
      "loss": 0.0252,
      "step": 19450
    },
    {
      "epoch": 2.3445783132530122,
      "grad_norm": 0.013205422088503838,
      "learning_rate": 1.5310843373493977e-05,
      "loss": 0.0528,
      "step": 19460
    },
    {
      "epoch": 2.3457831325301206,
      "grad_norm": 2.7497503757476807,
      "learning_rate": 1.530843373493976e-05,
      "loss": 0.0676,
      "step": 19470
    },
    {
      "epoch": 2.346987951807229,
      "grad_norm": 3.357489824295044,
      "learning_rate": 1.5306024096385544e-05,
      "loss": 0.1352,
      "step": 19480
    },
    {
      "epoch": 2.3481927710843373,
      "grad_norm": 2.286381483078003,
      "learning_rate": 1.5303614457831325e-05,
      "loss": 0.0473,
      "step": 19490
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 2.4830052852630615,
      "learning_rate": 1.530120481927711e-05,
      "loss": 0.0624,
      "step": 19500
    },
    {
      "epoch": 2.350602409638554,
      "grad_norm": 4.094201564788818,
      "learning_rate": 1.529879518072289e-05,
      "loss": 0.031,
      "step": 19510
    },
    {
      "epoch": 2.3518072289156624,
      "grad_norm": 0.07924073189496994,
      "learning_rate": 1.5296385542168677e-05,
      "loss": 0.0498,
      "step": 19520
    },
    {
      "epoch": 2.353012048192771,
      "grad_norm": 1.031653642654419,
      "learning_rate": 1.529397590361446e-05,
      "loss": 0.035,
      "step": 19530
    },
    {
      "epoch": 2.3542168674698796,
      "grad_norm": 0.04568826034665108,
      "learning_rate": 1.5291566265060243e-05,
      "loss": 0.0833,
      "step": 19540
    },
    {
      "epoch": 2.355421686746988,
      "grad_norm": 35.91061782836914,
      "learning_rate": 1.5289156626506024e-05,
      "loss": 0.0065,
      "step": 19550
    },
    {
      "epoch": 2.3566265060240963,
      "grad_norm": 2.523266315460205,
      "learning_rate": 1.528674698795181e-05,
      "loss": 0.0802,
      "step": 19560
    },
    {
      "epoch": 2.3578313253012047,
      "grad_norm": 4.721104145050049,
      "learning_rate": 1.528433734939759e-05,
      "loss": 0.0323,
      "step": 19570
    },
    {
      "epoch": 2.3590361445783135,
      "grad_norm": 0.03377451002597809,
      "learning_rate": 1.5281927710843376e-05,
      "loss": 0.1034,
      "step": 19580
    },
    {
      "epoch": 2.360240963855422,
      "grad_norm": 0.5647472143173218,
      "learning_rate": 1.527951807228916e-05,
      "loss": 0.0294,
      "step": 19590
    },
    {
      "epoch": 2.36144578313253,
      "grad_norm": 1.7135990858078003,
      "learning_rate": 1.5277108433734942e-05,
      "loss": 0.0521,
      "step": 19600
    },
    {
      "epoch": 2.3626506024096385,
      "grad_norm": 6.808749675750732,
      "learning_rate": 1.5274698795180723e-05,
      "loss": 0.041,
      "step": 19610
    },
    {
      "epoch": 2.363855421686747,
      "grad_norm": 0.0737873911857605,
      "learning_rate": 1.5272289156626508e-05,
      "loss": 0.0202,
      "step": 19620
    },
    {
      "epoch": 2.3650602409638553,
      "grad_norm": 0.10579663515090942,
      "learning_rate": 1.526987951807229e-05,
      "loss": 0.0642,
      "step": 19630
    },
    {
      "epoch": 2.3662650602409636,
      "grad_norm": 0.023191330954432487,
      "learning_rate": 1.5267469879518075e-05,
      "loss": 0.0083,
      "step": 19640
    },
    {
      "epoch": 2.3674698795180724,
      "grad_norm": 3.685624361038208,
      "learning_rate": 1.5265060240963856e-05,
      "loss": 0.0633,
      "step": 19650
    },
    {
      "epoch": 2.3686746987951808,
      "grad_norm": 0.23707374930381775,
      "learning_rate": 1.5262650602409638e-05,
      "loss": 0.0771,
      "step": 19660
    },
    {
      "epoch": 2.369879518072289,
      "grad_norm": 4.4590935707092285,
      "learning_rate": 1.5260240963855422e-05,
      "loss": 0.0298,
      "step": 19670
    },
    {
      "epoch": 2.3710843373493975,
      "grad_norm": 4.445530891418457,
      "learning_rate": 1.5257831325301207e-05,
      "loss": 0.064,
      "step": 19680
    },
    {
      "epoch": 2.372289156626506,
      "grad_norm": 0.10407713800668716,
      "learning_rate": 1.5255421686746989e-05,
      "loss": 0.0499,
      "step": 19690
    },
    {
      "epoch": 2.3734939759036147,
      "grad_norm": 2.780642509460449,
      "learning_rate": 1.5253012048192772e-05,
      "loss": 0.0153,
      "step": 19700
    },
    {
      "epoch": 2.374698795180723,
      "grad_norm": 0.7071027755737305,
      "learning_rate": 1.5250602409638555e-05,
      "loss": 0.027,
      "step": 19710
    },
    {
      "epoch": 2.3759036144578314,
      "grad_norm": 0.8978304266929626,
      "learning_rate": 1.5248192771084338e-05,
      "loss": 0.0907,
      "step": 19720
    },
    {
      "epoch": 2.3771084337349397,
      "grad_norm": 14.810236930847168,
      "learning_rate": 1.5245783132530122e-05,
      "loss": 0.0357,
      "step": 19730
    },
    {
      "epoch": 2.378313253012048,
      "grad_norm": 0.22223520278930664,
      "learning_rate": 1.5243373493975906e-05,
      "loss": 0.0833,
      "step": 19740
    },
    {
      "epoch": 2.3795180722891565,
      "grad_norm": 0.024447431787848473,
      "learning_rate": 1.524096385542169e-05,
      "loss": 0.0266,
      "step": 19750
    },
    {
      "epoch": 2.380722891566265,
      "grad_norm": 1.7159854173660278,
      "learning_rate": 1.5238554216867471e-05,
      "loss": 0.0261,
      "step": 19760
    },
    {
      "epoch": 2.3819277108433736,
      "grad_norm": 0.17620006203651428,
      "learning_rate": 1.5236144578313254e-05,
      "loss": 0.054,
      "step": 19770
    },
    {
      "epoch": 2.383132530120482,
      "grad_norm": 0.04291195422410965,
      "learning_rate": 1.5233734939759037e-05,
      "loss": 0.0144,
      "step": 19780
    },
    {
      "epoch": 2.3843373493975903,
      "grad_norm": 2.4347517490386963,
      "learning_rate": 1.523132530120482e-05,
      "loss": 0.0096,
      "step": 19790
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 0.018293367698788643,
      "learning_rate": 1.5228915662650604e-05,
      "loss": 0.0635,
      "step": 19800
    },
    {
      "epoch": 2.386746987951807,
      "grad_norm": 0.10166332870721817,
      "learning_rate": 1.5226506024096385e-05,
      "loss": 0.0235,
      "step": 19810
    },
    {
      "epoch": 2.387951807228916,
      "grad_norm": 10.743374824523926,
      "learning_rate": 1.522409638554217e-05,
      "loss": 0.0371,
      "step": 19820
    },
    {
      "epoch": 2.3891566265060242,
      "grad_norm": 0.028607552871108055,
      "learning_rate": 1.5221686746987953e-05,
      "loss": 0.0301,
      "step": 19830
    },
    {
      "epoch": 2.3903614457831326,
      "grad_norm": 0.556499183177948,
      "learning_rate": 1.5219277108433736e-05,
      "loss": 0.0726,
      "step": 19840
    },
    {
      "epoch": 2.391566265060241,
      "grad_norm": 0.011637113057076931,
      "learning_rate": 1.521686746987952e-05,
      "loss": 0.0515,
      "step": 19850
    },
    {
      "epoch": 2.3927710843373493,
      "grad_norm": 0.38452690839767456,
      "learning_rate": 1.5214457831325303e-05,
      "loss": 0.044,
      "step": 19860
    },
    {
      "epoch": 2.3939759036144577,
      "grad_norm": 11.365386962890625,
      "learning_rate": 1.5212048192771084e-05,
      "loss": 0.0358,
      "step": 19870
    },
    {
      "epoch": 2.395180722891566,
      "grad_norm": 0.012432432733476162,
      "learning_rate": 1.5209638554216867e-05,
      "loss": 0.0703,
      "step": 19880
    },
    {
      "epoch": 2.396385542168675,
      "grad_norm": 0.01330028846859932,
      "learning_rate": 1.5207228915662652e-05,
      "loss": 0.0454,
      "step": 19890
    },
    {
      "epoch": 2.397590361445783,
      "grad_norm": 0.01464535016566515,
      "learning_rate": 1.5204819277108436e-05,
      "loss": 0.0351,
      "step": 19900
    },
    {
      "epoch": 2.3987951807228916,
      "grad_norm": 14.523568153381348,
      "learning_rate": 1.5202409638554219e-05,
      "loss": 0.0773,
      "step": 19910
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.12109595537185669,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.0578,
      "step": 19920
    },
    {
      "epoch": 2.4012048192771083,
      "grad_norm": 0.13274647295475006,
      "learning_rate": 1.5197590361445785e-05,
      "loss": 0.0319,
      "step": 19930
    },
    {
      "epoch": 2.402409638554217,
      "grad_norm": 0.1115315705537796,
      "learning_rate": 1.5195180722891567e-05,
      "loss": 0.0162,
      "step": 19940
    },
    {
      "epoch": 2.4036144578313254,
      "grad_norm": 0.040367115288972855,
      "learning_rate": 1.519277108433735e-05,
      "loss": 0.0401,
      "step": 19950
    },
    {
      "epoch": 2.404819277108434,
      "grad_norm": 13.295808792114258,
      "learning_rate": 1.5190361445783133e-05,
      "loss": 0.0456,
      "step": 19960
    },
    {
      "epoch": 2.406024096385542,
      "grad_norm": 0.7018280029296875,
      "learning_rate": 1.5187951807228918e-05,
      "loss": 0.0063,
      "step": 19970
    },
    {
      "epoch": 2.4072289156626505,
      "grad_norm": 0.5635570287704468,
      "learning_rate": 1.5185542168674701e-05,
      "loss": 0.0148,
      "step": 19980
    },
    {
      "epoch": 2.408433734939759,
      "grad_norm": 0.45001131296157837,
      "learning_rate": 1.5183132530120484e-05,
      "loss": 0.0178,
      "step": 19990
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 1.5626169443130493,
      "learning_rate": 1.5180722891566266e-05,
      "loss": 0.0928,
      "step": 20000
    },
    {
      "epoch": 2.410843373493976,
      "grad_norm": 0.09704084694385529,
      "learning_rate": 1.5178313253012049e-05,
      "loss": 0.0931,
      "step": 20010
    },
    {
      "epoch": 2.4120481927710844,
      "grad_norm": 0.11273080110549927,
      "learning_rate": 1.5175903614457832e-05,
      "loss": 0.0364,
      "step": 20020
    },
    {
      "epoch": 2.4132530120481928,
      "grad_norm": 0.374429851770401,
      "learning_rate": 1.5173493975903615e-05,
      "loss": 0.0837,
      "step": 20030
    },
    {
      "epoch": 2.414457831325301,
      "grad_norm": 5.456805229187012,
      "learning_rate": 1.51710843373494e-05,
      "loss": 0.0325,
      "step": 20040
    },
    {
      "epoch": 2.4156626506024095,
      "grad_norm": 0.1767665445804596,
      "learning_rate": 1.5168674698795183e-05,
      "loss": 0.028,
      "step": 20050
    },
    {
      "epoch": 2.4168674698795183,
      "grad_norm": 0.657831072807312,
      "learning_rate": 1.5166265060240966e-05,
      "loss": 0.0529,
      "step": 20060
    },
    {
      "epoch": 2.4180722891566266,
      "grad_norm": 19.81196403503418,
      "learning_rate": 1.5163855421686748e-05,
      "loss": 0.0214,
      "step": 20070
    },
    {
      "epoch": 2.419277108433735,
      "grad_norm": 0.018666407093405724,
      "learning_rate": 1.5161445783132531e-05,
      "loss": 0.0802,
      "step": 20080
    },
    {
      "epoch": 2.4204819277108434,
      "grad_norm": 0.016448335722088814,
      "learning_rate": 1.5159036144578314e-05,
      "loss": 0.0406,
      "step": 20090
    },
    {
      "epoch": 2.4216867469879517,
      "grad_norm": 0.15603451430797577,
      "learning_rate": 1.5156626506024097e-05,
      "loss": 0.0759,
      "step": 20100
    },
    {
      "epoch": 2.42289156626506,
      "grad_norm": 0.6722341775894165,
      "learning_rate": 1.515421686746988e-05,
      "loss": 0.0171,
      "step": 20110
    },
    {
      "epoch": 2.4240963855421684,
      "grad_norm": 0.023677073419094086,
      "learning_rate": 1.5151807228915665e-05,
      "loss": 0.0391,
      "step": 20120
    },
    {
      "epoch": 2.4253012048192772,
      "grad_norm": 0.013852108269929886,
      "learning_rate": 1.5149397590361447e-05,
      "loss": 0.042,
      "step": 20130
    },
    {
      "epoch": 2.4265060240963856,
      "grad_norm": 4.205091953277588,
      "learning_rate": 1.514698795180723e-05,
      "loss": 0.0449,
      "step": 20140
    },
    {
      "epoch": 2.427710843373494,
      "grad_norm": 0.06442487984895706,
      "learning_rate": 1.5144578313253013e-05,
      "loss": 0.062,
      "step": 20150
    },
    {
      "epoch": 2.4289156626506023,
      "grad_norm": 0.7287954092025757,
      "learning_rate": 1.5142168674698796e-05,
      "loss": 0.0236,
      "step": 20160
    },
    {
      "epoch": 2.4301204819277107,
      "grad_norm": 0.3934112787246704,
      "learning_rate": 1.513975903614458e-05,
      "loss": 0.0869,
      "step": 20170
    },
    {
      "epoch": 2.4313253012048195,
      "grad_norm": 0.025055719539523125,
      "learning_rate": 1.5137349397590361e-05,
      "loss": 0.004,
      "step": 20180
    },
    {
      "epoch": 2.432530120481928,
      "grad_norm": 0.07427000254392624,
      "learning_rate": 1.5134939759036148e-05,
      "loss": 0.0218,
      "step": 20190
    },
    {
      "epoch": 2.433734939759036,
      "grad_norm": 0.02690999209880829,
      "learning_rate": 1.5132530120481929e-05,
      "loss": 0.0412,
      "step": 20200
    },
    {
      "epoch": 2.4349397590361446,
      "grad_norm": 13.380539894104004,
      "learning_rate": 1.5130120481927712e-05,
      "loss": 0.0975,
      "step": 20210
    },
    {
      "epoch": 2.436144578313253,
      "grad_norm": 0.19382354617118835,
      "learning_rate": 1.5127710843373495e-05,
      "loss": 0.0561,
      "step": 20220
    },
    {
      "epoch": 2.4373493975903613,
      "grad_norm": 1.7681044340133667,
      "learning_rate": 1.5125301204819279e-05,
      "loss": 0.0831,
      "step": 20230
    },
    {
      "epoch": 2.4385542168674696,
      "grad_norm": 6.173618316650391,
      "learning_rate": 1.5122891566265062e-05,
      "loss": 0.0722,
      "step": 20240
    },
    {
      "epoch": 2.4397590361445785,
      "grad_norm": 1.515394926071167,
      "learning_rate": 1.5120481927710843e-05,
      "loss": 0.0462,
      "step": 20250
    },
    {
      "epoch": 2.440963855421687,
      "grad_norm": 2.0918760299682617,
      "learning_rate": 1.5118072289156626e-05,
      "loss": 0.0501,
      "step": 20260
    },
    {
      "epoch": 2.442168674698795,
      "grad_norm": 0.11851368099451065,
      "learning_rate": 1.5115662650602411e-05,
      "loss": 0.0204,
      "step": 20270
    },
    {
      "epoch": 2.4433734939759035,
      "grad_norm": 0.019639264792203903,
      "learning_rate": 1.5113253012048194e-05,
      "loss": 0.0267,
      "step": 20280
    },
    {
      "epoch": 2.444578313253012,
      "grad_norm": 0.4403747320175171,
      "learning_rate": 1.5110843373493978e-05,
      "loss": 0.0637,
      "step": 20290
    },
    {
      "epoch": 2.4457831325301207,
      "grad_norm": 0.07766741514205933,
      "learning_rate": 1.5108433734939761e-05,
      "loss": 0.0907,
      "step": 20300
    },
    {
      "epoch": 2.446987951807229,
      "grad_norm": 0.11244253814220428,
      "learning_rate": 1.5106024096385542e-05,
      "loss": 0.0472,
      "step": 20310
    },
    {
      "epoch": 2.4481927710843374,
      "grad_norm": 0.33245670795440674,
      "learning_rate": 1.5103614457831326e-05,
      "loss": 0.0334,
      "step": 20320
    },
    {
      "epoch": 2.4493975903614458,
      "grad_norm": 0.3432066738605499,
      "learning_rate": 1.5101204819277109e-05,
      "loss": 0.0416,
      "step": 20330
    },
    {
      "epoch": 2.450602409638554,
      "grad_norm": 1.3349254131317139,
      "learning_rate": 1.5098795180722894e-05,
      "loss": 0.0292,
      "step": 20340
    },
    {
      "epoch": 2.4518072289156625,
      "grad_norm": 1.6197234392166138,
      "learning_rate": 1.5096385542168677e-05,
      "loss": 0.0681,
      "step": 20350
    },
    {
      "epoch": 2.453012048192771,
      "grad_norm": 5.477072715759277,
      "learning_rate": 1.509397590361446e-05,
      "loss": 0.0259,
      "step": 20360
    },
    {
      "epoch": 2.4542168674698797,
      "grad_norm": 4.195314407348633,
      "learning_rate": 1.5091566265060243e-05,
      "loss": 0.0474,
      "step": 20370
    },
    {
      "epoch": 2.455421686746988,
      "grad_norm": 2.0925378799438477,
      "learning_rate": 1.5089156626506025e-05,
      "loss": 0.0514,
      "step": 20380
    },
    {
      "epoch": 2.4566265060240964,
      "grad_norm": 0.19627374410629272,
      "learning_rate": 1.5086746987951808e-05,
      "loss": 0.0941,
      "step": 20390
    },
    {
      "epoch": 2.4578313253012047,
      "grad_norm": 1.363093376159668,
      "learning_rate": 1.5084337349397591e-05,
      "loss": 0.0744,
      "step": 20400
    },
    {
      "epoch": 2.459036144578313,
      "grad_norm": 53.29573440551758,
      "learning_rate": 1.5081927710843374e-05,
      "loss": 0.0362,
      "step": 20410
    },
    {
      "epoch": 2.460240963855422,
      "grad_norm": 0.23720364272594452,
      "learning_rate": 1.5079518072289159e-05,
      "loss": 0.0064,
      "step": 20420
    },
    {
      "epoch": 2.4614457831325303,
      "grad_norm": 0.07281399518251419,
      "learning_rate": 1.5077108433734942e-05,
      "loss": 0.0368,
      "step": 20430
    },
    {
      "epoch": 2.4626506024096386,
      "grad_norm": 0.014587652869522572,
      "learning_rate": 1.5074698795180724e-05,
      "loss": 0.0262,
      "step": 20440
    },
    {
      "epoch": 2.463855421686747,
      "grad_norm": 0.026367472484707832,
      "learning_rate": 1.5072289156626507e-05,
      "loss": 0.043,
      "step": 20450
    },
    {
      "epoch": 2.4650602409638553,
      "grad_norm": 8.77463150024414,
      "learning_rate": 1.506987951807229e-05,
      "loss": 0.0584,
      "step": 20460
    },
    {
      "epoch": 2.4662650602409637,
      "grad_norm": 0.03308170661330223,
      "learning_rate": 1.5067469879518073e-05,
      "loss": 0.0216,
      "step": 20470
    },
    {
      "epoch": 2.467469879518072,
      "grad_norm": 0.010222207754850388,
      "learning_rate": 1.5065060240963856e-05,
      "loss": 0.05,
      "step": 20480
    },
    {
      "epoch": 2.468674698795181,
      "grad_norm": 0.12050383538007736,
      "learning_rate": 1.5062650602409641e-05,
      "loss": 0.0659,
      "step": 20490
    },
    {
      "epoch": 2.4698795180722892,
      "grad_norm": 0.01355813629925251,
      "learning_rate": 1.5060240963855424e-05,
      "loss": 0.0468,
      "step": 20500
    },
    {
      "epoch": 2.4710843373493976,
      "grad_norm": 0.22363534569740295,
      "learning_rate": 1.5057831325301206e-05,
      "loss": 0.0655,
      "step": 20510
    },
    {
      "epoch": 2.472289156626506,
      "grad_norm": 4.02781343460083,
      "learning_rate": 1.5055421686746989e-05,
      "loss": 0.077,
      "step": 20520
    },
    {
      "epoch": 2.4734939759036143,
      "grad_norm": 0.2135007381439209,
      "learning_rate": 1.5053012048192772e-05,
      "loss": 0.0294,
      "step": 20530
    },
    {
      "epoch": 2.474698795180723,
      "grad_norm": 7.694260597229004,
      "learning_rate": 1.5050602409638555e-05,
      "loss": 0.0535,
      "step": 20540
    },
    {
      "epoch": 2.4759036144578315,
      "grad_norm": 0.02280978485941887,
      "learning_rate": 1.5048192771084339e-05,
      "loss": 0.0466,
      "step": 20550
    },
    {
      "epoch": 2.47710843373494,
      "grad_norm": 2.246398687362671,
      "learning_rate": 1.504578313253012e-05,
      "loss": 0.0142,
      "step": 20560
    },
    {
      "epoch": 2.478313253012048,
      "grad_norm": 0.4567531943321228,
      "learning_rate": 1.5043373493975905e-05,
      "loss": 0.0022,
      "step": 20570
    },
    {
      "epoch": 2.4795180722891565,
      "grad_norm": 0.017056766897439957,
      "learning_rate": 1.5040963855421688e-05,
      "loss": 0.0484,
      "step": 20580
    },
    {
      "epoch": 2.480722891566265,
      "grad_norm": 0.027302555739879608,
      "learning_rate": 1.5038554216867471e-05,
      "loss": 0.0192,
      "step": 20590
    },
    {
      "epoch": 2.4819277108433733,
      "grad_norm": 2.6799840927124023,
      "learning_rate": 1.5036144578313254e-05,
      "loss": 0.0168,
      "step": 20600
    },
    {
      "epoch": 2.483132530120482,
      "grad_norm": 0.010570472106337547,
      "learning_rate": 1.5033734939759038e-05,
      "loss": 0.054,
      "step": 20610
    },
    {
      "epoch": 2.4843373493975904,
      "grad_norm": 0.012966929003596306,
      "learning_rate": 1.5031325301204819e-05,
      "loss": 0.0439,
      "step": 20620
    },
    {
      "epoch": 2.485542168674699,
      "grad_norm": 0.009362957440316677,
      "learning_rate": 1.5028915662650602e-05,
      "loss": 0.045,
      "step": 20630
    },
    {
      "epoch": 2.486746987951807,
      "grad_norm": 0.012808513827621937,
      "learning_rate": 1.5026506024096387e-05,
      "loss": 0.0577,
      "step": 20640
    },
    {
      "epoch": 2.4879518072289155,
      "grad_norm": 0.17683547735214233,
      "learning_rate": 1.502409638554217e-05,
      "loss": 0.0335,
      "step": 20650
    },
    {
      "epoch": 2.4891566265060243,
      "grad_norm": 14.079469680786133,
      "learning_rate": 1.5021686746987953e-05,
      "loss": 0.0392,
      "step": 20660
    },
    {
      "epoch": 2.4903614457831327,
      "grad_norm": 0.015142114832997322,
      "learning_rate": 1.5019277108433737e-05,
      "loss": 0.0009,
      "step": 20670
    },
    {
      "epoch": 2.491566265060241,
      "grad_norm": 0.022517479956150055,
      "learning_rate": 1.501686746987952e-05,
      "loss": 0.0551,
      "step": 20680
    },
    {
      "epoch": 2.4927710843373494,
      "grad_norm": 0.2972206771373749,
      "learning_rate": 1.5014457831325301e-05,
      "loss": 0.0776,
      "step": 20690
    },
    {
      "epoch": 2.4939759036144578,
      "grad_norm": 2.0426528453826904,
      "learning_rate": 1.5012048192771084e-05,
      "loss": 0.0871,
      "step": 20700
    },
    {
      "epoch": 2.495180722891566,
      "grad_norm": 0.07984577119350433,
      "learning_rate": 1.5009638554216868e-05,
      "loss": 0.0114,
      "step": 20710
    },
    {
      "epoch": 2.4963855421686745,
      "grad_norm": 0.01537677738815546,
      "learning_rate": 1.5007228915662653e-05,
      "loss": 0.0324,
      "step": 20720
    },
    {
      "epoch": 2.4975903614457833,
      "grad_norm": 0.06522654742002487,
      "learning_rate": 1.5004819277108436e-05,
      "loss": 0.0423,
      "step": 20730
    },
    {
      "epoch": 2.4987951807228916,
      "grad_norm": 0.09446481615304947,
      "learning_rate": 1.5002409638554219e-05,
      "loss": 0.084,
      "step": 20740
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.24243700504302979,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.133,
      "step": 20750
    },
    {
      "epoch": 2.5012048192771084,
      "grad_norm": 0.1101345419883728,
      "learning_rate": 1.4997590361445784e-05,
      "loss": 0.0118,
      "step": 20760
    },
    {
      "epoch": 2.5024096385542167,
      "grad_norm": 1.6570101976394653,
      "learning_rate": 1.4995180722891567e-05,
      "loss": 0.0464,
      "step": 20770
    },
    {
      "epoch": 2.5036144578313255,
      "grad_norm": 0.06527993828058243,
      "learning_rate": 1.499277108433735e-05,
      "loss": 0.0338,
      "step": 20780
    },
    {
      "epoch": 2.504819277108434,
      "grad_norm": 0.06665627658367157,
      "learning_rate": 1.4990361445783135e-05,
      "loss": 0.046,
      "step": 20790
    },
    {
      "epoch": 2.5060240963855422,
      "grad_norm": 0.05304000899195671,
      "learning_rate": 1.4987951807228918e-05,
      "loss": 0.0746,
      "step": 20800
    },
    {
      "epoch": 2.5072289156626506,
      "grad_norm": 19.293758392333984,
      "learning_rate": 1.4985542168674701e-05,
      "loss": 0.0836,
      "step": 20810
    },
    {
      "epoch": 2.508433734939759,
      "grad_norm": 0.9800792932510376,
      "learning_rate": 1.4983132530120483e-05,
      "loss": 0.0287,
      "step": 20820
    },
    {
      "epoch": 2.5096385542168673,
      "grad_norm": 0.08511856198310852,
      "learning_rate": 1.4980722891566266e-05,
      "loss": 0.0462,
      "step": 20830
    },
    {
      "epoch": 2.5108433734939757,
      "grad_norm": 18.566646575927734,
      "learning_rate": 1.4978313253012049e-05,
      "loss": 0.0802,
      "step": 20840
    },
    {
      "epoch": 2.5120481927710845,
      "grad_norm": 0.5745693445205688,
      "learning_rate": 1.4975903614457832e-05,
      "loss": 0.0092,
      "step": 20850
    },
    {
      "epoch": 2.513253012048193,
      "grad_norm": 0.41656556725502014,
      "learning_rate": 1.4973493975903615e-05,
      "loss": 0.0777,
      "step": 20860
    },
    {
      "epoch": 2.514457831325301,
      "grad_norm": 0.7383478283882141,
      "learning_rate": 1.49710843373494e-05,
      "loss": 0.071,
      "step": 20870
    },
    {
      "epoch": 2.5156626506024096,
      "grad_norm": 0.16312094032764435,
      "learning_rate": 1.4968674698795183e-05,
      "loss": 0.053,
      "step": 20880
    },
    {
      "epoch": 2.516867469879518,
      "grad_norm": 0.14876368641853333,
      "learning_rate": 1.4966265060240965e-05,
      "loss": 0.0351,
      "step": 20890
    },
    {
      "epoch": 2.5180722891566267,
      "grad_norm": 3.271013021469116,
      "learning_rate": 1.4963855421686748e-05,
      "loss": 0.0493,
      "step": 20900
    },
    {
      "epoch": 2.519277108433735,
      "grad_norm": 1.0905216932296753,
      "learning_rate": 1.4961445783132531e-05,
      "loss": 0.0379,
      "step": 20910
    },
    {
      "epoch": 2.5204819277108435,
      "grad_norm": 0.0776553601026535,
      "learning_rate": 1.4959036144578314e-05,
      "loss": 0.0627,
      "step": 20920
    },
    {
      "epoch": 2.521686746987952,
      "grad_norm": 0.015717091038823128,
      "learning_rate": 1.4956626506024098e-05,
      "loss": 0.0448,
      "step": 20930
    },
    {
      "epoch": 2.52289156626506,
      "grad_norm": 0.07472654432058334,
      "learning_rate": 1.4954216867469882e-05,
      "loss": 0.0604,
      "step": 20940
    },
    {
      "epoch": 2.5240963855421685,
      "grad_norm": 0.328255295753479,
      "learning_rate": 1.4951807228915664e-05,
      "loss": 0.1133,
      "step": 20950
    },
    {
      "epoch": 2.525301204819277,
      "grad_norm": 1.2180659770965576,
      "learning_rate": 1.4949397590361447e-05,
      "loss": 0.0582,
      "step": 20960
    },
    {
      "epoch": 2.5265060240963857,
      "grad_norm": 0.02298501692712307,
      "learning_rate": 1.494698795180723e-05,
      "loss": 0.0333,
      "step": 20970
    },
    {
      "epoch": 2.527710843373494,
      "grad_norm": 1.2614377737045288,
      "learning_rate": 1.4944578313253013e-05,
      "loss": 0.0306,
      "step": 20980
    },
    {
      "epoch": 2.5289156626506024,
      "grad_norm": 0.3545790910720825,
      "learning_rate": 1.4942168674698797e-05,
      "loss": 0.0674,
      "step": 20990
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 4.954995632171631,
      "learning_rate": 1.4939759036144578e-05,
      "loss": 0.0808,
      "step": 21000
    },
    {
      "epoch": 2.531325301204819,
      "grad_norm": 1.9243104457855225,
      "learning_rate": 1.4937349397590361e-05,
      "loss": 0.0422,
      "step": 21010
    },
    {
      "epoch": 2.532530120481928,
      "grad_norm": 0.8173362016677856,
      "learning_rate": 1.4934939759036146e-05,
      "loss": 0.1027,
      "step": 21020
    },
    {
      "epoch": 2.5337349397590363,
      "grad_norm": 0.629176914691925,
      "learning_rate": 1.493253012048193e-05,
      "loss": 0.0699,
      "step": 21030
    },
    {
      "epoch": 2.5349397590361447,
      "grad_norm": 0.02315174601972103,
      "learning_rate": 1.4930120481927712e-05,
      "loss": 0.0246,
      "step": 21040
    },
    {
      "epoch": 2.536144578313253,
      "grad_norm": 41.77769088745117,
      "learning_rate": 1.4927710843373496e-05,
      "loss": 0.0372,
      "step": 21050
    },
    {
      "epoch": 2.5373493975903614,
      "grad_norm": 0.15008902549743652,
      "learning_rate": 1.4925301204819279e-05,
      "loss": 0.0998,
      "step": 21060
    },
    {
      "epoch": 2.5385542168674697,
      "grad_norm": 0.7875667810440063,
      "learning_rate": 1.492289156626506e-05,
      "loss": 0.0329,
      "step": 21070
    },
    {
      "epoch": 2.539759036144578,
      "grad_norm": 0.0476277619600296,
      "learning_rate": 1.4920481927710843e-05,
      "loss": 0.0585,
      "step": 21080
    },
    {
      "epoch": 2.540963855421687,
      "grad_norm": 4.455492973327637,
      "learning_rate": 1.4918072289156628e-05,
      "loss": 0.0699,
      "step": 21090
    },
    {
      "epoch": 2.5421686746987953,
      "grad_norm": 0.11053713411092758,
      "learning_rate": 1.4915662650602412e-05,
      "loss": 0.0079,
      "step": 21100
    },
    {
      "epoch": 2.5433734939759036,
      "grad_norm": 0.7505848407745361,
      "learning_rate": 1.4913253012048195e-05,
      "loss": 0.0261,
      "step": 21110
    },
    {
      "epoch": 2.544578313253012,
      "grad_norm": 44.21039581298828,
      "learning_rate": 1.4910843373493978e-05,
      "loss": 0.0585,
      "step": 21120
    },
    {
      "epoch": 2.5457831325301203,
      "grad_norm": 14.429049491882324,
      "learning_rate": 1.490843373493976e-05,
      "loss": 0.0838,
      "step": 21130
    },
    {
      "epoch": 2.546987951807229,
      "grad_norm": 0.20128296315670013,
      "learning_rate": 1.4906024096385543e-05,
      "loss": 0.0566,
      "step": 21140
    },
    {
      "epoch": 2.5481927710843375,
      "grad_norm": 10.019683837890625,
      "learning_rate": 1.4903614457831326e-05,
      "loss": 0.0332,
      "step": 21150
    },
    {
      "epoch": 2.549397590361446,
      "grad_norm": 14.114670753479004,
      "learning_rate": 1.4901204819277109e-05,
      "loss": 0.0818,
      "step": 21160
    },
    {
      "epoch": 2.5506024096385542,
      "grad_norm": 2.642427444458008,
      "learning_rate": 1.4898795180722894e-05,
      "loss": 0.077,
      "step": 21170
    },
    {
      "epoch": 2.5518072289156626,
      "grad_norm": 25.587541580200195,
      "learning_rate": 1.4896385542168677e-05,
      "loss": 0.0455,
      "step": 21180
    },
    {
      "epoch": 2.553012048192771,
      "grad_norm": 9.621782302856445,
      "learning_rate": 1.489397590361446e-05,
      "loss": 0.0818,
      "step": 21190
    },
    {
      "epoch": 2.5542168674698793,
      "grad_norm": 0.17671898007392883,
      "learning_rate": 1.4891566265060242e-05,
      "loss": 0.0477,
      "step": 21200
    },
    {
      "epoch": 2.555421686746988,
      "grad_norm": 0.20323048532009125,
      "learning_rate": 1.4889156626506025e-05,
      "loss": 0.0366,
      "step": 21210
    },
    {
      "epoch": 2.5566265060240965,
      "grad_norm": 0.9690591096878052,
      "learning_rate": 1.4886746987951808e-05,
      "loss": 0.0333,
      "step": 21220
    },
    {
      "epoch": 2.557831325301205,
      "grad_norm": 2.960587739944458,
      "learning_rate": 1.4884337349397591e-05,
      "loss": 0.0095,
      "step": 21230
    },
    {
      "epoch": 2.559036144578313,
      "grad_norm": 3.9281821250915527,
      "learning_rate": 1.4881927710843376e-05,
      "loss": 0.0403,
      "step": 21240
    },
    {
      "epoch": 2.5602409638554215,
      "grad_norm": 0.017631378024816513,
      "learning_rate": 1.487951807228916e-05,
      "loss": 0.0648,
      "step": 21250
    },
    {
      "epoch": 2.5614457831325304,
      "grad_norm": 0.44325295090675354,
      "learning_rate": 1.487710843373494e-05,
      "loss": 0.0527,
      "step": 21260
    },
    {
      "epoch": 2.5626506024096387,
      "grad_norm": 8.305157661437988,
      "learning_rate": 1.4874698795180724e-05,
      "loss": 0.0339,
      "step": 21270
    },
    {
      "epoch": 2.563855421686747,
      "grad_norm": 0.5576151013374329,
      "learning_rate": 1.4872289156626507e-05,
      "loss": 0.0547,
      "step": 21280
    },
    {
      "epoch": 2.5650602409638554,
      "grad_norm": 0.2071934938430786,
      "learning_rate": 1.486987951807229e-05,
      "loss": 0.0224,
      "step": 21290
    },
    {
      "epoch": 2.566265060240964,
      "grad_norm": 6.119463920593262,
      "learning_rate": 1.4867469879518073e-05,
      "loss": 0.0596,
      "step": 21300
    },
    {
      "epoch": 2.567469879518072,
      "grad_norm": 0.0588720440864563,
      "learning_rate": 1.4865060240963855e-05,
      "loss": 0.0517,
      "step": 21310
    },
    {
      "epoch": 2.5686746987951805,
      "grad_norm": 0.11203140020370483,
      "learning_rate": 1.4862650602409641e-05,
      "loss": 0.0564,
      "step": 21320
    },
    {
      "epoch": 2.5698795180722893,
      "grad_norm": 0.09257374703884125,
      "learning_rate": 1.4860240963855423e-05,
      "loss": 0.0776,
      "step": 21330
    },
    {
      "epoch": 2.5710843373493977,
      "grad_norm": 0.08835553377866745,
      "learning_rate": 1.4857831325301206e-05,
      "loss": 0.0281,
      "step": 21340
    },
    {
      "epoch": 2.572289156626506,
      "grad_norm": 0.27016472816467285,
      "learning_rate": 1.485542168674699e-05,
      "loss": 0.0534,
      "step": 21350
    },
    {
      "epoch": 2.5734939759036144,
      "grad_norm": 0.034274861216545105,
      "learning_rate": 1.4853012048192772e-05,
      "loss": 0.106,
      "step": 21360
    },
    {
      "epoch": 2.5746987951807228,
      "grad_norm": 0.014223942533135414,
      "learning_rate": 1.4850602409638556e-05,
      "loss": 0.0049,
      "step": 21370
    },
    {
      "epoch": 2.5759036144578316,
      "grad_norm": 0.32331371307373047,
      "learning_rate": 1.4848192771084337e-05,
      "loss": 0.061,
      "step": 21380
    },
    {
      "epoch": 2.57710843373494,
      "grad_norm": 0.3114200830459595,
      "learning_rate": 1.4845783132530122e-05,
      "loss": 0.0449,
      "step": 21390
    },
    {
      "epoch": 2.5783132530120483,
      "grad_norm": 0.10299290716648102,
      "learning_rate": 1.4843373493975905e-05,
      "loss": 0.0275,
      "step": 21400
    },
    {
      "epoch": 2.5795180722891566,
      "grad_norm": 2.0556745529174805,
      "learning_rate": 1.4840963855421688e-05,
      "loss": 0.0517,
      "step": 21410
    },
    {
      "epoch": 2.580722891566265,
      "grad_norm": 3.245527744293213,
      "learning_rate": 1.4838554216867471e-05,
      "loss": 0.0373,
      "step": 21420
    },
    {
      "epoch": 2.5819277108433734,
      "grad_norm": 0.025260277092456818,
      "learning_rate": 1.4836144578313255e-05,
      "loss": 0.0378,
      "step": 21430
    },
    {
      "epoch": 2.5831325301204817,
      "grad_norm": 0.1268697828054428,
      "learning_rate": 1.4833734939759036e-05,
      "loss": 0.0848,
      "step": 21440
    },
    {
      "epoch": 2.5843373493975905,
      "grad_norm": 0.4040522873401642,
      "learning_rate": 1.483132530120482e-05,
      "loss": 0.0411,
      "step": 21450
    },
    {
      "epoch": 2.585542168674699,
      "grad_norm": 7.511020660400391,
      "learning_rate": 1.4828915662650602e-05,
      "loss": 0.0594,
      "step": 21460
    },
    {
      "epoch": 2.5867469879518072,
      "grad_norm": 11.956216812133789,
      "learning_rate": 1.4826506024096387e-05,
      "loss": 0.03,
      "step": 21470
    },
    {
      "epoch": 2.5879518072289156,
      "grad_norm": 0.05310717225074768,
      "learning_rate": 1.482409638554217e-05,
      "loss": 0.0108,
      "step": 21480
    },
    {
      "epoch": 2.589156626506024,
      "grad_norm": 5.370265007019043,
      "learning_rate": 1.4821686746987954e-05,
      "loss": 0.0537,
      "step": 21490
    },
    {
      "epoch": 2.5903614457831328,
      "grad_norm": 1.5214567184448242,
      "learning_rate": 1.4819277108433737e-05,
      "loss": 0.0469,
      "step": 21500
    },
    {
      "epoch": 2.591566265060241,
      "grad_norm": 3.6431097984313965,
      "learning_rate": 1.4816867469879518e-05,
      "loss": 0.0373,
      "step": 21510
    },
    {
      "epoch": 2.5927710843373495,
      "grad_norm": 0.6111133098602295,
      "learning_rate": 1.4814457831325302e-05,
      "loss": 0.0735,
      "step": 21520
    },
    {
      "epoch": 2.593975903614458,
      "grad_norm": 0.6006105542182922,
      "learning_rate": 1.4812048192771085e-05,
      "loss": 0.0339,
      "step": 21530
    },
    {
      "epoch": 2.595180722891566,
      "grad_norm": 0.1276387870311737,
      "learning_rate": 1.480963855421687e-05,
      "loss": 0.0384,
      "step": 21540
    },
    {
      "epoch": 2.5963855421686746,
      "grad_norm": 31.036252975463867,
      "learning_rate": 1.4807228915662653e-05,
      "loss": 0.0293,
      "step": 21550
    },
    {
      "epoch": 2.597590361445783,
      "grad_norm": 0.15554217994213104,
      "learning_rate": 1.4804819277108436e-05,
      "loss": 0.0292,
      "step": 21560
    },
    {
      "epoch": 2.5987951807228917,
      "grad_norm": 0.05116426572203636,
      "learning_rate": 1.4802409638554217e-05,
      "loss": 0.0771,
      "step": 21570
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.1896691918373108,
      "learning_rate": 1.48e-05,
      "loss": 0.0189,
      "step": 21580
    },
    {
      "epoch": 2.6012048192771084,
      "grad_norm": 0.022059405222535133,
      "learning_rate": 1.4797590361445784e-05,
      "loss": 0.0622,
      "step": 21590
    },
    {
      "epoch": 2.602409638554217,
      "grad_norm": 0.0329371802508831,
      "learning_rate": 1.4795180722891567e-05,
      "loss": 0.0682,
      "step": 21600
    },
    {
      "epoch": 2.603614457831325,
      "grad_norm": 0.21524617075920105,
      "learning_rate": 1.479277108433735e-05,
      "loss": 0.004,
      "step": 21610
    },
    {
      "epoch": 2.604819277108434,
      "grad_norm": 0.2800459861755371,
      "learning_rate": 1.4790361445783135e-05,
      "loss": 0.0065,
      "step": 21620
    },
    {
      "epoch": 2.6060240963855423,
      "grad_norm": 8.867964744567871,
      "learning_rate": 1.4787951807228918e-05,
      "loss": 0.082,
      "step": 21630
    },
    {
      "epoch": 2.6072289156626507,
      "grad_norm": 0.015823980793356895,
      "learning_rate": 1.47855421686747e-05,
      "loss": 0.0419,
      "step": 21640
    },
    {
      "epoch": 2.608433734939759,
      "grad_norm": 0.7276479601860046,
      "learning_rate": 1.4783132530120483e-05,
      "loss": 0.0408,
      "step": 21650
    },
    {
      "epoch": 2.6096385542168674,
      "grad_norm": 0.03132898360490799,
      "learning_rate": 1.4780722891566266e-05,
      "loss": 0.088,
      "step": 21660
    },
    {
      "epoch": 2.6108433734939758,
      "grad_norm": 0.8777270317077637,
      "learning_rate": 1.477831325301205e-05,
      "loss": 0.0755,
      "step": 21670
    },
    {
      "epoch": 2.612048192771084,
      "grad_norm": 0.06727586686611176,
      "learning_rate": 1.4775903614457832e-05,
      "loss": 0.0339,
      "step": 21680
    },
    {
      "epoch": 2.613253012048193,
      "grad_norm": 12.29853630065918,
      "learning_rate": 1.4773493975903617e-05,
      "loss": 0.0885,
      "step": 21690
    },
    {
      "epoch": 2.6144578313253013,
      "grad_norm": 0.1524895876646042,
      "learning_rate": 1.4771084337349399e-05,
      "loss": 0.0379,
      "step": 21700
    },
    {
      "epoch": 2.6156626506024097,
      "grad_norm": 3.838934898376465,
      "learning_rate": 1.4768674698795182e-05,
      "loss": 0.0616,
      "step": 21710
    },
    {
      "epoch": 2.616867469879518,
      "grad_norm": 4.448659896850586,
      "learning_rate": 1.4766265060240965e-05,
      "loss": 0.0876,
      "step": 21720
    },
    {
      "epoch": 2.6180722891566264,
      "grad_norm": 5.223979949951172,
      "learning_rate": 1.4763855421686748e-05,
      "loss": 0.0429,
      "step": 21730
    },
    {
      "epoch": 2.619277108433735,
      "grad_norm": 1.2436540126800537,
      "learning_rate": 1.4761445783132531e-05,
      "loss": 0.0675,
      "step": 21740
    },
    {
      "epoch": 2.6204819277108435,
      "grad_norm": 0.015485906042158604,
      "learning_rate": 1.4759036144578313e-05,
      "loss": 0.036,
      "step": 21750
    },
    {
      "epoch": 2.621686746987952,
      "grad_norm": 13.61892318725586,
      "learning_rate": 1.4756626506024096e-05,
      "loss": 0.0065,
      "step": 21760
    },
    {
      "epoch": 2.6228915662650603,
      "grad_norm": 0.32608410716056824,
      "learning_rate": 1.4754216867469881e-05,
      "loss": 0.0342,
      "step": 21770
    },
    {
      "epoch": 2.6240963855421686,
      "grad_norm": 3.016308546066284,
      "learning_rate": 1.4751807228915664e-05,
      "loss": 0.0636,
      "step": 21780
    },
    {
      "epoch": 2.625301204819277,
      "grad_norm": 2.1222779750823975,
      "learning_rate": 1.4749397590361447e-05,
      "loss": 0.096,
      "step": 21790
    },
    {
      "epoch": 2.6265060240963853,
      "grad_norm": 5.112829685211182,
      "learning_rate": 1.474698795180723e-05,
      "loss": 0.034,
      "step": 21800
    },
    {
      "epoch": 2.627710843373494,
      "grad_norm": 1.4324328899383545,
      "learning_rate": 1.4744578313253014e-05,
      "loss": 0.0166,
      "step": 21810
    },
    {
      "epoch": 2.6289156626506025,
      "grad_norm": 8.466176986694336,
      "learning_rate": 1.4742168674698795e-05,
      "loss": 0.0666,
      "step": 21820
    },
    {
      "epoch": 2.630120481927711,
      "grad_norm": 0.22986936569213867,
      "learning_rate": 1.4739759036144578e-05,
      "loss": 0.0577,
      "step": 21830
    },
    {
      "epoch": 2.6313253012048192,
      "grad_norm": 0.8371657729148865,
      "learning_rate": 1.4737349397590363e-05,
      "loss": 0.0771,
      "step": 21840
    },
    {
      "epoch": 2.6325301204819276,
      "grad_norm": 0.6151735782623291,
      "learning_rate": 1.4734939759036146e-05,
      "loss": 0.027,
      "step": 21850
    },
    {
      "epoch": 2.6337349397590364,
      "grad_norm": 0.19270645081996918,
      "learning_rate": 1.473253012048193e-05,
      "loss": 0.0208,
      "step": 21860
    },
    {
      "epoch": 2.6349397590361443,
      "grad_norm": 1.066215991973877,
      "learning_rate": 1.4730120481927713e-05,
      "loss": 0.0095,
      "step": 21870
    },
    {
      "epoch": 2.636144578313253,
      "grad_norm": 0.02120097167789936,
      "learning_rate": 1.4727710843373494e-05,
      "loss": 0.0183,
      "step": 21880
    },
    {
      "epoch": 2.6373493975903615,
      "grad_norm": 0.28432509303092957,
      "learning_rate": 1.4725301204819277e-05,
      "loss": 0.1018,
      "step": 21890
    },
    {
      "epoch": 2.63855421686747,
      "grad_norm": 0.026497812941670418,
      "learning_rate": 1.472289156626506e-05,
      "loss": 0.0785,
      "step": 21900
    },
    {
      "epoch": 2.639759036144578,
      "grad_norm": 8.26529312133789,
      "learning_rate": 1.4720481927710844e-05,
      "loss": 0.0222,
      "step": 21910
    },
    {
      "epoch": 2.6409638554216865,
      "grad_norm": 0.286227822303772,
      "learning_rate": 1.4718072289156629e-05,
      "loss": 0.0523,
      "step": 21920
    },
    {
      "epoch": 2.6421686746987953,
      "grad_norm": 0.10807635635137558,
      "learning_rate": 1.4715662650602412e-05,
      "loss": 0.0689,
      "step": 21930
    },
    {
      "epoch": 2.6433734939759037,
      "grad_norm": 9.857189178466797,
      "learning_rate": 1.4713253012048195e-05,
      "loss": 0.0727,
      "step": 21940
    },
    {
      "epoch": 2.644578313253012,
      "grad_norm": 0.7970353364944458,
      "learning_rate": 1.4710843373493976e-05,
      "loss": 0.0336,
      "step": 21950
    },
    {
      "epoch": 2.6457831325301204,
      "grad_norm": 0.05487591400742531,
      "learning_rate": 1.470843373493976e-05,
      "loss": 0.0294,
      "step": 21960
    },
    {
      "epoch": 2.646987951807229,
      "grad_norm": 0.47659048438072205,
      "learning_rate": 1.4706024096385543e-05,
      "loss": 0.0274,
      "step": 21970
    },
    {
      "epoch": 2.6481927710843376,
      "grad_norm": 0.49984443187713623,
      "learning_rate": 1.4703614457831326e-05,
      "loss": 0.0952,
      "step": 21980
    },
    {
      "epoch": 2.6493975903614455,
      "grad_norm": 0.04478451982140541,
      "learning_rate": 1.470120481927711e-05,
      "loss": 0.0344,
      "step": 21990
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 1.4902153015136719,
      "learning_rate": 1.4698795180722894e-05,
      "loss": 0.0877,
      "step": 22000
    },
    {
      "epoch": 2.6518072289156627,
      "grad_norm": 0.029939880594611168,
      "learning_rate": 1.4696385542168675e-05,
      "loss": 0.0104,
      "step": 22010
    },
    {
      "epoch": 2.653012048192771,
      "grad_norm": 0.17124997079372406,
      "learning_rate": 1.4693975903614459e-05,
      "loss": 0.0482,
      "step": 22020
    },
    {
      "epoch": 2.6542168674698794,
      "grad_norm": 0.1103091761469841,
      "learning_rate": 1.4691566265060242e-05,
      "loss": 0.0296,
      "step": 22030
    },
    {
      "epoch": 2.6554216867469878,
      "grad_norm": 3.6772232055664062,
      "learning_rate": 1.4689156626506025e-05,
      "loss": 0.0375,
      "step": 22040
    },
    {
      "epoch": 2.6566265060240966,
      "grad_norm": 0.657996416091919,
      "learning_rate": 1.4686746987951808e-05,
      "loss": 0.0613,
      "step": 22050
    },
    {
      "epoch": 2.657831325301205,
      "grad_norm": 0.17493703961372375,
      "learning_rate": 1.468433734939759e-05,
      "loss": 0.008,
      "step": 22060
    },
    {
      "epoch": 2.6590361445783133,
      "grad_norm": 5.165524005889893,
      "learning_rate": 1.4681927710843376e-05,
      "loss": 0.0532,
      "step": 22070
    },
    {
      "epoch": 2.6602409638554216,
      "grad_norm": 0.012546725571155548,
      "learning_rate": 1.4679518072289158e-05,
      "loss": 0.0824,
      "step": 22080
    },
    {
      "epoch": 2.66144578313253,
      "grad_norm": 0.22044511139392853,
      "learning_rate": 1.4677108433734941e-05,
      "loss": 0.0282,
      "step": 22090
    },
    {
      "epoch": 2.662650602409639,
      "grad_norm": 0.17200712859630585,
      "learning_rate": 1.4674698795180724e-05,
      "loss": 0.037,
      "step": 22100
    },
    {
      "epoch": 2.6638554216867467,
      "grad_norm": 0.24446964263916016,
      "learning_rate": 1.4672289156626507e-05,
      "loss": 0.0606,
      "step": 22110
    },
    {
      "epoch": 2.6650602409638555,
      "grad_norm": 47.00817108154297,
      "learning_rate": 1.466987951807229e-05,
      "loss": 0.0523,
      "step": 22120
    },
    {
      "epoch": 2.666265060240964,
      "grad_norm": 0.01894351840019226,
      "learning_rate": 1.4667469879518072e-05,
      "loss": 0.0671,
      "step": 22130
    },
    {
      "epoch": 2.6674698795180722,
      "grad_norm": 0.2990218698978424,
      "learning_rate": 1.4665060240963857e-05,
      "loss": 0.0606,
      "step": 22140
    },
    {
      "epoch": 2.6686746987951806,
      "grad_norm": 1.8456871509552002,
      "learning_rate": 1.466265060240964e-05,
      "loss": 0.0956,
      "step": 22150
    },
    {
      "epoch": 2.669879518072289,
      "grad_norm": 0.682935357093811,
      "learning_rate": 1.4660240963855423e-05,
      "loss": 0.0143,
      "step": 22160
    },
    {
      "epoch": 2.6710843373493978,
      "grad_norm": 0.05910932645201683,
      "learning_rate": 1.4657831325301206e-05,
      "loss": 0.0247,
      "step": 22170
    },
    {
      "epoch": 2.672289156626506,
      "grad_norm": 0.6179677844047546,
      "learning_rate": 1.465542168674699e-05,
      "loss": 0.101,
      "step": 22180
    },
    {
      "epoch": 2.6734939759036145,
      "grad_norm": 0.3191729485988617,
      "learning_rate": 1.4653012048192771e-05,
      "loss": 0.048,
      "step": 22190
    },
    {
      "epoch": 2.674698795180723,
      "grad_norm": 0.21317774057388306,
      "learning_rate": 1.4650602409638554e-05,
      "loss": 0.0245,
      "step": 22200
    },
    {
      "epoch": 2.675903614457831,
      "grad_norm": 0.0829298198223114,
      "learning_rate": 1.4648192771084337e-05,
      "loss": 0.0494,
      "step": 22210
    },
    {
      "epoch": 2.67710843373494,
      "grad_norm": 0.03714947775006294,
      "learning_rate": 1.4645783132530122e-05,
      "loss": 0.0486,
      "step": 22220
    },
    {
      "epoch": 2.678313253012048,
      "grad_norm": 0.2933878004550934,
      "learning_rate": 1.4643373493975905e-05,
      "loss": 0.0068,
      "step": 22230
    },
    {
      "epoch": 2.6795180722891567,
      "grad_norm": 0.23918791115283966,
      "learning_rate": 1.4640963855421689e-05,
      "loss": 0.0629,
      "step": 22240
    },
    {
      "epoch": 2.680722891566265,
      "grad_norm": 0.0614861436188221,
      "learning_rate": 1.4638554216867472e-05,
      "loss": 0.023,
      "step": 22250
    },
    {
      "epoch": 2.6819277108433734,
      "grad_norm": 0.32742488384246826,
      "learning_rate": 1.4636144578313253e-05,
      "loss": 0.0287,
      "step": 22260
    },
    {
      "epoch": 2.683132530120482,
      "grad_norm": 5.154215335845947,
      "learning_rate": 1.4633734939759036e-05,
      "loss": 0.0906,
      "step": 22270
    },
    {
      "epoch": 2.68433734939759,
      "grad_norm": 0.032722655683755875,
      "learning_rate": 1.463132530120482e-05,
      "loss": 0.0234,
      "step": 22280
    },
    {
      "epoch": 2.685542168674699,
      "grad_norm": 0.2900610864162445,
      "learning_rate": 1.4628915662650604e-05,
      "loss": 0.0611,
      "step": 22290
    },
    {
      "epoch": 2.6867469879518073,
      "grad_norm": 1.4462264776229858,
      "learning_rate": 1.4626506024096388e-05,
      "loss": 0.1079,
      "step": 22300
    },
    {
      "epoch": 2.6879518072289157,
      "grad_norm": 6.948245048522949,
      "learning_rate": 1.462409638554217e-05,
      "loss": 0.0644,
      "step": 22310
    },
    {
      "epoch": 2.689156626506024,
      "grad_norm": 0.20473888516426086,
      "learning_rate": 1.4621686746987954e-05,
      "loss": 0.016,
      "step": 22320
    },
    {
      "epoch": 2.6903614457831324,
      "grad_norm": 6.3220367431640625,
      "learning_rate": 1.4619277108433735e-05,
      "loss": 0.0546,
      "step": 22330
    },
    {
      "epoch": 2.691566265060241,
      "grad_norm": 0.08207624405622482,
      "learning_rate": 1.4616867469879519e-05,
      "loss": 0.0448,
      "step": 22340
    },
    {
      "epoch": 2.692771084337349,
      "grad_norm": 0.04761570692062378,
      "learning_rate": 1.4614457831325302e-05,
      "loss": 0.0217,
      "step": 22350
    },
    {
      "epoch": 2.693975903614458,
      "grad_norm": 3.7953734397888184,
      "learning_rate": 1.4612048192771085e-05,
      "loss": 0.0716,
      "step": 22360
    },
    {
      "epoch": 2.6951807228915663,
      "grad_norm": 0.23403142392635345,
      "learning_rate": 1.460963855421687e-05,
      "loss": 0.0104,
      "step": 22370
    },
    {
      "epoch": 2.6963855421686747,
      "grad_norm": 0.051204171031713486,
      "learning_rate": 1.4607228915662653e-05,
      "loss": 0.0641,
      "step": 22380
    },
    {
      "epoch": 2.697590361445783,
      "grad_norm": 15.581013679504395,
      "learning_rate": 1.4604819277108434e-05,
      "loss": 0.0801,
      "step": 22390
    },
    {
      "epoch": 2.6987951807228914,
      "grad_norm": 7.0654215812683105,
      "learning_rate": 1.4602409638554218e-05,
      "loss": 0.0493,
      "step": 22400
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.11971928924322128,
      "learning_rate": 1.46e-05,
      "loss": 0.0043,
      "step": 22410
    },
    {
      "epoch": 2.7012048192771085,
      "grad_norm": 2.258822441101074,
      "learning_rate": 1.4597590361445784e-05,
      "loss": 0.058,
      "step": 22420
    },
    {
      "epoch": 2.702409638554217,
      "grad_norm": 0.15940351784229279,
      "learning_rate": 1.4595180722891567e-05,
      "loss": 0.0119,
      "step": 22430
    },
    {
      "epoch": 2.7036144578313253,
      "grad_norm": 2.835402488708496,
      "learning_rate": 1.4592771084337352e-05,
      "loss": 0.0441,
      "step": 22440
    },
    {
      "epoch": 2.7048192771084336,
      "grad_norm": 5.19471549987793,
      "learning_rate": 1.4590361445783135e-05,
      "loss": 0.0662,
      "step": 22450
    },
    {
      "epoch": 2.7060240963855424,
      "grad_norm": 0.02860335446894169,
      "learning_rate": 1.4587951807228917e-05,
      "loss": 0.0317,
      "step": 22460
    },
    {
      "epoch": 2.7072289156626503,
      "grad_norm": 0.0784989669919014,
      "learning_rate": 1.45855421686747e-05,
      "loss": 0.0301,
      "step": 22470
    },
    {
      "epoch": 2.708433734939759,
      "grad_norm": 0.2969205379486084,
      "learning_rate": 1.4583132530120483e-05,
      "loss": 0.0174,
      "step": 22480
    },
    {
      "epoch": 2.7096385542168675,
      "grad_norm": 5.902678966522217,
      "learning_rate": 1.4580722891566266e-05,
      "loss": 0.0772,
      "step": 22490
    },
    {
      "epoch": 2.710843373493976,
      "grad_norm": 0.07329554110765457,
      "learning_rate": 1.457831325301205e-05,
      "loss": 0.0205,
      "step": 22500
    },
    {
      "epoch": 2.712048192771084,
      "grad_norm": 0.021697767078876495,
      "learning_rate": 1.4575903614457831e-05,
      "loss": 0.0516,
      "step": 22510
    },
    {
      "epoch": 2.7132530120481926,
      "grad_norm": 0.1612333506345749,
      "learning_rate": 1.4573493975903616e-05,
      "loss": 0.0574,
      "step": 22520
    },
    {
      "epoch": 2.7144578313253014,
      "grad_norm": 22.738649368286133,
      "learning_rate": 1.4571084337349399e-05,
      "loss": 0.0556,
      "step": 22530
    },
    {
      "epoch": 2.7156626506024097,
      "grad_norm": 0.043470751494169235,
      "learning_rate": 1.4568674698795182e-05,
      "loss": 0.0384,
      "step": 22540
    },
    {
      "epoch": 2.716867469879518,
      "grad_norm": 2.2198429107666016,
      "learning_rate": 1.4566265060240965e-05,
      "loss": 0.0547,
      "step": 22550
    },
    {
      "epoch": 2.7180722891566265,
      "grad_norm": 2.199394464492798,
      "learning_rate": 1.4563855421686748e-05,
      "loss": 0.0522,
      "step": 22560
    },
    {
      "epoch": 2.719277108433735,
      "grad_norm": 5.272581100463867,
      "learning_rate": 1.456144578313253e-05,
      "loss": 0.0633,
      "step": 22570
    },
    {
      "epoch": 2.7204819277108436,
      "grad_norm": 0.11572658270597458,
      "learning_rate": 1.4559036144578313e-05,
      "loss": 0.0432,
      "step": 22580
    },
    {
      "epoch": 2.7216867469879515,
      "grad_norm": 0.8160967826843262,
      "learning_rate": 1.4556626506024098e-05,
      "loss": 0.1074,
      "step": 22590
    },
    {
      "epoch": 2.7228915662650603,
      "grad_norm": 46.07891082763672,
      "learning_rate": 1.4554216867469881e-05,
      "loss": 0.1052,
      "step": 22600
    },
    {
      "epoch": 2.7240963855421687,
      "grad_norm": 0.6506930589675903,
      "learning_rate": 1.4551807228915664e-05,
      "loss": 0.0378,
      "step": 22610
    },
    {
      "epoch": 2.725301204819277,
      "grad_norm": 0.34767523407936096,
      "learning_rate": 1.4549397590361448e-05,
      "loss": 0.0576,
      "step": 22620
    },
    {
      "epoch": 2.7265060240963854,
      "grad_norm": 2.4465012550354004,
      "learning_rate": 1.454698795180723e-05,
      "loss": 0.0675,
      "step": 22630
    },
    {
      "epoch": 2.727710843373494,
      "grad_norm": 0.7854726910591125,
      "learning_rate": 1.4544578313253012e-05,
      "loss": 0.0372,
      "step": 22640
    },
    {
      "epoch": 2.7289156626506026,
      "grad_norm": 18.7994384765625,
      "learning_rate": 1.4542168674698795e-05,
      "loss": 0.018,
      "step": 22650
    },
    {
      "epoch": 2.730120481927711,
      "grad_norm": 1.695241928100586,
      "learning_rate": 1.4539759036144579e-05,
      "loss": 0.0219,
      "step": 22660
    },
    {
      "epoch": 2.7313253012048193,
      "grad_norm": 0.03503171727061272,
      "learning_rate": 1.4537349397590363e-05,
      "loss": 0.0349,
      "step": 22670
    },
    {
      "epoch": 2.7325301204819277,
      "grad_norm": 1.9470421075820923,
      "learning_rate": 1.4534939759036147e-05,
      "loss": 0.0286,
      "step": 22680
    },
    {
      "epoch": 2.733734939759036,
      "grad_norm": 6.596729278564453,
      "learning_rate": 1.453253012048193e-05,
      "loss": 0.0813,
      "step": 22690
    },
    {
      "epoch": 2.734939759036145,
      "grad_norm": 0.7483278512954712,
      "learning_rate": 1.4530120481927711e-05,
      "loss": 0.0205,
      "step": 22700
    },
    {
      "epoch": 2.7361445783132528,
      "grad_norm": 2.5221498012542725,
      "learning_rate": 1.4527710843373494e-05,
      "loss": 0.0466,
      "step": 22710
    },
    {
      "epoch": 2.7373493975903616,
      "grad_norm": 0.04934035241603851,
      "learning_rate": 1.4525301204819278e-05,
      "loss": 0.0496,
      "step": 22720
    },
    {
      "epoch": 2.73855421686747,
      "grad_norm": 0.051023803651332855,
      "learning_rate": 1.452289156626506e-05,
      "loss": 0.0263,
      "step": 22730
    },
    {
      "epoch": 2.7397590361445783,
      "grad_norm": 3.5142972469329834,
      "learning_rate": 1.4520481927710846e-05,
      "loss": 0.0865,
      "step": 22740
    },
    {
      "epoch": 2.7409638554216866,
      "grad_norm": 0.10399793088436127,
      "learning_rate": 1.4518072289156629e-05,
      "loss": 0.0375,
      "step": 22750
    },
    {
      "epoch": 2.742168674698795,
      "grad_norm": 4.589178085327148,
      "learning_rate": 1.4515662650602412e-05,
      "loss": 0.031,
      "step": 22760
    },
    {
      "epoch": 2.743373493975904,
      "grad_norm": 11.590221405029297,
      "learning_rate": 1.4513253012048193e-05,
      "loss": 0.0454,
      "step": 22770
    },
    {
      "epoch": 2.744578313253012,
      "grad_norm": 0.03678114339709282,
      "learning_rate": 1.4510843373493977e-05,
      "loss": 0.0399,
      "step": 22780
    },
    {
      "epoch": 2.7457831325301205,
      "grad_norm": 0.02198714017868042,
      "learning_rate": 1.450843373493976e-05,
      "loss": 0.0688,
      "step": 22790
    },
    {
      "epoch": 2.746987951807229,
      "grad_norm": 2.7645626068115234,
      "learning_rate": 1.4506024096385543e-05,
      "loss": 0.0774,
      "step": 22800
    },
    {
      "epoch": 2.7481927710843372,
      "grad_norm": 20.65812110900879,
      "learning_rate": 1.4503614457831326e-05,
      "loss": 0.0989,
      "step": 22810
    },
    {
      "epoch": 2.749397590361446,
      "grad_norm": 4.542415618896484,
      "learning_rate": 1.4501204819277111e-05,
      "loss": 0.0191,
      "step": 22820
    },
    {
      "epoch": 2.750602409638554,
      "grad_norm": 0.05314751714468002,
      "learning_rate": 1.4498795180722893e-05,
      "loss": 0.0812,
      "step": 22830
    },
    {
      "epoch": 2.7518072289156628,
      "grad_norm": 2.1077523231506348,
      "learning_rate": 1.4496385542168676e-05,
      "loss": 0.0655,
      "step": 22840
    },
    {
      "epoch": 2.753012048192771,
      "grad_norm": 0.2955849766731262,
      "learning_rate": 1.4493975903614459e-05,
      "loss": 0.0531,
      "step": 22850
    },
    {
      "epoch": 2.7542168674698795,
      "grad_norm": 0.2258707582950592,
      "learning_rate": 1.4491566265060242e-05,
      "loss": 0.0152,
      "step": 22860
    },
    {
      "epoch": 2.755421686746988,
      "grad_norm": 0.03571914881467819,
      "learning_rate": 1.4489156626506025e-05,
      "loss": 0.0488,
      "step": 22870
    },
    {
      "epoch": 2.756626506024096,
      "grad_norm": 3.1147749423980713,
      "learning_rate": 1.4486746987951807e-05,
      "loss": 0.0615,
      "step": 22880
    },
    {
      "epoch": 2.757831325301205,
      "grad_norm": 0.05017818510532379,
      "learning_rate": 1.4484337349397593e-05,
      "loss": 0.0068,
      "step": 22890
    },
    {
      "epoch": 2.7590361445783134,
      "grad_norm": 3.053471326828003,
      "learning_rate": 1.4481927710843375e-05,
      "loss": 0.0567,
      "step": 22900
    },
    {
      "epoch": 2.7602409638554217,
      "grad_norm": 0.36579713225364685,
      "learning_rate": 1.4479518072289158e-05,
      "loss": 0.0258,
      "step": 22910
    },
    {
      "epoch": 2.76144578313253,
      "grad_norm": 0.028263574466109276,
      "learning_rate": 1.4477108433734941e-05,
      "loss": 0.0698,
      "step": 22920
    },
    {
      "epoch": 2.7626506024096384,
      "grad_norm": 12.078532218933105,
      "learning_rate": 1.4474698795180724e-05,
      "loss": 0.0404,
      "step": 22930
    },
    {
      "epoch": 2.7638554216867472,
      "grad_norm": 5.177969932556152,
      "learning_rate": 1.4472289156626507e-05,
      "loss": 0.0354,
      "step": 22940
    },
    {
      "epoch": 2.765060240963855,
      "grad_norm": 2.030531883239746,
      "learning_rate": 1.4469879518072289e-05,
      "loss": 0.0137,
      "step": 22950
    },
    {
      "epoch": 2.766265060240964,
      "grad_norm": 2.843874216079712,
      "learning_rate": 1.4467469879518074e-05,
      "loss": 0.0977,
      "step": 22960
    },
    {
      "epoch": 2.7674698795180723,
      "grad_norm": 89.58597564697266,
      "learning_rate": 1.4465060240963857e-05,
      "loss": 0.0395,
      "step": 22970
    },
    {
      "epoch": 2.7686746987951807,
      "grad_norm": 2.8867151737213135,
      "learning_rate": 1.446265060240964e-05,
      "loss": 0.0316,
      "step": 22980
    },
    {
      "epoch": 2.769879518072289,
      "grad_norm": 30.147674560546875,
      "learning_rate": 1.4460240963855423e-05,
      "loss": 0.0047,
      "step": 22990
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 0.05690999701619148,
      "learning_rate": 1.4457831325301207e-05,
      "loss": 0.0083,
      "step": 23000
    },
    {
      "epoch": 2.772289156626506,
      "grad_norm": 0.37001845240592957,
      "learning_rate": 1.4455421686746988e-05,
      "loss": 0.0938,
      "step": 23010
    },
    {
      "epoch": 2.7734939759036146,
      "grad_norm": 5.652719497680664,
      "learning_rate": 1.4453012048192771e-05,
      "loss": 0.043,
      "step": 23020
    },
    {
      "epoch": 2.774698795180723,
      "grad_norm": 2.587346315383911,
      "learning_rate": 1.4450602409638554e-05,
      "loss": 0.0784,
      "step": 23030
    },
    {
      "epoch": 2.7759036144578313,
      "grad_norm": 0.27555030584335327,
      "learning_rate": 1.444819277108434e-05,
      "loss": 0.0568,
      "step": 23040
    },
    {
      "epoch": 2.7771084337349397,
      "grad_norm": 5.883746147155762,
      "learning_rate": 1.4445783132530122e-05,
      "loss": 0.0845,
      "step": 23050
    },
    {
      "epoch": 2.7783132530120485,
      "grad_norm": 1.305055022239685,
      "learning_rate": 1.4443373493975906e-05,
      "loss": 0.0371,
      "step": 23060
    },
    {
      "epoch": 2.7795180722891564,
      "grad_norm": 0.08351645618677139,
      "learning_rate": 1.4440963855421689e-05,
      "loss": 0.0306,
      "step": 23070
    },
    {
      "epoch": 2.780722891566265,
      "grad_norm": 12.115549087524414,
      "learning_rate": 1.443855421686747e-05,
      "loss": 0.076,
      "step": 23080
    },
    {
      "epoch": 2.7819277108433735,
      "grad_norm": 0.05737616866827011,
      "learning_rate": 1.4436144578313253e-05,
      "loss": 0.0385,
      "step": 23090
    },
    {
      "epoch": 2.783132530120482,
      "grad_norm": 0.27470821142196655,
      "learning_rate": 1.4433734939759037e-05,
      "loss": 0.0319,
      "step": 23100
    },
    {
      "epoch": 2.7843373493975903,
      "grad_norm": 0.2980644404888153,
      "learning_rate": 1.4431325301204821e-05,
      "loss": 0.0235,
      "step": 23110
    },
    {
      "epoch": 2.7855421686746986,
      "grad_norm": 0.3953651189804077,
      "learning_rate": 1.4428915662650605e-05,
      "loss": 0.0353,
      "step": 23120
    },
    {
      "epoch": 2.7867469879518074,
      "grad_norm": 1.5209810733795166,
      "learning_rate": 1.4426506024096388e-05,
      "loss": 0.0968,
      "step": 23130
    },
    {
      "epoch": 2.787951807228916,
      "grad_norm": 0.07259204238653183,
      "learning_rate": 1.442409638554217e-05,
      "loss": 0.0084,
      "step": 23140
    },
    {
      "epoch": 2.789156626506024,
      "grad_norm": 0.02623249590396881,
      "learning_rate": 1.4421686746987952e-05,
      "loss": 0.0806,
      "step": 23150
    },
    {
      "epoch": 2.7903614457831325,
      "grad_norm": 0.030539603903889656,
      "learning_rate": 1.4419277108433736e-05,
      "loss": 0.0041,
      "step": 23160
    },
    {
      "epoch": 2.791566265060241,
      "grad_norm": 1.391992449760437,
      "learning_rate": 1.4416867469879519e-05,
      "loss": 0.0733,
      "step": 23170
    },
    {
      "epoch": 2.7927710843373497,
      "grad_norm": 0.04690292477607727,
      "learning_rate": 1.4414457831325302e-05,
      "loss": 0.0099,
      "step": 23180
    },
    {
      "epoch": 2.7939759036144576,
      "grad_norm": 0.06829889863729477,
      "learning_rate": 1.4412048192771087e-05,
      "loss": 0.0139,
      "step": 23190
    },
    {
      "epoch": 2.7951807228915664,
      "grad_norm": 0.0580250583589077,
      "learning_rate": 1.440963855421687e-05,
      "loss": 0.0014,
      "step": 23200
    },
    {
      "epoch": 2.7963855421686747,
      "grad_norm": 0.015933144837617874,
      "learning_rate": 1.4407228915662652e-05,
      "loss": 0.0554,
      "step": 23210
    },
    {
      "epoch": 2.797590361445783,
      "grad_norm": 1.1034046411514282,
      "learning_rate": 1.4404819277108435e-05,
      "loss": 0.0165,
      "step": 23220
    },
    {
      "epoch": 2.7987951807228915,
      "grad_norm": 0.023496823385357857,
      "learning_rate": 1.4402409638554218e-05,
      "loss": 0.0504,
      "step": 23230
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.010064027272164822,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0594,
      "step": 23240
    },
    {
      "epoch": 2.8012048192771086,
      "grad_norm": 0.15869814157485962,
      "learning_rate": 1.4397590361445784e-05,
      "loss": 0.0441,
      "step": 23250
    },
    {
      "epoch": 2.802409638554217,
      "grad_norm": 1.9988113641738892,
      "learning_rate": 1.4395180722891569e-05,
      "loss": 0.0416,
      "step": 23260
    },
    {
      "epoch": 2.8036144578313253,
      "grad_norm": 35.55137252807617,
      "learning_rate": 1.439277108433735e-05,
      "loss": 0.0742,
      "step": 23270
    },
    {
      "epoch": 2.8048192771084337,
      "grad_norm": 3.989672899246216,
      "learning_rate": 1.4390361445783134e-05,
      "loss": 0.0408,
      "step": 23280
    },
    {
      "epoch": 2.806024096385542,
      "grad_norm": 0.29285165667533875,
      "learning_rate": 1.4387951807228917e-05,
      "loss": 0.04,
      "step": 23290
    },
    {
      "epoch": 2.807228915662651,
      "grad_norm": 55.718223571777344,
      "learning_rate": 1.43855421686747e-05,
      "loss": 0.0553,
      "step": 23300
    },
    {
      "epoch": 2.808433734939759,
      "grad_norm": 5.793170928955078,
      "learning_rate": 1.4383132530120483e-05,
      "loss": 0.0386,
      "step": 23310
    },
    {
      "epoch": 2.8096385542168676,
      "grad_norm": 2.8139426708221436,
      "learning_rate": 1.4380722891566265e-05,
      "loss": 0.0106,
      "step": 23320
    },
    {
      "epoch": 2.810843373493976,
      "grad_norm": 0.1362883299589157,
      "learning_rate": 1.4378313253012048e-05,
      "loss": 0.0231,
      "step": 23330
    },
    {
      "epoch": 2.8120481927710843,
      "grad_norm": 0.005700970068573952,
      "learning_rate": 1.4375903614457833e-05,
      "loss": 0.0401,
      "step": 23340
    },
    {
      "epoch": 2.8132530120481927,
      "grad_norm": 2.3071610927581787,
      "learning_rate": 1.4373493975903616e-05,
      "loss": 0.1188,
      "step": 23350
    },
    {
      "epoch": 2.814457831325301,
      "grad_norm": 2.460867404937744,
      "learning_rate": 1.43710843373494e-05,
      "loss": 0.0396,
      "step": 23360
    },
    {
      "epoch": 2.81566265060241,
      "grad_norm": 7.3605875968933105,
      "learning_rate": 1.4368674698795182e-05,
      "loss": 0.065,
      "step": 23370
    },
    {
      "epoch": 2.816867469879518,
      "grad_norm": 0.06676167249679565,
      "learning_rate": 1.4366265060240966e-05,
      "loss": 0.0533,
      "step": 23380
    },
    {
      "epoch": 2.8180722891566266,
      "grad_norm": 0.03327716514468193,
      "learning_rate": 1.4363855421686747e-05,
      "loss": 0.032,
      "step": 23390
    },
    {
      "epoch": 2.819277108433735,
      "grad_norm": 5.891842842102051,
      "learning_rate": 1.436144578313253e-05,
      "loss": 0.057,
      "step": 23400
    },
    {
      "epoch": 2.8204819277108433,
      "grad_norm": 5.803936004638672,
      "learning_rate": 1.4359036144578315e-05,
      "loss": 0.0684,
      "step": 23410
    },
    {
      "epoch": 2.821686746987952,
      "grad_norm": 20.300838470458984,
      "learning_rate": 1.4356626506024098e-05,
      "loss": 0.0494,
      "step": 23420
    },
    {
      "epoch": 2.82289156626506,
      "grad_norm": 15.535959243774414,
      "learning_rate": 1.4354216867469881e-05,
      "loss": 0.0395,
      "step": 23430
    },
    {
      "epoch": 2.824096385542169,
      "grad_norm": 0.01197199895977974,
      "learning_rate": 1.4351807228915665e-05,
      "loss": 0.0142,
      "step": 23440
    },
    {
      "epoch": 2.825301204819277,
      "grad_norm": 0.3918079137802124,
      "learning_rate": 1.4349397590361446e-05,
      "loss": 0.0341,
      "step": 23450
    },
    {
      "epoch": 2.8265060240963855,
      "grad_norm": 0.01552263181656599,
      "learning_rate": 1.434698795180723e-05,
      "loss": 0.021,
      "step": 23460
    },
    {
      "epoch": 2.827710843373494,
      "grad_norm": 16.00086212158203,
      "learning_rate": 1.4344578313253012e-05,
      "loss": 0.062,
      "step": 23470
    },
    {
      "epoch": 2.8289156626506022,
      "grad_norm": 6.8551025390625,
      "learning_rate": 1.4342168674698796e-05,
      "loss": 0.0458,
      "step": 23480
    },
    {
      "epoch": 2.830120481927711,
      "grad_norm": 2.5475144386291504,
      "learning_rate": 1.433975903614458e-05,
      "loss": 0.0418,
      "step": 23490
    },
    {
      "epoch": 2.8313253012048194,
      "grad_norm": 0.21319057047367096,
      "learning_rate": 1.4337349397590364e-05,
      "loss": 0.0336,
      "step": 23500
    },
    {
      "epoch": 2.8325301204819278,
      "grad_norm": 6.342184543609619,
      "learning_rate": 1.4334939759036147e-05,
      "loss": 0.0713,
      "step": 23510
    },
    {
      "epoch": 2.833734939759036,
      "grad_norm": 0.056299854069948196,
      "learning_rate": 1.4332530120481928e-05,
      "loss": 0.0497,
      "step": 23520
    },
    {
      "epoch": 2.8349397590361445,
      "grad_norm": 0.4402448236942291,
      "learning_rate": 1.4330120481927711e-05,
      "loss": 0.0802,
      "step": 23530
    },
    {
      "epoch": 2.8361445783132533,
      "grad_norm": 5.46297025680542,
      "learning_rate": 1.4327710843373495e-05,
      "loss": 0.0524,
      "step": 23540
    },
    {
      "epoch": 2.837349397590361,
      "grad_norm": 0.1250113844871521,
      "learning_rate": 1.4325301204819278e-05,
      "loss": 0.0306,
      "step": 23550
    },
    {
      "epoch": 2.83855421686747,
      "grad_norm": 5.659823894500732,
      "learning_rate": 1.4322891566265063e-05,
      "loss": 0.0721,
      "step": 23560
    },
    {
      "epoch": 2.8397590361445784,
      "grad_norm": 0.10282722860574722,
      "learning_rate": 1.4320481927710846e-05,
      "loss": 0.035,
      "step": 23570
    },
    {
      "epoch": 2.8409638554216867,
      "grad_norm": 0.06021230295300484,
      "learning_rate": 1.4318072289156627e-05,
      "loss": 0.036,
      "step": 23580
    },
    {
      "epoch": 2.842168674698795,
      "grad_norm": 0.04228702560067177,
      "learning_rate": 1.431566265060241e-05,
      "loss": 0.0238,
      "step": 23590
    },
    {
      "epoch": 2.8433734939759034,
      "grad_norm": 0.056852325797080994,
      "learning_rate": 1.4313253012048194e-05,
      "loss": 0.0574,
      "step": 23600
    },
    {
      "epoch": 2.8445783132530122,
      "grad_norm": 0.008288329467177391,
      "learning_rate": 1.4310843373493977e-05,
      "loss": 0.038,
      "step": 23610
    },
    {
      "epoch": 2.8457831325301206,
      "grad_norm": 2.969266891479492,
      "learning_rate": 1.430843373493976e-05,
      "loss": 0.0264,
      "step": 23620
    },
    {
      "epoch": 2.846987951807229,
      "grad_norm": 3.5984883308410645,
      "learning_rate": 1.4306024096385542e-05,
      "loss": 0.0549,
      "step": 23630
    },
    {
      "epoch": 2.8481927710843373,
      "grad_norm": 1.7553421258926392,
      "learning_rate": 1.4303614457831328e-05,
      "loss": 0.0421,
      "step": 23640
    },
    {
      "epoch": 2.8493975903614457,
      "grad_norm": 0.1034146100282669,
      "learning_rate": 1.430120481927711e-05,
      "loss": 0.0349,
      "step": 23650
    },
    {
      "epoch": 2.8506024096385545,
      "grad_norm": 1.740414023399353,
      "learning_rate": 1.4298795180722893e-05,
      "loss": 0.0393,
      "step": 23660
    },
    {
      "epoch": 2.8518072289156624,
      "grad_norm": 5.312432289123535,
      "learning_rate": 1.4296385542168676e-05,
      "loss": 0.0129,
      "step": 23670
    },
    {
      "epoch": 2.853012048192771,
      "grad_norm": 0.5352480411529541,
      "learning_rate": 1.4293975903614459e-05,
      "loss": 0.0616,
      "step": 23680
    },
    {
      "epoch": 2.8542168674698796,
      "grad_norm": 0.0628061592578888,
      "learning_rate": 1.4291566265060242e-05,
      "loss": 0.0651,
      "step": 23690
    },
    {
      "epoch": 2.855421686746988,
      "grad_norm": 0.014741932973265648,
      "learning_rate": 1.4289156626506024e-05,
      "loss": 0.0527,
      "step": 23700
    },
    {
      "epoch": 2.8566265060240963,
      "grad_norm": 0.602465033531189,
      "learning_rate": 1.428674698795181e-05,
      "loss": 0.0311,
      "step": 23710
    },
    {
      "epoch": 2.8578313253012047,
      "grad_norm": 23.778018951416016,
      "learning_rate": 1.4284337349397592e-05,
      "loss": 0.0347,
      "step": 23720
    },
    {
      "epoch": 2.8590361445783135,
      "grad_norm": 0.01980872079730034,
      "learning_rate": 1.4281927710843375e-05,
      "loss": 0.0949,
      "step": 23730
    },
    {
      "epoch": 2.860240963855422,
      "grad_norm": 3.4986512660980225,
      "learning_rate": 1.4279518072289158e-05,
      "loss": 0.0106,
      "step": 23740
    },
    {
      "epoch": 2.86144578313253,
      "grad_norm": 0.03275713324546814,
      "learning_rate": 1.4277108433734941e-05,
      "loss": 0.0562,
      "step": 23750
    },
    {
      "epoch": 2.8626506024096385,
      "grad_norm": 0.15562306344509125,
      "learning_rate": 1.4274698795180725e-05,
      "loss": 0.0961,
      "step": 23760
    },
    {
      "epoch": 2.863855421686747,
      "grad_norm": 0.08941445499658585,
      "learning_rate": 1.4272289156626506e-05,
      "loss": 0.0211,
      "step": 23770
    },
    {
      "epoch": 2.8650602409638557,
      "grad_norm": 0.5252547264099121,
      "learning_rate": 1.426987951807229e-05,
      "loss": 0.0526,
      "step": 23780
    },
    {
      "epoch": 2.8662650602409636,
      "grad_norm": 0.7162113785743713,
      "learning_rate": 1.4267469879518074e-05,
      "loss": 0.0257,
      "step": 23790
    },
    {
      "epoch": 2.8674698795180724,
      "grad_norm": 8.044526100158691,
      "learning_rate": 1.4265060240963857e-05,
      "loss": 0.0825,
      "step": 23800
    },
    {
      "epoch": 2.8686746987951808,
      "grad_norm": 0.011189539916813374,
      "learning_rate": 1.426265060240964e-05,
      "loss": 0.0676,
      "step": 23810
    },
    {
      "epoch": 2.869879518072289,
      "grad_norm": 0.1889381855726242,
      "learning_rate": 1.4260240963855424e-05,
      "loss": 0.0758,
      "step": 23820
    },
    {
      "epoch": 2.8710843373493975,
      "grad_norm": 2.1202383041381836,
      "learning_rate": 1.4257831325301205e-05,
      "loss": 0.0341,
      "step": 23830
    },
    {
      "epoch": 2.872289156626506,
      "grad_norm": 4.866611957550049,
      "learning_rate": 1.4255421686746988e-05,
      "loss": 0.0579,
      "step": 23840
    },
    {
      "epoch": 2.8734939759036147,
      "grad_norm": 2.937533140182495,
      "learning_rate": 1.4253012048192771e-05,
      "loss": 0.027,
      "step": 23850
    },
    {
      "epoch": 2.874698795180723,
      "grad_norm": 0.2620868682861328,
      "learning_rate": 1.4250602409638556e-05,
      "loss": 0.0571,
      "step": 23860
    },
    {
      "epoch": 2.8759036144578314,
      "grad_norm": 0.07711076736450195,
      "learning_rate": 1.424819277108434e-05,
      "loss": 0.0192,
      "step": 23870
    },
    {
      "epoch": 2.8771084337349397,
      "grad_norm": 10.631831169128418,
      "learning_rate": 1.4245783132530123e-05,
      "loss": 0.0477,
      "step": 23880
    },
    {
      "epoch": 2.878313253012048,
      "grad_norm": 7.472086429595947,
      "learning_rate": 1.4243373493975906e-05,
      "loss": 0.0656,
      "step": 23890
    },
    {
      "epoch": 2.8795180722891565,
      "grad_norm": 65.0141830444336,
      "learning_rate": 1.4240963855421687e-05,
      "loss": 0.0431,
      "step": 23900
    },
    {
      "epoch": 2.880722891566265,
      "grad_norm": 0.44517460465431213,
      "learning_rate": 1.423855421686747e-05,
      "loss": 0.0162,
      "step": 23910
    },
    {
      "epoch": 2.8819277108433736,
      "grad_norm": 0.12495572119951248,
      "learning_rate": 1.4236144578313254e-05,
      "loss": 0.0148,
      "step": 23920
    },
    {
      "epoch": 2.883132530120482,
      "grad_norm": 0.07176974415779114,
      "learning_rate": 1.4233734939759037e-05,
      "loss": 0.0691,
      "step": 23930
    },
    {
      "epoch": 2.8843373493975903,
      "grad_norm": 0.9450897574424744,
      "learning_rate": 1.4231325301204822e-05,
      "loss": 0.0545,
      "step": 23940
    },
    {
      "epoch": 2.8855421686746987,
      "grad_norm": 2.978152275085449,
      "learning_rate": 1.4228915662650605e-05,
      "loss": 0.0629,
      "step": 23950
    },
    {
      "epoch": 2.886746987951807,
      "grad_norm": 0.5473992228507996,
      "learning_rate": 1.4226506024096386e-05,
      "loss": 0.0523,
      "step": 23960
    },
    {
      "epoch": 2.887951807228916,
      "grad_norm": 0.07261909544467926,
      "learning_rate": 1.422409638554217e-05,
      "loss": 0.0748,
      "step": 23970
    },
    {
      "epoch": 2.8891566265060242,
      "grad_norm": 55.66866683959961,
      "learning_rate": 1.4221686746987953e-05,
      "loss": 0.0645,
      "step": 23980
    },
    {
      "epoch": 2.8903614457831326,
      "grad_norm": 2.315481424331665,
      "learning_rate": 1.4219277108433736e-05,
      "loss": 0.0323,
      "step": 23990
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 0.00792054831981659,
      "learning_rate": 1.4216867469879519e-05,
      "loss": 0.0162,
      "step": 24000
    },
    {
      "epoch": 2.8927710843373493,
      "grad_norm": 0.056557320058345795,
      "learning_rate": 1.4214457831325304e-05,
      "loss": 0.0388,
      "step": 24010
    },
    {
      "epoch": 2.8939759036144577,
      "grad_norm": 6.056278705596924,
      "learning_rate": 1.4212048192771087e-05,
      "loss": 0.098,
      "step": 24020
    },
    {
      "epoch": 2.895180722891566,
      "grad_norm": 5.77750301361084,
      "learning_rate": 1.4209638554216869e-05,
      "loss": 0.047,
      "step": 24030
    },
    {
      "epoch": 2.896385542168675,
      "grad_norm": 10.669522285461426,
      "learning_rate": 1.4207228915662652e-05,
      "loss": 0.1076,
      "step": 24040
    },
    {
      "epoch": 2.897590361445783,
      "grad_norm": 10.39242935180664,
      "learning_rate": 1.4204819277108435e-05,
      "loss": 0.0623,
      "step": 24050
    },
    {
      "epoch": 2.8987951807228916,
      "grad_norm": 2.526010751724243,
      "learning_rate": 1.4202409638554218e-05,
      "loss": 0.0501,
      "step": 24060
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.245368242263794,
      "learning_rate": 1.4200000000000001e-05,
      "loss": 0.0244,
      "step": 24070
    },
    {
      "epoch": 2.9012048192771083,
      "grad_norm": 0.4105677902698517,
      "learning_rate": 1.4197590361445783e-05,
      "loss": 0.0287,
      "step": 24080
    },
    {
      "epoch": 2.902409638554217,
      "grad_norm": 0.021091733127832413,
      "learning_rate": 1.4195180722891568e-05,
      "loss": 0.0071,
      "step": 24090
    },
    {
      "epoch": 2.9036144578313254,
      "grad_norm": 0.015911765396595,
      "learning_rate": 1.419277108433735e-05,
      "loss": 0.0039,
      "step": 24100
    },
    {
      "epoch": 2.904819277108434,
      "grad_norm": 1.1147300004959106,
      "learning_rate": 1.4190361445783134e-05,
      "loss": 0.0267,
      "step": 24110
    },
    {
      "epoch": 2.906024096385542,
      "grad_norm": 0.258862167596817,
      "learning_rate": 1.4187951807228917e-05,
      "loss": 0.0337,
      "step": 24120
    },
    {
      "epoch": 2.9072289156626505,
      "grad_norm": 17.26228141784668,
      "learning_rate": 1.41855421686747e-05,
      "loss": 0.0311,
      "step": 24130
    },
    {
      "epoch": 2.908433734939759,
      "grad_norm": 0.015828482806682587,
      "learning_rate": 1.4183132530120482e-05,
      "loss": 0.0035,
      "step": 24140
    },
    {
      "epoch": 2.9096385542168672,
      "grad_norm": 0.028226008638739586,
      "learning_rate": 1.4180722891566265e-05,
      "loss": 0.016,
      "step": 24150
    },
    {
      "epoch": 2.910843373493976,
      "grad_norm": 0.3141331076622009,
      "learning_rate": 1.417831325301205e-05,
      "loss": 0.0376,
      "step": 24160
    },
    {
      "epoch": 2.9120481927710844,
      "grad_norm": 0.06336624175310135,
      "learning_rate": 1.4175903614457833e-05,
      "loss": 0.0125,
      "step": 24170
    },
    {
      "epoch": 2.9132530120481928,
      "grad_norm": 0.04152505472302437,
      "learning_rate": 1.4173493975903616e-05,
      "loss": 0.0111,
      "step": 24180
    },
    {
      "epoch": 2.914457831325301,
      "grad_norm": 0.005023807752877474,
      "learning_rate": 1.41710843373494e-05,
      "loss": 0.0405,
      "step": 24190
    },
    {
      "epoch": 2.9156626506024095,
      "grad_norm": 0.046181388199329376,
      "learning_rate": 1.4168674698795183e-05,
      "loss": 0.0307,
      "step": 24200
    },
    {
      "epoch": 2.9168674698795183,
      "grad_norm": 0.005005999933928251,
      "learning_rate": 1.4166265060240964e-05,
      "loss": 0.0368,
      "step": 24210
    },
    {
      "epoch": 2.9180722891566266,
      "grad_norm": 0.005774094257503748,
      "learning_rate": 1.4163855421686747e-05,
      "loss": 0.0413,
      "step": 24220
    },
    {
      "epoch": 2.919277108433735,
      "grad_norm": 9.003377914428711,
      "learning_rate": 1.416144578313253e-05,
      "loss": 0.0603,
      "step": 24230
    },
    {
      "epoch": 2.9204819277108434,
      "grad_norm": 0.0144033869728446,
      "learning_rate": 1.4159036144578315e-05,
      "loss": 0.0583,
      "step": 24240
    },
    {
      "epoch": 2.9216867469879517,
      "grad_norm": 0.057059600949287415,
      "learning_rate": 1.4156626506024098e-05,
      "loss": 0.116,
      "step": 24250
    },
    {
      "epoch": 2.92289156626506,
      "grad_norm": 2.1340386867523193,
      "learning_rate": 1.4154216867469882e-05,
      "loss": 0.0942,
      "step": 24260
    },
    {
      "epoch": 2.9240963855421684,
      "grad_norm": 0.6298931837081909,
      "learning_rate": 1.4151807228915663e-05,
      "loss": 0.0477,
      "step": 24270
    },
    {
      "epoch": 2.9253012048192772,
      "grad_norm": 0.7123956680297852,
      "learning_rate": 1.4149397590361446e-05,
      "loss": 0.0907,
      "step": 24280
    },
    {
      "epoch": 2.9265060240963856,
      "grad_norm": 0.049224697053432465,
      "learning_rate": 1.414698795180723e-05,
      "loss": 0.0539,
      "step": 24290
    },
    {
      "epoch": 2.927710843373494,
      "grad_norm": 9.250749588012695,
      "learning_rate": 1.4144578313253013e-05,
      "loss": 0.069,
      "step": 24300
    },
    {
      "epoch": 2.9289156626506023,
      "grad_norm": 16.449533462524414,
      "learning_rate": 1.4142168674698797e-05,
      "loss": 0.0297,
      "step": 24310
    },
    {
      "epoch": 2.9301204819277107,
      "grad_norm": 23.113718032836914,
      "learning_rate": 1.413975903614458e-05,
      "loss": 0.0287,
      "step": 24320
    },
    {
      "epoch": 2.9313253012048195,
      "grad_norm": 14.876428604125977,
      "learning_rate": 1.4137349397590364e-05,
      "loss": 0.0631,
      "step": 24330
    },
    {
      "epoch": 2.932530120481928,
      "grad_norm": 5.135723114013672,
      "learning_rate": 1.4134939759036145e-05,
      "loss": 0.0801,
      "step": 24340
    },
    {
      "epoch": 2.933734939759036,
      "grad_norm": 0.13199473917484283,
      "learning_rate": 1.4132530120481928e-05,
      "loss": 0.0239,
      "step": 24350
    },
    {
      "epoch": 2.9349397590361446,
      "grad_norm": 0.11563552916049957,
      "learning_rate": 1.4130120481927712e-05,
      "loss": 0.0198,
      "step": 24360
    },
    {
      "epoch": 2.936144578313253,
      "grad_norm": 0.04303698241710663,
      "learning_rate": 1.4127710843373495e-05,
      "loss": 0.0861,
      "step": 24370
    },
    {
      "epoch": 2.9373493975903613,
      "grad_norm": 0.5637643933296204,
      "learning_rate": 1.4125301204819278e-05,
      "loss": 0.0144,
      "step": 24380
    },
    {
      "epoch": 2.9385542168674696,
      "grad_norm": 0.031126467511057854,
      "learning_rate": 1.4122891566265063e-05,
      "loss": 0.0464,
      "step": 24390
    },
    {
      "epoch": 2.9397590361445785,
      "grad_norm": 5.990475654602051,
      "learning_rate": 1.4120481927710844e-05,
      "loss": 0.1012,
      "step": 24400
    },
    {
      "epoch": 2.940963855421687,
      "grad_norm": 0.5278192758560181,
      "learning_rate": 1.4118072289156628e-05,
      "loss": 0.0385,
      "step": 24410
    },
    {
      "epoch": 2.942168674698795,
      "grad_norm": 18.875499725341797,
      "learning_rate": 1.411566265060241e-05,
      "loss": 0.0359,
      "step": 24420
    },
    {
      "epoch": 2.9433734939759035,
      "grad_norm": 0.010693838819861412,
      "learning_rate": 1.4113253012048194e-05,
      "loss": 0.0118,
      "step": 24430
    },
    {
      "epoch": 2.944578313253012,
      "grad_norm": 0.06393266469240189,
      "learning_rate": 1.4110843373493977e-05,
      "loss": 0.017,
      "step": 24440
    },
    {
      "epoch": 2.9457831325301207,
      "grad_norm": 5.618866920471191,
      "learning_rate": 1.4108433734939759e-05,
      "loss": 0.0404,
      "step": 24450
    },
    {
      "epoch": 2.946987951807229,
      "grad_norm": 0.04134571552276611,
      "learning_rate": 1.4106024096385545e-05,
      "loss": 0.1159,
      "step": 24460
    },
    {
      "epoch": 2.9481927710843374,
      "grad_norm": 0.33521604537963867,
      "learning_rate": 1.4103614457831327e-05,
      "loss": 0.0394,
      "step": 24470
    },
    {
      "epoch": 2.9493975903614458,
      "grad_norm": 15.355636596679688,
      "learning_rate": 1.410120481927711e-05,
      "loss": 0.0854,
      "step": 24480
    },
    {
      "epoch": 2.950602409638554,
      "grad_norm": 1.6559451818466187,
      "learning_rate": 1.4098795180722893e-05,
      "loss": 0.05,
      "step": 24490
    },
    {
      "epoch": 2.9518072289156625,
      "grad_norm": 0.11915022134780884,
      "learning_rate": 1.4096385542168676e-05,
      "loss": 0.0216,
      "step": 24500
    },
    {
      "epoch": 2.953012048192771,
      "grad_norm": 0.032728683203458786,
      "learning_rate": 1.409397590361446e-05,
      "loss": 0.0481,
      "step": 24510
    },
    {
      "epoch": 2.9542168674698797,
      "grad_norm": 1.947349190711975,
      "learning_rate": 1.409156626506024e-05,
      "loss": 0.0598,
      "step": 24520
    },
    {
      "epoch": 2.955421686746988,
      "grad_norm": 0.028411319479346275,
      "learning_rate": 1.4089156626506024e-05,
      "loss": 0.0261,
      "step": 24530
    },
    {
      "epoch": 2.9566265060240964,
      "grad_norm": 2.381910800933838,
      "learning_rate": 1.4086746987951809e-05,
      "loss": 0.0197,
      "step": 24540
    },
    {
      "epoch": 2.9578313253012047,
      "grad_norm": 0.07329585403203964,
      "learning_rate": 1.4084337349397592e-05,
      "loss": 0.0197,
      "step": 24550
    },
    {
      "epoch": 2.959036144578313,
      "grad_norm": 3.8197760581970215,
      "learning_rate": 1.4081927710843375e-05,
      "loss": 0.0986,
      "step": 24560
    },
    {
      "epoch": 2.960240963855422,
      "grad_norm": 1.2848960161209106,
      "learning_rate": 1.4079518072289158e-05,
      "loss": 0.0409,
      "step": 24570
    },
    {
      "epoch": 2.9614457831325303,
      "grad_norm": 0.9595835208892822,
      "learning_rate": 1.407710843373494e-05,
      "loss": 0.0271,
      "step": 24580
    },
    {
      "epoch": 2.9626506024096386,
      "grad_norm": 3.4272515773773193,
      "learning_rate": 1.4074698795180723e-05,
      "loss": 0.0205,
      "step": 24590
    },
    {
      "epoch": 2.963855421686747,
      "grad_norm": 0.594995379447937,
      "learning_rate": 1.4072289156626506e-05,
      "loss": 0.1139,
      "step": 24600
    },
    {
      "epoch": 2.9650602409638553,
      "grad_norm": 0.13775749504566193,
      "learning_rate": 1.4069879518072291e-05,
      "loss": 0.0595,
      "step": 24610
    },
    {
      "epoch": 2.9662650602409637,
      "grad_norm": 0.3484995365142822,
      "learning_rate": 1.4067469879518074e-05,
      "loss": 0.0358,
      "step": 24620
    },
    {
      "epoch": 2.967469879518072,
      "grad_norm": 1.864311695098877,
      "learning_rate": 1.4065060240963857e-05,
      "loss": 0.0452,
      "step": 24630
    },
    {
      "epoch": 2.968674698795181,
      "grad_norm": 16.41744613647461,
      "learning_rate": 1.406265060240964e-05,
      "loss": 0.061,
      "step": 24640
    },
    {
      "epoch": 2.9698795180722892,
      "grad_norm": 4.9998698234558105,
      "learning_rate": 1.4060240963855422e-05,
      "loss": 0.0866,
      "step": 24650
    },
    {
      "epoch": 2.9710843373493976,
      "grad_norm": 0.020777756348252296,
      "learning_rate": 1.4057831325301205e-05,
      "loss": 0.0367,
      "step": 24660
    },
    {
      "epoch": 2.972289156626506,
      "grad_norm": 0.8195462226867676,
      "learning_rate": 1.4055421686746988e-05,
      "loss": 0.0421,
      "step": 24670
    },
    {
      "epoch": 2.9734939759036143,
      "grad_norm": 2.565474510192871,
      "learning_rate": 1.4053012048192772e-05,
      "loss": 0.1262,
      "step": 24680
    },
    {
      "epoch": 2.974698795180723,
      "grad_norm": 0.4540593922138214,
      "learning_rate": 1.4050602409638556e-05,
      "loss": 0.0625,
      "step": 24690
    },
    {
      "epoch": 2.9759036144578315,
      "grad_norm": 0.9139623045921326,
      "learning_rate": 1.404819277108434e-05,
      "loss": 0.045,
      "step": 24700
    },
    {
      "epoch": 2.97710843373494,
      "grad_norm": 9.554967880249023,
      "learning_rate": 1.4045783132530121e-05,
      "loss": 0.0463,
      "step": 24710
    },
    {
      "epoch": 2.978313253012048,
      "grad_norm": 3.8123016357421875,
      "learning_rate": 1.4043373493975904e-05,
      "loss": 0.0507,
      "step": 24720
    },
    {
      "epoch": 2.9795180722891565,
      "grad_norm": 0.061125364154577255,
      "learning_rate": 1.4040963855421687e-05,
      "loss": 0.0255,
      "step": 24730
    },
    {
      "epoch": 2.980722891566265,
      "grad_norm": 5.10736608505249,
      "learning_rate": 1.403855421686747e-05,
      "loss": 0.0639,
      "step": 24740
    },
    {
      "epoch": 2.9819277108433733,
      "grad_norm": 1.1799812316894531,
      "learning_rate": 1.4036144578313254e-05,
      "loss": 0.0568,
      "step": 24750
    },
    {
      "epoch": 2.983132530120482,
      "grad_norm": 1.6708130836486816,
      "learning_rate": 1.4033734939759039e-05,
      "loss": 0.0496,
      "step": 24760
    },
    {
      "epoch": 2.9843373493975904,
      "grad_norm": 3.6988914012908936,
      "learning_rate": 1.4031325301204822e-05,
      "loss": 0.0778,
      "step": 24770
    },
    {
      "epoch": 2.985542168674699,
      "grad_norm": 0.05504180118441582,
      "learning_rate": 1.4028915662650603e-05,
      "loss": 0.0339,
      "step": 24780
    },
    {
      "epoch": 2.986746987951807,
      "grad_norm": 0.047116123139858246,
      "learning_rate": 1.4026506024096387e-05,
      "loss": 0.0276,
      "step": 24790
    },
    {
      "epoch": 2.9879518072289155,
      "grad_norm": 1.2390356063842773,
      "learning_rate": 1.402409638554217e-05,
      "loss": 0.0558,
      "step": 24800
    },
    {
      "epoch": 2.9891566265060243,
      "grad_norm": 0.08984819799661636,
      "learning_rate": 1.4021686746987953e-05,
      "loss": 0.0523,
      "step": 24810
    },
    {
      "epoch": 2.9903614457831327,
      "grad_norm": 0.03252610191702843,
      "learning_rate": 1.4019277108433736e-05,
      "loss": 0.0567,
      "step": 24820
    },
    {
      "epoch": 2.991566265060241,
      "grad_norm": 0.0642654299736023,
      "learning_rate": 1.4016867469879518e-05,
      "loss": 0.0549,
      "step": 24830
    },
    {
      "epoch": 2.9927710843373494,
      "grad_norm": 0.03511589765548706,
      "learning_rate": 1.4014457831325302e-05,
      "loss": 0.0515,
      "step": 24840
    },
    {
      "epoch": 2.9939759036144578,
      "grad_norm": 0.790824294090271,
      "learning_rate": 1.4012048192771086e-05,
      "loss": 0.064,
      "step": 24850
    },
    {
      "epoch": 2.995180722891566,
      "grad_norm": 5.938045978546143,
      "learning_rate": 1.4009638554216869e-05,
      "loss": 0.0912,
      "step": 24860
    },
    {
      "epoch": 2.9963855421686745,
      "grad_norm": 0.1573500633239746,
      "learning_rate": 1.4007228915662652e-05,
      "loss": 0.0357,
      "step": 24870
    },
    {
      "epoch": 2.9975903614457833,
      "grad_norm": 3.0258631706237793,
      "learning_rate": 1.4004819277108435e-05,
      "loss": 0.072,
      "step": 24880
    },
    {
      "epoch": 2.9987951807228916,
      "grad_norm": 0.02430340275168419,
      "learning_rate": 1.4002409638554217e-05,
      "loss": 0.0165,
      "step": 24890
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6177074313163757,
      "learning_rate": 1.4e-05,
      "loss": 0.04,
      "step": 24900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9834083239595051,
      "eval_f1": 0.9559043348281017,
      "eval_loss": 0.05426924675703049,
      "eval_precision": 0.9634651600753296,
      "eval_recall": 0.9484612532443456,
      "eval_runtime": 3521.9502,
      "eval_samples_per_second": 12.121,
      "eval_steps_per_second": 0.505,
      "step": 24900
    },
    {
      "epoch": 3.0012048192771084,
      "grad_norm": 5.782699108123779,
      "learning_rate": 1.3997590361445785e-05,
      "loss": 0.1091,
      "step": 24910
    },
    {
      "epoch": 3.0024096385542167,
      "grad_norm": 0.026917582377791405,
      "learning_rate": 1.3995180722891568e-05,
      "loss": 0.0187,
      "step": 24920
    },
    {
      "epoch": 3.003614457831325,
      "grad_norm": 5.067232608795166,
      "learning_rate": 1.3992771084337351e-05,
      "loss": 0.039,
      "step": 24930
    },
    {
      "epoch": 3.004819277108434,
      "grad_norm": 0.23550385236740112,
      "learning_rate": 1.3990361445783134e-05,
      "loss": 0.0399,
      "step": 24940
    },
    {
      "epoch": 3.0060240963855422,
      "grad_norm": 0.48121941089630127,
      "learning_rate": 1.3987951807228917e-05,
      "loss": 0.0624,
      "step": 24950
    },
    {
      "epoch": 3.0072289156626506,
      "grad_norm": 0.48086467385292053,
      "learning_rate": 1.3985542168674699e-05,
      "loss": 0.0692,
      "step": 24960
    },
    {
      "epoch": 3.008433734939759,
      "grad_norm": 0.2472362071275711,
      "learning_rate": 1.3983132530120482e-05,
      "loss": 0.0263,
      "step": 24970
    },
    {
      "epoch": 3.0096385542168673,
      "grad_norm": 0.2332364171743393,
      "learning_rate": 1.3980722891566265e-05,
      "loss": 0.0406,
      "step": 24980
    },
    {
      "epoch": 3.0108433734939757,
      "grad_norm": 21.964441299438477,
      "learning_rate": 1.397831325301205e-05,
      "loss": 0.0529,
      "step": 24990
    },
    {
      "epoch": 3.0120481927710845,
      "grad_norm": 1.8046561479568481,
      "learning_rate": 1.3975903614457833e-05,
      "loss": 0.0307,
      "step": 25000
    },
    {
      "epoch": 3.013253012048193,
      "grad_norm": 0.04494775831699371,
      "learning_rate": 1.3973493975903616e-05,
      "loss": 0.0433,
      "step": 25010
    },
    {
      "epoch": 3.014457831325301,
      "grad_norm": 0.307727575302124,
      "learning_rate": 1.3971084337349398e-05,
      "loss": 0.0536,
      "step": 25020
    },
    {
      "epoch": 3.0156626506024096,
      "grad_norm": 0.0218588225543499,
      "learning_rate": 1.3968674698795181e-05,
      "loss": 0.0389,
      "step": 25030
    },
    {
      "epoch": 3.016867469879518,
      "grad_norm": 0.470102995634079,
      "learning_rate": 1.3966265060240964e-05,
      "loss": 0.0286,
      "step": 25040
    },
    {
      "epoch": 3.0180722891566263,
      "grad_norm": 0.04795042425394058,
      "learning_rate": 1.3963855421686747e-05,
      "loss": 0.0085,
      "step": 25050
    },
    {
      "epoch": 3.019277108433735,
      "grad_norm": 0.28588491678237915,
      "learning_rate": 1.3961445783132532e-05,
      "loss": 0.0062,
      "step": 25060
    },
    {
      "epoch": 3.0204819277108435,
      "grad_norm": 0.07546384632587433,
      "learning_rate": 1.3959036144578315e-05,
      "loss": 0.0768,
      "step": 25070
    },
    {
      "epoch": 3.021686746987952,
      "grad_norm": 0.2895239591598511,
      "learning_rate": 1.3956626506024099e-05,
      "loss": 0.0461,
      "step": 25080
    },
    {
      "epoch": 3.02289156626506,
      "grad_norm": 0.03287683427333832,
      "learning_rate": 1.395421686746988e-05,
      "loss": 0.044,
      "step": 25090
    },
    {
      "epoch": 3.0240963855421685,
      "grad_norm": 0.8868895173072815,
      "learning_rate": 1.3951807228915663e-05,
      "loss": 0.042,
      "step": 25100
    },
    {
      "epoch": 3.025301204819277,
      "grad_norm": 0.40292397141456604,
      "learning_rate": 1.3949397590361446e-05,
      "loss": 0.011,
      "step": 25110
    },
    {
      "epoch": 3.0265060240963857,
      "grad_norm": 2.328976631164551,
      "learning_rate": 1.394698795180723e-05,
      "loss": 0.0485,
      "step": 25120
    },
    {
      "epoch": 3.027710843373494,
      "grad_norm": 1.0840740203857422,
      "learning_rate": 1.3944578313253013e-05,
      "loss": 0.0279,
      "step": 25130
    },
    {
      "epoch": 3.0289156626506024,
      "grad_norm": 2.0312085151672363,
      "learning_rate": 1.3942168674698798e-05,
      "loss": 0.0546,
      "step": 25140
    },
    {
      "epoch": 3.0301204819277108,
      "grad_norm": 0.9734894633293152,
      "learning_rate": 1.393975903614458e-05,
      "loss": 0.0138,
      "step": 25150
    },
    {
      "epoch": 3.031325301204819,
      "grad_norm": 75.70695495605469,
      "learning_rate": 1.3937349397590362e-05,
      "loss": 0.0592,
      "step": 25160
    },
    {
      "epoch": 3.0325301204819275,
      "grad_norm": 0.15634219348430634,
      "learning_rate": 1.3934939759036146e-05,
      "loss": 0.0553,
      "step": 25170
    },
    {
      "epoch": 3.0337349397590363,
      "grad_norm": 10.906482696533203,
      "learning_rate": 1.3932530120481929e-05,
      "loss": 0.0967,
      "step": 25180
    },
    {
      "epoch": 3.0349397590361447,
      "grad_norm": 0.11366809159517288,
      "learning_rate": 1.3930120481927712e-05,
      "loss": 0.0204,
      "step": 25190
    },
    {
      "epoch": 3.036144578313253,
      "grad_norm": 0.04364900290966034,
      "learning_rate": 1.3927710843373493e-05,
      "loss": 0.025,
      "step": 25200
    },
    {
      "epoch": 3.0373493975903614,
      "grad_norm": 1.1558489799499512,
      "learning_rate": 1.392530120481928e-05,
      "loss": 0.0316,
      "step": 25210
    },
    {
      "epoch": 3.0385542168674697,
      "grad_norm": 0.019614126533269882,
      "learning_rate": 1.3922891566265061e-05,
      "loss": 0.0058,
      "step": 25220
    },
    {
      "epoch": 3.039759036144578,
      "grad_norm": 3.7676753997802734,
      "learning_rate": 1.3920481927710845e-05,
      "loss": 0.0708,
      "step": 25230
    },
    {
      "epoch": 3.040963855421687,
      "grad_norm": 0.015232328325510025,
      "learning_rate": 1.3918072289156628e-05,
      "loss": 0.0403,
      "step": 25240
    },
    {
      "epoch": 3.0421686746987953,
      "grad_norm": 0.6962496638298035,
      "learning_rate": 1.3915662650602411e-05,
      "loss": 0.0385,
      "step": 25250
    },
    {
      "epoch": 3.0433734939759036,
      "grad_norm": 5.218875885009766,
      "learning_rate": 1.3913253012048194e-05,
      "loss": 0.0228,
      "step": 25260
    },
    {
      "epoch": 3.044578313253012,
      "grad_norm": 1.1262542009353638,
      "learning_rate": 1.3910843373493976e-05,
      "loss": 0.0423,
      "step": 25270
    },
    {
      "epoch": 3.0457831325301203,
      "grad_norm": 2.4644155502319336,
      "learning_rate": 1.3908433734939759e-05,
      "loss": 0.0162,
      "step": 25280
    },
    {
      "epoch": 3.0469879518072287,
      "grad_norm": 0.09411434829235077,
      "learning_rate": 1.3906024096385544e-05,
      "loss": 0.0606,
      "step": 25290
    },
    {
      "epoch": 3.0481927710843375,
      "grad_norm": 0.09620578587055206,
      "learning_rate": 1.3903614457831327e-05,
      "loss": 0.0126,
      "step": 25300
    },
    {
      "epoch": 3.049397590361446,
      "grad_norm": 0.1726119965314865,
      "learning_rate": 1.390120481927711e-05,
      "loss": 0.018,
      "step": 25310
    },
    {
      "epoch": 3.0506024096385542,
      "grad_norm": 2.6233177185058594,
      "learning_rate": 1.3898795180722893e-05,
      "loss": 0.1092,
      "step": 25320
    },
    {
      "epoch": 3.0518072289156626,
      "grad_norm": 0.5405240058898926,
      "learning_rate": 1.3896385542168676e-05,
      "loss": 0.0664,
      "step": 25330
    },
    {
      "epoch": 3.053012048192771,
      "grad_norm": 1.0919859409332275,
      "learning_rate": 1.3893975903614458e-05,
      "loss": 0.022,
      "step": 25340
    },
    {
      "epoch": 3.0542168674698793,
      "grad_norm": 4.317298412322998,
      "learning_rate": 1.3891566265060241e-05,
      "loss": 0.0741,
      "step": 25350
    },
    {
      "epoch": 3.055421686746988,
      "grad_norm": 2.268665075302124,
      "learning_rate": 1.3889156626506026e-05,
      "loss": 0.0558,
      "step": 25360
    },
    {
      "epoch": 3.0566265060240965,
      "grad_norm": 92.14724731445312,
      "learning_rate": 1.3886746987951809e-05,
      "loss": 0.0205,
      "step": 25370
    },
    {
      "epoch": 3.057831325301205,
      "grad_norm": 2.190598964691162,
      "learning_rate": 1.3884337349397592e-05,
      "loss": 0.0437,
      "step": 25380
    },
    {
      "epoch": 3.059036144578313,
      "grad_norm": 0.0401604063808918,
      "learning_rate": 1.3881927710843375e-05,
      "loss": 0.0162,
      "step": 25390
    },
    {
      "epoch": 3.0602409638554215,
      "grad_norm": 0.019250620156526566,
      "learning_rate": 1.3879518072289157e-05,
      "loss": 0.0193,
      "step": 25400
    },
    {
      "epoch": 3.06144578313253,
      "grad_norm": 5.335597515106201,
      "learning_rate": 1.387710843373494e-05,
      "loss": 0.0738,
      "step": 25410
    },
    {
      "epoch": 3.0626506024096387,
      "grad_norm": 1.341359257698059,
      "learning_rate": 1.3874698795180723e-05,
      "loss": 0.0416,
      "step": 25420
    },
    {
      "epoch": 3.063855421686747,
      "grad_norm": 0.016514664515852928,
      "learning_rate": 1.3872289156626506e-05,
      "loss": 0.043,
      "step": 25430
    },
    {
      "epoch": 3.0650602409638554,
      "grad_norm": 0.0415850393474102,
      "learning_rate": 1.3869879518072291e-05,
      "loss": 0.0509,
      "step": 25440
    },
    {
      "epoch": 3.066265060240964,
      "grad_norm": 2.590965747833252,
      "learning_rate": 1.3867469879518074e-05,
      "loss": 0.0297,
      "step": 25450
    },
    {
      "epoch": 3.067469879518072,
      "grad_norm": 0.5432853698730469,
      "learning_rate": 1.3865060240963858e-05,
      "loss": 0.0558,
      "step": 25460
    },
    {
      "epoch": 3.0686746987951805,
      "grad_norm": 4.419272422790527,
      "learning_rate": 1.3862650602409639e-05,
      "loss": 0.0375,
      "step": 25470
    },
    {
      "epoch": 3.0698795180722893,
      "grad_norm": 0.04872127249836922,
      "learning_rate": 1.3860240963855422e-05,
      "loss": 0.0205,
      "step": 25480
    },
    {
      "epoch": 3.0710843373493977,
      "grad_norm": 0.2887880206108093,
      "learning_rate": 1.3857831325301205e-05,
      "loss": 0.0295,
      "step": 25490
    },
    {
      "epoch": 3.072289156626506,
      "grad_norm": 0.15011338889598846,
      "learning_rate": 1.3855421686746989e-05,
      "loss": 0.0151,
      "step": 25500
    },
    {
      "epoch": 3.0734939759036144,
      "grad_norm": 5.871208190917969,
      "learning_rate": 1.3853012048192774e-05,
      "loss": 0.0284,
      "step": 25510
    },
    {
      "epoch": 3.0746987951807228,
      "grad_norm": 0.0617716908454895,
      "learning_rate": 1.3850602409638557e-05,
      "loss": 0.0137,
      "step": 25520
    },
    {
      "epoch": 3.075903614457831,
      "grad_norm": 0.017902515828609467,
      "learning_rate": 1.3848192771084338e-05,
      "loss": 0.0147,
      "step": 25530
    },
    {
      "epoch": 3.07710843373494,
      "grad_norm": 0.373304158449173,
      "learning_rate": 1.3845783132530121e-05,
      "loss": 0.0769,
      "step": 25540
    },
    {
      "epoch": 3.0783132530120483,
      "grad_norm": 0.02443855069577694,
      "learning_rate": 1.3843373493975905e-05,
      "loss": 0.0174,
      "step": 25550
    },
    {
      "epoch": 3.0795180722891566,
      "grad_norm": 0.16820348799228668,
      "learning_rate": 1.3840963855421688e-05,
      "loss": 0.0239,
      "step": 25560
    },
    {
      "epoch": 3.080722891566265,
      "grad_norm": 8.070289611816406,
      "learning_rate": 1.3838554216867471e-05,
      "loss": 0.0547,
      "step": 25570
    },
    {
      "epoch": 3.0819277108433734,
      "grad_norm": 0.5964899063110352,
      "learning_rate": 1.3836144578313252e-05,
      "loss": 0.0283,
      "step": 25580
    },
    {
      "epoch": 3.0831325301204817,
      "grad_norm": 0.3970045745372772,
      "learning_rate": 1.3833734939759039e-05,
      "loss": 0.0573,
      "step": 25590
    },
    {
      "epoch": 3.0843373493975905,
      "grad_norm": 11.561712265014648,
      "learning_rate": 1.383132530120482e-05,
      "loss": 0.0084,
      "step": 25600
    },
    {
      "epoch": 3.085542168674699,
      "grad_norm": 0.017725717276334763,
      "learning_rate": 1.3828915662650604e-05,
      "loss": 0.0017,
      "step": 25610
    },
    {
      "epoch": 3.0867469879518072,
      "grad_norm": 0.3610912561416626,
      "learning_rate": 1.3826506024096387e-05,
      "loss": 0.0312,
      "step": 25620
    },
    {
      "epoch": 3.0879518072289156,
      "grad_norm": 0.015772227197885513,
      "learning_rate": 1.382409638554217e-05,
      "loss": 0.0021,
      "step": 25630
    },
    {
      "epoch": 3.089156626506024,
      "grad_norm": 0.259924054145813,
      "learning_rate": 1.3821686746987953e-05,
      "loss": 0.0329,
      "step": 25640
    },
    {
      "epoch": 3.0903614457831323,
      "grad_norm": 0.03874271735548973,
      "learning_rate": 1.3819277108433735e-05,
      "loss": 0.0342,
      "step": 25650
    },
    {
      "epoch": 3.091566265060241,
      "grad_norm": 0.05564403161406517,
      "learning_rate": 1.381686746987952e-05,
      "loss": 0.0081,
      "step": 25660
    },
    {
      "epoch": 3.0927710843373495,
      "grad_norm": 0.01041504181921482,
      "learning_rate": 1.3814457831325303e-05,
      "loss": 0.046,
      "step": 25670
    },
    {
      "epoch": 3.093975903614458,
      "grad_norm": 0.008852521888911724,
      "learning_rate": 1.3812048192771086e-05,
      "loss": 0.0339,
      "step": 25680
    },
    {
      "epoch": 3.095180722891566,
      "grad_norm": 0.029844101518392563,
      "learning_rate": 1.3809638554216869e-05,
      "loss": 0.0761,
      "step": 25690
    },
    {
      "epoch": 3.0963855421686746,
      "grad_norm": 4.270699501037598,
      "learning_rate": 1.3807228915662652e-05,
      "loss": 0.0766,
      "step": 25700
    },
    {
      "epoch": 3.097590361445783,
      "grad_norm": 0.2076706439256668,
      "learning_rate": 1.3804819277108434e-05,
      "loss": 0.0191,
      "step": 25710
    },
    {
      "epoch": 3.0987951807228917,
      "grad_norm": 0.1028020828962326,
      "learning_rate": 1.3802409638554217e-05,
      "loss": 0.0337,
      "step": 25720
    },
    {
      "epoch": 3.1,
      "grad_norm": 11.90121078491211,
      "learning_rate": 1.38e-05,
      "loss": 0.0398,
      "step": 25730
    },
    {
      "epoch": 3.1012048192771084,
      "grad_norm": 0.07478274405002594,
      "learning_rate": 1.3797590361445785e-05,
      "loss": 0.0538,
      "step": 25740
    },
    {
      "epoch": 3.102409638554217,
      "grad_norm": 0.42461827397346497,
      "learning_rate": 1.3795180722891568e-05,
      "loss": 0.0048,
      "step": 25750
    },
    {
      "epoch": 3.103614457831325,
      "grad_norm": 0.017063764855265617,
      "learning_rate": 1.3792771084337351e-05,
      "loss": 0.0191,
      "step": 25760
    },
    {
      "epoch": 3.1048192771084335,
      "grad_norm": 0.09316480159759521,
      "learning_rate": 1.3790361445783134e-05,
      "loss": 0.0357,
      "step": 25770
    },
    {
      "epoch": 3.1060240963855423,
      "grad_norm": 0.04131879657506943,
      "learning_rate": 1.3787951807228916e-05,
      "loss": 0.0927,
      "step": 25780
    },
    {
      "epoch": 3.1072289156626507,
      "grad_norm": 6.7559685707092285,
      "learning_rate": 1.3785542168674699e-05,
      "loss": 0.0421,
      "step": 25790
    },
    {
      "epoch": 3.108433734939759,
      "grad_norm": 0.009942560456693172,
      "learning_rate": 1.3783132530120482e-05,
      "loss": 0.0193,
      "step": 25800
    },
    {
      "epoch": 3.1096385542168674,
      "grad_norm": 3.780022382736206,
      "learning_rate": 1.3780722891566267e-05,
      "loss": 0.0582,
      "step": 25810
    },
    {
      "epoch": 3.1108433734939758,
      "grad_norm": 0.045599088072776794,
      "learning_rate": 1.377831325301205e-05,
      "loss": 0.0414,
      "step": 25820
    },
    {
      "epoch": 3.112048192771084,
      "grad_norm": 0.005963687784969807,
      "learning_rate": 1.3775903614457833e-05,
      "loss": 0.0587,
      "step": 25830
    },
    {
      "epoch": 3.113253012048193,
      "grad_norm": 0.03624822199344635,
      "learning_rate": 1.3773493975903615e-05,
      "loss": 0.031,
      "step": 25840
    },
    {
      "epoch": 3.1144578313253013,
      "grad_norm": 0.010182852856814861,
      "learning_rate": 1.3771084337349398e-05,
      "loss": 0.0198,
      "step": 25850
    },
    {
      "epoch": 3.1156626506024097,
      "grad_norm": 2.2422142028808594,
      "learning_rate": 1.3768674698795181e-05,
      "loss": 0.0557,
      "step": 25860
    },
    {
      "epoch": 3.116867469879518,
      "grad_norm": 0.037536945194005966,
      "learning_rate": 1.3766265060240964e-05,
      "loss": 0.0515,
      "step": 25870
    },
    {
      "epoch": 3.1180722891566264,
      "grad_norm": 0.061112284660339355,
      "learning_rate": 1.3763855421686748e-05,
      "loss": 0.0247,
      "step": 25880
    },
    {
      "epoch": 3.1192771084337347,
      "grad_norm": 0.013509785756468773,
      "learning_rate": 1.3761445783132533e-05,
      "loss": 0.0239,
      "step": 25890
    },
    {
      "epoch": 3.1204819277108435,
      "grad_norm": 3.3843793869018555,
      "learning_rate": 1.3759036144578316e-05,
      "loss": 0.0404,
      "step": 25900
    },
    {
      "epoch": 3.121686746987952,
      "grad_norm": 0.0372670441865921,
      "learning_rate": 1.3756626506024097e-05,
      "loss": 0.0615,
      "step": 25910
    },
    {
      "epoch": 3.1228915662650603,
      "grad_norm": 0.021581633016467094,
      "learning_rate": 1.375421686746988e-05,
      "loss": 0.0299,
      "step": 25920
    },
    {
      "epoch": 3.1240963855421686,
      "grad_norm": 0.08298737555742264,
      "learning_rate": 1.3751807228915664e-05,
      "loss": 0.0331,
      "step": 25930
    },
    {
      "epoch": 3.125301204819277,
      "grad_norm": 0.5771544575691223,
      "learning_rate": 1.3749397590361447e-05,
      "loss": 0.025,
      "step": 25940
    },
    {
      "epoch": 3.1265060240963853,
      "grad_norm": 0.021524440497159958,
      "learning_rate": 1.374698795180723e-05,
      "loss": 0.0418,
      "step": 25950
    },
    {
      "epoch": 3.127710843373494,
      "grad_norm": 0.04651608690619469,
      "learning_rate": 1.3744578313253015e-05,
      "loss": 0.0724,
      "step": 25960
    },
    {
      "epoch": 3.1289156626506025,
      "grad_norm": 0.035948704928159714,
      "learning_rate": 1.3742168674698796e-05,
      "loss": 0.0227,
      "step": 25970
    },
    {
      "epoch": 3.130120481927711,
      "grad_norm": 0.042691975831985474,
      "learning_rate": 1.373975903614458e-05,
      "loss": 0.0109,
      "step": 25980
    },
    {
      "epoch": 3.1313253012048192,
      "grad_norm": 3.726567268371582,
      "learning_rate": 1.3737349397590363e-05,
      "loss": 0.0299,
      "step": 25990
    },
    {
      "epoch": 3.1325301204819276,
      "grad_norm": 0.8205904364585876,
      "learning_rate": 1.3734939759036146e-05,
      "loss": 0.0448,
      "step": 26000
    },
    {
      "epoch": 3.133734939759036,
      "grad_norm": 0.014715055003762245,
      "learning_rate": 1.3732530120481929e-05,
      "loss": 0.0407,
      "step": 26010
    },
    {
      "epoch": 3.1349397590361447,
      "grad_norm": 0.8465086221694946,
      "learning_rate": 1.373012048192771e-05,
      "loss": 0.0275,
      "step": 26020
    },
    {
      "epoch": 3.136144578313253,
      "grad_norm": 0.1327412724494934,
      "learning_rate": 1.3727710843373494e-05,
      "loss": 0.0214,
      "step": 26030
    },
    {
      "epoch": 3.1373493975903615,
      "grad_norm": 0.03247451037168503,
      "learning_rate": 1.3725301204819278e-05,
      "loss": 0.044,
      "step": 26040
    },
    {
      "epoch": 3.13855421686747,
      "grad_norm": 0.018700221553444862,
      "learning_rate": 1.3722891566265062e-05,
      "loss": 0.0207,
      "step": 26050
    },
    {
      "epoch": 3.139759036144578,
      "grad_norm": 9.729238510131836,
      "learning_rate": 1.3720481927710845e-05,
      "loss": 0.0464,
      "step": 26060
    },
    {
      "epoch": 3.1409638554216865,
      "grad_norm": 0.09094565361738205,
      "learning_rate": 1.3718072289156628e-05,
      "loss": 0.0325,
      "step": 26070
    },
    {
      "epoch": 3.1421686746987953,
      "grad_norm": 0.2373168021440506,
      "learning_rate": 1.3715662650602411e-05,
      "loss": 0.0275,
      "step": 26080
    },
    {
      "epoch": 3.1433734939759037,
      "grad_norm": 0.5925437211990356,
      "learning_rate": 1.3713253012048193e-05,
      "loss": 0.005,
      "step": 26090
    },
    {
      "epoch": 3.144578313253012,
      "grad_norm": 1.0664883852005005,
      "learning_rate": 1.3710843373493976e-05,
      "loss": 0.0173,
      "step": 26100
    },
    {
      "epoch": 3.1457831325301204,
      "grad_norm": 0.012022958137094975,
      "learning_rate": 1.370843373493976e-05,
      "loss": 0.0223,
      "step": 26110
    },
    {
      "epoch": 3.146987951807229,
      "grad_norm": 2.9184906482696533,
      "learning_rate": 1.3706024096385544e-05,
      "loss": 0.0151,
      "step": 26120
    },
    {
      "epoch": 3.148192771084337,
      "grad_norm": 0.039637241512537,
      "learning_rate": 1.3703614457831327e-05,
      "loss": 0.019,
      "step": 26130
    },
    {
      "epoch": 3.149397590361446,
      "grad_norm": 23.01861572265625,
      "learning_rate": 1.370120481927711e-05,
      "loss": 0.0184,
      "step": 26140
    },
    {
      "epoch": 3.1506024096385543,
      "grad_norm": 1.2107304334640503,
      "learning_rate": 1.3698795180722892e-05,
      "loss": 0.0316,
      "step": 26150
    },
    {
      "epoch": 3.1518072289156627,
      "grad_norm": 0.005791807547211647,
      "learning_rate": 1.3696385542168675e-05,
      "loss": 0.0757,
      "step": 26160
    },
    {
      "epoch": 3.153012048192771,
      "grad_norm": 0.0068456511944532394,
      "learning_rate": 1.3693975903614458e-05,
      "loss": 0.0123,
      "step": 26170
    },
    {
      "epoch": 3.1542168674698794,
      "grad_norm": 0.005021815653890371,
      "learning_rate": 1.3691566265060241e-05,
      "loss": 0.006,
      "step": 26180
    },
    {
      "epoch": 3.1554216867469878,
      "grad_norm": 0.0036696919705718756,
      "learning_rate": 1.3689156626506026e-05,
      "loss": 0.0521,
      "step": 26190
    },
    {
      "epoch": 3.1566265060240966,
      "grad_norm": 0.04348983243107796,
      "learning_rate": 1.368674698795181e-05,
      "loss": 0.0259,
      "step": 26200
    },
    {
      "epoch": 3.157831325301205,
      "grad_norm": 0.028381038457155228,
      "learning_rate": 1.3684337349397592e-05,
      "loss": 0.0238,
      "step": 26210
    },
    {
      "epoch": 3.1590361445783133,
      "grad_norm": 0.008439240977168083,
      "learning_rate": 1.3681927710843374e-05,
      "loss": 0.0634,
      "step": 26220
    },
    {
      "epoch": 3.1602409638554216,
      "grad_norm": 0.12992067635059357,
      "learning_rate": 1.3679518072289157e-05,
      "loss": 0.037,
      "step": 26230
    },
    {
      "epoch": 3.16144578313253,
      "grad_norm": 0.7706868648529053,
      "learning_rate": 1.367710843373494e-05,
      "loss": 0.0157,
      "step": 26240
    },
    {
      "epoch": 3.1626506024096384,
      "grad_norm": 4.832634925842285,
      "learning_rate": 1.3674698795180723e-05,
      "loss": 0.0334,
      "step": 26250
    },
    {
      "epoch": 3.163855421686747,
      "grad_norm": 0.008752855472266674,
      "learning_rate": 1.3672289156626508e-05,
      "loss": 0.0726,
      "step": 26260
    },
    {
      "epoch": 3.1650602409638555,
      "grad_norm": 0.5632182955741882,
      "learning_rate": 1.3669879518072292e-05,
      "loss": 0.057,
      "step": 26270
    },
    {
      "epoch": 3.166265060240964,
      "grad_norm": 0.08281465619802475,
      "learning_rate": 1.3667469879518073e-05,
      "loss": 0.0092,
      "step": 26280
    },
    {
      "epoch": 3.1674698795180722,
      "grad_norm": 1.9643371105194092,
      "learning_rate": 1.3665060240963856e-05,
      "loss": 0.0668,
      "step": 26290
    },
    {
      "epoch": 3.1686746987951806,
      "grad_norm": 0.04390490800142288,
      "learning_rate": 1.366265060240964e-05,
      "loss": 0.0646,
      "step": 26300
    },
    {
      "epoch": 3.169879518072289,
      "grad_norm": 0.11738995462656021,
      "learning_rate": 1.3660240963855423e-05,
      "loss": 0.0702,
      "step": 26310
    },
    {
      "epoch": 3.1710843373493978,
      "grad_norm": 0.06910959631204605,
      "learning_rate": 1.3657831325301206e-05,
      "loss": 0.048,
      "step": 26320
    },
    {
      "epoch": 3.172289156626506,
      "grad_norm": 0.09587851166725159,
      "learning_rate": 1.3655421686746987e-05,
      "loss": 0.0116,
      "step": 26330
    },
    {
      "epoch": 3.1734939759036145,
      "grad_norm": 0.7148745059967041,
      "learning_rate": 1.3653012048192774e-05,
      "loss": 0.0333,
      "step": 26340
    },
    {
      "epoch": 3.174698795180723,
      "grad_norm": 1.2226488590240479,
      "learning_rate": 1.3650602409638555e-05,
      "loss": 0.025,
      "step": 26350
    },
    {
      "epoch": 3.175903614457831,
      "grad_norm": 0.1300530731678009,
      "learning_rate": 1.3648192771084338e-05,
      "loss": 0.0362,
      "step": 26360
    },
    {
      "epoch": 3.1771084337349396,
      "grad_norm": 0.011611426249146461,
      "learning_rate": 1.3645783132530122e-05,
      "loss": 0.0207,
      "step": 26370
    },
    {
      "epoch": 3.1783132530120484,
      "grad_norm": 0.04545317217707634,
      "learning_rate": 1.3643373493975905e-05,
      "loss": 0.0074,
      "step": 26380
    },
    {
      "epoch": 3.1795180722891567,
      "grad_norm": 0.011683104559779167,
      "learning_rate": 1.3640963855421688e-05,
      "loss": 0.0236,
      "step": 26390
    },
    {
      "epoch": 3.180722891566265,
      "grad_norm": 0.20001254975795746,
      "learning_rate": 1.363855421686747e-05,
      "loss": 0.0361,
      "step": 26400
    },
    {
      "epoch": 3.1819277108433734,
      "grad_norm": 0.38168033957481384,
      "learning_rate": 1.3636144578313254e-05,
      "loss": 0.0136,
      "step": 26410
    },
    {
      "epoch": 3.183132530120482,
      "grad_norm": 0.009616903960704803,
      "learning_rate": 1.3633734939759037e-05,
      "loss": 0.0199,
      "step": 26420
    },
    {
      "epoch": 3.18433734939759,
      "grad_norm": 0.007914887741208076,
      "learning_rate": 1.363132530120482e-05,
      "loss": 0.0085,
      "step": 26430
    },
    {
      "epoch": 3.185542168674699,
      "grad_norm": 0.015093017369508743,
      "learning_rate": 1.3628915662650604e-05,
      "loss": 0.0266,
      "step": 26440
    },
    {
      "epoch": 3.1867469879518073,
      "grad_norm": 0.0051042865961790085,
      "learning_rate": 1.3626506024096387e-05,
      "loss": 0.0163,
      "step": 26450
    },
    {
      "epoch": 3.1879518072289157,
      "grad_norm": 0.04634130746126175,
      "learning_rate": 1.3624096385542168e-05,
      "loss": 0.002,
      "step": 26460
    },
    {
      "epoch": 3.189156626506024,
      "grad_norm": 0.0033424326684325933,
      "learning_rate": 1.3621686746987952e-05,
      "loss": 0.0254,
      "step": 26470
    },
    {
      "epoch": 3.1903614457831324,
      "grad_norm": 0.008032577112317085,
      "learning_rate": 1.3619277108433735e-05,
      "loss": 0.0413,
      "step": 26480
    },
    {
      "epoch": 3.1915662650602408,
      "grad_norm": 0.005920706782490015,
      "learning_rate": 1.361686746987952e-05,
      "loss": 0.0369,
      "step": 26490
    },
    {
      "epoch": 3.1927710843373496,
      "grad_norm": 1.5608617067337036,
      "learning_rate": 1.3614457831325303e-05,
      "loss": 0.071,
      "step": 26500
    },
    {
      "epoch": 3.193975903614458,
      "grad_norm": 4.717216968536377,
      "learning_rate": 1.3612048192771086e-05,
      "loss": 0.071,
      "step": 26510
    },
    {
      "epoch": 3.1951807228915663,
      "grad_norm": 0.052829988300800323,
      "learning_rate": 1.360963855421687e-05,
      "loss": 0.0062,
      "step": 26520
    },
    {
      "epoch": 3.1963855421686747,
      "grad_norm": 0.022984806448221207,
      "learning_rate": 1.360722891566265e-05,
      "loss": 0.0785,
      "step": 26530
    },
    {
      "epoch": 3.197590361445783,
      "grad_norm": 0.4741600453853607,
      "learning_rate": 1.3604819277108434e-05,
      "loss": 0.0429,
      "step": 26540
    },
    {
      "epoch": 3.1987951807228914,
      "grad_norm": 6.482531547546387,
      "learning_rate": 1.3602409638554217e-05,
      "loss": 0.0469,
      "step": 26550
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.03077196516096592,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0662,
      "step": 26560
    },
    {
      "epoch": 3.2012048192771085,
      "grad_norm": 0.043457530438899994,
      "learning_rate": 1.3597590361445785e-05,
      "loss": 0.0272,
      "step": 26570
    },
    {
      "epoch": 3.202409638554217,
      "grad_norm": 0.38428550958633423,
      "learning_rate": 1.3595180722891568e-05,
      "loss": 0.0287,
      "step": 26580
    },
    {
      "epoch": 3.2036144578313253,
      "grad_norm": 0.030461831018328667,
      "learning_rate": 1.359277108433735e-05,
      "loss": 0.0195,
      "step": 26590
    },
    {
      "epoch": 3.2048192771084336,
      "grad_norm": 0.03440792113542557,
      "learning_rate": 1.3590361445783133e-05,
      "loss": 0.1022,
      "step": 26600
    },
    {
      "epoch": 3.206024096385542,
      "grad_norm": 0.3387608528137207,
      "learning_rate": 1.3587951807228916e-05,
      "loss": 0.0369,
      "step": 26610
    },
    {
      "epoch": 3.207228915662651,
      "grad_norm": 11.575620651245117,
      "learning_rate": 1.35855421686747e-05,
      "loss": 0.0374,
      "step": 26620
    },
    {
      "epoch": 3.208433734939759,
      "grad_norm": 0.03427563235163689,
      "learning_rate": 1.3583132530120482e-05,
      "loss": 0.0187,
      "step": 26630
    },
    {
      "epoch": 3.2096385542168675,
      "grad_norm": 1.8539113998413086,
      "learning_rate": 1.3580722891566267e-05,
      "loss": 0.0846,
      "step": 26640
    },
    {
      "epoch": 3.210843373493976,
      "grad_norm": 0.037517789751291275,
      "learning_rate": 1.357831325301205e-05,
      "loss": 0.0138,
      "step": 26650
    },
    {
      "epoch": 3.212048192771084,
      "grad_norm": 0.4231067895889282,
      "learning_rate": 1.3575903614457832e-05,
      "loss": 0.05,
      "step": 26660
    },
    {
      "epoch": 3.2132530120481926,
      "grad_norm": 0.9067192673683167,
      "learning_rate": 1.3573493975903615e-05,
      "loss": 0.0421,
      "step": 26670
    },
    {
      "epoch": 3.2144578313253014,
      "grad_norm": 0.03355109691619873,
      "learning_rate": 1.3571084337349398e-05,
      "loss": 0.0389,
      "step": 26680
    },
    {
      "epoch": 3.2156626506024097,
      "grad_norm": 0.172737255692482,
      "learning_rate": 1.3568674698795182e-05,
      "loss": 0.0671,
      "step": 26690
    },
    {
      "epoch": 3.216867469879518,
      "grad_norm": 2.179327964782715,
      "learning_rate": 1.3566265060240965e-05,
      "loss": 0.0509,
      "step": 26700
    },
    {
      "epoch": 3.2180722891566265,
      "grad_norm": 1.1946828365325928,
      "learning_rate": 1.356385542168675e-05,
      "loss": 0.0311,
      "step": 26710
    },
    {
      "epoch": 3.219277108433735,
      "grad_norm": 0.050708938390016556,
      "learning_rate": 1.3561445783132533e-05,
      "loss": 0.0176,
      "step": 26720
    },
    {
      "epoch": 3.220481927710843,
      "grad_norm": 0.11410628259181976,
      "learning_rate": 1.3559036144578314e-05,
      "loss": 0.0332,
      "step": 26730
    },
    {
      "epoch": 3.221686746987952,
      "grad_norm": 3.239302158355713,
      "learning_rate": 1.3556626506024097e-05,
      "loss": 0.0488,
      "step": 26740
    },
    {
      "epoch": 3.2228915662650603,
      "grad_norm": 0.713361382484436,
      "learning_rate": 1.355421686746988e-05,
      "loss": 0.0231,
      "step": 26750
    },
    {
      "epoch": 3.2240963855421687,
      "grad_norm": 0.31861940026283264,
      "learning_rate": 1.3551807228915664e-05,
      "loss": 0.0165,
      "step": 26760
    },
    {
      "epoch": 3.225301204819277,
      "grad_norm": 0.009591637179255486,
      "learning_rate": 1.3549397590361447e-05,
      "loss": 0.0538,
      "step": 26770
    },
    {
      "epoch": 3.2265060240963854,
      "grad_norm": 0.015968957915902138,
      "learning_rate": 1.3546987951807228e-05,
      "loss": 0.0419,
      "step": 26780
    },
    {
      "epoch": 3.227710843373494,
      "grad_norm": 3.376098155975342,
      "learning_rate": 1.3544578313253013e-05,
      "loss": 0.0176,
      "step": 26790
    },
    {
      "epoch": 3.2289156626506026,
      "grad_norm": 6.598605155944824,
      "learning_rate": 1.3542168674698796e-05,
      "loss": 0.0684,
      "step": 26800
    },
    {
      "epoch": 3.230120481927711,
      "grad_norm": 11.613727569580078,
      "learning_rate": 1.353975903614458e-05,
      "loss": 0.0652,
      "step": 26810
    },
    {
      "epoch": 3.2313253012048193,
      "grad_norm": 1.3020291328430176,
      "learning_rate": 1.3537349397590363e-05,
      "loss": 0.048,
      "step": 26820
    },
    {
      "epoch": 3.2325301204819277,
      "grad_norm": 0.056857895106077194,
      "learning_rate": 1.3534939759036146e-05,
      "loss": 0.017,
      "step": 26830
    },
    {
      "epoch": 3.233734939759036,
      "grad_norm": 2.7251994609832764,
      "learning_rate": 1.3532530120481927e-05,
      "loss": 0.0416,
      "step": 26840
    },
    {
      "epoch": 3.2349397590361444,
      "grad_norm": 25.26613998413086,
      "learning_rate": 1.353012048192771e-05,
      "loss": 0.0346,
      "step": 26850
    },
    {
      "epoch": 3.236144578313253,
      "grad_norm": 0.3849174976348877,
      "learning_rate": 1.3527710843373496e-05,
      "loss": 0.0453,
      "step": 26860
    },
    {
      "epoch": 3.2373493975903616,
      "grad_norm": 0.007748033851385117,
      "learning_rate": 1.3525301204819279e-05,
      "loss": 0.0362,
      "step": 26870
    },
    {
      "epoch": 3.23855421686747,
      "grad_norm": 0.015870220959186554,
      "learning_rate": 1.3522891566265062e-05,
      "loss": 0.0153,
      "step": 26880
    },
    {
      "epoch": 3.2397590361445783,
      "grad_norm": 0.011924875900149345,
      "learning_rate": 1.3520481927710845e-05,
      "loss": 0.0385,
      "step": 26890
    },
    {
      "epoch": 3.2409638554216866,
      "grad_norm": 0.5962957739830017,
      "learning_rate": 1.3518072289156628e-05,
      "loss": 0.0488,
      "step": 26900
    },
    {
      "epoch": 3.242168674698795,
      "grad_norm": 2.069453239440918,
      "learning_rate": 1.351566265060241e-05,
      "loss": 0.0814,
      "step": 26910
    },
    {
      "epoch": 3.243373493975904,
      "grad_norm": 0.013696110807359219,
      "learning_rate": 1.3513253012048193e-05,
      "loss": 0.0637,
      "step": 26920
    },
    {
      "epoch": 3.244578313253012,
      "grad_norm": 7.791449069976807,
      "learning_rate": 1.3510843373493976e-05,
      "loss": 0.076,
      "step": 26930
    },
    {
      "epoch": 3.2457831325301205,
      "grad_norm": 0.15632206201553345,
      "learning_rate": 1.3508433734939761e-05,
      "loss": 0.027,
      "step": 26940
    },
    {
      "epoch": 3.246987951807229,
      "grad_norm": 2.269418954849243,
      "learning_rate": 1.3506024096385544e-05,
      "loss": 0.0119,
      "step": 26950
    },
    {
      "epoch": 3.2481927710843372,
      "grad_norm": 0.006586202420294285,
      "learning_rate": 1.3503614457831327e-05,
      "loss": 0.0339,
      "step": 26960
    },
    {
      "epoch": 3.2493975903614456,
      "grad_norm": 0.15286238491535187,
      "learning_rate": 1.3501204819277109e-05,
      "loss": 0.0538,
      "step": 26970
    },
    {
      "epoch": 3.2506024096385544,
      "grad_norm": 4.531733989715576,
      "learning_rate": 1.3498795180722892e-05,
      "loss": 0.0297,
      "step": 26980
    },
    {
      "epoch": 3.2518072289156628,
      "grad_norm": 1.090033769607544,
      "learning_rate": 1.3496385542168675e-05,
      "loss": 0.0488,
      "step": 26990
    },
    {
      "epoch": 3.253012048192771,
      "grad_norm": 0.5682314038276672,
      "learning_rate": 1.3493975903614458e-05,
      "loss": 0.0132,
      "step": 27000
    },
    {
      "epoch": 3.2542168674698795,
      "grad_norm": 6.833621978759766,
      "learning_rate": 1.3491566265060243e-05,
      "loss": 0.0831,
      "step": 27010
    },
    {
      "epoch": 3.255421686746988,
      "grad_norm": 0.02537047117948532,
      "learning_rate": 1.3489156626506026e-05,
      "loss": 0.0189,
      "step": 27020
    },
    {
      "epoch": 3.256626506024096,
      "grad_norm": 0.010547160170972347,
      "learning_rate": 1.348674698795181e-05,
      "loss": 0.0367,
      "step": 27030
    },
    {
      "epoch": 3.257831325301205,
      "grad_norm": 21.467016220092773,
      "learning_rate": 1.3484337349397591e-05,
      "loss": 0.0958,
      "step": 27040
    },
    {
      "epoch": 3.2590361445783134,
      "grad_norm": 0.2175116091966629,
      "learning_rate": 1.3481927710843374e-05,
      "loss": 0.0153,
      "step": 27050
    },
    {
      "epoch": 3.2602409638554217,
      "grad_norm": 0.05171024054288864,
      "learning_rate": 1.3479518072289157e-05,
      "loss": 0.0746,
      "step": 27060
    },
    {
      "epoch": 3.26144578313253,
      "grad_norm": 10.183738708496094,
      "learning_rate": 1.347710843373494e-05,
      "loss": 0.0919,
      "step": 27070
    },
    {
      "epoch": 3.2626506024096384,
      "grad_norm": 0.3593548536300659,
      "learning_rate": 1.3474698795180725e-05,
      "loss": 0.0456,
      "step": 27080
    },
    {
      "epoch": 3.263855421686747,
      "grad_norm": 5.581929683685303,
      "learning_rate": 1.3472289156626509e-05,
      "loss": 0.059,
      "step": 27090
    },
    {
      "epoch": 3.2650602409638556,
      "grad_norm": 1.3381375074386597,
      "learning_rate": 1.346987951807229e-05,
      "loss": 0.0109,
      "step": 27100
    },
    {
      "epoch": 3.266265060240964,
      "grad_norm": 0.30485910177230835,
      "learning_rate": 1.3467469879518073e-05,
      "loss": 0.0296,
      "step": 27110
    },
    {
      "epoch": 3.2674698795180723,
      "grad_norm": 0.013064132072031498,
      "learning_rate": 1.3465060240963856e-05,
      "loss": 0.0199,
      "step": 27120
    },
    {
      "epoch": 3.2686746987951807,
      "grad_norm": 0.8151025772094727,
      "learning_rate": 1.346265060240964e-05,
      "loss": 0.0727,
      "step": 27130
    },
    {
      "epoch": 3.269879518072289,
      "grad_norm": 0.03274020180106163,
      "learning_rate": 1.3460240963855423e-05,
      "loss": 0.0019,
      "step": 27140
    },
    {
      "epoch": 3.2710843373493974,
      "grad_norm": 5.557881832122803,
      "learning_rate": 1.3457831325301204e-05,
      "loss": 0.0234,
      "step": 27150
    },
    {
      "epoch": 3.272289156626506,
      "grad_norm": 0.0802842304110527,
      "learning_rate": 1.345542168674699e-05,
      "loss": 0.0489,
      "step": 27160
    },
    {
      "epoch": 3.2734939759036146,
      "grad_norm": 4.941790580749512,
      "learning_rate": 1.3453012048192772e-05,
      "loss": 0.0318,
      "step": 27170
    },
    {
      "epoch": 3.274698795180723,
      "grad_norm": 12.293883323669434,
      "learning_rate": 1.3450602409638555e-05,
      "loss": 0.0322,
      "step": 27180
    },
    {
      "epoch": 3.2759036144578313,
      "grad_norm": 0.35244497656822205,
      "learning_rate": 1.3448192771084339e-05,
      "loss": 0.0184,
      "step": 27190
    },
    {
      "epoch": 3.2771084337349397,
      "grad_norm": 2.4970033168792725,
      "learning_rate": 1.3445783132530122e-05,
      "loss": 0.0471,
      "step": 27200
    },
    {
      "epoch": 3.278313253012048,
      "grad_norm": 1.6879712343215942,
      "learning_rate": 1.3443373493975905e-05,
      "loss": 0.0275,
      "step": 27210
    },
    {
      "epoch": 3.279518072289157,
      "grad_norm": 0.01393888145685196,
      "learning_rate": 1.3440963855421686e-05,
      "loss": 0.0231,
      "step": 27220
    },
    {
      "epoch": 3.280722891566265,
      "grad_norm": 19.251577377319336,
      "learning_rate": 1.3438554216867471e-05,
      "loss": 0.0505,
      "step": 27230
    },
    {
      "epoch": 3.2819277108433735,
      "grad_norm": 0.3237236440181732,
      "learning_rate": 1.3436144578313255e-05,
      "loss": 0.016,
      "step": 27240
    },
    {
      "epoch": 3.283132530120482,
      "grad_norm": 0.006705745123326778,
      "learning_rate": 1.3433734939759038e-05,
      "loss": 0.0038,
      "step": 27250
    },
    {
      "epoch": 3.2843373493975903,
      "grad_norm": 0.37823450565338135,
      "learning_rate": 1.3431325301204821e-05,
      "loss": 0.0204,
      "step": 27260
    },
    {
      "epoch": 3.2855421686746986,
      "grad_norm": 0.0076854233630001545,
      "learning_rate": 1.3428915662650604e-05,
      "loss": 0.0175,
      "step": 27270
    },
    {
      "epoch": 3.2867469879518074,
      "grad_norm": 0.10817571729421616,
      "learning_rate": 1.3426506024096386e-05,
      "loss": 0.0589,
      "step": 27280
    },
    {
      "epoch": 3.287951807228916,
      "grad_norm": 1.6802688837051392,
      "learning_rate": 1.3424096385542169e-05,
      "loss": 0.059,
      "step": 27290
    },
    {
      "epoch": 3.289156626506024,
      "grad_norm": 0.12947793304920197,
      "learning_rate": 1.3421686746987952e-05,
      "loss": 0.0138,
      "step": 27300
    },
    {
      "epoch": 3.2903614457831325,
      "grad_norm": 0.10990133881568909,
      "learning_rate": 1.3419277108433737e-05,
      "loss": 0.0038,
      "step": 27310
    },
    {
      "epoch": 3.291566265060241,
      "grad_norm": 0.24661920964717865,
      "learning_rate": 1.341686746987952e-05,
      "loss": 0.0298,
      "step": 27320
    },
    {
      "epoch": 3.292771084337349,
      "grad_norm": 4.425362586975098,
      "learning_rate": 1.3414457831325303e-05,
      "loss": 0.0345,
      "step": 27330
    },
    {
      "epoch": 3.293975903614458,
      "grad_norm": 1.323926329612732,
      "learning_rate": 1.3412048192771086e-05,
      "loss": 0.0411,
      "step": 27340
    },
    {
      "epoch": 3.2951807228915664,
      "grad_norm": 4.15565299987793,
      "learning_rate": 1.3409638554216868e-05,
      "loss": 0.0425,
      "step": 27350
    },
    {
      "epoch": 3.2963855421686747,
      "grad_norm": 31.86351203918457,
      "learning_rate": 1.3407228915662651e-05,
      "loss": 0.0581,
      "step": 27360
    },
    {
      "epoch": 3.297590361445783,
      "grad_norm": 0.03196299448609352,
      "learning_rate": 1.3404819277108434e-05,
      "loss": 0.0298,
      "step": 27370
    },
    {
      "epoch": 3.2987951807228915,
      "grad_norm": 0.02799140103161335,
      "learning_rate": 1.3402409638554219e-05,
      "loss": 0.0603,
      "step": 27380
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.005985393188893795,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0041,
      "step": 27390
    },
    {
      "epoch": 3.3012048192771086,
      "grad_norm": 0.02873626910150051,
      "learning_rate": 1.3397590361445785e-05,
      "loss": 0.0136,
      "step": 27400
    },
    {
      "epoch": 3.302409638554217,
      "grad_norm": 4.947054862976074,
      "learning_rate": 1.3395180722891567e-05,
      "loss": 0.1232,
      "step": 27410
    },
    {
      "epoch": 3.3036144578313253,
      "grad_norm": 3.4401376247406006,
      "learning_rate": 1.339277108433735e-05,
      "loss": 0.0217,
      "step": 27420
    },
    {
      "epoch": 3.3048192771084337,
      "grad_norm": 1.808283805847168,
      "learning_rate": 1.3390361445783133e-05,
      "loss": 0.0122,
      "step": 27430
    },
    {
      "epoch": 3.306024096385542,
      "grad_norm": 0.028081832453608513,
      "learning_rate": 1.3387951807228916e-05,
      "loss": 0.0726,
      "step": 27440
    },
    {
      "epoch": 3.3072289156626504,
      "grad_norm": 0.017825612798333168,
      "learning_rate": 1.33855421686747e-05,
      "loss": 0.0128,
      "step": 27450
    },
    {
      "epoch": 3.3084337349397592,
      "grad_norm": 0.874512255191803,
      "learning_rate": 1.3383132530120484e-05,
      "loss": 0.0171,
      "step": 27460
    },
    {
      "epoch": 3.3096385542168676,
      "grad_norm": 2.0679357051849365,
      "learning_rate": 1.3380722891566268e-05,
      "loss": 0.0122,
      "step": 27470
    },
    {
      "epoch": 3.310843373493976,
      "grad_norm": 0.009246769361197948,
      "learning_rate": 1.3378313253012049e-05,
      "loss": 0.0874,
      "step": 27480
    },
    {
      "epoch": 3.3120481927710843,
      "grad_norm": 0.5831884145736694,
      "learning_rate": 1.3375903614457832e-05,
      "loss": 0.0439,
      "step": 27490
    },
    {
      "epoch": 3.3132530120481927,
      "grad_norm": 0.021293936297297478,
      "learning_rate": 1.3373493975903615e-05,
      "loss": 0.0723,
      "step": 27500
    },
    {
      "epoch": 3.314457831325301,
      "grad_norm": 0.016718314960598946,
      "learning_rate": 1.3371084337349399e-05,
      "loss": 0.0571,
      "step": 27510
    },
    {
      "epoch": 3.31566265060241,
      "grad_norm": 0.22136570513248444,
      "learning_rate": 1.3368674698795182e-05,
      "loss": 0.0593,
      "step": 27520
    },
    {
      "epoch": 3.316867469879518,
      "grad_norm": 12.164462089538574,
      "learning_rate": 1.3366265060240967e-05,
      "loss": 0.0124,
      "step": 27530
    },
    {
      "epoch": 3.3180722891566266,
      "grad_norm": 1.6404051780700684,
      "learning_rate": 1.3363855421686748e-05,
      "loss": 0.0242,
      "step": 27540
    },
    {
      "epoch": 3.319277108433735,
      "grad_norm": 4.077012538909912,
      "learning_rate": 1.3361445783132531e-05,
      "loss": 0.0422,
      "step": 27550
    },
    {
      "epoch": 3.3204819277108433,
      "grad_norm": 0.032916661351919174,
      "learning_rate": 1.3359036144578314e-05,
      "loss": 0.0369,
      "step": 27560
    },
    {
      "epoch": 3.3216867469879516,
      "grad_norm": 5.55850887298584,
      "learning_rate": 1.3356626506024098e-05,
      "loss": 0.0664,
      "step": 27570
    },
    {
      "epoch": 3.32289156626506,
      "grad_norm": 2.844066858291626,
      "learning_rate": 1.335421686746988e-05,
      "loss": 0.0092,
      "step": 27580
    },
    {
      "epoch": 3.324096385542169,
      "grad_norm": 3.9105215072631836,
      "learning_rate": 1.3351807228915662e-05,
      "loss": 0.0347,
      "step": 27590
    },
    {
      "epoch": 3.325301204819277,
      "grad_norm": 0.049457669258117676,
      "learning_rate": 1.3349397590361445e-05,
      "loss": 0.1013,
      "step": 27600
    },
    {
      "epoch": 3.3265060240963855,
      "grad_norm": 0.014256894588470459,
      "learning_rate": 1.334698795180723e-05,
      "loss": 0.0411,
      "step": 27610
    },
    {
      "epoch": 3.327710843373494,
      "grad_norm": 1.1926010847091675,
      "learning_rate": 1.3344578313253014e-05,
      "loss": 0.0313,
      "step": 27620
    },
    {
      "epoch": 3.3289156626506022,
      "grad_norm": 0.5830140113830566,
      "learning_rate": 1.3342168674698797e-05,
      "loss": 0.0585,
      "step": 27630
    },
    {
      "epoch": 3.330120481927711,
      "grad_norm": 7.692974090576172,
      "learning_rate": 1.333975903614458e-05,
      "loss": 0.0472,
      "step": 27640
    },
    {
      "epoch": 3.3313253012048194,
      "grad_norm": 0.17495670914649963,
      "learning_rate": 1.3337349397590363e-05,
      "loss": 0.03,
      "step": 27650
    },
    {
      "epoch": 3.3325301204819278,
      "grad_norm": 0.010497299022972584,
      "learning_rate": 1.3334939759036145e-05,
      "loss": 0.0336,
      "step": 27660
    },
    {
      "epoch": 3.333734939759036,
      "grad_norm": 0.4018680155277252,
      "learning_rate": 1.3332530120481928e-05,
      "loss": 0.0126,
      "step": 27670
    },
    {
      "epoch": 3.3349397590361445,
      "grad_norm": 0.023704107850790024,
      "learning_rate": 1.3330120481927713e-05,
      "loss": 0.0169,
      "step": 27680
    },
    {
      "epoch": 3.336144578313253,
      "grad_norm": 2.5366132259368896,
      "learning_rate": 1.3327710843373496e-05,
      "loss": 0.042,
      "step": 27690
    },
    {
      "epoch": 3.337349397590361,
      "grad_norm": 8.316560745239258,
      "learning_rate": 1.3325301204819279e-05,
      "loss": 0.0532,
      "step": 27700
    },
    {
      "epoch": 3.33855421686747,
      "grad_norm": 0.010344905778765678,
      "learning_rate": 1.3322891566265062e-05,
      "loss": 0.0753,
      "step": 27710
    },
    {
      "epoch": 3.3397590361445784,
      "grad_norm": 2.997180223464966,
      "learning_rate": 1.3320481927710844e-05,
      "loss": 0.0525,
      "step": 27720
    },
    {
      "epoch": 3.3409638554216867,
      "grad_norm": 1.7622805833816528,
      "learning_rate": 1.3318072289156627e-05,
      "loss": 0.0649,
      "step": 27730
    },
    {
      "epoch": 3.342168674698795,
      "grad_norm": 0.010396725498139858,
      "learning_rate": 1.331566265060241e-05,
      "loss": 0.0447,
      "step": 27740
    },
    {
      "epoch": 3.3433734939759034,
      "grad_norm": 0.1517159640789032,
      "learning_rate": 1.3313253012048193e-05,
      "loss": 0.0294,
      "step": 27750
    },
    {
      "epoch": 3.3445783132530122,
      "grad_norm": 3.5913641452789307,
      "learning_rate": 1.3310843373493978e-05,
      "loss": 0.0437,
      "step": 27760
    },
    {
      "epoch": 3.3457831325301206,
      "grad_norm": 0.008877856656908989,
      "learning_rate": 1.3308433734939761e-05,
      "loss": 0.0556,
      "step": 27770
    },
    {
      "epoch": 3.346987951807229,
      "grad_norm": 0.35375916957855225,
      "learning_rate": 1.3306024096385544e-05,
      "loss": 0.0207,
      "step": 27780
    },
    {
      "epoch": 3.3481927710843373,
      "grad_norm": 0.027929410338401794,
      "learning_rate": 1.3303614457831326e-05,
      "loss": 0.0848,
      "step": 27790
    },
    {
      "epoch": 3.3493975903614457,
      "grad_norm": 9.074398040771484,
      "learning_rate": 1.3301204819277109e-05,
      "loss": 0.073,
      "step": 27800
    },
    {
      "epoch": 3.350602409638554,
      "grad_norm": 2.1655917167663574,
      "learning_rate": 1.3298795180722892e-05,
      "loss": 0.063,
      "step": 27810
    },
    {
      "epoch": 3.3518072289156624,
      "grad_norm": 0.048010557889938354,
      "learning_rate": 1.3296385542168675e-05,
      "loss": 0.007,
      "step": 27820
    },
    {
      "epoch": 3.353012048192771,
      "grad_norm": 4.236155986785889,
      "learning_rate": 1.329397590361446e-05,
      "loss": 0.0384,
      "step": 27830
    },
    {
      "epoch": 3.3542168674698796,
      "grad_norm": 0.34342139959335327,
      "learning_rate": 1.3291566265060243e-05,
      "loss": 0.0546,
      "step": 27840
    },
    {
      "epoch": 3.355421686746988,
      "grad_norm": 4.631622314453125,
      "learning_rate": 1.3289156626506025e-05,
      "loss": 0.0501,
      "step": 27850
    },
    {
      "epoch": 3.3566265060240963,
      "grad_norm": 1.9611108303070068,
      "learning_rate": 1.3286746987951808e-05,
      "loss": 0.0073,
      "step": 27860
    },
    {
      "epoch": 3.3578313253012047,
      "grad_norm": 0.41044607758522034,
      "learning_rate": 1.3284337349397591e-05,
      "loss": 0.003,
      "step": 27870
    },
    {
      "epoch": 3.3590361445783135,
      "grad_norm": 7.531618118286133,
      "learning_rate": 1.3281927710843374e-05,
      "loss": 0.0442,
      "step": 27880
    },
    {
      "epoch": 3.360240963855422,
      "grad_norm": 0.6330341100692749,
      "learning_rate": 1.3279518072289158e-05,
      "loss": 0.0153,
      "step": 27890
    },
    {
      "epoch": 3.36144578313253,
      "grad_norm": 17.244552612304688,
      "learning_rate": 1.3277108433734939e-05,
      "loss": 0.0682,
      "step": 27900
    },
    {
      "epoch": 3.3626506024096385,
      "grad_norm": 0.0432356595993042,
      "learning_rate": 1.3274698795180726e-05,
      "loss": 0.0418,
      "step": 27910
    },
    {
      "epoch": 3.363855421686747,
      "grad_norm": 0.10491108149290085,
      "learning_rate": 1.3272289156626507e-05,
      "loss": 0.0198,
      "step": 27920
    },
    {
      "epoch": 3.3650602409638553,
      "grad_norm": 0.023906506597995758,
      "learning_rate": 1.326987951807229e-05,
      "loss": 0.0092,
      "step": 27930
    },
    {
      "epoch": 3.3662650602409636,
      "grad_norm": 3.175909996032715,
      "learning_rate": 1.3267469879518073e-05,
      "loss": 0.0241,
      "step": 27940
    },
    {
      "epoch": 3.3674698795180724,
      "grad_norm": 18.3205509185791,
      "learning_rate": 1.3265060240963857e-05,
      "loss": 0.0693,
      "step": 27950
    },
    {
      "epoch": 3.3686746987951808,
      "grad_norm": 0.41176506876945496,
      "learning_rate": 1.326265060240964e-05,
      "loss": 0.0349,
      "step": 27960
    },
    {
      "epoch": 3.369879518072289,
      "grad_norm": 0.028319407254457474,
      "learning_rate": 1.3260240963855421e-05,
      "loss": 0.0412,
      "step": 27970
    },
    {
      "epoch": 3.3710843373493975,
      "grad_norm": 0.21648737788200378,
      "learning_rate": 1.3257831325301206e-05,
      "loss": 0.0397,
      "step": 27980
    },
    {
      "epoch": 3.372289156626506,
      "grad_norm": 4.269031524658203,
      "learning_rate": 1.325542168674699e-05,
      "loss": 0.0942,
      "step": 27990
    },
    {
      "epoch": 3.3734939759036147,
      "grad_norm": 0.013464461080729961,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 0.0547,
      "step": 28000
    },
    {
      "epoch": 3.374698795180723,
      "grad_norm": 2.1852846145629883,
      "learning_rate": 1.3250602409638556e-05,
      "loss": 0.0338,
      "step": 28010
    },
    {
      "epoch": 3.3759036144578314,
      "grad_norm": 0.007754742167890072,
      "learning_rate": 1.3248192771084339e-05,
      "loss": 0.0441,
      "step": 28020
    },
    {
      "epoch": 3.3771084337349397,
      "grad_norm": 8.725412368774414,
      "learning_rate": 1.324578313253012e-05,
      "loss": 0.0344,
      "step": 28030
    },
    {
      "epoch": 3.378313253012048,
      "grad_norm": 4.562804222106934,
      "learning_rate": 1.3243373493975904e-05,
      "loss": 0.0499,
      "step": 28040
    },
    {
      "epoch": 3.3795180722891565,
      "grad_norm": 0.6250917911529541,
      "learning_rate": 1.3240963855421687e-05,
      "loss": 0.0249,
      "step": 28050
    },
    {
      "epoch": 3.380722891566265,
      "grad_norm": 0.5754408836364746,
      "learning_rate": 1.3238554216867472e-05,
      "loss": 0.0211,
      "step": 28060
    },
    {
      "epoch": 3.3819277108433736,
      "grad_norm": 0.7533466219902039,
      "learning_rate": 1.3236144578313255e-05,
      "loss": 0.0406,
      "step": 28070
    },
    {
      "epoch": 3.383132530120482,
      "grad_norm": 0.0389455184340477,
      "learning_rate": 1.3233734939759038e-05,
      "loss": 0.0604,
      "step": 28080
    },
    {
      "epoch": 3.3843373493975903,
      "grad_norm": 0.1851077675819397,
      "learning_rate": 1.3231325301204821e-05,
      "loss": 0.0275,
      "step": 28090
    },
    {
      "epoch": 3.3855421686746987,
      "grad_norm": 6.988582611083984,
      "learning_rate": 1.3228915662650603e-05,
      "loss": 0.0977,
      "step": 28100
    },
    {
      "epoch": 3.386746987951807,
      "grad_norm": 0.6965082883834839,
      "learning_rate": 1.3226506024096386e-05,
      "loss": 0.005,
      "step": 28110
    },
    {
      "epoch": 3.387951807228916,
      "grad_norm": 0.5487120151519775,
      "learning_rate": 1.3224096385542169e-05,
      "loss": 0.0216,
      "step": 28120
    },
    {
      "epoch": 3.3891566265060242,
      "grad_norm": 0.03365420177578926,
      "learning_rate": 1.3221686746987954e-05,
      "loss": 0.0013,
      "step": 28130
    },
    {
      "epoch": 3.3903614457831326,
      "grad_norm": 1.270987629890442,
      "learning_rate": 1.3219277108433737e-05,
      "loss": 0.0292,
      "step": 28140
    },
    {
      "epoch": 3.391566265060241,
      "grad_norm": 5.345776081085205,
      "learning_rate": 1.321686746987952e-05,
      "loss": 0.0929,
      "step": 28150
    },
    {
      "epoch": 3.3927710843373493,
      "grad_norm": 0.01146966777741909,
      "learning_rate": 1.3214457831325303e-05,
      "loss": 0.0256,
      "step": 28160
    },
    {
      "epoch": 3.3939759036144577,
      "grad_norm": 0.11491841077804565,
      "learning_rate": 1.3212048192771085e-05,
      "loss": 0.0541,
      "step": 28170
    },
    {
      "epoch": 3.395180722891566,
      "grad_norm": 0.004734375048428774,
      "learning_rate": 1.3209638554216868e-05,
      "loss": 0.0062,
      "step": 28180
    },
    {
      "epoch": 3.396385542168675,
      "grad_norm": 2.1403603553771973,
      "learning_rate": 1.3207228915662651e-05,
      "loss": 0.0285,
      "step": 28190
    },
    {
      "epoch": 3.397590361445783,
      "grad_norm": 0.0395415835082531,
      "learning_rate": 1.3204819277108434e-05,
      "loss": 0.0592,
      "step": 28200
    },
    {
      "epoch": 3.3987951807228916,
      "grad_norm": 5.129855155944824,
      "learning_rate": 1.320240963855422e-05,
      "loss": 0.0294,
      "step": 28210
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.14138470590114594,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.0116,
      "step": 28220
    },
    {
      "epoch": 3.4012048192771083,
      "grad_norm": 2.6529266834259033,
      "learning_rate": 1.3197590361445784e-05,
      "loss": 0.1499,
      "step": 28230
    },
    {
      "epoch": 3.402409638554217,
      "grad_norm": 0.05467459559440613,
      "learning_rate": 1.3195180722891567e-05,
      "loss": 0.0544,
      "step": 28240
    },
    {
      "epoch": 3.4036144578313254,
      "grad_norm": 0.37006914615631104,
      "learning_rate": 1.319277108433735e-05,
      "loss": 0.0551,
      "step": 28250
    },
    {
      "epoch": 3.404819277108434,
      "grad_norm": 0.0792456567287445,
      "learning_rate": 1.3190361445783133e-05,
      "loss": 0.0746,
      "step": 28260
    },
    {
      "epoch": 3.406024096385542,
      "grad_norm": 0.16683830320835114,
      "learning_rate": 1.3187951807228917e-05,
      "loss": 0.0186,
      "step": 28270
    },
    {
      "epoch": 3.4072289156626505,
      "grad_norm": 0.8432401418685913,
      "learning_rate": 1.3185542168674701e-05,
      "loss": 0.0464,
      "step": 28280
    },
    {
      "epoch": 3.408433734939759,
      "grad_norm": 6.268148899078369,
      "learning_rate": 1.3183132530120485e-05,
      "loss": 0.0575,
      "step": 28290
    },
    {
      "epoch": 3.4096385542168672,
      "grad_norm": 1.3105918169021606,
      "learning_rate": 1.3180722891566266e-05,
      "loss": 0.0789,
      "step": 28300
    },
    {
      "epoch": 3.410843373493976,
      "grad_norm": 0.27094167470932007,
      "learning_rate": 1.317831325301205e-05,
      "loss": 0.0191,
      "step": 28310
    },
    {
      "epoch": 3.4120481927710844,
      "grad_norm": 0.560129702091217,
      "learning_rate": 1.3175903614457832e-05,
      "loss": 0.0639,
      "step": 28320
    },
    {
      "epoch": 3.4132530120481928,
      "grad_norm": 0.18632175028324127,
      "learning_rate": 1.3173493975903616e-05,
      "loss": 0.0263,
      "step": 28330
    },
    {
      "epoch": 3.414457831325301,
      "grad_norm": 0.02672128565609455,
      "learning_rate": 1.3171084337349399e-05,
      "loss": 0.0472,
      "step": 28340
    },
    {
      "epoch": 3.4156626506024095,
      "grad_norm": 0.2978915572166443,
      "learning_rate": 1.316867469879518e-05,
      "loss": 0.0041,
      "step": 28350
    },
    {
      "epoch": 3.4168674698795183,
      "grad_norm": 0.010296337306499481,
      "learning_rate": 1.3166265060240965e-05,
      "loss": 0.0138,
      "step": 28360
    },
    {
      "epoch": 3.4180722891566266,
      "grad_norm": 0.9399377107620239,
      "learning_rate": 1.3163855421686748e-05,
      "loss": 0.0101,
      "step": 28370
    },
    {
      "epoch": 3.419277108433735,
      "grad_norm": 0.01790626160800457,
      "learning_rate": 1.3161445783132531e-05,
      "loss": 0.0607,
      "step": 28380
    },
    {
      "epoch": 3.4204819277108434,
      "grad_norm": 14.738484382629395,
      "learning_rate": 1.3159036144578315e-05,
      "loss": 0.0264,
      "step": 28390
    },
    {
      "epoch": 3.4216867469879517,
      "grad_norm": 0.026948697865009308,
      "learning_rate": 1.3156626506024098e-05,
      "loss": 0.0116,
      "step": 28400
    },
    {
      "epoch": 3.42289156626506,
      "grad_norm": 0.00976790115237236,
      "learning_rate": 1.315421686746988e-05,
      "loss": 0.0092,
      "step": 28410
    },
    {
      "epoch": 3.4240963855421684,
      "grad_norm": 4.3832621574401855,
      "learning_rate": 1.3151807228915662e-05,
      "loss": 0.0419,
      "step": 28420
    },
    {
      "epoch": 3.4253012048192772,
      "grad_norm": 0.008589878678321838,
      "learning_rate": 1.3149397590361447e-05,
      "loss": 0.0859,
      "step": 28430
    },
    {
      "epoch": 3.4265060240963856,
      "grad_norm": 6.66754674911499,
      "learning_rate": 1.314698795180723e-05,
      "loss": 0.0661,
      "step": 28440
    },
    {
      "epoch": 3.427710843373494,
      "grad_norm": 0.20605520904064178,
      "learning_rate": 1.3144578313253014e-05,
      "loss": 0.0262,
      "step": 28450
    },
    {
      "epoch": 3.4289156626506023,
      "grad_norm": 0.14332477748394012,
      "learning_rate": 1.3142168674698797e-05,
      "loss": 0.0124,
      "step": 28460
    },
    {
      "epoch": 3.4301204819277107,
      "grad_norm": 0.4836249053478241,
      "learning_rate": 1.313975903614458e-05,
      "loss": 0.0401,
      "step": 28470
    },
    {
      "epoch": 3.4313253012048195,
      "grad_norm": 16.460487365722656,
      "learning_rate": 1.3137349397590362e-05,
      "loss": 0.0249,
      "step": 28480
    },
    {
      "epoch": 3.432530120481928,
      "grad_norm": 0.061811696738004684,
      "learning_rate": 1.3134939759036145e-05,
      "loss": 0.0053,
      "step": 28490
    },
    {
      "epoch": 3.433734939759036,
      "grad_norm": 0.004803065210580826,
      "learning_rate": 1.3132530120481928e-05,
      "loss": 0.0053,
      "step": 28500
    },
    {
      "epoch": 3.4349397590361446,
      "grad_norm": 0.00890959333628416,
      "learning_rate": 1.3130120481927713e-05,
      "loss": 0.0187,
      "step": 28510
    },
    {
      "epoch": 3.436144578313253,
      "grad_norm": 0.0062435828149318695,
      "learning_rate": 1.3127710843373496e-05,
      "loss": 0.0819,
      "step": 28520
    },
    {
      "epoch": 3.4373493975903613,
      "grad_norm": 0.5791705846786499,
      "learning_rate": 1.3125301204819279e-05,
      "loss": 0.028,
      "step": 28530
    },
    {
      "epoch": 3.4385542168674696,
      "grad_norm": 0.12083451449871063,
      "learning_rate": 1.312289156626506e-05,
      "loss": 0.0216,
      "step": 28540
    },
    {
      "epoch": 3.4397590361445785,
      "grad_norm": 0.36275961995124817,
      "learning_rate": 1.3120481927710844e-05,
      "loss": 0.0072,
      "step": 28550
    },
    {
      "epoch": 3.440963855421687,
      "grad_norm": 0.5353622436523438,
      "learning_rate": 1.3118072289156627e-05,
      "loss": 0.0153,
      "step": 28560
    },
    {
      "epoch": 3.442168674698795,
      "grad_norm": 19.27768898010254,
      "learning_rate": 1.311566265060241e-05,
      "loss": 0.0528,
      "step": 28570
    },
    {
      "epoch": 3.4433734939759035,
      "grad_norm": 0.10302170366048813,
      "learning_rate": 1.3113253012048195e-05,
      "loss": 0.0142,
      "step": 28580
    },
    {
      "epoch": 3.444578313253012,
      "grad_norm": 0.014966496266424656,
      "learning_rate": 1.3110843373493978e-05,
      "loss": 0.0297,
      "step": 28590
    },
    {
      "epoch": 3.4457831325301207,
      "grad_norm": 0.036038994789123535,
      "learning_rate": 1.3108433734939761e-05,
      "loss": 0.0355,
      "step": 28600
    },
    {
      "epoch": 3.446987951807229,
      "grad_norm": 2.3297691345214844,
      "learning_rate": 1.3106024096385543e-05,
      "loss": 0.0729,
      "step": 28610
    },
    {
      "epoch": 3.4481927710843374,
      "grad_norm": 0.07211606204509735,
      "learning_rate": 1.3103614457831326e-05,
      "loss": 0.0383,
      "step": 28620
    },
    {
      "epoch": 3.4493975903614458,
      "grad_norm": 2.3623764514923096,
      "learning_rate": 1.310120481927711e-05,
      "loss": 0.055,
      "step": 28630
    },
    {
      "epoch": 3.450602409638554,
      "grad_norm": 0.1732424646615982,
      "learning_rate": 1.3098795180722892e-05,
      "loss": 0.0359,
      "step": 28640
    },
    {
      "epoch": 3.4518072289156625,
      "grad_norm": 0.006701824255287647,
      "learning_rate": 1.3096385542168676e-05,
      "loss": 0.0173,
      "step": 28650
    },
    {
      "epoch": 3.453012048192771,
      "grad_norm": 0.09179214388132095,
      "learning_rate": 1.309397590361446e-05,
      "loss": 0.029,
      "step": 28660
    },
    {
      "epoch": 3.4542168674698797,
      "grad_norm": 0.150554358959198,
      "learning_rate": 1.3091566265060242e-05,
      "loss": 0.0114,
      "step": 28670
    },
    {
      "epoch": 3.455421686746988,
      "grad_norm": 0.354059100151062,
      "learning_rate": 1.3089156626506025e-05,
      "loss": 0.0306,
      "step": 28680
    },
    {
      "epoch": 3.4566265060240964,
      "grad_norm": 0.008848357945680618,
      "learning_rate": 1.3086746987951808e-05,
      "loss": 0.0528,
      "step": 28690
    },
    {
      "epoch": 3.4578313253012047,
      "grad_norm": 0.09413659572601318,
      "learning_rate": 1.3084337349397591e-05,
      "loss": 0.0414,
      "step": 28700
    },
    {
      "epoch": 3.459036144578313,
      "grad_norm": 1.2227123975753784,
      "learning_rate": 1.3081927710843375e-05,
      "loss": 0.0281,
      "step": 28710
    },
    {
      "epoch": 3.460240963855422,
      "grad_norm": 0.30483299493789673,
      "learning_rate": 1.3079518072289156e-05,
      "loss": 0.0065,
      "step": 28720
    },
    {
      "epoch": 3.4614457831325303,
      "grad_norm": 0.012905599549412727,
      "learning_rate": 1.3077108433734943e-05,
      "loss": 0.0656,
      "step": 28730
    },
    {
      "epoch": 3.4626506024096386,
      "grad_norm": 0.3352210819721222,
      "learning_rate": 1.3074698795180724e-05,
      "loss": 0.0367,
      "step": 28740
    },
    {
      "epoch": 3.463855421686747,
      "grad_norm": 0.02867506444454193,
      "learning_rate": 1.3072289156626507e-05,
      "loss": 0.0918,
      "step": 28750
    },
    {
      "epoch": 3.4650602409638553,
      "grad_norm": 0.784145176410675,
      "learning_rate": 1.306987951807229e-05,
      "loss": 0.015,
      "step": 28760
    },
    {
      "epoch": 3.4662650602409637,
      "grad_norm": 2.0222597122192383,
      "learning_rate": 1.3067469879518074e-05,
      "loss": 0.0137,
      "step": 28770
    },
    {
      "epoch": 3.467469879518072,
      "grad_norm": 0.08068953454494476,
      "learning_rate": 1.3065060240963857e-05,
      "loss": 0.0383,
      "step": 28780
    },
    {
      "epoch": 3.468674698795181,
      "grad_norm": 0.7862414717674255,
      "learning_rate": 1.3062650602409638e-05,
      "loss": 0.0121,
      "step": 28790
    },
    {
      "epoch": 3.4698795180722892,
      "grad_norm": 0.007013642694801092,
      "learning_rate": 1.3060240963855421e-05,
      "loss": 0.0511,
      "step": 28800
    },
    {
      "epoch": 3.4710843373493976,
      "grad_norm": 0.007004242390394211,
      "learning_rate": 1.3057831325301206e-05,
      "loss": 0.0118,
      "step": 28810
    },
    {
      "epoch": 3.472289156626506,
      "grad_norm": 6.300299644470215,
      "learning_rate": 1.305542168674699e-05,
      "loss": 0.0145,
      "step": 28820
    },
    {
      "epoch": 3.4734939759036143,
      "grad_norm": 0.028400860726833344,
      "learning_rate": 1.3053012048192773e-05,
      "loss": 0.0216,
      "step": 28830
    },
    {
      "epoch": 3.474698795180723,
      "grad_norm": 5.240284442901611,
      "learning_rate": 1.3050602409638556e-05,
      "loss": 0.0904,
      "step": 28840
    },
    {
      "epoch": 3.4759036144578315,
      "grad_norm": 0.27246612310409546,
      "learning_rate": 1.3048192771084337e-05,
      "loss": 0.0191,
      "step": 28850
    },
    {
      "epoch": 3.47710843373494,
      "grad_norm": 0.06579887121915817,
      "learning_rate": 1.304578313253012e-05,
      "loss": 0.0314,
      "step": 28860
    },
    {
      "epoch": 3.478313253012048,
      "grad_norm": 0.047115445137023926,
      "learning_rate": 1.3043373493975904e-05,
      "loss": 0.023,
      "step": 28870
    },
    {
      "epoch": 3.4795180722891565,
      "grad_norm": 0.016753874719142914,
      "learning_rate": 1.3040963855421689e-05,
      "loss": 0.0325,
      "step": 28880
    },
    {
      "epoch": 3.480722891566265,
      "grad_norm": 0.009578597731888294,
      "learning_rate": 1.3038554216867472e-05,
      "loss": 0.0121,
      "step": 28890
    },
    {
      "epoch": 3.4819277108433733,
      "grad_norm": 0.3104099929332733,
      "learning_rate": 1.3036144578313255e-05,
      "loss": 0.0253,
      "step": 28900
    },
    {
      "epoch": 3.483132530120482,
      "grad_norm": 0.007938596419990063,
      "learning_rate": 1.3033734939759038e-05,
      "loss": 0.0251,
      "step": 28910
    },
    {
      "epoch": 3.4843373493975904,
      "grad_norm": 4.466325283050537,
      "learning_rate": 1.303132530120482e-05,
      "loss": 0.0644,
      "step": 28920
    },
    {
      "epoch": 3.485542168674699,
      "grad_norm": 0.1815142184495926,
      "learning_rate": 1.3028915662650603e-05,
      "loss": 0.0558,
      "step": 28930
    },
    {
      "epoch": 3.486746987951807,
      "grad_norm": 3.401340961456299,
      "learning_rate": 1.3026506024096386e-05,
      "loss": 0.0472,
      "step": 28940
    },
    {
      "epoch": 3.4879518072289155,
      "grad_norm": 7.789495944976807,
      "learning_rate": 1.3024096385542169e-05,
      "loss": 0.0426,
      "step": 28950
    },
    {
      "epoch": 3.4891566265060243,
      "grad_norm": 3.8167591094970703,
      "learning_rate": 1.3021686746987954e-05,
      "loss": 0.0401,
      "step": 28960
    },
    {
      "epoch": 3.4903614457831327,
      "grad_norm": 0.04479756951332092,
      "learning_rate": 1.3019277108433737e-05,
      "loss": 0.0185,
      "step": 28970
    },
    {
      "epoch": 3.491566265060241,
      "grad_norm": 5.003453254699707,
      "learning_rate": 1.3016867469879519e-05,
      "loss": 0.0513,
      "step": 28980
    },
    {
      "epoch": 3.4927710843373494,
      "grad_norm": 0.018934687599539757,
      "learning_rate": 1.3014457831325302e-05,
      "loss": 0.0422,
      "step": 28990
    },
    {
      "epoch": 3.4939759036144578,
      "grad_norm": 0.023826632648706436,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 0.0018,
      "step": 29000
    },
    {
      "epoch": 3.495180722891566,
      "grad_norm": 6.314703464508057,
      "learning_rate": 1.3009638554216868e-05,
      "loss": 0.0403,
      "step": 29010
    },
    {
      "epoch": 3.4963855421686745,
      "grad_norm": 0.3347603380680084,
      "learning_rate": 1.3007228915662651e-05,
      "loss": 0.0231,
      "step": 29020
    },
    {
      "epoch": 3.4975903614457833,
      "grad_norm": 6.0619215965271,
      "learning_rate": 1.3004819277108436e-05,
      "loss": 0.0515,
      "step": 29030
    },
    {
      "epoch": 3.4987951807228916,
      "grad_norm": 3.8565430641174316,
      "learning_rate": 1.300240963855422e-05,
      "loss": 0.0791,
      "step": 29040
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.7145459651947021,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0121,
      "step": 29050
    },
    {
      "epoch": 3.5012048192771084,
      "grad_norm": 135.42205810546875,
      "learning_rate": 1.2997590361445784e-05,
      "loss": 0.0276,
      "step": 29060
    },
    {
      "epoch": 3.5024096385542167,
      "grad_norm": 2.851485252380371,
      "learning_rate": 1.2995180722891567e-05,
      "loss": 0.0121,
      "step": 29070
    },
    {
      "epoch": 3.5036144578313255,
      "grad_norm": 4.306325435638428,
      "learning_rate": 1.299277108433735e-05,
      "loss": 0.0721,
      "step": 29080
    },
    {
      "epoch": 3.504819277108434,
      "grad_norm": 1.9732824563980103,
      "learning_rate": 1.2990361445783134e-05,
      "loss": 0.0307,
      "step": 29090
    },
    {
      "epoch": 3.5060240963855422,
      "grad_norm": 0.08309600502252579,
      "learning_rate": 1.2987951807228915e-05,
      "loss": 0.0121,
      "step": 29100
    },
    {
      "epoch": 3.5072289156626506,
      "grad_norm": 8.351017951965332,
      "learning_rate": 1.29855421686747e-05,
      "loss": 0.0575,
      "step": 29110
    },
    {
      "epoch": 3.508433734939759,
      "grad_norm": 0.028639448806643486,
      "learning_rate": 1.2983132530120483e-05,
      "loss": 0.0336,
      "step": 29120
    },
    {
      "epoch": 3.5096385542168673,
      "grad_norm": 0.263590544462204,
      "learning_rate": 1.2980722891566266e-05,
      "loss": 0.0343,
      "step": 29130
    },
    {
      "epoch": 3.5108433734939757,
      "grad_norm": 0.026720114052295685,
      "learning_rate": 1.297831325301205e-05,
      "loss": 0.0106,
      "step": 29140
    },
    {
      "epoch": 3.5120481927710845,
      "grad_norm": 0.5904986262321472,
      "learning_rate": 1.2975903614457833e-05,
      "loss": 0.0242,
      "step": 29150
    },
    {
      "epoch": 3.513253012048193,
      "grad_norm": 2.1330416202545166,
      "learning_rate": 1.2973493975903614e-05,
      "loss": 0.0039,
      "step": 29160
    },
    {
      "epoch": 3.514457831325301,
      "grad_norm": 6.037150859832764,
      "learning_rate": 1.2971084337349397e-05,
      "loss": 0.0706,
      "step": 29170
    },
    {
      "epoch": 3.5156626506024096,
      "grad_norm": 0.01781208999454975,
      "learning_rate": 1.2968674698795182e-05,
      "loss": 0.023,
      "step": 29180
    },
    {
      "epoch": 3.516867469879518,
      "grad_norm": 0.019814005121588707,
      "learning_rate": 1.2966265060240965e-05,
      "loss": 0.0259,
      "step": 29190
    },
    {
      "epoch": 3.5180722891566267,
      "grad_norm": 0.005996211897581816,
      "learning_rate": 1.2963855421686749e-05,
      "loss": 0.0644,
      "step": 29200
    },
    {
      "epoch": 3.519277108433735,
      "grad_norm": 3.2419562339782715,
      "learning_rate": 1.2961445783132532e-05,
      "loss": 0.0294,
      "step": 29210
    },
    {
      "epoch": 3.5204819277108435,
      "grad_norm": 2.3618457317352295,
      "learning_rate": 1.2959036144578315e-05,
      "loss": 0.0654,
      "step": 29220
    },
    {
      "epoch": 3.521686746987952,
      "grad_norm": 0.5112752914428711,
      "learning_rate": 1.2956626506024096e-05,
      "loss": 0.0334,
      "step": 29230
    },
    {
      "epoch": 3.52289156626506,
      "grad_norm": 0.006662529427558184,
      "learning_rate": 1.295421686746988e-05,
      "loss": 0.0073,
      "step": 29240
    },
    {
      "epoch": 3.5240963855421685,
      "grad_norm": 0.005791204050183296,
      "learning_rate": 1.2951807228915663e-05,
      "loss": 0.0116,
      "step": 29250
    },
    {
      "epoch": 3.525301204819277,
      "grad_norm": 0.025394989177584648,
      "learning_rate": 1.2949397590361448e-05,
      "loss": 0.0164,
      "step": 29260
    },
    {
      "epoch": 3.5265060240963857,
      "grad_norm": 34.883060455322266,
      "learning_rate": 1.294698795180723e-05,
      "loss": 0.0489,
      "step": 29270
    },
    {
      "epoch": 3.527710843373494,
      "grad_norm": 4.165473461151123,
      "learning_rate": 1.2944578313253014e-05,
      "loss": 0.0487,
      "step": 29280
    },
    {
      "epoch": 3.5289156626506024,
      "grad_norm": 0.8556689620018005,
      "learning_rate": 1.2942168674698795e-05,
      "loss": 0.0837,
      "step": 29290
    },
    {
      "epoch": 3.5301204819277108,
      "grad_norm": 2.0343494415283203,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 0.0675,
      "step": 29300
    },
    {
      "epoch": 3.531325301204819,
      "grad_norm": 9.027592658996582,
      "learning_rate": 1.2937349397590362e-05,
      "loss": 0.0264,
      "step": 29310
    },
    {
      "epoch": 3.532530120481928,
      "grad_norm": 0.011221934109926224,
      "learning_rate": 1.2934939759036145e-05,
      "loss": 0.0063,
      "step": 29320
    },
    {
      "epoch": 3.5337349397590363,
      "grad_norm": 5.785611152648926,
      "learning_rate": 1.293253012048193e-05,
      "loss": 0.0452,
      "step": 29330
    },
    {
      "epoch": 3.5349397590361447,
      "grad_norm": 0.012221737764775753,
      "learning_rate": 1.2930120481927713e-05,
      "loss": 0.009,
      "step": 29340
    },
    {
      "epoch": 3.536144578313253,
      "grad_norm": 2.342172622680664,
      "learning_rate": 1.2927710843373496e-05,
      "loss": 0.0913,
      "step": 29350
    },
    {
      "epoch": 3.5373493975903614,
      "grad_norm": 14.858146667480469,
      "learning_rate": 1.2925301204819278e-05,
      "loss": 0.0962,
      "step": 29360
    },
    {
      "epoch": 3.5385542168674697,
      "grad_norm": 3.164134979248047,
      "learning_rate": 1.292289156626506e-05,
      "loss": 0.0777,
      "step": 29370
    },
    {
      "epoch": 3.539759036144578,
      "grad_norm": 0.9718936085700989,
      "learning_rate": 1.2920481927710844e-05,
      "loss": 0.0512,
      "step": 29380
    },
    {
      "epoch": 3.540963855421687,
      "grad_norm": 0.04517720267176628,
      "learning_rate": 1.2918072289156627e-05,
      "loss": 0.0219,
      "step": 29390
    },
    {
      "epoch": 3.5421686746987953,
      "grad_norm": 0.4714192748069763,
      "learning_rate": 1.291566265060241e-05,
      "loss": 0.0677,
      "step": 29400
    },
    {
      "epoch": 3.5433734939759036,
      "grad_norm": 3.1721272468566895,
      "learning_rate": 1.2913253012048195e-05,
      "loss": 0.0119,
      "step": 29410
    },
    {
      "epoch": 3.544578313253012,
      "grad_norm": 1.0814698934555054,
      "learning_rate": 1.2910843373493977e-05,
      "loss": 0.0289,
      "step": 29420
    },
    {
      "epoch": 3.5457831325301203,
      "grad_norm": 0.4308742880821228,
      "learning_rate": 1.290843373493976e-05,
      "loss": 0.01,
      "step": 29430
    },
    {
      "epoch": 3.546987951807229,
      "grad_norm": 0.03326849639415741,
      "learning_rate": 1.2906024096385543e-05,
      "loss": 0.0333,
      "step": 29440
    },
    {
      "epoch": 3.5481927710843375,
      "grad_norm": 0.8471963405609131,
      "learning_rate": 1.2903614457831326e-05,
      "loss": 0.012,
      "step": 29450
    },
    {
      "epoch": 3.549397590361446,
      "grad_norm": 0.060639381408691406,
      "learning_rate": 1.290120481927711e-05,
      "loss": 0.0402,
      "step": 29460
    },
    {
      "epoch": 3.5506024096385542,
      "grad_norm": 0.030881613492965698,
      "learning_rate": 1.2898795180722891e-05,
      "loss": 0.0361,
      "step": 29470
    },
    {
      "epoch": 3.5518072289156626,
      "grad_norm": 0.2356913983821869,
      "learning_rate": 1.2896385542168677e-05,
      "loss": 0.1315,
      "step": 29480
    },
    {
      "epoch": 3.553012048192771,
      "grad_norm": 0.3047671318054199,
      "learning_rate": 1.2893975903614459e-05,
      "loss": 0.0196,
      "step": 29490
    },
    {
      "epoch": 3.5542168674698793,
      "grad_norm": 2.7771658897399902,
      "learning_rate": 1.2891566265060242e-05,
      "loss": 0.0719,
      "step": 29500
    },
    {
      "epoch": 3.555421686746988,
      "grad_norm": 0.04451251029968262,
      "learning_rate": 1.2889156626506025e-05,
      "loss": 0.0272,
      "step": 29510
    },
    {
      "epoch": 3.5566265060240965,
      "grad_norm": 0.14897823333740234,
      "learning_rate": 1.2886746987951808e-05,
      "loss": 0.0212,
      "step": 29520
    },
    {
      "epoch": 3.557831325301205,
      "grad_norm": 0.7697924375534058,
      "learning_rate": 1.2884337349397592e-05,
      "loss": 0.03,
      "step": 29530
    },
    {
      "epoch": 3.559036144578313,
      "grad_norm": 0.03732594475150108,
      "learning_rate": 1.2881927710843373e-05,
      "loss": 0.0601,
      "step": 29540
    },
    {
      "epoch": 3.5602409638554215,
      "grad_norm": 0.037319116294384,
      "learning_rate": 1.2879518072289156e-05,
      "loss": 0.0199,
      "step": 29550
    },
    {
      "epoch": 3.5614457831325304,
      "grad_norm": 2.7707176208496094,
      "learning_rate": 1.2877108433734941e-05,
      "loss": 0.0397,
      "step": 29560
    },
    {
      "epoch": 3.5626506024096387,
      "grad_norm": 0.028144702315330505,
      "learning_rate": 1.2874698795180724e-05,
      "loss": 0.0118,
      "step": 29570
    },
    {
      "epoch": 3.563855421686747,
      "grad_norm": 0.018669700250029564,
      "learning_rate": 1.2872289156626508e-05,
      "loss": 0.0692,
      "step": 29580
    },
    {
      "epoch": 3.5650602409638554,
      "grad_norm": 0.2694469392299652,
      "learning_rate": 1.286987951807229e-05,
      "loss": 0.0262,
      "step": 29590
    },
    {
      "epoch": 3.566265060240964,
      "grad_norm": 0.029802776873111725,
      "learning_rate": 1.2867469879518072e-05,
      "loss": 0.0041,
      "step": 29600
    },
    {
      "epoch": 3.567469879518072,
      "grad_norm": 0.30964016914367676,
      "learning_rate": 1.2865060240963855e-05,
      "loss": 0.0163,
      "step": 29610
    },
    {
      "epoch": 3.5686746987951805,
      "grad_norm": 0.17564846575260162,
      "learning_rate": 1.2862650602409639e-05,
      "loss": 0.0348,
      "step": 29620
    },
    {
      "epoch": 3.5698795180722893,
      "grad_norm": 0.036140769720077515,
      "learning_rate": 1.2860240963855423e-05,
      "loss": 0.1118,
      "step": 29630
    },
    {
      "epoch": 3.5710843373493977,
      "grad_norm": 1.8739852905273438,
      "learning_rate": 1.2857831325301207e-05,
      "loss": 0.0391,
      "step": 29640
    },
    {
      "epoch": 3.572289156626506,
      "grad_norm": 0.016970502212643623,
      "learning_rate": 1.285542168674699e-05,
      "loss": 0.0009,
      "step": 29650
    },
    {
      "epoch": 3.5734939759036144,
      "grad_norm": 6.628688335418701,
      "learning_rate": 1.2853012048192773e-05,
      "loss": 0.033,
      "step": 29660
    },
    {
      "epoch": 3.5746987951807228,
      "grad_norm": 0.018216567113995552,
      "learning_rate": 1.2850602409638554e-05,
      "loss": 0.0202,
      "step": 29670
    },
    {
      "epoch": 3.5759036144578316,
      "grad_norm": 0.7871959805488586,
      "learning_rate": 1.2848192771084338e-05,
      "loss": 0.0313,
      "step": 29680
    },
    {
      "epoch": 3.57710843373494,
      "grad_norm": 1.8116416931152344,
      "learning_rate": 1.284578313253012e-05,
      "loss": 0.0372,
      "step": 29690
    },
    {
      "epoch": 3.5783132530120483,
      "grad_norm": 0.0325128436088562,
      "learning_rate": 1.2843373493975904e-05,
      "loss": 0.0016,
      "step": 29700
    },
    {
      "epoch": 3.5795180722891566,
      "grad_norm": 0.33231425285339355,
      "learning_rate": 1.2840963855421689e-05,
      "loss": 0.0259,
      "step": 29710
    },
    {
      "epoch": 3.580722891566265,
      "grad_norm": 2.9023141860961914,
      "learning_rate": 1.2838554216867472e-05,
      "loss": 0.1104,
      "step": 29720
    },
    {
      "epoch": 3.5819277108433734,
      "grad_norm": 9.771492004394531,
      "learning_rate": 1.2836144578313255e-05,
      "loss": 0.0559,
      "step": 29730
    },
    {
      "epoch": 3.5831325301204817,
      "grad_norm": 0.0076160067692399025,
      "learning_rate": 1.2833734939759037e-05,
      "loss": 0.0701,
      "step": 29740
    },
    {
      "epoch": 3.5843373493975905,
      "grad_norm": 0.06622821092605591,
      "learning_rate": 1.283132530120482e-05,
      "loss": 0.0073,
      "step": 29750
    },
    {
      "epoch": 3.585542168674699,
      "grad_norm": 0.12208317220211029,
      "learning_rate": 1.2828915662650603e-05,
      "loss": 0.0391,
      "step": 29760
    },
    {
      "epoch": 3.5867469879518072,
      "grad_norm": 6.174439907073975,
      "learning_rate": 1.2826506024096386e-05,
      "loss": 0.0249,
      "step": 29770
    },
    {
      "epoch": 3.5879518072289156,
      "grad_norm": 0.07669341564178467,
      "learning_rate": 1.2824096385542171e-05,
      "loss": 0.0084,
      "step": 29780
    },
    {
      "epoch": 3.589156626506024,
      "grad_norm": 1.883729338645935,
      "learning_rate": 1.2821686746987954e-05,
      "loss": 0.0459,
      "step": 29790
    },
    {
      "epoch": 3.5903614457831328,
      "grad_norm": 80.08917999267578,
      "learning_rate": 1.2819277108433736e-05,
      "loss": 0.0509,
      "step": 29800
    },
    {
      "epoch": 3.591566265060241,
      "grad_norm": 0.02528442069888115,
      "learning_rate": 1.2816867469879519e-05,
      "loss": 0.0216,
      "step": 29810
    },
    {
      "epoch": 3.5927710843373495,
      "grad_norm": 0.1086808517575264,
      "learning_rate": 1.2814457831325302e-05,
      "loss": 0.016,
      "step": 29820
    },
    {
      "epoch": 3.593975903614458,
      "grad_norm": 0.1248544231057167,
      "learning_rate": 1.2812048192771085e-05,
      "loss": 0.0033,
      "step": 29830
    },
    {
      "epoch": 3.595180722891566,
      "grad_norm": 9.479004859924316,
      "learning_rate": 1.2809638554216868e-05,
      "loss": 0.0451,
      "step": 29840
    },
    {
      "epoch": 3.5963855421686746,
      "grad_norm": 2.435084342956543,
      "learning_rate": 1.280722891566265e-05,
      "loss": 0.0426,
      "step": 29850
    },
    {
      "epoch": 3.597590361445783,
      "grad_norm": 1.084380030632019,
      "learning_rate": 1.2804819277108436e-05,
      "loss": 0.0202,
      "step": 29860
    },
    {
      "epoch": 3.5987951807228917,
      "grad_norm": 0.00793271791189909,
      "learning_rate": 1.2802409638554218e-05,
      "loss": 0.008,
      "step": 29870
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.009793028235435486,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0268,
      "step": 29880
    },
    {
      "epoch": 3.6012048192771084,
      "grad_norm": 0.02243667095899582,
      "learning_rate": 1.2797590361445784e-05,
      "loss": 0.0525,
      "step": 29890
    },
    {
      "epoch": 3.602409638554217,
      "grad_norm": 1.793021321296692,
      "learning_rate": 1.2795180722891567e-05,
      "loss": 0.0457,
      "step": 29900
    },
    {
      "epoch": 3.603614457831325,
      "grad_norm": 0.02228156477212906,
      "learning_rate": 1.279277108433735e-05,
      "loss": 0.0519,
      "step": 29910
    },
    {
      "epoch": 3.604819277108434,
      "grad_norm": 0.01786162331700325,
      "learning_rate": 1.2790361445783132e-05,
      "loss": 0.0325,
      "step": 29920
    },
    {
      "epoch": 3.6060240963855423,
      "grad_norm": 0.609359622001648,
      "learning_rate": 1.2787951807228917e-05,
      "loss": 0.0475,
      "step": 29930
    },
    {
      "epoch": 3.6072289156626507,
      "grad_norm": 0.012370932847261429,
      "learning_rate": 1.27855421686747e-05,
      "loss": 0.0327,
      "step": 29940
    },
    {
      "epoch": 3.608433734939759,
      "grad_norm": 0.008164927363395691,
      "learning_rate": 1.2783132530120483e-05,
      "loss": 0.0246,
      "step": 29950
    },
    {
      "epoch": 3.6096385542168674,
      "grad_norm": 0.009125536307692528,
      "learning_rate": 1.2780722891566267e-05,
      "loss": 0.0452,
      "step": 29960
    },
    {
      "epoch": 3.6108433734939758,
      "grad_norm": 0.9395864009857178,
      "learning_rate": 1.277831325301205e-05,
      "loss": 0.0457,
      "step": 29970
    },
    {
      "epoch": 3.612048192771084,
      "grad_norm": 0.060041576623916626,
      "learning_rate": 1.2775903614457831e-05,
      "loss": 0.0616,
      "step": 29980
    },
    {
      "epoch": 3.613253012048193,
      "grad_norm": 0.036459632217884064,
      "learning_rate": 1.2773493975903614e-05,
      "loss": 0.0812,
      "step": 29990
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 0.9581753611564636,
      "learning_rate": 1.2771084337349398e-05,
      "loss": 0.0136,
      "step": 30000
    },
    {
      "epoch": 3.6156626506024097,
      "grad_norm": 0.23930442333221436,
      "learning_rate": 1.2768674698795182e-05,
      "loss": 0.0288,
      "step": 30010
    },
    {
      "epoch": 3.616867469879518,
      "grad_norm": 0.015378400683403015,
      "learning_rate": 1.2766265060240966e-05,
      "loss": 0.052,
      "step": 30020
    },
    {
      "epoch": 3.6180722891566264,
      "grad_norm": 0.010547407902777195,
      "learning_rate": 1.2763855421686749e-05,
      "loss": 0.0592,
      "step": 30030
    },
    {
      "epoch": 3.619277108433735,
      "grad_norm": 1.5839816331863403,
      "learning_rate": 1.2761445783132532e-05,
      "loss": 0.0267,
      "step": 30040
    },
    {
      "epoch": 3.6204819277108435,
      "grad_norm": 0.17665411531925201,
      "learning_rate": 1.2759036144578313e-05,
      "loss": 0.0029,
      "step": 30050
    },
    {
      "epoch": 3.621686746987952,
      "grad_norm": 0.44260117411613464,
      "learning_rate": 1.2756626506024097e-05,
      "loss": 0.0288,
      "step": 30060
    },
    {
      "epoch": 3.6228915662650603,
      "grad_norm": 0.3911874294281006,
      "learning_rate": 1.275421686746988e-05,
      "loss": 0.0624,
      "step": 30070
    },
    {
      "epoch": 3.6240963855421686,
      "grad_norm": 0.12404879927635193,
      "learning_rate": 1.2751807228915665e-05,
      "loss": 0.0214,
      "step": 30080
    },
    {
      "epoch": 3.625301204819277,
      "grad_norm": 2.683302402496338,
      "learning_rate": 1.2749397590361448e-05,
      "loss": 0.0273,
      "step": 30090
    },
    {
      "epoch": 3.6265060240963853,
      "grad_norm": 1.7712196111679077,
      "learning_rate": 1.2746987951807231e-05,
      "loss": 0.043,
      "step": 30100
    },
    {
      "epoch": 3.627710843373494,
      "grad_norm": 0.1761343628168106,
      "learning_rate": 1.2744578313253012e-05,
      "loss": 0.0127,
      "step": 30110
    },
    {
      "epoch": 3.6289156626506025,
      "grad_norm": 0.5717148780822754,
      "learning_rate": 1.2742168674698796e-05,
      "loss": 0.02,
      "step": 30120
    },
    {
      "epoch": 3.630120481927711,
      "grad_norm": 1.3198000192642212,
      "learning_rate": 1.2739759036144579e-05,
      "loss": 0.0533,
      "step": 30130
    },
    {
      "epoch": 3.6313253012048192,
      "grad_norm": 0.1564217507839203,
      "learning_rate": 1.2737349397590362e-05,
      "loss": 0.0362,
      "step": 30140
    },
    {
      "epoch": 3.6325301204819276,
      "grad_norm": 0.010403311811387539,
      "learning_rate": 1.2734939759036145e-05,
      "loss": 0.0024,
      "step": 30150
    },
    {
      "epoch": 3.6337349397590364,
      "grad_norm": 3.8842220306396484,
      "learning_rate": 1.273253012048193e-05,
      "loss": 0.0959,
      "step": 30160
    },
    {
      "epoch": 3.6349397590361443,
      "grad_norm": 0.9717352390289307,
      "learning_rate": 1.2730120481927713e-05,
      "loss": 0.0055,
      "step": 30170
    },
    {
      "epoch": 3.636144578313253,
      "grad_norm": 0.3029310405254364,
      "learning_rate": 1.2727710843373495e-05,
      "loss": 0.003,
      "step": 30180
    },
    {
      "epoch": 3.6373493975903615,
      "grad_norm": 0.013820304535329342,
      "learning_rate": 1.2725301204819278e-05,
      "loss": 0.0599,
      "step": 30190
    },
    {
      "epoch": 3.63855421686747,
      "grad_norm": 0.0734616294503212,
      "learning_rate": 1.2722891566265061e-05,
      "loss": 0.0183,
      "step": 30200
    },
    {
      "epoch": 3.639759036144578,
      "grad_norm": 0.027990490198135376,
      "learning_rate": 1.2720481927710844e-05,
      "loss": 0.0187,
      "step": 30210
    },
    {
      "epoch": 3.6409638554216865,
      "grad_norm": 0.300205796957016,
      "learning_rate": 1.2718072289156627e-05,
      "loss": 0.0371,
      "step": 30220
    },
    {
      "epoch": 3.6421686746987953,
      "grad_norm": 0.12173742800951004,
      "learning_rate": 1.2715662650602412e-05,
      "loss": 0.0162,
      "step": 30230
    },
    {
      "epoch": 3.6433734939759037,
      "grad_norm": 0.04042304307222366,
      "learning_rate": 1.2713253012048194e-05,
      "loss": 0.0362,
      "step": 30240
    },
    {
      "epoch": 3.644578313253012,
      "grad_norm": 2.5363588333129883,
      "learning_rate": 1.2710843373493977e-05,
      "loss": 0.0626,
      "step": 30250
    },
    {
      "epoch": 3.6457831325301204,
      "grad_norm": 11.871355056762695,
      "learning_rate": 1.270843373493976e-05,
      "loss": 0.0251,
      "step": 30260
    },
    {
      "epoch": 3.646987951807229,
      "grad_norm": 0.15970934927463531,
      "learning_rate": 1.2706024096385543e-05,
      "loss": 0.0379,
      "step": 30270
    },
    {
      "epoch": 3.6481927710843376,
      "grad_norm": 0.02448679320514202,
      "learning_rate": 1.2703614457831326e-05,
      "loss": 0.0006,
      "step": 30280
    },
    {
      "epoch": 3.6493975903614455,
      "grad_norm": 0.08323285728693008,
      "learning_rate": 1.2701204819277108e-05,
      "loss": 0.0287,
      "step": 30290
    },
    {
      "epoch": 3.6506024096385543,
      "grad_norm": 0.012184490449726582,
      "learning_rate": 1.2698795180722891e-05,
      "loss": 0.0475,
      "step": 30300
    },
    {
      "epoch": 3.6518072289156627,
      "grad_norm": 0.009378848597407341,
      "learning_rate": 1.2696385542168676e-05,
      "loss": 0.048,
      "step": 30310
    },
    {
      "epoch": 3.653012048192771,
      "grad_norm": 2.0924885272979736,
      "learning_rate": 1.269397590361446e-05,
      "loss": 0.0448,
      "step": 30320
    },
    {
      "epoch": 3.6542168674698794,
      "grad_norm": 0.3949466347694397,
      "learning_rate": 1.2691566265060242e-05,
      "loss": 0.0507,
      "step": 30330
    },
    {
      "epoch": 3.6554216867469878,
      "grad_norm": 0.00949099101126194,
      "learning_rate": 1.2689156626506026e-05,
      "loss": 0.0245,
      "step": 30340
    },
    {
      "epoch": 3.6566265060240966,
      "grad_norm": 0.03743062913417816,
      "learning_rate": 1.2686746987951809e-05,
      "loss": 0.0149,
      "step": 30350
    },
    {
      "epoch": 3.657831325301205,
      "grad_norm": 2.1904168128967285,
      "learning_rate": 1.268433734939759e-05,
      "loss": 0.0383,
      "step": 30360
    },
    {
      "epoch": 3.6590361445783133,
      "grad_norm": 40.809024810791016,
      "learning_rate": 1.2681927710843373e-05,
      "loss": 0.0377,
      "step": 30370
    },
    {
      "epoch": 3.6602409638554216,
      "grad_norm": 0.10008454322814941,
      "learning_rate": 1.2679518072289158e-05,
      "loss": 0.0327,
      "step": 30380
    },
    {
      "epoch": 3.66144578313253,
      "grad_norm": 0.6846032738685608,
      "learning_rate": 1.2677108433734941e-05,
      "loss": 0.041,
      "step": 30390
    },
    {
      "epoch": 3.662650602409639,
      "grad_norm": 4.181490421295166,
      "learning_rate": 1.2674698795180725e-05,
      "loss": 0.057,
      "step": 30400
    },
    {
      "epoch": 3.6638554216867467,
      "grad_norm": 1.8137091398239136,
      "learning_rate": 1.2672289156626508e-05,
      "loss": 0.0065,
      "step": 30410
    },
    {
      "epoch": 3.6650602409638555,
      "grad_norm": 0.20126283168792725,
      "learning_rate": 1.266987951807229e-05,
      "loss": 0.0458,
      "step": 30420
    },
    {
      "epoch": 3.666265060240964,
      "grad_norm": 0.054580915719270706,
      "learning_rate": 1.2667469879518072e-05,
      "loss": 0.0308,
      "step": 30430
    },
    {
      "epoch": 3.6674698795180722,
      "grad_norm": 0.09481514245271683,
      "learning_rate": 1.2665060240963856e-05,
      "loss": 0.0232,
      "step": 30440
    },
    {
      "epoch": 3.6686746987951806,
      "grad_norm": 0.49979132413864136,
      "learning_rate": 1.2662650602409639e-05,
      "loss": 0.0653,
      "step": 30450
    },
    {
      "epoch": 3.669879518072289,
      "grad_norm": 0.052237965166568756,
      "learning_rate": 1.2660240963855424e-05,
      "loss": 0.0209,
      "step": 30460
    },
    {
      "epoch": 3.6710843373493978,
      "grad_norm": 0.08429304510354996,
      "learning_rate": 1.2657831325301207e-05,
      "loss": 0.0332,
      "step": 30470
    },
    {
      "epoch": 3.672289156626506,
      "grad_norm": 24.503530502319336,
      "learning_rate": 1.265542168674699e-05,
      "loss": 0.0323,
      "step": 30480
    },
    {
      "epoch": 3.6734939759036145,
      "grad_norm": 0.007871299050748348,
      "learning_rate": 1.2653012048192771e-05,
      "loss": 0.0376,
      "step": 30490
    },
    {
      "epoch": 3.674698795180723,
      "grad_norm": 0.01733483374118805,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 0.0233,
      "step": 30500
    },
    {
      "epoch": 3.675903614457831,
      "grad_norm": 1.907164454460144,
      "learning_rate": 1.2648192771084338e-05,
      "loss": 0.0193,
      "step": 30510
    },
    {
      "epoch": 3.67710843373494,
      "grad_norm": 13.606273651123047,
      "learning_rate": 1.2645783132530121e-05,
      "loss": 0.0543,
      "step": 30520
    },
    {
      "epoch": 3.678313253012048,
      "grad_norm": 4.284923076629639,
      "learning_rate": 1.2643373493975906e-05,
      "loss": 0.0184,
      "step": 30530
    },
    {
      "epoch": 3.6795180722891567,
      "grad_norm": 0.779276967048645,
      "learning_rate": 1.2640963855421689e-05,
      "loss": 0.0321,
      "step": 30540
    },
    {
      "epoch": 3.680722891566265,
      "grad_norm": 0.015777278691530228,
      "learning_rate": 1.263855421686747e-05,
      "loss": 0.021,
      "step": 30550
    },
    {
      "epoch": 3.6819277108433734,
      "grad_norm": 2.006943702697754,
      "learning_rate": 1.2636144578313254e-05,
      "loss": 0.0173,
      "step": 30560
    },
    {
      "epoch": 3.683132530120482,
      "grad_norm": 19.154645919799805,
      "learning_rate": 1.2633734939759037e-05,
      "loss": 0.0385,
      "step": 30570
    },
    {
      "epoch": 3.68433734939759,
      "grad_norm": 0.055259693413972855,
      "learning_rate": 1.263132530120482e-05,
      "loss": 0.0646,
      "step": 30580
    },
    {
      "epoch": 3.685542168674699,
      "grad_norm": 0.12368974089622498,
      "learning_rate": 1.2628915662650603e-05,
      "loss": 0.0365,
      "step": 30590
    },
    {
      "epoch": 3.6867469879518073,
      "grad_norm": 4.098474025726318,
      "learning_rate": 1.2626506024096385e-05,
      "loss": 0.0592,
      "step": 30600
    },
    {
      "epoch": 3.6879518072289157,
      "grad_norm": 9.541128158569336,
      "learning_rate": 1.2624096385542171e-05,
      "loss": 0.0354,
      "step": 30610
    },
    {
      "epoch": 3.689156626506024,
      "grad_norm": 0.0046666450798511505,
      "learning_rate": 1.2621686746987953e-05,
      "loss": 0.0018,
      "step": 30620
    },
    {
      "epoch": 3.6903614457831324,
      "grad_norm": 4.277450084686279,
      "learning_rate": 1.2619277108433736e-05,
      "loss": 0.0759,
      "step": 30630
    },
    {
      "epoch": 3.691566265060241,
      "grad_norm": 0.01787121593952179,
      "learning_rate": 1.2616867469879519e-05,
      "loss": 0.0598,
      "step": 30640
    },
    {
      "epoch": 3.692771084337349,
      "grad_norm": 0.08807399123907089,
      "learning_rate": 1.2614457831325302e-05,
      "loss": 0.0258,
      "step": 30650
    },
    {
      "epoch": 3.693975903614458,
      "grad_norm": 12.138333320617676,
      "learning_rate": 1.2612048192771085e-05,
      "loss": 0.0275,
      "step": 30660
    },
    {
      "epoch": 3.6951807228915663,
      "grad_norm": 21.013235092163086,
      "learning_rate": 1.2609638554216867e-05,
      "loss": 0.0111,
      "step": 30670
    },
    {
      "epoch": 3.6963855421686747,
      "grad_norm": 0.1770215630531311,
      "learning_rate": 1.2607228915662652e-05,
      "loss": 0.009,
      "step": 30680
    },
    {
      "epoch": 3.697590361445783,
      "grad_norm": 0.06737399846315384,
      "learning_rate": 1.2604819277108435e-05,
      "loss": 0.0406,
      "step": 30690
    },
    {
      "epoch": 3.6987951807228914,
      "grad_norm": 0.03061821684241295,
      "learning_rate": 1.2602409638554218e-05,
      "loss": 0.0606,
      "step": 30700
    },
    {
      "epoch": 3.7,
      "grad_norm": 10.741018295288086,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.077,
      "step": 30710
    },
    {
      "epoch": 3.7012048192771085,
      "grad_norm": 0.03835581988096237,
      "learning_rate": 1.2597590361445785e-05,
      "loss": 0.067,
      "step": 30720
    },
    {
      "epoch": 3.702409638554217,
      "grad_norm": 0.11593424528837204,
      "learning_rate": 1.2595180722891566e-05,
      "loss": 0.0666,
      "step": 30730
    },
    {
      "epoch": 3.7036144578313253,
      "grad_norm": 0.5255020260810852,
      "learning_rate": 1.259277108433735e-05,
      "loss": 0.0163,
      "step": 30740
    },
    {
      "epoch": 3.7048192771084336,
      "grad_norm": 0.26523667573928833,
      "learning_rate": 1.2590361445783132e-05,
      "loss": 0.0053,
      "step": 30750
    },
    {
      "epoch": 3.7060240963855424,
      "grad_norm": 5.9296555519104,
      "learning_rate": 1.2587951807228917e-05,
      "loss": 0.0452,
      "step": 30760
    },
    {
      "epoch": 3.7072289156626503,
      "grad_norm": 0.12691430747509003,
      "learning_rate": 1.25855421686747e-05,
      "loss": 0.0441,
      "step": 30770
    },
    {
      "epoch": 3.708433734939759,
      "grad_norm": 0.023481981828808784,
      "learning_rate": 1.2583132530120484e-05,
      "loss": 0.0134,
      "step": 30780
    },
    {
      "epoch": 3.7096385542168675,
      "grad_norm": 1.7003841400146484,
      "learning_rate": 1.2580722891566267e-05,
      "loss": 0.0288,
      "step": 30790
    },
    {
      "epoch": 3.710843373493976,
      "grad_norm": 1.4342005252838135,
      "learning_rate": 1.2578313253012048e-05,
      "loss": 0.018,
      "step": 30800
    },
    {
      "epoch": 3.712048192771084,
      "grad_norm": 0.025698604062199593,
      "learning_rate": 1.2575903614457831e-05,
      "loss": 0.0589,
      "step": 30810
    },
    {
      "epoch": 3.7132530120481926,
      "grad_norm": 0.010442594066262245,
      "learning_rate": 1.2573493975903615e-05,
      "loss": 0.0917,
      "step": 30820
    },
    {
      "epoch": 3.7144578313253014,
      "grad_norm": 0.19555184245109558,
      "learning_rate": 1.25710843373494e-05,
      "loss": 0.0312,
      "step": 30830
    },
    {
      "epoch": 3.7156626506024097,
      "grad_norm": 0.2557338774204254,
      "learning_rate": 1.2568674698795183e-05,
      "loss": 0.0384,
      "step": 30840
    },
    {
      "epoch": 3.716867469879518,
      "grad_norm": 0.27684375643730164,
      "learning_rate": 1.2566265060240966e-05,
      "loss": 0.0195,
      "step": 30850
    },
    {
      "epoch": 3.7180722891566265,
      "grad_norm": 0.3827277421951294,
      "learning_rate": 1.2563855421686747e-05,
      "loss": 0.0471,
      "step": 30860
    },
    {
      "epoch": 3.719277108433735,
      "grad_norm": 3.2417714595794678,
      "learning_rate": 1.256144578313253e-05,
      "loss": 0.0366,
      "step": 30870
    },
    {
      "epoch": 3.7204819277108436,
      "grad_norm": 0.49829110503196716,
      "learning_rate": 1.2559036144578314e-05,
      "loss": 0.032,
      "step": 30880
    },
    {
      "epoch": 3.7216867469879515,
      "grad_norm": 0.3071914315223694,
      "learning_rate": 1.2556626506024097e-05,
      "loss": 0.034,
      "step": 30890
    },
    {
      "epoch": 3.7228915662650603,
      "grad_norm": 0.4617803990840912,
      "learning_rate": 1.255421686746988e-05,
      "loss": 0.0222,
      "step": 30900
    },
    {
      "epoch": 3.7240963855421687,
      "grad_norm": 0.2929080128669739,
      "learning_rate": 1.2551807228915665e-05,
      "loss": 0.0514,
      "step": 30910
    },
    {
      "epoch": 3.725301204819277,
      "grad_norm": 0.14425823092460632,
      "learning_rate": 1.2549397590361448e-05,
      "loss": 0.0129,
      "step": 30920
    },
    {
      "epoch": 3.7265060240963854,
      "grad_norm": 0.009222579188644886,
      "learning_rate": 1.254698795180723e-05,
      "loss": 0.0402,
      "step": 30930
    },
    {
      "epoch": 3.727710843373494,
      "grad_norm": 0.044362712651491165,
      "learning_rate": 1.2544578313253013e-05,
      "loss": 0.058,
      "step": 30940
    },
    {
      "epoch": 3.7289156626506026,
      "grad_norm": 0.359483003616333,
      "learning_rate": 1.2542168674698796e-05,
      "loss": 0.0498,
      "step": 30950
    },
    {
      "epoch": 3.730120481927711,
      "grad_norm": 0.08976031839847565,
      "learning_rate": 1.2539759036144579e-05,
      "loss": 0.026,
      "step": 30960
    },
    {
      "epoch": 3.7313253012048193,
      "grad_norm": 0.06554171442985535,
      "learning_rate": 1.2537349397590362e-05,
      "loss": 0.0172,
      "step": 30970
    },
    {
      "epoch": 3.7325301204819277,
      "grad_norm": 0.279805988073349,
      "learning_rate": 1.2534939759036147e-05,
      "loss": 0.0041,
      "step": 30980
    },
    {
      "epoch": 3.733734939759036,
      "grad_norm": 0.045864325016736984,
      "learning_rate": 1.2532530120481929e-05,
      "loss": 0.0337,
      "step": 30990
    },
    {
      "epoch": 3.734939759036145,
      "grad_norm": 0.30280154943466187,
      "learning_rate": 1.2530120481927712e-05,
      "loss": 0.0172,
      "step": 31000
    },
    {
      "epoch": 3.7361445783132528,
      "grad_norm": 0.004114303272217512,
      "learning_rate": 1.2527710843373495e-05,
      "loss": 0.0393,
      "step": 31010
    },
    {
      "epoch": 3.7373493975903616,
      "grad_norm": 2.686267137527466,
      "learning_rate": 1.2525301204819278e-05,
      "loss": 0.0156,
      "step": 31020
    },
    {
      "epoch": 3.73855421686747,
      "grad_norm": 0.004393349401652813,
      "learning_rate": 1.2522891566265061e-05,
      "loss": 0.1008,
      "step": 31030
    },
    {
      "epoch": 3.7397590361445783,
      "grad_norm": 0.021392207592725754,
      "learning_rate": 1.2520481927710843e-05,
      "loss": 0.072,
      "step": 31040
    },
    {
      "epoch": 3.7409638554216866,
      "grad_norm": 1.2483234405517578,
      "learning_rate": 1.2518072289156626e-05,
      "loss": 0.0442,
      "step": 31050
    },
    {
      "epoch": 3.742168674698795,
      "grad_norm": 0.6802757978439331,
      "learning_rate": 1.251566265060241e-05,
      "loss": 0.0113,
      "step": 31060
    },
    {
      "epoch": 3.743373493975904,
      "grad_norm": 0.03598454222083092,
      "learning_rate": 1.2513253012048194e-05,
      "loss": 0.014,
      "step": 31070
    },
    {
      "epoch": 3.744578313253012,
      "grad_norm": 0.0510329008102417,
      "learning_rate": 1.2510843373493977e-05,
      "loss": 0.0037,
      "step": 31080
    },
    {
      "epoch": 3.7457831325301205,
      "grad_norm": 1.8742928504943848,
      "learning_rate": 1.250843373493976e-05,
      "loss": 0.0471,
      "step": 31090
    },
    {
      "epoch": 3.746987951807229,
      "grad_norm": 0.0032991396728903055,
      "learning_rate": 1.2506024096385544e-05,
      "loss": 0.0045,
      "step": 31100
    },
    {
      "epoch": 3.7481927710843372,
      "grad_norm": 0.5361549854278564,
      "learning_rate": 1.2503614457831325e-05,
      "loss": 0.0855,
      "step": 31110
    },
    {
      "epoch": 3.749397590361446,
      "grad_norm": 0.013264253735542297,
      "learning_rate": 1.2501204819277108e-05,
      "loss": 0.0637,
      "step": 31120
    },
    {
      "epoch": 3.750602409638554,
      "grad_norm": 0.01400834321975708,
      "learning_rate": 1.2498795180722893e-05,
      "loss": 0.013,
      "step": 31130
    },
    {
      "epoch": 3.7518072289156628,
      "grad_norm": 0.22774416208267212,
      "learning_rate": 1.2496385542168676e-05,
      "loss": 0.0195,
      "step": 31140
    },
    {
      "epoch": 3.753012048192771,
      "grad_norm": 0.5096597671508789,
      "learning_rate": 1.249397590361446e-05,
      "loss": 0.0035,
      "step": 31150
    },
    {
      "epoch": 3.7542168674698795,
      "grad_norm": 5.619762420654297,
      "learning_rate": 1.2491566265060243e-05,
      "loss": 0.0249,
      "step": 31160
    },
    {
      "epoch": 3.755421686746988,
      "grad_norm": 0.11502305418252945,
      "learning_rate": 1.2489156626506026e-05,
      "loss": 0.0481,
      "step": 31170
    },
    {
      "epoch": 3.756626506024096,
      "grad_norm": 0.177493616938591,
      "learning_rate": 1.2486746987951807e-05,
      "loss": 0.0166,
      "step": 31180
    },
    {
      "epoch": 3.757831325301205,
      "grad_norm": 0.02007560059428215,
      "learning_rate": 1.248433734939759e-05,
      "loss": 0.0354,
      "step": 31190
    },
    {
      "epoch": 3.7590361445783134,
      "grad_norm": 4.243241786956787,
      "learning_rate": 1.2481927710843375e-05,
      "loss": 0.0207,
      "step": 31200
    },
    {
      "epoch": 3.7602409638554217,
      "grad_norm": 21.496835708618164,
      "learning_rate": 1.2479518072289158e-05,
      "loss": 0.0991,
      "step": 31210
    },
    {
      "epoch": 3.76144578313253,
      "grad_norm": 0.11832542717456818,
      "learning_rate": 1.2477108433734942e-05,
      "loss": 0.0094,
      "step": 31220
    },
    {
      "epoch": 3.7626506024096384,
      "grad_norm": 0.2023376077413559,
      "learning_rate": 1.2474698795180725e-05,
      "loss": 0.0098,
      "step": 31230
    },
    {
      "epoch": 3.7638554216867472,
      "grad_norm": 15.425537109375,
      "learning_rate": 1.2472289156626506e-05,
      "loss": 0.0264,
      "step": 31240
    },
    {
      "epoch": 3.765060240963855,
      "grad_norm": 2.3209855556488037,
      "learning_rate": 1.246987951807229e-05,
      "loss": 0.0475,
      "step": 31250
    },
    {
      "epoch": 3.766265060240964,
      "grad_norm": 0.014770415611565113,
      "learning_rate": 1.2467469879518073e-05,
      "loss": 0.0542,
      "step": 31260
    },
    {
      "epoch": 3.7674698795180723,
      "grad_norm": 0.015824077650904655,
      "learning_rate": 1.2465060240963856e-05,
      "loss": 0.0676,
      "step": 31270
    },
    {
      "epoch": 3.7686746987951807,
      "grad_norm": 0.13628968596458435,
      "learning_rate": 1.246265060240964e-05,
      "loss": 0.014,
      "step": 31280
    },
    {
      "epoch": 3.769879518072289,
      "grad_norm": 0.16863277554512024,
      "learning_rate": 1.2460240963855424e-05,
      "loss": 0.0219,
      "step": 31290
    },
    {
      "epoch": 3.7710843373493974,
      "grad_norm": 0.303864449262619,
      "learning_rate": 1.2457831325301207e-05,
      "loss": 0.0144,
      "step": 31300
    },
    {
      "epoch": 3.772289156626506,
      "grad_norm": 0.007466170936822891,
      "learning_rate": 1.2455421686746989e-05,
      "loss": 0.0439,
      "step": 31310
    },
    {
      "epoch": 3.7734939759036146,
      "grad_norm": 0.5537695288658142,
      "learning_rate": 1.2453012048192772e-05,
      "loss": 0.1033,
      "step": 31320
    },
    {
      "epoch": 3.774698795180723,
      "grad_norm": 0.011674491688609123,
      "learning_rate": 1.2450602409638555e-05,
      "loss": 0.0819,
      "step": 31330
    },
    {
      "epoch": 3.7759036144578313,
      "grad_norm": 3.4939186573028564,
      "learning_rate": 1.2448192771084338e-05,
      "loss": 0.0173,
      "step": 31340
    },
    {
      "epoch": 3.7771084337349397,
      "grad_norm": 0.030207576230168343,
      "learning_rate": 1.2445783132530123e-05,
      "loss": 0.0258,
      "step": 31350
    },
    {
      "epoch": 3.7783132530120485,
      "grad_norm": 1.5725358724594116,
      "learning_rate": 1.2443373493975906e-05,
      "loss": 0.0247,
      "step": 31360
    },
    {
      "epoch": 3.7795180722891564,
      "grad_norm": 0.157211035490036,
      "learning_rate": 1.2440963855421688e-05,
      "loss": 0.0404,
      "step": 31370
    },
    {
      "epoch": 3.780722891566265,
      "grad_norm": 0.38770216703414917,
      "learning_rate": 1.243855421686747e-05,
      "loss": 0.0492,
      "step": 31380
    },
    {
      "epoch": 3.7819277108433735,
      "grad_norm": 0.017507381737232208,
      "learning_rate": 1.2436144578313254e-05,
      "loss": 0.0036,
      "step": 31390
    },
    {
      "epoch": 3.783132530120482,
      "grad_norm": 17.00782585144043,
      "learning_rate": 1.2433734939759037e-05,
      "loss": 0.0799,
      "step": 31400
    },
    {
      "epoch": 3.7843373493975903,
      "grad_norm": 0.2774842381477356,
      "learning_rate": 1.243132530120482e-05,
      "loss": 0.0219,
      "step": 31410
    },
    {
      "epoch": 3.7855421686746986,
      "grad_norm": 0.8681598901748657,
      "learning_rate": 1.2428915662650602e-05,
      "loss": 0.006,
      "step": 31420
    },
    {
      "epoch": 3.7867469879518074,
      "grad_norm": 4.002899646759033,
      "learning_rate": 1.2426506024096388e-05,
      "loss": 0.0247,
      "step": 31430
    },
    {
      "epoch": 3.787951807228916,
      "grad_norm": 9.366289138793945,
      "learning_rate": 1.242409638554217e-05,
      "loss": 0.0448,
      "step": 31440
    },
    {
      "epoch": 3.789156626506024,
      "grad_norm": 0.04342540353536606,
      "learning_rate": 1.2421686746987953e-05,
      "loss": 0.0168,
      "step": 31450
    },
    {
      "epoch": 3.7903614457831325,
      "grad_norm": 0.01702885329723358,
      "learning_rate": 1.2419277108433736e-05,
      "loss": 0.0168,
      "step": 31460
    },
    {
      "epoch": 3.791566265060241,
      "grad_norm": 2.042008638381958,
      "learning_rate": 1.241686746987952e-05,
      "loss": 0.0168,
      "step": 31470
    },
    {
      "epoch": 3.7927710843373497,
      "grad_norm": 1.8839187622070312,
      "learning_rate": 1.2414457831325303e-05,
      "loss": 0.0267,
      "step": 31480
    },
    {
      "epoch": 3.7939759036144576,
      "grad_norm": 0.029646432027220726,
      "learning_rate": 1.2412048192771084e-05,
      "loss": 0.0721,
      "step": 31490
    },
    {
      "epoch": 3.7951807228915664,
      "grad_norm": 0.43411898612976074,
      "learning_rate": 1.2409638554216869e-05,
      "loss": 0.0265,
      "step": 31500
    },
    {
      "epoch": 3.7963855421686747,
      "grad_norm": 0.062404897063970566,
      "learning_rate": 1.2407228915662652e-05,
      "loss": 0.0055,
      "step": 31510
    },
    {
      "epoch": 3.797590361445783,
      "grad_norm": 1.173231840133667,
      "learning_rate": 1.2404819277108435e-05,
      "loss": 0.0176,
      "step": 31520
    },
    {
      "epoch": 3.7987951807228915,
      "grad_norm": 2.30013108253479,
      "learning_rate": 1.2402409638554218e-05,
      "loss": 0.023,
      "step": 31530
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.02657540701329708,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0748,
      "step": 31540
    },
    {
      "epoch": 3.8012048192771086,
      "grad_norm": 17.394729614257812,
      "learning_rate": 1.2397590361445783e-05,
      "loss": 0.0596,
      "step": 31550
    },
    {
      "epoch": 3.802409638554217,
      "grad_norm": 0.03456321358680725,
      "learning_rate": 1.2395180722891566e-05,
      "loss": 0.0501,
      "step": 31560
    },
    {
      "epoch": 3.8036144578313253,
      "grad_norm": 0.20342323184013367,
      "learning_rate": 1.239277108433735e-05,
      "loss": 0.0291,
      "step": 31570
    },
    {
      "epoch": 3.8048192771084337,
      "grad_norm": 0.022088203579187393,
      "learning_rate": 1.2390361445783134e-05,
      "loss": 0.0087,
      "step": 31580
    },
    {
      "epoch": 3.806024096385542,
      "grad_norm": 0.04610979184508324,
      "learning_rate": 1.2387951807228917e-05,
      "loss": 0.007,
      "step": 31590
    },
    {
      "epoch": 3.807228915662651,
      "grad_norm": 5.970032691955566,
      "learning_rate": 1.23855421686747e-05,
      "loss": 0.04,
      "step": 31600
    },
    {
      "epoch": 3.808433734939759,
      "grad_norm": 4.716653347015381,
      "learning_rate": 1.2383132530120484e-05,
      "loss": 0.0185,
      "step": 31610
    },
    {
      "epoch": 3.8096385542168676,
      "grad_norm": 0.008860500529408455,
      "learning_rate": 1.2380722891566265e-05,
      "loss": 0.0115,
      "step": 31620
    },
    {
      "epoch": 3.810843373493976,
      "grad_norm": 0.2932424545288086,
      "learning_rate": 1.2378313253012048e-05,
      "loss": 0.0147,
      "step": 31630
    },
    {
      "epoch": 3.8120481927710843,
      "grad_norm": 2.9294800758361816,
      "learning_rate": 1.2375903614457832e-05,
      "loss": 0.0277,
      "step": 31640
    },
    {
      "epoch": 3.8132530120481927,
      "grad_norm": 3.465346097946167,
      "learning_rate": 1.2373493975903616e-05,
      "loss": 0.0728,
      "step": 31650
    },
    {
      "epoch": 3.814457831325301,
      "grad_norm": 0.18974842131137848,
      "learning_rate": 1.23710843373494e-05,
      "loss": 0.0322,
      "step": 31660
    },
    {
      "epoch": 3.81566265060241,
      "grad_norm": 0.029641900211572647,
      "learning_rate": 1.2368674698795183e-05,
      "loss": 0.0312,
      "step": 31670
    },
    {
      "epoch": 3.816867469879518,
      "grad_norm": 0.015441220253705978,
      "learning_rate": 1.2366265060240964e-05,
      "loss": 0.0247,
      "step": 31680
    },
    {
      "epoch": 3.8180722891566266,
      "grad_norm": 0.35218799114227295,
      "learning_rate": 1.2363855421686748e-05,
      "loss": 0.02,
      "step": 31690
    },
    {
      "epoch": 3.819277108433735,
      "grad_norm": 0.18347874283790588,
      "learning_rate": 1.236144578313253e-05,
      "loss": 0.0459,
      "step": 31700
    },
    {
      "epoch": 3.8204819277108433,
      "grad_norm": 0.01881910301744938,
      "learning_rate": 1.2359036144578314e-05,
      "loss": 0.1062,
      "step": 31710
    },
    {
      "epoch": 3.821686746987952,
      "grad_norm": 0.5506362318992615,
      "learning_rate": 1.2356626506024097e-05,
      "loss": 0.0358,
      "step": 31720
    },
    {
      "epoch": 3.82289156626506,
      "grad_norm": 0.04126327112317085,
      "learning_rate": 1.2354216867469882e-05,
      "loss": 0.0347,
      "step": 31730
    },
    {
      "epoch": 3.824096385542169,
      "grad_norm": 0.10881313681602478,
      "learning_rate": 1.2351807228915665e-05,
      "loss": 0.0288,
      "step": 31740
    },
    {
      "epoch": 3.825301204819277,
      "grad_norm": 2.792433738708496,
      "learning_rate": 1.2349397590361447e-05,
      "loss": 0.0509,
      "step": 31750
    },
    {
      "epoch": 3.8265060240963855,
      "grad_norm": 0.085872121155262,
      "learning_rate": 1.234698795180723e-05,
      "loss": 0.0481,
      "step": 31760
    },
    {
      "epoch": 3.827710843373494,
      "grad_norm": 0.22004801034927368,
      "learning_rate": 1.2344578313253013e-05,
      "loss": 0.0187,
      "step": 31770
    },
    {
      "epoch": 3.8289156626506022,
      "grad_norm": 0.12826737761497498,
      "learning_rate": 1.2342168674698796e-05,
      "loss": 0.0208,
      "step": 31780
    },
    {
      "epoch": 3.830120481927711,
      "grad_norm": 0.031409502029418945,
      "learning_rate": 1.233975903614458e-05,
      "loss": 0.0145,
      "step": 31790
    },
    {
      "epoch": 3.8313253012048194,
      "grad_norm": 0.34848669171333313,
      "learning_rate": 1.2337349397590364e-05,
      "loss": 0.0062,
      "step": 31800
    },
    {
      "epoch": 3.8325301204819278,
      "grad_norm": 2.7700183391571045,
      "learning_rate": 1.2334939759036146e-05,
      "loss": 0.0504,
      "step": 31810
    },
    {
      "epoch": 3.833734939759036,
      "grad_norm": 2.366778612136841,
      "learning_rate": 1.2332530120481929e-05,
      "loss": 0.0486,
      "step": 31820
    },
    {
      "epoch": 3.8349397590361445,
      "grad_norm": 0.024914221838116646,
      "learning_rate": 1.2330120481927712e-05,
      "loss": 0.0278,
      "step": 31830
    },
    {
      "epoch": 3.8361445783132533,
      "grad_norm": 0.04670081287622452,
      "learning_rate": 1.2327710843373495e-05,
      "loss": 0.0277,
      "step": 31840
    },
    {
      "epoch": 3.837349397590361,
      "grad_norm": 0.016545617952942848,
      "learning_rate": 1.2325301204819278e-05,
      "loss": 0.0492,
      "step": 31850
    },
    {
      "epoch": 3.83855421686747,
      "grad_norm": 2.3869762420654297,
      "learning_rate": 1.232289156626506e-05,
      "loss": 0.0784,
      "step": 31860
    },
    {
      "epoch": 3.8397590361445784,
      "grad_norm": 0.038910672068595886,
      "learning_rate": 1.2320481927710843e-05,
      "loss": 0.0128,
      "step": 31870
    },
    {
      "epoch": 3.8409638554216867,
      "grad_norm": 2.061899423599243,
      "learning_rate": 1.2318072289156628e-05,
      "loss": 0.011,
      "step": 31880
    },
    {
      "epoch": 3.842168674698795,
      "grad_norm": 3.314194440841675,
      "learning_rate": 1.2315662650602411e-05,
      "loss": 0.017,
      "step": 31890
    },
    {
      "epoch": 3.8433734939759034,
      "grad_norm": 0.012407544068992138,
      "learning_rate": 1.2313253012048194e-05,
      "loss": 0.0618,
      "step": 31900
    },
    {
      "epoch": 3.8445783132530122,
      "grad_norm": 0.0066075678914785385,
      "learning_rate": 1.2310843373493977e-05,
      "loss": 0.0301,
      "step": 31910
    },
    {
      "epoch": 3.8457831325301206,
      "grad_norm": 8.477973937988281,
      "learning_rate": 1.230843373493976e-05,
      "loss": 0.0483,
      "step": 31920
    },
    {
      "epoch": 3.846987951807229,
      "grad_norm": 6.288465976715088,
      "learning_rate": 1.2306024096385542e-05,
      "loss": 0.035,
      "step": 31930
    },
    {
      "epoch": 3.8481927710843373,
      "grad_norm": 6.9396281242370605,
      "learning_rate": 1.2303614457831325e-05,
      "loss": 0.0325,
      "step": 31940
    },
    {
      "epoch": 3.8493975903614457,
      "grad_norm": 0.04872646555304527,
      "learning_rate": 1.230120481927711e-05,
      "loss": 0.078,
      "step": 31950
    },
    {
      "epoch": 3.8506024096385545,
      "grad_norm": 3.8741390705108643,
      "learning_rate": 1.2298795180722893e-05,
      "loss": 0.0397,
      "step": 31960
    },
    {
      "epoch": 3.8518072289156624,
      "grad_norm": 1.7302075624465942,
      "learning_rate": 1.2296385542168676e-05,
      "loss": 0.0146,
      "step": 31970
    },
    {
      "epoch": 3.853012048192771,
      "grad_norm": 2.737828254699707,
      "learning_rate": 1.229397590361446e-05,
      "loss": 0.0519,
      "step": 31980
    },
    {
      "epoch": 3.8542168674698796,
      "grad_norm": 0.03852134197950363,
      "learning_rate": 1.2291566265060241e-05,
      "loss": 0.0276,
      "step": 31990
    },
    {
      "epoch": 3.855421686746988,
      "grad_norm": 0.32268449664115906,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 0.0193,
      "step": 32000
    },
    {
      "epoch": 3.8566265060240963,
      "grad_norm": 0.010059360414743423,
      "learning_rate": 1.2286746987951807e-05,
      "loss": 0.0434,
      "step": 32010
    },
    {
      "epoch": 3.8578313253012047,
      "grad_norm": 76.49749755859375,
      "learning_rate": 1.228433734939759e-05,
      "loss": 0.0214,
      "step": 32020
    },
    {
      "epoch": 3.8590361445783135,
      "grad_norm": 3.6032540798187256,
      "learning_rate": 1.2281927710843375e-05,
      "loss": 0.0343,
      "step": 32030
    },
    {
      "epoch": 3.860240963855422,
      "grad_norm": 0.5719825625419617,
      "learning_rate": 1.2279518072289159e-05,
      "loss": 0.024,
      "step": 32040
    },
    {
      "epoch": 3.86144578313253,
      "grad_norm": 0.01052139699459076,
      "learning_rate": 1.2277108433734942e-05,
      "loss": 0.0629,
      "step": 32050
    },
    {
      "epoch": 3.8626506024096385,
      "grad_norm": 0.01789245940744877,
      "learning_rate": 1.2274698795180723e-05,
      "loss": 0.0244,
      "step": 32060
    },
    {
      "epoch": 3.863855421686747,
      "grad_norm": 0.01895722560584545,
      "learning_rate": 1.2272289156626506e-05,
      "loss": 0.0401,
      "step": 32070
    },
    {
      "epoch": 3.8650602409638557,
      "grad_norm": 2.27774715423584,
      "learning_rate": 1.226987951807229e-05,
      "loss": 0.0093,
      "step": 32080
    },
    {
      "epoch": 3.8662650602409636,
      "grad_norm": 0.12548032402992249,
      "learning_rate": 1.2267469879518073e-05,
      "loss": 0.0256,
      "step": 32090
    },
    {
      "epoch": 3.8674698795180724,
      "grad_norm": 1.9302858114242554,
      "learning_rate": 1.2265060240963858e-05,
      "loss": 0.0554,
      "step": 32100
    },
    {
      "epoch": 3.8686746987951808,
      "grad_norm": 15.085168838500977,
      "learning_rate": 1.2262650602409641e-05,
      "loss": 0.0351,
      "step": 32110
    },
    {
      "epoch": 3.869879518072289,
      "grad_norm": 0.015167728066444397,
      "learning_rate": 1.2260240963855422e-05,
      "loss": 0.0245,
      "step": 32120
    },
    {
      "epoch": 3.8710843373493975,
      "grad_norm": 0.014501063153147697,
      "learning_rate": 1.2257831325301206e-05,
      "loss": 0.0595,
      "step": 32130
    },
    {
      "epoch": 3.872289156626506,
      "grad_norm": 1.7789233922958374,
      "learning_rate": 1.2255421686746989e-05,
      "loss": 0.0723,
      "step": 32140
    },
    {
      "epoch": 3.8734939759036147,
      "grad_norm": 0.12594833970069885,
      "learning_rate": 1.2253012048192772e-05,
      "loss": 0.0448,
      "step": 32150
    },
    {
      "epoch": 3.874698795180723,
      "grad_norm": 0.05764232203364372,
      "learning_rate": 1.2250602409638555e-05,
      "loss": 0.0086,
      "step": 32160
    },
    {
      "epoch": 3.8759036144578314,
      "grad_norm": 0.06420151889324188,
      "learning_rate": 1.2248192771084337e-05,
      "loss": 0.0063,
      "step": 32170
    },
    {
      "epoch": 3.8771084337349397,
      "grad_norm": 0.020719747990369797,
      "learning_rate": 1.2245783132530123e-05,
      "loss": 0.0506,
      "step": 32180
    },
    {
      "epoch": 3.878313253012048,
      "grad_norm": 0.04672299697995186,
      "learning_rate": 1.2243373493975905e-05,
      "loss": 0.0054,
      "step": 32190
    },
    {
      "epoch": 3.8795180722891565,
      "grad_norm": 2.8994061946868896,
      "learning_rate": 1.2240963855421688e-05,
      "loss": 0.0275,
      "step": 32200
    },
    {
      "epoch": 3.880722891566265,
      "grad_norm": 0.26301416754722595,
      "learning_rate": 1.2238554216867471e-05,
      "loss": 0.0529,
      "step": 32210
    },
    {
      "epoch": 3.8819277108433736,
      "grad_norm": 8.26282024383545,
      "learning_rate": 1.2236144578313254e-05,
      "loss": 0.0615,
      "step": 32220
    },
    {
      "epoch": 3.883132530120482,
      "grad_norm": 0.7338315844535828,
      "learning_rate": 1.2233734939759037e-05,
      "loss": 0.0527,
      "step": 32230
    },
    {
      "epoch": 3.8843373493975903,
      "grad_norm": 1.9714304208755493,
      "learning_rate": 1.2231325301204819e-05,
      "loss": 0.0452,
      "step": 32240
    },
    {
      "epoch": 3.8855421686746987,
      "grad_norm": 0.6442599296569824,
      "learning_rate": 1.2228915662650604e-05,
      "loss": 0.008,
      "step": 32250
    },
    {
      "epoch": 3.886746987951807,
      "grad_norm": 0.026572629809379578,
      "learning_rate": 1.2226506024096387e-05,
      "loss": 0.0334,
      "step": 32260
    },
    {
      "epoch": 3.887951807228916,
      "grad_norm": 3.534252405166626,
      "learning_rate": 1.222409638554217e-05,
      "loss": 0.0427,
      "step": 32270
    },
    {
      "epoch": 3.8891566265060242,
      "grad_norm": 0.022926973178982735,
      "learning_rate": 1.2221686746987953e-05,
      "loss": 0.0323,
      "step": 32280
    },
    {
      "epoch": 3.8903614457831326,
      "grad_norm": 14.875017166137695,
      "learning_rate": 1.2219277108433736e-05,
      "loss": 0.0665,
      "step": 32290
    },
    {
      "epoch": 3.891566265060241,
      "grad_norm": 0.04152139276266098,
      "learning_rate": 1.2216867469879518e-05,
      "loss": 0.0581,
      "step": 32300
    },
    {
      "epoch": 3.8927710843373493,
      "grad_norm": 0.7160881161689758,
      "learning_rate": 1.2214457831325301e-05,
      "loss": 0.0021,
      "step": 32310
    },
    {
      "epoch": 3.8939759036144577,
      "grad_norm": 0.04127144441008568,
      "learning_rate": 1.2212048192771084e-05,
      "loss": 0.0134,
      "step": 32320
    },
    {
      "epoch": 3.895180722891566,
      "grad_norm": 0.6531191468238831,
      "learning_rate": 1.2209638554216869e-05,
      "loss": 0.0021,
      "step": 32330
    },
    {
      "epoch": 3.896385542168675,
      "grad_norm": 1.0211372375488281,
      "learning_rate": 1.2207228915662652e-05,
      "loss": 0.0263,
      "step": 32340
    },
    {
      "epoch": 3.897590361445783,
      "grad_norm": 0.030866382643580437,
      "learning_rate": 1.2204819277108435e-05,
      "loss": 0.0222,
      "step": 32350
    },
    {
      "epoch": 3.8987951807228916,
      "grad_norm": 0.009032181464135647,
      "learning_rate": 1.2202409638554219e-05,
      "loss": 0.0389,
      "step": 32360
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.32007062435150146,
      "learning_rate": 1.22e-05,
      "loss": 0.0576,
      "step": 32370
    },
    {
      "epoch": 3.9012048192771083,
      "grad_norm": 0.014974604360759258,
      "learning_rate": 1.2197590361445783e-05,
      "loss": 0.0288,
      "step": 32380
    },
    {
      "epoch": 3.902409638554217,
      "grad_norm": 0.09539161622524261,
      "learning_rate": 1.2195180722891566e-05,
      "loss": 0.0441,
      "step": 32390
    },
    {
      "epoch": 3.9036144578313254,
      "grad_norm": 0.46887901425361633,
      "learning_rate": 1.2192771084337351e-05,
      "loss": 0.0249,
      "step": 32400
    },
    {
      "epoch": 3.904819277108434,
      "grad_norm": 2.3565454483032227,
      "learning_rate": 1.2190361445783134e-05,
      "loss": 0.0521,
      "step": 32410
    },
    {
      "epoch": 3.906024096385542,
      "grad_norm": 0.04072549566626549,
      "learning_rate": 1.2187951807228918e-05,
      "loss": 0.0262,
      "step": 32420
    },
    {
      "epoch": 3.9072289156626505,
      "grad_norm": 1.1302534341812134,
      "learning_rate": 1.2185542168674699e-05,
      "loss": 0.0388,
      "step": 32430
    },
    {
      "epoch": 3.908433734939759,
      "grad_norm": 6.68899393081665,
      "learning_rate": 1.2183132530120482e-05,
      "loss": 0.0297,
      "step": 32440
    },
    {
      "epoch": 3.9096385542168672,
      "grad_norm": 0.039898913353681564,
      "learning_rate": 1.2180722891566265e-05,
      "loss": 0.0254,
      "step": 32450
    },
    {
      "epoch": 3.910843373493976,
      "grad_norm": 0.023425854742527008,
      "learning_rate": 1.2178313253012049e-05,
      "loss": 0.0201,
      "step": 32460
    },
    {
      "epoch": 3.9120481927710844,
      "grad_norm": 0.7437025904655457,
      "learning_rate": 1.2175903614457832e-05,
      "loss": 0.064,
      "step": 32470
    },
    {
      "epoch": 3.9132530120481928,
      "grad_norm": 0.0212289709597826,
      "learning_rate": 1.2173493975903617e-05,
      "loss": 0.0459,
      "step": 32480
    },
    {
      "epoch": 3.914457831325301,
      "grad_norm": 0.03403544798493385,
      "learning_rate": 1.21710843373494e-05,
      "loss": 0.0473,
      "step": 32490
    },
    {
      "epoch": 3.9156626506024095,
      "grad_norm": 0.008751152083277702,
      "learning_rate": 1.2168674698795181e-05,
      "loss": 0.0115,
      "step": 32500
    },
    {
      "epoch": 3.9168674698795183,
      "grad_norm": 0.35502490401268005,
      "learning_rate": 1.2166265060240965e-05,
      "loss": 0.0893,
      "step": 32510
    },
    {
      "epoch": 3.9180722891566266,
      "grad_norm": 2.466979742050171,
      "learning_rate": 1.2163855421686748e-05,
      "loss": 0.0356,
      "step": 32520
    },
    {
      "epoch": 3.919277108433735,
      "grad_norm": 0.28961747884750366,
      "learning_rate": 1.2161445783132531e-05,
      "loss": 0.0071,
      "step": 32530
    },
    {
      "epoch": 3.9204819277108434,
      "grad_norm": 0.4771096706390381,
      "learning_rate": 1.2159036144578314e-05,
      "loss": 0.007,
      "step": 32540
    },
    {
      "epoch": 3.9216867469879517,
      "grad_norm": 49.63694763183594,
      "learning_rate": 1.2156626506024099e-05,
      "loss": 0.0399,
      "step": 32550
    },
    {
      "epoch": 3.92289156626506,
      "grad_norm": 0.10750507563352585,
      "learning_rate": 1.2154216867469882e-05,
      "loss": 0.0469,
      "step": 32560
    },
    {
      "epoch": 3.9240963855421684,
      "grad_norm": 0.17161311209201813,
      "learning_rate": 1.2151807228915664e-05,
      "loss": 0.0281,
      "step": 32570
    },
    {
      "epoch": 3.9253012048192772,
      "grad_norm": 1.0770673751831055,
      "learning_rate": 1.2149397590361447e-05,
      "loss": 0.0423,
      "step": 32580
    },
    {
      "epoch": 3.9265060240963856,
      "grad_norm": 0.009751335717737675,
      "learning_rate": 1.214698795180723e-05,
      "loss": 0.0288,
      "step": 32590
    },
    {
      "epoch": 3.927710843373494,
      "grad_norm": 0.008569265715777874,
      "learning_rate": 1.2144578313253013e-05,
      "loss": 0.039,
      "step": 32600
    },
    {
      "epoch": 3.9289156626506023,
      "grad_norm": 2.858729124069214,
      "learning_rate": 1.2142168674698795e-05,
      "loss": 0.0761,
      "step": 32610
    },
    {
      "epoch": 3.9301204819277107,
      "grad_norm": 0.9032918810844421,
      "learning_rate": 1.2139759036144578e-05,
      "loss": 0.0211,
      "step": 32620
    },
    {
      "epoch": 3.9313253012048195,
      "grad_norm": 0.012196119874715805,
      "learning_rate": 1.2137349397590363e-05,
      "loss": 0.0104,
      "step": 32630
    },
    {
      "epoch": 3.932530120481928,
      "grad_norm": 0.0158978421241045,
      "learning_rate": 1.2134939759036146e-05,
      "loss": 0.0064,
      "step": 32640
    },
    {
      "epoch": 3.933734939759036,
      "grad_norm": 0.01968064345419407,
      "learning_rate": 1.2132530120481929e-05,
      "loss": 0.0333,
      "step": 32650
    },
    {
      "epoch": 3.9349397590361446,
      "grad_norm": 0.012158982455730438,
      "learning_rate": 1.2130120481927712e-05,
      "loss": 0.0373,
      "step": 32660
    },
    {
      "epoch": 3.936144578313253,
      "grad_norm": 0.018087396398186684,
      "learning_rate": 1.2127710843373495e-05,
      "loss": 0.0084,
      "step": 32670
    },
    {
      "epoch": 3.9373493975903613,
      "grad_norm": 0.05109187960624695,
      "learning_rate": 1.2125301204819277e-05,
      "loss": 0.0573,
      "step": 32680
    },
    {
      "epoch": 3.9385542168674696,
      "grad_norm": 0.008786058984696865,
      "learning_rate": 1.212289156626506e-05,
      "loss": 0.0378,
      "step": 32690
    },
    {
      "epoch": 3.9397590361445785,
      "grad_norm": 0.015888532623648643,
      "learning_rate": 1.2120481927710845e-05,
      "loss": 0.0783,
      "step": 32700
    },
    {
      "epoch": 3.940963855421687,
      "grad_norm": 0.033124491572380066,
      "learning_rate": 1.2118072289156628e-05,
      "loss": 0.0436,
      "step": 32710
    },
    {
      "epoch": 3.942168674698795,
      "grad_norm": 0.04382636398077011,
      "learning_rate": 1.2115662650602411e-05,
      "loss": 0.0515,
      "step": 32720
    },
    {
      "epoch": 3.9433734939759035,
      "grad_norm": 0.048361264169216156,
      "learning_rate": 1.2113253012048194e-05,
      "loss": 0.035,
      "step": 32730
    },
    {
      "epoch": 3.944578313253012,
      "grad_norm": 0.029021533206105232,
      "learning_rate": 1.2110843373493978e-05,
      "loss": 0.0266,
      "step": 32740
    },
    {
      "epoch": 3.9457831325301207,
      "grad_norm": 0.01550512108951807,
      "learning_rate": 1.2108433734939759e-05,
      "loss": 0.0015,
      "step": 32750
    },
    {
      "epoch": 3.946987951807229,
      "grad_norm": 0.06304725259542465,
      "learning_rate": 1.2106024096385542e-05,
      "loss": 0.0575,
      "step": 32760
    },
    {
      "epoch": 3.9481927710843374,
      "grad_norm": 3.538182020187378,
      "learning_rate": 1.2103614457831325e-05,
      "loss": 0.0279,
      "step": 32770
    },
    {
      "epoch": 3.9493975903614458,
      "grad_norm": 0.8888375163078308,
      "learning_rate": 1.210120481927711e-05,
      "loss": 0.0242,
      "step": 32780
    },
    {
      "epoch": 3.950602409638554,
      "grad_norm": 17.196683883666992,
      "learning_rate": 1.2098795180722893e-05,
      "loss": 0.0228,
      "step": 32790
    },
    {
      "epoch": 3.9518072289156625,
      "grad_norm": 0.013732315972447395,
      "learning_rate": 1.2096385542168677e-05,
      "loss": 0.045,
      "step": 32800
    },
    {
      "epoch": 3.953012048192771,
      "grad_norm": 0.21311898529529572,
      "learning_rate": 1.2093975903614458e-05,
      "loss": 0.0685,
      "step": 32810
    },
    {
      "epoch": 3.9542168674698797,
      "grad_norm": 0.9095426797866821,
      "learning_rate": 1.2091566265060241e-05,
      "loss": 0.0239,
      "step": 32820
    },
    {
      "epoch": 3.955421686746988,
      "grad_norm": 0.028288891538977623,
      "learning_rate": 1.2089156626506024e-05,
      "loss": 0.0144,
      "step": 32830
    },
    {
      "epoch": 3.9566265060240964,
      "grad_norm": 0.017796596512198448,
      "learning_rate": 1.2086746987951808e-05,
      "loss": 0.0133,
      "step": 32840
    },
    {
      "epoch": 3.9578313253012047,
      "grad_norm": 0.23286950588226318,
      "learning_rate": 1.2084337349397593e-05,
      "loss": 0.0183,
      "step": 32850
    },
    {
      "epoch": 3.959036144578313,
      "grad_norm": 0.07591260224580765,
      "learning_rate": 1.2081927710843376e-05,
      "loss": 0.0179,
      "step": 32860
    },
    {
      "epoch": 3.960240963855422,
      "grad_norm": 2.546278953552246,
      "learning_rate": 1.2079518072289159e-05,
      "loss": 0.0905,
      "step": 32870
    },
    {
      "epoch": 3.9614457831325303,
      "grad_norm": 0.08767733722925186,
      "learning_rate": 1.207710843373494e-05,
      "loss": 0.0329,
      "step": 32880
    },
    {
      "epoch": 3.9626506024096386,
      "grad_norm": 8.210906982421875,
      "learning_rate": 1.2074698795180724e-05,
      "loss": 0.0553,
      "step": 32890
    },
    {
      "epoch": 3.963855421686747,
      "grad_norm": 0.10315212607383728,
      "learning_rate": 1.2072289156626507e-05,
      "loss": 0.0269,
      "step": 32900
    },
    {
      "epoch": 3.9650602409638553,
      "grad_norm": 1.8193018436431885,
      "learning_rate": 1.206987951807229e-05,
      "loss": 0.0318,
      "step": 32910
    },
    {
      "epoch": 3.9662650602409637,
      "grad_norm": 9.472146034240723,
      "learning_rate": 1.2067469879518073e-05,
      "loss": 0.0313,
      "step": 32920
    },
    {
      "epoch": 3.967469879518072,
      "grad_norm": 0.05469319969415665,
      "learning_rate": 1.2065060240963858e-05,
      "loss": 0.0114,
      "step": 32930
    },
    {
      "epoch": 3.968674698795181,
      "grad_norm": 0.12715749442577362,
      "learning_rate": 1.206265060240964e-05,
      "loss": 0.0304,
      "step": 32940
    },
    {
      "epoch": 3.9698795180722892,
      "grad_norm": 181.2322998046875,
      "learning_rate": 1.2060240963855423e-05,
      "loss": 0.0111,
      "step": 32950
    },
    {
      "epoch": 3.9710843373493976,
      "grad_norm": 1.6049222946166992,
      "learning_rate": 1.2057831325301206e-05,
      "loss": 0.0768,
      "step": 32960
    },
    {
      "epoch": 3.972289156626506,
      "grad_norm": 0.09392069280147552,
      "learning_rate": 1.2055421686746989e-05,
      "loss": 0.0424,
      "step": 32970
    },
    {
      "epoch": 3.9734939759036143,
      "grad_norm": 3.685023546218872,
      "learning_rate": 1.2053012048192772e-05,
      "loss": 0.047,
      "step": 32980
    },
    {
      "epoch": 3.974698795180723,
      "grad_norm": 1.2849797010421753,
      "learning_rate": 1.2050602409638554e-05,
      "loss": 0.0593,
      "step": 32990
    },
    {
      "epoch": 3.9759036144578315,
      "grad_norm": 7.825671195983887,
      "learning_rate": 1.204819277108434e-05,
      "loss": 0.0295,
      "step": 33000
    },
    {
      "epoch": 3.97710843373494,
      "grad_norm": 0.41711267828941345,
      "learning_rate": 1.2045783132530122e-05,
      "loss": 0.0155,
      "step": 33010
    },
    {
      "epoch": 3.978313253012048,
      "grad_norm": 0.7455693483352661,
      "learning_rate": 1.2043373493975905e-05,
      "loss": 0.0479,
      "step": 33020
    },
    {
      "epoch": 3.9795180722891565,
      "grad_norm": 0.17151029407978058,
      "learning_rate": 1.2040963855421688e-05,
      "loss": 0.0027,
      "step": 33030
    },
    {
      "epoch": 3.980722891566265,
      "grad_norm": 4.976195335388184,
      "learning_rate": 1.2038554216867471e-05,
      "loss": 0.039,
      "step": 33040
    },
    {
      "epoch": 3.9819277108433733,
      "grad_norm": 0.0385880284011364,
      "learning_rate": 1.2036144578313254e-05,
      "loss": 0.0358,
      "step": 33050
    },
    {
      "epoch": 3.983132530120482,
      "grad_norm": 0.2085491567850113,
      "learning_rate": 1.2033734939759036e-05,
      "loss": 0.0202,
      "step": 33060
    },
    {
      "epoch": 3.9843373493975904,
      "grad_norm": 70.99539184570312,
      "learning_rate": 1.2031325301204819e-05,
      "loss": 0.0588,
      "step": 33070
    },
    {
      "epoch": 3.985542168674699,
      "grad_norm": 0.008693404495716095,
      "learning_rate": 1.2028915662650604e-05,
      "loss": 0.0303,
      "step": 33080
    },
    {
      "epoch": 3.986746987951807,
      "grad_norm": 0.7305654287338257,
      "learning_rate": 1.2026506024096387e-05,
      "loss": 0.0772,
      "step": 33090
    },
    {
      "epoch": 3.9879518072289155,
      "grad_norm": 0.11326818913221359,
      "learning_rate": 1.202409638554217e-05,
      "loss": 0.1066,
      "step": 33100
    },
    {
      "epoch": 3.9891566265060243,
      "grad_norm": 0.042238593101501465,
      "learning_rate": 1.2021686746987953e-05,
      "loss": 0.0072,
      "step": 33110
    },
    {
      "epoch": 3.9903614457831327,
      "grad_norm": 0.049112748354673386,
      "learning_rate": 1.2019277108433735e-05,
      "loss": 0.0395,
      "step": 33120
    },
    {
      "epoch": 3.991566265060241,
      "grad_norm": 7.94907808303833,
      "learning_rate": 1.2016867469879518e-05,
      "loss": 0.0639,
      "step": 33130
    },
    {
      "epoch": 3.9927710843373494,
      "grad_norm": 0.40486276149749756,
      "learning_rate": 1.2014457831325301e-05,
      "loss": 0.0408,
      "step": 33140
    },
    {
      "epoch": 3.9939759036144578,
      "grad_norm": 1.0446795225143433,
      "learning_rate": 1.2012048192771086e-05,
      "loss": 0.0217,
      "step": 33150
    },
    {
      "epoch": 3.995180722891566,
      "grad_norm": 0.016965150833129883,
      "learning_rate": 1.200963855421687e-05,
      "loss": 0.0096,
      "step": 33160
    },
    {
      "epoch": 3.9963855421686745,
      "grad_norm": 8.468924522399902,
      "learning_rate": 1.2007228915662652e-05,
      "loss": 0.0489,
      "step": 33170
    },
    {
      "epoch": 3.9975903614457833,
      "grad_norm": 0.2303953617811203,
      "learning_rate": 1.2004819277108436e-05,
      "loss": 0.0613,
      "step": 33180
    },
    {
      "epoch": 3.9987951807228916,
      "grad_norm": 0.6620354056358337,
      "learning_rate": 1.2002409638554217e-05,
      "loss": 0.045,
      "step": 33190
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.7546860575675964,
      "learning_rate": 1.2e-05,
      "loss": 0.0478,
      "step": 33200
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9849081364829396,
      "eval_f1": 0.9599502487562189,
      "eval_loss": 0.04402436688542366,
      "eval_precision": 0.9660783577418951,
      "eval_recall": 0.9538993943888271,
      "eval_runtime": 3416.3212,
      "eval_samples_per_second": 12.496,
      "eval_steps_per_second": 0.521,
      "step": 33200
    },
    {
      "epoch": 4.001204819277109,
      "grad_norm": 0.3983836770057678,
      "learning_rate": 1.1997590361445783e-05,
      "loss": 0.0183,
      "step": 33210
    },
    {
      "epoch": 4.002409638554217,
      "grad_norm": 0.02227403037250042,
      "learning_rate": 1.1995180722891567e-05,
      "loss": 0.0248,
      "step": 33220
    },
    {
      "epoch": 4.0036144578313255,
      "grad_norm": 3.4556422233581543,
      "learning_rate": 1.1992771084337352e-05,
      "loss": 0.0097,
      "step": 33230
    },
    {
      "epoch": 4.004819277108433,
      "grad_norm": 0.020539330318570137,
      "learning_rate": 1.1990361445783135e-05,
      "loss": 0.0463,
      "step": 33240
    },
    {
      "epoch": 4.006024096385542,
      "grad_norm": 0.2903784513473511,
      "learning_rate": 1.1987951807228916e-05,
      "loss": 0.0226,
      "step": 33250
    },
    {
      "epoch": 4.00722891566265,
      "grad_norm": 0.02239247038960457,
      "learning_rate": 1.19855421686747e-05,
      "loss": 0.0356,
      "step": 33260
    },
    {
      "epoch": 4.008433734939759,
      "grad_norm": 0.0502423420548439,
      "learning_rate": 1.1983132530120483e-05,
      "loss": 0.0159,
      "step": 33270
    },
    {
      "epoch": 4.009638554216868,
      "grad_norm": 0.3883308470249176,
      "learning_rate": 1.1980722891566266e-05,
      "loss": 0.0101,
      "step": 33280
    },
    {
      "epoch": 4.010843373493976,
      "grad_norm": 0.01640433259308338,
      "learning_rate": 1.1978313253012049e-05,
      "loss": 0.0498,
      "step": 33290
    },
    {
      "epoch": 4.0120481927710845,
      "grad_norm": 0.195235013961792,
      "learning_rate": 1.1975903614457834e-05,
      "loss": 0.0256,
      "step": 33300
    },
    {
      "epoch": 4.013253012048192,
      "grad_norm": 0.09226667881011963,
      "learning_rate": 1.1973493975903617e-05,
      "loss": 0.0217,
      "step": 33310
    },
    {
      "epoch": 4.014457831325301,
      "grad_norm": 0.017136717215180397,
      "learning_rate": 1.1971084337349398e-05,
      "loss": 0.0294,
      "step": 33320
    },
    {
      "epoch": 4.01566265060241,
      "grad_norm": 0.34873080253601074,
      "learning_rate": 1.1968674698795182e-05,
      "loss": 0.0035,
      "step": 33330
    },
    {
      "epoch": 4.016867469879518,
      "grad_norm": 0.009512416087090969,
      "learning_rate": 1.1966265060240965e-05,
      "loss": 0.006,
      "step": 33340
    },
    {
      "epoch": 4.018072289156627,
      "grad_norm": 0.013323519378900528,
      "learning_rate": 1.1963855421686748e-05,
      "loss": 0.006,
      "step": 33350
    },
    {
      "epoch": 4.019277108433735,
      "grad_norm": 0.005318839568644762,
      "learning_rate": 1.1961445783132531e-05,
      "loss": 0.0161,
      "step": 33360
    },
    {
      "epoch": 4.0204819277108435,
      "grad_norm": 0.01548659335821867,
      "learning_rate": 1.1959036144578313e-05,
      "loss": 0.017,
      "step": 33370
    },
    {
      "epoch": 4.021686746987951,
      "grad_norm": 0.9352131485939026,
      "learning_rate": 1.1956626506024097e-05,
      "loss": 0.0509,
      "step": 33380
    },
    {
      "epoch": 4.02289156626506,
      "grad_norm": 0.014680733904242516,
      "learning_rate": 1.195421686746988e-05,
      "loss": 0.0125,
      "step": 33390
    },
    {
      "epoch": 4.024096385542169,
      "grad_norm": 0.009353124536573887,
      "learning_rate": 1.1951807228915664e-05,
      "loss": 0.0117,
      "step": 33400
    },
    {
      "epoch": 4.025301204819277,
      "grad_norm": 5.700930595397949,
      "learning_rate": 1.1949397590361447e-05,
      "loss": 0.0564,
      "step": 33410
    },
    {
      "epoch": 4.026506024096386,
      "grad_norm": 0.017625270411372185,
      "learning_rate": 1.194698795180723e-05,
      "loss": 0.0673,
      "step": 33420
    },
    {
      "epoch": 4.027710843373494,
      "grad_norm": 1.2370491027832031,
      "learning_rate": 1.1944578313253012e-05,
      "loss": 0.0195,
      "step": 33430
    },
    {
      "epoch": 4.028915662650602,
      "grad_norm": 4.646211624145508,
      "learning_rate": 1.1942168674698795e-05,
      "loss": 0.0421,
      "step": 33440
    },
    {
      "epoch": 4.030120481927711,
      "grad_norm": 16.57046127319336,
      "learning_rate": 1.193975903614458e-05,
      "loss": 0.0953,
      "step": 33450
    },
    {
      "epoch": 4.031325301204819,
      "grad_norm": 0.28423061966896057,
      "learning_rate": 1.1937349397590363e-05,
      "loss": 0.0115,
      "step": 33460
    },
    {
      "epoch": 4.032530120481928,
      "grad_norm": 2.8442234992980957,
      "learning_rate": 1.1934939759036146e-05,
      "loss": 0.0248,
      "step": 33470
    },
    {
      "epoch": 4.033734939759036,
      "grad_norm": 3.8868913650512695,
      "learning_rate": 1.193253012048193e-05,
      "loss": 0.0397,
      "step": 33480
    },
    {
      "epoch": 4.034939759036145,
      "grad_norm": 0.886868953704834,
      "learning_rate": 1.1930120481927712e-05,
      "loss": 0.0332,
      "step": 33490
    },
    {
      "epoch": 4.036144578313253,
      "grad_norm": 0.017434824258089066,
      "learning_rate": 1.1927710843373494e-05,
      "loss": 0.0339,
      "step": 33500
    },
    {
      "epoch": 4.037349397590361,
      "grad_norm": 3.841141700744629,
      "learning_rate": 1.1925301204819277e-05,
      "loss": 0.0376,
      "step": 33510
    },
    {
      "epoch": 4.03855421686747,
      "grad_norm": 1.3354358673095703,
      "learning_rate": 1.192289156626506e-05,
      "loss": 0.0512,
      "step": 33520
    },
    {
      "epoch": 4.039759036144578,
      "grad_norm": 0.08997289836406708,
      "learning_rate": 1.1920481927710845e-05,
      "loss": 0.0534,
      "step": 33530
    },
    {
      "epoch": 4.040963855421687,
      "grad_norm": 0.07766657322645187,
      "learning_rate": 1.1918072289156628e-05,
      "loss": 0.0148,
      "step": 33540
    },
    {
      "epoch": 4.042168674698795,
      "grad_norm": 0.17639507353305817,
      "learning_rate": 1.1915662650602411e-05,
      "loss": 0.03,
      "step": 33550
    },
    {
      "epoch": 4.043373493975904,
      "grad_norm": 1.743104338645935,
      "learning_rate": 1.1913253012048193e-05,
      "loss": 0.0306,
      "step": 33560
    },
    {
      "epoch": 4.044578313253012,
      "grad_norm": 0.04378311336040497,
      "learning_rate": 1.1910843373493976e-05,
      "loss": 0.0187,
      "step": 33570
    },
    {
      "epoch": 4.04578313253012,
      "grad_norm": 1.7039692401885986,
      "learning_rate": 1.190843373493976e-05,
      "loss": 0.0269,
      "step": 33580
    },
    {
      "epoch": 4.046987951807229,
      "grad_norm": 0.7918255925178528,
      "learning_rate": 1.1906024096385542e-05,
      "loss": 0.0032,
      "step": 33590
    },
    {
      "epoch": 4.048192771084337,
      "grad_norm": 0.6378517150878906,
      "learning_rate": 1.1903614457831327e-05,
      "loss": 0.0085,
      "step": 33600
    },
    {
      "epoch": 4.049397590361446,
      "grad_norm": 31.980125427246094,
      "learning_rate": 1.190120481927711e-05,
      "loss": 0.0957,
      "step": 33610
    },
    {
      "epoch": 4.050602409638554,
      "grad_norm": 0.4629584550857544,
      "learning_rate": 1.1898795180722894e-05,
      "loss": 0.0518,
      "step": 33620
    },
    {
      "epoch": 4.051807228915663,
      "grad_norm": 0.04397699981927872,
      "learning_rate": 1.1896385542168675e-05,
      "loss": 0.0269,
      "step": 33630
    },
    {
      "epoch": 4.053012048192771,
      "grad_norm": 0.01937798410654068,
      "learning_rate": 1.1893975903614458e-05,
      "loss": 0.034,
      "step": 33640
    },
    {
      "epoch": 4.054216867469879,
      "grad_norm": 0.0104904780164361,
      "learning_rate": 1.1891566265060242e-05,
      "loss": 0.0095,
      "step": 33650
    },
    {
      "epoch": 4.055421686746988,
      "grad_norm": 0.030608633533120155,
      "learning_rate": 1.1889156626506025e-05,
      "loss": 0.0301,
      "step": 33660
    },
    {
      "epoch": 4.056626506024096,
      "grad_norm": 0.007998794317245483,
      "learning_rate": 1.1886746987951808e-05,
      "loss": 0.0007,
      "step": 33670
    },
    {
      "epoch": 4.057831325301205,
      "grad_norm": 0.004894666839390993,
      "learning_rate": 1.1884337349397593e-05,
      "loss": 0.0133,
      "step": 33680
    },
    {
      "epoch": 4.059036144578314,
      "grad_norm": 2.6669557094573975,
      "learning_rate": 1.1881927710843374e-05,
      "loss": 0.0163,
      "step": 33690
    },
    {
      "epoch": 4.0602409638554215,
      "grad_norm": 0.018619520589709282,
      "learning_rate": 1.1879518072289157e-05,
      "loss": 0.006,
      "step": 33700
    },
    {
      "epoch": 4.06144578313253,
      "grad_norm": 2.595517873764038,
      "learning_rate": 1.187710843373494e-05,
      "loss": 0.0605,
      "step": 33710
    },
    {
      "epoch": 4.062650602409638,
      "grad_norm": 0.28877708315849304,
      "learning_rate": 1.1874698795180724e-05,
      "loss": 0.004,
      "step": 33720
    },
    {
      "epoch": 4.063855421686747,
      "grad_norm": 0.006717058829963207,
      "learning_rate": 1.1872289156626507e-05,
      "loss": 0.0072,
      "step": 33730
    },
    {
      "epoch": 4.065060240963855,
      "grad_norm": 0.004465172998607159,
      "learning_rate": 1.1869879518072288e-05,
      "loss": 0.0736,
      "step": 33740
    },
    {
      "epoch": 4.066265060240964,
      "grad_norm": 2.0585055351257324,
      "learning_rate": 1.1867469879518075e-05,
      "loss": 0.0116,
      "step": 33750
    },
    {
      "epoch": 4.067469879518073,
      "grad_norm": 0.011316741816699505,
      "learning_rate": 1.1865060240963856e-05,
      "loss": 0.0137,
      "step": 33760
    },
    {
      "epoch": 4.0686746987951805,
      "grad_norm": 1.219984531402588,
      "learning_rate": 1.186265060240964e-05,
      "loss": 0.1027,
      "step": 33770
    },
    {
      "epoch": 4.069879518072289,
      "grad_norm": 0.49625489115715027,
      "learning_rate": 1.1860240963855423e-05,
      "loss": 0.0178,
      "step": 33780
    },
    {
      "epoch": 4.071084337349397,
      "grad_norm": 0.018275003880262375,
      "learning_rate": 1.1857831325301206e-05,
      "loss": 0.0019,
      "step": 33790
    },
    {
      "epoch": 4.072289156626506,
      "grad_norm": 3.8073298931121826,
      "learning_rate": 1.185542168674699e-05,
      "loss": 0.0444,
      "step": 33800
    },
    {
      "epoch": 4.073493975903615,
      "grad_norm": 0.005800935905426741,
      "learning_rate": 1.185301204819277e-05,
      "loss": 0.0396,
      "step": 33810
    },
    {
      "epoch": 4.074698795180723,
      "grad_norm": 1.723544716835022,
      "learning_rate": 1.1850602409638554e-05,
      "loss": 0.0177,
      "step": 33820
    },
    {
      "epoch": 4.075903614457832,
      "grad_norm": 4.645752429962158,
      "learning_rate": 1.1848192771084339e-05,
      "loss": 0.0305,
      "step": 33830
    },
    {
      "epoch": 4.0771084337349395,
      "grad_norm": 0.46217721700668335,
      "learning_rate": 1.1845783132530122e-05,
      "loss": 0.0666,
      "step": 33840
    },
    {
      "epoch": 4.078313253012048,
      "grad_norm": 0.12931828200817108,
      "learning_rate": 1.1843373493975905e-05,
      "loss": 0.0421,
      "step": 33850
    },
    {
      "epoch": 4.079518072289156,
      "grad_norm": 0.19143356382846832,
      "learning_rate": 1.1840963855421688e-05,
      "loss": 0.0263,
      "step": 33860
    },
    {
      "epoch": 4.080722891566265,
      "grad_norm": 0.21136876940727234,
      "learning_rate": 1.183855421686747e-05,
      "loss": 0.0012,
      "step": 33870
    },
    {
      "epoch": 4.081927710843374,
      "grad_norm": 0.014040406793355942,
      "learning_rate": 1.1836144578313253e-05,
      "loss": 0.0535,
      "step": 33880
    },
    {
      "epoch": 4.083132530120482,
      "grad_norm": 0.11299402266740799,
      "learning_rate": 1.1833734939759036e-05,
      "loss": 0.0525,
      "step": 33890
    },
    {
      "epoch": 4.0843373493975905,
      "grad_norm": 0.41559338569641113,
      "learning_rate": 1.1831325301204821e-05,
      "loss": 0.0478,
      "step": 33900
    },
    {
      "epoch": 4.085542168674698,
      "grad_norm": 1.6730650663375854,
      "learning_rate": 1.1828915662650604e-05,
      "loss": 0.0048,
      "step": 33910
    },
    {
      "epoch": 4.086746987951807,
      "grad_norm": 0.09612846374511719,
      "learning_rate": 1.1826506024096387e-05,
      "loss": 0.021,
      "step": 33920
    },
    {
      "epoch": 4.087951807228916,
      "grad_norm": 8.50320053100586,
      "learning_rate": 1.182409638554217e-05,
      "loss": 0.0246,
      "step": 33930
    },
    {
      "epoch": 4.089156626506024,
      "grad_norm": 4.88126802444458,
      "learning_rate": 1.1821686746987952e-05,
      "loss": 0.0307,
      "step": 33940
    },
    {
      "epoch": 4.090361445783133,
      "grad_norm": 0.005340890493243933,
      "learning_rate": 1.1819277108433735e-05,
      "loss": 0.0225,
      "step": 33950
    },
    {
      "epoch": 4.091566265060241,
      "grad_norm": 0.03502361476421356,
      "learning_rate": 1.1816867469879518e-05,
      "loss": 0.0497,
      "step": 33960
    },
    {
      "epoch": 4.0927710843373495,
      "grad_norm": 0.6003095507621765,
      "learning_rate": 1.1814457831325301e-05,
      "loss": 0.0232,
      "step": 33970
    },
    {
      "epoch": 4.093975903614457,
      "grad_norm": 0.6967634558677673,
      "learning_rate": 1.1812048192771086e-05,
      "loss": 0.0213,
      "step": 33980
    },
    {
      "epoch": 4.095180722891566,
      "grad_norm": 0.04769524931907654,
      "learning_rate": 1.180963855421687e-05,
      "loss": 0.011,
      "step": 33990
    },
    {
      "epoch": 4.096385542168675,
      "grad_norm": 0.6533001065254211,
      "learning_rate": 1.1807228915662651e-05,
      "loss": 0.0051,
      "step": 34000
    },
    {
      "epoch": 4.097590361445783,
      "grad_norm": 0.009384113363921642,
      "learning_rate": 1.1804819277108434e-05,
      "loss": 0.026,
      "step": 34010
    },
    {
      "epoch": 4.098795180722892,
      "grad_norm": 0.3582531809806824,
      "learning_rate": 1.1802409638554217e-05,
      "loss": 0.0083,
      "step": 34020
    },
    {
      "epoch": 4.1,
      "grad_norm": 2.276648759841919,
      "learning_rate": 1.18e-05,
      "loss": 0.0652,
      "step": 34030
    },
    {
      "epoch": 4.1012048192771084,
      "grad_norm": 0.16528597474098206,
      "learning_rate": 1.1797590361445784e-05,
      "loss": 0.0633,
      "step": 34040
    },
    {
      "epoch": 4.102409638554217,
      "grad_norm": 0.6049054861068726,
      "learning_rate": 1.1795180722891569e-05,
      "loss": 0.0222,
      "step": 34050
    },
    {
      "epoch": 4.103614457831325,
      "grad_norm": 8.586581230163574,
      "learning_rate": 1.1792771084337352e-05,
      "loss": 0.0207,
      "step": 34060
    },
    {
      "epoch": 4.104819277108434,
      "grad_norm": 0.055258750915527344,
      "learning_rate": 1.1790361445783133e-05,
      "loss": 0.0242,
      "step": 34070
    },
    {
      "epoch": 4.106024096385542,
      "grad_norm": 0.45831868052482605,
      "learning_rate": 1.1787951807228916e-05,
      "loss": 0.1185,
      "step": 34080
    },
    {
      "epoch": 4.107228915662651,
      "grad_norm": 0.5042424201965332,
      "learning_rate": 1.17855421686747e-05,
      "loss": 0.0439,
      "step": 34090
    },
    {
      "epoch": 4.108433734939759,
      "grad_norm": 0.20173247158527374,
      "learning_rate": 1.1783132530120483e-05,
      "loss": 0.0267,
      "step": 34100
    },
    {
      "epoch": 4.109638554216867,
      "grad_norm": 0.034829508513212204,
      "learning_rate": 1.1780722891566266e-05,
      "loss": 0.0622,
      "step": 34110
    },
    {
      "epoch": 4.110843373493976,
      "grad_norm": 0.01163256075233221,
      "learning_rate": 1.1778313253012047e-05,
      "loss": 0.0107,
      "step": 34120
    },
    {
      "epoch": 4.112048192771084,
      "grad_norm": 0.012583679519593716,
      "learning_rate": 1.1775903614457834e-05,
      "loss": 0.0357,
      "step": 34130
    },
    {
      "epoch": 4.113253012048193,
      "grad_norm": 6.491888046264648,
      "learning_rate": 1.1773493975903615e-05,
      "loss": 0.0513,
      "step": 34140
    },
    {
      "epoch": 4.114457831325301,
      "grad_norm": 0.031876880675554276,
      "learning_rate": 1.1771084337349399e-05,
      "loss": 0.0472,
      "step": 34150
    },
    {
      "epoch": 4.11566265060241,
      "grad_norm": 0.05683954805135727,
      "learning_rate": 1.1768674698795182e-05,
      "loss": 0.0328,
      "step": 34160
    },
    {
      "epoch": 4.1168674698795185,
      "grad_norm": 0.48441797494888306,
      "learning_rate": 1.1766265060240965e-05,
      "loss": 0.0142,
      "step": 34170
    },
    {
      "epoch": 4.118072289156626,
      "grad_norm": 0.009512236341834068,
      "learning_rate": 1.1763855421686748e-05,
      "loss": 0.011,
      "step": 34180
    },
    {
      "epoch": 4.119277108433735,
      "grad_norm": 21.47527313232422,
      "learning_rate": 1.176144578313253e-05,
      "loss": 0.0279,
      "step": 34190
    },
    {
      "epoch": 4.120481927710843,
      "grad_norm": 0.1598152369260788,
      "learning_rate": 1.1759036144578315e-05,
      "loss": 0.0236,
      "step": 34200
    },
    {
      "epoch": 4.121686746987952,
      "grad_norm": 1.0135606527328491,
      "learning_rate": 1.1756626506024098e-05,
      "loss": 0.0034,
      "step": 34210
    },
    {
      "epoch": 4.12289156626506,
      "grad_norm": 2.3024353981018066,
      "learning_rate": 1.1754216867469881e-05,
      "loss": 0.0113,
      "step": 34220
    },
    {
      "epoch": 4.124096385542169,
      "grad_norm": 0.016168028116226196,
      "learning_rate": 1.1751807228915664e-05,
      "loss": 0.0476,
      "step": 34230
    },
    {
      "epoch": 4.125301204819277,
      "grad_norm": 0.04776039719581604,
      "learning_rate": 1.1749397590361447e-05,
      "loss": 0.0326,
      "step": 34240
    },
    {
      "epoch": 4.126506024096385,
      "grad_norm": 0.014552060514688492,
      "learning_rate": 1.1746987951807229e-05,
      "loss": 0.0092,
      "step": 34250
    },
    {
      "epoch": 4.127710843373494,
      "grad_norm": 16.971660614013672,
      "learning_rate": 1.1744578313253012e-05,
      "loss": 0.1101,
      "step": 34260
    },
    {
      "epoch": 4.128915662650602,
      "grad_norm": 7.877630710601807,
      "learning_rate": 1.1742168674698795e-05,
      "loss": 0.0354,
      "step": 34270
    },
    {
      "epoch": 4.130120481927711,
      "grad_norm": 0.13766226172447205,
      "learning_rate": 1.173975903614458e-05,
      "loss": 0.0142,
      "step": 34280
    },
    {
      "epoch": 4.13132530120482,
      "grad_norm": 0.02149396575987339,
      "learning_rate": 1.1737349397590363e-05,
      "loss": 0.0128,
      "step": 34290
    },
    {
      "epoch": 4.132530120481928,
      "grad_norm": 0.6204022765159607,
      "learning_rate": 1.1734939759036146e-05,
      "loss": 0.0032,
      "step": 34300
    },
    {
      "epoch": 4.133734939759036,
      "grad_norm": 74.01933288574219,
      "learning_rate": 1.173253012048193e-05,
      "loss": 0.0347,
      "step": 34310
    },
    {
      "epoch": 4.134939759036144,
      "grad_norm": 0.5232834219932556,
      "learning_rate": 1.1730120481927711e-05,
      "loss": 0.0524,
      "step": 34320
    },
    {
      "epoch": 4.136144578313253,
      "grad_norm": 0.009773985482752323,
      "learning_rate": 1.1727710843373494e-05,
      "loss": 0.0036,
      "step": 34330
    },
    {
      "epoch": 4.137349397590361,
      "grad_norm": 0.23172131180763245,
      "learning_rate": 1.1725301204819277e-05,
      "loss": 0.0509,
      "step": 34340
    },
    {
      "epoch": 4.13855421686747,
      "grad_norm": 2.242419958114624,
      "learning_rate": 1.1722891566265062e-05,
      "loss": 0.0511,
      "step": 34350
    },
    {
      "epoch": 4.139759036144579,
      "grad_norm": 0.08462850749492645,
      "learning_rate": 1.1720481927710845e-05,
      "loss": 0.0329,
      "step": 34360
    },
    {
      "epoch": 4.1409638554216865,
      "grad_norm": 34.38250732421875,
      "learning_rate": 1.1718072289156629e-05,
      "loss": 0.0294,
      "step": 34370
    },
    {
      "epoch": 4.142168674698795,
      "grad_norm": 0.118950754404068,
      "learning_rate": 1.171566265060241e-05,
      "loss": 0.0141,
      "step": 34380
    },
    {
      "epoch": 4.143373493975903,
      "grad_norm": 0.14811910688877106,
      "learning_rate": 1.1713253012048193e-05,
      "loss": 0.0151,
      "step": 34390
    },
    {
      "epoch": 4.144578313253012,
      "grad_norm": 0.10172440856695175,
      "learning_rate": 1.1710843373493976e-05,
      "loss": 0.0154,
      "step": 34400
    },
    {
      "epoch": 4.145783132530121,
      "grad_norm": 0.191716268658638,
      "learning_rate": 1.170843373493976e-05,
      "loss": 0.0156,
      "step": 34410
    },
    {
      "epoch": 4.146987951807229,
      "grad_norm": 2.298769474029541,
      "learning_rate": 1.1706024096385543e-05,
      "loss": 0.0232,
      "step": 34420
    },
    {
      "epoch": 4.148192771084338,
      "grad_norm": 0.020113060250878334,
      "learning_rate": 1.1703614457831328e-05,
      "loss": 0.0533,
      "step": 34430
    },
    {
      "epoch": 4.1493975903614455,
      "grad_norm": 0.032009780406951904,
      "learning_rate": 1.170120481927711e-05,
      "loss": 0.0315,
      "step": 34440
    },
    {
      "epoch": 4.150602409638554,
      "grad_norm": 0.524709165096283,
      "learning_rate": 1.1698795180722892e-05,
      "loss": 0.031,
      "step": 34450
    },
    {
      "epoch": 4.151807228915662,
      "grad_norm": 23.771936416625977,
      "learning_rate": 1.1696385542168675e-05,
      "loss": 0.0758,
      "step": 34460
    },
    {
      "epoch": 4.153012048192771,
      "grad_norm": 0.01461738720536232,
      "learning_rate": 1.1693975903614459e-05,
      "loss": 0.0069,
      "step": 34470
    },
    {
      "epoch": 4.15421686746988,
      "grad_norm": 0.4370393753051758,
      "learning_rate": 1.1691566265060242e-05,
      "loss": 0.0298,
      "step": 34480
    },
    {
      "epoch": 4.155421686746988,
      "grad_norm": 0.006884229835122824,
      "learning_rate": 1.1689156626506025e-05,
      "loss": 0.0222,
      "step": 34490
    },
    {
      "epoch": 4.156626506024097,
      "grad_norm": 0.025084100663661957,
      "learning_rate": 1.168674698795181e-05,
      "loss": 0.0325,
      "step": 34500
    },
    {
      "epoch": 4.1578313253012045,
      "grad_norm": 0.010075888596475124,
      "learning_rate": 1.1684337349397591e-05,
      "loss": 0.0361,
      "step": 34510
    },
    {
      "epoch": 4.159036144578313,
      "grad_norm": 0.01153944805264473,
      "learning_rate": 1.1681927710843374e-05,
      "loss": 0.047,
      "step": 34520
    },
    {
      "epoch": 4.160240963855422,
      "grad_norm": 0.01101053599268198,
      "learning_rate": 1.1679518072289158e-05,
      "loss": 0.0209,
      "step": 34530
    },
    {
      "epoch": 4.16144578313253,
      "grad_norm": 1.0838110446929932,
      "learning_rate": 1.167710843373494e-05,
      "loss": 0.0642,
      "step": 34540
    },
    {
      "epoch": 4.162650602409639,
      "grad_norm": 0.026608292013406754,
      "learning_rate": 1.1674698795180724e-05,
      "loss": 0.0147,
      "step": 34550
    },
    {
      "epoch": 4.163855421686747,
      "grad_norm": 1.0902639627456665,
      "learning_rate": 1.1672289156626505e-05,
      "loss": 0.0261,
      "step": 34560
    },
    {
      "epoch": 4.1650602409638555,
      "grad_norm": 0.5403541326522827,
      "learning_rate": 1.1669879518072289e-05,
      "loss": 0.0329,
      "step": 34570
    },
    {
      "epoch": 4.166265060240963,
      "grad_norm": 1.2271984815597534,
      "learning_rate": 1.1667469879518074e-05,
      "loss": 0.0049,
      "step": 34580
    },
    {
      "epoch": 4.167469879518072,
      "grad_norm": 0.22822119295597076,
      "learning_rate": 1.1665060240963857e-05,
      "loss": 0.0018,
      "step": 34590
    },
    {
      "epoch": 4.168674698795181,
      "grad_norm": 0.13989658653736115,
      "learning_rate": 1.166265060240964e-05,
      "loss": 0.0004,
      "step": 34600
    },
    {
      "epoch": 4.169879518072289,
      "grad_norm": 0.016063617542386055,
      "learning_rate": 1.1660240963855423e-05,
      "loss": 0.0006,
      "step": 34610
    },
    {
      "epoch": 4.171084337349398,
      "grad_norm": 0.03094140812754631,
      "learning_rate": 1.1657831325301206e-05,
      "loss": 0.0289,
      "step": 34620
    },
    {
      "epoch": 4.172289156626506,
      "grad_norm": 0.007702924311161041,
      "learning_rate": 1.1655421686746988e-05,
      "loss": 0.0228,
      "step": 34630
    },
    {
      "epoch": 4.1734939759036145,
      "grad_norm": 0.009174056351184845,
      "learning_rate": 1.1653012048192771e-05,
      "loss": 0.0675,
      "step": 34640
    },
    {
      "epoch": 4.174698795180723,
      "grad_norm": 0.02185319922864437,
      "learning_rate": 1.1650602409638556e-05,
      "loss": 0.0214,
      "step": 34650
    },
    {
      "epoch": 4.175903614457831,
      "grad_norm": 1.4034711122512817,
      "learning_rate": 1.1648192771084339e-05,
      "loss": 0.0191,
      "step": 34660
    },
    {
      "epoch": 4.17710843373494,
      "grad_norm": 0.837697446346283,
      "learning_rate": 1.1645783132530122e-05,
      "loss": 0.0211,
      "step": 34670
    },
    {
      "epoch": 4.178313253012048,
      "grad_norm": 0.022410528734326363,
      "learning_rate": 1.1643373493975905e-05,
      "loss": 0.0748,
      "step": 34680
    },
    {
      "epoch": 4.179518072289157,
      "grad_norm": 0.011133074760437012,
      "learning_rate": 1.1640963855421687e-05,
      "loss": 0.0548,
      "step": 34690
    },
    {
      "epoch": 4.180722891566265,
      "grad_norm": 0.013708226382732391,
      "learning_rate": 1.163855421686747e-05,
      "loss": 0.0381,
      "step": 34700
    },
    {
      "epoch": 4.1819277108433734,
      "grad_norm": 0.5462136268615723,
      "learning_rate": 1.1636144578313253e-05,
      "loss": 0.0504,
      "step": 34710
    },
    {
      "epoch": 4.183132530120482,
      "grad_norm": 0.007280159741640091,
      "learning_rate": 1.1633734939759036e-05,
      "loss": 0.0277,
      "step": 34720
    },
    {
      "epoch": 4.18433734939759,
      "grad_norm": 0.008408698253333569,
      "learning_rate": 1.1631325301204821e-05,
      "loss": 0.0243,
      "step": 34730
    },
    {
      "epoch": 4.185542168674699,
      "grad_norm": 0.006497188471257687,
      "learning_rate": 1.1628915662650604e-05,
      "loss": 0.033,
      "step": 34740
    },
    {
      "epoch": 4.186746987951807,
      "grad_norm": 0.03209951892495155,
      "learning_rate": 1.1626506024096388e-05,
      "loss": 0.0195,
      "step": 34750
    },
    {
      "epoch": 4.187951807228916,
      "grad_norm": 0.01157753262668848,
      "learning_rate": 1.1624096385542169e-05,
      "loss": 0.0085,
      "step": 34760
    },
    {
      "epoch": 4.1891566265060245,
      "grad_norm": 0.027236701920628548,
      "learning_rate": 1.1621686746987952e-05,
      "loss": 0.0253,
      "step": 34770
    },
    {
      "epoch": 4.190361445783132,
      "grad_norm": 0.022974707186222076,
      "learning_rate": 1.1619277108433735e-05,
      "loss": 0.0193,
      "step": 34780
    },
    {
      "epoch": 4.191566265060241,
      "grad_norm": 0.347273588180542,
      "learning_rate": 1.1616867469879519e-05,
      "loss": 0.0231,
      "step": 34790
    },
    {
      "epoch": 4.192771084337349,
      "grad_norm": 0.03815785050392151,
      "learning_rate": 1.1614457831325303e-05,
      "loss": 0.0374,
      "step": 34800
    },
    {
      "epoch": 4.193975903614458,
      "grad_norm": 0.015656528994441032,
      "learning_rate": 1.1612048192771087e-05,
      "loss": 0.0047,
      "step": 34810
    },
    {
      "epoch": 4.195180722891566,
      "grad_norm": 102.82760620117188,
      "learning_rate": 1.1609638554216868e-05,
      "loss": 0.0048,
      "step": 34820
    },
    {
      "epoch": 4.196385542168675,
      "grad_norm": 0.034564755856990814,
      "learning_rate": 1.1607228915662651e-05,
      "loss": 0.0483,
      "step": 34830
    },
    {
      "epoch": 4.1975903614457835,
      "grad_norm": 0.025639962404966354,
      "learning_rate": 1.1604819277108434e-05,
      "loss": 0.0219,
      "step": 34840
    },
    {
      "epoch": 4.198795180722891,
      "grad_norm": 0.47010430693626404,
      "learning_rate": 1.1602409638554218e-05,
      "loss": 0.0209,
      "step": 34850
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.0137674808502197,
      "learning_rate": 1.16e-05,
      "loss": 0.0579,
      "step": 34860
    },
    {
      "epoch": 4.201204819277108,
      "grad_norm": 0.02212037704885006,
      "learning_rate": 1.1597590361445782e-05,
      "loss": 0.0218,
      "step": 34870
    },
    {
      "epoch": 4.202409638554217,
      "grad_norm": 0.021061817184090614,
      "learning_rate": 1.1595180722891569e-05,
      "loss": 0.0223,
      "step": 34880
    },
    {
      "epoch": 4.203614457831326,
      "grad_norm": 6.723881244659424,
      "learning_rate": 1.159277108433735e-05,
      "loss": 0.1043,
      "step": 34890
    },
    {
      "epoch": 4.204819277108434,
      "grad_norm": 2.5877845287323,
      "learning_rate": 1.1590361445783133e-05,
      "loss": 0.0364,
      "step": 34900
    },
    {
      "epoch": 4.206024096385542,
      "grad_norm": 0.6438597440719604,
      "learning_rate": 1.1587951807228917e-05,
      "loss": 0.0094,
      "step": 34910
    },
    {
      "epoch": 4.20722891566265,
      "grad_norm": 1.744531512260437,
      "learning_rate": 1.15855421686747e-05,
      "loss": 0.0393,
      "step": 34920
    },
    {
      "epoch": 4.208433734939759,
      "grad_norm": 2.2605700492858887,
      "learning_rate": 1.1583132530120483e-05,
      "loss": 0.013,
      "step": 34930
    },
    {
      "epoch": 4.209638554216867,
      "grad_norm": 2.877856731414795,
      "learning_rate": 1.1580722891566264e-05,
      "loss": 0.0618,
      "step": 34940
    },
    {
      "epoch": 4.210843373493976,
      "grad_norm": 0.03193182870745659,
      "learning_rate": 1.157831325301205e-05,
      "loss": 0.0018,
      "step": 34950
    },
    {
      "epoch": 4.212048192771085,
      "grad_norm": 0.036737024784088135,
      "learning_rate": 1.1575903614457833e-05,
      "loss": 0.013,
      "step": 34960
    },
    {
      "epoch": 4.213253012048193,
      "grad_norm": 2.225924491882324,
      "learning_rate": 1.1573493975903616e-05,
      "loss": 0.0103,
      "step": 34970
    },
    {
      "epoch": 4.214457831325301,
      "grad_norm": 0.006567006465047598,
      "learning_rate": 1.1571084337349399e-05,
      "loss": 0.0651,
      "step": 34980
    },
    {
      "epoch": 4.215662650602409,
      "grad_norm": 0.01652355119585991,
      "learning_rate": 1.1568674698795182e-05,
      "loss": 0.0571,
      "step": 34990
    },
    {
      "epoch": 4.216867469879518,
      "grad_norm": 0.3250492513179779,
      "learning_rate": 1.1566265060240964e-05,
      "loss": 0.0177,
      "step": 35000
    },
    {
      "epoch": 4.218072289156627,
      "grad_norm": 0.014857441186904907,
      "learning_rate": 1.1563855421686747e-05,
      "loss": 0.0229,
      "step": 35010
    },
    {
      "epoch": 4.219277108433735,
      "grad_norm": 0.03436492756009102,
      "learning_rate": 1.156144578313253e-05,
      "loss": 0.0106,
      "step": 35020
    },
    {
      "epoch": 4.220481927710844,
      "grad_norm": 0.18985238671302795,
      "learning_rate": 1.1559036144578315e-05,
      "loss": 0.0565,
      "step": 35030
    },
    {
      "epoch": 4.2216867469879515,
      "grad_norm": 1.1909912824630737,
      "learning_rate": 1.1556626506024098e-05,
      "loss": 0.0402,
      "step": 35040
    },
    {
      "epoch": 4.22289156626506,
      "grad_norm": 0.029271546751260757,
      "learning_rate": 1.1554216867469881e-05,
      "loss": 0.0392,
      "step": 35050
    },
    {
      "epoch": 4.224096385542168,
      "grad_norm": 1.6867653131484985,
      "learning_rate": 1.1551807228915664e-05,
      "loss": 0.0528,
      "step": 35060
    },
    {
      "epoch": 4.225301204819277,
      "grad_norm": 0.04030568525195122,
      "learning_rate": 1.1549397590361446e-05,
      "loss": 0.0293,
      "step": 35070
    },
    {
      "epoch": 4.226506024096386,
      "grad_norm": 3.1179730892181396,
      "learning_rate": 1.1546987951807229e-05,
      "loss": 0.0081,
      "step": 35080
    },
    {
      "epoch": 4.227710843373494,
      "grad_norm": 0.03141956776380539,
      "learning_rate": 1.1544578313253012e-05,
      "loss": 0.0384,
      "step": 35090
    },
    {
      "epoch": 4.228915662650603,
      "grad_norm": 0.11819984763860703,
      "learning_rate": 1.1542168674698797e-05,
      "loss": 0.033,
      "step": 35100
    },
    {
      "epoch": 4.2301204819277105,
      "grad_norm": 1.7735344171524048,
      "learning_rate": 1.153975903614458e-05,
      "loss": 0.0457,
      "step": 35110
    },
    {
      "epoch": 4.231325301204819,
      "grad_norm": 3.331820249557495,
      "learning_rate": 1.1537349397590363e-05,
      "loss": 0.0439,
      "step": 35120
    },
    {
      "epoch": 4.232530120481928,
      "grad_norm": 0.19170865416526794,
      "learning_rate": 1.1534939759036145e-05,
      "loss": 0.0456,
      "step": 35130
    },
    {
      "epoch": 4.233734939759036,
      "grad_norm": 0.15854313969612122,
      "learning_rate": 1.1532530120481928e-05,
      "loss": 0.0297,
      "step": 35140
    },
    {
      "epoch": 4.234939759036145,
      "grad_norm": 0.11332038044929504,
      "learning_rate": 1.1530120481927711e-05,
      "loss": 0.048,
      "step": 35150
    },
    {
      "epoch": 4.236144578313253,
      "grad_norm": 0.13471786677837372,
      "learning_rate": 1.1527710843373494e-05,
      "loss": 0.0377,
      "step": 35160
    },
    {
      "epoch": 4.2373493975903616,
      "grad_norm": 0.22707808017730713,
      "learning_rate": 1.1525301204819278e-05,
      "loss": 0.0116,
      "step": 35170
    },
    {
      "epoch": 4.2385542168674695,
      "grad_norm": 8.123101234436035,
      "learning_rate": 1.1522891566265062e-05,
      "loss": 0.0342,
      "step": 35180
    },
    {
      "epoch": 4.239759036144578,
      "grad_norm": 0.020081643015146255,
      "learning_rate": 1.1520481927710846e-05,
      "loss": 0.0275,
      "step": 35190
    },
    {
      "epoch": 4.240963855421687,
      "grad_norm": 0.03832964226603508,
      "learning_rate": 1.1518072289156627e-05,
      "loss": 0.0203,
      "step": 35200
    },
    {
      "epoch": 4.242168674698795,
      "grad_norm": 0.025107353925704956,
      "learning_rate": 1.151566265060241e-05,
      "loss": 0.027,
      "step": 35210
    },
    {
      "epoch": 4.243373493975904,
      "grad_norm": 0.08719327300786972,
      "learning_rate": 1.1513253012048193e-05,
      "loss": 0.0065,
      "step": 35220
    },
    {
      "epoch": 4.244578313253012,
      "grad_norm": 0.00468585267663002,
      "learning_rate": 1.1510843373493977e-05,
      "loss": 0.0611,
      "step": 35230
    },
    {
      "epoch": 4.2457831325301205,
      "grad_norm": 2.7685353755950928,
      "learning_rate": 1.150843373493976e-05,
      "loss": 0.0258,
      "step": 35240
    },
    {
      "epoch": 4.246987951807229,
      "grad_norm": 0.3194487690925598,
      "learning_rate": 1.1506024096385545e-05,
      "loss": 0.041,
      "step": 35250
    },
    {
      "epoch": 4.248192771084337,
      "grad_norm": 0.4168297052383423,
      "learning_rate": 1.1503614457831326e-05,
      "loss": 0.0106,
      "step": 35260
    },
    {
      "epoch": 4.249397590361446,
      "grad_norm": 0.007623060140758753,
      "learning_rate": 1.150120481927711e-05,
      "loss": 0.0057,
      "step": 35270
    },
    {
      "epoch": 4.250602409638554,
      "grad_norm": 1.0334597826004028,
      "learning_rate": 1.1498795180722892e-05,
      "loss": 0.0122,
      "step": 35280
    },
    {
      "epoch": 4.251807228915663,
      "grad_norm": 0.0048529584892094135,
      "learning_rate": 1.1496385542168676e-05,
      "loss": 0.0131,
      "step": 35290
    },
    {
      "epoch": 4.253012048192771,
      "grad_norm": 0.008268938399851322,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 0.0119,
      "step": 35300
    },
    {
      "epoch": 4.2542168674698795,
      "grad_norm": 1.185498833656311,
      "learning_rate": 1.149156626506024e-05,
      "loss": 0.0319,
      "step": 35310
    },
    {
      "epoch": 4.255421686746988,
      "grad_norm": 0.5044400095939636,
      "learning_rate": 1.1489156626506027e-05,
      "loss": 0.0607,
      "step": 35320
    },
    {
      "epoch": 4.256626506024096,
      "grad_norm": 0.004062081221491098,
      "learning_rate": 1.1486746987951808e-05,
      "loss": 0.025,
      "step": 35330
    },
    {
      "epoch": 4.257831325301205,
      "grad_norm": 7.419281482696533,
      "learning_rate": 1.1484337349397592e-05,
      "loss": 0.0618,
      "step": 35340
    },
    {
      "epoch": 4.259036144578313,
      "grad_norm": 0.1271573305130005,
      "learning_rate": 1.1481927710843375e-05,
      "loss": 0.0142,
      "step": 35350
    },
    {
      "epoch": 4.260240963855422,
      "grad_norm": 3.125751495361328,
      "learning_rate": 1.1479518072289158e-05,
      "loss": 0.058,
      "step": 35360
    },
    {
      "epoch": 4.2614457831325305,
      "grad_norm": 2.131075859069824,
      "learning_rate": 1.1477108433734941e-05,
      "loss": 0.0091,
      "step": 35370
    },
    {
      "epoch": 4.2626506024096384,
      "grad_norm": 1.62489652633667,
      "learning_rate": 1.1474698795180723e-05,
      "loss": 0.0175,
      "step": 35380
    },
    {
      "epoch": 4.263855421686747,
      "grad_norm": 1.294410228729248,
      "learning_rate": 1.1472289156626506e-05,
      "loss": 0.0336,
      "step": 35390
    },
    {
      "epoch": 4.265060240963855,
      "grad_norm": 0.007360601332038641,
      "learning_rate": 1.146987951807229e-05,
      "loss": 0.0555,
      "step": 35400
    },
    {
      "epoch": 4.266265060240964,
      "grad_norm": 0.012804659083485603,
      "learning_rate": 1.1467469879518074e-05,
      "loss": 0.0064,
      "step": 35410
    },
    {
      "epoch": 4.267469879518072,
      "grad_norm": 0.0706464871764183,
      "learning_rate": 1.1465060240963857e-05,
      "loss": 0.025,
      "step": 35420
    },
    {
      "epoch": 4.268674698795181,
      "grad_norm": 7.459582328796387,
      "learning_rate": 1.146265060240964e-05,
      "loss": 0.0101,
      "step": 35430
    },
    {
      "epoch": 4.2698795180722895,
      "grad_norm": 35.399784088134766,
      "learning_rate": 1.1460240963855422e-05,
      "loss": 0.0353,
      "step": 35440
    },
    {
      "epoch": 4.271084337349397,
      "grad_norm": 0.007050748448818922,
      "learning_rate": 1.1457831325301205e-05,
      "loss": 0.0281,
      "step": 35450
    },
    {
      "epoch": 4.272289156626506,
      "grad_norm": 0.07676638662815094,
      "learning_rate": 1.1455421686746988e-05,
      "loss": 0.0021,
      "step": 35460
    },
    {
      "epoch": 4.273493975903614,
      "grad_norm": 0.010918082669377327,
      "learning_rate": 1.1453012048192773e-05,
      "loss": 0.0331,
      "step": 35470
    },
    {
      "epoch": 4.274698795180723,
      "grad_norm": 0.01452520303428173,
      "learning_rate": 1.1450602409638556e-05,
      "loss": 0.0141,
      "step": 35480
    },
    {
      "epoch": 4.275903614457832,
      "grad_norm": 0.5326564311981201,
      "learning_rate": 1.1448192771084339e-05,
      "loss": 0.0617,
      "step": 35490
    },
    {
      "epoch": 4.27710843373494,
      "grad_norm": 0.00479194987565279,
      "learning_rate": 1.1445783132530122e-05,
      "loss": 0.0166,
      "step": 35500
    },
    {
      "epoch": 4.2783132530120485,
      "grad_norm": 0.45740437507629395,
      "learning_rate": 1.1443373493975904e-05,
      "loss": 0.0324,
      "step": 35510
    },
    {
      "epoch": 4.279518072289156,
      "grad_norm": 0.004863546695560217,
      "learning_rate": 1.1440963855421687e-05,
      "loss": 0.002,
      "step": 35520
    },
    {
      "epoch": 4.280722891566265,
      "grad_norm": 5.2010087966918945,
      "learning_rate": 1.143855421686747e-05,
      "loss": 0.0177,
      "step": 35530
    },
    {
      "epoch": 4.281927710843373,
      "grad_norm": 0.4551044702529907,
      "learning_rate": 1.1436144578313253e-05,
      "loss": 0.0206,
      "step": 35540
    },
    {
      "epoch": 4.283132530120482,
      "grad_norm": 0.004003174137324095,
      "learning_rate": 1.1433734939759038e-05,
      "loss": 0.0241,
      "step": 35550
    },
    {
      "epoch": 4.284337349397591,
      "grad_norm": 0.004438893869519234,
      "learning_rate": 1.1431325301204821e-05,
      "loss": 0.0048,
      "step": 35560
    },
    {
      "epoch": 4.285542168674699,
      "grad_norm": 0.0042817723006010056,
      "learning_rate": 1.1428915662650605e-05,
      "loss": 0.0525,
      "step": 35570
    },
    {
      "epoch": 4.286746987951807,
      "grad_norm": 24.626697540283203,
      "learning_rate": 1.1426506024096386e-05,
      "loss": 0.1071,
      "step": 35580
    },
    {
      "epoch": 4.287951807228915,
      "grad_norm": 0.026719827204942703,
      "learning_rate": 1.142409638554217e-05,
      "loss": 0.0004,
      "step": 35590
    },
    {
      "epoch": 4.289156626506024,
      "grad_norm": 2.9989449977874756,
      "learning_rate": 1.1421686746987952e-05,
      "loss": 0.0287,
      "step": 35600
    },
    {
      "epoch": 4.290361445783133,
      "grad_norm": 2.485520362854004,
      "learning_rate": 1.1419277108433736e-05,
      "loss": 0.0164,
      "step": 35610
    },
    {
      "epoch": 4.291566265060241,
      "grad_norm": 0.021918106824159622,
      "learning_rate": 1.141686746987952e-05,
      "loss": 0.0085,
      "step": 35620
    },
    {
      "epoch": 4.29277108433735,
      "grad_norm": 0.005715128965675831,
      "learning_rate": 1.1414457831325304e-05,
      "loss": 0.0369,
      "step": 35630
    },
    {
      "epoch": 4.293975903614458,
      "grad_norm": 0.006395311094820499,
      "learning_rate": 1.1412048192771085e-05,
      "loss": 0.0158,
      "step": 35640
    },
    {
      "epoch": 4.295180722891566,
      "grad_norm": 0.006848943419754505,
      "learning_rate": 1.1409638554216868e-05,
      "loss": 0.0262,
      "step": 35650
    },
    {
      "epoch": 4.296385542168674,
      "grad_norm": 0.44108742475509644,
      "learning_rate": 1.1407228915662651e-05,
      "loss": 0.0233,
      "step": 35660
    },
    {
      "epoch": 4.297590361445783,
      "grad_norm": 0.04288071021437645,
      "learning_rate": 1.1404819277108435e-05,
      "loss": 0.0238,
      "step": 35670
    },
    {
      "epoch": 4.298795180722892,
      "grad_norm": 27.578645706176758,
      "learning_rate": 1.1402409638554218e-05,
      "loss": 0.0344,
      "step": 35680
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.6809225082397461,
      "learning_rate": 1.14e-05,
      "loss": 0.039,
      "step": 35690
    },
    {
      "epoch": 4.301204819277109,
      "grad_norm": 0.19744832813739777,
      "learning_rate": 1.1397590361445786e-05,
      "loss": 0.0284,
      "step": 35700
    },
    {
      "epoch": 4.3024096385542165,
      "grad_norm": 6.099738597869873,
      "learning_rate": 1.1395180722891567e-05,
      "loss": 0.0444,
      "step": 35710
    },
    {
      "epoch": 4.303614457831325,
      "grad_norm": 1.3447750806808472,
      "learning_rate": 1.139277108433735e-05,
      "loss": 0.035,
      "step": 35720
    },
    {
      "epoch": 4.304819277108434,
      "grad_norm": 166.082763671875,
      "learning_rate": 1.1390361445783134e-05,
      "loss": 0.0759,
      "step": 35730
    },
    {
      "epoch": 4.306024096385542,
      "grad_norm": 0.367022305727005,
      "learning_rate": 1.1387951807228917e-05,
      "loss": 0.0051,
      "step": 35740
    },
    {
      "epoch": 4.307228915662651,
      "grad_norm": 0.006174422334879637,
      "learning_rate": 1.13855421686747e-05,
      "loss": 0.0451,
      "step": 35750
    },
    {
      "epoch": 4.308433734939759,
      "grad_norm": 0.013939890079200268,
      "learning_rate": 1.1383132530120482e-05,
      "loss": 0.0115,
      "step": 35760
    },
    {
      "epoch": 4.309638554216868,
      "grad_norm": 7.99867057800293,
      "learning_rate": 1.1380722891566266e-05,
      "loss": 0.0641,
      "step": 35770
    },
    {
      "epoch": 4.3108433734939755,
      "grad_norm": 5.334643840789795,
      "learning_rate": 1.137831325301205e-05,
      "loss": 0.0393,
      "step": 35780
    },
    {
      "epoch": 4.312048192771084,
      "grad_norm": 0.21351806819438934,
      "learning_rate": 1.1375903614457833e-05,
      "loss": 0.0132,
      "step": 35790
    },
    {
      "epoch": 4.313253012048193,
      "grad_norm": 0.025910792872309685,
      "learning_rate": 1.1373493975903616e-05,
      "loss": 0.0401,
      "step": 35800
    },
    {
      "epoch": 4.314457831325301,
      "grad_norm": 0.012201663106679916,
      "learning_rate": 1.1371084337349399e-05,
      "loss": 0.0094,
      "step": 35810
    },
    {
      "epoch": 4.31566265060241,
      "grad_norm": 0.17649485170841217,
      "learning_rate": 1.136867469879518e-05,
      "loss": 0.0193,
      "step": 35820
    },
    {
      "epoch": 4.316867469879518,
      "grad_norm": 10.099963188171387,
      "learning_rate": 1.1366265060240964e-05,
      "loss": 0.0275,
      "step": 35830
    },
    {
      "epoch": 4.3180722891566266,
      "grad_norm": 0.17411620914936066,
      "learning_rate": 1.1363855421686747e-05,
      "loss": 0.0019,
      "step": 35840
    },
    {
      "epoch": 4.3192771084337345,
      "grad_norm": 3.3546361923217773,
      "learning_rate": 1.1361445783132532e-05,
      "loss": 0.0674,
      "step": 35850
    },
    {
      "epoch": 4.320481927710843,
      "grad_norm": 0.010283801704645157,
      "learning_rate": 1.1359036144578315e-05,
      "loss": 0.0127,
      "step": 35860
    },
    {
      "epoch": 4.321686746987952,
      "grad_norm": 0.006443494465202093,
      "learning_rate": 1.1356626506024098e-05,
      "loss": 0.0175,
      "step": 35870
    },
    {
      "epoch": 4.32289156626506,
      "grad_norm": 1.009059190750122,
      "learning_rate": 1.1354216867469881e-05,
      "loss": 0.0419,
      "step": 35880
    },
    {
      "epoch": 4.324096385542169,
      "grad_norm": 0.2524498701095581,
      "learning_rate": 1.1351807228915663e-05,
      "loss": 0.0269,
      "step": 35890
    },
    {
      "epoch": 4.325301204819277,
      "grad_norm": 0.010332470759749413,
      "learning_rate": 1.1349397590361446e-05,
      "loss": 0.0672,
      "step": 35900
    },
    {
      "epoch": 4.3265060240963855,
      "grad_norm": 0.011710556223988533,
      "learning_rate": 1.1346987951807229e-05,
      "loss": 0.0305,
      "step": 35910
    },
    {
      "epoch": 4.327710843373494,
      "grad_norm": 0.01447730977088213,
      "learning_rate": 1.1344578313253014e-05,
      "loss": 0.0432,
      "step": 35920
    },
    {
      "epoch": 4.328915662650602,
      "grad_norm": 0.10277906805276871,
      "learning_rate": 1.1342168674698797e-05,
      "loss": 0.0287,
      "step": 35930
    },
    {
      "epoch": 4.330120481927711,
      "grad_norm": 2.7645719051361084,
      "learning_rate": 1.133975903614458e-05,
      "loss": 0.0319,
      "step": 35940
    },
    {
      "epoch": 4.331325301204819,
      "grad_norm": 1.0169851779937744,
      "learning_rate": 1.1337349397590362e-05,
      "loss": 0.0547,
      "step": 35950
    },
    {
      "epoch": 4.332530120481928,
      "grad_norm": 0.05647043138742447,
      "learning_rate": 1.1334939759036145e-05,
      "loss": 0.0296,
      "step": 35960
    },
    {
      "epoch": 4.333734939759037,
      "grad_norm": 0.025430677458643913,
      "learning_rate": 1.1332530120481928e-05,
      "loss": 0.0164,
      "step": 35970
    },
    {
      "epoch": 4.3349397590361445,
      "grad_norm": 5.256231784820557,
      "learning_rate": 1.1330120481927711e-05,
      "loss": 0.0617,
      "step": 35980
    },
    {
      "epoch": 4.336144578313253,
      "grad_norm": 0.10636795312166214,
      "learning_rate": 1.1327710843373495e-05,
      "loss": 0.0384,
      "step": 35990
    },
    {
      "epoch": 4.337349397590361,
      "grad_norm": 0.46981993317604065,
      "learning_rate": 1.132530120481928e-05,
      "loss": 0.0177,
      "step": 36000
    },
    {
      "epoch": 4.33855421686747,
      "grad_norm": 0.12764309346675873,
      "learning_rate": 1.1322891566265063e-05,
      "loss": 0.0297,
      "step": 36010
    },
    {
      "epoch": 4.339759036144578,
      "grad_norm": 0.021109357476234436,
      "learning_rate": 1.1320481927710844e-05,
      "loss": 0.0116,
      "step": 36020
    },
    {
      "epoch": 4.340963855421687,
      "grad_norm": 0.3012346029281616,
      "learning_rate": 1.1318072289156627e-05,
      "loss": 0.0065,
      "step": 36030
    },
    {
      "epoch": 4.3421686746987955,
      "grad_norm": 6.8777570724487305,
      "learning_rate": 1.131566265060241e-05,
      "loss": 0.0616,
      "step": 36040
    },
    {
      "epoch": 4.343373493975903,
      "grad_norm": 0.21974898874759674,
      "learning_rate": 1.1313253012048194e-05,
      "loss": 0.0078,
      "step": 36050
    },
    {
      "epoch": 4.344578313253012,
      "grad_norm": 0.08741011470556259,
      "learning_rate": 1.1310843373493977e-05,
      "loss": 0.0328,
      "step": 36060
    },
    {
      "epoch": 4.34578313253012,
      "grad_norm": 0.033460404723882675,
      "learning_rate": 1.1308433734939762e-05,
      "loss": 0.0091,
      "step": 36070
    },
    {
      "epoch": 4.346987951807229,
      "grad_norm": 20.450428009033203,
      "learning_rate": 1.1306024096385543e-05,
      "loss": 0.0502,
      "step": 36080
    },
    {
      "epoch": 4.348192771084337,
      "grad_norm": 0.28279340267181396,
      "learning_rate": 1.1303614457831326e-05,
      "loss": 0.0078,
      "step": 36090
    },
    {
      "epoch": 4.349397590361446,
      "grad_norm": 12.873613357543945,
      "learning_rate": 1.130120481927711e-05,
      "loss": 0.0245,
      "step": 36100
    },
    {
      "epoch": 4.3506024096385545,
      "grad_norm": 1.4177043437957764,
      "learning_rate": 1.1298795180722893e-05,
      "loss": 0.0057,
      "step": 36110
    },
    {
      "epoch": 4.351807228915662,
      "grad_norm": 9.142772674560547,
      "learning_rate": 1.1296385542168676e-05,
      "loss": 0.043,
      "step": 36120
    },
    {
      "epoch": 4.353012048192771,
      "grad_norm": 2.089057683944702,
      "learning_rate": 1.1293975903614457e-05,
      "loss": 0.0174,
      "step": 36130
    },
    {
      "epoch": 4.354216867469879,
      "grad_norm": 0.00438593840226531,
      "learning_rate": 1.129156626506024e-05,
      "loss": 0.0122,
      "step": 36140
    },
    {
      "epoch": 4.355421686746988,
      "grad_norm": 19.966753005981445,
      "learning_rate": 1.1289156626506025e-05,
      "loss": 0.0697,
      "step": 36150
    },
    {
      "epoch": 4.356626506024097,
      "grad_norm": 0.014062231406569481,
      "learning_rate": 1.1286746987951809e-05,
      "loss": 0.0209,
      "step": 36160
    },
    {
      "epoch": 4.357831325301205,
      "grad_norm": 0.9485352635383606,
      "learning_rate": 1.1284337349397592e-05,
      "loss": 0.0284,
      "step": 36170
    },
    {
      "epoch": 4.3590361445783135,
      "grad_norm": 0.0248640738427639,
      "learning_rate": 1.1281927710843375e-05,
      "loss": 0.0302,
      "step": 36180
    },
    {
      "epoch": 4.360240963855421,
      "grad_norm": 0.30479949712753296,
      "learning_rate": 1.1279518072289158e-05,
      "loss": 0.0035,
      "step": 36190
    },
    {
      "epoch": 4.36144578313253,
      "grad_norm": 1.0298264026641846,
      "learning_rate": 1.127710843373494e-05,
      "loss": 0.0412,
      "step": 36200
    },
    {
      "epoch": 4.362650602409639,
      "grad_norm": 0.4495944380760193,
      "learning_rate": 1.1274698795180723e-05,
      "loss": 0.0461,
      "step": 36210
    },
    {
      "epoch": 4.363855421686747,
      "grad_norm": 0.15566693246364594,
      "learning_rate": 1.1272289156626508e-05,
      "loss": 0.0137,
      "step": 36220
    },
    {
      "epoch": 4.365060240963856,
      "grad_norm": 8.657465934753418,
      "learning_rate": 1.126987951807229e-05,
      "loss": 0.0374,
      "step": 36230
    },
    {
      "epoch": 4.366265060240964,
      "grad_norm": 1.8732962608337402,
      "learning_rate": 1.1267469879518074e-05,
      "loss": 0.0338,
      "step": 36240
    },
    {
      "epoch": 4.367469879518072,
      "grad_norm": 0.019198134541511536,
      "learning_rate": 1.1265060240963857e-05,
      "loss": 0.0523,
      "step": 36250
    },
    {
      "epoch": 4.36867469879518,
      "grad_norm": 3.5678656101226807,
      "learning_rate": 1.1262650602409639e-05,
      "loss": 0.0176,
      "step": 36260
    },
    {
      "epoch": 4.369879518072289,
      "grad_norm": 0.6371946334838867,
      "learning_rate": 1.1260240963855422e-05,
      "loss": 0.0659,
      "step": 36270
    },
    {
      "epoch": 4.371084337349398,
      "grad_norm": 0.882865309715271,
      "learning_rate": 1.1257831325301205e-05,
      "loss": 0.0391,
      "step": 36280
    },
    {
      "epoch": 4.372289156626506,
      "grad_norm": 0.790009081363678,
      "learning_rate": 1.1255421686746988e-05,
      "loss": 0.0192,
      "step": 36290
    },
    {
      "epoch": 4.373493975903615,
      "grad_norm": 2.610325574874878,
      "learning_rate": 1.1253012048192773e-05,
      "loss": 0.0681,
      "step": 36300
    },
    {
      "epoch": 4.374698795180723,
      "grad_norm": 0.17374993860721588,
      "learning_rate": 1.1250602409638556e-05,
      "loss": 0.0105,
      "step": 36310
    },
    {
      "epoch": 4.375903614457831,
      "grad_norm": 0.1969311684370041,
      "learning_rate": 1.124819277108434e-05,
      "loss": 0.013,
      "step": 36320
    },
    {
      "epoch": 4.377108433734939,
      "grad_norm": 8.950325965881348,
      "learning_rate": 1.124578313253012e-05,
      "loss": 0.0577,
      "step": 36330
    },
    {
      "epoch": 4.378313253012048,
      "grad_norm": 17.11865997314453,
      "learning_rate": 1.1243373493975904e-05,
      "loss": 0.0293,
      "step": 36340
    },
    {
      "epoch": 4.379518072289157,
      "grad_norm": 0.013394953683018684,
      "learning_rate": 1.1240963855421687e-05,
      "loss": 0.0445,
      "step": 36350
    },
    {
      "epoch": 4.380722891566265,
      "grad_norm": 0.018873099237680435,
      "learning_rate": 1.123855421686747e-05,
      "loss": 0.0188,
      "step": 36360
    },
    {
      "epoch": 4.381927710843374,
      "grad_norm": 9.1742582321167,
      "learning_rate": 1.1236144578313255e-05,
      "loss": 0.0268,
      "step": 36370
    },
    {
      "epoch": 4.3831325301204815,
      "grad_norm": 1.2653014659881592,
      "learning_rate": 1.1233734939759038e-05,
      "loss": 0.0416,
      "step": 36380
    },
    {
      "epoch": 4.38433734939759,
      "grad_norm": 0.034964464604854584,
      "learning_rate": 1.123132530120482e-05,
      "loss": 0.0032,
      "step": 36390
    },
    {
      "epoch": 4.385542168674699,
      "grad_norm": 0.00981401838362217,
      "learning_rate": 1.1228915662650603e-05,
      "loss": 0.0072,
      "step": 36400
    },
    {
      "epoch": 4.386746987951807,
      "grad_norm": 0.004083768464624882,
      "learning_rate": 1.1226506024096386e-05,
      "loss": 0.0368,
      "step": 36410
    },
    {
      "epoch": 4.387951807228916,
      "grad_norm": 0.19886229932308197,
      "learning_rate": 1.122409638554217e-05,
      "loss": 0.0372,
      "step": 36420
    },
    {
      "epoch": 4.389156626506024,
      "grad_norm": 1.6382793188095093,
      "learning_rate": 1.1221686746987953e-05,
      "loss": 0.0491,
      "step": 36430
    },
    {
      "epoch": 4.390361445783133,
      "grad_norm": 0.10321561247110367,
      "learning_rate": 1.1219277108433734e-05,
      "loss": 0.0669,
      "step": 36440
    },
    {
      "epoch": 4.391566265060241,
      "grad_norm": 0.005576825700700283,
      "learning_rate": 1.121686746987952e-05,
      "loss": 0.0194,
      "step": 36450
    },
    {
      "epoch": 4.392771084337349,
      "grad_norm": 0.19707317650318146,
      "learning_rate": 1.1214457831325302e-05,
      "loss": 0.0049,
      "step": 36460
    },
    {
      "epoch": 4.393975903614458,
      "grad_norm": 0.010941694490611553,
      "learning_rate": 1.1212048192771085e-05,
      "loss": 0.0407,
      "step": 36470
    },
    {
      "epoch": 4.395180722891566,
      "grad_norm": 2.5392682552337646,
      "learning_rate": 1.1209638554216868e-05,
      "loss": 0.0698,
      "step": 36480
    },
    {
      "epoch": 4.396385542168675,
      "grad_norm": 0.11871366947889328,
      "learning_rate": 1.1207228915662652e-05,
      "loss": 0.0052,
      "step": 36490
    },
    {
      "epoch": 4.397590361445783,
      "grad_norm": 0.37835782766342163,
      "learning_rate": 1.1204819277108435e-05,
      "loss": 0.0214,
      "step": 36500
    },
    {
      "epoch": 4.3987951807228916,
      "grad_norm": 8.236071586608887,
      "learning_rate": 1.1202409638554216e-05,
      "loss": 0.0467,
      "step": 36510
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.9069412350654602,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0133,
      "step": 36520
    },
    {
      "epoch": 4.401204819277108,
      "grad_norm": 0.005446582101285458,
      "learning_rate": 1.1197590361445784e-05,
      "loss": 0.0389,
      "step": 36530
    },
    {
      "epoch": 4.402409638554217,
      "grad_norm": 0.17409910261631012,
      "learning_rate": 1.1195180722891568e-05,
      "loss": 0.0469,
      "step": 36540
    },
    {
      "epoch": 4.403614457831325,
      "grad_norm": 31.88558578491211,
      "learning_rate": 1.119277108433735e-05,
      "loss": 0.0549,
      "step": 36550
    },
    {
      "epoch": 4.404819277108434,
      "grad_norm": 3.0764520168304443,
      "learning_rate": 1.1190361445783134e-05,
      "loss": 0.0165,
      "step": 36560
    },
    {
      "epoch": 4.406024096385542,
      "grad_norm": 0.5959730744361877,
      "learning_rate": 1.1187951807228915e-05,
      "loss": 0.0271,
      "step": 36570
    },
    {
      "epoch": 4.4072289156626505,
      "grad_norm": 0.0158847626298666,
      "learning_rate": 1.1185542168674699e-05,
      "loss": 0.0182,
      "step": 36580
    },
    {
      "epoch": 4.408433734939759,
      "grad_norm": 0.03692607581615448,
      "learning_rate": 1.1183132530120482e-05,
      "loss": 0.0021,
      "step": 36590
    },
    {
      "epoch": 4.409638554216867,
      "grad_norm": 0.006533322390168905,
      "learning_rate": 1.1180722891566267e-05,
      "loss": 0.0262,
      "step": 36600
    },
    {
      "epoch": 4.410843373493976,
      "grad_norm": 0.004795440938323736,
      "learning_rate": 1.117831325301205e-05,
      "loss": 0.0048,
      "step": 36610
    },
    {
      "epoch": 4.412048192771084,
      "grad_norm": 1.1730152368545532,
      "learning_rate": 1.1175903614457833e-05,
      "loss": 0.046,
      "step": 36620
    },
    {
      "epoch": 4.413253012048193,
      "grad_norm": 0.7327317595481873,
      "learning_rate": 1.1173493975903616e-05,
      "loss": 0.0484,
      "step": 36630
    },
    {
      "epoch": 4.414457831325302,
      "grad_norm": 0.004999406170099974,
      "learning_rate": 1.1171084337349398e-05,
      "loss": 0.0369,
      "step": 36640
    },
    {
      "epoch": 4.4156626506024095,
      "grad_norm": 0.0071472120471298695,
      "learning_rate": 1.116867469879518e-05,
      "loss": 0.0047,
      "step": 36650
    },
    {
      "epoch": 4.416867469879518,
      "grad_norm": 3.357879400253296,
      "learning_rate": 1.1166265060240964e-05,
      "loss": 0.0181,
      "step": 36660
    },
    {
      "epoch": 4.418072289156626,
      "grad_norm": 0.020192256197333336,
      "learning_rate": 1.1163855421686749e-05,
      "loss": 0.0178,
      "step": 36670
    },
    {
      "epoch": 4.419277108433735,
      "grad_norm": 7.986021041870117,
      "learning_rate": 1.1161445783132532e-05,
      "loss": 0.0535,
      "step": 36680
    },
    {
      "epoch": 4.420481927710844,
      "grad_norm": 0.5933372974395752,
      "learning_rate": 1.1159036144578315e-05,
      "loss": 0.025,
      "step": 36690
    },
    {
      "epoch": 4.421686746987952,
      "grad_norm": 0.09872332215309143,
      "learning_rate": 1.1156626506024097e-05,
      "loss": 0.0187,
      "step": 36700
    },
    {
      "epoch": 4.4228915662650605,
      "grad_norm": 6.705381870269775,
      "learning_rate": 1.115421686746988e-05,
      "loss": 0.0049,
      "step": 36710
    },
    {
      "epoch": 4.424096385542168,
      "grad_norm": 0.7597109079360962,
      "learning_rate": 1.1151807228915663e-05,
      "loss": 0.0285,
      "step": 36720
    },
    {
      "epoch": 4.425301204819277,
      "grad_norm": 7.88960075378418,
      "learning_rate": 1.1149397590361446e-05,
      "loss": 0.0517,
      "step": 36730
    },
    {
      "epoch": 4.426506024096385,
      "grad_norm": 0.043221693485975266,
      "learning_rate": 1.114698795180723e-05,
      "loss": 0.0445,
      "step": 36740
    },
    {
      "epoch": 4.427710843373494,
      "grad_norm": 2.743320941925049,
      "learning_rate": 1.1144578313253014e-05,
      "loss": 0.0291,
      "step": 36750
    },
    {
      "epoch": 4.428915662650603,
      "grad_norm": 3.6152570247650146,
      "learning_rate": 1.1142168674698797e-05,
      "loss": 0.0722,
      "step": 36760
    },
    {
      "epoch": 4.430120481927711,
      "grad_norm": 16.55925178527832,
      "learning_rate": 1.1139759036144579e-05,
      "loss": 0.0191,
      "step": 36770
    },
    {
      "epoch": 4.4313253012048195,
      "grad_norm": 10.559305191040039,
      "learning_rate": 1.1137349397590362e-05,
      "loss": 0.0367,
      "step": 36780
    },
    {
      "epoch": 4.432530120481927,
      "grad_norm": 1.192635416984558,
      "learning_rate": 1.1134939759036145e-05,
      "loss": 0.0128,
      "step": 36790
    },
    {
      "epoch": 4.433734939759036,
      "grad_norm": 0.010308396071195602,
      "learning_rate": 1.1132530120481928e-05,
      "loss": 0.043,
      "step": 36800
    },
    {
      "epoch": 4.434939759036144,
      "grad_norm": 0.055156901478767395,
      "learning_rate": 1.1130120481927712e-05,
      "loss": 0.0122,
      "step": 36810
    },
    {
      "epoch": 4.436144578313253,
      "grad_norm": 0.3146699368953705,
      "learning_rate": 1.1127710843373496e-05,
      "loss": 0.0522,
      "step": 36820
    },
    {
      "epoch": 4.437349397590362,
      "grad_norm": 0.023531844839453697,
      "learning_rate": 1.1125301204819278e-05,
      "loss": 0.0101,
      "step": 36830
    },
    {
      "epoch": 4.43855421686747,
      "grad_norm": 0.15294410288333893,
      "learning_rate": 1.1122891566265061e-05,
      "loss": 0.0321,
      "step": 36840
    },
    {
      "epoch": 4.4397590361445785,
      "grad_norm": 0.00800430215895176,
      "learning_rate": 1.1120481927710844e-05,
      "loss": 0.0056,
      "step": 36850
    },
    {
      "epoch": 4.440963855421686,
      "grad_norm": 5.805118083953857,
      "learning_rate": 1.1118072289156627e-05,
      "loss": 0.0237,
      "step": 36860
    },
    {
      "epoch": 4.442168674698795,
      "grad_norm": 5.057771682739258,
      "learning_rate": 1.111566265060241e-05,
      "loss": 0.0706,
      "step": 36870
    },
    {
      "epoch": 4.443373493975904,
      "grad_norm": 0.04899163544178009,
      "learning_rate": 1.1113253012048192e-05,
      "loss": 0.0134,
      "step": 36880
    },
    {
      "epoch": 4.444578313253012,
      "grad_norm": 0.012501634657382965,
      "learning_rate": 1.1110843373493975e-05,
      "loss": 0.0174,
      "step": 36890
    },
    {
      "epoch": 4.445783132530121,
      "grad_norm": 2.1085169315338135,
      "learning_rate": 1.110843373493976e-05,
      "loss": 0.0164,
      "step": 36900
    },
    {
      "epoch": 4.446987951807229,
      "grad_norm": 0.0119209885597229,
      "learning_rate": 1.1106024096385543e-05,
      "loss": 0.0496,
      "step": 36910
    },
    {
      "epoch": 4.448192771084337,
      "grad_norm": 1.0481572151184082,
      "learning_rate": 1.1103614457831327e-05,
      "loss": 0.019,
      "step": 36920
    },
    {
      "epoch": 4.449397590361446,
      "grad_norm": 0.007226828020066023,
      "learning_rate": 1.110120481927711e-05,
      "loss": 0.0039,
      "step": 36930
    },
    {
      "epoch": 4.450602409638554,
      "grad_norm": 0.010846526362001896,
      "learning_rate": 1.1098795180722893e-05,
      "loss": 0.0063,
      "step": 36940
    },
    {
      "epoch": 4.451807228915663,
      "grad_norm": 0.24075976014137268,
      "learning_rate": 1.1096385542168674e-05,
      "loss": 0.0045,
      "step": 36950
    },
    {
      "epoch": 4.453012048192771,
      "grad_norm": 0.0056204600259661674,
      "learning_rate": 1.1093975903614458e-05,
      "loss": 0.0145,
      "step": 36960
    },
    {
      "epoch": 4.45421686746988,
      "grad_norm": 1.3985886573791504,
      "learning_rate": 1.1091566265060242e-05,
      "loss": 0.0386,
      "step": 36970
    },
    {
      "epoch": 4.455421686746988,
      "grad_norm": 0.00602023396641016,
      "learning_rate": 1.1089156626506026e-05,
      "loss": 0.0541,
      "step": 36980
    },
    {
      "epoch": 4.456626506024096,
      "grad_norm": 0.20422104001045227,
      "learning_rate": 1.1086746987951809e-05,
      "loss": 0.002,
      "step": 36990
    },
    {
      "epoch": 4.457831325301205,
      "grad_norm": 0.010366472415626049,
      "learning_rate": 1.1084337349397592e-05,
      "loss": 0.0023,
      "step": 37000
    },
    {
      "epoch": 4.459036144578313,
      "grad_norm": 4.623687744140625,
      "learning_rate": 1.1081927710843373e-05,
      "loss": 0.0294,
      "step": 37010
    },
    {
      "epoch": 4.460240963855422,
      "grad_norm": 5.886523246765137,
      "learning_rate": 1.1079518072289157e-05,
      "loss": 0.0198,
      "step": 37020
    },
    {
      "epoch": 4.46144578313253,
      "grad_norm": 0.01583639159798622,
      "learning_rate": 1.107710843373494e-05,
      "loss": 0.0306,
      "step": 37030
    },
    {
      "epoch": 4.462650602409639,
      "grad_norm": 0.013008472509682178,
      "learning_rate": 1.1074698795180723e-05,
      "loss": 0.0053,
      "step": 37040
    },
    {
      "epoch": 4.4638554216867465,
      "grad_norm": 0.0641930028796196,
      "learning_rate": 1.1072289156626508e-05,
      "loss": 0.0331,
      "step": 37050
    },
    {
      "epoch": 4.465060240963855,
      "grad_norm": 6.1134538650512695,
      "learning_rate": 1.1069879518072291e-05,
      "loss": 0.0248,
      "step": 37060
    },
    {
      "epoch": 4.466265060240964,
      "grad_norm": 0.5715696215629578,
      "learning_rate": 1.1067469879518074e-05,
      "loss": 0.002,
      "step": 37070
    },
    {
      "epoch": 4.467469879518072,
      "grad_norm": 2.190708637237549,
      "learning_rate": 1.1065060240963856e-05,
      "loss": 0.0469,
      "step": 37080
    },
    {
      "epoch": 4.468674698795181,
      "grad_norm": 0.03153441101312637,
      "learning_rate": 1.1062650602409639e-05,
      "loss": 0.0538,
      "step": 37090
    },
    {
      "epoch": 4.469879518072289,
      "grad_norm": 0.017215527594089508,
      "learning_rate": 1.1060240963855422e-05,
      "loss": 0.0172,
      "step": 37100
    },
    {
      "epoch": 4.471084337349398,
      "grad_norm": 0.36354678869247437,
      "learning_rate": 1.1057831325301205e-05,
      "loss": 0.0143,
      "step": 37110
    },
    {
      "epoch": 4.472289156626506,
      "grad_norm": 2.2346959114074707,
      "learning_rate": 1.105542168674699e-05,
      "loss": 0.0396,
      "step": 37120
    },
    {
      "epoch": 4.473493975903614,
      "grad_norm": 0.003139096312224865,
      "learning_rate": 1.1053012048192773e-05,
      "loss": 0.0289,
      "step": 37130
    },
    {
      "epoch": 4.474698795180723,
      "grad_norm": 0.06785712391138077,
      "learning_rate": 1.1050602409638556e-05,
      "loss": 0.0102,
      "step": 37140
    },
    {
      "epoch": 4.475903614457831,
      "grad_norm": 0.01255237590521574,
      "learning_rate": 1.1048192771084338e-05,
      "loss": 0.0613,
      "step": 37150
    },
    {
      "epoch": 4.47710843373494,
      "grad_norm": 0.4873722493648529,
      "learning_rate": 1.1045783132530121e-05,
      "loss": 0.0684,
      "step": 37160
    },
    {
      "epoch": 4.478313253012049,
      "grad_norm": 0.39876437187194824,
      "learning_rate": 1.1043373493975904e-05,
      "loss": 0.0421,
      "step": 37170
    },
    {
      "epoch": 4.4795180722891565,
      "grad_norm": 3.8632025718688965,
      "learning_rate": 1.1040963855421687e-05,
      "loss": 0.0459,
      "step": 37180
    },
    {
      "epoch": 4.480722891566265,
      "grad_norm": 0.314487099647522,
      "learning_rate": 1.103855421686747e-05,
      "loss": 0.01,
      "step": 37190
    },
    {
      "epoch": 4.481927710843373,
      "grad_norm": 0.03311033919453621,
      "learning_rate": 1.1036144578313255e-05,
      "loss": 0.0187,
      "step": 37200
    },
    {
      "epoch": 4.483132530120482,
      "grad_norm": 0.021567517891526222,
      "learning_rate": 1.1033734939759037e-05,
      "loss": 0.0297,
      "step": 37210
    },
    {
      "epoch": 4.48433734939759,
      "grad_norm": 0.58037269115448,
      "learning_rate": 1.103132530120482e-05,
      "loss": 0.0227,
      "step": 37220
    },
    {
      "epoch": 4.485542168674699,
      "grad_norm": 1.299870252609253,
      "learning_rate": 1.1028915662650603e-05,
      "loss": 0.0101,
      "step": 37230
    },
    {
      "epoch": 4.486746987951808,
      "grad_norm": 8.845189094543457,
      "learning_rate": 1.1026506024096386e-05,
      "loss": 0.0314,
      "step": 37240
    },
    {
      "epoch": 4.4879518072289155,
      "grad_norm": 0.009993484243750572,
      "learning_rate": 1.102409638554217e-05,
      "loss": 0.0219,
      "step": 37250
    },
    {
      "epoch": 4.489156626506024,
      "grad_norm": 0.003769091097638011,
      "learning_rate": 1.1021686746987951e-05,
      "loss": 0.0139,
      "step": 37260
    },
    {
      "epoch": 4.490361445783132,
      "grad_norm": 0.02349315956234932,
      "learning_rate": 1.1019277108433738e-05,
      "loss": 0.0203,
      "step": 37270
    },
    {
      "epoch": 4.491566265060241,
      "grad_norm": 0.4048924744129181,
      "learning_rate": 1.101686746987952e-05,
      "loss": 0.0023,
      "step": 37280
    },
    {
      "epoch": 4.492771084337349,
      "grad_norm": 2.477140426635742,
      "learning_rate": 1.1014457831325302e-05,
      "loss": 0.0486,
      "step": 37290
    },
    {
      "epoch": 4.493975903614458,
      "grad_norm": 0.6939176321029663,
      "learning_rate": 1.1012048192771086e-05,
      "loss": 0.0875,
      "step": 37300
    },
    {
      "epoch": 4.495180722891567,
      "grad_norm": 1.5902987718582153,
      "learning_rate": 1.1009638554216869e-05,
      "loss": 0.0899,
      "step": 37310
    },
    {
      "epoch": 4.4963855421686745,
      "grad_norm": 33.6234130859375,
      "learning_rate": 1.1007228915662652e-05,
      "loss": 0.017,
      "step": 37320
    },
    {
      "epoch": 4.497590361445783,
      "grad_norm": 9.28283977508545,
      "learning_rate": 1.1004819277108433e-05,
      "loss": 0.0281,
      "step": 37330
    },
    {
      "epoch": 4.498795180722891,
      "grad_norm": 0.33805352449417114,
      "learning_rate": 1.1002409638554217e-05,
      "loss": 0.026,
      "step": 37340
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.14487291872501373,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0593,
      "step": 37350
    },
    {
      "epoch": 4.501204819277109,
      "grad_norm": 0.023637883365154266,
      "learning_rate": 1.0997590361445785e-05,
      "loss": 0.031,
      "step": 37360
    },
    {
      "epoch": 4.502409638554217,
      "grad_norm": 0.011029145680367947,
      "learning_rate": 1.0995180722891568e-05,
      "loss": 0.0039,
      "step": 37370
    },
    {
      "epoch": 4.5036144578313255,
      "grad_norm": 0.07484342902898788,
      "learning_rate": 1.0992771084337351e-05,
      "loss": 0.0109,
      "step": 37380
    },
    {
      "epoch": 4.504819277108433,
      "grad_norm": 0.2174537628889084,
      "learning_rate": 1.0990361445783132e-05,
      "loss": 0.012,
      "step": 37390
    },
    {
      "epoch": 4.506024096385542,
      "grad_norm": 0.00932083185762167,
      "learning_rate": 1.0987951807228916e-05,
      "loss": 0.0057,
      "step": 37400
    },
    {
      "epoch": 4.507228915662651,
      "grad_norm": 1.66892671585083,
      "learning_rate": 1.0985542168674699e-05,
      "loss": 0.0238,
      "step": 37410
    },
    {
      "epoch": 4.508433734939759,
      "grad_norm": 21.070178985595703,
      "learning_rate": 1.0983132530120484e-05,
      "loss": 0.0362,
      "step": 37420
    },
    {
      "epoch": 4.509638554216868,
      "grad_norm": 4.84238338470459,
      "learning_rate": 1.0980722891566267e-05,
      "loss": 0.0299,
      "step": 37430
    },
    {
      "epoch": 4.510843373493976,
      "grad_norm": 0.009621556848287582,
      "learning_rate": 1.097831325301205e-05,
      "loss": 0.0235,
      "step": 37440
    },
    {
      "epoch": 4.5120481927710845,
      "grad_norm": 0.07154013961553574,
      "learning_rate": 1.0975903614457833e-05,
      "loss": 0.0299,
      "step": 37450
    },
    {
      "epoch": 4.513253012048192,
      "grad_norm": 0.01390077918767929,
      "learning_rate": 1.0973493975903615e-05,
      "loss": 0.0348,
      "step": 37460
    },
    {
      "epoch": 4.514457831325301,
      "grad_norm": 0.006701840553432703,
      "learning_rate": 1.0971084337349398e-05,
      "loss": 0.0503,
      "step": 37470
    },
    {
      "epoch": 4.51566265060241,
      "grad_norm": 0.004648405592888594,
      "learning_rate": 1.0968674698795181e-05,
      "loss": 0.0126,
      "step": 37480
    },
    {
      "epoch": 4.516867469879518,
      "grad_norm": 0.007386799436062574,
      "learning_rate": 1.0966265060240964e-05,
      "loss": 0.1277,
      "step": 37490
    },
    {
      "epoch": 4.518072289156627,
      "grad_norm": 0.046023495495319366,
      "learning_rate": 1.0963855421686749e-05,
      "loss": 0.0018,
      "step": 37500
    },
    {
      "epoch": 4.519277108433735,
      "grad_norm": 0.057593852281570435,
      "learning_rate": 1.0961445783132532e-05,
      "loss": 0.0469,
      "step": 37510
    },
    {
      "epoch": 4.5204819277108435,
      "grad_norm": 0.011668343096971512,
      "learning_rate": 1.0959036144578314e-05,
      "loss": 0.0379,
      "step": 37520
    },
    {
      "epoch": 4.521686746987951,
      "grad_norm": 0.0422324575483799,
      "learning_rate": 1.0956626506024097e-05,
      "loss": 0.0536,
      "step": 37530
    },
    {
      "epoch": 4.52289156626506,
      "grad_norm": 0.8118305206298828,
      "learning_rate": 1.095421686746988e-05,
      "loss": 0.0041,
      "step": 37540
    },
    {
      "epoch": 4.524096385542169,
      "grad_norm": 0.12249478697776794,
      "learning_rate": 1.0951807228915663e-05,
      "loss": 0.0027,
      "step": 37550
    },
    {
      "epoch": 4.525301204819277,
      "grad_norm": 0.00822481606155634,
      "learning_rate": 1.0949397590361446e-05,
      "loss": 0.0329,
      "step": 37560
    },
    {
      "epoch": 4.526506024096386,
      "grad_norm": 2.413541078567505,
      "learning_rate": 1.0946987951807231e-05,
      "loss": 0.0106,
      "step": 37570
    },
    {
      "epoch": 4.527710843373494,
      "grad_norm": 0.004318641033023596,
      "learning_rate": 1.0944578313253014e-05,
      "loss": 0.057,
      "step": 37580
    },
    {
      "epoch": 4.528915662650602,
      "grad_norm": 0.030736766755580902,
      "learning_rate": 1.0942168674698796e-05,
      "loss": 0.0034,
      "step": 37590
    },
    {
      "epoch": 4.530120481927711,
      "grad_norm": 1.8963345289230347,
      "learning_rate": 1.0939759036144579e-05,
      "loss": 0.0219,
      "step": 37600
    },
    {
      "epoch": 4.531325301204819,
      "grad_norm": 0.00590802077203989,
      "learning_rate": 1.0937349397590362e-05,
      "loss": 0.033,
      "step": 37610
    },
    {
      "epoch": 4.532530120481928,
      "grad_norm": 0.08090801537036896,
      "learning_rate": 1.0934939759036145e-05,
      "loss": 0.0721,
      "step": 37620
    },
    {
      "epoch": 4.533734939759036,
      "grad_norm": 0.02938198484480381,
      "learning_rate": 1.0932530120481929e-05,
      "loss": 0.0267,
      "step": 37630
    },
    {
      "epoch": 4.534939759036145,
      "grad_norm": 0.7970860600471497,
      "learning_rate": 1.093012048192771e-05,
      "loss": 0.0199,
      "step": 37640
    },
    {
      "epoch": 4.5361445783132535,
      "grad_norm": 8.593974113464355,
      "learning_rate": 1.0927710843373495e-05,
      "loss": 0.0869,
      "step": 37650
    },
    {
      "epoch": 4.537349397590361,
      "grad_norm": 0.37954428791999817,
      "learning_rate": 1.0925301204819278e-05,
      "loss": 0.0153,
      "step": 37660
    },
    {
      "epoch": 4.53855421686747,
      "grad_norm": 0.010944853536784649,
      "learning_rate": 1.0922891566265061e-05,
      "loss": 0.0584,
      "step": 37670
    },
    {
      "epoch": 4.539759036144578,
      "grad_norm": 1.7110302448272705,
      "learning_rate": 1.0920481927710845e-05,
      "loss": 0.0459,
      "step": 37680
    },
    {
      "epoch": 4.540963855421687,
      "grad_norm": 0.05373236909508705,
      "learning_rate": 1.0918072289156628e-05,
      "loss": 0.0107,
      "step": 37690
    },
    {
      "epoch": 4.542168674698795,
      "grad_norm": 0.06466727703809738,
      "learning_rate": 1.091566265060241e-05,
      "loss": 0.0653,
      "step": 37700
    },
    {
      "epoch": 4.543373493975904,
      "grad_norm": 0.3580174744129181,
      "learning_rate": 1.0913253012048192e-05,
      "loss": 0.0107,
      "step": 37710
    },
    {
      "epoch": 4.544578313253012,
      "grad_norm": 0.02461896650493145,
      "learning_rate": 1.0910843373493977e-05,
      "loss": 0.007,
      "step": 37720
    },
    {
      "epoch": 4.54578313253012,
      "grad_norm": 0.3285483419895172,
      "learning_rate": 1.090843373493976e-05,
      "loss": 0.0552,
      "step": 37730
    },
    {
      "epoch": 4.546987951807229,
      "grad_norm": 0.017365412786602974,
      "learning_rate": 1.0906024096385544e-05,
      "loss": 0.0875,
      "step": 37740
    },
    {
      "epoch": 4.548192771084337,
      "grad_norm": 0.18448735773563385,
      "learning_rate": 1.0903614457831327e-05,
      "loss": 0.0179,
      "step": 37750
    },
    {
      "epoch": 4.549397590361446,
      "grad_norm": 0.024773724377155304,
      "learning_rate": 1.090120481927711e-05,
      "loss": 0.0633,
      "step": 37760
    },
    {
      "epoch": 4.550602409638554,
      "grad_norm": 0.018949104472994804,
      "learning_rate": 1.0898795180722891e-05,
      "loss": 0.0284,
      "step": 37770
    },
    {
      "epoch": 4.551807228915663,
      "grad_norm": 0.07173279672861099,
      "learning_rate": 1.0896385542168675e-05,
      "loss": 0.0248,
      "step": 37780
    },
    {
      "epoch": 4.553012048192771,
      "grad_norm": 0.006052831187844276,
      "learning_rate": 1.0893975903614458e-05,
      "loss": 0.0051,
      "step": 37790
    },
    {
      "epoch": 4.554216867469879,
      "grad_norm": 13.815045356750488,
      "learning_rate": 1.0891566265060243e-05,
      "loss": 0.0347,
      "step": 37800
    },
    {
      "epoch": 4.555421686746988,
      "grad_norm": 0.015833918005228043,
      "learning_rate": 1.0889156626506026e-05,
      "loss": 0.0336,
      "step": 37810
    },
    {
      "epoch": 4.556626506024096,
      "grad_norm": 0.24665263295173645,
      "learning_rate": 1.0886746987951809e-05,
      "loss": 0.0319,
      "step": 37820
    },
    {
      "epoch": 4.557831325301205,
      "grad_norm": 0.03281083703041077,
      "learning_rate": 1.088433734939759e-05,
      "loss": 0.0448,
      "step": 37830
    },
    {
      "epoch": 4.559036144578314,
      "grad_norm": 0.011010208167135715,
      "learning_rate": 1.0881927710843374e-05,
      "loss": 0.0319,
      "step": 37840
    },
    {
      "epoch": 4.5602409638554215,
      "grad_norm": 1.5205377340316772,
      "learning_rate": 1.0879518072289157e-05,
      "loss": 0.0128,
      "step": 37850
    },
    {
      "epoch": 4.56144578313253,
      "grad_norm": 0.00466463528573513,
      "learning_rate": 1.087710843373494e-05,
      "loss": 0.0083,
      "step": 37860
    },
    {
      "epoch": 4.562650602409638,
      "grad_norm": 0.004776999820023775,
      "learning_rate": 1.0874698795180725e-05,
      "loss": 0.0154,
      "step": 37870
    },
    {
      "epoch": 4.563855421686747,
      "grad_norm": 0.002476811408996582,
      "learning_rate": 1.0872289156626508e-05,
      "loss": 0.0263,
      "step": 37880
    },
    {
      "epoch": 4.565060240963856,
      "grad_norm": 31.027915954589844,
      "learning_rate": 1.0869879518072291e-05,
      "loss": 0.0125,
      "step": 37890
    },
    {
      "epoch": 4.566265060240964,
      "grad_norm": 1.7557594776153564,
      "learning_rate": 1.0867469879518073e-05,
      "loss": 0.0347,
      "step": 37900
    },
    {
      "epoch": 4.567469879518073,
      "grad_norm": 3.111603260040283,
      "learning_rate": 1.0865060240963856e-05,
      "loss": 0.0524,
      "step": 37910
    },
    {
      "epoch": 4.5686746987951805,
      "grad_norm": 2.8450818061828613,
      "learning_rate": 1.0862650602409639e-05,
      "loss": 0.012,
      "step": 37920
    },
    {
      "epoch": 4.569879518072289,
      "grad_norm": 1.9930949211120605,
      "learning_rate": 1.0860240963855422e-05,
      "loss": 0.0278,
      "step": 37930
    },
    {
      "epoch": 4.571084337349397,
      "grad_norm": 2.7519500255584717,
      "learning_rate": 1.0857831325301205e-05,
      "loss": 0.0373,
      "step": 37940
    },
    {
      "epoch": 4.572289156626506,
      "grad_norm": 0.23569168150424957,
      "learning_rate": 1.085542168674699e-05,
      "loss": 0.0077,
      "step": 37950
    },
    {
      "epoch": 4.573493975903615,
      "grad_norm": 0.2750984728336334,
      "learning_rate": 1.0853012048192772e-05,
      "loss": 0.0378,
      "step": 37960
    },
    {
      "epoch": 4.574698795180723,
      "grad_norm": 0.19582568109035492,
      "learning_rate": 1.0850602409638555e-05,
      "loss": 0.0007,
      "step": 37970
    },
    {
      "epoch": 4.575903614457832,
      "grad_norm": 2.8548951148986816,
      "learning_rate": 1.0848192771084338e-05,
      "loss": 0.0482,
      "step": 37980
    },
    {
      "epoch": 4.5771084337349395,
      "grad_norm": 0.185899555683136,
      "learning_rate": 1.0845783132530121e-05,
      "loss": 0.02,
      "step": 37990
    },
    {
      "epoch": 4.578313253012048,
      "grad_norm": 0.11087965220212936,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 0.0137,
      "step": 38000
    },
    {
      "epoch": 4.579518072289156,
      "grad_norm": 0.3602718710899353,
      "learning_rate": 1.0840963855421686e-05,
      "loss": 0.0415,
      "step": 38010
    },
    {
      "epoch": 4.580722891566265,
      "grad_norm": 0.002856726758182049,
      "learning_rate": 1.0838554216867473e-05,
      "loss": 0.0133,
      "step": 38020
    },
    {
      "epoch": 4.581927710843374,
      "grad_norm": 0.007114206440746784,
      "learning_rate": 1.0836144578313254e-05,
      "loss": 0.039,
      "step": 38030
    },
    {
      "epoch": 4.583132530120482,
      "grad_norm": 0.002857375890016556,
      "learning_rate": 1.0833734939759037e-05,
      "loss": 0.0267,
      "step": 38040
    },
    {
      "epoch": 4.5843373493975905,
      "grad_norm": 0.0049356333911418915,
      "learning_rate": 1.083132530120482e-05,
      "loss": 0.0283,
      "step": 38050
    },
    {
      "epoch": 4.585542168674698,
      "grad_norm": 0.010216092690825462,
      "learning_rate": 1.0828915662650604e-05,
      "loss": 0.0097,
      "step": 38060
    },
    {
      "epoch": 4.586746987951807,
      "grad_norm": 0.0011758679756894708,
      "learning_rate": 1.0826506024096387e-05,
      "loss": 0.0214,
      "step": 38070
    },
    {
      "epoch": 4.587951807228916,
      "grad_norm": 1.258800983428955,
      "learning_rate": 1.0824096385542168e-05,
      "loss": 0.0191,
      "step": 38080
    },
    {
      "epoch": 4.589156626506024,
      "grad_norm": 1.235416054725647,
      "learning_rate": 1.0821686746987951e-05,
      "loss": 0.0287,
      "step": 38090
    },
    {
      "epoch": 4.590361445783133,
      "grad_norm": 0.04914627969264984,
      "learning_rate": 1.0819277108433736e-05,
      "loss": 0.0374,
      "step": 38100
    },
    {
      "epoch": 4.591566265060241,
      "grad_norm": 25.37084197998047,
      "learning_rate": 1.081686746987952e-05,
      "loss": 0.0256,
      "step": 38110
    },
    {
      "epoch": 4.5927710843373495,
      "grad_norm": 0.9640341401100159,
      "learning_rate": 1.0814457831325303e-05,
      "loss": 0.0381,
      "step": 38120
    },
    {
      "epoch": 4.593975903614458,
      "grad_norm": 0.6313314437866211,
      "learning_rate": 1.0812048192771086e-05,
      "loss": 0.0647,
      "step": 38130
    },
    {
      "epoch": 4.595180722891566,
      "grad_norm": 0.04766862839460373,
      "learning_rate": 1.0809638554216867e-05,
      "loss": 0.0122,
      "step": 38140
    },
    {
      "epoch": 4.596385542168675,
      "grad_norm": 0.014380737207829952,
      "learning_rate": 1.080722891566265e-05,
      "loss": 0.0226,
      "step": 38150
    },
    {
      "epoch": 4.597590361445783,
      "grad_norm": 0.5887208580970764,
      "learning_rate": 1.0804819277108434e-05,
      "loss": 0.0356,
      "step": 38160
    },
    {
      "epoch": 4.598795180722892,
      "grad_norm": 1.1113415956497192,
      "learning_rate": 1.0802409638554218e-05,
      "loss": 0.02,
      "step": 38170
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0058295754715800285,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0099,
      "step": 38180
    },
    {
      "epoch": 4.6012048192771084,
      "grad_norm": 0.04915307089686394,
      "learning_rate": 1.0797590361445785e-05,
      "loss": 0.0491,
      "step": 38190
    },
    {
      "epoch": 4.602409638554217,
      "grad_norm": 0.9207103252410889,
      "learning_rate": 1.0795180722891568e-05,
      "loss": 0.0529,
      "step": 38200
    },
    {
      "epoch": 4.603614457831325,
      "grad_norm": 0.04611017182469368,
      "learning_rate": 1.079277108433735e-05,
      "loss": 0.0322,
      "step": 38210
    },
    {
      "epoch": 4.604819277108434,
      "grad_norm": 0.015662388876080513,
      "learning_rate": 1.0790361445783133e-05,
      "loss": 0.0463,
      "step": 38220
    },
    {
      "epoch": 4.606024096385542,
      "grad_norm": 2.7677364349365234,
      "learning_rate": 1.0787951807228916e-05,
      "loss": 0.0587,
      "step": 38230
    },
    {
      "epoch": 4.607228915662651,
      "grad_norm": 12.434234619140625,
      "learning_rate": 1.0785542168674699e-05,
      "loss": 0.0319,
      "step": 38240
    },
    {
      "epoch": 4.608433734939759,
      "grad_norm": 0.008162825368344784,
      "learning_rate": 1.0783132530120484e-05,
      "loss": 0.0017,
      "step": 38250
    },
    {
      "epoch": 4.609638554216867,
      "grad_norm": 0.007314061746001244,
      "learning_rate": 1.0780722891566267e-05,
      "loss": 0.0197,
      "step": 38260
    },
    {
      "epoch": 4.610843373493976,
      "grad_norm": 0.009855920448899269,
      "learning_rate": 1.0778313253012049e-05,
      "loss": 0.0015,
      "step": 38270
    },
    {
      "epoch": 4.612048192771084,
      "grad_norm": 1.1080676317214966,
      "learning_rate": 1.0775903614457832e-05,
      "loss": 0.032,
      "step": 38280
    },
    {
      "epoch": 4.613253012048193,
      "grad_norm": 0.02170141600072384,
      "learning_rate": 1.0773493975903615e-05,
      "loss": 0.031,
      "step": 38290
    },
    {
      "epoch": 4.614457831325301,
      "grad_norm": 0.04016207158565521,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 0.0112,
      "step": 38300
    },
    {
      "epoch": 4.61566265060241,
      "grad_norm": 0.008715598843991756,
      "learning_rate": 1.0768674698795181e-05,
      "loss": 0.0602,
      "step": 38310
    },
    {
      "epoch": 4.6168674698795185,
      "grad_norm": 0.7564424276351929,
      "learning_rate": 1.0766265060240966e-05,
      "loss": 0.018,
      "step": 38320
    },
    {
      "epoch": 4.618072289156626,
      "grad_norm": 0.0037600581999868155,
      "learning_rate": 1.076385542168675e-05,
      "loss": 0.0277,
      "step": 38330
    },
    {
      "epoch": 4.619277108433735,
      "grad_norm": 0.004722197074443102,
      "learning_rate": 1.076144578313253e-05,
      "loss": 0.0099,
      "step": 38340
    },
    {
      "epoch": 4.620481927710843,
      "grad_norm": 0.012693315744400024,
      "learning_rate": 1.0759036144578314e-05,
      "loss": 0.01,
      "step": 38350
    },
    {
      "epoch": 4.621686746987952,
      "grad_norm": 0.3038916289806366,
      "learning_rate": 1.0756626506024097e-05,
      "loss": 0.0257,
      "step": 38360
    },
    {
      "epoch": 4.622891566265061,
      "grad_norm": 0.00991953443735838,
      "learning_rate": 1.075421686746988e-05,
      "loss": 0.0095,
      "step": 38370
    },
    {
      "epoch": 4.624096385542169,
      "grad_norm": 0.08807215094566345,
      "learning_rate": 1.0751807228915663e-05,
      "loss": 0.0523,
      "step": 38380
    },
    {
      "epoch": 4.625301204819277,
      "grad_norm": 0.759752631187439,
      "learning_rate": 1.0749397590361445e-05,
      "loss": 0.0448,
      "step": 38390
    },
    {
      "epoch": 4.626506024096385,
      "grad_norm": 1.5366289615631104,
      "learning_rate": 1.074698795180723e-05,
      "loss": 0.0244,
      "step": 38400
    },
    {
      "epoch": 4.627710843373494,
      "grad_norm": 0.3211662769317627,
      "learning_rate": 1.0744578313253013e-05,
      "loss": 0.0319,
      "step": 38410
    },
    {
      "epoch": 4.628915662650602,
      "grad_norm": 1.1102087497711182,
      "learning_rate": 1.0742168674698796e-05,
      "loss": 0.039,
      "step": 38420
    },
    {
      "epoch": 4.630120481927711,
      "grad_norm": 0.013410097919404507,
      "learning_rate": 1.073975903614458e-05,
      "loss": 0.0408,
      "step": 38430
    },
    {
      "epoch": 4.63132530120482,
      "grad_norm": 0.005107598844915628,
      "learning_rate": 1.0737349397590363e-05,
      "loss": 0.0027,
      "step": 38440
    },
    {
      "epoch": 4.632530120481928,
      "grad_norm": 1.540022611618042,
      "learning_rate": 1.0734939759036144e-05,
      "loss": 0.0171,
      "step": 38450
    },
    {
      "epoch": 4.633734939759036,
      "grad_norm": 1.6475976705551147,
      "learning_rate": 1.0732530120481927e-05,
      "loss": 0.0437,
      "step": 38460
    },
    {
      "epoch": 4.634939759036144,
      "grad_norm": 0.20011405646800995,
      "learning_rate": 1.0730120481927712e-05,
      "loss": 0.0078,
      "step": 38470
    },
    {
      "epoch": 4.636144578313253,
      "grad_norm": 0.0034880414605140686,
      "learning_rate": 1.0727710843373495e-05,
      "loss": 0.02,
      "step": 38480
    },
    {
      "epoch": 4.637349397590361,
      "grad_norm": 0.5025178790092468,
      "learning_rate": 1.0725301204819278e-05,
      "loss": 0.0463,
      "step": 38490
    },
    {
      "epoch": 4.63855421686747,
      "grad_norm": 0.0758930891752243,
      "learning_rate": 1.0722891566265062e-05,
      "loss": 0.0449,
      "step": 38500
    },
    {
      "epoch": 4.639759036144579,
      "grad_norm": 0.004061417188495398,
      "learning_rate": 1.0720481927710845e-05,
      "loss": 0.0188,
      "step": 38510
    },
    {
      "epoch": 4.6409638554216865,
      "grad_norm": 0.19444386661052704,
      "learning_rate": 1.0718072289156626e-05,
      "loss": 0.0238,
      "step": 38520
    },
    {
      "epoch": 4.642168674698795,
      "grad_norm": 0.007528858259320259,
      "learning_rate": 1.071566265060241e-05,
      "loss": 0.0745,
      "step": 38530
    },
    {
      "epoch": 4.643373493975903,
      "grad_norm": 0.03934066742658615,
      "learning_rate": 1.0713253012048193e-05,
      "loss": 0.0463,
      "step": 38540
    },
    {
      "epoch": 4.644578313253012,
      "grad_norm": 0.036892205476760864,
      "learning_rate": 1.0710843373493977e-05,
      "loss": 0.0346,
      "step": 38550
    },
    {
      "epoch": 4.64578313253012,
      "grad_norm": 0.01567123457789421,
      "learning_rate": 1.070843373493976e-05,
      "loss": 0.0296,
      "step": 38560
    },
    {
      "epoch": 4.646987951807229,
      "grad_norm": 17.306699752807617,
      "learning_rate": 1.0706024096385544e-05,
      "loss": 0.0293,
      "step": 38570
    },
    {
      "epoch": 4.648192771084338,
      "grad_norm": 1.0021523237228394,
      "learning_rate": 1.0703614457831327e-05,
      "loss": 0.0132,
      "step": 38580
    },
    {
      "epoch": 4.6493975903614455,
      "grad_norm": 0.05281556397676468,
      "learning_rate": 1.0701204819277108e-05,
      "loss": 0.001,
      "step": 38590
    },
    {
      "epoch": 4.650602409638554,
      "grad_norm": 0.5707489252090454,
      "learning_rate": 1.0698795180722892e-05,
      "loss": 0.0089,
      "step": 38600
    },
    {
      "epoch": 4.651807228915663,
      "grad_norm": 0.008809865452349186,
      "learning_rate": 1.0696385542168675e-05,
      "loss": 0.0953,
      "step": 38610
    },
    {
      "epoch": 4.653012048192771,
      "grad_norm": 0.006039570085704327,
      "learning_rate": 1.069397590361446e-05,
      "loss": 0.0386,
      "step": 38620
    },
    {
      "epoch": 4.65421686746988,
      "grad_norm": 0.1007237434387207,
      "learning_rate": 1.0691566265060243e-05,
      "loss": 0.0366,
      "step": 38630
    },
    {
      "epoch": 4.655421686746988,
      "grad_norm": 0.27837637066841125,
      "learning_rate": 1.0689156626506026e-05,
      "loss": 0.0122,
      "step": 38640
    },
    {
      "epoch": 4.656626506024097,
      "grad_norm": 0.015952687710523605,
      "learning_rate": 1.0686746987951808e-05,
      "loss": 0.0448,
      "step": 38650
    },
    {
      "epoch": 4.6578313253012045,
      "grad_norm": 0.24749605357646942,
      "learning_rate": 1.068433734939759e-05,
      "loss": 0.0232,
      "step": 38660
    },
    {
      "epoch": 4.659036144578313,
      "grad_norm": 0.8749377131462097,
      "learning_rate": 1.0681927710843374e-05,
      "loss": 0.0319,
      "step": 38670
    },
    {
      "epoch": 4.660240963855422,
      "grad_norm": 0.009522073902189732,
      "learning_rate": 1.0679518072289157e-05,
      "loss": 0.0461,
      "step": 38680
    },
    {
      "epoch": 4.66144578313253,
      "grad_norm": 6.60129976272583,
      "learning_rate": 1.067710843373494e-05,
      "loss": 0.045,
      "step": 38690
    },
    {
      "epoch": 4.662650602409639,
      "grad_norm": 0.006437140982598066,
      "learning_rate": 1.0674698795180725e-05,
      "loss": 0.0305,
      "step": 38700
    },
    {
      "epoch": 4.663855421686747,
      "grad_norm": 0.8691921234130859,
      "learning_rate": 1.0672289156626508e-05,
      "loss": 0.0177,
      "step": 38710
    },
    {
      "epoch": 4.6650602409638555,
      "grad_norm": 0.008462505415081978,
      "learning_rate": 1.066987951807229e-05,
      "loss": 0.0017,
      "step": 38720
    },
    {
      "epoch": 4.666265060240963,
      "grad_norm": 7.020794868469238,
      "learning_rate": 1.0667469879518073e-05,
      "loss": 0.0533,
      "step": 38730
    },
    {
      "epoch": 4.667469879518072,
      "grad_norm": 0.004961032886058092,
      "learning_rate": 1.0665060240963856e-05,
      "loss": 0.025,
      "step": 38740
    },
    {
      "epoch": 4.668674698795181,
      "grad_norm": 0.035956669598817825,
      "learning_rate": 1.066265060240964e-05,
      "loss": 0.0089,
      "step": 38750
    },
    {
      "epoch": 4.669879518072289,
      "grad_norm": 0.011649825610220432,
      "learning_rate": 1.0660240963855422e-05,
      "loss": 0.0297,
      "step": 38760
    },
    {
      "epoch": 4.671084337349398,
      "grad_norm": 5.672236442565918,
      "learning_rate": 1.0657831325301207e-05,
      "loss": 0.0195,
      "step": 38770
    },
    {
      "epoch": 4.672289156626506,
      "grad_norm": 0.01941218413412571,
      "learning_rate": 1.0655421686746989e-05,
      "loss": 0.0927,
      "step": 38780
    },
    {
      "epoch": 4.6734939759036145,
      "grad_norm": 0.19051901996135712,
      "learning_rate": 1.0653012048192772e-05,
      "loss": 0.0167,
      "step": 38790
    },
    {
      "epoch": 4.674698795180722,
      "grad_norm": 0.41551434993743896,
      "learning_rate": 1.0650602409638555e-05,
      "loss": 0.0244,
      "step": 38800
    },
    {
      "epoch": 4.675903614457831,
      "grad_norm": 0.0057060252875089645,
      "learning_rate": 1.0648192771084338e-05,
      "loss": 0.0013,
      "step": 38810
    },
    {
      "epoch": 4.67710843373494,
      "grad_norm": 0.028323879465460777,
      "learning_rate": 1.0645783132530122e-05,
      "loss": 0.0521,
      "step": 38820
    },
    {
      "epoch": 4.678313253012048,
      "grad_norm": 0.6232549548149109,
      "learning_rate": 1.0643373493975903e-05,
      "loss": 0.006,
      "step": 38830
    },
    {
      "epoch": 4.679518072289157,
      "grad_norm": 0.17074009776115417,
      "learning_rate": 1.0640963855421686e-05,
      "loss": 0.0764,
      "step": 38840
    },
    {
      "epoch": 4.6807228915662655,
      "grad_norm": 5.612117290496826,
      "learning_rate": 1.0638554216867471e-05,
      "loss": 0.0346,
      "step": 38850
    },
    {
      "epoch": 4.6819277108433734,
      "grad_norm": 0.01081501878798008,
      "learning_rate": 1.0636144578313254e-05,
      "loss": 0.0192,
      "step": 38860
    },
    {
      "epoch": 4.683132530120482,
      "grad_norm": 1.1019558906555176,
      "learning_rate": 1.0633734939759037e-05,
      "loss": 0.005,
      "step": 38870
    },
    {
      "epoch": 4.68433734939759,
      "grad_norm": 0.05330021306872368,
      "learning_rate": 1.063132530120482e-05,
      "loss": 0.0566,
      "step": 38880
    },
    {
      "epoch": 4.685542168674699,
      "grad_norm": 0.37635016441345215,
      "learning_rate": 1.0628915662650604e-05,
      "loss": 0.0503,
      "step": 38890
    },
    {
      "epoch": 4.686746987951807,
      "grad_norm": 0.3615835905075073,
      "learning_rate": 1.0626506024096385e-05,
      "loss": 0.0094,
      "step": 38900
    },
    {
      "epoch": 4.687951807228916,
      "grad_norm": 0.02027929201722145,
      "learning_rate": 1.0624096385542168e-05,
      "loss": 0.0109,
      "step": 38910
    },
    {
      "epoch": 4.6891566265060245,
      "grad_norm": 5.025580406188965,
      "learning_rate": 1.0621686746987953e-05,
      "loss": 0.0453,
      "step": 38920
    },
    {
      "epoch": 4.690361445783132,
      "grad_norm": 2.373100757598877,
      "learning_rate": 1.0619277108433736e-05,
      "loss": 0.0656,
      "step": 38930
    },
    {
      "epoch": 4.691566265060241,
      "grad_norm": 0.010570770129561424,
      "learning_rate": 1.061686746987952e-05,
      "loss": 0.0027,
      "step": 38940
    },
    {
      "epoch": 4.692771084337349,
      "grad_norm": 13.919846534729004,
      "learning_rate": 1.0614457831325303e-05,
      "loss": 0.0137,
      "step": 38950
    },
    {
      "epoch": 4.693975903614458,
      "grad_norm": 0.12217067927122116,
      "learning_rate": 1.0612048192771084e-05,
      "loss": 0.0303,
      "step": 38960
    },
    {
      "epoch": 4.695180722891566,
      "grad_norm": 1.6102491617202759,
      "learning_rate": 1.0609638554216867e-05,
      "loss": 0.0233,
      "step": 38970
    },
    {
      "epoch": 4.696385542168675,
      "grad_norm": 0.30600082874298096,
      "learning_rate": 1.060722891566265e-05,
      "loss": 0.0096,
      "step": 38980
    },
    {
      "epoch": 4.6975903614457835,
      "grad_norm": 0.007284763269126415,
      "learning_rate": 1.0604819277108434e-05,
      "loss": 0.0128,
      "step": 38990
    },
    {
      "epoch": 4.698795180722891,
      "grad_norm": 1.4383172988891602,
      "learning_rate": 1.0602409638554219e-05,
      "loss": 0.0123,
      "step": 39000
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.013437931425869465,
      "learning_rate": 1.0600000000000002e-05,
      "loss": 0.026,
      "step": 39010
    },
    {
      "epoch": 4.701204819277108,
      "grad_norm": 0.10872320830821991,
      "learning_rate": 1.0597590361445785e-05,
      "loss": 0.0734,
      "step": 39020
    },
    {
      "epoch": 4.702409638554217,
      "grad_norm": 0.028771985322237015,
      "learning_rate": 1.0595180722891567e-05,
      "loss": 0.0084,
      "step": 39030
    },
    {
      "epoch": 4.703614457831325,
      "grad_norm": 0.22685647010803223,
      "learning_rate": 1.059277108433735e-05,
      "loss": 0.0327,
      "step": 39040
    },
    {
      "epoch": 4.704819277108434,
      "grad_norm": 0.0105684669688344,
      "learning_rate": 1.0590361445783133e-05,
      "loss": 0.0366,
      "step": 39050
    },
    {
      "epoch": 4.706024096385542,
      "grad_norm": 0.02630874142050743,
      "learning_rate": 1.0587951807228916e-05,
      "loss": 0.0492,
      "step": 39060
    },
    {
      "epoch": 4.70722891566265,
      "grad_norm": 0.040278319269418716,
      "learning_rate": 1.0585542168674701e-05,
      "loss": 0.0084,
      "step": 39070
    },
    {
      "epoch": 4.708433734939759,
      "grad_norm": 0.007225210778415203,
      "learning_rate": 1.0583132530120484e-05,
      "loss": 0.0039,
      "step": 39080
    },
    {
      "epoch": 4.709638554216868,
      "grad_norm": 0.0198199525475502,
      "learning_rate": 1.0580722891566266e-05,
      "loss": 0.0493,
      "step": 39090
    },
    {
      "epoch": 4.710843373493976,
      "grad_norm": 1.6820833683013916,
      "learning_rate": 1.0578313253012049e-05,
      "loss": 0.0367,
      "step": 39100
    },
    {
      "epoch": 4.712048192771085,
      "grad_norm": 0.28196799755096436,
      "learning_rate": 1.0575903614457832e-05,
      "loss": 0.0125,
      "step": 39110
    },
    {
      "epoch": 4.713253012048193,
      "grad_norm": 2.1998636722564697,
      "learning_rate": 1.0573493975903615e-05,
      "loss": 0.0244,
      "step": 39120
    },
    {
      "epoch": 4.714457831325301,
      "grad_norm": 1.3421118259429932,
      "learning_rate": 1.0571084337349398e-05,
      "loss": 0.0111,
      "step": 39130
    },
    {
      "epoch": 4.715662650602409,
      "grad_norm": 0.154271200299263,
      "learning_rate": 1.056867469879518e-05,
      "loss": 0.0757,
      "step": 39140
    },
    {
      "epoch": 4.716867469879518,
      "grad_norm": 0.004430125467479229,
      "learning_rate": 1.0566265060240966e-05,
      "loss": 0.0011,
      "step": 39150
    },
    {
      "epoch": 4.718072289156627,
      "grad_norm": 0.03611955791711807,
      "learning_rate": 1.0563855421686748e-05,
      "loss": 0.0135,
      "step": 39160
    },
    {
      "epoch": 4.719277108433735,
      "grad_norm": 22.09834861755371,
      "learning_rate": 1.0561445783132531e-05,
      "loss": 0.0301,
      "step": 39170
    },
    {
      "epoch": 4.720481927710844,
      "grad_norm": 3.099620819091797,
      "learning_rate": 1.0559036144578314e-05,
      "loss": 0.017,
      "step": 39180
    },
    {
      "epoch": 4.7216867469879515,
      "grad_norm": 0.38964754343032837,
      "learning_rate": 1.0556626506024097e-05,
      "loss": 0.0285,
      "step": 39190
    },
    {
      "epoch": 4.72289156626506,
      "grad_norm": 8.7529878616333,
      "learning_rate": 1.055421686746988e-05,
      "loss": 0.0761,
      "step": 39200
    },
    {
      "epoch": 4.724096385542168,
      "grad_norm": 0.050184108316898346,
      "learning_rate": 1.0551807228915662e-05,
      "loss": 0.0194,
      "step": 39210
    },
    {
      "epoch": 4.725301204819277,
      "grad_norm": 0.010082141496241093,
      "learning_rate": 1.0549397590361447e-05,
      "loss": 0.0107,
      "step": 39220
    },
    {
      "epoch": 4.726506024096386,
      "grad_norm": 13.462952613830566,
      "learning_rate": 1.054698795180723e-05,
      "loss": 0.0228,
      "step": 39230
    },
    {
      "epoch": 4.727710843373494,
      "grad_norm": 0.0033275028690695763,
      "learning_rate": 1.0544578313253013e-05,
      "loss": 0.039,
      "step": 39240
    },
    {
      "epoch": 4.728915662650603,
      "grad_norm": 2.0612311363220215,
      "learning_rate": 1.0542168674698796e-05,
      "loss": 0.0488,
      "step": 39250
    },
    {
      "epoch": 4.7301204819277105,
      "grad_norm": 1.4988092184066772,
      "learning_rate": 1.053975903614458e-05,
      "loss": 0.0397,
      "step": 39260
    },
    {
      "epoch": 4.731325301204819,
      "grad_norm": 0.2743106782436371,
      "learning_rate": 1.0537349397590361e-05,
      "loss": 0.1003,
      "step": 39270
    },
    {
      "epoch": 4.732530120481927,
      "grad_norm": 0.002729985397309065,
      "learning_rate": 1.0534939759036144e-05,
      "loss": 0.0034,
      "step": 39280
    },
    {
      "epoch": 4.733734939759036,
      "grad_norm": 5.06296443939209,
      "learning_rate": 1.0532530120481927e-05,
      "loss": 0.0498,
      "step": 39290
    },
    {
      "epoch": 4.734939759036145,
      "grad_norm": 0.01226056832820177,
      "learning_rate": 1.0530120481927712e-05,
      "loss": 0.0379,
      "step": 39300
    },
    {
      "epoch": 4.736144578313253,
      "grad_norm": 0.8727119565010071,
      "learning_rate": 1.0527710843373495e-05,
      "loss": 0.0036,
      "step": 39310
    },
    {
      "epoch": 4.7373493975903616,
      "grad_norm": 0.5658752918243408,
      "learning_rate": 1.0525301204819279e-05,
      "loss": 0.0025,
      "step": 39320
    },
    {
      "epoch": 4.73855421686747,
      "grad_norm": 16.00208282470703,
      "learning_rate": 1.0522891566265062e-05,
      "loss": 0.0375,
      "step": 39330
    },
    {
      "epoch": 4.739759036144578,
      "grad_norm": 0.014835367910563946,
      "learning_rate": 1.0520481927710843e-05,
      "loss": 0.0456,
      "step": 39340
    },
    {
      "epoch": 4.740963855421687,
      "grad_norm": 1.847994327545166,
      "learning_rate": 1.0518072289156626e-05,
      "loss": 0.0405,
      "step": 39350
    },
    {
      "epoch": 4.742168674698795,
      "grad_norm": 7.087849140167236,
      "learning_rate": 1.051566265060241e-05,
      "loss": 0.016,
      "step": 39360
    },
    {
      "epoch": 4.743373493975904,
      "grad_norm": 0.03115583397448063,
      "learning_rate": 1.0513253012048194e-05,
      "loss": 0.041,
      "step": 39370
    },
    {
      "epoch": 4.744578313253012,
      "grad_norm": 0.09409565478563309,
      "learning_rate": 1.0510843373493978e-05,
      "loss": 0.0142,
      "step": 39380
    },
    {
      "epoch": 4.7457831325301205,
      "grad_norm": 16.660030364990234,
      "learning_rate": 1.050843373493976e-05,
      "loss": 0.0382,
      "step": 39390
    },
    {
      "epoch": 4.746987951807229,
      "grad_norm": 6.5300679206848145,
      "learning_rate": 1.0506024096385542e-05,
      "loss": 0.0456,
      "step": 39400
    },
    {
      "epoch": 4.748192771084337,
      "grad_norm": 0.05652669817209244,
      "learning_rate": 1.0503614457831326e-05,
      "loss": 0.0476,
      "step": 39410
    },
    {
      "epoch": 4.749397590361446,
      "grad_norm": 0.5488177537918091,
      "learning_rate": 1.0501204819277109e-05,
      "loss": 0.0571,
      "step": 39420
    },
    {
      "epoch": 4.750602409638554,
      "grad_norm": 142.97573852539062,
      "learning_rate": 1.0498795180722892e-05,
      "loss": 0.0156,
      "step": 39430
    },
    {
      "epoch": 4.751807228915663,
      "grad_norm": 1.6566832065582275,
      "learning_rate": 1.0496385542168677e-05,
      "loss": 0.0195,
      "step": 39440
    },
    {
      "epoch": 4.753012048192771,
      "grad_norm": 0.011334875598549843,
      "learning_rate": 1.049397590361446e-05,
      "loss": 0.0693,
      "step": 39450
    },
    {
      "epoch": 4.7542168674698795,
      "grad_norm": 0.008097740821540356,
      "learning_rate": 1.0491566265060243e-05,
      "loss": 0.0641,
      "step": 39460
    },
    {
      "epoch": 4.755421686746988,
      "grad_norm": 0.6206358671188354,
      "learning_rate": 1.0489156626506025e-05,
      "loss": 0.0157,
      "step": 39470
    },
    {
      "epoch": 4.756626506024096,
      "grad_norm": 0.056597474962472916,
      "learning_rate": 1.0486746987951808e-05,
      "loss": 0.0024,
      "step": 39480
    },
    {
      "epoch": 4.757831325301205,
      "grad_norm": 3.2297725677490234,
      "learning_rate": 1.0484337349397591e-05,
      "loss": 0.0443,
      "step": 39490
    },
    {
      "epoch": 4.759036144578313,
      "grad_norm": 0.018459493294358253,
      "learning_rate": 1.0481927710843374e-05,
      "loss": 0.0731,
      "step": 39500
    },
    {
      "epoch": 4.760240963855422,
      "grad_norm": 2.004431962966919,
      "learning_rate": 1.0479518072289157e-05,
      "loss": 0.03,
      "step": 39510
    },
    {
      "epoch": 4.76144578313253,
      "grad_norm": 0.12113749235868454,
      "learning_rate": 1.0477108433734942e-05,
      "loss": 0.0026,
      "step": 39520
    },
    {
      "epoch": 4.7626506024096384,
      "grad_norm": 2.8246374130249023,
      "learning_rate": 1.0474698795180724e-05,
      "loss": 0.0259,
      "step": 39530
    },
    {
      "epoch": 4.763855421686747,
      "grad_norm": 0.7542368769645691,
      "learning_rate": 1.0472289156626507e-05,
      "loss": 0.0234,
      "step": 39540
    },
    {
      "epoch": 4.765060240963855,
      "grad_norm": 0.3810218870639801,
      "learning_rate": 1.046987951807229e-05,
      "loss": 0.0535,
      "step": 39550
    },
    {
      "epoch": 4.766265060240964,
      "grad_norm": 1.7966212034225464,
      "learning_rate": 1.0467469879518073e-05,
      "loss": 0.0218,
      "step": 39560
    },
    {
      "epoch": 4.767469879518073,
      "grad_norm": 0.006709774490445852,
      "learning_rate": 1.0465060240963856e-05,
      "loss": 0.0498,
      "step": 39570
    },
    {
      "epoch": 4.768674698795181,
      "grad_norm": 1.6853643655776978,
      "learning_rate": 1.0462650602409638e-05,
      "loss": 0.032,
      "step": 39580
    },
    {
      "epoch": 4.7698795180722895,
      "grad_norm": 0.7157599329948425,
      "learning_rate": 1.0460240963855424e-05,
      "loss": 0.011,
      "step": 39590
    },
    {
      "epoch": 4.771084337349397,
      "grad_norm": 0.010898166336119175,
      "learning_rate": 1.0457831325301206e-05,
      "loss": 0.0828,
      "step": 39600
    },
    {
      "epoch": 4.772289156626506,
      "grad_norm": 0.02350473590195179,
      "learning_rate": 1.0455421686746989e-05,
      "loss": 0.018,
      "step": 39610
    },
    {
      "epoch": 4.773493975903614,
      "grad_norm": 7.579938888549805,
      "learning_rate": 1.0453012048192772e-05,
      "loss": 0.0674,
      "step": 39620
    },
    {
      "epoch": 4.774698795180723,
      "grad_norm": 0.01471136324107647,
      "learning_rate": 1.0450602409638555e-05,
      "loss": 0.0395,
      "step": 39630
    },
    {
      "epoch": 4.775903614457832,
      "grad_norm": 2.8525876998901367,
      "learning_rate": 1.0448192771084339e-05,
      "loss": 0.0415,
      "step": 39640
    },
    {
      "epoch": 4.77710843373494,
      "grad_norm": 25.934284210205078,
      "learning_rate": 1.044578313253012e-05,
      "loss": 0.08,
      "step": 39650
    },
    {
      "epoch": 4.7783132530120485,
      "grad_norm": 0.34249812364578247,
      "learning_rate": 1.0443373493975903e-05,
      "loss": 0.0457,
      "step": 39660
    },
    {
      "epoch": 4.779518072289156,
      "grad_norm": 0.5577937960624695,
      "learning_rate": 1.0440963855421688e-05,
      "loss": 0.0545,
      "step": 39670
    },
    {
      "epoch": 4.780722891566265,
      "grad_norm": 0.08802579343318939,
      "learning_rate": 1.0438554216867471e-05,
      "loss": 0.0292,
      "step": 39680
    },
    {
      "epoch": 4.781927710843373,
      "grad_norm": 0.05108972638845444,
      "learning_rate": 1.0436144578313254e-05,
      "loss": 0.0079,
      "step": 39690
    },
    {
      "epoch": 4.783132530120482,
      "grad_norm": 0.7461119294166565,
      "learning_rate": 1.0433734939759038e-05,
      "loss": 0.0676,
      "step": 39700
    },
    {
      "epoch": 4.784337349397591,
      "grad_norm": 0.019228620454669,
      "learning_rate": 1.0431325301204819e-05,
      "loss": 0.0309,
      "step": 39710
    },
    {
      "epoch": 4.785542168674699,
      "grad_norm": 0.008097168058156967,
      "learning_rate": 1.0428915662650602e-05,
      "loss": 0.0203,
      "step": 39720
    },
    {
      "epoch": 4.786746987951807,
      "grad_norm": 5.150120735168457,
      "learning_rate": 1.0426506024096385e-05,
      "loss": 0.0642,
      "step": 39730
    },
    {
      "epoch": 4.787951807228915,
      "grad_norm": 0.29896464943885803,
      "learning_rate": 1.042409638554217e-05,
      "loss": 0.0319,
      "step": 39740
    },
    {
      "epoch": 4.789156626506024,
      "grad_norm": 6.287850856781006,
      "learning_rate": 1.0421686746987953e-05,
      "loss": 0.0547,
      "step": 39750
    },
    {
      "epoch": 4.790361445783132,
      "grad_norm": 0.6415256261825562,
      "learning_rate": 1.0419277108433737e-05,
      "loss": 0.0131,
      "step": 39760
    },
    {
      "epoch": 4.791566265060241,
      "grad_norm": 0.014895722270011902,
      "learning_rate": 1.041686746987952e-05,
      "loss": 0.0177,
      "step": 39770
    },
    {
      "epoch": 4.79277108433735,
      "grad_norm": 0.053473129868507385,
      "learning_rate": 1.0414457831325301e-05,
      "loss": 0.0035,
      "step": 39780
    },
    {
      "epoch": 4.793975903614458,
      "grad_norm": 0.008983515202999115,
      "learning_rate": 1.0412048192771084e-05,
      "loss": 0.0276,
      "step": 39790
    },
    {
      "epoch": 4.795180722891566,
      "grad_norm": 0.007673137355595827,
      "learning_rate": 1.0409638554216868e-05,
      "loss": 0.0131,
      "step": 39800
    },
    {
      "epoch": 4.796385542168675,
      "grad_norm": 0.01547948643565178,
      "learning_rate": 1.0407228915662651e-05,
      "loss": 0.0223,
      "step": 39810
    },
    {
      "epoch": 4.797590361445783,
      "grad_norm": 2.0207784175872803,
      "learning_rate": 1.0404819277108436e-05,
      "loss": 0.0414,
      "step": 39820
    },
    {
      "epoch": 4.798795180722892,
      "grad_norm": 0.5690152049064636,
      "learning_rate": 1.0402409638554219e-05,
      "loss": 0.0057,
      "step": 39830
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.023862628266215324,
      "learning_rate": 1.04e-05,
      "loss": 0.0385,
      "step": 39840
    },
    {
      "epoch": 4.801204819277109,
      "grad_norm": 1.7011336088180542,
      "learning_rate": 1.0397590361445784e-05,
      "loss": 0.0157,
      "step": 39850
    },
    {
      "epoch": 4.8024096385542165,
      "grad_norm": 0.25737690925598145,
      "learning_rate": 1.0395180722891567e-05,
      "loss": 0.034,
      "step": 39860
    },
    {
      "epoch": 4.803614457831325,
      "grad_norm": 4.674500942230225,
      "learning_rate": 1.039277108433735e-05,
      "loss": 0.0397,
      "step": 39870
    },
    {
      "epoch": 4.804819277108434,
      "grad_norm": 1.358241319656372,
      "learning_rate": 1.0390361445783133e-05,
      "loss": 0.0505,
      "step": 39880
    },
    {
      "epoch": 4.806024096385542,
      "grad_norm": 0.059661321341991425,
      "learning_rate": 1.0387951807228918e-05,
      "loss": 0.0125,
      "step": 39890
    },
    {
      "epoch": 4.807228915662651,
      "grad_norm": 6.886377811431885,
      "learning_rate": 1.0385542168674701e-05,
      "loss": 0.0636,
      "step": 39900
    },
    {
      "epoch": 4.808433734939759,
      "grad_norm": 14.682679176330566,
      "learning_rate": 1.0383132530120483e-05,
      "loss": 0.0899,
      "step": 39910
    },
    {
      "epoch": 4.809638554216868,
      "grad_norm": 27.60809326171875,
      "learning_rate": 1.0380722891566266e-05,
      "loss": 0.0682,
      "step": 39920
    },
    {
      "epoch": 4.8108433734939755,
      "grad_norm": 0.10973244160413742,
      "learning_rate": 1.0378313253012049e-05,
      "loss": 0.0461,
      "step": 39930
    },
    {
      "epoch": 4.812048192771084,
      "grad_norm": 1.158400535583496,
      "learning_rate": 1.0375903614457832e-05,
      "loss": 0.005,
      "step": 39940
    },
    {
      "epoch": 4.813253012048193,
      "grad_norm": 0.0262462068349123,
      "learning_rate": 1.0373493975903615e-05,
      "loss": 0.0519,
      "step": 39950
    },
    {
      "epoch": 4.814457831325301,
      "grad_norm": 0.21667920053005219,
      "learning_rate": 1.0371084337349397e-05,
      "loss": 0.0456,
      "step": 39960
    },
    {
      "epoch": 4.81566265060241,
      "grad_norm": 0.017273807898163795,
      "learning_rate": 1.0368674698795183e-05,
      "loss": 0.0375,
      "step": 39970
    },
    {
      "epoch": 4.816867469879518,
      "grad_norm": 0.09476017951965332,
      "learning_rate": 1.0366265060240965e-05,
      "loss": 0.0032,
      "step": 39980
    },
    {
      "epoch": 4.8180722891566266,
      "grad_norm": 3.026533842086792,
      "learning_rate": 1.0363855421686748e-05,
      "loss": 0.0326,
      "step": 39990
    },
    {
      "epoch": 4.8192771084337345,
      "grad_norm": 0.00956935714930296,
      "learning_rate": 1.0361445783132531e-05,
      "loss": 0.0484,
      "step": 40000
    },
    {
      "epoch": 4.820481927710843,
      "grad_norm": 1.90123450756073,
      "learning_rate": 1.0359036144578314e-05,
      "loss": 0.0649,
      "step": 40010
    },
    {
      "epoch": 4.821686746987952,
      "grad_norm": 0.019673358649015427,
      "learning_rate": 1.0356626506024096e-05,
      "loss": 0.0142,
      "step": 40020
    },
    {
      "epoch": 4.82289156626506,
      "grad_norm": 1.902736783027649,
      "learning_rate": 1.0354216867469879e-05,
      "loss": 0.0335,
      "step": 40030
    },
    {
      "epoch": 4.824096385542169,
      "grad_norm": 1.587590217590332,
      "learning_rate": 1.0351807228915664e-05,
      "loss": 0.0626,
      "step": 40040
    },
    {
      "epoch": 4.825301204819278,
      "grad_norm": 0.03137718886137009,
      "learning_rate": 1.0349397590361447e-05,
      "loss": 0.0512,
      "step": 40050
    },
    {
      "epoch": 4.8265060240963855,
      "grad_norm": 0.4279036223888397,
      "learning_rate": 1.034698795180723e-05,
      "loss": 0.0138,
      "step": 40060
    },
    {
      "epoch": 4.827710843373494,
      "grad_norm": 0.20324474573135376,
      "learning_rate": 1.0344578313253013e-05,
      "loss": 0.0182,
      "step": 40070
    },
    {
      "epoch": 4.828915662650602,
      "grad_norm": 0.12625528872013092,
      "learning_rate": 1.0342168674698797e-05,
      "loss": 0.0704,
      "step": 40080
    },
    {
      "epoch": 4.830120481927711,
      "grad_norm": 0.6830306053161621,
      "learning_rate": 1.0339759036144578e-05,
      "loss": 0.0047,
      "step": 40090
    },
    {
      "epoch": 4.831325301204819,
      "grad_norm": 18.233190536499023,
      "learning_rate": 1.0337349397590361e-05,
      "loss": 0.0571,
      "step": 40100
    },
    {
      "epoch": 4.832530120481928,
      "grad_norm": 0.011999949812889099,
      "learning_rate": 1.0334939759036144e-05,
      "loss": 0.0195,
      "step": 40110
    },
    {
      "epoch": 4.833734939759037,
      "grad_norm": 0.015482546761631966,
      "learning_rate": 1.033253012048193e-05,
      "loss": 0.03,
      "step": 40120
    },
    {
      "epoch": 4.8349397590361445,
      "grad_norm": 0.005227940622717142,
      "learning_rate": 1.0330120481927712e-05,
      "loss": 0.0023,
      "step": 40130
    },
    {
      "epoch": 4.836144578313253,
      "grad_norm": 0.2765166461467743,
      "learning_rate": 1.0327710843373496e-05,
      "loss": 0.0099,
      "step": 40140
    },
    {
      "epoch": 4.837349397590361,
      "grad_norm": 0.004035928286612034,
      "learning_rate": 1.0325301204819279e-05,
      "loss": 0.0364,
      "step": 40150
    },
    {
      "epoch": 4.83855421686747,
      "grad_norm": 3.7732574939727783,
      "learning_rate": 1.032289156626506e-05,
      "loss": 0.0185,
      "step": 40160
    },
    {
      "epoch": 4.839759036144578,
      "grad_norm": 0.007924985140562057,
      "learning_rate": 1.0320481927710843e-05,
      "loss": 0.0444,
      "step": 40170
    },
    {
      "epoch": 4.840963855421687,
      "grad_norm": 0.30665820837020874,
      "learning_rate": 1.0318072289156627e-05,
      "loss": 0.0232,
      "step": 40180
    },
    {
      "epoch": 4.8421686746987955,
      "grad_norm": 9.926752090454102,
      "learning_rate": 1.0315662650602412e-05,
      "loss": 0.0836,
      "step": 40190
    },
    {
      "epoch": 4.843373493975903,
      "grad_norm": 3.40165114402771,
      "learning_rate": 1.0313253012048195e-05,
      "loss": 0.0699,
      "step": 40200
    },
    {
      "epoch": 4.844578313253012,
      "grad_norm": 0.017045922577381134,
      "learning_rate": 1.0310843373493978e-05,
      "loss": 0.0462,
      "step": 40210
    },
    {
      "epoch": 4.84578313253012,
      "grad_norm": 0.050878338515758514,
      "learning_rate": 1.030843373493976e-05,
      "loss": 0.0059,
      "step": 40220
    },
    {
      "epoch": 4.846987951807229,
      "grad_norm": 0.01711059734225273,
      "learning_rate": 1.0306024096385543e-05,
      "loss": 0.0221,
      "step": 40230
    },
    {
      "epoch": 4.848192771084337,
      "grad_norm": 0.03439273685216904,
      "learning_rate": 1.0303614457831326e-05,
      "loss": 0.0021,
      "step": 40240
    },
    {
      "epoch": 4.849397590361446,
      "grad_norm": 0.028506003320217133,
      "learning_rate": 1.0301204819277109e-05,
      "loss": 0.0371,
      "step": 40250
    },
    {
      "epoch": 4.8506024096385545,
      "grad_norm": 0.7646579742431641,
      "learning_rate": 1.0298795180722892e-05,
      "loss": 0.019,
      "step": 40260
    },
    {
      "epoch": 4.851807228915662,
      "grad_norm": 0.4949510991573334,
      "learning_rate": 1.0296385542168677e-05,
      "loss": 0.0275,
      "step": 40270
    },
    {
      "epoch": 4.853012048192771,
      "grad_norm": 0.05691782012581825,
      "learning_rate": 1.029397590361446e-05,
      "loss": 0.0267,
      "step": 40280
    },
    {
      "epoch": 4.85421686746988,
      "grad_norm": 0.005874286871403456,
      "learning_rate": 1.0291566265060242e-05,
      "loss": 0.0281,
      "step": 40290
    },
    {
      "epoch": 4.855421686746988,
      "grad_norm": 7.646342754364014,
      "learning_rate": 1.0289156626506025e-05,
      "loss": 0.0415,
      "step": 40300
    },
    {
      "epoch": 4.856626506024097,
      "grad_norm": 0.06773735582828522,
      "learning_rate": 1.0286746987951808e-05,
      "loss": 0.04,
      "step": 40310
    },
    {
      "epoch": 4.857831325301205,
      "grad_norm": 0.009888903237879276,
      "learning_rate": 1.0284337349397591e-05,
      "loss": 0.0392,
      "step": 40320
    },
    {
      "epoch": 4.8590361445783135,
      "grad_norm": 0.04035288095474243,
      "learning_rate": 1.0281927710843374e-05,
      "loss": 0.0224,
      "step": 40330
    },
    {
      "epoch": 4.860240963855421,
      "grad_norm": 0.020624298602342606,
      "learning_rate": 1.027951807228916e-05,
      "loss": 0.0026,
      "step": 40340
    },
    {
      "epoch": 4.86144578313253,
      "grad_norm": 1.5552512407302856,
      "learning_rate": 1.027710843373494e-05,
      "loss": 0.0325,
      "step": 40350
    },
    {
      "epoch": 4.862650602409639,
      "grad_norm": 11.211079597473145,
      "learning_rate": 1.0274698795180724e-05,
      "loss": 0.0421,
      "step": 40360
    },
    {
      "epoch": 4.863855421686747,
      "grad_norm": 1.7669199705123901,
      "learning_rate": 1.0272289156626507e-05,
      "loss": 0.021,
      "step": 40370
    },
    {
      "epoch": 4.865060240963856,
      "grad_norm": 0.009868480265140533,
      "learning_rate": 1.026987951807229e-05,
      "loss": 0.0616,
      "step": 40380
    },
    {
      "epoch": 4.866265060240964,
      "grad_norm": 0.017833039164543152,
      "learning_rate": 1.0267469879518073e-05,
      "loss": 0.0628,
      "step": 40390
    },
    {
      "epoch": 4.867469879518072,
      "grad_norm": 0.020929310470819473,
      "learning_rate": 1.0265060240963855e-05,
      "loss": 0.0151,
      "step": 40400
    },
    {
      "epoch": 4.86867469879518,
      "grad_norm": 1.3208767175674438,
      "learning_rate": 1.0262650602409638e-05,
      "loss": 0.0392,
      "step": 40410
    },
    {
      "epoch": 4.869879518072289,
      "grad_norm": 0.040916942059993744,
      "learning_rate": 1.0260240963855423e-05,
      "loss": 0.015,
      "step": 40420
    },
    {
      "epoch": 4.871084337349398,
      "grad_norm": 2.2188963890075684,
      "learning_rate": 1.0257831325301206e-05,
      "loss": 0.025,
      "step": 40430
    },
    {
      "epoch": 4.872289156626506,
      "grad_norm": 0.10440494865179062,
      "learning_rate": 1.025542168674699e-05,
      "loss": 0.0503,
      "step": 40440
    },
    {
      "epoch": 4.873493975903615,
      "grad_norm": 0.02507799305021763,
      "learning_rate": 1.0253012048192772e-05,
      "loss": 0.0242,
      "step": 40450
    },
    {
      "epoch": 4.874698795180723,
      "grad_norm": 0.1478915512561798,
      "learning_rate": 1.0250602409638556e-05,
      "loss": 0.0049,
      "step": 40460
    },
    {
      "epoch": 4.875903614457831,
      "grad_norm": 8.592613220214844,
      "learning_rate": 1.0248192771084337e-05,
      "loss": 0.0395,
      "step": 40470
    },
    {
      "epoch": 4.877108433734939,
      "grad_norm": 0.013344192877411842,
      "learning_rate": 1.024578313253012e-05,
      "loss": 0.0422,
      "step": 40480
    },
    {
      "epoch": 4.878313253012048,
      "grad_norm": 0.005231928080320358,
      "learning_rate": 1.0243373493975905e-05,
      "loss": 0.0025,
      "step": 40490
    },
    {
      "epoch": 4.879518072289157,
      "grad_norm": 5.867388725280762,
      "learning_rate": 1.0240963855421688e-05,
      "loss": 0.0175,
      "step": 40500
    },
    {
      "epoch": 4.880722891566265,
      "grad_norm": 0.10801517963409424,
      "learning_rate": 1.0238554216867471e-05,
      "loss": 0.0068,
      "step": 40510
    },
    {
      "epoch": 4.881927710843374,
      "grad_norm": 0.3457634747028351,
      "learning_rate": 1.0236144578313255e-05,
      "loss": 0.0227,
      "step": 40520
    },
    {
      "epoch": 4.8831325301204815,
      "grad_norm": 0.004530010744929314,
      "learning_rate": 1.0233734939759036e-05,
      "loss": 0.0192,
      "step": 40530
    },
    {
      "epoch": 4.88433734939759,
      "grad_norm": 0.1988891363143921,
      "learning_rate": 1.023132530120482e-05,
      "loss": 0.0141,
      "step": 40540
    },
    {
      "epoch": 4.885542168674699,
      "grad_norm": 2.344395160675049,
      "learning_rate": 1.0228915662650602e-05,
      "loss": 0.0083,
      "step": 40550
    },
    {
      "epoch": 4.886746987951807,
      "grad_norm": 0.032903723418712616,
      "learning_rate": 1.0226506024096386e-05,
      "loss": 0.0537,
      "step": 40560
    },
    {
      "epoch": 4.887951807228916,
      "grad_norm": 0.004367301240563393,
      "learning_rate": 1.022409638554217e-05,
      "loss": 0.0222,
      "step": 40570
    },
    {
      "epoch": 4.889156626506024,
      "grad_norm": 0.0029453644528985023,
      "learning_rate": 1.0221686746987954e-05,
      "loss": 0.0572,
      "step": 40580
    },
    {
      "epoch": 4.890361445783133,
      "grad_norm": 0.026210539042949677,
      "learning_rate": 1.0219277108433737e-05,
      "loss": 0.0371,
      "step": 40590
    },
    {
      "epoch": 4.891566265060241,
      "grad_norm": 0.07844313234090805,
      "learning_rate": 1.0216867469879518e-05,
      "loss": 0.0461,
      "step": 40600
    },
    {
      "epoch": 4.892771084337349,
      "grad_norm": 0.0032931289169937372,
      "learning_rate": 1.0214457831325302e-05,
      "loss": 0.0229,
      "step": 40610
    },
    {
      "epoch": 4.893975903614458,
      "grad_norm": 0.02990787848830223,
      "learning_rate": 1.0212048192771085e-05,
      "loss": 0.0414,
      "step": 40620
    },
    {
      "epoch": 4.895180722891566,
      "grad_norm": 0.011798005551099777,
      "learning_rate": 1.0209638554216868e-05,
      "loss": 0.0092,
      "step": 40630
    },
    {
      "epoch": 4.896385542168675,
      "grad_norm": 1.2227330207824707,
      "learning_rate": 1.0207228915662653e-05,
      "loss": 0.0238,
      "step": 40640
    },
    {
      "epoch": 4.897590361445783,
      "grad_norm": 0.05308228358626366,
      "learning_rate": 1.0204819277108436e-05,
      "loss": 0.0305,
      "step": 40650
    },
    {
      "epoch": 4.8987951807228916,
      "grad_norm": 0.06292491406202316,
      "learning_rate": 1.0202409638554217e-05,
      "loss": 0.003,
      "step": 40660
    },
    {
      "epoch": 4.9,
      "grad_norm": 10.931475639343262,
      "learning_rate": 1.02e-05,
      "loss": 0.0331,
      "step": 40670
    },
    {
      "epoch": 4.901204819277108,
      "grad_norm": 4.352996349334717,
      "learning_rate": 1.0197590361445784e-05,
      "loss": 0.0185,
      "step": 40680
    },
    {
      "epoch": 4.902409638554217,
      "grad_norm": 25.098270416259766,
      "learning_rate": 1.0195180722891567e-05,
      "loss": 0.0038,
      "step": 40690
    },
    {
      "epoch": 4.903614457831325,
      "grad_norm": 28.363195419311523,
      "learning_rate": 1.019277108433735e-05,
      "loss": 0.0453,
      "step": 40700
    },
    {
      "epoch": 4.904819277108434,
      "grad_norm": 0.0636649802327156,
      "learning_rate": 1.0190361445783132e-05,
      "loss": 0.0137,
      "step": 40710
    },
    {
      "epoch": 4.906024096385542,
      "grad_norm": 2.7113165855407715,
      "learning_rate": 1.0187951807228918e-05,
      "loss": 0.0162,
      "step": 40720
    },
    {
      "epoch": 4.9072289156626505,
      "grad_norm": 1.3981945514678955,
      "learning_rate": 1.01855421686747e-05,
      "loss": 0.0264,
      "step": 40730
    },
    {
      "epoch": 4.908433734939759,
      "grad_norm": 0.18703527748584747,
      "learning_rate": 1.0183132530120483e-05,
      "loss": 0.0377,
      "step": 40740
    },
    {
      "epoch": 4.909638554216867,
      "grad_norm": 2.4224729537963867,
      "learning_rate": 1.0180722891566266e-05,
      "loss": 0.013,
      "step": 40750
    },
    {
      "epoch": 4.910843373493976,
      "grad_norm": 0.0023204730823636055,
      "learning_rate": 1.017831325301205e-05,
      "loss": 0.0416,
      "step": 40760
    },
    {
      "epoch": 4.912048192771084,
      "grad_norm": 1.4771795272827148,
      "learning_rate": 1.0175903614457832e-05,
      "loss": 0.0799,
      "step": 40770
    },
    {
      "epoch": 4.913253012048193,
      "grad_norm": 0.034824784845113754,
      "learning_rate": 1.0173493975903614e-05,
      "loss": 0.0272,
      "step": 40780
    },
    {
      "epoch": 4.914457831325302,
      "grad_norm": 0.13697616755962372,
      "learning_rate": 1.0171084337349399e-05,
      "loss": 0.0188,
      "step": 40790
    },
    {
      "epoch": 4.9156626506024095,
      "grad_norm": 0.17033617198467255,
      "learning_rate": 1.0168674698795182e-05,
      "loss": 0.0406,
      "step": 40800
    },
    {
      "epoch": 4.916867469879518,
      "grad_norm": 3.1368377208709717,
      "learning_rate": 1.0166265060240965e-05,
      "loss": 0.0156,
      "step": 40810
    },
    {
      "epoch": 4.918072289156626,
      "grad_norm": 1.787257432937622,
      "learning_rate": 1.0163855421686748e-05,
      "loss": 0.0799,
      "step": 40820
    },
    {
      "epoch": 4.919277108433735,
      "grad_norm": 0.5434222221374512,
      "learning_rate": 1.0161445783132531e-05,
      "loss": 0.0345,
      "step": 40830
    },
    {
      "epoch": 4.920481927710844,
      "grad_norm": 0.006876403000205755,
      "learning_rate": 1.0159036144578313e-05,
      "loss": 0.0641,
      "step": 40840
    },
    {
      "epoch": 4.921686746987952,
      "grad_norm": 0.6055235266685486,
      "learning_rate": 1.0156626506024096e-05,
      "loss": 0.0311,
      "step": 40850
    },
    {
      "epoch": 4.9228915662650605,
      "grad_norm": 0.009591793641448021,
      "learning_rate": 1.015421686746988e-05,
      "loss": 0.0294,
      "step": 40860
    },
    {
      "epoch": 4.924096385542168,
      "grad_norm": 0.4274800419807434,
      "learning_rate": 1.0151807228915664e-05,
      "loss": 0.0094,
      "step": 40870
    },
    {
      "epoch": 4.925301204819277,
      "grad_norm": 0.09475570917129517,
      "learning_rate": 1.0149397590361447e-05,
      "loss": 0.0607,
      "step": 40880
    },
    {
      "epoch": 4.926506024096385,
      "grad_norm": 1.3239500522613525,
      "learning_rate": 1.014698795180723e-05,
      "loss": 0.0142,
      "step": 40890
    },
    {
      "epoch": 4.927710843373494,
      "grad_norm": 0.015576324425637722,
      "learning_rate": 1.0144578313253014e-05,
      "loss": 0.0166,
      "step": 40900
    },
    {
      "epoch": 4.928915662650603,
      "grad_norm": 0.015861723572015762,
      "learning_rate": 1.0142168674698795e-05,
      "loss": 0.0071,
      "step": 40910
    },
    {
      "epoch": 4.930120481927711,
      "grad_norm": 0.1234411969780922,
      "learning_rate": 1.0139759036144578e-05,
      "loss": 0.0377,
      "step": 40920
    },
    {
      "epoch": 4.9313253012048195,
      "grad_norm": 0.007934454828500748,
      "learning_rate": 1.0137349397590361e-05,
      "loss": 0.0076,
      "step": 40930
    },
    {
      "epoch": 4.932530120481927,
      "grad_norm": 0.7481517791748047,
      "learning_rate": 1.0134939759036146e-05,
      "loss": 0.0298,
      "step": 40940
    },
    {
      "epoch": 4.933734939759036,
      "grad_norm": 1.1454344987869263,
      "learning_rate": 1.013253012048193e-05,
      "loss": 0.0254,
      "step": 40950
    },
    {
      "epoch": 4.934939759036144,
      "grad_norm": 0.09664274752140045,
      "learning_rate": 1.0130120481927713e-05,
      "loss": 0.0206,
      "step": 40960
    },
    {
      "epoch": 4.936144578313253,
      "grad_norm": 0.004718357231467962,
      "learning_rate": 1.0127710843373494e-05,
      "loss": 0.0274,
      "step": 40970
    },
    {
      "epoch": 4.937349397590362,
      "grad_norm": 0.010625356808304787,
      "learning_rate": 1.0125301204819277e-05,
      "loss": 0.0077,
      "step": 40980
    },
    {
      "epoch": 4.93855421686747,
      "grad_norm": 1.1165783405303955,
      "learning_rate": 1.012289156626506e-05,
      "loss": 0.0442,
      "step": 40990
    },
    {
      "epoch": 4.9397590361445785,
      "grad_norm": 2.0111446380615234,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 0.0533,
      "step": 41000
    },
    {
      "epoch": 4.940963855421686,
      "grad_norm": 2.0314693450927734,
      "learning_rate": 1.0118072289156627e-05,
      "loss": 0.0354,
      "step": 41010
    },
    {
      "epoch": 4.942168674698795,
      "grad_norm": 0.10145609080791473,
      "learning_rate": 1.0115662650602412e-05,
      "loss": 0.0024,
      "step": 41020
    },
    {
      "epoch": 4.943373493975904,
      "grad_norm": 2.222783327102661,
      "learning_rate": 1.0113253012048195e-05,
      "loss": 0.0614,
      "step": 41030
    },
    {
      "epoch": 4.944578313253012,
      "grad_norm": 1.1120214462280273,
      "learning_rate": 1.0110843373493976e-05,
      "loss": 0.0191,
      "step": 41040
    },
    {
      "epoch": 4.945783132530121,
      "grad_norm": 0.06294461339712143,
      "learning_rate": 1.010843373493976e-05,
      "loss": 0.0403,
      "step": 41050
    },
    {
      "epoch": 4.946987951807229,
      "grad_norm": 0.013453896157443523,
      "learning_rate": 1.0106024096385543e-05,
      "loss": 0.0343,
      "step": 41060
    },
    {
      "epoch": 4.948192771084337,
      "grad_norm": 1.9289835691452026,
      "learning_rate": 1.0103614457831326e-05,
      "loss": 0.0114,
      "step": 41070
    },
    {
      "epoch": 4.949397590361446,
      "grad_norm": 0.3551267087459564,
      "learning_rate": 1.0101204819277109e-05,
      "loss": 0.0142,
      "step": 41080
    },
    {
      "epoch": 4.950602409638554,
      "grad_norm": 5.713076114654541,
      "learning_rate": 1.0098795180722894e-05,
      "loss": 0.0432,
      "step": 41090
    },
    {
      "epoch": 4.951807228915663,
      "grad_norm": 0.029276229441165924,
      "learning_rate": 1.0096385542168675e-05,
      "loss": 0.0094,
      "step": 41100
    },
    {
      "epoch": 4.953012048192771,
      "grad_norm": 0.5355137586593628,
      "learning_rate": 1.0093975903614459e-05,
      "loss": 0.0073,
      "step": 41110
    },
    {
      "epoch": 4.95421686746988,
      "grad_norm": 0.18005387485027313,
      "learning_rate": 1.0091566265060242e-05,
      "loss": 0.0087,
      "step": 41120
    },
    {
      "epoch": 4.955421686746988,
      "grad_norm": 0.0079545509070158,
      "learning_rate": 1.0089156626506025e-05,
      "loss": 0.033,
      "step": 41130
    },
    {
      "epoch": 4.956626506024096,
      "grad_norm": 7.2405219078063965,
      "learning_rate": 1.0086746987951808e-05,
      "loss": 0.0518,
      "step": 41140
    },
    {
      "epoch": 4.957831325301205,
      "grad_norm": 0.005117645021528006,
      "learning_rate": 1.008433734939759e-05,
      "loss": 0.0963,
      "step": 41150
    },
    {
      "epoch": 4.959036144578313,
      "grad_norm": 2.2045116424560547,
      "learning_rate": 1.0081927710843373e-05,
      "loss": 0.0376,
      "step": 41160
    },
    {
      "epoch": 4.960240963855422,
      "grad_norm": 23.3485164642334,
      "learning_rate": 1.0079518072289158e-05,
      "loss": 0.0257,
      "step": 41170
    },
    {
      "epoch": 4.96144578313253,
      "grad_norm": 1.007775068283081,
      "learning_rate": 1.0077108433734941e-05,
      "loss": 0.0695,
      "step": 41180
    },
    {
      "epoch": 4.962650602409639,
      "grad_norm": 0.004913812968879938,
      "learning_rate": 1.0074698795180724e-05,
      "loss": 0.0134,
      "step": 41190
    },
    {
      "epoch": 4.9638554216867465,
      "grad_norm": 0.04931418597698212,
      "learning_rate": 1.0072289156626507e-05,
      "loss": 0.0575,
      "step": 41200
    },
    {
      "epoch": 4.965060240963855,
      "grad_norm": 0.8019047975540161,
      "learning_rate": 1.006987951807229e-05,
      "loss": 0.0108,
      "step": 41210
    },
    {
      "epoch": 4.966265060240964,
      "grad_norm": 1.6769591569900513,
      "learning_rate": 1.0067469879518072e-05,
      "loss": 0.0062,
      "step": 41220
    },
    {
      "epoch": 4.967469879518072,
      "grad_norm": 2.190964460372925,
      "learning_rate": 1.0065060240963855e-05,
      "loss": 0.0271,
      "step": 41230
    },
    {
      "epoch": 4.968674698795181,
      "grad_norm": 0.016547871753573418,
      "learning_rate": 1.006265060240964e-05,
      "loss": 0.013,
      "step": 41240
    },
    {
      "epoch": 4.969879518072289,
      "grad_norm": 10.265438079833984,
      "learning_rate": 1.0060240963855423e-05,
      "loss": 0.026,
      "step": 41250
    },
    {
      "epoch": 4.971084337349398,
      "grad_norm": 1.284910798072815,
      "learning_rate": 1.0057831325301206e-05,
      "loss": 0.0162,
      "step": 41260
    },
    {
      "epoch": 4.972289156626506,
      "grad_norm": 2.2624478340148926,
      "learning_rate": 1.005542168674699e-05,
      "loss": 0.1188,
      "step": 41270
    },
    {
      "epoch": 4.973493975903614,
      "grad_norm": 0.004402732476592064,
      "learning_rate": 1.0053012048192771e-05,
      "loss": 0.0186,
      "step": 41280
    },
    {
      "epoch": 4.974698795180723,
      "grad_norm": 0.059133704751729965,
      "learning_rate": 1.0050602409638554e-05,
      "loss": 0.0373,
      "step": 41290
    },
    {
      "epoch": 4.975903614457831,
      "grad_norm": 24.840242385864258,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 0.0219,
      "step": 41300
    },
    {
      "epoch": 4.97710843373494,
      "grad_norm": 0.027686573565006256,
      "learning_rate": 1.004578313253012e-05,
      "loss": 0.0502,
      "step": 41310
    },
    {
      "epoch": 4.978313253012049,
      "grad_norm": 2.037376642227173,
      "learning_rate": 1.0043373493975905e-05,
      "loss": 0.0555,
      "step": 41320
    },
    {
      "epoch": 4.9795180722891565,
      "grad_norm": 0.030532674863934517,
      "learning_rate": 1.0040963855421689e-05,
      "loss": 0.0031,
      "step": 41330
    },
    {
      "epoch": 4.980722891566265,
      "grad_norm": 1.6886404752731323,
      "learning_rate": 1.0038554216867472e-05,
      "loss": 0.0229,
      "step": 41340
    },
    {
      "epoch": 4.981927710843373,
      "grad_norm": 0.3281400501728058,
      "learning_rate": 1.0036144578313253e-05,
      "loss": 0.0393,
      "step": 41350
    },
    {
      "epoch": 4.983132530120482,
      "grad_norm": 0.004795593675225973,
      "learning_rate": 1.0033734939759036e-05,
      "loss": 0.0207,
      "step": 41360
    },
    {
      "epoch": 4.98433734939759,
      "grad_norm": 6.218663692474365,
      "learning_rate": 1.003132530120482e-05,
      "loss": 0.0419,
      "step": 41370
    },
    {
      "epoch": 4.985542168674699,
      "grad_norm": 0.006860032211989164,
      "learning_rate": 1.0028915662650603e-05,
      "loss": 0.0044,
      "step": 41380
    },
    {
      "epoch": 4.986746987951808,
      "grad_norm": 0.0050056204199790955,
      "learning_rate": 1.0026506024096388e-05,
      "loss": 0.0354,
      "step": 41390
    },
    {
      "epoch": 4.9879518072289155,
      "grad_norm": 0.20514366030693054,
      "learning_rate": 1.002409638554217e-05,
      "loss": 0.0222,
      "step": 41400
    },
    {
      "epoch": 4.989156626506024,
      "grad_norm": 0.0031672196928411722,
      "learning_rate": 1.0021686746987952e-05,
      "loss": 0.0092,
      "step": 41410
    },
    {
      "epoch": 4.990361445783132,
      "grad_norm": 0.0202107522636652,
      "learning_rate": 1.0019277108433735e-05,
      "loss": 0.0296,
      "step": 41420
    },
    {
      "epoch": 4.991566265060241,
      "grad_norm": 2.30143404006958,
      "learning_rate": 1.0016867469879519e-05,
      "loss": 0.0165,
      "step": 41430
    },
    {
      "epoch": 4.992771084337349,
      "grad_norm": 0.00453178072348237,
      "learning_rate": 1.0014457831325302e-05,
      "loss": 0.0074,
      "step": 41440
    },
    {
      "epoch": 4.993975903614458,
      "grad_norm": 0.1627884954214096,
      "learning_rate": 1.0012048192771085e-05,
      "loss": 0.0577,
      "step": 41450
    },
    {
      "epoch": 4.995180722891567,
      "grad_norm": 0.17291678488254547,
      "learning_rate": 1.0009638554216866e-05,
      "loss": 0.0142,
      "step": 41460
    },
    {
      "epoch": 4.9963855421686745,
      "grad_norm": 0.004145858809351921,
      "learning_rate": 1.0007228915662653e-05,
      "loss": 0.0603,
      "step": 41470
    },
    {
      "epoch": 4.997590361445783,
      "grad_norm": 0.00358558283187449,
      "learning_rate": 1.0004819277108434e-05,
      "loss": 0.0025,
      "step": 41480
    },
    {
      "epoch": 4.998795180722891,
      "grad_norm": 7.31378173828125,
      "learning_rate": 1.0002409638554218e-05,
      "loss": 0.0266,
      "step": 41490
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.326416552066803,
      "learning_rate": 1e-05,
      "loss": 0.0051,
      "step": 41500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9854705661792276,
      "eval_f1": 0.9612548431446069,
      "eval_loss": 0.05584666505455971,
      "eval_precision": 0.9721906206547845,
      "eval_recall": 0.9505623532319861,
      "eval_runtime": 3429.0261,
      "eval_samples_per_second": 12.45,
      "eval_steps_per_second": 0.519,
      "step": 41500
    },
    {
      "epoch": 5.001204819277109,
      "grad_norm": 0.006710071116685867,
      "learning_rate": 9.997590361445784e-06,
      "loss": 0.0146,
      "step": 41510
    },
    {
      "epoch": 5.002409638554217,
      "grad_norm": 0.004981071688234806,
      "learning_rate": 9.995180722891567e-06,
      "loss": 0.0145,
      "step": 41520
    },
    {
      "epoch": 5.0036144578313255,
      "grad_norm": 0.007811030838638544,
      "learning_rate": 9.99277108433735e-06,
      "loss": 0.0159,
      "step": 41530
    },
    {
      "epoch": 5.004819277108433,
      "grad_norm": 0.008686760440468788,
      "learning_rate": 9.990361445783134e-06,
      "loss": 0.0241,
      "step": 41540
    },
    {
      "epoch": 5.006024096385542,
      "grad_norm": 0.671698272228241,
      "learning_rate": 9.987951807228917e-06,
      "loss": 0.1044,
      "step": 41550
    },
    {
      "epoch": 5.00722891566265,
      "grad_norm": 0.20259734988212585,
      "learning_rate": 9.9855421686747e-06,
      "loss": 0.0175,
      "step": 41560
    },
    {
      "epoch": 5.008433734939759,
      "grad_norm": 0.03163672611117363,
      "learning_rate": 9.983132530120483e-06,
      "loss": 0.0204,
      "step": 41570
    },
    {
      "epoch": 5.009638554216868,
      "grad_norm": 0.03905545920133591,
      "learning_rate": 9.980722891566266e-06,
      "loss": 0.012,
      "step": 41580
    },
    {
      "epoch": 5.010843373493976,
      "grad_norm": 0.03645605966448784,
      "learning_rate": 9.97831325301205e-06,
      "loss": 0.0546,
      "step": 41590
    },
    {
      "epoch": 5.0120481927710845,
      "grad_norm": 0.5142722725868225,
      "learning_rate": 9.975903614457833e-06,
      "loss": 0.0068,
      "step": 41600
    },
    {
      "epoch": 5.013253012048192,
      "grad_norm": 0.014862767420709133,
      "learning_rate": 9.973493975903616e-06,
      "loss": 0.0444,
      "step": 41610
    },
    {
      "epoch": 5.014457831325301,
      "grad_norm": 0.060293037444353104,
      "learning_rate": 9.971084337349399e-06,
      "loss": 0.0051,
      "step": 41620
    },
    {
      "epoch": 5.01566265060241,
      "grad_norm": 0.12868663668632507,
      "learning_rate": 9.96867469879518e-06,
      "loss": 0.0189,
      "step": 41630
    },
    {
      "epoch": 5.016867469879518,
      "grad_norm": 0.05491166561841965,
      "learning_rate": 9.966265060240965e-06,
      "loss": 0.0005,
      "step": 41640
    },
    {
      "epoch": 5.018072289156627,
      "grad_norm": 0.009232703596353531,
      "learning_rate": 9.963855421686748e-06,
      "loss": 0.0042,
      "step": 41650
    },
    {
      "epoch": 5.019277108433735,
      "grad_norm": 0.7577434182167053,
      "learning_rate": 9.96144578313253e-06,
      "loss": 0.0348,
      "step": 41660
    },
    {
      "epoch": 5.0204819277108435,
      "grad_norm": 0.008693323470652103,
      "learning_rate": 9.959036144578315e-06,
      "loss": 0.0062,
      "step": 41670
    },
    {
      "epoch": 5.021686746987951,
      "grad_norm": 0.02160615660250187,
      "learning_rate": 9.956626506024098e-06,
      "loss": 0.0067,
      "step": 41680
    },
    {
      "epoch": 5.02289156626506,
      "grad_norm": 0.1281459480524063,
      "learning_rate": 9.95421686746988e-06,
      "loss": 0.0327,
      "step": 41690
    },
    {
      "epoch": 5.024096385542169,
      "grad_norm": 0.16398000717163086,
      "learning_rate": 9.951807228915663e-06,
      "loss": 0.0133,
      "step": 41700
    },
    {
      "epoch": 5.025301204819277,
      "grad_norm": 0.00920541025698185,
      "learning_rate": 9.949397590361448e-06,
      "loss": 0.0096,
      "step": 41710
    },
    {
      "epoch": 5.026506024096386,
      "grad_norm": 0.7593093514442444,
      "learning_rate": 9.94698795180723e-06,
      "loss": 0.0249,
      "step": 41720
    },
    {
      "epoch": 5.027710843373494,
      "grad_norm": 3.9619572162628174,
      "learning_rate": 9.944578313253012e-06,
      "loss": 0.0401,
      "step": 41730
    },
    {
      "epoch": 5.028915662650602,
      "grad_norm": 0.0033308742567896843,
      "learning_rate": 9.942168674698795e-06,
      "loss": 0.0051,
      "step": 41740
    },
    {
      "epoch": 5.030120481927711,
      "grad_norm": 1.2871158123016357,
      "learning_rate": 9.93975903614458e-06,
      "loss": 0.0079,
      "step": 41750
    },
    {
      "epoch": 5.031325301204819,
      "grad_norm": 0.1519937962293625,
      "learning_rate": 9.937349397590362e-06,
      "loss": 0.0056,
      "step": 41760
    },
    {
      "epoch": 5.032530120481928,
      "grad_norm": 0.003453310811892152,
      "learning_rate": 9.934939759036145e-06,
      "loss": 0.0965,
      "step": 41770
    },
    {
      "epoch": 5.033734939759036,
      "grad_norm": 0.006180493161082268,
      "learning_rate": 9.932530120481928e-06,
      "loss": 0.013,
      "step": 41780
    },
    {
      "epoch": 5.034939759036145,
      "grad_norm": 0.002348349429666996,
      "learning_rate": 9.930120481927711e-06,
      "loss": 0.0176,
      "step": 41790
    },
    {
      "epoch": 5.036144578313253,
      "grad_norm": 0.1439124494791031,
      "learning_rate": 9.927710843373494e-06,
      "loss": 0.0035,
      "step": 41800
    },
    {
      "epoch": 5.037349397590361,
      "grad_norm": 0.002816230058670044,
      "learning_rate": 9.925301204819278e-06,
      "loss": 0.0379,
      "step": 41810
    },
    {
      "epoch": 5.03855421686747,
      "grad_norm": 1.4920742511749268,
      "learning_rate": 9.92289156626506e-06,
      "loss": 0.0445,
      "step": 41820
    },
    {
      "epoch": 5.039759036144578,
      "grad_norm": 0.790062427520752,
      "learning_rate": 9.920481927710844e-06,
      "loss": 0.0215,
      "step": 41830
    },
    {
      "epoch": 5.040963855421687,
      "grad_norm": 0.006761309690773487,
      "learning_rate": 9.918072289156627e-06,
      "loss": 0.0141,
      "step": 41840
    },
    {
      "epoch": 5.042168674698795,
      "grad_norm": 0.005736575927585363,
      "learning_rate": 9.91566265060241e-06,
      "loss": 0.0277,
      "step": 41850
    },
    {
      "epoch": 5.043373493975904,
      "grad_norm": 0.038829777389764786,
      "learning_rate": 9.913253012048193e-06,
      "loss": 0.0469,
      "step": 41860
    },
    {
      "epoch": 5.044578313253012,
      "grad_norm": 5.228818893432617,
      "learning_rate": 9.910843373493977e-06,
      "loss": 0.0528,
      "step": 41870
    },
    {
      "epoch": 5.04578313253012,
      "grad_norm": 1.479742169380188,
      "learning_rate": 9.90843373493976e-06,
      "loss": 0.0142,
      "step": 41880
    },
    {
      "epoch": 5.046987951807229,
      "grad_norm": 0.30996865034103394,
      "learning_rate": 9.906024096385543e-06,
      "loss": 0.0188,
      "step": 41890
    },
    {
      "epoch": 5.048192771084337,
      "grad_norm": 1.0092747211456299,
      "learning_rate": 9.903614457831326e-06,
      "loss": 0.0052,
      "step": 41900
    },
    {
      "epoch": 5.049397590361446,
      "grad_norm": 0.025223609060049057,
      "learning_rate": 9.90120481927711e-06,
      "loss": 0.0399,
      "step": 41910
    },
    {
      "epoch": 5.050602409638554,
      "grad_norm": 0.05547873303294182,
      "learning_rate": 9.898795180722893e-06,
      "loss": 0.005,
      "step": 41920
    },
    {
      "epoch": 5.051807228915663,
      "grad_norm": 0.6939021348953247,
      "learning_rate": 9.896385542168676e-06,
      "loss": 0.0299,
      "step": 41930
    },
    {
      "epoch": 5.053012048192771,
      "grad_norm": 0.015732549130916595,
      "learning_rate": 9.893975903614459e-06,
      "loss": 0.0402,
      "step": 41940
    },
    {
      "epoch": 5.054216867469879,
      "grad_norm": 15.831748962402344,
      "learning_rate": 9.891566265060242e-06,
      "loss": 0.0401,
      "step": 41950
    },
    {
      "epoch": 5.055421686746988,
      "grad_norm": 0.8293070793151855,
      "learning_rate": 9.889156626506025e-06,
      "loss": 0.0147,
      "step": 41960
    },
    {
      "epoch": 5.056626506024096,
      "grad_norm": 0.6477053761482239,
      "learning_rate": 9.886746987951808e-06,
      "loss": 0.0064,
      "step": 41970
    },
    {
      "epoch": 5.057831325301205,
      "grad_norm": 2.6507601737976074,
      "learning_rate": 9.884337349397592e-06,
      "loss": 0.0302,
      "step": 41980
    },
    {
      "epoch": 5.059036144578314,
      "grad_norm": 0.15715104341506958,
      "learning_rate": 9.881927710843375e-06,
      "loss": 0.0143,
      "step": 41990
    },
    {
      "epoch": 5.0602409638554215,
      "grad_norm": 0.9506611824035645,
      "learning_rate": 9.879518072289156e-06,
      "loss": 0.0612,
      "step": 42000
    },
    {
      "epoch": 5.06144578313253,
      "grad_norm": 0.008529857732355595,
      "learning_rate": 9.877108433734941e-06,
      "loss": 0.0105,
      "step": 42010
    },
    {
      "epoch": 5.062650602409638,
      "grad_norm": 0.7915846109390259,
      "learning_rate": 9.874698795180724e-06,
      "loss": 0.0148,
      "step": 42020
    },
    {
      "epoch": 5.063855421686747,
      "grad_norm": 8.34922981262207,
      "learning_rate": 9.872289156626507e-06,
      "loss": 0.0378,
      "step": 42030
    },
    {
      "epoch": 5.065060240963855,
      "grad_norm": 0.03393387794494629,
      "learning_rate": 9.869879518072289e-06,
      "loss": 0.0016,
      "step": 42040
    },
    {
      "epoch": 5.066265060240964,
      "grad_norm": 0.02865392342209816,
      "learning_rate": 9.867469879518074e-06,
      "loss": 0.0169,
      "step": 42050
    },
    {
      "epoch": 5.067469879518073,
      "grad_norm": 0.007711089216172695,
      "learning_rate": 9.865060240963857e-06,
      "loss": 0.0093,
      "step": 42060
    },
    {
      "epoch": 5.0686746987951805,
      "grad_norm": 0.1229056790471077,
      "learning_rate": 9.862650602409638e-06,
      "loss": 0.0274,
      "step": 42070
    },
    {
      "epoch": 5.069879518072289,
      "grad_norm": 0.00532585708424449,
      "learning_rate": 9.860240963855422e-06,
      "loss": 0.0242,
      "step": 42080
    },
    {
      "epoch": 5.071084337349397,
      "grad_norm": 25.6383113861084,
      "learning_rate": 9.857831325301207e-06,
      "loss": 0.0248,
      "step": 42090
    },
    {
      "epoch": 5.072289156626506,
      "grad_norm": 0.005090461112558842,
      "learning_rate": 9.855421686746988e-06,
      "loss": 0.0018,
      "step": 42100
    },
    {
      "epoch": 5.073493975903615,
      "grad_norm": 2.6630661487579346,
      "learning_rate": 9.853012048192771e-06,
      "loss": 0.0608,
      "step": 42110
    },
    {
      "epoch": 5.074698795180723,
      "grad_norm": 0.6951792240142822,
      "learning_rate": 9.850602409638556e-06,
      "loss": 0.0132,
      "step": 42120
    },
    {
      "epoch": 5.075903614457832,
      "grad_norm": 0.0033528630156069994,
      "learning_rate": 9.848192771084338e-06,
      "loss": 0.0322,
      "step": 42130
    },
    {
      "epoch": 5.0771084337349395,
      "grad_norm": 0.22677023708820343,
      "learning_rate": 9.84578313253012e-06,
      "loss": 0.0062,
      "step": 42140
    },
    {
      "epoch": 5.078313253012048,
      "grad_norm": 0.07779441028833389,
      "learning_rate": 9.843373493975904e-06,
      "loss": 0.0547,
      "step": 42150
    },
    {
      "epoch": 5.079518072289156,
      "grad_norm": 0.029039781540632248,
      "learning_rate": 9.840963855421689e-06,
      "loss": 0.0121,
      "step": 42160
    },
    {
      "epoch": 5.080722891566265,
      "grad_norm": 0.06751920282840729,
      "learning_rate": 9.83855421686747e-06,
      "loss": 0.0427,
      "step": 42170
    },
    {
      "epoch": 5.081927710843374,
      "grad_norm": 0.5144840478897095,
      "learning_rate": 9.836144578313253e-06,
      "loss": 0.0224,
      "step": 42180
    },
    {
      "epoch": 5.083132530120482,
      "grad_norm": 0.006364069413393736,
      "learning_rate": 9.833734939759037e-06,
      "loss": 0.0273,
      "step": 42190
    },
    {
      "epoch": 5.0843373493975905,
      "grad_norm": 1.088573694229126,
      "learning_rate": 9.83132530120482e-06,
      "loss": 0.0268,
      "step": 42200
    },
    {
      "epoch": 5.085542168674698,
      "grad_norm": 0.0033377311192452908,
      "learning_rate": 9.828915662650603e-06,
      "loss": 0.0253,
      "step": 42210
    },
    {
      "epoch": 5.086746987951807,
      "grad_norm": 3.538472890853882,
      "learning_rate": 9.826506024096386e-06,
      "loss": 0.0142,
      "step": 42220
    },
    {
      "epoch": 5.087951807228916,
      "grad_norm": 0.009302754886448383,
      "learning_rate": 9.82409638554217e-06,
      "loss": 0.0334,
      "step": 42230
    },
    {
      "epoch": 5.089156626506024,
      "grad_norm": 0.004188579972833395,
      "learning_rate": 9.821686746987952e-06,
      "loss": 0.0073,
      "step": 42240
    },
    {
      "epoch": 5.090361445783133,
      "grad_norm": 0.003877023234963417,
      "learning_rate": 9.819277108433736e-06,
      "loss": 0.0623,
      "step": 42250
    },
    {
      "epoch": 5.091566265060241,
      "grad_norm": 0.859402596950531,
      "learning_rate": 9.816867469879519e-06,
      "loss": 0.0274,
      "step": 42260
    },
    {
      "epoch": 5.0927710843373495,
      "grad_norm": 0.0028122286312282085,
      "learning_rate": 9.814457831325302e-06,
      "loss": 0.0238,
      "step": 42270
    },
    {
      "epoch": 5.093975903614457,
      "grad_norm": 7.088975429534912,
      "learning_rate": 9.812048192771085e-06,
      "loss": 0.0374,
      "step": 42280
    },
    {
      "epoch": 5.095180722891566,
      "grad_norm": 0.11315896362066269,
      "learning_rate": 9.809638554216868e-06,
      "loss": 0.0424,
      "step": 42290
    },
    {
      "epoch": 5.096385542168675,
      "grad_norm": 0.27555444836616516,
      "learning_rate": 9.807228915662652e-06,
      "loss": 0.0096,
      "step": 42300
    },
    {
      "epoch": 5.097590361445783,
      "grad_norm": 0.008557496592402458,
      "learning_rate": 9.804819277108435e-06,
      "loss": 0.0375,
      "step": 42310
    },
    {
      "epoch": 5.098795180722892,
      "grad_norm": 0.052130356431007385,
      "learning_rate": 9.802409638554218e-06,
      "loss": 0.0595,
      "step": 42320
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.851723551750183,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.003,
      "step": 42330
    },
    {
      "epoch": 5.1012048192771084,
      "grad_norm": 0.023094693198800087,
      "learning_rate": 9.797590361445784e-06,
      "loss": 0.0208,
      "step": 42340
    },
    {
      "epoch": 5.102409638554217,
      "grad_norm": 0.43875178694725037,
      "learning_rate": 9.795180722891567e-06,
      "loss": 0.0099,
      "step": 42350
    },
    {
      "epoch": 5.103614457831325,
      "grad_norm": 0.007990515790879726,
      "learning_rate": 9.79277108433735e-06,
      "loss": 0.0219,
      "step": 42360
    },
    {
      "epoch": 5.104819277108434,
      "grad_norm": 0.019867785274982452,
      "learning_rate": 9.790361445783134e-06,
      "loss": 0.0109,
      "step": 42370
    },
    {
      "epoch": 5.106024096385542,
      "grad_norm": 0.006154848728328943,
      "learning_rate": 9.787951807228915e-06,
      "loss": 0.0083,
      "step": 42380
    },
    {
      "epoch": 5.107228915662651,
      "grad_norm": 0.004315742291510105,
      "learning_rate": 9.7855421686747e-06,
      "loss": 0.0122,
      "step": 42390
    },
    {
      "epoch": 5.108433734939759,
      "grad_norm": 5.447930812835693,
      "learning_rate": 9.783132530120483e-06,
      "loss": 0.0616,
      "step": 42400
    },
    {
      "epoch": 5.109638554216867,
      "grad_norm": 5.269878387451172,
      "learning_rate": 9.780722891566265e-06,
      "loss": 0.0195,
      "step": 42410
    },
    {
      "epoch": 5.110843373493976,
      "grad_norm": 0.00811032671481371,
      "learning_rate": 9.77831325301205e-06,
      "loss": 0.0401,
      "step": 42420
    },
    {
      "epoch": 5.112048192771084,
      "grad_norm": 0.07031048089265823,
      "learning_rate": 9.775903614457833e-06,
      "loss": 0.0117,
      "step": 42430
    },
    {
      "epoch": 5.113253012048193,
      "grad_norm": 0.05056300014257431,
      "learning_rate": 9.773493975903616e-06,
      "loss": 0.0456,
      "step": 42440
    },
    {
      "epoch": 5.114457831325301,
      "grad_norm": 0.010755346156656742,
      "learning_rate": 9.771084337349397e-06,
      "loss": 0.0377,
      "step": 42450
    },
    {
      "epoch": 5.11566265060241,
      "grad_norm": 0.2585373520851135,
      "learning_rate": 9.768674698795182e-06,
      "loss": 0.0127,
      "step": 42460
    },
    {
      "epoch": 5.1168674698795185,
      "grad_norm": 1.6892894506454468,
      "learning_rate": 9.766265060240966e-06,
      "loss": 0.0462,
      "step": 42470
    },
    {
      "epoch": 5.118072289156626,
      "grad_norm": 0.015845071524381638,
      "learning_rate": 9.763855421686747e-06,
      "loss": 0.0075,
      "step": 42480
    },
    {
      "epoch": 5.119277108433735,
      "grad_norm": 1.3525385856628418,
      "learning_rate": 9.76144578313253e-06,
      "loss": 0.0381,
      "step": 42490
    },
    {
      "epoch": 5.120481927710843,
      "grad_norm": 0.15363407135009766,
      "learning_rate": 9.759036144578315e-06,
      "loss": 0.0134,
      "step": 42500
    },
    {
      "epoch": 5.121686746987952,
      "grad_norm": 5.565991401672363,
      "learning_rate": 9.756626506024097e-06,
      "loss": 0.0509,
      "step": 42510
    },
    {
      "epoch": 5.12289156626506,
      "grad_norm": 1.7608593702316284,
      "learning_rate": 9.75421686746988e-06,
      "loss": 0.0554,
      "step": 42520
    },
    {
      "epoch": 5.124096385542169,
      "grad_norm": 0.018685320392251015,
      "learning_rate": 9.751807228915663e-06,
      "loss": 0.0287,
      "step": 42530
    },
    {
      "epoch": 5.125301204819277,
      "grad_norm": 116.3074951171875,
      "learning_rate": 9.749397590361446e-06,
      "loss": 0.0546,
      "step": 42540
    },
    {
      "epoch": 5.126506024096385,
      "grad_norm": 1.784742832183838,
      "learning_rate": 9.74698795180723e-06,
      "loss": 0.0181,
      "step": 42550
    },
    {
      "epoch": 5.127710843373494,
      "grad_norm": 0.0061001405119895935,
      "learning_rate": 9.744578313253012e-06,
      "loss": 0.0807,
      "step": 42560
    },
    {
      "epoch": 5.128915662650602,
      "grad_norm": 0.032747820019721985,
      "learning_rate": 9.742168674698797e-06,
      "loss": 0.0327,
      "step": 42570
    },
    {
      "epoch": 5.130120481927711,
      "grad_norm": 0.01580571010708809,
      "learning_rate": 9.739759036144579e-06,
      "loss": 0.0372,
      "step": 42580
    },
    {
      "epoch": 5.13132530120482,
      "grad_norm": 3.1565420627593994,
      "learning_rate": 9.737349397590362e-06,
      "loss": 0.0177,
      "step": 42590
    },
    {
      "epoch": 5.132530120481928,
      "grad_norm": 0.012080691754817963,
      "learning_rate": 9.734939759036145e-06,
      "loss": 0.0149,
      "step": 42600
    },
    {
      "epoch": 5.133734939759036,
      "grad_norm": 0.6170157194137573,
      "learning_rate": 9.732530120481928e-06,
      "loss": 0.0129,
      "step": 42610
    },
    {
      "epoch": 5.134939759036144,
      "grad_norm": 1.5905444622039795,
      "learning_rate": 9.730120481927711e-06,
      "loss": 0.0164,
      "step": 42620
    },
    {
      "epoch": 5.136144578313253,
      "grad_norm": 0.008569291792809963,
      "learning_rate": 9.727710843373495e-06,
      "loss": 0.0455,
      "step": 42630
    },
    {
      "epoch": 5.137349397590361,
      "grad_norm": 0.03987284004688263,
      "learning_rate": 9.725301204819278e-06,
      "loss": 0.0052,
      "step": 42640
    },
    {
      "epoch": 5.13855421686747,
      "grad_norm": 1.7647147178649902,
      "learning_rate": 9.722891566265061e-06,
      "loss": 0.0182,
      "step": 42650
    },
    {
      "epoch": 5.139759036144579,
      "grad_norm": 0.0069499546661973,
      "learning_rate": 9.720481927710844e-06,
      "loss": 0.0111,
      "step": 42660
    },
    {
      "epoch": 5.1409638554216865,
      "grad_norm": 0.10308363288640976,
      "learning_rate": 9.718072289156627e-06,
      "loss": 0.0208,
      "step": 42670
    },
    {
      "epoch": 5.142168674698795,
      "grad_norm": 0.07604292035102844,
      "learning_rate": 9.71566265060241e-06,
      "loss": 0.0162,
      "step": 42680
    },
    {
      "epoch": 5.143373493975903,
      "grad_norm": 0.0036455325316637754,
      "learning_rate": 9.713253012048194e-06,
      "loss": 0.0216,
      "step": 42690
    },
    {
      "epoch": 5.144578313253012,
      "grad_norm": 0.011591499671339989,
      "learning_rate": 9.710843373493977e-06,
      "loss": 0.0162,
      "step": 42700
    },
    {
      "epoch": 5.145783132530121,
      "grad_norm": 0.019948719069361687,
      "learning_rate": 9.70843373493976e-06,
      "loss": 0.0137,
      "step": 42710
    },
    {
      "epoch": 5.146987951807229,
      "grad_norm": 0.22282470762729645,
      "learning_rate": 9.706024096385543e-06,
      "loss": 0.0049,
      "step": 42720
    },
    {
      "epoch": 5.148192771084338,
      "grad_norm": 0.002754747634753585,
      "learning_rate": 9.703614457831326e-06,
      "loss": 0.0136,
      "step": 42730
    },
    {
      "epoch": 5.1493975903614455,
      "grad_norm": 0.795985996723175,
      "learning_rate": 9.70120481927711e-06,
      "loss": 0.0833,
      "step": 42740
    },
    {
      "epoch": 5.150602409638554,
      "grad_norm": 0.11785706877708435,
      "learning_rate": 9.698795180722893e-06,
      "loss": 0.0135,
      "step": 42750
    },
    {
      "epoch": 5.151807228915662,
      "grad_norm": 0.3530876040458679,
      "learning_rate": 9.696385542168676e-06,
      "loss": 0.0183,
      "step": 42760
    },
    {
      "epoch": 5.153012048192771,
      "grad_norm": 0.6286580562591553,
      "learning_rate": 9.693975903614459e-06,
      "loss": 0.0199,
      "step": 42770
    },
    {
      "epoch": 5.15421686746988,
      "grad_norm": 0.6715865135192871,
      "learning_rate": 9.691566265060242e-06,
      "loss": 0.0353,
      "step": 42780
    },
    {
      "epoch": 5.155421686746988,
      "grad_norm": 0.6436996459960938,
      "learning_rate": 9.689156626506024e-06,
      "loss": 0.0104,
      "step": 42790
    },
    {
      "epoch": 5.156626506024097,
      "grad_norm": 0.006849740631878376,
      "learning_rate": 9.686746987951809e-06,
      "loss": 0.0011,
      "step": 42800
    },
    {
      "epoch": 5.1578313253012045,
      "grad_norm": 0.005247713997960091,
      "learning_rate": 9.684337349397592e-06,
      "loss": 0.0026,
      "step": 42810
    },
    {
      "epoch": 5.159036144578313,
      "grad_norm": 0.011225824244320393,
      "learning_rate": 9.681927710843373e-06,
      "loss": 0.0206,
      "step": 42820
    },
    {
      "epoch": 5.160240963855422,
      "grad_norm": 0.09056559950113297,
      "learning_rate": 9.679518072289158e-06,
      "loss": 0.053,
      "step": 42830
    },
    {
      "epoch": 5.16144578313253,
      "grad_norm": 1.2827937602996826,
      "learning_rate": 9.677108433734941e-06,
      "loss": 0.0293,
      "step": 42840
    },
    {
      "epoch": 5.162650602409639,
      "grad_norm": 0.9392878413200378,
      "learning_rate": 9.674698795180723e-06,
      "loss": 0.0301,
      "step": 42850
    },
    {
      "epoch": 5.163855421686747,
      "grad_norm": 0.3307225704193115,
      "learning_rate": 9.672289156626506e-06,
      "loss": 0.0071,
      "step": 42860
    },
    {
      "epoch": 5.1650602409638555,
      "grad_norm": 1.3154014348983765,
      "learning_rate": 9.669879518072291e-06,
      "loss": 0.0147,
      "step": 42870
    },
    {
      "epoch": 5.166265060240963,
      "grad_norm": 0.02504049614071846,
      "learning_rate": 9.667469879518074e-06,
      "loss": 0.0232,
      "step": 42880
    },
    {
      "epoch": 5.167469879518072,
      "grad_norm": 0.007061651907861233,
      "learning_rate": 9.665060240963856e-06,
      "loss": 0.0312,
      "step": 42890
    },
    {
      "epoch": 5.168674698795181,
      "grad_norm": 0.012339383363723755,
      "learning_rate": 9.662650602409639e-06,
      "loss": 0.0244,
      "step": 42900
    },
    {
      "epoch": 5.169879518072289,
      "grad_norm": 7.351019382476807,
      "learning_rate": 9.660240963855424e-06,
      "loss": 0.0652,
      "step": 42910
    },
    {
      "epoch": 5.171084337349398,
      "grad_norm": 0.004425174091011286,
      "learning_rate": 9.657831325301205e-06,
      "loss": 0.017,
      "step": 42920
    },
    {
      "epoch": 5.172289156626506,
      "grad_norm": 0.12446320056915283,
      "learning_rate": 9.655421686746988e-06,
      "loss": 0.0356,
      "step": 42930
    },
    {
      "epoch": 5.1734939759036145,
      "grad_norm": 4.984837532043457,
      "learning_rate": 9.653012048192771e-06,
      "loss": 0.0515,
      "step": 42940
    },
    {
      "epoch": 5.174698795180723,
      "grad_norm": 1.261526346206665,
      "learning_rate": 9.650602409638555e-06,
      "loss": 0.0179,
      "step": 42950
    },
    {
      "epoch": 5.175903614457831,
      "grad_norm": 1.44370436668396,
      "learning_rate": 9.648192771084338e-06,
      "loss": 0.039,
      "step": 42960
    },
    {
      "epoch": 5.17710843373494,
      "grad_norm": 0.05320831015706062,
      "learning_rate": 9.645783132530121e-06,
      "loss": 0.03,
      "step": 42970
    },
    {
      "epoch": 5.178313253012048,
      "grad_norm": 3.20871901512146,
      "learning_rate": 9.643373493975906e-06,
      "loss": 0.0188,
      "step": 42980
    },
    {
      "epoch": 5.179518072289157,
      "grad_norm": 0.5241842865943909,
      "learning_rate": 9.640963855421687e-06,
      "loss": 0.0341,
      "step": 42990
    },
    {
      "epoch": 5.180722891566265,
      "grad_norm": 0.007331097964197397,
      "learning_rate": 9.63855421686747e-06,
      "loss": 0.0247,
      "step": 43000
    },
    {
      "epoch": 5.1819277108433734,
      "grad_norm": 0.010846743360161781,
      "learning_rate": 9.636144578313254e-06,
      "loss": 0.0675,
      "step": 43010
    },
    {
      "epoch": 5.183132530120482,
      "grad_norm": 1.7169617414474487,
      "learning_rate": 9.633734939759037e-06,
      "loss": 0.0248,
      "step": 43020
    },
    {
      "epoch": 5.18433734939759,
      "grad_norm": 0.08412434905767441,
      "learning_rate": 9.63132530120482e-06,
      "loss": 0.0101,
      "step": 43030
    },
    {
      "epoch": 5.185542168674699,
      "grad_norm": 0.01708722859621048,
      "learning_rate": 9.628915662650603e-06,
      "loss": 0.0129,
      "step": 43040
    },
    {
      "epoch": 5.186746987951807,
      "grad_norm": 0.007921054027974606,
      "learning_rate": 9.626506024096386e-06,
      "loss": 0.0064,
      "step": 43050
    },
    {
      "epoch": 5.187951807228916,
      "grad_norm": 0.005472182296216488,
      "learning_rate": 9.62409638554217e-06,
      "loss": 0.0139,
      "step": 43060
    },
    {
      "epoch": 5.1891566265060245,
      "grad_norm": 0.004346457775682211,
      "learning_rate": 9.621686746987953e-06,
      "loss": 0.0195,
      "step": 43070
    },
    {
      "epoch": 5.190361445783132,
      "grad_norm": 0.005531643982976675,
      "learning_rate": 9.619277108433736e-06,
      "loss": 0.0085,
      "step": 43080
    },
    {
      "epoch": 5.191566265060241,
      "grad_norm": 1.1007119417190552,
      "learning_rate": 9.616867469879519e-06,
      "loss": 0.0041,
      "step": 43090
    },
    {
      "epoch": 5.192771084337349,
      "grad_norm": 0.5239185690879822,
      "learning_rate": 9.614457831325302e-06,
      "loss": 0.0094,
      "step": 43100
    },
    {
      "epoch": 5.193975903614458,
      "grad_norm": 6.91485595703125,
      "learning_rate": 9.612048192771085e-06,
      "loss": 0.0361,
      "step": 43110
    },
    {
      "epoch": 5.195180722891566,
      "grad_norm": 0.1082189604640007,
      "learning_rate": 9.609638554216869e-06,
      "loss": 0.01,
      "step": 43120
    },
    {
      "epoch": 5.196385542168675,
      "grad_norm": 0.005591853987425566,
      "learning_rate": 9.607228915662652e-06,
      "loss": 0.0131,
      "step": 43130
    },
    {
      "epoch": 5.1975903614457835,
      "grad_norm": 0.13000786304473877,
      "learning_rate": 9.604819277108435e-06,
      "loss": 0.0104,
      "step": 43140
    },
    {
      "epoch": 5.198795180722891,
      "grad_norm": 0.013221684843301773,
      "learning_rate": 9.602409638554218e-06,
      "loss": 0.0162,
      "step": 43150
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.5976817607879639,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0081,
      "step": 43160
    },
    {
      "epoch": 5.201204819277108,
      "grad_norm": 3.368889570236206,
      "learning_rate": 9.597590361445784e-06,
      "loss": 0.0244,
      "step": 43170
    },
    {
      "epoch": 5.202409638554217,
      "grad_norm": 0.016240039840340614,
      "learning_rate": 9.595180722891568e-06,
      "loss": 0.0449,
      "step": 43180
    },
    {
      "epoch": 5.203614457831326,
      "grad_norm": 0.006844144314527512,
      "learning_rate": 9.59277108433735e-06,
      "loss": 0.0432,
      "step": 43190
    },
    {
      "epoch": 5.204819277108434,
      "grad_norm": 0.0060484763234853745,
      "learning_rate": 9.590361445783132e-06,
      "loss": 0.0041,
      "step": 43200
    },
    {
      "epoch": 5.206024096385542,
      "grad_norm": 0.0023534102365374565,
      "learning_rate": 9.587951807228917e-06,
      "loss": 0.0169,
      "step": 43210
    },
    {
      "epoch": 5.20722891566265,
      "grad_norm": 9.067261695861816,
      "learning_rate": 9.5855421686747e-06,
      "loss": 0.0422,
      "step": 43220
    },
    {
      "epoch": 5.208433734939759,
      "grad_norm": 0.024864457547664642,
      "learning_rate": 9.583132530120482e-06,
      "loss": 0.017,
      "step": 43230
    },
    {
      "epoch": 5.209638554216867,
      "grad_norm": 0.004049330949783325,
      "learning_rate": 9.580722891566265e-06,
      "loss": 0.0169,
      "step": 43240
    },
    {
      "epoch": 5.210843373493976,
      "grad_norm": 0.29654988646507263,
      "learning_rate": 9.57831325301205e-06,
      "loss": 0.0152,
      "step": 43250
    },
    {
      "epoch": 5.212048192771085,
      "grad_norm": 0.002858720952644944,
      "learning_rate": 9.575903614457831e-06,
      "loss": 0.0273,
      "step": 43260
    },
    {
      "epoch": 5.213253012048193,
      "grad_norm": 262.26593017578125,
      "learning_rate": 9.573493975903615e-06,
      "loss": 0.0885,
      "step": 43270
    },
    {
      "epoch": 5.214457831325301,
      "grad_norm": 0.07987861335277557,
      "learning_rate": 9.5710843373494e-06,
      "loss": 0.0266,
      "step": 43280
    },
    {
      "epoch": 5.215662650602409,
      "grad_norm": 4.962990760803223,
      "learning_rate": 9.568674698795183e-06,
      "loss": 0.0361,
      "step": 43290
    },
    {
      "epoch": 5.216867469879518,
      "grad_norm": 0.00712039228528738,
      "learning_rate": 9.566265060240964e-06,
      "loss": 0.0105,
      "step": 43300
    },
    {
      "epoch": 5.218072289156627,
      "grad_norm": 0.7539235353469849,
      "learning_rate": 9.563855421686747e-06,
      "loss": 0.0164,
      "step": 43310
    },
    {
      "epoch": 5.219277108433735,
      "grad_norm": 0.9562445282936096,
      "learning_rate": 9.561445783132532e-06,
      "loss": 0.0076,
      "step": 43320
    },
    {
      "epoch": 5.220481927710844,
      "grad_norm": 0.004109975416213274,
      "learning_rate": 9.559036144578314e-06,
      "loss": 0.009,
      "step": 43330
    },
    {
      "epoch": 5.2216867469879515,
      "grad_norm": 0.0025572229642421007,
      "learning_rate": 9.556626506024097e-06,
      "loss": 0.0076,
      "step": 43340
    },
    {
      "epoch": 5.22289156626506,
      "grad_norm": 0.3105354309082031,
      "learning_rate": 9.55421686746988e-06,
      "loss": 0.1214,
      "step": 43350
    },
    {
      "epoch": 5.224096385542168,
      "grad_norm": 0.008352141827344894,
      "learning_rate": 9.551807228915663e-06,
      "loss": 0.0357,
      "step": 43360
    },
    {
      "epoch": 5.225301204819277,
      "grad_norm": 0.007828470319509506,
      "learning_rate": 9.549397590361446e-06,
      "loss": 0.0083,
      "step": 43370
    },
    {
      "epoch": 5.226506024096386,
      "grad_norm": 0.08746657520532608,
      "learning_rate": 9.54698795180723e-06,
      "loss": 0.0141,
      "step": 43380
    },
    {
      "epoch": 5.227710843373494,
      "grad_norm": 10.919997215270996,
      "learning_rate": 9.544578313253013e-06,
      "loss": 0.0235,
      "step": 43390
    },
    {
      "epoch": 5.228915662650603,
      "grad_norm": 0.11209987848997116,
      "learning_rate": 9.542168674698796e-06,
      "loss": 0.0041,
      "step": 43400
    },
    {
      "epoch": 5.2301204819277105,
      "grad_norm": 3.473464012145996,
      "learning_rate": 9.539759036144579e-06,
      "loss": 0.0057,
      "step": 43410
    },
    {
      "epoch": 5.231325301204819,
      "grad_norm": 2.1561279296875,
      "learning_rate": 9.537349397590362e-06,
      "loss": 0.0425,
      "step": 43420
    },
    {
      "epoch": 5.232530120481928,
      "grad_norm": 0.012916424311697483,
      "learning_rate": 9.534939759036145e-06,
      "loss": 0.0167,
      "step": 43430
    },
    {
      "epoch": 5.233734939759036,
      "grad_norm": 0.07674287259578705,
      "learning_rate": 9.532530120481928e-06,
      "loss": 0.0109,
      "step": 43440
    },
    {
      "epoch": 5.234939759036145,
      "grad_norm": 21.903871536254883,
      "learning_rate": 9.530120481927712e-06,
      "loss": 0.0398,
      "step": 43450
    },
    {
      "epoch": 5.236144578313253,
      "grad_norm": 2.321713447570801,
      "learning_rate": 9.527710843373495e-06,
      "loss": 0.0525,
      "step": 43460
    },
    {
      "epoch": 5.2373493975903616,
      "grad_norm": 0.1291770040988922,
      "learning_rate": 9.525301204819278e-06,
      "loss": 0.0011,
      "step": 43470
    },
    {
      "epoch": 5.2385542168674695,
      "grad_norm": 0.0046464670449495316,
      "learning_rate": 9.522891566265061e-06,
      "loss": 0.0125,
      "step": 43480
    },
    {
      "epoch": 5.239759036144578,
      "grad_norm": 0.005789469927549362,
      "learning_rate": 9.520481927710844e-06,
      "loss": 0.0449,
      "step": 43490
    },
    {
      "epoch": 5.240963855421687,
      "grad_norm": 0.0037691709585487843,
      "learning_rate": 9.518072289156628e-06,
      "loss": 0.0047,
      "step": 43500
    },
    {
      "epoch": 5.242168674698795,
      "grad_norm": 0.0024003179278224707,
      "learning_rate": 9.51566265060241e-06,
      "loss": 0.0427,
      "step": 43510
    },
    {
      "epoch": 5.243373493975904,
      "grad_norm": 2.060988187789917,
      "learning_rate": 9.513253012048194e-06,
      "loss": 0.0177,
      "step": 43520
    },
    {
      "epoch": 5.244578313253012,
      "grad_norm": 0.022795114666223526,
      "learning_rate": 9.510843373493977e-06,
      "loss": 0.0077,
      "step": 43530
    },
    {
      "epoch": 5.2457831325301205,
      "grad_norm": 53.56103515625,
      "learning_rate": 9.508433734939759e-06,
      "loss": 0.0167,
      "step": 43540
    },
    {
      "epoch": 5.246987951807229,
      "grad_norm": 0.0018398140091449022,
      "learning_rate": 9.506024096385543e-06,
      "loss": 0.0118,
      "step": 43550
    },
    {
      "epoch": 5.248192771084337,
      "grad_norm": 3.9888229370117188,
      "learning_rate": 9.503614457831327e-06,
      "loss": 0.0219,
      "step": 43560
    },
    {
      "epoch": 5.249397590361446,
      "grad_norm": 0.006753083784133196,
      "learning_rate": 9.501204819277108e-06,
      "loss": 0.0511,
      "step": 43570
    },
    {
      "epoch": 5.250602409638554,
      "grad_norm": 0.005405859090387821,
      "learning_rate": 9.498795180722893e-06,
      "loss": 0.0004,
      "step": 43580
    },
    {
      "epoch": 5.251807228915663,
      "grad_norm": 0.035602349787950516,
      "learning_rate": 9.496385542168676e-06,
      "loss": 0.0049,
      "step": 43590
    },
    {
      "epoch": 5.253012048192771,
      "grad_norm": 1.3536500930786133,
      "learning_rate": 9.49397590361446e-06,
      "loss": 0.0352,
      "step": 43600
    },
    {
      "epoch": 5.2542168674698795,
      "grad_norm": 0.004717216826975346,
      "learning_rate": 9.49156626506024e-06,
      "loss": 0.0117,
      "step": 43610
    },
    {
      "epoch": 5.255421686746988,
      "grad_norm": 2.353787422180176,
      "learning_rate": 9.489156626506026e-06,
      "loss": 0.0256,
      "step": 43620
    },
    {
      "epoch": 5.256626506024096,
      "grad_norm": 0.010577576234936714,
      "learning_rate": 9.486746987951809e-06,
      "loss": 0.0124,
      "step": 43630
    },
    {
      "epoch": 5.257831325301205,
      "grad_norm": 0.009531970135867596,
      "learning_rate": 9.48433734939759e-06,
      "loss": 0.0391,
      "step": 43640
    },
    {
      "epoch": 5.259036144578313,
      "grad_norm": 0.006216704845428467,
      "learning_rate": 9.481927710843373e-06,
      "loss": 0.0008,
      "step": 43650
    },
    {
      "epoch": 5.260240963855422,
      "grad_norm": 0.22413890063762665,
      "learning_rate": 9.479518072289158e-06,
      "loss": 0.0722,
      "step": 43660
    },
    {
      "epoch": 5.2614457831325305,
      "grad_norm": 0.018699554726481438,
      "learning_rate": 9.47710843373494e-06,
      "loss": 0.0099,
      "step": 43670
    },
    {
      "epoch": 5.2626506024096384,
      "grad_norm": 0.2598089575767517,
      "learning_rate": 9.474698795180723e-06,
      "loss": 0.0192,
      "step": 43680
    },
    {
      "epoch": 5.263855421686747,
      "grad_norm": 0.004744451958686113,
      "learning_rate": 9.472289156626506e-06,
      "loss": 0.0392,
      "step": 43690
    },
    {
      "epoch": 5.265060240963855,
      "grad_norm": 0.038989078253507614,
      "learning_rate": 9.46987951807229e-06,
      "loss": 0.0844,
      "step": 43700
    },
    {
      "epoch": 5.266265060240964,
      "grad_norm": 0.1670101135969162,
      "learning_rate": 9.467469879518073e-06,
      "loss": 0.0106,
      "step": 43710
    },
    {
      "epoch": 5.267469879518072,
      "grad_norm": 0.38858553767204285,
      "learning_rate": 9.465060240963856e-06,
      "loss": 0.0085,
      "step": 43720
    },
    {
      "epoch": 5.268674698795181,
      "grad_norm": 0.008493863977491856,
      "learning_rate": 9.46265060240964e-06,
      "loss": 0.0117,
      "step": 43730
    },
    {
      "epoch": 5.2698795180722895,
      "grad_norm": 0.32531481981277466,
      "learning_rate": 9.460240963855422e-06,
      "loss": 0.0233,
      "step": 43740
    },
    {
      "epoch": 5.271084337349397,
      "grad_norm": 0.026114484295248985,
      "learning_rate": 9.457831325301205e-06,
      "loss": 0.0007,
      "step": 43750
    },
    {
      "epoch": 5.272289156626506,
      "grad_norm": 0.004866410046815872,
      "learning_rate": 9.455421686746988e-06,
      "loss": 0.0413,
      "step": 43760
    },
    {
      "epoch": 5.273493975903614,
      "grad_norm": 0.04916875436902046,
      "learning_rate": 9.453012048192772e-06,
      "loss": 0.0018,
      "step": 43770
    },
    {
      "epoch": 5.274698795180723,
      "grad_norm": 0.06761151552200317,
      "learning_rate": 9.450602409638555e-06,
      "loss": 0.0195,
      "step": 43780
    },
    {
      "epoch": 5.275903614457832,
      "grad_norm": 0.03914631903171539,
      "learning_rate": 9.448192771084338e-06,
      "loss": 0.0377,
      "step": 43790
    },
    {
      "epoch": 5.27710843373494,
      "grad_norm": 0.28015074133872986,
      "learning_rate": 9.445783132530121e-06,
      "loss": 0.0126,
      "step": 43800
    },
    {
      "epoch": 5.2783132530120485,
      "grad_norm": 0.007392609491944313,
      "learning_rate": 9.443373493975904e-06,
      "loss": 0.0113,
      "step": 43810
    },
    {
      "epoch": 5.279518072289156,
      "grad_norm": 0.033701904118061066,
      "learning_rate": 9.440963855421687e-06,
      "loss": 0.0143,
      "step": 43820
    },
    {
      "epoch": 5.280722891566265,
      "grad_norm": 58.380096435546875,
      "learning_rate": 9.43855421686747e-06,
      "loss": 0.0221,
      "step": 43830
    },
    {
      "epoch": 5.281927710843373,
      "grad_norm": 0.012346388772130013,
      "learning_rate": 9.436144578313254e-06,
      "loss": 0.011,
      "step": 43840
    },
    {
      "epoch": 5.283132530120482,
      "grad_norm": 1.455954670906067,
      "learning_rate": 9.433734939759037e-06,
      "loss": 0.0108,
      "step": 43850
    },
    {
      "epoch": 5.284337349397591,
      "grad_norm": 16.533893585205078,
      "learning_rate": 9.43132530120482e-06,
      "loss": 0.0225,
      "step": 43860
    },
    {
      "epoch": 5.285542168674699,
      "grad_norm": 0.017079820856451988,
      "learning_rate": 9.428915662650603e-06,
      "loss": 0.0305,
      "step": 43870
    },
    {
      "epoch": 5.286746987951807,
      "grad_norm": 0.33970528841018677,
      "learning_rate": 9.426506024096387e-06,
      "loss": 0.0337,
      "step": 43880
    },
    {
      "epoch": 5.287951807228915,
      "grad_norm": 0.01840255595743656,
      "learning_rate": 9.42409638554217e-06,
      "loss": 0.0019,
      "step": 43890
    },
    {
      "epoch": 5.289156626506024,
      "grad_norm": 0.01365478802472353,
      "learning_rate": 9.421686746987953e-06,
      "loss": 0.01,
      "step": 43900
    },
    {
      "epoch": 5.290361445783133,
      "grad_norm": 19.39238739013672,
      "learning_rate": 9.419277108433736e-06,
      "loss": 0.0317,
      "step": 43910
    },
    {
      "epoch": 5.291566265060241,
      "grad_norm": 2.1196908950805664,
      "learning_rate": 9.41686746987952e-06,
      "loss": 0.0366,
      "step": 43920
    },
    {
      "epoch": 5.29277108433735,
      "grad_norm": 0.04654312878847122,
      "learning_rate": 9.414457831325302e-06,
      "loss": 0.034,
      "step": 43930
    },
    {
      "epoch": 5.293975903614458,
      "grad_norm": 0.29319289326667786,
      "learning_rate": 9.412048192771086e-06,
      "loss": 0.0269,
      "step": 43940
    },
    {
      "epoch": 5.295180722891566,
      "grad_norm": 0.056042175740003586,
      "learning_rate": 9.409638554216867e-06,
      "loss": 0.0153,
      "step": 43950
    },
    {
      "epoch": 5.296385542168674,
      "grad_norm": 0.026958903297781944,
      "learning_rate": 9.407228915662652e-06,
      "loss": 0.0515,
      "step": 43960
    },
    {
      "epoch": 5.297590361445783,
      "grad_norm": 1.7446969747543335,
      "learning_rate": 9.404819277108435e-06,
      "loss": 0.0148,
      "step": 43970
    },
    {
      "epoch": 5.298795180722892,
      "grad_norm": 7.512166500091553,
      "learning_rate": 9.402409638554217e-06,
      "loss": 0.0425,
      "step": 43980
    },
    {
      "epoch": 5.3,
      "grad_norm": 2.1904056072235107,
      "learning_rate": 9.4e-06,
      "loss": 0.0106,
      "step": 43990
    },
    {
      "epoch": 5.301204819277109,
      "grad_norm": 0.007554210722446442,
      "learning_rate": 9.397590361445785e-06,
      "loss": 0.012,
      "step": 44000
    },
    {
      "epoch": 5.3024096385542165,
      "grad_norm": 14.119180679321289,
      "learning_rate": 9.395180722891568e-06,
      "loss": 0.019,
      "step": 44010
    },
    {
      "epoch": 5.303614457831325,
      "grad_norm": 0.12329057604074478,
      "learning_rate": 9.39277108433735e-06,
      "loss": 0.0125,
      "step": 44020
    },
    {
      "epoch": 5.304819277108434,
      "grad_norm": 279.8676452636719,
      "learning_rate": 9.390361445783134e-06,
      "loss": 0.0385,
      "step": 44030
    },
    {
      "epoch": 5.306024096385542,
      "grad_norm": 0.004833674989640713,
      "learning_rate": 9.387951807228917e-06,
      "loss": 0.021,
      "step": 44040
    },
    {
      "epoch": 5.307228915662651,
      "grad_norm": 1.4980608224868774,
      "learning_rate": 9.385542168674699e-06,
      "loss": 0.0384,
      "step": 44050
    },
    {
      "epoch": 5.308433734939759,
      "grad_norm": 0.007616071961820126,
      "learning_rate": 9.383132530120482e-06,
      "loss": 0.0145,
      "step": 44060
    },
    {
      "epoch": 5.309638554216868,
      "grad_norm": 5.294997692108154,
      "learning_rate": 9.380722891566267e-06,
      "loss": 0.0332,
      "step": 44070
    },
    {
      "epoch": 5.3108433734939755,
      "grad_norm": 0.004255346488207579,
      "learning_rate": 9.378313253012048e-06,
      "loss": 0.001,
      "step": 44080
    },
    {
      "epoch": 5.312048192771084,
      "grad_norm": 0.7960892915725708,
      "learning_rate": 9.375903614457832e-06,
      "loss": 0.0139,
      "step": 44090
    },
    {
      "epoch": 5.313253012048193,
      "grad_norm": 0.4395255744457245,
      "learning_rate": 9.373493975903615e-06,
      "loss": 0.0167,
      "step": 44100
    },
    {
      "epoch": 5.314457831325301,
      "grad_norm": 0.2528696358203888,
      "learning_rate": 9.371084337349398e-06,
      "loss": 0.0271,
      "step": 44110
    },
    {
      "epoch": 5.31566265060241,
      "grad_norm": 2.195584774017334,
      "learning_rate": 9.368674698795181e-06,
      "loss": 0.056,
      "step": 44120
    },
    {
      "epoch": 5.316867469879518,
      "grad_norm": 0.023471510037779808,
      "learning_rate": 9.366265060240964e-06,
      "loss": 0.0086,
      "step": 44130
    },
    {
      "epoch": 5.3180722891566266,
      "grad_norm": 1.0815978050231934,
      "learning_rate": 9.363855421686747e-06,
      "loss": 0.0169,
      "step": 44140
    },
    {
      "epoch": 5.3192771084337345,
      "grad_norm": 0.005457122810184956,
      "learning_rate": 9.36144578313253e-06,
      "loss": 0.0209,
      "step": 44150
    },
    {
      "epoch": 5.320481927710843,
      "grad_norm": 6.880141735076904,
      "learning_rate": 9.359036144578314e-06,
      "loss": 0.0402,
      "step": 44160
    },
    {
      "epoch": 5.321686746987952,
      "grad_norm": 0.00290405610576272,
      "learning_rate": 9.356626506024097e-06,
      "loss": 0.036,
      "step": 44170
    },
    {
      "epoch": 5.32289156626506,
      "grad_norm": 0.0044164881110191345,
      "learning_rate": 9.35421686746988e-06,
      "loss": 0.0223,
      "step": 44180
    },
    {
      "epoch": 5.324096385542169,
      "grad_norm": 0.005429635755717754,
      "learning_rate": 9.351807228915663e-06,
      "loss": 0.0114,
      "step": 44190
    },
    {
      "epoch": 5.325301204819277,
      "grad_norm": 1.8464430570602417,
      "learning_rate": 9.349397590361446e-06,
      "loss": 0.0728,
      "step": 44200
    },
    {
      "epoch": 5.3265060240963855,
      "grad_norm": 0.023185424506664276,
      "learning_rate": 9.34698795180723e-06,
      "loss": 0.03,
      "step": 44210
    },
    {
      "epoch": 5.327710843373494,
      "grad_norm": 0.0016795238479971886,
      "learning_rate": 9.344578313253013e-06,
      "loss": 0.0201,
      "step": 44220
    },
    {
      "epoch": 5.328915662650602,
      "grad_norm": 0.020891189575195312,
      "learning_rate": 9.342168674698796e-06,
      "loss": 0.0353,
      "step": 44230
    },
    {
      "epoch": 5.330120481927711,
      "grad_norm": 2.0682482719421387,
      "learning_rate": 9.33975903614458e-06,
      "loss": 0.024,
      "step": 44240
    },
    {
      "epoch": 5.331325301204819,
      "grad_norm": 0.3009333908557892,
      "learning_rate": 9.337349397590362e-06,
      "loss": 0.007,
      "step": 44250
    },
    {
      "epoch": 5.332530120481928,
      "grad_norm": 0.02233256585896015,
      "learning_rate": 9.334939759036146e-06,
      "loss": 0.001,
      "step": 44260
    },
    {
      "epoch": 5.333734939759037,
      "grad_norm": 0.7923492789268494,
      "learning_rate": 9.332530120481929e-06,
      "loss": 0.0372,
      "step": 44270
    },
    {
      "epoch": 5.3349397590361445,
      "grad_norm": 0.8564352989196777,
      "learning_rate": 9.330120481927712e-06,
      "loss": 0.0026,
      "step": 44280
    },
    {
      "epoch": 5.336144578313253,
      "grad_norm": 0.0037289545871317387,
      "learning_rate": 9.327710843373493e-06,
      "loss": 0.0032,
      "step": 44290
    },
    {
      "epoch": 5.337349397590361,
      "grad_norm": 2.1211917400360107,
      "learning_rate": 9.325301204819278e-06,
      "loss": 0.0351,
      "step": 44300
    },
    {
      "epoch": 5.33855421686747,
      "grad_norm": 3.701810598373413,
      "learning_rate": 9.322891566265061e-06,
      "loss": 0.0499,
      "step": 44310
    },
    {
      "epoch": 5.339759036144578,
      "grad_norm": 0.04708901792764664,
      "learning_rate": 9.320481927710845e-06,
      "loss": 0.0371,
      "step": 44320
    },
    {
      "epoch": 5.340963855421687,
      "grad_norm": 0.02196596749126911,
      "learning_rate": 9.318072289156628e-06,
      "loss": 0.04,
      "step": 44330
    },
    {
      "epoch": 5.3421686746987955,
      "grad_norm": 0.00864317175000906,
      "learning_rate": 9.315662650602411e-06,
      "loss": 0.0076,
      "step": 44340
    },
    {
      "epoch": 5.343373493975903,
      "grad_norm": 0.006286012940108776,
      "learning_rate": 9.313253012048194e-06,
      "loss": 0.0211,
      "step": 44350
    },
    {
      "epoch": 5.344578313253012,
      "grad_norm": 0.009635228663682938,
      "learning_rate": 9.310843373493976e-06,
      "loss": 0.0204,
      "step": 44360
    },
    {
      "epoch": 5.34578313253012,
      "grad_norm": 0.003859906457364559,
      "learning_rate": 9.30843373493976e-06,
      "loss": 0.0036,
      "step": 44370
    },
    {
      "epoch": 5.346987951807229,
      "grad_norm": 0.013148239813745022,
      "learning_rate": 9.306024096385544e-06,
      "loss": 0.0092,
      "step": 44380
    },
    {
      "epoch": 5.348192771084337,
      "grad_norm": 3.5570168495178223,
      "learning_rate": 9.303614457831325e-06,
      "loss": 0.0177,
      "step": 44390
    },
    {
      "epoch": 5.349397590361446,
      "grad_norm": 1.496656060218811,
      "learning_rate": 9.301204819277108e-06,
      "loss": 0.0365,
      "step": 44400
    },
    {
      "epoch": 5.3506024096385545,
      "grad_norm": 0.08171871304512024,
      "learning_rate": 9.298795180722893e-06,
      "loss": 0.0498,
      "step": 44410
    },
    {
      "epoch": 5.351807228915662,
      "grad_norm": 0.015561399981379509,
      "learning_rate": 9.296385542168675e-06,
      "loss": 0.0164,
      "step": 44420
    },
    {
      "epoch": 5.353012048192771,
      "grad_norm": 1.2192466259002686,
      "learning_rate": 9.293975903614458e-06,
      "loss": 0.0395,
      "step": 44430
    },
    {
      "epoch": 5.354216867469879,
      "grad_norm": 0.010546563193202019,
      "learning_rate": 9.291566265060241e-06,
      "loss": 0.0127,
      "step": 44440
    },
    {
      "epoch": 5.355421686746988,
      "grad_norm": 3.786256790161133,
      "learning_rate": 9.289156626506026e-06,
      "loss": 0.037,
      "step": 44450
    },
    {
      "epoch": 5.356626506024097,
      "grad_norm": 0.0033885405864566565,
      "learning_rate": 9.286746987951807e-06,
      "loss": 0.0956,
      "step": 44460
    },
    {
      "epoch": 5.357831325301205,
      "grad_norm": 0.005458771251142025,
      "learning_rate": 9.28433734939759e-06,
      "loss": 0.0059,
      "step": 44470
    },
    {
      "epoch": 5.3590361445783135,
      "grad_norm": 0.006498575210571289,
      "learning_rate": 9.281927710843375e-06,
      "loss": 0.032,
      "step": 44480
    },
    {
      "epoch": 5.360240963855421,
      "grad_norm": 0.23382417857646942,
      "learning_rate": 9.279518072289157e-06,
      "loss": 0.0079,
      "step": 44490
    },
    {
      "epoch": 5.36144578313253,
      "grad_norm": 0.040546808391809464,
      "learning_rate": 9.27710843373494e-06,
      "loss": 0.0483,
      "step": 44500
    },
    {
      "epoch": 5.362650602409639,
      "grad_norm": 0.5073952674865723,
      "learning_rate": 9.274698795180723e-06,
      "loss": 0.0194,
      "step": 44510
    },
    {
      "epoch": 5.363855421686747,
      "grad_norm": 4.643346309661865,
      "learning_rate": 9.272289156626506e-06,
      "loss": 0.0643,
      "step": 44520
    },
    {
      "epoch": 5.365060240963856,
      "grad_norm": 1.585433006286621,
      "learning_rate": 9.26987951807229e-06,
      "loss": 0.0464,
      "step": 44530
    },
    {
      "epoch": 5.366265060240964,
      "grad_norm": 0.04344237968325615,
      "learning_rate": 9.267469879518073e-06,
      "loss": 0.0092,
      "step": 44540
    },
    {
      "epoch": 5.367469879518072,
      "grad_norm": 0.04845280945301056,
      "learning_rate": 9.265060240963856e-06,
      "loss": 0.0154,
      "step": 44550
    },
    {
      "epoch": 5.36867469879518,
      "grad_norm": 1.0367687940597534,
      "learning_rate": 9.262650602409639e-06,
      "loss": 0.0311,
      "step": 44560
    },
    {
      "epoch": 5.369879518072289,
      "grad_norm": 0.328665167093277,
      "learning_rate": 9.260240963855422e-06,
      "loss": 0.0267,
      "step": 44570
    },
    {
      "epoch": 5.371084337349398,
      "grad_norm": 0.8836608529090881,
      "learning_rate": 9.257831325301205e-06,
      "loss": 0.0028,
      "step": 44580
    },
    {
      "epoch": 5.372289156626506,
      "grad_norm": 0.2790736258029938,
      "learning_rate": 9.255421686746989e-06,
      "loss": 0.019,
      "step": 44590
    },
    {
      "epoch": 5.373493975903615,
      "grad_norm": 0.04984826222062111,
      "learning_rate": 9.253012048192772e-06,
      "loss": 0.0204,
      "step": 44600
    },
    {
      "epoch": 5.374698795180723,
      "grad_norm": 0.012909670360386372,
      "learning_rate": 9.250602409638555e-06,
      "loss": 0.0816,
      "step": 44610
    },
    {
      "epoch": 5.375903614457831,
      "grad_norm": 0.14229804277420044,
      "learning_rate": 9.248192771084338e-06,
      "loss": 0.0198,
      "step": 44620
    },
    {
      "epoch": 5.377108433734939,
      "grad_norm": 1.0762853622436523,
      "learning_rate": 9.245783132530121e-06,
      "loss": 0.027,
      "step": 44630
    },
    {
      "epoch": 5.378313253012048,
      "grad_norm": 0.13715529441833496,
      "learning_rate": 9.243373493975905e-06,
      "loss": 0.0046,
      "step": 44640
    },
    {
      "epoch": 5.379518072289157,
      "grad_norm": 0.013824859634041786,
      "learning_rate": 9.240963855421688e-06,
      "loss": 0.0245,
      "step": 44650
    },
    {
      "epoch": 5.380722891566265,
      "grad_norm": 1.5119906663894653,
      "learning_rate": 9.238554216867471e-06,
      "loss": 0.019,
      "step": 44660
    },
    {
      "epoch": 5.381927710843374,
      "grad_norm": 0.9836583733558655,
      "learning_rate": 9.236144578313254e-06,
      "loss": 0.0318,
      "step": 44670
    },
    {
      "epoch": 5.3831325301204815,
      "grad_norm": 0.054818835109472275,
      "learning_rate": 9.233734939759037e-06,
      "loss": 0.0272,
      "step": 44680
    },
    {
      "epoch": 5.38433734939759,
      "grad_norm": 0.7744673490524292,
      "learning_rate": 9.23132530120482e-06,
      "loss": 0.015,
      "step": 44690
    },
    {
      "epoch": 5.385542168674699,
      "grad_norm": 0.005158551968634129,
      "learning_rate": 9.228915662650602e-06,
      "loss": 0.0129,
      "step": 44700
    },
    {
      "epoch": 5.386746987951807,
      "grad_norm": 2.319908618927002,
      "learning_rate": 9.226506024096387e-06,
      "loss": 0.0124,
      "step": 44710
    },
    {
      "epoch": 5.387951807228916,
      "grad_norm": 0.00705252168700099,
      "learning_rate": 9.22409638554217e-06,
      "loss": 0.0506,
      "step": 44720
    },
    {
      "epoch": 5.389156626506024,
      "grad_norm": 1.215417504310608,
      "learning_rate": 9.221686746987953e-06,
      "loss": 0.026,
      "step": 44730
    },
    {
      "epoch": 5.390361445783133,
      "grad_norm": 0.7800690531730652,
      "learning_rate": 9.219277108433736e-06,
      "loss": 0.0163,
      "step": 44740
    },
    {
      "epoch": 5.391566265060241,
      "grad_norm": 0.005864023230969906,
      "learning_rate": 9.21686746987952e-06,
      "loss": 0.011,
      "step": 44750
    },
    {
      "epoch": 5.392771084337349,
      "grad_norm": 9.729597091674805,
      "learning_rate": 9.214457831325303e-06,
      "loss": 0.0119,
      "step": 44760
    },
    {
      "epoch": 5.393975903614458,
      "grad_norm": 0.0037828620988875628,
      "learning_rate": 9.212048192771084e-06,
      "loss": 0.0324,
      "step": 44770
    },
    {
      "epoch": 5.395180722891566,
      "grad_norm": 0.0066083865240216255,
      "learning_rate": 9.209638554216869e-06,
      "loss": 0.0232,
      "step": 44780
    },
    {
      "epoch": 5.396385542168675,
      "grad_norm": 1.9032191038131714,
      "learning_rate": 9.207228915662652e-06,
      "loss": 0.0218,
      "step": 44790
    },
    {
      "epoch": 5.397590361445783,
      "grad_norm": 0.007872235029935837,
      "learning_rate": 9.204819277108434e-06,
      "loss": 0.0152,
      "step": 44800
    },
    {
      "epoch": 5.3987951807228916,
      "grad_norm": 0.004964016377925873,
      "learning_rate": 9.202409638554217e-06,
      "loss": 0.0038,
      "step": 44810
    },
    {
      "epoch": 5.4,
      "grad_norm": 2.252399206161499,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0207,
      "step": 44820
    },
    {
      "epoch": 5.401204819277108,
      "grad_norm": 0.005019434727728367,
      "learning_rate": 9.197590361445783e-06,
      "loss": 0.0107,
      "step": 44830
    },
    {
      "epoch": 5.402409638554217,
      "grad_norm": 1.036086916923523,
      "learning_rate": 9.195180722891566e-06,
      "loss": 0.0167,
      "step": 44840
    },
    {
      "epoch": 5.403614457831325,
      "grad_norm": 0.017786871641874313,
      "learning_rate": 9.19277108433735e-06,
      "loss": 0.0333,
      "step": 44850
    },
    {
      "epoch": 5.404819277108434,
      "grad_norm": 0.003867857391014695,
      "learning_rate": 9.190361445783134e-06,
      "loss": 0.0461,
      "step": 44860
    },
    {
      "epoch": 5.406024096385542,
      "grad_norm": 0.004138153977692127,
      "learning_rate": 9.187951807228916e-06,
      "loss": 0.0076,
      "step": 44870
    },
    {
      "epoch": 5.4072289156626505,
      "grad_norm": 4.1990532875061035,
      "learning_rate": 9.185542168674699e-06,
      "loss": 0.0378,
      "step": 44880
    },
    {
      "epoch": 5.408433734939759,
      "grad_norm": 7.062727928161621,
      "learning_rate": 9.183132530120484e-06,
      "loss": 0.0619,
      "step": 44890
    },
    {
      "epoch": 5.409638554216867,
      "grad_norm": 1.0685995817184448,
      "learning_rate": 9.180722891566265e-06,
      "loss": 0.0323,
      "step": 44900
    },
    {
      "epoch": 5.410843373493976,
      "grad_norm": 12.568231582641602,
      "learning_rate": 9.178313253012049e-06,
      "loss": 0.0398,
      "step": 44910
    },
    {
      "epoch": 5.412048192771084,
      "grad_norm": 0.10381606966257095,
      "learning_rate": 9.175903614457832e-06,
      "loss": 0.0066,
      "step": 44920
    },
    {
      "epoch": 5.413253012048193,
      "grad_norm": 0.28742745518684387,
      "learning_rate": 9.173493975903615e-06,
      "loss": 0.0616,
      "step": 44930
    },
    {
      "epoch": 5.414457831325302,
      "grad_norm": 1.7996323108673096,
      "learning_rate": 9.171084337349398e-06,
      "loss": 0.0324,
      "step": 44940
    },
    {
      "epoch": 5.4156626506024095,
      "grad_norm": 0.02154172584414482,
      "learning_rate": 9.168674698795181e-06,
      "loss": 0.0588,
      "step": 44950
    },
    {
      "epoch": 5.416867469879518,
      "grad_norm": 0.017061371356248856,
      "learning_rate": 9.166265060240964e-06,
      "loss": 0.005,
      "step": 44960
    },
    {
      "epoch": 5.418072289156626,
      "grad_norm": 0.729168176651001,
      "learning_rate": 9.163855421686748e-06,
      "loss": 0.0116,
      "step": 44970
    },
    {
      "epoch": 5.419277108433735,
      "grad_norm": 2.307177782058716,
      "learning_rate": 9.16144578313253e-06,
      "loss": 0.0538,
      "step": 44980
    },
    {
      "epoch": 5.420481927710844,
      "grad_norm": 0.006878383457660675,
      "learning_rate": 9.159036144578314e-06,
      "loss": 0.0073,
      "step": 44990
    },
    {
      "epoch": 5.421686746987952,
      "grad_norm": 1.8219908475875854,
      "learning_rate": 9.156626506024097e-06,
      "loss": 0.0119,
      "step": 45000
    },
    {
      "epoch": 5.4228915662650605,
      "grad_norm": 0.0070344507694244385,
      "learning_rate": 9.15421686746988e-06,
      "loss": 0.0119,
      "step": 45010
    },
    {
      "epoch": 5.424096385542168,
      "grad_norm": 0.02102922461926937,
      "learning_rate": 9.151807228915664e-06,
      "loss": 0.0031,
      "step": 45020
    },
    {
      "epoch": 5.425301204819277,
      "grad_norm": 0.013917827978730202,
      "learning_rate": 9.149397590361447e-06,
      "loss": 0.0084,
      "step": 45030
    },
    {
      "epoch": 5.426506024096385,
      "grad_norm": 0.0023944531567394733,
      "learning_rate": 9.14698795180723e-06,
      "loss": 0.0245,
      "step": 45040
    },
    {
      "epoch": 5.427710843373494,
      "grad_norm": 0.003256379859521985,
      "learning_rate": 9.144578313253013e-06,
      "loss": 0.0338,
      "step": 45050
    },
    {
      "epoch": 5.428915662650603,
      "grad_norm": 5.557875633239746,
      "learning_rate": 9.142168674698796e-06,
      "loss": 0.0184,
      "step": 45060
    },
    {
      "epoch": 5.430120481927711,
      "grad_norm": 0.015818506479263306,
      "learning_rate": 9.13975903614458e-06,
      "loss": 0.0094,
      "step": 45070
    },
    {
      "epoch": 5.4313253012048195,
      "grad_norm": 0.7428494095802307,
      "learning_rate": 9.137349397590363e-06,
      "loss": 0.0377,
      "step": 45080
    },
    {
      "epoch": 5.432530120481927,
      "grad_norm": 0.36119362711906433,
      "learning_rate": 9.134939759036146e-06,
      "loss": 0.0066,
      "step": 45090
    },
    {
      "epoch": 5.433734939759036,
      "grad_norm": 0.9166362881660461,
      "learning_rate": 9.132530120481929e-06,
      "loss": 0.0347,
      "step": 45100
    },
    {
      "epoch": 5.434939759036144,
      "grad_norm": 0.010330308228731155,
      "learning_rate": 9.13012048192771e-06,
      "loss": 0.0197,
      "step": 45110
    },
    {
      "epoch": 5.436144578313253,
      "grad_norm": 0.004675026051700115,
      "learning_rate": 9.127710843373495e-06,
      "loss": 0.0063,
      "step": 45120
    },
    {
      "epoch": 5.437349397590362,
      "grad_norm": 0.3825506269931793,
      "learning_rate": 9.125301204819278e-06,
      "loss": 0.0215,
      "step": 45130
    },
    {
      "epoch": 5.43855421686747,
      "grad_norm": 0.0028641342651098967,
      "learning_rate": 9.12289156626506e-06,
      "loss": 0.0282,
      "step": 45140
    },
    {
      "epoch": 5.4397590361445785,
      "grad_norm": 0.017178092151880264,
      "learning_rate": 9.120481927710843e-06,
      "loss": 0.0305,
      "step": 45150
    },
    {
      "epoch": 5.440963855421686,
      "grad_norm": 13.25586223602295,
      "learning_rate": 9.118072289156628e-06,
      "loss": 0.0607,
      "step": 45160
    },
    {
      "epoch": 5.442168674698795,
      "grad_norm": 0.011014442890882492,
      "learning_rate": 9.115662650602411e-06,
      "loss": 0.0176,
      "step": 45170
    },
    {
      "epoch": 5.443373493975904,
      "grad_norm": 0.009296353906393051,
      "learning_rate": 9.113253012048193e-06,
      "loss": 0.0216,
      "step": 45180
    },
    {
      "epoch": 5.444578313253012,
      "grad_norm": 0.003716290695592761,
      "learning_rate": 9.110843373493978e-06,
      "loss": 0.0419,
      "step": 45190
    },
    {
      "epoch": 5.445783132530121,
      "grad_norm": 10.88508415222168,
      "learning_rate": 9.10843373493976e-06,
      "loss": 0.0468,
      "step": 45200
    },
    {
      "epoch": 5.446987951807229,
      "grad_norm": 1.5210939645767212,
      "learning_rate": 9.106024096385542e-06,
      "loss": 0.028,
      "step": 45210
    },
    {
      "epoch": 5.448192771084337,
      "grad_norm": 0.00365709257312119,
      "learning_rate": 9.103614457831325e-06,
      "loss": 0.0227,
      "step": 45220
    },
    {
      "epoch": 5.449397590361446,
      "grad_norm": 0.029191261157393456,
      "learning_rate": 9.10120481927711e-06,
      "loss": 0.0178,
      "step": 45230
    },
    {
      "epoch": 5.450602409638554,
      "grad_norm": 0.0075833359733223915,
      "learning_rate": 9.098795180722892e-06,
      "loss": 0.024,
      "step": 45240
    },
    {
      "epoch": 5.451807228915663,
      "grad_norm": 0.012698548845946789,
      "learning_rate": 9.096385542168675e-06,
      "loss": 0.0273,
      "step": 45250
    },
    {
      "epoch": 5.453012048192771,
      "grad_norm": 0.0017962973797693849,
      "learning_rate": 9.093975903614458e-06,
      "loss": 0.0063,
      "step": 45260
    },
    {
      "epoch": 5.45421686746988,
      "grad_norm": 0.7444815039634705,
      "learning_rate": 9.091566265060243e-06,
      "loss": 0.0265,
      "step": 45270
    },
    {
      "epoch": 5.455421686746988,
      "grad_norm": 0.24441075325012207,
      "learning_rate": 9.089156626506024e-06,
      "loss": 0.0139,
      "step": 45280
    },
    {
      "epoch": 5.456626506024096,
      "grad_norm": 0.0040499125607311726,
      "learning_rate": 9.086746987951808e-06,
      "loss": 0.0363,
      "step": 45290
    },
    {
      "epoch": 5.457831325301205,
      "grad_norm": 0.004230695776641369,
      "learning_rate": 9.08433734939759e-06,
      "loss": 0.0166,
      "step": 45300
    },
    {
      "epoch": 5.459036144578313,
      "grad_norm": 19.931095123291016,
      "learning_rate": 9.081927710843374e-06,
      "loss": 0.037,
      "step": 45310
    },
    {
      "epoch": 5.460240963855422,
      "grad_norm": 0.007611317094415426,
      "learning_rate": 9.079518072289157e-06,
      "loss": 0.0241,
      "step": 45320
    },
    {
      "epoch": 5.46144578313253,
      "grad_norm": 0.009231816977262497,
      "learning_rate": 9.07710843373494e-06,
      "loss": 0.0015,
      "step": 45330
    },
    {
      "epoch": 5.462650602409639,
      "grad_norm": 0.00911982636898756,
      "learning_rate": 9.074698795180723e-06,
      "loss": 0.0899,
      "step": 45340
    },
    {
      "epoch": 5.4638554216867465,
      "grad_norm": 0.0034750609192997217,
      "learning_rate": 9.072289156626507e-06,
      "loss": 0.022,
      "step": 45350
    },
    {
      "epoch": 5.465060240963855,
      "grad_norm": 0.019692907109856606,
      "learning_rate": 9.06987951807229e-06,
      "loss": 0.0355,
      "step": 45360
    },
    {
      "epoch": 5.466265060240964,
      "grad_norm": 0.2223951369524002,
      "learning_rate": 9.067469879518073e-06,
      "loss": 0.0195,
      "step": 45370
    },
    {
      "epoch": 5.467469879518072,
      "grad_norm": 0.01455281674861908,
      "learning_rate": 9.065060240963856e-06,
      "loss": 0.0036,
      "step": 45380
    },
    {
      "epoch": 5.468674698795181,
      "grad_norm": 0.005908188875764608,
      "learning_rate": 9.06265060240964e-06,
      "loss": 0.04,
      "step": 45390
    },
    {
      "epoch": 5.469879518072289,
      "grad_norm": 1.7094115018844604,
      "learning_rate": 9.060240963855423e-06,
      "loss": 0.0262,
      "step": 45400
    },
    {
      "epoch": 5.471084337349398,
      "grad_norm": 0.14150144159793854,
      "learning_rate": 9.057831325301206e-06,
      "loss": 0.0216,
      "step": 45410
    },
    {
      "epoch": 5.472289156626506,
      "grad_norm": 0.013727803714573383,
      "learning_rate": 9.055421686746989e-06,
      "loss": 0.0054,
      "step": 45420
    },
    {
      "epoch": 5.473493975903614,
      "grad_norm": 0.0035881809890270233,
      "learning_rate": 9.053012048192772e-06,
      "loss": 0.0071,
      "step": 45430
    },
    {
      "epoch": 5.474698795180723,
      "grad_norm": 0.4139879047870636,
      "learning_rate": 9.050602409638555e-06,
      "loss": 0.0176,
      "step": 45440
    },
    {
      "epoch": 5.475903614457831,
      "grad_norm": 1.644087553024292,
      "learning_rate": 9.048192771084338e-06,
      "loss": 0.0101,
      "step": 45450
    },
    {
      "epoch": 5.47710843373494,
      "grad_norm": 1.314905047416687,
      "learning_rate": 9.045783132530122e-06,
      "loss": 0.0149,
      "step": 45460
    },
    {
      "epoch": 5.478313253012049,
      "grad_norm": 0.028967520222067833,
      "learning_rate": 9.043373493975905e-06,
      "loss": 0.035,
      "step": 45470
    },
    {
      "epoch": 5.4795180722891565,
      "grad_norm": 0.011861865408718586,
      "learning_rate": 9.040963855421688e-06,
      "loss": 0.0082,
      "step": 45480
    },
    {
      "epoch": 5.480722891566265,
      "grad_norm": 0.0030962310265749693,
      "learning_rate": 9.038554216867471e-06,
      "loss": 0.0011,
      "step": 45490
    },
    {
      "epoch": 5.481927710843373,
      "grad_norm": 0.0023140921257436275,
      "learning_rate": 9.036144578313254e-06,
      "loss": 0.041,
      "step": 45500
    },
    {
      "epoch": 5.483132530120482,
      "grad_norm": 0.014122395776212215,
      "learning_rate": 9.033734939759037e-06,
      "loss": 0.0414,
      "step": 45510
    },
    {
      "epoch": 5.48433734939759,
      "grad_norm": 0.02138960175216198,
      "learning_rate": 9.031325301204819e-06,
      "loss": 0.0189,
      "step": 45520
    },
    {
      "epoch": 5.485542168674699,
      "grad_norm": 68.66887664794922,
      "learning_rate": 9.028915662650604e-06,
      "loss": 0.0285,
      "step": 45530
    },
    {
      "epoch": 5.486746987951808,
      "grad_norm": 0.0044343192130327225,
      "learning_rate": 9.026506024096387e-06,
      "loss": 0.0105,
      "step": 45540
    },
    {
      "epoch": 5.4879518072289155,
      "grad_norm": 0.003741675056517124,
      "learning_rate": 9.024096385542168e-06,
      "loss": 0.0022,
      "step": 45550
    },
    {
      "epoch": 5.489156626506024,
      "grad_norm": 0.003397490130737424,
      "learning_rate": 9.021686746987952e-06,
      "loss": 0.0372,
      "step": 45560
    },
    {
      "epoch": 5.490361445783132,
      "grad_norm": 0.0224319901317358,
      "learning_rate": 9.019277108433737e-06,
      "loss": 0.0163,
      "step": 45570
    },
    {
      "epoch": 5.491566265060241,
      "grad_norm": 2.6639511585235596,
      "learning_rate": 9.01686746987952e-06,
      "loss": 0.0491,
      "step": 45580
    },
    {
      "epoch": 5.492771084337349,
      "grad_norm": 0.025794683024287224,
      "learning_rate": 9.014457831325301e-06,
      "loss": 0.0241,
      "step": 45590
    },
    {
      "epoch": 5.493975903614458,
      "grad_norm": 2.3200156688690186,
      "learning_rate": 9.012048192771084e-06,
      "loss": 0.0256,
      "step": 45600
    },
    {
      "epoch": 5.495180722891567,
      "grad_norm": 0.005884912330657244,
      "learning_rate": 9.00963855421687e-06,
      "loss": 0.0065,
      "step": 45610
    },
    {
      "epoch": 5.4963855421686745,
      "grad_norm": 0.08351834863424301,
      "learning_rate": 9.00722891566265e-06,
      "loss": 0.003,
      "step": 45620
    },
    {
      "epoch": 5.497590361445783,
      "grad_norm": 0.3329043686389923,
      "learning_rate": 9.004819277108434e-06,
      "loss": 0.0026,
      "step": 45630
    },
    {
      "epoch": 5.498795180722891,
      "grad_norm": 0.027172943577170372,
      "learning_rate": 9.002409638554219e-06,
      "loss": 0.0338,
      "step": 45640
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.0086204269900918,
      "learning_rate": 9e-06,
      "loss": 0.0065,
      "step": 45650
    },
    {
      "epoch": 5.501204819277109,
      "grad_norm": 0.014486264437437057,
      "learning_rate": 8.997590361445783e-06,
      "loss": 0.0058,
      "step": 45660
    },
    {
      "epoch": 5.502409638554217,
      "grad_norm": 1.5425587892532349,
      "learning_rate": 8.995180722891567e-06,
      "loss": 0.0093,
      "step": 45670
    },
    {
      "epoch": 5.5036144578313255,
      "grad_norm": 0.00638445932418108,
      "learning_rate": 8.99277108433735e-06,
      "loss": 0.0197,
      "step": 45680
    },
    {
      "epoch": 5.504819277108433,
      "grad_norm": 0.17932602763175964,
      "learning_rate": 8.990361445783133e-06,
      "loss": 0.0284,
      "step": 45690
    },
    {
      "epoch": 5.506024096385542,
      "grad_norm": 0.01376439817249775,
      "learning_rate": 8.987951807228916e-06,
      "loss": 0.0104,
      "step": 45700
    },
    {
      "epoch": 5.507228915662651,
      "grad_norm": 0.004436525050550699,
      "learning_rate": 8.9855421686747e-06,
      "loss": 0.0479,
      "step": 45710
    },
    {
      "epoch": 5.508433734939759,
      "grad_norm": 0.16523921489715576,
      "learning_rate": 8.983132530120482e-06,
      "loss": 0.0677,
      "step": 45720
    },
    {
      "epoch": 5.509638554216868,
      "grad_norm": 0.10760137438774109,
      "learning_rate": 8.980722891566266e-06,
      "loss": 0.0405,
      "step": 45730
    },
    {
      "epoch": 5.510843373493976,
      "grad_norm": 2.3295955657958984,
      "learning_rate": 8.978313253012049e-06,
      "loss": 0.0135,
      "step": 45740
    },
    {
      "epoch": 5.5120481927710845,
      "grad_norm": 0.0207572802901268,
      "learning_rate": 8.975903614457832e-06,
      "loss": 0.0131,
      "step": 45750
    },
    {
      "epoch": 5.513253012048192,
      "grad_norm": 0.004677749704569578,
      "learning_rate": 8.973493975903615e-06,
      "loss": 0.0018,
      "step": 45760
    },
    {
      "epoch": 5.514457831325301,
      "grad_norm": 0.010571600869297981,
      "learning_rate": 8.971084337349398e-06,
      "loss": 0.008,
      "step": 45770
    },
    {
      "epoch": 5.51566265060241,
      "grad_norm": 0.014848582446575165,
      "learning_rate": 8.968674698795182e-06,
      "loss": 0.0306,
      "step": 45780
    },
    {
      "epoch": 5.516867469879518,
      "grad_norm": 0.0022687730379402637,
      "learning_rate": 8.966265060240965e-06,
      "loss": 0.0567,
      "step": 45790
    },
    {
      "epoch": 5.518072289156627,
      "grad_norm": 0.2232722043991089,
      "learning_rate": 8.963855421686748e-06,
      "loss": 0.0157,
      "step": 45800
    },
    {
      "epoch": 5.519277108433735,
      "grad_norm": 0.772975742816925,
      "learning_rate": 8.961445783132531e-06,
      "loss": 0.0289,
      "step": 45810
    },
    {
      "epoch": 5.5204819277108435,
      "grad_norm": 0.5504586100578308,
      "learning_rate": 8.959036144578314e-06,
      "loss": 0.0237,
      "step": 45820
    },
    {
      "epoch": 5.521686746987951,
      "grad_norm": 0.00802539475262165,
      "learning_rate": 8.956626506024097e-06,
      "loss": 0.0072,
      "step": 45830
    },
    {
      "epoch": 5.52289156626506,
      "grad_norm": 0.005144922994077206,
      "learning_rate": 8.95421686746988e-06,
      "loss": 0.051,
      "step": 45840
    },
    {
      "epoch": 5.524096385542169,
      "grad_norm": 0.0040948460809886456,
      "learning_rate": 8.951807228915664e-06,
      "loss": 0.0531,
      "step": 45850
    },
    {
      "epoch": 5.525301204819277,
      "grad_norm": 0.2923637330532074,
      "learning_rate": 8.949397590361445e-06,
      "loss": 0.0449,
      "step": 45860
    },
    {
      "epoch": 5.526506024096386,
      "grad_norm": 0.0124281644821167,
      "learning_rate": 8.94698795180723e-06,
      "loss": 0.0096,
      "step": 45870
    },
    {
      "epoch": 5.527710843373494,
      "grad_norm": 0.0191025510430336,
      "learning_rate": 8.944578313253013e-06,
      "loss": 0.0028,
      "step": 45880
    },
    {
      "epoch": 5.528915662650602,
      "grad_norm": 0.6913658976554871,
      "learning_rate": 8.942168674698796e-06,
      "loss": 0.0333,
      "step": 45890
    },
    {
      "epoch": 5.530120481927711,
      "grad_norm": 0.008626935072243214,
      "learning_rate": 8.939759036144578e-06,
      "loss": 0.0343,
      "step": 45900
    },
    {
      "epoch": 5.531325301204819,
      "grad_norm": 0.6791031360626221,
      "learning_rate": 8.937349397590363e-06,
      "loss": 0.0214,
      "step": 45910
    },
    {
      "epoch": 5.532530120481928,
      "grad_norm": 0.010194988921284676,
      "learning_rate": 8.934939759036146e-06,
      "loss": 0.0132,
      "step": 45920
    },
    {
      "epoch": 5.533734939759036,
      "grad_norm": 0.5448256134986877,
      "learning_rate": 8.932530120481927e-06,
      "loss": 0.0175,
      "step": 45930
    },
    {
      "epoch": 5.534939759036145,
      "grad_norm": 0.006975281052291393,
      "learning_rate": 8.930120481927712e-06,
      "loss": 0.0206,
      "step": 45940
    },
    {
      "epoch": 5.5361445783132535,
      "grad_norm": 0.9570586681365967,
      "learning_rate": 8.927710843373496e-06,
      "loss": 0.0215,
      "step": 45950
    },
    {
      "epoch": 5.537349397590361,
      "grad_norm": 0.005717144347727299,
      "learning_rate": 8.925301204819277e-06,
      "loss": 0.0387,
      "step": 45960
    },
    {
      "epoch": 5.53855421686747,
      "grad_norm": 0.11076389253139496,
      "learning_rate": 8.92289156626506e-06,
      "loss": 0.0007,
      "step": 45970
    },
    {
      "epoch": 5.539759036144578,
      "grad_norm": 0.5578967928886414,
      "learning_rate": 8.920481927710845e-06,
      "loss": 0.0036,
      "step": 45980
    },
    {
      "epoch": 5.540963855421687,
      "grad_norm": 6.085206985473633,
      "learning_rate": 8.918072289156628e-06,
      "loss": 0.0502,
      "step": 45990
    },
    {
      "epoch": 5.542168674698795,
      "grad_norm": 0.00709626404568553,
      "learning_rate": 8.91566265060241e-06,
      "loss": 0.01,
      "step": 46000
    },
    {
      "epoch": 5.543373493975904,
      "grad_norm": 0.04543182998895645,
      "learning_rate": 8.913253012048193e-06,
      "loss": 0.031,
      "step": 46010
    },
    {
      "epoch": 5.544578313253012,
      "grad_norm": 0.007955419830977917,
      "learning_rate": 8.910843373493978e-06,
      "loss": 0.0339,
      "step": 46020
    },
    {
      "epoch": 5.54578313253012,
      "grad_norm": 0.005303411278873682,
      "learning_rate": 8.90843373493976e-06,
      "loss": 0.0093,
      "step": 46030
    },
    {
      "epoch": 5.546987951807229,
      "grad_norm": 0.3892354369163513,
      "learning_rate": 8.906024096385542e-06,
      "loss": 0.0207,
      "step": 46040
    },
    {
      "epoch": 5.548192771084337,
      "grad_norm": 22.15690803527832,
      "learning_rate": 8.903614457831326e-06,
      "loss": 0.0657,
      "step": 46050
    },
    {
      "epoch": 5.549397590361446,
      "grad_norm": 0.058173783123493195,
      "learning_rate": 8.901204819277109e-06,
      "loss": 0.0496,
      "step": 46060
    },
    {
      "epoch": 5.550602409638554,
      "grad_norm": 0.011657209135591984,
      "learning_rate": 8.898795180722892e-06,
      "loss": 0.0284,
      "step": 46070
    },
    {
      "epoch": 5.551807228915663,
      "grad_norm": 0.01235256064683199,
      "learning_rate": 8.896385542168675e-06,
      "loss": 0.0159,
      "step": 46080
    },
    {
      "epoch": 5.553012048192771,
      "grad_norm": 0.06268393248319626,
      "learning_rate": 8.893975903614458e-06,
      "loss": 0.0352,
      "step": 46090
    },
    {
      "epoch": 5.554216867469879,
      "grad_norm": 0.006446100305765867,
      "learning_rate": 8.891566265060241e-06,
      "loss": 0.0124,
      "step": 46100
    },
    {
      "epoch": 5.555421686746988,
      "grad_norm": 0.0298983883112669,
      "learning_rate": 8.889156626506025e-06,
      "loss": 0.0265,
      "step": 46110
    },
    {
      "epoch": 5.556626506024096,
      "grad_norm": 0.742663562297821,
      "learning_rate": 8.886746987951808e-06,
      "loss": 0.0045,
      "step": 46120
    },
    {
      "epoch": 5.557831325301205,
      "grad_norm": 0.005875930190086365,
      "learning_rate": 8.884337349397591e-06,
      "loss": 0.0099,
      "step": 46130
    },
    {
      "epoch": 5.559036144578314,
      "grad_norm": 24.695039749145508,
      "learning_rate": 8.881927710843374e-06,
      "loss": 0.0416,
      "step": 46140
    },
    {
      "epoch": 5.5602409638554215,
      "grad_norm": 0.08226189017295837,
      "learning_rate": 8.879518072289157e-06,
      "loss": 0.031,
      "step": 46150
    },
    {
      "epoch": 5.56144578313253,
      "grad_norm": 6.144647121429443,
      "learning_rate": 8.87710843373494e-06,
      "loss": 0.0695,
      "step": 46160
    },
    {
      "epoch": 5.562650602409638,
      "grad_norm": 0.012364069931209087,
      "learning_rate": 8.874698795180724e-06,
      "loss": 0.0151,
      "step": 46170
    },
    {
      "epoch": 5.563855421686747,
      "grad_norm": 3.2649037837982178,
      "learning_rate": 8.872289156626507e-06,
      "loss": 0.0343,
      "step": 46180
    },
    {
      "epoch": 5.565060240963856,
      "grad_norm": 28.532968521118164,
      "learning_rate": 8.86987951807229e-06,
      "loss": 0.0277,
      "step": 46190
    },
    {
      "epoch": 5.566265060240964,
      "grad_norm": 0.015583167783915997,
      "learning_rate": 8.867469879518073e-06,
      "loss": 0.0028,
      "step": 46200
    },
    {
      "epoch": 5.567469879518073,
      "grad_norm": 0.6550686359405518,
      "learning_rate": 8.865060240963856e-06,
      "loss": 0.0229,
      "step": 46210
    },
    {
      "epoch": 5.5686746987951805,
      "grad_norm": 1.4600379467010498,
      "learning_rate": 8.86265060240964e-06,
      "loss": 0.0294,
      "step": 46220
    },
    {
      "epoch": 5.569879518072289,
      "grad_norm": 2.5199332237243652,
      "learning_rate": 8.860240963855423e-06,
      "loss": 0.0582,
      "step": 46230
    },
    {
      "epoch": 5.571084337349397,
      "grad_norm": 0.25644323229789734,
      "learning_rate": 8.857831325301206e-06,
      "loss": 0.0618,
      "step": 46240
    },
    {
      "epoch": 5.572289156626506,
      "grad_norm": 1.6233474016189575,
      "learning_rate": 8.855421686746989e-06,
      "loss": 0.0172,
      "step": 46250
    },
    {
      "epoch": 5.573493975903615,
      "grad_norm": 0.02330183982849121,
      "learning_rate": 8.853012048192772e-06,
      "loss": 0.0052,
      "step": 46260
    },
    {
      "epoch": 5.574698795180723,
      "grad_norm": 0.14576083421707153,
      "learning_rate": 8.850602409638554e-06,
      "loss": 0.0519,
      "step": 46270
    },
    {
      "epoch": 5.575903614457832,
      "grad_norm": 0.8403201699256897,
      "learning_rate": 8.848192771084339e-06,
      "loss": 0.03,
      "step": 46280
    },
    {
      "epoch": 5.5771084337349395,
      "grad_norm": 0.026537001132965088,
      "learning_rate": 8.845783132530122e-06,
      "loss": 0.0385,
      "step": 46290
    },
    {
      "epoch": 5.578313253012048,
      "grad_norm": 0.6115666627883911,
      "learning_rate": 8.843373493975905e-06,
      "loss": 0.0309,
      "step": 46300
    },
    {
      "epoch": 5.579518072289156,
      "grad_norm": 0.004321463871747255,
      "learning_rate": 8.840963855421686e-06,
      "loss": 0.0048,
      "step": 46310
    },
    {
      "epoch": 5.580722891566265,
      "grad_norm": 0.003997631836682558,
      "learning_rate": 8.838554216867471e-06,
      "loss": 0.032,
      "step": 46320
    },
    {
      "epoch": 5.581927710843374,
      "grad_norm": 0.005164538975805044,
      "learning_rate": 8.836144578313255e-06,
      "loss": 0.0255,
      "step": 46330
    },
    {
      "epoch": 5.583132530120482,
      "grad_norm": 0.030484158545732498,
      "learning_rate": 8.833734939759036e-06,
      "loss": 0.0221,
      "step": 46340
    },
    {
      "epoch": 5.5843373493975905,
      "grad_norm": 0.18445304036140442,
      "learning_rate": 8.83132530120482e-06,
      "loss": 0.0803,
      "step": 46350
    },
    {
      "epoch": 5.585542168674698,
      "grad_norm": 0.24595043063163757,
      "learning_rate": 8.828915662650604e-06,
      "loss": 0.0549,
      "step": 46360
    },
    {
      "epoch": 5.586746987951807,
      "grad_norm": 0.014394273981451988,
      "learning_rate": 8.826506024096386e-06,
      "loss": 0.018,
      "step": 46370
    },
    {
      "epoch": 5.587951807228916,
      "grad_norm": 0.1822207272052765,
      "learning_rate": 8.824096385542169e-06,
      "loss": 0.0652,
      "step": 46380
    },
    {
      "epoch": 5.589156626506024,
      "grad_norm": 0.014846761710941792,
      "learning_rate": 8.821686746987954e-06,
      "loss": 0.0193,
      "step": 46390
    },
    {
      "epoch": 5.590361445783133,
      "grad_norm": 0.22065454721450806,
      "learning_rate": 8.819277108433735e-06,
      "loss": 0.0273,
      "step": 46400
    },
    {
      "epoch": 5.591566265060241,
      "grad_norm": 0.020010413601994514,
      "learning_rate": 8.816867469879518e-06,
      "loss": 0.0274,
      "step": 46410
    },
    {
      "epoch": 5.5927710843373495,
      "grad_norm": 1.1301982402801514,
      "learning_rate": 8.814457831325301e-06,
      "loss": 0.038,
      "step": 46420
    },
    {
      "epoch": 5.593975903614458,
      "grad_norm": 0.009229146875441074,
      "learning_rate": 8.812048192771086e-06,
      "loss": 0.0303,
      "step": 46430
    },
    {
      "epoch": 5.595180722891566,
      "grad_norm": 0.06744695454835892,
      "learning_rate": 8.809638554216868e-06,
      "loss": 0.0409,
      "step": 46440
    },
    {
      "epoch": 5.596385542168675,
      "grad_norm": 2.575042247772217,
      "learning_rate": 8.807228915662651e-06,
      "loss": 0.0426,
      "step": 46450
    },
    {
      "epoch": 5.597590361445783,
      "grad_norm": 0.3209754526615143,
      "learning_rate": 8.804819277108434e-06,
      "loss": 0.0164,
      "step": 46460
    },
    {
      "epoch": 5.598795180722892,
      "grad_norm": 0.06164621189236641,
      "learning_rate": 8.802409638554217e-06,
      "loss": 0.0103,
      "step": 46470
    },
    {
      "epoch": 5.6,
      "grad_norm": 2.4607114791870117,
      "learning_rate": 8.8e-06,
      "loss": 0.0327,
      "step": 46480
    },
    {
      "epoch": 5.6012048192771084,
      "grad_norm": 0.014445893466472626,
      "learning_rate": 8.797590361445784e-06,
      "loss": 0.0348,
      "step": 46490
    },
    {
      "epoch": 5.602409638554217,
      "grad_norm": 0.0073404316790401936,
      "learning_rate": 8.795180722891567e-06,
      "loss": 0.0225,
      "step": 46500
    },
    {
      "epoch": 5.603614457831325,
      "grad_norm": 6.674453258514404,
      "learning_rate": 8.79277108433735e-06,
      "loss": 0.0068,
      "step": 46510
    },
    {
      "epoch": 5.604819277108434,
      "grad_norm": 1.8169597387313843,
      "learning_rate": 8.790361445783133e-06,
      "loss": 0.0117,
      "step": 46520
    },
    {
      "epoch": 5.606024096385542,
      "grad_norm": 0.7697854042053223,
      "learning_rate": 8.787951807228916e-06,
      "loss": 0.0362,
      "step": 46530
    },
    {
      "epoch": 5.607228915662651,
      "grad_norm": 5.024837493896484,
      "learning_rate": 8.7855421686747e-06,
      "loss": 0.0899,
      "step": 46540
    },
    {
      "epoch": 5.608433734939759,
      "grad_norm": 0.008423034101724625,
      "learning_rate": 8.783132530120483e-06,
      "loss": 0.0208,
      "step": 46550
    },
    {
      "epoch": 5.609638554216867,
      "grad_norm": 1.5165042877197266,
      "learning_rate": 8.780722891566266e-06,
      "loss": 0.051,
      "step": 46560
    },
    {
      "epoch": 5.610843373493976,
      "grad_norm": 24.444435119628906,
      "learning_rate": 8.778313253012049e-06,
      "loss": 0.0185,
      "step": 46570
    },
    {
      "epoch": 5.612048192771084,
      "grad_norm": 2.1506049633026123,
      "learning_rate": 8.775903614457832e-06,
      "loss": 0.0094,
      "step": 46580
    },
    {
      "epoch": 5.613253012048193,
      "grad_norm": 1.024021029472351,
      "learning_rate": 8.773493975903615e-06,
      "loss": 0.068,
      "step": 46590
    },
    {
      "epoch": 5.614457831325301,
      "grad_norm": 0.06443198770284653,
      "learning_rate": 8.771084337349399e-06,
      "loss": 0.0206,
      "step": 46600
    },
    {
      "epoch": 5.61566265060241,
      "grad_norm": 0.17233417928218842,
      "learning_rate": 8.768674698795182e-06,
      "loss": 0.0383,
      "step": 46610
    },
    {
      "epoch": 5.6168674698795185,
      "grad_norm": 2.715142011642456,
      "learning_rate": 8.766265060240965e-06,
      "loss": 0.0439,
      "step": 46620
    },
    {
      "epoch": 5.618072289156626,
      "grad_norm": 0.16141463816165924,
      "learning_rate": 8.763855421686748e-06,
      "loss": 0.0073,
      "step": 46630
    },
    {
      "epoch": 5.619277108433735,
      "grad_norm": 0.012669816613197327,
      "learning_rate": 8.761445783132531e-06,
      "loss": 0.0456,
      "step": 46640
    },
    {
      "epoch": 5.620481927710843,
      "grad_norm": 1.7053817510604858,
      "learning_rate": 8.759036144578313e-06,
      "loss": 0.0254,
      "step": 46650
    },
    {
      "epoch": 5.621686746987952,
      "grad_norm": 0.8682123422622681,
      "learning_rate": 8.756626506024098e-06,
      "loss": 0.0169,
      "step": 46660
    },
    {
      "epoch": 5.622891566265061,
      "grad_norm": 0.006997915916144848,
      "learning_rate": 8.75421686746988e-06,
      "loss": 0.006,
      "step": 46670
    },
    {
      "epoch": 5.624096385542169,
      "grad_norm": 1.518628478050232,
      "learning_rate": 8.751807228915662e-06,
      "loss": 0.0266,
      "step": 46680
    },
    {
      "epoch": 5.625301204819277,
      "grad_norm": 0.03659477084875107,
      "learning_rate": 8.749397590361447e-06,
      "loss": 0.0252,
      "step": 46690
    },
    {
      "epoch": 5.626506024096385,
      "grad_norm": 0.013388429768383503,
      "learning_rate": 8.74698795180723e-06,
      "loss": 0.0405,
      "step": 46700
    },
    {
      "epoch": 5.627710843373494,
      "grad_norm": 0.007061236072331667,
      "learning_rate": 8.744578313253013e-06,
      "loss": 0.0149,
      "step": 46710
    },
    {
      "epoch": 5.628915662650602,
      "grad_norm": 0.013319200836122036,
      "learning_rate": 8.742168674698795e-06,
      "loss": 0.0293,
      "step": 46720
    },
    {
      "epoch": 5.630120481927711,
      "grad_norm": 0.016916519030928612,
      "learning_rate": 8.73975903614458e-06,
      "loss": 0.0341,
      "step": 46730
    },
    {
      "epoch": 5.63132530120482,
      "grad_norm": 0.2746303975582123,
      "learning_rate": 8.737349397590363e-06,
      "loss": 0.0103,
      "step": 46740
    },
    {
      "epoch": 5.632530120481928,
      "grad_norm": 0.07992890477180481,
      "learning_rate": 8.734939759036145e-06,
      "loss": 0.0087,
      "step": 46750
    },
    {
      "epoch": 5.633734939759036,
      "grad_norm": 0.07292588800191879,
      "learning_rate": 8.732530120481928e-06,
      "loss": 0.013,
      "step": 46760
    },
    {
      "epoch": 5.634939759036144,
      "grad_norm": 0.006387883331626654,
      "learning_rate": 8.730120481927713e-06,
      "loss": 0.0045,
      "step": 46770
    },
    {
      "epoch": 5.636144578313253,
      "grad_norm": 0.00456665363162756,
      "learning_rate": 8.727710843373494e-06,
      "loss": 0.0243,
      "step": 46780
    },
    {
      "epoch": 5.637349397590361,
      "grad_norm": 0.00471582030877471,
      "learning_rate": 8.725301204819277e-06,
      "loss": 0.0015,
      "step": 46790
    },
    {
      "epoch": 5.63855421686747,
      "grad_norm": 0.16329984366893768,
      "learning_rate": 8.722891566265062e-06,
      "loss": 0.0157,
      "step": 46800
    },
    {
      "epoch": 5.639759036144579,
      "grad_norm": 0.006004250142723322,
      "learning_rate": 8.720481927710844e-06,
      "loss": 0.022,
      "step": 46810
    },
    {
      "epoch": 5.6409638554216865,
      "grad_norm": 4.552338600158691,
      "learning_rate": 8.718072289156627e-06,
      "loss": 0.0295,
      "step": 46820
    },
    {
      "epoch": 5.642168674698795,
      "grad_norm": 0.002763808239251375,
      "learning_rate": 8.71566265060241e-06,
      "loss": 0.0207,
      "step": 46830
    },
    {
      "epoch": 5.643373493975903,
      "grad_norm": 2.3892271518707275,
      "learning_rate": 8.713253012048195e-06,
      "loss": 0.0278,
      "step": 46840
    },
    {
      "epoch": 5.644578313253012,
      "grad_norm": 2.916260004043579,
      "learning_rate": 8.710843373493976e-06,
      "loss": 0.0443,
      "step": 46850
    },
    {
      "epoch": 5.64578313253012,
      "grad_norm": 20.873336791992188,
      "learning_rate": 8.70843373493976e-06,
      "loss": 0.0202,
      "step": 46860
    },
    {
      "epoch": 5.646987951807229,
      "grad_norm": 1.6680043935775757,
      "learning_rate": 8.706024096385543e-06,
      "loss": 0.0529,
      "step": 46870
    },
    {
      "epoch": 5.648192771084338,
      "grad_norm": 0.2879470884799957,
      "learning_rate": 8.703614457831326e-06,
      "loss": 0.0244,
      "step": 46880
    },
    {
      "epoch": 5.6493975903614455,
      "grad_norm": 0.25576645135879517,
      "learning_rate": 8.701204819277109e-06,
      "loss": 0.0218,
      "step": 46890
    },
    {
      "epoch": 5.650602409638554,
      "grad_norm": 0.015462839975953102,
      "learning_rate": 8.698795180722892e-06,
      "loss": 0.0229,
      "step": 46900
    },
    {
      "epoch": 5.651807228915663,
      "grad_norm": 0.004343973472714424,
      "learning_rate": 8.696385542168675e-06,
      "loss": 0.0013,
      "step": 46910
    },
    {
      "epoch": 5.653012048192771,
      "grad_norm": 0.00431283051148057,
      "learning_rate": 8.693975903614458e-06,
      "loss": 0.001,
      "step": 46920
    },
    {
      "epoch": 5.65421686746988,
      "grad_norm": 0.0028135254979133606,
      "learning_rate": 8.691566265060242e-06,
      "loss": 0.0254,
      "step": 46930
    },
    {
      "epoch": 5.655421686746988,
      "grad_norm": 0.025911450386047363,
      "learning_rate": 8.689156626506025e-06,
      "loss": 0.0196,
      "step": 46940
    },
    {
      "epoch": 5.656626506024097,
      "grad_norm": 0.011199969798326492,
      "learning_rate": 8.686746987951808e-06,
      "loss": 0.0165,
      "step": 46950
    },
    {
      "epoch": 5.6578313253012045,
      "grad_norm": 0.0047465963289141655,
      "learning_rate": 8.684337349397591e-06,
      "loss": 0.0168,
      "step": 46960
    },
    {
      "epoch": 5.659036144578313,
      "grad_norm": 0.0034436751157045364,
      "learning_rate": 8.681927710843374e-06,
      "loss": 0.0403,
      "step": 46970
    },
    {
      "epoch": 5.660240963855422,
      "grad_norm": 0.023880301043391228,
      "learning_rate": 8.679518072289158e-06,
      "loss": 0.021,
      "step": 46980
    },
    {
      "epoch": 5.66144578313253,
      "grad_norm": 0.6957099437713623,
      "learning_rate": 8.67710843373494e-06,
      "loss": 0.0253,
      "step": 46990
    },
    {
      "epoch": 5.662650602409639,
      "grad_norm": 0.004669014364480972,
      "learning_rate": 8.674698795180724e-06,
      "loss": 0.0027,
      "step": 47000
    },
    {
      "epoch": 5.663855421686747,
      "grad_norm": 0.0399649553000927,
      "learning_rate": 8.672289156626507e-06,
      "loss": 0.0156,
      "step": 47010
    },
    {
      "epoch": 5.6650602409638555,
      "grad_norm": 0.006080294959247112,
      "learning_rate": 8.66987951807229e-06,
      "loss": 0.0147,
      "step": 47020
    },
    {
      "epoch": 5.666265060240963,
      "grad_norm": 2.5145485401153564,
      "learning_rate": 8.667469879518073e-06,
      "loss": 0.0193,
      "step": 47030
    },
    {
      "epoch": 5.667469879518072,
      "grad_norm": 0.004033153876662254,
      "learning_rate": 8.665060240963857e-06,
      "loss": 0.0124,
      "step": 47040
    },
    {
      "epoch": 5.668674698795181,
      "grad_norm": 0.5058736801147461,
      "learning_rate": 8.66265060240964e-06,
      "loss": 0.0057,
      "step": 47050
    },
    {
      "epoch": 5.669879518072289,
      "grad_norm": 2.5404257774353027,
      "learning_rate": 8.660240963855421e-06,
      "loss": 0.033,
      "step": 47060
    },
    {
      "epoch": 5.671084337349398,
      "grad_norm": 0.2056347131729126,
      "learning_rate": 8.657831325301206e-06,
      "loss": 0.0536,
      "step": 47070
    },
    {
      "epoch": 5.672289156626506,
      "grad_norm": 2.30167555809021,
      "learning_rate": 8.65542168674699e-06,
      "loss": 0.0136,
      "step": 47080
    },
    {
      "epoch": 5.6734939759036145,
      "grad_norm": 0.6088691353797913,
      "learning_rate": 8.65301204819277e-06,
      "loss": 0.0136,
      "step": 47090
    },
    {
      "epoch": 5.674698795180722,
      "grad_norm": 0.16350743174552917,
      "learning_rate": 8.650602409638556e-06,
      "loss": 0.0715,
      "step": 47100
    },
    {
      "epoch": 5.675903614457831,
      "grad_norm": 0.0032798319589346647,
      "learning_rate": 8.648192771084339e-06,
      "loss": 0.0015,
      "step": 47110
    },
    {
      "epoch": 5.67710843373494,
      "grad_norm": 0.09133166074752808,
      "learning_rate": 8.64578313253012e-06,
      "loss": 0.045,
      "step": 47120
    },
    {
      "epoch": 5.678313253012048,
      "grad_norm": 0.25490716099739075,
      "learning_rate": 8.643373493975904e-06,
      "loss": 0.0167,
      "step": 47130
    },
    {
      "epoch": 5.679518072289157,
      "grad_norm": 4.205663681030273,
      "learning_rate": 8.640963855421688e-06,
      "loss": 0.0373,
      "step": 47140
    },
    {
      "epoch": 5.6807228915662655,
      "grad_norm": 0.0018174240831285715,
      "learning_rate": 8.638554216867472e-06,
      "loss": 0.0068,
      "step": 47150
    },
    {
      "epoch": 5.6819277108433734,
      "grad_norm": 0.003114640712738037,
      "learning_rate": 8.636144578313253e-06,
      "loss": 0.0201,
      "step": 47160
    },
    {
      "epoch": 5.683132530120482,
      "grad_norm": 0.03825109824538231,
      "learning_rate": 8.633734939759036e-06,
      "loss": 0.0067,
      "step": 47170
    },
    {
      "epoch": 5.68433734939759,
      "grad_norm": 1.7630696296691895,
      "learning_rate": 8.631325301204821e-06,
      "loss": 0.036,
      "step": 47180
    },
    {
      "epoch": 5.685542168674699,
      "grad_norm": 0.5500328540802002,
      "learning_rate": 8.628915662650603e-06,
      "loss": 0.0095,
      "step": 47190
    },
    {
      "epoch": 5.686746987951807,
      "grad_norm": 0.008046794682741165,
      "learning_rate": 8.626506024096386e-06,
      "loss": 0.0137,
      "step": 47200
    },
    {
      "epoch": 5.687951807228916,
      "grad_norm": 0.14756383001804352,
      "learning_rate": 8.624096385542169e-06,
      "loss": 0.0142,
      "step": 47210
    },
    {
      "epoch": 5.6891566265060245,
      "grad_norm": 11.522347450256348,
      "learning_rate": 8.621686746987952e-06,
      "loss": 0.0823,
      "step": 47220
    },
    {
      "epoch": 5.690361445783132,
      "grad_norm": 1.43485689163208,
      "learning_rate": 8.619277108433735e-06,
      "loss": 0.0317,
      "step": 47230
    },
    {
      "epoch": 5.691566265060241,
      "grad_norm": 13.631321907043457,
      "learning_rate": 8.616867469879518e-06,
      "loss": 0.0478,
      "step": 47240
    },
    {
      "epoch": 5.692771084337349,
      "grad_norm": 2.684079170227051,
      "learning_rate": 8.614457831325302e-06,
      "loss": 0.0231,
      "step": 47250
    },
    {
      "epoch": 5.693975903614458,
      "grad_norm": 0.00768542755395174,
      "learning_rate": 8.612048192771085e-06,
      "loss": 0.0091,
      "step": 47260
    },
    {
      "epoch": 5.695180722891566,
      "grad_norm": 0.46224066615104675,
      "learning_rate": 8.609638554216868e-06,
      "loss": 0.0162,
      "step": 47270
    },
    {
      "epoch": 5.696385542168675,
      "grad_norm": 0.008153271861374378,
      "learning_rate": 8.607228915662651e-06,
      "loss": 0.0164,
      "step": 47280
    },
    {
      "epoch": 5.6975903614457835,
      "grad_norm": 0.006482743192464113,
      "learning_rate": 8.604819277108434e-06,
      "loss": 0.0217,
      "step": 47290
    },
    {
      "epoch": 5.698795180722891,
      "grad_norm": 0.006791920401155949,
      "learning_rate": 8.602409638554217e-06,
      "loss": 0.0438,
      "step": 47300
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.008434231393039227,
      "learning_rate": 8.6e-06,
      "loss": 0.0063,
      "step": 47310
    },
    {
      "epoch": 5.701204819277108,
      "grad_norm": 0.007783683482557535,
      "learning_rate": 8.597590361445784e-06,
      "loss": 0.0368,
      "step": 47320
    },
    {
      "epoch": 5.702409638554217,
      "grad_norm": 0.007241483777761459,
      "learning_rate": 8.595180722891567e-06,
      "loss": 0.0352,
      "step": 47330
    },
    {
      "epoch": 5.703614457831325,
      "grad_norm": 0.5937636494636536,
      "learning_rate": 8.59277108433735e-06,
      "loss": 0.0245,
      "step": 47340
    },
    {
      "epoch": 5.704819277108434,
      "grad_norm": 0.7717446684837341,
      "learning_rate": 8.590361445783133e-06,
      "loss": 0.0266,
      "step": 47350
    },
    {
      "epoch": 5.706024096385542,
      "grad_norm": 2.8291854858398438,
      "learning_rate": 8.587951807228917e-06,
      "loss": 0.0589,
      "step": 47360
    },
    {
      "epoch": 5.70722891566265,
      "grad_norm": 0.29518061876296997,
      "learning_rate": 8.5855421686747e-06,
      "loss": 0.0423,
      "step": 47370
    },
    {
      "epoch": 5.708433734939759,
      "grad_norm": 0.2237229198217392,
      "learning_rate": 8.583132530120483e-06,
      "loss": 0.0333,
      "step": 47380
    },
    {
      "epoch": 5.709638554216868,
      "grad_norm": 0.006906063295900822,
      "learning_rate": 8.580722891566266e-06,
      "loss": 0.0233,
      "step": 47390
    },
    {
      "epoch": 5.710843373493976,
      "grad_norm": 0.011967474594712257,
      "learning_rate": 8.57831325301205e-06,
      "loss": 0.0333,
      "step": 47400
    },
    {
      "epoch": 5.712048192771085,
      "grad_norm": 1.0266830921173096,
      "learning_rate": 8.575903614457832e-06,
      "loss": 0.0298,
      "step": 47410
    },
    {
      "epoch": 5.713253012048193,
      "grad_norm": 0.008631712757050991,
      "learning_rate": 8.573493975903616e-06,
      "loss": 0.007,
      "step": 47420
    },
    {
      "epoch": 5.714457831325301,
      "grad_norm": 0.7481602430343628,
      "learning_rate": 8.571084337349397e-06,
      "loss": 0.0105,
      "step": 47430
    },
    {
      "epoch": 5.715662650602409,
      "grad_norm": 0.8157433271408081,
      "learning_rate": 8.568674698795182e-06,
      "loss": 0.044,
      "step": 47440
    },
    {
      "epoch": 5.716867469879518,
      "grad_norm": 3.6912245750427246,
      "learning_rate": 8.566265060240965e-06,
      "loss": 0.0554,
      "step": 47450
    },
    {
      "epoch": 5.718072289156627,
      "grad_norm": 0.9122599959373474,
      "learning_rate": 8.563855421686748e-06,
      "loss": 0.0247,
      "step": 47460
    },
    {
      "epoch": 5.719277108433735,
      "grad_norm": 0.5252498984336853,
      "learning_rate": 8.56144578313253e-06,
      "loss": 0.004,
      "step": 47470
    },
    {
      "epoch": 5.720481927710844,
      "grad_norm": 0.015513399615883827,
      "learning_rate": 8.559036144578315e-06,
      "loss": 0.0584,
      "step": 47480
    },
    {
      "epoch": 5.7216867469879515,
      "grad_norm": 4.0090556144714355,
      "learning_rate": 8.556626506024098e-06,
      "loss": 0.0496,
      "step": 47490
    },
    {
      "epoch": 5.72289156626506,
      "grad_norm": 0.024449104443192482,
      "learning_rate": 8.55421686746988e-06,
      "loss": 0.011,
      "step": 47500
    },
    {
      "epoch": 5.724096385542168,
      "grad_norm": 1.116952896118164,
      "learning_rate": 8.551807228915662e-06,
      "loss": 0.0338,
      "step": 47510
    },
    {
      "epoch": 5.725301204819277,
      "grad_norm": 0.007568772416561842,
      "learning_rate": 8.549397590361447e-06,
      "loss": 0.0176,
      "step": 47520
    },
    {
      "epoch": 5.726506024096386,
      "grad_norm": 6.6303229331970215,
      "learning_rate": 8.546987951807229e-06,
      "loss": 0.0086,
      "step": 47530
    },
    {
      "epoch": 5.727710843373494,
      "grad_norm": 0.7792253494262695,
      "learning_rate": 8.544578313253012e-06,
      "loss": 0.0072,
      "step": 47540
    },
    {
      "epoch": 5.728915662650603,
      "grad_norm": 0.01343223825097084,
      "learning_rate": 8.542168674698797e-06,
      "loss": 0.0344,
      "step": 47550
    },
    {
      "epoch": 5.7301204819277105,
      "grad_norm": 0.017477568238973618,
      "learning_rate": 8.53975903614458e-06,
      "loss": 0.0233,
      "step": 47560
    },
    {
      "epoch": 5.731325301204819,
      "grad_norm": 0.49150896072387695,
      "learning_rate": 8.537349397590362e-06,
      "loss": 0.0192,
      "step": 47570
    },
    {
      "epoch": 5.732530120481927,
      "grad_norm": 0.14544832706451416,
      "learning_rate": 8.534939759036145e-06,
      "loss": 0.0447,
      "step": 47580
    },
    {
      "epoch": 5.733734939759036,
      "grad_norm": 2.7338216304779053,
      "learning_rate": 8.53253012048193e-06,
      "loss": 0.0439,
      "step": 47590
    },
    {
      "epoch": 5.734939759036145,
      "grad_norm": 0.013355547562241554,
      "learning_rate": 8.530120481927711e-06,
      "loss": 0.0023,
      "step": 47600
    },
    {
      "epoch": 5.736144578313253,
      "grad_norm": 0.01996922492980957,
      "learning_rate": 8.527710843373494e-06,
      "loss": 0.025,
      "step": 47610
    },
    {
      "epoch": 5.7373493975903616,
      "grad_norm": 0.006119534373283386,
      "learning_rate": 8.525301204819277e-06,
      "loss": 0.0367,
      "step": 47620
    },
    {
      "epoch": 5.73855421686747,
      "grad_norm": 0.013775007799267769,
      "learning_rate": 8.52289156626506e-06,
      "loss": 0.0143,
      "step": 47630
    },
    {
      "epoch": 5.739759036144578,
      "grad_norm": 0.006756204646080732,
      "learning_rate": 8.520481927710844e-06,
      "loss": 0.024,
      "step": 47640
    },
    {
      "epoch": 5.740963855421687,
      "grad_norm": 0.0430910587310791,
      "learning_rate": 8.518072289156627e-06,
      "loss": 0.0286,
      "step": 47650
    },
    {
      "epoch": 5.742168674698795,
      "grad_norm": 7.74689245223999,
      "learning_rate": 8.51566265060241e-06,
      "loss": 0.0811,
      "step": 47660
    },
    {
      "epoch": 5.743373493975904,
      "grad_norm": 0.010946044698357582,
      "learning_rate": 8.513253012048193e-06,
      "loss": 0.0096,
      "step": 47670
    },
    {
      "epoch": 5.744578313253012,
      "grad_norm": 0.01772015355527401,
      "learning_rate": 8.510843373493976e-06,
      "loss": 0.0264,
      "step": 47680
    },
    {
      "epoch": 5.7457831325301205,
      "grad_norm": 2.0052332878112793,
      "learning_rate": 8.50843373493976e-06,
      "loss": 0.0196,
      "step": 47690
    },
    {
      "epoch": 5.746987951807229,
      "grad_norm": 1.6674132347106934,
      "learning_rate": 8.506024096385543e-06,
      "loss": 0.0293,
      "step": 47700
    },
    {
      "epoch": 5.748192771084337,
      "grad_norm": 0.019729001447558403,
      "learning_rate": 8.503614457831326e-06,
      "loss": 0.0412,
      "step": 47710
    },
    {
      "epoch": 5.749397590361446,
      "grad_norm": 0.0160613302141428,
      "learning_rate": 8.50120481927711e-06,
      "loss": 0.0387,
      "step": 47720
    },
    {
      "epoch": 5.750602409638554,
      "grad_norm": 0.026040269061923027,
      "learning_rate": 8.498795180722892e-06,
      "loss": 0.0053,
      "step": 47730
    },
    {
      "epoch": 5.751807228915663,
      "grad_norm": 1.364577293395996,
      "learning_rate": 8.496385542168676e-06,
      "loss": 0.0058,
      "step": 47740
    },
    {
      "epoch": 5.753012048192771,
      "grad_norm": 0.004669790156185627,
      "learning_rate": 8.493975903614459e-06,
      "loss": 0.0158,
      "step": 47750
    },
    {
      "epoch": 5.7542168674698795,
      "grad_norm": 0.47366687655448914,
      "learning_rate": 8.491566265060242e-06,
      "loss": 0.0414,
      "step": 47760
    },
    {
      "epoch": 5.755421686746988,
      "grad_norm": 1.9727462530136108,
      "learning_rate": 8.489156626506025e-06,
      "loss": 0.042,
      "step": 47770
    },
    {
      "epoch": 5.756626506024096,
      "grad_norm": 0.005012157838791609,
      "learning_rate": 8.486746987951808e-06,
      "loss": 0.0119,
      "step": 47780
    },
    {
      "epoch": 5.757831325301205,
      "grad_norm": 0.041091710329055786,
      "learning_rate": 8.484337349397591e-06,
      "loss": 0.0341,
      "step": 47790
    },
    {
      "epoch": 5.759036144578313,
      "grad_norm": 0.005863259080797434,
      "learning_rate": 8.481927710843375e-06,
      "loss": 0.0017,
      "step": 47800
    },
    {
      "epoch": 5.760240963855422,
      "grad_norm": 0.0028163951355963945,
      "learning_rate": 8.479518072289156e-06,
      "loss": 0.0049,
      "step": 47810
    },
    {
      "epoch": 5.76144578313253,
      "grad_norm": 0.003871584078297019,
      "learning_rate": 8.477108433734941e-06,
      "loss": 0.0014,
      "step": 47820
    },
    {
      "epoch": 5.7626506024096384,
      "grad_norm": 0.012169832363724709,
      "learning_rate": 8.474698795180724e-06,
      "loss": 0.0191,
      "step": 47830
    },
    {
      "epoch": 5.763855421686747,
      "grad_norm": 0.3754896819591522,
      "learning_rate": 8.472289156626506e-06,
      "loss": 0.0312,
      "step": 47840
    },
    {
      "epoch": 5.765060240963855,
      "grad_norm": 0.0029377129394561052,
      "learning_rate": 8.46987951807229e-06,
      "loss": 0.0523,
      "step": 47850
    },
    {
      "epoch": 5.766265060240964,
      "grad_norm": 1.8974496126174927,
      "learning_rate": 8.467469879518074e-06,
      "loss": 0.0147,
      "step": 47860
    },
    {
      "epoch": 5.767469879518073,
      "grad_norm": 0.03328665345907211,
      "learning_rate": 8.465060240963857e-06,
      "loss": 0.0043,
      "step": 47870
    },
    {
      "epoch": 5.768674698795181,
      "grad_norm": 3.186155080795288,
      "learning_rate": 8.462650602409638e-06,
      "loss": 0.0255,
      "step": 47880
    },
    {
      "epoch": 5.7698795180722895,
      "grad_norm": 1.8427109718322754,
      "learning_rate": 8.460240963855423e-06,
      "loss": 0.0249,
      "step": 47890
    },
    {
      "epoch": 5.771084337349397,
      "grad_norm": 0.4664788246154785,
      "learning_rate": 8.457831325301206e-06,
      "loss": 0.015,
      "step": 47900
    },
    {
      "epoch": 5.772289156626506,
      "grad_norm": 0.02257613092660904,
      "learning_rate": 8.455421686746988e-06,
      "loss": 0.0122,
      "step": 47910
    },
    {
      "epoch": 5.773493975903614,
      "grad_norm": 7.289641857147217,
      "learning_rate": 8.453012048192771e-06,
      "loss": 0.0323,
      "step": 47920
    },
    {
      "epoch": 5.774698795180723,
      "grad_norm": 0.0066438582725822926,
      "learning_rate": 8.450602409638556e-06,
      "loss": 0.0155,
      "step": 47930
    },
    {
      "epoch": 5.775903614457832,
      "grad_norm": 2.029686450958252,
      "learning_rate": 8.448192771084337e-06,
      "loss": 0.0506,
      "step": 47940
    },
    {
      "epoch": 5.77710843373494,
      "grad_norm": 0.509419858455658,
      "learning_rate": 8.44578313253012e-06,
      "loss": 0.0096,
      "step": 47950
    },
    {
      "epoch": 5.7783132530120485,
      "grad_norm": 13.920470237731934,
      "learning_rate": 8.443373493975904e-06,
      "loss": 0.0565,
      "step": 47960
    },
    {
      "epoch": 5.779518072289156,
      "grad_norm": 0.07914994657039642,
      "learning_rate": 8.440963855421687e-06,
      "loss": 0.074,
      "step": 47970
    },
    {
      "epoch": 5.780722891566265,
      "grad_norm": 0.010623328387737274,
      "learning_rate": 8.43855421686747e-06,
      "loss": 0.0112,
      "step": 47980
    },
    {
      "epoch": 5.781927710843373,
      "grad_norm": 77.51863098144531,
      "learning_rate": 8.436144578313253e-06,
      "loss": 0.0233,
      "step": 47990
    },
    {
      "epoch": 5.783132530120482,
      "grad_norm": 0.006945705972611904,
      "learning_rate": 8.433734939759038e-06,
      "loss": 0.0325,
      "step": 48000
    },
    {
      "epoch": 5.784337349397591,
      "grad_norm": 0.4522641599178314,
      "learning_rate": 8.43132530120482e-06,
      "loss": 0.0099,
      "step": 48010
    },
    {
      "epoch": 5.785542168674699,
      "grad_norm": 0.8086019158363342,
      "learning_rate": 8.428915662650603e-06,
      "loss": 0.0028,
      "step": 48020
    },
    {
      "epoch": 5.786746987951807,
      "grad_norm": 1.9828574657440186,
      "learning_rate": 8.426506024096386e-06,
      "loss": 0.0156,
      "step": 48030
    },
    {
      "epoch": 5.787951807228915,
      "grad_norm": 4.8039703369140625,
      "learning_rate": 8.424096385542169e-06,
      "loss": 0.0225,
      "step": 48040
    },
    {
      "epoch": 5.789156626506024,
      "grad_norm": 0.8331918120384216,
      "learning_rate": 8.421686746987952e-06,
      "loss": 0.0155,
      "step": 48050
    },
    {
      "epoch": 5.790361445783132,
      "grad_norm": 0.006047752685844898,
      "learning_rate": 8.419277108433735e-06,
      "loss": 0.0167,
      "step": 48060
    },
    {
      "epoch": 5.791566265060241,
      "grad_norm": 0.3874477446079254,
      "learning_rate": 8.416867469879519e-06,
      "loss": 0.0105,
      "step": 48070
    },
    {
      "epoch": 5.79277108433735,
      "grad_norm": 0.00337994541041553,
      "learning_rate": 8.414457831325302e-06,
      "loss": 0.001,
      "step": 48080
    },
    {
      "epoch": 5.793975903614458,
      "grad_norm": 0.09752662479877472,
      "learning_rate": 8.412048192771085e-06,
      "loss": 0.0345,
      "step": 48090
    },
    {
      "epoch": 5.795180722891566,
      "grad_norm": 0.010857554152607918,
      "learning_rate": 8.409638554216868e-06,
      "loss": 0.0119,
      "step": 48100
    },
    {
      "epoch": 5.796385542168675,
      "grad_norm": 2.958482265472412,
      "learning_rate": 8.407228915662651e-06,
      "loss": 0.0304,
      "step": 48110
    },
    {
      "epoch": 5.797590361445783,
      "grad_norm": 0.005135761108249426,
      "learning_rate": 8.404819277108435e-06,
      "loss": 0.0324,
      "step": 48120
    },
    {
      "epoch": 5.798795180722892,
      "grad_norm": 1.4591604471206665,
      "learning_rate": 8.402409638554218e-06,
      "loss": 0.0333,
      "step": 48130
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.014734314754605293,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0104,
      "step": 48140
    },
    {
      "epoch": 5.801204819277109,
      "grad_norm": 2.164628505706787,
      "learning_rate": 8.397590361445784e-06,
      "loss": 0.0359,
      "step": 48150
    },
    {
      "epoch": 5.8024096385542165,
      "grad_norm": 0.00905030407011509,
      "learning_rate": 8.395180722891567e-06,
      "loss": 0.0219,
      "step": 48160
    },
    {
      "epoch": 5.803614457831325,
      "grad_norm": 0.13165703415870667,
      "learning_rate": 8.39277108433735e-06,
      "loss": 0.0135,
      "step": 48170
    },
    {
      "epoch": 5.804819277108434,
      "grad_norm": 1.9936450719833374,
      "learning_rate": 8.390361445783134e-06,
      "loss": 0.0233,
      "step": 48180
    },
    {
      "epoch": 5.806024096385542,
      "grad_norm": 6.314608573913574,
      "learning_rate": 8.387951807228917e-06,
      "loss": 0.0233,
      "step": 48190
    },
    {
      "epoch": 5.807228915662651,
      "grad_norm": 0.006678569596260786,
      "learning_rate": 8.3855421686747e-06,
      "loss": 0.0184,
      "step": 48200
    },
    {
      "epoch": 5.808433734939759,
      "grad_norm": 0.01354426983743906,
      "learning_rate": 8.383132530120483e-06,
      "loss": 0.0274,
      "step": 48210
    },
    {
      "epoch": 5.809638554216868,
      "grad_norm": 2.342177629470825,
      "learning_rate": 8.380722891566265e-06,
      "loss": 0.0097,
      "step": 48220
    },
    {
      "epoch": 5.8108433734939755,
      "grad_norm": 0.38392457365989685,
      "learning_rate": 8.37831325301205e-06,
      "loss": 0.001,
      "step": 48230
    },
    {
      "epoch": 5.812048192771084,
      "grad_norm": 0.008537927642464638,
      "learning_rate": 8.375903614457833e-06,
      "loss": 0.0056,
      "step": 48240
    },
    {
      "epoch": 5.813253012048193,
      "grad_norm": 0.04596760496497154,
      "learning_rate": 8.373493975903614e-06,
      "loss": 0.0047,
      "step": 48250
    },
    {
      "epoch": 5.814457831325301,
      "grad_norm": 0.604286789894104,
      "learning_rate": 8.371084337349397e-06,
      "loss": 0.0161,
      "step": 48260
    },
    {
      "epoch": 5.81566265060241,
      "grad_norm": 0.10020092874765396,
      "learning_rate": 8.368674698795182e-06,
      "loss": 0.0145,
      "step": 48270
    },
    {
      "epoch": 5.816867469879518,
      "grad_norm": 0.005535121541470289,
      "learning_rate": 8.366265060240965e-06,
      "loss": 0.0386,
      "step": 48280
    },
    {
      "epoch": 5.8180722891566266,
      "grad_norm": 0.3129207491874695,
      "learning_rate": 8.363855421686747e-06,
      "loss": 0.0274,
      "step": 48290
    },
    {
      "epoch": 5.8192771084337345,
      "grad_norm": 2.693023204803467,
      "learning_rate": 8.361445783132532e-06,
      "loss": 0.0719,
      "step": 48300
    },
    {
      "epoch": 5.820481927710843,
      "grad_norm": 0.00931485090404749,
      "learning_rate": 8.359036144578315e-06,
      "loss": 0.0056,
      "step": 48310
    },
    {
      "epoch": 5.821686746987952,
      "grad_norm": 0.003101988462731242,
      "learning_rate": 8.356626506024096e-06,
      "loss": 0.0061,
      "step": 48320
    },
    {
      "epoch": 5.82289156626506,
      "grad_norm": 0.2052471786737442,
      "learning_rate": 8.35421686746988e-06,
      "loss": 0.0091,
      "step": 48330
    },
    {
      "epoch": 5.824096385542169,
      "grad_norm": 0.00309311063028872,
      "learning_rate": 8.351807228915664e-06,
      "loss": 0.0129,
      "step": 48340
    },
    {
      "epoch": 5.825301204819278,
      "grad_norm": 0.9490454196929932,
      "learning_rate": 8.349397590361446e-06,
      "loss": 0.0024,
      "step": 48350
    },
    {
      "epoch": 5.8265060240963855,
      "grad_norm": 0.0016054236330091953,
      "learning_rate": 8.346987951807229e-06,
      "loss": 0.0278,
      "step": 48360
    },
    {
      "epoch": 5.827710843373494,
      "grad_norm": 0.001960882917046547,
      "learning_rate": 8.344578313253012e-06,
      "loss": 0.0088,
      "step": 48370
    },
    {
      "epoch": 5.828915662650602,
      "grad_norm": 0.0016011063707992435,
      "learning_rate": 8.342168674698795e-06,
      "loss": 0.006,
      "step": 48380
    },
    {
      "epoch": 5.830120481927711,
      "grad_norm": 0.003720909357070923,
      "learning_rate": 8.339759036144579e-06,
      "loss": 0.0078,
      "step": 48390
    },
    {
      "epoch": 5.831325301204819,
      "grad_norm": 0.008188815787434578,
      "learning_rate": 8.337349397590362e-06,
      "loss": 0.0033,
      "step": 48400
    },
    {
      "epoch": 5.832530120481928,
      "grad_norm": 0.04775870963931084,
      "learning_rate": 8.334939759036145e-06,
      "loss": 0.0416,
      "step": 48410
    },
    {
      "epoch": 5.833734939759037,
      "grad_norm": 0.009370560757815838,
      "learning_rate": 8.332530120481928e-06,
      "loss": 0.0107,
      "step": 48420
    },
    {
      "epoch": 5.8349397590361445,
      "grad_norm": 0.0018640861380845308,
      "learning_rate": 8.330120481927711e-06,
      "loss": 0.0156,
      "step": 48430
    },
    {
      "epoch": 5.836144578313253,
      "grad_norm": 0.0534866638481617,
      "learning_rate": 8.327710843373494e-06,
      "loss": 0.056,
      "step": 48440
    },
    {
      "epoch": 5.837349397590361,
      "grad_norm": 1.0280929803848267,
      "learning_rate": 8.325301204819278e-06,
      "loss": 0.0202,
      "step": 48450
    },
    {
      "epoch": 5.83855421686747,
      "grad_norm": 6.236450672149658,
      "learning_rate": 8.32289156626506e-06,
      "loss": 0.0395,
      "step": 48460
    },
    {
      "epoch": 5.839759036144578,
      "grad_norm": 0.020984146744012833,
      "learning_rate": 8.320481927710844e-06,
      "loss": 0.0364,
      "step": 48470
    },
    {
      "epoch": 5.840963855421687,
      "grad_norm": 0.16624195873737335,
      "learning_rate": 8.318072289156627e-06,
      "loss": 0.0066,
      "step": 48480
    },
    {
      "epoch": 5.8421686746987955,
      "grad_norm": 0.09045057743787766,
      "learning_rate": 8.31566265060241e-06,
      "loss": 0.0416,
      "step": 48490
    },
    {
      "epoch": 5.843373493975903,
      "grad_norm": 0.07124096155166626,
      "learning_rate": 8.313253012048194e-06,
      "loss": 0.0114,
      "step": 48500
    },
    {
      "epoch": 5.844578313253012,
      "grad_norm": 0.004307503812015057,
      "learning_rate": 8.310843373493977e-06,
      "loss": 0.0275,
      "step": 48510
    },
    {
      "epoch": 5.84578313253012,
      "grad_norm": 0.003317523282021284,
      "learning_rate": 8.30843373493976e-06,
      "loss": 0.0279,
      "step": 48520
    },
    {
      "epoch": 5.846987951807229,
      "grad_norm": 0.01635109633207321,
      "learning_rate": 8.306024096385543e-06,
      "loss": 0.0031,
      "step": 48530
    },
    {
      "epoch": 5.848192771084337,
      "grad_norm": 0.0019196146167814732,
      "learning_rate": 8.303614457831326e-06,
      "loss": 0.0509,
      "step": 48540
    },
    {
      "epoch": 5.849397590361446,
      "grad_norm": 2.115137815475464,
      "learning_rate": 8.30120481927711e-06,
      "loss": 0.0191,
      "step": 48550
    },
    {
      "epoch": 5.8506024096385545,
      "grad_norm": 0.02560725249350071,
      "learning_rate": 8.298795180722891e-06,
      "loss": 0.0057,
      "step": 48560
    },
    {
      "epoch": 5.851807228915662,
      "grad_norm": 0.41513630747795105,
      "learning_rate": 8.296385542168676e-06,
      "loss": 0.0171,
      "step": 48570
    },
    {
      "epoch": 5.853012048192771,
      "grad_norm": 1.5721017122268677,
      "learning_rate": 8.293975903614459e-06,
      "loss": 0.0145,
      "step": 48580
    },
    {
      "epoch": 5.85421686746988,
      "grad_norm": 0.0015439955750480294,
      "learning_rate": 8.291566265060242e-06,
      "loss": 0.0139,
      "step": 48590
    },
    {
      "epoch": 5.855421686746988,
      "grad_norm": 2.0201351642608643,
      "learning_rate": 8.289156626506025e-06,
      "loss": 0.0282,
      "step": 48600
    },
    {
      "epoch": 5.856626506024097,
      "grad_norm": 0.0014747226377949119,
      "learning_rate": 8.286746987951808e-06,
      "loss": 0.006,
      "step": 48610
    },
    {
      "epoch": 5.857831325301205,
      "grad_norm": 0.0011903123231604695,
      "learning_rate": 8.284337349397592e-06,
      "loss": 0.0411,
      "step": 48620
    },
    {
      "epoch": 5.8590361445783135,
      "grad_norm": 0.0014410887379199266,
      "learning_rate": 8.281927710843373e-06,
      "loss": 0.0104,
      "step": 48630
    },
    {
      "epoch": 5.860240963855421,
      "grad_norm": 0.011498779989778996,
      "learning_rate": 8.279518072289158e-06,
      "loss": 0.014,
      "step": 48640
    },
    {
      "epoch": 5.86144578313253,
      "grad_norm": 2.517685890197754,
      "learning_rate": 8.277108433734941e-06,
      "loss": 0.0387,
      "step": 48650
    },
    {
      "epoch": 5.862650602409639,
      "grad_norm": 0.001324371318332851,
      "learning_rate": 8.274698795180723e-06,
      "loss": 0.0286,
      "step": 48660
    },
    {
      "epoch": 5.863855421686747,
      "grad_norm": 0.003581127617508173,
      "learning_rate": 8.272289156626506e-06,
      "loss": 0.0253,
      "step": 48670
    },
    {
      "epoch": 5.865060240963856,
      "grad_norm": 1.9711014032363892,
      "learning_rate": 8.26987951807229e-06,
      "loss": 0.0126,
      "step": 48680
    },
    {
      "epoch": 5.866265060240964,
      "grad_norm": 0.04646389186382294,
      "learning_rate": 8.267469879518072e-06,
      "loss": 0.0128,
      "step": 48690
    },
    {
      "epoch": 5.867469879518072,
      "grad_norm": 0.003991492558270693,
      "learning_rate": 8.265060240963855e-06,
      "loss": 0.0838,
      "step": 48700
    },
    {
      "epoch": 5.86867469879518,
      "grad_norm": 0.004412307403981686,
      "learning_rate": 8.262650602409639e-06,
      "loss": 0.0043,
      "step": 48710
    },
    {
      "epoch": 5.869879518072289,
      "grad_norm": 0.08145637065172195,
      "learning_rate": 8.260240963855423e-06,
      "loss": 0.0435,
      "step": 48720
    },
    {
      "epoch": 5.871084337349398,
      "grad_norm": 0.00162114214617759,
      "learning_rate": 8.257831325301205e-06,
      "loss": 0.0095,
      "step": 48730
    },
    {
      "epoch": 5.872289156626506,
      "grad_norm": 0.024017484858632088,
      "learning_rate": 8.255421686746988e-06,
      "loss": 0.0359,
      "step": 48740
    },
    {
      "epoch": 5.873493975903615,
      "grad_norm": 0.3648955821990967,
      "learning_rate": 8.253012048192773e-06,
      "loss": 0.0391,
      "step": 48750
    },
    {
      "epoch": 5.874698795180723,
      "grad_norm": 1.117261290550232,
      "learning_rate": 8.250602409638554e-06,
      "loss": 0.0268,
      "step": 48760
    },
    {
      "epoch": 5.875903614457831,
      "grad_norm": 0.7522954344749451,
      "learning_rate": 8.248192771084338e-06,
      "loss": 0.0261,
      "step": 48770
    },
    {
      "epoch": 5.877108433734939,
      "grad_norm": 8.398982048034668,
      "learning_rate": 8.24578313253012e-06,
      "loss": 0.0842,
      "step": 48780
    },
    {
      "epoch": 5.878313253012048,
      "grad_norm": 0.008326714858412743,
      "learning_rate": 8.243373493975904e-06,
      "loss": 0.0362,
      "step": 48790
    },
    {
      "epoch": 5.879518072289157,
      "grad_norm": 0.6730127334594727,
      "learning_rate": 8.240963855421687e-06,
      "loss": 0.0118,
      "step": 48800
    },
    {
      "epoch": 5.880722891566265,
      "grad_norm": 2.352445363998413,
      "learning_rate": 8.23855421686747e-06,
      "loss": 0.0225,
      "step": 48810
    },
    {
      "epoch": 5.881927710843374,
      "grad_norm": 0.13299909234046936,
      "learning_rate": 8.236144578313253e-06,
      "loss": 0.0162,
      "step": 48820
    },
    {
      "epoch": 5.8831325301204815,
      "grad_norm": 2.0583951473236084,
      "learning_rate": 8.233734939759037e-06,
      "loss": 0.0476,
      "step": 48830
    },
    {
      "epoch": 5.88433734939759,
      "grad_norm": 7.454077243804932,
      "learning_rate": 8.23132530120482e-06,
      "loss": 0.0286,
      "step": 48840
    },
    {
      "epoch": 5.885542168674699,
      "grad_norm": 1.4789555072784424,
      "learning_rate": 8.228915662650603e-06,
      "loss": 0.0143,
      "step": 48850
    },
    {
      "epoch": 5.886746987951807,
      "grad_norm": 1.8327925205230713,
      "learning_rate": 8.226506024096386e-06,
      "loss": 0.0296,
      "step": 48860
    },
    {
      "epoch": 5.887951807228916,
      "grad_norm": 0.0623842291533947,
      "learning_rate": 8.22409638554217e-06,
      "loss": 0.005,
      "step": 48870
    },
    {
      "epoch": 5.889156626506024,
      "grad_norm": 1.2037063837051392,
      "learning_rate": 8.221686746987953e-06,
      "loss": 0.0054,
      "step": 48880
    },
    {
      "epoch": 5.890361445783133,
      "grad_norm": 0.0022645066492259502,
      "learning_rate": 8.219277108433736e-06,
      "loss": 0.0048,
      "step": 48890
    },
    {
      "epoch": 5.891566265060241,
      "grad_norm": 108.82989501953125,
      "learning_rate": 8.216867469879519e-06,
      "loss": 0.0115,
      "step": 48900
    },
    {
      "epoch": 5.892771084337349,
      "grad_norm": 2.001169443130493,
      "learning_rate": 8.214457831325302e-06,
      "loss": 0.0306,
      "step": 48910
    },
    {
      "epoch": 5.893975903614458,
      "grad_norm": 0.9019591808319092,
      "learning_rate": 8.212048192771085e-06,
      "loss": 0.0283,
      "step": 48920
    },
    {
      "epoch": 5.895180722891566,
      "grad_norm": 0.0027230805717408657,
      "learning_rate": 8.209638554216868e-06,
      "loss": 0.1176,
      "step": 48930
    },
    {
      "epoch": 5.896385542168675,
      "grad_norm": 58.432010650634766,
      "learning_rate": 8.207228915662652e-06,
      "loss": 0.0341,
      "step": 48940
    },
    {
      "epoch": 5.897590361445783,
      "grad_norm": 0.018322637304663658,
      "learning_rate": 8.204819277108435e-06,
      "loss": 0.0063,
      "step": 48950
    },
    {
      "epoch": 5.8987951807228916,
      "grad_norm": 0.0760960578918457,
      "learning_rate": 8.202409638554218e-06,
      "loss": 0.0268,
      "step": 48960
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.2755153179168701,
      "learning_rate": 8.2e-06,
      "loss": 0.0028,
      "step": 48970
    },
    {
      "epoch": 5.901204819277108,
      "grad_norm": 0.004364809021353722,
      "learning_rate": 8.197590361445784e-06,
      "loss": 0.0051,
      "step": 48980
    },
    {
      "epoch": 5.902409638554217,
      "grad_norm": 0.0012825927697122097,
      "learning_rate": 8.195180722891567e-06,
      "loss": 0.0276,
      "step": 48990
    },
    {
      "epoch": 5.903614457831325,
      "grad_norm": 0.019058752804994583,
      "learning_rate": 8.19277108433735e-06,
      "loss": 0.0654,
      "step": 49000
    },
    {
      "epoch": 5.904819277108434,
      "grad_norm": 0.626617431640625,
      "learning_rate": 8.190361445783134e-06,
      "loss": 0.0103,
      "step": 49010
    },
    {
      "epoch": 5.906024096385542,
      "grad_norm": 0.6916037201881409,
      "learning_rate": 8.187951807228917e-06,
      "loss": 0.0611,
      "step": 49020
    },
    {
      "epoch": 5.9072289156626505,
      "grad_norm": 0.0030702173244208097,
      "learning_rate": 8.1855421686747e-06,
      "loss": 0.0221,
      "step": 49030
    },
    {
      "epoch": 5.908433734939759,
      "grad_norm": 0.003940925467759371,
      "learning_rate": 8.183132530120482e-06,
      "loss": 0.0205,
      "step": 49040
    },
    {
      "epoch": 5.909638554216867,
      "grad_norm": 0.014475204050540924,
      "learning_rate": 8.180722891566267e-06,
      "loss": 0.0369,
      "step": 49050
    },
    {
      "epoch": 5.910843373493976,
      "grad_norm": 0.2665325105190277,
      "learning_rate": 8.17831325301205e-06,
      "loss": 0.0272,
      "step": 49060
    },
    {
      "epoch": 5.912048192771084,
      "grad_norm": 0.25134408473968506,
      "learning_rate": 8.175903614457831e-06,
      "loss": 0.0232,
      "step": 49070
    },
    {
      "epoch": 5.913253012048193,
      "grad_norm": 0.04862222447991371,
      "learning_rate": 8.173493975903614e-06,
      "loss": 0.0384,
      "step": 49080
    },
    {
      "epoch": 5.914457831325302,
      "grad_norm": 2.062514543533325,
      "learning_rate": 8.1710843373494e-06,
      "loss": 0.04,
      "step": 49090
    },
    {
      "epoch": 5.9156626506024095,
      "grad_norm": 0.8780778050422668,
      "learning_rate": 8.16867469879518e-06,
      "loss": 0.0658,
      "step": 49100
    },
    {
      "epoch": 5.916867469879518,
      "grad_norm": 1.3188327550888062,
      "learning_rate": 8.166265060240964e-06,
      "loss": 0.0103,
      "step": 49110
    },
    {
      "epoch": 5.918072289156626,
      "grad_norm": 2.3702681064605713,
      "learning_rate": 8.163855421686747e-06,
      "loss": 0.0147,
      "step": 49120
    },
    {
      "epoch": 5.919277108433735,
      "grad_norm": 3.9778244495391846,
      "learning_rate": 8.161445783132532e-06,
      "loss": 0.046,
      "step": 49130
    },
    {
      "epoch": 5.920481927710844,
      "grad_norm": 0.00354210683144629,
      "learning_rate": 8.159036144578313e-06,
      "loss": 0.0109,
      "step": 49140
    },
    {
      "epoch": 5.921686746987952,
      "grad_norm": 0.002278552856296301,
      "learning_rate": 8.156626506024097e-06,
      "loss": 0.0139,
      "step": 49150
    },
    {
      "epoch": 5.9228915662650605,
      "grad_norm": 5.6538801193237305,
      "learning_rate": 8.154216867469881e-06,
      "loss": 0.0717,
      "step": 49160
    },
    {
      "epoch": 5.924096385542168,
      "grad_norm": 0.3580915033817291,
      "learning_rate": 8.151807228915663e-06,
      "loss": 0.0138,
      "step": 49170
    },
    {
      "epoch": 5.925301204819277,
      "grad_norm": 0.3473646938800812,
      "learning_rate": 8.149397590361446e-06,
      "loss": 0.0061,
      "step": 49180
    },
    {
      "epoch": 5.926506024096385,
      "grad_norm": 0.0249762162566185,
      "learning_rate": 8.14698795180723e-06,
      "loss": 0.0127,
      "step": 49190
    },
    {
      "epoch": 5.927710843373494,
      "grad_norm": 0.004373630508780479,
      "learning_rate": 8.144578313253012e-06,
      "loss": 0.0266,
      "step": 49200
    },
    {
      "epoch": 5.928915662650603,
      "grad_norm": 0.004084879998117685,
      "learning_rate": 8.142168674698796e-06,
      "loss": 0.0034,
      "step": 49210
    },
    {
      "epoch": 5.930120481927711,
      "grad_norm": 0.8586547374725342,
      "learning_rate": 8.139759036144579e-06,
      "loss": 0.0142,
      "step": 49220
    },
    {
      "epoch": 5.9313253012048195,
      "grad_norm": 0.005283962935209274,
      "learning_rate": 8.137349397590362e-06,
      "loss": 0.0096,
      "step": 49230
    },
    {
      "epoch": 5.932530120481927,
      "grad_norm": 1.0431673526763916,
      "learning_rate": 8.134939759036145e-06,
      "loss": 0.0475,
      "step": 49240
    },
    {
      "epoch": 5.933734939759036,
      "grad_norm": 0.7077898383140564,
      "learning_rate": 8.132530120481928e-06,
      "loss": 0.0241,
      "step": 49250
    },
    {
      "epoch": 5.934939759036144,
      "grad_norm": 0.8864368796348572,
      "learning_rate": 8.130120481927712e-06,
      "loss": 0.0186,
      "step": 49260
    },
    {
      "epoch": 5.936144578313253,
      "grad_norm": 0.5749828219413757,
      "learning_rate": 8.127710843373495e-06,
      "loss": 0.031,
      "step": 49270
    },
    {
      "epoch": 5.937349397590362,
      "grad_norm": 0.006123627535998821,
      "learning_rate": 8.125301204819278e-06,
      "loss": 0.0037,
      "step": 49280
    },
    {
      "epoch": 5.93855421686747,
      "grad_norm": 0.00799921341240406,
      "learning_rate": 8.122891566265061e-06,
      "loss": 0.0388,
      "step": 49290
    },
    {
      "epoch": 5.9397590361445785,
      "grad_norm": 0.24094398319721222,
      "learning_rate": 8.120481927710844e-06,
      "loss": 0.0054,
      "step": 49300
    },
    {
      "epoch": 5.940963855421686,
      "grad_norm": 0.013275989331305027,
      "learning_rate": 8.118072289156627e-06,
      "loss": 0.047,
      "step": 49310
    },
    {
      "epoch": 5.942168674698795,
      "grad_norm": 0.036666687577962875,
      "learning_rate": 8.11566265060241e-06,
      "loss": 0.0391,
      "step": 49320
    },
    {
      "epoch": 5.943373493975904,
      "grad_norm": 0.10892642289400101,
      "learning_rate": 8.113253012048194e-06,
      "loss": 0.0032,
      "step": 49330
    },
    {
      "epoch": 5.944578313253012,
      "grad_norm": 4.357670783996582,
      "learning_rate": 8.110843373493977e-06,
      "loss": 0.01,
      "step": 49340
    },
    {
      "epoch": 5.945783132530121,
      "grad_norm": 0.939767599105835,
      "learning_rate": 8.10843373493976e-06,
      "loss": 0.0226,
      "step": 49350
    },
    {
      "epoch": 5.946987951807229,
      "grad_norm": 1.2781221866607666,
      "learning_rate": 8.106024096385543e-06,
      "loss": 0.0571,
      "step": 49360
    },
    {
      "epoch": 5.948192771084337,
      "grad_norm": 1.2190759181976318,
      "learning_rate": 8.103614457831326e-06,
      "loss": 0.0035,
      "step": 49370
    },
    {
      "epoch": 5.949397590361446,
      "grad_norm": 0.01946806162595749,
      "learning_rate": 8.101204819277108e-06,
      "loss": 0.0295,
      "step": 49380
    },
    {
      "epoch": 5.950602409638554,
      "grad_norm": 0.05670364201068878,
      "learning_rate": 8.098795180722893e-06,
      "loss": 0.0409,
      "step": 49390
    },
    {
      "epoch": 5.951807228915663,
      "grad_norm": 0.00626757275313139,
      "learning_rate": 8.096385542168676e-06,
      "loss": 0.0037,
      "step": 49400
    },
    {
      "epoch": 5.953012048192771,
      "grad_norm": 0.029424231499433517,
      "learning_rate": 8.093975903614457e-06,
      "loss": 0.0242,
      "step": 49410
    },
    {
      "epoch": 5.95421686746988,
      "grad_norm": 0.352816104888916,
      "learning_rate": 8.09156626506024e-06,
      "loss": 0.0113,
      "step": 49420
    },
    {
      "epoch": 5.955421686746988,
      "grad_norm": 0.0038552223704755306,
      "learning_rate": 8.089156626506026e-06,
      "loss": 0.0156,
      "step": 49430
    },
    {
      "epoch": 5.956626506024096,
      "grad_norm": 0.0044636414386332035,
      "learning_rate": 8.086746987951809e-06,
      "loss": 0.0094,
      "step": 49440
    },
    {
      "epoch": 5.957831325301205,
      "grad_norm": 0.2142331898212433,
      "learning_rate": 8.08433734939759e-06,
      "loss": 0.0121,
      "step": 49450
    },
    {
      "epoch": 5.959036144578313,
      "grad_norm": 0.0028969072736799717,
      "learning_rate": 8.081927710843375e-06,
      "loss": 0.0097,
      "step": 49460
    },
    {
      "epoch": 5.960240963855422,
      "grad_norm": 1.3173491954803467,
      "learning_rate": 8.079518072289158e-06,
      "loss": 0.0301,
      "step": 49470
    },
    {
      "epoch": 5.96144578313253,
      "grad_norm": 0.09646345674991608,
      "learning_rate": 8.07710843373494e-06,
      "loss": 0.048,
      "step": 49480
    },
    {
      "epoch": 5.962650602409639,
      "grad_norm": 0.016859102994203568,
      "learning_rate": 8.074698795180723e-06,
      "loss": 0.0687,
      "step": 49490
    },
    {
      "epoch": 5.9638554216867465,
      "grad_norm": 0.0038711123634129763,
      "learning_rate": 8.072289156626508e-06,
      "loss": 0.0022,
      "step": 49500
    },
    {
      "epoch": 5.965060240963855,
      "grad_norm": 0.009306802414357662,
      "learning_rate": 8.06987951807229e-06,
      "loss": 0.048,
      "step": 49510
    },
    {
      "epoch": 5.966265060240964,
      "grad_norm": 0.13927464187145233,
      "learning_rate": 8.067469879518072e-06,
      "loss": 0.0032,
      "step": 49520
    },
    {
      "epoch": 5.967469879518072,
      "grad_norm": 0.0035719056613743305,
      "learning_rate": 8.065060240963856e-06,
      "loss": 0.0171,
      "step": 49530
    },
    {
      "epoch": 5.968674698795181,
      "grad_norm": 0.1064477413892746,
      "learning_rate": 8.062650602409639e-06,
      "loss": 0.0166,
      "step": 49540
    },
    {
      "epoch": 5.969879518072289,
      "grad_norm": 1.9860104322433472,
      "learning_rate": 8.060240963855422e-06,
      "loss": 0.0247,
      "step": 49550
    },
    {
      "epoch": 5.971084337349398,
      "grad_norm": 2.4847307205200195,
      "learning_rate": 8.057831325301205e-06,
      "loss": 0.0098,
      "step": 49560
    },
    {
      "epoch": 5.972289156626506,
      "grad_norm": 0.003022325923666358,
      "learning_rate": 8.055421686746988e-06,
      "loss": 0.002,
      "step": 49570
    },
    {
      "epoch": 5.973493975903614,
      "grad_norm": 0.004408597014844418,
      "learning_rate": 8.053012048192771e-06,
      "loss": 0.0207,
      "step": 49580
    },
    {
      "epoch": 5.974698795180723,
      "grad_norm": 0.0356072336435318,
      "learning_rate": 8.050602409638555e-06,
      "loss": 0.0147,
      "step": 49590
    },
    {
      "epoch": 5.975903614457831,
      "grad_norm": 0.004587806295603514,
      "learning_rate": 8.048192771084338e-06,
      "loss": 0.0078,
      "step": 49600
    },
    {
      "epoch": 5.97710843373494,
      "grad_norm": 36.86681365966797,
      "learning_rate": 8.045783132530121e-06,
      "loss": 0.0458,
      "step": 49610
    },
    {
      "epoch": 5.978313253012049,
      "grad_norm": 1.7817662954330444,
      "learning_rate": 8.043373493975904e-06,
      "loss": 0.0233,
      "step": 49620
    },
    {
      "epoch": 5.9795180722891565,
      "grad_norm": 0.0080520398914814,
      "learning_rate": 8.040963855421687e-06,
      "loss": 0.0126,
      "step": 49630
    },
    {
      "epoch": 5.980722891566265,
      "grad_norm": 0.010640505701303482,
      "learning_rate": 8.03855421686747e-06,
      "loss": 0.0081,
      "step": 49640
    },
    {
      "epoch": 5.981927710843373,
      "grad_norm": 0.02863299660384655,
      "learning_rate": 8.036144578313254e-06,
      "loss": 0.0252,
      "step": 49650
    },
    {
      "epoch": 5.983132530120482,
      "grad_norm": 1.5995688438415527,
      "learning_rate": 8.033734939759037e-06,
      "loss": 0.0592,
      "step": 49660
    },
    {
      "epoch": 5.98433734939759,
      "grad_norm": 0.002891266020014882,
      "learning_rate": 8.03132530120482e-06,
      "loss": 0.0154,
      "step": 49670
    },
    {
      "epoch": 5.985542168674699,
      "grad_norm": 0.017369745299220085,
      "learning_rate": 8.028915662650603e-06,
      "loss": 0.0401,
      "step": 49680
    },
    {
      "epoch": 5.986746987951808,
      "grad_norm": 0.002919059945270419,
      "learning_rate": 8.026506024096386e-06,
      "loss": 0.0001,
      "step": 49690
    },
    {
      "epoch": 5.9879518072289155,
      "grad_norm": 9.567014694213867,
      "learning_rate": 8.02409638554217e-06,
      "loss": 0.0342,
      "step": 49700
    },
    {
      "epoch": 5.989156626506024,
      "grad_norm": 0.0034446357749402523,
      "learning_rate": 8.021686746987953e-06,
      "loss": 0.0231,
      "step": 49710
    },
    {
      "epoch": 5.990361445783132,
      "grad_norm": 0.0034355814568698406,
      "learning_rate": 8.019277108433736e-06,
      "loss": 0.0163,
      "step": 49720
    },
    {
      "epoch": 5.991566265060241,
      "grad_norm": 6.582690238952637,
      "learning_rate": 8.016867469879519e-06,
      "loss": 0.0554,
      "step": 49730
    },
    {
      "epoch": 5.992771084337349,
      "grad_norm": 0.7116518616676331,
      "learning_rate": 8.014457831325302e-06,
      "loss": 0.0134,
      "step": 49740
    },
    {
      "epoch": 5.993975903614458,
      "grad_norm": 0.3482970893383026,
      "learning_rate": 8.012048192771085e-06,
      "loss": 0.0065,
      "step": 49750
    },
    {
      "epoch": 5.995180722891567,
      "grad_norm": 0.02739850990474224,
      "learning_rate": 8.009638554216869e-06,
      "loss": 0.0206,
      "step": 49760
    },
    {
      "epoch": 5.9963855421686745,
      "grad_norm": 4.897852897644043,
      "learning_rate": 8.007228915662652e-06,
      "loss": 0.0416,
      "step": 49770
    },
    {
      "epoch": 5.997590361445783,
      "grad_norm": 0.003299134550616145,
      "learning_rate": 8.004819277108435e-06,
      "loss": 0.0057,
      "step": 49780
    },
    {
      "epoch": 5.998795180722891,
      "grad_norm": 1.8970859050750732,
      "learning_rate": 8.002409638554216e-06,
      "loss": 0.0817,
      "step": 49790
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.907550573348999,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0033,
      "step": 49800
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9873922009748781,
      "eval_f1": 0.966366591647912,
      "eval_loss": 0.040332578122615814,
      "eval_precision": 0.9777356103731816,
      "eval_recall": 0.9552589296749475,
      "eval_runtime": 3418.2924,
      "eval_samples_per_second": 12.489,
      "eval_steps_per_second": 0.52,
      "step": 49800
    },
    {
      "epoch": 6.001204819277109,
      "grad_norm": 0.008789410814642906,
      "learning_rate": 7.997590361445785e-06,
      "loss": 0.0277,
      "step": 49810
    },
    {
      "epoch": 6.002409638554217,
      "grad_norm": 0.4600884020328522,
      "learning_rate": 7.995180722891566e-06,
      "loss": 0.0153,
      "step": 49820
    },
    {
      "epoch": 6.0036144578313255,
      "grad_norm": 0.004717690404504538,
      "learning_rate": 7.99277108433735e-06,
      "loss": 0.0186,
      "step": 49830
    },
    {
      "epoch": 6.004819277108433,
      "grad_norm": 0.004171906970441341,
      "learning_rate": 7.990361445783134e-06,
      "loss": 0.0093,
      "step": 49840
    },
    {
      "epoch": 6.006024096385542,
      "grad_norm": 0.10626155883073807,
      "learning_rate": 7.987951807228917e-06,
      "loss": 0.0426,
      "step": 49850
    },
    {
      "epoch": 6.00722891566265,
      "grad_norm": 0.009716155007481575,
      "learning_rate": 7.985542168674699e-06,
      "loss": 0.0216,
      "step": 49860
    },
    {
      "epoch": 6.008433734939759,
      "grad_norm": 0.011166420765221119,
      "learning_rate": 7.983132530120482e-06,
      "loss": 0.0025,
      "step": 49870
    },
    {
      "epoch": 6.009638554216868,
      "grad_norm": 0.644273579120636,
      "learning_rate": 7.980722891566267e-06,
      "loss": 0.0195,
      "step": 49880
    },
    {
      "epoch": 6.010843373493976,
      "grad_norm": 0.012968866154551506,
      "learning_rate": 7.978313253012048e-06,
      "loss": 0.01,
      "step": 49890
    },
    {
      "epoch": 6.0120481927710845,
      "grad_norm": 0.7817476391792297,
      "learning_rate": 7.975903614457831e-06,
      "loss": 0.0089,
      "step": 49900
    },
    {
      "epoch": 6.013253012048192,
      "grad_norm": 0.1884462833404541,
      "learning_rate": 7.973493975903616e-06,
      "loss": 0.0076,
      "step": 49910
    },
    {
      "epoch": 6.014457831325301,
      "grad_norm": 1.8444122076034546,
      "learning_rate": 7.971084337349398e-06,
      "loss": 0.0231,
      "step": 49920
    },
    {
      "epoch": 6.01566265060241,
      "grad_norm": 0.2682223916053772,
      "learning_rate": 7.968674698795181e-06,
      "loss": 0.0035,
      "step": 49930
    },
    {
      "epoch": 6.016867469879518,
      "grad_norm": 0.009373702108860016,
      "learning_rate": 7.966265060240964e-06,
      "loss": 0.0252,
      "step": 49940
    },
    {
      "epoch": 6.018072289156627,
      "grad_norm": 0.0024986984208226204,
      "learning_rate": 7.963855421686747e-06,
      "loss": 0.0248,
      "step": 49950
    },
    {
      "epoch": 6.019277108433735,
      "grad_norm": 0.006335466168820858,
      "learning_rate": 7.96144578313253e-06,
      "loss": 0.0046,
      "step": 49960
    },
    {
      "epoch": 6.0204819277108435,
      "grad_norm": 0.0031132702715694904,
      "learning_rate": 7.959036144578314e-06,
      "loss": 0.0072,
      "step": 49970
    },
    {
      "epoch": 6.021686746987951,
      "grad_norm": 1.011642336845398,
      "learning_rate": 7.956626506024097e-06,
      "loss": 0.0029,
      "step": 49980
    },
    {
      "epoch": 6.02289156626506,
      "grad_norm": 0.21015053987503052,
      "learning_rate": 7.95421686746988e-06,
      "loss": 0.0062,
      "step": 49990
    },
    {
      "epoch": 6.024096385542169,
      "grad_norm": 0.004950148519128561,
      "learning_rate": 7.951807228915663e-06,
      "loss": 0.0049,
      "step": 50000
    },
    {
      "epoch": 6.025301204819277,
      "grad_norm": 1.6944667100906372,
      "learning_rate": 7.949397590361446e-06,
      "loss": 0.0314,
      "step": 50010
    },
    {
      "epoch": 6.026506024096386,
      "grad_norm": 0.0016946283867582679,
      "learning_rate": 7.94698795180723e-06,
      "loss": 0.0101,
      "step": 50020
    },
    {
      "epoch": 6.027710843373494,
      "grad_norm": 0.16084223985671997,
      "learning_rate": 7.944578313253013e-06,
      "loss": 0.0177,
      "step": 50030
    },
    {
      "epoch": 6.028915662650602,
      "grad_norm": 0.004009345546364784,
      "learning_rate": 7.942168674698796e-06,
      "loss": 0.0313,
      "step": 50040
    },
    {
      "epoch": 6.030120481927711,
      "grad_norm": 0.8751676678657532,
      "learning_rate": 7.939759036144579e-06,
      "loss": 0.0527,
      "step": 50050
    },
    {
      "epoch": 6.031325301204819,
      "grad_norm": 0.38455113768577576,
      "learning_rate": 7.937349397590362e-06,
      "loss": 0.0059,
      "step": 50060
    },
    {
      "epoch": 6.032530120481928,
      "grad_norm": 0.0021034537348896265,
      "learning_rate": 7.934939759036145e-06,
      "loss": 0.0144,
      "step": 50070
    },
    {
      "epoch": 6.033734939759036,
      "grad_norm": 0.010415330529212952,
      "learning_rate": 7.932530120481929e-06,
      "loss": 0.0191,
      "step": 50080
    },
    {
      "epoch": 6.034939759036145,
      "grad_norm": 0.004629636649042368,
      "learning_rate": 7.930120481927712e-06,
      "loss": 0.0014,
      "step": 50090
    },
    {
      "epoch": 6.036144578313253,
      "grad_norm": 0.001905632670968771,
      "learning_rate": 7.927710843373495e-06,
      "loss": 0.0137,
      "step": 50100
    },
    {
      "epoch": 6.037349397590361,
      "grad_norm": 0.0024837993551045656,
      "learning_rate": 7.925301204819278e-06,
      "loss": 0.0107,
      "step": 50110
    },
    {
      "epoch": 6.03855421686747,
      "grad_norm": 0.36484095454216003,
      "learning_rate": 7.922891566265061e-06,
      "loss": 0.0247,
      "step": 50120
    },
    {
      "epoch": 6.039759036144578,
      "grad_norm": 0.5456188917160034,
      "learning_rate": 7.920481927710843e-06,
      "loss": 0.0117,
      "step": 50130
    },
    {
      "epoch": 6.040963855421687,
      "grad_norm": 1.5393388271331787,
      "learning_rate": 7.918072289156628e-06,
      "loss": 0.0112,
      "step": 50140
    },
    {
      "epoch": 6.042168674698795,
      "grad_norm": 0.3619641363620758,
      "learning_rate": 7.91566265060241e-06,
      "loss": 0.0142,
      "step": 50150
    },
    {
      "epoch": 6.043373493975904,
      "grad_norm": 2.8687450885772705,
      "learning_rate": 7.913253012048194e-06,
      "loss": 0.0261,
      "step": 50160
    },
    {
      "epoch": 6.044578313253012,
      "grad_norm": 0.003941429313272238,
      "learning_rate": 7.910843373493975e-06,
      "loss": 0.01,
      "step": 50170
    },
    {
      "epoch": 6.04578313253012,
      "grad_norm": 0.4923591613769531,
      "learning_rate": 7.90843373493976e-06,
      "loss": 0.0074,
      "step": 50180
    },
    {
      "epoch": 6.046987951807229,
      "grad_norm": 0.007578221615403891,
      "learning_rate": 7.906024096385544e-06,
      "loss": 0.0346,
      "step": 50190
    },
    {
      "epoch": 6.048192771084337,
      "grad_norm": 37.53859329223633,
      "learning_rate": 7.903614457831325e-06,
      "loss": 0.0514,
      "step": 50200
    },
    {
      "epoch": 6.049397590361446,
      "grad_norm": 0.0045363884419202805,
      "learning_rate": 7.90120481927711e-06,
      "loss": 0.0336,
      "step": 50210
    },
    {
      "epoch": 6.050602409638554,
      "grad_norm": 0.012133369222283363,
      "learning_rate": 7.898795180722893e-06,
      "loss": 0.0032,
      "step": 50220
    },
    {
      "epoch": 6.051807228915663,
      "grad_norm": 0.0024130463134497404,
      "learning_rate": 7.896385542168675e-06,
      "loss": 0.012,
      "step": 50230
    },
    {
      "epoch": 6.053012048192771,
      "grad_norm": 0.2982240915298462,
      "learning_rate": 7.893975903614458e-06,
      "loss": 0.0026,
      "step": 50240
    },
    {
      "epoch": 6.054216867469879,
      "grad_norm": 0.0037688452284783125,
      "learning_rate": 7.891566265060243e-06,
      "loss": 0.0095,
      "step": 50250
    },
    {
      "epoch": 6.055421686746988,
      "grad_norm": 0.008618478663265705,
      "learning_rate": 7.889156626506024e-06,
      "loss": 0.0276,
      "step": 50260
    },
    {
      "epoch": 6.056626506024096,
      "grad_norm": 0.005123305134475231,
      "learning_rate": 7.886746987951807e-06,
      "loss": 0.0001,
      "step": 50270
    },
    {
      "epoch": 6.057831325301205,
      "grad_norm": 0.7011879086494446,
      "learning_rate": 7.88433734939759e-06,
      "loss": 0.0032,
      "step": 50280
    },
    {
      "epoch": 6.059036144578314,
      "grad_norm": 0.02950376830995083,
      "learning_rate": 7.881927710843375e-06,
      "loss": 0.0117,
      "step": 50290
    },
    {
      "epoch": 6.0602409638554215,
      "grad_norm": 0.8846458792686462,
      "learning_rate": 7.879518072289157e-06,
      "loss": 0.016,
      "step": 50300
    },
    {
      "epoch": 6.06144578313253,
      "grad_norm": 0.003442369168624282,
      "learning_rate": 7.87710843373494e-06,
      "loss": 0.0017,
      "step": 50310
    },
    {
      "epoch": 6.062650602409638,
      "grad_norm": 1.522282600402832,
      "learning_rate": 7.874698795180723e-06,
      "loss": 0.0053,
      "step": 50320
    },
    {
      "epoch": 6.063855421686747,
      "grad_norm": 1.6117496490478516,
      "learning_rate": 7.872289156626506e-06,
      "loss": 0.0165,
      "step": 50330
    },
    {
      "epoch": 6.065060240963855,
      "grad_norm": 1.9799690246582031,
      "learning_rate": 7.86987951807229e-06,
      "loss": 0.0136,
      "step": 50340
    },
    {
      "epoch": 6.066265060240964,
      "grad_norm": 0.002602296881377697,
      "learning_rate": 7.867469879518073e-06,
      "loss": 0.0157,
      "step": 50350
    },
    {
      "epoch": 6.067469879518073,
      "grad_norm": 0.00251045566983521,
      "learning_rate": 7.865060240963856e-06,
      "loss": 0.0154,
      "step": 50360
    },
    {
      "epoch": 6.0686746987951805,
      "grad_norm": 38.74755859375,
      "learning_rate": 7.862650602409639e-06,
      "loss": 0.0115,
      "step": 50370
    },
    {
      "epoch": 6.069879518072289,
      "grad_norm": 6.275274753570557,
      "learning_rate": 7.860240963855422e-06,
      "loss": 0.044,
      "step": 50380
    },
    {
      "epoch": 6.071084337349397,
      "grad_norm": 0.007483750116080046,
      "learning_rate": 7.857831325301205e-06,
      "loss": 0.0066,
      "step": 50390
    },
    {
      "epoch": 6.072289156626506,
      "grad_norm": 0.002538084052503109,
      "learning_rate": 7.855421686746989e-06,
      "loss": 0.0033,
      "step": 50400
    },
    {
      "epoch": 6.073493975903615,
      "grad_norm": 19.425487518310547,
      "learning_rate": 7.853012048192772e-06,
      "loss": 0.0292,
      "step": 50410
    },
    {
      "epoch": 6.074698795180723,
      "grad_norm": 0.0018318594666197896,
      "learning_rate": 7.850602409638555e-06,
      "loss": 0.0361,
      "step": 50420
    },
    {
      "epoch": 6.075903614457832,
      "grad_norm": 1.1506757736206055,
      "learning_rate": 7.848192771084338e-06,
      "loss": 0.0323,
      "step": 50430
    },
    {
      "epoch": 6.0771084337349395,
      "grad_norm": 0.006244693882763386,
      "learning_rate": 7.845783132530121e-06,
      "loss": 0.0054,
      "step": 50440
    },
    {
      "epoch": 6.078313253012048,
      "grad_norm": 1.0700843334197998,
      "learning_rate": 7.843373493975904e-06,
      "loss": 0.0065,
      "step": 50450
    },
    {
      "epoch": 6.079518072289156,
      "grad_norm": 0.18015269935131073,
      "learning_rate": 7.840963855421688e-06,
      "loss": 0.0067,
      "step": 50460
    },
    {
      "epoch": 6.080722891566265,
      "grad_norm": 8.680248260498047,
      "learning_rate": 7.83855421686747e-06,
      "loss": 0.04,
      "step": 50470
    },
    {
      "epoch": 6.081927710843374,
      "grad_norm": 0.39570799469947815,
      "learning_rate": 7.836144578313254e-06,
      "loss": 0.0081,
      "step": 50480
    },
    {
      "epoch": 6.083132530120482,
      "grad_norm": 0.0031400350853800774,
      "learning_rate": 7.833734939759037e-06,
      "loss": 0.0062,
      "step": 50490
    },
    {
      "epoch": 6.0843373493975905,
      "grad_norm": 0.0023738029412925243,
      "learning_rate": 7.83132530120482e-06,
      "loss": 0.011,
      "step": 50500
    },
    {
      "epoch": 6.085542168674698,
      "grad_norm": 0.40411752462387085,
      "learning_rate": 7.828915662650603e-06,
      "loss": 0.0171,
      "step": 50510
    },
    {
      "epoch": 6.086746987951807,
      "grad_norm": 0.16862359642982483,
      "learning_rate": 7.826506024096387e-06,
      "loss": 0.0202,
      "step": 50520
    },
    {
      "epoch": 6.087951807228916,
      "grad_norm": 0.008122124709188938,
      "learning_rate": 7.82409638554217e-06,
      "loss": 0.0083,
      "step": 50530
    },
    {
      "epoch": 6.089156626506024,
      "grad_norm": 0.001213541254401207,
      "learning_rate": 7.821686746987951e-06,
      "loss": 0.0361,
      "step": 50540
    },
    {
      "epoch": 6.090361445783133,
      "grad_norm": 1.4151654243469238,
      "learning_rate": 7.819277108433736e-06,
      "loss": 0.034,
      "step": 50550
    },
    {
      "epoch": 6.091566265060241,
      "grad_norm": 0.0022931895218789577,
      "learning_rate": 7.81686746987952e-06,
      "loss": 0.0152,
      "step": 50560
    },
    {
      "epoch": 6.0927710843373495,
      "grad_norm": 2.7240405082702637,
      "learning_rate": 7.814457831325302e-06,
      "loss": 0.0425,
      "step": 50570
    },
    {
      "epoch": 6.093975903614457,
      "grad_norm": 3.6800317764282227,
      "learning_rate": 7.812048192771084e-06,
      "loss": 0.0299,
      "step": 50580
    },
    {
      "epoch": 6.095180722891566,
      "grad_norm": 0.005647831596434116,
      "learning_rate": 7.809638554216869e-06,
      "loss": 0.0553,
      "step": 50590
    },
    {
      "epoch": 6.096385542168675,
      "grad_norm": 0.010492819361388683,
      "learning_rate": 7.807228915662652e-06,
      "loss": 0.0139,
      "step": 50600
    },
    {
      "epoch": 6.097590361445783,
      "grad_norm": 1.0062204599380493,
      "learning_rate": 7.804819277108434e-06,
      "loss": 0.0049,
      "step": 50610
    },
    {
      "epoch": 6.098795180722892,
      "grad_norm": 0.002782240742817521,
      "learning_rate": 7.802409638554217e-06,
      "loss": 0.0137,
      "step": 50620
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.009159933775663376,
      "learning_rate": 7.800000000000002e-06,
      "loss": 0.0316,
      "step": 50630
    },
    {
      "epoch": 6.1012048192771084,
      "grad_norm": 0.6471651196479797,
      "learning_rate": 7.797590361445783e-06,
      "loss": 0.0057,
      "step": 50640
    },
    {
      "epoch": 6.102409638554217,
      "grad_norm": 0.0033937697298824787,
      "learning_rate": 7.795180722891566e-06,
      "loss": 0.0247,
      "step": 50650
    },
    {
      "epoch": 6.103614457831325,
      "grad_norm": 0.005127085372805595,
      "learning_rate": 7.792771084337351e-06,
      "loss": 0.0479,
      "step": 50660
    },
    {
      "epoch": 6.104819277108434,
      "grad_norm": 0.003610004438087344,
      "learning_rate": 7.790361445783133e-06,
      "loss": 0.0106,
      "step": 50670
    },
    {
      "epoch": 6.106024096385542,
      "grad_norm": 0.008263979107141495,
      "learning_rate": 7.787951807228916e-06,
      "loss": 0.0137,
      "step": 50680
    },
    {
      "epoch": 6.107228915662651,
      "grad_norm": 2.080594539642334,
      "learning_rate": 7.785542168674699e-06,
      "loss": 0.0115,
      "step": 50690
    },
    {
      "epoch": 6.108433734939759,
      "grad_norm": 0.006959681399166584,
      "learning_rate": 7.783132530120484e-06,
      "loss": 0.0102,
      "step": 50700
    },
    {
      "epoch": 6.109638554216867,
      "grad_norm": 0.0024735298939049244,
      "learning_rate": 7.780722891566265e-06,
      "loss": 0.0061,
      "step": 50710
    },
    {
      "epoch": 6.110843373493976,
      "grad_norm": 0.002758331596851349,
      "learning_rate": 7.778313253012048e-06,
      "loss": 0.0023,
      "step": 50720
    },
    {
      "epoch": 6.112048192771084,
      "grad_norm": 0.003808921203017235,
      "learning_rate": 7.775903614457832e-06,
      "loss": 0.0448,
      "step": 50730
    },
    {
      "epoch": 6.113253012048193,
      "grad_norm": 0.04047812148928642,
      "learning_rate": 7.773493975903615e-06,
      "loss": 0.0245,
      "step": 50740
    },
    {
      "epoch": 6.114457831325301,
      "grad_norm": 0.007975636050105095,
      "learning_rate": 7.771084337349398e-06,
      "loss": 0.015,
      "step": 50750
    },
    {
      "epoch": 6.11566265060241,
      "grad_norm": 0.008626198396086693,
      "learning_rate": 7.768674698795181e-06,
      "loss": 0.0126,
      "step": 50760
    },
    {
      "epoch": 6.1168674698795185,
      "grad_norm": 0.39773452281951904,
      "learning_rate": 7.766265060240964e-06,
      "loss": 0.015,
      "step": 50770
    },
    {
      "epoch": 6.118072289156626,
      "grad_norm": 0.016047459095716476,
      "learning_rate": 7.763855421686747e-06,
      "loss": 0.0193,
      "step": 50780
    },
    {
      "epoch": 6.119277108433735,
      "grad_norm": 0.008261817507445812,
      "learning_rate": 7.76144578313253e-06,
      "loss": 0.0038,
      "step": 50790
    },
    {
      "epoch": 6.120481927710843,
      "grad_norm": 0.054990530014038086,
      "learning_rate": 7.759036144578314e-06,
      "loss": 0.0375,
      "step": 50800
    },
    {
      "epoch": 6.121686746987952,
      "grad_norm": 0.3375542461872101,
      "learning_rate": 7.756626506024097e-06,
      "loss": 0.0227,
      "step": 50810
    },
    {
      "epoch": 6.12289156626506,
      "grad_norm": 0.002698026830330491,
      "learning_rate": 7.75421686746988e-06,
      "loss": 0.0119,
      "step": 50820
    },
    {
      "epoch": 6.124096385542169,
      "grad_norm": 0.0015149688115343451,
      "learning_rate": 7.751807228915663e-06,
      "loss": 0.0406,
      "step": 50830
    },
    {
      "epoch": 6.125301204819277,
      "grad_norm": 1.4543237686157227,
      "learning_rate": 7.749397590361447e-06,
      "loss": 0.0361,
      "step": 50840
    },
    {
      "epoch": 6.126506024096385,
      "grad_norm": 0.0033911492209881544,
      "learning_rate": 7.74698795180723e-06,
      "loss": 0.0006,
      "step": 50850
    },
    {
      "epoch": 6.127710843373494,
      "grad_norm": 0.403994619846344,
      "learning_rate": 7.744578313253013e-06,
      "loss": 0.0129,
      "step": 50860
    },
    {
      "epoch": 6.128915662650602,
      "grad_norm": 1.5171639919281006,
      "learning_rate": 7.742168674698796e-06,
      "loss": 0.0102,
      "step": 50870
    },
    {
      "epoch": 6.130120481927711,
      "grad_norm": 0.002736681140959263,
      "learning_rate": 7.73975903614458e-06,
      "loss": 0.0021,
      "step": 50880
    },
    {
      "epoch": 6.13132530120482,
      "grad_norm": 7.083308219909668,
      "learning_rate": 7.737349397590362e-06,
      "loss": 0.0047,
      "step": 50890
    },
    {
      "epoch": 6.132530120481928,
      "grad_norm": 0.007667062804102898,
      "learning_rate": 7.734939759036146e-06,
      "loss": 0.0073,
      "step": 50900
    },
    {
      "epoch": 6.133734939759036,
      "grad_norm": 1.4777647256851196,
      "learning_rate": 7.732530120481929e-06,
      "loss": 0.0148,
      "step": 50910
    },
    {
      "epoch": 6.134939759036144,
      "grad_norm": 0.9707841277122498,
      "learning_rate": 7.730120481927712e-06,
      "loss": 0.026,
      "step": 50920
    },
    {
      "epoch": 6.136144578313253,
      "grad_norm": 0.37079471349716187,
      "learning_rate": 7.727710843373495e-06,
      "loss": 0.0112,
      "step": 50930
    },
    {
      "epoch": 6.137349397590361,
      "grad_norm": 0.0012931652599945664,
      "learning_rate": 7.725301204819278e-06,
      "loss": 0.0253,
      "step": 50940
    },
    {
      "epoch": 6.13855421686747,
      "grad_norm": 0.052588146179914474,
      "learning_rate": 7.72289156626506e-06,
      "loss": 0.0087,
      "step": 50950
    },
    {
      "epoch": 6.139759036144579,
      "grad_norm": 0.0013270966010168195,
      "learning_rate": 7.720481927710845e-06,
      "loss": 0.021,
      "step": 50960
    },
    {
      "epoch": 6.1409638554216865,
      "grad_norm": 0.0023203424643725157,
      "learning_rate": 7.718072289156628e-06,
      "loss": 0.0235,
      "step": 50970
    },
    {
      "epoch": 6.142168674698795,
      "grad_norm": 0.0018097066786140203,
      "learning_rate": 7.71566265060241e-06,
      "loss": 0.0105,
      "step": 50980
    },
    {
      "epoch": 6.143373493975903,
      "grad_norm": 6.179892063140869,
      "learning_rate": 7.713253012048193e-06,
      "loss": 0.0298,
      "step": 50990
    },
    {
      "epoch": 6.144578313253012,
      "grad_norm": 0.268385648727417,
      "learning_rate": 7.710843373493977e-06,
      "loss": 0.0505,
      "step": 51000
    },
    {
      "epoch": 6.145783132530121,
      "grad_norm": 0.006459695287048817,
      "learning_rate": 7.70843373493976e-06,
      "loss": 0.0399,
      "step": 51010
    },
    {
      "epoch": 6.146987951807229,
      "grad_norm": 2.489901542663574,
      "learning_rate": 7.706024096385542e-06,
      "loss": 0.0121,
      "step": 51020
    },
    {
      "epoch": 6.148192771084338,
      "grad_norm": 2.175585985183716,
      "learning_rate": 7.703614457831325e-06,
      "loss": 0.0318,
      "step": 51030
    },
    {
      "epoch": 6.1493975903614455,
      "grad_norm": 0.5253714919090271,
      "learning_rate": 7.70120481927711e-06,
      "loss": 0.0194,
      "step": 51040
    },
    {
      "epoch": 6.150602409638554,
      "grad_norm": 0.7455304265022278,
      "learning_rate": 7.698795180722892e-06,
      "loss": 0.0202,
      "step": 51050
    },
    {
      "epoch": 6.151807228915662,
      "grad_norm": 0.0025555393658578396,
      "learning_rate": 7.696385542168675e-06,
      "loss": 0.0029,
      "step": 51060
    },
    {
      "epoch": 6.153012048192771,
      "grad_norm": 0.8046878576278687,
      "learning_rate": 7.69397590361446e-06,
      "loss": 0.0234,
      "step": 51070
    },
    {
      "epoch": 6.15421686746988,
      "grad_norm": 0.004871873650699854,
      "learning_rate": 7.691566265060241e-06,
      "loss": 0.0878,
      "step": 51080
    },
    {
      "epoch": 6.155421686746988,
      "grad_norm": 0.0018396900268271565,
      "learning_rate": 7.689156626506024e-06,
      "loss": 0.0183,
      "step": 51090
    },
    {
      "epoch": 6.156626506024097,
      "grad_norm": 0.04875672236084938,
      "learning_rate": 7.686746987951807e-06,
      "loss": 0.0095,
      "step": 51100
    },
    {
      "epoch": 6.1578313253012045,
      "grad_norm": 0.051753342151641846,
      "learning_rate": 7.684337349397592e-06,
      "loss": 0.0214,
      "step": 51110
    },
    {
      "epoch": 6.159036144578313,
      "grad_norm": 6.890693187713623,
      "learning_rate": 7.681927710843374e-06,
      "loss": 0.0133,
      "step": 51120
    },
    {
      "epoch": 6.160240963855422,
      "grad_norm": 6.192695617675781,
      "learning_rate": 7.679518072289157e-06,
      "loss": 0.0453,
      "step": 51130
    },
    {
      "epoch": 6.16144578313253,
      "grad_norm": 0.015749331563711166,
      "learning_rate": 7.67710843373494e-06,
      "loss": 0.0597,
      "step": 51140
    },
    {
      "epoch": 6.162650602409639,
      "grad_norm": 0.003650375409051776,
      "learning_rate": 7.674698795180723e-06,
      "loss": 0.0253,
      "step": 51150
    },
    {
      "epoch": 6.163855421686747,
      "grad_norm": 0.025441177189350128,
      "learning_rate": 7.672289156626506e-06,
      "loss": 0.0058,
      "step": 51160
    },
    {
      "epoch": 6.1650602409638555,
      "grad_norm": 0.21160055696964264,
      "learning_rate": 7.66987951807229e-06,
      "loss": 0.0027,
      "step": 51170
    },
    {
      "epoch": 6.166265060240963,
      "grad_norm": 0.023230452090501785,
      "learning_rate": 7.667469879518073e-06,
      "loss": 0.0128,
      "step": 51180
    },
    {
      "epoch": 6.167469879518072,
      "grad_norm": 0.15134280920028687,
      "learning_rate": 7.665060240963856e-06,
      "loss": 0.0032,
      "step": 51190
    },
    {
      "epoch": 6.168674698795181,
      "grad_norm": 0.004199202638119459,
      "learning_rate": 7.66265060240964e-06,
      "loss": 0.0025,
      "step": 51200
    },
    {
      "epoch": 6.169879518072289,
      "grad_norm": 0.002726907841861248,
      "learning_rate": 7.660240963855422e-06,
      "loss": 0.0107,
      "step": 51210
    },
    {
      "epoch": 6.171084337349398,
      "grad_norm": 0.2112663835287094,
      "learning_rate": 7.657831325301206e-06,
      "loss": 0.0103,
      "step": 51220
    },
    {
      "epoch": 6.172289156626506,
      "grad_norm": 1.9774374961853027,
      "learning_rate": 7.655421686746989e-06,
      "loss": 0.0244,
      "step": 51230
    },
    {
      "epoch": 6.1734939759036145,
      "grad_norm": 1.42621910572052,
      "learning_rate": 7.653012048192772e-06,
      "loss": 0.0168,
      "step": 51240
    },
    {
      "epoch": 6.174698795180723,
      "grad_norm": 3.3773975372314453,
      "learning_rate": 7.650602409638555e-06,
      "loss": 0.02,
      "step": 51250
    },
    {
      "epoch": 6.175903614457831,
      "grad_norm": 0.0024605693761259317,
      "learning_rate": 7.648192771084338e-06,
      "loss": 0.0066,
      "step": 51260
    },
    {
      "epoch": 6.17710843373494,
      "grad_norm": 0.012110674753785133,
      "learning_rate": 7.645783132530121e-06,
      "loss": 0.0165,
      "step": 51270
    },
    {
      "epoch": 6.178313253012048,
      "grad_norm": 6.60334587097168,
      "learning_rate": 7.643373493975905e-06,
      "loss": 0.0191,
      "step": 51280
    },
    {
      "epoch": 6.179518072289157,
      "grad_norm": 0.021955231204628944,
      "learning_rate": 7.640963855421688e-06,
      "loss": 0.0113,
      "step": 51290
    },
    {
      "epoch": 6.180722891566265,
      "grad_norm": 0.1530134230852127,
      "learning_rate": 7.638554216867471e-06,
      "loss": 0.0118,
      "step": 51300
    },
    {
      "epoch": 6.1819277108433734,
      "grad_norm": 0.7021334767341614,
      "learning_rate": 7.636144578313254e-06,
      "loss": 0.0084,
      "step": 51310
    },
    {
      "epoch": 6.183132530120482,
      "grad_norm": 0.13163474202156067,
      "learning_rate": 7.633734939759037e-06,
      "loss": 0.024,
      "step": 51320
    },
    {
      "epoch": 6.18433734939759,
      "grad_norm": 0.6784303784370422,
      "learning_rate": 7.631325301204819e-06,
      "loss": 0.0067,
      "step": 51330
    },
    {
      "epoch": 6.185542168674699,
      "grad_norm": 0.008227979764342308,
      "learning_rate": 7.628915662650604e-06,
      "loss": 0.0125,
      "step": 51340
    },
    {
      "epoch": 6.186746987951807,
      "grad_norm": 0.007238970138132572,
      "learning_rate": 7.626506024096386e-06,
      "loss": 0.0098,
      "step": 51350
    },
    {
      "epoch": 6.187951807228916,
      "grad_norm": 0.0013560624793171883,
      "learning_rate": 7.624096385542169e-06,
      "loss": 0.0009,
      "step": 51360
    },
    {
      "epoch": 6.1891566265060245,
      "grad_norm": 0.003095663618296385,
      "learning_rate": 7.621686746987953e-06,
      "loss": 0.0068,
      "step": 51370
    },
    {
      "epoch": 6.190361445783132,
      "grad_norm": 0.0015351451002061367,
      "learning_rate": 7.6192771084337355e-06,
      "loss": 0.0305,
      "step": 51380
    },
    {
      "epoch": 6.191566265060241,
      "grad_norm": 1.1200069189071655,
      "learning_rate": 7.616867469879519e-06,
      "loss": 0.0251,
      "step": 51390
    },
    {
      "epoch": 6.192771084337349,
      "grad_norm": 0.0030635648872703314,
      "learning_rate": 7.614457831325302e-06,
      "loss": 0.0142,
      "step": 51400
    },
    {
      "epoch": 6.193975903614458,
      "grad_norm": 0.05497349053621292,
      "learning_rate": 7.612048192771085e-06,
      "loss": 0.0116,
      "step": 51410
    },
    {
      "epoch": 6.195180722891566,
      "grad_norm": 2.1942665576934814,
      "learning_rate": 7.609638554216868e-06,
      "loss": 0.0896,
      "step": 51420
    },
    {
      "epoch": 6.196385542168675,
      "grad_norm": 0.0017525244038552046,
      "learning_rate": 7.607228915662651e-06,
      "loss": 0.0431,
      "step": 51430
    },
    {
      "epoch": 6.1975903614457835,
      "grad_norm": 1.5187690258026123,
      "learning_rate": 7.604819277108434e-06,
      "loss": 0.0523,
      "step": 51440
    },
    {
      "epoch": 6.198795180722891,
      "grad_norm": 42.213104248046875,
      "learning_rate": 7.602409638554218e-06,
      "loss": 0.015,
      "step": 51450
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.7178249955177307,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.051,
      "step": 51460
    },
    {
      "epoch": 6.201204819277108,
      "grad_norm": 0.005843954160809517,
      "learning_rate": 7.597590361445783e-06,
      "loss": 0.029,
      "step": 51470
    },
    {
      "epoch": 6.202409638554217,
      "grad_norm": 0.002291320590302348,
      "learning_rate": 7.5951807228915664e-06,
      "loss": 0.0049,
      "step": 51480
    },
    {
      "epoch": 6.203614457831326,
      "grad_norm": 1.831176519393921,
      "learning_rate": 7.5927710843373505e-06,
      "loss": 0.0162,
      "step": 51490
    },
    {
      "epoch": 6.204819277108434,
      "grad_norm": 0.02897963859140873,
      "learning_rate": 7.590361445783133e-06,
      "loss": 0.0172,
      "step": 51500
    },
    {
      "epoch": 6.206024096385542,
      "grad_norm": 0.3050222396850586,
      "learning_rate": 7.587951807228916e-06,
      "loss": 0.022,
      "step": 51510
    },
    {
      "epoch": 6.20722891566265,
      "grad_norm": 0.6670085191726685,
      "learning_rate": 7.5855421686747e-06,
      "loss": 0.0185,
      "step": 51520
    },
    {
      "epoch": 6.208433734939759,
      "grad_norm": 0.2207624763250351,
      "learning_rate": 7.583132530120483e-06,
      "loss": 0.0266,
      "step": 51530
    },
    {
      "epoch": 6.209638554216867,
      "grad_norm": 2.3264453411102295,
      "learning_rate": 7.5807228915662655e-06,
      "loss": 0.0302,
      "step": 51540
    },
    {
      "epoch": 6.210843373493976,
      "grad_norm": 1.201195240020752,
      "learning_rate": 7.578313253012049e-06,
      "loss": 0.0141,
      "step": 51550
    },
    {
      "epoch": 6.212048192771085,
      "grad_norm": 0.0033123944886028767,
      "learning_rate": 7.575903614457833e-06,
      "loss": 0.011,
      "step": 51560
    },
    {
      "epoch": 6.213253012048193,
      "grad_norm": 0.002515962580218911,
      "learning_rate": 7.573493975903615e-06,
      "loss": 0.005,
      "step": 51570
    },
    {
      "epoch": 6.214457831325301,
      "grad_norm": 0.005573913920670748,
      "learning_rate": 7.571084337349398e-06,
      "loss": 0.0034,
      "step": 51580
    },
    {
      "epoch": 6.215662650602409,
      "grad_norm": 0.004939187318086624,
      "learning_rate": 7.5686746987951805e-06,
      "loss": 0.0338,
      "step": 51590
    },
    {
      "epoch": 6.216867469879518,
      "grad_norm": 8.866435050964355,
      "learning_rate": 7.5662650602409645e-06,
      "loss": 0.0201,
      "step": 51600
    },
    {
      "epoch": 6.218072289156627,
      "grad_norm": 3.640707015991211,
      "learning_rate": 7.563855421686748e-06,
      "loss": 0.0312,
      "step": 51610
    },
    {
      "epoch": 6.219277108433735,
      "grad_norm": 0.01503768190741539,
      "learning_rate": 7.561445783132531e-06,
      "loss": 0.018,
      "step": 51620
    },
    {
      "epoch": 6.220481927710844,
      "grad_norm": 0.591464102268219,
      "learning_rate": 7.559036144578313e-06,
      "loss": 0.009,
      "step": 51630
    },
    {
      "epoch": 6.2216867469879515,
      "grad_norm": 0.25504159927368164,
      "learning_rate": 7.556626506024097e-06,
      "loss": 0.0238,
      "step": 51640
    },
    {
      "epoch": 6.22289156626506,
      "grad_norm": 0.0022558874916285276,
      "learning_rate": 7.5542168674698804e-06,
      "loss": 0.0246,
      "step": 51650
    },
    {
      "epoch": 6.224096385542168,
      "grad_norm": 0.0016539207426831126,
      "learning_rate": 7.551807228915663e-06,
      "loss": 0.0019,
      "step": 51660
    },
    {
      "epoch": 6.225301204819277,
      "grad_norm": 6.64023494720459,
      "learning_rate": 7.549397590361447e-06,
      "loss": 0.039,
      "step": 51670
    },
    {
      "epoch": 6.226506024096386,
      "grad_norm": 1.5136626958847046,
      "learning_rate": 7.54698795180723e-06,
      "loss": 0.0412,
      "step": 51680
    },
    {
      "epoch": 6.227710843373494,
      "grad_norm": 2.494029998779297,
      "learning_rate": 7.544578313253012e-06,
      "loss": 0.023,
      "step": 51690
    },
    {
      "epoch": 6.228915662650603,
      "grad_norm": 1.812002420425415,
      "learning_rate": 7.5421686746987955e-06,
      "loss": 0.0207,
      "step": 51700
    },
    {
      "epoch": 6.2301204819277105,
      "grad_norm": 1.4399534463882446,
      "learning_rate": 7.5397590361445795e-06,
      "loss": 0.0159,
      "step": 51710
    },
    {
      "epoch": 6.231325301204819,
      "grad_norm": 30.668472290039062,
      "learning_rate": 7.537349397590362e-06,
      "loss": 0.0107,
      "step": 51720
    },
    {
      "epoch": 6.232530120481928,
      "grad_norm": 0.16586433351039886,
      "learning_rate": 7.534939759036145e-06,
      "loss": 0.0098,
      "step": 51730
    },
    {
      "epoch": 6.233734939759036,
      "grad_norm": 1.162412405014038,
      "learning_rate": 7.532530120481928e-06,
      "loss": 0.0092,
      "step": 51740
    },
    {
      "epoch": 6.234939759036145,
      "grad_norm": 1.145735740661621,
      "learning_rate": 7.530120481927712e-06,
      "loss": 0.0155,
      "step": 51750
    },
    {
      "epoch": 6.236144578313253,
      "grad_norm": 0.0031335109379142523,
      "learning_rate": 7.5277108433734945e-06,
      "loss": 0.0116,
      "step": 51760
    },
    {
      "epoch": 6.2373493975903616,
      "grad_norm": 2.183030366897583,
      "learning_rate": 7.525301204819278e-06,
      "loss": 0.0241,
      "step": 51770
    },
    {
      "epoch": 6.2385542168674695,
      "grad_norm": 1.4080195426940918,
      "learning_rate": 7.52289156626506e-06,
      "loss": 0.0346,
      "step": 51780
    },
    {
      "epoch": 6.239759036144578,
      "grad_norm": 0.0015222098445519805,
      "learning_rate": 7.520481927710844e-06,
      "loss": 0.008,
      "step": 51790
    },
    {
      "epoch": 6.240963855421687,
      "grad_norm": 0.00188669643830508,
      "learning_rate": 7.518072289156627e-06,
      "loss": 0.0143,
      "step": 51800
    },
    {
      "epoch": 6.242168674698795,
      "grad_norm": 0.008282061666250229,
      "learning_rate": 7.5156626506024095e-06,
      "loss": 0.0455,
      "step": 51810
    },
    {
      "epoch": 6.243373493975904,
      "grad_norm": 31.752065658569336,
      "learning_rate": 7.5132530120481936e-06,
      "loss": 0.0304,
      "step": 51820
    },
    {
      "epoch": 6.244578313253012,
      "grad_norm": 0.31334179639816284,
      "learning_rate": 7.510843373493977e-06,
      "loss": 0.0188,
      "step": 51830
    },
    {
      "epoch": 6.2457831325301205,
      "grad_norm": 0.001092581544071436,
      "learning_rate": 7.50843373493976e-06,
      "loss": 0.0158,
      "step": 51840
    },
    {
      "epoch": 6.246987951807229,
      "grad_norm": 0.8994717597961426,
      "learning_rate": 7.506024096385542e-06,
      "loss": 0.008,
      "step": 51850
    },
    {
      "epoch": 6.248192771084337,
      "grad_norm": 0.002323104767128825,
      "learning_rate": 7.503614457831326e-06,
      "loss": 0.0049,
      "step": 51860
    },
    {
      "epoch": 6.249397590361446,
      "grad_norm": 0.004626576788723469,
      "learning_rate": 7.5012048192771094e-06,
      "loss": 0.034,
      "step": 51870
    },
    {
      "epoch": 6.250602409638554,
      "grad_norm": 1.4158977270126343,
      "learning_rate": 7.498795180722892e-06,
      "loss": 0.0015,
      "step": 51880
    },
    {
      "epoch": 6.251807228915663,
      "grad_norm": 0.001416996237821877,
      "learning_rate": 7.496385542168675e-06,
      "loss": 0.0058,
      "step": 51890
    },
    {
      "epoch": 6.253012048192771,
      "grad_norm": 0.45784905552864075,
      "learning_rate": 7.493975903614459e-06,
      "loss": 0.0019,
      "step": 51900
    },
    {
      "epoch": 6.2542168674698795,
      "grad_norm": 0.0014106298331171274,
      "learning_rate": 7.491566265060241e-06,
      "loss": 0.0071,
      "step": 51910
    },
    {
      "epoch": 6.255421686746988,
      "grad_norm": 0.35640978813171387,
      "learning_rate": 7.4891566265060245e-06,
      "loss": 0.0078,
      "step": 51920
    },
    {
      "epoch": 6.256626506024096,
      "grad_norm": 0.0016634475905448198,
      "learning_rate": 7.486746987951808e-06,
      "loss": 0.0031,
      "step": 51930
    },
    {
      "epoch": 6.257831325301205,
      "grad_norm": 6.715057849884033,
      "learning_rate": 7.484337349397592e-06,
      "loss": 0.0453,
      "step": 51940
    },
    {
      "epoch": 6.259036144578313,
      "grad_norm": 0.014048234559595585,
      "learning_rate": 7.481927710843374e-06,
      "loss": 0.0029,
      "step": 51950
    },
    {
      "epoch": 6.260240963855422,
      "grad_norm": 0.002733327681198716,
      "learning_rate": 7.479518072289157e-06,
      "loss": 0.0283,
      "step": 51960
    },
    {
      "epoch": 6.2614457831325305,
      "grad_norm": 7.513516902923584,
      "learning_rate": 7.477108433734941e-06,
      "loss": 0.0117,
      "step": 51970
    },
    {
      "epoch": 6.2626506024096384,
      "grad_norm": 0.0014427576679736376,
      "learning_rate": 7.4746987951807235e-06,
      "loss": 0.001,
      "step": 51980
    },
    {
      "epoch": 6.263855421686747,
      "grad_norm": 0.0018719909712672234,
      "learning_rate": 7.472289156626507e-06,
      "loss": 0.0591,
      "step": 51990
    },
    {
      "epoch": 6.265060240963855,
      "grad_norm": 0.18667085468769073,
      "learning_rate": 7.469879518072289e-06,
      "loss": 0.0121,
      "step": 52000
    },
    {
      "epoch": 6.266265060240964,
      "grad_norm": 0.3081425726413727,
      "learning_rate": 7.467469879518073e-06,
      "loss": 0.0114,
      "step": 52010
    },
    {
      "epoch": 6.267469879518072,
      "grad_norm": 0.001686571165919304,
      "learning_rate": 7.465060240963856e-06,
      "loss": 0.0048,
      "step": 52020
    },
    {
      "epoch": 6.268674698795181,
      "grad_norm": 1.2073322534561157,
      "learning_rate": 7.462650602409639e-06,
      "loss": 0.0318,
      "step": 52030
    },
    {
      "epoch": 6.2698795180722895,
      "grad_norm": 1.9032236337661743,
      "learning_rate": 7.460240963855422e-06,
      "loss": 0.0639,
      "step": 52040
    },
    {
      "epoch": 6.271084337349397,
      "grad_norm": 0.004532101098448038,
      "learning_rate": 7.457831325301206e-06,
      "loss": 0.0101,
      "step": 52050
    },
    {
      "epoch": 6.272289156626506,
      "grad_norm": 0.0020710122771561146,
      "learning_rate": 7.455421686746989e-06,
      "loss": 0.0069,
      "step": 52060
    },
    {
      "epoch": 6.273493975903614,
      "grad_norm": 0.0013380893506109715,
      "learning_rate": 7.453012048192771e-06,
      "loss": 0.0149,
      "step": 52070
    },
    {
      "epoch": 6.274698795180723,
      "grad_norm": 0.0034867441281676292,
      "learning_rate": 7.4506024096385545e-06,
      "loss": 0.0085,
      "step": 52080
    },
    {
      "epoch": 6.275903614457832,
      "grad_norm": 0.15310238301753998,
      "learning_rate": 7.4481927710843385e-06,
      "loss": 0.003,
      "step": 52090
    },
    {
      "epoch": 6.27710843373494,
      "grad_norm": 0.001328179845586419,
      "learning_rate": 7.445783132530121e-06,
      "loss": 0.0004,
      "step": 52100
    },
    {
      "epoch": 6.2783132530120485,
      "grad_norm": 4.203824043273926,
      "learning_rate": 7.443373493975904e-06,
      "loss": 0.0262,
      "step": 52110
    },
    {
      "epoch": 6.279518072289156,
      "grad_norm": 0.003816453041508794,
      "learning_rate": 7.440963855421688e-06,
      "loss": 0.0001,
      "step": 52120
    },
    {
      "epoch": 6.280722891566265,
      "grad_norm": 0.0015502391615882516,
      "learning_rate": 7.43855421686747e-06,
      "loss": 0.0136,
      "step": 52130
    },
    {
      "epoch": 6.281927710843373,
      "grad_norm": 0.004936391022056341,
      "learning_rate": 7.4361445783132535e-06,
      "loss": 0.0562,
      "step": 52140
    },
    {
      "epoch": 6.283132530120482,
      "grad_norm": 0.004376646596938372,
      "learning_rate": 7.433734939759037e-06,
      "loss": 0.0369,
      "step": 52150
    },
    {
      "epoch": 6.284337349397591,
      "grad_norm": 0.003161063650622964,
      "learning_rate": 7.431325301204821e-06,
      "loss": 0.0049,
      "step": 52160
    },
    {
      "epoch": 6.285542168674699,
      "grad_norm": 0.021315205842256546,
      "learning_rate": 7.428915662650603e-06,
      "loss": 0.0152,
      "step": 52170
    },
    {
      "epoch": 6.286746987951807,
      "grad_norm": 0.18898233771324158,
      "learning_rate": 7.426506024096386e-06,
      "loss": 0.0104,
      "step": 52180
    },
    {
      "epoch": 6.287951807228915,
      "grad_norm": 0.0038804677315056324,
      "learning_rate": 7.4240963855421685e-06,
      "loss": 0.0231,
      "step": 52190
    },
    {
      "epoch": 6.289156626506024,
      "grad_norm": 0.0023288088850677013,
      "learning_rate": 7.4216867469879526e-06,
      "loss": 0.0258,
      "step": 52200
    },
    {
      "epoch": 6.290361445783133,
      "grad_norm": 0.0036298823542892933,
      "learning_rate": 7.419277108433736e-06,
      "loss": 0.0124,
      "step": 52210
    },
    {
      "epoch": 6.291566265060241,
      "grad_norm": 2.1175239086151123,
      "learning_rate": 7.416867469879518e-06,
      "loss": 0.0261,
      "step": 52220
    },
    {
      "epoch": 6.29277108433735,
      "grad_norm": 1.581304907798767,
      "learning_rate": 7.414457831325301e-06,
      "loss": 0.0126,
      "step": 52230
    },
    {
      "epoch": 6.293975903614458,
      "grad_norm": 1.2500810623168945,
      "learning_rate": 7.412048192771085e-06,
      "loss": 0.0067,
      "step": 52240
    },
    {
      "epoch": 6.295180722891566,
      "grad_norm": 0.023885667324066162,
      "learning_rate": 7.4096385542168684e-06,
      "loss": 0.0236,
      "step": 52250
    },
    {
      "epoch": 6.296385542168674,
      "grad_norm": 0.0025110668502748013,
      "learning_rate": 7.407228915662651e-06,
      "loss": 0.0143,
      "step": 52260
    },
    {
      "epoch": 6.297590361445783,
      "grad_norm": 17.900766372680664,
      "learning_rate": 7.404819277108435e-06,
      "loss": 0.0207,
      "step": 52270
    },
    {
      "epoch": 6.298795180722892,
      "grad_norm": 1.198048710823059,
      "learning_rate": 7.402409638554218e-06,
      "loss": 0.0191,
      "step": 52280
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.002907552756369114,
      "learning_rate": 7.4e-06,
      "loss": 0.0184,
      "step": 52290
    },
    {
      "epoch": 6.301204819277109,
      "grad_norm": 1.5008176565170288,
      "learning_rate": 7.3975903614457835e-06,
      "loss": 0.0056,
      "step": 52300
    },
    {
      "epoch": 6.3024096385542165,
      "grad_norm": 0.0013299869606271386,
      "learning_rate": 7.3951807228915675e-06,
      "loss": 0.0045,
      "step": 52310
    },
    {
      "epoch": 6.303614457831325,
      "grad_norm": 0.6914839148521423,
      "learning_rate": 7.39277108433735e-06,
      "loss": 0.0103,
      "step": 52320
    },
    {
      "epoch": 6.304819277108434,
      "grad_norm": 0.01739415153861046,
      "learning_rate": 7.390361445783133e-06,
      "loss": 0.0321,
      "step": 52330
    },
    {
      "epoch": 6.306024096385542,
      "grad_norm": 0.0019175226334482431,
      "learning_rate": 7.387951807228916e-06,
      "loss": 0.0009,
      "step": 52340
    },
    {
      "epoch": 6.307228915662651,
      "grad_norm": 2.6018760204315186,
      "learning_rate": 7.385542168674699e-06,
      "loss": 0.0232,
      "step": 52350
    },
    {
      "epoch": 6.308433734939759,
      "grad_norm": 3.1042401790618896,
      "learning_rate": 7.3831325301204825e-06,
      "loss": 0.0155,
      "step": 52360
    },
    {
      "epoch": 6.309638554216868,
      "grad_norm": 0.015870744362473488,
      "learning_rate": 7.380722891566266e-06,
      "loss": 0.0074,
      "step": 52370
    },
    {
      "epoch": 6.3108433734939755,
      "grad_norm": 2.4529478549957275,
      "learning_rate": 7.378313253012048e-06,
      "loss": 0.0538,
      "step": 52380
    },
    {
      "epoch": 6.312048192771084,
      "grad_norm": 0.33414319157600403,
      "learning_rate": 7.375903614457832e-06,
      "loss": 0.0063,
      "step": 52390
    },
    {
      "epoch": 6.313253012048193,
      "grad_norm": 0.5662105679512024,
      "learning_rate": 7.373493975903615e-06,
      "loss": 0.0184,
      "step": 52400
    },
    {
      "epoch": 6.314457831325301,
      "grad_norm": 3.9646661281585693,
      "learning_rate": 7.3710843373493976e-06,
      "loss": 0.0494,
      "step": 52410
    },
    {
      "epoch": 6.31566265060241,
      "grad_norm": 0.004554147366434336,
      "learning_rate": 7.368674698795182e-06,
      "loss": 0.0298,
      "step": 52420
    },
    {
      "epoch": 6.316867469879518,
      "grad_norm": 0.003473208751529455,
      "learning_rate": 7.366265060240965e-06,
      "loss": 0.0086,
      "step": 52430
    },
    {
      "epoch": 6.3180722891566266,
      "grad_norm": 0.024100635200738907,
      "learning_rate": 7.363855421686747e-06,
      "loss": 0.037,
      "step": 52440
    },
    {
      "epoch": 6.3192771084337345,
      "grad_norm": 0.05591487139463425,
      "learning_rate": 7.36144578313253e-06,
      "loss": 0.0303,
      "step": 52450
    },
    {
      "epoch": 6.320481927710843,
      "grad_norm": 0.08188285678625107,
      "learning_rate": 7.359036144578314e-06,
      "loss": 0.04,
      "step": 52460
    },
    {
      "epoch": 6.321686746987952,
      "grad_norm": 0.3281112015247345,
      "learning_rate": 7.3566265060240975e-06,
      "loss": 0.0164,
      "step": 52470
    },
    {
      "epoch": 6.32289156626506,
      "grad_norm": 0.00948183611035347,
      "learning_rate": 7.35421686746988e-06,
      "loss": 0.0081,
      "step": 52480
    },
    {
      "epoch": 6.324096385542169,
      "grad_norm": 0.5860310196876526,
      "learning_rate": 7.351807228915663e-06,
      "loss": 0.0144,
      "step": 52490
    },
    {
      "epoch": 6.325301204819277,
      "grad_norm": 1.193568468093872,
      "learning_rate": 7.349397590361447e-06,
      "loss": 0.0181,
      "step": 52500
    },
    {
      "epoch": 6.3265060240963855,
      "grad_norm": 0.007173606660217047,
      "learning_rate": 7.346987951807229e-06,
      "loss": 0.0144,
      "step": 52510
    },
    {
      "epoch": 6.327710843373494,
      "grad_norm": 0.0039217509329319,
      "learning_rate": 7.3445783132530125e-06,
      "loss": 0.0083,
      "step": 52520
    },
    {
      "epoch": 6.328915662650602,
      "grad_norm": 0.5065012574195862,
      "learning_rate": 7.342168674698795e-06,
      "loss": 0.0343,
      "step": 52530
    },
    {
      "epoch": 6.330120481927711,
      "grad_norm": 0.2227664738893509,
      "learning_rate": 7.339759036144579e-06,
      "loss": 0.055,
      "step": 52540
    },
    {
      "epoch": 6.331325301204819,
      "grad_norm": 0.0037585864774882793,
      "learning_rate": 7.337349397590362e-06,
      "loss": 0.0229,
      "step": 52550
    },
    {
      "epoch": 6.332530120481928,
      "grad_norm": 0.0029265638440847397,
      "learning_rate": 7.334939759036145e-06,
      "loss": 0.0079,
      "step": 52560
    },
    {
      "epoch": 6.333734939759037,
      "grad_norm": 1.6979727745056152,
      "learning_rate": 7.332530120481928e-06,
      "loss": 0.0266,
      "step": 52570
    },
    {
      "epoch": 6.3349397590361445,
      "grad_norm": 0.005161043256521225,
      "learning_rate": 7.3301204819277116e-06,
      "loss": 0.007,
      "step": 52580
    },
    {
      "epoch": 6.336144578313253,
      "grad_norm": 0.5578383207321167,
      "learning_rate": 7.327710843373495e-06,
      "loss": 0.0145,
      "step": 52590
    },
    {
      "epoch": 6.337349397590361,
      "grad_norm": 0.8846331238746643,
      "learning_rate": 7.325301204819277e-06,
      "loss": 0.0124,
      "step": 52600
    },
    {
      "epoch": 6.33855421686747,
      "grad_norm": 0.0830029845237732,
      "learning_rate": 7.322891566265061e-06,
      "loss": 0.0014,
      "step": 52610
    },
    {
      "epoch": 6.339759036144578,
      "grad_norm": 0.3403993844985962,
      "learning_rate": 7.320481927710844e-06,
      "loss": 0.024,
      "step": 52620
    },
    {
      "epoch": 6.340963855421687,
      "grad_norm": 19.802494049072266,
      "learning_rate": 7.318072289156627e-06,
      "loss": 0.0211,
      "step": 52630
    },
    {
      "epoch": 6.3421686746987955,
      "grad_norm": 0.5153096914291382,
      "learning_rate": 7.31566265060241e-06,
      "loss": 0.0077,
      "step": 52640
    },
    {
      "epoch": 6.343373493975903,
      "grad_norm": 0.0028623996768146753,
      "learning_rate": 7.313253012048194e-06,
      "loss": 0.0512,
      "step": 52650
    },
    {
      "epoch": 6.344578313253012,
      "grad_norm": 0.03206874802708626,
      "learning_rate": 7.310843373493977e-06,
      "loss": 0.0238,
      "step": 52660
    },
    {
      "epoch": 6.34578313253012,
      "grad_norm": 0.004873061552643776,
      "learning_rate": 7.308433734939759e-06,
      "loss": 0.0076,
      "step": 52670
    },
    {
      "epoch": 6.346987951807229,
      "grad_norm": 0.01327428501099348,
      "learning_rate": 7.3060240963855425e-06,
      "loss": 0.0216,
      "step": 52680
    },
    {
      "epoch": 6.348192771084337,
      "grad_norm": 0.0017803858499974012,
      "learning_rate": 7.3036144578313265e-06,
      "loss": 0.0115,
      "step": 52690
    },
    {
      "epoch": 6.349397590361446,
      "grad_norm": 0.007370047736912966,
      "learning_rate": 7.301204819277109e-06,
      "loss": 0.018,
      "step": 52700
    },
    {
      "epoch": 6.3506024096385545,
      "grad_norm": 0.6364609599113464,
      "learning_rate": 7.298795180722892e-06,
      "loss": 0.0091,
      "step": 52710
    },
    {
      "epoch": 6.351807228915662,
      "grad_norm": 1.7005722522735596,
      "learning_rate": 7.296385542168676e-06,
      "loss": 0.0636,
      "step": 52720
    },
    {
      "epoch": 6.353012048192771,
      "grad_norm": 0.49461328983306885,
      "learning_rate": 7.293975903614458e-06,
      "loss": 0.0238,
      "step": 52730
    },
    {
      "epoch": 6.354216867469879,
      "grad_norm": 1.141955018043518,
      "learning_rate": 7.2915662650602415e-06,
      "loss": 0.0448,
      "step": 52740
    },
    {
      "epoch": 6.355421686746988,
      "grad_norm": 1.949122667312622,
      "learning_rate": 7.289156626506025e-06,
      "loss": 0.0313,
      "step": 52750
    },
    {
      "epoch": 6.356626506024097,
      "grad_norm": 0.003294840455055237,
      "learning_rate": 7.286746987951808e-06,
      "loss": 0.0352,
      "step": 52760
    },
    {
      "epoch": 6.357831325301205,
      "grad_norm": 4.739964008331299,
      "learning_rate": 7.284337349397591e-06,
      "loss": 0.0459,
      "step": 52770
    },
    {
      "epoch": 6.3590361445783135,
      "grad_norm": 1.972669243812561,
      "learning_rate": 7.281927710843374e-06,
      "loss": 0.0095,
      "step": 52780
    },
    {
      "epoch": 6.360240963855421,
      "grad_norm": 0.176751509308815,
      "learning_rate": 7.2795180722891566e-06,
      "loss": 0.0011,
      "step": 52790
    },
    {
      "epoch": 6.36144578313253,
      "grad_norm": 0.03625790402293205,
      "learning_rate": 7.277108433734941e-06,
      "loss": 0.0117,
      "step": 52800
    },
    {
      "epoch": 6.362650602409639,
      "grad_norm": 1.0208834409713745,
      "learning_rate": 7.274698795180724e-06,
      "loss": 0.0401,
      "step": 52810
    },
    {
      "epoch": 6.363855421686747,
      "grad_norm": 3.9974429607391357,
      "learning_rate": 7.272289156626506e-06,
      "loss": 0.0491,
      "step": 52820
    },
    {
      "epoch": 6.365060240963856,
      "grad_norm": 0.06256567686796188,
      "learning_rate": 7.269879518072289e-06,
      "loss": 0.0633,
      "step": 52830
    },
    {
      "epoch": 6.366265060240964,
      "grad_norm": 0.011981518939137459,
      "learning_rate": 7.267469879518073e-06,
      "loss": 0.0234,
      "step": 52840
    },
    {
      "epoch": 6.367469879518072,
      "grad_norm": 0.8033086657524109,
      "learning_rate": 7.265060240963856e-06,
      "loss": 0.0122,
      "step": 52850
    },
    {
      "epoch": 6.36867469879518,
      "grad_norm": 0.6705750823020935,
      "learning_rate": 7.262650602409639e-06,
      "loss": 0.0256,
      "step": 52860
    },
    {
      "epoch": 6.369879518072289,
      "grad_norm": 0.0034238044172525406,
      "learning_rate": 7.260240963855423e-06,
      "loss": 0.0384,
      "step": 52870
    },
    {
      "epoch": 6.371084337349398,
      "grad_norm": 0.03058580495417118,
      "learning_rate": 7.257831325301206e-06,
      "loss": 0.0189,
      "step": 52880
    },
    {
      "epoch": 6.372289156626506,
      "grad_norm": 1.4913089275360107,
      "learning_rate": 7.255421686746988e-06,
      "loss": 0.0262,
      "step": 52890
    },
    {
      "epoch": 6.373493975903615,
      "grad_norm": 0.013958247378468513,
      "learning_rate": 7.2530120481927715e-06,
      "loss": 0.0088,
      "step": 52900
    },
    {
      "epoch": 6.374698795180723,
      "grad_norm": 0.056272540241479874,
      "learning_rate": 7.2506024096385555e-06,
      "loss": 0.008,
      "step": 52910
    },
    {
      "epoch": 6.375903614457831,
      "grad_norm": 0.002722605364397168,
      "learning_rate": 7.248192771084338e-06,
      "loss": 0.0312,
      "step": 52920
    },
    {
      "epoch": 6.377108433734939,
      "grad_norm": 6.873640060424805,
      "learning_rate": 7.245783132530121e-06,
      "loss": 0.0507,
      "step": 52930
    },
    {
      "epoch": 6.378313253012048,
      "grad_norm": 0.23784685134887695,
      "learning_rate": 7.243373493975903e-06,
      "loss": 0.0175,
      "step": 52940
    },
    {
      "epoch": 6.379518072289157,
      "grad_norm": 0.026505954563617706,
      "learning_rate": 7.240963855421687e-06,
      "loss": 0.0039,
      "step": 52950
    },
    {
      "epoch": 6.380722891566265,
      "grad_norm": 0.003276466391980648,
      "learning_rate": 7.2385542168674706e-06,
      "loss": 0.0048,
      "step": 52960
    },
    {
      "epoch": 6.381927710843374,
      "grad_norm": 0.03069903329014778,
      "learning_rate": 7.236144578313254e-06,
      "loss": 0.0331,
      "step": 52970
    },
    {
      "epoch": 6.3831325301204815,
      "grad_norm": 0.02674155868589878,
      "learning_rate": 7.233734939759037e-06,
      "loss": 0.0133,
      "step": 52980
    },
    {
      "epoch": 6.38433734939759,
      "grad_norm": 0.010515235364437103,
      "learning_rate": 7.23132530120482e-06,
      "loss": 0.005,
      "step": 52990
    },
    {
      "epoch": 6.385542168674699,
      "grad_norm": 0.2809494435787201,
      "learning_rate": 7.228915662650603e-06,
      "loss": 0.0108,
      "step": 53000
    },
    {
      "epoch": 6.386746987951807,
      "grad_norm": 0.027894152328372,
      "learning_rate": 7.226506024096386e-06,
      "loss": 0.0045,
      "step": 53010
    },
    {
      "epoch": 6.387951807228916,
      "grad_norm": 0.004967418033629656,
      "learning_rate": 7.22409638554217e-06,
      "loss": 0.0093,
      "step": 53020
    },
    {
      "epoch": 6.389156626506024,
      "grad_norm": 0.0018952295649796724,
      "learning_rate": 7.221686746987953e-06,
      "loss": 0.0059,
      "step": 53030
    },
    {
      "epoch": 6.390361445783133,
      "grad_norm": 0.23687395453453064,
      "learning_rate": 7.219277108433735e-06,
      "loss": 0.003,
      "step": 53040
    },
    {
      "epoch": 6.391566265060241,
      "grad_norm": 0.00464861374348402,
      "learning_rate": 7.216867469879518e-06,
      "loss": 0.0197,
      "step": 53050
    },
    {
      "epoch": 6.392771084337349,
      "grad_norm": 0.004090213682502508,
      "learning_rate": 7.214457831325302e-06,
      "loss": 0.0287,
      "step": 53060
    },
    {
      "epoch": 6.393975903614458,
      "grad_norm": 0.0076530915684998035,
      "learning_rate": 7.212048192771085e-06,
      "loss": 0.0008,
      "step": 53070
    },
    {
      "epoch": 6.395180722891566,
      "grad_norm": 1.4902352094650269,
      "learning_rate": 7.209638554216868e-06,
      "loss": 0.0207,
      "step": 53080
    },
    {
      "epoch": 6.396385542168675,
      "grad_norm": 0.004365170374512672,
      "learning_rate": 7.207228915662651e-06,
      "loss": 0.0043,
      "step": 53090
    },
    {
      "epoch": 6.397590361445783,
      "grad_norm": 0.0012443250743672252,
      "learning_rate": 7.204819277108435e-06,
      "loss": 0.027,
      "step": 53100
    },
    {
      "epoch": 6.3987951807228916,
      "grad_norm": 0.0014091995544731617,
      "learning_rate": 7.202409638554217e-06,
      "loss": 0.0273,
      "step": 53110
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.0023694008123129606,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0437,
      "step": 53120
    },
    {
      "epoch": 6.401204819277108,
      "grad_norm": 0.0018780863611027598,
      "learning_rate": 7.1975903614457845e-06,
      "loss": 0.009,
      "step": 53130
    },
    {
      "epoch": 6.402409638554217,
      "grad_norm": 0.025218268856406212,
      "learning_rate": 7.195180722891567e-06,
      "loss": 0.0131,
      "step": 53140
    },
    {
      "epoch": 6.403614457831325,
      "grad_norm": 0.0019595229532569647,
      "learning_rate": 7.19277108433735e-06,
      "loss": 0.014,
      "step": 53150
    },
    {
      "epoch": 6.404819277108434,
      "grad_norm": 0.0020841050427407026,
      "learning_rate": 7.190361445783132e-06,
      "loss": 0.0245,
      "step": 53160
    },
    {
      "epoch": 6.406024096385542,
      "grad_norm": 0.009111687541007996,
      "learning_rate": 7.187951807228916e-06,
      "loss": 0.0454,
      "step": 53170
    },
    {
      "epoch": 6.4072289156626505,
      "grad_norm": 2.18682861328125,
      "learning_rate": 7.1855421686747e-06,
      "loss": 0.0265,
      "step": 53180
    },
    {
      "epoch": 6.408433734939759,
      "grad_norm": 0.6290281414985657,
      "learning_rate": 7.183132530120483e-06,
      "loss": 0.0564,
      "step": 53190
    },
    {
      "epoch": 6.409638554216867,
      "grad_norm": 0.009412914514541626,
      "learning_rate": 7.180722891566265e-06,
      "loss": 0.0163,
      "step": 53200
    },
    {
      "epoch": 6.410843373493976,
      "grad_norm": 0.005931869614869356,
      "learning_rate": 7.178313253012049e-06,
      "loss": 0.0348,
      "step": 53210
    },
    {
      "epoch": 6.412048192771084,
      "grad_norm": 0.31637394428253174,
      "learning_rate": 7.175903614457832e-06,
      "loss": 0.0072,
      "step": 53220
    },
    {
      "epoch": 6.413253012048193,
      "grad_norm": 1.1077734231948853,
      "learning_rate": 7.173493975903615e-06,
      "loss": 0.0145,
      "step": 53230
    },
    {
      "epoch": 6.414457831325302,
      "grad_norm": 0.030141448602080345,
      "learning_rate": 7.171084337349398e-06,
      "loss": 0.0004,
      "step": 53240
    },
    {
      "epoch": 6.4156626506024095,
      "grad_norm": 34.85843276977539,
      "learning_rate": 7.168674698795182e-06,
      "loss": 0.0308,
      "step": 53250
    },
    {
      "epoch": 6.416867469879518,
      "grad_norm": 0.004874780308455229,
      "learning_rate": 7.166265060240964e-06,
      "loss": 0.0207,
      "step": 53260
    },
    {
      "epoch": 6.418072289156626,
      "grad_norm": 6.7881245613098145,
      "learning_rate": 7.163855421686747e-06,
      "loss": 0.0189,
      "step": 53270
    },
    {
      "epoch": 6.419277108433735,
      "grad_norm": 0.08748510479927063,
      "learning_rate": 7.161445783132531e-06,
      "loss": 0.0154,
      "step": 53280
    },
    {
      "epoch": 6.420481927710844,
      "grad_norm": 4.314089775085449,
      "learning_rate": 7.159036144578314e-06,
      "loss": 0.0194,
      "step": 53290
    },
    {
      "epoch": 6.421686746987952,
      "grad_norm": 0.0052268472500145435,
      "learning_rate": 7.156626506024097e-06,
      "loss": 0.002,
      "step": 53300
    },
    {
      "epoch": 6.4228915662650605,
      "grad_norm": 0.010485696606338024,
      "learning_rate": 7.15421686746988e-06,
      "loss": 0.0181,
      "step": 53310
    },
    {
      "epoch": 6.424096385542168,
      "grad_norm": 0.7381253242492676,
      "learning_rate": 7.151807228915664e-06,
      "loss": 0.0116,
      "step": 53320
    },
    {
      "epoch": 6.425301204819277,
      "grad_norm": 9.397682189941406,
      "learning_rate": 7.149397590361446e-06,
      "loss": 0.0285,
      "step": 53330
    },
    {
      "epoch": 6.426506024096385,
      "grad_norm": 0.0023210765793919563,
      "learning_rate": 7.1469879518072295e-06,
      "loss": 0.0167,
      "step": 53340
    },
    {
      "epoch": 6.427710843373494,
      "grad_norm": 0.026915909722447395,
      "learning_rate": 7.144578313253012e-06,
      "loss": 0.0671,
      "step": 53350
    },
    {
      "epoch": 6.428915662650603,
      "grad_norm": 0.03382435068488121,
      "learning_rate": 7.142168674698796e-06,
      "loss": 0.0262,
      "step": 53360
    },
    {
      "epoch": 6.430120481927711,
      "grad_norm": 3.4002485275268555,
      "learning_rate": 7.139759036144579e-06,
      "loss": 0.0152,
      "step": 53370
    },
    {
      "epoch": 6.4313253012048195,
      "grad_norm": 0.0041173407807946205,
      "learning_rate": 7.137349397590362e-06,
      "loss": 0.0089,
      "step": 53380
    },
    {
      "epoch": 6.432530120481927,
      "grad_norm": 0.27071890234947205,
      "learning_rate": 7.134939759036145e-06,
      "loss": 0.0314,
      "step": 53390
    },
    {
      "epoch": 6.433734939759036,
      "grad_norm": 0.0028990546707063913,
      "learning_rate": 7.132530120481929e-06,
      "loss": 0.0222,
      "step": 53400
    },
    {
      "epoch": 6.434939759036144,
      "grad_norm": 0.010024934075772762,
      "learning_rate": 7.130120481927712e-06,
      "loss": 0.0049,
      "step": 53410
    },
    {
      "epoch": 6.436144578313253,
      "grad_norm": 0.7474974989891052,
      "learning_rate": 7.127710843373494e-06,
      "loss": 0.0181,
      "step": 53420
    },
    {
      "epoch": 6.437349397590362,
      "grad_norm": 0.002592293079942465,
      "learning_rate": 7.125301204819278e-06,
      "loss": 0.0173,
      "step": 53430
    },
    {
      "epoch": 6.43855421686747,
      "grad_norm": 0.8601548671722412,
      "learning_rate": 7.122891566265061e-06,
      "loss": 0.0122,
      "step": 53440
    },
    {
      "epoch": 6.4397590361445785,
      "grad_norm": 0.0021233470179140568,
      "learning_rate": 7.120481927710844e-06,
      "loss": 0.0087,
      "step": 53450
    },
    {
      "epoch": 6.440963855421686,
      "grad_norm": 0.0033093304373323917,
      "learning_rate": 7.118072289156627e-06,
      "loss": 0.0087,
      "step": 53460
    },
    {
      "epoch": 6.442168674698795,
      "grad_norm": 1.8080335855484009,
      "learning_rate": 7.115662650602411e-06,
      "loss": 0.0469,
      "step": 53470
    },
    {
      "epoch": 6.443373493975904,
      "grad_norm": 0.058620721101760864,
      "learning_rate": 7.113253012048193e-06,
      "loss": 0.0055,
      "step": 53480
    },
    {
      "epoch": 6.444578313253012,
      "grad_norm": 0.0020335353910923004,
      "learning_rate": 7.110843373493976e-06,
      "loss": 0.0107,
      "step": 53490
    },
    {
      "epoch": 6.445783132530121,
      "grad_norm": 0.07783611118793488,
      "learning_rate": 7.1084337349397595e-06,
      "loss": 0.0186,
      "step": 53500
    },
    {
      "epoch": 6.446987951807229,
      "grad_norm": 0.050710976123809814,
      "learning_rate": 7.1060240963855435e-06,
      "loss": 0.0414,
      "step": 53510
    },
    {
      "epoch": 6.448192771084337,
      "grad_norm": 0.053779687732458115,
      "learning_rate": 7.103614457831326e-06,
      "loss": 0.0486,
      "step": 53520
    },
    {
      "epoch": 6.449397590361446,
      "grad_norm": 0.002343575470149517,
      "learning_rate": 7.101204819277109e-06,
      "loss": 0.0118,
      "step": 53530
    },
    {
      "epoch": 6.450602409638554,
      "grad_norm": 0.005265691317617893,
      "learning_rate": 7.098795180722891e-06,
      "loss": 0.0173,
      "step": 53540
    },
    {
      "epoch": 6.451807228915663,
      "grad_norm": 0.01286186184734106,
      "learning_rate": 7.096385542168675e-06,
      "loss": 0.0162,
      "step": 53550
    },
    {
      "epoch": 6.453012048192771,
      "grad_norm": 0.0017636563861742616,
      "learning_rate": 7.0939759036144586e-06,
      "loss": 0.0011,
      "step": 53560
    },
    {
      "epoch": 6.45421686746988,
      "grad_norm": 0.005858412012457848,
      "learning_rate": 7.091566265060241e-06,
      "loss": 0.0255,
      "step": 53570
    },
    {
      "epoch": 6.455421686746988,
      "grad_norm": 0.0389874204993248,
      "learning_rate": 7.089156626506025e-06,
      "loss": 0.0174,
      "step": 53580
    },
    {
      "epoch": 6.456626506024096,
      "grad_norm": 0.6902627944946289,
      "learning_rate": 7.086746987951808e-06,
      "loss": 0.0038,
      "step": 53590
    },
    {
      "epoch": 6.457831325301205,
      "grad_norm": 0.01255982369184494,
      "learning_rate": 7.084337349397591e-06,
      "loss": 0.0045,
      "step": 53600
    },
    {
      "epoch": 6.459036144578313,
      "grad_norm": 0.10980150103569031,
      "learning_rate": 7.081927710843374e-06,
      "loss": 0.0121,
      "step": 53610
    },
    {
      "epoch": 6.460240963855422,
      "grad_norm": 33.436241149902344,
      "learning_rate": 7.079518072289158e-06,
      "loss": 0.0334,
      "step": 53620
    },
    {
      "epoch": 6.46144578313253,
      "grad_norm": 0.05587982013821602,
      "learning_rate": 7.077108433734941e-06,
      "loss": 0.0049,
      "step": 53630
    },
    {
      "epoch": 6.462650602409639,
      "grad_norm": 0.001981083769351244,
      "learning_rate": 7.074698795180723e-06,
      "loss": 0.0033,
      "step": 53640
    },
    {
      "epoch": 6.4638554216867465,
      "grad_norm": 0.0502341091632843,
      "learning_rate": 7.072289156626506e-06,
      "loss": 0.0192,
      "step": 53650
    },
    {
      "epoch": 6.465060240963855,
      "grad_norm": 0.0023278328590095043,
      "learning_rate": 7.06987951807229e-06,
      "loss": 0.0006,
      "step": 53660
    },
    {
      "epoch": 6.466265060240964,
      "grad_norm": 0.0018416906241327524,
      "learning_rate": 7.067469879518073e-06,
      "loss": 0.0011,
      "step": 53670
    },
    {
      "epoch": 6.467469879518072,
      "grad_norm": 5.787768363952637,
      "learning_rate": 7.065060240963856e-06,
      "loss": 0.0376,
      "step": 53680
    },
    {
      "epoch": 6.468674698795181,
      "grad_norm": 0.26764413714408875,
      "learning_rate": 7.062650602409639e-06,
      "loss": 0.0135,
      "step": 53690
    },
    {
      "epoch": 6.469879518072289,
      "grad_norm": 0.1215800940990448,
      "learning_rate": 7.060240963855422e-06,
      "loss": 0.0163,
      "step": 53700
    },
    {
      "epoch": 6.471084337349398,
      "grad_norm": 0.007203280925750732,
      "learning_rate": 7.057831325301205e-06,
      "loss": 0.0264,
      "step": 53710
    },
    {
      "epoch": 6.472289156626506,
      "grad_norm": 0.002675263676792383,
      "learning_rate": 7.0554216867469885e-06,
      "loss": 0.0043,
      "step": 53720
    },
    {
      "epoch": 6.473493975903614,
      "grad_norm": 0.0013825466157868505,
      "learning_rate": 7.0530120481927726e-06,
      "loss": 0.0025,
      "step": 53730
    },
    {
      "epoch": 6.474698795180723,
      "grad_norm": 1.5055629014968872,
      "learning_rate": 7.050602409638555e-06,
      "loss": 0.045,
      "step": 53740
    },
    {
      "epoch": 6.475903614457831,
      "grad_norm": 0.0010247398167848587,
      "learning_rate": 7.048192771084338e-06,
      "loss": 0.0078,
      "step": 53750
    },
    {
      "epoch": 6.47710843373494,
      "grad_norm": 0.18486689031124115,
      "learning_rate": 7.04578313253012e-06,
      "loss": 0.0138,
      "step": 53760
    },
    {
      "epoch": 6.478313253012049,
      "grad_norm": 0.0010617019142955542,
      "learning_rate": 7.043373493975904e-06,
      "loss": 0.0072,
      "step": 53770
    },
    {
      "epoch": 6.4795180722891565,
      "grad_norm": 0.00310148810967803,
      "learning_rate": 7.040963855421688e-06,
      "loss": 0.0328,
      "step": 53780
    },
    {
      "epoch": 6.480722891566265,
      "grad_norm": 10.114387512207031,
      "learning_rate": 7.03855421686747e-06,
      "loss": 0.0073,
      "step": 53790
    },
    {
      "epoch": 6.481927710843373,
      "grad_norm": 0.0010612019104883075,
      "learning_rate": 7.036144578313253e-06,
      "loss": 0.0211,
      "step": 53800
    },
    {
      "epoch": 6.483132530120482,
      "grad_norm": 1.9664864540100098,
      "learning_rate": 7.033734939759037e-06,
      "loss": 0.0092,
      "step": 53810
    },
    {
      "epoch": 6.48433734939759,
      "grad_norm": 2.480851650238037,
      "learning_rate": 7.03132530120482e-06,
      "loss": 0.0154,
      "step": 53820
    },
    {
      "epoch": 6.485542168674699,
      "grad_norm": 0.005847064778208733,
      "learning_rate": 7.028915662650603e-06,
      "loss": 0.0725,
      "step": 53830
    },
    {
      "epoch": 6.486746987951808,
      "grad_norm": 0.8565955758094788,
      "learning_rate": 7.026506024096386e-06,
      "loss": 0.0273,
      "step": 53840
    },
    {
      "epoch": 6.4879518072289155,
      "grad_norm": 0.9045628905296326,
      "learning_rate": 7.02409638554217e-06,
      "loss": 0.0153,
      "step": 53850
    },
    {
      "epoch": 6.489156626506024,
      "grad_norm": 0.0021757876966148615,
      "learning_rate": 7.021686746987952e-06,
      "loss": 0.0157,
      "step": 53860
    },
    {
      "epoch": 6.490361445783132,
      "grad_norm": 0.0018249308923259377,
      "learning_rate": 7.019277108433735e-06,
      "loss": 0.0285,
      "step": 53870
    },
    {
      "epoch": 6.491566265060241,
      "grad_norm": 1.953378677368164,
      "learning_rate": 7.016867469879519e-06,
      "loss": 0.0179,
      "step": 53880
    },
    {
      "epoch": 6.492771084337349,
      "grad_norm": 1.1488956212997437,
      "learning_rate": 7.014457831325302e-06,
      "loss": 0.0412,
      "step": 53890
    },
    {
      "epoch": 6.493975903614458,
      "grad_norm": 0.21777130663394928,
      "learning_rate": 7.012048192771085e-06,
      "loss": 0.015,
      "step": 53900
    },
    {
      "epoch": 6.495180722891567,
      "grad_norm": 0.005729503929615021,
      "learning_rate": 7.009638554216868e-06,
      "loss": 0.0105,
      "step": 53910
    },
    {
      "epoch": 6.4963855421686745,
      "grad_norm": 1.8488026857376099,
      "learning_rate": 7.007228915662651e-06,
      "loss": 0.0329,
      "step": 53920
    },
    {
      "epoch": 6.497590361445783,
      "grad_norm": 0.00839325226843357,
      "learning_rate": 7.004819277108434e-06,
      "loss": 0.0165,
      "step": 53930
    },
    {
      "epoch": 6.498795180722891,
      "grad_norm": 0.8115541934967041,
      "learning_rate": 7.0024096385542176e-06,
      "loss": 0.0192,
      "step": 53940
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.239107608795166,
      "learning_rate": 7e-06,
      "loss": 0.0119,
      "step": 53950
    },
    {
      "epoch": 6.501204819277109,
      "grad_norm": 1.648179292678833,
      "learning_rate": 6.997590361445784e-06,
      "loss": 0.0249,
      "step": 53960
    },
    {
      "epoch": 6.502409638554217,
      "grad_norm": 0.43520477414131165,
      "learning_rate": 6.995180722891567e-06,
      "loss": 0.0203,
      "step": 53970
    },
    {
      "epoch": 6.5036144578313255,
      "grad_norm": 0.001301049953326583,
      "learning_rate": 6.992771084337349e-06,
      "loss": 0.0043,
      "step": 53980
    },
    {
      "epoch": 6.504819277108433,
      "grad_norm": 0.028838202357292175,
      "learning_rate": 6.990361445783133e-06,
      "loss": 0.0107,
      "step": 53990
    },
    {
      "epoch": 6.506024096385542,
      "grad_norm": 0.002750285202637315,
      "learning_rate": 6.987951807228917e-06,
      "loss": 0.0118,
      "step": 54000
    },
    {
      "epoch": 6.507228915662651,
      "grad_norm": 0.3568139970302582,
      "learning_rate": 6.985542168674699e-06,
      "loss": 0.0338,
      "step": 54010
    },
    {
      "epoch": 6.508433734939759,
      "grad_norm": 0.001955905696377158,
      "learning_rate": 6.983132530120482e-06,
      "loss": 0.0083,
      "step": 54020
    },
    {
      "epoch": 6.509638554216868,
      "grad_norm": 2.200650453567505,
      "learning_rate": 6.980722891566266e-06,
      "loss": 0.0307,
      "step": 54030
    },
    {
      "epoch": 6.510843373493976,
      "grad_norm": 0.0422857366502285,
      "learning_rate": 6.978313253012049e-06,
      "loss": 0.0208,
      "step": 54040
    },
    {
      "epoch": 6.5120481927710845,
      "grad_norm": 0.006443828344345093,
      "learning_rate": 6.975903614457832e-06,
      "loss": 0.0082,
      "step": 54050
    },
    {
      "epoch": 6.513253012048192,
      "grad_norm": 0.0021181441843509674,
      "learning_rate": 6.973493975903615e-06,
      "loss": 0.0046,
      "step": 54060
    },
    {
      "epoch": 6.514457831325301,
      "grad_norm": 0.0009962142212316394,
      "learning_rate": 6.971084337349399e-06,
      "loss": 0.0026,
      "step": 54070
    },
    {
      "epoch": 6.51566265060241,
      "grad_norm": 0.08447284996509552,
      "learning_rate": 6.968674698795181e-06,
      "loss": 0.0405,
      "step": 54080
    },
    {
      "epoch": 6.516867469879518,
      "grad_norm": 0.7290641069412231,
      "learning_rate": 6.966265060240964e-06,
      "loss": 0.012,
      "step": 54090
    },
    {
      "epoch": 6.518072289156627,
      "grad_norm": 0.019303563982248306,
      "learning_rate": 6.963855421686747e-06,
      "loss": 0.0352,
      "step": 54100
    },
    {
      "epoch": 6.519277108433735,
      "grad_norm": 0.2249005287885666,
      "learning_rate": 6.961445783132531e-06,
      "loss": 0.0064,
      "step": 54110
    },
    {
      "epoch": 6.5204819277108435,
      "grad_norm": 0.002997512463480234,
      "learning_rate": 6.959036144578314e-06,
      "loss": 0.0306,
      "step": 54120
    },
    {
      "epoch": 6.521686746987951,
      "grad_norm": 0.6080735325813293,
      "learning_rate": 6.956626506024097e-06,
      "loss": 0.003,
      "step": 54130
    },
    {
      "epoch": 6.52289156626506,
      "grad_norm": 2.0871639251708984,
      "learning_rate": 6.954216867469879e-06,
      "loss": 0.0452,
      "step": 54140
    },
    {
      "epoch": 6.524096385542169,
      "grad_norm": 1.9546767473220825,
      "learning_rate": 6.951807228915663e-06,
      "loss": 0.0462,
      "step": 54150
    },
    {
      "epoch": 6.525301204819277,
      "grad_norm": 6.169053554534912,
      "learning_rate": 6.949397590361447e-06,
      "loss": 0.0108,
      "step": 54160
    },
    {
      "epoch": 6.526506024096386,
      "grad_norm": 0.0021025927271693945,
      "learning_rate": 6.946987951807229e-06,
      "loss": 0.0045,
      "step": 54170
    },
    {
      "epoch": 6.527710843373494,
      "grad_norm": 0.00301780691370368,
      "learning_rate": 6.944578313253013e-06,
      "loss": 0.0111,
      "step": 54180
    },
    {
      "epoch": 6.528915662650602,
      "grad_norm": 0.2289201021194458,
      "learning_rate": 6.942168674698796e-06,
      "loss": 0.034,
      "step": 54190
    },
    {
      "epoch": 6.530120481927711,
      "grad_norm": 0.22798091173171997,
      "learning_rate": 6.9397590361445784e-06,
      "loss": 0.0438,
      "step": 54200
    },
    {
      "epoch": 6.531325301204819,
      "grad_norm": 0.1760486364364624,
      "learning_rate": 6.937349397590362e-06,
      "loss": 0.03,
      "step": 54210
    },
    {
      "epoch": 6.532530120481928,
      "grad_norm": 13.141243934631348,
      "learning_rate": 6.934939759036146e-06,
      "loss": 0.0288,
      "step": 54220
    },
    {
      "epoch": 6.533734939759036,
      "grad_norm": 0.0017671722453087568,
      "learning_rate": 6.932530120481929e-06,
      "loss": 0.0055,
      "step": 54230
    },
    {
      "epoch": 6.534939759036145,
      "grad_norm": 0.0019131171284243464,
      "learning_rate": 6.930120481927711e-06,
      "loss": 0.0035,
      "step": 54240
    },
    {
      "epoch": 6.5361445783132535,
      "grad_norm": 2.084322214126587,
      "learning_rate": 6.927710843373494e-06,
      "loss": 0.0366,
      "step": 54250
    },
    {
      "epoch": 6.537349397590361,
      "grad_norm": 0.5044691562652588,
      "learning_rate": 6.925301204819278e-06,
      "loss": 0.0598,
      "step": 54260
    },
    {
      "epoch": 6.53855421686747,
      "grad_norm": 0.0017282032640650868,
      "learning_rate": 6.922891566265061e-06,
      "loss": 0.0105,
      "step": 54270
    },
    {
      "epoch": 6.539759036144578,
      "grad_norm": 0.03575577214360237,
      "learning_rate": 6.920481927710844e-06,
      "loss": 0.0101,
      "step": 54280
    },
    {
      "epoch": 6.540963855421687,
      "grad_norm": 0.4224754571914673,
      "learning_rate": 6.918072289156626e-06,
      "loss": 0.0184,
      "step": 54290
    },
    {
      "epoch": 6.542168674698795,
      "grad_norm": 0.006000575143843889,
      "learning_rate": 6.91566265060241e-06,
      "loss": 0.0508,
      "step": 54300
    },
    {
      "epoch": 6.543373493975904,
      "grad_norm": 0.018654370680451393,
      "learning_rate": 6.913253012048193e-06,
      "loss": 0.0346,
      "step": 54310
    },
    {
      "epoch": 6.544578313253012,
      "grad_norm": 0.4257167875766754,
      "learning_rate": 6.9108433734939766e-06,
      "loss": 0.0112,
      "step": 54320
    },
    {
      "epoch": 6.54578313253012,
      "grad_norm": 0.002095261123031378,
      "learning_rate": 6.90843373493976e-06,
      "loss": 0.0106,
      "step": 54330
    },
    {
      "epoch": 6.546987951807229,
      "grad_norm": 0.011256217025220394,
      "learning_rate": 6.906024096385543e-06,
      "loss": 0.0034,
      "step": 54340
    },
    {
      "epoch": 6.548192771084337,
      "grad_norm": 0.8030999302864075,
      "learning_rate": 6.903614457831326e-06,
      "loss": 0.0079,
      "step": 54350
    },
    {
      "epoch": 6.549397590361446,
      "grad_norm": 0.0015234393067657948,
      "learning_rate": 6.901204819277108e-06,
      "loss": 0.0323,
      "step": 54360
    },
    {
      "epoch": 6.550602409638554,
      "grad_norm": 0.5107653737068176,
      "learning_rate": 6.8987951807228924e-06,
      "loss": 0.0247,
      "step": 54370
    },
    {
      "epoch": 6.551807228915663,
      "grad_norm": 9.047879219055176,
      "learning_rate": 6.896385542168676e-06,
      "loss": 0.0446,
      "step": 54380
    },
    {
      "epoch": 6.553012048192771,
      "grad_norm": 0.22001993656158447,
      "learning_rate": 6.893975903614458e-06,
      "loss": 0.0112,
      "step": 54390
    },
    {
      "epoch": 6.554216867469879,
      "grad_norm": 0.4737367331981659,
      "learning_rate": 6.891566265060241e-06,
      "loss": 0.005,
      "step": 54400
    },
    {
      "epoch": 6.555421686746988,
      "grad_norm": 0.0012568505480885506,
      "learning_rate": 6.889156626506025e-06,
      "loss": 0.0436,
      "step": 54410
    },
    {
      "epoch": 6.556626506024096,
      "grad_norm": 0.16018690168857574,
      "learning_rate": 6.8867469879518075e-06,
      "loss": 0.0436,
      "step": 54420
    },
    {
      "epoch": 6.557831325301205,
      "grad_norm": 0.9578633308410645,
      "learning_rate": 6.884337349397591e-06,
      "loss": 0.0032,
      "step": 54430
    },
    {
      "epoch": 6.559036144578314,
      "grad_norm": 0.013212253339588642,
      "learning_rate": 6.881927710843374e-06,
      "loss": 0.0524,
      "step": 54440
    },
    {
      "epoch": 6.5602409638554215,
      "grad_norm": 0.43440544605255127,
      "learning_rate": 6.879518072289158e-06,
      "loss": 0.053,
      "step": 54450
    },
    {
      "epoch": 6.56144578313253,
      "grad_norm": 0.19885990023612976,
      "learning_rate": 6.87710843373494e-06,
      "loss": 0.0786,
      "step": 54460
    },
    {
      "epoch": 6.562650602409638,
      "grad_norm": 0.13599389791488647,
      "learning_rate": 6.874698795180723e-06,
      "loss": 0.0516,
      "step": 54470
    },
    {
      "epoch": 6.563855421686747,
      "grad_norm": 1.730170488357544,
      "learning_rate": 6.872289156626507e-06,
      "loss": 0.0067,
      "step": 54480
    },
    {
      "epoch": 6.565060240963856,
      "grad_norm": 0.011212406679987907,
      "learning_rate": 6.86987951807229e-06,
      "loss": 0.0026,
      "step": 54490
    },
    {
      "epoch": 6.566265060240964,
      "grad_norm": 0.001817166106775403,
      "learning_rate": 6.867469879518073e-06,
      "loss": 0.0473,
      "step": 54500
    },
    {
      "epoch": 6.567469879518073,
      "grad_norm": 0.004803826566785574,
      "learning_rate": 6.865060240963855e-06,
      "loss": 0.0088,
      "step": 54510
    },
    {
      "epoch": 6.5686746987951805,
      "grad_norm": 1.6256228685379028,
      "learning_rate": 6.862650602409639e-06,
      "loss": 0.0393,
      "step": 54520
    },
    {
      "epoch": 6.569879518072289,
      "grad_norm": 0.03607119247317314,
      "learning_rate": 6.860240963855422e-06,
      "loss": 0.0054,
      "step": 54530
    },
    {
      "epoch": 6.571084337349397,
      "grad_norm": 0.013248181901872158,
      "learning_rate": 6.857831325301206e-06,
      "loss": 0.0302,
      "step": 54540
    },
    {
      "epoch": 6.572289156626506,
      "grad_norm": 0.0021882113069295883,
      "learning_rate": 6.855421686746988e-06,
      "loss": 0.0303,
      "step": 54550
    },
    {
      "epoch": 6.573493975903615,
      "grad_norm": 0.0031589316204190254,
      "learning_rate": 6.853012048192772e-06,
      "loss": 0.0236,
      "step": 54560
    },
    {
      "epoch": 6.574698795180723,
      "grad_norm": 0.42720508575439453,
      "learning_rate": 6.850602409638555e-06,
      "loss": 0.0353,
      "step": 54570
    },
    {
      "epoch": 6.575903614457832,
      "grad_norm": 0.005540743935853243,
      "learning_rate": 6.8481927710843374e-06,
      "loss": 0.0162,
      "step": 54580
    },
    {
      "epoch": 6.5771084337349395,
      "grad_norm": 0.014977329410612583,
      "learning_rate": 6.845783132530121e-06,
      "loss": 0.027,
      "step": 54590
    },
    {
      "epoch": 6.578313253012048,
      "grad_norm": 0.005992470309138298,
      "learning_rate": 6.843373493975905e-06,
      "loss": 0.0086,
      "step": 54600
    },
    {
      "epoch": 6.579518072289156,
      "grad_norm": 0.3462415337562561,
      "learning_rate": 6.840963855421687e-06,
      "loss": 0.0433,
      "step": 54610
    },
    {
      "epoch": 6.580722891566265,
      "grad_norm": 0.008214356377720833,
      "learning_rate": 6.83855421686747e-06,
      "loss": 0.0154,
      "step": 54620
    },
    {
      "epoch": 6.581927710843374,
      "grad_norm": 0.1806860715150833,
      "learning_rate": 6.836144578313254e-06,
      "loss": 0.0078,
      "step": 54630
    },
    {
      "epoch": 6.583132530120482,
      "grad_norm": 1.4909197092056274,
      "learning_rate": 6.8337349397590365e-06,
      "loss": 0.0221,
      "step": 54640
    },
    {
      "epoch": 6.5843373493975905,
      "grad_norm": 0.9469571709632874,
      "learning_rate": 6.83132530120482e-06,
      "loss": 0.0043,
      "step": 54650
    },
    {
      "epoch": 6.585542168674698,
      "grad_norm": 0.004021360073238611,
      "learning_rate": 6.828915662650603e-06,
      "loss": 0.0123,
      "step": 54660
    },
    {
      "epoch": 6.586746987951807,
      "grad_norm": 0.007405135780572891,
      "learning_rate": 6.826506024096387e-06,
      "loss": 0.0406,
      "step": 54670
    },
    {
      "epoch": 6.587951807228916,
      "grad_norm": 1.072904348373413,
      "learning_rate": 6.824096385542169e-06,
      "loss": 0.0268,
      "step": 54680
    },
    {
      "epoch": 6.589156626506024,
      "grad_norm": 0.19606614112854004,
      "learning_rate": 6.821686746987952e-06,
      "loss": 0.032,
      "step": 54690
    },
    {
      "epoch": 6.590361445783133,
      "grad_norm": 0.4380837678909302,
      "learning_rate": 6.819277108433735e-06,
      "loss": 0.0067,
      "step": 54700
    },
    {
      "epoch": 6.591566265060241,
      "grad_norm": 0.1131030023097992,
      "learning_rate": 6.816867469879519e-06,
      "loss": 0.0473,
      "step": 54710
    },
    {
      "epoch": 6.5927710843373495,
      "grad_norm": 1.230607032775879,
      "learning_rate": 6.814457831325302e-06,
      "loss": 0.0364,
      "step": 54720
    },
    {
      "epoch": 6.593975903614458,
      "grad_norm": 1.7349464893341064,
      "learning_rate": 6.812048192771084e-06,
      "loss": 0.0292,
      "step": 54730
    },
    {
      "epoch": 6.595180722891566,
      "grad_norm": 0.004017054568976164,
      "learning_rate": 6.809638554216867e-06,
      "loss": 0.0136,
      "step": 54740
    },
    {
      "epoch": 6.596385542168675,
      "grad_norm": 0.033687543123960495,
      "learning_rate": 6.8072289156626514e-06,
      "loss": 0.0135,
      "step": 54750
    },
    {
      "epoch": 6.597590361445783,
      "grad_norm": 0.0019188793376088142,
      "learning_rate": 6.804819277108435e-06,
      "loss": 0.0323,
      "step": 54760
    },
    {
      "epoch": 6.598795180722892,
      "grad_norm": 0.005450270604342222,
      "learning_rate": 6.802409638554217e-06,
      "loss": 0.0202,
      "step": 54770
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.6162450313568115,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0312,
      "step": 54780
    },
    {
      "epoch": 6.6012048192771084,
      "grad_norm": 1.449088454246521,
      "learning_rate": 6.797590361445784e-06,
      "loss": 0.0248,
      "step": 54790
    },
    {
      "epoch": 6.602409638554217,
      "grad_norm": 2.0873584747314453,
      "learning_rate": 6.7951807228915665e-06,
      "loss": 0.0696,
      "step": 54800
    },
    {
      "epoch": 6.603614457831325,
      "grad_norm": 0.04905211180448532,
      "learning_rate": 6.79277108433735e-06,
      "loss": 0.0164,
      "step": 54810
    },
    {
      "epoch": 6.604819277108434,
      "grad_norm": 0.002263294532895088,
      "learning_rate": 6.790361445783134e-06,
      "loss": 0.022,
      "step": 54820
    },
    {
      "epoch": 6.606024096385542,
      "grad_norm": 1.475204586982727,
      "learning_rate": 6.787951807228916e-06,
      "loss": 0.01,
      "step": 54830
    },
    {
      "epoch": 6.607228915662651,
      "grad_norm": 0.0010408014059066772,
      "learning_rate": 6.785542168674699e-06,
      "loss": 0.0098,
      "step": 54840
    },
    {
      "epoch": 6.608433734939759,
      "grad_norm": 0.004032918252050877,
      "learning_rate": 6.783132530120482e-06,
      "loss": 0.0107,
      "step": 54850
    },
    {
      "epoch": 6.609638554216867,
      "grad_norm": 0.0021590813994407654,
      "learning_rate": 6.780722891566266e-06,
      "loss": 0.0378,
      "step": 54860
    },
    {
      "epoch": 6.610843373493976,
      "grad_norm": 0.00334723643027246,
      "learning_rate": 6.778313253012049e-06,
      "loss": 0.0171,
      "step": 54870
    },
    {
      "epoch": 6.612048192771084,
      "grad_norm": 0.0038608822505921125,
      "learning_rate": 6.775903614457832e-06,
      "loss": 0.0199,
      "step": 54880
    },
    {
      "epoch": 6.613253012048193,
      "grad_norm": 0.002794926054775715,
      "learning_rate": 6.773493975903614e-06,
      "loss": 0.0086,
      "step": 54890
    },
    {
      "epoch": 6.614457831325301,
      "grad_norm": 2.514814615249634,
      "learning_rate": 6.771084337349398e-06,
      "loss": 0.0702,
      "step": 54900
    },
    {
      "epoch": 6.61566265060241,
      "grad_norm": 0.004211571533232927,
      "learning_rate": 6.768674698795181e-06,
      "loss": 0.052,
      "step": 54910
    },
    {
      "epoch": 6.6168674698795185,
      "grad_norm": 0.01425166055560112,
      "learning_rate": 6.766265060240964e-06,
      "loss": 0.008,
      "step": 54920
    },
    {
      "epoch": 6.618072289156626,
      "grad_norm": 0.7455140948295593,
      "learning_rate": 6.763855421686748e-06,
      "loss": 0.0311,
      "step": 54930
    },
    {
      "epoch": 6.619277108433735,
      "grad_norm": 0.21743227541446686,
      "learning_rate": 6.761445783132531e-06,
      "loss": 0.0092,
      "step": 54940
    },
    {
      "epoch": 6.620481927710843,
      "grad_norm": 0.0037775833625346422,
      "learning_rate": 6.759036144578314e-06,
      "loss": 0.012,
      "step": 54950
    },
    {
      "epoch": 6.621686746987952,
      "grad_norm": 0.0016116087790578604,
      "learning_rate": 6.7566265060240964e-06,
      "loss": 0.0002,
      "step": 54960
    },
    {
      "epoch": 6.622891566265061,
      "grad_norm": 0.005427344236522913,
      "learning_rate": 6.7542168674698805e-06,
      "loss": 0.0038,
      "step": 54970
    },
    {
      "epoch": 6.624096385542169,
      "grad_norm": 0.0021371813490986824,
      "learning_rate": 6.751807228915664e-06,
      "loss": 0.0453,
      "step": 54980
    },
    {
      "epoch": 6.625301204819277,
      "grad_norm": 0.026672545820474625,
      "learning_rate": 6.749397590361446e-06,
      "loss": 0.0239,
      "step": 54990
    },
    {
      "epoch": 6.626506024096385,
      "grad_norm": 0.004805708769708872,
      "learning_rate": 6.746987951807229e-06,
      "loss": 0.0321,
      "step": 55000
    },
    {
      "epoch": 6.627710843373494,
      "grad_norm": 0.010602404363453388,
      "learning_rate": 6.744578313253013e-06,
      "loss": 0.041,
      "step": 55010
    },
    {
      "epoch": 6.628915662650602,
      "grad_norm": 1.863136649131775,
      "learning_rate": 6.7421686746987955e-06,
      "loss": 0.0328,
      "step": 55020
    },
    {
      "epoch": 6.630120481927711,
      "grad_norm": 0.4027797281742096,
      "learning_rate": 6.739759036144579e-06,
      "loss": 0.0157,
      "step": 55030
    },
    {
      "epoch": 6.63132530120482,
      "grad_norm": 0.0026923695113509893,
      "learning_rate": 6.737349397590363e-06,
      "loss": 0.0066,
      "step": 55040
    },
    {
      "epoch": 6.632530120481928,
      "grad_norm": 0.23021799325942993,
      "learning_rate": 6.734939759036145e-06,
      "loss": 0.0057,
      "step": 55050
    },
    {
      "epoch": 6.633734939759036,
      "grad_norm": 0.002310939831659198,
      "learning_rate": 6.732530120481928e-06,
      "loss": 0.0306,
      "step": 55060
    },
    {
      "epoch": 6.634939759036144,
      "grad_norm": 0.01373727060854435,
      "learning_rate": 6.730120481927711e-06,
      "loss": 0.0154,
      "step": 55070
    },
    {
      "epoch": 6.636144578313253,
      "grad_norm": 0.007840917445719242,
      "learning_rate": 6.727710843373495e-06,
      "loss": 0.0426,
      "step": 55080
    },
    {
      "epoch": 6.637349397590361,
      "grad_norm": 2.0354223251342773,
      "learning_rate": 6.725301204819278e-06,
      "loss": 0.0369,
      "step": 55090
    },
    {
      "epoch": 6.63855421686747,
      "grad_norm": 0.004097559489309788,
      "learning_rate": 6.722891566265061e-06,
      "loss": 0.0348,
      "step": 55100
    },
    {
      "epoch": 6.639759036144579,
      "grad_norm": 0.5328215956687927,
      "learning_rate": 6.720481927710843e-06,
      "loss": 0.011,
      "step": 55110
    },
    {
      "epoch": 6.6409638554216865,
      "grad_norm": 0.05905872583389282,
      "learning_rate": 6.718072289156627e-06,
      "loss": 0.0079,
      "step": 55120
    },
    {
      "epoch": 6.642168674698795,
      "grad_norm": 0.0028999492060393095,
      "learning_rate": 6.7156626506024104e-06,
      "loss": 0.0002,
      "step": 55130
    },
    {
      "epoch": 6.643373493975903,
      "grad_norm": 0.011766604147851467,
      "learning_rate": 6.713253012048193e-06,
      "loss": 0.0185,
      "step": 55140
    },
    {
      "epoch": 6.644578313253012,
      "grad_norm": 0.016629723832011223,
      "learning_rate": 6.710843373493976e-06,
      "loss": 0.0047,
      "step": 55150
    },
    {
      "epoch": 6.64578313253012,
      "grad_norm": 0.33026209473609924,
      "learning_rate": 6.70843373493976e-06,
      "loss": 0.0195,
      "step": 55160
    },
    {
      "epoch": 6.646987951807229,
      "grad_norm": 0.08399103581905365,
      "learning_rate": 6.706024096385543e-06,
      "loss": 0.0499,
      "step": 55170
    },
    {
      "epoch": 6.648192771084338,
      "grad_norm": 0.01374735962599516,
      "learning_rate": 6.7036144578313255e-06,
      "loss": 0.0059,
      "step": 55180
    },
    {
      "epoch": 6.6493975903614455,
      "grad_norm": 3.465815544128418,
      "learning_rate": 6.7012048192771095e-06,
      "loss": 0.0268,
      "step": 55190
    },
    {
      "epoch": 6.650602409638554,
      "grad_norm": 0.0071653644554317,
      "learning_rate": 6.698795180722893e-06,
      "loss": 0.0035,
      "step": 55200
    },
    {
      "epoch": 6.651807228915663,
      "grad_norm": 0.07866603881120682,
      "learning_rate": 6.696385542168675e-06,
      "loss": 0.0147,
      "step": 55210
    },
    {
      "epoch": 6.653012048192771,
      "grad_norm": 0.03318493068218231,
      "learning_rate": 6.693975903614458e-06,
      "loss": 0.0118,
      "step": 55220
    },
    {
      "epoch": 6.65421686746988,
      "grad_norm": 0.008752625435590744,
      "learning_rate": 6.691566265060242e-06,
      "loss": 0.0198,
      "step": 55230
    },
    {
      "epoch": 6.655421686746988,
      "grad_norm": 0.16980086266994476,
      "learning_rate": 6.6891566265060245e-06,
      "loss": 0.0371,
      "step": 55240
    },
    {
      "epoch": 6.656626506024097,
      "grad_norm": 1.0733065605163574,
      "learning_rate": 6.686746987951808e-06,
      "loss": 0.0196,
      "step": 55250
    },
    {
      "epoch": 6.6578313253012045,
      "grad_norm": 0.04289090260863304,
      "learning_rate": 6.684337349397591e-06,
      "loss": 0.0636,
      "step": 55260
    },
    {
      "epoch": 6.659036144578313,
      "grad_norm": 0.128677099943161,
      "learning_rate": 6.681927710843374e-06,
      "loss": 0.0102,
      "step": 55270
    },
    {
      "epoch": 6.660240963855422,
      "grad_norm": 5.314330577850342,
      "learning_rate": 6.679518072289157e-06,
      "loss": 0.0398,
      "step": 55280
    },
    {
      "epoch": 6.66144578313253,
      "grad_norm": 0.009052877314388752,
      "learning_rate": 6.67710843373494e-06,
      "loss": 0.0506,
      "step": 55290
    },
    {
      "epoch": 6.662650602409639,
      "grad_norm": 0.007243570405989885,
      "learning_rate": 6.674698795180723e-06,
      "loss": 0.0004,
      "step": 55300
    },
    {
      "epoch": 6.663855421686747,
      "grad_norm": 4.108231544494629,
      "learning_rate": 6.672289156626507e-06,
      "loss": 0.0396,
      "step": 55310
    },
    {
      "epoch": 6.6650602409638555,
      "grad_norm": 0.547879695892334,
      "learning_rate": 6.66987951807229e-06,
      "loss": 0.0209,
      "step": 55320
    },
    {
      "epoch": 6.666265060240963,
      "grad_norm": 0.11717359721660614,
      "learning_rate": 6.667469879518072e-06,
      "loss": 0.0417,
      "step": 55330
    },
    {
      "epoch": 6.667469879518072,
      "grad_norm": 1.4171329736709595,
      "learning_rate": 6.665060240963856e-06,
      "loss": 0.0169,
      "step": 55340
    },
    {
      "epoch": 6.668674698795181,
      "grad_norm": 0.005558473523706198,
      "learning_rate": 6.6626506024096395e-06,
      "loss": 0.0185,
      "step": 55350
    },
    {
      "epoch": 6.669879518072289,
      "grad_norm": 0.05450291186571121,
      "learning_rate": 6.660240963855422e-06,
      "loss": 0.0069,
      "step": 55360
    },
    {
      "epoch": 6.671084337349398,
      "grad_norm": 0.014475882053375244,
      "learning_rate": 6.657831325301205e-06,
      "loss": 0.0536,
      "step": 55370
    },
    {
      "epoch": 6.672289156626506,
      "grad_norm": 0.9827070832252502,
      "learning_rate": 6.655421686746989e-06,
      "loss": 0.015,
      "step": 55380
    },
    {
      "epoch": 6.6734939759036145,
      "grad_norm": 0.009766248054802418,
      "learning_rate": 6.653012048192772e-06,
      "loss": 0.0133,
      "step": 55390
    },
    {
      "epoch": 6.674698795180722,
      "grad_norm": 0.009717305190861225,
      "learning_rate": 6.6506024096385545e-06,
      "loss": 0.0474,
      "step": 55400
    },
    {
      "epoch": 6.675903614457831,
      "grad_norm": 0.020256314426660538,
      "learning_rate": 6.648192771084338e-06,
      "loss": 0.0347,
      "step": 55410
    },
    {
      "epoch": 6.67710843373494,
      "grad_norm": 0.010248009115457535,
      "learning_rate": 6.645783132530122e-06,
      "loss": 0.0093,
      "step": 55420
    },
    {
      "epoch": 6.678313253012048,
      "grad_norm": 0.008280478417873383,
      "learning_rate": 6.643373493975904e-06,
      "loss": 0.0156,
      "step": 55430
    },
    {
      "epoch": 6.679518072289157,
      "grad_norm": 0.8935005068778992,
      "learning_rate": 6.640963855421687e-06,
      "loss": 0.0158,
      "step": 55440
    },
    {
      "epoch": 6.6807228915662655,
      "grad_norm": 0.2595558166503906,
      "learning_rate": 6.6385542168674695e-06,
      "loss": 0.0276,
      "step": 55450
    },
    {
      "epoch": 6.6819277108433734,
      "grad_norm": 1.0701141357421875,
      "learning_rate": 6.6361445783132535e-06,
      "loss": 0.0228,
      "step": 55460
    },
    {
      "epoch": 6.683132530120482,
      "grad_norm": 0.001974323997274041,
      "learning_rate": 6.633734939759037e-06,
      "loss": 0.0194,
      "step": 55470
    },
    {
      "epoch": 6.68433734939759,
      "grad_norm": 0.001433784607797861,
      "learning_rate": 6.63132530120482e-06,
      "loss": 0.0094,
      "step": 55480
    },
    {
      "epoch": 6.685542168674699,
      "grad_norm": 7.690605163574219,
      "learning_rate": 6.628915662650603e-06,
      "loss": 0.0347,
      "step": 55490
    },
    {
      "epoch": 6.686746987951807,
      "grad_norm": 0.011556276120245457,
      "learning_rate": 6.626506024096386e-06,
      "loss": 0.0217,
      "step": 55500
    },
    {
      "epoch": 6.687951807228916,
      "grad_norm": 1.8731392621994019,
      "learning_rate": 6.6240963855421694e-06,
      "loss": 0.0523,
      "step": 55510
    },
    {
      "epoch": 6.6891566265060245,
      "grad_norm": 0.0017613926902413368,
      "learning_rate": 6.621686746987952e-06,
      "loss": 0.0213,
      "step": 55520
    },
    {
      "epoch": 6.690361445783132,
      "grad_norm": 2.149123191833496,
      "learning_rate": 6.619277108433736e-06,
      "loss": 0.0339,
      "step": 55530
    },
    {
      "epoch": 6.691566265060241,
      "grad_norm": 0.008730806410312653,
      "learning_rate": 6.616867469879519e-06,
      "loss": 0.0044,
      "step": 55540
    },
    {
      "epoch": 6.692771084337349,
      "grad_norm": 0.016066936776041985,
      "learning_rate": 6.614457831325301e-06,
      "loss": 0.01,
      "step": 55550
    },
    {
      "epoch": 6.693975903614458,
      "grad_norm": 0.0017982054268941283,
      "learning_rate": 6.6120481927710845e-06,
      "loss": 0.0076,
      "step": 55560
    },
    {
      "epoch": 6.695180722891566,
      "grad_norm": 0.02371681109070778,
      "learning_rate": 6.6096385542168685e-06,
      "loss": 0.0456,
      "step": 55570
    },
    {
      "epoch": 6.696385542168675,
      "grad_norm": 0.0013722303556278348,
      "learning_rate": 6.607228915662652e-06,
      "loss": 0.0174,
      "step": 55580
    },
    {
      "epoch": 6.6975903614457835,
      "grad_norm": 0.0031403671018779278,
      "learning_rate": 6.604819277108434e-06,
      "loss": 0.0257,
      "step": 55590
    },
    {
      "epoch": 6.698795180722891,
      "grad_norm": 1.1665680408477783,
      "learning_rate": 6.602409638554217e-06,
      "loss": 0.0185,
      "step": 55600
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.0029416405595839024,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.0286,
      "step": 55610
    },
    {
      "epoch": 6.701204819277108,
      "grad_norm": 0.426143616437912,
      "learning_rate": 6.5975903614457835e-06,
      "loss": 0.0146,
      "step": 55620
    },
    {
      "epoch": 6.702409638554217,
      "grad_norm": 0.19473232328891754,
      "learning_rate": 6.595180722891567e-06,
      "loss": 0.0183,
      "step": 55630
    },
    {
      "epoch": 6.703614457831325,
      "grad_norm": 1.2168347835540771,
      "learning_rate": 6.592771084337351e-06,
      "loss": 0.0156,
      "step": 55640
    },
    {
      "epoch": 6.704819277108434,
      "grad_norm": 1.1965242624282837,
      "learning_rate": 6.590361445783133e-06,
      "loss": 0.0142,
      "step": 55650
    },
    {
      "epoch": 6.706024096385542,
      "grad_norm": 0.001549186185002327,
      "learning_rate": 6.587951807228916e-06,
      "loss": 0.0807,
      "step": 55660
    },
    {
      "epoch": 6.70722891566265,
      "grad_norm": 0.0038292661774903536,
      "learning_rate": 6.585542168674699e-06,
      "loss": 0.0092,
      "step": 55670
    },
    {
      "epoch": 6.708433734939759,
      "grad_norm": 0.01188794244080782,
      "learning_rate": 6.5831325301204826e-06,
      "loss": 0.0272,
      "step": 55680
    },
    {
      "epoch": 6.709638554216868,
      "grad_norm": 2.030142068862915,
      "learning_rate": 6.580722891566266e-06,
      "loss": 0.0254,
      "step": 55690
    },
    {
      "epoch": 6.710843373493976,
      "grad_norm": 0.277348130941391,
      "learning_rate": 6.578313253012049e-06,
      "loss": 0.0205,
      "step": 55700
    },
    {
      "epoch": 6.712048192771085,
      "grad_norm": 0.001138394232839346,
      "learning_rate": 6.575903614457831e-06,
      "loss": 0.0294,
      "step": 55710
    },
    {
      "epoch": 6.713253012048193,
      "grad_norm": 0.007129873149096966,
      "learning_rate": 6.573493975903615e-06,
      "loss": 0.0045,
      "step": 55720
    },
    {
      "epoch": 6.714457831325301,
      "grad_norm": 0.07381703704595566,
      "learning_rate": 6.5710843373493984e-06,
      "loss": 0.0137,
      "step": 55730
    },
    {
      "epoch": 6.715662650602409,
      "grad_norm": 5.119035243988037,
      "learning_rate": 6.568674698795181e-06,
      "loss": 0.042,
      "step": 55740
    },
    {
      "epoch": 6.716867469879518,
      "grad_norm": 1.2833099365234375,
      "learning_rate": 6.566265060240964e-06,
      "loss": 0.0449,
      "step": 55750
    },
    {
      "epoch": 6.718072289156627,
      "grad_norm": 0.08390092849731445,
      "learning_rate": 6.563855421686748e-06,
      "loss": 0.015,
      "step": 55760
    },
    {
      "epoch": 6.719277108433735,
      "grad_norm": 0.8415494561195374,
      "learning_rate": 6.56144578313253e-06,
      "loss": 0.0002,
      "step": 55770
    },
    {
      "epoch": 6.720481927710844,
      "grad_norm": 0.0031115184538066387,
      "learning_rate": 6.5590361445783135e-06,
      "loss": 0.0241,
      "step": 55780
    },
    {
      "epoch": 6.7216867469879515,
      "grad_norm": 0.0034923760686069727,
      "learning_rate": 6.5566265060240975e-06,
      "loss": 0.0209,
      "step": 55790
    },
    {
      "epoch": 6.72289156626506,
      "grad_norm": 0.0018670206191018224,
      "learning_rate": 6.554216867469881e-06,
      "loss": 0.0205,
      "step": 55800
    },
    {
      "epoch": 6.724096385542168,
      "grad_norm": 0.014893541112542152,
      "learning_rate": 6.551807228915663e-06,
      "loss": 0.0071,
      "step": 55810
    },
    {
      "epoch": 6.725301204819277,
      "grad_norm": 0.05230209231376648,
      "learning_rate": 6.549397590361446e-06,
      "loss": 0.0373,
      "step": 55820
    },
    {
      "epoch": 6.726506024096386,
      "grad_norm": 0.004415296018123627,
      "learning_rate": 6.54698795180723e-06,
      "loss": 0.0035,
      "step": 55830
    },
    {
      "epoch": 6.727710843373494,
      "grad_norm": 45.32999038696289,
      "learning_rate": 6.5445783132530125e-06,
      "loss": 0.0106,
      "step": 55840
    },
    {
      "epoch": 6.728915662650603,
      "grad_norm": 0.014805098064243793,
      "learning_rate": 6.542168674698796e-06,
      "loss": 0.0067,
      "step": 55850
    },
    {
      "epoch": 6.7301204819277105,
      "grad_norm": 0.12164262682199478,
      "learning_rate": 6.539759036144578e-06,
      "loss": 0.0184,
      "step": 55860
    },
    {
      "epoch": 6.731325301204819,
      "grad_norm": 19.071802139282227,
      "learning_rate": 6.537349397590362e-06,
      "loss": 0.052,
      "step": 55870
    },
    {
      "epoch": 6.732530120481927,
      "grad_norm": 0.46812859177589417,
      "learning_rate": 6.534939759036145e-06,
      "loss": 0.0164,
      "step": 55880
    },
    {
      "epoch": 6.733734939759036,
      "grad_norm": 0.2723924219608307,
      "learning_rate": 6.532530120481928e-06,
      "loss": 0.0064,
      "step": 55890
    },
    {
      "epoch": 6.734939759036145,
      "grad_norm": 0.004245040938258171,
      "learning_rate": 6.530120481927711e-06,
      "loss": 0.0126,
      "step": 55900
    },
    {
      "epoch": 6.736144578313253,
      "grad_norm": 1.0067691802978516,
      "learning_rate": 6.527710843373495e-06,
      "loss": 0.0226,
      "step": 55910
    },
    {
      "epoch": 6.7373493975903616,
      "grad_norm": 0.039593152701854706,
      "learning_rate": 6.525301204819278e-06,
      "loss": 0.055,
      "step": 55920
    },
    {
      "epoch": 6.73855421686747,
      "grad_norm": 0.003724641865119338,
      "learning_rate": 6.52289156626506e-06,
      "loss": 0.012,
      "step": 55930
    },
    {
      "epoch": 6.739759036144578,
      "grad_norm": 0.07895688712596893,
      "learning_rate": 6.520481927710844e-06,
      "loss": 0.0131,
      "step": 55940
    },
    {
      "epoch": 6.740963855421687,
      "grad_norm": 2.1372551918029785,
      "learning_rate": 6.5180722891566275e-06,
      "loss": 0.011,
      "step": 55950
    },
    {
      "epoch": 6.742168674698795,
      "grad_norm": 0.004326161928474903,
      "learning_rate": 6.51566265060241e-06,
      "loss": 0.0134,
      "step": 55960
    },
    {
      "epoch": 6.743373493975904,
      "grad_norm": 1.0864418745040894,
      "learning_rate": 6.513253012048193e-06,
      "loss": 0.012,
      "step": 55970
    },
    {
      "epoch": 6.744578313253012,
      "grad_norm": 0.007555943913757801,
      "learning_rate": 6.510843373493977e-06,
      "loss": 0.0391,
      "step": 55980
    },
    {
      "epoch": 6.7457831325301205,
      "grad_norm": 2.9718644618988037,
      "learning_rate": 6.508433734939759e-06,
      "loss": 0.0226,
      "step": 55990
    },
    {
      "epoch": 6.746987951807229,
      "grad_norm": 0.23661111295223236,
      "learning_rate": 6.5060240963855425e-06,
      "loss": 0.0108,
      "step": 56000
    },
    {
      "epoch": 6.748192771084337,
      "grad_norm": 0.0014600042486563325,
      "learning_rate": 6.503614457831326e-06,
      "loss": 0.0516,
      "step": 56010
    },
    {
      "epoch": 6.749397590361446,
      "grad_norm": 6.98515510559082,
      "learning_rate": 6.50120481927711e-06,
      "loss": 0.0579,
      "step": 56020
    },
    {
      "epoch": 6.750602409638554,
      "grad_norm": 0.06383374333381653,
      "learning_rate": 6.498795180722892e-06,
      "loss": 0.0208,
      "step": 56030
    },
    {
      "epoch": 6.751807228915663,
      "grad_norm": 1.1397045850753784,
      "learning_rate": 6.496385542168675e-06,
      "loss": 0.0201,
      "step": 56040
    },
    {
      "epoch": 6.753012048192771,
      "grad_norm": 0.005740605294704437,
      "learning_rate": 6.4939759036144575e-06,
      "loss": 0.017,
      "step": 56050
    },
    {
      "epoch": 6.7542168674698795,
      "grad_norm": 0.11515795439481735,
      "learning_rate": 6.4915662650602416e-06,
      "loss": 0.0027,
      "step": 56060
    },
    {
      "epoch": 6.755421686746988,
      "grad_norm": 0.0016894949367269874,
      "learning_rate": 6.489156626506025e-06,
      "loss": 0.0282,
      "step": 56070
    },
    {
      "epoch": 6.756626506024096,
      "grad_norm": 2.3594884872436523,
      "learning_rate": 6.486746987951807e-06,
      "loss": 0.0191,
      "step": 56080
    },
    {
      "epoch": 6.757831325301205,
      "grad_norm": 0.003139007603749633,
      "learning_rate": 6.484337349397591e-06,
      "loss": 0.0052,
      "step": 56090
    },
    {
      "epoch": 6.759036144578313,
      "grad_norm": 0.3138708472251892,
      "learning_rate": 6.481927710843374e-06,
      "loss": 0.0148,
      "step": 56100
    },
    {
      "epoch": 6.760240963855422,
      "grad_norm": 1.487443208694458,
      "learning_rate": 6.4795180722891574e-06,
      "loss": 0.0138,
      "step": 56110
    },
    {
      "epoch": 6.76144578313253,
      "grad_norm": 2.879788637161255,
      "learning_rate": 6.47710843373494e-06,
      "loss": 0.0154,
      "step": 56120
    },
    {
      "epoch": 6.7626506024096384,
      "grad_norm": 0.0027768646832555532,
      "learning_rate": 6.474698795180724e-06,
      "loss": 0.0086,
      "step": 56130
    },
    {
      "epoch": 6.763855421686747,
      "grad_norm": 0.0010870274854823947,
      "learning_rate": 6.472289156626507e-06,
      "loss": 0.0169,
      "step": 56140
    },
    {
      "epoch": 6.765060240963855,
      "grad_norm": 0.0012800934491679072,
      "learning_rate": 6.469879518072289e-06,
      "loss": 0.0441,
      "step": 56150
    },
    {
      "epoch": 6.766265060240964,
      "grad_norm": 0.0012292275205254555,
      "learning_rate": 6.4674698795180725e-06,
      "loss": 0.0178,
      "step": 56160
    },
    {
      "epoch": 6.767469879518073,
      "grad_norm": 0.00939246267080307,
      "learning_rate": 6.4650602409638565e-06,
      "loss": 0.0001,
      "step": 56170
    },
    {
      "epoch": 6.768674698795181,
      "grad_norm": 0.13055916130542755,
      "learning_rate": 6.462650602409639e-06,
      "loss": 0.0073,
      "step": 56180
    },
    {
      "epoch": 6.7698795180722895,
      "grad_norm": 23.2426700592041,
      "learning_rate": 6.460240963855422e-06,
      "loss": 0.0261,
      "step": 56190
    },
    {
      "epoch": 6.771084337349397,
      "grad_norm": 0.0008531001512892544,
      "learning_rate": 6.457831325301205e-06,
      "loss": 0.0467,
      "step": 56200
    },
    {
      "epoch": 6.772289156626506,
      "grad_norm": 0.0013869119575247169,
      "learning_rate": 6.455421686746988e-06,
      "loss": 0.011,
      "step": 56210
    },
    {
      "epoch": 6.773493975903614,
      "grad_norm": 8.763588905334473,
      "learning_rate": 6.4530120481927715e-06,
      "loss": 0.0297,
      "step": 56220
    },
    {
      "epoch": 6.774698795180723,
      "grad_norm": 0.001721182488836348,
      "learning_rate": 6.450602409638555e-06,
      "loss": 0.0573,
      "step": 56230
    },
    {
      "epoch": 6.775903614457832,
      "grad_norm": 2.217310905456543,
      "learning_rate": 6.448192771084339e-06,
      "loss": 0.0905,
      "step": 56240
    },
    {
      "epoch": 6.77710843373494,
      "grad_norm": 0.01871495507657528,
      "learning_rate": 6.445783132530121e-06,
      "loss": 0.0407,
      "step": 56250
    },
    {
      "epoch": 6.7783132530120485,
      "grad_norm": 0.001973299542441964,
      "learning_rate": 6.443373493975904e-06,
      "loss": 0.0048,
      "step": 56260
    },
    {
      "epoch": 6.779518072289156,
      "grad_norm": 0.001980024157091975,
      "learning_rate": 6.4409638554216866e-06,
      "loss": 0.008,
      "step": 56270
    },
    {
      "epoch": 6.780722891566265,
      "grad_norm": 3.5737738609313965,
      "learning_rate": 6.438554216867471e-06,
      "loss": 0.0513,
      "step": 56280
    },
    {
      "epoch": 6.781927710843373,
      "grad_norm": 0.0057910350151360035,
      "learning_rate": 6.436144578313254e-06,
      "loss": 0.0195,
      "step": 56290
    },
    {
      "epoch": 6.783132530120482,
      "grad_norm": 0.15292634069919586,
      "learning_rate": 6.433734939759036e-06,
      "loss": 0.0198,
      "step": 56300
    },
    {
      "epoch": 6.784337349397591,
      "grad_norm": 0.58995521068573,
      "learning_rate": 6.431325301204819e-06,
      "loss": 0.0392,
      "step": 56310
    },
    {
      "epoch": 6.785542168674699,
      "grad_norm": 0.8998782634735107,
      "learning_rate": 6.428915662650603e-06,
      "loss": 0.0126,
      "step": 56320
    },
    {
      "epoch": 6.786746987951807,
      "grad_norm": 1.9569981098175049,
      "learning_rate": 6.4265060240963865e-06,
      "loss": 0.0365,
      "step": 56330
    },
    {
      "epoch": 6.787951807228915,
      "grad_norm": 1.0961929559707642,
      "learning_rate": 6.424096385542169e-06,
      "loss": 0.033,
      "step": 56340
    },
    {
      "epoch": 6.789156626506024,
      "grad_norm": 0.008839646354317665,
      "learning_rate": 6.421686746987952e-06,
      "loss": 0.0167,
      "step": 56350
    },
    {
      "epoch": 6.790361445783132,
      "grad_norm": 2.756373643875122,
      "learning_rate": 6.419277108433736e-06,
      "loss": 0.0156,
      "step": 56360
    },
    {
      "epoch": 6.791566265060241,
      "grad_norm": 0.04639747366309166,
      "learning_rate": 6.416867469879518e-06,
      "loss": 0.0222,
      "step": 56370
    },
    {
      "epoch": 6.79277108433735,
      "grad_norm": 0.033999036997556686,
      "learning_rate": 6.4144578313253015e-06,
      "loss": 0.0436,
      "step": 56380
    },
    {
      "epoch": 6.793975903614458,
      "grad_norm": 1.6842464208602905,
      "learning_rate": 6.4120481927710855e-06,
      "loss": 0.0318,
      "step": 56390
    },
    {
      "epoch": 6.795180722891566,
      "grad_norm": 0.8918188810348511,
      "learning_rate": 6.409638554216868e-06,
      "loss": 0.009,
      "step": 56400
    },
    {
      "epoch": 6.796385542168675,
      "grad_norm": 0.011017962358891964,
      "learning_rate": 6.407228915662651e-06,
      "loss": 0.0276,
      "step": 56410
    },
    {
      "epoch": 6.797590361445783,
      "grad_norm": 1.131866455078125,
      "learning_rate": 6.404819277108434e-06,
      "loss": 0.0138,
      "step": 56420
    },
    {
      "epoch": 6.798795180722892,
      "grad_norm": 0.15778033435344696,
      "learning_rate": 6.402409638554218e-06,
      "loss": 0.046,
      "step": 56430
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.0045558856800198555,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0071,
      "step": 56440
    },
    {
      "epoch": 6.801204819277109,
      "grad_norm": 1.8405948877334595,
      "learning_rate": 6.397590361445784e-06,
      "loss": 0.027,
      "step": 56450
    },
    {
      "epoch": 6.8024096385542165,
      "grad_norm": 0.27087634801864624,
      "learning_rate": 6.395180722891566e-06,
      "loss": 0.0124,
      "step": 56460
    },
    {
      "epoch": 6.803614457831325,
      "grad_norm": 0.009659730829298496,
      "learning_rate": 6.39277108433735e-06,
      "loss": 0.0045,
      "step": 56470
    },
    {
      "epoch": 6.804819277108434,
      "grad_norm": 0.27764320373535156,
      "learning_rate": 6.390361445783133e-06,
      "loss": 0.0131,
      "step": 56480
    },
    {
      "epoch": 6.806024096385542,
      "grad_norm": 0.002066168002784252,
      "learning_rate": 6.387951807228916e-06,
      "loss": 0.0126,
      "step": 56490
    },
    {
      "epoch": 6.807228915662651,
      "grad_norm": 2.523179292678833,
      "learning_rate": 6.385542168674699e-06,
      "loss": 0.0312,
      "step": 56500
    },
    {
      "epoch": 6.808433734939759,
      "grad_norm": 3.377119541168213,
      "learning_rate": 6.383132530120483e-06,
      "loss": 0.0264,
      "step": 56510
    },
    {
      "epoch": 6.809638554216868,
      "grad_norm": 0.908607006072998,
      "learning_rate": 6.380722891566266e-06,
      "loss": 0.0167,
      "step": 56520
    },
    {
      "epoch": 6.8108433734939755,
      "grad_norm": 0.23183892667293549,
      "learning_rate": 6.378313253012048e-06,
      "loss": 0.0069,
      "step": 56530
    },
    {
      "epoch": 6.812048192771084,
      "grad_norm": 0.004562039393931627,
      "learning_rate": 6.375903614457832e-06,
      "loss": 0.0155,
      "step": 56540
    },
    {
      "epoch": 6.813253012048193,
      "grad_norm": 0.01636829786002636,
      "learning_rate": 6.3734939759036155e-06,
      "loss": 0.0033,
      "step": 56550
    },
    {
      "epoch": 6.814457831325301,
      "grad_norm": 0.4640529453754425,
      "learning_rate": 6.371084337349398e-06,
      "loss": 0.0135,
      "step": 56560
    },
    {
      "epoch": 6.81566265060241,
      "grad_norm": 0.0024887591134756804,
      "learning_rate": 6.368674698795181e-06,
      "loss": 0.0833,
      "step": 56570
    },
    {
      "epoch": 6.816867469879518,
      "grad_norm": 0.019001256674528122,
      "learning_rate": 6.366265060240965e-06,
      "loss": 0.0096,
      "step": 56580
    },
    {
      "epoch": 6.8180722891566266,
      "grad_norm": 0.450997918844223,
      "learning_rate": 6.363855421686747e-06,
      "loss": 0.0153,
      "step": 56590
    },
    {
      "epoch": 6.8192771084337345,
      "grad_norm": 0.29593536257743835,
      "learning_rate": 6.3614457831325305e-06,
      "loss": 0.0027,
      "step": 56600
    },
    {
      "epoch": 6.820481927710843,
      "grad_norm": 0.002913320902734995,
      "learning_rate": 6.359036144578314e-06,
      "loss": 0.0049,
      "step": 56610
    },
    {
      "epoch": 6.821686746987952,
      "grad_norm": 0.004308984614908695,
      "learning_rate": 6.356626506024097e-06,
      "loss": 0.0081,
      "step": 56620
    },
    {
      "epoch": 6.82289156626506,
      "grad_norm": 0.31231650710105896,
      "learning_rate": 6.35421686746988e-06,
      "loss": 0.0212,
      "step": 56630
    },
    {
      "epoch": 6.824096385542169,
      "grad_norm": 0.0014926678268238902,
      "learning_rate": 6.351807228915663e-06,
      "loss": 0.0216,
      "step": 56640
    },
    {
      "epoch": 6.825301204819278,
      "grad_norm": 0.00535493902862072,
      "learning_rate": 6.3493975903614456e-06,
      "loss": 0.0374,
      "step": 56650
    },
    {
      "epoch": 6.8265060240963855,
      "grad_norm": 0.45145756006240845,
      "learning_rate": 6.34698795180723e-06,
      "loss": 0.0452,
      "step": 56660
    },
    {
      "epoch": 6.827710843373494,
      "grad_norm": 0.009205514565110207,
      "learning_rate": 6.344578313253013e-06,
      "loss": 0.0327,
      "step": 56670
    },
    {
      "epoch": 6.828915662650602,
      "grad_norm": 0.2611442804336548,
      "learning_rate": 6.342168674698795e-06,
      "loss": 0.0382,
      "step": 56680
    },
    {
      "epoch": 6.830120481927711,
      "grad_norm": 0.019789166748523712,
      "learning_rate": 6.339759036144579e-06,
      "loss": 0.0387,
      "step": 56690
    },
    {
      "epoch": 6.831325301204819,
      "grad_norm": 0.207380473613739,
      "learning_rate": 6.337349397590362e-06,
      "loss": 0.0087,
      "step": 56700
    },
    {
      "epoch": 6.832530120481928,
      "grad_norm": 0.406096488237381,
      "learning_rate": 6.334939759036145e-06,
      "loss": 0.0378,
      "step": 56710
    },
    {
      "epoch": 6.833734939759037,
      "grad_norm": 0.47388795018196106,
      "learning_rate": 6.332530120481928e-06,
      "loss": 0.0094,
      "step": 56720
    },
    {
      "epoch": 6.8349397590361445,
      "grad_norm": 0.20510081946849823,
      "learning_rate": 6.330120481927712e-06,
      "loss": 0.0086,
      "step": 56730
    },
    {
      "epoch": 6.836144578313253,
      "grad_norm": 1.2056989669799805,
      "learning_rate": 6.327710843373495e-06,
      "loss": 0.0298,
      "step": 56740
    },
    {
      "epoch": 6.837349397590361,
      "grad_norm": 0.004067417699843645,
      "learning_rate": 6.325301204819277e-06,
      "loss": 0.0419,
      "step": 56750
    },
    {
      "epoch": 6.83855421686747,
      "grad_norm": 0.5318115949630737,
      "learning_rate": 6.3228915662650605e-06,
      "loss": 0.0269,
      "step": 56760
    },
    {
      "epoch": 6.839759036144578,
      "grad_norm": 0.971139132976532,
      "learning_rate": 6.3204819277108445e-06,
      "loss": 0.0174,
      "step": 56770
    },
    {
      "epoch": 6.840963855421687,
      "grad_norm": 0.012682515196502209,
      "learning_rate": 6.318072289156627e-06,
      "loss": 0.0233,
      "step": 56780
    },
    {
      "epoch": 6.8421686746987955,
      "grad_norm": 0.7597360610961914,
      "learning_rate": 6.31566265060241e-06,
      "loss": 0.0243,
      "step": 56790
    },
    {
      "epoch": 6.843373493975903,
      "grad_norm": 1.2194830179214478,
      "learning_rate": 6.313253012048192e-06,
      "loss": 0.0192,
      "step": 56800
    },
    {
      "epoch": 6.844578313253012,
      "grad_norm": 0.1600905954837799,
      "learning_rate": 6.310843373493976e-06,
      "loss": 0.0082,
      "step": 56810
    },
    {
      "epoch": 6.84578313253012,
      "grad_norm": 0.006617002189159393,
      "learning_rate": 6.3084337349397596e-06,
      "loss": 0.0376,
      "step": 56820
    },
    {
      "epoch": 6.846987951807229,
      "grad_norm": 1.765838861465454,
      "learning_rate": 6.306024096385543e-06,
      "loss": 0.0237,
      "step": 56830
    },
    {
      "epoch": 6.848192771084337,
      "grad_norm": 0.0014981860294938087,
      "learning_rate": 6.303614457831326e-06,
      "loss": 0.0046,
      "step": 56840
    },
    {
      "epoch": 6.849397590361446,
      "grad_norm": 2.57916259765625,
      "learning_rate": 6.301204819277109e-06,
      "loss": 0.0309,
      "step": 56850
    },
    {
      "epoch": 6.8506024096385545,
      "grad_norm": 0.010427591390907764,
      "learning_rate": 6.298795180722892e-06,
      "loss": 0.0277,
      "step": 56860
    },
    {
      "epoch": 6.851807228915662,
      "grad_norm": 1.5130282640457153,
      "learning_rate": 6.296385542168675e-06,
      "loss": 0.017,
      "step": 56870
    },
    {
      "epoch": 6.853012048192771,
      "grad_norm": 0.002743918215855956,
      "learning_rate": 6.293975903614459e-06,
      "loss": 0.0096,
      "step": 56880
    },
    {
      "epoch": 6.85421686746988,
      "grad_norm": 0.0029263768810778856,
      "learning_rate": 6.291566265060242e-06,
      "loss": 0.0129,
      "step": 56890
    },
    {
      "epoch": 6.855421686746988,
      "grad_norm": 0.0012400635750964284,
      "learning_rate": 6.289156626506024e-06,
      "loss": 0.0136,
      "step": 56900
    },
    {
      "epoch": 6.856626506024097,
      "grad_norm": 0.050821367651224136,
      "learning_rate": 6.286746987951807e-06,
      "loss": 0.007,
      "step": 56910
    },
    {
      "epoch": 6.857831325301205,
      "grad_norm": 0.002406930550932884,
      "learning_rate": 6.284337349397591e-06,
      "loss": 0.0251,
      "step": 56920
    },
    {
      "epoch": 6.8590361445783135,
      "grad_norm": 0.00996608380228281,
      "learning_rate": 6.281927710843374e-06,
      "loss": 0.0232,
      "step": 56930
    },
    {
      "epoch": 6.860240963855421,
      "grad_norm": 0.00973507296293974,
      "learning_rate": 6.279518072289157e-06,
      "loss": 0.0391,
      "step": 56940
    },
    {
      "epoch": 6.86144578313253,
      "grad_norm": 0.003867811756208539,
      "learning_rate": 6.27710843373494e-06,
      "loss": 0.018,
      "step": 56950
    },
    {
      "epoch": 6.862650602409639,
      "grad_norm": 0.003946829121559858,
      "learning_rate": 6.274698795180724e-06,
      "loss": 0.0327,
      "step": 56960
    },
    {
      "epoch": 6.863855421686747,
      "grad_norm": 1.5936193466186523,
      "learning_rate": 6.272289156626506e-06,
      "loss": 0.0148,
      "step": 56970
    },
    {
      "epoch": 6.865060240963856,
      "grad_norm": 0.11554902046918869,
      "learning_rate": 6.2698795180722895e-06,
      "loss": 0.0034,
      "step": 56980
    },
    {
      "epoch": 6.866265060240964,
      "grad_norm": 0.11263572424650192,
      "learning_rate": 6.2674698795180735e-06,
      "loss": 0.0155,
      "step": 56990
    },
    {
      "epoch": 6.867469879518072,
      "grad_norm": 0.007642436772584915,
      "learning_rate": 6.265060240963856e-06,
      "loss": 0.0063,
      "step": 57000
    },
    {
      "epoch": 6.86867469879518,
      "grad_norm": 0.001670941011980176,
      "learning_rate": 6.262650602409639e-06,
      "loss": 0.0029,
      "step": 57010
    },
    {
      "epoch": 6.869879518072289,
      "grad_norm": 0.00745194498449564,
      "learning_rate": 6.260240963855421e-06,
      "loss": 0.0175,
      "step": 57020
    },
    {
      "epoch": 6.871084337349398,
      "grad_norm": 0.05675539746880531,
      "learning_rate": 6.257831325301205e-06,
      "loss": 0.0053,
      "step": 57030
    },
    {
      "epoch": 6.872289156626506,
      "grad_norm": 0.8938064575195312,
      "learning_rate": 6.255421686746989e-06,
      "loss": 0.0519,
      "step": 57040
    },
    {
      "epoch": 6.873493975903615,
      "grad_norm": 1.7989614009857178,
      "learning_rate": 6.253012048192772e-06,
      "loss": 0.0135,
      "step": 57050
    },
    {
      "epoch": 6.874698795180723,
      "grad_norm": 0.002960756653919816,
      "learning_rate": 6.250602409638554e-06,
      "loss": 0.0021,
      "step": 57060
    },
    {
      "epoch": 6.875903614457831,
      "grad_norm": 0.009409859776496887,
      "learning_rate": 6.248192771084338e-06,
      "loss": 0.0063,
      "step": 57070
    },
    {
      "epoch": 6.877108433734939,
      "grad_norm": 0.8581563234329224,
      "learning_rate": 6.245783132530121e-06,
      "loss": 0.0051,
      "step": 57080
    },
    {
      "epoch": 6.878313253012048,
      "grad_norm": 0.007955696433782578,
      "learning_rate": 6.243373493975904e-06,
      "loss": 0.0066,
      "step": 57090
    },
    {
      "epoch": 6.879518072289157,
      "grad_norm": 0.0012805379228666425,
      "learning_rate": 6.240963855421688e-06,
      "loss": 0.0336,
      "step": 57100
    },
    {
      "epoch": 6.880722891566265,
      "grad_norm": 0.004394290503114462,
      "learning_rate": 6.238554216867471e-06,
      "loss": 0.0158,
      "step": 57110
    },
    {
      "epoch": 6.881927710843374,
      "grad_norm": 0.0017906230641528964,
      "learning_rate": 6.236144578313253e-06,
      "loss": 0.0327,
      "step": 57120
    },
    {
      "epoch": 6.8831325301204815,
      "grad_norm": 0.17381992936134338,
      "learning_rate": 6.233734939759036e-06,
      "loss": 0.0178,
      "step": 57130
    },
    {
      "epoch": 6.88433734939759,
      "grad_norm": 0.003904317505657673,
      "learning_rate": 6.23132530120482e-06,
      "loss": 0.0225,
      "step": 57140
    },
    {
      "epoch": 6.885542168674699,
      "grad_norm": 0.0030841254629194736,
      "learning_rate": 6.2289156626506035e-06,
      "loss": 0.0057,
      "step": 57150
    },
    {
      "epoch": 6.886746987951807,
      "grad_norm": 1.8349272012710571,
      "learning_rate": 6.226506024096386e-06,
      "loss": 0.0262,
      "step": 57160
    },
    {
      "epoch": 6.887951807228916,
      "grad_norm": 0.0019353299867361784,
      "learning_rate": 6.224096385542169e-06,
      "loss": 0.0066,
      "step": 57170
    },
    {
      "epoch": 6.889156626506024,
      "grad_norm": 0.0043970379047095776,
      "learning_rate": 6.221686746987953e-06,
      "loss": 0.0058,
      "step": 57180
    },
    {
      "epoch": 6.890361445783133,
      "grad_norm": 0.010201948694884777,
      "learning_rate": 6.219277108433735e-06,
      "loss": 0.0099,
      "step": 57190
    },
    {
      "epoch": 6.891566265060241,
      "grad_norm": 0.0014346822863444686,
      "learning_rate": 6.2168674698795185e-06,
      "loss": 0.0074,
      "step": 57200
    },
    {
      "epoch": 6.892771084337349,
      "grad_norm": 0.3680194318294525,
      "learning_rate": 6.214457831325301e-06,
      "loss": 0.0086,
      "step": 57210
    },
    {
      "epoch": 6.893975903614458,
      "grad_norm": 1.9101618528366089,
      "learning_rate": 6.212048192771085e-06,
      "loss": 0.0682,
      "step": 57220
    },
    {
      "epoch": 6.895180722891566,
      "grad_norm": 0.001648448989726603,
      "learning_rate": 6.209638554216868e-06,
      "loss": 0.004,
      "step": 57230
    },
    {
      "epoch": 6.896385542168675,
      "grad_norm": 0.4944610297679901,
      "learning_rate": 6.207228915662651e-06,
      "loss": 0.0144,
      "step": 57240
    },
    {
      "epoch": 6.897590361445783,
      "grad_norm": 2.9723563194274902,
      "learning_rate": 6.2048192771084344e-06,
      "loss": 0.0141,
      "step": 57250
    },
    {
      "epoch": 6.8987951807228916,
      "grad_norm": 0.053258951753377914,
      "learning_rate": 6.202409638554218e-06,
      "loss": 0.0053,
      "step": 57260
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.0017205424373969436,
      "learning_rate": 6.200000000000001e-06,
      "loss": 0.0111,
      "step": 57270
    },
    {
      "epoch": 6.901204819277108,
      "grad_norm": 0.0040067629888653755,
      "learning_rate": 6.197590361445783e-06,
      "loss": 0.0051,
      "step": 57280
    },
    {
      "epoch": 6.902409638554217,
      "grad_norm": 0.0042813546024262905,
      "learning_rate": 6.195180722891567e-06,
      "loss": 0.0096,
      "step": 57290
    },
    {
      "epoch": 6.903614457831325,
      "grad_norm": 0.001940065762028098,
      "learning_rate": 6.19277108433735e-06,
      "loss": 0.0015,
      "step": 57300
    },
    {
      "epoch": 6.904819277108434,
      "grad_norm": 0.011285698041319847,
      "learning_rate": 6.190361445783133e-06,
      "loss": 0.0061,
      "step": 57310
    },
    {
      "epoch": 6.906024096385542,
      "grad_norm": 0.0014214316615834832,
      "learning_rate": 6.187951807228916e-06,
      "loss": 0.0109,
      "step": 57320
    },
    {
      "epoch": 6.9072289156626505,
      "grad_norm": 0.00211886502802372,
      "learning_rate": 6.1855421686747e-06,
      "loss": 0.0462,
      "step": 57330
    },
    {
      "epoch": 6.908433734939759,
      "grad_norm": 0.0035054085310548544,
      "learning_rate": 6.183132530120482e-06,
      "loss": 0.0436,
      "step": 57340
    },
    {
      "epoch": 6.909638554216867,
      "grad_norm": 0.0017694056732580066,
      "learning_rate": 6.180722891566265e-06,
      "loss": 0.0159,
      "step": 57350
    },
    {
      "epoch": 6.910843373493976,
      "grad_norm": 1.4854575395584106,
      "learning_rate": 6.1783132530120485e-06,
      "loss": 0.0078,
      "step": 57360
    },
    {
      "epoch": 6.912048192771084,
      "grad_norm": 0.0010465719969943166,
      "learning_rate": 6.1759036144578325e-06,
      "loss": 0.0142,
      "step": 57370
    },
    {
      "epoch": 6.913253012048193,
      "grad_norm": 4.627649307250977,
      "learning_rate": 6.173493975903615e-06,
      "loss": 0.016,
      "step": 57380
    },
    {
      "epoch": 6.914457831325302,
      "grad_norm": 0.19572748243808746,
      "learning_rate": 6.171084337349398e-06,
      "loss": 0.014,
      "step": 57390
    },
    {
      "epoch": 6.9156626506024095,
      "grad_norm": 0.08387764543294907,
      "learning_rate": 6.168674698795182e-06,
      "loss": 0.0009,
      "step": 57400
    },
    {
      "epoch": 6.916867469879518,
      "grad_norm": 0.002647253219038248,
      "learning_rate": 6.166265060240964e-06,
      "loss": 0.0255,
      "step": 57410
    },
    {
      "epoch": 6.918072289156626,
      "grad_norm": 0.00195868662558496,
      "learning_rate": 6.1638554216867476e-06,
      "loss": 0.0054,
      "step": 57420
    },
    {
      "epoch": 6.919277108433735,
      "grad_norm": 0.0012509633088484406,
      "learning_rate": 6.16144578313253e-06,
      "loss": 0.0391,
      "step": 57430
    },
    {
      "epoch": 6.920481927710844,
      "grad_norm": 0.7300813794136047,
      "learning_rate": 6.159036144578314e-06,
      "loss": 0.0055,
      "step": 57440
    },
    {
      "epoch": 6.921686746987952,
      "grad_norm": 1.3614553213119507,
      "learning_rate": 6.156626506024097e-06,
      "loss": 0.0385,
      "step": 57450
    },
    {
      "epoch": 6.9228915662650605,
      "grad_norm": 0.0011151951039209962,
      "learning_rate": 6.15421686746988e-06,
      "loss": 0.0287,
      "step": 57460
    },
    {
      "epoch": 6.924096385542168,
      "grad_norm": 0.006034779828041792,
      "learning_rate": 6.151807228915663e-06,
      "loss": 0.0098,
      "step": 57470
    },
    {
      "epoch": 6.925301204819277,
      "grad_norm": 0.16135621070861816,
      "learning_rate": 6.149397590361447e-06,
      "loss": 0.029,
      "step": 57480
    },
    {
      "epoch": 6.926506024096385,
      "grad_norm": 0.36698561906814575,
      "learning_rate": 6.14698795180723e-06,
      "loss": 0.0187,
      "step": 57490
    },
    {
      "epoch": 6.927710843373494,
      "grad_norm": 0.0009218193008564413,
      "learning_rate": 6.144578313253012e-06,
      "loss": 0.009,
      "step": 57500
    },
    {
      "epoch": 6.928915662650603,
      "grad_norm": 6.4619669914245605,
      "learning_rate": 6.142168674698795e-06,
      "loss": 0.004,
      "step": 57510
    },
    {
      "epoch": 6.930120481927711,
      "grad_norm": 0.003339298302307725,
      "learning_rate": 6.139759036144579e-06,
      "loss": 0.0408,
      "step": 57520
    },
    {
      "epoch": 6.9313253012048195,
      "grad_norm": 0.01708332449197769,
      "learning_rate": 6.137349397590362e-06,
      "loss": 0.0022,
      "step": 57530
    },
    {
      "epoch": 6.932530120481927,
      "grad_norm": 0.13450084626674652,
      "learning_rate": 6.134939759036145e-06,
      "loss": 0.0497,
      "step": 57540
    },
    {
      "epoch": 6.933734939759036,
      "grad_norm": 7.103522777557373,
      "learning_rate": 6.132530120481929e-06,
      "loss": 0.0352,
      "step": 57550
    },
    {
      "epoch": 6.934939759036144,
      "grad_norm": 1.7973148822784424,
      "learning_rate": 6.130120481927711e-06,
      "loss": 0.0202,
      "step": 57560
    },
    {
      "epoch": 6.936144578313253,
      "grad_norm": 1.1706786155700684,
      "learning_rate": 6.127710843373494e-06,
      "loss": 0.0402,
      "step": 57570
    },
    {
      "epoch": 6.937349397590362,
      "grad_norm": 0.001677677035331726,
      "learning_rate": 6.1253012048192775e-06,
      "loss": 0.0038,
      "step": 57580
    },
    {
      "epoch": 6.93855421686747,
      "grad_norm": 0.006736944895237684,
      "learning_rate": 6.1228915662650616e-06,
      "loss": 0.0351,
      "step": 57590
    },
    {
      "epoch": 6.9397590361445785,
      "grad_norm": 1.6236664056777954,
      "learning_rate": 6.120481927710844e-06,
      "loss": 0.0216,
      "step": 57600
    },
    {
      "epoch": 6.940963855421686,
      "grad_norm": 1.176608681678772,
      "learning_rate": 6.118072289156627e-06,
      "loss": 0.0198,
      "step": 57610
    },
    {
      "epoch": 6.942168674698795,
      "grad_norm": 0.007118337322026491,
      "learning_rate": 6.115662650602409e-06,
      "loss": 0.0322,
      "step": 57620
    },
    {
      "epoch": 6.943373493975904,
      "grad_norm": 0.001749690156430006,
      "learning_rate": 6.113253012048193e-06,
      "loss": 0.0178,
      "step": 57630
    },
    {
      "epoch": 6.944578313253012,
      "grad_norm": 0.0022263280116021633,
      "learning_rate": 6.110843373493977e-06,
      "loss": 0.0163,
      "step": 57640
    },
    {
      "epoch": 6.945783132530121,
      "grad_norm": 0.0023335982114076614,
      "learning_rate": 6.108433734939759e-06,
      "loss": 0.0516,
      "step": 57650
    },
    {
      "epoch": 6.946987951807229,
      "grad_norm": 0.0635058656334877,
      "learning_rate": 6.106024096385542e-06,
      "loss": 0.02,
      "step": 57660
    },
    {
      "epoch": 6.948192771084337,
      "grad_norm": 0.00978464912623167,
      "learning_rate": 6.103614457831326e-06,
      "loss": 0.0284,
      "step": 57670
    },
    {
      "epoch": 6.949397590361446,
      "grad_norm": 0.0020878377836197615,
      "learning_rate": 6.101204819277109e-06,
      "loss": 0.0019,
      "step": 57680
    },
    {
      "epoch": 6.950602409638554,
      "grad_norm": 0.00131484295707196,
      "learning_rate": 6.098795180722892e-06,
      "loss": 0.0184,
      "step": 57690
    },
    {
      "epoch": 6.951807228915663,
      "grad_norm": 0.013324404135346413,
      "learning_rate": 6.096385542168676e-06,
      "loss": 0.021,
      "step": 57700
    },
    {
      "epoch": 6.953012048192771,
      "grad_norm": 0.06955579668283463,
      "learning_rate": 6.093975903614459e-06,
      "loss": 0.009,
      "step": 57710
    },
    {
      "epoch": 6.95421686746988,
      "grad_norm": 2.3201942443847656,
      "learning_rate": 6.091566265060241e-06,
      "loss": 0.0304,
      "step": 57720
    },
    {
      "epoch": 6.955421686746988,
      "grad_norm": 0.011882410384714603,
      "learning_rate": 6.089156626506024e-06,
      "loss": 0.0363,
      "step": 57730
    },
    {
      "epoch": 6.956626506024096,
      "grad_norm": 0.016850341111421585,
      "learning_rate": 6.086746987951808e-06,
      "loss": 0.0089,
      "step": 57740
    },
    {
      "epoch": 6.957831325301205,
      "grad_norm": 0.009451526217162609,
      "learning_rate": 6.084337349397591e-06,
      "loss": 0.0013,
      "step": 57750
    },
    {
      "epoch": 6.959036144578313,
      "grad_norm": 0.011130055412650108,
      "learning_rate": 6.081927710843374e-06,
      "loss": 0.0031,
      "step": 57760
    },
    {
      "epoch": 6.960240963855422,
      "grad_norm": 0.017992252483963966,
      "learning_rate": 6.079518072289157e-06,
      "loss": 0.0094,
      "step": 57770
    },
    {
      "epoch": 6.96144578313253,
      "grad_norm": 0.0045708357356488705,
      "learning_rate": 6.077108433734941e-06,
      "loss": 0.0016,
      "step": 57780
    },
    {
      "epoch": 6.962650602409639,
      "grad_norm": 0.0032796140294522047,
      "learning_rate": 6.074698795180723e-06,
      "loss": 0.0479,
      "step": 57790
    },
    {
      "epoch": 6.9638554216867465,
      "grad_norm": 4.0893144607543945,
      "learning_rate": 6.0722891566265066e-06,
      "loss": 0.011,
      "step": 57800
    },
    {
      "epoch": 6.965060240963855,
      "grad_norm": 0.12761004269123077,
      "learning_rate": 6.069879518072289e-06,
      "loss": 0.0248,
      "step": 57810
    },
    {
      "epoch": 6.966265060240964,
      "grad_norm": 0.02408646233379841,
      "learning_rate": 6.067469879518073e-06,
      "loss": 0.0135,
      "step": 57820
    },
    {
      "epoch": 6.967469879518072,
      "grad_norm": 0.7751086354255676,
      "learning_rate": 6.065060240963856e-06,
      "loss": 0.0598,
      "step": 57830
    },
    {
      "epoch": 6.968674698795181,
      "grad_norm": 0.06314005702733994,
      "learning_rate": 6.062650602409638e-06,
      "loss": 0.0349,
      "step": 57840
    },
    {
      "epoch": 6.969879518072289,
      "grad_norm": 0.6543581485748291,
      "learning_rate": 6.0602409638554224e-06,
      "loss": 0.0515,
      "step": 57850
    },
    {
      "epoch": 6.971084337349398,
      "grad_norm": 1.5619202852249146,
      "learning_rate": 6.057831325301206e-06,
      "loss": 0.0438,
      "step": 57860
    },
    {
      "epoch": 6.972289156626506,
      "grad_norm": 0.6980741620063782,
      "learning_rate": 6.055421686746989e-06,
      "loss": 0.0242,
      "step": 57870
    },
    {
      "epoch": 6.973493975903614,
      "grad_norm": 0.05883161351084709,
      "learning_rate": 6.053012048192771e-06,
      "loss": 0.0011,
      "step": 57880
    },
    {
      "epoch": 6.974698795180723,
      "grad_norm": 0.17379671335220337,
      "learning_rate": 6.050602409638555e-06,
      "loss": 0.0078,
      "step": 57890
    },
    {
      "epoch": 6.975903614457831,
      "grad_norm": 0.039369549602270126,
      "learning_rate": 6.048192771084338e-06,
      "loss": 0.0089,
      "step": 57900
    },
    {
      "epoch": 6.97710843373494,
      "grad_norm": 0.09923981130123138,
      "learning_rate": 6.045783132530121e-06,
      "loss": 0.0059,
      "step": 57910
    },
    {
      "epoch": 6.978313253012049,
      "grad_norm": 1.602612853050232,
      "learning_rate": 6.043373493975904e-06,
      "loss": 0.0367,
      "step": 57920
    },
    {
      "epoch": 6.9795180722891565,
      "grad_norm": 0.006686176639050245,
      "learning_rate": 6.040963855421688e-06,
      "loss": 0.0148,
      "step": 57930
    },
    {
      "epoch": 6.980722891566265,
      "grad_norm": 0.03193956986069679,
      "learning_rate": 6.03855421686747e-06,
      "loss": 0.011,
      "step": 57940
    },
    {
      "epoch": 6.981927710843373,
      "grad_norm": 0.023411398753523827,
      "learning_rate": 6.036144578313253e-06,
      "loss": 0.0911,
      "step": 57950
    },
    {
      "epoch": 6.983132530120482,
      "grad_norm": 40.892269134521484,
      "learning_rate": 6.0337349397590365e-06,
      "loss": 0.0504,
      "step": 57960
    },
    {
      "epoch": 6.98433734939759,
      "grad_norm": 0.04360548034310341,
      "learning_rate": 6.03132530120482e-06,
      "loss": 0.0224,
      "step": 57970
    },
    {
      "epoch": 6.985542168674699,
      "grad_norm": 0.8370510339736938,
      "learning_rate": 6.028915662650603e-06,
      "loss": 0.0658,
      "step": 57980
    },
    {
      "epoch": 6.986746987951808,
      "grad_norm": 0.5231708884239197,
      "learning_rate": 6.026506024096386e-06,
      "loss": 0.0106,
      "step": 57990
    },
    {
      "epoch": 6.9879518072289155,
      "grad_norm": 1.4728376865386963,
      "learning_rate": 6.02409638554217e-06,
      "loss": 0.0223,
      "step": 58000
    },
    {
      "epoch": 6.989156626506024,
      "grad_norm": 0.15659579634666443,
      "learning_rate": 6.021686746987952e-06,
      "loss": 0.0164,
      "step": 58010
    },
    {
      "epoch": 6.990361445783132,
      "grad_norm": 0.002497221576049924,
      "learning_rate": 6.019277108433736e-06,
      "loss": 0.0257,
      "step": 58020
    },
    {
      "epoch": 6.991566265060241,
      "grad_norm": 1.2020167112350464,
      "learning_rate": 6.016867469879518e-06,
      "loss": 0.0201,
      "step": 58030
    },
    {
      "epoch": 6.992771084337349,
      "grad_norm": 0.005670551210641861,
      "learning_rate": 6.014457831325302e-06,
      "loss": 0.0097,
      "step": 58040
    },
    {
      "epoch": 6.993975903614458,
      "grad_norm": 0.01435794122517109,
      "learning_rate": 6.012048192771085e-06,
      "loss": 0.0048,
      "step": 58050
    },
    {
      "epoch": 6.995180722891567,
      "grad_norm": 1.3882958889007568,
      "learning_rate": 6.0096385542168674e-06,
      "loss": 0.0234,
      "step": 58060
    },
    {
      "epoch": 6.9963855421686745,
      "grad_norm": 56.89952087402344,
      "learning_rate": 6.007228915662651e-06,
      "loss": 0.0253,
      "step": 58070
    },
    {
      "epoch": 6.997590361445783,
      "grad_norm": 0.16884180903434753,
      "learning_rate": 6.004819277108435e-06,
      "loss": 0.0318,
      "step": 58080
    },
    {
      "epoch": 6.998795180722891,
      "grad_norm": 3.83351469039917,
      "learning_rate": 6.002409638554218e-06,
      "loss": 0.0271,
      "step": 58090
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0390738919377327,
      "learning_rate": 6e-06,
      "loss": 0.0021,
      "step": 58100
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9869469441319835,
      "eval_f1": 0.9653153994644748,
      "eval_loss": 0.043914664536714554,
      "eval_precision": 0.9727660642570282,
      "eval_recall": 0.9579780002471883,
      "eval_runtime": 3409.3931,
      "eval_samples_per_second": 12.521,
      "eval_steps_per_second": 0.522,
      "step": 58100
    },
    {
      "epoch": 7.001204819277109,
      "grad_norm": 0.019535614177584648,
      "learning_rate": 5.997590361445783e-06,
      "loss": 0.0098,
      "step": 58110
    },
    {
      "epoch": 7.002409638554217,
      "grad_norm": 6.64731502532959,
      "learning_rate": 5.995180722891567e-06,
      "loss": 0.0311,
      "step": 58120
    },
    {
      "epoch": 7.0036144578313255,
      "grad_norm": 0.2238035351037979,
      "learning_rate": 5.99277108433735e-06,
      "loss": 0.0129,
      "step": 58130
    },
    {
      "epoch": 7.004819277108433,
      "grad_norm": 0.0044569456949830055,
      "learning_rate": 5.990361445783133e-06,
      "loss": 0.0286,
      "step": 58140
    },
    {
      "epoch": 7.006024096385542,
      "grad_norm": 0.004414563067257404,
      "learning_rate": 5.987951807228917e-06,
      "loss": 0.0702,
      "step": 58150
    },
    {
      "epoch": 7.00722891566265,
      "grad_norm": 0.009221982210874557,
      "learning_rate": 5.985542168674699e-06,
      "loss": 0.0319,
      "step": 58160
    },
    {
      "epoch": 7.008433734939759,
      "grad_norm": 0.00508121307939291,
      "learning_rate": 5.983132530120482e-06,
      "loss": 0.0109,
      "step": 58170
    },
    {
      "epoch": 7.009638554216868,
      "grad_norm": 0.012611087411642075,
      "learning_rate": 5.9807228915662656e-06,
      "loss": 0.034,
      "step": 58180
    },
    {
      "epoch": 7.010843373493976,
      "grad_norm": 1.1139154434204102,
      "learning_rate": 5.978313253012049e-06,
      "loss": 0.0162,
      "step": 58190
    },
    {
      "epoch": 7.0120481927710845,
      "grad_norm": 0.011080087162554264,
      "learning_rate": 5.975903614457832e-06,
      "loss": 0.0172,
      "step": 58200
    },
    {
      "epoch": 7.013253012048192,
      "grad_norm": 1.7167425155639648,
      "learning_rate": 5.973493975903615e-06,
      "loss": 0.0381,
      "step": 58210
    },
    {
      "epoch": 7.014457831325301,
      "grad_norm": 2.0135791301727295,
      "learning_rate": 5.971084337349397e-06,
      "loss": 0.0422,
      "step": 58220
    },
    {
      "epoch": 7.01566265060241,
      "grad_norm": 0.00907925795763731,
      "learning_rate": 5.9686746987951814e-06,
      "loss": 0.0017,
      "step": 58230
    },
    {
      "epoch": 7.016867469879518,
      "grad_norm": 0.010156567208468914,
      "learning_rate": 5.966265060240965e-06,
      "loss": 0.0049,
      "step": 58240
    },
    {
      "epoch": 7.018072289156627,
      "grad_norm": 0.031011320650577545,
      "learning_rate": 5.963855421686747e-06,
      "loss": 0.0011,
      "step": 58250
    },
    {
      "epoch": 7.019277108433735,
      "grad_norm": 0.9922457933425903,
      "learning_rate": 5.96144578313253e-06,
      "loss": 0.0417,
      "step": 58260
    },
    {
      "epoch": 7.0204819277108435,
      "grad_norm": 2.401250123977661,
      "learning_rate": 5.959036144578314e-06,
      "loss": 0.0315,
      "step": 58270
    },
    {
      "epoch": 7.021686746987951,
      "grad_norm": 0.004427916835993528,
      "learning_rate": 5.9566265060240965e-06,
      "loss": 0.0139,
      "step": 58280
    },
    {
      "epoch": 7.02289156626506,
      "grad_norm": 0.008178293704986572,
      "learning_rate": 5.95421686746988e-06,
      "loss": 0.0419,
      "step": 58290
    },
    {
      "epoch": 7.024096385542169,
      "grad_norm": 0.003926915116608143,
      "learning_rate": 5.951807228915664e-06,
      "loss": 0.0115,
      "step": 58300
    },
    {
      "epoch": 7.025301204819277,
      "grad_norm": 0.0045706359669566154,
      "learning_rate": 5.949397590361447e-06,
      "loss": 0.0115,
      "step": 58310
    },
    {
      "epoch": 7.026506024096386,
      "grad_norm": 0.4493364989757538,
      "learning_rate": 5.946987951807229e-06,
      "loss": 0.0088,
      "step": 58320
    },
    {
      "epoch": 7.027710843373494,
      "grad_norm": 0.0021728554274886847,
      "learning_rate": 5.944578313253012e-06,
      "loss": 0.0104,
      "step": 58330
    },
    {
      "epoch": 7.028915662650602,
      "grad_norm": 0.003304220736026764,
      "learning_rate": 5.942168674698796e-06,
      "loss": 0.0039,
      "step": 58340
    },
    {
      "epoch": 7.030120481927711,
      "grad_norm": 0.3212727904319763,
      "learning_rate": 5.939759036144579e-06,
      "loss": 0.0125,
      "step": 58350
    },
    {
      "epoch": 7.031325301204819,
      "grad_norm": 0.02932576648890972,
      "learning_rate": 5.937349397590362e-06,
      "loss": 0.0233,
      "step": 58360
    },
    {
      "epoch": 7.032530120481928,
      "grad_norm": 0.0017686865758150816,
      "learning_rate": 5.934939759036144e-06,
      "loss": 0.0363,
      "step": 58370
    },
    {
      "epoch": 7.033734939759036,
      "grad_norm": 0.0018996180733665824,
      "learning_rate": 5.932530120481928e-06,
      "loss": 0.0014,
      "step": 58380
    },
    {
      "epoch": 7.034939759036145,
      "grad_norm": 0.0033621457405388355,
      "learning_rate": 5.930120481927711e-06,
      "loss": 0.0304,
      "step": 58390
    },
    {
      "epoch": 7.036144578313253,
      "grad_norm": 0.002223196905106306,
      "learning_rate": 5.927710843373495e-06,
      "loss": 0.0051,
      "step": 58400
    },
    {
      "epoch": 7.037349397590361,
      "grad_norm": 3.3405652046203613,
      "learning_rate": 5.925301204819277e-06,
      "loss": 0.0254,
      "step": 58410
    },
    {
      "epoch": 7.03855421686747,
      "grad_norm": 0.1156131848692894,
      "learning_rate": 5.922891566265061e-06,
      "loss": 0.0022,
      "step": 58420
    },
    {
      "epoch": 7.039759036144578,
      "grad_norm": 0.0017414946341887116,
      "learning_rate": 5.920481927710844e-06,
      "loss": 0.0045,
      "step": 58430
    },
    {
      "epoch": 7.040963855421687,
      "grad_norm": 0.9290928840637207,
      "learning_rate": 5.9180722891566264e-06,
      "loss": 0.0236,
      "step": 58440
    },
    {
      "epoch": 7.042168674698795,
      "grad_norm": 0.011691950261592865,
      "learning_rate": 5.9156626506024105e-06,
      "loss": 0.0217,
      "step": 58450
    },
    {
      "epoch": 7.043373493975904,
      "grad_norm": 0.005121035035699606,
      "learning_rate": 5.913253012048194e-06,
      "loss": 0.0016,
      "step": 58460
    },
    {
      "epoch": 7.044578313253012,
      "grad_norm": 0.008882859721779823,
      "learning_rate": 5.910843373493976e-06,
      "loss": 0.0508,
      "step": 58470
    },
    {
      "epoch": 7.04578313253012,
      "grad_norm": 0.0023841410875320435,
      "learning_rate": 5.908433734939759e-06,
      "loss": 0.0225,
      "step": 58480
    },
    {
      "epoch": 7.046987951807229,
      "grad_norm": 0.439228355884552,
      "learning_rate": 5.906024096385543e-06,
      "loss": 0.0038,
      "step": 58490
    },
    {
      "epoch": 7.048192771084337,
      "grad_norm": 0.9194036722183228,
      "learning_rate": 5.9036144578313255e-06,
      "loss": 0.0104,
      "step": 58500
    },
    {
      "epoch": 7.049397590361446,
      "grad_norm": 0.033233318477869034,
      "learning_rate": 5.901204819277109e-06,
      "loss": 0.0102,
      "step": 58510
    },
    {
      "epoch": 7.050602409638554,
      "grad_norm": 0.05296723544597626,
      "learning_rate": 5.898795180722892e-06,
      "loss": 0.0352,
      "step": 58520
    },
    {
      "epoch": 7.051807228915663,
      "grad_norm": 0.001344860065728426,
      "learning_rate": 5.896385542168676e-06,
      "loss": 0.0145,
      "step": 58530
    },
    {
      "epoch": 7.053012048192771,
      "grad_norm": 0.009277780540287495,
      "learning_rate": 5.893975903614458e-06,
      "loss": 0.0426,
      "step": 58540
    },
    {
      "epoch": 7.054216867469879,
      "grad_norm": 0.006813982967287302,
      "learning_rate": 5.891566265060241e-06,
      "loss": 0.0055,
      "step": 58550
    },
    {
      "epoch": 7.055421686746988,
      "grad_norm": 0.07429908215999603,
      "learning_rate": 5.889156626506024e-06,
      "loss": 0.0026,
      "step": 58560
    },
    {
      "epoch": 7.056626506024096,
      "grad_norm": 1.7929736375808716,
      "learning_rate": 5.886746987951808e-06,
      "loss": 0.025,
      "step": 58570
    },
    {
      "epoch": 7.057831325301205,
      "grad_norm": 4.524369239807129,
      "learning_rate": 5.884337349397591e-06,
      "loss": 0.0273,
      "step": 58580
    },
    {
      "epoch": 7.059036144578314,
      "grad_norm": 0.11558211594820023,
      "learning_rate": 5.881927710843374e-06,
      "loss": 0.0021,
      "step": 58590
    },
    {
      "epoch": 7.0602409638554215,
      "grad_norm": 0.0016717684920877218,
      "learning_rate": 5.879518072289157e-06,
      "loss": 0.0136,
      "step": 58600
    },
    {
      "epoch": 7.06144578313253,
      "grad_norm": 0.007502558175474405,
      "learning_rate": 5.8771084337349404e-06,
      "loss": 0.0042,
      "step": 58610
    },
    {
      "epoch": 7.062650602409638,
      "grad_norm": 0.012417550198733807,
      "learning_rate": 5.874698795180724e-06,
      "loss": 0.014,
      "step": 58620
    },
    {
      "epoch": 7.063855421686747,
      "grad_norm": 0.025057941675186157,
      "learning_rate": 5.872289156626506e-06,
      "loss": 0.013,
      "step": 58630
    },
    {
      "epoch": 7.065060240963855,
      "grad_norm": 0.06875000894069672,
      "learning_rate": 5.86987951807229e-06,
      "loss": 0.0117,
      "step": 58640
    },
    {
      "epoch": 7.066265060240964,
      "grad_norm": 0.14190970361232758,
      "learning_rate": 5.867469879518073e-06,
      "loss": 0.0157,
      "step": 58650
    },
    {
      "epoch": 7.067469879518073,
      "grad_norm": 0.02906036749482155,
      "learning_rate": 5.8650602409638555e-06,
      "loss": 0.0066,
      "step": 58660
    },
    {
      "epoch": 7.0686746987951805,
      "grad_norm": 0.001820461475290358,
      "learning_rate": 5.862650602409639e-06,
      "loss": 0.0319,
      "step": 58670
    },
    {
      "epoch": 7.069879518072289,
      "grad_norm": 0.00249177822843194,
      "learning_rate": 5.860240963855423e-06,
      "loss": 0.023,
      "step": 58680
    },
    {
      "epoch": 7.071084337349397,
      "grad_norm": 6.345030784606934,
      "learning_rate": 5.857831325301205e-06,
      "loss": 0.0416,
      "step": 58690
    },
    {
      "epoch": 7.072289156626506,
      "grad_norm": 0.0035799075849354267,
      "learning_rate": 5.855421686746988e-06,
      "loss": 0.0143,
      "step": 58700
    },
    {
      "epoch": 7.073493975903615,
      "grad_norm": 1.545982837677002,
      "learning_rate": 5.853012048192771e-06,
      "loss": 0.0126,
      "step": 58710
    },
    {
      "epoch": 7.074698795180723,
      "grad_norm": 0.2541436553001404,
      "learning_rate": 5.850602409638555e-06,
      "loss": 0.0279,
      "step": 58720
    },
    {
      "epoch": 7.075903614457832,
      "grad_norm": 8.957880020141602,
      "learning_rate": 5.848192771084338e-06,
      "loss": 0.018,
      "step": 58730
    },
    {
      "epoch": 7.0771084337349395,
      "grad_norm": 0.17456914484500885,
      "learning_rate": 5.845783132530121e-06,
      "loss": 0.0169,
      "step": 58740
    },
    {
      "epoch": 7.078313253012048,
      "grad_norm": 0.49441856145858765,
      "learning_rate": 5.843373493975905e-06,
      "loss": 0.0063,
      "step": 58750
    },
    {
      "epoch": 7.079518072289156,
      "grad_norm": 1.734173059463501,
      "learning_rate": 5.840963855421687e-06,
      "loss": 0.0142,
      "step": 58760
    },
    {
      "epoch": 7.080722891566265,
      "grad_norm": 0.06713040918111801,
      "learning_rate": 5.83855421686747e-06,
      "loss": 0.0139,
      "step": 58770
    },
    {
      "epoch": 7.081927710843374,
      "grad_norm": 0.03705370053648949,
      "learning_rate": 5.836144578313253e-06,
      "loss": 0.0127,
      "step": 58780
    },
    {
      "epoch": 7.083132530120482,
      "grad_norm": 0.020265700295567513,
      "learning_rate": 5.833734939759037e-06,
      "loss": 0.0265,
      "step": 58790
    },
    {
      "epoch": 7.0843373493975905,
      "grad_norm": 0.46349820494651794,
      "learning_rate": 5.83132530120482e-06,
      "loss": 0.009,
      "step": 58800
    },
    {
      "epoch": 7.085542168674698,
      "grad_norm": 0.0025356991682201624,
      "learning_rate": 5.828915662650603e-06,
      "loss": 0.0014,
      "step": 58810
    },
    {
      "epoch": 7.086746987951807,
      "grad_norm": 0.08628068119287491,
      "learning_rate": 5.8265060240963854e-06,
      "loss": 0.0098,
      "step": 58820
    },
    {
      "epoch": 7.087951807228916,
      "grad_norm": 0.01094918791204691,
      "learning_rate": 5.8240963855421695e-06,
      "loss": 0.0178,
      "step": 58830
    },
    {
      "epoch": 7.089156626506024,
      "grad_norm": 0.005729657597839832,
      "learning_rate": 5.821686746987953e-06,
      "loss": 0.0038,
      "step": 58840
    },
    {
      "epoch": 7.090361445783133,
      "grad_norm": 0.4491645395755768,
      "learning_rate": 5.819277108433735e-06,
      "loss": 0.0369,
      "step": 58850
    },
    {
      "epoch": 7.091566265060241,
      "grad_norm": 1.766262173652649,
      "learning_rate": 5.816867469879518e-06,
      "loss": 0.0128,
      "step": 58860
    },
    {
      "epoch": 7.0927710843373495,
      "grad_norm": 0.0008580420399084687,
      "learning_rate": 5.814457831325302e-06,
      "loss": 0.0122,
      "step": 58870
    },
    {
      "epoch": 7.093975903614457,
      "grad_norm": 0.0009692090679891407,
      "learning_rate": 5.8120481927710845e-06,
      "loss": 0.0126,
      "step": 58880
    },
    {
      "epoch": 7.095180722891566,
      "grad_norm": 0.0024331538006663322,
      "learning_rate": 5.809638554216868e-06,
      "loss": 0.0088,
      "step": 58890
    },
    {
      "epoch": 7.096385542168675,
      "grad_norm": 0.0032845272216945887,
      "learning_rate": 5.807228915662652e-06,
      "loss": 0.0015,
      "step": 58900
    },
    {
      "epoch": 7.097590361445783,
      "grad_norm": 0.0030306223779916763,
      "learning_rate": 5.804819277108434e-06,
      "loss": 0.0154,
      "step": 58910
    },
    {
      "epoch": 7.098795180722892,
      "grad_norm": 0.001040823757648468,
      "learning_rate": 5.802409638554217e-06,
      "loss": 0.0243,
      "step": 58920
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.04513232409954071,
      "learning_rate": 5.8e-06,
      "loss": 0.0121,
      "step": 58930
    },
    {
      "epoch": 7.1012048192771084,
      "grad_norm": 0.321444034576416,
      "learning_rate": 5.797590361445784e-06,
      "loss": 0.0243,
      "step": 58940
    },
    {
      "epoch": 7.102409638554217,
      "grad_norm": 0.892504870891571,
      "learning_rate": 5.795180722891567e-06,
      "loss": 0.0119,
      "step": 58950
    },
    {
      "epoch": 7.103614457831325,
      "grad_norm": 0.001727016642689705,
      "learning_rate": 5.79277108433735e-06,
      "loss": 0.0042,
      "step": 58960
    },
    {
      "epoch": 7.104819277108434,
      "grad_norm": 0.1676860749721527,
      "learning_rate": 5.790361445783132e-06,
      "loss": 0.0017,
      "step": 58970
    },
    {
      "epoch": 7.106024096385542,
      "grad_norm": 0.00113739597145468,
      "learning_rate": 5.787951807228916e-06,
      "loss": 0.0036,
      "step": 58980
    },
    {
      "epoch": 7.107228915662651,
      "grad_norm": 1.070222020149231,
      "learning_rate": 5.7855421686746994e-06,
      "loss": 0.0364,
      "step": 58990
    },
    {
      "epoch": 7.108433734939759,
      "grad_norm": 0.0013525958638638258,
      "learning_rate": 5.783132530120482e-06,
      "loss": 0.01,
      "step": 59000
    },
    {
      "epoch": 7.109638554216867,
      "grad_norm": 0.001426846138201654,
      "learning_rate": 5.780722891566265e-06,
      "loss": 0.0162,
      "step": 59010
    },
    {
      "epoch": 7.110843373493976,
      "grad_norm": 0.001396248466335237,
      "learning_rate": 5.778313253012049e-06,
      "loss": 0.0227,
      "step": 59020
    },
    {
      "epoch": 7.112048192771084,
      "grad_norm": 0.001305922633036971,
      "learning_rate": 5.775903614457832e-06,
      "loss": 0.0073,
      "step": 59030
    },
    {
      "epoch": 7.113253012048193,
      "grad_norm": 0.007926376536488533,
      "learning_rate": 5.7734939759036145e-06,
      "loss": 0.0304,
      "step": 59040
    },
    {
      "epoch": 7.114457831325301,
      "grad_norm": 3.136484384536743,
      "learning_rate": 5.7710843373493985e-06,
      "loss": 0.0197,
      "step": 59050
    },
    {
      "epoch": 7.11566265060241,
      "grad_norm": 0.0007217814563773572,
      "learning_rate": 5.768674698795182e-06,
      "loss": 0.0177,
      "step": 59060
    },
    {
      "epoch": 7.1168674698795185,
      "grad_norm": 0.06895965337753296,
      "learning_rate": 5.766265060240964e-06,
      "loss": 0.005,
      "step": 59070
    },
    {
      "epoch": 7.118072289156626,
      "grad_norm": 0.0055960193276405334,
      "learning_rate": 5.763855421686747e-06,
      "loss": 0.0157,
      "step": 59080
    },
    {
      "epoch": 7.119277108433735,
      "grad_norm": 0.013999913819134235,
      "learning_rate": 5.761445783132531e-06,
      "loss": 0.0069,
      "step": 59090
    },
    {
      "epoch": 7.120481927710843,
      "grad_norm": 1.119930624961853,
      "learning_rate": 5.7590361445783135e-06,
      "loss": 0.0066,
      "step": 59100
    },
    {
      "epoch": 7.121686746987952,
      "grad_norm": 0.0051559023559093475,
      "learning_rate": 5.756626506024097e-06,
      "loss": 0.022,
      "step": 59110
    },
    {
      "epoch": 7.12289156626506,
      "grad_norm": 0.0022915261797606945,
      "learning_rate": 5.75421686746988e-06,
      "loss": 0.0201,
      "step": 59120
    },
    {
      "epoch": 7.124096385542169,
      "grad_norm": 1.5845153331756592,
      "learning_rate": 5.751807228915663e-06,
      "loss": 0.0141,
      "step": 59130
    },
    {
      "epoch": 7.125301204819277,
      "grad_norm": 0.004774990491569042,
      "learning_rate": 5.749397590361446e-06,
      "loss": 0.0202,
      "step": 59140
    },
    {
      "epoch": 7.126506024096385,
      "grad_norm": 1.2564860582351685,
      "learning_rate": 5.746987951807229e-06,
      "loss": 0.0148,
      "step": 59150
    },
    {
      "epoch": 7.127710843373494,
      "grad_norm": 0.30795997381210327,
      "learning_rate": 5.744578313253013e-06,
      "loss": 0.0101,
      "step": 59160
    },
    {
      "epoch": 7.128915662650602,
      "grad_norm": 0.0012992523843422532,
      "learning_rate": 5.742168674698796e-06,
      "loss": 0.0551,
      "step": 59170
    },
    {
      "epoch": 7.130120481927711,
      "grad_norm": 0.8941099643707275,
      "learning_rate": 5.739759036144579e-06,
      "loss": 0.0315,
      "step": 59180
    },
    {
      "epoch": 7.13132530120482,
      "grad_norm": 0.0016025967197492719,
      "learning_rate": 5.737349397590361e-06,
      "loss": 0.0069,
      "step": 59190
    },
    {
      "epoch": 7.132530120481928,
      "grad_norm": 0.0021875060629099607,
      "learning_rate": 5.734939759036145e-06,
      "loss": 0.0171,
      "step": 59200
    },
    {
      "epoch": 7.133734939759036,
      "grad_norm": 0.6656183004379272,
      "learning_rate": 5.7325301204819285e-06,
      "loss": 0.0069,
      "step": 59210
    },
    {
      "epoch": 7.134939759036144,
      "grad_norm": 0.0014319767942652106,
      "learning_rate": 5.730120481927711e-06,
      "loss": 0.0509,
      "step": 59220
    },
    {
      "epoch": 7.136144578313253,
      "grad_norm": 0.025119781494140625,
      "learning_rate": 5.727710843373494e-06,
      "loss": 0.0264,
      "step": 59230
    },
    {
      "epoch": 7.137349397590361,
      "grad_norm": 0.002818742534145713,
      "learning_rate": 5.725301204819278e-06,
      "loss": 0.0064,
      "step": 59240
    },
    {
      "epoch": 7.13855421686747,
      "grad_norm": 0.03910800814628601,
      "learning_rate": 5.722891566265061e-06,
      "loss": 0.0001,
      "step": 59250
    },
    {
      "epoch": 7.139759036144579,
      "grad_norm": 0.004889480769634247,
      "learning_rate": 5.7204819277108435e-06,
      "loss": 0.0324,
      "step": 59260
    },
    {
      "epoch": 7.1409638554216865,
      "grad_norm": 0.002123648999258876,
      "learning_rate": 5.718072289156627e-06,
      "loss": 0.0045,
      "step": 59270
    },
    {
      "epoch": 7.142168674698795,
      "grad_norm": 0.28952789306640625,
      "learning_rate": 5.715662650602411e-06,
      "loss": 0.006,
      "step": 59280
    },
    {
      "epoch": 7.143373493975903,
      "grad_norm": 0.027925916016101837,
      "learning_rate": 5.713253012048193e-06,
      "loss": 0.0084,
      "step": 59290
    },
    {
      "epoch": 7.144578313253012,
      "grad_norm": 0.010917273350059986,
      "learning_rate": 5.710843373493976e-06,
      "loss": 0.0238,
      "step": 59300
    },
    {
      "epoch": 7.145783132530121,
      "grad_norm": 0.001435431302525103,
      "learning_rate": 5.70843373493976e-06,
      "loss": 0.0326,
      "step": 59310
    },
    {
      "epoch": 7.146987951807229,
      "grad_norm": 1.1223303079605103,
      "learning_rate": 5.7060240963855425e-06,
      "loss": 0.0466,
      "step": 59320
    },
    {
      "epoch": 7.148192771084338,
      "grad_norm": 0.001741942367516458,
      "learning_rate": 5.703614457831326e-06,
      "loss": 0.0182,
      "step": 59330
    },
    {
      "epoch": 7.1493975903614455,
      "grad_norm": 0.010872544720768929,
      "learning_rate": 5.701204819277109e-06,
      "loss": 0.0147,
      "step": 59340
    },
    {
      "epoch": 7.150602409638554,
      "grad_norm": 1.3885493278503418,
      "learning_rate": 5.698795180722893e-06,
      "loss": 0.004,
      "step": 59350
    },
    {
      "epoch": 7.151807228915662,
      "grad_norm": 0.0074218874797225,
      "learning_rate": 5.696385542168675e-06,
      "loss": 0.0172,
      "step": 59360
    },
    {
      "epoch": 7.153012048192771,
      "grad_norm": 0.1056409403681755,
      "learning_rate": 5.693975903614458e-06,
      "loss": 0.0312,
      "step": 59370
    },
    {
      "epoch": 7.15421686746988,
      "grad_norm": 0.34227946400642395,
      "learning_rate": 5.691566265060241e-06,
      "loss": 0.0018,
      "step": 59380
    },
    {
      "epoch": 7.155421686746988,
      "grad_norm": 0.006565497722476721,
      "learning_rate": 5.689156626506025e-06,
      "loss": 0.0302,
      "step": 59390
    },
    {
      "epoch": 7.156626506024097,
      "grad_norm": 5.343076229095459,
      "learning_rate": 5.686746987951808e-06,
      "loss": 0.0614,
      "step": 59400
    },
    {
      "epoch": 7.1578313253012045,
      "grad_norm": 0.04511452838778496,
      "learning_rate": 5.68433734939759e-06,
      "loss": 0.0113,
      "step": 59410
    },
    {
      "epoch": 7.159036144578313,
      "grad_norm": 0.0022570921573787928,
      "learning_rate": 5.6819277108433735e-06,
      "loss": 0.0312,
      "step": 59420
    },
    {
      "epoch": 7.160240963855422,
      "grad_norm": 0.001198339625261724,
      "learning_rate": 5.6795180722891575e-06,
      "loss": 0.0099,
      "step": 59430
    },
    {
      "epoch": 7.16144578313253,
      "grad_norm": 0.0014887896832078695,
      "learning_rate": 5.677108433734941e-06,
      "loss": 0.0055,
      "step": 59440
    },
    {
      "epoch": 7.162650602409639,
      "grad_norm": 1.1854547262191772,
      "learning_rate": 5.674698795180723e-06,
      "loss": 0.0176,
      "step": 59450
    },
    {
      "epoch": 7.163855421686747,
      "grad_norm": 0.9207248687744141,
      "learning_rate": 5.672289156626507e-06,
      "loss": 0.0173,
      "step": 59460
    },
    {
      "epoch": 7.1650602409638555,
      "grad_norm": 0.8625037670135498,
      "learning_rate": 5.66987951807229e-06,
      "loss": 0.0402,
      "step": 59470
    },
    {
      "epoch": 7.166265060240963,
      "grad_norm": 0.12163422256708145,
      "learning_rate": 5.6674698795180725e-06,
      "loss": 0.0038,
      "step": 59480
    },
    {
      "epoch": 7.167469879518072,
      "grad_norm": 0.002888584276661277,
      "learning_rate": 5.665060240963856e-06,
      "loss": 0.0002,
      "step": 59490
    },
    {
      "epoch": 7.168674698795181,
      "grad_norm": 0.007768899668008089,
      "learning_rate": 5.66265060240964e-06,
      "loss": 0.0119,
      "step": 59500
    },
    {
      "epoch": 7.169879518072289,
      "grad_norm": 0.0016141205560415983,
      "learning_rate": 5.660240963855422e-06,
      "loss": 0.0203,
      "step": 59510
    },
    {
      "epoch": 7.171084337349398,
      "grad_norm": 0.18842943012714386,
      "learning_rate": 5.657831325301205e-06,
      "loss": 0.0154,
      "step": 59520
    },
    {
      "epoch": 7.172289156626506,
      "grad_norm": 0.6460977792739868,
      "learning_rate": 5.655421686746988e-06,
      "loss": 0.0195,
      "step": 59530
    },
    {
      "epoch": 7.1734939759036145,
      "grad_norm": 2.230339765548706,
      "learning_rate": 5.6530120481927716e-06,
      "loss": 0.0429,
      "step": 59540
    },
    {
      "epoch": 7.174698795180723,
      "grad_norm": 0.0021885407622903585,
      "learning_rate": 5.650602409638555e-06,
      "loss": 0.0133,
      "step": 59550
    },
    {
      "epoch": 7.175903614457831,
      "grad_norm": 0.2925041615962982,
      "learning_rate": 5.648192771084338e-06,
      "loss": 0.0322,
      "step": 59560
    },
    {
      "epoch": 7.17710843373494,
      "grad_norm": 0.00965410191565752,
      "learning_rate": 5.64578313253012e-06,
      "loss": 0.0124,
      "step": 59570
    },
    {
      "epoch": 7.178313253012048,
      "grad_norm": 0.0020193897653371096,
      "learning_rate": 5.643373493975904e-06,
      "loss": 0.0201,
      "step": 59580
    },
    {
      "epoch": 7.179518072289157,
      "grad_norm": 0.0014392149168998003,
      "learning_rate": 5.6409638554216874e-06,
      "loss": 0.0359,
      "step": 59590
    },
    {
      "epoch": 7.180722891566265,
      "grad_norm": 0.019950974732637405,
      "learning_rate": 5.63855421686747e-06,
      "loss": 0.01,
      "step": 59600
    },
    {
      "epoch": 7.1819277108433734,
      "grad_norm": 0.0012058535357937217,
      "learning_rate": 5.636144578313254e-06,
      "loss": 0.0006,
      "step": 59610
    },
    {
      "epoch": 7.183132530120482,
      "grad_norm": 0.002724235877394676,
      "learning_rate": 5.633734939759037e-06,
      "loss": 0.0133,
      "step": 59620
    },
    {
      "epoch": 7.18433734939759,
      "grad_norm": 0.9211469292640686,
      "learning_rate": 5.631325301204819e-06,
      "loss": 0.0225,
      "step": 59630
    },
    {
      "epoch": 7.185542168674699,
      "grad_norm": 0.45176050066947937,
      "learning_rate": 5.6289156626506025e-06,
      "loss": 0.0009,
      "step": 59640
    },
    {
      "epoch": 7.186746987951807,
      "grad_norm": 0.0072389324195683,
      "learning_rate": 5.6265060240963865e-06,
      "loss": 0.0317,
      "step": 59650
    },
    {
      "epoch": 7.187951807228916,
      "grad_norm": 0.0009004123276099563,
      "learning_rate": 5.62409638554217e-06,
      "loss": 0.0289,
      "step": 59660
    },
    {
      "epoch": 7.1891566265060245,
      "grad_norm": 0.07748564332723618,
      "learning_rate": 5.621686746987952e-06,
      "loss": 0.0089,
      "step": 59670
    },
    {
      "epoch": 7.190361445783132,
      "grad_norm": 11.416478157043457,
      "learning_rate": 5.619277108433735e-06,
      "loss": 0.0575,
      "step": 59680
    },
    {
      "epoch": 7.191566265060241,
      "grad_norm": 0.01978328265249729,
      "learning_rate": 5.616867469879519e-06,
      "loss": 0.011,
      "step": 59690
    },
    {
      "epoch": 7.192771084337349,
      "grad_norm": 1.0772596597671509,
      "learning_rate": 5.6144578313253015e-06,
      "loss": 0.017,
      "step": 59700
    },
    {
      "epoch": 7.193975903614458,
      "grad_norm": 0.004772892687469721,
      "learning_rate": 5.612048192771085e-06,
      "loss": 0.0102,
      "step": 59710
    },
    {
      "epoch": 7.195180722891566,
      "grad_norm": 0.0008963961154222488,
      "learning_rate": 5.609638554216867e-06,
      "loss": 0.0047,
      "step": 59720
    },
    {
      "epoch": 7.196385542168675,
      "grad_norm": 1.5902358293533325,
      "learning_rate": 5.607228915662651e-06,
      "loss": 0.0013,
      "step": 59730
    },
    {
      "epoch": 7.1975903614457835,
      "grad_norm": 0.023518456146121025,
      "learning_rate": 5.604819277108434e-06,
      "loss": 0.0366,
      "step": 59740
    },
    {
      "epoch": 7.198795180722891,
      "grad_norm": 0.001059091417118907,
      "learning_rate": 5.602409638554217e-06,
      "loss": 0.0008,
      "step": 59750
    },
    {
      "epoch": 7.2,
      "grad_norm": 2.128136157989502,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0267,
      "step": 59760
    },
    {
      "epoch": 7.201204819277108,
      "grad_norm": 0.0010230576153844595,
      "learning_rate": 5.597590361445784e-06,
      "loss": 0.0228,
      "step": 59770
    },
    {
      "epoch": 7.202409638554217,
      "grad_norm": 2.2962019443511963,
      "learning_rate": 5.595180722891567e-06,
      "loss": 0.0294,
      "step": 59780
    },
    {
      "epoch": 7.203614457831326,
      "grad_norm": 1.4609107971191406,
      "learning_rate": 5.592771084337349e-06,
      "loss": 0.0099,
      "step": 59790
    },
    {
      "epoch": 7.204819277108434,
      "grad_norm": 0.06086697429418564,
      "learning_rate": 5.590361445783133e-06,
      "loss": 0.02,
      "step": 59800
    },
    {
      "epoch": 7.206024096385542,
      "grad_norm": 4.8538079261779785,
      "learning_rate": 5.5879518072289165e-06,
      "loss": 0.0218,
      "step": 59810
    },
    {
      "epoch": 7.20722891566265,
      "grad_norm": 0.0038637917023152113,
      "learning_rate": 5.585542168674699e-06,
      "loss": 0.0154,
      "step": 59820
    },
    {
      "epoch": 7.208433734939759,
      "grad_norm": 0.012942262925207615,
      "learning_rate": 5.583132530120482e-06,
      "loss": 0.0191,
      "step": 59830
    },
    {
      "epoch": 7.209638554216867,
      "grad_norm": 0.003921637777239084,
      "learning_rate": 5.580722891566266e-06,
      "loss": 0.0133,
      "step": 59840
    },
    {
      "epoch": 7.210843373493976,
      "grad_norm": 0.00882525835186243,
      "learning_rate": 5.578313253012048e-06,
      "loss": 0.0106,
      "step": 59850
    },
    {
      "epoch": 7.212048192771085,
      "grad_norm": 3.7128732204437256,
      "learning_rate": 5.5759036144578315e-06,
      "loss": 0.0201,
      "step": 59860
    },
    {
      "epoch": 7.213253012048193,
      "grad_norm": 1.250732421875,
      "learning_rate": 5.573493975903615e-06,
      "loss": 0.0075,
      "step": 59870
    },
    {
      "epoch": 7.214457831325301,
      "grad_norm": 0.044604286551475525,
      "learning_rate": 5.571084337349399e-06,
      "loss": 0.0134,
      "step": 59880
    },
    {
      "epoch": 7.215662650602409,
      "grad_norm": 0.004419431556016207,
      "learning_rate": 5.568674698795181e-06,
      "loss": 0.003,
      "step": 59890
    },
    {
      "epoch": 7.216867469879518,
      "grad_norm": 0.0036280348431319,
      "learning_rate": 5.566265060240964e-06,
      "loss": 0.0039,
      "step": 59900
    },
    {
      "epoch": 7.218072289156627,
      "grad_norm": 0.14668166637420654,
      "learning_rate": 5.563855421686748e-06,
      "loss": 0.014,
      "step": 59910
    },
    {
      "epoch": 7.219277108433735,
      "grad_norm": 1.701965093612671,
      "learning_rate": 5.5614457831325306e-06,
      "loss": 0.026,
      "step": 59920
    },
    {
      "epoch": 7.220481927710844,
      "grad_norm": 0.052747759968042374,
      "learning_rate": 5.559036144578314e-06,
      "loss": 0.0075,
      "step": 59930
    },
    {
      "epoch": 7.2216867469879515,
      "grad_norm": 0.0020320366602391005,
      "learning_rate": 5.556626506024096e-06,
      "loss": 0.0423,
      "step": 59940
    },
    {
      "epoch": 7.22289156626506,
      "grad_norm": 0.02439947985112667,
      "learning_rate": 5.55421686746988e-06,
      "loss": 0.0004,
      "step": 59950
    },
    {
      "epoch": 7.224096385542168,
      "grad_norm": 0.0010909028351306915,
      "learning_rate": 5.551807228915663e-06,
      "loss": 0.0388,
      "step": 59960
    },
    {
      "epoch": 7.225301204819277,
      "grad_norm": 0.008688343688845634,
      "learning_rate": 5.5493975903614464e-06,
      "loss": 0.0046,
      "step": 59970
    },
    {
      "epoch": 7.226506024096386,
      "grad_norm": 0.06741072237491608,
      "learning_rate": 5.546987951807229e-06,
      "loss": 0.0125,
      "step": 59980
    },
    {
      "epoch": 7.227710843373494,
      "grad_norm": 0.5592790246009827,
      "learning_rate": 5.544578313253013e-06,
      "loss": 0.0125,
      "step": 59990
    },
    {
      "epoch": 7.228915662650603,
      "grad_norm": 0.0007268732297234237,
      "learning_rate": 5.542168674698796e-06,
      "loss": 0.016,
      "step": 60000
    },
    {
      "epoch": 7.2301204819277105,
      "grad_norm": 0.0006173806614242494,
      "learning_rate": 5.539759036144578e-06,
      "loss": 0.0161,
      "step": 60010
    },
    {
      "epoch": 7.231325301204819,
      "grad_norm": 0.011688541620969772,
      "learning_rate": 5.5373493975903615e-06,
      "loss": 0.0231,
      "step": 60020
    },
    {
      "epoch": 7.232530120481928,
      "grad_norm": 0.008021365851163864,
      "learning_rate": 5.5349397590361455e-06,
      "loss": 0.005,
      "step": 60030
    },
    {
      "epoch": 7.233734939759036,
      "grad_norm": 0.0009916193084791303,
      "learning_rate": 5.532530120481928e-06,
      "loss": 0.02,
      "step": 60040
    },
    {
      "epoch": 7.234939759036145,
      "grad_norm": 0.0006271876045502722,
      "learning_rate": 5.530120481927711e-06,
      "loss": 0.0186,
      "step": 60050
    },
    {
      "epoch": 7.236144578313253,
      "grad_norm": 4.9634857177734375,
      "learning_rate": 5.527710843373495e-06,
      "loss": 0.0254,
      "step": 60060
    },
    {
      "epoch": 7.2373493975903616,
      "grad_norm": 1.6575267314910889,
      "learning_rate": 5.525301204819278e-06,
      "loss": 0.0123,
      "step": 60070
    },
    {
      "epoch": 7.2385542168674695,
      "grad_norm": 0.008702498860657215,
      "learning_rate": 5.5228915662650605e-06,
      "loss": 0.0082,
      "step": 60080
    },
    {
      "epoch": 7.239759036144578,
      "grad_norm": 0.2232302725315094,
      "learning_rate": 5.520481927710844e-06,
      "loss": 0.0096,
      "step": 60090
    },
    {
      "epoch": 7.240963855421687,
      "grad_norm": 0.0009104760247282684,
      "learning_rate": 5.518072289156628e-06,
      "loss": 0.04,
      "step": 60100
    },
    {
      "epoch": 7.242168674698795,
      "grad_norm": 0.16996872425079346,
      "learning_rate": 5.51566265060241e-06,
      "loss": 0.001,
      "step": 60110
    },
    {
      "epoch": 7.243373493975904,
      "grad_norm": 0.001974728424102068,
      "learning_rate": 5.513253012048193e-06,
      "loss": 0.0215,
      "step": 60120
    },
    {
      "epoch": 7.244578313253012,
      "grad_norm": 0.4078260660171509,
      "learning_rate": 5.5108433734939756e-06,
      "loss": 0.0069,
      "step": 60130
    },
    {
      "epoch": 7.2457831325301205,
      "grad_norm": 0.0008155429386533797,
      "learning_rate": 5.50843373493976e-06,
      "loss": 0.0038,
      "step": 60140
    },
    {
      "epoch": 7.246987951807229,
      "grad_norm": 0.0011126030003651977,
      "learning_rate": 5.506024096385543e-06,
      "loss": 0.0186,
      "step": 60150
    },
    {
      "epoch": 7.248192771084337,
      "grad_norm": 5.917701721191406,
      "learning_rate": 5.503614457831326e-06,
      "loss": 0.0131,
      "step": 60160
    },
    {
      "epoch": 7.249397590361446,
      "grad_norm": 0.001050599617883563,
      "learning_rate": 5.501204819277108e-06,
      "loss": 0.0042,
      "step": 60170
    },
    {
      "epoch": 7.250602409638554,
      "grad_norm": 0.001046637655235827,
      "learning_rate": 5.498795180722892e-06,
      "loss": 0.0085,
      "step": 60180
    },
    {
      "epoch": 7.251807228915663,
      "grad_norm": 7.323962688446045,
      "learning_rate": 5.4963855421686755e-06,
      "loss": 0.0259,
      "step": 60190
    },
    {
      "epoch": 7.253012048192771,
      "grad_norm": 2.5011672973632812,
      "learning_rate": 5.493975903614458e-06,
      "loss": 0.0367,
      "step": 60200
    },
    {
      "epoch": 7.2542168674698795,
      "grad_norm": 0.32840442657470703,
      "learning_rate": 5.491566265060242e-06,
      "loss": 0.0263,
      "step": 60210
    },
    {
      "epoch": 7.255421686746988,
      "grad_norm": 0.0009248607093468308,
      "learning_rate": 5.489156626506025e-06,
      "loss": 0.0142,
      "step": 60220
    },
    {
      "epoch": 7.256626506024096,
      "grad_norm": 0.18593309819698334,
      "learning_rate": 5.486746987951807e-06,
      "loss": 0.0469,
      "step": 60230
    },
    {
      "epoch": 7.257831325301205,
      "grad_norm": 0.011352114379405975,
      "learning_rate": 5.4843373493975905e-06,
      "loss": 0.006,
      "step": 60240
    },
    {
      "epoch": 7.259036144578313,
      "grad_norm": 0.7663745880126953,
      "learning_rate": 5.4819277108433745e-06,
      "loss": 0.0932,
      "step": 60250
    },
    {
      "epoch": 7.260240963855422,
      "grad_norm": 0.0010932264849543571,
      "learning_rate": 5.479518072289157e-06,
      "loss": 0.0174,
      "step": 60260
    },
    {
      "epoch": 7.2614457831325305,
      "grad_norm": 1.530888319015503,
      "learning_rate": 5.47710843373494e-06,
      "loss": 0.0258,
      "step": 60270
    },
    {
      "epoch": 7.2626506024096384,
      "grad_norm": 0.0010129729053005576,
      "learning_rate": 5.474698795180723e-06,
      "loss": 0.0007,
      "step": 60280
    },
    {
      "epoch": 7.263855421686747,
      "grad_norm": 0.10307268053293228,
      "learning_rate": 5.472289156626507e-06,
      "loss": 0.0027,
      "step": 60290
    },
    {
      "epoch": 7.265060240963855,
      "grad_norm": 0.0007921242504380643,
      "learning_rate": 5.4698795180722896e-06,
      "loss": 0.0006,
      "step": 60300
    },
    {
      "epoch": 7.266265060240964,
      "grad_norm": 0.0018336049979552627,
      "learning_rate": 5.467469879518073e-06,
      "loss": 0.0185,
      "step": 60310
    },
    {
      "epoch": 7.267469879518072,
      "grad_norm": 0.018874872475862503,
      "learning_rate": 5.465060240963855e-06,
      "loss": 0.0207,
      "step": 60320
    },
    {
      "epoch": 7.268674698795181,
      "grad_norm": 0.002022166969254613,
      "learning_rate": 5.462650602409639e-06,
      "loss": 0.0425,
      "step": 60330
    },
    {
      "epoch": 7.2698795180722895,
      "grad_norm": 0.0034246575087308884,
      "learning_rate": 5.460240963855422e-06,
      "loss": 0.0318,
      "step": 60340
    },
    {
      "epoch": 7.271084337349397,
      "grad_norm": 0.001173763652332127,
      "learning_rate": 5.457831325301205e-06,
      "loss": 0.0005,
      "step": 60350
    },
    {
      "epoch": 7.272289156626506,
      "grad_norm": 0.25419214367866516,
      "learning_rate": 5.455421686746989e-06,
      "loss": 0.0024,
      "step": 60360
    },
    {
      "epoch": 7.273493975903614,
      "grad_norm": 0.003679255722090602,
      "learning_rate": 5.453012048192772e-06,
      "loss": 0.0067,
      "step": 60370
    },
    {
      "epoch": 7.274698795180723,
      "grad_norm": 0.0018344713607802987,
      "learning_rate": 5.450602409638555e-06,
      "loss": 0.0452,
      "step": 60380
    },
    {
      "epoch": 7.275903614457832,
      "grad_norm": 2.412767171859741,
      "learning_rate": 5.448192771084337e-06,
      "loss": 0.0159,
      "step": 60390
    },
    {
      "epoch": 7.27710843373494,
      "grad_norm": 0.0012460632715374231,
      "learning_rate": 5.445783132530121e-06,
      "loss": 0.0265,
      "step": 60400
    },
    {
      "epoch": 7.2783132530120485,
      "grad_norm": 0.0013173931511119008,
      "learning_rate": 5.4433734939759045e-06,
      "loss": 0.0457,
      "step": 60410
    },
    {
      "epoch": 7.279518072289156,
      "grad_norm": 2.5279905796051025,
      "learning_rate": 5.440963855421687e-06,
      "loss": 0.024,
      "step": 60420
    },
    {
      "epoch": 7.280722891566265,
      "grad_norm": 0.5099172592163086,
      "learning_rate": 5.43855421686747e-06,
      "loss": 0.02,
      "step": 60430
    },
    {
      "epoch": 7.281927710843373,
      "grad_norm": 1.0593229532241821,
      "learning_rate": 5.436144578313254e-06,
      "loss": 0.0064,
      "step": 60440
    },
    {
      "epoch": 7.283132530120482,
      "grad_norm": 0.05591926351189613,
      "learning_rate": 5.433734939759036e-06,
      "loss": 0.0122,
      "step": 60450
    },
    {
      "epoch": 7.284337349397591,
      "grad_norm": 0.0013602233957499266,
      "learning_rate": 5.4313253012048195e-06,
      "loss": 0.0107,
      "step": 60460
    },
    {
      "epoch": 7.285542168674699,
      "grad_norm": 2.798894166946411,
      "learning_rate": 5.428915662650603e-06,
      "loss": 0.0414,
      "step": 60470
    },
    {
      "epoch": 7.286746987951807,
      "grad_norm": 1.962003231048584,
      "learning_rate": 5.426506024096386e-06,
      "loss": 0.064,
      "step": 60480
    },
    {
      "epoch": 7.287951807228915,
      "grad_norm": 1.8564285039901733,
      "learning_rate": 5.424096385542169e-06,
      "loss": 0.0088,
      "step": 60490
    },
    {
      "epoch": 7.289156626506024,
      "grad_norm": 0.6992312073707581,
      "learning_rate": 5.421686746987952e-06,
      "loss": 0.0063,
      "step": 60500
    },
    {
      "epoch": 7.290361445783133,
      "grad_norm": 0.005808736197650433,
      "learning_rate": 5.419277108433736e-06,
      "loss": 0.0118,
      "step": 60510
    },
    {
      "epoch": 7.291566265060241,
      "grad_norm": 0.38631242513656616,
      "learning_rate": 5.416867469879519e-06,
      "loss": 0.0165,
      "step": 60520
    },
    {
      "epoch": 7.29277108433735,
      "grad_norm": 0.004224494565278292,
      "learning_rate": 5.414457831325302e-06,
      "loss": 0.0266,
      "step": 60530
    },
    {
      "epoch": 7.293975903614458,
      "grad_norm": 0.06982316076755524,
      "learning_rate": 5.412048192771084e-06,
      "loss": 0.0179,
      "step": 60540
    },
    {
      "epoch": 7.295180722891566,
      "grad_norm": 0.005119790323078632,
      "learning_rate": 5.409638554216868e-06,
      "loss": 0.0242,
      "step": 60550
    },
    {
      "epoch": 7.296385542168674,
      "grad_norm": 2.64261794090271,
      "learning_rate": 5.407228915662651e-06,
      "loss": 0.0118,
      "step": 60560
    },
    {
      "epoch": 7.297590361445783,
      "grad_norm": 0.058571502566337585,
      "learning_rate": 5.404819277108434e-06,
      "loss": 0.0065,
      "step": 60570
    },
    {
      "epoch": 7.298795180722892,
      "grad_norm": 0.924716591835022,
      "learning_rate": 5.402409638554217e-06,
      "loss": 0.0088,
      "step": 60580
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.03170954808592796,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.0144,
      "step": 60590
    },
    {
      "epoch": 7.301204819277109,
      "grad_norm": 1.069691777229309,
      "learning_rate": 5.397590361445784e-06,
      "loss": 0.0058,
      "step": 60600
    },
    {
      "epoch": 7.3024096385542165,
      "grad_norm": 0.005635635927319527,
      "learning_rate": 5.395180722891566e-06,
      "loss": 0.0302,
      "step": 60610
    },
    {
      "epoch": 7.303614457831325,
      "grad_norm": 0.0037814306560903788,
      "learning_rate": 5.3927710843373495e-06,
      "loss": 0.0489,
      "step": 60620
    },
    {
      "epoch": 7.304819277108434,
      "grad_norm": 0.09800804406404495,
      "learning_rate": 5.3903614457831335e-06,
      "loss": 0.0298,
      "step": 60630
    },
    {
      "epoch": 7.306024096385542,
      "grad_norm": 3.6753365993499756,
      "learning_rate": 5.387951807228916e-06,
      "loss": 0.0284,
      "step": 60640
    },
    {
      "epoch": 7.307228915662651,
      "grad_norm": 0.006106833927333355,
      "learning_rate": 5.385542168674699e-06,
      "loss": 0.0279,
      "step": 60650
    },
    {
      "epoch": 7.308433734939759,
      "grad_norm": 1.0493413209915161,
      "learning_rate": 5.383132530120483e-06,
      "loss": 0.0189,
      "step": 60660
    },
    {
      "epoch": 7.309638554216868,
      "grad_norm": 0.7233703136444092,
      "learning_rate": 5.380722891566265e-06,
      "loss": 0.0026,
      "step": 60670
    },
    {
      "epoch": 7.3108433734939755,
      "grad_norm": 0.823702871799469,
      "learning_rate": 5.3783132530120486e-06,
      "loss": 0.017,
      "step": 60680
    },
    {
      "epoch": 7.312048192771084,
      "grad_norm": 1.0393718481063843,
      "learning_rate": 5.375903614457832e-06,
      "loss": 0.0225,
      "step": 60690
    },
    {
      "epoch": 7.313253012048193,
      "grad_norm": 0.009234949015080929,
      "learning_rate": 5.373493975903615e-06,
      "loss": 0.0155,
      "step": 60700
    },
    {
      "epoch": 7.314457831325301,
      "grad_norm": 0.8555080890655518,
      "learning_rate": 5.371084337349398e-06,
      "loss": 0.0173,
      "step": 60710
    },
    {
      "epoch": 7.31566265060241,
      "grad_norm": 0.005535142030566931,
      "learning_rate": 5.368674698795181e-06,
      "loss": 0.0347,
      "step": 60720
    },
    {
      "epoch": 7.316867469879518,
      "grad_norm": 0.00238408031873405,
      "learning_rate": 5.366265060240964e-06,
      "loss": 0.0004,
      "step": 60730
    },
    {
      "epoch": 7.3180722891566266,
      "grad_norm": 0.0031547416001558304,
      "learning_rate": 5.363855421686748e-06,
      "loss": 0.0023,
      "step": 60740
    },
    {
      "epoch": 7.3192771084337345,
      "grad_norm": 0.9721052646636963,
      "learning_rate": 5.361445783132531e-06,
      "loss": 0.0055,
      "step": 60750
    },
    {
      "epoch": 7.320481927710843,
      "grad_norm": 0.0008915425860323012,
      "learning_rate": 5.359036144578313e-06,
      "loss": 0.0062,
      "step": 60760
    },
    {
      "epoch": 7.321686746987952,
      "grad_norm": 0.002327377675101161,
      "learning_rate": 5.356626506024096e-06,
      "loss": 0.0074,
      "step": 60770
    },
    {
      "epoch": 7.32289156626506,
      "grad_norm": 3.000478982925415,
      "learning_rate": 5.35421686746988e-06,
      "loss": 0.0416,
      "step": 60780
    },
    {
      "epoch": 7.324096385542169,
      "grad_norm": 0.01607179082930088,
      "learning_rate": 5.3518072289156635e-06,
      "loss": 0.009,
      "step": 60790
    },
    {
      "epoch": 7.325301204819277,
      "grad_norm": 46.67829132080078,
      "learning_rate": 5.349397590361446e-06,
      "loss": 0.0223,
      "step": 60800
    },
    {
      "epoch": 7.3265060240963855,
      "grad_norm": 0.04050007089972496,
      "learning_rate": 5.34698795180723e-06,
      "loss": 0.003,
      "step": 60810
    },
    {
      "epoch": 7.327710843373494,
      "grad_norm": 0.001221111393533647,
      "learning_rate": 5.344578313253013e-06,
      "loss": 0.0082,
      "step": 60820
    },
    {
      "epoch": 7.328915662650602,
      "grad_norm": 0.0019103855593129992,
      "learning_rate": 5.342168674698795e-06,
      "loss": 0.0438,
      "step": 60830
    },
    {
      "epoch": 7.330120481927711,
      "grad_norm": 0.00805344246327877,
      "learning_rate": 5.3397590361445785e-06,
      "loss": 0.029,
      "step": 60840
    },
    {
      "epoch": 7.331325301204819,
      "grad_norm": 0.0021452573128044605,
      "learning_rate": 5.3373493975903625e-06,
      "loss": 0.0498,
      "step": 60850
    },
    {
      "epoch": 7.332530120481928,
      "grad_norm": 0.0018267952837049961,
      "learning_rate": 5.334939759036145e-06,
      "loss": 0.0109,
      "step": 60860
    },
    {
      "epoch": 7.333734939759037,
      "grad_norm": 0.7588179111480713,
      "learning_rate": 5.332530120481928e-06,
      "loss": 0.0031,
      "step": 60870
    },
    {
      "epoch": 7.3349397590361445,
      "grad_norm": 0.004216395318508148,
      "learning_rate": 5.330120481927711e-06,
      "loss": 0.0098,
      "step": 60880
    },
    {
      "epoch": 7.336144578313253,
      "grad_norm": 0.0010431441478431225,
      "learning_rate": 5.327710843373494e-06,
      "loss": 0.0108,
      "step": 60890
    },
    {
      "epoch": 7.337349397590361,
      "grad_norm": 2.53676700592041,
      "learning_rate": 5.325301204819278e-06,
      "loss": 0.0183,
      "step": 60900
    },
    {
      "epoch": 7.33855421686747,
      "grad_norm": 1.409660816192627,
      "learning_rate": 5.322891566265061e-06,
      "loss": 0.023,
      "step": 60910
    },
    {
      "epoch": 7.339759036144578,
      "grad_norm": 0.02627982199192047,
      "learning_rate": 5.320481927710843e-06,
      "loss": 0.004,
      "step": 60920
    },
    {
      "epoch": 7.340963855421687,
      "grad_norm": 1.1520570516586304,
      "learning_rate": 5.318072289156627e-06,
      "loss": 0.0253,
      "step": 60930
    },
    {
      "epoch": 7.3421686746987955,
      "grad_norm": 1.2243977785110474,
      "learning_rate": 5.31566265060241e-06,
      "loss": 0.0138,
      "step": 60940
    },
    {
      "epoch": 7.343373493975903,
      "grad_norm": 0.0020965144503861666,
      "learning_rate": 5.313253012048193e-06,
      "loss": 0.0288,
      "step": 60950
    },
    {
      "epoch": 7.344578313253012,
      "grad_norm": 0.002914212178438902,
      "learning_rate": 5.310843373493977e-06,
      "loss": 0.0189,
      "step": 60960
    },
    {
      "epoch": 7.34578313253012,
      "grad_norm": 0.0014023571275174618,
      "learning_rate": 5.30843373493976e-06,
      "loss": 0.005,
      "step": 60970
    },
    {
      "epoch": 7.346987951807229,
      "grad_norm": 0.0005375485634431243,
      "learning_rate": 5.306024096385542e-06,
      "loss": 0.0101,
      "step": 60980
    },
    {
      "epoch": 7.348192771084337,
      "grad_norm": 0.0039957184344530106,
      "learning_rate": 5.303614457831325e-06,
      "loss": 0.0171,
      "step": 60990
    },
    {
      "epoch": 7.349397590361446,
      "grad_norm": 0.08792968839406967,
      "learning_rate": 5.301204819277109e-06,
      "loss": 0.0307,
      "step": 61000
    },
    {
      "epoch": 7.3506024096385545,
      "grad_norm": 6.269331455230713,
      "learning_rate": 5.2987951807228925e-06,
      "loss": 0.0217,
      "step": 61010
    },
    {
      "epoch": 7.351807228915662,
      "grad_norm": 0.0027423605788499117,
      "learning_rate": 5.296385542168675e-06,
      "loss": 0.0446,
      "step": 61020
    },
    {
      "epoch": 7.353012048192771,
      "grad_norm": 0.0006310662138275802,
      "learning_rate": 5.293975903614458e-06,
      "loss": 0.0006,
      "step": 61030
    },
    {
      "epoch": 7.354216867469879,
      "grad_norm": 0.03427574411034584,
      "learning_rate": 5.291566265060242e-06,
      "loss": 0.0366,
      "step": 61040
    },
    {
      "epoch": 7.355421686746988,
      "grad_norm": 0.0022676154039800167,
      "learning_rate": 5.289156626506024e-06,
      "loss": 0.0078,
      "step": 61050
    },
    {
      "epoch": 7.356626506024097,
      "grad_norm": 2.1123440265655518,
      "learning_rate": 5.2867469879518075e-06,
      "loss": 0.0611,
      "step": 61060
    },
    {
      "epoch": 7.357831325301205,
      "grad_norm": 0.04718668758869171,
      "learning_rate": 5.28433734939759e-06,
      "loss": 0.0259,
      "step": 61070
    },
    {
      "epoch": 7.3590361445783135,
      "grad_norm": 0.09607736021280289,
      "learning_rate": 5.281927710843374e-06,
      "loss": 0.0059,
      "step": 61080
    },
    {
      "epoch": 7.360240963855421,
      "grad_norm": 6.446785926818848,
      "learning_rate": 5.279518072289157e-06,
      "loss": 0.0178,
      "step": 61090
    },
    {
      "epoch": 7.36144578313253,
      "grad_norm": 0.002285722643136978,
      "learning_rate": 5.27710843373494e-06,
      "loss": 0.0142,
      "step": 61100
    },
    {
      "epoch": 7.362650602409639,
      "grad_norm": 0.008270153775811195,
      "learning_rate": 5.2746987951807234e-06,
      "loss": 0.0177,
      "step": 61110
    },
    {
      "epoch": 7.363855421686747,
      "grad_norm": 2.0068538188934326,
      "learning_rate": 5.272289156626507e-06,
      "loss": 0.0478,
      "step": 61120
    },
    {
      "epoch": 7.365060240963856,
      "grad_norm": 0.8805556297302246,
      "learning_rate": 5.26987951807229e-06,
      "loss": 0.0031,
      "step": 61130
    },
    {
      "epoch": 7.366265060240964,
      "grad_norm": 0.009131981059908867,
      "learning_rate": 5.267469879518072e-06,
      "loss": 0.0449,
      "step": 61140
    },
    {
      "epoch": 7.367469879518072,
      "grad_norm": 2.0536887645721436,
      "learning_rate": 5.265060240963856e-06,
      "loss": 0.0182,
      "step": 61150
    },
    {
      "epoch": 7.36867469879518,
      "grad_norm": 0.00982597004622221,
      "learning_rate": 5.262650602409639e-06,
      "loss": 0.0254,
      "step": 61160
    },
    {
      "epoch": 7.369879518072289,
      "grad_norm": 0.026124266907572746,
      "learning_rate": 5.260240963855422e-06,
      "loss": 0.002,
      "step": 61170
    },
    {
      "epoch": 7.371084337349398,
      "grad_norm": 0.0032320646569132805,
      "learning_rate": 5.257831325301205e-06,
      "loss": 0.0104,
      "step": 61180
    },
    {
      "epoch": 7.372289156626506,
      "grad_norm": 0.030755996704101562,
      "learning_rate": 5.255421686746989e-06,
      "loss": 0.005,
      "step": 61190
    },
    {
      "epoch": 7.373493975903615,
      "grad_norm": 0.002644271356984973,
      "learning_rate": 5.253012048192771e-06,
      "loss": 0.0314,
      "step": 61200
    },
    {
      "epoch": 7.374698795180723,
      "grad_norm": 0.2948628067970276,
      "learning_rate": 5.250602409638554e-06,
      "loss": 0.0122,
      "step": 61210
    },
    {
      "epoch": 7.375903614457831,
      "grad_norm": 0.10831724852323532,
      "learning_rate": 5.248192771084338e-06,
      "loss": 0.0115,
      "step": 61220
    },
    {
      "epoch": 7.377108433734939,
      "grad_norm": 2.286837339401245,
      "learning_rate": 5.2457831325301215e-06,
      "loss": 0.025,
      "step": 61230
    },
    {
      "epoch": 7.378313253012048,
      "grad_norm": 1.9001445770263672,
      "learning_rate": 5.243373493975904e-06,
      "loss": 0.0302,
      "step": 61240
    },
    {
      "epoch": 7.379518072289157,
      "grad_norm": 0.02303609624505043,
      "learning_rate": 5.240963855421687e-06,
      "loss": 0.0058,
      "step": 61250
    },
    {
      "epoch": 7.380722891566265,
      "grad_norm": 25.582481384277344,
      "learning_rate": 5.238554216867471e-06,
      "loss": 0.0295,
      "step": 61260
    },
    {
      "epoch": 7.381927710843374,
      "grad_norm": 0.003052701707929373,
      "learning_rate": 5.236144578313253e-06,
      "loss": 0.0029,
      "step": 61270
    },
    {
      "epoch": 7.3831325301204815,
      "grad_norm": 1.408158540725708,
      "learning_rate": 5.2337349397590366e-06,
      "loss": 0.032,
      "step": 61280
    },
    {
      "epoch": 7.38433734939759,
      "grad_norm": 0.44731810688972473,
      "learning_rate": 5.231325301204819e-06,
      "loss": 0.0141,
      "step": 61290
    },
    {
      "epoch": 7.385542168674699,
      "grad_norm": 0.0019799338188022375,
      "learning_rate": 5.228915662650603e-06,
      "loss": 0.0069,
      "step": 61300
    },
    {
      "epoch": 7.386746987951807,
      "grad_norm": 0.5116539001464844,
      "learning_rate": 5.226506024096386e-06,
      "loss": 0.0478,
      "step": 61310
    },
    {
      "epoch": 7.387951807228916,
      "grad_norm": 0.3726273477077484,
      "learning_rate": 5.224096385542169e-06,
      "loss": 0.0128,
      "step": 61320
    },
    {
      "epoch": 7.389156626506024,
      "grad_norm": 0.9405993223190308,
      "learning_rate": 5.221686746987952e-06,
      "loss": 0.0246,
      "step": 61330
    },
    {
      "epoch": 7.390361445783133,
      "grad_norm": 0.0012403352884575725,
      "learning_rate": 5.219277108433736e-06,
      "loss": 0.0316,
      "step": 61340
    },
    {
      "epoch": 7.391566265060241,
      "grad_norm": 0.0008563589653931558,
      "learning_rate": 5.216867469879519e-06,
      "loss": 0.0031,
      "step": 61350
    },
    {
      "epoch": 7.392771084337349,
      "grad_norm": 0.0011440295493230224,
      "learning_rate": 5.214457831325301e-06,
      "loss": 0.0148,
      "step": 61360
    },
    {
      "epoch": 7.393975903614458,
      "grad_norm": 0.12114066630601883,
      "learning_rate": 5.212048192771085e-06,
      "loss": 0.0197,
      "step": 61370
    },
    {
      "epoch": 7.395180722891566,
      "grad_norm": 0.002619741018861532,
      "learning_rate": 5.209638554216868e-06,
      "loss": 0.0001,
      "step": 61380
    },
    {
      "epoch": 7.396385542168675,
      "grad_norm": 0.0017366827232763171,
      "learning_rate": 5.207228915662651e-06,
      "loss": 0.0083,
      "step": 61390
    },
    {
      "epoch": 7.397590361445783,
      "grad_norm": 2.5839388370513916,
      "learning_rate": 5.204819277108434e-06,
      "loss": 0.0124,
      "step": 61400
    },
    {
      "epoch": 7.3987951807228916,
      "grad_norm": 0.318651020526886,
      "learning_rate": 5.202409638554218e-06,
      "loss": 0.0261,
      "step": 61410
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.23224423825740814,
      "learning_rate": 5.2e-06,
      "loss": 0.0143,
      "step": 61420
    },
    {
      "epoch": 7.401204819277108,
      "grad_norm": 0.002042544772848487,
      "learning_rate": 5.197590361445783e-06,
      "loss": 0.0062,
      "step": 61430
    },
    {
      "epoch": 7.402409638554217,
      "grad_norm": 0.3233284652233124,
      "learning_rate": 5.1951807228915665e-06,
      "loss": 0.0454,
      "step": 61440
    },
    {
      "epoch": 7.403614457831325,
      "grad_norm": 0.002001951215788722,
      "learning_rate": 5.1927710843373506e-06,
      "loss": 0.0098,
      "step": 61450
    },
    {
      "epoch": 7.404819277108434,
      "grad_norm": 0.018699470907449722,
      "learning_rate": 5.190361445783133e-06,
      "loss": 0.0098,
      "step": 61460
    },
    {
      "epoch": 7.406024096385542,
      "grad_norm": 0.431697815656662,
      "learning_rate": 5.187951807228916e-06,
      "loss": 0.0094,
      "step": 61470
    },
    {
      "epoch": 7.4072289156626505,
      "grad_norm": 0.7051264047622681,
      "learning_rate": 5.185542168674698e-06,
      "loss": 0.0158,
      "step": 61480
    },
    {
      "epoch": 7.408433734939759,
      "grad_norm": 1.0511590242385864,
      "learning_rate": 5.183132530120482e-06,
      "loss": 0.0153,
      "step": 61490
    },
    {
      "epoch": 7.409638554216867,
      "grad_norm": 0.02355801686644554,
      "learning_rate": 5.180722891566266e-06,
      "loss": 0.0185,
      "step": 61500
    },
    {
      "epoch": 7.410843373493976,
      "grad_norm": 0.009667939506471157,
      "learning_rate": 5.178313253012048e-06,
      "loss": 0.0008,
      "step": 61510
    },
    {
      "epoch": 7.412048192771084,
      "grad_norm": 0.0017205660697072744,
      "learning_rate": 5.175903614457832e-06,
      "loss": 0.0047,
      "step": 61520
    },
    {
      "epoch": 7.413253012048193,
      "grad_norm": 68.76731872558594,
      "learning_rate": 5.173493975903615e-06,
      "loss": 0.0288,
      "step": 61530
    },
    {
      "epoch": 7.414457831325302,
      "grad_norm": 0.0007240127888508141,
      "learning_rate": 5.171084337349398e-06,
      "loss": 0.0062,
      "step": 61540
    },
    {
      "epoch": 7.4156626506024095,
      "grad_norm": 1.8508285284042358,
      "learning_rate": 5.168674698795181e-06,
      "loss": 0.0229,
      "step": 61550
    },
    {
      "epoch": 7.416867469879518,
      "grad_norm": 0.00034197699278593063,
      "learning_rate": 5.166265060240965e-06,
      "loss": 0.0235,
      "step": 61560
    },
    {
      "epoch": 7.418072289156626,
      "grad_norm": 0.0006992905982770026,
      "learning_rate": 5.163855421686748e-06,
      "loss": 0.0146,
      "step": 61570
    },
    {
      "epoch": 7.419277108433735,
      "grad_norm": 0.0012279388029128313,
      "learning_rate": 5.16144578313253e-06,
      "loss": 0.0137,
      "step": 61580
    },
    {
      "epoch": 7.420481927710844,
      "grad_norm": 0.4450117349624634,
      "learning_rate": 5.159036144578313e-06,
      "loss": 0.0128,
      "step": 61590
    },
    {
      "epoch": 7.421686746987952,
      "grad_norm": 1.2041833400726318,
      "learning_rate": 5.156626506024097e-06,
      "loss": 0.0073,
      "step": 61600
    },
    {
      "epoch": 7.4228915662650605,
      "grad_norm": 0.01084019336849451,
      "learning_rate": 5.15421686746988e-06,
      "loss": 0.0143,
      "step": 61610
    },
    {
      "epoch": 7.424096385542168,
      "grad_norm": 0.049531955271959305,
      "learning_rate": 5.151807228915663e-06,
      "loss": 0.0382,
      "step": 61620
    },
    {
      "epoch": 7.425301204819277,
      "grad_norm": 0.0014823406236246228,
      "learning_rate": 5.149397590361446e-06,
      "loss": 0.0022,
      "step": 61630
    },
    {
      "epoch": 7.426506024096385,
      "grad_norm": 0.4388735890388489,
      "learning_rate": 5.14698795180723e-06,
      "loss": 0.0134,
      "step": 61640
    },
    {
      "epoch": 7.427710843373494,
      "grad_norm": 0.002552735386416316,
      "learning_rate": 5.144578313253012e-06,
      "loss": 0.0086,
      "step": 61650
    },
    {
      "epoch": 7.428915662650603,
      "grad_norm": 0.014552433975040913,
      "learning_rate": 5.1421686746987956e-06,
      "loss": 0.028,
      "step": 61660
    },
    {
      "epoch": 7.430120481927711,
      "grad_norm": 0.003226672764867544,
      "learning_rate": 5.13975903614458e-06,
      "loss": 0.0057,
      "step": 61670
    },
    {
      "epoch": 7.4313253012048195,
      "grad_norm": 0.0027383079286664724,
      "learning_rate": 5.137349397590362e-06,
      "loss": 0.0013,
      "step": 61680
    },
    {
      "epoch": 7.432530120481927,
      "grad_norm": 0.0015925932675600052,
      "learning_rate": 5.134939759036145e-06,
      "loss": 0.0138,
      "step": 61690
    },
    {
      "epoch": 7.433734939759036,
      "grad_norm": 0.33758407831192017,
      "learning_rate": 5.132530120481927e-06,
      "loss": 0.014,
      "step": 61700
    },
    {
      "epoch": 7.434939759036144,
      "grad_norm": 0.0010543788084760308,
      "learning_rate": 5.1301204819277114e-06,
      "loss": 0.0115,
      "step": 61710
    },
    {
      "epoch": 7.436144578313253,
      "grad_norm": 7.250003337860107,
      "learning_rate": 5.127710843373495e-06,
      "loss": 0.0432,
      "step": 61720
    },
    {
      "epoch": 7.437349397590362,
      "grad_norm": 0.0005526678287424147,
      "learning_rate": 5.125301204819278e-06,
      "loss": 0.0255,
      "step": 61730
    },
    {
      "epoch": 7.43855421686747,
      "grad_norm": 0.0014166274340823293,
      "learning_rate": 5.12289156626506e-06,
      "loss": 0.0279,
      "step": 61740
    },
    {
      "epoch": 7.4397590361445785,
      "grad_norm": 1.1153569221496582,
      "learning_rate": 5.120481927710844e-06,
      "loss": 0.0239,
      "step": 61750
    },
    {
      "epoch": 7.440963855421686,
      "grad_norm": 7.991950511932373,
      "learning_rate": 5.118072289156627e-06,
      "loss": 0.035,
      "step": 61760
    },
    {
      "epoch": 7.442168674698795,
      "grad_norm": 1.4867175817489624,
      "learning_rate": 5.11566265060241e-06,
      "loss": 0.016,
      "step": 61770
    },
    {
      "epoch": 7.443373493975904,
      "grad_norm": 0.006923508830368519,
      "learning_rate": 5.113253012048193e-06,
      "loss": 0.0021,
      "step": 61780
    },
    {
      "epoch": 7.444578313253012,
      "grad_norm": 0.013264006935060024,
      "learning_rate": 5.110843373493977e-06,
      "loss": 0.0003,
      "step": 61790
    },
    {
      "epoch": 7.445783132530121,
      "grad_norm": 0.0043106586672365665,
      "learning_rate": 5.108433734939759e-06,
      "loss": 0.0041,
      "step": 61800
    },
    {
      "epoch": 7.446987951807229,
      "grad_norm": 0.0012728823348879814,
      "learning_rate": 5.106024096385542e-06,
      "loss": 0.0401,
      "step": 61810
    },
    {
      "epoch": 7.448192771084337,
      "grad_norm": 0.3048357665538788,
      "learning_rate": 5.103614457831326e-06,
      "loss": 0.018,
      "step": 61820
    },
    {
      "epoch": 7.449397590361446,
      "grad_norm": 0.029384804889559746,
      "learning_rate": 5.101204819277109e-06,
      "loss": 0.01,
      "step": 61830
    },
    {
      "epoch": 7.450602409638554,
      "grad_norm": 0.00994433555752039,
      "learning_rate": 5.098795180722892e-06,
      "loss": 0.0055,
      "step": 61840
    },
    {
      "epoch": 7.451807228915663,
      "grad_norm": 0.09402640908956528,
      "learning_rate": 5.096385542168675e-06,
      "loss": 0.0059,
      "step": 61850
    },
    {
      "epoch": 7.453012048192771,
      "grad_norm": 0.0011201436864212155,
      "learning_rate": 5.093975903614459e-06,
      "loss": 0.019,
      "step": 61860
    },
    {
      "epoch": 7.45421686746988,
      "grad_norm": 1.1382274627685547,
      "learning_rate": 5.091566265060241e-06,
      "loss": 0.0098,
      "step": 61870
    },
    {
      "epoch": 7.455421686746988,
      "grad_norm": 1.7463083267211914,
      "learning_rate": 5.089156626506025e-06,
      "loss": 0.0077,
      "step": 61880
    },
    {
      "epoch": 7.456626506024096,
      "grad_norm": 0.18524639308452606,
      "learning_rate": 5.086746987951807e-06,
      "loss": 0.002,
      "step": 61890
    },
    {
      "epoch": 7.457831325301205,
      "grad_norm": 0.002493231324478984,
      "learning_rate": 5.084337349397591e-06,
      "loss": 0.0171,
      "step": 61900
    },
    {
      "epoch": 7.459036144578313,
      "grad_norm": 8.846830368041992,
      "learning_rate": 5.081927710843374e-06,
      "loss": 0.0072,
      "step": 61910
    },
    {
      "epoch": 7.460240963855422,
      "grad_norm": 0.9593842029571533,
      "learning_rate": 5.0795180722891564e-06,
      "loss": 0.0369,
      "step": 61920
    },
    {
      "epoch": 7.46144578313253,
      "grad_norm": 0.002946823602542281,
      "learning_rate": 5.07710843373494e-06,
      "loss": 0.0156,
      "step": 61930
    },
    {
      "epoch": 7.462650602409639,
      "grad_norm": 0.20937879383563995,
      "learning_rate": 5.074698795180724e-06,
      "loss": 0.0161,
      "step": 61940
    },
    {
      "epoch": 7.4638554216867465,
      "grad_norm": 0.0011597821721807122,
      "learning_rate": 5.072289156626507e-06,
      "loss": 0.0092,
      "step": 61950
    },
    {
      "epoch": 7.465060240963855,
      "grad_norm": 0.6115216612815857,
      "learning_rate": 5.069879518072289e-06,
      "loss": 0.0098,
      "step": 61960
    },
    {
      "epoch": 7.466265060240964,
      "grad_norm": 2.708678960800171,
      "learning_rate": 5.067469879518073e-06,
      "loss": 0.0265,
      "step": 61970
    },
    {
      "epoch": 7.467469879518072,
      "grad_norm": 0.0010209648171439767,
      "learning_rate": 5.065060240963856e-06,
      "loss": 0.0036,
      "step": 61980
    },
    {
      "epoch": 7.468674698795181,
      "grad_norm": 0.8686612844467163,
      "learning_rate": 5.062650602409639e-06,
      "loss": 0.0121,
      "step": 61990
    },
    {
      "epoch": 7.469879518072289,
      "grad_norm": 0.01569310389459133,
      "learning_rate": 5.060240963855422e-06,
      "loss": 0.0123,
      "step": 62000
    },
    {
      "epoch": 7.471084337349398,
      "grad_norm": 0.0007408944074995816,
      "learning_rate": 5.057831325301206e-06,
      "loss": 0.0094,
      "step": 62010
    },
    {
      "epoch": 7.472289156626506,
      "grad_norm": 0.0011189680080860853,
      "learning_rate": 5.055421686746988e-06,
      "loss": 0.0181,
      "step": 62020
    },
    {
      "epoch": 7.473493975903614,
      "grad_norm": 0.004768740385770798,
      "learning_rate": 5.053012048192771e-06,
      "loss": 0.0201,
      "step": 62030
    },
    {
      "epoch": 7.474698795180723,
      "grad_norm": 0.0015309372683987021,
      "learning_rate": 5.0506024096385546e-06,
      "loss": 0.0033,
      "step": 62040
    },
    {
      "epoch": 7.475903614457831,
      "grad_norm": 0.0005527219618670642,
      "learning_rate": 5.048192771084338e-06,
      "loss": 0.0033,
      "step": 62050
    },
    {
      "epoch": 7.47710843373494,
      "grad_norm": 1.270111083984375,
      "learning_rate": 5.045783132530121e-06,
      "loss": 0.0425,
      "step": 62060
    },
    {
      "epoch": 7.478313253012049,
      "grad_norm": 0.32720813155174255,
      "learning_rate": 5.043373493975904e-06,
      "loss": 0.0042,
      "step": 62070
    },
    {
      "epoch": 7.4795180722891565,
      "grad_norm": 1.2565679550170898,
      "learning_rate": 5.040963855421686e-06,
      "loss": 0.0077,
      "step": 62080
    },
    {
      "epoch": 7.480722891566265,
      "grad_norm": 0.0021631382405757904,
      "learning_rate": 5.0385542168674704e-06,
      "loss": 0.0114,
      "step": 62090
    },
    {
      "epoch": 7.481927710843373,
      "grad_norm": 0.03025267831981182,
      "learning_rate": 5.036144578313254e-06,
      "loss": 0.0061,
      "step": 62100
    },
    {
      "epoch": 7.483132530120482,
      "grad_norm": 0.0008162607555277646,
      "learning_rate": 5.033734939759036e-06,
      "loss": 0.0373,
      "step": 62110
    },
    {
      "epoch": 7.48433734939759,
      "grad_norm": 4.80620002746582,
      "learning_rate": 5.03132530120482e-06,
      "loss": 0.0227,
      "step": 62120
    },
    {
      "epoch": 7.485542168674699,
      "grad_norm": 0.015013247728347778,
      "learning_rate": 5.028915662650603e-06,
      "loss": 0.0163,
      "step": 62130
    },
    {
      "epoch": 7.486746987951808,
      "grad_norm": 0.010178430005908012,
      "learning_rate": 5.0265060240963855e-06,
      "loss": 0.0216,
      "step": 62140
    },
    {
      "epoch": 7.4879518072289155,
      "grad_norm": 0.0010527399135753512,
      "learning_rate": 5.024096385542169e-06,
      "loss": 0.0044,
      "step": 62150
    },
    {
      "epoch": 7.489156626506024,
      "grad_norm": 0.0009334906935691833,
      "learning_rate": 5.021686746987953e-06,
      "loss": 0.0067,
      "step": 62160
    },
    {
      "epoch": 7.490361445783132,
      "grad_norm": 2.4315237998962402,
      "learning_rate": 5.019277108433736e-06,
      "loss": 0.0195,
      "step": 62170
    },
    {
      "epoch": 7.491566265060241,
      "grad_norm": 0.0020878720097243786,
      "learning_rate": 5.016867469879518e-06,
      "loss": 0.0076,
      "step": 62180
    },
    {
      "epoch": 7.492771084337349,
      "grad_norm": 0.0006751767941750586,
      "learning_rate": 5.014457831325301e-06,
      "loss": 0.003,
      "step": 62190
    },
    {
      "epoch": 7.493975903614458,
      "grad_norm": 0.0025902993511408567,
      "learning_rate": 5.012048192771085e-06,
      "loss": 0.0134,
      "step": 62200
    },
    {
      "epoch": 7.495180722891567,
      "grad_norm": 1.2588640451431274,
      "learning_rate": 5.009638554216868e-06,
      "loss": 0.0109,
      "step": 62210
    },
    {
      "epoch": 7.4963855421686745,
      "grad_norm": 0.1509636491537094,
      "learning_rate": 5.007228915662651e-06,
      "loss": 0.0072,
      "step": 62220
    },
    {
      "epoch": 7.497590361445783,
      "grad_norm": 0.0011852274183183908,
      "learning_rate": 5.004819277108433e-06,
      "loss": 0.0293,
      "step": 62230
    },
    {
      "epoch": 7.498795180722891,
      "grad_norm": 0.1550748199224472,
      "learning_rate": 5.002409638554217e-06,
      "loss": 0.0015,
      "step": 62240
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.01416930090636015,
      "learning_rate": 5e-06,
      "loss": 0.0152,
      "step": 62250
    },
    {
      "epoch": 7.501204819277109,
      "grad_norm": 0.011043049395084381,
      "learning_rate": 4.997590361445784e-06,
      "loss": 0.0056,
      "step": 62260
    },
    {
      "epoch": 7.502409638554217,
      "grad_norm": 0.0004784366174135357,
      "learning_rate": 4.995180722891567e-06,
      "loss": 0.0092,
      "step": 62270
    },
    {
      "epoch": 7.5036144578313255,
      "grad_norm": 0.0007586070569232106,
      "learning_rate": 4.99277108433735e-06,
      "loss": 0.015,
      "step": 62280
    },
    {
      "epoch": 7.504819277108433,
      "grad_norm": 0.1261371374130249,
      "learning_rate": 4.990361445783133e-06,
      "loss": 0.0068,
      "step": 62290
    },
    {
      "epoch": 7.506024096385542,
      "grad_norm": 0.024729780852794647,
      "learning_rate": 4.987951807228916e-06,
      "loss": 0.0053,
      "step": 62300
    },
    {
      "epoch": 7.507228915662651,
      "grad_norm": 0.0007046366808936,
      "learning_rate": 4.9855421686746995e-06,
      "loss": 0.055,
      "step": 62310
    },
    {
      "epoch": 7.508433734939759,
      "grad_norm": 0.2640547454357147,
      "learning_rate": 4.983132530120483e-06,
      "loss": 0.0246,
      "step": 62320
    },
    {
      "epoch": 7.509638554216868,
      "grad_norm": 0.0025863507762551308,
      "learning_rate": 4.980722891566265e-06,
      "loss": 0.0195,
      "step": 62330
    },
    {
      "epoch": 7.510843373493976,
      "grad_norm": 0.4492393732070923,
      "learning_rate": 4.978313253012049e-06,
      "loss": 0.0342,
      "step": 62340
    },
    {
      "epoch": 7.5120481927710845,
      "grad_norm": 0.020167266950011253,
      "learning_rate": 4.975903614457831e-06,
      "loss": 0.0096,
      "step": 62350
    },
    {
      "epoch": 7.513253012048192,
      "grad_norm": 1.933835506439209,
      "learning_rate": 4.973493975903615e-06,
      "loss": 0.0258,
      "step": 62360
    },
    {
      "epoch": 7.514457831325301,
      "grad_norm": 0.01727287843823433,
      "learning_rate": 4.971084337349398e-06,
      "loss": 0.0553,
      "step": 62370
    },
    {
      "epoch": 7.51566265060241,
      "grad_norm": 1.151803970336914,
      "learning_rate": 4.968674698795181e-06,
      "loss": 0.0101,
      "step": 62380
    },
    {
      "epoch": 7.516867469879518,
      "grad_norm": 0.9239586591720581,
      "learning_rate": 4.966265060240964e-06,
      "loss": 0.0173,
      "step": 62390
    },
    {
      "epoch": 7.518072289156627,
      "grad_norm": 0.28511279821395874,
      "learning_rate": 4.963855421686747e-06,
      "loss": 0.0067,
      "step": 62400
    },
    {
      "epoch": 7.519277108433735,
      "grad_norm": 0.43851378560066223,
      "learning_rate": 4.96144578313253e-06,
      "loss": 0.0165,
      "step": 62410
    },
    {
      "epoch": 7.5204819277108435,
      "grad_norm": 0.000817280902992934,
      "learning_rate": 4.9590361445783136e-06,
      "loss": 0.0008,
      "step": 62420
    },
    {
      "epoch": 7.521686746987951,
      "grad_norm": 0.0008142617298290133,
      "learning_rate": 4.956626506024097e-06,
      "loss": 0.0113,
      "step": 62430
    },
    {
      "epoch": 7.52289156626506,
      "grad_norm": 0.036988530308008194,
      "learning_rate": 4.95421686746988e-06,
      "loss": 0.0054,
      "step": 62440
    },
    {
      "epoch": 7.524096385542169,
      "grad_norm": 0.000648645160254091,
      "learning_rate": 4.951807228915663e-06,
      "loss": 0.0159,
      "step": 62450
    },
    {
      "epoch": 7.525301204819277,
      "grad_norm": 3.885948896408081,
      "learning_rate": 4.949397590361446e-06,
      "loss": 0.026,
      "step": 62460
    },
    {
      "epoch": 7.526506024096386,
      "grad_norm": 0.0008084297878667712,
      "learning_rate": 4.9469879518072294e-06,
      "loss": 0.0196,
      "step": 62470
    },
    {
      "epoch": 7.527710843373494,
      "grad_norm": 0.012404432520270348,
      "learning_rate": 4.944578313253013e-06,
      "loss": 0.0508,
      "step": 62480
    },
    {
      "epoch": 7.528915662650602,
      "grad_norm": 0.5122380256652832,
      "learning_rate": 4.942168674698796e-06,
      "loss": 0.0243,
      "step": 62490
    },
    {
      "epoch": 7.530120481927711,
      "grad_norm": 0.004217453766614199,
      "learning_rate": 4.939759036144578e-06,
      "loss": 0.0087,
      "step": 62500
    },
    {
      "epoch": 7.531325301204819,
      "grad_norm": 0.24849791824817657,
      "learning_rate": 4.937349397590362e-06,
      "loss": 0.0158,
      "step": 62510
    },
    {
      "epoch": 7.532530120481928,
      "grad_norm": 0.001877427101135254,
      "learning_rate": 4.9349397590361445e-06,
      "loss": 0.0056,
      "step": 62520
    },
    {
      "epoch": 7.533734939759036,
      "grad_norm": 0.39943403005599976,
      "learning_rate": 4.9325301204819285e-06,
      "loss": 0.0029,
      "step": 62530
    },
    {
      "epoch": 7.534939759036145,
      "grad_norm": 1.9063763618469238,
      "learning_rate": 4.930120481927711e-06,
      "loss": 0.0163,
      "step": 62540
    },
    {
      "epoch": 7.5361445783132535,
      "grad_norm": 0.775658130645752,
      "learning_rate": 4.927710843373494e-06,
      "loss": 0.0108,
      "step": 62550
    },
    {
      "epoch": 7.537349397590361,
      "grad_norm": 0.012027471326291561,
      "learning_rate": 4.925301204819278e-06,
      "loss": 0.0038,
      "step": 62560
    },
    {
      "epoch": 7.53855421686747,
      "grad_norm": 0.061512477695941925,
      "learning_rate": 4.92289156626506e-06,
      "loss": 0.0075,
      "step": 62570
    },
    {
      "epoch": 7.539759036144578,
      "grad_norm": 0.242121621966362,
      "learning_rate": 4.920481927710844e-06,
      "loss": 0.02,
      "step": 62580
    },
    {
      "epoch": 7.540963855421687,
      "grad_norm": 0.01785217970609665,
      "learning_rate": 4.918072289156627e-06,
      "loss": 0.0362,
      "step": 62590
    },
    {
      "epoch": 7.542168674698795,
      "grad_norm": 0.8199474215507507,
      "learning_rate": 4.91566265060241e-06,
      "loss": 0.0186,
      "step": 62600
    },
    {
      "epoch": 7.543373493975904,
      "grad_norm": 0.016166625544428825,
      "learning_rate": 4.913253012048193e-06,
      "loss": 0.0128,
      "step": 62610
    },
    {
      "epoch": 7.544578313253012,
      "grad_norm": 0.028907090425491333,
      "learning_rate": 4.910843373493976e-06,
      "loss": 0.0159,
      "step": 62620
    },
    {
      "epoch": 7.54578313253012,
      "grad_norm": 0.0012581582413986325,
      "learning_rate": 4.908433734939759e-06,
      "loss": 0.0076,
      "step": 62630
    },
    {
      "epoch": 7.546987951807229,
      "grad_norm": 0.006273257080465555,
      "learning_rate": 4.906024096385543e-06,
      "loss": 0.0081,
      "step": 62640
    },
    {
      "epoch": 7.548192771084337,
      "grad_norm": 17.697786331176758,
      "learning_rate": 4.903614457831326e-06,
      "loss": 0.0161,
      "step": 62650
    },
    {
      "epoch": 7.549397590361446,
      "grad_norm": 0.0005887100705876946,
      "learning_rate": 4.901204819277109e-06,
      "loss": 0.0643,
      "step": 62660
    },
    {
      "epoch": 7.550602409638554,
      "grad_norm": 1.1510919332504272,
      "learning_rate": 4.898795180722892e-06,
      "loss": 0.0041,
      "step": 62670
    },
    {
      "epoch": 7.551807228915663,
      "grad_norm": 1.7425005435943604,
      "learning_rate": 4.896385542168675e-06,
      "loss": 0.0174,
      "step": 62680
    },
    {
      "epoch": 7.553012048192771,
      "grad_norm": 0.0010704140877351165,
      "learning_rate": 4.893975903614458e-06,
      "loss": 0.0054,
      "step": 62690
    },
    {
      "epoch": 7.554216867469879,
      "grad_norm": 0.6484279036521912,
      "learning_rate": 4.891566265060242e-06,
      "loss": 0.0026,
      "step": 62700
    },
    {
      "epoch": 7.555421686746988,
      "grad_norm": 0.9257869720458984,
      "learning_rate": 4.889156626506025e-06,
      "loss": 0.0152,
      "step": 62710
    },
    {
      "epoch": 7.556626506024096,
      "grad_norm": 0.002154059475287795,
      "learning_rate": 4.886746987951808e-06,
      "loss": 0.0036,
      "step": 62720
    },
    {
      "epoch": 7.557831325301205,
      "grad_norm": 0.39143824577331543,
      "learning_rate": 4.884337349397591e-06,
      "loss": 0.0189,
      "step": 62730
    },
    {
      "epoch": 7.559036144578314,
      "grad_norm": 0.007589026819914579,
      "learning_rate": 4.8819277108433735e-06,
      "loss": 0.0338,
      "step": 62740
    },
    {
      "epoch": 7.5602409638554215,
      "grad_norm": 0.9819391369819641,
      "learning_rate": 4.8795180722891575e-06,
      "loss": 0.0265,
      "step": 62750
    },
    {
      "epoch": 7.56144578313253,
      "grad_norm": 0.00598478689789772,
      "learning_rate": 4.87710843373494e-06,
      "loss": 0.013,
      "step": 62760
    },
    {
      "epoch": 7.562650602409638,
      "grad_norm": 0.017656167969107628,
      "learning_rate": 4.874698795180723e-06,
      "loss": 0.0081,
      "step": 62770
    },
    {
      "epoch": 7.563855421686747,
      "grad_norm": 0.013204099610447884,
      "learning_rate": 4.872289156626506e-06,
      "loss": 0.0033,
      "step": 62780
    },
    {
      "epoch": 7.565060240963856,
      "grad_norm": 0.004792909603565931,
      "learning_rate": 4.869879518072289e-06,
      "loss": 0.0147,
      "step": 62790
    },
    {
      "epoch": 7.566265060240964,
      "grad_norm": 0.631144106388092,
      "learning_rate": 4.8674698795180725e-06,
      "loss": 0.0157,
      "step": 62800
    },
    {
      "epoch": 7.567469879518073,
      "grad_norm": 0.005417247302830219,
      "learning_rate": 4.865060240963856e-06,
      "loss": 0.0203,
      "step": 62810
    },
    {
      "epoch": 7.5686746987951805,
      "grad_norm": 0.0007785296184010804,
      "learning_rate": 4.862650602409639e-06,
      "loss": 0.0001,
      "step": 62820
    },
    {
      "epoch": 7.569879518072289,
      "grad_norm": 0.0015717563219368458,
      "learning_rate": 4.860240963855422e-06,
      "loss": 0.0002,
      "step": 62830
    },
    {
      "epoch": 7.571084337349397,
      "grad_norm": 3.331584930419922,
      "learning_rate": 4.857831325301205e-06,
      "loss": 0.0416,
      "step": 62840
    },
    {
      "epoch": 7.572289156626506,
      "grad_norm": 0.0010051812278106809,
      "learning_rate": 4.8554216867469884e-06,
      "loss": 0.0035,
      "step": 62850
    },
    {
      "epoch": 7.573493975903615,
      "grad_norm": 0.6330152153968811,
      "learning_rate": 4.853012048192772e-06,
      "loss": 0.0029,
      "step": 62860
    },
    {
      "epoch": 7.574698795180723,
      "grad_norm": 0.1448564976453781,
      "learning_rate": 4.850602409638555e-06,
      "loss": 0.0254,
      "step": 62870
    },
    {
      "epoch": 7.575903614457832,
      "grad_norm": 0.0005238744779489934,
      "learning_rate": 4.848192771084338e-06,
      "loss": 0.0098,
      "step": 62880
    },
    {
      "epoch": 7.5771084337349395,
      "grad_norm": 0.07138895243406296,
      "learning_rate": 4.845783132530121e-06,
      "loss": 0.0084,
      "step": 62890
    },
    {
      "epoch": 7.578313253012048,
      "grad_norm": 0.0009964728960767388,
      "learning_rate": 4.843373493975904e-06,
      "loss": 0.0242,
      "step": 62900
    },
    {
      "epoch": 7.579518072289156,
      "grad_norm": 0.008035462349653244,
      "learning_rate": 4.840963855421687e-06,
      "loss": 0.0178,
      "step": 62910
    },
    {
      "epoch": 7.580722891566265,
      "grad_norm": 1.1325668096542358,
      "learning_rate": 4.838554216867471e-06,
      "loss": 0.0281,
      "step": 62920
    },
    {
      "epoch": 7.581927710843374,
      "grad_norm": 0.0012760104145854712,
      "learning_rate": 4.836144578313253e-06,
      "loss": 0.0363,
      "step": 62930
    },
    {
      "epoch": 7.583132530120482,
      "grad_norm": 0.0018805612344294786,
      "learning_rate": 4.833734939759037e-06,
      "loss": 0.0291,
      "step": 62940
    },
    {
      "epoch": 7.5843373493975905,
      "grad_norm": 0.0032489197328686714,
      "learning_rate": 4.831325301204819e-06,
      "loss": 0.0003,
      "step": 62950
    },
    {
      "epoch": 7.585542168674698,
      "grad_norm": 1.8103972673416138,
      "learning_rate": 4.8289156626506025e-06,
      "loss": 0.0107,
      "step": 62960
    },
    {
      "epoch": 7.586746987951807,
      "grad_norm": 0.0009733918705023825,
      "learning_rate": 4.826506024096386e-06,
      "loss": 0.0173,
      "step": 62970
    },
    {
      "epoch": 7.587951807228916,
      "grad_norm": 0.0018742934335023165,
      "learning_rate": 4.824096385542169e-06,
      "loss": 0.0173,
      "step": 62980
    },
    {
      "epoch": 7.589156626506024,
      "grad_norm": 0.001238937838934362,
      "learning_rate": 4.821686746987953e-06,
      "loss": 0.0074,
      "step": 62990
    },
    {
      "epoch": 7.590361445783133,
      "grad_norm": 0.0010601362446323037,
      "learning_rate": 4.819277108433735e-06,
      "loss": 0.003,
      "step": 63000
    },
    {
      "epoch": 7.591566265060241,
      "grad_norm": 1.777221441268921,
      "learning_rate": 4.816867469879518e-06,
      "loss": 0.0122,
      "step": 63010
    },
    {
      "epoch": 7.5927710843373495,
      "grad_norm": 0.0044029997661709785,
      "learning_rate": 4.8144578313253016e-06,
      "loss": 0.0106,
      "step": 63020
    },
    {
      "epoch": 7.593975903614458,
      "grad_norm": 0.0011659110896289349,
      "learning_rate": 4.812048192771085e-06,
      "loss": 0.0172,
      "step": 63030
    },
    {
      "epoch": 7.595180722891566,
      "grad_norm": 1.2968546152114868,
      "learning_rate": 4.809638554216868e-06,
      "loss": 0.0142,
      "step": 63040
    },
    {
      "epoch": 7.596385542168675,
      "grad_norm": 0.0005642186151817441,
      "learning_rate": 4.807228915662651e-06,
      "loss": 0.0204,
      "step": 63050
    },
    {
      "epoch": 7.597590361445783,
      "grad_norm": 1.7125192880630493,
      "learning_rate": 4.804819277108434e-06,
      "loss": 0.0127,
      "step": 63060
    },
    {
      "epoch": 7.598795180722892,
      "grad_norm": 0.22738458216190338,
      "learning_rate": 4.8024096385542175e-06,
      "loss": 0.0016,
      "step": 63070
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.0022880632895976305,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0127,
      "step": 63080
    },
    {
      "epoch": 7.6012048192771084,
      "grad_norm": 0.5933091640472412,
      "learning_rate": 4.797590361445784e-06,
      "loss": 0.0401,
      "step": 63090
    },
    {
      "epoch": 7.602409638554217,
      "grad_norm": 0.7147797346115112,
      "learning_rate": 4.795180722891566e-06,
      "loss": 0.0049,
      "step": 63100
    },
    {
      "epoch": 7.603614457831325,
      "grad_norm": 0.0013406688813120127,
      "learning_rate": 4.79277108433735e-06,
      "loss": 0.006,
      "step": 63110
    },
    {
      "epoch": 7.604819277108434,
      "grad_norm": 1.6603721380233765,
      "learning_rate": 4.7903614457831325e-06,
      "loss": 0.0141,
      "step": 63120
    },
    {
      "epoch": 7.606024096385542,
      "grad_norm": 0.0027301497757434845,
      "learning_rate": 4.787951807228916e-06,
      "loss": 0.0334,
      "step": 63130
    },
    {
      "epoch": 7.607228915662651,
      "grad_norm": 0.0004988937871530652,
      "learning_rate": 4.7855421686747e-06,
      "loss": 0.0008,
      "step": 63140
    },
    {
      "epoch": 7.608433734939759,
      "grad_norm": 1.7074633836746216,
      "learning_rate": 4.783132530120482e-06,
      "loss": 0.0141,
      "step": 63150
    },
    {
      "epoch": 7.609638554216867,
      "grad_norm": 1.8312543630599976,
      "learning_rate": 4.780722891566266e-06,
      "loss": 0.0151,
      "step": 63160
    },
    {
      "epoch": 7.610843373493976,
      "grad_norm": 0.7752844095230103,
      "learning_rate": 4.778313253012048e-06,
      "loss": 0.041,
      "step": 63170
    },
    {
      "epoch": 7.612048192771084,
      "grad_norm": 0.0014680238673463464,
      "learning_rate": 4.7759036144578315e-06,
      "loss": 0.0426,
      "step": 63180
    },
    {
      "epoch": 7.613253012048193,
      "grad_norm": 2.6721794605255127,
      "learning_rate": 4.773493975903615e-06,
      "loss": 0.0314,
      "step": 63190
    },
    {
      "epoch": 7.614457831325301,
      "grad_norm": 1.1081467866897583,
      "learning_rate": 4.771084337349398e-06,
      "loss": 0.0309,
      "step": 63200
    },
    {
      "epoch": 7.61566265060241,
      "grad_norm": 0.0006213492597453296,
      "learning_rate": 4.768674698795181e-06,
      "loss": 0.0085,
      "step": 63210
    },
    {
      "epoch": 7.6168674698795185,
      "grad_norm": 2.241612434387207,
      "learning_rate": 4.766265060240964e-06,
      "loss": 0.04,
      "step": 63220
    },
    {
      "epoch": 7.618072289156626,
      "grad_norm": 0.21022656559944153,
      "learning_rate": 4.763855421686747e-06,
      "loss": 0.013,
      "step": 63230
    },
    {
      "epoch": 7.619277108433735,
      "grad_norm": 0.0008255336433649063,
      "learning_rate": 4.761445783132531e-06,
      "loss": 0.0074,
      "step": 63240
    },
    {
      "epoch": 7.620481927710843,
      "grad_norm": 0.0033470173366367817,
      "learning_rate": 4.759036144578314e-06,
      "loss": 0.0051,
      "step": 63250
    },
    {
      "epoch": 7.621686746987952,
      "grad_norm": 0.0009001056896522641,
      "learning_rate": 4.756626506024097e-06,
      "loss": 0.0087,
      "step": 63260
    },
    {
      "epoch": 7.622891566265061,
      "grad_norm": 0.02787351980805397,
      "learning_rate": 4.754216867469879e-06,
      "loss": 0.0208,
      "step": 63270
    },
    {
      "epoch": 7.624096385542169,
      "grad_norm": 0.1339157074689865,
      "learning_rate": 4.751807228915663e-06,
      "loss": 0.0056,
      "step": 63280
    },
    {
      "epoch": 7.625301204819277,
      "grad_norm": 0.0018696823390200734,
      "learning_rate": 4.7493975903614465e-06,
      "loss": 0.0146,
      "step": 63290
    },
    {
      "epoch": 7.626506024096385,
      "grad_norm": 0.016572313383221626,
      "learning_rate": 4.74698795180723e-06,
      "loss": 0.0066,
      "step": 63300
    },
    {
      "epoch": 7.627710843373494,
      "grad_norm": 1.6253169775009155,
      "learning_rate": 4.744578313253013e-06,
      "loss": 0.0067,
      "step": 63310
    },
    {
      "epoch": 7.628915662650602,
      "grad_norm": 0.0009277070639654994,
      "learning_rate": 4.742168674698795e-06,
      "loss": 0.0084,
      "step": 63320
    },
    {
      "epoch": 7.630120481927711,
      "grad_norm": 1.2583352327346802,
      "learning_rate": 4.739759036144579e-06,
      "loss": 0.0074,
      "step": 63330
    },
    {
      "epoch": 7.63132530120482,
      "grad_norm": 1.6693722009658813,
      "learning_rate": 4.7373493975903615e-06,
      "loss": 0.0099,
      "step": 63340
    },
    {
      "epoch": 7.632530120481928,
      "grad_norm": 0.0029480941593647003,
      "learning_rate": 4.734939759036145e-06,
      "loss": 0.0027,
      "step": 63350
    },
    {
      "epoch": 7.633734939759036,
      "grad_norm": 0.02131880261003971,
      "learning_rate": 4.732530120481928e-06,
      "loss": 0.0026,
      "step": 63360
    },
    {
      "epoch": 7.634939759036144,
      "grad_norm": 1.2868796586990356,
      "learning_rate": 4.730120481927711e-06,
      "loss": 0.0276,
      "step": 63370
    },
    {
      "epoch": 7.636144578313253,
      "grad_norm": 0.026023399084806442,
      "learning_rate": 4.727710843373494e-06,
      "loss": 0.0437,
      "step": 63380
    },
    {
      "epoch": 7.637349397590361,
      "grad_norm": 0.02152714692056179,
      "learning_rate": 4.725301204819277e-06,
      "loss": 0.0082,
      "step": 63390
    },
    {
      "epoch": 7.63855421686747,
      "grad_norm": 0.12094005942344666,
      "learning_rate": 4.7228915662650606e-06,
      "loss": 0.0309,
      "step": 63400
    },
    {
      "epoch": 7.639759036144579,
      "grad_norm": 0.22753629088401794,
      "learning_rate": 4.720481927710844e-06,
      "loss": 0.0155,
      "step": 63410
    },
    {
      "epoch": 7.6409638554216865,
      "grad_norm": 0.001085171359591186,
      "learning_rate": 4.718072289156627e-06,
      "loss": 0.0063,
      "step": 63420
    },
    {
      "epoch": 7.642168674698795,
      "grad_norm": 0.0017678928561508656,
      "learning_rate": 4.71566265060241e-06,
      "loss": 0.0155,
      "step": 63430
    },
    {
      "epoch": 7.643373493975903,
      "grad_norm": 4.995532512664795,
      "learning_rate": 4.713253012048193e-06,
      "loss": 0.0125,
      "step": 63440
    },
    {
      "epoch": 7.644578313253012,
      "grad_norm": 0.0005291441339068115,
      "learning_rate": 4.7108433734939764e-06,
      "loss": 0.0059,
      "step": 63450
    },
    {
      "epoch": 7.64578313253012,
      "grad_norm": 0.3226868510246277,
      "learning_rate": 4.70843373493976e-06,
      "loss": 0.0182,
      "step": 63460
    },
    {
      "epoch": 7.646987951807229,
      "grad_norm": 0.000617331126704812,
      "learning_rate": 4.706024096385543e-06,
      "loss": 0.0053,
      "step": 63470
    },
    {
      "epoch": 7.648192771084338,
      "grad_norm": 0.001440097694285214,
      "learning_rate": 4.703614457831326e-06,
      "loss": 0.0168,
      "step": 63480
    },
    {
      "epoch": 7.6493975903614455,
      "grad_norm": 0.002469034167006612,
      "learning_rate": 4.701204819277108e-06,
      "loss": 0.0389,
      "step": 63490
    },
    {
      "epoch": 7.650602409638554,
      "grad_norm": 0.003072912571951747,
      "learning_rate": 4.698795180722892e-06,
      "loss": 0.0156,
      "step": 63500
    },
    {
      "epoch": 7.651807228915663,
      "grad_norm": 0.002208723220974207,
      "learning_rate": 4.696385542168675e-06,
      "loss": 0.0046,
      "step": 63510
    },
    {
      "epoch": 7.653012048192771,
      "grad_norm": 1.0598846673965454,
      "learning_rate": 4.693975903614459e-06,
      "loss": 0.0198,
      "step": 63520
    },
    {
      "epoch": 7.65421686746988,
      "grad_norm": 0.0008024676353670657,
      "learning_rate": 4.691566265060241e-06,
      "loss": 0.0262,
      "step": 63530
    },
    {
      "epoch": 7.655421686746988,
      "grad_norm": 0.22732776403427124,
      "learning_rate": 4.689156626506024e-06,
      "loss": 0.0076,
      "step": 63540
    },
    {
      "epoch": 7.656626506024097,
      "grad_norm": 0.0191471166908741,
      "learning_rate": 4.686746987951807e-06,
      "loss": 0.0038,
      "step": 63550
    },
    {
      "epoch": 7.6578313253012045,
      "grad_norm": 1.109250783920288,
      "learning_rate": 4.6843373493975905e-06,
      "loss": 0.0157,
      "step": 63560
    },
    {
      "epoch": 7.659036144578313,
      "grad_norm": 0.025959642603993416,
      "learning_rate": 4.681927710843374e-06,
      "loss": 0.0208,
      "step": 63570
    },
    {
      "epoch": 7.660240963855422,
      "grad_norm": 0.0028966625686734915,
      "learning_rate": 4.679518072289157e-06,
      "loss": 0.0056,
      "step": 63580
    },
    {
      "epoch": 7.66144578313253,
      "grad_norm": 0.011780887842178345,
      "learning_rate": 4.67710843373494e-06,
      "loss": 0.0037,
      "step": 63590
    },
    {
      "epoch": 7.662650602409639,
      "grad_norm": 0.0003597194154281169,
      "learning_rate": 4.674698795180723e-06,
      "loss": 0.04,
      "step": 63600
    },
    {
      "epoch": 7.663855421686747,
      "grad_norm": 0.4572415351867676,
      "learning_rate": 4.672289156626506e-06,
      "loss": 0.0055,
      "step": 63610
    },
    {
      "epoch": 7.6650602409638555,
      "grad_norm": 0.000791718834079802,
      "learning_rate": 4.66987951807229e-06,
      "loss": 0.0053,
      "step": 63620
    },
    {
      "epoch": 7.666265060240963,
      "grad_norm": 0.16674399375915527,
      "learning_rate": 4.667469879518073e-06,
      "loss": 0.0281,
      "step": 63630
    },
    {
      "epoch": 7.667469879518072,
      "grad_norm": 2.587013006210327,
      "learning_rate": 4.665060240963856e-06,
      "loss": 0.02,
      "step": 63640
    },
    {
      "epoch": 7.668674698795181,
      "grad_norm": 0.03880494460463524,
      "learning_rate": 4.662650602409639e-06,
      "loss": 0.0016,
      "step": 63650
    },
    {
      "epoch": 7.669879518072289,
      "grad_norm": 2.322227954864502,
      "learning_rate": 4.660240963855422e-06,
      "loss": 0.0138,
      "step": 63660
    },
    {
      "epoch": 7.671084337349398,
      "grad_norm": 0.0006175365997478366,
      "learning_rate": 4.6578313253012055e-06,
      "loss": 0.0118,
      "step": 63670
    },
    {
      "epoch": 7.672289156626506,
      "grad_norm": 3.0317981243133545,
      "learning_rate": 4.655421686746988e-06,
      "loss": 0.0345,
      "step": 63680
    },
    {
      "epoch": 7.6734939759036145,
      "grad_norm": 0.02286999486386776,
      "learning_rate": 4.653012048192772e-06,
      "loss": 0.0009,
      "step": 63690
    },
    {
      "epoch": 7.674698795180722,
      "grad_norm": 0.10686985403299332,
      "learning_rate": 4.650602409638554e-06,
      "loss": 0.0121,
      "step": 63700
    },
    {
      "epoch": 7.675903614457831,
      "grad_norm": 2.8971357345581055,
      "learning_rate": 4.648192771084337e-06,
      "loss": 0.0363,
      "step": 63710
    },
    {
      "epoch": 7.67710843373494,
      "grad_norm": 0.0004302128218114376,
      "learning_rate": 4.6457831325301205e-06,
      "loss": 0.006,
      "step": 63720
    },
    {
      "epoch": 7.678313253012048,
      "grad_norm": 0.0007945749675855041,
      "learning_rate": 4.643373493975904e-06,
      "loss": 0.007,
      "step": 63730
    },
    {
      "epoch": 7.679518072289157,
      "grad_norm": 0.0008088864851742983,
      "learning_rate": 4.640963855421688e-06,
      "loss": 0.0004,
      "step": 63740
    },
    {
      "epoch": 7.6807228915662655,
      "grad_norm": 0.0003994244325440377,
      "learning_rate": 4.63855421686747e-06,
      "loss": 0.0009,
      "step": 63750
    },
    {
      "epoch": 7.6819277108433734,
      "grad_norm": 0.11043868958950043,
      "learning_rate": 4.636144578313253e-06,
      "loss": 0.005,
      "step": 63760
    },
    {
      "epoch": 7.683132530120482,
      "grad_norm": 0.0006625467794947326,
      "learning_rate": 4.633734939759036e-06,
      "loss": 0.0075,
      "step": 63770
    },
    {
      "epoch": 7.68433734939759,
      "grad_norm": 0.0009205473470501602,
      "learning_rate": 4.6313253012048196e-06,
      "loss": 0.0044,
      "step": 63780
    },
    {
      "epoch": 7.685542168674699,
      "grad_norm": 0.001092796796001494,
      "learning_rate": 4.628915662650603e-06,
      "loss": 0.0291,
      "step": 63790
    },
    {
      "epoch": 7.686746987951807,
      "grad_norm": 0.00045440508984029293,
      "learning_rate": 4.626506024096386e-06,
      "loss": 0.0179,
      "step": 63800
    },
    {
      "epoch": 7.687951807228916,
      "grad_norm": 8.733078956604004,
      "learning_rate": 4.624096385542169e-06,
      "loss": 0.0542,
      "step": 63810
    },
    {
      "epoch": 7.6891566265060245,
      "grad_norm": 0.623153805732727,
      "learning_rate": 4.621686746987952e-06,
      "loss": 0.0019,
      "step": 63820
    },
    {
      "epoch": 7.690361445783132,
      "grad_norm": 0.9139437079429626,
      "learning_rate": 4.6192771084337354e-06,
      "loss": 0.0134,
      "step": 63830
    },
    {
      "epoch": 7.691566265060241,
      "grad_norm": 1.124482274055481,
      "learning_rate": 4.616867469879519e-06,
      "loss": 0.0294,
      "step": 63840
    },
    {
      "epoch": 7.692771084337349,
      "grad_norm": 0.8439182639122009,
      "learning_rate": 4.614457831325301e-06,
      "loss": 0.0488,
      "step": 63850
    },
    {
      "epoch": 7.693975903614458,
      "grad_norm": 2.0279908180236816,
      "learning_rate": 4.612048192771085e-06,
      "loss": 0.0116,
      "step": 63860
    },
    {
      "epoch": 7.695180722891566,
      "grad_norm": 0.009132824838161469,
      "learning_rate": 4.609638554216868e-06,
      "loss": 0.0199,
      "step": 63870
    },
    {
      "epoch": 7.696385542168675,
      "grad_norm": 0.0019506595563143492,
      "learning_rate": 4.607228915662651e-06,
      "loss": 0.0154,
      "step": 63880
    },
    {
      "epoch": 7.6975903614457835,
      "grad_norm": 0.0012817612150684,
      "learning_rate": 4.6048192771084345e-06,
      "loss": 0.0083,
      "step": 63890
    },
    {
      "epoch": 7.698795180722891,
      "grad_norm": 1.1563324928283691,
      "learning_rate": 4.602409638554217e-06,
      "loss": 0.0155,
      "step": 63900
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.0005615263944491744,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.0297,
      "step": 63910
    },
    {
      "epoch": 7.701204819277108,
      "grad_norm": 0.9203133583068848,
      "learning_rate": 4.597590361445783e-06,
      "loss": 0.0056,
      "step": 63920
    },
    {
      "epoch": 7.702409638554217,
      "grad_norm": 0.17303065955638885,
      "learning_rate": 4.595180722891567e-06,
      "loss": 0.0264,
      "step": 63930
    },
    {
      "epoch": 7.703614457831325,
      "grad_norm": 0.0036149686202406883,
      "learning_rate": 4.5927710843373495e-06,
      "loss": 0.0333,
      "step": 63940
    },
    {
      "epoch": 7.704819277108434,
      "grad_norm": 0.0006448024651035666,
      "learning_rate": 4.590361445783133e-06,
      "loss": 0.0166,
      "step": 63950
    },
    {
      "epoch": 7.706024096385542,
      "grad_norm": 0.0009066169150173664,
      "learning_rate": 4.587951807228916e-06,
      "loss": 0.0108,
      "step": 63960
    },
    {
      "epoch": 7.70722891566265,
      "grad_norm": 0.0318937674164772,
      "learning_rate": 4.585542168674699e-06,
      "loss": 0.0226,
      "step": 63970
    },
    {
      "epoch": 7.708433734939759,
      "grad_norm": 0.00046456523705273867,
      "learning_rate": 4.583132530120482e-06,
      "loss": 0.0089,
      "step": 63980
    },
    {
      "epoch": 7.709638554216868,
      "grad_norm": 0.0003583599755074829,
      "learning_rate": 4.580722891566265e-06,
      "loss": 0.0094,
      "step": 63990
    },
    {
      "epoch": 7.710843373493976,
      "grad_norm": 0.557938814163208,
      "learning_rate": 4.578313253012049e-06,
      "loss": 0.02,
      "step": 64000
    },
    {
      "epoch": 7.712048192771085,
      "grad_norm": 0.0012075923150405288,
      "learning_rate": 4.575903614457832e-06,
      "loss": 0.0295,
      "step": 64010
    },
    {
      "epoch": 7.713253012048193,
      "grad_norm": 0.00045532998046837747,
      "learning_rate": 4.573493975903615e-06,
      "loss": 0.0137,
      "step": 64020
    },
    {
      "epoch": 7.714457831325301,
      "grad_norm": 0.0008731394773349166,
      "learning_rate": 4.571084337349398e-06,
      "loss": 0.011,
      "step": 64030
    },
    {
      "epoch": 7.715662650602409,
      "grad_norm": 0.0009668372222222388,
      "learning_rate": 4.568674698795181e-06,
      "loss": 0.0126,
      "step": 64040
    },
    {
      "epoch": 7.716867469879518,
      "grad_norm": 1.348546028137207,
      "learning_rate": 4.5662650602409645e-06,
      "loss": 0.0079,
      "step": 64050
    },
    {
      "epoch": 7.718072289156627,
      "grad_norm": 1.135235071182251,
      "learning_rate": 4.563855421686748e-06,
      "loss": 0.0248,
      "step": 64060
    },
    {
      "epoch": 7.719277108433735,
      "grad_norm": 0.0005281188641674817,
      "learning_rate": 4.56144578313253e-06,
      "loss": 0.0149,
      "step": 64070
    },
    {
      "epoch": 7.720481927710844,
      "grad_norm": 0.7293432354927063,
      "learning_rate": 4.559036144578314e-06,
      "loss": 0.031,
      "step": 64080
    },
    {
      "epoch": 7.7216867469879515,
      "grad_norm": 0.22550144791603088,
      "learning_rate": 4.556626506024096e-06,
      "loss": 0.0031,
      "step": 64090
    },
    {
      "epoch": 7.72289156626506,
      "grad_norm": 0.0018594978610053658,
      "learning_rate": 4.55421686746988e-06,
      "loss": 0.0064,
      "step": 64100
    },
    {
      "epoch": 7.724096385542168,
      "grad_norm": 0.005684496369212866,
      "learning_rate": 4.551807228915663e-06,
      "loss": 0.0309,
      "step": 64110
    },
    {
      "epoch": 7.725301204819277,
      "grad_norm": 0.3614085614681244,
      "learning_rate": 4.549397590361446e-06,
      "loss": 0.0025,
      "step": 64120
    },
    {
      "epoch": 7.726506024096386,
      "grad_norm": 0.0007602612022310495,
      "learning_rate": 4.546987951807229e-06,
      "loss": 0.0406,
      "step": 64130
    },
    {
      "epoch": 7.727710843373494,
      "grad_norm": 0.023515740409493446,
      "learning_rate": 4.544578313253012e-06,
      "loss": 0.0263,
      "step": 64140
    },
    {
      "epoch": 7.728915662650603,
      "grad_norm": 1.5141148567199707,
      "learning_rate": 4.542168674698795e-06,
      "loss": 0.0142,
      "step": 64150
    },
    {
      "epoch": 7.7301204819277105,
      "grad_norm": 0.001040326664224267,
      "learning_rate": 4.5397590361445786e-06,
      "loss": 0.0088,
      "step": 64160
    },
    {
      "epoch": 7.731325301204819,
      "grad_norm": 0.0005911815678700805,
      "learning_rate": 4.537349397590362e-06,
      "loss": 0.0036,
      "step": 64170
    },
    {
      "epoch": 7.732530120481927,
      "grad_norm": 0.0035254904069006443,
      "learning_rate": 4.534939759036145e-06,
      "loss": 0.0095,
      "step": 64180
    },
    {
      "epoch": 7.733734939759036,
      "grad_norm": 0.0009752620826475322,
      "learning_rate": 4.532530120481928e-06,
      "loss": 0.0109,
      "step": 64190
    },
    {
      "epoch": 7.734939759036145,
      "grad_norm": 0.000515962834469974,
      "learning_rate": 4.530120481927711e-06,
      "loss": 0.0089,
      "step": 64200
    },
    {
      "epoch": 7.736144578313253,
      "grad_norm": 3.0729050636291504,
      "learning_rate": 4.5277108433734944e-06,
      "loss": 0.0341,
      "step": 64210
    },
    {
      "epoch": 7.7373493975903616,
      "grad_norm": 0.00047949908184818923,
      "learning_rate": 4.525301204819278e-06,
      "loss": 0.008,
      "step": 64220
    },
    {
      "epoch": 7.73855421686747,
      "grad_norm": 1.4990299940109253,
      "learning_rate": 4.522891566265061e-06,
      "loss": 0.0323,
      "step": 64230
    },
    {
      "epoch": 7.739759036144578,
      "grad_norm": 0.0013362328754737973,
      "learning_rate": 4.520481927710844e-06,
      "loss": 0.0147,
      "step": 64240
    },
    {
      "epoch": 7.740963855421687,
      "grad_norm": 1.1267101764678955,
      "learning_rate": 4.518072289156627e-06,
      "loss": 0.0056,
      "step": 64250
    },
    {
      "epoch": 7.742168674698795,
      "grad_norm": 0.0005138640990480781,
      "learning_rate": 4.5156626506024095e-06,
      "loss": 0.0053,
      "step": 64260
    },
    {
      "epoch": 7.743373493975904,
      "grad_norm": 0.010585140436887741,
      "learning_rate": 4.5132530120481935e-06,
      "loss": 0.0295,
      "step": 64270
    },
    {
      "epoch": 7.744578313253012,
      "grad_norm": 1.014863133430481,
      "learning_rate": 4.510843373493976e-06,
      "loss": 0.0258,
      "step": 64280
    },
    {
      "epoch": 7.7457831325301205,
      "grad_norm": 1.3197423219680786,
      "learning_rate": 4.50843373493976e-06,
      "loss": 0.0105,
      "step": 64290
    },
    {
      "epoch": 7.746987951807229,
      "grad_norm": 0.015187370590865612,
      "learning_rate": 4.506024096385542e-06,
      "loss": 0.0106,
      "step": 64300
    },
    {
      "epoch": 7.748192771084337,
      "grad_norm": 0.0005676228320226073,
      "learning_rate": 4.503614457831325e-06,
      "loss": 0.0204,
      "step": 64310
    },
    {
      "epoch": 7.749397590361446,
      "grad_norm": 0.0010990664595738053,
      "learning_rate": 4.501204819277109e-06,
      "loss": 0.0115,
      "step": 64320
    },
    {
      "epoch": 7.750602409638554,
      "grad_norm": 0.0005661306204274297,
      "learning_rate": 4.498795180722892e-06,
      "loss": 0.0275,
      "step": 64330
    },
    {
      "epoch": 7.751807228915663,
      "grad_norm": 0.017988186329603195,
      "learning_rate": 4.496385542168675e-06,
      "loss": 0.0061,
      "step": 64340
    },
    {
      "epoch": 7.753012048192771,
      "grad_norm": 0.0009000245481729507,
      "learning_rate": 4.493975903614458e-06,
      "loss": 0.0102,
      "step": 64350
    },
    {
      "epoch": 7.7542168674698795,
      "grad_norm": 0.00046679176739417017,
      "learning_rate": 4.491566265060241e-06,
      "loss": 0.0146,
      "step": 64360
    },
    {
      "epoch": 7.755421686746988,
      "grad_norm": 0.00462634302675724,
      "learning_rate": 4.489156626506024e-06,
      "loss": 0.0175,
      "step": 64370
    },
    {
      "epoch": 7.756626506024096,
      "grad_norm": 0.003081254195421934,
      "learning_rate": 4.486746987951808e-06,
      "loss": 0.0225,
      "step": 64380
    },
    {
      "epoch": 7.757831325301205,
      "grad_norm": 0.00038643545121885836,
      "learning_rate": 4.484337349397591e-06,
      "loss": 0.0115,
      "step": 64390
    },
    {
      "epoch": 7.759036144578313,
      "grad_norm": 0.0009614917216822505,
      "learning_rate": 4.481927710843374e-06,
      "loss": 0.0175,
      "step": 64400
    },
    {
      "epoch": 7.760240963855422,
      "grad_norm": 2.1129136085510254,
      "learning_rate": 4.479518072289157e-06,
      "loss": 0.0274,
      "step": 64410
    },
    {
      "epoch": 7.76144578313253,
      "grad_norm": 0.001143885776400566,
      "learning_rate": 4.47710843373494e-06,
      "loss": 0.0203,
      "step": 64420
    },
    {
      "epoch": 7.7626506024096384,
      "grad_norm": 1.4930016994476318,
      "learning_rate": 4.474698795180723e-06,
      "loss": 0.0086,
      "step": 64430
    },
    {
      "epoch": 7.763855421686747,
      "grad_norm": 1.4753450155258179,
      "learning_rate": 4.472289156626507e-06,
      "loss": 0.0162,
      "step": 64440
    },
    {
      "epoch": 7.765060240963855,
      "grad_norm": 0.0013913928996771574,
      "learning_rate": 4.469879518072289e-06,
      "loss": 0.005,
      "step": 64450
    },
    {
      "epoch": 7.766265060240964,
      "grad_norm": 38.49456024169922,
      "learning_rate": 4.467469879518073e-06,
      "loss": 0.0145,
      "step": 64460
    },
    {
      "epoch": 7.767469879518073,
      "grad_norm": 0.0041570113971829414,
      "learning_rate": 4.465060240963856e-06,
      "loss": 0.0276,
      "step": 64470
    },
    {
      "epoch": 7.768674698795181,
      "grad_norm": 0.01668437011539936,
      "learning_rate": 4.4626506024096385e-06,
      "loss": 0.0089,
      "step": 64480
    },
    {
      "epoch": 7.7698795180722895,
      "grad_norm": 0.7706280946731567,
      "learning_rate": 4.4602409638554225e-06,
      "loss": 0.0475,
      "step": 64490
    },
    {
      "epoch": 7.771084337349397,
      "grad_norm": 0.01653553731739521,
      "learning_rate": 4.457831325301205e-06,
      "loss": 0.0307,
      "step": 64500
    },
    {
      "epoch": 7.772289156626506,
      "grad_norm": 2.4540698528289795,
      "learning_rate": 4.455421686746989e-06,
      "loss": 0.0206,
      "step": 64510
    },
    {
      "epoch": 7.773493975903614,
      "grad_norm": 0.04726741835474968,
      "learning_rate": 4.453012048192771e-06,
      "loss": 0.0131,
      "step": 64520
    },
    {
      "epoch": 7.774698795180723,
      "grad_norm": 0.0012828459730371833,
      "learning_rate": 4.450602409638554e-06,
      "loss": 0.0072,
      "step": 64530
    },
    {
      "epoch": 7.775903614457832,
      "grad_norm": 0.011636998504400253,
      "learning_rate": 4.4481927710843376e-06,
      "loss": 0.0076,
      "step": 64540
    },
    {
      "epoch": 7.77710843373494,
      "grad_norm": 0.0007154743070714176,
      "learning_rate": 4.445783132530121e-06,
      "loss": 0.0292,
      "step": 64550
    },
    {
      "epoch": 7.7783132530120485,
      "grad_norm": 0.001667318749241531,
      "learning_rate": 4.443373493975904e-06,
      "loss": 0.0519,
      "step": 64560
    },
    {
      "epoch": 7.779518072289156,
      "grad_norm": 0.0029290018137544394,
      "learning_rate": 4.440963855421687e-06,
      "loss": 0.007,
      "step": 64570
    },
    {
      "epoch": 7.780722891566265,
      "grad_norm": 1.7197339534759521,
      "learning_rate": 4.43855421686747e-06,
      "loss": 0.0176,
      "step": 64580
    },
    {
      "epoch": 7.781927710843373,
      "grad_norm": 1.7790353298187256,
      "learning_rate": 4.4361445783132534e-06,
      "loss": 0.0017,
      "step": 64590
    },
    {
      "epoch": 7.783132530120482,
      "grad_norm": 0.0013294682139530778,
      "learning_rate": 4.433734939759037e-06,
      "loss": 0.0463,
      "step": 64600
    },
    {
      "epoch": 7.784337349397591,
      "grad_norm": 0.003505167318508029,
      "learning_rate": 4.43132530120482e-06,
      "loss": 0.0043,
      "step": 64610
    },
    {
      "epoch": 7.785542168674699,
      "grad_norm": 0.0016858639428392053,
      "learning_rate": 4.428915662650603e-06,
      "loss": 0.0077,
      "step": 64620
    },
    {
      "epoch": 7.786746987951807,
      "grad_norm": 0.0008094222866930068,
      "learning_rate": 4.426506024096386e-06,
      "loss": 0.0038,
      "step": 64630
    },
    {
      "epoch": 7.787951807228915,
      "grad_norm": 0.0007847319939173758,
      "learning_rate": 4.424096385542169e-06,
      "loss": 0.0014,
      "step": 64640
    },
    {
      "epoch": 7.789156626506024,
      "grad_norm": 0.02589418925344944,
      "learning_rate": 4.4216867469879525e-06,
      "loss": 0.0142,
      "step": 64650
    },
    {
      "epoch": 7.790361445783132,
      "grad_norm": 16.89617919921875,
      "learning_rate": 4.419277108433736e-06,
      "loss": 0.0016,
      "step": 64660
    },
    {
      "epoch": 7.791566265060241,
      "grad_norm": 0.7188205122947693,
      "learning_rate": 4.416867469879518e-06,
      "loss": 0.0038,
      "step": 64670
    },
    {
      "epoch": 7.79277108433735,
      "grad_norm": 0.0012542129261419177,
      "learning_rate": 4.414457831325302e-06,
      "loss": 0.0129,
      "step": 64680
    },
    {
      "epoch": 7.793975903614458,
      "grad_norm": 0.0006744559505023062,
      "learning_rate": 4.412048192771084e-06,
      "loss": 0.0018,
      "step": 64690
    },
    {
      "epoch": 7.795180722891566,
      "grad_norm": 0.0008652316173538566,
      "learning_rate": 4.4096385542168675e-06,
      "loss": 0.002,
      "step": 64700
    },
    {
      "epoch": 7.796385542168675,
      "grad_norm": 4.32925271987915,
      "learning_rate": 4.407228915662651e-06,
      "loss": 0.0139,
      "step": 64710
    },
    {
      "epoch": 7.797590361445783,
      "grad_norm": 0.022791879251599312,
      "learning_rate": 4.404819277108434e-06,
      "loss": 0.0475,
      "step": 64720
    },
    {
      "epoch": 7.798795180722892,
      "grad_norm": 2.031292200088501,
      "learning_rate": 4.402409638554217e-06,
      "loss": 0.0292,
      "step": 64730
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.9173572659492493,
      "learning_rate": 4.4e-06,
      "loss": 0.0112,
      "step": 64740
    },
    {
      "epoch": 7.801204819277109,
      "grad_norm": 0.04810430109500885,
      "learning_rate": 4.397590361445783e-06,
      "loss": 0.0211,
      "step": 64750
    },
    {
      "epoch": 7.8024096385542165,
      "grad_norm": 1.2938923835754395,
      "learning_rate": 4.3951807228915666e-06,
      "loss": 0.0087,
      "step": 64760
    },
    {
      "epoch": 7.803614457831325,
      "grad_norm": 0.0008433643961325288,
      "learning_rate": 4.39277108433735e-06,
      "loss": 0.0253,
      "step": 64770
    },
    {
      "epoch": 7.804819277108434,
      "grad_norm": 2.107024908065796,
      "learning_rate": 4.390361445783133e-06,
      "loss": 0.0271,
      "step": 64780
    },
    {
      "epoch": 7.806024096385542,
      "grad_norm": 0.0015620640479028225,
      "learning_rate": 4.387951807228916e-06,
      "loss": 0.0278,
      "step": 64790
    },
    {
      "epoch": 7.807228915662651,
      "grad_norm": 1.7665674686431885,
      "learning_rate": 4.385542168674699e-06,
      "loss": 0.0145,
      "step": 64800
    },
    {
      "epoch": 7.808433734939759,
      "grad_norm": 3.1277658939361572,
      "learning_rate": 4.3831325301204825e-06,
      "loss": 0.0171,
      "step": 64810
    },
    {
      "epoch": 7.809638554216868,
      "grad_norm": 17.52591323852539,
      "learning_rate": 4.380722891566266e-06,
      "loss": 0.0804,
      "step": 64820
    },
    {
      "epoch": 7.8108433734939755,
      "grad_norm": 0.0010083711240440607,
      "learning_rate": 4.378313253012049e-06,
      "loss": 0.0073,
      "step": 64830
    },
    {
      "epoch": 7.812048192771084,
      "grad_norm": 0.018974225968122482,
      "learning_rate": 4.375903614457831e-06,
      "loss": 0.0202,
      "step": 64840
    },
    {
      "epoch": 7.813253012048193,
      "grad_norm": 0.009404410608112812,
      "learning_rate": 4.373493975903615e-06,
      "loss": 0.013,
      "step": 64850
    },
    {
      "epoch": 7.814457831325301,
      "grad_norm": 0.5306078195571899,
      "learning_rate": 4.3710843373493975e-06,
      "loss": 0.0077,
      "step": 64860
    },
    {
      "epoch": 7.81566265060241,
      "grad_norm": 0.61440110206604,
      "learning_rate": 4.3686746987951815e-06,
      "loss": 0.0227,
      "step": 64870
    },
    {
      "epoch": 7.816867469879518,
      "grad_norm": 0.04983183741569519,
      "learning_rate": 4.366265060240964e-06,
      "loss": 0.0162,
      "step": 64880
    },
    {
      "epoch": 7.8180722891566266,
      "grad_norm": 0.0018375978106632829,
      "learning_rate": 4.363855421686747e-06,
      "loss": 0.0195,
      "step": 64890
    },
    {
      "epoch": 7.8192771084337345,
      "grad_norm": 0.17841234803199768,
      "learning_rate": 4.361445783132531e-06,
      "loss": 0.0115,
      "step": 64900
    },
    {
      "epoch": 7.820481927710843,
      "grad_norm": 3.6934640407562256,
      "learning_rate": 4.359036144578313e-06,
      "loss": 0.0253,
      "step": 64910
    },
    {
      "epoch": 7.821686746987952,
      "grad_norm": 0.0009503097971901298,
      "learning_rate": 4.356626506024097e-06,
      "loss": 0.0268,
      "step": 64920
    },
    {
      "epoch": 7.82289156626506,
      "grad_norm": 0.017335187643766403,
      "learning_rate": 4.35421686746988e-06,
      "loss": 0.0154,
      "step": 64930
    },
    {
      "epoch": 7.824096385542169,
      "grad_norm": 1.369874358177185,
      "learning_rate": 4.351807228915663e-06,
      "loss": 0.0283,
      "step": 64940
    },
    {
      "epoch": 7.825301204819278,
      "grad_norm": 1.3885462284088135,
      "learning_rate": 4.349397590361446e-06,
      "loss": 0.0138,
      "step": 64950
    },
    {
      "epoch": 7.8265060240963855,
      "grad_norm": 0.004280178342014551,
      "learning_rate": 4.346987951807229e-06,
      "loss": 0.0131,
      "step": 64960
    },
    {
      "epoch": 7.827710843373494,
      "grad_norm": 1.0437605381011963,
      "learning_rate": 4.3445783132530124e-06,
      "loss": 0.0102,
      "step": 64970
    },
    {
      "epoch": 7.828915662650602,
      "grad_norm": 0.0016761281294748187,
      "learning_rate": 4.342168674698796e-06,
      "loss": 0.009,
      "step": 64980
    },
    {
      "epoch": 7.830120481927711,
      "grad_norm": 0.10464773327112198,
      "learning_rate": 4.339759036144579e-06,
      "loss": 0.0091,
      "step": 64990
    },
    {
      "epoch": 7.831325301204819,
      "grad_norm": 2.9621407985687256,
      "learning_rate": 4.337349397590362e-06,
      "loss": 0.0234,
      "step": 65000
    },
    {
      "epoch": 7.832530120481928,
      "grad_norm": 0.0006837766850367188,
      "learning_rate": 4.334939759036145e-06,
      "loss": 0.0056,
      "step": 65010
    },
    {
      "epoch": 7.833734939759037,
      "grad_norm": 0.6834718585014343,
      "learning_rate": 4.332530120481928e-06,
      "loss": 0.0024,
      "step": 65020
    },
    {
      "epoch": 7.8349397590361445,
      "grad_norm": 0.8891929984092712,
      "learning_rate": 4.330120481927711e-06,
      "loss": 0.0135,
      "step": 65030
    },
    {
      "epoch": 7.836144578313253,
      "grad_norm": 0.003691145684570074,
      "learning_rate": 4.327710843373495e-06,
      "loss": 0.0094,
      "step": 65040
    },
    {
      "epoch": 7.837349397590361,
      "grad_norm": 0.934387743473053,
      "learning_rate": 4.325301204819278e-06,
      "loss": 0.017,
      "step": 65050
    },
    {
      "epoch": 7.83855421686747,
      "grad_norm": 0.0020868449937552214,
      "learning_rate": 4.32289156626506e-06,
      "loss": 0.0429,
      "step": 65060
    },
    {
      "epoch": 7.839759036144578,
      "grad_norm": 1.1046602725982666,
      "learning_rate": 4.320481927710844e-06,
      "loss": 0.0207,
      "step": 65070
    },
    {
      "epoch": 7.840963855421687,
      "grad_norm": 0.0012330510653555393,
      "learning_rate": 4.3180722891566265e-06,
      "loss": 0.0295,
      "step": 65080
    },
    {
      "epoch": 7.8421686746987955,
      "grad_norm": 0.19391246140003204,
      "learning_rate": 4.3156626506024105e-06,
      "loss": 0.0168,
      "step": 65090
    },
    {
      "epoch": 7.843373493975903,
      "grad_norm": 0.012410671450197697,
      "learning_rate": 4.313253012048193e-06,
      "loss": 0.0288,
      "step": 65100
    },
    {
      "epoch": 7.844578313253012,
      "grad_norm": 10.462864875793457,
      "learning_rate": 4.310843373493976e-06,
      "loss": 0.0242,
      "step": 65110
    },
    {
      "epoch": 7.84578313253012,
      "grad_norm": 0.004774642176926136,
      "learning_rate": 4.308433734939759e-06,
      "loss": 0.001,
      "step": 65120
    },
    {
      "epoch": 7.846987951807229,
      "grad_norm": 10.975170135498047,
      "learning_rate": 4.306024096385542e-06,
      "loss": 0.0115,
      "step": 65130
    },
    {
      "epoch": 7.848192771084337,
      "grad_norm": 0.0006530627142637968,
      "learning_rate": 4.3036144578313256e-06,
      "loss": 0.0038,
      "step": 65140
    },
    {
      "epoch": 7.849397590361446,
      "grad_norm": 1.015792727470398,
      "learning_rate": 4.301204819277109e-06,
      "loss": 0.0209,
      "step": 65150
    },
    {
      "epoch": 7.8506024096385545,
      "grad_norm": 1.1053366661071777,
      "learning_rate": 4.298795180722892e-06,
      "loss": 0.0148,
      "step": 65160
    },
    {
      "epoch": 7.851807228915662,
      "grad_norm": 0.0028068250976502895,
      "learning_rate": 4.296385542168675e-06,
      "loss": 0.0072,
      "step": 65170
    },
    {
      "epoch": 7.853012048192771,
      "grad_norm": 0.269883394241333,
      "learning_rate": 4.293975903614458e-06,
      "loss": 0.0119,
      "step": 65180
    },
    {
      "epoch": 7.85421686746988,
      "grad_norm": 0.20686322450637817,
      "learning_rate": 4.2915662650602415e-06,
      "loss": 0.0236,
      "step": 65190
    },
    {
      "epoch": 7.855421686746988,
      "grad_norm": 1.4785778522491455,
      "learning_rate": 4.289156626506025e-06,
      "loss": 0.0266,
      "step": 65200
    },
    {
      "epoch": 7.856626506024097,
      "grad_norm": 2.5253987312316895,
      "learning_rate": 4.286746987951808e-06,
      "loss": 0.0161,
      "step": 65210
    },
    {
      "epoch": 7.857831325301205,
      "grad_norm": 0.0005160686559975147,
      "learning_rate": 4.284337349397591e-06,
      "loss": 0.0441,
      "step": 65220
    },
    {
      "epoch": 7.8590361445783135,
      "grad_norm": 0.019358491525053978,
      "learning_rate": 4.281927710843374e-06,
      "loss": 0.0106,
      "step": 65230
    },
    {
      "epoch": 7.860240963855421,
      "grad_norm": 0.4260628819465637,
      "learning_rate": 4.279518072289157e-06,
      "loss": 0.0299,
      "step": 65240
    },
    {
      "epoch": 7.86144578313253,
      "grad_norm": 11.234046936035156,
      "learning_rate": 4.27710843373494e-06,
      "loss": 0.0386,
      "step": 65250
    },
    {
      "epoch": 7.862650602409639,
      "grad_norm": 2.138916254043579,
      "learning_rate": 4.274698795180724e-06,
      "loss": 0.0243,
      "step": 65260
    },
    {
      "epoch": 7.863855421686747,
      "grad_norm": 1.3404219150543213,
      "learning_rate": 4.272289156626506e-06,
      "loss": 0.0065,
      "step": 65270
    },
    {
      "epoch": 7.865060240963856,
      "grad_norm": 0.0018789716996252537,
      "learning_rate": 4.26987951807229e-06,
      "loss": 0.0218,
      "step": 65280
    },
    {
      "epoch": 7.866265060240964,
      "grad_norm": 0.3931252062320709,
      "learning_rate": 4.267469879518072e-06,
      "loss": 0.0032,
      "step": 65290
    },
    {
      "epoch": 7.867469879518072,
      "grad_norm": 0.0025218871887773275,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.008,
      "step": 65300
    },
    {
      "epoch": 7.86867469879518,
      "grad_norm": 0.0022379036527127028,
      "learning_rate": 4.262650602409639e-06,
      "loss": 0.0137,
      "step": 65310
    },
    {
      "epoch": 7.869879518072289,
      "grad_norm": 0.06682995706796646,
      "learning_rate": 4.260240963855422e-06,
      "loss": 0.0187,
      "step": 65320
    },
    {
      "epoch": 7.871084337349398,
      "grad_norm": 0.00037856752169318497,
      "learning_rate": 4.257831325301205e-06,
      "loss": 0.0167,
      "step": 65330
    },
    {
      "epoch": 7.872289156626506,
      "grad_norm": 1.6130582094192505,
      "learning_rate": 4.255421686746988e-06,
      "loss": 0.0226,
      "step": 65340
    },
    {
      "epoch": 7.873493975903615,
      "grad_norm": 0.015489148907363415,
      "learning_rate": 4.253012048192771e-06,
      "loss": 0.0131,
      "step": 65350
    },
    {
      "epoch": 7.874698795180723,
      "grad_norm": 0.00044996177894063294,
      "learning_rate": 4.250602409638555e-06,
      "loss": 0.0301,
      "step": 65360
    },
    {
      "epoch": 7.875903614457831,
      "grad_norm": 0.0008445159764960408,
      "learning_rate": 4.248192771084338e-06,
      "loss": 0.0049,
      "step": 65370
    },
    {
      "epoch": 7.877108433734939,
      "grad_norm": 0.0006329024326987565,
      "learning_rate": 4.245783132530121e-06,
      "loss": 0.0201,
      "step": 65380
    },
    {
      "epoch": 7.878313253012048,
      "grad_norm": 13.672908782958984,
      "learning_rate": 4.243373493975904e-06,
      "loss": 0.0177,
      "step": 65390
    },
    {
      "epoch": 7.879518072289157,
      "grad_norm": 0.001257650787010789,
      "learning_rate": 4.240963855421687e-06,
      "loss": 0.0203,
      "step": 65400
    },
    {
      "epoch": 7.880722891566265,
      "grad_norm": 0.0005515668308362365,
      "learning_rate": 4.2385542168674705e-06,
      "loss": 0.007,
      "step": 65410
    },
    {
      "epoch": 7.881927710843374,
      "grad_norm": 0.03873992711305618,
      "learning_rate": 4.236144578313253e-06,
      "loss": 0.0103,
      "step": 65420
    },
    {
      "epoch": 7.8831325301204815,
      "grad_norm": 0.980780839920044,
      "learning_rate": 4.233734939759037e-06,
      "loss": 0.0081,
      "step": 65430
    },
    {
      "epoch": 7.88433734939759,
      "grad_norm": 0.018521493300795555,
      "learning_rate": 4.231325301204819e-06,
      "loss": 0.0067,
      "step": 65440
    },
    {
      "epoch": 7.885542168674699,
      "grad_norm": 0.0990220382809639,
      "learning_rate": 4.228915662650603e-06,
      "loss": 0.0109,
      "step": 65450
    },
    {
      "epoch": 7.886746987951807,
      "grad_norm": 0.6789994835853577,
      "learning_rate": 4.2265060240963855e-06,
      "loss": 0.0099,
      "step": 65460
    },
    {
      "epoch": 7.887951807228916,
      "grad_norm": 0.0011886199936270714,
      "learning_rate": 4.224096385542169e-06,
      "loss": 0.0208,
      "step": 65470
    },
    {
      "epoch": 7.889156626506024,
      "grad_norm": 2.6626570224761963,
      "learning_rate": 4.221686746987952e-06,
      "loss": 0.0111,
      "step": 65480
    },
    {
      "epoch": 7.890361445783133,
      "grad_norm": 0.0030658189207315445,
      "learning_rate": 4.219277108433735e-06,
      "loss": 0.0137,
      "step": 65490
    },
    {
      "epoch": 7.891566265060241,
      "grad_norm": 0.0026650335639715195,
      "learning_rate": 4.216867469879519e-06,
      "loss": 0.0073,
      "step": 65500
    },
    {
      "epoch": 7.892771084337349,
      "grad_norm": 0.3697061538696289,
      "learning_rate": 4.214457831325301e-06,
      "loss": 0.0733,
      "step": 65510
    },
    {
      "epoch": 7.893975903614458,
      "grad_norm": 8.111724853515625,
      "learning_rate": 4.2120481927710846e-06,
      "loss": 0.0546,
      "step": 65520
    },
    {
      "epoch": 7.895180722891566,
      "grad_norm": 0.0006292923935689032,
      "learning_rate": 4.209638554216868e-06,
      "loss": 0.0269,
      "step": 65530
    },
    {
      "epoch": 7.896385542168675,
      "grad_norm": 1.4376167058944702,
      "learning_rate": 4.207228915662651e-06,
      "loss": 0.0308,
      "step": 65540
    },
    {
      "epoch": 7.897590361445783,
      "grad_norm": 1.819507122039795,
      "learning_rate": 4.204819277108434e-06,
      "loss": 0.0163,
      "step": 65550
    },
    {
      "epoch": 7.8987951807228916,
      "grad_norm": 0.0039949556812644005,
      "learning_rate": 4.202409638554217e-06,
      "loss": 0.0081,
      "step": 65560
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.34345752000808716,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0157,
      "step": 65570
    },
    {
      "epoch": 7.901204819277108,
      "grad_norm": 0.0007144334958866239,
      "learning_rate": 4.197590361445784e-06,
      "loss": 0.0104,
      "step": 65580
    },
    {
      "epoch": 7.902409638554217,
      "grad_norm": 1.6034445762634277,
      "learning_rate": 4.195180722891567e-06,
      "loss": 0.0427,
      "step": 65590
    },
    {
      "epoch": 7.903614457831325,
      "grad_norm": 0.009427486918866634,
      "learning_rate": 4.19277108433735e-06,
      "loss": 0.0303,
      "step": 65600
    },
    {
      "epoch": 7.904819277108434,
      "grad_norm": 0.37415754795074463,
      "learning_rate": 4.190361445783132e-06,
      "loss": 0.0149,
      "step": 65610
    },
    {
      "epoch": 7.906024096385542,
      "grad_norm": 2.5805346965789795,
      "learning_rate": 4.187951807228916e-06,
      "loss": 0.0266,
      "step": 65620
    },
    {
      "epoch": 7.9072289156626505,
      "grad_norm": 0.0007671128842048347,
      "learning_rate": 4.185542168674699e-06,
      "loss": 0.0199,
      "step": 65630
    },
    {
      "epoch": 7.908433734939759,
      "grad_norm": 0.56666499376297,
      "learning_rate": 4.183132530120483e-06,
      "loss": 0.0161,
      "step": 65640
    },
    {
      "epoch": 7.909638554216867,
      "grad_norm": 0.396314799785614,
      "learning_rate": 4.180722891566266e-06,
      "loss": 0.0009,
      "step": 65650
    },
    {
      "epoch": 7.910843373493976,
      "grad_norm": 0.0004865465161856264,
      "learning_rate": 4.178313253012048e-06,
      "loss": 0.0026,
      "step": 65660
    },
    {
      "epoch": 7.912048192771084,
      "grad_norm": 1.746350646018982,
      "learning_rate": 4.175903614457832e-06,
      "loss": 0.038,
      "step": 65670
    },
    {
      "epoch": 7.913253012048193,
      "grad_norm": 0.009819927625358105,
      "learning_rate": 4.1734939759036145e-06,
      "loss": 0.0013,
      "step": 65680
    },
    {
      "epoch": 7.914457831325302,
      "grad_norm": 0.0005225416389293969,
      "learning_rate": 4.171084337349398e-06,
      "loss": 0.0038,
      "step": 65690
    },
    {
      "epoch": 7.9156626506024095,
      "grad_norm": 2.083167552947998,
      "learning_rate": 4.168674698795181e-06,
      "loss": 0.0054,
      "step": 65700
    },
    {
      "epoch": 7.916867469879518,
      "grad_norm": 1.407142996788025,
      "learning_rate": 4.166265060240964e-06,
      "loss": 0.0169,
      "step": 65710
    },
    {
      "epoch": 7.918072289156626,
      "grad_norm": 0.39105552434921265,
      "learning_rate": 4.163855421686747e-06,
      "loss": 0.0087,
      "step": 65720
    },
    {
      "epoch": 7.919277108433735,
      "grad_norm": 0.0016432753764092922,
      "learning_rate": 4.16144578313253e-06,
      "loss": 0.01,
      "step": 65730
    },
    {
      "epoch": 7.920481927710844,
      "grad_norm": 0.0009337799856439233,
      "learning_rate": 4.159036144578314e-06,
      "loss": 0.0177,
      "step": 65740
    },
    {
      "epoch": 7.921686746987952,
      "grad_norm": 0.34091779589653015,
      "learning_rate": 4.156626506024097e-06,
      "loss": 0.0046,
      "step": 65750
    },
    {
      "epoch": 7.9228915662650605,
      "grad_norm": 0.0024147294461727142,
      "learning_rate": 4.15421686746988e-06,
      "loss": 0.0269,
      "step": 65760
    },
    {
      "epoch": 7.924096385542168,
      "grad_norm": 0.3145267069339752,
      "learning_rate": 4.151807228915663e-06,
      "loss": 0.0186,
      "step": 65770
    },
    {
      "epoch": 7.925301204819277,
      "grad_norm": 0.00036802099202759564,
      "learning_rate": 4.1493975903614454e-06,
      "loss": 0.0021,
      "step": 65780
    },
    {
      "epoch": 7.926506024096385,
      "grad_norm": 0.9314171671867371,
      "learning_rate": 4.1469879518072295e-06,
      "loss": 0.0048,
      "step": 65790
    },
    {
      "epoch": 7.927710843373494,
      "grad_norm": 2.582521677017212,
      "learning_rate": 4.144578313253013e-06,
      "loss": 0.0437,
      "step": 65800
    },
    {
      "epoch": 7.928915662650603,
      "grad_norm": 0.5285942554473877,
      "learning_rate": 4.142168674698796e-06,
      "loss": 0.0123,
      "step": 65810
    },
    {
      "epoch": 7.930120481927711,
      "grad_norm": 0.0013002773048356175,
      "learning_rate": 4.139759036144579e-06,
      "loss": 0.0029,
      "step": 65820
    },
    {
      "epoch": 7.9313253012048195,
      "grad_norm": 0.0011909358436241746,
      "learning_rate": 4.137349397590361e-06,
      "loss": 0.0023,
      "step": 65830
    },
    {
      "epoch": 7.932530120481927,
      "grad_norm": 1.469753623008728,
      "learning_rate": 4.134939759036145e-06,
      "loss": 0.0466,
      "step": 65840
    },
    {
      "epoch": 7.933734939759036,
      "grad_norm": 0.0007391108083538711,
      "learning_rate": 4.132530120481928e-06,
      "loss": 0.0331,
      "step": 65850
    },
    {
      "epoch": 7.934939759036144,
      "grad_norm": 1.7495757341384888,
      "learning_rate": 4.130120481927712e-06,
      "loss": 0.0151,
      "step": 65860
    },
    {
      "epoch": 7.936144578313253,
      "grad_norm": 1.0709283351898193,
      "learning_rate": 4.127710843373494e-06,
      "loss": 0.0175,
      "step": 65870
    },
    {
      "epoch": 7.937349397590362,
      "grad_norm": 0.5578765273094177,
      "learning_rate": 4.125301204819277e-06,
      "loss": 0.0208,
      "step": 65880
    },
    {
      "epoch": 7.93855421686747,
      "grad_norm": 4.205344200134277,
      "learning_rate": 4.12289156626506e-06,
      "loss": 0.0111,
      "step": 65890
    },
    {
      "epoch": 7.9397590361445785,
      "grad_norm": 0.0006739153759554029,
      "learning_rate": 4.1204819277108436e-06,
      "loss": 0.0131,
      "step": 65900
    },
    {
      "epoch": 7.940963855421686,
      "grad_norm": 0.0008296400192193687,
      "learning_rate": 4.118072289156627e-06,
      "loss": 0.045,
      "step": 65910
    },
    {
      "epoch": 7.942168674698795,
      "grad_norm": 0.0006000266876071692,
      "learning_rate": 4.11566265060241e-06,
      "loss": 0.0016,
      "step": 65920
    },
    {
      "epoch": 7.943373493975904,
      "grad_norm": 0.006006469018757343,
      "learning_rate": 4.113253012048193e-06,
      "loss": 0.0077,
      "step": 65930
    },
    {
      "epoch": 7.944578313253012,
      "grad_norm": 1.3872700929641724,
      "learning_rate": 4.110843373493976e-06,
      "loss": 0.0168,
      "step": 65940
    },
    {
      "epoch": 7.945783132530121,
      "grad_norm": 0.003987748175859451,
      "learning_rate": 4.1084337349397594e-06,
      "loss": 0.0037,
      "step": 65950
    },
    {
      "epoch": 7.946987951807229,
      "grad_norm": 0.0021018993575125933,
      "learning_rate": 4.106024096385543e-06,
      "loss": 0.0307,
      "step": 65960
    },
    {
      "epoch": 7.948192771084337,
      "grad_norm": 0.21940059959888458,
      "learning_rate": 4.103614457831326e-06,
      "loss": 0.0047,
      "step": 65970
    },
    {
      "epoch": 7.949397590361446,
      "grad_norm": 0.8782873749732971,
      "learning_rate": 4.101204819277109e-06,
      "loss": 0.0173,
      "step": 65980
    },
    {
      "epoch": 7.950602409638554,
      "grad_norm": 0.0012978905579075217,
      "learning_rate": 4.098795180722892e-06,
      "loss": 0.0083,
      "step": 65990
    },
    {
      "epoch": 7.951807228915663,
      "grad_norm": 0.0012784526916220784,
      "learning_rate": 4.096385542168675e-06,
      "loss": 0.0227,
      "step": 66000
    },
    {
      "epoch": 7.953012048192771,
      "grad_norm": 1.0463342666625977,
      "learning_rate": 4.0939759036144585e-06,
      "loss": 0.0038,
      "step": 66010
    },
    {
      "epoch": 7.95421686746988,
      "grad_norm": 0.8557472825050354,
      "learning_rate": 4.091566265060241e-06,
      "loss": 0.0283,
      "step": 66020
    },
    {
      "epoch": 7.955421686746988,
      "grad_norm": 0.00048521970165893435,
      "learning_rate": 4.089156626506025e-06,
      "loss": 0.0056,
      "step": 66030
    },
    {
      "epoch": 7.956626506024096,
      "grad_norm": 0.0008900425164029002,
      "learning_rate": 4.086746987951807e-06,
      "loss": 0.0169,
      "step": 66040
    },
    {
      "epoch": 7.957831325301205,
      "grad_norm": 0.00046191454748623073,
      "learning_rate": 4.08433734939759e-06,
      "loss": 0.009,
      "step": 66050
    },
    {
      "epoch": 7.959036144578313,
      "grad_norm": 0.00041818019235506654,
      "learning_rate": 4.0819277108433735e-06,
      "loss": 0.019,
      "step": 66060
    },
    {
      "epoch": 7.960240963855422,
      "grad_norm": 0.5797538757324219,
      "learning_rate": 4.079518072289157e-06,
      "loss": 0.0171,
      "step": 66070
    },
    {
      "epoch": 7.96144578313253,
      "grad_norm": 0.27164724469184875,
      "learning_rate": 4.077108433734941e-06,
      "loss": 0.0182,
      "step": 66080
    },
    {
      "epoch": 7.962650602409639,
      "grad_norm": 0.000555303180590272,
      "learning_rate": 4.074698795180723e-06,
      "loss": 0.0132,
      "step": 66090
    },
    {
      "epoch": 7.9638554216867465,
      "grad_norm": 18.817590713500977,
      "learning_rate": 4.072289156626506e-06,
      "loss": 0.0156,
      "step": 66100
    },
    {
      "epoch": 7.965060240963855,
      "grad_norm": 0.0006008374039083719,
      "learning_rate": 4.069879518072289e-06,
      "loss": 0.0163,
      "step": 66110
    },
    {
      "epoch": 7.966265060240964,
      "grad_norm": 2.269664764404297,
      "learning_rate": 4.067469879518073e-06,
      "loss": 0.0114,
      "step": 66120
    },
    {
      "epoch": 7.967469879518072,
      "grad_norm": 0.0006404647720046341,
      "learning_rate": 4.065060240963856e-06,
      "loss": 0.0138,
      "step": 66130
    },
    {
      "epoch": 7.968674698795181,
      "grad_norm": 0.0008091261843219399,
      "learning_rate": 4.062650602409639e-06,
      "loss": 0.0052,
      "step": 66140
    },
    {
      "epoch": 7.969879518072289,
      "grad_norm": 1.1973909139633179,
      "learning_rate": 4.060240963855422e-06,
      "loss": 0.0258,
      "step": 66150
    },
    {
      "epoch": 7.971084337349398,
      "grad_norm": 0.0003861075674649328,
      "learning_rate": 4.057831325301205e-06,
      "loss": 0.0247,
      "step": 66160
    },
    {
      "epoch": 7.972289156626506,
      "grad_norm": 0.0004993492038920522,
      "learning_rate": 4.0554216867469885e-06,
      "loss": 0.0111,
      "step": 66170
    },
    {
      "epoch": 7.973493975903614,
      "grad_norm": 0.001144436071626842,
      "learning_rate": 4.053012048192772e-06,
      "loss": 0.0015,
      "step": 66180
    },
    {
      "epoch": 7.974698795180723,
      "grad_norm": 0.0004893819568678737,
      "learning_rate": 4.050602409638554e-06,
      "loss": 0.0067,
      "step": 66190
    },
    {
      "epoch": 7.975903614457831,
      "grad_norm": 10.93713665008545,
      "learning_rate": 4.048192771084338e-06,
      "loss": 0.0049,
      "step": 66200
    },
    {
      "epoch": 7.97710843373494,
      "grad_norm": 1.5015517473220825,
      "learning_rate": 4.04578313253012e-06,
      "loss": 0.0047,
      "step": 66210
    },
    {
      "epoch": 7.978313253012049,
      "grad_norm": 0.03128717839717865,
      "learning_rate": 4.043373493975904e-06,
      "loss": 0.0176,
      "step": 66220
    },
    {
      "epoch": 7.9795180722891565,
      "grad_norm": 0.0006027163472026587,
      "learning_rate": 4.0409638554216875e-06,
      "loss": 0.005,
      "step": 66230
    },
    {
      "epoch": 7.980722891566265,
      "grad_norm": 0.0010764084290713072,
      "learning_rate": 4.03855421686747e-06,
      "loss": 0.024,
      "step": 66240
    },
    {
      "epoch": 7.981927710843373,
      "grad_norm": 1.594443917274475,
      "learning_rate": 4.036144578313254e-06,
      "loss": 0.0139,
      "step": 66250
    },
    {
      "epoch": 7.983132530120482,
      "grad_norm": 0.32421717047691345,
      "learning_rate": 4.033734939759036e-06,
      "loss": 0.0141,
      "step": 66260
    },
    {
      "epoch": 7.98433734939759,
      "grad_norm": 1.8977550268173218,
      "learning_rate": 4.031325301204819e-06,
      "loss": 0.0262,
      "step": 66270
    },
    {
      "epoch": 7.985542168674699,
      "grad_norm": 1.3199121952056885,
      "learning_rate": 4.0289156626506026e-06,
      "loss": 0.012,
      "step": 66280
    },
    {
      "epoch": 7.986746987951808,
      "grad_norm": 0.3856024444103241,
      "learning_rate": 4.026506024096386e-06,
      "loss": 0.0111,
      "step": 66290
    },
    {
      "epoch": 7.9879518072289155,
      "grad_norm": 0.8924093842506409,
      "learning_rate": 4.024096385542169e-06,
      "loss": 0.0316,
      "step": 66300
    },
    {
      "epoch": 7.989156626506024,
      "grad_norm": 2.6644363403320312,
      "learning_rate": 4.021686746987952e-06,
      "loss": 0.0217,
      "step": 66310
    },
    {
      "epoch": 7.990361445783132,
      "grad_norm": 0.035186365246772766,
      "learning_rate": 4.019277108433735e-06,
      "loss": 0.0274,
      "step": 66320
    },
    {
      "epoch": 7.991566265060241,
      "grad_norm": 0.0010235608788207173,
      "learning_rate": 4.0168674698795184e-06,
      "loss": 0.0019,
      "step": 66330
    },
    {
      "epoch": 7.992771084337349,
      "grad_norm": 0.005921799223870039,
      "learning_rate": 4.014457831325302e-06,
      "loss": 0.0194,
      "step": 66340
    },
    {
      "epoch": 7.993975903614458,
      "grad_norm": 0.05923427641391754,
      "learning_rate": 4.012048192771085e-06,
      "loss": 0.009,
      "step": 66350
    },
    {
      "epoch": 7.995180722891567,
      "grad_norm": 0.0005617441493086517,
      "learning_rate": 4.009638554216868e-06,
      "loss": 0.0162,
      "step": 66360
    },
    {
      "epoch": 7.9963855421686745,
      "grad_norm": 0.00046327884774655104,
      "learning_rate": 4.007228915662651e-06,
      "loss": 0.0069,
      "step": 66370
    },
    {
      "epoch": 7.997590361445783,
      "grad_norm": 2.2194101810455322,
      "learning_rate": 4.004819277108434e-06,
      "loss": 0.0252,
      "step": 66380
    },
    {
      "epoch": 7.998795180722891,
      "grad_norm": 0.004908848088234663,
      "learning_rate": 4.0024096385542175e-06,
      "loss": 0.0273,
      "step": 66390
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.006431365851312876,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0091,
      "step": 66400
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9873687664041995,
      "eval_f1": 0.9663061824092019,
      "eval_loss": 0.05189305171370506,
      "eval_precision": 0.9776119402985075,
      "eval_recall": 0.9552589296749475,
      "eval_runtime": 3423.1013,
      "eval_samples_per_second": 12.471,
      "eval_steps_per_second": 0.52,
      "step": 66400
    },
    {
      "epoch": 8.001204819277108,
      "grad_norm": 0.22740697860717773,
      "learning_rate": 3.997590361445783e-06,
      "loss": 0.0131,
      "step": 66410
    },
    {
      "epoch": 8.002409638554218,
      "grad_norm": 0.00031792387017048895,
      "learning_rate": 3.995180722891567e-06,
      "loss": 0.0026,
      "step": 66420
    },
    {
      "epoch": 8.003614457831326,
      "grad_norm": 0.0003811317728832364,
      "learning_rate": 3.992771084337349e-06,
      "loss": 0.0049,
      "step": 66430
    },
    {
      "epoch": 8.004819277108433,
      "grad_norm": 0.0017384813399985433,
      "learning_rate": 3.990361445783133e-06,
      "loss": 0.0039,
      "step": 66440
    },
    {
      "epoch": 8.006024096385541,
      "grad_norm": 0.00041467483970336616,
      "learning_rate": 3.987951807228916e-06,
      "loss": 0.0086,
      "step": 66450
    },
    {
      "epoch": 8.007228915662651,
      "grad_norm": 1.2446961402893066,
      "learning_rate": 3.985542168674699e-06,
      "loss": 0.037,
      "step": 66460
    },
    {
      "epoch": 8.008433734939759,
      "grad_norm": 2.350536584854126,
      "learning_rate": 3.983132530120482e-06,
      "loss": 0.0313,
      "step": 66470
    },
    {
      "epoch": 8.009638554216867,
      "grad_norm": 0.000549867341760546,
      "learning_rate": 3.980722891566265e-06,
      "loss": 0.0099,
      "step": 66480
    },
    {
      "epoch": 8.010843373493977,
      "grad_norm": 0.0003463589819148183,
      "learning_rate": 3.978313253012048e-06,
      "loss": 0.0051,
      "step": 66490
    },
    {
      "epoch": 8.012048192771084,
      "grad_norm": 0.0003702272952068597,
      "learning_rate": 3.975903614457832e-06,
      "loss": 0.0246,
      "step": 66500
    },
    {
      "epoch": 8.013253012048192,
      "grad_norm": 0.02334744855761528,
      "learning_rate": 3.973493975903615e-06,
      "loss": 0.0101,
      "step": 66510
    },
    {
      "epoch": 8.0144578313253,
      "grad_norm": 1.737988829612732,
      "learning_rate": 3.971084337349398e-06,
      "loss": 0.0154,
      "step": 66520
    },
    {
      "epoch": 8.01566265060241,
      "grad_norm": 1.0732307434082031,
      "learning_rate": 3.968674698795181e-06,
      "loss": 0.0116,
      "step": 66530
    },
    {
      "epoch": 8.016867469879518,
      "grad_norm": 0.0006798015674576163,
      "learning_rate": 3.966265060240964e-06,
      "loss": 0.013,
      "step": 66540
    },
    {
      "epoch": 8.018072289156626,
      "grad_norm": 0.00065908971009776,
      "learning_rate": 3.9638554216867475e-06,
      "loss": 0.011,
      "step": 66550
    },
    {
      "epoch": 8.019277108433736,
      "grad_norm": 0.0003977876913268119,
      "learning_rate": 3.961445783132531e-06,
      "loss": 0.0368,
      "step": 66560
    },
    {
      "epoch": 8.020481927710843,
      "grad_norm": 60.72740173339844,
      "learning_rate": 3.959036144578314e-06,
      "loss": 0.0238,
      "step": 66570
    },
    {
      "epoch": 8.021686746987951,
      "grad_norm": 0.0008614909020252526,
      "learning_rate": 3.956626506024097e-06,
      "loss": 0.0162,
      "step": 66580
    },
    {
      "epoch": 8.022891566265061,
      "grad_norm": 0.0009046761551871896,
      "learning_rate": 3.95421686746988e-06,
      "loss": 0.0014,
      "step": 66590
    },
    {
      "epoch": 8.024096385542169,
      "grad_norm": 0.0003317699010949582,
      "learning_rate": 3.9518072289156625e-06,
      "loss": 0.0162,
      "step": 66600
    },
    {
      "epoch": 8.025301204819277,
      "grad_norm": 0.18478745222091675,
      "learning_rate": 3.9493975903614465e-06,
      "loss": 0.0177,
      "step": 66610
    },
    {
      "epoch": 8.026506024096385,
      "grad_norm": 0.7832218408584595,
      "learning_rate": 3.946987951807229e-06,
      "loss": 0.0024,
      "step": 66620
    },
    {
      "epoch": 8.027710843373494,
      "grad_norm": 0.1460132747888565,
      "learning_rate": 3.944578313253012e-06,
      "loss": 0.0154,
      "step": 66630
    },
    {
      "epoch": 8.028915662650602,
      "grad_norm": 0.0004463644290808588,
      "learning_rate": 3.942168674698795e-06,
      "loss": 0.0739,
      "step": 66640
    },
    {
      "epoch": 8.03012048192771,
      "grad_norm": 0.000674647802952677,
      "learning_rate": 3.939759036144578e-06,
      "loss": 0.0051,
      "step": 66650
    },
    {
      "epoch": 8.03132530120482,
      "grad_norm": 0.000430590269388631,
      "learning_rate": 3.9373493975903615e-06,
      "loss": 0.0319,
      "step": 66660
    },
    {
      "epoch": 8.032530120481928,
      "grad_norm": 0.8605919480323792,
      "learning_rate": 3.934939759036145e-06,
      "loss": 0.0121,
      "step": 66670
    },
    {
      "epoch": 8.033734939759036,
      "grad_norm": 0.605847954750061,
      "learning_rate": 3.932530120481928e-06,
      "loss": 0.015,
      "step": 66680
    },
    {
      "epoch": 8.034939759036144,
      "grad_norm": 1.0202393531799316,
      "learning_rate": 3.930120481927711e-06,
      "loss": 0.0137,
      "step": 66690
    },
    {
      "epoch": 8.036144578313253,
      "grad_norm": 1.4095221757888794,
      "learning_rate": 3.927710843373494e-06,
      "loss": 0.0067,
      "step": 66700
    },
    {
      "epoch": 8.037349397590361,
      "grad_norm": 1.0431753396987915,
      "learning_rate": 3.9253012048192774e-06,
      "loss": 0.0087,
      "step": 66710
    },
    {
      "epoch": 8.03855421686747,
      "grad_norm": 0.0008692084811627865,
      "learning_rate": 3.922891566265061e-06,
      "loss": 0.0093,
      "step": 66720
    },
    {
      "epoch": 8.039759036144579,
      "grad_norm": 0.44383886456489563,
      "learning_rate": 3.920481927710844e-06,
      "loss": 0.0028,
      "step": 66730
    },
    {
      "epoch": 8.040963855421687,
      "grad_norm": 0.0017526288283988833,
      "learning_rate": 3.918072289156627e-06,
      "loss": 0.0117,
      "step": 66740
    },
    {
      "epoch": 8.042168674698795,
      "grad_norm": 0.544770359992981,
      "learning_rate": 3.91566265060241e-06,
      "loss": 0.0198,
      "step": 66750
    },
    {
      "epoch": 8.043373493975903,
      "grad_norm": 0.012132599018514156,
      "learning_rate": 3.913253012048193e-06,
      "loss": 0.0022,
      "step": 66760
    },
    {
      "epoch": 8.044578313253012,
      "grad_norm": 0.0004433107387740165,
      "learning_rate": 3.910843373493976e-06,
      "loss": 0.0134,
      "step": 66770
    },
    {
      "epoch": 8.04578313253012,
      "grad_norm": 0.0004132580943405628,
      "learning_rate": 3.90843373493976e-06,
      "loss": 0.0363,
      "step": 66780
    },
    {
      "epoch": 8.046987951807228,
      "grad_norm": 0.8336754441261292,
      "learning_rate": 3.906024096385542e-06,
      "loss": 0.007,
      "step": 66790
    },
    {
      "epoch": 8.048192771084338,
      "grad_norm": 1.5326324701309204,
      "learning_rate": 3.903614457831326e-06,
      "loss": 0.0133,
      "step": 66800
    },
    {
      "epoch": 8.049397590361446,
      "grad_norm": 0.0009262521634809673,
      "learning_rate": 3.901204819277108e-06,
      "loss": 0.0231,
      "step": 66810
    },
    {
      "epoch": 8.050602409638554,
      "grad_norm": 0.0008148292545229197,
      "learning_rate": 3.8987951807228915e-06,
      "loss": 0.0027,
      "step": 66820
    },
    {
      "epoch": 8.051807228915663,
      "grad_norm": 0.5430595278739929,
      "learning_rate": 3.8963855421686755e-06,
      "loss": 0.0662,
      "step": 66830
    },
    {
      "epoch": 8.053012048192771,
      "grad_norm": 0.2609057128429413,
      "learning_rate": 3.893975903614458e-06,
      "loss": 0.006,
      "step": 66840
    },
    {
      "epoch": 8.05421686746988,
      "grad_norm": 1.2160148620605469,
      "learning_rate": 3.891566265060242e-06,
      "loss": 0.0052,
      "step": 66850
    },
    {
      "epoch": 8.055421686746987,
      "grad_norm": 0.0006209228886291385,
      "learning_rate": 3.889156626506024e-06,
      "loss": 0.0305,
      "step": 66860
    },
    {
      "epoch": 8.056626506024097,
      "grad_norm": 0.0007151418249122798,
      "learning_rate": 3.886746987951807e-06,
      "loss": 0.0318,
      "step": 66870
    },
    {
      "epoch": 8.057831325301205,
      "grad_norm": 0.47424402832984924,
      "learning_rate": 3.8843373493975906e-06,
      "loss": 0.0145,
      "step": 66880
    },
    {
      "epoch": 8.059036144578313,
      "grad_norm": 0.048725392669439316,
      "learning_rate": 3.881927710843374e-06,
      "loss": 0.0031,
      "step": 66890
    },
    {
      "epoch": 8.060240963855422,
      "grad_norm": 0.008399373851716518,
      "learning_rate": 3.879518072289157e-06,
      "loss": 0.0147,
      "step": 66900
    },
    {
      "epoch": 8.06144578313253,
      "grad_norm": 1.2866990566253662,
      "learning_rate": 3.87710843373494e-06,
      "loss": 0.0149,
      "step": 66910
    },
    {
      "epoch": 8.062650602409638,
      "grad_norm": 0.5461336970329285,
      "learning_rate": 3.874698795180723e-06,
      "loss": 0.0205,
      "step": 66920
    },
    {
      "epoch": 8.063855421686746,
      "grad_norm": 3.0437729358673096,
      "learning_rate": 3.8722891566265065e-06,
      "loss": 0.0219,
      "step": 66930
    },
    {
      "epoch": 8.065060240963856,
      "grad_norm": 0.002839963650330901,
      "learning_rate": 3.86987951807229e-06,
      "loss": 0.0259,
      "step": 66940
    },
    {
      "epoch": 8.066265060240964,
      "grad_norm": 0.010567384772002697,
      "learning_rate": 3.867469879518073e-06,
      "loss": 0.0227,
      "step": 66950
    },
    {
      "epoch": 8.067469879518072,
      "grad_norm": 0.0005271252593956888,
      "learning_rate": 3.865060240963856e-06,
      "loss": 0.0099,
      "step": 66960
    },
    {
      "epoch": 8.068674698795181,
      "grad_norm": 0.0031680711545050144,
      "learning_rate": 3.862650602409639e-06,
      "loss": 0.0133,
      "step": 66970
    },
    {
      "epoch": 8.06987951807229,
      "grad_norm": 1.0161265134811401,
      "learning_rate": 3.860240963855422e-06,
      "loss": 0.0175,
      "step": 66980
    },
    {
      "epoch": 8.071084337349397,
      "grad_norm": 0.002213874366134405,
      "learning_rate": 3.857831325301205e-06,
      "loss": 0.0141,
      "step": 66990
    },
    {
      "epoch": 8.072289156626505,
      "grad_norm": 0.0022366135381162167,
      "learning_rate": 3.855421686746989e-06,
      "loss": 0.0144,
      "step": 67000
    },
    {
      "epoch": 8.073493975903615,
      "grad_norm": 0.00048820109805092216,
      "learning_rate": 3.853012048192771e-06,
      "loss": 0.0031,
      "step": 67010
    },
    {
      "epoch": 8.074698795180723,
      "grad_norm": 0.0021028860937803984,
      "learning_rate": 3.850602409638555e-06,
      "loss": 0.0074,
      "step": 67020
    },
    {
      "epoch": 8.07590361445783,
      "grad_norm": 0.0005487797898240387,
      "learning_rate": 3.848192771084337e-06,
      "loss": 0.0245,
      "step": 67030
    },
    {
      "epoch": 8.07710843373494,
      "grad_norm": 0.013551875948905945,
      "learning_rate": 3.8457831325301205e-06,
      "loss": 0.0014,
      "step": 67040
    },
    {
      "epoch": 8.078313253012048,
      "grad_norm": 1.755639672279358,
      "learning_rate": 3.843373493975904e-06,
      "loss": 0.01,
      "step": 67050
    },
    {
      "epoch": 8.079518072289156,
      "grad_norm": 0.0008471646578982472,
      "learning_rate": 3.840963855421687e-06,
      "loss": 0.0,
      "step": 67060
    },
    {
      "epoch": 8.080722891566266,
      "grad_norm": 0.2316334992647171,
      "learning_rate": 3.83855421686747e-06,
      "loss": 0.0022,
      "step": 67070
    },
    {
      "epoch": 8.081927710843374,
      "grad_norm": 0.08536601811647415,
      "learning_rate": 3.836144578313253e-06,
      "loss": 0.0126,
      "step": 67080
    },
    {
      "epoch": 8.083132530120482,
      "grad_norm": 0.0019627839792519808,
      "learning_rate": 3.833734939759036e-06,
      "loss": 0.0056,
      "step": 67090
    },
    {
      "epoch": 8.08433734939759,
      "grad_norm": 0.0008510665502399206,
      "learning_rate": 3.83132530120482e-06,
      "loss": 0.0173,
      "step": 67100
    },
    {
      "epoch": 8.0855421686747,
      "grad_norm": 0.21191006898880005,
      "learning_rate": 3.828915662650603e-06,
      "loss": 0.01,
      "step": 67110
    },
    {
      "epoch": 8.086746987951807,
      "grad_norm": 0.0007724635070189834,
      "learning_rate": 3.826506024096386e-06,
      "loss": 0.0014,
      "step": 67120
    },
    {
      "epoch": 8.087951807228915,
      "grad_norm": 0.25836649537086487,
      "learning_rate": 3.824096385542169e-06,
      "loss": 0.0323,
      "step": 67130
    },
    {
      "epoch": 8.089156626506025,
      "grad_norm": 18.671876907348633,
      "learning_rate": 3.821686746987952e-06,
      "loss": 0.0168,
      "step": 67140
    },
    {
      "epoch": 8.090361445783133,
      "grad_norm": 0.02576267533004284,
      "learning_rate": 3.8192771084337355e-06,
      "loss": 0.0036,
      "step": 67150
    },
    {
      "epoch": 8.09156626506024,
      "grad_norm": 0.0007736514089629054,
      "learning_rate": 3.816867469879519e-06,
      "loss": 0.0086,
      "step": 67160
    },
    {
      "epoch": 8.092771084337349,
      "grad_norm": 0.0007932105218060315,
      "learning_rate": 3.814457831325302e-06,
      "loss": 0.0105,
      "step": 67170
    },
    {
      "epoch": 8.093975903614458,
      "grad_norm": 0.001455293851904571,
      "learning_rate": 3.8120481927710846e-06,
      "loss": 0.0006,
      "step": 67180
    },
    {
      "epoch": 8.095180722891566,
      "grad_norm": 1.3696162700653076,
      "learning_rate": 3.8096385542168678e-06,
      "loss": 0.0113,
      "step": 67190
    },
    {
      "epoch": 8.096385542168674,
      "grad_norm": 0.00046180145000107586,
      "learning_rate": 3.807228915662651e-06,
      "loss": 0.0034,
      "step": 67200
    },
    {
      "epoch": 8.097590361445784,
      "grad_norm": 0.0034223308321088552,
      "learning_rate": 3.804819277108434e-06,
      "loss": 0.0129,
      "step": 67210
    },
    {
      "epoch": 8.098795180722892,
      "grad_norm": 1.6023595333099365,
      "learning_rate": 3.802409638554217e-06,
      "loss": 0.0144,
      "step": 67220
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.004473274573683739,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.0143,
      "step": 67230
    },
    {
      "epoch": 8.101204819277108,
      "grad_norm": 0.8590680360794067,
      "learning_rate": 3.7975903614457832e-06,
      "loss": 0.019,
      "step": 67240
    },
    {
      "epoch": 8.102409638554217,
      "grad_norm": 0.0011961000273004174,
      "learning_rate": 3.7951807228915664e-06,
      "loss": 0.0044,
      "step": 67250
    },
    {
      "epoch": 8.103614457831325,
      "grad_norm": 0.0004373083356767893,
      "learning_rate": 3.79277108433735e-06,
      "loss": 0.0248,
      "step": 67260
    },
    {
      "epoch": 8.104819277108433,
      "grad_norm": 0.0013422020711004734,
      "learning_rate": 3.7903614457831327e-06,
      "loss": 0.0021,
      "step": 67270
    },
    {
      "epoch": 8.106024096385543,
      "grad_norm": 0.00041710957884788513,
      "learning_rate": 3.7879518072289163e-06,
      "loss": 0.0186,
      "step": 67280
    },
    {
      "epoch": 8.10722891566265,
      "grad_norm": 0.0018923686584457755,
      "learning_rate": 3.785542168674699e-06,
      "loss": 0.0059,
      "step": 67290
    },
    {
      "epoch": 8.108433734939759,
      "grad_norm": 0.2721051275730133,
      "learning_rate": 3.7831325301204823e-06,
      "loss": 0.0185,
      "step": 67300
    },
    {
      "epoch": 8.109638554216868,
      "grad_norm": 0.07454300671815872,
      "learning_rate": 3.7807228915662654e-06,
      "loss": 0.012,
      "step": 67310
    },
    {
      "epoch": 8.110843373493976,
      "grad_norm": 0.0005665410426445305,
      "learning_rate": 3.7783132530120486e-06,
      "loss": 0.0196,
      "step": 67320
    },
    {
      "epoch": 8.112048192771084,
      "grad_norm": 0.0005190639640204608,
      "learning_rate": 3.7759036144578314e-06,
      "loss": 0.0464,
      "step": 67330
    },
    {
      "epoch": 8.113253012048192,
      "grad_norm": 0.000529570272192359,
      "learning_rate": 3.773493975903615e-06,
      "loss": 0.0196,
      "step": 67340
    },
    {
      "epoch": 8.114457831325302,
      "grad_norm": 0.047864485532045364,
      "learning_rate": 3.7710843373493977e-06,
      "loss": 0.0279,
      "step": 67350
    },
    {
      "epoch": 8.11566265060241,
      "grad_norm": 0.606740415096283,
      "learning_rate": 3.768674698795181e-06,
      "loss": 0.0053,
      "step": 67360
    },
    {
      "epoch": 8.116867469879518,
      "grad_norm": 0.772430419921875,
      "learning_rate": 3.766265060240964e-06,
      "loss": 0.0681,
      "step": 67370
    },
    {
      "epoch": 8.118072289156627,
      "grad_norm": 0.0017875456251204014,
      "learning_rate": 3.7638554216867473e-06,
      "loss": 0.0024,
      "step": 67380
    },
    {
      "epoch": 8.119277108433735,
      "grad_norm": 0.0011348488042131066,
      "learning_rate": 3.76144578313253e-06,
      "loss": 0.0135,
      "step": 67390
    },
    {
      "epoch": 8.120481927710843,
      "grad_norm": 0.005077356472611427,
      "learning_rate": 3.7590361445783136e-06,
      "loss": 0.0055,
      "step": 67400
    },
    {
      "epoch": 8.121686746987951,
      "grad_norm": 0.006097402889281511,
      "learning_rate": 3.7566265060240968e-06,
      "loss": 0.0023,
      "step": 67410
    },
    {
      "epoch": 8.12289156626506,
      "grad_norm": 0.023845799267292023,
      "learning_rate": 3.75421686746988e-06,
      "loss": 0.0034,
      "step": 67420
    },
    {
      "epoch": 8.124096385542169,
      "grad_norm": 0.3492306172847748,
      "learning_rate": 3.751807228915663e-06,
      "loss": 0.0131,
      "step": 67430
    },
    {
      "epoch": 8.125301204819277,
      "grad_norm": 0.5536790490150452,
      "learning_rate": 3.749397590361446e-06,
      "loss": 0.02,
      "step": 67440
    },
    {
      "epoch": 8.126506024096386,
      "grad_norm": 0.0004061807703692466,
      "learning_rate": 3.7469879518072295e-06,
      "loss": 0.0221,
      "step": 67450
    },
    {
      "epoch": 8.127710843373494,
      "grad_norm": 0.0008025942370295525,
      "learning_rate": 3.7445783132530122e-06,
      "loss": 0.0306,
      "step": 67460
    },
    {
      "epoch": 8.128915662650602,
      "grad_norm": 0.7946067452430725,
      "learning_rate": 3.742168674698796e-06,
      "loss": 0.0048,
      "step": 67470
    },
    {
      "epoch": 8.13012048192771,
      "grad_norm": 0.0009234747849404812,
      "learning_rate": 3.7397590361445786e-06,
      "loss": 0.0136,
      "step": 67480
    },
    {
      "epoch": 8.13132530120482,
      "grad_norm": 0.0009753857739269733,
      "learning_rate": 3.7373493975903618e-06,
      "loss": 0.0264,
      "step": 67490
    },
    {
      "epoch": 8.132530120481928,
      "grad_norm": 0.0007862598868086934,
      "learning_rate": 3.7349397590361445e-06,
      "loss": 0.004,
      "step": 67500
    },
    {
      "epoch": 8.133734939759035,
      "grad_norm": 0.1791256219148636,
      "learning_rate": 3.732530120481928e-06,
      "loss": 0.001,
      "step": 67510
    },
    {
      "epoch": 8.134939759036145,
      "grad_norm": 2.40765118598938,
      "learning_rate": 3.730120481927711e-06,
      "loss": 0.0263,
      "step": 67520
    },
    {
      "epoch": 8.136144578313253,
      "grad_norm": 0.02860267274081707,
      "learning_rate": 3.7277108433734945e-06,
      "loss": 0.0127,
      "step": 67530
    },
    {
      "epoch": 8.137349397590361,
      "grad_norm": 0.0004982406971976161,
      "learning_rate": 3.7253012048192772e-06,
      "loss": 0.0,
      "step": 67540
    },
    {
      "epoch": 8.13855421686747,
      "grad_norm": 0.004262732341885567,
      "learning_rate": 3.7228915662650604e-06,
      "loss": 0.0315,
      "step": 67550
    },
    {
      "epoch": 8.139759036144579,
      "grad_norm": 0.0003839402343146503,
      "learning_rate": 3.720481927710844e-06,
      "loss": 0.0059,
      "step": 67560
    },
    {
      "epoch": 8.140963855421687,
      "grad_norm": 0.00042151729576289654,
      "learning_rate": 3.7180722891566268e-06,
      "loss": 0.0459,
      "step": 67570
    },
    {
      "epoch": 8.142168674698794,
      "grad_norm": 0.0006089195376262069,
      "learning_rate": 3.7156626506024104e-06,
      "loss": 0.0342,
      "step": 67580
    },
    {
      "epoch": 8.143373493975904,
      "grad_norm": 0.0037897781003266573,
      "learning_rate": 3.713253012048193e-06,
      "loss": 0.0097,
      "step": 67590
    },
    {
      "epoch": 8.144578313253012,
      "grad_norm": 1.7085899114608765,
      "learning_rate": 3.7108433734939763e-06,
      "loss": 0.0121,
      "step": 67600
    },
    {
      "epoch": 8.14578313253012,
      "grad_norm": 0.2351604700088501,
      "learning_rate": 3.708433734939759e-06,
      "loss": 0.0295,
      "step": 67610
    },
    {
      "epoch": 8.14698795180723,
      "grad_norm": 0.0007004979415796697,
      "learning_rate": 3.7060240963855426e-06,
      "loss": 0.0157,
      "step": 67620
    },
    {
      "epoch": 8.148192771084338,
      "grad_norm": 1.0585412979125977,
      "learning_rate": 3.7036144578313254e-06,
      "loss": 0.0121,
      "step": 67630
    },
    {
      "epoch": 8.149397590361446,
      "grad_norm": 0.14701221883296967,
      "learning_rate": 3.701204819277109e-06,
      "loss": 0.0042,
      "step": 67640
    },
    {
      "epoch": 8.150602409638553,
      "grad_norm": 0.0015374692156910896,
      "learning_rate": 3.6987951807228917e-06,
      "loss": 0.0167,
      "step": 67650
    },
    {
      "epoch": 8.151807228915663,
      "grad_norm": 0.0004062746011186391,
      "learning_rate": 3.696385542168675e-06,
      "loss": 0.0067,
      "step": 67660
    },
    {
      "epoch": 8.153012048192771,
      "grad_norm": 0.0006841840804554522,
      "learning_rate": 3.693975903614458e-06,
      "loss": 0.0105,
      "step": 67670
    },
    {
      "epoch": 8.154216867469879,
      "grad_norm": 0.0004722461453638971,
      "learning_rate": 3.6915662650602413e-06,
      "loss": 0.0032,
      "step": 67680
    },
    {
      "epoch": 8.155421686746989,
      "grad_norm": 0.001062297378666699,
      "learning_rate": 3.689156626506024e-06,
      "loss": 0.0202,
      "step": 67690
    },
    {
      "epoch": 8.156626506024097,
      "grad_norm": 1.2588304281234741,
      "learning_rate": 3.6867469879518076e-06,
      "loss": 0.0312,
      "step": 67700
    },
    {
      "epoch": 8.157831325301204,
      "grad_norm": 0.0020058094523847103,
      "learning_rate": 3.684337349397591e-06,
      "loss": 0.0085,
      "step": 67710
    },
    {
      "epoch": 8.159036144578312,
      "grad_norm": 1.394641399383545,
      "learning_rate": 3.6819277108433735e-06,
      "loss": 0.0273,
      "step": 67720
    },
    {
      "epoch": 8.160240963855422,
      "grad_norm": 0.0009712197934277356,
      "learning_rate": 3.679518072289157e-06,
      "loss": 0.0017,
      "step": 67730
    },
    {
      "epoch": 8.16144578313253,
      "grad_norm": 0.0004472937434911728,
      "learning_rate": 3.67710843373494e-06,
      "loss": 0.0048,
      "step": 67740
    },
    {
      "epoch": 8.162650602409638,
      "grad_norm": 0.00033298583002761006,
      "learning_rate": 3.6746987951807235e-06,
      "loss": 0.0012,
      "step": 67750
    },
    {
      "epoch": 8.163855421686748,
      "grad_norm": 0.0016995444893836975,
      "learning_rate": 3.6722891566265063e-06,
      "loss": 0.0058,
      "step": 67760
    },
    {
      "epoch": 8.165060240963856,
      "grad_norm": 0.000541931891348213,
      "learning_rate": 3.6698795180722894e-06,
      "loss": 0.0201,
      "step": 67770
    },
    {
      "epoch": 8.166265060240963,
      "grad_norm": 0.027964439243078232,
      "learning_rate": 3.6674698795180726e-06,
      "loss": 0.0221,
      "step": 67780
    },
    {
      "epoch": 8.167469879518073,
      "grad_norm": 0.27668485045433044,
      "learning_rate": 3.6650602409638558e-06,
      "loss": 0.0103,
      "step": 67790
    },
    {
      "epoch": 8.168674698795181,
      "grad_norm": 0.001307233120314777,
      "learning_rate": 3.6626506024096385e-06,
      "loss": 0.0065,
      "step": 67800
    },
    {
      "epoch": 8.169879518072289,
      "grad_norm": 0.0007331807282753289,
      "learning_rate": 3.660240963855422e-06,
      "loss": 0.0152,
      "step": 67810
    },
    {
      "epoch": 8.171084337349397,
      "grad_norm": 0.6484794020652771,
      "learning_rate": 3.657831325301205e-06,
      "loss": 0.0045,
      "step": 67820
    },
    {
      "epoch": 8.172289156626507,
      "grad_norm": 2.4192287921905518,
      "learning_rate": 3.6554216867469885e-06,
      "loss": 0.0012,
      "step": 67830
    },
    {
      "epoch": 8.173493975903614,
      "grad_norm": 1.712892770767212,
      "learning_rate": 3.6530120481927712e-06,
      "loss": 0.0181,
      "step": 67840
    },
    {
      "epoch": 8.174698795180722,
      "grad_norm": 0.0390348955988884,
      "learning_rate": 3.6506024096385544e-06,
      "loss": 0.0023,
      "step": 67850
    },
    {
      "epoch": 8.175903614457832,
      "grad_norm": 0.0010500443167984486,
      "learning_rate": 3.648192771084338e-06,
      "loss": 0.0109,
      "step": 67860
    },
    {
      "epoch": 8.17710843373494,
      "grad_norm": 0.0004253471561241895,
      "learning_rate": 3.6457831325301208e-06,
      "loss": 0.0328,
      "step": 67870
    },
    {
      "epoch": 8.178313253012048,
      "grad_norm": 0.000605009263381362,
      "learning_rate": 3.643373493975904e-06,
      "loss": 0.0005,
      "step": 67880
    },
    {
      "epoch": 8.179518072289156,
      "grad_norm": 0.0005571826477535069,
      "learning_rate": 3.640963855421687e-06,
      "loss": 0.0045,
      "step": 67890
    },
    {
      "epoch": 8.180722891566266,
      "grad_norm": 0.001627625897526741,
      "learning_rate": 3.6385542168674703e-06,
      "loss": 0.0108,
      "step": 67900
    },
    {
      "epoch": 8.181927710843373,
      "grad_norm": 1.2396454811096191,
      "learning_rate": 3.636144578313253e-06,
      "loss": 0.0057,
      "step": 67910
    },
    {
      "epoch": 8.183132530120481,
      "grad_norm": 0.0003786790475714952,
      "learning_rate": 3.6337349397590366e-06,
      "loss": 0.0004,
      "step": 67920
    },
    {
      "epoch": 8.184337349397591,
      "grad_norm": 0.000579675892367959,
      "learning_rate": 3.6313253012048194e-06,
      "loss": 0.0083,
      "step": 67930
    },
    {
      "epoch": 8.185542168674699,
      "grad_norm": 0.00048000607057474554,
      "learning_rate": 3.628915662650603e-06,
      "loss": 0.001,
      "step": 67940
    },
    {
      "epoch": 8.186746987951807,
      "grad_norm": 0.0005784529494121671,
      "learning_rate": 3.6265060240963857e-06,
      "loss": 0.006,
      "step": 67950
    },
    {
      "epoch": 8.187951807228915,
      "grad_norm": 0.0004362257895991206,
      "learning_rate": 3.624096385542169e-06,
      "loss": 0.0203,
      "step": 67960
    },
    {
      "epoch": 8.189156626506024,
      "grad_norm": 2.285862922668457,
      "learning_rate": 3.6216867469879517e-06,
      "loss": 0.0008,
      "step": 67970
    },
    {
      "epoch": 8.190361445783132,
      "grad_norm": 0.004878388252109289,
      "learning_rate": 3.6192771084337353e-06,
      "loss": 0.014,
      "step": 67980
    },
    {
      "epoch": 8.19156626506024,
      "grad_norm": 0.011920002289116383,
      "learning_rate": 3.6168674698795185e-06,
      "loss": 0.005,
      "step": 67990
    },
    {
      "epoch": 8.19277108433735,
      "grad_norm": 2.104980945587158,
      "learning_rate": 3.6144578313253016e-06,
      "loss": 0.0346,
      "step": 68000
    },
    {
      "epoch": 8.193975903614458,
      "grad_norm": 0.0003444430185481906,
      "learning_rate": 3.612048192771085e-06,
      "loss": 0.0085,
      "step": 68010
    },
    {
      "epoch": 8.195180722891566,
      "grad_norm": 0.0004173939232714474,
      "learning_rate": 3.6096385542168676e-06,
      "loss": 0.0293,
      "step": 68020
    },
    {
      "epoch": 8.196385542168676,
      "grad_norm": 0.00037973103462718427,
      "learning_rate": 3.607228915662651e-06,
      "loss": 0.0203,
      "step": 68030
    },
    {
      "epoch": 8.197590361445783,
      "grad_norm": 1.6016803979873657,
      "learning_rate": 3.604819277108434e-06,
      "loss": 0.0148,
      "step": 68040
    },
    {
      "epoch": 8.198795180722891,
      "grad_norm": 0.0006735227070748806,
      "learning_rate": 3.6024096385542175e-06,
      "loss": 0.0527,
      "step": 68050
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.3177897930145264,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.0186,
      "step": 68060
    },
    {
      "epoch": 8.201204819277109,
      "grad_norm": 2.1785683631896973,
      "learning_rate": 3.5975903614457834e-06,
      "loss": 0.0292,
      "step": 68070
    },
    {
      "epoch": 8.202409638554217,
      "grad_norm": 1.6672046184539795,
      "learning_rate": 3.595180722891566e-06,
      "loss": 0.0118,
      "step": 68080
    },
    {
      "epoch": 8.203614457831325,
      "grad_norm": 0.0032252361997962,
      "learning_rate": 3.59277108433735e-06,
      "loss": 0.0098,
      "step": 68090
    },
    {
      "epoch": 8.204819277108435,
      "grad_norm": 2.0476431846618652,
      "learning_rate": 3.5903614457831325e-06,
      "loss": 0.0237,
      "step": 68100
    },
    {
      "epoch": 8.206024096385542,
      "grad_norm": 0.20273582637310028,
      "learning_rate": 3.587951807228916e-06,
      "loss": 0.0131,
      "step": 68110
    },
    {
      "epoch": 8.20722891566265,
      "grad_norm": 0.00590392854064703,
      "learning_rate": 3.585542168674699e-06,
      "loss": 0.0138,
      "step": 68120
    },
    {
      "epoch": 8.208433734939758,
      "grad_norm": 0.5699167847633362,
      "learning_rate": 3.583132530120482e-06,
      "loss": 0.0249,
      "step": 68130
    },
    {
      "epoch": 8.209638554216868,
      "grad_norm": 0.3319808840751648,
      "learning_rate": 3.5807228915662657e-06,
      "loss": 0.001,
      "step": 68140
    },
    {
      "epoch": 8.210843373493976,
      "grad_norm": 0.0004182853735983372,
      "learning_rate": 3.5783132530120484e-06,
      "loss": 0.0067,
      "step": 68150
    },
    {
      "epoch": 8.212048192771084,
      "grad_norm": 2.073007822036743,
      "learning_rate": 3.575903614457832e-06,
      "loss": 0.0237,
      "step": 68160
    },
    {
      "epoch": 8.213253012048193,
      "grad_norm": 0.10462885349988937,
      "learning_rate": 3.5734939759036148e-06,
      "loss": 0.0127,
      "step": 68170
    },
    {
      "epoch": 8.214457831325301,
      "grad_norm": 0.030957935377955437,
      "learning_rate": 3.571084337349398e-06,
      "loss": 0.0162,
      "step": 68180
    },
    {
      "epoch": 8.21566265060241,
      "grad_norm": 0.0005656196153722703,
      "learning_rate": 3.568674698795181e-06,
      "loss": 0.0138,
      "step": 68190
    },
    {
      "epoch": 8.216867469879517,
      "grad_norm": 0.7684860229492188,
      "learning_rate": 3.5662650602409643e-06,
      "loss": 0.0187,
      "step": 68200
    },
    {
      "epoch": 8.218072289156627,
      "grad_norm": 1.3378503322601318,
      "learning_rate": 3.563855421686747e-06,
      "loss": 0.0243,
      "step": 68210
    },
    {
      "epoch": 8.219277108433735,
      "grad_norm": 0.0008190348744392395,
      "learning_rate": 3.5614457831325307e-06,
      "loss": 0.0252,
      "step": 68220
    },
    {
      "epoch": 8.220481927710843,
      "grad_norm": 0.0016699995612725616,
      "learning_rate": 3.5590361445783134e-06,
      "loss": 0.0096,
      "step": 68230
    },
    {
      "epoch": 8.221686746987952,
      "grad_norm": 0.009006059728562832,
      "learning_rate": 3.5566265060240966e-06,
      "loss": 0.0182,
      "step": 68240
    },
    {
      "epoch": 8.22289156626506,
      "grad_norm": 1.9329828023910522,
      "learning_rate": 3.5542168674698798e-06,
      "loss": 0.0136,
      "step": 68250
    },
    {
      "epoch": 8.224096385542168,
      "grad_norm": 0.511661171913147,
      "learning_rate": 3.551807228915663e-06,
      "loss": 0.0075,
      "step": 68260
    },
    {
      "epoch": 8.225301204819278,
      "grad_norm": 0.21414141356945038,
      "learning_rate": 3.5493975903614457e-06,
      "loss": 0.0253,
      "step": 68270
    },
    {
      "epoch": 8.226506024096386,
      "grad_norm": 0.5596149563789368,
      "learning_rate": 3.5469879518072293e-06,
      "loss": 0.0264,
      "step": 68280
    },
    {
      "epoch": 8.227710843373494,
      "grad_norm": 0.638053834438324,
      "learning_rate": 3.5445783132530125e-06,
      "loss": 0.0039,
      "step": 68290
    },
    {
      "epoch": 8.228915662650602,
      "grad_norm": 4.0871968269348145,
      "learning_rate": 3.5421686746987956e-06,
      "loss": 0.0196,
      "step": 68300
    },
    {
      "epoch": 8.230120481927711,
      "grad_norm": 0.00821260828524828,
      "learning_rate": 3.539759036144579e-06,
      "loss": 0.0083,
      "step": 68310
    },
    {
      "epoch": 8.23132530120482,
      "grad_norm": 0.001683784881606698,
      "learning_rate": 3.5373493975903616e-06,
      "loss": 0.037,
      "step": 68320
    },
    {
      "epoch": 8.232530120481927,
      "grad_norm": 0.0036077341064810753,
      "learning_rate": 3.534939759036145e-06,
      "loss": 0.0012,
      "step": 68330
    },
    {
      "epoch": 8.233734939759037,
      "grad_norm": 0.0008616089471615851,
      "learning_rate": 3.532530120481928e-06,
      "loss": 0.0056,
      "step": 68340
    },
    {
      "epoch": 8.234939759036145,
      "grad_norm": 1.6961957216262817,
      "learning_rate": 3.530120481927711e-06,
      "loss": 0.0133,
      "step": 68350
    },
    {
      "epoch": 8.236144578313253,
      "grad_norm": 4.527821063995361,
      "learning_rate": 3.5277108433734943e-06,
      "loss": 0.0331,
      "step": 68360
    },
    {
      "epoch": 8.23734939759036,
      "grad_norm": 1.6794201135635376,
      "learning_rate": 3.5253012048192774e-06,
      "loss": 0.0077,
      "step": 68370
    },
    {
      "epoch": 8.23855421686747,
      "grad_norm": 0.359513521194458,
      "learning_rate": 3.52289156626506e-06,
      "loss": 0.0055,
      "step": 68380
    },
    {
      "epoch": 8.239759036144578,
      "grad_norm": 0.0004960342776030302,
      "learning_rate": 3.520481927710844e-06,
      "loss": 0.0023,
      "step": 68390
    },
    {
      "epoch": 8.240963855421686,
      "grad_norm": 0.0004614519129972905,
      "learning_rate": 3.5180722891566266e-06,
      "loss": 0.0011,
      "step": 68400
    },
    {
      "epoch": 8.242168674698796,
      "grad_norm": 0.001448737340979278,
      "learning_rate": 3.51566265060241e-06,
      "loss": 0.0048,
      "step": 68410
    },
    {
      "epoch": 8.243373493975904,
      "grad_norm": 0.0010725036263465881,
      "learning_rate": 3.513253012048193e-06,
      "loss": 0.0383,
      "step": 68420
    },
    {
      "epoch": 8.244578313253012,
      "grad_norm": 11.976022720336914,
      "learning_rate": 3.510843373493976e-06,
      "loss": 0.0284,
      "step": 68430
    },
    {
      "epoch": 8.24578313253012,
      "grad_norm": 0.9774320125579834,
      "learning_rate": 3.5084337349397597e-06,
      "loss": 0.0522,
      "step": 68440
    },
    {
      "epoch": 8.24698795180723,
      "grad_norm": 0.00364811928011477,
      "learning_rate": 3.5060240963855424e-06,
      "loss": 0.0151,
      "step": 68450
    },
    {
      "epoch": 8.248192771084337,
      "grad_norm": 0.39399054646492004,
      "learning_rate": 3.5036144578313256e-06,
      "loss": 0.0175,
      "step": 68460
    },
    {
      "epoch": 8.249397590361445,
      "grad_norm": 0.000705075275618583,
      "learning_rate": 3.5012048192771088e-06,
      "loss": 0.0246,
      "step": 68470
    },
    {
      "epoch": 8.250602409638555,
      "grad_norm": 0.00031996608595363796,
      "learning_rate": 3.498795180722892e-06,
      "loss": 0.0073,
      "step": 68480
    },
    {
      "epoch": 8.251807228915663,
      "grad_norm": 0.00038379395846277475,
      "learning_rate": 3.4963855421686747e-06,
      "loss": 0.007,
      "step": 68490
    },
    {
      "epoch": 8.25301204819277,
      "grad_norm": 0.0004363080661278218,
      "learning_rate": 3.4939759036144583e-06,
      "loss": 0.0332,
      "step": 68500
    },
    {
      "epoch": 8.25421686746988,
      "grad_norm": 0.001790695358067751,
      "learning_rate": 3.491566265060241e-06,
      "loss": 0.0008,
      "step": 68510
    },
    {
      "epoch": 8.255421686746988,
      "grad_norm": 1.9238948822021484,
      "learning_rate": 3.4891566265060247e-06,
      "loss": 0.0131,
      "step": 68520
    },
    {
      "epoch": 8.256626506024096,
      "grad_norm": 0.0006299906526692212,
      "learning_rate": 3.4867469879518074e-06,
      "loss": 0.0079,
      "step": 68530
    },
    {
      "epoch": 8.257831325301204,
      "grad_norm": 1.8835779428482056,
      "learning_rate": 3.4843373493975906e-06,
      "loss": 0.0127,
      "step": 68540
    },
    {
      "epoch": 8.259036144578314,
      "grad_norm": 0.0004053704906255007,
      "learning_rate": 3.4819277108433733e-06,
      "loss": 0.0217,
      "step": 68550
    },
    {
      "epoch": 8.260240963855422,
      "grad_norm": 0.001278273412026465,
      "learning_rate": 3.479518072289157e-06,
      "loss": 0.0087,
      "step": 68560
    },
    {
      "epoch": 8.26144578313253,
      "grad_norm": 0.0013533615274354815,
      "learning_rate": 3.4771084337349397e-06,
      "loss": 0.0036,
      "step": 68570
    },
    {
      "epoch": 8.26265060240964,
      "grad_norm": 0.00030417475500144064,
      "learning_rate": 3.4746987951807233e-06,
      "loss": 0.006,
      "step": 68580
    },
    {
      "epoch": 8.263855421686747,
      "grad_norm": 0.0005994791863486171,
      "learning_rate": 3.4722891566265065e-06,
      "loss": 0.0162,
      "step": 68590
    },
    {
      "epoch": 8.265060240963855,
      "grad_norm": 0.0003212935116607696,
      "learning_rate": 3.4698795180722892e-06,
      "loss": 0.0102,
      "step": 68600
    },
    {
      "epoch": 8.266265060240963,
      "grad_norm": 0.011014005169272423,
      "learning_rate": 3.467469879518073e-06,
      "loss": 0.0038,
      "step": 68610
    },
    {
      "epoch": 8.267469879518073,
      "grad_norm": 0.0011963588185608387,
      "learning_rate": 3.4650602409638556e-06,
      "loss": 0.023,
      "step": 68620
    },
    {
      "epoch": 8.26867469879518,
      "grad_norm": 0.7995592951774597,
      "learning_rate": 3.462650602409639e-06,
      "loss": 0.0119,
      "step": 68630
    },
    {
      "epoch": 8.269879518072289,
      "grad_norm": 0.2659035921096802,
      "learning_rate": 3.460240963855422e-06,
      "loss": 0.0047,
      "step": 68640
    },
    {
      "epoch": 8.271084337349398,
      "grad_norm": 0.38020604848861694,
      "learning_rate": 3.457831325301205e-06,
      "loss": 0.0106,
      "step": 68650
    },
    {
      "epoch": 8.272289156626506,
      "grad_norm": 1.6706621646881104,
      "learning_rate": 3.4554216867469883e-06,
      "loss": 0.009,
      "step": 68660
    },
    {
      "epoch": 8.273493975903614,
      "grad_norm": 2.8862671852111816,
      "learning_rate": 3.4530120481927715e-06,
      "loss": 0.0316,
      "step": 68670
    },
    {
      "epoch": 8.274698795180722,
      "grad_norm": 0.001112082740291953,
      "learning_rate": 3.450602409638554e-06,
      "loss": 0.0006,
      "step": 68680
    },
    {
      "epoch": 8.275903614457832,
      "grad_norm": 0.00027172351838089526,
      "learning_rate": 3.448192771084338e-06,
      "loss": 0.0153,
      "step": 68690
    },
    {
      "epoch": 8.27710843373494,
      "grad_norm": 0.00904180109500885,
      "learning_rate": 3.4457831325301206e-06,
      "loss": 0.0232,
      "step": 68700
    },
    {
      "epoch": 8.278313253012048,
      "grad_norm": 0.001627229037694633,
      "learning_rate": 3.4433734939759037e-06,
      "loss": 0.0049,
      "step": 68710
    },
    {
      "epoch": 8.279518072289157,
      "grad_norm": 0.0003229229187127203,
      "learning_rate": 3.440963855421687e-06,
      "loss": 0.001,
      "step": 68720
    },
    {
      "epoch": 8.280722891566265,
      "grad_norm": 0.0004467984545044601,
      "learning_rate": 3.43855421686747e-06,
      "loss": 0.0161,
      "step": 68730
    },
    {
      "epoch": 8.281927710843373,
      "grad_norm": 1.6649699211120605,
      "learning_rate": 3.4361445783132537e-06,
      "loss": 0.0262,
      "step": 68740
    },
    {
      "epoch": 8.283132530120483,
      "grad_norm": 0.0002505962329450995,
      "learning_rate": 3.4337349397590364e-06,
      "loss": 0.0064,
      "step": 68750
    },
    {
      "epoch": 8.28433734939759,
      "grad_norm": 0.24089489877223969,
      "learning_rate": 3.4313253012048196e-06,
      "loss": 0.0145,
      "step": 68760
    },
    {
      "epoch": 8.285542168674699,
      "grad_norm": 12.943103790283203,
      "learning_rate": 3.428915662650603e-06,
      "loss": 0.0356,
      "step": 68770
    },
    {
      "epoch": 8.286746987951807,
      "grad_norm": 0.00031881965696811676,
      "learning_rate": 3.426506024096386e-06,
      "loss": 0.0022,
      "step": 68780
    },
    {
      "epoch": 8.287951807228916,
      "grad_norm": 0.6688172817230225,
      "learning_rate": 3.4240963855421687e-06,
      "loss": 0.0097,
      "step": 68790
    },
    {
      "epoch": 8.289156626506024,
      "grad_norm": 0.0004634018987417221,
      "learning_rate": 3.4216867469879523e-06,
      "loss": 0.0025,
      "step": 68800
    },
    {
      "epoch": 8.290361445783132,
      "grad_norm": 0.00029486947460100055,
      "learning_rate": 3.419277108433735e-06,
      "loss": 0.0016,
      "step": 68810
    },
    {
      "epoch": 8.291566265060242,
      "grad_norm": 0.4528837502002716,
      "learning_rate": 3.4168674698795182e-06,
      "loss": 0.011,
      "step": 68820
    },
    {
      "epoch": 8.29277108433735,
      "grad_norm": 0.0024154193233698606,
      "learning_rate": 3.4144578313253014e-06,
      "loss": 0.0206,
      "step": 68830
    },
    {
      "epoch": 8.293975903614458,
      "grad_norm": 9.790233612060547,
      "learning_rate": 3.4120481927710846e-06,
      "loss": 0.0674,
      "step": 68840
    },
    {
      "epoch": 8.295180722891565,
      "grad_norm": 0.0007878726464696229,
      "learning_rate": 3.4096385542168674e-06,
      "loss": 0.0125,
      "step": 68850
    },
    {
      "epoch": 8.296385542168675,
      "grad_norm": 0.015195634216070175,
      "learning_rate": 3.407228915662651e-06,
      "loss": 0.0145,
      "step": 68860
    },
    {
      "epoch": 8.297590361445783,
      "grad_norm": 0.4857196807861328,
      "learning_rate": 3.4048192771084337e-06,
      "loss": 0.0141,
      "step": 68870
    },
    {
      "epoch": 8.298795180722891,
      "grad_norm": 0.0006940352031961083,
      "learning_rate": 3.4024096385542173e-06,
      "loss": 0.0097,
      "step": 68880
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.0004922073567286134,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0389,
      "step": 68890
    },
    {
      "epoch": 8.301204819277109,
      "grad_norm": 0.9677228927612305,
      "learning_rate": 3.3975903614457832e-06,
      "loss": 0.0301,
      "step": 68900
    },
    {
      "epoch": 8.302409638554217,
      "grad_norm": 0.001530861365608871,
      "learning_rate": 3.395180722891567e-06,
      "loss": 0.0177,
      "step": 68910
    },
    {
      "epoch": 8.303614457831324,
      "grad_norm": 2.1876776218414307,
      "learning_rate": 3.3927710843373496e-06,
      "loss": 0.016,
      "step": 68920
    },
    {
      "epoch": 8.304819277108434,
      "grad_norm": 0.0004913947777822614,
      "learning_rate": 3.390361445783133e-06,
      "loss": 0.0018,
      "step": 68930
    },
    {
      "epoch": 8.306024096385542,
      "grad_norm": 0.000515440187882632,
      "learning_rate": 3.387951807228916e-06,
      "loss": 0.0257,
      "step": 68940
    },
    {
      "epoch": 8.30722891566265,
      "grad_norm": 0.001080669229850173,
      "learning_rate": 3.385542168674699e-06,
      "loss": 0.0085,
      "step": 68950
    },
    {
      "epoch": 8.30843373493976,
      "grad_norm": 0.04876212775707245,
      "learning_rate": 3.383132530120482e-06,
      "loss": 0.0034,
      "step": 68960
    },
    {
      "epoch": 8.309638554216868,
      "grad_norm": 0.000648600806016475,
      "learning_rate": 3.3807228915662655e-06,
      "loss": 0.0053,
      "step": 68970
    },
    {
      "epoch": 8.310843373493976,
      "grad_norm": 0.5448865294456482,
      "learning_rate": 3.3783132530120482e-06,
      "loss": 0.0114,
      "step": 68980
    },
    {
      "epoch": 8.312048192771085,
      "grad_norm": 0.002906734123826027,
      "learning_rate": 3.375903614457832e-06,
      "loss": 0.0097,
      "step": 68990
    },
    {
      "epoch": 8.313253012048193,
      "grad_norm": 0.836890697479248,
      "learning_rate": 3.3734939759036146e-06,
      "loss": 0.0127,
      "step": 69000
    },
    {
      "epoch": 8.314457831325301,
      "grad_norm": 0.0022233810741454363,
      "learning_rate": 3.3710843373493977e-06,
      "loss": 0.0123,
      "step": 69010
    },
    {
      "epoch": 8.315662650602409,
      "grad_norm": 0.0005393428727984428,
      "learning_rate": 3.3686746987951813e-06,
      "loss": 0.0029,
      "step": 69020
    },
    {
      "epoch": 8.316867469879519,
      "grad_norm": 0.06294020265340805,
      "learning_rate": 3.366265060240964e-06,
      "loss": 0.0033,
      "step": 69030
    },
    {
      "epoch": 8.318072289156627,
      "grad_norm": 0.0003705412964336574,
      "learning_rate": 3.3638554216867477e-06,
      "loss": 0.0189,
      "step": 69040
    },
    {
      "epoch": 8.319277108433734,
      "grad_norm": 0.0004344258923083544,
      "learning_rate": 3.3614457831325305e-06,
      "loss": 0.0035,
      "step": 69050
    },
    {
      "epoch": 8.320481927710844,
      "grad_norm": 0.339827299118042,
      "learning_rate": 3.3590361445783136e-06,
      "loss": 0.0493,
      "step": 69060
    },
    {
      "epoch": 8.321686746987952,
      "grad_norm": 2.5206899642944336,
      "learning_rate": 3.3566265060240964e-06,
      "loss": 0.0219,
      "step": 69070
    },
    {
      "epoch": 8.32289156626506,
      "grad_norm": 0.22146527469158173,
      "learning_rate": 3.35421686746988e-06,
      "loss": 0.0089,
      "step": 69080
    },
    {
      "epoch": 8.324096385542168,
      "grad_norm": 0.3924049139022827,
      "learning_rate": 3.3518072289156627e-06,
      "loss": 0.0116,
      "step": 69090
    },
    {
      "epoch": 8.325301204819278,
      "grad_norm": 0.0004937516059726477,
      "learning_rate": 3.3493975903614463e-06,
      "loss": 0.009,
      "step": 69100
    },
    {
      "epoch": 8.326506024096386,
      "grad_norm": 0.21590952575206757,
      "learning_rate": 3.346987951807229e-06,
      "loss": 0.0216,
      "step": 69110
    },
    {
      "epoch": 8.327710843373493,
      "grad_norm": 0.6629891395568848,
      "learning_rate": 3.3445783132530123e-06,
      "loss": 0.0229,
      "step": 69120
    },
    {
      "epoch": 8.328915662650603,
      "grad_norm": 0.00040032286779023707,
      "learning_rate": 3.3421686746987954e-06,
      "loss": 0.013,
      "step": 69130
    },
    {
      "epoch": 8.330120481927711,
      "grad_norm": 1.7039824724197388,
      "learning_rate": 3.3397590361445786e-06,
      "loss": 0.0079,
      "step": 69140
    },
    {
      "epoch": 8.331325301204819,
      "grad_norm": 0.0004728294152300805,
      "learning_rate": 3.3373493975903614e-06,
      "loss": 0.015,
      "step": 69150
    },
    {
      "epoch": 8.332530120481927,
      "grad_norm": 4.950742721557617,
      "learning_rate": 3.334939759036145e-06,
      "loss": 0.0703,
      "step": 69160
    },
    {
      "epoch": 8.333734939759037,
      "grad_norm": 0.020209578797221184,
      "learning_rate": 3.332530120481928e-06,
      "loss": 0.0113,
      "step": 69170
    },
    {
      "epoch": 8.334939759036144,
      "grad_norm": 0.0007689628400839865,
      "learning_rate": 3.330120481927711e-06,
      "loss": 0.0123,
      "step": 69180
    },
    {
      "epoch": 8.336144578313252,
      "grad_norm": 0.0005803380045108497,
      "learning_rate": 3.3277108433734945e-06,
      "loss": 0.002,
      "step": 69190
    },
    {
      "epoch": 8.337349397590362,
      "grad_norm": 0.0008150783833116293,
      "learning_rate": 3.3253012048192772e-06,
      "loss": 0.0137,
      "step": 69200
    },
    {
      "epoch": 8.33855421686747,
      "grad_norm": 0.001007383456453681,
      "learning_rate": 3.322891566265061e-06,
      "loss": 0.0034,
      "step": 69210
    },
    {
      "epoch": 8.339759036144578,
      "grad_norm": 1.2800909280776978,
      "learning_rate": 3.3204819277108436e-06,
      "loss": 0.0075,
      "step": 69220
    },
    {
      "epoch": 8.340963855421688,
      "grad_norm": 0.00044594457722269,
      "learning_rate": 3.3180722891566268e-06,
      "loss": 0.0135,
      "step": 69230
    },
    {
      "epoch": 8.342168674698796,
      "grad_norm": 0.000561873777769506,
      "learning_rate": 3.31566265060241e-06,
      "loss": 0.021,
      "step": 69240
    },
    {
      "epoch": 8.343373493975903,
      "grad_norm": 0.3059309422969818,
      "learning_rate": 3.313253012048193e-06,
      "loss": 0.0037,
      "step": 69250
    },
    {
      "epoch": 8.344578313253011,
      "grad_norm": 0.00034073242568410933,
      "learning_rate": 3.310843373493976e-06,
      "loss": 0.0039,
      "step": 69260
    },
    {
      "epoch": 8.345783132530121,
      "grad_norm": 2.032017469406128,
      "learning_rate": 3.3084337349397595e-06,
      "loss": 0.0156,
      "step": 69270
    },
    {
      "epoch": 8.346987951807229,
      "grad_norm": 0.0003601537609938532,
      "learning_rate": 3.3060240963855422e-06,
      "loss": 0.0229,
      "step": 69280
    },
    {
      "epoch": 8.348192771084337,
      "grad_norm": 0.0037669893354177475,
      "learning_rate": 3.303614457831326e-06,
      "loss": 0.0135,
      "step": 69290
    },
    {
      "epoch": 8.349397590361447,
      "grad_norm": 1.0627065896987915,
      "learning_rate": 3.3012048192771086e-06,
      "loss": 0.0126,
      "step": 69300
    },
    {
      "epoch": 8.350602409638554,
      "grad_norm": 0.001090003876015544,
      "learning_rate": 3.2987951807228918e-06,
      "loss": 0.0074,
      "step": 69310
    },
    {
      "epoch": 8.351807228915662,
      "grad_norm": 1.890633463859558,
      "learning_rate": 3.2963855421686754e-06,
      "loss": 0.0196,
      "step": 69320
    },
    {
      "epoch": 8.35301204819277,
      "grad_norm": 0.000986649189144373,
      "learning_rate": 3.293975903614458e-06,
      "loss": 0.0211,
      "step": 69330
    },
    {
      "epoch": 8.35421686746988,
      "grad_norm": 1.5901869535446167,
      "learning_rate": 3.2915662650602413e-06,
      "loss": 0.0122,
      "step": 69340
    },
    {
      "epoch": 8.355421686746988,
      "grad_norm": 0.0004993897746317089,
      "learning_rate": 3.2891566265060245e-06,
      "loss": 0.0257,
      "step": 69350
    },
    {
      "epoch": 8.356626506024096,
      "grad_norm": 0.0004943735548295081,
      "learning_rate": 3.2867469879518076e-06,
      "loss": 0.0098,
      "step": 69360
    },
    {
      "epoch": 8.357831325301206,
      "grad_norm": 0.1758202612400055,
      "learning_rate": 3.2843373493975904e-06,
      "loss": 0.0111,
      "step": 69370
    },
    {
      "epoch": 8.359036144578313,
      "grad_norm": 0.0004356452263891697,
      "learning_rate": 3.281927710843374e-06,
      "loss": 0.0179,
      "step": 69380
    },
    {
      "epoch": 8.360240963855421,
      "grad_norm": 0.0005572843365371227,
      "learning_rate": 3.2795180722891567e-06,
      "loss": 0.0019,
      "step": 69390
    },
    {
      "epoch": 8.36144578313253,
      "grad_norm": 0.00041180779226124287,
      "learning_rate": 3.2771084337349403e-06,
      "loss": 0.0166,
      "step": 69400
    },
    {
      "epoch": 8.362650602409639,
      "grad_norm": 0.005895164329558611,
      "learning_rate": 3.274698795180723e-06,
      "loss": 0.0033,
      "step": 69410
    },
    {
      "epoch": 8.363855421686747,
      "grad_norm": 0.0005725221708416939,
      "learning_rate": 3.2722891566265063e-06,
      "loss": 0.0,
      "step": 69420
    },
    {
      "epoch": 8.365060240963855,
      "grad_norm": 1.6068750619888306,
      "learning_rate": 3.269879518072289e-06,
      "loss": 0.0134,
      "step": 69430
    },
    {
      "epoch": 8.366265060240965,
      "grad_norm": 0.5071731805801392,
      "learning_rate": 3.2674698795180726e-06,
      "loss": 0.0449,
      "step": 69440
    },
    {
      "epoch": 8.367469879518072,
      "grad_norm": 0.0014670167583972216,
      "learning_rate": 3.2650602409638554e-06,
      "loss": 0.0103,
      "step": 69450
    },
    {
      "epoch": 8.36867469879518,
      "grad_norm": 0.7660495042800903,
      "learning_rate": 3.262650602409639e-06,
      "loss": 0.0063,
      "step": 69460
    },
    {
      "epoch": 8.369879518072288,
      "grad_norm": 0.0004865546361543238,
      "learning_rate": 3.260240963855422e-06,
      "loss": 0.015,
      "step": 69470
    },
    {
      "epoch": 8.371084337349398,
      "grad_norm": 0.00029244268080219626,
      "learning_rate": 3.257831325301205e-06,
      "loss": 0.0192,
      "step": 69480
    },
    {
      "epoch": 8.372289156626506,
      "grad_norm": 0.0009688931168057024,
      "learning_rate": 3.2554216867469885e-06,
      "loss": 0.0028,
      "step": 69490
    },
    {
      "epoch": 8.373493975903614,
      "grad_norm": 0.00035077761276625097,
      "learning_rate": 3.2530120481927713e-06,
      "loss": 0.01,
      "step": 69500
    },
    {
      "epoch": 8.374698795180723,
      "grad_norm": 0.0004445811500772834,
      "learning_rate": 3.250602409638555e-06,
      "loss": 0.0127,
      "step": 69510
    },
    {
      "epoch": 8.375903614457831,
      "grad_norm": 3.0731358528137207,
      "learning_rate": 3.2481927710843376e-06,
      "loss": 0.0146,
      "step": 69520
    },
    {
      "epoch": 8.37710843373494,
      "grad_norm": 0.00041960529051721096,
      "learning_rate": 3.2457831325301208e-06,
      "loss": 0.0052,
      "step": 69530
    },
    {
      "epoch": 8.378313253012049,
      "grad_norm": 2.1583306789398193,
      "learning_rate": 3.2433734939759035e-06,
      "loss": 0.0196,
      "step": 69540
    },
    {
      "epoch": 8.379518072289157,
      "grad_norm": 0.0012884666211903095,
      "learning_rate": 3.240963855421687e-06,
      "loss": 0.0025,
      "step": 69550
    },
    {
      "epoch": 8.380722891566265,
      "grad_norm": 1.9683489799499512,
      "learning_rate": 3.23855421686747e-06,
      "loss": 0.0245,
      "step": 69560
    },
    {
      "epoch": 8.381927710843373,
      "grad_norm": 0.32609713077545166,
      "learning_rate": 3.2361445783132535e-06,
      "loss": 0.0041,
      "step": 69570
    },
    {
      "epoch": 8.383132530120482,
      "grad_norm": 0.0002636719145812094,
      "learning_rate": 3.2337349397590362e-06,
      "loss": 0.004,
      "step": 69580
    },
    {
      "epoch": 8.38433734939759,
      "grad_norm": 0.0013377071591094136,
      "learning_rate": 3.2313253012048194e-06,
      "loss": 0.0256,
      "step": 69590
    },
    {
      "epoch": 8.385542168674698,
      "grad_norm": 0.0014022981049492955,
      "learning_rate": 3.2289156626506026e-06,
      "loss": 0.0078,
      "step": 69600
    },
    {
      "epoch": 8.386746987951808,
      "grad_norm": 0.000638456316664815,
      "learning_rate": 3.2265060240963858e-06,
      "loss": 0.0179,
      "step": 69610
    },
    {
      "epoch": 8.387951807228916,
      "grad_norm": 0.006834168918430805,
      "learning_rate": 3.2240963855421694e-06,
      "loss": 0.0509,
      "step": 69620
    },
    {
      "epoch": 8.389156626506024,
      "grad_norm": 13.250267028808594,
      "learning_rate": 3.221686746987952e-06,
      "loss": 0.03,
      "step": 69630
    },
    {
      "epoch": 8.390361445783132,
      "grad_norm": 0.09628324955701828,
      "learning_rate": 3.2192771084337353e-06,
      "loss": 0.037,
      "step": 69640
    },
    {
      "epoch": 8.391566265060241,
      "grad_norm": 0.20051464438438416,
      "learning_rate": 3.216867469879518e-06,
      "loss": 0.0106,
      "step": 69650
    },
    {
      "epoch": 8.39277108433735,
      "grad_norm": 0.004906646907329559,
      "learning_rate": 3.2144578313253016e-06,
      "loss": 0.0421,
      "step": 69660
    },
    {
      "epoch": 8.393975903614457,
      "grad_norm": 0.03482603654265404,
      "learning_rate": 3.2120481927710844e-06,
      "loss": 0.0016,
      "step": 69670
    },
    {
      "epoch": 8.395180722891567,
      "grad_norm": 0.03926543891429901,
      "learning_rate": 3.209638554216868e-06,
      "loss": 0.0224,
      "step": 69680
    },
    {
      "epoch": 8.396385542168675,
      "grad_norm": 0.7125962376594543,
      "learning_rate": 3.2072289156626508e-06,
      "loss": 0.0051,
      "step": 69690
    },
    {
      "epoch": 8.397590361445783,
      "grad_norm": 1.5935591459274292,
      "learning_rate": 3.204819277108434e-06,
      "loss": 0.0152,
      "step": 69700
    },
    {
      "epoch": 8.398795180722892,
      "grad_norm": 0.00045762534136883914,
      "learning_rate": 3.202409638554217e-06,
      "loss": 0.0079,
      "step": 69710
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.4621276557445526,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0057,
      "step": 69720
    },
    {
      "epoch": 8.401204819277108,
      "grad_norm": 0.00044468199484981596,
      "learning_rate": 3.197590361445783e-06,
      "loss": 0.0052,
      "step": 69730
    },
    {
      "epoch": 8.402409638554216,
      "grad_norm": 0.11984667181968689,
      "learning_rate": 3.1951807228915666e-06,
      "loss": 0.002,
      "step": 69740
    },
    {
      "epoch": 8.403614457831326,
      "grad_norm": 0.0007248831097967923,
      "learning_rate": 3.1927710843373494e-06,
      "loss": 0.012,
      "step": 69750
    },
    {
      "epoch": 8.404819277108434,
      "grad_norm": 2.2903761863708496,
      "learning_rate": 3.190361445783133e-06,
      "loss": 0.0351,
      "step": 69760
    },
    {
      "epoch": 8.406024096385542,
      "grad_norm": 0.0006779179093427956,
      "learning_rate": 3.187951807228916e-06,
      "loss": 0.0092,
      "step": 69770
    },
    {
      "epoch": 8.407228915662651,
      "grad_norm": 1.8225396871566772,
      "learning_rate": 3.185542168674699e-06,
      "loss": 0.0106,
      "step": 69780
    },
    {
      "epoch": 8.40843373493976,
      "grad_norm": 0.00433573080226779,
      "learning_rate": 3.1831325301204825e-06,
      "loss": 0.0099,
      "step": 69790
    },
    {
      "epoch": 8.409638554216867,
      "grad_norm": 0.3566286861896515,
      "learning_rate": 3.1807228915662653e-06,
      "loss": 0.0098,
      "step": 69800
    },
    {
      "epoch": 8.410843373493975,
      "grad_norm": 1.506971001625061,
      "learning_rate": 3.1783132530120484e-06,
      "loss": 0.0126,
      "step": 69810
    },
    {
      "epoch": 8.412048192771085,
      "grad_norm": 1.9838628768920898,
      "learning_rate": 3.1759036144578316e-06,
      "loss": 0.0125,
      "step": 69820
    },
    {
      "epoch": 8.413253012048193,
      "grad_norm": 0.00038877417682670057,
      "learning_rate": 3.173493975903615e-06,
      "loss": 0.0071,
      "step": 69830
    },
    {
      "epoch": 8.4144578313253,
      "grad_norm": 0.00041228480404242873,
      "learning_rate": 3.1710843373493975e-06,
      "loss": 0.0131,
      "step": 69840
    },
    {
      "epoch": 8.41566265060241,
      "grad_norm": 0.35745927691459656,
      "learning_rate": 3.168674698795181e-06,
      "loss": 0.0268,
      "step": 69850
    },
    {
      "epoch": 8.416867469879518,
      "grad_norm": 3.3016884326934814,
      "learning_rate": 3.166265060240964e-06,
      "loss": 0.0261,
      "step": 69860
    },
    {
      "epoch": 8.418072289156626,
      "grad_norm": 0.00025178954820148647,
      "learning_rate": 3.1638554216867475e-06,
      "loss": 0.0218,
      "step": 69870
    },
    {
      "epoch": 8.419277108433734,
      "grad_norm": 0.1347011774778366,
      "learning_rate": 3.1614457831325302e-06,
      "loss": 0.025,
      "step": 69880
    },
    {
      "epoch": 8.420481927710844,
      "grad_norm": 0.00044616067316383123,
      "learning_rate": 3.1590361445783134e-06,
      "loss": 0.0292,
      "step": 69890
    },
    {
      "epoch": 8.421686746987952,
      "grad_norm": 0.0005070772022008896,
      "learning_rate": 3.156626506024096e-06,
      "loss": 0.0053,
      "step": 69900
    },
    {
      "epoch": 8.42289156626506,
      "grad_norm": 0.0004013260768260807,
      "learning_rate": 3.1542168674698798e-06,
      "loss": 0.0121,
      "step": 69910
    },
    {
      "epoch": 8.42409638554217,
      "grad_norm": 0.19589900970458984,
      "learning_rate": 3.151807228915663e-06,
      "loss": 0.0092,
      "step": 69920
    },
    {
      "epoch": 8.425301204819277,
      "grad_norm": 0.001074502943083644,
      "learning_rate": 3.149397590361446e-06,
      "loss": 0.0104,
      "step": 69930
    },
    {
      "epoch": 8.426506024096385,
      "grad_norm": 0.0004993634065613151,
      "learning_rate": 3.1469879518072293e-06,
      "loss": 0.0056,
      "step": 69940
    },
    {
      "epoch": 8.427710843373493,
      "grad_norm": 0.5398657321929932,
      "learning_rate": 3.144578313253012e-06,
      "loss": 0.0175,
      "step": 69950
    },
    {
      "epoch": 8.428915662650603,
      "grad_norm": 0.013841378502547741,
      "learning_rate": 3.1421686746987957e-06,
      "loss": 0.0207,
      "step": 69960
    },
    {
      "epoch": 8.43012048192771,
      "grad_norm": 0.13212603330612183,
      "learning_rate": 3.1397590361445784e-06,
      "loss": 0.0014,
      "step": 69970
    },
    {
      "epoch": 8.431325301204819,
      "grad_norm": 0.0008143874583765864,
      "learning_rate": 3.137349397590362e-06,
      "loss": 0.0032,
      "step": 69980
    },
    {
      "epoch": 8.432530120481928,
      "grad_norm": 0.0003497845900710672,
      "learning_rate": 3.1349397590361448e-06,
      "loss": 0.0239,
      "step": 69990
    },
    {
      "epoch": 8.433734939759036,
      "grad_norm": 0.0007966079865582287,
      "learning_rate": 3.132530120481928e-06,
      "loss": 0.0208,
      "step": 70000
    },
    {
      "epoch": 8.434939759036144,
      "grad_norm": 0.19354546070098877,
      "learning_rate": 3.1301204819277107e-06,
      "loss": 0.0242,
      "step": 70010
    },
    {
      "epoch": 8.436144578313254,
      "grad_norm": 0.8406350612640381,
      "learning_rate": 3.1277108433734943e-06,
      "loss": 0.0047,
      "step": 70020
    },
    {
      "epoch": 8.437349397590362,
      "grad_norm": 0.00864300224930048,
      "learning_rate": 3.125301204819277e-06,
      "loss": 0.0156,
      "step": 70030
    },
    {
      "epoch": 8.43855421686747,
      "grad_norm": 0.014431710354983807,
      "learning_rate": 3.1228915662650606e-06,
      "loss": 0.0105,
      "step": 70040
    },
    {
      "epoch": 8.439759036144578,
      "grad_norm": 0.0006079655140638351,
      "learning_rate": 3.120481927710844e-06,
      "loss": 0.0099,
      "step": 70050
    },
    {
      "epoch": 8.440963855421687,
      "grad_norm": 0.001474681543186307,
      "learning_rate": 3.1180722891566266e-06,
      "loss": 0.0175,
      "step": 70060
    },
    {
      "epoch": 8.442168674698795,
      "grad_norm": 0.0006543677882291377,
      "learning_rate": 3.11566265060241e-06,
      "loss": 0.0104,
      "step": 70070
    },
    {
      "epoch": 8.443373493975903,
      "grad_norm": 0.06657028198242188,
      "learning_rate": 3.113253012048193e-06,
      "loss": 0.0125,
      "step": 70080
    },
    {
      "epoch": 8.444578313253013,
      "grad_norm": 0.2885127663612366,
      "learning_rate": 3.1108433734939765e-06,
      "loss": 0.0074,
      "step": 70090
    },
    {
      "epoch": 8.44578313253012,
      "grad_norm": 1.63352370262146,
      "learning_rate": 3.1084337349397593e-06,
      "loss": 0.0186,
      "step": 70100
    },
    {
      "epoch": 8.446987951807229,
      "grad_norm": 0.24337071180343628,
      "learning_rate": 3.1060240963855424e-06,
      "loss": 0.0132,
      "step": 70110
    },
    {
      "epoch": 8.448192771084337,
      "grad_norm": 0.0005339423078112304,
      "learning_rate": 3.1036144578313256e-06,
      "loss": 0.0033,
      "step": 70120
    },
    {
      "epoch": 8.449397590361446,
      "grad_norm": 0.0006855802494101226,
      "learning_rate": 3.101204819277109e-06,
      "loss": 0.0057,
      "step": 70130
    },
    {
      "epoch": 8.450602409638554,
      "grad_norm": 0.000397645344492048,
      "learning_rate": 3.0987951807228916e-06,
      "loss": 0.0088,
      "step": 70140
    },
    {
      "epoch": 8.451807228915662,
      "grad_norm": 0.0014364056987687945,
      "learning_rate": 3.096385542168675e-06,
      "loss": 0.0087,
      "step": 70150
    },
    {
      "epoch": 8.453012048192772,
      "grad_norm": 0.0003362999705132097,
      "learning_rate": 3.093975903614458e-06,
      "loss": 0.0076,
      "step": 70160
    },
    {
      "epoch": 8.45421686746988,
      "grad_norm": 0.0015485381009057164,
      "learning_rate": 3.091566265060241e-06,
      "loss": 0.0101,
      "step": 70170
    },
    {
      "epoch": 8.455421686746988,
      "grad_norm": 0.14450174570083618,
      "learning_rate": 3.0891566265060243e-06,
      "loss": 0.0203,
      "step": 70180
    },
    {
      "epoch": 8.456626506024097,
      "grad_norm": 0.0002835439227055758,
      "learning_rate": 3.0867469879518074e-06,
      "loss": 0.0363,
      "step": 70190
    },
    {
      "epoch": 8.457831325301205,
      "grad_norm": 0.0004453787696547806,
      "learning_rate": 3.084337349397591e-06,
      "loss": 0.0214,
      "step": 70200
    },
    {
      "epoch": 8.459036144578313,
      "grad_norm": 0.000563542009331286,
      "learning_rate": 3.0819277108433738e-06,
      "loss": 0.0305,
      "step": 70210
    },
    {
      "epoch": 8.460240963855421,
      "grad_norm": 0.0005502665881067514,
      "learning_rate": 3.079518072289157e-06,
      "loss": 0.0135,
      "step": 70220
    },
    {
      "epoch": 8.46144578313253,
      "grad_norm": 0.0004732926608994603,
      "learning_rate": 3.07710843373494e-06,
      "loss": 0.0146,
      "step": 70230
    },
    {
      "epoch": 8.462650602409639,
      "grad_norm": 0.0003247301501687616,
      "learning_rate": 3.0746987951807233e-06,
      "loss": 0.0004,
      "step": 70240
    },
    {
      "epoch": 8.463855421686747,
      "grad_norm": 0.8338384032249451,
      "learning_rate": 3.072289156626506e-06,
      "loss": 0.013,
      "step": 70250
    },
    {
      "epoch": 8.465060240963856,
      "grad_norm": 0.0003858170530293137,
      "learning_rate": 3.0698795180722897e-06,
      "loss": 0.0035,
      "step": 70260
    },
    {
      "epoch": 8.466265060240964,
      "grad_norm": 0.0011504393769428134,
      "learning_rate": 3.0674698795180724e-06,
      "loss": 0.0017,
      "step": 70270
    },
    {
      "epoch": 8.467469879518072,
      "grad_norm": 0.0003209718270227313,
      "learning_rate": 3.0650602409638556e-06,
      "loss": 0.0076,
      "step": 70280
    },
    {
      "epoch": 8.46867469879518,
      "grad_norm": 0.8477876782417297,
      "learning_rate": 3.0626506024096388e-06,
      "loss": 0.0166,
      "step": 70290
    },
    {
      "epoch": 8.46987951807229,
      "grad_norm": 0.0004679987905547023,
      "learning_rate": 3.060240963855422e-06,
      "loss": 0.0071,
      "step": 70300
    },
    {
      "epoch": 8.471084337349398,
      "grad_norm": 18.178909301757812,
      "learning_rate": 3.0578313253012047e-06,
      "loss": 0.016,
      "step": 70310
    },
    {
      "epoch": 8.472289156626506,
      "grad_norm": 1.3206357955932617,
      "learning_rate": 3.0554216867469883e-06,
      "loss": 0.0297,
      "step": 70320
    },
    {
      "epoch": 8.473493975903615,
      "grad_norm": 0.0005144132301211357,
      "learning_rate": 3.053012048192771e-06,
      "loss": 0.0024,
      "step": 70330
    },
    {
      "epoch": 8.474698795180723,
      "grad_norm": 0.0003116873267572373,
      "learning_rate": 3.0506024096385547e-06,
      "loss": 0.0035,
      "step": 70340
    },
    {
      "epoch": 8.475903614457831,
      "grad_norm": 0.1212843582034111,
      "learning_rate": 3.048192771084338e-06,
      "loss": 0.0237,
      "step": 70350
    },
    {
      "epoch": 8.477108433734939,
      "grad_norm": 0.9145588874816895,
      "learning_rate": 3.0457831325301206e-06,
      "loss": 0.0041,
      "step": 70360
    },
    {
      "epoch": 8.478313253012049,
      "grad_norm": 0.00048545803292654455,
      "learning_rate": 3.043373493975904e-06,
      "loss": 0.0365,
      "step": 70370
    },
    {
      "epoch": 8.479518072289157,
      "grad_norm": 1.9120630025863647,
      "learning_rate": 3.040963855421687e-06,
      "loss": 0.0341,
      "step": 70380
    },
    {
      "epoch": 8.480722891566264,
      "grad_norm": 0.00040057263686321676,
      "learning_rate": 3.0385542168674705e-06,
      "loss": 0.0174,
      "step": 70390
    },
    {
      "epoch": 8.481927710843374,
      "grad_norm": 0.0007625276921316981,
      "learning_rate": 3.0361445783132533e-06,
      "loss": 0.0099,
      "step": 70400
    },
    {
      "epoch": 8.483132530120482,
      "grad_norm": 0.0008943815482780337,
      "learning_rate": 3.0337349397590365e-06,
      "loss": 0.0127,
      "step": 70410
    },
    {
      "epoch": 8.48433734939759,
      "grad_norm": 2.465444803237915,
      "learning_rate": 3.031325301204819e-06,
      "loss": 0.03,
      "step": 70420
    },
    {
      "epoch": 8.485542168674698,
      "grad_norm": 2.2276816368103027,
      "learning_rate": 3.028915662650603e-06,
      "loss": 0.0089,
      "step": 70430
    },
    {
      "epoch": 8.486746987951808,
      "grad_norm": 0.5209680795669556,
      "learning_rate": 3.0265060240963856e-06,
      "loss": 0.01,
      "step": 70440
    },
    {
      "epoch": 8.487951807228916,
      "grad_norm": 0.000620298320427537,
      "learning_rate": 3.024096385542169e-06,
      "loss": 0.003,
      "step": 70450
    },
    {
      "epoch": 8.489156626506023,
      "grad_norm": 1.25252366065979,
      "learning_rate": 3.021686746987952e-06,
      "loss": 0.0199,
      "step": 70460
    },
    {
      "epoch": 8.490361445783133,
      "grad_norm": 7.771941184997559,
      "learning_rate": 3.019277108433735e-06,
      "loss": 0.053,
      "step": 70470
    },
    {
      "epoch": 8.491566265060241,
      "grad_norm": 0.02594977244734764,
      "learning_rate": 3.0168674698795183e-06,
      "loss": 0.0144,
      "step": 70480
    },
    {
      "epoch": 8.492771084337349,
      "grad_norm": 0.00040932404226623476,
      "learning_rate": 3.0144578313253014e-06,
      "loss": 0.0066,
      "step": 70490
    },
    {
      "epoch": 8.493975903614459,
      "grad_norm": 0.0003503489133436233,
      "learning_rate": 3.012048192771085e-06,
      "loss": 0.021,
      "step": 70500
    },
    {
      "epoch": 8.495180722891567,
      "grad_norm": 0.0001906563265947625,
      "learning_rate": 3.009638554216868e-06,
      "loss": 0.011,
      "step": 70510
    },
    {
      "epoch": 8.496385542168674,
      "grad_norm": 0.7871924042701721,
      "learning_rate": 3.007228915662651e-06,
      "loss": 0.0132,
      "step": 70520
    },
    {
      "epoch": 8.497590361445782,
      "grad_norm": 1.2144540548324585,
      "learning_rate": 3.0048192771084337e-06,
      "loss": 0.0344,
      "step": 70530
    },
    {
      "epoch": 8.498795180722892,
      "grad_norm": 0.00037444947520270944,
      "learning_rate": 3.0024096385542173e-06,
      "loss": 0.0072,
      "step": 70540
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.0003155643353238702,
      "learning_rate": 3e-06,
      "loss": 0.003,
      "step": 70550
    },
    {
      "epoch": 8.501204819277108,
      "grad_norm": 3.9977152347564697,
      "learning_rate": 2.9975903614457837e-06,
      "loss": 0.0123,
      "step": 70560
    },
    {
      "epoch": 8.502409638554218,
      "grad_norm": 0.22938700020313263,
      "learning_rate": 2.9951807228915664e-06,
      "loss": 0.0245,
      "step": 70570
    },
    {
      "epoch": 8.503614457831326,
      "grad_norm": 2.3685874938964844,
      "learning_rate": 2.9927710843373496e-06,
      "loss": 0.0146,
      "step": 70580
    },
    {
      "epoch": 8.504819277108433,
      "grad_norm": 0.00043537880992516875,
      "learning_rate": 2.9903614457831328e-06,
      "loss": 0.0004,
      "step": 70590
    },
    {
      "epoch": 8.506024096385541,
      "grad_norm": 0.00042521272553130984,
      "learning_rate": 2.987951807228916e-06,
      "loss": 0.0122,
      "step": 70600
    },
    {
      "epoch": 8.507228915662651,
      "grad_norm": 0.00026114797219634056,
      "learning_rate": 2.9855421686746987e-06,
      "loss": 0.005,
      "step": 70610
    },
    {
      "epoch": 8.508433734939759,
      "grad_norm": 0.00026252566021867096,
      "learning_rate": 2.9831325301204823e-06,
      "loss": 0.0054,
      "step": 70620
    },
    {
      "epoch": 8.509638554216867,
      "grad_norm": 0.706534743309021,
      "learning_rate": 2.980722891566265e-06,
      "loss": 0.027,
      "step": 70630
    },
    {
      "epoch": 8.510843373493977,
      "grad_norm": 0.1213616356253624,
      "learning_rate": 2.9783132530120482e-06,
      "loss": 0.0172,
      "step": 70640
    },
    {
      "epoch": 8.512048192771084,
      "grad_norm": 0.0009193247533403337,
      "learning_rate": 2.975903614457832e-06,
      "loss": 0.0176,
      "step": 70650
    },
    {
      "epoch": 8.513253012048192,
      "grad_norm": 0.1454981118440628,
      "learning_rate": 2.9734939759036146e-06,
      "loss": 0.0003,
      "step": 70660
    },
    {
      "epoch": 8.514457831325302,
      "grad_norm": 0.002610081573948264,
      "learning_rate": 2.971084337349398e-06,
      "loss": 0.0122,
      "step": 70670
    },
    {
      "epoch": 8.51566265060241,
      "grad_norm": 0.9461256861686707,
      "learning_rate": 2.968674698795181e-06,
      "loss": 0.0055,
      "step": 70680
    },
    {
      "epoch": 8.516867469879518,
      "grad_norm": 0.00033625008654780686,
      "learning_rate": 2.966265060240964e-06,
      "loss": 0.0054,
      "step": 70690
    },
    {
      "epoch": 8.518072289156626,
      "grad_norm": 0.00042983144521713257,
      "learning_rate": 2.9638554216867473e-06,
      "loss": 0.0045,
      "step": 70700
    },
    {
      "epoch": 8.519277108433736,
      "grad_norm": 0.00026829808484762907,
      "learning_rate": 2.9614457831325305e-06,
      "loss": 0.0068,
      "step": 70710
    },
    {
      "epoch": 8.520481927710843,
      "grad_norm": 0.000281613232800737,
      "learning_rate": 2.9590361445783132e-06,
      "loss": 0.0044,
      "step": 70720
    },
    {
      "epoch": 8.521686746987951,
      "grad_norm": 0.0009684803080745041,
      "learning_rate": 2.956626506024097e-06,
      "loss": 0.0017,
      "step": 70730
    },
    {
      "epoch": 8.522891566265061,
      "grad_norm": 0.00024342078540939838,
      "learning_rate": 2.9542168674698796e-06,
      "loss": 0.0029,
      "step": 70740
    },
    {
      "epoch": 8.524096385542169,
      "grad_norm": 0.0003012406814377755,
      "learning_rate": 2.9518072289156627e-06,
      "loss": 0.0003,
      "step": 70750
    },
    {
      "epoch": 8.525301204819277,
      "grad_norm": 1.6720916032791138,
      "learning_rate": 2.949397590361446e-06,
      "loss": 0.0046,
      "step": 70760
    },
    {
      "epoch": 8.526506024096385,
      "grad_norm": 0.30454227328300476,
      "learning_rate": 2.946987951807229e-06,
      "loss": 0.0031,
      "step": 70770
    },
    {
      "epoch": 8.527710843373494,
      "grad_norm": 0.0002741609059739858,
      "learning_rate": 2.944578313253012e-06,
      "loss": 0.0245,
      "step": 70780
    },
    {
      "epoch": 8.528915662650602,
      "grad_norm": 0.0003144489601254463,
      "learning_rate": 2.9421686746987955e-06,
      "loss": 0.004,
      "step": 70790
    },
    {
      "epoch": 8.53012048192771,
      "grad_norm": 0.0003771832271013409,
      "learning_rate": 2.9397590361445786e-06,
      "loss": 0.0018,
      "step": 70800
    },
    {
      "epoch": 8.53132530120482,
      "grad_norm": 0.0026204176247119904,
      "learning_rate": 2.937349397590362e-06,
      "loss": 0.0044,
      "step": 70810
    },
    {
      "epoch": 8.532530120481928,
      "grad_norm": 0.0003256219788454473,
      "learning_rate": 2.934939759036145e-06,
      "loss": 0.0035,
      "step": 70820
    },
    {
      "epoch": 8.533734939759036,
      "grad_norm": 3.7457547187805176,
      "learning_rate": 2.9325301204819277e-06,
      "loss": 0.0107,
      "step": 70830
    },
    {
      "epoch": 8.534939759036144,
      "grad_norm": 22.126028060913086,
      "learning_rate": 2.9301204819277113e-06,
      "loss": 0.0108,
      "step": 70840
    },
    {
      "epoch": 8.536144578313253,
      "grad_norm": 0.0002907360321842134,
      "learning_rate": 2.927710843373494e-06,
      "loss": 0.0075,
      "step": 70850
    },
    {
      "epoch": 8.537349397590361,
      "grad_norm": 0.00036506992182694376,
      "learning_rate": 2.9253012048192777e-06,
      "loss": 0.012,
      "step": 70860
    },
    {
      "epoch": 8.53855421686747,
      "grad_norm": 0.20130406320095062,
      "learning_rate": 2.9228915662650604e-06,
      "loss": 0.0061,
      "step": 70870
    },
    {
      "epoch": 8.539759036144579,
      "grad_norm": 0.23004068434238434,
      "learning_rate": 2.9204819277108436e-06,
      "loss": 0.0012,
      "step": 70880
    },
    {
      "epoch": 8.540963855421687,
      "grad_norm": 0.00038061212399043143,
      "learning_rate": 2.9180722891566264e-06,
      "loss": 0.0091,
      "step": 70890
    },
    {
      "epoch": 8.542168674698795,
      "grad_norm": 1.1377393007278442,
      "learning_rate": 2.91566265060241e-06,
      "loss": 0.03,
      "step": 70900
    },
    {
      "epoch": 8.543373493975903,
      "grad_norm": 1.759585976600647,
      "learning_rate": 2.9132530120481927e-06,
      "loss": 0.0141,
      "step": 70910
    },
    {
      "epoch": 8.544578313253012,
      "grad_norm": 0.2425076812505722,
      "learning_rate": 2.9108433734939763e-06,
      "loss": 0.0121,
      "step": 70920
    },
    {
      "epoch": 8.54578313253012,
      "grad_norm": 0.00037142939982004464,
      "learning_rate": 2.908433734939759e-06,
      "loss": 0.0063,
      "step": 70930
    },
    {
      "epoch": 8.546987951807228,
      "grad_norm": 1.5287394523620605,
      "learning_rate": 2.9060240963855422e-06,
      "loss": 0.0077,
      "step": 70940
    },
    {
      "epoch": 8.548192771084338,
      "grad_norm": 0.00048418043297715485,
      "learning_rate": 2.903614457831326e-06,
      "loss": 0.015,
      "step": 70950
    },
    {
      "epoch": 8.549397590361446,
      "grad_norm": 0.7960522174835205,
      "learning_rate": 2.9012048192771086e-06,
      "loss": 0.0149,
      "step": 70960
    },
    {
      "epoch": 8.550602409638554,
      "grad_norm": 0.0005084233707748353,
      "learning_rate": 2.898795180722892e-06,
      "loss": 0.0437,
      "step": 70970
    },
    {
      "epoch": 8.551807228915663,
      "grad_norm": 0.0008389037102460861,
      "learning_rate": 2.896385542168675e-06,
      "loss": 0.0061,
      "step": 70980
    },
    {
      "epoch": 8.553012048192771,
      "grad_norm": 0.0004476769536267966,
      "learning_rate": 2.893975903614458e-06,
      "loss": 0.0207,
      "step": 70990
    },
    {
      "epoch": 8.55421686746988,
      "grad_norm": 1.0584430694580078,
      "learning_rate": 2.891566265060241e-06,
      "loss": 0.0062,
      "step": 71000
    },
    {
      "epoch": 8.555421686746987,
      "grad_norm": 1.820392370223999,
      "learning_rate": 2.8891566265060245e-06,
      "loss": 0.0238,
      "step": 71010
    },
    {
      "epoch": 8.556626506024097,
      "grad_norm": 0.00037825529580004513,
      "learning_rate": 2.8867469879518072e-06,
      "loss": 0.0079,
      "step": 71020
    },
    {
      "epoch": 8.557831325301205,
      "grad_norm": 2.2784242630004883,
      "learning_rate": 2.884337349397591e-06,
      "loss": 0.0524,
      "step": 71030
    },
    {
      "epoch": 8.559036144578313,
      "grad_norm": 0.0014178380370140076,
      "learning_rate": 2.8819277108433736e-06,
      "loss": 0.0038,
      "step": 71040
    },
    {
      "epoch": 8.560240963855422,
      "grad_norm": 0.0002838239015545696,
      "learning_rate": 2.8795180722891568e-06,
      "loss": 0.0066,
      "step": 71050
    },
    {
      "epoch": 8.56144578313253,
      "grad_norm": 0.0003197448677383363,
      "learning_rate": 2.87710843373494e-06,
      "loss": 0.0127,
      "step": 71060
    },
    {
      "epoch": 8.562650602409638,
      "grad_norm": 0.0004580929526127875,
      "learning_rate": 2.874698795180723e-06,
      "loss": 0.0128,
      "step": 71070
    },
    {
      "epoch": 8.563855421686746,
      "grad_norm": 9.297038078308105,
      "learning_rate": 2.8722891566265067e-06,
      "loss": 0.0137,
      "step": 71080
    },
    {
      "epoch": 8.565060240963856,
      "grad_norm": 0.0003076377615798265,
      "learning_rate": 2.8698795180722895e-06,
      "loss": 0.0054,
      "step": 71090
    },
    {
      "epoch": 8.566265060240964,
      "grad_norm": 0.00016826372302602977,
      "learning_rate": 2.8674698795180726e-06,
      "loss": 0.0262,
      "step": 71100
    },
    {
      "epoch": 8.567469879518072,
      "grad_norm": 0.8166857361793518,
      "learning_rate": 2.8650602409638554e-06,
      "loss": 0.0114,
      "step": 71110
    },
    {
      "epoch": 8.568674698795181,
      "grad_norm": 0.0003082005132455379,
      "learning_rate": 2.862650602409639e-06,
      "loss": 0.0197,
      "step": 71120
    },
    {
      "epoch": 8.56987951807229,
      "grad_norm": 0.00035195949021726847,
      "learning_rate": 2.8602409638554217e-06,
      "loss": 0.0354,
      "step": 71130
    },
    {
      "epoch": 8.571084337349397,
      "grad_norm": 0.00036559085128828883,
      "learning_rate": 2.8578313253012053e-06,
      "loss": 0.042,
      "step": 71140
    },
    {
      "epoch": 8.572289156626507,
      "grad_norm": 1.683253288269043,
      "learning_rate": 2.855421686746988e-06,
      "loss": 0.0075,
      "step": 71150
    },
    {
      "epoch": 8.573493975903615,
      "grad_norm": 0.018594447523355484,
      "learning_rate": 2.8530120481927713e-06,
      "loss": 0.0039,
      "step": 71160
    },
    {
      "epoch": 8.574698795180723,
      "grad_norm": 0.0003347580204717815,
      "learning_rate": 2.8506024096385544e-06,
      "loss": 0.0192,
      "step": 71170
    },
    {
      "epoch": 8.57590361445783,
      "grad_norm": 0.003688061609864235,
      "learning_rate": 2.8481927710843376e-06,
      "loss": 0.0061,
      "step": 71180
    },
    {
      "epoch": 8.57710843373494,
      "grad_norm": 0.00026811170391738415,
      "learning_rate": 2.8457831325301204e-06,
      "loss": 0.0209,
      "step": 71190
    },
    {
      "epoch": 8.578313253012048,
      "grad_norm": 0.00020761990163009614,
      "learning_rate": 2.843373493975904e-06,
      "loss": 0.0217,
      "step": 71200
    },
    {
      "epoch": 8.579518072289156,
      "grad_norm": 0.00021813275816384703,
      "learning_rate": 2.8409638554216867e-06,
      "loss": 0.0155,
      "step": 71210
    },
    {
      "epoch": 8.580722891566266,
      "grad_norm": 1.096293568611145,
      "learning_rate": 2.8385542168674703e-06,
      "loss": 0.0168,
      "step": 71220
    },
    {
      "epoch": 8.581927710843374,
      "grad_norm": 0.00022949211415834725,
      "learning_rate": 2.8361445783132535e-06,
      "loss": 0.0161,
      "step": 71230
    },
    {
      "epoch": 8.583132530120482,
      "grad_norm": 1.0356730222702026,
      "learning_rate": 2.8337349397590363e-06,
      "loss": 0.0059,
      "step": 71240
    },
    {
      "epoch": 8.58433734939759,
      "grad_norm": 0.0003008147468790412,
      "learning_rate": 2.83132530120482e-06,
      "loss": 0.0168,
      "step": 71250
    },
    {
      "epoch": 8.5855421686747,
      "grad_norm": 0.00037882252945564687,
      "learning_rate": 2.8289156626506026e-06,
      "loss": 0.0177,
      "step": 71260
    },
    {
      "epoch": 8.586746987951807,
      "grad_norm": 0.2565755248069763,
      "learning_rate": 2.8265060240963858e-06,
      "loss": 0.0243,
      "step": 71270
    },
    {
      "epoch": 8.587951807228915,
      "grad_norm": 0.0004248518671374768,
      "learning_rate": 2.824096385542169e-06,
      "loss": 0.0021,
      "step": 71280
    },
    {
      "epoch": 8.589156626506025,
      "grad_norm": 84.4929428100586,
      "learning_rate": 2.821686746987952e-06,
      "loss": 0.0192,
      "step": 71290
    },
    {
      "epoch": 8.590361445783133,
      "grad_norm": 0.000995142851024866,
      "learning_rate": 2.819277108433735e-06,
      "loss": 0.0121,
      "step": 71300
    },
    {
      "epoch": 8.59156626506024,
      "grad_norm": 0.0005173460813239217,
      "learning_rate": 2.8168674698795185e-06,
      "loss": 0.0249,
      "step": 71310
    },
    {
      "epoch": 8.592771084337349,
      "grad_norm": 1.0186822414398193,
      "learning_rate": 2.8144578313253012e-06,
      "loss": 0.0038,
      "step": 71320
    },
    {
      "epoch": 8.593975903614458,
      "grad_norm": 1.6736509799957275,
      "learning_rate": 2.812048192771085e-06,
      "loss": 0.0062,
      "step": 71330
    },
    {
      "epoch": 8.595180722891566,
      "grad_norm": 2.4265666007995605,
      "learning_rate": 2.8096385542168676e-06,
      "loss": 0.0421,
      "step": 71340
    },
    {
      "epoch": 8.596385542168674,
      "grad_norm": 0.0003654448955785483,
      "learning_rate": 2.8072289156626508e-06,
      "loss": 0.0097,
      "step": 71350
    },
    {
      "epoch": 8.597590361445784,
      "grad_norm": 0.0003644367097876966,
      "learning_rate": 2.8048192771084335e-06,
      "loss": 0.006,
      "step": 71360
    },
    {
      "epoch": 8.598795180722892,
      "grad_norm": 0.0004728827334474772,
      "learning_rate": 2.802409638554217e-06,
      "loss": 0.0205,
      "step": 71370
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.0023708397056907415,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0114,
      "step": 71380
    },
    {
      "epoch": 8.601204819277108,
      "grad_norm": 0.00028811031370423734,
      "learning_rate": 2.7975903614457835e-06,
      "loss": 0.0139,
      "step": 71390
    },
    {
      "epoch": 8.602409638554217,
      "grad_norm": 0.00024425520678050816,
      "learning_rate": 2.7951807228915666e-06,
      "loss": 0.0016,
      "step": 71400
    },
    {
      "epoch": 8.603614457831325,
      "grad_norm": 2.4168787002563477,
      "learning_rate": 2.7927710843373494e-06,
      "loss": 0.0211,
      "step": 71410
    },
    {
      "epoch": 8.604819277108433,
      "grad_norm": 1.9220298528671265,
      "learning_rate": 2.790361445783133e-06,
      "loss": 0.0107,
      "step": 71420
    },
    {
      "epoch": 8.606024096385543,
      "grad_norm": 1.1078987121582031,
      "learning_rate": 2.7879518072289158e-06,
      "loss": 0.012,
      "step": 71430
    },
    {
      "epoch": 8.60722891566265,
      "grad_norm": 0.0003751676995307207,
      "learning_rate": 2.7855421686746994e-06,
      "loss": 0.0315,
      "step": 71440
    },
    {
      "epoch": 8.608433734939759,
      "grad_norm": 1.3705333471298218,
      "learning_rate": 2.783132530120482e-06,
      "loss": 0.0154,
      "step": 71450
    },
    {
      "epoch": 8.609638554216868,
      "grad_norm": 0.0006783120334148407,
      "learning_rate": 2.7807228915662653e-06,
      "loss": 0.0023,
      "step": 71460
    },
    {
      "epoch": 8.610843373493976,
      "grad_norm": 0.001243087463080883,
      "learning_rate": 2.778313253012048e-06,
      "loss": 0.0228,
      "step": 71470
    },
    {
      "epoch": 8.612048192771084,
      "grad_norm": 2.186206579208374,
      "learning_rate": 2.7759036144578316e-06,
      "loss": 0.0179,
      "step": 71480
    },
    {
      "epoch": 8.613253012048192,
      "grad_norm": 0.04874975234270096,
      "learning_rate": 2.7734939759036144e-06,
      "loss": 0.0014,
      "step": 71490
    },
    {
      "epoch": 8.614457831325302,
      "grad_norm": 0.0002791105071082711,
      "learning_rate": 2.771084337349398e-06,
      "loss": 0.0027,
      "step": 71500
    },
    {
      "epoch": 8.61566265060241,
      "grad_norm": 0.00042528932681307197,
      "learning_rate": 2.7686746987951807e-06,
      "loss": 0.0169,
      "step": 71510
    },
    {
      "epoch": 8.616867469879518,
      "grad_norm": 0.0002604131295811385,
      "learning_rate": 2.766265060240964e-06,
      "loss": 0.0049,
      "step": 71520
    },
    {
      "epoch": 8.618072289156627,
      "grad_norm": 0.0005881288088858128,
      "learning_rate": 2.7638554216867475e-06,
      "loss": 0.0004,
      "step": 71530
    },
    {
      "epoch": 8.619277108433735,
      "grad_norm": 0.000916648015845567,
      "learning_rate": 2.7614457831325303e-06,
      "loss": 0.0082,
      "step": 71540
    },
    {
      "epoch": 8.620481927710843,
      "grad_norm": 0.00024399743415415287,
      "learning_rate": 2.759036144578314e-06,
      "loss": 0.02,
      "step": 71550
    },
    {
      "epoch": 8.621686746987951,
      "grad_norm": 3.294861078262329,
      "learning_rate": 2.7566265060240966e-06,
      "loss": 0.0252,
      "step": 71560
    },
    {
      "epoch": 8.62289156626506,
      "grad_norm": 1.986221194267273,
      "learning_rate": 2.75421686746988e-06,
      "loss": 0.0136,
      "step": 71570
    },
    {
      "epoch": 8.624096385542169,
      "grad_norm": 0.00017822027439251542,
      "learning_rate": 2.751807228915663e-06,
      "loss": 0.0095,
      "step": 71580
    },
    {
      "epoch": 8.625301204819277,
      "grad_norm": 0.4155895709991455,
      "learning_rate": 2.749397590361446e-06,
      "loss": 0.0028,
      "step": 71590
    },
    {
      "epoch": 8.626506024096386,
      "grad_norm": 0.00127981451805681,
      "learning_rate": 2.746987951807229e-06,
      "loss": 0.0012,
      "step": 71600
    },
    {
      "epoch": 8.627710843373494,
      "grad_norm": 0.00031290436163544655,
      "learning_rate": 2.7445783132530125e-06,
      "loss": 0.0141,
      "step": 71610
    },
    {
      "epoch": 8.628915662650602,
      "grad_norm": 0.0022834523115307093,
      "learning_rate": 2.7421686746987953e-06,
      "loss": 0.0135,
      "step": 71620
    },
    {
      "epoch": 8.630120481927712,
      "grad_norm": 0.00024673345615155995,
      "learning_rate": 2.7397590361445784e-06,
      "loss": 0.0154,
      "step": 71630
    },
    {
      "epoch": 8.63132530120482,
      "grad_norm": 0.0014999289996922016,
      "learning_rate": 2.7373493975903616e-06,
      "loss": 0.021,
      "step": 71640
    },
    {
      "epoch": 8.632530120481928,
      "grad_norm": 0.0003033851971849799,
      "learning_rate": 2.7349397590361448e-06,
      "loss": 0.0003,
      "step": 71650
    },
    {
      "epoch": 8.633734939759035,
      "grad_norm": 0.16548629105091095,
      "learning_rate": 2.7325301204819275e-06,
      "loss": 0.0047,
      "step": 71660
    },
    {
      "epoch": 8.634939759036145,
      "grad_norm": 0.00024663223302923143,
      "learning_rate": 2.730120481927711e-06,
      "loss": 0.0114,
      "step": 71670
    },
    {
      "epoch": 8.636144578313253,
      "grad_norm": 0.00026012686430476606,
      "learning_rate": 2.7277108433734943e-06,
      "loss": 0.001,
      "step": 71680
    },
    {
      "epoch": 8.637349397590361,
      "grad_norm": 0.006132899783551693,
      "learning_rate": 2.7253012048192775e-06,
      "loss": 0.0021,
      "step": 71690
    },
    {
      "epoch": 8.638554216867469,
      "grad_norm": 0.001492579118348658,
      "learning_rate": 2.7228915662650607e-06,
      "loss": 0.0071,
      "step": 71700
    },
    {
      "epoch": 8.639759036144579,
      "grad_norm": 0.0004702179576270282,
      "learning_rate": 2.7204819277108434e-06,
      "loss": 0.0093,
      "step": 71710
    },
    {
      "epoch": 8.640963855421687,
      "grad_norm": 0.00037227850407361984,
      "learning_rate": 2.718072289156627e-06,
      "loss": 0.0156,
      "step": 71720
    },
    {
      "epoch": 8.642168674698794,
      "grad_norm": 0.0009153838036581874,
      "learning_rate": 2.7156626506024098e-06,
      "loss": 0.014,
      "step": 71730
    },
    {
      "epoch": 8.643373493975904,
      "grad_norm": 8.798066139221191,
      "learning_rate": 2.713253012048193e-06,
      "loss": 0.0311,
      "step": 71740
    },
    {
      "epoch": 8.644578313253012,
      "grad_norm": 3.287647008895874,
      "learning_rate": 2.710843373493976e-06,
      "loss": 0.0574,
      "step": 71750
    },
    {
      "epoch": 8.64578313253012,
      "grad_norm": 0.0012592116836458445,
      "learning_rate": 2.7084337349397593e-06,
      "loss": 0.0186,
      "step": 71760
    },
    {
      "epoch": 8.64698795180723,
      "grad_norm": 0.004868770018219948,
      "learning_rate": 2.706024096385542e-06,
      "loss": 0.0095,
      "step": 71770
    },
    {
      "epoch": 8.648192771084338,
      "grad_norm": 0.0003603165678214282,
      "learning_rate": 2.7036144578313256e-06,
      "loss": 0.0398,
      "step": 71780
    },
    {
      "epoch": 8.649397590361446,
      "grad_norm": 0.9092374444007874,
      "learning_rate": 2.7012048192771084e-06,
      "loss": 0.0296,
      "step": 71790
    },
    {
      "epoch": 8.650602409638553,
      "grad_norm": 0.00022468570386990905,
      "learning_rate": 2.698795180722892e-06,
      "loss": 0.0151,
      "step": 71800
    },
    {
      "epoch": 8.651807228915663,
      "grad_norm": 0.00038910098373889923,
      "learning_rate": 2.6963855421686747e-06,
      "loss": 0.0104,
      "step": 71810
    },
    {
      "epoch": 8.653012048192771,
      "grad_norm": 0.00022389243531506509,
      "learning_rate": 2.693975903614458e-06,
      "loss": 0.0109,
      "step": 71820
    },
    {
      "epoch": 8.654216867469879,
      "grad_norm": 1.1251282691955566,
      "learning_rate": 2.6915662650602415e-06,
      "loss": 0.0054,
      "step": 71830
    },
    {
      "epoch": 8.655421686746989,
      "grad_norm": 0.00040848011849448085,
      "learning_rate": 2.6891566265060243e-06,
      "loss": 0.0038,
      "step": 71840
    },
    {
      "epoch": 8.656626506024097,
      "grad_norm": 0.00029329341487027705,
      "learning_rate": 2.6867469879518075e-06,
      "loss": 0.0014,
      "step": 71850
    },
    {
      "epoch": 8.657831325301204,
      "grad_norm": 1.8348368406295776,
      "learning_rate": 2.6843373493975906e-06,
      "loss": 0.0405,
      "step": 71860
    },
    {
      "epoch": 8.659036144578312,
      "grad_norm": 171.4928436279297,
      "learning_rate": 2.681927710843374e-06,
      "loss": 0.0467,
      "step": 71870
    },
    {
      "epoch": 8.660240963855422,
      "grad_norm": 0.309207946062088,
      "learning_rate": 2.6795180722891566e-06,
      "loss": 0.0282,
      "step": 71880
    },
    {
      "epoch": 8.66144578313253,
      "grad_norm": 3.0349197387695312,
      "learning_rate": 2.67710843373494e-06,
      "loss": 0.0306,
      "step": 71890
    },
    {
      "epoch": 8.662650602409638,
      "grad_norm": 0.0011991395149379969,
      "learning_rate": 2.674698795180723e-06,
      "loss": 0.0251,
      "step": 71900
    },
    {
      "epoch": 8.663855421686748,
      "grad_norm": 0.00039634681888855994,
      "learning_rate": 2.6722891566265065e-06,
      "loss": 0.0062,
      "step": 71910
    },
    {
      "epoch": 8.665060240963856,
      "grad_norm": 0.7095128893852234,
      "learning_rate": 2.6698795180722893e-06,
      "loss": 0.0112,
      "step": 71920
    },
    {
      "epoch": 8.666265060240963,
      "grad_norm": 1.3321601152420044,
      "learning_rate": 2.6674698795180724e-06,
      "loss": 0.0171,
      "step": 71930
    },
    {
      "epoch": 8.667469879518073,
      "grad_norm": 0.00031751921051181853,
      "learning_rate": 2.6650602409638556e-06,
      "loss": 0.0001,
      "step": 71940
    },
    {
      "epoch": 8.668674698795181,
      "grad_norm": 0.0005747138056904078,
      "learning_rate": 2.662650602409639e-06,
      "loss": 0.0011,
      "step": 71950
    },
    {
      "epoch": 8.669879518072289,
      "grad_norm": 0.0003011568624060601,
      "learning_rate": 2.6602409638554215e-06,
      "loss": 0.0047,
      "step": 71960
    },
    {
      "epoch": 8.671084337349397,
      "grad_norm": 1.220871925354004,
      "learning_rate": 2.657831325301205e-06,
      "loss": 0.0118,
      "step": 71970
    },
    {
      "epoch": 8.672289156626507,
      "grad_norm": 0.0017491723410785198,
      "learning_rate": 2.6554216867469883e-06,
      "loss": 0.0,
      "step": 71980
    },
    {
      "epoch": 8.673493975903614,
      "grad_norm": 0.0008890048484317958,
      "learning_rate": 2.653012048192771e-06,
      "loss": 0.0018,
      "step": 71990
    },
    {
      "epoch": 8.674698795180722,
      "grad_norm": 1.0157655477523804,
      "learning_rate": 2.6506024096385547e-06,
      "loss": 0.0348,
      "step": 72000
    },
    {
      "epoch": 8.675903614457832,
      "grad_norm": 0.000339718593750149,
      "learning_rate": 2.6481927710843374e-06,
      "loss": 0.0,
      "step": 72010
    },
    {
      "epoch": 8.67710843373494,
      "grad_norm": 0.01620129868388176,
      "learning_rate": 2.645783132530121e-06,
      "loss": 0.0136,
      "step": 72020
    },
    {
      "epoch": 8.678313253012048,
      "grad_norm": 2.0120537281036377,
      "learning_rate": 2.6433734939759038e-06,
      "loss": 0.0143,
      "step": 72030
    },
    {
      "epoch": 8.679518072289156,
      "grad_norm": 0.323363333940506,
      "learning_rate": 2.640963855421687e-06,
      "loss": 0.023,
      "step": 72040
    },
    {
      "epoch": 8.680722891566266,
      "grad_norm": 0.00021891861979383975,
      "learning_rate": 2.63855421686747e-06,
      "loss": 0.0031,
      "step": 72050
    },
    {
      "epoch": 8.681927710843373,
      "grad_norm": 0.00167926587164402,
      "learning_rate": 2.6361445783132533e-06,
      "loss": 0.0353,
      "step": 72060
    },
    {
      "epoch": 8.683132530120481,
      "grad_norm": 0.00017132595530711114,
      "learning_rate": 2.633734939759036e-06,
      "loss": 0.0508,
      "step": 72070
    },
    {
      "epoch": 8.684337349397591,
      "grad_norm": 0.002594234189018607,
      "learning_rate": 2.6313253012048197e-06,
      "loss": 0.0088,
      "step": 72080
    },
    {
      "epoch": 8.685542168674699,
      "grad_norm": 0.0002965566236525774,
      "learning_rate": 2.6289156626506024e-06,
      "loss": 0.0198,
      "step": 72090
    },
    {
      "epoch": 8.686746987951807,
      "grad_norm": 0.00021251456928439438,
      "learning_rate": 2.6265060240963856e-06,
      "loss": 0.017,
      "step": 72100
    },
    {
      "epoch": 8.687951807228917,
      "grad_norm": 0.0001528311549918726,
      "learning_rate": 2.624096385542169e-06,
      "loss": 0.036,
      "step": 72110
    },
    {
      "epoch": 8.689156626506024,
      "grad_norm": 0.0015362564008682966,
      "learning_rate": 2.621686746987952e-06,
      "loss": 0.0005,
      "step": 72120
    },
    {
      "epoch": 8.690361445783132,
      "grad_norm": 0.00021179461327847093,
      "learning_rate": 2.6192771084337355e-06,
      "loss": 0.0118,
      "step": 72130
    },
    {
      "epoch": 8.69156626506024,
      "grad_norm": 2.6667587757110596,
      "learning_rate": 2.6168674698795183e-06,
      "loss": 0.0172,
      "step": 72140
    },
    {
      "epoch": 8.69277108433735,
      "grad_norm": 0.00023807535762898624,
      "learning_rate": 2.6144578313253015e-06,
      "loss": 0.0259,
      "step": 72150
    },
    {
      "epoch": 8.693975903614458,
      "grad_norm": 0.00026331256958656013,
      "learning_rate": 2.6120481927710846e-06,
      "loss": 0.0251,
      "step": 72160
    },
    {
      "epoch": 8.695180722891566,
      "grad_norm": 0.5000883936882019,
      "learning_rate": 2.609638554216868e-06,
      "loss": 0.0095,
      "step": 72170
    },
    {
      "epoch": 8.696385542168674,
      "grad_norm": 2.253082275390625,
      "learning_rate": 2.6072289156626506e-06,
      "loss": 0.0043,
      "step": 72180
    },
    {
      "epoch": 8.697590361445783,
      "grad_norm": 0.0002688535605557263,
      "learning_rate": 2.604819277108434e-06,
      "loss": 0.0109,
      "step": 72190
    },
    {
      "epoch": 8.698795180722891,
      "grad_norm": 0.00044780696043744683,
      "learning_rate": 2.602409638554217e-06,
      "loss": 0.0175,
      "step": 72200
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.0006878558779135346,
      "learning_rate": 2.6e-06,
      "loss": 0.0014,
      "step": 72210
    },
    {
      "epoch": 8.701204819277109,
      "grad_norm": 0.0004152394540142268,
      "learning_rate": 2.5975903614457833e-06,
      "loss": 0.0586,
      "step": 72220
    },
    {
      "epoch": 8.702409638554217,
      "grad_norm": 0.0005517661920748651,
      "learning_rate": 2.5951807228915664e-06,
      "loss": 0.0055,
      "step": 72230
    },
    {
      "epoch": 8.703614457831325,
      "grad_norm": 0.0008176521514542401,
      "learning_rate": 2.592771084337349e-06,
      "loss": 0.0053,
      "step": 72240
    },
    {
      "epoch": 8.704819277108435,
      "grad_norm": 0.00034663203405216336,
      "learning_rate": 2.590361445783133e-06,
      "loss": 0.0032,
      "step": 72250
    },
    {
      "epoch": 8.706024096385542,
      "grad_norm": 2.8596203327178955,
      "learning_rate": 2.587951807228916e-06,
      "loss": 0.0205,
      "step": 72260
    },
    {
      "epoch": 8.70722891566265,
      "grad_norm": 1.1611013412475586,
      "learning_rate": 2.585542168674699e-06,
      "loss": 0.0095,
      "step": 72270
    },
    {
      "epoch": 8.708433734939758,
      "grad_norm": 0.5979688763618469,
      "learning_rate": 2.5831325301204823e-06,
      "loss": 0.0164,
      "step": 72280
    },
    {
      "epoch": 8.709638554216868,
      "grad_norm": 1.207097053527832,
      "learning_rate": 2.580722891566265e-06,
      "loss": 0.0041,
      "step": 72290
    },
    {
      "epoch": 8.710843373493976,
      "grad_norm": 0.0005167629569768906,
      "learning_rate": 2.5783132530120487e-06,
      "loss": 0.0073,
      "step": 72300
    },
    {
      "epoch": 8.712048192771084,
      "grad_norm": 0.00017492937331553549,
      "learning_rate": 2.5759036144578314e-06,
      "loss": 0.0257,
      "step": 72310
    },
    {
      "epoch": 8.713253012048193,
      "grad_norm": 0.0006729033193551004,
      "learning_rate": 2.573493975903615e-06,
      "loss": 0.0,
      "step": 72320
    },
    {
      "epoch": 8.714457831325301,
      "grad_norm": 0.0006282838294282556,
      "learning_rate": 2.5710843373493978e-06,
      "loss": 0.009,
      "step": 72330
    },
    {
      "epoch": 8.71566265060241,
      "grad_norm": 0.00041704930481500924,
      "learning_rate": 2.568674698795181e-06,
      "loss": 0.0006,
      "step": 72340
    },
    {
      "epoch": 8.716867469879517,
      "grad_norm": 0.0003970683319494128,
      "learning_rate": 2.5662650602409637e-06,
      "loss": 0.0122,
      "step": 72350
    },
    {
      "epoch": 8.718072289156627,
      "grad_norm": 0.0008304119692184031,
      "learning_rate": 2.5638554216867473e-06,
      "loss": 0.0082,
      "step": 72360
    },
    {
      "epoch": 8.719277108433735,
      "grad_norm": 0.00044807555968873203,
      "learning_rate": 2.56144578313253e-06,
      "loss": 0.0194,
      "step": 72370
    },
    {
      "epoch": 8.720481927710843,
      "grad_norm": 0.00039496453246101737,
      "learning_rate": 2.5590361445783137e-06,
      "loss": 0.0316,
      "step": 72380
    },
    {
      "epoch": 8.721686746987952,
      "grad_norm": 0.0006050406955182552,
      "learning_rate": 2.5566265060240964e-06,
      "loss": 0.0032,
      "step": 72390
    },
    {
      "epoch": 8.72289156626506,
      "grad_norm": 1.241262674331665,
      "learning_rate": 2.5542168674698796e-06,
      "loss": 0.0112,
      "step": 72400
    },
    {
      "epoch": 8.724096385542168,
      "grad_norm": 0.0002768267586361617,
      "learning_rate": 2.551807228915663e-06,
      "loss": 0.0082,
      "step": 72410
    },
    {
      "epoch": 8.725301204819278,
      "grad_norm": 1.9731597900390625,
      "learning_rate": 2.549397590361446e-06,
      "loss": 0.0204,
      "step": 72420
    },
    {
      "epoch": 8.726506024096386,
      "grad_norm": 0.0058151851408183575,
      "learning_rate": 2.5469879518072295e-06,
      "loss": 0.0214,
      "step": 72430
    },
    {
      "epoch": 8.727710843373494,
      "grad_norm": 0.00027702146326191723,
      "learning_rate": 2.5445783132530123e-06,
      "loss": 0.0018,
      "step": 72440
    },
    {
      "epoch": 8.728915662650602,
      "grad_norm": 14.482182502746582,
      "learning_rate": 2.5421686746987955e-06,
      "loss": 0.0319,
      "step": 72450
    },
    {
      "epoch": 8.730120481927711,
      "grad_norm": 1.9393353462219238,
      "learning_rate": 2.5397590361445782e-06,
      "loss": 0.0149,
      "step": 72460
    },
    {
      "epoch": 8.73132530120482,
      "grad_norm": 0.00022278986580204219,
      "learning_rate": 2.537349397590362e-06,
      "loss": 0.0128,
      "step": 72470
    },
    {
      "epoch": 8.732530120481927,
      "grad_norm": 2.837200403213501,
      "learning_rate": 2.5349397590361446e-06,
      "loss": 0.0186,
      "step": 72480
    },
    {
      "epoch": 8.733734939759037,
      "grad_norm": 0.0004745318437926471,
      "learning_rate": 2.532530120481928e-06,
      "loss": 0.015,
      "step": 72490
    },
    {
      "epoch": 8.734939759036145,
      "grad_norm": 0.373396098613739,
      "learning_rate": 2.530120481927711e-06,
      "loss": 0.0047,
      "step": 72500
    },
    {
      "epoch": 8.736144578313253,
      "grad_norm": 0.0017343070358037949,
      "learning_rate": 2.527710843373494e-06,
      "loss": 0.0161,
      "step": 72510
    },
    {
      "epoch": 8.73734939759036,
      "grad_norm": 0.0003562892961781472,
      "learning_rate": 2.5253012048192773e-06,
      "loss": 0.0048,
      "step": 72520
    },
    {
      "epoch": 8.73855421686747,
      "grad_norm": 0.00041470915311947465,
      "learning_rate": 2.5228915662650605e-06,
      "loss": 0.02,
      "step": 72530
    },
    {
      "epoch": 8.739759036144578,
      "grad_norm": 0.34826961159706116,
      "learning_rate": 2.520481927710843e-06,
      "loss": 0.008,
      "step": 72540
    },
    {
      "epoch": 8.740963855421686,
      "grad_norm": 0.9501740336418152,
      "learning_rate": 2.518072289156627e-06,
      "loss": 0.011,
      "step": 72550
    },
    {
      "epoch": 8.742168674698796,
      "grad_norm": 0.00020907452562823892,
      "learning_rate": 2.51566265060241e-06,
      "loss": 0.0185,
      "step": 72560
    },
    {
      "epoch": 8.743373493975904,
      "grad_norm": 0.0031600622460246086,
      "learning_rate": 2.5132530120481927e-06,
      "loss": 0.0275,
      "step": 72570
    },
    {
      "epoch": 8.744578313253012,
      "grad_norm": 0.00024372893676627427,
      "learning_rate": 2.5108433734939763e-06,
      "loss": 0.0075,
      "step": 72580
    },
    {
      "epoch": 8.745783132530121,
      "grad_norm": 0.0012398967519402504,
      "learning_rate": 2.508433734939759e-06,
      "loss": 0.0128,
      "step": 72590
    },
    {
      "epoch": 8.74698795180723,
      "grad_norm": 128.94097900390625,
      "learning_rate": 2.5060240963855427e-06,
      "loss": 0.0097,
      "step": 72600
    },
    {
      "epoch": 8.748192771084337,
      "grad_norm": 0.00021976827702019364,
      "learning_rate": 2.5036144578313254e-06,
      "loss": 0.0233,
      "step": 72610
    },
    {
      "epoch": 8.749397590361445,
      "grad_norm": 0.0070202830247581005,
      "learning_rate": 2.5012048192771086e-06,
      "loss": 0.0035,
      "step": 72620
    },
    {
      "epoch": 8.750602409638555,
      "grad_norm": 0.00019058513862546533,
      "learning_rate": 2.498795180722892e-06,
      "loss": 0.0144,
      "step": 72630
    },
    {
      "epoch": 8.751807228915663,
      "grad_norm": 0.00026607263134792447,
      "learning_rate": 2.496385542168675e-06,
      "loss": 0.0134,
      "step": 72640
    },
    {
      "epoch": 8.75301204819277,
      "grad_norm": 0.30135294795036316,
      "learning_rate": 2.493975903614458e-06,
      "loss": 0.0036,
      "step": 72650
    },
    {
      "epoch": 8.754216867469879,
      "grad_norm": 0.00028912193374708295,
      "learning_rate": 2.4915662650602413e-06,
      "loss": 0.0408,
      "step": 72660
    },
    {
      "epoch": 8.755421686746988,
      "grad_norm": 1.040752649307251,
      "learning_rate": 2.4891566265060245e-06,
      "loss": 0.0057,
      "step": 72670
    },
    {
      "epoch": 8.756626506024096,
      "grad_norm": 0.0002658781595528126,
      "learning_rate": 2.4867469879518077e-06,
      "loss": 0.0023,
      "step": 72680
    },
    {
      "epoch": 8.757831325301204,
      "grad_norm": 0.0003383448638487607,
      "learning_rate": 2.4843373493975904e-06,
      "loss": 0.0121,
      "step": 72690
    },
    {
      "epoch": 8.759036144578314,
      "grad_norm": 0.9943524599075317,
      "learning_rate": 2.4819277108433736e-06,
      "loss": 0.0238,
      "step": 72700
    },
    {
      "epoch": 8.760240963855422,
      "grad_norm": 0.0003843589511234313,
      "learning_rate": 2.4795180722891568e-06,
      "loss": 0.0132,
      "step": 72710
    },
    {
      "epoch": 8.76144578313253,
      "grad_norm": 0.00026315980358049273,
      "learning_rate": 2.47710843373494e-06,
      "loss": 0.023,
      "step": 72720
    },
    {
      "epoch": 8.76265060240964,
      "grad_norm": 13.94005298614502,
      "learning_rate": 2.474698795180723e-06,
      "loss": 0.0338,
      "step": 72730
    },
    {
      "epoch": 8.763855421686747,
      "grad_norm": 0.3684125244617462,
      "learning_rate": 2.4722891566265063e-06,
      "loss": 0.0043,
      "step": 72740
    },
    {
      "epoch": 8.765060240963855,
      "grad_norm": 0.0003135149599984288,
      "learning_rate": 2.469879518072289e-06,
      "loss": 0.0069,
      "step": 72750
    },
    {
      "epoch": 8.766265060240963,
      "grad_norm": 0.00029328803066164255,
      "learning_rate": 2.4674698795180722e-06,
      "loss": 0.0057,
      "step": 72760
    },
    {
      "epoch": 8.767469879518073,
      "grad_norm": 0.0003203631495125592,
      "learning_rate": 2.4650602409638554e-06,
      "loss": 0.0468,
      "step": 72770
    },
    {
      "epoch": 8.76867469879518,
      "grad_norm": 0.00031246457365341485,
      "learning_rate": 2.462650602409639e-06,
      "loss": 0.0023,
      "step": 72780
    },
    {
      "epoch": 8.769879518072289,
      "grad_norm": 0.0013947323895990849,
      "learning_rate": 2.460240963855422e-06,
      "loss": 0.0182,
      "step": 72790
    },
    {
      "epoch": 8.771084337349398,
      "grad_norm": 0.0016337604029104114,
      "learning_rate": 2.457831325301205e-06,
      "loss": 0.0023,
      "step": 72800
    },
    {
      "epoch": 8.772289156626506,
      "grad_norm": 0.0002570029173512012,
      "learning_rate": 2.455421686746988e-06,
      "loss": 0.0159,
      "step": 72810
    },
    {
      "epoch": 8.773493975903614,
      "grad_norm": 1.815003752708435,
      "learning_rate": 2.4530120481927713e-06,
      "loss": 0.0171,
      "step": 72820
    },
    {
      "epoch": 8.774698795180722,
      "grad_norm": 1.6889228820800781,
      "learning_rate": 2.4506024096385545e-06,
      "loss": 0.024,
      "step": 72830
    },
    {
      "epoch": 8.775903614457832,
      "grad_norm": 1.5087170600891113,
      "learning_rate": 2.4481927710843376e-06,
      "loss": 0.0149,
      "step": 72840
    },
    {
      "epoch": 8.77710843373494,
      "grad_norm": 0.0003179220366291702,
      "learning_rate": 2.445783132530121e-06,
      "loss": 0.0344,
      "step": 72850
    },
    {
      "epoch": 8.778313253012048,
      "grad_norm": 0.0007524758693762124,
      "learning_rate": 2.443373493975904e-06,
      "loss": 0.0321,
      "step": 72860
    },
    {
      "epoch": 8.779518072289157,
      "grad_norm": 0.0012869021156802773,
      "learning_rate": 2.4409638554216867e-06,
      "loss": 0.0062,
      "step": 72870
    },
    {
      "epoch": 8.780722891566265,
      "grad_norm": 0.5726450681686401,
      "learning_rate": 2.43855421686747e-06,
      "loss": 0.0311,
      "step": 72880
    },
    {
      "epoch": 8.781927710843373,
      "grad_norm": 0.001464247121475637,
      "learning_rate": 2.436144578313253e-06,
      "loss": 0.0025,
      "step": 72890
    },
    {
      "epoch": 8.783132530120483,
      "grad_norm": 0.00046695396304130554,
      "learning_rate": 2.4337349397590363e-06,
      "loss": 0.0133,
      "step": 72900
    },
    {
      "epoch": 8.78433734939759,
      "grad_norm": 0.00044007759424857795,
      "learning_rate": 2.4313253012048195e-06,
      "loss": 0.0346,
      "step": 72910
    },
    {
      "epoch": 8.785542168674699,
      "grad_norm": 0.00029052537865936756,
      "learning_rate": 2.4289156626506026e-06,
      "loss": 0.0316,
      "step": 72920
    },
    {
      "epoch": 8.786746987951807,
      "grad_norm": 1.49612557888031,
      "learning_rate": 2.426506024096386e-06,
      "loss": 0.0148,
      "step": 72930
    },
    {
      "epoch": 8.787951807228916,
      "grad_norm": 0.000976253766566515,
      "learning_rate": 2.424096385542169e-06,
      "loss": 0.0001,
      "step": 72940
    },
    {
      "epoch": 8.789156626506024,
      "grad_norm": 0.0005121362046338618,
      "learning_rate": 2.421686746987952e-06,
      "loss": 0.0364,
      "step": 72950
    },
    {
      "epoch": 8.790361445783132,
      "grad_norm": 0.0004151467001065612,
      "learning_rate": 2.4192771084337353e-06,
      "loss": 0.0133,
      "step": 72960
    },
    {
      "epoch": 8.791566265060242,
      "grad_norm": 0.0004701003199443221,
      "learning_rate": 2.4168674698795185e-06,
      "loss": 0.0074,
      "step": 72970
    },
    {
      "epoch": 8.79277108433735,
      "grad_norm": 0.0003059587616007775,
      "learning_rate": 2.4144578313253013e-06,
      "loss": 0.0128,
      "step": 72980
    },
    {
      "epoch": 8.793975903614458,
      "grad_norm": 9.676645278930664,
      "learning_rate": 2.4120481927710844e-06,
      "loss": 0.0151,
      "step": 72990
    },
    {
      "epoch": 8.795180722891565,
      "grad_norm": 0.00029266561614349484,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 0.0372,
      "step": 73000
    },
    {
      "epoch": 8.796385542168675,
      "grad_norm": 0.5377720594406128,
      "learning_rate": 2.4072289156626508e-06,
      "loss": 0.0223,
      "step": 73010
    },
    {
      "epoch": 8.797590361445783,
      "grad_norm": 0.0476517528295517,
      "learning_rate": 2.404819277108434e-06,
      "loss": 0.0025,
      "step": 73020
    },
    {
      "epoch": 8.798795180722891,
      "grad_norm": 0.025834200903773308,
      "learning_rate": 2.402409638554217e-06,
      "loss": 0.0087,
      "step": 73030
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.719772219657898,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.012,
      "step": 73040
    },
    {
      "epoch": 8.801204819277109,
      "grad_norm": 2.645136833190918,
      "learning_rate": 2.397590361445783e-06,
      "loss": 0.0149,
      "step": 73050
    },
    {
      "epoch": 8.802409638554217,
      "grad_norm": 0.3821435570716858,
      "learning_rate": 2.3951807228915662e-06,
      "loss": 0.0128,
      "step": 73060
    },
    {
      "epoch": 8.803614457831326,
      "grad_norm": 0.00020933481573592871,
      "learning_rate": 2.39277108433735e-06,
      "loss": 0.0136,
      "step": 73070
    },
    {
      "epoch": 8.804819277108434,
      "grad_norm": 0.046430978924036026,
      "learning_rate": 2.390361445783133e-06,
      "loss": 0.0045,
      "step": 73080
    },
    {
      "epoch": 8.806024096385542,
      "grad_norm": 0.6578719615936279,
      "learning_rate": 2.3879518072289158e-06,
      "loss": 0.0144,
      "step": 73090
    },
    {
      "epoch": 8.80722891566265,
      "grad_norm": 0.33266982436180115,
      "learning_rate": 2.385542168674699e-06,
      "loss": 0.0088,
      "step": 73100
    },
    {
      "epoch": 8.80843373493976,
      "grad_norm": 0.0002943574218079448,
      "learning_rate": 2.383132530120482e-06,
      "loss": 0.0205,
      "step": 73110
    },
    {
      "epoch": 8.809638554216868,
      "grad_norm": 0.004718562122434378,
      "learning_rate": 2.3807228915662653e-06,
      "loss": 0.0134,
      "step": 73120
    },
    {
      "epoch": 8.810843373493976,
      "grad_norm": 0.0003317326190881431,
      "learning_rate": 2.3783132530120485e-06,
      "loss": 0.0114,
      "step": 73130
    },
    {
      "epoch": 8.812048192771083,
      "grad_norm": 0.0002358130004722625,
      "learning_rate": 2.3759036144578317e-06,
      "loss": 0.0146,
      "step": 73140
    },
    {
      "epoch": 8.813253012048193,
      "grad_norm": 0.00284789502620697,
      "learning_rate": 2.373493975903615e-06,
      "loss": 0.004,
      "step": 73150
    },
    {
      "epoch": 8.814457831325301,
      "grad_norm": 0.0033436124213039875,
      "learning_rate": 2.3710843373493976e-06,
      "loss": 0.0101,
      "step": 73160
    },
    {
      "epoch": 8.815662650602409,
      "grad_norm": 0.009019625373184681,
      "learning_rate": 2.3686746987951808e-06,
      "loss": 0.0023,
      "step": 73170
    },
    {
      "epoch": 8.816867469879519,
      "grad_norm": 1.2295902967453003,
      "learning_rate": 2.366265060240964e-06,
      "loss": 0.0202,
      "step": 73180
    },
    {
      "epoch": 8.818072289156627,
      "grad_norm": 0.00038138870149850845,
      "learning_rate": 2.363855421686747e-06,
      "loss": 0.0252,
      "step": 73190
    },
    {
      "epoch": 8.819277108433734,
      "grad_norm": 0.009175116196274757,
      "learning_rate": 2.3614457831325303e-06,
      "loss": 0.0091,
      "step": 73200
    },
    {
      "epoch": 8.820481927710844,
      "grad_norm": 0.00023069503367878497,
      "learning_rate": 2.3590361445783135e-06,
      "loss": 0.0066,
      "step": 73210
    },
    {
      "epoch": 8.821686746987952,
      "grad_norm": 0.28544700145721436,
      "learning_rate": 2.3566265060240966e-06,
      "loss": 0.0033,
      "step": 73220
    },
    {
      "epoch": 8.82289156626506,
      "grad_norm": 0.48706457018852234,
      "learning_rate": 2.35421686746988e-06,
      "loss": 0.0286,
      "step": 73230
    },
    {
      "epoch": 8.824096385542168,
      "grad_norm": 0.0002698098251130432,
      "learning_rate": 2.351807228915663e-06,
      "loss": 0.0035,
      "step": 73240
    },
    {
      "epoch": 8.825301204819278,
      "grad_norm": 0.0004045944078825414,
      "learning_rate": 2.349397590361446e-06,
      "loss": 0.0026,
      "step": 73250
    },
    {
      "epoch": 8.826506024096386,
      "grad_norm": 0.00036741202347911894,
      "learning_rate": 2.3469879518072293e-06,
      "loss": 0.0113,
      "step": 73260
    },
    {
      "epoch": 8.827710843373493,
      "grad_norm": 0.0018748641014099121,
      "learning_rate": 2.344578313253012e-06,
      "loss": 0.0028,
      "step": 73270
    },
    {
      "epoch": 8.828915662650603,
      "grad_norm": 0.0005702564958482981,
      "learning_rate": 2.3421686746987953e-06,
      "loss": 0.056,
      "step": 73280
    },
    {
      "epoch": 8.830120481927711,
      "grad_norm": 0.40418341755867004,
      "learning_rate": 2.3397590361445784e-06,
      "loss": 0.0203,
      "step": 73290
    },
    {
      "epoch": 8.831325301204819,
      "grad_norm": 0.00022996948973741382,
      "learning_rate": 2.3373493975903616e-06,
      "loss": 0.0329,
      "step": 73300
    },
    {
      "epoch": 8.832530120481927,
      "grad_norm": 0.0002109235938405618,
      "learning_rate": 2.334939759036145e-06,
      "loss": 0.0093,
      "step": 73310
    },
    {
      "epoch": 8.833734939759037,
      "grad_norm": 0.0004504166718106717,
      "learning_rate": 2.332530120481928e-06,
      "loss": 0.0199,
      "step": 73320
    },
    {
      "epoch": 8.834939759036144,
      "grad_norm": 0.00023172440705820918,
      "learning_rate": 2.330120481927711e-06,
      "loss": 0.0135,
      "step": 73330
    },
    {
      "epoch": 8.836144578313252,
      "grad_norm": 1.947130560874939,
      "learning_rate": 2.327710843373494e-06,
      "loss": 0.0232,
      "step": 73340
    },
    {
      "epoch": 8.837349397590362,
      "grad_norm": 0.0003773869830183685,
      "learning_rate": 2.325301204819277e-06,
      "loss": 0.0214,
      "step": 73350
    },
    {
      "epoch": 8.83855421686747,
      "grad_norm": 0.06007257103919983,
      "learning_rate": 2.3228915662650603e-06,
      "loss": 0.0021,
      "step": 73360
    },
    {
      "epoch": 8.839759036144578,
      "grad_norm": 0.00105886603705585,
      "learning_rate": 2.320481927710844e-06,
      "loss": 0.0103,
      "step": 73370
    },
    {
      "epoch": 8.840963855421688,
      "grad_norm": 0.0002691629924811423,
      "learning_rate": 2.3180722891566266e-06,
      "loss": 0.0279,
      "step": 73380
    },
    {
      "epoch": 8.842168674698796,
      "grad_norm": 0.0012165786465629935,
      "learning_rate": 2.3156626506024098e-06,
      "loss": 0.0065,
      "step": 73390
    },
    {
      "epoch": 8.843373493975903,
      "grad_norm": 0.0010486311512067914,
      "learning_rate": 2.313253012048193e-06,
      "loss": 0.0119,
      "step": 73400
    },
    {
      "epoch": 8.844578313253011,
      "grad_norm": 1.42674720287323,
      "learning_rate": 2.310843373493976e-06,
      "loss": 0.006,
      "step": 73410
    },
    {
      "epoch": 8.845783132530121,
      "grad_norm": 0.008481454104185104,
      "learning_rate": 2.3084337349397593e-06,
      "loss": 0.0056,
      "step": 73420
    },
    {
      "epoch": 8.846987951807229,
      "grad_norm": 0.00020937346562277526,
      "learning_rate": 2.3060240963855425e-06,
      "loss": 0.0102,
      "step": 73430
    },
    {
      "epoch": 8.848192771084337,
      "grad_norm": 0.0003208312264177948,
      "learning_rate": 2.3036144578313257e-06,
      "loss": 0.0138,
      "step": 73440
    },
    {
      "epoch": 8.849397590361447,
      "grad_norm": 0.0005102237337268889,
      "learning_rate": 2.3012048192771084e-06,
      "loss": 0.0006,
      "step": 73450
    },
    {
      "epoch": 8.850602409638554,
      "grad_norm": 0.00029847928090021014,
      "learning_rate": 2.2987951807228916e-06,
      "loss": 0.0143,
      "step": 73460
    },
    {
      "epoch": 8.851807228915662,
      "grad_norm": 0.00033037603134289384,
      "learning_rate": 2.2963855421686748e-06,
      "loss": 0.0126,
      "step": 73470
    },
    {
      "epoch": 8.85301204819277,
      "grad_norm": 0.25134918093681335,
      "learning_rate": 2.293975903614458e-06,
      "loss": 0.0145,
      "step": 73480
    },
    {
      "epoch": 8.85421686746988,
      "grad_norm": 0.09697408974170685,
      "learning_rate": 2.291566265060241e-06,
      "loss": 0.0131,
      "step": 73490
    },
    {
      "epoch": 8.855421686746988,
      "grad_norm": 0.4134444296360016,
      "learning_rate": 2.2891566265060243e-06,
      "loss": 0.004,
      "step": 73500
    },
    {
      "epoch": 8.856626506024096,
      "grad_norm": 11.410538673400879,
      "learning_rate": 2.2867469879518075e-06,
      "loss": 0.0239,
      "step": 73510
    },
    {
      "epoch": 8.857831325301206,
      "grad_norm": 0.028794897720217705,
      "learning_rate": 2.2843373493975906e-06,
      "loss": 0.0224,
      "step": 73520
    },
    {
      "epoch": 8.859036144578313,
      "grad_norm": 0.0003168913535773754,
      "learning_rate": 2.281927710843374e-06,
      "loss": 0.0124,
      "step": 73530
    },
    {
      "epoch": 8.860240963855421,
      "grad_norm": 0.033477917313575745,
      "learning_rate": 2.279518072289157e-06,
      "loss": 0.0291,
      "step": 73540
    },
    {
      "epoch": 8.861445783132531,
      "grad_norm": 1.4869532585144043,
      "learning_rate": 2.27710843373494e-06,
      "loss": 0.016,
      "step": 73550
    },
    {
      "epoch": 8.862650602409639,
      "grad_norm": 0.022587154060602188,
      "learning_rate": 2.274698795180723e-06,
      "loss": 0.0032,
      "step": 73560
    },
    {
      "epoch": 8.863855421686747,
      "grad_norm": 0.0001870719133876264,
      "learning_rate": 2.272289156626506e-06,
      "loss": 0.0035,
      "step": 73570
    },
    {
      "epoch": 8.865060240963855,
      "grad_norm": 0.5993834137916565,
      "learning_rate": 2.2698795180722893e-06,
      "loss": 0.0077,
      "step": 73580
    },
    {
      "epoch": 8.866265060240965,
      "grad_norm": 0.0007951278239488602,
      "learning_rate": 2.2674698795180725e-06,
      "loss": 0.0091,
      "step": 73590
    },
    {
      "epoch": 8.867469879518072,
      "grad_norm": 2.198774814605713,
      "learning_rate": 2.2650602409638556e-06,
      "loss": 0.0243,
      "step": 73600
    },
    {
      "epoch": 8.86867469879518,
      "grad_norm": 0.18950699269771576,
      "learning_rate": 2.262650602409639e-06,
      "loss": 0.0112,
      "step": 73610
    },
    {
      "epoch": 8.869879518072288,
      "grad_norm": 1.9560394287109375,
      "learning_rate": 2.260240963855422e-06,
      "loss": 0.0118,
      "step": 73620
    },
    {
      "epoch": 8.871084337349398,
      "grad_norm": 0.0003643310919869691,
      "learning_rate": 2.2578313253012047e-06,
      "loss": 0.0384,
      "step": 73630
    },
    {
      "epoch": 8.872289156626506,
      "grad_norm": 1.357039451599121,
      "learning_rate": 2.255421686746988e-06,
      "loss": 0.012,
      "step": 73640
    },
    {
      "epoch": 8.873493975903614,
      "grad_norm": 0.00024003646103665233,
      "learning_rate": 2.253012048192771e-06,
      "loss": 0.0348,
      "step": 73650
    },
    {
      "epoch": 8.874698795180723,
      "grad_norm": 5.024131774902344,
      "learning_rate": 2.2506024096385547e-06,
      "loss": 0.0258,
      "step": 73660
    },
    {
      "epoch": 8.875903614457831,
      "grad_norm": 0.00025342137087136507,
      "learning_rate": 2.2481927710843374e-06,
      "loss": 0.0097,
      "step": 73670
    },
    {
      "epoch": 8.87710843373494,
      "grad_norm": 0.0002845451526809484,
      "learning_rate": 2.2457831325301206e-06,
      "loss": 0.0159,
      "step": 73680
    },
    {
      "epoch": 8.878313253012049,
      "grad_norm": 0.00045463634887710214,
      "learning_rate": 2.243373493975904e-06,
      "loss": 0.0126,
      "step": 73690
    },
    {
      "epoch": 8.879518072289157,
      "grad_norm": 1.8091293573379517,
      "learning_rate": 2.240963855421687e-06,
      "loss": 0.0225,
      "step": 73700
    },
    {
      "epoch": 8.880722891566265,
      "grad_norm": 8.697340965270996,
      "learning_rate": 2.23855421686747e-06,
      "loss": 0.0273,
      "step": 73710
    },
    {
      "epoch": 8.881927710843373,
      "grad_norm": 0.24366991221904755,
      "learning_rate": 2.2361445783132533e-06,
      "loss": 0.0182,
      "step": 73720
    },
    {
      "epoch": 8.883132530120482,
      "grad_norm": 0.0007722274167463183,
      "learning_rate": 2.2337349397590365e-06,
      "loss": 0.0055,
      "step": 73730
    },
    {
      "epoch": 8.88433734939759,
      "grad_norm": 0.5478923320770264,
      "learning_rate": 2.2313253012048192e-06,
      "loss": 0.012,
      "step": 73740
    },
    {
      "epoch": 8.885542168674698,
      "grad_norm": 0.00023812153085600585,
      "learning_rate": 2.2289156626506024e-06,
      "loss": 0.0029,
      "step": 73750
    },
    {
      "epoch": 8.886746987951808,
      "grad_norm": 0.0004969192668795586,
      "learning_rate": 2.2265060240963856e-06,
      "loss": 0.0091,
      "step": 73760
    },
    {
      "epoch": 8.887951807228916,
      "grad_norm": 1.2042567729949951,
      "learning_rate": 2.2240963855421688e-06,
      "loss": 0.0044,
      "step": 73770
    },
    {
      "epoch": 8.889156626506024,
      "grad_norm": 0.0004170789325144142,
      "learning_rate": 2.221686746987952e-06,
      "loss": 0.0193,
      "step": 73780
    },
    {
      "epoch": 8.890361445783132,
      "grad_norm": 0.00043541978811845183,
      "learning_rate": 2.219277108433735e-06,
      "loss": 0.0016,
      "step": 73790
    },
    {
      "epoch": 8.891566265060241,
      "grad_norm": 0.0003807336324825883,
      "learning_rate": 2.2168674698795183e-06,
      "loss": 0.0074,
      "step": 73800
    },
    {
      "epoch": 8.89277108433735,
      "grad_norm": 0.00024186892551369965,
      "learning_rate": 2.2144578313253015e-06,
      "loss": 0.0055,
      "step": 73810
    },
    {
      "epoch": 8.893975903614457,
      "grad_norm": 0.00020245912310201675,
      "learning_rate": 2.2120481927710847e-06,
      "loss": 0.029,
      "step": 73820
    },
    {
      "epoch": 8.895180722891567,
      "grad_norm": 1.1151034832000732,
      "learning_rate": 2.209638554216868e-06,
      "loss": 0.0194,
      "step": 73830
    },
    {
      "epoch": 8.896385542168675,
      "grad_norm": 0.2415362298488617,
      "learning_rate": 2.207228915662651e-06,
      "loss": 0.0084,
      "step": 73840
    },
    {
      "epoch": 8.897590361445783,
      "grad_norm": 0.0021363149862736464,
      "learning_rate": 2.2048192771084338e-06,
      "loss": 0.0183,
      "step": 73850
    },
    {
      "epoch": 8.898795180722892,
      "grad_norm": 0.9008333086967468,
      "learning_rate": 2.202409638554217e-06,
      "loss": 0.0062,
      "step": 73860
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.0004763150354847312,
      "learning_rate": 2.2e-06,
      "loss": 0.0092,
      "step": 73870
    },
    {
      "epoch": 8.901204819277108,
      "grad_norm": 0.00024026163737289608,
      "learning_rate": 2.1975903614457833e-06,
      "loss": 0.0068,
      "step": 73880
    },
    {
      "epoch": 8.902409638554216,
      "grad_norm": 0.0006304837297648191,
      "learning_rate": 2.1951807228915665e-06,
      "loss": 0.0,
      "step": 73890
    },
    {
      "epoch": 8.903614457831326,
      "grad_norm": 0.3923836052417755,
      "learning_rate": 2.1927710843373496e-06,
      "loss": 0.0548,
      "step": 73900
    },
    {
      "epoch": 8.904819277108434,
      "grad_norm": 1.4491016864776611,
      "learning_rate": 2.190361445783133e-06,
      "loss": 0.0069,
      "step": 73910
    },
    {
      "epoch": 8.906024096385542,
      "grad_norm": 0.3301258981227875,
      "learning_rate": 2.1879518072289156e-06,
      "loss": 0.0061,
      "step": 73920
    },
    {
      "epoch": 8.907228915662651,
      "grad_norm": 0.00044974710908718407,
      "learning_rate": 2.1855421686746987e-06,
      "loss": 0.0038,
      "step": 73930
    },
    {
      "epoch": 8.90843373493976,
      "grad_norm": 0.000313484575599432,
      "learning_rate": 2.183132530120482e-06,
      "loss": 0.0012,
      "step": 73940
    },
    {
      "epoch": 8.909638554216867,
      "grad_norm": 2.4542200565338135,
      "learning_rate": 2.1807228915662655e-06,
      "loss": 0.0153,
      "step": 73950
    },
    {
      "epoch": 8.910843373493975,
      "grad_norm": 0.0002711783745326102,
      "learning_rate": 2.1783132530120487e-06,
      "loss": 0.0368,
      "step": 73960
    },
    {
      "epoch": 8.912048192771085,
      "grad_norm": 0.0004771132080350071,
      "learning_rate": 2.1759036144578314e-06,
      "loss": 0.0585,
      "step": 73970
    },
    {
      "epoch": 8.913253012048193,
      "grad_norm": 1.001491665840149,
      "learning_rate": 2.1734939759036146e-06,
      "loss": 0.0176,
      "step": 73980
    },
    {
      "epoch": 8.9144578313253,
      "grad_norm": 0.00028428807854652405,
      "learning_rate": 2.171084337349398e-06,
      "loss": 0.0,
      "step": 73990
    },
    {
      "epoch": 8.91566265060241,
      "grad_norm": 0.0008095066295936704,
      "learning_rate": 2.168674698795181e-06,
      "loss": 0.0206,
      "step": 74000
    },
    {
      "epoch": 8.916867469879518,
      "grad_norm": 0.7578108906745911,
      "learning_rate": 2.166265060240964e-06,
      "loss": 0.0017,
      "step": 74010
    },
    {
      "epoch": 8.918072289156626,
      "grad_norm": 0.20859186351299286,
      "learning_rate": 2.1638554216867473e-06,
      "loss": 0.016,
      "step": 74020
    },
    {
      "epoch": 8.919277108433734,
      "grad_norm": 0.0019270583288744092,
      "learning_rate": 2.16144578313253e-06,
      "loss": 0.0462,
      "step": 74030
    },
    {
      "epoch": 8.920481927710844,
      "grad_norm": 0.0002514546213205904,
      "learning_rate": 2.1590361445783133e-06,
      "loss": 0.0102,
      "step": 74040
    },
    {
      "epoch": 8.921686746987952,
      "grad_norm": 0.412593811750412,
      "learning_rate": 2.1566265060240964e-06,
      "loss": 0.0075,
      "step": 74050
    },
    {
      "epoch": 8.92289156626506,
      "grad_norm": 0.0005381396622397006,
      "learning_rate": 2.1542168674698796e-06,
      "loss": 0.0037,
      "step": 74060
    },
    {
      "epoch": 8.92409638554217,
      "grad_norm": 0.014429486356675625,
      "learning_rate": 2.1518072289156628e-06,
      "loss": 0.0036,
      "step": 74070
    },
    {
      "epoch": 8.925301204819277,
      "grad_norm": 1.1833325624465942,
      "learning_rate": 2.149397590361446e-06,
      "loss": 0.0082,
      "step": 74080
    },
    {
      "epoch": 8.926506024096385,
      "grad_norm": 0.0004296989063732326,
      "learning_rate": 2.146987951807229e-06,
      "loss": 0.0211,
      "step": 74090
    },
    {
      "epoch": 8.927710843373493,
      "grad_norm": 0.17555807530879974,
      "learning_rate": 2.1445783132530123e-06,
      "loss": 0.0099,
      "step": 74100
    },
    {
      "epoch": 8.928915662650603,
      "grad_norm": 0.00026619923301041126,
      "learning_rate": 2.1421686746987955e-06,
      "loss": 0.0024,
      "step": 74110
    },
    {
      "epoch": 8.93012048192771,
      "grad_norm": 0.00016443326603621244,
      "learning_rate": 2.1397590361445787e-06,
      "loss": 0.0037,
      "step": 74120
    },
    {
      "epoch": 8.931325301204819,
      "grad_norm": 0.00036335407639853656,
      "learning_rate": 2.137349397590362e-06,
      "loss": 0.0185,
      "step": 74130
    },
    {
      "epoch": 8.932530120481928,
      "grad_norm": 0.0004302967863623053,
      "learning_rate": 2.134939759036145e-06,
      "loss": 0.0197,
      "step": 74140
    },
    {
      "epoch": 8.933734939759036,
      "grad_norm": 0.00025838433066383004,
      "learning_rate": 2.1325301204819278e-06,
      "loss": 0.0049,
      "step": 74150
    },
    {
      "epoch": 8.934939759036144,
      "grad_norm": 1.6402314901351929,
      "learning_rate": 2.130120481927711e-06,
      "loss": 0.0372,
      "step": 74160
    },
    {
      "epoch": 8.936144578313254,
      "grad_norm": 0.0005103152361698449,
      "learning_rate": 2.127710843373494e-06,
      "loss": 0.0057,
      "step": 74170
    },
    {
      "epoch": 8.937349397590362,
      "grad_norm": 0.2866445779800415,
      "learning_rate": 2.1253012048192773e-06,
      "loss": 0.0292,
      "step": 74180
    },
    {
      "epoch": 8.93855421686747,
      "grad_norm": 0.955458402633667,
      "learning_rate": 2.1228915662650605e-06,
      "loss": 0.0075,
      "step": 74190
    },
    {
      "epoch": 8.939759036144578,
      "grad_norm": 0.00034018667065538466,
      "learning_rate": 2.1204819277108437e-06,
      "loss": 0.0084,
      "step": 74200
    },
    {
      "epoch": 8.940963855421687,
      "grad_norm": 0.16744142770767212,
      "learning_rate": 2.1180722891566264e-06,
      "loss": 0.0009,
      "step": 74210
    },
    {
      "epoch": 8.942168674698795,
      "grad_norm": 0.00021011233911849558,
      "learning_rate": 2.1156626506024096e-06,
      "loss": 0.0058,
      "step": 74220
    },
    {
      "epoch": 8.943373493975903,
      "grad_norm": 0.8125616908073425,
      "learning_rate": 2.1132530120481928e-06,
      "loss": 0.0219,
      "step": 74230
    },
    {
      "epoch": 8.944578313253013,
      "grad_norm": 0.0005948810139670968,
      "learning_rate": 2.110843373493976e-06,
      "loss": 0.0115,
      "step": 74240
    },
    {
      "epoch": 8.94578313253012,
      "grad_norm": 0.0007783717010170221,
      "learning_rate": 2.1084337349397595e-06,
      "loss": 0.0035,
      "step": 74250
    },
    {
      "epoch": 8.946987951807229,
      "grad_norm": 0.011277743615210056,
      "learning_rate": 2.1060240963855423e-06,
      "loss": 0.0145,
      "step": 74260
    },
    {
      "epoch": 8.948192771084337,
      "grad_norm": 0.0002471056650392711,
      "learning_rate": 2.1036144578313255e-06,
      "loss": 0.0228,
      "step": 74270
    },
    {
      "epoch": 8.949397590361446,
      "grad_norm": 0.0001602261036168784,
      "learning_rate": 2.1012048192771086e-06,
      "loss": 0.0061,
      "step": 74280
    },
    {
      "epoch": 8.950602409638554,
      "grad_norm": 0.0011906910222023726,
      "learning_rate": 2.098795180722892e-06,
      "loss": 0.0083,
      "step": 74290
    },
    {
      "epoch": 8.951807228915662,
      "grad_norm": 0.9451268315315247,
      "learning_rate": 2.096385542168675e-06,
      "loss": 0.0153,
      "step": 74300
    },
    {
      "epoch": 8.953012048192772,
      "grad_norm": 0.00221459474414587,
      "learning_rate": 2.093975903614458e-06,
      "loss": 0.0155,
      "step": 74310
    },
    {
      "epoch": 8.95421686746988,
      "grad_norm": 0.000304128770949319,
      "learning_rate": 2.0915662650602413e-06,
      "loss": 0.0003,
      "step": 74320
    },
    {
      "epoch": 8.955421686746988,
      "grad_norm": 1.4424793720245361,
      "learning_rate": 2.089156626506024e-06,
      "loss": 0.0111,
      "step": 74330
    },
    {
      "epoch": 8.956626506024097,
      "grad_norm": 0.0002305384841747582,
      "learning_rate": 2.0867469879518073e-06,
      "loss": 0.0075,
      "step": 74340
    },
    {
      "epoch": 8.957831325301205,
      "grad_norm": 0.00029511642060242593,
      "learning_rate": 2.0843373493975904e-06,
      "loss": 0.0107,
      "step": 74350
    },
    {
      "epoch": 8.959036144578313,
      "grad_norm": 0.00026783565408550203,
      "learning_rate": 2.0819277108433736e-06,
      "loss": 0.0204,
      "step": 74360
    },
    {
      "epoch": 8.960240963855421,
      "grad_norm": 1.8799216747283936,
      "learning_rate": 2.079518072289157e-06,
      "loss": 0.0116,
      "step": 74370
    },
    {
      "epoch": 8.96144578313253,
      "grad_norm": 0.0002119545970344916,
      "learning_rate": 2.07710843373494e-06,
      "loss": 0.0016,
      "step": 74380
    },
    {
      "epoch": 8.962650602409639,
      "grad_norm": 0.00020092209160793573,
      "learning_rate": 2.0746987951807227e-06,
      "loss": 0.0269,
      "step": 74390
    },
    {
      "epoch": 8.963855421686747,
      "grad_norm": 54.448814392089844,
      "learning_rate": 2.0722891566265063e-06,
      "loss": 0.0342,
      "step": 74400
    },
    {
      "epoch": 8.965060240963856,
      "grad_norm": 0.00023271875397767872,
      "learning_rate": 2.0698795180722895e-06,
      "loss": 0.0068,
      "step": 74410
    },
    {
      "epoch": 8.966265060240964,
      "grad_norm": 0.00024159123131539673,
      "learning_rate": 2.0674698795180727e-06,
      "loss": 0.0185,
      "step": 74420
    },
    {
      "epoch": 8.967469879518072,
      "grad_norm": 1.5628315210342407,
      "learning_rate": 2.065060240963856e-06,
      "loss": 0.0294,
      "step": 74430
    },
    {
      "epoch": 8.96867469879518,
      "grad_norm": 0.4746555984020233,
      "learning_rate": 2.0626506024096386e-06,
      "loss": 0.0129,
      "step": 74440
    },
    {
      "epoch": 8.96987951807229,
      "grad_norm": 0.000265140290139243,
      "learning_rate": 2.0602409638554218e-06,
      "loss": 0.0125,
      "step": 74450
    },
    {
      "epoch": 8.971084337349398,
      "grad_norm": 0.0002842617395799607,
      "learning_rate": 2.057831325301205e-06,
      "loss": 0.0008,
      "step": 74460
    },
    {
      "epoch": 8.972289156626506,
      "grad_norm": 1.0442044734954834,
      "learning_rate": 2.055421686746988e-06,
      "loss": 0.0093,
      "step": 74470
    },
    {
      "epoch": 8.973493975903615,
      "grad_norm": 1.9772913455963135,
      "learning_rate": 2.0530120481927713e-06,
      "loss": 0.018,
      "step": 74480
    },
    {
      "epoch": 8.974698795180723,
      "grad_norm": 1.055071473121643,
      "learning_rate": 2.0506024096385545e-06,
      "loss": 0.0033,
      "step": 74490
    },
    {
      "epoch": 8.975903614457831,
      "grad_norm": 0.0002291416167281568,
      "learning_rate": 2.0481927710843377e-06,
      "loss": 0.0071,
      "step": 74500
    },
    {
      "epoch": 8.977108433734939,
      "grad_norm": 2.9140188694000244,
      "learning_rate": 2.0457831325301204e-06,
      "loss": 0.0129,
      "step": 74510
    },
    {
      "epoch": 8.978313253012049,
      "grad_norm": 0.0005595688708126545,
      "learning_rate": 2.0433734939759036e-06,
      "loss": 0.0192,
      "step": 74520
    },
    {
      "epoch": 8.979518072289157,
      "grad_norm": 0.7932613492012024,
      "learning_rate": 2.0409638554216868e-06,
      "loss": 0.0124,
      "step": 74530
    },
    {
      "epoch": 8.980722891566264,
      "grad_norm": 1.1600894927978516,
      "learning_rate": 2.0385542168674704e-06,
      "loss": 0.0142,
      "step": 74540
    },
    {
      "epoch": 8.981927710843374,
      "grad_norm": 0.005223562475293875,
      "learning_rate": 2.036144578313253e-06,
      "loss": 0.0058,
      "step": 74550
    },
    {
      "epoch": 8.983132530120482,
      "grad_norm": 0.0001821215992094949,
      "learning_rate": 2.0337349397590363e-06,
      "loss": 0.0093,
      "step": 74560
    },
    {
      "epoch": 8.98433734939759,
      "grad_norm": 3.3125360012054443,
      "learning_rate": 2.0313253012048195e-06,
      "loss": 0.0188,
      "step": 74570
    },
    {
      "epoch": 8.985542168674698,
      "grad_norm": 2.854487657546997,
      "learning_rate": 2.0289156626506026e-06,
      "loss": 0.0248,
      "step": 74580
    },
    {
      "epoch": 8.986746987951808,
      "grad_norm": 0.0011123203439638019,
      "learning_rate": 2.026506024096386e-06,
      "loss": 0.0109,
      "step": 74590
    },
    {
      "epoch": 8.987951807228916,
      "grad_norm": 0.00023237225832417607,
      "learning_rate": 2.024096385542169e-06,
      "loss": 0.0173,
      "step": 74600
    },
    {
      "epoch": 8.989156626506023,
      "grad_norm": 10.597095489501953,
      "learning_rate": 2.021686746987952e-06,
      "loss": 0.0399,
      "step": 74610
    },
    {
      "epoch": 8.990361445783133,
      "grad_norm": 0.00017395267786923796,
      "learning_rate": 2.019277108433735e-06,
      "loss": 0.0036,
      "step": 74620
    },
    {
      "epoch": 8.991566265060241,
      "grad_norm": 0.0002803304814733565,
      "learning_rate": 2.016867469879518e-06,
      "loss": 0.0005,
      "step": 74630
    },
    {
      "epoch": 8.992771084337349,
      "grad_norm": 0.00018521718448027968,
      "learning_rate": 2.0144578313253013e-06,
      "loss": 0.0454,
      "step": 74640
    },
    {
      "epoch": 8.993975903614459,
      "grad_norm": 0.00023215258261188865,
      "learning_rate": 2.0120481927710845e-06,
      "loss": 0.0397,
      "step": 74650
    },
    {
      "epoch": 8.995180722891567,
      "grad_norm": 0.8499223589897156,
      "learning_rate": 2.0096385542168676e-06,
      "loss": 0.012,
      "step": 74660
    },
    {
      "epoch": 8.996385542168674,
      "grad_norm": 0.3499249517917633,
      "learning_rate": 2.007228915662651e-06,
      "loss": 0.0358,
      "step": 74670
    },
    {
      "epoch": 8.997590361445782,
      "grad_norm": 0.43206092715263367,
      "learning_rate": 2.004819277108434e-06,
      "loss": 0.012,
      "step": 74680
    },
    {
      "epoch": 8.998795180722892,
      "grad_norm": 0.000321945728501305,
      "learning_rate": 2.002409638554217e-06,
      "loss": 0.0168,
      "step": 74690
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.0014922117115929723,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0124,
      "step": 74700
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9874625046869141,
      "eval_f1": 0.9666770476487075,
      "eval_loss": 0.054762374609708786,
      "eval_precision": 0.9743847312908086,
      "eval_recall": 0.9590903472994685,
      "eval_runtime": 3572.4853,
      "eval_samples_per_second": 11.95,
      "eval_steps_per_second": 0.498,
      "step": 74700
    }
  ],
  "logging_steps": 10,
  "max_steps": 83000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.497124837448412e+17,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
