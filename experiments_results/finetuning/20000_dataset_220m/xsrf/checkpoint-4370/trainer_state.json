{
  "best_metric": 0.8488063660477454,
  "best_model_checkpoint": "../saved_models/xsrf/checkpoint-4370",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4370,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002288329519450801,
      "grad_norm": 54.999420166015625,
      "learning_rate": 1.99954233409611e-05,
      "loss": 1.256,
      "step": 1
    },
    {
      "epoch": 0.02288329519450801,
      "grad_norm": 23.671297073364258,
      "learning_rate": 1.9954233409610984e-05,
      "loss": 0.5441,
      "step": 10
    },
    {
      "epoch": 0.04576659038901602,
      "grad_norm": 22.215726852416992,
      "learning_rate": 1.990846681922197e-05,
      "loss": 0.4189,
      "step": 20
    },
    {
      "epoch": 0.06864988558352403,
      "grad_norm": 20.731538772583008,
      "learning_rate": 1.9862700228832953e-05,
      "loss": 0.3885,
      "step": 30
    },
    {
      "epoch": 0.09153318077803203,
      "grad_norm": 17.630659103393555,
      "learning_rate": 1.981693363844394e-05,
      "loss": 0.4206,
      "step": 40
    },
    {
      "epoch": 0.11441647597254005,
      "grad_norm": 18.72393798828125,
      "learning_rate": 1.977116704805492e-05,
      "loss": 0.4074,
      "step": 50
    },
    {
      "epoch": 0.13729977116704806,
      "grad_norm": 16.10576057434082,
      "learning_rate": 1.9725400457665907e-05,
      "loss": 0.4246,
      "step": 60
    },
    {
      "epoch": 0.16018306636155608,
      "grad_norm": 71.71865844726562,
      "learning_rate": 1.967963386727689e-05,
      "loss": 0.4485,
      "step": 70
    },
    {
      "epoch": 0.18306636155606407,
      "grad_norm": 18.55157470703125,
      "learning_rate": 1.9633867276887872e-05,
      "loss": 0.4247,
      "step": 80
    },
    {
      "epoch": 0.20594965675057209,
      "grad_norm": 12.844444274902344,
      "learning_rate": 1.9588100686498858e-05,
      "loss": 0.3984,
      "step": 90
    },
    {
      "epoch": 0.2288329519450801,
      "grad_norm": 10.765459060668945,
      "learning_rate": 1.954233409610984e-05,
      "loss": 0.3932,
      "step": 100
    },
    {
      "epoch": 0.2517162471395881,
      "grad_norm": 13.408778190612793,
      "learning_rate": 1.9496567505720823e-05,
      "loss": 0.3845,
      "step": 110
    },
    {
      "epoch": 0.2745995423340961,
      "grad_norm": 79.45378875732422,
      "learning_rate": 1.945080091533181e-05,
      "loss": 0.413,
      "step": 120
    },
    {
      "epoch": 0.2974828375286041,
      "grad_norm": 10.516096115112305,
      "learning_rate": 1.9405034324942792e-05,
      "loss": 0.4173,
      "step": 130
    },
    {
      "epoch": 0.32036613272311215,
      "grad_norm": 13.389251708984375,
      "learning_rate": 1.9359267734553778e-05,
      "loss": 0.3833,
      "step": 140
    },
    {
      "epoch": 0.34324942791762014,
      "grad_norm": 14.592484474182129,
      "learning_rate": 1.931350114416476e-05,
      "loss": 0.3941,
      "step": 150
    },
    {
      "epoch": 0.36613272311212813,
      "grad_norm": 11.775910377502441,
      "learning_rate": 1.9267734553775746e-05,
      "loss": 0.4147,
      "step": 160
    },
    {
      "epoch": 0.3890160183066362,
      "grad_norm": 9.15472412109375,
      "learning_rate": 1.922196796338673e-05,
      "loss": 0.4093,
      "step": 170
    },
    {
      "epoch": 0.41189931350114417,
      "grad_norm": 16.896465301513672,
      "learning_rate": 1.9176201372997715e-05,
      "loss": 0.4185,
      "step": 180
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 8.444775581359863,
      "learning_rate": 1.9130434782608697e-05,
      "loss": 0.3922,
      "step": 190
    },
    {
      "epoch": 0.4576659038901602,
      "grad_norm": 6.216880798339844,
      "learning_rate": 1.9084668192219683e-05,
      "loss": 0.3663,
      "step": 200
    },
    {
      "epoch": 0.4805491990846682,
      "grad_norm": 7.424416542053223,
      "learning_rate": 1.9038901601830666e-05,
      "loss": 0.3752,
      "step": 210
    },
    {
      "epoch": 0.5034324942791762,
      "grad_norm": 7.449732303619385,
      "learning_rate": 1.8993135011441652e-05,
      "loss": 0.4428,
      "step": 220
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 15.412410736083984,
      "learning_rate": 1.894736842105263e-05,
      "loss": 0.3859,
      "step": 230
    },
    {
      "epoch": 0.5491990846681922,
      "grad_norm": 7.820295333862305,
      "learning_rate": 1.8901601830663617e-05,
      "loss": 0.408,
      "step": 240
    },
    {
      "epoch": 0.5720823798627003,
      "grad_norm": 7.2431488037109375,
      "learning_rate": 1.88558352402746e-05,
      "loss": 0.3526,
      "step": 250
    },
    {
      "epoch": 0.5949656750572082,
      "grad_norm": 6.474973678588867,
      "learning_rate": 1.8810068649885585e-05,
      "loss": 0.3798,
      "step": 260
    },
    {
      "epoch": 0.6178489702517163,
      "grad_norm": 6.285362720489502,
      "learning_rate": 1.8764302059496568e-05,
      "loss": 0.4239,
      "step": 270
    },
    {
      "epoch": 0.6407322654462243,
      "grad_norm": 4.986244201660156,
      "learning_rate": 1.8718535469107554e-05,
      "loss": 0.3301,
      "step": 280
    },
    {
      "epoch": 0.6636155606407322,
      "grad_norm": 7.404465198516846,
      "learning_rate": 1.8672768878718537e-05,
      "loss": 0.3573,
      "step": 290
    },
    {
      "epoch": 0.6864988558352403,
      "grad_norm": 9.079949378967285,
      "learning_rate": 1.8627002288329522e-05,
      "loss": 0.3604,
      "step": 300
    },
    {
      "epoch": 0.7093821510297483,
      "grad_norm": 6.084490776062012,
      "learning_rate": 1.8581235697940505e-05,
      "loss": 0.3457,
      "step": 310
    },
    {
      "epoch": 0.7322654462242563,
      "grad_norm": 5.261830806732178,
      "learning_rate": 1.8535469107551488e-05,
      "loss": 0.3645,
      "step": 320
    },
    {
      "epoch": 0.7551487414187643,
      "grad_norm": 6.020383358001709,
      "learning_rate": 1.8489702517162474e-05,
      "loss": 0.394,
      "step": 330
    },
    {
      "epoch": 0.7780320366132724,
      "grad_norm": 7.843419075012207,
      "learning_rate": 1.8443935926773456e-05,
      "loss": 0.3738,
      "step": 340
    },
    {
      "epoch": 0.8009153318077803,
      "grad_norm": 6.469651222229004,
      "learning_rate": 1.8398169336384442e-05,
      "loss": 0.3816,
      "step": 350
    },
    {
      "epoch": 0.8237986270022883,
      "grad_norm": 10.266883850097656,
      "learning_rate": 1.8352402745995425e-05,
      "loss": 0.391,
      "step": 360
    },
    {
      "epoch": 0.8466819221967964,
      "grad_norm": 6.134343147277832,
      "learning_rate": 1.830663615560641e-05,
      "loss": 0.2837,
      "step": 370
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 6.189779281616211,
      "learning_rate": 1.8260869565217393e-05,
      "loss": 0.3077,
      "step": 380
    },
    {
      "epoch": 0.8924485125858124,
      "grad_norm": 5.126924514770508,
      "learning_rate": 1.8215102974828376e-05,
      "loss": 0.3176,
      "step": 390
    },
    {
      "epoch": 0.9153318077803204,
      "grad_norm": 7.746819972991943,
      "learning_rate": 1.816933638443936e-05,
      "loss": 0.3995,
      "step": 400
    },
    {
      "epoch": 0.9382151029748284,
      "grad_norm": 6.4702935218811035,
      "learning_rate": 1.8123569794050344e-05,
      "loss": 0.3704,
      "step": 410
    },
    {
      "epoch": 0.9610983981693364,
      "grad_norm": 5.677186012268066,
      "learning_rate": 1.8077803203661327e-05,
      "loss": 0.3485,
      "step": 420
    },
    {
      "epoch": 0.9839816933638444,
      "grad_norm": 3.8850200176239014,
      "learning_rate": 1.8032036613272313e-05,
      "loss": 0.278,
      "step": 430
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.882,
      "eval_f1": 0.30314960629921267,
      "eval_loss": 0.3069918155670166,
      "eval_precision": 0.6260162601626016,
      "eval_recall": 0.2,
      "eval_runtime": 482.5267,
      "eval_samples_per_second": 6.217,
      "eval_steps_per_second": 0.777,
      "step": 437
    },
    {
      "epoch": 1.0068649885583525,
      "grad_norm": 29.36437225341797,
      "learning_rate": 1.7986270022883295e-05,
      "loss": 0.3801,
      "step": 440
    },
    {
      "epoch": 1.0297482837528604,
      "grad_norm": 3.8362977504730225,
      "learning_rate": 1.794050343249428e-05,
      "loss": 0.3393,
      "step": 450
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 9.06236743927002,
      "learning_rate": 1.7894736842105264e-05,
      "loss": 0.3893,
      "step": 460
    },
    {
      "epoch": 1.0755148741418765,
      "grad_norm": 8.70960521697998,
      "learning_rate": 1.784897025171625e-05,
      "loss": 0.3935,
      "step": 470
    },
    {
      "epoch": 1.0983981693363845,
      "grad_norm": 5.604091644287109,
      "learning_rate": 1.7803203661327232e-05,
      "loss": 0.327,
      "step": 480
    },
    {
      "epoch": 1.1212814645308924,
      "grad_norm": 5.799663066864014,
      "learning_rate": 1.7757437070938218e-05,
      "loss": 0.3364,
      "step": 490
    },
    {
      "epoch": 1.1441647597254005,
      "grad_norm": 4.605184555053711,
      "learning_rate": 1.77116704805492e-05,
      "loss": 0.3172,
      "step": 500
    },
    {
      "epoch": 1.1670480549199085,
      "grad_norm": 5.109387397766113,
      "learning_rate": 1.7665903890160187e-05,
      "loss": 0.2842,
      "step": 510
    },
    {
      "epoch": 1.1899313501144164,
      "grad_norm": 4.655028820037842,
      "learning_rate": 1.762013729977117e-05,
      "loss": 0.2579,
      "step": 520
    },
    {
      "epoch": 1.2128146453089246,
      "grad_norm": 5.336664199829102,
      "learning_rate": 1.7574370709382152e-05,
      "loss": 0.2728,
      "step": 530
    },
    {
      "epoch": 1.2356979405034325,
      "grad_norm": 8.3019380569458,
      "learning_rate": 1.7528604118993134e-05,
      "loss": 0.3132,
      "step": 540
    },
    {
      "epoch": 1.2585812356979404,
      "grad_norm": 9.664238929748535,
      "learning_rate": 1.748283752860412e-05,
      "loss": 0.3406,
      "step": 550
    },
    {
      "epoch": 1.2814645308924484,
      "grad_norm": 4.726368427276611,
      "learning_rate": 1.7437070938215103e-05,
      "loss": 0.2756,
      "step": 560
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 6.158860683441162,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.3207,
      "step": 570
    },
    {
      "epoch": 1.3272311212814645,
      "grad_norm": 4.696842193603516,
      "learning_rate": 1.734553775743707e-05,
      "loss": 0.2589,
      "step": 580
    },
    {
      "epoch": 1.3501144164759724,
      "grad_norm": 9.166302680969238,
      "learning_rate": 1.7299771167048057e-05,
      "loss": 0.3148,
      "step": 590
    },
    {
      "epoch": 1.3729977116704806,
      "grad_norm": 6.40227746963501,
      "learning_rate": 1.725400457665904e-05,
      "loss": 0.2556,
      "step": 600
    },
    {
      "epoch": 1.3958810068649885,
      "grad_norm": 4.740471363067627,
      "learning_rate": 1.7208237986270026e-05,
      "loss": 0.2371,
      "step": 610
    },
    {
      "epoch": 1.4187643020594964,
      "grad_norm": 5.24658203125,
      "learning_rate": 1.716247139588101e-05,
      "loss": 0.2823,
      "step": 620
    },
    {
      "epoch": 1.4416475972540046,
      "grad_norm": 6.555773735046387,
      "learning_rate": 1.7116704805491994e-05,
      "loss": 0.282,
      "step": 630
    },
    {
      "epoch": 1.4645308924485125,
      "grad_norm": 7.577878952026367,
      "learning_rate": 1.7070938215102977e-05,
      "loss": 0.2796,
      "step": 640
    },
    {
      "epoch": 1.4874141876430205,
      "grad_norm": 11.121981620788574,
      "learning_rate": 1.702517162471396e-05,
      "loss": 0.2595,
      "step": 650
    },
    {
      "epoch": 1.5102974828375286,
      "grad_norm": 3.1390514373779297,
      "learning_rate": 1.6979405034324945e-05,
      "loss": 0.2449,
      "step": 660
    },
    {
      "epoch": 1.5331807780320366,
      "grad_norm": 5.381315231323242,
      "learning_rate": 1.6933638443935928e-05,
      "loss": 0.2973,
      "step": 670
    },
    {
      "epoch": 1.5560640732265445,
      "grad_norm": 5.969697952270508,
      "learning_rate": 1.688787185354691e-05,
      "loss": 0.2642,
      "step": 680
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 4.242194175720215,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.2541,
      "step": 690
    },
    {
      "epoch": 1.6018306636155606,
      "grad_norm": 5.928893089294434,
      "learning_rate": 1.679633867276888e-05,
      "loss": 0.2208,
      "step": 700
    },
    {
      "epoch": 1.6247139588100685,
      "grad_norm": 7.039247035980225,
      "learning_rate": 1.6750572082379865e-05,
      "loss": 0.2304,
      "step": 710
    },
    {
      "epoch": 1.6475972540045767,
      "grad_norm": 6.524928569793701,
      "learning_rate": 1.6704805491990848e-05,
      "loss": 0.2038,
      "step": 720
    },
    {
      "epoch": 1.6704805491990846,
      "grad_norm": 5.765074729919434,
      "learning_rate": 1.665903890160183e-05,
      "loss": 0.2329,
      "step": 730
    },
    {
      "epoch": 1.6933638443935926,
      "grad_norm": 4.865461826324463,
      "learning_rate": 1.6613272311212816e-05,
      "loss": 0.2327,
      "step": 740
    },
    {
      "epoch": 1.7162471395881007,
      "grad_norm": 4.401451587677002,
      "learning_rate": 1.65675057208238e-05,
      "loss": 0.3504,
      "step": 750
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 7.016302585601807,
      "learning_rate": 1.6521739130434785e-05,
      "loss": 0.2926,
      "step": 760
    },
    {
      "epoch": 1.7620137299771166,
      "grad_norm": 4.945687770843506,
      "learning_rate": 1.6475972540045767e-05,
      "loss": 0.2592,
      "step": 770
    },
    {
      "epoch": 1.7848970251716247,
      "grad_norm": 8.866548538208008,
      "learning_rate": 1.6430205949656753e-05,
      "loss": 0.3406,
      "step": 780
    },
    {
      "epoch": 1.8077803203661327,
      "grad_norm": 5.856745719909668,
      "learning_rate": 1.6384439359267736e-05,
      "loss": 0.2088,
      "step": 790
    },
    {
      "epoch": 1.8306636155606406,
      "grad_norm": 3.0020294189453125,
      "learning_rate": 1.633867276887872e-05,
      "loss": 0.2412,
      "step": 800
    },
    {
      "epoch": 1.8535469107551488,
      "grad_norm": 6.320089340209961,
      "learning_rate": 1.6292906178489704e-05,
      "loss": 0.2447,
      "step": 810
    },
    {
      "epoch": 1.8764302059496567,
      "grad_norm": 5.378382682800293,
      "learning_rate": 1.624713958810069e-05,
      "loss": 0.3056,
      "step": 820
    },
    {
      "epoch": 1.8993135011441646,
      "grad_norm": 6.147809982299805,
      "learning_rate": 1.620137299771167e-05,
      "loss": 0.2023,
      "step": 830
    },
    {
      "epoch": 1.9221967963386728,
      "grad_norm": 5.863129138946533,
      "learning_rate": 1.6155606407322655e-05,
      "loss": 0.2293,
      "step": 840
    },
    {
      "epoch": 1.9450800915331807,
      "grad_norm": 9.060140609741211,
      "learning_rate": 1.6109839816933638e-05,
      "loss": 0.2237,
      "step": 850
    },
    {
      "epoch": 1.9679633867276887,
      "grad_norm": 6.961728572845459,
      "learning_rate": 1.6064073226544624e-05,
      "loss": 0.2581,
      "step": 860
    },
    {
      "epoch": 1.9908466819221968,
      "grad_norm": 6.26356315612793,
      "learning_rate": 1.6018306636155606e-05,
      "loss": 0.2635,
      "step": 870
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.922,
      "eval_f1": 0.625,
      "eval_loss": 0.2201540768146515,
      "eval_precision": 0.8158995815899581,
      "eval_recall": 0.5064935064935064,
      "eval_runtime": 466.793,
      "eval_samples_per_second": 6.427,
      "eval_steps_per_second": 0.803,
      "step": 874
    },
    {
      "epoch": 2.013729977116705,
      "grad_norm": 5.640688896179199,
      "learning_rate": 1.5972540045766592e-05,
      "loss": 0.2104,
      "step": 880
    },
    {
      "epoch": 2.0366132723112127,
      "grad_norm": 3.123063802719116,
      "learning_rate": 1.5926773455377575e-05,
      "loss": 0.1974,
      "step": 890
    },
    {
      "epoch": 2.059496567505721,
      "grad_norm": 7.012423992156982,
      "learning_rate": 1.588100686498856e-05,
      "loss": 0.1734,
      "step": 900
    },
    {
      "epoch": 2.082379862700229,
      "grad_norm": 2.9646661281585693,
      "learning_rate": 1.5835240274599543e-05,
      "loss": 0.183,
      "step": 910
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 5.397683620452881,
      "learning_rate": 1.578947368421053e-05,
      "loss": 0.2024,
      "step": 920
    },
    {
      "epoch": 2.128146453089245,
      "grad_norm": 8.884462356567383,
      "learning_rate": 1.5743707093821512e-05,
      "loss": 0.2221,
      "step": 930
    },
    {
      "epoch": 2.151029748283753,
      "grad_norm": 10.535781860351562,
      "learning_rate": 1.5697940503432498e-05,
      "loss": 0.1892,
      "step": 940
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 7.635497093200684,
      "learning_rate": 1.565217391304348e-05,
      "loss": 0.2331,
      "step": 950
    },
    {
      "epoch": 2.196796338672769,
      "grad_norm": 5.792485237121582,
      "learning_rate": 1.5606407322654463e-05,
      "loss": 0.1427,
      "step": 960
    },
    {
      "epoch": 2.219679633867277,
      "grad_norm": 4.823039531707764,
      "learning_rate": 1.556064073226545e-05,
      "loss": 0.1346,
      "step": 970
    },
    {
      "epoch": 2.242562929061785,
      "grad_norm": 3.3252811431884766,
      "learning_rate": 1.551487414187643e-05,
      "loss": 0.2519,
      "step": 980
    },
    {
      "epoch": 2.265446224256293,
      "grad_norm": 6.725792407989502,
      "learning_rate": 1.5469107551487414e-05,
      "loss": 0.2087,
      "step": 990
    },
    {
      "epoch": 2.288329519450801,
      "grad_norm": 5.564913272857666,
      "learning_rate": 1.54233409610984e-05,
      "loss": 0.2071,
      "step": 1000
    },
    {
      "epoch": 2.311212814645309,
      "grad_norm": 7.3963422775268555,
      "learning_rate": 1.5377574370709382e-05,
      "loss": 0.1197,
      "step": 1010
    },
    {
      "epoch": 2.334096109839817,
      "grad_norm": 7.683533191680908,
      "learning_rate": 1.533180778032037e-05,
      "loss": 0.1303,
      "step": 1020
    },
    {
      "epoch": 2.356979405034325,
      "grad_norm": 7.085971832275391,
      "learning_rate": 1.528604118993135e-05,
      "loss": 0.2279,
      "step": 1030
    },
    {
      "epoch": 2.379862700228833,
      "grad_norm": 6.286126136779785,
      "learning_rate": 1.5240274599542335e-05,
      "loss": 0.2119,
      "step": 1040
    },
    {
      "epoch": 2.402745995423341,
      "grad_norm": 8.203539848327637,
      "learning_rate": 1.519450800915332e-05,
      "loss": 0.1789,
      "step": 1050
    },
    {
      "epoch": 2.425629290617849,
      "grad_norm": 4.136854648590088,
      "learning_rate": 1.5148741418764304e-05,
      "loss": 0.1901,
      "step": 1060
    },
    {
      "epoch": 2.448512585812357,
      "grad_norm": 7.339995861053467,
      "learning_rate": 1.5102974828375288e-05,
      "loss": 0.1203,
      "step": 1070
    },
    {
      "epoch": 2.471395881006865,
      "grad_norm": 9.476655006408691,
      "learning_rate": 1.5057208237986272e-05,
      "loss": 0.1569,
      "step": 1080
    },
    {
      "epoch": 2.494279176201373,
      "grad_norm": 2.3362557888031006,
      "learning_rate": 1.5011441647597256e-05,
      "loss": 0.1559,
      "step": 1090
    },
    {
      "epoch": 2.517162471395881,
      "grad_norm": 16.05406379699707,
      "learning_rate": 1.496567505720824e-05,
      "loss": 0.1998,
      "step": 1100
    },
    {
      "epoch": 2.540045766590389,
      "grad_norm": 6.27494478225708,
      "learning_rate": 1.4919908466819223e-05,
      "loss": 0.1773,
      "step": 1110
    },
    {
      "epoch": 2.5629290617848968,
      "grad_norm": 4.944930553436279,
      "learning_rate": 1.4874141876430207e-05,
      "loss": 0.1273,
      "step": 1120
    },
    {
      "epoch": 2.585812356979405,
      "grad_norm": 8.45081615447998,
      "learning_rate": 1.4828375286041192e-05,
      "loss": 0.1373,
      "step": 1130
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 7.712760925292969,
      "learning_rate": 1.4782608695652174e-05,
      "loss": 0.1813,
      "step": 1140
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 1.1060882806777954,
      "learning_rate": 1.4736842105263159e-05,
      "loss": 0.146,
      "step": 1150
    },
    {
      "epoch": 2.654462242562929,
      "grad_norm": 9.616839408874512,
      "learning_rate": 1.4691075514874143e-05,
      "loss": 0.1376,
      "step": 1160
    },
    {
      "epoch": 2.677345537757437,
      "grad_norm": 8.932140350341797,
      "learning_rate": 1.4645308924485127e-05,
      "loss": 0.1287,
      "step": 1170
    },
    {
      "epoch": 2.700228832951945,
      "grad_norm": 7.729507923126221,
      "learning_rate": 1.4599542334096111e-05,
      "loss": 0.1424,
      "step": 1180
    },
    {
      "epoch": 2.723112128146453,
      "grad_norm": 14.757052421569824,
      "learning_rate": 1.4553775743707096e-05,
      "loss": 0.1085,
      "step": 1190
    },
    {
      "epoch": 2.745995423340961,
      "grad_norm": 7.117783069610596,
      "learning_rate": 1.4508009153318078e-05,
      "loss": 0.1609,
      "step": 1200
    },
    {
      "epoch": 2.7688787185354693,
      "grad_norm": 9.284151077270508,
      "learning_rate": 1.4462242562929062e-05,
      "loss": 0.1738,
      "step": 1210
    },
    {
      "epoch": 2.791762013729977,
      "grad_norm": 7.640414714813232,
      "learning_rate": 1.4416475972540047e-05,
      "loss": 0.2624,
      "step": 1220
    },
    {
      "epoch": 2.814645308924485,
      "grad_norm": 5.538022994995117,
      "learning_rate": 1.4370709382151031e-05,
      "loss": 0.1293,
      "step": 1230
    },
    {
      "epoch": 2.837528604118993,
      "grad_norm": 4.844033718109131,
      "learning_rate": 1.4324942791762015e-05,
      "loss": 0.1408,
      "step": 1240
    },
    {
      "epoch": 2.860411899313501,
      "grad_norm": 5.944941520690918,
      "learning_rate": 1.4279176201373e-05,
      "loss": 0.1635,
      "step": 1250
    },
    {
      "epoch": 2.883295194508009,
      "grad_norm": 6.237316131591797,
      "learning_rate": 1.4233409610983984e-05,
      "loss": 0.1216,
      "step": 1260
    },
    {
      "epoch": 2.9061784897025174,
      "grad_norm": 7.063939571380615,
      "learning_rate": 1.4187643020594968e-05,
      "loss": 0.0973,
      "step": 1270
    },
    {
      "epoch": 2.929061784897025,
      "grad_norm": 12.854307174682617,
      "learning_rate": 1.4141876430205952e-05,
      "loss": 0.1803,
      "step": 1280
    },
    {
      "epoch": 2.9519450800915332,
      "grad_norm": 0.8570767045021057,
      "learning_rate": 1.4096109839816933e-05,
      "loss": 0.1438,
      "step": 1290
    },
    {
      "epoch": 2.974828375286041,
      "grad_norm": 9.806314468383789,
      "learning_rate": 1.4050343249427917e-05,
      "loss": 0.1552,
      "step": 1300
    },
    {
      "epoch": 2.997711670480549,
      "grad_norm": 7.831913948059082,
      "learning_rate": 1.4004576659038902e-05,
      "loss": 0.1533,
      "step": 1310
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9403333333333334,
      "eval_f1": 0.7324364723467862,
      "eval_loss": 0.18450553715229034,
      "eval_precision": 0.8626760563380281,
      "eval_recall": 0.6363636363636364,
      "eval_runtime": 480.4905,
      "eval_samples_per_second": 6.244,
      "eval_steps_per_second": 0.78,
      "step": 1311
    },
    {
      "epoch": 3.0205949656750573,
      "grad_norm": 1.958554744720459,
      "learning_rate": 1.3958810068649886e-05,
      "loss": 0.0868,
      "step": 1320
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 5.3028435707092285,
      "learning_rate": 1.391304347826087e-05,
      "loss": 0.0914,
      "step": 1330
    },
    {
      "epoch": 3.066361556064073,
      "grad_norm": 3.720022678375244,
      "learning_rate": 1.3867276887871854e-05,
      "loss": 0.0984,
      "step": 1340
    },
    {
      "epoch": 3.0892448512585813,
      "grad_norm": 10.25777530670166,
      "learning_rate": 1.3821510297482839e-05,
      "loss": 0.0877,
      "step": 1350
    },
    {
      "epoch": 3.1121281464530894,
      "grad_norm": 4.630906105041504,
      "learning_rate": 1.3775743707093823e-05,
      "loss": 0.0723,
      "step": 1360
    },
    {
      "epoch": 3.135011441647597,
      "grad_norm": 4.382411003112793,
      "learning_rate": 1.3729977116704807e-05,
      "loss": 0.1898,
      "step": 1370
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 1.088720440864563,
      "learning_rate": 1.3684210526315791e-05,
      "loss": 0.158,
      "step": 1380
    },
    {
      "epoch": 3.1807780320366135,
      "grad_norm": 4.97512149810791,
      "learning_rate": 1.3638443935926776e-05,
      "loss": 0.0634,
      "step": 1390
    },
    {
      "epoch": 3.203661327231121,
      "grad_norm": 1.1368225812911987,
      "learning_rate": 1.359267734553776e-05,
      "loss": 0.1073,
      "step": 1400
    },
    {
      "epoch": 3.2265446224256293,
      "grad_norm": 9.31472110748291,
      "learning_rate": 1.3546910755148744e-05,
      "loss": 0.1381,
      "step": 1410
    },
    {
      "epoch": 3.2494279176201375,
      "grad_norm": 9.989169120788574,
      "learning_rate": 1.3501144164759727e-05,
      "loss": 0.1276,
      "step": 1420
    },
    {
      "epoch": 3.272311212814645,
      "grad_norm": 10.348637580871582,
      "learning_rate": 1.3455377574370711e-05,
      "loss": 0.1177,
      "step": 1430
    },
    {
      "epoch": 3.2951945080091534,
      "grad_norm": 8.951682090759277,
      "learning_rate": 1.3409610983981693e-05,
      "loss": 0.1019,
      "step": 1440
    },
    {
      "epoch": 3.3180778032036615,
      "grad_norm": 11.483595848083496,
      "learning_rate": 1.3363844393592678e-05,
      "loss": 0.107,
      "step": 1450
    },
    {
      "epoch": 3.3409610983981692,
      "grad_norm": 15.191910743713379,
      "learning_rate": 1.3318077803203662e-05,
      "loss": 0.0831,
      "step": 1460
    },
    {
      "epoch": 3.3638443935926774,
      "grad_norm": 1.4436626434326172,
      "learning_rate": 1.3272311212814646e-05,
      "loss": 0.1019,
      "step": 1470
    },
    {
      "epoch": 3.386727688787185,
      "grad_norm": 0.8494045734405518,
      "learning_rate": 1.322654462242563e-05,
      "loss": 0.0823,
      "step": 1480
    },
    {
      "epoch": 3.4096109839816933,
      "grad_norm": 4.853121757507324,
      "learning_rate": 1.3180778032036615e-05,
      "loss": 0.1525,
      "step": 1490
    },
    {
      "epoch": 3.4324942791762014,
      "grad_norm": 11.029701232910156,
      "learning_rate": 1.3135011441647599e-05,
      "loss": 0.1007,
      "step": 1500
    },
    {
      "epoch": 3.4553775743707096,
      "grad_norm": 10.328639030456543,
      "learning_rate": 1.3089244851258582e-05,
      "loss": 0.08,
      "step": 1510
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 2.812377691268921,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.1734,
      "step": 1520
    },
    {
      "epoch": 3.5011441647597255,
      "grad_norm": 3.1342504024505615,
      "learning_rate": 1.299771167048055e-05,
      "loss": 0.1086,
      "step": 1530
    },
    {
      "epoch": 3.524027459954233,
      "grad_norm": 6.755650520324707,
      "learning_rate": 1.2951945080091534e-05,
      "loss": 0.0899,
      "step": 1540
    },
    {
      "epoch": 3.5469107551487413,
      "grad_norm": 3.3751380443573,
      "learning_rate": 1.2906178489702519e-05,
      "loss": 0.1596,
      "step": 1550
    },
    {
      "epoch": 3.5697940503432495,
      "grad_norm": 5.178233623504639,
      "learning_rate": 1.2860411899313503e-05,
      "loss": 0.1058,
      "step": 1560
    },
    {
      "epoch": 3.5926773455377576,
      "grad_norm": 2.970304489135742,
      "learning_rate": 1.2814645308924487e-05,
      "loss": 0.0853,
      "step": 1570
    },
    {
      "epoch": 3.6155606407322654,
      "grad_norm": 1.2781848907470703,
      "learning_rate": 1.2768878718535471e-05,
      "loss": 0.0215,
      "step": 1580
    },
    {
      "epoch": 3.6384439359267735,
      "grad_norm": 5.022684574127197,
      "learning_rate": 1.2723112128146454e-05,
      "loss": 0.1873,
      "step": 1590
    },
    {
      "epoch": 3.6613272311212812,
      "grad_norm": 9.672075271606445,
      "learning_rate": 1.2677345537757438e-05,
      "loss": 0.1521,
      "step": 1600
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 0.808684229850769,
      "learning_rate": 1.263157894736842e-05,
      "loss": 0.1135,
      "step": 1610
    },
    {
      "epoch": 3.7070938215102975,
      "grad_norm": 3.6225969791412354,
      "learning_rate": 1.2585812356979405e-05,
      "loss": 0.1554,
      "step": 1620
    },
    {
      "epoch": 3.7299771167048057,
      "grad_norm": 9.272879600524902,
      "learning_rate": 1.254004576659039e-05,
      "loss": 0.1403,
      "step": 1630
    },
    {
      "epoch": 3.7528604118993134,
      "grad_norm": 10.954666137695312,
      "learning_rate": 1.2494279176201373e-05,
      "loss": 0.1139,
      "step": 1640
    },
    {
      "epoch": 3.7757437070938216,
      "grad_norm": 8.950544357299805,
      "learning_rate": 1.2448512585812358e-05,
      "loss": 0.102,
      "step": 1650
    },
    {
      "epoch": 3.7986270022883293,
      "grad_norm": 9.160441398620605,
      "learning_rate": 1.2402745995423342e-05,
      "loss": 0.1337,
      "step": 1660
    },
    {
      "epoch": 3.8215102974828374,
      "grad_norm": 4.248624324798584,
      "learning_rate": 1.2356979405034326e-05,
      "loss": 0.096,
      "step": 1670
    },
    {
      "epoch": 3.8443935926773456,
      "grad_norm": 7.205380916595459,
      "learning_rate": 1.231121281464531e-05,
      "loss": 0.1787,
      "step": 1680
    },
    {
      "epoch": 3.8672768878718538,
      "grad_norm": 7.7987895011901855,
      "learning_rate": 1.2265446224256295e-05,
      "loss": 0.153,
      "step": 1690
    },
    {
      "epoch": 3.8901601830663615,
      "grad_norm": 9.114705085754395,
      "learning_rate": 1.2219679633867279e-05,
      "loss": 0.0462,
      "step": 1700
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 11.758488655090332,
      "learning_rate": 1.2173913043478263e-05,
      "loss": 0.1294,
      "step": 1710
    },
    {
      "epoch": 3.9359267734553773,
      "grad_norm": 4.584585666656494,
      "learning_rate": 1.2128146453089247e-05,
      "loss": 0.0804,
      "step": 1720
    },
    {
      "epoch": 3.9588100686498855,
      "grad_norm": 7.8445143699646,
      "learning_rate": 1.2082379862700232e-05,
      "loss": 0.0946,
      "step": 1730
    },
    {
      "epoch": 3.9816933638443937,
      "grad_norm": 7.713889122009277,
      "learning_rate": 1.2036613272311213e-05,
      "loss": 0.1103,
      "step": 1740
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.947,
      "eval_f1": 0.7916120576671035,
      "eval_loss": 0.1739961802959442,
      "eval_precision": 0.798941798941799,
      "eval_recall": 0.7844155844155845,
      "eval_runtime": 484.2255,
      "eval_samples_per_second": 6.195,
      "eval_steps_per_second": 0.774,
      "step": 1748
    },
    {
      "epoch": 4.004576659038902,
      "grad_norm": 4.842547416687012,
      "learning_rate": 1.1990846681922197e-05,
      "loss": 0.1225,
      "step": 1750
    },
    {
      "epoch": 4.02745995423341,
      "grad_norm": 9.649746894836426,
      "learning_rate": 1.1945080091533181e-05,
      "loss": 0.0356,
      "step": 1760
    },
    {
      "epoch": 4.050343249427917,
      "grad_norm": 1.4539258480072021,
      "learning_rate": 1.1899313501144165e-05,
      "loss": 0.0891,
      "step": 1770
    },
    {
      "epoch": 4.073226544622425,
      "grad_norm": 3.9862403869628906,
      "learning_rate": 1.185354691075515e-05,
      "loss": 0.0881,
      "step": 1780
    },
    {
      "epoch": 4.0961098398169336,
      "grad_norm": 0.904597818851471,
      "learning_rate": 1.1807780320366134e-05,
      "loss": 0.0503,
      "step": 1790
    },
    {
      "epoch": 4.118993135011442,
      "grad_norm": 0.5362563729286194,
      "learning_rate": 1.1762013729977118e-05,
      "loss": 0.0638,
      "step": 1800
    },
    {
      "epoch": 4.14187643020595,
      "grad_norm": 10.193656921386719,
      "learning_rate": 1.1716247139588102e-05,
      "loss": 0.0797,
      "step": 1810
    },
    {
      "epoch": 4.164759725400458,
      "grad_norm": 0.9323107600212097,
      "learning_rate": 1.1670480549199087e-05,
      "loss": 0.091,
      "step": 1820
    },
    {
      "epoch": 4.187643020594965,
      "grad_norm": 8.776518821716309,
      "learning_rate": 1.1624713958810069e-05,
      "loss": 0.0709,
      "step": 1830
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 32.00632858276367,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.097,
      "step": 1840
    },
    {
      "epoch": 4.233409610983982,
      "grad_norm": 6.682929039001465,
      "learning_rate": 1.1533180778032038e-05,
      "loss": 0.1369,
      "step": 1850
    },
    {
      "epoch": 4.25629290617849,
      "grad_norm": 7.394244194030762,
      "learning_rate": 1.1487414187643022e-05,
      "loss": 0.0448,
      "step": 1860
    },
    {
      "epoch": 4.279176201372998,
      "grad_norm": 2.1588375568389893,
      "learning_rate": 1.1441647597254006e-05,
      "loss": 0.0578,
      "step": 1870
    },
    {
      "epoch": 4.302059496567506,
      "grad_norm": 13.671113967895508,
      "learning_rate": 1.139588100686499e-05,
      "loss": 0.0692,
      "step": 1880
    },
    {
      "epoch": 4.324942791762013,
      "grad_norm": 3.5848677158355713,
      "learning_rate": 1.1350114416475973e-05,
      "loss": 0.1424,
      "step": 1890
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 1.2093760967254639,
      "learning_rate": 1.1304347826086957e-05,
      "loss": 0.0908,
      "step": 1900
    },
    {
      "epoch": 4.37070938215103,
      "grad_norm": 7.004308700561523,
      "learning_rate": 1.1258581235697941e-05,
      "loss": 0.0741,
      "step": 1910
    },
    {
      "epoch": 4.393592677345538,
      "grad_norm": 1.0218676328659058,
      "learning_rate": 1.1212814645308924e-05,
      "loss": 0.0381,
      "step": 1920
    },
    {
      "epoch": 4.416475972540046,
      "grad_norm": 0.5433114171028137,
      "learning_rate": 1.1167048054919908e-05,
      "loss": 0.0635,
      "step": 1930
    },
    {
      "epoch": 4.439359267734554,
      "grad_norm": 15.500242233276367,
      "learning_rate": 1.1121281464530893e-05,
      "loss": 0.1155,
      "step": 1940
    },
    {
      "epoch": 4.462242562929061,
      "grad_norm": 11.12073040008545,
      "learning_rate": 1.1075514874141877e-05,
      "loss": 0.1074,
      "step": 1950
    },
    {
      "epoch": 4.48512585812357,
      "grad_norm": 2.4723286628723145,
      "learning_rate": 1.1029748283752861e-05,
      "loss": 0.0692,
      "step": 1960
    },
    {
      "epoch": 4.508009153318078,
      "grad_norm": 0.8850125074386597,
      "learning_rate": 1.0983981693363845e-05,
      "loss": 0.1001,
      "step": 1970
    },
    {
      "epoch": 4.530892448512586,
      "grad_norm": 1.3539841175079346,
      "learning_rate": 1.093821510297483e-05,
      "loss": 0.0691,
      "step": 1980
    },
    {
      "epoch": 4.553775743707094,
      "grad_norm": 13.392587661743164,
      "learning_rate": 1.0892448512585814e-05,
      "loss": 0.1143,
      "step": 1990
    },
    {
      "epoch": 4.576659038901602,
      "grad_norm": 0.677757740020752,
      "learning_rate": 1.0846681922196798e-05,
      "loss": 0.0894,
      "step": 2000
    },
    {
      "epoch": 4.5995423340961095,
      "grad_norm": 13.974298477172852,
      "learning_rate": 1.0800915331807782e-05,
      "loss": 0.1108,
      "step": 2010
    },
    {
      "epoch": 4.622425629290618,
      "grad_norm": 1.3631123304367065,
      "learning_rate": 1.0755148741418767e-05,
      "loss": 0.1027,
      "step": 2020
    },
    {
      "epoch": 4.645308924485126,
      "grad_norm": 7.351154804229736,
      "learning_rate": 1.070938215102975e-05,
      "loss": 0.0962,
      "step": 2030
    },
    {
      "epoch": 4.668192219679634,
      "grad_norm": 0.17597872018814087,
      "learning_rate": 1.0663615560640732e-05,
      "loss": 0.0716,
      "step": 2040
    },
    {
      "epoch": 4.691075514874142,
      "grad_norm": 2.3791229724884033,
      "learning_rate": 1.0617848970251716e-05,
      "loss": 0.0565,
      "step": 2050
    },
    {
      "epoch": 4.71395881006865,
      "grad_norm": 9.367830276489258,
      "learning_rate": 1.05720823798627e-05,
      "loss": 0.0667,
      "step": 2060
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 4.948362350463867,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.087,
      "step": 2070
    },
    {
      "epoch": 4.759725400457666,
      "grad_norm": 4.57525634765625,
      "learning_rate": 1.0480549199084669e-05,
      "loss": 0.0343,
      "step": 2080
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 1.6146554946899414,
      "learning_rate": 1.0434782608695653e-05,
      "loss": 0.0232,
      "step": 2090
    },
    {
      "epoch": 4.805491990846682,
      "grad_norm": 0.06703134626150131,
      "learning_rate": 1.0389016018306637e-05,
      "loss": 0.1061,
      "step": 2100
    },
    {
      "epoch": 4.82837528604119,
      "grad_norm": 5.9480977058410645,
      "learning_rate": 1.0343249427917621e-05,
      "loss": 0.0872,
      "step": 2110
    },
    {
      "epoch": 4.851258581235698,
      "grad_norm": 6.407832145690918,
      "learning_rate": 1.0297482837528606e-05,
      "loss": 0.0659,
      "step": 2120
    },
    {
      "epoch": 4.874141876430206,
      "grad_norm": 17.560134887695312,
      "learning_rate": 1.025171624713959e-05,
      "loss": 0.0982,
      "step": 2130
    },
    {
      "epoch": 4.897025171624714,
      "grad_norm": 0.8704062700271606,
      "learning_rate": 1.0205949656750573e-05,
      "loss": 0.0833,
      "step": 2140
    },
    {
      "epoch": 4.919908466819222,
      "grad_norm": 4.861249923706055,
      "learning_rate": 1.0160183066361557e-05,
      "loss": 0.0366,
      "step": 2150
    },
    {
      "epoch": 4.94279176201373,
      "grad_norm": 13.853109359741211,
      "learning_rate": 1.0114416475972541e-05,
      "loss": 0.1253,
      "step": 2160
    },
    {
      "epoch": 4.965675057208238,
      "grad_norm": 0.12402172386646271,
      "learning_rate": 1.0068649885583525e-05,
      "loss": 0.0295,
      "step": 2170
    },
    {
      "epoch": 4.988558352402746,
      "grad_norm": 7.446539878845215,
      "learning_rate": 1.002288329519451e-05,
      "loss": 0.0993,
      "step": 2180
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9566666666666667,
      "eval_f1": 0.8209366391184573,
      "eval_loss": 0.18482747673988342,
      "eval_precision": 0.873900293255132,
      "eval_recall": 0.7740259740259741,
      "eval_runtime": 487.752,
      "eval_samples_per_second": 6.151,
      "eval_steps_per_second": 0.769,
      "step": 2185
    },
    {
      "epoch": 5.011441647597254,
      "grad_norm": 34.108154296875,
      "learning_rate": 9.977116704805492e-06,
      "loss": 0.065,
      "step": 2190
    },
    {
      "epoch": 5.034324942791762,
      "grad_norm": 13.608236312866211,
      "learning_rate": 9.931350114416476e-06,
      "loss": 0.0363,
      "step": 2200
    },
    {
      "epoch": 5.05720823798627,
      "grad_norm": 3.2144134044647217,
      "learning_rate": 9.88558352402746e-06,
      "loss": 0.0504,
      "step": 2210
    },
    {
      "epoch": 5.080091533180778,
      "grad_norm": 5.781980514526367,
      "learning_rate": 9.839816933638445e-06,
      "loss": 0.063,
      "step": 2220
    },
    {
      "epoch": 5.102974828375286,
      "grad_norm": 0.5758342146873474,
      "learning_rate": 9.794050343249429e-06,
      "loss": 0.0589,
      "step": 2230
    },
    {
      "epoch": 5.125858123569794,
      "grad_norm": 2.81217360496521,
      "learning_rate": 9.748283752860412e-06,
      "loss": 0.0739,
      "step": 2240
    },
    {
      "epoch": 5.148741418764302,
      "grad_norm": 7.917785167694092,
      "learning_rate": 9.702517162471396e-06,
      "loss": 0.0647,
      "step": 2250
    },
    {
      "epoch": 5.17162471395881,
      "grad_norm": 3.4581542015075684,
      "learning_rate": 9.65675057208238e-06,
      "loss": 0.0583,
      "step": 2260
    },
    {
      "epoch": 5.194508009153318,
      "grad_norm": 0.5402331948280334,
      "learning_rate": 9.610983981693364e-06,
      "loss": 0.0467,
      "step": 2270
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 5.992833137512207,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.0393,
      "step": 2280
    },
    {
      "epoch": 5.240274599542334,
      "grad_norm": 6.255791187286377,
      "learning_rate": 9.519450800915333e-06,
      "loss": 0.0597,
      "step": 2290
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 16.440099716186523,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.0434,
      "step": 2300
    },
    {
      "epoch": 5.28604118993135,
      "grad_norm": 4.343466758728027,
      "learning_rate": 9.4279176201373e-06,
      "loss": 0.0656,
      "step": 2310
    },
    {
      "epoch": 5.308924485125858,
      "grad_norm": 10.251387596130371,
      "learning_rate": 9.382151029748284e-06,
      "loss": 0.0548,
      "step": 2320
    },
    {
      "epoch": 5.331807780320366,
      "grad_norm": 0.09303326904773712,
      "learning_rate": 9.336384439359268e-06,
      "loss": 0.006,
      "step": 2330
    },
    {
      "epoch": 5.354691075514874,
      "grad_norm": 0.09579654783010483,
      "learning_rate": 9.290617848970253e-06,
      "loss": 0.0521,
      "step": 2340
    },
    {
      "epoch": 5.377574370709382,
      "grad_norm": 13.25965690612793,
      "learning_rate": 9.244851258581237e-06,
      "loss": 0.0482,
      "step": 2350
    },
    {
      "epoch": 5.4004576659038905,
      "grad_norm": 7.063952922821045,
      "learning_rate": 9.199084668192221e-06,
      "loss": 0.0385,
      "step": 2360
    },
    {
      "epoch": 5.423340961098398,
      "grad_norm": 0.02596321329474449,
      "learning_rate": 9.153318077803205e-06,
      "loss": 0.0445,
      "step": 2370
    },
    {
      "epoch": 5.446224256292906,
      "grad_norm": 6.1282219886779785,
      "learning_rate": 9.107551487414188e-06,
      "loss": 0.0406,
      "step": 2380
    },
    {
      "epoch": 5.469107551487414,
      "grad_norm": 2.6471519470214844,
      "learning_rate": 9.061784897025172e-06,
      "loss": 0.0726,
      "step": 2390
    },
    {
      "epoch": 5.491990846681922,
      "grad_norm": 13.22978401184082,
      "learning_rate": 9.016018306636156e-06,
      "loss": 0.0287,
      "step": 2400
    },
    {
      "epoch": 5.51487414187643,
      "grad_norm": 0.24730604887008667,
      "learning_rate": 8.97025171624714e-06,
      "loss": 0.0447,
      "step": 2410
    },
    {
      "epoch": 5.537757437070939,
      "grad_norm": 0.09373641014099121,
      "learning_rate": 8.924485125858125e-06,
      "loss": 0.0527,
      "step": 2420
    },
    {
      "epoch": 5.560640732265446,
      "grad_norm": 12.915432929992676,
      "learning_rate": 8.878718535469109e-06,
      "loss": 0.0369,
      "step": 2430
    },
    {
      "epoch": 5.583524027459954,
      "grad_norm": 0.13901591300964355,
      "learning_rate": 8.832951945080093e-06,
      "loss": 0.0275,
      "step": 2440
    },
    {
      "epoch": 5.606407322654462,
      "grad_norm": 1.3569397926330566,
      "learning_rate": 8.787185354691076e-06,
      "loss": 0.079,
      "step": 2450
    },
    {
      "epoch": 5.62929061784897,
      "grad_norm": 0.9236404299736023,
      "learning_rate": 8.74141876430206e-06,
      "loss": 0.0502,
      "step": 2460
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 25.0471134185791,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0905,
      "step": 2470
    },
    {
      "epoch": 5.675057208237987,
      "grad_norm": 3.172802686691284,
      "learning_rate": 8.649885583524029e-06,
      "loss": 0.0375,
      "step": 2480
    },
    {
      "epoch": 5.697940503432494,
      "grad_norm": 0.17244823276996613,
      "learning_rate": 8.604118993135013e-06,
      "loss": 0.0498,
      "step": 2490
    },
    {
      "epoch": 5.720823798627002,
      "grad_norm": 0.07754943519830704,
      "learning_rate": 8.558352402745997e-06,
      "loss": 0.0244,
      "step": 2500
    },
    {
      "epoch": 5.74370709382151,
      "grad_norm": 5.766843318939209,
      "learning_rate": 8.51258581235698e-06,
      "loss": 0.1092,
      "step": 2510
    },
    {
      "epoch": 5.766590389016018,
      "grad_norm": 0.32190456986427307,
      "learning_rate": 8.466819221967964e-06,
      "loss": 0.0192,
      "step": 2520
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 0.6670517921447754,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.0558,
      "step": 2530
    },
    {
      "epoch": 5.812356979405035,
      "grad_norm": 6.787315845489502,
      "learning_rate": 8.375286041189932e-06,
      "loss": 0.061,
      "step": 2540
    },
    {
      "epoch": 5.835240274599542,
      "grad_norm": 5.624329090118408,
      "learning_rate": 8.329519450800915e-06,
      "loss": 0.0597,
      "step": 2550
    },
    {
      "epoch": 5.85812356979405,
      "grad_norm": 0.3094680607318878,
      "learning_rate": 8.2837528604119e-06,
      "loss": 0.0298,
      "step": 2560
    },
    {
      "epoch": 5.881006864988558,
      "grad_norm": 6.475803375244141,
      "learning_rate": 8.237986270022884e-06,
      "loss": 0.0709,
      "step": 2570
    },
    {
      "epoch": 5.9038901601830664,
      "grad_norm": 6.373477935791016,
      "learning_rate": 8.192219679633868e-06,
      "loss": 0.0941,
      "step": 2580
    },
    {
      "epoch": 5.926773455377575,
      "grad_norm": 2.7081711292266846,
      "learning_rate": 8.146453089244852e-06,
      "loss": 0.0551,
      "step": 2590
    },
    {
      "epoch": 5.949656750572083,
      "grad_norm": 0.0725860670208931,
      "learning_rate": 8.100686498855835e-06,
      "loss": 0.0511,
      "step": 2600
    },
    {
      "epoch": 5.97254004576659,
      "grad_norm": 9.917418479919434,
      "learning_rate": 8.054919908466819e-06,
      "loss": 0.0824,
      "step": 2610
    },
    {
      "epoch": 5.995423340961098,
      "grad_norm": 10.323348999023438,
      "learning_rate": 8.009153318077803e-06,
      "loss": 0.0828,
      "step": 2620
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9546666666666667,
      "eval_f1": 0.8224543080939948,
      "eval_loss": 0.18422828614711761,
      "eval_precision": 0.8267716535433071,
      "eval_recall": 0.8181818181818182,
      "eval_runtime": 482.9123,
      "eval_samples_per_second": 6.212,
      "eval_steps_per_second": 0.777,
      "step": 2622
    },
    {
      "epoch": 6.018306636155606,
      "grad_norm": 0.3304610252380371,
      "learning_rate": 7.963386727688787e-06,
      "loss": 0.0449,
      "step": 2630
    },
    {
      "epoch": 6.0411899313501145,
      "grad_norm": 1.7483686208724976,
      "learning_rate": 7.917620137299772e-06,
      "loss": 0.0295,
      "step": 2640
    },
    {
      "epoch": 6.064073226544623,
      "grad_norm": 1.9704283475875854,
      "learning_rate": 7.871853546910756e-06,
      "loss": 0.0106,
      "step": 2650
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 1.250950813293457,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.0337,
      "step": 2660
    },
    {
      "epoch": 6.109839816933638,
      "grad_norm": 0.07276958972215652,
      "learning_rate": 7.780320366132724e-06,
      "loss": 0.0204,
      "step": 2670
    },
    {
      "epoch": 6.132723112128146,
      "grad_norm": 13.211008071899414,
      "learning_rate": 7.734553775743707e-06,
      "loss": 0.0366,
      "step": 2680
    },
    {
      "epoch": 6.155606407322654,
      "grad_norm": 25.164451599121094,
      "learning_rate": 7.688787185354691e-06,
      "loss": 0.0635,
      "step": 2690
    },
    {
      "epoch": 6.178489702517163,
      "grad_norm": 11.677979469299316,
      "learning_rate": 7.643020594965675e-06,
      "loss": 0.0513,
      "step": 2700
    },
    {
      "epoch": 6.201372997711671,
      "grad_norm": 1.7251139879226685,
      "learning_rate": 7.59725400457666e-06,
      "loss": 0.0255,
      "step": 2710
    },
    {
      "epoch": 6.224256292906179,
      "grad_norm": 0.06408274173736572,
      "learning_rate": 7.551487414187644e-06,
      "loss": 0.0177,
      "step": 2720
    },
    {
      "epoch": 6.247139588100686,
      "grad_norm": 4.99061393737793,
      "learning_rate": 7.505720823798628e-06,
      "loss": 0.0438,
      "step": 2730
    },
    {
      "epoch": 6.270022883295194,
      "grad_norm": 1.2597424983978271,
      "learning_rate": 7.459954233409612e-06,
      "loss": 0.0152,
      "step": 2740
    },
    {
      "epoch": 6.2929061784897025,
      "grad_norm": 0.09343810379505157,
      "learning_rate": 7.414187643020596e-06,
      "loss": 0.0562,
      "step": 2750
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 14.002947807312012,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0603,
      "step": 2760
    },
    {
      "epoch": 6.338672768878719,
      "grad_norm": 13.746837615966797,
      "learning_rate": 7.3226544622425635e-06,
      "loss": 0.0447,
      "step": 2770
    },
    {
      "epoch": 6.361556064073227,
      "grad_norm": 8.076384544372559,
      "learning_rate": 7.276887871853548e-06,
      "loss": 0.0152,
      "step": 2780
    },
    {
      "epoch": 6.384439359267734,
      "grad_norm": 0.06626226007938385,
      "learning_rate": 7.231121281464531e-06,
      "loss": 0.043,
      "step": 2790
    },
    {
      "epoch": 6.407322654462242,
      "grad_norm": 0.03910987824201584,
      "learning_rate": 7.1853546910755154e-06,
      "loss": 0.0367,
      "step": 2800
    },
    {
      "epoch": 6.4302059496567505,
      "grad_norm": 0.36352571845054626,
      "learning_rate": 7.1395881006865e-06,
      "loss": 0.0351,
      "step": 2810
    },
    {
      "epoch": 6.453089244851259,
      "grad_norm": 5.302651882171631,
      "learning_rate": 7.093821510297484e-06,
      "loss": 0.0235,
      "step": 2820
    },
    {
      "epoch": 6.475972540045767,
      "grad_norm": 0.0955335721373558,
      "learning_rate": 7.0480549199084665e-06,
      "loss": 0.0066,
      "step": 2830
    },
    {
      "epoch": 6.498855835240275,
      "grad_norm": 0.05399693176150322,
      "learning_rate": 7.002288329519451e-06,
      "loss": 0.044,
      "step": 2840
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 1.2910200357437134,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.0655,
      "step": 2850
    },
    {
      "epoch": 6.54462242562929,
      "grad_norm": 0.09291088581085205,
      "learning_rate": 6.910755148741419e-06,
      "loss": 0.0391,
      "step": 2860
    },
    {
      "epoch": 6.567505720823799,
      "grad_norm": 12.287659645080566,
      "learning_rate": 6.8649885583524035e-06,
      "loss": 0.0403,
      "step": 2870
    },
    {
      "epoch": 6.590389016018307,
      "grad_norm": 17.3586483001709,
      "learning_rate": 6.819221967963388e-06,
      "loss": 0.0816,
      "step": 2880
    },
    {
      "epoch": 6.613272311212815,
      "grad_norm": 2.283620595932007,
      "learning_rate": 6.773455377574372e-06,
      "loss": 0.0257,
      "step": 2890
    },
    {
      "epoch": 6.636155606407323,
      "grad_norm": 5.857091426849365,
      "learning_rate": 6.7276887871853554e-06,
      "loss": 0.0323,
      "step": 2900
    },
    {
      "epoch": 6.65903890160183,
      "grad_norm": 0.1564737856388092,
      "learning_rate": 6.681922196796339e-06,
      "loss": 0.024,
      "step": 2910
    },
    {
      "epoch": 6.6819221967963385,
      "grad_norm": 4.840410232543945,
      "learning_rate": 6.636155606407323e-06,
      "loss": 0.0095,
      "step": 2920
    },
    {
      "epoch": 6.704805491990847,
      "grad_norm": 0.03732015937566757,
      "learning_rate": 6.590389016018307e-06,
      "loss": 0.0024,
      "step": 2930
    },
    {
      "epoch": 6.727688787185355,
      "grad_norm": 17.051992416381836,
      "learning_rate": 6.544622425629291e-06,
      "loss": 0.0355,
      "step": 2940
    },
    {
      "epoch": 6.750572082379863,
      "grad_norm": 0.21356625854969025,
      "learning_rate": 6.498855835240275e-06,
      "loss": 0.0712,
      "step": 2950
    },
    {
      "epoch": 6.77345537757437,
      "grad_norm": 24.441272735595703,
      "learning_rate": 6.453089244851259e-06,
      "loss": 0.0566,
      "step": 2960
    },
    {
      "epoch": 6.796338672768878,
      "grad_norm": 0.0346912182867527,
      "learning_rate": 6.4073226544622435e-06,
      "loss": 0.0128,
      "step": 2970
    },
    {
      "epoch": 6.8192219679633865,
      "grad_norm": 0.09826188534498215,
      "learning_rate": 6.361556064073227e-06,
      "loss": 0.032,
      "step": 2980
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 0.028876157477498055,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.0203,
      "step": 2990
    },
    {
      "epoch": 6.864988558352403,
      "grad_norm": 0.04845708608627319,
      "learning_rate": 6.270022883295195e-06,
      "loss": 0.0306,
      "step": 3000
    },
    {
      "epoch": 6.887871853546911,
      "grad_norm": 0.10485723614692688,
      "learning_rate": 6.224256292906179e-06,
      "loss": 0.032,
      "step": 3010
    },
    {
      "epoch": 6.910755148741419,
      "grad_norm": 0.03566228225827217,
      "learning_rate": 6.178489702517163e-06,
      "loss": 0.1129,
      "step": 3020
    },
    {
      "epoch": 6.933638443935926,
      "grad_norm": 9.495827674865723,
      "learning_rate": 6.132723112128147e-06,
      "loss": 0.0764,
      "step": 3030
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 0.13236373662948608,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.0784,
      "step": 3040
    },
    {
      "epoch": 6.979405034324943,
      "grad_norm": 9.212897300720215,
      "learning_rate": 6.041189931350116e-06,
      "loss": 0.0561,
      "step": 3050
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9576666666666667,
      "eval_f1": 0.8276797829036635,
      "eval_loss": 0.22649210691452026,
      "eval_precision": 0.8664772727272727,
      "eval_recall": 0.7922077922077922,
      "eval_runtime": 477.7781,
      "eval_samples_per_second": 6.279,
      "eval_steps_per_second": 0.785,
      "step": 3059
    },
    {
      "epoch": 7.002288329519451,
      "grad_norm": 0.2230781465768814,
      "learning_rate": 5.995423340961098e-06,
      "loss": 0.0175,
      "step": 3060
    },
    {
      "epoch": 7.025171624713959,
      "grad_norm": 0.3139317035675049,
      "learning_rate": 5.949656750572083e-06,
      "loss": 0.0305,
      "step": 3070
    },
    {
      "epoch": 7.048054919908467,
      "grad_norm": 1.572851538658142,
      "learning_rate": 5.903890160183067e-06,
      "loss": 0.0144,
      "step": 3080
    },
    {
      "epoch": 7.0709382151029745,
      "grad_norm": 0.015420913696289062,
      "learning_rate": 5.858123569794051e-06,
      "loss": 0.0445,
      "step": 3090
    },
    {
      "epoch": 7.093821510297483,
      "grad_norm": 0.01284050103276968,
      "learning_rate": 5.8123569794050346e-06,
      "loss": 0.0063,
      "step": 3100
    },
    {
      "epoch": 7.116704805491991,
      "grad_norm": 0.005511228460818529,
      "learning_rate": 5.766590389016019e-06,
      "loss": 0.0195,
      "step": 3110
    },
    {
      "epoch": 7.139588100686499,
      "grad_norm": 0.17987781763076782,
      "learning_rate": 5.720823798627003e-06,
      "loss": 0.0135,
      "step": 3120
    },
    {
      "epoch": 7.162471395881007,
      "grad_norm": 1.9991252422332764,
      "learning_rate": 5.6750572082379865e-06,
      "loss": 0.0281,
      "step": 3130
    },
    {
      "epoch": 7.185354691075515,
      "grad_norm": 0.08361247181892395,
      "learning_rate": 5.629290617848971e-06,
      "loss": 0.0165,
      "step": 3140
    },
    {
      "epoch": 7.2082379862700225,
      "grad_norm": 11.7578125,
      "learning_rate": 5.583524027459954e-06,
      "loss": 0.0644,
      "step": 3150
    },
    {
      "epoch": 7.231121281464531,
      "grad_norm": 134.83526611328125,
      "learning_rate": 5.537757437070938e-06,
      "loss": 0.0511,
      "step": 3160
    },
    {
      "epoch": 7.254004576659039,
      "grad_norm": 0.17748823761940002,
      "learning_rate": 5.491990846681923e-06,
      "loss": 0.0023,
      "step": 3170
    },
    {
      "epoch": 7.276887871853547,
      "grad_norm": 0.07415437698364258,
      "learning_rate": 5.446224256292907e-06,
      "loss": 0.0152,
      "step": 3180
    },
    {
      "epoch": 7.299771167048055,
      "grad_norm": 0.02325492911040783,
      "learning_rate": 5.400457665903891e-06,
      "loss": 0.0025,
      "step": 3190
    },
    {
      "epoch": 7.322654462242563,
      "grad_norm": 0.014740431681275368,
      "learning_rate": 5.354691075514875e-06,
      "loss": 0.0235,
      "step": 3200
    },
    {
      "epoch": 7.345537757437071,
      "grad_norm": 15.180429458618164,
      "learning_rate": 5.308924485125858e-06,
      "loss": 0.0342,
      "step": 3210
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 0.017640849575400352,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.0753,
      "step": 3220
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 2.5490193367004395,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.031,
      "step": 3230
    },
    {
      "epoch": 7.414187643020595,
      "grad_norm": 0.03710060566663742,
      "learning_rate": 5.171624713958811e-06,
      "loss": 0.0441,
      "step": 3240
    },
    {
      "epoch": 7.437070938215103,
      "grad_norm": 0.04576344043016434,
      "learning_rate": 5.125858123569795e-06,
      "loss": 0.0077,
      "step": 3250
    },
    {
      "epoch": 7.459954233409611,
      "grad_norm": 9.757031440734863,
      "learning_rate": 5.080091533180778e-06,
      "loss": 0.0357,
      "step": 3260
    },
    {
      "epoch": 7.482837528604119,
      "grad_norm": 3.826807975769043,
      "learning_rate": 5.034324942791763e-06,
      "loss": 0.0098,
      "step": 3270
    },
    {
      "epoch": 7.505720823798627,
      "grad_norm": 0.012159720994532108,
      "learning_rate": 4.988558352402746e-06,
      "loss": 0.0099,
      "step": 3280
    },
    {
      "epoch": 7.528604118993135,
      "grad_norm": 0.024385057389736176,
      "learning_rate": 4.94279176201373e-06,
      "loss": 0.0415,
      "step": 3290
    },
    {
      "epoch": 7.551487414187643,
      "grad_norm": 10.798223495483398,
      "learning_rate": 4.8970251716247146e-06,
      "loss": 0.0338,
      "step": 3300
    },
    {
      "epoch": 7.574370709382151,
      "grad_norm": 0.1050088107585907,
      "learning_rate": 4.851258581235698e-06,
      "loss": 0.0149,
      "step": 3310
    },
    {
      "epoch": 7.597254004576659,
      "grad_norm": 0.10075128078460693,
      "learning_rate": 4.805491990846682e-06,
      "loss": 0.0346,
      "step": 3320
    },
    {
      "epoch": 7.620137299771167,
      "grad_norm": 0.01154378429055214,
      "learning_rate": 4.7597254004576665e-06,
      "loss": 0.0304,
      "step": 3330
    },
    {
      "epoch": 7.643020594965675,
      "grad_norm": 0.14656661450862885,
      "learning_rate": 4.71395881006865e-06,
      "loss": 0.0218,
      "step": 3340
    },
    {
      "epoch": 7.665903890160183,
      "grad_norm": 0.1296929568052292,
      "learning_rate": 4.668192219679634e-06,
      "loss": 0.004,
      "step": 3350
    },
    {
      "epoch": 7.688787185354691,
      "grad_norm": 17.99071502685547,
      "learning_rate": 4.622425629290618e-06,
      "loss": 0.0124,
      "step": 3360
    },
    {
      "epoch": 7.711670480549199,
      "grad_norm": 0.031111977994441986,
      "learning_rate": 4.576659038901603e-06,
      "loss": 0.043,
      "step": 3370
    },
    {
      "epoch": 7.7345537757437075,
      "grad_norm": 0.15365378558635712,
      "learning_rate": 4.530892448512586e-06,
      "loss": 0.0347,
      "step": 3380
    },
    {
      "epoch": 7.757437070938215,
      "grad_norm": 7.1013264656066895,
      "learning_rate": 4.48512585812357e-06,
      "loss": 0.0221,
      "step": 3390
    },
    {
      "epoch": 7.780320366132723,
      "grad_norm": 0.016889646649360657,
      "learning_rate": 4.4393592677345545e-06,
      "loss": 0.0081,
      "step": 3400
    },
    {
      "epoch": 7.803203661327231,
      "grad_norm": 0.024218769744038582,
      "learning_rate": 4.393592677345538e-06,
      "loss": 0.0113,
      "step": 3410
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 0.19976332783699036,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0675,
      "step": 3420
    },
    {
      "epoch": 7.848970251716247,
      "grad_norm": 0.048462435603141785,
      "learning_rate": 4.3020594965675065e-06,
      "loss": 0.0033,
      "step": 3430
    },
    {
      "epoch": 7.871853546910755,
      "grad_norm": 0.5736739635467529,
      "learning_rate": 4.25629290617849e-06,
      "loss": 0.0017,
      "step": 3440
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 108.88908386230469,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.0439,
      "step": 3450
    },
    {
      "epoch": 7.917620137299771,
      "grad_norm": 0.007330596446990967,
      "learning_rate": 4.1647597254004575e-06,
      "loss": 0.0254,
      "step": 3460
    },
    {
      "epoch": 7.940503432494279,
      "grad_norm": 3.7773475646972656,
      "learning_rate": 4.118993135011442e-06,
      "loss": 0.0065,
      "step": 3470
    },
    {
      "epoch": 7.963386727688787,
      "grad_norm": 0.013736007735133171,
      "learning_rate": 4.073226544622426e-06,
      "loss": 0.0178,
      "step": 3480
    },
    {
      "epoch": 7.9862700228832955,
      "grad_norm": 6.686263084411621,
      "learning_rate": 4.0274599542334094e-06,
      "loss": 0.0261,
      "step": 3490
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9596666666666667,
      "eval_f1": 0.8414154652686763,
      "eval_loss": 0.26019713282585144,
      "eval_precision": 0.8492063492063492,
      "eval_recall": 0.8337662337662337,
      "eval_runtime": 466.5356,
      "eval_samples_per_second": 6.43,
      "eval_steps_per_second": 0.804,
      "step": 3496
    },
    {
      "epoch": 8.009153318077804,
      "grad_norm": 0.008571583777666092,
      "learning_rate": 3.981693363844394e-06,
      "loss": 0.0019,
      "step": 3500
    },
    {
      "epoch": 8.03203661327231,
      "grad_norm": 0.0352618470788002,
      "learning_rate": 3.935926773455378e-06,
      "loss": 0.0138,
      "step": 3510
    },
    {
      "epoch": 8.05491990846682,
      "grad_norm": 0.006273346953094006,
      "learning_rate": 3.890160183066362e-06,
      "loss": 0.018,
      "step": 3520
    },
    {
      "epoch": 8.077803203661327,
      "grad_norm": 6.938276290893555,
      "learning_rate": 3.844393592677346e-06,
      "loss": 0.042,
      "step": 3530
    },
    {
      "epoch": 8.100686498855834,
      "grad_norm": 1.6476205587387085,
      "learning_rate": 3.79862700228833e-06,
      "loss": 0.0026,
      "step": 3540
    },
    {
      "epoch": 8.123569794050344,
      "grad_norm": 0.020218966528773308,
      "learning_rate": 3.752860411899314e-06,
      "loss": 0.0082,
      "step": 3550
    },
    {
      "epoch": 8.14645308924485,
      "grad_norm": 0.17721182107925415,
      "learning_rate": 3.707093821510298e-06,
      "loss": 0.0014,
      "step": 3560
    },
    {
      "epoch": 8.16933638443936,
      "grad_norm": 0.06898996978998184,
      "learning_rate": 3.6613272311212818e-06,
      "loss": 0.0004,
      "step": 3570
    },
    {
      "epoch": 8.192219679633867,
      "grad_norm": 0.10675925016403198,
      "learning_rate": 3.6155606407322656e-06,
      "loss": 0.0296,
      "step": 3580
    },
    {
      "epoch": 8.215102974828376,
      "grad_norm": 7.639638423919678,
      "learning_rate": 3.56979405034325e-06,
      "loss": 0.0324,
      "step": 3590
    },
    {
      "epoch": 8.237986270022883,
      "grad_norm": 1.7010204792022705,
      "learning_rate": 3.5240274599542333e-06,
      "loss": 0.0357,
      "step": 3600
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 1.0433343648910522,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.0012,
      "step": 3610
    },
    {
      "epoch": 8.2837528604119,
      "grad_norm": 34.7675666809082,
      "learning_rate": 3.4324942791762018e-06,
      "loss": 0.0485,
      "step": 3620
    },
    {
      "epoch": 8.306636155606407,
      "grad_norm": 26.645437240600586,
      "learning_rate": 3.386727688787186e-06,
      "loss": 0.016,
      "step": 3630
    },
    {
      "epoch": 8.329519450800916,
      "grad_norm": 0.10542299598455429,
      "learning_rate": 3.3409610983981694e-06,
      "loss": 0.0046,
      "step": 3640
    },
    {
      "epoch": 8.352402745995423,
      "grad_norm": 0.016184169799089432,
      "learning_rate": 3.2951945080091537e-06,
      "loss": 0.0074,
      "step": 3650
    },
    {
      "epoch": 8.37528604118993,
      "grad_norm": 0.047333862632513046,
      "learning_rate": 3.2494279176201375e-06,
      "loss": 0.0191,
      "step": 3660
    },
    {
      "epoch": 8.39816933638444,
      "grad_norm": 21.44321632385254,
      "learning_rate": 3.2036613272311218e-06,
      "loss": 0.0382,
      "step": 3670
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 0.019649453461170197,
      "learning_rate": 3.157894736842105e-06,
      "loss": 0.025,
      "step": 3680
    },
    {
      "epoch": 8.443935926773456,
      "grad_norm": 5.050129413604736,
      "learning_rate": 3.1121281464530894e-06,
      "loss": 0.0198,
      "step": 3690
    },
    {
      "epoch": 8.466819221967963,
      "grad_norm": 3.520448684692383,
      "learning_rate": 3.0663615560640737e-06,
      "loss": 0.0294,
      "step": 3700
    },
    {
      "epoch": 8.48970251716247,
      "grad_norm": 33.353885650634766,
      "learning_rate": 3.020594965675058e-06,
      "loss": 0.0221,
      "step": 3710
    },
    {
      "epoch": 8.51258581235698,
      "grad_norm": 0.04414966702461243,
      "learning_rate": 2.9748283752860413e-06,
      "loss": 0.0242,
      "step": 3720
    },
    {
      "epoch": 8.535469107551487,
      "grad_norm": 0.9558678269386292,
      "learning_rate": 2.9290617848970256e-06,
      "loss": 0.0186,
      "step": 3730
    },
    {
      "epoch": 8.558352402745996,
      "grad_norm": 0.9849497675895691,
      "learning_rate": 2.8832951945080094e-06,
      "loss": 0.0292,
      "step": 3740
    },
    {
      "epoch": 8.581235697940503,
      "grad_norm": 9.622822761535645,
      "learning_rate": 2.8375286041189932e-06,
      "loss": 0.0398,
      "step": 3750
    },
    {
      "epoch": 8.604118993135012,
      "grad_norm": 0.03259555995464325,
      "learning_rate": 2.791762013729977e-06,
      "loss": 0.017,
      "step": 3760
    },
    {
      "epoch": 8.62700228832952,
      "grad_norm": 5.548686504364014,
      "learning_rate": 2.7459954233409613e-06,
      "loss": 0.0048,
      "step": 3770
    },
    {
      "epoch": 8.649885583524027,
      "grad_norm": 0.006408915389329195,
      "learning_rate": 2.7002288329519456e-06,
      "loss": 0.0262,
      "step": 3780
    },
    {
      "epoch": 8.672768878718536,
      "grad_norm": 0.47724056243896484,
      "learning_rate": 2.654462242562929e-06,
      "loss": 0.0022,
      "step": 3790
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.10813333839178085,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 0.0106,
      "step": 3800
    },
    {
      "epoch": 8.718535469107552,
      "grad_norm": 0.06871946901082993,
      "learning_rate": 2.5629290617848975e-06,
      "loss": 0.0291,
      "step": 3810
    },
    {
      "epoch": 8.74141876430206,
      "grad_norm": 0.3179403841495514,
      "learning_rate": 2.5171624713958813e-06,
      "loss": 0.0092,
      "step": 3820
    },
    {
      "epoch": 8.764302059496568,
      "grad_norm": 0.08669746667146683,
      "learning_rate": 2.471395881006865e-06,
      "loss": 0.0095,
      "step": 3830
    },
    {
      "epoch": 8.787185354691076,
      "grad_norm": 0.020604506134986877,
      "learning_rate": 2.425629290617849e-06,
      "loss": 0.0202,
      "step": 3840
    },
    {
      "epoch": 8.810068649885583,
      "grad_norm": 0.004582814406603575,
      "learning_rate": 2.3798627002288332e-06,
      "loss": 0.0004,
      "step": 3850
    },
    {
      "epoch": 8.832951945080092,
      "grad_norm": 5.689143180847168,
      "learning_rate": 2.334096109839817e-06,
      "loss": 0.0029,
      "step": 3860
    },
    {
      "epoch": 8.8558352402746,
      "grad_norm": 73.8190689086914,
      "learning_rate": 2.2883295194508013e-06,
      "loss": 0.0444,
      "step": 3870
    },
    {
      "epoch": 8.878718535469108,
      "grad_norm": 2.3638854026794434,
      "learning_rate": 2.242562929061785e-06,
      "loss": 0.0141,
      "step": 3880
    },
    {
      "epoch": 8.901601830663616,
      "grad_norm": 0.011888883076608181,
      "learning_rate": 2.196796338672769e-06,
      "loss": 0.0098,
      "step": 3890
    },
    {
      "epoch": 8.924485125858123,
      "grad_norm": 0.6864758133888245,
      "learning_rate": 2.1510297482837532e-06,
      "loss": 0.0129,
      "step": 3900
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 0.00810778234153986,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.0011,
      "step": 3910
    },
    {
      "epoch": 8.97025171624714,
      "grad_norm": 5.5685601234436035,
      "learning_rate": 2.059496567505721e-06,
      "loss": 0.0141,
      "step": 3920
    },
    {
      "epoch": 8.993135011441648,
      "grad_norm": 0.008869398385286331,
      "learning_rate": 2.0137299771167047e-06,
      "loss": 0.0258,
      "step": 3930
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9613333333333334,
      "eval_f1": 0.8440860215053764,
      "eval_loss": 0.2673221528530121,
      "eval_precision": 0.8746518105849582,
      "eval_recall": 0.8155844155844156,
      "eval_runtime": 472.8331,
      "eval_samples_per_second": 6.345,
      "eval_steps_per_second": 0.793,
      "step": 3933
    },
    {
      "epoch": 9.016018306636155,
      "grad_norm": 0.0051914118230342865,
      "learning_rate": 1.967963386727689e-06,
      "loss": 0.0197,
      "step": 3940
    },
    {
      "epoch": 9.038901601830664,
      "grad_norm": 0.09092117846012115,
      "learning_rate": 1.922196796338673e-06,
      "loss": 0.0003,
      "step": 3950
    },
    {
      "epoch": 9.061784897025172,
      "grad_norm": 0.03341400995850563,
      "learning_rate": 1.876430205949657e-06,
      "loss": 0.0377,
      "step": 3960
    },
    {
      "epoch": 9.084668192219679,
      "grad_norm": 0.006642322521656752,
      "learning_rate": 1.8306636155606409e-06,
      "loss": 0.0004,
      "step": 3970
    },
    {
      "epoch": 9.107551487414188,
      "grad_norm": 0.007744298316538334,
      "learning_rate": 1.784897025171625e-06,
      "loss": 0.0035,
      "step": 3980
    },
    {
      "epoch": 9.130434782608695,
      "grad_norm": 0.023565055802464485,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 0.0103,
      "step": 3990
    },
    {
      "epoch": 9.153318077803204,
      "grad_norm": 0.005116146523505449,
      "learning_rate": 1.693363844393593e-06,
      "loss": 0.0178,
      "step": 4000
    },
    {
      "epoch": 9.176201372997712,
      "grad_norm": 0.019349945709109306,
      "learning_rate": 1.6475972540045768e-06,
      "loss": 0.002,
      "step": 4010
    },
    {
      "epoch": 9.199084668192219,
      "grad_norm": 0.01796320267021656,
      "learning_rate": 1.6018306636155609e-06,
      "loss": 0.0077,
      "step": 4020
    },
    {
      "epoch": 9.221967963386728,
      "grad_norm": 0.1697349101305008,
      "learning_rate": 1.5560640732265447e-06,
      "loss": 0.0093,
      "step": 4030
    },
    {
      "epoch": 9.244851258581235,
      "grad_norm": 2.8793463706970215,
      "learning_rate": 1.510297482837529e-06,
      "loss": 0.0022,
      "step": 4040
    },
    {
      "epoch": 9.267734553775744,
      "grad_norm": 0.022108454257249832,
      "learning_rate": 1.4645308924485128e-06,
      "loss": 0.0424,
      "step": 4050
    },
    {
      "epoch": 9.290617848970252,
      "grad_norm": 1.413526177406311,
      "learning_rate": 1.4187643020594966e-06,
      "loss": 0.0034,
      "step": 4060
    },
    {
      "epoch": 9.31350114416476,
      "grad_norm": 0.015098568052053452,
      "learning_rate": 1.3729977116704807e-06,
      "loss": 0.029,
      "step": 4070
    },
    {
      "epoch": 9.336384439359268,
      "grad_norm": 0.33030542731285095,
      "learning_rate": 1.3272311212814645e-06,
      "loss": 0.0036,
      "step": 4080
    },
    {
      "epoch": 9.359267734553775,
      "grad_norm": 1.1159307956695557,
      "learning_rate": 1.2814645308924487e-06,
      "loss": 0.0007,
      "step": 4090
    },
    {
      "epoch": 9.382151029748284,
      "grad_norm": 0.020972557365894318,
      "learning_rate": 1.2356979405034326e-06,
      "loss": 0.0171,
      "step": 4100
    },
    {
      "epoch": 9.405034324942791,
      "grad_norm": 0.013007641769945621,
      "learning_rate": 1.1899313501144166e-06,
      "loss": 0.0014,
      "step": 4110
    },
    {
      "epoch": 9.4279176201373,
      "grad_norm": 0.12193078547716141,
      "learning_rate": 1.1441647597254007e-06,
      "loss": 0.0176,
      "step": 4120
    },
    {
      "epoch": 9.450800915331808,
      "grad_norm": 0.05575573071837425,
      "learning_rate": 1.0983981693363845e-06,
      "loss": 0.0026,
      "step": 4130
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 0.020916394889354706,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.0004,
      "step": 4140
    },
    {
      "epoch": 9.496567505720824,
      "grad_norm": 1.0259963274002075,
      "learning_rate": 1.0068649885583524e-06,
      "loss": 0.006,
      "step": 4150
    },
    {
      "epoch": 9.519450800915331,
      "grad_norm": 0.134369894862175,
      "learning_rate": 9.610983981693364e-07,
      "loss": 0.0009,
      "step": 4160
    },
    {
      "epoch": 9.54233409610984,
      "grad_norm": 42.30548858642578,
      "learning_rate": 9.153318077803204e-07,
      "loss": 0.0575,
      "step": 4170
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 0.03641732409596443,
      "learning_rate": 8.695652173913044e-07,
      "loss": 0.0124,
      "step": 4180
    },
    {
      "epoch": 9.588100686498855,
      "grad_norm": 0.07150658220052719,
      "learning_rate": 8.237986270022884e-07,
      "loss": 0.0042,
      "step": 4190
    },
    {
      "epoch": 9.610983981693364,
      "grad_norm": 2.3043642044067383,
      "learning_rate": 7.780320366132724e-07,
      "loss": 0.0243,
      "step": 4200
    },
    {
      "epoch": 9.633867276887871,
      "grad_norm": 0.01958906278014183,
      "learning_rate": 7.322654462242564e-07,
      "loss": 0.0003,
      "step": 4210
    },
    {
      "epoch": 9.65675057208238,
      "grad_norm": 0.008513566106557846,
      "learning_rate": 6.864988558352403e-07,
      "loss": 0.0109,
      "step": 4220
    },
    {
      "epoch": 9.679633867276888,
      "grad_norm": 0.07091318070888519,
      "learning_rate": 6.407322654462244e-07,
      "loss": 0.0198,
      "step": 4230
    },
    {
      "epoch": 9.702517162471397,
      "grad_norm": 13.271448135375977,
      "learning_rate": 5.949656750572083e-07,
      "loss": 0.0068,
      "step": 4240
    },
    {
      "epoch": 9.725400457665904,
      "grad_norm": 0.043078839778900146,
      "learning_rate": 5.491990846681922e-07,
      "loss": 0.0296,
      "step": 4250
    },
    {
      "epoch": 9.748283752860411,
      "grad_norm": 0.0028806733898818493,
      "learning_rate": 5.034324942791762e-07,
      "loss": 0.0198,
      "step": 4260
    },
    {
      "epoch": 9.77116704805492,
      "grad_norm": 0.07452284544706345,
      "learning_rate": 4.576659038901602e-07,
      "loss": 0.0005,
      "step": 4270
    },
    {
      "epoch": 9.794050343249427,
      "grad_norm": 0.006516794208437204,
      "learning_rate": 4.118993135011442e-07,
      "loss": 0.0185,
      "step": 4280
    },
    {
      "epoch": 9.816933638443937,
      "grad_norm": 0.2801021337509155,
      "learning_rate": 3.661327231121282e-07,
      "loss": 0.0013,
      "step": 4290
    },
    {
      "epoch": 9.839816933638444,
      "grad_norm": 0.5288317203521729,
      "learning_rate": 3.203661327231122e-07,
      "loss": 0.0131,
      "step": 4300
    },
    {
      "epoch": 9.862700228832953,
      "grad_norm": 0.004140443168580532,
      "learning_rate": 2.745995423340961e-07,
      "loss": 0.0005,
      "step": 4310
    },
    {
      "epoch": 9.88558352402746,
      "grad_norm": 0.002962003229185939,
      "learning_rate": 2.288329519450801e-07,
      "loss": 0.0063,
      "step": 4320
    },
    {
      "epoch": 9.908466819221967,
      "grad_norm": 0.04008721187710762,
      "learning_rate": 1.830663615560641e-07,
      "loss": 0.0024,
      "step": 4330
    },
    {
      "epoch": 9.931350114416476,
      "grad_norm": 0.004838024731725454,
      "learning_rate": 1.3729977116704806e-07,
      "loss": 0.0015,
      "step": 4340
    },
    {
      "epoch": 9.954233409610984,
      "grad_norm": 0.09578116238117218,
      "learning_rate": 9.153318077803205e-08,
      "loss": 0.0005,
      "step": 4350
    },
    {
      "epoch": 9.977116704805493,
      "grad_norm": 11.087814331054688,
      "learning_rate": 4.5766590389016025e-08,
      "loss": 0.0273,
      "step": 4360
    },
    {
      "epoch": 10.0,
      "grad_norm": 52.68523025512695,
      "learning_rate": 0.0,
      "loss": 0.0294,
      "step": 4370
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.962,
      "eval_f1": 0.8488063660477454,
      "eval_loss": 0.2668556272983551,
      "eval_precision": 0.8672086720867209,
      "eval_recall": 0.8311688311688312,
      "eval_runtime": 485.5164,
      "eval_samples_per_second": 6.179,
      "eval_steps_per_second": 0.772,
      "step": 4370
    }
  ],
  "logging_steps": 10,
  "max_steps": 4370,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.291579857719104e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
