{
  "best_metric": 0.8013816925734025,
  "best_model_checkpoint": "../saved_models/sql/checkpoint-4370",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4370,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002288329519450801,
      "grad_norm": 61.03783416748047,
      "learning_rate": 1.99954233409611e-05,
      "loss": 1.5685,
      "step": 1
    },
    {
      "epoch": 0.02288329519450801,
      "grad_norm": 17.645153045654297,
      "learning_rate": 1.9954233409610984e-05,
      "loss": 0.5725,
      "step": 10
    },
    {
      "epoch": 0.04576659038901602,
      "grad_norm": 30.7518310546875,
      "learning_rate": 1.990846681922197e-05,
      "loss": 0.7052,
      "step": 20
    },
    {
      "epoch": 0.06864988558352403,
      "grad_norm": 31.06073760986328,
      "learning_rate": 1.9862700228832953e-05,
      "loss": 0.6182,
      "step": 30
    },
    {
      "epoch": 0.09153318077803203,
      "grad_norm": 27.483606338500977,
      "learning_rate": 1.981693363844394e-05,
      "loss": 0.5162,
      "step": 40
    },
    {
      "epoch": 0.11441647597254005,
      "grad_norm": 16.432443618774414,
      "learning_rate": 1.977116704805492e-05,
      "loss": 0.4988,
      "step": 50
    },
    {
      "epoch": 0.13729977116704806,
      "grad_norm": 40.59064865112305,
      "learning_rate": 1.9725400457665907e-05,
      "loss": 0.5159,
      "step": 60
    },
    {
      "epoch": 0.16018306636155608,
      "grad_norm": 20.92201042175293,
      "learning_rate": 1.967963386727689e-05,
      "loss": 0.4073,
      "step": 70
    },
    {
      "epoch": 0.18306636155606407,
      "grad_norm": 16.27320671081543,
      "learning_rate": 1.9633867276887872e-05,
      "loss": 0.5358,
      "step": 80
    },
    {
      "epoch": 0.20594965675057209,
      "grad_norm": 15.943371772766113,
      "learning_rate": 1.9588100686498858e-05,
      "loss": 0.499,
      "step": 90
    },
    {
      "epoch": 0.2288329519450801,
      "grad_norm": 28.77305793762207,
      "learning_rate": 1.954233409610984e-05,
      "loss": 0.3757,
      "step": 100
    },
    {
      "epoch": 0.2517162471395881,
      "grad_norm": 14.917487144470215,
      "learning_rate": 1.9496567505720823e-05,
      "loss": 0.4506,
      "step": 110
    },
    {
      "epoch": 0.2745995423340961,
      "grad_norm": 9.682428359985352,
      "learning_rate": 1.945080091533181e-05,
      "loss": 0.4057,
      "step": 120
    },
    {
      "epoch": 0.2974828375286041,
      "grad_norm": 12.01247787475586,
      "learning_rate": 1.9405034324942792e-05,
      "loss": 0.3795,
      "step": 130
    },
    {
      "epoch": 0.32036613272311215,
      "grad_norm": 11.225068092346191,
      "learning_rate": 1.9359267734553778e-05,
      "loss": 0.4859,
      "step": 140
    },
    {
      "epoch": 0.34324942791762014,
      "grad_norm": 6.16972541809082,
      "learning_rate": 1.931350114416476e-05,
      "loss": 0.4057,
      "step": 150
    },
    {
      "epoch": 0.36613272311212813,
      "grad_norm": 9.032160758972168,
      "learning_rate": 1.9267734553775746e-05,
      "loss": 0.4145,
      "step": 160
    },
    {
      "epoch": 0.3890160183066362,
      "grad_norm": 15.63507080078125,
      "learning_rate": 1.922196796338673e-05,
      "loss": 0.4035,
      "step": 170
    },
    {
      "epoch": 0.41189931350114417,
      "grad_norm": 11.165133476257324,
      "learning_rate": 1.9176201372997715e-05,
      "loss": 0.4501,
      "step": 180
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 9.046773910522461,
      "learning_rate": 1.9130434782608697e-05,
      "loss": 0.4571,
      "step": 190
    },
    {
      "epoch": 0.4576659038901602,
      "grad_norm": 9.033400535583496,
      "learning_rate": 1.9084668192219683e-05,
      "loss": 0.4072,
      "step": 200
    },
    {
      "epoch": 0.4805491990846682,
      "grad_norm": 10.3526029586792,
      "learning_rate": 1.9038901601830666e-05,
      "loss": 0.4503,
      "step": 210
    },
    {
      "epoch": 0.5034324942791762,
      "grad_norm": 6.503599643707275,
      "learning_rate": 1.8993135011441652e-05,
      "loss": 0.4565,
      "step": 220
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 13.423504829406738,
      "learning_rate": 1.894736842105263e-05,
      "loss": 0.3949,
      "step": 230
    },
    {
      "epoch": 0.5491990846681922,
      "grad_norm": 8.186392784118652,
      "learning_rate": 1.8901601830663617e-05,
      "loss": 0.4592,
      "step": 240
    },
    {
      "epoch": 0.5720823798627003,
      "grad_norm": 5.397015571594238,
      "learning_rate": 1.88558352402746e-05,
      "loss": 0.4889,
      "step": 250
    },
    {
      "epoch": 0.5949656750572082,
      "grad_norm": 5.613473415374756,
      "learning_rate": 1.8810068649885585e-05,
      "loss": 0.4404,
      "step": 260
    },
    {
      "epoch": 0.6178489702517163,
      "grad_norm": 6.5037078857421875,
      "learning_rate": 1.8764302059496568e-05,
      "loss": 0.4272,
      "step": 270
    },
    {
      "epoch": 0.6407322654462243,
      "grad_norm": 6.081467151641846,
      "learning_rate": 1.8718535469107554e-05,
      "loss": 0.4069,
      "step": 280
    },
    {
      "epoch": 0.6636155606407322,
      "grad_norm": 4.440225601196289,
      "learning_rate": 1.8672768878718537e-05,
      "loss": 0.3536,
      "step": 290
    },
    {
      "epoch": 0.6864988558352403,
      "grad_norm": 6.815807342529297,
      "learning_rate": 1.8627002288329522e-05,
      "loss": 0.4343,
      "step": 300
    },
    {
      "epoch": 0.7093821510297483,
      "grad_norm": 11.129619598388672,
      "learning_rate": 1.8581235697940505e-05,
      "loss": 0.4391,
      "step": 310
    },
    {
      "epoch": 0.7322654462242563,
      "grad_norm": 6.2577385902404785,
      "learning_rate": 1.8535469107551488e-05,
      "loss": 0.3689,
      "step": 320
    },
    {
      "epoch": 0.7551487414187643,
      "grad_norm": 7.792388439178467,
      "learning_rate": 1.8489702517162474e-05,
      "loss": 0.4008,
      "step": 330
    },
    {
      "epoch": 0.7780320366132724,
      "grad_norm": 4.603669166564941,
      "learning_rate": 1.8443935926773456e-05,
      "loss": 0.3799,
      "step": 340
    },
    {
      "epoch": 0.8009153318077803,
      "grad_norm": 12.375829696655273,
      "learning_rate": 1.8398169336384442e-05,
      "loss": 0.3765,
      "step": 350
    },
    {
      "epoch": 0.8237986270022883,
      "grad_norm": 11.191445350646973,
      "learning_rate": 1.8352402745995425e-05,
      "loss": 0.4603,
      "step": 360
    },
    {
      "epoch": 0.8466819221967964,
      "grad_norm": 4.6254143714904785,
      "learning_rate": 1.830663615560641e-05,
      "loss": 0.388,
      "step": 370
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 7.466394424438477,
      "learning_rate": 1.8260869565217393e-05,
      "loss": 0.4224,
      "step": 380
    },
    {
      "epoch": 0.8924485125858124,
      "grad_norm": 6.574636936187744,
      "learning_rate": 1.8215102974828376e-05,
      "loss": 0.4476,
      "step": 390
    },
    {
      "epoch": 0.9153318077803204,
      "grad_norm": 10.851714134216309,
      "learning_rate": 1.816933638443936e-05,
      "loss": 0.4098,
      "step": 400
    },
    {
      "epoch": 0.9382151029748284,
      "grad_norm": 5.669507026672363,
      "learning_rate": 1.8123569794050344e-05,
      "loss": 0.4139,
      "step": 410
    },
    {
      "epoch": 0.9610983981693364,
      "grad_norm": 5.724079132080078,
      "learning_rate": 1.8077803203661327e-05,
      "loss": 0.3522,
      "step": 420
    },
    {
      "epoch": 0.9839816933638444,
      "grad_norm": 5.276863098144531,
      "learning_rate": 1.8032036613272313e-05,
      "loss": 0.2991,
      "step": 430
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8373333333333334,
      "eval_f1": 0.5711775043936731,
      "eval_loss": 0.3906998634338379,
      "eval_precision": 0.5855855855855856,
      "eval_recall": 0.5574614065180102,
      "eval_runtime": 665.4776,
      "eval_samples_per_second": 4.508,
      "eval_steps_per_second": 0.564,
      "step": 437
    },
    {
      "epoch": 1.0068649885583525,
      "grad_norm": 4.862346649169922,
      "learning_rate": 1.7986270022883295e-05,
      "loss": 0.3324,
      "step": 440
    },
    {
      "epoch": 1.0297482837528604,
      "grad_norm": 4.099836826324463,
      "learning_rate": 1.794050343249428e-05,
      "loss": 0.3662,
      "step": 450
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 5.245140552520752,
      "learning_rate": 1.7894736842105264e-05,
      "loss": 0.3771,
      "step": 460
    },
    {
      "epoch": 1.0755148741418765,
      "grad_norm": 6.38095235824585,
      "learning_rate": 1.784897025171625e-05,
      "loss": 0.3703,
      "step": 470
    },
    {
      "epoch": 1.0983981693363845,
      "grad_norm": 9.140666007995605,
      "learning_rate": 1.7803203661327232e-05,
      "loss": 0.3148,
      "step": 480
    },
    {
      "epoch": 1.1212814645308924,
      "grad_norm": 10.077341079711914,
      "learning_rate": 1.7757437070938218e-05,
      "loss": 0.3566,
      "step": 490
    },
    {
      "epoch": 1.1441647597254005,
      "grad_norm": 4.904110908508301,
      "learning_rate": 1.77116704805492e-05,
      "loss": 0.388,
      "step": 500
    },
    {
      "epoch": 1.1670480549199085,
      "grad_norm": 5.754586219787598,
      "learning_rate": 1.7665903890160187e-05,
      "loss": 0.3829,
      "step": 510
    },
    {
      "epoch": 1.1899313501144164,
      "grad_norm": 8.778313636779785,
      "learning_rate": 1.762013729977117e-05,
      "loss": 0.3455,
      "step": 520
    },
    {
      "epoch": 1.2128146453089246,
      "grad_norm": 7.548794746398926,
      "learning_rate": 1.7574370709382152e-05,
      "loss": 0.3136,
      "step": 530
    },
    {
      "epoch": 1.2356979405034325,
      "grad_norm": 3.5286142826080322,
      "learning_rate": 1.7528604118993134e-05,
      "loss": 0.3105,
      "step": 540
    },
    {
      "epoch": 1.2585812356979404,
      "grad_norm": 6.3306498527526855,
      "learning_rate": 1.748283752860412e-05,
      "loss": 0.3258,
      "step": 550
    },
    {
      "epoch": 1.2814645308924484,
      "grad_norm": 6.532656669616699,
      "learning_rate": 1.7437070938215103e-05,
      "loss": 0.3346,
      "step": 560
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 4.942221641540527,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.3078,
      "step": 570
    },
    {
      "epoch": 1.3272311212814645,
      "grad_norm": 4.414430618286133,
      "learning_rate": 1.734553775743707e-05,
      "loss": 0.3295,
      "step": 580
    },
    {
      "epoch": 1.3501144164759724,
      "grad_norm": 6.038383960723877,
      "learning_rate": 1.7299771167048057e-05,
      "loss": 0.3321,
      "step": 590
    },
    {
      "epoch": 1.3729977116704806,
      "grad_norm": 4.420163154602051,
      "learning_rate": 1.725400457665904e-05,
      "loss": 0.3833,
      "step": 600
    },
    {
      "epoch": 1.3958810068649885,
      "grad_norm": 7.488698482513428,
      "learning_rate": 1.7208237986270026e-05,
      "loss": 0.3187,
      "step": 610
    },
    {
      "epoch": 1.4187643020594964,
      "grad_norm": 6.413153648376465,
      "learning_rate": 1.716247139588101e-05,
      "loss": 0.3835,
      "step": 620
    },
    {
      "epoch": 1.4416475972540046,
      "grad_norm": 6.105809688568115,
      "learning_rate": 1.7116704805491994e-05,
      "loss": 0.2896,
      "step": 630
    },
    {
      "epoch": 1.4645308924485125,
      "grad_norm": 6.205892562866211,
      "learning_rate": 1.7070938215102977e-05,
      "loss": 0.402,
      "step": 640
    },
    {
      "epoch": 1.4874141876430205,
      "grad_norm": 6.968987941741943,
      "learning_rate": 1.702517162471396e-05,
      "loss": 0.3142,
      "step": 650
    },
    {
      "epoch": 1.5102974828375286,
      "grad_norm": 5.073025703430176,
      "learning_rate": 1.6979405034324945e-05,
      "loss": 0.3057,
      "step": 660
    },
    {
      "epoch": 1.5331807780320366,
      "grad_norm": 5.177525997161865,
      "learning_rate": 1.6933638443935928e-05,
      "loss": 0.3422,
      "step": 670
    },
    {
      "epoch": 1.5560640732265445,
      "grad_norm": 21.269556045532227,
      "learning_rate": 1.688787185354691e-05,
      "loss": 0.3076,
      "step": 680
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 5.029827117919922,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.3313,
      "step": 690
    },
    {
      "epoch": 1.6018306636155606,
      "grad_norm": 4.912254333496094,
      "learning_rate": 1.679633867276888e-05,
      "loss": 0.3088,
      "step": 700
    },
    {
      "epoch": 1.6247139588100685,
      "grad_norm": 7.922378063201904,
      "learning_rate": 1.6750572082379865e-05,
      "loss": 0.3454,
      "step": 710
    },
    {
      "epoch": 1.6475972540045767,
      "grad_norm": 7.601696968078613,
      "learning_rate": 1.6704805491990848e-05,
      "loss": 0.3202,
      "step": 720
    },
    {
      "epoch": 1.6704805491990846,
      "grad_norm": 7.1489176750183105,
      "learning_rate": 1.665903890160183e-05,
      "loss": 0.3543,
      "step": 730
    },
    {
      "epoch": 1.6933638443935926,
      "grad_norm": 6.746363639831543,
      "learning_rate": 1.6613272311212816e-05,
      "loss": 0.3793,
      "step": 740
    },
    {
      "epoch": 1.7162471395881007,
      "grad_norm": 7.448302745819092,
      "learning_rate": 1.65675057208238e-05,
      "loss": 0.3507,
      "step": 750
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 3.4104790687561035,
      "learning_rate": 1.6521739130434785e-05,
      "loss": 0.3139,
      "step": 760
    },
    {
      "epoch": 1.7620137299771166,
      "grad_norm": 6.1268630027771,
      "learning_rate": 1.6475972540045767e-05,
      "loss": 0.3816,
      "step": 770
    },
    {
      "epoch": 1.7848970251716247,
      "grad_norm": 6.66227388381958,
      "learning_rate": 1.6430205949656753e-05,
      "loss": 0.3294,
      "step": 780
    },
    {
      "epoch": 1.8077803203661327,
      "grad_norm": 6.444109916687012,
      "learning_rate": 1.6384439359267736e-05,
      "loss": 0.2906,
      "step": 790
    },
    {
      "epoch": 1.8306636155606406,
      "grad_norm": 10.395820617675781,
      "learning_rate": 1.633867276887872e-05,
      "loss": 0.344,
      "step": 800
    },
    {
      "epoch": 1.8535469107551488,
      "grad_norm": 7.331141471862793,
      "learning_rate": 1.6292906178489704e-05,
      "loss": 0.3461,
      "step": 810
    },
    {
      "epoch": 1.8764302059496567,
      "grad_norm": 6.377621650695801,
      "learning_rate": 1.624713958810069e-05,
      "loss": 0.3123,
      "step": 820
    },
    {
      "epoch": 1.8993135011441646,
      "grad_norm": 7.060072898864746,
      "learning_rate": 1.620137299771167e-05,
      "loss": 0.3335,
      "step": 830
    },
    {
      "epoch": 1.9221967963386728,
      "grad_norm": 5.00485372543335,
      "learning_rate": 1.6155606407322655e-05,
      "loss": 0.3076,
      "step": 840
    },
    {
      "epoch": 1.9450800915331807,
      "grad_norm": 3.093966007232666,
      "learning_rate": 1.6109839816933638e-05,
      "loss": 0.2677,
      "step": 850
    },
    {
      "epoch": 1.9679633867276887,
      "grad_norm": 9.792135238647461,
      "learning_rate": 1.6064073226544624e-05,
      "loss": 0.3172,
      "step": 860
    },
    {
      "epoch": 1.9908466819221968,
      "grad_norm": 7.2530694007873535,
      "learning_rate": 1.6018306636155606e-05,
      "loss": 0.2994,
      "step": 870
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8803333333333333,
      "eval_f1": 0.6511175898931001,
      "eval_loss": 0.2998204827308655,
      "eval_precision": 0.7511210762331838,
      "eval_recall": 0.5746140651801029,
      "eval_runtime": 683.7818,
      "eval_samples_per_second": 4.387,
      "eval_steps_per_second": 0.548,
      "step": 874
    },
    {
      "epoch": 2.013729977116705,
      "grad_norm": 6.159717082977295,
      "learning_rate": 1.5972540045766592e-05,
      "loss": 0.3088,
      "step": 880
    },
    {
      "epoch": 2.0366132723112127,
      "grad_norm": 8.058279991149902,
      "learning_rate": 1.5926773455377575e-05,
      "loss": 0.1901,
      "step": 890
    },
    {
      "epoch": 2.059496567505721,
      "grad_norm": 5.397153377532959,
      "learning_rate": 1.588100686498856e-05,
      "loss": 0.2551,
      "step": 900
    },
    {
      "epoch": 2.082379862700229,
      "grad_norm": 4.676844596862793,
      "learning_rate": 1.5835240274599543e-05,
      "loss": 0.2348,
      "step": 910
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 8.644866943359375,
      "learning_rate": 1.578947368421053e-05,
      "loss": 0.2933,
      "step": 920
    },
    {
      "epoch": 2.128146453089245,
      "grad_norm": 7.8944172859191895,
      "learning_rate": 1.5743707093821512e-05,
      "loss": 0.3144,
      "step": 930
    },
    {
      "epoch": 2.151029748283753,
      "grad_norm": 4.808680534362793,
      "learning_rate": 1.5697940503432498e-05,
      "loss": 0.2628,
      "step": 940
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 6.639596462249756,
      "learning_rate": 1.565217391304348e-05,
      "loss": 0.2669,
      "step": 950
    },
    {
      "epoch": 2.196796338672769,
      "grad_norm": 4.554083824157715,
      "learning_rate": 1.5606407322654463e-05,
      "loss": 0.2195,
      "step": 960
    },
    {
      "epoch": 2.219679633867277,
      "grad_norm": 16.02008056640625,
      "learning_rate": 1.556064073226545e-05,
      "loss": 0.2861,
      "step": 970
    },
    {
      "epoch": 2.242562929061785,
      "grad_norm": 4.834615230560303,
      "learning_rate": 1.551487414187643e-05,
      "loss": 0.2358,
      "step": 980
    },
    {
      "epoch": 2.265446224256293,
      "grad_norm": 7.234901428222656,
      "learning_rate": 1.5469107551487414e-05,
      "loss": 0.2468,
      "step": 990
    },
    {
      "epoch": 2.288329519450801,
      "grad_norm": 3.2453958988189697,
      "learning_rate": 1.54233409610984e-05,
      "loss": 0.2846,
      "step": 1000
    },
    {
      "epoch": 2.311212814645309,
      "grad_norm": 6.48776912689209,
      "learning_rate": 1.5377574370709382e-05,
      "loss": 0.2467,
      "step": 1010
    },
    {
      "epoch": 2.334096109839817,
      "grad_norm": 9.402069091796875,
      "learning_rate": 1.533180778032037e-05,
      "loss": 0.2141,
      "step": 1020
    },
    {
      "epoch": 2.356979405034325,
      "grad_norm": 11.879206657409668,
      "learning_rate": 1.528604118993135e-05,
      "loss": 0.2628,
      "step": 1030
    },
    {
      "epoch": 2.379862700228833,
      "grad_norm": 7.573514461517334,
      "learning_rate": 1.5240274599542335e-05,
      "loss": 0.2539,
      "step": 1040
    },
    {
      "epoch": 2.402745995423341,
      "grad_norm": 7.929099082946777,
      "learning_rate": 1.519450800915332e-05,
      "loss": 0.2258,
      "step": 1050
    },
    {
      "epoch": 2.425629290617849,
      "grad_norm": 6.481472492218018,
      "learning_rate": 1.5148741418764304e-05,
      "loss": 0.2774,
      "step": 1060
    },
    {
      "epoch": 2.448512585812357,
      "grad_norm": 8.596057891845703,
      "learning_rate": 1.5102974828375288e-05,
      "loss": 0.3395,
      "step": 1070
    },
    {
      "epoch": 2.471395881006865,
      "grad_norm": 7.048842430114746,
      "learning_rate": 1.5057208237986272e-05,
      "loss": 0.24,
      "step": 1080
    },
    {
      "epoch": 2.494279176201373,
      "grad_norm": 4.14277458190918,
      "learning_rate": 1.5011441647597256e-05,
      "loss": 0.2439,
      "step": 1090
    },
    {
      "epoch": 2.517162471395881,
      "grad_norm": 6.44525146484375,
      "learning_rate": 1.496567505720824e-05,
      "loss": 0.2477,
      "step": 1100
    },
    {
      "epoch": 2.540045766590389,
      "grad_norm": 7.670914649963379,
      "learning_rate": 1.4919908466819223e-05,
      "loss": 0.2558,
      "step": 1110
    },
    {
      "epoch": 2.5629290617848968,
      "grad_norm": 7.163345813751221,
      "learning_rate": 1.4874141876430207e-05,
      "loss": 0.2983,
      "step": 1120
    },
    {
      "epoch": 2.585812356979405,
      "grad_norm": 7.601205348968506,
      "learning_rate": 1.4828375286041192e-05,
      "loss": 0.3066,
      "step": 1130
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 6.107032299041748,
      "learning_rate": 1.4782608695652174e-05,
      "loss": 0.1724,
      "step": 1140
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 6.755357265472412,
      "learning_rate": 1.4736842105263159e-05,
      "loss": 0.3359,
      "step": 1150
    },
    {
      "epoch": 2.654462242562929,
      "grad_norm": 5.285195350646973,
      "learning_rate": 1.4691075514874143e-05,
      "loss": 0.2777,
      "step": 1160
    },
    {
      "epoch": 2.677345537757437,
      "grad_norm": 5.976034164428711,
      "learning_rate": 1.4645308924485127e-05,
      "loss": 0.1968,
      "step": 1170
    },
    {
      "epoch": 2.700228832951945,
      "grad_norm": 6.036872863769531,
      "learning_rate": 1.4599542334096111e-05,
      "loss": 0.1756,
      "step": 1180
    },
    {
      "epoch": 2.723112128146453,
      "grad_norm": 6.097574234008789,
      "learning_rate": 1.4553775743707096e-05,
      "loss": 0.211,
      "step": 1190
    },
    {
      "epoch": 2.745995423340961,
      "grad_norm": 3.824146032333374,
      "learning_rate": 1.4508009153318078e-05,
      "loss": 0.2422,
      "step": 1200
    },
    {
      "epoch": 2.7688787185354693,
      "grad_norm": 5.516704082489014,
      "learning_rate": 1.4462242562929062e-05,
      "loss": 0.274,
      "step": 1210
    },
    {
      "epoch": 2.791762013729977,
      "grad_norm": 10.80062484741211,
      "learning_rate": 1.4416475972540047e-05,
      "loss": 0.2577,
      "step": 1220
    },
    {
      "epoch": 2.814645308924485,
      "grad_norm": 3.3737783432006836,
      "learning_rate": 1.4370709382151031e-05,
      "loss": 0.2626,
      "step": 1230
    },
    {
      "epoch": 2.837528604118993,
      "grad_norm": 9.3385009765625,
      "learning_rate": 1.4324942791762015e-05,
      "loss": 0.2314,
      "step": 1240
    },
    {
      "epoch": 2.860411899313501,
      "grad_norm": 4.813507080078125,
      "learning_rate": 1.4279176201373e-05,
      "loss": 0.237,
      "step": 1250
    },
    {
      "epoch": 2.883295194508009,
      "grad_norm": 9.539222717285156,
      "learning_rate": 1.4233409610983984e-05,
      "loss": 0.2449,
      "step": 1260
    },
    {
      "epoch": 2.9061784897025174,
      "grad_norm": 7.952460289001465,
      "learning_rate": 1.4187643020594968e-05,
      "loss": 0.2297,
      "step": 1270
    },
    {
      "epoch": 2.929061784897025,
      "grad_norm": 5.4384050369262695,
      "learning_rate": 1.4141876430205952e-05,
      "loss": 0.3234,
      "step": 1280
    },
    {
      "epoch": 2.9519450800915332,
      "grad_norm": 8.368539810180664,
      "learning_rate": 1.4096109839816933e-05,
      "loss": 0.2332,
      "step": 1290
    },
    {
      "epoch": 2.974828375286041,
      "grad_norm": 8.119955062866211,
      "learning_rate": 1.4050343249427917e-05,
      "loss": 0.3259,
      "step": 1300
    },
    {
      "epoch": 2.997711670480549,
      "grad_norm": 6.065619945526123,
      "learning_rate": 1.4004576659038902e-05,
      "loss": 0.2833,
      "step": 1310
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8883333333333333,
      "eval_f1": 0.6462513199577614,
      "eval_loss": 0.2858494222164154,
      "eval_precision": 0.8406593406593407,
      "eval_recall": 0.5248713550600344,
      "eval_runtime": 645.5562,
      "eval_samples_per_second": 4.647,
      "eval_steps_per_second": 0.581,
      "step": 1311
    },
    {
      "epoch": 3.0205949656750573,
      "grad_norm": 5.261510848999023,
      "learning_rate": 1.3958810068649886e-05,
      "loss": 0.1998,
      "step": 1320
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 7.995758533477783,
      "learning_rate": 1.391304347826087e-05,
      "loss": 0.1769,
      "step": 1330
    },
    {
      "epoch": 3.066361556064073,
      "grad_norm": 4.498012542724609,
      "learning_rate": 1.3867276887871854e-05,
      "loss": 0.2315,
      "step": 1340
    },
    {
      "epoch": 3.0892448512585813,
      "grad_norm": 5.15555477142334,
      "learning_rate": 1.3821510297482839e-05,
      "loss": 0.2093,
      "step": 1350
    },
    {
      "epoch": 3.1121281464530894,
      "grad_norm": 8.074148178100586,
      "learning_rate": 1.3775743707093823e-05,
      "loss": 0.1679,
      "step": 1360
    },
    {
      "epoch": 3.135011441647597,
      "grad_norm": 5.998871803283691,
      "learning_rate": 1.3729977116704807e-05,
      "loss": 0.1301,
      "step": 1370
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 2.3148717880249023,
      "learning_rate": 1.3684210526315791e-05,
      "loss": 0.123,
      "step": 1380
    },
    {
      "epoch": 3.1807780320366135,
      "grad_norm": 9.226591110229492,
      "learning_rate": 1.3638443935926776e-05,
      "loss": 0.181,
      "step": 1390
    },
    {
      "epoch": 3.203661327231121,
      "grad_norm": 4.390482425689697,
      "learning_rate": 1.359267734553776e-05,
      "loss": 0.2008,
      "step": 1400
    },
    {
      "epoch": 3.2265446224256293,
      "grad_norm": 4.426965236663818,
      "learning_rate": 1.3546910755148744e-05,
      "loss": 0.1491,
      "step": 1410
    },
    {
      "epoch": 3.2494279176201375,
      "grad_norm": 6.410452365875244,
      "learning_rate": 1.3501144164759727e-05,
      "loss": 0.2279,
      "step": 1420
    },
    {
      "epoch": 3.272311212814645,
      "grad_norm": 7.5587239265441895,
      "learning_rate": 1.3455377574370711e-05,
      "loss": 0.1375,
      "step": 1430
    },
    {
      "epoch": 3.2951945080091534,
      "grad_norm": 12.086578369140625,
      "learning_rate": 1.3409610983981693e-05,
      "loss": 0.1884,
      "step": 1440
    },
    {
      "epoch": 3.3180778032036615,
      "grad_norm": 7.373082160949707,
      "learning_rate": 1.3363844393592678e-05,
      "loss": 0.1571,
      "step": 1450
    },
    {
      "epoch": 3.3409610983981692,
      "grad_norm": 11.90259075164795,
      "learning_rate": 1.3318077803203662e-05,
      "loss": 0.1891,
      "step": 1460
    },
    {
      "epoch": 3.3638443935926774,
      "grad_norm": 9.215938568115234,
      "learning_rate": 1.3272311212814646e-05,
      "loss": 0.1694,
      "step": 1470
    },
    {
      "epoch": 3.386727688787185,
      "grad_norm": 8.76724910736084,
      "learning_rate": 1.322654462242563e-05,
      "loss": 0.2194,
      "step": 1480
    },
    {
      "epoch": 3.4096109839816933,
      "grad_norm": 9.593953132629395,
      "learning_rate": 1.3180778032036615e-05,
      "loss": 0.2148,
      "step": 1490
    },
    {
      "epoch": 3.4324942791762014,
      "grad_norm": 4.07496452331543,
      "learning_rate": 1.3135011441647599e-05,
      "loss": 0.1445,
      "step": 1500
    },
    {
      "epoch": 3.4553775743707096,
      "grad_norm": 13.069637298583984,
      "learning_rate": 1.3089244851258582e-05,
      "loss": 0.1978,
      "step": 1510
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 7.897576808929443,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.1595,
      "step": 1520
    },
    {
      "epoch": 3.5011441647597255,
      "grad_norm": 6.122560501098633,
      "learning_rate": 1.299771167048055e-05,
      "loss": 0.1608,
      "step": 1530
    },
    {
      "epoch": 3.524027459954233,
      "grad_norm": 11.92203140258789,
      "learning_rate": 1.2951945080091534e-05,
      "loss": 0.2141,
      "step": 1540
    },
    {
      "epoch": 3.5469107551487413,
      "grad_norm": 7.067647933959961,
      "learning_rate": 1.2906178489702519e-05,
      "loss": 0.2231,
      "step": 1550
    },
    {
      "epoch": 3.5697940503432495,
      "grad_norm": 6.9667067527771,
      "learning_rate": 1.2860411899313503e-05,
      "loss": 0.1934,
      "step": 1560
    },
    {
      "epoch": 3.5926773455377576,
      "grad_norm": 6.1901936531066895,
      "learning_rate": 1.2814645308924487e-05,
      "loss": 0.172,
      "step": 1570
    },
    {
      "epoch": 3.6155606407322654,
      "grad_norm": 8.96493911743164,
      "learning_rate": 1.2768878718535471e-05,
      "loss": 0.1443,
      "step": 1580
    },
    {
      "epoch": 3.6384439359267735,
      "grad_norm": 5.945191383361816,
      "learning_rate": 1.2723112128146454e-05,
      "loss": 0.2324,
      "step": 1590
    },
    {
      "epoch": 3.6613272311212812,
      "grad_norm": 7.542407512664795,
      "learning_rate": 1.2677345537757438e-05,
      "loss": 0.1514,
      "step": 1600
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 4.626245975494385,
      "learning_rate": 1.263157894736842e-05,
      "loss": 0.1617,
      "step": 1610
    },
    {
      "epoch": 3.7070938215102975,
      "grad_norm": 7.442316055297852,
      "learning_rate": 1.2585812356979405e-05,
      "loss": 0.1406,
      "step": 1620
    },
    {
      "epoch": 3.7299771167048057,
      "grad_norm": 17.032634735107422,
      "learning_rate": 1.254004576659039e-05,
      "loss": 0.1681,
      "step": 1630
    },
    {
      "epoch": 3.7528604118993134,
      "grad_norm": 7.6241350173950195,
      "learning_rate": 1.2494279176201373e-05,
      "loss": 0.24,
      "step": 1640
    },
    {
      "epoch": 3.7757437070938216,
      "grad_norm": 5.998086929321289,
      "learning_rate": 1.2448512585812358e-05,
      "loss": 0.1808,
      "step": 1650
    },
    {
      "epoch": 3.7986270022883293,
      "grad_norm": 2.5735533237457275,
      "learning_rate": 1.2402745995423342e-05,
      "loss": 0.1785,
      "step": 1660
    },
    {
      "epoch": 3.8215102974828374,
      "grad_norm": 4.645374774932861,
      "learning_rate": 1.2356979405034326e-05,
      "loss": 0.1814,
      "step": 1670
    },
    {
      "epoch": 3.8443935926773456,
      "grad_norm": 11.861018180847168,
      "learning_rate": 1.231121281464531e-05,
      "loss": 0.158,
      "step": 1680
    },
    {
      "epoch": 3.8672768878718538,
      "grad_norm": 6.0449323654174805,
      "learning_rate": 1.2265446224256295e-05,
      "loss": 0.1497,
      "step": 1690
    },
    {
      "epoch": 3.8901601830663615,
      "grad_norm": 2.174386501312256,
      "learning_rate": 1.2219679633867279e-05,
      "loss": 0.118,
      "step": 1700
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 5.716592311859131,
      "learning_rate": 1.2173913043478263e-05,
      "loss": 0.1665,
      "step": 1710
    },
    {
      "epoch": 3.9359267734553773,
      "grad_norm": 7.719555377960205,
      "learning_rate": 1.2128146453089247e-05,
      "loss": 0.1977,
      "step": 1720
    },
    {
      "epoch": 3.9588100686498855,
      "grad_norm": 9.087430953979492,
      "learning_rate": 1.2082379862700232e-05,
      "loss": 0.1402,
      "step": 1730
    },
    {
      "epoch": 3.9816933638443937,
      "grad_norm": 4.863699913024902,
      "learning_rate": 1.2036613272311213e-05,
      "loss": 0.1827,
      "step": 1740
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9006666666666666,
      "eval_f1": 0.7664576802507838,
      "eval_loss": 0.279429167509079,
      "eval_precision": 0.7056277056277056,
      "eval_recall": 0.8387650085763293,
      "eval_runtime": 659.7427,
      "eval_samples_per_second": 4.547,
      "eval_steps_per_second": 0.568,
      "step": 1748
    },
    {
      "epoch": 4.004576659038902,
      "grad_norm": 10.948301315307617,
      "learning_rate": 1.1990846681922197e-05,
      "loss": 0.2202,
      "step": 1750
    },
    {
      "epoch": 4.02745995423341,
      "grad_norm": 4.370145320892334,
      "learning_rate": 1.1945080091533181e-05,
      "loss": 0.1542,
      "step": 1760
    },
    {
      "epoch": 4.050343249427917,
      "grad_norm": 4.460419178009033,
      "learning_rate": 1.1899313501144165e-05,
      "loss": 0.0882,
      "step": 1770
    },
    {
      "epoch": 4.073226544622425,
      "grad_norm": 5.145376205444336,
      "learning_rate": 1.185354691075515e-05,
      "loss": 0.0985,
      "step": 1780
    },
    {
      "epoch": 4.0961098398169336,
      "grad_norm": 9.138543128967285,
      "learning_rate": 1.1807780320366134e-05,
      "loss": 0.1025,
      "step": 1790
    },
    {
      "epoch": 4.118993135011442,
      "grad_norm": 2.534564256668091,
      "learning_rate": 1.1762013729977118e-05,
      "loss": 0.1078,
      "step": 1800
    },
    {
      "epoch": 4.14187643020595,
      "grad_norm": 6.876835346221924,
      "learning_rate": 1.1716247139588102e-05,
      "loss": 0.1003,
      "step": 1810
    },
    {
      "epoch": 4.164759725400458,
      "grad_norm": 15.752449035644531,
      "learning_rate": 1.1670480549199087e-05,
      "loss": 0.1351,
      "step": 1820
    },
    {
      "epoch": 4.187643020594965,
      "grad_norm": 10.030060768127441,
      "learning_rate": 1.1624713958810069e-05,
      "loss": 0.106,
      "step": 1830
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 6.565807342529297,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.0808,
      "step": 1840
    },
    {
      "epoch": 4.233409610983982,
      "grad_norm": 11.727742195129395,
      "learning_rate": 1.1533180778032038e-05,
      "loss": 0.1458,
      "step": 1850
    },
    {
      "epoch": 4.25629290617849,
      "grad_norm": 14.420233726501465,
      "learning_rate": 1.1487414187643022e-05,
      "loss": 0.0892,
      "step": 1860
    },
    {
      "epoch": 4.279176201372998,
      "grad_norm": 6.989002704620361,
      "learning_rate": 1.1441647597254006e-05,
      "loss": 0.1006,
      "step": 1870
    },
    {
      "epoch": 4.302059496567506,
      "grad_norm": 10.600654602050781,
      "learning_rate": 1.139588100686499e-05,
      "loss": 0.0619,
      "step": 1880
    },
    {
      "epoch": 4.324942791762013,
      "grad_norm": 1.820526123046875,
      "learning_rate": 1.1350114416475973e-05,
      "loss": 0.0941,
      "step": 1890
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 8.618853569030762,
      "learning_rate": 1.1304347826086957e-05,
      "loss": 0.1126,
      "step": 1900
    },
    {
      "epoch": 4.37070938215103,
      "grad_norm": 0.8589030504226685,
      "learning_rate": 1.1258581235697941e-05,
      "loss": 0.136,
      "step": 1910
    },
    {
      "epoch": 4.393592677345538,
      "grad_norm": 7.73363733291626,
      "learning_rate": 1.1212814645308924e-05,
      "loss": 0.0958,
      "step": 1920
    },
    {
      "epoch": 4.416475972540046,
      "grad_norm": 12.451501846313477,
      "learning_rate": 1.1167048054919908e-05,
      "loss": 0.0921,
      "step": 1930
    },
    {
      "epoch": 4.439359267734554,
      "grad_norm": 10.57390022277832,
      "learning_rate": 1.1121281464530893e-05,
      "loss": 0.1578,
      "step": 1940
    },
    {
      "epoch": 4.462242562929061,
      "grad_norm": 10.323328971862793,
      "learning_rate": 1.1075514874141877e-05,
      "loss": 0.1342,
      "step": 1950
    },
    {
      "epoch": 4.48512585812357,
      "grad_norm": 1.6560195684432983,
      "learning_rate": 1.1029748283752861e-05,
      "loss": 0.1142,
      "step": 1960
    },
    {
      "epoch": 4.508009153318078,
      "grad_norm": 19.7176456451416,
      "learning_rate": 1.0983981693363845e-05,
      "loss": 0.1599,
      "step": 1970
    },
    {
      "epoch": 4.530892448512586,
      "grad_norm": 10.134881019592285,
      "learning_rate": 1.093821510297483e-05,
      "loss": 0.1346,
      "step": 1980
    },
    {
      "epoch": 4.553775743707094,
      "grad_norm": 6.5392165184021,
      "learning_rate": 1.0892448512585814e-05,
      "loss": 0.1463,
      "step": 1990
    },
    {
      "epoch": 4.576659038901602,
      "grad_norm": 2.3918261528015137,
      "learning_rate": 1.0846681922196798e-05,
      "loss": 0.0879,
      "step": 2000
    },
    {
      "epoch": 4.5995423340961095,
      "grad_norm": 5.37092924118042,
      "learning_rate": 1.0800915331807782e-05,
      "loss": 0.0831,
      "step": 2010
    },
    {
      "epoch": 4.622425629290618,
      "grad_norm": 5.520730495452881,
      "learning_rate": 1.0755148741418767e-05,
      "loss": 0.1536,
      "step": 2020
    },
    {
      "epoch": 4.645308924485126,
      "grad_norm": 8.73831558227539,
      "learning_rate": 1.070938215102975e-05,
      "loss": 0.1153,
      "step": 2030
    },
    {
      "epoch": 4.668192219679634,
      "grad_norm": 6.047656536102295,
      "learning_rate": 1.0663615560640732e-05,
      "loss": 0.1217,
      "step": 2040
    },
    {
      "epoch": 4.691075514874142,
      "grad_norm": 14.283792495727539,
      "learning_rate": 1.0617848970251716e-05,
      "loss": 0.1095,
      "step": 2050
    },
    {
      "epoch": 4.71395881006865,
      "grad_norm": 8.129334449768066,
      "learning_rate": 1.05720823798627e-05,
      "loss": 0.1061,
      "step": 2060
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 1.3766000270843506,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.1441,
      "step": 2070
    },
    {
      "epoch": 4.759725400457666,
      "grad_norm": 5.696884632110596,
      "learning_rate": 1.0480549199084669e-05,
      "loss": 0.1008,
      "step": 2080
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 4.00890588760376,
      "learning_rate": 1.0434782608695653e-05,
      "loss": 0.1061,
      "step": 2090
    },
    {
      "epoch": 4.805491990846682,
      "grad_norm": 4.879056930541992,
      "learning_rate": 1.0389016018306637e-05,
      "loss": 0.089,
      "step": 2100
    },
    {
      "epoch": 4.82837528604119,
      "grad_norm": 6.892885684967041,
      "learning_rate": 1.0343249427917621e-05,
      "loss": 0.1392,
      "step": 2110
    },
    {
      "epoch": 4.851258581235698,
      "grad_norm": 6.020927906036377,
      "learning_rate": 1.0297482837528606e-05,
      "loss": 0.1608,
      "step": 2120
    },
    {
      "epoch": 4.874141876430206,
      "grad_norm": 17.397836685180664,
      "learning_rate": 1.025171624713959e-05,
      "loss": 0.1125,
      "step": 2130
    },
    {
      "epoch": 4.897025171624714,
      "grad_norm": 4.669654846191406,
      "learning_rate": 1.0205949656750573e-05,
      "loss": 0.1108,
      "step": 2140
    },
    {
      "epoch": 4.919908466819222,
      "grad_norm": 7.600491046905518,
      "learning_rate": 1.0160183066361557e-05,
      "loss": 0.1167,
      "step": 2150
    },
    {
      "epoch": 4.94279176201373,
      "grad_norm": 7.748783111572266,
      "learning_rate": 1.0114416475972541e-05,
      "loss": 0.1365,
      "step": 2160
    },
    {
      "epoch": 4.965675057208238,
      "grad_norm": 8.446825981140137,
      "learning_rate": 1.0068649885583525e-05,
      "loss": 0.13,
      "step": 2170
    },
    {
      "epoch": 4.988558352402746,
      "grad_norm": 5.593907833099365,
      "learning_rate": 1.002288329519451e-05,
      "loss": 0.1365,
      "step": 2180
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.917,
      "eval_f1": 0.7905803195962993,
      "eval_loss": 0.2961982190608978,
      "eval_precision": 0.7755775577557755,
      "eval_recall": 0.8061749571183533,
      "eval_runtime": 666.7216,
      "eval_samples_per_second": 4.5,
      "eval_steps_per_second": 0.562,
      "step": 2185
    },
    {
      "epoch": 5.011441647597254,
      "grad_norm": 39.95850372314453,
      "learning_rate": 9.977116704805492e-06,
      "loss": 0.1026,
      "step": 2190
    },
    {
      "epoch": 5.034324942791762,
      "grad_norm": 3.222175121307373,
      "learning_rate": 9.931350114416476e-06,
      "loss": 0.0466,
      "step": 2200
    },
    {
      "epoch": 5.05720823798627,
      "grad_norm": 7.840512752532959,
      "learning_rate": 9.88558352402746e-06,
      "loss": 0.0595,
      "step": 2210
    },
    {
      "epoch": 5.080091533180778,
      "grad_norm": 0.16642071306705475,
      "learning_rate": 9.839816933638445e-06,
      "loss": 0.0543,
      "step": 2220
    },
    {
      "epoch": 5.102974828375286,
      "grad_norm": 3.951190948486328,
      "learning_rate": 9.794050343249429e-06,
      "loss": 0.1122,
      "step": 2230
    },
    {
      "epoch": 5.125858123569794,
      "grad_norm": 6.1544270515441895,
      "learning_rate": 9.748283752860412e-06,
      "loss": 0.0689,
      "step": 2240
    },
    {
      "epoch": 5.148741418764302,
      "grad_norm": 3.7595040798187256,
      "learning_rate": 9.702517162471396e-06,
      "loss": 0.1195,
      "step": 2250
    },
    {
      "epoch": 5.17162471395881,
      "grad_norm": 17.53715705871582,
      "learning_rate": 9.65675057208238e-06,
      "loss": 0.0693,
      "step": 2260
    },
    {
      "epoch": 5.194508009153318,
      "grad_norm": 7.582944869995117,
      "learning_rate": 9.610983981693364e-06,
      "loss": 0.0649,
      "step": 2270
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 12.340950965881348,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.0324,
      "step": 2280
    },
    {
      "epoch": 5.240274599542334,
      "grad_norm": 8.16906452178955,
      "learning_rate": 9.519450800915333e-06,
      "loss": 0.1123,
      "step": 2290
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 15.208721160888672,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.0667,
      "step": 2300
    },
    {
      "epoch": 5.28604118993135,
      "grad_norm": 17.047008514404297,
      "learning_rate": 9.4279176201373e-06,
      "loss": 0.0753,
      "step": 2310
    },
    {
      "epoch": 5.308924485125858,
      "grad_norm": 12.849501609802246,
      "learning_rate": 9.382151029748284e-06,
      "loss": 0.0679,
      "step": 2320
    },
    {
      "epoch": 5.331807780320366,
      "grad_norm": 7.201321601867676,
      "learning_rate": 9.336384439359268e-06,
      "loss": 0.0685,
      "step": 2330
    },
    {
      "epoch": 5.354691075514874,
      "grad_norm": 1.781295895576477,
      "learning_rate": 9.290617848970253e-06,
      "loss": 0.0359,
      "step": 2340
    },
    {
      "epoch": 5.377574370709382,
      "grad_norm": 14.829343795776367,
      "learning_rate": 9.244851258581237e-06,
      "loss": 0.1395,
      "step": 2350
    },
    {
      "epoch": 5.4004576659038905,
      "grad_norm": 2.840615749359131,
      "learning_rate": 9.199084668192221e-06,
      "loss": 0.0561,
      "step": 2360
    },
    {
      "epoch": 5.423340961098398,
      "grad_norm": 3.3771016597747803,
      "learning_rate": 9.153318077803205e-06,
      "loss": 0.0988,
      "step": 2370
    },
    {
      "epoch": 5.446224256292906,
      "grad_norm": 24.295366287231445,
      "learning_rate": 9.107551487414188e-06,
      "loss": 0.1451,
      "step": 2380
    },
    {
      "epoch": 5.469107551487414,
      "grad_norm": 13.216574668884277,
      "learning_rate": 9.061784897025172e-06,
      "loss": 0.0842,
      "step": 2390
    },
    {
      "epoch": 5.491990846681922,
      "grad_norm": 5.0993571281433105,
      "learning_rate": 9.016018306636156e-06,
      "loss": 0.1072,
      "step": 2400
    },
    {
      "epoch": 5.51487414187643,
      "grad_norm": 23.077144622802734,
      "learning_rate": 8.97025171624714e-06,
      "loss": 0.1148,
      "step": 2410
    },
    {
      "epoch": 5.537757437070939,
      "grad_norm": 9.581753730773926,
      "learning_rate": 8.924485125858125e-06,
      "loss": 0.1382,
      "step": 2420
    },
    {
      "epoch": 5.560640732265446,
      "grad_norm": 4.47524881362915,
      "learning_rate": 8.878718535469109e-06,
      "loss": 0.0688,
      "step": 2430
    },
    {
      "epoch": 5.583524027459954,
      "grad_norm": 0.8229915499687195,
      "learning_rate": 8.832951945080093e-06,
      "loss": 0.0557,
      "step": 2440
    },
    {
      "epoch": 5.606407322654462,
      "grad_norm": 0.1664271205663681,
      "learning_rate": 8.787185354691076e-06,
      "loss": 0.0588,
      "step": 2450
    },
    {
      "epoch": 5.62929061784897,
      "grad_norm": 5.990485191345215,
      "learning_rate": 8.74141876430206e-06,
      "loss": 0.072,
      "step": 2460
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 6.68239688873291,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0294,
      "step": 2470
    },
    {
      "epoch": 5.675057208237987,
      "grad_norm": 14.86047077178955,
      "learning_rate": 8.649885583524029e-06,
      "loss": 0.0997,
      "step": 2480
    },
    {
      "epoch": 5.697940503432494,
      "grad_norm": 4.2966132164001465,
      "learning_rate": 8.604118993135013e-06,
      "loss": 0.0498,
      "step": 2490
    },
    {
      "epoch": 5.720823798627002,
      "grad_norm": 9.9150972366333,
      "learning_rate": 8.558352402745997e-06,
      "loss": 0.1041,
      "step": 2500
    },
    {
      "epoch": 5.74370709382151,
      "grad_norm": 3.546604871749878,
      "learning_rate": 8.51258581235698e-06,
      "loss": 0.0809,
      "step": 2510
    },
    {
      "epoch": 5.766590389016018,
      "grad_norm": 3.9938759803771973,
      "learning_rate": 8.466819221967964e-06,
      "loss": 0.0763,
      "step": 2520
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 5.195213794708252,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.0567,
      "step": 2530
    },
    {
      "epoch": 5.812356979405035,
      "grad_norm": 1.8339356184005737,
      "learning_rate": 8.375286041189932e-06,
      "loss": 0.0353,
      "step": 2540
    },
    {
      "epoch": 5.835240274599542,
      "grad_norm": 0.23875360190868378,
      "learning_rate": 8.329519450800915e-06,
      "loss": 0.0791,
      "step": 2550
    },
    {
      "epoch": 5.85812356979405,
      "grad_norm": 0.8720571398735046,
      "learning_rate": 8.2837528604119e-06,
      "loss": 0.081,
      "step": 2560
    },
    {
      "epoch": 5.881006864988558,
      "grad_norm": 7.290085792541504,
      "learning_rate": 8.237986270022884e-06,
      "loss": 0.1561,
      "step": 2570
    },
    {
      "epoch": 5.9038901601830664,
      "grad_norm": 6.7774786949157715,
      "learning_rate": 8.192219679633868e-06,
      "loss": 0.0548,
      "step": 2580
    },
    {
      "epoch": 5.926773455377575,
      "grad_norm": 12.029736518859863,
      "learning_rate": 8.146453089244852e-06,
      "loss": 0.0549,
      "step": 2590
    },
    {
      "epoch": 5.949656750572083,
      "grad_norm": 2.831657648086548,
      "learning_rate": 8.100686498855835e-06,
      "loss": 0.0748,
      "step": 2600
    },
    {
      "epoch": 5.97254004576659,
      "grad_norm": 2.2704455852508545,
      "learning_rate": 8.054919908466819e-06,
      "loss": 0.0414,
      "step": 2610
    },
    {
      "epoch": 5.995423340961098,
      "grad_norm": 21.228225708007812,
      "learning_rate": 8.009153318077803e-06,
      "loss": 0.126,
      "step": 2620
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.912,
      "eval_f1": 0.7870967741935484,
      "eval_loss": 0.36278295516967773,
      "eval_precision": 0.7427701674277016,
      "eval_recall": 0.8370497427101201,
      "eval_runtime": 665.8885,
      "eval_samples_per_second": 4.505,
      "eval_steps_per_second": 0.563,
      "step": 2622
    },
    {
      "epoch": 6.018306636155606,
      "grad_norm": 2.8317763805389404,
      "learning_rate": 7.963386727688787e-06,
      "loss": 0.045,
      "step": 2630
    },
    {
      "epoch": 6.0411899313501145,
      "grad_norm": 0.06414720416069031,
      "learning_rate": 7.917620137299772e-06,
      "loss": 0.043,
      "step": 2640
    },
    {
      "epoch": 6.064073226544623,
      "grad_norm": 18.155744552612305,
      "learning_rate": 7.871853546910756e-06,
      "loss": 0.066,
      "step": 2650
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 3.025543451309204,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.0816,
      "step": 2660
    },
    {
      "epoch": 6.109839816933638,
      "grad_norm": 1.495849847793579,
      "learning_rate": 7.780320366132724e-06,
      "loss": 0.066,
      "step": 2670
    },
    {
      "epoch": 6.132723112128146,
      "grad_norm": 0.3694044053554535,
      "learning_rate": 7.734553775743707e-06,
      "loss": 0.0436,
      "step": 2680
    },
    {
      "epoch": 6.155606407322654,
      "grad_norm": 1.824328064918518,
      "learning_rate": 7.688787185354691e-06,
      "loss": 0.0361,
      "step": 2690
    },
    {
      "epoch": 6.178489702517163,
      "grad_norm": 8.149116516113281,
      "learning_rate": 7.643020594965675e-06,
      "loss": 0.0698,
      "step": 2700
    },
    {
      "epoch": 6.201372997711671,
      "grad_norm": 9.521347999572754,
      "learning_rate": 7.59725400457666e-06,
      "loss": 0.0399,
      "step": 2710
    },
    {
      "epoch": 6.224256292906179,
      "grad_norm": 0.24068433046340942,
      "learning_rate": 7.551487414187644e-06,
      "loss": 0.0312,
      "step": 2720
    },
    {
      "epoch": 6.247139588100686,
      "grad_norm": 11.792516708374023,
      "learning_rate": 7.505720823798628e-06,
      "loss": 0.0434,
      "step": 2730
    },
    {
      "epoch": 6.270022883295194,
      "grad_norm": 1.1354457139968872,
      "learning_rate": 7.459954233409612e-06,
      "loss": 0.0548,
      "step": 2740
    },
    {
      "epoch": 6.2929061784897025,
      "grad_norm": 7.058971881866455,
      "learning_rate": 7.414187643020596e-06,
      "loss": 0.0223,
      "step": 2750
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 13.07348918914795,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0808,
      "step": 2760
    },
    {
      "epoch": 6.338672768878719,
      "grad_norm": 2.6308095455169678,
      "learning_rate": 7.3226544622425635e-06,
      "loss": 0.0223,
      "step": 2770
    },
    {
      "epoch": 6.361556064073227,
      "grad_norm": 7.540648937225342,
      "learning_rate": 7.276887871853548e-06,
      "loss": 0.0653,
      "step": 2780
    },
    {
      "epoch": 6.384439359267734,
      "grad_norm": 22.699819564819336,
      "learning_rate": 7.231121281464531e-06,
      "loss": 0.0436,
      "step": 2790
    },
    {
      "epoch": 6.407322654462242,
      "grad_norm": 43.61781311035156,
      "learning_rate": 7.1853546910755154e-06,
      "loss": 0.0525,
      "step": 2800
    },
    {
      "epoch": 6.4302059496567505,
      "grad_norm": 5.452027797698975,
      "learning_rate": 7.1395881006865e-06,
      "loss": 0.0335,
      "step": 2810
    },
    {
      "epoch": 6.453089244851259,
      "grad_norm": 12.703049659729004,
      "learning_rate": 7.093821510297484e-06,
      "loss": 0.0402,
      "step": 2820
    },
    {
      "epoch": 6.475972540045767,
      "grad_norm": 4.106993198394775,
      "learning_rate": 7.0480549199084665e-06,
      "loss": 0.0541,
      "step": 2830
    },
    {
      "epoch": 6.498855835240275,
      "grad_norm": 7.203525543212891,
      "learning_rate": 7.002288329519451e-06,
      "loss": 0.0757,
      "step": 2840
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.4095516800880432,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.1026,
      "step": 2850
    },
    {
      "epoch": 6.54462242562929,
      "grad_norm": 11.954456329345703,
      "learning_rate": 6.910755148741419e-06,
      "loss": 0.0643,
      "step": 2860
    },
    {
      "epoch": 6.567505720823799,
      "grad_norm": 17.55900001525879,
      "learning_rate": 6.8649885583524035e-06,
      "loss": 0.0467,
      "step": 2870
    },
    {
      "epoch": 6.590389016018307,
      "grad_norm": 0.8851101994514465,
      "learning_rate": 6.819221967963388e-06,
      "loss": 0.0306,
      "step": 2880
    },
    {
      "epoch": 6.613272311212815,
      "grad_norm": 6.111057281494141,
      "learning_rate": 6.773455377574372e-06,
      "loss": 0.0331,
      "step": 2890
    },
    {
      "epoch": 6.636155606407323,
      "grad_norm": 21.19968605041504,
      "learning_rate": 6.7276887871853554e-06,
      "loss": 0.0886,
      "step": 2900
    },
    {
      "epoch": 6.65903890160183,
      "grad_norm": 0.31305691599845886,
      "learning_rate": 6.681922196796339e-06,
      "loss": 0.0361,
      "step": 2910
    },
    {
      "epoch": 6.6819221967963385,
      "grad_norm": 12.236605644226074,
      "learning_rate": 6.636155606407323e-06,
      "loss": 0.0753,
      "step": 2920
    },
    {
      "epoch": 6.704805491990847,
      "grad_norm": 7.420158386230469,
      "learning_rate": 6.590389016018307e-06,
      "loss": 0.0577,
      "step": 2930
    },
    {
      "epoch": 6.727688787185355,
      "grad_norm": 3.315171003341675,
      "learning_rate": 6.544622425629291e-06,
      "loss": 0.0458,
      "step": 2940
    },
    {
      "epoch": 6.750572082379863,
      "grad_norm": 0.7956370115280151,
      "learning_rate": 6.498855835240275e-06,
      "loss": 0.0329,
      "step": 2950
    },
    {
      "epoch": 6.77345537757437,
      "grad_norm": 0.060157667845487595,
      "learning_rate": 6.453089244851259e-06,
      "loss": 0.0465,
      "step": 2960
    },
    {
      "epoch": 6.796338672768878,
      "grad_norm": 6.295839786529541,
      "learning_rate": 6.4073226544622435e-06,
      "loss": 0.0323,
      "step": 2970
    },
    {
      "epoch": 6.8192219679633865,
      "grad_norm": 3.967505931854248,
      "learning_rate": 6.361556064073227e-06,
      "loss": 0.0287,
      "step": 2980
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 0.3387817144393921,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.0508,
      "step": 2990
    },
    {
      "epoch": 6.864988558352403,
      "grad_norm": 10.143442153930664,
      "learning_rate": 6.270022883295195e-06,
      "loss": 0.0629,
      "step": 3000
    },
    {
      "epoch": 6.887871853546911,
      "grad_norm": 0.5686784982681274,
      "learning_rate": 6.224256292906179e-06,
      "loss": 0.0148,
      "step": 3010
    },
    {
      "epoch": 6.910755148741419,
      "grad_norm": 7.03937292098999,
      "learning_rate": 6.178489702517163e-06,
      "loss": 0.0514,
      "step": 3020
    },
    {
      "epoch": 6.933638443935926,
      "grad_norm": 1.4669519662857056,
      "learning_rate": 6.132723112128147e-06,
      "loss": 0.074,
      "step": 3030
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 4.4097185134887695,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.0563,
      "step": 3040
    },
    {
      "epoch": 6.979405034324943,
      "grad_norm": 6.012221813201904,
      "learning_rate": 6.041189931350116e-06,
      "loss": 0.0197,
      "step": 3050
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9236666666666666,
      "eval_f1": 0.7989464442493415,
      "eval_loss": 0.43902239203453064,
      "eval_precision": 0.8183453237410072,
      "eval_recall": 0.7804459691252144,
      "eval_runtime": 660.2991,
      "eval_samples_per_second": 4.543,
      "eval_steps_per_second": 0.568,
      "step": 3059
    },
    {
      "epoch": 7.002288329519451,
      "grad_norm": 3.2963814735412598,
      "learning_rate": 5.995423340961098e-06,
      "loss": 0.0499,
      "step": 3060
    },
    {
      "epoch": 7.025171624713959,
      "grad_norm": 13.010701179504395,
      "learning_rate": 5.949656750572083e-06,
      "loss": 0.0374,
      "step": 3070
    },
    {
      "epoch": 7.048054919908467,
      "grad_norm": 0.5216689109802246,
      "learning_rate": 5.903890160183067e-06,
      "loss": 0.0117,
      "step": 3080
    },
    {
      "epoch": 7.0709382151029745,
      "grad_norm": 1.8946465253829956,
      "learning_rate": 5.858123569794051e-06,
      "loss": 0.0418,
      "step": 3090
    },
    {
      "epoch": 7.093821510297483,
      "grad_norm": 1.4152507781982422,
      "learning_rate": 5.8123569794050346e-06,
      "loss": 0.0301,
      "step": 3100
    },
    {
      "epoch": 7.116704805491991,
      "grad_norm": 0.23025375604629517,
      "learning_rate": 5.766590389016019e-06,
      "loss": 0.0294,
      "step": 3110
    },
    {
      "epoch": 7.139588100686499,
      "grad_norm": 2.883700132369995,
      "learning_rate": 5.720823798627003e-06,
      "loss": 0.0327,
      "step": 3120
    },
    {
      "epoch": 7.162471395881007,
      "grad_norm": 0.9511737823486328,
      "learning_rate": 5.6750572082379865e-06,
      "loss": 0.0192,
      "step": 3130
    },
    {
      "epoch": 7.185354691075515,
      "grad_norm": 0.20702381432056427,
      "learning_rate": 5.629290617848971e-06,
      "loss": 0.0322,
      "step": 3140
    },
    {
      "epoch": 7.2082379862700225,
      "grad_norm": 0.7036097645759583,
      "learning_rate": 5.583524027459954e-06,
      "loss": 0.0564,
      "step": 3150
    },
    {
      "epoch": 7.231121281464531,
      "grad_norm": 2.247222900390625,
      "learning_rate": 5.537757437070938e-06,
      "loss": 0.0203,
      "step": 3160
    },
    {
      "epoch": 7.254004576659039,
      "grad_norm": 1.0929076671600342,
      "learning_rate": 5.491990846681923e-06,
      "loss": 0.0482,
      "step": 3170
    },
    {
      "epoch": 7.276887871853547,
      "grad_norm": 6.511846542358398,
      "learning_rate": 5.446224256292907e-06,
      "loss": 0.0257,
      "step": 3180
    },
    {
      "epoch": 7.299771167048055,
      "grad_norm": 9.58724308013916,
      "learning_rate": 5.400457665903891e-06,
      "loss": 0.0465,
      "step": 3190
    },
    {
      "epoch": 7.322654462242563,
      "grad_norm": 0.10434477776288986,
      "learning_rate": 5.354691075514875e-06,
      "loss": 0.0695,
      "step": 3200
    },
    {
      "epoch": 7.345537757437071,
      "grad_norm": 5.028778553009033,
      "learning_rate": 5.308924485125858e-06,
      "loss": 0.0209,
      "step": 3210
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 11.886198043823242,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.0195,
      "step": 3220
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 0.11623533070087433,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.0076,
      "step": 3230
    },
    {
      "epoch": 7.414187643020595,
      "grad_norm": 1.197376012802124,
      "learning_rate": 5.171624713958811e-06,
      "loss": 0.0364,
      "step": 3240
    },
    {
      "epoch": 7.437070938215103,
      "grad_norm": 1.5683457851409912,
      "learning_rate": 5.125858123569795e-06,
      "loss": 0.0802,
      "step": 3250
    },
    {
      "epoch": 7.459954233409611,
      "grad_norm": 3.8763883113861084,
      "learning_rate": 5.080091533180778e-06,
      "loss": 0.0176,
      "step": 3260
    },
    {
      "epoch": 7.482837528604119,
      "grad_norm": 0.008977172896265984,
      "learning_rate": 5.034324942791763e-06,
      "loss": 0.0457,
      "step": 3270
    },
    {
      "epoch": 7.505720823798627,
      "grad_norm": 0.11499220877885818,
      "learning_rate": 4.988558352402746e-06,
      "loss": 0.0279,
      "step": 3280
    },
    {
      "epoch": 7.528604118993135,
      "grad_norm": 25.600887298583984,
      "learning_rate": 4.94279176201373e-06,
      "loss": 0.0467,
      "step": 3290
    },
    {
      "epoch": 7.551487414187643,
      "grad_norm": 3.1476826667785645,
      "learning_rate": 4.8970251716247146e-06,
      "loss": 0.0172,
      "step": 3300
    },
    {
      "epoch": 7.574370709382151,
      "grad_norm": 0.09072957932949066,
      "learning_rate": 4.851258581235698e-06,
      "loss": 0.0312,
      "step": 3310
    },
    {
      "epoch": 7.597254004576659,
      "grad_norm": 17.493759155273438,
      "learning_rate": 4.805491990846682e-06,
      "loss": 0.0476,
      "step": 3320
    },
    {
      "epoch": 7.620137299771167,
      "grad_norm": 0.040840938687324524,
      "learning_rate": 4.7597254004576665e-06,
      "loss": 0.1223,
      "step": 3330
    },
    {
      "epoch": 7.643020594965675,
      "grad_norm": 11.220489501953125,
      "learning_rate": 4.71395881006865e-06,
      "loss": 0.0789,
      "step": 3340
    },
    {
      "epoch": 7.665903890160183,
      "grad_norm": 0.11330218613147736,
      "learning_rate": 4.668192219679634e-06,
      "loss": 0.0182,
      "step": 3350
    },
    {
      "epoch": 7.688787185354691,
      "grad_norm": 0.052816856652498245,
      "learning_rate": 4.622425629290618e-06,
      "loss": 0.0318,
      "step": 3360
    },
    {
      "epoch": 7.711670480549199,
      "grad_norm": 0.651726245880127,
      "learning_rate": 4.576659038901603e-06,
      "loss": 0.0507,
      "step": 3370
    },
    {
      "epoch": 7.7345537757437075,
      "grad_norm": 0.021205518394708633,
      "learning_rate": 4.530892448512586e-06,
      "loss": 0.0977,
      "step": 3380
    },
    {
      "epoch": 7.757437070938215,
      "grad_norm": 0.20202812552452087,
      "learning_rate": 4.48512585812357e-06,
      "loss": 0.0263,
      "step": 3390
    },
    {
      "epoch": 7.780320366132723,
      "grad_norm": 0.20647676289081573,
      "learning_rate": 4.4393592677345545e-06,
      "loss": 0.0466,
      "step": 3400
    },
    {
      "epoch": 7.803203661327231,
      "grad_norm": 0.8318988084793091,
      "learning_rate": 4.393592677345538e-06,
      "loss": 0.0167,
      "step": 3410
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 0.1999516636133194,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0192,
      "step": 3420
    },
    {
      "epoch": 7.848970251716247,
      "grad_norm": 0.28253301978111267,
      "learning_rate": 4.3020594965675065e-06,
      "loss": 0.0042,
      "step": 3430
    },
    {
      "epoch": 7.871853546910755,
      "grad_norm": 30.68919563293457,
      "learning_rate": 4.25629290617849e-06,
      "loss": 0.0518,
      "step": 3440
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 1.7123955488204956,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.0341,
      "step": 3450
    },
    {
      "epoch": 7.917620137299771,
      "grad_norm": 3.5468626022338867,
      "learning_rate": 4.1647597254004575e-06,
      "loss": 0.0315,
      "step": 3460
    },
    {
      "epoch": 7.940503432494279,
      "grad_norm": 1.5765827894210815,
      "learning_rate": 4.118993135011442e-06,
      "loss": 0.0814,
      "step": 3470
    },
    {
      "epoch": 7.963386727688787,
      "grad_norm": 0.7087117433547974,
      "learning_rate": 4.073226544622426e-06,
      "loss": 0.026,
      "step": 3480
    },
    {
      "epoch": 7.9862700228832955,
      "grad_norm": 0.10292782634496689,
      "learning_rate": 4.0274599542334094e-06,
      "loss": 0.0224,
      "step": 3490
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.928,
      "eval_f1": 0.800369685767098,
      "eval_loss": 0.4823560416698456,
      "eval_precision": 0.8677354709418837,
      "eval_recall": 0.7427101200686106,
      "eval_runtime": 661.5059,
      "eval_samples_per_second": 4.535,
      "eval_steps_per_second": 0.567,
      "step": 3496
    },
    {
      "epoch": 8.009153318077804,
      "grad_norm": 0.21708083152770996,
      "learning_rate": 3.981693363844394e-06,
      "loss": 0.0205,
      "step": 3500
    },
    {
      "epoch": 8.03203661327231,
      "grad_norm": 1.1345878839492798,
      "learning_rate": 3.935926773455378e-06,
      "loss": 0.0198,
      "step": 3510
    },
    {
      "epoch": 8.05491990846682,
      "grad_norm": 0.07233471423387527,
      "learning_rate": 3.890160183066362e-06,
      "loss": 0.0198,
      "step": 3520
    },
    {
      "epoch": 8.077803203661327,
      "grad_norm": 0.01644895039498806,
      "learning_rate": 3.844393592677346e-06,
      "loss": 0.045,
      "step": 3530
    },
    {
      "epoch": 8.100686498855834,
      "grad_norm": 7.028849124908447,
      "learning_rate": 3.79862700228833e-06,
      "loss": 0.0134,
      "step": 3540
    },
    {
      "epoch": 8.123569794050344,
      "grad_norm": 0.06017013639211655,
      "learning_rate": 3.752860411899314e-06,
      "loss": 0.0352,
      "step": 3550
    },
    {
      "epoch": 8.14645308924485,
      "grad_norm": 0.11606404185295105,
      "learning_rate": 3.707093821510298e-06,
      "loss": 0.0022,
      "step": 3560
    },
    {
      "epoch": 8.16933638443936,
      "grad_norm": 0.0151340551674366,
      "learning_rate": 3.6613272311212818e-06,
      "loss": 0.0094,
      "step": 3570
    },
    {
      "epoch": 8.192219679633867,
      "grad_norm": 0.1893010437488556,
      "learning_rate": 3.6155606407322656e-06,
      "loss": 0.0326,
      "step": 3580
    },
    {
      "epoch": 8.215102974828376,
      "grad_norm": 0.05078805238008499,
      "learning_rate": 3.56979405034325e-06,
      "loss": 0.0143,
      "step": 3590
    },
    {
      "epoch": 8.237986270022883,
      "grad_norm": 2.81146240234375,
      "learning_rate": 3.5240274599542333e-06,
      "loss": 0.0124,
      "step": 3600
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 0.621340274810791,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.0119,
      "step": 3610
    },
    {
      "epoch": 8.2837528604119,
      "grad_norm": 12.279220581054688,
      "learning_rate": 3.4324942791762018e-06,
      "loss": 0.0078,
      "step": 3620
    },
    {
      "epoch": 8.306636155606407,
      "grad_norm": 0.49828797578811646,
      "learning_rate": 3.386727688787186e-06,
      "loss": 0.0304,
      "step": 3630
    },
    {
      "epoch": 8.329519450800916,
      "grad_norm": 1.2806440591812134,
      "learning_rate": 3.3409610983981694e-06,
      "loss": 0.0242,
      "step": 3640
    },
    {
      "epoch": 8.352402745995423,
      "grad_norm": 0.3924025595188141,
      "learning_rate": 3.2951945080091537e-06,
      "loss": 0.0162,
      "step": 3650
    },
    {
      "epoch": 8.37528604118993,
      "grad_norm": 0.788154661655426,
      "learning_rate": 3.2494279176201375e-06,
      "loss": 0.0265,
      "step": 3660
    },
    {
      "epoch": 8.39816933638444,
      "grad_norm": 0.10765373706817627,
      "learning_rate": 3.2036613272311218e-06,
      "loss": 0.0062,
      "step": 3670
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 0.814895749092102,
      "learning_rate": 3.157894736842105e-06,
      "loss": 0.0226,
      "step": 3680
    },
    {
      "epoch": 8.443935926773456,
      "grad_norm": 9.912583351135254,
      "learning_rate": 3.1121281464530894e-06,
      "loss": 0.0097,
      "step": 3690
    },
    {
      "epoch": 8.466819221967963,
      "grad_norm": 0.8196647763252258,
      "learning_rate": 3.0663615560640737e-06,
      "loss": 0.0371,
      "step": 3700
    },
    {
      "epoch": 8.48970251716247,
      "grad_norm": 0.12576623260974884,
      "learning_rate": 3.020594965675058e-06,
      "loss": 0.0006,
      "step": 3710
    },
    {
      "epoch": 8.51258581235698,
      "grad_norm": 0.034846916794776917,
      "learning_rate": 2.9748283752860413e-06,
      "loss": 0.0456,
      "step": 3720
    },
    {
      "epoch": 8.535469107551487,
      "grad_norm": 0.05998847261071205,
      "learning_rate": 2.9290617848970256e-06,
      "loss": 0.0332,
      "step": 3730
    },
    {
      "epoch": 8.558352402745996,
      "grad_norm": 0.10383093357086182,
      "learning_rate": 2.8832951945080094e-06,
      "loss": 0.0216,
      "step": 3740
    },
    {
      "epoch": 8.581235697940503,
      "grad_norm": 0.010626256465911865,
      "learning_rate": 2.8375286041189932e-06,
      "loss": 0.0288,
      "step": 3750
    },
    {
      "epoch": 8.604118993135012,
      "grad_norm": 0.02812943607568741,
      "learning_rate": 2.791762013729977e-06,
      "loss": 0.0736,
      "step": 3760
    },
    {
      "epoch": 8.62700228832952,
      "grad_norm": 0.23013746738433838,
      "learning_rate": 2.7459954233409613e-06,
      "loss": 0.02,
      "step": 3770
    },
    {
      "epoch": 8.649885583524027,
      "grad_norm": 0.0528702586889267,
      "learning_rate": 2.7002288329519456e-06,
      "loss": 0.0708,
      "step": 3780
    },
    {
      "epoch": 8.672768878718536,
      "grad_norm": 28.67554473876953,
      "learning_rate": 2.654462242562929e-06,
      "loss": 0.0206,
      "step": 3790
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.0114853885024786,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 0.0039,
      "step": 3800
    },
    {
      "epoch": 8.718535469107552,
      "grad_norm": 0.3712811768054962,
      "learning_rate": 2.5629290617848975e-06,
      "loss": 0.002,
      "step": 3810
    },
    {
      "epoch": 8.74141876430206,
      "grad_norm": 8.1933012008667,
      "learning_rate": 2.5171624713958813e-06,
      "loss": 0.0191,
      "step": 3820
    },
    {
      "epoch": 8.764302059496568,
      "grad_norm": 2.0935192108154297,
      "learning_rate": 2.471395881006865e-06,
      "loss": 0.0325,
      "step": 3830
    },
    {
      "epoch": 8.787185354691076,
      "grad_norm": 9.819594383239746,
      "learning_rate": 2.425629290617849e-06,
      "loss": 0.0057,
      "step": 3840
    },
    {
      "epoch": 8.810068649885583,
      "grad_norm": 5.454345703125,
      "learning_rate": 2.3798627002288332e-06,
      "loss": 0.013,
      "step": 3850
    },
    {
      "epoch": 8.832951945080092,
      "grad_norm": 5.262129783630371,
      "learning_rate": 2.334096109839817e-06,
      "loss": 0.0534,
      "step": 3860
    },
    {
      "epoch": 8.8558352402746,
      "grad_norm": 0.7696936726570129,
      "learning_rate": 2.2883295194508013e-06,
      "loss": 0.0297,
      "step": 3870
    },
    {
      "epoch": 8.878718535469108,
      "grad_norm": 3.8707337379455566,
      "learning_rate": 2.242562929061785e-06,
      "loss": 0.0484,
      "step": 3880
    },
    {
      "epoch": 8.901601830663616,
      "grad_norm": 0.02423970215022564,
      "learning_rate": 2.196796338672769e-06,
      "loss": 0.0093,
      "step": 3890
    },
    {
      "epoch": 8.924485125858123,
      "grad_norm": 0.024862082675099373,
      "learning_rate": 2.1510297482837532e-06,
      "loss": 0.0125,
      "step": 3900
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 0.01930372603237629,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.0132,
      "step": 3910
    },
    {
      "epoch": 8.97025171624714,
      "grad_norm": 0.039356447756290436,
      "learning_rate": 2.059496567505721e-06,
      "loss": 0.0086,
      "step": 3920
    },
    {
      "epoch": 8.993135011441648,
      "grad_norm": 0.7779843211174011,
      "learning_rate": 2.0137299771167047e-06,
      "loss": 0.0177,
      "step": 3930
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9226666666666666,
      "eval_f1": 0.8003442340791739,
      "eval_loss": 0.5249217748641968,
      "eval_precision": 0.8031088082901554,
      "eval_recall": 0.7975986277873071,
      "eval_runtime": 591.3104,
      "eval_samples_per_second": 5.073,
      "eval_steps_per_second": 0.634,
      "step": 3933
    },
    {
      "epoch": 9.016018306636155,
      "grad_norm": 0.36206483840942383,
      "learning_rate": 1.967963386727689e-06,
      "loss": 0.0167,
      "step": 3940
    },
    {
      "epoch": 9.038901601830664,
      "grad_norm": 7.196785926818848,
      "learning_rate": 1.922196796338673e-06,
      "loss": 0.0114,
      "step": 3950
    },
    {
      "epoch": 9.061784897025172,
      "grad_norm": 0.3868759870529175,
      "learning_rate": 1.876430205949657e-06,
      "loss": 0.0199,
      "step": 3960
    },
    {
      "epoch": 9.084668192219679,
      "grad_norm": 2.9043281078338623,
      "learning_rate": 1.8306636155606409e-06,
      "loss": 0.0024,
      "step": 3970
    },
    {
      "epoch": 9.107551487414188,
      "grad_norm": 0.09436050802469254,
      "learning_rate": 1.784897025171625e-06,
      "loss": 0.0042,
      "step": 3980
    },
    {
      "epoch": 9.130434782608695,
      "grad_norm": 0.31165122985839844,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 0.0093,
      "step": 3990
    },
    {
      "epoch": 9.153318077803204,
      "grad_norm": 0.07091841101646423,
      "learning_rate": 1.693363844393593e-06,
      "loss": 0.0075,
      "step": 4000
    },
    {
      "epoch": 9.176201372997712,
      "grad_norm": 12.007049560546875,
      "learning_rate": 1.6475972540045768e-06,
      "loss": 0.0132,
      "step": 4010
    },
    {
      "epoch": 9.199084668192219,
      "grad_norm": 0.1708192527294159,
      "learning_rate": 1.6018306636155609e-06,
      "loss": 0.0031,
      "step": 4020
    },
    {
      "epoch": 9.221967963386728,
      "grad_norm": 0.5579962134361267,
      "learning_rate": 1.5560640732265447e-06,
      "loss": 0.0405,
      "step": 4030
    },
    {
      "epoch": 9.244851258581235,
      "grad_norm": 4.516491413116455,
      "learning_rate": 1.510297482837529e-06,
      "loss": 0.0232,
      "step": 4040
    },
    {
      "epoch": 9.267734553775744,
      "grad_norm": 3.815730333328247,
      "learning_rate": 1.4645308924485128e-06,
      "loss": 0.0088,
      "step": 4050
    },
    {
      "epoch": 9.290617848970252,
      "grad_norm": 8.277087211608887,
      "learning_rate": 1.4187643020594966e-06,
      "loss": 0.0241,
      "step": 4060
    },
    {
      "epoch": 9.31350114416476,
      "grad_norm": 4.535100936889648,
      "learning_rate": 1.3729977116704807e-06,
      "loss": 0.0311,
      "step": 4070
    },
    {
      "epoch": 9.336384439359268,
      "grad_norm": 0.020815609022974968,
      "learning_rate": 1.3272311212814645e-06,
      "loss": 0.0165,
      "step": 4080
    },
    {
      "epoch": 9.359267734553775,
      "grad_norm": 7.700078010559082,
      "learning_rate": 1.2814645308924487e-06,
      "loss": 0.0193,
      "step": 4090
    },
    {
      "epoch": 9.382151029748284,
      "grad_norm": 0.3002651035785675,
      "learning_rate": 1.2356979405034326e-06,
      "loss": 0.0131,
      "step": 4100
    },
    {
      "epoch": 9.405034324942791,
      "grad_norm": 0.041644010692834854,
      "learning_rate": 1.1899313501144166e-06,
      "loss": 0.0081,
      "step": 4110
    },
    {
      "epoch": 9.4279176201373,
      "grad_norm": 26.38460922241211,
      "learning_rate": 1.1441647597254007e-06,
      "loss": 0.0368,
      "step": 4120
    },
    {
      "epoch": 9.450800915331808,
      "grad_norm": 3.3622167110443115,
      "learning_rate": 1.0983981693363845e-06,
      "loss": 0.0089,
      "step": 4130
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 0.02548300102353096,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.017,
      "step": 4140
    },
    {
      "epoch": 9.496567505720824,
      "grad_norm": 19.560766220092773,
      "learning_rate": 1.0068649885583524e-06,
      "loss": 0.0143,
      "step": 4150
    },
    {
      "epoch": 9.519450800915331,
      "grad_norm": 0.6060125827789307,
      "learning_rate": 9.610983981693364e-07,
      "loss": 0.0423,
      "step": 4160
    },
    {
      "epoch": 9.54233409610984,
      "grad_norm": 9.880924224853516,
      "learning_rate": 9.153318077803204e-07,
      "loss": 0.0026,
      "step": 4170
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 0.08842257410287857,
      "learning_rate": 8.695652173913044e-07,
      "loss": 0.0104,
      "step": 4180
    },
    {
      "epoch": 9.588100686498855,
      "grad_norm": 3.150074005126953,
      "learning_rate": 8.237986270022884e-07,
      "loss": 0.0236,
      "step": 4190
    },
    {
      "epoch": 9.610983981693364,
      "grad_norm": 0.17439833283424377,
      "learning_rate": 7.780320366132724e-07,
      "loss": 0.017,
      "step": 4200
    },
    {
      "epoch": 9.633867276887871,
      "grad_norm": 0.00589127978309989,
      "learning_rate": 7.322654462242564e-07,
      "loss": 0.0476,
      "step": 4210
    },
    {
      "epoch": 9.65675057208238,
      "grad_norm": 21.126798629760742,
      "learning_rate": 6.864988558352403e-07,
      "loss": 0.0494,
      "step": 4220
    },
    {
      "epoch": 9.679633867276888,
      "grad_norm": 9.484078407287598,
      "learning_rate": 6.407322654462244e-07,
      "loss": 0.0355,
      "step": 4230
    },
    {
      "epoch": 9.702517162471397,
      "grad_norm": 0.7610783576965332,
      "learning_rate": 5.949656750572083e-07,
      "loss": 0.0007,
      "step": 4240
    },
    {
      "epoch": 9.725400457665904,
      "grad_norm": 0.038827911019325256,
      "learning_rate": 5.491990846681922e-07,
      "loss": 0.0013,
      "step": 4250
    },
    {
      "epoch": 9.748283752860411,
      "grad_norm": 4.230271339416504,
      "learning_rate": 5.034324942791762e-07,
      "loss": 0.0189,
      "step": 4260
    },
    {
      "epoch": 9.77116704805492,
      "grad_norm": 0.017618617042899132,
      "learning_rate": 4.576659038901602e-07,
      "loss": 0.0069,
      "step": 4270
    },
    {
      "epoch": 9.794050343249427,
      "grad_norm": 0.24992763996124268,
      "learning_rate": 4.118993135011442e-07,
      "loss": 0.0003,
      "step": 4280
    },
    {
      "epoch": 9.816933638443937,
      "grad_norm": 0.34629181027412415,
      "learning_rate": 3.661327231121282e-07,
      "loss": 0.0085,
      "step": 4290
    },
    {
      "epoch": 9.839816933638444,
      "grad_norm": 1.0979487895965576,
      "learning_rate": 3.203661327231122e-07,
      "loss": 0.006,
      "step": 4300
    },
    {
      "epoch": 9.862700228832953,
      "grad_norm": 0.03979838266968727,
      "learning_rate": 2.745995423340961e-07,
      "loss": 0.0179,
      "step": 4310
    },
    {
      "epoch": 9.88558352402746,
      "grad_norm": 0.14062443375587463,
      "learning_rate": 2.288329519450801e-07,
      "loss": 0.0113,
      "step": 4320
    },
    {
      "epoch": 9.908466819221967,
      "grad_norm": 13.298968315124512,
      "learning_rate": 1.830663615560641e-07,
      "loss": 0.029,
      "step": 4330
    },
    {
      "epoch": 9.931350114416476,
      "grad_norm": 0.5812291502952576,
      "learning_rate": 1.3729977116704806e-07,
      "loss": 0.0037,
      "step": 4340
    },
    {
      "epoch": 9.954233409610984,
      "grad_norm": 17.541810989379883,
      "learning_rate": 9.153318077803205e-08,
      "loss": 0.0044,
      "step": 4350
    },
    {
      "epoch": 9.977116704805493,
      "grad_norm": 0.014040198177099228,
      "learning_rate": 4.5766590389016025e-08,
      "loss": 0.0351,
      "step": 4360
    },
    {
      "epoch": 10.0,
      "grad_norm": 6.660256862640381,
      "learning_rate": 0.0,
      "loss": 0.0214,
      "step": 4370
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9233333333333333,
      "eval_f1": 0.8013816925734025,
      "eval_loss": 0.5500050187110901,
      "eval_precision": 0.8069565217391305,
      "eval_recall": 0.7958833619210978,
      "eval_runtime": 594.4022,
      "eval_samples_per_second": 5.047,
      "eval_steps_per_second": 0.631,
      "step": 4370
    }
  ],
  "logging_steps": 10,
  "max_steps": 4370,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.917375162406464e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
