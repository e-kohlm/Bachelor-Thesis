{
  "best_metric": 0.8857142857142858,
  "best_model_checkpoint": "../saved_models/open_redirect/checkpoint-4370",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4370,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002288329519450801,
      "grad_norm": 57.59197235107422,
      "learning_rate": 1.99954233409611e-05,
      "loss": 0.9357,
      "step": 1
    },
    {
      "epoch": 0.02288329519450801,
      "grad_norm": 27.59092903137207,
      "learning_rate": 1.9954233409610984e-05,
      "loss": 0.5043,
      "step": 10
    },
    {
      "epoch": 0.04576659038901602,
      "grad_norm": 25.380189895629883,
      "learning_rate": 1.990846681922197e-05,
      "loss": 0.5011,
      "step": 20
    },
    {
      "epoch": 0.06864988558352403,
      "grad_norm": 18.594905853271484,
      "learning_rate": 1.9862700228832953e-05,
      "loss": 0.4072,
      "step": 30
    },
    {
      "epoch": 0.09153318077803203,
      "grad_norm": 20.496673583984375,
      "learning_rate": 1.981693363844394e-05,
      "loss": 0.5357,
      "step": 40
    },
    {
      "epoch": 0.11441647597254005,
      "grad_norm": 18.047080993652344,
      "learning_rate": 1.977116704805492e-05,
      "loss": 0.4601,
      "step": 50
    },
    {
      "epoch": 0.13729977116704806,
      "grad_norm": 15.182110786437988,
      "learning_rate": 1.9725400457665907e-05,
      "loss": 0.4646,
      "step": 60
    },
    {
      "epoch": 0.16018306636155608,
      "grad_norm": 21.983766555786133,
      "learning_rate": 1.967963386727689e-05,
      "loss": 0.4428,
      "step": 70
    },
    {
      "epoch": 0.18306636155606407,
      "grad_norm": 22.982988357543945,
      "learning_rate": 1.9633867276887872e-05,
      "loss": 0.3692,
      "step": 80
    },
    {
      "epoch": 0.20594965675057209,
      "grad_norm": 22.111019134521484,
      "learning_rate": 1.9588100686498858e-05,
      "loss": 0.4771,
      "step": 90
    },
    {
      "epoch": 0.2288329519450801,
      "grad_norm": 15.194893836975098,
      "learning_rate": 1.954233409610984e-05,
      "loss": 0.3709,
      "step": 100
    },
    {
      "epoch": 0.2517162471395881,
      "grad_norm": 16.532442092895508,
      "learning_rate": 1.9496567505720823e-05,
      "loss": 0.4035,
      "step": 110
    },
    {
      "epoch": 0.2745995423340961,
      "grad_norm": 24.95999526977539,
      "learning_rate": 1.945080091533181e-05,
      "loss": 0.4473,
      "step": 120
    },
    {
      "epoch": 0.2974828375286041,
      "grad_norm": 16.6716251373291,
      "learning_rate": 1.9405034324942792e-05,
      "loss": 0.427,
      "step": 130
    },
    {
      "epoch": 0.32036613272311215,
      "grad_norm": 11.182916641235352,
      "learning_rate": 1.9359267734553778e-05,
      "loss": 0.3667,
      "step": 140
    },
    {
      "epoch": 0.34324942791762014,
      "grad_norm": 17.12020492553711,
      "learning_rate": 1.931350114416476e-05,
      "loss": 0.3991,
      "step": 150
    },
    {
      "epoch": 0.36613272311212813,
      "grad_norm": 14.123332977294922,
      "learning_rate": 1.9267734553775746e-05,
      "loss": 0.3978,
      "step": 160
    },
    {
      "epoch": 0.3890160183066362,
      "grad_norm": 16.538772583007812,
      "learning_rate": 1.922196796338673e-05,
      "loss": 0.4823,
      "step": 170
    },
    {
      "epoch": 0.41189931350114417,
      "grad_norm": 20.357337951660156,
      "learning_rate": 1.9176201372997715e-05,
      "loss": 0.4581,
      "step": 180
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 11.213679313659668,
      "learning_rate": 1.9130434782608697e-05,
      "loss": 0.4452,
      "step": 190
    },
    {
      "epoch": 0.4576659038901602,
      "grad_norm": 13.777766227722168,
      "learning_rate": 1.9084668192219683e-05,
      "loss": 0.4366,
      "step": 200
    },
    {
      "epoch": 0.4805491990846682,
      "grad_norm": 5.3209638595581055,
      "learning_rate": 1.9038901601830666e-05,
      "loss": 0.3692,
      "step": 210
    },
    {
      "epoch": 0.5034324942791762,
      "grad_norm": 12.047423362731934,
      "learning_rate": 1.8993135011441652e-05,
      "loss": 0.4118,
      "step": 220
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 10.649314880371094,
      "learning_rate": 1.894736842105263e-05,
      "loss": 0.5032,
      "step": 230
    },
    {
      "epoch": 0.5491990846681922,
      "grad_norm": 11.596297264099121,
      "learning_rate": 1.8901601830663617e-05,
      "loss": 0.4088,
      "step": 240
    },
    {
      "epoch": 0.5720823798627003,
      "grad_norm": 10.689451217651367,
      "learning_rate": 1.88558352402746e-05,
      "loss": 0.3597,
      "step": 250
    },
    {
      "epoch": 0.5949656750572082,
      "grad_norm": 10.807947158813477,
      "learning_rate": 1.8810068649885585e-05,
      "loss": 0.3394,
      "step": 260
    },
    {
      "epoch": 0.6178489702517163,
      "grad_norm": 11.976451873779297,
      "learning_rate": 1.8764302059496568e-05,
      "loss": 0.4425,
      "step": 270
    },
    {
      "epoch": 0.6407322654462243,
      "grad_norm": 10.158783912658691,
      "learning_rate": 1.8718535469107554e-05,
      "loss": 0.428,
      "step": 280
    },
    {
      "epoch": 0.6636155606407322,
      "grad_norm": 11.85040283203125,
      "learning_rate": 1.8672768878718537e-05,
      "loss": 0.3547,
      "step": 290
    },
    {
      "epoch": 0.6864988558352403,
      "grad_norm": 4.990052223205566,
      "learning_rate": 1.8627002288329522e-05,
      "loss": 0.3157,
      "step": 300
    },
    {
      "epoch": 0.7093821510297483,
      "grad_norm": 13.755819320678711,
      "learning_rate": 1.8581235697940505e-05,
      "loss": 0.4709,
      "step": 310
    },
    {
      "epoch": 0.7322654462242563,
      "grad_norm": 6.377031326293945,
      "learning_rate": 1.8535469107551488e-05,
      "loss": 0.362,
      "step": 320
    },
    {
      "epoch": 0.7551487414187643,
      "grad_norm": 7.697761058807373,
      "learning_rate": 1.8489702517162474e-05,
      "loss": 0.3581,
      "step": 330
    },
    {
      "epoch": 0.7780320366132724,
      "grad_norm": 12.022067070007324,
      "learning_rate": 1.8443935926773456e-05,
      "loss": 0.3968,
      "step": 340
    },
    {
      "epoch": 0.8009153318077803,
      "grad_norm": 9.273134231567383,
      "learning_rate": 1.8398169336384442e-05,
      "loss": 0.4706,
      "step": 350
    },
    {
      "epoch": 0.8237986270022883,
      "grad_norm": 17.48117446899414,
      "learning_rate": 1.8352402745995425e-05,
      "loss": 0.3992,
      "step": 360
    },
    {
      "epoch": 0.8466819221967964,
      "grad_norm": 7.5574445724487305,
      "learning_rate": 1.830663615560641e-05,
      "loss": 0.34,
      "step": 370
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 13.280340194702148,
      "learning_rate": 1.8260869565217393e-05,
      "loss": 0.3872,
      "step": 380
    },
    {
      "epoch": 0.8924485125858124,
      "grad_norm": 6.71609354019165,
      "learning_rate": 1.8215102974828376e-05,
      "loss": 0.3657,
      "step": 390
    },
    {
      "epoch": 0.9153318077803204,
      "grad_norm": 14.186893463134766,
      "learning_rate": 1.816933638443936e-05,
      "loss": 0.4658,
      "step": 400
    },
    {
      "epoch": 0.9382151029748284,
      "grad_norm": 10.617474555969238,
      "learning_rate": 1.8123569794050344e-05,
      "loss": 0.3832,
      "step": 410
    },
    {
      "epoch": 0.9610983981693364,
      "grad_norm": 15.897076606750488,
      "learning_rate": 1.8077803203661327e-05,
      "loss": 0.3921,
      "step": 420
    },
    {
      "epoch": 0.9839816933638444,
      "grad_norm": 15.074573516845703,
      "learning_rate": 1.8032036613272313e-05,
      "loss": 0.3519,
      "step": 430
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8786666666666667,
      "eval_f1": 0.21551724137931033,
      "eval_loss": 0.3400600850582123,
      "eval_precision": 0.746268656716418,
      "eval_recall": 0.12594458438287154,
      "eval_runtime": 468.1086,
      "eval_samples_per_second": 6.409,
      "eval_steps_per_second": 0.801,
      "step": 437
    },
    {
      "epoch": 1.0068649885583525,
      "grad_norm": 98.36669921875,
      "learning_rate": 1.7986270022883295e-05,
      "loss": 0.3997,
      "step": 440
    },
    {
      "epoch": 1.0297482837528604,
      "grad_norm": 35.93440246582031,
      "learning_rate": 1.794050343249428e-05,
      "loss": 0.2878,
      "step": 450
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 11.088784217834473,
      "learning_rate": 1.7894736842105264e-05,
      "loss": 0.3308,
      "step": 460
    },
    {
      "epoch": 1.0755148741418765,
      "grad_norm": 13.995429039001465,
      "learning_rate": 1.784897025171625e-05,
      "loss": 0.2879,
      "step": 470
    },
    {
      "epoch": 1.0983981693363845,
      "grad_norm": 12.143120765686035,
      "learning_rate": 1.7803203661327232e-05,
      "loss": 0.3031,
      "step": 480
    },
    {
      "epoch": 1.1212814645308924,
      "grad_norm": 18.246826171875,
      "learning_rate": 1.7757437070938218e-05,
      "loss": 0.3063,
      "step": 490
    },
    {
      "epoch": 1.1441647597254005,
      "grad_norm": 8.186283111572266,
      "learning_rate": 1.77116704805492e-05,
      "loss": 0.2839,
      "step": 500
    },
    {
      "epoch": 1.1670480549199085,
      "grad_norm": 10.86886978149414,
      "learning_rate": 1.7665903890160187e-05,
      "loss": 0.3567,
      "step": 510
    },
    {
      "epoch": 1.1899313501144164,
      "grad_norm": 7.455733299255371,
      "learning_rate": 1.762013729977117e-05,
      "loss": 0.3,
      "step": 520
    },
    {
      "epoch": 1.2128146453089246,
      "grad_norm": 6.483842372894287,
      "learning_rate": 1.7574370709382152e-05,
      "loss": 0.3146,
      "step": 530
    },
    {
      "epoch": 1.2356979405034325,
      "grad_norm": 9.55317497253418,
      "learning_rate": 1.7528604118993134e-05,
      "loss": 0.3623,
      "step": 540
    },
    {
      "epoch": 1.2585812356979404,
      "grad_norm": 10.549633979797363,
      "learning_rate": 1.748283752860412e-05,
      "loss": 0.2966,
      "step": 550
    },
    {
      "epoch": 1.2814645308924484,
      "grad_norm": 73.7628173828125,
      "learning_rate": 1.7437070938215103e-05,
      "loss": 0.392,
      "step": 560
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 8.956567764282227,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.3548,
      "step": 570
    },
    {
      "epoch": 1.3272311212814645,
      "grad_norm": 11.729063034057617,
      "learning_rate": 1.734553775743707e-05,
      "loss": 0.2841,
      "step": 580
    },
    {
      "epoch": 1.3501144164759724,
      "grad_norm": 12.523642539978027,
      "learning_rate": 1.7299771167048057e-05,
      "loss": 0.3985,
      "step": 590
    },
    {
      "epoch": 1.3729977116704806,
      "grad_norm": 14.691418647766113,
      "learning_rate": 1.725400457665904e-05,
      "loss": 0.3309,
      "step": 600
    },
    {
      "epoch": 1.3958810068649885,
      "grad_norm": 12.275964736938477,
      "learning_rate": 1.7208237986270026e-05,
      "loss": 0.2469,
      "step": 610
    },
    {
      "epoch": 1.4187643020594964,
      "grad_norm": 7.187310218811035,
      "learning_rate": 1.716247139588101e-05,
      "loss": 0.3394,
      "step": 620
    },
    {
      "epoch": 1.4416475972540046,
      "grad_norm": 6.838919639587402,
      "learning_rate": 1.7116704805491994e-05,
      "loss": 0.2409,
      "step": 630
    },
    {
      "epoch": 1.4645308924485125,
      "grad_norm": 9.302846908569336,
      "learning_rate": 1.7070938215102977e-05,
      "loss": 0.3064,
      "step": 640
    },
    {
      "epoch": 1.4874141876430205,
      "grad_norm": 8.560785293579102,
      "learning_rate": 1.702517162471396e-05,
      "loss": 0.2804,
      "step": 650
    },
    {
      "epoch": 1.5102974828375286,
      "grad_norm": 5.794976711273193,
      "learning_rate": 1.6979405034324945e-05,
      "loss": 0.2651,
      "step": 660
    },
    {
      "epoch": 1.5331807780320366,
      "grad_norm": 9.788829803466797,
      "learning_rate": 1.6933638443935928e-05,
      "loss": 0.3385,
      "step": 670
    },
    {
      "epoch": 1.5560640732265445,
      "grad_norm": 11.239583015441895,
      "learning_rate": 1.688787185354691e-05,
      "loss": 0.329,
      "step": 680
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 8.354844093322754,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.3457,
      "step": 690
    },
    {
      "epoch": 1.6018306636155606,
      "grad_norm": 6.468973636627197,
      "learning_rate": 1.679633867276888e-05,
      "loss": 0.2994,
      "step": 700
    },
    {
      "epoch": 1.6247139588100685,
      "grad_norm": 11.636140823364258,
      "learning_rate": 1.6750572082379865e-05,
      "loss": 0.3739,
      "step": 710
    },
    {
      "epoch": 1.6475972540045767,
      "grad_norm": 6.60694694519043,
      "learning_rate": 1.6704805491990848e-05,
      "loss": 0.29,
      "step": 720
    },
    {
      "epoch": 1.6704805491990846,
      "grad_norm": 10.31166934967041,
      "learning_rate": 1.665903890160183e-05,
      "loss": 0.2958,
      "step": 730
    },
    {
      "epoch": 1.6933638443935926,
      "grad_norm": 6.181920528411865,
      "learning_rate": 1.6613272311212816e-05,
      "loss": 0.1704,
      "step": 740
    },
    {
      "epoch": 1.7162471395881007,
      "grad_norm": 5.998568534851074,
      "learning_rate": 1.65675057208238e-05,
      "loss": 0.2149,
      "step": 750
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 11.105683326721191,
      "learning_rate": 1.6521739130434785e-05,
      "loss": 0.2517,
      "step": 760
    },
    {
      "epoch": 1.7620137299771166,
      "grad_norm": 15.14771556854248,
      "learning_rate": 1.6475972540045767e-05,
      "loss": 0.3116,
      "step": 770
    },
    {
      "epoch": 1.7848970251716247,
      "grad_norm": 9.39438533782959,
      "learning_rate": 1.6430205949656753e-05,
      "loss": 0.2283,
      "step": 780
    },
    {
      "epoch": 1.8077803203661327,
      "grad_norm": 9.335064888000488,
      "learning_rate": 1.6384439359267736e-05,
      "loss": 0.2897,
      "step": 790
    },
    {
      "epoch": 1.8306636155606406,
      "grad_norm": 8.865593910217285,
      "learning_rate": 1.633867276887872e-05,
      "loss": 0.2562,
      "step": 800
    },
    {
      "epoch": 1.8535469107551488,
      "grad_norm": 3.9608426094055176,
      "learning_rate": 1.6292906178489704e-05,
      "loss": 0.2119,
      "step": 810
    },
    {
      "epoch": 1.8764302059496567,
      "grad_norm": 8.71420955657959,
      "learning_rate": 1.624713958810069e-05,
      "loss": 0.1992,
      "step": 820
    },
    {
      "epoch": 1.8993135011441646,
      "grad_norm": 2.3491272926330566,
      "learning_rate": 1.620137299771167e-05,
      "loss": 0.2174,
      "step": 830
    },
    {
      "epoch": 1.9221967963386728,
      "grad_norm": 6.266578197479248,
      "learning_rate": 1.6155606407322655e-05,
      "loss": 0.2544,
      "step": 840
    },
    {
      "epoch": 1.9450800915331807,
      "grad_norm": 11.222816467285156,
      "learning_rate": 1.6109839816933638e-05,
      "loss": 0.2405,
      "step": 850
    },
    {
      "epoch": 1.9679633867276887,
      "grad_norm": 13.724030494689941,
      "learning_rate": 1.6064073226544624e-05,
      "loss": 0.2898,
      "step": 860
    },
    {
      "epoch": 1.9908466819221968,
      "grad_norm": 5.99254846572876,
      "learning_rate": 1.6018306636155606e-05,
      "loss": 0.2441,
      "step": 870
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9213333333333333,
      "eval_f1": 0.6300940438871473,
      "eval_loss": 0.2116529792547226,
      "eval_precision": 0.8340248962655602,
      "eval_recall": 0.5062972292191436,
      "eval_runtime": 462.237,
      "eval_samples_per_second": 6.49,
      "eval_steps_per_second": 0.811,
      "step": 874
    },
    {
      "epoch": 2.013729977116705,
      "grad_norm": 6.893585205078125,
      "learning_rate": 1.5972540045766592e-05,
      "loss": 0.2167,
      "step": 880
    },
    {
      "epoch": 2.0366132723112127,
      "grad_norm": 7.404932022094727,
      "learning_rate": 1.5926773455377575e-05,
      "loss": 0.1903,
      "step": 890
    },
    {
      "epoch": 2.059496567505721,
      "grad_norm": 11.270553588867188,
      "learning_rate": 1.588100686498856e-05,
      "loss": 0.1768,
      "step": 900
    },
    {
      "epoch": 2.082379862700229,
      "grad_norm": 7.713705539703369,
      "learning_rate": 1.5835240274599543e-05,
      "loss": 0.1786,
      "step": 910
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 11.515567779541016,
      "learning_rate": 1.578947368421053e-05,
      "loss": 0.2071,
      "step": 920
    },
    {
      "epoch": 2.128146453089245,
      "grad_norm": 9.190244674682617,
      "learning_rate": 1.5743707093821512e-05,
      "loss": 0.2065,
      "step": 930
    },
    {
      "epoch": 2.151029748283753,
      "grad_norm": 8.169469833374023,
      "learning_rate": 1.5697940503432498e-05,
      "loss": 0.1803,
      "step": 940
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 7.988734722137451,
      "learning_rate": 1.565217391304348e-05,
      "loss": 0.1977,
      "step": 950
    },
    {
      "epoch": 2.196796338672769,
      "grad_norm": 5.547702789306641,
      "learning_rate": 1.5606407322654463e-05,
      "loss": 0.1786,
      "step": 960
    },
    {
      "epoch": 2.219679633867277,
      "grad_norm": 3.0209667682647705,
      "learning_rate": 1.556064073226545e-05,
      "loss": 0.1742,
      "step": 970
    },
    {
      "epoch": 2.242562929061785,
      "grad_norm": 11.952444076538086,
      "learning_rate": 1.551487414187643e-05,
      "loss": 0.1636,
      "step": 980
    },
    {
      "epoch": 2.265446224256293,
      "grad_norm": 7.448755264282227,
      "learning_rate": 1.5469107551487414e-05,
      "loss": 0.214,
      "step": 990
    },
    {
      "epoch": 2.288329519450801,
      "grad_norm": 2.3964343070983887,
      "learning_rate": 1.54233409610984e-05,
      "loss": 0.1312,
      "step": 1000
    },
    {
      "epoch": 2.311212814645309,
      "grad_norm": 8.268579483032227,
      "learning_rate": 1.5377574370709382e-05,
      "loss": 0.1754,
      "step": 1010
    },
    {
      "epoch": 2.334096109839817,
      "grad_norm": 11.000587463378906,
      "learning_rate": 1.533180778032037e-05,
      "loss": 0.1854,
      "step": 1020
    },
    {
      "epoch": 2.356979405034325,
      "grad_norm": 10.713464736938477,
      "learning_rate": 1.528604118993135e-05,
      "loss": 0.2447,
      "step": 1030
    },
    {
      "epoch": 2.379862700228833,
      "grad_norm": 11.304498672485352,
      "learning_rate": 1.5240274599542335e-05,
      "loss": 0.1585,
      "step": 1040
    },
    {
      "epoch": 2.402745995423341,
      "grad_norm": 7.051107406616211,
      "learning_rate": 1.519450800915332e-05,
      "loss": 0.1233,
      "step": 1050
    },
    {
      "epoch": 2.425629290617849,
      "grad_norm": 7.72782039642334,
      "learning_rate": 1.5148741418764304e-05,
      "loss": 0.1608,
      "step": 1060
    },
    {
      "epoch": 2.448512585812357,
      "grad_norm": 11.689065933227539,
      "learning_rate": 1.5102974828375288e-05,
      "loss": 0.1889,
      "step": 1070
    },
    {
      "epoch": 2.471395881006865,
      "grad_norm": 18.63577651977539,
      "learning_rate": 1.5057208237986272e-05,
      "loss": 0.1693,
      "step": 1080
    },
    {
      "epoch": 2.494279176201373,
      "grad_norm": 3.60071063041687,
      "learning_rate": 1.5011441647597256e-05,
      "loss": 0.1385,
      "step": 1090
    },
    {
      "epoch": 2.517162471395881,
      "grad_norm": 11.975761413574219,
      "learning_rate": 1.496567505720824e-05,
      "loss": 0.1948,
      "step": 1100
    },
    {
      "epoch": 2.540045766590389,
      "grad_norm": 8.978821754455566,
      "learning_rate": 1.4919908466819223e-05,
      "loss": 0.1292,
      "step": 1110
    },
    {
      "epoch": 2.5629290617848968,
      "grad_norm": 14.639589309692383,
      "learning_rate": 1.4874141876430207e-05,
      "loss": 0.1853,
      "step": 1120
    },
    {
      "epoch": 2.585812356979405,
      "grad_norm": 5.045446872711182,
      "learning_rate": 1.4828375286041192e-05,
      "loss": 0.1697,
      "step": 1130
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 6.833805561065674,
      "learning_rate": 1.4782608695652174e-05,
      "loss": 0.1709,
      "step": 1140
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 13.816079139709473,
      "learning_rate": 1.4736842105263159e-05,
      "loss": 0.1799,
      "step": 1150
    },
    {
      "epoch": 2.654462242562929,
      "grad_norm": 11.509825706481934,
      "learning_rate": 1.4691075514874143e-05,
      "loss": 0.1774,
      "step": 1160
    },
    {
      "epoch": 2.677345537757437,
      "grad_norm": 3.689460039138794,
      "learning_rate": 1.4645308924485127e-05,
      "loss": 0.1171,
      "step": 1170
    },
    {
      "epoch": 2.700228832951945,
      "grad_norm": 4.583869457244873,
      "learning_rate": 1.4599542334096111e-05,
      "loss": 0.1449,
      "step": 1180
    },
    {
      "epoch": 2.723112128146453,
      "grad_norm": 8.638625144958496,
      "learning_rate": 1.4553775743707096e-05,
      "loss": 0.1082,
      "step": 1190
    },
    {
      "epoch": 2.745995423340961,
      "grad_norm": 7.292347431182861,
      "learning_rate": 1.4508009153318078e-05,
      "loss": 0.2255,
      "step": 1200
    },
    {
      "epoch": 2.7688787185354693,
      "grad_norm": 6.7521257400512695,
      "learning_rate": 1.4462242562929062e-05,
      "loss": 0.1375,
      "step": 1210
    },
    {
      "epoch": 2.791762013729977,
      "grad_norm": 12.207625389099121,
      "learning_rate": 1.4416475972540047e-05,
      "loss": 0.163,
      "step": 1220
    },
    {
      "epoch": 2.814645308924485,
      "grad_norm": 11.794021606445312,
      "learning_rate": 1.4370709382151031e-05,
      "loss": 0.1309,
      "step": 1230
    },
    {
      "epoch": 2.837528604118993,
      "grad_norm": 10.732002258300781,
      "learning_rate": 1.4324942791762015e-05,
      "loss": 0.1507,
      "step": 1240
    },
    {
      "epoch": 2.860411899313501,
      "grad_norm": 1.8947182893753052,
      "learning_rate": 1.4279176201373e-05,
      "loss": 0.1351,
      "step": 1250
    },
    {
      "epoch": 2.883295194508009,
      "grad_norm": 14.447771072387695,
      "learning_rate": 1.4233409610983984e-05,
      "loss": 0.1383,
      "step": 1260
    },
    {
      "epoch": 2.9061784897025174,
      "grad_norm": 13.82927417755127,
      "learning_rate": 1.4187643020594968e-05,
      "loss": 0.1716,
      "step": 1270
    },
    {
      "epoch": 2.929061784897025,
      "grad_norm": 10.222026824951172,
      "learning_rate": 1.4141876430205952e-05,
      "loss": 0.1683,
      "step": 1280
    },
    {
      "epoch": 2.9519450800915332,
      "grad_norm": 9.60585880279541,
      "learning_rate": 1.4096109839816933e-05,
      "loss": 0.2005,
      "step": 1290
    },
    {
      "epoch": 2.974828375286041,
      "grad_norm": 5.650913715362549,
      "learning_rate": 1.4050343249427917e-05,
      "loss": 0.1922,
      "step": 1300
    },
    {
      "epoch": 2.997711670480549,
      "grad_norm": 4.892266750335693,
      "learning_rate": 1.4004576659038902e-05,
      "loss": 0.1936,
      "step": 1310
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9523333333333334,
      "eval_f1": 0.8054421768707483,
      "eval_loss": 0.13924747705459595,
      "eval_precision": 0.8757396449704142,
      "eval_recall": 0.7455919395465995,
      "eval_runtime": 460.3884,
      "eval_samples_per_second": 6.516,
      "eval_steps_per_second": 0.815,
      "step": 1311
    },
    {
      "epoch": 3.0205949656750573,
      "grad_norm": 3.0491602420806885,
      "learning_rate": 1.3958810068649886e-05,
      "loss": 0.0944,
      "step": 1320
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 8.433229446411133,
      "learning_rate": 1.391304347826087e-05,
      "loss": 0.0834,
      "step": 1330
    },
    {
      "epoch": 3.066361556064073,
      "grad_norm": 9.297148704528809,
      "learning_rate": 1.3867276887871854e-05,
      "loss": 0.0799,
      "step": 1340
    },
    {
      "epoch": 3.0892448512585813,
      "grad_norm": 2.819823980331421,
      "learning_rate": 1.3821510297482839e-05,
      "loss": 0.0966,
      "step": 1350
    },
    {
      "epoch": 3.1121281464530894,
      "grad_norm": 15.658863067626953,
      "learning_rate": 1.3775743707093823e-05,
      "loss": 0.1178,
      "step": 1360
    },
    {
      "epoch": 3.135011441647597,
      "grad_norm": 5.479966640472412,
      "learning_rate": 1.3729977116704807e-05,
      "loss": 0.1226,
      "step": 1370
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 8.952964782714844,
      "learning_rate": 1.3684210526315791e-05,
      "loss": 0.1473,
      "step": 1380
    },
    {
      "epoch": 3.1807780320366135,
      "grad_norm": 6.047740459442139,
      "learning_rate": 1.3638443935926776e-05,
      "loss": 0.2009,
      "step": 1390
    },
    {
      "epoch": 3.203661327231121,
      "grad_norm": 2.804523229598999,
      "learning_rate": 1.359267734553776e-05,
      "loss": 0.1132,
      "step": 1400
    },
    {
      "epoch": 3.2265446224256293,
      "grad_norm": 0.2667667865753174,
      "learning_rate": 1.3546910755148744e-05,
      "loss": 0.0997,
      "step": 1410
    },
    {
      "epoch": 3.2494279176201375,
      "grad_norm": 0.86891770362854,
      "learning_rate": 1.3501144164759727e-05,
      "loss": 0.1116,
      "step": 1420
    },
    {
      "epoch": 3.272311212814645,
      "grad_norm": 4.575049877166748,
      "learning_rate": 1.3455377574370711e-05,
      "loss": 0.0989,
      "step": 1430
    },
    {
      "epoch": 3.2951945080091534,
      "grad_norm": 8.821588516235352,
      "learning_rate": 1.3409610983981693e-05,
      "loss": 0.1294,
      "step": 1440
    },
    {
      "epoch": 3.3180778032036615,
      "grad_norm": 4.529551029205322,
      "learning_rate": 1.3363844393592678e-05,
      "loss": 0.1472,
      "step": 1450
    },
    {
      "epoch": 3.3409610983981692,
      "grad_norm": 17.633342742919922,
      "learning_rate": 1.3318077803203662e-05,
      "loss": 0.0661,
      "step": 1460
    },
    {
      "epoch": 3.3638443935926774,
      "grad_norm": 5.515124797821045,
      "learning_rate": 1.3272311212814646e-05,
      "loss": 0.131,
      "step": 1470
    },
    {
      "epoch": 3.386727688787185,
      "grad_norm": 2.4359962940216064,
      "learning_rate": 1.322654462242563e-05,
      "loss": 0.1155,
      "step": 1480
    },
    {
      "epoch": 3.4096109839816933,
      "grad_norm": 0.545121967792511,
      "learning_rate": 1.3180778032036615e-05,
      "loss": 0.0779,
      "step": 1490
    },
    {
      "epoch": 3.4324942791762014,
      "grad_norm": 14.433094024658203,
      "learning_rate": 1.3135011441647599e-05,
      "loss": 0.0891,
      "step": 1500
    },
    {
      "epoch": 3.4553775743707096,
      "grad_norm": 9.767110824584961,
      "learning_rate": 1.3089244851258582e-05,
      "loss": 0.0974,
      "step": 1510
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 9.739363670349121,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.1097,
      "step": 1520
    },
    {
      "epoch": 3.5011441647597255,
      "grad_norm": 7.434014797210693,
      "learning_rate": 1.299771167048055e-05,
      "loss": 0.0737,
      "step": 1530
    },
    {
      "epoch": 3.524027459954233,
      "grad_norm": 14.297178268432617,
      "learning_rate": 1.2951945080091534e-05,
      "loss": 0.1061,
      "step": 1540
    },
    {
      "epoch": 3.5469107551487413,
      "grad_norm": 6.912107944488525,
      "learning_rate": 1.2906178489702519e-05,
      "loss": 0.08,
      "step": 1550
    },
    {
      "epoch": 3.5697940503432495,
      "grad_norm": 6.384998798370361,
      "learning_rate": 1.2860411899313503e-05,
      "loss": 0.1004,
      "step": 1560
    },
    {
      "epoch": 3.5926773455377576,
      "grad_norm": 5.0051774978637695,
      "learning_rate": 1.2814645308924487e-05,
      "loss": 0.0664,
      "step": 1570
    },
    {
      "epoch": 3.6155606407322654,
      "grad_norm": 8.564663887023926,
      "learning_rate": 1.2768878718535471e-05,
      "loss": 0.0931,
      "step": 1580
    },
    {
      "epoch": 3.6384439359267735,
      "grad_norm": 13.217878341674805,
      "learning_rate": 1.2723112128146454e-05,
      "loss": 0.0924,
      "step": 1590
    },
    {
      "epoch": 3.6613272311212812,
      "grad_norm": 2.709810733795166,
      "learning_rate": 1.2677345537757438e-05,
      "loss": 0.0822,
      "step": 1600
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 6.308758735656738,
      "learning_rate": 1.263157894736842e-05,
      "loss": 0.0945,
      "step": 1610
    },
    {
      "epoch": 3.7070938215102975,
      "grad_norm": 0.8225557208061218,
      "learning_rate": 1.2585812356979405e-05,
      "loss": 0.0948,
      "step": 1620
    },
    {
      "epoch": 3.7299771167048057,
      "grad_norm": 1.448577642440796,
      "learning_rate": 1.254004576659039e-05,
      "loss": 0.0935,
      "step": 1630
    },
    {
      "epoch": 3.7528604118993134,
      "grad_norm": 8.632292747497559,
      "learning_rate": 1.2494279176201373e-05,
      "loss": 0.0666,
      "step": 1640
    },
    {
      "epoch": 3.7757437070938216,
      "grad_norm": 9.550970077514648,
      "learning_rate": 1.2448512585812358e-05,
      "loss": 0.0869,
      "step": 1650
    },
    {
      "epoch": 3.7986270022883293,
      "grad_norm": 3.7688755989074707,
      "learning_rate": 1.2402745995423342e-05,
      "loss": 0.1133,
      "step": 1660
    },
    {
      "epoch": 3.8215102974828374,
      "grad_norm": 1.7490772008895874,
      "learning_rate": 1.2356979405034326e-05,
      "loss": 0.0597,
      "step": 1670
    },
    {
      "epoch": 3.8443935926773456,
      "grad_norm": 4.932440280914307,
      "learning_rate": 1.231121281464531e-05,
      "loss": 0.1548,
      "step": 1680
    },
    {
      "epoch": 3.8672768878718538,
      "grad_norm": 3.5510685443878174,
      "learning_rate": 1.2265446224256295e-05,
      "loss": 0.072,
      "step": 1690
    },
    {
      "epoch": 3.8901601830663615,
      "grad_norm": 9.94247055053711,
      "learning_rate": 1.2219679633867279e-05,
      "loss": 0.1361,
      "step": 1700
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 1.6546918153762817,
      "learning_rate": 1.2173913043478263e-05,
      "loss": 0.1067,
      "step": 1710
    },
    {
      "epoch": 3.9359267734553773,
      "grad_norm": 20.843505859375,
      "learning_rate": 1.2128146453089247e-05,
      "loss": 0.1598,
      "step": 1720
    },
    {
      "epoch": 3.9588100686498855,
      "grad_norm": 2.02848744392395,
      "learning_rate": 1.2082379862700232e-05,
      "loss": 0.1059,
      "step": 1730
    },
    {
      "epoch": 3.9816933638443937,
      "grad_norm": 5.621677875518799,
      "learning_rate": 1.2036613272311213e-05,
      "loss": 0.058,
      "step": 1740
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9556666666666667,
      "eval_f1": 0.8339575530586767,
      "eval_loss": 0.14352606236934662,
      "eval_precision": 0.8267326732673267,
      "eval_recall": 0.8413098236775819,
      "eval_runtime": 478.6708,
      "eval_samples_per_second": 6.267,
      "eval_steps_per_second": 0.783,
      "step": 1748
    },
    {
      "epoch": 4.004576659038902,
      "grad_norm": 7.22905969619751,
      "learning_rate": 1.1990846681922197e-05,
      "loss": 0.1121,
      "step": 1750
    },
    {
      "epoch": 4.02745995423341,
      "grad_norm": 6.441571235656738,
      "learning_rate": 1.1945080091533181e-05,
      "loss": 0.065,
      "step": 1760
    },
    {
      "epoch": 4.050343249427917,
      "grad_norm": 5.3932929039001465,
      "learning_rate": 1.1899313501144165e-05,
      "loss": 0.0711,
      "step": 1770
    },
    {
      "epoch": 4.073226544622425,
      "grad_norm": 4.546255111694336,
      "learning_rate": 1.185354691075515e-05,
      "loss": 0.0512,
      "step": 1780
    },
    {
      "epoch": 4.0961098398169336,
      "grad_norm": 5.934439659118652,
      "learning_rate": 1.1807780320366134e-05,
      "loss": 0.0505,
      "step": 1790
    },
    {
      "epoch": 4.118993135011442,
      "grad_norm": 11.505936622619629,
      "learning_rate": 1.1762013729977118e-05,
      "loss": 0.0527,
      "step": 1800
    },
    {
      "epoch": 4.14187643020595,
      "grad_norm": 15.102737426757812,
      "learning_rate": 1.1716247139588102e-05,
      "loss": 0.0648,
      "step": 1810
    },
    {
      "epoch": 4.164759725400458,
      "grad_norm": 6.558681488037109,
      "learning_rate": 1.1670480549199087e-05,
      "loss": 0.0601,
      "step": 1820
    },
    {
      "epoch": 4.187643020594965,
      "grad_norm": 0.2561704218387604,
      "learning_rate": 1.1624713958810069e-05,
      "loss": 0.0179,
      "step": 1830
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 0.37545838952064514,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.0356,
      "step": 1840
    },
    {
      "epoch": 4.233409610983982,
      "grad_norm": 2.4655346870422363,
      "learning_rate": 1.1533180778032038e-05,
      "loss": 0.0295,
      "step": 1850
    },
    {
      "epoch": 4.25629290617849,
      "grad_norm": 11.605141639709473,
      "learning_rate": 1.1487414187643022e-05,
      "loss": 0.0982,
      "step": 1860
    },
    {
      "epoch": 4.279176201372998,
      "grad_norm": 24.2401180267334,
      "learning_rate": 1.1441647597254006e-05,
      "loss": 0.0639,
      "step": 1870
    },
    {
      "epoch": 4.302059496567506,
      "grad_norm": 9.676973342895508,
      "learning_rate": 1.139588100686499e-05,
      "loss": 0.0929,
      "step": 1880
    },
    {
      "epoch": 4.324942791762013,
      "grad_norm": 3.660417079925537,
      "learning_rate": 1.1350114416475973e-05,
      "loss": 0.0489,
      "step": 1890
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 1.058323621749878,
      "learning_rate": 1.1304347826086957e-05,
      "loss": 0.0943,
      "step": 1900
    },
    {
      "epoch": 4.37070938215103,
      "grad_norm": 0.1514211744070053,
      "learning_rate": 1.1258581235697941e-05,
      "loss": 0.0673,
      "step": 1910
    },
    {
      "epoch": 4.393592677345538,
      "grad_norm": 12.049468994140625,
      "learning_rate": 1.1212814645308924e-05,
      "loss": 0.0764,
      "step": 1920
    },
    {
      "epoch": 4.416475972540046,
      "grad_norm": 14.531816482543945,
      "learning_rate": 1.1167048054919908e-05,
      "loss": 0.0669,
      "step": 1930
    },
    {
      "epoch": 4.439359267734554,
      "grad_norm": 2.3027753829956055,
      "learning_rate": 1.1121281464530893e-05,
      "loss": 0.0638,
      "step": 1940
    },
    {
      "epoch": 4.462242562929061,
      "grad_norm": 4.929769992828369,
      "learning_rate": 1.1075514874141877e-05,
      "loss": 0.0943,
      "step": 1950
    },
    {
      "epoch": 4.48512585812357,
      "grad_norm": 0.9353731274604797,
      "learning_rate": 1.1029748283752861e-05,
      "loss": 0.0877,
      "step": 1960
    },
    {
      "epoch": 4.508009153318078,
      "grad_norm": 0.49040237069129944,
      "learning_rate": 1.0983981693363845e-05,
      "loss": 0.0415,
      "step": 1970
    },
    {
      "epoch": 4.530892448512586,
      "grad_norm": 16.79096794128418,
      "learning_rate": 1.093821510297483e-05,
      "loss": 0.0362,
      "step": 1980
    },
    {
      "epoch": 4.553775743707094,
      "grad_norm": 0.11483103781938553,
      "learning_rate": 1.0892448512585814e-05,
      "loss": 0.147,
      "step": 1990
    },
    {
      "epoch": 4.576659038901602,
      "grad_norm": 6.4078145027160645,
      "learning_rate": 1.0846681922196798e-05,
      "loss": 0.0584,
      "step": 2000
    },
    {
      "epoch": 4.5995423340961095,
      "grad_norm": 5.200875282287598,
      "learning_rate": 1.0800915331807782e-05,
      "loss": 0.0972,
      "step": 2010
    },
    {
      "epoch": 4.622425629290618,
      "grad_norm": 3.4072964191436768,
      "learning_rate": 1.0755148741418767e-05,
      "loss": 0.06,
      "step": 2020
    },
    {
      "epoch": 4.645308924485126,
      "grad_norm": 7.492972373962402,
      "learning_rate": 1.070938215102975e-05,
      "loss": 0.0616,
      "step": 2030
    },
    {
      "epoch": 4.668192219679634,
      "grad_norm": 7.802633285522461,
      "learning_rate": 1.0663615560640732e-05,
      "loss": 0.0716,
      "step": 2040
    },
    {
      "epoch": 4.691075514874142,
      "grad_norm": 5.392646789550781,
      "learning_rate": 1.0617848970251716e-05,
      "loss": 0.0289,
      "step": 2050
    },
    {
      "epoch": 4.71395881006865,
      "grad_norm": 0.6836872100830078,
      "learning_rate": 1.05720823798627e-05,
      "loss": 0.0549,
      "step": 2060
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 1.1234973669052124,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.1041,
      "step": 2070
    },
    {
      "epoch": 4.759725400457666,
      "grad_norm": 6.77147912979126,
      "learning_rate": 1.0480549199084669e-05,
      "loss": 0.0574,
      "step": 2080
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 0.5360842347145081,
      "learning_rate": 1.0434782608695653e-05,
      "loss": 0.0221,
      "step": 2090
    },
    {
      "epoch": 4.805491990846682,
      "grad_norm": 7.104959964752197,
      "learning_rate": 1.0389016018306637e-05,
      "loss": 0.0478,
      "step": 2100
    },
    {
      "epoch": 4.82837528604119,
      "grad_norm": 0.2960122227668762,
      "learning_rate": 1.0343249427917621e-05,
      "loss": 0.0551,
      "step": 2110
    },
    {
      "epoch": 4.851258581235698,
      "grad_norm": 12.957817077636719,
      "learning_rate": 1.0297482837528606e-05,
      "loss": 0.128,
      "step": 2120
    },
    {
      "epoch": 4.874141876430206,
      "grad_norm": 0.3734408915042877,
      "learning_rate": 1.025171624713959e-05,
      "loss": 0.082,
      "step": 2130
    },
    {
      "epoch": 4.897025171624714,
      "grad_norm": 12.445669174194336,
      "learning_rate": 1.0205949656750573e-05,
      "loss": 0.0748,
      "step": 2140
    },
    {
      "epoch": 4.919908466819222,
      "grad_norm": 10.45583724975586,
      "learning_rate": 1.0160183066361557e-05,
      "loss": 0.0742,
      "step": 2150
    },
    {
      "epoch": 4.94279176201373,
      "grad_norm": 6.676595687866211,
      "learning_rate": 1.0114416475972541e-05,
      "loss": 0.0661,
      "step": 2160
    },
    {
      "epoch": 4.965675057208238,
      "grad_norm": 9.05308723449707,
      "learning_rate": 1.0068649885583525e-05,
      "loss": 0.0606,
      "step": 2170
    },
    {
      "epoch": 4.988558352402746,
      "grad_norm": 6.29246187210083,
      "learning_rate": 1.002288329519451e-05,
      "loss": 0.0317,
      "step": 2180
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9646666666666667,
      "eval_f1": 0.8575268817204301,
      "eval_loss": 0.16416646540164948,
      "eval_precision": 0.9193083573487032,
      "eval_recall": 0.8035264483627204,
      "eval_runtime": 575.7382,
      "eval_samples_per_second": 5.211,
      "eval_steps_per_second": 0.651,
      "step": 2185
    },
    {
      "epoch": 5.011441647597254,
      "grad_norm": 10.635743141174316,
      "learning_rate": 9.977116704805492e-06,
      "loss": 0.0408,
      "step": 2190
    },
    {
      "epoch": 5.034324942791762,
      "grad_norm": 0.48500293493270874,
      "learning_rate": 9.931350114416476e-06,
      "loss": 0.0324,
      "step": 2200
    },
    {
      "epoch": 5.05720823798627,
      "grad_norm": 0.041479431092739105,
      "learning_rate": 9.88558352402746e-06,
      "loss": 0.043,
      "step": 2210
    },
    {
      "epoch": 5.080091533180778,
      "grad_norm": 9.839924812316895,
      "learning_rate": 9.839816933638445e-06,
      "loss": 0.0696,
      "step": 2220
    },
    {
      "epoch": 5.102974828375286,
      "grad_norm": 10.08930492401123,
      "learning_rate": 9.794050343249429e-06,
      "loss": 0.0444,
      "step": 2230
    },
    {
      "epoch": 5.125858123569794,
      "grad_norm": 3.8697636127471924,
      "learning_rate": 9.748283752860412e-06,
      "loss": 0.0364,
      "step": 2240
    },
    {
      "epoch": 5.148741418764302,
      "grad_norm": 0.2557069957256317,
      "learning_rate": 9.702517162471396e-06,
      "loss": 0.0259,
      "step": 2250
    },
    {
      "epoch": 5.17162471395881,
      "grad_norm": 0.2693733274936676,
      "learning_rate": 9.65675057208238e-06,
      "loss": 0.1088,
      "step": 2260
    },
    {
      "epoch": 5.194508009153318,
      "grad_norm": 11.675621032714844,
      "learning_rate": 9.610983981693364e-06,
      "loss": 0.022,
      "step": 2270
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 2.665640354156494,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.0169,
      "step": 2280
    },
    {
      "epoch": 5.240274599542334,
      "grad_norm": 24.49306297302246,
      "learning_rate": 9.519450800915333e-06,
      "loss": 0.0761,
      "step": 2290
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.12630239129066467,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.0555,
      "step": 2300
    },
    {
      "epoch": 5.28604118993135,
      "grad_norm": 6.44063663482666,
      "learning_rate": 9.4279176201373e-06,
      "loss": 0.0553,
      "step": 2310
    },
    {
      "epoch": 5.308924485125858,
      "grad_norm": 5.900711536407471,
      "learning_rate": 9.382151029748284e-06,
      "loss": 0.0754,
      "step": 2320
    },
    {
      "epoch": 5.331807780320366,
      "grad_norm": 4.994762897491455,
      "learning_rate": 9.336384439359268e-06,
      "loss": 0.0667,
      "step": 2330
    },
    {
      "epoch": 5.354691075514874,
      "grad_norm": 7.411646842956543,
      "learning_rate": 9.290617848970253e-06,
      "loss": 0.0219,
      "step": 2340
    },
    {
      "epoch": 5.377574370709382,
      "grad_norm": 0.2829843759536743,
      "learning_rate": 9.244851258581237e-06,
      "loss": 0.0056,
      "step": 2350
    },
    {
      "epoch": 5.4004576659038905,
      "grad_norm": 0.04407018795609474,
      "learning_rate": 9.199084668192221e-06,
      "loss": 0.0093,
      "step": 2360
    },
    {
      "epoch": 5.423340961098398,
      "grad_norm": 7.059818267822266,
      "learning_rate": 9.153318077803205e-06,
      "loss": 0.0479,
      "step": 2370
    },
    {
      "epoch": 5.446224256292906,
      "grad_norm": 8.705843925476074,
      "learning_rate": 9.107551487414188e-06,
      "loss": 0.0494,
      "step": 2380
    },
    {
      "epoch": 5.469107551487414,
      "grad_norm": 0.3170817792415619,
      "learning_rate": 9.061784897025172e-06,
      "loss": 0.0133,
      "step": 2390
    },
    {
      "epoch": 5.491990846681922,
      "grad_norm": 10.064664840698242,
      "learning_rate": 9.016018306636156e-06,
      "loss": 0.0767,
      "step": 2400
    },
    {
      "epoch": 5.51487414187643,
      "grad_norm": 3.4310991764068604,
      "learning_rate": 8.97025171624714e-06,
      "loss": 0.0467,
      "step": 2410
    },
    {
      "epoch": 5.537757437070939,
      "grad_norm": 20.74376106262207,
      "learning_rate": 8.924485125858125e-06,
      "loss": 0.0523,
      "step": 2420
    },
    {
      "epoch": 5.560640732265446,
      "grad_norm": 0.9085853099822998,
      "learning_rate": 8.878718535469109e-06,
      "loss": 0.0326,
      "step": 2430
    },
    {
      "epoch": 5.583524027459954,
      "grad_norm": 0.03611317649483681,
      "learning_rate": 8.832951945080093e-06,
      "loss": 0.0278,
      "step": 2440
    },
    {
      "epoch": 5.606407322654462,
      "grad_norm": 1.0317251682281494,
      "learning_rate": 8.787185354691076e-06,
      "loss": 0.0743,
      "step": 2450
    },
    {
      "epoch": 5.62929061784897,
      "grad_norm": 7.150415897369385,
      "learning_rate": 8.74141876430206e-06,
      "loss": 0.0866,
      "step": 2460
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 0.008903071284294128,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0237,
      "step": 2470
    },
    {
      "epoch": 5.675057208237987,
      "grad_norm": 7.384971618652344,
      "learning_rate": 8.649885583524029e-06,
      "loss": 0.0358,
      "step": 2480
    },
    {
      "epoch": 5.697940503432494,
      "grad_norm": 0.2343873828649521,
      "learning_rate": 8.604118993135013e-06,
      "loss": 0.0413,
      "step": 2490
    },
    {
      "epoch": 5.720823798627002,
      "grad_norm": 0.3149837851524353,
      "learning_rate": 8.558352402745997e-06,
      "loss": 0.054,
      "step": 2500
    },
    {
      "epoch": 5.74370709382151,
      "grad_norm": 9.537972450256348,
      "learning_rate": 8.51258581235698e-06,
      "loss": 0.0427,
      "step": 2510
    },
    {
      "epoch": 5.766590389016018,
      "grad_norm": 0.05460438132286072,
      "learning_rate": 8.466819221967964e-06,
      "loss": 0.0096,
      "step": 2520
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 6.510940074920654,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.0571,
      "step": 2530
    },
    {
      "epoch": 5.812356979405035,
      "grad_norm": 0.10173846036195755,
      "learning_rate": 8.375286041189932e-06,
      "loss": 0.0393,
      "step": 2540
    },
    {
      "epoch": 5.835240274599542,
      "grad_norm": 0.17281410098075867,
      "learning_rate": 8.329519450800915e-06,
      "loss": 0.0601,
      "step": 2550
    },
    {
      "epoch": 5.85812356979405,
      "grad_norm": 0.145091712474823,
      "learning_rate": 8.2837528604119e-06,
      "loss": 0.041,
      "step": 2560
    },
    {
      "epoch": 5.881006864988558,
      "grad_norm": 8.417047500610352,
      "learning_rate": 8.237986270022884e-06,
      "loss": 0.0358,
      "step": 2570
    },
    {
      "epoch": 5.9038901601830664,
      "grad_norm": 0.09743780642747879,
      "learning_rate": 8.192219679633868e-06,
      "loss": 0.0193,
      "step": 2580
    },
    {
      "epoch": 5.926773455377575,
      "grad_norm": 0.10446708649396896,
      "learning_rate": 8.146453089244852e-06,
      "loss": 0.0422,
      "step": 2590
    },
    {
      "epoch": 5.949656750572083,
      "grad_norm": 10.289162635803223,
      "learning_rate": 8.100686498855835e-06,
      "loss": 0.0612,
      "step": 2600
    },
    {
      "epoch": 5.97254004576659,
      "grad_norm": 34.91473388671875,
      "learning_rate": 8.054919908466819e-06,
      "loss": 0.0662,
      "step": 2610
    },
    {
      "epoch": 5.995423340961098,
      "grad_norm": 1.2255009412765503,
      "learning_rate": 8.009153318077803e-06,
      "loss": 0.0607,
      "step": 2620
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.966,
      "eval_f1": 0.8708860759493671,
      "eval_loss": 0.16230061650276184,
      "eval_precision": 0.8753180661577609,
      "eval_recall": 0.8664987405541562,
      "eval_runtime": 546.4492,
      "eval_samples_per_second": 5.49,
      "eval_steps_per_second": 0.686,
      "step": 2622
    },
    {
      "epoch": 6.018306636155606,
      "grad_norm": 0.060162127017974854,
      "learning_rate": 7.963386727688787e-06,
      "loss": 0.0038,
      "step": 2630
    },
    {
      "epoch": 6.0411899313501145,
      "grad_norm": 2.1060163974761963,
      "learning_rate": 7.917620137299772e-06,
      "loss": 0.0568,
      "step": 2640
    },
    {
      "epoch": 6.064073226544623,
      "grad_norm": 1.1607215404510498,
      "learning_rate": 7.871853546910756e-06,
      "loss": 0.0933,
      "step": 2650
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 0.8252773284912109,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.0498,
      "step": 2660
    },
    {
      "epoch": 6.109839816933638,
      "grad_norm": 10.836668968200684,
      "learning_rate": 7.780320366132724e-06,
      "loss": 0.0311,
      "step": 2670
    },
    {
      "epoch": 6.132723112128146,
      "grad_norm": 12.182276725769043,
      "learning_rate": 7.734553775743707e-06,
      "loss": 0.0402,
      "step": 2680
    },
    {
      "epoch": 6.155606407322654,
      "grad_norm": 0.056602757424116135,
      "learning_rate": 7.688787185354691e-06,
      "loss": 0.0076,
      "step": 2690
    },
    {
      "epoch": 6.178489702517163,
      "grad_norm": 0.8673331141471863,
      "learning_rate": 7.643020594965675e-06,
      "loss": 0.0473,
      "step": 2700
    },
    {
      "epoch": 6.201372997711671,
      "grad_norm": 0.03748008608818054,
      "learning_rate": 7.59725400457666e-06,
      "loss": 0.0328,
      "step": 2710
    },
    {
      "epoch": 6.224256292906179,
      "grad_norm": 14.931931495666504,
      "learning_rate": 7.551487414187644e-06,
      "loss": 0.0574,
      "step": 2720
    },
    {
      "epoch": 6.247139588100686,
      "grad_norm": 0.08381200581789017,
      "learning_rate": 7.505720823798628e-06,
      "loss": 0.0012,
      "step": 2730
    },
    {
      "epoch": 6.270022883295194,
      "grad_norm": 0.32530149817466736,
      "learning_rate": 7.459954233409612e-06,
      "loss": 0.0186,
      "step": 2740
    },
    {
      "epoch": 6.2929061784897025,
      "grad_norm": 12.565858840942383,
      "learning_rate": 7.414187643020596e-06,
      "loss": 0.0353,
      "step": 2750
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 0.07073075324296951,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0458,
      "step": 2760
    },
    {
      "epoch": 6.338672768878719,
      "grad_norm": 13.529909133911133,
      "learning_rate": 7.3226544622425635e-06,
      "loss": 0.0341,
      "step": 2770
    },
    {
      "epoch": 6.361556064073227,
      "grad_norm": 3.794384002685547,
      "learning_rate": 7.276887871853548e-06,
      "loss": 0.0328,
      "step": 2780
    },
    {
      "epoch": 6.384439359267734,
      "grad_norm": 1.542524814605713,
      "learning_rate": 7.231121281464531e-06,
      "loss": 0.0024,
      "step": 2790
    },
    {
      "epoch": 6.407322654462242,
      "grad_norm": 0.011028626002371311,
      "learning_rate": 7.1853546910755154e-06,
      "loss": 0.0225,
      "step": 2800
    },
    {
      "epoch": 6.4302059496567505,
      "grad_norm": 0.14774642884731293,
      "learning_rate": 7.1395881006865e-06,
      "loss": 0.0129,
      "step": 2810
    },
    {
      "epoch": 6.453089244851259,
      "grad_norm": 7.411795616149902,
      "learning_rate": 7.093821510297484e-06,
      "loss": 0.0097,
      "step": 2820
    },
    {
      "epoch": 6.475972540045767,
      "grad_norm": 0.21816569566726685,
      "learning_rate": 7.0480549199084665e-06,
      "loss": 0.0095,
      "step": 2830
    },
    {
      "epoch": 6.498855835240275,
      "grad_norm": 0.02028038166463375,
      "learning_rate": 7.002288329519451e-06,
      "loss": 0.0207,
      "step": 2840
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.8687199354171753,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.0276,
      "step": 2850
    },
    {
      "epoch": 6.54462242562929,
      "grad_norm": 3.301619291305542,
      "learning_rate": 6.910755148741419e-06,
      "loss": 0.0562,
      "step": 2860
    },
    {
      "epoch": 6.567505720823799,
      "grad_norm": 0.11760559678077698,
      "learning_rate": 6.8649885583524035e-06,
      "loss": 0.0236,
      "step": 2870
    },
    {
      "epoch": 6.590389016018307,
      "grad_norm": 0.11179647594690323,
      "learning_rate": 6.819221967963388e-06,
      "loss": 0.0461,
      "step": 2880
    },
    {
      "epoch": 6.613272311212815,
      "grad_norm": 0.11174280196428299,
      "learning_rate": 6.773455377574372e-06,
      "loss": 0.0292,
      "step": 2890
    },
    {
      "epoch": 6.636155606407323,
      "grad_norm": 0.023554936051368713,
      "learning_rate": 6.7276887871853554e-06,
      "loss": 0.0347,
      "step": 2900
    },
    {
      "epoch": 6.65903890160183,
      "grad_norm": 0.4932841658592224,
      "learning_rate": 6.681922196796339e-06,
      "loss": 0.038,
      "step": 2910
    },
    {
      "epoch": 6.6819221967963385,
      "grad_norm": 0.5269229412078857,
      "learning_rate": 6.636155606407323e-06,
      "loss": 0.0248,
      "step": 2920
    },
    {
      "epoch": 6.704805491990847,
      "grad_norm": 0.13220275938510895,
      "learning_rate": 6.590389016018307e-06,
      "loss": 0.0435,
      "step": 2930
    },
    {
      "epoch": 6.727688787185355,
      "grad_norm": 0.21694928407669067,
      "learning_rate": 6.544622425629291e-06,
      "loss": 0.0098,
      "step": 2940
    },
    {
      "epoch": 6.750572082379863,
      "grad_norm": 0.05791013687849045,
      "learning_rate": 6.498855835240275e-06,
      "loss": 0.0521,
      "step": 2950
    },
    {
      "epoch": 6.77345537757437,
      "grad_norm": 0.9571483731269836,
      "learning_rate": 6.453089244851259e-06,
      "loss": 0.0215,
      "step": 2960
    },
    {
      "epoch": 6.796338672768878,
      "grad_norm": 10.118001937866211,
      "learning_rate": 6.4073226544622435e-06,
      "loss": 0.0316,
      "step": 2970
    },
    {
      "epoch": 6.8192219679633865,
      "grad_norm": 0.9291603565216064,
      "learning_rate": 6.361556064073227e-06,
      "loss": 0.0052,
      "step": 2980
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 14.681618690490723,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.0428,
      "step": 2990
    },
    {
      "epoch": 6.864988558352403,
      "grad_norm": 0.4849949777126312,
      "learning_rate": 6.270022883295195e-06,
      "loss": 0.0337,
      "step": 3000
    },
    {
      "epoch": 6.887871853546911,
      "grad_norm": 11.549595832824707,
      "learning_rate": 6.224256292906179e-06,
      "loss": 0.0703,
      "step": 3010
    },
    {
      "epoch": 6.910755148741419,
      "grad_norm": 12.826394081115723,
      "learning_rate": 6.178489702517163e-06,
      "loss": 0.0334,
      "step": 3020
    },
    {
      "epoch": 6.933638443935926,
      "grad_norm": 0.004613113589584827,
      "learning_rate": 6.132723112128147e-06,
      "loss": 0.0661,
      "step": 3030
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 0.25039273500442505,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.0146,
      "step": 3040
    },
    {
      "epoch": 6.979405034324943,
      "grad_norm": 0.2570621967315674,
      "learning_rate": 6.041189931350116e-06,
      "loss": 0.0194,
      "step": 3050
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.965,
      "eval_f1": 0.8563611491108072,
      "eval_loss": 0.2138974964618683,
      "eval_precision": 0.937125748502994,
      "eval_recall": 0.7884130982367759,
      "eval_runtime": 545.9659,
      "eval_samples_per_second": 5.495,
      "eval_steps_per_second": 0.687,
      "step": 3059
    },
    {
      "epoch": 7.002288329519451,
      "grad_norm": 7.238432884216309,
      "learning_rate": 5.995423340961098e-06,
      "loss": 0.0594,
      "step": 3060
    },
    {
      "epoch": 7.025171624713959,
      "grad_norm": 3.068840265274048,
      "learning_rate": 5.949656750572083e-06,
      "loss": 0.0556,
      "step": 3070
    },
    {
      "epoch": 7.048054919908467,
      "grad_norm": 8.114304542541504,
      "learning_rate": 5.903890160183067e-06,
      "loss": 0.0272,
      "step": 3080
    },
    {
      "epoch": 7.0709382151029745,
      "grad_norm": 0.07553733140230179,
      "learning_rate": 5.858123569794051e-06,
      "loss": 0.017,
      "step": 3090
    },
    {
      "epoch": 7.093821510297483,
      "grad_norm": 0.022408828139305115,
      "learning_rate": 5.8123569794050346e-06,
      "loss": 0.0042,
      "step": 3100
    },
    {
      "epoch": 7.116704805491991,
      "grad_norm": 0.013315440155565739,
      "learning_rate": 5.766590389016019e-06,
      "loss": 0.0299,
      "step": 3110
    },
    {
      "epoch": 7.139588100686499,
      "grad_norm": 0.004757114686071873,
      "learning_rate": 5.720823798627003e-06,
      "loss": 0.0344,
      "step": 3120
    },
    {
      "epoch": 7.162471395881007,
      "grad_norm": 0.019458958879113197,
      "learning_rate": 5.6750572082379865e-06,
      "loss": 0.0007,
      "step": 3130
    },
    {
      "epoch": 7.185354691075515,
      "grad_norm": 0.11883372068405151,
      "learning_rate": 5.629290617848971e-06,
      "loss": 0.0158,
      "step": 3140
    },
    {
      "epoch": 7.2082379862700225,
      "grad_norm": 0.24036026000976562,
      "learning_rate": 5.583524027459954e-06,
      "loss": 0.0184,
      "step": 3150
    },
    {
      "epoch": 7.231121281464531,
      "grad_norm": 1.5503742694854736,
      "learning_rate": 5.537757437070938e-06,
      "loss": 0.0035,
      "step": 3160
    },
    {
      "epoch": 7.254004576659039,
      "grad_norm": 6.622085094451904,
      "learning_rate": 5.491990846681923e-06,
      "loss": 0.0119,
      "step": 3170
    },
    {
      "epoch": 7.276887871853547,
      "grad_norm": 0.007348258513957262,
      "learning_rate": 5.446224256292907e-06,
      "loss": 0.0442,
      "step": 3180
    },
    {
      "epoch": 7.299771167048055,
      "grad_norm": 0.18013304471969604,
      "learning_rate": 5.400457665903891e-06,
      "loss": 0.0154,
      "step": 3190
    },
    {
      "epoch": 7.322654462242563,
      "grad_norm": 0.09960419684648514,
      "learning_rate": 5.354691075514875e-06,
      "loss": 0.0191,
      "step": 3200
    },
    {
      "epoch": 7.345537757437071,
      "grad_norm": 0.8709280490875244,
      "learning_rate": 5.308924485125858e-06,
      "loss": 0.0481,
      "step": 3210
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 0.006443559657782316,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.0185,
      "step": 3220
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 0.29041963815689087,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.033,
      "step": 3230
    },
    {
      "epoch": 7.414187643020595,
      "grad_norm": 0.021399827674031258,
      "learning_rate": 5.171624713958811e-06,
      "loss": 0.0143,
      "step": 3240
    },
    {
      "epoch": 7.437070938215103,
      "grad_norm": 0.039391860365867615,
      "learning_rate": 5.125858123569795e-06,
      "loss": 0.0072,
      "step": 3250
    },
    {
      "epoch": 7.459954233409611,
      "grad_norm": 1.2141598463058472,
      "learning_rate": 5.080091533180778e-06,
      "loss": 0.0026,
      "step": 3260
    },
    {
      "epoch": 7.482837528604119,
      "grad_norm": 0.05855058878660202,
      "learning_rate": 5.034324942791763e-06,
      "loss": 0.0015,
      "step": 3270
    },
    {
      "epoch": 7.505720823798627,
      "grad_norm": 0.012374931015074253,
      "learning_rate": 4.988558352402746e-06,
      "loss": 0.006,
      "step": 3280
    },
    {
      "epoch": 7.528604118993135,
      "grad_norm": 8.679635047912598,
      "learning_rate": 4.94279176201373e-06,
      "loss": 0.014,
      "step": 3290
    },
    {
      "epoch": 7.551487414187643,
      "grad_norm": 0.4399523437023163,
      "learning_rate": 4.8970251716247146e-06,
      "loss": 0.0117,
      "step": 3300
    },
    {
      "epoch": 7.574370709382151,
      "grad_norm": 0.23860757052898407,
      "learning_rate": 4.851258581235698e-06,
      "loss": 0.0043,
      "step": 3310
    },
    {
      "epoch": 7.597254004576659,
      "grad_norm": 32.91789245605469,
      "learning_rate": 4.805491990846682e-06,
      "loss": 0.0414,
      "step": 3320
    },
    {
      "epoch": 7.620137299771167,
      "grad_norm": 0.4771735966205597,
      "learning_rate": 4.7597254004576665e-06,
      "loss": 0.0255,
      "step": 3330
    },
    {
      "epoch": 7.643020594965675,
      "grad_norm": 18.136205673217773,
      "learning_rate": 4.71395881006865e-06,
      "loss": 0.0138,
      "step": 3340
    },
    {
      "epoch": 7.665903890160183,
      "grad_norm": 0.05220850184559822,
      "learning_rate": 4.668192219679634e-06,
      "loss": 0.0412,
      "step": 3350
    },
    {
      "epoch": 7.688787185354691,
      "grad_norm": 0.12009035795927048,
      "learning_rate": 4.622425629290618e-06,
      "loss": 0.0241,
      "step": 3360
    },
    {
      "epoch": 7.711670480549199,
      "grad_norm": 0.6423066854476929,
      "learning_rate": 4.576659038901603e-06,
      "loss": 0.0062,
      "step": 3370
    },
    {
      "epoch": 7.7345537757437075,
      "grad_norm": 0.022894497960805893,
      "learning_rate": 4.530892448512586e-06,
      "loss": 0.0244,
      "step": 3380
    },
    {
      "epoch": 7.757437070938215,
      "grad_norm": 0.00490235909819603,
      "learning_rate": 4.48512585812357e-06,
      "loss": 0.0583,
      "step": 3390
    },
    {
      "epoch": 7.780320366132723,
      "grad_norm": 3.0324416160583496,
      "learning_rate": 4.4393592677345545e-06,
      "loss": 0.0252,
      "step": 3400
    },
    {
      "epoch": 7.803203661327231,
      "grad_norm": 0.2718809247016907,
      "learning_rate": 4.393592677345538e-06,
      "loss": 0.0009,
      "step": 3410
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 1.3577073812484741,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0085,
      "step": 3420
    },
    {
      "epoch": 7.848970251716247,
      "grad_norm": 0.1774081289768219,
      "learning_rate": 4.3020594965675065e-06,
      "loss": 0.0435,
      "step": 3430
    },
    {
      "epoch": 7.871853546910755,
      "grad_norm": 2.67170786857605,
      "learning_rate": 4.25629290617849e-06,
      "loss": 0.03,
      "step": 3440
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 0.183578759431839,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.0175,
      "step": 3450
    },
    {
      "epoch": 7.917620137299771,
      "grad_norm": 0.021349290385842323,
      "learning_rate": 4.1647597254004575e-06,
      "loss": 0.0021,
      "step": 3460
    },
    {
      "epoch": 7.940503432494279,
      "grad_norm": 0.28220227360725403,
      "learning_rate": 4.118993135011442e-06,
      "loss": 0.0316,
      "step": 3470
    },
    {
      "epoch": 7.963386727688787,
      "grad_norm": 0.1938706338405609,
      "learning_rate": 4.073226544622426e-06,
      "loss": 0.0116,
      "step": 3480
    },
    {
      "epoch": 7.9862700228832955,
      "grad_norm": 7.286409854888916,
      "learning_rate": 4.0274599542334094e-06,
      "loss": 0.0269,
      "step": 3490
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.97,
      "eval_f1": 0.8809523809523809,
      "eval_loss": 0.18975968658924103,
      "eval_precision": 0.9275766016713092,
      "eval_recall": 0.8387909319899244,
      "eval_runtime": 562.3167,
      "eval_samples_per_second": 5.335,
      "eval_steps_per_second": 0.667,
      "step": 3496
    },
    {
      "epoch": 8.009153318077804,
      "grad_norm": 0.0017703425837680697,
      "learning_rate": 3.981693363844394e-06,
      "loss": 0.0102,
      "step": 3500
    },
    {
      "epoch": 8.03203661327231,
      "grad_norm": 2.9234578609466553,
      "learning_rate": 3.935926773455378e-06,
      "loss": 0.0022,
      "step": 3510
    },
    {
      "epoch": 8.05491990846682,
      "grad_norm": 0.3668723404407501,
      "learning_rate": 3.890160183066362e-06,
      "loss": 0.03,
      "step": 3520
    },
    {
      "epoch": 8.077803203661327,
      "grad_norm": 1.5671952962875366,
      "learning_rate": 3.844393592677346e-06,
      "loss": 0.006,
      "step": 3530
    },
    {
      "epoch": 8.100686498855834,
      "grad_norm": 0.009156364016234875,
      "learning_rate": 3.79862700228833e-06,
      "loss": 0.0021,
      "step": 3540
    },
    {
      "epoch": 8.123569794050344,
      "grad_norm": 0.05055953562259674,
      "learning_rate": 3.752860411899314e-06,
      "loss": 0.0011,
      "step": 3550
    },
    {
      "epoch": 8.14645308924485,
      "grad_norm": 0.6061505079269409,
      "learning_rate": 3.707093821510298e-06,
      "loss": 0.0009,
      "step": 3560
    },
    {
      "epoch": 8.16933638443936,
      "grad_norm": 13.127095222473145,
      "learning_rate": 3.6613272311212818e-06,
      "loss": 0.0322,
      "step": 3570
    },
    {
      "epoch": 8.192219679633867,
      "grad_norm": 0.4167901277542114,
      "learning_rate": 3.6155606407322656e-06,
      "loss": 0.0376,
      "step": 3580
    },
    {
      "epoch": 8.215102974828376,
      "grad_norm": 0.1620403677225113,
      "learning_rate": 3.56979405034325e-06,
      "loss": 0.0003,
      "step": 3590
    },
    {
      "epoch": 8.237986270022883,
      "grad_norm": 5.126620769500732,
      "learning_rate": 3.5240274599542333e-06,
      "loss": 0.038,
      "step": 3600
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 0.24558931589126587,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.0067,
      "step": 3610
    },
    {
      "epoch": 8.2837528604119,
      "grad_norm": 0.6572337746620178,
      "learning_rate": 3.4324942791762018e-06,
      "loss": 0.001,
      "step": 3620
    },
    {
      "epoch": 8.306636155606407,
      "grad_norm": 0.01866549253463745,
      "learning_rate": 3.386727688787186e-06,
      "loss": 0.0156,
      "step": 3630
    },
    {
      "epoch": 8.329519450800916,
      "grad_norm": 0.03413698449730873,
      "learning_rate": 3.3409610983981694e-06,
      "loss": 0.0158,
      "step": 3640
    },
    {
      "epoch": 8.352402745995423,
      "grad_norm": 0.9102832078933716,
      "learning_rate": 3.2951945080091537e-06,
      "loss": 0.0016,
      "step": 3650
    },
    {
      "epoch": 8.37528604118993,
      "grad_norm": 0.11623106151819229,
      "learning_rate": 3.2494279176201375e-06,
      "loss": 0.0092,
      "step": 3660
    },
    {
      "epoch": 8.39816933638444,
      "grad_norm": 0.003198101185262203,
      "learning_rate": 3.2036613272311218e-06,
      "loss": 0.0214,
      "step": 3670
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 1.040195107460022,
      "learning_rate": 3.157894736842105e-06,
      "loss": 0.0249,
      "step": 3680
    },
    {
      "epoch": 8.443935926773456,
      "grad_norm": 0.571595311164856,
      "learning_rate": 3.1121281464530894e-06,
      "loss": 0.0304,
      "step": 3690
    },
    {
      "epoch": 8.466819221967963,
      "grad_norm": 0.008751792833209038,
      "learning_rate": 3.0663615560640737e-06,
      "loss": 0.0284,
      "step": 3700
    },
    {
      "epoch": 8.48970251716247,
      "grad_norm": 0.08471120893955231,
      "learning_rate": 3.020594965675058e-06,
      "loss": 0.0002,
      "step": 3710
    },
    {
      "epoch": 8.51258581235698,
      "grad_norm": 0.1301276981830597,
      "learning_rate": 2.9748283752860413e-06,
      "loss": 0.0155,
      "step": 3720
    },
    {
      "epoch": 8.535469107551487,
      "grad_norm": 0.18844446539878845,
      "learning_rate": 2.9290617848970256e-06,
      "loss": 0.0079,
      "step": 3730
    },
    {
      "epoch": 8.558352402745996,
      "grad_norm": 0.27909380197525024,
      "learning_rate": 2.8832951945080094e-06,
      "loss": 0.0069,
      "step": 3740
    },
    {
      "epoch": 8.581235697940503,
      "grad_norm": 9.294859886169434,
      "learning_rate": 2.8375286041189932e-06,
      "loss": 0.02,
      "step": 3750
    },
    {
      "epoch": 8.604118993135012,
      "grad_norm": 1.8544813394546509,
      "learning_rate": 2.791762013729977e-06,
      "loss": 0.0013,
      "step": 3760
    },
    {
      "epoch": 8.62700228832952,
      "grad_norm": 5.921808242797852,
      "learning_rate": 2.7459954233409613e-06,
      "loss": 0.0225,
      "step": 3770
    },
    {
      "epoch": 8.649885583524027,
      "grad_norm": 10.798995018005371,
      "learning_rate": 2.7002288329519456e-06,
      "loss": 0.0223,
      "step": 3780
    },
    {
      "epoch": 8.672768878718536,
      "grad_norm": 0.5709384679794312,
      "learning_rate": 2.654462242562929e-06,
      "loss": 0.0215,
      "step": 3790
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.0029790184926241636,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 0.0002,
      "step": 3800
    },
    {
      "epoch": 8.718535469107552,
      "grad_norm": 5.754162788391113,
      "learning_rate": 2.5629290617848975e-06,
      "loss": 0.0154,
      "step": 3810
    },
    {
      "epoch": 8.74141876430206,
      "grad_norm": 0.018172508105635643,
      "learning_rate": 2.5171624713958813e-06,
      "loss": 0.0225,
      "step": 3820
    },
    {
      "epoch": 8.764302059496568,
      "grad_norm": 0.8540471196174622,
      "learning_rate": 2.471395881006865e-06,
      "loss": 0.0066,
      "step": 3830
    },
    {
      "epoch": 8.787185354691076,
      "grad_norm": 0.016429707407951355,
      "learning_rate": 2.425629290617849e-06,
      "loss": 0.0039,
      "step": 3840
    },
    {
      "epoch": 8.810068649885583,
      "grad_norm": 17.505279541015625,
      "learning_rate": 2.3798627002288332e-06,
      "loss": 0.0319,
      "step": 3850
    },
    {
      "epoch": 8.832951945080092,
      "grad_norm": 0.04714920371770859,
      "learning_rate": 2.334096109839817e-06,
      "loss": 0.0329,
      "step": 3860
    },
    {
      "epoch": 8.8558352402746,
      "grad_norm": 0.022170236334204674,
      "learning_rate": 2.2883295194508013e-06,
      "loss": 0.0003,
      "step": 3870
    },
    {
      "epoch": 8.878718535469108,
      "grad_norm": 0.005065326113253832,
      "learning_rate": 2.242562929061785e-06,
      "loss": 0.0018,
      "step": 3880
    },
    {
      "epoch": 8.901601830663616,
      "grad_norm": 0.01200474239885807,
      "learning_rate": 2.196796338672769e-06,
      "loss": 0.0132,
      "step": 3890
    },
    {
      "epoch": 8.924485125858123,
      "grad_norm": 19.25109100341797,
      "learning_rate": 2.1510297482837532e-06,
      "loss": 0.0109,
      "step": 3900
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 5.6339240074157715,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.0367,
      "step": 3910
    },
    {
      "epoch": 8.97025171624714,
      "grad_norm": 2.0625827312469482,
      "learning_rate": 2.059496567505721e-06,
      "loss": 0.019,
      "step": 3920
    },
    {
      "epoch": 8.993135011441648,
      "grad_norm": 0.267924427986145,
      "learning_rate": 2.0137299771167047e-06,
      "loss": 0.0027,
      "step": 3930
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.971,
      "eval_f1": 0.8853754940711462,
      "eval_loss": 0.19263610243797302,
      "eval_precision": 0.9281767955801105,
      "eval_recall": 0.8463476070528967,
      "eval_runtime": 582.5562,
      "eval_samples_per_second": 5.15,
      "eval_steps_per_second": 0.644,
      "step": 3933
    },
    {
      "epoch": 9.016018306636155,
      "grad_norm": 0.010127007961273193,
      "learning_rate": 1.967963386727689e-06,
      "loss": 0.0145,
      "step": 3940
    },
    {
      "epoch": 9.038901601830664,
      "grad_norm": 0.709644079208374,
      "learning_rate": 1.922196796338673e-06,
      "loss": 0.0202,
      "step": 3950
    },
    {
      "epoch": 9.061784897025172,
      "grad_norm": 0.012129596434533596,
      "learning_rate": 1.876430205949657e-06,
      "loss": 0.0003,
      "step": 3960
    },
    {
      "epoch": 9.084668192219679,
      "grad_norm": 0.0016444232314825058,
      "learning_rate": 1.8306636155606409e-06,
      "loss": 0.0041,
      "step": 3970
    },
    {
      "epoch": 9.107551487414188,
      "grad_norm": 0.0034309211187064648,
      "learning_rate": 1.784897025171625e-06,
      "loss": 0.0162,
      "step": 3980
    },
    {
      "epoch": 9.130434782608695,
      "grad_norm": 0.002391803776845336,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 0.0039,
      "step": 3990
    },
    {
      "epoch": 9.153318077803204,
      "grad_norm": 0.001722742454148829,
      "learning_rate": 1.693363844393593e-06,
      "loss": 0.0006,
      "step": 4000
    },
    {
      "epoch": 9.176201372997712,
      "grad_norm": 0.20370453596115112,
      "learning_rate": 1.6475972540045768e-06,
      "loss": 0.0117,
      "step": 4010
    },
    {
      "epoch": 9.199084668192219,
      "grad_norm": 0.028319818899035454,
      "learning_rate": 1.6018306636155609e-06,
      "loss": 0.0085,
      "step": 4020
    },
    {
      "epoch": 9.221967963386728,
      "grad_norm": 0.07465381175279617,
      "learning_rate": 1.5560640732265447e-06,
      "loss": 0.0149,
      "step": 4030
    },
    {
      "epoch": 9.244851258581235,
      "grad_norm": 7.682955741882324,
      "learning_rate": 1.510297482837529e-06,
      "loss": 0.0081,
      "step": 4040
    },
    {
      "epoch": 9.267734553775744,
      "grad_norm": 0.01652855984866619,
      "learning_rate": 1.4645308924485128e-06,
      "loss": 0.0009,
      "step": 4050
    },
    {
      "epoch": 9.290617848970252,
      "grad_norm": 0.1847953349351883,
      "learning_rate": 1.4187643020594966e-06,
      "loss": 0.0067,
      "step": 4060
    },
    {
      "epoch": 9.31350114416476,
      "grad_norm": 0.0010478479089215398,
      "learning_rate": 1.3729977116704807e-06,
      "loss": 0.0002,
      "step": 4070
    },
    {
      "epoch": 9.336384439359268,
      "grad_norm": 0.6654871106147766,
      "learning_rate": 1.3272311212814645e-06,
      "loss": 0.0091,
      "step": 4080
    },
    {
      "epoch": 9.359267734553775,
      "grad_norm": 0.2864517867565155,
      "learning_rate": 1.2814645308924487e-06,
      "loss": 0.0181,
      "step": 4090
    },
    {
      "epoch": 9.382151029748284,
      "grad_norm": 0.000957255600951612,
      "learning_rate": 1.2356979405034326e-06,
      "loss": 0.0184,
      "step": 4100
    },
    {
      "epoch": 9.405034324942791,
      "grad_norm": 0.09518062323331833,
      "learning_rate": 1.1899313501144166e-06,
      "loss": 0.0002,
      "step": 4110
    },
    {
      "epoch": 9.4279176201373,
      "grad_norm": 0.8827207684516907,
      "learning_rate": 1.1441647597254007e-06,
      "loss": 0.0029,
      "step": 4120
    },
    {
      "epoch": 9.450800915331808,
      "grad_norm": 0.020507609471678734,
      "learning_rate": 1.0983981693363845e-06,
      "loss": 0.0407,
      "step": 4130
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 0.0074789077043533325,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.0101,
      "step": 4140
    },
    {
      "epoch": 9.496567505720824,
      "grad_norm": 0.6239632964134216,
      "learning_rate": 1.0068649885583524e-06,
      "loss": 0.0092,
      "step": 4150
    },
    {
      "epoch": 9.519450800915331,
      "grad_norm": 0.11452124267816544,
      "learning_rate": 9.610983981693364e-07,
      "loss": 0.003,
      "step": 4160
    },
    {
      "epoch": 9.54233409610984,
      "grad_norm": 0.004360174760222435,
      "learning_rate": 9.153318077803204e-07,
      "loss": 0.0132,
      "step": 4170
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 0.001240271725691855,
      "learning_rate": 8.695652173913044e-07,
      "loss": 0.0079,
      "step": 4180
    },
    {
      "epoch": 9.588100686498855,
      "grad_norm": 0.07399056851863861,
      "learning_rate": 8.237986270022884e-07,
      "loss": 0.0075,
      "step": 4190
    },
    {
      "epoch": 9.610983981693364,
      "grad_norm": 0.03481783717870712,
      "learning_rate": 7.780320366132724e-07,
      "loss": 0.0003,
      "step": 4200
    },
    {
      "epoch": 9.633867276887871,
      "grad_norm": 0.019388429820537567,
      "learning_rate": 7.322654462242564e-07,
      "loss": 0.0193,
      "step": 4210
    },
    {
      "epoch": 9.65675057208238,
      "grad_norm": 0.10768256336450577,
      "learning_rate": 6.864988558352403e-07,
      "loss": 0.0172,
      "step": 4220
    },
    {
      "epoch": 9.679633867276888,
      "grad_norm": 0.005731785204261541,
      "learning_rate": 6.407322654462244e-07,
      "loss": 0.0096,
      "step": 4230
    },
    {
      "epoch": 9.702517162471397,
      "grad_norm": 0.08383563160896301,
      "learning_rate": 5.949656750572083e-07,
      "loss": 0.0145,
      "step": 4240
    },
    {
      "epoch": 9.725400457665904,
      "grad_norm": 0.33656907081604004,
      "learning_rate": 5.491990846681922e-07,
      "loss": 0.004,
      "step": 4250
    },
    {
      "epoch": 9.748283752860411,
      "grad_norm": 0.0640578493475914,
      "learning_rate": 5.034324942791762e-07,
      "loss": 0.0105,
      "step": 4260
    },
    {
      "epoch": 9.77116704805492,
      "grad_norm": 2.2285478115081787,
      "learning_rate": 4.576659038901602e-07,
      "loss": 0.0113,
      "step": 4270
    },
    {
      "epoch": 9.794050343249427,
      "grad_norm": 0.42670193314552307,
      "learning_rate": 4.118993135011442e-07,
      "loss": 0.0071,
      "step": 4280
    },
    {
      "epoch": 9.816933638443937,
      "grad_norm": 0.10248726606369019,
      "learning_rate": 3.661327231121282e-07,
      "loss": 0.0018,
      "step": 4290
    },
    {
      "epoch": 9.839816933638444,
      "grad_norm": 0.01970536634325981,
      "learning_rate": 3.203661327231122e-07,
      "loss": 0.0061,
      "step": 4300
    },
    {
      "epoch": 9.862700228832953,
      "grad_norm": 0.06843116134405136,
      "learning_rate": 2.745995423340961e-07,
      "loss": 0.0046,
      "step": 4310
    },
    {
      "epoch": 9.88558352402746,
      "grad_norm": 0.0749133825302124,
      "learning_rate": 2.288329519450801e-07,
      "loss": 0.0011,
      "step": 4320
    },
    {
      "epoch": 9.908466819221967,
      "grad_norm": 0.004135420545935631,
      "learning_rate": 1.830663615560641e-07,
      "loss": 0.0023,
      "step": 4330
    },
    {
      "epoch": 9.931350114416476,
      "grad_norm": 0.12531888484954834,
      "learning_rate": 1.3729977116704806e-07,
      "loss": 0.0489,
      "step": 4340
    },
    {
      "epoch": 9.954233409610984,
      "grad_norm": 1.523356318473816,
      "learning_rate": 9.153318077803205e-08,
      "loss": 0.0045,
      "step": 4350
    },
    {
      "epoch": 9.977116704805493,
      "grad_norm": 0.012707815505564213,
      "learning_rate": 4.5766590389016025e-08,
      "loss": 0.0023,
      "step": 4360
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0060986424796283245,
      "learning_rate": 0.0,
      "loss": 0.0147,
      "step": 4370
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9706666666666667,
      "eval_f1": 0.8857142857142858,
      "eval_loss": 0.19167675077915192,
      "eval_precision": 0.9142091152815014,
      "eval_recall": 0.8589420654911839,
      "eval_runtime": 589.1186,
      "eval_samples_per_second": 5.092,
      "eval_steps_per_second": 0.637,
      "step": 4370
    }
  ],
  "logging_steps": 10,
  "max_steps": 4370,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.512551310463936e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
