{
  "best_metric": 0.8632872503840247,
  "best_model_checkpoint": "../saved_models/path_disclosure/checkpoint-4370",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4370,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002288329519450801,
      "grad_norm": 42.33000946044922,
      "learning_rate": 1.99954233409611e-05,
      "loss": 0.823,
      "step": 1
    },
    {
      "epoch": 0.02288329519450801,
      "grad_norm": 17.894445419311523,
      "learning_rate": 1.9954233409610984e-05,
      "loss": 0.484,
      "step": 10
    },
    {
      "epoch": 0.04576659038901602,
      "grad_norm": 17.343101501464844,
      "learning_rate": 1.990846681922197e-05,
      "loss": 0.4118,
      "step": 20
    },
    {
      "epoch": 0.06864988558352403,
      "grad_norm": 13.777907371520996,
      "learning_rate": 1.9862700228832953e-05,
      "loss": 0.3771,
      "step": 30
    },
    {
      "epoch": 0.09153318077803203,
      "grad_norm": 18.513004302978516,
      "learning_rate": 1.981693363844394e-05,
      "loss": 0.4175,
      "step": 40
    },
    {
      "epoch": 0.11441647597254005,
      "grad_norm": 9.526275634765625,
      "learning_rate": 1.977116704805492e-05,
      "loss": 0.3663,
      "step": 50
    },
    {
      "epoch": 0.13729977116704806,
      "grad_norm": 20.276182174682617,
      "learning_rate": 1.9725400457665907e-05,
      "loss": 0.3875,
      "step": 60
    },
    {
      "epoch": 0.16018306636155608,
      "grad_norm": 18.704072952270508,
      "learning_rate": 1.967963386727689e-05,
      "loss": 0.4607,
      "step": 70
    },
    {
      "epoch": 0.18306636155606407,
      "grad_norm": 27.96556854248047,
      "learning_rate": 1.9633867276887872e-05,
      "loss": 0.4348,
      "step": 80
    },
    {
      "epoch": 0.20594965675057209,
      "grad_norm": 15.924971580505371,
      "learning_rate": 1.9588100686498858e-05,
      "loss": 0.438,
      "step": 90
    },
    {
      "epoch": 0.2288329519450801,
      "grad_norm": 18.831884384155273,
      "learning_rate": 1.954233409610984e-05,
      "loss": 0.4064,
      "step": 100
    },
    {
      "epoch": 0.2517162471395881,
      "grad_norm": 18.889835357666016,
      "learning_rate": 1.9496567505720823e-05,
      "loss": 0.456,
      "step": 110
    },
    {
      "epoch": 0.2745995423340961,
      "grad_norm": 18.231334686279297,
      "learning_rate": 1.945080091533181e-05,
      "loss": 0.4022,
      "step": 120
    },
    {
      "epoch": 0.2974828375286041,
      "grad_norm": 21.409412384033203,
      "learning_rate": 1.9405034324942792e-05,
      "loss": 0.3878,
      "step": 130
    },
    {
      "epoch": 0.32036613272311215,
      "grad_norm": 7.9072370529174805,
      "learning_rate": 1.9359267734553778e-05,
      "loss": 0.3243,
      "step": 140
    },
    {
      "epoch": 0.34324942791762014,
      "grad_norm": 7.3965959548950195,
      "learning_rate": 1.931350114416476e-05,
      "loss": 0.4375,
      "step": 150
    },
    {
      "epoch": 0.36613272311212813,
      "grad_norm": 10.776726722717285,
      "learning_rate": 1.9267734553775746e-05,
      "loss": 0.344,
      "step": 160
    },
    {
      "epoch": 0.3890160183066362,
      "grad_norm": 10.10959529876709,
      "learning_rate": 1.922196796338673e-05,
      "loss": 0.3391,
      "step": 170
    },
    {
      "epoch": 0.41189931350114417,
      "grad_norm": 32.894989013671875,
      "learning_rate": 1.9176201372997715e-05,
      "loss": 0.3907,
      "step": 180
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 9.845932960510254,
      "learning_rate": 1.9130434782608697e-05,
      "loss": 0.3797,
      "step": 190
    },
    {
      "epoch": 0.4576659038901602,
      "grad_norm": 7.139847278594971,
      "learning_rate": 1.9084668192219683e-05,
      "loss": 0.3768,
      "step": 200
    },
    {
      "epoch": 0.4805491990846682,
      "grad_norm": 8.9733304977417,
      "learning_rate": 1.9038901601830666e-05,
      "loss": 0.392,
      "step": 210
    },
    {
      "epoch": 0.5034324942791762,
      "grad_norm": 12.815791130065918,
      "learning_rate": 1.8993135011441652e-05,
      "loss": 0.4106,
      "step": 220
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 5.853370189666748,
      "learning_rate": 1.894736842105263e-05,
      "loss": 0.3116,
      "step": 230
    },
    {
      "epoch": 0.5491990846681922,
      "grad_norm": 10.880159378051758,
      "learning_rate": 1.8901601830663617e-05,
      "loss": 0.4063,
      "step": 240
    },
    {
      "epoch": 0.5720823798627003,
      "grad_norm": 11.118636131286621,
      "learning_rate": 1.88558352402746e-05,
      "loss": 0.2937,
      "step": 250
    },
    {
      "epoch": 0.5949656750572082,
      "grad_norm": 11.114405632019043,
      "learning_rate": 1.8810068649885585e-05,
      "loss": 0.3102,
      "step": 260
    },
    {
      "epoch": 0.6178489702517163,
      "grad_norm": 21.920949935913086,
      "learning_rate": 1.8764302059496568e-05,
      "loss": 0.3992,
      "step": 270
    },
    {
      "epoch": 0.6407322654462243,
      "grad_norm": 17.283737182617188,
      "learning_rate": 1.8718535469107554e-05,
      "loss": 0.4296,
      "step": 280
    },
    {
      "epoch": 0.6636155606407322,
      "grad_norm": 13.780353546142578,
      "learning_rate": 1.8672768878718537e-05,
      "loss": 0.3107,
      "step": 290
    },
    {
      "epoch": 0.6864988558352403,
      "grad_norm": 9.41326904296875,
      "learning_rate": 1.8627002288329522e-05,
      "loss": 0.3686,
      "step": 300
    },
    {
      "epoch": 0.7093821510297483,
      "grad_norm": 10.186697959899902,
      "learning_rate": 1.8581235697940505e-05,
      "loss": 0.3338,
      "step": 310
    },
    {
      "epoch": 0.7322654462242563,
      "grad_norm": 10.232808113098145,
      "learning_rate": 1.8535469107551488e-05,
      "loss": 0.2835,
      "step": 320
    },
    {
      "epoch": 0.7551487414187643,
      "grad_norm": 11.334440231323242,
      "learning_rate": 1.8489702517162474e-05,
      "loss": 0.326,
      "step": 330
    },
    {
      "epoch": 0.7780320366132724,
      "grad_norm": 13.015743255615234,
      "learning_rate": 1.8443935926773456e-05,
      "loss": 0.2594,
      "step": 340
    },
    {
      "epoch": 0.8009153318077803,
      "grad_norm": 14.34302043914795,
      "learning_rate": 1.8398169336384442e-05,
      "loss": 0.2931,
      "step": 350
    },
    {
      "epoch": 0.8237986270022883,
      "grad_norm": 8.54873275756836,
      "learning_rate": 1.8352402745995425e-05,
      "loss": 0.2846,
      "step": 360
    },
    {
      "epoch": 0.8466819221967964,
      "grad_norm": 8.18936538696289,
      "learning_rate": 1.830663615560641e-05,
      "loss": 0.3435,
      "step": 370
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 9.150389671325684,
      "learning_rate": 1.8260869565217393e-05,
      "loss": 0.3278,
      "step": 380
    },
    {
      "epoch": 0.8924485125858124,
      "grad_norm": 6.539839267730713,
      "learning_rate": 1.8215102974828376e-05,
      "loss": 0.2992,
      "step": 390
    },
    {
      "epoch": 0.9153318077803204,
      "grad_norm": 5.926939010620117,
      "learning_rate": 1.816933638443936e-05,
      "loss": 0.2671,
      "step": 400
    },
    {
      "epoch": 0.9382151029748284,
      "grad_norm": 6.614269733428955,
      "learning_rate": 1.8123569794050344e-05,
      "loss": 0.2977,
      "step": 410
    },
    {
      "epoch": 0.9610983981693364,
      "grad_norm": 13.946203231811523,
      "learning_rate": 1.8077803203661327e-05,
      "loss": 0.3692,
      "step": 420
    },
    {
      "epoch": 0.9839816933638444,
      "grad_norm": 13.714089393615723,
      "learning_rate": 1.8032036613272313e-05,
      "loss": 0.3253,
      "step": 430
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8956666666666667,
      "eval_f1": 0.11331444759206798,
      "eval_loss": 0.30662959814071655,
      "eval_precision": 0.9523809523809523,
      "eval_recall": 0.060240963855421686,
      "eval_runtime": 394.8939,
      "eval_samples_per_second": 7.597,
      "eval_steps_per_second": 0.95,
      "step": 437
    },
    {
      "epoch": 1.0068649885583525,
      "grad_norm": 8.92007064819336,
      "learning_rate": 1.7986270022883295e-05,
      "loss": 0.2898,
      "step": 440
    },
    {
      "epoch": 1.0297482837528604,
      "grad_norm": 8.118043899536133,
      "learning_rate": 1.794050343249428e-05,
      "loss": 0.2997,
      "step": 450
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 5.628709316253662,
      "learning_rate": 1.7894736842105264e-05,
      "loss": 0.2929,
      "step": 460
    },
    {
      "epoch": 1.0755148741418765,
      "grad_norm": 5.788283348083496,
      "learning_rate": 1.784897025171625e-05,
      "loss": 0.2862,
      "step": 470
    },
    {
      "epoch": 1.0983981693363845,
      "grad_norm": 8.996699333190918,
      "learning_rate": 1.7803203661327232e-05,
      "loss": 0.2961,
      "step": 480
    },
    {
      "epoch": 1.1212814645308924,
      "grad_norm": 7.203675746917725,
      "learning_rate": 1.7757437070938218e-05,
      "loss": 0.3622,
      "step": 490
    },
    {
      "epoch": 1.1441647597254005,
      "grad_norm": 7.841869354248047,
      "learning_rate": 1.77116704805492e-05,
      "loss": 0.291,
      "step": 500
    },
    {
      "epoch": 1.1670480549199085,
      "grad_norm": 5.878080368041992,
      "learning_rate": 1.7665903890160187e-05,
      "loss": 0.2139,
      "step": 510
    },
    {
      "epoch": 1.1899313501144164,
      "grad_norm": 5.394832611083984,
      "learning_rate": 1.762013729977117e-05,
      "loss": 0.2626,
      "step": 520
    },
    {
      "epoch": 1.2128146453089246,
      "grad_norm": 8.574636459350586,
      "learning_rate": 1.7574370709382152e-05,
      "loss": 0.2858,
      "step": 530
    },
    {
      "epoch": 1.2356979405034325,
      "grad_norm": 9.027914047241211,
      "learning_rate": 1.7528604118993134e-05,
      "loss": 0.2706,
      "step": 540
    },
    {
      "epoch": 1.2585812356979404,
      "grad_norm": 7.663227081298828,
      "learning_rate": 1.748283752860412e-05,
      "loss": 0.3446,
      "step": 550
    },
    {
      "epoch": 1.2814645308924484,
      "grad_norm": 8.932640075683594,
      "learning_rate": 1.7437070938215103e-05,
      "loss": 0.2384,
      "step": 560
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 6.099036693572998,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.2357,
      "step": 570
    },
    {
      "epoch": 1.3272311212814645,
      "grad_norm": 13.146631240844727,
      "learning_rate": 1.734553775743707e-05,
      "loss": 0.3299,
      "step": 580
    },
    {
      "epoch": 1.3501144164759724,
      "grad_norm": 12.194658279418945,
      "learning_rate": 1.7299771167048057e-05,
      "loss": 0.3492,
      "step": 590
    },
    {
      "epoch": 1.3729977116704806,
      "grad_norm": 6.681573390960693,
      "learning_rate": 1.725400457665904e-05,
      "loss": 0.2252,
      "step": 600
    },
    {
      "epoch": 1.3958810068649885,
      "grad_norm": 7.4462714195251465,
      "learning_rate": 1.7208237986270026e-05,
      "loss": 0.2608,
      "step": 610
    },
    {
      "epoch": 1.4187643020594964,
      "grad_norm": 6.727351188659668,
      "learning_rate": 1.716247139588101e-05,
      "loss": 0.244,
      "step": 620
    },
    {
      "epoch": 1.4416475972540046,
      "grad_norm": 8.670614242553711,
      "learning_rate": 1.7116704805491994e-05,
      "loss": 0.2578,
      "step": 630
    },
    {
      "epoch": 1.4645308924485125,
      "grad_norm": 4.879349708557129,
      "learning_rate": 1.7070938215102977e-05,
      "loss": 0.2044,
      "step": 640
    },
    {
      "epoch": 1.4874141876430205,
      "grad_norm": 6.584069728851318,
      "learning_rate": 1.702517162471396e-05,
      "loss": 0.1936,
      "step": 650
    },
    {
      "epoch": 1.5102974828375286,
      "grad_norm": 7.284031867980957,
      "learning_rate": 1.6979405034324945e-05,
      "loss": 0.215,
      "step": 660
    },
    {
      "epoch": 1.5331807780320366,
      "grad_norm": 7.885095119476318,
      "learning_rate": 1.6933638443935928e-05,
      "loss": 0.2649,
      "step": 670
    },
    {
      "epoch": 1.5560640732265445,
      "grad_norm": 5.544750690460205,
      "learning_rate": 1.688787185354691e-05,
      "loss": 0.1914,
      "step": 680
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 9.441383361816406,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.2051,
      "step": 690
    },
    {
      "epoch": 1.6018306636155606,
      "grad_norm": 10.43990707397461,
      "learning_rate": 1.679633867276888e-05,
      "loss": 0.1931,
      "step": 700
    },
    {
      "epoch": 1.6247139588100685,
      "grad_norm": 10.405828475952148,
      "learning_rate": 1.6750572082379865e-05,
      "loss": 0.3496,
      "step": 710
    },
    {
      "epoch": 1.6475972540045767,
      "grad_norm": 5.767891883850098,
      "learning_rate": 1.6704805491990848e-05,
      "loss": 0.2333,
      "step": 720
    },
    {
      "epoch": 1.6704805491990846,
      "grad_norm": 17.632333755493164,
      "learning_rate": 1.665903890160183e-05,
      "loss": 0.2453,
      "step": 730
    },
    {
      "epoch": 1.6933638443935926,
      "grad_norm": 4.001975059509277,
      "learning_rate": 1.6613272311212816e-05,
      "loss": 0.2447,
      "step": 740
    },
    {
      "epoch": 1.7162471395881007,
      "grad_norm": 6.0922322273254395,
      "learning_rate": 1.65675057208238e-05,
      "loss": 0.1828,
      "step": 750
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 4.781247615814209,
      "learning_rate": 1.6521739130434785e-05,
      "loss": 0.2076,
      "step": 760
    },
    {
      "epoch": 1.7620137299771166,
      "grad_norm": 5.448617935180664,
      "learning_rate": 1.6475972540045767e-05,
      "loss": 0.2038,
      "step": 770
    },
    {
      "epoch": 1.7848970251716247,
      "grad_norm": 32.17607498168945,
      "learning_rate": 1.6430205949656753e-05,
      "loss": 0.1801,
      "step": 780
    },
    {
      "epoch": 1.8077803203661327,
      "grad_norm": 7.303800106048584,
      "learning_rate": 1.6384439359267736e-05,
      "loss": 0.2477,
      "step": 790
    },
    {
      "epoch": 1.8306636155606406,
      "grad_norm": 8.365245819091797,
      "learning_rate": 1.633867276887872e-05,
      "loss": 0.2462,
      "step": 800
    },
    {
      "epoch": 1.8535469107551488,
      "grad_norm": 7.472077369689941,
      "learning_rate": 1.6292906178489704e-05,
      "loss": 0.2274,
      "step": 810
    },
    {
      "epoch": 1.8764302059496567,
      "grad_norm": 8.697633743286133,
      "learning_rate": 1.624713958810069e-05,
      "loss": 0.2301,
      "step": 820
    },
    {
      "epoch": 1.8993135011441646,
      "grad_norm": 5.245330333709717,
      "learning_rate": 1.620137299771167e-05,
      "loss": 0.1897,
      "step": 830
    },
    {
      "epoch": 1.9221967963386728,
      "grad_norm": 7.576410293579102,
      "learning_rate": 1.6155606407322655e-05,
      "loss": 0.206,
      "step": 840
    },
    {
      "epoch": 1.9450800915331807,
      "grad_norm": 14.614798545837402,
      "learning_rate": 1.6109839816933638e-05,
      "loss": 0.2478,
      "step": 850
    },
    {
      "epoch": 1.9679633867276887,
      "grad_norm": 8.360706329345703,
      "learning_rate": 1.6064073226544624e-05,
      "loss": 0.1912,
      "step": 860
    },
    {
      "epoch": 1.9908466819221968,
      "grad_norm": 5.3429059982299805,
      "learning_rate": 1.6018306636155606e-05,
      "loss": 0.1574,
      "step": 870
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9293333333333333,
      "eval_f1": 0.6145454545454545,
      "eval_loss": 0.18608638644218445,
      "eval_precision": 0.7752293577981652,
      "eval_recall": 0.5090361445783133,
      "eval_runtime": 399.7243,
      "eval_samples_per_second": 7.505,
      "eval_steps_per_second": 0.938,
      "step": 874
    },
    {
      "epoch": 2.013729977116705,
      "grad_norm": 8.006412506103516,
      "learning_rate": 1.5972540045766592e-05,
      "loss": 0.1514,
      "step": 880
    },
    {
      "epoch": 2.0366132723112127,
      "grad_norm": 6.114214897155762,
      "learning_rate": 1.5926773455377575e-05,
      "loss": 0.159,
      "step": 890
    },
    {
      "epoch": 2.059496567505721,
      "grad_norm": 9.839985847473145,
      "learning_rate": 1.588100686498856e-05,
      "loss": 0.1663,
      "step": 900
    },
    {
      "epoch": 2.082379862700229,
      "grad_norm": 8.426557540893555,
      "learning_rate": 1.5835240274599543e-05,
      "loss": 0.1703,
      "step": 910
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 5.933172225952148,
      "learning_rate": 1.578947368421053e-05,
      "loss": 0.1511,
      "step": 920
    },
    {
      "epoch": 2.128146453089245,
      "grad_norm": 9.7702054977417,
      "learning_rate": 1.5743707093821512e-05,
      "loss": 0.1849,
      "step": 930
    },
    {
      "epoch": 2.151029748283753,
      "grad_norm": 12.210699081420898,
      "learning_rate": 1.5697940503432498e-05,
      "loss": 0.1762,
      "step": 940
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 13.693603515625,
      "learning_rate": 1.565217391304348e-05,
      "loss": 0.1349,
      "step": 950
    },
    {
      "epoch": 2.196796338672769,
      "grad_norm": 12.865735054016113,
      "learning_rate": 1.5606407322654463e-05,
      "loss": 0.155,
      "step": 960
    },
    {
      "epoch": 2.219679633867277,
      "grad_norm": 11.277685165405273,
      "learning_rate": 1.556064073226545e-05,
      "loss": 0.1535,
      "step": 970
    },
    {
      "epoch": 2.242562929061785,
      "grad_norm": 14.403379440307617,
      "learning_rate": 1.551487414187643e-05,
      "loss": 0.1628,
      "step": 980
    },
    {
      "epoch": 2.265446224256293,
      "grad_norm": 10.649843215942383,
      "learning_rate": 1.5469107551487414e-05,
      "loss": 0.1581,
      "step": 990
    },
    {
      "epoch": 2.288329519450801,
      "grad_norm": 11.668723106384277,
      "learning_rate": 1.54233409610984e-05,
      "loss": 0.2514,
      "step": 1000
    },
    {
      "epoch": 2.311212814645309,
      "grad_norm": 18.99295425415039,
      "learning_rate": 1.5377574370709382e-05,
      "loss": 0.1916,
      "step": 1010
    },
    {
      "epoch": 2.334096109839817,
      "grad_norm": 10.356975555419922,
      "learning_rate": 1.533180778032037e-05,
      "loss": 0.1973,
      "step": 1020
    },
    {
      "epoch": 2.356979405034325,
      "grad_norm": 3.9248592853546143,
      "learning_rate": 1.528604118993135e-05,
      "loss": 0.1358,
      "step": 1030
    },
    {
      "epoch": 2.379862700228833,
      "grad_norm": 9.552044868469238,
      "learning_rate": 1.5240274599542335e-05,
      "loss": 0.1899,
      "step": 1040
    },
    {
      "epoch": 2.402745995423341,
      "grad_norm": 17.95973014831543,
      "learning_rate": 1.519450800915332e-05,
      "loss": 0.1034,
      "step": 1050
    },
    {
      "epoch": 2.425629290617849,
      "grad_norm": 13.512701034545898,
      "learning_rate": 1.5148741418764304e-05,
      "loss": 0.1952,
      "step": 1060
    },
    {
      "epoch": 2.448512585812357,
      "grad_norm": 9.08702278137207,
      "learning_rate": 1.5102974828375288e-05,
      "loss": 0.1349,
      "step": 1070
    },
    {
      "epoch": 2.471395881006865,
      "grad_norm": 11.23929214477539,
      "learning_rate": 1.5057208237986272e-05,
      "loss": 0.116,
      "step": 1080
    },
    {
      "epoch": 2.494279176201373,
      "grad_norm": 8.188172340393066,
      "learning_rate": 1.5011441647597256e-05,
      "loss": 0.1274,
      "step": 1090
    },
    {
      "epoch": 2.517162471395881,
      "grad_norm": 9.825983047485352,
      "learning_rate": 1.496567505720824e-05,
      "loss": 0.0983,
      "step": 1100
    },
    {
      "epoch": 2.540045766590389,
      "grad_norm": 5.764614105224609,
      "learning_rate": 1.4919908466819223e-05,
      "loss": 0.1822,
      "step": 1110
    },
    {
      "epoch": 2.5629290617848968,
      "grad_norm": 10.338872909545898,
      "learning_rate": 1.4874141876430207e-05,
      "loss": 0.1106,
      "step": 1120
    },
    {
      "epoch": 2.585812356979405,
      "grad_norm": 9.837037086486816,
      "learning_rate": 1.4828375286041192e-05,
      "loss": 0.1385,
      "step": 1130
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 11.528230667114258,
      "learning_rate": 1.4782608695652174e-05,
      "loss": 0.1511,
      "step": 1140
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 7.728184223175049,
      "learning_rate": 1.4736842105263159e-05,
      "loss": 0.1524,
      "step": 1150
    },
    {
      "epoch": 2.654462242562929,
      "grad_norm": 15.740752220153809,
      "learning_rate": 1.4691075514874143e-05,
      "loss": 0.129,
      "step": 1160
    },
    {
      "epoch": 2.677345537757437,
      "grad_norm": 8.968952178955078,
      "learning_rate": 1.4645308924485127e-05,
      "loss": 0.0899,
      "step": 1170
    },
    {
      "epoch": 2.700228832951945,
      "grad_norm": 13.002480506896973,
      "learning_rate": 1.4599542334096111e-05,
      "loss": 0.2054,
      "step": 1180
    },
    {
      "epoch": 2.723112128146453,
      "grad_norm": 5.642910957336426,
      "learning_rate": 1.4553775743707096e-05,
      "loss": 0.0984,
      "step": 1190
    },
    {
      "epoch": 2.745995423340961,
      "grad_norm": 2.897190809249878,
      "learning_rate": 1.4508009153318078e-05,
      "loss": 0.1619,
      "step": 1200
    },
    {
      "epoch": 2.7688787185354693,
      "grad_norm": 1.5360997915267944,
      "learning_rate": 1.4462242562929062e-05,
      "loss": 0.1311,
      "step": 1210
    },
    {
      "epoch": 2.791762013729977,
      "grad_norm": 19.04886817932129,
      "learning_rate": 1.4416475972540047e-05,
      "loss": 0.1436,
      "step": 1220
    },
    {
      "epoch": 2.814645308924485,
      "grad_norm": 10.622316360473633,
      "learning_rate": 1.4370709382151031e-05,
      "loss": 0.196,
      "step": 1230
    },
    {
      "epoch": 2.837528604118993,
      "grad_norm": 16.90561294555664,
      "learning_rate": 1.4324942791762015e-05,
      "loss": 0.208,
      "step": 1240
    },
    {
      "epoch": 2.860411899313501,
      "grad_norm": 7.024208068847656,
      "learning_rate": 1.4279176201373e-05,
      "loss": 0.1685,
      "step": 1250
    },
    {
      "epoch": 2.883295194508009,
      "grad_norm": 9.131526947021484,
      "learning_rate": 1.4233409610983984e-05,
      "loss": 0.0893,
      "step": 1260
    },
    {
      "epoch": 2.9061784897025174,
      "grad_norm": 7.303746223449707,
      "learning_rate": 1.4187643020594968e-05,
      "loss": 0.1292,
      "step": 1270
    },
    {
      "epoch": 2.929061784897025,
      "grad_norm": 6.877894401550293,
      "learning_rate": 1.4141876430205952e-05,
      "loss": 0.1527,
      "step": 1280
    },
    {
      "epoch": 2.9519450800915332,
      "grad_norm": 7.7558417320251465,
      "learning_rate": 1.4096109839816933e-05,
      "loss": 0.1249,
      "step": 1290
    },
    {
      "epoch": 2.974828375286041,
      "grad_norm": 1.936284065246582,
      "learning_rate": 1.4050343249427917e-05,
      "loss": 0.1092,
      "step": 1300
    },
    {
      "epoch": 2.997711670480549,
      "grad_norm": 10.15730094909668,
      "learning_rate": 1.4004576659038902e-05,
      "loss": 0.123,
      "step": 1310
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9496666666666667,
      "eval_f1": 0.7591706539074959,
      "eval_loss": 0.15132053196430206,
      "eval_precision": 0.8067796610169492,
      "eval_recall": 0.7168674698795181,
      "eval_runtime": 403.3884,
      "eval_samples_per_second": 7.437,
      "eval_steps_per_second": 0.93,
      "step": 1311
    },
    {
      "epoch": 3.0205949656750573,
      "grad_norm": 5.3504862785339355,
      "learning_rate": 1.3958810068649886e-05,
      "loss": 0.0709,
      "step": 1320
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 11.89708423614502,
      "learning_rate": 1.391304347826087e-05,
      "loss": 0.0843,
      "step": 1330
    },
    {
      "epoch": 3.066361556064073,
      "grad_norm": 1.3665391206741333,
      "learning_rate": 1.3867276887871854e-05,
      "loss": 0.089,
      "step": 1340
    },
    {
      "epoch": 3.0892448512585813,
      "grad_norm": 3.339493751525879,
      "learning_rate": 1.3821510297482839e-05,
      "loss": 0.1054,
      "step": 1350
    },
    {
      "epoch": 3.1121281464530894,
      "grad_norm": 10.7007417678833,
      "learning_rate": 1.3775743707093823e-05,
      "loss": 0.068,
      "step": 1360
    },
    {
      "epoch": 3.135011441647597,
      "grad_norm": 3.7509970664978027,
      "learning_rate": 1.3729977116704807e-05,
      "loss": 0.0394,
      "step": 1370
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 15.352625846862793,
      "learning_rate": 1.3684210526315791e-05,
      "loss": 0.115,
      "step": 1380
    },
    {
      "epoch": 3.1807780320366135,
      "grad_norm": 2.3436954021453857,
      "learning_rate": 1.3638443935926776e-05,
      "loss": 0.129,
      "step": 1390
    },
    {
      "epoch": 3.203661327231121,
      "grad_norm": 10.975687026977539,
      "learning_rate": 1.359267734553776e-05,
      "loss": 0.0882,
      "step": 1400
    },
    {
      "epoch": 3.2265446224256293,
      "grad_norm": 11.380315780639648,
      "learning_rate": 1.3546910755148744e-05,
      "loss": 0.1087,
      "step": 1410
    },
    {
      "epoch": 3.2494279176201375,
      "grad_norm": 20.76383399963379,
      "learning_rate": 1.3501144164759727e-05,
      "loss": 0.077,
      "step": 1420
    },
    {
      "epoch": 3.272311212814645,
      "grad_norm": 17.24502944946289,
      "learning_rate": 1.3455377574370711e-05,
      "loss": 0.1279,
      "step": 1430
    },
    {
      "epoch": 3.2951945080091534,
      "grad_norm": 4.1075758934021,
      "learning_rate": 1.3409610983981693e-05,
      "loss": 0.0478,
      "step": 1440
    },
    {
      "epoch": 3.3180778032036615,
      "grad_norm": 10.539817810058594,
      "learning_rate": 1.3363844393592678e-05,
      "loss": 0.0747,
      "step": 1450
    },
    {
      "epoch": 3.3409610983981692,
      "grad_norm": 0.06901459395885468,
      "learning_rate": 1.3318077803203662e-05,
      "loss": 0.0566,
      "step": 1460
    },
    {
      "epoch": 3.3638443935926774,
      "grad_norm": 6.488336086273193,
      "learning_rate": 1.3272311212814646e-05,
      "loss": 0.1082,
      "step": 1470
    },
    {
      "epoch": 3.386727688787185,
      "grad_norm": 15.533385276794434,
      "learning_rate": 1.322654462242563e-05,
      "loss": 0.0928,
      "step": 1480
    },
    {
      "epoch": 3.4096109839816933,
      "grad_norm": 10.364691734313965,
      "learning_rate": 1.3180778032036615e-05,
      "loss": 0.0584,
      "step": 1490
    },
    {
      "epoch": 3.4324942791762014,
      "grad_norm": 13.99140453338623,
      "learning_rate": 1.3135011441647599e-05,
      "loss": 0.054,
      "step": 1500
    },
    {
      "epoch": 3.4553775743707096,
      "grad_norm": 14.887307167053223,
      "learning_rate": 1.3089244851258582e-05,
      "loss": 0.1501,
      "step": 1510
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 15.928976058959961,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.1307,
      "step": 1520
    },
    {
      "epoch": 3.5011441647597255,
      "grad_norm": 4.310233116149902,
      "learning_rate": 1.299771167048055e-05,
      "loss": 0.1362,
      "step": 1530
    },
    {
      "epoch": 3.524027459954233,
      "grad_norm": 1.0192290544509888,
      "learning_rate": 1.2951945080091534e-05,
      "loss": 0.0535,
      "step": 1540
    },
    {
      "epoch": 3.5469107551487413,
      "grad_norm": 15.678236961364746,
      "learning_rate": 1.2906178489702519e-05,
      "loss": 0.1724,
      "step": 1550
    },
    {
      "epoch": 3.5697940503432495,
      "grad_norm": 5.496831893920898,
      "learning_rate": 1.2860411899313503e-05,
      "loss": 0.0519,
      "step": 1560
    },
    {
      "epoch": 3.5926773455377576,
      "grad_norm": 21.68557357788086,
      "learning_rate": 1.2814645308924487e-05,
      "loss": 0.0686,
      "step": 1570
    },
    {
      "epoch": 3.6155606407322654,
      "grad_norm": 24.190719604492188,
      "learning_rate": 1.2768878718535471e-05,
      "loss": 0.0974,
      "step": 1580
    },
    {
      "epoch": 3.6384439359267735,
      "grad_norm": 1.6308788061141968,
      "learning_rate": 1.2723112128146454e-05,
      "loss": 0.0908,
      "step": 1590
    },
    {
      "epoch": 3.6613272311212812,
      "grad_norm": 7.606157302856445,
      "learning_rate": 1.2677345537757438e-05,
      "loss": 0.0559,
      "step": 1600
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 0.8611788153648376,
      "learning_rate": 1.263157894736842e-05,
      "loss": 0.0646,
      "step": 1610
    },
    {
      "epoch": 3.7070938215102975,
      "grad_norm": 3.3854730129241943,
      "learning_rate": 1.2585812356979405e-05,
      "loss": 0.0635,
      "step": 1620
    },
    {
      "epoch": 3.7299771167048057,
      "grad_norm": 13.477940559387207,
      "learning_rate": 1.254004576659039e-05,
      "loss": 0.096,
      "step": 1630
    },
    {
      "epoch": 3.7528604118993134,
      "grad_norm": 5.0086669921875,
      "learning_rate": 1.2494279176201373e-05,
      "loss": 0.0806,
      "step": 1640
    },
    {
      "epoch": 3.7757437070938216,
      "grad_norm": 5.391355514526367,
      "learning_rate": 1.2448512585812358e-05,
      "loss": 0.0705,
      "step": 1650
    },
    {
      "epoch": 3.7986270022883293,
      "grad_norm": 6.602672100067139,
      "learning_rate": 1.2402745995423342e-05,
      "loss": 0.1171,
      "step": 1660
    },
    {
      "epoch": 3.8215102974828374,
      "grad_norm": 0.48623907566070557,
      "learning_rate": 1.2356979405034326e-05,
      "loss": 0.0565,
      "step": 1670
    },
    {
      "epoch": 3.8443935926773456,
      "grad_norm": 8.603023529052734,
      "learning_rate": 1.231121281464531e-05,
      "loss": 0.0424,
      "step": 1680
    },
    {
      "epoch": 3.8672768878718538,
      "grad_norm": 12.651045799255371,
      "learning_rate": 1.2265446224256295e-05,
      "loss": 0.1031,
      "step": 1690
    },
    {
      "epoch": 3.8901601830663615,
      "grad_norm": 1.7280298471450806,
      "learning_rate": 1.2219679633867279e-05,
      "loss": 0.0726,
      "step": 1700
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 7.553221702575684,
      "learning_rate": 1.2173913043478263e-05,
      "loss": 0.08,
      "step": 1710
    },
    {
      "epoch": 3.9359267734553773,
      "grad_norm": 7.217187404632568,
      "learning_rate": 1.2128146453089247e-05,
      "loss": 0.068,
      "step": 1720
    },
    {
      "epoch": 3.9588100686498855,
      "grad_norm": 9.183018684387207,
      "learning_rate": 1.2082379862700232e-05,
      "loss": 0.0492,
      "step": 1730
    },
    {
      "epoch": 3.9816933638443937,
      "grad_norm": 25.89409637451172,
      "learning_rate": 1.2036613272311213e-05,
      "loss": 0.1577,
      "step": 1740
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9613333333333334,
      "eval_f1": 0.8226299694189603,
      "eval_loss": 0.13800309598445892,
      "eval_precision": 0.8354037267080745,
      "eval_recall": 0.8102409638554217,
      "eval_runtime": 399.9321,
      "eval_samples_per_second": 7.501,
      "eval_steps_per_second": 0.938,
      "step": 1748
    },
    {
      "epoch": 4.004576659038902,
      "grad_norm": 1.4895884990692139,
      "learning_rate": 1.1990846681922197e-05,
      "loss": 0.0986,
      "step": 1750
    },
    {
      "epoch": 4.02745995423341,
      "grad_norm": 0.09133651852607727,
      "learning_rate": 1.1945080091533181e-05,
      "loss": 0.0102,
      "step": 1760
    },
    {
      "epoch": 4.050343249427917,
      "grad_norm": 14.797188758850098,
      "learning_rate": 1.1899313501144165e-05,
      "loss": 0.05,
      "step": 1770
    },
    {
      "epoch": 4.073226544622425,
      "grad_norm": 11.144031524658203,
      "learning_rate": 1.185354691075515e-05,
      "loss": 0.0947,
      "step": 1780
    },
    {
      "epoch": 4.0961098398169336,
      "grad_norm": 4.347477436065674,
      "learning_rate": 1.1807780320366134e-05,
      "loss": 0.0336,
      "step": 1790
    },
    {
      "epoch": 4.118993135011442,
      "grad_norm": 18.159868240356445,
      "learning_rate": 1.1762013729977118e-05,
      "loss": 0.0791,
      "step": 1800
    },
    {
      "epoch": 4.14187643020595,
      "grad_norm": 0.38731104135513306,
      "learning_rate": 1.1716247139588102e-05,
      "loss": 0.1028,
      "step": 1810
    },
    {
      "epoch": 4.164759725400458,
      "grad_norm": 6.414250373840332,
      "learning_rate": 1.1670480549199087e-05,
      "loss": 0.0632,
      "step": 1820
    },
    {
      "epoch": 4.187643020594965,
      "grad_norm": 2.236861228942871,
      "learning_rate": 1.1624713958810069e-05,
      "loss": 0.0331,
      "step": 1830
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 7.5287556648254395,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.1083,
      "step": 1840
    },
    {
      "epoch": 4.233409610983982,
      "grad_norm": 7.219174861907959,
      "learning_rate": 1.1533180778032038e-05,
      "loss": 0.024,
      "step": 1850
    },
    {
      "epoch": 4.25629290617849,
      "grad_norm": 0.2980816662311554,
      "learning_rate": 1.1487414187643022e-05,
      "loss": 0.0495,
      "step": 1860
    },
    {
      "epoch": 4.279176201372998,
      "grad_norm": 16.082683563232422,
      "learning_rate": 1.1441647597254006e-05,
      "loss": 0.1106,
      "step": 1870
    },
    {
      "epoch": 4.302059496567506,
      "grad_norm": 2.6280806064605713,
      "learning_rate": 1.139588100686499e-05,
      "loss": 0.0523,
      "step": 1880
    },
    {
      "epoch": 4.324942791762013,
      "grad_norm": 22.17121124267578,
      "learning_rate": 1.1350114416475973e-05,
      "loss": 0.1101,
      "step": 1890
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 2.9486582279205322,
      "learning_rate": 1.1304347826086957e-05,
      "loss": 0.0688,
      "step": 1900
    },
    {
      "epoch": 4.37070938215103,
      "grad_norm": 19.099294662475586,
      "learning_rate": 1.1258581235697941e-05,
      "loss": 0.0367,
      "step": 1910
    },
    {
      "epoch": 4.393592677345538,
      "grad_norm": 14.667064666748047,
      "learning_rate": 1.1212814645308924e-05,
      "loss": 0.0864,
      "step": 1920
    },
    {
      "epoch": 4.416475972540046,
      "grad_norm": 10.544306755065918,
      "learning_rate": 1.1167048054919908e-05,
      "loss": 0.0406,
      "step": 1930
    },
    {
      "epoch": 4.439359267734554,
      "grad_norm": 15.84972858428955,
      "learning_rate": 1.1121281464530893e-05,
      "loss": 0.033,
      "step": 1940
    },
    {
      "epoch": 4.462242562929061,
      "grad_norm": 1.0749101638793945,
      "learning_rate": 1.1075514874141877e-05,
      "loss": 0.0325,
      "step": 1950
    },
    {
      "epoch": 4.48512585812357,
      "grad_norm": 4.08333683013916,
      "learning_rate": 1.1029748283752861e-05,
      "loss": 0.0421,
      "step": 1960
    },
    {
      "epoch": 4.508009153318078,
      "grad_norm": 5.046902656555176,
      "learning_rate": 1.0983981693363845e-05,
      "loss": 0.0406,
      "step": 1970
    },
    {
      "epoch": 4.530892448512586,
      "grad_norm": 6.190456390380859,
      "learning_rate": 1.093821510297483e-05,
      "loss": 0.024,
      "step": 1980
    },
    {
      "epoch": 4.553775743707094,
      "grad_norm": 6.202503204345703,
      "learning_rate": 1.0892448512585814e-05,
      "loss": 0.1062,
      "step": 1990
    },
    {
      "epoch": 4.576659038901602,
      "grad_norm": 18.773902893066406,
      "learning_rate": 1.0846681922196798e-05,
      "loss": 0.0206,
      "step": 2000
    },
    {
      "epoch": 4.5995423340961095,
      "grad_norm": 15.33918571472168,
      "learning_rate": 1.0800915331807782e-05,
      "loss": 0.09,
      "step": 2010
    },
    {
      "epoch": 4.622425629290618,
      "grad_norm": 2.8809220790863037,
      "learning_rate": 1.0755148741418767e-05,
      "loss": 0.0552,
      "step": 2020
    },
    {
      "epoch": 4.645308924485126,
      "grad_norm": 1.4060709476470947,
      "learning_rate": 1.070938215102975e-05,
      "loss": 0.0392,
      "step": 2030
    },
    {
      "epoch": 4.668192219679634,
      "grad_norm": 0.2528218626976013,
      "learning_rate": 1.0663615560640732e-05,
      "loss": 0.0225,
      "step": 2040
    },
    {
      "epoch": 4.691075514874142,
      "grad_norm": 3.0354580879211426,
      "learning_rate": 1.0617848970251716e-05,
      "loss": 0.0255,
      "step": 2050
    },
    {
      "epoch": 4.71395881006865,
      "grad_norm": 12.564413070678711,
      "learning_rate": 1.05720823798627e-05,
      "loss": 0.0353,
      "step": 2060
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 0.5810843706130981,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.0182,
      "step": 2070
    },
    {
      "epoch": 4.759725400457666,
      "grad_norm": 2.238349676132202,
      "learning_rate": 1.0480549199084669e-05,
      "loss": 0.0405,
      "step": 2080
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 19.133508682250977,
      "learning_rate": 1.0434782608695653e-05,
      "loss": 0.0587,
      "step": 2090
    },
    {
      "epoch": 4.805491990846682,
      "grad_norm": 36.664878845214844,
      "learning_rate": 1.0389016018306637e-05,
      "loss": 0.0887,
      "step": 2100
    },
    {
      "epoch": 4.82837528604119,
      "grad_norm": 17.022478103637695,
      "learning_rate": 1.0343249427917621e-05,
      "loss": 0.0336,
      "step": 2110
    },
    {
      "epoch": 4.851258581235698,
      "grad_norm": 0.2686963677406311,
      "learning_rate": 1.0297482837528606e-05,
      "loss": 0.0912,
      "step": 2120
    },
    {
      "epoch": 4.874141876430206,
      "grad_norm": 14.633703231811523,
      "learning_rate": 1.025171624713959e-05,
      "loss": 0.0517,
      "step": 2130
    },
    {
      "epoch": 4.897025171624714,
      "grad_norm": 14.103557586669922,
      "learning_rate": 1.0205949656750573e-05,
      "loss": 0.02,
      "step": 2140
    },
    {
      "epoch": 4.919908466819222,
      "grad_norm": 1.3982059955596924,
      "learning_rate": 1.0160183066361557e-05,
      "loss": 0.0408,
      "step": 2150
    },
    {
      "epoch": 4.94279176201373,
      "grad_norm": 31.50109100341797,
      "learning_rate": 1.0114416475972541e-05,
      "loss": 0.0832,
      "step": 2160
    },
    {
      "epoch": 4.965675057208238,
      "grad_norm": 35.213436126708984,
      "learning_rate": 1.0068649885583525e-05,
      "loss": 0.1123,
      "step": 2170
    },
    {
      "epoch": 4.988558352402746,
      "grad_norm": 0.09118787944316864,
      "learning_rate": 1.002288329519451e-05,
      "loss": 0.039,
      "step": 2180
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9406666666666667,
      "eval_f1": 0.770618556701031,
      "eval_loss": 0.26919791102409363,
      "eval_precision": 0.6734234234234234,
      "eval_recall": 0.9006024096385542,
      "eval_runtime": 402.1883,
      "eval_samples_per_second": 7.459,
      "eval_steps_per_second": 0.932,
      "step": 2185
    },
    {
      "epoch": 5.011441647597254,
      "grad_norm": 0.08526010811328888,
      "learning_rate": 9.977116704805492e-06,
      "loss": 0.0842,
      "step": 2190
    },
    {
      "epoch": 5.034324942791762,
      "grad_norm": 2.8839468955993652,
      "learning_rate": 9.931350114416476e-06,
      "loss": 0.0625,
      "step": 2200
    },
    {
      "epoch": 5.05720823798627,
      "grad_norm": 14.380115509033203,
      "learning_rate": 9.88558352402746e-06,
      "loss": 0.0315,
      "step": 2210
    },
    {
      "epoch": 5.080091533180778,
      "grad_norm": 1.6262784004211426,
      "learning_rate": 9.839816933638445e-06,
      "loss": 0.0335,
      "step": 2220
    },
    {
      "epoch": 5.102974828375286,
      "grad_norm": 0.7610247731208801,
      "learning_rate": 9.794050343249429e-06,
      "loss": 0.0114,
      "step": 2230
    },
    {
      "epoch": 5.125858123569794,
      "grad_norm": 23.043758392333984,
      "learning_rate": 9.748283752860412e-06,
      "loss": 0.0511,
      "step": 2240
    },
    {
      "epoch": 5.148741418764302,
      "grad_norm": 16.584884643554688,
      "learning_rate": 9.702517162471396e-06,
      "loss": 0.0238,
      "step": 2250
    },
    {
      "epoch": 5.17162471395881,
      "grad_norm": 2.2406728267669678,
      "learning_rate": 9.65675057208238e-06,
      "loss": 0.0306,
      "step": 2260
    },
    {
      "epoch": 5.194508009153318,
      "grad_norm": 0.16805022954940796,
      "learning_rate": 9.610983981693364e-06,
      "loss": 0.014,
      "step": 2270
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 0.05335373803973198,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.0515,
      "step": 2280
    },
    {
      "epoch": 5.240274599542334,
      "grad_norm": 11.184386253356934,
      "learning_rate": 9.519450800915333e-06,
      "loss": 0.0141,
      "step": 2290
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.2977709174156189,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.0311,
      "step": 2300
    },
    {
      "epoch": 5.28604118993135,
      "grad_norm": 8.052166938781738,
      "learning_rate": 9.4279176201373e-06,
      "loss": 0.0462,
      "step": 2310
    },
    {
      "epoch": 5.308924485125858,
      "grad_norm": 0.3345724642276764,
      "learning_rate": 9.382151029748284e-06,
      "loss": 0.0095,
      "step": 2320
    },
    {
      "epoch": 5.331807780320366,
      "grad_norm": 0.04087646305561066,
      "learning_rate": 9.336384439359268e-06,
      "loss": 0.0352,
      "step": 2330
    },
    {
      "epoch": 5.354691075514874,
      "grad_norm": 15.938468933105469,
      "learning_rate": 9.290617848970253e-06,
      "loss": 0.0761,
      "step": 2340
    },
    {
      "epoch": 5.377574370709382,
      "grad_norm": 0.023320090025663376,
      "learning_rate": 9.244851258581237e-06,
      "loss": 0.0224,
      "step": 2350
    },
    {
      "epoch": 5.4004576659038905,
      "grad_norm": 0.009347123093903065,
      "learning_rate": 9.199084668192221e-06,
      "loss": 0.0172,
      "step": 2360
    },
    {
      "epoch": 5.423340961098398,
      "grad_norm": 17.762889862060547,
      "learning_rate": 9.153318077803205e-06,
      "loss": 0.0213,
      "step": 2370
    },
    {
      "epoch": 5.446224256292906,
      "grad_norm": 0.5457404851913452,
      "learning_rate": 9.107551487414188e-06,
      "loss": 0.0859,
      "step": 2380
    },
    {
      "epoch": 5.469107551487414,
      "grad_norm": 16.167919158935547,
      "learning_rate": 9.061784897025172e-06,
      "loss": 0.0644,
      "step": 2390
    },
    {
      "epoch": 5.491990846681922,
      "grad_norm": 29.021272659301758,
      "learning_rate": 9.016018306636156e-06,
      "loss": 0.0574,
      "step": 2400
    },
    {
      "epoch": 5.51487414187643,
      "grad_norm": 0.31003478169441223,
      "learning_rate": 8.97025171624714e-06,
      "loss": 0.0341,
      "step": 2410
    },
    {
      "epoch": 5.537757437070939,
      "grad_norm": 0.03950754925608635,
      "learning_rate": 8.924485125858125e-06,
      "loss": 0.037,
      "step": 2420
    },
    {
      "epoch": 5.560640732265446,
      "grad_norm": 12.556354522705078,
      "learning_rate": 8.878718535469109e-06,
      "loss": 0.0781,
      "step": 2430
    },
    {
      "epoch": 5.583524027459954,
      "grad_norm": 13.38266658782959,
      "learning_rate": 8.832951945080093e-06,
      "loss": 0.0277,
      "step": 2440
    },
    {
      "epoch": 5.606407322654462,
      "grad_norm": 22.172195434570312,
      "learning_rate": 8.787185354691076e-06,
      "loss": 0.0274,
      "step": 2450
    },
    {
      "epoch": 5.62929061784897,
      "grad_norm": 14.116620063781738,
      "learning_rate": 8.74141876430206e-06,
      "loss": 0.0867,
      "step": 2460
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 25.112916946411133,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0489,
      "step": 2470
    },
    {
      "epoch": 5.675057208237987,
      "grad_norm": 1.3273802995681763,
      "learning_rate": 8.649885583524029e-06,
      "loss": 0.0232,
      "step": 2480
    },
    {
      "epoch": 5.697940503432494,
      "grad_norm": 0.005706471391022205,
      "learning_rate": 8.604118993135013e-06,
      "loss": 0.0353,
      "step": 2490
    },
    {
      "epoch": 5.720823798627002,
      "grad_norm": 0.0271573718637228,
      "learning_rate": 8.558352402745997e-06,
      "loss": 0.0178,
      "step": 2500
    },
    {
      "epoch": 5.74370709382151,
      "grad_norm": 10.774649620056152,
      "learning_rate": 8.51258581235698e-06,
      "loss": 0.0579,
      "step": 2510
    },
    {
      "epoch": 5.766590389016018,
      "grad_norm": 11.377683639526367,
      "learning_rate": 8.466819221967964e-06,
      "loss": 0.0525,
      "step": 2520
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 0.6634283065795898,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.0583,
      "step": 2530
    },
    {
      "epoch": 5.812356979405035,
      "grad_norm": 4.544502258300781,
      "learning_rate": 8.375286041189932e-06,
      "loss": 0.0958,
      "step": 2540
    },
    {
      "epoch": 5.835240274599542,
      "grad_norm": 0.027850614860653877,
      "learning_rate": 8.329519450800915e-06,
      "loss": 0.0144,
      "step": 2550
    },
    {
      "epoch": 5.85812356979405,
      "grad_norm": 8.786781311035156,
      "learning_rate": 8.2837528604119e-06,
      "loss": 0.0229,
      "step": 2560
    },
    {
      "epoch": 5.881006864988558,
      "grad_norm": 0.13545763492584229,
      "learning_rate": 8.237986270022884e-06,
      "loss": 0.0762,
      "step": 2570
    },
    {
      "epoch": 5.9038901601830664,
      "grad_norm": 0.10486169159412384,
      "learning_rate": 8.192219679633868e-06,
      "loss": 0.0077,
      "step": 2580
    },
    {
      "epoch": 5.926773455377575,
      "grad_norm": 0.031696923077106476,
      "learning_rate": 8.146453089244852e-06,
      "loss": 0.0634,
      "step": 2590
    },
    {
      "epoch": 5.949656750572083,
      "grad_norm": 0.08315736055374146,
      "learning_rate": 8.100686498855835e-06,
      "loss": 0.0052,
      "step": 2600
    },
    {
      "epoch": 5.97254004576659,
      "grad_norm": 2.4939301013946533,
      "learning_rate": 8.054919908466819e-06,
      "loss": 0.0156,
      "step": 2610
    },
    {
      "epoch": 5.995423340961098,
      "grad_norm": 0.5004864931106567,
      "learning_rate": 8.009153318077803e-06,
      "loss": 0.0316,
      "step": 2620
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9673333333333334,
      "eval_f1": 0.8501529051987767,
      "eval_loss": 0.18046386539936066,
      "eval_precision": 0.8633540372670807,
      "eval_recall": 0.8373493975903614,
      "eval_runtime": 400.9499,
      "eval_samples_per_second": 7.482,
      "eval_steps_per_second": 0.935,
      "step": 2622
    },
    {
      "epoch": 6.018306636155606,
      "grad_norm": 0.29058611392974854,
      "learning_rate": 7.963386727688787e-06,
      "loss": 0.0032,
      "step": 2630
    },
    {
      "epoch": 6.0411899313501145,
      "grad_norm": 0.046991992741823196,
      "learning_rate": 7.917620137299772e-06,
      "loss": 0.0166,
      "step": 2640
    },
    {
      "epoch": 6.064073226544623,
      "grad_norm": 0.3028109073638916,
      "learning_rate": 7.871853546910756e-06,
      "loss": 0.0014,
      "step": 2650
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 13.431057929992676,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.0308,
      "step": 2660
    },
    {
      "epoch": 6.109839816933638,
      "grad_norm": 0.0056198290549218655,
      "learning_rate": 7.780320366132724e-06,
      "loss": 0.0015,
      "step": 2670
    },
    {
      "epoch": 6.132723112128146,
      "grad_norm": 0.007490489166229963,
      "learning_rate": 7.734553775743707e-06,
      "loss": 0.0246,
      "step": 2680
    },
    {
      "epoch": 6.155606407322654,
      "grad_norm": 0.30455997586250305,
      "learning_rate": 7.688787185354691e-06,
      "loss": 0.0184,
      "step": 2690
    },
    {
      "epoch": 6.178489702517163,
      "grad_norm": 3.394547462463379,
      "learning_rate": 7.643020594965675e-06,
      "loss": 0.0202,
      "step": 2700
    },
    {
      "epoch": 6.201372997711671,
      "grad_norm": 5.082012176513672,
      "learning_rate": 7.59725400457666e-06,
      "loss": 0.0254,
      "step": 2710
    },
    {
      "epoch": 6.224256292906179,
      "grad_norm": 0.40944838523864746,
      "learning_rate": 7.551487414187644e-06,
      "loss": 0.0306,
      "step": 2720
    },
    {
      "epoch": 6.247139588100686,
      "grad_norm": 0.28734204173088074,
      "learning_rate": 7.505720823798628e-06,
      "loss": 0.0313,
      "step": 2730
    },
    {
      "epoch": 6.270022883295194,
      "grad_norm": 23.621431350708008,
      "learning_rate": 7.459954233409612e-06,
      "loss": 0.0188,
      "step": 2740
    },
    {
      "epoch": 6.2929061784897025,
      "grad_norm": 2.874708414077759,
      "learning_rate": 7.414187643020596e-06,
      "loss": 0.0403,
      "step": 2750
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 0.09343179315328598,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0046,
      "step": 2760
    },
    {
      "epoch": 6.338672768878719,
      "grad_norm": 0.008293064311146736,
      "learning_rate": 7.3226544622425635e-06,
      "loss": 0.0005,
      "step": 2770
    },
    {
      "epoch": 6.361556064073227,
      "grad_norm": 0.3207494020462036,
      "learning_rate": 7.276887871853548e-06,
      "loss": 0.0062,
      "step": 2780
    },
    {
      "epoch": 6.384439359267734,
      "grad_norm": 3.1855297088623047,
      "learning_rate": 7.231121281464531e-06,
      "loss": 0.0128,
      "step": 2790
    },
    {
      "epoch": 6.407322654462242,
      "grad_norm": 0.006854552775621414,
      "learning_rate": 7.1853546910755154e-06,
      "loss": 0.0075,
      "step": 2800
    },
    {
      "epoch": 6.4302059496567505,
      "grad_norm": 3.1224348545074463,
      "learning_rate": 7.1395881006865e-06,
      "loss": 0.0383,
      "step": 2810
    },
    {
      "epoch": 6.453089244851259,
      "grad_norm": 17.604206085205078,
      "learning_rate": 7.093821510297484e-06,
      "loss": 0.0347,
      "step": 2820
    },
    {
      "epoch": 6.475972540045767,
      "grad_norm": 0.027358373627066612,
      "learning_rate": 7.0480549199084665e-06,
      "loss": 0.0605,
      "step": 2830
    },
    {
      "epoch": 6.498855835240275,
      "grad_norm": 0.03390080854296684,
      "learning_rate": 7.002288329519451e-06,
      "loss": 0.0176,
      "step": 2840
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.028404390439391136,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.015,
      "step": 2850
    },
    {
      "epoch": 6.54462242562929,
      "grad_norm": 0.01185978390276432,
      "learning_rate": 6.910755148741419e-06,
      "loss": 0.0352,
      "step": 2860
    },
    {
      "epoch": 6.567505720823799,
      "grad_norm": 0.009026129730045795,
      "learning_rate": 6.8649885583524035e-06,
      "loss": 0.0271,
      "step": 2870
    },
    {
      "epoch": 6.590389016018307,
      "grad_norm": 6.332788944244385,
      "learning_rate": 6.819221967963388e-06,
      "loss": 0.042,
      "step": 2880
    },
    {
      "epoch": 6.613272311212815,
      "grad_norm": 0.057854991406202316,
      "learning_rate": 6.773455377574372e-06,
      "loss": 0.0331,
      "step": 2890
    },
    {
      "epoch": 6.636155606407323,
      "grad_norm": 0.010516121052205563,
      "learning_rate": 6.7276887871853554e-06,
      "loss": 0.011,
      "step": 2900
    },
    {
      "epoch": 6.65903890160183,
      "grad_norm": 0.054286859929561615,
      "learning_rate": 6.681922196796339e-06,
      "loss": 0.0295,
      "step": 2910
    },
    {
      "epoch": 6.6819221967963385,
      "grad_norm": 1.283403992652893,
      "learning_rate": 6.636155606407323e-06,
      "loss": 0.0093,
      "step": 2920
    },
    {
      "epoch": 6.704805491990847,
      "grad_norm": 21.58649253845215,
      "learning_rate": 6.590389016018307e-06,
      "loss": 0.0171,
      "step": 2930
    },
    {
      "epoch": 6.727688787185355,
      "grad_norm": 5.694614410400391,
      "learning_rate": 6.544622425629291e-06,
      "loss": 0.003,
      "step": 2940
    },
    {
      "epoch": 6.750572082379863,
      "grad_norm": 18.721561431884766,
      "learning_rate": 6.498855835240275e-06,
      "loss": 0.0231,
      "step": 2950
    },
    {
      "epoch": 6.77345537757437,
      "grad_norm": 17.246807098388672,
      "learning_rate": 6.453089244851259e-06,
      "loss": 0.0128,
      "step": 2960
    },
    {
      "epoch": 6.796338672768878,
      "grad_norm": 9.963483810424805,
      "learning_rate": 6.4073226544622435e-06,
      "loss": 0.0287,
      "step": 2970
    },
    {
      "epoch": 6.8192219679633865,
      "grad_norm": 0.3044029772281647,
      "learning_rate": 6.361556064073227e-06,
      "loss": 0.0143,
      "step": 2980
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 0.6095116138458252,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.0006,
      "step": 2990
    },
    {
      "epoch": 6.864988558352403,
      "grad_norm": 0.2384614497423172,
      "learning_rate": 6.270022883295195e-06,
      "loss": 0.0583,
      "step": 3000
    },
    {
      "epoch": 6.887871853546911,
      "grad_norm": 0.04864202067255974,
      "learning_rate": 6.224256292906179e-06,
      "loss": 0.0003,
      "step": 3010
    },
    {
      "epoch": 6.910755148741419,
      "grad_norm": 2.368818521499634,
      "learning_rate": 6.178489702517163e-06,
      "loss": 0.0066,
      "step": 3020
    },
    {
      "epoch": 6.933638443935926,
      "grad_norm": 0.023229239508509636,
      "learning_rate": 6.132723112128147e-06,
      "loss": 0.0108,
      "step": 3030
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 6.7046918869018555,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.0352,
      "step": 3040
    },
    {
      "epoch": 6.979405034324943,
      "grad_norm": 9.004008293151855,
      "learning_rate": 6.041189931350116e-06,
      "loss": 0.0066,
      "step": 3050
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.968,
      "eval_f1": 0.8504672897196262,
      "eval_loss": 0.20982323586940765,
      "eval_precision": 0.8806451612903226,
      "eval_recall": 0.822289156626506,
      "eval_runtime": 396.7205,
      "eval_samples_per_second": 7.562,
      "eval_steps_per_second": 0.945,
      "step": 3059
    },
    {
      "epoch": 7.002288329519451,
      "grad_norm": 0.007688400335609913,
      "learning_rate": 5.995423340961098e-06,
      "loss": 0.0305,
      "step": 3060
    },
    {
      "epoch": 7.025171624713959,
      "grad_norm": 0.39562228322029114,
      "learning_rate": 5.949656750572083e-06,
      "loss": 0.0025,
      "step": 3070
    },
    {
      "epoch": 7.048054919908467,
      "grad_norm": 0.1688534915447235,
      "learning_rate": 5.903890160183067e-06,
      "loss": 0.0109,
      "step": 3080
    },
    {
      "epoch": 7.0709382151029745,
      "grad_norm": 18.324291229248047,
      "learning_rate": 5.858123569794051e-06,
      "loss": 0.0145,
      "step": 3090
    },
    {
      "epoch": 7.093821510297483,
      "grad_norm": 0.07998176664113998,
      "learning_rate": 5.8123569794050346e-06,
      "loss": 0.0072,
      "step": 3100
    },
    {
      "epoch": 7.116704805491991,
      "grad_norm": 0.00447268458083272,
      "learning_rate": 5.766590389016019e-06,
      "loss": 0.0087,
      "step": 3110
    },
    {
      "epoch": 7.139588100686499,
      "grad_norm": 1.1204454898834229,
      "learning_rate": 5.720823798627003e-06,
      "loss": 0.009,
      "step": 3120
    },
    {
      "epoch": 7.162471395881007,
      "grad_norm": 0.00468872394412756,
      "learning_rate": 5.6750572082379865e-06,
      "loss": 0.0008,
      "step": 3130
    },
    {
      "epoch": 7.185354691075515,
      "grad_norm": 7.452607154846191,
      "learning_rate": 5.629290617848971e-06,
      "loss": 0.0269,
      "step": 3140
    },
    {
      "epoch": 7.2082379862700225,
      "grad_norm": 0.06245303526520729,
      "learning_rate": 5.583524027459954e-06,
      "loss": 0.0165,
      "step": 3150
    },
    {
      "epoch": 7.231121281464531,
      "grad_norm": 0.046430107206106186,
      "learning_rate": 5.537757437070938e-06,
      "loss": 0.0005,
      "step": 3160
    },
    {
      "epoch": 7.254004576659039,
      "grad_norm": 13.077881813049316,
      "learning_rate": 5.491990846681923e-06,
      "loss": 0.0085,
      "step": 3170
    },
    {
      "epoch": 7.276887871853547,
      "grad_norm": 0.008641420863568783,
      "learning_rate": 5.446224256292907e-06,
      "loss": 0.0311,
      "step": 3180
    },
    {
      "epoch": 7.299771167048055,
      "grad_norm": 0.42559951543807983,
      "learning_rate": 5.400457665903891e-06,
      "loss": 0.004,
      "step": 3190
    },
    {
      "epoch": 7.322654462242563,
      "grad_norm": 0.3968595266342163,
      "learning_rate": 5.354691075514875e-06,
      "loss": 0.0014,
      "step": 3200
    },
    {
      "epoch": 7.345537757437071,
      "grad_norm": 0.010422767139971256,
      "learning_rate": 5.308924485125858e-06,
      "loss": 0.0019,
      "step": 3210
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 0.06968987733125687,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.012,
      "step": 3220
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 2.4709372520446777,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.0167,
      "step": 3230
    },
    {
      "epoch": 7.414187643020595,
      "grad_norm": 0.6664507985115051,
      "learning_rate": 5.171624713958811e-06,
      "loss": 0.0013,
      "step": 3240
    },
    {
      "epoch": 7.437070938215103,
      "grad_norm": 13.014312744140625,
      "learning_rate": 5.125858123569795e-06,
      "loss": 0.0262,
      "step": 3250
    },
    {
      "epoch": 7.459954233409611,
      "grad_norm": 0.0049110520631074905,
      "learning_rate": 5.080091533180778e-06,
      "loss": 0.0193,
      "step": 3260
    },
    {
      "epoch": 7.482837528604119,
      "grad_norm": 0.00455115269869566,
      "learning_rate": 5.034324942791763e-06,
      "loss": 0.0157,
      "step": 3270
    },
    {
      "epoch": 7.505720823798627,
      "grad_norm": 0.022143704816699028,
      "learning_rate": 4.988558352402746e-06,
      "loss": 0.0046,
      "step": 3280
    },
    {
      "epoch": 7.528604118993135,
      "grad_norm": 0.05208843573927879,
      "learning_rate": 4.94279176201373e-06,
      "loss": 0.0009,
      "step": 3290
    },
    {
      "epoch": 7.551487414187643,
      "grad_norm": 0.005590887740254402,
      "learning_rate": 4.8970251716247146e-06,
      "loss": 0.0097,
      "step": 3300
    },
    {
      "epoch": 7.574370709382151,
      "grad_norm": 0.07359445095062256,
      "learning_rate": 4.851258581235698e-06,
      "loss": 0.0039,
      "step": 3310
    },
    {
      "epoch": 7.597254004576659,
      "grad_norm": 0.07193209230899811,
      "learning_rate": 4.805491990846682e-06,
      "loss": 0.0045,
      "step": 3320
    },
    {
      "epoch": 7.620137299771167,
      "grad_norm": 0.0032988127786666155,
      "learning_rate": 4.7597254004576665e-06,
      "loss": 0.0154,
      "step": 3330
    },
    {
      "epoch": 7.643020594965675,
      "grad_norm": 3.038252592086792,
      "learning_rate": 4.71395881006865e-06,
      "loss": 0.0009,
      "step": 3340
    },
    {
      "epoch": 7.665903890160183,
      "grad_norm": 0.0040988135151565075,
      "learning_rate": 4.668192219679634e-06,
      "loss": 0.0157,
      "step": 3350
    },
    {
      "epoch": 7.688787185354691,
      "grad_norm": 32.83938980102539,
      "learning_rate": 4.622425629290618e-06,
      "loss": 0.0314,
      "step": 3360
    },
    {
      "epoch": 7.711670480549199,
      "grad_norm": 0.015736140310764313,
      "learning_rate": 4.576659038901603e-06,
      "loss": 0.0164,
      "step": 3370
    },
    {
      "epoch": 7.7345537757437075,
      "grad_norm": 0.9613236784934998,
      "learning_rate": 4.530892448512586e-06,
      "loss": 0.0067,
      "step": 3380
    },
    {
      "epoch": 7.757437070938215,
      "grad_norm": 1.7258496284484863,
      "learning_rate": 4.48512585812357e-06,
      "loss": 0.0198,
      "step": 3390
    },
    {
      "epoch": 7.780320366132723,
      "grad_norm": 35.289581298828125,
      "learning_rate": 4.4393592677345545e-06,
      "loss": 0.0247,
      "step": 3400
    },
    {
      "epoch": 7.803203661327231,
      "grad_norm": 0.013179394416511059,
      "learning_rate": 4.393592677345538e-06,
      "loss": 0.0001,
      "step": 3410
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 1.4035744667053223,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0005,
      "step": 3420
    },
    {
      "epoch": 7.848970251716247,
      "grad_norm": 0.18751558661460876,
      "learning_rate": 4.3020594965675065e-06,
      "loss": 0.0009,
      "step": 3430
    },
    {
      "epoch": 7.871853546910755,
      "grad_norm": 0.004871740471571684,
      "learning_rate": 4.25629290617849e-06,
      "loss": 0.0016,
      "step": 3440
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 0.054252490401268005,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.0333,
      "step": 3450
    },
    {
      "epoch": 7.917620137299771,
      "grad_norm": 8.661676406860352,
      "learning_rate": 4.1647597254004575e-06,
      "loss": 0.0144,
      "step": 3460
    },
    {
      "epoch": 7.940503432494279,
      "grad_norm": 0.006862051319330931,
      "learning_rate": 4.118993135011442e-06,
      "loss": 0.0021,
      "step": 3470
    },
    {
      "epoch": 7.963386727688787,
      "grad_norm": 0.007504560053348541,
      "learning_rate": 4.073226544622426e-06,
      "loss": 0.0197,
      "step": 3480
    },
    {
      "epoch": 7.9862700228832955,
      "grad_norm": 0.003331413958221674,
      "learning_rate": 4.0274599542334094e-06,
      "loss": 0.0025,
      "step": 3490
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.967,
      "eval_f1": 0.8554744525547445,
      "eval_loss": 0.22318346798419952,
      "eval_precision": 0.830028328611898,
      "eval_recall": 0.8825301204819277,
      "eval_runtime": 408.1837,
      "eval_samples_per_second": 7.35,
      "eval_steps_per_second": 0.919,
      "step": 3496
    },
    {
      "epoch": 8.009153318077804,
      "grad_norm": 0.15172438323497772,
      "learning_rate": 3.981693363844394e-06,
      "loss": 0.0104,
      "step": 3500
    },
    {
      "epoch": 8.03203661327231,
      "grad_norm": 0.0028524603694677353,
      "learning_rate": 3.935926773455378e-06,
      "loss": 0.0046,
      "step": 3510
    },
    {
      "epoch": 8.05491990846682,
      "grad_norm": 0.021328026428818703,
      "learning_rate": 3.890160183066362e-06,
      "loss": 0.0134,
      "step": 3520
    },
    {
      "epoch": 8.077803203661327,
      "grad_norm": 0.030190151184797287,
      "learning_rate": 3.844393592677346e-06,
      "loss": 0.0001,
      "step": 3530
    },
    {
      "epoch": 8.100686498855834,
      "grad_norm": 0.00637257844209671,
      "learning_rate": 3.79862700228833e-06,
      "loss": 0.0178,
      "step": 3540
    },
    {
      "epoch": 8.123569794050344,
      "grad_norm": 0.9741061925888062,
      "learning_rate": 3.752860411899314e-06,
      "loss": 0.0228,
      "step": 3550
    },
    {
      "epoch": 8.14645308924485,
      "grad_norm": 0.0020370520651340485,
      "learning_rate": 3.707093821510298e-06,
      "loss": 0.0001,
      "step": 3560
    },
    {
      "epoch": 8.16933638443936,
      "grad_norm": 0.001612273626960814,
      "learning_rate": 3.6613272311212818e-06,
      "loss": 0.0025,
      "step": 3570
    },
    {
      "epoch": 8.192219679633867,
      "grad_norm": 0.017847418785095215,
      "learning_rate": 3.6155606407322656e-06,
      "loss": 0.0106,
      "step": 3580
    },
    {
      "epoch": 8.215102974828376,
      "grad_norm": 0.015301438979804516,
      "learning_rate": 3.56979405034325e-06,
      "loss": 0.0154,
      "step": 3590
    },
    {
      "epoch": 8.237986270022883,
      "grad_norm": 1.8859540224075317,
      "learning_rate": 3.5240274599542333e-06,
      "loss": 0.0003,
      "step": 3600
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 0.011364097706973553,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.0106,
      "step": 3610
    },
    {
      "epoch": 8.2837528604119,
      "grad_norm": 2.3502421379089355,
      "learning_rate": 3.4324942791762018e-06,
      "loss": 0.0048,
      "step": 3620
    },
    {
      "epoch": 8.306636155606407,
      "grad_norm": 0.2577391564846039,
      "learning_rate": 3.386727688787186e-06,
      "loss": 0.0239,
      "step": 3630
    },
    {
      "epoch": 8.329519450800916,
      "grad_norm": 0.01741652935743332,
      "learning_rate": 3.3409610983981694e-06,
      "loss": 0.0019,
      "step": 3640
    },
    {
      "epoch": 8.352402745995423,
      "grad_norm": 1.5398015975952148,
      "learning_rate": 3.2951945080091537e-06,
      "loss": 0.0006,
      "step": 3650
    },
    {
      "epoch": 8.37528604118993,
      "grad_norm": 0.009808420203626156,
      "learning_rate": 3.2494279176201375e-06,
      "loss": 0.0004,
      "step": 3660
    },
    {
      "epoch": 8.39816933638444,
      "grad_norm": 0.009699073620140553,
      "learning_rate": 3.2036613272311218e-06,
      "loss": 0.0001,
      "step": 3670
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 0.011987321078777313,
      "learning_rate": 3.157894736842105e-06,
      "loss": 0.0124,
      "step": 3680
    },
    {
      "epoch": 8.443935926773456,
      "grad_norm": 0.0016795204719528556,
      "learning_rate": 3.1121281464530894e-06,
      "loss": 0.0062,
      "step": 3690
    },
    {
      "epoch": 8.466819221967963,
      "grad_norm": 0.5637078285217285,
      "learning_rate": 3.0663615560640737e-06,
      "loss": 0.0024,
      "step": 3700
    },
    {
      "epoch": 8.48970251716247,
      "grad_norm": 0.0016633376944810152,
      "learning_rate": 3.020594965675058e-06,
      "loss": 0.0166,
      "step": 3710
    },
    {
      "epoch": 8.51258581235698,
      "grad_norm": 0.017218170687556267,
      "learning_rate": 2.9748283752860413e-06,
      "loss": 0.0033,
      "step": 3720
    },
    {
      "epoch": 8.535469107551487,
      "grad_norm": 0.0024097836576402187,
      "learning_rate": 2.9290617848970256e-06,
      "loss": 0.0065,
      "step": 3730
    },
    {
      "epoch": 8.558352402745996,
      "grad_norm": 0.0077650900930166245,
      "learning_rate": 2.8832951945080094e-06,
      "loss": 0.0001,
      "step": 3740
    },
    {
      "epoch": 8.581235697940503,
      "grad_norm": 0.016781579703092575,
      "learning_rate": 2.8375286041189932e-06,
      "loss": 0.0032,
      "step": 3750
    },
    {
      "epoch": 8.604118993135012,
      "grad_norm": 0.001821775222197175,
      "learning_rate": 2.791762013729977e-06,
      "loss": 0.0001,
      "step": 3760
    },
    {
      "epoch": 8.62700228832952,
      "grad_norm": 0.0022027711383998394,
      "learning_rate": 2.7459954233409613e-06,
      "loss": 0.004,
      "step": 3770
    },
    {
      "epoch": 8.649885583524027,
      "grad_norm": 0.021752340719103813,
      "learning_rate": 2.7002288329519456e-06,
      "loss": 0.0147,
      "step": 3780
    },
    {
      "epoch": 8.672768878718536,
      "grad_norm": 0.023639317601919174,
      "learning_rate": 2.654462242562929e-06,
      "loss": 0.0001,
      "step": 3790
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.002217981033027172,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 0.0001,
      "step": 3800
    },
    {
      "epoch": 8.718535469107552,
      "grad_norm": 19.14315414428711,
      "learning_rate": 2.5629290617848975e-06,
      "loss": 0.0159,
      "step": 3810
    },
    {
      "epoch": 8.74141876430206,
      "grad_norm": 0.22712022066116333,
      "learning_rate": 2.5171624713958813e-06,
      "loss": 0.0032,
      "step": 3820
    },
    {
      "epoch": 8.764302059496568,
      "grad_norm": 0.0035705226473510265,
      "learning_rate": 2.471395881006865e-06,
      "loss": 0.0001,
      "step": 3830
    },
    {
      "epoch": 8.787185354691076,
      "grad_norm": 3.775629997253418,
      "learning_rate": 2.425629290617849e-06,
      "loss": 0.0083,
      "step": 3840
    },
    {
      "epoch": 8.810068649885583,
      "grad_norm": 0.0008630981319583952,
      "learning_rate": 2.3798627002288332e-06,
      "loss": 0.0049,
      "step": 3850
    },
    {
      "epoch": 8.832951945080092,
      "grad_norm": 0.006455407477915287,
      "learning_rate": 2.334096109839817e-06,
      "loss": 0.0006,
      "step": 3860
    },
    {
      "epoch": 8.8558352402746,
      "grad_norm": 0.0011654311092570424,
      "learning_rate": 2.2883295194508013e-06,
      "loss": 0.0021,
      "step": 3870
    },
    {
      "epoch": 8.878718535469108,
      "grad_norm": 0.03483037278056145,
      "learning_rate": 2.242562929061785e-06,
      "loss": 0.0102,
      "step": 3880
    },
    {
      "epoch": 8.901601830663616,
      "grad_norm": 0.02276315912604332,
      "learning_rate": 2.196796338672769e-06,
      "loss": 0.013,
      "step": 3890
    },
    {
      "epoch": 8.924485125858123,
      "grad_norm": 0.025127677246928215,
      "learning_rate": 2.1510297482837532e-06,
      "loss": 0.0292,
      "step": 3900
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 0.00899253785610199,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 8.97025171624714,
      "grad_norm": 0.004118326585739851,
      "learning_rate": 2.059496567505721e-06,
      "loss": 0.0179,
      "step": 3920
    },
    {
      "epoch": 8.993135011441648,
      "grad_norm": 1.2719252109527588,
      "learning_rate": 2.0137299771167047e-06,
      "loss": 0.0055,
      "step": 3930
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9706666666666667,
      "eval_f1": 0.8620689655172413,
      "eval_loss": 0.229704350233078,
      "eval_precision": 0.8986928104575164,
      "eval_recall": 0.8283132530120482,
      "eval_runtime": 402.4031,
      "eval_samples_per_second": 7.455,
      "eval_steps_per_second": 0.932,
      "step": 3933
    },
    {
      "epoch": 9.016018306636155,
      "grad_norm": 0.016214195638895035,
      "learning_rate": 1.967963386727689e-06,
      "loss": 0.0036,
      "step": 3940
    },
    {
      "epoch": 9.038901601830664,
      "grad_norm": 0.009313938207924366,
      "learning_rate": 1.922196796338673e-06,
      "loss": 0.0002,
      "step": 3950
    },
    {
      "epoch": 9.061784897025172,
      "grad_norm": 0.010564228519797325,
      "learning_rate": 1.876430205949657e-06,
      "loss": 0.0001,
      "step": 3960
    },
    {
      "epoch": 9.084668192219679,
      "grad_norm": 0.07054386287927628,
      "learning_rate": 1.8306636155606409e-06,
      "loss": 0.0034,
      "step": 3970
    },
    {
      "epoch": 9.107551487414188,
      "grad_norm": 20.141937255859375,
      "learning_rate": 1.784897025171625e-06,
      "loss": 0.0069,
      "step": 3980
    },
    {
      "epoch": 9.130434782608695,
      "grad_norm": 0.09030373394489288,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 0.0011,
      "step": 3990
    },
    {
      "epoch": 9.153318077803204,
      "grad_norm": 0.008093852549791336,
      "learning_rate": 1.693363844393593e-06,
      "loss": 0.0033,
      "step": 4000
    },
    {
      "epoch": 9.176201372997712,
      "grad_norm": 0.011449487879872322,
      "learning_rate": 1.6475972540045768e-06,
      "loss": 0.0001,
      "step": 4010
    },
    {
      "epoch": 9.199084668192219,
      "grad_norm": 0.0011132600484415889,
      "learning_rate": 1.6018306636155609e-06,
      "loss": 0.0,
      "step": 4020
    },
    {
      "epoch": 9.221967963386728,
      "grad_norm": 0.001923037925735116,
      "learning_rate": 1.5560640732265447e-06,
      "loss": 0.0014,
      "step": 4030
    },
    {
      "epoch": 9.244851258581235,
      "grad_norm": 0.09664095193147659,
      "learning_rate": 1.510297482837529e-06,
      "loss": 0.0003,
      "step": 4040
    },
    {
      "epoch": 9.267734553775744,
      "grad_norm": 0.010144715197384357,
      "learning_rate": 1.4645308924485128e-06,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 9.290617848970252,
      "grad_norm": 0.01873716711997986,
      "learning_rate": 1.4187643020594966e-06,
      "loss": 0.0,
      "step": 4060
    },
    {
      "epoch": 9.31350114416476,
      "grad_norm": 0.0009955415735021234,
      "learning_rate": 1.3729977116704807e-06,
      "loss": 0.0009,
      "step": 4070
    },
    {
      "epoch": 9.336384439359268,
      "grad_norm": 0.000602436950430274,
      "learning_rate": 1.3272311212814645e-06,
      "loss": 0.0001,
      "step": 4080
    },
    {
      "epoch": 9.359267734553775,
      "grad_norm": 0.014427517540752888,
      "learning_rate": 1.2814645308924487e-06,
      "loss": 0.004,
      "step": 4090
    },
    {
      "epoch": 9.382151029748284,
      "grad_norm": 0.031321436166763306,
      "learning_rate": 1.2356979405034326e-06,
      "loss": 0.0149,
      "step": 4100
    },
    {
      "epoch": 9.405034324942791,
      "grad_norm": 0.012708274647593498,
      "learning_rate": 1.1899313501144166e-06,
      "loss": 0.0003,
      "step": 4110
    },
    {
      "epoch": 9.4279176201373,
      "grad_norm": 0.0009221156360581517,
      "learning_rate": 1.1441647597254007e-06,
      "loss": 0.0019,
      "step": 4120
    },
    {
      "epoch": 9.450800915331808,
      "grad_norm": 0.0013599133817479014,
      "learning_rate": 1.0983981693363845e-06,
      "loss": 0.0001,
      "step": 4130
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 0.03666400536894798,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.004,
      "step": 4140
    },
    {
      "epoch": 9.496567505720824,
      "grad_norm": 0.000713588553480804,
      "learning_rate": 1.0068649885583524e-06,
      "loss": 0.0093,
      "step": 4150
    },
    {
      "epoch": 9.519450800915331,
      "grad_norm": 0.015817278996109962,
      "learning_rate": 9.610983981693364e-07,
      "loss": 0.0162,
      "step": 4160
    },
    {
      "epoch": 9.54233409610984,
      "grad_norm": 0.009818574413657188,
      "learning_rate": 9.153318077803204e-07,
      "loss": 0.0099,
      "step": 4170
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 0.005130237899720669,
      "learning_rate": 8.695652173913044e-07,
      "loss": 0.005,
      "step": 4180
    },
    {
      "epoch": 9.588100686498855,
      "grad_norm": 0.034720540046691895,
      "learning_rate": 8.237986270022884e-07,
      "loss": 0.0009,
      "step": 4190
    },
    {
      "epoch": 9.610983981693364,
      "grad_norm": 0.031633585691452026,
      "learning_rate": 7.780320366132724e-07,
      "loss": 0.0001,
      "step": 4200
    },
    {
      "epoch": 9.633867276887871,
      "grad_norm": 0.0020132416393607855,
      "learning_rate": 7.322654462242564e-07,
      "loss": 0.0008,
      "step": 4210
    },
    {
      "epoch": 9.65675057208238,
      "grad_norm": 0.5867128968238831,
      "learning_rate": 6.864988558352403e-07,
      "loss": 0.0002,
      "step": 4220
    },
    {
      "epoch": 9.679633867276888,
      "grad_norm": 0.03330330550670624,
      "learning_rate": 6.407322654462244e-07,
      "loss": 0.003,
      "step": 4230
    },
    {
      "epoch": 9.702517162471397,
      "grad_norm": 0.002413966227322817,
      "learning_rate": 5.949656750572083e-07,
      "loss": 0.0001,
      "step": 4240
    },
    {
      "epoch": 9.725400457665904,
      "grad_norm": 0.0016357839340344071,
      "learning_rate": 5.491990846681922e-07,
      "loss": 0.0004,
      "step": 4250
    },
    {
      "epoch": 9.748283752860411,
      "grad_norm": 4.614151954650879,
      "learning_rate": 5.034324942791762e-07,
      "loss": 0.001,
      "step": 4260
    },
    {
      "epoch": 9.77116704805492,
      "grad_norm": 0.02133418247103691,
      "learning_rate": 4.576659038901602e-07,
      "loss": 0.0,
      "step": 4270
    },
    {
      "epoch": 9.794050343249427,
      "grad_norm": 0.007444494869560003,
      "learning_rate": 4.118993135011442e-07,
      "loss": 0.0001,
      "step": 4280
    },
    {
      "epoch": 9.816933638443937,
      "grad_norm": 0.011219936423003674,
      "learning_rate": 3.661327231121282e-07,
      "loss": 0.0001,
      "step": 4290
    },
    {
      "epoch": 9.839816933638444,
      "grad_norm": 0.007733295671641827,
      "learning_rate": 3.203661327231122e-07,
      "loss": 0.0002,
      "step": 4300
    },
    {
      "epoch": 9.862700228832953,
      "grad_norm": 0.0007438616012223065,
      "learning_rate": 2.745995423340961e-07,
      "loss": 0.0211,
      "step": 4310
    },
    {
      "epoch": 9.88558352402746,
      "grad_norm": 0.001043760566972196,
      "learning_rate": 2.288329519450801e-07,
      "loss": 0.0121,
      "step": 4320
    },
    {
      "epoch": 9.908466819221967,
      "grad_norm": 0.2002553641796112,
      "learning_rate": 1.830663615560641e-07,
      "loss": 0.0001,
      "step": 4330
    },
    {
      "epoch": 9.931350114416476,
      "grad_norm": 0.06922270357608795,
      "learning_rate": 1.3729977116704806e-07,
      "loss": 0.0014,
      "step": 4340
    },
    {
      "epoch": 9.954233409610984,
      "grad_norm": 0.0011122662108391523,
      "learning_rate": 9.153318077803205e-08,
      "loss": 0.0124,
      "step": 4350
    },
    {
      "epoch": 9.977116704805493,
      "grad_norm": 0.1164097785949707,
      "learning_rate": 4.5766590389016025e-08,
      "loss": 0.0074,
      "step": 4360
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.685694694519043,
      "learning_rate": 0.0,
      "loss": 0.0005,
      "step": 4370
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9703333333333334,
      "eval_f1": 0.8632872503840247,
      "eval_loss": 0.23146802186965942,
      "eval_precision": 0.8808777429467085,
      "eval_recall": 0.8463855421686747,
      "eval_runtime": 394.8553,
      "eval_samples_per_second": 7.598,
      "eval_steps_per_second": 0.95,
      "step": 4370
    }
  ],
  "logging_steps": 10,
  "max_steps": 4370,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.156540899407104e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
