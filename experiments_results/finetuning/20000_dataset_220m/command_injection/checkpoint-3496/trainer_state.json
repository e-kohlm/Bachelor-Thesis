{
  "best_metric": 0.9041835357624831,
  "best_model_checkpoint": "../saved_models/command_injection/checkpoint-3496",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 3496,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002288329519450801,
      "grad_norm": 67.82654571533203,
      "learning_rate": 1.99954233409611e-05,
      "loss": 1.4159,
      "step": 1
    },
    {
      "epoch": 0.02288329519450801,
      "grad_norm": 22.623159408569336,
      "learning_rate": 1.9954233409610984e-05,
      "loss": 0.6448,
      "step": 10
    },
    {
      "epoch": 0.04576659038901602,
      "grad_norm": 29.521352767944336,
      "learning_rate": 1.990846681922197e-05,
      "loss": 0.5281,
      "step": 20
    },
    {
      "epoch": 0.06864988558352403,
      "grad_norm": 19.935747146606445,
      "learning_rate": 1.9862700228832953e-05,
      "loss": 0.4076,
      "step": 30
    },
    {
      "epoch": 0.09153318077803203,
      "grad_norm": 23.88459014892578,
      "learning_rate": 1.981693363844394e-05,
      "loss": 0.4539,
      "step": 40
    },
    {
      "epoch": 0.11441647597254005,
      "grad_norm": 25.67224884033203,
      "learning_rate": 1.977116704805492e-05,
      "loss": 0.4121,
      "step": 50
    },
    {
      "epoch": 0.13729977116704806,
      "grad_norm": 134.5426483154297,
      "learning_rate": 1.9725400457665907e-05,
      "loss": 0.3929,
      "step": 60
    },
    {
      "epoch": 0.16018306636155608,
      "grad_norm": 23.559322357177734,
      "learning_rate": 1.967963386727689e-05,
      "loss": 0.446,
      "step": 70
    },
    {
      "epoch": 0.18306636155606407,
      "grad_norm": 16.92341423034668,
      "learning_rate": 1.9633867276887872e-05,
      "loss": 0.4615,
      "step": 80
    },
    {
      "epoch": 0.20594965675057209,
      "grad_norm": 234.07582092285156,
      "learning_rate": 1.9588100686498858e-05,
      "loss": 0.3465,
      "step": 90
    },
    {
      "epoch": 0.2288329519450801,
      "grad_norm": 13.571483612060547,
      "learning_rate": 1.954233409610984e-05,
      "loss": 0.3274,
      "step": 100
    },
    {
      "epoch": 0.2517162471395881,
      "grad_norm": 13.287558555603027,
      "learning_rate": 1.9496567505720823e-05,
      "loss": 0.3997,
      "step": 110
    },
    {
      "epoch": 0.2745995423340961,
      "grad_norm": 17.708553314208984,
      "learning_rate": 1.945080091533181e-05,
      "loss": 0.4499,
      "step": 120
    },
    {
      "epoch": 0.2974828375286041,
      "grad_norm": 20.28679847717285,
      "learning_rate": 1.9405034324942792e-05,
      "loss": 0.4302,
      "step": 130
    },
    {
      "epoch": 0.32036613272311215,
      "grad_norm": 11.211244583129883,
      "learning_rate": 1.9359267734553778e-05,
      "loss": 0.4504,
      "step": 140
    },
    {
      "epoch": 0.34324942791762014,
      "grad_norm": 15.369696617126465,
      "learning_rate": 1.931350114416476e-05,
      "loss": 0.3001,
      "step": 150
    },
    {
      "epoch": 0.36613272311212813,
      "grad_norm": 17.832834243774414,
      "learning_rate": 1.9267734553775746e-05,
      "loss": 0.4315,
      "step": 160
    },
    {
      "epoch": 0.3890160183066362,
      "grad_norm": 30.47638702392578,
      "learning_rate": 1.922196796338673e-05,
      "loss": 0.4139,
      "step": 170
    },
    {
      "epoch": 0.41189931350114417,
      "grad_norm": 16.817731857299805,
      "learning_rate": 1.9176201372997715e-05,
      "loss": 0.4002,
      "step": 180
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 9.931997299194336,
      "learning_rate": 1.9130434782608697e-05,
      "loss": 0.3926,
      "step": 190
    },
    {
      "epoch": 0.4576659038901602,
      "grad_norm": 9.108497619628906,
      "learning_rate": 1.9084668192219683e-05,
      "loss": 0.3405,
      "step": 200
    },
    {
      "epoch": 0.4805491990846682,
      "grad_norm": 9.08980941772461,
      "learning_rate": 1.9038901601830666e-05,
      "loss": 0.3533,
      "step": 210
    },
    {
      "epoch": 0.5034324942791762,
      "grad_norm": 22.972763061523438,
      "learning_rate": 1.8993135011441652e-05,
      "loss": 0.3366,
      "step": 220
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 7.709705829620361,
      "learning_rate": 1.894736842105263e-05,
      "loss": 0.3286,
      "step": 230
    },
    {
      "epoch": 0.5491990846681922,
      "grad_norm": 13.917174339294434,
      "learning_rate": 1.8901601830663617e-05,
      "loss": 0.3506,
      "step": 240
    },
    {
      "epoch": 0.5720823798627003,
      "grad_norm": 28.123981475830078,
      "learning_rate": 1.88558352402746e-05,
      "loss": 0.3394,
      "step": 250
    },
    {
      "epoch": 0.5949656750572082,
      "grad_norm": 9.198965072631836,
      "learning_rate": 1.8810068649885585e-05,
      "loss": 0.3922,
      "step": 260
    },
    {
      "epoch": 0.6178489702517163,
      "grad_norm": 8.080222129821777,
      "learning_rate": 1.8764302059496568e-05,
      "loss": 0.3577,
      "step": 270
    },
    {
      "epoch": 0.6407322654462243,
      "grad_norm": 8.224720001220703,
      "learning_rate": 1.8718535469107554e-05,
      "loss": 0.3479,
      "step": 280
    },
    {
      "epoch": 0.6636155606407322,
      "grad_norm": 8.34076976776123,
      "learning_rate": 1.8672768878718537e-05,
      "loss": 0.3629,
      "step": 290
    },
    {
      "epoch": 0.6864988558352403,
      "grad_norm": 9.884564399719238,
      "learning_rate": 1.8627002288329522e-05,
      "loss": 0.354,
      "step": 300
    },
    {
      "epoch": 0.7093821510297483,
      "grad_norm": 6.644557476043701,
      "learning_rate": 1.8581235697940505e-05,
      "loss": 0.3149,
      "step": 310
    },
    {
      "epoch": 0.7322654462242563,
      "grad_norm": 11.946968078613281,
      "learning_rate": 1.8535469107551488e-05,
      "loss": 0.3312,
      "step": 320
    },
    {
      "epoch": 0.7551487414187643,
      "grad_norm": 18.332050323486328,
      "learning_rate": 1.8489702517162474e-05,
      "loss": 0.3112,
      "step": 330
    },
    {
      "epoch": 0.7780320366132724,
      "grad_norm": 4.874045372009277,
      "learning_rate": 1.8443935926773456e-05,
      "loss": 0.2442,
      "step": 340
    },
    {
      "epoch": 0.8009153318077803,
      "grad_norm": 6.304730415344238,
      "learning_rate": 1.8398169336384442e-05,
      "loss": 0.3038,
      "step": 350
    },
    {
      "epoch": 0.8237986270022883,
      "grad_norm": 6.65995454788208,
      "learning_rate": 1.8352402745995425e-05,
      "loss": 0.2889,
      "step": 360
    },
    {
      "epoch": 0.8466819221967964,
      "grad_norm": 10.249363899230957,
      "learning_rate": 1.830663615560641e-05,
      "loss": 0.32,
      "step": 370
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 5.926332473754883,
      "learning_rate": 1.8260869565217393e-05,
      "loss": 0.3068,
      "step": 380
    },
    {
      "epoch": 0.8924485125858124,
      "grad_norm": 12.417009353637695,
      "learning_rate": 1.8215102974828376e-05,
      "loss": 0.2797,
      "step": 390
    },
    {
      "epoch": 0.9153318077803204,
      "grad_norm": 7.032578945159912,
      "learning_rate": 1.816933638443936e-05,
      "loss": 0.2364,
      "step": 400
    },
    {
      "epoch": 0.9382151029748284,
      "grad_norm": 4.679418087005615,
      "learning_rate": 1.8123569794050344e-05,
      "loss": 0.2308,
      "step": 410
    },
    {
      "epoch": 0.9610983981693364,
      "grad_norm": 4.446414947509766,
      "learning_rate": 1.8077803203661327e-05,
      "loss": 0.27,
      "step": 420
    },
    {
      "epoch": 0.9839816933638444,
      "grad_norm": 8.390576362609863,
      "learning_rate": 1.8032036613272313e-05,
      "loss": 0.2751,
      "step": 430
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9073333333333333,
      "eval_f1": 0.4813432835820896,
      "eval_loss": 0.25575900077819824,
      "eval_precision": 0.821656050955414,
      "eval_recall": 0.3403693931398417,
      "eval_runtime": 587.2957,
      "eval_samples_per_second": 5.108,
      "eval_steps_per_second": 0.639,
      "step": 437
    },
    {
      "epoch": 1.0068649885583525,
      "grad_norm": 5.722803115844727,
      "learning_rate": 1.7986270022883295e-05,
      "loss": 0.2827,
      "step": 440
    },
    {
      "epoch": 1.0297482837528604,
      "grad_norm": 8.798386573791504,
      "learning_rate": 1.794050343249428e-05,
      "loss": 0.2927,
      "step": 450
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 4.803518772125244,
      "learning_rate": 1.7894736842105264e-05,
      "loss": 0.2538,
      "step": 460
    },
    {
      "epoch": 1.0755148741418765,
      "grad_norm": 7.252923011779785,
      "learning_rate": 1.784897025171625e-05,
      "loss": 0.3013,
      "step": 470
    },
    {
      "epoch": 1.0983981693363845,
      "grad_norm": 6.409665107727051,
      "learning_rate": 1.7803203661327232e-05,
      "loss": 0.2045,
      "step": 480
    },
    {
      "epoch": 1.1212814645308924,
      "grad_norm": 8.432514190673828,
      "learning_rate": 1.7757437070938218e-05,
      "loss": 0.2458,
      "step": 490
    },
    {
      "epoch": 1.1441647597254005,
      "grad_norm": 8.516518592834473,
      "learning_rate": 1.77116704805492e-05,
      "loss": 0.2312,
      "step": 500
    },
    {
      "epoch": 1.1670480549199085,
      "grad_norm": 7.110820293426514,
      "learning_rate": 1.7665903890160187e-05,
      "loss": 0.2581,
      "step": 510
    },
    {
      "epoch": 1.1899313501144164,
      "grad_norm": 4.961585521697998,
      "learning_rate": 1.762013729977117e-05,
      "loss": 0.2267,
      "step": 520
    },
    {
      "epoch": 1.2128146453089246,
      "grad_norm": 6.64039421081543,
      "learning_rate": 1.7574370709382152e-05,
      "loss": 0.3062,
      "step": 530
    },
    {
      "epoch": 1.2356979405034325,
      "grad_norm": 7.297259330749512,
      "learning_rate": 1.7528604118993134e-05,
      "loss": 0.2702,
      "step": 540
    },
    {
      "epoch": 1.2585812356979404,
      "grad_norm": 6.222190856933594,
      "learning_rate": 1.748283752860412e-05,
      "loss": 0.2212,
      "step": 550
    },
    {
      "epoch": 1.2814645308924484,
      "grad_norm": 9.027602195739746,
      "learning_rate": 1.7437070938215103e-05,
      "loss": 0.2215,
      "step": 560
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 6.441245079040527,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.2349,
      "step": 570
    },
    {
      "epoch": 1.3272311212814645,
      "grad_norm": 9.456158638000488,
      "learning_rate": 1.734553775743707e-05,
      "loss": 0.1723,
      "step": 580
    },
    {
      "epoch": 1.3501144164759724,
      "grad_norm": 4.916919708251953,
      "learning_rate": 1.7299771167048057e-05,
      "loss": 0.1737,
      "step": 590
    },
    {
      "epoch": 1.3729977116704806,
      "grad_norm": 4.994007587432861,
      "learning_rate": 1.725400457665904e-05,
      "loss": 0.2355,
      "step": 600
    },
    {
      "epoch": 1.3958810068649885,
      "grad_norm": 7.055683135986328,
      "learning_rate": 1.7208237986270026e-05,
      "loss": 0.2181,
      "step": 610
    },
    {
      "epoch": 1.4187643020594964,
      "grad_norm": 7.941903591156006,
      "learning_rate": 1.716247139588101e-05,
      "loss": 0.1488,
      "step": 620
    },
    {
      "epoch": 1.4416475972540046,
      "grad_norm": 7.226171970367432,
      "learning_rate": 1.7116704805491994e-05,
      "loss": 0.1535,
      "step": 630
    },
    {
      "epoch": 1.4645308924485125,
      "grad_norm": 6.558609485626221,
      "learning_rate": 1.7070938215102977e-05,
      "loss": 0.1874,
      "step": 640
    },
    {
      "epoch": 1.4874141876430205,
      "grad_norm": 10.367595672607422,
      "learning_rate": 1.702517162471396e-05,
      "loss": 0.188,
      "step": 650
    },
    {
      "epoch": 1.5102974828375286,
      "grad_norm": 11.590010643005371,
      "learning_rate": 1.6979405034324945e-05,
      "loss": 0.2556,
      "step": 660
    },
    {
      "epoch": 1.5331807780320366,
      "grad_norm": 5.892457962036133,
      "learning_rate": 1.6933638443935928e-05,
      "loss": 0.1973,
      "step": 670
    },
    {
      "epoch": 1.5560640732265445,
      "grad_norm": 3.3509984016418457,
      "learning_rate": 1.688787185354691e-05,
      "loss": 0.1638,
      "step": 680
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 6.216709613800049,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.1832,
      "step": 690
    },
    {
      "epoch": 1.6018306636155606,
      "grad_norm": 7.419618606567383,
      "learning_rate": 1.679633867276888e-05,
      "loss": 0.1817,
      "step": 700
    },
    {
      "epoch": 1.6247139588100685,
      "grad_norm": 6.54814338684082,
      "learning_rate": 1.6750572082379865e-05,
      "loss": 0.1989,
      "step": 710
    },
    {
      "epoch": 1.6475972540045767,
      "grad_norm": 6.241817951202393,
      "learning_rate": 1.6704805491990848e-05,
      "loss": 0.208,
      "step": 720
    },
    {
      "epoch": 1.6704805491990846,
      "grad_norm": 4.770610809326172,
      "learning_rate": 1.665903890160183e-05,
      "loss": 0.2136,
      "step": 730
    },
    {
      "epoch": 1.6933638443935926,
      "grad_norm": 6.758936882019043,
      "learning_rate": 1.6613272311212816e-05,
      "loss": 0.175,
      "step": 740
    },
    {
      "epoch": 1.7162471395881007,
      "grad_norm": 6.621975421905518,
      "learning_rate": 1.65675057208238e-05,
      "loss": 0.1386,
      "step": 750
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 5.7610087394714355,
      "learning_rate": 1.6521739130434785e-05,
      "loss": 0.1608,
      "step": 760
    },
    {
      "epoch": 1.7620137299771166,
      "grad_norm": 6.220501899719238,
      "learning_rate": 1.6475972540045767e-05,
      "loss": 0.1536,
      "step": 770
    },
    {
      "epoch": 1.7848970251716247,
      "grad_norm": 2.661421298980713,
      "learning_rate": 1.6430205949656753e-05,
      "loss": 0.1589,
      "step": 780
    },
    {
      "epoch": 1.8077803203661327,
      "grad_norm": 6.782078742980957,
      "learning_rate": 1.6384439359267736e-05,
      "loss": 0.1556,
      "step": 790
    },
    {
      "epoch": 1.8306636155606406,
      "grad_norm": 7.393075466156006,
      "learning_rate": 1.633867276887872e-05,
      "loss": 0.1446,
      "step": 800
    },
    {
      "epoch": 1.8535469107551488,
      "grad_norm": 12.18712329864502,
      "learning_rate": 1.6292906178489704e-05,
      "loss": 0.1716,
      "step": 810
    },
    {
      "epoch": 1.8764302059496567,
      "grad_norm": 8.299843788146973,
      "learning_rate": 1.624713958810069e-05,
      "loss": 0.1736,
      "step": 820
    },
    {
      "epoch": 1.8993135011441646,
      "grad_norm": 9.085920333862305,
      "learning_rate": 1.620137299771167e-05,
      "loss": 0.1367,
      "step": 830
    },
    {
      "epoch": 1.9221967963386728,
      "grad_norm": 6.160684108734131,
      "learning_rate": 1.6155606407322655e-05,
      "loss": 0.1368,
      "step": 840
    },
    {
      "epoch": 1.9450800915331807,
      "grad_norm": 6.406018257141113,
      "learning_rate": 1.6109839816933638e-05,
      "loss": 0.1359,
      "step": 850
    },
    {
      "epoch": 1.9679633867276887,
      "grad_norm": 10.10585880279541,
      "learning_rate": 1.6064073226544624e-05,
      "loss": 0.1346,
      "step": 860
    },
    {
      "epoch": 1.9908466819221968,
      "grad_norm": 3.2816622257232666,
      "learning_rate": 1.6018306636155606e-05,
      "loss": 0.1234,
      "step": 870
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9453333333333334,
      "eval_f1": 0.7602339181286549,
      "eval_loss": 0.17042049765586853,
      "eval_precision": 0.8524590163934426,
      "eval_recall": 0.6860158311345647,
      "eval_runtime": 588.7709,
      "eval_samples_per_second": 5.095,
      "eval_steps_per_second": 0.637,
      "step": 874
    },
    {
      "epoch": 2.013729977116705,
      "grad_norm": 3.734145164489746,
      "learning_rate": 1.5972540045766592e-05,
      "loss": 0.1175,
      "step": 880
    },
    {
      "epoch": 2.0366132723112127,
      "grad_norm": 6.922421455383301,
      "learning_rate": 1.5926773455377575e-05,
      "loss": 0.1412,
      "step": 890
    },
    {
      "epoch": 2.059496567505721,
      "grad_norm": 2.4196979999542236,
      "learning_rate": 1.588100686498856e-05,
      "loss": 0.1139,
      "step": 900
    },
    {
      "epoch": 2.082379862700229,
      "grad_norm": 9.508654594421387,
      "learning_rate": 1.5835240274599543e-05,
      "loss": 0.1629,
      "step": 910
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 8.354670524597168,
      "learning_rate": 1.578947368421053e-05,
      "loss": 0.1544,
      "step": 920
    },
    {
      "epoch": 2.128146453089245,
      "grad_norm": 10.694371223449707,
      "learning_rate": 1.5743707093821512e-05,
      "loss": 0.1315,
      "step": 930
    },
    {
      "epoch": 2.151029748283753,
      "grad_norm": 1.5650962591171265,
      "learning_rate": 1.5697940503432498e-05,
      "loss": 0.1615,
      "step": 940
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 4.8128557205200195,
      "learning_rate": 1.565217391304348e-05,
      "loss": 0.0988,
      "step": 950
    },
    {
      "epoch": 2.196796338672769,
      "grad_norm": 4.312042713165283,
      "learning_rate": 1.5606407322654463e-05,
      "loss": 0.1286,
      "step": 960
    },
    {
      "epoch": 2.219679633867277,
      "grad_norm": 9.908169746398926,
      "learning_rate": 1.556064073226545e-05,
      "loss": 0.0864,
      "step": 970
    },
    {
      "epoch": 2.242562929061785,
      "grad_norm": 6.261294841766357,
      "learning_rate": 1.551487414187643e-05,
      "loss": 0.0594,
      "step": 980
    },
    {
      "epoch": 2.265446224256293,
      "grad_norm": 6.3534440994262695,
      "learning_rate": 1.5469107551487414e-05,
      "loss": 0.0868,
      "step": 990
    },
    {
      "epoch": 2.288329519450801,
      "grad_norm": 0.4340019226074219,
      "learning_rate": 1.54233409610984e-05,
      "loss": 0.0511,
      "step": 1000
    },
    {
      "epoch": 2.311212814645309,
      "grad_norm": 13.20012092590332,
      "learning_rate": 1.5377574370709382e-05,
      "loss": 0.1984,
      "step": 1010
    },
    {
      "epoch": 2.334096109839817,
      "grad_norm": 6.377017498016357,
      "learning_rate": 1.533180778032037e-05,
      "loss": 0.1226,
      "step": 1020
    },
    {
      "epoch": 2.356979405034325,
      "grad_norm": 10.637371063232422,
      "learning_rate": 1.528604118993135e-05,
      "loss": 0.183,
      "step": 1030
    },
    {
      "epoch": 2.379862700228833,
      "grad_norm": 9.884025573730469,
      "learning_rate": 1.5240274599542335e-05,
      "loss": 0.1374,
      "step": 1040
    },
    {
      "epoch": 2.402745995423341,
      "grad_norm": 12.082139015197754,
      "learning_rate": 1.519450800915332e-05,
      "loss": 0.1292,
      "step": 1050
    },
    {
      "epoch": 2.425629290617849,
      "grad_norm": 10.6105318069458,
      "learning_rate": 1.5148741418764304e-05,
      "loss": 0.1206,
      "step": 1060
    },
    {
      "epoch": 2.448512585812357,
      "grad_norm": 9.956069946289062,
      "learning_rate": 1.5102974828375288e-05,
      "loss": 0.0705,
      "step": 1070
    },
    {
      "epoch": 2.471395881006865,
      "grad_norm": 6.2297797203063965,
      "learning_rate": 1.5057208237986272e-05,
      "loss": 0.1195,
      "step": 1080
    },
    {
      "epoch": 2.494279176201373,
      "grad_norm": 6.834155082702637,
      "learning_rate": 1.5011441647597256e-05,
      "loss": 0.1572,
      "step": 1090
    },
    {
      "epoch": 2.517162471395881,
      "grad_norm": 0.4699721336364746,
      "learning_rate": 1.496567505720824e-05,
      "loss": 0.0686,
      "step": 1100
    },
    {
      "epoch": 2.540045766590389,
      "grad_norm": 7.5695013999938965,
      "learning_rate": 1.4919908466819223e-05,
      "loss": 0.1418,
      "step": 1110
    },
    {
      "epoch": 2.5629290617848968,
      "grad_norm": 5.922999382019043,
      "learning_rate": 1.4874141876430207e-05,
      "loss": 0.1834,
      "step": 1120
    },
    {
      "epoch": 2.585812356979405,
      "grad_norm": 10.80413818359375,
      "learning_rate": 1.4828375286041192e-05,
      "loss": 0.1383,
      "step": 1130
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 9.809186935424805,
      "learning_rate": 1.4782608695652174e-05,
      "loss": 0.1186,
      "step": 1140
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 8.322257041931152,
      "learning_rate": 1.4736842105263159e-05,
      "loss": 0.0896,
      "step": 1150
    },
    {
      "epoch": 2.654462242562929,
      "grad_norm": 7.513802528381348,
      "learning_rate": 1.4691075514874143e-05,
      "loss": 0.1049,
      "step": 1160
    },
    {
      "epoch": 2.677345537757437,
      "grad_norm": 5.030442237854004,
      "learning_rate": 1.4645308924485127e-05,
      "loss": 0.0661,
      "step": 1170
    },
    {
      "epoch": 2.700228832951945,
      "grad_norm": 11.590282440185547,
      "learning_rate": 1.4599542334096111e-05,
      "loss": 0.1251,
      "step": 1180
    },
    {
      "epoch": 2.723112128146453,
      "grad_norm": 8.860011100769043,
      "learning_rate": 1.4553775743707096e-05,
      "loss": 0.0782,
      "step": 1190
    },
    {
      "epoch": 2.745995423340961,
      "grad_norm": 3.4118032455444336,
      "learning_rate": 1.4508009153318078e-05,
      "loss": 0.0931,
      "step": 1200
    },
    {
      "epoch": 2.7688787185354693,
      "grad_norm": 0.46840858459472656,
      "learning_rate": 1.4462242562929062e-05,
      "loss": 0.0815,
      "step": 1210
    },
    {
      "epoch": 2.791762013729977,
      "grad_norm": 8.347912788391113,
      "learning_rate": 1.4416475972540047e-05,
      "loss": 0.1365,
      "step": 1220
    },
    {
      "epoch": 2.814645308924485,
      "grad_norm": 6.94081449508667,
      "learning_rate": 1.4370709382151031e-05,
      "loss": 0.061,
      "step": 1230
    },
    {
      "epoch": 2.837528604118993,
      "grad_norm": 10.95274829864502,
      "learning_rate": 1.4324942791762015e-05,
      "loss": 0.0781,
      "step": 1240
    },
    {
      "epoch": 2.860411899313501,
      "grad_norm": 17.863401412963867,
      "learning_rate": 1.4279176201373e-05,
      "loss": 0.0983,
      "step": 1250
    },
    {
      "epoch": 2.883295194508009,
      "grad_norm": 2.6221537590026855,
      "learning_rate": 1.4233409610983984e-05,
      "loss": 0.0936,
      "step": 1260
    },
    {
      "epoch": 2.9061784897025174,
      "grad_norm": 9.396796226501465,
      "learning_rate": 1.4187643020594968e-05,
      "loss": 0.1538,
      "step": 1270
    },
    {
      "epoch": 2.929061784897025,
      "grad_norm": 6.6387619972229,
      "learning_rate": 1.4141876430205952e-05,
      "loss": 0.0523,
      "step": 1280
    },
    {
      "epoch": 2.9519450800915332,
      "grad_norm": 12.567229270935059,
      "learning_rate": 1.4096109839816933e-05,
      "loss": 0.073,
      "step": 1290
    },
    {
      "epoch": 2.974828375286041,
      "grad_norm": 0.19381748139858246,
      "learning_rate": 1.4050343249427917e-05,
      "loss": 0.0676,
      "step": 1300
    },
    {
      "epoch": 2.997711670480549,
      "grad_norm": 8.520490646362305,
      "learning_rate": 1.4004576659038902e-05,
      "loss": 0.2365,
      "step": 1310
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9523333333333334,
      "eval_f1": 0.8236744759556104,
      "eval_loss": 0.1457066535949707,
      "eval_precision": 0.7731481481481481,
      "eval_recall": 0.8812664907651715,
      "eval_runtime": 594.1805,
      "eval_samples_per_second": 5.049,
      "eval_steps_per_second": 0.631,
      "step": 1311
    },
    {
      "epoch": 3.0205949656750573,
      "grad_norm": 1.701581597328186,
      "learning_rate": 1.3958810068649886e-05,
      "loss": 0.0455,
      "step": 1320
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 2.392787218093872,
      "learning_rate": 1.391304347826087e-05,
      "loss": 0.1203,
      "step": 1330
    },
    {
      "epoch": 3.066361556064073,
      "grad_norm": 11.640680313110352,
      "learning_rate": 1.3867276887871854e-05,
      "loss": 0.0801,
      "step": 1340
    },
    {
      "epoch": 3.0892448512585813,
      "grad_norm": 90.0174560546875,
      "learning_rate": 1.3821510297482839e-05,
      "loss": 0.0584,
      "step": 1350
    },
    {
      "epoch": 3.1121281464530894,
      "grad_norm": 1.1566424369812012,
      "learning_rate": 1.3775743707093823e-05,
      "loss": 0.0582,
      "step": 1360
    },
    {
      "epoch": 3.135011441647597,
      "grad_norm": 0.7617319226264954,
      "learning_rate": 1.3729977116704807e-05,
      "loss": 0.0554,
      "step": 1370
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 1.719679594039917,
      "learning_rate": 1.3684210526315791e-05,
      "loss": 0.0519,
      "step": 1380
    },
    {
      "epoch": 3.1807780320366135,
      "grad_norm": 14.127832412719727,
      "learning_rate": 1.3638443935926776e-05,
      "loss": 0.0824,
      "step": 1390
    },
    {
      "epoch": 3.203661327231121,
      "grad_norm": 3.8961477279663086,
      "learning_rate": 1.359267734553776e-05,
      "loss": 0.1091,
      "step": 1400
    },
    {
      "epoch": 3.2265446224256293,
      "grad_norm": 3.271733522415161,
      "learning_rate": 1.3546910755148744e-05,
      "loss": 0.0466,
      "step": 1410
    },
    {
      "epoch": 3.2494279176201375,
      "grad_norm": 3.442035436630249,
      "learning_rate": 1.3501144164759727e-05,
      "loss": 0.0415,
      "step": 1420
    },
    {
      "epoch": 3.272311212814645,
      "grad_norm": 8.603757858276367,
      "learning_rate": 1.3455377574370711e-05,
      "loss": 0.0418,
      "step": 1430
    },
    {
      "epoch": 3.2951945080091534,
      "grad_norm": 7.082554817199707,
      "learning_rate": 1.3409610983981693e-05,
      "loss": 0.1,
      "step": 1440
    },
    {
      "epoch": 3.3180778032036615,
      "grad_norm": 12.647594451904297,
      "learning_rate": 1.3363844393592678e-05,
      "loss": 0.0559,
      "step": 1450
    },
    {
      "epoch": 3.3409610983981692,
      "grad_norm": 0.26877543330192566,
      "learning_rate": 1.3318077803203662e-05,
      "loss": 0.0436,
      "step": 1460
    },
    {
      "epoch": 3.3638443935926774,
      "grad_norm": 7.087852478027344,
      "learning_rate": 1.3272311212814646e-05,
      "loss": 0.0634,
      "step": 1470
    },
    {
      "epoch": 3.386727688787185,
      "grad_norm": 8.936997413635254,
      "learning_rate": 1.322654462242563e-05,
      "loss": 0.1851,
      "step": 1480
    },
    {
      "epoch": 3.4096109839816933,
      "grad_norm": 7.680881023406982,
      "learning_rate": 1.3180778032036615e-05,
      "loss": 0.1099,
      "step": 1490
    },
    {
      "epoch": 3.4324942791762014,
      "grad_norm": 6.967147350311279,
      "learning_rate": 1.3135011441647599e-05,
      "loss": 0.0622,
      "step": 1500
    },
    {
      "epoch": 3.4553775743707096,
      "grad_norm": 5.990661144256592,
      "learning_rate": 1.3089244851258582e-05,
      "loss": 0.0575,
      "step": 1510
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 5.018080234527588,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.0403,
      "step": 1520
    },
    {
      "epoch": 3.5011441647597255,
      "grad_norm": 7.247599124908447,
      "learning_rate": 1.299771167048055e-05,
      "loss": 0.0822,
      "step": 1530
    },
    {
      "epoch": 3.524027459954233,
      "grad_norm": 0.27935677766799927,
      "learning_rate": 1.2951945080091534e-05,
      "loss": 0.1028,
      "step": 1540
    },
    {
      "epoch": 3.5469107551487413,
      "grad_norm": 0.49635836482048035,
      "learning_rate": 1.2906178489702519e-05,
      "loss": 0.0709,
      "step": 1550
    },
    {
      "epoch": 3.5697940503432495,
      "grad_norm": 9.848182678222656,
      "learning_rate": 1.2860411899313503e-05,
      "loss": 0.1046,
      "step": 1560
    },
    {
      "epoch": 3.5926773455377576,
      "grad_norm": 2.905050277709961,
      "learning_rate": 1.2814645308924487e-05,
      "loss": 0.0371,
      "step": 1570
    },
    {
      "epoch": 3.6155606407322654,
      "grad_norm": 13.326056480407715,
      "learning_rate": 1.2768878718535471e-05,
      "loss": 0.0761,
      "step": 1580
    },
    {
      "epoch": 3.6384439359267735,
      "grad_norm": 1.3309128284454346,
      "learning_rate": 1.2723112128146454e-05,
      "loss": 0.0482,
      "step": 1590
    },
    {
      "epoch": 3.6613272311212812,
      "grad_norm": 12.695815086364746,
      "learning_rate": 1.2677345537757438e-05,
      "loss": 0.1062,
      "step": 1600
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 5.988350868225098,
      "learning_rate": 1.263157894736842e-05,
      "loss": 0.0627,
      "step": 1610
    },
    {
      "epoch": 3.7070938215102975,
      "grad_norm": 10.156980514526367,
      "learning_rate": 1.2585812356979405e-05,
      "loss": 0.0566,
      "step": 1620
    },
    {
      "epoch": 3.7299771167048057,
      "grad_norm": 0.08305074274539948,
      "learning_rate": 1.254004576659039e-05,
      "loss": 0.0665,
      "step": 1630
    },
    {
      "epoch": 3.7528604118993134,
      "grad_norm": 8.503275871276855,
      "learning_rate": 1.2494279176201373e-05,
      "loss": 0.0828,
      "step": 1640
    },
    {
      "epoch": 3.7757437070938216,
      "grad_norm": 0.11831003427505493,
      "learning_rate": 1.2448512585812358e-05,
      "loss": 0.0167,
      "step": 1650
    },
    {
      "epoch": 3.7986270022883293,
      "grad_norm": 0.24213333427906036,
      "learning_rate": 1.2402745995423342e-05,
      "loss": 0.0731,
      "step": 1660
    },
    {
      "epoch": 3.8215102974828374,
      "grad_norm": 2.6062254905700684,
      "learning_rate": 1.2356979405034326e-05,
      "loss": 0.1013,
      "step": 1670
    },
    {
      "epoch": 3.8443935926773456,
      "grad_norm": 0.8883655667304993,
      "learning_rate": 1.231121281464531e-05,
      "loss": 0.0594,
      "step": 1680
    },
    {
      "epoch": 3.8672768878718538,
      "grad_norm": 6.257089614868164,
      "learning_rate": 1.2265446224256295e-05,
      "loss": 0.0724,
      "step": 1690
    },
    {
      "epoch": 3.8901601830663615,
      "grad_norm": 6.034675121307373,
      "learning_rate": 1.2219679633867279e-05,
      "loss": 0.075,
      "step": 1700
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 2.634281873703003,
      "learning_rate": 1.2173913043478263e-05,
      "loss": 0.1011,
      "step": 1710
    },
    {
      "epoch": 3.9359267734553773,
      "grad_norm": 7.548056125640869,
      "learning_rate": 1.2128146453089247e-05,
      "loss": 0.0705,
      "step": 1720
    },
    {
      "epoch": 3.9588100686498855,
      "grad_norm": 0.26039135456085205,
      "learning_rate": 1.2082379862700232e-05,
      "loss": 0.0513,
      "step": 1730
    },
    {
      "epoch": 3.9816933638443937,
      "grad_norm": 7.934882640838623,
      "learning_rate": 1.2036613272311213e-05,
      "loss": 0.1037,
      "step": 1740
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.958,
      "eval_f1": 0.8444444444444444,
      "eval_loss": 0.15170331299304962,
      "eval_precision": 0.7935034802784223,
      "eval_recall": 0.9023746701846965,
      "eval_runtime": 840.2432,
      "eval_samples_per_second": 3.57,
      "eval_steps_per_second": 0.446,
      "step": 1748
    },
    {
      "epoch": 4.004576659038902,
      "grad_norm": 0.35039573907852173,
      "learning_rate": 1.1990846681922197e-05,
      "loss": 0.0288,
      "step": 1750
    },
    {
      "epoch": 4.02745995423341,
      "grad_norm": 0.17965872585773468,
      "learning_rate": 1.1945080091533181e-05,
      "loss": 0.0426,
      "step": 1760
    },
    {
      "epoch": 4.050343249427917,
      "grad_norm": 0.6393327116966248,
      "learning_rate": 1.1899313501144165e-05,
      "loss": 0.0425,
      "step": 1770
    },
    {
      "epoch": 4.073226544622425,
      "grad_norm": 0.28272926807403564,
      "learning_rate": 1.185354691075515e-05,
      "loss": 0.0116,
      "step": 1780
    },
    {
      "epoch": 4.0961098398169336,
      "grad_norm": 0.1327182799577713,
      "learning_rate": 1.1807780320366134e-05,
      "loss": 0.0143,
      "step": 1790
    },
    {
      "epoch": 4.118993135011442,
      "grad_norm": 5.991559982299805,
      "learning_rate": 1.1762013729977118e-05,
      "loss": 0.0421,
      "step": 1800
    },
    {
      "epoch": 4.14187643020595,
      "grad_norm": 9.217525482177734,
      "learning_rate": 1.1716247139588102e-05,
      "loss": 0.0372,
      "step": 1810
    },
    {
      "epoch": 4.164759725400458,
      "grad_norm": 0.08135858178138733,
      "learning_rate": 1.1670480549199087e-05,
      "loss": 0.0724,
      "step": 1820
    },
    {
      "epoch": 4.187643020594965,
      "grad_norm": 0.2486492097377777,
      "learning_rate": 1.1624713958810069e-05,
      "loss": 0.1554,
      "step": 1830
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 6.576598167419434,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.1168,
      "step": 1840
    },
    {
      "epoch": 4.233409610983982,
      "grad_norm": 0.3606749475002289,
      "learning_rate": 1.1533180778032038e-05,
      "loss": 0.0328,
      "step": 1850
    },
    {
      "epoch": 4.25629290617849,
      "grad_norm": 8.751301765441895,
      "learning_rate": 1.1487414187643022e-05,
      "loss": 0.0552,
      "step": 1860
    },
    {
      "epoch": 4.279176201372998,
      "grad_norm": 0.061764493584632874,
      "learning_rate": 1.1441647597254006e-05,
      "loss": 0.0047,
      "step": 1870
    },
    {
      "epoch": 4.302059496567506,
      "grad_norm": 0.6237295866012573,
      "learning_rate": 1.139588100686499e-05,
      "loss": 0.0195,
      "step": 1880
    },
    {
      "epoch": 4.324942791762013,
      "grad_norm": 0.14955012500286102,
      "learning_rate": 1.1350114416475973e-05,
      "loss": 0.0245,
      "step": 1890
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.0742243155837059,
      "learning_rate": 1.1304347826086957e-05,
      "loss": 0.0157,
      "step": 1900
    },
    {
      "epoch": 4.37070938215103,
      "grad_norm": 4.78897762298584,
      "learning_rate": 1.1258581235697941e-05,
      "loss": 0.0335,
      "step": 1910
    },
    {
      "epoch": 4.393592677345538,
      "grad_norm": 7.681253433227539,
      "learning_rate": 1.1212814645308924e-05,
      "loss": 0.0553,
      "step": 1920
    },
    {
      "epoch": 4.416475972540046,
      "grad_norm": 0.06848098337650299,
      "learning_rate": 1.1167048054919908e-05,
      "loss": 0.0384,
      "step": 1930
    },
    {
      "epoch": 4.439359267734554,
      "grad_norm": 0.32190605998039246,
      "learning_rate": 1.1121281464530893e-05,
      "loss": 0.0514,
      "step": 1940
    },
    {
      "epoch": 4.462242562929061,
      "grad_norm": 0.16968849301338196,
      "learning_rate": 1.1075514874141877e-05,
      "loss": 0.0338,
      "step": 1950
    },
    {
      "epoch": 4.48512585812357,
      "grad_norm": 0.4874051511287689,
      "learning_rate": 1.1029748283752861e-05,
      "loss": 0.0403,
      "step": 1960
    },
    {
      "epoch": 4.508009153318078,
      "grad_norm": 0.134229838848114,
      "learning_rate": 1.0983981693363845e-05,
      "loss": 0.0233,
      "step": 1970
    },
    {
      "epoch": 4.530892448512586,
      "grad_norm": 17.23841667175293,
      "learning_rate": 1.093821510297483e-05,
      "loss": 0.0541,
      "step": 1980
    },
    {
      "epoch": 4.553775743707094,
      "grad_norm": 7.803861618041992,
      "learning_rate": 1.0892448512585814e-05,
      "loss": 0.0873,
      "step": 1990
    },
    {
      "epoch": 4.576659038901602,
      "grad_norm": 11.657454490661621,
      "learning_rate": 1.0846681922196798e-05,
      "loss": 0.0344,
      "step": 2000
    },
    {
      "epoch": 4.5995423340961095,
      "grad_norm": 16.91526222229004,
      "learning_rate": 1.0800915331807782e-05,
      "loss": 0.0423,
      "step": 2010
    },
    {
      "epoch": 4.622425629290618,
      "grad_norm": 0.08672478795051575,
      "learning_rate": 1.0755148741418767e-05,
      "loss": 0.0277,
      "step": 2020
    },
    {
      "epoch": 4.645308924485126,
      "grad_norm": 10.12226676940918,
      "learning_rate": 1.070938215102975e-05,
      "loss": 0.0366,
      "step": 2030
    },
    {
      "epoch": 4.668192219679634,
      "grad_norm": 1.6980561017990112,
      "learning_rate": 1.0663615560640732e-05,
      "loss": 0.0547,
      "step": 2040
    },
    {
      "epoch": 4.691075514874142,
      "grad_norm": 7.225153923034668,
      "learning_rate": 1.0617848970251716e-05,
      "loss": 0.0312,
      "step": 2050
    },
    {
      "epoch": 4.71395881006865,
      "grad_norm": 0.05355072394013405,
      "learning_rate": 1.05720823798627e-05,
      "loss": 0.0645,
      "step": 2060
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 10.750184059143066,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.0322,
      "step": 2070
    },
    {
      "epoch": 4.759725400457666,
      "grad_norm": 12.701261520385742,
      "learning_rate": 1.0480549199084669e-05,
      "loss": 0.0531,
      "step": 2080
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 2.675992488861084,
      "learning_rate": 1.0434782608695653e-05,
      "loss": 0.0468,
      "step": 2090
    },
    {
      "epoch": 4.805491990846682,
      "grad_norm": 0.1412964165210724,
      "learning_rate": 1.0389016018306637e-05,
      "loss": 0.0723,
      "step": 2100
    },
    {
      "epoch": 4.82837528604119,
      "grad_norm": 0.26231908798217773,
      "learning_rate": 1.0343249427917621e-05,
      "loss": 0.0504,
      "step": 2110
    },
    {
      "epoch": 4.851258581235698,
      "grad_norm": 1.0707025527954102,
      "learning_rate": 1.0297482837528606e-05,
      "loss": 0.0289,
      "step": 2120
    },
    {
      "epoch": 4.874141876430206,
      "grad_norm": 8.503471374511719,
      "learning_rate": 1.025171624713959e-05,
      "loss": 0.0474,
      "step": 2130
    },
    {
      "epoch": 4.897025171624714,
      "grad_norm": 2.525294542312622,
      "learning_rate": 1.0205949656750573e-05,
      "loss": 0.0822,
      "step": 2140
    },
    {
      "epoch": 4.919908466819222,
      "grad_norm": 0.7364407777786255,
      "learning_rate": 1.0160183066361557e-05,
      "loss": 0.0157,
      "step": 2150
    },
    {
      "epoch": 4.94279176201373,
      "grad_norm": 5.615062713623047,
      "learning_rate": 1.0114416475972541e-05,
      "loss": 0.0873,
      "step": 2160
    },
    {
      "epoch": 4.965675057208238,
      "grad_norm": 0.3066580891609192,
      "learning_rate": 1.0068649885583525e-05,
      "loss": 0.0306,
      "step": 2170
    },
    {
      "epoch": 4.988558352402746,
      "grad_norm": 1.5084636211395264,
      "learning_rate": 1.002288329519451e-05,
      "loss": 0.0232,
      "step": 2180
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9706666666666667,
      "eval_f1": 0.8842105263157896,
      "eval_loss": 0.14010260999202728,
      "eval_precision": 0.8818897637795275,
      "eval_recall": 0.8865435356200527,
      "eval_runtime": 758.0714,
      "eval_samples_per_second": 3.957,
      "eval_steps_per_second": 0.495,
      "step": 2185
    },
    {
      "epoch": 5.011441647597254,
      "grad_norm": 0.030531078577041626,
      "learning_rate": 9.977116704805492e-06,
      "loss": 0.0177,
      "step": 2190
    },
    {
      "epoch": 5.034324942791762,
      "grad_norm": 0.48088768124580383,
      "learning_rate": 9.931350114416476e-06,
      "loss": 0.002,
      "step": 2200
    },
    {
      "epoch": 5.05720823798627,
      "grad_norm": 1.1010626554489136,
      "learning_rate": 9.88558352402746e-06,
      "loss": 0.0277,
      "step": 2210
    },
    {
      "epoch": 5.080091533180778,
      "grad_norm": 10.377949714660645,
      "learning_rate": 9.839816933638445e-06,
      "loss": 0.0237,
      "step": 2220
    },
    {
      "epoch": 5.102974828375286,
      "grad_norm": 10.033637046813965,
      "learning_rate": 9.794050343249429e-06,
      "loss": 0.0387,
      "step": 2230
    },
    {
      "epoch": 5.125858123569794,
      "grad_norm": 0.16544018685817719,
      "learning_rate": 9.748283752860412e-06,
      "loss": 0.0617,
      "step": 2240
    },
    {
      "epoch": 5.148741418764302,
      "grad_norm": 6.230093002319336,
      "learning_rate": 9.702517162471396e-06,
      "loss": 0.0467,
      "step": 2250
    },
    {
      "epoch": 5.17162471395881,
      "grad_norm": 0.03940270096063614,
      "learning_rate": 9.65675057208238e-06,
      "loss": 0.0063,
      "step": 2260
    },
    {
      "epoch": 5.194508009153318,
      "grad_norm": 7.462733745574951,
      "learning_rate": 9.610983981693364e-06,
      "loss": 0.0295,
      "step": 2270
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 3.4577763080596924,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.024,
      "step": 2280
    },
    {
      "epoch": 5.240274599542334,
      "grad_norm": 3.0583369731903076,
      "learning_rate": 9.519450800915333e-06,
      "loss": 0.0049,
      "step": 2290
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 7.52587366104126,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.0277,
      "step": 2300
    },
    {
      "epoch": 5.28604118993135,
      "grad_norm": 0.49673399329185486,
      "learning_rate": 9.4279176201373e-06,
      "loss": 0.0057,
      "step": 2310
    },
    {
      "epoch": 5.308924485125858,
      "grad_norm": 4.874752521514893,
      "learning_rate": 9.382151029748284e-06,
      "loss": 0.019,
      "step": 2320
    },
    {
      "epoch": 5.331807780320366,
      "grad_norm": 1.6044267416000366,
      "learning_rate": 9.336384439359268e-06,
      "loss": 0.0253,
      "step": 2330
    },
    {
      "epoch": 5.354691075514874,
      "grad_norm": 0.250793993473053,
      "learning_rate": 9.290617848970253e-06,
      "loss": 0.0025,
      "step": 2340
    },
    {
      "epoch": 5.377574370709382,
      "grad_norm": 7.7580084800720215,
      "learning_rate": 9.244851258581237e-06,
      "loss": 0.0143,
      "step": 2350
    },
    {
      "epoch": 5.4004576659038905,
      "grad_norm": 0.016045669093728065,
      "learning_rate": 9.199084668192221e-06,
      "loss": 0.0425,
      "step": 2360
    },
    {
      "epoch": 5.423340961098398,
      "grad_norm": 10.87308120727539,
      "learning_rate": 9.153318077803205e-06,
      "loss": 0.0422,
      "step": 2370
    },
    {
      "epoch": 5.446224256292906,
      "grad_norm": 8.792859077453613,
      "learning_rate": 9.107551487414188e-06,
      "loss": 0.038,
      "step": 2380
    },
    {
      "epoch": 5.469107551487414,
      "grad_norm": 5.2424187660217285,
      "learning_rate": 9.061784897025172e-06,
      "loss": 0.0325,
      "step": 2390
    },
    {
      "epoch": 5.491990846681922,
      "grad_norm": 0.32888129353523254,
      "learning_rate": 9.016018306636156e-06,
      "loss": 0.0137,
      "step": 2400
    },
    {
      "epoch": 5.51487414187643,
      "grad_norm": 6.606708526611328,
      "learning_rate": 8.97025171624714e-06,
      "loss": 0.0066,
      "step": 2410
    },
    {
      "epoch": 5.537757437070939,
      "grad_norm": 0.010495343245565891,
      "learning_rate": 8.924485125858125e-06,
      "loss": 0.0362,
      "step": 2420
    },
    {
      "epoch": 5.560640732265446,
      "grad_norm": 0.051990147680044174,
      "learning_rate": 8.878718535469109e-06,
      "loss": 0.0361,
      "step": 2430
    },
    {
      "epoch": 5.583524027459954,
      "grad_norm": 0.01835944876074791,
      "learning_rate": 8.832951945080093e-06,
      "loss": 0.0004,
      "step": 2440
    },
    {
      "epoch": 5.606407322654462,
      "grad_norm": 1.9525290727615356,
      "learning_rate": 8.787185354691076e-06,
      "loss": 0.0359,
      "step": 2450
    },
    {
      "epoch": 5.62929061784897,
      "grad_norm": 1.3692100048065186,
      "learning_rate": 8.74141876430206e-06,
      "loss": 0.007,
      "step": 2460
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 0.971448540687561,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.082,
      "step": 2470
    },
    {
      "epoch": 5.675057208237987,
      "grad_norm": 0.016716834157705307,
      "learning_rate": 8.649885583524029e-06,
      "loss": 0.0222,
      "step": 2480
    },
    {
      "epoch": 5.697940503432494,
      "grad_norm": 25.629274368286133,
      "learning_rate": 8.604118993135013e-06,
      "loss": 0.0498,
      "step": 2490
    },
    {
      "epoch": 5.720823798627002,
      "grad_norm": 0.27720218896865845,
      "learning_rate": 8.558352402745997e-06,
      "loss": 0.0339,
      "step": 2500
    },
    {
      "epoch": 5.74370709382151,
      "grad_norm": 6.194399356842041,
      "learning_rate": 8.51258581235698e-06,
      "loss": 0.0181,
      "step": 2510
    },
    {
      "epoch": 5.766590389016018,
      "grad_norm": 8.515388488769531,
      "learning_rate": 8.466819221967964e-06,
      "loss": 0.0538,
      "step": 2520
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 10.781781196594238,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.0659,
      "step": 2530
    },
    {
      "epoch": 5.812356979405035,
      "grad_norm": 0.0711292251944542,
      "learning_rate": 8.375286041189932e-06,
      "loss": 0.0187,
      "step": 2540
    },
    {
      "epoch": 5.835240274599542,
      "grad_norm": 0.9230826497077942,
      "learning_rate": 8.329519450800915e-06,
      "loss": 0.0383,
      "step": 2550
    },
    {
      "epoch": 5.85812356979405,
      "grad_norm": 0.007570124696940184,
      "learning_rate": 8.2837528604119e-06,
      "loss": 0.0389,
      "step": 2560
    },
    {
      "epoch": 5.881006864988558,
      "grad_norm": 2.909431219100952,
      "learning_rate": 8.237986270022884e-06,
      "loss": 0.0299,
      "step": 2570
    },
    {
      "epoch": 5.9038901601830664,
      "grad_norm": 0.017710886895656586,
      "learning_rate": 8.192219679633868e-06,
      "loss": 0.0053,
      "step": 2580
    },
    {
      "epoch": 5.926773455377575,
      "grad_norm": 1.5648645162582397,
      "learning_rate": 8.146453089244852e-06,
      "loss": 0.0271,
      "step": 2590
    },
    {
      "epoch": 5.949656750572083,
      "grad_norm": 6.064261436462402,
      "learning_rate": 8.100686498855835e-06,
      "loss": 0.1016,
      "step": 2600
    },
    {
      "epoch": 5.97254004576659,
      "grad_norm": 0.5972269177436829,
      "learning_rate": 8.054919908466819e-06,
      "loss": 0.021,
      "step": 2610
    },
    {
      "epoch": 5.995423340961098,
      "grad_norm": 0.19940392673015594,
      "learning_rate": 8.009153318077803e-06,
      "loss": 0.0331,
      "step": 2620
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9716666666666667,
      "eval_f1": 0.8888888888888888,
      "eval_loss": 0.13689495623111725,
      "eval_precision": 0.8808290155440415,
      "eval_recall": 0.8970976253298153,
      "eval_runtime": 756.0764,
      "eval_samples_per_second": 3.968,
      "eval_steps_per_second": 0.496,
      "step": 2622
    },
    {
      "epoch": 6.018306636155606,
      "grad_norm": 0.0711444839835167,
      "learning_rate": 7.963386727688787e-06,
      "loss": 0.0017,
      "step": 2630
    },
    {
      "epoch": 6.0411899313501145,
      "grad_norm": 0.011764015071094036,
      "learning_rate": 7.917620137299772e-06,
      "loss": 0.0012,
      "step": 2640
    },
    {
      "epoch": 6.064073226544623,
      "grad_norm": 0.3269742429256439,
      "learning_rate": 7.871853546910756e-06,
      "loss": 0.0245,
      "step": 2650
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 0.0798315778374672,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.0129,
      "step": 2660
    },
    {
      "epoch": 6.109839816933638,
      "grad_norm": 0.07822446525096893,
      "learning_rate": 7.780320366132724e-06,
      "loss": 0.0005,
      "step": 2670
    },
    {
      "epoch": 6.132723112128146,
      "grad_norm": 0.004727569408714771,
      "learning_rate": 7.734553775743707e-06,
      "loss": 0.0019,
      "step": 2680
    },
    {
      "epoch": 6.155606407322654,
      "grad_norm": 0.013957533985376358,
      "learning_rate": 7.688787185354691e-06,
      "loss": 0.0083,
      "step": 2690
    },
    {
      "epoch": 6.178489702517163,
      "grad_norm": 0.033070530742406845,
      "learning_rate": 7.643020594965675e-06,
      "loss": 0.0003,
      "step": 2700
    },
    {
      "epoch": 6.201372997711671,
      "grad_norm": 8.401510238647461,
      "learning_rate": 7.59725400457666e-06,
      "loss": 0.0338,
      "step": 2710
    },
    {
      "epoch": 6.224256292906179,
      "grad_norm": 0.03495941311120987,
      "learning_rate": 7.551487414187644e-06,
      "loss": 0.0032,
      "step": 2720
    },
    {
      "epoch": 6.247139588100686,
      "grad_norm": 0.05697382241487503,
      "learning_rate": 7.505720823798628e-06,
      "loss": 0.0178,
      "step": 2730
    },
    {
      "epoch": 6.270022883295194,
      "grad_norm": 5.832038402557373,
      "learning_rate": 7.459954233409612e-06,
      "loss": 0.0084,
      "step": 2740
    },
    {
      "epoch": 6.2929061784897025,
      "grad_norm": 13.245565414428711,
      "learning_rate": 7.414187643020596e-06,
      "loss": 0.0299,
      "step": 2750
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 0.0696980282664299,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0454,
      "step": 2760
    },
    {
      "epoch": 6.338672768878719,
      "grad_norm": 0.006122501101344824,
      "learning_rate": 7.3226544622425635e-06,
      "loss": 0.0301,
      "step": 2770
    },
    {
      "epoch": 6.361556064073227,
      "grad_norm": 0.0032276890706270933,
      "learning_rate": 7.276887871853548e-06,
      "loss": 0.0239,
      "step": 2780
    },
    {
      "epoch": 6.384439359267734,
      "grad_norm": 0.03288666158914566,
      "learning_rate": 7.231121281464531e-06,
      "loss": 0.0318,
      "step": 2790
    },
    {
      "epoch": 6.407322654462242,
      "grad_norm": 0.36502885818481445,
      "learning_rate": 7.1853546910755154e-06,
      "loss": 0.0006,
      "step": 2800
    },
    {
      "epoch": 6.4302059496567505,
      "grad_norm": 0.05192243680357933,
      "learning_rate": 7.1395881006865e-06,
      "loss": 0.0167,
      "step": 2810
    },
    {
      "epoch": 6.453089244851259,
      "grad_norm": 0.07438009977340698,
      "learning_rate": 7.093821510297484e-06,
      "loss": 0.019,
      "step": 2820
    },
    {
      "epoch": 6.475972540045767,
      "grad_norm": 0.39822152256965637,
      "learning_rate": 7.0480549199084665e-06,
      "loss": 0.0102,
      "step": 2830
    },
    {
      "epoch": 6.498855835240275,
      "grad_norm": 0.06183436140418053,
      "learning_rate": 7.002288329519451e-06,
      "loss": 0.0062,
      "step": 2840
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.21537832915782928,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.0346,
      "step": 2850
    },
    {
      "epoch": 6.54462242562929,
      "grad_norm": 0.024477386847138405,
      "learning_rate": 6.910755148741419e-06,
      "loss": 0.0251,
      "step": 2860
    },
    {
      "epoch": 6.567505720823799,
      "grad_norm": 0.03302959352731705,
      "learning_rate": 6.8649885583524035e-06,
      "loss": 0.0194,
      "step": 2870
    },
    {
      "epoch": 6.590389016018307,
      "grad_norm": 4.000676155090332,
      "learning_rate": 6.819221967963388e-06,
      "loss": 0.032,
      "step": 2880
    },
    {
      "epoch": 6.613272311212815,
      "grad_norm": 0.01688145287334919,
      "learning_rate": 6.773455377574372e-06,
      "loss": 0.0214,
      "step": 2890
    },
    {
      "epoch": 6.636155606407323,
      "grad_norm": 2.206735134124756,
      "learning_rate": 6.7276887871853554e-06,
      "loss": 0.0166,
      "step": 2900
    },
    {
      "epoch": 6.65903890160183,
      "grad_norm": 1.741082787513733,
      "learning_rate": 6.681922196796339e-06,
      "loss": 0.0471,
      "step": 2910
    },
    {
      "epoch": 6.6819221967963385,
      "grad_norm": 0.005953684914857149,
      "learning_rate": 6.636155606407323e-06,
      "loss": 0.0253,
      "step": 2920
    },
    {
      "epoch": 6.704805491990847,
      "grad_norm": 0.030217071995139122,
      "learning_rate": 6.590389016018307e-06,
      "loss": 0.0198,
      "step": 2930
    },
    {
      "epoch": 6.727688787185355,
      "grad_norm": 0.37566906213760376,
      "learning_rate": 6.544622425629291e-06,
      "loss": 0.0112,
      "step": 2940
    },
    {
      "epoch": 6.750572082379863,
      "grad_norm": 0.17430733144283295,
      "learning_rate": 6.498855835240275e-06,
      "loss": 0.0211,
      "step": 2950
    },
    {
      "epoch": 6.77345537757437,
      "grad_norm": 7.816272258758545,
      "learning_rate": 6.453089244851259e-06,
      "loss": 0.0311,
      "step": 2960
    },
    {
      "epoch": 6.796338672768878,
      "grad_norm": 0.007133255712687969,
      "learning_rate": 6.4073226544622435e-06,
      "loss": 0.001,
      "step": 2970
    },
    {
      "epoch": 6.8192219679633865,
      "grad_norm": 0.28235235810279846,
      "learning_rate": 6.361556064073227e-06,
      "loss": 0.0248,
      "step": 2980
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 0.016002235934138298,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.0224,
      "step": 2990
    },
    {
      "epoch": 6.864988558352403,
      "grad_norm": 0.40421923995018005,
      "learning_rate": 6.270022883295195e-06,
      "loss": 0.0016,
      "step": 3000
    },
    {
      "epoch": 6.887871853546911,
      "grad_norm": 6.980607032775879,
      "learning_rate": 6.224256292906179e-06,
      "loss": 0.0121,
      "step": 3010
    },
    {
      "epoch": 6.910755148741419,
      "grad_norm": 5.824012756347656,
      "learning_rate": 6.178489702517163e-06,
      "loss": 0.01,
      "step": 3020
    },
    {
      "epoch": 6.933638443935926,
      "grad_norm": 0.0076820701360702515,
      "learning_rate": 6.132723112128147e-06,
      "loss": 0.015,
      "step": 3030
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 0.09821382164955139,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.0311,
      "step": 3040
    },
    {
      "epoch": 6.979405034324943,
      "grad_norm": 0.25050267577171326,
      "learning_rate": 6.041189931350116e-06,
      "loss": 0.0181,
      "step": 3050
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9756666666666667,
      "eval_f1": 0.9020134228187919,
      "eval_loss": 0.14633561670780182,
      "eval_precision": 0.9180327868852459,
      "eval_recall": 0.8865435356200527,
      "eval_runtime": 804.1681,
      "eval_samples_per_second": 3.731,
      "eval_steps_per_second": 0.466,
      "step": 3059
    },
    {
      "epoch": 7.002288329519451,
      "grad_norm": 0.5623075366020203,
      "learning_rate": 5.995423340961098e-06,
      "loss": 0.0116,
      "step": 3060
    },
    {
      "epoch": 7.025171624713959,
      "grad_norm": 0.04923303425312042,
      "learning_rate": 5.949656750572083e-06,
      "loss": 0.0198,
      "step": 3070
    },
    {
      "epoch": 7.048054919908467,
      "grad_norm": 0.0038011730648577213,
      "learning_rate": 5.903890160183067e-06,
      "loss": 0.0114,
      "step": 3080
    },
    {
      "epoch": 7.0709382151029745,
      "grad_norm": 0.9437828660011292,
      "learning_rate": 5.858123569794051e-06,
      "loss": 0.0393,
      "step": 3090
    },
    {
      "epoch": 7.093821510297483,
      "grad_norm": 0.037842586636543274,
      "learning_rate": 5.8123569794050346e-06,
      "loss": 0.0027,
      "step": 3100
    },
    {
      "epoch": 7.116704805491991,
      "grad_norm": 0.053185224533081055,
      "learning_rate": 5.766590389016019e-06,
      "loss": 0.0043,
      "step": 3110
    },
    {
      "epoch": 7.139588100686499,
      "grad_norm": 0.07397308945655823,
      "learning_rate": 5.720823798627003e-06,
      "loss": 0.0009,
      "step": 3120
    },
    {
      "epoch": 7.162471395881007,
      "grad_norm": 0.014853131957352161,
      "learning_rate": 5.6750572082379865e-06,
      "loss": 0.0127,
      "step": 3130
    },
    {
      "epoch": 7.185354691075515,
      "grad_norm": 4.784605026245117,
      "learning_rate": 5.629290617848971e-06,
      "loss": 0.0037,
      "step": 3140
    },
    {
      "epoch": 7.2082379862700225,
      "grad_norm": 13.644314765930176,
      "learning_rate": 5.583524027459954e-06,
      "loss": 0.0226,
      "step": 3150
    },
    {
      "epoch": 7.231121281464531,
      "grad_norm": 0.002934905467554927,
      "learning_rate": 5.537757437070938e-06,
      "loss": 0.0075,
      "step": 3160
    },
    {
      "epoch": 7.254004576659039,
      "grad_norm": 0.3132252097129822,
      "learning_rate": 5.491990846681923e-06,
      "loss": 0.0006,
      "step": 3170
    },
    {
      "epoch": 7.276887871853547,
      "grad_norm": 0.05100362375378609,
      "learning_rate": 5.446224256292907e-06,
      "loss": 0.0004,
      "step": 3180
    },
    {
      "epoch": 7.299771167048055,
      "grad_norm": 0.061433445662260056,
      "learning_rate": 5.400457665903891e-06,
      "loss": 0.0067,
      "step": 3190
    },
    {
      "epoch": 7.322654462242563,
      "grad_norm": 0.136699840426445,
      "learning_rate": 5.354691075514875e-06,
      "loss": 0.0368,
      "step": 3200
    },
    {
      "epoch": 7.345537757437071,
      "grad_norm": 0.0058221067301929,
      "learning_rate": 5.308924485125858e-06,
      "loss": 0.0009,
      "step": 3210
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 0.04208439588546753,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.0014,
      "step": 3220
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 10.4429349899292,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.0038,
      "step": 3230
    },
    {
      "epoch": 7.414187643020595,
      "grad_norm": 0.029804188758134842,
      "learning_rate": 5.171624713958811e-06,
      "loss": 0.0139,
      "step": 3240
    },
    {
      "epoch": 7.437070938215103,
      "grad_norm": 15.079387664794922,
      "learning_rate": 5.125858123569795e-06,
      "loss": 0.0182,
      "step": 3250
    },
    {
      "epoch": 7.459954233409611,
      "grad_norm": 0.11289221793413162,
      "learning_rate": 5.080091533180778e-06,
      "loss": 0.0438,
      "step": 3260
    },
    {
      "epoch": 7.482837528604119,
      "grad_norm": 0.7372238636016846,
      "learning_rate": 5.034324942791763e-06,
      "loss": 0.0004,
      "step": 3270
    },
    {
      "epoch": 7.505720823798627,
      "grad_norm": 0.013000110164284706,
      "learning_rate": 4.988558352402746e-06,
      "loss": 0.0014,
      "step": 3280
    },
    {
      "epoch": 7.528604118993135,
      "grad_norm": 0.002225915202870965,
      "learning_rate": 4.94279176201373e-06,
      "loss": 0.0053,
      "step": 3290
    },
    {
      "epoch": 7.551487414187643,
      "grad_norm": 0.01013306062668562,
      "learning_rate": 4.8970251716247146e-06,
      "loss": 0.0153,
      "step": 3300
    },
    {
      "epoch": 7.574370709382151,
      "grad_norm": 0.011402299627661705,
      "learning_rate": 4.851258581235698e-06,
      "loss": 0.001,
      "step": 3310
    },
    {
      "epoch": 7.597254004576659,
      "grad_norm": 0.020978663116693497,
      "learning_rate": 4.805491990846682e-06,
      "loss": 0.0044,
      "step": 3320
    },
    {
      "epoch": 7.620137299771167,
      "grad_norm": 1.4845876693725586,
      "learning_rate": 4.7597254004576665e-06,
      "loss": 0.0056,
      "step": 3330
    },
    {
      "epoch": 7.643020594965675,
      "grad_norm": 0.021811293438076973,
      "learning_rate": 4.71395881006865e-06,
      "loss": 0.0009,
      "step": 3340
    },
    {
      "epoch": 7.665903890160183,
      "grad_norm": 0.307356595993042,
      "learning_rate": 4.668192219679634e-06,
      "loss": 0.0063,
      "step": 3350
    },
    {
      "epoch": 7.688787185354691,
      "grad_norm": 0.006579542066901922,
      "learning_rate": 4.622425629290618e-06,
      "loss": 0.0081,
      "step": 3360
    },
    {
      "epoch": 7.711670480549199,
      "grad_norm": 0.0015494837425649166,
      "learning_rate": 4.576659038901603e-06,
      "loss": 0.0029,
      "step": 3370
    },
    {
      "epoch": 7.7345537757437075,
      "grad_norm": 0.0808996707201004,
      "learning_rate": 4.530892448512586e-06,
      "loss": 0.0004,
      "step": 3380
    },
    {
      "epoch": 7.757437070938215,
      "grad_norm": 0.002741249743849039,
      "learning_rate": 4.48512585812357e-06,
      "loss": 0.0205,
      "step": 3390
    },
    {
      "epoch": 7.780320366132723,
      "grad_norm": 15.356264114379883,
      "learning_rate": 4.4393592677345545e-06,
      "loss": 0.0246,
      "step": 3400
    },
    {
      "epoch": 7.803203661327231,
      "grad_norm": 0.007973960600793362,
      "learning_rate": 4.393592677345538e-06,
      "loss": 0.0047,
      "step": 3410
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 0.07738983631134033,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0004,
      "step": 3420
    },
    {
      "epoch": 7.848970251716247,
      "grad_norm": 0.0012941514141857624,
      "learning_rate": 4.3020594965675065e-06,
      "loss": 0.0007,
      "step": 3430
    },
    {
      "epoch": 7.871853546910755,
      "grad_norm": 0.0077473921701312065,
      "learning_rate": 4.25629290617849e-06,
      "loss": 0.0137,
      "step": 3440
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 0.013882930390536785,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.0048,
      "step": 3450
    },
    {
      "epoch": 7.917620137299771,
      "grad_norm": 2.9593112468719482,
      "learning_rate": 4.1647597254004575e-06,
      "loss": 0.0014,
      "step": 3460
    },
    {
      "epoch": 7.940503432494279,
      "grad_norm": 0.328401118516922,
      "learning_rate": 4.118993135011442e-06,
      "loss": 0.0067,
      "step": 3470
    },
    {
      "epoch": 7.963386727688787,
      "grad_norm": 0.01016298495233059,
      "learning_rate": 4.073226544622426e-06,
      "loss": 0.0165,
      "step": 3480
    },
    {
      "epoch": 7.9862700228832955,
      "grad_norm": 0.42276185750961304,
      "learning_rate": 4.0274599542334094e-06,
      "loss": 0.0054,
      "step": 3490
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9763333333333334,
      "eval_f1": 0.9041835357624831,
      "eval_loss": 0.1736067533493042,
      "eval_precision": 0.925414364640884,
      "eval_recall": 0.8839050131926122,
      "eval_runtime": 710.385,
      "eval_samples_per_second": 4.223,
      "eval_steps_per_second": 0.528,
      "step": 3496
    }
  ],
  "logging_steps": 10,
  "max_steps": 4370,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.832883491405824e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
