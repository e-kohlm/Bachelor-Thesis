{
  "best_metric": 0.9333333333333335,
  "best_model_checkpoint": "../saved_models/command_injection_40000/checkpoint-4370",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4370,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002288329519450801,
      "grad_norm": 39.51082229614258,
      "learning_rate": 1.99954233409611e-05,
      "loss": 1.1842,
      "step": 1
    },
    {
      "epoch": 0.02288329519450801,
      "grad_norm": 18.168212890625,
      "learning_rate": 1.9954233409610984e-05,
      "loss": 0.5317,
      "step": 10
    },
    {
      "epoch": 0.04576659038901602,
      "grad_norm": 23.640533447265625,
      "learning_rate": 1.990846681922197e-05,
      "loss": 0.5106,
      "step": 20
    },
    {
      "epoch": 0.06864988558352403,
      "grad_norm": 10.461788177490234,
      "learning_rate": 1.9862700228832953e-05,
      "loss": 0.375,
      "step": 30
    },
    {
      "epoch": 0.09153318077803203,
      "grad_norm": 19.45977783203125,
      "learning_rate": 1.981693363844394e-05,
      "loss": 0.4627,
      "step": 40
    },
    {
      "epoch": 0.11441647597254005,
      "grad_norm": 18.309955596923828,
      "learning_rate": 1.977116704805492e-05,
      "loss": 0.421,
      "step": 50
    },
    {
      "epoch": 0.13729977116704806,
      "grad_norm": 18.669923782348633,
      "learning_rate": 1.9725400457665907e-05,
      "loss": 0.4478,
      "step": 60
    },
    {
      "epoch": 0.16018306636155608,
      "grad_norm": 13.933008193969727,
      "learning_rate": 1.967963386727689e-05,
      "loss": 0.361,
      "step": 70
    },
    {
      "epoch": 0.18306636155606407,
      "grad_norm": 27.70824432373047,
      "learning_rate": 1.9633867276887872e-05,
      "loss": 0.4194,
      "step": 80
    },
    {
      "epoch": 0.20594965675057209,
      "grad_norm": 14.810364723205566,
      "learning_rate": 1.9588100686498858e-05,
      "loss": 0.4456,
      "step": 90
    },
    {
      "epoch": 0.2288329519450801,
      "grad_norm": 11.210930824279785,
      "learning_rate": 1.954233409610984e-05,
      "loss": 0.3871,
      "step": 100
    },
    {
      "epoch": 0.2517162471395881,
      "grad_norm": 12.57529067993164,
      "learning_rate": 1.9496567505720823e-05,
      "loss": 0.3738,
      "step": 110
    },
    {
      "epoch": 0.2745995423340961,
      "grad_norm": 6.916160583496094,
      "learning_rate": 1.945080091533181e-05,
      "loss": 0.3275,
      "step": 120
    },
    {
      "epoch": 0.2974828375286041,
      "grad_norm": 43.09779357910156,
      "learning_rate": 1.9405034324942792e-05,
      "loss": 0.3729,
      "step": 130
    },
    {
      "epoch": 0.32036613272311215,
      "grad_norm": 6.6102375984191895,
      "learning_rate": 1.9359267734553778e-05,
      "loss": 0.3315,
      "step": 140
    },
    {
      "epoch": 0.34324942791762014,
      "grad_norm": 9.922407150268555,
      "learning_rate": 1.931350114416476e-05,
      "loss": 0.3516,
      "step": 150
    },
    {
      "epoch": 0.36613272311212813,
      "grad_norm": 10.756726264953613,
      "learning_rate": 1.9267734553775746e-05,
      "loss": 0.349,
      "step": 160
    },
    {
      "epoch": 0.3890160183066362,
      "grad_norm": 8.962119102478027,
      "learning_rate": 1.922196796338673e-05,
      "loss": 0.3507,
      "step": 170
    },
    {
      "epoch": 0.41189931350114417,
      "grad_norm": 12.841984748840332,
      "learning_rate": 1.9176201372997715e-05,
      "loss": 0.3003,
      "step": 180
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 10.96865463256836,
      "learning_rate": 1.9130434782608697e-05,
      "loss": 0.389,
      "step": 190
    },
    {
      "epoch": 0.4576659038901602,
      "grad_norm": 5.418217182159424,
      "learning_rate": 1.9084668192219683e-05,
      "loss": 0.3524,
      "step": 200
    },
    {
      "epoch": 0.4805491990846682,
      "grad_norm": 10.24614143371582,
      "learning_rate": 1.9038901601830666e-05,
      "loss": 0.3023,
      "step": 210
    },
    {
      "epoch": 0.5034324942791762,
      "grad_norm": 8.377099990844727,
      "learning_rate": 1.8993135011441652e-05,
      "loss": 0.2995,
      "step": 220
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 32.8553352355957,
      "learning_rate": 1.894736842105263e-05,
      "loss": 0.3262,
      "step": 230
    },
    {
      "epoch": 0.5491990846681922,
      "grad_norm": 7.661301136016846,
      "learning_rate": 1.8901601830663617e-05,
      "loss": 0.3447,
      "step": 240
    },
    {
      "epoch": 0.5720823798627003,
      "grad_norm": 6.674104690551758,
      "learning_rate": 1.88558352402746e-05,
      "loss": 0.3565,
      "step": 250
    },
    {
      "epoch": 0.5949656750572082,
      "grad_norm": 6.342448711395264,
      "learning_rate": 1.8810068649885585e-05,
      "loss": 0.3464,
      "step": 260
    },
    {
      "epoch": 0.6178489702517163,
      "grad_norm": 5.125518798828125,
      "learning_rate": 1.8764302059496568e-05,
      "loss": 0.287,
      "step": 270
    },
    {
      "epoch": 0.6407322654462243,
      "grad_norm": 4.377548694610596,
      "learning_rate": 1.8718535469107554e-05,
      "loss": 0.2838,
      "step": 280
    },
    {
      "epoch": 0.6636155606407322,
      "grad_norm": 5.869236946105957,
      "learning_rate": 1.8672768878718537e-05,
      "loss": 0.301,
      "step": 290
    },
    {
      "epoch": 0.6864988558352403,
      "grad_norm": 9.289146423339844,
      "learning_rate": 1.8627002288329522e-05,
      "loss": 0.2559,
      "step": 300
    },
    {
      "epoch": 0.7093821510297483,
      "grad_norm": 5.878881931304932,
      "learning_rate": 1.8581235697940505e-05,
      "loss": 0.2937,
      "step": 310
    },
    {
      "epoch": 0.7322654462242563,
      "grad_norm": 8.862478256225586,
      "learning_rate": 1.8535469107551488e-05,
      "loss": 0.2625,
      "step": 320
    },
    {
      "epoch": 0.7551487414187643,
      "grad_norm": 4.8283209800720215,
      "learning_rate": 1.8489702517162474e-05,
      "loss": 0.2709,
      "step": 330
    },
    {
      "epoch": 0.7780320366132724,
      "grad_norm": 8.590590476989746,
      "learning_rate": 1.8443935926773456e-05,
      "loss": 0.255,
      "step": 340
    },
    {
      "epoch": 0.8009153318077803,
      "grad_norm": 5.5068678855896,
      "learning_rate": 1.8398169336384442e-05,
      "loss": 0.2804,
      "step": 350
    },
    {
      "epoch": 0.8237986270022883,
      "grad_norm": 3.888734817504883,
      "learning_rate": 1.8352402745995425e-05,
      "loss": 0.2614,
      "step": 360
    },
    {
      "epoch": 0.8466819221967964,
      "grad_norm": 8.295878410339355,
      "learning_rate": 1.830663615560641e-05,
      "loss": 0.2174,
      "step": 370
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 3.965895175933838,
      "learning_rate": 1.8260869565217393e-05,
      "loss": 0.2137,
      "step": 380
    },
    {
      "epoch": 0.8924485125858124,
      "grad_norm": 4.6889328956604,
      "learning_rate": 1.8215102974828376e-05,
      "loss": 0.2425,
      "step": 390
    },
    {
      "epoch": 0.9153318077803204,
      "grad_norm": 5.111130714416504,
      "learning_rate": 1.816933638443936e-05,
      "loss": 0.2311,
      "step": 400
    },
    {
      "epoch": 0.9382151029748284,
      "grad_norm": 3.9807188510894775,
      "learning_rate": 1.8123569794050344e-05,
      "loss": 0.2522,
      "step": 410
    },
    {
      "epoch": 0.9610983981693364,
      "grad_norm": 5.499059200286865,
      "learning_rate": 1.8077803203661327e-05,
      "loss": 0.22,
      "step": 420
    },
    {
      "epoch": 0.9839816933638444,
      "grad_norm": 7.064518451690674,
      "learning_rate": 1.8032036613272313e-05,
      "loss": 0.2205,
      "step": 430
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9239639037433155,
      "eval_f1": 0.5670789724072313,
      "eval_loss": 0.22269383072853088,
      "eval_precision": 0.9226006191950464,
      "eval_recall": 0.40934065934065933,
      "eval_runtime": 91.3342,
      "eval_samples_per_second": 65.693,
      "eval_steps_per_second": 2.058,
      "step": 437
    },
    {
      "epoch": 1.0068649885583525,
      "grad_norm": 5.236075401306152,
      "learning_rate": 1.7986270022883295e-05,
      "loss": 0.2009,
      "step": 440
    },
    {
      "epoch": 1.0297482837528604,
      "grad_norm": 7.742269515991211,
      "learning_rate": 1.794050343249428e-05,
      "loss": 0.1736,
      "step": 450
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 6.5555500984191895,
      "learning_rate": 1.7894736842105264e-05,
      "loss": 0.2092,
      "step": 460
    },
    {
      "epoch": 1.0755148741418765,
      "grad_norm": 3.960040807723999,
      "learning_rate": 1.784897025171625e-05,
      "loss": 0.1778,
      "step": 470
    },
    {
      "epoch": 1.0983981693363845,
      "grad_norm": 3.6069133281707764,
      "learning_rate": 1.7803203661327232e-05,
      "loss": 0.1401,
      "step": 480
    },
    {
      "epoch": 1.1212814645308924,
      "grad_norm": 5.348484039306641,
      "learning_rate": 1.7757437070938218e-05,
      "loss": 0.1617,
      "step": 490
    },
    {
      "epoch": 1.1441647597254005,
      "grad_norm": 7.493255615234375,
      "learning_rate": 1.77116704805492e-05,
      "loss": 0.2034,
      "step": 500
    },
    {
      "epoch": 1.1670480549199085,
      "grad_norm": 4.028228282928467,
      "learning_rate": 1.7665903890160187e-05,
      "loss": 0.1952,
      "step": 510
    },
    {
      "epoch": 1.1899313501144164,
      "grad_norm": 11.035408973693848,
      "learning_rate": 1.762013729977117e-05,
      "loss": 0.2034,
      "step": 520
    },
    {
      "epoch": 1.2128146453089246,
      "grad_norm": 6.5894670486450195,
      "learning_rate": 1.7574370709382152e-05,
      "loss": 0.2073,
      "step": 530
    },
    {
      "epoch": 1.2356979405034325,
      "grad_norm": 4.012196063995361,
      "learning_rate": 1.7528604118993134e-05,
      "loss": 0.1323,
      "step": 540
    },
    {
      "epoch": 1.2585812356979404,
      "grad_norm": 4.390690803527832,
      "learning_rate": 1.748283752860412e-05,
      "loss": 0.1635,
      "step": 550
    },
    {
      "epoch": 1.2814645308924484,
      "grad_norm": 4.617702007293701,
      "learning_rate": 1.7437070938215103e-05,
      "loss": 0.1468,
      "step": 560
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 4.313027381896973,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.1591,
      "step": 570
    },
    {
      "epoch": 1.3272311212814645,
      "grad_norm": 6.989960193634033,
      "learning_rate": 1.734553775743707e-05,
      "loss": 0.1692,
      "step": 580
    },
    {
      "epoch": 1.3501144164759724,
      "grad_norm": 6.942687511444092,
      "learning_rate": 1.7299771167048057e-05,
      "loss": 0.1605,
      "step": 590
    },
    {
      "epoch": 1.3729977116704806,
      "grad_norm": 7.267640113830566,
      "learning_rate": 1.725400457665904e-05,
      "loss": 0.1985,
      "step": 600
    },
    {
      "epoch": 1.3958810068649885,
      "grad_norm": 5.315751552581787,
      "learning_rate": 1.7208237986270026e-05,
      "loss": 0.147,
      "step": 610
    },
    {
      "epoch": 1.4187643020594964,
      "grad_norm": 6.079560279846191,
      "learning_rate": 1.716247139588101e-05,
      "loss": 0.1247,
      "step": 620
    },
    {
      "epoch": 1.4416475972540046,
      "grad_norm": 3.9750914573669434,
      "learning_rate": 1.7116704805491994e-05,
      "loss": 0.1047,
      "step": 630
    },
    {
      "epoch": 1.4645308924485125,
      "grad_norm": 1.4732365608215332,
      "learning_rate": 1.7070938215102977e-05,
      "loss": 0.1203,
      "step": 640
    },
    {
      "epoch": 1.4874141876430205,
      "grad_norm": 7.027830600738525,
      "learning_rate": 1.702517162471396e-05,
      "loss": 0.1226,
      "step": 650
    },
    {
      "epoch": 1.5102974828375286,
      "grad_norm": 3.261545419692993,
      "learning_rate": 1.6979405034324945e-05,
      "loss": 0.1472,
      "step": 660
    },
    {
      "epoch": 1.5331807780320366,
      "grad_norm": 3.3808722496032715,
      "learning_rate": 1.6933638443935928e-05,
      "loss": 0.1399,
      "step": 670
    },
    {
      "epoch": 1.5560640732265445,
      "grad_norm": 3.5952084064483643,
      "learning_rate": 1.688787185354691e-05,
      "loss": 0.1144,
      "step": 680
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 7.853606224060059,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.1627,
      "step": 690
    },
    {
      "epoch": 1.6018306636155606,
      "grad_norm": 15.069750785827637,
      "learning_rate": 1.679633867276888e-05,
      "loss": 0.1466,
      "step": 700
    },
    {
      "epoch": 1.6247139588100685,
      "grad_norm": 5.126176834106445,
      "learning_rate": 1.6750572082379865e-05,
      "loss": 0.1402,
      "step": 710
    },
    {
      "epoch": 1.6475972540045767,
      "grad_norm": 3.449063301086426,
      "learning_rate": 1.6704805491990848e-05,
      "loss": 0.1193,
      "step": 720
    },
    {
      "epoch": 1.6704805491990846,
      "grad_norm": 3.885911226272583,
      "learning_rate": 1.665903890160183e-05,
      "loss": 0.1127,
      "step": 730
    },
    {
      "epoch": 1.6933638443935926,
      "grad_norm": 5.519503593444824,
      "learning_rate": 1.6613272311212816e-05,
      "loss": 0.1275,
      "step": 740
    },
    {
      "epoch": 1.7162471395881007,
      "grad_norm": 5.784572124481201,
      "learning_rate": 1.65675057208238e-05,
      "loss": 0.1125,
      "step": 750
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 6.615464687347412,
      "learning_rate": 1.6521739130434785e-05,
      "loss": 0.1374,
      "step": 760
    },
    {
      "epoch": 1.7620137299771166,
      "grad_norm": 5.169887542724609,
      "learning_rate": 1.6475972540045767e-05,
      "loss": 0.1545,
      "step": 770
    },
    {
      "epoch": 1.7848970251716247,
      "grad_norm": 5.257208347320557,
      "learning_rate": 1.6430205949656753e-05,
      "loss": 0.1018,
      "step": 780
    },
    {
      "epoch": 1.8077803203661327,
      "grad_norm": 6.4933061599731445,
      "learning_rate": 1.6384439359267736e-05,
      "loss": 0.1337,
      "step": 790
    },
    {
      "epoch": 1.8306636155606406,
      "grad_norm": 5.6683502197265625,
      "learning_rate": 1.633867276887872e-05,
      "loss": 0.1156,
      "step": 800
    },
    {
      "epoch": 1.8535469107551488,
      "grad_norm": 6.933206558227539,
      "learning_rate": 1.6292906178489704e-05,
      "loss": 0.1027,
      "step": 810
    },
    {
      "epoch": 1.8764302059496567,
      "grad_norm": 8.003060340881348,
      "learning_rate": 1.624713958810069e-05,
      "loss": 0.1492,
      "step": 820
    },
    {
      "epoch": 1.8993135011441646,
      "grad_norm": 5.105761528015137,
      "learning_rate": 1.620137299771167e-05,
      "loss": 0.1305,
      "step": 830
    },
    {
      "epoch": 1.9221967963386728,
      "grad_norm": 4.029310703277588,
      "learning_rate": 1.6155606407322655e-05,
      "loss": 0.0926,
      "step": 840
    },
    {
      "epoch": 1.9450800915331807,
      "grad_norm": 6.724945545196533,
      "learning_rate": 1.6109839816933638e-05,
      "loss": 0.1305,
      "step": 850
    },
    {
      "epoch": 1.9679633867276887,
      "grad_norm": 5.722589492797852,
      "learning_rate": 1.6064073226544624e-05,
      "loss": 0.095,
      "step": 860
    },
    {
      "epoch": 1.9908466819221968,
      "grad_norm": 10.910420417785645,
      "learning_rate": 1.6018306636155606e-05,
      "loss": 0.1176,
      "step": 870
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9629010695187166,
      "eval_f1": 0.8284389489953632,
      "eval_loss": 0.11917424201965332,
      "eval_precision": 0.9469964664310954,
      "eval_recall": 0.7362637362637363,
      "eval_runtime": 88.6455,
      "eval_samples_per_second": 67.685,
      "eval_steps_per_second": 2.121,
      "step": 874
    },
    {
      "epoch": 2.013729977116705,
      "grad_norm": 2.4758567810058594,
      "learning_rate": 1.5972540045766592e-05,
      "loss": 0.0868,
      "step": 880
    },
    {
      "epoch": 2.0366132723112127,
      "grad_norm": 4.147484302520752,
      "learning_rate": 1.5926773455377575e-05,
      "loss": 0.1029,
      "step": 890
    },
    {
      "epoch": 2.059496567505721,
      "grad_norm": 9.049445152282715,
      "learning_rate": 1.588100686498856e-05,
      "loss": 0.0755,
      "step": 900
    },
    {
      "epoch": 2.082379862700229,
      "grad_norm": 6.652467727661133,
      "learning_rate": 1.5835240274599543e-05,
      "loss": 0.078,
      "step": 910
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 38.61091613769531,
      "learning_rate": 1.578947368421053e-05,
      "loss": 0.1085,
      "step": 920
    },
    {
      "epoch": 2.128146453089245,
      "grad_norm": 4.511880874633789,
      "learning_rate": 1.5743707093821512e-05,
      "loss": 0.1303,
      "step": 930
    },
    {
      "epoch": 2.151029748283753,
      "grad_norm": 4.102357387542725,
      "learning_rate": 1.5697940503432498e-05,
      "loss": 0.0894,
      "step": 940
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 3.425349473953247,
      "learning_rate": 1.565217391304348e-05,
      "loss": 0.0846,
      "step": 950
    },
    {
      "epoch": 2.196796338672769,
      "grad_norm": 5.452822208404541,
      "learning_rate": 1.5606407322654463e-05,
      "loss": 0.0836,
      "step": 960
    },
    {
      "epoch": 2.219679633867277,
      "grad_norm": 7.9158616065979,
      "learning_rate": 1.556064073226545e-05,
      "loss": 0.0872,
      "step": 970
    },
    {
      "epoch": 2.242562929061785,
      "grad_norm": 7.226189136505127,
      "learning_rate": 1.551487414187643e-05,
      "loss": 0.0895,
      "step": 980
    },
    {
      "epoch": 2.265446224256293,
      "grad_norm": 3.194573163986206,
      "learning_rate": 1.5469107551487414e-05,
      "loss": 0.0854,
      "step": 990
    },
    {
      "epoch": 2.288329519450801,
      "grad_norm": 6.029909610748291,
      "learning_rate": 1.54233409610984e-05,
      "loss": 0.0686,
      "step": 1000
    },
    {
      "epoch": 2.311212814645309,
      "grad_norm": 1.7659450769424438,
      "learning_rate": 1.5377574370709382e-05,
      "loss": 0.0783,
      "step": 1010
    },
    {
      "epoch": 2.334096109839817,
      "grad_norm": 1.5410436391830444,
      "learning_rate": 1.533180778032037e-05,
      "loss": 0.0488,
      "step": 1020
    },
    {
      "epoch": 2.356979405034325,
      "grad_norm": 7.335301876068115,
      "learning_rate": 1.528604118993135e-05,
      "loss": 0.0677,
      "step": 1030
    },
    {
      "epoch": 2.379862700228833,
      "grad_norm": 4.642149448394775,
      "learning_rate": 1.5240274599542335e-05,
      "loss": 0.0421,
      "step": 1040
    },
    {
      "epoch": 2.402745995423341,
      "grad_norm": 2.3012402057647705,
      "learning_rate": 1.519450800915332e-05,
      "loss": 0.0802,
      "step": 1050
    },
    {
      "epoch": 2.425629290617849,
      "grad_norm": 2.3021984100341797,
      "learning_rate": 1.5148741418764304e-05,
      "loss": 0.0498,
      "step": 1060
    },
    {
      "epoch": 2.448512585812357,
      "grad_norm": 3.2866034507751465,
      "learning_rate": 1.5102974828375288e-05,
      "loss": 0.1025,
      "step": 1070
    },
    {
      "epoch": 2.471395881006865,
      "grad_norm": 6.835920810699463,
      "learning_rate": 1.5057208237986272e-05,
      "loss": 0.0939,
      "step": 1080
    },
    {
      "epoch": 2.494279176201373,
      "grad_norm": 5.5861663818359375,
      "learning_rate": 1.5011441647597256e-05,
      "loss": 0.0809,
      "step": 1090
    },
    {
      "epoch": 2.517162471395881,
      "grad_norm": 2.7106335163116455,
      "learning_rate": 1.496567505720824e-05,
      "loss": 0.0439,
      "step": 1100
    },
    {
      "epoch": 2.540045766590389,
      "grad_norm": 4.519847869873047,
      "learning_rate": 1.4919908466819223e-05,
      "loss": 0.0502,
      "step": 1110
    },
    {
      "epoch": 2.5629290617848968,
      "grad_norm": 7.827998161315918,
      "learning_rate": 1.4874141876430207e-05,
      "loss": 0.0946,
      "step": 1120
    },
    {
      "epoch": 2.585812356979405,
      "grad_norm": 12.935239791870117,
      "learning_rate": 1.4828375286041192e-05,
      "loss": 0.1043,
      "step": 1130
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 5.72468376159668,
      "learning_rate": 1.4782608695652174e-05,
      "loss": 0.1123,
      "step": 1140
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 6.866938591003418,
      "learning_rate": 1.4736842105263159e-05,
      "loss": 0.1296,
      "step": 1150
    },
    {
      "epoch": 2.654462242562929,
      "grad_norm": 10.10135555267334,
      "learning_rate": 1.4691075514874143e-05,
      "loss": 0.0818,
      "step": 1160
    },
    {
      "epoch": 2.677345537757437,
      "grad_norm": 4.036993026733398,
      "learning_rate": 1.4645308924485127e-05,
      "loss": 0.0564,
      "step": 1170
    },
    {
      "epoch": 2.700228832951945,
      "grad_norm": 2.1261093616485596,
      "learning_rate": 1.4599542334096111e-05,
      "loss": 0.0981,
      "step": 1180
    },
    {
      "epoch": 2.723112128146453,
      "grad_norm": 10.93330192565918,
      "learning_rate": 1.4553775743707096e-05,
      "loss": 0.0763,
      "step": 1190
    },
    {
      "epoch": 2.745995423340961,
      "grad_norm": 3.9310171604156494,
      "learning_rate": 1.4508009153318078e-05,
      "loss": 0.0677,
      "step": 1200
    },
    {
      "epoch": 2.7688787185354693,
      "grad_norm": 4.758055210113525,
      "learning_rate": 1.4462242562929062e-05,
      "loss": 0.0385,
      "step": 1210
    },
    {
      "epoch": 2.791762013729977,
      "grad_norm": 1.9399149417877197,
      "learning_rate": 1.4416475972540047e-05,
      "loss": 0.0782,
      "step": 1220
    },
    {
      "epoch": 2.814645308924485,
      "grad_norm": 8.758272171020508,
      "learning_rate": 1.4370709382151031e-05,
      "loss": 0.0999,
      "step": 1230
    },
    {
      "epoch": 2.837528604118993,
      "grad_norm": 3.6804635524749756,
      "learning_rate": 1.4324942791762015e-05,
      "loss": 0.0631,
      "step": 1240
    },
    {
      "epoch": 2.860411899313501,
      "grad_norm": 3.6472795009613037,
      "learning_rate": 1.4279176201373e-05,
      "loss": 0.0772,
      "step": 1250
    },
    {
      "epoch": 2.883295194508009,
      "grad_norm": 7.143889904022217,
      "learning_rate": 1.4233409610983984e-05,
      "loss": 0.0648,
      "step": 1260
    },
    {
      "epoch": 2.9061784897025174,
      "grad_norm": 3.0607123374938965,
      "learning_rate": 1.4187643020594968e-05,
      "loss": 0.0792,
      "step": 1270
    },
    {
      "epoch": 2.929061784897025,
      "grad_norm": 7.267963409423828,
      "learning_rate": 1.4141876430205952e-05,
      "loss": 0.069,
      "step": 1280
    },
    {
      "epoch": 2.9519450800915332,
      "grad_norm": 5.508252143859863,
      "learning_rate": 1.4096109839816933e-05,
      "loss": 0.0752,
      "step": 1290
    },
    {
      "epoch": 2.974828375286041,
      "grad_norm": 6.55360221862793,
      "learning_rate": 1.4050343249427917e-05,
      "loss": 0.0943,
      "step": 1300
    },
    {
      "epoch": 2.997711670480549,
      "grad_norm": 2.6840221881866455,
      "learning_rate": 1.4004576659038902e-05,
      "loss": 0.058,
      "step": 1310
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9744318181818182,
      "eval_f1": 0.8948453608247423,
      "eval_loss": 0.06955766677856445,
      "eval_precision": 0.8954607977991746,
      "eval_recall": 0.8942307692307693,
      "eval_runtime": 93.6343,
      "eval_samples_per_second": 64.079,
      "eval_steps_per_second": 2.008,
      "step": 1311
    },
    {
      "epoch": 3.0205949656750573,
      "grad_norm": 4.583639621734619,
      "learning_rate": 1.3958810068649886e-05,
      "loss": 0.041,
      "step": 1320
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 3.6137120723724365,
      "learning_rate": 1.391304347826087e-05,
      "loss": 0.044,
      "step": 1330
    },
    {
      "epoch": 3.066361556064073,
      "grad_norm": 3.4651057720184326,
      "learning_rate": 1.3867276887871854e-05,
      "loss": 0.0443,
      "step": 1340
    },
    {
      "epoch": 3.0892448512585813,
      "grad_norm": 0.8435571193695068,
      "learning_rate": 1.3821510297482839e-05,
      "loss": 0.0394,
      "step": 1350
    },
    {
      "epoch": 3.1121281464530894,
      "grad_norm": 1.845719814300537,
      "learning_rate": 1.3775743707093823e-05,
      "loss": 0.0448,
      "step": 1360
    },
    {
      "epoch": 3.135011441647597,
      "grad_norm": 3.0354435443878174,
      "learning_rate": 1.3729977116704807e-05,
      "loss": 0.0595,
      "step": 1370
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 3.105379104614258,
      "learning_rate": 1.3684210526315791e-05,
      "loss": 0.0535,
      "step": 1380
    },
    {
      "epoch": 3.1807780320366135,
      "grad_norm": 6.713377475738525,
      "learning_rate": 1.3638443935926776e-05,
      "loss": 0.0496,
      "step": 1390
    },
    {
      "epoch": 3.203661327231121,
      "grad_norm": 3.8853211402893066,
      "learning_rate": 1.359267734553776e-05,
      "loss": 0.0714,
      "step": 1400
    },
    {
      "epoch": 3.2265446224256293,
      "grad_norm": 4.38438081741333,
      "learning_rate": 1.3546910755148744e-05,
      "loss": 0.051,
      "step": 1410
    },
    {
      "epoch": 3.2494279176201375,
      "grad_norm": 1.1984024047851562,
      "learning_rate": 1.3501144164759727e-05,
      "loss": 0.0386,
      "step": 1420
    },
    {
      "epoch": 3.272311212814645,
      "grad_norm": 3.1366868019104004,
      "learning_rate": 1.3455377574370711e-05,
      "loss": 0.0372,
      "step": 1430
    },
    {
      "epoch": 3.2951945080091534,
      "grad_norm": 4.373237133026123,
      "learning_rate": 1.3409610983981693e-05,
      "loss": 0.0612,
      "step": 1440
    },
    {
      "epoch": 3.3180778032036615,
      "grad_norm": 1.4269403219223022,
      "learning_rate": 1.3363844393592678e-05,
      "loss": 0.0666,
      "step": 1450
    },
    {
      "epoch": 3.3409610983981692,
      "grad_norm": 3.590825319290161,
      "learning_rate": 1.3318077803203662e-05,
      "loss": 0.0505,
      "step": 1460
    },
    {
      "epoch": 3.3638443935926774,
      "grad_norm": 3.4688549041748047,
      "learning_rate": 1.3272311212814646e-05,
      "loss": 0.034,
      "step": 1470
    },
    {
      "epoch": 3.386727688787185,
      "grad_norm": 4.32855749130249,
      "learning_rate": 1.322654462242563e-05,
      "loss": 0.0357,
      "step": 1480
    },
    {
      "epoch": 3.4096109839816933,
      "grad_norm": 8.70949935913086,
      "learning_rate": 1.3180778032036615e-05,
      "loss": 0.0497,
      "step": 1490
    },
    {
      "epoch": 3.4324942791762014,
      "grad_norm": 6.7280707359313965,
      "learning_rate": 1.3135011441647599e-05,
      "loss": 0.0521,
      "step": 1500
    },
    {
      "epoch": 3.4553775743707096,
      "grad_norm": 1.8538730144500732,
      "learning_rate": 1.3089244851258582e-05,
      "loss": 0.0289,
      "step": 1510
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 9.685860633850098,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.0648,
      "step": 1520
    },
    {
      "epoch": 3.5011441647597255,
      "grad_norm": 6.0703558921813965,
      "learning_rate": 1.299771167048055e-05,
      "loss": 0.045,
      "step": 1530
    },
    {
      "epoch": 3.524027459954233,
      "grad_norm": 2.6697769165039062,
      "learning_rate": 1.2951945080091534e-05,
      "loss": 0.0365,
      "step": 1540
    },
    {
      "epoch": 3.5469107551487413,
      "grad_norm": 4.633593559265137,
      "learning_rate": 1.2906178489702519e-05,
      "loss": 0.0674,
      "step": 1550
    },
    {
      "epoch": 3.5697940503432495,
      "grad_norm": 3.6496129035949707,
      "learning_rate": 1.2860411899313503e-05,
      "loss": 0.0393,
      "step": 1560
    },
    {
      "epoch": 3.5926773455377576,
      "grad_norm": 0.898745596408844,
      "learning_rate": 1.2814645308924487e-05,
      "loss": 0.0584,
      "step": 1570
    },
    {
      "epoch": 3.6155606407322654,
      "grad_norm": 0.41930902004241943,
      "learning_rate": 1.2768878718535471e-05,
      "loss": 0.0591,
      "step": 1580
    },
    {
      "epoch": 3.6384439359267735,
      "grad_norm": 0.876033365726471,
      "learning_rate": 1.2723112128146454e-05,
      "loss": 0.0312,
      "step": 1590
    },
    {
      "epoch": 3.6613272311212812,
      "grad_norm": 1.6680142879486084,
      "learning_rate": 1.2677345537757438e-05,
      "loss": 0.0729,
      "step": 1600
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 1.7264326810836792,
      "learning_rate": 1.263157894736842e-05,
      "loss": 0.0589,
      "step": 1610
    },
    {
      "epoch": 3.7070938215102975,
      "grad_norm": 2.1859474182128906,
      "learning_rate": 1.2585812356979405e-05,
      "loss": 0.0818,
      "step": 1620
    },
    {
      "epoch": 3.7299771167048057,
      "grad_norm": 5.408481597900391,
      "learning_rate": 1.254004576659039e-05,
      "loss": 0.0514,
      "step": 1630
    },
    {
      "epoch": 3.7528604118993134,
      "grad_norm": 2.669456958770752,
      "learning_rate": 1.2494279176201373e-05,
      "loss": 0.0461,
      "step": 1640
    },
    {
      "epoch": 3.7757437070938216,
      "grad_norm": 0.6569640040397644,
      "learning_rate": 1.2448512585812358e-05,
      "loss": 0.0589,
      "step": 1650
    },
    {
      "epoch": 3.7986270022883293,
      "grad_norm": 11.679287910461426,
      "learning_rate": 1.2402745995423342e-05,
      "loss": 0.0271,
      "step": 1660
    },
    {
      "epoch": 3.8215102974828374,
      "grad_norm": 6.787223815917969,
      "learning_rate": 1.2356979405034326e-05,
      "loss": 0.0612,
      "step": 1670
    },
    {
      "epoch": 3.8443935926773456,
      "grad_norm": 0.508761465549469,
      "learning_rate": 1.231121281464531e-05,
      "loss": 0.0385,
      "step": 1680
    },
    {
      "epoch": 3.8672768878718538,
      "grad_norm": 3.3904716968536377,
      "learning_rate": 1.2265446224256295e-05,
      "loss": 0.0734,
      "step": 1690
    },
    {
      "epoch": 3.8901601830663615,
      "grad_norm": 1.5985212326049805,
      "learning_rate": 1.2219679633867279e-05,
      "loss": 0.0593,
      "step": 1700
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 1.164033055305481,
      "learning_rate": 1.2173913043478263e-05,
      "loss": 0.0198,
      "step": 1710
    },
    {
      "epoch": 3.9359267734553773,
      "grad_norm": 7.094393730163574,
      "learning_rate": 1.2128146453089247e-05,
      "loss": 0.0734,
      "step": 1720
    },
    {
      "epoch": 3.9588100686498855,
      "grad_norm": 3.213874101638794,
      "learning_rate": 1.2082379862700232e-05,
      "loss": 0.0377,
      "step": 1730
    },
    {
      "epoch": 3.9816933638443937,
      "grad_norm": 3.8790042400360107,
      "learning_rate": 1.2036613272311213e-05,
      "loss": 0.0327,
      "step": 1740
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9801136363636364,
      "eval_f1": 0.91493924231594,
      "eval_loss": 0.08343763649463654,
      "eval_precision": 0.9538002980625931,
      "eval_recall": 0.8791208791208791,
      "eval_runtime": 92.373,
      "eval_samples_per_second": 64.954,
      "eval_steps_per_second": 2.035,
      "step": 1748
    },
    {
      "epoch": 4.004576659038902,
      "grad_norm": 0.9034677743911743,
      "learning_rate": 1.1990846681922197e-05,
      "loss": 0.0173,
      "step": 1750
    },
    {
      "epoch": 4.02745995423341,
      "grad_norm": 1.2128766775131226,
      "learning_rate": 1.1945080091533181e-05,
      "loss": 0.0444,
      "step": 1760
    },
    {
      "epoch": 4.050343249427917,
      "grad_norm": 0.8621396422386169,
      "learning_rate": 1.1899313501144165e-05,
      "loss": 0.0079,
      "step": 1770
    },
    {
      "epoch": 4.073226544622425,
      "grad_norm": 0.5748212933540344,
      "learning_rate": 1.185354691075515e-05,
      "loss": 0.0099,
      "step": 1780
    },
    {
      "epoch": 4.0961098398169336,
      "grad_norm": 0.1272905170917511,
      "learning_rate": 1.1807780320366134e-05,
      "loss": 0.0191,
      "step": 1790
    },
    {
      "epoch": 4.118993135011442,
      "grad_norm": 2.774690866470337,
      "learning_rate": 1.1762013729977118e-05,
      "loss": 0.019,
      "step": 1800
    },
    {
      "epoch": 4.14187643020595,
      "grad_norm": 5.500736236572266,
      "learning_rate": 1.1716247139588102e-05,
      "loss": 0.0631,
      "step": 1810
    },
    {
      "epoch": 4.164759725400458,
      "grad_norm": 11.70427131652832,
      "learning_rate": 1.1670480549199087e-05,
      "loss": 0.0244,
      "step": 1820
    },
    {
      "epoch": 4.187643020594965,
      "grad_norm": 3.101321220397949,
      "learning_rate": 1.1624713958810069e-05,
      "loss": 0.0259,
      "step": 1830
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 2.4156932830810547,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.0457,
      "step": 1840
    },
    {
      "epoch": 4.233409610983982,
      "grad_norm": 5.813185691833496,
      "learning_rate": 1.1533180778032038e-05,
      "loss": 0.0479,
      "step": 1850
    },
    {
      "epoch": 4.25629290617849,
      "grad_norm": 6.010588645935059,
      "learning_rate": 1.1487414187643022e-05,
      "loss": 0.0414,
      "step": 1860
    },
    {
      "epoch": 4.279176201372998,
      "grad_norm": 0.020205892622470856,
      "learning_rate": 1.1441647597254006e-05,
      "loss": 0.0242,
      "step": 1870
    },
    {
      "epoch": 4.302059496567506,
      "grad_norm": 3.39011812210083,
      "learning_rate": 1.139588100686499e-05,
      "loss": 0.0367,
      "step": 1880
    },
    {
      "epoch": 4.324942791762013,
      "grad_norm": 1.6931498050689697,
      "learning_rate": 1.1350114416475973e-05,
      "loss": 0.0361,
      "step": 1890
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.5755450129508972,
      "learning_rate": 1.1304347826086957e-05,
      "loss": 0.0431,
      "step": 1900
    },
    {
      "epoch": 4.37070938215103,
      "grad_norm": 0.27539297938346863,
      "learning_rate": 1.1258581235697941e-05,
      "loss": 0.0211,
      "step": 1910
    },
    {
      "epoch": 4.393592677345538,
      "grad_norm": 4.711341381072998,
      "learning_rate": 1.1212814645308924e-05,
      "loss": 0.0537,
      "step": 1920
    },
    {
      "epoch": 4.416475972540046,
      "grad_norm": 0.20410139858722687,
      "learning_rate": 1.1167048054919908e-05,
      "loss": 0.0469,
      "step": 1930
    },
    {
      "epoch": 4.439359267734554,
      "grad_norm": 6.024087429046631,
      "learning_rate": 1.1121281464530893e-05,
      "loss": 0.0241,
      "step": 1940
    },
    {
      "epoch": 4.462242562929061,
      "grad_norm": 0.8599053025245667,
      "learning_rate": 1.1075514874141877e-05,
      "loss": 0.0231,
      "step": 1950
    },
    {
      "epoch": 4.48512585812357,
      "grad_norm": 4.958748817443848,
      "learning_rate": 1.1029748283752861e-05,
      "loss": 0.0259,
      "step": 1960
    },
    {
      "epoch": 4.508009153318078,
      "grad_norm": 0.09710206091403961,
      "learning_rate": 1.0983981693363845e-05,
      "loss": 0.0498,
      "step": 1970
    },
    {
      "epoch": 4.530892448512586,
      "grad_norm": 0.05756830796599388,
      "learning_rate": 1.093821510297483e-05,
      "loss": 0.0364,
      "step": 1980
    },
    {
      "epoch": 4.553775743707094,
      "grad_norm": 7.3818254470825195,
      "learning_rate": 1.0892448512585814e-05,
      "loss": 0.0473,
      "step": 1990
    },
    {
      "epoch": 4.576659038901602,
      "grad_norm": 4.930438041687012,
      "learning_rate": 1.0846681922196798e-05,
      "loss": 0.028,
      "step": 2000
    },
    {
      "epoch": 4.5995423340961095,
      "grad_norm": 5.651989936828613,
      "learning_rate": 1.0800915331807782e-05,
      "loss": 0.049,
      "step": 2010
    },
    {
      "epoch": 4.622425629290618,
      "grad_norm": 2.4302892684936523,
      "learning_rate": 1.0755148741418767e-05,
      "loss": 0.0544,
      "step": 2020
    },
    {
      "epoch": 4.645308924485126,
      "grad_norm": 3.9934704303741455,
      "learning_rate": 1.070938215102975e-05,
      "loss": 0.0339,
      "step": 2030
    },
    {
      "epoch": 4.668192219679634,
      "grad_norm": 6.335474014282227,
      "learning_rate": 1.0663615560640732e-05,
      "loss": 0.0473,
      "step": 2040
    },
    {
      "epoch": 4.691075514874142,
      "grad_norm": 5.887994766235352,
      "learning_rate": 1.0617848970251716e-05,
      "loss": 0.0603,
      "step": 2050
    },
    {
      "epoch": 4.71395881006865,
      "grad_norm": 3.239281177520752,
      "learning_rate": 1.05720823798627e-05,
      "loss": 0.0511,
      "step": 2060
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 1.6324783563613892,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.0202,
      "step": 2070
    },
    {
      "epoch": 4.759725400457666,
      "grad_norm": 5.568251609802246,
      "learning_rate": 1.0480549199084669e-05,
      "loss": 0.0377,
      "step": 2080
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 1.439910888671875,
      "learning_rate": 1.0434782608695653e-05,
      "loss": 0.033,
      "step": 2090
    },
    {
      "epoch": 4.805491990846682,
      "grad_norm": 0.11393535882234573,
      "learning_rate": 1.0389016018306637e-05,
      "loss": 0.0126,
      "step": 2100
    },
    {
      "epoch": 4.82837528604119,
      "grad_norm": 0.26254746317863464,
      "learning_rate": 1.0343249427917621e-05,
      "loss": 0.0338,
      "step": 2110
    },
    {
      "epoch": 4.851258581235698,
      "grad_norm": 4.017982482910156,
      "learning_rate": 1.0297482837528606e-05,
      "loss": 0.0474,
      "step": 2120
    },
    {
      "epoch": 4.874141876430206,
      "grad_norm": 1.9814671277999878,
      "learning_rate": 1.025171624713959e-05,
      "loss": 0.0207,
      "step": 2130
    },
    {
      "epoch": 4.897025171624714,
      "grad_norm": 5.925267696380615,
      "learning_rate": 1.0205949656750573e-05,
      "loss": 0.0516,
      "step": 2140
    },
    {
      "epoch": 4.919908466819222,
      "grad_norm": 5.346256732940674,
      "learning_rate": 1.0160183066361557e-05,
      "loss": 0.037,
      "step": 2150
    },
    {
      "epoch": 4.94279176201373,
      "grad_norm": 0.6102805137634277,
      "learning_rate": 1.0114416475972541e-05,
      "loss": 0.0553,
      "step": 2160
    },
    {
      "epoch": 4.965675057208238,
      "grad_norm": 3.6934521198272705,
      "learning_rate": 1.0068649885583525e-05,
      "loss": 0.0276,
      "step": 2170
    },
    {
      "epoch": 4.988558352402746,
      "grad_norm": 2.6384661197662354,
      "learning_rate": 1.002288329519451e-05,
      "loss": 0.0428,
      "step": 2180
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9804478609625669,
      "eval_f1": 0.9168443496801705,
      "eval_loss": 0.06903603672981262,
      "eval_precision": 0.9499263622974963,
      "eval_recall": 0.885989010989011,
      "eval_runtime": 96.048,
      "eval_samples_per_second": 62.469,
      "eval_steps_per_second": 1.957,
      "step": 2185
    },
    {
      "epoch": 5.011441647597254,
      "grad_norm": 0.17415505647659302,
      "learning_rate": 9.977116704805492e-06,
      "loss": 0.0119,
      "step": 2190
    },
    {
      "epoch": 5.034324942791762,
      "grad_norm": 1.5610079765319824,
      "learning_rate": 9.931350114416476e-06,
      "loss": 0.0088,
      "step": 2200
    },
    {
      "epoch": 5.05720823798627,
      "grad_norm": 0.4447494447231293,
      "learning_rate": 9.88558352402746e-06,
      "loss": 0.0037,
      "step": 2210
    },
    {
      "epoch": 5.080091533180778,
      "grad_norm": 2.4485549926757812,
      "learning_rate": 9.839816933638445e-06,
      "loss": 0.0299,
      "step": 2220
    },
    {
      "epoch": 5.102974828375286,
      "grad_norm": 3.228510618209839,
      "learning_rate": 9.794050343249429e-06,
      "loss": 0.0108,
      "step": 2230
    },
    {
      "epoch": 5.125858123569794,
      "grad_norm": 3.559724807739258,
      "learning_rate": 9.748283752860412e-06,
      "loss": 0.0354,
      "step": 2240
    },
    {
      "epoch": 5.148741418764302,
      "grad_norm": 1.6688742637634277,
      "learning_rate": 9.702517162471396e-06,
      "loss": 0.0221,
      "step": 2250
    },
    {
      "epoch": 5.17162471395881,
      "grad_norm": 2.3876123428344727,
      "learning_rate": 9.65675057208238e-06,
      "loss": 0.0229,
      "step": 2260
    },
    {
      "epoch": 5.194508009153318,
      "grad_norm": 0.08153535425662994,
      "learning_rate": 9.610983981693364e-06,
      "loss": 0.0119,
      "step": 2270
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 0.9028400778770447,
      "learning_rate": 9.565217391304349e-06,
      "loss": 0.0177,
      "step": 2280
    },
    {
      "epoch": 5.240274599542334,
      "grad_norm": 0.012994394637644291,
      "learning_rate": 9.519450800915333e-06,
      "loss": 0.0355,
      "step": 2290
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.03359037637710571,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.0219,
      "step": 2300
    },
    {
      "epoch": 5.28604118993135,
      "grad_norm": 0.9494956135749817,
      "learning_rate": 9.4279176201373e-06,
      "loss": 0.0339,
      "step": 2310
    },
    {
      "epoch": 5.308924485125858,
      "grad_norm": 0.2061980962753296,
      "learning_rate": 9.382151029748284e-06,
      "loss": 0.0333,
      "step": 2320
    },
    {
      "epoch": 5.331807780320366,
      "grad_norm": 4.1968793869018555,
      "learning_rate": 9.336384439359268e-06,
      "loss": 0.0329,
      "step": 2330
    },
    {
      "epoch": 5.354691075514874,
      "grad_norm": 9.51456356048584,
      "learning_rate": 9.290617848970253e-06,
      "loss": 0.0183,
      "step": 2340
    },
    {
      "epoch": 5.377574370709382,
      "grad_norm": 1.988985300064087,
      "learning_rate": 9.244851258581237e-06,
      "loss": 0.0163,
      "step": 2350
    },
    {
      "epoch": 5.4004576659038905,
      "grad_norm": 0.2086397409439087,
      "learning_rate": 9.199084668192221e-06,
      "loss": 0.0181,
      "step": 2360
    },
    {
      "epoch": 5.423340961098398,
      "grad_norm": 3.0383975505828857,
      "learning_rate": 9.153318077803205e-06,
      "loss": 0.0256,
      "step": 2370
    },
    {
      "epoch": 5.446224256292906,
      "grad_norm": 0.17775540053844452,
      "learning_rate": 9.107551487414188e-06,
      "loss": 0.0116,
      "step": 2380
    },
    {
      "epoch": 5.469107551487414,
      "grad_norm": 4.028380870819092,
      "learning_rate": 9.061784897025172e-06,
      "loss": 0.0258,
      "step": 2390
    },
    {
      "epoch": 5.491990846681922,
      "grad_norm": 5.044055938720703,
      "learning_rate": 9.016018306636156e-06,
      "loss": 0.026,
      "step": 2400
    },
    {
      "epoch": 5.51487414187643,
      "grad_norm": 4.115647315979004,
      "learning_rate": 8.97025171624714e-06,
      "loss": 0.0269,
      "step": 2410
    },
    {
      "epoch": 5.537757437070939,
      "grad_norm": 4.681589603424072,
      "learning_rate": 8.924485125858125e-06,
      "loss": 0.0167,
      "step": 2420
    },
    {
      "epoch": 5.560640732265446,
      "grad_norm": 5.382699966430664,
      "learning_rate": 8.878718535469109e-06,
      "loss": 0.0324,
      "step": 2430
    },
    {
      "epoch": 5.583524027459954,
      "grad_norm": 7.027338981628418,
      "learning_rate": 8.832951945080093e-06,
      "loss": 0.022,
      "step": 2440
    },
    {
      "epoch": 5.606407322654462,
      "grad_norm": 9.874638557434082,
      "learning_rate": 8.787185354691076e-06,
      "loss": 0.0319,
      "step": 2450
    },
    {
      "epoch": 5.62929061784897,
      "grad_norm": 0.30875471234321594,
      "learning_rate": 8.74141876430206e-06,
      "loss": 0.0258,
      "step": 2460
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 0.9245032072067261,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0221,
      "step": 2470
    },
    {
      "epoch": 5.675057208237987,
      "grad_norm": 0.01237072329968214,
      "learning_rate": 8.649885583524029e-06,
      "loss": 0.0308,
      "step": 2480
    },
    {
      "epoch": 5.697940503432494,
      "grad_norm": 9.10566234588623,
      "learning_rate": 8.604118993135013e-06,
      "loss": 0.0145,
      "step": 2490
    },
    {
      "epoch": 5.720823798627002,
      "grad_norm": 6.18948221206665,
      "learning_rate": 8.558352402745997e-06,
      "loss": 0.0319,
      "step": 2500
    },
    {
      "epoch": 5.74370709382151,
      "grad_norm": 5.712131023406982,
      "learning_rate": 8.51258581235698e-06,
      "loss": 0.0607,
      "step": 2510
    },
    {
      "epoch": 5.766590389016018,
      "grad_norm": 2.5701797008514404,
      "learning_rate": 8.466819221967964e-06,
      "loss": 0.0205,
      "step": 2520
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 0.0870947539806366,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.0151,
      "step": 2530
    },
    {
      "epoch": 5.812356979405035,
      "grad_norm": 4.727579593658447,
      "learning_rate": 8.375286041189932e-06,
      "loss": 0.0281,
      "step": 2540
    },
    {
      "epoch": 5.835240274599542,
      "grad_norm": 0.5226531624794006,
      "learning_rate": 8.329519450800915e-06,
      "loss": 0.023,
      "step": 2550
    },
    {
      "epoch": 5.85812356979405,
      "grad_norm": 12.173989295959473,
      "learning_rate": 8.2837528604119e-06,
      "loss": 0.0437,
      "step": 2560
    },
    {
      "epoch": 5.881006864988558,
      "grad_norm": 3.170365571975708,
      "learning_rate": 8.237986270022884e-06,
      "loss": 0.0144,
      "step": 2570
    },
    {
      "epoch": 5.9038901601830664,
      "grad_norm": 4.694824695587158,
      "learning_rate": 8.192219679633868e-06,
      "loss": 0.0381,
      "step": 2580
    },
    {
      "epoch": 5.926773455377575,
      "grad_norm": 0.027738602831959724,
      "learning_rate": 8.146453089244852e-06,
      "loss": 0.0262,
      "step": 2590
    },
    {
      "epoch": 5.949656750572083,
      "grad_norm": 5.651086807250977,
      "learning_rate": 8.100686498855835e-06,
      "loss": 0.0318,
      "step": 2600
    },
    {
      "epoch": 5.97254004576659,
      "grad_norm": 2.7229297161102295,
      "learning_rate": 8.054919908466819e-06,
      "loss": 0.0126,
      "step": 2610
    },
    {
      "epoch": 5.995423340961098,
      "grad_norm": 8.007221221923828,
      "learning_rate": 8.009153318077803e-06,
      "loss": 0.0243,
      "step": 2620
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9824532085561497,
      "eval_f1": 0.9265220433869839,
      "eval_loss": 0.07005905359983444,
      "eval_precision": 0.9443651925820257,
      "eval_recall": 0.9093406593406593,
      "eval_runtime": 95.9559,
      "eval_samples_per_second": 62.529,
      "eval_steps_per_second": 1.959,
      "step": 2622
    },
    {
      "epoch": 6.018306636155606,
      "grad_norm": 0.3222998082637787,
      "learning_rate": 7.963386727688787e-06,
      "loss": 0.0147,
      "step": 2630
    },
    {
      "epoch": 6.0411899313501145,
      "grad_norm": 0.24734783172607422,
      "learning_rate": 7.917620137299772e-06,
      "loss": 0.015,
      "step": 2640
    },
    {
      "epoch": 6.064073226544623,
      "grad_norm": 3.1282639503479004,
      "learning_rate": 7.871853546910756e-06,
      "loss": 0.0237,
      "step": 2650
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 7.787444114685059,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.0134,
      "step": 2660
    },
    {
      "epoch": 6.109839816933638,
      "grad_norm": 3.070502996444702,
      "learning_rate": 7.780320366132724e-06,
      "loss": 0.0383,
      "step": 2670
    },
    {
      "epoch": 6.132723112128146,
      "grad_norm": 0.22992098331451416,
      "learning_rate": 7.734553775743707e-06,
      "loss": 0.0239,
      "step": 2680
    },
    {
      "epoch": 6.155606407322654,
      "grad_norm": 0.8166487216949463,
      "learning_rate": 7.688787185354691e-06,
      "loss": 0.016,
      "step": 2690
    },
    {
      "epoch": 6.178489702517163,
      "grad_norm": 0.0457342192530632,
      "learning_rate": 7.643020594965675e-06,
      "loss": 0.008,
      "step": 2700
    },
    {
      "epoch": 6.201372997711671,
      "grad_norm": 4.451076507568359,
      "learning_rate": 7.59725400457666e-06,
      "loss": 0.0086,
      "step": 2710
    },
    {
      "epoch": 6.224256292906179,
      "grad_norm": 0.25628426671028137,
      "learning_rate": 7.551487414187644e-06,
      "loss": 0.0012,
      "step": 2720
    },
    {
      "epoch": 6.247139588100686,
      "grad_norm": 1.7264536619186401,
      "learning_rate": 7.505720823798628e-06,
      "loss": 0.0188,
      "step": 2730
    },
    {
      "epoch": 6.270022883295194,
      "grad_norm": 0.06191054359078407,
      "learning_rate": 7.459954233409612e-06,
      "loss": 0.0091,
      "step": 2740
    },
    {
      "epoch": 6.2929061784897025,
      "grad_norm": 0.5919049382209778,
      "learning_rate": 7.414187643020596e-06,
      "loss": 0.0131,
      "step": 2750
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 0.2608806788921356,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0197,
      "step": 2760
    },
    {
      "epoch": 6.338672768878719,
      "grad_norm": 2.764968156814575,
      "learning_rate": 7.3226544622425635e-06,
      "loss": 0.018,
      "step": 2770
    },
    {
      "epoch": 6.361556064073227,
      "grad_norm": 0.006101640872657299,
      "learning_rate": 7.276887871853548e-06,
      "loss": 0.0323,
      "step": 2780
    },
    {
      "epoch": 6.384439359267734,
      "grad_norm": 0.040563806891441345,
      "learning_rate": 7.231121281464531e-06,
      "loss": 0.0044,
      "step": 2790
    },
    {
      "epoch": 6.407322654462242,
      "grad_norm": 3.0011284351348877,
      "learning_rate": 7.1853546910755154e-06,
      "loss": 0.0291,
      "step": 2800
    },
    {
      "epoch": 6.4302059496567505,
      "grad_norm": 0.062363483011722565,
      "learning_rate": 7.1395881006865e-06,
      "loss": 0.0319,
      "step": 2810
    },
    {
      "epoch": 6.453089244851259,
      "grad_norm": 0.5485329627990723,
      "learning_rate": 7.093821510297484e-06,
      "loss": 0.0213,
      "step": 2820
    },
    {
      "epoch": 6.475972540045767,
      "grad_norm": 4.943570137023926,
      "learning_rate": 7.0480549199084665e-06,
      "loss": 0.0144,
      "step": 2830
    },
    {
      "epoch": 6.498855835240275,
      "grad_norm": 0.5241737961769104,
      "learning_rate": 7.002288329519451e-06,
      "loss": 0.011,
      "step": 2840
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 1.9669685363769531,
      "learning_rate": 6.956521739130435e-06,
      "loss": 0.0295,
      "step": 2850
    },
    {
      "epoch": 6.54462242562929,
      "grad_norm": 0.036339495331048965,
      "learning_rate": 6.910755148741419e-06,
      "loss": 0.0127,
      "step": 2860
    },
    {
      "epoch": 6.567505720823799,
      "grad_norm": 0.09395923465490341,
      "learning_rate": 6.8649885583524035e-06,
      "loss": 0.0128,
      "step": 2870
    },
    {
      "epoch": 6.590389016018307,
      "grad_norm": 6.288682460784912,
      "learning_rate": 6.819221967963388e-06,
      "loss": 0.0225,
      "step": 2880
    },
    {
      "epoch": 6.613272311212815,
      "grad_norm": 3.2030019760131836,
      "learning_rate": 6.773455377574372e-06,
      "loss": 0.0296,
      "step": 2890
    },
    {
      "epoch": 6.636155606407323,
      "grad_norm": 1.2916369438171387,
      "learning_rate": 6.7276887871853554e-06,
      "loss": 0.0025,
      "step": 2900
    },
    {
      "epoch": 6.65903890160183,
      "grad_norm": 3.7451248168945312,
      "learning_rate": 6.681922196796339e-06,
      "loss": 0.0141,
      "step": 2910
    },
    {
      "epoch": 6.6819221967963385,
      "grad_norm": 0.7712080478668213,
      "learning_rate": 6.636155606407323e-06,
      "loss": 0.0301,
      "step": 2920
    },
    {
      "epoch": 6.704805491990847,
      "grad_norm": 0.054504044353961945,
      "learning_rate": 6.590389016018307e-06,
      "loss": 0.0166,
      "step": 2930
    },
    {
      "epoch": 6.727688787185355,
      "grad_norm": 7.6945085525512695,
      "learning_rate": 6.544622425629291e-06,
      "loss": 0.0278,
      "step": 2940
    },
    {
      "epoch": 6.750572082379863,
      "grad_norm": 0.0024727678392082453,
      "learning_rate": 6.498855835240275e-06,
      "loss": 0.0088,
      "step": 2950
    },
    {
      "epoch": 6.77345537757437,
      "grad_norm": 2.5884735584259033,
      "learning_rate": 6.453089244851259e-06,
      "loss": 0.0174,
      "step": 2960
    },
    {
      "epoch": 6.796338672768878,
      "grad_norm": 2.9324798583984375,
      "learning_rate": 6.4073226544622435e-06,
      "loss": 0.0193,
      "step": 2970
    },
    {
      "epoch": 6.8192219679633865,
      "grad_norm": 7.1289286613464355,
      "learning_rate": 6.361556064073227e-06,
      "loss": 0.0174,
      "step": 2980
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 1.6657058000564575,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.0523,
      "step": 2990
    },
    {
      "epoch": 6.864988558352403,
      "grad_norm": 0.6457635760307312,
      "learning_rate": 6.270022883295195e-06,
      "loss": 0.0177,
      "step": 3000
    },
    {
      "epoch": 6.887871853546911,
      "grad_norm": 2.000897169113159,
      "learning_rate": 6.224256292906179e-06,
      "loss": 0.0087,
      "step": 3010
    },
    {
      "epoch": 6.910755148741419,
      "grad_norm": 5.679478645324707,
      "learning_rate": 6.178489702517163e-06,
      "loss": 0.0131,
      "step": 3020
    },
    {
      "epoch": 6.933638443935926,
      "grad_norm": 9.040837287902832,
      "learning_rate": 6.132723112128147e-06,
      "loss": 0.0092,
      "step": 3030
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 0.38332706689834595,
      "learning_rate": 6.086956521739132e-06,
      "loss": 0.0205,
      "step": 3040
    },
    {
      "epoch": 6.979405034324943,
      "grad_norm": 0.3159632682800293,
      "learning_rate": 6.041189931350116e-06,
      "loss": 0.0118,
      "step": 3050
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9829545454545454,
      "eval_f1": 0.9301369863013699,
      "eval_loss": 0.06939110904932022,
      "eval_precision": 0.9275956284153005,
      "eval_recall": 0.9326923076923077,
      "eval_runtime": 93.8683,
      "eval_samples_per_second": 63.919,
      "eval_steps_per_second": 2.003,
      "step": 3059
    },
    {
      "epoch": 7.002288329519451,
      "grad_norm": 0.05171563848853111,
      "learning_rate": 5.995423340961098e-06,
      "loss": 0.0087,
      "step": 3060
    },
    {
      "epoch": 7.025171624713959,
      "grad_norm": 0.42876118421554565,
      "learning_rate": 5.949656750572083e-06,
      "loss": 0.0103,
      "step": 3070
    },
    {
      "epoch": 7.048054919908467,
      "grad_norm": 0.1294495016336441,
      "learning_rate": 5.903890160183067e-06,
      "loss": 0.0047,
      "step": 3080
    },
    {
      "epoch": 7.0709382151029745,
      "grad_norm": 3.0173261165618896,
      "learning_rate": 5.858123569794051e-06,
      "loss": 0.0074,
      "step": 3090
    },
    {
      "epoch": 7.093821510297483,
      "grad_norm": 3.1516478061676025,
      "learning_rate": 5.8123569794050346e-06,
      "loss": 0.005,
      "step": 3100
    },
    {
      "epoch": 7.116704805491991,
      "grad_norm": 0.11754444986581802,
      "learning_rate": 5.766590389016019e-06,
      "loss": 0.0145,
      "step": 3110
    },
    {
      "epoch": 7.139588100686499,
      "grad_norm": 0.2174517959356308,
      "learning_rate": 5.720823798627003e-06,
      "loss": 0.0056,
      "step": 3120
    },
    {
      "epoch": 7.162471395881007,
      "grad_norm": 3.00949764251709,
      "learning_rate": 5.6750572082379865e-06,
      "loss": 0.0151,
      "step": 3130
    },
    {
      "epoch": 7.185354691075515,
      "grad_norm": 2.7608277797698975,
      "learning_rate": 5.629290617848971e-06,
      "loss": 0.0117,
      "step": 3140
    },
    {
      "epoch": 7.2082379862700225,
      "grad_norm": 2.6862595081329346,
      "learning_rate": 5.583524027459954e-06,
      "loss": 0.017,
      "step": 3150
    },
    {
      "epoch": 7.231121281464531,
      "grad_norm": 0.04384951665997505,
      "learning_rate": 5.537757437070938e-06,
      "loss": 0.003,
      "step": 3160
    },
    {
      "epoch": 7.254004576659039,
      "grad_norm": 0.1605703979730606,
      "learning_rate": 5.491990846681923e-06,
      "loss": 0.0195,
      "step": 3170
    },
    {
      "epoch": 7.276887871853547,
      "grad_norm": 0.01136828027665615,
      "learning_rate": 5.446224256292907e-06,
      "loss": 0.0091,
      "step": 3180
    },
    {
      "epoch": 7.299771167048055,
      "grad_norm": 0.06643375009298325,
      "learning_rate": 5.400457665903891e-06,
      "loss": 0.0034,
      "step": 3190
    },
    {
      "epoch": 7.322654462242563,
      "grad_norm": 0.01937054842710495,
      "learning_rate": 5.354691075514875e-06,
      "loss": 0.0184,
      "step": 3200
    },
    {
      "epoch": 7.345537757437071,
      "grad_norm": 2.4490725994110107,
      "learning_rate": 5.308924485125858e-06,
      "loss": 0.0116,
      "step": 3210
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 0.7850732803344727,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.0042,
      "step": 3220
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 0.024387622252106667,
      "learning_rate": 5.2173913043478265e-06,
      "loss": 0.0199,
      "step": 3230
    },
    {
      "epoch": 7.414187643020595,
      "grad_norm": 0.4941574037075043,
      "learning_rate": 5.171624713958811e-06,
      "loss": 0.0058,
      "step": 3240
    },
    {
      "epoch": 7.437070938215103,
      "grad_norm": 0.3396885097026825,
      "learning_rate": 5.125858123569795e-06,
      "loss": 0.0022,
      "step": 3250
    },
    {
      "epoch": 7.459954233409611,
      "grad_norm": 0.036945633590221405,
      "learning_rate": 5.080091533180778e-06,
      "loss": 0.007,
      "step": 3260
    },
    {
      "epoch": 7.482837528604119,
      "grad_norm": 0.05399995297193527,
      "learning_rate": 5.034324942791763e-06,
      "loss": 0.0036,
      "step": 3270
    },
    {
      "epoch": 7.505720823798627,
      "grad_norm": 4.101680278778076,
      "learning_rate": 4.988558352402746e-06,
      "loss": 0.0177,
      "step": 3280
    },
    {
      "epoch": 7.528604118993135,
      "grad_norm": 0.7754659652709961,
      "learning_rate": 4.94279176201373e-06,
      "loss": 0.0093,
      "step": 3290
    },
    {
      "epoch": 7.551487414187643,
      "grad_norm": 0.06629041582345963,
      "learning_rate": 4.8970251716247146e-06,
      "loss": 0.014,
      "step": 3300
    },
    {
      "epoch": 7.574370709382151,
      "grad_norm": 0.4083332121372223,
      "learning_rate": 4.851258581235698e-06,
      "loss": 0.0236,
      "step": 3310
    },
    {
      "epoch": 7.597254004576659,
      "grad_norm": 0.893807590007782,
      "learning_rate": 4.805491990846682e-06,
      "loss": 0.0101,
      "step": 3320
    },
    {
      "epoch": 7.620137299771167,
      "grad_norm": 8.685863494873047,
      "learning_rate": 4.7597254004576665e-06,
      "loss": 0.0212,
      "step": 3330
    },
    {
      "epoch": 7.643020594965675,
      "grad_norm": 1.2080694437026978,
      "learning_rate": 4.71395881006865e-06,
      "loss": 0.0076,
      "step": 3340
    },
    {
      "epoch": 7.665903890160183,
      "grad_norm": 0.7822521924972534,
      "learning_rate": 4.668192219679634e-06,
      "loss": 0.0087,
      "step": 3350
    },
    {
      "epoch": 7.688787185354691,
      "grad_norm": 0.3152594268321991,
      "learning_rate": 4.622425629290618e-06,
      "loss": 0.009,
      "step": 3360
    },
    {
      "epoch": 7.711670480549199,
      "grad_norm": 5.120791912078857,
      "learning_rate": 4.576659038901603e-06,
      "loss": 0.0147,
      "step": 3370
    },
    {
      "epoch": 7.7345537757437075,
      "grad_norm": 2.7275776863098145,
      "learning_rate": 4.530892448512586e-06,
      "loss": 0.0273,
      "step": 3380
    },
    {
      "epoch": 7.757437070938215,
      "grad_norm": 5.445882320404053,
      "learning_rate": 4.48512585812357e-06,
      "loss": 0.0222,
      "step": 3390
    },
    {
      "epoch": 7.780320366132723,
      "grad_norm": 0.47574368119239807,
      "learning_rate": 4.4393592677345545e-06,
      "loss": 0.0151,
      "step": 3400
    },
    {
      "epoch": 7.803203661327231,
      "grad_norm": 7.222473621368408,
      "learning_rate": 4.393592677345538e-06,
      "loss": 0.022,
      "step": 3410
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 0.0417601503431797,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0054,
      "step": 3420
    },
    {
      "epoch": 7.848970251716247,
      "grad_norm": 0.09057100117206573,
      "learning_rate": 4.3020594965675065e-06,
      "loss": 0.0104,
      "step": 3430
    },
    {
      "epoch": 7.871853546910755,
      "grad_norm": 0.005034495610743761,
      "learning_rate": 4.25629290617849e-06,
      "loss": 0.0095,
      "step": 3440
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 0.034734684973955154,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.0044,
      "step": 3450
    },
    {
      "epoch": 7.917620137299771,
      "grad_norm": 0.02027568779885769,
      "learning_rate": 4.1647597254004575e-06,
      "loss": 0.008,
      "step": 3460
    },
    {
      "epoch": 7.940503432494279,
      "grad_norm": 0.8542553186416626,
      "learning_rate": 4.118993135011442e-06,
      "loss": 0.0077,
      "step": 3470
    },
    {
      "epoch": 7.963386727688787,
      "grad_norm": 0.06896265596151352,
      "learning_rate": 4.073226544622426e-06,
      "loss": 0.0079,
      "step": 3480
    },
    {
      "epoch": 7.9862700228832955,
      "grad_norm": 0.0032552790362387896,
      "learning_rate": 4.0274599542334094e-06,
      "loss": 0.0018,
      "step": 3490
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.982620320855615,
      "eval_f1": 0.9274755927475592,
      "eval_loss": 0.08695995807647705,
      "eval_precision": 0.9419263456090652,
      "eval_recall": 0.9134615384615384,
      "eval_runtime": 119.1112,
      "eval_samples_per_second": 50.373,
      "eval_steps_per_second": 1.578,
      "step": 3496
    },
    {
      "epoch": 8.009153318077804,
      "grad_norm": 0.04643220081925392,
      "learning_rate": 3.981693363844394e-06,
      "loss": 0.0092,
      "step": 3500
    },
    {
      "epoch": 8.03203661327231,
      "grad_norm": 0.11554805934429169,
      "learning_rate": 3.935926773455378e-06,
      "loss": 0.0024,
      "step": 3510
    },
    {
      "epoch": 8.05491990846682,
      "grad_norm": 0.09723924100399017,
      "learning_rate": 3.890160183066362e-06,
      "loss": 0.005,
      "step": 3520
    },
    {
      "epoch": 8.077803203661327,
      "grad_norm": 0.09854812175035477,
      "learning_rate": 3.844393592677346e-06,
      "loss": 0.0131,
      "step": 3530
    },
    {
      "epoch": 8.100686498855834,
      "grad_norm": 3.7235279083251953,
      "learning_rate": 3.79862700228833e-06,
      "loss": 0.0071,
      "step": 3540
    },
    {
      "epoch": 8.123569794050344,
      "grad_norm": 5.941033840179443,
      "learning_rate": 3.752860411899314e-06,
      "loss": 0.0063,
      "step": 3550
    },
    {
      "epoch": 8.14645308924485,
      "grad_norm": 0.539469838142395,
      "learning_rate": 3.707093821510298e-06,
      "loss": 0.0039,
      "step": 3560
    },
    {
      "epoch": 8.16933638443936,
      "grad_norm": 0.06535732001066208,
      "learning_rate": 3.6613272311212818e-06,
      "loss": 0.0096,
      "step": 3570
    },
    {
      "epoch": 8.192219679633867,
      "grad_norm": 3.8661279678344727,
      "learning_rate": 3.6155606407322656e-06,
      "loss": 0.0062,
      "step": 3580
    },
    {
      "epoch": 8.215102974828376,
      "grad_norm": 0.4330955743789673,
      "learning_rate": 3.56979405034325e-06,
      "loss": 0.0164,
      "step": 3590
    },
    {
      "epoch": 8.237986270022883,
      "grad_norm": 0.699253499507904,
      "learning_rate": 3.5240274599542333e-06,
      "loss": 0.0016,
      "step": 3600
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 0.03474719077348709,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.0089,
      "step": 3610
    },
    {
      "epoch": 8.2837528604119,
      "grad_norm": 0.18072909116744995,
      "learning_rate": 3.4324942791762018e-06,
      "loss": 0.0014,
      "step": 3620
    },
    {
      "epoch": 8.306636155606407,
      "grad_norm": 0.05544484779238701,
      "learning_rate": 3.386727688787186e-06,
      "loss": 0.0003,
      "step": 3630
    },
    {
      "epoch": 8.329519450800916,
      "grad_norm": 0.6204032301902771,
      "learning_rate": 3.3409610983981694e-06,
      "loss": 0.0186,
      "step": 3640
    },
    {
      "epoch": 8.352402745995423,
      "grad_norm": 0.04583967104554176,
      "learning_rate": 3.2951945080091537e-06,
      "loss": 0.0038,
      "step": 3650
    },
    {
      "epoch": 8.37528604118993,
      "grad_norm": 0.05548746883869171,
      "learning_rate": 3.2494279176201375e-06,
      "loss": 0.0015,
      "step": 3660
    },
    {
      "epoch": 8.39816933638444,
      "grad_norm": 0.6191365718841553,
      "learning_rate": 3.2036613272311218e-06,
      "loss": 0.0029,
      "step": 3670
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 1.543373942375183,
      "learning_rate": 3.157894736842105e-06,
      "loss": 0.0004,
      "step": 3680
    },
    {
      "epoch": 8.443935926773456,
      "grad_norm": 0.02935338392853737,
      "learning_rate": 3.1121281464530894e-06,
      "loss": 0.0183,
      "step": 3690
    },
    {
      "epoch": 8.466819221967963,
      "grad_norm": 4.289392471313477,
      "learning_rate": 3.0663615560640737e-06,
      "loss": 0.0121,
      "step": 3700
    },
    {
      "epoch": 8.48970251716247,
      "grad_norm": 9.69717025756836,
      "learning_rate": 3.020594965675058e-06,
      "loss": 0.0231,
      "step": 3710
    },
    {
      "epoch": 8.51258581235698,
      "grad_norm": 0.3092389702796936,
      "learning_rate": 2.9748283752860413e-06,
      "loss": 0.0062,
      "step": 3720
    },
    {
      "epoch": 8.535469107551487,
      "grad_norm": 0.01058749109506607,
      "learning_rate": 2.9290617848970256e-06,
      "loss": 0.0004,
      "step": 3730
    },
    {
      "epoch": 8.558352402745996,
      "grad_norm": 0.06625694781541824,
      "learning_rate": 2.8832951945080094e-06,
      "loss": 0.0039,
      "step": 3740
    },
    {
      "epoch": 8.581235697940503,
      "grad_norm": 0.5801059603691101,
      "learning_rate": 2.8375286041189932e-06,
      "loss": 0.0248,
      "step": 3750
    },
    {
      "epoch": 8.604118993135012,
      "grad_norm": 5.860234260559082,
      "learning_rate": 2.791762013729977e-06,
      "loss": 0.0048,
      "step": 3760
    },
    {
      "epoch": 8.62700228832952,
      "grad_norm": 0.006080543156713247,
      "learning_rate": 2.7459954233409613e-06,
      "loss": 0.0056,
      "step": 3770
    },
    {
      "epoch": 8.649885583524027,
      "grad_norm": 10.60161018371582,
      "learning_rate": 2.7002288329519456e-06,
      "loss": 0.0057,
      "step": 3780
    },
    {
      "epoch": 8.672768878718536,
      "grad_norm": 0.015166214667260647,
      "learning_rate": 2.654462242562929e-06,
      "loss": 0.0059,
      "step": 3790
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.31755921244621277,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 0.0045,
      "step": 3800
    },
    {
      "epoch": 8.718535469107552,
      "grad_norm": 0.1669529229402542,
      "learning_rate": 2.5629290617848975e-06,
      "loss": 0.0044,
      "step": 3810
    },
    {
      "epoch": 8.74141876430206,
      "grad_norm": 0.004484375938773155,
      "learning_rate": 2.5171624713958813e-06,
      "loss": 0.0071,
      "step": 3820
    },
    {
      "epoch": 8.764302059496568,
      "grad_norm": 0.8166099786758423,
      "learning_rate": 2.471395881006865e-06,
      "loss": 0.0008,
      "step": 3830
    },
    {
      "epoch": 8.787185354691076,
      "grad_norm": 0.0028758023399859667,
      "learning_rate": 2.425629290617849e-06,
      "loss": 0.0187,
      "step": 3840
    },
    {
      "epoch": 8.810068649885583,
      "grad_norm": 0.0008204138721339405,
      "learning_rate": 2.3798627002288332e-06,
      "loss": 0.0118,
      "step": 3850
    },
    {
      "epoch": 8.832951945080092,
      "grad_norm": 0.9510209560394287,
      "learning_rate": 2.334096109839817e-06,
      "loss": 0.0052,
      "step": 3860
    },
    {
      "epoch": 8.8558352402746,
      "grad_norm": 3.690566301345825,
      "learning_rate": 2.2883295194508013e-06,
      "loss": 0.012,
      "step": 3870
    },
    {
      "epoch": 8.878718535469108,
      "grad_norm": 0.07479076832532883,
      "learning_rate": 2.242562929061785e-06,
      "loss": 0.002,
      "step": 3880
    },
    {
      "epoch": 8.901601830663616,
      "grad_norm": 0.024842077866196632,
      "learning_rate": 2.196796338672769e-06,
      "loss": 0.0107,
      "step": 3890
    },
    {
      "epoch": 8.924485125858123,
      "grad_norm": 2.384131669998169,
      "learning_rate": 2.1510297482837532e-06,
      "loss": 0.0034,
      "step": 3900
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 0.07673536241054535,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.0098,
      "step": 3910
    },
    {
      "epoch": 8.97025171624714,
      "grad_norm": 0.1322290003299713,
      "learning_rate": 2.059496567505721e-06,
      "loss": 0.0045,
      "step": 3920
    },
    {
      "epoch": 8.993135011441648,
      "grad_norm": 0.04230470955371857,
      "learning_rate": 2.0137299771167047e-06,
      "loss": 0.0081,
      "step": 3930
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9827874331550802,
      "eval_f1": 0.9284225156358582,
      "eval_loss": 0.08971929550170898,
      "eval_precision": 0.939521800281294,
      "eval_recall": 0.9175824175824175,
      "eval_runtime": 114.6978,
      "eval_samples_per_second": 52.311,
      "eval_steps_per_second": 1.639,
      "step": 3933
    },
    {
      "epoch": 9.016018306636155,
      "grad_norm": 0.012881986796855927,
      "learning_rate": 1.967963386727689e-06,
      "loss": 0.0073,
      "step": 3940
    },
    {
      "epoch": 9.038901601830664,
      "grad_norm": 0.014508729800581932,
      "learning_rate": 1.922196796338673e-06,
      "loss": 0.0013,
      "step": 3950
    },
    {
      "epoch": 9.061784897025172,
      "grad_norm": 0.2502972185611725,
      "learning_rate": 1.876430205949657e-06,
      "loss": 0.0048,
      "step": 3960
    },
    {
      "epoch": 9.084668192219679,
      "grad_norm": 0.01896677166223526,
      "learning_rate": 1.8306636155606409e-06,
      "loss": 0.013,
      "step": 3970
    },
    {
      "epoch": 9.107551487414188,
      "grad_norm": 1.5963982343673706,
      "learning_rate": 1.784897025171625e-06,
      "loss": 0.002,
      "step": 3980
    },
    {
      "epoch": 9.130434782608695,
      "grad_norm": 0.0534282848238945,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 0.0019,
      "step": 3990
    },
    {
      "epoch": 9.153318077803204,
      "grad_norm": 0.0746980682015419,
      "learning_rate": 1.693363844393593e-06,
      "loss": 0.0009,
      "step": 4000
    },
    {
      "epoch": 9.176201372997712,
      "grad_norm": 0.02259652316570282,
      "learning_rate": 1.6475972540045768e-06,
      "loss": 0.0018,
      "step": 4010
    },
    {
      "epoch": 9.199084668192219,
      "grad_norm": 0.21538366377353668,
      "learning_rate": 1.6018306636155609e-06,
      "loss": 0.006,
      "step": 4020
    },
    {
      "epoch": 9.221967963386728,
      "grad_norm": 0.014438838697969913,
      "learning_rate": 1.5560640732265447e-06,
      "loss": 0.0028,
      "step": 4030
    },
    {
      "epoch": 9.244851258581235,
      "grad_norm": 0.6944578886032104,
      "learning_rate": 1.510297482837529e-06,
      "loss": 0.0041,
      "step": 4040
    },
    {
      "epoch": 9.267734553775744,
      "grad_norm": 0.01264596451073885,
      "learning_rate": 1.4645308924485128e-06,
      "loss": 0.0087,
      "step": 4050
    },
    {
      "epoch": 9.290617848970252,
      "grad_norm": 0.027698051184415817,
      "learning_rate": 1.4187643020594966e-06,
      "loss": 0.0094,
      "step": 4060
    },
    {
      "epoch": 9.31350114416476,
      "grad_norm": 0.9419615864753723,
      "learning_rate": 1.3729977116704807e-06,
      "loss": 0.0069,
      "step": 4070
    },
    {
      "epoch": 9.336384439359268,
      "grad_norm": 0.11674394458532333,
      "learning_rate": 1.3272311212814645e-06,
      "loss": 0.0007,
      "step": 4080
    },
    {
      "epoch": 9.359267734553775,
      "grad_norm": 0.031287357211112976,
      "learning_rate": 1.2814645308924487e-06,
      "loss": 0.0007,
      "step": 4090
    },
    {
      "epoch": 9.382151029748284,
      "grad_norm": 2.1444666385650635,
      "learning_rate": 1.2356979405034326e-06,
      "loss": 0.0127,
      "step": 4100
    },
    {
      "epoch": 9.405034324942791,
      "grad_norm": 2.813983201980591,
      "learning_rate": 1.1899313501144166e-06,
      "loss": 0.0019,
      "step": 4110
    },
    {
      "epoch": 9.4279176201373,
      "grad_norm": 0.006453158799558878,
      "learning_rate": 1.1441647597254007e-06,
      "loss": 0.0165,
      "step": 4120
    },
    {
      "epoch": 9.450800915331808,
      "grad_norm": 0.007326842285692692,
      "learning_rate": 1.0983981693363845e-06,
      "loss": 0.0104,
      "step": 4130
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 0.02270878106355667,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.0015,
      "step": 4140
    },
    {
      "epoch": 9.496567505720824,
      "grad_norm": 0.024161946028470993,
      "learning_rate": 1.0068649885583524e-06,
      "loss": 0.0058,
      "step": 4150
    },
    {
      "epoch": 9.519450800915331,
      "grad_norm": 0.36080402135849,
      "learning_rate": 9.610983981693364e-07,
      "loss": 0.0008,
      "step": 4160
    },
    {
      "epoch": 9.54233409610984,
      "grad_norm": 1.3202226161956787,
      "learning_rate": 9.153318077803204e-07,
      "loss": 0.0009,
      "step": 4170
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 0.005196870770305395,
      "learning_rate": 8.695652173913044e-07,
      "loss": 0.0009,
      "step": 4180
    },
    {
      "epoch": 9.588100686498855,
      "grad_norm": 0.06726020574569702,
      "learning_rate": 8.237986270022884e-07,
      "loss": 0.0003,
      "step": 4190
    },
    {
      "epoch": 9.610983981693364,
      "grad_norm": 0.019157767295837402,
      "learning_rate": 7.780320366132724e-07,
      "loss": 0.0107,
      "step": 4200
    },
    {
      "epoch": 9.633867276887871,
      "grad_norm": 1.2248375415802002,
      "learning_rate": 7.322654462242564e-07,
      "loss": 0.0028,
      "step": 4210
    },
    {
      "epoch": 9.65675057208238,
      "grad_norm": 1.9238122701644897,
      "learning_rate": 6.864988558352403e-07,
      "loss": 0.0019,
      "step": 4220
    },
    {
      "epoch": 9.679633867276888,
      "grad_norm": 0.07694502919912338,
      "learning_rate": 6.407322654462244e-07,
      "loss": 0.0049,
      "step": 4230
    },
    {
      "epoch": 9.702517162471397,
      "grad_norm": 0.5617258548736572,
      "learning_rate": 5.949656750572083e-07,
      "loss": 0.0023,
      "step": 4240
    },
    {
      "epoch": 9.725400457665904,
      "grad_norm": 0.28722482919692993,
      "learning_rate": 5.491990846681922e-07,
      "loss": 0.0052,
      "step": 4250
    },
    {
      "epoch": 9.748283752860411,
      "grad_norm": 0.0009547073277644813,
      "learning_rate": 5.034324942791762e-07,
      "loss": 0.0007,
      "step": 4260
    },
    {
      "epoch": 9.77116704805492,
      "grad_norm": 4.578179359436035,
      "learning_rate": 4.576659038901602e-07,
      "loss": 0.0096,
      "step": 4270
    },
    {
      "epoch": 9.794050343249427,
      "grad_norm": 1.4444572925567627,
      "learning_rate": 4.118993135011442e-07,
      "loss": 0.0038,
      "step": 4280
    },
    {
      "epoch": 9.816933638443937,
      "grad_norm": 0.4045136868953705,
      "learning_rate": 3.661327231121282e-07,
      "loss": 0.0002,
      "step": 4290
    },
    {
      "epoch": 9.839816933638444,
      "grad_norm": 0.041961558163166046,
      "learning_rate": 3.203661327231122e-07,
      "loss": 0.0077,
      "step": 4300
    },
    {
      "epoch": 9.862700228832953,
      "grad_norm": 0.006969097536057234,
      "learning_rate": 2.745995423340961e-07,
      "loss": 0.0028,
      "step": 4310
    },
    {
      "epoch": 9.88558352402746,
      "grad_norm": 0.016398349776864052,
      "learning_rate": 2.288329519450801e-07,
      "loss": 0.0016,
      "step": 4320
    },
    {
      "epoch": 9.908466819221967,
      "grad_norm": 0.23048293590545654,
      "learning_rate": 1.830663615560641e-07,
      "loss": 0.0045,
      "step": 4330
    },
    {
      "epoch": 9.931350114416476,
      "grad_norm": 0.2840723991394043,
      "learning_rate": 1.3729977116704806e-07,
      "loss": 0.004,
      "step": 4340
    },
    {
      "epoch": 9.954233409610984,
      "grad_norm": 0.5142775177955627,
      "learning_rate": 9.153318077803205e-08,
      "loss": 0.0083,
      "step": 4350
    },
    {
      "epoch": 9.977116704805493,
      "grad_norm": 0.004056383389979601,
      "learning_rate": 4.5766590389016025e-08,
      "loss": 0.0008,
      "step": 4360
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.657891035079956,
      "learning_rate": 0.0,
      "loss": 0.0042,
      "step": 4370
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9837901069518716,
      "eval_f1": 0.9333333333333335,
      "eval_loss": 0.08960707485675812,
      "eval_precision": 0.9339752407152683,
      "eval_recall": 0.9326923076923077,
      "eval_runtime": 118.598,
      "eval_samples_per_second": 50.591,
      "eval_steps_per_second": 1.585,
      "step": 4370
    }
  ],
  "logging_steps": 10,
  "max_steps": 4370,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.708220872851456e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
