{
  "best_metric": 0.918918918918919,
  "best_model_checkpoint": "../saved_models/gpu_xsrf/checkpoint-130662",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 130662,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00010714668381013607,
      "grad_norm": 57.963138580322266,
      "learning_rate": 1.999985713775492e-05,
      "loss": 0.484,
      "step": 1
    },
    {
      "epoch": 0.0010714668381013607,
      "grad_norm": 28.774993896484375,
      "learning_rate": 1.99985713775492e-05,
      "loss": 0.74,
      "step": 10
    },
    {
      "epoch": 0.0021429336762027215,
      "grad_norm": 55.2821044921875,
      "learning_rate": 1.9997142755098397e-05,
      "loss": 0.7452,
      "step": 20
    },
    {
      "epoch": 0.0032144005143040825,
      "grad_norm": 19.437530517578125,
      "learning_rate": 1.9995714132647596e-05,
      "loss": 0.4722,
      "step": 30
    },
    {
      "epoch": 0.004285867352405443,
      "grad_norm": 11.154376983642578,
      "learning_rate": 1.9994285510196792e-05,
      "loss": 0.9384,
      "step": 40
    },
    {
      "epoch": 0.005357334190506804,
      "grad_norm": 2.794935464859009,
      "learning_rate": 1.999285688774599e-05,
      "loss": 0.6527,
      "step": 50
    },
    {
      "epoch": 0.006428801028608165,
      "grad_norm": 19.4782772064209,
      "learning_rate": 1.999142826529519e-05,
      "loss": 0.7379,
      "step": 60
    },
    {
      "epoch": 0.007500267866709525,
      "grad_norm": 71.09820556640625,
      "learning_rate": 1.998999964284439e-05,
      "loss": 0.8939,
      "step": 70
    },
    {
      "epoch": 0.008571734704810886,
      "grad_norm": 94.36831665039062,
      "learning_rate": 1.9988571020393586e-05,
      "loss": 1.0578,
      "step": 80
    },
    {
      "epoch": 0.009643201542912247,
      "grad_norm": 0.7995187044143677,
      "learning_rate": 1.9987142397942786e-05,
      "loss": 0.7245,
      "step": 90
    },
    {
      "epoch": 0.010714668381013608,
      "grad_norm": 72.25941467285156,
      "learning_rate": 1.9985713775491985e-05,
      "loss": 0.6667,
      "step": 100
    },
    {
      "epoch": 0.011786135219114969,
      "grad_norm": 0.10110846161842346,
      "learning_rate": 1.998428515304118e-05,
      "loss": 0.6499,
      "step": 110
    },
    {
      "epoch": 0.01285760205721633,
      "grad_norm": 0.1788233071565628,
      "learning_rate": 1.998285653059038e-05,
      "loss": 0.4723,
      "step": 120
    },
    {
      "epoch": 0.013929068895317689,
      "grad_norm": 0.37305334210395813,
      "learning_rate": 1.998142790813958e-05,
      "loss": 0.6912,
      "step": 130
    },
    {
      "epoch": 0.01500053573341905,
      "grad_norm": 68.61541748046875,
      "learning_rate": 1.9979999285688776e-05,
      "loss": 0.641,
      "step": 140
    },
    {
      "epoch": 0.016072002571520413,
      "grad_norm": 0.23090142011642456,
      "learning_rate": 1.9978570663237975e-05,
      "loss": 0.9281,
      "step": 150
    },
    {
      "epoch": 0.017143469409621772,
      "grad_norm": 108.59318542480469,
      "learning_rate": 1.997714204078717e-05,
      "loss": 1.1665,
      "step": 160
    },
    {
      "epoch": 0.018214936247723135,
      "grad_norm": 6.198420524597168,
      "learning_rate": 1.997571341833637e-05,
      "loss": 0.6286,
      "step": 170
    },
    {
      "epoch": 0.019286403085824494,
      "grad_norm": 0.13855893909931183,
      "learning_rate": 1.9974284795885567e-05,
      "loss": 0.6432,
      "step": 180
    },
    {
      "epoch": 0.020357869923925853,
      "grad_norm": 0.19805532693862915,
      "learning_rate": 1.9972856173434766e-05,
      "loss": 0.699,
      "step": 190
    },
    {
      "epoch": 0.021429336762027216,
      "grad_norm": 58.30643844604492,
      "learning_rate": 1.9971427550983965e-05,
      "loss": 0.9976,
      "step": 200
    },
    {
      "epoch": 0.022500803600128575,
      "grad_norm": 46.1429443359375,
      "learning_rate": 1.9969998928533165e-05,
      "loss": 0.5364,
      "step": 210
    },
    {
      "epoch": 0.023572270438229938,
      "grad_norm": 81.79998016357422,
      "learning_rate": 1.996857030608236e-05,
      "loss": 1.0516,
      "step": 220
    },
    {
      "epoch": 0.024643737276331297,
      "grad_norm": 0.8081461787223816,
      "learning_rate": 1.996714168363156e-05,
      "loss": 0.7293,
      "step": 230
    },
    {
      "epoch": 0.02571520411443266,
      "grad_norm": 44.780799865722656,
      "learning_rate": 1.996571306118076e-05,
      "loss": 0.6462,
      "step": 240
    },
    {
      "epoch": 0.02678667095253402,
      "grad_norm": 0.1335204690694809,
      "learning_rate": 1.996428443872996e-05,
      "loss": 0.0015,
      "step": 250
    },
    {
      "epoch": 0.027858137790635378,
      "grad_norm": 81.42967224121094,
      "learning_rate": 1.9962855816279155e-05,
      "loss": 1.1554,
      "step": 260
    },
    {
      "epoch": 0.02892960462873674,
      "grad_norm": 42.065731048583984,
      "learning_rate": 1.9961427193828354e-05,
      "loss": 1.0387,
      "step": 270
    },
    {
      "epoch": 0.0300010714668381,
      "grad_norm": 39.9859619140625,
      "learning_rate": 1.995999857137755e-05,
      "loss": 0.6396,
      "step": 280
    },
    {
      "epoch": 0.031072538304939463,
      "grad_norm": 0.13777749240398407,
      "learning_rate": 1.995856994892675e-05,
      "loss": 0.4906,
      "step": 290
    },
    {
      "epoch": 0.032144005143040826,
      "grad_norm": 0.025395769625902176,
      "learning_rate": 1.9957141326475945e-05,
      "loss": 0.2341,
      "step": 300
    },
    {
      "epoch": 0.033215471981142185,
      "grad_norm": 31.940420150756836,
      "learning_rate": 1.9955712704025145e-05,
      "loss": 1.1704,
      "step": 310
    },
    {
      "epoch": 0.034286938819243544,
      "grad_norm": 34.36626052856445,
      "learning_rate": 1.9954284081574344e-05,
      "loss": 0.5198,
      "step": 320
    },
    {
      "epoch": 0.0353584056573449,
      "grad_norm": 34.88381576538086,
      "learning_rate": 1.995285545912354e-05,
      "loss": 0.4917,
      "step": 330
    },
    {
      "epoch": 0.03642987249544627,
      "grad_norm": 0.40204668045043945,
      "learning_rate": 1.995142683667274e-05,
      "loss": 1.0334,
      "step": 340
    },
    {
      "epoch": 0.03750133933354763,
      "grad_norm": 0.14682161808013916,
      "learning_rate": 1.994999821422194e-05,
      "loss": 0.1556,
      "step": 350
    },
    {
      "epoch": 0.03857280617164899,
      "grad_norm": 0.05933979153633118,
      "learning_rate": 1.9948569591771135e-05,
      "loss": 0.7071,
      "step": 360
    },
    {
      "epoch": 0.03964427300975035,
      "grad_norm": 39.430973052978516,
      "learning_rate": 1.9947140969320334e-05,
      "loss": 0.8503,
      "step": 370
    },
    {
      "epoch": 0.040715739847851706,
      "grad_norm": 50.33723449707031,
      "learning_rate": 1.9945712346869534e-05,
      "loss": 0.8441,
      "step": 380
    },
    {
      "epoch": 0.04178720668595307,
      "grad_norm": 24.23914909362793,
      "learning_rate": 1.9944283724418733e-05,
      "loss": 0.7806,
      "step": 390
    },
    {
      "epoch": 0.04285867352405443,
      "grad_norm": 0.29143375158309937,
      "learning_rate": 1.994285510196793e-05,
      "loss": 0.7558,
      "step": 400
    },
    {
      "epoch": 0.04393014036215579,
      "grad_norm": 0.1747099906206131,
      "learning_rate": 1.9941426479517128e-05,
      "loss": 0.1654,
      "step": 410
    },
    {
      "epoch": 0.04500160720025715,
      "grad_norm": 0.10207519680261612,
      "learning_rate": 1.9939997857066324e-05,
      "loss": 0.7891,
      "step": 420
    },
    {
      "epoch": 0.04607307403835851,
      "grad_norm": 30.21263313293457,
      "learning_rate": 1.9938569234615524e-05,
      "loss": 0.7561,
      "step": 430
    },
    {
      "epoch": 0.047144540876459876,
      "grad_norm": 0.7500000596046448,
      "learning_rate": 1.9937140612164723e-05,
      "loss": 0.7188,
      "step": 440
    },
    {
      "epoch": 0.048216007714561235,
      "grad_norm": 0.08718768507242203,
      "learning_rate": 1.993571198971392e-05,
      "loss": 0.2264,
      "step": 450
    },
    {
      "epoch": 0.049287474552662594,
      "grad_norm": 0.1534607857465744,
      "learning_rate": 1.9934283367263118e-05,
      "loss": 0.9279,
      "step": 460
    },
    {
      "epoch": 0.05035894139076395,
      "grad_norm": 46.16272735595703,
      "learning_rate": 1.9932854744812314e-05,
      "loss": 1.1154,
      "step": 470
    },
    {
      "epoch": 0.05143040822886532,
      "grad_norm": 42.22950744628906,
      "learning_rate": 1.9931426122361514e-05,
      "loss": 1.2646,
      "step": 480
    },
    {
      "epoch": 0.05250187506696668,
      "grad_norm": 42.4188346862793,
      "learning_rate": 1.9929997499910713e-05,
      "loss": 0.5111,
      "step": 490
    },
    {
      "epoch": 0.05357334190506804,
      "grad_norm": 0.3719322383403778,
      "learning_rate": 1.992856887745991e-05,
      "loss": 0.6176,
      "step": 500
    },
    {
      "epoch": 0.0546448087431694,
      "grad_norm": 0.5442522168159485,
      "learning_rate": 1.992714025500911e-05,
      "loss": 1.107,
      "step": 510
    },
    {
      "epoch": 0.055716275581270756,
      "grad_norm": 0.5852220058441162,
      "learning_rate": 1.9925711632558308e-05,
      "loss": 0.6894,
      "step": 520
    },
    {
      "epoch": 0.05678774241937212,
      "grad_norm": 0.19224649667739868,
      "learning_rate": 1.9924283010107507e-05,
      "loss": 0.3838,
      "step": 530
    },
    {
      "epoch": 0.05785920925747348,
      "grad_norm": 28.05975914001465,
      "learning_rate": 1.9922854387656703e-05,
      "loss": 1.2885,
      "step": 540
    },
    {
      "epoch": 0.05893067609557484,
      "grad_norm": 0.14713367819786072,
      "learning_rate": 1.9921425765205902e-05,
      "loss": 0.1521,
      "step": 550
    },
    {
      "epoch": 0.0600021429336762,
      "grad_norm": 43.98002624511719,
      "learning_rate": 1.9919997142755102e-05,
      "loss": 1.4393,
      "step": 560
    },
    {
      "epoch": 0.061073609771777566,
      "grad_norm": 1.1035982370376587,
      "learning_rate": 1.9918568520304298e-05,
      "loss": 1.1727,
      "step": 570
    },
    {
      "epoch": 0.062145076609878926,
      "grad_norm": 0.9994703531265259,
      "learning_rate": 1.9917139897853497e-05,
      "loss": 0.5251,
      "step": 580
    },
    {
      "epoch": 0.06321654344798029,
      "grad_norm": 0.07353007048368454,
      "learning_rate": 1.9915711275402693e-05,
      "loss": 0.4425,
      "step": 590
    },
    {
      "epoch": 0.06428801028608165,
      "grad_norm": 0.10966309159994125,
      "learning_rate": 1.9914282652951892e-05,
      "loss": 1.0158,
      "step": 600
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.4149651527404785,
      "learning_rate": 1.9912854030501092e-05,
      "loss": 1.0026,
      "step": 610
    },
    {
      "epoch": 0.06643094396228437,
      "grad_norm": 1.0259709358215332,
      "learning_rate": 1.9911425408050288e-05,
      "loss": 0.6286,
      "step": 620
    },
    {
      "epoch": 0.06750241080038573,
      "grad_norm": 26.139558792114258,
      "learning_rate": 1.9909996785599487e-05,
      "loss": 0.6362,
      "step": 630
    },
    {
      "epoch": 0.06857387763848709,
      "grad_norm": 0.45214810967445374,
      "learning_rate": 1.9908568163148687e-05,
      "loss": 0.5005,
      "step": 640
    },
    {
      "epoch": 0.06964534447658845,
      "grad_norm": 38.18373489379883,
      "learning_rate": 1.9907139540697883e-05,
      "loss": 0.8184,
      "step": 650
    },
    {
      "epoch": 0.0707168113146898,
      "grad_norm": 21.548385620117188,
      "learning_rate": 1.9905710918247082e-05,
      "loss": 0.8068,
      "step": 660
    },
    {
      "epoch": 0.07178827815279117,
      "grad_norm": 0.5160870552062988,
      "learning_rate": 1.990428229579628e-05,
      "loss": 0.4519,
      "step": 670
    },
    {
      "epoch": 0.07285974499089254,
      "grad_norm": 0.1175127923488617,
      "learning_rate": 1.990285367334548e-05,
      "loss": 0.3979,
      "step": 680
    },
    {
      "epoch": 0.0739312118289939,
      "grad_norm": 0.21712574362754822,
      "learning_rate": 1.9901425050894677e-05,
      "loss": 0.5931,
      "step": 690
    },
    {
      "epoch": 0.07500267866709526,
      "grad_norm": 0.22033819556236267,
      "learning_rate": 1.9899996428443876e-05,
      "loss": 0.354,
      "step": 700
    },
    {
      "epoch": 0.07607414550519662,
      "grad_norm": 0.22025209665298462,
      "learning_rate": 1.9898567805993072e-05,
      "loss": 0.3898,
      "step": 710
    },
    {
      "epoch": 0.07714561234329798,
      "grad_norm": 0.22051961719989777,
      "learning_rate": 1.989713918354227e-05,
      "loss": 0.3557,
      "step": 720
    },
    {
      "epoch": 0.07821707918139933,
      "grad_norm": 24.828229904174805,
      "learning_rate": 1.989571056109147e-05,
      "loss": 1.0736,
      "step": 730
    },
    {
      "epoch": 0.0792885460195007,
      "grad_norm": 0.5037031173706055,
      "learning_rate": 1.9894281938640667e-05,
      "loss": 0.4724,
      "step": 740
    },
    {
      "epoch": 0.08036001285760205,
      "grad_norm": 21.147258758544922,
      "learning_rate": 1.9892853316189866e-05,
      "loss": 1.2971,
      "step": 750
    },
    {
      "epoch": 0.08143147969570341,
      "grad_norm": 2.93595552444458,
      "learning_rate": 1.9891424693739062e-05,
      "loss": 0.3509,
      "step": 760
    },
    {
      "epoch": 0.08250294653380477,
      "grad_norm": 0.38085752725601196,
      "learning_rate": 1.988999607128826e-05,
      "loss": 0.2629,
      "step": 770
    },
    {
      "epoch": 0.08357441337190614,
      "grad_norm": 46.384281158447266,
      "learning_rate": 1.988856744883746e-05,
      "loss": 0.806,
      "step": 780
    },
    {
      "epoch": 0.0846458802100075,
      "grad_norm": 0.110775887966156,
      "learning_rate": 1.9887138826386657e-05,
      "loss": 0.6142,
      "step": 790
    },
    {
      "epoch": 0.08571734704810886,
      "grad_norm": 33.11244201660156,
      "learning_rate": 1.9885710203935856e-05,
      "loss": 0.8703,
      "step": 800
    },
    {
      "epoch": 0.08678881388621022,
      "grad_norm": 25.610876083374023,
      "learning_rate": 1.9884281581485055e-05,
      "loss": 0.3392,
      "step": 810
    },
    {
      "epoch": 0.08786028072431158,
      "grad_norm": 36.704994201660156,
      "learning_rate": 1.9882852959034255e-05,
      "loss": 1.1544,
      "step": 820
    },
    {
      "epoch": 0.08893174756241294,
      "grad_norm": 0.5489172339439392,
      "learning_rate": 1.988142433658345e-05,
      "loss": 0.4286,
      "step": 830
    },
    {
      "epoch": 0.0900032144005143,
      "grad_norm": 0.22887299954891205,
      "learning_rate": 1.987999571413265e-05,
      "loss": 0.4893,
      "step": 840
    },
    {
      "epoch": 0.09107468123861566,
      "grad_norm": 19.943387985229492,
      "learning_rate": 1.987856709168185e-05,
      "loss": 0.6851,
      "step": 850
    },
    {
      "epoch": 0.09214614807671702,
      "grad_norm": 24.446008682250977,
      "learning_rate": 1.9877138469231046e-05,
      "loss": 0.553,
      "step": 860
    },
    {
      "epoch": 0.09321761491481839,
      "grad_norm": 0.3752795159816742,
      "learning_rate": 1.9875709846780245e-05,
      "loss": 0.627,
      "step": 870
    },
    {
      "epoch": 0.09428908175291975,
      "grad_norm": 0.17876669764518738,
      "learning_rate": 1.987428122432944e-05,
      "loss": 0.6643,
      "step": 880
    },
    {
      "epoch": 0.09536054859102111,
      "grad_norm": 29.500568389892578,
      "learning_rate": 1.987285260187864e-05,
      "loss": 0.5811,
      "step": 890
    },
    {
      "epoch": 0.09643201542912247,
      "grad_norm": 0.34966909885406494,
      "learning_rate": 1.9871423979427836e-05,
      "loss": 0.1879,
      "step": 900
    },
    {
      "epoch": 0.09750348226722383,
      "grad_norm": 48.330257415771484,
      "learning_rate": 1.9869995356977036e-05,
      "loss": 0.6861,
      "step": 910
    },
    {
      "epoch": 0.09857494910532519,
      "grad_norm": 0.4739568829536438,
      "learning_rate": 1.9868566734526235e-05,
      "loss": 0.5164,
      "step": 920
    },
    {
      "epoch": 0.09964641594342655,
      "grad_norm": 0.48938414454460144,
      "learning_rate": 1.986713811207543e-05,
      "loss": 1.0304,
      "step": 930
    },
    {
      "epoch": 0.1007178827815279,
      "grad_norm": 0.15281729400157928,
      "learning_rate": 1.986570948962463e-05,
      "loss": 0.3816,
      "step": 940
    },
    {
      "epoch": 0.10178934961962927,
      "grad_norm": 0.15502777695655823,
      "learning_rate": 1.986428086717383e-05,
      "loss": 0.802,
      "step": 950
    },
    {
      "epoch": 0.10286081645773064,
      "grad_norm": 0.7728859186172485,
      "learning_rate": 1.986285224472303e-05,
      "loss": 0.6768,
      "step": 960
    },
    {
      "epoch": 0.103932283295832,
      "grad_norm": 26.682588577270508,
      "learning_rate": 1.9861423622272225e-05,
      "loss": 0.511,
      "step": 970
    },
    {
      "epoch": 0.10500375013393336,
      "grad_norm": 0.27790215611457825,
      "learning_rate": 1.9859994999821424e-05,
      "loss": 0.152,
      "step": 980
    },
    {
      "epoch": 0.10607521697203472,
      "grad_norm": 21.901813507080078,
      "learning_rate": 1.9858566377370624e-05,
      "loss": 1.3323,
      "step": 990
    },
    {
      "epoch": 0.10714668381013608,
      "grad_norm": 21.356874465942383,
      "learning_rate": 1.985713775491982e-05,
      "loss": 0.4558,
      "step": 1000
    },
    {
      "epoch": 0.10821815064823744,
      "grad_norm": 0.5704751014709473,
      "learning_rate": 1.985570913246902e-05,
      "loss": 0.5491,
      "step": 1010
    },
    {
      "epoch": 0.1092896174863388,
      "grad_norm": 20.622163772583008,
      "learning_rate": 1.9854280510018215e-05,
      "loss": 0.5698,
      "step": 1020
    },
    {
      "epoch": 0.11036108432444015,
      "grad_norm": 0.8174253702163696,
      "learning_rate": 1.9852851887567414e-05,
      "loss": 0.6315,
      "step": 1030
    },
    {
      "epoch": 0.11143255116254151,
      "grad_norm": 0.7360492944717407,
      "learning_rate": 1.9851423265116614e-05,
      "loss": 1.0571,
      "step": 1040
    },
    {
      "epoch": 0.11250401800064289,
      "grad_norm": 5.1229376792907715,
      "learning_rate": 1.984999464266581e-05,
      "loss": 0.5856,
      "step": 1050
    },
    {
      "epoch": 0.11357548483874425,
      "grad_norm": 0.7323752641677856,
      "learning_rate": 1.984856602021501e-05,
      "loss": 0.4806,
      "step": 1060
    },
    {
      "epoch": 0.1146469516768456,
      "grad_norm": 41.82606887817383,
      "learning_rate": 1.9847137397764205e-05,
      "loss": 0.5126,
      "step": 1070
    },
    {
      "epoch": 0.11571841851494696,
      "grad_norm": 23.14192008972168,
      "learning_rate": 1.9845708775313404e-05,
      "loss": 1.2674,
      "step": 1080
    },
    {
      "epoch": 0.11678988535304832,
      "grad_norm": 0.29782289266586304,
      "learning_rate": 1.9844280152862604e-05,
      "loss": 0.3977,
      "step": 1090
    },
    {
      "epoch": 0.11786135219114968,
      "grad_norm": 26.435775756835938,
      "learning_rate": 1.9842851530411803e-05,
      "loss": 0.6822,
      "step": 1100
    },
    {
      "epoch": 0.11893281902925104,
      "grad_norm": 0.6695877909660339,
      "learning_rate": 1.9841422907961003e-05,
      "loss": 1.1873,
      "step": 1110
    },
    {
      "epoch": 0.1200042858673524,
      "grad_norm": 20.18408203125,
      "learning_rate": 1.98399942855102e-05,
      "loss": 0.916,
      "step": 1120
    },
    {
      "epoch": 0.12107575270545376,
      "grad_norm": 20.16793441772461,
      "learning_rate": 1.9838565663059398e-05,
      "loss": 0.5796,
      "step": 1130
    },
    {
      "epoch": 0.12214721954355513,
      "grad_norm": 21.616851806640625,
      "learning_rate": 1.9837137040608594e-05,
      "loss": 0.4556,
      "step": 1140
    },
    {
      "epoch": 0.12321868638165649,
      "grad_norm": 3.7190330028533936,
      "learning_rate": 1.9835708418157793e-05,
      "loss": 0.2566,
      "step": 1150
    },
    {
      "epoch": 0.12429015321975785,
      "grad_norm": 23.07271957397461,
      "learning_rate": 1.9834279795706993e-05,
      "loss": 0.7009,
      "step": 1160
    },
    {
      "epoch": 0.1253616200578592,
      "grad_norm": 0.09708940982818604,
      "learning_rate": 1.983285117325619e-05,
      "loss": 0.5518,
      "step": 1170
    },
    {
      "epoch": 0.12643308689596058,
      "grad_norm": 0.25565868616104126,
      "learning_rate": 1.9831422550805388e-05,
      "loss": 0.3403,
      "step": 1180
    },
    {
      "epoch": 0.12750455373406194,
      "grad_norm": 0.08410205692052841,
      "learning_rate": 1.9829993928354584e-05,
      "loss": 0.5712,
      "step": 1190
    },
    {
      "epoch": 0.1285760205721633,
      "grad_norm": 0.21469014883041382,
      "learning_rate": 1.9828565305903783e-05,
      "loss": 0.7425,
      "step": 1200
    },
    {
      "epoch": 0.12964748741026466,
      "grad_norm": 25.404541015625,
      "learning_rate": 1.9827136683452983e-05,
      "loss": 0.5938,
      "step": 1210
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.2916620373725891,
      "learning_rate": 1.982570806100218e-05,
      "loss": 0.3637,
      "step": 1220
    },
    {
      "epoch": 0.13179042108646738,
      "grad_norm": 0.5629490613937378,
      "learning_rate": 1.9824279438551378e-05,
      "loss": 0.9155,
      "step": 1230
    },
    {
      "epoch": 0.13286188792456874,
      "grad_norm": 0.24341005086898804,
      "learning_rate": 1.9822850816100577e-05,
      "loss": 0.1471,
      "step": 1240
    },
    {
      "epoch": 0.1339333547626701,
      "grad_norm": 0.10305791348218918,
      "learning_rate": 1.9821422193649777e-05,
      "loss": 0.4228,
      "step": 1250
    },
    {
      "epoch": 0.13500482160077146,
      "grad_norm": 21.3839168548584,
      "learning_rate": 1.9819993571198973e-05,
      "loss": 1.7163,
      "step": 1260
    },
    {
      "epoch": 0.13607628843887282,
      "grad_norm": 0.42578306794166565,
      "learning_rate": 1.9818564948748172e-05,
      "loss": 0.7545,
      "step": 1270
    },
    {
      "epoch": 0.13714775527697418,
      "grad_norm": 0.31075870990753174,
      "learning_rate": 1.981713632629737e-05,
      "loss": 0.4101,
      "step": 1280
    },
    {
      "epoch": 0.13821922211507554,
      "grad_norm": 21.071365356445312,
      "learning_rate": 1.9815707703846567e-05,
      "loss": 0.7762,
      "step": 1290
    },
    {
      "epoch": 0.1392906889531769,
      "grad_norm": 23.211267471313477,
      "learning_rate": 1.9814279081395767e-05,
      "loss": 0.3192,
      "step": 1300
    },
    {
      "epoch": 0.14036215579127825,
      "grad_norm": 30.924978256225586,
      "learning_rate": 1.9812850458944963e-05,
      "loss": 0.71,
      "step": 1310
    },
    {
      "epoch": 0.1414336226293796,
      "grad_norm": 21.597492218017578,
      "learning_rate": 1.9811421836494162e-05,
      "loss": 0.2799,
      "step": 1320
    },
    {
      "epoch": 0.14250508946748097,
      "grad_norm": 0.141020268201828,
      "learning_rate": 1.9809993214043358e-05,
      "loss": 0.6847,
      "step": 1330
    },
    {
      "epoch": 0.14357655630558233,
      "grad_norm": 0.1816234141588211,
      "learning_rate": 1.9808564591592558e-05,
      "loss": 0.1634,
      "step": 1340
    },
    {
      "epoch": 0.1446480231436837,
      "grad_norm": 0.08068982511758804,
      "learning_rate": 1.9807135969141757e-05,
      "loss": 0.2261,
      "step": 1350
    },
    {
      "epoch": 0.14571948998178508,
      "grad_norm": 24.33014488220215,
      "learning_rate": 1.9805707346690953e-05,
      "loss": 1.1746,
      "step": 1360
    },
    {
      "epoch": 0.14679095681988644,
      "grad_norm": 0.7400588989257812,
      "learning_rate": 1.9804278724240152e-05,
      "loss": 0.3233,
      "step": 1370
    },
    {
      "epoch": 0.1478624236579878,
      "grad_norm": 0.19092145562171936,
      "learning_rate": 1.980285010178935e-05,
      "loss": 0.6845,
      "step": 1380
    },
    {
      "epoch": 0.14893389049608916,
      "grad_norm": 21.732450485229492,
      "learning_rate": 1.980142147933855e-05,
      "loss": 0.6262,
      "step": 1390
    },
    {
      "epoch": 0.15000535733419051,
      "grad_norm": 30.10370635986328,
      "learning_rate": 1.979999285688775e-05,
      "loss": 0.7021,
      "step": 1400
    },
    {
      "epoch": 0.15107682417229187,
      "grad_norm": 4.136870861053467,
      "learning_rate": 1.9798564234436946e-05,
      "loss": 0.5679,
      "step": 1410
    },
    {
      "epoch": 0.15214829101039323,
      "grad_norm": 5.411887168884277,
      "learning_rate": 1.9797135611986146e-05,
      "loss": 0.912,
      "step": 1420
    },
    {
      "epoch": 0.1532197578484946,
      "grad_norm": 1.0027071237564087,
      "learning_rate": 1.979570698953534e-05,
      "loss": 0.4264,
      "step": 1430
    },
    {
      "epoch": 0.15429122468659595,
      "grad_norm": 0.04721955209970474,
      "learning_rate": 1.979427836708454e-05,
      "loss": 0.2138,
      "step": 1440
    },
    {
      "epoch": 0.1553626915246973,
      "grad_norm": 0.10880069434642792,
      "learning_rate": 1.9792849744633737e-05,
      "loss": 1.4984,
      "step": 1450
    },
    {
      "epoch": 0.15643415836279867,
      "grad_norm": 0.40317198634147644,
      "learning_rate": 1.9791421122182936e-05,
      "loss": 0.7002,
      "step": 1460
    },
    {
      "epoch": 0.15750562520090003,
      "grad_norm": 26.80923843383789,
      "learning_rate": 1.9789992499732136e-05,
      "loss": 0.8819,
      "step": 1470
    },
    {
      "epoch": 0.1585770920390014,
      "grad_norm": 0.4245322644710541,
      "learning_rate": 1.9788563877281332e-05,
      "loss": 0.3964,
      "step": 1480
    },
    {
      "epoch": 0.15964855887710275,
      "grad_norm": 0.2567145824432373,
      "learning_rate": 1.978713525483053e-05,
      "loss": 0.5886,
      "step": 1490
    },
    {
      "epoch": 0.1607200257152041,
      "grad_norm": 0.2393922507762909,
      "learning_rate": 1.9785706632379727e-05,
      "loss": 0.4387,
      "step": 1500
    },
    {
      "epoch": 0.16179149255330547,
      "grad_norm": 0.2938511073589325,
      "learning_rate": 1.9784278009928926e-05,
      "loss": 0.4798,
      "step": 1510
    },
    {
      "epoch": 0.16286295939140683,
      "grad_norm": 18.35310173034668,
      "learning_rate": 1.9782849387478126e-05,
      "loss": 0.4876,
      "step": 1520
    },
    {
      "epoch": 0.16393442622950818,
      "grad_norm": 17.996551513671875,
      "learning_rate": 1.9781420765027325e-05,
      "loss": 0.6172,
      "step": 1530
    },
    {
      "epoch": 0.16500589306760954,
      "grad_norm": 1.1016372442245483,
      "learning_rate": 1.9779992142576525e-05,
      "loss": 0.3097,
      "step": 1540
    },
    {
      "epoch": 0.16607735990571093,
      "grad_norm": 0.4943140149116516,
      "learning_rate": 1.977856352012572e-05,
      "loss": 0.351,
      "step": 1550
    },
    {
      "epoch": 0.1671488267438123,
      "grad_norm": 0.13863088190555573,
      "learning_rate": 1.977713489767492e-05,
      "loss": 0.5439,
      "step": 1560
    },
    {
      "epoch": 0.16822029358191365,
      "grad_norm": 20.90804100036621,
      "learning_rate": 1.9775706275224116e-05,
      "loss": 0.8552,
      "step": 1570
    },
    {
      "epoch": 0.169291760420015,
      "grad_norm": 0.5563512444496155,
      "learning_rate": 1.9774277652773315e-05,
      "loss": 1.0666,
      "step": 1580
    },
    {
      "epoch": 0.17036322725811637,
      "grad_norm": 0.4420005977153778,
      "learning_rate": 1.9772849030322515e-05,
      "loss": 0.5087,
      "step": 1590
    },
    {
      "epoch": 0.17143469409621773,
      "grad_norm": 0.30104172229766846,
      "learning_rate": 1.977142040787171e-05,
      "loss": 0.068,
      "step": 1600
    },
    {
      "epoch": 0.17250616093431909,
      "grad_norm": 17.992815017700195,
      "learning_rate": 1.976999178542091e-05,
      "loss": 0.6271,
      "step": 1610
    },
    {
      "epoch": 0.17357762777242045,
      "grad_norm": 25.30118179321289,
      "learning_rate": 1.9768563162970106e-05,
      "loss": 1.105,
      "step": 1620
    },
    {
      "epoch": 0.1746490946105218,
      "grad_norm": 36.65791320800781,
      "learning_rate": 1.9767134540519305e-05,
      "loss": 0.6464,
      "step": 1630
    },
    {
      "epoch": 0.17572056144862316,
      "grad_norm": 0.2954200804233551,
      "learning_rate": 1.9765705918068505e-05,
      "loss": 0.8694,
      "step": 1640
    },
    {
      "epoch": 0.17679202828672452,
      "grad_norm": 0.24457518756389618,
      "learning_rate": 1.97642772956177e-05,
      "loss": 0.5413,
      "step": 1650
    },
    {
      "epoch": 0.17786349512482588,
      "grad_norm": 2.443957805633545,
      "learning_rate": 1.97628486731669e-05,
      "loss": 0.8541,
      "step": 1660
    },
    {
      "epoch": 0.17893496196292724,
      "grad_norm": 0.5875763297080994,
      "learning_rate": 1.97614200507161e-05,
      "loss": 0.5768,
      "step": 1670
    },
    {
      "epoch": 0.1800064288010286,
      "grad_norm": 27.676513671875,
      "learning_rate": 1.97599914282653e-05,
      "loss": 0.3401,
      "step": 1680
    },
    {
      "epoch": 0.18107789563912996,
      "grad_norm": 29.142454147338867,
      "learning_rate": 1.9758562805814495e-05,
      "loss": 0.6187,
      "step": 1690
    },
    {
      "epoch": 0.18214936247723132,
      "grad_norm": 0.12008637934923172,
      "learning_rate": 1.9757134183363694e-05,
      "loss": 0.1653,
      "step": 1700
    },
    {
      "epoch": 0.18322082931533268,
      "grad_norm": 0.16317236423492432,
      "learning_rate": 1.9755705560912893e-05,
      "loss": 0.2562,
      "step": 1710
    },
    {
      "epoch": 0.18429229615343404,
      "grad_norm": 25.706981658935547,
      "learning_rate": 1.975427693846209e-05,
      "loss": 0.7321,
      "step": 1720
    },
    {
      "epoch": 0.18536376299153542,
      "grad_norm": 20.646684646606445,
      "learning_rate": 1.975284831601129e-05,
      "loss": 0.4496,
      "step": 1730
    },
    {
      "epoch": 0.18643522982963678,
      "grad_norm": 19.12005043029785,
      "learning_rate": 1.9751419693560485e-05,
      "loss": 0.8387,
      "step": 1740
    },
    {
      "epoch": 0.18750669666773814,
      "grad_norm": 31.899272918701172,
      "learning_rate": 1.9749991071109684e-05,
      "loss": 0.7567,
      "step": 1750
    },
    {
      "epoch": 0.1885781635058395,
      "grad_norm": 0.8316028714179993,
      "learning_rate": 1.9748562448658883e-05,
      "loss": 0.5754,
      "step": 1760
    },
    {
      "epoch": 0.18964963034394086,
      "grad_norm": 0.5154245495796204,
      "learning_rate": 1.974713382620808e-05,
      "loss": 0.7548,
      "step": 1770
    },
    {
      "epoch": 0.19072109718204222,
      "grad_norm": 0.39333394169807434,
      "learning_rate": 1.974570520375728e-05,
      "loss": 1.1759,
      "step": 1780
    },
    {
      "epoch": 0.19179256402014358,
      "grad_norm": 0.508526086807251,
      "learning_rate": 1.9744276581306475e-05,
      "loss": 0.3661,
      "step": 1790
    },
    {
      "epoch": 0.19286403085824494,
      "grad_norm": 0.24011610448360443,
      "learning_rate": 1.9742847958855674e-05,
      "loss": 0.5072,
      "step": 1800
    },
    {
      "epoch": 0.1939354976963463,
      "grad_norm": 0.5985389947891235,
      "learning_rate": 1.9741419336404874e-05,
      "loss": 0.7619,
      "step": 1810
    },
    {
      "epoch": 0.19500696453444766,
      "grad_norm": 21.54938507080078,
      "learning_rate": 1.9739990713954073e-05,
      "loss": 0.2053,
      "step": 1820
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.09888233244419098,
      "learning_rate": 1.973856209150327e-05,
      "loss": 0.7254,
      "step": 1830
    },
    {
      "epoch": 0.19714989821065038,
      "grad_norm": 0.22911396622657776,
      "learning_rate": 1.9737133469052468e-05,
      "loss": 0.892,
      "step": 1840
    },
    {
      "epoch": 0.19822136504875174,
      "grad_norm": 0.34082868695259094,
      "learning_rate": 1.9735704846601668e-05,
      "loss": 0.3495,
      "step": 1850
    },
    {
      "epoch": 0.1992928318868531,
      "grad_norm": 0.2998849153518677,
      "learning_rate": 1.9734276224150864e-05,
      "loss": 0.34,
      "step": 1860
    },
    {
      "epoch": 0.20036429872495445,
      "grad_norm": 0.12105859071016312,
      "learning_rate": 1.9732847601700063e-05,
      "loss": 0.3549,
      "step": 1870
    },
    {
      "epoch": 0.2014357655630558,
      "grad_norm": 0.19917066395282745,
      "learning_rate": 1.973141897924926e-05,
      "loss": 0.8996,
      "step": 1880
    },
    {
      "epoch": 0.20250723240115717,
      "grad_norm": 20.44904136657715,
      "learning_rate": 1.9729990356798458e-05,
      "loss": 0.5968,
      "step": 1890
    },
    {
      "epoch": 0.20357869923925853,
      "grad_norm": 0.6265773177146912,
      "learning_rate": 1.9728561734347658e-05,
      "loss": 0.7473,
      "step": 1900
    },
    {
      "epoch": 0.20465016607735992,
      "grad_norm": 1.9280892610549927,
      "learning_rate": 1.9727133111896854e-05,
      "loss": 0.6654,
      "step": 1910
    },
    {
      "epoch": 0.20572163291546128,
      "grad_norm": 0.22751440107822418,
      "learning_rate": 1.9725704489446053e-05,
      "loss": 0.203,
      "step": 1920
    },
    {
      "epoch": 0.20679309975356264,
      "grad_norm": 0.11083106696605682,
      "learning_rate": 1.972427586699525e-05,
      "loss": 0.4259,
      "step": 1930
    },
    {
      "epoch": 0.207864566591664,
      "grad_norm": 0.18258987367153168,
      "learning_rate": 1.972284724454445e-05,
      "loss": 1.2003,
      "step": 1940
    },
    {
      "epoch": 0.20893603342976536,
      "grad_norm": 0.8982701301574707,
      "learning_rate": 1.9721418622093648e-05,
      "loss": 1.2915,
      "step": 1950
    },
    {
      "epoch": 0.21000750026786671,
      "grad_norm": 21.448314666748047,
      "learning_rate": 1.9719989999642847e-05,
      "loss": 0.8663,
      "step": 1960
    },
    {
      "epoch": 0.21107896710596807,
      "grad_norm": 0.6968420147895813,
      "learning_rate": 1.9718561377192046e-05,
      "loss": 0.1256,
      "step": 1970
    },
    {
      "epoch": 0.21215043394406943,
      "grad_norm": 28.557191848754883,
      "learning_rate": 1.9717132754741242e-05,
      "loss": 0.609,
      "step": 1980
    },
    {
      "epoch": 0.2132219007821708,
      "grad_norm": 19.531612396240234,
      "learning_rate": 1.9715704132290442e-05,
      "loss": 0.5832,
      "step": 1990
    },
    {
      "epoch": 0.21429336762027215,
      "grad_norm": 4.554335117340088,
      "learning_rate": 1.9714275509839638e-05,
      "loss": 0.3812,
      "step": 2000
    },
    {
      "epoch": 0.2153648344583735,
      "grad_norm": 0.11418686807155609,
      "learning_rate": 1.9712846887388837e-05,
      "loss": 0.2865,
      "step": 2010
    },
    {
      "epoch": 0.21643630129647487,
      "grad_norm": 3.6827688217163086,
      "learning_rate": 1.9711418264938037e-05,
      "loss": 0.6017,
      "step": 2020
    },
    {
      "epoch": 0.21750776813457623,
      "grad_norm": 0.12064670026302338,
      "learning_rate": 1.9709989642487232e-05,
      "loss": 0.3873,
      "step": 2030
    },
    {
      "epoch": 0.2185792349726776,
      "grad_norm": 25.290424346923828,
      "learning_rate": 1.9708561020036432e-05,
      "loss": 1.0661,
      "step": 2040
    },
    {
      "epoch": 0.21965070181077895,
      "grad_norm": 8.481051445007324,
      "learning_rate": 1.9707132397585628e-05,
      "loss": 0.9472,
      "step": 2050
    },
    {
      "epoch": 0.2207221686488803,
      "grad_norm": 23.224384307861328,
      "learning_rate": 1.9705703775134827e-05,
      "loss": 0.1736,
      "step": 2060
    },
    {
      "epoch": 0.22179363548698167,
      "grad_norm": 0.4469146132469177,
      "learning_rate": 1.9704275152684027e-05,
      "loss": 0.7513,
      "step": 2070
    },
    {
      "epoch": 0.22286510232508303,
      "grad_norm": 0.37374910712242126,
      "learning_rate": 1.9702846530233223e-05,
      "loss": 0.6405,
      "step": 2080
    },
    {
      "epoch": 0.2239365691631844,
      "grad_norm": 0.2406795769929886,
      "learning_rate": 1.9701417907782422e-05,
      "loss": 0.281,
      "step": 2090
    },
    {
      "epoch": 0.22500803600128577,
      "grad_norm": 0.20891907811164856,
      "learning_rate": 1.969998928533162e-05,
      "loss": 0.4333,
      "step": 2100
    },
    {
      "epoch": 0.22607950283938713,
      "grad_norm": 19.0203857421875,
      "learning_rate": 1.969856066288082e-05,
      "loss": 0.579,
      "step": 2110
    },
    {
      "epoch": 0.2271509696774885,
      "grad_norm": 0.1846771091222763,
      "learning_rate": 1.9697132040430017e-05,
      "loss": 0.3959,
      "step": 2120
    },
    {
      "epoch": 0.22822243651558985,
      "grad_norm": 0.2003582864999771,
      "learning_rate": 1.9695703417979216e-05,
      "loss": 0.4612,
      "step": 2130
    },
    {
      "epoch": 0.2292939033536912,
      "grad_norm": 0.2696780860424042,
      "learning_rate": 1.9694274795528415e-05,
      "loss": 0.8922,
      "step": 2140
    },
    {
      "epoch": 0.23036537019179257,
      "grad_norm": 0.43702465295791626,
      "learning_rate": 1.969284617307761e-05,
      "loss": 0.4342,
      "step": 2150
    },
    {
      "epoch": 0.23143683702989393,
      "grad_norm": 21.820859909057617,
      "learning_rate": 1.969141755062681e-05,
      "loss": 0.6299,
      "step": 2160
    },
    {
      "epoch": 0.2325083038679953,
      "grad_norm": 17.852523803710938,
      "learning_rate": 1.9689988928176007e-05,
      "loss": 0.7731,
      "step": 2170
    },
    {
      "epoch": 0.23357977070609665,
      "grad_norm": 0.680038332939148,
      "learning_rate": 1.9688560305725206e-05,
      "loss": 0.5538,
      "step": 2180
    },
    {
      "epoch": 0.234651237544198,
      "grad_norm": 0.427645206451416,
      "learning_rate": 1.9687131683274405e-05,
      "loss": 0.2994,
      "step": 2190
    },
    {
      "epoch": 0.23572270438229936,
      "grad_norm": 0.2810084819793701,
      "learning_rate": 1.96857030608236e-05,
      "loss": 0.4829,
      "step": 2200
    },
    {
      "epoch": 0.23679417122040072,
      "grad_norm": 0.4280134439468384,
      "learning_rate": 1.96842744383728e-05,
      "loss": 0.1403,
      "step": 2210
    },
    {
      "epoch": 0.23786563805850208,
      "grad_norm": 0.5328495502471924,
      "learning_rate": 1.9682845815921997e-05,
      "loss": 0.6352,
      "step": 2220
    },
    {
      "epoch": 0.23893710489660344,
      "grad_norm": 0.6316815614700317,
      "learning_rate": 1.9681417193471196e-05,
      "loss": 0.173,
      "step": 2230
    },
    {
      "epoch": 0.2400085717347048,
      "grad_norm": 21.48331642150879,
      "learning_rate": 1.9679988571020395e-05,
      "loss": 1.2587,
      "step": 2240
    },
    {
      "epoch": 0.24108003857280616,
      "grad_norm": 19.883909225463867,
      "learning_rate": 1.9678559948569595e-05,
      "loss": 0.3938,
      "step": 2250
    },
    {
      "epoch": 0.24215150541090752,
      "grad_norm": 0.47457098960876465,
      "learning_rate": 1.967713132611879e-05,
      "loss": 0.0116,
      "step": 2260
    },
    {
      "epoch": 0.2432229722490089,
      "grad_norm": 0.17477194964885712,
      "learning_rate": 1.967570270366799e-05,
      "loss": 0.3661,
      "step": 2270
    },
    {
      "epoch": 0.24429443908711027,
      "grad_norm": 0.1255185306072235,
      "learning_rate": 1.967427408121719e-05,
      "loss": 0.8933,
      "step": 2280
    },
    {
      "epoch": 0.24536590592521162,
      "grad_norm": 0.19222275912761688,
      "learning_rate": 1.9672845458766386e-05,
      "loss": 0.3418,
      "step": 2290
    },
    {
      "epoch": 0.24643737276331298,
      "grad_norm": 0.2088560163974762,
      "learning_rate": 1.9671416836315585e-05,
      "loss": 0.1682,
      "step": 2300
    },
    {
      "epoch": 0.24750883960141434,
      "grad_norm": 0.1372554451227188,
      "learning_rate": 1.9669988213864784e-05,
      "loss": 0.1955,
      "step": 2310
    },
    {
      "epoch": 0.2485803064395157,
      "grad_norm": 0.14408834278583527,
      "learning_rate": 1.966855959141398e-05,
      "loss": 0.7782,
      "step": 2320
    },
    {
      "epoch": 0.24965177327761706,
      "grad_norm": 0.37101733684539795,
      "learning_rate": 1.966713096896318e-05,
      "loss": 0.821,
      "step": 2330
    },
    {
      "epoch": 0.2507232401157184,
      "grad_norm": 0.22066906094551086,
      "learning_rate": 1.9665702346512376e-05,
      "loss": 0.1785,
      "step": 2340
    },
    {
      "epoch": 0.2517947069538198,
      "grad_norm": 1.9208331108093262,
      "learning_rate": 1.9664273724061575e-05,
      "loss": 0.3748,
      "step": 2350
    },
    {
      "epoch": 0.25286617379192117,
      "grad_norm": 3.4208614826202393,
      "learning_rate": 1.966284510161077e-05,
      "loss": 0.5218,
      "step": 2360
    },
    {
      "epoch": 0.2539376406300225,
      "grad_norm": 0.23573347926139832,
      "learning_rate": 1.966141647915997e-05,
      "loss": 0.2007,
      "step": 2370
    },
    {
      "epoch": 0.2550091074681239,
      "grad_norm": 0.15204982459545135,
      "learning_rate": 1.965998785670917e-05,
      "loss": 0.5604,
      "step": 2380
    },
    {
      "epoch": 0.2560805743062252,
      "grad_norm": 4.998154640197754,
      "learning_rate": 1.965855923425837e-05,
      "loss": 0.4214,
      "step": 2390
    },
    {
      "epoch": 0.2571520411443266,
      "grad_norm": 11.359742164611816,
      "learning_rate": 1.9657130611807565e-05,
      "loss": 0.2578,
      "step": 2400
    },
    {
      "epoch": 0.25822350798242794,
      "grad_norm": 0.07701808959245682,
      "learning_rate": 1.9655701989356764e-05,
      "loss": 0.2504,
      "step": 2410
    },
    {
      "epoch": 0.2592949748205293,
      "grad_norm": 40.041439056396484,
      "learning_rate": 1.9654273366905964e-05,
      "loss": 0.7252,
      "step": 2420
    },
    {
      "epoch": 0.26036644165863065,
      "grad_norm": 0.0918017104268074,
      "learning_rate": 1.9652844744455163e-05,
      "loss": 0.2012,
      "step": 2430
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.0753404051065445,
      "learning_rate": 1.965141612200436e-05,
      "loss": 0.7787,
      "step": 2440
    },
    {
      "epoch": 0.2625093753348334,
      "grad_norm": 0.2064530849456787,
      "learning_rate": 1.964998749955356e-05,
      "loss": 0.7011,
      "step": 2450
    },
    {
      "epoch": 0.26358084217293476,
      "grad_norm": 0.20068688690662384,
      "learning_rate": 1.9648558877102754e-05,
      "loss": 0.3323,
      "step": 2460
    },
    {
      "epoch": 0.2646523090110361,
      "grad_norm": 0.2080894559621811,
      "learning_rate": 1.9647130254651954e-05,
      "loss": 0.3348,
      "step": 2470
    },
    {
      "epoch": 0.2657237758491375,
      "grad_norm": 0.11831432580947876,
      "learning_rate": 1.964570163220115e-05,
      "loss": 0.3542,
      "step": 2480
    },
    {
      "epoch": 0.2667952426872388,
      "grad_norm": 0.18211014568805695,
      "learning_rate": 1.964427300975035e-05,
      "loss": 0.3862,
      "step": 2490
    },
    {
      "epoch": 0.2678667095253402,
      "grad_norm": 0.20179259777069092,
      "learning_rate": 1.964284438729955e-05,
      "loss": 0.9306,
      "step": 2500
    },
    {
      "epoch": 0.26893817636344153,
      "grad_norm": 18.815200805664062,
      "learning_rate": 1.9641415764848744e-05,
      "loss": 0.988,
      "step": 2510
    },
    {
      "epoch": 0.2700096432015429,
      "grad_norm": 0.4161930978298187,
      "learning_rate": 1.9639987142397944e-05,
      "loss": 0.679,
      "step": 2520
    },
    {
      "epoch": 0.27108111003964425,
      "grad_norm": 32.61550521850586,
      "learning_rate": 1.9638558519947143e-05,
      "loss": 0.6198,
      "step": 2530
    },
    {
      "epoch": 0.27215257687774563,
      "grad_norm": 1.6534043550491333,
      "learning_rate": 1.9637129897496343e-05,
      "loss": 0.6567,
      "step": 2540
    },
    {
      "epoch": 0.273224043715847,
      "grad_norm": 17.444520950317383,
      "learning_rate": 1.963570127504554e-05,
      "loss": 0.7836,
      "step": 2550
    },
    {
      "epoch": 0.27429551055394835,
      "grad_norm": 23.340381622314453,
      "learning_rate": 1.9634272652594738e-05,
      "loss": 0.299,
      "step": 2560
    },
    {
      "epoch": 0.27536697739204974,
      "grad_norm": 0.36072999238967896,
      "learning_rate": 1.9632844030143937e-05,
      "loss": 0.6528,
      "step": 2570
    },
    {
      "epoch": 0.27643844423015107,
      "grad_norm": 39.0091667175293,
      "learning_rate": 1.9631415407693133e-05,
      "loss": 0.9454,
      "step": 2580
    },
    {
      "epoch": 0.27750991106825246,
      "grad_norm": 0.7502373456954956,
      "learning_rate": 1.9629986785242333e-05,
      "loss": 0.6543,
      "step": 2590
    },
    {
      "epoch": 0.2785813779063538,
      "grad_norm": 0.2670884132385254,
      "learning_rate": 1.962855816279153e-05,
      "loss": 0.5781,
      "step": 2600
    },
    {
      "epoch": 0.2796528447444552,
      "grad_norm": 0.16755717992782593,
      "learning_rate": 1.9627129540340728e-05,
      "loss": 0.2921,
      "step": 2610
    },
    {
      "epoch": 0.2807243115825565,
      "grad_norm": 0.7311621904373169,
      "learning_rate": 1.9625700917889927e-05,
      "loss": 0.7893,
      "step": 2620
    },
    {
      "epoch": 0.2817957784206579,
      "grad_norm": 71.92071533203125,
      "learning_rate": 1.9624272295439123e-05,
      "loss": 0.7507,
      "step": 2630
    },
    {
      "epoch": 0.2828672452587592,
      "grad_norm": 0.5396219491958618,
      "learning_rate": 1.9622843672988323e-05,
      "loss": 0.7158,
      "step": 2640
    },
    {
      "epoch": 0.2839387120968606,
      "grad_norm": 0.3695581555366516,
      "learning_rate": 1.962141505053752e-05,
      "loss": 0.5772,
      "step": 2650
    },
    {
      "epoch": 0.28501017893496194,
      "grad_norm": 48.478267669677734,
      "learning_rate": 1.9619986428086718e-05,
      "loss": 1.0077,
      "step": 2660
    },
    {
      "epoch": 0.28608164577306333,
      "grad_norm": 0.6622639894485474,
      "learning_rate": 1.9618557805635917e-05,
      "loss": 0.8139,
      "step": 2670
    },
    {
      "epoch": 0.28715311261116466,
      "grad_norm": 2.0097463130950928,
      "learning_rate": 1.9617129183185117e-05,
      "loss": 0.9307,
      "step": 2680
    },
    {
      "epoch": 0.28822457944926605,
      "grad_norm": 0.37763094902038574,
      "learning_rate": 1.9615700560734313e-05,
      "loss": 0.3875,
      "step": 2690
    },
    {
      "epoch": 0.2892960462873674,
      "grad_norm": 19.724224090576172,
      "learning_rate": 1.9614271938283512e-05,
      "loss": 0.587,
      "step": 2700
    },
    {
      "epoch": 0.29036751312546877,
      "grad_norm": 0.13947002589702606,
      "learning_rate": 1.961284331583271e-05,
      "loss": 0.2315,
      "step": 2710
    },
    {
      "epoch": 0.29143897996357016,
      "grad_norm": 0.23543314635753632,
      "learning_rate": 1.9611414693381907e-05,
      "loss": 0.4126,
      "step": 2720
    },
    {
      "epoch": 0.2925104468016715,
      "grad_norm": 24.5507755279541,
      "learning_rate": 1.9609986070931107e-05,
      "loss": 0.9852,
      "step": 2730
    },
    {
      "epoch": 0.2935819136397729,
      "grad_norm": 0.523186445236206,
      "learning_rate": 1.9608557448480306e-05,
      "loss": 0.5485,
      "step": 2740
    },
    {
      "epoch": 0.2946533804778742,
      "grad_norm": 0.6178840398788452,
      "learning_rate": 1.9607128826029502e-05,
      "loss": 0.6611,
      "step": 2750
    },
    {
      "epoch": 0.2957248473159756,
      "grad_norm": 0.2986292541027069,
      "learning_rate": 1.96057002035787e-05,
      "loss": 0.9884,
      "step": 2760
    },
    {
      "epoch": 0.2967963141540769,
      "grad_norm": 0.2316872775554657,
      "learning_rate": 1.9604271581127898e-05,
      "loss": 0.3207,
      "step": 2770
    },
    {
      "epoch": 0.2978677809921783,
      "grad_norm": 24.532453536987305,
      "learning_rate": 1.9602842958677097e-05,
      "loss": 0.3771,
      "step": 2780
    },
    {
      "epoch": 0.29893924783027964,
      "grad_norm": 0.48966699838638306,
      "learning_rate": 1.9601414336226293e-05,
      "loss": 0.834,
      "step": 2790
    },
    {
      "epoch": 0.30001071466838103,
      "grad_norm": 19.1119327545166,
      "learning_rate": 1.9599985713775492e-05,
      "loss": 0.6734,
      "step": 2800
    },
    {
      "epoch": 0.30108218150648236,
      "grad_norm": 0.1366305947303772,
      "learning_rate": 1.959855709132469e-05,
      "loss": 0.5215,
      "step": 2810
    },
    {
      "epoch": 0.30215364834458375,
      "grad_norm": 0.8541109561920166,
      "learning_rate": 1.959712846887389e-05,
      "loss": 0.7047,
      "step": 2820
    },
    {
      "epoch": 0.3032251151826851,
      "grad_norm": 0.5162804126739502,
      "learning_rate": 1.9595699846423087e-05,
      "loss": 0.7865,
      "step": 2830
    },
    {
      "epoch": 0.30429658202078647,
      "grad_norm": 1.3435821533203125,
      "learning_rate": 1.9594271223972286e-05,
      "loss": 0.5008,
      "step": 2840
    },
    {
      "epoch": 0.3053680488588878,
      "grad_norm": 22.352489471435547,
      "learning_rate": 1.9592842601521486e-05,
      "loss": 0.9963,
      "step": 2850
    },
    {
      "epoch": 0.3064395156969892,
      "grad_norm": 1.8901867866516113,
      "learning_rate": 1.9591413979070685e-05,
      "loss": 0.6257,
      "step": 2860
    },
    {
      "epoch": 0.3075109825350905,
      "grad_norm": 0.05334029719233513,
      "learning_rate": 1.958998535661988e-05,
      "loss": 0.9182,
      "step": 2870
    },
    {
      "epoch": 0.3085824493731919,
      "grad_norm": 1.8591115474700928,
      "learning_rate": 1.958855673416908e-05,
      "loss": 0.144,
      "step": 2880
    },
    {
      "epoch": 0.30965391621129323,
      "grad_norm": 25.403234481811523,
      "learning_rate": 1.9587128111718276e-05,
      "loss": 0.9942,
      "step": 2890
    },
    {
      "epoch": 0.3107253830493946,
      "grad_norm": 0.16309227049350739,
      "learning_rate": 1.9585699489267476e-05,
      "loss": 0.2208,
      "step": 2900
    },
    {
      "epoch": 0.311796849887496,
      "grad_norm": 0.07903052866458893,
      "learning_rate": 1.9584270866816672e-05,
      "loss": 0.3085,
      "step": 2910
    },
    {
      "epoch": 0.31286831672559734,
      "grad_norm": 0.09736168384552002,
      "learning_rate": 1.958284224436587e-05,
      "loss": 1.1523,
      "step": 2920
    },
    {
      "epoch": 0.3139397835636987,
      "grad_norm": 37.77507019042969,
      "learning_rate": 1.958141362191507e-05,
      "loss": 1.0301,
      "step": 2930
    },
    {
      "epoch": 0.31501125040180006,
      "grad_norm": 21.423587799072266,
      "learning_rate": 1.9579984999464266e-05,
      "loss": 0.662,
      "step": 2940
    },
    {
      "epoch": 0.31608271723990145,
      "grad_norm": 0.436715692281723,
      "learning_rate": 1.9578556377013466e-05,
      "loss": 0.567,
      "step": 2950
    },
    {
      "epoch": 0.3171541840780028,
      "grad_norm": 0.1992795467376709,
      "learning_rate": 1.9577127754562665e-05,
      "loss": 0.0087,
      "step": 2960
    },
    {
      "epoch": 0.31822565091610416,
      "grad_norm": 0.09228179603815079,
      "learning_rate": 1.957569913211186e-05,
      "loss": 0.3815,
      "step": 2970
    },
    {
      "epoch": 0.3192971177542055,
      "grad_norm": 0.12827913463115692,
      "learning_rate": 1.957427050966106e-05,
      "loss": 0.9371,
      "step": 2980
    },
    {
      "epoch": 0.3203685845923069,
      "grad_norm": 0.33484068512916565,
      "learning_rate": 1.957284188721026e-05,
      "loss": 1.0362,
      "step": 2990
    },
    {
      "epoch": 0.3214400514304082,
      "grad_norm": 0.30903249979019165,
      "learning_rate": 1.957141326475946e-05,
      "loss": 0.1957,
      "step": 3000
    },
    {
      "epoch": 0.3225115182685096,
      "grad_norm": 0.3321332335472107,
      "learning_rate": 1.9569984642308655e-05,
      "loss": 0.6973,
      "step": 3010
    },
    {
      "epoch": 0.32358298510661093,
      "grad_norm": 0.3016059398651123,
      "learning_rate": 1.9568556019857855e-05,
      "loss": 0.3697,
      "step": 3020
    },
    {
      "epoch": 0.3246544519447123,
      "grad_norm": 0.1589607149362564,
      "learning_rate": 1.956712739740705e-05,
      "loss": 0.2741,
      "step": 3030
    },
    {
      "epoch": 0.32572591878281365,
      "grad_norm": 17.828580856323242,
      "learning_rate": 1.956569877495625e-05,
      "loss": 0.7945,
      "step": 3040
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 19.49863052368164,
      "learning_rate": 1.956427015250545e-05,
      "loss": 0.6612,
      "step": 3050
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 0.9988892078399658,
      "learning_rate": 1.9562841530054645e-05,
      "loss": 0.86,
      "step": 3060
    },
    {
      "epoch": 0.32894031929711776,
      "grad_norm": 0.6901010274887085,
      "learning_rate": 1.9561412907603845e-05,
      "loss": 0.9912,
      "step": 3070
    },
    {
      "epoch": 0.3300117861352191,
      "grad_norm": 18.325435638427734,
      "learning_rate": 1.955998428515304e-05,
      "loss": 0.6884,
      "step": 3080
    },
    {
      "epoch": 0.3310832529733205,
      "grad_norm": 17.339948654174805,
      "learning_rate": 1.955855566270224e-05,
      "loss": 0.7966,
      "step": 3090
    },
    {
      "epoch": 0.33215471981142186,
      "grad_norm": 0.5127505660057068,
      "learning_rate": 1.955712704025144e-05,
      "loss": 0.4966,
      "step": 3100
    },
    {
      "epoch": 0.3332261866495232,
      "grad_norm": 8.753926277160645,
      "learning_rate": 1.955569841780064e-05,
      "loss": 0.8362,
      "step": 3110
    },
    {
      "epoch": 0.3342976534876246,
      "grad_norm": 0.5371496677398682,
      "learning_rate": 1.9554269795349835e-05,
      "loss": 0.0689,
      "step": 3120
    },
    {
      "epoch": 0.3353691203257259,
      "grad_norm": 30.341556549072266,
      "learning_rate": 1.9552841172899034e-05,
      "loss": 0.9204,
      "step": 3130
    },
    {
      "epoch": 0.3364405871638273,
      "grad_norm": 7.339926242828369,
      "learning_rate": 1.9551412550448233e-05,
      "loss": 0.8584,
      "step": 3140
    },
    {
      "epoch": 0.33751205400192863,
      "grad_norm": 17.889904022216797,
      "learning_rate": 1.954998392799743e-05,
      "loss": 0.511,
      "step": 3150
    },
    {
      "epoch": 0.33858352084003,
      "grad_norm": 56.3125,
      "learning_rate": 1.954855530554663e-05,
      "loss": 0.5483,
      "step": 3160
    },
    {
      "epoch": 0.33965498767813135,
      "grad_norm": 13.821078300476074,
      "learning_rate": 1.9547126683095828e-05,
      "loss": 0.9504,
      "step": 3170
    },
    {
      "epoch": 0.34072645451623274,
      "grad_norm": 7.2230401039123535,
      "learning_rate": 1.9545698060645024e-05,
      "loss": 0.288,
      "step": 3180
    },
    {
      "epoch": 0.34179792135433407,
      "grad_norm": 3.3281846046447754,
      "learning_rate": 1.9544269438194223e-05,
      "loss": 0.6391,
      "step": 3190
    },
    {
      "epoch": 0.34286938819243545,
      "grad_norm": 0.3880392014980316,
      "learning_rate": 1.954284081574342e-05,
      "loss": 0.2981,
      "step": 3200
    },
    {
      "epoch": 0.3439408550305368,
      "grad_norm": 0.34170255064964294,
      "learning_rate": 1.954141219329262e-05,
      "loss": 0.949,
      "step": 3210
    },
    {
      "epoch": 0.34501232186863817,
      "grad_norm": 22.618764877319336,
      "learning_rate": 1.9539983570841818e-05,
      "loss": 0.4538,
      "step": 3220
    },
    {
      "epoch": 0.3460837887067395,
      "grad_norm": 0.5705304741859436,
      "learning_rate": 1.9538554948391014e-05,
      "loss": 0.4932,
      "step": 3230
    },
    {
      "epoch": 0.3471552555448409,
      "grad_norm": 0.2061307728290558,
      "learning_rate": 1.9537126325940214e-05,
      "loss": 0.6737,
      "step": 3240
    },
    {
      "epoch": 0.3482267223829422,
      "grad_norm": 2.0445497035980225,
      "learning_rate": 1.9535697703489413e-05,
      "loss": 0.6938,
      "step": 3250
    },
    {
      "epoch": 0.3492981892210436,
      "grad_norm": 0.20326516032218933,
      "learning_rate": 1.953426908103861e-05,
      "loss": 0.3361,
      "step": 3260
    },
    {
      "epoch": 0.350369656059145,
      "grad_norm": 15.960136413574219,
      "learning_rate": 1.9532840458587808e-05,
      "loss": 0.6182,
      "step": 3270
    },
    {
      "epoch": 0.3514411228972463,
      "grad_norm": 0.1713777780532837,
      "learning_rate": 1.9531411836137008e-05,
      "loss": 0.3353,
      "step": 3280
    },
    {
      "epoch": 0.3525125897353477,
      "grad_norm": 27.930370330810547,
      "learning_rate": 1.9529983213686207e-05,
      "loss": 0.7509,
      "step": 3290
    },
    {
      "epoch": 0.35358405657344905,
      "grad_norm": 1.682955265045166,
      "learning_rate": 1.9528554591235403e-05,
      "loss": 1.0196,
      "step": 3300
    },
    {
      "epoch": 0.35465552341155043,
      "grad_norm": 0.591294527053833,
      "learning_rate": 1.9527125968784602e-05,
      "loss": 0.3528,
      "step": 3310
    },
    {
      "epoch": 0.35572699024965176,
      "grad_norm": 1.4643244743347168,
      "learning_rate": 1.95256973463338e-05,
      "loss": 0.4525,
      "step": 3320
    },
    {
      "epoch": 0.35679845708775315,
      "grad_norm": 3.2166688442230225,
      "learning_rate": 1.9524268723882998e-05,
      "loss": 0.7416,
      "step": 3330
    },
    {
      "epoch": 0.3578699239258545,
      "grad_norm": 57.94877624511719,
      "learning_rate": 1.9522840101432197e-05,
      "loss": 0.2742,
      "step": 3340
    },
    {
      "epoch": 0.35894139076395587,
      "grad_norm": 0.05957316607236862,
      "learning_rate": 1.9521411478981393e-05,
      "loss": 0.1732,
      "step": 3350
    },
    {
      "epoch": 0.3600128576020572,
      "grad_norm": 25.777896881103516,
      "learning_rate": 1.9519982856530592e-05,
      "loss": 1.5498,
      "step": 3360
    },
    {
      "epoch": 0.3610843244401586,
      "grad_norm": 26.68571662902832,
      "learning_rate": 1.951855423407979e-05,
      "loss": 1.0374,
      "step": 3370
    },
    {
      "epoch": 0.3621557912782599,
      "grad_norm": 1.4414023160934448,
      "learning_rate": 1.9517125611628988e-05,
      "loss": 0.3304,
      "step": 3380
    },
    {
      "epoch": 0.3632272581163613,
      "grad_norm": 0.08328554779291153,
      "learning_rate": 1.9515696989178187e-05,
      "loss": 0.8625,
      "step": 3390
    },
    {
      "epoch": 0.36429872495446264,
      "grad_norm": 0.21303361654281616,
      "learning_rate": 1.9514268366727383e-05,
      "loss": 1.0497,
      "step": 3400
    },
    {
      "epoch": 0.365370191792564,
      "grad_norm": 0.2111463099718094,
      "learning_rate": 1.9512839744276582e-05,
      "loss": 0.2767,
      "step": 3410
    },
    {
      "epoch": 0.36644165863066536,
      "grad_norm": 0.472927063703537,
      "learning_rate": 1.9511411121825782e-05,
      "loss": 0.5232,
      "step": 3420
    },
    {
      "epoch": 0.36751312546876674,
      "grad_norm": 30.70879364013672,
      "learning_rate": 1.950998249937498e-05,
      "loss": 0.4595,
      "step": 3430
    },
    {
      "epoch": 0.3685845923068681,
      "grad_norm": 25.478778839111328,
      "learning_rate": 1.9508553876924177e-05,
      "loss": 0.7391,
      "step": 3440
    },
    {
      "epoch": 0.36965605914496946,
      "grad_norm": 0.13292555510997772,
      "learning_rate": 1.9507125254473377e-05,
      "loss": 0.4054,
      "step": 3450
    },
    {
      "epoch": 0.37072752598307085,
      "grad_norm": 2.5628137588500977,
      "learning_rate": 1.9505696632022576e-05,
      "loss": 0.082,
      "step": 3460
    },
    {
      "epoch": 0.3717989928211722,
      "grad_norm": 1.6777660846710205,
      "learning_rate": 1.9504268009571772e-05,
      "loss": 0.4155,
      "step": 3470
    },
    {
      "epoch": 0.37287045965927357,
      "grad_norm": 16.9901123046875,
      "learning_rate": 1.950283938712097e-05,
      "loss": 0.5582,
      "step": 3480
    },
    {
      "epoch": 0.3739419264973749,
      "grad_norm": 0.1511944830417633,
      "learning_rate": 1.9501410764670167e-05,
      "loss": 0.2754,
      "step": 3490
    },
    {
      "epoch": 0.3750133933354763,
      "grad_norm": 0.18896172940731049,
      "learning_rate": 1.9499982142219367e-05,
      "loss": 0.5647,
      "step": 3500
    },
    {
      "epoch": 0.3760848601735776,
      "grad_norm": 65.53929901123047,
      "learning_rate": 1.9498553519768563e-05,
      "loss": 1.0847,
      "step": 3510
    },
    {
      "epoch": 0.377156327011679,
      "grad_norm": 1.0349279642105103,
      "learning_rate": 1.9497124897317762e-05,
      "loss": 0.4846,
      "step": 3520
    },
    {
      "epoch": 0.37822779384978034,
      "grad_norm": 28.49846839904785,
      "learning_rate": 1.949569627486696e-05,
      "loss": 0.682,
      "step": 3530
    },
    {
      "epoch": 0.3792992606878817,
      "grad_norm": 1.9396220445632935,
      "learning_rate": 1.9494267652416157e-05,
      "loss": 0.8507,
      "step": 3540
    },
    {
      "epoch": 0.38037072752598305,
      "grad_norm": 10.802240371704102,
      "learning_rate": 1.9492839029965357e-05,
      "loss": 0.3858,
      "step": 3550
    },
    {
      "epoch": 0.38144219436408444,
      "grad_norm": 0.8931912183761597,
      "learning_rate": 1.9491410407514556e-05,
      "loss": 0.1293,
      "step": 3560
    },
    {
      "epoch": 0.3825136612021858,
      "grad_norm": 0.5850144028663635,
      "learning_rate": 1.9489981785063755e-05,
      "loss": 0.7776,
      "step": 3570
    },
    {
      "epoch": 0.38358512804028716,
      "grad_norm": 0.5845152139663696,
      "learning_rate": 1.9488553162612955e-05,
      "loss": 0.4099,
      "step": 3580
    },
    {
      "epoch": 0.3846565948783885,
      "grad_norm": 0.10292316228151321,
      "learning_rate": 1.948712454016215e-05,
      "loss": 0.9069,
      "step": 3590
    },
    {
      "epoch": 0.3857280617164899,
      "grad_norm": 0.09268699586391449,
      "learning_rate": 1.948569591771135e-05,
      "loss": 0.4362,
      "step": 3600
    },
    {
      "epoch": 0.3867995285545912,
      "grad_norm": 1.1238346099853516,
      "learning_rate": 1.9484267295260546e-05,
      "loss": 0.9572,
      "step": 3610
    },
    {
      "epoch": 0.3878709953926926,
      "grad_norm": 1.681631326675415,
      "learning_rate": 1.9482838672809745e-05,
      "loss": 0.6383,
      "step": 3620
    },
    {
      "epoch": 0.388942462230794,
      "grad_norm": 0.5378330945968628,
      "learning_rate": 1.948141005035894e-05,
      "loss": 0.8524,
      "step": 3630
    },
    {
      "epoch": 0.3900139290688953,
      "grad_norm": 18.921817779541016,
      "learning_rate": 1.947998142790814e-05,
      "loss": 0.614,
      "step": 3640
    },
    {
      "epoch": 0.3910853959069967,
      "grad_norm": 0.33789584040641785,
      "learning_rate": 1.947855280545734e-05,
      "loss": 0.3951,
      "step": 3650
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 149.88255310058594,
      "learning_rate": 1.9477124183006536e-05,
      "loss": 0.7264,
      "step": 3660
    },
    {
      "epoch": 0.3932283295831994,
      "grad_norm": 19.671594619750977,
      "learning_rate": 1.9475695560555735e-05,
      "loss": 0.9851,
      "step": 3670
    },
    {
      "epoch": 0.39429979642130075,
      "grad_norm": 19.305112838745117,
      "learning_rate": 1.9474266938104935e-05,
      "loss": 0.7912,
      "step": 3680
    },
    {
      "epoch": 0.39537126325940214,
      "grad_norm": 0.22018158435821533,
      "learning_rate": 1.947283831565413e-05,
      "loss": 0.6392,
      "step": 3690
    },
    {
      "epoch": 0.39644273009750347,
      "grad_norm": 0.17785805463790894,
      "learning_rate": 1.947140969320333e-05,
      "loss": 0.159,
      "step": 3700
    },
    {
      "epoch": 0.39751419693560486,
      "grad_norm": 0.15167725086212158,
      "learning_rate": 1.946998107075253e-05,
      "loss": 0.4907,
      "step": 3710
    },
    {
      "epoch": 0.3985856637737062,
      "grad_norm": 0.08620839565992355,
      "learning_rate": 1.946855244830173e-05,
      "loss": 0.4029,
      "step": 3720
    },
    {
      "epoch": 0.3996571306118076,
      "grad_norm": 17.19105339050293,
      "learning_rate": 1.9467123825850925e-05,
      "loss": 0.8622,
      "step": 3730
    },
    {
      "epoch": 0.4007285974499089,
      "grad_norm": 19.812091827392578,
      "learning_rate": 1.9465695203400124e-05,
      "loss": 0.6653,
      "step": 3740
    },
    {
      "epoch": 0.4018000642880103,
      "grad_norm": 0.6325041651725769,
      "learning_rate": 1.946426658094932e-05,
      "loss": 0.7254,
      "step": 3750
    },
    {
      "epoch": 0.4028715311261116,
      "grad_norm": 0.4476262032985687,
      "learning_rate": 1.946283795849852e-05,
      "loss": 0.3695,
      "step": 3760
    },
    {
      "epoch": 0.403942997964213,
      "grad_norm": 0.33120468258857727,
      "learning_rate": 1.946140933604772e-05,
      "loss": 0.532,
      "step": 3770
    },
    {
      "epoch": 0.40501446480231434,
      "grad_norm": 0.3956284821033478,
      "learning_rate": 1.9459980713596915e-05,
      "loss": 0.9043,
      "step": 3780
    },
    {
      "epoch": 0.40608593164041573,
      "grad_norm": 16.042724609375,
      "learning_rate": 1.9458552091146114e-05,
      "loss": 0.4297,
      "step": 3790
    },
    {
      "epoch": 0.40715739847851706,
      "grad_norm": 0.282715380191803,
      "learning_rate": 1.945712346869531e-05,
      "loss": 0.1939,
      "step": 3800
    },
    {
      "epoch": 0.40822886531661845,
      "grad_norm": 0.3166998028755188,
      "learning_rate": 1.945569484624451e-05,
      "loss": 0.8433,
      "step": 3810
    },
    {
      "epoch": 0.40930033215471984,
      "grad_norm": 0.26404884457588196,
      "learning_rate": 1.945426622379371e-05,
      "loss": 0.0798,
      "step": 3820
    },
    {
      "epoch": 0.41037179899282117,
      "grad_norm": 0.12748919427394867,
      "learning_rate": 1.9452837601342905e-05,
      "loss": 0.3082,
      "step": 3830
    },
    {
      "epoch": 0.41144326583092256,
      "grad_norm": 24.364280700683594,
      "learning_rate": 1.9451408978892104e-05,
      "loss": 1.0703,
      "step": 3840
    },
    {
      "epoch": 0.4125147326690239,
      "grad_norm": 23.169330596923828,
      "learning_rate": 1.9449980356441304e-05,
      "loss": 0.4615,
      "step": 3850
    },
    {
      "epoch": 0.4135861995071253,
      "grad_norm": 0.45934993028640747,
      "learning_rate": 1.9448551733990503e-05,
      "loss": 0.3975,
      "step": 3860
    },
    {
      "epoch": 0.4146576663452266,
      "grad_norm": 0.1641886830329895,
      "learning_rate": 1.94471231115397e-05,
      "loss": 0.7768,
      "step": 3870
    },
    {
      "epoch": 0.415729133183328,
      "grad_norm": 18.693132400512695,
      "learning_rate": 1.94456944890889e-05,
      "loss": 0.6428,
      "step": 3880
    },
    {
      "epoch": 0.4168006000214293,
      "grad_norm": 0.719170331954956,
      "learning_rate": 1.9444265866638098e-05,
      "loss": 0.8743,
      "step": 3890
    },
    {
      "epoch": 0.4178720668595307,
      "grad_norm": 0.4713838994503021,
      "learning_rate": 1.9442837244187294e-05,
      "loss": 0.6035,
      "step": 3900
    },
    {
      "epoch": 0.41894353369763204,
      "grad_norm": 0.35912153124809265,
      "learning_rate": 1.9441408621736493e-05,
      "loss": 0.4384,
      "step": 3910
    },
    {
      "epoch": 0.42001500053573343,
      "grad_norm": 0.43831637501716614,
      "learning_rate": 1.943997999928569e-05,
      "loss": 0.1957,
      "step": 3920
    },
    {
      "epoch": 0.42108646737383476,
      "grad_norm": 0.15635119378566742,
      "learning_rate": 1.943855137683489e-05,
      "loss": 0.5301,
      "step": 3930
    },
    {
      "epoch": 0.42215793421193615,
      "grad_norm": 18.016395568847656,
      "learning_rate": 1.9437122754384085e-05,
      "loss": 0.4569,
      "step": 3940
    },
    {
      "epoch": 0.4232294010500375,
      "grad_norm": 24.683488845825195,
      "learning_rate": 1.9435694131933284e-05,
      "loss": 1.0481,
      "step": 3950
    },
    {
      "epoch": 0.42430086788813887,
      "grad_norm": 10.173296928405762,
      "learning_rate": 1.9434265509482483e-05,
      "loss": 0.4864,
      "step": 3960
    },
    {
      "epoch": 0.4253723347262402,
      "grad_norm": 0.24477417767047882,
      "learning_rate": 1.943283688703168e-05,
      "loss": 0.3942,
      "step": 3970
    },
    {
      "epoch": 0.4264438015643416,
      "grad_norm": 0.7026832699775696,
      "learning_rate": 1.943140826458088e-05,
      "loss": 1.1547,
      "step": 3980
    },
    {
      "epoch": 0.42751526840244297,
      "grad_norm": 0.8184248208999634,
      "learning_rate": 1.9429979642130078e-05,
      "loss": 0.215,
      "step": 3990
    },
    {
      "epoch": 0.4285867352405443,
      "grad_norm": 0.31220316886901855,
      "learning_rate": 1.9428551019679277e-05,
      "loss": 0.461,
      "step": 4000
    },
    {
      "epoch": 0.4296582020786457,
      "grad_norm": 0.34809061884880066,
      "learning_rate": 1.9427122397228477e-05,
      "loss": 0.4896,
      "step": 4010
    },
    {
      "epoch": 0.430729668916747,
      "grad_norm": 6.865355968475342,
      "learning_rate": 1.9425693774777673e-05,
      "loss": 0.5414,
      "step": 4020
    },
    {
      "epoch": 0.4318011357548484,
      "grad_norm": 1.214976191520691,
      "learning_rate": 1.9424265152326872e-05,
      "loss": 0.1549,
      "step": 4030
    },
    {
      "epoch": 0.43287260259294974,
      "grad_norm": 20.29330825805664,
      "learning_rate": 1.9422836529876068e-05,
      "loss": 1.2434,
      "step": 4040
    },
    {
      "epoch": 0.4339440694310511,
      "grad_norm": 16.956771850585938,
      "learning_rate": 1.9421407907425267e-05,
      "loss": 1.0359,
      "step": 4050
    },
    {
      "epoch": 0.43501553626915246,
      "grad_norm": 0.35051050782203674,
      "learning_rate": 1.9419979284974463e-05,
      "loss": 0.5749,
      "step": 4060
    },
    {
      "epoch": 0.43608700310725385,
      "grad_norm": 18.6126708984375,
      "learning_rate": 1.9418550662523663e-05,
      "loss": 0.6717,
      "step": 4070
    },
    {
      "epoch": 0.4371584699453552,
      "grad_norm": 28.044353485107422,
      "learning_rate": 1.9417122040072862e-05,
      "loss": 0.8718,
      "step": 4080
    },
    {
      "epoch": 0.43822993678345656,
      "grad_norm": 0.8940954804420471,
      "learning_rate": 1.9415693417622058e-05,
      "loss": 1.1636,
      "step": 4090
    },
    {
      "epoch": 0.4393014036215579,
      "grad_norm": 13.98375129699707,
      "learning_rate": 1.9414264795171257e-05,
      "loss": 0.7946,
      "step": 4100
    },
    {
      "epoch": 0.4403728704596593,
      "grad_norm": 21.85817527770996,
      "learning_rate": 1.9412836172720453e-05,
      "loss": 0.8008,
      "step": 4110
    },
    {
      "epoch": 0.4414443372977606,
      "grad_norm": 0.490383505821228,
      "learning_rate": 1.9411407550269653e-05,
      "loss": 0.5735,
      "step": 4120
    },
    {
      "epoch": 0.442515804135862,
      "grad_norm": 20.637022018432617,
      "learning_rate": 1.9409978927818852e-05,
      "loss": 0.451,
      "step": 4130
    },
    {
      "epoch": 0.44358727097396333,
      "grad_norm": 17.131975173950195,
      "learning_rate": 1.940855030536805e-05,
      "loss": 1.0203,
      "step": 4140
    },
    {
      "epoch": 0.4446587378120647,
      "grad_norm": 20.193866729736328,
      "learning_rate": 1.940712168291725e-05,
      "loss": 0.5275,
      "step": 4150
    },
    {
      "epoch": 0.44573020465016605,
      "grad_norm": 0.592120885848999,
      "learning_rate": 1.9405693060466447e-05,
      "loss": 0.4464,
      "step": 4160
    },
    {
      "epoch": 0.44680167148826744,
      "grad_norm": 1.3913747072219849,
      "learning_rate": 1.9404264438015646e-05,
      "loss": 0.6808,
      "step": 4170
    },
    {
      "epoch": 0.4478731383263688,
      "grad_norm": 0.1276094764471054,
      "learning_rate": 1.9402835815564842e-05,
      "loss": 0.3928,
      "step": 4180
    },
    {
      "epoch": 0.44894460516447016,
      "grad_norm": 0.18678902089595795,
      "learning_rate": 1.940140719311404e-05,
      "loss": 0.3808,
      "step": 4190
    },
    {
      "epoch": 0.45001607200257154,
      "grad_norm": 0.21032065153121948,
      "learning_rate": 1.939997857066324e-05,
      "loss": 0.818,
      "step": 4200
    },
    {
      "epoch": 0.4510875388406729,
      "grad_norm": 0.47968924045562744,
      "learning_rate": 1.9398549948212437e-05,
      "loss": 0.8166,
      "step": 4210
    },
    {
      "epoch": 0.45215900567877426,
      "grad_norm": 14.705700874328613,
      "learning_rate": 1.9397121325761636e-05,
      "loss": 0.6238,
      "step": 4220
    },
    {
      "epoch": 0.4532304725168756,
      "grad_norm": 16.755741119384766,
      "learning_rate": 1.9395692703310832e-05,
      "loss": 0.6016,
      "step": 4230
    },
    {
      "epoch": 0.454301939354977,
      "grad_norm": 18.54412269592285,
      "learning_rate": 1.939426408086003e-05,
      "loss": 0.4244,
      "step": 4240
    },
    {
      "epoch": 0.4553734061930783,
      "grad_norm": 0.19168423116207123,
      "learning_rate": 1.939283545840923e-05,
      "loss": 0.3285,
      "step": 4250
    },
    {
      "epoch": 0.4564448730311797,
      "grad_norm": 0.17880693078041077,
      "learning_rate": 1.9391406835958427e-05,
      "loss": 0.4726,
      "step": 4260
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 20.18960952758789,
      "learning_rate": 1.9389978213507626e-05,
      "loss": 0.5454,
      "step": 4270
    },
    {
      "epoch": 0.4585878067073824,
      "grad_norm": 30.334529876708984,
      "learning_rate": 1.9388549591056826e-05,
      "loss": 0.4426,
      "step": 4280
    },
    {
      "epoch": 0.45965927354548375,
      "grad_norm": 17.753679275512695,
      "learning_rate": 1.9387120968606025e-05,
      "loss": 1.0973,
      "step": 4290
    },
    {
      "epoch": 0.46073074038358514,
      "grad_norm": 31.326265335083008,
      "learning_rate": 1.938569234615522e-05,
      "loss": 1.0252,
      "step": 4300
    },
    {
      "epoch": 0.46180220722168647,
      "grad_norm": 0.8266111612319946,
      "learning_rate": 1.938426372370442e-05,
      "loss": 0.3575,
      "step": 4310
    },
    {
      "epoch": 0.46287367405978785,
      "grad_norm": 14.51005744934082,
      "learning_rate": 1.938283510125362e-05,
      "loss": 0.7276,
      "step": 4320
    },
    {
      "epoch": 0.4639451408978892,
      "grad_norm": 1.1457328796386719,
      "learning_rate": 1.9381406478802816e-05,
      "loss": 0.83,
      "step": 4330
    },
    {
      "epoch": 0.4650166077359906,
      "grad_norm": 1.0224155187606812,
      "learning_rate": 1.9379977856352015e-05,
      "loss": 0.5539,
      "step": 4340
    },
    {
      "epoch": 0.46608807457409196,
      "grad_norm": 17.57921028137207,
      "learning_rate": 1.937854923390121e-05,
      "loss": 0.6592,
      "step": 4350
    },
    {
      "epoch": 0.4671595414121933,
      "grad_norm": 15.131192207336426,
      "learning_rate": 1.937712061145041e-05,
      "loss": 0.4473,
      "step": 4360
    },
    {
      "epoch": 0.4682310082502947,
      "grad_norm": 16.756519317626953,
      "learning_rate": 1.937569198899961e-05,
      "loss": 1.1356,
      "step": 4370
    },
    {
      "epoch": 0.469302475088396,
      "grad_norm": 0.6531345844268799,
      "learning_rate": 1.9374263366548806e-05,
      "loss": 0.5346,
      "step": 4380
    },
    {
      "epoch": 0.4703739419264974,
      "grad_norm": 0.29341763257980347,
      "learning_rate": 1.9372834744098005e-05,
      "loss": 0.2804,
      "step": 4390
    },
    {
      "epoch": 0.47144540876459873,
      "grad_norm": 18.149381637573242,
      "learning_rate": 1.93714061216472e-05,
      "loss": 0.6853,
      "step": 4400
    },
    {
      "epoch": 0.4725168756027001,
      "grad_norm": 0.407020628452301,
      "learning_rate": 1.93699774991964e-05,
      "loss": 0.3401,
      "step": 4410
    },
    {
      "epoch": 0.47358834244080145,
      "grad_norm": 0.29931941628456116,
      "learning_rate": 1.93685488767456e-05,
      "loss": 0.7589,
      "step": 4420
    },
    {
      "epoch": 0.47465980927890283,
      "grad_norm": 0.419288694858551,
      "learning_rate": 1.93671202542948e-05,
      "loss": 0.5934,
      "step": 4430
    },
    {
      "epoch": 0.47573127611700416,
      "grad_norm": 13.96674633026123,
      "learning_rate": 1.9365691631843995e-05,
      "loss": 0.9597,
      "step": 4440
    },
    {
      "epoch": 0.47680274295510555,
      "grad_norm": 0.43002769351005554,
      "learning_rate": 1.9364263009393195e-05,
      "loss": 0.2527,
      "step": 4450
    },
    {
      "epoch": 0.4778742097932069,
      "grad_norm": 32.48050308227539,
      "learning_rate": 1.9362834386942394e-05,
      "loss": 0.7219,
      "step": 4460
    },
    {
      "epoch": 0.47894567663130827,
      "grad_norm": 15.568925857543945,
      "learning_rate": 1.936140576449159e-05,
      "loss": 0.8308,
      "step": 4470
    },
    {
      "epoch": 0.4800171434694096,
      "grad_norm": 1.2586438655853271,
      "learning_rate": 1.935997714204079e-05,
      "loss": 0.5612,
      "step": 4480
    },
    {
      "epoch": 0.481088610307511,
      "grad_norm": 34.056671142578125,
      "learning_rate": 1.935854851958999e-05,
      "loss": 0.6327,
      "step": 4490
    },
    {
      "epoch": 0.4821600771456123,
      "grad_norm": 0.8312849402427673,
      "learning_rate": 1.9357119897139185e-05,
      "loss": 1.1767,
      "step": 4500
    },
    {
      "epoch": 0.4832315439837137,
      "grad_norm": 15.264287948608398,
      "learning_rate": 1.9355691274688384e-05,
      "loss": 0.4512,
      "step": 4510
    },
    {
      "epoch": 0.48430301082181504,
      "grad_norm": 15.01220417022705,
      "learning_rate": 1.935426265223758e-05,
      "loss": 0.3845,
      "step": 4520
    },
    {
      "epoch": 0.4853744776599164,
      "grad_norm": 0.19239434599876404,
      "learning_rate": 1.935283402978678e-05,
      "loss": 0.8674,
      "step": 4530
    },
    {
      "epoch": 0.4864459444980178,
      "grad_norm": 24.086923599243164,
      "learning_rate": 1.9351405407335975e-05,
      "loss": 0.7959,
      "step": 4540
    },
    {
      "epoch": 0.48751741133611914,
      "grad_norm": 1.3730380535125732,
      "learning_rate": 1.9349976784885175e-05,
      "loss": 0.4518,
      "step": 4550
    },
    {
      "epoch": 0.48858887817422053,
      "grad_norm": 0.3268303871154785,
      "learning_rate": 1.9348548162434374e-05,
      "loss": 0.8037,
      "step": 4560
    },
    {
      "epoch": 0.48966034501232186,
      "grad_norm": 0.16280488669872284,
      "learning_rate": 1.9347119539983573e-05,
      "loss": 0.3721,
      "step": 4570
    },
    {
      "epoch": 0.49073181185042325,
      "grad_norm": 0.11264310032129288,
      "learning_rate": 1.9345690917532773e-05,
      "loss": 0.5625,
      "step": 4580
    },
    {
      "epoch": 0.4918032786885246,
      "grad_norm": 0.2166726142168045,
      "learning_rate": 1.934426229508197e-05,
      "loss": 0.7737,
      "step": 4590
    },
    {
      "epoch": 0.49287474552662597,
      "grad_norm": 3.819089651107788,
      "learning_rate": 1.9342833672631168e-05,
      "loss": 0.446,
      "step": 4600
    },
    {
      "epoch": 0.4939462123647273,
      "grad_norm": 12.271997451782227,
      "learning_rate": 1.9341405050180364e-05,
      "loss": 0.6195,
      "step": 4610
    },
    {
      "epoch": 0.4950176792028287,
      "grad_norm": 7.343784332275391,
      "learning_rate": 1.9339976427729564e-05,
      "loss": 0.361,
      "step": 4620
    },
    {
      "epoch": 0.49608914604093,
      "grad_norm": 0.10875242948532104,
      "learning_rate": 1.9338547805278763e-05,
      "loss": 0.0291,
      "step": 4630
    },
    {
      "epoch": 0.4971606128790314,
      "grad_norm": 0.02636459842324257,
      "learning_rate": 1.933711918282796e-05,
      "loss": 0.4962,
      "step": 4640
    },
    {
      "epoch": 0.49823207971713274,
      "grad_norm": 0.12493675202131271,
      "learning_rate": 1.9335690560377158e-05,
      "loss": 0.6679,
      "step": 4650
    },
    {
      "epoch": 0.4993035465552341,
      "grad_norm": 0.4881528317928314,
      "learning_rate": 1.9334261937926354e-05,
      "loss": 0.3587,
      "step": 4660
    },
    {
      "epoch": 0.5003750133933355,
      "grad_norm": 0.17043747007846832,
      "learning_rate": 1.9332833315475554e-05,
      "loss": 0.1821,
      "step": 4670
    },
    {
      "epoch": 0.5014464802314368,
      "grad_norm": 20.387292861938477,
      "learning_rate": 1.9331404693024753e-05,
      "loss": 0.4586,
      "step": 4680
    },
    {
      "epoch": 0.5025179470695382,
      "grad_norm": 16.807199478149414,
      "learning_rate": 1.932997607057395e-05,
      "loss": 1.1656,
      "step": 4690
    },
    {
      "epoch": 0.5035894139076396,
      "grad_norm": 18.951461791992188,
      "learning_rate": 1.9328547448123148e-05,
      "loss": 0.6431,
      "step": 4700
    },
    {
      "epoch": 0.5046608807457409,
      "grad_norm": 0.3982880115509033,
      "learning_rate": 1.9327118825672348e-05,
      "loss": 0.5363,
      "step": 4710
    },
    {
      "epoch": 0.5057323475838423,
      "grad_norm": 0.18678520619869232,
      "learning_rate": 1.9325690203221547e-05,
      "loss": 0.2393,
      "step": 4720
    },
    {
      "epoch": 0.5068038144219437,
      "grad_norm": 17.069360733032227,
      "learning_rate": 1.9324261580770743e-05,
      "loss": 0.885,
      "step": 4730
    },
    {
      "epoch": 0.507875281260045,
      "grad_norm": 0.7825621962547302,
      "learning_rate": 1.9322832958319942e-05,
      "loss": 0.4761,
      "step": 4740
    },
    {
      "epoch": 0.5089467480981463,
      "grad_norm": 0.7102090120315552,
      "learning_rate": 1.9321404335869142e-05,
      "loss": 0.4058,
      "step": 4750
    },
    {
      "epoch": 0.5100182149362478,
      "grad_norm": 0.23851598799228668,
      "learning_rate": 1.9319975713418338e-05,
      "loss": 0.2297,
      "step": 4760
    },
    {
      "epoch": 0.5110896817743491,
      "grad_norm": 0.13440850377082825,
      "learning_rate": 1.9318547090967537e-05,
      "loss": 0.6567,
      "step": 4770
    },
    {
      "epoch": 0.5121611486124504,
      "grad_norm": 14.1359224319458,
      "learning_rate": 1.9317118468516733e-05,
      "loss": 0.6833,
      "step": 4780
    },
    {
      "epoch": 0.5132326154505518,
      "grad_norm": 2.3528618812561035,
      "learning_rate": 1.9315689846065932e-05,
      "loss": 0.2629,
      "step": 4790
    },
    {
      "epoch": 0.5143040822886532,
      "grad_norm": 0.2154010385274887,
      "learning_rate": 1.9314261223615132e-05,
      "loss": 0.5183,
      "step": 4800
    },
    {
      "epoch": 0.5153755491267545,
      "grad_norm": 0.899778425693512,
      "learning_rate": 1.9312832601164328e-05,
      "loss": 1.2252,
      "step": 4810
    },
    {
      "epoch": 0.5164470159648559,
      "grad_norm": 1.2081907987594604,
      "learning_rate": 1.9311403978713527e-05,
      "loss": 0.3408,
      "step": 4820
    },
    {
      "epoch": 0.5175184828029572,
      "grad_norm": 0.15869605541229248,
      "learning_rate": 1.9309975356262723e-05,
      "loss": 0.3034,
      "step": 4830
    },
    {
      "epoch": 0.5185899496410586,
      "grad_norm": 15.232370376586914,
      "learning_rate": 1.9308546733811922e-05,
      "loss": 0.4873,
      "step": 4840
    },
    {
      "epoch": 0.51966141647916,
      "grad_norm": 1.333767056465149,
      "learning_rate": 1.9307118111361122e-05,
      "loss": 0.7334,
      "step": 4850
    },
    {
      "epoch": 0.5207328833172613,
      "grad_norm": 0.9055532813072205,
      "learning_rate": 1.930568948891032e-05,
      "loss": 0.3912,
      "step": 4860
    },
    {
      "epoch": 0.5218043501553626,
      "grad_norm": 0.12049426883459091,
      "learning_rate": 1.9304260866459517e-05,
      "loss": 0.1887,
      "step": 4870
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.13753296434879303,
      "learning_rate": 1.9302832244008717e-05,
      "loss": 0.9761,
      "step": 4880
    },
    {
      "epoch": 0.5239472838315654,
      "grad_norm": 17.40324592590332,
      "learning_rate": 1.9301403621557916e-05,
      "loss": 0.2613,
      "step": 4890
    },
    {
      "epoch": 0.5250187506696667,
      "grad_norm": 0.3090333044528961,
      "learning_rate": 1.9299974999107112e-05,
      "loss": 0.8351,
      "step": 4900
    },
    {
      "epoch": 0.5260902175077682,
      "grad_norm": 0.44596773386001587,
      "learning_rate": 1.929854637665631e-05,
      "loss": 0.6362,
      "step": 4910
    },
    {
      "epoch": 0.5271616843458695,
      "grad_norm": 13.896516799926758,
      "learning_rate": 1.929711775420551e-05,
      "loss": 0.605,
      "step": 4920
    },
    {
      "epoch": 0.5282331511839709,
      "grad_norm": 0.3440033793449402,
      "learning_rate": 1.9295689131754707e-05,
      "loss": 0.2725,
      "step": 4930
    },
    {
      "epoch": 0.5293046180220722,
      "grad_norm": 13.133902549743652,
      "learning_rate": 1.9294260509303906e-05,
      "loss": 0.2629,
      "step": 4940
    },
    {
      "epoch": 0.5303760848601736,
      "grad_norm": 0.08213970065116882,
      "learning_rate": 1.9292831886853102e-05,
      "loss": 0.5643,
      "step": 4950
    },
    {
      "epoch": 0.531447551698275,
      "grad_norm": 0.10699880868196487,
      "learning_rate": 1.92914032644023e-05,
      "loss": 0.444,
      "step": 4960
    },
    {
      "epoch": 0.5325190185363763,
      "grad_norm": 26.937034606933594,
      "learning_rate": 1.9289974641951497e-05,
      "loss": 0.7957,
      "step": 4970
    },
    {
      "epoch": 0.5335904853744776,
      "grad_norm": 0.6319677829742432,
      "learning_rate": 1.9288546019500697e-05,
      "loss": 0.3975,
      "step": 4980
    },
    {
      "epoch": 0.5346619522125791,
      "grad_norm": 6.643929958343506,
      "learning_rate": 1.9287117397049896e-05,
      "loss": 0.1819,
      "step": 4990
    },
    {
      "epoch": 0.5357334190506804,
      "grad_norm": 22.382129669189453,
      "learning_rate": 1.9285688774599095e-05,
      "loss": 0.7473,
      "step": 5000
    },
    {
      "epoch": 0.5368048858887817,
      "grad_norm": 22.338258743286133,
      "learning_rate": 1.928426015214829e-05,
      "loss": 0.4973,
      "step": 5010
    },
    {
      "epoch": 0.5378763527268831,
      "grad_norm": 14.906084060668945,
      "learning_rate": 1.928283152969749e-05,
      "loss": 1.0896,
      "step": 5020
    },
    {
      "epoch": 0.5389478195649845,
      "grad_norm": 1.171199917793274,
      "learning_rate": 1.928140290724669e-05,
      "loss": 0.4437,
      "step": 5030
    },
    {
      "epoch": 0.5400192864030858,
      "grad_norm": 16.464862823486328,
      "learning_rate": 1.927997428479589e-05,
      "loss": 0.6353,
      "step": 5040
    },
    {
      "epoch": 0.5410907532411872,
      "grad_norm": 0.22765280306339264,
      "learning_rate": 1.9278545662345085e-05,
      "loss": 0.3201,
      "step": 5050
    },
    {
      "epoch": 0.5421622200792885,
      "grad_norm": 8.156576156616211,
      "learning_rate": 1.9277117039894285e-05,
      "loss": 0.2871,
      "step": 5060
    },
    {
      "epoch": 0.5432336869173899,
      "grad_norm": 0.16771595180034637,
      "learning_rate": 1.927568841744348e-05,
      "loss": 0.2303,
      "step": 5070
    },
    {
      "epoch": 0.5443051537554913,
      "grad_norm": 18.36815643310547,
      "learning_rate": 1.927425979499268e-05,
      "loss": 0.3656,
      "step": 5080
    },
    {
      "epoch": 0.5453766205935926,
      "grad_norm": 0.11201324313879013,
      "learning_rate": 1.9272831172541876e-05,
      "loss": 0.4144,
      "step": 5090
    },
    {
      "epoch": 0.546448087431694,
      "grad_norm": 21.50041389465332,
      "learning_rate": 1.9271402550091076e-05,
      "loss": 0.2682,
      "step": 5100
    },
    {
      "epoch": 0.5475195542697954,
      "grad_norm": 0.13647060096263885,
      "learning_rate": 1.9269973927640275e-05,
      "loss": 0.2321,
      "step": 5110
    },
    {
      "epoch": 0.5485910211078967,
      "grad_norm": 0.04709360748529434,
      "learning_rate": 1.926854530518947e-05,
      "loss": 0.0037,
      "step": 5120
    },
    {
      "epoch": 0.549662487945998,
      "grad_norm": 0.04653306305408478,
      "learning_rate": 1.926711668273867e-05,
      "loss": 0.2319,
      "step": 5130
    },
    {
      "epoch": 0.5507339547840995,
      "grad_norm": 0.07008090615272522,
      "learning_rate": 1.926568806028787e-05,
      "loss": 0.4261,
      "step": 5140
    },
    {
      "epoch": 0.5518054216222008,
      "grad_norm": 0.09062240272760391,
      "learning_rate": 1.926425943783707e-05,
      "loss": 0.3592,
      "step": 5150
    },
    {
      "epoch": 0.5528768884603021,
      "grad_norm": 19.102846145629883,
      "learning_rate": 1.9262830815386265e-05,
      "loss": 1.4249,
      "step": 5160
    },
    {
      "epoch": 0.5539483552984035,
      "grad_norm": 15.82311725616455,
      "learning_rate": 1.9261402192935464e-05,
      "loss": 0.5344,
      "step": 5170
    },
    {
      "epoch": 0.5550198221365049,
      "grad_norm": 0.7968859076499939,
      "learning_rate": 1.9259973570484664e-05,
      "loss": 0.4374,
      "step": 5180
    },
    {
      "epoch": 0.5560912889746062,
      "grad_norm": 4.222236633300781,
      "learning_rate": 1.925854494803386e-05,
      "loss": 0.6052,
      "step": 5190
    },
    {
      "epoch": 0.5571627558127076,
      "grad_norm": 0.26954421401023865,
      "learning_rate": 1.925711632558306e-05,
      "loss": 0.1315,
      "step": 5200
    },
    {
      "epoch": 0.5582342226508089,
      "grad_norm": 0.17823486030101776,
      "learning_rate": 1.9255687703132255e-05,
      "loss": 0.575,
      "step": 5210
    },
    {
      "epoch": 0.5593056894889104,
      "grad_norm": 18.363405227661133,
      "learning_rate": 1.9254259080681454e-05,
      "loss": 0.5225,
      "step": 5220
    },
    {
      "epoch": 0.5603771563270117,
      "grad_norm": 0.8812670111656189,
      "learning_rate": 1.9252830458230654e-05,
      "loss": 0.1987,
      "step": 5230
    },
    {
      "epoch": 0.561448623165113,
      "grad_norm": 18.766613006591797,
      "learning_rate": 1.925140183577985e-05,
      "loss": 1.09,
      "step": 5240
    },
    {
      "epoch": 0.5625200900032143,
      "grad_norm": 0.319020539522171,
      "learning_rate": 1.924997321332905e-05,
      "loss": 0.2259,
      "step": 5250
    },
    {
      "epoch": 0.5635915568413158,
      "grad_norm": 0.9865022301673889,
      "learning_rate": 1.9248544590878245e-05,
      "loss": 0.2432,
      "step": 5260
    },
    {
      "epoch": 0.5646630236794171,
      "grad_norm": 22.288557052612305,
      "learning_rate": 1.9247115968427444e-05,
      "loss": 0.4151,
      "step": 5270
    },
    {
      "epoch": 0.5657344905175185,
      "grad_norm": 49.833740234375,
      "learning_rate": 1.9245687345976644e-05,
      "loss": 0.5168,
      "step": 5280
    },
    {
      "epoch": 0.5668059573556199,
      "grad_norm": 2.7734837532043457,
      "learning_rate": 1.9244258723525843e-05,
      "loss": 0.2618,
      "step": 5290
    },
    {
      "epoch": 0.5678774241937212,
      "grad_norm": 0.8456477522850037,
      "learning_rate": 1.924283010107504e-05,
      "loss": 0.2165,
      "step": 5300
    },
    {
      "epoch": 0.5689488910318226,
      "grad_norm": 0.10129445791244507,
      "learning_rate": 1.924140147862424e-05,
      "loss": 0.5522,
      "step": 5310
    },
    {
      "epoch": 0.5700203578699239,
      "grad_norm": 19.11380386352539,
      "learning_rate": 1.9239972856173438e-05,
      "loss": 0.774,
      "step": 5320
    },
    {
      "epoch": 0.5710918247080253,
      "grad_norm": 0.16460424661636353,
      "learning_rate": 1.9238544233722634e-05,
      "loss": 0.0657,
      "step": 5330
    },
    {
      "epoch": 0.5721632915461267,
      "grad_norm": 0.3888123035430908,
      "learning_rate": 1.9237115611271833e-05,
      "loss": 0.9491,
      "step": 5340
    },
    {
      "epoch": 0.573234758384228,
      "grad_norm": 0.39646440744400024,
      "learning_rate": 1.9235686988821033e-05,
      "loss": 0.1525,
      "step": 5350
    },
    {
      "epoch": 0.5743062252223293,
      "grad_norm": 0.16492822766304016,
      "learning_rate": 1.923425836637023e-05,
      "loss": 0.8948,
      "step": 5360
    },
    {
      "epoch": 0.5753776920604308,
      "grad_norm": 1.2179441452026367,
      "learning_rate": 1.9232829743919428e-05,
      "loss": 0.3445,
      "step": 5370
    },
    {
      "epoch": 0.5764491588985321,
      "grad_norm": 0.23648670315742493,
      "learning_rate": 1.9231401121468624e-05,
      "loss": 0.4138,
      "step": 5380
    },
    {
      "epoch": 0.5775206257366334,
      "grad_norm": 0.18113625049591064,
      "learning_rate": 1.9229972499017823e-05,
      "loss": 0.3741,
      "step": 5390
    },
    {
      "epoch": 0.5785920925747348,
      "grad_norm": 54.43142318725586,
      "learning_rate": 1.9228543876567023e-05,
      "loss": 0.7344,
      "step": 5400
    },
    {
      "epoch": 0.5796635594128362,
      "grad_norm": 18.883522033691406,
      "learning_rate": 1.922711525411622e-05,
      "loss": 0.8758,
      "step": 5410
    },
    {
      "epoch": 0.5807350262509375,
      "grad_norm": 2.5444390773773193,
      "learning_rate": 1.9225686631665418e-05,
      "loss": 0.3282,
      "step": 5420
    },
    {
      "epoch": 0.5818064930890389,
      "grad_norm": 8.377814292907715,
      "learning_rate": 1.9224258009214617e-05,
      "loss": 0.7426,
      "step": 5430
    },
    {
      "epoch": 0.5828779599271403,
      "grad_norm": 83.80197143554688,
      "learning_rate": 1.9222829386763813e-05,
      "loss": 0.7762,
      "step": 5440
    },
    {
      "epoch": 0.5839494267652416,
      "grad_norm": 120.6237564086914,
      "learning_rate": 1.9221400764313013e-05,
      "loss": 0.355,
      "step": 5450
    },
    {
      "epoch": 0.585020893603343,
      "grad_norm": 105.43434143066406,
      "learning_rate": 1.9219972141862212e-05,
      "loss": 0.3384,
      "step": 5460
    },
    {
      "epoch": 0.5860923604414443,
      "grad_norm": 16.622692108154297,
      "learning_rate": 1.921854351941141e-05,
      "loss": 1.0173,
      "step": 5470
    },
    {
      "epoch": 0.5871638272795457,
      "grad_norm": 0.09558898210525513,
      "learning_rate": 1.9217114896960607e-05,
      "loss": 0.5183,
      "step": 5480
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.35484349727630615,
      "learning_rate": 1.9215686274509807e-05,
      "loss": 0.7621,
      "step": 5490
    },
    {
      "epoch": 0.5893067609557484,
      "grad_norm": 27.702739715576172,
      "learning_rate": 1.9214257652059003e-05,
      "loss": 0.4607,
      "step": 5500
    },
    {
      "epoch": 0.5903782277938497,
      "grad_norm": 0.12429481744766235,
      "learning_rate": 1.9212829029608202e-05,
      "loss": 0.5231,
      "step": 5510
    },
    {
      "epoch": 0.5914496946319512,
      "grad_norm": 34.178218841552734,
      "learning_rate": 1.9211400407157398e-05,
      "loss": 0.4243,
      "step": 5520
    },
    {
      "epoch": 0.5925211614700525,
      "grad_norm": 51.38241958618164,
      "learning_rate": 1.9209971784706597e-05,
      "loss": 0.4818,
      "step": 5530
    },
    {
      "epoch": 0.5935926283081538,
      "grad_norm": 0.06730053573846817,
      "learning_rate": 1.9208543162255797e-05,
      "loss": 0.4668,
      "step": 5540
    },
    {
      "epoch": 0.5946640951462552,
      "grad_norm": 0.10759928077459335,
      "learning_rate": 1.9207114539804993e-05,
      "loss": 0.2018,
      "step": 5550
    },
    {
      "epoch": 0.5957355619843566,
      "grad_norm": 0.1184254065155983,
      "learning_rate": 1.9205685917354192e-05,
      "loss": 0.368,
      "step": 5560
    },
    {
      "epoch": 0.596807028822458,
      "grad_norm": 24.994775772094727,
      "learning_rate": 1.920425729490339e-05,
      "loss": 0.5782,
      "step": 5570
    },
    {
      "epoch": 0.5978784956605593,
      "grad_norm": 1.176647663116455,
      "learning_rate": 1.9202828672452588e-05,
      "loss": 0.382,
      "step": 5580
    },
    {
      "epoch": 0.5989499624986606,
      "grad_norm": 0.3113937973976135,
      "learning_rate": 1.9201400050001787e-05,
      "loss": 0.9173,
      "step": 5590
    },
    {
      "epoch": 0.6000214293367621,
      "grad_norm": 2.944563865661621,
      "learning_rate": 1.9199971427550986e-05,
      "loss": 0.463,
      "step": 5600
    },
    {
      "epoch": 0.6010928961748634,
      "grad_norm": 0.08808433264493942,
      "learning_rate": 1.9198542805100186e-05,
      "loss": 0.2605,
      "step": 5610
    },
    {
      "epoch": 0.6021643630129647,
      "grad_norm": 17.55738067626953,
      "learning_rate": 1.919711418264938e-05,
      "loss": 0.2775,
      "step": 5620
    },
    {
      "epoch": 0.6032358298510662,
      "grad_norm": 0.08337743580341339,
      "learning_rate": 1.919568556019858e-05,
      "loss": 0.721,
      "step": 5630
    },
    {
      "epoch": 0.6043072966891675,
      "grad_norm": 0.4113156497478485,
      "learning_rate": 1.9194256937747777e-05,
      "loss": 0.7634,
      "step": 5640
    },
    {
      "epoch": 0.6053787635272688,
      "grad_norm": 0.8899630904197693,
      "learning_rate": 1.9192828315296976e-05,
      "loss": 0.5118,
      "step": 5650
    },
    {
      "epoch": 0.6064502303653702,
      "grad_norm": 0.4815763235092163,
      "learning_rate": 1.9191399692846176e-05,
      "loss": 0.4373,
      "step": 5660
    },
    {
      "epoch": 0.6075216972034716,
      "grad_norm": 15.0392427444458,
      "learning_rate": 1.918997107039537e-05,
      "loss": 0.4238,
      "step": 5670
    },
    {
      "epoch": 0.6085931640415729,
      "grad_norm": 0.44686359167099,
      "learning_rate": 1.918854244794457e-05,
      "loss": 0.1742,
      "step": 5680
    },
    {
      "epoch": 0.6096646308796743,
      "grad_norm": 0.152750626206398,
      "learning_rate": 1.9187113825493767e-05,
      "loss": 0.3654,
      "step": 5690
    },
    {
      "epoch": 0.6107360977177756,
      "grad_norm": 16.833189010620117,
      "learning_rate": 1.9185685203042966e-05,
      "loss": 0.7005,
      "step": 5700
    },
    {
      "epoch": 0.611807564555877,
      "grad_norm": 0.16939178109169006,
      "learning_rate": 1.9184256580592166e-05,
      "loss": 0.349,
      "step": 5710
    },
    {
      "epoch": 0.6128790313939784,
      "grad_norm": 0.19730161130428314,
      "learning_rate": 1.9182827958141365e-05,
      "loss": 0.6289,
      "step": 5720
    },
    {
      "epoch": 0.6139504982320797,
      "grad_norm": 0.24560442566871643,
      "learning_rate": 1.918139933569056e-05,
      "loss": 0.1818,
      "step": 5730
    },
    {
      "epoch": 0.615021965070181,
      "grad_norm": 0.11768405139446259,
      "learning_rate": 1.917997071323976e-05,
      "loss": 0.201,
      "step": 5740
    },
    {
      "epoch": 0.6160934319082825,
      "grad_norm": 0.11348222941160202,
      "learning_rate": 1.917854209078896e-05,
      "loss": 0.5728,
      "step": 5750
    },
    {
      "epoch": 0.6171648987463838,
      "grad_norm": 0.04846370965242386,
      "learning_rate": 1.9177113468338156e-05,
      "loss": 0.2772,
      "step": 5760
    },
    {
      "epoch": 0.6182363655844851,
      "grad_norm": 0.058037832379341125,
      "learning_rate": 1.9175684845887355e-05,
      "loss": 0.373,
      "step": 5770
    },
    {
      "epoch": 0.6193078324225865,
      "grad_norm": 0.09100610017776489,
      "learning_rate": 1.9174256223436555e-05,
      "loss": 0.8339,
      "step": 5780
    },
    {
      "epoch": 0.6203792992606879,
      "grad_norm": 1.6557265520095825,
      "learning_rate": 1.917282760098575e-05,
      "loss": 0.2512,
      "step": 5790
    },
    {
      "epoch": 0.6214507660987892,
      "grad_norm": 176.55101013183594,
      "learning_rate": 1.917139897853495e-05,
      "loss": 0.3078,
      "step": 5800
    },
    {
      "epoch": 0.6225222329368906,
      "grad_norm": 44.31551742553711,
      "learning_rate": 1.9169970356084146e-05,
      "loss": 0.6519,
      "step": 5810
    },
    {
      "epoch": 0.623593699774992,
      "grad_norm": 16.652040481567383,
      "learning_rate": 1.9168541733633345e-05,
      "loss": 0.3924,
      "step": 5820
    },
    {
      "epoch": 0.6246651666130933,
      "grad_norm": 81.46575927734375,
      "learning_rate": 1.9167113111182545e-05,
      "loss": 1.2486,
      "step": 5830
    },
    {
      "epoch": 0.6257366334511947,
      "grad_norm": 34.772613525390625,
      "learning_rate": 1.916568448873174e-05,
      "loss": 0.5319,
      "step": 5840
    },
    {
      "epoch": 0.626808100289296,
      "grad_norm": 17.6239013671875,
      "learning_rate": 1.916425586628094e-05,
      "loss": 0.9606,
      "step": 5850
    },
    {
      "epoch": 0.6278795671273975,
      "grad_norm": 0.21585378050804138,
      "learning_rate": 1.916282724383014e-05,
      "loss": 0.3302,
      "step": 5860
    },
    {
      "epoch": 0.6289510339654988,
      "grad_norm": 39.045074462890625,
      "learning_rate": 1.9161398621379335e-05,
      "loss": 0.1599,
      "step": 5870
    },
    {
      "epoch": 0.6300225008036001,
      "grad_norm": 0.05109434574842453,
      "learning_rate": 1.9159969998928535e-05,
      "loss": 0.2874,
      "step": 5880
    },
    {
      "epoch": 0.6310939676417014,
      "grad_norm": 0.036017246544361115,
      "learning_rate": 1.9158541376477734e-05,
      "loss": 0.2503,
      "step": 5890
    },
    {
      "epoch": 0.6321654344798029,
      "grad_norm": 0.059117432683706284,
      "learning_rate": 1.9157112754026933e-05,
      "loss": 0.5,
      "step": 5900
    },
    {
      "epoch": 0.6332369013179042,
      "grad_norm": 19.37885093688965,
      "learning_rate": 1.915568413157613e-05,
      "loss": 0.9514,
      "step": 5910
    },
    {
      "epoch": 0.6343083681560056,
      "grad_norm": 0.23020349442958832,
      "learning_rate": 1.915425550912533e-05,
      "loss": 0.4843,
      "step": 5920
    },
    {
      "epoch": 0.6353798349941069,
      "grad_norm": 0.35656216740608215,
      "learning_rate": 1.9152826886674525e-05,
      "loss": 0.1714,
      "step": 5930
    },
    {
      "epoch": 0.6364513018322083,
      "grad_norm": 0.2130318582057953,
      "learning_rate": 1.9151398264223724e-05,
      "loss": 0.4121,
      "step": 5940
    },
    {
      "epoch": 0.6375227686703097,
      "grad_norm": 0.46313750743865967,
      "learning_rate": 1.9149969641772923e-05,
      "loss": 0.2532,
      "step": 5950
    },
    {
      "epoch": 0.638594235508411,
      "grad_norm": 21.612079620361328,
      "learning_rate": 1.914854101932212e-05,
      "loss": 0.5037,
      "step": 5960
    },
    {
      "epoch": 0.6396657023465123,
      "grad_norm": 0.14314430952072144,
      "learning_rate": 1.914711239687132e-05,
      "loss": 0.5212,
      "step": 5970
    },
    {
      "epoch": 0.6407371691846138,
      "grad_norm": 24.088951110839844,
      "learning_rate": 1.9145683774420515e-05,
      "loss": 0.8604,
      "step": 5980
    },
    {
      "epoch": 0.6418086360227151,
      "grad_norm": 25.85137176513672,
      "learning_rate": 1.9144255151969714e-05,
      "loss": 0.6221,
      "step": 5990
    },
    {
      "epoch": 0.6428801028608164,
      "grad_norm": 23.774322509765625,
      "learning_rate": 1.9142826529518913e-05,
      "loss": 0.3974,
      "step": 6000
    },
    {
      "epoch": 0.6439515696989179,
      "grad_norm": 0.11953625828027725,
      "learning_rate": 1.914139790706811e-05,
      "loss": 0.4368,
      "step": 6010
    },
    {
      "epoch": 0.6450230365370192,
      "grad_norm": 0.2210073471069336,
      "learning_rate": 1.913996928461731e-05,
      "loss": 0.7336,
      "step": 6020
    },
    {
      "epoch": 0.6460945033751205,
      "grad_norm": 13.42546272277832,
      "learning_rate": 1.9138540662166508e-05,
      "loss": 1.0562,
      "step": 6030
    },
    {
      "epoch": 0.6471659702132219,
      "grad_norm": 1.0599639415740967,
      "learning_rate": 1.9137112039715708e-05,
      "loss": 0.1086,
      "step": 6040
    },
    {
      "epoch": 0.6482374370513233,
      "grad_norm": 0.11232543736696243,
      "learning_rate": 1.9135683417264904e-05,
      "loss": 0.4744,
      "step": 6050
    },
    {
      "epoch": 0.6493089038894246,
      "grad_norm": 0.13506315648555756,
      "learning_rate": 1.9134254794814103e-05,
      "loss": 0.2874,
      "step": 6060
    },
    {
      "epoch": 0.650380370727526,
      "grad_norm": 20.65107536315918,
      "learning_rate": 1.9132826172363302e-05,
      "loss": 0.4967,
      "step": 6070
    },
    {
      "epoch": 0.6514518375656273,
      "grad_norm": 17.22980499267578,
      "learning_rate": 1.9131397549912498e-05,
      "loss": 0.5857,
      "step": 6080
    },
    {
      "epoch": 0.6525233044037287,
      "grad_norm": 1.2201628684997559,
      "learning_rate": 1.9129968927461698e-05,
      "loss": 0.6198,
      "step": 6090
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.4321063458919525,
      "learning_rate": 1.9128540305010894e-05,
      "loss": 0.3259,
      "step": 6100
    },
    {
      "epoch": 0.6546662380799314,
      "grad_norm": 0.1427217423915863,
      "learning_rate": 1.9127111682560093e-05,
      "loss": 0.6024,
      "step": 6110
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.19565102458000183,
      "learning_rate": 1.912568306010929e-05,
      "loss": 0.2423,
      "step": 6120
    },
    {
      "epoch": 0.6568091717561342,
      "grad_norm": 15.234846115112305,
      "learning_rate": 1.9124254437658488e-05,
      "loss": 0.4648,
      "step": 6130
    },
    {
      "epoch": 0.6578806385942355,
      "grad_norm": 0.08193623274564743,
      "learning_rate": 1.9122825815207688e-05,
      "loss": 0.3877,
      "step": 6140
    },
    {
      "epoch": 0.6589521054323368,
      "grad_norm": 0.1993018388748169,
      "learning_rate": 1.9121397192756887e-05,
      "loss": 0.164,
      "step": 6150
    },
    {
      "epoch": 0.6600235722704382,
      "grad_norm": 0.05826498940587044,
      "learning_rate": 1.9119968570306083e-05,
      "loss": 0.4593,
      "step": 6160
    },
    {
      "epoch": 0.6610950391085396,
      "grad_norm": 18.215959548950195,
      "learning_rate": 1.9118539947855282e-05,
      "loss": 0.8126,
      "step": 6170
    },
    {
      "epoch": 0.662166505946641,
      "grad_norm": 22.957088470458984,
      "learning_rate": 1.9117111325404482e-05,
      "loss": 0.2988,
      "step": 6180
    },
    {
      "epoch": 0.6632379727847423,
      "grad_norm": 0.7272994518280029,
      "learning_rate": 1.911568270295368e-05,
      "loss": 0.5104,
      "step": 6190
    },
    {
      "epoch": 0.6643094396228437,
      "grad_norm": 2.2010059356689453,
      "learning_rate": 1.9114254080502877e-05,
      "loss": 0.2048,
      "step": 6200
    },
    {
      "epoch": 0.665380906460945,
      "grad_norm": 1.0820358991622925,
      "learning_rate": 1.9112825458052076e-05,
      "loss": 0.3902,
      "step": 6210
    },
    {
      "epoch": 0.6664523732990464,
      "grad_norm": 0.03347215801477432,
      "learning_rate": 1.9111396835601272e-05,
      "loss": 0.2525,
      "step": 6220
    },
    {
      "epoch": 0.6675238401371477,
      "grad_norm": 33.176910400390625,
      "learning_rate": 1.9109968213150472e-05,
      "loss": 0.5628,
      "step": 6230
    },
    {
      "epoch": 0.6685953069752492,
      "grad_norm": 0.07555536925792694,
      "learning_rate": 1.9108539590699668e-05,
      "loss": 0.6062,
      "step": 6240
    },
    {
      "epoch": 0.6696667738133505,
      "grad_norm": 12.061347007751465,
      "learning_rate": 1.9107110968248867e-05,
      "loss": 0.851,
      "step": 6250
    },
    {
      "epoch": 0.6707382406514518,
      "grad_norm": 0.10461033880710602,
      "learning_rate": 1.9105682345798067e-05,
      "loss": 0.2526,
      "step": 6260
    },
    {
      "epoch": 0.6718097074895532,
      "grad_norm": 0.485834002494812,
      "learning_rate": 1.9104253723347262e-05,
      "loss": 0.4361,
      "step": 6270
    },
    {
      "epoch": 0.6728811743276546,
      "grad_norm": 0.12066982686519623,
      "learning_rate": 1.9102825100896462e-05,
      "loss": 0.3994,
      "step": 6280
    },
    {
      "epoch": 0.6739526411657559,
      "grad_norm": 77.94515228271484,
      "learning_rate": 1.910139647844566e-05,
      "loss": 0.8172,
      "step": 6290
    },
    {
      "epoch": 0.6750241080038573,
      "grad_norm": 2.0457890033721924,
      "learning_rate": 1.9099967855994857e-05,
      "loss": 0.375,
      "step": 6300
    },
    {
      "epoch": 0.6760955748419586,
      "grad_norm": 9.867443084716797,
      "learning_rate": 1.9098539233544057e-05,
      "loss": 0.3895,
      "step": 6310
    },
    {
      "epoch": 0.67716704168006,
      "grad_norm": 8.960586547851562,
      "learning_rate": 1.9097110611093256e-05,
      "loss": 0.2622,
      "step": 6320
    },
    {
      "epoch": 0.6782385085181614,
      "grad_norm": 0.736099898815155,
      "learning_rate": 1.9095681988642455e-05,
      "loss": 0.2087,
      "step": 6330
    },
    {
      "epoch": 0.6793099753562627,
      "grad_norm": 33.572509765625,
      "learning_rate": 1.909425336619165e-05,
      "loss": 0.7734,
      "step": 6340
    },
    {
      "epoch": 0.6803814421943641,
      "grad_norm": 0.47987642884254456,
      "learning_rate": 1.909282474374085e-05,
      "loss": 0.8165,
      "step": 6350
    },
    {
      "epoch": 0.6814529090324655,
      "grad_norm": 48.871822357177734,
      "learning_rate": 1.9091396121290047e-05,
      "loss": 0.7884,
      "step": 6360
    },
    {
      "epoch": 0.6825243758705668,
      "grad_norm": 0.4425196051597595,
      "learning_rate": 1.9089967498839246e-05,
      "loss": 0.4887,
      "step": 6370
    },
    {
      "epoch": 0.6835958427086681,
      "grad_norm": 30.338830947875977,
      "learning_rate": 1.9088538876388445e-05,
      "loss": 0.5467,
      "step": 6380
    },
    {
      "epoch": 0.6846673095467696,
      "grad_norm": 0.292391300201416,
      "learning_rate": 1.908711025393764e-05,
      "loss": 0.2816,
      "step": 6390
    },
    {
      "epoch": 0.6857387763848709,
      "grad_norm": 32.513607025146484,
      "learning_rate": 1.908568163148684e-05,
      "loss": 0.4657,
      "step": 6400
    },
    {
      "epoch": 0.6868102432229722,
      "grad_norm": 0.2666592299938202,
      "learning_rate": 1.9084253009036037e-05,
      "loss": 0.1631,
      "step": 6410
    },
    {
      "epoch": 0.6878817100610736,
      "grad_norm": 0.10634785145521164,
      "learning_rate": 1.9082824386585236e-05,
      "loss": 0.5991,
      "step": 6420
    },
    {
      "epoch": 0.688953176899175,
      "grad_norm": 18.983957290649414,
      "learning_rate": 1.9081395764134435e-05,
      "loss": 0.592,
      "step": 6430
    },
    {
      "epoch": 0.6900246437372763,
      "grad_norm": 0.20905587077140808,
      "learning_rate": 1.907996714168363e-05,
      "loss": 0.0063,
      "step": 6440
    },
    {
      "epoch": 0.6910961105753777,
      "grad_norm": 0.16221758723258972,
      "learning_rate": 1.907853851923283e-05,
      "loss": 0.3125,
      "step": 6450
    },
    {
      "epoch": 0.692167577413479,
      "grad_norm": 22.365009307861328,
      "learning_rate": 1.907710989678203e-05,
      "loss": 0.5463,
      "step": 6460
    },
    {
      "epoch": 0.6932390442515804,
      "grad_norm": 0.12439184635877609,
      "learning_rate": 1.907568127433123e-05,
      "loss": 0.3647,
      "step": 6470
    },
    {
      "epoch": 0.6943105110896818,
      "grad_norm": 27.38611602783203,
      "learning_rate": 1.9074252651880425e-05,
      "loss": 0.66,
      "step": 6480
    },
    {
      "epoch": 0.6953819779277831,
      "grad_norm": 29.321552276611328,
      "learning_rate": 1.9072824029429625e-05,
      "loss": 0.6325,
      "step": 6490
    },
    {
      "epoch": 0.6964534447658844,
      "grad_norm": 0.0814775601029396,
      "learning_rate": 1.9071395406978824e-05,
      "loss": 0.3571,
      "step": 6500
    },
    {
      "epoch": 0.6975249116039859,
      "grad_norm": 0.07054741680622101,
      "learning_rate": 1.906996678452802e-05,
      "loss": 0.6912,
      "step": 6510
    },
    {
      "epoch": 0.6985963784420872,
      "grad_norm": 0.08732283115386963,
      "learning_rate": 1.906853816207722e-05,
      "loss": 0.6841,
      "step": 6520
    },
    {
      "epoch": 0.6996678452801885,
      "grad_norm": 9.896441459655762,
      "learning_rate": 1.9067109539626416e-05,
      "loss": 0.6535,
      "step": 6530
    },
    {
      "epoch": 0.70073931211829,
      "grad_norm": 20.21240997314453,
      "learning_rate": 1.9065680917175615e-05,
      "loss": 0.3588,
      "step": 6540
    },
    {
      "epoch": 0.7018107789563913,
      "grad_norm": 0.18331973254680634,
      "learning_rate": 1.906425229472481e-05,
      "loss": 0.3498,
      "step": 6550
    },
    {
      "epoch": 0.7028822457944927,
      "grad_norm": 17.31167984008789,
      "learning_rate": 1.906282367227401e-05,
      "loss": 0.823,
      "step": 6560
    },
    {
      "epoch": 0.703953712632594,
      "grad_norm": 4.224114894866943,
      "learning_rate": 1.906139504982321e-05,
      "loss": 0.2051,
      "step": 6570
    },
    {
      "epoch": 0.7050251794706954,
      "grad_norm": 0.335985004901886,
      "learning_rate": 1.9059966427372406e-05,
      "loss": 0.3761,
      "step": 6580
    },
    {
      "epoch": 0.7060966463087968,
      "grad_norm": 0.17661233246326447,
      "learning_rate": 1.9058537804921605e-05,
      "loss": 0.5006,
      "step": 6590
    },
    {
      "epoch": 0.7071681131468981,
      "grad_norm": 25.640132904052734,
      "learning_rate": 1.9057109182470804e-05,
      "loss": 0.6331,
      "step": 6600
    },
    {
      "epoch": 0.7082395799849994,
      "grad_norm": 0.13033272325992584,
      "learning_rate": 1.9055680560020004e-05,
      "loss": 0.1001,
      "step": 6610
    },
    {
      "epoch": 0.7093110468231009,
      "grad_norm": 112.485595703125,
      "learning_rate": 1.9054251937569203e-05,
      "loss": 0.3426,
      "step": 6620
    },
    {
      "epoch": 0.7103825136612022,
      "grad_norm": 18.150291442871094,
      "learning_rate": 1.90528233151184e-05,
      "loss": 0.4407,
      "step": 6630
    },
    {
      "epoch": 0.7114539804993035,
      "grad_norm": 0.11648765206336975,
      "learning_rate": 1.90513946926676e-05,
      "loss": 0.5467,
      "step": 6640
    },
    {
      "epoch": 0.7125254473374049,
      "grad_norm": 0.578126847743988,
      "learning_rate": 1.9049966070216794e-05,
      "loss": 0.2253,
      "step": 6650
    },
    {
      "epoch": 0.7135969141755063,
      "grad_norm": 19.520057678222656,
      "learning_rate": 1.9048537447765994e-05,
      "loss": 0.6602,
      "step": 6660
    },
    {
      "epoch": 0.7146683810136076,
      "grad_norm": 27.22461700439453,
      "learning_rate": 1.904710882531519e-05,
      "loss": 0.4458,
      "step": 6670
    },
    {
      "epoch": 0.715739847851709,
      "grad_norm": 23.904651641845703,
      "learning_rate": 1.904568020286439e-05,
      "loss": 0.5294,
      "step": 6680
    },
    {
      "epoch": 0.7168113146898103,
      "grad_norm": 0.19137349724769592,
      "learning_rate": 1.904425158041359e-05,
      "loss": 0.2374,
      "step": 6690
    },
    {
      "epoch": 0.7178827815279117,
      "grad_norm": 16.81062126159668,
      "learning_rate": 1.9042822957962784e-05,
      "loss": 0.8453,
      "step": 6700
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 37.626399993896484,
      "learning_rate": 1.9041394335511984e-05,
      "loss": 0.3688,
      "step": 6710
    },
    {
      "epoch": 0.7200257152041144,
      "grad_norm": 23.3870906829834,
      "learning_rate": 1.9039965713061183e-05,
      "loss": 0.668,
      "step": 6720
    },
    {
      "epoch": 0.7210971820422158,
      "grad_norm": 0.22392186522483826,
      "learning_rate": 1.903853709061038e-05,
      "loss": 0.3934,
      "step": 6730
    },
    {
      "epoch": 0.7221686488803172,
      "grad_norm": 1.9968314170837402,
      "learning_rate": 1.903710846815958e-05,
      "loss": 0.6204,
      "step": 6740
    },
    {
      "epoch": 0.7232401157184185,
      "grad_norm": 89.66959381103516,
      "learning_rate": 1.9035679845708778e-05,
      "loss": 0.1751,
      "step": 6750
    },
    {
      "epoch": 0.7243115825565198,
      "grad_norm": 19.476207733154297,
      "learning_rate": 1.9034251223257977e-05,
      "loss": 0.8197,
      "step": 6760
    },
    {
      "epoch": 0.7253830493946213,
      "grad_norm": 0.19042445719242096,
      "learning_rate": 1.9032822600807173e-05,
      "loss": 0.2452,
      "step": 6770
    },
    {
      "epoch": 0.7264545162327226,
      "grad_norm": 19.73982048034668,
      "learning_rate": 1.9031393978356373e-05,
      "loss": 0.7337,
      "step": 6780
    },
    {
      "epoch": 0.727525983070824,
      "grad_norm": 26.822385787963867,
      "learning_rate": 1.902996535590557e-05,
      "loss": 0.6219,
      "step": 6790
    },
    {
      "epoch": 0.7285974499089253,
      "grad_norm": 12.80777359008789,
      "learning_rate": 1.9028536733454768e-05,
      "loss": 0.5789,
      "step": 6800
    },
    {
      "epoch": 0.7296689167470267,
      "grad_norm": 14.093879699707031,
      "learning_rate": 1.9027108111003967e-05,
      "loss": 0.495,
      "step": 6810
    },
    {
      "epoch": 0.730740383585128,
      "grad_norm": 18.809486389160156,
      "learning_rate": 1.9025679488553163e-05,
      "loss": 0.478,
      "step": 6820
    },
    {
      "epoch": 0.7318118504232294,
      "grad_norm": 14.986715316772461,
      "learning_rate": 1.9024250866102363e-05,
      "loss": 0.3755,
      "step": 6830
    },
    {
      "epoch": 0.7328833172613307,
      "grad_norm": 2.17982816696167,
      "learning_rate": 1.902282224365156e-05,
      "loss": 0.4488,
      "step": 6840
    },
    {
      "epoch": 0.7339547840994322,
      "grad_norm": 32.58412170410156,
      "learning_rate": 1.9021393621200758e-05,
      "loss": 0.7064,
      "step": 6850
    },
    {
      "epoch": 0.7350262509375335,
      "grad_norm": 24.33527374267578,
      "learning_rate": 1.9019964998749957e-05,
      "loss": 0.4448,
      "step": 6860
    },
    {
      "epoch": 0.7360977177756348,
      "grad_norm": 18.115453720092773,
      "learning_rate": 1.9018536376299153e-05,
      "loss": 0.3643,
      "step": 6870
    },
    {
      "epoch": 0.7371691846137362,
      "grad_norm": 0.1265929937362671,
      "learning_rate": 1.9017107753848353e-05,
      "loss": 0.1501,
      "step": 6880
    },
    {
      "epoch": 0.7382406514518376,
      "grad_norm": 0.13182124495506287,
      "learning_rate": 1.9015679131397552e-05,
      "loss": 0.4649,
      "step": 6890
    },
    {
      "epoch": 0.7393121182899389,
      "grad_norm": 0.1521490514278412,
      "learning_rate": 1.901425050894675e-05,
      "loss": 0.2217,
      "step": 6900
    },
    {
      "epoch": 0.7403835851280403,
      "grad_norm": 20.955259323120117,
      "learning_rate": 1.9012821886495947e-05,
      "loss": 0.5037,
      "step": 6910
    },
    {
      "epoch": 0.7414550519661417,
      "grad_norm": 25.469144821166992,
      "learning_rate": 1.9011393264045147e-05,
      "loss": 0.392,
      "step": 6920
    },
    {
      "epoch": 0.742526518804243,
      "grad_norm": 0.027541328221559525,
      "learning_rate": 1.9009964641594346e-05,
      "loss": 0.0151,
      "step": 6930
    },
    {
      "epoch": 0.7435979856423444,
      "grad_norm": 18.119524002075195,
      "learning_rate": 1.9008536019143542e-05,
      "loss": 0.9813,
      "step": 6940
    },
    {
      "epoch": 0.7446694524804457,
      "grad_norm": 18.9094295501709,
      "learning_rate": 1.900710739669274e-05,
      "loss": 0.7061,
      "step": 6950
    },
    {
      "epoch": 0.7457409193185471,
      "grad_norm": 0.09082720428705215,
      "learning_rate": 1.9005678774241937e-05,
      "loss": 0.1226,
      "step": 6960
    },
    {
      "epoch": 0.7468123861566485,
      "grad_norm": 23.998422622680664,
      "learning_rate": 1.9004250151791137e-05,
      "loss": 0.5032,
      "step": 6970
    },
    {
      "epoch": 0.7478838529947498,
      "grad_norm": 0.11765861511230469,
      "learning_rate": 1.9002821529340336e-05,
      "loss": 0.48,
      "step": 6980
    },
    {
      "epoch": 0.7489553198328511,
      "grad_norm": 0.20034927129745483,
      "learning_rate": 1.9001392906889532e-05,
      "loss": 0.2532,
      "step": 6990
    },
    {
      "epoch": 0.7500267866709526,
      "grad_norm": 33.427677154541016,
      "learning_rate": 1.899996428443873e-05,
      "loss": 0.5174,
      "step": 7000
    },
    {
      "epoch": 0.7510982535090539,
      "grad_norm": 29.82340431213379,
      "learning_rate": 1.8998535661987928e-05,
      "loss": 0.4441,
      "step": 7010
    },
    {
      "epoch": 0.7521697203471552,
      "grad_norm": 0.12525589764118195,
      "learning_rate": 1.8997107039537127e-05,
      "loss": 0.4616,
      "step": 7020
    },
    {
      "epoch": 0.7532411871852566,
      "grad_norm": 18.92867088317871,
      "learning_rate": 1.8995678417086326e-05,
      "loss": 0.3625,
      "step": 7030
    },
    {
      "epoch": 0.754312654023358,
      "grad_norm": 0.0626186728477478,
      "learning_rate": 1.8994249794635526e-05,
      "loss": 0.1255,
      "step": 7040
    },
    {
      "epoch": 0.7553841208614593,
      "grad_norm": 98.02284240722656,
      "learning_rate": 1.8992821172184725e-05,
      "loss": 0.6588,
      "step": 7050
    },
    {
      "epoch": 0.7564555876995607,
      "grad_norm": 0.5529881119728088,
      "learning_rate": 1.899139254973392e-05,
      "loss": 0.494,
      "step": 7060
    },
    {
      "epoch": 0.7575270545376621,
      "grad_norm": 61.06523132324219,
      "learning_rate": 1.898996392728312e-05,
      "loss": 0.1058,
      "step": 7070
    },
    {
      "epoch": 0.7585985213757634,
      "grad_norm": 37.15898513793945,
      "learning_rate": 1.8988535304832316e-05,
      "loss": 0.8517,
      "step": 7080
    },
    {
      "epoch": 0.7596699882138648,
      "grad_norm": 0.08226504176855087,
      "learning_rate": 1.8987106682381516e-05,
      "loss": 0.0032,
      "step": 7090
    },
    {
      "epoch": 0.7607414550519661,
      "grad_norm": 0.18116819858551025,
      "learning_rate": 1.8985678059930715e-05,
      "loss": 0.3227,
      "step": 7100
    },
    {
      "epoch": 0.7618129218900676,
      "grad_norm": 0.04507257416844368,
      "learning_rate": 1.898424943747991e-05,
      "loss": 0.1657,
      "step": 7110
    },
    {
      "epoch": 0.7628843887281689,
      "grad_norm": 20.255285263061523,
      "learning_rate": 1.898282081502911e-05,
      "loss": 0.9849,
      "step": 7120
    },
    {
      "epoch": 0.7639558555662702,
      "grad_norm": 0.18689562380313873,
      "learning_rate": 1.8981392192578306e-05,
      "loss": 0.3355,
      "step": 7130
    },
    {
      "epoch": 0.7650273224043715,
      "grad_norm": 0.1406257301568985,
      "learning_rate": 1.8979963570127506e-05,
      "loss": 0.0034,
      "step": 7140
    },
    {
      "epoch": 0.766098789242473,
      "grad_norm": 1.4546524286270142,
      "learning_rate": 1.8978534947676702e-05,
      "loss": 0.4885,
      "step": 7150
    },
    {
      "epoch": 0.7671702560805743,
      "grad_norm": 17.325258255004883,
      "learning_rate": 1.89771063252259e-05,
      "loss": 0.5399,
      "step": 7160
    },
    {
      "epoch": 0.7682417229186757,
      "grad_norm": 0.34426796436309814,
      "learning_rate": 1.89756777027751e-05,
      "loss": 0.231,
      "step": 7170
    },
    {
      "epoch": 0.769313189756777,
      "grad_norm": 1.1105170249938965,
      "learning_rate": 1.89742490803243e-05,
      "loss": 0.5852,
      "step": 7180
    },
    {
      "epoch": 0.7703846565948784,
      "grad_norm": 0.20432895421981812,
      "learning_rate": 1.89728204578735e-05,
      "loss": 0.4376,
      "step": 7190
    },
    {
      "epoch": 0.7714561234329798,
      "grad_norm": 67.58026123046875,
      "learning_rate": 1.8971391835422695e-05,
      "loss": 0.6615,
      "step": 7200
    },
    {
      "epoch": 0.7725275902710811,
      "grad_norm": 0.07635604590177536,
      "learning_rate": 1.8969963212971895e-05,
      "loss": 0.4946,
      "step": 7210
    },
    {
      "epoch": 0.7735990571091824,
      "grad_norm": 17.274234771728516,
      "learning_rate": 1.8968534590521094e-05,
      "loss": 0.5939,
      "step": 7220
    },
    {
      "epoch": 0.7746705239472839,
      "grad_norm": 5.441473960876465,
      "learning_rate": 1.896710596807029e-05,
      "loss": 0.3298,
      "step": 7230
    },
    {
      "epoch": 0.7757419907853852,
      "grad_norm": 1.3203119039535522,
      "learning_rate": 1.896567734561949e-05,
      "loss": 0.302,
      "step": 7240
    },
    {
      "epoch": 0.7768134576234865,
      "grad_norm": 0.14265857636928558,
      "learning_rate": 1.8964248723168685e-05,
      "loss": 0.4814,
      "step": 7250
    },
    {
      "epoch": 0.777884924461588,
      "grad_norm": 0.5243626236915588,
      "learning_rate": 1.8962820100717885e-05,
      "loss": 0.416,
      "step": 7260
    },
    {
      "epoch": 0.7789563912996893,
      "grad_norm": 0.11329061537981033,
      "learning_rate": 1.896139147826708e-05,
      "loss": 0.2687,
      "step": 7270
    },
    {
      "epoch": 0.7800278581377906,
      "grad_norm": 1.4901255369186401,
      "learning_rate": 1.895996285581628e-05,
      "loss": 0.678,
      "step": 7280
    },
    {
      "epoch": 0.781099324975892,
      "grad_norm": 0.30861756205558777,
      "learning_rate": 1.895853423336548e-05,
      "loss": 0.1856,
      "step": 7290
    },
    {
      "epoch": 0.7821707918139934,
      "grad_norm": 0.08229925483465195,
      "learning_rate": 1.8957105610914675e-05,
      "loss": 0.2949,
      "step": 7300
    },
    {
      "epoch": 0.7832422586520947,
      "grad_norm": 0.1447724848985672,
      "learning_rate": 1.8955676988463875e-05,
      "loss": 0.2322,
      "step": 7310
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.12483232468366623,
      "learning_rate": 1.8954248366013074e-05,
      "loss": 1.0589,
      "step": 7320
    },
    {
      "epoch": 0.7853851923282974,
      "grad_norm": 28.158811569213867,
      "learning_rate": 1.8952819743562273e-05,
      "loss": 0.4854,
      "step": 7330
    },
    {
      "epoch": 0.7864566591663988,
      "grad_norm": 33.46550369262695,
      "learning_rate": 1.895139112111147e-05,
      "loss": 0.4206,
      "step": 7340
    },
    {
      "epoch": 0.7875281260045002,
      "grad_norm": 0.2287871390581131,
      "learning_rate": 1.894996249866067e-05,
      "loss": 0.7406,
      "step": 7350
    },
    {
      "epoch": 0.7885995928426015,
      "grad_norm": 0.1444140076637268,
      "learning_rate": 1.8948533876209868e-05,
      "loss": 0.0283,
      "step": 7360
    },
    {
      "epoch": 0.7896710596807028,
      "grad_norm": 85.5313491821289,
      "learning_rate": 1.8947105253759064e-05,
      "loss": 0.7699,
      "step": 7370
    },
    {
      "epoch": 0.7907425265188043,
      "grad_norm": 6.07623815536499,
      "learning_rate": 1.8945676631308263e-05,
      "loss": 0.5378,
      "step": 7380
    },
    {
      "epoch": 0.7918139933569056,
      "grad_norm": 80.78437805175781,
      "learning_rate": 1.894424800885746e-05,
      "loss": 0.7234,
      "step": 7390
    },
    {
      "epoch": 0.7928854601950069,
      "grad_norm": 0.37616392970085144,
      "learning_rate": 1.894281938640666e-05,
      "loss": 0.3165,
      "step": 7400
    },
    {
      "epoch": 0.7939569270331083,
      "grad_norm": 10.648388862609863,
      "learning_rate": 1.8941390763955858e-05,
      "loss": 0.3655,
      "step": 7410
    },
    {
      "epoch": 0.7950283938712097,
      "grad_norm": 4.159889221191406,
      "learning_rate": 1.8939962141505054e-05,
      "loss": 0.2279,
      "step": 7420
    },
    {
      "epoch": 0.796099860709311,
      "grad_norm": 23.49431610107422,
      "learning_rate": 1.8938533519054253e-05,
      "loss": 0.4136,
      "step": 7430
    },
    {
      "epoch": 0.7971713275474124,
      "grad_norm": 0.08584219217300415,
      "learning_rate": 1.893710489660345e-05,
      "loss": 0.3866,
      "step": 7440
    },
    {
      "epoch": 0.7982427943855138,
      "grad_norm": 0.06523694097995758,
      "learning_rate": 1.893567627415265e-05,
      "loss": 0.4908,
      "step": 7450
    },
    {
      "epoch": 0.7993142612236152,
      "grad_norm": 0.3661055266857147,
      "learning_rate": 1.8934247651701848e-05,
      "loss": 0.4878,
      "step": 7460
    },
    {
      "epoch": 0.8003857280617165,
      "grad_norm": 0.09575537592172623,
      "learning_rate": 1.8932819029251048e-05,
      "loss": 0.2446,
      "step": 7470
    },
    {
      "epoch": 0.8014571948998178,
      "grad_norm": 0.30241093039512634,
      "learning_rate": 1.8931390406800244e-05,
      "loss": 0.4259,
      "step": 7480
    },
    {
      "epoch": 0.8025286617379193,
      "grad_norm": 0.1591089516878128,
      "learning_rate": 1.8929961784349443e-05,
      "loss": 0.9625,
      "step": 7490
    },
    {
      "epoch": 0.8036001285760206,
      "grad_norm": 3.822458028793335,
      "learning_rate": 1.8928533161898642e-05,
      "loss": 0.1948,
      "step": 7500
    },
    {
      "epoch": 0.8046715954141219,
      "grad_norm": 0.15443599224090576,
      "learning_rate": 1.8927104539447838e-05,
      "loss": 0.2068,
      "step": 7510
    },
    {
      "epoch": 0.8057430622522233,
      "grad_norm": 0.7461023926734924,
      "learning_rate": 1.8925675916997038e-05,
      "loss": 0.2389,
      "step": 7520
    },
    {
      "epoch": 0.8068145290903247,
      "grad_norm": 0.08515884727239609,
      "learning_rate": 1.8924247294546237e-05,
      "loss": 0.1352,
      "step": 7530
    },
    {
      "epoch": 0.807885995928426,
      "grad_norm": 71.8966064453125,
      "learning_rate": 1.8922818672095433e-05,
      "loss": 1.1045,
      "step": 7540
    },
    {
      "epoch": 0.8089574627665274,
      "grad_norm": 181.60301208496094,
      "learning_rate": 1.8921390049644632e-05,
      "loss": 0.7358,
      "step": 7550
    },
    {
      "epoch": 0.8100289296046287,
      "grad_norm": 0.2154415249824524,
      "learning_rate": 1.8919961427193828e-05,
      "loss": 0.2342,
      "step": 7560
    },
    {
      "epoch": 0.8111003964427301,
      "grad_norm": 0.09778188914060593,
      "learning_rate": 1.8918532804743028e-05,
      "loss": 0.1802,
      "step": 7570
    },
    {
      "epoch": 0.8121718632808315,
      "grad_norm": 0.16476957499980927,
      "learning_rate": 1.8917104182292224e-05,
      "loss": 0.3693,
      "step": 7580
    },
    {
      "epoch": 0.8132433301189328,
      "grad_norm": 0.08382014185190201,
      "learning_rate": 1.8915675559841423e-05,
      "loss": 0.6248,
      "step": 7590
    },
    {
      "epoch": 0.8143147969570341,
      "grad_norm": 0.4154353737831116,
      "learning_rate": 1.8914246937390622e-05,
      "loss": 0.3032,
      "step": 7600
    },
    {
      "epoch": 0.8153862637951356,
      "grad_norm": 45.62745666503906,
      "learning_rate": 1.8912818314939822e-05,
      "loss": 0.3298,
      "step": 7610
    },
    {
      "epoch": 0.8164577306332369,
      "grad_norm": 298.0459289550781,
      "learning_rate": 1.891138969248902e-05,
      "loss": 0.3886,
      "step": 7620
    },
    {
      "epoch": 0.8175291974713382,
      "grad_norm": 0.06428234279155731,
      "learning_rate": 1.8909961070038217e-05,
      "loss": 0.9628,
      "step": 7630
    },
    {
      "epoch": 0.8186006643094397,
      "grad_norm": 0.06821995973587036,
      "learning_rate": 1.8908532447587416e-05,
      "loss": 0.7024,
      "step": 7640
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.1321813017129898,
      "learning_rate": 1.8907103825136616e-05,
      "loss": 0.184,
      "step": 7650
    },
    {
      "epoch": 0.8207435979856423,
      "grad_norm": 18.15520477294922,
      "learning_rate": 1.8905675202685812e-05,
      "loss": 0.414,
      "step": 7660
    },
    {
      "epoch": 0.8218150648237437,
      "grad_norm": 0.16460955142974854,
      "learning_rate": 1.890424658023501e-05,
      "loss": 0.4258,
      "step": 7670
    },
    {
      "epoch": 0.8228865316618451,
      "grad_norm": 0.1344892829656601,
      "learning_rate": 1.8902817957784207e-05,
      "loss": 0.2623,
      "step": 7680
    },
    {
      "epoch": 0.8239579984999464,
      "grad_norm": 0.16309703886508942,
      "learning_rate": 1.8901389335333407e-05,
      "loss": 0.0059,
      "step": 7690
    },
    {
      "epoch": 0.8250294653380478,
      "grad_norm": 0.10416644811630249,
      "learning_rate": 1.8899960712882602e-05,
      "loss": 0.1733,
      "step": 7700
    },
    {
      "epoch": 0.8261009321761491,
      "grad_norm": 0.11437855660915375,
      "learning_rate": 1.8898532090431802e-05,
      "loss": 0.4204,
      "step": 7710
    },
    {
      "epoch": 0.8271723990142505,
      "grad_norm": 58.75286865234375,
      "learning_rate": 1.8897103467981e-05,
      "loss": 0.1262,
      "step": 7720
    },
    {
      "epoch": 0.8282438658523519,
      "grad_norm": 16.645185470581055,
      "learning_rate": 1.8895674845530197e-05,
      "loss": 0.7523,
      "step": 7730
    },
    {
      "epoch": 0.8293153326904532,
      "grad_norm": 232.4674530029297,
      "learning_rate": 1.8894246223079397e-05,
      "loss": 0.8122,
      "step": 7740
    },
    {
      "epoch": 0.8303867995285545,
      "grad_norm": 0.4609455168247223,
      "learning_rate": 1.8892817600628596e-05,
      "loss": 0.5782,
      "step": 7750
    },
    {
      "epoch": 0.831458266366656,
      "grad_norm": 17.34039878845215,
      "learning_rate": 1.8891388978177795e-05,
      "loss": 0.7989,
      "step": 7760
    },
    {
      "epoch": 0.8325297332047573,
      "grad_norm": 16.345577239990234,
      "learning_rate": 1.888996035572699e-05,
      "loss": 0.5053,
      "step": 7770
    },
    {
      "epoch": 0.8336012000428586,
      "grad_norm": 0.09092889726161957,
      "learning_rate": 1.888853173327619e-05,
      "loss": 0.1245,
      "step": 7780
    },
    {
      "epoch": 0.83467266688096,
      "grad_norm": 1.2340754270553589,
      "learning_rate": 1.888710311082539e-05,
      "loss": 0.3094,
      "step": 7790
    },
    {
      "epoch": 0.8357441337190614,
      "grad_norm": 0.13425102829933167,
      "learning_rate": 1.8885674488374586e-05,
      "loss": 0.9794,
      "step": 7800
    },
    {
      "epoch": 0.8368156005571628,
      "grad_norm": 0.0862068384885788,
      "learning_rate": 1.8884245865923785e-05,
      "loss": 0.3261,
      "step": 7810
    },
    {
      "epoch": 0.8378870673952641,
      "grad_norm": 0.20449429750442505,
      "learning_rate": 1.888281724347298e-05,
      "loss": 0.85,
      "step": 7820
    },
    {
      "epoch": 0.8389585342333655,
      "grad_norm": 18.45540428161621,
      "learning_rate": 1.888138862102218e-05,
      "loss": 0.2522,
      "step": 7830
    },
    {
      "epoch": 0.8400300010714669,
      "grad_norm": 0.13421514630317688,
      "learning_rate": 1.887995999857138e-05,
      "loss": 0.1558,
      "step": 7840
    },
    {
      "epoch": 0.8411014679095682,
      "grad_norm": 0.07597806304693222,
      "learning_rate": 1.8878531376120576e-05,
      "loss": 0.3792,
      "step": 7850
    },
    {
      "epoch": 0.8421729347476695,
      "grad_norm": 93.98385620117188,
      "learning_rate": 1.8877102753669775e-05,
      "loss": 0.4001,
      "step": 7860
    },
    {
      "epoch": 0.843244401585771,
      "grad_norm": 0.19458220899105072,
      "learning_rate": 1.887567413121897e-05,
      "loss": 0.396,
      "step": 7870
    },
    {
      "epoch": 0.8443158684238723,
      "grad_norm": 0.11143065989017487,
      "learning_rate": 1.887424550876817e-05,
      "loss": 0.3191,
      "step": 7880
    },
    {
      "epoch": 0.8453873352619736,
      "grad_norm": 0.8172797560691833,
      "learning_rate": 1.887281688631737e-05,
      "loss": 0.5666,
      "step": 7890
    },
    {
      "epoch": 0.846458802100075,
      "grad_norm": 0.17483937740325928,
      "learning_rate": 1.887138826386657e-05,
      "loss": 0.4418,
      "step": 7900
    },
    {
      "epoch": 0.8475302689381764,
      "grad_norm": 0.26647621393203735,
      "learning_rate": 1.8869959641415765e-05,
      "loss": 0.8257,
      "step": 7910
    },
    {
      "epoch": 0.8486017357762777,
      "grad_norm": 0.18747325241565704,
      "learning_rate": 1.8868531018964965e-05,
      "loss": 0.2039,
      "step": 7920
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 16.669889450073242,
      "learning_rate": 1.8867102396514164e-05,
      "loss": 0.5273,
      "step": 7930
    },
    {
      "epoch": 0.8507446694524804,
      "grad_norm": 0.09666428714990616,
      "learning_rate": 1.886567377406336e-05,
      "loss": 0.6649,
      "step": 7940
    },
    {
      "epoch": 0.8518161362905818,
      "grad_norm": 0.2880631387233734,
      "learning_rate": 1.886424515161256e-05,
      "loss": 0.9246,
      "step": 7950
    },
    {
      "epoch": 0.8528876031286832,
      "grad_norm": 0.20951895415782928,
      "learning_rate": 1.886281652916176e-05,
      "loss": 0.0047,
      "step": 7960
    },
    {
      "epoch": 0.8539590699667845,
      "grad_norm": 22.173839569091797,
      "learning_rate": 1.8861387906710955e-05,
      "loss": 0.9352,
      "step": 7970
    },
    {
      "epoch": 0.8550305368048859,
      "grad_norm": 0.4427455961704254,
      "learning_rate": 1.8859959284260154e-05,
      "loss": 0.5362,
      "step": 7980
    },
    {
      "epoch": 0.8561020036429873,
      "grad_norm": 99.0626449584961,
      "learning_rate": 1.885853066180935e-05,
      "loss": 0.4057,
      "step": 7990
    },
    {
      "epoch": 0.8571734704810886,
      "grad_norm": 0.1270601749420166,
      "learning_rate": 1.885710203935855e-05,
      "loss": 0.4034,
      "step": 8000
    },
    {
      "epoch": 0.8582449373191899,
      "grad_norm": 23.310850143432617,
      "learning_rate": 1.885567341690775e-05,
      "loss": 0.8517,
      "step": 8010
    },
    {
      "epoch": 0.8593164041572914,
      "grad_norm": 0.06798390299081802,
      "learning_rate": 1.8854244794456945e-05,
      "loss": 0.5188,
      "step": 8020
    },
    {
      "epoch": 0.8603878709953927,
      "grad_norm": 22.005176544189453,
      "learning_rate": 1.8852816172006144e-05,
      "loss": 0.3882,
      "step": 8030
    },
    {
      "epoch": 0.861459337833494,
      "grad_norm": 0.11073913425207138,
      "learning_rate": 1.8851387549555344e-05,
      "loss": 0.0035,
      "step": 8040
    },
    {
      "epoch": 0.8625308046715954,
      "grad_norm": 0.027544789016246796,
      "learning_rate": 1.884995892710454e-05,
      "loss": 0.4349,
      "step": 8050
    },
    {
      "epoch": 0.8636022715096968,
      "grad_norm": 0.043231282383203506,
      "learning_rate": 1.884853030465374e-05,
      "loss": 1.0085,
      "step": 8060
    },
    {
      "epoch": 0.8646737383477981,
      "grad_norm": 21.67505645751953,
      "learning_rate": 1.884710168220294e-05,
      "loss": 0.8966,
      "step": 8070
    },
    {
      "epoch": 0.8657452051858995,
      "grad_norm": 0.26776546239852905,
      "learning_rate": 1.8845673059752138e-05,
      "loss": 0.6427,
      "step": 8080
    },
    {
      "epoch": 0.8668166720240008,
      "grad_norm": 1.2235106229782104,
      "learning_rate": 1.8844244437301334e-05,
      "loss": 0.7984,
      "step": 8090
    },
    {
      "epoch": 0.8678881388621023,
      "grad_norm": 22.770992279052734,
      "learning_rate": 1.8842815814850533e-05,
      "loss": 0.212,
      "step": 8100
    },
    {
      "epoch": 0.8689596057002036,
      "grad_norm": 3.7118568420410156,
      "learning_rate": 1.884138719239973e-05,
      "loss": 0.3947,
      "step": 8110
    },
    {
      "epoch": 0.8700310725383049,
      "grad_norm": 37.63075637817383,
      "learning_rate": 1.883995856994893e-05,
      "loss": 0.0258,
      "step": 8120
    },
    {
      "epoch": 0.8711025393764062,
      "grad_norm": 1.5888608694076538,
      "learning_rate": 1.8838529947498128e-05,
      "loss": 0.1302,
      "step": 8130
    },
    {
      "epoch": 0.8721740062145077,
      "grad_norm": 0.4060712456703186,
      "learning_rate": 1.8837101325047324e-05,
      "loss": 0.3425,
      "step": 8140
    },
    {
      "epoch": 0.873245473052609,
      "grad_norm": 0.09515079110860825,
      "learning_rate": 1.8835672702596523e-05,
      "loss": 0.3898,
      "step": 8150
    },
    {
      "epoch": 0.8743169398907104,
      "grad_norm": 118.11876678466797,
      "learning_rate": 1.883424408014572e-05,
      "loss": 1.0397,
      "step": 8160
    },
    {
      "epoch": 0.8753884067288118,
      "grad_norm": 25.220354080200195,
      "learning_rate": 1.883281545769492e-05,
      "loss": 0.703,
      "step": 8170
    },
    {
      "epoch": 0.8764598735669131,
      "grad_norm": 17.66031265258789,
      "learning_rate": 1.8831386835244118e-05,
      "loss": 0.8781,
      "step": 8180
    },
    {
      "epoch": 0.8775313404050145,
      "grad_norm": 0.2610362768173218,
      "learning_rate": 1.8829958212793317e-05,
      "loss": 0.3031,
      "step": 8190
    },
    {
      "epoch": 0.8786028072431158,
      "grad_norm": 0.07799383997917175,
      "learning_rate": 1.8828529590342513e-05,
      "loss": 0.0028,
      "step": 8200
    },
    {
      "epoch": 0.8796742740812172,
      "grad_norm": 0.9013556241989136,
      "learning_rate": 1.8827100967891713e-05,
      "loss": 0.4273,
      "step": 8210
    },
    {
      "epoch": 0.8807457409193186,
      "grad_norm": 0.1052149161696434,
      "learning_rate": 1.8825672345440912e-05,
      "loss": 0.0527,
      "step": 8220
    },
    {
      "epoch": 0.8818172077574199,
      "grad_norm": 1.0479726791381836,
      "learning_rate": 1.8824243722990108e-05,
      "loss": 0.9953,
      "step": 8230
    },
    {
      "epoch": 0.8828886745955212,
      "grad_norm": 68.48799133300781,
      "learning_rate": 1.8822815100539307e-05,
      "loss": 0.4337,
      "step": 8240
    },
    {
      "epoch": 0.8839601414336227,
      "grad_norm": 0.47557333111763,
      "learning_rate": 1.8821386478088503e-05,
      "loss": 0.4719,
      "step": 8250
    },
    {
      "epoch": 0.885031608271724,
      "grad_norm": 0.36746126413345337,
      "learning_rate": 1.8819957855637703e-05,
      "loss": 0.9974,
      "step": 8260
    },
    {
      "epoch": 0.8861030751098253,
      "grad_norm": 0.31408798694610596,
      "learning_rate": 1.8818529233186902e-05,
      "loss": 0.422,
      "step": 8270
    },
    {
      "epoch": 0.8871745419479267,
      "grad_norm": 0.1538303941488266,
      "learning_rate": 1.8817100610736098e-05,
      "loss": 0.2073,
      "step": 8280
    },
    {
      "epoch": 0.8882460087860281,
      "grad_norm": 17.473054885864258,
      "learning_rate": 1.8815671988285297e-05,
      "loss": 0.3442,
      "step": 8290
    },
    {
      "epoch": 0.8893174756241294,
      "grad_norm": 0.1020231544971466,
      "learning_rate": 1.8814243365834493e-05,
      "loss": 0.0043,
      "step": 8300
    },
    {
      "epoch": 0.8903889424622308,
      "grad_norm": 0.0777246505022049,
      "learning_rate": 1.8812814743383693e-05,
      "loss": 0.3846,
      "step": 8310
    },
    {
      "epoch": 0.8914604093003321,
      "grad_norm": 0.053666576743125916,
      "learning_rate": 1.8811386120932892e-05,
      "loss": 0.0036,
      "step": 8320
    },
    {
      "epoch": 0.8925318761384335,
      "grad_norm": 1.3495204448699951,
      "learning_rate": 1.880995749848209e-05,
      "loss": 0.0708,
      "step": 8330
    },
    {
      "epoch": 0.8936033429765349,
      "grad_norm": 20.610807418823242,
      "learning_rate": 1.8808528876031287e-05,
      "loss": 0.9527,
      "step": 8340
    },
    {
      "epoch": 0.8946748098146362,
      "grad_norm": 16.25670051574707,
      "learning_rate": 1.8807100253580487e-05,
      "loss": 0.4335,
      "step": 8350
    },
    {
      "epoch": 0.8957462766527376,
      "grad_norm": 0.9790921807289124,
      "learning_rate": 1.8805671631129686e-05,
      "loss": 0.5169,
      "step": 8360
    },
    {
      "epoch": 0.896817743490839,
      "grad_norm": 0.10844997316598892,
      "learning_rate": 1.8804243008678882e-05,
      "loss": 0.455,
      "step": 8370
    },
    {
      "epoch": 0.8978892103289403,
      "grad_norm": 0.24105282127857208,
      "learning_rate": 1.880281438622808e-05,
      "loss": 0.2904,
      "step": 8380
    },
    {
      "epoch": 0.8989606771670416,
      "grad_norm": 0.12940749526023865,
      "learning_rate": 1.880138576377728e-05,
      "loss": 0.3369,
      "step": 8390
    },
    {
      "epoch": 0.9000321440051431,
      "grad_norm": 28.839385986328125,
      "learning_rate": 1.8799957141326477e-05,
      "loss": 0.4991,
      "step": 8400
    },
    {
      "epoch": 0.9011036108432444,
      "grad_norm": 0.06337181478738785,
      "learning_rate": 1.8798528518875676e-05,
      "loss": 0.4184,
      "step": 8410
    },
    {
      "epoch": 0.9021750776813457,
      "grad_norm": 23.26883888244629,
      "learning_rate": 1.8797099896424872e-05,
      "loss": 0.2844,
      "step": 8420
    },
    {
      "epoch": 0.9032465445194471,
      "grad_norm": 0.06826816499233246,
      "learning_rate": 1.879567127397407e-05,
      "loss": 0.0034,
      "step": 8430
    },
    {
      "epoch": 0.9043180113575485,
      "grad_norm": 0.19926691055297852,
      "learning_rate": 1.879424265152327e-05,
      "loss": 0.5836,
      "step": 8440
    },
    {
      "epoch": 0.9053894781956499,
      "grad_norm": 0.05023656785488129,
      "learning_rate": 1.8792814029072467e-05,
      "loss": 0.1624,
      "step": 8450
    },
    {
      "epoch": 0.9064609450337512,
      "grad_norm": 1.4672235250473022,
      "learning_rate": 1.8791385406621666e-05,
      "loss": 0.311,
      "step": 8460
    },
    {
      "epoch": 0.9075324118718525,
      "grad_norm": 29.541542053222656,
      "learning_rate": 1.8789956784170866e-05,
      "loss": 0.897,
      "step": 8470
    },
    {
      "epoch": 0.908603878709954,
      "grad_norm": 0.08277033269405365,
      "learning_rate": 1.878852816172006e-05,
      "loss": 0.1074,
      "step": 8480
    },
    {
      "epoch": 0.9096753455480553,
      "grad_norm": 0.14082945883274078,
      "learning_rate": 1.878709953926926e-05,
      "loss": 0.7598,
      "step": 8490
    },
    {
      "epoch": 0.9107468123861566,
      "grad_norm": 0.08933945000171661,
      "learning_rate": 1.878567091681846e-05,
      "loss": 0.0034,
      "step": 8500
    },
    {
      "epoch": 0.911818279224258,
      "grad_norm": 0.08274117112159729,
      "learning_rate": 1.878424229436766e-05,
      "loss": 0.1661,
      "step": 8510
    },
    {
      "epoch": 0.9128897460623594,
      "grad_norm": 30.99794578552246,
      "learning_rate": 1.8782813671916856e-05,
      "loss": 0.7532,
      "step": 8520
    },
    {
      "epoch": 0.9139612129004607,
      "grad_norm": 15.664485931396484,
      "learning_rate": 1.8781385049466055e-05,
      "loss": 0.6531,
      "step": 8530
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.1532634198665619,
      "learning_rate": 1.877995642701525e-05,
      "loss": 0.0045,
      "step": 8540
    },
    {
      "epoch": 0.9161041465766635,
      "grad_norm": 0.17718207836151123,
      "learning_rate": 1.877852780456445e-05,
      "loss": 0.5576,
      "step": 8550
    },
    {
      "epoch": 0.9171756134147648,
      "grad_norm": 0.29710710048675537,
      "learning_rate": 1.877709918211365e-05,
      "loss": 0.5598,
      "step": 8560
    },
    {
      "epoch": 0.9182470802528662,
      "grad_norm": 20.287940979003906,
      "learning_rate": 1.8775670559662846e-05,
      "loss": 0.6817,
      "step": 8570
    },
    {
      "epoch": 0.9193185470909675,
      "grad_norm": 0.08933950960636139,
      "learning_rate": 1.8774241937212045e-05,
      "loss": 0.2814,
      "step": 8580
    },
    {
      "epoch": 0.9203900139290689,
      "grad_norm": 252.87925720214844,
      "learning_rate": 1.877281331476124e-05,
      "loss": 0.4511,
      "step": 8590
    },
    {
      "epoch": 0.9214614807671703,
      "grad_norm": 0.06083141639828682,
      "learning_rate": 1.877138469231044e-05,
      "loss": 0.3277,
      "step": 8600
    },
    {
      "epoch": 0.9225329476052716,
      "grad_norm": 0.1398189514875412,
      "learning_rate": 1.876995606985964e-05,
      "loss": 0.4934,
      "step": 8610
    },
    {
      "epoch": 0.9236044144433729,
      "grad_norm": 0.02900986187160015,
      "learning_rate": 1.8768527447408836e-05,
      "loss": 0.2447,
      "step": 8620
    },
    {
      "epoch": 0.9246758812814744,
      "grad_norm": 0.1875624656677246,
      "learning_rate": 1.8767098824958035e-05,
      "loss": 0.1345,
      "step": 8630
    },
    {
      "epoch": 0.9257473481195757,
      "grad_norm": 0.01687377132475376,
      "learning_rate": 1.8765670202507235e-05,
      "loss": 0.4939,
      "step": 8640
    },
    {
      "epoch": 0.926818814957677,
      "grad_norm": 0.03559623658657074,
      "learning_rate": 1.8764241580056434e-05,
      "loss": 0.0039,
      "step": 8650
    },
    {
      "epoch": 0.9278902817957784,
      "grad_norm": 0.030387677252292633,
      "learning_rate": 1.876281295760563e-05,
      "loss": 0.9339,
      "step": 8660
    },
    {
      "epoch": 0.9289617486338798,
      "grad_norm": 0.19181616604328156,
      "learning_rate": 1.876138433515483e-05,
      "loss": 0.6057,
      "step": 8670
    },
    {
      "epoch": 0.9300332154719811,
      "grad_norm": 0.5479500889778137,
      "learning_rate": 1.875995571270403e-05,
      "loss": 0.1835,
      "step": 8680
    },
    {
      "epoch": 0.9311046823100825,
      "grad_norm": 0.21262721717357635,
      "learning_rate": 1.8758527090253225e-05,
      "loss": 0.4919,
      "step": 8690
    },
    {
      "epoch": 0.9321761491481839,
      "grad_norm": 0.21567565202713013,
      "learning_rate": 1.8757098467802424e-05,
      "loss": 0.46,
      "step": 8700
    },
    {
      "epoch": 0.9332476159862853,
      "grad_norm": 0.8793022632598877,
      "learning_rate": 1.875566984535162e-05,
      "loss": 0.4994,
      "step": 8710
    },
    {
      "epoch": 0.9343190828243866,
      "grad_norm": 0.09136908501386642,
      "learning_rate": 1.875424122290082e-05,
      "loss": 0.2237,
      "step": 8720
    },
    {
      "epoch": 0.9353905496624879,
      "grad_norm": 0.16659900546073914,
      "learning_rate": 1.8752812600450015e-05,
      "loss": 0.3802,
      "step": 8730
    },
    {
      "epoch": 0.9364620165005894,
      "grad_norm": 0.07305588573217392,
      "learning_rate": 1.8751383977999215e-05,
      "loss": 0.0021,
      "step": 8740
    },
    {
      "epoch": 0.9375334833386907,
      "grad_norm": 0.049518924206495285,
      "learning_rate": 1.8749955355548414e-05,
      "loss": 0.1273,
      "step": 8750
    },
    {
      "epoch": 0.938604950176792,
      "grad_norm": 0.04977664723992348,
      "learning_rate": 1.8748526733097613e-05,
      "loss": 0.4671,
      "step": 8760
    },
    {
      "epoch": 0.9396764170148934,
      "grad_norm": 0.06189050152897835,
      "learning_rate": 1.874709811064681e-05,
      "loss": 0.3623,
      "step": 8770
    },
    {
      "epoch": 0.9407478838529948,
      "grad_norm": 0.10280991345643997,
      "learning_rate": 1.874566948819601e-05,
      "loss": 0.2116,
      "step": 8780
    },
    {
      "epoch": 0.9418193506910961,
      "grad_norm": 19.775081634521484,
      "learning_rate": 1.8744240865745208e-05,
      "loss": 0.6868,
      "step": 8790
    },
    {
      "epoch": 0.9428908175291975,
      "grad_norm": 0.13406813144683838,
      "learning_rate": 1.8742812243294407e-05,
      "loss": 0.3635,
      "step": 8800
    },
    {
      "epoch": 0.9439622843672988,
      "grad_norm": 20.970348358154297,
      "learning_rate": 1.8741383620843603e-05,
      "loss": 0.8184,
      "step": 8810
    },
    {
      "epoch": 0.9450337512054002,
      "grad_norm": 0.8957688808441162,
      "learning_rate": 1.8739954998392803e-05,
      "loss": 0.9861,
      "step": 8820
    },
    {
      "epoch": 0.9461052180435016,
      "grad_norm": 0.5894160866737366,
      "learning_rate": 1.8738526375942e-05,
      "loss": 0.3419,
      "step": 8830
    },
    {
      "epoch": 0.9471766848816029,
      "grad_norm": 0.5968565940856934,
      "learning_rate": 1.8737097753491198e-05,
      "loss": 0.4752,
      "step": 8840
    },
    {
      "epoch": 0.9482481517197042,
      "grad_norm": 0.43068090081214905,
      "learning_rate": 1.8735669131040394e-05,
      "loss": 0.6166,
      "step": 8850
    },
    {
      "epoch": 0.9493196185578057,
      "grad_norm": 1.2157772779464722,
      "learning_rate": 1.8734240508589593e-05,
      "loss": 0.642,
      "step": 8860
    },
    {
      "epoch": 0.950391085395907,
      "grad_norm": 0.5776256322860718,
      "learning_rate": 1.8732811886138793e-05,
      "loss": 0.6664,
      "step": 8870
    },
    {
      "epoch": 0.9514625522340083,
      "grad_norm": 0.3147464096546173,
      "learning_rate": 1.873138326368799e-05,
      "loss": 0.5251,
      "step": 8880
    },
    {
      "epoch": 0.9525340190721098,
      "grad_norm": 16.321731567382812,
      "learning_rate": 1.8729954641237188e-05,
      "loss": 0.1536,
      "step": 8890
    },
    {
      "epoch": 0.9536054859102111,
      "grad_norm": 0.2666800022125244,
      "learning_rate": 1.8728526018786388e-05,
      "loss": 0.2907,
      "step": 8900
    },
    {
      "epoch": 0.9546769527483124,
      "grad_norm": 22.970163345336914,
      "learning_rate": 1.8727097396335584e-05,
      "loss": 0.455,
      "step": 8910
    },
    {
      "epoch": 0.9557484195864138,
      "grad_norm": 0.17860253155231476,
      "learning_rate": 1.8725668773884783e-05,
      "loss": 0.0083,
      "step": 8920
    },
    {
      "epoch": 0.9568198864245152,
      "grad_norm": 0.021716898307204247,
      "learning_rate": 1.8724240151433982e-05,
      "loss": 0.0021,
      "step": 8930
    },
    {
      "epoch": 0.9578913532626165,
      "grad_norm": 15.65484619140625,
      "learning_rate": 1.872281152898318e-05,
      "loss": 1.2194,
      "step": 8940
    },
    {
      "epoch": 0.9589628201007179,
      "grad_norm": 0.12904025614261627,
      "learning_rate": 1.8721382906532378e-05,
      "loss": 0.7521,
      "step": 8950
    },
    {
      "epoch": 0.9600342869388192,
      "grad_norm": 0.6830400824546814,
      "learning_rate": 1.8719954284081577e-05,
      "loss": 0.3521,
      "step": 8960
    },
    {
      "epoch": 0.9611057537769206,
      "grad_norm": 15.47579574584961,
      "learning_rate": 1.8718525661630773e-05,
      "loss": 0.4691,
      "step": 8970
    },
    {
      "epoch": 0.962177220615022,
      "grad_norm": 0.5138302445411682,
      "learning_rate": 1.8717097039179972e-05,
      "loss": 0.5846,
      "step": 8980
    },
    {
      "epoch": 0.9632486874531233,
      "grad_norm": 218.3490753173828,
      "learning_rate": 1.8715668416729172e-05,
      "loss": 0.1846,
      "step": 8990
    },
    {
      "epoch": 0.9643201542912246,
      "grad_norm": 0.14503180980682373,
      "learning_rate": 1.8714239794278368e-05,
      "loss": 0.4778,
      "step": 9000
    },
    {
      "epoch": 0.9653916211293261,
      "grad_norm": 1.1638768911361694,
      "learning_rate": 1.8712811171827567e-05,
      "loss": 0.3287,
      "step": 9010
    },
    {
      "epoch": 0.9664630879674274,
      "grad_norm": 16.28658103942871,
      "learning_rate": 1.8711382549376763e-05,
      "loss": 0.8503,
      "step": 9020
    },
    {
      "epoch": 0.9675345548055287,
      "grad_norm": 1.147891640663147,
      "learning_rate": 1.8709953926925962e-05,
      "loss": 0.6715,
      "step": 9030
    },
    {
      "epoch": 0.9686060216436301,
      "grad_norm": 0.2300584465265274,
      "learning_rate": 1.8708525304475162e-05,
      "loss": 0.1256,
      "step": 9040
    },
    {
      "epoch": 0.9696774884817315,
      "grad_norm": 0.23216156661510468,
      "learning_rate": 1.8707096682024358e-05,
      "loss": 0.7259,
      "step": 9050
    },
    {
      "epoch": 0.9707489553198329,
      "grad_norm": 0.2168077975511551,
      "learning_rate": 1.8705668059573557e-05,
      "loss": 0.0084,
      "step": 9060
    },
    {
      "epoch": 0.9718204221579342,
      "grad_norm": 16.911128997802734,
      "learning_rate": 1.8704239437122756e-05,
      "loss": 0.432,
      "step": 9070
    },
    {
      "epoch": 0.9728918889960356,
      "grad_norm": 0.4405656158924103,
      "learning_rate": 1.8702810814671956e-05,
      "loss": 0.1936,
      "step": 9080
    },
    {
      "epoch": 0.973963355834137,
      "grad_norm": 0.07701742649078369,
      "learning_rate": 1.8701382192221152e-05,
      "loss": 0.3763,
      "step": 9090
    },
    {
      "epoch": 0.9750348226722383,
      "grad_norm": 29.231910705566406,
      "learning_rate": 1.869995356977035e-05,
      "loss": 0.7795,
      "step": 9100
    },
    {
      "epoch": 0.9761062895103396,
      "grad_norm": 0.1483934372663498,
      "learning_rate": 1.869852494731955e-05,
      "loss": 0.389,
      "step": 9110
    },
    {
      "epoch": 0.9771777563484411,
      "grad_norm": 0.17296601831912994,
      "learning_rate": 1.8697096324868747e-05,
      "loss": 0.3009,
      "step": 9120
    },
    {
      "epoch": 0.9782492231865424,
      "grad_norm": 0.1348550021648407,
      "learning_rate": 1.8695667702417946e-05,
      "loss": 0.9931,
      "step": 9130
    },
    {
      "epoch": 0.9793206900246437,
      "grad_norm": 18.61777687072754,
      "learning_rate": 1.8694239079967142e-05,
      "loss": 0.5537,
      "step": 9140
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.15592049062252045,
      "learning_rate": 1.869281045751634e-05,
      "loss": 0.0098,
      "step": 9150
    },
    {
      "epoch": 0.9814636237008465,
      "grad_norm": 0.5338985919952393,
      "learning_rate": 1.8691381835065537e-05,
      "loss": 0.5806,
      "step": 9160
    },
    {
      "epoch": 0.9825350905389478,
      "grad_norm": 0.0495452918112278,
      "learning_rate": 1.8689953212614737e-05,
      "loss": 0.233,
      "step": 9170
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 288.525146484375,
      "learning_rate": 1.8688524590163936e-05,
      "loss": 0.5338,
      "step": 9180
    },
    {
      "epoch": 0.9846780242151505,
      "grad_norm": 22.59583854675293,
      "learning_rate": 1.8687095967713132e-05,
      "loss": 0.5136,
      "step": 9190
    },
    {
      "epoch": 0.9857494910532519,
      "grad_norm": 0.32101571559906006,
      "learning_rate": 1.868566734526233e-05,
      "loss": 0.4275,
      "step": 9200
    },
    {
      "epoch": 0.9868209578913533,
      "grad_norm": 0.5033061504364014,
      "learning_rate": 1.868423872281153e-05,
      "loss": 0.4445,
      "step": 9210
    },
    {
      "epoch": 0.9878924247294546,
      "grad_norm": 0.24893534183502197,
      "learning_rate": 1.868281010036073e-05,
      "loss": 0.6984,
      "step": 9220
    },
    {
      "epoch": 0.9889638915675559,
      "grad_norm": 60.35809326171875,
      "learning_rate": 1.868138147790993e-05,
      "loss": 0.2665,
      "step": 9230
    },
    {
      "epoch": 0.9900353584056574,
      "grad_norm": 0.47987842559814453,
      "learning_rate": 1.8679952855459125e-05,
      "loss": 0.0223,
      "step": 9240
    },
    {
      "epoch": 0.9911068252437587,
      "grad_norm": 16.602954864501953,
      "learning_rate": 1.8678524233008325e-05,
      "loss": 0.8439,
      "step": 9250
    },
    {
      "epoch": 0.99217829208186,
      "grad_norm": 0.1369708925485611,
      "learning_rate": 1.867709561055752e-05,
      "loss": 0.4425,
      "step": 9260
    },
    {
      "epoch": 0.9932497589199615,
      "grad_norm": 0.03361200541257858,
      "learning_rate": 1.867566698810672e-05,
      "loss": 0.0921,
      "step": 9270
    },
    {
      "epoch": 0.9943212257580628,
      "grad_norm": 0.06228687986731529,
      "learning_rate": 1.8674238365655916e-05,
      "loss": 0.4254,
      "step": 9280
    },
    {
      "epoch": 0.9953926925961641,
      "grad_norm": 0.0622762031853199,
      "learning_rate": 1.8672809743205115e-05,
      "loss": 0.2256,
      "step": 9290
    },
    {
      "epoch": 0.9964641594342655,
      "grad_norm": 16.59741973876953,
      "learning_rate": 1.8671381120754315e-05,
      "loss": 0.5862,
      "step": 9300
    },
    {
      "epoch": 0.9975356262723669,
      "grad_norm": 20.75098991394043,
      "learning_rate": 1.866995249830351e-05,
      "loss": 0.5964,
      "step": 9310
    },
    {
      "epoch": 0.9986070931104682,
      "grad_norm": 19.652225494384766,
      "learning_rate": 1.866852387585271e-05,
      "loss": 0.0843,
      "step": 9320
    },
    {
      "epoch": 0.9996785599485696,
      "grad_norm": 26.10616683959961,
      "learning_rate": 1.866709525340191e-05,
      "loss": 0.2866,
      "step": 9330
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.913,
      "eval_f1": 0.6081081081081081,
      "eval_loss": 0.39114445447921753,
      "eval_precision": 0.7043478260869566,
      "eval_recall": 0.535006605019815,
      "eval_runtime": 401.9625,
      "eval_samples_per_second": 14.927,
      "eval_steps_per_second": 4.976,
      "step": 9333
    },
    {
      "epoch": 1.000750026786671,
      "grad_norm": 0.03989855945110321,
      "learning_rate": 1.8665666630951105e-05,
      "loss": 0.2768,
      "step": 9340
    },
    {
      "epoch": 1.0018214936247722,
      "grad_norm": 11.355621337890625,
      "learning_rate": 1.8664238008500305e-05,
      "loss": 0.7281,
      "step": 9350
    },
    {
      "epoch": 1.0028929604628736,
      "grad_norm": 0.058816708624362946,
      "learning_rate": 1.8662809386049504e-05,
      "loss": 0.3057,
      "step": 9360
    },
    {
      "epoch": 1.0039644273009751,
      "grad_norm": 17.943843841552734,
      "learning_rate": 1.8661380763598704e-05,
      "loss": 0.5981,
      "step": 9370
    },
    {
      "epoch": 1.0050358941390765,
      "grad_norm": 0.2871372699737549,
      "learning_rate": 1.86599521411479e-05,
      "loss": 0.0914,
      "step": 9380
    },
    {
      "epoch": 1.0061073609771778,
      "grad_norm": 0.35894468426704407,
      "learning_rate": 1.86585235186971e-05,
      "loss": 0.2519,
      "step": 9390
    },
    {
      "epoch": 1.0071788278152791,
      "grad_norm": 0.036544762551784515,
      "learning_rate": 1.8657094896246295e-05,
      "loss": 0.2274,
      "step": 9400
    },
    {
      "epoch": 1.0082502946533805,
      "grad_norm": 74.36747741699219,
      "learning_rate": 1.8655666273795494e-05,
      "loss": 0.0188,
      "step": 9410
    },
    {
      "epoch": 1.0093217614914818,
      "grad_norm": 25.56352424621582,
      "learning_rate": 1.8654237651344694e-05,
      "loss": 0.4571,
      "step": 9420
    },
    {
      "epoch": 1.0103932283295831,
      "grad_norm": 0.025818469002842903,
      "learning_rate": 1.865280902889389e-05,
      "loss": 0.3688,
      "step": 9430
    },
    {
      "epoch": 1.0114646951676847,
      "grad_norm": 0.04622311517596245,
      "learning_rate": 1.865138040644309e-05,
      "loss": 0.0027,
      "step": 9440
    },
    {
      "epoch": 1.012536162005786,
      "grad_norm": 0.024282824248075485,
      "learning_rate": 1.8649951783992285e-05,
      "loss": 0.9341,
      "step": 9450
    },
    {
      "epoch": 1.0136076288438873,
      "grad_norm": 18.514738082885742,
      "learning_rate": 1.8648523161541484e-05,
      "loss": 0.1489,
      "step": 9460
    },
    {
      "epoch": 1.0146790956819887,
      "grad_norm": 0.058906178921461105,
      "learning_rate": 1.8647094539090684e-05,
      "loss": 0.7707,
      "step": 9470
    },
    {
      "epoch": 1.01575056252009,
      "grad_norm": 15.986340522766113,
      "learning_rate": 1.864566591663988e-05,
      "loss": 0.6085,
      "step": 9480
    },
    {
      "epoch": 1.0168220293581913,
      "grad_norm": 0.10280255973339081,
      "learning_rate": 1.864423729418908e-05,
      "loss": 0.0017,
      "step": 9490
    },
    {
      "epoch": 1.0178934961962927,
      "grad_norm": 125.10484313964844,
      "learning_rate": 1.864280867173828e-05,
      "loss": 0.7009,
      "step": 9500
    },
    {
      "epoch": 1.018964963034394,
      "grad_norm": 0.4237532913684845,
      "learning_rate": 1.8641380049287478e-05,
      "loss": 0.4133,
      "step": 9510
    },
    {
      "epoch": 1.0200364298724955,
      "grad_norm": 0.11611601710319519,
      "learning_rate": 1.8639951426836674e-05,
      "loss": 0.3043,
      "step": 9520
    },
    {
      "epoch": 1.0211078967105969,
      "grad_norm": 0.32069653272628784,
      "learning_rate": 1.8638522804385873e-05,
      "loss": 0.4536,
      "step": 9530
    },
    {
      "epoch": 1.0221793635486982,
      "grad_norm": 0.08494123071432114,
      "learning_rate": 1.8637094181935072e-05,
      "loss": 0.566,
      "step": 9540
    },
    {
      "epoch": 1.0232508303867995,
      "grad_norm": 0.37722229957580566,
      "learning_rate": 1.863566555948427e-05,
      "loss": 0.0925,
      "step": 9550
    },
    {
      "epoch": 1.0243222972249009,
      "grad_norm": 0.6080639958381653,
      "learning_rate": 1.8634236937033468e-05,
      "loss": 0.6886,
      "step": 9560
    },
    {
      "epoch": 1.0253937640630022,
      "grad_norm": 23.268463134765625,
      "learning_rate": 1.8632808314582664e-05,
      "loss": 0.2883,
      "step": 9570
    },
    {
      "epoch": 1.0264652309011035,
      "grad_norm": 0.21437931060791016,
      "learning_rate": 1.8631379692131863e-05,
      "loss": 0.1337,
      "step": 9580
    },
    {
      "epoch": 1.0275366977392049,
      "grad_norm": 0.5082876682281494,
      "learning_rate": 1.8629951069681063e-05,
      "loss": 0.1901,
      "step": 9590
    },
    {
      "epoch": 1.0286081645773064,
      "grad_norm": 0.39914220571517944,
      "learning_rate": 1.862852244723026e-05,
      "loss": 0.0025,
      "step": 9600
    },
    {
      "epoch": 1.0296796314154077,
      "grad_norm": 0.013261747546494007,
      "learning_rate": 1.8627093824779458e-05,
      "loss": 0.004,
      "step": 9610
    },
    {
      "epoch": 1.030751098253509,
      "grad_norm": 21.402423858642578,
      "learning_rate": 1.8625665202328654e-05,
      "loss": 0.8713,
      "step": 9620
    },
    {
      "epoch": 1.0318225650916104,
      "grad_norm": 0.21260808408260345,
      "learning_rate": 1.8624236579877853e-05,
      "loss": 0.1304,
      "step": 9630
    },
    {
      "epoch": 1.0328940319297117,
      "grad_norm": 0.04196196049451828,
      "learning_rate": 1.8622807957427053e-05,
      "loss": 0.3382,
      "step": 9640
    },
    {
      "epoch": 1.033965498767813,
      "grad_norm": 0.12807846069335938,
      "learning_rate": 1.8621379334976252e-05,
      "loss": 0.6353,
      "step": 9650
    },
    {
      "epoch": 1.0350369656059144,
      "grad_norm": 8.633051872253418,
      "learning_rate": 1.861995071252545e-05,
      "loss": 0.4845,
      "step": 9660
    },
    {
      "epoch": 1.036108432444016,
      "grad_norm": 0.10526448488235474,
      "learning_rate": 1.8618522090074647e-05,
      "loss": 0.4976,
      "step": 9670
    },
    {
      "epoch": 1.0371798992821173,
      "grad_norm": 0.4930242896080017,
      "learning_rate": 1.8617093467623847e-05,
      "loss": 0.2964,
      "step": 9680
    },
    {
      "epoch": 1.0382513661202186,
      "grad_norm": 0.167770653963089,
      "learning_rate": 1.8615664845173043e-05,
      "loss": 0.4093,
      "step": 9690
    },
    {
      "epoch": 1.03932283295832,
      "grad_norm": 0.34258291125297546,
      "learning_rate": 1.8614236222722242e-05,
      "loss": 0.4231,
      "step": 9700
    },
    {
      "epoch": 1.0403942997964213,
      "grad_norm": 16.471012115478516,
      "learning_rate": 1.861280760027144e-05,
      "loss": 0.3145,
      "step": 9710
    },
    {
      "epoch": 1.0414657666345226,
      "grad_norm": 0.06249433010816574,
      "learning_rate": 1.8611378977820637e-05,
      "loss": 0.3672,
      "step": 9720
    },
    {
      "epoch": 1.042537233472624,
      "grad_norm": 0.4431684613227844,
      "learning_rate": 1.8609950355369837e-05,
      "loss": 0.4541,
      "step": 9730
    },
    {
      "epoch": 1.0436087003107253,
      "grad_norm": 22.42769432067871,
      "learning_rate": 1.8608521732919033e-05,
      "loss": 0.6777,
      "step": 9740
    },
    {
      "epoch": 1.0446801671488268,
      "grad_norm": 1.2246613502502441,
      "learning_rate": 1.8607093110468232e-05,
      "loss": 0.5752,
      "step": 9750
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.24252958595752716,
      "learning_rate": 1.8605664488017428e-05,
      "loss": 0.0108,
      "step": 9760
    },
    {
      "epoch": 1.0468231008250295,
      "grad_norm": 0.027833621948957443,
      "learning_rate": 1.8604235865566627e-05,
      "loss": 0.1085,
      "step": 9770
    },
    {
      "epoch": 1.0478945676631308,
      "grad_norm": 0.07749078422784805,
      "learning_rate": 1.8602807243115827e-05,
      "loss": 0.4345,
      "step": 9780
    },
    {
      "epoch": 1.0489660345012322,
      "grad_norm": 0.07597308605909348,
      "learning_rate": 1.8601378620665026e-05,
      "loss": 0.3389,
      "step": 9790
    },
    {
      "epoch": 1.0500375013393335,
      "grad_norm": 0.032722316682338715,
      "learning_rate": 1.8599949998214226e-05,
      "loss": 0.6296,
      "step": 9800
    },
    {
      "epoch": 1.0511089681774348,
      "grad_norm": 21.143596649169922,
      "learning_rate": 1.859852137576342e-05,
      "loss": 0.3212,
      "step": 9810
    },
    {
      "epoch": 1.0521804350155364,
      "grad_norm": 0.2452169805765152,
      "learning_rate": 1.859709275331262e-05,
      "loss": 0.6708,
      "step": 9820
    },
    {
      "epoch": 1.0532519018536377,
      "grad_norm": 0.09004276245832443,
      "learning_rate": 1.859566413086182e-05,
      "loss": 0.0055,
      "step": 9830
    },
    {
      "epoch": 1.054323368691739,
      "grad_norm": 0.15586437284946442,
      "learning_rate": 1.8594235508411016e-05,
      "loss": 0.318,
      "step": 9840
    },
    {
      "epoch": 1.0553948355298404,
      "grad_norm": 0.12561282515525818,
      "learning_rate": 1.8592806885960216e-05,
      "loss": 0.8087,
      "step": 9850
    },
    {
      "epoch": 1.0564663023679417,
      "grad_norm": 14.471308708190918,
      "learning_rate": 1.859137826350941e-05,
      "loss": 0.4669,
      "step": 9860
    },
    {
      "epoch": 1.057537769206043,
      "grad_norm": 22.061952590942383,
      "learning_rate": 1.858994964105861e-05,
      "loss": 0.4968,
      "step": 9870
    },
    {
      "epoch": 1.0586092360441444,
      "grad_norm": 0.37392866611480713,
      "learning_rate": 1.8588521018607807e-05,
      "loss": 0.4892,
      "step": 9880
    },
    {
      "epoch": 1.0596807028822457,
      "grad_norm": 0.12217915058135986,
      "learning_rate": 1.8587092396157006e-05,
      "loss": 0.1869,
      "step": 9890
    },
    {
      "epoch": 1.0607521697203472,
      "grad_norm": 0.0805852860212326,
      "learning_rate": 1.8585663773706206e-05,
      "loss": 0.1997,
      "step": 9900
    },
    {
      "epoch": 1.0618236365584486,
      "grad_norm": 0.7120526432991028,
      "learning_rate": 1.85842351512554e-05,
      "loss": 0.0877,
      "step": 9910
    },
    {
      "epoch": 1.06289510339655,
      "grad_norm": 29.557025909423828,
      "learning_rate": 1.85828065288046e-05,
      "loss": 0.5912,
      "step": 9920
    },
    {
      "epoch": 1.0639665702346512,
      "grad_norm": 0.261319637298584,
      "learning_rate": 1.85813779063538e-05,
      "loss": 0.1535,
      "step": 9930
    },
    {
      "epoch": 1.0650380370727526,
      "grad_norm": 54.68854904174805,
      "learning_rate": 1.8579949283903e-05,
      "loss": 0.6229,
      "step": 9940
    },
    {
      "epoch": 1.066109503910854,
      "grad_norm": 0.04285113513469696,
      "learning_rate": 1.8578520661452196e-05,
      "loss": 0.0053,
      "step": 9950
    },
    {
      "epoch": 1.0671809707489552,
      "grad_norm": 51.09248352050781,
      "learning_rate": 1.8577092039001395e-05,
      "loss": 0.1339,
      "step": 9960
    },
    {
      "epoch": 1.0682524375870566,
      "grad_norm": 0.016864391043782234,
      "learning_rate": 1.8575663416550594e-05,
      "loss": 0.1109,
      "step": 9970
    },
    {
      "epoch": 1.0693239044251581,
      "grad_norm": 4.066723346710205,
      "learning_rate": 1.857423479409979e-05,
      "loss": 0.7589,
      "step": 9980
    },
    {
      "epoch": 1.0703953712632595,
      "grad_norm": 1.7544077634811401,
      "learning_rate": 1.857280617164899e-05,
      "loss": 0.3271,
      "step": 9990
    },
    {
      "epoch": 1.0714668381013608,
      "grad_norm": 0.036184608936309814,
      "learning_rate": 1.8571377549198186e-05,
      "loss": 0.2436,
      "step": 10000
    },
    {
      "epoch": 1.0725383049394621,
      "grad_norm": 0.07962469011545181,
      "learning_rate": 1.8569948926747385e-05,
      "loss": 0.6533,
      "step": 10010
    },
    {
      "epoch": 1.0736097717775634,
      "grad_norm": 0.28947529196739197,
      "learning_rate": 1.8568520304296584e-05,
      "loss": 0.5907,
      "step": 10020
    },
    {
      "epoch": 1.0746812386156648,
      "grad_norm": 2.514727830886841,
      "learning_rate": 1.856709168184578e-05,
      "loss": 0.1145,
      "step": 10030
    },
    {
      "epoch": 1.0757527054537661,
      "grad_norm": 0.08807899802923203,
      "learning_rate": 1.856566305939498e-05,
      "loss": 0.5329,
      "step": 10040
    },
    {
      "epoch": 1.0768241722918677,
      "grad_norm": 21.388334274291992,
      "learning_rate": 1.8564234436944176e-05,
      "loss": 0.6111,
      "step": 10050
    },
    {
      "epoch": 1.077895639129969,
      "grad_norm": 0.0546419583261013,
      "learning_rate": 1.8562805814493375e-05,
      "loss": 0.2323,
      "step": 10060
    },
    {
      "epoch": 1.0789671059680703,
      "grad_norm": 0.5674854516983032,
      "learning_rate": 1.8561377192042575e-05,
      "loss": 0.8521,
      "step": 10070
    },
    {
      "epoch": 1.0800385728061717,
      "grad_norm": 0.29157155752182007,
      "learning_rate": 1.8559948569591774e-05,
      "loss": 0.3016,
      "step": 10080
    },
    {
      "epoch": 1.081110039644273,
      "grad_norm": 0.4986603856086731,
      "learning_rate": 1.8558519947140973e-05,
      "loss": 0.1364,
      "step": 10090
    },
    {
      "epoch": 1.0821815064823743,
      "grad_norm": 24.802875518798828,
      "learning_rate": 1.855709132469017e-05,
      "loss": 0.333,
      "step": 10100
    },
    {
      "epoch": 1.0832529733204757,
      "grad_norm": 0.19477416574954987,
      "learning_rate": 1.855566270223937e-05,
      "loss": 0.6413,
      "step": 10110
    },
    {
      "epoch": 1.0843244401585772,
      "grad_norm": 0.1485528200864792,
      "learning_rate": 1.8554234079788565e-05,
      "loss": 0.7379,
      "step": 10120
    },
    {
      "epoch": 1.0853959069966785,
      "grad_norm": 0.613264262676239,
      "learning_rate": 1.8552805457337764e-05,
      "loss": 0.3717,
      "step": 10130
    },
    {
      "epoch": 1.0864673738347799,
      "grad_norm": 5.231644153594971,
      "learning_rate": 1.8551376834886963e-05,
      "loss": 0.3188,
      "step": 10140
    },
    {
      "epoch": 1.0875388406728812,
      "grad_norm": 0.19265583157539368,
      "learning_rate": 1.854994821243616e-05,
      "loss": 0.1703,
      "step": 10150
    },
    {
      "epoch": 1.0886103075109825,
      "grad_norm": 15.704630851745605,
      "learning_rate": 1.854851958998536e-05,
      "loss": 0.4744,
      "step": 10160
    },
    {
      "epoch": 1.0896817743490839,
      "grad_norm": 0.6937522888183594,
      "learning_rate": 1.8547090967534555e-05,
      "loss": 0.3145,
      "step": 10170
    },
    {
      "epoch": 1.0907532411871852,
      "grad_norm": 0.2981685996055603,
      "learning_rate": 1.8545662345083754e-05,
      "loss": 0.5426,
      "step": 10180
    },
    {
      "epoch": 1.0918247080252865,
      "grad_norm": 21.165864944458008,
      "learning_rate": 1.854423372263295e-05,
      "loss": 0.6074,
      "step": 10190
    },
    {
      "epoch": 1.092896174863388,
      "grad_norm": 2.8382887840270996,
      "learning_rate": 1.854280510018215e-05,
      "loss": 0.3512,
      "step": 10200
    },
    {
      "epoch": 1.0939676417014894,
      "grad_norm": 0.09052669256925583,
      "learning_rate": 1.854137647773135e-05,
      "loss": 0.3043,
      "step": 10210
    },
    {
      "epoch": 1.0950391085395907,
      "grad_norm": 0.03928475081920624,
      "learning_rate": 1.8539947855280548e-05,
      "loss": 0.0585,
      "step": 10220
    },
    {
      "epoch": 1.096110575377692,
      "grad_norm": 0.014779243618249893,
      "learning_rate": 1.8538519232829747e-05,
      "loss": 0.0045,
      "step": 10230
    },
    {
      "epoch": 1.0971820422157934,
      "grad_norm": 0.17584507167339325,
      "learning_rate": 1.8537090610378943e-05,
      "loss": 0.1818,
      "step": 10240
    },
    {
      "epoch": 1.0982535090538947,
      "grad_norm": 0.09954966604709625,
      "learning_rate": 1.8535661987928143e-05,
      "loss": 0.5457,
      "step": 10250
    },
    {
      "epoch": 1.099324975891996,
      "grad_norm": 17.670352935791016,
      "learning_rate": 1.8534233365477342e-05,
      "loss": 0.3356,
      "step": 10260
    },
    {
      "epoch": 1.1003964427300974,
      "grad_norm": 0.03034440614283085,
      "learning_rate": 1.8532804743026538e-05,
      "loss": 0.4755,
      "step": 10270
    },
    {
      "epoch": 1.101467909568199,
      "grad_norm": 0.06473385542631149,
      "learning_rate": 1.8531376120575738e-05,
      "loss": 0.4486,
      "step": 10280
    },
    {
      "epoch": 1.1025393764063003,
      "grad_norm": 0.24105997383594513,
      "learning_rate": 1.8529947498124934e-05,
      "loss": 0.0966,
      "step": 10290
    },
    {
      "epoch": 1.1036108432444016,
      "grad_norm": 0.18999098241329193,
      "learning_rate": 1.8528518875674133e-05,
      "loss": 0.1521,
      "step": 10300
    },
    {
      "epoch": 1.104682310082503,
      "grad_norm": 0.009775296784937382,
      "learning_rate": 1.852709025322333e-05,
      "loss": 0.1588,
      "step": 10310
    },
    {
      "epoch": 1.1057537769206043,
      "grad_norm": 0.0175437331199646,
      "learning_rate": 1.8525661630772528e-05,
      "loss": 0.6391,
      "step": 10320
    },
    {
      "epoch": 1.1068252437587056,
      "grad_norm": 0.15914098918437958,
      "learning_rate": 1.8524233008321728e-05,
      "loss": 0.6674,
      "step": 10330
    },
    {
      "epoch": 1.107896710596807,
      "grad_norm": 38.803924560546875,
      "learning_rate": 1.8522804385870924e-05,
      "loss": 0.3617,
      "step": 10340
    },
    {
      "epoch": 1.1089681774349085,
      "grad_norm": 0.358477383852005,
      "learning_rate": 1.8521375763420123e-05,
      "loss": 0.6913,
      "step": 10350
    },
    {
      "epoch": 1.1100396442730098,
      "grad_norm": 14.044254302978516,
      "learning_rate": 1.8519947140969322e-05,
      "loss": 0.4243,
      "step": 10360
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.09030024707317352,
      "learning_rate": 1.851851851851852e-05,
      "loss": 0.2042,
      "step": 10370
    },
    {
      "epoch": 1.1121825779492125,
      "grad_norm": 0.08405568450689316,
      "learning_rate": 1.8517089896067718e-05,
      "loss": 0.34,
      "step": 10380
    },
    {
      "epoch": 1.1132540447873138,
      "grad_norm": 0.020059453323483467,
      "learning_rate": 1.8515661273616917e-05,
      "loss": 0.6037,
      "step": 10390
    },
    {
      "epoch": 1.1143255116254152,
      "grad_norm": 0.06688933819532394,
      "learning_rate": 1.8514232651166116e-05,
      "loss": 0.4173,
      "step": 10400
    },
    {
      "epoch": 1.1153969784635165,
      "grad_norm": 0.9852862358093262,
      "learning_rate": 1.8512804028715312e-05,
      "loss": 0.139,
      "step": 10410
    },
    {
      "epoch": 1.1164684453016178,
      "grad_norm": 0.01199788972735405,
      "learning_rate": 1.8511375406264512e-05,
      "loss": 0.0032,
      "step": 10420
    },
    {
      "epoch": 1.1175399121397194,
      "grad_norm": 0.014442402869462967,
      "learning_rate": 1.8509946783813708e-05,
      "loss": 0.1077,
      "step": 10430
    },
    {
      "epoch": 1.1186113789778207,
      "grad_norm": 0.015711840242147446,
      "learning_rate": 1.8508518161362907e-05,
      "loss": 0.1812,
      "step": 10440
    },
    {
      "epoch": 1.119682845815922,
      "grad_norm": 0.8078354597091675,
      "learning_rate": 1.8507089538912106e-05,
      "loss": 0.0112,
      "step": 10450
    },
    {
      "epoch": 1.1207543126540234,
      "grad_norm": 0.06043783575296402,
      "learning_rate": 1.8505660916461302e-05,
      "loss": 0.778,
      "step": 10460
    },
    {
      "epoch": 1.1218257794921247,
      "grad_norm": 0.01818758435547352,
      "learning_rate": 1.8504232294010502e-05,
      "loss": 0.153,
      "step": 10470
    },
    {
      "epoch": 1.122897246330226,
      "grad_norm": 18.676450729370117,
      "learning_rate": 1.8502803671559698e-05,
      "loss": 0.275,
      "step": 10480
    },
    {
      "epoch": 1.1239687131683274,
      "grad_norm": 0.16352280974388123,
      "learning_rate": 1.8501375049108897e-05,
      "loss": 0.3396,
      "step": 10490
    },
    {
      "epoch": 1.1250401800064287,
      "grad_norm": 0.04851561412215233,
      "learning_rate": 1.8499946426658096e-05,
      "loss": 0.289,
      "step": 10500
    },
    {
      "epoch": 1.1261116468445302,
      "grad_norm": 0.2807919383049011,
      "learning_rate": 1.8498517804207296e-05,
      "loss": 0.1131,
      "step": 10510
    },
    {
      "epoch": 1.1271831136826316,
      "grad_norm": 17.95120620727539,
      "learning_rate": 1.8497089181756492e-05,
      "loss": 0.1578,
      "step": 10520
    },
    {
      "epoch": 1.128254580520733,
      "grad_norm": 0.21730852127075195,
      "learning_rate": 1.849566055930569e-05,
      "loss": 0.4601,
      "step": 10530
    },
    {
      "epoch": 1.1293260473588342,
      "grad_norm": 0.7445634603500366,
      "learning_rate": 1.849423193685489e-05,
      "loss": 0.2561,
      "step": 10540
    },
    {
      "epoch": 1.1303975141969356,
      "grad_norm": 192.4387969970703,
      "learning_rate": 1.8492803314404087e-05,
      "loss": 0.4253,
      "step": 10550
    },
    {
      "epoch": 1.131468981035037,
      "grad_norm": 84.93292999267578,
      "learning_rate": 1.8491374691953286e-05,
      "loss": 1.038,
      "step": 10560
    },
    {
      "epoch": 1.1325404478731382,
      "grad_norm": 0.25851160287857056,
      "learning_rate": 1.8489946069502485e-05,
      "loss": 0.4526,
      "step": 10570
    },
    {
      "epoch": 1.1336119147112398,
      "grad_norm": 0.48568275570869446,
      "learning_rate": 1.848851744705168e-05,
      "loss": 0.7342,
      "step": 10580
    },
    {
      "epoch": 1.1346833815493411,
      "grad_norm": 0.13752958178520203,
      "learning_rate": 1.848708882460088e-05,
      "loss": 0.1208,
      "step": 10590
    },
    {
      "epoch": 1.1357548483874425,
      "grad_norm": 0.1058625727891922,
      "learning_rate": 1.8485660202150077e-05,
      "loss": 0.3637,
      "step": 10600
    },
    {
      "epoch": 1.1368263152255438,
      "grad_norm": 25.833839416503906,
      "learning_rate": 1.8484231579699276e-05,
      "loss": 0.2405,
      "step": 10610
    },
    {
      "epoch": 1.1378977820636451,
      "grad_norm": 0.09085745364427567,
      "learning_rate": 1.8482802957248475e-05,
      "loss": 0.0042,
      "step": 10620
    },
    {
      "epoch": 1.1389692489017464,
      "grad_norm": 0.11761650443077087,
      "learning_rate": 1.848137433479767e-05,
      "loss": 0.1152,
      "step": 10630
    },
    {
      "epoch": 1.1400407157398478,
      "grad_norm": 0.06553339213132858,
      "learning_rate": 1.847994571234687e-05,
      "loss": 0.002,
      "step": 10640
    },
    {
      "epoch": 1.1411121825779493,
      "grad_norm": 0.04108721762895584,
      "learning_rate": 1.847851708989607e-05,
      "loss": 0.7913,
      "step": 10650
    },
    {
      "epoch": 1.1421836494160507,
      "grad_norm": 17.475757598876953,
      "learning_rate": 1.847708846744527e-05,
      "loss": 0.3439,
      "step": 10660
    },
    {
      "epoch": 1.143255116254152,
      "grad_norm": 0.338615357875824,
      "learning_rate": 1.8475659844994465e-05,
      "loss": 0.564,
      "step": 10670
    },
    {
      "epoch": 1.1443265830922533,
      "grad_norm": 0.37863296270370483,
      "learning_rate": 1.8474231222543665e-05,
      "loss": 0.2136,
      "step": 10680
    },
    {
      "epoch": 1.1453980499303547,
      "grad_norm": 0.09845434129238129,
      "learning_rate": 1.8472802600092864e-05,
      "loss": 0.3412,
      "step": 10690
    },
    {
      "epoch": 1.146469516768456,
      "grad_norm": 0.08519331365823746,
      "learning_rate": 1.847137397764206e-05,
      "loss": 0.0027,
      "step": 10700
    },
    {
      "epoch": 1.1475409836065573,
      "grad_norm": 0.39896687865257263,
      "learning_rate": 1.846994535519126e-05,
      "loss": 0.6434,
      "step": 10710
    },
    {
      "epoch": 1.1486124504446587,
      "grad_norm": 21.189697265625,
      "learning_rate": 1.8468516732740455e-05,
      "loss": 0.2043,
      "step": 10720
    },
    {
      "epoch": 1.14968391728276,
      "grad_norm": 0.14858083426952362,
      "learning_rate": 1.8467088110289655e-05,
      "loss": 0.4588,
      "step": 10730
    },
    {
      "epoch": 1.1507553841208615,
      "grad_norm": 0.13656991720199585,
      "learning_rate": 1.8465659487838854e-05,
      "loss": 0.2755,
      "step": 10740
    },
    {
      "epoch": 1.1518268509589629,
      "grad_norm": 0.06290120631456375,
      "learning_rate": 1.846423086538805e-05,
      "loss": 0.2969,
      "step": 10750
    },
    {
      "epoch": 1.1528983177970642,
      "grad_norm": 0.2544890344142914,
      "learning_rate": 1.846280224293725e-05,
      "loss": 0.4683,
      "step": 10760
    },
    {
      "epoch": 1.1539697846351655,
      "grad_norm": 0.08782114088535309,
      "learning_rate": 1.8461373620486446e-05,
      "loss": 0.4475,
      "step": 10770
    },
    {
      "epoch": 1.1550412514732669,
      "grad_norm": 1.9279452562332153,
      "learning_rate": 1.8459944998035645e-05,
      "loss": 0.1712,
      "step": 10780
    },
    {
      "epoch": 1.1561127183113682,
      "grad_norm": 0.17687615752220154,
      "learning_rate": 1.8458516375584844e-05,
      "loss": 0.1622,
      "step": 10790
    },
    {
      "epoch": 1.1571841851494695,
      "grad_norm": 0.27369481325149536,
      "learning_rate": 1.8457087753134044e-05,
      "loss": 0.4005,
      "step": 10800
    },
    {
      "epoch": 1.158255651987571,
      "grad_norm": 0.25364959239959717,
      "learning_rate": 1.845565913068324e-05,
      "loss": 0.3464,
      "step": 10810
    },
    {
      "epoch": 1.1593271188256724,
      "grad_norm": 0.06943612545728683,
      "learning_rate": 1.845423050823244e-05,
      "loss": 0.1441,
      "step": 10820
    },
    {
      "epoch": 1.1603985856637737,
      "grad_norm": 0.6465308666229248,
      "learning_rate": 1.845280188578164e-05,
      "loss": 0.4225,
      "step": 10830
    },
    {
      "epoch": 1.161470052501875,
      "grad_norm": 0.4194180369377136,
      "learning_rate": 1.8451373263330834e-05,
      "loss": 0.2505,
      "step": 10840
    },
    {
      "epoch": 1.1625415193399764,
      "grad_norm": 1.6570137739181519,
      "learning_rate": 1.8449944640880034e-05,
      "loss": 0.6517,
      "step": 10850
    },
    {
      "epoch": 1.1636129861780777,
      "grad_norm": 34.33551025390625,
      "learning_rate": 1.8448516018429233e-05,
      "loss": 0.13,
      "step": 10860
    },
    {
      "epoch": 1.164684453016179,
      "grad_norm": 0.7254208326339722,
      "learning_rate": 1.844708739597843e-05,
      "loss": 0.1811,
      "step": 10870
    },
    {
      "epoch": 1.1657559198542806,
      "grad_norm": 0.40983107686042786,
      "learning_rate": 1.844565877352763e-05,
      "loss": 0.2894,
      "step": 10880
    },
    {
      "epoch": 1.166827386692382,
      "grad_norm": 0.14157989621162415,
      "learning_rate": 1.8444230151076824e-05,
      "loss": 0.1969,
      "step": 10890
    },
    {
      "epoch": 1.1678988535304833,
      "grad_norm": 1.4696110486984253,
      "learning_rate": 1.8442801528626024e-05,
      "loss": 0.62,
      "step": 10900
    },
    {
      "epoch": 1.1689703203685846,
      "grad_norm": 0.40696442127227783,
      "learning_rate": 1.844137290617522e-05,
      "loss": 0.3237,
      "step": 10910
    },
    {
      "epoch": 1.170041787206686,
      "grad_norm": 0.715457558631897,
      "learning_rate": 1.843994428372442e-05,
      "loss": 0.3377,
      "step": 10920
    },
    {
      "epoch": 1.1711132540447873,
      "grad_norm": 0.014015245251357555,
      "learning_rate": 1.843851566127362e-05,
      "loss": 0.3662,
      "step": 10930
    },
    {
      "epoch": 1.1721847208828886,
      "grad_norm": 0.009634586982429028,
      "learning_rate": 1.8437087038822818e-05,
      "loss": 0.5494,
      "step": 10940
    },
    {
      "epoch": 1.17325618772099,
      "grad_norm": 0.07412514090538025,
      "learning_rate": 1.8435658416372014e-05,
      "loss": 0.6496,
      "step": 10950
    },
    {
      "epoch": 1.1743276545590913,
      "grad_norm": 17.066162109375,
      "learning_rate": 1.8434229793921213e-05,
      "loss": 0.6235,
      "step": 10960
    },
    {
      "epoch": 1.1753991213971928,
      "grad_norm": 0.06360232084989548,
      "learning_rate": 1.8432801171470413e-05,
      "loss": 0.0029,
      "step": 10970
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.03985549136996269,
      "learning_rate": 1.843137254901961e-05,
      "loss": 0.1171,
      "step": 10980
    },
    {
      "epoch": 1.1775420550733955,
      "grad_norm": 0.041958075016736984,
      "learning_rate": 1.8429943926568808e-05,
      "loss": 0.3766,
      "step": 10990
    },
    {
      "epoch": 1.1786135219114968,
      "grad_norm": 0.6657458543777466,
      "learning_rate": 1.8428515304118007e-05,
      "loss": 0.0731,
      "step": 11000
    },
    {
      "epoch": 1.1796849887495982,
      "grad_norm": 0.03503644838929176,
      "learning_rate": 1.8427086681667203e-05,
      "loss": 0.46,
      "step": 11010
    },
    {
      "epoch": 1.1807564555876995,
      "grad_norm": 0.03133083134889603,
      "learning_rate": 1.8425658059216403e-05,
      "loss": 0.3935,
      "step": 11020
    },
    {
      "epoch": 1.1818279224258008,
      "grad_norm": 0.1258426159620285,
      "learning_rate": 1.84242294367656e-05,
      "loss": 0.1163,
      "step": 11030
    },
    {
      "epoch": 1.1828993892639024,
      "grad_norm": 181.9557342529297,
      "learning_rate": 1.8422800814314798e-05,
      "loss": 0.261,
      "step": 11040
    },
    {
      "epoch": 1.1839708561020037,
      "grad_norm": 51.67768478393555,
      "learning_rate": 1.8421372191863997e-05,
      "loss": 0.5374,
      "step": 11050
    },
    {
      "epoch": 1.185042322940105,
      "grad_norm": 0.017519760876893997,
      "learning_rate": 1.8419943569413193e-05,
      "loss": 0.0045,
      "step": 11060
    },
    {
      "epoch": 1.1861137897782064,
      "grad_norm": 0.007631378248333931,
      "learning_rate": 1.8418514946962393e-05,
      "loss": 0.0011,
      "step": 11070
    },
    {
      "epoch": 1.1871852566163077,
      "grad_norm": 0.33691108226776123,
      "learning_rate": 1.8417086324511592e-05,
      "loss": 1.079,
      "step": 11080
    },
    {
      "epoch": 1.188256723454409,
      "grad_norm": 0.022092018276453018,
      "learning_rate": 1.8415657702060788e-05,
      "loss": 0.6969,
      "step": 11090
    },
    {
      "epoch": 1.1893281902925104,
      "grad_norm": 0.3611597418785095,
      "learning_rate": 1.8414229079609987e-05,
      "loss": 0.0013,
      "step": 11100
    },
    {
      "epoch": 1.190399657130612,
      "grad_norm": 0.08557143807411194,
      "learning_rate": 1.8412800457159187e-05,
      "loss": 0.5461,
      "step": 11110
    },
    {
      "epoch": 1.1914711239687132,
      "grad_norm": 18.391008377075195,
      "learning_rate": 1.8411371834708386e-05,
      "loss": 0.5163,
      "step": 11120
    },
    {
      "epoch": 1.1925425908068146,
      "grad_norm": 0.49085962772369385,
      "learning_rate": 1.8409943212257582e-05,
      "loss": 0.2542,
      "step": 11130
    },
    {
      "epoch": 1.193614057644916,
      "grad_norm": 28.357437133789062,
      "learning_rate": 1.840851458980678e-05,
      "loss": 0.1215,
      "step": 11140
    },
    {
      "epoch": 1.1946855244830172,
      "grad_norm": 17.986154556274414,
      "learning_rate": 1.8407085967355977e-05,
      "loss": 0.5817,
      "step": 11150
    },
    {
      "epoch": 1.1957569913211186,
      "grad_norm": 0.055448777973651886,
      "learning_rate": 1.8405657344905177e-05,
      "loss": 0.0028,
      "step": 11160
    },
    {
      "epoch": 1.19682845815922,
      "grad_norm": 21.288433074951172,
      "learning_rate": 1.8404228722454376e-05,
      "loss": 0.3524,
      "step": 11170
    },
    {
      "epoch": 1.1978999249973215,
      "grad_norm": 0.06463257968425751,
      "learning_rate": 1.8402800100003572e-05,
      "loss": 0.4018,
      "step": 11180
    },
    {
      "epoch": 1.1989713918354228,
      "grad_norm": 0.27863702178001404,
      "learning_rate": 1.840137147755277e-05,
      "loss": 0.2765,
      "step": 11190
    },
    {
      "epoch": 1.2000428586735241,
      "grad_norm": 24.021780014038086,
      "learning_rate": 1.8399942855101967e-05,
      "loss": 0.7451,
      "step": 11200
    },
    {
      "epoch": 1.2011143255116254,
      "grad_norm": 0.03704935684800148,
      "learning_rate": 1.8398514232651167e-05,
      "loss": 0.2186,
      "step": 11210
    },
    {
      "epoch": 1.2021857923497268,
      "grad_norm": 0.5995942950248718,
      "learning_rate": 1.8397085610200366e-05,
      "loss": 0.2513,
      "step": 11220
    },
    {
      "epoch": 1.203257259187828,
      "grad_norm": 0.017648817971348763,
      "learning_rate": 1.8395656987749566e-05,
      "loss": 0.1116,
      "step": 11230
    },
    {
      "epoch": 1.2043287260259294,
      "grad_norm": 0.07836028933525085,
      "learning_rate": 1.839422836529876e-05,
      "loss": 0.4429,
      "step": 11240
    },
    {
      "epoch": 1.2054001928640308,
      "grad_norm": 0.14368313550949097,
      "learning_rate": 1.839279974284796e-05,
      "loss": 0.3803,
      "step": 11250
    },
    {
      "epoch": 1.206471659702132,
      "grad_norm": 0.03685091808438301,
      "learning_rate": 1.839137112039716e-05,
      "loss": 0.2647,
      "step": 11260
    },
    {
      "epoch": 1.2075431265402337,
      "grad_norm": 0.05878153443336487,
      "learning_rate": 1.8389942497946356e-05,
      "loss": 0.6678,
      "step": 11270
    },
    {
      "epoch": 1.208614593378335,
      "grad_norm": 0.17868582904338837,
      "learning_rate": 1.8388513875495556e-05,
      "loss": 0.2296,
      "step": 11280
    },
    {
      "epoch": 1.2096860602164363,
      "grad_norm": 28.635181427001953,
      "learning_rate": 1.8387085253044755e-05,
      "loss": 0.6891,
      "step": 11290
    },
    {
      "epoch": 1.2107575270545377,
      "grad_norm": 20.59873390197754,
      "learning_rate": 1.838565663059395e-05,
      "loss": 0.4437,
      "step": 11300
    },
    {
      "epoch": 1.211828993892639,
      "grad_norm": 0.6122274994850159,
      "learning_rate": 1.838422800814315e-05,
      "loss": 0.21,
      "step": 11310
    },
    {
      "epoch": 1.2129004607307403,
      "grad_norm": 0.17328855395317078,
      "learning_rate": 1.8382799385692346e-05,
      "loss": 0.3511,
      "step": 11320
    },
    {
      "epoch": 1.2139719275688416,
      "grad_norm": 0.08637687563896179,
      "learning_rate": 1.8381370763241546e-05,
      "loss": 0.1545,
      "step": 11330
    },
    {
      "epoch": 1.2150433944069432,
      "grad_norm": 31.999324798583984,
      "learning_rate": 1.837994214079074e-05,
      "loss": 0.6414,
      "step": 11340
    },
    {
      "epoch": 1.2161148612450445,
      "grad_norm": 0.11962426453828812,
      "learning_rate": 1.837851351833994e-05,
      "loss": 0.3553,
      "step": 11350
    },
    {
      "epoch": 1.2171863280831459,
      "grad_norm": 0.03419211506843567,
      "learning_rate": 1.837708489588914e-05,
      "loss": 0.1937,
      "step": 11360
    },
    {
      "epoch": 1.2182577949212472,
      "grad_norm": 0.04334459453821182,
      "learning_rate": 1.837565627343834e-05,
      "loss": 0.2301,
      "step": 11370
    },
    {
      "epoch": 1.2193292617593485,
      "grad_norm": 0.020733391866087914,
      "learning_rate": 1.8374227650987536e-05,
      "loss": 0.1994,
      "step": 11380
    },
    {
      "epoch": 1.2204007285974499,
      "grad_norm": 0.31130680441856384,
      "learning_rate": 1.8372799028536735e-05,
      "loss": 0.1461,
      "step": 11390
    },
    {
      "epoch": 1.2214721954355512,
      "grad_norm": 69.74002075195312,
      "learning_rate": 1.8371370406085934e-05,
      "loss": 0.4072,
      "step": 11400
    },
    {
      "epoch": 1.2225436622736527,
      "grad_norm": 0.015498691238462925,
      "learning_rate": 1.8369941783635134e-05,
      "loss": 0.0501,
      "step": 11410
    },
    {
      "epoch": 1.223615129111754,
      "grad_norm": 16.857255935668945,
      "learning_rate": 1.836851316118433e-05,
      "loss": 0.6224,
      "step": 11420
    },
    {
      "epoch": 1.2246865959498554,
      "grad_norm": 0.03057796135544777,
      "learning_rate": 1.836708453873353e-05,
      "loss": 0.2447,
      "step": 11430
    },
    {
      "epoch": 1.2257580627879567,
      "grad_norm": 502.3296813964844,
      "learning_rate": 1.8365655916282725e-05,
      "loss": 0.4882,
      "step": 11440
    },
    {
      "epoch": 1.226829529626058,
      "grad_norm": 1.1107172966003418,
      "learning_rate": 1.8364227293831925e-05,
      "loss": 0.2576,
      "step": 11450
    },
    {
      "epoch": 1.2279009964641594,
      "grad_norm": 0.0595601350069046,
      "learning_rate": 1.836279867138112e-05,
      "loss": 0.0186,
      "step": 11460
    },
    {
      "epoch": 1.2289724633022607,
      "grad_norm": 19.76603126525879,
      "learning_rate": 1.836137004893032e-05,
      "loss": 0.8135,
      "step": 11470
    },
    {
      "epoch": 1.230043930140362,
      "grad_norm": 0.05804618075489998,
      "learning_rate": 1.835994142647952e-05,
      "loss": 0.4086,
      "step": 11480
    },
    {
      "epoch": 1.2311153969784634,
      "grad_norm": 0.08078581839799881,
      "learning_rate": 1.8358512804028715e-05,
      "loss": 0.4524,
      "step": 11490
    },
    {
      "epoch": 1.232186863816565,
      "grad_norm": 0.16531948745250702,
      "learning_rate": 1.8357084181577915e-05,
      "loss": 0.7249,
      "step": 11500
    },
    {
      "epoch": 1.2332583306546663,
      "grad_norm": 135.85581970214844,
      "learning_rate": 1.8355655559127114e-05,
      "loss": 0.5673,
      "step": 11510
    },
    {
      "epoch": 1.2343297974927676,
      "grad_norm": 0.2515236735343933,
      "learning_rate": 1.835422693667631e-05,
      "loss": 0.07,
      "step": 11520
    },
    {
      "epoch": 1.235401264330869,
      "grad_norm": 0.0857364758849144,
      "learning_rate": 1.835279831422551e-05,
      "loss": 0.6925,
      "step": 11530
    },
    {
      "epoch": 1.2364727311689703,
      "grad_norm": 37.4663200378418,
      "learning_rate": 1.835136969177471e-05,
      "loss": 0.1946,
      "step": 11540
    },
    {
      "epoch": 1.2375441980070716,
      "grad_norm": 21.206178665161133,
      "learning_rate": 1.8349941069323908e-05,
      "loss": 0.1756,
      "step": 11550
    },
    {
      "epoch": 1.238615664845173,
      "grad_norm": 0.039137016981840134,
      "learning_rate": 1.8348512446873104e-05,
      "loss": 0.2432,
      "step": 11560
    },
    {
      "epoch": 1.2396871316832745,
      "grad_norm": 0.04489594325423241,
      "learning_rate": 1.8347083824422303e-05,
      "loss": 0.6062,
      "step": 11570
    },
    {
      "epoch": 1.2407585985213758,
      "grad_norm": 0.12205918878316879,
      "learning_rate": 1.83456552019715e-05,
      "loss": 0.3167,
      "step": 11580
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.11407411843538284,
      "learning_rate": 1.83442265795207e-05,
      "loss": 0.331,
      "step": 11590
    },
    {
      "epoch": 1.2429015321975785,
      "grad_norm": 18.406078338623047,
      "learning_rate": 1.8342797957069898e-05,
      "loss": 0.4147,
      "step": 11600
    },
    {
      "epoch": 1.2439729990356798,
      "grad_norm": 0.09221455454826355,
      "learning_rate": 1.8341369334619094e-05,
      "loss": 0.4008,
      "step": 11610
    },
    {
      "epoch": 1.2450444658737811,
      "grad_norm": 0.1777706891298294,
      "learning_rate": 1.8339940712168293e-05,
      "loss": 0.2925,
      "step": 11620
    },
    {
      "epoch": 1.2461159327118825,
      "grad_norm": 0.04071158170700073,
      "learning_rate": 1.833851208971749e-05,
      "loss": 0.2386,
      "step": 11630
    },
    {
      "epoch": 1.247187399549984,
      "grad_norm": 25.209026336669922,
      "learning_rate": 1.833708346726669e-05,
      "loss": 0.5109,
      "step": 11640
    },
    {
      "epoch": 1.2482588663880854,
      "grad_norm": 10.333258628845215,
      "learning_rate": 1.8335654844815888e-05,
      "loss": 0.2635,
      "step": 11650
    },
    {
      "epoch": 1.2493303332261867,
      "grad_norm": 23.187625885009766,
      "learning_rate": 1.8334226222365084e-05,
      "loss": 0.1764,
      "step": 11660
    },
    {
      "epoch": 1.250401800064288,
      "grad_norm": 0.04642923176288605,
      "learning_rate": 1.8332797599914283e-05,
      "loss": 0.4492,
      "step": 11670
    },
    {
      "epoch": 1.2514732669023894,
      "grad_norm": 0.31712213158607483,
      "learning_rate": 1.8331368977463483e-05,
      "loss": 0.4156,
      "step": 11680
    },
    {
      "epoch": 1.2525447337404907,
      "grad_norm": 0.18430842459201813,
      "learning_rate": 1.8329940355012682e-05,
      "loss": 0.8807,
      "step": 11690
    },
    {
      "epoch": 1.253616200578592,
      "grad_norm": 0.2546297609806061,
      "learning_rate": 1.8328511732561878e-05,
      "loss": 0.437,
      "step": 11700
    },
    {
      "epoch": 1.2546876674166936,
      "grad_norm": 0.3868652880191803,
      "learning_rate": 1.8327083110111078e-05,
      "loss": 0.3821,
      "step": 11710
    },
    {
      "epoch": 1.2557591342547947,
      "grad_norm": 5.970252990722656,
      "learning_rate": 1.8325654487660277e-05,
      "loss": 0.2354,
      "step": 11720
    },
    {
      "epoch": 1.2568306010928962,
      "grad_norm": 0.4377991259098053,
      "learning_rate": 1.8324225865209473e-05,
      "loss": 0.2174,
      "step": 11730
    },
    {
      "epoch": 1.2579020679309976,
      "grad_norm": 0.05048966780304909,
      "learning_rate": 1.8322797242758672e-05,
      "loss": 0.0021,
      "step": 11740
    },
    {
      "epoch": 1.258973534769099,
      "grad_norm": 105.15618133544922,
      "learning_rate": 1.8321368620307868e-05,
      "loss": 0.4436,
      "step": 11750
    },
    {
      "epoch": 1.2600450016072002,
      "grad_norm": 0.05880753695964813,
      "learning_rate": 1.8319939997857068e-05,
      "loss": 0.3528,
      "step": 11760
    },
    {
      "epoch": 1.2611164684453016,
      "grad_norm": 0.2432262897491455,
      "learning_rate": 1.8318511375406267e-05,
      "loss": 0.2401,
      "step": 11770
    },
    {
      "epoch": 1.2621879352834031,
      "grad_norm": 0.04449847713112831,
      "learning_rate": 1.8317082752955463e-05,
      "loss": 0.4535,
      "step": 11780
    },
    {
      "epoch": 1.2632594021215042,
      "grad_norm": 0.3604736924171448,
      "learning_rate": 1.8315654130504662e-05,
      "loss": 0.1501,
      "step": 11790
    },
    {
      "epoch": 1.2643308689596058,
      "grad_norm": 0.23370523750782013,
      "learning_rate": 1.831422550805386e-05,
      "loss": 0.1719,
      "step": 11800
    },
    {
      "epoch": 1.2654023357977071,
      "grad_norm": 0.09202957153320312,
      "learning_rate": 1.8312796885603058e-05,
      "loss": 0.2482,
      "step": 11810
    },
    {
      "epoch": 1.2664738026358084,
      "grad_norm": 16.63363265991211,
      "learning_rate": 1.8311368263152257e-05,
      "loss": 0.4666,
      "step": 11820
    },
    {
      "epoch": 1.2675452694739098,
      "grad_norm": 14.757323265075684,
      "learning_rate": 1.8309939640701456e-05,
      "loss": 0.4353,
      "step": 11830
    },
    {
      "epoch": 1.268616736312011,
      "grad_norm": 0.5992217659950256,
      "learning_rate": 1.8308511018250656e-05,
      "loss": 0.0139,
      "step": 11840
    },
    {
      "epoch": 1.2696882031501124,
      "grad_norm": 20.783836364746094,
      "learning_rate": 1.8307082395799852e-05,
      "loss": 0.5862,
      "step": 11850
    },
    {
      "epoch": 1.2707596699882138,
      "grad_norm": 0.1700001209974289,
      "learning_rate": 1.830565377334905e-05,
      "loss": 0.3561,
      "step": 11860
    },
    {
      "epoch": 1.2718311368263153,
      "grad_norm": 0.20892444252967834,
      "learning_rate": 1.8304225150898247e-05,
      "loss": 0.4763,
      "step": 11870
    },
    {
      "epoch": 1.2729026036644167,
      "grad_norm": 0.15933647751808167,
      "learning_rate": 1.8302796528447446e-05,
      "loss": 0.0028,
      "step": 11880
    },
    {
      "epoch": 1.273974070502518,
      "grad_norm": 20.06441879272461,
      "learning_rate": 1.8301367905996642e-05,
      "loss": 0.8008,
      "step": 11890
    },
    {
      "epoch": 1.2750455373406193,
      "grad_norm": 21.095115661621094,
      "learning_rate": 1.8299939283545842e-05,
      "loss": 0.7499,
      "step": 11900
    },
    {
      "epoch": 1.2761170041787206,
      "grad_norm": 15.675192832946777,
      "learning_rate": 1.829851066109504e-05,
      "loss": 0.9194,
      "step": 11910
    },
    {
      "epoch": 1.277188471016822,
      "grad_norm": 1.4238632917404175,
      "learning_rate": 1.8297082038644237e-05,
      "loss": 0.6948,
      "step": 11920
    },
    {
      "epoch": 1.2782599378549233,
      "grad_norm": 0.20460256934165955,
      "learning_rate": 1.8295653416193437e-05,
      "loss": 0.1412,
      "step": 11930
    },
    {
      "epoch": 1.2793314046930249,
      "grad_norm": 0.11126594245433807,
      "learning_rate": 1.8294224793742636e-05,
      "loss": 0.0174,
      "step": 11940
    },
    {
      "epoch": 1.280402871531126,
      "grad_norm": 0.043119609355926514,
      "learning_rate": 1.8292796171291832e-05,
      "loss": 0.5405,
      "step": 11950
    },
    {
      "epoch": 1.2814743383692275,
      "grad_norm": 24.569210052490234,
      "learning_rate": 1.829136754884103e-05,
      "loss": 0.4806,
      "step": 11960
    },
    {
      "epoch": 1.2825458052073289,
      "grad_norm": 0.39635464549064636,
      "learning_rate": 1.828993892639023e-05,
      "loss": 0.9649,
      "step": 11970
    },
    {
      "epoch": 1.2836172720454302,
      "grad_norm": 0.3507256805896759,
      "learning_rate": 1.828851030393943e-05,
      "loss": 0.3016,
      "step": 11980
    },
    {
      "epoch": 1.2846887388835315,
      "grad_norm": 0.33329886198043823,
      "learning_rate": 1.8287081681488626e-05,
      "loss": 0.2605,
      "step": 11990
    },
    {
      "epoch": 1.2857602057216329,
      "grad_norm": 0.07619498670101166,
      "learning_rate": 1.8285653059037825e-05,
      "loss": 0.0064,
      "step": 12000
    },
    {
      "epoch": 1.2868316725597344,
      "grad_norm": 21.883956909179688,
      "learning_rate": 1.828422443658702e-05,
      "loss": 0.4078,
      "step": 12010
    },
    {
      "epoch": 1.2879031393978355,
      "grad_norm": 0.02929949387907982,
      "learning_rate": 1.828279581413622e-05,
      "loss": 0.2311,
      "step": 12020
    },
    {
      "epoch": 1.288974606235937,
      "grad_norm": 0.11345528811216354,
      "learning_rate": 1.828136719168542e-05,
      "loss": 0.7976,
      "step": 12030
    },
    {
      "epoch": 1.2900460730740384,
      "grad_norm": 0.16111068427562714,
      "learning_rate": 1.8279938569234616e-05,
      "loss": 0.2475,
      "step": 12040
    },
    {
      "epoch": 1.2911175399121397,
      "grad_norm": 0.08808305859565735,
      "learning_rate": 1.8278509946783815e-05,
      "loss": 0.4391,
      "step": 12050
    },
    {
      "epoch": 1.292189006750241,
      "grad_norm": 0.10760987550020218,
      "learning_rate": 1.827708132433301e-05,
      "loss": 0.3218,
      "step": 12060
    },
    {
      "epoch": 1.2932604735883424,
      "grad_norm": 6.114353656768799,
      "learning_rate": 1.827565270188221e-05,
      "loss": 0.6346,
      "step": 12070
    },
    {
      "epoch": 1.2943319404264437,
      "grad_norm": 0.1092962995171547,
      "learning_rate": 1.827422407943141e-05,
      "loss": 0.2905,
      "step": 12080
    },
    {
      "epoch": 1.295403407264545,
      "grad_norm": 0.09317264705896378,
      "learning_rate": 1.8272795456980606e-05,
      "loss": 0.1468,
      "step": 12090
    },
    {
      "epoch": 1.2964748741026466,
      "grad_norm": 18.046152114868164,
      "learning_rate": 1.8271366834529805e-05,
      "loss": 0.2586,
      "step": 12100
    },
    {
      "epoch": 1.297546340940748,
      "grad_norm": 0.19745884835720062,
      "learning_rate": 1.8269938212079005e-05,
      "loss": 0.233,
      "step": 12110
    },
    {
      "epoch": 1.2986178077788493,
      "grad_norm": 40.81663513183594,
      "learning_rate": 1.8268509589628204e-05,
      "loss": 0.3948,
      "step": 12120
    },
    {
      "epoch": 1.2996892746169506,
      "grad_norm": 0.09295894205570221,
      "learning_rate": 1.82670809671774e-05,
      "loss": 0.1832,
      "step": 12130
    },
    {
      "epoch": 1.300760741455052,
      "grad_norm": 0.009548723697662354,
      "learning_rate": 1.82656523447266e-05,
      "loss": 0.0959,
      "step": 12140
    },
    {
      "epoch": 1.3018322082931533,
      "grad_norm": 0.011247444897890091,
      "learning_rate": 1.82642237222758e-05,
      "loss": 0.0024,
      "step": 12150
    },
    {
      "epoch": 1.3029036751312546,
      "grad_norm": 0.011507037095725536,
      "learning_rate": 1.8262795099824995e-05,
      "loss": 0.7461,
      "step": 12160
    },
    {
      "epoch": 1.3039751419693562,
      "grad_norm": 0.013992924243211746,
      "learning_rate": 1.8261366477374194e-05,
      "loss": 0.1549,
      "step": 12170
    },
    {
      "epoch": 1.3050466088074575,
      "grad_norm": 0.04096636548638344,
      "learning_rate": 1.825993785492339e-05,
      "loss": 0.5809,
      "step": 12180
    },
    {
      "epoch": 1.3061180756455588,
      "grad_norm": 22.287776947021484,
      "learning_rate": 1.825850923247259e-05,
      "loss": 0.8638,
      "step": 12190
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.19749143719673157,
      "learning_rate": 1.825708061002179e-05,
      "loss": 0.5143,
      "step": 12200
    },
    {
      "epoch": 1.3082610093217615,
      "grad_norm": 0.5170206427574158,
      "learning_rate": 1.8255651987570985e-05,
      "loss": 0.5359,
      "step": 12210
    },
    {
      "epoch": 1.3093324761598628,
      "grad_norm": 20.397171020507812,
      "learning_rate": 1.8254223365120184e-05,
      "loss": 0.3629,
      "step": 12220
    },
    {
      "epoch": 1.3104039429979641,
      "grad_norm": 0.3137660324573517,
      "learning_rate": 1.825279474266938e-05,
      "loss": 0.1253,
      "step": 12230
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 0.02621249109506607,
      "learning_rate": 1.825136612021858e-05,
      "loss": 0.2774,
      "step": 12240
    },
    {
      "epoch": 1.3125468766741668,
      "grad_norm": 0.047778137028217316,
      "learning_rate": 1.824993749776778e-05,
      "loss": 0.0142,
      "step": 12250
    },
    {
      "epoch": 1.3136183435122684,
      "grad_norm": 0.01091877929866314,
      "learning_rate": 1.824850887531698e-05,
      "loss": 0.0104,
      "step": 12260
    },
    {
      "epoch": 1.3146898103503697,
      "grad_norm": 0.024871526286005974,
      "learning_rate": 1.8247080252866178e-05,
      "loss": 0.413,
      "step": 12270
    },
    {
      "epoch": 1.315761277188471,
      "grad_norm": 0.020074987784028053,
      "learning_rate": 1.8245651630415374e-05,
      "loss": 0.6989,
      "step": 12280
    },
    {
      "epoch": 1.3168327440265724,
      "grad_norm": 0.1855277568101883,
      "learning_rate": 1.8244223007964573e-05,
      "loss": 0.5364,
      "step": 12290
    },
    {
      "epoch": 1.3179042108646737,
      "grad_norm": 19.787466049194336,
      "learning_rate": 1.824279438551377e-05,
      "loss": 0.3768,
      "step": 12300
    },
    {
      "epoch": 1.318975677702775,
      "grad_norm": 0.46254804730415344,
      "learning_rate": 1.824136576306297e-05,
      "loss": 0.1514,
      "step": 12310
    },
    {
      "epoch": 1.3200471445408763,
      "grad_norm": 0.5859190225601196,
      "learning_rate": 1.8239937140612168e-05,
      "loss": 0.4591,
      "step": 12320
    },
    {
      "epoch": 1.321118611378978,
      "grad_norm": 0.04876333475112915,
      "learning_rate": 1.8238508518161364e-05,
      "loss": 0.2904,
      "step": 12330
    },
    {
      "epoch": 1.3221900782170792,
      "grad_norm": 169.93421936035156,
      "learning_rate": 1.8237079895710563e-05,
      "loss": 0.3988,
      "step": 12340
    },
    {
      "epoch": 1.3232615450551806,
      "grad_norm": 0.043008629232645035,
      "learning_rate": 1.823565127325976e-05,
      "loss": 0.0029,
      "step": 12350
    },
    {
      "epoch": 1.324333011893282,
      "grad_norm": 31.042341232299805,
      "learning_rate": 1.823422265080896e-05,
      "loss": 0.6378,
      "step": 12360
    },
    {
      "epoch": 1.3254044787313832,
      "grad_norm": 10.878116607666016,
      "learning_rate": 1.8232794028358158e-05,
      "loss": 0.2026,
      "step": 12370
    },
    {
      "epoch": 1.3264759455694846,
      "grad_norm": 0.08392583578824997,
      "learning_rate": 1.8231365405907354e-05,
      "loss": 0.484,
      "step": 12380
    },
    {
      "epoch": 1.327547412407586,
      "grad_norm": 0.09551805257797241,
      "learning_rate": 1.8229936783456553e-05,
      "loss": 0.2348,
      "step": 12390
    },
    {
      "epoch": 1.3286188792456874,
      "grad_norm": 0.03551391139626503,
      "learning_rate": 1.8228508161005753e-05,
      "loss": 0.0084,
      "step": 12400
    },
    {
      "epoch": 1.3296903460837888,
      "grad_norm": 0.32675302028656006,
      "learning_rate": 1.8227079538554952e-05,
      "loss": 0.5433,
      "step": 12410
    },
    {
      "epoch": 1.33076181292189,
      "grad_norm": 0.30894333124160767,
      "learning_rate": 1.8225650916104148e-05,
      "loss": 0.1674,
      "step": 12420
    },
    {
      "epoch": 1.3318332797599914,
      "grad_norm": 0.699199914932251,
      "learning_rate": 1.8224222293653347e-05,
      "loss": 0.2824,
      "step": 12430
    },
    {
      "epoch": 1.3329047465980928,
      "grad_norm": 21.362018585205078,
      "learning_rate": 1.8222793671202547e-05,
      "loss": 0.6266,
      "step": 12440
    },
    {
      "epoch": 1.333976213436194,
      "grad_norm": 47.332759857177734,
      "learning_rate": 1.8221365048751743e-05,
      "loss": 0.5153,
      "step": 12450
    },
    {
      "epoch": 1.3350476802742954,
      "grad_norm": 0.09310363233089447,
      "learning_rate": 1.8219936426300942e-05,
      "loss": 0.175,
      "step": 12460
    },
    {
      "epoch": 1.336119147112397,
      "grad_norm": 41.165592193603516,
      "learning_rate": 1.8218507803850138e-05,
      "loss": 0.1549,
      "step": 12470
    },
    {
      "epoch": 1.337190613950498,
      "grad_norm": 33.08199691772461,
      "learning_rate": 1.8217079181399337e-05,
      "loss": 0.0196,
      "step": 12480
    },
    {
      "epoch": 1.3382620807885997,
      "grad_norm": 27.351036071777344,
      "learning_rate": 1.8215650558948533e-05,
      "loss": 0.9152,
      "step": 12490
    },
    {
      "epoch": 1.339333547626701,
      "grad_norm": 0.21417966485023499,
      "learning_rate": 1.8214221936497733e-05,
      "loss": 0.1074,
      "step": 12500
    },
    {
      "epoch": 1.3404050144648023,
      "grad_norm": 0.06871300935745239,
      "learning_rate": 1.8212793314046932e-05,
      "loss": 0.5499,
      "step": 12510
    },
    {
      "epoch": 1.3414764813029036,
      "grad_norm": 0.7077358961105347,
      "learning_rate": 1.8211364691596128e-05,
      "loss": 0.8089,
      "step": 12520
    },
    {
      "epoch": 1.342547948141005,
      "grad_norm": 0.1970742642879486,
      "learning_rate": 1.8209936069145327e-05,
      "loss": 0.164,
      "step": 12530
    },
    {
      "epoch": 1.3436194149791065,
      "grad_norm": 0.21667271852493286,
      "learning_rate": 1.8208507446694527e-05,
      "loss": 0.3389,
      "step": 12540
    },
    {
      "epoch": 1.3446908818172076,
      "grad_norm": 0.09058938175439835,
      "learning_rate": 1.8207078824243726e-05,
      "loss": 0.11,
      "step": 12550
    },
    {
      "epoch": 1.3457623486553092,
      "grad_norm": 0.03401803970336914,
      "learning_rate": 1.8205650201792922e-05,
      "loss": 0.1746,
      "step": 12560
    },
    {
      "epoch": 1.3468338154934105,
      "grad_norm": 0.06823460012674332,
      "learning_rate": 1.820422157934212e-05,
      "loss": 0.3901,
      "step": 12570
    },
    {
      "epoch": 1.3479052823315119,
      "grad_norm": 0.08431249856948853,
      "learning_rate": 1.820279295689132e-05,
      "loss": 0.512,
      "step": 12580
    },
    {
      "epoch": 1.3489767491696132,
      "grad_norm": 17.02634048461914,
      "learning_rate": 1.8201364334440517e-05,
      "loss": 0.542,
      "step": 12590
    },
    {
      "epoch": 1.3500482160077145,
      "grad_norm": 0.040807370096445084,
      "learning_rate": 1.8199935711989716e-05,
      "loss": 0.2736,
      "step": 12600
    },
    {
      "epoch": 1.3511196828458159,
      "grad_norm": 24.226572036743164,
      "learning_rate": 1.8198507089538912e-05,
      "loss": 0.1861,
      "step": 12610
    },
    {
      "epoch": 1.3521911496839172,
      "grad_norm": 0.03842729330062866,
      "learning_rate": 1.819707846708811e-05,
      "loss": 0.2007,
      "step": 12620
    },
    {
      "epoch": 1.3532626165220187,
      "grad_norm": 0.3052050471305847,
      "learning_rate": 1.819564984463731e-05,
      "loss": 0.2931,
      "step": 12630
    },
    {
      "epoch": 1.35433408336012,
      "grad_norm": 0.0631524845957756,
      "learning_rate": 1.8194221222186507e-05,
      "loss": 0.1354,
      "step": 12640
    },
    {
      "epoch": 1.3554055501982214,
      "grad_norm": 20.2690372467041,
      "learning_rate": 1.8192792599735706e-05,
      "loss": 0.939,
      "step": 12650
    },
    {
      "epoch": 1.3564770170363227,
      "grad_norm": 1.5473787784576416,
      "learning_rate": 1.8191363977284902e-05,
      "loss": 0.1721,
      "step": 12660
    },
    {
      "epoch": 1.357548483874424,
      "grad_norm": 0.1016537994146347,
      "learning_rate": 1.81899353548341e-05,
      "loss": 0.0073,
      "step": 12670
    },
    {
      "epoch": 1.3586199507125254,
      "grad_norm": 0.24019640684127808,
      "learning_rate": 1.81885067323833e-05,
      "loss": 0.1481,
      "step": 12680
    },
    {
      "epoch": 1.3596914175506267,
      "grad_norm": 0.0383799709379673,
      "learning_rate": 1.81870781099325e-05,
      "loss": 0.2788,
      "step": 12690
    },
    {
      "epoch": 1.3607628843887283,
      "grad_norm": 0.05060979723930359,
      "learning_rate": 1.81856494874817e-05,
      "loss": 0.6412,
      "step": 12700
    },
    {
      "epoch": 1.3618343512268296,
      "grad_norm": 0.0938311293721199,
      "learning_rate": 1.8184220865030896e-05,
      "loss": 0.1659,
      "step": 12710
    },
    {
      "epoch": 1.362905818064931,
      "grad_norm": 15.570184707641602,
      "learning_rate": 1.8182792242580095e-05,
      "loss": 0.5314,
      "step": 12720
    },
    {
      "epoch": 1.3639772849030323,
      "grad_norm": 0.2812417447566986,
      "learning_rate": 1.818136362012929e-05,
      "loss": 0.1473,
      "step": 12730
    },
    {
      "epoch": 1.3650487517411336,
      "grad_norm": 0.029184505343437195,
      "learning_rate": 1.817993499767849e-05,
      "loss": 0.3743,
      "step": 12740
    },
    {
      "epoch": 1.366120218579235,
      "grad_norm": 0.155366912484169,
      "learning_rate": 1.817850637522769e-05,
      "loss": 0.0011,
      "step": 12750
    },
    {
      "epoch": 1.3671916854173363,
      "grad_norm": 0.11871387809515,
      "learning_rate": 1.8177077752776886e-05,
      "loss": 0.7249,
      "step": 12760
    },
    {
      "epoch": 1.3682631522554378,
      "grad_norm": 0.06336469948291779,
      "learning_rate": 1.8175649130326085e-05,
      "loss": 0.119,
      "step": 12770
    },
    {
      "epoch": 1.369334619093539,
      "grad_norm": 0.35974985361099243,
      "learning_rate": 1.817422050787528e-05,
      "loss": 0.2266,
      "step": 12780
    },
    {
      "epoch": 1.3704060859316405,
      "grad_norm": 0.13644373416900635,
      "learning_rate": 1.817279188542448e-05,
      "loss": 0.1138,
      "step": 12790
    },
    {
      "epoch": 1.3714775527697418,
      "grad_norm": 0.027368564158678055,
      "learning_rate": 1.8171363262973676e-05,
      "loss": 0.4091,
      "step": 12800
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.02644229494035244,
      "learning_rate": 1.8169934640522876e-05,
      "loss": 0.4245,
      "step": 12810
    },
    {
      "epoch": 1.3736204864459445,
      "grad_norm": 0.015479039400815964,
      "learning_rate": 1.8168506018072075e-05,
      "loss": 0.3967,
      "step": 12820
    },
    {
      "epoch": 1.3746919532840458,
      "grad_norm": 30.19096565246582,
      "learning_rate": 1.8167077395621274e-05,
      "loss": 0.3331,
      "step": 12830
    },
    {
      "epoch": 1.3757634201221471,
      "grad_norm": 20.53651237487793,
      "learning_rate": 1.8165648773170474e-05,
      "loss": 0.1371,
      "step": 12840
    },
    {
      "epoch": 1.3768348869602485,
      "grad_norm": 18.70835304260254,
      "learning_rate": 1.816422015071967e-05,
      "loss": 0.6008,
      "step": 12850
    },
    {
      "epoch": 1.37790635379835,
      "grad_norm": 0.36511269211769104,
      "learning_rate": 1.816279152826887e-05,
      "loss": 0.3242,
      "step": 12860
    },
    {
      "epoch": 1.3789778206364514,
      "grad_norm": 0.20910190045833588,
      "learning_rate": 1.816136290581807e-05,
      "loss": 0.4376,
      "step": 12870
    },
    {
      "epoch": 1.3800492874745527,
      "grad_norm": 0.03259013593196869,
      "learning_rate": 1.8159934283367265e-05,
      "loss": 0.5803,
      "step": 12880
    },
    {
      "epoch": 1.381120754312654,
      "grad_norm": 0.15139177441596985,
      "learning_rate": 1.8158505660916464e-05,
      "loss": 0.3157,
      "step": 12890
    },
    {
      "epoch": 1.3821922211507554,
      "grad_norm": 0.054360128939151764,
      "learning_rate": 1.815707703846566e-05,
      "loss": 0.0019,
      "step": 12900
    },
    {
      "epoch": 1.3832636879888567,
      "grad_norm": 0.024980993941426277,
      "learning_rate": 1.815564841601486e-05,
      "loss": 0.2444,
      "step": 12910
    },
    {
      "epoch": 1.384335154826958,
      "grad_norm": 0.047113146632909775,
      "learning_rate": 1.8154219793564055e-05,
      "loss": 0.4477,
      "step": 12920
    },
    {
      "epoch": 1.3854066216650596,
      "grad_norm": 0.1039007157087326,
      "learning_rate": 1.8152791171113255e-05,
      "loss": 0.0039,
      "step": 12930
    },
    {
      "epoch": 1.386478088503161,
      "grad_norm": 0.12030823528766632,
      "learning_rate": 1.8151362548662454e-05,
      "loss": 0.2403,
      "step": 12940
    },
    {
      "epoch": 1.3875495553412622,
      "grad_norm": 0.029870061203837395,
      "learning_rate": 1.814993392621165e-05,
      "loss": 0.2423,
      "step": 12950
    },
    {
      "epoch": 1.3886210221793636,
      "grad_norm": 15.599644660949707,
      "learning_rate": 1.814850530376085e-05,
      "loss": 0.7755,
      "step": 12960
    },
    {
      "epoch": 1.389692489017465,
      "grad_norm": 0.02905433438718319,
      "learning_rate": 1.814707668131005e-05,
      "loss": 0.3638,
      "step": 12970
    },
    {
      "epoch": 1.3907639558555662,
      "grad_norm": 0.5202910900115967,
      "learning_rate": 1.8145648058859248e-05,
      "loss": 0.4321,
      "step": 12980
    },
    {
      "epoch": 1.3918354226936676,
      "grad_norm": 0.2639918327331543,
      "learning_rate": 1.8144219436408444e-05,
      "loss": 0.7785,
      "step": 12990
    },
    {
      "epoch": 1.392906889531769,
      "grad_norm": 0.05663624778389931,
      "learning_rate": 1.8142790813957643e-05,
      "loss": 0.1924,
      "step": 13000
    },
    {
      "epoch": 1.3939783563698702,
      "grad_norm": 0.04522155597805977,
      "learning_rate": 1.8141362191506843e-05,
      "loss": 0.0023,
      "step": 13010
    },
    {
      "epoch": 1.3950498232079718,
      "grad_norm": 28.89183807373047,
      "learning_rate": 1.813993356905604e-05,
      "loss": 0.3568,
      "step": 13020
    },
    {
      "epoch": 1.396121290046073,
      "grad_norm": 0.08072762936353683,
      "learning_rate": 1.8138504946605238e-05,
      "loss": 0.2259,
      "step": 13030
    },
    {
      "epoch": 1.3971927568841744,
      "grad_norm": 0.04853726178407669,
      "learning_rate": 1.8137076324154434e-05,
      "loss": 0.1967,
      "step": 13040
    },
    {
      "epoch": 1.3982642237222758,
      "grad_norm": 0.07650220394134521,
      "learning_rate": 1.8135647701703633e-05,
      "loss": 0.2639,
      "step": 13050
    },
    {
      "epoch": 1.399335690560377,
      "grad_norm": 0.03333798050880432,
      "learning_rate": 1.8134219079252833e-05,
      "loss": 0.0413,
      "step": 13060
    },
    {
      "epoch": 1.4004071573984787,
      "grad_norm": 0.05173197016119957,
      "learning_rate": 1.813279045680203e-05,
      "loss": 0.1033,
      "step": 13070
    },
    {
      "epoch": 1.4014786242365798,
      "grad_norm": 74.38452911376953,
      "learning_rate": 1.8131361834351228e-05,
      "loss": 0.5392,
      "step": 13080
    },
    {
      "epoch": 1.4025500910746813,
      "grad_norm": 0.07176406681537628,
      "learning_rate": 1.8129933211900424e-05,
      "loss": 0.6713,
      "step": 13090
    },
    {
      "epoch": 1.4036215579127826,
      "grad_norm": 0.038738589733839035,
      "learning_rate": 1.8128504589449623e-05,
      "loss": 0.2983,
      "step": 13100
    },
    {
      "epoch": 1.404693024750884,
      "grad_norm": 0.03369242325425148,
      "learning_rate": 1.8127075966998823e-05,
      "loss": 0.3705,
      "step": 13110
    },
    {
      "epoch": 1.4057644915889853,
      "grad_norm": 17.4141845703125,
      "learning_rate": 1.8125647344548022e-05,
      "loss": 0.6899,
      "step": 13120
    },
    {
      "epoch": 1.4068359584270866,
      "grad_norm": 0.1982981562614441,
      "learning_rate": 1.8124218722097218e-05,
      "loss": 0.6161,
      "step": 13130
    },
    {
      "epoch": 1.407907425265188,
      "grad_norm": 2.679034948348999,
      "learning_rate": 1.8122790099646418e-05,
      "loss": 0.4209,
      "step": 13140
    },
    {
      "epoch": 1.4089788921032893,
      "grad_norm": 0.2389790266752243,
      "learning_rate": 1.8121361477195617e-05,
      "loss": 0.2043,
      "step": 13150
    },
    {
      "epoch": 1.4100503589413909,
      "grad_norm": 0.3550940752029419,
      "learning_rate": 1.8119932854744813e-05,
      "loss": 0.4732,
      "step": 13160
    },
    {
      "epoch": 1.4111218257794922,
      "grad_norm": 0.24272753298282623,
      "learning_rate": 1.8118504232294012e-05,
      "loss": 0.249,
      "step": 13170
    },
    {
      "epoch": 1.4121932926175935,
      "grad_norm": 0.06232057884335518,
      "learning_rate": 1.811707560984321e-05,
      "loss": 0.1709,
      "step": 13180
    },
    {
      "epoch": 1.4132647594556949,
      "grad_norm": 39.972389221191406,
      "learning_rate": 1.8115646987392408e-05,
      "loss": 0.4142,
      "step": 13190
    },
    {
      "epoch": 1.4143362262937962,
      "grad_norm": 89.5654525756836,
      "learning_rate": 1.8114218364941607e-05,
      "loss": 0.6518,
      "step": 13200
    },
    {
      "epoch": 1.4154076931318975,
      "grad_norm": 0.18522897362709045,
      "learning_rate": 1.8112789742490803e-05,
      "loss": 0.4071,
      "step": 13210
    },
    {
      "epoch": 1.4164791599699988,
      "grad_norm": 0.24982106685638428,
      "learning_rate": 1.8111361120040002e-05,
      "loss": 0.1023,
      "step": 13220
    },
    {
      "epoch": 1.4175506268081004,
      "grad_norm": 15.445528030395508,
      "learning_rate": 1.81099324975892e-05,
      "loss": 0.4622,
      "step": 13230
    },
    {
      "epoch": 1.4186220936462017,
      "grad_norm": 0.06407932192087173,
      "learning_rate": 1.8108503875138398e-05,
      "loss": 0.3126,
      "step": 13240
    },
    {
      "epoch": 1.419693560484303,
      "grad_norm": 21.891239166259766,
      "learning_rate": 1.8107075252687597e-05,
      "loss": 0.7542,
      "step": 13250
    },
    {
      "epoch": 1.4207650273224044,
      "grad_norm": 17.629026412963867,
      "learning_rate": 1.8105646630236796e-05,
      "loss": 0.1004,
      "step": 13260
    },
    {
      "epoch": 1.4218364941605057,
      "grad_norm": 0.025781383737921715,
      "learning_rate": 1.8104218007785996e-05,
      "loss": 0.0684,
      "step": 13270
    },
    {
      "epoch": 1.422907960998607,
      "grad_norm": 0.059726327657699585,
      "learning_rate": 1.8102789385335192e-05,
      "loss": 0.8114,
      "step": 13280
    },
    {
      "epoch": 1.4239794278367084,
      "grad_norm": 0.07744936645030975,
      "learning_rate": 1.810136076288439e-05,
      "loss": 0.0882,
      "step": 13290
    },
    {
      "epoch": 1.42505089467481,
      "grad_norm": 0.0851566419005394,
      "learning_rate": 1.809993214043359e-05,
      "loss": 0.0805,
      "step": 13300
    },
    {
      "epoch": 1.426122361512911,
      "grad_norm": 0.05743255466222763,
      "learning_rate": 1.8098503517982786e-05,
      "loss": 0.7717,
      "step": 13310
    },
    {
      "epoch": 1.4271938283510126,
      "grad_norm": 14.8526029586792,
      "learning_rate": 1.8097074895531986e-05,
      "loss": 0.4024,
      "step": 13320
    },
    {
      "epoch": 1.428265295189114,
      "grad_norm": 0.05916576832532883,
      "learning_rate": 1.8095646273081182e-05,
      "loss": 0.32,
      "step": 13330
    },
    {
      "epoch": 1.4293367620272153,
      "grad_norm": 0.029417859390378,
      "learning_rate": 1.809421765063038e-05,
      "loss": 0.5211,
      "step": 13340
    },
    {
      "epoch": 1.4304082288653166,
      "grad_norm": 15.14294147491455,
      "learning_rate": 1.809278902817958e-05,
      "loss": 0.3724,
      "step": 13350
    },
    {
      "epoch": 1.431479695703418,
      "grad_norm": 0.04308059439063072,
      "learning_rate": 1.8091360405728777e-05,
      "loss": 0.0047,
      "step": 13360
    },
    {
      "epoch": 1.4325511625415193,
      "grad_norm": 22.912811279296875,
      "learning_rate": 1.8089931783277976e-05,
      "loss": 0.7268,
      "step": 13370
    },
    {
      "epoch": 1.4336226293796206,
      "grad_norm": 4.001075744628906,
      "learning_rate": 1.8088503160827172e-05,
      "loss": 0.1795,
      "step": 13380
    },
    {
      "epoch": 1.4346940962177221,
      "grad_norm": 0.02754025347530842,
      "learning_rate": 1.808707453837637e-05,
      "loss": 0.344,
      "step": 13390
    },
    {
      "epoch": 1.4357655630558235,
      "grad_norm": 20.150863647460938,
      "learning_rate": 1.808564591592557e-05,
      "loss": 0.5536,
      "step": 13400
    },
    {
      "epoch": 1.4368370298939248,
      "grad_norm": 0.16524243354797363,
      "learning_rate": 1.808421729347477e-05,
      "loss": 0.1106,
      "step": 13410
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.12953214347362518,
      "learning_rate": 1.8082788671023966e-05,
      "loss": 0.2379,
      "step": 13420
    },
    {
      "epoch": 1.4389799635701275,
      "grad_norm": 0.07110784947872162,
      "learning_rate": 1.8081360048573165e-05,
      "loss": 0.6041,
      "step": 13430
    },
    {
      "epoch": 1.4400514304082288,
      "grad_norm": 0.14253942668437958,
      "learning_rate": 1.8079931426122365e-05,
      "loss": 0.2867,
      "step": 13440
    },
    {
      "epoch": 1.4411228972463301,
      "grad_norm": 223.10658264160156,
      "learning_rate": 1.807850280367156e-05,
      "loss": 0.446,
      "step": 13450
    },
    {
      "epoch": 1.4421943640844317,
      "grad_norm": 23.376731872558594,
      "learning_rate": 1.807707418122076e-05,
      "loss": 0.1934,
      "step": 13460
    },
    {
      "epoch": 1.443265830922533,
      "grad_norm": 0.038825079798698425,
      "learning_rate": 1.807564555876996e-05,
      "loss": 0.5313,
      "step": 13470
    },
    {
      "epoch": 1.4443372977606344,
      "grad_norm": 0.11343029141426086,
      "learning_rate": 1.8074216936319155e-05,
      "loss": 0.0894,
      "step": 13480
    },
    {
      "epoch": 1.4454087645987357,
      "grad_norm": 0.09092527627944946,
      "learning_rate": 1.8072788313868355e-05,
      "loss": 0.4949,
      "step": 13490
    },
    {
      "epoch": 1.446480231436837,
      "grad_norm": 0.0638449490070343,
      "learning_rate": 1.807135969141755e-05,
      "loss": 0.115,
      "step": 13500
    },
    {
      "epoch": 1.4475516982749383,
      "grad_norm": 40.31906509399414,
      "learning_rate": 1.806993106896675e-05,
      "loss": 0.45,
      "step": 13510
    },
    {
      "epoch": 1.4486231651130397,
      "grad_norm": 0.16093739867210388,
      "learning_rate": 1.8068502446515946e-05,
      "loss": 0.2471,
      "step": 13520
    },
    {
      "epoch": 1.4496946319511412,
      "grad_norm": 15.125861167907715,
      "learning_rate": 1.8067073824065145e-05,
      "loss": 0.0945,
      "step": 13530
    },
    {
      "epoch": 1.4507660987892423,
      "grad_norm": 0.05325090512633324,
      "learning_rate": 1.8065645201614345e-05,
      "loss": 0.0017,
      "step": 13540
    },
    {
      "epoch": 1.451837565627344,
      "grad_norm": 0.7439336776733398,
      "learning_rate": 1.8064216579163544e-05,
      "loss": 0.3456,
      "step": 13550
    },
    {
      "epoch": 1.4529090324654452,
      "grad_norm": 24.083919525146484,
      "learning_rate": 1.806278795671274e-05,
      "loss": 0.2942,
      "step": 13560
    },
    {
      "epoch": 1.4539804993035466,
      "grad_norm": 0.44070443511009216,
      "learning_rate": 1.806135933426194e-05,
      "loss": 0.4115,
      "step": 13570
    },
    {
      "epoch": 1.455051966141648,
      "grad_norm": 0.01881231553852558,
      "learning_rate": 1.805993071181114e-05,
      "loss": 0.0946,
      "step": 13580
    },
    {
      "epoch": 1.4561234329797492,
      "grad_norm": 0.21865426003932953,
      "learning_rate": 1.8058502089360338e-05,
      "loss": 0.2063,
      "step": 13590
    },
    {
      "epoch": 1.4571948998178508,
      "grad_norm": 0.3481786847114563,
      "learning_rate": 1.8057073466909534e-05,
      "loss": 0.3876,
      "step": 13600
    },
    {
      "epoch": 1.4582663666559519,
      "grad_norm": 0.12717564404010773,
      "learning_rate": 1.8055644844458734e-05,
      "loss": 0.4593,
      "step": 13610
    },
    {
      "epoch": 1.4593378334940534,
      "grad_norm": 0.7749355435371399,
      "learning_rate": 1.805421622200793e-05,
      "loss": 0.3379,
      "step": 13620
    },
    {
      "epoch": 1.4604093003321548,
      "grad_norm": 0.06906981766223907,
      "learning_rate": 1.805278759955713e-05,
      "loss": 0.0779,
      "step": 13630
    },
    {
      "epoch": 1.461480767170256,
      "grad_norm": 0.01982877403497696,
      "learning_rate": 1.8051358977106325e-05,
      "loss": 0.8196,
      "step": 13640
    },
    {
      "epoch": 1.4625522340083574,
      "grad_norm": 0.10236475616693497,
      "learning_rate": 1.8049930354655524e-05,
      "loss": 0.5073,
      "step": 13650
    },
    {
      "epoch": 1.4636237008464588,
      "grad_norm": 42.906917572021484,
      "learning_rate": 1.8048501732204724e-05,
      "loss": 0.5594,
      "step": 13660
    },
    {
      "epoch": 1.46469516768456,
      "grad_norm": 26.403051376342773,
      "learning_rate": 1.804707310975392e-05,
      "loss": 0.5991,
      "step": 13670
    },
    {
      "epoch": 1.4657666345226614,
      "grad_norm": 0.04775775969028473,
      "learning_rate": 1.804564448730312e-05,
      "loss": 0.5275,
      "step": 13680
    },
    {
      "epoch": 1.466838101360763,
      "grad_norm": 0.13042525947093964,
      "learning_rate": 1.804421586485232e-05,
      "loss": 0.1594,
      "step": 13690
    },
    {
      "epoch": 1.4679095681988643,
      "grad_norm": 0.9877128601074219,
      "learning_rate": 1.8042787242401518e-05,
      "loss": 0.2037,
      "step": 13700
    },
    {
      "epoch": 1.4689810350369656,
      "grad_norm": 0.048256777226924896,
      "learning_rate": 1.8041358619950714e-05,
      "loss": 0.5451,
      "step": 13710
    },
    {
      "epoch": 1.470052501875067,
      "grad_norm": 0.06481791287660599,
      "learning_rate": 1.8039929997499913e-05,
      "loss": 0.0026,
      "step": 13720
    },
    {
      "epoch": 1.4711239687131683,
      "grad_norm": 2.6073338985443115,
      "learning_rate": 1.8038501375049112e-05,
      "loss": 0.6805,
      "step": 13730
    },
    {
      "epoch": 1.4721954355512696,
      "grad_norm": 0.20561550557613373,
      "learning_rate": 1.803707275259831e-05,
      "loss": 0.2191,
      "step": 13740
    },
    {
      "epoch": 1.473266902389371,
      "grad_norm": 44.04977798461914,
      "learning_rate": 1.8035644130147508e-05,
      "loss": 0.1401,
      "step": 13750
    },
    {
      "epoch": 1.4743383692274725,
      "grad_norm": 0.1447741687297821,
      "learning_rate": 1.8034215507696704e-05,
      "loss": 0.5526,
      "step": 13760
    },
    {
      "epoch": 1.4754098360655736,
      "grad_norm": 41.71139144897461,
      "learning_rate": 1.8032786885245903e-05,
      "loss": 0.3425,
      "step": 13770
    },
    {
      "epoch": 1.4764813029036752,
      "grad_norm": 20.62628746032715,
      "learning_rate": 1.8031358262795102e-05,
      "loss": 0.382,
      "step": 13780
    },
    {
      "epoch": 1.4775527697417765,
      "grad_norm": 0.37891989946365356,
      "learning_rate": 1.80299296403443e-05,
      "loss": 0.3196,
      "step": 13790
    },
    {
      "epoch": 1.4786242365798778,
      "grad_norm": 0.05401749163866043,
      "learning_rate": 1.8028501017893498e-05,
      "loss": 0.138,
      "step": 13800
    },
    {
      "epoch": 1.4796957034179792,
      "grad_norm": 0.08258270472288132,
      "learning_rate": 1.8027072395442694e-05,
      "loss": 0.2689,
      "step": 13810
    },
    {
      "epoch": 1.4807671702560805,
      "grad_norm": 0.6434524059295654,
      "learning_rate": 1.8025643772991893e-05,
      "loss": 0.3891,
      "step": 13820
    },
    {
      "epoch": 1.481838637094182,
      "grad_norm": 0.2028358280658722,
      "learning_rate": 1.8024215150541093e-05,
      "loss": 0.1265,
      "step": 13830
    },
    {
      "epoch": 1.4829101039322832,
      "grad_norm": 1353.7845458984375,
      "learning_rate": 1.8022786528090292e-05,
      "loss": 0.3816,
      "step": 13840
    },
    {
      "epoch": 1.4839815707703847,
      "grad_norm": 0.027730818837881088,
      "learning_rate": 1.8021357905639488e-05,
      "loss": 0.2542,
      "step": 13850
    },
    {
      "epoch": 1.485053037608486,
      "grad_norm": 0.01953318901360035,
      "learning_rate": 1.8019929283188687e-05,
      "loss": 0.0973,
      "step": 13860
    },
    {
      "epoch": 1.4861245044465874,
      "grad_norm": 43.31329345703125,
      "learning_rate": 1.8018500660737887e-05,
      "loss": 0.3294,
      "step": 13870
    },
    {
      "epoch": 1.4871959712846887,
      "grad_norm": 51.998741149902344,
      "learning_rate": 1.8017072038287083e-05,
      "loss": 0.4225,
      "step": 13880
    },
    {
      "epoch": 1.48826743812279,
      "grad_norm": 0.039009939879179,
      "learning_rate": 1.8015643415836282e-05,
      "loss": 0.4214,
      "step": 13890
    },
    {
      "epoch": 1.4893389049608914,
      "grad_norm": 48.29808807373047,
      "learning_rate": 1.801421479338548e-05,
      "loss": 0.2289,
      "step": 13900
    },
    {
      "epoch": 1.4904103717989927,
      "grad_norm": 0.09710437059402466,
      "learning_rate": 1.8012786170934677e-05,
      "loss": 0.2294,
      "step": 13910
    },
    {
      "epoch": 1.4914818386370943,
      "grad_norm": 0.09018559008836746,
      "learning_rate": 1.8011357548483877e-05,
      "loss": 0.3248,
      "step": 13920
    },
    {
      "epoch": 1.4925533054751956,
      "grad_norm": 0.04862054064869881,
      "learning_rate": 1.8009928926033073e-05,
      "loss": 0.2328,
      "step": 13930
    },
    {
      "epoch": 1.493624772313297,
      "grad_norm": 0.09302375465631485,
      "learning_rate": 1.8008500303582272e-05,
      "loss": 0.4128,
      "step": 13940
    },
    {
      "epoch": 1.4946962391513983,
      "grad_norm": 0.07045452296733856,
      "learning_rate": 1.8007071681131468e-05,
      "loss": 0.1384,
      "step": 13950
    },
    {
      "epoch": 1.4957677059894996,
      "grad_norm": 0.03503686934709549,
      "learning_rate": 1.8005643058680667e-05,
      "loss": 0.4091,
      "step": 13960
    },
    {
      "epoch": 1.496839172827601,
      "grad_norm": 0.02987525425851345,
      "learning_rate": 1.8004214436229867e-05,
      "loss": 0.0096,
      "step": 13970
    },
    {
      "epoch": 1.4979106396657023,
      "grad_norm": 0.07070067524909973,
      "learning_rate": 1.8002785813779066e-05,
      "loss": 0.19,
      "step": 13980
    },
    {
      "epoch": 1.4989821065038038,
      "grad_norm": 0.017076220363378525,
      "learning_rate": 1.8001357191328262e-05,
      "loss": 0.4568,
      "step": 13990
    },
    {
      "epoch": 1.500053573341905,
      "grad_norm": 0.5367572903633118,
      "learning_rate": 1.799992856887746e-05,
      "loss": 0.581,
      "step": 14000
    },
    {
      "epoch": 1.5011250401800065,
      "grad_norm": 1.2835215330123901,
      "learning_rate": 1.799849994642666e-05,
      "loss": 0.5242,
      "step": 14010
    },
    {
      "epoch": 1.5021965070181078,
      "grad_norm": 1.5003224611282349,
      "learning_rate": 1.799707132397586e-05,
      "loss": 0.3581,
      "step": 14020
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.15130561590194702,
      "learning_rate": 1.7995642701525056e-05,
      "loss": 0.28,
      "step": 14030
    },
    {
      "epoch": 1.5043394406943105,
      "grad_norm": 24.33197784423828,
      "learning_rate": 1.7994214079074256e-05,
      "loss": 0.3643,
      "step": 14040
    },
    {
      "epoch": 1.5054109075324118,
      "grad_norm": 0.13253434002399445,
      "learning_rate": 1.799278545662345e-05,
      "loss": 0.3062,
      "step": 14050
    },
    {
      "epoch": 1.5064823743705134,
      "grad_norm": 0.2417149543762207,
      "learning_rate": 1.799135683417265e-05,
      "loss": 0.518,
      "step": 14060
    },
    {
      "epoch": 1.5075538412086145,
      "grad_norm": 0.04565988481044769,
      "learning_rate": 1.7989928211721847e-05,
      "loss": 0.2055,
      "step": 14070
    },
    {
      "epoch": 1.508625308046716,
      "grad_norm": 0.2906331419944763,
      "learning_rate": 1.7988499589271046e-05,
      "loss": 0.4344,
      "step": 14080
    },
    {
      "epoch": 1.5096967748848173,
      "grad_norm": 0.25526583194732666,
      "learning_rate": 1.7987070966820246e-05,
      "loss": 0.1881,
      "step": 14090
    },
    {
      "epoch": 1.5107682417229187,
      "grad_norm": 26.277545928955078,
      "learning_rate": 1.798564234436944e-05,
      "loss": 0.3529,
      "step": 14100
    },
    {
      "epoch": 1.51183970856102,
      "grad_norm": 0.06394714117050171,
      "learning_rate": 1.798421372191864e-05,
      "loss": 0.5315,
      "step": 14110
    },
    {
      "epoch": 1.5129111753991213,
      "grad_norm": 1.4526362419128418,
      "learning_rate": 1.798278509946784e-05,
      "loss": 0.5067,
      "step": 14120
    },
    {
      "epoch": 1.513982642237223,
      "grad_norm": 0.2886326313018799,
      "learning_rate": 1.7981356477017036e-05,
      "loss": 0.0081,
      "step": 14130
    },
    {
      "epoch": 1.515054109075324,
      "grad_norm": 0.1808830201625824,
      "learning_rate": 1.7979927854566236e-05,
      "loss": 0.3803,
      "step": 14140
    },
    {
      "epoch": 1.5161255759134256,
      "grad_norm": 0.0825904831290245,
      "learning_rate": 1.7978499232115435e-05,
      "loss": 0.1631,
      "step": 14150
    },
    {
      "epoch": 1.517197042751527,
      "grad_norm": 0.0491466261446476,
      "learning_rate": 1.7977070609664634e-05,
      "loss": 0.6278,
      "step": 14160
    },
    {
      "epoch": 1.5182685095896282,
      "grad_norm": 0.04074208810925484,
      "learning_rate": 1.797564198721383e-05,
      "loss": 0.0019,
      "step": 14170
    },
    {
      "epoch": 1.5193399764277296,
      "grad_norm": 0.02744881436228752,
      "learning_rate": 1.797421336476303e-05,
      "loss": 0.1774,
      "step": 14180
    },
    {
      "epoch": 1.5204114432658309,
      "grad_norm": 0.020619062706828117,
      "learning_rate": 1.7972784742312226e-05,
      "loss": 0.0011,
      "step": 14190
    },
    {
      "epoch": 1.5214829101039324,
      "grad_norm": 0.06591110676527023,
      "learning_rate": 1.7971356119861425e-05,
      "loss": 0.0015,
      "step": 14200
    },
    {
      "epoch": 1.5225543769420335,
      "grad_norm": 19.570035934448242,
      "learning_rate": 1.7969927497410624e-05,
      "loss": 0.7095,
      "step": 14210
    },
    {
      "epoch": 1.523625843780135,
      "grad_norm": 65.6338882446289,
      "learning_rate": 1.796849887495982e-05,
      "loss": 0.4401,
      "step": 14220
    },
    {
      "epoch": 1.5246973106182362,
      "grad_norm": 0.14491286873817444,
      "learning_rate": 1.796707025250902e-05,
      "loss": 0.3603,
      "step": 14230
    },
    {
      "epoch": 1.5257687774563378,
      "grad_norm": 18.239709854125977,
      "learning_rate": 1.7965641630058216e-05,
      "loss": 0.5379,
      "step": 14240
    },
    {
      "epoch": 1.526840244294439,
      "grad_norm": 14.929299354553223,
      "learning_rate": 1.7964213007607415e-05,
      "loss": 0.3988,
      "step": 14250
    },
    {
      "epoch": 1.5279117111325404,
      "grad_norm": 20.10329246520996,
      "learning_rate": 1.7962784385156614e-05,
      "loss": 0.3222,
      "step": 14260
    },
    {
      "epoch": 1.5289831779706418,
      "grad_norm": 0.22680999338626862,
      "learning_rate": 1.7961355762705814e-05,
      "loss": 0.3703,
      "step": 14270
    },
    {
      "epoch": 1.530054644808743,
      "grad_norm": 0.20276370644569397,
      "learning_rate": 1.795992714025501e-05,
      "loss": 0.0044,
      "step": 14280
    },
    {
      "epoch": 1.5311261116468446,
      "grad_norm": 0.015517588704824448,
      "learning_rate": 1.795849851780421e-05,
      "loss": 0.2524,
      "step": 14290
    },
    {
      "epoch": 1.5321975784849458,
      "grad_norm": 0.010883903130888939,
      "learning_rate": 1.795706989535341e-05,
      "loss": 0.2644,
      "step": 14300
    },
    {
      "epoch": 1.5332690453230473,
      "grad_norm": 0.027881382033228874,
      "learning_rate": 1.7955641272902605e-05,
      "loss": 0.2943,
      "step": 14310
    },
    {
      "epoch": 1.5343405121611486,
      "grad_norm": 0.3054894506931305,
      "learning_rate": 1.7954212650451804e-05,
      "loss": 0.8937,
      "step": 14320
    },
    {
      "epoch": 1.53541197899925,
      "grad_norm": 0.449952095746994,
      "learning_rate": 1.7952784028001003e-05,
      "loss": 0.227,
      "step": 14330
    },
    {
      "epoch": 1.5364834458373513,
      "grad_norm": 0.0851135328412056,
      "learning_rate": 1.79513554055502e-05,
      "loss": 0.3003,
      "step": 14340
    },
    {
      "epoch": 1.5375549126754526,
      "grad_norm": 0.0440216101706028,
      "learning_rate": 1.79499267830994e-05,
      "loss": 0.0068,
      "step": 14350
    },
    {
      "epoch": 1.5386263795135542,
      "grad_norm": 0.04532080143690109,
      "learning_rate": 1.7948498160648595e-05,
      "loss": 0.0061,
      "step": 14360
    },
    {
      "epoch": 1.5396978463516553,
      "grad_norm": 24.781280517578125,
      "learning_rate": 1.7947069538197794e-05,
      "loss": 0.6722,
      "step": 14370
    },
    {
      "epoch": 1.5407693131897569,
      "grad_norm": 0.08930026739835739,
      "learning_rate": 1.7945640915746993e-05,
      "loss": 0.4979,
      "step": 14380
    },
    {
      "epoch": 1.5418407800278582,
      "grad_norm": 0.06932492554187775,
      "learning_rate": 1.794421229329619e-05,
      "loss": 0.1744,
      "step": 14390
    },
    {
      "epoch": 1.5429122468659595,
      "grad_norm": 0.11227691918611526,
      "learning_rate": 1.794278367084539e-05,
      "loss": 0.162,
      "step": 14400
    },
    {
      "epoch": 1.5439837137040608,
      "grad_norm": 0.04547930136322975,
      "learning_rate": 1.7941355048394588e-05,
      "loss": 0.0013,
      "step": 14410
    },
    {
      "epoch": 1.5450551805421622,
      "grad_norm": 0.15426738560199738,
      "learning_rate": 1.7939926425943784e-05,
      "loss": 0.369,
      "step": 14420
    },
    {
      "epoch": 1.5461266473802637,
      "grad_norm": 18.219045639038086,
      "learning_rate": 1.7938497803492983e-05,
      "loss": 0.2421,
      "step": 14430
    },
    {
      "epoch": 1.5471981142183648,
      "grad_norm": 18.243717193603516,
      "learning_rate": 1.7937069181042183e-05,
      "loss": 0.6051,
      "step": 14440
    },
    {
      "epoch": 1.5482695810564664,
      "grad_norm": 0.06972057372331619,
      "learning_rate": 1.7935640558591382e-05,
      "loss": 0.347,
      "step": 14450
    },
    {
      "epoch": 1.5493410478945675,
      "grad_norm": 0.5199337005615234,
      "learning_rate": 1.7934211936140578e-05,
      "loss": 0.8196,
      "step": 14460
    },
    {
      "epoch": 1.550412514732669,
      "grad_norm": 0.1664646863937378,
      "learning_rate": 1.7932783313689777e-05,
      "loss": 0.428,
      "step": 14470
    },
    {
      "epoch": 1.5514839815707704,
      "grad_norm": 30.832836151123047,
      "learning_rate": 1.7931354691238973e-05,
      "loss": 0.7001,
      "step": 14480
    },
    {
      "epoch": 1.5525554484088717,
      "grad_norm": 21.718412399291992,
      "learning_rate": 1.7929926068788173e-05,
      "loss": 0.5651,
      "step": 14490
    },
    {
      "epoch": 1.5536269152469733,
      "grad_norm": 0.49019578099250793,
      "learning_rate": 1.792849744633737e-05,
      "loss": 0.2128,
      "step": 14500
    },
    {
      "epoch": 1.5546983820850744,
      "grad_norm": 0.4814697206020355,
      "learning_rate": 1.7927068823886568e-05,
      "loss": 0.0069,
      "step": 14510
    },
    {
      "epoch": 1.555769848923176,
      "grad_norm": 0.2418804168701172,
      "learning_rate": 1.7925640201435768e-05,
      "loss": 0.3205,
      "step": 14520
    },
    {
      "epoch": 1.556841315761277,
      "grad_norm": 35.89020919799805,
      "learning_rate": 1.7924211578984963e-05,
      "loss": 0.5416,
      "step": 14530
    },
    {
      "epoch": 1.5579127825993786,
      "grad_norm": 15.47725772857666,
      "learning_rate": 1.7922782956534163e-05,
      "loss": 0.4476,
      "step": 14540
    },
    {
      "epoch": 1.55898424943748,
      "grad_norm": 2.2017762660980225,
      "learning_rate": 1.7921354334083362e-05,
      "loss": 0.0068,
      "step": 14550
    },
    {
      "epoch": 1.5600557162755813,
      "grad_norm": 0.2890560030937195,
      "learning_rate": 1.7919925711632558e-05,
      "loss": 0.3131,
      "step": 14560
    },
    {
      "epoch": 1.5611271831136826,
      "grad_norm": 0.030530676245689392,
      "learning_rate": 1.7918497089181758e-05,
      "loss": 0.15,
      "step": 14570
    },
    {
      "epoch": 1.562198649951784,
      "grad_norm": 21.633798599243164,
      "learning_rate": 1.7917068466730957e-05,
      "loss": 0.5415,
      "step": 14580
    },
    {
      "epoch": 1.5632701167898855,
      "grad_norm": 19.162351608276367,
      "learning_rate": 1.7915639844280156e-05,
      "loss": 0.6499,
      "step": 14590
    },
    {
      "epoch": 1.5643415836279866,
      "grad_norm": 0.19508817791938782,
      "learning_rate": 1.7914211221829352e-05,
      "loss": 0.199,
      "step": 14600
    },
    {
      "epoch": 1.5654130504660881,
      "grad_norm": 0.0492604598402977,
      "learning_rate": 1.791278259937855e-05,
      "loss": 0.002,
      "step": 14610
    },
    {
      "epoch": 1.5664845173041895,
      "grad_norm": 19.866426467895508,
      "learning_rate": 1.7911353976927748e-05,
      "loss": 0.4412,
      "step": 14620
    },
    {
      "epoch": 1.5675559841422908,
      "grad_norm": 0.050939928740262985,
      "learning_rate": 1.7909925354476947e-05,
      "loss": 0.0021,
      "step": 14630
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 0.017277799546718597,
      "learning_rate": 1.7908496732026146e-05,
      "loss": 0.1337,
      "step": 14640
    },
    {
      "epoch": 1.5696989178184935,
      "grad_norm": 0.24551144242286682,
      "learning_rate": 1.7907068109575342e-05,
      "loss": 0.1424,
      "step": 14650
    },
    {
      "epoch": 1.570770384656595,
      "grad_norm": 19.7807674407959,
      "learning_rate": 1.7905639487124542e-05,
      "loss": 0.4089,
      "step": 14660
    },
    {
      "epoch": 1.5718418514946961,
      "grad_norm": 0.10912227630615234,
      "learning_rate": 1.7904210864673738e-05,
      "loss": 0.002,
      "step": 14670
    },
    {
      "epoch": 1.5729133183327977,
      "grad_norm": 0.05090947821736336,
      "learning_rate": 1.7902782242222937e-05,
      "loss": 0.3434,
      "step": 14680
    },
    {
      "epoch": 1.573984785170899,
      "grad_norm": 0.09194012731313705,
      "learning_rate": 1.7901353619772136e-05,
      "loss": 0.0018,
      "step": 14690
    },
    {
      "epoch": 1.5750562520090003,
      "grad_norm": 23.25752067565918,
      "learning_rate": 1.7899924997321332e-05,
      "loss": 0.899,
      "step": 14700
    },
    {
      "epoch": 1.5761277188471017,
      "grad_norm": 19.84165382385254,
      "learning_rate": 1.7898496374870532e-05,
      "loss": 0.1804,
      "step": 14710
    },
    {
      "epoch": 1.577199185685203,
      "grad_norm": 0.2182110846042633,
      "learning_rate": 1.789706775241973e-05,
      "loss": 0.6719,
      "step": 14720
    },
    {
      "epoch": 1.5782706525233046,
      "grad_norm": 0.21314601600170135,
      "learning_rate": 1.789563912996893e-05,
      "loss": 0.3058,
      "step": 14730
    },
    {
      "epoch": 1.5793421193614057,
      "grad_norm": 0.10305336862802505,
      "learning_rate": 1.7894210507518126e-05,
      "loss": 0.1328,
      "step": 14740
    },
    {
      "epoch": 1.5804135861995072,
      "grad_norm": 22.78420066833496,
      "learning_rate": 1.7892781885067326e-05,
      "loss": 0.5707,
      "step": 14750
    },
    {
      "epoch": 1.5814850530376083,
      "grad_norm": 17.47719383239746,
      "learning_rate": 1.7891353262616525e-05,
      "loss": 0.331,
      "step": 14760
    },
    {
      "epoch": 1.5825565198757099,
      "grad_norm": 0.1761300265789032,
      "learning_rate": 1.788992464016572e-05,
      "loss": 0.3634,
      "step": 14770
    },
    {
      "epoch": 1.5836279867138112,
      "grad_norm": 0.0884917601943016,
      "learning_rate": 1.788849601771492e-05,
      "loss": 0.4688,
      "step": 14780
    },
    {
      "epoch": 1.5846994535519126,
      "grad_norm": 0.17942534387111664,
      "learning_rate": 1.7887067395264117e-05,
      "loss": 0.4706,
      "step": 14790
    },
    {
      "epoch": 1.5857709203900139,
      "grad_norm": 0.0565788634121418,
      "learning_rate": 1.7885638772813316e-05,
      "loss": 0.7348,
      "step": 14800
    },
    {
      "epoch": 1.5868423872281152,
      "grad_norm": 0.8655588626861572,
      "learning_rate": 1.7884210150362515e-05,
      "loss": 0.1884,
      "step": 14810
    },
    {
      "epoch": 1.5879138540662168,
      "grad_norm": 0.034128330647945404,
      "learning_rate": 1.788278152791171e-05,
      "loss": 0.2128,
      "step": 14820
    },
    {
      "epoch": 1.5889853209043179,
      "grad_norm": 18.76439094543457,
      "learning_rate": 1.788135290546091e-05,
      "loss": 0.2586,
      "step": 14830
    },
    {
      "epoch": 1.5900567877424194,
      "grad_norm": 19.305753707885742,
      "learning_rate": 1.787992428301011e-05,
      "loss": 0.4407,
      "step": 14840
    },
    {
      "epoch": 1.5911282545805208,
      "grad_norm": 0.3408278226852417,
      "learning_rate": 1.7878495660559306e-05,
      "loss": 0.1174,
      "step": 14850
    },
    {
      "epoch": 1.592199721418622,
      "grad_norm": 0.2997146248817444,
      "learning_rate": 1.7877067038108505e-05,
      "loss": 0.2668,
      "step": 14860
    },
    {
      "epoch": 1.5932711882567234,
      "grad_norm": 0.7482490539550781,
      "learning_rate": 1.7875638415657705e-05,
      "loss": 0.1879,
      "step": 14870
    },
    {
      "epoch": 1.5943426550948248,
      "grad_norm": 0.011931360699236393,
      "learning_rate": 1.7874209793206904e-05,
      "loss": 0.0037,
      "step": 14880
    },
    {
      "epoch": 1.5954141219329263,
      "grad_norm": 0.14543017745018005,
      "learning_rate": 1.78727811707561e-05,
      "loss": 0.3358,
      "step": 14890
    },
    {
      "epoch": 1.5964855887710274,
      "grad_norm": 14.85846996307373,
      "learning_rate": 1.78713525483053e-05,
      "loss": 0.4978,
      "step": 14900
    },
    {
      "epoch": 1.597557055609129,
      "grad_norm": 20.163000106811523,
      "learning_rate": 1.7869923925854495e-05,
      "loss": 0.224,
      "step": 14910
    },
    {
      "epoch": 1.5986285224472303,
      "grad_norm": 0.010476497001945972,
      "learning_rate": 1.7868495303403695e-05,
      "loss": 0.3686,
      "step": 14920
    },
    {
      "epoch": 1.5996999892853316,
      "grad_norm": 0.06972578912973404,
      "learning_rate": 1.7867066680952894e-05,
      "loss": 0.3482,
      "step": 14930
    },
    {
      "epoch": 1.600771456123433,
      "grad_norm": 22.50489044189453,
      "learning_rate": 1.786563805850209e-05,
      "loss": 0.3875,
      "step": 14940
    },
    {
      "epoch": 1.6018429229615343,
      "grad_norm": 0.10656929016113281,
      "learning_rate": 1.786420943605129e-05,
      "loss": 0.3774,
      "step": 14950
    },
    {
      "epoch": 1.6029143897996359,
      "grad_norm": 0.25753000378608704,
      "learning_rate": 1.7862780813600485e-05,
      "loss": 0.1551,
      "step": 14960
    },
    {
      "epoch": 1.603985856637737,
      "grad_norm": 0.14173045754432678,
      "learning_rate": 1.7861352191149685e-05,
      "loss": 0.4286,
      "step": 14970
    },
    {
      "epoch": 1.6050573234758385,
      "grad_norm": 0.031261932104825974,
      "learning_rate": 1.7859923568698884e-05,
      "loss": 0.2355,
      "step": 14980
    },
    {
      "epoch": 1.6061287903139396,
      "grad_norm": 21.036739349365234,
      "learning_rate": 1.785849494624808e-05,
      "loss": 0.3643,
      "step": 14990
    },
    {
      "epoch": 1.6072002571520412,
      "grad_norm": 0.49762052297592163,
      "learning_rate": 1.785706632379728e-05,
      "loss": 0.0128,
      "step": 15000
    },
    {
      "epoch": 1.6082717239901425,
      "grad_norm": 0.1970648318529129,
      "learning_rate": 1.785563770134648e-05,
      "loss": 0.2106,
      "step": 15010
    },
    {
      "epoch": 1.6093431908282438,
      "grad_norm": 17.297061920166016,
      "learning_rate": 1.7854209078895678e-05,
      "loss": 0.5261,
      "step": 15020
    },
    {
      "epoch": 1.6104146576663452,
      "grad_norm": 31.065332412719727,
      "learning_rate": 1.7852780456444874e-05,
      "loss": 1.0813,
      "step": 15030
    },
    {
      "epoch": 1.6114861245044465,
      "grad_norm": 0.15133491158485413,
      "learning_rate": 1.7851351833994074e-05,
      "loss": 0.1627,
      "step": 15040
    },
    {
      "epoch": 1.612557591342548,
      "grad_norm": 0.16994301974773407,
      "learning_rate": 1.7849923211543273e-05,
      "loss": 0.0084,
      "step": 15050
    },
    {
      "epoch": 1.6136290581806492,
      "grad_norm": 0.08366977423429489,
      "learning_rate": 1.784849458909247e-05,
      "loss": 0.2808,
      "step": 15060
    },
    {
      "epoch": 1.6147005250187507,
      "grad_norm": 18.774593353271484,
      "learning_rate": 1.7847065966641668e-05,
      "loss": 0.6227,
      "step": 15070
    },
    {
      "epoch": 1.615771991856852,
      "grad_norm": 0.12406175583600998,
      "learning_rate": 1.7845637344190864e-05,
      "loss": 0.0058,
      "step": 15080
    },
    {
      "epoch": 1.6168434586949534,
      "grad_norm": 21.467538833618164,
      "learning_rate": 1.7844208721740064e-05,
      "loss": 0.7413,
      "step": 15090
    },
    {
      "epoch": 1.6179149255330547,
      "grad_norm": 18.742538452148438,
      "learning_rate": 1.784278009928926e-05,
      "loss": 0.457,
      "step": 15100
    },
    {
      "epoch": 1.618986392371156,
      "grad_norm": 0.5515047907829285,
      "learning_rate": 1.784135147683846e-05,
      "loss": 0.0161,
      "step": 15110
    },
    {
      "epoch": 1.6200578592092576,
      "grad_norm": 140.3668975830078,
      "learning_rate": 1.783992285438766e-05,
      "loss": 0.3153,
      "step": 15120
    },
    {
      "epoch": 1.6211293260473587,
      "grad_norm": 0.1112605556845665,
      "learning_rate": 1.7838494231936854e-05,
      "loss": 0.1789,
      "step": 15130
    },
    {
      "epoch": 1.6222007928854603,
      "grad_norm": 16.329423904418945,
      "learning_rate": 1.7837065609486054e-05,
      "loss": 0.3152,
      "step": 15140
    },
    {
      "epoch": 1.6232722597235616,
      "grad_norm": 0.28066885471343994,
      "learning_rate": 1.7835636987035253e-05,
      "loss": 0.2076,
      "step": 15150
    },
    {
      "epoch": 1.624343726561663,
      "grad_norm": 0.07695300877094269,
      "learning_rate": 1.7834208364584452e-05,
      "loss": 0.5885,
      "step": 15160
    },
    {
      "epoch": 1.6254151933997643,
      "grad_norm": 0.08114772289991379,
      "learning_rate": 1.7832779742133652e-05,
      "loss": 0.3929,
      "step": 15170
    },
    {
      "epoch": 1.6264866602378656,
      "grad_norm": 0.06732937693595886,
      "learning_rate": 1.7831351119682848e-05,
      "loss": 0.1184,
      "step": 15180
    },
    {
      "epoch": 1.6275581270759671,
      "grad_norm": 0.20636312663555145,
      "learning_rate": 1.7829922497232047e-05,
      "loss": 0.4802,
      "step": 15190
    },
    {
      "epoch": 1.6286295939140683,
      "grad_norm": 0.062429383397102356,
      "learning_rate": 1.7828493874781243e-05,
      "loss": 0.2605,
      "step": 15200
    },
    {
      "epoch": 1.6297010607521698,
      "grad_norm": 0.288983017206192,
      "learning_rate": 1.7827065252330442e-05,
      "loss": 0.3154,
      "step": 15210
    },
    {
      "epoch": 1.630772527590271,
      "grad_norm": 1.0906141996383667,
      "learning_rate": 1.782563662987964e-05,
      "loss": 0.6346,
      "step": 15220
    },
    {
      "epoch": 1.6318439944283725,
      "grad_norm": 17.239086151123047,
      "learning_rate": 1.7824208007428838e-05,
      "loss": 0.2429,
      "step": 15230
    },
    {
      "epoch": 1.6329154612664738,
      "grad_norm": 18.671649932861328,
      "learning_rate": 1.7822779384978037e-05,
      "loss": 0.3336,
      "step": 15240
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.21316082775592804,
      "learning_rate": 1.7821350762527233e-05,
      "loss": 0.5029,
      "step": 15250
    },
    {
      "epoch": 1.6350583949426767,
      "grad_norm": 0.20878079533576965,
      "learning_rate": 1.7819922140076433e-05,
      "loss": 0.2507,
      "step": 15260
    },
    {
      "epoch": 1.6361298617807778,
      "grad_norm": 0.1662931889295578,
      "learning_rate": 1.781849351762563e-05,
      "loss": 0.4765,
      "step": 15270
    },
    {
      "epoch": 1.6372013286188793,
      "grad_norm": 72.54825592041016,
      "learning_rate": 1.7817064895174828e-05,
      "loss": 0.5613,
      "step": 15280
    },
    {
      "epoch": 1.6382727954569805,
      "grad_norm": 30.485904693603516,
      "learning_rate": 1.7815636272724027e-05,
      "loss": 0.7037,
      "step": 15290
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 0.11209297180175781,
      "learning_rate": 1.7814207650273227e-05,
      "loss": 0.2966,
      "step": 15300
    },
    {
      "epoch": 1.6404157291331833,
      "grad_norm": 0.09213290363550186,
      "learning_rate": 1.7812779027822426e-05,
      "loss": 0.1734,
      "step": 15310
    },
    {
      "epoch": 1.6414871959712847,
      "grad_norm": 53.32333755493164,
      "learning_rate": 1.7811350405371622e-05,
      "loss": 0.5101,
      "step": 15320
    },
    {
      "epoch": 1.642558662809386,
      "grad_norm": 0.14310447871685028,
      "learning_rate": 1.780992178292082e-05,
      "loss": 0.1917,
      "step": 15330
    },
    {
      "epoch": 1.6436301296474873,
      "grad_norm": 0.10779163986444473,
      "learning_rate": 1.7808493160470017e-05,
      "loss": 0.1568,
      "step": 15340
    },
    {
      "epoch": 1.644701596485589,
      "grad_norm": 0.14661137759685516,
      "learning_rate": 1.7807064538019217e-05,
      "loss": 0.5,
      "step": 15350
    },
    {
      "epoch": 1.64577306332369,
      "grad_norm": 0.21833966672420502,
      "learning_rate": 1.7805635915568416e-05,
      "loss": 0.2081,
      "step": 15360
    },
    {
      "epoch": 1.6468445301617916,
      "grad_norm": 0.09985464066267014,
      "learning_rate": 1.7804207293117612e-05,
      "loss": 0.3459,
      "step": 15370
    },
    {
      "epoch": 1.6479159969998929,
      "grad_norm": 0.015969188883900642,
      "learning_rate": 1.780277867066681e-05,
      "loss": 0.0037,
      "step": 15380
    },
    {
      "epoch": 1.6489874638379942,
      "grad_norm": 0.08410698175430298,
      "learning_rate": 1.7801350048216007e-05,
      "loss": 0.2552,
      "step": 15390
    },
    {
      "epoch": 1.6500589306760955,
      "grad_norm": 18.253114700317383,
      "learning_rate": 1.7799921425765207e-05,
      "loss": 0.7906,
      "step": 15400
    },
    {
      "epoch": 1.6511303975141969,
      "grad_norm": 0.06667510420084,
      "learning_rate": 1.7798492803314406e-05,
      "loss": 0.2022,
      "step": 15410
    },
    {
      "epoch": 1.6522018643522984,
      "grad_norm": 0.5646949410438538,
      "learning_rate": 1.7797064180863602e-05,
      "loss": 0.3133,
      "step": 15420
    },
    {
      "epoch": 1.6532733311903995,
      "grad_norm": 0.15071703493595123,
      "learning_rate": 1.77956355584128e-05,
      "loss": 0.0031,
      "step": 15430
    },
    {
      "epoch": 1.654344798028501,
      "grad_norm": 0.017339982092380524,
      "learning_rate": 1.7794206935962e-05,
      "loss": 0.0049,
      "step": 15440
    },
    {
      "epoch": 1.6554162648666024,
      "grad_norm": 0.020122816786170006,
      "learning_rate": 1.77927783135112e-05,
      "loss": 0.3148,
      "step": 15450
    },
    {
      "epoch": 1.6564877317047038,
      "grad_norm": 0.021036555990576744,
      "learning_rate": 1.7791349691060396e-05,
      "loss": 0.2288,
      "step": 15460
    },
    {
      "epoch": 1.657559198542805,
      "grad_norm": 0.2807982861995697,
      "learning_rate": 1.7789921068609596e-05,
      "loss": 0.2003,
      "step": 15470
    },
    {
      "epoch": 1.6586306653809064,
      "grad_norm": 50.56610870361328,
      "learning_rate": 1.7788492446158795e-05,
      "loss": 0.9481,
      "step": 15480
    },
    {
      "epoch": 1.659702132219008,
      "grad_norm": 0.08957721292972565,
      "learning_rate": 1.778706382370799e-05,
      "loss": 0.3789,
      "step": 15490
    },
    {
      "epoch": 1.660773599057109,
      "grad_norm": 0.2374393194913864,
      "learning_rate": 1.778563520125719e-05,
      "loss": 0.2967,
      "step": 15500
    },
    {
      "epoch": 1.6618450658952106,
      "grad_norm": 0.15869517624378204,
      "learning_rate": 1.7784206578806386e-05,
      "loss": 0.6207,
      "step": 15510
    },
    {
      "epoch": 1.6629165327333117,
      "grad_norm": 0.4008060395717621,
      "learning_rate": 1.7782777956355586e-05,
      "loss": 0.3261,
      "step": 15520
    },
    {
      "epoch": 1.6639879995714133,
      "grad_norm": 19.88713264465332,
      "learning_rate": 1.778134933390478e-05,
      "loss": 0.2226,
      "step": 15530
    },
    {
      "epoch": 1.6650594664095146,
      "grad_norm": 0.05626514554023743,
      "learning_rate": 1.777992071145398e-05,
      "loss": 0.3973,
      "step": 15540
    },
    {
      "epoch": 1.666130933247616,
      "grad_norm": 0.10975738614797592,
      "learning_rate": 1.777849208900318e-05,
      "loss": 0.3768,
      "step": 15550
    },
    {
      "epoch": 1.6672024000857173,
      "grad_norm": 0.043974217027425766,
      "learning_rate": 1.7777063466552376e-05,
      "loss": 0.1273,
      "step": 15560
    },
    {
      "epoch": 1.6682738669238186,
      "grad_norm": 0.04035721346735954,
      "learning_rate": 1.7775634844101576e-05,
      "loss": 0.2425,
      "step": 15570
    },
    {
      "epoch": 1.6693453337619202,
      "grad_norm": 0.06813377887010574,
      "learning_rate": 1.7774206221650775e-05,
      "loss": 0.3467,
      "step": 15580
    },
    {
      "epoch": 1.6704168006000213,
      "grad_norm": 15.944268226623535,
      "learning_rate": 1.7772777599199974e-05,
      "loss": 0.1759,
      "step": 15590
    },
    {
      "epoch": 1.6714882674381228,
      "grad_norm": 0.14925464987754822,
      "learning_rate": 1.777134897674917e-05,
      "loss": 0.2017,
      "step": 15600
    },
    {
      "epoch": 1.6725597342762242,
      "grad_norm": 17.460285186767578,
      "learning_rate": 1.776992035429837e-05,
      "loss": 0.5154,
      "step": 15610
    },
    {
      "epoch": 1.6736312011143255,
      "grad_norm": 0.2689792811870575,
      "learning_rate": 1.776849173184757e-05,
      "loss": 0.3335,
      "step": 15620
    },
    {
      "epoch": 1.6747026679524268,
      "grad_norm": 0.05020321533083916,
      "learning_rate": 1.7767063109396765e-05,
      "loss": 0.3372,
      "step": 15630
    },
    {
      "epoch": 1.6757741347905282,
      "grad_norm": 0.5889894962310791,
      "learning_rate": 1.7765634486945964e-05,
      "loss": 0.2411,
      "step": 15640
    },
    {
      "epoch": 1.6768456016286297,
      "grad_norm": 0.07151862978935242,
      "learning_rate": 1.776420586449516e-05,
      "loss": 0.1799,
      "step": 15650
    },
    {
      "epoch": 1.6779170684667308,
      "grad_norm": 19.869836807250977,
      "learning_rate": 1.776277724204436e-05,
      "loss": 0.327,
      "step": 15660
    },
    {
      "epoch": 1.6789885353048324,
      "grad_norm": 0.10422395169734955,
      "learning_rate": 1.776134861959356e-05,
      "loss": 0.0025,
      "step": 15670
    },
    {
      "epoch": 1.6800600021429337,
      "grad_norm": 26.399572372436523,
      "learning_rate": 1.7759919997142755e-05,
      "loss": 0.195,
      "step": 15680
    },
    {
      "epoch": 1.681131468981035,
      "grad_norm": 0.07156246900558472,
      "learning_rate": 1.7758491374691954e-05,
      "loss": 0.2574,
      "step": 15690
    },
    {
      "epoch": 1.6822029358191364,
      "grad_norm": 0.24227996170520782,
      "learning_rate": 1.775706275224115e-05,
      "loss": 0.4294,
      "step": 15700
    },
    {
      "epoch": 1.6832744026572377,
      "grad_norm": 0.34648239612579346,
      "learning_rate": 1.775563412979035e-05,
      "loss": 0.373,
      "step": 15710
    },
    {
      "epoch": 1.6843458694953393,
      "grad_norm": 19.76930046081543,
      "learning_rate": 1.775420550733955e-05,
      "loss": 0.613,
      "step": 15720
    },
    {
      "epoch": 1.6854173363334404,
      "grad_norm": 0.1969919502735138,
      "learning_rate": 1.775277688488875e-05,
      "loss": 0.3096,
      "step": 15730
    },
    {
      "epoch": 1.686488803171542,
      "grad_norm": 0.024672485888004303,
      "learning_rate": 1.7751348262437948e-05,
      "loss": 0.2034,
      "step": 15740
    },
    {
      "epoch": 1.687560270009643,
      "grad_norm": 13.992450714111328,
      "learning_rate": 1.7749919639987144e-05,
      "loss": 0.6733,
      "step": 15750
    },
    {
      "epoch": 1.6886317368477446,
      "grad_norm": 0.13160549104213715,
      "learning_rate": 1.7748491017536343e-05,
      "loss": 0.0096,
      "step": 15760
    },
    {
      "epoch": 1.689703203685846,
      "grad_norm": 0.021516283974051476,
      "learning_rate": 1.774706239508554e-05,
      "loss": 0.3202,
      "step": 15770
    },
    {
      "epoch": 1.6907746705239473,
      "grad_norm": 0.007596956565976143,
      "learning_rate": 1.774563377263474e-05,
      "loss": 0.0028,
      "step": 15780
    },
    {
      "epoch": 1.6918461373620488,
      "grad_norm": 0.11491528153419495,
      "learning_rate": 1.7744205150183938e-05,
      "loss": 0.0024,
      "step": 15790
    },
    {
      "epoch": 1.69291760420015,
      "grad_norm": 0.008513515815138817,
      "learning_rate": 1.7742776527733134e-05,
      "loss": 0.0469,
      "step": 15800
    },
    {
      "epoch": 1.6939890710382515,
      "grad_norm": 19.543169021606445,
      "learning_rate": 1.7741347905282333e-05,
      "loss": 1.0182,
      "step": 15810
    },
    {
      "epoch": 1.6950605378763526,
      "grad_norm": 0.7265518307685852,
      "learning_rate": 1.773991928283153e-05,
      "loss": 0.7118,
      "step": 15820
    },
    {
      "epoch": 1.6961320047144541,
      "grad_norm": 0.02002578042447567,
      "learning_rate": 1.773849066038073e-05,
      "loss": 0.4398,
      "step": 15830
    },
    {
      "epoch": 1.6972034715525555,
      "grad_norm": 0.21473903954029083,
      "learning_rate": 1.7737062037929928e-05,
      "loss": 0.003,
      "step": 15840
    },
    {
      "epoch": 1.6982749383906568,
      "grad_norm": 0.011801747605204582,
      "learning_rate": 1.7735633415479124e-05,
      "loss": 0.0009,
      "step": 15850
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 38.52064514160156,
      "learning_rate": 1.7734204793028323e-05,
      "loss": 0.4287,
      "step": 15860
    },
    {
      "epoch": 1.7004178720668595,
      "grad_norm": 0.4236210584640503,
      "learning_rate": 1.7732776170577523e-05,
      "loss": 0.3663,
      "step": 15870
    },
    {
      "epoch": 1.701489338904961,
      "grad_norm": 0.052045710384845734,
      "learning_rate": 1.7731347548126722e-05,
      "loss": 0.2497,
      "step": 15880
    },
    {
      "epoch": 1.7025608057430621,
      "grad_norm": 19.32999038696289,
      "learning_rate": 1.7729918925675918e-05,
      "loss": 0.5711,
      "step": 15890
    },
    {
      "epoch": 1.7036322725811637,
      "grad_norm": 20.008970260620117,
      "learning_rate": 1.7728490303225117e-05,
      "loss": 0.3875,
      "step": 15900
    },
    {
      "epoch": 1.704703739419265,
      "grad_norm": 0.0661114901304245,
      "learning_rate": 1.7727061680774317e-05,
      "loss": 0.0018,
      "step": 15910
    },
    {
      "epoch": 1.7057752062573663,
      "grad_norm": 60.236209869384766,
      "learning_rate": 1.7725633058323513e-05,
      "loss": 0.1367,
      "step": 15920
    },
    {
      "epoch": 1.7068466730954677,
      "grad_norm": 0.03605932742357254,
      "learning_rate": 1.7724204435872712e-05,
      "loss": 0.4674,
      "step": 15930
    },
    {
      "epoch": 1.707918139933569,
      "grad_norm": 0.14844878017902374,
      "learning_rate": 1.7722775813421908e-05,
      "loss": 0.1756,
      "step": 15940
    },
    {
      "epoch": 1.7089896067716706,
      "grad_norm": 0.47775620222091675,
      "learning_rate": 1.7721347190971108e-05,
      "loss": 0.3334,
      "step": 15950
    },
    {
      "epoch": 1.7100610736097717,
      "grad_norm": 0.020045027136802673,
      "learning_rate": 1.7719918568520307e-05,
      "loss": 0.0033,
      "step": 15960
    },
    {
      "epoch": 1.7111325404478732,
      "grad_norm": 8.931474685668945,
      "learning_rate": 1.7718489946069503e-05,
      "loss": 0.2588,
      "step": 15970
    },
    {
      "epoch": 1.7122040072859745,
      "grad_norm": 0.02709171175956726,
      "learning_rate": 1.7717061323618702e-05,
      "loss": 0.2943,
      "step": 15980
    },
    {
      "epoch": 1.7132754741240759,
      "grad_norm": 28.309677124023438,
      "learning_rate": 1.7715632701167898e-05,
      "loss": 0.8751,
      "step": 15990
    },
    {
      "epoch": 1.7143469409621772,
      "grad_norm": 0.5278356075286865,
      "learning_rate": 1.7714204078717098e-05,
      "loss": 0.2338,
      "step": 16000
    },
    {
      "epoch": 1.7154184078002785,
      "grad_norm": 13.770574569702148,
      "learning_rate": 1.7712775456266297e-05,
      "loss": 0.5263,
      "step": 16010
    },
    {
      "epoch": 1.71648987463838,
      "grad_norm": 1.0253181457519531,
      "learning_rate": 1.7711346833815496e-05,
      "loss": 0.5717,
      "step": 16020
    },
    {
      "epoch": 1.7175613414764812,
      "grad_norm": 26.763479232788086,
      "learning_rate": 1.7709918211364692e-05,
      "loss": 0.1444,
      "step": 16030
    },
    {
      "epoch": 1.7186328083145828,
      "grad_norm": 0.5287908315658569,
      "learning_rate": 1.770848958891389e-05,
      "loss": 0.121,
      "step": 16040
    },
    {
      "epoch": 1.7197042751526839,
      "grad_norm": 0.7516090869903564,
      "learning_rate": 1.770706096646309e-05,
      "loss": 0.4346,
      "step": 16050
    },
    {
      "epoch": 1.7207757419907854,
      "grad_norm": 0.011613691225647926,
      "learning_rate": 1.7705632344012287e-05,
      "loss": 0.1611,
      "step": 16060
    },
    {
      "epoch": 1.7218472088288868,
      "grad_norm": 0.011065886355936527,
      "learning_rate": 1.7704203721561486e-05,
      "loss": 0.0037,
      "step": 16070
    },
    {
      "epoch": 1.722918675666988,
      "grad_norm": 0.006273054983466864,
      "learning_rate": 1.7702775099110686e-05,
      "loss": 0.2658,
      "step": 16080
    },
    {
      "epoch": 1.7239901425050894,
      "grad_norm": 0.01038417499512434,
      "learning_rate": 1.7701346476659882e-05,
      "loss": 0.2807,
      "step": 16090
    },
    {
      "epoch": 1.7250616093431907,
      "grad_norm": 0.10612692683935165,
      "learning_rate": 1.769991785420908e-05,
      "loss": 0.1545,
      "step": 16100
    },
    {
      "epoch": 1.7261330761812923,
      "grad_norm": 0.6256757974624634,
      "learning_rate": 1.7698489231758277e-05,
      "loss": 0.8531,
      "step": 16110
    },
    {
      "epoch": 1.7272045430193934,
      "grad_norm": 0.07325845211744308,
      "learning_rate": 1.7697060609307476e-05,
      "loss": 0.3075,
      "step": 16120
    },
    {
      "epoch": 1.728276009857495,
      "grad_norm": 0.2817300260066986,
      "learning_rate": 1.7695631986856672e-05,
      "loss": 0.4566,
      "step": 16130
    },
    {
      "epoch": 1.7293474766955963,
      "grad_norm": 0.1793724149465561,
      "learning_rate": 1.7694203364405872e-05,
      "loss": 0.2863,
      "step": 16140
    },
    {
      "epoch": 1.7304189435336976,
      "grad_norm": 0.02013852819800377,
      "learning_rate": 1.769277474195507e-05,
      "loss": 0.0021,
      "step": 16150
    },
    {
      "epoch": 1.731490410371799,
      "grad_norm": 0.03691226243972778,
      "learning_rate": 1.769134611950427e-05,
      "loss": 0.1011,
      "step": 16160
    },
    {
      "epoch": 1.7325618772099003,
      "grad_norm": 0.015022657811641693,
      "learning_rate": 1.7689917497053466e-05,
      "loss": 0.2569,
      "step": 16170
    },
    {
      "epoch": 1.7336333440480018,
      "grad_norm": 41.29294204711914,
      "learning_rate": 1.7688488874602666e-05,
      "loss": 0.6492,
      "step": 16180
    },
    {
      "epoch": 1.734704810886103,
      "grad_norm": 0.17605526745319366,
      "learning_rate": 1.7687060252151865e-05,
      "loss": 0.1751,
      "step": 16190
    },
    {
      "epoch": 1.7357762777242045,
      "grad_norm": 0.31445208191871643,
      "learning_rate": 1.7685631629701065e-05,
      "loss": 0.6967,
      "step": 16200
    },
    {
      "epoch": 1.7368477445623058,
      "grad_norm": 0.020854542031884193,
      "learning_rate": 1.768420300725026e-05,
      "loss": 0.3882,
      "step": 16210
    },
    {
      "epoch": 1.7379192114004072,
      "grad_norm": 0.07176373898983002,
      "learning_rate": 1.768277438479946e-05,
      "loss": 0.0833,
      "step": 16220
    },
    {
      "epoch": 1.7389906782385085,
      "grad_norm": 1.0294057130813599,
      "learning_rate": 1.7681345762348656e-05,
      "loss": 0.3278,
      "step": 16230
    },
    {
      "epoch": 1.7400621450766098,
      "grad_norm": 0.2984887659549713,
      "learning_rate": 1.7679917139897855e-05,
      "loss": 0.0038,
      "step": 16240
    },
    {
      "epoch": 1.7411336119147114,
      "grad_norm": 0.03990648314356804,
      "learning_rate": 1.767848851744705e-05,
      "loss": 0.2622,
      "step": 16250
    },
    {
      "epoch": 1.7422050787528125,
      "grad_norm": 0.010381121188402176,
      "learning_rate": 1.767705989499625e-05,
      "loss": 0.1693,
      "step": 16260
    },
    {
      "epoch": 1.743276545590914,
      "grad_norm": 0.01046061236411333,
      "learning_rate": 1.767563127254545e-05,
      "loss": 0.0006,
      "step": 16270
    },
    {
      "epoch": 1.7443480124290152,
      "grad_norm": 16.738252639770508,
      "learning_rate": 1.7674202650094646e-05,
      "loss": 0.6982,
      "step": 16280
    },
    {
      "epoch": 1.7454194792671167,
      "grad_norm": 44.5909538269043,
      "learning_rate": 1.7672774027643845e-05,
      "loss": 0.2952,
      "step": 16290
    },
    {
      "epoch": 1.746490946105218,
      "grad_norm": 1.5263891220092773,
      "learning_rate": 1.7671345405193045e-05,
      "loss": 0.1644,
      "step": 16300
    },
    {
      "epoch": 1.7475624129433194,
      "grad_norm": 0.08766727894544601,
      "learning_rate": 1.7669916782742244e-05,
      "loss": 0.1202,
      "step": 16310
    },
    {
      "epoch": 1.748633879781421,
      "grad_norm": 0.2569381296634674,
      "learning_rate": 1.766848816029144e-05,
      "loss": 0.7697,
      "step": 16320
    },
    {
      "epoch": 1.749705346619522,
      "grad_norm": 0.29325243830680847,
      "learning_rate": 1.766705953784064e-05,
      "loss": 0.7131,
      "step": 16330
    },
    {
      "epoch": 1.7507768134576236,
      "grad_norm": 0.028299463912844658,
      "learning_rate": 1.766563091538984e-05,
      "loss": 0.6522,
      "step": 16340
    },
    {
      "epoch": 1.7518482802957247,
      "grad_norm": 25.2636775970459,
      "learning_rate": 1.7664202292939035e-05,
      "loss": 0.2942,
      "step": 16350
    },
    {
      "epoch": 1.7529197471338263,
      "grad_norm": 0.16972696781158447,
      "learning_rate": 1.7662773670488234e-05,
      "loss": 0.29,
      "step": 16360
    },
    {
      "epoch": 1.7539912139719276,
      "grad_norm": 0.3670025169849396,
      "learning_rate": 1.766134504803743e-05,
      "loss": 0.1367,
      "step": 16370
    },
    {
      "epoch": 1.755062680810029,
      "grad_norm": 0.2412310093641281,
      "learning_rate": 1.765991642558663e-05,
      "loss": 0.5219,
      "step": 16380
    },
    {
      "epoch": 1.7561341476481303,
      "grad_norm": 0.23282721638679504,
      "learning_rate": 1.765848780313583e-05,
      "loss": 0.5317,
      "step": 16390
    },
    {
      "epoch": 1.7572056144862316,
      "grad_norm": 0.4629671573638916,
      "learning_rate": 1.7657059180685025e-05,
      "loss": 0.3751,
      "step": 16400
    },
    {
      "epoch": 1.7582770813243331,
      "grad_norm": 0.16025541722774506,
      "learning_rate": 1.7655630558234224e-05,
      "loss": 0.1717,
      "step": 16410
    },
    {
      "epoch": 1.7593485481624342,
      "grad_norm": 0.16435694694519043,
      "learning_rate": 1.765420193578342e-05,
      "loss": 0.0037,
      "step": 16420
    },
    {
      "epoch": 1.7604200150005358,
      "grad_norm": 0.06156405806541443,
      "learning_rate": 1.765277331333262e-05,
      "loss": 0.5447,
      "step": 16430
    },
    {
      "epoch": 1.7614914818386371,
      "grad_norm": 0.07440488785505295,
      "learning_rate": 1.765134469088182e-05,
      "loss": 0.8657,
      "step": 16440
    },
    {
      "epoch": 1.7625629486767385,
      "grad_norm": 0.06429088115692139,
      "learning_rate": 1.7649916068431018e-05,
      "loss": 0.0039,
      "step": 16450
    },
    {
      "epoch": 1.7636344155148398,
      "grad_norm": 0.23309165239334106,
      "learning_rate": 1.7648487445980214e-05,
      "loss": 0.0037,
      "step": 16460
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 14.054925918579102,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 0.4752,
      "step": 16470
    },
    {
      "epoch": 1.7657773491910427,
      "grad_norm": 0.056706931442022324,
      "learning_rate": 1.7645630201078613e-05,
      "loss": 0.4559,
      "step": 16480
    },
    {
      "epoch": 1.7668488160291438,
      "grad_norm": 0.01857714354991913,
      "learning_rate": 1.764420157862781e-05,
      "loss": 0.5051,
      "step": 16490
    },
    {
      "epoch": 1.7679202828672453,
      "grad_norm": 0.2096085101366043,
      "learning_rate": 1.764277295617701e-05,
      "loss": 0.3392,
      "step": 16500
    },
    {
      "epoch": 1.7689917497053467,
      "grad_norm": 0.013707412406802177,
      "learning_rate": 1.7641344333726208e-05,
      "loss": 0.0032,
      "step": 16510
    },
    {
      "epoch": 1.770063216543448,
      "grad_norm": 0.333105206489563,
      "learning_rate": 1.7639915711275404e-05,
      "loss": 0.2678,
      "step": 16520
    },
    {
      "epoch": 1.7711346833815493,
      "grad_norm": 0.021327152848243713,
      "learning_rate": 1.7638487088824603e-05,
      "loss": 0.6125,
      "step": 16530
    },
    {
      "epoch": 1.7722061502196507,
      "grad_norm": 0.46000006794929504,
      "learning_rate": 1.76370584663738e-05,
      "loss": 0.1428,
      "step": 16540
    },
    {
      "epoch": 1.7732776170577522,
      "grad_norm": 0.5070936679840088,
      "learning_rate": 1.7635629843923e-05,
      "loss": 0.8489,
      "step": 16550
    },
    {
      "epoch": 1.7743490838958533,
      "grad_norm": 0.015190364792943,
      "learning_rate": 1.7634201221472194e-05,
      "loss": 0.1104,
      "step": 16560
    },
    {
      "epoch": 1.7754205507339549,
      "grad_norm": 0.12070170044898987,
      "learning_rate": 1.7632772599021394e-05,
      "loss": 0.3559,
      "step": 16570
    },
    {
      "epoch": 1.776492017572056,
      "grad_norm": 0.2219955325126648,
      "learning_rate": 1.7631343976570593e-05,
      "loss": 0.6052,
      "step": 16580
    },
    {
      "epoch": 1.7775634844101575,
      "grad_norm": 0.4056033194065094,
      "learning_rate": 1.7629915354119792e-05,
      "loss": 0.455,
      "step": 16590
    },
    {
      "epoch": 1.7786349512482589,
      "grad_norm": 0.08605104684829712,
      "learning_rate": 1.762848673166899e-05,
      "loss": 0.2887,
      "step": 16600
    },
    {
      "epoch": 1.7797064180863602,
      "grad_norm": 14.032999038696289,
      "learning_rate": 1.7627058109218188e-05,
      "loss": 0.2395,
      "step": 16610
    },
    {
      "epoch": 1.7807778849244615,
      "grad_norm": 0.16485615074634552,
      "learning_rate": 1.7625629486767387e-05,
      "loss": 0.4121,
      "step": 16620
    },
    {
      "epoch": 1.7818493517625629,
      "grad_norm": 0.6459776759147644,
      "learning_rate": 1.7624200864316587e-05,
      "loss": 0.2754,
      "step": 16630
    },
    {
      "epoch": 1.7829208186006644,
      "grad_norm": 0.3413452208042145,
      "learning_rate": 1.7622772241865783e-05,
      "loss": 0.3872,
      "step": 16640
    },
    {
      "epoch": 1.7839922854387655,
      "grad_norm": 0.024918267503380775,
      "learning_rate": 1.7621343619414982e-05,
      "loss": 0.4199,
      "step": 16650
    },
    {
      "epoch": 1.785063752276867,
      "grad_norm": 1.3353781700134277,
      "learning_rate": 1.7619914996964178e-05,
      "loss": 0.0048,
      "step": 16660
    },
    {
      "epoch": 1.7861352191149684,
      "grad_norm": 0.20508462190628052,
      "learning_rate": 1.7618486374513377e-05,
      "loss": 0.6835,
      "step": 16670
    },
    {
      "epoch": 1.7872066859530698,
      "grad_norm": 0.02166140079498291,
      "learning_rate": 1.7617057752062573e-05,
      "loss": 0.3764,
      "step": 16680
    },
    {
      "epoch": 1.788278152791171,
      "grad_norm": 0.6238701343536377,
      "learning_rate": 1.7615629129611773e-05,
      "loss": 0.0059,
      "step": 16690
    },
    {
      "epoch": 1.7893496196292724,
      "grad_norm": 0.023840030655264854,
      "learning_rate": 1.7614200507160972e-05,
      "loss": 0.5234,
      "step": 16700
    },
    {
      "epoch": 1.790421086467374,
      "grad_norm": 1.1989394426345825,
      "learning_rate": 1.7612771884710168e-05,
      "loss": 1.0479,
      "step": 16710
    },
    {
      "epoch": 1.791492553305475,
      "grad_norm": 0.09380214661359787,
      "learning_rate": 1.7611343262259367e-05,
      "loss": 0.2003,
      "step": 16720
    },
    {
      "epoch": 1.7925640201435766,
      "grad_norm": 43.12750244140625,
      "learning_rate": 1.7609914639808567e-05,
      "loss": 0.765,
      "step": 16730
    },
    {
      "epoch": 1.793635486981678,
      "grad_norm": 0.16275092959403992,
      "learning_rate": 1.7608486017357763e-05,
      "loss": 0.3587,
      "step": 16740
    },
    {
      "epoch": 1.7947069538197793,
      "grad_norm": 0.23151850700378418,
      "learning_rate": 1.7607057394906962e-05,
      "loss": 0.1055,
      "step": 16750
    },
    {
      "epoch": 1.7957784206578806,
      "grad_norm": 27.852983474731445,
      "learning_rate": 1.760562877245616e-05,
      "loss": 0.1443,
      "step": 16760
    },
    {
      "epoch": 1.796849887495982,
      "grad_norm": 0.019093358889222145,
      "learning_rate": 1.760420015000536e-05,
      "loss": 0.1692,
      "step": 16770
    },
    {
      "epoch": 1.7979213543340835,
      "grad_norm": 0.13943931460380554,
      "learning_rate": 1.7602771527554557e-05,
      "loss": 0.0008,
      "step": 16780
    },
    {
      "epoch": 1.7989928211721846,
      "grad_norm": 14.248064994812012,
      "learning_rate": 1.7601342905103756e-05,
      "loss": 0.6719,
      "step": 16790
    },
    {
      "epoch": 1.8000642880102862,
      "grad_norm": 0.01921902783215046,
      "learning_rate": 1.7599914282652952e-05,
      "loss": 0.2517,
      "step": 16800
    },
    {
      "epoch": 1.8011357548483873,
      "grad_norm": 0.7516307830810547,
      "learning_rate": 1.759848566020215e-05,
      "loss": 0.7316,
      "step": 16810
    },
    {
      "epoch": 1.8022072216864888,
      "grad_norm": 0.033543966710567474,
      "learning_rate": 1.759705703775135e-05,
      "loss": 0.3992,
      "step": 16820
    },
    {
      "epoch": 1.8032786885245902,
      "grad_norm": 0.49111947417259216,
      "learning_rate": 1.7595628415300547e-05,
      "loss": 0.1803,
      "step": 16830
    },
    {
      "epoch": 1.8043501553626915,
      "grad_norm": 0.7326459884643555,
      "learning_rate": 1.7594199792849746e-05,
      "loss": 0.2704,
      "step": 16840
    },
    {
      "epoch": 1.8054216222007928,
      "grad_norm": 0.7330308556556702,
      "learning_rate": 1.7592771170398942e-05,
      "loss": 0.0106,
      "step": 16850
    },
    {
      "epoch": 1.8064930890388942,
      "grad_norm": 0.027226382866501808,
      "learning_rate": 1.759134254794814e-05,
      "loss": 0.003,
      "step": 16860
    },
    {
      "epoch": 1.8075645558769957,
      "grad_norm": 0.030027762055397034,
      "learning_rate": 1.758991392549734e-05,
      "loss": 0.9992,
      "step": 16870
    },
    {
      "epoch": 1.8086360227150968,
      "grad_norm": 0.18092523515224457,
      "learning_rate": 1.758848530304654e-05,
      "loss": 0.416,
      "step": 16880
    },
    {
      "epoch": 1.8097074895531984,
      "grad_norm": 0.15145252645015717,
      "learning_rate": 1.7587056680595736e-05,
      "loss": 0.7665,
      "step": 16890
    },
    {
      "epoch": 1.8107789563912997,
      "grad_norm": 17.17131996154785,
      "learning_rate": 1.7585628058144936e-05,
      "loss": 0.1292,
      "step": 16900
    },
    {
      "epoch": 1.811850423229401,
      "grad_norm": 0.04741405323147774,
      "learning_rate": 1.7584199435694135e-05,
      "loss": 0.2886,
      "step": 16910
    },
    {
      "epoch": 1.8129218900675024,
      "grad_norm": 22.962535858154297,
      "learning_rate": 1.758277081324333e-05,
      "loss": 0.1521,
      "step": 16920
    },
    {
      "epoch": 1.8139933569056037,
      "grad_norm": 1.8497434854507446,
      "learning_rate": 1.758134219079253e-05,
      "loss": 0.0038,
      "step": 16930
    },
    {
      "epoch": 1.8150648237437053,
      "grad_norm": 0.2693675756454468,
      "learning_rate": 1.757991356834173e-05,
      "loss": 0.0033,
      "step": 16940
    },
    {
      "epoch": 1.8161362905818064,
      "grad_norm": 0.019215762615203857,
      "learning_rate": 1.7578484945890926e-05,
      "loss": 0.3905,
      "step": 16950
    },
    {
      "epoch": 1.817207757419908,
      "grad_norm": 0.1572273224592209,
      "learning_rate": 1.7577056323440125e-05,
      "loss": 0.0014,
      "step": 16960
    },
    {
      "epoch": 1.8182792242580093,
      "grad_norm": 0.15405137836933136,
      "learning_rate": 1.757562770098932e-05,
      "loss": 0.3119,
      "step": 16970
    },
    {
      "epoch": 1.8193506910961106,
      "grad_norm": 0.031806301325559616,
      "learning_rate": 1.757419907853852e-05,
      "loss": 0.1618,
      "step": 16980
    },
    {
      "epoch": 1.820422157934212,
      "grad_norm": 16.19650650024414,
      "learning_rate": 1.757277045608772e-05,
      "loss": 0.4418,
      "step": 16990
    },
    {
      "epoch": 1.8214936247723132,
      "grad_norm": 0.05565464496612549,
      "learning_rate": 1.7571341833636916e-05,
      "loss": 0.2647,
      "step": 17000
    },
    {
      "epoch": 1.8225650916104148,
      "grad_norm": 0.024650294333696365,
      "learning_rate": 1.7569913211186115e-05,
      "loss": 0.0036,
      "step": 17010
    },
    {
      "epoch": 1.823636558448516,
      "grad_norm": 0.21755681931972504,
      "learning_rate": 1.7568484588735314e-05,
      "loss": 0.2775,
      "step": 17020
    },
    {
      "epoch": 1.8247080252866175,
      "grad_norm": 15.810276985168457,
      "learning_rate": 1.756705596628451e-05,
      "loss": 0.4273,
      "step": 17030
    },
    {
      "epoch": 1.8257794921247188,
      "grad_norm": 25.966032028198242,
      "learning_rate": 1.756562734383371e-05,
      "loss": 0.922,
      "step": 17040
    },
    {
      "epoch": 1.8268509589628201,
      "grad_norm": 0.3768680989742279,
      "learning_rate": 1.756419872138291e-05,
      "loss": 0.2229,
      "step": 17050
    },
    {
      "epoch": 1.8279224258009215,
      "grad_norm": 0.5605153441429138,
      "learning_rate": 1.756277009893211e-05,
      "loss": 0.3009,
      "step": 17060
    },
    {
      "epoch": 1.8289938926390228,
      "grad_norm": 0.44495517015457153,
      "learning_rate": 1.7561341476481304e-05,
      "loss": 0.0042,
      "step": 17070
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.25823354721069336,
      "learning_rate": 1.7559912854030504e-05,
      "loss": 0.0017,
      "step": 17080
    },
    {
      "epoch": 1.8311368263152255,
      "grad_norm": 23.48603630065918,
      "learning_rate": 1.75584842315797e-05,
      "loss": 0.5146,
      "step": 17090
    },
    {
      "epoch": 1.832208293153327,
      "grad_norm": 16.308618545532227,
      "learning_rate": 1.75570556091289e-05,
      "loss": 0.1495,
      "step": 17100
    },
    {
      "epoch": 1.8332797599914281,
      "grad_norm": 0.05513504892587662,
      "learning_rate": 1.75556269866781e-05,
      "loss": 0.2878,
      "step": 17110
    },
    {
      "epoch": 1.8343512268295297,
      "grad_norm": 0.066172756254673,
      "learning_rate": 1.7554198364227295e-05,
      "loss": 0.3869,
      "step": 17120
    },
    {
      "epoch": 1.835422693667631,
      "grad_norm": 77.18294525146484,
      "learning_rate": 1.7552769741776494e-05,
      "loss": 0.5321,
      "step": 17130
    },
    {
      "epoch": 1.8364941605057323,
      "grad_norm": 0.10671298205852509,
      "learning_rate": 1.755134111932569e-05,
      "loss": 0.002,
      "step": 17140
    },
    {
      "epoch": 1.8375656273438337,
      "grad_norm": 0.0327446348965168,
      "learning_rate": 1.754991249687489e-05,
      "loss": 0.1639,
      "step": 17150
    },
    {
      "epoch": 1.838637094181935,
      "grad_norm": 0.09105058759450912,
      "learning_rate": 1.754848387442409e-05,
      "loss": 0.3595,
      "step": 17160
    },
    {
      "epoch": 1.8397085610200365,
      "grad_norm": 0.147780641913414,
      "learning_rate": 1.7547055251973285e-05,
      "loss": 0.1381,
      "step": 17170
    },
    {
      "epoch": 1.8407800278581377,
      "grad_norm": 21.429126739501953,
      "learning_rate": 1.7545626629522484e-05,
      "loss": 0.1905,
      "step": 17180
    },
    {
      "epoch": 1.8418514946962392,
      "grad_norm": 1.4119938611984253,
      "learning_rate": 1.7544198007071683e-05,
      "loss": 0.3561,
      "step": 17190
    },
    {
      "epoch": 1.8429229615343405,
      "grad_norm": 0.025661883875727654,
      "learning_rate": 1.7542769384620883e-05,
      "loss": 0.4113,
      "step": 17200
    },
    {
      "epoch": 1.8439944283724419,
      "grad_norm": 0.09501384943723679,
      "learning_rate": 1.754134076217008e-05,
      "loss": 0.5773,
      "step": 17210
    },
    {
      "epoch": 1.8450658952105432,
      "grad_norm": 0.4075523614883423,
      "learning_rate": 1.7539912139719278e-05,
      "loss": 0.2363,
      "step": 17220
    },
    {
      "epoch": 1.8461373620486445,
      "grad_norm": 0.1462935358285904,
      "learning_rate": 1.7538483517268474e-05,
      "loss": 0.5567,
      "step": 17230
    },
    {
      "epoch": 1.847208828886746,
      "grad_norm": 0.5662429332733154,
      "learning_rate": 1.7537054894817673e-05,
      "loss": 0.2362,
      "step": 17240
    },
    {
      "epoch": 1.8482802957248472,
      "grad_norm": 0.11697937548160553,
      "learning_rate": 1.7535626272366873e-05,
      "loss": 0.0049,
      "step": 17250
    },
    {
      "epoch": 1.8493517625629488,
      "grad_norm": 0.23055870831012726,
      "learning_rate": 1.753419764991607e-05,
      "loss": 0.2759,
      "step": 17260
    },
    {
      "epoch": 1.85042322940105,
      "grad_norm": 1.26271653175354,
      "learning_rate": 1.7532769027465268e-05,
      "loss": 0.0987,
      "step": 17270
    },
    {
      "epoch": 1.8514946962391514,
      "grad_norm": 0.020128650590777397,
      "learning_rate": 1.7531340405014464e-05,
      "loss": 0.1137,
      "step": 17280
    },
    {
      "epoch": 1.8525661630772527,
      "grad_norm": 0.011926768347620964,
      "learning_rate": 1.7529911782563663e-05,
      "loss": 0.1728,
      "step": 17290
    },
    {
      "epoch": 1.853637629915354,
      "grad_norm": 0.6887316107749939,
      "learning_rate": 1.7528483160112863e-05,
      "loss": 0.1058,
      "step": 17300
    },
    {
      "epoch": 1.8547090967534556,
      "grad_norm": 0.14277715981006622,
      "learning_rate": 1.752705453766206e-05,
      "loss": 0.7505,
      "step": 17310
    },
    {
      "epoch": 1.8557805635915567,
      "grad_norm": 0.02522384189069271,
      "learning_rate": 1.7525625915211258e-05,
      "loss": 0.2483,
      "step": 17320
    },
    {
      "epoch": 1.8568520304296583,
      "grad_norm": 0.4203352630138397,
      "learning_rate": 1.7524197292760457e-05,
      "loss": 0.1208,
      "step": 17330
    },
    {
      "epoch": 1.8579234972677594,
      "grad_norm": 23.854707717895508,
      "learning_rate": 1.7522768670309657e-05,
      "loss": 0.4252,
      "step": 17340
    },
    {
      "epoch": 1.858994964105861,
      "grad_norm": 0.08936258405447006,
      "learning_rate": 1.7521340047858853e-05,
      "loss": 0.0022,
      "step": 17350
    },
    {
      "epoch": 1.8600664309439623,
      "grad_norm": 0.01844293437898159,
      "learning_rate": 1.7519911425408052e-05,
      "loss": 0.533,
      "step": 17360
    },
    {
      "epoch": 1.8611378977820636,
      "grad_norm": 0.02881786786019802,
      "learning_rate": 1.751848280295725e-05,
      "loss": 0.2655,
      "step": 17370
    },
    {
      "epoch": 1.862209364620165,
      "grad_norm": 36.51375198364258,
      "learning_rate": 1.7517054180506448e-05,
      "loss": 0.3029,
      "step": 17380
    },
    {
      "epoch": 1.8632808314582663,
      "grad_norm": 0.082276850938797,
      "learning_rate": 1.7515625558055647e-05,
      "loss": 0.1805,
      "step": 17390
    },
    {
      "epoch": 1.8643522982963678,
      "grad_norm": 0.08480492234230042,
      "learning_rate": 1.7514196935604843e-05,
      "loss": 0.2572,
      "step": 17400
    },
    {
      "epoch": 1.865423765134469,
      "grad_norm": 0.030424928292632103,
      "learning_rate": 1.7512768313154042e-05,
      "loss": 0.2525,
      "step": 17410
    },
    {
      "epoch": 1.8664952319725705,
      "grad_norm": 0.08581526577472687,
      "learning_rate": 1.751133969070324e-05,
      "loss": 0.2371,
      "step": 17420
    },
    {
      "epoch": 1.8675666988106718,
      "grad_norm": 0.08330890536308289,
      "learning_rate": 1.7509911068252438e-05,
      "loss": 0.6378,
      "step": 17430
    },
    {
      "epoch": 1.8686381656487732,
      "grad_norm": 0.021939249709248543,
      "learning_rate": 1.7508482445801637e-05,
      "loss": 0.3696,
      "step": 17440
    },
    {
      "epoch": 1.8697096324868745,
      "grad_norm": 0.016106048598885536,
      "learning_rate": 1.7507053823350836e-05,
      "loss": 0.0014,
      "step": 17450
    },
    {
      "epoch": 1.8707810993249758,
      "grad_norm": 15.941896438598633,
      "learning_rate": 1.7505625200900032e-05,
      "loss": 0.2107,
      "step": 17460
    },
    {
      "epoch": 1.8718525661630774,
      "grad_norm": 230.73680114746094,
      "learning_rate": 1.750419657844923e-05,
      "loss": 0.5418,
      "step": 17470
    },
    {
      "epoch": 1.8729240330011785,
      "grad_norm": 0.0334438793361187,
      "learning_rate": 1.750276795599843e-05,
      "loss": 0.2674,
      "step": 17480
    },
    {
      "epoch": 1.87399549983928,
      "grad_norm": 0.34586483240127563,
      "learning_rate": 1.750133933354763e-05,
      "loss": 0.1078,
      "step": 17490
    },
    {
      "epoch": 1.8750669666773814,
      "grad_norm": 0.04455564171075821,
      "learning_rate": 1.7499910711096826e-05,
      "loss": 0.8714,
      "step": 17500
    },
    {
      "epoch": 1.8761384335154827,
      "grad_norm": 0.08640775829553604,
      "learning_rate": 1.7498482088646026e-05,
      "loss": 0.2009,
      "step": 17510
    },
    {
      "epoch": 1.877209900353584,
      "grad_norm": 0.01194649375975132,
      "learning_rate": 1.7497053466195222e-05,
      "loss": 0.0027,
      "step": 17520
    },
    {
      "epoch": 1.8782813671916854,
      "grad_norm": 0.021395070478320122,
      "learning_rate": 1.749562484374442e-05,
      "loss": 0.395,
      "step": 17530
    },
    {
      "epoch": 1.879352834029787,
      "grad_norm": 0.010362951084971428,
      "learning_rate": 1.749419622129362e-05,
      "loss": 0.1459,
      "step": 17540
    },
    {
      "epoch": 1.880424300867888,
      "grad_norm": 28.536602020263672,
      "learning_rate": 1.7492767598842816e-05,
      "loss": 0.1723,
      "step": 17550
    },
    {
      "epoch": 1.8814957677059896,
      "grad_norm": 0.049357496201992035,
      "learning_rate": 1.7491338976392016e-05,
      "loss": 0.3909,
      "step": 17560
    },
    {
      "epoch": 1.8825672345440907,
      "grad_norm": 1.9001165628433228,
      "learning_rate": 1.7489910353941212e-05,
      "loss": 0.2817,
      "step": 17570
    },
    {
      "epoch": 1.8836387013821922,
      "grad_norm": 0.07366243004798889,
      "learning_rate": 1.748848173149041e-05,
      "loss": 0.3349,
      "step": 17580
    },
    {
      "epoch": 1.8847101682202936,
      "grad_norm": 0.023716192692518234,
      "learning_rate": 1.748705310903961e-05,
      "loss": 0.2775,
      "step": 17590
    },
    {
      "epoch": 1.885781635058395,
      "grad_norm": 0.1514490395784378,
      "learning_rate": 1.7485624486588807e-05,
      "loss": 0.0064,
      "step": 17600
    },
    {
      "epoch": 1.8868531018964965,
      "grad_norm": 0.028104174882173538,
      "learning_rate": 1.7484195864138006e-05,
      "loss": 0.5096,
      "step": 17610
    },
    {
      "epoch": 1.8879245687345976,
      "grad_norm": 0.37623950839042664,
      "learning_rate": 1.7482767241687205e-05,
      "loss": 0.2721,
      "step": 17620
    },
    {
      "epoch": 1.8889960355726991,
      "grad_norm": 0.010490301996469498,
      "learning_rate": 1.7481338619236405e-05,
      "loss": 0.0019,
      "step": 17630
    },
    {
      "epoch": 1.8900675024108002,
      "grad_norm": 0.006035130936652422,
      "learning_rate": 1.74799099967856e-05,
      "loss": 0.0007,
      "step": 17640
    },
    {
      "epoch": 1.8911389692489018,
      "grad_norm": 0.003919810988008976,
      "learning_rate": 1.74784813743348e-05,
      "loss": 0.0018,
      "step": 17650
    },
    {
      "epoch": 1.8922104360870031,
      "grad_norm": 0.008136552758514881,
      "learning_rate": 1.7477052751884e-05,
      "loss": 0.2974,
      "step": 17660
    },
    {
      "epoch": 1.8932819029251045,
      "grad_norm": 0.007693555671721697,
      "learning_rate": 1.7475624129433195e-05,
      "loss": 0.2636,
      "step": 17670
    },
    {
      "epoch": 1.8943533697632058,
      "grad_norm": 0.04310963675379753,
      "learning_rate": 1.7474195506982395e-05,
      "loss": 0.1974,
      "step": 17680
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.12002668529748917,
      "learning_rate": 1.747276688453159e-05,
      "loss": 0.3535,
      "step": 17690
    },
    {
      "epoch": 1.8964963034394087,
      "grad_norm": 0.07783020287752151,
      "learning_rate": 1.747133826208079e-05,
      "loss": 0.4723,
      "step": 17700
    },
    {
      "epoch": 1.8975677702775098,
      "grad_norm": 5.6791582107543945,
      "learning_rate": 1.7469909639629986e-05,
      "loss": 0.0052,
      "step": 17710
    },
    {
      "epoch": 1.8986392371156113,
      "grad_norm": 0.02735726535320282,
      "learning_rate": 1.7468481017179185e-05,
      "loss": 0.3494,
      "step": 17720
    },
    {
      "epoch": 1.8997107039537127,
      "grad_norm": 0.021462248638272285,
      "learning_rate": 1.7467052394728385e-05,
      "loss": 0.1716,
      "step": 17730
    },
    {
      "epoch": 1.900782170791814,
      "grad_norm": 30.063899993896484,
      "learning_rate": 1.746562377227758e-05,
      "loss": 0.7674,
      "step": 17740
    },
    {
      "epoch": 1.9018536376299153,
      "grad_norm": 0.0508967787027359,
      "learning_rate": 1.746419514982678e-05,
      "loss": 0.5729,
      "step": 17750
    },
    {
      "epoch": 1.9029251044680167,
      "grad_norm": 1.0816781520843506,
      "learning_rate": 1.746276652737598e-05,
      "loss": 0.2843,
      "step": 17760
    },
    {
      "epoch": 1.9039965713061182,
      "grad_norm": 0.10362789779901505,
      "learning_rate": 1.746133790492518e-05,
      "loss": 0.3651,
      "step": 17770
    },
    {
      "epoch": 1.9050680381442193,
      "grad_norm": 5.012750625610352,
      "learning_rate": 1.7459909282474378e-05,
      "loss": 0.1487,
      "step": 17780
    },
    {
      "epoch": 1.9061395049823209,
      "grad_norm": 0.40831947326660156,
      "learning_rate": 1.7458480660023574e-05,
      "loss": 0.3205,
      "step": 17790
    },
    {
      "epoch": 1.9072109718204222,
      "grad_norm": 0.01916237734258175,
      "learning_rate": 1.7457052037572774e-05,
      "loss": 0.2325,
      "step": 17800
    },
    {
      "epoch": 1.9082824386585235,
      "grad_norm": 0.02913769893348217,
      "learning_rate": 1.745562341512197e-05,
      "loss": 0.0079,
      "step": 17810
    },
    {
      "epoch": 1.9093539054966249,
      "grad_norm": 0.022247055545449257,
      "learning_rate": 1.745419479267117e-05,
      "loss": 0.2276,
      "step": 17820
    },
    {
      "epoch": 1.9104253723347262,
      "grad_norm": 0.18608324229717255,
      "learning_rate": 1.7452766170220365e-05,
      "loss": 0.6608,
      "step": 17830
    },
    {
      "epoch": 1.9114968391728278,
      "grad_norm": 0.021920878440141678,
      "learning_rate": 1.7451337547769564e-05,
      "loss": 0.6882,
      "step": 17840
    },
    {
      "epoch": 1.9125683060109289,
      "grad_norm": 24.54039764404297,
      "learning_rate": 1.7449908925318764e-05,
      "loss": 0.5392,
      "step": 17850
    },
    {
      "epoch": 1.9136397728490304,
      "grad_norm": 22.429813385009766,
      "learning_rate": 1.744848030286796e-05,
      "loss": 0.3239,
      "step": 17860
    },
    {
      "epoch": 1.9147112396871315,
      "grad_norm": 0.08281467854976654,
      "learning_rate": 1.744705168041716e-05,
      "loss": 0.1842,
      "step": 17870
    },
    {
      "epoch": 1.915782706525233,
      "grad_norm": 0.05786082148551941,
      "learning_rate": 1.7445623057966355e-05,
      "loss": 0.0059,
      "step": 17880
    },
    {
      "epoch": 1.9168541733633344,
      "grad_norm": 0.026540126651525497,
      "learning_rate": 1.7444194435515554e-05,
      "loss": 0.5849,
      "step": 17890
    },
    {
      "epoch": 1.9179256402014357,
      "grad_norm": 3.4678592681884766,
      "learning_rate": 1.7442765813064754e-05,
      "loss": 0.298,
      "step": 17900
    },
    {
      "epoch": 1.918997107039537,
      "grad_norm": 0.10976731032133102,
      "learning_rate": 1.7441337190613953e-05,
      "loss": 0.1298,
      "step": 17910
    },
    {
      "epoch": 1.9200685738776384,
      "grad_norm": 0.03472665324807167,
      "learning_rate": 1.7439908568163152e-05,
      "loss": 0.5712,
      "step": 17920
    },
    {
      "epoch": 1.92114004071574,
      "grad_norm": 0.416507750749588,
      "learning_rate": 1.743847994571235e-05,
      "loss": 0.315,
      "step": 17930
    },
    {
      "epoch": 1.922211507553841,
      "grad_norm": 0.09206810593605042,
      "learning_rate": 1.7437051323261548e-05,
      "loss": 0.1432,
      "step": 17940
    },
    {
      "epoch": 1.9232829743919426,
      "grad_norm": 0.04253431782126427,
      "learning_rate": 1.7435622700810744e-05,
      "loss": 0.0044,
      "step": 17950
    },
    {
      "epoch": 1.924354441230044,
      "grad_norm": 23.144872665405273,
      "learning_rate": 1.7434194078359943e-05,
      "loss": 0.2388,
      "step": 17960
    },
    {
      "epoch": 1.9254259080681453,
      "grad_norm": 0.04972412437200546,
      "learning_rate": 1.7432765455909142e-05,
      "loss": 0.3358,
      "step": 17970
    },
    {
      "epoch": 1.9264973749062466,
      "grad_norm": 24.454452514648438,
      "learning_rate": 1.743133683345834e-05,
      "loss": 0.6873,
      "step": 17980
    },
    {
      "epoch": 1.927568841744348,
      "grad_norm": 0.2744615077972412,
      "learning_rate": 1.7429908211007538e-05,
      "loss": 0.8232,
      "step": 17990
    },
    {
      "epoch": 1.9286403085824495,
      "grad_norm": 21.111282348632812,
      "learning_rate": 1.7428479588556734e-05,
      "loss": 0.4128,
      "step": 18000
    },
    {
      "epoch": 1.9297117754205506,
      "grad_norm": 1.0719995498657227,
      "learning_rate": 1.7427050966105933e-05,
      "loss": 0.0075,
      "step": 18010
    },
    {
      "epoch": 1.9307832422586522,
      "grad_norm": 0.5631071925163269,
      "learning_rate": 1.7425622343655132e-05,
      "loss": 0.0941,
      "step": 18020
    },
    {
      "epoch": 1.9318547090967535,
      "grad_norm": 0.03355428948998451,
      "learning_rate": 1.742419372120433e-05,
      "loss": 0.0017,
      "step": 18030
    },
    {
      "epoch": 1.9329261759348548,
      "grad_norm": 0.04700890928506851,
      "learning_rate": 1.7422765098753528e-05,
      "loss": 0.5367,
      "step": 18040
    },
    {
      "epoch": 1.9339976427729562,
      "grad_norm": 0.08957739174365997,
      "learning_rate": 1.7421336476302727e-05,
      "loss": 0.3646,
      "step": 18050
    },
    {
      "epoch": 1.9350691096110575,
      "grad_norm": 0.3056093156337738,
      "learning_rate": 1.7419907853851927e-05,
      "loss": 0.2537,
      "step": 18060
    },
    {
      "epoch": 1.936140576449159,
      "grad_norm": 0.4134758412837982,
      "learning_rate": 1.7418479231401123e-05,
      "loss": 0.2402,
      "step": 18070
    },
    {
      "epoch": 1.9372120432872602,
      "grad_norm": 0.05015556886792183,
      "learning_rate": 1.7417050608950322e-05,
      "loss": 0.1527,
      "step": 18080
    },
    {
      "epoch": 1.9382835101253617,
      "grad_norm": 2337.844482421875,
      "learning_rate": 1.741562198649952e-05,
      "loss": 0.3575,
      "step": 18090
    },
    {
      "epoch": 1.9393549769634628,
      "grad_norm": 0.0989098772406578,
      "learning_rate": 1.7414193364048717e-05,
      "loss": 0.6078,
      "step": 18100
    },
    {
      "epoch": 1.9404264438015644,
      "grad_norm": 0.053594935685396194,
      "learning_rate": 1.7412764741597917e-05,
      "loss": 0.1549,
      "step": 18110
    },
    {
      "epoch": 1.9414979106396657,
      "grad_norm": 0.01306726410984993,
      "learning_rate": 1.7411336119147113e-05,
      "loss": 0.0031,
      "step": 18120
    },
    {
      "epoch": 1.942569377477767,
      "grad_norm": 20.52798080444336,
      "learning_rate": 1.7409907496696312e-05,
      "loss": 0.8466,
      "step": 18130
    },
    {
      "epoch": 1.9436408443158686,
      "grad_norm": 0.10442395508289337,
      "learning_rate": 1.7408478874245508e-05,
      "loss": 0.3502,
      "step": 18140
    },
    {
      "epoch": 1.9447123111539697,
      "grad_norm": 0.3487834632396698,
      "learning_rate": 1.7407050251794707e-05,
      "loss": 0.627,
      "step": 18150
    },
    {
      "epoch": 1.9457837779920713,
      "grad_norm": 0.28508082032203674,
      "learning_rate": 1.7405621629343907e-05,
      "loss": 0.4182,
      "step": 18160
    },
    {
      "epoch": 1.9468552448301724,
      "grad_norm": 17.388591766357422,
      "learning_rate": 1.7404193006893103e-05,
      "loss": 0.524,
      "step": 18170
    },
    {
      "epoch": 1.947926711668274,
      "grad_norm": 0.44289031624794006,
      "learning_rate": 1.7402764384442302e-05,
      "loss": 0.4163,
      "step": 18180
    },
    {
      "epoch": 1.9489981785063752,
      "grad_norm": 0.09053380787372589,
      "learning_rate": 1.74013357619915e-05,
      "loss": 0.1346,
      "step": 18190
    },
    {
      "epoch": 1.9500696453444766,
      "grad_norm": 16.643478393554688,
      "learning_rate": 1.73999071395407e-05,
      "loss": 0.545,
      "step": 18200
    },
    {
      "epoch": 1.951141112182578,
      "grad_norm": 0.3275066912174225,
      "learning_rate": 1.73984785170899e-05,
      "loss": 0.5125,
      "step": 18210
    },
    {
      "epoch": 1.9522125790206792,
      "grad_norm": 0.04737676680088043,
      "learning_rate": 1.7397049894639096e-05,
      "loss": 0.0125,
      "step": 18220
    },
    {
      "epoch": 1.9532840458587808,
      "grad_norm": 0.04005281254649162,
      "learning_rate": 1.7395621272188295e-05,
      "loss": 0.3573,
      "step": 18230
    },
    {
      "epoch": 1.954355512696882,
      "grad_norm": 0.022637607529759407,
      "learning_rate": 1.739419264973749e-05,
      "loss": 0.4,
      "step": 18240
    },
    {
      "epoch": 1.9554269795349835,
      "grad_norm": 27.23639678955078,
      "learning_rate": 1.739276402728669e-05,
      "loss": 0.2641,
      "step": 18250
    },
    {
      "epoch": 1.9564984463730848,
      "grad_norm": 0.15758076310157776,
      "learning_rate": 1.7391335404835887e-05,
      "loss": 0.0849,
      "step": 18260
    },
    {
      "epoch": 1.9575699132111861,
      "grad_norm": 1.2189671993255615,
      "learning_rate": 1.7389906782385086e-05,
      "loss": 0.131,
      "step": 18270
    },
    {
      "epoch": 1.9586413800492875,
      "grad_norm": 16.777782440185547,
      "learning_rate": 1.7388478159934286e-05,
      "loss": 0.707,
      "step": 18280
    },
    {
      "epoch": 1.9597128468873888,
      "grad_norm": 0.635205864906311,
      "learning_rate": 1.738704953748348e-05,
      "loss": 0.3092,
      "step": 18290
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.02009710483253002,
      "learning_rate": 1.738562091503268e-05,
      "loss": 0.0015,
      "step": 18300
    },
    {
      "epoch": 1.9618557805635914,
      "grad_norm": 32.144901275634766,
      "learning_rate": 1.7384192292581877e-05,
      "loss": 0.2344,
      "step": 18310
    },
    {
      "epoch": 1.962927247401693,
      "grad_norm": 0.9168131351470947,
      "learning_rate": 1.7382763670131076e-05,
      "loss": 0.4962,
      "step": 18320
    },
    {
      "epoch": 1.9639987142397943,
      "grad_norm": 0.7353819012641907,
      "learning_rate": 1.7381335047680276e-05,
      "loss": 0.4977,
      "step": 18330
    },
    {
      "epoch": 1.9650701810778957,
      "grad_norm": 0.024638449773192406,
      "learning_rate": 1.7379906425229475e-05,
      "loss": 0.1092,
      "step": 18340
    },
    {
      "epoch": 1.966141647915997,
      "grad_norm": 0.027389688417315483,
      "learning_rate": 1.7378477802778674e-05,
      "loss": 0.5929,
      "step": 18350
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 0.07580593228340149,
      "learning_rate": 1.737704918032787e-05,
      "loss": 0.4947,
      "step": 18360
    },
    {
      "epoch": 1.9682845815921999,
      "grad_norm": 0.25258180499076843,
      "learning_rate": 1.737562055787707e-05,
      "loss": 0.0018,
      "step": 18370
    },
    {
      "epoch": 1.969356048430301,
      "grad_norm": 0.0797613337635994,
      "learning_rate": 1.7374191935426266e-05,
      "loss": 0.1246,
      "step": 18380
    },
    {
      "epoch": 1.9704275152684025,
      "grad_norm": 0.017014607787132263,
      "learning_rate": 1.7372763312975465e-05,
      "loss": 0.0048,
      "step": 18390
    },
    {
      "epoch": 1.9714989821065037,
      "grad_norm": 0.14774189889431,
      "learning_rate": 1.7371334690524664e-05,
      "loss": 0.4101,
      "step": 18400
    },
    {
      "epoch": 1.9725704489446052,
      "grad_norm": 18.503284454345703,
      "learning_rate": 1.736990606807386e-05,
      "loss": 0.1717,
      "step": 18410
    },
    {
      "epoch": 1.9736419157827065,
      "grad_norm": 0.015794463455677032,
      "learning_rate": 1.736847744562306e-05,
      "loss": 0.1598,
      "step": 18420
    },
    {
      "epoch": 1.9747133826208079,
      "grad_norm": 0.02770521678030491,
      "learning_rate": 1.7367048823172256e-05,
      "loss": 0.24,
      "step": 18430
    },
    {
      "epoch": 1.9757848494589092,
      "grad_norm": 0.021737240254878998,
      "learning_rate": 1.7365620200721455e-05,
      "loss": 0.1798,
      "step": 18440
    },
    {
      "epoch": 1.9768563162970105,
      "grad_norm": 0.018299821764230728,
      "learning_rate": 1.7364191578270654e-05,
      "loss": 0.3459,
      "step": 18450
    },
    {
      "epoch": 1.977927783135112,
      "grad_norm": 0.0660923421382904,
      "learning_rate": 1.736276295581985e-05,
      "loss": 0.8847,
      "step": 18460
    },
    {
      "epoch": 1.9789992499732132,
      "grad_norm": 0.1298130750656128,
      "learning_rate": 1.736133433336905e-05,
      "loss": 0.2198,
      "step": 18470
    },
    {
      "epoch": 1.9800707168113147,
      "grad_norm": 0.2156345248222351,
      "learning_rate": 1.735990571091825e-05,
      "loss": 0.7996,
      "step": 18480
    },
    {
      "epoch": 1.981142183649416,
      "grad_norm": 0.9267920851707458,
      "learning_rate": 1.735847708846745e-05,
      "loss": 0.4143,
      "step": 18490
    },
    {
      "epoch": 1.9822136504875174,
      "grad_norm": 0.23039495944976807,
      "learning_rate": 1.7357048466016644e-05,
      "loss": 0.1844,
      "step": 18500
    },
    {
      "epoch": 1.9832851173256187,
      "grad_norm": 0.19192232191562653,
      "learning_rate": 1.7355619843565844e-05,
      "loss": 0.1754,
      "step": 18510
    },
    {
      "epoch": 1.98435658416372,
      "grad_norm": 23.980607986450195,
      "learning_rate": 1.7354191221115043e-05,
      "loss": 0.7129,
      "step": 18520
    },
    {
      "epoch": 1.9854280510018216,
      "grad_norm": 1.1919472217559814,
      "learning_rate": 1.735276259866424e-05,
      "loss": 0.0045,
      "step": 18530
    },
    {
      "epoch": 1.9864995178399227,
      "grad_norm": 15.875382423400879,
      "learning_rate": 1.735133397621344e-05,
      "loss": 0.3524,
      "step": 18540
    },
    {
      "epoch": 1.9875709846780243,
      "grad_norm": 0.07975456863641739,
      "learning_rate": 1.7349905353762635e-05,
      "loss": 0.6528,
      "step": 18550
    },
    {
      "epoch": 1.9886424515161256,
      "grad_norm": 0.1331322342157364,
      "learning_rate": 1.7348476731311834e-05,
      "loss": 0.1468,
      "step": 18560
    },
    {
      "epoch": 1.989713918354227,
      "grad_norm": 0.04204073175787926,
      "learning_rate": 1.7347048108861033e-05,
      "loss": 0.3266,
      "step": 18570
    },
    {
      "epoch": 1.9907853851923283,
      "grad_norm": 46.79369354248047,
      "learning_rate": 1.734561948641023e-05,
      "loss": 1.2575,
      "step": 18580
    },
    {
      "epoch": 1.9918568520304296,
      "grad_norm": 0.15441325306892395,
      "learning_rate": 1.734419086395943e-05,
      "loss": 0.0026,
      "step": 18590
    },
    {
      "epoch": 1.9929283188685312,
      "grad_norm": 0.06723131984472275,
      "learning_rate": 1.7342762241508625e-05,
      "loss": 0.217,
      "step": 18600
    },
    {
      "epoch": 1.9939997857066323,
      "grad_norm": 0.04714207723736763,
      "learning_rate": 1.7341333619057824e-05,
      "loss": 0.5059,
      "step": 18610
    },
    {
      "epoch": 1.9950712525447338,
      "grad_norm": 0.08613189309835434,
      "learning_rate": 1.7339904996607023e-05,
      "loss": 0.3934,
      "step": 18620
    },
    {
      "epoch": 1.996142719382835,
      "grad_norm": 0.02109506167471409,
      "learning_rate": 1.7338476374156223e-05,
      "loss": 0.4456,
      "step": 18630
    },
    {
      "epoch": 1.9972141862209365,
      "grad_norm": 0.3475419878959656,
      "learning_rate": 1.733704775170542e-05,
      "loss": 0.0044,
      "step": 18640
    },
    {
      "epoch": 1.9982856530590378,
      "grad_norm": 0.0059224399738013744,
      "learning_rate": 1.7335619129254618e-05,
      "loss": 0.005,
      "step": 18650
    },
    {
      "epoch": 1.9993571198971392,
      "grad_norm": 0.33182278275489807,
      "learning_rate": 1.7334190506803817e-05,
      "loss": 0.0026,
      "step": 18660
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.94,
      "eval_f1": 0.7593582887700535,
      "eval_loss": 0.32655927538871765,
      "eval_precision": 0.7686062246278755,
      "eval_recall": 0.750330250990753,
      "eval_runtime": 390.2591,
      "eval_samples_per_second": 15.374,
      "eval_steps_per_second": 5.125,
      "step": 18666
    },
    {
      "epoch": 2.0004285867352407,
      "grad_norm": 0.0169735848903656,
      "learning_rate": 1.7332761884353013e-05,
      "loss": 0.4103,
      "step": 18670
    },
    {
      "epoch": 2.001500053573342,
      "grad_norm": 27.209808349609375,
      "learning_rate": 1.7331333261902213e-05,
      "loss": 0.6078,
      "step": 18680
    },
    {
      "epoch": 2.0025715204114434,
      "grad_norm": 0.014856725931167603,
      "learning_rate": 1.7329904639451412e-05,
      "loss": 0.0017,
      "step": 18690
    },
    {
      "epoch": 2.0036429872495445,
      "grad_norm": 0.07847613841295242,
      "learning_rate": 1.7328476017000608e-05,
      "loss": 0.8962,
      "step": 18700
    },
    {
      "epoch": 2.004714454087646,
      "grad_norm": 0.043674129992723465,
      "learning_rate": 1.7327047394549807e-05,
      "loss": 0.001,
      "step": 18710
    },
    {
      "epoch": 2.005785920925747,
      "grad_norm": 0.06756289303302765,
      "learning_rate": 1.7325618772099003e-05,
      "loss": 0.1411,
      "step": 18720
    },
    {
      "epoch": 2.0068573877638487,
      "grad_norm": 0.14174051582813263,
      "learning_rate": 1.7324190149648203e-05,
      "loss": 0.0023,
      "step": 18730
    },
    {
      "epoch": 2.0079288546019503,
      "grad_norm": 0.07514888048171997,
      "learning_rate": 1.73227615271974e-05,
      "loss": 0.5165,
      "step": 18740
    },
    {
      "epoch": 2.0090003214400514,
      "grad_norm": 0.1193305253982544,
      "learning_rate": 1.7321332904746598e-05,
      "loss": 0.1405,
      "step": 18750
    },
    {
      "epoch": 2.010071788278153,
      "grad_norm": 0.07168944180011749,
      "learning_rate": 1.7319904282295798e-05,
      "loss": 0.0029,
      "step": 18760
    },
    {
      "epoch": 2.011143255116254,
      "grad_norm": 0.011018139310181141,
      "learning_rate": 1.7318475659844997e-05,
      "loss": 0.0577,
      "step": 18770
    },
    {
      "epoch": 2.0122147219543556,
      "grad_norm": 0.012808126397430897,
      "learning_rate": 1.7317047037394196e-05,
      "loss": 0.1611,
      "step": 18780
    },
    {
      "epoch": 2.0132861887924567,
      "grad_norm": 22.290908813476562,
      "learning_rate": 1.7315618414943392e-05,
      "loss": 0.6284,
      "step": 18790
    },
    {
      "epoch": 2.0143576556305582,
      "grad_norm": 0.09356182813644409,
      "learning_rate": 1.731418979249259e-05,
      "loss": 0.5295,
      "step": 18800
    },
    {
      "epoch": 2.01542912246866,
      "grad_norm": 0.1711193174123764,
      "learning_rate": 1.731276117004179e-05,
      "loss": 0.1804,
      "step": 18810
    },
    {
      "epoch": 2.016500589306761,
      "grad_norm": 0.37957310676574707,
      "learning_rate": 1.7311332547590987e-05,
      "loss": 0.2049,
      "step": 18820
    },
    {
      "epoch": 2.0175720561448625,
      "grad_norm": 0.0502578429877758,
      "learning_rate": 1.7309903925140186e-05,
      "loss": 0.1031,
      "step": 18830
    },
    {
      "epoch": 2.0186435229829636,
      "grad_norm": 0.04596677049994469,
      "learning_rate": 1.7308475302689382e-05,
      "loss": 0.3412,
      "step": 18840
    },
    {
      "epoch": 2.019714989821065,
      "grad_norm": 0.10190264135599136,
      "learning_rate": 1.730704668023858e-05,
      "loss": 0.0026,
      "step": 18850
    },
    {
      "epoch": 2.0207864566591662,
      "grad_norm": 0.04173799604177475,
      "learning_rate": 1.7305618057787778e-05,
      "loss": 0.4462,
      "step": 18860
    },
    {
      "epoch": 2.021857923497268,
      "grad_norm": 0.6298486590385437,
      "learning_rate": 1.7304189435336977e-05,
      "loss": 0.0939,
      "step": 18870
    },
    {
      "epoch": 2.0229293903353693,
      "grad_norm": 0.03737927973270416,
      "learning_rate": 1.7302760812886176e-05,
      "loss": 0.5791,
      "step": 18880
    },
    {
      "epoch": 2.0240008571734704,
      "grad_norm": 0.0560903325676918,
      "learning_rate": 1.7301332190435372e-05,
      "loss": 0.4779,
      "step": 18890
    },
    {
      "epoch": 2.025072324011572,
      "grad_norm": 0.6123987436294556,
      "learning_rate": 1.7299903567984572e-05,
      "loss": 0.3658,
      "step": 18900
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.18308347463607788,
      "learning_rate": 1.729847494553377e-05,
      "loss": 0.1155,
      "step": 18910
    },
    {
      "epoch": 2.0272152576877747,
      "grad_norm": 0.08498990535736084,
      "learning_rate": 1.729704632308297e-05,
      "loss": 0.6804,
      "step": 18920
    },
    {
      "epoch": 2.0282867245258758,
      "grad_norm": 0.04490466043353081,
      "learning_rate": 1.7295617700632166e-05,
      "loss": 0.2859,
      "step": 18930
    },
    {
      "epoch": 2.0293581913639773,
      "grad_norm": 0.09593044966459274,
      "learning_rate": 1.7294189078181366e-05,
      "loss": 0.0022,
      "step": 18940
    },
    {
      "epoch": 2.0304296582020784,
      "grad_norm": 0.7045512199401855,
      "learning_rate": 1.7292760455730565e-05,
      "loss": 0.1434,
      "step": 18950
    },
    {
      "epoch": 2.03150112504018,
      "grad_norm": 0.12019465863704681,
      "learning_rate": 1.729133183327976e-05,
      "loss": 0.1645,
      "step": 18960
    },
    {
      "epoch": 2.0325725918782815,
      "grad_norm": 0.19390778243541718,
      "learning_rate": 1.728990321082896e-05,
      "loss": 0.2745,
      "step": 18970
    },
    {
      "epoch": 2.0336440587163827,
      "grad_norm": 0.0707363709807396,
      "learning_rate": 1.7288474588378156e-05,
      "loss": 0.1473,
      "step": 18980
    },
    {
      "epoch": 2.034715525554484,
      "grad_norm": 16.439685821533203,
      "learning_rate": 1.7287045965927356e-05,
      "loss": 0.505,
      "step": 18990
    },
    {
      "epoch": 2.0357869923925853,
      "grad_norm": 20.293659210205078,
      "learning_rate": 1.7285617343476555e-05,
      "loss": 0.3067,
      "step": 19000
    },
    {
      "epoch": 2.036858459230687,
      "grad_norm": 0.04688933491706848,
      "learning_rate": 1.728418872102575e-05,
      "loss": 0.0034,
      "step": 19010
    },
    {
      "epoch": 2.037929926068788,
      "grad_norm": 0.012069528922438622,
      "learning_rate": 1.728276009857495e-05,
      "loss": 0.0036,
      "step": 19020
    },
    {
      "epoch": 2.0390013929068895,
      "grad_norm": 0.07880871742963791,
      "learning_rate": 1.7281331476124147e-05,
      "loss": 0.3061,
      "step": 19030
    },
    {
      "epoch": 2.040072859744991,
      "grad_norm": 0.09472555667161942,
      "learning_rate": 1.7279902853673346e-05,
      "loss": 0.4491,
      "step": 19040
    },
    {
      "epoch": 2.041144326583092,
      "grad_norm": 0.0876382365822792,
      "learning_rate": 1.7278474231222545e-05,
      "loss": 0.1521,
      "step": 19050
    },
    {
      "epoch": 2.0422157934211937,
      "grad_norm": 0.005172581411898136,
      "learning_rate": 1.7277045608771745e-05,
      "loss": 0.366,
      "step": 19060
    },
    {
      "epoch": 2.043287260259295,
      "grad_norm": 0.18117831647396088,
      "learning_rate": 1.727561698632094e-05,
      "loss": 0.4359,
      "step": 19070
    },
    {
      "epoch": 2.0443587270973964,
      "grad_norm": 0.1336248517036438,
      "learning_rate": 1.727418836387014e-05,
      "loss": 0.0012,
      "step": 19080
    },
    {
      "epoch": 2.0454301939354975,
      "grad_norm": 0.020311962813138962,
      "learning_rate": 1.727275974141934e-05,
      "loss": 0.2331,
      "step": 19090
    },
    {
      "epoch": 2.046501660773599,
      "grad_norm": 0.0063216835260391235,
      "learning_rate": 1.7271331118968535e-05,
      "loss": 0.0646,
      "step": 19100
    },
    {
      "epoch": 2.0475731276117006,
      "grad_norm": 0.01764487288892269,
      "learning_rate": 1.7269902496517735e-05,
      "loss": 0.3907,
      "step": 19110
    },
    {
      "epoch": 2.0486445944498017,
      "grad_norm": 0.17019346356391907,
      "learning_rate": 1.7268473874066934e-05,
      "loss": 0.4265,
      "step": 19120
    },
    {
      "epoch": 2.0497160612879033,
      "grad_norm": 0.048955947160720825,
      "learning_rate": 1.726704525161613e-05,
      "loss": 0.0419,
      "step": 19130
    },
    {
      "epoch": 2.0507875281260044,
      "grad_norm": 0.2596893310546875,
      "learning_rate": 1.726561662916533e-05,
      "loss": 0.6001,
      "step": 19140
    },
    {
      "epoch": 2.051858994964106,
      "grad_norm": 0.19215832650661469,
      "learning_rate": 1.7264188006714525e-05,
      "loss": 0.1268,
      "step": 19150
    },
    {
      "epoch": 2.052930461802207,
      "grad_norm": 0.039976585656404495,
      "learning_rate": 1.7262759384263725e-05,
      "loss": 0.1772,
      "step": 19160
    },
    {
      "epoch": 2.0540019286403086,
      "grad_norm": 19.53426742553711,
      "learning_rate": 1.726133076181292e-05,
      "loss": 0.4754,
      "step": 19170
    },
    {
      "epoch": 2.0550733954784097,
      "grad_norm": 0.1676570177078247,
      "learning_rate": 1.725990213936212e-05,
      "loss": 0.125,
      "step": 19180
    },
    {
      "epoch": 2.0561448623165113,
      "grad_norm": 0.04866686090826988,
      "learning_rate": 1.725847351691132e-05,
      "loss": 0.1034,
      "step": 19190
    },
    {
      "epoch": 2.057216329154613,
      "grad_norm": 0.0369696281850338,
      "learning_rate": 1.725704489446052e-05,
      "loss": 0.0011,
      "step": 19200
    },
    {
      "epoch": 2.058287795992714,
      "grad_norm": 1.2474956512451172,
      "learning_rate": 1.7255616272009715e-05,
      "loss": 0.4502,
      "step": 19210
    },
    {
      "epoch": 2.0593592628308155,
      "grad_norm": 0.2444629967212677,
      "learning_rate": 1.7254187649558914e-05,
      "loss": 0.3917,
      "step": 19220
    },
    {
      "epoch": 2.0604307296689166,
      "grad_norm": 0.08373314142227173,
      "learning_rate": 1.7252759027108114e-05,
      "loss": 0.3701,
      "step": 19230
    },
    {
      "epoch": 2.061502196507018,
      "grad_norm": 0.33392533659935,
      "learning_rate": 1.7251330404657313e-05,
      "loss": 0.3103,
      "step": 19240
    },
    {
      "epoch": 2.0625736633451193,
      "grad_norm": 0.12173078954219818,
      "learning_rate": 1.724990178220651e-05,
      "loss": 0.513,
      "step": 19250
    },
    {
      "epoch": 2.063645130183221,
      "grad_norm": 8.087878227233887,
      "learning_rate": 1.7248473159755708e-05,
      "loss": 0.1479,
      "step": 19260
    },
    {
      "epoch": 2.0647165970213224,
      "grad_norm": 0.025890082120895386,
      "learning_rate": 1.7247044537304904e-05,
      "loss": 0.0239,
      "step": 19270
    },
    {
      "epoch": 2.0657880638594235,
      "grad_norm": 0.11952715367078781,
      "learning_rate": 1.7245615914854104e-05,
      "loss": 0.229,
      "step": 19280
    },
    {
      "epoch": 2.066859530697525,
      "grad_norm": 0.10745459049940109,
      "learning_rate": 1.72441872924033e-05,
      "loss": 0.1388,
      "step": 19290
    },
    {
      "epoch": 2.067930997535626,
      "grad_norm": 23.726736068725586,
      "learning_rate": 1.72427586699525e-05,
      "loss": 0.5274,
      "step": 19300
    },
    {
      "epoch": 2.0690024643737277,
      "grad_norm": 0.010299664922058582,
      "learning_rate": 1.7241330047501698e-05,
      "loss": 0.6103,
      "step": 19310
    },
    {
      "epoch": 2.070073931211829,
      "grad_norm": 0.010723719373345375,
      "learning_rate": 1.7239901425050894e-05,
      "loss": 0.1282,
      "step": 19320
    },
    {
      "epoch": 2.0711453980499304,
      "grad_norm": 0.1240839958190918,
      "learning_rate": 1.7238472802600094e-05,
      "loss": 0.4174,
      "step": 19330
    },
    {
      "epoch": 2.072216864888032,
      "grad_norm": 0.09049985557794571,
      "learning_rate": 1.7237044180149293e-05,
      "loss": 0.0021,
      "step": 19340
    },
    {
      "epoch": 2.073288331726133,
      "grad_norm": 0.10898270457983017,
      "learning_rate": 1.7235615557698492e-05,
      "loss": 0.0678,
      "step": 19350
    },
    {
      "epoch": 2.0743597985642346,
      "grad_norm": 0.029428834095597267,
      "learning_rate": 1.723418693524769e-05,
      "loss": 0.1303,
      "step": 19360
    },
    {
      "epoch": 2.0754312654023357,
      "grad_norm": 0.7527635097503662,
      "learning_rate": 1.7232758312796888e-05,
      "loss": 0.1223,
      "step": 19370
    },
    {
      "epoch": 2.0765027322404372,
      "grad_norm": 0.9977679252624512,
      "learning_rate": 1.7231329690346087e-05,
      "loss": 0.6175,
      "step": 19380
    },
    {
      "epoch": 2.0775741990785384,
      "grad_norm": 0.0042390660382807255,
      "learning_rate": 1.7229901067895283e-05,
      "loss": 0.4765,
      "step": 19390
    },
    {
      "epoch": 2.07864566591664,
      "grad_norm": 0.4306614398956299,
      "learning_rate": 1.7228472445444482e-05,
      "loss": 0.1365,
      "step": 19400
    },
    {
      "epoch": 2.079717132754741,
      "grad_norm": 0.01086838822811842,
      "learning_rate": 1.722704382299368e-05,
      "loss": 0.003,
      "step": 19410
    },
    {
      "epoch": 2.0807885995928426,
      "grad_norm": 0.27622342109680176,
      "learning_rate": 1.7225615200542878e-05,
      "loss": 0.1137,
      "step": 19420
    },
    {
      "epoch": 2.081860066430944,
      "grad_norm": 0.008179194293916225,
      "learning_rate": 1.7224186578092077e-05,
      "loss": 0.1102,
      "step": 19430
    },
    {
      "epoch": 2.0829315332690452,
      "grad_norm": 0.0025440191384404898,
      "learning_rate": 1.7222757955641273e-05,
      "loss": 0.0004,
      "step": 19440
    },
    {
      "epoch": 2.084003000107147,
      "grad_norm": 0.005907129030674696,
      "learning_rate": 1.7221329333190472e-05,
      "loss": 0.0017,
      "step": 19450
    },
    {
      "epoch": 2.085074466945248,
      "grad_norm": 0.022474465891718864,
      "learning_rate": 1.721990071073967e-05,
      "loss": 0.3103,
      "step": 19460
    },
    {
      "epoch": 2.0861459337833494,
      "grad_norm": 0.033603355288505554,
      "learning_rate": 1.7218472088288868e-05,
      "loss": 0.0046,
      "step": 19470
    },
    {
      "epoch": 2.0872174006214506,
      "grad_norm": 0.0352834053337574,
      "learning_rate": 1.7217043465838067e-05,
      "loss": 0.2648,
      "step": 19480
    },
    {
      "epoch": 2.088288867459552,
      "grad_norm": 0.04305622726678848,
      "learning_rate": 1.7215614843387267e-05,
      "loss": 0.1507,
      "step": 19490
    },
    {
      "epoch": 2.0893603342976537,
      "grad_norm": 1330.83203125,
      "learning_rate": 1.7214186220936463e-05,
      "loss": 0.4481,
      "step": 19500
    },
    {
      "epoch": 2.0904318011357548,
      "grad_norm": 0.4864092171192169,
      "learning_rate": 1.7212757598485662e-05,
      "loss": 0.4431,
      "step": 19510
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 76.9105453491211,
      "learning_rate": 1.721132897603486e-05,
      "loss": 0.2152,
      "step": 19520
    },
    {
      "epoch": 2.0925747348119574,
      "grad_norm": 0.5804142951965332,
      "learning_rate": 1.7209900353584057e-05,
      "loss": 0.3171,
      "step": 19530
    },
    {
      "epoch": 2.093646201650059,
      "grad_norm": 0.03442341461777687,
      "learning_rate": 1.7208471731133257e-05,
      "loss": 0.2435,
      "step": 19540
    },
    {
      "epoch": 2.09471766848816,
      "grad_norm": 0.007503327447921038,
      "learning_rate": 1.7207043108682456e-05,
      "loss": 0.2209,
      "step": 19550
    },
    {
      "epoch": 2.0957891353262617,
      "grad_norm": 0.06827626377344131,
      "learning_rate": 1.7205614486231652e-05,
      "loss": 0.2276,
      "step": 19560
    },
    {
      "epoch": 2.096860602164363,
      "grad_norm": 0.10705795884132385,
      "learning_rate": 1.720418586378085e-05,
      "loss": 0.0074,
      "step": 19570
    },
    {
      "epoch": 2.0979320690024643,
      "grad_norm": 0.04678131639957428,
      "learning_rate": 1.7202757241330047e-05,
      "loss": 0.1486,
      "step": 19580
    },
    {
      "epoch": 2.099003535840566,
      "grad_norm": 0.043601907789707184,
      "learning_rate": 1.7201328618879247e-05,
      "loss": 0.0019,
      "step": 19590
    },
    {
      "epoch": 2.100075002678667,
      "grad_norm": 0.10872259736061096,
      "learning_rate": 1.7199899996428446e-05,
      "loss": 0.0006,
      "step": 19600
    },
    {
      "epoch": 2.1011464695167685,
      "grad_norm": 0.09268900752067566,
      "learning_rate": 1.7198471373977642e-05,
      "loss": 0.5134,
      "step": 19610
    },
    {
      "epoch": 2.1022179363548696,
      "grad_norm": 0.004015190061181784,
      "learning_rate": 1.719704275152684e-05,
      "loss": 0.3267,
      "step": 19620
    },
    {
      "epoch": 2.103289403192971,
      "grad_norm": 0.22211508452892303,
      "learning_rate": 1.719561412907604e-05,
      "loss": 0.4948,
      "step": 19630
    },
    {
      "epoch": 2.1043608700310727,
      "grad_norm": 0.03634999692440033,
      "learning_rate": 1.7194185506625237e-05,
      "loss": 0.29,
      "step": 19640
    },
    {
      "epoch": 2.105432336869174,
      "grad_norm": 4.911064147949219,
      "learning_rate": 1.7192756884174436e-05,
      "loss": 0.2879,
      "step": 19650
    },
    {
      "epoch": 2.1065038037072754,
      "grad_norm": 0.15912175178527832,
      "learning_rate": 1.7191328261723635e-05,
      "loss": 0.2778,
      "step": 19660
    },
    {
      "epoch": 2.1075752705453765,
      "grad_norm": 0.020335355773568153,
      "learning_rate": 1.7189899639272835e-05,
      "loss": 0.2742,
      "step": 19670
    },
    {
      "epoch": 2.108646737383478,
      "grad_norm": 0.03674868866801262,
      "learning_rate": 1.718847101682203e-05,
      "loss": 0.4387,
      "step": 19680
    },
    {
      "epoch": 2.109718204221579,
      "grad_norm": 0.14984337985515594,
      "learning_rate": 1.718704239437123e-05,
      "loss": 0.1297,
      "step": 19690
    },
    {
      "epoch": 2.1107896710596807,
      "grad_norm": 0.02830883115530014,
      "learning_rate": 1.7185613771920426e-05,
      "loss": 0.0023,
      "step": 19700
    },
    {
      "epoch": 2.1118611378977823,
      "grad_norm": 0.0066251615062355995,
      "learning_rate": 1.7184185149469626e-05,
      "loss": 0.3756,
      "step": 19710
    },
    {
      "epoch": 2.1129326047358834,
      "grad_norm": 0.42604875564575195,
      "learning_rate": 1.7182756527018825e-05,
      "loss": 0.0036,
      "step": 19720
    },
    {
      "epoch": 2.114004071573985,
      "grad_norm": 0.33374151587486267,
      "learning_rate": 1.718132790456802e-05,
      "loss": 0.1399,
      "step": 19730
    },
    {
      "epoch": 2.115075538412086,
      "grad_norm": 0.20357897877693176,
      "learning_rate": 1.717989928211722e-05,
      "loss": 0.4302,
      "step": 19740
    },
    {
      "epoch": 2.1161470052501876,
      "grad_norm": 0.026903895661234856,
      "learning_rate": 1.7178470659666416e-05,
      "loss": 0.156,
      "step": 19750
    },
    {
      "epoch": 2.1172184720882887,
      "grad_norm": 0.33475542068481445,
      "learning_rate": 1.7177042037215616e-05,
      "loss": 0.3728,
      "step": 19760
    },
    {
      "epoch": 2.1182899389263903,
      "grad_norm": 0.045437026768922806,
      "learning_rate": 1.7175613414764815e-05,
      "loss": 0.2117,
      "step": 19770
    },
    {
      "epoch": 2.1193614057644914,
      "grad_norm": 0.006896597798913717,
      "learning_rate": 1.717418479231401e-05,
      "loss": 0.0086,
      "step": 19780
    },
    {
      "epoch": 2.120432872602593,
      "grad_norm": 0.2006913721561432,
      "learning_rate": 1.717275616986321e-05,
      "loss": 0.5245,
      "step": 19790
    },
    {
      "epoch": 2.1215043394406945,
      "grad_norm": 0.008604314178228378,
      "learning_rate": 1.717132754741241e-05,
      "loss": 0.0014,
      "step": 19800
    },
    {
      "epoch": 2.1225758062787956,
      "grad_norm": 1.3232489824295044,
      "learning_rate": 1.716989892496161e-05,
      "loss": 0.2143,
      "step": 19810
    },
    {
      "epoch": 2.123647273116897,
      "grad_norm": 0.011425107717514038,
      "learning_rate": 1.7168470302510805e-05,
      "loss": 0.0015,
      "step": 19820
    },
    {
      "epoch": 2.1247187399549983,
      "grad_norm": 0.10145819932222366,
      "learning_rate": 1.7167041680060004e-05,
      "loss": 0.2464,
      "step": 19830
    },
    {
      "epoch": 2.1257902067931,
      "grad_norm": 0.034869030117988586,
      "learning_rate": 1.7165613057609204e-05,
      "loss": 0.5617,
      "step": 19840
    },
    {
      "epoch": 2.126861673631201,
      "grad_norm": 0.11152138561010361,
      "learning_rate": 1.71641844351584e-05,
      "loss": 0.723,
      "step": 19850
    },
    {
      "epoch": 2.1279331404693025,
      "grad_norm": 0.13155533373355865,
      "learning_rate": 1.71627558127076e-05,
      "loss": 0.3374,
      "step": 19860
    },
    {
      "epoch": 2.129004607307404,
      "grad_norm": 0.11734405159950256,
      "learning_rate": 1.7161327190256795e-05,
      "loss": 0.0063,
      "step": 19870
    },
    {
      "epoch": 2.130076074145505,
      "grad_norm": 0.17286907136440277,
      "learning_rate": 1.7159898567805994e-05,
      "loss": 0.1875,
      "step": 19880
    },
    {
      "epoch": 2.1311475409836067,
      "grad_norm": 0.09853676706552505,
      "learning_rate": 1.715846994535519e-05,
      "loss": 0.2796,
      "step": 19890
    },
    {
      "epoch": 2.132219007821708,
      "grad_norm": 0.06013278290629387,
      "learning_rate": 1.715704132290439e-05,
      "loss": 0.1959,
      "step": 19900
    },
    {
      "epoch": 2.1332904746598094,
      "grad_norm": 16.20682144165039,
      "learning_rate": 1.715561270045359e-05,
      "loss": 0.1705,
      "step": 19910
    },
    {
      "epoch": 2.1343619414979105,
      "grad_norm": 0.06490267068147659,
      "learning_rate": 1.715418407800279e-05,
      "loss": 0.0023,
      "step": 19920
    },
    {
      "epoch": 2.135433408336012,
      "grad_norm": 0.05241551995277405,
      "learning_rate": 1.7152755455551984e-05,
      "loss": 0.0007,
      "step": 19930
    },
    {
      "epoch": 2.136504875174113,
      "grad_norm": 35.902076721191406,
      "learning_rate": 1.7151326833101184e-05,
      "loss": 0.4072,
      "step": 19940
    },
    {
      "epoch": 2.1375763420122147,
      "grad_norm": 0.02051682397723198,
      "learning_rate": 1.7149898210650383e-05,
      "loss": 0.0008,
      "step": 19950
    },
    {
      "epoch": 2.1386478088503162,
      "grad_norm": 29.43474769592285,
      "learning_rate": 1.714846958819958e-05,
      "loss": 0.2144,
      "step": 19960
    },
    {
      "epoch": 2.1397192756884174,
      "grad_norm": 0.008453070186078548,
      "learning_rate": 1.714704096574878e-05,
      "loss": 0.0014,
      "step": 19970
    },
    {
      "epoch": 2.140790742526519,
      "grad_norm": 0.172653928399086,
      "learning_rate": 1.7145612343297978e-05,
      "loss": 0.1262,
      "step": 19980
    },
    {
      "epoch": 2.14186220936462,
      "grad_norm": 0.1299215704202652,
      "learning_rate": 1.7144183720847174e-05,
      "loss": 0.1682,
      "step": 19990
    },
    {
      "epoch": 2.1429336762027216,
      "grad_norm": 0.012945092283189297,
      "learning_rate": 1.7142755098396373e-05,
      "loss": 0.2877,
      "step": 20000
    },
    {
      "epoch": 2.1440051430408227,
      "grad_norm": 0.005741731263697147,
      "learning_rate": 1.714132647594557e-05,
      "loss": 0.3613,
      "step": 20010
    },
    {
      "epoch": 2.1450766098789242,
      "grad_norm": 0.06909745186567307,
      "learning_rate": 1.713989785349477e-05,
      "loss": 0.1798,
      "step": 20020
    },
    {
      "epoch": 2.146148076717026,
      "grad_norm": 0.03947147727012634,
      "learning_rate": 1.7138469231043968e-05,
      "loss": 0.0023,
      "step": 20030
    },
    {
      "epoch": 2.147219543555127,
      "grad_norm": 0.15674982964992523,
      "learning_rate": 1.7137040608593164e-05,
      "loss": 0.102,
      "step": 20040
    },
    {
      "epoch": 2.1482910103932285,
      "grad_norm": 31.95326805114746,
      "learning_rate": 1.7135611986142363e-05,
      "loss": 0.5382,
      "step": 20050
    },
    {
      "epoch": 2.1493624772313296,
      "grad_norm": 0.014864942990243435,
      "learning_rate": 1.7134183363691563e-05,
      "loss": 0.001,
      "step": 20060
    },
    {
      "epoch": 2.150433944069431,
      "grad_norm": 0.00689390953630209,
      "learning_rate": 1.713275474124076e-05,
      "loss": 0.4457,
      "step": 20070
    },
    {
      "epoch": 2.1515054109075322,
      "grad_norm": 0.06308254599571228,
      "learning_rate": 1.7131326118789958e-05,
      "loss": 0.0019,
      "step": 20080
    },
    {
      "epoch": 2.1525768777456338,
      "grad_norm": 0.012401235289871693,
      "learning_rate": 1.7129897496339157e-05,
      "loss": 0.23,
      "step": 20090
    },
    {
      "epoch": 2.1536483445837353,
      "grad_norm": 0.04976385086774826,
      "learning_rate": 1.7128468873888357e-05,
      "loss": 0.122,
      "step": 20100
    },
    {
      "epoch": 2.1547198114218364,
      "grad_norm": 0.01128616277128458,
      "learning_rate": 1.7127040251437553e-05,
      "loss": 0.1854,
      "step": 20110
    },
    {
      "epoch": 2.155791278259938,
      "grad_norm": 0.002522092778235674,
      "learning_rate": 1.7125611628986752e-05,
      "loss": 0.0004,
      "step": 20120
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.0666469857096672,
      "learning_rate": 1.7124183006535948e-05,
      "loss": 0.4191,
      "step": 20130
    },
    {
      "epoch": 2.1579342119361407,
      "grad_norm": 0.02109583094716072,
      "learning_rate": 1.7122754384085147e-05,
      "loss": 0.4705,
      "step": 20140
    },
    {
      "epoch": 2.1590056787742418,
      "grad_norm": 0.11180011928081512,
      "learning_rate": 1.7121325761634347e-05,
      "loss": 0.0039,
      "step": 20150
    },
    {
      "epoch": 2.1600771456123433,
      "grad_norm": 0.10964281111955643,
      "learning_rate": 1.7119897139183543e-05,
      "loss": 0.5949,
      "step": 20160
    },
    {
      "epoch": 2.161148612450445,
      "grad_norm": 0.010897924192249775,
      "learning_rate": 1.7118468516732742e-05,
      "loss": 0.0018,
      "step": 20170
    },
    {
      "epoch": 2.162220079288546,
      "grad_norm": 0.02363850176334381,
      "learning_rate": 1.7117039894281938e-05,
      "loss": 0.1449,
      "step": 20180
    },
    {
      "epoch": 2.1632915461266475,
      "grad_norm": 16.10988998413086,
      "learning_rate": 1.7115611271831138e-05,
      "loss": 0.1186,
      "step": 20190
    },
    {
      "epoch": 2.1643630129647486,
      "grad_norm": 0.115870900452137,
      "learning_rate": 1.7114182649380337e-05,
      "loss": 0.1653,
      "step": 20200
    },
    {
      "epoch": 2.16543447980285,
      "grad_norm": 17.319530487060547,
      "learning_rate": 1.7112754026929533e-05,
      "loss": 0.1571,
      "step": 20210
    },
    {
      "epoch": 2.1665059466409513,
      "grad_norm": 0.004003230016678572,
      "learning_rate": 1.7111325404478732e-05,
      "loss": 0.448,
      "step": 20220
    },
    {
      "epoch": 2.167577413479053,
      "grad_norm": 0.013131840154528618,
      "learning_rate": 1.710989678202793e-05,
      "loss": 0.1632,
      "step": 20230
    },
    {
      "epoch": 2.1686488803171544,
      "grad_norm": 0.02573978900909424,
      "learning_rate": 1.710846815957713e-05,
      "loss": 0.1202,
      "step": 20240
    },
    {
      "epoch": 2.1697203471552555,
      "grad_norm": 60.1611328125,
      "learning_rate": 1.7107039537126327e-05,
      "loss": 0.4845,
      "step": 20250
    },
    {
      "epoch": 2.170791813993357,
      "grad_norm": 0.1632186472415924,
      "learning_rate": 1.7105610914675526e-05,
      "loss": 0.2655,
      "step": 20260
    },
    {
      "epoch": 2.171863280831458,
      "grad_norm": 0.07743043452501297,
      "learning_rate": 1.7104182292224726e-05,
      "loss": 0.1435,
      "step": 20270
    },
    {
      "epoch": 2.1729347476695597,
      "grad_norm": 0.005274449475109577,
      "learning_rate": 1.710275366977392e-05,
      "loss": 0.3473,
      "step": 20280
    },
    {
      "epoch": 2.174006214507661,
      "grad_norm": 0.09660772979259491,
      "learning_rate": 1.710132504732312e-05,
      "loss": 0.2457,
      "step": 20290
    },
    {
      "epoch": 2.1750776813457624,
      "grad_norm": 0.1586742401123047,
      "learning_rate": 1.7099896424872317e-05,
      "loss": 0.3153,
      "step": 20300
    },
    {
      "epoch": 2.1761491481838635,
      "grad_norm": 0.06998871266841888,
      "learning_rate": 1.7098467802421516e-05,
      "loss": 0.0069,
      "step": 20310
    },
    {
      "epoch": 2.177220615021965,
      "grad_norm": 0.3318496644496918,
      "learning_rate": 1.7097039179970712e-05,
      "loss": 0.1458,
      "step": 20320
    },
    {
      "epoch": 2.1782920818600666,
      "grad_norm": 0.004598218947649002,
      "learning_rate": 1.7095610557519912e-05,
      "loss": 0.211,
      "step": 20330
    },
    {
      "epoch": 2.1793635486981677,
      "grad_norm": 0.2370225042104721,
      "learning_rate": 1.709418193506911e-05,
      "loss": 0.1302,
      "step": 20340
    },
    {
      "epoch": 2.1804350155362693,
      "grad_norm": 0.005031112115830183,
      "learning_rate": 1.7092753312618307e-05,
      "loss": 0.2953,
      "step": 20350
    },
    {
      "epoch": 2.1815064823743704,
      "grad_norm": 0.17173323035240173,
      "learning_rate": 1.7091324690167506e-05,
      "loss": 0.0008,
      "step": 20360
    },
    {
      "epoch": 2.182577949212472,
      "grad_norm": 0.08035954087972641,
      "learning_rate": 1.7089896067716706e-05,
      "loss": 0.0017,
      "step": 20370
    },
    {
      "epoch": 2.183649416050573,
      "grad_norm": 0.06032364442944527,
      "learning_rate": 1.7088467445265905e-05,
      "loss": 0.0006,
      "step": 20380
    },
    {
      "epoch": 2.1847208828886746,
      "grad_norm": 0.02579105645418167,
      "learning_rate": 1.7087038822815105e-05,
      "loss": 0.0004,
      "step": 20390
    },
    {
      "epoch": 2.185792349726776,
      "grad_norm": 23.80088996887207,
      "learning_rate": 1.70856102003643e-05,
      "loss": 0.5326,
      "step": 20400
    },
    {
      "epoch": 2.1868638165648773,
      "grad_norm": 74.62943267822266,
      "learning_rate": 1.70841815779135e-05,
      "loss": 0.2876,
      "step": 20410
    },
    {
      "epoch": 2.187935283402979,
      "grad_norm": 35.313289642333984,
      "learning_rate": 1.7082752955462696e-05,
      "loss": 0.5613,
      "step": 20420
    },
    {
      "epoch": 2.18900675024108,
      "grad_norm": 0.058515723794698715,
      "learning_rate": 1.7081324333011895e-05,
      "loss": 0.0028,
      "step": 20430
    },
    {
      "epoch": 2.1900782170791815,
      "grad_norm": 0.04101451486349106,
      "learning_rate": 1.707989571056109e-05,
      "loss": 0.2111,
      "step": 20440
    },
    {
      "epoch": 2.1911496839172826,
      "grad_norm": 0.0024271439760923386,
      "learning_rate": 1.707846708811029e-05,
      "loss": 0.0035,
      "step": 20450
    },
    {
      "epoch": 2.192221150755384,
      "grad_norm": 56.32242965698242,
      "learning_rate": 1.707703846565949e-05,
      "loss": 0.232,
      "step": 20460
    },
    {
      "epoch": 2.1932926175934853,
      "grad_norm": 0.03660869225859642,
      "learning_rate": 1.7075609843208686e-05,
      "loss": 0.0012,
      "step": 20470
    },
    {
      "epoch": 2.194364084431587,
      "grad_norm": 0.569676399230957,
      "learning_rate": 1.7074181220757885e-05,
      "loss": 0.3315,
      "step": 20480
    },
    {
      "epoch": 2.1954355512696884,
      "grad_norm": 0.02354096807539463,
      "learning_rate": 1.7072752598307085e-05,
      "loss": 0.3463,
      "step": 20490
    },
    {
      "epoch": 2.1965070181077895,
      "grad_norm": 1.2362571954727173,
      "learning_rate": 1.707132397585628e-05,
      "loss": 0.5498,
      "step": 20500
    },
    {
      "epoch": 2.197578484945891,
      "grad_norm": 0.005585686769336462,
      "learning_rate": 1.706989535340548e-05,
      "loss": 0.1963,
      "step": 20510
    },
    {
      "epoch": 2.198649951783992,
      "grad_norm": 0.010645843110978603,
      "learning_rate": 1.706846673095468e-05,
      "loss": 0.1234,
      "step": 20520
    },
    {
      "epoch": 2.1997214186220937,
      "grad_norm": 0.41430044174194336,
      "learning_rate": 1.706703810850388e-05,
      "loss": 0.7036,
      "step": 20530
    },
    {
      "epoch": 2.200792885460195,
      "grad_norm": 0.010627713985741138,
      "learning_rate": 1.7065609486053075e-05,
      "loss": 0.158,
      "step": 20540
    },
    {
      "epoch": 2.2018643522982964,
      "grad_norm": 28.02580451965332,
      "learning_rate": 1.7064180863602274e-05,
      "loss": 0.1903,
      "step": 20550
    },
    {
      "epoch": 2.202935819136398,
      "grad_norm": 0.029202032834291458,
      "learning_rate": 1.706275224115147e-05,
      "loss": 0.2145,
      "step": 20560
    },
    {
      "epoch": 2.204007285974499,
      "grad_norm": 27.97520637512207,
      "learning_rate": 1.706132361870067e-05,
      "loss": 0.3113,
      "step": 20570
    },
    {
      "epoch": 2.2050787528126006,
      "grad_norm": 0.2088399976491928,
      "learning_rate": 1.705989499624987e-05,
      "loss": 0.1517,
      "step": 20580
    },
    {
      "epoch": 2.2061502196507017,
      "grad_norm": 22.630109786987305,
      "learning_rate": 1.7058466373799065e-05,
      "loss": 0.1568,
      "step": 20590
    },
    {
      "epoch": 2.2072216864888032,
      "grad_norm": 0.014551050961017609,
      "learning_rate": 1.7057037751348264e-05,
      "loss": 0.1374,
      "step": 20600
    },
    {
      "epoch": 2.2082931533269043,
      "grad_norm": 0.00263663730584085,
      "learning_rate": 1.705560912889746e-05,
      "loss": 0.105,
      "step": 20610
    },
    {
      "epoch": 2.209364620165006,
      "grad_norm": 0.08834078162908554,
      "learning_rate": 1.705418050644666e-05,
      "loss": 0.3906,
      "step": 20620
    },
    {
      "epoch": 2.2104360870031075,
      "grad_norm": 0.15920798480510712,
      "learning_rate": 1.705275188399586e-05,
      "loss": 0.0042,
      "step": 20630
    },
    {
      "epoch": 2.2115075538412086,
      "grad_norm": 0.06051704287528992,
      "learning_rate": 1.7051323261545055e-05,
      "loss": 0.125,
      "step": 20640
    },
    {
      "epoch": 2.21257902067931,
      "grad_norm": 0.6367636919021606,
      "learning_rate": 1.7049894639094254e-05,
      "loss": 0.0018,
      "step": 20650
    },
    {
      "epoch": 2.2136504875174112,
      "grad_norm": 0.051739539951086044,
      "learning_rate": 1.7048466016643454e-05,
      "loss": 0.3155,
      "step": 20660
    },
    {
      "epoch": 2.214721954355513,
      "grad_norm": 0.19239212572574615,
      "learning_rate": 1.7047037394192653e-05,
      "loss": 0.2873,
      "step": 20670
    },
    {
      "epoch": 2.215793421193614,
      "grad_norm": 0.08161593228578568,
      "learning_rate": 1.704560877174185e-05,
      "loss": 0.2939,
      "step": 20680
    },
    {
      "epoch": 2.2168648880317154,
      "grad_norm": 0.04681367427110672,
      "learning_rate": 1.7044180149291048e-05,
      "loss": 0.2941,
      "step": 20690
    },
    {
      "epoch": 2.217936354869817,
      "grad_norm": 0.04855865240097046,
      "learning_rate": 1.7042751526840248e-05,
      "loss": 0.2818,
      "step": 20700
    },
    {
      "epoch": 2.219007821707918,
      "grad_norm": 0.02319803647696972,
      "learning_rate": 1.7041322904389444e-05,
      "loss": 0.1161,
      "step": 20710
    },
    {
      "epoch": 2.2200792885460197,
      "grad_norm": 0.02605651319026947,
      "learning_rate": 1.7039894281938643e-05,
      "loss": 0.3051,
      "step": 20720
    },
    {
      "epoch": 2.2211507553841208,
      "grad_norm": 0.05085599049925804,
      "learning_rate": 1.703846565948784e-05,
      "loss": 0.0013,
      "step": 20730
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 20.880495071411133,
      "learning_rate": 1.7037037037037038e-05,
      "loss": 0.1082,
      "step": 20740
    },
    {
      "epoch": 2.2232936890603234,
      "grad_norm": 0.007597566582262516,
      "learning_rate": 1.7035608414586238e-05,
      "loss": 0.161,
      "step": 20750
    },
    {
      "epoch": 2.224365155898425,
      "grad_norm": 0.010169722139835358,
      "learning_rate": 1.7034179792135434e-05,
      "loss": 0.5837,
      "step": 20760
    },
    {
      "epoch": 2.2254366227365265,
      "grad_norm": 0.0012180126504972577,
      "learning_rate": 1.7032751169684633e-05,
      "loss": 0.1376,
      "step": 20770
    },
    {
      "epoch": 2.2265080895746276,
      "grad_norm": 0.0027365137357264757,
      "learning_rate": 1.703132254723383e-05,
      "loss": 0.3617,
      "step": 20780
    },
    {
      "epoch": 2.227579556412729,
      "grad_norm": 0.014594243839383125,
      "learning_rate": 1.702989392478303e-05,
      "loss": 0.3664,
      "step": 20790
    },
    {
      "epoch": 2.2286510232508303,
      "grad_norm": 19.758255004882812,
      "learning_rate": 1.7028465302332228e-05,
      "loss": 0.3523,
      "step": 20800
    },
    {
      "epoch": 2.229722490088932,
      "grad_norm": 0.05271243676543236,
      "learning_rate": 1.7027036679881427e-05,
      "loss": 0.1828,
      "step": 20810
    },
    {
      "epoch": 2.230793956927033,
      "grad_norm": 0.021592240780591965,
      "learning_rate": 1.7025608057430626e-05,
      "loss": 0.2286,
      "step": 20820
    },
    {
      "epoch": 2.2318654237651345,
      "grad_norm": 0.008400547318160534,
      "learning_rate": 1.7024179434979822e-05,
      "loss": 0.235,
      "step": 20830
    },
    {
      "epoch": 2.2329368906032356,
      "grad_norm": 0.010789234191179276,
      "learning_rate": 1.7022750812529022e-05,
      "loss": 0.1112,
      "step": 20840
    },
    {
      "epoch": 2.234008357441337,
      "grad_norm": 0.13975630700588226,
      "learning_rate": 1.7021322190078218e-05,
      "loss": 0.4585,
      "step": 20850
    },
    {
      "epoch": 2.2350798242794387,
      "grad_norm": 0.027082188054919243,
      "learning_rate": 1.7019893567627417e-05,
      "loss": 0.5893,
      "step": 20860
    },
    {
      "epoch": 2.23615129111754,
      "grad_norm": 0.012727105990052223,
      "learning_rate": 1.7018464945176613e-05,
      "loss": 0.1003,
      "step": 20870
    },
    {
      "epoch": 2.2372227579556414,
      "grad_norm": 0.08137509226799011,
      "learning_rate": 1.7017036322725812e-05,
      "loss": 0.0023,
      "step": 20880
    },
    {
      "epoch": 2.2382942247937425,
      "grad_norm": 18.195167541503906,
      "learning_rate": 1.7015607700275012e-05,
      "loss": 0.2866,
      "step": 20890
    },
    {
      "epoch": 2.239365691631844,
      "grad_norm": 0.0038121577817946672,
      "learning_rate": 1.7014179077824208e-05,
      "loss": 0.294,
      "step": 20900
    },
    {
      "epoch": 2.240437158469945,
      "grad_norm": 0.016728760674595833,
      "learning_rate": 1.7012750455373407e-05,
      "loss": 0.002,
      "step": 20910
    },
    {
      "epoch": 2.2415086253080467,
      "grad_norm": 34.01632308959961,
      "learning_rate": 1.7011321832922603e-05,
      "loss": 0.6985,
      "step": 20920
    },
    {
      "epoch": 2.242580092146148,
      "grad_norm": 0.020857729017734528,
      "learning_rate": 1.7009893210471803e-05,
      "loss": 0.2332,
      "step": 20930
    },
    {
      "epoch": 2.2436515589842494,
      "grad_norm": 0.023153869435191154,
      "learning_rate": 1.7008464588021002e-05,
      "loss": 0.2891,
      "step": 20940
    },
    {
      "epoch": 2.244723025822351,
      "grad_norm": 0.017139986157417297,
      "learning_rate": 1.70070359655702e-05,
      "loss": 0.1321,
      "step": 20950
    },
    {
      "epoch": 2.245794492660452,
      "grad_norm": 0.006894352845847607,
      "learning_rate": 1.70056073431194e-05,
      "loss": 0.0013,
      "step": 20960
    },
    {
      "epoch": 2.2468659594985536,
      "grad_norm": 0.09469995647668839,
      "learning_rate": 1.7004178720668597e-05,
      "loss": 0.0513,
      "step": 20970
    },
    {
      "epoch": 2.2479374263366547,
      "grad_norm": 0.03950946405529976,
      "learning_rate": 1.7002750098217796e-05,
      "loss": 0.0058,
      "step": 20980
    },
    {
      "epoch": 2.2490088931747563,
      "grad_norm": 0.0030611692927777767,
      "learning_rate": 1.7001321475766992e-05,
      "loss": 0.7138,
      "step": 20990
    },
    {
      "epoch": 2.2500803600128574,
      "grad_norm": 0.017791658639907837,
      "learning_rate": 1.699989285331619e-05,
      "loss": 0.3333,
      "step": 21000
    },
    {
      "epoch": 2.251151826850959,
      "grad_norm": 4.200704574584961,
      "learning_rate": 1.699846423086539e-05,
      "loss": 0.1577,
      "step": 21010
    },
    {
      "epoch": 2.2522232936890605,
      "grad_norm": 0.009173954837024212,
      "learning_rate": 1.6997035608414587e-05,
      "loss": 0.3856,
      "step": 21020
    },
    {
      "epoch": 2.2532947605271616,
      "grad_norm": 0.25460436940193176,
      "learning_rate": 1.6995606985963786e-05,
      "loss": 0.34,
      "step": 21030
    },
    {
      "epoch": 2.254366227365263,
      "grad_norm": 4.664735317230225,
      "learning_rate": 1.6994178363512982e-05,
      "loss": 0.0028,
      "step": 21040
    },
    {
      "epoch": 2.2554376942033643,
      "grad_norm": 1.064754843711853,
      "learning_rate": 1.699274974106218e-05,
      "loss": 0.24,
      "step": 21050
    },
    {
      "epoch": 2.256509161041466,
      "grad_norm": 0.008166154846549034,
      "learning_rate": 1.699132111861138e-05,
      "loss": 0.1832,
      "step": 21060
    },
    {
      "epoch": 2.257580627879567,
      "grad_norm": 15.724507331848145,
      "learning_rate": 1.6989892496160577e-05,
      "loss": 0.5408,
      "step": 21070
    },
    {
      "epoch": 2.2586520947176685,
      "grad_norm": 0.011865378357470036,
      "learning_rate": 1.6988463873709776e-05,
      "loss": 0.0878,
      "step": 21080
    },
    {
      "epoch": 2.25972356155577,
      "grad_norm": 0.02170131728053093,
      "learning_rate": 1.6987035251258975e-05,
      "loss": 0.2564,
      "step": 21090
    },
    {
      "epoch": 2.260795028393871,
      "grad_norm": 0.013513035140931606,
      "learning_rate": 1.6985606628808175e-05,
      "loss": 0.0017,
      "step": 21100
    },
    {
      "epoch": 2.2618664952319727,
      "grad_norm": 182.1471405029297,
      "learning_rate": 1.698417800635737e-05,
      "loss": 0.187,
      "step": 21110
    },
    {
      "epoch": 2.262937962070074,
      "grad_norm": 0.007618826813995838,
      "learning_rate": 1.698274938390657e-05,
      "loss": 0.003,
      "step": 21120
    },
    {
      "epoch": 2.2640094289081754,
      "grad_norm": 17.699554443359375,
      "learning_rate": 1.698132076145577e-05,
      "loss": 0.5581,
      "step": 21130
    },
    {
      "epoch": 2.2650808957462765,
      "grad_norm": 0.023061152547597885,
      "learning_rate": 1.6979892139004966e-05,
      "loss": 0.3852,
      "step": 21140
    },
    {
      "epoch": 2.266152362584378,
      "grad_norm": 0.009983650408685207,
      "learning_rate": 1.6978463516554165e-05,
      "loss": 0.119,
      "step": 21150
    },
    {
      "epoch": 2.2672238294224796,
      "grad_norm": 31.209980010986328,
      "learning_rate": 1.697703489410336e-05,
      "loss": 0.1159,
      "step": 21160
    },
    {
      "epoch": 2.2682952962605807,
      "grad_norm": 3.20055890083313,
      "learning_rate": 1.697560627165256e-05,
      "loss": 0.3507,
      "step": 21170
    },
    {
      "epoch": 2.2693667630986822,
      "grad_norm": 0.008527175523340702,
      "learning_rate": 1.697417764920176e-05,
      "loss": 0.0017,
      "step": 21180
    },
    {
      "epoch": 2.2704382299367833,
      "grad_norm": 0.007168126758188009,
      "learning_rate": 1.6972749026750956e-05,
      "loss": 0.3107,
      "step": 21190
    },
    {
      "epoch": 2.271509696774885,
      "grad_norm": 15.474642753601074,
      "learning_rate": 1.6971320404300155e-05,
      "loss": 0.729,
      "step": 21200
    },
    {
      "epoch": 2.272581163612986,
      "grad_norm": 0.06577307730913162,
      "learning_rate": 1.696989178184935e-05,
      "loss": 0.0056,
      "step": 21210
    },
    {
      "epoch": 2.2736526304510876,
      "grad_norm": 0.01602257415652275,
      "learning_rate": 1.696846315939855e-05,
      "loss": 0.1866,
      "step": 21220
    },
    {
      "epoch": 2.274724097289189,
      "grad_norm": 0.040807899087667465,
      "learning_rate": 1.696703453694775e-05,
      "loss": 0.0868,
      "step": 21230
    },
    {
      "epoch": 2.2757955641272902,
      "grad_norm": 0.022000962868332863,
      "learning_rate": 1.696560591449695e-05,
      "loss": 0.2152,
      "step": 21240
    },
    {
      "epoch": 2.276867030965392,
      "grad_norm": 0.015518197789788246,
      "learning_rate": 1.696417729204615e-05,
      "loss": 0.2149,
      "step": 21250
    },
    {
      "epoch": 2.277938497803493,
      "grad_norm": 0.11925683915615082,
      "learning_rate": 1.6962748669595344e-05,
      "loss": 0.0044,
      "step": 21260
    },
    {
      "epoch": 2.2790099646415944,
      "grad_norm": 0.024674508720636368,
      "learning_rate": 1.6961320047144544e-05,
      "loss": 0.2624,
      "step": 21270
    },
    {
      "epoch": 2.2800814314796956,
      "grad_norm": 0.11083225905895233,
      "learning_rate": 1.695989142469374e-05,
      "loss": 0.0048,
      "step": 21280
    },
    {
      "epoch": 2.281152898317797,
      "grad_norm": 0.024000540375709534,
      "learning_rate": 1.695846280224294e-05,
      "loss": 0.0006,
      "step": 21290
    },
    {
      "epoch": 2.2822243651558987,
      "grad_norm": 0.00283398968167603,
      "learning_rate": 1.695703417979214e-05,
      "loss": 0.0005,
      "step": 21300
    },
    {
      "epoch": 2.2832958319939998,
      "grad_norm": 0.0498250387609005,
      "learning_rate": 1.6955605557341334e-05,
      "loss": 0.4089,
      "step": 21310
    },
    {
      "epoch": 2.2843672988321013,
      "grad_norm": 34.113624572753906,
      "learning_rate": 1.6954176934890534e-05,
      "loss": 0.4898,
      "step": 21320
    },
    {
      "epoch": 2.2854387656702024,
      "grad_norm": 0.07319822162389755,
      "learning_rate": 1.695274831243973e-05,
      "loss": 0.3147,
      "step": 21330
    },
    {
      "epoch": 2.286510232508304,
      "grad_norm": 0.06588053703308105,
      "learning_rate": 1.695131968998893e-05,
      "loss": 0.4978,
      "step": 21340
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 0.4044196903705597,
      "learning_rate": 1.6949891067538125e-05,
      "loss": 0.1354,
      "step": 21350
    },
    {
      "epoch": 2.2886531661845066,
      "grad_norm": 0.06637237966060638,
      "learning_rate": 1.6948462445087324e-05,
      "loss": 0.1831,
      "step": 21360
    },
    {
      "epoch": 2.2897246330226078,
      "grad_norm": 37.30400085449219,
      "learning_rate": 1.6947033822636524e-05,
      "loss": 0.3848,
      "step": 21370
    },
    {
      "epoch": 2.2907960998607093,
      "grad_norm": 0.03624076768755913,
      "learning_rate": 1.6945605200185723e-05,
      "loss": 0.0063,
      "step": 21380
    },
    {
      "epoch": 2.291867566698811,
      "grad_norm": 0.11677704751491547,
      "learning_rate": 1.6944176577734923e-05,
      "loss": 0.1903,
      "step": 21390
    },
    {
      "epoch": 2.292939033536912,
      "grad_norm": 0.00331902876496315,
      "learning_rate": 1.694274795528412e-05,
      "loss": 0.3537,
      "step": 21400
    },
    {
      "epoch": 2.2940105003750135,
      "grad_norm": 70.33528900146484,
      "learning_rate": 1.6941319332833318e-05,
      "loss": 0.3763,
      "step": 21410
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 0.08278641849756241,
      "learning_rate": 1.6939890710382517e-05,
      "loss": 0.0035,
      "step": 21420
    },
    {
      "epoch": 2.296153434051216,
      "grad_norm": 0.021832983940839767,
      "learning_rate": 1.6938462087931713e-05,
      "loss": 0.1998,
      "step": 21430
    },
    {
      "epoch": 2.2972249008893173,
      "grad_norm": 0.07090849429368973,
      "learning_rate": 1.6937033465480913e-05,
      "loss": 0.247,
      "step": 21440
    },
    {
      "epoch": 2.298296367727419,
      "grad_norm": 0.1423814743757248,
      "learning_rate": 1.693560484303011e-05,
      "loss": 0.0411,
      "step": 21450
    },
    {
      "epoch": 2.29936783456552,
      "grad_norm": 0.0125629473477602,
      "learning_rate": 1.6934176220579308e-05,
      "loss": 0.0017,
      "step": 21460
    },
    {
      "epoch": 2.3004393014036215,
      "grad_norm": 0.048819106072187424,
      "learning_rate": 1.6932747598128504e-05,
      "loss": 0.3657,
      "step": 21470
    },
    {
      "epoch": 2.301510768241723,
      "grad_norm": 0.07264464348554611,
      "learning_rate": 1.6931318975677703e-05,
      "loss": 0.2443,
      "step": 21480
    },
    {
      "epoch": 2.302582235079824,
      "grad_norm": 0.005257011391222477,
      "learning_rate": 1.6929890353226903e-05,
      "loss": 0.0011,
      "step": 21490
    },
    {
      "epoch": 2.3036537019179257,
      "grad_norm": 0.0613400824368,
      "learning_rate": 1.69284617307761e-05,
      "loss": 0.0019,
      "step": 21500
    },
    {
      "epoch": 2.304725168756027,
      "grad_norm": 0.19959190487861633,
      "learning_rate": 1.6927033108325298e-05,
      "loss": 0.0022,
      "step": 21510
    },
    {
      "epoch": 2.3057966355941284,
      "grad_norm": 0.0019602037500590086,
      "learning_rate": 1.6925604485874497e-05,
      "loss": 0.2874,
      "step": 21520
    },
    {
      "epoch": 2.3068681024322295,
      "grad_norm": 0.02540510520339012,
      "learning_rate": 1.6924175863423697e-05,
      "loss": 0.393,
      "step": 21530
    },
    {
      "epoch": 2.307939569270331,
      "grad_norm": 0.06222647428512573,
      "learning_rate": 1.6922747240972893e-05,
      "loss": 0.0007,
      "step": 21540
    },
    {
      "epoch": 2.3090110361084326,
      "grad_norm": 0.05376816168427467,
      "learning_rate": 1.6921318618522092e-05,
      "loss": 0.8886,
      "step": 21550
    },
    {
      "epoch": 2.3100825029465337,
      "grad_norm": 0.016230756416916847,
      "learning_rate": 1.691988999607129e-05,
      "loss": 0.6041,
      "step": 21560
    },
    {
      "epoch": 2.3111539697846353,
      "grad_norm": 0.11102497577667236,
      "learning_rate": 1.6918461373620487e-05,
      "loss": 0.1311,
      "step": 21570
    },
    {
      "epoch": 2.3122254366227364,
      "grad_norm": 0.012370203621685505,
      "learning_rate": 1.6917032751169687e-05,
      "loss": 0.0019,
      "step": 21580
    },
    {
      "epoch": 2.313296903460838,
      "grad_norm": 0.008690941147506237,
      "learning_rate": 1.6915604128718883e-05,
      "loss": 0.3489,
      "step": 21590
    },
    {
      "epoch": 2.314368370298939,
      "grad_norm": 0.09879917651414871,
      "learning_rate": 1.6914175506268082e-05,
      "loss": 0.4704,
      "step": 21600
    },
    {
      "epoch": 2.3154398371370406,
      "grad_norm": 0.12275511771440506,
      "learning_rate": 1.691274688381728e-05,
      "loss": 0.0013,
      "step": 21610
    },
    {
      "epoch": 2.316511303975142,
      "grad_norm": 0.010989286005496979,
      "learning_rate": 1.6911318261366478e-05,
      "loss": 0.1422,
      "step": 21620
    },
    {
      "epoch": 2.3175827708132433,
      "grad_norm": 0.08129055798053741,
      "learning_rate": 1.6909889638915677e-05,
      "loss": 0.5186,
      "step": 21630
    },
    {
      "epoch": 2.318654237651345,
      "grad_norm": 0.00312791601754725,
      "learning_rate": 1.6908461016464873e-05,
      "loss": 0.0015,
      "step": 21640
    },
    {
      "epoch": 2.319725704489446,
      "grad_norm": 0.2896565794944763,
      "learning_rate": 1.6907032394014072e-05,
      "loss": 0.2008,
      "step": 21650
    },
    {
      "epoch": 2.3207971713275475,
      "grad_norm": 0.006196795031428337,
      "learning_rate": 1.690560377156327e-05,
      "loss": 0.312,
      "step": 21660
    },
    {
      "epoch": 2.3218686381656486,
      "grad_norm": 0.0038802747149020433,
      "learning_rate": 1.690417514911247e-05,
      "loss": 0.2271,
      "step": 21670
    },
    {
      "epoch": 2.32294010500375,
      "grad_norm": 0.012773187831044197,
      "learning_rate": 1.6902746526661667e-05,
      "loss": 0.1519,
      "step": 21680
    },
    {
      "epoch": 2.3240115718418517,
      "grad_norm": 0.040541209280490875,
      "learning_rate": 1.6901317904210866e-05,
      "loss": 0.1843,
      "step": 21690
    },
    {
      "epoch": 2.325083038679953,
      "grad_norm": 0.07021746784448624,
      "learning_rate": 1.6899889281760066e-05,
      "loss": 0.0017,
      "step": 21700
    },
    {
      "epoch": 2.3261545055180544,
      "grad_norm": 0.08756732195615768,
      "learning_rate": 1.689846065930926e-05,
      "loss": 0.3662,
      "step": 21710
    },
    {
      "epoch": 2.3272259723561555,
      "grad_norm": 0.07497359067201614,
      "learning_rate": 1.689703203685846e-05,
      "loss": 0.3641,
      "step": 21720
    },
    {
      "epoch": 2.328297439194257,
      "grad_norm": 0.058489080518484116,
      "learning_rate": 1.689560341440766e-05,
      "loss": 0.1699,
      "step": 21730
    },
    {
      "epoch": 2.329368906032358,
      "grad_norm": 0.0062886495143175125,
      "learning_rate": 1.6894174791956856e-05,
      "loss": 0.0023,
      "step": 21740
    },
    {
      "epoch": 2.3304403728704597,
      "grad_norm": 0.2690158188343048,
      "learning_rate": 1.6892746169506056e-05,
      "loss": 0.3242,
      "step": 21750
    },
    {
      "epoch": 2.3315118397085612,
      "grad_norm": 0.12671062350273132,
      "learning_rate": 1.6891317547055252e-05,
      "loss": 0.3019,
      "step": 21760
    },
    {
      "epoch": 2.3325833065466623,
      "grad_norm": 0.021479133516550064,
      "learning_rate": 1.688988892460445e-05,
      "loss": 0.3745,
      "step": 21770
    },
    {
      "epoch": 2.333654773384764,
      "grad_norm": 0.209233820438385,
      "learning_rate": 1.6888460302153647e-05,
      "loss": 0.0035,
      "step": 21780
    },
    {
      "epoch": 2.334726240222865,
      "grad_norm": 0.1106138527393341,
      "learning_rate": 1.6887031679702846e-05,
      "loss": 0.0024,
      "step": 21790
    },
    {
      "epoch": 2.3357977070609666,
      "grad_norm": 0.002479820279404521,
      "learning_rate": 1.6885603057252046e-05,
      "loss": 0.0015,
      "step": 21800
    },
    {
      "epoch": 2.3368691738990677,
      "grad_norm": 0.005087162367999554,
      "learning_rate": 1.6884174434801245e-05,
      "loss": 0.0028,
      "step": 21810
    },
    {
      "epoch": 2.3379406407371692,
      "grad_norm": 0.05418265983462334,
      "learning_rate": 1.6882745812350445e-05,
      "loss": 0.6295,
      "step": 21820
    },
    {
      "epoch": 2.339012107575271,
      "grad_norm": 0.04344772547483444,
      "learning_rate": 1.688131718989964e-05,
      "loss": 0.2907,
      "step": 21830
    },
    {
      "epoch": 2.340083574413372,
      "grad_norm": 0.06828607618808746,
      "learning_rate": 1.687988856744884e-05,
      "loss": 0.1761,
      "step": 21840
    },
    {
      "epoch": 2.3411550412514734,
      "grad_norm": 0.1672193855047226,
      "learning_rate": 1.687845994499804e-05,
      "loss": 0.1518,
      "step": 21850
    },
    {
      "epoch": 2.3422265080895746,
      "grad_norm": 0.08222565799951553,
      "learning_rate": 1.6877031322547235e-05,
      "loss": 0.0009,
      "step": 21860
    },
    {
      "epoch": 2.343297974927676,
      "grad_norm": 0.0009906096383929253,
      "learning_rate": 1.6875602700096435e-05,
      "loss": 0.345,
      "step": 21870
    },
    {
      "epoch": 2.344369441765777,
      "grad_norm": 0.1118721067905426,
      "learning_rate": 1.687417407764563e-05,
      "loss": 0.1374,
      "step": 21880
    },
    {
      "epoch": 2.3454409086038788,
      "grad_norm": 0.15770947933197021,
      "learning_rate": 1.687274545519483e-05,
      "loss": 0.1559,
      "step": 21890
    },
    {
      "epoch": 2.34651237544198,
      "grad_norm": 0.000787113094702363,
      "learning_rate": 1.6871316832744026e-05,
      "loss": 0.394,
      "step": 21900
    },
    {
      "epoch": 2.3475838422800814,
      "grad_norm": 0.11504542827606201,
      "learning_rate": 1.6869888210293225e-05,
      "loss": 0.1478,
      "step": 21910
    },
    {
      "epoch": 2.3486553091181825,
      "grad_norm": 0.002898327074944973,
      "learning_rate": 1.6868459587842425e-05,
      "loss": 0.3362,
      "step": 21920
    },
    {
      "epoch": 2.349726775956284,
      "grad_norm": 0.06121106445789337,
      "learning_rate": 1.686703096539162e-05,
      "loss": 0.3947,
      "step": 21930
    },
    {
      "epoch": 2.3507982427943857,
      "grad_norm": 0.19609038531780243,
      "learning_rate": 1.686560234294082e-05,
      "loss": 0.3409,
      "step": 21940
    },
    {
      "epoch": 2.3518697096324868,
      "grad_norm": 0.19903682172298431,
      "learning_rate": 1.686417372049002e-05,
      "loss": 0.0016,
      "step": 21950
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 32.30175018310547,
      "learning_rate": 1.686274509803922e-05,
      "loss": 0.3264,
      "step": 21960
    },
    {
      "epoch": 2.3540126433086894,
      "grad_norm": 0.0166318342089653,
      "learning_rate": 1.6861316475588415e-05,
      "loss": 0.3136,
      "step": 21970
    },
    {
      "epoch": 2.355084110146791,
      "grad_norm": 0.19101464748382568,
      "learning_rate": 1.6859887853137614e-05,
      "loss": 0.1464,
      "step": 21980
    },
    {
      "epoch": 2.356155576984892,
      "grad_norm": 0.12159417569637299,
      "learning_rate": 1.6858459230686813e-05,
      "loss": 0.1345,
      "step": 21990
    },
    {
      "epoch": 2.3572270438229936,
      "grad_norm": 15.659481048583984,
      "learning_rate": 1.685703060823601e-05,
      "loss": 0.1175,
      "step": 22000
    },
    {
      "epoch": 2.358298510661095,
      "grad_norm": 0.03288723900914192,
      "learning_rate": 1.685560198578521e-05,
      "loss": 0.2637,
      "step": 22010
    },
    {
      "epoch": 2.3593699774991963,
      "grad_norm": 0.001062768162228167,
      "learning_rate": 1.6854173363334405e-05,
      "loss": 0.143,
      "step": 22020
    },
    {
      "epoch": 2.360441444337298,
      "grad_norm": 0.6460526585578918,
      "learning_rate": 1.6852744740883604e-05,
      "loss": 0.4099,
      "step": 22030
    },
    {
      "epoch": 2.361512911175399,
      "grad_norm": 0.015050560235977173,
      "learning_rate": 1.6851316118432803e-05,
      "loss": 0.0027,
      "step": 22040
    },
    {
      "epoch": 2.3625843780135005,
      "grad_norm": 0.0018761616665869951,
      "learning_rate": 1.6849887495982e-05,
      "loss": 0.3214,
      "step": 22050
    },
    {
      "epoch": 2.3636558448516016,
      "grad_norm": 0.09262846410274506,
      "learning_rate": 1.68484588735312e-05,
      "loss": 0.1061,
      "step": 22060
    },
    {
      "epoch": 2.364727311689703,
      "grad_norm": 0.24456898868083954,
      "learning_rate": 1.6847030251080395e-05,
      "loss": 0.0025,
      "step": 22070
    },
    {
      "epoch": 2.3657987785278047,
      "grad_norm": 0.09031829982995987,
      "learning_rate": 1.6845601628629594e-05,
      "loss": 0.0004,
      "step": 22080
    },
    {
      "epoch": 2.366870245365906,
      "grad_norm": 45.902381896972656,
      "learning_rate": 1.6844173006178794e-05,
      "loss": 0.5236,
      "step": 22090
    },
    {
      "epoch": 2.3679417122040074,
      "grad_norm": 0.034738145768642426,
      "learning_rate": 1.6842744383727993e-05,
      "loss": 0.2966,
      "step": 22100
    },
    {
      "epoch": 2.3690131790421085,
      "grad_norm": 0.11269489675760269,
      "learning_rate": 1.684131576127719e-05,
      "loss": 0.1573,
      "step": 22110
    },
    {
      "epoch": 2.37008464588021,
      "grad_norm": 0.019939305260777473,
      "learning_rate": 1.6839887138826388e-05,
      "loss": 0.0037,
      "step": 22120
    },
    {
      "epoch": 2.371156112718311,
      "grad_norm": 0.001534261624328792,
      "learning_rate": 1.6838458516375588e-05,
      "loss": 0.3946,
      "step": 22130
    },
    {
      "epoch": 2.3722275795564127,
      "grad_norm": 0.0024907314218580723,
      "learning_rate": 1.6837029893924784e-05,
      "loss": 0.1878,
      "step": 22140
    },
    {
      "epoch": 2.3732990463945143,
      "grad_norm": 0.0234967190772295,
      "learning_rate": 1.6835601271473983e-05,
      "loss": 0.0024,
      "step": 22150
    },
    {
      "epoch": 2.3743705132326154,
      "grad_norm": 0.0015415565576404333,
      "learning_rate": 1.6834172649023182e-05,
      "loss": 0.3265,
      "step": 22160
    },
    {
      "epoch": 2.375441980070717,
      "grad_norm": 0.11863987147808075,
      "learning_rate": 1.683274402657238e-05,
      "loss": 0.1524,
      "step": 22170
    },
    {
      "epoch": 2.376513446908818,
      "grad_norm": 0.4387996196746826,
      "learning_rate": 1.6831315404121578e-05,
      "loss": 0.4401,
      "step": 22180
    },
    {
      "epoch": 2.3775849137469196,
      "grad_norm": 1.2830921411514282,
      "learning_rate": 1.6829886781670774e-05,
      "loss": 0.4038,
      "step": 22190
    },
    {
      "epoch": 2.3786563805850207,
      "grad_norm": 0.08065467327833176,
      "learning_rate": 1.6828458159219973e-05,
      "loss": 0.3405,
      "step": 22200
    },
    {
      "epoch": 2.3797278474231223,
      "grad_norm": 62.954811096191406,
      "learning_rate": 1.6827029536769172e-05,
      "loss": 0.1469,
      "step": 22210
    },
    {
      "epoch": 2.380799314261224,
      "grad_norm": 0.5896053910255432,
      "learning_rate": 1.682560091431837e-05,
      "loss": 0.1293,
      "step": 22220
    },
    {
      "epoch": 2.381870781099325,
      "grad_norm": 0.002890003612264991,
      "learning_rate": 1.6824172291867568e-05,
      "loss": 0.0867,
      "step": 22230
    },
    {
      "epoch": 2.3829422479374265,
      "grad_norm": 0.011436393484473228,
      "learning_rate": 1.6822743669416767e-05,
      "loss": 0.1542,
      "step": 22240
    },
    {
      "epoch": 2.3840137147755276,
      "grad_norm": 0.08912207931280136,
      "learning_rate": 1.6821315046965963e-05,
      "loss": 0.1371,
      "step": 22250
    },
    {
      "epoch": 2.385085181613629,
      "grad_norm": 0.34935107827186584,
      "learning_rate": 1.6819886424515162e-05,
      "loss": 0.197,
      "step": 22260
    },
    {
      "epoch": 2.3861566484517303,
      "grad_norm": 0.0012384618166834116,
      "learning_rate": 1.6818457802064362e-05,
      "loss": 0.0005,
      "step": 22270
    },
    {
      "epoch": 2.387228115289832,
      "grad_norm": 16.506763458251953,
      "learning_rate": 1.681702917961356e-05,
      "loss": 0.3246,
      "step": 22280
    },
    {
      "epoch": 2.3882995821279334,
      "grad_norm": 0.0007766007911413908,
      "learning_rate": 1.6815600557162757e-05,
      "loss": 0.0021,
      "step": 22290
    },
    {
      "epoch": 2.3893710489660345,
      "grad_norm": 0.12631230056285858,
      "learning_rate": 1.6814171934711957e-05,
      "loss": 0.206,
      "step": 22300
    },
    {
      "epoch": 2.390442515804136,
      "grad_norm": 0.1423216462135315,
      "learning_rate": 1.6812743312261153e-05,
      "loss": 0.0019,
      "step": 22310
    },
    {
      "epoch": 2.391513982642237,
      "grad_norm": 0.05594954267144203,
      "learning_rate": 1.6811314689810352e-05,
      "loss": 0.0011,
      "step": 22320
    },
    {
      "epoch": 2.3925854494803387,
      "grad_norm": 0.007138771936297417,
      "learning_rate": 1.680988606735955e-05,
      "loss": 0.2216,
      "step": 22330
    },
    {
      "epoch": 2.39365691631844,
      "grad_norm": 1.0709513425827026,
      "learning_rate": 1.6808457444908747e-05,
      "loss": 0.3796,
      "step": 22340
    },
    {
      "epoch": 2.3947283831565414,
      "grad_norm": 0.055014025419950485,
      "learning_rate": 1.6807028822457947e-05,
      "loss": 0.0007,
      "step": 22350
    },
    {
      "epoch": 2.395799849994643,
      "grad_norm": 0.06864462047815323,
      "learning_rate": 1.6805600200007143e-05,
      "loss": 0.4039,
      "step": 22360
    },
    {
      "epoch": 2.396871316832744,
      "grad_norm": 0.07238579541444778,
      "learning_rate": 1.6804171577556342e-05,
      "loss": 0.2017,
      "step": 22370
    },
    {
      "epoch": 2.3979427836708456,
      "grad_norm": 0.007144229952245951,
      "learning_rate": 1.680274295510554e-05,
      "loss": 0.4515,
      "step": 22380
    },
    {
      "epoch": 2.3990142505089467,
      "grad_norm": 0.04410296678543091,
      "learning_rate": 1.680131433265474e-05,
      "loss": 0.1377,
      "step": 22390
    },
    {
      "epoch": 2.4000857173470482,
      "grad_norm": 0.39680978655815125,
      "learning_rate": 1.6799885710203937e-05,
      "loss": 0.0029,
      "step": 22400
    },
    {
      "epoch": 2.4011571841851493,
      "grad_norm": 0.5738807320594788,
      "learning_rate": 1.6798457087753136e-05,
      "loss": 0.3235,
      "step": 22410
    },
    {
      "epoch": 2.402228651023251,
      "grad_norm": 1.2196178436279297,
      "learning_rate": 1.6797028465302335e-05,
      "loss": 0.2742,
      "step": 22420
    },
    {
      "epoch": 2.403300117861352,
      "grad_norm": 0.023167455568909645,
      "learning_rate": 1.679559984285153e-05,
      "loss": 0.002,
      "step": 22430
    },
    {
      "epoch": 2.4043715846994536,
      "grad_norm": 0.0006213473388925195,
      "learning_rate": 1.679417122040073e-05,
      "loss": 0.0002,
      "step": 22440
    },
    {
      "epoch": 2.4054430515375547,
      "grad_norm": 0.10186634957790375,
      "learning_rate": 1.679274259794993e-05,
      "loss": 0.4523,
      "step": 22450
    },
    {
      "epoch": 2.406514518375656,
      "grad_norm": 0.005095997825264931,
      "learning_rate": 1.6791313975499126e-05,
      "loss": 0.0055,
      "step": 22460
    },
    {
      "epoch": 2.4075859852137578,
      "grad_norm": 0.10953088849782944,
      "learning_rate": 1.6789885353048325e-05,
      "loss": 0.1199,
      "step": 22470
    },
    {
      "epoch": 2.408657452051859,
      "grad_norm": 0.489989697933197,
      "learning_rate": 1.678845673059752e-05,
      "loss": 0.0018,
      "step": 22480
    },
    {
      "epoch": 2.4097289188899604,
      "grad_norm": 0.026464080438017845,
      "learning_rate": 1.678702810814672e-05,
      "loss": 0.3403,
      "step": 22490
    },
    {
      "epoch": 2.4108003857280615,
      "grad_norm": 3.6186447143554688,
      "learning_rate": 1.6785599485695917e-05,
      "loss": 0.1233,
      "step": 22500
    },
    {
      "epoch": 2.411871852566163,
      "grad_norm": 1.9992002248764038,
      "learning_rate": 1.6784170863245116e-05,
      "loss": 0.256,
      "step": 22510
    },
    {
      "epoch": 2.412943319404264,
      "grad_norm": 17.634538650512695,
      "learning_rate": 1.6782742240794315e-05,
      "loss": 0.3447,
      "step": 22520
    },
    {
      "epoch": 2.4140147862423658,
      "grad_norm": 0.010150682181119919,
      "learning_rate": 1.6781313618343515e-05,
      "loss": 0.494,
      "step": 22530
    },
    {
      "epoch": 2.4150862530804673,
      "grad_norm": 0.02729259803891182,
      "learning_rate": 1.677988499589271e-05,
      "loss": 0.0011,
      "step": 22540
    },
    {
      "epoch": 2.4161577199185684,
      "grad_norm": 17.23150062561035,
      "learning_rate": 1.677845637344191e-05,
      "loss": 0.5704,
      "step": 22550
    },
    {
      "epoch": 2.41722918675667,
      "grad_norm": 0.19813108444213867,
      "learning_rate": 1.677702775099111e-05,
      "loss": 0.1571,
      "step": 22560
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.060455042868852615,
      "learning_rate": 1.677559912854031e-05,
      "loss": 0.2451,
      "step": 22570
    },
    {
      "epoch": 2.4193721204328726,
      "grad_norm": 21.80644989013672,
      "learning_rate": 1.6774170506089505e-05,
      "loss": 0.7079,
      "step": 22580
    },
    {
      "epoch": 2.4204435872709738,
      "grad_norm": 67.12564849853516,
      "learning_rate": 1.6772741883638704e-05,
      "loss": 0.4262,
      "step": 22590
    },
    {
      "epoch": 2.4215150541090753,
      "grad_norm": 31.556055068969727,
      "learning_rate": 1.67713132611879e-05,
      "loss": 0.2206,
      "step": 22600
    },
    {
      "epoch": 2.422586520947177,
      "grad_norm": 0.020715489983558655,
      "learning_rate": 1.67698846387371e-05,
      "loss": 0.1895,
      "step": 22610
    },
    {
      "epoch": 2.423657987785278,
      "grad_norm": 2.075162887573242,
      "learning_rate": 1.6768456016286296e-05,
      "loss": 0.2915,
      "step": 22620
    },
    {
      "epoch": 2.4247294546233795,
      "grad_norm": 0.08148504793643951,
      "learning_rate": 1.6767027393835495e-05,
      "loss": 0.3923,
      "step": 22630
    },
    {
      "epoch": 2.4258009214614806,
      "grad_norm": 0.06591718643903732,
      "learning_rate": 1.6765598771384694e-05,
      "loss": 0.0058,
      "step": 22640
    },
    {
      "epoch": 2.426872388299582,
      "grad_norm": 27.839950561523438,
      "learning_rate": 1.676417014893389e-05,
      "loss": 0.2592,
      "step": 22650
    },
    {
      "epoch": 2.4279438551376833,
      "grad_norm": 0.09679093956947327,
      "learning_rate": 1.676274152648309e-05,
      "loss": 0.3548,
      "step": 22660
    },
    {
      "epoch": 2.429015321975785,
      "grad_norm": 0.012055709958076477,
      "learning_rate": 1.676131290403229e-05,
      "loss": 0.0052,
      "step": 22670
    },
    {
      "epoch": 2.4300867888138864,
      "grad_norm": 0.0508396215736866,
      "learning_rate": 1.6759884281581485e-05,
      "loss": 0.0007,
      "step": 22680
    },
    {
      "epoch": 2.4311582556519875,
      "grad_norm": 13.811806678771973,
      "learning_rate": 1.6758455659130684e-05,
      "loss": 0.2464,
      "step": 22690
    },
    {
      "epoch": 2.432229722490089,
      "grad_norm": 0.005832555703818798,
      "learning_rate": 1.6757027036679884e-05,
      "loss": 0.2234,
      "step": 22700
    },
    {
      "epoch": 2.43330118932819,
      "grad_norm": 0.05408117547631264,
      "learning_rate": 1.6755598414229083e-05,
      "loss": 0.256,
      "step": 22710
    },
    {
      "epoch": 2.4343726561662917,
      "grad_norm": 61.670536041259766,
      "learning_rate": 1.675416979177828e-05,
      "loss": 0.2105,
      "step": 22720
    },
    {
      "epoch": 2.435444123004393,
      "grad_norm": 0.0705798864364624,
      "learning_rate": 1.675274116932748e-05,
      "loss": 0.2865,
      "step": 22730
    },
    {
      "epoch": 2.4365155898424944,
      "grad_norm": 0.041110023856163025,
      "learning_rate": 1.6751312546876674e-05,
      "loss": 0.2295,
      "step": 22740
    },
    {
      "epoch": 2.437587056680596,
      "grad_norm": 0.01566263847053051,
      "learning_rate": 1.6749883924425874e-05,
      "loss": 0.1148,
      "step": 22750
    },
    {
      "epoch": 2.438658523518697,
      "grad_norm": 0.23467659950256348,
      "learning_rate": 1.6748455301975073e-05,
      "loss": 0.2082,
      "step": 22760
    },
    {
      "epoch": 2.4397299903567986,
      "grad_norm": 0.2344440072774887,
      "learning_rate": 1.674702667952427e-05,
      "loss": 0.0007,
      "step": 22770
    },
    {
      "epoch": 2.4408014571948997,
      "grad_norm": 0.037768710404634476,
      "learning_rate": 1.674559805707347e-05,
      "loss": 0.1839,
      "step": 22780
    },
    {
      "epoch": 2.4418729240330013,
      "grad_norm": 21.44133758544922,
      "learning_rate": 1.6744169434622665e-05,
      "loss": 0.411,
      "step": 22790
    },
    {
      "epoch": 2.4429443908711024,
      "grad_norm": 0.02130507118999958,
      "learning_rate": 1.6742740812171864e-05,
      "loss": 0.0874,
      "step": 22800
    },
    {
      "epoch": 2.444015857709204,
      "grad_norm": 0.010146589949727058,
      "learning_rate": 1.6741312189721063e-05,
      "loss": 0.2599,
      "step": 22810
    },
    {
      "epoch": 2.4450873245473055,
      "grad_norm": 0.3659836947917938,
      "learning_rate": 1.673988356727026e-05,
      "loss": 0.0032,
      "step": 22820
    },
    {
      "epoch": 2.4461587913854066,
      "grad_norm": 0.04498916119337082,
      "learning_rate": 1.673845494481946e-05,
      "loss": 0.4333,
      "step": 22830
    },
    {
      "epoch": 2.447230258223508,
      "grad_norm": 0.07789374887943268,
      "learning_rate": 1.6737026322368658e-05,
      "loss": 0.2319,
      "step": 22840
    },
    {
      "epoch": 2.4483017250616093,
      "grad_norm": 0.006760666146874428,
      "learning_rate": 1.6735597699917857e-05,
      "loss": 0.0019,
      "step": 22850
    },
    {
      "epoch": 2.449373191899711,
      "grad_norm": 0.04072108119726181,
      "learning_rate": 1.6734169077467053e-05,
      "loss": 0.0004,
      "step": 22860
    },
    {
      "epoch": 2.450444658737812,
      "grad_norm": 1.7147961854934692,
      "learning_rate": 1.6732740455016253e-05,
      "loss": 0.4268,
      "step": 22870
    },
    {
      "epoch": 2.4515161255759135,
      "grad_norm": 0.0044714054092764854,
      "learning_rate": 1.6731311832565452e-05,
      "loss": 0.0049,
      "step": 22880
    },
    {
      "epoch": 2.452587592414015,
      "grad_norm": 0.3359066843986511,
      "learning_rate": 1.6729883210114648e-05,
      "loss": 0.0008,
      "step": 22890
    },
    {
      "epoch": 2.453659059252116,
      "grad_norm": 0.01540636457502842,
      "learning_rate": 1.6728454587663847e-05,
      "loss": 0.1882,
      "step": 22900
    },
    {
      "epoch": 2.4547305260902177,
      "grad_norm": 0.012305733747780323,
      "learning_rate": 1.6727025965213043e-05,
      "loss": 0.0007,
      "step": 22910
    },
    {
      "epoch": 2.455801992928319,
      "grad_norm": 0.0033401919063180685,
      "learning_rate": 1.6725597342762243e-05,
      "loss": 0.3162,
      "step": 22920
    },
    {
      "epoch": 2.4568734597664204,
      "grad_norm": 0.002948096254840493,
      "learning_rate": 1.672416872031144e-05,
      "loss": 0.2372,
      "step": 22930
    },
    {
      "epoch": 2.4579449266045215,
      "grad_norm": 23.920501708984375,
      "learning_rate": 1.6722740097860638e-05,
      "loss": 0.5589,
      "step": 22940
    },
    {
      "epoch": 2.459016393442623,
      "grad_norm": 0.06151968613266945,
      "learning_rate": 1.6721311475409837e-05,
      "loss": 0.2747,
      "step": 22950
    },
    {
      "epoch": 2.460087860280724,
      "grad_norm": 0.12871937453746796,
      "learning_rate": 1.6719882852959037e-05,
      "loss": 0.2149,
      "step": 22960
    },
    {
      "epoch": 2.4611593271188257,
      "grad_norm": 45.10942459106445,
      "learning_rate": 1.6718454230508233e-05,
      "loss": 0.3788,
      "step": 22970
    },
    {
      "epoch": 2.462230793956927,
      "grad_norm": 0.7946474552154541,
      "learning_rate": 1.6717025608057432e-05,
      "loss": 0.1278,
      "step": 22980
    },
    {
      "epoch": 2.4633022607950283,
      "grad_norm": 0.08272648602724075,
      "learning_rate": 1.671559698560663e-05,
      "loss": 0.1228,
      "step": 22990
    },
    {
      "epoch": 2.46437372763313,
      "grad_norm": 0.029026510193943977,
      "learning_rate": 1.671416836315583e-05,
      "loss": 0.0004,
      "step": 23000
    },
    {
      "epoch": 2.465445194471231,
      "grad_norm": 0.004347135312855244,
      "learning_rate": 1.6712739740705027e-05,
      "loss": 0.4483,
      "step": 23010
    },
    {
      "epoch": 2.4665166613093326,
      "grad_norm": 0.0342002809047699,
      "learning_rate": 1.6711311118254226e-05,
      "loss": 0.1315,
      "step": 23020
    },
    {
      "epoch": 2.4675881281474337,
      "grad_norm": 0.04180122911930084,
      "learning_rate": 1.6709882495803422e-05,
      "loss": 0.3551,
      "step": 23030
    },
    {
      "epoch": 2.468659594985535,
      "grad_norm": 33.50568389892578,
      "learning_rate": 1.670845387335262e-05,
      "loss": 0.2835,
      "step": 23040
    },
    {
      "epoch": 2.4697310618236363,
      "grad_norm": 0.6837252378463745,
      "learning_rate": 1.6707025250901818e-05,
      "loss": 0.4,
      "step": 23050
    },
    {
      "epoch": 2.470802528661738,
      "grad_norm": 0.03295987844467163,
      "learning_rate": 1.6705596628451017e-05,
      "loss": 0.183,
      "step": 23060
    },
    {
      "epoch": 2.4718739954998394,
      "grad_norm": 0.031208178028464317,
      "learning_rate": 1.6704168006000216e-05,
      "loss": 0.2108,
      "step": 23070
    },
    {
      "epoch": 2.4729454623379405,
      "grad_norm": 0.07527186721563339,
      "learning_rate": 1.6702739383549412e-05,
      "loss": 0.3245,
      "step": 23080
    },
    {
      "epoch": 2.474016929176042,
      "grad_norm": 0.07677194476127625,
      "learning_rate": 1.670131076109861e-05,
      "loss": 0.0023,
      "step": 23090
    },
    {
      "epoch": 2.475088396014143,
      "grad_norm": 0.007310475688427687,
      "learning_rate": 1.669988213864781e-05,
      "loss": 0.0517,
      "step": 23100
    },
    {
      "epoch": 2.4761598628522448,
      "grad_norm": 0.0819552019238472,
      "learning_rate": 1.6698453516197007e-05,
      "loss": 0.33,
      "step": 23110
    },
    {
      "epoch": 2.477231329690346,
      "grad_norm": 1.0070180892944336,
      "learning_rate": 1.6697024893746206e-05,
      "loss": 0.4686,
      "step": 23120
    },
    {
      "epoch": 2.4783027965284474,
      "grad_norm": 0.07113873213529587,
      "learning_rate": 1.6695596271295406e-05,
      "loss": 0.2959,
      "step": 23130
    },
    {
      "epoch": 2.479374263366549,
      "grad_norm": 0.08059756457805634,
      "learning_rate": 1.6694167648844605e-05,
      "loss": 0.4593,
      "step": 23140
    },
    {
      "epoch": 2.48044573020465,
      "grad_norm": 0.723467230796814,
      "learning_rate": 1.66927390263938e-05,
      "loss": 0.0095,
      "step": 23150
    },
    {
      "epoch": 2.4815171970427516,
      "grad_norm": 16.43412208557129,
      "learning_rate": 1.6691310403943e-05,
      "loss": 0.716,
      "step": 23160
    },
    {
      "epoch": 2.4825886638808528,
      "grad_norm": 43.94430160522461,
      "learning_rate": 1.6689881781492196e-05,
      "loss": 0.4959,
      "step": 23170
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.01639561541378498,
      "learning_rate": 1.6688453159041396e-05,
      "loss": 0.0018,
      "step": 23180
    },
    {
      "epoch": 2.4847315975570554,
      "grad_norm": 0.17022645473480225,
      "learning_rate": 1.6687024536590595e-05,
      "loss": 0.2554,
      "step": 23190
    },
    {
      "epoch": 2.485803064395157,
      "grad_norm": 0.03447648882865906,
      "learning_rate": 1.668559591413979e-05,
      "loss": 0.3253,
      "step": 23200
    },
    {
      "epoch": 2.4868745312332585,
      "grad_norm": 0.0035202752333134413,
      "learning_rate": 1.668416729168899e-05,
      "loss": 0.0088,
      "step": 23210
    },
    {
      "epoch": 2.4879459980713596,
      "grad_norm": 0.06419167667627335,
      "learning_rate": 1.6682738669238186e-05,
      "loss": 0.274,
      "step": 23220
    },
    {
      "epoch": 2.489017464909461,
      "grad_norm": 0.06881339102983475,
      "learning_rate": 1.6681310046787386e-05,
      "loss": 0.0041,
      "step": 23230
    },
    {
      "epoch": 2.4900889317475623,
      "grad_norm": 0.07662173360586166,
      "learning_rate": 1.6679881424336585e-05,
      "loss": 0.5484,
      "step": 23240
    },
    {
      "epoch": 2.491160398585664,
      "grad_norm": 0.022493407130241394,
      "learning_rate": 1.667845280188578e-05,
      "loss": 0.2164,
      "step": 23250
    },
    {
      "epoch": 2.492231865423765,
      "grad_norm": 0.5279159545898438,
      "learning_rate": 1.667702417943498e-05,
      "loss": 0.2729,
      "step": 23260
    },
    {
      "epoch": 2.4933033322618665,
      "grad_norm": 0.01686234027147293,
      "learning_rate": 1.667559555698418e-05,
      "loss": 0.2379,
      "step": 23270
    },
    {
      "epoch": 2.494374799099968,
      "grad_norm": 0.02588154561817646,
      "learning_rate": 1.667416693453338e-05,
      "loss": 0.0018,
      "step": 23280
    },
    {
      "epoch": 2.495446265938069,
      "grad_norm": 50.789527893066406,
      "learning_rate": 1.6672738312082575e-05,
      "loss": 0.6018,
      "step": 23290
    },
    {
      "epoch": 2.4965177327761707,
      "grad_norm": 0.21515776216983795,
      "learning_rate": 1.6671309689631775e-05,
      "loss": 0.2893,
      "step": 23300
    },
    {
      "epoch": 2.497589199614272,
      "grad_norm": 0.06095287948846817,
      "learning_rate": 1.6669881067180974e-05,
      "loss": 0.1076,
      "step": 23310
    },
    {
      "epoch": 2.4986606664523734,
      "grad_norm": 0.0398886539041996,
      "learning_rate": 1.666845244473017e-05,
      "loss": 0.1393,
      "step": 23320
    },
    {
      "epoch": 2.4997321332904745,
      "grad_norm": 28.589921951293945,
      "learning_rate": 1.666702382227937e-05,
      "loss": 0.5479,
      "step": 23330
    },
    {
      "epoch": 2.500803600128576,
      "grad_norm": 0.10425245016813278,
      "learning_rate": 1.6665595199828565e-05,
      "loss": 0.2924,
      "step": 23340
    },
    {
      "epoch": 2.5018750669666776,
      "grad_norm": 0.06406226009130478,
      "learning_rate": 1.6664166577377765e-05,
      "loss": 0.1915,
      "step": 23350
    },
    {
      "epoch": 2.5029465338047787,
      "grad_norm": 0.018337683752179146,
      "learning_rate": 1.6662737954926964e-05,
      "loss": 0.0968,
      "step": 23360
    },
    {
      "epoch": 2.50401800064288,
      "grad_norm": 0.15397264063358307,
      "learning_rate": 1.666130933247616e-05,
      "loss": 0.2611,
      "step": 23370
    },
    {
      "epoch": 2.5050894674809814,
      "grad_norm": 1.1617075204849243,
      "learning_rate": 1.665988071002536e-05,
      "loss": 0.1957,
      "step": 23380
    },
    {
      "epoch": 2.506160934319083,
      "grad_norm": 2.179168939590454,
      "learning_rate": 1.6658452087574555e-05,
      "loss": 0.6637,
      "step": 23390
    },
    {
      "epoch": 2.507232401157184,
      "grad_norm": 0.006342038977891207,
      "learning_rate": 1.6657023465123755e-05,
      "loss": 0.3293,
      "step": 23400
    },
    {
      "epoch": 2.5083038679952856,
      "grad_norm": 0.08212064206600189,
      "learning_rate": 1.6655594842672954e-05,
      "loss": 0.2724,
      "step": 23410
    },
    {
      "epoch": 2.509375334833387,
      "grad_norm": 43.76890563964844,
      "learning_rate": 1.6654166220222153e-05,
      "loss": 0.31,
      "step": 23420
    },
    {
      "epoch": 2.5104468016714883,
      "grad_norm": 0.04186251014471054,
      "learning_rate": 1.6652737597771353e-05,
      "loss": 0.1799,
      "step": 23430
    },
    {
      "epoch": 2.5115182685095894,
      "grad_norm": 0.0032356749288737774,
      "learning_rate": 1.665130897532055e-05,
      "loss": 0.0005,
      "step": 23440
    },
    {
      "epoch": 2.512589735347691,
      "grad_norm": 0.019558308646082878,
      "learning_rate": 1.6649880352869748e-05,
      "loss": 0.0942,
      "step": 23450
    },
    {
      "epoch": 2.5136612021857925,
      "grad_norm": 0.007484730798751116,
      "learning_rate": 1.6648451730418944e-05,
      "loss": 0.2037,
      "step": 23460
    },
    {
      "epoch": 2.5147326690238936,
      "grad_norm": 0.0021321589592844248,
      "learning_rate": 1.6647023107968144e-05,
      "loss": 0.2179,
      "step": 23470
    },
    {
      "epoch": 2.515804135861995,
      "grad_norm": 0.0031040101312100887,
      "learning_rate": 1.6645594485517343e-05,
      "loss": 0.8521,
      "step": 23480
    },
    {
      "epoch": 2.5168756027000967,
      "grad_norm": 0.04549376666545868,
      "learning_rate": 1.664416586306654e-05,
      "loss": 0.179,
      "step": 23490
    },
    {
      "epoch": 2.517947069538198,
      "grad_norm": 17.92049217224121,
      "learning_rate": 1.6642737240615738e-05,
      "loss": 0.5523,
      "step": 23500
    },
    {
      "epoch": 2.519018536376299,
      "grad_norm": 0.23146246373653412,
      "learning_rate": 1.6641308618164934e-05,
      "loss": 0.1024,
      "step": 23510
    },
    {
      "epoch": 2.5200900032144005,
      "grad_norm": 0.3103296160697937,
      "learning_rate": 1.6639879995714134e-05,
      "loss": 0.0504,
      "step": 23520
    },
    {
      "epoch": 2.521161470052502,
      "grad_norm": 71.80062866210938,
      "learning_rate": 1.6638451373263333e-05,
      "loss": 0.1283,
      "step": 23530
    },
    {
      "epoch": 2.522232936890603,
      "grad_norm": 0.0058075375854969025,
      "learning_rate": 1.663702275081253e-05,
      "loss": 0.2932,
      "step": 23540
    },
    {
      "epoch": 2.5233044037287047,
      "grad_norm": 0.05522361770272255,
      "learning_rate": 1.6635594128361728e-05,
      "loss": 0.0038,
      "step": 23550
    },
    {
      "epoch": 2.5243758705668062,
      "grad_norm": 0.0022704382427036762,
      "learning_rate": 1.6634165505910928e-05,
      "loss": 0.3803,
      "step": 23560
    },
    {
      "epoch": 2.5254473374049073,
      "grad_norm": 0.23298606276512146,
      "learning_rate": 1.6632736883460127e-05,
      "loss": 0.0006,
      "step": 23570
    },
    {
      "epoch": 2.5265188042430085,
      "grad_norm": 0.002336301375180483,
      "learning_rate": 1.6631308261009323e-05,
      "loss": 0.2203,
      "step": 23580
    },
    {
      "epoch": 2.52759027108111,
      "grad_norm": 26.18475341796875,
      "learning_rate": 1.6629879638558522e-05,
      "loss": 0.7053,
      "step": 23590
    },
    {
      "epoch": 2.5286617379192116,
      "grad_norm": 0.022325970232486725,
      "learning_rate": 1.662845101610772e-05,
      "loss": 0.0733,
      "step": 23600
    },
    {
      "epoch": 2.5297332047573127,
      "grad_norm": 0.009303807280957699,
      "learning_rate": 1.6627022393656918e-05,
      "loss": 0.2648,
      "step": 23610
    },
    {
      "epoch": 2.5308046715954142,
      "grad_norm": 0.11993353813886642,
      "learning_rate": 1.6625593771206117e-05,
      "loss": 0.5853,
      "step": 23620
    },
    {
      "epoch": 2.5318761384335153,
      "grad_norm": 0.13507336378097534,
      "learning_rate": 1.6624165148755313e-05,
      "loss": 0.0032,
      "step": 23630
    },
    {
      "epoch": 2.532947605271617,
      "grad_norm": 0.026269234716892242,
      "learning_rate": 1.6622736526304512e-05,
      "loss": 0.0075,
      "step": 23640
    },
    {
      "epoch": 2.534019072109718,
      "grad_norm": 0.015194111503660679,
      "learning_rate": 1.662130790385371e-05,
      "loss": 0.1943,
      "step": 23650
    },
    {
      "epoch": 2.5350905389478195,
      "grad_norm": 0.03654755279421806,
      "learning_rate": 1.6619879281402908e-05,
      "loss": 0.4109,
      "step": 23660
    },
    {
      "epoch": 2.536162005785921,
      "grad_norm": 0.002892768941819668,
      "learning_rate": 1.6618450658952107e-05,
      "loss": 0.4323,
      "step": 23670
    },
    {
      "epoch": 2.537233472624022,
      "grad_norm": 17.37947654724121,
      "learning_rate": 1.6617022036501303e-05,
      "loss": 0.6352,
      "step": 23680
    },
    {
      "epoch": 2.5383049394621238,
      "grad_norm": 0.17772072553634644,
      "learning_rate": 1.6615593414050502e-05,
      "loss": 0.0069,
      "step": 23690
    },
    {
      "epoch": 2.539376406300225,
      "grad_norm": 0.004380501806735992,
      "learning_rate": 1.6614164791599702e-05,
      "loss": 0.2298,
      "step": 23700
    },
    {
      "epoch": 2.5404478731383264,
      "grad_norm": 0.05094301328063011,
      "learning_rate": 1.66127361691489e-05,
      "loss": 0.2285,
      "step": 23710
    },
    {
      "epoch": 2.5415193399764275,
      "grad_norm": 1.5592581033706665,
      "learning_rate": 1.6611307546698097e-05,
      "loss": 0.0023,
      "step": 23720
    },
    {
      "epoch": 2.542590806814529,
      "grad_norm": 0.21685823798179626,
      "learning_rate": 1.6609878924247297e-05,
      "loss": 0.197,
      "step": 23730
    },
    {
      "epoch": 2.5436622736526306,
      "grad_norm": 0.019427813589572906,
      "learning_rate": 1.6608450301796496e-05,
      "loss": 0.16,
      "step": 23740
    },
    {
      "epoch": 2.5447337404907318,
      "grad_norm": 0.0036589549854397774,
      "learning_rate": 1.6607021679345692e-05,
      "loss": 0.2022,
      "step": 23750
    },
    {
      "epoch": 2.5458052073288333,
      "grad_norm": 0.006419668439775705,
      "learning_rate": 1.660559305689489e-05,
      "loss": 0.0031,
      "step": 23760
    },
    {
      "epoch": 2.5468766741669344,
      "grad_norm": 0.00793012697249651,
      "learning_rate": 1.6604164434444087e-05,
      "loss": 0.2046,
      "step": 23770
    },
    {
      "epoch": 2.547948141005036,
      "grad_norm": 0.022420937195420265,
      "learning_rate": 1.6602735811993287e-05,
      "loss": 0.2375,
      "step": 23780
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.20081424713134766,
      "learning_rate": 1.6601307189542486e-05,
      "loss": 0.2897,
      "step": 23790
    },
    {
      "epoch": 2.5500910746812386,
      "grad_norm": 0.05241907387971878,
      "learning_rate": 1.6599878567091682e-05,
      "loss": 0.0044,
      "step": 23800
    },
    {
      "epoch": 2.55116254151934,
      "grad_norm": 0.020866628736257553,
      "learning_rate": 1.659844994464088e-05,
      "loss": 0.2449,
      "step": 23810
    },
    {
      "epoch": 2.5522340083574413,
      "grad_norm": 0.0002807020500767976,
      "learning_rate": 1.6597021322190077e-05,
      "loss": 0.3993,
      "step": 23820
    },
    {
      "epoch": 2.553305475195543,
      "grad_norm": 14.858541488647461,
      "learning_rate": 1.6595592699739277e-05,
      "loss": 0.76,
      "step": 23830
    },
    {
      "epoch": 2.554376942033644,
      "grad_norm": 0.0065175010822713375,
      "learning_rate": 1.6594164077288476e-05,
      "loss": 0.173,
      "step": 23840
    },
    {
      "epoch": 2.5554484088717455,
      "grad_norm": 0.3810809552669525,
      "learning_rate": 1.6592735454837675e-05,
      "loss": 0.2327,
      "step": 23850
    },
    {
      "epoch": 2.5565198757098466,
      "grad_norm": 0.00381711614318192,
      "learning_rate": 1.6591306832386875e-05,
      "loss": 0.16,
      "step": 23860
    },
    {
      "epoch": 2.557591342547948,
      "grad_norm": 0.0014860392548143864,
      "learning_rate": 1.658987820993607e-05,
      "loss": 0.1922,
      "step": 23870
    },
    {
      "epoch": 2.5586628093860497,
      "grad_norm": 0.03226340189576149,
      "learning_rate": 1.658844958748527e-05,
      "loss": 0.0017,
      "step": 23880
    },
    {
      "epoch": 2.559734276224151,
      "grad_norm": 0.0005410491139627993,
      "learning_rate": 1.6587020965034466e-05,
      "loss": 0.204,
      "step": 23890
    },
    {
      "epoch": 2.560805743062252,
      "grad_norm": 0.0017868870636448264,
      "learning_rate": 1.6585592342583665e-05,
      "loss": 0.0012,
      "step": 23900
    },
    {
      "epoch": 2.5618772099003535,
      "grad_norm": 107.98580932617188,
      "learning_rate": 1.6584163720132865e-05,
      "loss": 0.1789,
      "step": 23910
    },
    {
      "epoch": 2.562948676738455,
      "grad_norm": 0.05076213926076889,
      "learning_rate": 1.658273509768206e-05,
      "loss": 0.0005,
      "step": 23920
    },
    {
      "epoch": 2.564020143576556,
      "grad_norm": 0.0015809980686753988,
      "learning_rate": 1.658130647523126e-05,
      "loss": 0.3352,
      "step": 23930
    },
    {
      "epoch": 2.5650916104146577,
      "grad_norm": 0.0016105740796774626,
      "learning_rate": 1.6579877852780456e-05,
      "loss": 0.0098,
      "step": 23940
    },
    {
      "epoch": 2.5661630772527593,
      "grad_norm": 0.001254046568647027,
      "learning_rate": 1.6578449230329656e-05,
      "loss": 0.3136,
      "step": 23950
    },
    {
      "epoch": 2.5672345440908604,
      "grad_norm": 4.553396701812744,
      "learning_rate": 1.657702060787885e-05,
      "loss": 0.1617,
      "step": 23960
    },
    {
      "epoch": 2.5683060109289615,
      "grad_norm": 0.0008848236175253987,
      "learning_rate": 1.657559198542805e-05,
      "loss": 0.2295,
      "step": 23970
    },
    {
      "epoch": 2.569377477767063,
      "grad_norm": 0.00046664217370562255,
      "learning_rate": 1.657416336297725e-05,
      "loss": 0.0095,
      "step": 23980
    },
    {
      "epoch": 2.5704489446051646,
      "grad_norm": 0.000465830962639302,
      "learning_rate": 1.657273474052645e-05,
      "loss": 0.2104,
      "step": 23990
    },
    {
      "epoch": 2.5715204114432657,
      "grad_norm": 0.6174713373184204,
      "learning_rate": 1.657130611807565e-05,
      "loss": 0.3523,
      "step": 24000
    },
    {
      "epoch": 2.5725918782813673,
      "grad_norm": 0.1231537014245987,
      "learning_rate": 1.6569877495624845e-05,
      "loss": 0.3194,
      "step": 24010
    },
    {
      "epoch": 2.573663345119469,
      "grad_norm": 0.0005492502241395414,
      "learning_rate": 1.6568448873174044e-05,
      "loss": 0.2749,
      "step": 24020
    },
    {
      "epoch": 2.57473481195757,
      "grad_norm": 0.0002814691106323153,
      "learning_rate": 1.6567020250723244e-05,
      "loss": 0.2684,
      "step": 24030
    },
    {
      "epoch": 2.575806278795671,
      "grad_norm": 0.14049331843852997,
      "learning_rate": 1.656559162827244e-05,
      "loss": 0.0009,
      "step": 24040
    },
    {
      "epoch": 2.5768777456337726,
      "grad_norm": 0.00027028704062104225,
      "learning_rate": 1.656416300582164e-05,
      "loss": 0.1364,
      "step": 24050
    },
    {
      "epoch": 2.577949212471874,
      "grad_norm": 0.00038237852277234197,
      "learning_rate": 1.6562734383370835e-05,
      "loss": 0.8833,
      "step": 24060
    },
    {
      "epoch": 2.5790206793099753,
      "grad_norm": 0.12928910553455353,
      "learning_rate": 1.6561305760920034e-05,
      "loss": 0.2224,
      "step": 24070
    },
    {
      "epoch": 2.580092146148077,
      "grad_norm": 0.002508545061573386,
      "learning_rate": 1.655987713846923e-05,
      "loss": 0.041,
      "step": 24080
    },
    {
      "epoch": 2.581163612986178,
      "grad_norm": 0.25194692611694336,
      "learning_rate": 1.655844851601843e-05,
      "loss": 0.0622,
      "step": 24090
    },
    {
      "epoch": 2.5822350798242795,
      "grad_norm": 0.006957901641726494,
      "learning_rate": 1.655701989356763e-05,
      "loss": 0.0072,
      "step": 24100
    },
    {
      "epoch": 2.5833065466623806,
      "grad_norm": 0.0014105610316619277,
      "learning_rate": 1.6555591271116825e-05,
      "loss": 0.1221,
      "step": 24110
    },
    {
      "epoch": 2.584378013500482,
      "grad_norm": 1.0134292840957642,
      "learning_rate": 1.6554162648666024e-05,
      "loss": 0.0042,
      "step": 24120
    },
    {
      "epoch": 2.5854494803385837,
      "grad_norm": 0.012858674861490726,
      "learning_rate": 1.6552734026215224e-05,
      "loss": 0.1391,
      "step": 24130
    },
    {
      "epoch": 2.586520947176685,
      "grad_norm": 0.007797292899340391,
      "learning_rate": 1.6551305403764423e-05,
      "loss": 0.2483,
      "step": 24140
    },
    {
      "epoch": 2.5875924140147863,
      "grad_norm": 0.0026011401787400246,
      "learning_rate": 1.654987678131362e-05,
      "loss": 0.3887,
      "step": 24150
    },
    {
      "epoch": 2.5886638808528875,
      "grad_norm": 0.040688250213861465,
      "learning_rate": 1.654844815886282e-05,
      "loss": 0.5975,
      "step": 24160
    },
    {
      "epoch": 2.589735347690989,
      "grad_norm": 0.06199541315436363,
      "learning_rate": 1.6547019536412018e-05,
      "loss": 0.3395,
      "step": 24170
    },
    {
      "epoch": 2.59080681452909,
      "grad_norm": 0.08830887824296951,
      "learning_rate": 1.6545590913961214e-05,
      "loss": 0.2438,
      "step": 24180
    },
    {
      "epoch": 2.5918782813671917,
      "grad_norm": 0.08720055967569351,
      "learning_rate": 1.6544162291510413e-05,
      "loss": 0.2164,
      "step": 24190
    },
    {
      "epoch": 2.5929497482052932,
      "grad_norm": 0.02003728598356247,
      "learning_rate": 1.654273366905961e-05,
      "loss": 0.5138,
      "step": 24200
    },
    {
      "epoch": 2.5940212150433943,
      "grad_norm": 0.06324887275695801,
      "learning_rate": 1.654130504660881e-05,
      "loss": 0.2921,
      "step": 24210
    },
    {
      "epoch": 2.595092681881496,
      "grad_norm": 0.33121782541275024,
      "learning_rate": 1.6539876424158008e-05,
      "loss": 0.0026,
      "step": 24220
    },
    {
      "epoch": 2.596164148719597,
      "grad_norm": 0.035708725452423096,
      "learning_rate": 1.6538447801707204e-05,
      "loss": 0.3346,
      "step": 24230
    },
    {
      "epoch": 2.5972356155576986,
      "grad_norm": 0.02244090475142002,
      "learning_rate": 1.6537019179256403e-05,
      "loss": 0.001,
      "step": 24240
    },
    {
      "epoch": 2.5983070823957997,
      "grad_norm": 0.08079471439123154,
      "learning_rate": 1.65355905568056e-05,
      "loss": 0.0008,
      "step": 24250
    },
    {
      "epoch": 2.599378549233901,
      "grad_norm": 0.036431990563869476,
      "learning_rate": 1.65341619343548e-05,
      "loss": 0.2258,
      "step": 24260
    },
    {
      "epoch": 2.6004500160720028,
      "grad_norm": 0.03812121972441673,
      "learning_rate": 1.6532733311903998e-05,
      "loss": 0.2444,
      "step": 24270
    },
    {
      "epoch": 2.601521482910104,
      "grad_norm": 0.04972677677869797,
      "learning_rate": 1.6531304689453197e-05,
      "loss": 0.0009,
      "step": 24280
    },
    {
      "epoch": 2.6025929497482054,
      "grad_norm": 0.0913633182644844,
      "learning_rate": 1.6529876067002393e-05,
      "loss": 0.406,
      "step": 24290
    },
    {
      "epoch": 2.6036644165863065,
      "grad_norm": 0.02442791499197483,
      "learning_rate": 1.6528447444551593e-05,
      "loss": 0.0009,
      "step": 24300
    },
    {
      "epoch": 2.604735883424408,
      "grad_norm": 0.06894981861114502,
      "learning_rate": 1.6527018822100792e-05,
      "loss": 0.2228,
      "step": 24310
    },
    {
      "epoch": 2.605807350262509,
      "grad_norm": 14.75943660736084,
      "learning_rate": 1.6525590199649988e-05,
      "loss": 0.4378,
      "step": 24320
    },
    {
      "epoch": 2.6068788171006108,
      "grad_norm": 0.009036397561430931,
      "learning_rate": 1.6524161577199187e-05,
      "loss": 0.0962,
      "step": 24330
    },
    {
      "epoch": 2.6079502839387123,
      "grad_norm": 0.00376897887326777,
      "learning_rate": 1.6522732954748387e-05,
      "loss": 0.1687,
      "step": 24340
    },
    {
      "epoch": 2.6090217507768134,
      "grad_norm": 0.012391054071485996,
      "learning_rate": 1.6521304332297583e-05,
      "loss": 0.3265,
      "step": 24350
    },
    {
      "epoch": 2.610093217614915,
      "grad_norm": 0.00723295146599412,
      "learning_rate": 1.6519875709846782e-05,
      "loss": 0.4247,
      "step": 24360
    },
    {
      "epoch": 2.611164684453016,
      "grad_norm": 16.248964309692383,
      "learning_rate": 1.6518447087395978e-05,
      "loss": 0.3919,
      "step": 24370
    },
    {
      "epoch": 2.6122361512911176,
      "grad_norm": 0.7089027762413025,
      "learning_rate": 1.6517018464945177e-05,
      "loss": 0.2502,
      "step": 24380
    },
    {
      "epoch": 2.6133076181292187,
      "grad_norm": 29.47165870666504,
      "learning_rate": 1.6515589842494377e-05,
      "loss": 0.2549,
      "step": 24390
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.09889070689678192,
      "learning_rate": 1.6514161220043573e-05,
      "loss": 0.0017,
      "step": 24400
    },
    {
      "epoch": 2.615450551805422,
      "grad_norm": 0.033085897564888,
      "learning_rate": 1.6512732597592772e-05,
      "loss": 0.2981,
      "step": 24410
    },
    {
      "epoch": 2.616522018643523,
      "grad_norm": 0.5405359268188477,
      "learning_rate": 1.651130397514197e-05,
      "loss": 0.3492,
      "step": 24420
    },
    {
      "epoch": 2.617593485481624,
      "grad_norm": 0.02384323626756668,
      "learning_rate": 1.650987535269117e-05,
      "loss": 0.1641,
      "step": 24430
    },
    {
      "epoch": 2.6186649523197256,
      "grad_norm": 0.33442312479019165,
      "learning_rate": 1.6508446730240367e-05,
      "loss": 0.1523,
      "step": 24440
    },
    {
      "epoch": 2.619736419157827,
      "grad_norm": 0.046348609030246735,
      "learning_rate": 1.6507018107789566e-05,
      "loss": 0.3425,
      "step": 24450
    },
    {
      "epoch": 2.6208078859959283,
      "grad_norm": 63.43920135498047,
      "learning_rate": 1.6505589485338766e-05,
      "loss": 0.3724,
      "step": 24460
    },
    {
      "epoch": 2.62187935283403,
      "grad_norm": 0.04228384792804718,
      "learning_rate": 1.650416086288796e-05,
      "loss": 0.0044,
      "step": 24470
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 22.34984016418457,
      "learning_rate": 1.650273224043716e-05,
      "loss": 0.2058,
      "step": 24480
    },
    {
      "epoch": 2.6240222865102325,
      "grad_norm": 0.07126466929912567,
      "learning_rate": 1.6501303617986357e-05,
      "loss": 0.3374,
      "step": 24490
    },
    {
      "epoch": 2.6250937533483336,
      "grad_norm": 0.017493847757577896,
      "learning_rate": 1.6499874995535556e-05,
      "loss": 0.4936,
      "step": 24500
    },
    {
      "epoch": 2.626165220186435,
      "grad_norm": 0.06922367960214615,
      "learning_rate": 1.6498446373084752e-05,
      "loss": 0.3727,
      "step": 24510
    },
    {
      "epoch": 2.6272366870245367,
      "grad_norm": 27.466049194335938,
      "learning_rate": 1.649701775063395e-05,
      "loss": 0.3446,
      "step": 24520
    },
    {
      "epoch": 2.628308153862638,
      "grad_norm": 20.2371768951416,
      "learning_rate": 1.649558912818315e-05,
      "loss": 0.1024,
      "step": 24530
    },
    {
      "epoch": 2.6293796207007394,
      "grad_norm": 0.36406707763671875,
      "learning_rate": 1.6494160505732347e-05,
      "loss": 0.323,
      "step": 24540
    },
    {
      "epoch": 2.630451087538841,
      "grad_norm": 0.03335704654455185,
      "learning_rate": 1.6492731883281546e-05,
      "loss": 0.395,
      "step": 24550
    },
    {
      "epoch": 2.631522554376942,
      "grad_norm": 0.04653334617614746,
      "learning_rate": 1.6491303260830746e-05,
      "loss": 0.2378,
      "step": 24560
    },
    {
      "epoch": 2.632594021215043,
      "grad_norm": 0.0028713042847812176,
      "learning_rate": 1.6489874638379945e-05,
      "loss": 0.165,
      "step": 24570
    },
    {
      "epoch": 2.6336654880531447,
      "grad_norm": 0.04111543297767639,
      "learning_rate": 1.648844601592914e-05,
      "loss": 0.0015,
      "step": 24580
    },
    {
      "epoch": 2.6347369548912463,
      "grad_norm": 0.2885929346084595,
      "learning_rate": 1.648701739347834e-05,
      "loss": 0.14,
      "step": 24590
    },
    {
      "epoch": 2.6358084217293474,
      "grad_norm": 0.001166574889793992,
      "learning_rate": 1.648558877102754e-05,
      "loss": 0.1671,
      "step": 24600
    },
    {
      "epoch": 2.636879888567449,
      "grad_norm": 0.02868850901722908,
      "learning_rate": 1.6484160148576736e-05,
      "loss": 0.0005,
      "step": 24610
    },
    {
      "epoch": 2.63795135540555,
      "grad_norm": 0.47721725702285767,
      "learning_rate": 1.6482731526125935e-05,
      "loss": 0.0025,
      "step": 24620
    },
    {
      "epoch": 2.6390228222436516,
      "grad_norm": 28.336219787597656,
      "learning_rate": 1.648130290367513e-05,
      "loss": 0.1351,
      "step": 24630
    },
    {
      "epoch": 2.6400942890817527,
      "grad_norm": 0.019734956324100494,
      "learning_rate": 1.647987428122433e-05,
      "loss": 0.3495,
      "step": 24640
    },
    {
      "epoch": 2.6411657559198543,
      "grad_norm": 15.673277854919434,
      "learning_rate": 1.647844565877353e-05,
      "loss": 0.6758,
      "step": 24650
    },
    {
      "epoch": 2.642237222757956,
      "grad_norm": 0.002503111492842436,
      "learning_rate": 1.6477017036322726e-05,
      "loss": 0.1868,
      "step": 24660
    },
    {
      "epoch": 2.643308689596057,
      "grad_norm": 0.0026571578346192837,
      "learning_rate": 1.6475588413871925e-05,
      "loss": 0.1468,
      "step": 24670
    },
    {
      "epoch": 2.6443801564341585,
      "grad_norm": 0.06197467818856239,
      "learning_rate": 1.647415979142112e-05,
      "loss": 0.3104,
      "step": 24680
    },
    {
      "epoch": 2.6454516232722596,
      "grad_norm": 0.048089876770973206,
      "learning_rate": 1.647273116897032e-05,
      "loss": 0.3569,
      "step": 24690
    },
    {
      "epoch": 2.646523090110361,
      "grad_norm": 0.005573887377977371,
      "learning_rate": 1.647130254651952e-05,
      "loss": 0.0021,
      "step": 24700
    },
    {
      "epoch": 2.6475945569484622,
      "grad_norm": 0.002471395069733262,
      "learning_rate": 1.646987392406872e-05,
      "loss": 0.17,
      "step": 24710
    },
    {
      "epoch": 2.648666023786564,
      "grad_norm": 0.003309170948341489,
      "learning_rate": 1.6468445301617915e-05,
      "loss": 0.1789,
      "step": 24720
    },
    {
      "epoch": 2.6497374906246653,
      "grad_norm": 0.1660616397857666,
      "learning_rate": 1.6467016679167115e-05,
      "loss": 0.383,
      "step": 24730
    },
    {
      "epoch": 2.6508089574627665,
      "grad_norm": 0.11205650120973587,
      "learning_rate": 1.6465588056716314e-05,
      "loss": 0.1489,
      "step": 24740
    },
    {
      "epoch": 2.651880424300868,
      "grad_norm": 0.025272883474826813,
      "learning_rate": 1.646415943426551e-05,
      "loss": 0.0711,
      "step": 24750
    },
    {
      "epoch": 2.652951891138969,
      "grad_norm": 0.012636218219995499,
      "learning_rate": 1.646273081181471e-05,
      "loss": 0.1587,
      "step": 24760
    },
    {
      "epoch": 2.6540233579770707,
      "grad_norm": 0.015714285895228386,
      "learning_rate": 1.646130218936391e-05,
      "loss": 0.1585,
      "step": 24770
    },
    {
      "epoch": 2.655094824815172,
      "grad_norm": 0.05785108357667923,
      "learning_rate": 1.6459873566913105e-05,
      "loss": 0.1781,
      "step": 24780
    },
    {
      "epoch": 2.6561662916532733,
      "grad_norm": 0.0034097142051905394,
      "learning_rate": 1.6458444944462304e-05,
      "loss": 0.002,
      "step": 24790
    },
    {
      "epoch": 2.657237758491375,
      "grad_norm": 0.14419135451316833,
      "learning_rate": 1.64570163220115e-05,
      "loss": 0.2838,
      "step": 24800
    },
    {
      "epoch": 2.658309225329476,
      "grad_norm": 34.22150802612305,
      "learning_rate": 1.64555876995607e-05,
      "loss": 0.4399,
      "step": 24810
    },
    {
      "epoch": 2.6593806921675776,
      "grad_norm": 0.052705612033605576,
      "learning_rate": 1.64541590771099e-05,
      "loss": 0.1656,
      "step": 24820
    },
    {
      "epoch": 2.6604521590056787,
      "grad_norm": 0.518165111541748,
      "learning_rate": 1.6452730454659095e-05,
      "loss": 0.4124,
      "step": 24830
    },
    {
      "epoch": 2.66152362584378,
      "grad_norm": 57.602149963378906,
      "learning_rate": 1.6451301832208294e-05,
      "loss": 0.5437,
      "step": 24840
    },
    {
      "epoch": 2.6625950926818813,
      "grad_norm": 0.007967633195221424,
      "learning_rate": 1.6449873209757493e-05,
      "loss": 0.0006,
      "step": 24850
    },
    {
      "epoch": 2.663666559519983,
      "grad_norm": 0.004485967569053173,
      "learning_rate": 1.644844458730669e-05,
      "loss": 0.0012,
      "step": 24860
    },
    {
      "epoch": 2.6647380263580844,
      "grad_norm": 0.014320692047476768,
      "learning_rate": 1.644701596485589e-05,
      "loss": 0.0011,
      "step": 24870
    },
    {
      "epoch": 2.6658094931961855,
      "grad_norm": 0.052570097148418427,
      "learning_rate": 1.6445587342405088e-05,
      "loss": 0.0017,
      "step": 24880
    },
    {
      "epoch": 2.666880960034287,
      "grad_norm": 0.0013608786975964904,
      "learning_rate": 1.6444158719954288e-05,
      "loss": 0.7467,
      "step": 24890
    },
    {
      "epoch": 2.667952426872388,
      "grad_norm": 0.09845519810914993,
      "learning_rate": 1.6442730097503484e-05,
      "loss": 0.0009,
      "step": 24900
    },
    {
      "epoch": 2.6690238937104898,
      "grad_norm": 0.002405978972092271,
      "learning_rate": 1.6441301475052683e-05,
      "loss": 0.376,
      "step": 24910
    },
    {
      "epoch": 2.670095360548591,
      "grad_norm": 38.45111083984375,
      "learning_rate": 1.643987285260188e-05,
      "loss": 0.3208,
      "step": 24920
    },
    {
      "epoch": 2.6711668273866924,
      "grad_norm": 0.061482466757297516,
      "learning_rate": 1.6438444230151078e-05,
      "loss": 0.4087,
      "step": 24930
    },
    {
      "epoch": 2.672238294224794,
      "grad_norm": 0.030893946066498756,
      "learning_rate": 1.6437015607700278e-05,
      "loss": 0.2834,
      "step": 24940
    },
    {
      "epoch": 2.673309761062895,
      "grad_norm": 28.156286239624023,
      "learning_rate": 1.6435586985249474e-05,
      "loss": 0.1879,
      "step": 24950
    },
    {
      "epoch": 2.674381227900996,
      "grad_norm": 0.03917069733142853,
      "learning_rate": 1.6434158362798673e-05,
      "loss": 0.317,
      "step": 24960
    },
    {
      "epoch": 2.6754526947390977,
      "grad_norm": 0.051749683916568756,
      "learning_rate": 1.643272974034787e-05,
      "loss": 0.2476,
      "step": 24970
    },
    {
      "epoch": 2.6765241615771993,
      "grad_norm": 0.13781523704528809,
      "learning_rate": 1.6431301117897068e-05,
      "loss": 0.0029,
      "step": 24980
    },
    {
      "epoch": 2.6775956284153004,
      "grad_norm": 0.016595957800745964,
      "learning_rate": 1.6429872495446268e-05,
      "loss": 0.3121,
      "step": 24990
    },
    {
      "epoch": 2.678667095253402,
      "grad_norm": 1.271468997001648,
      "learning_rate": 1.6428443872995467e-05,
      "loss": 0.2258,
      "step": 25000
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.18300484120845795,
      "learning_rate": 1.6427015250544663e-05,
      "loss": 0.0014,
      "step": 25010
    },
    {
      "epoch": 2.6808100289296046,
      "grad_norm": 0.01885739341378212,
      "learning_rate": 1.6425586628093862e-05,
      "loss": 0.0009,
      "step": 25020
    },
    {
      "epoch": 2.6818814957677057,
      "grad_norm": 0.14193762838840485,
      "learning_rate": 1.6424158005643062e-05,
      "loss": 0.1413,
      "step": 25030
    },
    {
      "epoch": 2.6829529626058073,
      "grad_norm": 0.048782188445329666,
      "learning_rate": 1.6422729383192258e-05,
      "loss": 0.0056,
      "step": 25040
    },
    {
      "epoch": 2.684024429443909,
      "grad_norm": 4.61246395111084,
      "learning_rate": 1.6421300760741457e-05,
      "loss": 0.1327,
      "step": 25050
    },
    {
      "epoch": 2.68509589628201,
      "grad_norm": 0.26083189249038696,
      "learning_rate": 1.6419872138290656e-05,
      "loss": 0.1371,
      "step": 25060
    },
    {
      "epoch": 2.6861673631201115,
      "grad_norm": 0.035319529473781586,
      "learning_rate": 1.6418443515839852e-05,
      "loss": 0.4595,
      "step": 25070
    },
    {
      "epoch": 2.687238829958213,
      "grad_norm": 0.005210897885262966,
      "learning_rate": 1.6417014893389052e-05,
      "loss": 0.3413,
      "step": 25080
    },
    {
      "epoch": 2.688310296796314,
      "grad_norm": 0.00825574528425932,
      "learning_rate": 1.6415586270938248e-05,
      "loss": 0.0126,
      "step": 25090
    },
    {
      "epoch": 2.6893817636344153,
      "grad_norm": 0.05314802750945091,
      "learning_rate": 1.6414157648487447e-05,
      "loss": 0.1478,
      "step": 25100
    },
    {
      "epoch": 2.690453230472517,
      "grad_norm": 0.051014892756938934,
      "learning_rate": 1.6412729026036643e-05,
      "loss": 0.2313,
      "step": 25110
    },
    {
      "epoch": 2.6915246973106184,
      "grad_norm": 16.70298957824707,
      "learning_rate": 1.6411300403585842e-05,
      "loss": 0.3365,
      "step": 25120
    },
    {
      "epoch": 2.6925961641487195,
      "grad_norm": 0.15974919497966766,
      "learning_rate": 1.6409871781135042e-05,
      "loss": 0.4888,
      "step": 25130
    },
    {
      "epoch": 2.693667630986821,
      "grad_norm": 0.271062433719635,
      "learning_rate": 1.640844315868424e-05,
      "loss": 0.1872,
      "step": 25140
    },
    {
      "epoch": 2.694739097824922,
      "grad_norm": 0.00844383705407381,
      "learning_rate": 1.6407014536233437e-05,
      "loss": 0.0012,
      "step": 25150
    },
    {
      "epoch": 2.6958105646630237,
      "grad_norm": 31.760507583618164,
      "learning_rate": 1.6405585913782637e-05,
      "loss": 0.3324,
      "step": 25160
    },
    {
      "epoch": 2.696882031501125,
      "grad_norm": 28.044431686401367,
      "learning_rate": 1.6404157291331836e-05,
      "loss": 0.3421,
      "step": 25170
    },
    {
      "epoch": 2.6979534983392264,
      "grad_norm": 16.976282119750977,
      "learning_rate": 1.6402728668881035e-05,
      "loss": 0.6039,
      "step": 25180
    },
    {
      "epoch": 2.699024965177328,
      "grad_norm": 53.27164077758789,
      "learning_rate": 1.640130004643023e-05,
      "loss": 0.0515,
      "step": 25190
    },
    {
      "epoch": 2.700096432015429,
      "grad_norm": 0.012763416394591331,
      "learning_rate": 1.639987142397943e-05,
      "loss": 0.1769,
      "step": 25200
    },
    {
      "epoch": 2.7011678988535306,
      "grad_norm": 0.01638147421181202,
      "learning_rate": 1.6398442801528627e-05,
      "loss": 0.0014,
      "step": 25210
    },
    {
      "epoch": 2.7022393656916317,
      "grad_norm": 0.02144150249660015,
      "learning_rate": 1.6397014179077826e-05,
      "loss": 0.0076,
      "step": 25220
    },
    {
      "epoch": 2.7033108325297333,
      "grad_norm": 0.2506180703639984,
      "learning_rate": 1.6395585556627022e-05,
      "loss": 0.0021,
      "step": 25230
    },
    {
      "epoch": 2.7043822993678344,
      "grad_norm": 0.2230682224035263,
      "learning_rate": 1.639415693417622e-05,
      "loss": 0.2405,
      "step": 25240
    },
    {
      "epoch": 2.705453766205936,
      "grad_norm": 0.02723994478583336,
      "learning_rate": 1.639272831172542e-05,
      "loss": 0.4696,
      "step": 25250
    },
    {
      "epoch": 2.7065252330440375,
      "grad_norm": 21.944692611694336,
      "learning_rate": 1.6391299689274617e-05,
      "loss": 0.6905,
      "step": 25260
    },
    {
      "epoch": 2.7075966998821386,
      "grad_norm": 0.2604365348815918,
      "learning_rate": 1.6389871066823816e-05,
      "loss": 0.0029,
      "step": 25270
    },
    {
      "epoch": 2.70866816672024,
      "grad_norm": 21.09723663330078,
      "learning_rate": 1.6388442444373015e-05,
      "loss": 0.1153,
      "step": 25280
    },
    {
      "epoch": 2.7097396335583412,
      "grad_norm": 25.634347915649414,
      "learning_rate": 1.638701382192221e-05,
      "loss": 0.6952,
      "step": 25290
    },
    {
      "epoch": 2.710811100396443,
      "grad_norm": 0.06263236701488495,
      "learning_rate": 1.638558519947141e-05,
      "loss": 0.2995,
      "step": 25300
    },
    {
      "epoch": 2.711882567234544,
      "grad_norm": 0.4019355773925781,
      "learning_rate": 1.638415657702061e-05,
      "loss": 0.4742,
      "step": 25310
    },
    {
      "epoch": 2.7129540340726455,
      "grad_norm": 0.02246820740401745,
      "learning_rate": 1.638272795456981e-05,
      "loss": 0.1377,
      "step": 25320
    },
    {
      "epoch": 2.714025500910747,
      "grad_norm": 0.008862852118909359,
      "learning_rate": 1.6381299332119005e-05,
      "loss": 0.1523,
      "step": 25330
    },
    {
      "epoch": 2.715096967748848,
      "grad_norm": 0.020883994176983833,
      "learning_rate": 1.6379870709668205e-05,
      "loss": 0.5077,
      "step": 25340
    },
    {
      "epoch": 2.7161684345869497,
      "grad_norm": 25.1334171295166,
      "learning_rate": 1.63784420872174e-05,
      "loss": 0.2508,
      "step": 25350
    },
    {
      "epoch": 2.717239901425051,
      "grad_norm": 0.33096930384635925,
      "learning_rate": 1.63770134647666e-05,
      "loss": 0.2507,
      "step": 25360
    },
    {
      "epoch": 2.7183113682631523,
      "grad_norm": 0.017750876024365425,
      "learning_rate": 1.63755848423158e-05,
      "loss": 0.3926,
      "step": 25370
    },
    {
      "epoch": 2.7193828351012534,
      "grad_norm": 27.45905303955078,
      "learning_rate": 1.6374156219864996e-05,
      "loss": 0.24,
      "step": 25380
    },
    {
      "epoch": 2.720454301939355,
      "grad_norm": 0.04054196923971176,
      "learning_rate": 1.6372727597414195e-05,
      "loss": 0.0021,
      "step": 25390
    },
    {
      "epoch": 2.7215257687774566,
      "grad_norm": 0.08690424263477325,
      "learning_rate": 1.637129897496339e-05,
      "loss": 0.1694,
      "step": 25400
    },
    {
      "epoch": 2.7225972356155577,
      "grad_norm": 0.02055005170404911,
      "learning_rate": 1.636987035251259e-05,
      "loss": 0.2499,
      "step": 25410
    },
    {
      "epoch": 2.723668702453659,
      "grad_norm": 0.22230827808380127,
      "learning_rate": 1.636844173006179e-05,
      "loss": 0.0021,
      "step": 25420
    },
    {
      "epoch": 2.7247401692917603,
      "grad_norm": 0.14192438125610352,
      "learning_rate": 1.636701310761099e-05,
      "loss": 0.0021,
      "step": 25430
    },
    {
      "epoch": 2.725811636129862,
      "grad_norm": 0.008210256695747375,
      "learning_rate": 1.6365584485160185e-05,
      "loss": 0.0008,
      "step": 25440
    },
    {
      "epoch": 2.726883102967963,
      "grad_norm": 152.291015625,
      "learning_rate": 1.6364155862709384e-05,
      "loss": 0.145,
      "step": 25450
    },
    {
      "epoch": 2.7279545698060645,
      "grad_norm": 0.08353117853403091,
      "learning_rate": 1.6362727240258584e-05,
      "loss": 0.7672,
      "step": 25460
    },
    {
      "epoch": 2.729026036644166,
      "grad_norm": 43.074649810791016,
      "learning_rate": 1.636129861780778e-05,
      "loss": 0.236,
      "step": 25470
    },
    {
      "epoch": 2.730097503482267,
      "grad_norm": 0.02184145525097847,
      "learning_rate": 1.635986999535698e-05,
      "loss": 0.3293,
      "step": 25480
    },
    {
      "epoch": 2.7311689703203683,
      "grad_norm": 27.614421844482422,
      "learning_rate": 1.635844137290618e-05,
      "loss": 0.3246,
      "step": 25490
    },
    {
      "epoch": 2.73224043715847,
      "grad_norm": 0.020166397094726562,
      "learning_rate": 1.6357012750455374e-05,
      "loss": 0.17,
      "step": 25500
    },
    {
      "epoch": 2.7333119039965714,
      "grad_norm": 0.3225507140159607,
      "learning_rate": 1.6355584128004574e-05,
      "loss": 0.0012,
      "step": 25510
    },
    {
      "epoch": 2.7343833708346725,
      "grad_norm": 0.0039804899133741856,
      "learning_rate": 1.635415550555377e-05,
      "loss": 0.1398,
      "step": 25520
    },
    {
      "epoch": 2.735454837672774,
      "grad_norm": 0.01861252449452877,
      "learning_rate": 1.635272688310297e-05,
      "loss": 0.1449,
      "step": 25530
    },
    {
      "epoch": 2.7365263045108756,
      "grad_norm": 0.03924098238348961,
      "learning_rate": 1.6351298260652165e-05,
      "loss": 0.0082,
      "step": 25540
    },
    {
      "epoch": 2.7375977713489767,
      "grad_norm": 33.35657501220703,
      "learning_rate": 1.6349869638201364e-05,
      "loss": 0.4184,
      "step": 25550
    },
    {
      "epoch": 2.738669238187078,
      "grad_norm": 0.04479097202420235,
      "learning_rate": 1.6348441015750564e-05,
      "loss": 0.0012,
      "step": 25560
    },
    {
      "epoch": 2.7397407050251794,
      "grad_norm": 0.010285290889441967,
      "learning_rate": 1.6347012393299763e-05,
      "loss": 0.0004,
      "step": 25570
    },
    {
      "epoch": 2.740812171863281,
      "grad_norm": 0.03694557398557663,
      "learning_rate": 1.634558377084896e-05,
      "loss": 0.0012,
      "step": 25580
    },
    {
      "epoch": 2.741883638701382,
      "grad_norm": 0.011303508654236794,
      "learning_rate": 1.634415514839816e-05,
      "loss": 0.0109,
      "step": 25590
    },
    {
      "epoch": 2.7429551055394836,
      "grad_norm": 0.02126605063676834,
      "learning_rate": 1.6342726525947358e-05,
      "loss": 0.1975,
      "step": 25600
    },
    {
      "epoch": 2.744026572377585,
      "grad_norm": 0.02488810382783413,
      "learning_rate": 1.6341297903496557e-05,
      "loss": 0.4355,
      "step": 25610
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.030488507822155952,
      "learning_rate": 1.6339869281045753e-05,
      "loss": 0.3397,
      "step": 25620
    },
    {
      "epoch": 2.7461695060537874,
      "grad_norm": 0.4082537889480591,
      "learning_rate": 1.6338440658594953e-05,
      "loss": 0.1674,
      "step": 25630
    },
    {
      "epoch": 2.747240972891889,
      "grad_norm": 0.051364414393901825,
      "learning_rate": 1.633701203614415e-05,
      "loss": 0.3159,
      "step": 25640
    },
    {
      "epoch": 2.7483124397299905,
      "grad_norm": 0.34564149379730225,
      "learning_rate": 1.6335583413693348e-05,
      "loss": 0.1415,
      "step": 25650
    },
    {
      "epoch": 2.7493839065680916,
      "grad_norm": 0.012722740881145,
      "learning_rate": 1.6334154791242544e-05,
      "loss": 0.0025,
      "step": 25660
    },
    {
      "epoch": 2.750455373406193,
      "grad_norm": 0.08108529448509216,
      "learning_rate": 1.6332726168791743e-05,
      "loss": 0.2421,
      "step": 25670
    },
    {
      "epoch": 2.7515268402442943,
      "grad_norm": 0.009222244843840599,
      "learning_rate": 1.6331297546340943e-05,
      "loss": 0.172,
      "step": 25680
    },
    {
      "epoch": 2.752598307082396,
      "grad_norm": 0.008229503408074379,
      "learning_rate": 1.632986892389014e-05,
      "loss": 0.0503,
      "step": 25690
    },
    {
      "epoch": 2.753669773920497,
      "grad_norm": 0.06258418411016464,
      "learning_rate": 1.6328440301439338e-05,
      "loss": 0.1236,
      "step": 25700
    },
    {
      "epoch": 2.7547412407585985,
      "grad_norm": 0.8778219223022461,
      "learning_rate": 1.6327011678988537e-05,
      "loss": 0.1278,
      "step": 25710
    },
    {
      "epoch": 2.7558127075967,
      "grad_norm": 0.45276111364364624,
      "learning_rate": 1.6325583056537733e-05,
      "loss": 0.0245,
      "step": 25720
    },
    {
      "epoch": 2.756884174434801,
      "grad_norm": 0.009466811083257198,
      "learning_rate": 1.6324154434086933e-05,
      "loss": 0.6539,
      "step": 25730
    },
    {
      "epoch": 2.7579556412729027,
      "grad_norm": 40.818275451660156,
      "learning_rate": 1.6322725811636132e-05,
      "loss": 0.1775,
      "step": 25740
    },
    {
      "epoch": 2.759027108111004,
      "grad_norm": 0.04545190930366516,
      "learning_rate": 1.632129718918533e-05,
      "loss": 0.0007,
      "step": 25750
    },
    {
      "epoch": 2.7600985749491054,
      "grad_norm": 0.005175749771296978,
      "learning_rate": 1.6319868566734527e-05,
      "loss": 0.0004,
      "step": 25760
    },
    {
      "epoch": 2.7611700417872065,
      "grad_norm": 0.03562066704034805,
      "learning_rate": 1.6318439944283727e-05,
      "loss": 0.4079,
      "step": 25770
    },
    {
      "epoch": 2.762241508625308,
      "grad_norm": 0.016180969774723053,
      "learning_rate": 1.6317011321832923e-05,
      "loss": 0.002,
      "step": 25780
    },
    {
      "epoch": 2.7633129754634096,
      "grad_norm": 0.011556142009794712,
      "learning_rate": 1.6315582699382122e-05,
      "loss": 0.14,
      "step": 25790
    },
    {
      "epoch": 2.7643844423015107,
      "grad_norm": 0.06010054796934128,
      "learning_rate": 1.631415407693132e-05,
      "loss": 0.5149,
      "step": 25800
    },
    {
      "epoch": 2.7654559091396123,
      "grad_norm": 0.004563437774777412,
      "learning_rate": 1.6312725454480517e-05,
      "loss": 0.2023,
      "step": 25810
    },
    {
      "epoch": 2.7665273759777134,
      "grad_norm": 0.07669544965028763,
      "learning_rate": 1.6311296832029717e-05,
      "loss": 0.143,
      "step": 25820
    },
    {
      "epoch": 2.767598842815815,
      "grad_norm": 0.008505737408995628,
      "learning_rate": 1.6309868209578913e-05,
      "loss": 0.1361,
      "step": 25830
    },
    {
      "epoch": 2.768670309653916,
      "grad_norm": 0.014734749682247639,
      "learning_rate": 1.6308439587128112e-05,
      "loss": 0.219,
      "step": 25840
    },
    {
      "epoch": 2.7697417764920176,
      "grad_norm": 0.2649211585521698,
      "learning_rate": 1.630701096467731e-05,
      "loss": 0.0014,
      "step": 25850
    },
    {
      "epoch": 2.770813243330119,
      "grad_norm": 0.027781840413808823,
      "learning_rate": 1.6305582342226508e-05,
      "loss": 0.6257,
      "step": 25860
    },
    {
      "epoch": 2.7718847101682202,
      "grad_norm": 0.006000259425491095,
      "learning_rate": 1.6304153719775707e-05,
      "loss": 0.176,
      "step": 25870
    },
    {
      "epoch": 2.772956177006322,
      "grad_norm": 0.27222752571105957,
      "learning_rate": 1.6302725097324906e-05,
      "loss": 0.3263,
      "step": 25880
    },
    {
      "epoch": 2.774027643844423,
      "grad_norm": 0.06060805916786194,
      "learning_rate": 1.6301296474874106e-05,
      "loss": 0.0007,
      "step": 25890
    },
    {
      "epoch": 2.7750991106825245,
      "grad_norm": 0.01315778587013483,
      "learning_rate": 1.62998678524233e-05,
      "loss": 0.3681,
      "step": 25900
    },
    {
      "epoch": 2.7761705775206256,
      "grad_norm": 0.09083951264619827,
      "learning_rate": 1.62984392299725e-05,
      "loss": 0.0986,
      "step": 25910
    },
    {
      "epoch": 2.777242044358727,
      "grad_norm": 0.19695763289928436,
      "learning_rate": 1.62970106075217e-05,
      "loss": 0.6369,
      "step": 25920
    },
    {
      "epoch": 2.7783135111968287,
      "grad_norm": 0.014008640311658382,
      "learning_rate": 1.6295581985070896e-05,
      "loss": 0.5162,
      "step": 25930
    },
    {
      "epoch": 2.77938497803493,
      "grad_norm": 0.08427927643060684,
      "learning_rate": 1.6294153362620096e-05,
      "loss": 0.0018,
      "step": 25940
    },
    {
      "epoch": 2.7804564448730313,
      "grad_norm": 0.05785972252488136,
      "learning_rate": 1.629272474016929e-05,
      "loss": 0.3163,
      "step": 25950
    },
    {
      "epoch": 2.7815279117111325,
      "grad_norm": 0.01000789925456047,
      "learning_rate": 1.629129611771849e-05,
      "loss": 0.0048,
      "step": 25960
    },
    {
      "epoch": 2.782599378549234,
      "grad_norm": 0.04829719290137291,
      "learning_rate": 1.628986749526769e-05,
      "loss": 0.0021,
      "step": 25970
    },
    {
      "epoch": 2.783670845387335,
      "grad_norm": 0.07108283787965775,
      "learning_rate": 1.6288438872816886e-05,
      "loss": 0.0021,
      "step": 25980
    },
    {
      "epoch": 2.7847423122254367,
      "grad_norm": 0.05316884070634842,
      "learning_rate": 1.6287010250366086e-05,
      "loss": 0.2439,
      "step": 25990
    },
    {
      "epoch": 2.785813779063538,
      "grad_norm": 0.053924862295389175,
      "learning_rate": 1.6285581627915285e-05,
      "loss": 0.1534,
      "step": 26000
    },
    {
      "epoch": 2.7868852459016393,
      "grad_norm": 0.0505172424018383,
      "learning_rate": 1.628415300546448e-05,
      "loss": 0.5656,
      "step": 26010
    },
    {
      "epoch": 2.7879567127397404,
      "grad_norm": 0.04376159980893135,
      "learning_rate": 1.628272438301368e-05,
      "loss": 0.1444,
      "step": 26020
    },
    {
      "epoch": 2.789028179577842,
      "grad_norm": 0.03532226011157036,
      "learning_rate": 1.628129576056288e-05,
      "loss": 0.125,
      "step": 26030
    },
    {
      "epoch": 2.7900996464159435,
      "grad_norm": 17.926576614379883,
      "learning_rate": 1.627986713811208e-05,
      "loss": 0.2959,
      "step": 26040
    },
    {
      "epoch": 2.7911711132540447,
      "grad_norm": 0.015874193981289864,
      "learning_rate": 1.6278438515661275e-05,
      "loss": 0.0015,
      "step": 26050
    },
    {
      "epoch": 2.792242580092146,
      "grad_norm": 0.015111860819160938,
      "learning_rate": 1.6277009893210475e-05,
      "loss": 0.1257,
      "step": 26060
    },
    {
      "epoch": 2.7933140469302478,
      "grad_norm": 0.03315000981092453,
      "learning_rate": 1.627558127075967e-05,
      "loss": 0.1755,
      "step": 26070
    },
    {
      "epoch": 2.794385513768349,
      "grad_norm": 0.07969652861356735,
      "learning_rate": 1.627415264830887e-05,
      "loss": 0.1696,
      "step": 26080
    },
    {
      "epoch": 2.79545698060645,
      "grad_norm": 23.63134002685547,
      "learning_rate": 1.627272402585807e-05,
      "loss": 0.3774,
      "step": 26090
    },
    {
      "epoch": 2.7965284474445515,
      "grad_norm": 0.04685862734913826,
      "learning_rate": 1.6271295403407265e-05,
      "loss": 0.0891,
      "step": 26100
    },
    {
      "epoch": 2.797599914282653,
      "grad_norm": 0.024845976382493973,
      "learning_rate": 1.6269866780956465e-05,
      "loss": 0.1124,
      "step": 26110
    },
    {
      "epoch": 2.798671381120754,
      "grad_norm": 0.07400795817375183,
      "learning_rate": 1.626843815850566e-05,
      "loss": 0.176,
      "step": 26120
    },
    {
      "epoch": 2.7997428479588558,
      "grad_norm": 37.88410949707031,
      "learning_rate": 1.626700953605486e-05,
      "loss": 0.1812,
      "step": 26130
    },
    {
      "epoch": 2.8008143147969573,
      "grad_norm": 0.007257489487528801,
      "learning_rate": 1.626558091360406e-05,
      "loss": 0.1864,
      "step": 26140
    },
    {
      "epoch": 2.8018857816350584,
      "grad_norm": 0.03390628844499588,
      "learning_rate": 1.6264152291153255e-05,
      "loss": 0.2108,
      "step": 26150
    },
    {
      "epoch": 2.8029572484731595,
      "grad_norm": 0.20964445173740387,
      "learning_rate": 1.6262723668702455e-05,
      "loss": 0.1639,
      "step": 26160
    },
    {
      "epoch": 2.804028715311261,
      "grad_norm": 0.016819821670651436,
      "learning_rate": 1.6261295046251654e-05,
      "loss": 0.2882,
      "step": 26170
    },
    {
      "epoch": 2.8051001821493626,
      "grad_norm": 0.013080920092761517,
      "learning_rate": 1.6259866423800853e-05,
      "loss": 0.1642,
      "step": 26180
    },
    {
      "epoch": 2.8061716489874637,
      "grad_norm": 0.03601900488138199,
      "learning_rate": 1.625843780135005e-05,
      "loss": 0.2445,
      "step": 26190
    },
    {
      "epoch": 2.8072431158255653,
      "grad_norm": 0.08158420026302338,
      "learning_rate": 1.625700917889925e-05,
      "loss": 0.1239,
      "step": 26200
    },
    {
      "epoch": 2.8083145826636664,
      "grad_norm": 4.368182182312012,
      "learning_rate": 1.6255580556448448e-05,
      "loss": 0.3041,
      "step": 26210
    },
    {
      "epoch": 2.809386049501768,
      "grad_norm": 0.037821341305971146,
      "learning_rate": 1.6254151933997644e-05,
      "loss": 0.1917,
      "step": 26220
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 4.81303596496582,
      "learning_rate": 1.6252723311546843e-05,
      "loss": 0.1577,
      "step": 26230
    },
    {
      "epoch": 2.8115289831779706,
      "grad_norm": 0.013610477559268475,
      "learning_rate": 1.625129468909604e-05,
      "loss": 0.2626,
      "step": 26240
    },
    {
      "epoch": 2.812600450016072,
      "grad_norm": 0.010903507471084595,
      "learning_rate": 1.624986606664524e-05,
      "loss": 0.3675,
      "step": 26250
    },
    {
      "epoch": 2.8136719168541733,
      "grad_norm": 0.1380651593208313,
      "learning_rate": 1.6248437444194435e-05,
      "loss": 0.4545,
      "step": 26260
    },
    {
      "epoch": 2.814743383692275,
      "grad_norm": 1.375550627708435,
      "learning_rate": 1.6247008821743634e-05,
      "loss": 0.0053,
      "step": 26270
    },
    {
      "epoch": 2.815814850530376,
      "grad_norm": 0.019064361229538918,
      "learning_rate": 1.6245580199292833e-05,
      "loss": 0.4542,
      "step": 26280
    },
    {
      "epoch": 2.8168863173684775,
      "grad_norm": 0.08363606035709381,
      "learning_rate": 1.624415157684203e-05,
      "loss": 0.5693,
      "step": 26290
    },
    {
      "epoch": 2.8179577842065786,
      "grad_norm": 0.495121031999588,
      "learning_rate": 1.624272295439123e-05,
      "loss": 0.0047,
      "step": 26300
    },
    {
      "epoch": 2.81902925104468,
      "grad_norm": 0.07081852108240128,
      "learning_rate": 1.6241294331940428e-05,
      "loss": 0.1609,
      "step": 26310
    },
    {
      "epoch": 2.8201007178827817,
      "grad_norm": 0.20642980933189392,
      "learning_rate": 1.6239865709489628e-05,
      "loss": 0.0015,
      "step": 26320
    },
    {
      "epoch": 2.821172184720883,
      "grad_norm": 26.83659553527832,
      "learning_rate": 1.6238437087038824e-05,
      "loss": 0.1811,
      "step": 26330
    },
    {
      "epoch": 2.8222436515589844,
      "grad_norm": 1.513222336769104,
      "learning_rate": 1.6237008464588023e-05,
      "loss": 0.2919,
      "step": 26340
    },
    {
      "epoch": 2.8233151183970855,
      "grad_norm": 0.052982065826654434,
      "learning_rate": 1.6235579842137222e-05,
      "loss": 0.3923,
      "step": 26350
    },
    {
      "epoch": 2.824386585235187,
      "grad_norm": 0.049392785876989365,
      "learning_rate": 1.6234151219686418e-05,
      "loss": 0.3062,
      "step": 26360
    },
    {
      "epoch": 2.825458052073288,
      "grad_norm": 0.010506528429687023,
      "learning_rate": 1.6232722597235618e-05,
      "loss": 0.1488,
      "step": 26370
    },
    {
      "epoch": 2.8265295189113897,
      "grad_norm": 0.003387679811567068,
      "learning_rate": 1.6231293974784814e-05,
      "loss": 0.1947,
      "step": 26380
    },
    {
      "epoch": 2.8276009857494913,
      "grad_norm": 0.3818017542362213,
      "learning_rate": 1.6229865352334013e-05,
      "loss": 0.0041,
      "step": 26390
    },
    {
      "epoch": 2.8286724525875924,
      "grad_norm": 0.0034475699067115784,
      "learning_rate": 1.6228436729883212e-05,
      "loss": 0.459,
      "step": 26400
    },
    {
      "epoch": 2.829743919425694,
      "grad_norm": 0.03382505849003792,
      "learning_rate": 1.622700810743241e-05,
      "loss": 0.0012,
      "step": 26410
    },
    {
      "epoch": 2.830815386263795,
      "grad_norm": 0.043122775852680206,
      "learning_rate": 1.6225579484981608e-05,
      "loss": 0.4059,
      "step": 26420
    },
    {
      "epoch": 2.8318868531018966,
      "grad_norm": 0.0037483556661754847,
      "learning_rate": 1.6224150862530804e-05,
      "loss": 0.0015,
      "step": 26430
    },
    {
      "epoch": 2.8329583199399977,
      "grad_norm": 0.005211675073951483,
      "learning_rate": 1.6222722240080003e-05,
      "loss": 0.0004,
      "step": 26440
    },
    {
      "epoch": 2.8340297867780992,
      "grad_norm": 0.07555996626615524,
      "learning_rate": 1.6221293617629202e-05,
      "loss": 0.0013,
      "step": 26450
    },
    {
      "epoch": 2.835101253616201,
      "grad_norm": 0.10438010841608047,
      "learning_rate": 1.6219864995178402e-05,
      "loss": 0.3792,
      "step": 26460
    },
    {
      "epoch": 2.836172720454302,
      "grad_norm": 0.01624988578259945,
      "learning_rate": 1.62184363727276e-05,
      "loss": 0.1917,
      "step": 26470
    },
    {
      "epoch": 2.8372441872924035,
      "grad_norm": 0.39797794818878174,
      "learning_rate": 1.6217007750276797e-05,
      "loss": 0.1442,
      "step": 26480
    },
    {
      "epoch": 2.8383156541305046,
      "grad_norm": 0.20842784643173218,
      "learning_rate": 1.6215579127825996e-05,
      "loss": 0.0012,
      "step": 26490
    },
    {
      "epoch": 2.839387120968606,
      "grad_norm": 11.84650993347168,
      "learning_rate": 1.6214150505375192e-05,
      "loss": 0.1412,
      "step": 26500
    },
    {
      "epoch": 2.8404585878067072,
      "grad_norm": 0.11591244488954544,
      "learning_rate": 1.6212721882924392e-05,
      "loss": 0.2217,
      "step": 26510
    },
    {
      "epoch": 2.841530054644809,
      "grad_norm": 0.4755539894104004,
      "learning_rate": 1.621129326047359e-05,
      "loss": 0.002,
      "step": 26520
    },
    {
      "epoch": 2.8426015214829103,
      "grad_norm": 17.232389450073242,
      "learning_rate": 1.6209864638022787e-05,
      "loss": 0.2899,
      "step": 26530
    },
    {
      "epoch": 2.8436729883210115,
      "grad_norm": 0.1299988031387329,
      "learning_rate": 1.6208436015571987e-05,
      "loss": 0.0017,
      "step": 26540
    },
    {
      "epoch": 2.8447444551591126,
      "grad_norm": 0.006076718680560589,
      "learning_rate": 1.6207007393121182e-05,
      "loss": 0.6176,
      "step": 26550
    },
    {
      "epoch": 2.845815921997214,
      "grad_norm": 0.005678171291947365,
      "learning_rate": 1.6205578770670382e-05,
      "loss": 0.0019,
      "step": 26560
    },
    {
      "epoch": 2.8468873888353157,
      "grad_norm": 1.0040888786315918,
      "learning_rate": 1.620415014821958e-05,
      "loss": 0.2212,
      "step": 26570
    },
    {
      "epoch": 2.847958855673417,
      "grad_norm": 0.18390128016471863,
      "learning_rate": 1.6202721525768777e-05,
      "loss": 0.0016,
      "step": 26580
    },
    {
      "epoch": 2.8490303225115183,
      "grad_norm": 0.015481041744351387,
      "learning_rate": 1.6201292903317977e-05,
      "loss": 0.0028,
      "step": 26590
    },
    {
      "epoch": 2.85010178934962,
      "grad_norm": 56.689125061035156,
      "learning_rate": 1.6199864280867176e-05,
      "loss": 0.4427,
      "step": 26600
    },
    {
      "epoch": 2.851173256187721,
      "grad_norm": 0.2502049207687378,
      "learning_rate": 1.6198435658416375e-05,
      "loss": 0.1567,
      "step": 26610
    },
    {
      "epoch": 2.852244723025822,
      "grad_norm": 0.00678299693390727,
      "learning_rate": 1.619700703596557e-05,
      "loss": 0.2338,
      "step": 26620
    },
    {
      "epoch": 2.8533161898639237,
      "grad_norm": 0.00428994745016098,
      "learning_rate": 1.619557841351477e-05,
      "loss": 0.3004,
      "step": 26630
    },
    {
      "epoch": 2.854387656702025,
      "grad_norm": 0.01243621576577425,
      "learning_rate": 1.619414979106397e-05,
      "loss": 0.0003,
      "step": 26640
    },
    {
      "epoch": 2.8554591235401263,
      "grad_norm": 0.01908370479941368,
      "learning_rate": 1.6192721168613166e-05,
      "loss": 0.2636,
      "step": 26650
    },
    {
      "epoch": 2.856530590378228,
      "grad_norm": 0.03219947963953018,
      "learning_rate": 1.6191292546162365e-05,
      "loss": 0.4222,
      "step": 26660
    },
    {
      "epoch": 2.8576020572163294,
      "grad_norm": 0.07990240305662155,
      "learning_rate": 1.618986392371156e-05,
      "loss": 0.5421,
      "step": 26670
    },
    {
      "epoch": 2.8586735240544305,
      "grad_norm": 0.043378766626119614,
      "learning_rate": 1.618843530126076e-05,
      "loss": 0.2001,
      "step": 26680
    },
    {
      "epoch": 2.8597449908925316,
      "grad_norm": 0.00422582495957613,
      "learning_rate": 1.6187006678809957e-05,
      "loss": 0.0004,
      "step": 26690
    },
    {
      "epoch": 2.860816457730633,
      "grad_norm": 0.0651724636554718,
      "learning_rate": 1.6185578056359156e-05,
      "loss": 0.1532,
      "step": 26700
    },
    {
      "epoch": 2.8618879245687348,
      "grad_norm": 0.018208974972367287,
      "learning_rate": 1.6184149433908355e-05,
      "loss": 0.6077,
      "step": 26710
    },
    {
      "epoch": 2.862959391406836,
      "grad_norm": 38.45161819458008,
      "learning_rate": 1.618272081145755e-05,
      "loss": 0.4195,
      "step": 26720
    },
    {
      "epoch": 2.8640308582449374,
      "grad_norm": 0.16851021349430084,
      "learning_rate": 1.618129218900675e-05,
      "loss": 0.0037,
      "step": 26730
    },
    {
      "epoch": 2.8651023250830385,
      "grad_norm": 0.0540158748626709,
      "learning_rate": 1.617986356655595e-05,
      "loss": 0.1519,
      "step": 26740
    },
    {
      "epoch": 2.86617379192114,
      "grad_norm": 0.29380708932876587,
      "learning_rate": 1.617843494410515e-05,
      "loss": 0.1625,
      "step": 26750
    },
    {
      "epoch": 2.867245258759241,
      "grad_norm": 0.5658036470413208,
      "learning_rate": 1.6177006321654345e-05,
      "loss": 0.1486,
      "step": 26760
    },
    {
      "epoch": 2.8683167255973427,
      "grad_norm": 0.02583993785083294,
      "learning_rate": 1.6175577699203545e-05,
      "loss": 0.1806,
      "step": 26770
    },
    {
      "epoch": 2.8693881924354443,
      "grad_norm": 0.03763599321246147,
      "learning_rate": 1.6174149076752744e-05,
      "loss": 0.0009,
      "step": 26780
    },
    {
      "epoch": 2.8704596592735454,
      "grad_norm": 0.01830168440937996,
      "learning_rate": 1.617272045430194e-05,
      "loss": 0.2322,
      "step": 26790
    },
    {
      "epoch": 2.871531126111647,
      "grad_norm": 0.0015688022831454873,
      "learning_rate": 1.617129183185114e-05,
      "loss": 0.1473,
      "step": 26800
    },
    {
      "epoch": 2.872602592949748,
      "grad_norm": 0.002761651063337922,
      "learning_rate": 1.6169863209400336e-05,
      "loss": 0.1566,
      "step": 26810
    },
    {
      "epoch": 2.8736740597878496,
      "grad_norm": 0.04943324625492096,
      "learning_rate": 1.6168434586949535e-05,
      "loss": 0.6059,
      "step": 26820
    },
    {
      "epoch": 2.8747455266259507,
      "grad_norm": 21.227384567260742,
      "learning_rate": 1.6167005964498734e-05,
      "loss": 0.1879,
      "step": 26830
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 0.0053571066819131374,
      "learning_rate": 1.616557734204793e-05,
      "loss": 0.0836,
      "step": 26840
    },
    {
      "epoch": 2.876888460302154,
      "grad_norm": 0.08481089025735855,
      "learning_rate": 1.616414871959713e-05,
      "loss": 0.7167,
      "step": 26850
    },
    {
      "epoch": 2.877959927140255,
      "grad_norm": 0.013831790536642075,
      "learning_rate": 1.6162720097146326e-05,
      "loss": 0.1551,
      "step": 26860
    },
    {
      "epoch": 2.8790313939783565,
      "grad_norm": 0.40324676036834717,
      "learning_rate": 1.6161291474695525e-05,
      "loss": 0.2528,
      "step": 26870
    },
    {
      "epoch": 2.8801028608164576,
      "grad_norm": 0.05449283495545387,
      "learning_rate": 1.6159862852244724e-05,
      "loss": 0.0989,
      "step": 26880
    },
    {
      "epoch": 2.881174327654559,
      "grad_norm": 0.06389432400465012,
      "learning_rate": 1.6158434229793924e-05,
      "loss": 0.2422,
      "step": 26890
    },
    {
      "epoch": 2.8822457944926603,
      "grad_norm": 0.003933854401111603,
      "learning_rate": 1.6157005607343123e-05,
      "loss": 0.0058,
      "step": 26900
    },
    {
      "epoch": 2.883317261330762,
      "grad_norm": 0.005560917314141989,
      "learning_rate": 1.615557698489232e-05,
      "loss": 0.0058,
      "step": 26910
    },
    {
      "epoch": 2.8843887281688634,
      "grad_norm": 0.31983765959739685,
      "learning_rate": 1.615414836244152e-05,
      "loss": 0.0023,
      "step": 26920
    },
    {
      "epoch": 2.8854601950069645,
      "grad_norm": 0.0036692433059215546,
      "learning_rate": 1.6152719739990714e-05,
      "loss": 0.1508,
      "step": 26930
    },
    {
      "epoch": 2.886531661845066,
      "grad_norm": 0.04141716659069061,
      "learning_rate": 1.6151291117539914e-05,
      "loss": 0.3078,
      "step": 26940
    },
    {
      "epoch": 2.887603128683167,
      "grad_norm": 27.991619110107422,
      "learning_rate": 1.6149862495089113e-05,
      "loss": 0.8657,
      "step": 26950
    },
    {
      "epoch": 2.8886745955212687,
      "grad_norm": 26.90869903564453,
      "learning_rate": 1.614843387263831e-05,
      "loss": 0.176,
      "step": 26960
    },
    {
      "epoch": 2.88974606235937,
      "grad_norm": 1.225669026374817,
      "learning_rate": 1.614700525018751e-05,
      "loss": 0.1759,
      "step": 26970
    },
    {
      "epoch": 2.8908175291974714,
      "grad_norm": 523.2535400390625,
      "learning_rate": 1.6145576627736704e-05,
      "loss": 0.5329,
      "step": 26980
    },
    {
      "epoch": 2.891888996035573,
      "grad_norm": 0.009244229644536972,
      "learning_rate": 1.6144148005285904e-05,
      "loss": 0.5386,
      "step": 26990
    },
    {
      "epoch": 2.892960462873674,
      "grad_norm": 0.04622694477438927,
      "learning_rate": 1.6142719382835103e-05,
      "loss": 0.156,
      "step": 27000
    },
    {
      "epoch": 2.8940319297117756,
      "grad_norm": 0.6519907116889954,
      "learning_rate": 1.61412907603843e-05,
      "loss": 0.0023,
      "step": 27010
    },
    {
      "epoch": 2.8951033965498767,
      "grad_norm": 0.0676342099905014,
      "learning_rate": 1.61398621379335e-05,
      "loss": 0.236,
      "step": 27020
    },
    {
      "epoch": 2.8961748633879782,
      "grad_norm": 2.1335997581481934,
      "learning_rate": 1.6138433515482698e-05,
      "loss": 0.1915,
      "step": 27030
    },
    {
      "epoch": 2.8972463302260794,
      "grad_norm": 0.028585350140929222,
      "learning_rate": 1.6137004893031897e-05,
      "loss": 0.0134,
      "step": 27040
    },
    {
      "epoch": 2.898317797064181,
      "grad_norm": 54.04984664916992,
      "learning_rate": 1.6135576270581093e-05,
      "loss": 0.5204,
      "step": 27050
    },
    {
      "epoch": 2.8993892639022825,
      "grad_norm": 0.04713583365082741,
      "learning_rate": 1.6134147648130293e-05,
      "loss": 0.0045,
      "step": 27060
    },
    {
      "epoch": 2.9004607307403836,
      "grad_norm": 0.3155690133571625,
      "learning_rate": 1.6132719025679492e-05,
      "loss": 0.2397,
      "step": 27070
    },
    {
      "epoch": 2.9015321975784847,
      "grad_norm": 0.07303065806627274,
      "learning_rate": 1.6131290403228688e-05,
      "loss": 0.0032,
      "step": 27080
    },
    {
      "epoch": 2.9026036644165862,
      "grad_norm": 0.028625955805182457,
      "learning_rate": 1.6129861780777887e-05,
      "loss": 0.2034,
      "step": 27090
    },
    {
      "epoch": 2.903675131254688,
      "grad_norm": 0.03754021227359772,
      "learning_rate": 1.6128433158327083e-05,
      "loss": 0.5898,
      "step": 27100
    },
    {
      "epoch": 2.904746598092789,
      "grad_norm": 0.008755284361541271,
      "learning_rate": 1.6127004535876283e-05,
      "loss": 0.4804,
      "step": 27110
    },
    {
      "epoch": 2.9058180649308905,
      "grad_norm": 17.622190475463867,
      "learning_rate": 1.6125575913425482e-05,
      "loss": 0.3238,
      "step": 27120
    },
    {
      "epoch": 2.906889531768992,
      "grad_norm": 0.016169199720025063,
      "learning_rate": 1.6124147290974678e-05,
      "loss": 0.1782,
      "step": 27130
    },
    {
      "epoch": 2.907960998607093,
      "grad_norm": 0.008074586279690266,
      "learning_rate": 1.6122718668523877e-05,
      "loss": 0.1567,
      "step": 27140
    },
    {
      "epoch": 2.9090324654451942,
      "grad_norm": 0.1554616093635559,
      "learning_rate": 1.6121290046073073e-05,
      "loss": 0.3304,
      "step": 27150
    },
    {
      "epoch": 2.910103932283296,
      "grad_norm": 0.004212020896375179,
      "learning_rate": 1.6119861423622273e-05,
      "loss": 0.2698,
      "step": 27160
    },
    {
      "epoch": 2.9111753991213973,
      "grad_norm": 0.03975917771458626,
      "learning_rate": 1.6118432801171472e-05,
      "loss": 0.1635,
      "step": 27170
    },
    {
      "epoch": 2.9122468659594984,
      "grad_norm": 0.31177788972854614,
      "learning_rate": 1.611700417872067e-05,
      "loss": 0.1922,
      "step": 27180
    },
    {
      "epoch": 2.9133183327976,
      "grad_norm": 0.02194623276591301,
      "learning_rate": 1.6115575556269867e-05,
      "loss": 0.0019,
      "step": 27190
    },
    {
      "epoch": 2.9143897996357016,
      "grad_norm": 0.011730811558663845,
      "learning_rate": 1.6114146933819067e-05,
      "loss": 0.189,
      "step": 27200
    },
    {
      "epoch": 2.9154612664738027,
      "grad_norm": 0.0125596197322011,
      "learning_rate": 1.6112718311368266e-05,
      "loss": 0.0014,
      "step": 27210
    },
    {
      "epoch": 2.9165327333119038,
      "grad_norm": 0.006138201802968979,
      "learning_rate": 1.6111289688917462e-05,
      "loss": 0.133,
      "step": 27220
    },
    {
      "epoch": 2.9176042001500053,
      "grad_norm": 0.11999490112066269,
      "learning_rate": 1.610986106646666e-05,
      "loss": 0.3031,
      "step": 27230
    },
    {
      "epoch": 2.918675666988107,
      "grad_norm": 0.4008927047252655,
      "learning_rate": 1.6108432444015857e-05,
      "loss": 0.1685,
      "step": 27240
    },
    {
      "epoch": 2.919747133826208,
      "grad_norm": 0.007052976172417402,
      "learning_rate": 1.6107003821565057e-05,
      "loss": 0.5314,
      "step": 27250
    },
    {
      "epoch": 2.9208186006643095,
      "grad_norm": 0.009867317043244839,
      "learning_rate": 1.6105575199114256e-05,
      "loss": 0.0021,
      "step": 27260
    },
    {
      "epoch": 2.9218900675024106,
      "grad_norm": 0.04535520821809769,
      "learning_rate": 1.6104146576663452e-05,
      "loss": 0.0986,
      "step": 27270
    },
    {
      "epoch": 2.922961534340512,
      "grad_norm": 0.015069441869854927,
      "learning_rate": 1.610271795421265e-05,
      "loss": 0.3178,
      "step": 27280
    },
    {
      "epoch": 2.9240330011786133,
      "grad_norm": 0.001672354293987155,
      "learning_rate": 1.6101289331761848e-05,
      "loss": 0.2614,
      "step": 27290
    },
    {
      "epoch": 2.925104468016715,
      "grad_norm": 0.03453925997018814,
      "learning_rate": 1.6099860709311047e-05,
      "loss": 0.0019,
      "step": 27300
    },
    {
      "epoch": 2.9261759348548164,
      "grad_norm": 22.726272583007812,
      "learning_rate": 1.6098432086860246e-05,
      "loss": 0.4371,
      "step": 27310
    },
    {
      "epoch": 2.9272474016929175,
      "grad_norm": 0.30451545119285583,
      "learning_rate": 1.6097003464409446e-05,
      "loss": 0.3076,
      "step": 27320
    },
    {
      "epoch": 2.928318868531019,
      "grad_norm": 0.03615251183509827,
      "learning_rate": 1.609557484195864e-05,
      "loss": 0.4546,
      "step": 27330
    },
    {
      "epoch": 2.92939033536912,
      "grad_norm": 0.16114868223667145,
      "learning_rate": 1.609414621950784e-05,
      "loss": 0.197,
      "step": 27340
    },
    {
      "epoch": 2.9304618022072217,
      "grad_norm": 0.31353989243507385,
      "learning_rate": 1.609271759705704e-05,
      "loss": 0.4544,
      "step": 27350
    },
    {
      "epoch": 2.931533269045323,
      "grad_norm": 0.3083798587322235,
      "learning_rate": 1.6091288974606236e-05,
      "loss": 0.0542,
      "step": 27360
    },
    {
      "epoch": 2.9326047358834244,
      "grad_norm": 16.14153289794922,
      "learning_rate": 1.6089860352155436e-05,
      "loss": 0.1816,
      "step": 27370
    },
    {
      "epoch": 2.933676202721526,
      "grad_norm": 0.0227816104888916,
      "learning_rate": 1.6088431729704635e-05,
      "loss": 0.1477,
      "step": 27380
    },
    {
      "epoch": 2.934747669559627,
      "grad_norm": 26.912105560302734,
      "learning_rate": 1.608700310725383e-05,
      "loss": 0.4769,
      "step": 27390
    },
    {
      "epoch": 2.9358191363977286,
      "grad_norm": 0.44459545612335205,
      "learning_rate": 1.608557448480303e-05,
      "loss": 0.3453,
      "step": 27400
    },
    {
      "epoch": 2.9368906032358297,
      "grad_norm": 0.020577967166900635,
      "learning_rate": 1.6084145862352226e-05,
      "loss": 0.0205,
      "step": 27410
    },
    {
      "epoch": 2.9379620700739313,
      "grad_norm": 0.10045962780714035,
      "learning_rate": 1.6082717239901426e-05,
      "loss": 0.0994,
      "step": 27420
    },
    {
      "epoch": 2.9390335369120324,
      "grad_norm": 0.007790144998580217,
      "learning_rate": 1.6081288617450625e-05,
      "loss": 0.0013,
      "step": 27430
    },
    {
      "epoch": 2.940105003750134,
      "grad_norm": 0.004943625070154667,
      "learning_rate": 1.607985999499982e-05,
      "loss": 0.2062,
      "step": 27440
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.2165777087211609,
      "learning_rate": 1.607843137254902e-05,
      "loss": 0.1645,
      "step": 27450
    },
    {
      "epoch": 2.9422479374263366,
      "grad_norm": 0.009947466664016247,
      "learning_rate": 1.607700275009822e-05,
      "loss": 0.001,
      "step": 27460
    },
    {
      "epoch": 2.943319404264438,
      "grad_norm": 0.007929534651339054,
      "learning_rate": 1.607557412764742e-05,
      "loss": 0.292,
      "step": 27470
    },
    {
      "epoch": 2.9443908711025393,
      "grad_norm": 0.01990877091884613,
      "learning_rate": 1.6074145505196615e-05,
      "loss": 0.0006,
      "step": 27480
    },
    {
      "epoch": 2.945462337940641,
      "grad_norm": 0.008721829392015934,
      "learning_rate": 1.6072716882745815e-05,
      "loss": 0.198,
      "step": 27490
    },
    {
      "epoch": 2.946533804778742,
      "grad_norm": 0.7335011959075928,
      "learning_rate": 1.6071288260295014e-05,
      "loss": 0.3849,
      "step": 27500
    },
    {
      "epoch": 2.9476052716168435,
      "grad_norm": 19.246994018554688,
      "learning_rate": 1.606985963784421e-05,
      "loss": 0.7563,
      "step": 27510
    },
    {
      "epoch": 2.948676738454945,
      "grad_norm": 0.1973871886730194,
      "learning_rate": 1.606843101539341e-05,
      "loss": 0.3129,
      "step": 27520
    },
    {
      "epoch": 2.949748205293046,
      "grad_norm": 0.016778994351625443,
      "learning_rate": 1.6067002392942605e-05,
      "loss": 0.1643,
      "step": 27530
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 16.474531173706055,
      "learning_rate": 1.6065573770491805e-05,
      "loss": 0.1814,
      "step": 27540
    },
    {
      "epoch": 2.951891138969249,
      "grad_norm": 17.421720504760742,
      "learning_rate": 1.6064145148041004e-05,
      "loss": 0.1894,
      "step": 27550
    },
    {
      "epoch": 2.9529626058073504,
      "grad_norm": 0.01778605952858925,
      "learning_rate": 1.60627165255902e-05,
      "loss": 0.1573,
      "step": 27560
    },
    {
      "epoch": 2.9540340726454515,
      "grad_norm": 0.005184774752706289,
      "learning_rate": 1.60612879031394e-05,
      "loss": 0.1528,
      "step": 27570
    },
    {
      "epoch": 2.955105539483553,
      "grad_norm": 0.1783522516489029,
      "learning_rate": 1.6059859280688595e-05,
      "loss": 0.1718,
      "step": 27580
    },
    {
      "epoch": 2.9561770063216546,
      "grad_norm": 0.16563037037849426,
      "learning_rate": 1.6058430658237795e-05,
      "loss": 0.2936,
      "step": 27590
    },
    {
      "epoch": 2.9572484731597557,
      "grad_norm": 2026.4498291015625,
      "learning_rate": 1.6057002035786994e-05,
      "loss": 0.685,
      "step": 27600
    },
    {
      "epoch": 2.958319939997857,
      "grad_norm": 0.16168668866157532,
      "learning_rate": 1.6055573413336193e-05,
      "loss": 0.0035,
      "step": 27610
    },
    {
      "epoch": 2.9593914068359584,
      "grad_norm": 0.2680676579475403,
      "learning_rate": 1.605414479088539e-05,
      "loss": 0.0015,
      "step": 27620
    },
    {
      "epoch": 2.96046287367406,
      "grad_norm": 0.0034778027329593897,
      "learning_rate": 1.605271616843459e-05,
      "loss": 0.0006,
      "step": 27630
    },
    {
      "epoch": 2.961534340512161,
      "grad_norm": 0.025632893666625023,
      "learning_rate": 1.6051287545983788e-05,
      "loss": 0.1774,
      "step": 27640
    },
    {
      "epoch": 2.9626058073502626,
      "grad_norm": 0.095326267182827,
      "learning_rate": 1.6049858923532984e-05,
      "loss": 0.2819,
      "step": 27650
    },
    {
      "epoch": 2.963677274188364,
      "grad_norm": 155.19602966308594,
      "learning_rate": 1.6048430301082183e-05,
      "loss": 0.3351,
      "step": 27660
    },
    {
      "epoch": 2.9647487410264652,
      "grad_norm": 0.3098599314689636,
      "learning_rate": 1.6047001678631383e-05,
      "loss": 0.1887,
      "step": 27670
    },
    {
      "epoch": 2.9658202078645663,
      "grad_norm": 0.10151011496782303,
      "learning_rate": 1.604557305618058e-05,
      "loss": 0.0017,
      "step": 27680
    },
    {
      "epoch": 2.966891674702668,
      "grad_norm": 0.010828103870153427,
      "learning_rate": 1.6044144433729778e-05,
      "loss": 0.4354,
      "step": 27690
    },
    {
      "epoch": 2.9679631415407695,
      "grad_norm": 0.014898761175572872,
      "learning_rate": 1.6042715811278974e-05,
      "loss": 0.0009,
      "step": 27700
    },
    {
      "epoch": 2.9690346083788706,
      "grad_norm": 0.07844993472099304,
      "learning_rate": 1.6041287188828173e-05,
      "loss": 0.1683,
      "step": 27710
    },
    {
      "epoch": 2.970106075216972,
      "grad_norm": 0.014451689086854458,
      "learning_rate": 1.603985856637737e-05,
      "loss": 0.4588,
      "step": 27720
    },
    {
      "epoch": 2.9711775420550737,
      "grad_norm": 32.85874938964844,
      "learning_rate": 1.603842994392657e-05,
      "loss": 0.4913,
      "step": 27730
    },
    {
      "epoch": 2.972249008893175,
      "grad_norm": 0.03368917107582092,
      "learning_rate": 1.6037001321475768e-05,
      "loss": 0.149,
      "step": 27740
    },
    {
      "epoch": 2.973320475731276,
      "grad_norm": 0.11796465516090393,
      "learning_rate": 1.6035572699024968e-05,
      "loss": 0.002,
      "step": 27750
    },
    {
      "epoch": 2.9743919425693774,
      "grad_norm": 0.09198502451181412,
      "learning_rate": 1.6034144076574164e-05,
      "loss": 0.0018,
      "step": 27760
    },
    {
      "epoch": 2.975463409407479,
      "grad_norm": 0.06527410447597504,
      "learning_rate": 1.6032715454123363e-05,
      "loss": 0.0054,
      "step": 27770
    },
    {
      "epoch": 2.97653487624558,
      "grad_norm": 0.15337906777858734,
      "learning_rate": 1.6031286831672562e-05,
      "loss": 0.0029,
      "step": 27780
    },
    {
      "epoch": 2.9776063430836817,
      "grad_norm": 0.05037602782249451,
      "learning_rate": 1.602985820922176e-05,
      "loss": 0.4718,
      "step": 27790
    },
    {
      "epoch": 2.9786778099217828,
      "grad_norm": 0.24025730788707733,
      "learning_rate": 1.6028429586770958e-05,
      "loss": 0.0028,
      "step": 27800
    },
    {
      "epoch": 2.9797492767598843,
      "grad_norm": 0.07032516598701477,
      "learning_rate": 1.6027000964320157e-05,
      "loss": 0.1621,
      "step": 27810
    },
    {
      "epoch": 2.9808207435979854,
      "grad_norm": 0.25043657422065735,
      "learning_rate": 1.6025572341869353e-05,
      "loss": 0.3392,
      "step": 27820
    },
    {
      "epoch": 2.981892210436087,
      "grad_norm": 0.20304204523563385,
      "learning_rate": 1.6024143719418552e-05,
      "loss": 0.0012,
      "step": 27830
    },
    {
      "epoch": 2.9829636772741885,
      "grad_norm": 0.010802372358739376,
      "learning_rate": 1.602271509696775e-05,
      "loss": 0.1469,
      "step": 27840
    },
    {
      "epoch": 2.9840351441122897,
      "grad_norm": 0.04739875718951225,
      "learning_rate": 1.6021286474516948e-05,
      "loss": 0.1934,
      "step": 27850
    },
    {
      "epoch": 2.985106610950391,
      "grad_norm": 542.6206665039062,
      "learning_rate": 1.6019857852066147e-05,
      "loss": 0.1046,
      "step": 27860
    },
    {
      "epoch": 2.9861780777884923,
      "grad_norm": 0.14823944866657257,
      "learning_rate": 1.6018429229615343e-05,
      "loss": 0.4863,
      "step": 27870
    },
    {
      "epoch": 2.987249544626594,
      "grad_norm": 0.4033922553062439,
      "learning_rate": 1.6017000607164542e-05,
      "loss": 0.19,
      "step": 27880
    },
    {
      "epoch": 2.988321011464695,
      "grad_norm": 0.11415121704339981,
      "learning_rate": 1.6015571984713742e-05,
      "loss": 0.1758,
      "step": 27890
    },
    {
      "epoch": 2.9893924783027965,
      "grad_norm": 0.045198846608400345,
      "learning_rate": 1.6014143362262938e-05,
      "loss": 0.0019,
      "step": 27900
    },
    {
      "epoch": 2.990463945140898,
      "grad_norm": 0.013563594780862331,
      "learning_rate": 1.6012714739812137e-05,
      "loss": 0.156,
      "step": 27910
    },
    {
      "epoch": 2.991535411978999,
      "grad_norm": 0.04025997966527939,
      "learning_rate": 1.6011286117361336e-05,
      "loss": 0.126,
      "step": 27920
    },
    {
      "epoch": 2.9926068788171007,
      "grad_norm": 0.04403868690133095,
      "learning_rate": 1.6009857494910536e-05,
      "loss": 0.0007,
      "step": 27930
    },
    {
      "epoch": 2.993678345655202,
      "grad_norm": 0.09722267836332321,
      "learning_rate": 1.6008428872459732e-05,
      "loss": 0.2149,
      "step": 27940
    },
    {
      "epoch": 2.9947498124933034,
      "grad_norm": 0.45385977625846863,
      "learning_rate": 1.600700025000893e-05,
      "loss": 0.2074,
      "step": 27950
    },
    {
      "epoch": 2.9958212793314045,
      "grad_norm": 0.04168698191642761,
      "learning_rate": 1.6005571627558127e-05,
      "loss": 0.2172,
      "step": 27960
    },
    {
      "epoch": 2.996892746169506,
      "grad_norm": 0.01058865338563919,
      "learning_rate": 1.6004143005107327e-05,
      "loss": 0.0006,
      "step": 27970
    },
    {
      "epoch": 2.9979642130076076,
      "grad_norm": 0.03238259628415108,
      "learning_rate": 1.6002714382656526e-05,
      "loss": 0.0005,
      "step": 27980
    },
    {
      "epoch": 2.9990356798457087,
      "grad_norm": 0.008300838991999626,
      "learning_rate": 1.6001285760205722e-05,
      "loss": 0.1546,
      "step": 27990
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.948,
      "eval_f1": 0.8052434456928839,
      "eval_loss": 0.28015193343162537,
      "eval_precision": 0.7633136094674556,
      "eval_recall": 0.8520475561426685,
      "eval_runtime": 386.4106,
      "eval_samples_per_second": 15.528,
      "eval_steps_per_second": 5.176,
      "step": 27999
    },
    {
      "epoch": 3.0001071466838103,
      "grad_norm": 0.005316916853189468,
      "learning_rate": 1.599985713775492e-05,
      "loss": 0.1785,
      "step": 28000
    },
    {
      "epoch": 3.0011786135219114,
      "grad_norm": 18.830535888671875,
      "learning_rate": 1.5998428515304117e-05,
      "loss": 0.3953,
      "step": 28010
    },
    {
      "epoch": 3.002250080360013,
      "grad_norm": 0.06093381345272064,
      "learning_rate": 1.5996999892853317e-05,
      "loss": 0.1713,
      "step": 28020
    },
    {
      "epoch": 3.003321547198114,
      "grad_norm": 0.0887313261628151,
      "learning_rate": 1.5995571270402516e-05,
      "loss": 0.0008,
      "step": 28030
    },
    {
      "epoch": 3.0043930140362156,
      "grad_norm": 0.11874096840620041,
      "learning_rate": 1.5994142647951715e-05,
      "loss": 0.0007,
      "step": 28040
    },
    {
      "epoch": 3.0054644808743167,
      "grad_norm": 0.0031826873309910297,
      "learning_rate": 1.599271402550091e-05,
      "loss": 0.0015,
      "step": 28050
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 0.001651850063353777,
      "learning_rate": 1.599128540305011e-05,
      "loss": 0.0005,
      "step": 28060
    },
    {
      "epoch": 3.00760741455052,
      "grad_norm": 0.035330262035131454,
      "learning_rate": 1.598985678059931e-05,
      "loss": 0.0005,
      "step": 28070
    },
    {
      "epoch": 3.008678881388621,
      "grad_norm": 0.06159554421901703,
      "learning_rate": 1.5988428158148506e-05,
      "loss": 0.1125,
      "step": 28080
    },
    {
      "epoch": 3.0097503482267225,
      "grad_norm": 38.13486862182617,
      "learning_rate": 1.5986999535697705e-05,
      "loss": 0.2357,
      "step": 28090
    },
    {
      "epoch": 3.0108218150648236,
      "grad_norm": 0.006982428953051567,
      "learning_rate": 1.5985570913246905e-05,
      "loss": 0.0002,
      "step": 28100
    },
    {
      "epoch": 3.011893281902925,
      "grad_norm": 0.0033519722055643797,
      "learning_rate": 1.59841422907961e-05,
      "loss": 0.1938,
      "step": 28110
    },
    {
      "epoch": 3.0129647487410263,
      "grad_norm": 0.0024639207404106855,
      "learning_rate": 1.59827136683453e-05,
      "loss": 0.001,
      "step": 28120
    },
    {
      "epoch": 3.014036215579128,
      "grad_norm": 0.0008413128671236336,
      "learning_rate": 1.5981285045894496e-05,
      "loss": 0.0005,
      "step": 28130
    },
    {
      "epoch": 3.0151076824172294,
      "grad_norm": 0.0008699297904968262,
      "learning_rate": 1.5979856423443695e-05,
      "loss": 0.0011,
      "step": 28140
    },
    {
      "epoch": 3.0161791492553305,
      "grad_norm": 0.015908291563391685,
      "learning_rate": 1.597842780099289e-05,
      "loss": 0.1597,
      "step": 28150
    },
    {
      "epoch": 3.017250616093432,
      "grad_norm": 0.39705324172973633,
      "learning_rate": 1.597699917854209e-05,
      "loss": 0.395,
      "step": 28160
    },
    {
      "epoch": 3.018322082931533,
      "grad_norm": 0.04284081608057022,
      "learning_rate": 1.597557055609129e-05,
      "loss": 0.0006,
      "step": 28170
    },
    {
      "epoch": 3.0193935497696347,
      "grad_norm": 0.006612828932702541,
      "learning_rate": 1.597414193364049e-05,
      "loss": 0.0412,
      "step": 28180
    },
    {
      "epoch": 3.020465016607736,
      "grad_norm": 25.027446746826172,
      "learning_rate": 1.5972713311189685e-05,
      "loss": 0.1583,
      "step": 28190
    },
    {
      "epoch": 3.0215364834458374,
      "grad_norm": 0.0012696649646386504,
      "learning_rate": 1.5971284688738885e-05,
      "loss": 0.0011,
      "step": 28200
    },
    {
      "epoch": 3.022607950283939,
      "grad_norm": 0.0015622630016878247,
      "learning_rate": 1.5969856066288084e-05,
      "loss": 0.1545,
      "step": 28210
    },
    {
      "epoch": 3.02367941712204,
      "grad_norm": 0.0007426550146192312,
      "learning_rate": 1.5968427443837284e-05,
      "loss": 0.0004,
      "step": 28220
    },
    {
      "epoch": 3.0247508839601416,
      "grad_norm": 0.0010698571568354964,
      "learning_rate": 1.596699882138648e-05,
      "loss": 0.6847,
      "step": 28230
    },
    {
      "epoch": 3.0258223507982427,
      "grad_norm": 0.0013789947843179107,
      "learning_rate": 1.596557019893568e-05,
      "loss": 0.001,
      "step": 28240
    },
    {
      "epoch": 3.0268938176363442,
      "grad_norm": 18.49938201904297,
      "learning_rate": 1.5964141576484875e-05,
      "loss": 0.3299,
      "step": 28250
    },
    {
      "epoch": 3.0279652844744454,
      "grad_norm": 0.11320102214813232,
      "learning_rate": 1.5962712954034074e-05,
      "loss": 0.3977,
      "step": 28260
    },
    {
      "epoch": 3.029036751312547,
      "grad_norm": 0.04785027727484703,
      "learning_rate": 1.596128433158327e-05,
      "loss": 0.167,
      "step": 28270
    },
    {
      "epoch": 3.030108218150648,
      "grad_norm": 0.04184180498123169,
      "learning_rate": 1.595985570913247e-05,
      "loss": 0.204,
      "step": 28280
    },
    {
      "epoch": 3.0311796849887496,
      "grad_norm": 0.061757683753967285,
      "learning_rate": 1.595842708668167e-05,
      "loss": 0.0011,
      "step": 28290
    },
    {
      "epoch": 3.032251151826851,
      "grad_norm": 0.06040246784687042,
      "learning_rate": 1.5956998464230865e-05,
      "loss": 0.1511,
      "step": 28300
    },
    {
      "epoch": 3.0333226186649522,
      "grad_norm": 0.06477484852075577,
      "learning_rate": 1.5955569841780064e-05,
      "loss": 0.3237,
      "step": 28310
    },
    {
      "epoch": 3.034394085503054,
      "grad_norm": 0.28632140159606934,
      "learning_rate": 1.5954141219329264e-05,
      "loss": 0.1514,
      "step": 28320
    },
    {
      "epoch": 3.035465552341155,
      "grad_norm": 0.003428986994549632,
      "learning_rate": 1.595271259687846e-05,
      "loss": 0.1525,
      "step": 28330
    },
    {
      "epoch": 3.0365370191792564,
      "grad_norm": 0.017384588718414307,
      "learning_rate": 1.595128397442766e-05,
      "loss": 0.0015,
      "step": 28340
    },
    {
      "epoch": 3.0376084860173576,
      "grad_norm": 0.0024778314400464296,
      "learning_rate": 1.594985535197686e-05,
      "loss": 0.1714,
      "step": 28350
    },
    {
      "epoch": 3.038679952855459,
      "grad_norm": 0.06516490876674652,
      "learning_rate": 1.5948426729526058e-05,
      "loss": 0.735,
      "step": 28360
    },
    {
      "epoch": 3.0397514196935607,
      "grad_norm": 0.004549133591353893,
      "learning_rate": 1.5946998107075254e-05,
      "loss": 0.3147,
      "step": 28370
    },
    {
      "epoch": 3.0408228865316618,
      "grad_norm": 0.05408657342195511,
      "learning_rate": 1.5945569484624453e-05,
      "loss": 0.1612,
      "step": 28380
    },
    {
      "epoch": 3.0418943533697633,
      "grad_norm": 0.01359599456191063,
      "learning_rate": 1.594414086217365e-05,
      "loss": 0.0024,
      "step": 28390
    },
    {
      "epoch": 3.0429658202078644,
      "grad_norm": 0.0039041079580783844,
      "learning_rate": 1.594271223972285e-05,
      "loss": 0.0012,
      "step": 28400
    },
    {
      "epoch": 3.044037287045966,
      "grad_norm": 0.018815902993083,
      "learning_rate": 1.5941283617272048e-05,
      "loss": 0.3691,
      "step": 28410
    },
    {
      "epoch": 3.045108753884067,
      "grad_norm": 0.03583187237381935,
      "learning_rate": 1.5939854994821244e-05,
      "loss": 0.0025,
      "step": 28420
    },
    {
      "epoch": 3.0461802207221687,
      "grad_norm": 0.0026289860252290964,
      "learning_rate": 1.5938426372370443e-05,
      "loss": 0.524,
      "step": 28430
    },
    {
      "epoch": 3.04725168756027,
      "grad_norm": 0.029308870434761047,
      "learning_rate": 1.593699774991964e-05,
      "loss": 0.1694,
      "step": 28440
    },
    {
      "epoch": 3.0483231543983713,
      "grad_norm": 0.009007210843265057,
      "learning_rate": 1.593556912746884e-05,
      "loss": 0.0008,
      "step": 28450
    },
    {
      "epoch": 3.049394621236473,
      "grad_norm": 0.0028396258130669594,
      "learning_rate": 1.5934140505018038e-05,
      "loss": 0.0023,
      "step": 28460
    },
    {
      "epoch": 3.050466088074574,
      "grad_norm": 0.02726660668849945,
      "learning_rate": 1.5932711882567234e-05,
      "loss": 0.3057,
      "step": 28470
    },
    {
      "epoch": 3.0515375549126755,
      "grad_norm": 0.06935258209705353,
      "learning_rate": 1.5931283260116433e-05,
      "loss": 0.0004,
      "step": 28480
    },
    {
      "epoch": 3.0526090217507766,
      "grad_norm": 0.11483518779277802,
      "learning_rate": 1.5929854637665633e-05,
      "loss": 0.0007,
      "step": 28490
    },
    {
      "epoch": 3.053680488588878,
      "grad_norm": 0.05629223212599754,
      "learning_rate": 1.5928426015214832e-05,
      "loss": 0.0004,
      "step": 28500
    },
    {
      "epoch": 3.0547519554269797,
      "grad_norm": 0.033926524221897125,
      "learning_rate": 1.5926997392764028e-05,
      "loss": 0.179,
      "step": 28510
    },
    {
      "epoch": 3.055823422265081,
      "grad_norm": 0.0012696613557636738,
      "learning_rate": 1.5925568770313227e-05,
      "loss": 0.0005,
      "step": 28520
    },
    {
      "epoch": 3.0568948891031824,
      "grad_norm": 0.0005180570879019797,
      "learning_rate": 1.5924140147862427e-05,
      "loss": 0.0012,
      "step": 28530
    },
    {
      "epoch": 3.0579663559412835,
      "grad_norm": 0.007408112287521362,
      "learning_rate": 1.5922711525411623e-05,
      "loss": 0.2233,
      "step": 28540
    },
    {
      "epoch": 3.059037822779385,
      "grad_norm": 2.931809425354004,
      "learning_rate": 1.5921282902960822e-05,
      "loss": 0.0018,
      "step": 28550
    },
    {
      "epoch": 3.060109289617486,
      "grad_norm": 0.021123705431818962,
      "learning_rate": 1.5919854280510018e-05,
      "loss": 0.1755,
      "step": 28560
    },
    {
      "epoch": 3.0611807564555877,
      "grad_norm": 0.07779350876808167,
      "learning_rate": 1.5918425658059217e-05,
      "loss": 0.1486,
      "step": 28570
    },
    {
      "epoch": 3.062252223293689,
      "grad_norm": 0.044688403606414795,
      "learning_rate": 1.5916997035608417e-05,
      "loss": 0.3231,
      "step": 28580
    },
    {
      "epoch": 3.0633236901317904,
      "grad_norm": 0.04952918738126755,
      "learning_rate": 1.5915568413157613e-05,
      "loss": 0.0006,
      "step": 28590
    },
    {
      "epoch": 3.064395156969892,
      "grad_norm": 22.67866325378418,
      "learning_rate": 1.5914139790706812e-05,
      "loss": 0.1556,
      "step": 28600
    },
    {
      "epoch": 3.065466623807993,
      "grad_norm": 18.737945556640625,
      "learning_rate": 1.591271116825601e-05,
      "loss": 0.1198,
      "step": 28610
    },
    {
      "epoch": 3.0665380906460946,
      "grad_norm": 0.005007155705243349,
      "learning_rate": 1.5911282545805207e-05,
      "loss": 0.0014,
      "step": 28620
    },
    {
      "epoch": 3.0676095574841957,
      "grad_norm": 0.02489967830479145,
      "learning_rate": 1.5909853923354407e-05,
      "loss": 0.2027,
      "step": 28630
    },
    {
      "epoch": 3.0686810243222973,
      "grad_norm": 0.002166104270145297,
      "learning_rate": 1.5908425300903606e-05,
      "loss": 0.0008,
      "step": 28640
    },
    {
      "epoch": 3.0697524911603984,
      "grad_norm": 0.05617543309926987,
      "learning_rate": 1.5906996678452806e-05,
      "loss": 0.151,
      "step": 28650
    },
    {
      "epoch": 3.0708239579985,
      "grad_norm": 0.7207096219062805,
      "learning_rate": 1.5905568056002e-05,
      "loss": 0.0038,
      "step": 28660
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 17.816665649414062,
      "learning_rate": 1.59041394335512e-05,
      "loss": 0.1499,
      "step": 28670
    },
    {
      "epoch": 3.0729668916747026,
      "grad_norm": 0.013755427673459053,
      "learning_rate": 1.5902710811100397e-05,
      "loss": 0.3638,
      "step": 28680
    },
    {
      "epoch": 3.074038358512804,
      "grad_norm": 0.0006773790810257196,
      "learning_rate": 1.5901282188649596e-05,
      "loss": 0.0005,
      "step": 28690
    },
    {
      "epoch": 3.0751098253509053,
      "grad_norm": 0.029944509267807007,
      "learning_rate": 1.5899853566198796e-05,
      "loss": 0.0003,
      "step": 28700
    },
    {
      "epoch": 3.076181292189007,
      "grad_norm": 0.0006949171656742692,
      "learning_rate": 1.589842494374799e-05,
      "loss": 0.1152,
      "step": 28710
    },
    {
      "epoch": 3.077252759027108,
      "grad_norm": 0.0002901141415350139,
      "learning_rate": 1.589699632129719e-05,
      "loss": 0.0019,
      "step": 28720
    },
    {
      "epoch": 3.0783242258652095,
      "grad_norm": 84.07369232177734,
      "learning_rate": 1.5895567698846387e-05,
      "loss": 0.4849,
      "step": 28730
    },
    {
      "epoch": 3.079395692703311,
      "grad_norm": 0.003633843269199133,
      "learning_rate": 1.5894139076395586e-05,
      "loss": 0.156,
      "step": 28740
    },
    {
      "epoch": 3.080467159541412,
      "grad_norm": 16.023988723754883,
      "learning_rate": 1.5892710453944786e-05,
      "loss": 0.415,
      "step": 28750
    },
    {
      "epoch": 3.0815386263795137,
      "grad_norm": 0.0675852969288826,
      "learning_rate": 1.589128183149398e-05,
      "loss": 0.147,
      "step": 28760
    },
    {
      "epoch": 3.082610093217615,
      "grad_norm": 20.046262741088867,
      "learning_rate": 1.588985320904318e-05,
      "loss": 0.4464,
      "step": 28770
    },
    {
      "epoch": 3.0836815600557164,
      "grad_norm": 0.016272390261292458,
      "learning_rate": 1.588842458659238e-05,
      "loss": 0.2178,
      "step": 28780
    },
    {
      "epoch": 3.0847530268938175,
      "grad_norm": 0.5508983731269836,
      "learning_rate": 1.588699596414158e-05,
      "loss": 0.1836,
      "step": 28790
    },
    {
      "epoch": 3.085824493731919,
      "grad_norm": 0.03514943644404411,
      "learning_rate": 1.5885567341690776e-05,
      "loss": 0.0012,
      "step": 28800
    },
    {
      "epoch": 3.08689596057002,
      "grad_norm": 0.3181881010532379,
      "learning_rate": 1.5884138719239975e-05,
      "loss": 0.3597,
      "step": 28810
    },
    {
      "epoch": 3.0879674274081217,
      "grad_norm": 0.9727786183357239,
      "learning_rate": 1.5882710096789174e-05,
      "loss": 0.0015,
      "step": 28820
    },
    {
      "epoch": 3.0890388942462232,
      "grad_norm": 0.021456850692629814,
      "learning_rate": 1.588128147433837e-05,
      "loss": 0.2324,
      "step": 28830
    },
    {
      "epoch": 3.0901103610843244,
      "grad_norm": 0.01950749196112156,
      "learning_rate": 1.587985285188757e-05,
      "loss": 0.339,
      "step": 28840
    },
    {
      "epoch": 3.091181827922426,
      "grad_norm": 0.036427609622478485,
      "learning_rate": 1.5878424229436766e-05,
      "loss": 0.1569,
      "step": 28850
    },
    {
      "epoch": 3.092253294760527,
      "grad_norm": 0.0012743433471769094,
      "learning_rate": 1.5876995606985965e-05,
      "loss": 0.0021,
      "step": 28860
    },
    {
      "epoch": 3.0933247615986286,
      "grad_norm": 0.07038859277963638,
      "learning_rate": 1.587556698453516e-05,
      "loss": 0.3506,
      "step": 28870
    },
    {
      "epoch": 3.0943962284367297,
      "grad_norm": 0.002113383961841464,
      "learning_rate": 1.587413836208436e-05,
      "loss": 0.1351,
      "step": 28880
    },
    {
      "epoch": 3.0954676952748312,
      "grad_norm": 0.10213939100503922,
      "learning_rate": 1.587270973963356e-05,
      "loss": 0.2169,
      "step": 28890
    },
    {
      "epoch": 3.096539162112933,
      "grad_norm": 0.09663475304841995,
      "learning_rate": 1.5871281117182756e-05,
      "loss": 0.5022,
      "step": 28900
    },
    {
      "epoch": 3.097610628951034,
      "grad_norm": 0.013766404241323471,
      "learning_rate": 1.5869852494731955e-05,
      "loss": 0.1276,
      "step": 28910
    },
    {
      "epoch": 3.0986820957891354,
      "grad_norm": 0.4171468913555145,
      "learning_rate": 1.5868423872281155e-05,
      "loss": 0.102,
      "step": 28920
    },
    {
      "epoch": 3.0997535626272366,
      "grad_norm": 0.019377976655960083,
      "learning_rate": 1.5866995249830354e-05,
      "loss": 0.0024,
      "step": 28930
    },
    {
      "epoch": 3.100825029465338,
      "grad_norm": 0.0013605172280222178,
      "learning_rate": 1.5865566627379553e-05,
      "loss": 0.1333,
      "step": 28940
    },
    {
      "epoch": 3.101896496303439,
      "grad_norm": 0.004326910711824894,
      "learning_rate": 1.586413800492875e-05,
      "loss": 0.2176,
      "step": 28950
    },
    {
      "epoch": 3.1029679631415408,
      "grad_norm": 0.0006358679966069758,
      "learning_rate": 1.586270938247795e-05,
      "loss": 0.0911,
      "step": 28960
    },
    {
      "epoch": 3.1040394299796423,
      "grad_norm": 0.10842851549386978,
      "learning_rate": 1.5861280760027145e-05,
      "loss": 0.1315,
      "step": 28970
    },
    {
      "epoch": 3.1051108968177434,
      "grad_norm": 0.002334290649741888,
      "learning_rate": 1.5859852137576344e-05,
      "loss": 0.1461,
      "step": 28980
    },
    {
      "epoch": 3.106182363655845,
      "grad_norm": 0.027452930808067322,
      "learning_rate": 1.585842351512554e-05,
      "loss": 0.0236,
      "step": 28990
    },
    {
      "epoch": 3.107253830493946,
      "grad_norm": 0.0004834640712942928,
      "learning_rate": 1.585699489267474e-05,
      "loss": 0.1272,
      "step": 29000
    },
    {
      "epoch": 3.1083252973320477,
      "grad_norm": 0.036460038274526596,
      "learning_rate": 1.585556627022394e-05,
      "loss": 0.4547,
      "step": 29010
    },
    {
      "epoch": 3.1093967641701488,
      "grad_norm": 0.07835642993450165,
      "learning_rate": 1.5854137647773135e-05,
      "loss": 0.0002,
      "step": 29020
    },
    {
      "epoch": 3.1104682310082503,
      "grad_norm": 0.07508894801139832,
      "learning_rate": 1.5852709025322334e-05,
      "loss": 0.0002,
      "step": 29030
    },
    {
      "epoch": 3.111539697846352,
      "grad_norm": 0.0001810664834920317,
      "learning_rate": 1.585128040287153e-05,
      "loss": 0.0017,
      "step": 29040
    },
    {
      "epoch": 3.112611164684453,
      "grad_norm": 0.09055545181035995,
      "learning_rate": 1.584985178042073e-05,
      "loss": 0.0008,
      "step": 29050
    },
    {
      "epoch": 3.1136826315225545,
      "grad_norm": 0.0004709317290689796,
      "learning_rate": 1.584842315796993e-05,
      "loss": 0.0002,
      "step": 29060
    },
    {
      "epoch": 3.1147540983606556,
      "grad_norm": 0.00025104222004301846,
      "learning_rate": 1.5846994535519128e-05,
      "loss": 0.0005,
      "step": 29070
    },
    {
      "epoch": 3.115825565198757,
      "grad_norm": 0.0005527338362298906,
      "learning_rate": 1.5845565913068327e-05,
      "loss": 0.1956,
      "step": 29080
    },
    {
      "epoch": 3.1168970320368583,
      "grad_norm": 0.0003787779132835567,
      "learning_rate": 1.5844137290617523e-05,
      "loss": 0.3657,
      "step": 29090
    },
    {
      "epoch": 3.11796849887496,
      "grad_norm": 0.08258577436208725,
      "learning_rate": 1.5842708668166723e-05,
      "loss": 0.3719,
      "step": 29100
    },
    {
      "epoch": 3.119039965713061,
      "grad_norm": 0.5351234674453735,
      "learning_rate": 1.584128004571592e-05,
      "loss": 0.0031,
      "step": 29110
    },
    {
      "epoch": 3.1201114325511625,
      "grad_norm": 0.0016095214523375034,
      "learning_rate": 1.5839851423265118e-05,
      "loss": 0.0016,
      "step": 29120
    },
    {
      "epoch": 3.121182899389264,
      "grad_norm": 0.019651880487799644,
      "learning_rate": 1.5838422800814318e-05,
      "loss": 0.1494,
      "step": 29130
    },
    {
      "epoch": 3.122254366227365,
      "grad_norm": 0.005015982780605555,
      "learning_rate": 1.5836994178363514e-05,
      "loss": 0.0008,
      "step": 29140
    },
    {
      "epoch": 3.1233258330654667,
      "grad_norm": 0.0007858322933316231,
      "learning_rate": 1.5835565555912713e-05,
      "loss": 0.3463,
      "step": 29150
    },
    {
      "epoch": 3.124397299903568,
      "grad_norm": 0.001215502037666738,
      "learning_rate": 1.583413693346191e-05,
      "loss": 0.1047,
      "step": 29160
    },
    {
      "epoch": 3.1254687667416694,
      "grad_norm": 0.0006860356661491096,
      "learning_rate": 1.5832708311011108e-05,
      "loss": 0.0001,
      "step": 29170
    },
    {
      "epoch": 3.1265402335797705,
      "grad_norm": 0.003867753781378269,
      "learning_rate": 1.5831279688560308e-05,
      "loss": 0.0013,
      "step": 29180
    },
    {
      "epoch": 3.127611700417872,
      "grad_norm": 0.02690567821264267,
      "learning_rate": 1.5829851066109504e-05,
      "loss": 0.2123,
      "step": 29190
    },
    {
      "epoch": 3.1286831672559736,
      "grad_norm": 0.018483135849237442,
      "learning_rate": 1.5828422443658703e-05,
      "loss": 0.1433,
      "step": 29200
    },
    {
      "epoch": 3.1297546340940747,
      "grad_norm": 0.0008586202748119831,
      "learning_rate": 1.5826993821207902e-05,
      "loss": 0.1049,
      "step": 29210
    },
    {
      "epoch": 3.1308261009321763,
      "grad_norm": 0.08892624080181122,
      "learning_rate": 1.58255651987571e-05,
      "loss": 0.0005,
      "step": 29220
    },
    {
      "epoch": 3.1318975677702774,
      "grad_norm": 18.42363929748535,
      "learning_rate": 1.5824136576306298e-05,
      "loss": 0.1842,
      "step": 29230
    },
    {
      "epoch": 3.132969034608379,
      "grad_norm": 0.016346966847777367,
      "learning_rate": 1.5822707953855497e-05,
      "loss": 0.1768,
      "step": 29240
    },
    {
      "epoch": 3.13404050144648,
      "grad_norm": 0.7628588080406189,
      "learning_rate": 1.5821279331404696e-05,
      "loss": 0.2726,
      "step": 29250
    },
    {
      "epoch": 3.1351119682845816,
      "grad_norm": 20.689924240112305,
      "learning_rate": 1.5819850708953892e-05,
      "loss": 0.4277,
      "step": 29260
    },
    {
      "epoch": 3.136183435122683,
      "grad_norm": 0.029609106481075287,
      "learning_rate": 1.5818422086503092e-05,
      "loss": 0.0029,
      "step": 29270
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 0.0018918149871751666,
      "learning_rate": 1.5816993464052288e-05,
      "loss": 0.001,
      "step": 29280
    },
    {
      "epoch": 3.138326368798886,
      "grad_norm": 2.3600409030914307,
      "learning_rate": 1.5815564841601487e-05,
      "loss": 0.0009,
      "step": 29290
    },
    {
      "epoch": 3.139397835636987,
      "grad_norm": 0.018423935398459435,
      "learning_rate": 1.5814136219150683e-05,
      "loss": 0.3392,
      "step": 29300
    },
    {
      "epoch": 3.1404693024750885,
      "grad_norm": 0.024719201028347015,
      "learning_rate": 1.5812707596699882e-05,
      "loss": 0.0963,
      "step": 29310
    },
    {
      "epoch": 3.1415407693131896,
      "grad_norm": 0.05059512332081795,
      "learning_rate": 1.5811278974249082e-05,
      "loss": 0.0033,
      "step": 29320
    },
    {
      "epoch": 3.142612236151291,
      "grad_norm": 0.00042828460573218763,
      "learning_rate": 1.5809850351798278e-05,
      "loss": 0.2157,
      "step": 29330
    },
    {
      "epoch": 3.1436837029893923,
      "grad_norm": 0.0003848682390525937,
      "learning_rate": 1.5808421729347477e-05,
      "loss": 0.2918,
      "step": 29340
    },
    {
      "epoch": 3.144755169827494,
      "grad_norm": 0.0009448403143323958,
      "learning_rate": 1.5806993106896676e-05,
      "loss": 0.0004,
      "step": 29350
    },
    {
      "epoch": 3.1458266366655954,
      "grad_norm": 0.0682222843170166,
      "learning_rate": 1.5805564484445876e-05,
      "loss": 0.0004,
      "step": 29360
    },
    {
      "epoch": 3.1468981035036965,
      "grad_norm": 0.0076423585414886475,
      "learning_rate": 1.5804135861995075e-05,
      "loss": 0.499,
      "step": 29370
    },
    {
      "epoch": 3.147969570341798,
      "grad_norm": 0.01300206407904625,
      "learning_rate": 1.580270723954427e-05,
      "loss": 0.1993,
      "step": 29380
    },
    {
      "epoch": 3.149041037179899,
      "grad_norm": 0.18956413865089417,
      "learning_rate": 1.580127861709347e-05,
      "loss": 0.4802,
      "step": 29390
    },
    {
      "epoch": 3.1501125040180007,
      "grad_norm": 0.04167667776346207,
      "learning_rate": 1.5799849994642667e-05,
      "loss": 0.4893,
      "step": 29400
    },
    {
      "epoch": 3.151183970856102,
      "grad_norm": 0.30625593662261963,
      "learning_rate": 1.5798421372191866e-05,
      "loss": 0.1242,
      "step": 29410
    },
    {
      "epoch": 3.1522554376942034,
      "grad_norm": 0.041759882122278214,
      "learning_rate": 1.5796992749741062e-05,
      "loss": 0.1291,
      "step": 29420
    },
    {
      "epoch": 3.153326904532305,
      "grad_norm": 0.020015988498926163,
      "learning_rate": 1.579556412729026e-05,
      "loss": 0.0018,
      "step": 29430
    },
    {
      "epoch": 3.154398371370406,
      "grad_norm": 0.06899356842041016,
      "learning_rate": 1.579413550483946e-05,
      "loss": 0.1927,
      "step": 29440
    },
    {
      "epoch": 3.1554698382085076,
      "grad_norm": 15.950697898864746,
      "learning_rate": 1.5792706882388657e-05,
      "loss": 0.4619,
      "step": 29450
    },
    {
      "epoch": 3.1565413050466087,
      "grad_norm": 0.014573445543646812,
      "learning_rate": 1.5791278259937856e-05,
      "loss": 0.3683,
      "step": 29460
    },
    {
      "epoch": 3.1576127718847102,
      "grad_norm": 0.015481898561120033,
      "learning_rate": 1.5789849637487052e-05,
      "loss": 0.1022,
      "step": 29470
    },
    {
      "epoch": 3.1586842387228113,
      "grad_norm": 0.014807779341936111,
      "learning_rate": 1.578842101503625e-05,
      "loss": 0.1058,
      "step": 29480
    },
    {
      "epoch": 3.159755705560913,
      "grad_norm": 19.638763427734375,
      "learning_rate": 1.578699239258545e-05,
      "loss": 0.373,
      "step": 29490
    },
    {
      "epoch": 3.1608271723990145,
      "grad_norm": 0.369899719953537,
      "learning_rate": 1.578556377013465e-05,
      "loss": 0.0012,
      "step": 29500
    },
    {
      "epoch": 3.1618986392371156,
      "grad_norm": 0.001418690080754459,
      "learning_rate": 1.578413514768385e-05,
      "loss": 0.0009,
      "step": 29510
    },
    {
      "epoch": 3.162970106075217,
      "grad_norm": 0.032067906111478806,
      "learning_rate": 1.5782706525233045e-05,
      "loss": 0.5598,
      "step": 29520
    },
    {
      "epoch": 3.1640415729133182,
      "grad_norm": 0.00627900380641222,
      "learning_rate": 1.5781277902782245e-05,
      "loss": 0.1577,
      "step": 29530
    },
    {
      "epoch": 3.1651130397514198,
      "grad_norm": 0.012254063040018082,
      "learning_rate": 1.577984928033144e-05,
      "loss": 0.0006,
      "step": 29540
    },
    {
      "epoch": 3.166184506589521,
      "grad_norm": 0.19007058441638947,
      "learning_rate": 1.577842065788064e-05,
      "loss": 0.7408,
      "step": 29550
    },
    {
      "epoch": 3.1672559734276224,
      "grad_norm": 61.54850387573242,
      "learning_rate": 1.577699203542984e-05,
      "loss": 0.7243,
      "step": 29560
    },
    {
      "epoch": 3.168327440265724,
      "grad_norm": 0.07097598165273666,
      "learning_rate": 1.5775563412979035e-05,
      "loss": 0.1067,
      "step": 29570
    },
    {
      "epoch": 3.169398907103825,
      "grad_norm": 0.2219385802745819,
      "learning_rate": 1.5774134790528235e-05,
      "loss": 0.0025,
      "step": 29580
    },
    {
      "epoch": 3.1704703739419267,
      "grad_norm": 0.004979393910616636,
      "learning_rate": 1.577270616807743e-05,
      "loss": 0.1399,
      "step": 29590
    },
    {
      "epoch": 3.1715418407800278,
      "grad_norm": 0.4522293508052826,
      "learning_rate": 1.577127754562663e-05,
      "loss": 0.0985,
      "step": 29600
    },
    {
      "epoch": 3.1726133076181293,
      "grad_norm": 0.009426907636225224,
      "learning_rate": 1.576984892317583e-05,
      "loss": 0.0011,
      "step": 29610
    },
    {
      "epoch": 3.1736847744562304,
      "grad_norm": 0.016168536618351936,
      "learning_rate": 1.5768420300725026e-05,
      "loss": 0.2336,
      "step": 29620
    },
    {
      "epoch": 3.174756241294332,
      "grad_norm": 0.01582314632833004,
      "learning_rate": 1.5766991678274225e-05,
      "loss": 0.0022,
      "step": 29630
    },
    {
      "epoch": 3.1758277081324335,
      "grad_norm": 0.0216279998421669,
      "learning_rate": 1.5765563055823424e-05,
      "loss": 0.3996,
      "step": 29640
    },
    {
      "epoch": 3.1768991749705346,
      "grad_norm": 0.08173856884241104,
      "learning_rate": 1.5764134433372624e-05,
      "loss": 0.0013,
      "step": 29650
    },
    {
      "epoch": 3.177970641808636,
      "grad_norm": 0.030326735228300095,
      "learning_rate": 1.576270581092182e-05,
      "loss": 0.0009,
      "step": 29660
    },
    {
      "epoch": 3.1790421086467373,
      "grad_norm": 0.061311300843954086,
      "learning_rate": 1.576127718847102e-05,
      "loss": 0.0006,
      "step": 29670
    },
    {
      "epoch": 3.180113575484839,
      "grad_norm": 0.060414187610149384,
      "learning_rate": 1.575984856602022e-05,
      "loss": 0.0007,
      "step": 29680
    },
    {
      "epoch": 3.18118504232294,
      "grad_norm": 0.07769010961055756,
      "learning_rate": 1.5758419943569414e-05,
      "loss": 0.0004,
      "step": 29690
    },
    {
      "epoch": 3.1822565091610415,
      "grad_norm": 0.014802688732743263,
      "learning_rate": 1.5756991321118614e-05,
      "loss": 0.0034,
      "step": 29700
    },
    {
      "epoch": 3.1833279759991426,
      "grad_norm": 0.6703042387962341,
      "learning_rate": 1.575556269866781e-05,
      "loss": 0.1754,
      "step": 29710
    },
    {
      "epoch": 3.184399442837244,
      "grad_norm": 0.004612510092556477,
      "learning_rate": 1.575413407621701e-05,
      "loss": 0.0012,
      "step": 29720
    },
    {
      "epoch": 3.1854709096753457,
      "grad_norm": 0.0009937216527760029,
      "learning_rate": 1.575270545376621e-05,
      "loss": 0.1392,
      "step": 29730
    },
    {
      "epoch": 3.186542376513447,
      "grad_norm": 19.436559677124023,
      "learning_rate": 1.5751276831315404e-05,
      "loss": 0.2356,
      "step": 29740
    },
    {
      "epoch": 3.1876138433515484,
      "grad_norm": 0.0026061306707561016,
      "learning_rate": 1.5749848208864604e-05,
      "loss": 0.2987,
      "step": 29750
    },
    {
      "epoch": 3.1886853101896495,
      "grad_norm": 0.008531787432730198,
      "learning_rate": 1.57484195864138e-05,
      "loss": 0.0003,
      "step": 29760
    },
    {
      "epoch": 3.189756777027751,
      "grad_norm": 44.908599853515625,
      "learning_rate": 1.5746990963963e-05,
      "loss": 0.3626,
      "step": 29770
    },
    {
      "epoch": 3.190828243865852,
      "grad_norm": 0.0032092633191496134,
      "learning_rate": 1.57455623415122e-05,
      "loss": 0.3157,
      "step": 29780
    },
    {
      "epoch": 3.1918997107039537,
      "grad_norm": 0.0004779681912623346,
      "learning_rate": 1.5744133719061398e-05,
      "loss": 0.4053,
      "step": 29790
    },
    {
      "epoch": 3.192971177542055,
      "grad_norm": 0.0020279916934669018,
      "learning_rate": 1.5742705096610594e-05,
      "loss": 0.1574,
      "step": 29800
    },
    {
      "epoch": 3.1940426443801564,
      "grad_norm": 4.56241512298584,
      "learning_rate": 1.5741276474159793e-05,
      "loss": 0.1762,
      "step": 29810
    },
    {
      "epoch": 3.195114111218258,
      "grad_norm": 0.04181724786758423,
      "learning_rate": 1.5739847851708993e-05,
      "loss": 0.0018,
      "step": 29820
    },
    {
      "epoch": 3.196185578056359,
      "grad_norm": 0.004841986577957869,
      "learning_rate": 1.573841922925819e-05,
      "loss": 0.2617,
      "step": 29830
    },
    {
      "epoch": 3.1972570448944606,
      "grad_norm": 0.002130590146407485,
      "learning_rate": 1.5736990606807388e-05,
      "loss": 0.0047,
      "step": 29840
    },
    {
      "epoch": 3.1983285117325617,
      "grad_norm": 0.1916617453098297,
      "learning_rate": 1.5735561984356587e-05,
      "loss": 0.0984,
      "step": 29850
    },
    {
      "epoch": 3.1993999785706633,
      "grad_norm": 0.12127614766359329,
      "learning_rate": 1.5734133361905783e-05,
      "loss": 0.0878,
      "step": 29860
    },
    {
      "epoch": 3.2004714454087644,
      "grad_norm": 72.34870910644531,
      "learning_rate": 1.5732704739454983e-05,
      "loss": 0.1037,
      "step": 29870
    },
    {
      "epoch": 3.201542912246866,
      "grad_norm": 0.0008440274395979941,
      "learning_rate": 1.573127611700418e-05,
      "loss": 0.1781,
      "step": 29880
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 94.41465759277344,
      "learning_rate": 1.5729847494553378e-05,
      "loss": 0.651,
      "step": 29890
    },
    {
      "epoch": 3.2036858459230686,
      "grad_norm": 0.0832955464720726,
      "learning_rate": 1.5728418872102574e-05,
      "loss": 0.1828,
      "step": 29900
    },
    {
      "epoch": 3.20475731276117,
      "grad_norm": 0.012219609692692757,
      "learning_rate": 1.5726990249651773e-05,
      "loss": 0.0042,
      "step": 29910
    },
    {
      "epoch": 3.2058287795992713,
      "grad_norm": 0.09320005029439926,
      "learning_rate": 1.5725561627200973e-05,
      "loss": 0.226,
      "step": 29920
    },
    {
      "epoch": 3.206900246437373,
      "grad_norm": 0.04357096552848816,
      "learning_rate": 1.5724133004750172e-05,
      "loss": 0.2272,
      "step": 29930
    },
    {
      "epoch": 3.207971713275474,
      "grad_norm": 0.5035519599914551,
      "learning_rate": 1.572270438229937e-05,
      "loss": 0.2988,
      "step": 29940
    },
    {
      "epoch": 3.2090431801135755,
      "grad_norm": 0.07565785944461823,
      "learning_rate": 1.5721275759848567e-05,
      "loss": 0.1972,
      "step": 29950
    },
    {
      "epoch": 3.210114646951677,
      "grad_norm": 0.020663714036345482,
      "learning_rate": 1.5719847137397767e-05,
      "loss": 0.2031,
      "step": 29960
    },
    {
      "epoch": 3.211186113789778,
      "grad_norm": 23.506092071533203,
      "learning_rate": 1.5718418514946963e-05,
      "loss": 0.3615,
      "step": 29970
    },
    {
      "epoch": 3.2122575806278797,
      "grad_norm": 0.019813550636172295,
      "learning_rate": 1.5716989892496162e-05,
      "loss": 0.0008,
      "step": 29980
    },
    {
      "epoch": 3.213329047465981,
      "grad_norm": 0.09810228645801544,
      "learning_rate": 1.571556127004536e-05,
      "loss": 0.3158,
      "step": 29990
    },
    {
      "epoch": 3.2144005143040824,
      "grad_norm": 0.0642753541469574,
      "learning_rate": 1.5714132647594557e-05,
      "loss": 0.0022,
      "step": 30000
    },
    {
      "epoch": 3.2154719811421835,
      "grad_norm": 0.04948393628001213,
      "learning_rate": 1.5712704025143757e-05,
      "loss": 0.1833,
      "step": 30010
    },
    {
      "epoch": 3.216543447980285,
      "grad_norm": 0.002375340322032571,
      "learning_rate": 1.5711275402692953e-05,
      "loss": 0.1462,
      "step": 30020
    },
    {
      "epoch": 3.2176149148183866,
      "grad_norm": 0.000827379641123116,
      "learning_rate": 1.5709846780242152e-05,
      "loss": 0.1313,
      "step": 30030
    },
    {
      "epoch": 3.2186863816564877,
      "grad_norm": 0.0017838765634223819,
      "learning_rate": 1.570841815779135e-05,
      "loss": 0.1642,
      "step": 30040
    },
    {
      "epoch": 3.2197578484945892,
      "grad_norm": 0.006625700742006302,
      "learning_rate": 1.5706989535340547e-05,
      "loss": 0.0023,
      "step": 30050
    },
    {
      "epoch": 3.2208293153326903,
      "grad_norm": 0.04148177057504654,
      "learning_rate": 1.5705560912889747e-05,
      "loss": 0.0025,
      "step": 30060
    },
    {
      "epoch": 3.221900782170792,
      "grad_norm": 0.0883856862783432,
      "learning_rate": 1.5704132290438946e-05,
      "loss": 0.1666,
      "step": 30070
    },
    {
      "epoch": 3.222972249008893,
      "grad_norm": 0.12530332803726196,
      "learning_rate": 1.5702703667988146e-05,
      "loss": 0.1625,
      "step": 30080
    },
    {
      "epoch": 3.2240437158469946,
      "grad_norm": 0.07162976264953613,
      "learning_rate": 1.570127504553734e-05,
      "loss": 0.3554,
      "step": 30090
    },
    {
      "epoch": 3.225115182685096,
      "grad_norm": 0.0017795830499380827,
      "learning_rate": 1.569984642308654e-05,
      "loss": 0.5304,
      "step": 30100
    },
    {
      "epoch": 3.2261866495231972,
      "grad_norm": 0.004761533811688423,
      "learning_rate": 1.569841780063574e-05,
      "loss": 0.0029,
      "step": 30110
    },
    {
      "epoch": 3.227258116361299,
      "grad_norm": 0.008277996443212032,
      "learning_rate": 1.5696989178184936e-05,
      "loss": 0.002,
      "step": 30120
    },
    {
      "epoch": 3.2283295831994,
      "grad_norm": 0.0462767630815506,
      "learning_rate": 1.5695560555734136e-05,
      "loss": 0.0008,
      "step": 30130
    },
    {
      "epoch": 3.2294010500375014,
      "grad_norm": 0.0355837456882,
      "learning_rate": 1.569413193328333e-05,
      "loss": 0.0991,
      "step": 30140
    },
    {
      "epoch": 3.2304725168756026,
      "grad_norm": 0.061750657856464386,
      "learning_rate": 1.569270331083253e-05,
      "loss": 0.4916,
      "step": 30150
    },
    {
      "epoch": 3.231543983713704,
      "grad_norm": 0.06613462418317795,
      "learning_rate": 1.569127468838173e-05,
      "loss": 0.1595,
      "step": 30160
    },
    {
      "epoch": 3.232615450551805,
      "grad_norm": 0.001827714848332107,
      "learning_rate": 1.5689846065930926e-05,
      "loss": 0.001,
      "step": 30170
    },
    {
      "epoch": 3.2336869173899068,
      "grad_norm": 0.10568810254335403,
      "learning_rate": 1.5688417443480126e-05,
      "loss": 0.162,
      "step": 30180
    },
    {
      "epoch": 3.2347583842280083,
      "grad_norm": 0.034263573586940765,
      "learning_rate": 1.568698882102932e-05,
      "loss": 0.0009,
      "step": 30190
    },
    {
      "epoch": 3.2358298510661094,
      "grad_norm": 0.0006235820474103093,
      "learning_rate": 1.568556019857852e-05,
      "loss": 0.1074,
      "step": 30200
    },
    {
      "epoch": 3.236901317904211,
      "grad_norm": 0.00568203441798687,
      "learning_rate": 1.568413157612772e-05,
      "loss": 0.2847,
      "step": 30210
    },
    {
      "epoch": 3.237972784742312,
      "grad_norm": 0.0009356759255751967,
      "learning_rate": 1.568270295367692e-05,
      "loss": 0.0006,
      "step": 30220
    },
    {
      "epoch": 3.2390442515804136,
      "grad_norm": 0.15121552348136902,
      "learning_rate": 1.5681274331226116e-05,
      "loss": 0.2132,
      "step": 30230
    },
    {
      "epoch": 3.2401157184185148,
      "grad_norm": 49.98116683959961,
      "learning_rate": 1.5679845708775315e-05,
      "loss": 0.1831,
      "step": 30240
    },
    {
      "epoch": 3.2411871852566163,
      "grad_norm": 0.03293899819254875,
      "learning_rate": 1.5678417086324514e-05,
      "loss": 0.2071,
      "step": 30250
    },
    {
      "epoch": 3.242258652094718,
      "grad_norm": 0.0016137048369273543,
      "learning_rate": 1.567698846387371e-05,
      "loss": 0.4785,
      "step": 30260
    },
    {
      "epoch": 3.243330118932819,
      "grad_norm": 0.02412724494934082,
      "learning_rate": 1.567555984142291e-05,
      "loss": 0.2486,
      "step": 30270
    },
    {
      "epoch": 3.2444015857709205,
      "grad_norm": 0.32647761702537537,
      "learning_rate": 1.567413121897211e-05,
      "loss": 0.0033,
      "step": 30280
    },
    {
      "epoch": 3.2454730526090216,
      "grad_norm": 0.0012339461827650666,
      "learning_rate": 1.5672702596521305e-05,
      "loss": 0.0004,
      "step": 30290
    },
    {
      "epoch": 3.246544519447123,
      "grad_norm": 0.005337319802492857,
      "learning_rate": 1.5671273974070505e-05,
      "loss": 0.1815,
      "step": 30300
    },
    {
      "epoch": 3.2476159862852243,
      "grad_norm": 0.8644495010375977,
      "learning_rate": 1.56698453516197e-05,
      "loss": 0.0021,
      "step": 30310
    },
    {
      "epoch": 3.248687453123326,
      "grad_norm": 0.006185245234519243,
      "learning_rate": 1.56684167291689e-05,
      "loss": 0.4223,
      "step": 30320
    },
    {
      "epoch": 3.249758919961427,
      "grad_norm": 0.06110444664955139,
      "learning_rate": 1.5666988106718096e-05,
      "loss": 0.3193,
      "step": 30330
    },
    {
      "epoch": 3.2508303867995285,
      "grad_norm": 0.27830079197883606,
      "learning_rate": 1.5665559484267295e-05,
      "loss": 0.0073,
      "step": 30340
    },
    {
      "epoch": 3.25190185363763,
      "grad_norm": 0.002002217574045062,
      "learning_rate": 1.5664130861816495e-05,
      "loss": 0.4111,
      "step": 30350
    },
    {
      "epoch": 3.252973320475731,
      "grad_norm": 0.028595415875315666,
      "learning_rate": 1.5662702239365694e-05,
      "loss": 0.001,
      "step": 30360
    },
    {
      "epoch": 3.2540447873138327,
      "grad_norm": 0.0009448268101550639,
      "learning_rate": 1.566127361691489e-05,
      "loss": 0.1527,
      "step": 30370
    },
    {
      "epoch": 3.255116254151934,
      "grad_norm": 0.000734032248146832,
      "learning_rate": 1.565984499446409e-05,
      "loss": 0.0015,
      "step": 30380
    },
    {
      "epoch": 3.2561877209900354,
      "grad_norm": 0.033647071570158005,
      "learning_rate": 1.565841637201329e-05,
      "loss": 0.0004,
      "step": 30390
    },
    {
      "epoch": 3.2572591878281365,
      "grad_norm": 25.952415466308594,
      "learning_rate": 1.5656987749562488e-05,
      "loss": 0.1416,
      "step": 30400
    },
    {
      "epoch": 3.258330654666238,
      "grad_norm": 1.584815502166748,
      "learning_rate": 1.5655559127111684e-05,
      "loss": 0.1892,
      "step": 30410
    },
    {
      "epoch": 3.2594021215043396,
      "grad_norm": 0.00034332138602621853,
      "learning_rate": 1.5654130504660883e-05,
      "loss": 0.1876,
      "step": 30420
    },
    {
      "epoch": 3.2604735883424407,
      "grad_norm": 0.024545280262827873,
      "learning_rate": 1.565270188221008e-05,
      "loss": 0.1326,
      "step": 30430
    },
    {
      "epoch": 3.2615450551805423,
      "grad_norm": 0.03428037464618683,
      "learning_rate": 1.565127325975928e-05,
      "loss": 0.0008,
      "step": 30440
    },
    {
      "epoch": 3.2626165220186434,
      "grad_norm": 0.02611635997891426,
      "learning_rate": 1.5649844637308475e-05,
      "loss": 0.268,
      "step": 30450
    },
    {
      "epoch": 3.263687988856745,
      "grad_norm": 17.81865119934082,
      "learning_rate": 1.5648416014857674e-05,
      "loss": 0.4037,
      "step": 30460
    },
    {
      "epoch": 3.264759455694846,
      "grad_norm": 0.009786933660507202,
      "learning_rate": 1.5646987392406873e-05,
      "loss": 0.2686,
      "step": 30470
    },
    {
      "epoch": 3.2658309225329476,
      "grad_norm": 0.039207927882671356,
      "learning_rate": 1.564555876995607e-05,
      "loss": 0.3962,
      "step": 30480
    },
    {
      "epoch": 3.266902389371049,
      "grad_norm": 0.10093620419502258,
      "learning_rate": 1.564413014750527e-05,
      "loss": 0.0045,
      "step": 30490
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 0.09963793307542801,
      "learning_rate": 1.5642701525054468e-05,
      "loss": 0.1486,
      "step": 30500
    },
    {
      "epoch": 3.269045323047252,
      "grad_norm": 0.030716747045516968,
      "learning_rate": 1.5641272902603667e-05,
      "loss": 0.0172,
      "step": 30510
    },
    {
      "epoch": 3.270116789885353,
      "grad_norm": 0.07190793752670288,
      "learning_rate": 1.5639844280152863e-05,
      "loss": 0.0077,
      "step": 30520
    },
    {
      "epoch": 3.2711882567234545,
      "grad_norm": 0.0020594741217792034,
      "learning_rate": 1.5638415657702063e-05,
      "loss": 0.3339,
      "step": 30530
    },
    {
      "epoch": 3.2722597235615556,
      "grad_norm": 0.002956004813313484,
      "learning_rate": 1.5636987035251262e-05,
      "loss": 0.1843,
      "step": 30540
    },
    {
      "epoch": 3.273331190399657,
      "grad_norm": 0.10443297028541565,
      "learning_rate": 1.5635558412800458e-05,
      "loss": 0.2372,
      "step": 30550
    },
    {
      "epoch": 3.2744026572377587,
      "grad_norm": 0.006610130425542593,
      "learning_rate": 1.5634129790349658e-05,
      "loss": 0.1453,
      "step": 30560
    },
    {
      "epoch": 3.27547412407586,
      "grad_norm": 0.022256026044487953,
      "learning_rate": 1.5632701167898854e-05,
      "loss": 0.1624,
      "step": 30570
    },
    {
      "epoch": 3.2765455909139614,
      "grad_norm": 0.0029636367689818144,
      "learning_rate": 1.5631272545448053e-05,
      "loss": 0.0022,
      "step": 30580
    },
    {
      "epoch": 3.2776170577520625,
      "grad_norm": 0.0023276088759303093,
      "learning_rate": 1.5629843922997252e-05,
      "loss": 0.2143,
      "step": 30590
    },
    {
      "epoch": 3.278688524590164,
      "grad_norm": 0.03129470720887184,
      "learning_rate": 1.5628415300546448e-05,
      "loss": 0.0052,
      "step": 30600
    },
    {
      "epoch": 3.279759991428265,
      "grad_norm": 17.46258544921875,
      "learning_rate": 1.5626986678095648e-05,
      "loss": 0.3168,
      "step": 30610
    },
    {
      "epoch": 3.2808314582663667,
      "grad_norm": 0.0015396850649267435,
      "learning_rate": 1.5625558055644844e-05,
      "loss": 0.1965,
      "step": 30620
    },
    {
      "epoch": 3.2819029251044682,
      "grad_norm": 0.15473078191280365,
      "learning_rate": 1.5624129433194043e-05,
      "loss": 0.2841,
      "step": 30630
    },
    {
      "epoch": 3.2829743919425693,
      "grad_norm": 0.06273896247148514,
      "learning_rate": 1.5622700810743242e-05,
      "loss": 0.3086,
      "step": 30640
    },
    {
      "epoch": 3.284045858780671,
      "grad_norm": 0.008043533191084862,
      "learning_rate": 1.562127218829244e-05,
      "loss": 0.3202,
      "step": 30650
    },
    {
      "epoch": 3.285117325618772,
      "grad_norm": 0.11746922880411148,
      "learning_rate": 1.5619843565841638e-05,
      "loss": 0.1807,
      "step": 30660
    },
    {
      "epoch": 3.2861887924568736,
      "grad_norm": 0.0029635170940309763,
      "learning_rate": 1.5618414943390837e-05,
      "loss": 0.083,
      "step": 30670
    },
    {
      "epoch": 3.2872602592949747,
      "grad_norm": 0.0016745345201343298,
      "learning_rate": 1.5616986320940036e-05,
      "loss": 0.0112,
      "step": 30680
    },
    {
      "epoch": 3.2883317261330762,
      "grad_norm": 0.7511975169181824,
      "learning_rate": 1.5615557698489232e-05,
      "loss": 0.2571,
      "step": 30690
    },
    {
      "epoch": 3.289403192971178,
      "grad_norm": 0.006083203013986349,
      "learning_rate": 1.5614129076038432e-05,
      "loss": 0.1388,
      "step": 30700
    },
    {
      "epoch": 3.290474659809279,
      "grad_norm": 0.001690235105343163,
      "learning_rate": 1.561270045358763e-05,
      "loss": 0.0017,
      "step": 30710
    },
    {
      "epoch": 3.2915461266473804,
      "grad_norm": 0.002173491520807147,
      "learning_rate": 1.5611271831136827e-05,
      "loss": 0.8044,
      "step": 30720
    },
    {
      "epoch": 3.2926175934854816,
      "grad_norm": 24.615388870239258,
      "learning_rate": 1.5609843208686026e-05,
      "loss": 0.1166,
      "step": 30730
    },
    {
      "epoch": 3.293689060323583,
      "grad_norm": 0.017177246510982513,
      "learning_rate": 1.5608414586235222e-05,
      "loss": 0.5983,
      "step": 30740
    },
    {
      "epoch": 3.294760527161684,
      "grad_norm": 0.15103952586650848,
      "learning_rate": 1.5606985963784422e-05,
      "loss": 0.002,
      "step": 30750
    },
    {
      "epoch": 3.2958319939997858,
      "grad_norm": 0.12724025547504425,
      "learning_rate": 1.560555734133362e-05,
      "loss": 0.3024,
      "step": 30760
    },
    {
      "epoch": 3.296903460837887,
      "grad_norm": 0.0061570098623633385,
      "learning_rate": 1.5604128718882817e-05,
      "loss": 0.0015,
      "step": 30770
    },
    {
      "epoch": 3.2979749276759884,
      "grad_norm": 0.012900721281766891,
      "learning_rate": 1.5602700096432017e-05,
      "loss": 0.2353,
      "step": 30780
    },
    {
      "epoch": 3.2990463945140895,
      "grad_norm": 0.0569266676902771,
      "learning_rate": 1.5601271473981216e-05,
      "loss": 0.0017,
      "step": 30790
    },
    {
      "epoch": 3.300117861352191,
      "grad_norm": 0.006346970796585083,
      "learning_rate": 1.5599842851530412e-05,
      "loss": 0.283,
      "step": 30800
    },
    {
      "epoch": 3.3011893281902926,
      "grad_norm": 0.24112507700920105,
      "learning_rate": 1.559841422907961e-05,
      "loss": 0.0009,
      "step": 30810
    },
    {
      "epoch": 3.3022607950283938,
      "grad_norm": 0.0363454706966877,
      "learning_rate": 1.559698560662881e-05,
      "loss": 0.2643,
      "step": 30820
    },
    {
      "epoch": 3.3033322618664953,
      "grad_norm": 0.00695377541705966,
      "learning_rate": 1.559555698417801e-05,
      "loss": 0.2783,
      "step": 30830
    },
    {
      "epoch": 3.3044037287045964,
      "grad_norm": 0.0044675301760435104,
      "learning_rate": 1.5594128361727206e-05,
      "loss": 0.1333,
      "step": 30840
    },
    {
      "epoch": 3.305475195542698,
      "grad_norm": 0.192921981215477,
      "learning_rate": 1.5592699739276405e-05,
      "loss": 0.001,
      "step": 30850
    },
    {
      "epoch": 3.306546662380799,
      "grad_norm": 0.001224794890731573,
      "learning_rate": 1.55912711168256e-05,
      "loss": 0.3915,
      "step": 30860
    },
    {
      "epoch": 3.3076181292189006,
      "grad_norm": 0.020463120192289352,
      "learning_rate": 1.55898424943748e-05,
      "loss": 0.1765,
      "step": 30870
    },
    {
      "epoch": 3.308689596057002,
      "grad_norm": 0.2634940445423126,
      "learning_rate": 1.5588413871923997e-05,
      "loss": 0.2465,
      "step": 30880
    },
    {
      "epoch": 3.3097610628951033,
      "grad_norm": 0.43210458755493164,
      "learning_rate": 1.5586985249473196e-05,
      "loss": 0.1373,
      "step": 30890
    },
    {
      "epoch": 3.310832529733205,
      "grad_norm": 0.1685459166765213,
      "learning_rate": 1.5585556627022395e-05,
      "loss": 0.3366,
      "step": 30900
    },
    {
      "epoch": 3.311903996571306,
      "grad_norm": 2.624617576599121,
      "learning_rate": 1.558412800457159e-05,
      "loss": 0.224,
      "step": 30910
    },
    {
      "epoch": 3.3129754634094075,
      "grad_norm": 0.000938636832870543,
      "learning_rate": 1.558269938212079e-05,
      "loss": 0.0076,
      "step": 30920
    },
    {
      "epoch": 3.3140469302475086,
      "grad_norm": 0.0020970723126083612,
      "learning_rate": 1.558127075966999e-05,
      "loss": 0.0004,
      "step": 30930
    },
    {
      "epoch": 3.31511839708561,
      "grad_norm": 0.7489163875579834,
      "learning_rate": 1.5579842137219186e-05,
      "loss": 0.1033,
      "step": 30940
    },
    {
      "epoch": 3.3161898639237117,
      "grad_norm": 0.0008158835116773844,
      "learning_rate": 1.5578413514768385e-05,
      "loss": 0.0015,
      "step": 30950
    },
    {
      "epoch": 3.317261330761813,
      "grad_norm": 0.0005699748871847987,
      "learning_rate": 1.5576984892317585e-05,
      "loss": 0.3415,
      "step": 30960
    },
    {
      "epoch": 3.3183327975999144,
      "grad_norm": 0.02696927823126316,
      "learning_rate": 1.5575556269866784e-05,
      "loss": 0.0009,
      "step": 30970
    },
    {
      "epoch": 3.3194042644380155,
      "grad_norm": 0.0005138879059813917,
      "learning_rate": 1.557412764741598e-05,
      "loss": 0.1571,
      "step": 30980
    },
    {
      "epoch": 3.320475731276117,
      "grad_norm": 75.37281036376953,
      "learning_rate": 1.557269902496518e-05,
      "loss": 0.2234,
      "step": 30990
    },
    {
      "epoch": 3.321547198114218,
      "grad_norm": 0.0006784207071177661,
      "learning_rate": 1.5571270402514375e-05,
      "loss": 0.0,
      "step": 31000
    },
    {
      "epoch": 3.3226186649523197,
      "grad_norm": 0.0005364126991480589,
      "learning_rate": 1.5569841780063575e-05,
      "loss": 0.0014,
      "step": 31010
    },
    {
      "epoch": 3.3236901317904213,
      "grad_norm": 0.0006255155894905329,
      "learning_rate": 1.5568413157612774e-05,
      "loss": 0.0427,
      "step": 31020
    },
    {
      "epoch": 3.3247615986285224,
      "grad_norm": 0.08400499075651169,
      "learning_rate": 1.556698453516197e-05,
      "loss": 0.3229,
      "step": 31030
    },
    {
      "epoch": 3.325833065466624,
      "grad_norm": 0.0006486541242338717,
      "learning_rate": 1.556555591271117e-05,
      "loss": 0.1902,
      "step": 31040
    },
    {
      "epoch": 3.326904532304725,
      "grad_norm": 14.917515754699707,
      "learning_rate": 1.5564127290260366e-05,
      "loss": 0.3619,
      "step": 31050
    },
    {
      "epoch": 3.3279759991428266,
      "grad_norm": 0.010304595343768597,
      "learning_rate": 1.5562698667809565e-05,
      "loss": 0.0003,
      "step": 31060
    },
    {
      "epoch": 3.3290474659809277,
      "grad_norm": 0.0006187977851368487,
      "learning_rate": 1.5561270045358764e-05,
      "loss": 0.0004,
      "step": 31070
    },
    {
      "epoch": 3.3301189328190293,
      "grad_norm": 0.30797722935676575,
      "learning_rate": 1.5559841422907964e-05,
      "loss": 0.0024,
      "step": 31080
    },
    {
      "epoch": 3.331190399657131,
      "grad_norm": 14.626733779907227,
      "learning_rate": 1.555841280045716e-05,
      "loss": 0.1989,
      "step": 31090
    },
    {
      "epoch": 3.332261866495232,
      "grad_norm": 89.26190185546875,
      "learning_rate": 1.555698417800636e-05,
      "loss": 0.1032,
      "step": 31100
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.0005434694467112422,
      "learning_rate": 1.555555555555556e-05,
      "loss": 0.3399,
      "step": 31110
    },
    {
      "epoch": 3.3344048001714346,
      "grad_norm": 0.03250253200531006,
      "learning_rate": 1.5554126933104754e-05,
      "loss": 0.1093,
      "step": 31120
    },
    {
      "epoch": 3.335476267009536,
      "grad_norm": 0.2756880521774292,
      "learning_rate": 1.5552698310653954e-05,
      "loss": 0.4906,
      "step": 31130
    },
    {
      "epoch": 3.3365477338476373,
      "grad_norm": 0.003229029942303896,
      "learning_rate": 1.5551269688203153e-05,
      "loss": 0.0027,
      "step": 31140
    },
    {
      "epoch": 3.337619200685739,
      "grad_norm": 0.0035885993856936693,
      "learning_rate": 1.554984106575235e-05,
      "loss": 0.2335,
      "step": 31150
    },
    {
      "epoch": 3.3386906675238404,
      "grad_norm": 4.063492774963379,
      "learning_rate": 1.554841244330155e-05,
      "loss": 0.0018,
      "step": 31160
    },
    {
      "epoch": 3.3397621343619415,
      "grad_norm": 0.16604860126972198,
      "learning_rate": 1.5546983820850744e-05,
      "loss": 0.0006,
      "step": 31170
    },
    {
      "epoch": 3.340833601200043,
      "grad_norm": 0.0009624932426959276,
      "learning_rate": 1.5545555198399944e-05,
      "loss": 0.0061,
      "step": 31180
    },
    {
      "epoch": 3.341905068038144,
      "grad_norm": 0.0009795529767870903,
      "learning_rate": 1.5544126575949143e-05,
      "loss": 0.1787,
      "step": 31190
    },
    {
      "epoch": 3.3429765348762457,
      "grad_norm": 0.0033576961141079664,
      "learning_rate": 1.554269795349834e-05,
      "loss": 0.0034,
      "step": 31200
    },
    {
      "epoch": 3.344048001714347,
      "grad_norm": 0.0020822593942284584,
      "learning_rate": 1.554126933104754e-05,
      "loss": 0.4186,
      "step": 31210
    },
    {
      "epoch": 3.3451194685524483,
      "grad_norm": 0.00386421219445765,
      "learning_rate": 1.5539840708596738e-05,
      "loss": 0.0026,
      "step": 31220
    },
    {
      "epoch": 3.34619093539055,
      "grad_norm": 0.0016061823116615415,
      "learning_rate": 1.5538412086145934e-05,
      "loss": 0.0004,
      "step": 31230
    },
    {
      "epoch": 3.347262402228651,
      "grad_norm": 0.0010681608691811562,
      "learning_rate": 1.5536983463695133e-05,
      "loss": 0.0032,
      "step": 31240
    },
    {
      "epoch": 3.3483338690667526,
      "grad_norm": 0.001607188954949379,
      "learning_rate": 1.5535554841244333e-05,
      "loss": 0.3399,
      "step": 31250
    },
    {
      "epoch": 3.3494053359048537,
      "grad_norm": 0.05017450824379921,
      "learning_rate": 1.5534126218793532e-05,
      "loss": 0.1183,
      "step": 31260
    },
    {
      "epoch": 3.3504768027429552,
      "grad_norm": 0.6324096918106079,
      "learning_rate": 1.5532697596342728e-05,
      "loss": 0.0012,
      "step": 31270
    },
    {
      "epoch": 3.3515482695810563,
      "grad_norm": 0.12519066035747528,
      "learning_rate": 1.5531268973891927e-05,
      "loss": 0.0006,
      "step": 31280
    },
    {
      "epoch": 3.352619736419158,
      "grad_norm": 28.225540161132812,
      "learning_rate": 1.5529840351441123e-05,
      "loss": 0.4436,
      "step": 31290
    },
    {
      "epoch": 3.353691203257259,
      "grad_norm": 0.48199591040611267,
      "learning_rate": 1.5528411728990323e-05,
      "loss": 0.2782,
      "step": 31300
    },
    {
      "epoch": 3.3547626700953606,
      "grad_norm": 0.30564382672309875,
      "learning_rate": 1.5526983106539522e-05,
      "loss": 0.0018,
      "step": 31310
    },
    {
      "epoch": 3.3558341369334617,
      "grad_norm": 17.738431930541992,
      "learning_rate": 1.5525554484088718e-05,
      "loss": 0.2285,
      "step": 31320
    },
    {
      "epoch": 3.356905603771563,
      "grad_norm": 0.00860428437590599,
      "learning_rate": 1.5524125861637917e-05,
      "loss": 0.0012,
      "step": 31330
    },
    {
      "epoch": 3.3579770706096648,
      "grad_norm": 0.5231792330741882,
      "learning_rate": 1.5522697239187113e-05,
      "loss": 0.5697,
      "step": 31340
    },
    {
      "epoch": 3.359048537447766,
      "grad_norm": 0.10164568573236465,
      "learning_rate": 1.5521268616736313e-05,
      "loss": 0.0011,
      "step": 31350
    },
    {
      "epoch": 3.3601200042858674,
      "grad_norm": 0.031206952407956123,
      "learning_rate": 1.5519839994285512e-05,
      "loss": 0.0014,
      "step": 31360
    },
    {
      "epoch": 3.3611914711239685,
      "grad_norm": 1.4299339056015015,
      "learning_rate": 1.5518411371834708e-05,
      "loss": 0.0006,
      "step": 31370
    },
    {
      "epoch": 3.36226293796207,
      "grad_norm": 0.05287223309278488,
      "learning_rate": 1.5516982749383907e-05,
      "loss": 0.5789,
      "step": 31380
    },
    {
      "epoch": 3.363334404800171,
      "grad_norm": 0.031092768535017967,
      "learning_rate": 1.5515554126933107e-05,
      "loss": 0.2651,
      "step": 31390
    },
    {
      "epoch": 3.3644058716382728,
      "grad_norm": 0.045783642679452896,
      "learning_rate": 1.5514125504482306e-05,
      "loss": 0.002,
      "step": 31400
    },
    {
      "epoch": 3.3654773384763743,
      "grad_norm": 0.01839561015367508,
      "learning_rate": 1.5512696882031502e-05,
      "loss": 0.0005,
      "step": 31410
    },
    {
      "epoch": 3.3665488053144754,
      "grad_norm": 0.03126641362905502,
      "learning_rate": 1.55112682595807e-05,
      "loss": 0.4389,
      "step": 31420
    },
    {
      "epoch": 3.367620272152577,
      "grad_norm": 0.039756689220666885,
      "learning_rate": 1.55098396371299e-05,
      "loss": 0.0008,
      "step": 31430
    },
    {
      "epoch": 3.368691738990678,
      "grad_norm": 5.397373676300049,
      "learning_rate": 1.5508411014679097e-05,
      "loss": 0.125,
      "step": 31440
    },
    {
      "epoch": 3.3697632058287796,
      "grad_norm": 0.020170265808701515,
      "learning_rate": 1.5506982392228296e-05,
      "loss": 0.3532,
      "step": 31450
    },
    {
      "epoch": 3.3708346726668807,
      "grad_norm": 0.05618106573820114,
      "learning_rate": 1.5505553769777492e-05,
      "loss": 0.0008,
      "step": 31460
    },
    {
      "epoch": 3.3719061395049823,
      "grad_norm": 0.03393571451306343,
      "learning_rate": 1.550412514732669e-05,
      "loss": 0.0025,
      "step": 31470
    },
    {
      "epoch": 3.372977606343084,
      "grad_norm": 30.509151458740234,
      "learning_rate": 1.5502696524875887e-05,
      "loss": 0.2029,
      "step": 31480
    },
    {
      "epoch": 3.374049073181185,
      "grad_norm": 0.22423264384269714,
      "learning_rate": 1.5501267902425087e-05,
      "loss": 0.1617,
      "step": 31490
    },
    {
      "epoch": 3.3751205400192865,
      "grad_norm": 0.061954863369464874,
      "learning_rate": 1.5499839279974286e-05,
      "loss": 0.1417,
      "step": 31500
    },
    {
      "epoch": 3.3761920068573876,
      "grad_norm": 0.006257097236812115,
      "learning_rate": 1.5498410657523482e-05,
      "loss": 0.0005,
      "step": 31510
    },
    {
      "epoch": 3.377263473695489,
      "grad_norm": 0.12569674849510193,
      "learning_rate": 1.549698203507268e-05,
      "loss": 0.2796,
      "step": 31520
    },
    {
      "epoch": 3.3783349405335903,
      "grad_norm": 0.3208062946796417,
      "learning_rate": 1.549555341262188e-05,
      "loss": 0.0009,
      "step": 31530
    },
    {
      "epoch": 3.379406407371692,
      "grad_norm": 0.0059252227656543255,
      "learning_rate": 1.549412479017108e-05,
      "loss": 0.4112,
      "step": 31540
    },
    {
      "epoch": 3.3804778742097934,
      "grad_norm": 0.010540641844272614,
      "learning_rate": 1.549269616772028e-05,
      "loss": 0.4481,
      "step": 31550
    },
    {
      "epoch": 3.3815493410478945,
      "grad_norm": 0.5099184513092041,
      "learning_rate": 1.5491267545269476e-05,
      "loss": 0.0029,
      "step": 31560
    },
    {
      "epoch": 3.382620807885996,
      "grad_norm": 0.02645033784210682,
      "learning_rate": 1.5489838922818675e-05,
      "loss": 0.4871,
      "step": 31570
    },
    {
      "epoch": 3.383692274724097,
      "grad_norm": 0.2721191942691803,
      "learning_rate": 1.548841030036787e-05,
      "loss": 0.4474,
      "step": 31580
    },
    {
      "epoch": 3.3847637415621987,
      "grad_norm": 0.2760724723339081,
      "learning_rate": 1.548698167791707e-05,
      "loss": 0.1642,
      "step": 31590
    },
    {
      "epoch": 3.3858352084003,
      "grad_norm": 0.021907448768615723,
      "learning_rate": 1.5485553055466266e-05,
      "loss": 0.0023,
      "step": 31600
    },
    {
      "epoch": 3.3869066752384014,
      "grad_norm": 0.020483793690800667,
      "learning_rate": 1.5484124433015466e-05,
      "loss": 0.3864,
      "step": 31610
    },
    {
      "epoch": 3.387978142076503,
      "grad_norm": 0.006733553949743509,
      "learning_rate": 1.5482695810564665e-05,
      "loss": 0.0018,
      "step": 31620
    },
    {
      "epoch": 3.389049608914604,
      "grad_norm": 0.13661503791809082,
      "learning_rate": 1.548126718811386e-05,
      "loss": 0.003,
      "step": 31630
    },
    {
      "epoch": 3.3901210757527056,
      "grad_norm": 0.08846956491470337,
      "learning_rate": 1.547983856566306e-05,
      "loss": 0.0015,
      "step": 31640
    },
    {
      "epoch": 3.3911925425908067,
      "grad_norm": 0.009870823472738266,
      "learning_rate": 1.547840994321226e-05,
      "loss": 0.152,
      "step": 31650
    },
    {
      "epoch": 3.3922640094289083,
      "grad_norm": 0.00543341226875782,
      "learning_rate": 1.5476981320761456e-05,
      "loss": 0.1919,
      "step": 31660
    },
    {
      "epoch": 3.3933354762670094,
      "grad_norm": 13.671517372131348,
      "learning_rate": 1.5475552698310655e-05,
      "loss": 0.1836,
      "step": 31670
    },
    {
      "epoch": 3.394406943105111,
      "grad_norm": 0.0759492889046669,
      "learning_rate": 1.5474124075859854e-05,
      "loss": 0.001,
      "step": 31680
    },
    {
      "epoch": 3.3954784099432125,
      "grad_norm": 0.03236938267946243,
      "learning_rate": 1.5472695453409054e-05,
      "loss": 0.1817,
      "step": 31690
    },
    {
      "epoch": 3.3965498767813136,
      "grad_norm": 0.0349690206348896,
      "learning_rate": 1.547126683095825e-05,
      "loss": 0.0004,
      "step": 31700
    },
    {
      "epoch": 3.397621343619415,
      "grad_norm": 0.0029466007836163044,
      "learning_rate": 1.546983820850745e-05,
      "loss": 0.0008,
      "step": 31710
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 0.13611671328544617,
      "learning_rate": 1.5468409586056645e-05,
      "loss": 0.0008,
      "step": 31720
    },
    {
      "epoch": 3.399764277295618,
      "grad_norm": 0.00958540104329586,
      "learning_rate": 1.5466980963605845e-05,
      "loss": 0.2759,
      "step": 31730
    },
    {
      "epoch": 3.400835744133719,
      "grad_norm": 0.004077694844454527,
      "learning_rate": 1.5465552341155044e-05,
      "loss": 0.0004,
      "step": 31740
    },
    {
      "epoch": 3.4019072109718205,
      "grad_norm": 0.02020086906850338,
      "learning_rate": 1.546412371870424e-05,
      "loss": 0.1631,
      "step": 31750
    },
    {
      "epoch": 3.402978677809922,
      "grad_norm": 0.13026270270347595,
      "learning_rate": 1.546269509625344e-05,
      "loss": 0.001,
      "step": 31760
    },
    {
      "epoch": 3.404050144648023,
      "grad_norm": 1749.7947998046875,
      "learning_rate": 1.5461266473802635e-05,
      "loss": 0.087,
      "step": 31770
    },
    {
      "epoch": 3.4051216114861247,
      "grad_norm": 0.015143315307796001,
      "learning_rate": 1.5459837851351835e-05,
      "loss": 0.0005,
      "step": 31780
    },
    {
      "epoch": 3.406193078324226,
      "grad_norm": 0.004704213235527277,
      "learning_rate": 1.5458409228901034e-05,
      "loss": 0.1965,
      "step": 31790
    },
    {
      "epoch": 3.4072645451623274,
      "grad_norm": 17.004375457763672,
      "learning_rate": 1.545698060645023e-05,
      "loss": 0.1622,
      "step": 31800
    },
    {
      "epoch": 3.4083360120004285,
      "grad_norm": 0.004649497102946043,
      "learning_rate": 1.545555198399943e-05,
      "loss": 0.2664,
      "step": 31810
    },
    {
      "epoch": 3.40940747883853,
      "grad_norm": 0.007784728892147541,
      "learning_rate": 1.545412336154863e-05,
      "loss": 0.2009,
      "step": 31820
    },
    {
      "epoch": 3.410478945676631,
      "grad_norm": 0.01599222607910633,
      "learning_rate": 1.5452694739097828e-05,
      "loss": 0.213,
      "step": 31830
    },
    {
      "epoch": 3.4115504125147327,
      "grad_norm": 0.03735296055674553,
      "learning_rate": 1.5451266116647024e-05,
      "loss": 0.3241,
      "step": 31840
    },
    {
      "epoch": 3.412621879352834,
      "grad_norm": 0.020283186808228493,
      "learning_rate": 1.5449837494196223e-05,
      "loss": 0.0012,
      "step": 31850
    },
    {
      "epoch": 3.4136933461909353,
      "grad_norm": 0.007540457416325808,
      "learning_rate": 1.5448408871745423e-05,
      "loss": 0.002,
      "step": 31860
    },
    {
      "epoch": 3.414764813029037,
      "grad_norm": 0.02745053544640541,
      "learning_rate": 1.544698024929462e-05,
      "loss": 0.1776,
      "step": 31870
    },
    {
      "epoch": 3.415836279867138,
      "grad_norm": 0.10637738555669785,
      "learning_rate": 1.5445551626843818e-05,
      "loss": 0.2933,
      "step": 31880
    },
    {
      "epoch": 3.4169077467052396,
      "grad_norm": 0.02438354678452015,
      "learning_rate": 1.5444123004393014e-05,
      "loss": 0.1058,
      "step": 31890
    },
    {
      "epoch": 3.4179792135433407,
      "grad_norm": 0.0038591418415308,
      "learning_rate": 1.5442694381942213e-05,
      "loss": 0.1237,
      "step": 31900
    },
    {
      "epoch": 3.419050680381442,
      "grad_norm": 0.013640984892845154,
      "learning_rate": 1.544126575949141e-05,
      "loss": 0.2224,
      "step": 31910
    },
    {
      "epoch": 3.4201221472195433,
      "grad_norm": 0.015360521152615547,
      "learning_rate": 1.543983713704061e-05,
      "loss": 0.3989,
      "step": 31920
    },
    {
      "epoch": 3.421193614057645,
      "grad_norm": 0.004032065626233816,
      "learning_rate": 1.5438408514589808e-05,
      "loss": 0.1301,
      "step": 31930
    },
    {
      "epoch": 3.4222650808957464,
      "grad_norm": 0.004258128348737955,
      "learning_rate": 1.5436979892139004e-05,
      "loss": 0.224,
      "step": 31940
    },
    {
      "epoch": 3.4233365477338475,
      "grad_norm": 0.016765903681516647,
      "learning_rate": 1.5435551269688203e-05,
      "loss": 0.0019,
      "step": 31950
    },
    {
      "epoch": 3.424408014571949,
      "grad_norm": 0.16836310923099518,
      "learning_rate": 1.5434122647237403e-05,
      "loss": 0.0006,
      "step": 31960
    },
    {
      "epoch": 3.42547948141005,
      "grad_norm": 0.11635181307792664,
      "learning_rate": 1.5432694024786602e-05,
      "loss": 0.3,
      "step": 31970
    },
    {
      "epoch": 3.4265509482481518,
      "grad_norm": 15.77363109588623,
      "learning_rate": 1.54312654023358e-05,
      "loss": 0.2725,
      "step": 31980
    },
    {
      "epoch": 3.427622415086253,
      "grad_norm": 0.2793267071247101,
      "learning_rate": 1.5429836779884998e-05,
      "loss": 0.182,
      "step": 31990
    },
    {
      "epoch": 3.4286938819243544,
      "grad_norm": 0.3965325653553009,
      "learning_rate": 1.5428408157434197e-05,
      "loss": 0.174,
      "step": 32000
    },
    {
      "epoch": 3.429765348762456,
      "grad_norm": 0.014371871016919613,
      "learning_rate": 1.5426979534983393e-05,
      "loss": 0.1568,
      "step": 32010
    },
    {
      "epoch": 3.430836815600557,
      "grad_norm": 0.004948333837091923,
      "learning_rate": 1.5425550912532592e-05,
      "loss": 0.3723,
      "step": 32020
    },
    {
      "epoch": 3.4319082824386586,
      "grad_norm": 0.002877120627090335,
      "learning_rate": 1.5424122290081788e-05,
      "loss": 0.208,
      "step": 32030
    },
    {
      "epoch": 3.4329797492767598,
      "grad_norm": 0.12863729894161224,
      "learning_rate": 1.5422693667630988e-05,
      "loss": 0.0013,
      "step": 32040
    },
    {
      "epoch": 3.4340512161148613,
      "grad_norm": 0.002274200087413192,
      "learning_rate": 1.5421265045180187e-05,
      "loss": 0.1484,
      "step": 32050
    },
    {
      "epoch": 3.4351226829529624,
      "grad_norm": 0.47588369250297546,
      "learning_rate": 1.5419836422729383e-05,
      "loss": 0.0003,
      "step": 32060
    },
    {
      "epoch": 3.436194149791064,
      "grad_norm": 0.0016967614647001028,
      "learning_rate": 1.5418407800278582e-05,
      "loss": 0.3359,
      "step": 32070
    },
    {
      "epoch": 3.4372656166291655,
      "grad_norm": 0.00883986335247755,
      "learning_rate": 1.541697917782778e-05,
      "loss": 0.106,
      "step": 32080
    },
    {
      "epoch": 3.4383370834672666,
      "grad_norm": 0.0019420486642047763,
      "learning_rate": 1.5415550555376978e-05,
      "loss": 0.0014,
      "step": 32090
    },
    {
      "epoch": 3.439408550305368,
      "grad_norm": 0.02145005576312542,
      "learning_rate": 1.5414121932926177e-05,
      "loss": 0.1434,
      "step": 32100
    },
    {
      "epoch": 3.4404800171434693,
      "grad_norm": 0.12086747586727142,
      "learning_rate": 1.5412693310475376e-05,
      "loss": 0.0013,
      "step": 32110
    },
    {
      "epoch": 3.441551483981571,
      "grad_norm": 0.004030724987387657,
      "learning_rate": 1.5411264688024576e-05,
      "loss": 0.0001,
      "step": 32120
    },
    {
      "epoch": 3.442622950819672,
      "grad_norm": 0.1298712193965912,
      "learning_rate": 1.5409836065573772e-05,
      "loss": 0.3342,
      "step": 32130
    },
    {
      "epoch": 3.4436944176577735,
      "grad_norm": 0.05854101479053497,
      "learning_rate": 1.540840744312297e-05,
      "loss": 0.0015,
      "step": 32140
    },
    {
      "epoch": 3.444765884495875,
      "grad_norm": 0.002056922996416688,
      "learning_rate": 1.5406978820672167e-05,
      "loss": 0.1883,
      "step": 32150
    },
    {
      "epoch": 3.445837351333976,
      "grad_norm": 0.003138479311019182,
      "learning_rate": 1.5405550198221366e-05,
      "loss": 0.0003,
      "step": 32160
    },
    {
      "epoch": 3.4469088181720777,
      "grad_norm": 0.08324471861124039,
      "learning_rate": 1.5404121575770566e-05,
      "loss": 0.1673,
      "step": 32170
    },
    {
      "epoch": 3.447980285010179,
      "grad_norm": 0.19092018902301788,
      "learning_rate": 1.5402692953319762e-05,
      "loss": 0.0009,
      "step": 32180
    },
    {
      "epoch": 3.4490517518482804,
      "grad_norm": 16.192840576171875,
      "learning_rate": 1.540126433086896e-05,
      "loss": 0.3031,
      "step": 32190
    },
    {
      "epoch": 3.4501232186863815,
      "grad_norm": 0.055802397429943085,
      "learning_rate": 1.5399835708418157e-05,
      "loss": 0.0009,
      "step": 32200
    },
    {
      "epoch": 3.451194685524483,
      "grad_norm": 0.2143034040927887,
      "learning_rate": 1.5398407085967357e-05,
      "loss": 0.1416,
      "step": 32210
    },
    {
      "epoch": 3.4522661523625846,
      "grad_norm": 0.002883773297071457,
      "learning_rate": 1.5396978463516556e-05,
      "loss": 0.0006,
      "step": 32220
    },
    {
      "epoch": 3.4533376192006857,
      "grad_norm": 0.003747665323317051,
      "learning_rate": 1.5395549841065752e-05,
      "loss": 0.2483,
      "step": 32230
    },
    {
      "epoch": 3.4544090860387873,
      "grad_norm": 0.02531861513853073,
      "learning_rate": 1.539412121861495e-05,
      "loss": 0.3468,
      "step": 32240
    },
    {
      "epoch": 3.4554805528768884,
      "grad_norm": 0.014841896481812,
      "learning_rate": 1.539269259616415e-05,
      "loss": 0.6214,
      "step": 32250
    },
    {
      "epoch": 3.45655201971499,
      "grad_norm": 0.013072430156171322,
      "learning_rate": 1.539126397371335e-05,
      "loss": 0.2193,
      "step": 32260
    },
    {
      "epoch": 3.457623486553091,
      "grad_norm": 0.011648216284811497,
      "learning_rate": 1.5389835351262546e-05,
      "loss": 0.1684,
      "step": 32270
    },
    {
      "epoch": 3.4586949533911926,
      "grad_norm": 0.10593511164188385,
      "learning_rate": 1.5388406728811745e-05,
      "loss": 0.0018,
      "step": 32280
    },
    {
      "epoch": 3.459766420229294,
      "grad_norm": 0.05571248009800911,
      "learning_rate": 1.5386978106360945e-05,
      "loss": 0.0027,
      "step": 32290
    },
    {
      "epoch": 3.4608378870673953,
      "grad_norm": 0.029555177316069603,
      "learning_rate": 1.538554948391014e-05,
      "loss": 0.0014,
      "step": 32300
    },
    {
      "epoch": 3.461909353905497,
      "grad_norm": 0.00987253524363041,
      "learning_rate": 1.538412086145934e-05,
      "loss": 0.1902,
      "step": 32310
    },
    {
      "epoch": 3.462980820743598,
      "grad_norm": 0.0048207733780145645,
      "learning_rate": 1.5382692239008536e-05,
      "loss": 0.0006,
      "step": 32320
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 0.15213599801063538,
      "learning_rate": 1.5381263616557735e-05,
      "loss": 0.0005,
      "step": 32330
    },
    {
      "epoch": 3.4651237544198006,
      "grad_norm": 0.0033249591942876577,
      "learning_rate": 1.5379834994106935e-05,
      "loss": 0.0004,
      "step": 32340
    },
    {
      "epoch": 3.466195221257902,
      "grad_norm": 0.010892337188124657,
      "learning_rate": 1.537840637165613e-05,
      "loss": 0.0004,
      "step": 32350
    },
    {
      "epoch": 3.4672666880960032,
      "grad_norm": 0.0028517385944724083,
      "learning_rate": 1.537697774920533e-05,
      "loss": 0.0008,
      "step": 32360
    },
    {
      "epoch": 3.468338154934105,
      "grad_norm": 0.0024487427435815334,
      "learning_rate": 1.5375549126754526e-05,
      "loss": 0.1802,
      "step": 32370
    },
    {
      "epoch": 3.469409621772206,
      "grad_norm": 0.004937222693115473,
      "learning_rate": 1.5374120504303725e-05,
      "loss": 0.2566,
      "step": 32380
    },
    {
      "epoch": 3.4704810886103075,
      "grad_norm": 0.025224095210433006,
      "learning_rate": 1.5372691881852925e-05,
      "loss": 0.161,
      "step": 32390
    },
    {
      "epoch": 3.471552555448409,
      "grad_norm": 0.02519947849214077,
      "learning_rate": 1.5371263259402124e-05,
      "loss": 0.1551,
      "step": 32400
    },
    {
      "epoch": 3.47262402228651,
      "grad_norm": 0.047876570373773575,
      "learning_rate": 1.5369834636951324e-05,
      "loss": 0.2476,
      "step": 32410
    },
    {
      "epoch": 3.4736954891246117,
      "grad_norm": 0.06598926335573196,
      "learning_rate": 1.536840601450052e-05,
      "loss": 0.0017,
      "step": 32420
    },
    {
      "epoch": 3.474766955962713,
      "grad_norm": 0.08099706470966339,
      "learning_rate": 1.536697739204972e-05,
      "loss": 0.2155,
      "step": 32430
    },
    {
      "epoch": 3.4758384228008143,
      "grad_norm": 0.11222977936267853,
      "learning_rate": 1.5365548769598915e-05,
      "loss": 0.0011,
      "step": 32440
    },
    {
      "epoch": 3.4769098896389155,
      "grad_norm": 0.044903457164764404,
      "learning_rate": 1.5364120147148114e-05,
      "loss": 0.3063,
      "step": 32450
    },
    {
      "epoch": 3.477981356477017,
      "grad_norm": 0.009757046587765217,
      "learning_rate": 1.5362691524697314e-05,
      "loss": 0.0008,
      "step": 32460
    },
    {
      "epoch": 3.4790528233151186,
      "grad_norm": 0.010107154957950115,
      "learning_rate": 1.536126290224651e-05,
      "loss": 0.0012,
      "step": 32470
    },
    {
      "epoch": 3.4801242901532197,
      "grad_norm": 39.86919403076172,
      "learning_rate": 1.535983427979571e-05,
      "loss": 0.2892,
      "step": 32480
    },
    {
      "epoch": 3.481195756991321,
      "grad_norm": 0.010203019715845585,
      "learning_rate": 1.5358405657344905e-05,
      "loss": 0.3637,
      "step": 32490
    },
    {
      "epoch": 3.4822672238294223,
      "grad_norm": 0.013675716705620289,
      "learning_rate": 1.5356977034894104e-05,
      "loss": 0.332,
      "step": 32500
    },
    {
      "epoch": 3.483338690667524,
      "grad_norm": 0.1551566869020462,
      "learning_rate": 1.53555484124433e-05,
      "loss": 0.0049,
      "step": 32510
    },
    {
      "epoch": 3.484410157505625,
      "grad_norm": 0.18147212266921997,
      "learning_rate": 1.53541197899925e-05,
      "loss": 0.0035,
      "step": 32520
    },
    {
      "epoch": 3.4854816243437265,
      "grad_norm": 0.09513101726770401,
      "learning_rate": 1.53526911675417e-05,
      "loss": 0.2635,
      "step": 32530
    },
    {
      "epoch": 3.486553091181828,
      "grad_norm": 0.011954480782151222,
      "learning_rate": 1.53512625450909e-05,
      "loss": 0.2027,
      "step": 32540
    },
    {
      "epoch": 3.487624558019929,
      "grad_norm": 68.48026275634766,
      "learning_rate": 1.5349833922640098e-05,
      "loss": 0.1726,
      "step": 32550
    },
    {
      "epoch": 3.4886960248580308,
      "grad_norm": 0.004839789122343063,
      "learning_rate": 1.5348405300189294e-05,
      "loss": 0.0007,
      "step": 32560
    },
    {
      "epoch": 3.489767491696132,
      "grad_norm": 0.18477623164653778,
      "learning_rate": 1.5346976677738493e-05,
      "loss": 0.0013,
      "step": 32570
    },
    {
      "epoch": 3.4908389585342334,
      "grad_norm": 0.26387131214141846,
      "learning_rate": 1.5345548055287692e-05,
      "loss": 0.0011,
      "step": 32580
    },
    {
      "epoch": 3.4919104253723345,
      "grad_norm": 0.003977837041020393,
      "learning_rate": 1.534411943283689e-05,
      "loss": 0.0006,
      "step": 32590
    },
    {
      "epoch": 3.492981892210436,
      "grad_norm": 29.42534065246582,
      "learning_rate": 1.5342690810386088e-05,
      "loss": 0.3539,
      "step": 32600
    },
    {
      "epoch": 3.4940533590485376,
      "grad_norm": 99.25800323486328,
      "learning_rate": 1.5341262187935284e-05,
      "loss": 0.4928,
      "step": 32610
    },
    {
      "epoch": 3.4951248258866388,
      "grad_norm": 36.2054328918457,
      "learning_rate": 1.5339833565484483e-05,
      "loss": 0.1617,
      "step": 32620
    },
    {
      "epoch": 3.4961962927247403,
      "grad_norm": 0.006477226968854666,
      "learning_rate": 1.533840494303368e-05,
      "loss": 0.0005,
      "step": 32630
    },
    {
      "epoch": 3.4972677595628414,
      "grad_norm": 0.005435611121356487,
      "learning_rate": 1.533697632058288e-05,
      "loss": 0.1199,
      "step": 32640
    },
    {
      "epoch": 3.498339226400943,
      "grad_norm": 0.0038144777063280344,
      "learning_rate": 1.5335547698132078e-05,
      "loss": 0.331,
      "step": 32650
    },
    {
      "epoch": 3.499410693239044,
      "grad_norm": 0.27130359411239624,
      "learning_rate": 1.5334119075681274e-05,
      "loss": 0.0013,
      "step": 32660
    },
    {
      "epoch": 3.5004821600771456,
      "grad_norm": 0.2764263451099396,
      "learning_rate": 1.5332690453230473e-05,
      "loss": 0.195,
      "step": 32670
    },
    {
      "epoch": 3.501553626915247,
      "grad_norm": 0.00949122291058302,
      "learning_rate": 1.5331261830779673e-05,
      "loss": 0.0008,
      "step": 32680
    },
    {
      "epoch": 3.5026250937533483,
      "grad_norm": 0.0433121919631958,
      "learning_rate": 1.5329833208328872e-05,
      "loss": 0.0007,
      "step": 32690
    },
    {
      "epoch": 3.50369656059145,
      "grad_norm": 0.060563825070858,
      "learning_rate": 1.5328404585878068e-05,
      "loss": 0.1569,
      "step": 32700
    },
    {
      "epoch": 3.504768027429551,
      "grad_norm": 0.00473435502499342,
      "learning_rate": 1.5326975963427267e-05,
      "loss": 0.1626,
      "step": 32710
    },
    {
      "epoch": 3.5058394942676525,
      "grad_norm": 0.005698349326848984,
      "learning_rate": 1.5325547340976467e-05,
      "loss": 0.172,
      "step": 32720
    },
    {
      "epoch": 3.5069109611057536,
      "grad_norm": 1.68193519115448,
      "learning_rate": 1.5324118718525663e-05,
      "loss": 0.086,
      "step": 32730
    },
    {
      "epoch": 3.507982427943855,
      "grad_norm": 17.806930541992188,
      "learning_rate": 1.5322690096074862e-05,
      "loss": 0.1442,
      "step": 32740
    },
    {
      "epoch": 3.5090538947819567,
      "grad_norm": 0.08562367409467697,
      "learning_rate": 1.5321261473624058e-05,
      "loss": 0.4609,
      "step": 32750
    },
    {
      "epoch": 3.510125361620058,
      "grad_norm": 0.23746468126773834,
      "learning_rate": 1.5319832851173257e-05,
      "loss": 0.1509,
      "step": 32760
    },
    {
      "epoch": 3.511196828458159,
      "grad_norm": 0.03581637144088745,
      "learning_rate": 1.5318404228722457e-05,
      "loss": 0.002,
      "step": 32770
    },
    {
      "epoch": 3.5122682952962605,
      "grad_norm": 0.0025047447998076677,
      "learning_rate": 1.5316975606271653e-05,
      "loss": 0.468,
      "step": 32780
    },
    {
      "epoch": 3.513339762134362,
      "grad_norm": 47.12289047241211,
      "learning_rate": 1.5315546983820852e-05,
      "loss": 0.3018,
      "step": 32790
    },
    {
      "epoch": 3.514411228972463,
      "grad_norm": 0.06117485091090202,
      "learning_rate": 1.5314118361370048e-05,
      "loss": 0.0008,
      "step": 32800
    },
    {
      "epoch": 3.5154826958105647,
      "grad_norm": 0.10604803264141083,
      "learning_rate": 1.5312689738919247e-05,
      "loss": 0.347,
      "step": 32810
    },
    {
      "epoch": 3.5165541626486663,
      "grad_norm": 24.69767951965332,
      "learning_rate": 1.5311261116468447e-05,
      "loss": 0.3372,
      "step": 32820
    },
    {
      "epoch": 3.5176256294867674,
      "grad_norm": 0.14738449454307556,
      "learning_rate": 1.5309832494017646e-05,
      "loss": 0.1448,
      "step": 32830
    },
    {
      "epoch": 3.5186970963248685,
      "grad_norm": 0.01341263484209776,
      "learning_rate": 1.5308403871566842e-05,
      "loss": 0.1934,
      "step": 32840
    },
    {
      "epoch": 3.51976856316297,
      "grad_norm": 0.002278857631608844,
      "learning_rate": 1.530697524911604e-05,
      "loss": 0.1401,
      "step": 32850
    },
    {
      "epoch": 3.5208400300010716,
      "grad_norm": 0.005218320991843939,
      "learning_rate": 1.530554662666524e-05,
      "loss": 0.0038,
      "step": 32860
    },
    {
      "epoch": 3.5219114968391727,
      "grad_norm": 1.6166404485702515,
      "learning_rate": 1.5304118004214437e-05,
      "loss": 0.489,
      "step": 32870
    },
    {
      "epoch": 3.5229829636772743,
      "grad_norm": 0.11157851666212082,
      "learning_rate": 1.5302689381763636e-05,
      "loss": 0.0007,
      "step": 32880
    },
    {
      "epoch": 3.524054430515376,
      "grad_norm": 0.0038854843005537987,
      "learning_rate": 1.5301260759312836e-05,
      "loss": 0.1219,
      "step": 32890
    },
    {
      "epoch": 3.525125897353477,
      "grad_norm": 0.1479514092206955,
      "learning_rate": 1.529983213686203e-05,
      "loss": 0.1341,
      "step": 32900
    },
    {
      "epoch": 3.526197364191578,
      "grad_norm": 0.004886608570814133,
      "learning_rate": 1.529840351441123e-05,
      "loss": 0.0002,
      "step": 32910
    },
    {
      "epoch": 3.5272688310296796,
      "grad_norm": 0.002170796738937497,
      "learning_rate": 1.5296974891960427e-05,
      "loss": 0.001,
      "step": 32920
    },
    {
      "epoch": 3.528340297867781,
      "grad_norm": 17.328502655029297,
      "learning_rate": 1.5295546269509626e-05,
      "loss": 0.8311,
      "step": 32930
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.007907482795417309,
      "learning_rate": 1.5294117647058822e-05,
      "loss": 0.2461,
      "step": 32940
    },
    {
      "epoch": 3.530483231543984,
      "grad_norm": 0.004548551049083471,
      "learning_rate": 1.529268902460802e-05,
      "loss": 0.1553,
      "step": 32950
    },
    {
      "epoch": 3.531554698382085,
      "grad_norm": 0.018032895401120186,
      "learning_rate": 1.529126040215722e-05,
      "loss": 0.132,
      "step": 32960
    },
    {
      "epoch": 3.5326261652201865,
      "grad_norm": 0.016677742823958397,
      "learning_rate": 1.528983177970642e-05,
      "loss": 0.0015,
      "step": 32970
    },
    {
      "epoch": 3.5336976320582876,
      "grad_norm": 0.0031058622989803553,
      "learning_rate": 1.528840315725562e-05,
      "loss": 0.0017,
      "step": 32980
    },
    {
      "epoch": 3.534769098896389,
      "grad_norm": 0.003987510688602924,
      "learning_rate": 1.5286974534804816e-05,
      "loss": 0.0023,
      "step": 32990
    },
    {
      "epoch": 3.5358405657344907,
      "grad_norm": 0.04990534484386444,
      "learning_rate": 1.5285545912354015e-05,
      "loss": 0.0006,
      "step": 33000
    },
    {
      "epoch": 3.536912032572592,
      "grad_norm": 14.058303833007812,
      "learning_rate": 1.5284117289903214e-05,
      "loss": 0.1376,
      "step": 33010
    },
    {
      "epoch": 3.5379834994106933,
      "grad_norm": 0.0017279500607401133,
      "learning_rate": 1.528268866745241e-05,
      "loss": 0.3293,
      "step": 33020
    },
    {
      "epoch": 3.5390549662487945,
      "grad_norm": 0.0018426080932840705,
      "learning_rate": 1.528126004500161e-05,
      "loss": 0.3705,
      "step": 33030
    },
    {
      "epoch": 3.540126433086896,
      "grad_norm": 0.0038732001557946205,
      "learning_rate": 1.5279831422550806e-05,
      "loss": 0.0998,
      "step": 33040
    },
    {
      "epoch": 3.541197899924997,
      "grad_norm": 0.004212318919599056,
      "learning_rate": 1.5278402800100005e-05,
      "loss": 0.003,
      "step": 33050
    },
    {
      "epoch": 3.5422693667630987,
      "grad_norm": 0.0033511973451822996,
      "learning_rate": 1.52769741776492e-05,
      "loss": 0.001,
      "step": 33060
    },
    {
      "epoch": 3.5433408336012002,
      "grad_norm": 0.03650758042931557,
      "learning_rate": 1.52755455551984e-05,
      "loss": 0.001,
      "step": 33070
    },
    {
      "epoch": 3.5444123004393013,
      "grad_norm": 0.04021771624684334,
      "learning_rate": 1.52741169327476e-05,
      "loss": 0.0007,
      "step": 33080
    },
    {
      "epoch": 3.545483767277403,
      "grad_norm": 0.033470410853624344,
      "learning_rate": 1.5272688310296796e-05,
      "loss": 0.0007,
      "step": 33090
    },
    {
      "epoch": 3.546555234115504,
      "grad_norm": 45.957740783691406,
      "learning_rate": 1.5271259687845995e-05,
      "loss": 0.5295,
      "step": 33100
    },
    {
      "epoch": 3.5476267009536055,
      "grad_norm": 16.203235626220703,
      "learning_rate": 1.5269831065395194e-05,
      "loss": 0.5631,
      "step": 33110
    },
    {
      "epoch": 3.5486981677917067,
      "grad_norm": 0.002002112800255418,
      "learning_rate": 1.5268402442944394e-05,
      "loss": 0.2074,
      "step": 33120
    },
    {
      "epoch": 3.549769634629808,
      "grad_norm": 0.002593387383967638,
      "learning_rate": 1.526697382049359e-05,
      "loss": 0.1862,
      "step": 33130
    },
    {
      "epoch": 3.5508411014679098,
      "grad_norm": 14.790818214416504,
      "learning_rate": 1.526554519804279e-05,
      "loss": 0.1753,
      "step": 33140
    },
    {
      "epoch": 3.551912568306011,
      "grad_norm": 0.0373811200261116,
      "learning_rate": 1.526411657559199e-05,
      "loss": 0.1135,
      "step": 33150
    },
    {
      "epoch": 3.5529840351441124,
      "grad_norm": 0.0016524356324225664,
      "learning_rate": 1.5262687953141185e-05,
      "loss": 0.2065,
      "step": 33160
    },
    {
      "epoch": 3.5540555019822135,
      "grad_norm": 0.15283533930778503,
      "learning_rate": 1.5261259330690384e-05,
      "loss": 0.1245,
      "step": 33170
    },
    {
      "epoch": 3.555126968820315,
      "grad_norm": 20.18744468688965,
      "learning_rate": 1.525983070823958e-05,
      "loss": 0.1603,
      "step": 33180
    },
    {
      "epoch": 3.556198435658416,
      "grad_norm": 0.21714968979358673,
      "learning_rate": 1.525840208578878e-05,
      "loss": 0.0007,
      "step": 33190
    },
    {
      "epoch": 3.5572699024965178,
      "grad_norm": 0.001357054803520441,
      "learning_rate": 1.5256973463337979e-05,
      "loss": 0.0019,
      "step": 33200
    },
    {
      "epoch": 3.5583413693346193,
      "grad_norm": 0.07426277548074722,
      "learning_rate": 1.5255544840887175e-05,
      "loss": 0.001,
      "step": 33210
    },
    {
      "epoch": 3.5594128361727204,
      "grad_norm": 0.08325155079364777,
      "learning_rate": 1.5254116218436374e-05,
      "loss": 0.1732,
      "step": 33220
    },
    {
      "epoch": 3.560484303010822,
      "grad_norm": 0.2582028806209564,
      "learning_rate": 1.5252687595985572e-05,
      "loss": 0.4461,
      "step": 33230
    },
    {
      "epoch": 3.561555769848923,
      "grad_norm": 0.0009808021131902933,
      "learning_rate": 1.5251258973534771e-05,
      "loss": 0.0005,
      "step": 33240
    },
    {
      "epoch": 3.5626272366870246,
      "grad_norm": 0.07652046531438828,
      "learning_rate": 1.524983035108397e-05,
      "loss": 0.0035,
      "step": 33250
    },
    {
      "epoch": 3.5636987035251257,
      "grad_norm": 0.06719397008419037,
      "learning_rate": 1.5248401728633166e-05,
      "loss": 0.1753,
      "step": 33260
    },
    {
      "epoch": 3.5647701703632273,
      "grad_norm": 0.0013957308838143945,
      "learning_rate": 1.5246973106182366e-05,
      "loss": 0.1654,
      "step": 33270
    },
    {
      "epoch": 3.565841637201329,
      "grad_norm": 0.0017081619007512927,
      "learning_rate": 1.5245544483731562e-05,
      "loss": 0.1824,
      "step": 33280
    },
    {
      "epoch": 3.56691310403943,
      "grad_norm": 0.003085741540417075,
      "learning_rate": 1.5244115861280761e-05,
      "loss": 0.0004,
      "step": 33290
    },
    {
      "epoch": 3.567984570877531,
      "grad_norm": 0.0018122902838513255,
      "learning_rate": 1.5242687238829959e-05,
      "loss": 0.0006,
      "step": 33300
    },
    {
      "epoch": 3.5690560377156326,
      "grad_norm": 0.0018923406023532152,
      "learning_rate": 1.5241258616379158e-05,
      "loss": 0.3531,
      "step": 33310
    },
    {
      "epoch": 3.570127504553734,
      "grad_norm": 0.15847495198249817,
      "learning_rate": 1.5239829993928357e-05,
      "loss": 0.4118,
      "step": 33320
    },
    {
      "epoch": 3.5711989713918353,
      "grad_norm": 0.22898714244365692,
      "learning_rate": 1.5238401371477553e-05,
      "loss": 0.0018,
      "step": 33330
    },
    {
      "epoch": 3.572270438229937,
      "grad_norm": 0.04148377850651741,
      "learning_rate": 1.5236972749026753e-05,
      "loss": 0.1449,
      "step": 33340
    },
    {
      "epoch": 3.5733419050680384,
      "grad_norm": 0.0054078903049230576,
      "learning_rate": 1.5235544126575949e-05,
      "loss": 0.0015,
      "step": 33350
    },
    {
      "epoch": 3.5744133719061395,
      "grad_norm": 0.0011372610460966825,
      "learning_rate": 1.5234115504125148e-05,
      "loss": 0.1246,
      "step": 33360
    },
    {
      "epoch": 3.5754848387442406,
      "grad_norm": 0.001354634528979659,
      "learning_rate": 1.5232686881674348e-05,
      "loss": 0.0003,
      "step": 33370
    },
    {
      "epoch": 3.576556305582342,
      "grad_norm": 0.03652692586183548,
      "learning_rate": 1.5231258259223545e-05,
      "loss": 0.2169,
      "step": 33380
    },
    {
      "epoch": 3.5776277724204437,
      "grad_norm": 0.001725135138258338,
      "learning_rate": 1.5229829636772745e-05,
      "loss": 0.1532,
      "step": 33390
    },
    {
      "epoch": 3.578699239258545,
      "grad_norm": 0.024974215775728226,
      "learning_rate": 1.522840101432194e-05,
      "loss": 0.1409,
      "step": 33400
    },
    {
      "epoch": 3.5797707060966464,
      "grad_norm": 0.0016412872355431318,
      "learning_rate": 1.522697239187114e-05,
      "loss": 0.001,
      "step": 33410
    },
    {
      "epoch": 3.580842172934748,
      "grad_norm": 0.038537029176950455,
      "learning_rate": 1.5225543769420338e-05,
      "loss": 0.2124,
      "step": 33420
    },
    {
      "epoch": 3.581913639772849,
      "grad_norm": 0.0014277462614700198,
      "learning_rate": 1.5224115146969535e-05,
      "loss": 0.145,
      "step": 33430
    },
    {
      "epoch": 3.58298510661095,
      "grad_norm": 0.0008027849835343659,
      "learning_rate": 1.5222686524518735e-05,
      "loss": 0.0005,
      "step": 33440
    },
    {
      "epoch": 3.5840565734490517,
      "grad_norm": 0.09322632849216461,
      "learning_rate": 1.5221257902067932e-05,
      "loss": 0.1605,
      "step": 33450
    },
    {
      "epoch": 3.5851280402871533,
      "grad_norm": 0.000719857809599489,
      "learning_rate": 1.5219829279617132e-05,
      "loss": 0.0012,
      "step": 33460
    },
    {
      "epoch": 3.5861995071252544,
      "grad_norm": 0.001001186785288155,
      "learning_rate": 1.5218400657166328e-05,
      "loss": 0.0003,
      "step": 33470
    },
    {
      "epoch": 3.587270973963356,
      "grad_norm": 0.05467165634036064,
      "learning_rate": 1.5216972034715527e-05,
      "loss": 0.7845,
      "step": 33480
    },
    {
      "epoch": 3.588342440801457,
      "grad_norm": 0.5606588125228882,
      "learning_rate": 1.5215543412264726e-05,
      "loss": 0.1521,
      "step": 33490
    },
    {
      "epoch": 3.5894139076395586,
      "grad_norm": 0.0012738885125145316,
      "learning_rate": 1.5214114789813922e-05,
      "loss": 0.1787,
      "step": 33500
    },
    {
      "epoch": 3.5904853744776597,
      "grad_norm": 0.24954922497272491,
      "learning_rate": 1.5212686167363122e-05,
      "loss": 0.0008,
      "step": 33510
    },
    {
      "epoch": 3.5915568413157613,
      "grad_norm": 0.0032744368072599173,
      "learning_rate": 1.521125754491232e-05,
      "loss": 0.4685,
      "step": 33520
    },
    {
      "epoch": 3.592628308153863,
      "grad_norm": 0.0016898013418540359,
      "learning_rate": 1.5209828922461519e-05,
      "loss": 0.002,
      "step": 33530
    },
    {
      "epoch": 3.593699774991964,
      "grad_norm": 0.8088538646697998,
      "learning_rate": 1.5208400300010715e-05,
      "loss": 0.1566,
      "step": 33540
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 0.001781489234417677,
      "learning_rate": 1.5206971677559914e-05,
      "loss": 0.3175,
      "step": 33550
    },
    {
      "epoch": 3.5958427086681666,
      "grad_norm": 0.004242719151079655,
      "learning_rate": 1.5205543055109113e-05,
      "loss": 0.0014,
      "step": 33560
    },
    {
      "epoch": 3.596914175506268,
      "grad_norm": 0.017139527946710587,
      "learning_rate": 1.520411443265831e-05,
      "loss": 0.1548,
      "step": 33570
    },
    {
      "epoch": 3.5979856423443692,
      "grad_norm": 0.1046346053481102,
      "learning_rate": 1.5202685810207509e-05,
      "loss": 0.0008,
      "step": 33580
    },
    {
      "epoch": 3.599057109182471,
      "grad_norm": 0.0022918852046132088,
      "learning_rate": 1.5201257187756706e-05,
      "loss": 0.0006,
      "step": 33590
    },
    {
      "epoch": 3.6001285760205723,
      "grad_norm": 0.0044025336392223835,
      "learning_rate": 1.5199828565305906e-05,
      "loss": 0.0007,
      "step": 33600
    },
    {
      "epoch": 3.6012000428586735,
      "grad_norm": 94.84817504882812,
      "learning_rate": 1.5198399942855102e-05,
      "loss": 0.549,
      "step": 33610
    },
    {
      "epoch": 3.602271509696775,
      "grad_norm": 0.0020041712559759617,
      "learning_rate": 1.5196971320404301e-05,
      "loss": 0.7407,
      "step": 33620
    },
    {
      "epoch": 3.603342976534876,
      "grad_norm": 0.06314957141876221,
      "learning_rate": 1.51955426979535e-05,
      "loss": 0.2338,
      "step": 33630
    },
    {
      "epoch": 3.6044144433729777,
      "grad_norm": 0.03665541112422943,
      "learning_rate": 1.5194114075502697e-05,
      "loss": 0.0007,
      "step": 33640
    },
    {
      "epoch": 3.605485910211079,
      "grad_norm": 33.80674362182617,
      "learning_rate": 1.5192685453051896e-05,
      "loss": 0.316,
      "step": 33650
    },
    {
      "epoch": 3.6065573770491803,
      "grad_norm": 15.723440170288086,
      "learning_rate": 1.5191256830601094e-05,
      "loss": 0.7423,
      "step": 33660
    },
    {
      "epoch": 3.607628843887282,
      "grad_norm": 0.1990136057138443,
      "learning_rate": 1.5189828208150293e-05,
      "loss": 0.1327,
      "step": 33670
    },
    {
      "epoch": 3.608700310725383,
      "grad_norm": 0.4489732086658478,
      "learning_rate": 1.5188399585699492e-05,
      "loss": 0.0025,
      "step": 33680
    },
    {
      "epoch": 3.6097717775634846,
      "grad_norm": 0.36220288276672363,
      "learning_rate": 1.5186970963248688e-05,
      "loss": 0.0005,
      "step": 33690
    },
    {
      "epoch": 3.6108432444015857,
      "grad_norm": 0.05199460685253143,
      "learning_rate": 1.5185542340797888e-05,
      "loss": 0.3938,
      "step": 33700
    },
    {
      "epoch": 3.611914711239687,
      "grad_norm": 0.004933943040668964,
      "learning_rate": 1.5184113718347084e-05,
      "loss": 0.001,
      "step": 33710
    },
    {
      "epoch": 3.6129861780777883,
      "grad_norm": 0.0031550107523798943,
      "learning_rate": 1.5182685095896283e-05,
      "loss": 0.0012,
      "step": 33720
    },
    {
      "epoch": 3.61405764491589,
      "grad_norm": 0.0054688286036252975,
      "learning_rate": 1.518125647344548e-05,
      "loss": 0.3825,
      "step": 33730
    },
    {
      "epoch": 3.6151291117539914,
      "grad_norm": 16.34320831298828,
      "learning_rate": 1.517982785099468e-05,
      "loss": 0.2113,
      "step": 33740
    },
    {
      "epoch": 3.6162005785920925,
      "grad_norm": 0.022360382601618767,
      "learning_rate": 1.517839922854388e-05,
      "loss": 0.0004,
      "step": 33750
    },
    {
      "epoch": 3.617272045430194,
      "grad_norm": 0.003371910657733679,
      "learning_rate": 1.5176970606093075e-05,
      "loss": 0.0022,
      "step": 33760
    },
    {
      "epoch": 3.618343512268295,
      "grad_norm": 0.6839472651481628,
      "learning_rate": 1.5175541983642275e-05,
      "loss": 0.0017,
      "step": 33770
    },
    {
      "epoch": 3.6194149791063968,
      "grad_norm": 0.059990111738443375,
      "learning_rate": 1.517411336119147e-05,
      "loss": 0.001,
      "step": 33780
    },
    {
      "epoch": 3.620486445944498,
      "grad_norm": 0.0017044238047674298,
      "learning_rate": 1.517268473874067e-05,
      "loss": 0.0018,
      "step": 33790
    },
    {
      "epoch": 3.6215579127825994,
      "grad_norm": 0.01543295569717884,
      "learning_rate": 1.517125611628987e-05,
      "loss": 0.1542,
      "step": 33800
    },
    {
      "epoch": 3.622629379620701,
      "grad_norm": 0.02175995148718357,
      "learning_rate": 1.5169827493839067e-05,
      "loss": 0.001,
      "step": 33810
    },
    {
      "epoch": 3.623700846458802,
      "grad_norm": 0.025620827451348305,
      "learning_rate": 1.5168398871388266e-05,
      "loss": 0.0008,
      "step": 33820
    },
    {
      "epoch": 3.624772313296903,
      "grad_norm": 0.0022999891079962254,
      "learning_rate": 1.5166970248937462e-05,
      "loss": 0.3384,
      "step": 33830
    },
    {
      "epoch": 3.6258437801350047,
      "grad_norm": 0.0013106694677844644,
      "learning_rate": 1.5165541626486662e-05,
      "loss": 0.1479,
      "step": 33840
    },
    {
      "epoch": 3.6269152469731063,
      "grad_norm": 0.0015515665290877223,
      "learning_rate": 1.5164113004035858e-05,
      "loss": 0.0001,
      "step": 33850
    },
    {
      "epoch": 3.6279867138112074,
      "grad_norm": 0.036290813237428665,
      "learning_rate": 1.5162684381585057e-05,
      "loss": 0.1932,
      "step": 33860
    },
    {
      "epoch": 3.629058180649309,
      "grad_norm": 0.0016522526275366545,
      "learning_rate": 1.5161255759134257e-05,
      "loss": 0.0003,
      "step": 33870
    },
    {
      "epoch": 3.6301296474874105,
      "grad_norm": 0.08453596383333206,
      "learning_rate": 1.5159827136683454e-05,
      "loss": 0.4358,
      "step": 33880
    },
    {
      "epoch": 3.6312011143255116,
      "grad_norm": 0.002185870660468936,
      "learning_rate": 1.5158398514232654e-05,
      "loss": 0.5978,
      "step": 33890
    },
    {
      "epoch": 3.6322725811636127,
      "grad_norm": 0.004302771296352148,
      "learning_rate": 1.515696989178185e-05,
      "loss": 0.3121,
      "step": 33900
    },
    {
      "epoch": 3.6333440480017143,
      "grad_norm": 0.2864070534706116,
      "learning_rate": 1.5155541269331049e-05,
      "loss": 0.135,
      "step": 33910
    },
    {
      "epoch": 3.634415514839816,
      "grad_norm": 0.008099481463432312,
      "learning_rate": 1.5154112646880248e-05,
      "loss": 0.172,
      "step": 33920
    },
    {
      "epoch": 3.635486981677917,
      "grad_norm": 0.04300360009074211,
      "learning_rate": 1.5152684024429444e-05,
      "loss": 0.0007,
      "step": 33930
    },
    {
      "epoch": 3.6365584485160185,
      "grad_norm": 0.004969177767634392,
      "learning_rate": 1.5151255401978644e-05,
      "loss": 0.3166,
      "step": 33940
    },
    {
      "epoch": 3.63762991535412,
      "grad_norm": 0.06675703078508377,
      "learning_rate": 1.5149826779527841e-05,
      "loss": 0.1296,
      "step": 33950
    },
    {
      "epoch": 3.638701382192221,
      "grad_norm": 0.022438615560531616,
      "learning_rate": 1.514839815707704e-05,
      "loss": 0.0017,
      "step": 33960
    },
    {
      "epoch": 3.6397728490303223,
      "grad_norm": 0.030026204884052277,
      "learning_rate": 1.5146969534626237e-05,
      "loss": 0.3068,
      "step": 33970
    },
    {
      "epoch": 3.640844315868424,
      "grad_norm": 0.0429898165166378,
      "learning_rate": 1.5145540912175436e-05,
      "loss": 0.0012,
      "step": 33980
    },
    {
      "epoch": 3.6419157827065254,
      "grad_norm": 0.0022222939878702164,
      "learning_rate": 1.5144112289724635e-05,
      "loss": 0.0029,
      "step": 33990
    },
    {
      "epoch": 3.6429872495446265,
      "grad_norm": 0.008699549362063408,
      "learning_rate": 1.5142683667273831e-05,
      "loss": 0.0015,
      "step": 34000
    },
    {
      "epoch": 3.644058716382728,
      "grad_norm": 0.1925574094057083,
      "learning_rate": 1.514125504482303e-05,
      "loss": 0.0005,
      "step": 34010
    },
    {
      "epoch": 3.645130183220829,
      "grad_norm": 0.0021146454382687807,
      "learning_rate": 1.5139826422372228e-05,
      "loss": 0.0012,
      "step": 34020
    },
    {
      "epoch": 3.6462016500589307,
      "grad_norm": 0.0013219675747677684,
      "learning_rate": 1.5138397799921428e-05,
      "loss": 0.1571,
      "step": 34030
    },
    {
      "epoch": 3.647273116897032,
      "grad_norm": 0.00203518895432353,
      "learning_rate": 1.5136969177470625e-05,
      "loss": 0.0002,
      "step": 34040
    },
    {
      "epoch": 3.6483445837351334,
      "grad_norm": 0.05655033141374588,
      "learning_rate": 1.5135540555019823e-05,
      "loss": 0.4173,
      "step": 34050
    },
    {
      "epoch": 3.649416050573235,
      "grad_norm": 0.009162096306681633,
      "learning_rate": 1.5134111932569022e-05,
      "loss": 0.3581,
      "step": 34060
    },
    {
      "epoch": 3.650487517411336,
      "grad_norm": 0.003849429078400135,
      "learning_rate": 1.5132683310118218e-05,
      "loss": 0.2236,
      "step": 34070
    },
    {
      "epoch": 3.6515589842494376,
      "grad_norm": 19.179304122924805,
      "learning_rate": 1.5131254687667418e-05,
      "loss": 0.3725,
      "step": 34080
    },
    {
      "epoch": 3.6526304510875387,
      "grad_norm": 0.15237189829349518,
      "learning_rate": 1.5129826065216616e-05,
      "loss": 0.0016,
      "step": 34090
    },
    {
      "epoch": 3.6537019179256403,
      "grad_norm": 0.01778358593583107,
      "learning_rate": 1.5128397442765815e-05,
      "loss": 0.0008,
      "step": 34100
    },
    {
      "epoch": 3.6547733847637414,
      "grad_norm": 0.27293652296066284,
      "learning_rate": 1.5126968820315013e-05,
      "loss": 0.1725,
      "step": 34110
    },
    {
      "epoch": 3.655844851601843,
      "grad_norm": 0.023675674572587013,
      "learning_rate": 1.512554019786421e-05,
      "loss": 0.522,
      "step": 34120
    },
    {
      "epoch": 3.6569163184399445,
      "grad_norm": 0.24220594763755798,
      "learning_rate": 1.512411157541341e-05,
      "loss": 0.403,
      "step": 34130
    },
    {
      "epoch": 3.6579877852780456,
      "grad_norm": 0.004587196279317141,
      "learning_rate": 1.5122682952962606e-05,
      "loss": 0.512,
      "step": 34140
    },
    {
      "epoch": 3.659059252116147,
      "grad_norm": 0.0062837181612849236,
      "learning_rate": 1.5121254330511805e-05,
      "loss": 0.1675,
      "step": 34150
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 0.03874706104397774,
      "learning_rate": 1.5119825708061004e-05,
      "loss": 0.0016,
      "step": 34160
    },
    {
      "epoch": 3.66120218579235,
      "grad_norm": 0.05154465511441231,
      "learning_rate": 1.5118397085610202e-05,
      "loss": 0.1833,
      "step": 34170
    },
    {
      "epoch": 3.662273652630451,
      "grad_norm": 0.015166218392550945,
      "learning_rate": 1.51169684631594e-05,
      "loss": 0.0023,
      "step": 34180
    },
    {
      "epoch": 3.6633451194685525,
      "grad_norm": 0.0802033320069313,
      "learning_rate": 1.5115539840708597e-05,
      "loss": 0.0011,
      "step": 34190
    },
    {
      "epoch": 3.664416586306654,
      "grad_norm": 0.11397803574800491,
      "learning_rate": 1.5114111218257797e-05,
      "loss": 0.4433,
      "step": 34200
    },
    {
      "epoch": 3.665488053144755,
      "grad_norm": 0.013474246487021446,
      "learning_rate": 1.5112682595806993e-05,
      "loss": 0.448,
      "step": 34210
    },
    {
      "epoch": 3.6665595199828567,
      "grad_norm": 0.007250762078911066,
      "learning_rate": 1.5111253973356192e-05,
      "loss": 0.0011,
      "step": 34220
    },
    {
      "epoch": 3.667630986820958,
      "grad_norm": 21.70673179626465,
      "learning_rate": 1.5109825350905391e-05,
      "loss": 0.7463,
      "step": 34230
    },
    {
      "epoch": 3.6687024536590593,
      "grad_norm": 0.18337930738925934,
      "learning_rate": 1.5108396728454589e-05,
      "loss": 0.1409,
      "step": 34240
    },
    {
      "epoch": 3.6697739204971604,
      "grad_norm": 0.016893040388822556,
      "learning_rate": 1.5106968106003788e-05,
      "loss": 0.0022,
      "step": 34250
    },
    {
      "epoch": 3.670845387335262,
      "grad_norm": 0.02846396714448929,
      "learning_rate": 1.5105539483552984e-05,
      "loss": 0.2865,
      "step": 34260
    },
    {
      "epoch": 3.6719168541733636,
      "grad_norm": 0.3820819556713104,
      "learning_rate": 1.5104110861102184e-05,
      "loss": 0.0027,
      "step": 34270
    },
    {
      "epoch": 3.6729883210114647,
      "grad_norm": 23.027210235595703,
      "learning_rate": 1.5102682238651383e-05,
      "loss": 0.3928,
      "step": 34280
    },
    {
      "epoch": 3.674059787849566,
      "grad_norm": 0.013484185561537743,
      "learning_rate": 1.5101253616200579e-05,
      "loss": 0.0012,
      "step": 34290
    },
    {
      "epoch": 3.6751312546876673,
      "grad_norm": 29.124046325683594,
      "learning_rate": 1.5099824993749778e-05,
      "loss": 0.2761,
      "step": 34300
    },
    {
      "epoch": 3.676202721525769,
      "grad_norm": 0.06253668665885925,
      "learning_rate": 1.5098396371298976e-05,
      "loss": 0.001,
      "step": 34310
    },
    {
      "epoch": 3.67727418836387,
      "grad_norm": 0.00878931861370802,
      "learning_rate": 1.5096967748848176e-05,
      "loss": 0.0008,
      "step": 34320
    },
    {
      "epoch": 3.6783456552019715,
      "grad_norm": 0.24455077946186066,
      "learning_rate": 1.5095539126397372e-05,
      "loss": 0.1388,
      "step": 34330
    },
    {
      "epoch": 3.679417122040073,
      "grad_norm": 0.09394672513008118,
      "learning_rate": 1.5094110503946571e-05,
      "loss": 0.2215,
      "step": 34340
    },
    {
      "epoch": 3.680488588878174,
      "grad_norm": 0.0034675602801144123,
      "learning_rate": 1.509268188149577e-05,
      "loss": 0.2787,
      "step": 34350
    },
    {
      "epoch": 3.6815600557162753,
      "grad_norm": 0.034750796854496,
      "learning_rate": 1.5091253259044966e-05,
      "loss": 0.2971,
      "step": 34360
    },
    {
      "epoch": 3.682631522554377,
      "grad_norm": 0.15335918962955475,
      "learning_rate": 1.5089824636594166e-05,
      "loss": 0.0022,
      "step": 34370
    },
    {
      "epoch": 3.6837029893924784,
      "grad_norm": 0.049934275448322296,
      "learning_rate": 1.5088396014143363e-05,
      "loss": 0.0009,
      "step": 34380
    },
    {
      "epoch": 3.6847744562305795,
      "grad_norm": 0.19190926849842072,
      "learning_rate": 1.5086967391692563e-05,
      "loss": 0.002,
      "step": 34390
    },
    {
      "epoch": 3.685845923068681,
      "grad_norm": 30.686594009399414,
      "learning_rate": 1.508553876924176e-05,
      "loss": 0.1822,
      "step": 34400
    },
    {
      "epoch": 3.6869173899067826,
      "grad_norm": 0.011881311424076557,
      "learning_rate": 1.5084110146790958e-05,
      "loss": 0.0005,
      "step": 34410
    },
    {
      "epoch": 3.6879888567448837,
      "grad_norm": 0.014969450421631336,
      "learning_rate": 1.5082681524340157e-05,
      "loss": 0.0014,
      "step": 34420
    },
    {
      "epoch": 3.689060323582985,
      "grad_norm": 0.00400866474956274,
      "learning_rate": 1.5081252901889353e-05,
      "loss": 0.5776,
      "step": 34430
    },
    {
      "epoch": 3.6901317904210864,
      "grad_norm": 0.028647426515817642,
      "learning_rate": 1.5079824279438553e-05,
      "loss": 0.1719,
      "step": 34440
    },
    {
      "epoch": 3.691203257259188,
      "grad_norm": 0.007694078143686056,
      "learning_rate": 1.507839565698775e-05,
      "loss": 0.1672,
      "step": 34450
    },
    {
      "epoch": 3.692274724097289,
      "grad_norm": 0.004919624887406826,
      "learning_rate": 1.507696703453695e-05,
      "loss": 0.0005,
      "step": 34460
    },
    {
      "epoch": 3.6933461909353906,
      "grad_norm": 0.005292749963700771,
      "learning_rate": 1.5075538412086147e-05,
      "loss": 0.1982,
      "step": 34470
    },
    {
      "epoch": 3.694417657773492,
      "grad_norm": 0.02686602994799614,
      "learning_rate": 1.5074109789635345e-05,
      "loss": 0.001,
      "step": 34480
    },
    {
      "epoch": 3.6954891246115933,
      "grad_norm": 0.0021415348164737225,
      "learning_rate": 1.5072681167184544e-05,
      "loss": 0.531,
      "step": 34490
    },
    {
      "epoch": 3.6965605914496944,
      "grad_norm": 0.0036875330843031406,
      "learning_rate": 1.507125254473374e-05,
      "loss": 0.0012,
      "step": 34500
    },
    {
      "epoch": 3.697632058287796,
      "grad_norm": 316.3443908691406,
      "learning_rate": 1.506982392228294e-05,
      "loss": 0.1268,
      "step": 34510
    },
    {
      "epoch": 3.6987035251258975,
      "grad_norm": 0.0021147567313164473,
      "learning_rate": 1.5068395299832137e-05,
      "loss": 0.2146,
      "step": 34520
    },
    {
      "epoch": 3.6997749919639986,
      "grad_norm": 35.76372146606445,
      "learning_rate": 1.5066966677381337e-05,
      "loss": 0.6208,
      "step": 34530
    },
    {
      "epoch": 3.7008464588021,
      "grad_norm": 0.05928865820169449,
      "learning_rate": 1.5065538054930534e-05,
      "loss": 0.3073,
      "step": 34540
    },
    {
      "epoch": 3.7019179256402013,
      "grad_norm": 0.1767987310886383,
      "learning_rate": 1.5064109432479732e-05,
      "loss": 0.2672,
      "step": 34550
    },
    {
      "epoch": 3.702989392478303,
      "grad_norm": 0.006688750348985195,
      "learning_rate": 1.5062680810028932e-05,
      "loss": 0.003,
      "step": 34560
    },
    {
      "epoch": 3.704060859316404,
      "grad_norm": 0.008360538631677628,
      "learning_rate": 1.5061252187578128e-05,
      "loss": 0.286,
      "step": 34570
    },
    {
      "epoch": 3.7051323261545055,
      "grad_norm": 0.32155656814575195,
      "learning_rate": 1.5059823565127327e-05,
      "loss": 0.542,
      "step": 34580
    },
    {
      "epoch": 3.706203792992607,
      "grad_norm": 0.13230150938034058,
      "learning_rate": 1.5058394942676526e-05,
      "loss": 0.003,
      "step": 34590
    },
    {
      "epoch": 3.707275259830708,
      "grad_norm": 0.008389748632907867,
      "learning_rate": 1.5056966320225724e-05,
      "loss": 0.2502,
      "step": 34600
    },
    {
      "epoch": 3.7083467266688097,
      "grad_norm": 0.2746049165725708,
      "learning_rate": 1.5055537697774922e-05,
      "loss": 0.0032,
      "step": 34610
    },
    {
      "epoch": 3.709418193506911,
      "grad_norm": 0.40848207473754883,
      "learning_rate": 1.505410907532412e-05,
      "loss": 0.1322,
      "step": 34620
    },
    {
      "epoch": 3.7104896603450124,
      "grad_norm": 0.039326634258031845,
      "learning_rate": 1.5052680452873319e-05,
      "loss": 0.3103,
      "step": 34630
    },
    {
      "epoch": 3.7115611271831135,
      "grad_norm": 0.005484602879732847,
      "learning_rate": 1.5051251830422515e-05,
      "loss": 0.0019,
      "step": 34640
    },
    {
      "epoch": 3.712632594021215,
      "grad_norm": 0.044526632875204086,
      "learning_rate": 1.5049823207971714e-05,
      "loss": 0.0014,
      "step": 34650
    },
    {
      "epoch": 3.7137040608593166,
      "grad_norm": 0.03966681659221649,
      "learning_rate": 1.5048394585520913e-05,
      "loss": 0.2407,
      "step": 34660
    },
    {
      "epoch": 3.7147755276974177,
      "grad_norm": 0.018275080248713493,
      "learning_rate": 1.5046965963070111e-05,
      "loss": 0.0003,
      "step": 34670
    },
    {
      "epoch": 3.7158469945355193,
      "grad_norm": 20.524675369262695,
      "learning_rate": 1.5045537340619309e-05,
      "loss": 0.2062,
      "step": 34680
    },
    {
      "epoch": 3.7169184613736204,
      "grad_norm": 0.004042352549731731,
      "learning_rate": 1.5044108718168506e-05,
      "loss": 0.0007,
      "step": 34690
    },
    {
      "epoch": 3.717989928211722,
      "grad_norm": 0.002938374876976013,
      "learning_rate": 1.5042680095717706e-05,
      "loss": 0.3494,
      "step": 34700
    },
    {
      "epoch": 3.719061395049823,
      "grad_norm": 0.005552632734179497,
      "learning_rate": 1.5041251473266905e-05,
      "loss": 0.1477,
      "step": 34710
    },
    {
      "epoch": 3.7201328618879246,
      "grad_norm": 0.05660844221711159,
      "learning_rate": 1.5039822850816101e-05,
      "loss": 0.0014,
      "step": 34720
    },
    {
      "epoch": 3.721204328726026,
      "grad_norm": 36.32844543457031,
      "learning_rate": 1.50383942283653e-05,
      "loss": 0.5255,
      "step": 34730
    },
    {
      "epoch": 3.7222757955641272,
      "grad_norm": 0.275165855884552,
      "learning_rate": 1.5036965605914498e-05,
      "loss": 0.1617,
      "step": 34740
    },
    {
      "epoch": 3.723347262402229,
      "grad_norm": 15.107006072998047,
      "learning_rate": 1.5035536983463696e-05,
      "loss": 0.2858,
      "step": 34750
    },
    {
      "epoch": 3.72441872924033,
      "grad_norm": 0.12025095522403717,
      "learning_rate": 1.5034108361012893e-05,
      "loss": 0.0011,
      "step": 34760
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 0.002022322965785861,
      "learning_rate": 1.5032679738562093e-05,
      "loss": 0.318,
      "step": 34770
    },
    {
      "epoch": 3.7265616629165326,
      "grad_norm": 0.1535324901342392,
      "learning_rate": 1.5031251116111292e-05,
      "loss": 0.1096,
      "step": 34780
    },
    {
      "epoch": 3.727633129754634,
      "grad_norm": 32.77629852294922,
      "learning_rate": 1.5029822493660488e-05,
      "loss": 0.2464,
      "step": 34790
    },
    {
      "epoch": 3.7287045965927357,
      "grad_norm": 0.017858531326055527,
      "learning_rate": 1.5028393871209688e-05,
      "loss": 0.447,
      "step": 34800
    },
    {
      "epoch": 3.729776063430837,
      "grad_norm": 0.00818039383739233,
      "learning_rate": 1.5026965248758885e-05,
      "loss": 0.0014,
      "step": 34810
    },
    {
      "epoch": 3.7308475302689383,
      "grad_norm": 27.870336532592773,
      "learning_rate": 1.5025536626308085e-05,
      "loss": 0.3052,
      "step": 34820
    },
    {
      "epoch": 3.7319189971070394,
      "grad_norm": 0.03498947247862816,
      "learning_rate": 1.5024108003857282e-05,
      "loss": 0.0029,
      "step": 34830
    },
    {
      "epoch": 3.732990463945141,
      "grad_norm": 0.003494542557746172,
      "learning_rate": 1.502267938140648e-05,
      "loss": 0.0024,
      "step": 34840
    },
    {
      "epoch": 3.734061930783242,
      "grad_norm": 14.79491138458252,
      "learning_rate": 1.502125075895568e-05,
      "loss": 0.1442,
      "step": 34850
    },
    {
      "epoch": 3.7351333976213437,
      "grad_norm": 0.0017075598007068038,
      "learning_rate": 1.5019822136504875e-05,
      "loss": 0.001,
      "step": 34860
    },
    {
      "epoch": 3.736204864459445,
      "grad_norm": 0.002163429744541645,
      "learning_rate": 1.5018393514054075e-05,
      "loss": 0.0002,
      "step": 34870
    },
    {
      "epoch": 3.7372763312975463,
      "grad_norm": 0.07181704789400101,
      "learning_rate": 1.5016964891603272e-05,
      "loss": 0.1739,
      "step": 34880
    },
    {
      "epoch": 3.7383477981356474,
      "grad_norm": 0.07085838913917542,
      "learning_rate": 1.5015536269152472e-05,
      "loss": 0.1282,
      "step": 34890
    },
    {
      "epoch": 3.739419264973749,
      "grad_norm": 0.0638449564576149,
      "learning_rate": 1.501410764670167e-05,
      "loss": 0.0009,
      "step": 34900
    },
    {
      "epoch": 3.7404907318118505,
      "grad_norm": 0.05428474396467209,
      "learning_rate": 1.5012679024250867e-05,
      "loss": 0.3261,
      "step": 34910
    },
    {
      "epoch": 3.7415621986499517,
      "grad_norm": 0.00234349281527102,
      "learning_rate": 1.5011250401800066e-05,
      "loss": 0.0015,
      "step": 34920
    },
    {
      "epoch": 3.742633665488053,
      "grad_norm": 0.004428756423294544,
      "learning_rate": 1.5009821779349262e-05,
      "loss": 0.0007,
      "step": 34930
    },
    {
      "epoch": 3.7437051323261548,
      "grad_norm": 0.18428780138492584,
      "learning_rate": 1.5008393156898462e-05,
      "loss": 0.4195,
      "step": 34940
    },
    {
      "epoch": 3.744776599164256,
      "grad_norm": 0.20734182000160217,
      "learning_rate": 1.5006964534447661e-05,
      "loss": 0.3384,
      "step": 34950
    },
    {
      "epoch": 3.745848066002357,
      "grad_norm": 0.011310719884932041,
      "learning_rate": 1.5005535911996859e-05,
      "loss": 0.5363,
      "step": 34960
    },
    {
      "epoch": 3.7469195328404585,
      "grad_norm": 0.12096192687749863,
      "learning_rate": 1.5004107289546056e-05,
      "loss": 0.0019,
      "step": 34970
    },
    {
      "epoch": 3.74799099967856,
      "grad_norm": 0.033042777329683304,
      "learning_rate": 1.5002678667095254e-05,
      "loss": 0.2134,
      "step": 34980
    },
    {
      "epoch": 3.749062466516661,
      "grad_norm": 23.5855712890625,
      "learning_rate": 1.5001250044644453e-05,
      "loss": 0.1837,
      "step": 34990
    },
    {
      "epoch": 3.7501339333547627,
      "grad_norm": 0.005635391920804977,
      "learning_rate": 1.499982142219365e-05,
      "loss": 0.0006,
      "step": 35000
    },
    {
      "epoch": 3.7512054001928643,
      "grad_norm": 0.0328080952167511,
      "learning_rate": 1.4998392799742849e-05,
      "loss": 0.0027,
      "step": 35010
    },
    {
      "epoch": 3.7522768670309654,
      "grad_norm": 0.02569734677672386,
      "learning_rate": 1.4996964177292048e-05,
      "loss": 0.0022,
      "step": 35020
    },
    {
      "epoch": 3.7533483338690665,
      "grad_norm": 0.0022108021657913923,
      "learning_rate": 1.4995535554841246e-05,
      "loss": 0.2561,
      "step": 35030
    },
    {
      "epoch": 3.754419800707168,
      "grad_norm": 5.107207775115967,
      "learning_rate": 1.4994106932390444e-05,
      "loss": 0.4636,
      "step": 35040
    },
    {
      "epoch": 3.7554912675452696,
      "grad_norm": 0.002824579831212759,
      "learning_rate": 1.4992678309939641e-05,
      "loss": 0.0008,
      "step": 35050
    },
    {
      "epoch": 3.7565627343833707,
      "grad_norm": 0.003339204704388976,
      "learning_rate": 1.499124968748884e-05,
      "loss": 0.1856,
      "step": 35060
    },
    {
      "epoch": 3.7576342012214723,
      "grad_norm": 0.5810651183128357,
      "learning_rate": 1.498982106503804e-05,
      "loss": 0.0018,
      "step": 35070
    },
    {
      "epoch": 3.7587056680595734,
      "grad_norm": 0.31167998909950256,
      "learning_rate": 1.4988392442587236e-05,
      "loss": 0.155,
      "step": 35080
    },
    {
      "epoch": 3.759777134897675,
      "grad_norm": 0.00361057510599494,
      "learning_rate": 1.4986963820136435e-05,
      "loss": 0.0006,
      "step": 35090
    },
    {
      "epoch": 3.760848601735776,
      "grad_norm": 0.08372132480144501,
      "learning_rate": 1.4985535197685633e-05,
      "loss": 0.0003,
      "step": 35100
    },
    {
      "epoch": 3.7619200685738776,
      "grad_norm": 0.002082320861518383,
      "learning_rate": 1.498410657523483e-05,
      "loss": 0.1495,
      "step": 35110
    },
    {
      "epoch": 3.762991535411979,
      "grad_norm": 0.0017759627662599087,
      "learning_rate": 1.4982677952784028e-05,
      "loss": 0.001,
      "step": 35120
    },
    {
      "epoch": 3.7640630022500803,
      "grad_norm": 0.0038128967862576246,
      "learning_rate": 1.4981249330333228e-05,
      "loss": 0.0008,
      "step": 35130
    },
    {
      "epoch": 3.765134469088182,
      "grad_norm": 0.002100943122059107,
      "learning_rate": 1.4979820707882427e-05,
      "loss": 0.0009,
      "step": 35140
    },
    {
      "epoch": 3.766205935926283,
      "grad_norm": 0.0017294748686254025,
      "learning_rate": 1.4978392085431623e-05,
      "loss": 0.0002,
      "step": 35150
    },
    {
      "epoch": 3.7672774027643845,
      "grad_norm": 0.01755332574248314,
      "learning_rate": 1.4976963462980822e-05,
      "loss": 0.0012,
      "step": 35160
    },
    {
      "epoch": 3.7683488696024856,
      "grad_norm": 0.0029951054602861404,
      "learning_rate": 1.497553484053002e-05,
      "loss": 0.0004,
      "step": 35170
    },
    {
      "epoch": 3.769420336440587,
      "grad_norm": 0.007727150805294514,
      "learning_rate": 1.4974106218079218e-05,
      "loss": 0.0002,
      "step": 35180
    },
    {
      "epoch": 3.7704918032786887,
      "grad_norm": 0.01041563879698515,
      "learning_rate": 1.4972677595628417e-05,
      "loss": 0.0004,
      "step": 35190
    },
    {
      "epoch": 3.77156327011679,
      "grad_norm": 0.0016809884691610932,
      "learning_rate": 1.4971248973177615e-05,
      "loss": 0.1566,
      "step": 35200
    },
    {
      "epoch": 3.7726347369548914,
      "grad_norm": 0.04070056974887848,
      "learning_rate": 1.4969820350726814e-05,
      "loss": 0.2518,
      "step": 35210
    },
    {
      "epoch": 3.7737062037929925,
      "grad_norm": 0.0021729234140366316,
      "learning_rate": 1.496839172827601e-05,
      "loss": 0.0002,
      "step": 35220
    },
    {
      "epoch": 3.774777670631094,
      "grad_norm": 0.0015168250538408756,
      "learning_rate": 1.496696310582521e-05,
      "loss": 0.1454,
      "step": 35230
    },
    {
      "epoch": 3.775849137469195,
      "grad_norm": 0.01051244419068098,
      "learning_rate": 1.4965534483374407e-05,
      "loss": 0.6455,
      "step": 35240
    },
    {
      "epoch": 3.7769206043072967,
      "grad_norm": 0.047035109251737595,
      "learning_rate": 1.4964105860923605e-05,
      "loss": 0.0002,
      "step": 35250
    },
    {
      "epoch": 3.7779920711453983,
      "grad_norm": 0.003314850153401494,
      "learning_rate": 1.4962677238472804e-05,
      "loss": 0.2508,
      "step": 35260
    },
    {
      "epoch": 3.7790635379834994,
      "grad_norm": 0.00542451674118638,
      "learning_rate": 1.4961248616022002e-05,
      "loss": 0.0006,
      "step": 35270
    },
    {
      "epoch": 3.780135004821601,
      "grad_norm": 0.003161041531711817,
      "learning_rate": 1.4959819993571201e-05,
      "loss": 0.0006,
      "step": 35280
    },
    {
      "epoch": 3.781206471659702,
      "grad_norm": 0.003945980221033096,
      "learning_rate": 1.4958391371120397e-05,
      "loss": 0.2446,
      "step": 35290
    },
    {
      "epoch": 3.7822779384978036,
      "grad_norm": 0.11882432550191879,
      "learning_rate": 1.4956962748669597e-05,
      "loss": 0.003,
      "step": 35300
    },
    {
      "epoch": 3.7833494053359047,
      "grad_norm": 0.006517406553030014,
      "learning_rate": 1.4955534126218796e-05,
      "loss": 0.0004,
      "step": 35310
    },
    {
      "epoch": 3.7844208721740062,
      "grad_norm": 0.004451847169548273,
      "learning_rate": 1.4954105503767992e-05,
      "loss": 0.4689,
      "step": 35320
    },
    {
      "epoch": 3.785492339012108,
      "grad_norm": 0.019479457288980484,
      "learning_rate": 1.4952676881317191e-05,
      "loss": 0.1801,
      "step": 35330
    },
    {
      "epoch": 3.786563805850209,
      "grad_norm": 0.007384792901575565,
      "learning_rate": 1.4951248258866389e-05,
      "loss": 0.0008,
      "step": 35340
    },
    {
      "epoch": 3.7876352726883105,
      "grad_norm": 0.2660227119922638,
      "learning_rate": 1.4949819636415588e-05,
      "loss": 0.0007,
      "step": 35350
    },
    {
      "epoch": 3.7887067395264116,
      "grad_norm": 0.04626452922821045,
      "learning_rate": 1.4948391013964784e-05,
      "loss": 0.0004,
      "step": 35360
    },
    {
      "epoch": 3.789778206364513,
      "grad_norm": 0.003631328232586384,
      "learning_rate": 1.4946962391513984e-05,
      "loss": 0.098,
      "step": 35370
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 0.02095257118344307,
      "learning_rate": 1.4945533769063183e-05,
      "loss": 0.001,
      "step": 35380
    },
    {
      "epoch": 3.791921140040716,
      "grad_norm": 0.00469966558739543,
      "learning_rate": 1.494410514661238e-05,
      "loss": 0.0005,
      "step": 35390
    },
    {
      "epoch": 3.7929926068788173,
      "grad_norm": 0.02391960844397545,
      "learning_rate": 1.4942676524161578e-05,
      "loss": 0.2878,
      "step": 35400
    },
    {
      "epoch": 3.7940640737169185,
      "grad_norm": 0.032396599650382996,
      "learning_rate": 1.4941247901710776e-05,
      "loss": 0.0004,
      "step": 35410
    },
    {
      "epoch": 3.7951355405550196,
      "grad_norm": 0.010464235208928585,
      "learning_rate": 1.4939819279259975e-05,
      "loss": 0.002,
      "step": 35420
    },
    {
      "epoch": 3.796207007393121,
      "grad_norm": 0.0073917037807404995,
      "learning_rate": 1.4938390656809171e-05,
      "loss": 0.5263,
      "step": 35430
    },
    {
      "epoch": 3.7972784742312227,
      "grad_norm": 0.014125806279480457,
      "learning_rate": 1.493696203435837e-05,
      "loss": 0.1814,
      "step": 35440
    },
    {
      "epoch": 3.7983499410693238,
      "grad_norm": 85.57735443115234,
      "learning_rate": 1.493553341190757e-05,
      "loss": 0.81,
      "step": 35450
    },
    {
      "epoch": 3.7994214079074253,
      "grad_norm": 0.8018718361854553,
      "learning_rate": 1.4934104789456768e-05,
      "loss": 0.3529,
      "step": 35460
    },
    {
      "epoch": 3.800492874745527,
      "grad_norm": 0.2665257155895233,
      "learning_rate": 1.4932676167005965e-05,
      "loss": 0.0036,
      "step": 35470
    },
    {
      "epoch": 3.801564341583628,
      "grad_norm": 0.1662212312221527,
      "learning_rate": 1.4931247544555163e-05,
      "loss": 0.001,
      "step": 35480
    },
    {
      "epoch": 3.802635808421729,
      "grad_norm": 0.07745501399040222,
      "learning_rate": 1.4929818922104363e-05,
      "loss": 0.1573,
      "step": 35490
    },
    {
      "epoch": 3.8037072752598307,
      "grad_norm": 0.18158571422100067,
      "learning_rate": 1.4928390299653562e-05,
      "loss": 0.3647,
      "step": 35500
    },
    {
      "epoch": 3.804778742097932,
      "grad_norm": 0.0342005118727684,
      "learning_rate": 1.4926961677202758e-05,
      "loss": 0.0011,
      "step": 35510
    },
    {
      "epoch": 3.8058502089360333,
      "grad_norm": 0.034532833844423294,
      "learning_rate": 1.4925533054751957e-05,
      "loss": 0.0008,
      "step": 35520
    },
    {
      "epoch": 3.806921675774135,
      "grad_norm": 27.581226348876953,
      "learning_rate": 1.4924104432301155e-05,
      "loss": 0.2025,
      "step": 35530
    },
    {
      "epoch": 3.8079931426122364,
      "grad_norm": 0.007105203811079264,
      "learning_rate": 1.4922675809850353e-05,
      "loss": 0.0005,
      "step": 35540
    },
    {
      "epoch": 3.8090646094503375,
      "grad_norm": 0.07783068716526031,
      "learning_rate": 1.492124718739955e-05,
      "loss": 0.1858,
      "step": 35550
    },
    {
      "epoch": 3.8101360762884386,
      "grad_norm": 0.014053183607757092,
      "learning_rate": 1.491981856494875e-05,
      "loss": 0.1853,
      "step": 35560
    },
    {
      "epoch": 3.81120754312654,
      "grad_norm": 0.009911663830280304,
      "learning_rate": 1.4918389942497949e-05,
      "loss": 0.1694,
      "step": 35570
    },
    {
      "epoch": 3.8122790099646418,
      "grad_norm": 0.12613359093666077,
      "learning_rate": 1.4916961320047145e-05,
      "loss": 0.1911,
      "step": 35580
    },
    {
      "epoch": 3.813350476802743,
      "grad_norm": 0.00884248223155737,
      "learning_rate": 1.4915532697596344e-05,
      "loss": 0.0011,
      "step": 35590
    },
    {
      "epoch": 3.8144219436408444,
      "grad_norm": 0.005081596784293652,
      "learning_rate": 1.4914104075145542e-05,
      "loss": 0.0006,
      "step": 35600
    },
    {
      "epoch": 3.8154934104789455,
      "grad_norm": 0.16252385079860687,
      "learning_rate": 1.491267545269474e-05,
      "loss": 0.1496,
      "step": 35610
    },
    {
      "epoch": 3.816564877317047,
      "grad_norm": 0.005549843423068523,
      "learning_rate": 1.4911246830243939e-05,
      "loss": 0.1588,
      "step": 35620
    },
    {
      "epoch": 3.817636344155148,
      "grad_norm": 0.018669744953513145,
      "learning_rate": 1.4909818207793137e-05,
      "loss": 0.0034,
      "step": 35630
    },
    {
      "epoch": 3.8187078109932497,
      "grad_norm": 20.17660903930664,
      "learning_rate": 1.4908389585342336e-05,
      "loss": 0.3253,
      "step": 35640
    },
    {
      "epoch": 3.8197792778313513,
      "grad_norm": 0.5526309013366699,
      "learning_rate": 1.4906960962891532e-05,
      "loss": 0.0017,
      "step": 35650
    },
    {
      "epoch": 3.8208507446694524,
      "grad_norm": 0.024326253682374954,
      "learning_rate": 1.4905532340440731e-05,
      "loss": 0.1597,
      "step": 35660
    },
    {
      "epoch": 3.821922211507554,
      "grad_norm": 0.03539853170514107,
      "learning_rate": 1.4904103717989929e-05,
      "loss": 0.1772,
      "step": 35670
    },
    {
      "epoch": 3.822993678345655,
      "grad_norm": 0.003611302003264427,
      "learning_rate": 1.4902675095539127e-05,
      "loss": 0.3562,
      "step": 35680
    },
    {
      "epoch": 3.8240651451837566,
      "grad_norm": 0.020650004968047142,
      "learning_rate": 1.4901246473088326e-05,
      "loss": 0.1181,
      "step": 35690
    },
    {
      "epoch": 3.8251366120218577,
      "grad_norm": 0.013834582641720772,
      "learning_rate": 1.4899817850637524e-05,
      "loss": 0.0008,
      "step": 35700
    },
    {
      "epoch": 3.8262080788599593,
      "grad_norm": 0.03879218548536301,
      "learning_rate": 1.4898389228186723e-05,
      "loss": 0.0015,
      "step": 35710
    },
    {
      "epoch": 3.827279545698061,
      "grad_norm": 0.0021015554666519165,
      "learning_rate": 1.4896960605735919e-05,
      "loss": 0.0008,
      "step": 35720
    },
    {
      "epoch": 3.828351012536162,
      "grad_norm": 0.025645464658737183,
      "learning_rate": 1.4895531983285119e-05,
      "loss": 0.1963,
      "step": 35730
    },
    {
      "epoch": 3.8294224793742635,
      "grad_norm": 0.009754079394042492,
      "learning_rate": 1.4894103360834318e-05,
      "loss": 0.2373,
      "step": 35740
    },
    {
      "epoch": 3.8304939462123646,
      "grad_norm": 0.003065661992877722,
      "learning_rate": 1.4892674738383514e-05,
      "loss": 0.0004,
      "step": 35750
    },
    {
      "epoch": 3.831565413050466,
      "grad_norm": 0.08533290773630142,
      "learning_rate": 1.4891246115932713e-05,
      "loss": 0.0007,
      "step": 35760
    },
    {
      "epoch": 3.8326368798885673,
      "grad_norm": 0.021614596247673035,
      "learning_rate": 1.4889817493481911e-05,
      "loss": 0.0004,
      "step": 35770
    },
    {
      "epoch": 3.833708346726669,
      "grad_norm": 0.11997874826192856,
      "learning_rate": 1.488838887103111e-05,
      "loss": 0.5751,
      "step": 35780
    },
    {
      "epoch": 3.8347798135647704,
      "grad_norm": 0.0852145403623581,
      "learning_rate": 1.4886960248580306e-05,
      "loss": 0.1893,
      "step": 35790
    },
    {
      "epoch": 3.8358512804028715,
      "grad_norm": 0.05948640778660774,
      "learning_rate": 1.4885531626129506e-05,
      "loss": 0.3605,
      "step": 35800
    },
    {
      "epoch": 3.836922747240973,
      "grad_norm": 0.003947447054088116,
      "learning_rate": 1.4884103003678705e-05,
      "loss": 0.0022,
      "step": 35810
    },
    {
      "epoch": 3.837994214079074,
      "grad_norm": 0.10771044343709946,
      "learning_rate": 1.4882674381227901e-05,
      "loss": 0.001,
      "step": 35820
    },
    {
      "epoch": 3.8390656809171757,
      "grad_norm": 0.06491131335496902,
      "learning_rate": 1.48812457587771e-05,
      "loss": 0.0008,
      "step": 35830
    },
    {
      "epoch": 3.840137147755277,
      "grad_norm": 0.12381324172019958,
      "learning_rate": 1.4879817136326298e-05,
      "loss": 0.0009,
      "step": 35840
    },
    {
      "epoch": 3.8412086145933784,
      "grad_norm": 0.0020055631175637245,
      "learning_rate": 1.4878388513875497e-05,
      "loss": 0.0005,
      "step": 35850
    },
    {
      "epoch": 3.84228008143148,
      "grad_norm": 0.06761359423398972,
      "learning_rate": 1.4876959891424697e-05,
      "loss": 0.2856,
      "step": 35860
    },
    {
      "epoch": 3.843351548269581,
      "grad_norm": 0.014486613683402538,
      "learning_rate": 1.4875531268973893e-05,
      "loss": 0.1769,
      "step": 35870
    },
    {
      "epoch": 3.844423015107682,
      "grad_norm": 0.060791704803705215,
      "learning_rate": 1.4874102646523092e-05,
      "loss": 0.1632,
      "step": 35880
    },
    {
      "epoch": 3.8454944819457837,
      "grad_norm": 33.56028366088867,
      "learning_rate": 1.4872674024072288e-05,
      "loss": 0.4609,
      "step": 35890
    },
    {
      "epoch": 3.8465659487838852,
      "grad_norm": 0.00219518318772316,
      "learning_rate": 1.4871245401621487e-05,
      "loss": 0.0024,
      "step": 35900
    },
    {
      "epoch": 3.8476374156219864,
      "grad_norm": 0.03189484030008316,
      "learning_rate": 1.4869816779170685e-05,
      "loss": 0.1363,
      "step": 35910
    },
    {
      "epoch": 3.848708882460088,
      "grad_norm": 0.00698568532243371,
      "learning_rate": 1.4868388156719884e-05,
      "loss": 0.2943,
      "step": 35920
    },
    {
      "epoch": 3.8497803492981895,
      "grad_norm": 0.027233164757490158,
      "learning_rate": 1.4866959534269084e-05,
      "loss": 0.2627,
      "step": 35930
    },
    {
      "epoch": 3.8508518161362906,
      "grad_norm": 0.0027705372776836157,
      "learning_rate": 1.486553091181828e-05,
      "loss": 0.0004,
      "step": 35940
    },
    {
      "epoch": 3.8519232829743917,
      "grad_norm": 36.343265533447266,
      "learning_rate": 1.486410228936748e-05,
      "loss": 0.1748,
      "step": 35950
    },
    {
      "epoch": 3.8529947498124932,
      "grad_norm": 0.6228685975074768,
      "learning_rate": 1.4862673666916677e-05,
      "loss": 0.2388,
      "step": 35960
    },
    {
      "epoch": 3.854066216650595,
      "grad_norm": 0.03236527368426323,
      "learning_rate": 1.4861245044465875e-05,
      "loss": 0.0004,
      "step": 35970
    },
    {
      "epoch": 3.855137683488696,
      "grad_norm": 0.002030064817517996,
      "learning_rate": 1.4859816422015074e-05,
      "loss": 0.3079,
      "step": 35980
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 0.0011796315666288137,
      "learning_rate": 1.4858387799564272e-05,
      "loss": 0.0014,
      "step": 35990
    },
    {
      "epoch": 3.857280617164899,
      "grad_norm": 0.0016977728810161352,
      "learning_rate": 1.4856959177113471e-05,
      "loss": 0.2629,
      "step": 36000
    },
    {
      "epoch": 3.858352084003,
      "grad_norm": 0.02284170687198639,
      "learning_rate": 1.4855530554662667e-05,
      "loss": 0.3922,
      "step": 36010
    },
    {
      "epoch": 3.8594235508411012,
      "grad_norm": 0.0030034242663532495,
      "learning_rate": 1.4854101932211866e-05,
      "loss": 0.1023,
      "step": 36020
    },
    {
      "epoch": 3.860495017679203,
      "grad_norm": 0.2896219491958618,
      "learning_rate": 1.4852673309761064e-05,
      "loss": 0.0994,
      "step": 36030
    },
    {
      "epoch": 3.8615664845173043,
      "grad_norm": 0.03938696160912514,
      "learning_rate": 1.4851244687310262e-05,
      "loss": 0.0028,
      "step": 36040
    },
    {
      "epoch": 3.8626379513554054,
      "grad_norm": 0.0334935337305069,
      "learning_rate": 1.4849816064859461e-05,
      "loss": 0.0003,
      "step": 36050
    },
    {
      "epoch": 3.863709418193507,
      "grad_norm": 0.00391736812889576,
      "learning_rate": 1.4848387442408659e-05,
      "loss": 0.0013,
      "step": 36060
    },
    {
      "epoch": 3.8647808850316085,
      "grad_norm": 0.002329676179215312,
      "learning_rate": 1.4846958819957858e-05,
      "loss": 0.4477,
      "step": 36070
    },
    {
      "epoch": 3.8658523518697097,
      "grad_norm": 0.6547386050224304,
      "learning_rate": 1.4845530197507054e-05,
      "loss": 0.1191,
      "step": 36080
    },
    {
      "epoch": 3.8669238187078108,
      "grad_norm": 0.0029303347691893578,
      "learning_rate": 1.4844101575056253e-05,
      "loss": 0.0004,
      "step": 36090
    },
    {
      "epoch": 3.8679952855459123,
      "grad_norm": 0.021559087559580803,
      "learning_rate": 1.4842672952605453e-05,
      "loss": 0.2379,
      "step": 36100
    },
    {
      "epoch": 3.869066752384014,
      "grad_norm": 0.0033422517590224743,
      "learning_rate": 1.4841244330154649e-05,
      "loss": 0.3661,
      "step": 36110
    },
    {
      "epoch": 3.870138219222115,
      "grad_norm": 0.011132863350212574,
      "learning_rate": 1.4839815707703848e-05,
      "loss": 0.2101,
      "step": 36120
    },
    {
      "epoch": 3.8712096860602165,
      "grad_norm": 0.019438279792666435,
      "learning_rate": 1.4838387085253046e-05,
      "loss": 0.092,
      "step": 36130
    },
    {
      "epoch": 3.8722811528983176,
      "grad_norm": 0.009461118839681149,
      "learning_rate": 1.4836958462802245e-05,
      "loss": 0.0795,
      "step": 36140
    },
    {
      "epoch": 3.873352619736419,
      "grad_norm": 0.008275034837424755,
      "learning_rate": 1.4835529840351441e-05,
      "loss": 0.0004,
      "step": 36150
    },
    {
      "epoch": 3.8744240865745203,
      "grad_norm": 0.010218163020908833,
      "learning_rate": 1.483410121790064e-05,
      "loss": 0.0003,
      "step": 36160
    },
    {
      "epoch": 3.875495553412622,
      "grad_norm": 0.0023671395611017942,
      "learning_rate": 1.483267259544984e-05,
      "loss": 0.1211,
      "step": 36170
    },
    {
      "epoch": 3.8765670202507234,
      "grad_norm": 0.002791916485875845,
      "learning_rate": 1.4831243972999036e-05,
      "loss": 0.3659,
      "step": 36180
    },
    {
      "epoch": 3.8776384870888245,
      "grad_norm": 0.00604963256046176,
      "learning_rate": 1.4829815350548235e-05,
      "loss": 0.0056,
      "step": 36190
    },
    {
      "epoch": 3.878709953926926,
      "grad_norm": 0.003302635159343481,
      "learning_rate": 1.4828386728097433e-05,
      "loss": 0.0022,
      "step": 36200
    },
    {
      "epoch": 3.879781420765027,
      "grad_norm": 0.009999372996389866,
      "learning_rate": 1.4826958105646632e-05,
      "loss": 0.0004,
      "step": 36210
    },
    {
      "epoch": 3.8808528876031287,
      "grad_norm": 0.0014146656030789018,
      "learning_rate": 1.4825529483195832e-05,
      "loss": 0.0005,
      "step": 36220
    },
    {
      "epoch": 3.88192435444123,
      "grad_norm": 0.0019604370463639498,
      "learning_rate": 1.4824100860745028e-05,
      "loss": 0.5457,
      "step": 36230
    },
    {
      "epoch": 3.8829958212793314,
      "grad_norm": 0.0021828636527061462,
      "learning_rate": 1.4822672238294227e-05,
      "loss": 0.2149,
      "step": 36240
    },
    {
      "epoch": 3.884067288117433,
      "grad_norm": 0.005069640465080738,
      "learning_rate": 1.4821243615843423e-05,
      "loss": 0.0001,
      "step": 36250
    },
    {
      "epoch": 3.885138754955534,
      "grad_norm": 0.004457895644009113,
      "learning_rate": 1.4819814993392622e-05,
      "loss": 0.0006,
      "step": 36260
    },
    {
      "epoch": 3.8862102217936356,
      "grad_norm": 0.0023368108086287975,
      "learning_rate": 1.481838637094182e-05,
      "loss": 0.0096,
      "step": 36270
    },
    {
      "epoch": 3.8872816886317367,
      "grad_norm": 0.003703255206346512,
      "learning_rate": 1.481695774849102e-05,
      "loss": 0.2123,
      "step": 36280
    },
    {
      "epoch": 3.8883531554698383,
      "grad_norm": 0.03483191877603531,
      "learning_rate": 1.4815529126040219e-05,
      "loss": 0.1833,
      "step": 36290
    },
    {
      "epoch": 3.8894246223079394,
      "grad_norm": 0.10077426582574844,
      "learning_rate": 1.4814100503589415e-05,
      "loss": 0.1464,
      "step": 36300
    },
    {
      "epoch": 3.890496089146041,
      "grad_norm": 0.0021274113096296787,
      "learning_rate": 1.4812671881138614e-05,
      "loss": 0.2213,
      "step": 36310
    },
    {
      "epoch": 3.8915675559841425,
      "grad_norm": 0.042086273431777954,
      "learning_rate": 1.481124325868781e-05,
      "loss": 0.0813,
      "step": 36320
    },
    {
      "epoch": 3.8926390228222436,
      "grad_norm": 0.0022145959082990885,
      "learning_rate": 1.480981463623701e-05,
      "loss": 0.1135,
      "step": 36330
    },
    {
      "epoch": 3.893710489660345,
      "grad_norm": 0.0059896428138017654,
      "learning_rate": 1.4808386013786207e-05,
      "loss": 0.1826,
      "step": 36340
    },
    {
      "epoch": 3.8947819564984463,
      "grad_norm": 244.4219512939453,
      "learning_rate": 1.4806957391335406e-05,
      "loss": 0.1941,
      "step": 36350
    },
    {
      "epoch": 3.895853423336548,
      "grad_norm": 0.0025563437957316637,
      "learning_rate": 1.4805528768884606e-05,
      "loss": 0.0757,
      "step": 36360
    },
    {
      "epoch": 3.896924890174649,
      "grad_norm": 0.11751820147037506,
      "learning_rate": 1.4804100146433802e-05,
      "loss": 0.0557,
      "step": 36370
    },
    {
      "epoch": 3.8979963570127505,
      "grad_norm": 0.0008243127958849072,
      "learning_rate": 1.4802671523983001e-05,
      "loss": 0.3809,
      "step": 36380
    },
    {
      "epoch": 3.899067823850852,
      "grad_norm": 0.015393058769404888,
      "learning_rate": 1.4801242901532197e-05,
      "loss": 0.1915,
      "step": 36390
    },
    {
      "epoch": 3.900139290688953,
      "grad_norm": 0.0036557079292833805,
      "learning_rate": 1.4799814279081396e-05,
      "loss": 0.1729,
      "step": 36400
    },
    {
      "epoch": 3.9012107575270543,
      "grad_norm": 0.003847894025966525,
      "learning_rate": 1.4798385656630596e-05,
      "loss": 0.0503,
      "step": 36410
    },
    {
      "epoch": 3.902282224365156,
      "grad_norm": 0.01917060650885105,
      "learning_rate": 1.4796957034179793e-05,
      "loss": 0.0006,
      "step": 36420
    },
    {
      "epoch": 3.9033536912032574,
      "grad_norm": 0.04259054362773895,
      "learning_rate": 1.4795528411728993e-05,
      "loss": 0.0006,
      "step": 36430
    },
    {
      "epoch": 3.9044251580413585,
      "grad_norm": 0.05025318264961243,
      "learning_rate": 1.4794099789278189e-05,
      "loss": 0.3108,
      "step": 36440
    },
    {
      "epoch": 3.90549662487946,
      "grad_norm": 0.0450173020362854,
      "learning_rate": 1.4792671166827388e-05,
      "loss": 0.1263,
      "step": 36450
    },
    {
      "epoch": 3.9065680917175616,
      "grad_norm": 0.24331432580947876,
      "learning_rate": 1.4791242544376584e-05,
      "loss": 0.1549,
      "step": 36460
    },
    {
      "epoch": 3.9076395585556627,
      "grad_norm": 0.20673151314258575,
      "learning_rate": 1.4789813921925784e-05,
      "loss": 0.2114,
      "step": 36470
    },
    {
      "epoch": 3.908711025393764,
      "grad_norm": 0.0013863606145605445,
      "learning_rate": 1.4788385299474983e-05,
      "loss": 0.2651,
      "step": 36480
    },
    {
      "epoch": 3.9097824922318654,
      "grad_norm": 0.0013499323977157474,
      "learning_rate": 1.478695667702418e-05,
      "loss": 0.1923,
      "step": 36490
    },
    {
      "epoch": 3.910853959069967,
      "grad_norm": 0.024981871247291565,
      "learning_rate": 1.478552805457338e-05,
      "loss": 0.0014,
      "step": 36500
    },
    {
      "epoch": 3.911925425908068,
      "grad_norm": 0.001307475264184177,
      "learning_rate": 1.4784099432122576e-05,
      "loss": 0.0104,
      "step": 36510
    },
    {
      "epoch": 3.9129968927461696,
      "grad_norm": 17.93192481994629,
      "learning_rate": 1.4782670809671775e-05,
      "loss": 0.0842,
      "step": 36520
    },
    {
      "epoch": 3.914068359584271,
      "grad_norm": 0.0497581847012043,
      "learning_rate": 1.4781242187220975e-05,
      "loss": 0.1309,
      "step": 36530
    },
    {
      "epoch": 3.9151398264223722,
      "grad_norm": 0.0006619714549742639,
      "learning_rate": 1.477981356477017e-05,
      "loss": 0.1425,
      "step": 36540
    },
    {
      "epoch": 3.9162112932604733,
      "grad_norm": 0.014334576204419136,
      "learning_rate": 1.477838494231937e-05,
      "loss": 0.0004,
      "step": 36550
    },
    {
      "epoch": 3.917282760098575,
      "grad_norm": 0.20567721128463745,
      "learning_rate": 1.4776956319868568e-05,
      "loss": 0.0002,
      "step": 36560
    },
    {
      "epoch": 3.9183542269366765,
      "grad_norm": 0.0011085403384640813,
      "learning_rate": 1.4775527697417767e-05,
      "loss": 0.1827,
      "step": 36570
    },
    {
      "epoch": 3.9194256937747776,
      "grad_norm": 0.000535468861926347,
      "learning_rate": 1.4774099074966963e-05,
      "loss": 0.0003,
      "step": 36580
    },
    {
      "epoch": 3.920497160612879,
      "grad_norm": 0.05787757784128189,
      "learning_rate": 1.4772670452516162e-05,
      "loss": 0.0005,
      "step": 36590
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 0.047802265733480453,
      "learning_rate": 1.4771241830065362e-05,
      "loss": 0.0003,
      "step": 36600
    },
    {
      "epoch": 3.922640094289082,
      "grad_norm": 0.30201777815818787,
      "learning_rate": 1.4769813207614558e-05,
      "loss": 0.0002,
      "step": 36610
    },
    {
      "epoch": 3.923711561127183,
      "grad_norm": 0.0007225080044008791,
      "learning_rate": 1.4768384585163757e-05,
      "loss": 0.1948,
      "step": 36620
    },
    {
      "epoch": 3.9247830279652844,
      "grad_norm": 15.647359848022461,
      "learning_rate": 1.4766955962712955e-05,
      "loss": 0.2436,
      "step": 36630
    },
    {
      "epoch": 3.925854494803386,
      "grad_norm": 0.0013107776176184416,
      "learning_rate": 1.4765527340262154e-05,
      "loss": 0.2331,
      "step": 36640
    },
    {
      "epoch": 3.926925961641487,
      "grad_norm": 0.2217881828546524,
      "learning_rate": 1.4764098717811352e-05,
      "loss": 0.1056,
      "step": 36650
    },
    {
      "epoch": 3.9279974284795887,
      "grad_norm": 0.0447564460337162,
      "learning_rate": 1.476267009536055e-05,
      "loss": 0.224,
      "step": 36660
    },
    {
      "epoch": 3.9290688953176898,
      "grad_norm": 0.026498833671212196,
      "learning_rate": 1.4761241472909749e-05,
      "loss": 0.4483,
      "step": 36670
    },
    {
      "epoch": 3.9301403621557913,
      "grad_norm": 0.01883292943239212,
      "learning_rate": 1.4759812850458945e-05,
      "loss": 0.0026,
      "step": 36680
    },
    {
      "epoch": 3.9312118289938924,
      "grad_norm": 0.040847018361091614,
      "learning_rate": 1.4758384228008144e-05,
      "loss": 0.0006,
      "step": 36690
    },
    {
      "epoch": 3.932283295831994,
      "grad_norm": 0.002967222360894084,
      "learning_rate": 1.4756955605557342e-05,
      "loss": 0.3367,
      "step": 36700
    },
    {
      "epoch": 3.9333547626700955,
      "grad_norm": 0.002399299293756485,
      "learning_rate": 1.4755526983106541e-05,
      "loss": 0.0006,
      "step": 36710
    },
    {
      "epoch": 3.9344262295081966,
      "grad_norm": 16.594789505004883,
      "learning_rate": 1.4754098360655739e-05,
      "loss": 0.3328,
      "step": 36720
    },
    {
      "epoch": 3.935497696346298,
      "grad_norm": 0.0011437027715146542,
      "learning_rate": 1.4752669738204937e-05,
      "loss": 0.0008,
      "step": 36730
    },
    {
      "epoch": 3.9365691631843993,
      "grad_norm": 0.002051293384283781,
      "learning_rate": 1.4751241115754136e-05,
      "loss": 0.1778,
      "step": 36740
    },
    {
      "epoch": 3.937640630022501,
      "grad_norm": 0.014123967848718166,
      "learning_rate": 1.4749812493303332e-05,
      "loss": 0.1641,
      "step": 36750
    },
    {
      "epoch": 3.938712096860602,
      "grad_norm": 6.87687349319458,
      "learning_rate": 1.4748383870852531e-05,
      "loss": 0.1356,
      "step": 36760
    },
    {
      "epoch": 3.9397835636987035,
      "grad_norm": 34.36354064941406,
      "learning_rate": 1.474695524840173e-05,
      "loss": 0.5322,
      "step": 36770
    },
    {
      "epoch": 3.940855030536805,
      "grad_norm": 0.001972112338989973,
      "learning_rate": 1.4745526625950928e-05,
      "loss": 0.0019,
      "step": 36780
    },
    {
      "epoch": 3.941926497374906,
      "grad_norm": 0.046824436634778976,
      "learning_rate": 1.4744098003500128e-05,
      "loss": 0.4018,
      "step": 36790
    },
    {
      "epoch": 3.9429979642130077,
      "grad_norm": 0.19686657190322876,
      "learning_rate": 1.4742669381049324e-05,
      "loss": 0.1808,
      "step": 36800
    },
    {
      "epoch": 3.944069431051109,
      "grad_norm": 0.12120389938354492,
      "learning_rate": 1.4741240758598523e-05,
      "loss": 0.0016,
      "step": 36810
    },
    {
      "epoch": 3.9451408978892104,
      "grad_norm": 0.003520156955346465,
      "learning_rate": 1.4739812136147719e-05,
      "loss": 0.3714,
      "step": 36820
    },
    {
      "epoch": 3.9462123647273115,
      "grad_norm": 0.03157079592347145,
      "learning_rate": 1.4738383513696918e-05,
      "loss": 0.1811,
      "step": 36830
    },
    {
      "epoch": 3.947283831565413,
      "grad_norm": 0.05165375396609306,
      "learning_rate": 1.4736954891246118e-05,
      "loss": 0.2744,
      "step": 36840
    },
    {
      "epoch": 3.9483552984035146,
      "grad_norm": 0.038783878087997437,
      "learning_rate": 1.4735526268795315e-05,
      "loss": 0.0015,
      "step": 36850
    },
    {
      "epoch": 3.9494267652416157,
      "grad_norm": 0.05706717446446419,
      "learning_rate": 1.4734097646344515e-05,
      "loss": 0.1506,
      "step": 36860
    },
    {
      "epoch": 3.9504982320797173,
      "grad_norm": 0.12692199647426605,
      "learning_rate": 1.473266902389371e-05,
      "loss": 0.2544,
      "step": 36870
    },
    {
      "epoch": 3.9515696989178184,
      "grad_norm": 0.0393858402967453,
      "learning_rate": 1.473124040144291e-05,
      "loss": 0.0037,
      "step": 36880
    },
    {
      "epoch": 3.95264116575592,
      "grad_norm": 0.0033453430514782667,
      "learning_rate": 1.472981177899211e-05,
      "loss": 0.1454,
      "step": 36890
    },
    {
      "epoch": 3.953712632594021,
      "grad_norm": 0.051300302147865295,
      "learning_rate": 1.4728383156541305e-05,
      "loss": 0.235,
      "step": 36900
    },
    {
      "epoch": 3.9547840994321226,
      "grad_norm": 0.008263658732175827,
      "learning_rate": 1.4726954534090505e-05,
      "loss": 0.2127,
      "step": 36910
    },
    {
      "epoch": 3.955855566270224,
      "grad_norm": 0.02994929626584053,
      "learning_rate": 1.4725525911639703e-05,
      "loss": 0.3745,
      "step": 36920
    },
    {
      "epoch": 3.9569270331083253,
      "grad_norm": 34.064327239990234,
      "learning_rate": 1.4724097289188902e-05,
      "loss": 0.4206,
      "step": 36930
    },
    {
      "epoch": 3.9579984999464264,
      "grad_norm": 0.0009090223466046154,
      "learning_rate": 1.4722668666738098e-05,
      "loss": 0.1604,
      "step": 36940
    },
    {
      "epoch": 3.959069966784528,
      "grad_norm": 0.0030037378892302513,
      "learning_rate": 1.4721240044287297e-05,
      "loss": 0.1969,
      "step": 36950
    },
    {
      "epoch": 3.9601414336226295,
      "grad_norm": 0.0028287838213145733,
      "learning_rate": 1.4719811421836497e-05,
      "loss": 0.155,
      "step": 36960
    },
    {
      "epoch": 3.9612129004607306,
      "grad_norm": 31.571090698242188,
      "learning_rate": 1.4718382799385693e-05,
      "loss": 0.3165,
      "step": 36970
    },
    {
      "epoch": 3.962284367298832,
      "grad_norm": 0.004938929807394743,
      "learning_rate": 1.4716954176934892e-05,
      "loss": 0.2394,
      "step": 36980
    },
    {
      "epoch": 3.9633558341369337,
      "grad_norm": 0.1229323223233223,
      "learning_rate": 1.471552555448409e-05,
      "loss": 0.1025,
      "step": 36990
    },
    {
      "epoch": 3.964427300975035,
      "grad_norm": 0.0031751932110637426,
      "learning_rate": 1.4714096932033289e-05,
      "loss": 0.1425,
      "step": 37000
    },
    {
      "epoch": 3.965498767813136,
      "grad_norm": 0.008321869187057018,
      "learning_rate": 1.4712668309582487e-05,
      "loss": 0.002,
      "step": 37010
    },
    {
      "epoch": 3.9665702346512375,
      "grad_norm": 0.12929897010326385,
      "learning_rate": 1.4711239687131684e-05,
      "loss": 0.1428,
      "step": 37020
    },
    {
      "epoch": 3.967641701489339,
      "grad_norm": 0.0008087038295343518,
      "learning_rate": 1.4709811064680884e-05,
      "loss": 0.0007,
      "step": 37030
    },
    {
      "epoch": 3.96871316832744,
      "grad_norm": 0.0006548467208631337,
      "learning_rate": 1.470838244223008e-05,
      "loss": 0.001,
      "step": 37040
    },
    {
      "epoch": 3.9697846351655417,
      "grad_norm": 0.9932633638381958,
      "learning_rate": 1.4706953819779279e-05,
      "loss": 0.0012,
      "step": 37050
    },
    {
      "epoch": 3.9708561020036433,
      "grad_norm": 0.0009516127756796777,
      "learning_rate": 1.4705525197328477e-05,
      "loss": 0.1936,
      "step": 37060
    },
    {
      "epoch": 3.9719275688417444,
      "grad_norm": 0.0007843227940611541,
      "learning_rate": 1.4704096574877676e-05,
      "loss": 0.0005,
      "step": 37070
    },
    {
      "epoch": 3.9729990356798455,
      "grad_norm": 0.000877971644513309,
      "learning_rate": 1.4702667952426874e-05,
      "loss": 0.6456,
      "step": 37080
    },
    {
      "epoch": 3.974070502517947,
      "grad_norm": 0.34365034103393555,
      "learning_rate": 1.4701239329976071e-05,
      "loss": 0.0013,
      "step": 37090
    },
    {
      "epoch": 3.9751419693560486,
      "grad_norm": 0.0024493252858519554,
      "learning_rate": 1.469981070752527e-05,
      "loss": 0.2054,
      "step": 37100
    },
    {
      "epoch": 3.9762134361941497,
      "grad_norm": 0.004455575253814459,
      "learning_rate": 1.4698382085074467e-05,
      "loss": 0.2864,
      "step": 37110
    },
    {
      "epoch": 3.9772849030322512,
      "grad_norm": 0.07641811668872833,
      "learning_rate": 1.4696953462623666e-05,
      "loss": 0.0006,
      "step": 37120
    },
    {
      "epoch": 3.9783563698703523,
      "grad_norm": 0.0029447125270962715,
      "learning_rate": 1.4695524840172866e-05,
      "loss": 0.0951,
      "step": 37130
    },
    {
      "epoch": 3.979427836708454,
      "grad_norm": 0.13405771553516388,
      "learning_rate": 1.4694096217722063e-05,
      "loss": 0.0005,
      "step": 37140
    },
    {
      "epoch": 3.980499303546555,
      "grad_norm": 0.0032532333862036467,
      "learning_rate": 1.4692667595271261e-05,
      "loss": 0.0002,
      "step": 37150
    },
    {
      "epoch": 3.9815707703846566,
      "grad_norm": 0.027426132932305336,
      "learning_rate": 1.4691238972820459e-05,
      "loss": 0.0003,
      "step": 37160
    },
    {
      "epoch": 3.982642237222758,
      "grad_norm": 9.861607551574707,
      "learning_rate": 1.4689810350369658e-05,
      "loss": 0.3712,
      "step": 37170
    },
    {
      "epoch": 3.9837137040608592,
      "grad_norm": 0.0033937343396246433,
      "learning_rate": 1.4688381727918854e-05,
      "loss": 0.1541,
      "step": 37180
    },
    {
      "epoch": 3.984785170898961,
      "grad_norm": 0.0043369741179049015,
      "learning_rate": 1.4686953105468053e-05,
      "loss": 0.0002,
      "step": 37190
    },
    {
      "epoch": 3.985856637737062,
      "grad_norm": 22.81572723388672,
      "learning_rate": 1.4685524483017253e-05,
      "loss": 0.3723,
      "step": 37200
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 0.01681951805949211,
      "learning_rate": 1.468409586056645e-05,
      "loss": 0.1777,
      "step": 37210
    },
    {
      "epoch": 3.9879995714132646,
      "grad_norm": 0.03095434233546257,
      "learning_rate": 1.4682667238115648e-05,
      "loss": 0.0988,
      "step": 37220
    },
    {
      "epoch": 3.989071038251366,
      "grad_norm": 50.518898010253906,
      "learning_rate": 1.4681238615664846e-05,
      "loss": 0.2709,
      "step": 37230
    },
    {
      "epoch": 3.9901425050894677,
      "grad_norm": 0.0018991648685187101,
      "learning_rate": 1.4679809993214045e-05,
      "loss": 0.3351,
      "step": 37240
    },
    {
      "epoch": 3.9912139719275688,
      "grad_norm": 0.15009626746177673,
      "learning_rate": 1.4678381370763241e-05,
      "loss": 0.1295,
      "step": 37250
    },
    {
      "epoch": 3.9922854387656703,
      "grad_norm": 0.3166479170322418,
      "learning_rate": 1.467695274831244e-05,
      "loss": 0.0037,
      "step": 37260
    },
    {
      "epoch": 3.9933569056037714,
      "grad_norm": 0.007218502461910248,
      "learning_rate": 1.467552412586164e-05,
      "loss": 0.0008,
      "step": 37270
    },
    {
      "epoch": 3.994428372441873,
      "grad_norm": 0.04966191202402115,
      "learning_rate": 1.4674095503410837e-05,
      "loss": 0.1628,
      "step": 37280
    },
    {
      "epoch": 3.995499839279974,
      "grad_norm": 0.1646568477153778,
      "learning_rate": 1.4672666880960035e-05,
      "loss": 0.1883,
      "step": 37290
    },
    {
      "epoch": 3.9965713061180757,
      "grad_norm": 0.32400646805763245,
      "learning_rate": 1.4671238258509233e-05,
      "loss": 0.4527,
      "step": 37300
    },
    {
      "epoch": 3.997642772956177,
      "grad_norm": 0.0024570187088102102,
      "learning_rate": 1.4669809636058432e-05,
      "loss": 0.2525,
      "step": 37310
    },
    {
      "epoch": 3.9987142397942783,
      "grad_norm": 0.059043604880571365,
      "learning_rate": 1.4668381013607631e-05,
      "loss": 0.6166,
      "step": 37320
    },
    {
      "epoch": 3.99978570663238,
      "grad_norm": 53.498287200927734,
      "learning_rate": 1.4666952391156827e-05,
      "loss": 0.3869,
      "step": 37330
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9605,
      "eval_f1": 0.8468002585649644,
      "eval_loss": 0.16180460155010223,
      "eval_precision": 0.8291139240506329,
      "eval_recall": 0.8652575957727873,
      "eval_runtime": 383.6109,
      "eval_samples_per_second": 15.641,
      "eval_steps_per_second": 5.214,
      "step": 37332
    },
    {
      "epoch": 4.000857173470481,
      "grad_norm": 0.1152895838022232,
      "learning_rate": 1.4665523768706027e-05,
      "loss": 0.0944,
      "step": 37340
    },
    {
      "epoch": 4.0019286403085825,
      "grad_norm": 0.04069321230053902,
      "learning_rate": 1.4664095146255224e-05,
      "loss": 0.0056,
      "step": 37350
    },
    {
      "epoch": 4.003000107146684,
      "grad_norm": 0.5902546048164368,
      "learning_rate": 1.4662666523804424e-05,
      "loss": 0.0025,
      "step": 37360
    },
    {
      "epoch": 4.004071573984785,
      "grad_norm": 0.014490699395537376,
      "learning_rate": 1.466123790135362e-05,
      "loss": 0.1032,
      "step": 37370
    },
    {
      "epoch": 4.005143040822887,
      "grad_norm": 0.04858030378818512,
      "learning_rate": 1.465980927890282e-05,
      "loss": 0.0993,
      "step": 37380
    },
    {
      "epoch": 4.006214507660988,
      "grad_norm": 17.227760314941406,
      "learning_rate": 1.4658380656452019e-05,
      "loss": 0.2194,
      "step": 37390
    },
    {
      "epoch": 4.007285974499089,
      "grad_norm": 0.021837878972291946,
      "learning_rate": 1.4656952034001215e-05,
      "loss": 0.0003,
      "step": 37400
    },
    {
      "epoch": 4.008357441337191,
      "grad_norm": 0.007300739176571369,
      "learning_rate": 1.4655523411550414e-05,
      "loss": 0.1359,
      "step": 37410
    },
    {
      "epoch": 4.009428908175292,
      "grad_norm": 0.0030816642101854086,
      "learning_rate": 1.4654094789099612e-05,
      "loss": 0.0004,
      "step": 37420
    },
    {
      "epoch": 4.010500375013393,
      "grad_norm": 0.00549268675968051,
      "learning_rate": 1.4652666166648811e-05,
      "loss": 0.3048,
      "step": 37430
    },
    {
      "epoch": 4.011571841851494,
      "grad_norm": 0.07915560156106949,
      "learning_rate": 1.4651237544198009e-05,
      "loss": 0.0742,
      "step": 37440
    },
    {
      "epoch": 4.012643308689596,
      "grad_norm": 0.5367755889892578,
      "learning_rate": 1.4649808921747206e-05,
      "loss": 0.001,
      "step": 37450
    },
    {
      "epoch": 4.013714775527697,
      "grad_norm": 0.025751681998372078,
      "learning_rate": 1.4648380299296406e-05,
      "loss": 0.206,
      "step": 37460
    },
    {
      "epoch": 4.0147862423657985,
      "grad_norm": 0.01659819483757019,
      "learning_rate": 1.4646951676845602e-05,
      "loss": 0.202,
      "step": 37470
    },
    {
      "epoch": 4.0158577092039005,
      "grad_norm": 26.411773681640625,
      "learning_rate": 1.4645523054394801e-05,
      "loss": 0.2293,
      "step": 37480
    },
    {
      "epoch": 4.016929176042002,
      "grad_norm": 0.0500616580247879,
      "learning_rate": 1.4644094431943999e-05,
      "loss": 0.2101,
      "step": 37490
    },
    {
      "epoch": 4.018000642880103,
      "grad_norm": 0.008797752670943737,
      "learning_rate": 1.4642665809493198e-05,
      "loss": 0.1062,
      "step": 37500
    },
    {
      "epoch": 4.019072109718204,
      "grad_norm": 0.029710177332162857,
      "learning_rate": 1.4641237187042396e-05,
      "loss": 0.0005,
      "step": 37510
    },
    {
      "epoch": 4.020143576556306,
      "grad_norm": 42.20512771606445,
      "learning_rate": 1.4639808564591593e-05,
      "loss": 0.3854,
      "step": 37520
    },
    {
      "epoch": 4.021215043394407,
      "grad_norm": 0.002092391485348344,
      "learning_rate": 1.4638379942140793e-05,
      "loss": 0.2499,
      "step": 37530
    },
    {
      "epoch": 4.022286510232508,
      "grad_norm": 28.351598739624023,
      "learning_rate": 1.4636951319689989e-05,
      "loss": 0.3577,
      "step": 37540
    },
    {
      "epoch": 4.02335797707061,
      "grad_norm": 0.0448080375790596,
      "learning_rate": 1.4635522697239188e-05,
      "loss": 0.001,
      "step": 37550
    },
    {
      "epoch": 4.024429443908711,
      "grad_norm": 0.005012489855289459,
      "learning_rate": 1.4634094074788387e-05,
      "loss": 0.1589,
      "step": 37560
    },
    {
      "epoch": 4.025500910746812,
      "grad_norm": 0.26305633783340454,
      "learning_rate": 1.4632665452337585e-05,
      "loss": 0.192,
      "step": 37570
    },
    {
      "epoch": 4.026572377584913,
      "grad_norm": 0.0024706569965928793,
      "learning_rate": 1.4631236829886783e-05,
      "loss": 0.0075,
      "step": 37580
    },
    {
      "epoch": 4.027643844423015,
      "grad_norm": 0.6800222396850586,
      "learning_rate": 1.462980820743598e-05,
      "loss": 0.0016,
      "step": 37590
    },
    {
      "epoch": 4.0287153112611165,
      "grad_norm": 0.03759798780083656,
      "learning_rate": 1.462837958498518e-05,
      "loss": 0.0007,
      "step": 37600
    },
    {
      "epoch": 4.029786778099218,
      "grad_norm": 0.0010593195911496878,
      "learning_rate": 1.4626950962534376e-05,
      "loss": 0.0001,
      "step": 37610
    },
    {
      "epoch": 4.03085824493732,
      "grad_norm": 0.0009200749336741865,
      "learning_rate": 1.4625522340083575e-05,
      "loss": 0.0009,
      "step": 37620
    },
    {
      "epoch": 4.031929711775421,
      "grad_norm": 0.0011962724383920431,
      "learning_rate": 1.4624093717632775e-05,
      "loss": 0.0004,
      "step": 37630
    },
    {
      "epoch": 4.033001178613522,
      "grad_norm": 0.02683190256357193,
      "learning_rate": 1.4622665095181972e-05,
      "loss": 0.2236,
      "step": 37640
    },
    {
      "epoch": 4.034072645451623,
      "grad_norm": 0.05548912659287453,
      "learning_rate": 1.462123647273117e-05,
      "loss": 0.0013,
      "step": 37650
    },
    {
      "epoch": 4.035144112289725,
      "grad_norm": 0.32084062695503235,
      "learning_rate": 1.4619807850280368e-05,
      "loss": 0.0016,
      "step": 37660
    },
    {
      "epoch": 4.036215579127826,
      "grad_norm": 0.004120773635804653,
      "learning_rate": 1.4618379227829567e-05,
      "loss": 0.2222,
      "step": 37670
    },
    {
      "epoch": 4.037287045965927,
      "grad_norm": 0.0014992165379226208,
      "learning_rate": 1.4616950605378766e-05,
      "loss": 0.0008,
      "step": 37680
    },
    {
      "epoch": 4.038358512804029,
      "grad_norm": 0.03351384401321411,
      "learning_rate": 1.4615521982927962e-05,
      "loss": 0.0007,
      "step": 37690
    },
    {
      "epoch": 4.03942997964213,
      "grad_norm": 0.025467557832598686,
      "learning_rate": 1.4614093360477162e-05,
      "loss": 0.1221,
      "step": 37700
    },
    {
      "epoch": 4.040501446480231,
      "grad_norm": 0.0018831640481948853,
      "learning_rate": 1.461266473802636e-05,
      "loss": 0.0008,
      "step": 37710
    },
    {
      "epoch": 4.0415729133183325,
      "grad_norm": 0.040363751351833344,
      "learning_rate": 1.4611236115575557e-05,
      "loss": 0.0007,
      "step": 37720
    },
    {
      "epoch": 4.0426443801564345,
      "grad_norm": 0.023678340017795563,
      "learning_rate": 1.4609807493124755e-05,
      "loss": 0.0012,
      "step": 37730
    },
    {
      "epoch": 4.043715846994536,
      "grad_norm": 0.6987133026123047,
      "learning_rate": 1.4608378870673954e-05,
      "loss": 0.0007,
      "step": 37740
    },
    {
      "epoch": 4.044787313832637,
      "grad_norm": 0.0018986734794452786,
      "learning_rate": 1.4606950248223153e-05,
      "loss": 0.0004,
      "step": 37750
    },
    {
      "epoch": 4.045858780670739,
      "grad_norm": 0.0011105095036327839,
      "learning_rate": 1.460552162577235e-05,
      "loss": 0.0002,
      "step": 37760
    },
    {
      "epoch": 4.04693024750884,
      "grad_norm": 0.049301184713840485,
      "learning_rate": 1.4604093003321549e-05,
      "loss": 0.0866,
      "step": 37770
    },
    {
      "epoch": 4.048001714346941,
      "grad_norm": 0.02690591849386692,
      "learning_rate": 1.4602664380870746e-05,
      "loss": 0.1991,
      "step": 37780
    },
    {
      "epoch": 4.049073181185042,
      "grad_norm": 45.250633239746094,
      "learning_rate": 1.4601235758419944e-05,
      "loss": 0.2644,
      "step": 37790
    },
    {
      "epoch": 4.050144648023144,
      "grad_norm": 0.02948121540248394,
      "learning_rate": 1.4599807135969143e-05,
      "loss": 0.418,
      "step": 37800
    },
    {
      "epoch": 4.051216114861245,
      "grad_norm": 439.4327697753906,
      "learning_rate": 1.4598378513518341e-05,
      "loss": 0.2558,
      "step": 37810
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 0.026905756443738937,
      "learning_rate": 1.459694989106754e-05,
      "loss": 0.0005,
      "step": 37820
    },
    {
      "epoch": 4.053359048537447,
      "grad_norm": 0.04532063752412796,
      "learning_rate": 1.4595521268616736e-05,
      "loss": 0.4081,
      "step": 37830
    },
    {
      "epoch": 4.054430515375549,
      "grad_norm": 0.023115839809179306,
      "learning_rate": 1.4594092646165936e-05,
      "loss": 0.0037,
      "step": 37840
    },
    {
      "epoch": 4.05550198221365,
      "grad_norm": 0.009472335688769817,
      "learning_rate": 1.4592664023715134e-05,
      "loss": 0.1302,
      "step": 37850
    },
    {
      "epoch": 4.0565734490517515,
      "grad_norm": 0.34461650252342224,
      "learning_rate": 1.4591235401264331e-05,
      "loss": 0.0014,
      "step": 37860
    },
    {
      "epoch": 4.0576449158898535,
      "grad_norm": 25.136518478393555,
      "learning_rate": 1.458980677881353e-05,
      "loss": 0.255,
      "step": 37870
    },
    {
      "epoch": 4.058716382727955,
      "grad_norm": 0.005618306342512369,
      "learning_rate": 1.4588378156362728e-05,
      "loss": 0.001,
      "step": 37880
    },
    {
      "epoch": 4.059787849566056,
      "grad_norm": 0.060962893068790436,
      "learning_rate": 1.4586949533911928e-05,
      "loss": 0.0007,
      "step": 37890
    },
    {
      "epoch": 4.060859316404157,
      "grad_norm": 0.001487650559283793,
      "learning_rate": 1.4585520911461124e-05,
      "loss": 0.0004,
      "step": 37900
    },
    {
      "epoch": 4.061930783242259,
      "grad_norm": 61.92414855957031,
      "learning_rate": 1.4584092289010323e-05,
      "loss": 0.5086,
      "step": 37910
    },
    {
      "epoch": 4.06300225008036,
      "grad_norm": 0.20908567309379578,
      "learning_rate": 1.4582663666559522e-05,
      "loss": 0.0078,
      "step": 37920
    },
    {
      "epoch": 4.064073716918461,
      "grad_norm": 0.10479406267404556,
      "learning_rate": 1.458123504410872e-05,
      "loss": 0.1476,
      "step": 37930
    },
    {
      "epoch": 4.065145183756563,
      "grad_norm": 0.0676492378115654,
      "learning_rate": 1.4579806421657918e-05,
      "loss": 0.1878,
      "step": 37940
    },
    {
      "epoch": 4.066216650594664,
      "grad_norm": 0.004923458676785231,
      "learning_rate": 1.4578377799207115e-05,
      "loss": 0.0005,
      "step": 37950
    },
    {
      "epoch": 4.067288117432765,
      "grad_norm": 0.0006544181960634887,
      "learning_rate": 1.4576949176756315e-05,
      "loss": 0.0013,
      "step": 37960
    },
    {
      "epoch": 4.068359584270866,
      "grad_norm": 34.901309967041016,
      "learning_rate": 1.457552055430551e-05,
      "loss": 0.302,
      "step": 37970
    },
    {
      "epoch": 4.069431051108968,
      "grad_norm": 0.07064139097929001,
      "learning_rate": 1.457409193185471e-05,
      "loss": 0.0015,
      "step": 37980
    },
    {
      "epoch": 4.0705025179470695,
      "grad_norm": 0.059624724090099335,
      "learning_rate": 1.457266330940391e-05,
      "loss": 0.0606,
      "step": 37990
    },
    {
      "epoch": 4.071573984785171,
      "grad_norm": 17.749975204467773,
      "learning_rate": 1.4571234686953107e-05,
      "loss": 0.4783,
      "step": 38000
    },
    {
      "epoch": 4.072645451623273,
      "grad_norm": 0.044620122760534286,
      "learning_rate": 1.4569806064502305e-05,
      "loss": 0.001,
      "step": 38010
    },
    {
      "epoch": 4.073716918461374,
      "grad_norm": 0.006392850540578365,
      "learning_rate": 1.4568377442051502e-05,
      "loss": 0.0997,
      "step": 38020
    },
    {
      "epoch": 4.074788385299475,
      "grad_norm": 0.00041060344665311277,
      "learning_rate": 1.4566948819600702e-05,
      "loss": 0.1827,
      "step": 38030
    },
    {
      "epoch": 4.075859852137576,
      "grad_norm": 289.8275146484375,
      "learning_rate": 1.4565520197149901e-05,
      "loss": 0.0086,
      "step": 38040
    },
    {
      "epoch": 4.076931318975678,
      "grad_norm": 0.0014357961481437087,
      "learning_rate": 1.4564091574699097e-05,
      "loss": 0.0001,
      "step": 38050
    },
    {
      "epoch": 4.078002785813779,
      "grad_norm": 0.0012625554809346795,
      "learning_rate": 1.4562662952248296e-05,
      "loss": 0.2092,
      "step": 38060
    },
    {
      "epoch": 4.07907425265188,
      "grad_norm": 0.006188712548464537,
      "learning_rate": 1.4561234329797494e-05,
      "loss": 0.0014,
      "step": 38070
    },
    {
      "epoch": 4.080145719489982,
      "grad_norm": 0.10930400341749191,
      "learning_rate": 1.4559805707346692e-05,
      "loss": 0.1109,
      "step": 38080
    },
    {
      "epoch": 4.081217186328083,
      "grad_norm": 0.0032036982011049986,
      "learning_rate": 1.455837708489589e-05,
      "loss": 0.1068,
      "step": 38090
    },
    {
      "epoch": 4.082288653166184,
      "grad_norm": 0.0003733014455065131,
      "learning_rate": 1.4556948462445089e-05,
      "loss": 0.2843,
      "step": 38100
    },
    {
      "epoch": 4.0833601200042855,
      "grad_norm": 0.0008673934498801827,
      "learning_rate": 1.4555519839994288e-05,
      "loss": 0.0906,
      "step": 38110
    },
    {
      "epoch": 4.0844315868423875,
      "grad_norm": 0.4923146665096283,
      "learning_rate": 1.4554091217543484e-05,
      "loss": 0.1771,
      "step": 38120
    },
    {
      "epoch": 4.085503053680489,
      "grad_norm": 0.10828033834695816,
      "learning_rate": 1.4552662595092684e-05,
      "loss": 0.0007,
      "step": 38130
    },
    {
      "epoch": 4.08657452051859,
      "grad_norm": 0.029176434502005577,
      "learning_rate": 1.4551233972641881e-05,
      "loss": 0.1921,
      "step": 38140
    },
    {
      "epoch": 4.087645987356692,
      "grad_norm": 33.66876983642578,
      "learning_rate": 1.4549805350191079e-05,
      "loss": 0.1004,
      "step": 38150
    },
    {
      "epoch": 4.088717454194793,
      "grad_norm": 0.000553577730897814,
      "learning_rate": 1.4548376727740277e-05,
      "loss": 0.0002,
      "step": 38160
    },
    {
      "epoch": 4.089788921032894,
      "grad_norm": 0.08539659529924393,
      "learning_rate": 1.4546948105289476e-05,
      "loss": 0.0013,
      "step": 38170
    },
    {
      "epoch": 4.090860387870995,
      "grad_norm": 0.00020263429905753583,
      "learning_rate": 1.4545519482838675e-05,
      "loss": 0.0001,
      "step": 38180
    },
    {
      "epoch": 4.091931854709097,
      "grad_norm": 0.0015342718688771129,
      "learning_rate": 1.4544090860387871e-05,
      "loss": 0.591,
      "step": 38190
    },
    {
      "epoch": 4.093003321547198,
      "grad_norm": 0.00031031566322781146,
      "learning_rate": 1.454266223793707e-05,
      "loss": 0.0003,
      "step": 38200
    },
    {
      "epoch": 4.094074788385299,
      "grad_norm": 0.0009004109888337553,
      "learning_rate": 1.4541233615486268e-05,
      "loss": 0.3609,
      "step": 38210
    },
    {
      "epoch": 4.095146255223401,
      "grad_norm": 0.006444244179874659,
      "learning_rate": 1.4539804993035466e-05,
      "loss": 0.1487,
      "step": 38220
    },
    {
      "epoch": 4.096217722061502,
      "grad_norm": 0.0015768154989928007,
      "learning_rate": 1.4538376370584665e-05,
      "loss": 0.002,
      "step": 38230
    },
    {
      "epoch": 4.0972891888996035,
      "grad_norm": 0.0031180130317807198,
      "learning_rate": 1.4536947748133863e-05,
      "loss": 0.0652,
      "step": 38240
    },
    {
      "epoch": 4.098360655737705,
      "grad_norm": 0.03075610101222992,
      "learning_rate": 1.4535519125683062e-05,
      "loss": 0.001,
      "step": 38250
    },
    {
      "epoch": 4.099432122575807,
      "grad_norm": 26.23044776916504,
      "learning_rate": 1.4534090503232258e-05,
      "loss": 0.1392,
      "step": 38260
    },
    {
      "epoch": 4.100503589413908,
      "grad_norm": 0.0008440681267529726,
      "learning_rate": 1.4532661880781458e-05,
      "loss": 0.2134,
      "step": 38270
    },
    {
      "epoch": 4.101575056252009,
      "grad_norm": 0.0008813767926767468,
      "learning_rate": 1.4531233258330655e-05,
      "loss": 0.0013,
      "step": 38280
    },
    {
      "epoch": 4.102646523090111,
      "grad_norm": 0.0005923397256992757,
      "learning_rate": 1.4529804635879853e-05,
      "loss": 0.0001,
      "step": 38290
    },
    {
      "epoch": 4.103717989928212,
      "grad_norm": 0.02707282267510891,
      "learning_rate": 1.4528376013429052e-05,
      "loss": 0.0002,
      "step": 38300
    },
    {
      "epoch": 4.104789456766313,
      "grad_norm": 0.0005283909267745912,
      "learning_rate": 1.452694739097825e-05,
      "loss": 0.0005,
      "step": 38310
    },
    {
      "epoch": 4.105860923604414,
      "grad_norm": 0.0005577670526690781,
      "learning_rate": 1.452551876852745e-05,
      "loss": 0.0001,
      "step": 38320
    },
    {
      "epoch": 4.106932390442516,
      "grad_norm": 0.040891632437705994,
      "learning_rate": 1.4524090146076646e-05,
      "loss": 0.0003,
      "step": 38330
    },
    {
      "epoch": 4.108003857280617,
      "grad_norm": 0.031017422676086426,
      "learning_rate": 1.4522661523625845e-05,
      "loss": 0.0006,
      "step": 38340
    },
    {
      "epoch": 4.109075324118718,
      "grad_norm": 0.02246726118028164,
      "learning_rate": 1.4521232901175044e-05,
      "loss": 0.2198,
      "step": 38350
    },
    {
      "epoch": 4.1101467909568195,
      "grad_norm": 0.016400180757045746,
      "learning_rate": 1.451980427872424e-05,
      "loss": 0.2112,
      "step": 38360
    },
    {
      "epoch": 4.1112182577949214,
      "grad_norm": 0.01986001618206501,
      "learning_rate": 1.451837565627344e-05,
      "loss": 0.0003,
      "step": 38370
    },
    {
      "epoch": 4.112289724633023,
      "grad_norm": 0.034759972244501114,
      "learning_rate": 1.4516947033822637e-05,
      "loss": 0.0014,
      "step": 38380
    },
    {
      "epoch": 4.113361191471124,
      "grad_norm": 0.0015184718649834394,
      "learning_rate": 1.4515518411371837e-05,
      "loss": 0.334,
      "step": 38390
    },
    {
      "epoch": 4.114432658309226,
      "grad_norm": 0.02610659971833229,
      "learning_rate": 1.4514089788921033e-05,
      "loss": 0.0004,
      "step": 38400
    },
    {
      "epoch": 4.115504125147327,
      "grad_norm": 0.0016423516208305955,
      "learning_rate": 1.4512661166470232e-05,
      "loss": 0.0004,
      "step": 38410
    },
    {
      "epoch": 4.116575591985428,
      "grad_norm": 0.01269895862787962,
      "learning_rate": 1.4511232544019431e-05,
      "loss": 0.0002,
      "step": 38420
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.012294075451791286,
      "learning_rate": 1.4509803921568629e-05,
      "loss": 0.1341,
      "step": 38430
    },
    {
      "epoch": 4.118718525661631,
      "grad_norm": 0.001091766287572682,
      "learning_rate": 1.4508375299117827e-05,
      "loss": 0.0002,
      "step": 38440
    },
    {
      "epoch": 4.119789992499732,
      "grad_norm": 0.023520849645137787,
      "learning_rate": 1.4506946676667024e-05,
      "loss": 0.0001,
      "step": 38450
    },
    {
      "epoch": 4.120861459337833,
      "grad_norm": 36.265411376953125,
      "learning_rate": 1.4505518054216224e-05,
      "loss": 0.3909,
      "step": 38460
    },
    {
      "epoch": 4.121932926175935,
      "grad_norm": 0.000597893085796386,
      "learning_rate": 1.4504089431765423e-05,
      "loss": 0.0012,
      "step": 38470
    },
    {
      "epoch": 4.123004393014036,
      "grad_norm": 0.043193716555833817,
      "learning_rate": 1.4502660809314619e-05,
      "loss": 0.2842,
      "step": 38480
    },
    {
      "epoch": 4.124075859852137,
      "grad_norm": 0.03456564247608185,
      "learning_rate": 1.4501232186863818e-05,
      "loss": 0.0804,
      "step": 38490
    },
    {
      "epoch": 4.1251473266902385,
      "grad_norm": 0.01360135618597269,
      "learning_rate": 1.4499803564413016e-05,
      "loss": 0.0003,
      "step": 38500
    },
    {
      "epoch": 4.1262187935283405,
      "grad_norm": 0.04743729904294014,
      "learning_rate": 1.4498374941962214e-05,
      "loss": 0.0008,
      "step": 38510
    },
    {
      "epoch": 4.127290260366442,
      "grad_norm": 0.03167400509119034,
      "learning_rate": 1.4496946319511411e-05,
      "loss": 0.1607,
      "step": 38520
    },
    {
      "epoch": 4.128361727204543,
      "grad_norm": 0.0011259716702625155,
      "learning_rate": 1.449551769706061e-05,
      "loss": 0.1407,
      "step": 38530
    },
    {
      "epoch": 4.129433194042645,
      "grad_norm": 2.1304948329925537,
      "learning_rate": 1.449408907460981e-05,
      "loss": 0.001,
      "step": 38540
    },
    {
      "epoch": 4.130504660880746,
      "grad_norm": 0.022143356502056122,
      "learning_rate": 1.4492660452159006e-05,
      "loss": 0.3076,
      "step": 38550
    },
    {
      "epoch": 4.131576127718847,
      "grad_norm": 0.000988215091638267,
      "learning_rate": 1.4491231829708206e-05,
      "loss": 0.0011,
      "step": 38560
    },
    {
      "epoch": 4.132647594556948,
      "grad_norm": 45.9301872253418,
      "learning_rate": 1.4489803207257403e-05,
      "loss": 0.216,
      "step": 38570
    },
    {
      "epoch": 4.13371906139505,
      "grad_norm": 0.0025679829996079206,
      "learning_rate": 1.4488374584806601e-05,
      "loss": 0.0003,
      "step": 38580
    },
    {
      "epoch": 4.134790528233151,
      "grad_norm": 0.5913113355636597,
      "learning_rate": 1.44869459623558e-05,
      "loss": 0.1207,
      "step": 38590
    },
    {
      "epoch": 4.135861995071252,
      "grad_norm": 0.0030578868463635445,
      "learning_rate": 1.4485517339904998e-05,
      "loss": 0.0008,
      "step": 38600
    },
    {
      "epoch": 4.136933461909354,
      "grad_norm": 0.05061117559671402,
      "learning_rate": 1.4484088717454197e-05,
      "loss": 0.1177,
      "step": 38610
    },
    {
      "epoch": 4.138004928747455,
      "grad_norm": 0.0022757300175726414,
      "learning_rate": 1.4482660095003393e-05,
      "loss": 0.0149,
      "step": 38620
    },
    {
      "epoch": 4.1390763955855565,
      "grad_norm": 0.19494645297527313,
      "learning_rate": 1.4481231472552593e-05,
      "loss": 0.2093,
      "step": 38630
    },
    {
      "epoch": 4.140147862423658,
      "grad_norm": 0.00047628331230953336,
      "learning_rate": 1.447980285010179e-05,
      "loss": 0.0023,
      "step": 38640
    },
    {
      "epoch": 4.14121932926176,
      "grad_norm": 0.007486078422516584,
      "learning_rate": 1.4478374227650988e-05,
      "loss": 0.138,
      "step": 38650
    },
    {
      "epoch": 4.142290796099861,
      "grad_norm": 0.0005712932907044888,
      "learning_rate": 1.4476945605200187e-05,
      "loss": 0.141,
      "step": 38660
    },
    {
      "epoch": 4.143362262937962,
      "grad_norm": 69.78832244873047,
      "learning_rate": 1.4475516982749385e-05,
      "loss": 0.7573,
      "step": 38670
    },
    {
      "epoch": 4.144433729776064,
      "grad_norm": 0.07806868106126785,
      "learning_rate": 1.4474088360298584e-05,
      "loss": 0.0029,
      "step": 38680
    },
    {
      "epoch": 4.145505196614165,
      "grad_norm": 0.020339183509349823,
      "learning_rate": 1.447265973784778e-05,
      "loss": 0.135,
      "step": 38690
    },
    {
      "epoch": 4.146576663452266,
      "grad_norm": 47.071075439453125,
      "learning_rate": 1.447123111539698e-05,
      "loss": 0.0944,
      "step": 38700
    },
    {
      "epoch": 4.147648130290367,
      "grad_norm": 0.5084621906280518,
      "learning_rate": 1.4469802492946179e-05,
      "loss": 0.2316,
      "step": 38710
    },
    {
      "epoch": 4.148719597128469,
      "grad_norm": 0.04141032695770264,
      "learning_rate": 1.4468373870495375e-05,
      "loss": 0.1971,
      "step": 38720
    },
    {
      "epoch": 4.14979106396657,
      "grad_norm": 28.531679153442383,
      "learning_rate": 1.4466945248044574e-05,
      "loss": 0.2817,
      "step": 38730
    },
    {
      "epoch": 4.150862530804671,
      "grad_norm": 0.0009306574938818812,
      "learning_rate": 1.4465516625593772e-05,
      "loss": 0.1439,
      "step": 38740
    },
    {
      "epoch": 4.151933997642773,
      "grad_norm": 0.024729907512664795,
      "learning_rate": 1.4464088003142971e-05,
      "loss": 0.1827,
      "step": 38750
    },
    {
      "epoch": 4.1530054644808745,
      "grad_norm": 0.027881525456905365,
      "learning_rate": 1.4462659380692167e-05,
      "loss": 0.34,
      "step": 38760
    },
    {
      "epoch": 4.154076931318976,
      "grad_norm": 1.8671948909759521,
      "learning_rate": 1.4461230758241367e-05,
      "loss": 0.1001,
      "step": 38770
    },
    {
      "epoch": 4.155148398157077,
      "grad_norm": 0.30102038383483887,
      "learning_rate": 1.4459802135790566e-05,
      "loss": 0.0015,
      "step": 38780
    },
    {
      "epoch": 4.156219864995179,
      "grad_norm": 0.07091224193572998,
      "learning_rate": 1.4458373513339762e-05,
      "loss": 0.0003,
      "step": 38790
    },
    {
      "epoch": 4.15729133183328,
      "grad_norm": 0.003908712416887283,
      "learning_rate": 1.4456944890888962e-05,
      "loss": 0.1496,
      "step": 38800
    },
    {
      "epoch": 4.158362798671381,
      "grad_norm": 0.001033022883348167,
      "learning_rate": 1.445551626843816e-05,
      "loss": 0.1782,
      "step": 38810
    },
    {
      "epoch": 4.159434265509482,
      "grad_norm": 0.2912096083164215,
      "learning_rate": 1.4454087645987359e-05,
      "loss": 0.0016,
      "step": 38820
    },
    {
      "epoch": 4.160505732347584,
      "grad_norm": 0.1011606976389885,
      "learning_rate": 1.4452659023536558e-05,
      "loss": 0.0003,
      "step": 38830
    },
    {
      "epoch": 4.161577199185685,
      "grad_norm": 0.0006676475168205798,
      "learning_rate": 1.4451230401085754e-05,
      "loss": 0.3003,
      "step": 38840
    },
    {
      "epoch": 4.162648666023786,
      "grad_norm": 0.0005967451143078506,
      "learning_rate": 1.4449801778634953e-05,
      "loss": 0.1497,
      "step": 38850
    },
    {
      "epoch": 4.163720132861888,
      "grad_norm": 0.0009908770443871617,
      "learning_rate": 1.444837315618415e-05,
      "loss": 0.4526,
      "step": 38860
    },
    {
      "epoch": 4.164791599699989,
      "grad_norm": 0.06367114186286926,
      "learning_rate": 1.4446944533733349e-05,
      "loss": 0.113,
      "step": 38870
    },
    {
      "epoch": 4.1658630665380905,
      "grad_norm": 0.012787994928658009,
      "learning_rate": 1.4445515911282546e-05,
      "loss": 0.0013,
      "step": 38880
    },
    {
      "epoch": 4.1669345333761925,
      "grad_norm": 0.05548648536205292,
      "learning_rate": 1.4444087288831746e-05,
      "loss": 0.3616,
      "step": 38890
    },
    {
      "epoch": 4.168006000214294,
      "grad_norm": 0.08355274051427841,
      "learning_rate": 1.4442658666380945e-05,
      "loss": 0.0014,
      "step": 38900
    },
    {
      "epoch": 4.169077467052395,
      "grad_norm": 0.09902654588222504,
      "learning_rate": 1.4441230043930141e-05,
      "loss": 0.33,
      "step": 38910
    },
    {
      "epoch": 4.170148933890496,
      "grad_norm": 0.3360198438167572,
      "learning_rate": 1.443980142147934e-05,
      "loss": 0.0105,
      "step": 38920
    },
    {
      "epoch": 4.171220400728598,
      "grad_norm": 0.0013869950780645013,
      "learning_rate": 1.4438372799028536e-05,
      "loss": 0.1354,
      "step": 38930
    },
    {
      "epoch": 4.172291867566699,
      "grad_norm": 0.025690555572509766,
      "learning_rate": 1.4436944176577736e-05,
      "loss": 0.0016,
      "step": 38940
    },
    {
      "epoch": 4.1733633344048,
      "grad_norm": 0.00335711776278913,
      "learning_rate": 1.4435515554126935e-05,
      "loss": 0.0004,
      "step": 38950
    },
    {
      "epoch": 4.174434801242901,
      "grad_norm": 0.029266688972711563,
      "learning_rate": 1.4434086931676133e-05,
      "loss": 0.0004,
      "step": 38960
    },
    {
      "epoch": 4.175506268081003,
      "grad_norm": 0.015974977985024452,
      "learning_rate": 1.4432658309225332e-05,
      "loss": 0.1989,
      "step": 38970
    },
    {
      "epoch": 4.176577734919104,
      "grad_norm": 0.001278716023080051,
      "learning_rate": 1.4431229686774528e-05,
      "loss": 0.1641,
      "step": 38980
    },
    {
      "epoch": 4.177649201757205,
      "grad_norm": 0.0025237787049263716,
      "learning_rate": 1.4429801064323727e-05,
      "loss": 0.0003,
      "step": 38990
    },
    {
      "epoch": 4.178720668595307,
      "grad_norm": 0.00042967492481693625,
      "learning_rate": 1.4428372441872925e-05,
      "loss": 0.2873,
      "step": 39000
    },
    {
      "epoch": 4.179792135433408,
      "grad_norm": 0.0009979757014662027,
      "learning_rate": 1.4426943819422123e-05,
      "loss": 0.1933,
      "step": 39010
    },
    {
      "epoch": 4.1808636022715095,
      "grad_norm": 0.16816140711307526,
      "learning_rate": 1.4425515196971322e-05,
      "loss": 0.0008,
      "step": 39020
    },
    {
      "epoch": 4.181935069109611,
      "grad_norm": 0.0038574556820094585,
      "learning_rate": 1.442408657452052e-05,
      "loss": 0.0019,
      "step": 39030
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 14.668643951416016,
      "learning_rate": 1.442265795206972e-05,
      "loss": 0.1677,
      "step": 39040
    },
    {
      "epoch": 4.184078002785814,
      "grad_norm": 14.669234275817871,
      "learning_rate": 1.4421229329618915e-05,
      "loss": 0.1609,
      "step": 39050
    },
    {
      "epoch": 4.185149469623915,
      "grad_norm": 0.0012922146124765277,
      "learning_rate": 1.4419800707168115e-05,
      "loss": 0.1311,
      "step": 39060
    },
    {
      "epoch": 4.186220936462017,
      "grad_norm": 0.02967161126434803,
      "learning_rate": 1.4418372084717312e-05,
      "loss": 0.2098,
      "step": 39070
    },
    {
      "epoch": 4.187292403300118,
      "grad_norm": 0.00036086238105781376,
      "learning_rate": 1.441694346226651e-05,
      "loss": 0.1626,
      "step": 39080
    },
    {
      "epoch": 4.188363870138219,
      "grad_norm": 0.22713282704353333,
      "learning_rate": 1.441551483981571e-05,
      "loss": 0.0007,
      "step": 39090
    },
    {
      "epoch": 4.18943533697632,
      "grad_norm": 0.00024105490592774004,
      "learning_rate": 1.4414086217364907e-05,
      "loss": 0.0019,
      "step": 39100
    },
    {
      "epoch": 4.190506803814422,
      "grad_norm": 0.020042454823851585,
      "learning_rate": 1.4412657594914106e-05,
      "loss": 0.0006,
      "step": 39110
    },
    {
      "epoch": 4.191578270652523,
      "grad_norm": 0.3729494512081146,
      "learning_rate": 1.4411228972463302e-05,
      "loss": 0.2647,
      "step": 39120
    },
    {
      "epoch": 4.192649737490624,
      "grad_norm": 0.0013016607845202088,
      "learning_rate": 1.4409800350012502e-05,
      "loss": 0.0008,
      "step": 39130
    },
    {
      "epoch": 4.193721204328726,
      "grad_norm": 0.0005258843884803355,
      "learning_rate": 1.4408371727561701e-05,
      "loss": 0.2967,
      "step": 39140
    },
    {
      "epoch": 4.1947926711668275,
      "grad_norm": 0.01050585601478815,
      "learning_rate": 1.4406943105110897e-05,
      "loss": 0.317,
      "step": 39150
    },
    {
      "epoch": 4.195864138004929,
      "grad_norm": 0.0002586519985925406,
      "learning_rate": 1.4405514482660096e-05,
      "loss": 0.0014,
      "step": 39160
    },
    {
      "epoch": 4.19693560484303,
      "grad_norm": 0.017071999609470367,
      "learning_rate": 1.4404085860209294e-05,
      "loss": 0.6797,
      "step": 39170
    },
    {
      "epoch": 4.198007071681132,
      "grad_norm": 0.013783899135887623,
      "learning_rate": 1.4402657237758493e-05,
      "loss": 0.2519,
      "step": 39180
    },
    {
      "epoch": 4.199078538519233,
      "grad_norm": 0.0494445338845253,
      "learning_rate": 1.440122861530769e-05,
      "loss": 0.0008,
      "step": 39190
    },
    {
      "epoch": 4.200150005357334,
      "grad_norm": 0.02473818138241768,
      "learning_rate": 1.4399799992856889e-05,
      "loss": 0.3312,
      "step": 39200
    },
    {
      "epoch": 4.201221472195436,
      "grad_norm": 0.05282796174287796,
      "learning_rate": 1.4398371370406088e-05,
      "loss": 0.0017,
      "step": 39210
    },
    {
      "epoch": 4.202292939033537,
      "grad_norm": 0.018723495304584503,
      "learning_rate": 1.4396942747955284e-05,
      "loss": 0.0011,
      "step": 39220
    },
    {
      "epoch": 4.203364405871638,
      "grad_norm": 0.009218449704349041,
      "learning_rate": 1.4395514125504483e-05,
      "loss": 0.2184,
      "step": 39230
    },
    {
      "epoch": 4.204435872709739,
      "grad_norm": 0.028591075912117958,
      "learning_rate": 1.4394085503053681e-05,
      "loss": 0.3405,
      "step": 39240
    },
    {
      "epoch": 4.205507339547841,
      "grad_norm": 0.033251043409109116,
      "learning_rate": 1.439265688060288e-05,
      "loss": 0.0005,
      "step": 39250
    },
    {
      "epoch": 4.206578806385942,
      "grad_norm": 0.15582378208637238,
      "learning_rate": 1.439122825815208e-05,
      "loss": 0.0008,
      "step": 39260
    },
    {
      "epoch": 4.2076502732240435,
      "grad_norm": 0.018529538065195084,
      "learning_rate": 1.4389799635701276e-05,
      "loss": 0.0009,
      "step": 39270
    },
    {
      "epoch": 4.2087217400621455,
      "grad_norm": 0.0011969300685450435,
      "learning_rate": 1.4388371013250475e-05,
      "loss": 0.0003,
      "step": 39280
    },
    {
      "epoch": 4.209793206900247,
      "grad_norm": 0.054276254028081894,
      "learning_rate": 1.4386942390799671e-05,
      "loss": 0.0003,
      "step": 39290
    },
    {
      "epoch": 4.210864673738348,
      "grad_norm": 0.0005623840843327343,
      "learning_rate": 1.438551376834887e-05,
      "loss": 0.0008,
      "step": 39300
    },
    {
      "epoch": 4.211936140576449,
      "grad_norm": 16.314054489135742,
      "learning_rate": 1.4384085145898068e-05,
      "loss": 0.5597,
      "step": 39310
    },
    {
      "epoch": 4.213007607414551,
      "grad_norm": 0.006106227170675993,
      "learning_rate": 1.4382656523447268e-05,
      "loss": 0.0011,
      "step": 39320
    },
    {
      "epoch": 4.214079074252652,
      "grad_norm": 0.0005421628593467176,
      "learning_rate": 1.4381227900996467e-05,
      "loss": 0.0614,
      "step": 39330
    },
    {
      "epoch": 4.215150541090753,
      "grad_norm": 0.04375263303518295,
      "learning_rate": 1.4379799278545663e-05,
      "loss": 0.0005,
      "step": 39340
    },
    {
      "epoch": 4.216222007928854,
      "grad_norm": 0.00034772465005517006,
      "learning_rate": 1.4378370656094862e-05,
      "loss": 0.001,
      "step": 39350
    },
    {
      "epoch": 4.217293474766956,
      "grad_norm": 0.0009849569760262966,
      "learning_rate": 1.4376942033644058e-05,
      "loss": 0.1878,
      "step": 39360
    },
    {
      "epoch": 4.218364941605057,
      "grad_norm": 0.2092542052268982,
      "learning_rate": 1.4375513411193258e-05,
      "loss": 0.3108,
      "step": 39370
    },
    {
      "epoch": 4.219436408443158,
      "grad_norm": 0.009877857752144337,
      "learning_rate": 1.4374084788742457e-05,
      "loss": 0.0121,
      "step": 39380
    },
    {
      "epoch": 4.22050787528126,
      "grad_norm": 0.0015850708587095141,
      "learning_rate": 1.4372656166291655e-05,
      "loss": 0.2123,
      "step": 39390
    },
    {
      "epoch": 4.2215793421193615,
      "grad_norm": 0.0008090698393061757,
      "learning_rate": 1.4371227543840854e-05,
      "loss": 0.1684,
      "step": 39400
    },
    {
      "epoch": 4.222650808957463,
      "grad_norm": 0.01044695358723402,
      "learning_rate": 1.436979892139005e-05,
      "loss": 0.0008,
      "step": 39410
    },
    {
      "epoch": 4.223722275795565,
      "grad_norm": 0.0009630673448555171,
      "learning_rate": 1.436837029893925e-05,
      "loss": 0.0006,
      "step": 39420
    },
    {
      "epoch": 4.224793742633666,
      "grad_norm": 0.1752622127532959,
      "learning_rate": 1.4366941676488445e-05,
      "loss": 0.003,
      "step": 39430
    },
    {
      "epoch": 4.225865209471767,
      "grad_norm": 17.317914962768555,
      "learning_rate": 1.4365513054037645e-05,
      "loss": 0.3671,
      "step": 39440
    },
    {
      "epoch": 4.226936676309868,
      "grad_norm": 0.06654124706983566,
      "learning_rate": 1.4364084431586844e-05,
      "loss": 0.0008,
      "step": 39450
    },
    {
      "epoch": 4.22800814314797,
      "grad_norm": 0.21883860230445862,
      "learning_rate": 1.4362655809136042e-05,
      "loss": 0.2464,
      "step": 39460
    },
    {
      "epoch": 4.229079609986071,
      "grad_norm": 0.0014575616223737597,
      "learning_rate": 1.4361227186685241e-05,
      "loss": 0.0002,
      "step": 39470
    },
    {
      "epoch": 4.230151076824172,
      "grad_norm": 0.16479846835136414,
      "learning_rate": 1.4359798564234437e-05,
      "loss": 0.1787,
      "step": 39480
    },
    {
      "epoch": 4.231222543662273,
      "grad_norm": 0.00041050073923543096,
      "learning_rate": 1.4358369941783636e-05,
      "loss": 0.2619,
      "step": 39490
    },
    {
      "epoch": 4.232294010500375,
      "grad_norm": 0.0032455679029226303,
      "learning_rate": 1.4356941319332836e-05,
      "loss": 0.1368,
      "step": 39500
    },
    {
      "epoch": 4.233365477338476,
      "grad_norm": 0.02586229331791401,
      "learning_rate": 1.4355512696882032e-05,
      "loss": 0.0013,
      "step": 39510
    },
    {
      "epoch": 4.2344369441765775,
      "grad_norm": 0.0801919475197792,
      "learning_rate": 1.4354084074431231e-05,
      "loss": 0.2323,
      "step": 39520
    },
    {
      "epoch": 4.2355084110146795,
      "grad_norm": 0.0009210502612404525,
      "learning_rate": 1.4352655451980429e-05,
      "loss": 0.0036,
      "step": 39530
    },
    {
      "epoch": 4.236579877852781,
      "grad_norm": 0.045564766973257065,
      "learning_rate": 1.4351226829529628e-05,
      "loss": 0.0003,
      "step": 39540
    },
    {
      "epoch": 4.237651344690882,
      "grad_norm": 0.0007561201346106827,
      "learning_rate": 1.4349798207078824e-05,
      "loss": 0.0003,
      "step": 39550
    },
    {
      "epoch": 4.238722811528983,
      "grad_norm": 0.008348517119884491,
      "learning_rate": 1.4348369584628024e-05,
      "loss": 0.0001,
      "step": 39560
    },
    {
      "epoch": 4.239794278367085,
      "grad_norm": 0.022750668227672577,
      "learning_rate": 1.4346940962177223e-05,
      "loss": 0.0008,
      "step": 39570
    },
    {
      "epoch": 4.240865745205186,
      "grad_norm": 0.0006970107206143439,
      "learning_rate": 1.4345512339726419e-05,
      "loss": 0.029,
      "step": 39580
    },
    {
      "epoch": 4.241937212043287,
      "grad_norm": 0.011498499661684036,
      "learning_rate": 1.4344083717275618e-05,
      "loss": 0.1703,
      "step": 39590
    },
    {
      "epoch": 4.243008678881389,
      "grad_norm": 0.0002704709186218679,
      "learning_rate": 1.4342655094824816e-05,
      "loss": 0.2035,
      "step": 39600
    },
    {
      "epoch": 4.24408014571949,
      "grad_norm": 0.00029802339849993587,
      "learning_rate": 1.4341226472374015e-05,
      "loss": 0.1983,
      "step": 39610
    },
    {
      "epoch": 4.245151612557591,
      "grad_norm": 0.0003788229951169342,
      "learning_rate": 1.4339797849923213e-05,
      "loss": 0.1456,
      "step": 39620
    },
    {
      "epoch": 4.246223079395692,
      "grad_norm": 0.002592946868389845,
      "learning_rate": 1.433836922747241e-05,
      "loss": 0.0011,
      "step": 39630
    },
    {
      "epoch": 4.247294546233794,
      "grad_norm": 0.00047207059105858207,
      "learning_rate": 1.433694060502161e-05,
      "loss": 0.2035,
      "step": 39640
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 0.0003857599222101271,
      "learning_rate": 1.4335511982570806e-05,
      "loss": 0.0005,
      "step": 39650
    },
    {
      "epoch": 4.2494374799099965,
      "grad_norm": 0.0024897418916225433,
      "learning_rate": 1.4334083360120005e-05,
      "loss": 0.1727,
      "step": 39660
    },
    {
      "epoch": 4.2505089467480985,
      "grad_norm": 0.0019201250979676843,
      "learning_rate": 1.4332654737669203e-05,
      "loss": 0.0747,
      "step": 39670
    },
    {
      "epoch": 4.2515804135862,
      "grad_norm": 0.00046690789167769253,
      "learning_rate": 1.4331226115218402e-05,
      "loss": 0.0015,
      "step": 39680
    },
    {
      "epoch": 4.252651880424301,
      "grad_norm": 0.00579245388507843,
      "learning_rate": 1.43297974927676e-05,
      "loss": 0.0005,
      "step": 39690
    },
    {
      "epoch": 4.253723347262402,
      "grad_norm": 0.012276298366487026,
      "learning_rate": 1.4328368870316798e-05,
      "loss": 0.0004,
      "step": 39700
    },
    {
      "epoch": 4.254794814100504,
      "grad_norm": 0.00019749702187255025,
      "learning_rate": 1.4326940247865997e-05,
      "loss": 0.0004,
      "step": 39710
    },
    {
      "epoch": 4.255866280938605,
      "grad_norm": 0.01265646331012249,
      "learning_rate": 1.4325511625415193e-05,
      "loss": 0.0003,
      "step": 39720
    },
    {
      "epoch": 4.256937747776706,
      "grad_norm": 120.45479583740234,
      "learning_rate": 1.4324083002964392e-05,
      "loss": 0.1732,
      "step": 39730
    },
    {
      "epoch": 4.258009214614808,
      "grad_norm": 0.0822225883603096,
      "learning_rate": 1.4322654380513592e-05,
      "loss": 0.4688,
      "step": 39740
    },
    {
      "epoch": 4.259080681452909,
      "grad_norm": 0.014046935364603996,
      "learning_rate": 1.432122575806279e-05,
      "loss": 0.3878,
      "step": 39750
    },
    {
      "epoch": 4.26015214829101,
      "grad_norm": 0.09119666367769241,
      "learning_rate": 1.4319797135611987e-05,
      "loss": 0.0235,
      "step": 39760
    },
    {
      "epoch": 4.261223615129111,
      "grad_norm": 0.00014515957445837557,
      "learning_rate": 1.4318368513161185e-05,
      "loss": 0.1862,
      "step": 39770
    },
    {
      "epoch": 4.262295081967213,
      "grad_norm": 0.0002292995632160455,
      "learning_rate": 1.4316939890710384e-05,
      "loss": 0.2008,
      "step": 39780
    },
    {
      "epoch": 4.2633665488053145,
      "grad_norm": 0.041211072355508804,
      "learning_rate": 1.431551126825958e-05,
      "loss": 0.0008,
      "step": 39790
    },
    {
      "epoch": 4.264438015643416,
      "grad_norm": 0.00018653666484169662,
      "learning_rate": 1.431408264580878e-05,
      "loss": 0.2868,
      "step": 39800
    },
    {
      "epoch": 4.265509482481518,
      "grad_norm": 0.23127144575119019,
      "learning_rate": 1.4312654023357979e-05,
      "loss": 0.002,
      "step": 39810
    },
    {
      "epoch": 4.266580949319619,
      "grad_norm": 18.89933204650879,
      "learning_rate": 1.4311225400907177e-05,
      "loss": 0.3275,
      "step": 39820
    },
    {
      "epoch": 4.26765241615772,
      "grad_norm": 0.3877067565917969,
      "learning_rate": 1.4309796778456376e-05,
      "loss": 0.0021,
      "step": 39830
    },
    {
      "epoch": 4.268723882995821,
      "grad_norm": 0.002973859664052725,
      "learning_rate": 1.4308368156005572e-05,
      "loss": 0.0011,
      "step": 39840
    },
    {
      "epoch": 4.269795349833923,
      "grad_norm": 0.000216682004975155,
      "learning_rate": 1.4306939533554771e-05,
      "loss": 0.0003,
      "step": 39850
    },
    {
      "epoch": 4.270866816672024,
      "grad_norm": 0.02960662543773651,
      "learning_rate": 1.430551091110397e-05,
      "loss": 0.0011,
      "step": 39860
    },
    {
      "epoch": 4.271938283510125,
      "grad_norm": 9.787177259568125e-05,
      "learning_rate": 1.4304082288653167e-05,
      "loss": 0.1609,
      "step": 39870
    },
    {
      "epoch": 4.273009750348226,
      "grad_norm": 0.04889519885182381,
      "learning_rate": 1.4302653666202366e-05,
      "loss": 0.0252,
      "step": 39880
    },
    {
      "epoch": 4.274081217186328,
      "grad_norm": 0.00010920396016445011,
      "learning_rate": 1.4301225043751564e-05,
      "loss": 0.0002,
      "step": 39890
    },
    {
      "epoch": 4.275152684024429,
      "grad_norm": 0.02420630306005478,
      "learning_rate": 1.4299796421300763e-05,
      "loss": 0.3707,
      "step": 39900
    },
    {
      "epoch": 4.2762241508625305,
      "grad_norm": 0.10837157815694809,
      "learning_rate": 1.4298367798849959e-05,
      "loss": 0.1275,
      "step": 39910
    },
    {
      "epoch": 4.2772956177006325,
      "grad_norm": 7.130412996048108e-05,
      "learning_rate": 1.4296939176399158e-05,
      "loss": 0.0004,
      "step": 39920
    },
    {
      "epoch": 4.278367084538734,
      "grad_norm": 0.08531662821769714,
      "learning_rate": 1.4295510553948358e-05,
      "loss": 0.0005,
      "step": 39930
    },
    {
      "epoch": 4.279438551376835,
      "grad_norm": 9.966484503820539e-05,
      "learning_rate": 1.4294081931497554e-05,
      "loss": 0.2367,
      "step": 39940
    },
    {
      "epoch": 4.280510018214937,
      "grad_norm": 0.043619077652692795,
      "learning_rate": 1.4292653309046753e-05,
      "loss": 0.0002,
      "step": 39950
    },
    {
      "epoch": 4.281581485053038,
      "grad_norm": 0.00013778895663563162,
      "learning_rate": 1.429122468659595e-05,
      "loss": 0.3426,
      "step": 39960
    },
    {
      "epoch": 4.282652951891139,
      "grad_norm": 0.0071713924407958984,
      "learning_rate": 1.428979606414515e-05,
      "loss": 0.0011,
      "step": 39970
    },
    {
      "epoch": 4.28372441872924,
      "grad_norm": 0.03363154083490372,
      "learning_rate": 1.4288367441694346e-05,
      "loss": 0.0005,
      "step": 39980
    },
    {
      "epoch": 4.284795885567342,
      "grad_norm": 0.005056625697761774,
      "learning_rate": 1.4286938819243546e-05,
      "loss": 0.0007,
      "step": 39990
    },
    {
      "epoch": 4.285867352405443,
      "grad_norm": 0.02561642974615097,
      "learning_rate": 1.4285510196792745e-05,
      "loss": 0.1932,
      "step": 40000
    },
    {
      "epoch": 4.286938819243544,
      "grad_norm": 48.76814651489258,
      "learning_rate": 1.4284081574341941e-05,
      "loss": 0.187,
      "step": 40010
    },
    {
      "epoch": 4.288010286081645,
      "grad_norm": 0.043895866721868515,
      "learning_rate": 1.428265295189114e-05,
      "loss": 0.0005,
      "step": 40020
    },
    {
      "epoch": 4.289081752919747,
      "grad_norm": 0.07437574118375778,
      "learning_rate": 1.4281224329440338e-05,
      "loss": 0.1757,
      "step": 40030
    },
    {
      "epoch": 4.2901532197578485,
      "grad_norm": 0.00024584680795669556,
      "learning_rate": 1.4279795706989537e-05,
      "loss": 0.4865,
      "step": 40040
    },
    {
      "epoch": 4.29122468659595,
      "grad_norm": 0.00018361797265242785,
      "learning_rate": 1.4278367084538735e-05,
      "loss": 0.0003,
      "step": 40050
    },
    {
      "epoch": 4.292296153434052,
      "grad_norm": 0.00012057228741468862,
      "learning_rate": 1.4276938462087933e-05,
      "loss": 0.0004,
      "step": 40060
    },
    {
      "epoch": 4.293367620272153,
      "grad_norm": 0.017655104398727417,
      "learning_rate": 1.4275509839637132e-05,
      "loss": 0.0013,
      "step": 40070
    },
    {
      "epoch": 4.294439087110254,
      "grad_norm": 0.04586314037442207,
      "learning_rate": 1.4274081217186328e-05,
      "loss": 0.0055,
      "step": 40080
    },
    {
      "epoch": 4.295510553948355,
      "grad_norm": 0.04391056299209595,
      "learning_rate": 1.4272652594735527e-05,
      "loss": 0.0004,
      "step": 40090
    },
    {
      "epoch": 4.296582020786457,
      "grad_norm": 0.05942388251423836,
      "learning_rate": 1.4271223972284725e-05,
      "loss": 0.1477,
      "step": 40100
    },
    {
      "epoch": 4.297653487624558,
      "grad_norm": 0.18275940418243408,
      "learning_rate": 1.4269795349833924e-05,
      "loss": 0.1728,
      "step": 40110
    },
    {
      "epoch": 4.298724954462659,
      "grad_norm": 0.00015268388960976154,
      "learning_rate": 1.4268366727383122e-05,
      "loss": 0.0001,
      "step": 40120
    },
    {
      "epoch": 4.299796421300761,
      "grad_norm": 0.04016349837183952,
      "learning_rate": 1.426693810493232e-05,
      "loss": 0.4076,
      "step": 40130
    },
    {
      "epoch": 4.300867888138862,
      "grad_norm": 0.000694787479005754,
      "learning_rate": 1.4265509482481519e-05,
      "loss": 0.2095,
      "step": 40140
    },
    {
      "epoch": 4.301939354976963,
      "grad_norm": 6.617036706302315e-05,
      "learning_rate": 1.4264080860030715e-05,
      "loss": 0.2189,
      "step": 40150
    },
    {
      "epoch": 4.3030108218150644,
      "grad_norm": 0.15236720442771912,
      "learning_rate": 1.4262652237579914e-05,
      "loss": 0.1519,
      "step": 40160
    },
    {
      "epoch": 4.304082288653166,
      "grad_norm": 0.00031661224784329534,
      "learning_rate": 1.4261223615129114e-05,
      "loss": 0.1329,
      "step": 40170
    },
    {
      "epoch": 4.3051537554912676,
      "grad_norm": 0.01536580827087164,
      "learning_rate": 1.4259794992678311e-05,
      "loss": 0.4987,
      "step": 40180
    },
    {
      "epoch": 4.306225222329369,
      "grad_norm": 0.017604952678084373,
      "learning_rate": 1.4258366370227509e-05,
      "loss": 0.1561,
      "step": 40190
    },
    {
      "epoch": 4.307296689167471,
      "grad_norm": 0.01432952843606472,
      "learning_rate": 1.4256937747776707e-05,
      "loss": 0.0008,
      "step": 40200
    },
    {
      "epoch": 4.308368156005572,
      "grad_norm": 0.053623732179403305,
      "learning_rate": 1.4255509125325906e-05,
      "loss": 0.1427,
      "step": 40210
    },
    {
      "epoch": 4.309439622843673,
      "grad_norm": 0.3766304552555084,
      "learning_rate": 1.4254080502875102e-05,
      "loss": 0.1445,
      "step": 40220
    },
    {
      "epoch": 4.310511089681774,
      "grad_norm": 0.03221774846315384,
      "learning_rate": 1.4252651880424302e-05,
      "loss": 0.0011,
      "step": 40230
    },
    {
      "epoch": 4.311582556519876,
      "grad_norm": 0.01570102572441101,
      "learning_rate": 1.4251223257973501e-05,
      "loss": 0.15,
      "step": 40240
    },
    {
      "epoch": 4.312654023357977,
      "grad_norm": 0.0015781588153913617,
      "learning_rate": 1.4249794635522699e-05,
      "loss": 0.0017,
      "step": 40250
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.02550404705107212,
      "learning_rate": 1.4248366013071896e-05,
      "loss": 0.163,
      "step": 40260
    },
    {
      "epoch": 4.31479695703418,
      "grad_norm": 0.19767345488071442,
      "learning_rate": 1.4246937390621094e-05,
      "loss": 0.1915,
      "step": 40270
    },
    {
      "epoch": 4.315868423872281,
      "grad_norm": 0.0005674476851709187,
      "learning_rate": 1.4245508768170293e-05,
      "loss": 0.1132,
      "step": 40280
    },
    {
      "epoch": 4.316939890710382,
      "grad_norm": 0.005889264866709709,
      "learning_rate": 1.4244080145719493e-05,
      "loss": 0.1917,
      "step": 40290
    },
    {
      "epoch": 4.3180113575484835,
      "grad_norm": 0.0005544267478398979,
      "learning_rate": 1.4242651523268689e-05,
      "loss": 0.0001,
      "step": 40300
    },
    {
      "epoch": 4.3190828243865855,
      "grad_norm": 0.0005312271532602608,
      "learning_rate": 1.4241222900817888e-05,
      "loss": 0.1732,
      "step": 40310
    },
    {
      "epoch": 4.320154291224687,
      "grad_norm": 0.0006103232735767961,
      "learning_rate": 1.4239794278367086e-05,
      "loss": 0.0563,
      "step": 40320
    },
    {
      "epoch": 4.321225758062788,
      "grad_norm": 0.00036602048203349113,
      "learning_rate": 1.4238365655916283e-05,
      "loss": 0.2695,
      "step": 40330
    },
    {
      "epoch": 4.32229722490089,
      "grad_norm": 0.0004651058989111334,
      "learning_rate": 1.4236937033465481e-05,
      "loss": 0.108,
      "step": 40340
    },
    {
      "epoch": 4.323368691738991,
      "grad_norm": 0.0013305464526638389,
      "learning_rate": 1.423550841101468e-05,
      "loss": 0.0007,
      "step": 40350
    },
    {
      "epoch": 4.324440158577092,
      "grad_norm": 1.3657740354537964,
      "learning_rate": 1.423407978856388e-05,
      "loss": 0.2927,
      "step": 40360
    },
    {
      "epoch": 4.325511625415193,
      "grad_norm": 0.0008048567688092589,
      "learning_rate": 1.4232651166113076e-05,
      "loss": 0.0003,
      "step": 40370
    },
    {
      "epoch": 4.326583092253295,
      "grad_norm": 0.019083473831415176,
      "learning_rate": 1.4231222543662275e-05,
      "loss": 0.1944,
      "step": 40380
    },
    {
      "epoch": 4.327654559091396,
      "grad_norm": 0.005300872027873993,
      "learning_rate": 1.4229793921211473e-05,
      "loss": 0.1883,
      "step": 40390
    },
    {
      "epoch": 4.328726025929497,
      "grad_norm": 0.08250612765550613,
      "learning_rate": 1.4228365298760672e-05,
      "loss": 0.1794,
      "step": 40400
    },
    {
      "epoch": 4.329797492767598,
      "grad_norm": 0.0008984347223304212,
      "learning_rate": 1.422693667630987e-05,
      "loss": 0.0002,
      "step": 40410
    },
    {
      "epoch": 4.3308689596057,
      "grad_norm": 0.0020805944222956896,
      "learning_rate": 1.4225508053859067e-05,
      "loss": 0.1525,
      "step": 40420
    },
    {
      "epoch": 4.3319404264438015,
      "grad_norm": 0.013371768407523632,
      "learning_rate": 1.4224079431408267e-05,
      "loss": 0.2293,
      "step": 40430
    },
    {
      "epoch": 4.333011893281903,
      "grad_norm": 0.056061699986457825,
      "learning_rate": 1.4222650808957463e-05,
      "loss": 0.1792,
      "step": 40440
    },
    {
      "epoch": 4.334083360120005,
      "grad_norm": 0.024720750749111176,
      "learning_rate": 1.4221222186506662e-05,
      "loss": 0.0015,
      "step": 40450
    },
    {
      "epoch": 4.335154826958106,
      "grad_norm": 0.002351431641727686,
      "learning_rate": 1.421979356405586e-05,
      "loss": 0.2319,
      "step": 40460
    },
    {
      "epoch": 4.336226293796207,
      "grad_norm": 0.009594599716365337,
      "learning_rate": 1.421836494160506e-05,
      "loss": 0.4419,
      "step": 40470
    },
    {
      "epoch": 4.337297760634309,
      "grad_norm": 0.001936713932082057,
      "learning_rate": 1.4216936319154257e-05,
      "loss": 0.157,
      "step": 40480
    },
    {
      "epoch": 4.33836922747241,
      "grad_norm": 0.0006243961397558451,
      "learning_rate": 1.4215507696703455e-05,
      "loss": 0.147,
      "step": 40490
    },
    {
      "epoch": 4.339440694310511,
      "grad_norm": 0.005236554890871048,
      "learning_rate": 1.4214079074252654e-05,
      "loss": 0.001,
      "step": 40500
    },
    {
      "epoch": 4.340512161148612,
      "grad_norm": 0.04422205686569214,
      "learning_rate": 1.421265045180185e-05,
      "loss": 0.0007,
      "step": 40510
    },
    {
      "epoch": 4.341583627986714,
      "grad_norm": 0.07641831040382385,
      "learning_rate": 1.421122182935105e-05,
      "loss": 0.0007,
      "step": 40520
    },
    {
      "epoch": 4.342655094824815,
      "grad_norm": 0.0009634265443310142,
      "learning_rate": 1.4209793206900249e-05,
      "loss": 0.0005,
      "step": 40530
    },
    {
      "epoch": 4.343726561662916,
      "grad_norm": 0.00047401958727277815,
      "learning_rate": 1.4208364584449446e-05,
      "loss": 0.2358,
      "step": 40540
    },
    {
      "epoch": 4.3447980285010175,
      "grad_norm": 0.024806413799524307,
      "learning_rate": 1.4206935961998644e-05,
      "loss": 0.1662,
      "step": 40550
    },
    {
      "epoch": 4.3458694953391195,
      "grad_norm": 0.0006498866132460535,
      "learning_rate": 1.4205507339547842e-05,
      "loss": 0.2022,
      "step": 40560
    },
    {
      "epoch": 4.346940962177221,
      "grad_norm": 0.022955792024731636,
      "learning_rate": 1.4204078717097041e-05,
      "loss": 0.3287,
      "step": 40570
    },
    {
      "epoch": 4.348012429015322,
      "grad_norm": 0.0005754004814662039,
      "learning_rate": 1.4202650094646237e-05,
      "loss": 0.0007,
      "step": 40580
    },
    {
      "epoch": 4.349083895853424,
      "grad_norm": 0.11825902760028839,
      "learning_rate": 1.4201221472195436e-05,
      "loss": 0.2108,
      "step": 40590
    },
    {
      "epoch": 4.350155362691525,
      "grad_norm": 0.0004506497352849692,
      "learning_rate": 1.4199792849744636e-05,
      "loss": 0.1841,
      "step": 40600
    },
    {
      "epoch": 4.351226829529626,
      "grad_norm": 0.15085850656032562,
      "learning_rate": 1.4198364227293833e-05,
      "loss": 0.1173,
      "step": 40610
    },
    {
      "epoch": 4.352298296367727,
      "grad_norm": 0.0010458632605150342,
      "learning_rate": 1.4196935604843031e-05,
      "loss": 0.3239,
      "step": 40620
    },
    {
      "epoch": 4.353369763205829,
      "grad_norm": 0.005487697198987007,
      "learning_rate": 1.4195506982392229e-05,
      "loss": 0.0015,
      "step": 40630
    },
    {
      "epoch": 4.35444123004393,
      "grad_norm": 0.003003046615049243,
      "learning_rate": 1.4194078359941428e-05,
      "loss": 0.2128,
      "step": 40640
    },
    {
      "epoch": 4.355512696882031,
      "grad_norm": 0.004529341123998165,
      "learning_rate": 1.4192649737490627e-05,
      "loss": 0.0013,
      "step": 40650
    },
    {
      "epoch": 4.356584163720133,
      "grad_norm": 0.0748414471745491,
      "learning_rate": 1.4191221115039823e-05,
      "loss": 0.0008,
      "step": 40660
    },
    {
      "epoch": 4.357655630558234,
      "grad_norm": 0.031068356707692146,
      "learning_rate": 1.4189792492589023e-05,
      "loss": 0.3412,
      "step": 40670
    },
    {
      "epoch": 4.3587270973963355,
      "grad_norm": 0.006032364442944527,
      "learning_rate": 1.418836387013822e-05,
      "loss": 0.0007,
      "step": 40680
    },
    {
      "epoch": 4.359798564234437,
      "grad_norm": 0.0031582156661897898,
      "learning_rate": 1.4186935247687418e-05,
      "loss": 0.8244,
      "step": 40690
    },
    {
      "epoch": 4.360870031072539,
      "grad_norm": 0.06125807389616966,
      "learning_rate": 1.4185506625236616e-05,
      "loss": 0.1436,
      "step": 40700
    },
    {
      "epoch": 4.36194149791064,
      "grad_norm": 0.16242645680904388,
      "learning_rate": 1.4184078002785815e-05,
      "loss": 0.0009,
      "step": 40710
    },
    {
      "epoch": 4.363012964748741,
      "grad_norm": 0.036361753940582275,
      "learning_rate": 1.4182649380335015e-05,
      "loss": 0.0017,
      "step": 40720
    },
    {
      "epoch": 4.364084431586843,
      "grad_norm": 0.0014764606021344662,
      "learning_rate": 1.418122075788421e-05,
      "loss": 0.0012,
      "step": 40730
    },
    {
      "epoch": 4.365155898424944,
      "grad_norm": 0.0015132335247471929,
      "learning_rate": 1.417979213543341e-05,
      "loss": 0.0004,
      "step": 40740
    },
    {
      "epoch": 4.366227365263045,
      "grad_norm": 0.03496015444397926,
      "learning_rate": 1.4178363512982608e-05,
      "loss": 0.1338,
      "step": 40750
    },
    {
      "epoch": 4.367298832101146,
      "grad_norm": 0.25539568066596985,
      "learning_rate": 1.4176934890531805e-05,
      "loss": 0.1173,
      "step": 40760
    },
    {
      "epoch": 4.368370298939248,
      "grad_norm": 0.0511869341135025,
      "learning_rate": 1.4175506268081005e-05,
      "loss": 0.0027,
      "step": 40770
    },
    {
      "epoch": 4.369441765777349,
      "grad_norm": 0.09440620988607407,
      "learning_rate": 1.4174077645630202e-05,
      "loss": 0.208,
      "step": 40780
    },
    {
      "epoch": 4.37051323261545,
      "grad_norm": 0.002494840184226632,
      "learning_rate": 1.4172649023179402e-05,
      "loss": 0.1131,
      "step": 40790
    },
    {
      "epoch": 4.371584699453552,
      "grad_norm": 0.0006101918988861144,
      "learning_rate": 1.4171220400728598e-05,
      "loss": 0.0006,
      "step": 40800
    },
    {
      "epoch": 4.372656166291653,
      "grad_norm": 0.0006898402934893966,
      "learning_rate": 1.4169791778277797e-05,
      "loss": 0.3825,
      "step": 40810
    },
    {
      "epoch": 4.3737276331297545,
      "grad_norm": 1.4243595600128174,
      "learning_rate": 1.4168363155826995e-05,
      "loss": 0.0015,
      "step": 40820
    },
    {
      "epoch": 4.374799099967856,
      "grad_norm": 0.3091159164905548,
      "learning_rate": 1.4166934533376192e-05,
      "loss": 0.0007,
      "step": 40830
    },
    {
      "epoch": 4.375870566805958,
      "grad_norm": 0.054132912307977676,
      "learning_rate": 1.4165505910925392e-05,
      "loss": 0.15,
      "step": 40840
    },
    {
      "epoch": 4.376942033644059,
      "grad_norm": 0.013548659160733223,
      "learning_rate": 1.416407728847459e-05,
      "loss": 0.2233,
      "step": 40850
    },
    {
      "epoch": 4.37801350048216,
      "grad_norm": 0.12165596336126328,
      "learning_rate": 1.4162648666023789e-05,
      "loss": 0.0005,
      "step": 40860
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 0.001248802407644689,
      "learning_rate": 1.4161220043572985e-05,
      "loss": 0.0006,
      "step": 40870
    },
    {
      "epoch": 4.380156434158363,
      "grad_norm": 20.345048904418945,
      "learning_rate": 1.4159791421122184e-05,
      "loss": 0.3645,
      "step": 40880
    },
    {
      "epoch": 4.381227900996464,
      "grad_norm": 0.026383688673377037,
      "learning_rate": 1.4158362798671382e-05,
      "loss": 0.0005,
      "step": 40890
    },
    {
      "epoch": 4.382299367834565,
      "grad_norm": 17.469270706176758,
      "learning_rate": 1.415693417622058e-05,
      "loss": 0.1399,
      "step": 40900
    },
    {
      "epoch": 4.383370834672667,
      "grad_norm": 0.0034383332822471857,
      "learning_rate": 1.4155505553769779e-05,
      "loss": 0.4224,
      "step": 40910
    },
    {
      "epoch": 4.384442301510768,
      "grad_norm": 0.034096065908670425,
      "learning_rate": 1.4154076931318977e-05,
      "loss": 0.0007,
      "step": 40920
    },
    {
      "epoch": 4.385513768348869,
      "grad_norm": 0.008652327582240105,
      "learning_rate": 1.4152648308868176e-05,
      "loss": 0.0007,
      "step": 40930
    },
    {
      "epoch": 4.3865852351869705,
      "grad_norm": 0.02084275521337986,
      "learning_rate": 1.4151219686417372e-05,
      "loss": 0.3327,
      "step": 40940
    },
    {
      "epoch": 4.3876567020250725,
      "grad_norm": 0.0010926948161795735,
      "learning_rate": 1.4149791063966571e-05,
      "loss": 0.0028,
      "step": 40950
    },
    {
      "epoch": 4.388728168863174,
      "grad_norm": 102.27995300292969,
      "learning_rate": 1.414836244151577e-05,
      "loss": 0.1309,
      "step": 40960
    },
    {
      "epoch": 4.389799635701275,
      "grad_norm": 3.7385075092315674,
      "learning_rate": 1.4146933819064968e-05,
      "loss": 0.0013,
      "step": 40970
    },
    {
      "epoch": 4.390871102539377,
      "grad_norm": 0.00023617187980562449,
      "learning_rate": 1.4145505196614166e-05,
      "loss": 0.0004,
      "step": 40980
    },
    {
      "epoch": 4.391942569377478,
      "grad_norm": 0.02200324274599552,
      "learning_rate": 1.4144076574163364e-05,
      "loss": 0.0011,
      "step": 40990
    },
    {
      "epoch": 4.393014036215579,
      "grad_norm": 0.1645534783601761,
      "learning_rate": 1.4142647951712563e-05,
      "loss": 0.7277,
      "step": 41000
    },
    {
      "epoch": 4.394085503053681,
      "grad_norm": 24.244701385498047,
      "learning_rate": 1.4141219329261759e-05,
      "loss": 0.2325,
      "step": 41010
    },
    {
      "epoch": 4.395156969891782,
      "grad_norm": 0.0049209194257855415,
      "learning_rate": 1.4139790706810958e-05,
      "loss": 0.0992,
      "step": 41020
    },
    {
      "epoch": 4.396228436729883,
      "grad_norm": 49.909034729003906,
      "learning_rate": 1.4138362084360158e-05,
      "loss": 0.1364,
      "step": 41030
    },
    {
      "epoch": 4.397299903567984,
      "grad_norm": 0.0045809135772287846,
      "learning_rate": 1.4136933461909355e-05,
      "loss": 0.001,
      "step": 41040
    },
    {
      "epoch": 4.398371370406086,
      "grad_norm": 0.0009925055783241987,
      "learning_rate": 1.4135504839458553e-05,
      "loss": 0.002,
      "step": 41050
    },
    {
      "epoch": 4.399442837244187,
      "grad_norm": 0.03838445618748665,
      "learning_rate": 1.413407621700775e-05,
      "loss": 0.4124,
      "step": 41060
    },
    {
      "epoch": 4.4005143040822885,
      "grad_norm": 3.4629664421081543,
      "learning_rate": 1.413264759455695e-05,
      "loss": 0.2054,
      "step": 41070
    },
    {
      "epoch": 4.40158577092039,
      "grad_norm": 0.002188290236517787,
      "learning_rate": 1.413121897210615e-05,
      "loss": 0.0032,
      "step": 41080
    },
    {
      "epoch": 4.402657237758492,
      "grad_norm": 0.0023048575967550278,
      "learning_rate": 1.4129790349655345e-05,
      "loss": 0.1965,
      "step": 41090
    },
    {
      "epoch": 4.403728704596593,
      "grad_norm": 0.0025315999519079924,
      "learning_rate": 1.4128361727204545e-05,
      "loss": 0.5446,
      "step": 41100
    },
    {
      "epoch": 4.404800171434694,
      "grad_norm": 0.007637140341103077,
      "learning_rate": 1.4126933104753742e-05,
      "loss": 0.0126,
      "step": 41110
    },
    {
      "epoch": 4.405871638272796,
      "grad_norm": 0.005860477685928345,
      "learning_rate": 1.412550448230294e-05,
      "loss": 0.0013,
      "step": 41120
    },
    {
      "epoch": 4.406943105110897,
      "grad_norm": 0.9060819149017334,
      "learning_rate": 1.4124075859852138e-05,
      "loss": 0.3,
      "step": 41130
    },
    {
      "epoch": 4.408014571948998,
      "grad_norm": 0.03380323201417923,
      "learning_rate": 1.4122647237401337e-05,
      "loss": 0.0008,
      "step": 41140
    },
    {
      "epoch": 4.409086038787099,
      "grad_norm": 0.0017434281762689352,
      "learning_rate": 1.4121218614950537e-05,
      "loss": 0.0006,
      "step": 41150
    },
    {
      "epoch": 4.410157505625201,
      "grad_norm": 0.011903567239642143,
      "learning_rate": 1.4119789992499733e-05,
      "loss": 0.3987,
      "step": 41160
    },
    {
      "epoch": 4.411228972463302,
      "grad_norm": 22.300962448120117,
      "learning_rate": 1.4118361370048932e-05,
      "loss": 0.2734,
      "step": 41170
    },
    {
      "epoch": 4.412300439301403,
      "grad_norm": 0.02373196743428707,
      "learning_rate": 1.411693274759813e-05,
      "loss": 0.3459,
      "step": 41180
    },
    {
      "epoch": 4.413371906139505,
      "grad_norm": 0.023763082921504974,
      "learning_rate": 1.4115504125147327e-05,
      "loss": 0.1581,
      "step": 41190
    },
    {
      "epoch": 4.4144433729776065,
      "grad_norm": 0.08358967304229736,
      "learning_rate": 1.4114075502696527e-05,
      "loss": 0.0025,
      "step": 41200
    },
    {
      "epoch": 4.415514839815708,
      "grad_norm": 0.005602620542049408,
      "learning_rate": 1.4112646880245724e-05,
      "loss": 0.158,
      "step": 41210
    },
    {
      "epoch": 4.416586306653809,
      "grad_norm": 45.50226974487305,
      "learning_rate": 1.4111218257794924e-05,
      "loss": 0.184,
      "step": 41220
    },
    {
      "epoch": 4.417657773491911,
      "grad_norm": 0.05020463094115257,
      "learning_rate": 1.410978963534412e-05,
      "loss": 0.1036,
      "step": 41230
    },
    {
      "epoch": 4.418729240330012,
      "grad_norm": 1.525701642036438,
      "learning_rate": 1.4108361012893319e-05,
      "loss": 0.2294,
      "step": 41240
    },
    {
      "epoch": 4.419800707168113,
      "grad_norm": 4.093665599822998,
      "learning_rate": 1.4106932390442517e-05,
      "loss": 0.1827,
      "step": 41250
    },
    {
      "epoch": 4.420872174006215,
      "grad_norm": 0.3326398432254791,
      "learning_rate": 1.4105503767991714e-05,
      "loss": 0.0044,
      "step": 41260
    },
    {
      "epoch": 4.421943640844316,
      "grad_norm": 0.024555683135986328,
      "learning_rate": 1.4104075145540914e-05,
      "loss": 0.213,
      "step": 41270
    },
    {
      "epoch": 4.423015107682417,
      "grad_norm": 0.0023471263702958822,
      "learning_rate": 1.4102646523090111e-05,
      "loss": 0.001,
      "step": 41280
    },
    {
      "epoch": 4.424086574520518,
      "grad_norm": 0.0012218706542626023,
      "learning_rate": 1.410121790063931e-05,
      "loss": 0.0006,
      "step": 41290
    },
    {
      "epoch": 4.42515804135862,
      "grad_norm": 0.03391709178686142,
      "learning_rate": 1.4099789278188507e-05,
      "loss": 0.0015,
      "step": 41300
    },
    {
      "epoch": 4.426229508196721,
      "grad_norm": 0.022349053993821144,
      "learning_rate": 1.4098360655737706e-05,
      "loss": 0.71,
      "step": 41310
    },
    {
      "epoch": 4.4273009750348225,
      "grad_norm": 0.00541116576641798,
      "learning_rate": 1.4096932033286905e-05,
      "loss": 0.0015,
      "step": 41320
    },
    {
      "epoch": 4.4283724418729244,
      "grad_norm": 0.0019397219875827432,
      "learning_rate": 1.4095503410836101e-05,
      "loss": 0.3747,
      "step": 41330
    },
    {
      "epoch": 4.429443908711026,
      "grad_norm": 0.01001574657857418,
      "learning_rate": 1.40940747883853e-05,
      "loss": 0.0007,
      "step": 41340
    },
    {
      "epoch": 4.430515375549127,
      "grad_norm": 0.004635715391486883,
      "learning_rate": 1.4092646165934498e-05,
      "loss": 0.3583,
      "step": 41350
    },
    {
      "epoch": 4.431586842387228,
      "grad_norm": 0.003061204217374325,
      "learning_rate": 1.4091217543483698e-05,
      "loss": 0.0013,
      "step": 41360
    },
    {
      "epoch": 4.43265830922533,
      "grad_norm": 0.029656607657670975,
      "learning_rate": 1.4089788921032894e-05,
      "loss": 0.0005,
      "step": 41370
    },
    {
      "epoch": 4.433729776063431,
      "grad_norm": 1.0762627124786377,
      "learning_rate": 1.4088360298582093e-05,
      "loss": 0.0997,
      "step": 41380
    },
    {
      "epoch": 4.434801242901532,
      "grad_norm": 0.0992337316274643,
      "learning_rate": 1.4086931676131293e-05,
      "loss": 0.1709,
      "step": 41390
    },
    {
      "epoch": 4.435872709739634,
      "grad_norm": 0.08722320199012756,
      "learning_rate": 1.4085503053680489e-05,
      "loss": 0.1585,
      "step": 41400
    },
    {
      "epoch": 4.436944176577735,
      "grad_norm": 0.9168195724487305,
      "learning_rate": 1.4084074431229688e-05,
      "loss": 0.1498,
      "step": 41410
    },
    {
      "epoch": 4.438015643415836,
      "grad_norm": 0.007460376247763634,
      "learning_rate": 1.4082645808778886e-05,
      "loss": 0.0834,
      "step": 41420
    },
    {
      "epoch": 4.439087110253937,
      "grad_norm": 0.003308982588350773,
      "learning_rate": 1.4081217186328085e-05,
      "loss": 0.3379,
      "step": 41430
    },
    {
      "epoch": 4.440158577092039,
      "grad_norm": 8.376076698303223,
      "learning_rate": 1.4079788563877284e-05,
      "loss": 0.0093,
      "step": 41440
    },
    {
      "epoch": 4.44123004393014,
      "grad_norm": 0.0024093538522720337,
      "learning_rate": 1.407835994142648e-05,
      "loss": 0.0051,
      "step": 41450
    },
    {
      "epoch": 4.4423015107682415,
      "grad_norm": 0.03894168511033058,
      "learning_rate": 1.407693131897568e-05,
      "loss": 0.1917,
      "step": 41460
    },
    {
      "epoch": 4.443372977606343,
      "grad_norm": 0.3083353638648987,
      "learning_rate": 1.4075502696524876e-05,
      "loss": 0.0009,
      "step": 41470
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.00266930740326643,
      "learning_rate": 1.4074074074074075e-05,
      "loss": 0.1451,
      "step": 41480
    },
    {
      "epoch": 4.445515911282546,
      "grad_norm": 0.18913985788822174,
      "learning_rate": 1.4072645451623273e-05,
      "loss": 0.002,
      "step": 41490
    },
    {
      "epoch": 4.446587378120647,
      "grad_norm": 16.045425415039062,
      "learning_rate": 1.4071216829172472e-05,
      "loss": 0.1951,
      "step": 41500
    },
    {
      "epoch": 4.447658844958749,
      "grad_norm": 0.004006942268460989,
      "learning_rate": 1.4069788206721671e-05,
      "loss": 0.0003,
      "step": 41510
    },
    {
      "epoch": 4.44873031179685,
      "grad_norm": 0.0015152072301134467,
      "learning_rate": 1.4068359584270867e-05,
      "loss": 0.368,
      "step": 41520
    },
    {
      "epoch": 4.449801778634951,
      "grad_norm": 0.09184127300977707,
      "learning_rate": 1.4066930961820067e-05,
      "loss": 0.2035,
      "step": 41530
    },
    {
      "epoch": 4.450873245473053,
      "grad_norm": 0.0017121875425800681,
      "learning_rate": 1.4065502339369264e-05,
      "loss": 0.0005,
      "step": 41540
    },
    {
      "epoch": 4.451944712311154,
      "grad_norm": 0.0016416525468230247,
      "learning_rate": 1.4064073716918462e-05,
      "loss": 0.1643,
      "step": 41550
    },
    {
      "epoch": 4.453016179149255,
      "grad_norm": 0.0010254518128931522,
      "learning_rate": 1.4062645094467661e-05,
      "loss": 0.0002,
      "step": 41560
    },
    {
      "epoch": 4.454087645987356,
      "grad_norm": 0.001522021135315299,
      "learning_rate": 1.4061216472016859e-05,
      "loss": 0.0004,
      "step": 41570
    },
    {
      "epoch": 4.455159112825458,
      "grad_norm": 0.0014062211848795414,
      "learning_rate": 1.4059787849566058e-05,
      "loss": 0.2272,
      "step": 41580
    },
    {
      "epoch": 4.4562305796635595,
      "grad_norm": 0.05328434705734253,
      "learning_rate": 1.4058359227115254e-05,
      "loss": 0.335,
      "step": 41590
    },
    {
      "epoch": 4.457302046501661,
      "grad_norm": 0.05771402269601822,
      "learning_rate": 1.4056930604664454e-05,
      "loss": 0.1784,
      "step": 41600
    },
    {
      "epoch": 4.458373513339762,
      "grad_norm": 0.02659253031015396,
      "learning_rate": 1.4055501982213651e-05,
      "loss": 0.0018,
      "step": 41610
    },
    {
      "epoch": 4.459444980177864,
      "grad_norm": 0.021132325753569603,
      "learning_rate": 1.405407335976285e-05,
      "loss": 0.1381,
      "step": 41620
    },
    {
      "epoch": 4.460516447015965,
      "grad_norm": 0.09012293815612793,
      "learning_rate": 1.4052644737312049e-05,
      "loss": 0.4448,
      "step": 41630
    },
    {
      "epoch": 4.461587913854066,
      "grad_norm": 0.013305380009114742,
      "learning_rate": 1.4051216114861246e-05,
      "loss": 0.1485,
      "step": 41640
    },
    {
      "epoch": 4.462659380692168,
      "grad_norm": 13.391716003417969,
      "learning_rate": 1.4049787492410446e-05,
      "loss": 0.1223,
      "step": 41650
    },
    {
      "epoch": 4.463730847530269,
      "grad_norm": 0.006010573357343674,
      "learning_rate": 1.4048358869959642e-05,
      "loss": 0.0926,
      "step": 41660
    },
    {
      "epoch": 4.46480231436837,
      "grad_norm": 0.004687288776040077,
      "learning_rate": 1.4046930247508841e-05,
      "loss": 0.0004,
      "step": 41670
    },
    {
      "epoch": 4.465873781206471,
      "grad_norm": 0.016418686136603355,
      "learning_rate": 1.404550162505804e-05,
      "loss": 0.1203,
      "step": 41680
    },
    {
      "epoch": 4.466945248044573,
      "grad_norm": 32.70574188232422,
      "learning_rate": 1.4044073002607236e-05,
      "loss": 0.4918,
      "step": 41690
    },
    {
      "epoch": 4.468016714882674,
      "grad_norm": 0.04145418852567673,
      "learning_rate": 1.4042644380156436e-05,
      "loss": 0.3636,
      "step": 41700
    },
    {
      "epoch": 4.4690881817207755,
      "grad_norm": 0.23387371003627777,
      "learning_rate": 1.4041215757705633e-05,
      "loss": 0.1091,
      "step": 41710
    },
    {
      "epoch": 4.4701596485588775,
      "grad_norm": 34.077606201171875,
      "learning_rate": 1.4039787135254833e-05,
      "loss": 0.1811,
      "step": 41720
    },
    {
      "epoch": 4.471231115396979,
      "grad_norm": 0.002866813214495778,
      "learning_rate": 1.4038358512804029e-05,
      "loss": 0.2063,
      "step": 41730
    },
    {
      "epoch": 4.47230258223508,
      "grad_norm": 378.12042236328125,
      "learning_rate": 1.4036929890353228e-05,
      "loss": 0.0221,
      "step": 41740
    },
    {
      "epoch": 4.473374049073181,
      "grad_norm": 0.03342738002538681,
      "learning_rate": 1.4035501267902427e-05,
      "loss": 0.0012,
      "step": 41750
    },
    {
      "epoch": 4.474445515911283,
      "grad_norm": 0.004652931354939938,
      "learning_rate": 1.4034072645451623e-05,
      "loss": 0.0004,
      "step": 41760
    },
    {
      "epoch": 4.475516982749384,
      "grad_norm": 0.003949808422476053,
      "learning_rate": 1.4032644023000823e-05,
      "loss": 0.0951,
      "step": 41770
    },
    {
      "epoch": 4.476588449587485,
      "grad_norm": 0.005114653147757053,
      "learning_rate": 1.403121540055002e-05,
      "loss": 0.0013,
      "step": 41780
    },
    {
      "epoch": 4.477659916425587,
      "grad_norm": 0.0028630373999476433,
      "learning_rate": 1.402978677809922e-05,
      "loss": 0.0734,
      "step": 41790
    },
    {
      "epoch": 4.478731383263688,
      "grad_norm": 0.0026176581159234047,
      "learning_rate": 1.4028358155648416e-05,
      "loss": 0.0007,
      "step": 41800
    },
    {
      "epoch": 4.479802850101789,
      "grad_norm": 23.82130241394043,
      "learning_rate": 1.4026929533197615e-05,
      "loss": 0.1469,
      "step": 41810
    },
    {
      "epoch": 4.48087431693989,
      "grad_norm": 0.037185557186603546,
      "learning_rate": 1.4025500910746814e-05,
      "loss": 0.0646,
      "step": 41820
    },
    {
      "epoch": 4.481945783777992,
      "grad_norm": 69.49848937988281,
      "learning_rate": 1.402407228829601e-05,
      "loss": 0.3597,
      "step": 41830
    },
    {
      "epoch": 4.4830172506160935,
      "grad_norm": 0.16514307260513306,
      "learning_rate": 1.402264366584521e-05,
      "loss": 0.0004,
      "step": 41840
    },
    {
      "epoch": 4.484088717454195,
      "grad_norm": 0.042538516223430634,
      "learning_rate": 1.4021215043394407e-05,
      "loss": 0.2477,
      "step": 41850
    },
    {
      "epoch": 4.485160184292296,
      "grad_norm": 0.020251529291272163,
      "learning_rate": 1.4019786420943607e-05,
      "loss": 0.0022,
      "step": 41860
    },
    {
      "epoch": 4.486231651130398,
      "grad_norm": 0.010593629442155361,
      "learning_rate": 1.4018357798492806e-05,
      "loss": 0.157,
      "step": 41870
    },
    {
      "epoch": 4.487303117968499,
      "grad_norm": 0.005169311538338661,
      "learning_rate": 1.4016929176042002e-05,
      "loss": 0.2249,
      "step": 41880
    },
    {
      "epoch": 4.4883745848066,
      "grad_norm": 0.043727826327085495,
      "learning_rate": 1.4015500553591202e-05,
      "loss": 0.2092,
      "step": 41890
    },
    {
      "epoch": 4.489446051644702,
      "grad_norm": 0.02674846537411213,
      "learning_rate": 1.4014071931140398e-05,
      "loss": 0.0956,
      "step": 41900
    },
    {
      "epoch": 4.490517518482803,
      "grad_norm": 0.012235937640070915,
      "learning_rate": 1.4012643308689597e-05,
      "loss": 0.3507,
      "step": 41910
    },
    {
      "epoch": 4.491588985320904,
      "grad_norm": 0.004347214475274086,
      "learning_rate": 1.4011214686238795e-05,
      "loss": 0.1145,
      "step": 41920
    },
    {
      "epoch": 4.492660452159006,
      "grad_norm": 0.03651304170489311,
      "learning_rate": 1.4009786063787994e-05,
      "loss": 0.0008,
      "step": 41930
    },
    {
      "epoch": 4.493731918997107,
      "grad_norm": 0.029198486357927322,
      "learning_rate": 1.4008357441337193e-05,
      "loss": 0.0011,
      "step": 41940
    },
    {
      "epoch": 4.494803385835208,
      "grad_norm": 0.01694755256175995,
      "learning_rate": 1.400692881888639e-05,
      "loss": 0.0006,
      "step": 41950
    },
    {
      "epoch": 4.495874852673309,
      "grad_norm": 0.004654350224882364,
      "learning_rate": 1.4005500196435589e-05,
      "loss": 0.197,
      "step": 41960
    },
    {
      "epoch": 4.496946319511411,
      "grad_norm": 0.0027864021249115467,
      "learning_rate": 1.4004071573984785e-05,
      "loss": 0.0005,
      "step": 41970
    },
    {
      "epoch": 4.4980177863495125,
      "grad_norm": 0.0036885980516672134,
      "learning_rate": 1.4002642951533984e-05,
      "loss": 0.1233,
      "step": 41980
    },
    {
      "epoch": 4.499089253187614,
      "grad_norm": 0.2342631220817566,
      "learning_rate": 1.4001214329083183e-05,
      "loss": 0.0013,
      "step": 41990
    },
    {
      "epoch": 4.500160720025715,
      "grad_norm": 0.004605668596923351,
      "learning_rate": 1.3999785706632381e-05,
      "loss": 0.4284,
      "step": 42000
    },
    {
      "epoch": 4.501232186863817,
      "grad_norm": 0.002379549900069833,
      "learning_rate": 1.399835708418158e-05,
      "loss": 0.227,
      "step": 42010
    },
    {
      "epoch": 4.502303653701918,
      "grad_norm": 0.0019135929178446531,
      "learning_rate": 1.3996928461730776e-05,
      "loss": 0.0001,
      "step": 42020
    },
    {
      "epoch": 4.503375120540019,
      "grad_norm": 0.0017409685533493757,
      "learning_rate": 1.3995499839279976e-05,
      "loss": 0.1465,
      "step": 42030
    },
    {
      "epoch": 4.504446587378121,
      "grad_norm": 21.373254776000977,
      "learning_rate": 1.3994071216829172e-05,
      "loss": 0.5837,
      "step": 42040
    },
    {
      "epoch": 4.505518054216222,
      "grad_norm": 57.61216354370117,
      "learning_rate": 1.3992642594378371e-05,
      "loss": 0.16,
      "step": 42050
    },
    {
      "epoch": 4.506589521054323,
      "grad_norm": 0.00871746614575386,
      "learning_rate": 1.399121397192757e-05,
      "loss": 0.0046,
      "step": 42060
    },
    {
      "epoch": 4.507660987892425,
      "grad_norm": 0.00660843076184392,
      "learning_rate": 1.3989785349476768e-05,
      "loss": 0.0018,
      "step": 42070
    },
    {
      "epoch": 4.508732454730526,
      "grad_norm": 0.01728695072233677,
      "learning_rate": 1.3988356727025968e-05,
      "loss": 0.0009,
      "step": 42080
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 0.014831487089395523,
      "learning_rate": 1.3986928104575163e-05,
      "loss": 0.0009,
      "step": 42090
    },
    {
      "epoch": 4.5108753884067285,
      "grad_norm": 0.01636502332985401,
      "learning_rate": 1.3985499482124363e-05,
      "loss": 0.0009,
      "step": 42100
    },
    {
      "epoch": 4.5119468552448305,
      "grad_norm": 0.0029537752270698547,
      "learning_rate": 1.3984070859673562e-05,
      "loss": 0.0006,
      "step": 42110
    },
    {
      "epoch": 4.513018322082932,
      "grad_norm": 0.010378721170127392,
      "learning_rate": 1.3982642237222758e-05,
      "loss": 0.3599,
      "step": 42120
    },
    {
      "epoch": 4.514089788921033,
      "grad_norm": 0.01694345846772194,
      "learning_rate": 1.3981213614771958e-05,
      "loss": 0.0985,
      "step": 42130
    },
    {
      "epoch": 4.515161255759134,
      "grad_norm": 0.114217609167099,
      "learning_rate": 1.3979784992321155e-05,
      "loss": 0.0008,
      "step": 42140
    },
    {
      "epoch": 4.516232722597236,
      "grad_norm": 0.002392766997218132,
      "learning_rate": 1.3978356369870355e-05,
      "loss": 0.1042,
      "step": 42150
    },
    {
      "epoch": 4.517304189435337,
      "grad_norm": 0.002264349954202771,
      "learning_rate": 1.397692774741955e-05,
      "loss": 0.0028,
      "step": 42160
    },
    {
      "epoch": 4.518375656273438,
      "grad_norm": 0.0017425039550289512,
      "learning_rate": 1.397549912496875e-05,
      "loss": 0.0004,
      "step": 42170
    },
    {
      "epoch": 4.51944712311154,
      "grad_norm": 0.002006297465413809,
      "learning_rate": 1.397407050251795e-05,
      "loss": 0.2347,
      "step": 42180
    },
    {
      "epoch": 4.520518589949641,
      "grad_norm": 0.04862416908144951,
      "learning_rate": 1.3972641880067145e-05,
      "loss": 0.0003,
      "step": 42190
    },
    {
      "epoch": 4.521590056787742,
      "grad_norm": 0.0016671973280608654,
      "learning_rate": 1.3971213257616345e-05,
      "loss": 0.1467,
      "step": 42200
    },
    {
      "epoch": 4.522661523625843,
      "grad_norm": 0.0017882047686725855,
      "learning_rate": 1.3969784635165542e-05,
      "loss": 0.0018,
      "step": 42210
    },
    {
      "epoch": 4.523732990463945,
      "grad_norm": 0.002324229571968317,
      "learning_rate": 1.3968356012714742e-05,
      "loss": 0.0058,
      "step": 42220
    },
    {
      "epoch": 4.5248044573020465,
      "grad_norm": 0.008400161750614643,
      "learning_rate": 1.396692739026394e-05,
      "loss": 0.0004,
      "step": 42230
    },
    {
      "epoch": 4.525875924140148,
      "grad_norm": 133.62892150878906,
      "learning_rate": 1.3965498767813137e-05,
      "loss": 0.1739,
      "step": 42240
    },
    {
      "epoch": 4.52694739097825,
      "grad_norm": 30.678409576416016,
      "learning_rate": 1.3964070145362336e-05,
      "loss": 0.4794,
      "step": 42250
    },
    {
      "epoch": 4.528018857816351,
      "grad_norm": 0.0014333389699459076,
      "learning_rate": 1.3962641522911532e-05,
      "loss": 0.0001,
      "step": 42260
    },
    {
      "epoch": 4.529090324654452,
      "grad_norm": 0.004525298252701759,
      "learning_rate": 1.3961212900460732e-05,
      "loss": 0.0845,
      "step": 42270
    },
    {
      "epoch": 4.530161791492553,
      "grad_norm": 0.02597227692604065,
      "learning_rate": 1.395978427800993e-05,
      "loss": 0.3315,
      "step": 42280
    },
    {
      "epoch": 4.531233258330655,
      "grad_norm": 0.0058394987136125565,
      "learning_rate": 1.3958355655559129e-05,
      "loss": 0.1825,
      "step": 42290
    },
    {
      "epoch": 4.532304725168756,
      "grad_norm": 0.018851174041628838,
      "learning_rate": 1.3956927033108326e-05,
      "loss": 0.4268,
      "step": 42300
    },
    {
      "epoch": 4.533376192006857,
      "grad_norm": 0.027406910434365273,
      "learning_rate": 1.3955498410657524e-05,
      "loss": 0.1252,
      "step": 42310
    },
    {
      "epoch": 4.534447658844959,
      "grad_norm": 0.03209549933671951,
      "learning_rate": 1.3954069788206724e-05,
      "loss": 0.189,
      "step": 42320
    },
    {
      "epoch": 4.53551912568306,
      "grad_norm": 0.12368853390216827,
      "learning_rate": 1.395264116575592e-05,
      "loss": 0.1547,
      "step": 42330
    },
    {
      "epoch": 4.536590592521161,
      "grad_norm": 0.049941837787628174,
      "learning_rate": 1.3951212543305119e-05,
      "loss": 0.1132,
      "step": 42340
    },
    {
      "epoch": 4.5376620593592625,
      "grad_norm": 206.6647186279297,
      "learning_rate": 1.3949783920854318e-05,
      "loss": 0.0124,
      "step": 42350
    },
    {
      "epoch": 4.5387335261973645,
      "grad_norm": 0.0640924796462059,
      "learning_rate": 1.3948355298403516e-05,
      "loss": 0.1585,
      "step": 42360
    },
    {
      "epoch": 4.539804993035466,
      "grad_norm": 0.11904353648424149,
      "learning_rate": 1.3946926675952715e-05,
      "loss": 0.1436,
      "step": 42370
    },
    {
      "epoch": 4.540876459873567,
      "grad_norm": 0.0862933024764061,
      "learning_rate": 1.3945498053501911e-05,
      "loss": 0.0009,
      "step": 42380
    },
    {
      "epoch": 4.541947926711668,
      "grad_norm": 0.0011966365855187178,
      "learning_rate": 1.394406943105111e-05,
      "loss": 0.1333,
      "step": 42390
    },
    {
      "epoch": 4.54301939354977,
      "grad_norm": 0.006245665717869997,
      "learning_rate": 1.3942640808600307e-05,
      "loss": 0.0003,
      "step": 42400
    },
    {
      "epoch": 4.544090860387871,
      "grad_norm": 0.03346904739737511,
      "learning_rate": 1.3941212186149506e-05,
      "loss": 0.1388,
      "step": 42410
    },
    {
      "epoch": 4.545162327225972,
      "grad_norm": 0.09654553234577179,
      "learning_rate": 1.3939783563698705e-05,
      "loss": 0.2099,
      "step": 42420
    },
    {
      "epoch": 4.546233794064074,
      "grad_norm": 0.32709285616874695,
      "learning_rate": 1.3938354941247903e-05,
      "loss": 0.0015,
      "step": 42430
    },
    {
      "epoch": 4.547305260902175,
      "grad_norm": 0.001100015826523304,
      "learning_rate": 1.3936926318797102e-05,
      "loss": 0.4464,
      "step": 42440
    },
    {
      "epoch": 4.548376727740276,
      "grad_norm": 0.0012329594464972615,
      "learning_rate": 1.3935497696346298e-05,
      "loss": 0.0127,
      "step": 42450
    },
    {
      "epoch": 4.549448194578378,
      "grad_norm": 36.92439270019531,
      "learning_rate": 1.3934069073895498e-05,
      "loss": 0.4144,
      "step": 42460
    },
    {
      "epoch": 4.550519661416479,
      "grad_norm": 0.02250041998922825,
      "learning_rate": 1.3932640451444697e-05,
      "loss": 0.0005,
      "step": 42470
    },
    {
      "epoch": 4.5515911282545805,
      "grad_norm": 0.08254299312829971,
      "learning_rate": 1.3931211828993893e-05,
      "loss": 0.002,
      "step": 42480
    },
    {
      "epoch": 4.552662595092682,
      "grad_norm": 0.001719994586892426,
      "learning_rate": 1.3929783206543092e-05,
      "loss": 0.1207,
      "step": 42490
    },
    {
      "epoch": 4.553734061930784,
      "grad_norm": 0.002198618371039629,
      "learning_rate": 1.392835458409229e-05,
      "loss": 0.4427,
      "step": 42500
    },
    {
      "epoch": 4.554805528768885,
      "grad_norm": 0.0014820615760982037,
      "learning_rate": 1.392692596164149e-05,
      "loss": 0.0002,
      "step": 42510
    },
    {
      "epoch": 4.555876995606986,
      "grad_norm": 0.0020590133499354124,
      "learning_rate": 1.3925497339190685e-05,
      "loss": 0.3535,
      "step": 42520
    },
    {
      "epoch": 4.556948462445087,
      "grad_norm": 0.013257150538265705,
      "learning_rate": 1.3924068716739885e-05,
      "loss": 0.288,
      "step": 42530
    },
    {
      "epoch": 4.558019929283189,
      "grad_norm": 0.003296208567917347,
      "learning_rate": 1.3922640094289084e-05,
      "loss": 0.0007,
      "step": 42540
    },
    {
      "epoch": 4.55909139612129,
      "grad_norm": 0.028815438970923424,
      "learning_rate": 1.392121147183828e-05,
      "loss": 0.302,
      "step": 42550
    },
    {
      "epoch": 4.560162862959391,
      "grad_norm": 0.3925682306289673,
      "learning_rate": 1.391978284938748e-05,
      "loss": 0.3943,
      "step": 42560
    },
    {
      "epoch": 4.561234329797493,
      "grad_norm": 0.12803688645362854,
      "learning_rate": 1.3918354226936677e-05,
      "loss": 0.0042,
      "step": 42570
    },
    {
      "epoch": 4.562305796635594,
      "grad_norm": 0.017048083245754242,
      "learning_rate": 1.3916925604485877e-05,
      "loss": 0.1711,
      "step": 42580
    },
    {
      "epoch": 4.563377263473695,
      "grad_norm": 0.1420750766992569,
      "learning_rate": 1.3915496982035073e-05,
      "loss": 0.2185,
      "step": 42590
    },
    {
      "epoch": 4.564448730311797,
      "grad_norm": 3.532931327819824,
      "learning_rate": 1.3914068359584272e-05,
      "loss": 0.1519,
      "step": 42600
    },
    {
      "epoch": 4.565520197149898,
      "grad_norm": 0.35014405846595764,
      "learning_rate": 1.3912639737133471e-05,
      "loss": 0.0015,
      "step": 42610
    },
    {
      "epoch": 4.5665916639879995,
      "grad_norm": 0.02941133826971054,
      "learning_rate": 1.3911211114682667e-05,
      "loss": 0.0011,
      "step": 42620
    },
    {
      "epoch": 4.567663130826101,
      "grad_norm": 40.92906951904297,
      "learning_rate": 1.3909782492231867e-05,
      "loss": 0.0914,
      "step": 42630
    },
    {
      "epoch": 4.568734597664203,
      "grad_norm": 0.045029401779174805,
      "learning_rate": 1.3908353869781064e-05,
      "loss": 0.2119,
      "step": 42640
    },
    {
      "epoch": 4.569806064502304,
      "grad_norm": 0.1700671911239624,
      "learning_rate": 1.3906925247330264e-05,
      "loss": 0.0007,
      "step": 42650
    },
    {
      "epoch": 4.570877531340405,
      "grad_norm": 0.0018726871348917484,
      "learning_rate": 1.3905496624879461e-05,
      "loss": 0.1573,
      "step": 42660
    },
    {
      "epoch": 4.571948998178506,
      "grad_norm": 0.0011254181154072285,
      "learning_rate": 1.3904068002428659e-05,
      "loss": 0.0189,
      "step": 42670
    },
    {
      "epoch": 4.573020465016608,
      "grad_norm": 0.03563053905963898,
      "learning_rate": 1.3902639379977858e-05,
      "loss": 0.0002,
      "step": 42680
    },
    {
      "epoch": 4.574091931854709,
      "grad_norm": 0.01777673326432705,
      "learning_rate": 1.3901210757527054e-05,
      "loss": 0.2673,
      "step": 42690
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 0.003482634201645851,
      "learning_rate": 1.3899782135076254e-05,
      "loss": 0.0009,
      "step": 42700
    },
    {
      "epoch": 4.576234865530912,
      "grad_norm": 0.003642665222287178,
      "learning_rate": 1.3898353512625451e-05,
      "loss": 0.3428,
      "step": 42710
    },
    {
      "epoch": 4.577306332369013,
      "grad_norm": 0.0025699292309582233,
      "learning_rate": 1.389692489017465e-05,
      "loss": 0.0015,
      "step": 42720
    },
    {
      "epoch": 4.578377799207114,
      "grad_norm": 0.04681922122836113,
      "learning_rate": 1.3895496267723848e-05,
      "loss": 0.1269,
      "step": 42730
    },
    {
      "epoch": 4.5794492660452155,
      "grad_norm": 0.0496707558631897,
      "learning_rate": 1.3894067645273046e-05,
      "loss": 0.2462,
      "step": 42740
    },
    {
      "epoch": 4.5805207328833175,
      "grad_norm": 0.07550269365310669,
      "learning_rate": 1.3892639022822245e-05,
      "loss": 0.7441,
      "step": 42750
    },
    {
      "epoch": 4.581592199721419,
      "grad_norm": 0.04595855623483658,
      "learning_rate": 1.3891210400371441e-05,
      "loss": 0.0006,
      "step": 42760
    },
    {
      "epoch": 4.58266366655952,
      "grad_norm": 0.06035758927464485,
      "learning_rate": 1.388978177792064e-05,
      "loss": 0.0007,
      "step": 42770
    },
    {
      "epoch": 4.583735133397622,
      "grad_norm": 0.0024071845691651106,
      "learning_rate": 1.388835315546984e-05,
      "loss": 0.0007,
      "step": 42780
    },
    {
      "epoch": 4.584806600235723,
      "grad_norm": 0.15261556208133698,
      "learning_rate": 1.3886924533019038e-05,
      "loss": 0.4067,
      "step": 42790
    },
    {
      "epoch": 4.585878067073824,
      "grad_norm": 0.0031159936916083097,
      "learning_rate": 1.3885495910568236e-05,
      "loss": 0.0389,
      "step": 42800
    },
    {
      "epoch": 4.586949533911925,
      "grad_norm": 0.010864767245948315,
      "learning_rate": 1.3884067288117433e-05,
      "loss": 0.0272,
      "step": 42810
    },
    {
      "epoch": 4.588021000750027,
      "grad_norm": 0.0024043309967964888,
      "learning_rate": 1.3882638665666633e-05,
      "loss": 0.0002,
      "step": 42820
    },
    {
      "epoch": 4.589092467588128,
      "grad_norm": 0.027559634298086166,
      "learning_rate": 1.3881210043215829e-05,
      "loss": 0.221,
      "step": 42830
    },
    {
      "epoch": 4.590163934426229,
      "grad_norm": 0.04227621853351593,
      "learning_rate": 1.3879781420765028e-05,
      "loss": 0.0032,
      "step": 42840
    },
    {
      "epoch": 4.591235401264331,
      "grad_norm": 0.04329239949584007,
      "learning_rate": 1.3878352798314227e-05,
      "loss": 0.0007,
      "step": 42850
    },
    {
      "epoch": 4.592306868102432,
      "grad_norm": 0.02061305195093155,
      "learning_rate": 1.3876924175863425e-05,
      "loss": 0.3029,
      "step": 42860
    },
    {
      "epoch": 4.5933783349405335,
      "grad_norm": 0.016790930181741714,
      "learning_rate": 1.3875495553412623e-05,
      "loss": 0.0006,
      "step": 42870
    },
    {
      "epoch": 4.594449801778635,
      "grad_norm": 0.05148765444755554,
      "learning_rate": 1.387406693096182e-05,
      "loss": 0.0012,
      "step": 42880
    },
    {
      "epoch": 4.595521268616737,
      "grad_norm": 31.887317657470703,
      "learning_rate": 1.387263830851102e-05,
      "loss": 0.1394,
      "step": 42890
    },
    {
      "epoch": 4.596592735454838,
      "grad_norm": 18.76702880859375,
      "learning_rate": 1.3871209686060219e-05,
      "loss": 0.1342,
      "step": 42900
    },
    {
      "epoch": 4.597664202292939,
      "grad_norm": 0.003429901320487261,
      "learning_rate": 1.3869781063609415e-05,
      "loss": 0.0034,
      "step": 42910
    },
    {
      "epoch": 4.59873566913104,
      "grad_norm": 0.006668405141681433,
      "learning_rate": 1.3868352441158614e-05,
      "loss": 0.1158,
      "step": 42920
    },
    {
      "epoch": 4.599807135969142,
      "grad_norm": 0.02632080391049385,
      "learning_rate": 1.3866923818707812e-05,
      "loss": 0.3879,
      "step": 42930
    },
    {
      "epoch": 4.600878602807243,
      "grad_norm": 0.40601107478141785,
      "learning_rate": 1.3865495196257011e-05,
      "loss": 0.165,
      "step": 42940
    },
    {
      "epoch": 4.601950069645344,
      "grad_norm": 0.027599092572927475,
      "learning_rate": 1.3864066573806207e-05,
      "loss": 0.393,
      "step": 42950
    },
    {
      "epoch": 4.603021536483446,
      "grad_norm": 0.40587371587753296,
      "learning_rate": 1.3862637951355407e-05,
      "loss": 0.4649,
      "step": 42960
    },
    {
      "epoch": 4.604093003321547,
      "grad_norm": 0.0026140143163502216,
      "learning_rate": 1.3861209328904606e-05,
      "loss": 0.0002,
      "step": 42970
    },
    {
      "epoch": 4.605164470159648,
      "grad_norm": 0.03817563131451607,
      "learning_rate": 1.3859780706453802e-05,
      "loss": 0.0013,
      "step": 42980
    },
    {
      "epoch": 4.60623593699775,
      "grad_norm": 0.0020808272529393435,
      "learning_rate": 1.3858352084003001e-05,
      "loss": 0.1793,
      "step": 42990
    },
    {
      "epoch": 4.6073074038358515,
      "grad_norm": 0.07086478918790817,
      "learning_rate": 1.3856923461552199e-05,
      "loss": 0.2441,
      "step": 43000
    },
    {
      "epoch": 4.608378870673953,
      "grad_norm": 0.020072655752301216,
      "learning_rate": 1.3855494839101398e-05,
      "loss": 0.05,
      "step": 43010
    },
    {
      "epoch": 4.609450337512054,
      "grad_norm": 0.04633177071809769,
      "learning_rate": 1.3854066216650596e-05,
      "loss": 0.0006,
      "step": 43020
    },
    {
      "epoch": 4.610521804350156,
      "grad_norm": 0.07105045765638351,
      "learning_rate": 1.3852637594199794e-05,
      "loss": 0.0015,
      "step": 43030
    },
    {
      "epoch": 4.611593271188257,
      "grad_norm": 0.14593134820461273,
      "learning_rate": 1.3851208971748993e-05,
      "loss": 0.1465,
      "step": 43040
    },
    {
      "epoch": 4.612664738026358,
      "grad_norm": 109.61347198486328,
      "learning_rate": 1.384978034929819e-05,
      "loss": 0.0113,
      "step": 43050
    },
    {
      "epoch": 4.613736204864459,
      "grad_norm": 0.0065710218623280525,
      "learning_rate": 1.3848351726847389e-05,
      "loss": 0.1516,
      "step": 43060
    },
    {
      "epoch": 4.614807671702561,
      "grad_norm": 0.0037507175002247095,
      "learning_rate": 1.3846923104396586e-05,
      "loss": 0.0001,
      "step": 43070
    },
    {
      "epoch": 4.615879138540662,
      "grad_norm": 0.0016163786640390754,
      "learning_rate": 1.3845494481945786e-05,
      "loss": 0.1076,
      "step": 43080
    },
    {
      "epoch": 4.616950605378763,
      "grad_norm": 0.0008629956864751875,
      "learning_rate": 1.3844065859494983e-05,
      "loss": 0.0018,
      "step": 43090
    },
    {
      "epoch": 4.618022072216865,
      "grad_norm": 0.0005244655767455697,
      "learning_rate": 1.3842637237044181e-05,
      "loss": 0.0004,
      "step": 43100
    },
    {
      "epoch": 4.619093539054966,
      "grad_norm": 0.0013499731430783868,
      "learning_rate": 1.384120861459338e-05,
      "loss": 0.2082,
      "step": 43110
    },
    {
      "epoch": 4.6201650058930674,
      "grad_norm": 0.01881410740315914,
      "learning_rate": 1.3839779992142576e-05,
      "loss": 0.4891,
      "step": 43120
    },
    {
      "epoch": 4.621236472731169,
      "grad_norm": 0.02131255343556404,
      "learning_rate": 1.3838351369691776e-05,
      "loss": 0.0003,
      "step": 43130
    },
    {
      "epoch": 4.6223079395692706,
      "grad_norm": 0.0021669662091881037,
      "learning_rate": 1.3836922747240975e-05,
      "loss": 0.0005,
      "step": 43140
    },
    {
      "epoch": 4.623379406407372,
      "grad_norm": 0.003068485762923956,
      "learning_rate": 1.3835494124790173e-05,
      "loss": 0.4225,
      "step": 43150
    },
    {
      "epoch": 4.624450873245473,
      "grad_norm": 0.2905435562133789,
      "learning_rate": 1.383406550233937e-05,
      "loss": 0.2447,
      "step": 43160
    },
    {
      "epoch": 4.625522340083575,
      "grad_norm": 0.06460058689117432,
      "learning_rate": 1.3832636879888568e-05,
      "loss": 0.0537,
      "step": 43170
    },
    {
      "epoch": 4.626593806921676,
      "grad_norm": 0.011729470454156399,
      "learning_rate": 1.3831208257437767e-05,
      "loss": 0.4033,
      "step": 43180
    },
    {
      "epoch": 4.627665273759777,
      "grad_norm": 0.002061349106952548,
      "learning_rate": 1.3829779634986963e-05,
      "loss": 0.0026,
      "step": 43190
    },
    {
      "epoch": 4.628736740597878,
      "grad_norm": 0.01881234720349312,
      "learning_rate": 1.3828351012536163e-05,
      "loss": 0.0013,
      "step": 43200
    },
    {
      "epoch": 4.62980820743598,
      "grad_norm": 0.0292991790920496,
      "learning_rate": 1.3826922390085362e-05,
      "loss": 0.0016,
      "step": 43210
    },
    {
      "epoch": 4.630879674274081,
      "grad_norm": 0.03571349009871483,
      "learning_rate": 1.382549376763456e-05,
      "loss": 0.1993,
      "step": 43220
    },
    {
      "epoch": 4.631951141112182,
      "grad_norm": 0.0006689424626529217,
      "learning_rate": 1.3824065145183757e-05,
      "loss": 0.0008,
      "step": 43230
    },
    {
      "epoch": 4.633022607950284,
      "grad_norm": 0.2711331844329834,
      "learning_rate": 1.3822636522732955e-05,
      "loss": 0.2044,
      "step": 43240
    },
    {
      "epoch": 4.634094074788385,
      "grad_norm": 0.15224771201610565,
      "learning_rate": 1.3821207900282154e-05,
      "loss": 0.0006,
      "step": 43250
    },
    {
      "epoch": 4.6351655416264865,
      "grad_norm": 0.036120686680078506,
      "learning_rate": 1.3819779277831354e-05,
      "loss": 0.04,
      "step": 43260
    },
    {
      "epoch": 4.636237008464588,
      "grad_norm": 27.22224998474121,
      "learning_rate": 1.381835065538055e-05,
      "loss": 0.3621,
      "step": 43270
    },
    {
      "epoch": 4.63730847530269,
      "grad_norm": 0.05299743264913559,
      "learning_rate": 1.381692203292975e-05,
      "loss": 0.0005,
      "step": 43280
    },
    {
      "epoch": 4.638379942140791,
      "grad_norm": 20.794475555419922,
      "learning_rate": 1.3815493410478947e-05,
      "loss": 0.2146,
      "step": 43290
    },
    {
      "epoch": 4.639451408978892,
      "grad_norm": 0.031808190047740936,
      "learning_rate": 1.3814064788028145e-05,
      "loss": 0.0011,
      "step": 43300
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 0.0010953119490295649,
      "learning_rate": 1.3812636165577342e-05,
      "loss": 0.0004,
      "step": 43310
    },
    {
      "epoch": 4.641594342655095,
      "grad_norm": 0.001298779621720314,
      "learning_rate": 1.3811207543126542e-05,
      "loss": 0.3539,
      "step": 43320
    },
    {
      "epoch": 4.642665809493196,
      "grad_norm": 0.0014146305620670319,
      "learning_rate": 1.3809778920675741e-05,
      "loss": 0.2913,
      "step": 43330
    },
    {
      "epoch": 4.643737276331297,
      "grad_norm": 0.03505663573741913,
      "learning_rate": 1.3808350298224937e-05,
      "loss": 0.0899,
      "step": 43340
    },
    {
      "epoch": 4.644808743169399,
      "grad_norm": 0.0007612121407873929,
      "learning_rate": 1.3806921675774136e-05,
      "loss": 0.0021,
      "step": 43350
    },
    {
      "epoch": 4.6458802100075,
      "grad_norm": 0.0017978600226342678,
      "learning_rate": 1.3805493053323334e-05,
      "loss": 0.0021,
      "step": 43360
    },
    {
      "epoch": 4.646951676845601,
      "grad_norm": 0.020320691168308258,
      "learning_rate": 1.3804064430872532e-05,
      "loss": 0.1908,
      "step": 43370
    },
    {
      "epoch": 4.648023143683703,
      "grad_norm": 0.003609665669500828,
      "learning_rate": 1.3802635808421731e-05,
      "loss": 0.0005,
      "step": 43380
    },
    {
      "epoch": 4.6490946105218045,
      "grad_norm": 0.025374531745910645,
      "learning_rate": 1.3801207185970929e-05,
      "loss": 0.1119,
      "step": 43390
    },
    {
      "epoch": 4.650166077359906,
      "grad_norm": 0.015440762042999268,
      "learning_rate": 1.3799778563520128e-05,
      "loss": 0.2325,
      "step": 43400
    },
    {
      "epoch": 4.651237544198007,
      "grad_norm": 0.03364899381995201,
      "learning_rate": 1.3798349941069324e-05,
      "loss": 0.0005,
      "step": 43410
    },
    {
      "epoch": 4.652309011036109,
      "grad_norm": 0.0007236645906232297,
      "learning_rate": 1.3796921318618523e-05,
      "loss": 0.1315,
      "step": 43420
    },
    {
      "epoch": 4.65338047787421,
      "grad_norm": 0.04674072191119194,
      "learning_rate": 1.3795492696167721e-05,
      "loss": 0.0015,
      "step": 43430
    },
    {
      "epoch": 4.654451944712311,
      "grad_norm": 15.058514595031738,
      "learning_rate": 1.3794064073716919e-05,
      "loss": 0.2939,
      "step": 43440
    },
    {
      "epoch": 4.655523411550412,
      "grad_norm": 0.0010508301202207804,
      "learning_rate": 1.3792635451266118e-05,
      "loss": 0.0003,
      "step": 43450
    },
    {
      "epoch": 4.656594878388514,
      "grad_norm": 0.011747097596526146,
      "learning_rate": 1.3791206828815316e-05,
      "loss": 0.0754,
      "step": 43460
    },
    {
      "epoch": 4.657666345226615,
      "grad_norm": 0.0012344933347776532,
      "learning_rate": 1.3789778206364515e-05,
      "loss": 0.0009,
      "step": 43470
    },
    {
      "epoch": 4.658737812064716,
      "grad_norm": 0.0008198607829399407,
      "learning_rate": 1.3788349583913711e-05,
      "loss": 0.1853,
      "step": 43480
    },
    {
      "epoch": 4.659809278902818,
      "grad_norm": 0.029270151630043983,
      "learning_rate": 1.378692096146291e-05,
      "loss": 0.0005,
      "step": 43490
    },
    {
      "epoch": 4.660880745740919,
      "grad_norm": 0.0002688333916012198,
      "learning_rate": 1.3785492339012108e-05,
      "loss": 0.183,
      "step": 43500
    },
    {
      "epoch": 4.6619522125790205,
      "grad_norm": 0.08578947186470032,
      "learning_rate": 1.3784063716561308e-05,
      "loss": 0.0017,
      "step": 43510
    },
    {
      "epoch": 4.6630236794171225,
      "grad_norm": 0.0004531690792646259,
      "learning_rate": 1.3782635094110505e-05,
      "loss": 0.0002,
      "step": 43520
    },
    {
      "epoch": 4.664095146255224,
      "grad_norm": 0.0003707423456944525,
      "learning_rate": 1.3781206471659703e-05,
      "loss": 0.0005,
      "step": 43530
    },
    {
      "epoch": 4.665166613093325,
      "grad_norm": 0.01937020942568779,
      "learning_rate": 1.3779777849208902e-05,
      "loss": 0.0002,
      "step": 43540
    },
    {
      "epoch": 4.666238079931426,
      "grad_norm": 0.8885616660118103,
      "learning_rate": 1.3778349226758098e-05,
      "loss": 0.2013,
      "step": 43550
    },
    {
      "epoch": 4.667309546769528,
      "grad_norm": 0.0002368228160776198,
      "learning_rate": 1.3776920604307298e-05,
      "loss": 0.0005,
      "step": 43560
    },
    {
      "epoch": 4.668381013607629,
      "grad_norm": 0.0003275744093116373,
      "learning_rate": 1.3775491981856497e-05,
      "loss": 0.5079,
      "step": 43570
    },
    {
      "epoch": 4.66945248044573,
      "grad_norm": 0.04501897096633911,
      "learning_rate": 1.3774063359405695e-05,
      "loss": 0.0004,
      "step": 43580
    },
    {
      "epoch": 4.670523947283831,
      "grad_norm": 0.0015225746901705861,
      "learning_rate": 1.3772634736954892e-05,
      "loss": 0.0002,
      "step": 43590
    },
    {
      "epoch": 4.671595414121933,
      "grad_norm": 0.04285329207777977,
      "learning_rate": 1.377120611450409e-05,
      "loss": 0.3761,
      "step": 43600
    },
    {
      "epoch": 4.672666880960034,
      "grad_norm": 0.054889097809791565,
      "learning_rate": 1.376977749205329e-05,
      "loss": 0.1836,
      "step": 43610
    },
    {
      "epoch": 4.673738347798135,
      "grad_norm": 0.013352805748581886,
      "learning_rate": 1.3768348869602485e-05,
      "loss": 0.3685,
      "step": 43620
    },
    {
      "epoch": 4.674809814636237,
      "grad_norm": 0.015652373433113098,
      "learning_rate": 1.3766920247151685e-05,
      "loss": 0.1145,
      "step": 43630
    },
    {
      "epoch": 4.6758812814743385,
      "grad_norm": 0.017138732597231865,
      "learning_rate": 1.3765491624700884e-05,
      "loss": 0.2064,
      "step": 43640
    },
    {
      "epoch": 4.67695274831244,
      "grad_norm": 0.0005003084079362452,
      "learning_rate": 1.3764063002250082e-05,
      "loss": 0.0013,
      "step": 43650
    },
    {
      "epoch": 4.678024215150542,
      "grad_norm": 0.001785796950571239,
      "learning_rate": 1.376263437979928e-05,
      "loss": 0.0002,
      "step": 43660
    },
    {
      "epoch": 4.679095681988643,
      "grad_norm": 0.03222563490271568,
      "learning_rate": 1.3761205757348477e-05,
      "loss": 0.0042,
      "step": 43670
    },
    {
      "epoch": 4.680167148826744,
      "grad_norm": 0.022805504500865936,
      "learning_rate": 1.3759777134897676e-05,
      "loss": 0.1983,
      "step": 43680
    },
    {
      "epoch": 4.681238615664845,
      "grad_norm": 0.023598970845341682,
      "learning_rate": 1.3758348512446876e-05,
      "loss": 0.3372,
      "step": 43690
    },
    {
      "epoch": 4.682310082502947,
      "grad_norm": 0.0662187933921814,
      "learning_rate": 1.3756919889996072e-05,
      "loss": 0.0013,
      "step": 43700
    },
    {
      "epoch": 4.683381549341048,
      "grad_norm": 0.026989296078681946,
      "learning_rate": 1.3755491267545271e-05,
      "loss": 0.0003,
      "step": 43710
    },
    {
      "epoch": 4.684453016179149,
      "grad_norm": 47.98428726196289,
      "learning_rate": 1.3754062645094469e-05,
      "loss": 0.3244,
      "step": 43720
    },
    {
      "epoch": 4.68552448301725,
      "grad_norm": 0.009368074126541615,
      "learning_rate": 1.3752634022643666e-05,
      "loss": 0.0002,
      "step": 43730
    },
    {
      "epoch": 4.686595949855352,
      "grad_norm": 0.09129780530929565,
      "learning_rate": 1.3751205400192864e-05,
      "loss": 0.0006,
      "step": 43740
    },
    {
      "epoch": 4.687667416693453,
      "grad_norm": 0.014468126930296421,
      "learning_rate": 1.3749776777742064e-05,
      "loss": 0.226,
      "step": 43750
    },
    {
      "epoch": 4.688738883531554,
      "grad_norm": 24.822139739990234,
      "learning_rate": 1.3748348155291263e-05,
      "loss": 0.6345,
      "step": 43760
    },
    {
      "epoch": 4.689810350369656,
      "grad_norm": 35.799591064453125,
      "learning_rate": 1.3746919532840459e-05,
      "loss": 0.1542,
      "step": 43770
    },
    {
      "epoch": 4.6908818172077575,
      "grad_norm": 0.22836335003376007,
      "learning_rate": 1.3745490910389658e-05,
      "loss": 0.1382,
      "step": 43780
    },
    {
      "epoch": 4.691953284045859,
      "grad_norm": 0.0022797295823693275,
      "learning_rate": 1.3744062287938856e-05,
      "loss": 0.0014,
      "step": 43790
    },
    {
      "epoch": 4.69302475088396,
      "grad_norm": 0.02318190596997738,
      "learning_rate": 1.3742633665488054e-05,
      "loss": 0.0084,
      "step": 43800
    },
    {
      "epoch": 4.694096217722062,
      "grad_norm": 0.040956273674964905,
      "learning_rate": 1.3741205043037253e-05,
      "loss": 0.0007,
      "step": 43810
    },
    {
      "epoch": 4.695167684560163,
      "grad_norm": 0.0050283619202673435,
      "learning_rate": 1.373977642058645e-05,
      "loss": 0.0007,
      "step": 43820
    },
    {
      "epoch": 4.696239151398264,
      "grad_norm": 0.0005155914695933461,
      "learning_rate": 1.373834779813565e-05,
      "loss": 0.1343,
      "step": 43830
    },
    {
      "epoch": 4.697310618236365,
      "grad_norm": 0.019744519144296646,
      "learning_rate": 1.3736919175684846e-05,
      "loss": 0.178,
      "step": 43840
    },
    {
      "epoch": 4.698382085074467,
      "grad_norm": 0.0011241922620683908,
      "learning_rate": 1.3735490553234045e-05,
      "loss": 0.0002,
      "step": 43850
    },
    {
      "epoch": 4.699453551912568,
      "grad_norm": 0.27616992592811584,
      "learning_rate": 1.3734061930783243e-05,
      "loss": 0.0007,
      "step": 43860
    },
    {
      "epoch": 4.700525018750669,
      "grad_norm": 0.0004095305048394948,
      "learning_rate": 1.373263330833244e-05,
      "loss": 0.0002,
      "step": 43870
    },
    {
      "epoch": 4.701596485588771,
      "grad_norm": 0.011274922639131546,
      "learning_rate": 1.373120468588164e-05,
      "loss": 0.007,
      "step": 43880
    },
    {
      "epoch": 4.702667952426872,
      "grad_norm": 0.003286893479526043,
      "learning_rate": 1.3729776063430838e-05,
      "loss": 0.2629,
      "step": 43890
    },
    {
      "epoch": 4.7037394192649735,
      "grad_norm": 0.0026034556794911623,
      "learning_rate": 1.3728347440980037e-05,
      "loss": 0.0006,
      "step": 43900
    },
    {
      "epoch": 4.7048108861030755,
      "grad_norm": 0.011056693270802498,
      "learning_rate": 1.3726918818529233e-05,
      "loss": 0.0004,
      "step": 43910
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 96.56837463378906,
      "learning_rate": 1.3725490196078432e-05,
      "loss": 0.156,
      "step": 43920
    },
    {
      "epoch": 4.706953819779278,
      "grad_norm": 0.9323618412017822,
      "learning_rate": 1.3724061573627632e-05,
      "loss": 0.0009,
      "step": 43930
    },
    {
      "epoch": 4.708025286617379,
      "grad_norm": 103.09957122802734,
      "learning_rate": 1.3722632951176828e-05,
      "loss": 0.3641,
      "step": 43940
    },
    {
      "epoch": 4.709096753455481,
      "grad_norm": 0.0005967495962977409,
      "learning_rate": 1.3721204328726027e-05,
      "loss": 0.2994,
      "step": 43950
    },
    {
      "epoch": 4.710168220293582,
      "grad_norm": 0.001112160854972899,
      "learning_rate": 1.3719775706275225e-05,
      "loss": 0.0004,
      "step": 43960
    },
    {
      "epoch": 4.711239687131683,
      "grad_norm": 0.011620975099503994,
      "learning_rate": 1.3718347083824424e-05,
      "loss": 0.0002,
      "step": 43970
    },
    {
      "epoch": 4.712311153969784,
      "grad_norm": 0.01949303038418293,
      "learning_rate": 1.371691846137362e-05,
      "loss": 0.1998,
      "step": 43980
    },
    {
      "epoch": 4.713382620807886,
      "grad_norm": 0.01998751610517502,
      "learning_rate": 1.371548983892282e-05,
      "loss": 0.2916,
      "step": 43990
    },
    {
      "epoch": 4.714454087645987,
      "grad_norm": 0.013700529001653194,
      "learning_rate": 1.3714061216472019e-05,
      "loss": 0.1717,
      "step": 44000
    },
    {
      "epoch": 4.715525554484088,
      "grad_norm": 0.028634704649448395,
      "learning_rate": 1.3712632594021215e-05,
      "loss": 0.0017,
      "step": 44010
    },
    {
      "epoch": 4.71659702132219,
      "grad_norm": 0.0005154467071406543,
      "learning_rate": 1.3711203971570414e-05,
      "loss": 0.0017,
      "step": 44020
    },
    {
      "epoch": 4.7176684881602915,
      "grad_norm": 0.019635917618870735,
      "learning_rate": 1.3709775349119612e-05,
      "loss": 0.0009,
      "step": 44030
    },
    {
      "epoch": 4.718739954998393,
      "grad_norm": 0.0006243310053832829,
      "learning_rate": 1.3708346726668811e-05,
      "loss": 0.1843,
      "step": 44040
    },
    {
      "epoch": 4.719811421836495,
      "grad_norm": 0.0011871253373101354,
      "learning_rate": 1.370691810421801e-05,
      "loss": 0.0002,
      "step": 44050
    },
    {
      "epoch": 4.720882888674596,
      "grad_norm": 0.01853342168033123,
      "learning_rate": 1.3705489481767207e-05,
      "loss": 0.3708,
      "step": 44060
    },
    {
      "epoch": 4.721954355512697,
      "grad_norm": 0.45111557841300964,
      "learning_rate": 1.3704060859316406e-05,
      "loss": 0.1715,
      "step": 44070
    },
    {
      "epoch": 4.723025822350798,
      "grad_norm": 0.030207278206944466,
      "learning_rate": 1.3702632236865604e-05,
      "loss": 0.0022,
      "step": 44080
    },
    {
      "epoch": 4.7240972891889,
      "grad_norm": 0.06602921336889267,
      "learning_rate": 1.3701203614414801e-05,
      "loss": 0.0007,
      "step": 44090
    },
    {
      "epoch": 4.725168756027001,
      "grad_norm": 0.007106117904186249,
      "learning_rate": 1.3699774991963999e-05,
      "loss": 0.3586,
      "step": 44100
    },
    {
      "epoch": 4.726240222865102,
      "grad_norm": 0.000739305920433253,
      "learning_rate": 1.3698346369513198e-05,
      "loss": 0.1653,
      "step": 44110
    },
    {
      "epoch": 4.727311689703203,
      "grad_norm": 0.07245977222919464,
      "learning_rate": 1.3696917747062398e-05,
      "loss": 0.0006,
      "step": 44120
    },
    {
      "epoch": 4.728383156541305,
      "grad_norm": 0.0006712543545290828,
      "learning_rate": 1.3695489124611594e-05,
      "loss": 0.1692,
      "step": 44130
    },
    {
      "epoch": 4.729454623379406,
      "grad_norm": 0.025812117382884026,
      "learning_rate": 1.3694060502160793e-05,
      "loss": 0.0633,
      "step": 44140
    },
    {
      "epoch": 4.7305260902175075,
      "grad_norm": 0.0007954464526847005,
      "learning_rate": 1.369263187970999e-05,
      "loss": 0.2298,
      "step": 44150
    },
    {
      "epoch": 4.7315975570556095,
      "grad_norm": 0.1730944663286209,
      "learning_rate": 1.3691203257259188e-05,
      "loss": 0.3004,
      "step": 44160
    },
    {
      "epoch": 4.732669023893711,
      "grad_norm": 0.13674421608448029,
      "learning_rate": 1.3689774634808388e-05,
      "loss": 0.3325,
      "step": 44170
    },
    {
      "epoch": 4.733740490731812,
      "grad_norm": 0.0008387606358155608,
      "learning_rate": 1.3688346012357585e-05,
      "loss": 0.0008,
      "step": 44180
    },
    {
      "epoch": 4.734811957569914,
      "grad_norm": 0.02817068062722683,
      "learning_rate": 1.3686917389906785e-05,
      "loss": 0.4439,
      "step": 44190
    },
    {
      "epoch": 4.735883424408015,
      "grad_norm": 0.00679505430161953,
      "learning_rate": 1.368548876745598e-05,
      "loss": 0.1934,
      "step": 44200
    },
    {
      "epoch": 4.736954891246116,
      "grad_norm": 0.02603761851787567,
      "learning_rate": 1.368406014500518e-05,
      "loss": 0.1999,
      "step": 44210
    },
    {
      "epoch": 4.738026358084217,
      "grad_norm": 0.00724985683336854,
      "learning_rate": 1.3682631522554378e-05,
      "loss": 0.0009,
      "step": 44220
    },
    {
      "epoch": 4.739097824922319,
      "grad_norm": 0.2560907006263733,
      "learning_rate": 1.3681202900103576e-05,
      "loss": 0.0047,
      "step": 44230
    },
    {
      "epoch": 4.74016929176042,
      "grad_norm": 0.028822069987654686,
      "learning_rate": 1.3679774277652775e-05,
      "loss": 0.0917,
      "step": 44240
    },
    {
      "epoch": 4.741240758598521,
      "grad_norm": 0.0008655002457089722,
      "learning_rate": 1.3678345655201973e-05,
      "loss": 0.0005,
      "step": 44250
    },
    {
      "epoch": 4.742312225436622,
      "grad_norm": 0.0003886308695655316,
      "learning_rate": 1.3676917032751172e-05,
      "loss": 0.1684,
      "step": 44260
    },
    {
      "epoch": 4.743383692274724,
      "grad_norm": 0.015648253262043,
      "learning_rate": 1.3675488410300368e-05,
      "loss": 0.0006,
      "step": 44270
    },
    {
      "epoch": 4.7444551591128254,
      "grad_norm": 0.00022736597748007625,
      "learning_rate": 1.3674059787849567e-05,
      "loss": 0.0009,
      "step": 44280
    },
    {
      "epoch": 4.745526625950927,
      "grad_norm": 38.039005279541016,
      "learning_rate": 1.3672631165398767e-05,
      "loss": 0.3099,
      "step": 44290
    },
    {
      "epoch": 4.7465980927890286,
      "grad_norm": 0.08149538189172745,
      "learning_rate": 1.3671202542947963e-05,
      "loss": 0.001,
      "step": 44300
    },
    {
      "epoch": 4.74766955962713,
      "grad_norm": 0.00024036690592765808,
      "learning_rate": 1.3669773920497162e-05,
      "loss": 0.0463,
      "step": 44310
    },
    {
      "epoch": 4.748741026465231,
      "grad_norm": 0.00046393723459914327,
      "learning_rate": 1.366834529804636e-05,
      "loss": 0.1129,
      "step": 44320
    },
    {
      "epoch": 4.749812493303332,
      "grad_norm": 0.0005610791267827153,
      "learning_rate": 1.3666916675595559e-05,
      "loss": 0.0037,
      "step": 44330
    },
    {
      "epoch": 4.750883960141434,
      "grad_norm": 3.1112751960754395,
      "learning_rate": 1.3665488053144755e-05,
      "loss": 0.3709,
      "step": 44340
    },
    {
      "epoch": 4.751955426979535,
      "grad_norm": 0.00017217300774063915,
      "learning_rate": 1.3664059430693954e-05,
      "loss": 0.0,
      "step": 44350
    },
    {
      "epoch": 4.753026893817636,
      "grad_norm": 0.26624417304992676,
      "learning_rate": 1.3662630808243154e-05,
      "loss": 0.3417,
      "step": 44360
    },
    {
      "epoch": 4.754098360655737,
      "grad_norm": 1.5168014764785767,
      "learning_rate": 1.366120218579235e-05,
      "loss": 0.0033,
      "step": 44370
    },
    {
      "epoch": 4.755169827493839,
      "grad_norm": 0.00032211726647801697,
      "learning_rate": 1.3659773563341549e-05,
      "loss": 0.0007,
      "step": 44380
    },
    {
      "epoch": 4.75624129433194,
      "grad_norm": 0.00023774967121426016,
      "learning_rate": 1.3658344940890747e-05,
      "loss": 0.2975,
      "step": 44390
    },
    {
      "epoch": 4.757312761170041,
      "grad_norm": 0.0009845795575529337,
      "learning_rate": 1.3656916318439946e-05,
      "loss": 0.196,
      "step": 44400
    },
    {
      "epoch": 4.758384228008143,
      "grad_norm": 0.0020876158960163593,
      "learning_rate": 1.3655487695989142e-05,
      "loss": 0.027,
      "step": 44410
    },
    {
      "epoch": 4.7594556948462445,
      "grad_norm": 0.0023979998659342527,
      "learning_rate": 1.3654059073538341e-05,
      "loss": 0.2643,
      "step": 44420
    },
    {
      "epoch": 4.760527161684346,
      "grad_norm": 0.4633025825023651,
      "learning_rate": 1.365263045108754e-05,
      "loss": 0.0005,
      "step": 44430
    },
    {
      "epoch": 4.761598628522448,
      "grad_norm": 0.005537931341677904,
      "learning_rate": 1.3651201828636737e-05,
      "loss": 0.3648,
      "step": 44440
    },
    {
      "epoch": 4.762670095360549,
      "grad_norm": 0.0007747040945105255,
      "learning_rate": 1.3649773206185936e-05,
      "loss": 0.2669,
      "step": 44450
    },
    {
      "epoch": 4.76374156219865,
      "grad_norm": 0.00174276705365628,
      "learning_rate": 1.3648344583735134e-05,
      "loss": 0.0875,
      "step": 44460
    },
    {
      "epoch": 4.764813029036751,
      "grad_norm": 0.07085481286048889,
      "learning_rate": 1.3646915961284333e-05,
      "loss": 0.0004,
      "step": 44470
    },
    {
      "epoch": 4.765884495874853,
      "grad_norm": 0.37593093514442444,
      "learning_rate": 1.3645487338833533e-05,
      "loss": 0.1978,
      "step": 44480
    },
    {
      "epoch": 4.766955962712954,
      "grad_norm": 0.10145729035139084,
      "learning_rate": 1.3644058716382729e-05,
      "loss": 0.0013,
      "step": 44490
    },
    {
      "epoch": 4.768027429551055,
      "grad_norm": 0.023476915434002876,
      "learning_rate": 1.3642630093931928e-05,
      "loss": 0.0013,
      "step": 44500
    },
    {
      "epoch": 4.769098896389156,
      "grad_norm": 0.5091140270233154,
      "learning_rate": 1.3641201471481124e-05,
      "loss": 0.0007,
      "step": 44510
    },
    {
      "epoch": 4.770170363227258,
      "grad_norm": 0.009989636018872261,
      "learning_rate": 1.3639772849030323e-05,
      "loss": 0.2458,
      "step": 44520
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 0.020488400012254715,
      "learning_rate": 1.3638344226579521e-05,
      "loss": 0.0004,
      "step": 44530
    },
    {
      "epoch": 4.7723132969034605,
      "grad_norm": 0.018868599086999893,
      "learning_rate": 1.363691560412872e-05,
      "loss": 0.0004,
      "step": 44540
    },
    {
      "epoch": 4.7733847637415625,
      "grad_norm": 0.0009359357645735145,
      "learning_rate": 1.363548698167792e-05,
      "loss": 0.0008,
      "step": 44550
    },
    {
      "epoch": 4.774456230579664,
      "grad_norm": 0.14522336423397064,
      "learning_rate": 1.3634058359227116e-05,
      "loss": 0.0752,
      "step": 44560
    },
    {
      "epoch": 4.775527697417765,
      "grad_norm": 0.0078033870086073875,
      "learning_rate": 1.3632629736776315e-05,
      "loss": 0.0003,
      "step": 44570
    },
    {
      "epoch": 4.776599164255867,
      "grad_norm": 0.01628291793167591,
      "learning_rate": 1.3631201114325513e-05,
      "loss": 0.0009,
      "step": 44580
    },
    {
      "epoch": 4.777670631093968,
      "grad_norm": 32.478546142578125,
      "learning_rate": 1.362977249187471e-05,
      "loss": 0.4453,
      "step": 44590
    },
    {
      "epoch": 4.778742097932069,
      "grad_norm": 0.0002218241133959964,
      "learning_rate": 1.362834386942391e-05,
      "loss": 0.5776,
      "step": 44600
    },
    {
      "epoch": 4.77981356477017,
      "grad_norm": 0.02715088054537773,
      "learning_rate": 1.3626915246973107e-05,
      "loss": 0.0003,
      "step": 44610
    },
    {
      "epoch": 4.780885031608272,
      "grad_norm": 0.12932385504245758,
      "learning_rate": 1.3625486624522307e-05,
      "loss": 0.0003,
      "step": 44620
    },
    {
      "epoch": 4.781956498446373,
      "grad_norm": 0.02066967450082302,
      "learning_rate": 1.3624058002071503e-05,
      "loss": 0.0038,
      "step": 44630
    },
    {
      "epoch": 4.783027965284474,
      "grad_norm": 0.0013232643250375986,
      "learning_rate": 1.3622629379620702e-05,
      "loss": 0.0009,
      "step": 44640
    },
    {
      "epoch": 4.784099432122575,
      "grad_norm": 0.0023705107159912586,
      "learning_rate": 1.36212007571699e-05,
      "loss": 0.2091,
      "step": 44650
    },
    {
      "epoch": 4.785170898960677,
      "grad_norm": 0.024545039981603622,
      "learning_rate": 1.3619772134719097e-05,
      "loss": 0.2258,
      "step": 44660
    },
    {
      "epoch": 4.7862423657987785,
      "grad_norm": 0.0005033900961279869,
      "learning_rate": 1.3618343512268297e-05,
      "loss": 0.373,
      "step": 44670
    },
    {
      "epoch": 4.78731383263688,
      "grad_norm": 0.02879563346505165,
      "learning_rate": 1.3616914889817495e-05,
      "loss": 0.1003,
      "step": 44680
    },
    {
      "epoch": 4.788385299474982,
      "grad_norm": 0.18829326331615448,
      "learning_rate": 1.3615486267366694e-05,
      "loss": 0.001,
      "step": 44690
    },
    {
      "epoch": 4.789456766313083,
      "grad_norm": 0.02237730473279953,
      "learning_rate": 1.361405764491589e-05,
      "loss": 0.0013,
      "step": 44700
    },
    {
      "epoch": 4.790528233151184,
      "grad_norm": 0.07856165617704391,
      "learning_rate": 1.361262902246509e-05,
      "loss": 0.0005,
      "step": 44710
    },
    {
      "epoch": 4.791599699989286,
      "grad_norm": 0.0005035288631916046,
      "learning_rate": 1.3611200400014289e-05,
      "loss": 0.2149,
      "step": 44720
    },
    {
      "epoch": 4.792671166827387,
      "grad_norm": 21.37227439880371,
      "learning_rate": 1.3609771777563485e-05,
      "loss": 0.0043,
      "step": 44730
    },
    {
      "epoch": 4.793742633665488,
      "grad_norm": 0.004882314708083868,
      "learning_rate": 1.3608343155112684e-05,
      "loss": 0.0002,
      "step": 44740
    },
    {
      "epoch": 4.794814100503589,
      "grad_norm": 0.0005502593121491373,
      "learning_rate": 1.3606914532661882e-05,
      "loss": 0.1921,
      "step": 44750
    },
    {
      "epoch": 4.795885567341691,
      "grad_norm": 0.06684348732233047,
      "learning_rate": 1.3605485910211081e-05,
      "loss": 0.473,
      "step": 44760
    },
    {
      "epoch": 4.796957034179792,
      "grad_norm": 0.04048844426870346,
      "learning_rate": 1.3604057287760277e-05,
      "loss": 0.0004,
      "step": 44770
    },
    {
      "epoch": 4.798028501017893,
      "grad_norm": 0.033092837780714035,
      "learning_rate": 1.3602628665309476e-05,
      "loss": 0.0004,
      "step": 44780
    },
    {
      "epoch": 4.7990999678559945,
      "grad_norm": 0.06736637651920319,
      "learning_rate": 1.3601200042858676e-05,
      "loss": 0.1178,
      "step": 44790
    },
    {
      "epoch": 4.8001714346940965,
      "grad_norm": 0.0002360333310207352,
      "learning_rate": 1.3599771420407872e-05,
      "loss": 0.1736,
      "step": 44800
    },
    {
      "epoch": 4.801242901532198,
      "grad_norm": 0.0002266798837808892,
      "learning_rate": 1.3598342797957071e-05,
      "loss": 0.1623,
      "step": 44810
    },
    {
      "epoch": 4.802314368370299,
      "grad_norm": 0.0645429864525795,
      "learning_rate": 1.3596914175506269e-05,
      "loss": 0.1424,
      "step": 44820
    },
    {
      "epoch": 4.803385835208401,
      "grad_norm": 0.120812326669693,
      "learning_rate": 1.3595485553055468e-05,
      "loss": 0.1875,
      "step": 44830
    },
    {
      "epoch": 4.804457302046502,
      "grad_norm": 0.003274389309808612,
      "learning_rate": 1.3594056930604666e-05,
      "loss": 0.001,
      "step": 44840
    },
    {
      "epoch": 4.805528768884603,
      "grad_norm": 0.2844145596027374,
      "learning_rate": 1.3592628308153863e-05,
      "loss": 0.0007,
      "step": 44850
    },
    {
      "epoch": 4.806600235722704,
      "grad_norm": 0.00020427608978934586,
      "learning_rate": 1.3591199685703063e-05,
      "loss": 0.0001,
      "step": 44860
    },
    {
      "epoch": 4.807671702560806,
      "grad_norm": 0.03472190350294113,
      "learning_rate": 1.3589771063252259e-05,
      "loss": 0.1996,
      "step": 44870
    },
    {
      "epoch": 4.808743169398907,
      "grad_norm": 0.00015454154345206916,
      "learning_rate": 1.3588342440801458e-05,
      "loss": 0.0004,
      "step": 44880
    },
    {
      "epoch": 4.809814636237008,
      "grad_norm": 0.0002588355273474008,
      "learning_rate": 1.3586913818350656e-05,
      "loss": 0.4837,
      "step": 44890
    },
    {
      "epoch": 4.810886103075109,
      "grad_norm": 0.10254883766174316,
      "learning_rate": 1.3585485195899855e-05,
      "loss": 0.0005,
      "step": 44900
    },
    {
      "epoch": 4.811957569913211,
      "grad_norm": 0.2519635260105133,
      "learning_rate": 1.3584056573449055e-05,
      "loss": 0.0013,
      "step": 44910
    },
    {
      "epoch": 4.813029036751312,
      "grad_norm": 0.04905956983566284,
      "learning_rate": 1.358262795099825e-05,
      "loss": 0.1539,
      "step": 44920
    },
    {
      "epoch": 4.8141005035894135,
      "grad_norm": 0.01945256069302559,
      "learning_rate": 1.358119932854745e-05,
      "loss": 0.1401,
      "step": 44930
    },
    {
      "epoch": 4.8151719704275155,
      "grad_norm": 0.029987651854753494,
      "learning_rate": 1.3579770706096646e-05,
      "loss": 0.3637,
      "step": 44940
    },
    {
      "epoch": 4.816243437265617,
      "grad_norm": 0.0006133584538474679,
      "learning_rate": 1.3578342083645845e-05,
      "loss": 0.1484,
      "step": 44950
    },
    {
      "epoch": 4.817314904103718,
      "grad_norm": 0.0312199629843235,
      "learning_rate": 1.3576913461195045e-05,
      "loss": 0.0049,
      "step": 44960
    },
    {
      "epoch": 4.81838637094182,
      "grad_norm": 0.0006368089816533029,
      "learning_rate": 1.3575484838744242e-05,
      "loss": 0.001,
      "step": 44970
    },
    {
      "epoch": 4.819457837779921,
      "grad_norm": 0.0005925199366174638,
      "learning_rate": 1.3574056216293442e-05,
      "loss": 0.0005,
      "step": 44980
    },
    {
      "epoch": 4.820529304618022,
      "grad_norm": 0.00028114323504269123,
      "learning_rate": 1.3572627593842638e-05,
      "loss": 0.0011,
      "step": 44990
    },
    {
      "epoch": 4.821600771456123,
      "grad_norm": 0.03434859588742256,
      "learning_rate": 1.3571198971391837e-05,
      "loss": 0.3128,
      "step": 45000
    },
    {
      "epoch": 4.822672238294225,
      "grad_norm": 0.00032466594711877406,
      "learning_rate": 1.3569770348941033e-05,
      "loss": 0.3956,
      "step": 45010
    },
    {
      "epoch": 4.823743705132326,
      "grad_norm": 0.1999179720878601,
      "learning_rate": 1.3568341726490232e-05,
      "loss": 0.1873,
      "step": 45020
    },
    {
      "epoch": 4.824815171970427,
      "grad_norm": 0.00041213573422282934,
      "learning_rate": 1.3566913104039432e-05,
      "loss": 0.0001,
      "step": 45030
    },
    {
      "epoch": 4.825886638808528,
      "grad_norm": 30.772153854370117,
      "learning_rate": 1.356548448158863e-05,
      "loss": 0.1525,
      "step": 45040
    },
    {
      "epoch": 4.82695810564663,
      "grad_norm": 0.0005721413181163371,
      "learning_rate": 1.3564055859137829e-05,
      "loss": 0.1692,
      "step": 45050
    },
    {
      "epoch": 4.8280295724847315,
      "grad_norm": 0.0779193714261055,
      "learning_rate": 1.3562627236687025e-05,
      "loss": 0.1677,
      "step": 45060
    },
    {
      "epoch": 4.829101039322833,
      "grad_norm": 0.0003446810587774962,
      "learning_rate": 1.3561198614236224e-05,
      "loss": 0.0006,
      "step": 45070
    },
    {
      "epoch": 4.830172506160935,
      "grad_norm": 0.057432033121585846,
      "learning_rate": 1.3559769991785423e-05,
      "loss": 0.1921,
      "step": 45080
    },
    {
      "epoch": 4.831243972999036,
      "grad_norm": 0.013016046956181526,
      "learning_rate": 1.355834136933462e-05,
      "loss": 0.0004,
      "step": 45090
    },
    {
      "epoch": 4.832315439837137,
      "grad_norm": 0.03254504129290581,
      "learning_rate": 1.3556912746883819e-05,
      "loss": 0.0663,
      "step": 45100
    },
    {
      "epoch": 4.833386906675239,
      "grad_norm": 0.00021530762023758143,
      "learning_rate": 1.3555484124433016e-05,
      "loss": 0.1079,
      "step": 45110
    },
    {
      "epoch": 4.83445837351334,
      "grad_norm": 0.17080773413181305,
      "learning_rate": 1.3554055501982216e-05,
      "loss": 0.0212,
      "step": 45120
    },
    {
      "epoch": 4.835529840351441,
      "grad_norm": 0.00023678278375882655,
      "learning_rate": 1.3552626879531412e-05,
      "loss": 0.0004,
      "step": 45130
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.0002713901048991829,
      "learning_rate": 1.3551198257080611e-05,
      "loss": 0.1494,
      "step": 45140
    },
    {
      "epoch": 4.837672774027644,
      "grad_norm": 0.00024859028053469956,
      "learning_rate": 1.354976963462981e-05,
      "loss": 0.181,
      "step": 45150
    },
    {
      "epoch": 4.838744240865745,
      "grad_norm": 0.026572084054350853,
      "learning_rate": 1.3548341012179007e-05,
      "loss": 0.1074,
      "step": 45160
    },
    {
      "epoch": 4.839815707703846,
      "grad_norm": 0.006309610791504383,
      "learning_rate": 1.3546912389728206e-05,
      "loss": 0.0003,
      "step": 45170
    },
    {
      "epoch": 4.8408871745419475,
      "grad_norm": 0.013397861272096634,
      "learning_rate": 1.3545483767277404e-05,
      "loss": 0.0002,
      "step": 45180
    },
    {
      "epoch": 4.8419586413800495,
      "grad_norm": 27.96811866760254,
      "learning_rate": 1.3544055144826603e-05,
      "loss": 0.1373,
      "step": 45190
    },
    {
      "epoch": 4.843030108218151,
      "grad_norm": 0.008112223818898201,
      "learning_rate": 1.35426265223758e-05,
      "loss": 0.0445,
      "step": 45200
    },
    {
      "epoch": 4.844101575056252,
      "grad_norm": 0.009366655722260475,
      "learning_rate": 1.3541197899924998e-05,
      "loss": 0.0094,
      "step": 45210
    },
    {
      "epoch": 4.845173041894354,
      "grad_norm": 0.015817783772945404,
      "learning_rate": 1.3539769277474198e-05,
      "loss": 0.0001,
      "step": 45220
    },
    {
      "epoch": 4.846244508732455,
      "grad_norm": 0.00013082768418826163,
      "learning_rate": 1.3538340655023394e-05,
      "loss": 0.1502,
      "step": 45230
    },
    {
      "epoch": 4.847315975570556,
      "grad_norm": 0.3944586515426636,
      "learning_rate": 1.3536912032572593e-05,
      "loss": 0.0009,
      "step": 45240
    },
    {
      "epoch": 4.848387442408658,
      "grad_norm": 0.0076776472851634026,
      "learning_rate": 1.353548341012179e-05,
      "loss": 0.15,
      "step": 45250
    },
    {
      "epoch": 4.849458909246759,
      "grad_norm": 0.7630401253700256,
      "learning_rate": 1.353405478767099e-05,
      "loss": 0.3581,
      "step": 45260
    },
    {
      "epoch": 4.85053037608486,
      "grad_norm": 0.0016325033502653241,
      "learning_rate": 1.3532626165220188e-05,
      "loss": 0.0002,
      "step": 45270
    },
    {
      "epoch": 4.851601842922961,
      "grad_norm": 0.2269495576620102,
      "learning_rate": 1.3531197542769385e-05,
      "loss": 0.1156,
      "step": 45280
    },
    {
      "epoch": 4.852673309761063,
      "grad_norm": 147.82595825195312,
      "learning_rate": 1.3529768920318585e-05,
      "loss": 0.0125,
      "step": 45290
    },
    {
      "epoch": 4.853744776599164,
      "grad_norm": 0.013002841733396053,
      "learning_rate": 1.352834029786778e-05,
      "loss": 0.1351,
      "step": 45300
    },
    {
      "epoch": 4.8548162434372655,
      "grad_norm": 0.006085362285375595,
      "learning_rate": 1.352691167541698e-05,
      "loss": 0.0001,
      "step": 45310
    },
    {
      "epoch": 4.855887710275367,
      "grad_norm": 0.7720076441764832,
      "learning_rate": 1.3525483052966178e-05,
      "loss": 0.0018,
      "step": 45320
    },
    {
      "epoch": 4.856959177113469,
      "grad_norm": 0.00556439533829689,
      "learning_rate": 1.3524054430515377e-05,
      "loss": 0.0004,
      "step": 45330
    },
    {
      "epoch": 4.85803064395157,
      "grad_norm": 0.00010249581100651994,
      "learning_rate": 1.3522625808064575e-05,
      "loss": 0.0009,
      "step": 45340
    },
    {
      "epoch": 4.859102110789671,
      "grad_norm": 0.08323121070861816,
      "learning_rate": 1.3521197185613772e-05,
      "loss": 0.0002,
      "step": 45350
    },
    {
      "epoch": 4.860173577627773,
      "grad_norm": 0.05404654145240784,
      "learning_rate": 1.3519768563162972e-05,
      "loss": 0.2596,
      "step": 45360
    },
    {
      "epoch": 4.861245044465874,
      "grad_norm": 0.0077437907457351685,
      "learning_rate": 1.3518339940712168e-05,
      "loss": 0.1404,
      "step": 45370
    },
    {
      "epoch": 4.862316511303975,
      "grad_norm": 0.00012230098946020007,
      "learning_rate": 1.3516911318261367e-05,
      "loss": 0.0002,
      "step": 45380
    },
    {
      "epoch": 4.863387978142076,
      "grad_norm": 45.45369338989258,
      "learning_rate": 1.3515482695810567e-05,
      "loss": 0.1698,
      "step": 45390
    },
    {
      "epoch": 4.864459444980178,
      "grad_norm": 23.09563636779785,
      "learning_rate": 1.3514054073359764e-05,
      "loss": 0.1483,
      "step": 45400
    },
    {
      "epoch": 4.865530911818279,
      "grad_norm": 0.28466442227363586,
      "learning_rate": 1.3512625450908964e-05,
      "loss": 0.0002,
      "step": 45410
    },
    {
      "epoch": 4.86660237865638,
      "grad_norm": 0.036850035190582275,
      "learning_rate": 1.351119682845816e-05,
      "loss": 0.0002,
      "step": 45420
    },
    {
      "epoch": 4.8676738454944815,
      "grad_norm": 0.00023250485537573695,
      "learning_rate": 1.3509768206007359e-05,
      "loss": 0.3992,
      "step": 45430
    },
    {
      "epoch": 4.8687453123325835,
      "grad_norm": 0.007930953055620193,
      "learning_rate": 1.3508339583556555e-05,
      "loss": 0.3181,
      "step": 45440
    },
    {
      "epoch": 4.869816779170685,
      "grad_norm": 0.005717793945223093,
      "learning_rate": 1.3506910961105754e-05,
      "loss": 0.0006,
      "step": 45450
    },
    {
      "epoch": 4.870888246008786,
      "grad_norm": 0.0010153393959626555,
      "learning_rate": 1.3505482338654954e-05,
      "loss": 0.5087,
      "step": 45460
    },
    {
      "epoch": 4.871959712846888,
      "grad_norm": 0.0013352856040000916,
      "learning_rate": 1.3504053716204151e-05,
      "loss": 0.0001,
      "step": 45470
    },
    {
      "epoch": 4.873031179684989,
      "grad_norm": 0.0012881457805633545,
      "learning_rate": 1.350262509375335e-05,
      "loss": 0.0004,
      "step": 45480
    },
    {
      "epoch": 4.87410264652309,
      "grad_norm": 0.016386309638619423,
      "learning_rate": 1.3501196471302547e-05,
      "loss": 0.0004,
      "step": 45490
    },
    {
      "epoch": 4.875174113361192,
      "grad_norm": 0.0010756728006526828,
      "learning_rate": 1.3499767848851746e-05,
      "loss": 0.0004,
      "step": 45500
    },
    {
      "epoch": 4.876245580199293,
      "grad_norm": 0.0005985546158626676,
      "learning_rate": 1.3498339226400945e-05,
      "loss": 0.139,
      "step": 45510
    },
    {
      "epoch": 4.877317047037394,
      "grad_norm": 0.007433305960148573,
      "learning_rate": 1.3496910603950141e-05,
      "loss": 0.1765,
      "step": 45520
    },
    {
      "epoch": 4.878388513875495,
      "grad_norm": 0.07679648697376251,
      "learning_rate": 1.349548198149934e-05,
      "loss": 0.2761,
      "step": 45530
    },
    {
      "epoch": 4.879459980713597,
      "grad_norm": 0.0011331255082041025,
      "learning_rate": 1.3494053359048538e-05,
      "loss": 0.2226,
      "step": 45540
    },
    {
      "epoch": 4.880531447551698,
      "grad_norm": 0.000791488098911941,
      "learning_rate": 1.3492624736597738e-05,
      "loss": 0.2061,
      "step": 45550
    },
    {
      "epoch": 4.881602914389799,
      "grad_norm": 0.012517611496150494,
      "learning_rate": 1.3491196114146934e-05,
      "loss": 0.329,
      "step": 45560
    },
    {
      "epoch": 4.8826743812279005,
      "grad_norm": 1.3437869548797607,
      "learning_rate": 1.3489767491696133e-05,
      "loss": 0.0051,
      "step": 45570
    },
    {
      "epoch": 4.8837458480660025,
      "grad_norm": 0.002764016157016158,
      "learning_rate": 1.3488338869245332e-05,
      "loss": 0.0002,
      "step": 45580
    },
    {
      "epoch": 4.884817314904104,
      "grad_norm": 0.06204445660114288,
      "learning_rate": 1.3486910246794528e-05,
      "loss": 0.0025,
      "step": 45590
    },
    {
      "epoch": 4.885888781742205,
      "grad_norm": 0.002509085228666663,
      "learning_rate": 1.3485481624343728e-05,
      "loss": 0.0005,
      "step": 45600
    },
    {
      "epoch": 4.886960248580307,
      "grad_norm": 0.03282421827316284,
      "learning_rate": 1.3484053001892925e-05,
      "loss": 0.062,
      "step": 45610
    },
    {
      "epoch": 4.888031715418408,
      "grad_norm": 0.13729150593280792,
      "learning_rate": 1.3482624379442125e-05,
      "loss": 0.1987,
      "step": 45620
    },
    {
      "epoch": 4.889103182256509,
      "grad_norm": 0.0006453142850659788,
      "learning_rate": 1.3481195756991323e-05,
      "loss": 0.2466,
      "step": 45630
    },
    {
      "epoch": 4.890174649094611,
      "grad_norm": 0.059763774275779724,
      "learning_rate": 1.347976713454052e-05,
      "loss": 0.3387,
      "step": 45640
    },
    {
      "epoch": 4.891246115932712,
      "grad_norm": 0.0005808132118545473,
      "learning_rate": 1.347833851208972e-05,
      "loss": 0.0004,
      "step": 45650
    },
    {
      "epoch": 4.892317582770813,
      "grad_norm": 0.055635128170251846,
      "learning_rate": 1.3476909889638916e-05,
      "loss": 0.0006,
      "step": 45660
    },
    {
      "epoch": 4.893389049608914,
      "grad_norm": 0.0011418663198128343,
      "learning_rate": 1.3475481267188115e-05,
      "loss": 0.1617,
      "step": 45670
    },
    {
      "epoch": 4.894460516447016,
      "grad_norm": 0.0005418191431090236,
      "learning_rate": 1.3474052644737313e-05,
      "loss": 0.2638,
      "step": 45680
    },
    {
      "epoch": 4.895531983285117,
      "grad_norm": 0.0013978893402963877,
      "learning_rate": 1.3472624022286512e-05,
      "loss": 0.2054,
      "step": 45690
    },
    {
      "epoch": 4.8966034501232185,
      "grad_norm": 0.029216405004262924,
      "learning_rate": 1.347119539983571e-05,
      "loss": 0.2763,
      "step": 45700
    },
    {
      "epoch": 4.89767491696132,
      "grad_norm": 0.004830014891922474,
      "learning_rate": 1.3469766777384907e-05,
      "loss": 0.0017,
      "step": 45710
    },
    {
      "epoch": 4.898746383799422,
      "grad_norm": 0.7483283877372742,
      "learning_rate": 1.3468338154934107e-05,
      "loss": 0.0143,
      "step": 45720
    },
    {
      "epoch": 4.899817850637523,
      "grad_norm": 0.01793830282986164,
      "learning_rate": 1.3466909532483303e-05,
      "loss": 0.0009,
      "step": 45730
    },
    {
      "epoch": 4.900889317475624,
      "grad_norm": 0.017962437123060226,
      "learning_rate": 1.3465480910032502e-05,
      "loss": 0.2925,
      "step": 45740
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 0.2607785165309906,
      "learning_rate": 1.3464052287581701e-05,
      "loss": 0.022,
      "step": 45750
    },
    {
      "epoch": 4.903032251151827,
      "grad_norm": 0.0014222902245819569,
      "learning_rate": 1.3462623665130899e-05,
      "loss": 0.3743,
      "step": 45760
    },
    {
      "epoch": 4.904103717989928,
      "grad_norm": 0.007089579943567514,
      "learning_rate": 1.3461195042680097e-05,
      "loss": 0.0003,
      "step": 45770
    },
    {
      "epoch": 4.90517518482803,
      "grad_norm": 0.047381337732076645,
      "learning_rate": 1.3459766420229294e-05,
      "loss": 0.2849,
      "step": 45780
    },
    {
      "epoch": 4.906246651666131,
      "grad_norm": 0.006744015030562878,
      "learning_rate": 1.3458337797778494e-05,
      "loss": 0.3867,
      "step": 45790
    },
    {
      "epoch": 4.907318118504232,
      "grad_norm": 9.63050651550293,
      "learning_rate": 1.345690917532769e-05,
      "loss": 0.0009,
      "step": 45800
    },
    {
      "epoch": 4.908389585342333,
      "grad_norm": 0.001929241931065917,
      "learning_rate": 1.3455480552876889e-05,
      "loss": 0.2783,
      "step": 45810
    },
    {
      "epoch": 4.909461052180435,
      "grad_norm": 0.013962254859507084,
      "learning_rate": 1.3454051930426088e-05,
      "loss": 0.0009,
      "step": 45820
    },
    {
      "epoch": 4.9105325190185365,
      "grad_norm": 0.07249182462692261,
      "learning_rate": 1.3452623307975286e-05,
      "loss": 0.2865,
      "step": 45830
    },
    {
      "epoch": 4.911603985856638,
      "grad_norm": 0.025045733898878098,
      "learning_rate": 1.3451194685524484e-05,
      "loss": 0.001,
      "step": 45840
    },
    {
      "epoch": 4.912675452694739,
      "grad_norm": 0.02865396998822689,
      "learning_rate": 1.3449766063073681e-05,
      "loss": 0.001,
      "step": 45850
    },
    {
      "epoch": 4.913746919532841,
      "grad_norm": 33.627967834472656,
      "learning_rate": 1.344833744062288e-05,
      "loss": 0.0027,
      "step": 45860
    },
    {
      "epoch": 4.914818386370942,
      "grad_norm": 0.003450552700087428,
      "learning_rate": 1.344690881817208e-05,
      "loss": 0.0504,
      "step": 45870
    },
    {
      "epoch": 4.915889853209043,
      "grad_norm": 0.10596010088920593,
      "learning_rate": 1.3445480195721276e-05,
      "loss": 0.0003,
      "step": 45880
    },
    {
      "epoch": 4.916961320047145,
      "grad_norm": 0.001031531486660242,
      "learning_rate": 1.3444051573270476e-05,
      "loss": 0.0005,
      "step": 45890
    },
    {
      "epoch": 4.918032786885246,
      "grad_norm": 0.002843540394678712,
      "learning_rate": 1.3442622950819673e-05,
      "loss": 0.0002,
      "step": 45900
    },
    {
      "epoch": 4.919104253723347,
      "grad_norm": 0.11330215632915497,
      "learning_rate": 1.3441194328368871e-05,
      "loss": 0.0004,
      "step": 45910
    },
    {
      "epoch": 4.920175720561448,
      "grad_norm": 0.040589042007923126,
      "learning_rate": 1.3439765705918069e-05,
      "loss": 0.0007,
      "step": 45920
    },
    {
      "epoch": 4.92124718739955,
      "grad_norm": 0.059212494641542435,
      "learning_rate": 1.3438337083467268e-05,
      "loss": 0.0003,
      "step": 45930
    },
    {
      "epoch": 4.922318654237651,
      "grad_norm": 0.001371129765175283,
      "learning_rate": 1.3436908461016467e-05,
      "loss": 0.1635,
      "step": 45940
    },
    {
      "epoch": 4.9233901210757525,
      "grad_norm": 0.004704748280346394,
      "learning_rate": 1.3435479838565663e-05,
      "loss": 0.0,
      "step": 45950
    },
    {
      "epoch": 4.924461587913854,
      "grad_norm": 0.012915010564029217,
      "learning_rate": 1.3434051216114863e-05,
      "loss": 0.1467,
      "step": 45960
    },
    {
      "epoch": 4.925533054751956,
      "grad_norm": 0.005384668707847595,
      "learning_rate": 1.343262259366406e-05,
      "loss": 0.3284,
      "step": 45970
    },
    {
      "epoch": 4.926604521590057,
      "grad_norm": 0.00044766475912183523,
      "learning_rate": 1.343119397121326e-05,
      "loss": 0.3191,
      "step": 45980
    },
    {
      "epoch": 4.927675988428158,
      "grad_norm": 0.0021273924503475428,
      "learning_rate": 1.3429765348762457e-05,
      "loss": 0.0005,
      "step": 45990
    },
    {
      "epoch": 4.92874745526626,
      "grad_norm": 0.023586884140968323,
      "learning_rate": 1.3428336726311655e-05,
      "loss": 0.0005,
      "step": 46000
    },
    {
      "epoch": 4.929818922104361,
      "grad_norm": 0.02929365448653698,
      "learning_rate": 1.3426908103860854e-05,
      "loss": 0.0002,
      "step": 46010
    },
    {
      "epoch": 4.930890388942462,
      "grad_norm": 0.390001118183136,
      "learning_rate": 1.342547948141005e-05,
      "loss": 0.1909,
      "step": 46020
    },
    {
      "epoch": 4.931961855780564,
      "grad_norm": 0.056927502155303955,
      "learning_rate": 1.342405085895925e-05,
      "loss": 0.0004,
      "step": 46030
    },
    {
      "epoch": 4.933033322618665,
      "grad_norm": 0.005935419350862503,
      "learning_rate": 1.3422622236508447e-05,
      "loss": 0.1534,
      "step": 46040
    },
    {
      "epoch": 4.934104789456766,
      "grad_norm": 0.0012287009740248322,
      "learning_rate": 1.3421193614057647e-05,
      "loss": 0.0004,
      "step": 46050
    },
    {
      "epoch": 4.935176256294867,
      "grad_norm": 0.0009708909201435745,
      "learning_rate": 1.3419764991606844e-05,
      "loss": 0.1235,
      "step": 46060
    },
    {
      "epoch": 4.936247723132969,
      "grad_norm": 0.11695390194654465,
      "learning_rate": 1.3418336369156042e-05,
      "loss": 0.255,
      "step": 46070
    },
    {
      "epoch": 4.93731918997107,
      "grad_norm": 0.06943003833293915,
      "learning_rate": 1.3416907746705242e-05,
      "loss": 0.0009,
      "step": 46080
    },
    {
      "epoch": 4.9383906568091716,
      "grad_norm": 0.000704814912751317,
      "learning_rate": 1.3415479124254437e-05,
      "loss": 0.1992,
      "step": 46090
    },
    {
      "epoch": 4.939462123647273,
      "grad_norm": 0.0007435209699906409,
      "learning_rate": 1.3414050501803637e-05,
      "loss": 0.0002,
      "step": 46100
    },
    {
      "epoch": 4.940533590485375,
      "grad_norm": 0.03432273492217064,
      "learning_rate": 1.3412621879352836e-05,
      "loss": 0.0004,
      "step": 46110
    },
    {
      "epoch": 4.941605057323476,
      "grad_norm": 0.04536901041865349,
      "learning_rate": 1.3411193256902034e-05,
      "loss": 0.1636,
      "step": 46120
    },
    {
      "epoch": 4.942676524161577,
      "grad_norm": 0.048631370067596436,
      "learning_rate": 1.3409764634451232e-05,
      "loss": 0.001,
      "step": 46130
    },
    {
      "epoch": 4.943747990999679,
      "grad_norm": 0.0036005552392452955,
      "learning_rate": 1.340833601200043e-05,
      "loss": 0.0001,
      "step": 46140
    },
    {
      "epoch": 4.94481945783778,
      "grad_norm": 101.10152435302734,
      "learning_rate": 1.3406907389549629e-05,
      "loss": 0.1292,
      "step": 46150
    },
    {
      "epoch": 4.945890924675881,
      "grad_norm": 0.0031283823773264885,
      "learning_rate": 1.3405478767098825e-05,
      "loss": 0.1602,
      "step": 46160
    },
    {
      "epoch": 4.946962391513983,
      "grad_norm": 0.09564594179391861,
      "learning_rate": 1.3404050144648024e-05,
      "loss": 0.0005,
      "step": 46170
    },
    {
      "epoch": 4.948033858352084,
      "grad_norm": 0.010508998297154903,
      "learning_rate": 1.3402621522197223e-05,
      "loss": 0.0002,
      "step": 46180
    },
    {
      "epoch": 4.949105325190185,
      "grad_norm": 0.0005097630782984197,
      "learning_rate": 1.3401192899746421e-05,
      "loss": 0.0001,
      "step": 46190
    },
    {
      "epoch": 4.950176792028286,
      "grad_norm": 35.90179443359375,
      "learning_rate": 1.3399764277295619e-05,
      "loss": 0.0831,
      "step": 46200
    },
    {
      "epoch": 4.951248258866388,
      "grad_norm": 0.00046212709276005626,
      "learning_rate": 1.3398335654844816e-05,
      "loss": 0.0014,
      "step": 46210
    },
    {
      "epoch": 4.9523197257044895,
      "grad_norm": 0.02788708545267582,
      "learning_rate": 1.3396907032394016e-05,
      "loss": 0.2634,
      "step": 46220
    },
    {
      "epoch": 4.953391192542591,
      "grad_norm": 0.006147598382085562,
      "learning_rate": 1.3395478409943212e-05,
      "loss": 0.0065,
      "step": 46230
    },
    {
      "epoch": 4.954462659380692,
      "grad_norm": 0.0339108407497406,
      "learning_rate": 1.3394049787492411e-05,
      "loss": 0.1551,
      "step": 46240
    },
    {
      "epoch": 4.955534126218794,
      "grad_norm": 0.006664851680397987,
      "learning_rate": 1.339262116504161e-05,
      "loss": 0.2432,
      "step": 46250
    },
    {
      "epoch": 4.956605593056895,
      "grad_norm": 0.03133426979184151,
      "learning_rate": 1.3391192542590808e-05,
      "loss": 0.1375,
      "step": 46260
    },
    {
      "epoch": 4.957677059894996,
      "grad_norm": 0.01960902288556099,
      "learning_rate": 1.3389763920140006e-05,
      "loss": 0.0005,
      "step": 46270
    },
    {
      "epoch": 4.958748526733098,
      "grad_norm": 0.0400807224214077,
      "learning_rate": 1.3388335297689203e-05,
      "loss": 0.0004,
      "step": 46280
    },
    {
      "epoch": 4.959819993571199,
      "grad_norm": 0.01251971535384655,
      "learning_rate": 1.3386906675238403e-05,
      "loss": 0.1774,
      "step": 46290
    },
    {
      "epoch": 4.9608914604093,
      "grad_norm": 0.14864487946033478,
      "learning_rate": 1.3385478052787602e-05,
      "loss": 0.0011,
      "step": 46300
    },
    {
      "epoch": 4.961962927247402,
      "grad_norm": 0.0003806224267464131,
      "learning_rate": 1.3384049430336798e-05,
      "loss": 0.0009,
      "step": 46310
    },
    {
      "epoch": 4.963034394085503,
      "grad_norm": 0.0029682039748877287,
      "learning_rate": 1.3382620807885997e-05,
      "loss": 0.2258,
      "step": 46320
    },
    {
      "epoch": 4.964105860923604,
      "grad_norm": 0.000275462050922215,
      "learning_rate": 1.3381192185435195e-05,
      "loss": 0.0002,
      "step": 46330
    },
    {
      "epoch": 4.9651773277617055,
      "grad_norm": 0.011717845685780048,
      "learning_rate": 1.3379763562984393e-05,
      "loss": 0.0,
      "step": 46340
    },
    {
      "epoch": 4.9662487945998075,
      "grad_norm": 0.021230455487966537,
      "learning_rate": 1.337833494053359e-05,
      "loss": 0.2088,
      "step": 46350
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 0.04138273745775223,
      "learning_rate": 1.337690631808279e-05,
      "loss": 0.0002,
      "step": 46360
    },
    {
      "epoch": 4.96839172827601,
      "grad_norm": 0.06264825165271759,
      "learning_rate": 1.337547769563199e-05,
      "loss": 0.2569,
      "step": 46370
    },
    {
      "epoch": 4.969463195114111,
      "grad_norm": 0.0002145212347386405,
      "learning_rate": 1.3374049073181185e-05,
      "loss": 0.2146,
      "step": 46380
    },
    {
      "epoch": 4.970534661952213,
      "grad_norm": 0.0002857585495803505,
      "learning_rate": 1.3372620450730385e-05,
      "loss": 0.0002,
      "step": 46390
    },
    {
      "epoch": 4.971606128790314,
      "grad_norm": 0.03881671279668808,
      "learning_rate": 1.3371191828279582e-05,
      "loss": 0.4197,
      "step": 46400
    },
    {
      "epoch": 4.972677595628415,
      "grad_norm": 0.00016218912787735462,
      "learning_rate": 1.336976320582878e-05,
      "loss": 0.0003,
      "step": 46410
    },
    {
      "epoch": 4.973749062466517,
      "grad_norm": 0.03481052443385124,
      "learning_rate": 1.336833458337798e-05,
      "loss": 0.0005,
      "step": 46420
    },
    {
      "epoch": 4.974820529304618,
      "grad_norm": 0.06329800188541412,
      "learning_rate": 1.3366905960927177e-05,
      "loss": 0.0002,
      "step": 46430
    },
    {
      "epoch": 4.975891996142719,
      "grad_norm": 0.00020027327991556376,
      "learning_rate": 1.3365477338476376e-05,
      "loss": 0.2232,
      "step": 46440
    },
    {
      "epoch": 4.97696346298082,
      "grad_norm": 0.012965233065187931,
      "learning_rate": 1.3364048716025572e-05,
      "loss": 0.0008,
      "step": 46450
    },
    {
      "epoch": 4.978034929818922,
      "grad_norm": 0.000366605119779706,
      "learning_rate": 1.3362620093574772e-05,
      "loss": 0.1501,
      "step": 46460
    },
    {
      "epoch": 4.9791063966570235,
      "grad_norm": 0.36731645464897156,
      "learning_rate": 1.336119147112397e-05,
      "loss": 0.0008,
      "step": 46470
    },
    {
      "epoch": 4.980177863495125,
      "grad_norm": 0.020813077688217163,
      "learning_rate": 1.3359762848673167e-05,
      "loss": 0.0001,
      "step": 46480
    },
    {
      "epoch": 4.981249330333226,
      "grad_norm": 0.00025866509531624615,
      "learning_rate": 1.3358334226222366e-05,
      "loss": 0.3961,
      "step": 46490
    },
    {
      "epoch": 4.982320797171328,
      "grad_norm": 0.00048635422717779875,
      "learning_rate": 1.3356905603771564e-05,
      "loss": 0.2199,
      "step": 46500
    },
    {
      "epoch": 4.983392264009429,
      "grad_norm": 0.10794657468795776,
      "learning_rate": 1.3355476981320763e-05,
      "loss": 0.1094,
      "step": 46510
    },
    {
      "epoch": 4.98446373084753,
      "grad_norm": 0.03409910202026367,
      "learning_rate": 1.335404835886996e-05,
      "loss": 0.4654,
      "step": 46520
    },
    {
      "epoch": 4.985535197685632,
      "grad_norm": 0.03690940886735916,
      "learning_rate": 1.3352619736419159e-05,
      "loss": 0.3416,
      "step": 46530
    },
    {
      "epoch": 4.986606664523733,
      "grad_norm": 0.010252534411847591,
      "learning_rate": 1.3351191113968358e-05,
      "loss": 0.0025,
      "step": 46540
    },
    {
      "epoch": 4.987678131361834,
      "grad_norm": 0.06527381390333176,
      "learning_rate": 1.3349762491517556e-05,
      "loss": 0.001,
      "step": 46550
    },
    {
      "epoch": 4.988749598199936,
      "grad_norm": 0.011824369430541992,
      "learning_rate": 1.3348333869066753e-05,
      "loss": 0.0012,
      "step": 46560
    },
    {
      "epoch": 4.989821065038037,
      "grad_norm": 0.033505722880363464,
      "learning_rate": 1.3346905246615951e-05,
      "loss": 0.2205,
      "step": 46570
    },
    {
      "epoch": 4.990892531876138,
      "grad_norm": 0.0194197129458189,
      "learning_rate": 1.334547662416515e-05,
      "loss": 0.2371,
      "step": 46580
    },
    {
      "epoch": 4.9919639987142395,
      "grad_norm": 0.05061377212405205,
      "learning_rate": 1.3344048001714347e-05,
      "loss": 0.3751,
      "step": 46590
    },
    {
      "epoch": 4.9930354655523415,
      "grad_norm": 0.035080309957265854,
      "learning_rate": 1.3342619379263546e-05,
      "loss": 0.0008,
      "step": 46600
    },
    {
      "epoch": 4.994106932390443,
      "grad_norm": 0.031249357387423515,
      "learning_rate": 1.3341190756812745e-05,
      "loss": 0.0068,
      "step": 46610
    },
    {
      "epoch": 4.995178399228544,
      "grad_norm": 0.014817585237324238,
      "learning_rate": 1.3339762134361943e-05,
      "loss": 0.1681,
      "step": 46620
    },
    {
      "epoch": 4.996249866066645,
      "grad_norm": 0.016381865367293358,
      "learning_rate": 1.333833351191114e-05,
      "loss": 0.0004,
      "step": 46630
    },
    {
      "epoch": 4.997321332904747,
      "grad_norm": 0.028644299134612083,
      "learning_rate": 1.3336904889460338e-05,
      "loss": 0.0004,
      "step": 46640
    },
    {
      "epoch": 4.998392799742848,
      "grad_norm": 0.028708070516586304,
      "learning_rate": 1.3335476267009538e-05,
      "loss": 0.0006,
      "step": 46650
    },
    {
      "epoch": 4.999464266580949,
      "grad_norm": 0.05722154304385185,
      "learning_rate": 1.3334047644558737e-05,
      "loss": 0.0002,
      "step": 46660
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9683333333333334,
      "eval_f1": 0.8756544502617802,
      "eval_loss": 0.19259876012802124,
      "eval_precision": 0.867704280155642,
      "eval_recall": 0.8837516512549538,
      "eval_runtime": 395.0847,
      "eval_samples_per_second": 15.187,
      "eval_steps_per_second": 5.062,
      "step": 46665
    },
    {
      "epoch": 5.000535733419051,
      "grad_norm": 0.02461397275328636,
      "learning_rate": 1.3332619022107933e-05,
      "loss": 0.0003,
      "step": 46670
    },
    {
      "epoch": 5.001607200257152,
      "grad_norm": 0.0035298061557114124,
      "learning_rate": 1.3331190399657132e-05,
      "loss": 0.0005,
      "step": 46680
    },
    {
      "epoch": 5.002678667095253,
      "grad_norm": 0.0044723800383508205,
      "learning_rate": 1.332976177720633e-05,
      "loss": 0.0001,
      "step": 46690
    },
    {
      "epoch": 5.003750133933354,
      "grad_norm": 0.01128707267343998,
      "learning_rate": 1.3328333154755528e-05,
      "loss": 0.0002,
      "step": 46700
    },
    {
      "epoch": 5.004821600771456,
      "grad_norm": 0.004265132825821638,
      "learning_rate": 1.3326904532304725e-05,
      "loss": 0.0004,
      "step": 46710
    },
    {
      "epoch": 5.005893067609557,
      "grad_norm": 0.012689877301454544,
      "learning_rate": 1.3325475909853925e-05,
      "loss": 0.1304,
      "step": 46720
    },
    {
      "epoch": 5.0069645344476585,
      "grad_norm": 0.03331669792532921,
      "learning_rate": 1.3324047287403124e-05,
      "loss": 0.0008,
      "step": 46730
    },
    {
      "epoch": 5.0080360012857605,
      "grad_norm": 0.006560280453413725,
      "learning_rate": 1.332261866495232e-05,
      "loss": 0.0001,
      "step": 46740
    },
    {
      "epoch": 5.009107468123862,
      "grad_norm": 0.0026908819563686848,
      "learning_rate": 1.332119004250152e-05,
      "loss": 0.1604,
      "step": 46750
    },
    {
      "epoch": 5.010178934961963,
      "grad_norm": 0.0032666949555277824,
      "learning_rate": 1.3319761420050717e-05,
      "loss": 0.1918,
      "step": 46760
    },
    {
      "epoch": 5.011250401800064,
      "grad_norm": 0.000929162953980267,
      "learning_rate": 1.3318332797599915e-05,
      "loss": 0.0006,
      "step": 46770
    },
    {
      "epoch": 5.012321868638166,
      "grad_norm": 0.006682307459414005,
      "learning_rate": 1.3316904175149114e-05,
      "loss": 0.1378,
      "step": 46780
    },
    {
      "epoch": 5.013393335476267,
      "grad_norm": 0.0006477535353042185,
      "learning_rate": 1.3315475552698312e-05,
      "loss": 0.0002,
      "step": 46790
    },
    {
      "epoch": 5.014464802314368,
      "grad_norm": 0.0039749532006680965,
      "learning_rate": 1.3314046930247511e-05,
      "loss": 0.0006,
      "step": 46800
    },
    {
      "epoch": 5.01553626915247,
      "grad_norm": 0.015114742331206799,
      "learning_rate": 1.3312618307796707e-05,
      "loss": 0.1863,
      "step": 46810
    },
    {
      "epoch": 5.016607735990571,
      "grad_norm": 0.0005794494645670056,
      "learning_rate": 1.3311189685345907e-05,
      "loss": 0.0,
      "step": 46820
    },
    {
      "epoch": 5.017679202828672,
      "grad_norm": 0.0011756879976019263,
      "learning_rate": 1.3309761062895104e-05,
      "loss": 0.3207,
      "step": 46830
    },
    {
      "epoch": 5.018750669666773,
      "grad_norm": 0.00036377928336150944,
      "learning_rate": 1.3308332440444302e-05,
      "loss": 0.3754,
      "step": 46840
    },
    {
      "epoch": 5.019822136504875,
      "grad_norm": 0.0006232471205294132,
      "learning_rate": 1.3306903817993501e-05,
      "loss": 0.0003,
      "step": 46850
    },
    {
      "epoch": 5.0208936033429765,
      "grad_norm": 0.0004384605272207409,
      "learning_rate": 1.3305475195542699e-05,
      "loss": 0.226,
      "step": 46860
    },
    {
      "epoch": 5.021965070181078,
      "grad_norm": 0.0053317612037062645,
      "learning_rate": 1.3304046573091898e-05,
      "loss": 0.2363,
      "step": 46870
    },
    {
      "epoch": 5.02303653701918,
      "grad_norm": 0.011623851023614407,
      "learning_rate": 1.3302617950641094e-05,
      "loss": 0.1334,
      "step": 46880
    },
    {
      "epoch": 5.024108003857281,
      "grad_norm": 0.014510472305119038,
      "learning_rate": 1.3301189328190294e-05,
      "loss": 0.1915,
      "step": 46890
    },
    {
      "epoch": 5.025179470695382,
      "grad_norm": 2.2451775074005127,
      "learning_rate": 1.3299760705739493e-05,
      "loss": 0.0015,
      "step": 46900
    },
    {
      "epoch": 5.026250937533483,
      "grad_norm": 0.020189426839351654,
      "learning_rate": 1.3298332083288689e-05,
      "loss": 0.0016,
      "step": 46910
    },
    {
      "epoch": 5.027322404371585,
      "grad_norm": 0.00393267534673214,
      "learning_rate": 1.3296903460837888e-05,
      "loss": 0.0005,
      "step": 46920
    },
    {
      "epoch": 5.028393871209686,
      "grad_norm": 0.0009435489773750305,
      "learning_rate": 1.3295474838387086e-05,
      "loss": 0.1511,
      "step": 46930
    },
    {
      "epoch": 5.029465338047787,
      "grad_norm": 0.009974789805710316,
      "learning_rate": 1.3294046215936285e-05,
      "loss": 0.1662,
      "step": 46940
    },
    {
      "epoch": 5.030536804885889,
      "grad_norm": 0.0008514223154634237,
      "learning_rate": 1.3292617593485481e-05,
      "loss": 0.2013,
      "step": 46950
    },
    {
      "epoch": 5.03160827172399,
      "grad_norm": 0.018920695409178734,
      "learning_rate": 1.329118897103468e-05,
      "loss": 0.0028,
      "step": 46960
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 0.015882128849625587,
      "learning_rate": 1.328976034858388e-05,
      "loss": 0.2007,
      "step": 46970
    },
    {
      "epoch": 5.0337512054001925,
      "grad_norm": 0.0012933241669088602,
      "learning_rate": 1.3288331726133076e-05,
      "loss": 0.0003,
      "step": 46980
    },
    {
      "epoch": 5.0348226722382945,
      "grad_norm": 141.50210571289062,
      "learning_rate": 1.3286903103682275e-05,
      "loss": 0.0305,
      "step": 46990
    },
    {
      "epoch": 5.035894139076396,
      "grad_norm": 0.02490469068288803,
      "learning_rate": 1.3285474481231473e-05,
      "loss": 0.0872,
      "step": 47000
    },
    {
      "epoch": 5.036965605914497,
      "grad_norm": 0.0005297788302414119,
      "learning_rate": 1.3284045858780672e-05,
      "loss": 0.2249,
      "step": 47010
    },
    {
      "epoch": 5.038037072752599,
      "grad_norm": 0.0006630247225984931,
      "learning_rate": 1.3282617236329872e-05,
      "loss": 0.0004,
      "step": 47020
    },
    {
      "epoch": 5.0391085395907,
      "grad_norm": 0.0006551026017405093,
      "learning_rate": 1.3281188613879068e-05,
      "loss": 0.0004,
      "step": 47030
    },
    {
      "epoch": 5.040180006428801,
      "grad_norm": 0.006592554040253162,
      "learning_rate": 1.3279759991428267e-05,
      "loss": 0.1595,
      "step": 47040
    },
    {
      "epoch": 5.041251473266902,
      "grad_norm": 0.000544494076166302,
      "learning_rate": 1.3278331368977463e-05,
      "loss": 0.0006,
      "step": 47050
    },
    {
      "epoch": 5.042322940105004,
      "grad_norm": 0.028278611600399017,
      "learning_rate": 1.3276902746526663e-05,
      "loss": 0.0013,
      "step": 47060
    },
    {
      "epoch": 5.043394406943105,
      "grad_norm": 0.000724594749044627,
      "learning_rate": 1.327547412407586e-05,
      "loss": 0.1841,
      "step": 47070
    },
    {
      "epoch": 5.044465873781206,
      "grad_norm": 0.014929227530956268,
      "learning_rate": 1.327404550162506e-05,
      "loss": 0.0002,
      "step": 47080
    },
    {
      "epoch": 5.045537340619308,
      "grad_norm": 0.023556111380457878,
      "learning_rate": 1.3272616879174259e-05,
      "loss": 0.0004,
      "step": 47090
    },
    {
      "epoch": 5.046608807457409,
      "grad_norm": 0.024570468813180923,
      "learning_rate": 1.3271188256723455e-05,
      "loss": 0.1622,
      "step": 47100
    },
    {
      "epoch": 5.0476802742955105,
      "grad_norm": 0.0005616956623271108,
      "learning_rate": 1.3269759634272654e-05,
      "loss": 0.0001,
      "step": 47110
    },
    {
      "epoch": 5.048751741133612,
      "grad_norm": 0.007019552402198315,
      "learning_rate": 1.3268331011821852e-05,
      "loss": 0.1983,
      "step": 47120
    },
    {
      "epoch": 5.049823207971714,
      "grad_norm": 0.0067689623683691025,
      "learning_rate": 1.326690238937105e-05,
      "loss": 0.0001,
      "step": 47130
    },
    {
      "epoch": 5.050894674809815,
      "grad_norm": 0.0008145982283167541,
      "learning_rate": 1.3265473766920247e-05,
      "loss": 0.1557,
      "step": 47140
    },
    {
      "epoch": 5.051966141647916,
      "grad_norm": 0.0006889951764605939,
      "learning_rate": 1.3264045144469447e-05,
      "loss": 0.0001,
      "step": 47150
    },
    {
      "epoch": 5.053037608486018,
      "grad_norm": 0.08340911567211151,
      "learning_rate": 1.3262616522018646e-05,
      "loss": 0.0853,
      "step": 47160
    },
    {
      "epoch": 5.054109075324119,
      "grad_norm": 0.00578073738142848,
      "learning_rate": 1.3261187899567842e-05,
      "loss": 0.0857,
      "step": 47170
    },
    {
      "epoch": 5.05518054216222,
      "grad_norm": 0.0005598283605650067,
      "learning_rate": 1.3259759277117041e-05,
      "loss": 0.0001,
      "step": 47180
    },
    {
      "epoch": 5.056252009000321,
      "grad_norm": 0.3081943988800049,
      "learning_rate": 1.3258330654666239e-05,
      "loss": 0.1452,
      "step": 47190
    },
    {
      "epoch": 5.057323475838423,
      "grad_norm": 0.0007688294863328338,
      "learning_rate": 1.3256902032215437e-05,
      "loss": 0.1507,
      "step": 47200
    },
    {
      "epoch": 5.058394942676524,
      "grad_norm": 0.09200943261384964,
      "learning_rate": 1.3255473409764636e-05,
      "loss": 0.2359,
      "step": 47210
    },
    {
      "epoch": 5.059466409514625,
      "grad_norm": 0.0014843986136838794,
      "learning_rate": 1.3254044787313834e-05,
      "loss": 0.2035,
      "step": 47220
    },
    {
      "epoch": 5.0605378763527264,
      "grad_norm": 0.003182596992701292,
      "learning_rate": 1.3252616164863033e-05,
      "loss": 0.001,
      "step": 47230
    },
    {
      "epoch": 5.0616093431908284,
      "grad_norm": 0.03377343714237213,
      "learning_rate": 1.3251187542412229e-05,
      "loss": 0.0732,
      "step": 47240
    },
    {
      "epoch": 5.06268081002893,
      "grad_norm": 0.10406583547592163,
      "learning_rate": 1.3249758919961428e-05,
      "loss": 0.1469,
      "step": 47250
    },
    {
      "epoch": 5.063752276867031,
      "grad_norm": 0.006155342794954777,
      "learning_rate": 1.3248330297510626e-05,
      "loss": 0.0013,
      "step": 47260
    },
    {
      "epoch": 5.064823743705133,
      "grad_norm": 0.01606575772166252,
      "learning_rate": 1.3246901675059824e-05,
      "loss": 0.0001,
      "step": 47270
    },
    {
      "epoch": 5.065895210543234,
      "grad_norm": 0.07571811228990555,
      "learning_rate": 1.3245473052609023e-05,
      "loss": 0.0007,
      "step": 47280
    },
    {
      "epoch": 5.066966677381335,
      "grad_norm": 0.17602455615997314,
      "learning_rate": 1.3244044430158221e-05,
      "loss": 0.0005,
      "step": 47290
    },
    {
      "epoch": 5.068038144219436,
      "grad_norm": 0.00021399390243459493,
      "learning_rate": 1.324261580770742e-05,
      "loss": 0.001,
      "step": 47300
    },
    {
      "epoch": 5.069109611057538,
      "grad_norm": 142.31365966796875,
      "learning_rate": 1.3241187185256616e-05,
      "loss": 0.1011,
      "step": 47310
    },
    {
      "epoch": 5.070181077895639,
      "grad_norm": 0.10417897254228592,
      "learning_rate": 1.3239758562805816e-05,
      "loss": 0.006,
      "step": 47320
    },
    {
      "epoch": 5.07125254473374,
      "grad_norm": 0.010968189686536789,
      "learning_rate": 1.3238329940355015e-05,
      "loss": 0.0031,
      "step": 47330
    },
    {
      "epoch": 5.072324011571842,
      "grad_norm": 0.0005715975421480834,
      "learning_rate": 1.3236901317904211e-05,
      "loss": 0.0003,
      "step": 47340
    },
    {
      "epoch": 5.073395478409943,
      "grad_norm": 0.0003655643085949123,
      "learning_rate": 1.323547269545341e-05,
      "loss": 0.192,
      "step": 47350
    },
    {
      "epoch": 5.074466945248044,
      "grad_norm": 0.007037127856165171,
      "learning_rate": 1.3234044073002608e-05,
      "loss": 0.0004,
      "step": 47360
    },
    {
      "epoch": 5.0755384120861455,
      "grad_norm": 0.00027332830359227955,
      "learning_rate": 1.3232615450551807e-05,
      "loss": 0.0003,
      "step": 47370
    },
    {
      "epoch": 5.0766098789242475,
      "grad_norm": 376.2304382324219,
      "learning_rate": 1.3231186828101003e-05,
      "loss": 0.0964,
      "step": 47380
    },
    {
      "epoch": 5.077681345762349,
      "grad_norm": 0.0020852203015238047,
      "learning_rate": 1.3229758205650203e-05,
      "loss": 0.1472,
      "step": 47390
    },
    {
      "epoch": 5.07875281260045,
      "grad_norm": 0.005940903443843126,
      "learning_rate": 1.3228329583199402e-05,
      "loss": 0.0,
      "step": 47400
    },
    {
      "epoch": 5.079824279438552,
      "grad_norm": 0.003981274552643299,
      "learning_rate": 1.3226900960748598e-05,
      "loss": 0.3327,
      "step": 47410
    },
    {
      "epoch": 5.080895746276653,
      "grad_norm": 0.018308689817786217,
      "learning_rate": 1.3225472338297797e-05,
      "loss": 0.06,
      "step": 47420
    },
    {
      "epoch": 5.081967213114754,
      "grad_norm": 3.609199285507202,
      "learning_rate": 1.3224043715846995e-05,
      "loss": 0.0069,
      "step": 47430
    },
    {
      "epoch": 5.083038679952855,
      "grad_norm": 0.00031663745176047087,
      "learning_rate": 1.3222615093396194e-05,
      "loss": 0.2147,
      "step": 47440
    },
    {
      "epoch": 5.084110146790957,
      "grad_norm": 0.0007319250144064426,
      "learning_rate": 1.3221186470945394e-05,
      "loss": 0.1485,
      "step": 47450
    },
    {
      "epoch": 5.085181613629058,
      "grad_norm": 0.004582894500344992,
      "learning_rate": 1.321975784849459e-05,
      "loss": 0.0689,
      "step": 47460
    },
    {
      "epoch": 5.086253080467159,
      "grad_norm": 0.006788498256355524,
      "learning_rate": 1.3218329226043789e-05,
      "loss": 0.0237,
      "step": 47470
    },
    {
      "epoch": 5.087324547305261,
      "grad_norm": 0.0033300272189080715,
      "learning_rate": 1.3216900603592985e-05,
      "loss": 0.0001,
      "step": 47480
    },
    {
      "epoch": 5.088396014143362,
      "grad_norm": 0.00972556322813034,
      "learning_rate": 1.3215471981142184e-05,
      "loss": 0.0015,
      "step": 47490
    },
    {
      "epoch": 5.0894674809814635,
      "grad_norm": 0.00043713059858419,
      "learning_rate": 1.3214043358691382e-05,
      "loss": 0.1589,
      "step": 47500
    },
    {
      "epoch": 5.090538947819565,
      "grad_norm": 0.0006247376441024244,
      "learning_rate": 1.3212614736240582e-05,
      "loss": 0.0002,
      "step": 47510
    },
    {
      "epoch": 5.091610414657667,
      "grad_norm": 0.00031416374258697033,
      "learning_rate": 1.3211186113789781e-05,
      "loss": 0.0001,
      "step": 47520
    },
    {
      "epoch": 5.092681881495768,
      "grad_norm": 0.0005697951419278979,
      "learning_rate": 1.3209757491338977e-05,
      "loss": 0.0006,
      "step": 47530
    },
    {
      "epoch": 5.093753348333869,
      "grad_norm": 0.012258724309504032,
      "learning_rate": 1.3208328868888176e-05,
      "loss": 0.0002,
      "step": 47540
    },
    {
      "epoch": 5.094824815171971,
      "grad_norm": 0.004320844542235136,
      "learning_rate": 1.3206900246437372e-05,
      "loss": 0.1636,
      "step": 47550
    },
    {
      "epoch": 5.095896282010072,
      "grad_norm": 0.0002832963946275413,
      "learning_rate": 1.3205471623986572e-05,
      "loss": 0.0001,
      "step": 47560
    },
    {
      "epoch": 5.096967748848173,
      "grad_norm": 0.34887048602104187,
      "learning_rate": 1.3204043001535771e-05,
      "loss": 0.0005,
      "step": 47570
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 0.002683702390640974,
      "learning_rate": 1.3202614379084969e-05,
      "loss": 0.0002,
      "step": 47580
    },
    {
      "epoch": 5.099110682524376,
      "grad_norm": 0.0003456897393334657,
      "learning_rate": 1.3201185756634168e-05,
      "loss": 0.0,
      "step": 47590
    },
    {
      "epoch": 5.100182149362477,
      "grad_norm": 0.0002245384966954589,
      "learning_rate": 1.3199757134183364e-05,
      "loss": 0.0022,
      "step": 47600
    },
    {
      "epoch": 5.101253616200578,
      "grad_norm": 0.002972134156152606,
      "learning_rate": 1.3198328511732563e-05,
      "loss": 0.0001,
      "step": 47610
    },
    {
      "epoch": 5.10232508303868,
      "grad_norm": 0.004007739946246147,
      "learning_rate": 1.319689988928176e-05,
      "loss": 0.0,
      "step": 47620
    },
    {
      "epoch": 5.1033965498767815,
      "grad_norm": 0.005031073931604624,
      "learning_rate": 1.3195471266830959e-05,
      "loss": 0.0001,
      "step": 47630
    },
    {
      "epoch": 5.104468016714883,
      "grad_norm": 0.0024578161537647247,
      "learning_rate": 1.3194042644380158e-05,
      "loss": 0.0003,
      "step": 47640
    },
    {
      "epoch": 5.105539483552984,
      "grad_norm": 0.0002485496224835515,
      "learning_rate": 1.3192614021929356e-05,
      "loss": 0.0596,
      "step": 47650
    },
    {
      "epoch": 5.106610950391086,
      "grad_norm": 0.0032671582885086536,
      "learning_rate": 1.3191185399478555e-05,
      "loss": 0.0002,
      "step": 47660
    },
    {
      "epoch": 5.107682417229187,
      "grad_norm": 0.002669423585757613,
      "learning_rate": 1.3189756777027751e-05,
      "loss": 0.0326,
      "step": 47670
    },
    {
      "epoch": 5.108753884067288,
      "grad_norm": 0.19667485356330872,
      "learning_rate": 1.318832815457695e-05,
      "loss": 0.0011,
      "step": 47680
    },
    {
      "epoch": 5.109825350905389,
      "grad_norm": 0.016059618443250656,
      "learning_rate": 1.318689953212615e-05,
      "loss": 0.0001,
      "step": 47690
    },
    {
      "epoch": 5.110896817743491,
      "grad_norm": 0.00016985030379146338,
      "learning_rate": 1.3185470909675346e-05,
      "loss": 0.0003,
      "step": 47700
    },
    {
      "epoch": 5.111968284581592,
      "grad_norm": 0.0002613128744997084,
      "learning_rate": 1.3184042287224545e-05,
      "loss": 0.0003,
      "step": 47710
    },
    {
      "epoch": 5.113039751419693,
      "grad_norm": 0.00019273872021585703,
      "learning_rate": 1.3182613664773743e-05,
      "loss": 0.0001,
      "step": 47720
    },
    {
      "epoch": 5.114111218257795,
      "grad_norm": 0.00014329810801427811,
      "learning_rate": 1.3181185042322942e-05,
      "loss": 0.2616,
      "step": 47730
    },
    {
      "epoch": 5.115182685095896,
      "grad_norm": 0.005197831895202398,
      "learning_rate": 1.3179756419872138e-05,
      "loss": 0.0,
      "step": 47740
    },
    {
      "epoch": 5.1162541519339975,
      "grad_norm": 0.0007918592309579253,
      "learning_rate": 1.3178327797421338e-05,
      "loss": 0.1174,
      "step": 47750
    },
    {
      "epoch": 5.117325618772099,
      "grad_norm": 0.002945826156064868,
      "learning_rate": 1.3176899174970537e-05,
      "loss": 0.1607,
      "step": 47760
    },
    {
      "epoch": 5.118397085610201,
      "grad_norm": 0.020404433831572533,
      "learning_rate": 1.3175470552519733e-05,
      "loss": 0.0001,
      "step": 47770
    },
    {
      "epoch": 5.119468552448302,
      "grad_norm": 0.00021679277415387332,
      "learning_rate": 1.3174041930068932e-05,
      "loss": 0.0001,
      "step": 47780
    },
    {
      "epoch": 5.120540019286403,
      "grad_norm": 0.00019739210256375372,
      "learning_rate": 1.317261330761813e-05,
      "loss": 0.0005,
      "step": 47790
    },
    {
      "epoch": 5.121611486124505,
      "grad_norm": 0.00028955936431884766,
      "learning_rate": 1.317118468516733e-05,
      "loss": 0.2174,
      "step": 47800
    },
    {
      "epoch": 5.122682952962606,
      "grad_norm": 0.0023337050806730986,
      "learning_rate": 1.3169756062716527e-05,
      "loss": 0.0001,
      "step": 47810
    },
    {
      "epoch": 5.123754419800707,
      "grad_norm": 0.006215814501047134,
      "learning_rate": 1.3168327440265725e-05,
      "loss": 0.0,
      "step": 47820
    },
    {
      "epoch": 5.124825886638808,
      "grad_norm": 0.0021483267191797495,
      "learning_rate": 1.3166898817814924e-05,
      "loss": 0.2644,
      "step": 47830
    },
    {
      "epoch": 5.12589735347691,
      "grad_norm": 17.644968032836914,
      "learning_rate": 1.316547019536412e-05,
      "loss": 0.1916,
      "step": 47840
    },
    {
      "epoch": 5.126968820315011,
      "grad_norm": 0.04726596176624298,
      "learning_rate": 1.316404157291332e-05,
      "loss": 0.0006,
      "step": 47850
    },
    {
      "epoch": 5.128040287153112,
      "grad_norm": 0.02558654360473156,
      "learning_rate": 1.3162612950462517e-05,
      "loss": 0.1411,
      "step": 47860
    },
    {
      "epoch": 5.129111753991214,
      "grad_norm": 0.001584339770488441,
      "learning_rate": 1.3161184328011716e-05,
      "loss": 0.0003,
      "step": 47870
    },
    {
      "epoch": 5.130183220829315,
      "grad_norm": 0.0005623995093628764,
      "learning_rate": 1.3159755705560914e-05,
      "loss": 0.0001,
      "step": 47880
    },
    {
      "epoch": 5.1312546876674165,
      "grad_norm": 0.0013574018375948071,
      "learning_rate": 1.3158327083110112e-05,
      "loss": 0.0003,
      "step": 47890
    },
    {
      "epoch": 5.132326154505518,
      "grad_norm": 84.02930450439453,
      "learning_rate": 1.3156898460659311e-05,
      "loss": 0.1296,
      "step": 47900
    },
    {
      "epoch": 5.13339762134362,
      "grad_norm": 0.08443979173898697,
      "learning_rate": 1.3155469838208507e-05,
      "loss": 0.0004,
      "step": 47910
    },
    {
      "epoch": 5.134469088181721,
      "grad_norm": 0.0005174910766072571,
      "learning_rate": 1.3154041215757706e-05,
      "loss": 0.0004,
      "step": 47920
    },
    {
      "epoch": 5.135540555019822,
      "grad_norm": 0.0003396114334464073,
      "learning_rate": 1.3152612593306906e-05,
      "loss": 0.0002,
      "step": 47930
    },
    {
      "epoch": 5.136612021857924,
      "grad_norm": 0.00031842125463299453,
      "learning_rate": 1.3151183970856103e-05,
      "loss": 0.2088,
      "step": 47940
    },
    {
      "epoch": 5.137683488696025,
      "grad_norm": 0.0021333093754947186,
      "learning_rate": 1.3149755348405303e-05,
      "loss": 0.0,
      "step": 47950
    },
    {
      "epoch": 5.138754955534126,
      "grad_norm": 0.0006619166233576834,
      "learning_rate": 1.3148326725954499e-05,
      "loss": 0.272,
      "step": 47960
    },
    {
      "epoch": 5.139826422372227,
      "grad_norm": 0.01342961098998785,
      "learning_rate": 1.3146898103503698e-05,
      "loss": 0.1712,
      "step": 47970
    },
    {
      "epoch": 5.140897889210329,
      "grad_norm": 0.01357909757643938,
      "learning_rate": 1.3145469481052894e-05,
      "loss": 0.1876,
      "step": 47980
    },
    {
      "epoch": 5.14196935604843,
      "grad_norm": 0.015654396265745163,
      "learning_rate": 1.3144040858602094e-05,
      "loss": 0.0005,
      "step": 47990
    },
    {
      "epoch": 5.143040822886531,
      "grad_norm": 0.09621541202068329,
      "learning_rate": 1.3142612236151293e-05,
      "loss": 0.0048,
      "step": 48000
    },
    {
      "epoch": 5.144112289724633,
      "grad_norm": 0.0020998490508645773,
      "learning_rate": 1.314118361370049e-05,
      "loss": 0.0002,
      "step": 48010
    },
    {
      "epoch": 5.1451837565627345,
      "grad_norm": 0.03556191548705101,
      "learning_rate": 1.313975499124969e-05,
      "loss": 0.0001,
      "step": 48020
    },
    {
      "epoch": 5.146255223400836,
      "grad_norm": 0.0029599943663924932,
      "learning_rate": 1.3138326368798886e-05,
      "loss": 0.1598,
      "step": 48030
    },
    {
      "epoch": 5.147326690238937,
      "grad_norm": 0.16465884447097778,
      "learning_rate": 1.3136897746348085e-05,
      "loss": 0.1764,
      "step": 48040
    },
    {
      "epoch": 5.148398157077039,
      "grad_norm": 0.0909249410033226,
      "learning_rate": 1.3135469123897281e-05,
      "loss": 0.0004,
      "step": 48050
    },
    {
      "epoch": 5.14946962391514,
      "grad_norm": 0.0004766119527630508,
      "learning_rate": 1.313404050144648e-05,
      "loss": 0.1531,
      "step": 48060
    },
    {
      "epoch": 5.150541090753241,
      "grad_norm": 0.00033607735531404614,
      "learning_rate": 1.313261187899568e-05,
      "loss": 0.1344,
      "step": 48070
    },
    {
      "epoch": 5.151612557591343,
      "grad_norm": 0.002449203748255968,
      "learning_rate": 1.3131183256544878e-05,
      "loss": 0.0006,
      "step": 48080
    },
    {
      "epoch": 5.152684024429444,
      "grad_norm": 0.0006543815252371132,
      "learning_rate": 1.3129754634094077e-05,
      "loss": 0.118,
      "step": 48090
    },
    {
      "epoch": 5.153755491267545,
      "grad_norm": 0.00264458148740232,
      "learning_rate": 1.3128326011643273e-05,
      "loss": 0.0069,
      "step": 48100
    },
    {
      "epoch": 5.154826958105646,
      "grad_norm": 0.6312384009361267,
      "learning_rate": 1.3126897389192472e-05,
      "loss": 0.161,
      "step": 48110
    },
    {
      "epoch": 5.155898424943748,
      "grad_norm": 0.0039254724979400635,
      "learning_rate": 1.3125468766741672e-05,
      "loss": 0.0215,
      "step": 48120
    },
    {
      "epoch": 5.156969891781849,
      "grad_norm": 0.0016436330042779446,
      "learning_rate": 1.3124040144290868e-05,
      "loss": 0.036,
      "step": 48130
    },
    {
      "epoch": 5.1580413586199505,
      "grad_norm": 0.025764767080545425,
      "learning_rate": 1.3122611521840067e-05,
      "loss": 0.0002,
      "step": 48140
    },
    {
      "epoch": 5.1591128254580525,
      "grad_norm": 0.006686043925583363,
      "learning_rate": 1.3121182899389265e-05,
      "loss": 0.0004,
      "step": 48150
    },
    {
      "epoch": 5.160184292296154,
      "grad_norm": 0.00452602980658412,
      "learning_rate": 1.3119754276938464e-05,
      "loss": 0.0004,
      "step": 48160
    },
    {
      "epoch": 5.161255759134255,
      "grad_norm": 0.00016755615069996566,
      "learning_rate": 1.311832565448766e-05,
      "loss": 0.2742,
      "step": 48170
    },
    {
      "epoch": 5.162327225972356,
      "grad_norm": 128.4930419921875,
      "learning_rate": 1.311689703203686e-05,
      "loss": 0.0736,
      "step": 48180
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 0.0002222587791038677,
      "learning_rate": 1.3115468409586059e-05,
      "loss": 0.0001,
      "step": 48190
    },
    {
      "epoch": 5.164470159648559,
      "grad_norm": 0.00024273227609228343,
      "learning_rate": 1.3114039787135255e-05,
      "loss": 0.0003,
      "step": 48200
    },
    {
      "epoch": 5.16554162648666,
      "grad_norm": 0.0017069806344807148,
      "learning_rate": 1.3112611164684454e-05,
      "loss": 0.1682,
      "step": 48210
    },
    {
      "epoch": 5.166613093324761,
      "grad_norm": 0.0013085209066048265,
      "learning_rate": 1.3111182542233652e-05,
      "loss": 0.0003,
      "step": 48220
    },
    {
      "epoch": 5.167684560162863,
      "grad_norm": 0.00012577130110003054,
      "learning_rate": 1.3109753919782851e-05,
      "loss": 0.0,
      "step": 48230
    },
    {
      "epoch": 5.168756027000964,
      "grad_norm": 59.55460739135742,
      "learning_rate": 1.3108325297332049e-05,
      "loss": 0.3008,
      "step": 48240
    },
    {
      "epoch": 5.169827493839065,
      "grad_norm": 0.04830923303961754,
      "learning_rate": 1.3106896674881247e-05,
      "loss": 0.2943,
      "step": 48250
    },
    {
      "epoch": 5.170898960677167,
      "grad_norm": 0.003474611323326826,
      "learning_rate": 1.3105468052430446e-05,
      "loss": 0.176,
      "step": 48260
    },
    {
      "epoch": 5.1719704275152685,
      "grad_norm": 0.004624170251190662,
      "learning_rate": 1.3104039429979642e-05,
      "loss": 0.1338,
      "step": 48270
    },
    {
      "epoch": 5.17304189435337,
      "grad_norm": 260.282958984375,
      "learning_rate": 1.3102610807528841e-05,
      "loss": 0.0915,
      "step": 48280
    },
    {
      "epoch": 5.174113361191471,
      "grad_norm": 0.21044495701789856,
      "learning_rate": 1.3101182185078039e-05,
      "loss": 0.0004,
      "step": 48290
    },
    {
      "epoch": 5.175184828029573,
      "grad_norm": 0.0002790997677948326,
      "learning_rate": 1.3099753562627238e-05,
      "loss": 0.0006,
      "step": 48300
    },
    {
      "epoch": 5.176256294867674,
      "grad_norm": 0.00019800802692770958,
      "learning_rate": 1.3098324940176436e-05,
      "loss": 0.0001,
      "step": 48310
    },
    {
      "epoch": 5.177327761705775,
      "grad_norm": 0.038100019097328186,
      "learning_rate": 1.3096896317725634e-05,
      "loss": 0.0002,
      "step": 48320
    },
    {
      "epoch": 5.178399228543877,
      "grad_norm": 0.004563713446259499,
      "learning_rate": 1.3095467695274833e-05,
      "loss": 0.0387,
      "step": 48330
    },
    {
      "epoch": 5.179470695381978,
      "grad_norm": 0.01330845057964325,
      "learning_rate": 1.3094039072824029e-05,
      "loss": 0.2947,
      "step": 48340
    },
    {
      "epoch": 5.180542162220079,
      "grad_norm": 0.005121236201375723,
      "learning_rate": 1.3092610450373228e-05,
      "loss": 0.3677,
      "step": 48350
    },
    {
      "epoch": 5.18161362905818,
      "grad_norm": 0.15772920846939087,
      "learning_rate": 1.3091181827922428e-05,
      "loss": 0.126,
      "step": 48360
    },
    {
      "epoch": 5.182685095896282,
      "grad_norm": 0.02437247335910797,
      "learning_rate": 1.3089753205471625e-05,
      "loss": 0.0619,
      "step": 48370
    },
    {
      "epoch": 5.183756562734383,
      "grad_norm": 0.09916099160909653,
      "learning_rate": 1.3088324583020823e-05,
      "loss": 0.2046,
      "step": 48380
    },
    {
      "epoch": 5.1848280295724845,
      "grad_norm": 0.023718951269984245,
      "learning_rate": 1.308689596057002e-05,
      "loss": 0.0008,
      "step": 48390
    },
    {
      "epoch": 5.1858994964105865,
      "grad_norm": 0.0027706280816346407,
      "learning_rate": 1.308546733811922e-05,
      "loss": 0.0004,
      "step": 48400
    },
    {
      "epoch": 5.186970963248688,
      "grad_norm": 0.05427790433168411,
      "learning_rate": 1.3084038715668416e-05,
      "loss": 0.0024,
      "step": 48410
    },
    {
      "epoch": 5.188042430086789,
      "grad_norm": 0.00019373752002138644,
      "learning_rate": 1.3082610093217615e-05,
      "loss": 0.0001,
      "step": 48420
    },
    {
      "epoch": 5.18911389692489,
      "grad_norm": 0.1006188839673996,
      "learning_rate": 1.3081181470766815e-05,
      "loss": 0.2644,
      "step": 48430
    },
    {
      "epoch": 5.190185363762992,
      "grad_norm": 0.002798705128952861,
      "learning_rate": 1.3079752848316012e-05,
      "loss": 0.2297,
      "step": 48440
    },
    {
      "epoch": 5.191256830601093,
      "grad_norm": 0.07255957275629044,
      "learning_rate": 1.307832422586521e-05,
      "loss": 0.3648,
      "step": 48450
    },
    {
      "epoch": 5.192328297439194,
      "grad_norm": 0.03099791705608368,
      "learning_rate": 1.3076895603414408e-05,
      "loss": 0.1657,
      "step": 48460
    },
    {
      "epoch": 5.193399764277296,
      "grad_norm": 0.02550731971859932,
      "learning_rate": 1.3075466980963607e-05,
      "loss": 0.0004,
      "step": 48470
    },
    {
      "epoch": 5.194471231115397,
      "grad_norm": 0.0005948857287876308,
      "learning_rate": 1.3074038358512807e-05,
      "loss": 0.0002,
      "step": 48480
    },
    {
      "epoch": 5.195542697953498,
      "grad_norm": 0.009209446609020233,
      "learning_rate": 1.3072609736062003e-05,
      "loss": 0.1436,
      "step": 48490
    },
    {
      "epoch": 5.196614164791599,
      "grad_norm": 0.49462389945983887,
      "learning_rate": 1.3071181113611202e-05,
      "loss": 0.0005,
      "step": 48500
    },
    {
      "epoch": 5.197685631629701,
      "grad_norm": 0.021133357658982277,
      "learning_rate": 1.30697524911604e-05,
      "loss": 0.1737,
      "step": 48510
    },
    {
      "epoch": 5.198757098467802,
      "grad_norm": 0.0002906639128923416,
      "learning_rate": 1.3068323868709599e-05,
      "loss": 0.0578,
      "step": 48520
    },
    {
      "epoch": 5.1998285653059035,
      "grad_norm": 0.2795046269893646,
      "learning_rate": 1.3066895246258795e-05,
      "loss": 0.0005,
      "step": 48530
    },
    {
      "epoch": 5.2009000321440055,
      "grad_norm": 0.0002846192510332912,
      "learning_rate": 1.3065466623807994e-05,
      "loss": 0.243,
      "step": 48540
    },
    {
      "epoch": 5.201971498982107,
      "grad_norm": 0.013248971663415432,
      "learning_rate": 1.3064038001357194e-05,
      "loss": 0.0524,
      "step": 48550
    },
    {
      "epoch": 5.203042965820208,
      "grad_norm": 0.028568610548973083,
      "learning_rate": 1.306260937890639e-05,
      "loss": 0.0008,
      "step": 48560
    },
    {
      "epoch": 5.204114432658309,
      "grad_norm": 0.014829173684120178,
      "learning_rate": 1.3061180756455589e-05,
      "loss": 0.2443,
      "step": 48570
    },
    {
      "epoch": 5.205185899496411,
      "grad_norm": 0.05633893981575966,
      "learning_rate": 1.3059752134004787e-05,
      "loss": 0.0009,
      "step": 48580
    },
    {
      "epoch": 5.206257366334512,
      "grad_norm": 14.33861255645752,
      "learning_rate": 1.3058323511553986e-05,
      "loss": 0.1408,
      "step": 48590
    },
    {
      "epoch": 5.207328833172613,
      "grad_norm": 0.002170089166611433,
      "learning_rate": 1.3056894889103184e-05,
      "loss": 0.0001,
      "step": 48600
    },
    {
      "epoch": 5.208400300010715,
      "grad_norm": 0.09160551428794861,
      "learning_rate": 1.3055466266652381e-05,
      "loss": 0.0003,
      "step": 48610
    },
    {
      "epoch": 5.209471766848816,
      "grad_norm": 0.021497787907719612,
      "learning_rate": 1.305403764420158e-05,
      "loss": 0.1595,
      "step": 48620
    },
    {
      "epoch": 5.210543233686917,
      "grad_norm": 0.0002607542846817523,
      "learning_rate": 1.3052609021750777e-05,
      "loss": 0.1336,
      "step": 48630
    },
    {
      "epoch": 5.211614700525018,
      "grad_norm": 0.005248709116131067,
      "learning_rate": 1.3051180399299976e-05,
      "loss": 0.1241,
      "step": 48640
    },
    {
      "epoch": 5.21268616736312,
      "grad_norm": 0.008823242969810963,
      "learning_rate": 1.3049751776849174e-05,
      "loss": 0.2867,
      "step": 48650
    },
    {
      "epoch": 5.2137576342012215,
      "grad_norm": 0.0001849435066105798,
      "learning_rate": 1.3048323154398373e-05,
      "loss": 0.0014,
      "step": 48660
    },
    {
      "epoch": 5.214829101039323,
      "grad_norm": 0.0010650715557858348,
      "learning_rate": 1.304689453194757e-05,
      "loss": 0.1888,
      "step": 48670
    },
    {
      "epoch": 5.215900567877425,
      "grad_norm": 0.11108064651489258,
      "learning_rate": 1.3045465909496768e-05,
      "loss": 0.0006,
      "step": 48680
    },
    {
      "epoch": 5.216972034715526,
      "grad_norm": 0.030537687242031097,
      "learning_rate": 1.3044037287045968e-05,
      "loss": 0.1248,
      "step": 48690
    },
    {
      "epoch": 5.218043501553627,
      "grad_norm": 0.024315861985087395,
      "learning_rate": 1.3042608664595164e-05,
      "loss": 0.0091,
      "step": 48700
    },
    {
      "epoch": 5.219114968391728,
      "grad_norm": 0.01423378475010395,
      "learning_rate": 1.3041180042144363e-05,
      "loss": 0.2922,
      "step": 48710
    },
    {
      "epoch": 5.22018643522983,
      "grad_norm": 0.010333199054002762,
      "learning_rate": 1.3039751419693563e-05,
      "loss": 0.001,
      "step": 48720
    },
    {
      "epoch": 5.221257902067931,
      "grad_norm": 73.08887481689453,
      "learning_rate": 1.303832279724276e-05,
      "loss": 0.3769,
      "step": 48730
    },
    {
      "epoch": 5.222329368906032,
      "grad_norm": 0.0005951135535724461,
      "learning_rate": 1.3036894174791958e-05,
      "loss": 0.1482,
      "step": 48740
    },
    {
      "epoch": 5.223400835744133,
      "grad_norm": 0.008555459789931774,
      "learning_rate": 1.3035465552341156e-05,
      "loss": 0.0013,
      "step": 48750
    },
    {
      "epoch": 5.224472302582235,
      "grad_norm": 0.00036622877814807,
      "learning_rate": 1.3034036929890355e-05,
      "loss": 0.0003,
      "step": 48760
    },
    {
      "epoch": 5.225543769420336,
      "grad_norm": 0.008986789733171463,
      "learning_rate": 1.3032608307439551e-05,
      "loss": 0.0001,
      "step": 48770
    },
    {
      "epoch": 5.2266152362584375,
      "grad_norm": 0.00910718273371458,
      "learning_rate": 1.303117968498875e-05,
      "loss": 0.1489,
      "step": 48780
    },
    {
      "epoch": 5.2276867030965395,
      "grad_norm": 0.03137258440256119,
      "learning_rate": 1.302975106253795e-05,
      "loss": 0.0739,
      "step": 48790
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 0.02127476967871189,
      "learning_rate": 1.3028322440087147e-05,
      "loss": 0.0001,
      "step": 48800
    },
    {
      "epoch": 5.229829636772742,
      "grad_norm": 0.00038638117257505655,
      "learning_rate": 1.3026893817636345e-05,
      "loss": 0.0002,
      "step": 48810
    },
    {
      "epoch": 5.230901103610843,
      "grad_norm": 199.5171661376953,
      "learning_rate": 1.3025465195185543e-05,
      "loss": 0.1553,
      "step": 48820
    },
    {
      "epoch": 5.231972570448945,
      "grad_norm": 0.0002728537656366825,
      "learning_rate": 1.3024036572734742e-05,
      "loss": 0.0159,
      "step": 48830
    },
    {
      "epoch": 5.233044037287046,
      "grad_norm": 0.006974269635975361,
      "learning_rate": 1.3022607950283941e-05,
      "loss": 0.0002,
      "step": 48840
    },
    {
      "epoch": 5.234115504125147,
      "grad_norm": 0.00018604697834234685,
      "learning_rate": 1.3021179327833137e-05,
      "loss": 0.0002,
      "step": 48850
    },
    {
      "epoch": 5.235186970963249,
      "grad_norm": 0.00040490453829988837,
      "learning_rate": 1.3019750705382337e-05,
      "loss": 0.1238,
      "step": 48860
    },
    {
      "epoch": 5.23625843780135,
      "grad_norm": 0.011945103295147419,
      "learning_rate": 1.3018322082931534e-05,
      "loss": 0.283,
      "step": 48870
    },
    {
      "epoch": 5.237329904639451,
      "grad_norm": 0.01607031188905239,
      "learning_rate": 1.3016893460480732e-05,
      "loss": 0.3019,
      "step": 48880
    },
    {
      "epoch": 5.238401371477552,
      "grad_norm": 16.740314483642578,
      "learning_rate": 1.301546483802993e-05,
      "loss": 0.1298,
      "step": 48890
    },
    {
      "epoch": 5.239472838315654,
      "grad_norm": 0.014784719794988632,
      "learning_rate": 1.3014036215579129e-05,
      "loss": 0.0009,
      "step": 48900
    },
    {
      "epoch": 5.2405443051537555,
      "grad_norm": 0.028829632326960564,
      "learning_rate": 1.3012607593128329e-05,
      "loss": 0.3322,
      "step": 48910
    },
    {
      "epoch": 5.241615771991857,
      "grad_norm": 0.017973775044083595,
      "learning_rate": 1.3011178970677524e-05,
      "loss": 0.0014,
      "step": 48920
    },
    {
      "epoch": 5.242687238829959,
      "grad_norm": 0.342161625623703,
      "learning_rate": 1.3009750348226724e-05,
      "loss": 0.0003,
      "step": 48930
    },
    {
      "epoch": 5.24375870566806,
      "grad_norm": 0.0003617710608523339,
      "learning_rate": 1.3008321725775922e-05,
      "loss": 0.2418,
      "step": 48940
    },
    {
      "epoch": 5.244830172506161,
      "grad_norm": 0.5849103927612305,
      "learning_rate": 1.300689310332512e-05,
      "loss": 0.1827,
      "step": 48950
    },
    {
      "epoch": 5.245901639344262,
      "grad_norm": 0.0002555333776399493,
      "learning_rate": 1.3005464480874317e-05,
      "loss": 0.2304,
      "step": 48960
    },
    {
      "epoch": 5.246973106182364,
      "grad_norm": 0.02513916604220867,
      "learning_rate": 1.3004035858423516e-05,
      "loss": 0.0019,
      "step": 48970
    },
    {
      "epoch": 5.248044573020465,
      "grad_norm": 0.00015658361371606588,
      "learning_rate": 1.3002607235972716e-05,
      "loss": 0.0037,
      "step": 48980
    },
    {
      "epoch": 5.249116039858566,
      "grad_norm": 0.020210498943924904,
      "learning_rate": 1.3001178613521912e-05,
      "loss": 0.3964,
      "step": 48990
    },
    {
      "epoch": 5.250187506696668,
      "grad_norm": 0.0006317905499599874,
      "learning_rate": 1.2999749991071111e-05,
      "loss": 0.2027,
      "step": 49000
    },
    {
      "epoch": 5.251258973534769,
      "grad_norm": 0.0035907928831875324,
      "learning_rate": 1.2998321368620309e-05,
      "loss": 0.0967,
      "step": 49010
    },
    {
      "epoch": 5.25233044037287,
      "grad_norm": 0.2845023572444916,
      "learning_rate": 1.2996892746169506e-05,
      "loss": 0.0529,
      "step": 49020
    },
    {
      "epoch": 5.2534019072109714,
      "grad_norm": 0.03510864078998566,
      "learning_rate": 1.2995464123718706e-05,
      "loss": 0.0391,
      "step": 49030
    },
    {
      "epoch": 5.254473374049073,
      "grad_norm": 0.005885855760425329,
      "learning_rate": 1.2994035501267903e-05,
      "loss": 0.1002,
      "step": 49040
    },
    {
      "epoch": 5.2555448408871746,
      "grad_norm": 0.0002421061071800068,
      "learning_rate": 1.2992606878817103e-05,
      "loss": 0.0002,
      "step": 49050
    },
    {
      "epoch": 5.256616307725276,
      "grad_norm": 0.052221834659576416,
      "learning_rate": 1.2991178256366299e-05,
      "loss": 0.0014,
      "step": 49060
    },
    {
      "epoch": 5.257687774563378,
      "grad_norm": 0.010608035139739513,
      "learning_rate": 1.2989749633915498e-05,
      "loss": 0.0001,
      "step": 49070
    },
    {
      "epoch": 5.258759241401479,
      "grad_norm": 0.010810320265591145,
      "learning_rate": 1.2988321011464696e-05,
      "loss": 0.0062,
      "step": 49080
    },
    {
      "epoch": 5.25983070823958,
      "grad_norm": 0.0038609185721725225,
      "learning_rate": 1.2986892389013895e-05,
      "loss": 0.0017,
      "step": 49090
    },
    {
      "epoch": 5.260902175077681,
      "grad_norm": 0.0001525651168776676,
      "learning_rate": 1.2985463766563093e-05,
      "loss": 0.0001,
      "step": 49100
    },
    {
      "epoch": 5.261973641915783,
      "grad_norm": 0.00012194638111395761,
      "learning_rate": 1.298403514411229e-05,
      "loss": 0.0,
      "step": 49110
    },
    {
      "epoch": 5.263045108753884,
      "grad_norm": 0.00018395647930447012,
      "learning_rate": 1.298260652166149e-05,
      "loss": 0.0039,
      "step": 49120
    },
    {
      "epoch": 5.264116575591985,
      "grad_norm": 0.001955851214006543,
      "learning_rate": 1.2981177899210686e-05,
      "loss": 0.3808,
      "step": 49130
    },
    {
      "epoch": 5.265188042430087,
      "grad_norm": 0.00018784117128234357,
      "learning_rate": 1.2979749276759885e-05,
      "loss": 0.001,
      "step": 49140
    },
    {
      "epoch": 5.266259509268188,
      "grad_norm": 0.0001835070870583877,
      "learning_rate": 1.2978320654309085e-05,
      "loss": 0.1955,
      "step": 49150
    },
    {
      "epoch": 5.267330976106289,
      "grad_norm": 0.0008039608364924788,
      "learning_rate": 1.2976892031858282e-05,
      "loss": 0.0007,
      "step": 49160
    },
    {
      "epoch": 5.2684024429443905,
      "grad_norm": 0.00685231015086174,
      "learning_rate": 1.297546340940748e-05,
      "loss": 0.2599,
      "step": 49170
    },
    {
      "epoch": 5.2694739097824925,
      "grad_norm": 0.007922801189124584,
      "learning_rate": 1.2974034786956678e-05,
      "loss": 0.0001,
      "step": 49180
    },
    {
      "epoch": 5.270545376620594,
      "grad_norm": 0.005971678998321295,
      "learning_rate": 1.2972606164505877e-05,
      "loss": 0.0002,
      "step": 49190
    },
    {
      "epoch": 5.271616843458695,
      "grad_norm": 0.044351447373628616,
      "learning_rate": 1.2971177542055073e-05,
      "loss": 0.0004,
      "step": 49200
    },
    {
      "epoch": 5.272688310296797,
      "grad_norm": 0.008039339445531368,
      "learning_rate": 1.2969748919604272e-05,
      "loss": 0.0001,
      "step": 49210
    },
    {
      "epoch": 5.273759777134898,
      "grad_norm": 0.0046148356050252914,
      "learning_rate": 1.2968320297153472e-05,
      "loss": 0.0333,
      "step": 49220
    },
    {
      "epoch": 5.274831243972999,
      "grad_norm": 0.00016918634355533868,
      "learning_rate": 1.296689167470267e-05,
      "loss": 0.0002,
      "step": 49230
    },
    {
      "epoch": 5.2759027108111,
      "grad_norm": 0.013047760352492332,
      "learning_rate": 1.2965463052251867e-05,
      "loss": 0.0,
      "step": 49240
    },
    {
      "epoch": 5.276974177649202,
      "grad_norm": 0.007741074543446302,
      "learning_rate": 1.2964034429801065e-05,
      "loss": 0.1578,
      "step": 49250
    },
    {
      "epoch": 5.278045644487303,
      "grad_norm": 24.96182632446289,
      "learning_rate": 1.2962605807350264e-05,
      "loss": 0.2157,
      "step": 49260
    },
    {
      "epoch": 5.279117111325404,
      "grad_norm": 0.00036380175151862204,
      "learning_rate": 1.2961177184899463e-05,
      "loss": 0.0002,
      "step": 49270
    },
    {
      "epoch": 5.280188578163505,
      "grad_norm": 0.00020714968559332192,
      "learning_rate": 1.295974856244866e-05,
      "loss": 0.0029,
      "step": 49280
    },
    {
      "epoch": 5.281260045001607,
      "grad_norm": 19.30316734313965,
      "learning_rate": 1.2958319939997859e-05,
      "loss": 0.4719,
      "step": 49290
    },
    {
      "epoch": 5.2823315118397085,
      "grad_norm": 0.0004457357572391629,
      "learning_rate": 1.2956891317547056e-05,
      "loss": 0.1627,
      "step": 49300
    },
    {
      "epoch": 5.28340297867781,
      "grad_norm": 0.06376006454229355,
      "learning_rate": 1.2955462695096254e-05,
      "loss": 0.0002,
      "step": 49310
    },
    {
      "epoch": 5.284474445515912,
      "grad_norm": 0.0003115813888143748,
      "learning_rate": 1.2954034072645452e-05,
      "loss": 0.0003,
      "step": 49320
    },
    {
      "epoch": 5.285545912354013,
      "grad_norm": 0.0002823610557243228,
      "learning_rate": 1.2952605450194651e-05,
      "loss": 0.0004,
      "step": 49330
    },
    {
      "epoch": 5.286617379192114,
      "grad_norm": 0.008108776994049549,
      "learning_rate": 1.295117682774385e-05,
      "loss": 0.0002,
      "step": 49340
    },
    {
      "epoch": 5.287688846030216,
      "grad_norm": 0.00017344568914268166,
      "learning_rate": 1.2949748205293046e-05,
      "loss": 0.0001,
      "step": 49350
    },
    {
      "epoch": 5.288760312868317,
      "grad_norm": 0.00018386328883934766,
      "learning_rate": 1.2948319582842246e-05,
      "loss": 0.0001,
      "step": 49360
    },
    {
      "epoch": 5.289831779706418,
      "grad_norm": 0.0004549468867480755,
      "learning_rate": 1.2946890960391443e-05,
      "loss": 0.2299,
      "step": 49370
    },
    {
      "epoch": 5.290903246544519,
      "grad_norm": 0.002263331785798073,
      "learning_rate": 1.2945462337940641e-05,
      "loss": 0.2533,
      "step": 49380
    },
    {
      "epoch": 5.291974713382621,
      "grad_norm": 0.2848140299320221,
      "learning_rate": 1.294403371548984e-05,
      "loss": 0.0005,
      "step": 49390
    },
    {
      "epoch": 5.293046180220722,
      "grad_norm": 0.0025791048537939787,
      "learning_rate": 1.2942605093039038e-05,
      "loss": 0.0003,
      "step": 49400
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.011045826599001884,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 0.0017,
      "step": 49410
    },
    {
      "epoch": 5.2951891138969245,
      "grad_norm": 0.1160723939538002,
      "learning_rate": 1.2939747848137434e-05,
      "loss": 0.1241,
      "step": 49420
    },
    {
      "epoch": 5.2962605807350265,
      "grad_norm": 0.15924707055091858,
      "learning_rate": 1.2938319225686633e-05,
      "loss": 0.2063,
      "step": 49430
    },
    {
      "epoch": 5.297332047573128,
      "grad_norm": 0.0007062581717036664,
      "learning_rate": 1.293689060323583e-05,
      "loss": 0.0004,
      "step": 49440
    },
    {
      "epoch": 5.298403514411229,
      "grad_norm": 0.006530021782964468,
      "learning_rate": 1.2935461980785028e-05,
      "loss": 0.8826,
      "step": 49450
    },
    {
      "epoch": 5.299474981249331,
      "grad_norm": 0.015770206227898598,
      "learning_rate": 1.2934033358334228e-05,
      "loss": 0.1098,
      "step": 49460
    },
    {
      "epoch": 5.300546448087432,
      "grad_norm": 0.017569558694958687,
      "learning_rate": 1.2932604735883425e-05,
      "loss": 0.1477,
      "step": 49470
    },
    {
      "epoch": 5.301617914925533,
      "grad_norm": 0.13972972333431244,
      "learning_rate": 1.2931176113432625e-05,
      "loss": 0.0006,
      "step": 49480
    },
    {
      "epoch": 5.302689381763634,
      "grad_norm": 0.5265343189239502,
      "learning_rate": 1.292974749098182e-05,
      "loss": 0.0008,
      "step": 49490
    },
    {
      "epoch": 5.303760848601736,
      "grad_norm": 0.0010956653859466314,
      "learning_rate": 1.292831886853102e-05,
      "loss": 0.1698,
      "step": 49500
    },
    {
      "epoch": 5.304832315439837,
      "grad_norm": 0.0011136096436530352,
      "learning_rate": 1.292689024608022e-05,
      "loss": 0.0003,
      "step": 49510
    },
    {
      "epoch": 5.305903782277938,
      "grad_norm": 0.001254503265954554,
      "learning_rate": 1.2925461623629415e-05,
      "loss": 0.0001,
      "step": 49520
    },
    {
      "epoch": 5.30697524911604,
      "grad_norm": 1.5340039730072021,
      "learning_rate": 1.2924033001178615e-05,
      "loss": 0.0039,
      "step": 49530
    },
    {
      "epoch": 5.308046715954141,
      "grad_norm": 0.001209756825119257,
      "learning_rate": 1.2922604378727812e-05,
      "loss": 0.0002,
      "step": 49540
    },
    {
      "epoch": 5.3091181827922425,
      "grad_norm": 0.0011379498755559325,
      "learning_rate": 1.2921175756277012e-05,
      "loss": 0.041,
      "step": 49550
    },
    {
      "epoch": 5.310189649630344,
      "grad_norm": 0.0003357132081873715,
      "learning_rate": 1.2919747133826208e-05,
      "loss": 0.0002,
      "step": 49560
    },
    {
      "epoch": 5.311261116468446,
      "grad_norm": 0.0002541584544815123,
      "learning_rate": 1.2918318511375407e-05,
      "loss": 0.0006,
      "step": 49570
    },
    {
      "epoch": 5.312332583306547,
      "grad_norm": 0.00504490127786994,
      "learning_rate": 1.2916889888924606e-05,
      "loss": 0.3317,
      "step": 49580
    },
    {
      "epoch": 5.313404050144648,
      "grad_norm": 0.0005099336849525571,
      "learning_rate": 1.2915461266473802e-05,
      "loss": 0.0003,
      "step": 49590
    },
    {
      "epoch": 5.31447551698275,
      "grad_norm": 0.02297494001686573,
      "learning_rate": 1.2914032644023002e-05,
      "loss": 0.0002,
      "step": 49600
    },
    {
      "epoch": 5.315546983820851,
      "grad_norm": 0.05180862173438072,
      "learning_rate": 1.29126040215722e-05,
      "loss": 0.0015,
      "step": 49610
    },
    {
      "epoch": 5.316618450658952,
      "grad_norm": 0.0002819165529217571,
      "learning_rate": 1.2911175399121399e-05,
      "loss": 0.0003,
      "step": 49620
    },
    {
      "epoch": 5.317689917497053,
      "grad_norm": 0.0016071513528004289,
      "learning_rate": 1.2909746776670598e-05,
      "loss": 0.2383,
      "step": 49630
    },
    {
      "epoch": 5.318761384335155,
      "grad_norm": 0.03963102400302887,
      "learning_rate": 1.2908318154219794e-05,
      "loss": 0.1643,
      "step": 49640
    },
    {
      "epoch": 5.319832851173256,
      "grad_norm": 0.022677740082144737,
      "learning_rate": 1.2906889531768994e-05,
      "loss": 0.3787,
      "step": 49650
    },
    {
      "epoch": 5.320904318011357,
      "grad_norm": 0.0003428944619372487,
      "learning_rate": 1.2905460909318191e-05,
      "loss": 0.0007,
      "step": 49660
    },
    {
      "epoch": 5.321975784849459,
      "grad_norm": 96.78369903564453,
      "learning_rate": 1.2904032286867389e-05,
      "loss": 0.0062,
      "step": 49670
    },
    {
      "epoch": 5.32304725168756,
      "grad_norm": 0.00016936920292209834,
      "learning_rate": 1.2902603664416587e-05,
      "loss": 0.0002,
      "step": 49680
    },
    {
      "epoch": 5.3241187185256615,
      "grad_norm": 0.00016853836132213473,
      "learning_rate": 1.2901175041965786e-05,
      "loss": 0.1652,
      "step": 49690
    },
    {
      "epoch": 5.325190185363763,
      "grad_norm": 0.00024413691426161677,
      "learning_rate": 1.2899746419514985e-05,
      "loss": 0.0002,
      "step": 49700
    },
    {
      "epoch": 5.326261652201865,
      "grad_norm": 18.89619255065918,
      "learning_rate": 1.2898317797064181e-05,
      "loss": 0.3456,
      "step": 49710
    },
    {
      "epoch": 5.327333119039966,
      "grad_norm": 0.0005143266171216965,
      "learning_rate": 1.289688917461338e-05,
      "loss": 0.0001,
      "step": 49720
    },
    {
      "epoch": 5.328404585878067,
      "grad_norm": 0.00023625233734492213,
      "learning_rate": 1.2895460552162578e-05,
      "loss": 0.0008,
      "step": 49730
    },
    {
      "epoch": 5.329476052716169,
      "grad_norm": 0.0004901018692180514,
      "learning_rate": 1.2894031929711776e-05,
      "loss": 0.2229,
      "step": 49740
    },
    {
      "epoch": 5.33054751955427,
      "grad_norm": 0.0923667699098587,
      "learning_rate": 1.2892603307260975e-05,
      "loss": 0.0006,
      "step": 49750
    },
    {
      "epoch": 5.331618986392371,
      "grad_norm": 0.12106329202651978,
      "learning_rate": 1.2891174684810173e-05,
      "loss": 0.0006,
      "step": 49760
    },
    {
      "epoch": 5.332690453230472,
      "grad_norm": 0.0002874108904507011,
      "learning_rate": 1.2889746062359372e-05,
      "loss": 0.0002,
      "step": 49770
    },
    {
      "epoch": 5.333761920068574,
      "grad_norm": 0.17158745229244232,
      "learning_rate": 1.2888317439908568e-05,
      "loss": 0.0008,
      "step": 49780
    },
    {
      "epoch": 5.334833386906675,
      "grad_norm": 0.00018681953952182084,
      "learning_rate": 1.2886888817457768e-05,
      "loss": 0.0001,
      "step": 49790
    },
    {
      "epoch": 5.335904853744776,
      "grad_norm": 0.00028396848938427866,
      "learning_rate": 1.2885460195006965e-05,
      "loss": 0.1192,
      "step": 49800
    },
    {
      "epoch": 5.3369763205828775,
      "grad_norm": 0.011711112223565578,
      "learning_rate": 1.2884031572556163e-05,
      "loss": 0.0006,
      "step": 49810
    },
    {
      "epoch": 5.3380477874209795,
      "grad_norm": 0.021969212219119072,
      "learning_rate": 1.2882602950105362e-05,
      "loss": 0.0001,
      "step": 49820
    },
    {
      "epoch": 5.339119254259081,
      "grad_norm": 0.00043819486745633185,
      "learning_rate": 1.288117432765456e-05,
      "loss": 0.0004,
      "step": 49830
    },
    {
      "epoch": 5.340190721097182,
      "grad_norm": 0.08940000087022781,
      "learning_rate": 1.287974570520376e-05,
      "loss": 0.0002,
      "step": 49840
    },
    {
      "epoch": 5.341262187935284,
      "grad_norm": 0.014161182567477226,
      "learning_rate": 1.2878317082752955e-05,
      "loss": 0.0002,
      "step": 49850
    },
    {
      "epoch": 5.342333654773385,
      "grad_norm": 0.00020799193589482456,
      "learning_rate": 1.2876888460302155e-05,
      "loss": 0.1584,
      "step": 49860
    },
    {
      "epoch": 5.343405121611486,
      "grad_norm": 0.013964168727397919,
      "learning_rate": 1.2875459837851353e-05,
      "loss": 0.0005,
      "step": 49870
    },
    {
      "epoch": 5.344476588449588,
      "grad_norm": 0.00014726704102940857,
      "learning_rate": 1.287403121540055e-05,
      "loss": 0.0001,
      "step": 49880
    },
    {
      "epoch": 5.345548055287689,
      "grad_norm": 0.00017382504302076995,
      "learning_rate": 1.287260259294975e-05,
      "loss": 0.0455,
      "step": 49890
    },
    {
      "epoch": 5.34661952212579,
      "grad_norm": 0.02497749589383602,
      "learning_rate": 1.2871173970498947e-05,
      "loss": 0.0003,
      "step": 49900
    },
    {
      "epoch": 5.347690988963891,
      "grad_norm": 0.00022783853637520224,
      "learning_rate": 1.2869745348048147e-05,
      "loss": 0.0,
      "step": 49910
    },
    {
      "epoch": 5.348762455801993,
      "grad_norm": 0.004895237274467945,
      "learning_rate": 1.2868316725597343e-05,
      "loss": 0.0005,
      "step": 49920
    },
    {
      "epoch": 5.349833922640094,
      "grad_norm": 0.01222237478941679,
      "learning_rate": 1.2866888103146542e-05,
      "loss": 0.0001,
      "step": 49930
    },
    {
      "epoch": 5.3509053894781955,
      "grad_norm": 0.00012739926751237363,
      "learning_rate": 1.2865459480695741e-05,
      "loss": 0.0002,
      "step": 49940
    },
    {
      "epoch": 5.351976856316297,
      "grad_norm": 0.009721516631543636,
      "learning_rate": 1.2864030858244937e-05,
      "loss": 0.1563,
      "step": 49950
    },
    {
      "epoch": 5.353048323154399,
      "grad_norm": 0.013181515969336033,
      "learning_rate": 1.2862602235794137e-05,
      "loss": 0.0014,
      "step": 49960
    },
    {
      "epoch": 5.3541197899925,
      "grad_norm": 0.010239126160740852,
      "learning_rate": 1.2861173613343334e-05,
      "loss": 0.0001,
      "step": 49970
    },
    {
      "epoch": 5.355191256830601,
      "grad_norm": 29.303255081176758,
      "learning_rate": 1.2859744990892534e-05,
      "loss": 0.3589,
      "step": 49980
    },
    {
      "epoch": 5.356262723668703,
      "grad_norm": 0.00010804524208651856,
      "learning_rate": 1.285831636844173e-05,
      "loss": 0.0002,
      "step": 49990
    },
    {
      "epoch": 5.357334190506804,
      "grad_norm": 0.016434310004115105,
      "learning_rate": 1.2856887745990929e-05,
      "loss": 0.0002,
      "step": 50000
    },
    {
      "epoch": 5.358405657344905,
      "grad_norm": 0.16918517649173737,
      "learning_rate": 1.2855459123540128e-05,
      "loss": 0.0003,
      "step": 50010
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 8.174037066055462e-05,
      "learning_rate": 1.2854030501089324e-05,
      "loss": 0.0021,
      "step": 50020
    },
    {
      "epoch": 5.360548591021108,
      "grad_norm": 0.0001624199067009613,
      "learning_rate": 1.2852601878638524e-05,
      "loss": 0.6236,
      "step": 50030
    },
    {
      "epoch": 5.361620057859209,
      "grad_norm": 0.014129321090877056,
      "learning_rate": 1.2851173256187721e-05,
      "loss": 0.1769,
      "step": 50040
    },
    {
      "epoch": 5.36269152469731,
      "grad_norm": 0.0006950779352337122,
      "learning_rate": 1.284974463373692e-05,
      "loss": 0.6038,
      "step": 50050
    },
    {
      "epoch": 5.363762991535412,
      "grad_norm": 0.012896046973764896,
      "learning_rate": 1.284831601128612e-05,
      "loss": 0.0005,
      "step": 50060
    },
    {
      "epoch": 5.3648344583735135,
      "grad_norm": 0.2480214685201645,
      "learning_rate": 1.2846887388835316e-05,
      "loss": 0.3362,
      "step": 50070
    },
    {
      "epoch": 5.365905925211615,
      "grad_norm": 0.000600192288402468,
      "learning_rate": 1.2845458766384515e-05,
      "loss": 0.0004,
      "step": 50080
    },
    {
      "epoch": 5.366977392049716,
      "grad_norm": 0.0018037472618743777,
      "learning_rate": 1.2844030143933711e-05,
      "loss": 0.0007,
      "step": 50090
    },
    {
      "epoch": 5.368048858887818,
      "grad_norm": 0.02002476528286934,
      "learning_rate": 1.284260152148291e-05,
      "loss": 0.1327,
      "step": 50100
    },
    {
      "epoch": 5.369120325725919,
      "grad_norm": 0.038175951689481735,
      "learning_rate": 1.2841172899032109e-05,
      "loss": 0.2296,
      "step": 50110
    },
    {
      "epoch": 5.37019179256402,
      "grad_norm": 0.001897383132018149,
      "learning_rate": 1.2839744276581308e-05,
      "loss": 0.1796,
      "step": 50120
    },
    {
      "epoch": 5.371263259402122,
      "grad_norm": 0.014181230217218399,
      "learning_rate": 1.2838315654130507e-05,
      "loss": 0.2239,
      "step": 50130
    },
    {
      "epoch": 5.372334726240223,
      "grad_norm": 0.03293653950095177,
      "learning_rate": 1.2836887031679703e-05,
      "loss": 0.2481,
      "step": 50140
    },
    {
      "epoch": 5.373406193078324,
      "grad_norm": 0.01158063393086195,
      "learning_rate": 1.2835458409228903e-05,
      "loss": 0.105,
      "step": 50150
    },
    {
      "epoch": 5.374477659916425,
      "grad_norm": 0.0006538082961924374,
      "learning_rate": 1.2834029786778099e-05,
      "loss": 0.001,
      "step": 50160
    },
    {
      "epoch": 5.375549126754527,
      "grad_norm": 0.021608712151646614,
      "learning_rate": 1.2832601164327298e-05,
      "loss": 0.1907,
      "step": 50170
    },
    {
      "epoch": 5.376620593592628,
      "grad_norm": 0.009543524123728275,
      "learning_rate": 1.2831172541876497e-05,
      "loss": 0.125,
      "step": 50180
    },
    {
      "epoch": 5.3776920604307294,
      "grad_norm": 0.0004147423605900258,
      "learning_rate": 1.2829743919425695e-05,
      "loss": 0.1156,
      "step": 50190
    },
    {
      "epoch": 5.3787635272688314,
      "grad_norm": 0.33399835228919983,
      "learning_rate": 1.2828315296974894e-05,
      "loss": 0.3274,
      "step": 50200
    },
    {
      "epoch": 5.3798349941069326,
      "grad_norm": 0.5752665400505066,
      "learning_rate": 1.282688667452409e-05,
      "loss": 0.0011,
      "step": 50210
    },
    {
      "epoch": 5.380906460945034,
      "grad_norm": 0.00027158105513080955,
      "learning_rate": 1.282545805207329e-05,
      "loss": 0.0002,
      "step": 50220
    },
    {
      "epoch": 5.381977927783135,
      "grad_norm": 0.006279048044234514,
      "learning_rate": 1.2824029429622487e-05,
      "loss": 0.0005,
      "step": 50230
    },
    {
      "epoch": 5.383049394621237,
      "grad_norm": 0.00015766928845550865,
      "learning_rate": 1.2822600807171685e-05,
      "loss": 0.0012,
      "step": 50240
    },
    {
      "epoch": 5.384120861459338,
      "grad_norm": 0.00039899154216982424,
      "learning_rate": 1.2821172184720884e-05,
      "loss": 0.1079,
      "step": 50250
    },
    {
      "epoch": 5.385192328297439,
      "grad_norm": 0.00926960352808237,
      "learning_rate": 1.2819743562270082e-05,
      "loss": 0.0017,
      "step": 50260
    },
    {
      "epoch": 5.386263795135541,
      "grad_norm": 0.21479429304599762,
      "learning_rate": 1.2818314939819281e-05,
      "loss": 0.7566,
      "step": 50270
    },
    {
      "epoch": 5.387335261973642,
      "grad_norm": 0.03552770987153053,
      "learning_rate": 1.2816886317368477e-05,
      "loss": 0.0002,
      "step": 50280
    },
    {
      "epoch": 5.388406728811743,
      "grad_norm": 0.03956378251314163,
      "learning_rate": 1.2815457694917677e-05,
      "loss": 0.1918,
      "step": 50290
    },
    {
      "epoch": 5.389478195649844,
      "grad_norm": 0.004584577400237322,
      "learning_rate": 1.2814029072466876e-05,
      "loss": 0.1904,
      "step": 50300
    },
    {
      "epoch": 5.390549662487946,
      "grad_norm": 0.005486758891493082,
      "learning_rate": 1.2812600450016072e-05,
      "loss": 0.0004,
      "step": 50310
    },
    {
      "epoch": 5.391621129326047,
      "grad_norm": 0.38664743304252625,
      "learning_rate": 1.2811171827565271e-05,
      "loss": 0.0016,
      "step": 50320
    },
    {
      "epoch": 5.3926925961641485,
      "grad_norm": 0.058379486203193665,
      "learning_rate": 1.280974320511447e-05,
      "loss": 0.0009,
      "step": 50330
    },
    {
      "epoch": 5.39376406300225,
      "grad_norm": 0.05173574388027191,
      "learning_rate": 1.2808314582663669e-05,
      "loss": 0.3452,
      "step": 50340
    },
    {
      "epoch": 5.394835529840352,
      "grad_norm": 0.0026973870117217302,
      "learning_rate": 1.2806885960212865e-05,
      "loss": 0.0049,
      "step": 50350
    },
    {
      "epoch": 5.395906996678453,
      "grad_norm": 0.004202909301966429,
      "learning_rate": 1.2805457337762064e-05,
      "loss": 0.1231,
      "step": 50360
    },
    {
      "epoch": 5.396978463516554,
      "grad_norm": 0.035392481833696365,
      "learning_rate": 1.2804028715311263e-05,
      "loss": 0.2158,
      "step": 50370
    },
    {
      "epoch": 5.398049930354656,
      "grad_norm": 0.04947453737258911,
      "learning_rate": 1.280260009286046e-05,
      "loss": 0.2249,
      "step": 50380
    },
    {
      "epoch": 5.399121397192757,
      "grad_norm": 0.5525447130203247,
      "learning_rate": 1.2801171470409659e-05,
      "loss": 0.0813,
      "step": 50390
    },
    {
      "epoch": 5.400192864030858,
      "grad_norm": 0.0015308517031371593,
      "learning_rate": 1.2799742847958856e-05,
      "loss": 0.0019,
      "step": 50400
    },
    {
      "epoch": 5.40126433086896,
      "grad_norm": 0.046832866966724396,
      "learning_rate": 1.2798314225508056e-05,
      "loss": 0.0003,
      "step": 50410
    },
    {
      "epoch": 5.402335797707061,
      "grad_norm": 0.0010894262231886387,
      "learning_rate": 1.2796885603057253e-05,
      "loss": 0.0003,
      "step": 50420
    },
    {
      "epoch": 5.403407264545162,
      "grad_norm": 84.08858489990234,
      "learning_rate": 1.2795456980606451e-05,
      "loss": 0.1185,
      "step": 50430
    },
    {
      "epoch": 5.404478731383263,
      "grad_norm": 20.75157356262207,
      "learning_rate": 1.279402835815565e-05,
      "loss": 0.1333,
      "step": 50440
    },
    {
      "epoch": 5.405550198221365,
      "grad_norm": 13.81787109375,
      "learning_rate": 1.2792599735704846e-05,
      "loss": 0.2138,
      "step": 50450
    },
    {
      "epoch": 5.4066216650594665,
      "grad_norm": 0.03313404694199562,
      "learning_rate": 1.2791171113254046e-05,
      "loss": 0.0003,
      "step": 50460
    },
    {
      "epoch": 5.407693131897568,
      "grad_norm": 0.03558453917503357,
      "learning_rate": 1.2789742490803243e-05,
      "loss": 0.0009,
      "step": 50470
    },
    {
      "epoch": 5.408764598735669,
      "grad_norm": 0.026862051337957382,
      "learning_rate": 1.2788313868352443e-05,
      "loss": 0.1451,
      "step": 50480
    },
    {
      "epoch": 5.409836065573771,
      "grad_norm": 0.002150975400581956,
      "learning_rate": 1.2786885245901642e-05,
      "loss": 0.4954,
      "step": 50490
    },
    {
      "epoch": 5.410907532411872,
      "grad_norm": 0.035479698330163956,
      "learning_rate": 1.2785456623450838e-05,
      "loss": 0.1141,
      "step": 50500
    },
    {
      "epoch": 5.411978999249973,
      "grad_norm": 11.970192909240723,
      "learning_rate": 1.2784028001000037e-05,
      "loss": 0.2112,
      "step": 50510
    },
    {
      "epoch": 5.413050466088075,
      "grad_norm": 0.06855091452598572,
      "learning_rate": 1.2782599378549233e-05,
      "loss": 0.1456,
      "step": 50520
    },
    {
      "epoch": 5.414121932926176,
      "grad_norm": 15.744190216064453,
      "learning_rate": 1.2781170756098433e-05,
      "loss": 0.1603,
      "step": 50530
    },
    {
      "epoch": 5.415193399764277,
      "grad_norm": 12.22726821899414,
      "learning_rate": 1.2779742133647632e-05,
      "loss": 0.0135,
      "step": 50540
    },
    {
      "epoch": 5.416264866602378,
      "grad_norm": 0.0014363061636686325,
      "learning_rate": 1.277831351119683e-05,
      "loss": 0.0044,
      "step": 50550
    },
    {
      "epoch": 5.41733633344048,
      "grad_norm": 0.10170824080705643,
      "learning_rate": 1.277688488874603e-05,
      "loss": 0.0056,
      "step": 50560
    },
    {
      "epoch": 5.418407800278581,
      "grad_norm": 0.0008535588858649135,
      "learning_rate": 1.2775456266295225e-05,
      "loss": 0.0208,
      "step": 50570
    },
    {
      "epoch": 5.4194792671166825,
      "grad_norm": 0.0015814796788617969,
      "learning_rate": 1.2774027643844425e-05,
      "loss": 0.0008,
      "step": 50580
    },
    {
      "epoch": 5.4205507339547845,
      "grad_norm": 23.108675003051758,
      "learning_rate": 1.277259902139362e-05,
      "loss": 0.2715,
      "step": 50590
    },
    {
      "epoch": 5.421622200792886,
      "grad_norm": 0.08454807102680206,
      "learning_rate": 1.277117039894282e-05,
      "loss": 0.1056,
      "step": 50600
    },
    {
      "epoch": 5.422693667630987,
      "grad_norm": 0.0013026874512434006,
      "learning_rate": 1.276974177649202e-05,
      "loss": 0.2419,
      "step": 50610
    },
    {
      "epoch": 5.423765134469088,
      "grad_norm": 0.0011611510999500751,
      "learning_rate": 1.2768313154041217e-05,
      "loss": 0.0009,
      "step": 50620
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 29.010210037231445,
      "learning_rate": 1.2766884531590416e-05,
      "loss": 0.1275,
      "step": 50630
    },
    {
      "epoch": 5.425908068145291,
      "grad_norm": 24.711397171020508,
      "learning_rate": 1.2765455909139612e-05,
      "loss": 0.1834,
      "step": 50640
    },
    {
      "epoch": 5.426979534983392,
      "grad_norm": 0.0012508253566920757,
      "learning_rate": 1.2764027286688812e-05,
      "loss": 0.0266,
      "step": 50650
    },
    {
      "epoch": 5.428051001821494,
      "grad_norm": 0.00233699893578887,
      "learning_rate": 1.2762598664238011e-05,
      "loss": 0.0018,
      "step": 50660
    },
    {
      "epoch": 5.429122468659595,
      "grad_norm": 0.002838189946487546,
      "learning_rate": 1.2761170041787207e-05,
      "loss": 0.0011,
      "step": 50670
    },
    {
      "epoch": 5.430193935497696,
      "grad_norm": 0.0012254464672878385,
      "learning_rate": 1.2759741419336406e-05,
      "loss": 0.0003,
      "step": 50680
    },
    {
      "epoch": 5.431265402335797,
      "grad_norm": 0.011387517675757408,
      "learning_rate": 1.2758312796885604e-05,
      "loss": 0.186,
      "step": 50690
    },
    {
      "epoch": 5.432336869173899,
      "grad_norm": 0.0011418691137805581,
      "learning_rate": 1.2756884174434803e-05,
      "loss": 0.0143,
      "step": 50700
    },
    {
      "epoch": 5.4334083360120005,
      "grad_norm": 0.0008122892468236387,
      "learning_rate": 1.2755455551984e-05,
      "loss": 0.1923,
      "step": 50710
    },
    {
      "epoch": 5.434479802850102,
      "grad_norm": 0.0009414410451427102,
      "learning_rate": 1.2754026929533199e-05,
      "loss": 0.3356,
      "step": 50720
    },
    {
      "epoch": 5.435551269688203,
      "grad_norm": 0.004217649810016155,
      "learning_rate": 1.2752598307082398e-05,
      "loss": 0.0026,
      "step": 50730
    },
    {
      "epoch": 5.436622736526305,
      "grad_norm": 0.000588217459153384,
      "learning_rate": 1.2751169684631594e-05,
      "loss": 0.1471,
      "step": 50740
    },
    {
      "epoch": 5.437694203364406,
      "grad_norm": 12.691061973571777,
      "learning_rate": 1.2749741062180793e-05,
      "loss": 0.2794,
      "step": 50750
    },
    {
      "epoch": 5.438765670202507,
      "grad_norm": 0.09073631465435028,
      "learning_rate": 1.2748312439729991e-05,
      "loss": 0.0011,
      "step": 50760
    },
    {
      "epoch": 5.439837137040609,
      "grad_norm": 0.0007029848638921976,
      "learning_rate": 1.274688381727919e-05,
      "loss": 0.0011,
      "step": 50770
    },
    {
      "epoch": 5.44090860387871,
      "grad_norm": 0.11801330745220184,
      "learning_rate": 1.2745455194828386e-05,
      "loss": 0.3383,
      "step": 50780
    },
    {
      "epoch": 5.441980070716811,
      "grad_norm": 0.0031129566486924887,
      "learning_rate": 1.2744026572377586e-05,
      "loss": 0.3579,
      "step": 50790
    },
    {
      "epoch": 5.443051537554913,
      "grad_norm": 0.15098294615745544,
      "learning_rate": 1.2742597949926785e-05,
      "loss": 0.2892,
      "step": 50800
    },
    {
      "epoch": 5.444123004393014,
      "grad_norm": 0.08637179434299469,
      "learning_rate": 1.2741169327475981e-05,
      "loss": 0.0011,
      "step": 50810
    },
    {
      "epoch": 5.445194471231115,
      "grad_norm": 0.0009460625005885959,
      "learning_rate": 1.273974070502518e-05,
      "loss": 0.0015,
      "step": 50820
    },
    {
      "epoch": 5.446265938069216,
      "grad_norm": 0.04796605929732323,
      "learning_rate": 1.2738312082574378e-05,
      "loss": 0.3446,
      "step": 50830
    },
    {
      "epoch": 5.447337404907318,
      "grad_norm": 0.0005414750776253641,
      "learning_rate": 1.2736883460123578e-05,
      "loss": 0.083,
      "step": 50840
    },
    {
      "epoch": 5.4484088717454195,
      "grad_norm": 0.06918064504861832,
      "learning_rate": 1.2735454837672775e-05,
      "loss": 0.1835,
      "step": 50850
    },
    {
      "epoch": 5.449480338583521,
      "grad_norm": 0.00044450617861002684,
      "learning_rate": 1.2734026215221973e-05,
      "loss": 0.0007,
      "step": 50860
    },
    {
      "epoch": 5.450551805421622,
      "grad_norm": 0.06395862996578217,
      "learning_rate": 1.2732597592771172e-05,
      "loss": 0.3419,
      "step": 50870
    },
    {
      "epoch": 5.451623272259724,
      "grad_norm": 0.0006516947178170085,
      "learning_rate": 1.2731168970320368e-05,
      "loss": 0.0008,
      "step": 50880
    },
    {
      "epoch": 5.452694739097825,
      "grad_norm": 0.7857012152671814,
      "learning_rate": 1.2729740347869568e-05,
      "loss": 0.2215,
      "step": 50890
    },
    {
      "epoch": 5.453766205935926,
      "grad_norm": 0.039953187108039856,
      "learning_rate": 1.2728311725418765e-05,
      "loss": 0.0005,
      "step": 50900
    },
    {
      "epoch": 5.454837672774028,
      "grad_norm": 0.0009879518765956163,
      "learning_rate": 1.2726883102967965e-05,
      "loss": 0.1958,
      "step": 50910
    },
    {
      "epoch": 5.455909139612129,
      "grad_norm": 0.0011176783591508865,
      "learning_rate": 1.2725454480517162e-05,
      "loss": 0.0007,
      "step": 50920
    },
    {
      "epoch": 5.45698060645023,
      "grad_norm": 0.012014458887279034,
      "learning_rate": 1.272402585806636e-05,
      "loss": 0.0033,
      "step": 50930
    },
    {
      "epoch": 5.458052073288332,
      "grad_norm": 0.1268037110567093,
      "learning_rate": 1.272259723561556e-05,
      "loss": 0.0016,
      "step": 50940
    },
    {
      "epoch": 5.459123540126433,
      "grad_norm": 0.04873984307050705,
      "learning_rate": 1.2721168613164755e-05,
      "loss": 0.0536,
      "step": 50950
    },
    {
      "epoch": 5.460195006964534,
      "grad_norm": 0.03454700484871864,
      "learning_rate": 1.2719739990713955e-05,
      "loss": 0.001,
      "step": 50960
    },
    {
      "epoch": 5.4612664738026355,
      "grad_norm": 0.012902497313916683,
      "learning_rate": 1.2718311368263154e-05,
      "loss": 0.3424,
      "step": 50970
    },
    {
      "epoch": 5.4623379406407375,
      "grad_norm": 0.014556224457919598,
      "learning_rate": 1.2716882745812352e-05,
      "loss": 0.0011,
      "step": 50980
    },
    {
      "epoch": 5.463409407478839,
      "grad_norm": 0.002792060375213623,
      "learning_rate": 1.271545412336155e-05,
      "loss": 0.1417,
      "step": 50990
    },
    {
      "epoch": 5.46448087431694,
      "grad_norm": 0.017688963562250137,
      "learning_rate": 1.2714025500910747e-05,
      "loss": 0.0003,
      "step": 51000
    },
    {
      "epoch": 5.465552341155041,
      "grad_norm": 0.020190469920635223,
      "learning_rate": 1.2712596878459946e-05,
      "loss": 0.1677,
      "step": 51010
    },
    {
      "epoch": 5.466623807993143,
      "grad_norm": 0.0026504395063966513,
      "learning_rate": 1.2711168256009142e-05,
      "loss": 0.2818,
      "step": 51020
    },
    {
      "epoch": 5.467695274831244,
      "grad_norm": 0.11046113073825836,
      "learning_rate": 1.2709739633558342e-05,
      "loss": 0.0005,
      "step": 51030
    },
    {
      "epoch": 5.468766741669345,
      "grad_norm": 0.054333265870809555,
      "learning_rate": 1.2708311011107541e-05,
      "loss": 0.0017,
      "step": 51040
    },
    {
      "epoch": 5.469838208507447,
      "grad_norm": 16.462602615356445,
      "learning_rate": 1.2706882388656739e-05,
      "loss": 0.3813,
      "step": 51050
    },
    {
      "epoch": 5.470909675345548,
      "grad_norm": 0.0018236610339954495,
      "learning_rate": 1.2705453766205938e-05,
      "loss": 0.2357,
      "step": 51060
    },
    {
      "epoch": 5.471981142183649,
      "grad_norm": 0.04470452666282654,
      "learning_rate": 1.2704025143755134e-05,
      "loss": 0.1168,
      "step": 51070
    },
    {
      "epoch": 5.47305260902175,
      "grad_norm": 0.03599877282977104,
      "learning_rate": 1.2702596521304334e-05,
      "loss": 0.1581,
      "step": 51080
    },
    {
      "epoch": 5.474124075859852,
      "grad_norm": 0.017507430166006088,
      "learning_rate": 1.2701167898853533e-05,
      "loss": 0.0005,
      "step": 51090
    },
    {
      "epoch": 5.4751955426979535,
      "grad_norm": 0.06535468995571136,
      "learning_rate": 1.2699739276402729e-05,
      "loss": 0.0004,
      "step": 51100
    },
    {
      "epoch": 5.476267009536055,
      "grad_norm": 0.0022770820651203394,
      "learning_rate": 1.2698310653951928e-05,
      "loss": 0.0006,
      "step": 51110
    },
    {
      "epoch": 5.477338476374157,
      "grad_norm": 0.002047341549769044,
      "learning_rate": 1.2696882031501126e-05,
      "loss": 0.0002,
      "step": 51120
    },
    {
      "epoch": 5.478409943212258,
      "grad_norm": 0.028406253084540367,
      "learning_rate": 1.2695453409050325e-05,
      "loss": 0.001,
      "step": 51130
    },
    {
      "epoch": 5.479481410050359,
      "grad_norm": 0.0008884418639354408,
      "learning_rate": 1.2694024786599521e-05,
      "loss": 0.0006,
      "step": 51140
    },
    {
      "epoch": 5.48055287688846,
      "grad_norm": 0.0031699843239039183,
      "learning_rate": 1.269259616414872e-05,
      "loss": 0.0003,
      "step": 51150
    },
    {
      "epoch": 5.481624343726562,
      "grad_norm": 0.000621077255345881,
      "learning_rate": 1.269116754169792e-05,
      "loss": 0.2021,
      "step": 51160
    },
    {
      "epoch": 5.482695810564663,
      "grad_norm": 16.34282684326172,
      "learning_rate": 1.2689738919247116e-05,
      "loss": 0.1589,
      "step": 51170
    },
    {
      "epoch": 5.483767277402764,
      "grad_norm": 0.0004204894066788256,
      "learning_rate": 1.2688310296796315e-05,
      "loss": 0.1566,
      "step": 51180
    },
    {
      "epoch": 5.484838744240866,
      "grad_norm": 16.58376693725586,
      "learning_rate": 1.2686881674345513e-05,
      "loss": 0.1863,
      "step": 51190
    },
    {
      "epoch": 5.485910211078967,
      "grad_norm": 11.593549728393555,
      "learning_rate": 1.2685453051894712e-05,
      "loss": 0.0192,
      "step": 51200
    },
    {
      "epoch": 5.486981677917068,
      "grad_norm": 0.00812556128948927,
      "learning_rate": 1.268402442944391e-05,
      "loss": 0.0002,
      "step": 51210
    },
    {
      "epoch": 5.4880531447551695,
      "grad_norm": 0.04517129063606262,
      "learning_rate": 1.2682595806993108e-05,
      "loss": 0.0004,
      "step": 51220
    },
    {
      "epoch": 5.4891246115932715,
      "grad_norm": 0.0006757177761755884,
      "learning_rate": 1.2681167184542307e-05,
      "loss": 0.2293,
      "step": 51230
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 7.169068813323975,
      "learning_rate": 1.2679738562091503e-05,
      "loss": 0.0023,
      "step": 51240
    },
    {
      "epoch": 5.491267545269474,
      "grad_norm": 0.0005581761943176389,
      "learning_rate": 1.2678309939640702e-05,
      "loss": 0.0007,
      "step": 51250
    },
    {
      "epoch": 5.492339012107575,
      "grad_norm": 0.03821002319455147,
      "learning_rate": 1.26768813171899e-05,
      "loss": 0.0005,
      "step": 51260
    },
    {
      "epoch": 5.493410478945677,
      "grad_norm": 0.03378696367144585,
      "learning_rate": 1.26754526947391e-05,
      "loss": 0.4097,
      "step": 51270
    },
    {
      "epoch": 5.494481945783778,
      "grad_norm": 0.0004304642789065838,
      "learning_rate": 1.2674024072288297e-05,
      "loss": 0.0002,
      "step": 51280
    },
    {
      "epoch": 5.495553412621879,
      "grad_norm": 0.0010512343142181635,
      "learning_rate": 1.2672595449837495e-05,
      "loss": 0.133,
      "step": 51290
    },
    {
      "epoch": 5.496624879459981,
      "grad_norm": 0.00170691788662225,
      "learning_rate": 1.2671166827386694e-05,
      "loss": 0.0078,
      "step": 51300
    },
    {
      "epoch": 5.497696346298082,
      "grad_norm": 0.0007181043038144708,
      "learning_rate": 1.266973820493589e-05,
      "loss": 0.0091,
      "step": 51310
    },
    {
      "epoch": 5.498767813136183,
      "grad_norm": 0.0006011872901581228,
      "learning_rate": 1.266830958248509e-05,
      "loss": 0.0005,
      "step": 51320
    },
    {
      "epoch": 5.499839279974285,
      "grad_norm": 0.03544227406382561,
      "learning_rate": 1.2666880960034289e-05,
      "loss": 0.1665,
      "step": 51330
    },
    {
      "epoch": 5.500910746812386,
      "grad_norm": 0.02791404165327549,
      "learning_rate": 1.2665452337583487e-05,
      "loss": 0.3473,
      "step": 51340
    },
    {
      "epoch": 5.5019822136504875,
      "grad_norm": 0.00075994071085006,
      "learning_rate": 1.2664023715132684e-05,
      "loss": 0.0004,
      "step": 51350
    },
    {
      "epoch": 5.503053680488589,
      "grad_norm": 0.0006295167841017246,
      "learning_rate": 1.2662595092681882e-05,
      "loss": 0.0001,
      "step": 51360
    },
    {
      "epoch": 5.504125147326691,
      "grad_norm": 0.00045782310189679265,
      "learning_rate": 1.2661166470231081e-05,
      "loss": 0.0004,
      "step": 51370
    },
    {
      "epoch": 5.505196614164792,
      "grad_norm": 0.0007335054106079042,
      "learning_rate": 1.2659737847780277e-05,
      "loss": 0.0002,
      "step": 51380
    },
    {
      "epoch": 5.506268081002893,
      "grad_norm": 0.000642973929643631,
      "learning_rate": 1.2658309225329477e-05,
      "loss": 0.0001,
      "step": 51390
    },
    {
      "epoch": 5.507339547840994,
      "grad_norm": 0.05216514319181442,
      "learning_rate": 1.2656880602878676e-05,
      "loss": 0.2118,
      "step": 51400
    },
    {
      "epoch": 5.508411014679096,
      "grad_norm": 0.001000150223262608,
      "learning_rate": 1.2655451980427874e-05,
      "loss": 0.0001,
      "step": 51410
    },
    {
      "epoch": 5.509482481517197,
      "grad_norm": 0.000677040487062186,
      "learning_rate": 1.2654023357977071e-05,
      "loss": 0.2616,
      "step": 51420
    },
    {
      "epoch": 5.510553948355298,
      "grad_norm": 0.0014112700009718537,
      "learning_rate": 1.2652594735526269e-05,
      "loss": 0.0256,
      "step": 51430
    },
    {
      "epoch": 5.5116254151934,
      "grad_norm": 0.001127653056755662,
      "learning_rate": 1.2651166113075468e-05,
      "loss": 0.4447,
      "step": 51440
    },
    {
      "epoch": 5.512696882031501,
      "grad_norm": 24.782726287841797,
      "learning_rate": 1.2649737490624668e-05,
      "loss": 0.1793,
      "step": 51450
    },
    {
      "epoch": 5.513768348869602,
      "grad_norm": 0.014207965694367886,
      "learning_rate": 1.2648308868173864e-05,
      "loss": 0.2644,
      "step": 51460
    },
    {
      "epoch": 5.514839815707704,
      "grad_norm": 0.023686539381742477,
      "learning_rate": 1.2646880245723063e-05,
      "loss": 0.0012,
      "step": 51470
    },
    {
      "epoch": 5.515911282545805,
      "grad_norm": 0.05741056427359581,
      "learning_rate": 1.264545162327226e-05,
      "loss": 0.0005,
      "step": 51480
    },
    {
      "epoch": 5.5169827493839065,
      "grad_norm": 0.014926688745617867,
      "learning_rate": 1.2644023000821458e-05,
      "loss": 0.193,
      "step": 51490
    },
    {
      "epoch": 5.518054216222008,
      "grad_norm": 0.0036500494461506605,
      "learning_rate": 1.2642594378370656e-05,
      "loss": 0.3964,
      "step": 51500
    },
    {
      "epoch": 5.51912568306011,
      "grad_norm": 0.023959681391716003,
      "learning_rate": 1.2641165755919856e-05,
      "loss": 0.2333,
      "step": 51510
    },
    {
      "epoch": 5.520197149898211,
      "grad_norm": 0.05527519807219505,
      "learning_rate": 1.2639737133469055e-05,
      "loss": 0.1373,
      "step": 51520
    },
    {
      "epoch": 5.521268616736312,
      "grad_norm": 0.002127109793946147,
      "learning_rate": 1.2638308511018251e-05,
      "loss": 0.101,
      "step": 51530
    },
    {
      "epoch": 5.522340083574413,
      "grad_norm": 0.003005868988111615,
      "learning_rate": 1.263687988856745e-05,
      "loss": 0.0116,
      "step": 51540
    },
    {
      "epoch": 5.523411550412515,
      "grad_norm": 0.010511823929846287,
      "learning_rate": 1.2635451266116648e-05,
      "loss": 0.0005,
      "step": 51550
    },
    {
      "epoch": 5.524483017250616,
      "grad_norm": 0.002394006121903658,
      "learning_rate": 1.2634022643665847e-05,
      "loss": 0.0004,
      "step": 51560
    },
    {
      "epoch": 5.525554484088717,
      "grad_norm": 0.0013243610737845302,
      "learning_rate": 1.2632594021215045e-05,
      "loss": 0.0005,
      "step": 51570
    },
    {
      "epoch": 5.526625950926819,
      "grad_norm": 0.0020255951676517725,
      "learning_rate": 1.2631165398764243e-05,
      "loss": 0.2062,
      "step": 51580
    },
    {
      "epoch": 5.52769741776492,
      "grad_norm": 0.0050638411194086075,
      "learning_rate": 1.2629736776313442e-05,
      "loss": 0.2054,
      "step": 51590
    },
    {
      "epoch": 5.528768884603021,
      "grad_norm": 0.047659970819950104,
      "learning_rate": 1.2628308153862638e-05,
      "loss": 0.0007,
      "step": 51600
    },
    {
      "epoch": 5.5298403514411225,
      "grad_norm": 0.030449850484728813,
      "learning_rate": 1.2626879531411837e-05,
      "loss": 0.1111,
      "step": 51610
    },
    {
      "epoch": 5.5309118182792245,
      "grad_norm": 0.049871545284986496,
      "learning_rate": 1.2625450908961035e-05,
      "loss": 0.0003,
      "step": 51620
    },
    {
      "epoch": 5.531983285117326,
      "grad_norm": 0.0012838122202083468,
      "learning_rate": 1.2624022286510234e-05,
      "loss": 0.1025,
      "step": 51630
    },
    {
      "epoch": 5.533054751955427,
      "grad_norm": 0.00061347073642537,
      "learning_rate": 1.2622593664059432e-05,
      "loss": 0.0008,
      "step": 51640
    },
    {
      "epoch": 5.534126218793529,
      "grad_norm": 0.01067152339965105,
      "learning_rate": 1.262116504160863e-05,
      "loss": 0.0007,
      "step": 51650
    },
    {
      "epoch": 5.53519768563163,
      "grad_norm": 0.00032978670787997544,
      "learning_rate": 1.2619736419157829e-05,
      "loss": 0.0018,
      "step": 51660
    },
    {
      "epoch": 5.536269152469731,
      "grad_norm": 0.02059789188206196,
      "learning_rate": 1.2618307796707025e-05,
      "loss": 0.0012,
      "step": 51670
    },
    {
      "epoch": 5.537340619307832,
      "grad_norm": 0.00039423673297278583,
      "learning_rate": 1.2616879174256224e-05,
      "loss": 0.0002,
      "step": 51680
    },
    {
      "epoch": 5.538412086145934,
      "grad_norm": 0.025409555062651634,
      "learning_rate": 1.2615450551805422e-05,
      "loss": 0.0001,
      "step": 51690
    },
    {
      "epoch": 5.539483552984035,
      "grad_norm": 0.00027578917797654867,
      "learning_rate": 1.2614021929354621e-05,
      "loss": 0.0015,
      "step": 51700
    },
    {
      "epoch": 5.540555019822136,
      "grad_norm": 0.014097335748374462,
      "learning_rate": 1.2612593306903819e-05,
      "loss": 0.0003,
      "step": 51710
    },
    {
      "epoch": 5.541626486660238,
      "grad_norm": 0.0004813942068722099,
      "learning_rate": 1.2611164684453017e-05,
      "loss": 0.0001,
      "step": 51720
    },
    {
      "epoch": 5.542697953498339,
      "grad_norm": 0.00035520229721441865,
      "learning_rate": 1.2609736062002216e-05,
      "loss": 0.2179,
      "step": 51730
    },
    {
      "epoch": 5.5437694203364405,
      "grad_norm": 0.019353803247213364,
      "learning_rate": 1.2608307439551412e-05,
      "loss": 0.0002,
      "step": 51740
    },
    {
      "epoch": 5.544840887174542,
      "grad_norm": 0.001520806341432035,
      "learning_rate": 1.2606878817100612e-05,
      "loss": 0.1653,
      "step": 51750
    },
    {
      "epoch": 5.545912354012644,
      "grad_norm": 0.014235316775739193,
      "learning_rate": 1.2605450194649811e-05,
      "loss": 0.0005,
      "step": 51760
    },
    {
      "epoch": 5.546983820850745,
      "grad_norm": 0.07794693857431412,
      "learning_rate": 1.2604021572199009e-05,
      "loss": 0.0597,
      "step": 51770
    },
    {
      "epoch": 5.548055287688846,
      "grad_norm": 42.27865982055664,
      "learning_rate": 1.2602592949748206e-05,
      "loss": 0.3045,
      "step": 51780
    },
    {
      "epoch": 5.549126754526947,
      "grad_norm": 0.0009311916655860841,
      "learning_rate": 1.2601164327297404e-05,
      "loss": 0.1051,
      "step": 51790
    },
    {
      "epoch": 5.550198221365049,
      "grad_norm": 0.021844755858182907,
      "learning_rate": 1.2599735704846603e-05,
      "loss": 0.2378,
      "step": 51800
    },
    {
      "epoch": 5.55126968820315,
      "grad_norm": 0.0052594877779483795,
      "learning_rate": 1.25983070823958e-05,
      "loss": 0.0002,
      "step": 51810
    },
    {
      "epoch": 5.552341155041251,
      "grad_norm": 0.0017553326906636357,
      "learning_rate": 1.2596878459944999e-05,
      "loss": 0.0005,
      "step": 51820
    },
    {
      "epoch": 5.553412621879353,
      "grad_norm": 0.5807799100875854,
      "learning_rate": 1.2595449837494198e-05,
      "loss": 0.0005,
      "step": 51830
    },
    {
      "epoch": 5.554484088717454,
      "grad_norm": 0.011645497754216194,
      "learning_rate": 1.2594021215043396e-05,
      "loss": 0.0001,
      "step": 51840
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.0009999271715059876,
      "learning_rate": 1.2592592592592593e-05,
      "loss": 0.0002,
      "step": 51850
    },
    {
      "epoch": 5.556627022393657,
      "grad_norm": 0.015440006740391254,
      "learning_rate": 1.2591163970141791e-05,
      "loss": 0.1791,
      "step": 51860
    },
    {
      "epoch": 5.5576984892317585,
      "grad_norm": 0.0054393052123487,
      "learning_rate": 1.258973534769099e-05,
      "loss": 0.6513,
      "step": 51870
    },
    {
      "epoch": 5.55876995606986,
      "grad_norm": 0.020384561270475388,
      "learning_rate": 1.258830672524019e-05,
      "loss": 0.2813,
      "step": 51880
    },
    {
      "epoch": 5.559841422907961,
      "grad_norm": 0.002045262372121215,
      "learning_rate": 1.2586878102789386e-05,
      "loss": 0.1856,
      "step": 51890
    },
    {
      "epoch": 5.560912889746063,
      "grad_norm": 1.0949931144714355,
      "learning_rate": 1.2585449480338585e-05,
      "loss": 0.0023,
      "step": 51900
    },
    {
      "epoch": 5.561984356584164,
      "grad_norm": 0.002677476266399026,
      "learning_rate": 1.2584020857887783e-05,
      "loss": 0.0829,
      "step": 51910
    },
    {
      "epoch": 5.563055823422265,
      "grad_norm": 0.37753745913505554,
      "learning_rate": 1.258259223543698e-05,
      "loss": 0.175,
      "step": 51920
    },
    {
      "epoch": 5.564127290260366,
      "grad_norm": 0.023115787655115128,
      "learning_rate": 1.2581163612986178e-05,
      "loss": 0.0002,
      "step": 51930
    },
    {
      "epoch": 5.565198757098468,
      "grad_norm": 0.026505347341299057,
      "learning_rate": 1.2579734990535377e-05,
      "loss": 0.0005,
      "step": 51940
    },
    {
      "epoch": 5.566270223936569,
      "grad_norm": 0.0005028107552789152,
      "learning_rate": 1.2578306368084577e-05,
      "loss": 0.0003,
      "step": 51950
    },
    {
      "epoch": 5.56734169077467,
      "grad_norm": 0.0010714656673371792,
      "learning_rate": 1.2576877745633773e-05,
      "loss": 0.153,
      "step": 51960
    },
    {
      "epoch": 5.568413157612772,
      "grad_norm": 0.00045716293971054256,
      "learning_rate": 1.2575449123182972e-05,
      "loss": 0.0922,
      "step": 51970
    },
    {
      "epoch": 5.569484624450873,
      "grad_norm": 0.00047917853225953877,
      "learning_rate": 1.257402050073217e-05,
      "loss": 0.0002,
      "step": 51980
    },
    {
      "epoch": 5.570556091288974,
      "grad_norm": 27.6702938079834,
      "learning_rate": 1.2572591878281368e-05,
      "loss": 0.2047,
      "step": 51990
    },
    {
      "epoch": 5.571627558127076,
      "grad_norm": 0.04489815980195999,
      "learning_rate": 1.2571163255830567e-05,
      "loss": 0.1195,
      "step": 52000
    },
    {
      "epoch": 5.5726990249651775,
      "grad_norm": 0.04128701612353325,
      "learning_rate": 1.2569734633379765e-05,
      "loss": 0.0042,
      "step": 52010
    },
    {
      "epoch": 5.573770491803279,
      "grad_norm": 0.0011518303072080016,
      "learning_rate": 1.2568306010928964e-05,
      "loss": 0.2029,
      "step": 52020
    },
    {
      "epoch": 5.57484195864138,
      "grad_norm": 0.00021607328380923718,
      "learning_rate": 1.256687738847816e-05,
      "loss": 0.0045,
      "step": 52030
    },
    {
      "epoch": 5.575913425479482,
      "grad_norm": 0.0004826970980502665,
      "learning_rate": 1.256544876602736e-05,
      "loss": 0.0062,
      "step": 52040
    },
    {
      "epoch": 5.576984892317583,
      "grad_norm": 0.00029239343712106347,
      "learning_rate": 1.2564020143576557e-05,
      "loss": 0.0012,
      "step": 52050
    },
    {
      "epoch": 5.578056359155684,
      "grad_norm": 0.0003092957194894552,
      "learning_rate": 1.2562591521125755e-05,
      "loss": 0.0008,
      "step": 52060
    },
    {
      "epoch": 5.579127825993785,
      "grad_norm": 0.00019395600247662514,
      "learning_rate": 1.2561162898674954e-05,
      "loss": 0.0007,
      "step": 52070
    },
    {
      "epoch": 5.580199292831887,
      "grad_norm": 0.04212897643446922,
      "learning_rate": 1.2559734276224152e-05,
      "loss": 0.1557,
      "step": 52080
    },
    {
      "epoch": 5.581270759669988,
      "grad_norm": 0.00013153630425222218,
      "learning_rate": 1.2558305653773351e-05,
      "loss": 0.0002,
      "step": 52090
    },
    {
      "epoch": 5.582342226508089,
      "grad_norm": 0.00019174418412148952,
      "learning_rate": 1.2556877031322547e-05,
      "loss": 0.0001,
      "step": 52100
    },
    {
      "epoch": 5.583413693346191,
      "grad_norm": 0.0001320109295193106,
      "learning_rate": 1.2555448408871746e-05,
      "loss": 0.0002,
      "step": 52110
    },
    {
      "epoch": 5.584485160184292,
      "grad_norm": 0.020274490118026733,
      "learning_rate": 1.2554019786420946e-05,
      "loss": 0.3087,
      "step": 52120
    },
    {
      "epoch": 5.5855566270223935,
      "grad_norm": 0.00029824982630088925,
      "learning_rate": 1.2552591163970143e-05,
      "loss": 0.0003,
      "step": 52130
    },
    {
      "epoch": 5.586628093860495,
      "grad_norm": 0.02973615936934948,
      "learning_rate": 1.2551162541519341e-05,
      "loss": 0.0004,
      "step": 52140
    },
    {
      "epoch": 5.587699560698597,
      "grad_norm": 0.27299967408180237,
      "learning_rate": 1.2549733919068539e-05,
      "loss": 0.0006,
      "step": 52150
    },
    {
      "epoch": 5.588771027536698,
      "grad_norm": 0.0001669785415288061,
      "learning_rate": 1.2548305296617738e-05,
      "loss": 0.1176,
      "step": 52160
    },
    {
      "epoch": 5.589842494374799,
      "grad_norm": 0.01990523375570774,
      "learning_rate": 1.2546876674166934e-05,
      "loss": 0.0006,
      "step": 52170
    },
    {
      "epoch": 5.5909139612129,
      "grad_norm": 0.028874734416604042,
      "learning_rate": 1.2545448051716133e-05,
      "loss": 0.2106,
      "step": 52180
    },
    {
      "epoch": 5.591985428051002,
      "grad_norm": 20.859230041503906,
      "learning_rate": 1.2544019429265333e-05,
      "loss": 0.5147,
      "step": 52190
    },
    {
      "epoch": 5.593056894889103,
      "grad_norm": 0.03291642293334007,
      "learning_rate": 1.254259080681453e-05,
      "loss": 0.0003,
      "step": 52200
    },
    {
      "epoch": 5.594128361727204,
      "grad_norm": 0.0005836228374391794,
      "learning_rate": 1.2541162184363728e-05,
      "loss": 0.0005,
      "step": 52210
    },
    {
      "epoch": 5.595199828565306,
      "grad_norm": 0.23372331261634827,
      "learning_rate": 1.2539733561912926e-05,
      "loss": 0.1924,
      "step": 52220
    },
    {
      "epoch": 5.596271295403407,
      "grad_norm": 0.035491328686475754,
      "learning_rate": 1.2538304939462125e-05,
      "loss": 0.0773,
      "step": 52230
    },
    {
      "epoch": 5.597342762241508,
      "grad_norm": 0.0008933923090808094,
      "learning_rate": 1.2536876317011325e-05,
      "loss": 0.0008,
      "step": 52240
    },
    {
      "epoch": 5.59841422907961,
      "grad_norm": 0.0003838385746348649,
      "learning_rate": 1.253544769456052e-05,
      "loss": 0.2602,
      "step": 52250
    },
    {
      "epoch": 5.5994856959177115,
      "grad_norm": 0.0006019725697115064,
      "learning_rate": 1.253401907210972e-05,
      "loss": 0.0009,
      "step": 52260
    },
    {
      "epoch": 5.600557162755813,
      "grad_norm": 0.030461439862847328,
      "learning_rate": 1.2532590449658918e-05,
      "loss": 0.0004,
      "step": 52270
    },
    {
      "epoch": 5.601628629593914,
      "grad_norm": 0.030772821977734566,
      "learning_rate": 1.2531161827208115e-05,
      "loss": 0.1508,
      "step": 52280
    },
    {
      "epoch": 5.602700096432016,
      "grad_norm": 0.0011194993276149035,
      "learning_rate": 1.2529733204757313e-05,
      "loss": 0.0006,
      "step": 52290
    },
    {
      "epoch": 5.603771563270117,
      "grad_norm": 0.0015838727122172713,
      "learning_rate": 1.2528304582306512e-05,
      "loss": 0.1623,
      "step": 52300
    },
    {
      "epoch": 5.604843030108218,
      "grad_norm": 0.11510506272315979,
      "learning_rate": 1.2526875959855712e-05,
      "loss": 0.0004,
      "step": 52310
    },
    {
      "epoch": 5.605914496946319,
      "grad_norm": 0.022635864093899727,
      "learning_rate": 1.2525447337404908e-05,
      "loss": 0.1505,
      "step": 52320
    },
    {
      "epoch": 5.606985963784421,
      "grad_norm": 0.33201202750205994,
      "learning_rate": 1.2524018714954107e-05,
      "loss": 0.093,
      "step": 52330
    },
    {
      "epoch": 5.608057430622522,
      "grad_norm": 0.21308492124080658,
      "learning_rate": 1.2522590092503305e-05,
      "loss": 0.2055,
      "step": 52340
    },
    {
      "epoch": 5.609128897460623,
      "grad_norm": 0.0007918082410469651,
      "learning_rate": 1.2521161470052502e-05,
      "loss": 0.0003,
      "step": 52350
    },
    {
      "epoch": 5.610200364298725,
      "grad_norm": 0.0026220318395644426,
      "learning_rate": 1.2519732847601702e-05,
      "loss": 0.0001,
      "step": 52360
    },
    {
      "epoch": 5.611271831136826,
      "grad_norm": 0.0008274688734672964,
      "learning_rate": 1.25183042251509e-05,
      "loss": 0.2795,
      "step": 52370
    },
    {
      "epoch": 5.6123432979749275,
      "grad_norm": 0.0008211320964619517,
      "learning_rate": 1.2516875602700099e-05,
      "loss": 0.0098,
      "step": 52380
    },
    {
      "epoch": 5.6134147648130295,
      "grad_norm": 0.0435444600880146,
      "learning_rate": 1.2515446980249295e-05,
      "loss": 0.4673,
      "step": 52390
    },
    {
      "epoch": 5.614486231651131,
      "grad_norm": 0.070552758872509,
      "learning_rate": 1.2514018357798494e-05,
      "loss": 0.3922,
      "step": 52400
    },
    {
      "epoch": 5.615557698489232,
      "grad_norm": 0.02488422393798828,
      "learning_rate": 1.2512589735347692e-05,
      "loss": 0.0002,
      "step": 52410
    },
    {
      "epoch": 5.616629165327333,
      "grad_norm": 0.015028523281216621,
      "learning_rate": 1.251116111289689e-05,
      "loss": 0.0007,
      "step": 52420
    },
    {
      "epoch": 5.617700632165435,
      "grad_norm": 0.0008609016076661646,
      "learning_rate": 1.2509732490446089e-05,
      "loss": 0.0003,
      "step": 52430
    },
    {
      "epoch": 5.618772099003536,
      "grad_norm": 0.0009065771009773016,
      "learning_rate": 1.2508303867995286e-05,
      "loss": 0.0004,
      "step": 52440
    },
    {
      "epoch": 5.619843565841637,
      "grad_norm": 0.0005789982387796044,
      "learning_rate": 1.2506875245544486e-05,
      "loss": 0.1494,
      "step": 52450
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 0.00041459116619080305,
      "learning_rate": 1.2505446623093682e-05,
      "loss": 0.0005,
      "step": 52460
    },
    {
      "epoch": 5.62198649951784,
      "grad_norm": 0.08142895996570587,
      "learning_rate": 1.2504018000642881e-05,
      "loss": 0.0015,
      "step": 52470
    },
    {
      "epoch": 5.623057966355941,
      "grad_norm": 0.05967181921005249,
      "learning_rate": 1.250258937819208e-05,
      "loss": 0.2046,
      "step": 52480
    },
    {
      "epoch": 5.624129433194042,
      "grad_norm": 0.00042952640797011554,
      "learning_rate": 1.2501160755741277e-05,
      "loss": 0.0001,
      "step": 52490
    },
    {
      "epoch": 5.625200900032144,
      "grad_norm": 0.0002868493611458689,
      "learning_rate": 1.2499732133290476e-05,
      "loss": 0.0954,
      "step": 52500
    },
    {
      "epoch": 5.6262723668702455,
      "grad_norm": 25.1812686920166,
      "learning_rate": 1.2498303510839674e-05,
      "loss": 0.1161,
      "step": 52510
    },
    {
      "epoch": 5.627343833708347,
      "grad_norm": 0.06044445559382439,
      "learning_rate": 1.2496874888388873e-05,
      "loss": 0.5613,
      "step": 52520
    },
    {
      "epoch": 5.628415300546449,
      "grad_norm": 30.952850341796875,
      "learning_rate": 1.2495446265938069e-05,
      "loss": 0.3016,
      "step": 52530
    },
    {
      "epoch": 5.62948676738455,
      "grad_norm": 0.004515906795859337,
      "learning_rate": 1.2494017643487268e-05,
      "loss": 0.0005,
      "step": 52540
    },
    {
      "epoch": 5.630558234222651,
      "grad_norm": 0.0006811562925577164,
      "learning_rate": 1.2492589021036468e-05,
      "loss": 0.0003,
      "step": 52550
    },
    {
      "epoch": 5.631629701060752,
      "grad_norm": 0.0015304948901757598,
      "learning_rate": 1.2491160398585664e-05,
      "loss": 0.1171,
      "step": 52560
    },
    {
      "epoch": 5.632701167898854,
      "grad_norm": 0.0006868759519420564,
      "learning_rate": 1.2489731776134863e-05,
      "loss": 0.0009,
      "step": 52570
    },
    {
      "epoch": 5.633772634736955,
      "grad_norm": 0.0006886909832246602,
      "learning_rate": 1.248830315368406e-05,
      "loss": 0.1359,
      "step": 52580
    },
    {
      "epoch": 5.634844101575056,
      "grad_norm": 0.0010722001316025853,
      "learning_rate": 1.248687453123326e-05,
      "loss": 0.0212,
      "step": 52590
    },
    {
      "epoch": 5.635915568413157,
      "grad_norm": 0.02123812772333622,
      "learning_rate": 1.2485445908782456e-05,
      "loss": 0.1759,
      "step": 52600
    },
    {
      "epoch": 5.636987035251259,
      "grad_norm": 0.07150745391845703,
      "learning_rate": 1.2484017286331655e-05,
      "loss": 0.0006,
      "step": 52610
    },
    {
      "epoch": 5.63805850208936,
      "grad_norm": 0.00025967150577344,
      "learning_rate": 1.2482588663880855e-05,
      "loss": 0.001,
      "step": 52620
    },
    {
      "epoch": 5.639129968927461,
      "grad_norm": 90.66679382324219,
      "learning_rate": 1.248116004143005e-05,
      "loss": 0.1457,
      "step": 52630
    },
    {
      "epoch": 5.640201435765563,
      "grad_norm": 0.0025778424460440874,
      "learning_rate": 1.247973141897925e-05,
      "loss": 0.1616,
      "step": 52640
    },
    {
      "epoch": 5.6412729026036645,
      "grad_norm": 0.0003348330792505294,
      "learning_rate": 1.2478302796528448e-05,
      "loss": 0.0654,
      "step": 52650
    },
    {
      "epoch": 5.642344369441766,
      "grad_norm": 0.0008256396395154297,
      "learning_rate": 1.2476874174077647e-05,
      "loss": 0.0016,
      "step": 52660
    },
    {
      "epoch": 5.643415836279867,
      "grad_norm": 0.0006988852983340621,
      "learning_rate": 1.2475445551626847e-05,
      "loss": 0.0009,
      "step": 52670
    },
    {
      "epoch": 5.644487303117969,
      "grad_norm": 0.0002731698041316122,
      "learning_rate": 1.2474016929176042e-05,
      "loss": 0.0002,
      "step": 52680
    },
    {
      "epoch": 5.64555876995607,
      "grad_norm": 0.019884854555130005,
      "learning_rate": 1.2472588306725242e-05,
      "loss": 0.0005,
      "step": 52690
    },
    {
      "epoch": 5.646630236794171,
      "grad_norm": 0.0012946665519848466,
      "learning_rate": 1.247115968427444e-05,
      "loss": 0.0001,
      "step": 52700
    },
    {
      "epoch": 5.647701703632272,
      "grad_norm": 0.0005468422896228731,
      "learning_rate": 1.2469731061823637e-05,
      "loss": 0.0003,
      "step": 52710
    },
    {
      "epoch": 5.648773170470374,
      "grad_norm": 0.03620012104511261,
      "learning_rate": 1.2468302439372835e-05,
      "loss": 0.0003,
      "step": 52720
    },
    {
      "epoch": 5.649844637308475,
      "grad_norm": 0.05245180055499077,
      "learning_rate": 1.2466873816922034e-05,
      "loss": 0.0022,
      "step": 52730
    },
    {
      "epoch": 5.650916104146576,
      "grad_norm": 0.03879356011748314,
      "learning_rate": 1.2465445194471234e-05,
      "loss": 0.4254,
      "step": 52740
    },
    {
      "epoch": 5.651987570984678,
      "grad_norm": 0.00047082966193556786,
      "learning_rate": 1.246401657202043e-05,
      "loss": 0.3407,
      "step": 52750
    },
    {
      "epoch": 5.653059037822779,
      "grad_norm": 0.022940155118703842,
      "learning_rate": 1.2462587949569629e-05,
      "loss": 0.1445,
      "step": 52760
    },
    {
      "epoch": 5.6541305046608805,
      "grad_norm": 0.0005659791058860719,
      "learning_rate": 1.2461159327118827e-05,
      "loss": 0.0006,
      "step": 52770
    },
    {
      "epoch": 5.6552019714989825,
      "grad_norm": 0.02751753106713295,
      "learning_rate": 1.2459730704668024e-05,
      "loss": 0.21,
      "step": 52780
    },
    {
      "epoch": 5.656273438337084,
      "grad_norm": 0.0005632241955026984,
      "learning_rate": 1.2458302082217224e-05,
      "loss": 0.0006,
      "step": 52790
    },
    {
      "epoch": 5.657344905175185,
      "grad_norm": 0.014484918676316738,
      "learning_rate": 1.2456873459766421e-05,
      "loss": 0.0005,
      "step": 52800
    },
    {
      "epoch": 5.658416372013286,
      "grad_norm": 0.0008993263472802937,
      "learning_rate": 1.245544483731562e-05,
      "loss": 0.0003,
      "step": 52810
    },
    {
      "epoch": 5.659487838851388,
      "grad_norm": 0.0006328064482659101,
      "learning_rate": 1.2454016214864817e-05,
      "loss": 0.0001,
      "step": 52820
    },
    {
      "epoch": 5.660559305689489,
      "grad_norm": 0.03318071737885475,
      "learning_rate": 1.2452587592414016e-05,
      "loss": 0.0005,
      "step": 52830
    },
    {
      "epoch": 5.66163077252759,
      "grad_norm": 0.00039015247602947056,
      "learning_rate": 1.2451158969963214e-05,
      "loss": 0.0004,
      "step": 52840
    },
    {
      "epoch": 5.662702239365691,
      "grad_norm": 0.001972310012206435,
      "learning_rate": 1.2449730347512411e-05,
      "loss": 0.0003,
      "step": 52850
    },
    {
      "epoch": 5.663773706203793,
      "grad_norm": 75.35527801513672,
      "learning_rate": 1.244830172506161e-05,
      "loss": 0.2916,
      "step": 52860
    },
    {
      "epoch": 5.664845173041894,
      "grad_norm": 0.000261628651060164,
      "learning_rate": 1.2446873102610808e-05,
      "loss": 0.1383,
      "step": 52870
    },
    {
      "epoch": 5.665916639879995,
      "grad_norm": 0.0006524702766910195,
      "learning_rate": 1.2445444480160008e-05,
      "loss": 0.0005,
      "step": 52880
    },
    {
      "epoch": 5.666988106718097,
      "grad_norm": 0.0008750436245463789,
      "learning_rate": 1.2444015857709204e-05,
      "loss": 0.3381,
      "step": 52890
    },
    {
      "epoch": 5.6680595735561985,
      "grad_norm": 0.0005105030722916126,
      "learning_rate": 1.2442587235258403e-05,
      "loss": 0.0002,
      "step": 52900
    },
    {
      "epoch": 5.6691310403943,
      "grad_norm": 0.0008234030101448298,
      "learning_rate": 1.2441158612807602e-05,
      "loss": 0.0043,
      "step": 52910
    },
    {
      "epoch": 5.670202507232402,
      "grad_norm": 0.055300645530223846,
      "learning_rate": 1.2439729990356798e-05,
      "loss": 0.0004,
      "step": 52920
    },
    {
      "epoch": 5.671273974070503,
      "grad_norm": 0.015289455652236938,
      "learning_rate": 1.2438301367905998e-05,
      "loss": 0.0001,
      "step": 52930
    },
    {
      "epoch": 5.672345440908604,
      "grad_norm": 0.00038777297595515847,
      "learning_rate": 1.2436872745455196e-05,
      "loss": 0.0003,
      "step": 52940
    },
    {
      "epoch": 5.673416907746705,
      "grad_norm": 0.01763872615993023,
      "learning_rate": 1.2435444123004395e-05,
      "loss": 0.0003,
      "step": 52950
    },
    {
      "epoch": 5.674488374584807,
      "grad_norm": 0.013901342637836933,
      "learning_rate": 1.2434015500553591e-05,
      "loss": 0.0002,
      "step": 52960
    },
    {
      "epoch": 5.675559841422908,
      "grad_norm": 0.0003268652653787285,
      "learning_rate": 1.243258687810279e-05,
      "loss": 0.0001,
      "step": 52970
    },
    {
      "epoch": 5.676631308261009,
      "grad_norm": 0.017630964517593384,
      "learning_rate": 1.243115825565199e-05,
      "loss": 0.0007,
      "step": 52980
    },
    {
      "epoch": 5.67770277509911,
      "grad_norm": 0.0003996945742983371,
      "learning_rate": 1.2429729633201186e-05,
      "loss": 0.0001,
      "step": 52990
    },
    {
      "epoch": 5.678774241937212,
      "grad_norm": 0.010721038095653057,
      "learning_rate": 1.2428301010750385e-05,
      "loss": 0.1506,
      "step": 53000
    },
    {
      "epoch": 5.679845708775313,
      "grad_norm": 0.018146350979804993,
      "learning_rate": 1.2426872388299583e-05,
      "loss": 0.2211,
      "step": 53010
    },
    {
      "epoch": 5.6809171756134145,
      "grad_norm": 0.000629618123639375,
      "learning_rate": 1.2425443765848782e-05,
      "loss": 0.7284,
      "step": 53020
    },
    {
      "epoch": 5.6819886424515165,
      "grad_norm": 0.26716628670692444,
      "learning_rate": 1.2424015143397981e-05,
      "loss": 0.2065,
      "step": 53030
    },
    {
      "epoch": 5.683060109289618,
      "grad_norm": 0.030137283727526665,
      "learning_rate": 1.2422586520947177e-05,
      "loss": 0.0109,
      "step": 53040
    },
    {
      "epoch": 5.684131576127719,
      "grad_norm": 0.0016452261479571462,
      "learning_rate": 1.2421157898496377e-05,
      "loss": 0.0973,
      "step": 53050
    },
    {
      "epoch": 5.685203042965821,
      "grad_norm": 0.20718811452388763,
      "learning_rate": 1.2419729276045573e-05,
      "loss": 0.0011,
      "step": 53060
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 0.1403731256723404,
      "learning_rate": 1.2418300653594772e-05,
      "loss": 0.0004,
      "step": 53070
    },
    {
      "epoch": 5.687345976642023,
      "grad_norm": 0.027169352397322655,
      "learning_rate": 1.241687203114397e-05,
      "loss": 0.0004,
      "step": 53080
    },
    {
      "epoch": 5.688417443480124,
      "grad_norm": 28.462858200073242,
      "learning_rate": 1.2415443408693169e-05,
      "loss": 0.2437,
      "step": 53090
    },
    {
      "epoch": 5.689488910318226,
      "grad_norm": 19.907392501831055,
      "learning_rate": 1.2414014786242368e-05,
      "loss": 0.0064,
      "step": 53100
    },
    {
      "epoch": 5.690560377156327,
      "grad_norm": 0.0014422920066863298,
      "learning_rate": 1.2412586163791564e-05,
      "loss": 0.1232,
      "step": 53110
    },
    {
      "epoch": 5.691631843994428,
      "grad_norm": 0.001219159341417253,
      "learning_rate": 1.2411157541340764e-05,
      "loss": 0.0003,
      "step": 53120
    },
    {
      "epoch": 5.692703310832529,
      "grad_norm": 0.006147762294858694,
      "learning_rate": 1.240972891888996e-05,
      "loss": 0.0004,
      "step": 53130
    },
    {
      "epoch": 5.693774777670631,
      "grad_norm": 0.01576656475663185,
      "learning_rate": 1.2408300296439159e-05,
      "loss": 0.0006,
      "step": 53140
    },
    {
      "epoch": 5.6948462445087324,
      "grad_norm": 0.0028922297060489655,
      "learning_rate": 1.2406871673988358e-05,
      "loss": 0.0005,
      "step": 53150
    },
    {
      "epoch": 5.695917711346834,
      "grad_norm": 0.0005606058984994888,
      "learning_rate": 1.2405443051537556e-05,
      "loss": 0.0006,
      "step": 53160
    },
    {
      "epoch": 5.6969891781849356,
      "grad_norm": 0.011620759963989258,
      "learning_rate": 1.2404014429086756e-05,
      "loss": 0.0002,
      "step": 53170
    },
    {
      "epoch": 5.698060645023037,
      "grad_norm": 0.01289997436106205,
      "learning_rate": 1.2402585806635952e-05,
      "loss": 0.0001,
      "step": 53180
    },
    {
      "epoch": 5.699132111861138,
      "grad_norm": 0.000833060359582305,
      "learning_rate": 1.2401157184185151e-05,
      "loss": 0.0001,
      "step": 53190
    },
    {
      "epoch": 5.700203578699239,
      "grad_norm": 0.0005476523656398058,
      "learning_rate": 1.2399728561734347e-05,
      "loss": 0.0408,
      "step": 53200
    },
    {
      "epoch": 5.701275045537341,
      "grad_norm": 0.0005244424683041871,
      "learning_rate": 1.2398299939283546e-05,
      "loss": 0.0298,
      "step": 53210
    },
    {
      "epoch": 5.702346512375442,
      "grad_norm": 0.0003852368681691587,
      "learning_rate": 1.2396871316832746e-05,
      "loss": 0.0002,
      "step": 53220
    },
    {
      "epoch": 5.703417979213543,
      "grad_norm": 0.006114967633038759,
      "learning_rate": 1.2395442694381943e-05,
      "loss": 0.0002,
      "step": 53230
    },
    {
      "epoch": 5.704489446051644,
      "grad_norm": 0.0008676480501890182,
      "learning_rate": 1.2394014071931143e-05,
      "loss": 0.2113,
      "step": 53240
    },
    {
      "epoch": 5.705560912889746,
      "grad_norm": 0.0004152247274760157,
      "learning_rate": 1.2392585449480339e-05,
      "loss": 0.4303,
      "step": 53250
    },
    {
      "epoch": 5.706632379727847,
      "grad_norm": 0.0004046699614264071,
      "learning_rate": 1.2391156827029538e-05,
      "loss": 0.0002,
      "step": 53260
    },
    {
      "epoch": 5.707703846565948,
      "grad_norm": 0.0022891350090503693,
      "learning_rate": 1.2389728204578737e-05,
      "loss": 0.0001,
      "step": 53270
    },
    {
      "epoch": 5.70877531340405,
      "grad_norm": 0.000899237347766757,
      "learning_rate": 1.2388299582127933e-05,
      "loss": 0.1914,
      "step": 53280
    },
    {
      "epoch": 5.7098467802421515,
      "grad_norm": 0.023534346371889114,
      "learning_rate": 1.2386870959677133e-05,
      "loss": 0.0002,
      "step": 53290
    },
    {
      "epoch": 5.710918247080253,
      "grad_norm": 0.02151734009385109,
      "learning_rate": 1.238544233722633e-05,
      "loss": 0.1389,
      "step": 53300
    },
    {
      "epoch": 5.711989713918355,
      "grad_norm": 0.0017351714195683599,
      "learning_rate": 1.238401371477553e-05,
      "loss": 0.0002,
      "step": 53310
    },
    {
      "epoch": 5.713061180756456,
      "grad_norm": 0.01467351708561182,
      "learning_rate": 1.2382585092324726e-05,
      "loss": 0.1678,
      "step": 53320
    },
    {
      "epoch": 5.714132647594557,
      "grad_norm": 0.001761673716828227,
      "learning_rate": 1.2381156469873925e-05,
      "loss": 0.0002,
      "step": 53330
    },
    {
      "epoch": 5.715204114432658,
      "grad_norm": 0.005947563331574202,
      "learning_rate": 1.2379727847423124e-05,
      "loss": 0.0002,
      "step": 53340
    },
    {
      "epoch": 5.71627558127076,
      "grad_norm": 0.002156004775315523,
      "learning_rate": 1.237829922497232e-05,
      "loss": 0.0003,
      "step": 53350
    },
    {
      "epoch": 5.717347048108861,
      "grad_norm": 0.015118863433599472,
      "learning_rate": 1.237687060252152e-05,
      "loss": 0.0003,
      "step": 53360
    },
    {
      "epoch": 5.718418514946962,
      "grad_norm": 0.00043676450150087476,
      "learning_rate": 1.2375441980070717e-05,
      "loss": 0.2384,
      "step": 53370
    },
    {
      "epoch": 5.719489981785063,
      "grad_norm": 0.0007014970178715885,
      "learning_rate": 1.2374013357619917e-05,
      "loss": 0.3224,
      "step": 53380
    },
    {
      "epoch": 5.720561448623165,
      "grad_norm": 0.015244347974658012,
      "learning_rate": 1.2372584735169114e-05,
      "loss": 0.2731,
      "step": 53390
    },
    {
      "epoch": 5.721632915461266,
      "grad_norm": 0.06101794168353081,
      "learning_rate": 1.2371156112718312e-05,
      "loss": 0.0003,
      "step": 53400
    },
    {
      "epoch": 5.7227043822993675,
      "grad_norm": 0.029434673488140106,
      "learning_rate": 1.2369727490267512e-05,
      "loss": 0.1305,
      "step": 53410
    },
    {
      "epoch": 5.7237758491374695,
      "grad_norm": 34.34162902832031,
      "learning_rate": 1.2368298867816708e-05,
      "loss": 0.0128,
      "step": 53420
    },
    {
      "epoch": 5.724847315975571,
      "grad_norm": 0.022296426817774773,
      "learning_rate": 1.2366870245365907e-05,
      "loss": 0.0002,
      "step": 53430
    },
    {
      "epoch": 5.725918782813672,
      "grad_norm": 0.015136254951357841,
      "learning_rate": 1.2365441622915105e-05,
      "loss": 0.0003,
      "step": 53440
    },
    {
      "epoch": 5.726990249651774,
      "grad_norm": 0.03328606113791466,
      "learning_rate": 1.2364013000464304e-05,
      "loss": 0.1616,
      "step": 53450
    },
    {
      "epoch": 5.728061716489875,
      "grad_norm": 0.008031744509935379,
      "learning_rate": 1.2362584378013502e-05,
      "loss": 0.0004,
      "step": 53460
    },
    {
      "epoch": 5.729133183327976,
      "grad_norm": 0.038211219012737274,
      "learning_rate": 1.23611557555627e-05,
      "loss": 0.0004,
      "step": 53470
    },
    {
      "epoch": 5.730204650166077,
      "grad_norm": 0.009944121353328228,
      "learning_rate": 1.2359727133111899e-05,
      "loss": 0.2425,
      "step": 53480
    },
    {
      "epoch": 5.731276117004179,
      "grad_norm": 0.1281166970729828,
      "learning_rate": 1.2358298510661095e-05,
      "loss": 0.0424,
      "step": 53490
    },
    {
      "epoch": 5.73234758384228,
      "grad_norm": 0.03300956264138222,
      "learning_rate": 1.2356869888210294e-05,
      "loss": 0.3357,
      "step": 53500
    },
    {
      "epoch": 5.733419050680381,
      "grad_norm": 0.0044918367639184,
      "learning_rate": 1.2355441265759492e-05,
      "loss": 0.0218,
      "step": 53510
    },
    {
      "epoch": 5.734490517518482,
      "grad_norm": 0.01910240389406681,
      "learning_rate": 1.2354012643308691e-05,
      "loss": 0.0005,
      "step": 53520
    },
    {
      "epoch": 5.735561984356584,
      "grad_norm": 0.0015879133716225624,
      "learning_rate": 1.235258402085789e-05,
      "loss": 0.0001,
      "step": 53530
    },
    {
      "epoch": 5.7366334511946855,
      "grad_norm": 0.004243418574333191,
      "learning_rate": 1.2351155398407086e-05,
      "loss": 0.0001,
      "step": 53540
    },
    {
      "epoch": 5.737704918032787,
      "grad_norm": 0.00106927624437958,
      "learning_rate": 1.2349726775956286e-05,
      "loss": 0.0081,
      "step": 53550
    },
    {
      "epoch": 5.738776384870889,
      "grad_norm": 0.011464698240160942,
      "learning_rate": 1.2348298153505482e-05,
      "loss": 0.0004,
      "step": 53560
    },
    {
      "epoch": 5.73984785170899,
      "grad_norm": 0.0007774850237183273,
      "learning_rate": 1.2346869531054681e-05,
      "loss": 0.0002,
      "step": 53570
    },
    {
      "epoch": 5.740919318547091,
      "grad_norm": 0.01940200850367546,
      "learning_rate": 1.234544090860388e-05,
      "loss": 0.1468,
      "step": 53580
    },
    {
      "epoch": 5.741990785385193,
      "grad_norm": 0.0006645750836469233,
      "learning_rate": 1.2344012286153078e-05,
      "loss": 0.1254,
      "step": 53590
    },
    {
      "epoch": 5.743062252223294,
      "grad_norm": 0.005565210711210966,
      "learning_rate": 1.2342583663702277e-05,
      "loss": 0.001,
      "step": 53600
    },
    {
      "epoch": 5.744133719061395,
      "grad_norm": 0.020848529413342476,
      "learning_rate": 1.2341155041251473e-05,
      "loss": 0.0003,
      "step": 53610
    },
    {
      "epoch": 5.745205185899496,
      "grad_norm": 0.0008372415904887021,
      "learning_rate": 1.2339726418800673e-05,
      "loss": 0.0749,
      "step": 53620
    },
    {
      "epoch": 5.746276652737598,
      "grad_norm": 0.00041842309292405844,
      "learning_rate": 1.2338297796349869e-05,
      "loss": 0.197,
      "step": 53630
    },
    {
      "epoch": 5.747348119575699,
      "grad_norm": 0.006988662760704756,
      "learning_rate": 1.2336869173899068e-05,
      "loss": 0.0041,
      "step": 53640
    },
    {
      "epoch": 5.7484195864138,
      "grad_norm": 0.0007344313198700547,
      "learning_rate": 1.2335440551448268e-05,
      "loss": 0.0001,
      "step": 53650
    },
    {
      "epoch": 5.7494910532519015,
      "grad_norm": 0.0003917791473213583,
      "learning_rate": 1.2334011928997465e-05,
      "loss": 0.0199,
      "step": 53660
    },
    {
      "epoch": 5.7505625200900035,
      "grad_norm": 0.01277751475572586,
      "learning_rate": 1.2332583306546665e-05,
      "loss": 0.001,
      "step": 53670
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 0.02714972011744976,
      "learning_rate": 1.233115468409586e-05,
      "loss": 0.0002,
      "step": 53680
    },
    {
      "epoch": 5.752705453766206,
      "grad_norm": 0.0038065824192017317,
      "learning_rate": 1.232972606164506e-05,
      "loss": 0.0001,
      "step": 53690
    },
    {
      "epoch": 5.753776920604308,
      "grad_norm": 0.013408094644546509,
      "learning_rate": 1.232829743919426e-05,
      "loss": 0.4028,
      "step": 53700
    },
    {
      "epoch": 5.754848387442409,
      "grad_norm": 0.0912570059299469,
      "learning_rate": 1.2326868816743455e-05,
      "loss": 0.0001,
      "step": 53710
    },
    {
      "epoch": 5.75591985428051,
      "grad_norm": 63.63246536254883,
      "learning_rate": 1.2325440194292655e-05,
      "loss": 0.0172,
      "step": 53720
    },
    {
      "epoch": 5.756991321118611,
      "grad_norm": 0.0064764851704239845,
      "learning_rate": 1.2324011571841852e-05,
      "loss": 0.0002,
      "step": 53730
    },
    {
      "epoch": 5.758062787956713,
      "grad_norm": 0.0016604368574917316,
      "learning_rate": 1.2322582949391052e-05,
      "loss": 0.0645,
      "step": 53740
    },
    {
      "epoch": 5.759134254794814,
      "grad_norm": 0.002281577093526721,
      "learning_rate": 1.2321154326940248e-05,
      "loss": 0.0003,
      "step": 53750
    },
    {
      "epoch": 5.760205721632915,
      "grad_norm": 0.0009710498270578682,
      "learning_rate": 1.2319725704489447e-05,
      "loss": 0.0001,
      "step": 53760
    },
    {
      "epoch": 5.761277188471016,
      "grad_norm": 0.00643230602145195,
      "learning_rate": 1.2318297082038646e-05,
      "loss": 0.1528,
      "step": 53770
    },
    {
      "epoch": 5.762348655309118,
      "grad_norm": 0.0005055307992734015,
      "learning_rate": 1.2316868459587842e-05,
      "loss": 0.142,
      "step": 53780
    },
    {
      "epoch": 5.763420122147219,
      "grad_norm": 0.0033378074876964092,
      "learning_rate": 1.2315439837137042e-05,
      "loss": 0.1527,
      "step": 53790
    },
    {
      "epoch": 5.7644915889853205,
      "grad_norm": 1.561684250831604,
      "learning_rate": 1.231401121468624e-05,
      "loss": 0.1818,
      "step": 53800
    },
    {
      "epoch": 5.7655630558234225,
      "grad_norm": 0.0006167273968458176,
      "learning_rate": 1.2312582592235439e-05,
      "loss": 0.1909,
      "step": 53810
    },
    {
      "epoch": 5.766634522661524,
      "grad_norm": 0.0006803027936257422,
      "learning_rate": 1.2311153969784636e-05,
      "loss": 0.3938,
      "step": 53820
    },
    {
      "epoch": 5.767705989499625,
      "grad_norm": 0.00041903226519934833,
      "learning_rate": 1.2309725347333834e-05,
      "loss": 0.141,
      "step": 53830
    },
    {
      "epoch": 5.768777456337727,
      "grad_norm": 0.002159591531381011,
      "learning_rate": 1.2308296724883033e-05,
      "loss": 0.1332,
      "step": 53840
    },
    {
      "epoch": 5.769848923175828,
      "grad_norm": 0.0052740005776286125,
      "learning_rate": 1.230686810243223e-05,
      "loss": 0.3081,
      "step": 53850
    },
    {
      "epoch": 5.770920390013929,
      "grad_norm": 0.014154238626360893,
      "learning_rate": 1.2305439479981429e-05,
      "loss": 0.0042,
      "step": 53860
    },
    {
      "epoch": 5.77199185685203,
      "grad_norm": 0.049003079533576965,
      "learning_rate": 1.2304010857530626e-05,
      "loss": 0.0024,
      "step": 53870
    },
    {
      "epoch": 5.773063323690132,
      "grad_norm": 0.015404154546558857,
      "learning_rate": 1.2302582235079826e-05,
      "loss": 0.2287,
      "step": 53880
    },
    {
      "epoch": 5.774134790528233,
      "grad_norm": 0.025610316544771194,
      "learning_rate": 1.2301153612629024e-05,
      "loss": 0.0002,
      "step": 53890
    },
    {
      "epoch": 5.775206257366334,
      "grad_norm": 0.00019735729438252747,
      "learning_rate": 1.2299724990178221e-05,
      "loss": 0.1266,
      "step": 53900
    },
    {
      "epoch": 5.776277724204435,
      "grad_norm": 0.0004092395247425884,
      "learning_rate": 1.229829636772742e-05,
      "loss": 0.0004,
      "step": 53910
    },
    {
      "epoch": 5.777349191042537,
      "grad_norm": 0.01241146121174097,
      "learning_rate": 1.2296867745276617e-05,
      "loss": 0.0002,
      "step": 53920
    },
    {
      "epoch": 5.7784206578806385,
      "grad_norm": 0.0013079927302896976,
      "learning_rate": 1.2295439122825816e-05,
      "loss": 0.1777,
      "step": 53930
    },
    {
      "epoch": 5.77949212471874,
      "grad_norm": 0.009866761974990368,
      "learning_rate": 1.2294010500375015e-05,
      "loss": 0.0005,
      "step": 53940
    },
    {
      "epoch": 5.780563591556842,
      "grad_norm": 0.000295828387606889,
      "learning_rate": 1.2292581877924213e-05,
      "loss": 0.0487,
      "step": 53950
    },
    {
      "epoch": 5.781635058394943,
      "grad_norm": 0.00039253212162293494,
      "learning_rate": 1.229115325547341e-05,
      "loss": 0.223,
      "step": 53960
    },
    {
      "epoch": 5.782706525233044,
      "grad_norm": 0.0005831547896377742,
      "learning_rate": 1.2289724633022608e-05,
      "loss": 0.1655,
      "step": 53970
    },
    {
      "epoch": 5.783777992071146,
      "grad_norm": 0.028824806213378906,
      "learning_rate": 1.2288296010571808e-05,
      "loss": 0.0007,
      "step": 53980
    },
    {
      "epoch": 5.784849458909247,
      "grad_norm": 0.5235361456871033,
      "learning_rate": 1.2286867388121004e-05,
      "loss": 0.0013,
      "step": 53990
    },
    {
      "epoch": 5.785920925747348,
      "grad_norm": 0.01971135474741459,
      "learning_rate": 1.2285438765670203e-05,
      "loss": 0.0002,
      "step": 54000
    },
    {
      "epoch": 5.786992392585449,
      "grad_norm": 0.0016206632135435939,
      "learning_rate": 1.2284010143219402e-05,
      "loss": 0.0002,
      "step": 54010
    },
    {
      "epoch": 5.788063859423551,
      "grad_norm": 0.00022785547480452806,
      "learning_rate": 1.22825815207686e-05,
      "loss": 0.072,
      "step": 54020
    },
    {
      "epoch": 5.789135326261652,
      "grad_norm": 0.04875963181257248,
      "learning_rate": 1.2281152898317798e-05,
      "loss": 0.0013,
      "step": 54030
    },
    {
      "epoch": 5.790206793099753,
      "grad_norm": 0.00012953730765730143,
      "learning_rate": 1.2279724275866995e-05,
      "loss": 0.0001,
      "step": 54040
    },
    {
      "epoch": 5.7912782599378545,
      "grad_norm": 0.01904810033738613,
      "learning_rate": 1.2278295653416195e-05,
      "loss": 0.2471,
      "step": 54050
    },
    {
      "epoch": 5.7923497267759565,
      "grad_norm": 0.009474685415625572,
      "learning_rate": 1.2276867030965394e-05,
      "loss": 0.0007,
      "step": 54060
    },
    {
      "epoch": 5.793421193614058,
      "grad_norm": 0.00020210034563206136,
      "learning_rate": 1.227543840851459e-05,
      "loss": 0.0005,
      "step": 54070
    },
    {
      "epoch": 5.794492660452159,
      "grad_norm": 0.007329553831368685,
      "learning_rate": 1.227400978606379e-05,
      "loss": 0.0002,
      "step": 54080
    },
    {
      "epoch": 5.795564127290261,
      "grad_norm": 0.0012482180027291179,
      "learning_rate": 1.2272581163612987e-05,
      "loss": 0.0033,
      "step": 54090
    },
    {
      "epoch": 5.796635594128362,
      "grad_norm": 0.013061470352113247,
      "learning_rate": 1.2271152541162187e-05,
      "loss": 0.1799,
      "step": 54100
    },
    {
      "epoch": 5.797707060966463,
      "grad_norm": 0.00023750508262310177,
      "learning_rate": 1.2269723918711382e-05,
      "loss": 0.0659,
      "step": 54110
    },
    {
      "epoch": 5.798778527804565,
      "grad_norm": 0.00021268040291033685,
      "learning_rate": 1.2268295296260582e-05,
      "loss": 0.0007,
      "step": 54120
    },
    {
      "epoch": 5.799849994642666,
      "grad_norm": 0.01136979553848505,
      "learning_rate": 1.2266866673809781e-05,
      "loss": 0.1703,
      "step": 54130
    },
    {
      "epoch": 5.800921461480767,
      "grad_norm": 0.017941782251000404,
      "learning_rate": 1.2265438051358977e-05,
      "loss": 0.0003,
      "step": 54140
    },
    {
      "epoch": 5.801992928318868,
      "grad_norm": 0.017641011625528336,
      "learning_rate": 1.2264009428908177e-05,
      "loss": 0.0001,
      "step": 54150
    },
    {
      "epoch": 5.80306439515697,
      "grad_norm": 8.272687409771606e-05,
      "learning_rate": 1.2262580806457374e-05,
      "loss": 0.0001,
      "step": 54160
    },
    {
      "epoch": 5.804135861995071,
      "grad_norm": 0.0007193144410848618,
      "learning_rate": 1.2261152184006574e-05,
      "loss": 0.0001,
      "step": 54170
    },
    {
      "epoch": 5.8052073288331725,
      "grad_norm": 0.00013453024439513683,
      "learning_rate": 1.2259723561555771e-05,
      "loss": 0.0001,
      "step": 54180
    },
    {
      "epoch": 5.806278795671274,
      "grad_norm": 9.718984074424952e-05,
      "learning_rate": 1.2258294939104969e-05,
      "loss": 0.0001,
      "step": 54190
    },
    {
      "epoch": 5.807350262509376,
      "grad_norm": 0.00010501281940378249,
      "learning_rate": 1.2256866316654168e-05,
      "loss": 0.2394,
      "step": 54200
    },
    {
      "epoch": 5.808421729347477,
      "grad_norm": 0.00019958592019975185,
      "learning_rate": 1.2255437694203364e-05,
      "loss": 0.1965,
      "step": 54210
    },
    {
      "epoch": 5.809493196185578,
      "grad_norm": 0.0001021852731355466,
      "learning_rate": 1.2254009071752564e-05,
      "loss": 0.0942,
      "step": 54220
    },
    {
      "epoch": 5.81056466302368,
      "grad_norm": 0.00010324051982024685,
      "learning_rate": 1.2252580449301761e-05,
      "loss": 0.0002,
      "step": 54230
    },
    {
      "epoch": 5.811636129861781,
      "grad_norm": 0.00012496812269091606,
      "learning_rate": 1.225115182685096e-05,
      "loss": 0.0009,
      "step": 54240
    },
    {
      "epoch": 5.812707596699882,
      "grad_norm": 0.0001395348517689854,
      "learning_rate": 1.2249723204400158e-05,
      "loss": 0.0001,
      "step": 54250
    },
    {
      "epoch": 5.813779063537983,
      "grad_norm": 0.01925206370651722,
      "learning_rate": 1.2248294581949356e-05,
      "loss": 0.0003,
      "step": 54260
    },
    {
      "epoch": 5.814850530376085,
      "grad_norm": 0.00039234530413523316,
      "learning_rate": 1.2246865959498555e-05,
      "loss": 0.2056,
      "step": 54270
    },
    {
      "epoch": 5.815921997214186,
      "grad_norm": 0.00019750880892388523,
      "learning_rate": 1.2245437337047751e-05,
      "loss": 0.0915,
      "step": 54280
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 0.010315692983567715,
      "learning_rate": 1.224400871459695e-05,
      "loss": 0.0003,
      "step": 54290
    },
    {
      "epoch": 5.8180649308903885,
      "grad_norm": 0.0066368174739181995,
      "learning_rate": 1.224258009214615e-05,
      "loss": 0.0002,
      "step": 54300
    },
    {
      "epoch": 5.8191363977284905,
      "grad_norm": 0.003905247198417783,
      "learning_rate": 1.2241151469695348e-05,
      "loss": 0.0013,
      "step": 54310
    },
    {
      "epoch": 5.820207864566592,
      "grad_norm": 0.008968673646450043,
      "learning_rate": 1.2239722847244545e-05,
      "loss": 0.0001,
      "step": 54320
    },
    {
      "epoch": 5.821279331404693,
      "grad_norm": 0.00011336518218740821,
      "learning_rate": 1.2238294224793743e-05,
      "loss": 0.0,
      "step": 54330
    },
    {
      "epoch": 5.822350798242795,
      "grad_norm": 0.00013421392941381782,
      "learning_rate": 1.2236865602342943e-05,
      "loss": 0.0003,
      "step": 54340
    },
    {
      "epoch": 5.823422265080896,
      "grad_norm": 0.007268781308084726,
      "learning_rate": 1.2235436979892138e-05,
      "loss": 0.0001,
      "step": 54350
    },
    {
      "epoch": 5.824493731918997,
      "grad_norm": 18.74207305908203,
      "learning_rate": 1.2234008357441338e-05,
      "loss": 0.4343,
      "step": 54360
    },
    {
      "epoch": 5.825565198757099,
      "grad_norm": 0.00017934403149411082,
      "learning_rate": 1.2232579734990537e-05,
      "loss": 0.0002,
      "step": 54370
    },
    {
      "epoch": 5.8266366655952,
      "grad_norm": 0.002334061311557889,
      "learning_rate": 1.2231151112539735e-05,
      "loss": 0.0005,
      "step": 54380
    },
    {
      "epoch": 5.827708132433301,
      "grad_norm": 0.0020140318665653467,
      "learning_rate": 1.2229722490088933e-05,
      "loss": 0.2082,
      "step": 54390
    },
    {
      "epoch": 5.828779599271402,
      "grad_norm": 0.9171306490898132,
      "learning_rate": 1.222829386763813e-05,
      "loss": 0.001,
      "step": 54400
    },
    {
      "epoch": 5.829851066109504,
      "grad_norm": 0.3520849347114563,
      "learning_rate": 1.222686524518733e-05,
      "loss": 0.0009,
      "step": 54410
    },
    {
      "epoch": 5.830922532947605,
      "grad_norm": 0.010833649896085262,
      "learning_rate": 1.2225436622736526e-05,
      "loss": 0.1608,
      "step": 54420
    },
    {
      "epoch": 5.831993999785706,
      "grad_norm": 0.00011870389425894246,
      "learning_rate": 1.2224008000285725e-05,
      "loss": 0.0078,
      "step": 54430
    },
    {
      "epoch": 5.8330654666238075,
      "grad_norm": 0.015439333394169807,
      "learning_rate": 1.2222579377834924e-05,
      "loss": 0.4531,
      "step": 54440
    },
    {
      "epoch": 5.8341369334619095,
      "grad_norm": 0.02399090863764286,
      "learning_rate": 1.2221150755384122e-05,
      "loss": 0.0002,
      "step": 54450
    },
    {
      "epoch": 5.835208400300011,
      "grad_norm": 0.03942035138607025,
      "learning_rate": 1.221972213293332e-05,
      "loss": 0.1946,
      "step": 54460
    },
    {
      "epoch": 5.836279867138112,
      "grad_norm": 0.05131085589528084,
      "learning_rate": 1.2218293510482517e-05,
      "loss": 0.1681,
      "step": 54470
    },
    {
      "epoch": 5.837351333976214,
      "grad_norm": 0.00020274808048270643,
      "learning_rate": 1.2216864888031717e-05,
      "loss": 0.0103,
      "step": 54480
    },
    {
      "epoch": 5.838422800814315,
      "grad_norm": 0.04005512595176697,
      "learning_rate": 1.2215436265580916e-05,
      "loss": 0.2563,
      "step": 54490
    },
    {
      "epoch": 5.839494267652416,
      "grad_norm": 0.05420037731528282,
      "learning_rate": 1.2214007643130112e-05,
      "loss": 0.0006,
      "step": 54500
    },
    {
      "epoch": 5.840565734490518,
      "grad_norm": 0.04762975126504898,
      "learning_rate": 1.2212579020679311e-05,
      "loss": 0.0003,
      "step": 54510
    },
    {
      "epoch": 5.841637201328619,
      "grad_norm": 0.13014884293079376,
      "learning_rate": 1.2211150398228509e-05,
      "loss": 0.0012,
      "step": 54520
    },
    {
      "epoch": 5.84270866816672,
      "grad_norm": 0.04934059455990791,
      "learning_rate": 1.2209721775777707e-05,
      "loss": 0.167,
      "step": 54530
    },
    {
      "epoch": 5.843780135004821,
      "grad_norm": 0.02132660523056984,
      "learning_rate": 1.2208293153326904e-05,
      "loss": 0.0015,
      "step": 54540
    },
    {
      "epoch": 5.844851601842923,
      "grad_norm": 0.002130368025973439,
      "learning_rate": 1.2206864530876104e-05,
      "loss": 0.0001,
      "step": 54550
    },
    {
      "epoch": 5.845923068681024,
      "grad_norm": 0.27071914076805115,
      "learning_rate": 1.2205435908425303e-05,
      "loss": 0.0003,
      "step": 54560
    },
    {
      "epoch": 5.8469945355191255,
      "grad_norm": 0.00023703790793661028,
      "learning_rate": 1.2204007285974499e-05,
      "loss": 0.0002,
      "step": 54570
    },
    {
      "epoch": 5.848066002357227,
      "grad_norm": 0.0007853802526369691,
      "learning_rate": 1.2202578663523699e-05,
      "loss": 0.3346,
      "step": 54580
    },
    {
      "epoch": 5.849137469195329,
      "grad_norm": 20.739042282104492,
      "learning_rate": 1.2201150041072896e-05,
      "loss": 0.099,
      "step": 54590
    },
    {
      "epoch": 5.85020893603343,
      "grad_norm": 0.0003198250487912446,
      "learning_rate": 1.2199721418622094e-05,
      "loss": 0.0004,
      "step": 54600
    },
    {
      "epoch": 5.851280402871531,
      "grad_norm": 0.0001906287216115743,
      "learning_rate": 1.2198292796171293e-05,
      "loss": 0.2792,
      "step": 54610
    },
    {
      "epoch": 5.852351869709633,
      "grad_norm": 0.0005914602661505342,
      "learning_rate": 1.2196864173720491e-05,
      "loss": 0.1908,
      "step": 54620
    },
    {
      "epoch": 5.853423336547734,
      "grad_norm": 0.0004295096732676029,
      "learning_rate": 1.219543555126969e-05,
      "loss": 0.3006,
      "step": 54630
    },
    {
      "epoch": 5.854494803385835,
      "grad_norm": 0.0008434660267084837,
      "learning_rate": 1.2194006928818886e-05,
      "loss": 0.0883,
      "step": 54640
    },
    {
      "epoch": 5.855566270223937,
      "grad_norm": 0.011222870089113712,
      "learning_rate": 1.2192578306368086e-05,
      "loss": 0.0003,
      "step": 54650
    },
    {
      "epoch": 5.856637737062038,
      "grad_norm": 0.0009781447006389499,
      "learning_rate": 1.2191149683917283e-05,
      "loss": 0.2603,
      "step": 54660
    },
    {
      "epoch": 5.857709203900139,
      "grad_norm": 0.006123876664787531,
      "learning_rate": 1.2189721061466483e-05,
      "loss": 0.3424,
      "step": 54670
    },
    {
      "epoch": 5.85878067073824,
      "grad_norm": 0.009401830844581127,
      "learning_rate": 1.218829243901568e-05,
      "loss": 0.0003,
      "step": 54680
    },
    {
      "epoch": 5.859852137576342,
      "grad_norm": 0.011145103722810745,
      "learning_rate": 1.2186863816564878e-05,
      "loss": 0.1509,
      "step": 54690
    },
    {
      "epoch": 5.8609236044144435,
      "grad_norm": 0.0007668966427445412,
      "learning_rate": 1.2185435194114077e-05,
      "loss": 0.2625,
      "step": 54700
    },
    {
      "epoch": 5.861995071252545,
      "grad_norm": 0.0005986422766000032,
      "learning_rate": 1.2184006571663273e-05,
      "loss": 0.0011,
      "step": 54710
    },
    {
      "epoch": 5.863066538090646,
      "grad_norm": 0.00033209644607268274,
      "learning_rate": 1.2182577949212473e-05,
      "loss": 0.0003,
      "step": 54720
    },
    {
      "epoch": 5.864138004928748,
      "grad_norm": 0.011903484351933002,
      "learning_rate": 1.2181149326761672e-05,
      "loss": 0.0014,
      "step": 54730
    },
    {
      "epoch": 5.865209471766849,
      "grad_norm": 0.017249735072255135,
      "learning_rate": 1.217972070431087e-05,
      "loss": 0.1048,
      "step": 54740
    },
    {
      "epoch": 5.86628093860495,
      "grad_norm": 0.00027876708190888166,
      "learning_rate": 1.2178292081860067e-05,
      "loss": 0.1412,
      "step": 54750
    },
    {
      "epoch": 5.867352405443052,
      "grad_norm": 0.00019920161867048591,
      "learning_rate": 1.2176863459409265e-05,
      "loss": 0.0705,
      "step": 54760
    },
    {
      "epoch": 5.868423872281153,
      "grad_norm": 0.0032221926376223564,
      "learning_rate": 1.2175434836958464e-05,
      "loss": 0.0002,
      "step": 54770
    },
    {
      "epoch": 5.869495339119254,
      "grad_norm": 0.0026744622737169266,
      "learning_rate": 1.217400621450766e-05,
      "loss": 0.001,
      "step": 54780
    },
    {
      "epoch": 5.870566805957355,
      "grad_norm": 0.0006503484328277409,
      "learning_rate": 1.217257759205686e-05,
      "loss": 0.1183,
      "step": 54790
    },
    {
      "epoch": 5.871638272795457,
      "grad_norm": 0.000226292570005171,
      "learning_rate": 1.217114896960606e-05,
      "loss": 0.1386,
      "step": 54800
    },
    {
      "epoch": 5.872709739633558,
      "grad_norm": 0.0001822921767598018,
      "learning_rate": 1.2169720347155257e-05,
      "loss": 0.0402,
      "step": 54810
    },
    {
      "epoch": 5.8737812064716595,
      "grad_norm": 0.0011321952333673835,
      "learning_rate": 1.2168291724704455e-05,
      "loss": 0.0001,
      "step": 54820
    },
    {
      "epoch": 5.874852673309761,
      "grad_norm": 0.00043833706877194345,
      "learning_rate": 1.2166863102253652e-05,
      "loss": 0.0002,
      "step": 54830
    },
    {
      "epoch": 5.875924140147863,
      "grad_norm": 0.00035106236464343965,
      "learning_rate": 1.2165434479802852e-05,
      "loss": 0.1698,
      "step": 54840
    },
    {
      "epoch": 5.876995606985964,
      "grad_norm": 0.00023668062931392342,
      "learning_rate": 1.2164005857352051e-05,
      "loss": 0.0004,
      "step": 54850
    },
    {
      "epoch": 5.878067073824065,
      "grad_norm": 0.0002692682028282434,
      "learning_rate": 1.2162577234901247e-05,
      "loss": 0.1399,
      "step": 54860
    },
    {
      "epoch": 5.879138540662167,
      "grad_norm": 0.0306243933737278,
      "learning_rate": 1.2161148612450446e-05,
      "loss": 0.0003,
      "step": 54870
    },
    {
      "epoch": 5.880210007500268,
      "grad_norm": 0.051502544432878494,
      "learning_rate": 1.2159719989999644e-05,
      "loss": 0.2499,
      "step": 54880
    },
    {
      "epoch": 5.881281474338369,
      "grad_norm": 0.00040029044612310827,
      "learning_rate": 1.2158291367548842e-05,
      "loss": 0.0005,
      "step": 54890
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.00030370193417184055,
      "learning_rate": 1.215686274509804e-05,
      "loss": 0.1893,
      "step": 54900
    },
    {
      "epoch": 5.883424408014572,
      "grad_norm": 0.6190685629844666,
      "learning_rate": 1.2155434122647239e-05,
      "loss": 0.0012,
      "step": 54910
    },
    {
      "epoch": 5.884495874852673,
      "grad_norm": 0.00014533991634380072,
      "learning_rate": 1.2154005500196438e-05,
      "loss": 0.0504,
      "step": 54920
    },
    {
      "epoch": 5.885567341690774,
      "grad_norm": 0.00011843095126096159,
      "learning_rate": 1.2152576877745634e-05,
      "loss": 0.0001,
      "step": 54930
    },
    {
      "epoch": 5.886638808528876,
      "grad_norm": 0.029346559196710587,
      "learning_rate": 1.2151148255294833e-05,
      "loss": 0.0002,
      "step": 54940
    },
    {
      "epoch": 5.887710275366977,
      "grad_norm": 0.043774042278528214,
      "learning_rate": 1.2149719632844031e-05,
      "loss": 0.399,
      "step": 54950
    },
    {
      "epoch": 5.8887817422050786,
      "grad_norm": 0.00014106779417488724,
      "learning_rate": 1.2148291010393229e-05,
      "loss": 0.0458,
      "step": 54960
    },
    {
      "epoch": 5.88985320904318,
      "grad_norm": 0.005359858274459839,
      "learning_rate": 1.2146862387942428e-05,
      "loss": 0.1736,
      "step": 54970
    },
    {
      "epoch": 5.890924675881282,
      "grad_norm": 0.051730792969465256,
      "learning_rate": 1.2145433765491626e-05,
      "loss": 0.0004,
      "step": 54980
    },
    {
      "epoch": 5.891996142719383,
      "grad_norm": 36.56696701049805,
      "learning_rate": 1.2144005143040825e-05,
      "loss": 0.0052,
      "step": 54990
    },
    {
      "epoch": 5.893067609557484,
      "grad_norm": 0.00013927201507613063,
      "learning_rate": 1.2142576520590021e-05,
      "loss": 0.0008,
      "step": 55000
    },
    {
      "epoch": 5.894139076395586,
      "grad_norm": 0.0770597979426384,
      "learning_rate": 1.214114789813922e-05,
      "loss": 0.0003,
      "step": 55010
    },
    {
      "epoch": 5.895210543233687,
      "grad_norm": 0.026563042774796486,
      "learning_rate": 1.2139719275688418e-05,
      "loss": 0.0006,
      "step": 55020
    },
    {
      "epoch": 5.896282010071788,
      "grad_norm": 0.00019746899488382041,
      "learning_rate": 1.2138290653237616e-05,
      "loss": 0.5513,
      "step": 55030
    },
    {
      "epoch": 5.89735347690989,
      "grad_norm": 0.0008485752041451633,
      "learning_rate": 1.2136862030786815e-05,
      "loss": 0.1147,
      "step": 55040
    },
    {
      "epoch": 5.898424943747991,
      "grad_norm": 0.0007413154235109687,
      "learning_rate": 1.2135433408336013e-05,
      "loss": 0.1758,
      "step": 55050
    },
    {
      "epoch": 5.899496410586092,
      "grad_norm": 0.0005671672406606376,
      "learning_rate": 1.2134004785885212e-05,
      "loss": 0.2945,
      "step": 55060
    },
    {
      "epoch": 5.900567877424193,
      "grad_norm": 0.04077860340476036,
      "learning_rate": 1.2132576163434408e-05,
      "loss": 0.0007,
      "step": 55070
    },
    {
      "epoch": 5.901639344262295,
      "grad_norm": 0.000947546330280602,
      "learning_rate": 1.2131147540983608e-05,
      "loss": 0.0011,
      "step": 55080
    },
    {
      "epoch": 5.9027108111003965,
      "grad_norm": 0.0014667302602902055,
      "learning_rate": 1.2129718918532807e-05,
      "loss": 0.2427,
      "step": 55090
    },
    {
      "epoch": 5.903782277938498,
      "grad_norm": 6.659326076507568,
      "learning_rate": 1.2128290296082003e-05,
      "loss": 0.0023,
      "step": 55100
    },
    {
      "epoch": 5.904853744776599,
      "grad_norm": 664.7295532226562,
      "learning_rate": 1.2126861673631202e-05,
      "loss": 0.0415,
      "step": 55110
    },
    {
      "epoch": 5.905925211614701,
      "grad_norm": 0.0013476962922140956,
      "learning_rate": 1.21254330511804e-05,
      "loss": 0.0057,
      "step": 55120
    },
    {
      "epoch": 5.906996678452802,
      "grad_norm": 0.0030983721371740103,
      "learning_rate": 1.21240044287296e-05,
      "loss": 0.0008,
      "step": 55130
    },
    {
      "epoch": 5.908068145290903,
      "grad_norm": 0.04490973427891731,
      "learning_rate": 1.2122575806278795e-05,
      "loss": 0.0006,
      "step": 55140
    },
    {
      "epoch": 5.909139612129005,
      "grad_norm": 99.88958740234375,
      "learning_rate": 1.2121147183827995e-05,
      "loss": 0.1582,
      "step": 55150
    },
    {
      "epoch": 5.910211078967106,
      "grad_norm": 0.01594572141766548,
      "learning_rate": 1.2119718561377194e-05,
      "loss": 0.2517,
      "step": 55160
    },
    {
      "epoch": 5.911282545805207,
      "grad_norm": 0.017617423087358475,
      "learning_rate": 1.211828993892639e-05,
      "loss": 0.0956,
      "step": 55170
    },
    {
      "epoch": 5.912354012643309,
      "grad_norm": 0.0029219745192676783,
      "learning_rate": 1.211686131647559e-05,
      "loss": 0.2006,
      "step": 55180
    },
    {
      "epoch": 5.91342547948141,
      "grad_norm": 0.0021387157030403614,
      "learning_rate": 1.2115432694024787e-05,
      "loss": 0.1463,
      "step": 55190
    },
    {
      "epoch": 5.914496946319511,
      "grad_norm": 0.02942192368209362,
      "learning_rate": 1.2114004071573986e-05,
      "loss": 0.0828,
      "step": 55200
    },
    {
      "epoch": 5.9155684131576125,
      "grad_norm": 0.026810279116034508,
      "learning_rate": 1.2112575449123186e-05,
      "loss": 0.0004,
      "step": 55210
    },
    {
      "epoch": 5.9166398799957145,
      "grad_norm": 0.01739427074790001,
      "learning_rate": 1.2111146826672382e-05,
      "loss": 0.1961,
      "step": 55220
    },
    {
      "epoch": 5.917711346833816,
      "grad_norm": 0.02471921779215336,
      "learning_rate": 1.2109718204221581e-05,
      "loss": 0.0002,
      "step": 55230
    },
    {
      "epoch": 5.918782813671917,
      "grad_norm": 0.017464499920606613,
      "learning_rate": 1.2108289581770779e-05,
      "loss": 0.1572,
      "step": 55240
    },
    {
      "epoch": 5.919854280510018,
      "grad_norm": 0.052491188049316406,
      "learning_rate": 1.2106860959319976e-05,
      "loss": 0.1037,
      "step": 55250
    },
    {
      "epoch": 5.92092574734812,
      "grad_norm": 1.5534933805465698,
      "learning_rate": 1.2105432336869174e-05,
      "loss": 0.0022,
      "step": 55260
    },
    {
      "epoch": 5.921997214186221,
      "grad_norm": 0.0033656382001936436,
      "learning_rate": 1.2104003714418373e-05,
      "loss": 0.1575,
      "step": 55270
    },
    {
      "epoch": 5.923068681024322,
      "grad_norm": 0.00412431126460433,
      "learning_rate": 1.2102575091967573e-05,
      "loss": 0.0337,
      "step": 55280
    },
    {
      "epoch": 5.924140147862424,
      "grad_norm": 0.035874221473932266,
      "learning_rate": 1.2101146469516769e-05,
      "loss": 0.2947,
      "step": 55290
    },
    {
      "epoch": 5.925211614700525,
      "grad_norm": 0.0012578536989167333,
      "learning_rate": 1.2099717847065968e-05,
      "loss": 0.0005,
      "step": 55300
    },
    {
      "epoch": 5.926283081538626,
      "grad_norm": 19.286731719970703,
      "learning_rate": 1.2098289224615166e-05,
      "loss": 0.2136,
      "step": 55310
    },
    {
      "epoch": 5.927354548376727,
      "grad_norm": 0.0006258692592382431,
      "learning_rate": 1.2096860602164364e-05,
      "loss": 0.0009,
      "step": 55320
    },
    {
      "epoch": 5.928426015214829,
      "grad_norm": 0.01231683325022459,
      "learning_rate": 1.2095431979713561e-05,
      "loss": 0.2913,
      "step": 55330
    },
    {
      "epoch": 5.9294974820529305,
      "grad_norm": 23.902952194213867,
      "learning_rate": 1.209400335726276e-05,
      "loss": 0.1504,
      "step": 55340
    },
    {
      "epoch": 5.930568948891032,
      "grad_norm": 0.010810839012265205,
      "learning_rate": 1.209257473481196e-05,
      "loss": 0.0002,
      "step": 55350
    },
    {
      "epoch": 5.931640415729133,
      "grad_norm": 0.0009763818234205246,
      "learning_rate": 1.2091146112361156e-05,
      "loss": 0.0002,
      "step": 55360
    },
    {
      "epoch": 5.932711882567235,
      "grad_norm": 0.0036861596163362265,
      "learning_rate": 1.2089717489910355e-05,
      "loss": 0.0011,
      "step": 55370
    },
    {
      "epoch": 5.933783349405336,
      "grad_norm": 0.1353866308927536,
      "learning_rate": 1.2088288867459553e-05,
      "loss": 0.0003,
      "step": 55380
    },
    {
      "epoch": 5.934854816243437,
      "grad_norm": 0.0010289294878020883,
      "learning_rate": 1.208686024500875e-05,
      "loss": 0.0003,
      "step": 55390
    },
    {
      "epoch": 5.935926283081539,
      "grad_norm": 0.016354721039533615,
      "learning_rate": 1.208543162255795e-05,
      "loss": 0.2057,
      "step": 55400
    },
    {
      "epoch": 5.93699774991964,
      "grad_norm": 0.0018866873579099774,
      "learning_rate": 1.2084003000107148e-05,
      "loss": 0.0003,
      "step": 55410
    },
    {
      "epoch": 5.938069216757741,
      "grad_norm": 0.03634466603398323,
      "learning_rate": 1.2082574377656347e-05,
      "loss": 0.0005,
      "step": 55420
    },
    {
      "epoch": 5.939140683595843,
      "grad_norm": 0.03930070996284485,
      "learning_rate": 1.2081145755205543e-05,
      "loss": 0.0276,
      "step": 55430
    },
    {
      "epoch": 5.940212150433944,
      "grad_norm": 114.2784423828125,
      "learning_rate": 1.2079717132754742e-05,
      "loss": 0.0315,
      "step": 55440
    },
    {
      "epoch": 5.941283617272045,
      "grad_norm": 0.023715972900390625,
      "learning_rate": 1.207828851030394e-05,
      "loss": 0.0002,
      "step": 55450
    },
    {
      "epoch": 5.9423550841101465,
      "grad_norm": 29.779659271240234,
      "learning_rate": 1.2076859887853138e-05,
      "loss": 0.1618,
      "step": 55460
    },
    {
      "epoch": 5.9434265509482485,
      "grad_norm": 0.0008121946011669934,
      "learning_rate": 1.2075431265402337e-05,
      "loss": 0.0002,
      "step": 55470
    },
    {
      "epoch": 5.94449801778635,
      "grad_norm": 0.014038462191820145,
      "learning_rate": 1.2074002642951535e-05,
      "loss": 0.4608,
      "step": 55480
    },
    {
      "epoch": 5.945569484624451,
      "grad_norm": 0.028792111203074455,
      "learning_rate": 1.2072574020500734e-05,
      "loss": 0.0679,
      "step": 55490
    },
    {
      "epoch": 5.946640951462552,
      "grad_norm": 0.010713315568864346,
      "learning_rate": 1.207114539804993e-05,
      "loss": 0.0002,
      "step": 55500
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 16.04610252380371,
      "learning_rate": 1.206971677559913e-05,
      "loss": 0.1739,
      "step": 55510
    },
    {
      "epoch": 5.948783885138755,
      "grad_norm": 0.006526737008243799,
      "learning_rate": 1.2068288153148329e-05,
      "loss": 0.0003,
      "step": 55520
    },
    {
      "epoch": 5.949855351976856,
      "grad_norm": 0.0009294159826822579,
      "learning_rate": 1.2066859530697525e-05,
      "loss": 0.0004,
      "step": 55530
    },
    {
      "epoch": 5.950926818814958,
      "grad_norm": 7.8944573402404785,
      "learning_rate": 1.2065430908246724e-05,
      "loss": 0.0065,
      "step": 55540
    },
    {
      "epoch": 5.951998285653059,
      "grad_norm": 0.0016056039603427052,
      "learning_rate": 1.2064002285795922e-05,
      "loss": 0.2177,
      "step": 55550
    },
    {
      "epoch": 5.95306975249116,
      "grad_norm": 0.0050924066454172134,
      "learning_rate": 1.2062573663345121e-05,
      "loss": 0.0003,
      "step": 55560
    },
    {
      "epoch": 5.954141219329262,
      "grad_norm": 35.75246047973633,
      "learning_rate": 1.2061145040894317e-05,
      "loss": 0.515,
      "step": 55570
    },
    {
      "epoch": 5.955212686167363,
      "grad_norm": 0.0009875576943159103,
      "learning_rate": 1.2059716418443517e-05,
      "loss": 0.2994,
      "step": 55580
    },
    {
      "epoch": 5.956284153005464,
      "grad_norm": 0.0013616642681881785,
      "learning_rate": 1.2058287795992716e-05,
      "loss": 0.1707,
      "step": 55590
    },
    {
      "epoch": 5.9573556198435655,
      "grad_norm": 0.03371165320277214,
      "learning_rate": 1.2056859173541912e-05,
      "loss": 0.0005,
      "step": 55600
    },
    {
      "epoch": 5.9584270866816675,
      "grad_norm": 0.0011089700274169445,
      "learning_rate": 1.2055430551091111e-05,
      "loss": 0.0005,
      "step": 55610
    },
    {
      "epoch": 5.959498553519769,
      "grad_norm": 0.0194671880453825,
      "learning_rate": 1.2054001928640309e-05,
      "loss": 0.0008,
      "step": 55620
    },
    {
      "epoch": 5.96057002035787,
      "grad_norm": 0.0003626699326559901,
      "learning_rate": 1.2052573306189508e-05,
      "loss": 0.0005,
      "step": 55630
    },
    {
      "epoch": 5.961641487195971,
      "grad_norm": 0.0005886571598239243,
      "learning_rate": 1.2051144683738708e-05,
      "loss": 0.2126,
      "step": 55640
    },
    {
      "epoch": 5.962712954034073,
      "grad_norm": 0.05072781443595886,
      "learning_rate": 1.2049716061287904e-05,
      "loss": 0.0024,
      "step": 55650
    },
    {
      "epoch": 5.963784420872174,
      "grad_norm": 0.009874691255390644,
      "learning_rate": 1.2048287438837103e-05,
      "loss": 0.0002,
      "step": 55660
    },
    {
      "epoch": 5.964855887710275,
      "grad_norm": 0.07702159136533737,
      "learning_rate": 1.2046858816386299e-05,
      "loss": 0.5134,
      "step": 55670
    },
    {
      "epoch": 5.965927354548377,
      "grad_norm": 0.630529522895813,
      "learning_rate": 1.2045430193935498e-05,
      "loss": 0.0008,
      "step": 55680
    },
    {
      "epoch": 5.966998821386478,
      "grad_norm": 0.013463471084833145,
      "learning_rate": 1.2044001571484696e-05,
      "loss": 0.0011,
      "step": 55690
    },
    {
      "epoch": 5.968070288224579,
      "grad_norm": 0.0012759893434122205,
      "learning_rate": 1.2042572949033895e-05,
      "loss": 0.0006,
      "step": 55700
    },
    {
      "epoch": 5.969141755062681,
      "grad_norm": 0.0005216708523221314,
      "learning_rate": 1.2041144326583095e-05,
      "loss": 0.2356,
      "step": 55710
    },
    {
      "epoch": 5.970213221900782,
      "grad_norm": 0.0008079105173237622,
      "learning_rate": 1.203971570413229e-05,
      "loss": 0.0003,
      "step": 55720
    },
    {
      "epoch": 5.9712846887388835,
      "grad_norm": 0.03454447165131569,
      "learning_rate": 1.203828708168149e-05,
      "loss": 0.0002,
      "step": 55730
    },
    {
      "epoch": 5.972356155576985,
      "grad_norm": 0.015379519201815128,
      "learning_rate": 1.2036858459230686e-05,
      "loss": 0.1752,
      "step": 55740
    },
    {
      "epoch": 5.973427622415087,
      "grad_norm": 0.0006427796906791627,
      "learning_rate": 1.2035429836779885e-05,
      "loss": 0.1844,
      "step": 55750
    },
    {
      "epoch": 5.974499089253188,
      "grad_norm": 0.0014005147386342287,
      "learning_rate": 1.2034001214329085e-05,
      "loss": 0.0003,
      "step": 55760
    },
    {
      "epoch": 5.975570556091289,
      "grad_norm": 0.042854443192481995,
      "learning_rate": 1.2032572591878283e-05,
      "loss": 0.0009,
      "step": 55770
    },
    {
      "epoch": 5.97664202292939,
      "grad_norm": 0.00669122813269496,
      "learning_rate": 1.2031143969427482e-05,
      "loss": 0.0002,
      "step": 55780
    },
    {
      "epoch": 5.977713489767492,
      "grad_norm": 0.015220477245748043,
      "learning_rate": 1.2029715346976678e-05,
      "loss": 0.2047,
      "step": 55790
    },
    {
      "epoch": 5.978784956605593,
      "grad_norm": 0.0006391506758518517,
      "learning_rate": 1.2028286724525877e-05,
      "loss": 0.0009,
      "step": 55800
    },
    {
      "epoch": 5.979856423443694,
      "grad_norm": 0.009173738770186901,
      "learning_rate": 1.2026858102075075e-05,
      "loss": 0.0002,
      "step": 55810
    },
    {
      "epoch": 5.980927890281796,
      "grad_norm": 0.01719464175403118,
      "learning_rate": 1.2025429479624273e-05,
      "loss": 0.1711,
      "step": 55820
    },
    {
      "epoch": 5.981999357119897,
      "grad_norm": 0.13996924459934235,
      "learning_rate": 1.2024000857173472e-05,
      "loss": 0.0013,
      "step": 55830
    },
    {
      "epoch": 5.983070823957998,
      "grad_norm": 0.0007965128170326352,
      "learning_rate": 1.202257223472267e-05,
      "loss": 0.1208,
      "step": 55840
    },
    {
      "epoch": 5.9841422907960995,
      "grad_norm": 0.016982724890112877,
      "learning_rate": 1.2021143612271869e-05,
      "loss": 0.0311,
      "step": 55850
    },
    {
      "epoch": 5.9852137576342015,
      "grad_norm": 0.009935062378644943,
      "learning_rate": 1.2019714989821065e-05,
      "loss": 0.0034,
      "step": 55860
    },
    {
      "epoch": 5.986285224472303,
      "grad_norm": 0.0005213863914832473,
      "learning_rate": 1.2018286367370264e-05,
      "loss": 0.0001,
      "step": 55870
    },
    {
      "epoch": 5.987356691310404,
      "grad_norm": 0.009870458394289017,
      "learning_rate": 1.2016857744919464e-05,
      "loss": 0.41,
      "step": 55880
    },
    {
      "epoch": 5.988428158148505,
      "grad_norm": 0.0005170361255295575,
      "learning_rate": 1.201542912246866e-05,
      "loss": 0.0006,
      "step": 55890
    },
    {
      "epoch": 5.989499624986607,
      "grad_norm": 0.0003846380568575114,
      "learning_rate": 1.2014000500017859e-05,
      "loss": 0.0005,
      "step": 55900
    },
    {
      "epoch": 5.990571091824708,
      "grad_norm": 21.789026260375977,
      "learning_rate": 1.2012571877567057e-05,
      "loss": 0.1453,
      "step": 55910
    },
    {
      "epoch": 5.991642558662809,
      "grad_norm": 0.09516216814517975,
      "learning_rate": 1.2011143255116256e-05,
      "loss": 0.0002,
      "step": 55920
    },
    {
      "epoch": 5.992714025500911,
      "grad_norm": 0.025387059897184372,
      "learning_rate": 1.2009714632665452e-05,
      "loss": 0.0002,
      "step": 55930
    },
    {
      "epoch": 5.993785492339012,
      "grad_norm": 0.012297706678509712,
      "learning_rate": 1.2008286010214651e-05,
      "loss": 0.0006,
      "step": 55940
    },
    {
      "epoch": 5.994856959177113,
      "grad_norm": 0.0008415424963459373,
      "learning_rate": 1.200685738776385e-05,
      "loss": 0.001,
      "step": 55950
    },
    {
      "epoch": 5.995928426015215,
      "grad_norm": 0.0003985948278568685,
      "learning_rate": 1.2005428765313047e-05,
      "loss": 0.1548,
      "step": 55960
    },
    {
      "epoch": 5.996999892853316,
      "grad_norm": 0.011499907821416855,
      "learning_rate": 1.2004000142862246e-05,
      "loss": 0.1536,
      "step": 55970
    },
    {
      "epoch": 5.9980713596914175,
      "grad_norm": 0.03914119675755501,
      "learning_rate": 1.2002571520411444e-05,
      "loss": 0.0001,
      "step": 55980
    },
    {
      "epoch": 5.999142826529519,
      "grad_norm": 0.037123627960681915,
      "learning_rate": 1.2001142897960643e-05,
      "loss": 0.0008,
      "step": 55990
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.971,
      "eval_f1": 0.8789986091794159,
      "eval_loss": 0.172470360994339,
      "eval_precision": 0.9280469897209985,
      "eval_recall": 0.8348745046235139,
      "eval_runtime": 389.5837,
      "eval_samples_per_second": 15.401,
      "eval_steps_per_second": 5.134,
      "step": 55998
    },
    {
      "epoch": 6.000214293367621,
      "grad_norm": 0.0003408075135666877,
      "learning_rate": 1.1999714275509841e-05,
      "loss": 0.3142,
      "step": 56000
    },
    {
      "epoch": 6.001285760205722,
      "grad_norm": 0.06979937851428986,
      "learning_rate": 1.1998285653059039e-05,
      "loss": 0.2176,
      "step": 56010
    },
    {
      "epoch": 6.002357227043823,
      "grad_norm": 0.03589286282658577,
      "learning_rate": 1.1996857030608238e-05,
      "loss": 0.0004,
      "step": 56020
    },
    {
      "epoch": 6.003428693881925,
      "grad_norm": 0.0032020907383412123,
      "learning_rate": 1.1995428408157434e-05,
      "loss": 0.2628,
      "step": 56030
    },
    {
      "epoch": 6.004500160720026,
      "grad_norm": 0.005936640314757824,
      "learning_rate": 1.1993999785706633e-05,
      "loss": 0.0944,
      "step": 56040
    },
    {
      "epoch": 6.005571627558127,
      "grad_norm": 2.189866065979004,
      "learning_rate": 1.1992571163255831e-05,
      "loss": 0.1443,
      "step": 56050
    },
    {
      "epoch": 6.006643094396228,
      "grad_norm": 0.006801025476306677,
      "learning_rate": 1.199114254080503e-05,
      "loss": 0.2632,
      "step": 56060
    },
    {
      "epoch": 6.00771456123433,
      "grad_norm": 0.017326299101114273,
      "learning_rate": 1.198971391835423e-05,
      "loss": 0.0011,
      "step": 56070
    },
    {
      "epoch": 6.008786028072431,
      "grad_norm": 0.029647113755345345,
      "learning_rate": 1.1988285295903426e-05,
      "loss": 0.0008,
      "step": 56080
    },
    {
      "epoch": 6.009857494910532,
      "grad_norm": 0.004833129700273275,
      "learning_rate": 1.1986856673452625e-05,
      "loss": 0.0005,
      "step": 56090
    },
    {
      "epoch": 6.0109289617486334,
      "grad_norm": 0.0884360820055008,
      "learning_rate": 1.1985428051001821e-05,
      "loss": 0.0004,
      "step": 56100
    },
    {
      "epoch": 6.0120004285867354,
      "grad_norm": 0.0025558387860655785,
      "learning_rate": 1.198399942855102e-05,
      "loss": 0.14,
      "step": 56110
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 0.0006776908994652331,
      "learning_rate": 1.198257080610022e-05,
      "loss": 0.0001,
      "step": 56120
    },
    {
      "epoch": 6.014143362262938,
      "grad_norm": 0.0010921970242634416,
      "learning_rate": 1.1981142183649417e-05,
      "loss": 0.0007,
      "step": 56130
    },
    {
      "epoch": 6.01521482910104,
      "grad_norm": 0.011289848014712334,
      "learning_rate": 1.1979713561198617e-05,
      "loss": 0.0004,
      "step": 56140
    },
    {
      "epoch": 6.016286295939141,
      "grad_norm": 0.036524102091789246,
      "learning_rate": 1.1978284938747813e-05,
      "loss": 0.0108,
      "step": 56150
    },
    {
      "epoch": 6.017357762777242,
      "grad_norm": 0.012770921923220158,
      "learning_rate": 1.1976856316297012e-05,
      "loss": 0.2312,
      "step": 56160
    },
    {
      "epoch": 6.018429229615343,
      "grad_norm": 0.0007923010853119195,
      "learning_rate": 1.1975427693846208e-05,
      "loss": 0.0006,
      "step": 56170
    },
    {
      "epoch": 6.019500696453445,
      "grad_norm": 0.0004276622203178704,
      "learning_rate": 1.1973999071395407e-05,
      "loss": 0.0001,
      "step": 56180
    },
    {
      "epoch": 6.020572163291546,
      "grad_norm": 0.007183652371168137,
      "learning_rate": 1.1972570448944607e-05,
      "loss": 0.0001,
      "step": 56190
    },
    {
      "epoch": 6.021643630129647,
      "grad_norm": 0.050048306584358215,
      "learning_rate": 1.1971141826493804e-05,
      "loss": 0.1584,
      "step": 56200
    },
    {
      "epoch": 6.022715096967749,
      "grad_norm": 0.012560476548969746,
      "learning_rate": 1.1969713204043004e-05,
      "loss": 0.1456,
      "step": 56210
    },
    {
      "epoch": 6.02378656380585,
      "grad_norm": 0.0013292484218254685,
      "learning_rate": 1.19682845815922e-05,
      "loss": 0.0004,
      "step": 56220
    },
    {
      "epoch": 6.024858030643951,
      "grad_norm": 0.0004910596180707216,
      "learning_rate": 1.19668559591414e-05,
      "loss": 0.0003,
      "step": 56230
    },
    {
      "epoch": 6.0259294974820525,
      "grad_norm": 0.007480822037905455,
      "learning_rate": 1.1965427336690595e-05,
      "loss": 0.0002,
      "step": 56240
    },
    {
      "epoch": 6.0270009643201545,
      "grad_norm": 0.004306514281779528,
      "learning_rate": 1.1963998714239795e-05,
      "loss": 0.2406,
      "step": 56250
    },
    {
      "epoch": 6.028072431158256,
      "grad_norm": 0.0009840423008427024,
      "learning_rate": 1.1962570091788994e-05,
      "loss": 0.1533,
      "step": 56260
    },
    {
      "epoch": 6.029143897996357,
      "grad_norm": 0.18217624723911285,
      "learning_rate": 1.1961141469338192e-05,
      "loss": 0.0019,
      "step": 56270
    },
    {
      "epoch": 6.030215364834459,
      "grad_norm": 0.06289514899253845,
      "learning_rate": 1.1959712846887391e-05,
      "loss": 0.2623,
      "step": 56280
    },
    {
      "epoch": 6.03128683167256,
      "grad_norm": 0.003161777276545763,
      "learning_rate": 1.1958284224436587e-05,
      "loss": 0.0003,
      "step": 56290
    },
    {
      "epoch": 6.032358298510661,
      "grad_norm": 0.013876397162675858,
      "learning_rate": 1.1956855601985786e-05,
      "loss": 0.0007,
      "step": 56300
    },
    {
      "epoch": 6.033429765348762,
      "grad_norm": 0.2651192247867584,
      "learning_rate": 1.1955426979534986e-05,
      "loss": 0.0004,
      "step": 56310
    },
    {
      "epoch": 6.034501232186864,
      "grad_norm": 0.0006637052283622324,
      "learning_rate": 1.1953998357084182e-05,
      "loss": 0.0007,
      "step": 56320
    },
    {
      "epoch": 6.035572699024965,
      "grad_norm": 0.0005346976104192436,
      "learning_rate": 1.1952569734633381e-05,
      "loss": 0.0002,
      "step": 56330
    },
    {
      "epoch": 6.036644165863066,
      "grad_norm": 0.012585277669131756,
      "learning_rate": 1.1951141112182579e-05,
      "loss": 0.0009,
      "step": 56340
    },
    {
      "epoch": 6.037715632701168,
      "grad_norm": 0.2855350375175476,
      "learning_rate": 1.1949712489731778e-05,
      "loss": 0.0008,
      "step": 56350
    },
    {
      "epoch": 6.038787099539269,
      "grad_norm": 0.00036149274092167616,
      "learning_rate": 1.1948283867280974e-05,
      "loss": 0.0003,
      "step": 56360
    },
    {
      "epoch": 6.0398585663773705,
      "grad_norm": 0.00043938306043855846,
      "learning_rate": 1.1946855244830173e-05,
      "loss": 0.1266,
      "step": 56370
    },
    {
      "epoch": 6.040930033215472,
      "grad_norm": 0.003424492198973894,
      "learning_rate": 1.1945426622379373e-05,
      "loss": 0.0015,
      "step": 56380
    },
    {
      "epoch": 6.042001500053574,
      "grad_norm": 77.05029296875,
      "learning_rate": 1.1943997999928569e-05,
      "loss": 0.1751,
      "step": 56390
    },
    {
      "epoch": 6.043072966891675,
      "grad_norm": 0.0004327092901803553,
      "learning_rate": 1.1942569377477768e-05,
      "loss": 0.0002,
      "step": 56400
    },
    {
      "epoch": 6.044144433729776,
      "grad_norm": 0.015009204857051373,
      "learning_rate": 1.1941140755026966e-05,
      "loss": 0.0004,
      "step": 56410
    },
    {
      "epoch": 6.045215900567878,
      "grad_norm": 0.007580169476568699,
      "learning_rate": 1.1939712132576165e-05,
      "loss": 0.0001,
      "step": 56420
    },
    {
      "epoch": 6.046287367405979,
      "grad_norm": 36.43035888671875,
      "learning_rate": 1.1938283510125363e-05,
      "loss": 0.6746,
      "step": 56430
    },
    {
      "epoch": 6.04735883424408,
      "grad_norm": 0.005454731173813343,
      "learning_rate": 1.193685488767456e-05,
      "loss": 0.151,
      "step": 56440
    },
    {
      "epoch": 6.048430301082181,
      "grad_norm": 0.001027943566441536,
      "learning_rate": 1.193542626522376e-05,
      "loss": 0.0008,
      "step": 56450
    },
    {
      "epoch": 6.049501767920283,
      "grad_norm": 0.0020491392351686954,
      "learning_rate": 1.1933997642772956e-05,
      "loss": 0.0901,
      "step": 56460
    },
    {
      "epoch": 6.050573234758384,
      "grad_norm": 0.008819637820124626,
      "learning_rate": 1.1932569020322155e-05,
      "loss": 0.0005,
      "step": 56470
    },
    {
      "epoch": 6.051644701596485,
      "grad_norm": 0.023093614727258682,
      "learning_rate": 1.1931140397871353e-05,
      "loss": 0.2213,
      "step": 56480
    },
    {
      "epoch": 6.052716168434587,
      "grad_norm": 0.10065452754497528,
      "learning_rate": 1.1929711775420552e-05,
      "loss": 0.0001,
      "step": 56490
    },
    {
      "epoch": 6.0537876352726885,
      "grad_norm": 0.01211633998900652,
      "learning_rate": 1.192828315296975e-05,
      "loss": 0.0012,
      "step": 56500
    },
    {
      "epoch": 6.05485910211079,
      "grad_norm": 0.0005204833578318357,
      "learning_rate": 1.1926854530518948e-05,
      "loss": 0.0014,
      "step": 56510
    },
    {
      "epoch": 6.055930568948891,
      "grad_norm": 0.0005456869839690626,
      "learning_rate": 1.1925425908068147e-05,
      "loss": 0.2581,
      "step": 56520
    },
    {
      "epoch": 6.057002035786993,
      "grad_norm": 0.000934152863919735,
      "learning_rate": 1.1923997285617343e-05,
      "loss": 0.0003,
      "step": 56530
    },
    {
      "epoch": 6.058073502625094,
      "grad_norm": 0.016304563730955124,
      "learning_rate": 1.1922568663166542e-05,
      "loss": 0.0002,
      "step": 56540
    },
    {
      "epoch": 6.059144969463195,
      "grad_norm": 0.0017693635309115052,
      "learning_rate": 1.1921140040715742e-05,
      "loss": 0.0002,
      "step": 56550
    },
    {
      "epoch": 6.060216436301296,
      "grad_norm": 0.0011466046562418342,
      "learning_rate": 1.191971141826494e-05,
      "loss": 0.0005,
      "step": 56560
    },
    {
      "epoch": 6.061287903139398,
      "grad_norm": 0.015407762490212917,
      "learning_rate": 1.1918282795814137e-05,
      "loss": 0.0002,
      "step": 56570
    },
    {
      "epoch": 6.062359369977499,
      "grad_norm": 0.010177635587751865,
      "learning_rate": 1.1916854173363335e-05,
      "loss": 0.0005,
      "step": 56580
    },
    {
      "epoch": 6.0634308368156,
      "grad_norm": 0.0010715248063206673,
      "learning_rate": 1.1915425550912534e-05,
      "loss": 0.0001,
      "step": 56590
    },
    {
      "epoch": 6.064502303653702,
      "grad_norm": 0.0010202274424955249,
      "learning_rate": 1.191399692846173e-05,
      "loss": 0.0002,
      "step": 56600
    },
    {
      "epoch": 6.065573770491803,
      "grad_norm": 0.0063227503560483456,
      "learning_rate": 1.191256830601093e-05,
      "loss": 0.0002,
      "step": 56610
    },
    {
      "epoch": 6.0666452373299045,
      "grad_norm": 0.0010795854032039642,
      "learning_rate": 1.1911139683560129e-05,
      "loss": 0.0003,
      "step": 56620
    },
    {
      "epoch": 6.067716704168006,
      "grad_norm": 0.0052014123648405075,
      "learning_rate": 1.1909711061109326e-05,
      "loss": 0.2034,
      "step": 56630
    },
    {
      "epoch": 6.068788171006108,
      "grad_norm": 0.011397148482501507,
      "learning_rate": 1.1908282438658526e-05,
      "loss": 0.0002,
      "step": 56640
    },
    {
      "epoch": 6.069859637844209,
      "grad_norm": 0.011331610381603241,
      "learning_rate": 1.1906853816207722e-05,
      "loss": 0.1274,
      "step": 56650
    },
    {
      "epoch": 6.07093110468231,
      "grad_norm": 0.011093729175627232,
      "learning_rate": 1.1905425193756921e-05,
      "loss": 0.0002,
      "step": 56660
    },
    {
      "epoch": 6.072002571520412,
      "grad_norm": 0.0011319268960505724,
      "learning_rate": 1.190399657130612e-05,
      "loss": 0.0002,
      "step": 56670
    },
    {
      "epoch": 6.073074038358513,
      "grad_norm": 0.0008447839645668864,
      "learning_rate": 1.1902567948855316e-05,
      "loss": 0.0001,
      "step": 56680
    },
    {
      "epoch": 6.074145505196614,
      "grad_norm": 17.059152603149414,
      "learning_rate": 1.1901139326404516e-05,
      "loss": 0.2213,
      "step": 56690
    },
    {
      "epoch": 6.075216972034715,
      "grad_norm": 0.0773647278547287,
      "learning_rate": 1.1899710703953714e-05,
      "loss": 0.0002,
      "step": 56700
    },
    {
      "epoch": 6.076288438872817,
      "grad_norm": 0.04172138869762421,
      "learning_rate": 1.1898282081502913e-05,
      "loss": 0.0003,
      "step": 56710
    },
    {
      "epoch": 6.077359905710918,
      "grad_norm": 0.0006489049410447478,
      "learning_rate": 1.1896853459052109e-05,
      "loss": 0.0003,
      "step": 56720
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 0.00036383038968779147,
      "learning_rate": 1.1895424836601308e-05,
      "loss": 0.0002,
      "step": 56730
    },
    {
      "epoch": 6.079502839387121,
      "grad_norm": 0.01199498400092125,
      "learning_rate": 1.1893996214150508e-05,
      "loss": 0.1384,
      "step": 56740
    },
    {
      "epoch": 6.080574306225222,
      "grad_norm": 0.023995615541934967,
      "learning_rate": 1.1892567591699704e-05,
      "loss": 0.167,
      "step": 56750
    },
    {
      "epoch": 6.0816457730633235,
      "grad_norm": 0.137160062789917,
      "learning_rate": 1.1891138969248903e-05,
      "loss": 0.1592,
      "step": 56760
    },
    {
      "epoch": 6.082717239901425,
      "grad_norm": 0.0008200551383197308,
      "learning_rate": 1.18897103467981e-05,
      "loss": 0.0003,
      "step": 56770
    },
    {
      "epoch": 6.083788706739527,
      "grad_norm": 0.011937451548874378,
      "learning_rate": 1.18882817243473e-05,
      "loss": 0.0003,
      "step": 56780
    },
    {
      "epoch": 6.084860173577628,
      "grad_norm": 0.029828529804944992,
      "learning_rate": 1.1886853101896498e-05,
      "loss": 0.0007,
      "step": 56790
    },
    {
      "epoch": 6.085931640415729,
      "grad_norm": 0.00039438001113012433,
      "learning_rate": 1.1885424479445695e-05,
      "loss": 0.0,
      "step": 56800
    },
    {
      "epoch": 6.087003107253831,
      "grad_norm": 0.0003635203465819359,
      "learning_rate": 1.1883995856994895e-05,
      "loss": 0.3563,
      "step": 56810
    },
    {
      "epoch": 6.088074574091932,
      "grad_norm": 0.008613557554781437,
      "learning_rate": 1.188256723454409e-05,
      "loss": 0.1445,
      "step": 56820
    },
    {
      "epoch": 6.089146040930033,
      "grad_norm": 0.024721411988139153,
      "learning_rate": 1.188113861209329e-05,
      "loss": 0.0011,
      "step": 56830
    },
    {
      "epoch": 6.090217507768134,
      "grad_norm": 0.015001887455582619,
      "learning_rate": 1.1879709989642488e-05,
      "loss": 0.0001,
      "step": 56840
    },
    {
      "epoch": 6.091288974606236,
      "grad_norm": 0.008921492844820023,
      "learning_rate": 1.1878281367191687e-05,
      "loss": 0.0003,
      "step": 56850
    },
    {
      "epoch": 6.092360441444337,
      "grad_norm": 0.0005037426599301398,
      "learning_rate": 1.1876852744740885e-05,
      "loss": 0.2816,
      "step": 56860
    },
    {
      "epoch": 6.093431908282438,
      "grad_norm": 0.0005426134448498487,
      "learning_rate": 1.1875424122290082e-05,
      "loss": 0.1292,
      "step": 56870
    },
    {
      "epoch": 6.09450337512054,
      "grad_norm": 0.0009022658923640847,
      "learning_rate": 1.1873995499839282e-05,
      "loss": 0.1262,
      "step": 56880
    },
    {
      "epoch": 6.0955748419586415,
      "grad_norm": 0.0007913621957413852,
      "learning_rate": 1.1872566877388478e-05,
      "loss": 0.037,
      "step": 56890
    },
    {
      "epoch": 6.096646308796743,
      "grad_norm": 0.025809109210968018,
      "learning_rate": 1.1871138254937677e-05,
      "loss": 0.1396,
      "step": 56900
    },
    {
      "epoch": 6.097717775634844,
      "grad_norm": 1.9556677341461182,
      "learning_rate": 1.1869709632486876e-05,
      "loss": 0.0021,
      "step": 56910
    },
    {
      "epoch": 6.098789242472946,
      "grad_norm": 0.017236527055501938,
      "learning_rate": 1.1868281010036074e-05,
      "loss": 0.0002,
      "step": 56920
    },
    {
      "epoch": 6.099860709311047,
      "grad_norm": 0.0003671338490676135,
      "learning_rate": 1.1866852387585272e-05,
      "loss": 0.0001,
      "step": 56930
    },
    {
      "epoch": 6.100932176149148,
      "grad_norm": 0.00031436592689715326,
      "learning_rate": 1.186542376513447e-05,
      "loss": 0.0004,
      "step": 56940
    },
    {
      "epoch": 6.10200364298725,
      "grad_norm": 0.02773970179259777,
      "learning_rate": 1.1863995142683669e-05,
      "loss": 0.1523,
      "step": 56950
    },
    {
      "epoch": 6.103075109825351,
      "grad_norm": 0.00020746140216942877,
      "learning_rate": 1.1862566520232865e-05,
      "loss": 0.0001,
      "step": 56960
    },
    {
      "epoch": 6.104146576663452,
      "grad_norm": 0.017937064170837402,
      "learning_rate": 1.1861137897782064e-05,
      "loss": 0.0005,
      "step": 56970
    },
    {
      "epoch": 6.105218043501553,
      "grad_norm": 0.000560377724468708,
      "learning_rate": 1.1859709275331264e-05,
      "loss": 0.2133,
      "step": 56980
    },
    {
      "epoch": 6.106289510339655,
      "grad_norm": 0.0004596957005560398,
      "learning_rate": 1.1858280652880461e-05,
      "loss": 0.0002,
      "step": 56990
    },
    {
      "epoch": 6.107360977177756,
      "grad_norm": 0.008520692586898804,
      "learning_rate": 1.1856852030429659e-05,
      "loss": 0.0001,
      "step": 57000
    },
    {
      "epoch": 6.1084324440158575,
      "grad_norm": 0.00022128436830826104,
      "learning_rate": 1.1855423407978857e-05,
      "loss": 0.1175,
      "step": 57010
    },
    {
      "epoch": 6.1095039108539595,
      "grad_norm": 47.17202377319336,
      "learning_rate": 1.1853994785528056e-05,
      "loss": 0.1374,
      "step": 57020
    },
    {
      "epoch": 6.110575377692061,
      "grad_norm": 0.0013529594289138913,
      "learning_rate": 1.1852566163077255e-05,
      "loss": 0.0,
      "step": 57030
    },
    {
      "epoch": 6.111646844530162,
      "grad_norm": 0.0007643605931662023,
      "learning_rate": 1.1851137540626451e-05,
      "loss": 0.0004,
      "step": 57040
    },
    {
      "epoch": 6.112718311368263,
      "grad_norm": 0.00016187064466066658,
      "learning_rate": 1.184970891817565e-05,
      "loss": 0.0001,
      "step": 57050
    },
    {
      "epoch": 6.113789778206365,
      "grad_norm": 0.004220948554575443,
      "learning_rate": 1.1848280295724848e-05,
      "loss": 0.0002,
      "step": 57060
    },
    {
      "epoch": 6.114861245044466,
      "grad_norm": 0.09769508242607117,
      "learning_rate": 1.1846851673274046e-05,
      "loss": 0.1678,
      "step": 57070
    },
    {
      "epoch": 6.115932711882567,
      "grad_norm": 0.003273659385740757,
      "learning_rate": 1.1845423050823244e-05,
      "loss": 0.0075,
      "step": 57080
    },
    {
      "epoch": 6.117004178720668,
      "grad_norm": 0.00031083921203389764,
      "learning_rate": 1.1843994428372443e-05,
      "loss": 0.0015,
      "step": 57090
    },
    {
      "epoch": 6.11807564555877,
      "grad_norm": 22.90740966796875,
      "learning_rate": 1.1842565805921642e-05,
      "loss": 0.1863,
      "step": 57100
    },
    {
      "epoch": 6.119147112396871,
      "grad_norm": 0.005917035974562168,
      "learning_rate": 1.1841137183470838e-05,
      "loss": 0.1596,
      "step": 57110
    },
    {
      "epoch": 6.120218579234972,
      "grad_norm": 0.005246400833129883,
      "learning_rate": 1.1839708561020038e-05,
      "loss": 0.099,
      "step": 57120
    },
    {
      "epoch": 6.121290046073074,
      "grad_norm": 0.0003554503491614014,
      "learning_rate": 1.1838279938569235e-05,
      "loss": 0.0001,
      "step": 57130
    },
    {
      "epoch": 6.1223615129111755,
      "grad_norm": 0.000251934805419296,
      "learning_rate": 1.1836851316118433e-05,
      "loss": 0.0014,
      "step": 57140
    },
    {
      "epoch": 6.123432979749277,
      "grad_norm": 0.017788495868444443,
      "learning_rate": 1.183542269366763e-05,
      "loss": 0.1176,
      "step": 57150
    },
    {
      "epoch": 6.124504446587378,
      "grad_norm": 0.0002999818534590304,
      "learning_rate": 1.183399407121683e-05,
      "loss": 0.0022,
      "step": 57160
    },
    {
      "epoch": 6.12557591342548,
      "grad_norm": 0.00017390804714523256,
      "learning_rate": 1.183256544876603e-05,
      "loss": 0.0,
      "step": 57170
    },
    {
      "epoch": 6.126647380263581,
      "grad_norm": 0.048163361847400665,
      "learning_rate": 1.1831136826315226e-05,
      "loss": 0.0968,
      "step": 57180
    },
    {
      "epoch": 6.127718847101682,
      "grad_norm": 0.0291387178003788,
      "learning_rate": 1.1829708203864425e-05,
      "loss": 0.0002,
      "step": 57190
    },
    {
      "epoch": 6.128790313939784,
      "grad_norm": 0.39860522747039795,
      "learning_rate": 1.1828279581413623e-05,
      "loss": 0.0002,
      "step": 57200
    },
    {
      "epoch": 6.129861780777885,
      "grad_norm": 0.00023587854229845107,
      "learning_rate": 1.1826850958962822e-05,
      "loss": 0.0019,
      "step": 57210
    },
    {
      "epoch": 6.130933247615986,
      "grad_norm": 0.0004631796036846936,
      "learning_rate": 1.182542233651202e-05,
      "loss": 0.0,
      "step": 57220
    },
    {
      "epoch": 6.132004714454087,
      "grad_norm": 0.010276997461915016,
      "learning_rate": 1.1823993714061217e-05,
      "loss": 0.2583,
      "step": 57230
    },
    {
      "epoch": 6.133076181292189,
      "grad_norm": 0.0001338446163572371,
      "learning_rate": 1.1822565091610417e-05,
      "loss": 0.2437,
      "step": 57240
    },
    {
      "epoch": 6.13414764813029,
      "grad_norm": 0.2000575214624405,
      "learning_rate": 1.1821136469159613e-05,
      "loss": 0.0912,
      "step": 57250
    },
    {
      "epoch": 6.1352191149683915,
      "grad_norm": 0.0010262392461299896,
      "learning_rate": 1.1819707846708812e-05,
      "loss": 0.0002,
      "step": 57260
    },
    {
      "epoch": 6.1362905818064934,
      "grad_norm": 0.0015604556538164616,
      "learning_rate": 1.181827922425801e-05,
      "loss": 0.3612,
      "step": 57270
    },
    {
      "epoch": 6.137362048644595,
      "grad_norm": 0.030689997598528862,
      "learning_rate": 1.1816850601807209e-05,
      "loss": 0.0018,
      "step": 57280
    },
    {
      "epoch": 6.138433515482696,
      "grad_norm": 0.006691501475870609,
      "learning_rate": 1.1815421979356407e-05,
      "loss": 0.0766,
      "step": 57290
    },
    {
      "epoch": 6.139504982320797,
      "grad_norm": 0.0001788433437468484,
      "learning_rate": 1.1813993356905604e-05,
      "loss": 0.0003,
      "step": 57300
    },
    {
      "epoch": 6.140576449158899,
      "grad_norm": 0.006315976846963167,
      "learning_rate": 1.1812564734454804e-05,
      "loss": 0.0276,
      "step": 57310
    },
    {
      "epoch": 6.141647915997,
      "grad_norm": 0.00015260356303770095,
      "learning_rate": 1.1811136112004e-05,
      "loss": 0.0009,
      "step": 57320
    },
    {
      "epoch": 6.142719382835101,
      "grad_norm": 0.02806500904262066,
      "learning_rate": 1.1809707489553199e-05,
      "loss": 0.0071,
      "step": 57330
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 0.014134232886135578,
      "learning_rate": 1.1808278867102398e-05,
      "loss": 0.0002,
      "step": 57340
    },
    {
      "epoch": 6.144862316511304,
      "grad_norm": 0.00017609521455597132,
      "learning_rate": 1.1806850244651596e-05,
      "loss": 0.0394,
      "step": 57350
    },
    {
      "epoch": 6.145933783349405,
      "grad_norm": 0.00011165196337969974,
      "learning_rate": 1.1805421622200794e-05,
      "loss": 0.1685,
      "step": 57360
    },
    {
      "epoch": 6.147005250187506,
      "grad_norm": 0.00014324633229989558,
      "learning_rate": 1.1803992999749991e-05,
      "loss": 0.0795,
      "step": 57370
    },
    {
      "epoch": 6.148076717025608,
      "grad_norm": 0.0489661768078804,
      "learning_rate": 1.180256437729919e-05,
      "loss": 0.0001,
      "step": 57380
    },
    {
      "epoch": 6.149148183863709,
      "grad_norm": 0.004626632668077946,
      "learning_rate": 1.1801135754848387e-05,
      "loss": 0.0004,
      "step": 57390
    },
    {
      "epoch": 6.1502196507018105,
      "grad_norm": 0.00013980075891595334,
      "learning_rate": 1.1799707132397586e-05,
      "loss": 0.0001,
      "step": 57400
    },
    {
      "epoch": 6.1512911175399125,
      "grad_norm": 0.00012965910718776286,
      "learning_rate": 1.1798278509946786e-05,
      "loss": 0.0005,
      "step": 57410
    },
    {
      "epoch": 6.152362584378014,
      "grad_norm": 0.006835548207163811,
      "learning_rate": 1.1796849887495983e-05,
      "loss": 0.0012,
      "step": 57420
    },
    {
      "epoch": 6.153434051216115,
      "grad_norm": 0.0003970366669818759,
      "learning_rate": 1.1795421265045181e-05,
      "loss": 0.0166,
      "step": 57430
    },
    {
      "epoch": 6.154505518054216,
      "grad_norm": 0.01859542727470398,
      "learning_rate": 1.1793992642594379e-05,
      "loss": 0.0001,
      "step": 57440
    },
    {
      "epoch": 6.155576984892318,
      "grad_norm": 0.00046118302270770073,
      "learning_rate": 1.1792564020143578e-05,
      "loss": 0.0001,
      "step": 57450
    },
    {
      "epoch": 6.156648451730419,
      "grad_norm": 0.00021603342611342669,
      "learning_rate": 1.1791135397692777e-05,
      "loss": 0.0001,
      "step": 57460
    },
    {
      "epoch": 6.15771991856852,
      "grad_norm": 0.0005414147744886577,
      "learning_rate": 1.1789706775241973e-05,
      "loss": 0.3579,
      "step": 57470
    },
    {
      "epoch": 6.158791385406622,
      "grad_norm": 0.00647394685074687,
      "learning_rate": 1.1788278152791173e-05,
      "loss": 0.0002,
      "step": 57480
    },
    {
      "epoch": 6.159862852244723,
      "grad_norm": 0.011527185328304768,
      "learning_rate": 1.178684953034037e-05,
      "loss": 0.0003,
      "step": 57490
    },
    {
      "epoch": 6.160934319082824,
      "grad_norm": 0.00011718853056663647,
      "learning_rate": 1.1785420907889568e-05,
      "loss": 0.0001,
      "step": 57500
    },
    {
      "epoch": 6.162005785920925,
      "grad_norm": 0.00010300869325874373,
      "learning_rate": 1.1783992285438766e-05,
      "loss": 0.0001,
      "step": 57510
    },
    {
      "epoch": 6.163077252759027,
      "grad_norm": 0.00011455984349595383,
      "learning_rate": 1.1782563662987965e-05,
      "loss": 0.0,
      "step": 57520
    },
    {
      "epoch": 6.1641487195971285,
      "grad_norm": 0.007892049849033356,
      "learning_rate": 1.1781135040537164e-05,
      "loss": 0.121,
      "step": 57530
    },
    {
      "epoch": 6.16522018643523,
      "grad_norm": 0.005251835100352764,
      "learning_rate": 1.177970641808636e-05,
      "loss": 0.0001,
      "step": 57540
    },
    {
      "epoch": 6.166291653273332,
      "grad_norm": 0.0001169612878584303,
      "learning_rate": 1.177827779563556e-05,
      "loss": 0.0,
      "step": 57550
    },
    {
      "epoch": 6.167363120111433,
      "grad_norm": 0.00011155746324220672,
      "learning_rate": 1.1776849173184757e-05,
      "loss": 0.0002,
      "step": 57560
    },
    {
      "epoch": 6.168434586949534,
      "grad_norm": 0.09655733406543732,
      "learning_rate": 1.1775420550733955e-05,
      "loss": 0.112,
      "step": 57570
    },
    {
      "epoch": 6.169506053787635,
      "grad_norm": 0.00012188636901555583,
      "learning_rate": 1.1773991928283154e-05,
      "loss": 0.0001,
      "step": 57580
    },
    {
      "epoch": 6.170577520625737,
      "grad_norm": 0.001387057127431035,
      "learning_rate": 1.1772563305832352e-05,
      "loss": 0.0,
      "step": 57590
    },
    {
      "epoch": 6.171648987463838,
      "grad_norm": 9.304303966928273e-05,
      "learning_rate": 1.1771134683381551e-05,
      "loss": 0.0,
      "step": 57600
    },
    {
      "epoch": 6.172720454301939,
      "grad_norm": 0.004543316084891558,
      "learning_rate": 1.1769706060930747e-05,
      "loss": 0.0001,
      "step": 57610
    },
    {
      "epoch": 6.17379192114004,
      "grad_norm": 0.00011642426397884265,
      "learning_rate": 1.1768277438479947e-05,
      "loss": 0.0001,
      "step": 57620
    },
    {
      "epoch": 6.174863387978142,
      "grad_norm": 0.004645835608243942,
      "learning_rate": 1.1766848816029144e-05,
      "loss": 0.0001,
      "step": 57630
    },
    {
      "epoch": 6.175934854816243,
      "grad_norm": 0.005586533807218075,
      "learning_rate": 1.1765420193578342e-05,
      "loss": 0.3969,
      "step": 57640
    },
    {
      "epoch": 6.1770063216543445,
      "grad_norm": 0.00024114345433190465,
      "learning_rate": 1.1763991571127542e-05,
      "loss": 0.0001,
      "step": 57650
    },
    {
      "epoch": 6.1780777884924465,
      "grad_norm": 0.0009773880010470748,
      "learning_rate": 1.176256294867674e-05,
      "loss": 0.0024,
      "step": 57660
    },
    {
      "epoch": 6.179149255330548,
      "grad_norm": 0.016602931544184685,
      "learning_rate": 1.1761134326225939e-05,
      "loss": 0.0001,
      "step": 57670
    },
    {
      "epoch": 6.180220722168649,
      "grad_norm": 0.0008953363285399973,
      "learning_rate": 1.1759705703775135e-05,
      "loss": 0.0001,
      "step": 57680
    },
    {
      "epoch": 6.18129218900675,
      "grad_norm": 0.00021508143981918693,
      "learning_rate": 1.1758277081324334e-05,
      "loss": 0.0003,
      "step": 57690
    },
    {
      "epoch": 6.182363655844852,
      "grad_norm": 0.01840166561305523,
      "learning_rate": 1.1756848458873533e-05,
      "loss": 0.0578,
      "step": 57700
    },
    {
      "epoch": 6.183435122682953,
      "grad_norm": 0.0014566356549039483,
      "learning_rate": 1.1755419836422731e-05,
      "loss": 0.0,
      "step": 57710
    },
    {
      "epoch": 6.184506589521054,
      "grad_norm": 0.0005308560794219375,
      "learning_rate": 1.1753991213971929e-05,
      "loss": 0.003,
      "step": 57720
    },
    {
      "epoch": 6.185578056359156,
      "grad_norm": 0.0023184525780379772,
      "learning_rate": 1.1752562591521126e-05,
      "loss": 0.0001,
      "step": 57730
    },
    {
      "epoch": 6.186649523197257,
      "grad_norm": 0.0025940765626728535,
      "learning_rate": 1.1751133969070326e-05,
      "loss": 0.1822,
      "step": 57740
    },
    {
      "epoch": 6.187720990035358,
      "grad_norm": 0.00023703985789325088,
      "learning_rate": 1.1749705346619522e-05,
      "loss": 0.2958,
      "step": 57750
    },
    {
      "epoch": 6.188792456873459,
      "grad_norm": 0.00486927293241024,
      "learning_rate": 1.1748276724168721e-05,
      "loss": 0.0001,
      "step": 57760
    },
    {
      "epoch": 6.189863923711561,
      "grad_norm": 0.007574120070785284,
      "learning_rate": 1.174684810171792e-05,
      "loss": 0.0,
      "step": 57770
    },
    {
      "epoch": 6.1909353905496625,
      "grad_norm": 0.00025744695449247956,
      "learning_rate": 1.1745419479267118e-05,
      "loss": 0.0001,
      "step": 57780
    },
    {
      "epoch": 6.192006857387764,
      "grad_norm": 0.0005873100599274039,
      "learning_rate": 1.1743990856816316e-05,
      "loss": 0.2358,
      "step": 57790
    },
    {
      "epoch": 6.193078324225866,
      "grad_norm": 0.008356042206287384,
      "learning_rate": 1.1742562234365513e-05,
      "loss": 0.1469,
      "step": 57800
    },
    {
      "epoch": 6.194149791063967,
      "grad_norm": 0.00527025293558836,
      "learning_rate": 1.1741133611914713e-05,
      "loss": 0.0001,
      "step": 57810
    },
    {
      "epoch": 6.195221257902068,
      "grad_norm": 0.01619926653802395,
      "learning_rate": 1.1739704989463912e-05,
      "loss": 0.2669,
      "step": 57820
    },
    {
      "epoch": 6.196292724740169,
      "grad_norm": 0.00046682407264597714,
      "learning_rate": 1.1738276367013108e-05,
      "loss": 0.0001,
      "step": 57830
    },
    {
      "epoch": 6.197364191578271,
      "grad_norm": 0.011511292308568954,
      "learning_rate": 1.1736847744562307e-05,
      "loss": 0.0668,
      "step": 57840
    },
    {
      "epoch": 6.198435658416372,
      "grad_norm": 0.0004552327445708215,
      "learning_rate": 1.1735419122111505e-05,
      "loss": 0.0,
      "step": 57850
    },
    {
      "epoch": 6.199507125254473,
      "grad_norm": 0.011556549929082394,
      "learning_rate": 1.1733990499660703e-05,
      "loss": 0.2591,
      "step": 57860
    },
    {
      "epoch": 6.200578592092575,
      "grad_norm": 16.362634658813477,
      "learning_rate": 1.17325618772099e-05,
      "loss": 0.2453,
      "step": 57870
    },
    {
      "epoch": 6.201650058930676,
      "grad_norm": 0.014375739730894566,
      "learning_rate": 1.17311332547591e-05,
      "loss": 0.0001,
      "step": 57880
    },
    {
      "epoch": 6.202721525768777,
      "grad_norm": 0.00026906633866019547,
      "learning_rate": 1.17297046323083e-05,
      "loss": 0.0067,
      "step": 57890
    },
    {
      "epoch": 6.203792992606878,
      "grad_norm": 0.029888352379202843,
      "learning_rate": 1.1728276009857495e-05,
      "loss": 0.0002,
      "step": 57900
    },
    {
      "epoch": 6.20486445944498,
      "grad_norm": 0.0020471697207540274,
      "learning_rate": 1.1726847387406695e-05,
      "loss": 0.0001,
      "step": 57910
    },
    {
      "epoch": 6.2059359262830815,
      "grad_norm": 0.00031958898762241006,
      "learning_rate": 1.1725418764955892e-05,
      "loss": 0.3886,
      "step": 57920
    },
    {
      "epoch": 6.207007393121183,
      "grad_norm": 0.033641453832387924,
      "learning_rate": 1.172399014250509e-05,
      "loss": 0.0002,
      "step": 57930
    },
    {
      "epoch": 6.208078859959285,
      "grad_norm": 0.0005177731509320438,
      "learning_rate": 1.172256152005429e-05,
      "loss": 0.0343,
      "step": 57940
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 0.017699966207146645,
      "learning_rate": 1.1721132897603487e-05,
      "loss": 0.0003,
      "step": 57950
    },
    {
      "epoch": 6.210221793635487,
      "grad_norm": 0.03375881165266037,
      "learning_rate": 1.1719704275152686e-05,
      "loss": 0.0004,
      "step": 57960
    },
    {
      "epoch": 6.211293260473588,
      "grad_norm": 0.008961698040366173,
      "learning_rate": 1.1718275652701882e-05,
      "loss": 0.0003,
      "step": 57970
    },
    {
      "epoch": 6.21236472731169,
      "grad_norm": 0.03271086886525154,
      "learning_rate": 1.1716847030251082e-05,
      "loss": 0.0002,
      "step": 57980
    },
    {
      "epoch": 6.213436194149791,
      "grad_norm": 0.014282618649303913,
      "learning_rate": 1.171541840780028e-05,
      "loss": 0.0008,
      "step": 57990
    },
    {
      "epoch": 6.214507660987892,
      "grad_norm": 185.5872802734375,
      "learning_rate": 1.1713989785349477e-05,
      "loss": 0.2221,
      "step": 58000
    },
    {
      "epoch": 6.215579127825994,
      "grad_norm": 0.0002301639033248648,
      "learning_rate": 1.1712561162898676e-05,
      "loss": 0.0001,
      "step": 58010
    },
    {
      "epoch": 6.216650594664095,
      "grad_norm": 0.016426607966423035,
      "learning_rate": 1.1711132540447874e-05,
      "loss": 0.2406,
      "step": 58020
    },
    {
      "epoch": 6.217722061502196,
      "grad_norm": 0.009283561259508133,
      "learning_rate": 1.1709703917997073e-05,
      "loss": 0.1786,
      "step": 58030
    },
    {
      "epoch": 6.2187935283402975,
      "grad_norm": 0.09673522412776947,
      "learning_rate": 1.170827529554627e-05,
      "loss": 0.0002,
      "step": 58040
    },
    {
      "epoch": 6.2198649951783995,
      "grad_norm": 0.013261160813272,
      "learning_rate": 1.1706846673095469e-05,
      "loss": 0.0001,
      "step": 58050
    },
    {
      "epoch": 6.220936462016501,
      "grad_norm": 0.023586060851812363,
      "learning_rate": 1.1705418050644666e-05,
      "loss": 0.2116,
      "step": 58060
    },
    {
      "epoch": 6.222007928854602,
      "grad_norm": 0.00035312387626618147,
      "learning_rate": 1.1703989428193864e-05,
      "loss": 0.0004,
      "step": 58070
    },
    {
      "epoch": 6.223079395692704,
      "grad_norm": 0.0019396806601434946,
      "learning_rate": 1.1702560805743063e-05,
      "loss": 0.0001,
      "step": 58080
    },
    {
      "epoch": 6.224150862530805,
      "grad_norm": 0.015318268910050392,
      "learning_rate": 1.1701132183292261e-05,
      "loss": 0.0001,
      "step": 58090
    },
    {
      "epoch": 6.225222329368906,
      "grad_norm": 0.000549888180103153,
      "learning_rate": 1.169970356084146e-05,
      "loss": 0.0002,
      "step": 58100
    },
    {
      "epoch": 6.226293796207007,
      "grad_norm": 0.0003052007232327014,
      "learning_rate": 1.1698274938390656e-05,
      "loss": 0.0001,
      "step": 58110
    },
    {
      "epoch": 6.227365263045109,
      "grad_norm": 0.00036787596764042974,
      "learning_rate": 1.1696846315939856e-05,
      "loss": 0.0001,
      "step": 58120
    },
    {
      "epoch": 6.22843672988321,
      "grad_norm": 55.806766510009766,
      "learning_rate": 1.1695417693489055e-05,
      "loss": 0.2096,
      "step": 58130
    },
    {
      "epoch": 6.229508196721311,
      "grad_norm": 0.00444811163470149,
      "learning_rate": 1.1693989071038251e-05,
      "loss": 0.0002,
      "step": 58140
    },
    {
      "epoch": 6.230579663559412,
      "grad_norm": 0.00024740351364016533,
      "learning_rate": 1.169256044858745e-05,
      "loss": 0.0048,
      "step": 58150
    },
    {
      "epoch": 6.231651130397514,
      "grad_norm": 0.06543289870023727,
      "learning_rate": 1.1691131826136648e-05,
      "loss": 0.3224,
      "step": 58160
    },
    {
      "epoch": 6.2327225972356155,
      "grad_norm": 0.024317171424627304,
      "learning_rate": 1.1689703203685848e-05,
      "loss": 0.0004,
      "step": 58170
    },
    {
      "epoch": 6.233794064073717,
      "grad_norm": 0.010996226221323013,
      "learning_rate": 1.1688274581235044e-05,
      "loss": 0.0004,
      "step": 58180
    },
    {
      "epoch": 6.234865530911819,
      "grad_norm": 0.010993166826665401,
      "learning_rate": 1.1686845958784243e-05,
      "loss": 0.0013,
      "step": 58190
    },
    {
      "epoch": 6.23593699774992,
      "grad_norm": 0.0003772620402742177,
      "learning_rate": 1.1685417336333442e-05,
      "loss": 0.0001,
      "step": 58200
    },
    {
      "epoch": 6.237008464588021,
      "grad_norm": 0.00034981343196704984,
      "learning_rate": 1.1683988713882638e-05,
      "loss": 0.1756,
      "step": 58210
    },
    {
      "epoch": 6.238079931426122,
      "grad_norm": 0.0003197173646185547,
      "learning_rate": 1.1682560091431838e-05,
      "loss": 0.0005,
      "step": 58220
    },
    {
      "epoch": 6.239151398264224,
      "grad_norm": 0.00041675512329675257,
      "learning_rate": 1.1681131468981035e-05,
      "loss": 0.0007,
      "step": 58230
    },
    {
      "epoch": 6.240222865102325,
      "grad_norm": 0.01709897257387638,
      "learning_rate": 1.1679702846530235e-05,
      "loss": 0.1935,
      "step": 58240
    },
    {
      "epoch": 6.241294331940426,
      "grad_norm": 0.014011971652507782,
      "learning_rate": 1.1678274224079434e-05,
      "loss": 0.0002,
      "step": 58250
    },
    {
      "epoch": 6.242365798778528,
      "grad_norm": 0.015408792532980442,
      "learning_rate": 1.167684560162863e-05,
      "loss": 0.1698,
      "step": 58260
    },
    {
      "epoch": 6.243437265616629,
      "grad_norm": 14.851451873779297,
      "learning_rate": 1.167541697917783e-05,
      "loss": 0.2327,
      "step": 58270
    },
    {
      "epoch": 6.24450873245473,
      "grad_norm": 0.001962416572496295,
      "learning_rate": 1.1673988356727027e-05,
      "loss": 0.1289,
      "step": 58280
    },
    {
      "epoch": 6.2455801992928315,
      "grad_norm": 0.09406418353319168,
      "learning_rate": 1.1672559734276225e-05,
      "loss": 0.3726,
      "step": 58290
    },
    {
      "epoch": 6.2466516661309335,
      "grad_norm": 0.0017808357952162623,
      "learning_rate": 1.1671131111825422e-05,
      "loss": 0.0005,
      "step": 58300
    },
    {
      "epoch": 6.247723132969035,
      "grad_norm": 0.07148576527833939,
      "learning_rate": 1.1669702489374622e-05,
      "loss": 0.1083,
      "step": 58310
    },
    {
      "epoch": 6.248794599807136,
      "grad_norm": 0.001924098003655672,
      "learning_rate": 1.1668273866923821e-05,
      "loss": 0.0011,
      "step": 58320
    },
    {
      "epoch": 6.249866066645238,
      "grad_norm": 0.11774235218763351,
      "learning_rate": 1.1666845244473017e-05,
      "loss": 0.0028,
      "step": 58330
    },
    {
      "epoch": 6.250937533483339,
      "grad_norm": 0.0005607130588032305,
      "learning_rate": 1.1665416622022217e-05,
      "loss": 0.1752,
      "step": 58340
    },
    {
      "epoch": 6.25200900032144,
      "grad_norm": 0.0004474074812605977,
      "learning_rate": 1.1663987999571414e-05,
      "loss": 0.0002,
      "step": 58350
    },
    {
      "epoch": 6.253080467159541,
      "grad_norm": 0.0004198226670268923,
      "learning_rate": 1.1662559377120612e-05,
      "loss": 0.192,
      "step": 58360
    },
    {
      "epoch": 6.254151933997643,
      "grad_norm": 0.00040985015220940113,
      "learning_rate": 1.1661130754669811e-05,
      "loss": 0.2614,
      "step": 58370
    },
    {
      "epoch": 6.255223400835744,
      "grad_norm": 0.0007845392101444304,
      "learning_rate": 1.1659702132219009e-05,
      "loss": 0.0011,
      "step": 58380
    },
    {
      "epoch": 6.256294867673845,
      "grad_norm": 0.0009250833536498249,
      "learning_rate": 1.1658273509768208e-05,
      "loss": 0.0004,
      "step": 58390
    },
    {
      "epoch": 6.257366334511947,
      "grad_norm": 0.004869135562330484,
      "learning_rate": 1.1656844887317404e-05,
      "loss": 0.0008,
      "step": 58400
    },
    {
      "epoch": 6.258437801350048,
      "grad_norm": 0.0005275564035400748,
      "learning_rate": 1.1655416264866604e-05,
      "loss": 0.0002,
      "step": 58410
    },
    {
      "epoch": 6.2595092681881495,
      "grad_norm": 0.0014777641044929624,
      "learning_rate": 1.1653987642415801e-05,
      "loss": 0.0037,
      "step": 58420
    },
    {
      "epoch": 6.260580735026251,
      "grad_norm": 0.05290031060576439,
      "learning_rate": 1.1652559019964999e-05,
      "loss": 0.0007,
      "step": 58430
    },
    {
      "epoch": 6.261652201864353,
      "grad_norm": 0.0002932834904640913,
      "learning_rate": 1.1651130397514198e-05,
      "loss": 0.0005,
      "step": 58440
    },
    {
      "epoch": 6.262723668702454,
      "grad_norm": 0.00033009829348884523,
      "learning_rate": 1.1649701775063396e-05,
      "loss": 0.0002,
      "step": 58450
    },
    {
      "epoch": 6.263795135540555,
      "grad_norm": 0.0006597363972105086,
      "learning_rate": 1.1648273152612595e-05,
      "loss": 0.0004,
      "step": 58460
    },
    {
      "epoch": 6.264866602378657,
      "grad_norm": 0.024270834401249886,
      "learning_rate": 1.1646844530161791e-05,
      "loss": 0.0005,
      "step": 58470
    },
    {
      "epoch": 6.265938069216758,
      "grad_norm": 0.02090350165963173,
      "learning_rate": 1.164541590771099e-05,
      "loss": 0.0001,
      "step": 58480
    },
    {
      "epoch": 6.267009536054859,
      "grad_norm": 0.08560189604759216,
      "learning_rate": 1.164398728526019e-05,
      "loss": 0.1987,
      "step": 58490
    },
    {
      "epoch": 6.26808100289296,
      "grad_norm": 0.03048298880457878,
      "learning_rate": 1.1642558662809386e-05,
      "loss": 0.0003,
      "step": 58500
    },
    {
      "epoch": 6.269152469731062,
      "grad_norm": 0.025548424571752548,
      "learning_rate": 1.1641130040358585e-05,
      "loss": 0.1835,
      "step": 58510
    },
    {
      "epoch": 6.270223936569163,
      "grad_norm": 0.02256755344569683,
      "learning_rate": 1.1639701417907783e-05,
      "loss": 0.1993,
      "step": 58520
    },
    {
      "epoch": 6.271295403407264,
      "grad_norm": 0.028787894174456596,
      "learning_rate": 1.1638272795456982e-05,
      "loss": 0.2004,
      "step": 58530
    },
    {
      "epoch": 6.272366870245366,
      "grad_norm": 0.07336000353097916,
      "learning_rate": 1.1636844173006178e-05,
      "loss": 0.1729,
      "step": 58540
    },
    {
      "epoch": 6.273438337083467,
      "grad_norm": 0.00033813738264143467,
      "learning_rate": 1.1635415550555378e-05,
      "loss": 0.259,
      "step": 58550
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 0.00033426444861106575,
      "learning_rate": 1.1633986928104577e-05,
      "loss": 0.0006,
      "step": 58560
    },
    {
      "epoch": 6.27558127075967,
      "grad_norm": 0.0062911007553339005,
      "learning_rate": 1.1632558305653773e-05,
      "loss": 0.0004,
      "step": 58570
    },
    {
      "epoch": 6.276652737597772,
      "grad_norm": 0.038009852170944214,
      "learning_rate": 1.1631129683202973e-05,
      "loss": 0.0002,
      "step": 58580
    },
    {
      "epoch": 6.277724204435873,
      "grad_norm": 0.1619253307580948,
      "learning_rate": 1.162970106075217e-05,
      "loss": 0.0007,
      "step": 58590
    },
    {
      "epoch": 6.278795671273974,
      "grad_norm": 0.04816322773694992,
      "learning_rate": 1.162827243830137e-05,
      "loss": 0.0024,
      "step": 58600
    },
    {
      "epoch": 6.279867138112076,
      "grad_norm": 1.2114843130111694,
      "learning_rate": 1.1626843815850569e-05,
      "loss": 0.0013,
      "step": 58610
    },
    {
      "epoch": 6.280938604950177,
      "grad_norm": 0.00026803126093000174,
      "learning_rate": 1.1625415193399765e-05,
      "loss": 0.0004,
      "step": 58620
    },
    {
      "epoch": 6.282010071788278,
      "grad_norm": 0.011603918857872486,
      "learning_rate": 1.1623986570948964e-05,
      "loss": 0.1799,
      "step": 58630
    },
    {
      "epoch": 6.283081538626379,
      "grad_norm": 0.039799951016902924,
      "learning_rate": 1.162255794849816e-05,
      "loss": 0.1767,
      "step": 58640
    },
    {
      "epoch": 6.284153005464481,
      "grad_norm": 0.006733605172485113,
      "learning_rate": 1.162112932604736e-05,
      "loss": 0.001,
      "step": 58650
    },
    {
      "epoch": 6.285224472302582,
      "grad_norm": 0.0010524069657549262,
      "learning_rate": 1.1619700703596557e-05,
      "loss": 0.0001,
      "step": 58660
    },
    {
      "epoch": 6.286295939140683,
      "grad_norm": 0.005384871736168861,
      "learning_rate": 1.1618272081145757e-05,
      "loss": 0.3861,
      "step": 58670
    },
    {
      "epoch": 6.2873674059787845,
      "grad_norm": 0.05210917815566063,
      "learning_rate": 1.1616843458694956e-05,
      "loss": 0.1307,
      "step": 58680
    },
    {
      "epoch": 6.2884388728168865,
      "grad_norm": 0.0002589649520814419,
      "learning_rate": 1.1615414836244152e-05,
      "loss": 0.0001,
      "step": 58690
    },
    {
      "epoch": 6.289510339654988,
      "grad_norm": 0.04019613191485405,
      "learning_rate": 1.1613986213793351e-05,
      "loss": 0.1372,
      "step": 58700
    },
    {
      "epoch": 6.290581806493089,
      "grad_norm": 0.00022317399270832539,
      "learning_rate": 1.1612557591342547e-05,
      "loss": 0.3717,
      "step": 58710
    },
    {
      "epoch": 6.291653273331191,
      "grad_norm": 0.00023520697141066194,
      "learning_rate": 1.1611128968891747e-05,
      "loss": 0.1116,
      "step": 58720
    },
    {
      "epoch": 6.292724740169292,
      "grad_norm": 0.005273839458823204,
      "learning_rate": 1.1609700346440946e-05,
      "loss": 0.1461,
      "step": 58730
    },
    {
      "epoch": 6.293796207007393,
      "grad_norm": 0.00022495901794172823,
      "learning_rate": 1.1608271723990144e-05,
      "loss": 0.0004,
      "step": 58740
    },
    {
      "epoch": 6.294867673845495,
      "grad_norm": 0.23654231429100037,
      "learning_rate": 1.1606843101539343e-05,
      "loss": 0.0017,
      "step": 58750
    },
    {
      "epoch": 6.295939140683596,
      "grad_norm": 0.05366301164031029,
      "learning_rate": 1.1605414479088539e-05,
      "loss": 0.2705,
      "step": 58760
    },
    {
      "epoch": 6.297010607521697,
      "grad_norm": 0.10846205055713654,
      "learning_rate": 1.1603985856637738e-05,
      "loss": 0.0006,
      "step": 58770
    },
    {
      "epoch": 6.298082074359798,
      "grad_norm": 0.01804693602025509,
      "learning_rate": 1.1602557234186934e-05,
      "loss": 0.1076,
      "step": 58780
    },
    {
      "epoch": 6.2991535411979,
      "grad_norm": 0.00024462121655233204,
      "learning_rate": 1.1601128611736134e-05,
      "loss": 0.1514,
      "step": 58790
    },
    {
      "epoch": 6.300225008036001,
      "grad_norm": 0.00031854392727836967,
      "learning_rate": 1.1599699989285333e-05,
      "loss": 0.1019,
      "step": 58800
    },
    {
      "epoch": 6.3012964748741025,
      "grad_norm": 0.03894949331879616,
      "learning_rate": 1.159827136683453e-05,
      "loss": 0.1667,
      "step": 58810
    },
    {
      "epoch": 6.302367941712204,
      "grad_norm": 0.03202523663640022,
      "learning_rate": 1.159684274438373e-05,
      "loss": 0.0004,
      "step": 58820
    },
    {
      "epoch": 6.303439408550306,
      "grad_norm": 0.017456136643886566,
      "learning_rate": 1.1595414121932926e-05,
      "loss": 0.0002,
      "step": 58830
    },
    {
      "epoch": 6.304510875388407,
      "grad_norm": 0.05543208494782448,
      "learning_rate": 1.1593985499482126e-05,
      "loss": 0.1861,
      "step": 58840
    },
    {
      "epoch": 6.305582342226508,
      "grad_norm": 0.04812559112906456,
      "learning_rate": 1.1592556877031325e-05,
      "loss": 0.0828,
      "step": 58850
    },
    {
      "epoch": 6.30665380906461,
      "grad_norm": 0.04424101486802101,
      "learning_rate": 1.1591128254580521e-05,
      "loss": 0.0004,
      "step": 58860
    },
    {
      "epoch": 6.307725275902711,
      "grad_norm": 0.01924429088830948,
      "learning_rate": 1.158969963212972e-05,
      "loss": 0.294,
      "step": 58870
    },
    {
      "epoch": 6.308796742740812,
      "grad_norm": 0.0001929088612087071,
      "learning_rate": 1.1588271009678918e-05,
      "loss": 0.0001,
      "step": 58880
    },
    {
      "epoch": 6.309868209578913,
      "grad_norm": 0.14462676644325256,
      "learning_rate": 1.1586842387228117e-05,
      "loss": 0.0003,
      "step": 58890
    },
    {
      "epoch": 6.310939676417015,
      "grad_norm": 0.017516449093818665,
      "learning_rate": 1.1585413764777313e-05,
      "loss": 0.0032,
      "step": 58900
    },
    {
      "epoch": 6.312011143255116,
      "grad_norm": 0.0009941173484548926,
      "learning_rate": 1.1583985142326513e-05,
      "loss": 0.243,
      "step": 58910
    },
    {
      "epoch": 6.313082610093217,
      "grad_norm": 0.00019371981034055352,
      "learning_rate": 1.1582556519875712e-05,
      "loss": 0.0018,
      "step": 58920
    },
    {
      "epoch": 6.314154076931319,
      "grad_norm": 0.0002888761810027063,
      "learning_rate": 1.1581127897424908e-05,
      "loss": 0.2412,
      "step": 58930
    },
    {
      "epoch": 6.3152255437694205,
      "grad_norm": 0.0002266599185531959,
      "learning_rate": 1.1579699274974107e-05,
      "loss": 0.1742,
      "step": 58940
    },
    {
      "epoch": 6.316297010607522,
      "grad_norm": 0.041869424283504486,
      "learning_rate": 1.1578270652523305e-05,
      "loss": 0.5503,
      "step": 58950
    },
    {
      "epoch": 6.317368477445623,
      "grad_norm": 0.056827180087566376,
      "learning_rate": 1.1576842030072504e-05,
      "loss": 0.1388,
      "step": 58960
    },
    {
      "epoch": 6.318439944283725,
      "grad_norm": 0.04061014577746391,
      "learning_rate": 1.15754134076217e-05,
      "loss": 0.0015,
      "step": 58970
    },
    {
      "epoch": 6.319511411121826,
      "grad_norm": 0.0008877533837221563,
      "learning_rate": 1.15739847851709e-05,
      "loss": 0.1099,
      "step": 58980
    },
    {
      "epoch": 6.320582877959927,
      "grad_norm": 0.0015467640478163958,
      "learning_rate": 1.1572556162720099e-05,
      "loss": 0.3308,
      "step": 58990
    },
    {
      "epoch": 6.321654344798029,
      "grad_norm": 0.014432054944336414,
      "learning_rate": 1.1571127540269295e-05,
      "loss": 0.0008,
      "step": 59000
    },
    {
      "epoch": 6.32272581163613,
      "grad_norm": 0.003040247829630971,
      "learning_rate": 1.1569698917818494e-05,
      "loss": 0.282,
      "step": 59010
    },
    {
      "epoch": 6.323797278474231,
      "grad_norm": 0.059750329703092575,
      "learning_rate": 1.1568270295367692e-05,
      "loss": 0.0028,
      "step": 59020
    },
    {
      "epoch": 6.324868745312332,
      "grad_norm": 0.002374856034293771,
      "learning_rate": 1.1566841672916891e-05,
      "loss": 0.0012,
      "step": 59030
    },
    {
      "epoch": 6.325940212150434,
      "grad_norm": 67.69709014892578,
      "learning_rate": 1.156541305046609e-05,
      "loss": 0.2519,
      "step": 59040
    },
    {
      "epoch": 6.327011678988535,
      "grad_norm": 0.001774060307070613,
      "learning_rate": 1.1563984428015287e-05,
      "loss": 0.0006,
      "step": 59050
    },
    {
      "epoch": 6.3280831458266364,
      "grad_norm": 0.036441050469875336,
      "learning_rate": 1.1562555805564486e-05,
      "loss": 0.0016,
      "step": 59060
    },
    {
      "epoch": 6.3291546126647376,
      "grad_norm": 0.0007043437799438834,
      "learning_rate": 1.1561127183113682e-05,
      "loss": 0.1804,
      "step": 59070
    },
    {
      "epoch": 6.3302260795028396,
      "grad_norm": 0.0009299142984673381,
      "learning_rate": 1.1559698560662882e-05,
      "loss": 0.0001,
      "step": 59080
    },
    {
      "epoch": 6.331297546340941,
      "grad_norm": 0.0007147637661546469,
      "learning_rate": 1.155826993821208e-05,
      "loss": 0.0009,
      "step": 59090
    },
    {
      "epoch": 6.332369013179042,
      "grad_norm": 0.0017391975270584226,
      "learning_rate": 1.1556841315761279e-05,
      "loss": 0.0,
      "step": 59100
    },
    {
      "epoch": 6.333440480017144,
      "grad_norm": 0.0006483212928287685,
      "learning_rate": 1.1555412693310478e-05,
      "loss": 0.0016,
      "step": 59110
    },
    {
      "epoch": 6.334511946855245,
      "grad_norm": 0.02231702022254467,
      "learning_rate": 1.1553984070859674e-05,
      "loss": 0.2137,
      "step": 59120
    },
    {
      "epoch": 6.335583413693346,
      "grad_norm": 0.011644706130027771,
      "learning_rate": 1.1552555448408873e-05,
      "loss": 0.0002,
      "step": 59130
    },
    {
      "epoch": 6.336654880531448,
      "grad_norm": 0.0011830328730866313,
      "learning_rate": 1.155112682595807e-05,
      "loss": 0.0001,
      "step": 59140
    },
    {
      "epoch": 6.337726347369549,
      "grad_norm": 0.0026022212114185095,
      "learning_rate": 1.1549698203507269e-05,
      "loss": 0.0006,
      "step": 59150
    },
    {
      "epoch": 6.33879781420765,
      "grad_norm": 0.02487427555024624,
      "learning_rate": 1.1548269581056468e-05,
      "loss": 0.0827,
      "step": 59160
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 0.005262475926429033,
      "learning_rate": 1.1546840958605666e-05,
      "loss": 0.0011,
      "step": 59170
    },
    {
      "epoch": 6.340940747883853,
      "grad_norm": 0.002101370831951499,
      "learning_rate": 1.1545412336154865e-05,
      "loss": 0.2026,
      "step": 59180
    },
    {
      "epoch": 6.342012214721954,
      "grad_norm": 0.010711386799812317,
      "learning_rate": 1.1543983713704061e-05,
      "loss": 0.0006,
      "step": 59190
    },
    {
      "epoch": 6.3430836815600555,
      "grad_norm": 0.010308320634067059,
      "learning_rate": 1.154255509125326e-05,
      "loss": 0.2688,
      "step": 59200
    },
    {
      "epoch": 6.344155148398157,
      "grad_norm": 15.744900703430176,
      "learning_rate": 1.1541126468802456e-05,
      "loss": 0.3992,
      "step": 59210
    },
    {
      "epoch": 6.345226615236259,
      "grad_norm": 0.018981337547302246,
      "learning_rate": 1.1539697846351656e-05,
      "loss": 0.2151,
      "step": 59220
    },
    {
      "epoch": 6.34629808207436,
      "grad_norm": 0.0008579997811466455,
      "learning_rate": 1.1538269223900855e-05,
      "loss": 0.0012,
      "step": 59230
    },
    {
      "epoch": 6.347369548912461,
      "grad_norm": 0.09410446137189865,
      "learning_rate": 1.1536840601450053e-05,
      "loss": 0.0015,
      "step": 59240
    },
    {
      "epoch": 6.348441015750563,
      "grad_norm": 0.004042624495923519,
      "learning_rate": 1.1535411978999252e-05,
      "loss": 0.1,
      "step": 59250
    },
    {
      "epoch": 6.349512482588664,
      "grad_norm": 0.009473252110183239,
      "learning_rate": 1.1533983356548448e-05,
      "loss": 0.0006,
      "step": 59260
    },
    {
      "epoch": 6.350583949426765,
      "grad_norm": 0.0012284504482522607,
      "learning_rate": 1.1532554734097647e-05,
      "loss": 0.0004,
      "step": 59270
    },
    {
      "epoch": 6.351655416264867,
      "grad_norm": 0.0015163474017754197,
      "learning_rate": 1.1531126111646847e-05,
      "loss": 0.0004,
      "step": 59280
    },
    {
      "epoch": 6.352726883102968,
      "grad_norm": 0.0015535117127001286,
      "learning_rate": 1.1529697489196043e-05,
      "loss": 0.0004,
      "step": 59290
    },
    {
      "epoch": 6.353798349941069,
      "grad_norm": 0.1741504818201065,
      "learning_rate": 1.1528268866745242e-05,
      "loss": 0.0004,
      "step": 59300
    },
    {
      "epoch": 6.35486981677917,
      "grad_norm": 0.000984099111519754,
      "learning_rate": 1.152684024429444e-05,
      "loss": 0.0003,
      "step": 59310
    },
    {
      "epoch": 6.355941283617272,
      "grad_norm": 0.001054413616657257,
      "learning_rate": 1.152541162184364e-05,
      "loss": 0.0007,
      "step": 59320
    },
    {
      "epoch": 6.3570127504553735,
      "grad_norm": 0.004010519478470087,
      "learning_rate": 1.1523982999392835e-05,
      "loss": 0.2812,
      "step": 59330
    },
    {
      "epoch": 6.358084217293475,
      "grad_norm": 0.0016792064998298883,
      "learning_rate": 1.1522554376942035e-05,
      "loss": 0.0034,
      "step": 59340
    },
    {
      "epoch": 6.359155684131576,
      "grad_norm": 0.005827485583722591,
      "learning_rate": 1.1521125754491234e-05,
      "loss": 0.0003,
      "step": 59350
    },
    {
      "epoch": 6.360227150969678,
      "grad_norm": 0.017083432525396347,
      "learning_rate": 1.151969713204043e-05,
      "loss": 0.0003,
      "step": 59360
    },
    {
      "epoch": 6.361298617807779,
      "grad_norm": 0.020046906545758247,
      "learning_rate": 1.151826850958963e-05,
      "loss": 0.0004,
      "step": 59370
    },
    {
      "epoch": 6.36237008464588,
      "grad_norm": 0.014732850715517998,
      "learning_rate": 1.1516839887138827e-05,
      "loss": 0.0012,
      "step": 59380
    },
    {
      "epoch": 6.363441551483982,
      "grad_norm": 0.0006823756848461926,
      "learning_rate": 1.1515411264688026e-05,
      "loss": 0.0004,
      "step": 59390
    },
    {
      "epoch": 6.364513018322083,
      "grad_norm": 0.0005288415122777224,
      "learning_rate": 1.1513982642237224e-05,
      "loss": 0.0003,
      "step": 59400
    },
    {
      "epoch": 6.365584485160184,
      "grad_norm": 0.001227642991580069,
      "learning_rate": 1.1512554019786422e-05,
      "loss": 0.0001,
      "step": 59410
    },
    {
      "epoch": 6.366655951998285,
      "grad_norm": 0.0009905967162922025,
      "learning_rate": 1.1511125397335621e-05,
      "loss": 0.0001,
      "step": 59420
    },
    {
      "epoch": 6.367727418836387,
      "grad_norm": 0.0015712291933596134,
      "learning_rate": 1.1509696774884817e-05,
      "loss": 0.0001,
      "step": 59430
    },
    {
      "epoch": 6.368798885674488,
      "grad_norm": 0.012304224073886871,
      "learning_rate": 1.1508268152434016e-05,
      "loss": 0.0001,
      "step": 59440
    },
    {
      "epoch": 6.3698703525125895,
      "grad_norm": 0.0016339215217158198,
      "learning_rate": 1.1506839529983214e-05,
      "loss": 0.2,
      "step": 59450
    },
    {
      "epoch": 6.3709418193506915,
      "grad_norm": 0.000863207271322608,
      "learning_rate": 1.1505410907532413e-05,
      "loss": 0.0001,
      "step": 59460
    },
    {
      "epoch": 6.372013286188793,
      "grad_norm": 0.0010875415755435824,
      "learning_rate": 1.1503982285081611e-05,
      "loss": 0.0003,
      "step": 59470
    },
    {
      "epoch": 6.373084753026894,
      "grad_norm": 0.0014259553281590343,
      "learning_rate": 1.1502553662630809e-05,
      "loss": 0.2235,
      "step": 59480
    },
    {
      "epoch": 6.374156219864995,
      "grad_norm": 0.009088157676160336,
      "learning_rate": 1.1501125040180008e-05,
      "loss": 0.0001,
      "step": 59490
    },
    {
      "epoch": 6.375227686703097,
      "grad_norm": 0.0006749306339770555,
      "learning_rate": 1.1499696417729204e-05,
      "loss": 0.15,
      "step": 59500
    },
    {
      "epoch": 6.376299153541198,
      "grad_norm": 0.0016080698696896434,
      "learning_rate": 1.1498267795278403e-05,
      "loss": 0.2214,
      "step": 59510
    },
    {
      "epoch": 6.377370620379299,
      "grad_norm": 0.036232106387615204,
      "learning_rate": 1.1496839172827603e-05,
      "loss": 0.238,
      "step": 59520
    },
    {
      "epoch": 6.378442087217401,
      "grad_norm": 0.005336032249033451,
      "learning_rate": 1.14954105503768e-05,
      "loss": 0.0004,
      "step": 59530
    },
    {
      "epoch": 6.379513554055502,
      "grad_norm": 0.02054229937493801,
      "learning_rate": 1.1493981927925998e-05,
      "loss": 0.1227,
      "step": 59540
    },
    {
      "epoch": 6.380585020893603,
      "grad_norm": 0.053275592625141144,
      "learning_rate": 1.1492553305475196e-05,
      "loss": 0.3911,
      "step": 59550
    },
    {
      "epoch": 6.381656487731704,
      "grad_norm": 0.0014520935947075486,
      "learning_rate": 1.1491124683024395e-05,
      "loss": 0.0004,
      "step": 59560
    },
    {
      "epoch": 6.382727954569806,
      "grad_norm": 0.0006010504439473152,
      "learning_rate": 1.1489696060573591e-05,
      "loss": 0.0005,
      "step": 59570
    },
    {
      "epoch": 6.3837994214079075,
      "grad_norm": 0.08365368843078613,
      "learning_rate": 1.148826743812279e-05,
      "loss": 0.1244,
      "step": 59580
    },
    {
      "epoch": 6.384870888246009,
      "grad_norm": 0.9825338125228882,
      "learning_rate": 1.148683881567199e-05,
      "loss": 0.0018,
      "step": 59590
    },
    {
      "epoch": 6.38594235508411,
      "grad_norm": 0.013861856423318386,
      "learning_rate": 1.1485410193221188e-05,
      "loss": 0.3893,
      "step": 59600
    },
    {
      "epoch": 6.387013821922212,
      "grad_norm": 0.44586417078971863,
      "learning_rate": 1.1483981570770385e-05,
      "loss": 0.2194,
      "step": 59610
    },
    {
      "epoch": 6.388085288760313,
      "grad_norm": 0.13426737487316132,
      "learning_rate": 1.1482552948319583e-05,
      "loss": 0.1257,
      "step": 59620
    },
    {
      "epoch": 6.389156755598414,
      "grad_norm": 0.0011150672798976302,
      "learning_rate": 1.1481124325868782e-05,
      "loss": 0.3164,
      "step": 59630
    },
    {
      "epoch": 6.390228222436516,
      "grad_norm": 0.00042867823503911495,
      "learning_rate": 1.1479695703417982e-05,
      "loss": 0.0011,
      "step": 59640
    },
    {
      "epoch": 6.391299689274617,
      "grad_norm": 0.00040552744758315384,
      "learning_rate": 1.1478267080967178e-05,
      "loss": 0.0023,
      "step": 59650
    },
    {
      "epoch": 6.392371156112718,
      "grad_norm": 0.00042079633567482233,
      "learning_rate": 1.1476838458516377e-05,
      "loss": 0.0006,
      "step": 59660
    },
    {
      "epoch": 6.39344262295082,
      "grad_norm": 0.000385283085051924,
      "learning_rate": 1.1475409836065575e-05,
      "loss": 0.0004,
      "step": 59670
    },
    {
      "epoch": 6.394514089788921,
      "grad_norm": 0.0005230199312791228,
      "learning_rate": 1.1473981213614774e-05,
      "loss": 0.0005,
      "step": 59680
    },
    {
      "epoch": 6.395585556627022,
      "grad_norm": 0.0014870198210701346,
      "learning_rate": 1.147255259116397e-05,
      "loss": 0.0004,
      "step": 59690
    },
    {
      "epoch": 6.396657023465123,
      "grad_norm": 0.03723602369427681,
      "learning_rate": 1.147112396871317e-05,
      "loss": 0.0011,
      "step": 59700
    },
    {
      "epoch": 6.397728490303225,
      "grad_norm": 0.12517201900482178,
      "learning_rate": 1.1469695346262369e-05,
      "loss": 0.0006,
      "step": 59710
    },
    {
      "epoch": 6.3987999571413265,
      "grad_norm": 0.0002854974300134927,
      "learning_rate": 1.1468266723811565e-05,
      "loss": 0.0007,
      "step": 59720
    },
    {
      "epoch": 6.399871423979428,
      "grad_norm": 0.013307602144777775,
      "learning_rate": 1.1466838101360764e-05,
      "loss": 0.0003,
      "step": 59730
    },
    {
      "epoch": 6.400942890817529,
      "grad_norm": 0.0003266222483944148,
      "learning_rate": 1.1465409478909962e-05,
      "loss": 0.0002,
      "step": 59740
    },
    {
      "epoch": 6.402014357655631,
      "grad_norm": 0.0007824678323231637,
      "learning_rate": 1.1463980856459161e-05,
      "loss": 0.0002,
      "step": 59750
    },
    {
      "epoch": 6.403085824493732,
      "grad_norm": 0.0001604605495231226,
      "learning_rate": 1.1462552234008359e-05,
      "loss": 0.0004,
      "step": 59760
    },
    {
      "epoch": 6.404157291331833,
      "grad_norm": 0.0002607746282592416,
      "learning_rate": 1.1461123611557557e-05,
      "loss": 0.0003,
      "step": 59770
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 0.00784242618829012,
      "learning_rate": 1.1459694989106756e-05,
      "loss": 0.0002,
      "step": 59780
    },
    {
      "epoch": 6.406300225008036,
      "grad_norm": 0.00017355335876345634,
      "learning_rate": 1.1458266366655952e-05,
      "loss": 0.4439,
      "step": 59790
    },
    {
      "epoch": 6.407371691846137,
      "grad_norm": 0.0005690208054147661,
      "learning_rate": 1.1456837744205151e-05,
      "loss": 0.0002,
      "step": 59800
    },
    {
      "epoch": 6.408443158684239,
      "grad_norm": 0.0004156164941377938,
      "learning_rate": 1.1455409121754349e-05,
      "loss": 0.1534,
      "step": 59810
    },
    {
      "epoch": 6.40951462552234,
      "grad_norm": 0.00019228531164117157,
      "learning_rate": 1.1453980499303548e-05,
      "loss": 0.0002,
      "step": 59820
    },
    {
      "epoch": 6.410586092360441,
      "grad_norm": 0.00030176847940310836,
      "learning_rate": 1.1452551876852746e-05,
      "loss": 0.0003,
      "step": 59830
    },
    {
      "epoch": 6.4116575591985425,
      "grad_norm": 0.00039644399657845497,
      "learning_rate": 1.1451123254401944e-05,
      "loss": 0.1734,
      "step": 59840
    },
    {
      "epoch": 6.4127290260366445,
      "grad_norm": 1.7980729341506958,
      "learning_rate": 1.1449694631951143e-05,
      "loss": 0.2239,
      "step": 59850
    },
    {
      "epoch": 6.413800492874746,
      "grad_norm": 0.00024957716232165694,
      "learning_rate": 1.1448266009500339e-05,
      "loss": 0.0002,
      "step": 59860
    },
    {
      "epoch": 6.414871959712847,
      "grad_norm": 0.038217030465602875,
      "learning_rate": 1.1446837387049538e-05,
      "loss": 0.0017,
      "step": 59870
    },
    {
      "epoch": 6.415943426550948,
      "grad_norm": 0.012734356336295605,
      "learning_rate": 1.1445408764598736e-05,
      "loss": 0.0004,
      "step": 59880
    },
    {
      "epoch": 6.41701489338905,
      "grad_norm": 0.0003207397530786693,
      "learning_rate": 1.1443980142147935e-05,
      "loss": 0.0003,
      "step": 59890
    },
    {
      "epoch": 6.418086360227151,
      "grad_norm": 0.001783599378541112,
      "learning_rate": 1.1442551519697133e-05,
      "loss": 0.0002,
      "step": 59900
    },
    {
      "epoch": 6.419157827065252,
      "grad_norm": 0.00053067208500579,
      "learning_rate": 1.144112289724633e-05,
      "loss": 0.0004,
      "step": 59910
    },
    {
      "epoch": 6.420229293903354,
      "grad_norm": 0.0005118197877891362,
      "learning_rate": 1.143969427479553e-05,
      "loss": 0.0002,
      "step": 59920
    },
    {
      "epoch": 6.421300760741455,
      "grad_norm": 0.0004269037744961679,
      "learning_rate": 1.1438265652344726e-05,
      "loss": 0.0003,
      "step": 59930
    },
    {
      "epoch": 6.422372227579556,
      "grad_norm": 0.14516665041446686,
      "learning_rate": 1.1436837029893925e-05,
      "loss": 0.0006,
      "step": 59940
    },
    {
      "epoch": 6.423443694417657,
      "grad_norm": 0.00014485709834843874,
      "learning_rate": 1.1435408407443125e-05,
      "loss": 0.1286,
      "step": 59950
    },
    {
      "epoch": 6.424515161255759,
      "grad_norm": 0.000587562914006412,
      "learning_rate": 1.1433979784992322e-05,
      "loss": 0.387,
      "step": 59960
    },
    {
      "epoch": 6.4255866280938605,
      "grad_norm": 0.030613841488957405,
      "learning_rate": 1.143255116254152e-05,
      "loss": 0.0002,
      "step": 59970
    },
    {
      "epoch": 6.426658094931962,
      "grad_norm": 0.0010903968941420317,
      "learning_rate": 1.1431122540090718e-05,
      "loss": 0.1602,
      "step": 59980
    },
    {
      "epoch": 6.427729561770064,
      "grad_norm": 0.0005650810780934989,
      "learning_rate": 1.1429693917639917e-05,
      "loss": 0.0001,
      "step": 59990
    },
    {
      "epoch": 6.428801028608165,
      "grad_norm": 0.00036045757587999105,
      "learning_rate": 1.1428265295189113e-05,
      "loss": 0.0002,
      "step": 60000
    },
    {
      "epoch": 6.429872495446266,
      "grad_norm": 0.016127193346619606,
      "learning_rate": 1.1426836672738313e-05,
      "loss": 0.0003,
      "step": 60010
    },
    {
      "epoch": 6.430943962284367,
      "grad_norm": 0.0003595584712456912,
      "learning_rate": 1.1425408050287512e-05,
      "loss": 0.0001,
      "step": 60020
    },
    {
      "epoch": 6.432015429122469,
      "grad_norm": 15.180373191833496,
      "learning_rate": 1.142397942783671e-05,
      "loss": 0.3121,
      "step": 60030
    },
    {
      "epoch": 6.43308689596057,
      "grad_norm": 0.006411953829228878,
      "learning_rate": 1.1422550805385907e-05,
      "loss": 0.0004,
      "step": 60040
    },
    {
      "epoch": 6.434158362798671,
      "grad_norm": 0.00027720051002688706,
      "learning_rate": 1.1421122182935105e-05,
      "loss": 0.0003,
      "step": 60050
    },
    {
      "epoch": 6.435229829636773,
      "grad_norm": 0.007105711847543716,
      "learning_rate": 1.1419693560484304e-05,
      "loss": 0.0004,
      "step": 60060
    },
    {
      "epoch": 6.436301296474874,
      "grad_norm": 0.00020751090778503567,
      "learning_rate": 1.1418264938033504e-05,
      "loss": 0.0017,
      "step": 60070
    },
    {
      "epoch": 6.437372763312975,
      "grad_norm": 0.004472964443266392,
      "learning_rate": 1.14168363155827e-05,
      "loss": 0.0002,
      "step": 60080
    },
    {
      "epoch": 6.4384442301510765,
      "grad_norm": 0.0889095813035965,
      "learning_rate": 1.1415407693131899e-05,
      "loss": 0.0006,
      "step": 60090
    },
    {
      "epoch": 6.4395156969891785,
      "grad_norm": 0.00019925544620491564,
      "learning_rate": 1.1413979070681097e-05,
      "loss": 0.0,
      "step": 60100
    },
    {
      "epoch": 6.44058716382728,
      "grad_norm": 0.07739732414484024,
      "learning_rate": 1.1412550448230294e-05,
      "loss": 0.0011,
      "step": 60110
    },
    {
      "epoch": 6.441658630665381,
      "grad_norm": 0.04513067379593849,
      "learning_rate": 1.1411121825779492e-05,
      "loss": 0.0001,
      "step": 60120
    },
    {
      "epoch": 6.442730097503482,
      "grad_norm": 0.00019402206817176193,
      "learning_rate": 1.1409693203328691e-05,
      "loss": 0.0,
      "step": 60130
    },
    {
      "epoch": 6.443801564341584,
      "grad_norm": 0.0001750041701598093,
      "learning_rate": 1.140826458087789e-05,
      "loss": 0.1534,
      "step": 60140
    },
    {
      "epoch": 6.444873031179685,
      "grad_norm": 0.00651314714923501,
      "learning_rate": 1.1406835958427087e-05,
      "loss": 0.0002,
      "step": 60150
    },
    {
      "epoch": 6.445944498017786,
      "grad_norm": 108.50694274902344,
      "learning_rate": 1.1405407335976286e-05,
      "loss": 0.1606,
      "step": 60160
    },
    {
      "epoch": 6.447015964855888,
      "grad_norm": 0.008906176313757896,
      "learning_rate": 1.1403978713525484e-05,
      "loss": 0.0002,
      "step": 60170
    },
    {
      "epoch": 6.448087431693989,
      "grad_norm": 0.005015985574573278,
      "learning_rate": 1.1402550091074681e-05,
      "loss": 0.0001,
      "step": 60180
    },
    {
      "epoch": 6.44915889853209,
      "grad_norm": 0.001015593996271491,
      "learning_rate": 1.140112146862388e-05,
      "loss": 0.0002,
      "step": 60190
    },
    {
      "epoch": 6.450230365370192,
      "grad_norm": 0.006510376930236816,
      "learning_rate": 1.1399692846173078e-05,
      "loss": 0.0002,
      "step": 60200
    },
    {
      "epoch": 6.451301832208293,
      "grad_norm": 0.00024642597418278456,
      "learning_rate": 1.1398264223722278e-05,
      "loss": 0.0,
      "step": 60210
    },
    {
      "epoch": 6.4523732990463945,
      "grad_norm": 0.005087994504719973,
      "learning_rate": 1.1396835601271474e-05,
      "loss": 0.0001,
      "step": 60220
    },
    {
      "epoch": 6.453444765884496,
      "grad_norm": 0.005192446988075972,
      "learning_rate": 1.1395406978820673e-05,
      "loss": 0.0006,
      "step": 60230
    },
    {
      "epoch": 6.454516232722598,
      "grad_norm": 0.0018616481684148312,
      "learning_rate": 1.139397835636987e-05,
      "loss": 0.0001,
      "step": 60240
    },
    {
      "epoch": 6.455587699560699,
      "grad_norm": 0.0002758681948762387,
      "learning_rate": 1.139254973391907e-05,
      "loss": 0.0,
      "step": 60250
    },
    {
      "epoch": 6.4566591663988,
      "grad_norm": 0.00487598218023777,
      "learning_rate": 1.1391121111468268e-05,
      "loss": 0.0003,
      "step": 60260
    },
    {
      "epoch": 6.457730633236901,
      "grad_norm": 0.00020088213204871863,
      "learning_rate": 1.1389692489017466e-05,
      "loss": 0.0001,
      "step": 60270
    },
    {
      "epoch": 6.458802100075003,
      "grad_norm": 0.0001747275673551485,
      "learning_rate": 1.1388263866566665e-05,
      "loss": 0.0004,
      "step": 60280
    },
    {
      "epoch": 6.459873566913104,
      "grad_norm": 0.014671715907752514,
      "learning_rate": 1.1386835244115861e-05,
      "loss": 0.0001,
      "step": 60290
    },
    {
      "epoch": 6.460945033751205,
      "grad_norm": 0.005064898170530796,
      "learning_rate": 1.138540662166506e-05,
      "loss": 0.0002,
      "step": 60300
    },
    {
      "epoch": 6.462016500589307,
      "grad_norm": 0.025081787258386612,
      "learning_rate": 1.138397799921426e-05,
      "loss": 0.0001,
      "step": 60310
    },
    {
      "epoch": 6.463087967427408,
      "grad_norm": 0.003789789043366909,
      "learning_rate": 1.1382549376763457e-05,
      "loss": 0.0007,
      "step": 60320
    },
    {
      "epoch": 6.464159434265509,
      "grad_norm": 0.0006957483128644526,
      "learning_rate": 1.1381120754312655e-05,
      "loss": 0.0003,
      "step": 60330
    },
    {
      "epoch": 6.46523090110361,
      "grad_norm": 0.006487505044788122,
      "learning_rate": 1.1379692131861853e-05,
      "loss": 0.0001,
      "step": 60340
    },
    {
      "epoch": 6.466302367941712,
      "grad_norm": 0.00021557067520916462,
      "learning_rate": 1.1378263509411052e-05,
      "loss": 0.0001,
      "step": 60350
    },
    {
      "epoch": 6.4673738347798135,
      "grad_norm": 0.026365313678979874,
      "learning_rate": 1.1376834886960248e-05,
      "loss": 0.0001,
      "step": 60360
    },
    {
      "epoch": 6.468445301617915,
      "grad_norm": 0.00010914344602497295,
      "learning_rate": 1.1375406264509447e-05,
      "loss": 0.2866,
      "step": 60370
    },
    {
      "epoch": 6.469516768456017,
      "grad_norm": 0.08796641230583191,
      "learning_rate": 1.1373977642058647e-05,
      "loss": 0.0003,
      "step": 60380
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.006840633228421211,
      "learning_rate": 1.1372549019607844e-05,
      "loss": 0.145,
      "step": 60390
    },
    {
      "epoch": 6.471659702132219,
      "grad_norm": 0.005772371310740709,
      "learning_rate": 1.1371120397157042e-05,
      "loss": 0.0003,
      "step": 60400
    },
    {
      "epoch": 6.47273116897032,
      "grad_norm": 0.004405091982334852,
      "learning_rate": 1.136969177470624e-05,
      "loss": 0.0,
      "step": 60410
    },
    {
      "epoch": 6.473802635808422,
      "grad_norm": 0.0019349225331097841,
      "learning_rate": 1.1368263152255439e-05,
      "loss": 0.0001,
      "step": 60420
    },
    {
      "epoch": 6.474874102646523,
      "grad_norm": 0.00025775926769711077,
      "learning_rate": 1.1366834529804638e-05,
      "loss": 0.0001,
      "step": 60430
    },
    {
      "epoch": 6.475945569484624,
      "grad_norm": 0.00030450313352048397,
      "learning_rate": 1.1365405907353834e-05,
      "loss": 0.2153,
      "step": 60440
    },
    {
      "epoch": 6.477017036322726,
      "grad_norm": 0.00016100320499390364,
      "learning_rate": 1.1363977284903034e-05,
      "loss": 0.1672,
      "step": 60450
    },
    {
      "epoch": 6.478088503160827,
      "grad_norm": 0.002750588348135352,
      "learning_rate": 1.1362548662452231e-05,
      "loss": 0.0011,
      "step": 60460
    },
    {
      "epoch": 6.479159969998928,
      "grad_norm": 0.00355587643571198,
      "learning_rate": 1.136112004000143e-05,
      "loss": 0.0005,
      "step": 60470
    },
    {
      "epoch": 6.4802314368370295,
      "grad_norm": 0.005810930393636227,
      "learning_rate": 1.1359691417550627e-05,
      "loss": 0.0001,
      "step": 60480
    },
    {
      "epoch": 6.4813029036751315,
      "grad_norm": 0.0002556046820245683,
      "learning_rate": 1.1358262795099826e-05,
      "loss": 0.0002,
      "step": 60490
    },
    {
      "epoch": 6.482374370513233,
      "grad_norm": 0.0054586720652878284,
      "learning_rate": 1.1356834172649026e-05,
      "loss": 0.2169,
      "step": 60500
    },
    {
      "epoch": 6.483445837351334,
      "grad_norm": 0.0035830093547701836,
      "learning_rate": 1.1355405550198222e-05,
      "loss": 0.1323,
      "step": 60510
    },
    {
      "epoch": 6.484517304189436,
      "grad_norm": 0.0002698398020584136,
      "learning_rate": 1.1353976927747421e-05,
      "loss": 0.0002,
      "step": 60520
    },
    {
      "epoch": 6.485588771027537,
      "grad_norm": 0.004042773973196745,
      "learning_rate": 1.1352548305296619e-05,
      "loss": 0.0001,
      "step": 60530
    },
    {
      "epoch": 6.486660237865638,
      "grad_norm": 0.0003606790560297668,
      "learning_rate": 1.1351119682845816e-05,
      "loss": 0.0028,
      "step": 60540
    },
    {
      "epoch": 6.487731704703739,
      "grad_norm": 0.0002142151352018118,
      "learning_rate": 1.1349691060395016e-05,
      "loss": 0.0002,
      "step": 60550
    },
    {
      "epoch": 6.488803171541841,
      "grad_norm": 0.007248046807944775,
      "learning_rate": 1.1348262437944213e-05,
      "loss": 0.2715,
      "step": 60560
    },
    {
      "epoch": 6.489874638379942,
      "grad_norm": 14.961153030395508,
      "learning_rate": 1.1346833815493413e-05,
      "loss": 0.2499,
      "step": 60570
    },
    {
      "epoch": 6.490946105218043,
      "grad_norm": 0.0005985035677440464,
      "learning_rate": 1.1345405193042609e-05,
      "loss": 0.0004,
      "step": 60580
    },
    {
      "epoch": 6.492017572056145,
      "grad_norm": 0.0005140322609804571,
      "learning_rate": 1.1343976570591808e-05,
      "loss": 0.0001,
      "step": 60590
    },
    {
      "epoch": 6.493089038894246,
      "grad_norm": 0.003660727757960558,
      "learning_rate": 1.1342547948141006e-05,
      "loss": 0.0001,
      "step": 60600
    },
    {
      "epoch": 6.4941605057323475,
      "grad_norm": 0.0014800452627241611,
      "learning_rate": 1.1341119325690203e-05,
      "loss": 0.0003,
      "step": 60610
    },
    {
      "epoch": 6.495231972570449,
      "grad_norm": 0.008963222615420818,
      "learning_rate": 1.1339690703239403e-05,
      "loss": 0.1536,
      "step": 60620
    },
    {
      "epoch": 6.496303439408551,
      "grad_norm": 0.00013505884271580726,
      "learning_rate": 1.13382620807886e-05,
      "loss": 0.0001,
      "step": 60630
    },
    {
      "epoch": 6.497374906246652,
      "grad_norm": 0.48116615414619446,
      "learning_rate": 1.13368334583378e-05,
      "loss": 0.0029,
      "step": 60640
    },
    {
      "epoch": 6.498446373084753,
      "grad_norm": 0.0007606222061440349,
      "learning_rate": 1.1335404835886996e-05,
      "loss": 0.2033,
      "step": 60650
    },
    {
      "epoch": 6.499517839922854,
      "grad_norm": 0.00015544627967756242,
      "learning_rate": 1.1333976213436195e-05,
      "loss": 0.0001,
      "step": 60660
    },
    {
      "epoch": 6.500589306760956,
      "grad_norm": 0.005687804892659187,
      "learning_rate": 1.1332547590985394e-05,
      "loss": 0.0004,
      "step": 60670
    },
    {
      "epoch": 6.501660773599057,
      "grad_norm": 0.0002632687974255532,
      "learning_rate": 1.133111896853459e-05,
      "loss": 0.0001,
      "step": 60680
    },
    {
      "epoch": 6.502732240437158,
      "grad_norm": 0.00018373697821516544,
      "learning_rate": 1.132969034608379e-05,
      "loss": 0.2275,
      "step": 60690
    },
    {
      "epoch": 6.50380370727526,
      "grad_norm": 0.00435613002628088,
      "learning_rate": 1.1328261723632987e-05,
      "loss": 0.0002,
      "step": 60700
    },
    {
      "epoch": 6.504875174113361,
      "grad_norm": 0.3393559753894806,
      "learning_rate": 1.1326833101182187e-05,
      "loss": 0.1455,
      "step": 60710
    },
    {
      "epoch": 6.505946640951462,
      "grad_norm": 93.29136657714844,
      "learning_rate": 1.1325404478731383e-05,
      "loss": 0.8791,
      "step": 60720
    },
    {
      "epoch": 6.507018107789564,
      "grad_norm": 0.022168923169374466,
      "learning_rate": 1.1323975856280582e-05,
      "loss": 0.381,
      "step": 60730
    },
    {
      "epoch": 6.5080895746276655,
      "grad_norm": 0.0012488295324146748,
      "learning_rate": 1.1322547233829782e-05,
      "loss": 0.0009,
      "step": 60740
    },
    {
      "epoch": 6.509161041465767,
      "grad_norm": 0.14712364971637726,
      "learning_rate": 1.1321118611378978e-05,
      "loss": 0.2791,
      "step": 60750
    },
    {
      "epoch": 6.510232508303868,
      "grad_norm": 15.725431442260742,
      "learning_rate": 1.1319689988928177e-05,
      "loss": 0.1075,
      "step": 60760
    },
    {
      "epoch": 6.51130397514197,
      "grad_norm": 0.0002605880727060139,
      "learning_rate": 1.1318261366477375e-05,
      "loss": 0.0017,
      "step": 60770
    },
    {
      "epoch": 6.512375441980071,
      "grad_norm": 0.03062848560512066,
      "learning_rate": 1.1316832744026574e-05,
      "loss": 0.1375,
      "step": 60780
    },
    {
      "epoch": 6.513446908818172,
      "grad_norm": 0.014858757145702839,
      "learning_rate": 1.131540412157577e-05,
      "loss": 0.0009,
      "step": 60790
    },
    {
      "epoch": 6.514518375656273,
      "grad_norm": 0.0003976290172431618,
      "learning_rate": 1.131397549912497e-05,
      "loss": 0.0007,
      "step": 60800
    },
    {
      "epoch": 6.515589842494375,
      "grad_norm": 0.02464853972196579,
      "learning_rate": 1.1312546876674169e-05,
      "loss": 0.0002,
      "step": 60810
    },
    {
      "epoch": 6.516661309332476,
      "grad_norm": 0.02517649158835411,
      "learning_rate": 1.1311118254223366e-05,
      "loss": 0.1334,
      "step": 60820
    },
    {
      "epoch": 6.517732776170577,
      "grad_norm": 0.00033432766213081777,
      "learning_rate": 1.1309689631772564e-05,
      "loss": 0.0013,
      "step": 60830
    },
    {
      "epoch": 6.518804243008679,
      "grad_norm": 0.0001743007160257548,
      "learning_rate": 1.1308261009321762e-05,
      "loss": 0.0009,
      "step": 60840
    },
    {
      "epoch": 6.51987570984678,
      "grad_norm": 0.0001500562357250601,
      "learning_rate": 1.1306832386870961e-05,
      "loss": 0.0005,
      "step": 60850
    },
    {
      "epoch": 6.520947176684881,
      "grad_norm": 0.00030364462872967124,
      "learning_rate": 1.130540376442016e-05,
      "loss": 0.0002,
      "step": 60860
    },
    {
      "epoch": 6.522018643522983,
      "grad_norm": 0.007362325210124254,
      "learning_rate": 1.1303975141969356e-05,
      "loss": 0.0002,
      "step": 60870
    },
    {
      "epoch": 6.5230901103610845,
      "grad_norm": 0.009997989982366562,
      "learning_rate": 1.1302546519518556e-05,
      "loss": 0.1352,
      "step": 60880
    },
    {
      "epoch": 6.524161577199186,
      "grad_norm": 0.00024946744088083506,
      "learning_rate": 1.1301117897067753e-05,
      "loss": 0.0002,
      "step": 60890
    },
    {
      "epoch": 6.525233044037287,
      "grad_norm": 0.0001254712842637673,
      "learning_rate": 1.1299689274616951e-05,
      "loss": 0.0001,
      "step": 60900
    },
    {
      "epoch": 6.526304510875389,
      "grad_norm": 18.585735321044922,
      "learning_rate": 1.1298260652166149e-05,
      "loss": 0.002,
      "step": 60910
    },
    {
      "epoch": 6.52737597771349,
      "grad_norm": 1.788622498512268,
      "learning_rate": 1.1296832029715348e-05,
      "loss": 0.003,
      "step": 60920
    },
    {
      "epoch": 6.528447444551591,
      "grad_norm": 0.00012032894301228225,
      "learning_rate": 1.1295403407264548e-05,
      "loss": 0.0027,
      "step": 60930
    },
    {
      "epoch": 6.529518911389692,
      "grad_norm": 0.00013656532973982394,
      "learning_rate": 1.1293974784813743e-05,
      "loss": 0.0,
      "step": 60940
    },
    {
      "epoch": 6.530590378227794,
      "grad_norm": 0.00017184070020448416,
      "learning_rate": 1.1292546162362943e-05,
      "loss": 0.3697,
      "step": 60950
    },
    {
      "epoch": 6.531661845065895,
      "grad_norm": 0.0001382591581204906,
      "learning_rate": 1.129111753991214e-05,
      "loss": 0.0018,
      "step": 60960
    },
    {
      "epoch": 6.532733311903996,
      "grad_norm": 29.591875076293945,
      "learning_rate": 1.1289688917461338e-05,
      "loss": 0.2165,
      "step": 60970
    },
    {
      "epoch": 6.533804778742098,
      "grad_norm": 0.011040364392101765,
      "learning_rate": 1.1288260295010538e-05,
      "loss": 0.0003,
      "step": 60980
    },
    {
      "epoch": 6.534876245580199,
      "grad_norm": 0.00014450063463300467,
      "learning_rate": 1.1286831672559735e-05,
      "loss": 0.0001,
      "step": 60990
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 0.032321229577064514,
      "learning_rate": 1.1285403050108935e-05,
      "loss": 0.3554,
      "step": 61000
    },
    {
      "epoch": 6.537019179256402,
      "grad_norm": 0.0007794005796313286,
      "learning_rate": 1.128397442765813e-05,
      "loss": 0.0004,
      "step": 61010
    },
    {
      "epoch": 6.538090646094504,
      "grad_norm": 0.0004299642750993371,
      "learning_rate": 1.128254580520733e-05,
      "loss": 0.0002,
      "step": 61020
    },
    {
      "epoch": 6.539162112932605,
      "grad_norm": 0.00018399415421299636,
      "learning_rate": 1.1281117182756528e-05,
      "loss": 0.1347,
      "step": 61030
    },
    {
      "epoch": 6.540233579770706,
      "grad_norm": 0.00010970979928970337,
      "learning_rate": 1.1279688560305725e-05,
      "loss": 0.1004,
      "step": 61040
    },
    {
      "epoch": 6.541305046608807,
      "grad_norm": 0.0156699325889349,
      "learning_rate": 1.1278259937854925e-05,
      "loss": 0.1438,
      "step": 61050
    },
    {
      "epoch": 6.542376513446909,
      "grad_norm": 0.03677977994084358,
      "learning_rate": 1.1276831315404122e-05,
      "loss": 0.12,
      "step": 61060
    },
    {
      "epoch": 6.54344798028501,
      "grad_norm": 0.0004350031085778028,
      "learning_rate": 1.1275402692953322e-05,
      "loss": 0.0003,
      "step": 61070
    },
    {
      "epoch": 6.544519447123111,
      "grad_norm": 0.00021725203259848058,
      "learning_rate": 1.1273974070502518e-05,
      "loss": 0.0001,
      "step": 61080
    },
    {
      "epoch": 6.545590913961213,
      "grad_norm": 232.218505859375,
      "learning_rate": 1.1272545448051717e-05,
      "loss": 0.104,
      "step": 61090
    },
    {
      "epoch": 6.546662380799314,
      "grad_norm": 0.00016131401935126632,
      "learning_rate": 1.1271116825600916e-05,
      "loss": 0.1324,
      "step": 61100
    },
    {
      "epoch": 6.547733847637415,
      "grad_norm": 0.013702393509447575,
      "learning_rate": 1.1269688203150112e-05,
      "loss": 0.2515,
      "step": 61110
    },
    {
      "epoch": 6.548805314475517,
      "grad_norm": 0.027896882966160774,
      "learning_rate": 1.1268259580699312e-05,
      "loss": 0.1445,
      "step": 61120
    },
    {
      "epoch": 6.5498767813136185,
      "grad_norm": 0.023934388533234596,
      "learning_rate": 1.126683095824851e-05,
      "loss": 0.0005,
      "step": 61130
    },
    {
      "epoch": 6.55094824815172,
      "grad_norm": 0.002957467222586274,
      "learning_rate": 1.1265402335797709e-05,
      "loss": 0.4612,
      "step": 61140
    },
    {
      "epoch": 6.552019714989821,
      "grad_norm": 0.0035132416523993015,
      "learning_rate": 1.1263973713346905e-05,
      "loss": 0.0003,
      "step": 61150
    },
    {
      "epoch": 6.553091181827923,
      "grad_norm": 0.5817278623580933,
      "learning_rate": 1.1262545090896104e-05,
      "loss": 0.0012,
      "step": 61160
    },
    {
      "epoch": 6.554162648666024,
      "grad_norm": 0.00019899719336535782,
      "learning_rate": 1.1261116468445304e-05,
      "loss": 0.0002,
      "step": 61170
    },
    {
      "epoch": 6.555234115504125,
      "grad_norm": 0.0015856758691370487,
      "learning_rate": 1.12596878459945e-05,
      "loss": 0.0111,
      "step": 61180
    },
    {
      "epoch": 6.556305582342226,
      "grad_norm": 0.03197920694947243,
      "learning_rate": 1.1258259223543699e-05,
      "loss": 0.0003,
      "step": 61190
    },
    {
      "epoch": 6.557377049180328,
      "grad_norm": 0.00024962180759757757,
      "learning_rate": 1.1256830601092897e-05,
      "loss": 0.0003,
      "step": 61200
    },
    {
      "epoch": 6.558448516018429,
      "grad_norm": 0.00018824457947630435,
      "learning_rate": 1.1255401978642096e-05,
      "loss": 0.0003,
      "step": 61210
    },
    {
      "epoch": 6.55951998285653,
      "grad_norm": 0.013810624368488789,
      "learning_rate": 1.1253973356191295e-05,
      "loss": 0.0001,
      "step": 61220
    },
    {
      "epoch": 6.560591449694632,
      "grad_norm": 0.012032934464514256,
      "learning_rate": 1.1252544733740491e-05,
      "loss": 0.1091,
      "step": 61230
    },
    {
      "epoch": 6.561662916532733,
      "grad_norm": 0.0006264618132263422,
      "learning_rate": 1.125111611128969e-05,
      "loss": 0.254,
      "step": 61240
    },
    {
      "epoch": 6.5627343833708345,
      "grad_norm": 0.00025144434766843915,
      "learning_rate": 1.1249687488838887e-05,
      "loss": 0.0003,
      "step": 61250
    },
    {
      "epoch": 6.5638058502089365,
      "grad_norm": 0.011153770610690117,
      "learning_rate": 1.1248258866388086e-05,
      "loss": 0.0002,
      "step": 61260
    },
    {
      "epoch": 6.564877317047038,
      "grad_norm": 0.005735635291785002,
      "learning_rate": 1.1246830243937284e-05,
      "loss": 0.2064,
      "step": 61270
    },
    {
      "epoch": 6.565948783885139,
      "grad_norm": 0.7403062582015991,
      "learning_rate": 1.1245401621486483e-05,
      "loss": 0.1191,
      "step": 61280
    },
    {
      "epoch": 6.56702025072324,
      "grad_norm": 0.0002925187873188406,
      "learning_rate": 1.1243972999035682e-05,
      "loss": 0.0007,
      "step": 61290
    },
    {
      "epoch": 6.568091717561342,
      "grad_norm": 0.48649361729621887,
      "learning_rate": 1.1242544376584878e-05,
      "loss": 0.0004,
      "step": 61300
    },
    {
      "epoch": 6.569163184399443,
      "grad_norm": 0.007732972502708435,
      "learning_rate": 1.1241115754134078e-05,
      "loss": 0.0007,
      "step": 61310
    },
    {
      "epoch": 6.570234651237544,
      "grad_norm": 0.00020516129734460264,
      "learning_rate": 1.1239687131683274e-05,
      "loss": 0.0001,
      "step": 61320
    },
    {
      "epoch": 6.571306118075645,
      "grad_norm": 0.00023994510411284864,
      "learning_rate": 1.1238258509232473e-05,
      "loss": 0.0001,
      "step": 61330
    },
    {
      "epoch": 6.572377584913747,
      "grad_norm": 0.0018194527365267277,
      "learning_rate": 1.1236829886781672e-05,
      "loss": 0.0001,
      "step": 61340
    },
    {
      "epoch": 6.573449051751848,
      "grad_norm": 0.00015736221394035965,
      "learning_rate": 1.123540126433087e-05,
      "loss": 0.3933,
      "step": 61350
    },
    {
      "epoch": 6.574520518589949,
      "grad_norm": 0.0001276226103072986,
      "learning_rate": 1.123397264188007e-05,
      "loss": 0.1725,
      "step": 61360
    },
    {
      "epoch": 6.575591985428051,
      "grad_norm": 0.00042714294977486134,
      "learning_rate": 1.1232544019429265e-05,
      "loss": 0.1111,
      "step": 61370
    },
    {
      "epoch": 6.5766634522661525,
      "grad_norm": 0.00024569264496676624,
      "learning_rate": 1.1231115396978465e-05,
      "loss": 0.1482,
      "step": 61380
    },
    {
      "epoch": 6.577734919104254,
      "grad_norm": 0.0006712349131703377,
      "learning_rate": 1.1229686774527662e-05,
      "loss": 0.0001,
      "step": 61390
    },
    {
      "epoch": 6.578806385942356,
      "grad_norm": 0.015711508691310883,
      "learning_rate": 1.122825815207686e-05,
      "loss": 0.1073,
      "step": 61400
    },
    {
      "epoch": 6.579877852780457,
      "grad_norm": 0.0002016750950133428,
      "learning_rate": 1.122682952962606e-05,
      "loss": 0.0,
      "step": 61410
    },
    {
      "epoch": 6.580949319618558,
      "grad_norm": 0.010962212458252907,
      "learning_rate": 1.1225400907175257e-05,
      "loss": 0.002,
      "step": 61420
    },
    {
      "epoch": 6.582020786456659,
      "grad_norm": 0.002074172720313072,
      "learning_rate": 1.1223972284724457e-05,
      "loss": 0.0016,
      "step": 61430
    },
    {
      "epoch": 6.583092253294761,
      "grad_norm": 1.1728646755218506,
      "learning_rate": 1.1222543662273653e-05,
      "loss": 0.0026,
      "step": 61440
    },
    {
      "epoch": 6.584163720132862,
      "grad_norm": 0.013270017690956593,
      "learning_rate": 1.1221115039822852e-05,
      "loss": 0.0004,
      "step": 61450
    },
    {
      "epoch": 6.585235186970963,
      "grad_norm": 0.007271946873515844,
      "learning_rate": 1.1219686417372051e-05,
      "loss": 0.3639,
      "step": 61460
    },
    {
      "epoch": 6.586306653809064,
      "grad_norm": 0.00021501476294361055,
      "learning_rate": 1.1218257794921247e-05,
      "loss": 0.0001,
      "step": 61470
    },
    {
      "epoch": 6.587378120647166,
      "grad_norm": 0.00991891697049141,
      "learning_rate": 1.1216829172470447e-05,
      "loss": 0.1076,
      "step": 61480
    },
    {
      "epoch": 6.588449587485267,
      "grad_norm": 0.0004962730454280972,
      "learning_rate": 1.1215400550019644e-05,
      "loss": 0.1192,
      "step": 61490
    },
    {
      "epoch": 6.589521054323368,
      "grad_norm": 0.0003861981676891446,
      "learning_rate": 1.1213971927568844e-05,
      "loss": 0.0001,
      "step": 61500
    },
    {
      "epoch": 6.59059252116147,
      "grad_norm": 0.0015737167559564114,
      "learning_rate": 1.121254330511804e-05,
      "loss": 0.1632,
      "step": 61510
    },
    {
      "epoch": 6.5916639879995715,
      "grad_norm": 0.014681264758110046,
      "learning_rate": 1.1211114682667239e-05,
      "loss": 0.0003,
      "step": 61520
    },
    {
      "epoch": 6.592735454837673,
      "grad_norm": 0.17078672349452972,
      "learning_rate": 1.1209686060216438e-05,
      "loss": 0.0003,
      "step": 61530
    },
    {
      "epoch": 6.593806921675774,
      "grad_norm": 0.0007991628372110426,
      "learning_rate": 1.1208257437765634e-05,
      "loss": 0.0028,
      "step": 61540
    },
    {
      "epoch": 6.594878388513876,
      "grad_norm": 0.7457830905914307,
      "learning_rate": 1.1206828815314834e-05,
      "loss": 0.0015,
      "step": 61550
    },
    {
      "epoch": 6.595949855351977,
      "grad_norm": 0.01307726837694645,
      "learning_rate": 1.1205400192864031e-05,
      "loss": 0.2848,
      "step": 61560
    },
    {
      "epoch": 6.597021322190078,
      "grad_norm": 0.0002807485871016979,
      "learning_rate": 1.120397157041323e-05,
      "loss": 0.1172,
      "step": 61570
    },
    {
      "epoch": 6.598092789028179,
      "grad_norm": 0.00018235146126244217,
      "learning_rate": 1.1202542947962428e-05,
      "loss": 0.2354,
      "step": 61580
    },
    {
      "epoch": 6.599164255866281,
      "grad_norm": 0.012794028036296368,
      "learning_rate": 1.1201114325511626e-05,
      "loss": 0.1349,
      "step": 61590
    },
    {
      "epoch": 6.600235722704382,
      "grad_norm": 0.0016384752234444022,
      "learning_rate": 1.1199685703060825e-05,
      "loss": 0.2496,
      "step": 61600
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 0.0002667704247869551,
      "learning_rate": 1.1198257080610021e-05,
      "loss": 0.0001,
      "step": 61610
    },
    {
      "epoch": 6.602378656380585,
      "grad_norm": 0.0018183954525738955,
      "learning_rate": 1.119682845815922e-05,
      "loss": 0.0003,
      "step": 61620
    },
    {
      "epoch": 6.603450123218686,
      "grad_norm": 0.00024305781698785722,
      "learning_rate": 1.1195399835708418e-05,
      "loss": 0.2637,
      "step": 61630
    },
    {
      "epoch": 6.6045215900567875,
      "grad_norm": 0.009060056880116463,
      "learning_rate": 1.1193971213257618e-05,
      "loss": 0.1503,
      "step": 61640
    },
    {
      "epoch": 6.6055930568948895,
      "grad_norm": 0.00826079212129116,
      "learning_rate": 1.1192542590806817e-05,
      "loss": 0.0004,
      "step": 61650
    },
    {
      "epoch": 6.606664523732991,
      "grad_norm": 0.003127843840047717,
      "learning_rate": 1.1191113968356013e-05,
      "loss": 0.0001,
      "step": 61660
    },
    {
      "epoch": 6.607735990571092,
      "grad_norm": 0.0002994986716657877,
      "learning_rate": 1.1189685345905213e-05,
      "loss": 0.0001,
      "step": 61670
    },
    {
      "epoch": 6.608807457409193,
      "grad_norm": 0.016422191634774208,
      "learning_rate": 1.1188256723454409e-05,
      "loss": 0.0001,
      "step": 61680
    },
    {
      "epoch": 6.609878924247295,
      "grad_norm": 0.000784986128564924,
      "learning_rate": 1.1186828101003608e-05,
      "loss": 0.0001,
      "step": 61690
    },
    {
      "epoch": 6.610950391085396,
      "grad_norm": 0.0002666426298674196,
      "learning_rate": 1.1185399478552806e-05,
      "loss": 0.0053,
      "step": 61700
    },
    {
      "epoch": 6.612021857923497,
      "grad_norm": 0.0005086110904812813,
      "learning_rate": 1.1183970856102005e-05,
      "loss": 0.2521,
      "step": 61710
    },
    {
      "epoch": 6.613093324761598,
      "grad_norm": 0.009326489642262459,
      "learning_rate": 1.1182542233651204e-05,
      "loss": 0.0001,
      "step": 61720
    },
    {
      "epoch": 6.6141647915997,
      "grad_norm": 0.6528254747390747,
      "learning_rate": 1.11811136112004e-05,
      "loss": 0.0973,
      "step": 61730
    },
    {
      "epoch": 6.615236258437801,
      "grad_norm": 0.008087594993412495,
      "learning_rate": 1.11796849887496e-05,
      "loss": 0.1226,
      "step": 61740
    },
    {
      "epoch": 6.616307725275902,
      "grad_norm": 0.0015283841639757156,
      "learning_rate": 1.1178256366298796e-05,
      "loss": 0.0882,
      "step": 61750
    },
    {
      "epoch": 6.617379192114004,
      "grad_norm": 0.007978826761245728,
      "learning_rate": 1.1176827743847995e-05,
      "loss": 0.0002,
      "step": 61760
    },
    {
      "epoch": 6.6184506589521055,
      "grad_norm": 0.02184961549937725,
      "learning_rate": 1.1175399121397194e-05,
      "loss": 0.0004,
      "step": 61770
    },
    {
      "epoch": 6.619522125790207,
      "grad_norm": 0.00017189423670060933,
      "learning_rate": 1.1173970498946392e-05,
      "loss": 0.0001,
      "step": 61780
    },
    {
      "epoch": 6.620593592628309,
      "grad_norm": 0.000206895187147893,
      "learning_rate": 1.1172541876495591e-05,
      "loss": 0.0,
      "step": 61790
    },
    {
      "epoch": 6.62166505946641,
      "grad_norm": 0.005428725853562355,
      "learning_rate": 1.1171113254044787e-05,
      "loss": 0.3544,
      "step": 61800
    },
    {
      "epoch": 6.622736526304511,
      "grad_norm": 0.009995712898671627,
      "learning_rate": 1.1169684631593987e-05,
      "loss": 0.0012,
      "step": 61810
    },
    {
      "epoch": 6.623807993142612,
      "grad_norm": 0.0010185138089582324,
      "learning_rate": 1.1168256009143183e-05,
      "loss": 0.0001,
      "step": 61820
    },
    {
      "epoch": 6.624879459980714,
      "grad_norm": 0.007413513958454132,
      "learning_rate": 1.1166827386692382e-05,
      "loss": 0.141,
      "step": 61830
    },
    {
      "epoch": 6.625950926818815,
      "grad_norm": 0.0009901110315695405,
      "learning_rate": 1.1165398764241581e-05,
      "loss": 0.1719,
      "step": 61840
    },
    {
      "epoch": 6.627022393656916,
      "grad_norm": 0.000905099674127996,
      "learning_rate": 1.1163970141790779e-05,
      "loss": 0.152,
      "step": 61850
    },
    {
      "epoch": 6.628093860495017,
      "grad_norm": 0.01899382285773754,
      "learning_rate": 1.1162541519339978e-05,
      "loss": 0.0011,
      "step": 61860
    },
    {
      "epoch": 6.629165327333119,
      "grad_norm": 0.0007708309567533433,
      "learning_rate": 1.1161112896889174e-05,
      "loss": 0.1418,
      "step": 61870
    },
    {
      "epoch": 6.63023679417122,
      "grad_norm": 0.013002513907849789,
      "learning_rate": 1.1159684274438374e-05,
      "loss": 0.0002,
      "step": 61880
    },
    {
      "epoch": 6.6313082610093215,
      "grad_norm": 0.10274896770715714,
      "learning_rate": 1.1158255651987573e-05,
      "loss": 0.0002,
      "step": 61890
    },
    {
      "epoch": 6.6323797278474235,
      "grad_norm": 0.003215285949409008,
      "learning_rate": 1.115682702953677e-05,
      "loss": 0.0006,
      "step": 61900
    },
    {
      "epoch": 6.633451194685525,
      "grad_norm": 0.0016319907736033201,
      "learning_rate": 1.1155398407085969e-05,
      "loss": 0.3823,
      "step": 61910
    },
    {
      "epoch": 6.634522661523626,
      "grad_norm": 1.4500195980072021,
      "learning_rate": 1.1153969784635166e-05,
      "loss": 0.0033,
      "step": 61920
    },
    {
      "epoch": 6.635594128361728,
      "grad_norm": 0.045038338750600815,
      "learning_rate": 1.1152541162184366e-05,
      "loss": 0.0011,
      "step": 61930
    },
    {
      "epoch": 6.636665595199829,
      "grad_norm": 0.005455848295241594,
      "learning_rate": 1.1151112539733562e-05,
      "loss": 0.0002,
      "step": 61940
    },
    {
      "epoch": 6.63773706203793,
      "grad_norm": 0.01461994368582964,
      "learning_rate": 1.1149683917282761e-05,
      "loss": 0.0001,
      "step": 61950
    },
    {
      "epoch": 6.638808528876031,
      "grad_norm": 16.584375381469727,
      "learning_rate": 1.114825529483196e-05,
      "loss": 0.4273,
      "step": 61960
    },
    {
      "epoch": 6.639879995714133,
      "grad_norm": 0.01377289742231369,
      "learning_rate": 1.1146826672381156e-05,
      "loss": 0.0025,
      "step": 61970
    },
    {
      "epoch": 6.640951462552234,
      "grad_norm": 3.224684715270996,
      "learning_rate": 1.1145398049930356e-05,
      "loss": 0.0015,
      "step": 61980
    },
    {
      "epoch": 6.642022929390335,
      "grad_norm": 0.0010446299565955997,
      "learning_rate": 1.1143969427479553e-05,
      "loss": 0.2403,
      "step": 61990
    },
    {
      "epoch": 6.643094396228436,
      "grad_norm": 21.90791130065918,
      "learning_rate": 1.1142540805028753e-05,
      "loss": 0.1456,
      "step": 62000
    },
    {
      "epoch": 6.644165863066538,
      "grad_norm": 0.0013930529821664095,
      "learning_rate": 1.114111218257795e-05,
      "loss": 0.0001,
      "step": 62010
    },
    {
      "epoch": 6.6452373299046394,
      "grad_norm": 0.06808025389909744,
      "learning_rate": 1.1139683560127148e-05,
      "loss": 0.0023,
      "step": 62020
    },
    {
      "epoch": 6.6463087967427406,
      "grad_norm": 0.0008627119241282344,
      "learning_rate": 1.1138254937676347e-05,
      "loss": 0.124,
      "step": 62030
    },
    {
      "epoch": 6.6473802635808426,
      "grad_norm": 0.0006527252844534814,
      "learning_rate": 1.1136826315225543e-05,
      "loss": 0.0002,
      "step": 62040
    },
    {
      "epoch": 6.648451730418944,
      "grad_norm": 0.001356881228275597,
      "learning_rate": 1.1135397692774743e-05,
      "loss": 0.0003,
      "step": 62050
    },
    {
      "epoch": 6.649523197257045,
      "grad_norm": 0.4686608612537384,
      "learning_rate": 1.113396907032394e-05,
      "loss": 0.0016,
      "step": 62060
    },
    {
      "epoch": 6.650594664095146,
      "grad_norm": 0.24036522209644318,
      "learning_rate": 1.113254044787314e-05,
      "loss": 0.001,
      "step": 62070
    },
    {
      "epoch": 6.651666130933248,
      "grad_norm": 0.0006008807686157525,
      "learning_rate": 1.1131111825422337e-05,
      "loss": 0.5555,
      "step": 62080
    },
    {
      "epoch": 6.652737597771349,
      "grad_norm": 0.1429252326488495,
      "learning_rate": 1.1129683202971535e-05,
      "loss": 0.0007,
      "step": 62090
    },
    {
      "epoch": 6.65380906460945,
      "grad_norm": 0.0012058961438015103,
      "learning_rate": 1.1128254580520734e-05,
      "loss": 0.1008,
      "step": 62100
    },
    {
      "epoch": 6.654880531447551,
      "grad_norm": 0.0007981419912539423,
      "learning_rate": 1.112682595806993e-05,
      "loss": 0.0006,
      "step": 62110
    },
    {
      "epoch": 6.655951998285653,
      "grad_norm": 0.0034959022887051105,
      "learning_rate": 1.112539733561913e-05,
      "loss": 0.0004,
      "step": 62120
    },
    {
      "epoch": 6.657023465123754,
      "grad_norm": 0.01217574067413807,
      "learning_rate": 1.112396871316833e-05,
      "loss": 0.001,
      "step": 62130
    },
    {
      "epoch": 6.658094931961855,
      "grad_norm": 0.0015052875969558954,
      "learning_rate": 1.1122540090717527e-05,
      "loss": 0.204,
      "step": 62140
    },
    {
      "epoch": 6.659166398799957,
      "grad_norm": 0.0013814038829877973,
      "learning_rate": 1.1121111468266725e-05,
      "loss": 0.0002,
      "step": 62150
    },
    {
      "epoch": 6.6602378656380585,
      "grad_norm": 0.009389910846948624,
      "learning_rate": 1.1119682845815922e-05,
      "loss": 0.1214,
      "step": 62160
    },
    {
      "epoch": 6.66130933247616,
      "grad_norm": 0.01971609517931938,
      "learning_rate": 1.1118254223365122e-05,
      "loss": 0.0002,
      "step": 62170
    },
    {
      "epoch": 6.662380799314262,
      "grad_norm": 0.004070027265697718,
      "learning_rate": 1.1116825600914318e-05,
      "loss": 0.0001,
      "step": 62180
    },
    {
      "epoch": 6.663452266152363,
      "grad_norm": 0.0008495567599311471,
      "learning_rate": 1.1115396978463517e-05,
      "loss": 0.0,
      "step": 62190
    },
    {
      "epoch": 6.664523732990464,
      "grad_norm": 0.0011106504825875163,
      "learning_rate": 1.1113968356012716e-05,
      "loss": 0.1385,
      "step": 62200
    },
    {
      "epoch": 6.665595199828565,
      "grad_norm": 0.11430554836988449,
      "learning_rate": 1.1112539733561914e-05,
      "loss": 0.1011,
      "step": 62210
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.0016087519470602274,
      "learning_rate": 1.1111111111111113e-05,
      "loss": 0.0006,
      "step": 62220
    },
    {
      "epoch": 6.667738133504768,
      "grad_norm": 0.001067416393198073,
      "learning_rate": 1.110968248866031e-05,
      "loss": 0.2475,
      "step": 62230
    },
    {
      "epoch": 6.668809600342869,
      "grad_norm": 0.005787066649645567,
      "learning_rate": 1.1108253866209509e-05,
      "loss": 0.0001,
      "step": 62240
    },
    {
      "epoch": 6.66988106718097,
      "grad_norm": 0.0119205666705966,
      "learning_rate": 1.1106825243758708e-05,
      "loss": 0.2493,
      "step": 62250
    },
    {
      "epoch": 6.670952534019072,
      "grad_norm": 0.000778943533077836,
      "learning_rate": 1.1105396621307904e-05,
      "loss": 0.2856,
      "step": 62260
    },
    {
      "epoch": 6.672024000857173,
      "grad_norm": 40.752994537353516,
      "learning_rate": 1.1103967998857103e-05,
      "loss": 0.1112,
      "step": 62270
    },
    {
      "epoch": 6.6730954676952745,
      "grad_norm": 0.008723367936909199,
      "learning_rate": 1.1102539376406301e-05,
      "loss": 0.0001,
      "step": 62280
    },
    {
      "epoch": 6.6741669345333765,
      "grad_norm": 0.001571541652083397,
      "learning_rate": 1.11011107539555e-05,
      "loss": 0.0003,
      "step": 62290
    },
    {
      "epoch": 6.675238401371478,
      "grad_norm": 0.026370756328105927,
      "learning_rate": 1.1099682131504696e-05,
      "loss": 0.0001,
      "step": 62300
    },
    {
      "epoch": 6.676309868209579,
      "grad_norm": 0.042527344077825546,
      "learning_rate": 1.1098253509053896e-05,
      "loss": 0.2401,
      "step": 62310
    },
    {
      "epoch": 6.677381335047681,
      "grad_norm": 0.009545928798615932,
      "learning_rate": 1.1096824886603095e-05,
      "loss": 0.0002,
      "step": 62320
    },
    {
      "epoch": 6.678452801885782,
      "grad_norm": 0.003376174718141556,
      "learning_rate": 1.1095396264152291e-05,
      "loss": 0.203,
      "step": 62330
    },
    {
      "epoch": 6.679524268723883,
      "grad_norm": 0.0020293709821999073,
      "learning_rate": 1.109396764170149e-05,
      "loss": 0.2041,
      "step": 62340
    },
    {
      "epoch": 6.680595735561984,
      "grad_norm": 0.010375741869211197,
      "learning_rate": 1.1092539019250688e-05,
      "loss": 0.0004,
      "step": 62350
    },
    {
      "epoch": 6.681667202400086,
      "grad_norm": 0.0015965037746354938,
      "learning_rate": 1.1091110396799888e-05,
      "loss": 0.0006,
      "step": 62360
    },
    {
      "epoch": 6.682738669238187,
      "grad_norm": 0.021966421976685524,
      "learning_rate": 1.1089681774349085e-05,
      "loss": 0.2173,
      "step": 62370
    },
    {
      "epoch": 6.683810136076288,
      "grad_norm": 0.009616025723516941,
      "learning_rate": 1.1088253151898283e-05,
      "loss": 0.0002,
      "step": 62380
    },
    {
      "epoch": 6.684881602914389,
      "grad_norm": 0.009976712055504322,
      "learning_rate": 1.1086824529447482e-05,
      "loss": 0.1492,
      "step": 62390
    },
    {
      "epoch": 6.685953069752491,
      "grad_norm": 0.2544892728328705,
      "learning_rate": 1.1085395906996678e-05,
      "loss": 0.1132,
      "step": 62400
    },
    {
      "epoch": 6.6870245365905925,
      "grad_norm": 0.01842566393315792,
      "learning_rate": 1.1083967284545878e-05,
      "loss": 0.3242,
      "step": 62410
    },
    {
      "epoch": 6.688096003428694,
      "grad_norm": 0.0006833267398178577,
      "learning_rate": 1.1082538662095075e-05,
      "loss": 0.2065,
      "step": 62420
    },
    {
      "epoch": 6.689167470266796,
      "grad_norm": 0.0018139461753889918,
      "learning_rate": 1.1081110039644275e-05,
      "loss": 0.0011,
      "step": 62430
    },
    {
      "epoch": 6.690238937104897,
      "grad_norm": 0.013297776691615582,
      "learning_rate": 1.1079681417193472e-05,
      "loss": 0.1614,
      "step": 62440
    },
    {
      "epoch": 6.691310403942998,
      "grad_norm": 53.17512512207031,
      "learning_rate": 1.107825279474267e-05,
      "loss": 0.1684,
      "step": 62450
    },
    {
      "epoch": 6.6923818707811,
      "grad_norm": 0.024310404434800148,
      "learning_rate": 1.107682417229187e-05,
      "loss": 0.0009,
      "step": 62460
    },
    {
      "epoch": 6.693453337619201,
      "grad_norm": 0.0015780406538397074,
      "learning_rate": 1.1075395549841065e-05,
      "loss": 0.0726,
      "step": 62470
    },
    {
      "epoch": 6.694524804457302,
      "grad_norm": 0.0015308604342862964,
      "learning_rate": 1.1073966927390265e-05,
      "loss": 0.0007,
      "step": 62480
    },
    {
      "epoch": 6.695596271295403,
      "grad_norm": 0.000758555019274354,
      "learning_rate": 1.1072538304939464e-05,
      "loss": 0.001,
      "step": 62490
    },
    {
      "epoch": 6.696667738133505,
      "grad_norm": 0.04200832545757294,
      "learning_rate": 1.1071109682488662e-05,
      "loss": 0.0037,
      "step": 62500
    },
    {
      "epoch": 6.697739204971606,
      "grad_norm": 0.0005900419782847166,
      "learning_rate": 1.106968106003786e-05,
      "loss": 0.1217,
      "step": 62510
    },
    {
      "epoch": 6.698810671809707,
      "grad_norm": 0.00641134986653924,
      "learning_rate": 1.1068252437587057e-05,
      "loss": 0.0002,
      "step": 62520
    },
    {
      "epoch": 6.6998821386478085,
      "grad_norm": 0.0003437310515437275,
      "learning_rate": 1.1066823815136256e-05,
      "loss": 0.0017,
      "step": 62530
    },
    {
      "epoch": 6.7009536054859105,
      "grad_norm": 0.0002658880839589983,
      "learning_rate": 1.1065395192685452e-05,
      "loss": 0.0017,
      "step": 62540
    },
    {
      "epoch": 6.702025072324012,
      "grad_norm": 0.03070307895541191,
      "learning_rate": 1.1063966570234652e-05,
      "loss": 0.0002,
      "step": 62550
    },
    {
      "epoch": 6.703096539162113,
      "grad_norm": 33.583980560302734,
      "learning_rate": 1.1062537947783851e-05,
      "loss": 0.142,
      "step": 62560
    },
    {
      "epoch": 6.704168006000215,
      "grad_norm": 0.005975911859422922,
      "learning_rate": 1.1061109325333049e-05,
      "loss": 0.0003,
      "step": 62570
    },
    {
      "epoch": 6.705239472838316,
      "grad_norm": 0.009565090760588646,
      "learning_rate": 1.1059680702882246e-05,
      "loss": 0.0004,
      "step": 62580
    },
    {
      "epoch": 6.706310939676417,
      "grad_norm": 0.015184001997113228,
      "learning_rate": 1.1058252080431444e-05,
      "loss": 0.0001,
      "step": 62590
    },
    {
      "epoch": 6.707382406514518,
      "grad_norm": 0.0003211060247849673,
      "learning_rate": 1.1056823457980644e-05,
      "loss": 0.0001,
      "step": 62600
    },
    {
      "epoch": 6.70845387335262,
      "grad_norm": 0.00036990855005569756,
      "learning_rate": 1.105539483552984e-05,
      "loss": 0.0,
      "step": 62610
    },
    {
      "epoch": 6.709525340190721,
      "grad_norm": 0.0009520961903035641,
      "learning_rate": 1.1053966213079039e-05,
      "loss": 0.0003,
      "step": 62620
    },
    {
      "epoch": 6.710596807028822,
      "grad_norm": 0.000710046966560185,
      "learning_rate": 1.1052537590628238e-05,
      "loss": 0.0001,
      "step": 62630
    },
    {
      "epoch": 6.711668273866923,
      "grad_norm": 0.00022618265938945115,
      "learning_rate": 1.1051108968177436e-05,
      "loss": 0.2337,
      "step": 62640
    },
    {
      "epoch": 6.712739740705025,
      "grad_norm": 0.0031299516558647156,
      "learning_rate": 1.1049680345726634e-05,
      "loss": 0.2585,
      "step": 62650
    },
    {
      "epoch": 6.713811207543126,
      "grad_norm": 0.0014809544663876295,
      "learning_rate": 1.1048251723275831e-05,
      "loss": 0.163,
      "step": 62660
    },
    {
      "epoch": 6.7148826743812275,
      "grad_norm": 0.0003420970169827342,
      "learning_rate": 1.104682310082503e-05,
      "loss": 0.2318,
      "step": 62670
    },
    {
      "epoch": 6.7159541412193295,
      "grad_norm": 0.14233136177062988,
      "learning_rate": 1.104539447837423e-05,
      "loss": 0.1244,
      "step": 62680
    },
    {
      "epoch": 6.717025608057431,
      "grad_norm": 0.0005984760937280953,
      "learning_rate": 1.1043965855923426e-05,
      "loss": 0.0003,
      "step": 62690
    },
    {
      "epoch": 6.718097074895532,
      "grad_norm": 0.012442586943507195,
      "learning_rate": 1.1042537233472625e-05,
      "loss": 0.3543,
      "step": 62700
    },
    {
      "epoch": 6.719168541733634,
      "grad_norm": 0.018161078914999962,
      "learning_rate": 1.1041108611021823e-05,
      "loss": 0.0013,
      "step": 62710
    },
    {
      "epoch": 6.720240008571735,
      "grad_norm": 0.0009971066610887647,
      "learning_rate": 1.103967998857102e-05,
      "loss": 0.0009,
      "step": 62720
    },
    {
      "epoch": 6.721311475409836,
      "grad_norm": 0.00023597416293341666,
      "learning_rate": 1.1038251366120218e-05,
      "loss": 0.0002,
      "step": 62730
    },
    {
      "epoch": 6.722382942247937,
      "grad_norm": 0.3070211112499237,
      "learning_rate": 1.1036822743669418e-05,
      "loss": 0.0003,
      "step": 62740
    },
    {
      "epoch": 6.723454409086039,
      "grad_norm": 0.01565476320683956,
      "learning_rate": 1.1035394121218617e-05,
      "loss": 0.0021,
      "step": 62750
    },
    {
      "epoch": 6.72452587592414,
      "grad_norm": 0.000269648851826787,
      "learning_rate": 1.1033965498767813e-05,
      "loss": 0.3549,
      "step": 62760
    },
    {
      "epoch": 6.725597342762241,
      "grad_norm": 0.007482726126909256,
      "learning_rate": 1.1032536876317012e-05,
      "loss": 0.1537,
      "step": 62770
    },
    {
      "epoch": 6.726668809600342,
      "grad_norm": 0.0009528754744678736,
      "learning_rate": 1.103110825386621e-05,
      "loss": 0.0001,
      "step": 62780
    },
    {
      "epoch": 6.727740276438444,
      "grad_norm": 0.009254150092601776,
      "learning_rate": 1.102967963141541e-05,
      "loss": 0.2006,
      "step": 62790
    },
    {
      "epoch": 6.7288117432765455,
      "grad_norm": 0.08549754321575165,
      "learning_rate": 1.1028251008964607e-05,
      "loss": 0.0004,
      "step": 62800
    },
    {
      "epoch": 6.729883210114647,
      "grad_norm": 0.016416091471910477,
      "learning_rate": 1.1026822386513805e-05,
      "loss": 0.0008,
      "step": 62810
    },
    {
      "epoch": 6.730954676952749,
      "grad_norm": 0.012050132267177105,
      "learning_rate": 1.1025393764063004e-05,
      "loss": 0.0009,
      "step": 62820
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 0.38351717591285706,
      "learning_rate": 1.10239651416122e-05,
      "loss": 0.0011,
      "step": 62830
    },
    {
      "epoch": 6.733097610628951,
      "grad_norm": 0.0006508639780804515,
      "learning_rate": 1.10225365191614e-05,
      "loss": 0.1999,
      "step": 62840
    },
    {
      "epoch": 6.734169077467053,
      "grad_norm": 0.000568580231629312,
      "learning_rate": 1.1021107896710597e-05,
      "loss": 0.0005,
      "step": 62850
    },
    {
      "epoch": 6.735240544305154,
      "grad_norm": 0.0006699325749650598,
      "learning_rate": 1.1019679274259797e-05,
      "loss": 0.0006,
      "step": 62860
    },
    {
      "epoch": 6.736312011143255,
      "grad_norm": 0.0008593302336521447,
      "learning_rate": 1.1018250651808994e-05,
      "loss": 0.0012,
      "step": 62870
    },
    {
      "epoch": 6.737383477981356,
      "grad_norm": 0.004085097927600145,
      "learning_rate": 1.1016822029358192e-05,
      "loss": 0.099,
      "step": 62880
    },
    {
      "epoch": 6.738454944819458,
      "grad_norm": 0.041836656630039215,
      "learning_rate": 1.1015393406907391e-05,
      "loss": 0.0002,
      "step": 62890
    },
    {
      "epoch": 6.739526411657559,
      "grad_norm": 0.0002702436759136617,
      "learning_rate": 1.1013964784456587e-05,
      "loss": 0.0002,
      "step": 62900
    },
    {
      "epoch": 6.74059787849566,
      "grad_norm": 0.00016928363766055554,
      "learning_rate": 1.1012536162005787e-05,
      "loss": 0.0002,
      "step": 62910
    },
    {
      "epoch": 6.7416693453337615,
      "grad_norm": 0.00545463664457202,
      "learning_rate": 1.1011107539554986e-05,
      "loss": 0.0001,
      "step": 62920
    },
    {
      "epoch": 6.7427408121718635,
      "grad_norm": 0.22183461487293243,
      "learning_rate": 1.1009678917104184e-05,
      "loss": 0.0029,
      "step": 62930
    },
    {
      "epoch": 6.743812279009965,
      "grad_norm": 0.0007495149620808661,
      "learning_rate": 1.1008250294653381e-05,
      "loss": 0.1653,
      "step": 62940
    },
    {
      "epoch": 6.744883745848066,
      "grad_norm": 0.005033505614846945,
      "learning_rate": 1.1006821672202579e-05,
      "loss": 0.168,
      "step": 62950
    },
    {
      "epoch": 6.745955212686168,
      "grad_norm": 0.0001665434247115627,
      "learning_rate": 1.1005393049751778e-05,
      "loss": 0.0002,
      "step": 62960
    },
    {
      "epoch": 6.747026679524269,
      "grad_norm": 0.0002718457253649831,
      "learning_rate": 1.1003964427300974e-05,
      "loss": 0.0031,
      "step": 62970
    },
    {
      "epoch": 6.74809814636237,
      "grad_norm": 0.014723356813192368,
      "learning_rate": 1.1002535804850174e-05,
      "loss": 0.0001,
      "step": 62980
    },
    {
      "epoch": 6.749169613200472,
      "grad_norm": 0.00039582603494636714,
      "learning_rate": 1.1001107182399373e-05,
      "loss": 0.1341,
      "step": 62990
    },
    {
      "epoch": 6.750241080038573,
      "grad_norm": 0.0002416312345303595,
      "learning_rate": 1.099967855994857e-05,
      "loss": 0.0936,
      "step": 63000
    },
    {
      "epoch": 6.751312546876674,
      "grad_norm": 0.000225081603275612,
      "learning_rate": 1.0998249937497768e-05,
      "loss": 0.0001,
      "step": 63010
    },
    {
      "epoch": 6.752384013714775,
      "grad_norm": 0.0005342208896763623,
      "learning_rate": 1.0996821315046966e-05,
      "loss": 0.1517,
      "step": 63020
    },
    {
      "epoch": 6.753455480552877,
      "grad_norm": 0.00016922439681366086,
      "learning_rate": 1.0995392692596165e-05,
      "loss": 0.1117,
      "step": 63030
    },
    {
      "epoch": 6.754526947390978,
      "grad_norm": 15.907947540283203,
      "learning_rate": 1.0993964070145365e-05,
      "loss": 0.1324,
      "step": 63040
    },
    {
      "epoch": 6.7555984142290795,
      "grad_norm": 0.00024956752895377576,
      "learning_rate": 1.099253544769456e-05,
      "loss": 0.0002,
      "step": 63050
    },
    {
      "epoch": 6.756669881067181,
      "grad_norm": 0.00030302366940304637,
      "learning_rate": 1.099110682524376e-05,
      "loss": 0.0001,
      "step": 63060
    },
    {
      "epoch": 6.757741347905283,
      "grad_norm": 0.0047005158849060535,
      "learning_rate": 1.0989678202792958e-05,
      "loss": 0.0001,
      "step": 63070
    },
    {
      "epoch": 6.758812814743384,
      "grad_norm": 0.012484636157751083,
      "learning_rate": 1.0988249580342156e-05,
      "loss": 0.0006,
      "step": 63080
    },
    {
      "epoch": 6.759884281581485,
      "grad_norm": 0.00015343338600359857,
      "learning_rate": 1.0986820957891353e-05,
      "loss": 0.0001,
      "step": 63090
    },
    {
      "epoch": 6.760955748419587,
      "grad_norm": 0.0007274884846992791,
      "learning_rate": 1.0985392335440553e-05,
      "loss": 0.333,
      "step": 63100
    },
    {
      "epoch": 6.762027215257688,
      "grad_norm": 0.0008931339834816754,
      "learning_rate": 1.0983963712989752e-05,
      "loss": 0.0001,
      "step": 63110
    },
    {
      "epoch": 6.763098682095789,
      "grad_norm": 0.0008042306290008128,
      "learning_rate": 1.0982535090538948e-05,
      "loss": 0.0002,
      "step": 63120
    },
    {
      "epoch": 6.76417014893389,
      "grad_norm": 0.0013756881235167384,
      "learning_rate": 1.0981106468088147e-05,
      "loss": 0.0001,
      "step": 63130
    },
    {
      "epoch": 6.765241615771992,
      "grad_norm": 0.000544777896720916,
      "learning_rate": 1.0979677845637345e-05,
      "loss": 0.0003,
      "step": 63140
    },
    {
      "epoch": 6.766313082610093,
      "grad_norm": 0.0038817436434328556,
      "learning_rate": 1.0978249223186543e-05,
      "loss": 0.0001,
      "step": 63150
    },
    {
      "epoch": 6.767384549448194,
      "grad_norm": 0.004014529287815094,
      "learning_rate": 1.0976820600735742e-05,
      "loss": 0.0004,
      "step": 63160
    },
    {
      "epoch": 6.7684560162862955,
      "grad_norm": 0.007967994548380375,
      "learning_rate": 1.097539197828494e-05,
      "loss": 0.228,
      "step": 63170
    },
    {
      "epoch": 6.7695274831243974,
      "grad_norm": 0.022884439677000046,
      "learning_rate": 1.0973963355834139e-05,
      "loss": 0.0007,
      "step": 63180
    },
    {
      "epoch": 6.770598949962499,
      "grad_norm": 0.01790187880396843,
      "learning_rate": 1.0972534733383335e-05,
      "loss": 0.4086,
      "step": 63190
    },
    {
      "epoch": 6.7716704168006,
      "grad_norm": 0.006220204755663872,
      "learning_rate": 1.0971106110932534e-05,
      "loss": 0.0012,
      "step": 63200
    },
    {
      "epoch": 6.772741883638702,
      "grad_norm": 0.0004917694022879004,
      "learning_rate": 1.0969677488481732e-05,
      "loss": 0.0001,
      "step": 63210
    },
    {
      "epoch": 6.773813350476803,
      "grad_norm": 130.93606567382812,
      "learning_rate": 1.096824886603093e-05,
      "loss": 0.0503,
      "step": 63220
    },
    {
      "epoch": 6.774884817314904,
      "grad_norm": 0.0003155242884531617,
      "learning_rate": 1.0966820243580129e-05,
      "loss": 0.0001,
      "step": 63230
    },
    {
      "epoch": 6.775956284153006,
      "grad_norm": 0.0021500198636204004,
      "learning_rate": 1.0965391621129327e-05,
      "loss": 0.0001,
      "step": 63240
    },
    {
      "epoch": 6.777027750991107,
      "grad_norm": 0.5308682918548584,
      "learning_rate": 1.0963962998678526e-05,
      "loss": 0.0004,
      "step": 63250
    },
    {
      "epoch": 6.778099217829208,
      "grad_norm": 0.0029921967070549726,
      "learning_rate": 1.0962534376227722e-05,
      "loss": 0.3038,
      "step": 63260
    },
    {
      "epoch": 6.779170684667309,
      "grad_norm": 0.06982127577066422,
      "learning_rate": 1.0961105753776921e-05,
      "loss": 0.0002,
      "step": 63270
    },
    {
      "epoch": 6.780242151505411,
      "grad_norm": 0.0004956767079420388,
      "learning_rate": 1.095967713132612e-05,
      "loss": 0.0001,
      "step": 63280
    },
    {
      "epoch": 6.781313618343512,
      "grad_norm": 0.00038734852569177747,
      "learning_rate": 1.0958248508875317e-05,
      "loss": 0.2436,
      "step": 63290
    },
    {
      "epoch": 6.782385085181613,
      "grad_norm": 230.43228149414062,
      "learning_rate": 1.0956819886424516e-05,
      "loss": 0.1029,
      "step": 63300
    },
    {
      "epoch": 6.7834565520197145,
      "grad_norm": 0.001497316057793796,
      "learning_rate": 1.0955391263973714e-05,
      "loss": 0.0002,
      "step": 63310
    },
    {
      "epoch": 6.7845280188578165,
      "grad_norm": 0.0003919378505088389,
      "learning_rate": 1.0953962641522913e-05,
      "loss": 0.2168,
      "step": 63320
    },
    {
      "epoch": 6.785599485695918,
      "grad_norm": 0.000415713875554502,
      "learning_rate": 1.095253401907211e-05,
      "loss": 0.1343,
      "step": 63330
    },
    {
      "epoch": 6.786670952534019,
      "grad_norm": 0.0028034308925271034,
      "learning_rate": 1.0951105396621309e-05,
      "loss": 0.0001,
      "step": 63340
    },
    {
      "epoch": 6.787742419372121,
      "grad_norm": 0.03149706497788429,
      "learning_rate": 1.0949676774170508e-05,
      "loss": 0.0004,
      "step": 63350
    },
    {
      "epoch": 6.788813886210222,
      "grad_norm": 0.0013047298416495323,
      "learning_rate": 1.0948248151719706e-05,
      "loss": 0.0003,
      "step": 63360
    },
    {
      "epoch": 6.789885353048323,
      "grad_norm": 0.01304917223751545,
      "learning_rate": 1.0946819529268903e-05,
      "loss": 0.272,
      "step": 63370
    },
    {
      "epoch": 6.790956819886425,
      "grad_norm": 0.0006882905727252364,
      "learning_rate": 1.0945390906818101e-05,
      "loss": 0.0688,
      "step": 63380
    },
    {
      "epoch": 6.792028286724526,
      "grad_norm": 0.0005713775753974915,
      "learning_rate": 1.09439622843673e-05,
      "loss": 0.4463,
      "step": 63390
    },
    {
      "epoch": 6.793099753562627,
      "grad_norm": 0.0073854015208780766,
      "learning_rate": 1.09425336619165e-05,
      "loss": 0.0007,
      "step": 63400
    },
    {
      "epoch": 6.794171220400728,
      "grad_norm": 151.36508178710938,
      "learning_rate": 1.0941105039465696e-05,
      "loss": 0.1578,
      "step": 63410
    },
    {
      "epoch": 6.79524268723883,
      "grad_norm": 0.0004746323684230447,
      "learning_rate": 1.0939676417014895e-05,
      "loss": 0.0031,
      "step": 63420
    },
    {
      "epoch": 6.796314154076931,
      "grad_norm": 0.015693364664912224,
      "learning_rate": 1.0938247794564093e-05,
      "loss": 0.0002,
      "step": 63430
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 0.018896322697401047,
      "learning_rate": 1.093681917211329e-05,
      "loss": 0.0005,
      "step": 63440
    },
    {
      "epoch": 6.798457087753134,
      "grad_norm": 0.075853630900383,
      "learning_rate": 1.0935390549662488e-05,
      "loss": 0.1464,
      "step": 63450
    },
    {
      "epoch": 6.799528554591236,
      "grad_norm": 0.00034630938898772,
      "learning_rate": 1.0933961927211687e-05,
      "loss": 0.1923,
      "step": 63460
    },
    {
      "epoch": 6.800600021429337,
      "grad_norm": 0.03516005724668503,
      "learning_rate": 1.0932533304760887e-05,
      "loss": 0.0003,
      "step": 63470
    },
    {
      "epoch": 6.801671488267438,
      "grad_norm": 0.00978020578622818,
      "learning_rate": 1.0931104682310083e-05,
      "loss": 0.0004,
      "step": 63480
    },
    {
      "epoch": 6.80274295510554,
      "grad_norm": 0.11518552154302597,
      "learning_rate": 1.0929676059859282e-05,
      "loss": 0.2094,
      "step": 63490
    },
    {
      "epoch": 6.803814421943641,
      "grad_norm": 0.00043915011337958276,
      "learning_rate": 1.092824743740848e-05,
      "loss": 0.0009,
      "step": 63500
    },
    {
      "epoch": 6.804885888781742,
      "grad_norm": 0.0023079284001141787,
      "learning_rate": 1.0926818814957677e-05,
      "loss": 0.2986,
      "step": 63510
    },
    {
      "epoch": 6.805957355619844,
      "grad_norm": 0.0005919832037761807,
      "learning_rate": 1.0925390192506875e-05,
      "loss": 0.2266,
      "step": 63520
    },
    {
      "epoch": 6.807028822457945,
      "grad_norm": 0.0009801946580410004,
      "learning_rate": 1.0923961570056075e-05,
      "loss": 0.0005,
      "step": 63530
    },
    {
      "epoch": 6.808100289296046,
      "grad_norm": 0.0735393539071083,
      "learning_rate": 1.0922532947605274e-05,
      "loss": 0.0006,
      "step": 63540
    },
    {
      "epoch": 6.809171756134147,
      "grad_norm": 0.03281724825501442,
      "learning_rate": 1.092110432515447e-05,
      "loss": 0.1341,
      "step": 63550
    },
    {
      "epoch": 6.810243222972249,
      "grad_norm": 0.024090422317385674,
      "learning_rate": 1.091967570270367e-05,
      "loss": 0.1653,
      "step": 63560
    },
    {
      "epoch": 6.8113146898103505,
      "grad_norm": 0.00026688797515816987,
      "learning_rate": 1.0918247080252867e-05,
      "loss": 0.0716,
      "step": 63570
    },
    {
      "epoch": 6.812386156648452,
      "grad_norm": 0.023857880383729935,
      "learning_rate": 1.0916818457802065e-05,
      "loss": 0.0001,
      "step": 63580
    },
    {
      "epoch": 6.813457623486553,
      "grad_norm": 0.1371253877878189,
      "learning_rate": 1.0915389835351264e-05,
      "loss": 0.0005,
      "step": 63590
    },
    {
      "epoch": 6.814529090324655,
      "grad_norm": 0.017349613830447197,
      "learning_rate": 1.0913961212900462e-05,
      "loss": 0.0012,
      "step": 63600
    },
    {
      "epoch": 6.815600557162756,
      "grad_norm": 0.0001556171482661739,
      "learning_rate": 1.0912532590449661e-05,
      "loss": 0.0005,
      "step": 63610
    },
    {
      "epoch": 6.816672024000857,
      "grad_norm": 0.0005737531464546919,
      "learning_rate": 1.0911103967998857e-05,
      "loss": 0.0007,
      "step": 63620
    },
    {
      "epoch": 6.817743490838959,
      "grad_norm": 0.0005131095531396568,
      "learning_rate": 1.0909675345548056e-05,
      "loss": 0.0007,
      "step": 63630
    },
    {
      "epoch": 6.81881495767706,
      "grad_norm": 0.0273218285292387,
      "learning_rate": 1.0908246723097254e-05,
      "loss": 0.0002,
      "step": 63640
    },
    {
      "epoch": 6.819886424515161,
      "grad_norm": 0.011590237729251385,
      "learning_rate": 1.0906818100646452e-05,
      "loss": 0.0003,
      "step": 63650
    },
    {
      "epoch": 6.820957891353262,
      "grad_norm": 0.000123220743262209,
      "learning_rate": 1.0905389478195651e-05,
      "loss": 0.0002,
      "step": 63660
    },
    {
      "epoch": 6.822029358191364,
      "grad_norm": 0.008736275136470795,
      "learning_rate": 1.0903960855744849e-05,
      "loss": 0.2017,
      "step": 63670
    },
    {
      "epoch": 6.823100825029465,
      "grad_norm": 0.0001482113148085773,
      "learning_rate": 1.0902532233294048e-05,
      "loss": 0.0003,
      "step": 63680
    },
    {
      "epoch": 6.8241722918675665,
      "grad_norm": 0.0001597062509972602,
      "learning_rate": 1.0901103610843244e-05,
      "loss": 0.1507,
      "step": 63690
    },
    {
      "epoch": 6.825243758705668,
      "grad_norm": 0.017809772863984108,
      "learning_rate": 1.0899674988392443e-05,
      "loss": 0.0002,
      "step": 63700
    },
    {
      "epoch": 6.82631522554377,
      "grad_norm": 8.79334329511039e-05,
      "learning_rate": 1.0898246365941643e-05,
      "loss": 0.0003,
      "step": 63710
    },
    {
      "epoch": 6.827386692381871,
      "grad_norm": 0.021604178473353386,
      "learning_rate": 1.0896817743490839e-05,
      "loss": 0.0002,
      "step": 63720
    },
    {
      "epoch": 6.828458159219972,
      "grad_norm": 0.00014987849863246083,
      "learning_rate": 1.0895389121040038e-05,
      "loss": 0.3264,
      "step": 63730
    },
    {
      "epoch": 6.829529626058074,
      "grad_norm": 0.005358542315661907,
      "learning_rate": 1.0893960498589236e-05,
      "loss": 0.0004,
      "step": 63740
    },
    {
      "epoch": 6.830601092896175,
      "grad_norm": 0.017998186871409416,
      "learning_rate": 1.0892531876138435e-05,
      "loss": 0.1858,
      "step": 63750
    },
    {
      "epoch": 6.831672559734276,
      "grad_norm": 0.04205618053674698,
      "learning_rate": 1.0891103253687631e-05,
      "loss": 0.0,
      "step": 63760
    },
    {
      "epoch": 6.832744026572378,
      "grad_norm": 0.07927712053060532,
      "learning_rate": 1.088967463123683e-05,
      "loss": 0.3895,
      "step": 63770
    },
    {
      "epoch": 6.833815493410479,
      "grad_norm": 0.0006888529751449823,
      "learning_rate": 1.088824600878603e-05,
      "loss": 0.0004,
      "step": 63780
    },
    {
      "epoch": 6.83488696024858,
      "grad_norm": 0.00016813889669720083,
      "learning_rate": 1.0886817386335226e-05,
      "loss": 0.0564,
      "step": 63790
    },
    {
      "epoch": 6.835958427086681,
      "grad_norm": 0.034854184836149216,
      "learning_rate": 1.0885388763884425e-05,
      "loss": 0.0003,
      "step": 63800
    },
    {
      "epoch": 6.837029893924783,
      "grad_norm": 0.09728557616472244,
      "learning_rate": 1.0883960141433623e-05,
      "loss": 0.2017,
      "step": 63810
    },
    {
      "epoch": 6.838101360762884,
      "grad_norm": 0.007756819482892752,
      "learning_rate": 1.0882531518982822e-05,
      "loss": 0.0062,
      "step": 63820
    },
    {
      "epoch": 6.8391728276009855,
      "grad_norm": 0.01596136949956417,
      "learning_rate": 1.0881102896532022e-05,
      "loss": 0.0003,
      "step": 63830
    },
    {
      "epoch": 6.840244294439087,
      "grad_norm": 0.023182928562164307,
      "learning_rate": 1.0879674274081218e-05,
      "loss": 0.0002,
      "step": 63840
    },
    {
      "epoch": 6.841315761277189,
      "grad_norm": 14.471664428710938,
      "learning_rate": 1.0878245651630417e-05,
      "loss": 0.2196,
      "step": 63850
    },
    {
      "epoch": 6.84238722811529,
      "grad_norm": 0.017258796840906143,
      "learning_rate": 1.0876817029179615e-05,
      "loss": 0.1937,
      "step": 63860
    },
    {
      "epoch": 6.843458694953391,
      "grad_norm": 0.003110547550022602,
      "learning_rate": 1.0875388406728812e-05,
      "loss": 0.0006,
      "step": 63870
    },
    {
      "epoch": 6.844530161791493,
      "grad_norm": 0.050108958035707474,
      "learning_rate": 1.087395978427801e-05,
      "loss": 0.1977,
      "step": 63880
    },
    {
      "epoch": 6.845601628629594,
      "grad_norm": 0.00019538607739377767,
      "learning_rate": 1.087253116182721e-05,
      "loss": 0.0006,
      "step": 63890
    },
    {
      "epoch": 6.846673095467695,
      "grad_norm": 0.0037556758616119623,
      "learning_rate": 1.0871102539376409e-05,
      "loss": 0.0003,
      "step": 63900
    },
    {
      "epoch": 6.847744562305797,
      "grad_norm": 0.030932161957025528,
      "learning_rate": 1.0869673916925605e-05,
      "loss": 0.0007,
      "step": 63910
    },
    {
      "epoch": 6.848816029143898,
      "grad_norm": 0.00012190941924927756,
      "learning_rate": 1.0868245294474804e-05,
      "loss": 0.1574,
      "step": 63920
    },
    {
      "epoch": 6.849887495981999,
      "grad_norm": 0.00016613310435786843,
      "learning_rate": 1.0866816672024002e-05,
      "loss": 0.0003,
      "step": 63930
    },
    {
      "epoch": 6.8509589628201,
      "grad_norm": 0.00017426034901291132,
      "learning_rate": 1.08653880495732e-05,
      "loss": 0.0001,
      "step": 63940
    },
    {
      "epoch": 6.852030429658202,
      "grad_norm": 9.016785770654678e-05,
      "learning_rate": 1.0863959427122399e-05,
      "loss": 0.1937,
      "step": 63950
    },
    {
      "epoch": 6.8531018964963035,
      "grad_norm": 0.03675386682152748,
      "learning_rate": 1.0862530804671596e-05,
      "loss": 0.2183,
      "step": 63960
    },
    {
      "epoch": 6.854173363334405,
      "grad_norm": 0.00017361697973683476,
      "learning_rate": 1.0861102182220796e-05,
      "loss": 0.3345,
      "step": 63970
    },
    {
      "epoch": 6.855244830172506,
      "grad_norm": 0.00015984756464604288,
      "learning_rate": 1.0859673559769992e-05,
      "loss": 0.1092,
      "step": 63980
    },
    {
      "epoch": 6.856316297010608,
      "grad_norm": 0.00026170630007982254,
      "learning_rate": 1.0858244937319191e-05,
      "loss": 0.0004,
      "step": 63990
    },
    {
      "epoch": 6.857387763848709,
      "grad_norm": 0.043452974408864975,
      "learning_rate": 1.0856816314868389e-05,
      "loss": 0.0756,
      "step": 64000
    },
    {
      "epoch": 6.85845923068681,
      "grad_norm": 0.04625232145190239,
      "learning_rate": 1.0855387692417587e-05,
      "loss": 0.0007,
      "step": 64010
    },
    {
      "epoch": 6.859530697524912,
      "grad_norm": 0.00013487048272509128,
      "learning_rate": 1.0853959069966786e-05,
      "loss": 0.0005,
      "step": 64020
    },
    {
      "epoch": 6.860602164363013,
      "grad_norm": 0.013810091651976109,
      "learning_rate": 1.0852530447515984e-05,
      "loss": 0.0011,
      "step": 64030
    },
    {
      "epoch": 6.861673631201114,
      "grad_norm": 15.840499877929688,
      "learning_rate": 1.0851101825065183e-05,
      "loss": 0.1291,
      "step": 64040
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 18.34929656982422,
      "learning_rate": 1.0849673202614379e-05,
      "loss": 0.1638,
      "step": 64050
    },
    {
      "epoch": 6.863816564877317,
      "grad_norm": 0.00014867873687762767,
      "learning_rate": 1.0848244580163578e-05,
      "loss": 0.0008,
      "step": 64060
    },
    {
      "epoch": 6.864888031715418,
      "grad_norm": 0.00010427414235891774,
      "learning_rate": 1.0846815957712778e-05,
      "loss": 0.0005,
      "step": 64070
    },
    {
      "epoch": 6.8659594985535195,
      "grad_norm": 0.00016315549146384,
      "learning_rate": 1.0845387335261974e-05,
      "loss": 0.0003,
      "step": 64080
    },
    {
      "epoch": 6.8670309653916215,
      "grad_norm": 0.00016537912597414106,
      "learning_rate": 1.0843958712811173e-05,
      "loss": 0.0005,
      "step": 64090
    },
    {
      "epoch": 6.868102432229723,
      "grad_norm": 0.05932476371526718,
      "learning_rate": 1.084253009036037e-05,
      "loss": 0.0003,
      "step": 64100
    },
    {
      "epoch": 6.869173899067824,
      "grad_norm": 0.00016662897542119026,
      "learning_rate": 1.084110146790957e-05,
      "loss": 0.7893,
      "step": 64110
    },
    {
      "epoch": 6.870245365905925,
      "grad_norm": 0.033664505928754807,
      "learning_rate": 1.0839672845458766e-05,
      "loss": 0.2819,
      "step": 64120
    },
    {
      "epoch": 6.871316832744027,
      "grad_norm": 0.0042496598325669765,
      "learning_rate": 1.0838244223007965e-05,
      "loss": 0.0009,
      "step": 64130
    },
    {
      "epoch": 6.872388299582128,
      "grad_norm": 0.02702571451663971,
      "learning_rate": 1.0836815600557165e-05,
      "loss": 0.0008,
      "step": 64140
    },
    {
      "epoch": 6.873459766420229,
      "grad_norm": 0.13119961321353912,
      "learning_rate": 1.083538697810636e-05,
      "loss": 0.0006,
      "step": 64150
    },
    {
      "epoch": 6.874531233258331,
      "grad_norm": 0.0008750411798246205,
      "learning_rate": 1.083395835565556e-05,
      "loss": 0.0001,
      "step": 64160
    },
    {
      "epoch": 6.875602700096432,
      "grad_norm": 0.0002608759969007224,
      "learning_rate": 1.0832529733204758e-05,
      "loss": 0.0002,
      "step": 64170
    },
    {
      "epoch": 6.876674166934533,
      "grad_norm": 0.05810289829969406,
      "learning_rate": 1.0831101110753957e-05,
      "loss": 0.0003,
      "step": 64180
    },
    {
      "epoch": 6.877745633772634,
      "grad_norm": 0.0013518455671146512,
      "learning_rate": 1.0829672488303156e-05,
      "loss": 0.1615,
      "step": 64190
    },
    {
      "epoch": 6.878817100610736,
      "grad_norm": 0.016169916838407516,
      "learning_rate": 1.0828243865852352e-05,
      "loss": 0.1849,
      "step": 64200
    },
    {
      "epoch": 6.8798885674488375,
      "grad_norm": 0.0004609150346368551,
      "learning_rate": 1.0826815243401552e-05,
      "loss": 0.0001,
      "step": 64210
    },
    {
      "epoch": 6.880960034286939,
      "grad_norm": 19.04265022277832,
      "learning_rate": 1.0825386620950748e-05,
      "loss": 0.2895,
      "step": 64220
    },
    {
      "epoch": 6.88203150112504,
      "grad_norm": 0.032809603959321976,
      "learning_rate": 1.0823957998499947e-05,
      "loss": 0.0008,
      "step": 64230
    },
    {
      "epoch": 6.883102967963142,
      "grad_norm": 0.00017749604012351483,
      "learning_rate": 1.0822529376049145e-05,
      "loss": 0.0004,
      "step": 64240
    },
    {
      "epoch": 6.884174434801243,
      "grad_norm": 0.0009382661082781851,
      "learning_rate": 1.0821100753598344e-05,
      "loss": 0.0004,
      "step": 64250
    },
    {
      "epoch": 6.885245901639344,
      "grad_norm": 0.0002536878455430269,
      "learning_rate": 1.0819672131147544e-05,
      "loss": 0.0026,
      "step": 64260
    },
    {
      "epoch": 6.886317368477446,
      "grad_norm": 0.00032919866498559713,
      "learning_rate": 1.081824350869674e-05,
      "loss": 0.0007,
      "step": 64270
    },
    {
      "epoch": 6.887388835315547,
      "grad_norm": 0.000251277961069718,
      "learning_rate": 1.0816814886245939e-05,
      "loss": 0.181,
      "step": 64280
    },
    {
      "epoch": 6.888460302153648,
      "grad_norm": 0.00021234338055364788,
      "learning_rate": 1.0815386263795135e-05,
      "loss": 0.0005,
      "step": 64290
    },
    {
      "epoch": 6.88953176899175,
      "grad_norm": 0.1279660314321518,
      "learning_rate": 1.0813957641344334e-05,
      "loss": 0.0004,
      "step": 64300
    },
    {
      "epoch": 6.890603235829851,
      "grad_norm": 0.17445296049118042,
      "learning_rate": 1.0812529018893534e-05,
      "loss": 0.2225,
      "step": 64310
    },
    {
      "epoch": 6.891674702667952,
      "grad_norm": 0.0015433545922860503,
      "learning_rate": 1.0811100396442731e-05,
      "loss": 0.0001,
      "step": 64320
    },
    {
      "epoch": 6.8927461695060535,
      "grad_norm": 0.0007328515057452023,
      "learning_rate": 1.080967177399193e-05,
      "loss": 0.0007,
      "step": 64330
    },
    {
      "epoch": 6.8938176363441555,
      "grad_norm": 0.0572681687772274,
      "learning_rate": 1.0808243151541127e-05,
      "loss": 0.1931,
      "step": 64340
    },
    {
      "epoch": 6.894889103182257,
      "grad_norm": 0.023104717954993248,
      "learning_rate": 1.0806814529090326e-05,
      "loss": 0.1127,
      "step": 64350
    },
    {
      "epoch": 6.895960570020358,
      "grad_norm": 0.000334224256221205,
      "learning_rate": 1.0805385906639522e-05,
      "loss": 0.0005,
      "step": 64360
    },
    {
      "epoch": 6.897032036858459,
      "grad_norm": 0.00019843185145873576,
      "learning_rate": 1.0803957284188721e-05,
      "loss": 0.0003,
      "step": 64370
    },
    {
      "epoch": 6.898103503696561,
      "grad_norm": 0.0002700549957808107,
      "learning_rate": 1.080252866173792e-05,
      "loss": 0.2015,
      "step": 64380
    },
    {
      "epoch": 6.899174970534662,
      "grad_norm": 0.10386145114898682,
      "learning_rate": 1.0801100039287118e-05,
      "loss": 0.0005,
      "step": 64390
    },
    {
      "epoch": 6.900246437372763,
      "grad_norm": 0.1331971436738968,
      "learning_rate": 1.0799671416836318e-05,
      "loss": 0.1044,
      "step": 64400
    },
    {
      "epoch": 6.901317904210865,
      "grad_norm": 0.013010839931666851,
      "learning_rate": 1.0798242794385514e-05,
      "loss": 0.0004,
      "step": 64410
    },
    {
      "epoch": 6.902389371048966,
      "grad_norm": 0.0001642752467887476,
      "learning_rate": 1.0796814171934713e-05,
      "loss": 0.0002,
      "step": 64420
    },
    {
      "epoch": 6.903460837887067,
      "grad_norm": 0.0004699469427578151,
      "learning_rate": 1.079538554948391e-05,
      "loss": 0.0001,
      "step": 64430
    },
    {
      "epoch": 6.904532304725169,
      "grad_norm": 0.00036283626104705036,
      "learning_rate": 1.0793956927033108e-05,
      "loss": 0.0697,
      "step": 64440
    },
    {
      "epoch": 6.90560377156327,
      "grad_norm": 0.09706958383321762,
      "learning_rate": 1.0792528304582308e-05,
      "loss": 0.0007,
      "step": 64450
    },
    {
      "epoch": 6.906675238401371,
      "grad_norm": 0.0019619676750153303,
      "learning_rate": 1.0791099682131505e-05,
      "loss": 0.0001,
      "step": 64460
    },
    {
      "epoch": 6.9077467052394725,
      "grad_norm": 21.052265167236328,
      "learning_rate": 1.0789671059680705e-05,
      "loss": 0.3542,
      "step": 64470
    },
    {
      "epoch": 6.9088181720775745,
      "grad_norm": 0.04815129563212395,
      "learning_rate": 1.07882424372299e-05,
      "loss": 0.0002,
      "step": 64480
    },
    {
      "epoch": 6.909889638915676,
      "grad_norm": 0.010421432554721832,
      "learning_rate": 1.07868138147791e-05,
      "loss": 0.0001,
      "step": 64490
    },
    {
      "epoch": 6.910961105753777,
      "grad_norm": 0.032110441476106644,
      "learning_rate": 1.07853851923283e-05,
      "loss": 0.0006,
      "step": 64500
    },
    {
      "epoch": 6.912032572591878,
      "grad_norm": 0.0007637354428879917,
      "learning_rate": 1.0783956569877496e-05,
      "loss": 0.3117,
      "step": 64510
    },
    {
      "epoch": 6.91310403942998,
      "grad_norm": 0.05388995260000229,
      "learning_rate": 1.0782527947426695e-05,
      "loss": 0.1524,
      "step": 64520
    },
    {
      "epoch": 6.914175506268081,
      "grad_norm": 0.0015361206606030464,
      "learning_rate": 1.0781099324975893e-05,
      "loss": 0.0002,
      "step": 64530
    },
    {
      "epoch": 6.915246973106182,
      "grad_norm": 0.0006833657971583307,
      "learning_rate": 1.0779670702525092e-05,
      "loss": 0.1711,
      "step": 64540
    },
    {
      "epoch": 6.916318439944284,
      "grad_norm": 0.023899102583527565,
      "learning_rate": 1.0778242080074288e-05,
      "loss": 0.2253,
      "step": 64550
    },
    {
      "epoch": 6.917389906782385,
      "grad_norm": 0.0006497233989648521,
      "learning_rate": 1.0776813457623487e-05,
      "loss": 0.0005,
      "step": 64560
    },
    {
      "epoch": 6.918461373620486,
      "grad_norm": 0.0006301358807832003,
      "learning_rate": 1.0775384835172687e-05,
      "loss": 0.0004,
      "step": 64570
    },
    {
      "epoch": 6.919532840458588,
      "grad_norm": 0.0017379034543409944,
      "learning_rate": 1.0773956212721883e-05,
      "loss": 0.2323,
      "step": 64580
    },
    {
      "epoch": 6.920604307296689,
      "grad_norm": 0.09001407027244568,
      "learning_rate": 1.0772527590271082e-05,
      "loss": 0.0006,
      "step": 64590
    },
    {
      "epoch": 6.9216757741347905,
      "grad_norm": 0.024001486599445343,
      "learning_rate": 1.077109896782028e-05,
      "loss": 0.0004,
      "step": 64600
    },
    {
      "epoch": 6.922747240972892,
      "grad_norm": 0.00042376015335321426,
      "learning_rate": 1.0769670345369479e-05,
      "loss": 0.0003,
      "step": 64610
    },
    {
      "epoch": 6.923818707810994,
      "grad_norm": 0.000523970986250788,
      "learning_rate": 1.0768241722918677e-05,
      "loss": 0.3638,
      "step": 64620
    },
    {
      "epoch": 6.924890174649095,
      "grad_norm": 0.0013402458280324936,
      "learning_rate": 1.0766813100467874e-05,
      "loss": 0.1014,
      "step": 64630
    },
    {
      "epoch": 6.925961641487196,
      "grad_norm": 0.0020052017644047737,
      "learning_rate": 1.0765384478017074e-05,
      "loss": 0.0005,
      "step": 64640
    },
    {
      "epoch": 6.927033108325297,
      "grad_norm": 0.0017283560009673238,
      "learning_rate": 1.076395585556627e-05,
      "loss": 0.0009,
      "step": 64650
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 0.01102778222411871,
      "learning_rate": 1.0762527233115469e-05,
      "loss": 0.0691,
      "step": 64660
    },
    {
      "epoch": 6.9291760420015,
      "grad_norm": 0.006254862993955612,
      "learning_rate": 1.0761098610664667e-05,
      "loss": 0.0001,
      "step": 64670
    },
    {
      "epoch": 6.930247508839601,
      "grad_norm": 0.0022664202842861414,
      "learning_rate": 1.0759669988213866e-05,
      "loss": 0.2111,
      "step": 64680
    },
    {
      "epoch": 6.931318975677703,
      "grad_norm": 0.0018766133580356836,
      "learning_rate": 1.0758241365763066e-05,
      "loss": 0.0002,
      "step": 64690
    },
    {
      "epoch": 6.932390442515804,
      "grad_norm": 0.01139711681753397,
      "learning_rate": 1.0756812743312261e-05,
      "loss": 0.0005,
      "step": 64700
    },
    {
      "epoch": 6.933461909353905,
      "grad_norm": 23.77791404724121,
      "learning_rate": 1.0755384120861461e-05,
      "loss": 0.2118,
      "step": 64710
    },
    {
      "epoch": 6.9345333761920065,
      "grad_norm": 0.0004088216810487211,
      "learning_rate": 1.0753955498410657e-05,
      "loss": 0.0006,
      "step": 64720
    },
    {
      "epoch": 6.9356048430301085,
      "grad_norm": 0.019399957731366158,
      "learning_rate": 1.0752526875959856e-05,
      "loss": 0.0048,
      "step": 64730
    },
    {
      "epoch": 6.93667630986821,
      "grad_norm": 0.011202619411051273,
      "learning_rate": 1.0751098253509056e-05,
      "loss": 0.0001,
      "step": 64740
    },
    {
      "epoch": 6.937747776706311,
      "grad_norm": 0.0002239789318991825,
      "learning_rate": 1.0749669631058253e-05,
      "loss": 0.0004,
      "step": 64750
    },
    {
      "epoch": 6.938819243544412,
      "grad_norm": 0.007735755760222673,
      "learning_rate": 1.0748241008607453e-05,
      "loss": 0.0002,
      "step": 64760
    },
    {
      "epoch": 6.939890710382514,
      "grad_norm": 0.10209077596664429,
      "learning_rate": 1.0746812386156649e-05,
      "loss": 0.0002,
      "step": 64770
    },
    {
      "epoch": 6.940962177220615,
      "grad_norm": 0.032263610512018204,
      "learning_rate": 1.0745383763705848e-05,
      "loss": 0.0002,
      "step": 64780
    },
    {
      "epoch": 6.942033644058716,
      "grad_norm": 0.0070262146182358265,
      "learning_rate": 1.0743955141255044e-05,
      "loss": 0.0002,
      "step": 64790
    },
    {
      "epoch": 6.943105110896818,
      "grad_norm": 0.030213912948966026,
      "learning_rate": 1.0742526518804243e-05,
      "loss": 0.0007,
      "step": 64800
    },
    {
      "epoch": 6.944176577734919,
      "grad_norm": 0.0099331671372056,
      "learning_rate": 1.0741097896353443e-05,
      "loss": 0.4022,
      "step": 64810
    },
    {
      "epoch": 6.94524804457302,
      "grad_norm": 0.0012162018101662397,
      "learning_rate": 1.073966927390264e-05,
      "loss": 0.0003,
      "step": 64820
    },
    {
      "epoch": 6.946319511411122,
      "grad_norm": 0.00996819231659174,
      "learning_rate": 1.073824065145184e-05,
      "loss": 0.0005,
      "step": 64830
    },
    {
      "epoch": 6.947390978249223,
      "grad_norm": 16.587493896484375,
      "learning_rate": 1.0736812029001036e-05,
      "loss": 0.0929,
      "step": 64840
    },
    {
      "epoch": 6.9484624450873245,
      "grad_norm": 21.937925338745117,
      "learning_rate": 1.0735383406550235e-05,
      "loss": 0.1925,
      "step": 64850
    },
    {
      "epoch": 6.949533911925426,
      "grad_norm": 0.0002936223754659295,
      "learning_rate": 1.0733954784099434e-05,
      "loss": 0.1714,
      "step": 64860
    },
    {
      "epoch": 6.950605378763528,
      "grad_norm": 0.00039542894228361547,
      "learning_rate": 1.073252616164863e-05,
      "loss": 0.0004,
      "step": 64870
    },
    {
      "epoch": 6.951676845601629,
      "grad_norm": 0.0005015377537347376,
      "learning_rate": 1.073109753919783e-05,
      "loss": 0.0005,
      "step": 64880
    },
    {
      "epoch": 6.95274831243973,
      "grad_norm": 0.03702814504504204,
      "learning_rate": 1.0729668916747027e-05,
      "loss": 0.3302,
      "step": 64890
    },
    {
      "epoch": 6.953819779277831,
      "grad_norm": 0.00020253028196748346,
      "learning_rate": 1.0728240294296227e-05,
      "loss": 0.0001,
      "step": 64900
    },
    {
      "epoch": 6.954891246115933,
      "grad_norm": 0.019573623314499855,
      "learning_rate": 1.0726811671845423e-05,
      "loss": 0.5213,
      "step": 64910
    },
    {
      "epoch": 6.955962712954034,
      "grad_norm": 0.001049380749464035,
      "learning_rate": 1.0725383049394622e-05,
      "loss": 0.1504,
      "step": 64920
    },
    {
      "epoch": 6.957034179792135,
      "grad_norm": 0.0006106023793108761,
      "learning_rate": 1.0723954426943822e-05,
      "loss": 0.0008,
      "step": 64930
    },
    {
      "epoch": 6.958105646630237,
      "grad_norm": 0.038997046649456024,
      "learning_rate": 1.0722525804493017e-05,
      "loss": 0.0003,
      "step": 64940
    },
    {
      "epoch": 6.959177113468338,
      "grad_norm": 0.004533423110842705,
      "learning_rate": 1.0721097182042217e-05,
      "loss": 0.0005,
      "step": 64950
    },
    {
      "epoch": 6.960248580306439,
      "grad_norm": 0.023517820984125137,
      "learning_rate": 1.0719668559591415e-05,
      "loss": 0.0752,
      "step": 64960
    },
    {
      "epoch": 6.961320047144541,
      "grad_norm": 14.35578727722168,
      "learning_rate": 1.0718239937140614e-05,
      "loss": 0.2983,
      "step": 64970
    },
    {
      "epoch": 6.962391513982642,
      "grad_norm": 0.0004067330155521631,
      "learning_rate": 1.0716811314689812e-05,
      "loss": 0.0005,
      "step": 64980
    },
    {
      "epoch": 6.9634629808207436,
      "grad_norm": 0.0005271951085887849,
      "learning_rate": 1.071538269223901e-05,
      "loss": 0.0002,
      "step": 64990
    },
    {
      "epoch": 6.964534447658845,
      "grad_norm": 0.002786739729344845,
      "learning_rate": 1.0713954069788209e-05,
      "loss": 0.0007,
      "step": 65000
    },
    {
      "epoch": 6.965605914496947,
      "grad_norm": 0.045614831149578094,
      "learning_rate": 1.0712525447337405e-05,
      "loss": 0.0034,
      "step": 65010
    },
    {
      "epoch": 6.966677381335048,
      "grad_norm": 1.1625961065292358,
      "learning_rate": 1.0711096824886604e-05,
      "loss": 0.0015,
      "step": 65020
    },
    {
      "epoch": 6.967748848173149,
      "grad_norm": 0.012155375443398952,
      "learning_rate": 1.0709668202435802e-05,
      "loss": 0.4951,
      "step": 65030
    },
    {
      "epoch": 6.96882031501125,
      "grad_norm": 0.44999781250953674,
      "learning_rate": 1.0708239579985001e-05,
      "loss": 0.0007,
      "step": 65040
    },
    {
      "epoch": 6.969891781849352,
      "grad_norm": 0.1085604801774025,
      "learning_rate": 1.0706810957534199e-05,
      "loss": 0.1444,
      "step": 65050
    },
    {
      "epoch": 6.970963248687453,
      "grad_norm": 0.06199592351913452,
      "learning_rate": 1.0705382335083396e-05,
      "loss": 0.1302,
      "step": 65060
    },
    {
      "epoch": 6.972034715525554,
      "grad_norm": 0.07778438180685043,
      "learning_rate": 1.0703953712632596e-05,
      "loss": 0.0029,
      "step": 65070
    },
    {
      "epoch": 6.973106182363656,
      "grad_norm": 0.14450664818286896,
      "learning_rate": 1.0702525090181792e-05,
      "loss": 0.0009,
      "step": 65080
    },
    {
      "epoch": 6.974177649201757,
      "grad_norm": 0.5092177391052246,
      "learning_rate": 1.0701096467730991e-05,
      "loss": 0.0008,
      "step": 65090
    },
    {
      "epoch": 6.975249116039858,
      "grad_norm": 0.0005896787042729557,
      "learning_rate": 1.069966784528019e-05,
      "loss": 0.1237,
      "step": 65100
    },
    {
      "epoch": 6.97632058287796,
      "grad_norm": 0.16656126081943512,
      "learning_rate": 1.0698239222829388e-05,
      "loss": 0.2076,
      "step": 65110
    },
    {
      "epoch": 6.9773920497160615,
      "grad_norm": 0.0002900565159507096,
      "learning_rate": 1.0696810600378586e-05,
      "loss": 0.0002,
      "step": 65120
    },
    {
      "epoch": 6.978463516554163,
      "grad_norm": 0.00040435115806758404,
      "learning_rate": 1.0695381977927783e-05,
      "loss": 0.0006,
      "step": 65130
    },
    {
      "epoch": 6.979534983392264,
      "grad_norm": 0.007665055803954601,
      "learning_rate": 1.0693953355476983e-05,
      "loss": 0.0005,
      "step": 65140
    },
    {
      "epoch": 6.980606450230366,
      "grad_norm": 0.14296047389507294,
      "learning_rate": 1.0692524733026179e-05,
      "loss": 0.0001,
      "step": 65150
    },
    {
      "epoch": 6.981677917068467,
      "grad_norm": 0.018257450312376022,
      "learning_rate": 1.0691096110575378e-05,
      "loss": 0.0002,
      "step": 65160
    },
    {
      "epoch": 6.982749383906568,
      "grad_norm": 0.0002421237004455179,
      "learning_rate": 1.0689667488124578e-05,
      "loss": 0.388,
      "step": 65170
    },
    {
      "epoch": 6.983820850744669,
      "grad_norm": 0.01753806322813034,
      "learning_rate": 1.0688238865673775e-05,
      "loss": 0.0008,
      "step": 65180
    },
    {
      "epoch": 6.984892317582771,
      "grad_norm": 0.018282297998666763,
      "learning_rate": 1.0686810243222973e-05,
      "loss": 0.1684,
      "step": 65190
    },
    {
      "epoch": 6.985963784420872,
      "grad_norm": 0.0005718088359571993,
      "learning_rate": 1.068538162077217e-05,
      "loss": 0.0005,
      "step": 65200
    },
    {
      "epoch": 6.987035251258973,
      "grad_norm": 0.013518812134861946,
      "learning_rate": 1.068395299832137e-05,
      "loss": 0.1423,
      "step": 65210
    },
    {
      "epoch": 6.988106718097075,
      "grad_norm": 0.012990317307412624,
      "learning_rate": 1.068252437587057e-05,
      "loss": 0.0002,
      "step": 65220
    },
    {
      "epoch": 6.989178184935176,
      "grad_norm": 0.0007396812434308231,
      "learning_rate": 1.0681095753419765e-05,
      "loss": 0.2097,
      "step": 65230
    },
    {
      "epoch": 6.9902496517732775,
      "grad_norm": 0.0015660366043448448,
      "learning_rate": 1.0679667130968965e-05,
      "loss": 0.0001,
      "step": 65240
    },
    {
      "epoch": 6.991321118611379,
      "grad_norm": 0.00016367153148166835,
      "learning_rate": 1.0678238508518162e-05,
      "loss": 0.1072,
      "step": 65250
    },
    {
      "epoch": 6.992392585449481,
      "grad_norm": 0.0050072320736944675,
      "learning_rate": 1.0676809886067362e-05,
      "loss": 0.2406,
      "step": 65260
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 0.00013000740727875382,
      "learning_rate": 1.0675381263616558e-05,
      "loss": 0.0007,
      "step": 65270
    },
    {
      "epoch": 6.994535519125683,
      "grad_norm": 0.0006887721829116344,
      "learning_rate": 1.0673952641165757e-05,
      "loss": 0.0004,
      "step": 65280
    },
    {
      "epoch": 6.995606985963784,
      "grad_norm": 0.02561403624713421,
      "learning_rate": 1.0672524018714956e-05,
      "loss": 0.1704,
      "step": 65290
    },
    {
      "epoch": 6.996678452801886,
      "grad_norm": 17.974424362182617,
      "learning_rate": 1.0671095396264152e-05,
      "loss": 0.1578,
      "step": 65300
    },
    {
      "epoch": 6.997749919639987,
      "grad_norm": 0.039475422352552414,
      "learning_rate": 1.0669666773813352e-05,
      "loss": 0.2623,
      "step": 65310
    },
    {
      "epoch": 6.998821386478088,
      "grad_norm": 30.259042739868164,
      "learning_rate": 1.066823815136255e-05,
      "loss": 0.1454,
      "step": 65320
    },
    {
      "epoch": 6.99989285331619,
      "grad_norm": 0.21754054725170135,
      "learning_rate": 1.0666809528911749e-05,
      "loss": 0.0014,
      "step": 65330
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9756666666666667,
      "eval_f1": 0.9012178619756429,
      "eval_loss": 0.13329023122787476,
      "eval_precision": 0.9237170596393898,
      "eval_recall": 0.8797886393659181,
      "eval_runtime": 393.0937,
      "eval_samples_per_second": 15.264,
      "eval_steps_per_second": 5.088,
      "step": 65331
    },
    {
      "epoch": 7.000964320154291,
      "grad_norm": 0.0025887226220220327,
      "learning_rate": 1.0665380906460945e-05,
      "loss": 0.1375,
      "step": 65340
    },
    {
      "epoch": 7.002035786992392,
      "grad_norm": 0.00042570970254018903,
      "learning_rate": 1.0663952284010144e-05,
      "loss": 0.0004,
      "step": 65350
    },
    {
      "epoch": 7.003107253830494,
      "grad_norm": 0.02635333500802517,
      "learning_rate": 1.0662523661559343e-05,
      "loss": 0.0005,
      "step": 65360
    },
    {
      "epoch": 7.0041787206685955,
      "grad_norm": 0.0038322904147207737,
      "learning_rate": 1.066109503910854e-05,
      "loss": 0.0008,
      "step": 65370
    },
    {
      "epoch": 7.005250187506697,
      "grad_norm": 0.06202123686671257,
      "learning_rate": 1.0659666416657739e-05,
      "loss": 0.0211,
      "step": 65380
    },
    {
      "epoch": 7.006321654344798,
      "grad_norm": 0.01387177687138319,
      "learning_rate": 1.0658237794206936e-05,
      "loss": 0.0003,
      "step": 65390
    },
    {
      "epoch": 7.0073931211829,
      "grad_norm": 0.026562044396996498,
      "learning_rate": 1.0656809171756136e-05,
      "loss": 0.0003,
      "step": 65400
    },
    {
      "epoch": 7.008464588021001,
      "grad_norm": 0.09669846296310425,
      "learning_rate": 1.0655380549305334e-05,
      "loss": 0.0043,
      "step": 65410
    },
    {
      "epoch": 7.009536054859102,
      "grad_norm": 0.00016422371845692396,
      "learning_rate": 1.0653951926854531e-05,
      "loss": 0.0002,
      "step": 65420
    },
    {
      "epoch": 7.010607521697204,
      "grad_norm": 0.08017808198928833,
      "learning_rate": 1.065252330440373e-05,
      "loss": 0.0002,
      "step": 65430
    },
    {
      "epoch": 7.011678988535305,
      "grad_norm": 8.323704969370738e-05,
      "learning_rate": 1.0651094681952927e-05,
      "loss": 0.001,
      "step": 65440
    },
    {
      "epoch": 7.012750455373406,
      "grad_norm": 0.0006694454932585359,
      "learning_rate": 1.0649666059502126e-05,
      "loss": 0.0,
      "step": 65450
    },
    {
      "epoch": 7.013821922211507,
      "grad_norm": 0.004894936457276344,
      "learning_rate": 1.0648237437051324e-05,
      "loss": 0.3193,
      "step": 65460
    },
    {
      "epoch": 7.014893389049609,
      "grad_norm": 0.00016770402726251632,
      "learning_rate": 1.0646808814600523e-05,
      "loss": 0.0007,
      "step": 65470
    },
    {
      "epoch": 7.01596485588771,
      "grad_norm": 0.006793107837438583,
      "learning_rate": 1.064538019214972e-05,
      "loss": 0.0004,
      "step": 65480
    },
    {
      "epoch": 7.0170363227258115,
      "grad_norm": 0.11330869793891907,
      "learning_rate": 1.0643951569698918e-05,
      "loss": 0.2248,
      "step": 65490
    },
    {
      "epoch": 7.018107789563913,
      "grad_norm": 0.05354982987046242,
      "learning_rate": 1.0642522947248118e-05,
      "loss": 0.1699,
      "step": 65500
    },
    {
      "epoch": 7.019179256402015,
      "grad_norm": 77.46736907958984,
      "learning_rate": 1.0641094324797314e-05,
      "loss": 0.3853,
      "step": 65510
    },
    {
      "epoch": 7.020250723240116,
      "grad_norm": 0.031802475452423096,
      "learning_rate": 1.0639665702346513e-05,
      "loss": 0.0002,
      "step": 65520
    },
    {
      "epoch": 7.021322190078217,
      "grad_norm": 0.0011143775191158056,
      "learning_rate": 1.0638237079895712e-05,
      "loss": 0.0003,
      "step": 65530
    },
    {
      "epoch": 7.022393656916319,
      "grad_norm": 0.0005302965873852372,
      "learning_rate": 1.063680845744491e-05,
      "loss": 0.0001,
      "step": 65540
    },
    {
      "epoch": 7.02346512375442,
      "grad_norm": 0.11763109266757965,
      "learning_rate": 1.0635379834994108e-05,
      "loss": 0.0004,
      "step": 65550
    },
    {
      "epoch": 7.024536590592521,
      "grad_norm": 0.0001486667024437338,
      "learning_rate": 1.0633951212543305e-05,
      "loss": 0.0001,
      "step": 65560
    },
    {
      "epoch": 7.025608057430622,
      "grad_norm": 0.0003107801894657314,
      "learning_rate": 1.0632522590092505e-05,
      "loss": 0.0001,
      "step": 65570
    },
    {
      "epoch": 7.026679524268724,
      "grad_norm": 0.000312876480165869,
      "learning_rate": 1.06310939676417e-05,
      "loss": 0.0002,
      "step": 65580
    },
    {
      "epoch": 7.027750991106825,
      "grad_norm": 0.021097952499985695,
      "learning_rate": 1.06296653451909e-05,
      "loss": 0.0005,
      "step": 65590
    },
    {
      "epoch": 7.028822457944926,
      "grad_norm": 0.0073769306764006615,
      "learning_rate": 1.06282367227401e-05,
      "loss": 0.0014,
      "step": 65600
    },
    {
      "epoch": 7.029893924783028,
      "grad_norm": 0.0002007535076700151,
      "learning_rate": 1.0626808100289297e-05,
      "loss": 0.2145,
      "step": 65610
    },
    {
      "epoch": 7.030965391621129,
      "grad_norm": 0.0003412411024328321,
      "learning_rate": 1.0625379477838495e-05,
      "loss": 0.0001,
      "step": 65620
    },
    {
      "epoch": 7.0320368584592305,
      "grad_norm": 0.0051884958520531654,
      "learning_rate": 1.0623950855387692e-05,
      "loss": 0.0001,
      "step": 65630
    },
    {
      "epoch": 7.033108325297332,
      "grad_norm": 0.005955364089459181,
      "learning_rate": 1.0622522232936892e-05,
      "loss": 0.0001,
      "step": 65640
    },
    {
      "epoch": 7.034179792135434,
      "grad_norm": 0.0002069240144919604,
      "learning_rate": 1.0621093610486091e-05,
      "loss": 0.0003,
      "step": 65650
    },
    {
      "epoch": 7.035251258973535,
      "grad_norm": 0.00031588852289132774,
      "learning_rate": 1.0619664988035287e-05,
      "loss": 0.1162,
      "step": 65660
    },
    {
      "epoch": 7.036322725811636,
      "grad_norm": 0.0007392715779133141,
      "learning_rate": 1.0618236365584487e-05,
      "loss": 0.0002,
      "step": 65670
    },
    {
      "epoch": 7.037394192649738,
      "grad_norm": 0.0015303732361644506,
      "learning_rate": 1.0616807743133684e-05,
      "loss": 0.0003,
      "step": 65680
    },
    {
      "epoch": 7.038465659487839,
      "grad_norm": 0.015112234279513359,
      "learning_rate": 1.0615379120682882e-05,
      "loss": 0.0001,
      "step": 65690
    },
    {
      "epoch": 7.03953712632594,
      "grad_norm": 0.003965616691857576,
      "learning_rate": 1.061395049823208e-05,
      "loss": 0.0022,
      "step": 65700
    },
    {
      "epoch": 7.040608593164041,
      "grad_norm": 0.003155913669615984,
      "learning_rate": 1.0612521875781279e-05,
      "loss": 0.1924,
      "step": 65710
    },
    {
      "epoch": 7.041680060002143,
      "grad_norm": 0.0001407117524649948,
      "learning_rate": 1.0611093253330478e-05,
      "loss": 0.0001,
      "step": 65720
    },
    {
      "epoch": 7.042751526840244,
      "grad_norm": 0.0006359529797919095,
      "learning_rate": 1.0609664630879674e-05,
      "loss": 0.0003,
      "step": 65730
    },
    {
      "epoch": 7.043822993678345,
      "grad_norm": 0.00010364020272390917,
      "learning_rate": 1.0608236008428874e-05,
      "loss": 0.0003,
      "step": 65740
    },
    {
      "epoch": 7.044894460516447,
      "grad_norm": 0.00012732234608847648,
      "learning_rate": 1.0606807385978071e-05,
      "loss": 0.0007,
      "step": 65750
    },
    {
      "epoch": 7.0459659273545485,
      "grad_norm": 0.00013483487418852746,
      "learning_rate": 1.0605378763527269e-05,
      "loss": 0.0,
      "step": 65760
    },
    {
      "epoch": 7.04703739419265,
      "grad_norm": 0.03408461809158325,
      "learning_rate": 1.0603950141076468e-05,
      "loss": 0.0001,
      "step": 65770
    },
    {
      "epoch": 7.048108861030751,
      "grad_norm": 0.00012020758731523529,
      "learning_rate": 1.0602521518625666e-05,
      "loss": 0.0,
      "step": 65780
    },
    {
      "epoch": 7.049180327868853,
      "grad_norm": 0.0028273931238800287,
      "learning_rate": 1.0601092896174865e-05,
      "loss": 0.0001,
      "step": 65790
    },
    {
      "epoch": 7.050251794706954,
      "grad_norm": 0.003027569502592087,
      "learning_rate": 1.0599664273724061e-05,
      "loss": 0.0001,
      "step": 65800
    },
    {
      "epoch": 7.051323261545055,
      "grad_norm": 7.93721919762902e-05,
      "learning_rate": 1.059823565127326e-05,
      "loss": 0.0,
      "step": 65810
    },
    {
      "epoch": 7.052394728383157,
      "grad_norm": 0.00013665563892573118,
      "learning_rate": 1.0596807028822458e-05,
      "loss": 0.2639,
      "step": 65820
    },
    {
      "epoch": 7.053466195221258,
      "grad_norm": 0.00013578108337242156,
      "learning_rate": 1.0595378406371658e-05,
      "loss": 0.0,
      "step": 65830
    },
    {
      "epoch": 7.054537662059359,
      "grad_norm": 0.002318139187991619,
      "learning_rate": 1.0593949783920855e-05,
      "loss": 0.0,
      "step": 65840
    },
    {
      "epoch": 7.05560912889746,
      "grad_norm": 0.00029773145797662437,
      "learning_rate": 1.0592521161470053e-05,
      "loss": 0.1282,
      "step": 65850
    },
    {
      "epoch": 7.056680595735562,
      "grad_norm": 0.0059601059183478355,
      "learning_rate": 1.0591092539019252e-05,
      "loss": 0.4215,
      "step": 65860
    },
    {
      "epoch": 7.057752062573663,
      "grad_norm": 0.006539282854646444,
      "learning_rate": 1.0589663916568448e-05,
      "loss": 0.0003,
      "step": 65870
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.00015943114703986794,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 0.0,
      "step": 65880
    },
    {
      "epoch": 7.0598949962498665,
      "grad_norm": 0.0002849568263627589,
      "learning_rate": 1.0586806671666847e-05,
      "loss": 0.0008,
      "step": 65890
    },
    {
      "epoch": 7.060966463087968,
      "grad_norm": 0.0003907357167918235,
      "learning_rate": 1.0585378049216045e-05,
      "loss": 0.0009,
      "step": 65900
    },
    {
      "epoch": 7.062037929926069,
      "grad_norm": 0.00011955938680330291,
      "learning_rate": 1.0583949426765243e-05,
      "loss": 0.0,
      "step": 65910
    },
    {
      "epoch": 7.06310939676417,
      "grad_norm": 0.021824629977345467,
      "learning_rate": 1.058252080431444e-05,
      "loss": 0.0001,
      "step": 65920
    },
    {
      "epoch": 7.064180863602272,
      "grad_norm": 0.00015188366523943841,
      "learning_rate": 1.058109218186364e-05,
      "loss": 0.0,
      "step": 65930
    },
    {
      "epoch": 7.065252330440373,
      "grad_norm": 0.012205497361719608,
      "learning_rate": 1.0579663559412836e-05,
      "loss": 0.0002,
      "step": 65940
    },
    {
      "epoch": 7.066323797278474,
      "grad_norm": 0.0010766148334369063,
      "learning_rate": 1.0578234936962035e-05,
      "loss": 0.2307,
      "step": 65950
    },
    {
      "epoch": 7.067395264116575,
      "grad_norm": 0.0001477274636272341,
      "learning_rate": 1.0576806314511234e-05,
      "loss": 0.0008,
      "step": 65960
    },
    {
      "epoch": 7.068466730954677,
      "grad_norm": 0.00019868629169650376,
      "learning_rate": 1.0575377692060432e-05,
      "loss": 0.2614,
      "step": 65970
    },
    {
      "epoch": 7.069538197792778,
      "grad_norm": 0.00013281127030495554,
      "learning_rate": 1.057394906960963e-05,
      "loss": 0.0002,
      "step": 65980
    },
    {
      "epoch": 7.070609664630879,
      "grad_norm": 0.014327897690236568,
      "learning_rate": 1.0572520447158827e-05,
      "loss": 0.4678,
      "step": 65990
    },
    {
      "epoch": 7.071681131468981,
      "grad_norm": 0.06214809790253639,
      "learning_rate": 1.0571091824708027e-05,
      "loss": 0.0008,
      "step": 66000
    },
    {
      "epoch": 7.0727525983070825,
      "grad_norm": 0.012527693063020706,
      "learning_rate": 1.0569663202257226e-05,
      "loss": 0.0002,
      "step": 66010
    },
    {
      "epoch": 7.073824065145184,
      "grad_norm": 0.00020083908748347312,
      "learning_rate": 1.0568234579806422e-05,
      "loss": 0.1782,
      "step": 66020
    },
    {
      "epoch": 7.074895531983285,
      "grad_norm": 0.00017721683252602816,
      "learning_rate": 1.0566805957355621e-05,
      "loss": 0.178,
      "step": 66030
    },
    {
      "epoch": 7.075966998821387,
      "grad_norm": 0.16568775475025177,
      "learning_rate": 1.0565377334904819e-05,
      "loss": 0.0007,
      "step": 66040
    },
    {
      "epoch": 7.077038465659488,
      "grad_norm": 0.0004313514509703964,
      "learning_rate": 1.0563948712454017e-05,
      "loss": 0.0012,
      "step": 66050
    },
    {
      "epoch": 7.078109932497589,
      "grad_norm": 0.015894673764705658,
      "learning_rate": 1.0562520090003214e-05,
      "loss": 0.0003,
      "step": 66060
    },
    {
      "epoch": 7.079181399335691,
      "grad_norm": 0.0018762481631711125,
      "learning_rate": 1.0561091467552414e-05,
      "loss": 0.0002,
      "step": 66070
    },
    {
      "epoch": 7.080252866173792,
      "grad_norm": 0.0003541434707585722,
      "learning_rate": 1.0559662845101613e-05,
      "loss": 0.0,
      "step": 66080
    },
    {
      "epoch": 7.081324333011893,
      "grad_norm": 0.0018520383164286613,
      "learning_rate": 1.0558234222650809e-05,
      "loss": 0.0002,
      "step": 66090
    },
    {
      "epoch": 7.082395799849994,
      "grad_norm": 0.0005644410848617554,
      "learning_rate": 1.0556805600200008e-05,
      "loss": 0.0004,
      "step": 66100
    },
    {
      "epoch": 7.083467266688096,
      "grad_norm": 0.00021802441915497184,
      "learning_rate": 1.0555376977749206e-05,
      "loss": 0.0002,
      "step": 66110
    },
    {
      "epoch": 7.084538733526197,
      "grad_norm": 0.00026417311164550483,
      "learning_rate": 1.0553948355298404e-05,
      "loss": 0.0002,
      "step": 66120
    },
    {
      "epoch": 7.0856102003642984,
      "grad_norm": 0.03058258816599846,
      "learning_rate": 1.0552519732847603e-05,
      "loss": 0.0002,
      "step": 66130
    },
    {
      "epoch": 7.0866816672024004,
      "grad_norm": 0.0027542919851839542,
      "learning_rate": 1.0551091110396801e-05,
      "loss": 0.0001,
      "step": 66140
    },
    {
      "epoch": 7.087753134040502,
      "grad_norm": 0.00045436524669639766,
      "learning_rate": 1.0549662487946e-05,
      "loss": 0.2499,
      "step": 66150
    },
    {
      "epoch": 7.088824600878603,
      "grad_norm": 9.517821308691055e-05,
      "learning_rate": 1.0548233865495196e-05,
      "loss": 0.0005,
      "step": 66160
    },
    {
      "epoch": 7.089896067716704,
      "grad_norm": 0.013406257145106792,
      "learning_rate": 1.0546805243044396e-05,
      "loss": 0.0001,
      "step": 66170
    },
    {
      "epoch": 7.090967534554806,
      "grad_norm": 18.660484313964844,
      "learning_rate": 1.0545376620593593e-05,
      "loss": 0.348,
      "step": 66180
    },
    {
      "epoch": 7.092039001392907,
      "grad_norm": 0.00015720052761025727,
      "learning_rate": 1.0543947998142791e-05,
      "loss": 0.2209,
      "step": 66190
    },
    {
      "epoch": 7.093110468231008,
      "grad_norm": 0.00011453749903012067,
      "learning_rate": 1.054251937569199e-05,
      "loss": 0.0005,
      "step": 66200
    },
    {
      "epoch": 7.09418193506911,
      "grad_norm": 0.0023441396187990904,
      "learning_rate": 1.0541090753241188e-05,
      "loss": 0.0003,
      "step": 66210
    },
    {
      "epoch": 7.095253401907211,
      "grad_norm": 0.0331212617456913,
      "learning_rate": 1.0539662130790387e-05,
      "loss": 0.0007,
      "step": 66220
    },
    {
      "epoch": 7.096324868745312,
      "grad_norm": 0.00013321175356395543,
      "learning_rate": 1.0538233508339583e-05,
      "loss": 0.0001,
      "step": 66230
    },
    {
      "epoch": 7.097396335583413,
      "grad_norm": 0.11837565153837204,
      "learning_rate": 1.0536804885888783e-05,
      "loss": 0.0004,
      "step": 66240
    },
    {
      "epoch": 7.098467802421515,
      "grad_norm": 0.07502571493387222,
      "learning_rate": 1.053537626343798e-05,
      "loss": 0.0058,
      "step": 66250
    },
    {
      "epoch": 7.099539269259616,
      "grad_norm": 0.0049344627186656,
      "learning_rate": 1.0533947640987178e-05,
      "loss": 0.0017,
      "step": 66260
    },
    {
      "epoch": 7.1006107360977175,
      "grad_norm": 0.00011195182014489546,
      "learning_rate": 1.0532519018536377e-05,
      "loss": 0.0002,
      "step": 66270
    },
    {
      "epoch": 7.1016822029358195,
      "grad_norm": 0.007871008478105068,
      "learning_rate": 1.0531090396085575e-05,
      "loss": 0.0001,
      "step": 66280
    },
    {
      "epoch": 7.102753669773921,
      "grad_norm": 0.006643278058618307,
      "learning_rate": 1.0529661773634774e-05,
      "loss": 0.0002,
      "step": 66290
    },
    {
      "epoch": 7.103825136612022,
      "grad_norm": 0.007625998463481665,
      "learning_rate": 1.052823315118397e-05,
      "loss": 0.0004,
      "step": 66300
    },
    {
      "epoch": 7.104896603450123,
      "grad_norm": 0.0005468748277053237,
      "learning_rate": 1.052680452873317e-05,
      "loss": 0.0003,
      "step": 66310
    },
    {
      "epoch": 7.105968070288225,
      "grad_norm": 0.000237534026382491,
      "learning_rate": 1.0525375906282369e-05,
      "loss": 0.0009,
      "step": 66320
    },
    {
      "epoch": 7.107039537126326,
      "grad_norm": 0.00041228579357266426,
      "learning_rate": 1.0523947283831565e-05,
      "loss": 0.0001,
      "step": 66330
    },
    {
      "epoch": 7.108111003964427,
      "grad_norm": 0.00023347236856352538,
      "learning_rate": 1.0522518661380764e-05,
      "loss": 0.1824,
      "step": 66340
    },
    {
      "epoch": 7.109182470802529,
      "grad_norm": 0.0002971059293486178,
      "learning_rate": 1.0521090038929962e-05,
      "loss": 0.0003,
      "step": 66350
    },
    {
      "epoch": 7.11025393764063,
      "grad_norm": 0.16353559494018555,
      "learning_rate": 1.0519661416479162e-05,
      "loss": 0.0002,
      "step": 66360
    },
    {
      "epoch": 7.111325404478731,
      "grad_norm": 0.07508255541324615,
      "learning_rate": 1.0518232794028357e-05,
      "loss": 0.0003,
      "step": 66370
    },
    {
      "epoch": 7.112396871316832,
      "grad_norm": 0.02640056423842907,
      "learning_rate": 1.0516804171577557e-05,
      "loss": 0.0002,
      "step": 66380
    },
    {
      "epoch": 7.113468338154934,
      "grad_norm": 0.08696850389242172,
      "learning_rate": 1.0515375549126756e-05,
      "loss": 0.0003,
      "step": 66390
    },
    {
      "epoch": 7.1145398049930355,
      "grad_norm": 0.010776049457490444,
      "learning_rate": 1.0513946926675954e-05,
      "loss": 0.0002,
      "step": 66400
    },
    {
      "epoch": 7.115611271831137,
      "grad_norm": 9.087472426472232e-05,
      "learning_rate": 1.0512518304225152e-05,
      "loss": 0.0001,
      "step": 66410
    },
    {
      "epoch": 7.116682738669239,
      "grad_norm": 0.000544378999620676,
      "learning_rate": 1.051108968177435e-05,
      "loss": 0.0006,
      "step": 66420
    },
    {
      "epoch": 7.11775420550734,
      "grad_norm": 0.00012985331704840064,
      "learning_rate": 1.0509661059323549e-05,
      "loss": 0.3277,
      "step": 66430
    },
    {
      "epoch": 7.118825672345441,
      "grad_norm": 32.239959716796875,
      "learning_rate": 1.0508232436872748e-05,
      "loss": 0.2256,
      "step": 66440
    },
    {
      "epoch": 7.119897139183542,
      "grad_norm": 2.6990129947662354,
      "learning_rate": 1.0506803814421944e-05,
      "loss": 0.0006,
      "step": 66450
    },
    {
      "epoch": 7.120968606021644,
      "grad_norm": 0.00010672258940758184,
      "learning_rate": 1.0505375191971143e-05,
      "loss": 0.2314,
      "step": 66460
    },
    {
      "epoch": 7.122040072859745,
      "grad_norm": 0.016549002379179,
      "learning_rate": 1.0503946569520341e-05,
      "loss": 0.1509,
      "step": 66470
    },
    {
      "epoch": 7.123111539697846,
      "grad_norm": 0.015474020503461361,
      "learning_rate": 1.0502517947069539e-05,
      "loss": 0.0003,
      "step": 66480
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 0.00013112799206282943,
      "learning_rate": 1.0501089324618736e-05,
      "loss": 0.0002,
      "step": 66490
    },
    {
      "epoch": 7.125254473374049,
      "grad_norm": 0.025041237473487854,
      "learning_rate": 1.0499660702167936e-05,
      "loss": 0.0004,
      "step": 66500
    },
    {
      "epoch": 7.12632594021215,
      "grad_norm": 0.00010471001587575302,
      "learning_rate": 1.0498232079717135e-05,
      "loss": 0.0007,
      "step": 66510
    },
    {
      "epoch": 7.1273974070502515,
      "grad_norm": 0.00018650600395631045,
      "learning_rate": 1.0496803457266331e-05,
      "loss": 0.1484,
      "step": 66520
    },
    {
      "epoch": 7.1284688738883535,
      "grad_norm": 0.00013541871157940477,
      "learning_rate": 1.049537483481553e-05,
      "loss": 0.0001,
      "step": 66530
    },
    {
      "epoch": 7.129540340726455,
      "grad_norm": 0.00010905967792496085,
      "learning_rate": 1.0493946212364728e-05,
      "loss": 0.0002,
      "step": 66540
    },
    {
      "epoch": 7.130611807564556,
      "grad_norm": 0.00017904958804138005,
      "learning_rate": 1.0492517589913926e-05,
      "loss": 0.0011,
      "step": 66550
    },
    {
      "epoch": 7.131683274402657,
      "grad_norm": 0.1748063862323761,
      "learning_rate": 1.0491088967463125e-05,
      "loss": 0.0006,
      "step": 66560
    },
    {
      "epoch": 7.132754741240759,
      "grad_norm": 0.01725110039114952,
      "learning_rate": 1.0489660345012323e-05,
      "loss": 0.0003,
      "step": 66570
    },
    {
      "epoch": 7.13382620807886,
      "grad_norm": 0.001356329768896103,
      "learning_rate": 1.0488231722561522e-05,
      "loss": 0.0003,
      "step": 66580
    },
    {
      "epoch": 7.134897674916961,
      "grad_norm": 9.337945812148973e-05,
      "learning_rate": 1.0486803100110718e-05,
      "loss": 0.0001,
      "step": 66590
    },
    {
      "epoch": 7.135969141755063,
      "grad_norm": 0.00013524394307751209,
      "learning_rate": 1.0485374477659918e-05,
      "loss": 0.3261,
      "step": 66600
    },
    {
      "epoch": 7.137040608593164,
      "grad_norm": 0.00015809512115083635,
      "learning_rate": 1.0483945855209115e-05,
      "loss": 0.0001,
      "step": 66610
    },
    {
      "epoch": 7.138112075431265,
      "grad_norm": 0.0012263668468222022,
      "learning_rate": 1.0482517232758313e-05,
      "loss": 0.0002,
      "step": 66620
    },
    {
      "epoch": 7.139183542269366,
      "grad_norm": 0.03172386437654495,
      "learning_rate": 1.0481088610307512e-05,
      "loss": 0.1452,
      "step": 66630
    },
    {
      "epoch": 7.140255009107468,
      "grad_norm": 0.00047063667443580925,
      "learning_rate": 1.047965998785671e-05,
      "loss": 0.0002,
      "step": 66640
    },
    {
      "epoch": 7.1413264759455695,
      "grad_norm": 0.018496206030249596,
      "learning_rate": 1.047823136540591e-05,
      "loss": 0.1681,
      "step": 66650
    },
    {
      "epoch": 7.142397942783671,
      "grad_norm": 0.011387082748115063,
      "learning_rate": 1.0476802742955105e-05,
      "loss": 0.0005,
      "step": 66660
    },
    {
      "epoch": 7.143469409621773,
      "grad_norm": 0.0003112971899099648,
      "learning_rate": 1.0475374120504305e-05,
      "loss": 0.0001,
      "step": 66670
    },
    {
      "epoch": 7.144540876459874,
      "grad_norm": 0.0002905480796471238,
      "learning_rate": 1.0473945498053504e-05,
      "loss": 0.004,
      "step": 66680
    },
    {
      "epoch": 7.145612343297975,
      "grad_norm": 0.008971390314400196,
      "learning_rate": 1.04725168756027e-05,
      "loss": 0.3006,
      "step": 66690
    },
    {
      "epoch": 7.146683810136076,
      "grad_norm": 0.00040755613008514047,
      "learning_rate": 1.04710882531519e-05,
      "loss": 0.0008,
      "step": 66700
    },
    {
      "epoch": 7.147755276974178,
      "grad_norm": 0.0003081593313254416,
      "learning_rate": 1.0469659630701097e-05,
      "loss": 0.0009,
      "step": 66710
    },
    {
      "epoch": 7.148826743812279,
      "grad_norm": 0.022339241579174995,
      "learning_rate": 1.0468231008250296e-05,
      "loss": 0.1994,
      "step": 66720
    },
    {
      "epoch": 7.14989821065038,
      "grad_norm": 0.0011747280368581414,
      "learning_rate": 1.0466802385799492e-05,
      "loss": 0.0007,
      "step": 66730
    },
    {
      "epoch": 7.150969677488482,
      "grad_norm": 0.0008710481924936175,
      "learning_rate": 1.0465373763348692e-05,
      "loss": 0.0001,
      "step": 66740
    },
    {
      "epoch": 7.152041144326583,
      "grad_norm": 0.0003236733318772167,
      "learning_rate": 1.0463945140897891e-05,
      "loss": 0.0001,
      "step": 66750
    },
    {
      "epoch": 7.153112611164684,
      "grad_norm": 0.00025680018006823957,
      "learning_rate": 1.0462516518447087e-05,
      "loss": 0.0006,
      "step": 66760
    },
    {
      "epoch": 7.154184078002785,
      "grad_norm": 0.0005995419342070818,
      "learning_rate": 1.0461087895996286e-05,
      "loss": 0.0008,
      "step": 66770
    },
    {
      "epoch": 7.155255544840887,
      "grad_norm": 0.0010677969548851252,
      "learning_rate": 1.0459659273545484e-05,
      "loss": 0.0003,
      "step": 66780
    },
    {
      "epoch": 7.1563270116789885,
      "grad_norm": 0.0002186166966566816,
      "learning_rate": 1.0458230651094683e-05,
      "loss": 0.0006,
      "step": 66790
    },
    {
      "epoch": 7.15739847851709,
      "grad_norm": 0.09544312953948975,
      "learning_rate": 1.0456802028643883e-05,
      "loss": 0.2894,
      "step": 66800
    },
    {
      "epoch": 7.158469945355192,
      "grad_norm": 0.0007116479682736099,
      "learning_rate": 1.0455373406193079e-05,
      "loss": 0.0001,
      "step": 66810
    },
    {
      "epoch": 7.159541412193293,
      "grad_norm": 0.0032806626986712217,
      "learning_rate": 1.0453944783742278e-05,
      "loss": 0.0004,
      "step": 66820
    },
    {
      "epoch": 7.160612879031394,
      "grad_norm": 0.02346549555659294,
      "learning_rate": 1.0452516161291474e-05,
      "loss": 0.0001,
      "step": 66830
    },
    {
      "epoch": 7.161684345869495,
      "grad_norm": 0.0017451295861974359,
      "learning_rate": 1.0451087538840674e-05,
      "loss": 0.0001,
      "step": 66840
    },
    {
      "epoch": 7.162755812707597,
      "grad_norm": 0.0002058821264654398,
      "learning_rate": 1.0449658916389871e-05,
      "loss": 0.1392,
      "step": 66850
    },
    {
      "epoch": 7.163827279545698,
      "grad_norm": 0.0014329920522868633,
      "learning_rate": 1.044823029393907e-05,
      "loss": 0.0,
      "step": 66860
    },
    {
      "epoch": 7.164898746383799,
      "grad_norm": 0.00021479667339008301,
      "learning_rate": 1.044680167148827e-05,
      "loss": 0.0002,
      "step": 66870
    },
    {
      "epoch": 7.165970213221901,
      "grad_norm": 0.00020077175577171147,
      "learning_rate": 1.0445373049037466e-05,
      "loss": 0.2191,
      "step": 66880
    },
    {
      "epoch": 7.167041680060002,
      "grad_norm": 0.000583353394176811,
      "learning_rate": 1.0443944426586665e-05,
      "loss": 0.0002,
      "step": 66890
    },
    {
      "epoch": 7.168113146898103,
      "grad_norm": 0.0003285145794507116,
      "learning_rate": 1.0442515804135861e-05,
      "loss": 0.0005,
      "step": 66900
    },
    {
      "epoch": 7.1691846137362045,
      "grad_norm": 0.009969989769160748,
      "learning_rate": 1.044108718168506e-05,
      "loss": 0.0005,
      "step": 66910
    },
    {
      "epoch": 7.1702560805743065,
      "grad_norm": 0.0001745991175994277,
      "learning_rate": 1.043965855923426e-05,
      "loss": 0.0005,
      "step": 66920
    },
    {
      "epoch": 7.171327547412408,
      "grad_norm": 0.032925594598054886,
      "learning_rate": 1.0438229936783458e-05,
      "loss": 0.2309,
      "step": 66930
    },
    {
      "epoch": 7.172399014250509,
      "grad_norm": 0.1410980373620987,
      "learning_rate": 1.0436801314332657e-05,
      "loss": 0.0005,
      "step": 66940
    },
    {
      "epoch": 7.173470481088611,
      "grad_norm": 0.00090599968098104,
      "learning_rate": 1.0435372691881853e-05,
      "loss": 0.0001,
      "step": 66950
    },
    {
      "epoch": 7.174541947926712,
      "grad_norm": 0.038703110069036484,
      "learning_rate": 1.0433944069431052e-05,
      "loss": 0.0003,
      "step": 66960
    },
    {
      "epoch": 7.175613414764813,
      "grad_norm": 142.71835327148438,
      "learning_rate": 1.043251544698025e-05,
      "loss": 0.3328,
      "step": 66970
    },
    {
      "epoch": 7.176684881602914,
      "grad_norm": 0.010929633863270283,
      "learning_rate": 1.0431086824529448e-05,
      "loss": 0.0004,
      "step": 66980
    },
    {
      "epoch": 7.177756348441016,
      "grad_norm": 0.005904914811253548,
      "learning_rate": 1.0429658202078647e-05,
      "loss": 0.0019,
      "step": 66990
    },
    {
      "epoch": 7.178827815279117,
      "grad_norm": 0.00015265621186699718,
      "learning_rate": 1.0428229579627845e-05,
      "loss": 0.0001,
      "step": 67000
    },
    {
      "epoch": 7.179899282117218,
      "grad_norm": 0.0005333627923391759,
      "learning_rate": 1.0426800957177044e-05,
      "loss": 0.2659,
      "step": 67010
    },
    {
      "epoch": 7.180970748955319,
      "grad_norm": 0.00036050373455509543,
      "learning_rate": 1.042537233472624e-05,
      "loss": 0.0008,
      "step": 67020
    },
    {
      "epoch": 7.182042215793421,
      "grad_norm": 0.004014898557215929,
      "learning_rate": 1.042394371227544e-05,
      "loss": 0.0001,
      "step": 67030
    },
    {
      "epoch": 7.1831136826315225,
      "grad_norm": 0.0001449611154384911,
      "learning_rate": 1.0422515089824639e-05,
      "loss": 0.2312,
      "step": 67040
    },
    {
      "epoch": 7.184185149469624,
      "grad_norm": 0.009885282255709171,
      "learning_rate": 1.0421086467373835e-05,
      "loss": 0.0002,
      "step": 67050
    },
    {
      "epoch": 7.185256616307726,
      "grad_norm": 0.0001462405052734539,
      "learning_rate": 1.0419657844923034e-05,
      "loss": 0.0005,
      "step": 67060
    },
    {
      "epoch": 7.186328083145827,
      "grad_norm": 7.719041605014354e-05,
      "learning_rate": 1.0418229222472232e-05,
      "loss": 0.0002,
      "step": 67070
    },
    {
      "epoch": 7.187399549983928,
      "grad_norm": 0.0003593361470848322,
      "learning_rate": 1.0416800600021431e-05,
      "loss": 0.0001,
      "step": 67080
    },
    {
      "epoch": 7.188471016822029,
      "grad_norm": 0.0003149652329739183,
      "learning_rate": 1.0415371977570627e-05,
      "loss": 0.0004,
      "step": 67090
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 0.0049351234920322895,
      "learning_rate": 1.0413943355119827e-05,
      "loss": 0.0009,
      "step": 67100
    },
    {
      "epoch": 7.190613950498232,
      "grad_norm": 0.0013794430997222662,
      "learning_rate": 1.0412514732669026e-05,
      "loss": 0.0003,
      "step": 67110
    },
    {
      "epoch": 7.191685417336333,
      "grad_norm": 0.002491200575605035,
      "learning_rate": 1.0411086110218222e-05,
      "loss": 0.0,
      "step": 67120
    },
    {
      "epoch": 7.192756884174435,
      "grad_norm": 45.68143081665039,
      "learning_rate": 1.0409657487767421e-05,
      "loss": 0.6115,
      "step": 67130
    },
    {
      "epoch": 7.193828351012536,
      "grad_norm": 0.0023403377272188663,
      "learning_rate": 1.0408228865316619e-05,
      "loss": 0.0002,
      "step": 67140
    },
    {
      "epoch": 7.194899817850637,
      "grad_norm": 0.0013315115356817842,
      "learning_rate": 1.0406800242865818e-05,
      "loss": 0.0002,
      "step": 67150
    },
    {
      "epoch": 7.1959712846887385,
      "grad_norm": 0.0035669796634465456,
      "learning_rate": 1.0405371620415014e-05,
      "loss": 0.0002,
      "step": 67160
    },
    {
      "epoch": 7.1970427515268405,
      "grad_norm": 0.0036591049283742905,
      "learning_rate": 1.0403942997964214e-05,
      "loss": 0.0005,
      "step": 67170
    },
    {
      "epoch": 7.198114218364942,
      "grad_norm": 0.0018504540203139186,
      "learning_rate": 1.0402514375513413e-05,
      "loss": 0.0001,
      "step": 67180
    },
    {
      "epoch": 7.199185685203043,
      "grad_norm": 0.0009274900075979531,
      "learning_rate": 1.0401085753062609e-05,
      "loss": 0.0001,
      "step": 67190
    },
    {
      "epoch": 7.200257152041145,
      "grad_norm": 0.0031137685291469097,
      "learning_rate": 1.0399657130611808e-05,
      "loss": 0.002,
      "step": 67200
    },
    {
      "epoch": 7.201328618879246,
      "grad_norm": 0.0026364659424871206,
      "learning_rate": 1.0398228508161006e-05,
      "loss": 0.0001,
      "step": 67210
    },
    {
      "epoch": 7.202400085717347,
      "grad_norm": 0.00941136572510004,
      "learning_rate": 1.0396799885710205e-05,
      "loss": 0.0001,
      "step": 67220
    },
    {
      "epoch": 7.203471552555448,
      "grad_norm": 0.0008326527895405889,
      "learning_rate": 1.0395371263259405e-05,
      "loss": 0.278,
      "step": 67230
    },
    {
      "epoch": 7.20454301939355,
      "grad_norm": 0.007354014087468386,
      "learning_rate": 1.03939426408086e-05,
      "loss": 0.0002,
      "step": 67240
    },
    {
      "epoch": 7.205614486231651,
      "grad_norm": 0.004167881794273853,
      "learning_rate": 1.03925140183578e-05,
      "loss": 0.0001,
      "step": 67250
    },
    {
      "epoch": 7.206685953069752,
      "grad_norm": 0.005460035055875778,
      "learning_rate": 1.0391085395906996e-05,
      "loss": 0.0001,
      "step": 67260
    },
    {
      "epoch": 7.207757419907854,
      "grad_norm": 0.026287047192454338,
      "learning_rate": 1.0389656773456195e-05,
      "loss": 0.0002,
      "step": 67270
    },
    {
      "epoch": 7.208828886745955,
      "grad_norm": 0.001995708327740431,
      "learning_rate": 1.0388228151005393e-05,
      "loss": 0.1461,
      "step": 67280
    },
    {
      "epoch": 7.2099003535840565,
      "grad_norm": 0.001738336170092225,
      "learning_rate": 1.0386799528554592e-05,
      "loss": 0.1511,
      "step": 67290
    },
    {
      "epoch": 7.210971820422158,
      "grad_norm": 0.0015038235578686,
      "learning_rate": 1.0385370906103792e-05,
      "loss": 0.0001,
      "step": 67300
    },
    {
      "epoch": 7.21204328726026,
      "grad_norm": 0.0018916081171482801,
      "learning_rate": 1.0383942283652988e-05,
      "loss": 0.0002,
      "step": 67310
    },
    {
      "epoch": 7.213114754098361,
      "grad_norm": 0.0354900099337101,
      "learning_rate": 1.0382513661202187e-05,
      "loss": 0.0002,
      "step": 67320
    },
    {
      "epoch": 7.214186220936462,
      "grad_norm": 0.0019391794921830297,
      "learning_rate": 1.0381085038751383e-05,
      "loss": 0.0001,
      "step": 67330
    },
    {
      "epoch": 7.215257687774564,
      "grad_norm": 0.14633367955684662,
      "learning_rate": 1.0379656416300583e-05,
      "loss": 0.1526,
      "step": 67340
    },
    {
      "epoch": 7.216329154612665,
      "grad_norm": 0.007330450229346752,
      "learning_rate": 1.0378227793849782e-05,
      "loss": 0.0001,
      "step": 67350
    },
    {
      "epoch": 7.217400621450766,
      "grad_norm": 0.003510626731440425,
      "learning_rate": 1.037679917139898e-05,
      "loss": 0.0001,
      "step": 67360
    },
    {
      "epoch": 7.218472088288867,
      "grad_norm": 0.006241969298571348,
      "learning_rate": 1.0375370548948179e-05,
      "loss": 0.0019,
      "step": 67370
    },
    {
      "epoch": 7.219543555126969,
      "grad_norm": 0.0015334691852331161,
      "learning_rate": 1.0373941926497375e-05,
      "loss": 0.0009,
      "step": 67380
    },
    {
      "epoch": 7.22061502196507,
      "grad_norm": 0.00046500255120918155,
      "learning_rate": 1.0372513304046574e-05,
      "loss": 0.0004,
      "step": 67390
    },
    {
      "epoch": 7.221686488803171,
      "grad_norm": 0.0029433260206133127,
      "learning_rate": 1.037108468159577e-05,
      "loss": 0.1613,
      "step": 67400
    },
    {
      "epoch": 7.222757955641273,
      "grad_norm": 0.006081456318497658,
      "learning_rate": 1.036965605914497e-05,
      "loss": 0.0001,
      "step": 67410
    },
    {
      "epoch": 7.223829422479374,
      "grad_norm": 0.0027489226777106524,
      "learning_rate": 1.0368227436694169e-05,
      "loss": 0.0002,
      "step": 67420
    },
    {
      "epoch": 7.2249008893174755,
      "grad_norm": 0.002135044662281871,
      "learning_rate": 1.0366798814243367e-05,
      "loss": 0.1609,
      "step": 67430
    },
    {
      "epoch": 7.225972356155577,
      "grad_norm": 0.0029694249387830496,
      "learning_rate": 1.0365370191792566e-05,
      "loss": 0.0,
      "step": 67440
    },
    {
      "epoch": 7.227043822993679,
      "grad_norm": 0.001687104580923915,
      "learning_rate": 1.0363941569341762e-05,
      "loss": 0.0001,
      "step": 67450
    },
    {
      "epoch": 7.22811528983178,
      "grad_norm": 0.004551789723336697,
      "learning_rate": 1.0362512946890961e-05,
      "loss": 0.001,
      "step": 67460
    },
    {
      "epoch": 7.229186756669881,
      "grad_norm": 0.003464814741164446,
      "learning_rate": 1.036108432444016e-05,
      "loss": 0.1458,
      "step": 67470
    },
    {
      "epoch": 7.230258223507983,
      "grad_norm": 0.001459693070501089,
      "learning_rate": 1.0359655701989357e-05,
      "loss": 0.0003,
      "step": 67480
    },
    {
      "epoch": 7.231329690346084,
      "grad_norm": 0.0038495822809636593,
      "learning_rate": 1.0358227079538556e-05,
      "loss": 0.1824,
      "step": 67490
    },
    {
      "epoch": 7.232401157184185,
      "grad_norm": 0.0014796201139688492,
      "learning_rate": 1.0356798457087754e-05,
      "loss": 0.3071,
      "step": 67500
    },
    {
      "epoch": 7.233472624022286,
      "grad_norm": 0.0007215688819997013,
      "learning_rate": 1.0355369834636953e-05,
      "loss": 0.0001,
      "step": 67510
    },
    {
      "epoch": 7.234544090860388,
      "grad_norm": 0.0002859302330762148,
      "learning_rate": 1.0353941212186149e-05,
      "loss": 0.0001,
      "step": 67520
    },
    {
      "epoch": 7.235615557698489,
      "grad_norm": 0.0011893085902556777,
      "learning_rate": 1.0352512589735348e-05,
      "loss": 0.0013,
      "step": 67530
    },
    {
      "epoch": 7.23668702453659,
      "grad_norm": 0.0009885670151561499,
      "learning_rate": 1.0351083967284548e-05,
      "loss": 0.0,
      "step": 67540
    },
    {
      "epoch": 7.2377584913746915,
      "grad_norm": 0.001324583776295185,
      "learning_rate": 1.0349655344833744e-05,
      "loss": 0.0,
      "step": 67550
    },
    {
      "epoch": 7.2388299582127935,
      "grad_norm": 0.020417768508195877,
      "learning_rate": 1.0348226722382943e-05,
      "loss": 0.0001,
      "step": 67560
    },
    {
      "epoch": 7.239901425050895,
      "grad_norm": 0.0030703770462423563,
      "learning_rate": 1.0346798099932141e-05,
      "loss": 0.0001,
      "step": 67570
    },
    {
      "epoch": 7.240972891888996,
      "grad_norm": 0.00744831096380949,
      "learning_rate": 1.034536947748134e-05,
      "loss": 0.0001,
      "step": 67580
    },
    {
      "epoch": 7.242044358727098,
      "grad_norm": 0.00017845550610218197,
      "learning_rate": 1.0343940855030538e-05,
      "loss": 0.0005,
      "step": 67590
    },
    {
      "epoch": 7.243115825565199,
      "grad_norm": 0.002259699394926429,
      "learning_rate": 1.0342512232579736e-05,
      "loss": 0.0,
      "step": 67600
    },
    {
      "epoch": 7.2441872924033,
      "grad_norm": 0.00026390477432869375,
      "learning_rate": 1.0341083610128935e-05,
      "loss": 0.0,
      "step": 67610
    },
    {
      "epoch": 7.245258759241401,
      "grad_norm": 0.001349710044451058,
      "learning_rate": 1.0339654987678131e-05,
      "loss": 0.2897,
      "step": 67620
    },
    {
      "epoch": 7.246330226079503,
      "grad_norm": 0.0011877295328304172,
      "learning_rate": 1.033822636522733e-05,
      "loss": 0.1504,
      "step": 67630
    },
    {
      "epoch": 7.247401692917604,
      "grad_norm": 0.0005503229913301766,
      "learning_rate": 1.0336797742776528e-05,
      "loss": 0.0074,
      "step": 67640
    },
    {
      "epoch": 7.248473159755705,
      "grad_norm": 0.02720804698765278,
      "learning_rate": 1.0335369120325727e-05,
      "loss": 0.0028,
      "step": 67650
    },
    {
      "epoch": 7.249544626593807,
      "grad_norm": 0.018009435385465622,
      "learning_rate": 1.0333940497874925e-05,
      "loss": 0.0001,
      "step": 67660
    },
    {
      "epoch": 7.250616093431908,
      "grad_norm": 0.00020505649445112795,
      "learning_rate": 1.0332511875424123e-05,
      "loss": 0.0,
      "step": 67670
    },
    {
      "epoch": 7.2516875602700095,
      "grad_norm": 0.0001538858632557094,
      "learning_rate": 1.0331083252973322e-05,
      "loss": 0.0028,
      "step": 67680
    },
    {
      "epoch": 7.252759027108111,
      "grad_norm": 0.00019749990315176547,
      "learning_rate": 1.0329654630522518e-05,
      "loss": 0.0001,
      "step": 67690
    },
    {
      "epoch": 7.253830493946213,
      "grad_norm": 0.00041537475772202015,
      "learning_rate": 1.0328226008071717e-05,
      "loss": 0.1253,
      "step": 67700
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.001287495018914342,
      "learning_rate": 1.0326797385620917e-05,
      "loss": 0.0001,
      "step": 67710
    },
    {
      "epoch": 7.255973427622415,
      "grad_norm": 0.0035385452210903168,
      "learning_rate": 1.0325368763170114e-05,
      "loss": 0.0005,
      "step": 67720
    },
    {
      "epoch": 7.257044894460517,
      "grad_norm": 0.0013160097878426313,
      "learning_rate": 1.0323940140719312e-05,
      "loss": 0.001,
      "step": 67730
    },
    {
      "epoch": 7.258116361298618,
      "grad_norm": 0.00015859853010624647,
      "learning_rate": 1.032251151826851e-05,
      "loss": 0.0,
      "step": 67740
    },
    {
      "epoch": 7.259187828136719,
      "grad_norm": 0.0003512096300255507,
      "learning_rate": 1.0321082895817709e-05,
      "loss": 0.2664,
      "step": 67750
    },
    {
      "epoch": 7.26025929497482,
      "grad_norm": 0.0015137955779209733,
      "learning_rate": 1.0319654273366905e-05,
      "loss": 0.001,
      "step": 67760
    },
    {
      "epoch": 7.261330761812922,
      "grad_norm": 0.0012596379965543747,
      "learning_rate": 1.0318225650916104e-05,
      "loss": 0.0002,
      "step": 67770
    },
    {
      "epoch": 7.262402228651023,
      "grad_norm": 0.000930103356949985,
      "learning_rate": 1.0316797028465304e-05,
      "loss": 0.1351,
      "step": 67780
    },
    {
      "epoch": 7.263473695489124,
      "grad_norm": 0.00017468153964728117,
      "learning_rate": 1.0315368406014502e-05,
      "loss": 0.0,
      "step": 67790
    },
    {
      "epoch": 7.264545162327226,
      "grad_norm": 0.0011284886859357357,
      "learning_rate": 1.0313939783563701e-05,
      "loss": 0.0001,
      "step": 67800
    },
    {
      "epoch": 7.2656166291653275,
      "grad_norm": 0.0003866446786560118,
      "learning_rate": 1.0312511161112897e-05,
      "loss": 0.0003,
      "step": 67810
    },
    {
      "epoch": 7.266688096003429,
      "grad_norm": 0.0002629639348015189,
      "learning_rate": 1.0311082538662096e-05,
      "loss": 0.1699,
      "step": 67820
    },
    {
      "epoch": 7.26775956284153,
      "grad_norm": 0.0012639315100386739,
      "learning_rate": 1.0309653916211296e-05,
      "loss": 0.0,
      "step": 67830
    },
    {
      "epoch": 7.268831029679632,
      "grad_norm": 0.00022252704366110265,
      "learning_rate": 1.0308225293760492e-05,
      "loss": 0.0001,
      "step": 67840
    },
    {
      "epoch": 7.269902496517733,
      "grad_norm": 0.0009885611943900585,
      "learning_rate": 1.0306796671309691e-05,
      "loss": 0.0001,
      "step": 67850
    },
    {
      "epoch": 7.270973963355834,
      "grad_norm": 0.000431518186815083,
      "learning_rate": 1.0305368048858889e-05,
      "loss": 0.0049,
      "step": 67860
    },
    {
      "epoch": 7.272045430193936,
      "grad_norm": 0.00020186470646876842,
      "learning_rate": 1.0303939426408088e-05,
      "loss": 0.0002,
      "step": 67870
    },
    {
      "epoch": 7.273116897032037,
      "grad_norm": 0.00016884169599507004,
      "learning_rate": 1.0302510803957284e-05,
      "loss": 0.1349,
      "step": 67880
    },
    {
      "epoch": 7.274188363870138,
      "grad_norm": 0.009911228902637959,
      "learning_rate": 1.0301082181506483e-05,
      "loss": 0.0959,
      "step": 67890
    },
    {
      "epoch": 7.275259830708239,
      "grad_norm": 0.009573138318955898,
      "learning_rate": 1.0299653559055683e-05,
      "loss": 0.1239,
      "step": 67900
    },
    {
      "epoch": 7.276331297546341,
      "grad_norm": 1.2571797370910645,
      "learning_rate": 1.0298224936604879e-05,
      "loss": 0.0026,
      "step": 67910
    },
    {
      "epoch": 7.277402764384442,
      "grad_norm": 0.001122095505706966,
      "learning_rate": 1.0296796314154078e-05,
      "loss": 0.0019,
      "step": 67920
    },
    {
      "epoch": 7.2784742312225434,
      "grad_norm": 8.048652671277523e-05,
      "learning_rate": 1.0295367691703276e-05,
      "loss": 0.0001,
      "step": 67930
    },
    {
      "epoch": 7.2795456980606446,
      "grad_norm": 0.001447978662326932,
      "learning_rate": 1.0293939069252475e-05,
      "loss": 0.2096,
      "step": 67940
    },
    {
      "epoch": 7.2806171648987466,
      "grad_norm": 0.0022705316077917814,
      "learning_rate": 1.0292510446801673e-05,
      "loss": 0.0,
      "step": 67950
    },
    {
      "epoch": 7.281688631736848,
      "grad_norm": 0.00018812058260664344,
      "learning_rate": 1.029108182435087e-05,
      "loss": 0.2451,
      "step": 67960
    },
    {
      "epoch": 7.282760098574949,
      "grad_norm": 0.007625528611242771,
      "learning_rate": 1.028965320190007e-05,
      "loss": 0.0,
      "step": 67970
    },
    {
      "epoch": 7.283831565413051,
      "grad_norm": 0.48369449377059937,
      "learning_rate": 1.0288224579449266e-05,
      "loss": 0.0005,
      "step": 67980
    },
    {
      "epoch": 7.284903032251152,
      "grad_norm": 0.0002579436113592237,
      "learning_rate": 1.0286795956998465e-05,
      "loss": 0.0002,
      "step": 67990
    },
    {
      "epoch": 7.285974499089253,
      "grad_norm": 0.0010260905837640166,
      "learning_rate": 1.0285367334547663e-05,
      "loss": 0.0002,
      "step": 68000
    },
    {
      "epoch": 7.287045965927355,
      "grad_norm": 0.32574230432510376,
      "learning_rate": 1.0283938712096862e-05,
      "loss": 0.0007,
      "step": 68010
    },
    {
      "epoch": 7.288117432765456,
      "grad_norm": 0.0001839883771026507,
      "learning_rate": 1.028251008964606e-05,
      "loss": 0.0008,
      "step": 68020
    },
    {
      "epoch": 7.289188899603557,
      "grad_norm": 0.001927350414916873,
      "learning_rate": 1.0281081467195258e-05,
      "loss": 0.1185,
      "step": 68030
    },
    {
      "epoch": 7.290260366441658,
      "grad_norm": 0.0011061497498303652,
      "learning_rate": 1.0279652844744457e-05,
      "loss": 0.0,
      "step": 68040
    },
    {
      "epoch": 7.29133183327976,
      "grad_norm": 0.0016179480589926243,
      "learning_rate": 1.0278224222293653e-05,
      "loss": 0.0001,
      "step": 68050
    },
    {
      "epoch": 7.292403300117861,
      "grad_norm": 0.000321391096804291,
      "learning_rate": 1.0276795599842852e-05,
      "loss": 0.0,
      "step": 68060
    },
    {
      "epoch": 7.2934747669559625,
      "grad_norm": 140.56997680664062,
      "learning_rate": 1.027536697739205e-05,
      "loss": 0.1083,
      "step": 68070
    },
    {
      "epoch": 7.294546233794064,
      "grad_norm": 0.0001275351387448609,
      "learning_rate": 1.027393835494125e-05,
      "loss": 0.0,
      "step": 68080
    },
    {
      "epoch": 7.295617700632166,
      "grad_norm": 0.001854244968853891,
      "learning_rate": 1.0272509732490447e-05,
      "loss": 0.0003,
      "step": 68090
    },
    {
      "epoch": 7.296689167470267,
      "grad_norm": 0.00039878831012174487,
      "learning_rate": 1.0271081110039645e-05,
      "loss": 0.0,
      "step": 68100
    },
    {
      "epoch": 7.297760634308368,
      "grad_norm": 0.0014019664376974106,
      "learning_rate": 1.0269652487588844e-05,
      "loss": 0.0,
      "step": 68110
    },
    {
      "epoch": 7.29883210114647,
      "grad_norm": 0.0016209862660616636,
      "learning_rate": 1.026822386513804e-05,
      "loss": 0.0,
      "step": 68120
    },
    {
      "epoch": 7.299903567984571,
      "grad_norm": 0.014171740040183067,
      "learning_rate": 1.026679524268724e-05,
      "loss": 0.0,
      "step": 68130
    },
    {
      "epoch": 7.300975034822672,
      "grad_norm": 7.860196637921035e-05,
      "learning_rate": 1.0265366620236439e-05,
      "loss": 0.2924,
      "step": 68140
    },
    {
      "epoch": 7.302046501660774,
      "grad_norm": 0.0013067557010799646,
      "learning_rate": 1.0263937997785636e-05,
      "loss": 0.0,
      "step": 68150
    },
    {
      "epoch": 7.303117968498875,
      "grad_norm": 0.0017485851421952248,
      "learning_rate": 1.0262509375334834e-05,
      "loss": 0.1631,
      "step": 68160
    },
    {
      "epoch": 7.304189435336976,
      "grad_norm": 0.00031602810486219823,
      "learning_rate": 1.0261080752884032e-05,
      "loss": 0.2303,
      "step": 68170
    },
    {
      "epoch": 7.305260902175077,
      "grad_norm": 0.0012060879962518811,
      "learning_rate": 1.0259652130433231e-05,
      "loss": 0.0015,
      "step": 68180
    },
    {
      "epoch": 7.306332369013179,
      "grad_norm": 0.00016873628192115575,
      "learning_rate": 1.0258223507982427e-05,
      "loss": 0.0,
      "step": 68190
    },
    {
      "epoch": 7.3074038358512805,
      "grad_norm": 0.0009607307147234678,
      "learning_rate": 1.0256794885531626e-05,
      "loss": 0.0001,
      "step": 68200
    },
    {
      "epoch": 7.308475302689382,
      "grad_norm": 0.0007757809362374246,
      "learning_rate": 1.0255366263080826e-05,
      "loss": 0.0,
      "step": 68210
    },
    {
      "epoch": 7.309546769527483,
      "grad_norm": 0.01345277950167656,
      "learning_rate": 1.0253937640630023e-05,
      "loss": 0.0001,
      "step": 68220
    },
    {
      "epoch": 7.310618236365585,
      "grad_norm": 0.0008685866487212479,
      "learning_rate": 1.0252509018179221e-05,
      "loss": 0.0001,
      "step": 68230
    },
    {
      "epoch": 7.311689703203686,
      "grad_norm": 0.0012057791464030743,
      "learning_rate": 1.0251080395728419e-05,
      "loss": 0.0,
      "step": 68240
    },
    {
      "epoch": 7.312761170041787,
      "grad_norm": 0.00020640026195906103,
      "learning_rate": 1.0249651773277618e-05,
      "loss": 0.0001,
      "step": 68250
    },
    {
      "epoch": 7.313832636879889,
      "grad_norm": 9.709700680105016e-05,
      "learning_rate": 1.0248223150826818e-05,
      "loss": 0.0,
      "step": 68260
    },
    {
      "epoch": 7.31490410371799,
      "grad_norm": 0.000148928738781251,
      "learning_rate": 1.0246794528376014e-05,
      "loss": 0.1789,
      "step": 68270
    },
    {
      "epoch": 7.315975570556091,
      "grad_norm": 0.0012005901662632823,
      "learning_rate": 1.0245365905925213e-05,
      "loss": 0.2181,
      "step": 68280
    },
    {
      "epoch": 7.317047037394192,
      "grad_norm": 0.008739832788705826,
      "learning_rate": 1.024393728347441e-05,
      "loss": 0.0001,
      "step": 68290
    },
    {
      "epoch": 7.318118504232294,
      "grad_norm": 0.008288213051855564,
      "learning_rate": 1.0242508661023608e-05,
      "loss": 0.122,
      "step": 68300
    },
    {
      "epoch": 7.319189971070395,
      "grad_norm": 0.0009082729229703546,
      "learning_rate": 1.0241080038572806e-05,
      "loss": 0.0001,
      "step": 68310
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 0.0009131459519267082,
      "learning_rate": 1.0239651416122005e-05,
      "loss": 0.0025,
      "step": 68320
    },
    {
      "epoch": 7.3213329047465985,
      "grad_norm": 0.00017052143812179565,
      "learning_rate": 1.0238222793671205e-05,
      "loss": 0.0002,
      "step": 68330
    },
    {
      "epoch": 7.3224043715847,
      "grad_norm": 0.002014850964769721,
      "learning_rate": 1.02367941712204e-05,
      "loss": 0.0,
      "step": 68340
    },
    {
      "epoch": 7.323475838422801,
      "grad_norm": 0.0006068852380849421,
      "learning_rate": 1.02353655487696e-05,
      "loss": 0.0,
      "step": 68350
    },
    {
      "epoch": 7.324547305260902,
      "grad_norm": 1.1816520690917969,
      "learning_rate": 1.0233936926318798e-05,
      "loss": 0.0004,
      "step": 68360
    },
    {
      "epoch": 7.325618772099004,
      "grad_norm": 0.0004988584551028907,
      "learning_rate": 1.0232508303867997e-05,
      "loss": 0.5319,
      "step": 68370
    },
    {
      "epoch": 7.326690238937105,
      "grad_norm": 0.0001634808286326006,
      "learning_rate": 1.0231079681417195e-05,
      "loss": 0.0006,
      "step": 68380
    },
    {
      "epoch": 7.327761705775206,
      "grad_norm": 0.05468103289604187,
      "learning_rate": 1.0229651058966392e-05,
      "loss": 0.0001,
      "step": 68390
    },
    {
      "epoch": 7.328833172613308,
      "grad_norm": 0.0022205249406397343,
      "learning_rate": 1.0228222436515592e-05,
      "loss": 0.0,
      "step": 68400
    },
    {
      "epoch": 7.329904639451409,
      "grad_norm": 0.00011678900773404166,
      "learning_rate": 1.0226793814064788e-05,
      "loss": 0.0,
      "step": 68410
    },
    {
      "epoch": 7.33097610628951,
      "grad_norm": 0.0001107632415369153,
      "learning_rate": 1.0225365191613987e-05,
      "loss": 0.0001,
      "step": 68420
    },
    {
      "epoch": 7.332047573127611,
      "grad_norm": 0.00015801408153492957,
      "learning_rate": 1.0223936569163185e-05,
      "loss": 0.2187,
      "step": 68430
    },
    {
      "epoch": 7.333119039965713,
      "grad_norm": 0.00015645098756067455,
      "learning_rate": 1.0222507946712384e-05,
      "loss": 0.0,
      "step": 68440
    },
    {
      "epoch": 7.3341905068038145,
      "grad_norm": 0.0032563521526753902,
      "learning_rate": 1.0221079324261582e-05,
      "loss": 0.0014,
      "step": 68450
    },
    {
      "epoch": 7.335261973641916,
      "grad_norm": 0.002324902219697833,
      "learning_rate": 1.021965070181078e-05,
      "loss": 0.001,
      "step": 68460
    },
    {
      "epoch": 7.336333440480017,
      "grad_norm": 0.0022125171963125467,
      "learning_rate": 1.0218222079359979e-05,
      "loss": 0.0,
      "step": 68470
    },
    {
      "epoch": 7.337404907318119,
      "grad_norm": 0.0032585388980805874,
      "learning_rate": 1.0216793456909175e-05,
      "loss": 0.4421,
      "step": 68480
    },
    {
      "epoch": 7.33847637415622,
      "grad_norm": 0.00014396055485121906,
      "learning_rate": 1.0215364834458374e-05,
      "loss": 0.0001,
      "step": 68490
    },
    {
      "epoch": 7.339547840994321,
      "grad_norm": 0.04365209862589836,
      "learning_rate": 1.0213936212007574e-05,
      "loss": 0.1746,
      "step": 68500
    },
    {
      "epoch": 7.340619307832423,
      "grad_norm": 39.20225143432617,
      "learning_rate": 1.0212507589556771e-05,
      "loss": 0.2233,
      "step": 68510
    },
    {
      "epoch": 7.341690774670524,
      "grad_norm": 0.0013439522590488195,
      "learning_rate": 1.0211078967105969e-05,
      "loss": 0.0011,
      "step": 68520
    },
    {
      "epoch": 7.342762241508625,
      "grad_norm": 0.07543221861124039,
      "learning_rate": 1.0209650344655167e-05,
      "loss": 0.0004,
      "step": 68530
    },
    {
      "epoch": 7.343833708346727,
      "grad_norm": 0.004971199668943882,
      "learning_rate": 1.0208221722204366e-05,
      "loss": 0.0001,
      "step": 68540
    },
    {
      "epoch": 7.344905175184828,
      "grad_norm": 0.009462065063416958,
      "learning_rate": 1.0206793099753562e-05,
      "loss": 0.0001,
      "step": 68550
    },
    {
      "epoch": 7.345976642022929,
      "grad_norm": 0.00023873220197856426,
      "learning_rate": 1.0205364477302761e-05,
      "loss": 0.0001,
      "step": 68560
    },
    {
      "epoch": 7.34704810886103,
      "grad_norm": 0.2531794309616089,
      "learning_rate": 1.020393585485196e-05,
      "loss": 0.1752,
      "step": 68570
    },
    {
      "epoch": 7.348119575699132,
      "grad_norm": 0.2794311046600342,
      "learning_rate": 1.0202507232401158e-05,
      "loss": 0.0006,
      "step": 68580
    },
    {
      "epoch": 7.3491910425372335,
      "grad_norm": 0.0005867865984328091,
      "learning_rate": 1.0201078609950356e-05,
      "loss": 0.0006,
      "step": 68590
    },
    {
      "epoch": 7.350262509375335,
      "grad_norm": 0.005314640235155821,
      "learning_rate": 1.0199649987499554e-05,
      "loss": 0.0001,
      "step": 68600
    },
    {
      "epoch": 7.351333976213436,
      "grad_norm": 0.0001716204424155876,
      "learning_rate": 1.0198221365048753e-05,
      "loss": 0.0004,
      "step": 68610
    },
    {
      "epoch": 7.352405443051538,
      "grad_norm": 0.002005077200010419,
      "learning_rate": 1.0196792742597952e-05,
      "loss": 0.0003,
      "step": 68620
    },
    {
      "epoch": 7.353476909889639,
      "grad_norm": 0.04437407851219177,
      "learning_rate": 1.0195364120147148e-05,
      "loss": 0.0001,
      "step": 68630
    },
    {
      "epoch": 7.35454837672774,
      "grad_norm": 0.0001246607134817168,
      "learning_rate": 1.0193935497696348e-05,
      "loss": 0.0992,
      "step": 68640
    },
    {
      "epoch": 7.355619843565842,
      "grad_norm": 0.00012037995475111529,
      "learning_rate": 1.0192506875245545e-05,
      "loss": 0.0,
      "step": 68650
    },
    {
      "epoch": 7.356691310403943,
      "grad_norm": 0.004298933781683445,
      "learning_rate": 1.0191078252794743e-05,
      "loss": 0.0002,
      "step": 68660
    },
    {
      "epoch": 7.357762777242044,
      "grad_norm": 0.00017792863945942372,
      "learning_rate": 1.018964963034394e-05,
      "loss": 0.0,
      "step": 68670
    },
    {
      "epoch": 7.358834244080145,
      "grad_norm": 0.0033708654809743166,
      "learning_rate": 1.018822100789314e-05,
      "loss": 0.0001,
      "step": 68680
    },
    {
      "epoch": 7.359905710918247,
      "grad_norm": 0.00013395289715845138,
      "learning_rate": 1.018679238544234e-05,
      "loss": 0.0001,
      "step": 68690
    },
    {
      "epoch": 7.360977177756348,
      "grad_norm": 0.0008829120779410005,
      "learning_rate": 1.0185363762991535e-05,
      "loss": 0.0001,
      "step": 68700
    },
    {
      "epoch": 7.3620486445944495,
      "grad_norm": 0.016889961436390877,
      "learning_rate": 1.0183935140540735e-05,
      "loss": 0.0002,
      "step": 68710
    },
    {
      "epoch": 7.3631201114325515,
      "grad_norm": 0.0028019831515848637,
      "learning_rate": 1.0182506518089933e-05,
      "loss": 0.2954,
      "step": 68720
    },
    {
      "epoch": 7.364191578270653,
      "grad_norm": 0.009556815028190613,
      "learning_rate": 1.018107789563913e-05,
      "loss": 0.0001,
      "step": 68730
    },
    {
      "epoch": 7.365263045108754,
      "grad_norm": 0.0021272916346788406,
      "learning_rate": 1.017964927318833e-05,
      "loss": 0.0001,
      "step": 68740
    },
    {
      "epoch": 7.366334511946855,
      "grad_norm": 0.0004089688591193408,
      "learning_rate": 1.0178220650737527e-05,
      "loss": 0.2461,
      "step": 68750
    },
    {
      "epoch": 7.367405978784957,
      "grad_norm": 0.0012455880641937256,
      "learning_rate": 1.0176792028286727e-05,
      "loss": 0.0229,
      "step": 68760
    },
    {
      "epoch": 7.368477445623058,
      "grad_norm": 9.088077786145732e-05,
      "learning_rate": 1.0175363405835923e-05,
      "loss": 0.0,
      "step": 68770
    },
    {
      "epoch": 7.369548912461159,
      "grad_norm": 0.00034314492950215936,
      "learning_rate": 1.0173934783385122e-05,
      "loss": 0.1102,
      "step": 68780
    },
    {
      "epoch": 7.370620379299261,
      "grad_norm": 16.642742156982422,
      "learning_rate": 1.017250616093432e-05,
      "loss": 0.0975,
      "step": 68790
    },
    {
      "epoch": 7.371691846137362,
      "grad_norm": 6.219896022230387e-05,
      "learning_rate": 1.0171077538483517e-05,
      "loss": 0.0,
      "step": 68800
    },
    {
      "epoch": 7.372763312975463,
      "grad_norm": 0.00010894463048316538,
      "learning_rate": 1.0169648916032717e-05,
      "loss": 0.0002,
      "step": 68810
    },
    {
      "epoch": 7.373834779813564,
      "grad_norm": 0.0002303168730577454,
      "learning_rate": 1.0168220293581914e-05,
      "loss": 0.0004,
      "step": 68820
    },
    {
      "epoch": 7.374906246651666,
      "grad_norm": 0.004959458485245705,
      "learning_rate": 1.0166791671131114e-05,
      "loss": 0.0001,
      "step": 68830
    },
    {
      "epoch": 7.3759777134897675,
      "grad_norm": 17.144866943359375,
      "learning_rate": 1.016536304868031e-05,
      "loss": 0.3155,
      "step": 68840
    },
    {
      "epoch": 7.377049180327869,
      "grad_norm": 0.00011967596219619736,
      "learning_rate": 1.0163934426229509e-05,
      "loss": 0.0007,
      "step": 68850
    },
    {
      "epoch": 7.378120647165971,
      "grad_norm": 0.0009173774742521346,
      "learning_rate": 1.0162505803778708e-05,
      "loss": 0.1422,
      "step": 68860
    },
    {
      "epoch": 7.379192114004072,
      "grad_norm": 0.00011034588533220813,
      "learning_rate": 1.0161077181327904e-05,
      "loss": 0.0,
      "step": 68870
    },
    {
      "epoch": 7.380263580842173,
      "grad_norm": 7.538665522588417e-05,
      "learning_rate": 1.0159648558877104e-05,
      "loss": 0.1033,
      "step": 68880
    },
    {
      "epoch": 7.381335047680274,
      "grad_norm": 9.67828236753121e-05,
      "learning_rate": 1.0158219936426301e-05,
      "loss": 0.0001,
      "step": 68890
    },
    {
      "epoch": 7.382406514518376,
      "grad_norm": 0.003562042722478509,
      "learning_rate": 1.01567913139755e-05,
      "loss": 0.0007,
      "step": 68900
    },
    {
      "epoch": 7.383477981356477,
      "grad_norm": 0.00023382346262224019,
      "learning_rate": 1.0155362691524697e-05,
      "loss": 0.0785,
      "step": 68910
    },
    {
      "epoch": 7.384549448194578,
      "grad_norm": 0.0014587873592972755,
      "learning_rate": 1.0153934069073896e-05,
      "loss": 0.0001,
      "step": 68920
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 0.002200805116444826,
      "learning_rate": 1.0152505446623095e-05,
      "loss": 0.0005,
      "step": 68930
    },
    {
      "epoch": 7.386692381870781,
      "grad_norm": 0.002391934162005782,
      "learning_rate": 1.0151076824172293e-05,
      "loss": 0.0001,
      "step": 68940
    },
    {
      "epoch": 7.387763848708882,
      "grad_norm": 0.011969631537795067,
      "learning_rate": 1.014964820172149e-05,
      "loss": 0.0003,
      "step": 68950
    },
    {
      "epoch": 7.3888353155469835,
      "grad_norm": 0.0001559311494929716,
      "learning_rate": 1.0148219579270689e-05,
      "loss": 0.0,
      "step": 68960
    },
    {
      "epoch": 7.3899067823850855,
      "grad_norm": 6.94826157996431e-05,
      "learning_rate": 1.0146790956819888e-05,
      "loss": 0.0001,
      "step": 68970
    },
    {
      "epoch": 7.390978249223187,
      "grad_norm": 0.0014725782675668597,
      "learning_rate": 1.0145362334369084e-05,
      "loss": 0.0001,
      "step": 68980
    },
    {
      "epoch": 7.392049716061288,
      "grad_norm": 0.0014636708656325936,
      "learning_rate": 1.0143933711918283e-05,
      "loss": 0.0001,
      "step": 68990
    },
    {
      "epoch": 7.393121182899389,
      "grad_norm": 0.00252789119258523,
      "learning_rate": 1.0142505089467483e-05,
      "loss": 0.0,
      "step": 69000
    },
    {
      "epoch": 7.394192649737491,
      "grad_norm": 0.0010862479684874415,
      "learning_rate": 1.014107646701668e-05,
      "loss": 0.0,
      "step": 69010
    },
    {
      "epoch": 7.395264116575592,
      "grad_norm": 0.0013768697390332818,
      "learning_rate": 1.0139647844565878e-05,
      "loss": 0.0003,
      "step": 69020
    },
    {
      "epoch": 7.396335583413693,
      "grad_norm": 0.0006756347720511258,
      "learning_rate": 1.0138219222115076e-05,
      "loss": 0.0001,
      "step": 69030
    },
    {
      "epoch": 7.397407050251795,
      "grad_norm": 0.05138586834073067,
      "learning_rate": 1.0136790599664275e-05,
      "loss": 0.0007,
      "step": 69040
    },
    {
      "epoch": 7.398478517089896,
      "grad_norm": 0.12289156019687653,
      "learning_rate": 1.0135361977213474e-05,
      "loss": 0.0001,
      "step": 69050
    },
    {
      "epoch": 7.399549983927997,
      "grad_norm": 0.002529674209654331,
      "learning_rate": 1.013393335476267e-05,
      "loss": 0.0,
      "step": 69060
    },
    {
      "epoch": 7.400621450766099,
      "grad_norm": 0.20943626761436462,
      "learning_rate": 1.013250473231187e-05,
      "loss": 0.0002,
      "step": 69070
    },
    {
      "epoch": 7.4016929176042,
      "grad_norm": 0.0028935219161212444,
      "learning_rate": 1.0131076109861067e-05,
      "loss": 0.0005,
      "step": 69080
    },
    {
      "epoch": 7.4027643844423014,
      "grad_norm": 5.950480772298761e-05,
      "learning_rate": 1.0129647487410265e-05,
      "loss": 0.5696,
      "step": 69090
    },
    {
      "epoch": 7.403835851280403,
      "grad_norm": 7.958619244163856e-05,
      "learning_rate": 1.0128218864959463e-05,
      "loss": 0.1936,
      "step": 69100
    },
    {
      "epoch": 7.4049073181185046,
      "grad_norm": 6.408520130207762e-05,
      "learning_rate": 1.0126790242508662e-05,
      "loss": 0.2013,
      "step": 69110
    },
    {
      "epoch": 7.405978784956606,
      "grad_norm": 7.213597564259544e-05,
      "learning_rate": 1.0125361620057861e-05,
      "loss": 0.0006,
      "step": 69120
    },
    {
      "epoch": 7.407050251794707,
      "grad_norm": 17.369770050048828,
      "learning_rate": 1.0123932997607057e-05,
      "loss": 0.4387,
      "step": 69130
    },
    {
      "epoch": 7.408121718632808,
      "grad_norm": 0.0046850163489580154,
      "learning_rate": 1.0122504375156257e-05,
      "loss": 0.0002,
      "step": 69140
    },
    {
      "epoch": 7.40919318547091,
      "grad_norm": 0.0034591348376125097,
      "learning_rate": 1.0121075752705454e-05,
      "loss": 0.0034,
      "step": 69150
    },
    {
      "epoch": 7.410264652309011,
      "grad_norm": 0.00016490546113345772,
      "learning_rate": 1.0119647130254652e-05,
      "loss": 0.0016,
      "step": 69160
    },
    {
      "epoch": 7.411336119147112,
      "grad_norm": 0.00016441747720818967,
      "learning_rate": 1.0118218507803851e-05,
      "loss": 0.1345,
      "step": 69170
    },
    {
      "epoch": 7.412407585985214,
      "grad_norm": 0.061514437198638916,
      "learning_rate": 1.011678988535305e-05,
      "loss": 0.0003,
      "step": 69180
    },
    {
      "epoch": 7.413479052823315,
      "grad_norm": 0.0001936445478349924,
      "learning_rate": 1.0115361262902249e-05,
      "loss": 0.4037,
      "step": 69190
    },
    {
      "epoch": 7.414550519661416,
      "grad_norm": 0.000903579406440258,
      "learning_rate": 1.0113932640451445e-05,
      "loss": 0.1083,
      "step": 69200
    },
    {
      "epoch": 7.415621986499517,
      "grad_norm": 0.0008654848206788301,
      "learning_rate": 1.0112504018000644e-05,
      "loss": 0.0002,
      "step": 69210
    },
    {
      "epoch": 7.416693453337619,
      "grad_norm": 0.0014790019486099482,
      "learning_rate": 1.0111075395549842e-05,
      "loss": 0.1925,
      "step": 69220
    },
    {
      "epoch": 7.4177649201757205,
      "grad_norm": 0.007810112088918686,
      "learning_rate": 1.010964677309904e-05,
      "loss": 0.0002,
      "step": 69230
    },
    {
      "epoch": 7.418836387013822,
      "grad_norm": 0.007784352172166109,
      "learning_rate": 1.0108218150648239e-05,
      "loss": 0.1116,
      "step": 69240
    },
    {
      "epoch": 7.419907853851924,
      "grad_norm": 0.031561773270368576,
      "learning_rate": 1.0106789528197436e-05,
      "loss": 0.0001,
      "step": 69250
    },
    {
      "epoch": 7.420979320690025,
      "grad_norm": 0.011310930363833904,
      "learning_rate": 1.0105360905746636e-05,
      "loss": 0.2091,
      "step": 69260
    },
    {
      "epoch": 7.422050787528126,
      "grad_norm": 0.001554624061100185,
      "learning_rate": 1.0103932283295832e-05,
      "loss": 0.0003,
      "step": 69270
    },
    {
      "epoch": 7.423122254366227,
      "grad_norm": 18.77044105529785,
      "learning_rate": 1.0102503660845031e-05,
      "loss": 0.183,
      "step": 69280
    },
    {
      "epoch": 7.424193721204329,
      "grad_norm": 0.0021459825802594423,
      "learning_rate": 1.010107503839423e-05,
      "loss": 0.0001,
      "step": 69290
    },
    {
      "epoch": 7.42526518804243,
      "grad_norm": 0.0010326384799554944,
      "learning_rate": 1.0099646415943426e-05,
      "loss": 0.0,
      "step": 69300
    },
    {
      "epoch": 7.426336654880531,
      "grad_norm": 0.0008340398781001568,
      "learning_rate": 1.0098217793492626e-05,
      "loss": 0.0862,
      "step": 69310
    },
    {
      "epoch": 7.427408121718633,
      "grad_norm": 0.0017576598329469562,
      "learning_rate": 1.0096789171041823e-05,
      "loss": 0.1389,
      "step": 69320
    },
    {
      "epoch": 7.428479588556734,
      "grad_norm": 0.0007295427494682372,
      "learning_rate": 1.0095360548591023e-05,
      "loss": 0.0002,
      "step": 69330
    },
    {
      "epoch": 7.429551055394835,
      "grad_norm": 0.06681611388921738,
      "learning_rate": 1.0093931926140219e-05,
      "loss": 0.0909,
      "step": 69340
    },
    {
      "epoch": 7.4306225222329365,
      "grad_norm": 0.03963096812367439,
      "learning_rate": 1.0092503303689418e-05,
      "loss": 0.0011,
      "step": 69350
    },
    {
      "epoch": 7.4316939890710385,
      "grad_norm": 0.011507917195558548,
      "learning_rate": 1.0091074681238617e-05,
      "loss": 0.174,
      "step": 69360
    },
    {
      "epoch": 7.43276545590914,
      "grad_norm": 0.0007871371344663203,
      "learning_rate": 1.0089646058787813e-05,
      "loss": 0.0004,
      "step": 69370
    },
    {
      "epoch": 7.433836922747241,
      "grad_norm": 0.0012230974389240146,
      "learning_rate": 1.0088217436337013e-05,
      "loss": 0.0004,
      "step": 69380
    },
    {
      "epoch": 7.434908389585343,
      "grad_norm": 0.0007272046059370041,
      "learning_rate": 1.008678881388621e-05,
      "loss": 0.0745,
      "step": 69390
    },
    {
      "epoch": 7.435979856423444,
      "grad_norm": 0.0006173045258037746,
      "learning_rate": 1.008536019143541e-05,
      "loss": 0.0001,
      "step": 69400
    },
    {
      "epoch": 7.437051323261545,
      "grad_norm": 0.012819744646549225,
      "learning_rate": 1.008393156898461e-05,
      "loss": 0.0001,
      "step": 69410
    },
    {
      "epoch": 7.438122790099646,
      "grad_norm": 0.0728757455945015,
      "learning_rate": 1.0082502946533805e-05,
      "loss": 0.092,
      "step": 69420
    },
    {
      "epoch": 7.439194256937748,
      "grad_norm": 0.05816761776804924,
      "learning_rate": 1.0081074324083005e-05,
      "loss": 0.0002,
      "step": 69430
    },
    {
      "epoch": 7.440265723775849,
      "grad_norm": 0.0063881282694637775,
      "learning_rate": 1.00796457016322e-05,
      "loss": 0.0012,
      "step": 69440
    },
    {
      "epoch": 7.44133719061395,
      "grad_norm": 0.00039755675243213773,
      "learning_rate": 1.00782170791814e-05,
      "loss": 0.0003,
      "step": 69450
    },
    {
      "epoch": 7.442408657452052,
      "grad_norm": 0.00045549668720923364,
      "learning_rate": 1.0076788456730598e-05,
      "loss": 0.1811,
      "step": 69460
    },
    {
      "epoch": 7.443480124290153,
      "grad_norm": 0.000609276641625911,
      "learning_rate": 1.0075359834279797e-05,
      "loss": 0.0051,
      "step": 69470
    },
    {
      "epoch": 7.4445515911282545,
      "grad_norm": 0.001264292630366981,
      "learning_rate": 1.0073931211828996e-05,
      "loss": 0.0001,
      "step": 69480
    },
    {
      "epoch": 7.445623057966356,
      "grad_norm": 0.009613340720534325,
      "learning_rate": 1.0072502589378192e-05,
      "loss": 0.0759,
      "step": 69490
    },
    {
      "epoch": 7.446694524804458,
      "grad_norm": 0.004511368926614523,
      "learning_rate": 1.0071073966927392e-05,
      "loss": 0.0953,
      "step": 69500
    },
    {
      "epoch": 7.447765991642559,
      "grad_norm": 0.002345692366361618,
      "learning_rate": 1.006964534447659e-05,
      "loss": 0.0001,
      "step": 69510
    },
    {
      "epoch": 7.44883745848066,
      "grad_norm": 17.921491622924805,
      "learning_rate": 1.0068216722025787e-05,
      "loss": 0.4767,
      "step": 69520
    },
    {
      "epoch": 7.449908925318761,
      "grad_norm": 0.0008245262433774769,
      "learning_rate": 1.0066788099574986e-05,
      "loss": 0.0001,
      "step": 69530
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 0.004473485518246889,
      "learning_rate": 1.0065359477124184e-05,
      "loss": 0.0002,
      "step": 69540
    },
    {
      "epoch": 7.452051858994964,
      "grad_norm": 0.026927165687084198,
      "learning_rate": 1.0063930854673383e-05,
      "loss": 0.1323,
      "step": 69550
    },
    {
      "epoch": 7.453123325833065,
      "grad_norm": 0.00034724036231637,
      "learning_rate": 1.006250223222258e-05,
      "loss": 0.0001,
      "step": 69560
    },
    {
      "epoch": 7.454194792671167,
      "grad_norm": 0.010946153663098812,
      "learning_rate": 1.0061073609771779e-05,
      "loss": 0.0001,
      "step": 69570
    },
    {
      "epoch": 7.455266259509268,
      "grad_norm": 0.029833151027560234,
      "learning_rate": 1.0059644987320976e-05,
      "loss": 0.0005,
      "step": 69580
    },
    {
      "epoch": 7.456337726347369,
      "grad_norm": 0.002284914953634143,
      "learning_rate": 1.0058216364870174e-05,
      "loss": 0.0001,
      "step": 69590
    },
    {
      "epoch": 7.457409193185471,
      "grad_norm": 0.011287960223853588,
      "learning_rate": 1.0056787742419373e-05,
      "loss": 0.0003,
      "step": 69600
    },
    {
      "epoch": 7.4584806600235725,
      "grad_norm": 0.004766680765897036,
      "learning_rate": 1.0055359119968571e-05,
      "loss": 0.0,
      "step": 69610
    },
    {
      "epoch": 7.459552126861674,
      "grad_norm": 0.9505605697631836,
      "learning_rate": 1.005393049751777e-05,
      "loss": 0.0014,
      "step": 69620
    },
    {
      "epoch": 7.460623593699775,
      "grad_norm": 0.011222830042243004,
      "learning_rate": 1.0052501875066966e-05,
      "loss": 0.0002,
      "step": 69630
    },
    {
      "epoch": 7.461695060537877,
      "grad_norm": 0.06659109890460968,
      "learning_rate": 1.0051073252616166e-05,
      "loss": 0.143,
      "step": 69640
    },
    {
      "epoch": 7.462766527375978,
      "grad_norm": 0.0012527571525424719,
      "learning_rate": 1.0049644630165365e-05,
      "loss": 0.0004,
      "step": 69650
    },
    {
      "epoch": 7.463837994214079,
      "grad_norm": 0.0003024933685082942,
      "learning_rate": 1.0048216007714561e-05,
      "loss": 0.1619,
      "step": 69660
    },
    {
      "epoch": 7.46490946105218,
      "grad_norm": 0.00026806778623722494,
      "learning_rate": 1.004678738526376e-05,
      "loss": 0.0001,
      "step": 69670
    },
    {
      "epoch": 7.465980927890282,
      "grad_norm": 0.0002061897102976218,
      "learning_rate": 1.0045358762812958e-05,
      "loss": 0.0001,
      "step": 69680
    },
    {
      "epoch": 7.467052394728383,
      "grad_norm": 0.002455516019836068,
      "learning_rate": 1.0043930140362158e-05,
      "loss": 0.0002,
      "step": 69690
    },
    {
      "epoch": 7.468123861566484,
      "grad_norm": 0.0005835405900143087,
      "learning_rate": 1.0042501517911354e-05,
      "loss": 0.0001,
      "step": 69700
    },
    {
      "epoch": 7.469195328404586,
      "grad_norm": 0.00026128554600290954,
      "learning_rate": 1.0041072895460553e-05,
      "loss": 0.0,
      "step": 69710
    },
    {
      "epoch": 7.470266795242687,
      "grad_norm": 0.0035335335414856672,
      "learning_rate": 1.0039644273009752e-05,
      "loss": 0.0001,
      "step": 69720
    },
    {
      "epoch": 7.471338262080788,
      "grad_norm": 0.0018251963192597032,
      "learning_rate": 1.0038215650558948e-05,
      "loss": 0.0,
      "step": 69730
    },
    {
      "epoch": 7.4724097289188895,
      "grad_norm": 0.00023890749434940517,
      "learning_rate": 1.0036787028108148e-05,
      "loss": 0.2644,
      "step": 69740
    },
    {
      "epoch": 7.4734811957569915,
      "grad_norm": 0.004341856110841036,
      "learning_rate": 1.0035358405657345e-05,
      "loss": 0.0,
      "step": 69750
    },
    {
      "epoch": 7.474552662595093,
      "grad_norm": 0.00297676888294518,
      "learning_rate": 1.0033929783206545e-05,
      "loss": 0.0003,
      "step": 69760
    },
    {
      "epoch": 7.475624129433194,
      "grad_norm": 0.004941022489219904,
      "learning_rate": 1.0032501160755744e-05,
      "loss": 0.0002,
      "step": 69770
    },
    {
      "epoch": 7.476695596271296,
      "grad_norm": 0.0003098769229836762,
      "learning_rate": 1.003107253830494e-05,
      "loss": 0.1447,
      "step": 69780
    },
    {
      "epoch": 7.477767063109397,
      "grad_norm": 0.0057800873182713985,
      "learning_rate": 1.002964391585414e-05,
      "loss": 0.0007,
      "step": 69790
    },
    {
      "epoch": 7.478838529947498,
      "grad_norm": 0.00020719852182082832,
      "learning_rate": 1.0028215293403335e-05,
      "loss": 0.0001,
      "step": 69800
    },
    {
      "epoch": 7.479909996785599,
      "grad_norm": 0.0014855848858132958,
      "learning_rate": 1.0026786670952535e-05,
      "loss": 0.0794,
      "step": 69810
    },
    {
      "epoch": 7.480981463623701,
      "grad_norm": 65.29790496826172,
      "learning_rate": 1.0025358048501732e-05,
      "loss": 0.3701,
      "step": 69820
    },
    {
      "epoch": 7.482052930461802,
      "grad_norm": 0.00219902815297246,
      "learning_rate": 1.0023929426050932e-05,
      "loss": 0.0,
      "step": 69830
    },
    {
      "epoch": 7.483124397299903,
      "grad_norm": 0.0002806700940709561,
      "learning_rate": 1.0022500803600131e-05,
      "loss": 0.0004,
      "step": 69840
    },
    {
      "epoch": 7.484195864138005,
      "grad_norm": 0.01775044947862625,
      "learning_rate": 1.0021072181149327e-05,
      "loss": 0.0001,
      "step": 69850
    },
    {
      "epoch": 7.485267330976106,
      "grad_norm": 0.00019756282563321292,
      "learning_rate": 1.0019643558698526e-05,
      "loss": 0.1016,
      "step": 69860
    },
    {
      "epoch": 7.4863387978142075,
      "grad_norm": 0.0042068008333444595,
      "learning_rate": 1.0018214936247722e-05,
      "loss": 0.0,
      "step": 69870
    },
    {
      "epoch": 7.487410264652309,
      "grad_norm": 0.00020228125504218042,
      "learning_rate": 1.0016786313796922e-05,
      "loss": 0.0,
      "step": 69880
    },
    {
      "epoch": 7.488481731490411,
      "grad_norm": 0.00020151906937826425,
      "learning_rate": 1.001535769134612e-05,
      "loss": 0.0003,
      "step": 69890
    },
    {
      "epoch": 7.489553198328512,
      "grad_norm": 0.01311896089464426,
      "learning_rate": 1.0013929068895319e-05,
      "loss": 0.0001,
      "step": 69900
    },
    {
      "epoch": 7.490624665166613,
      "grad_norm": 0.0002038045204244554,
      "learning_rate": 1.0012500446444518e-05,
      "loss": 0.1573,
      "step": 69910
    },
    {
      "epoch": 7.491696132004715,
      "grad_norm": 0.0037449048832058907,
      "learning_rate": 1.0011071823993714e-05,
      "loss": 0.0,
      "step": 69920
    },
    {
      "epoch": 7.492767598842816,
      "grad_norm": 0.00023470357700716704,
      "learning_rate": 1.0009643201542914e-05,
      "loss": 0.0001,
      "step": 69930
    },
    {
      "epoch": 7.493839065680917,
      "grad_norm": 0.0012558484449982643,
      "learning_rate": 1.000821457909211e-05,
      "loss": 0.0,
      "step": 69940
    },
    {
      "epoch": 7.494910532519018,
      "grad_norm": 0.002192021580412984,
      "learning_rate": 1.0006785956641309e-05,
      "loss": 0.0001,
      "step": 69950
    },
    {
      "epoch": 7.49598199935712,
      "grad_norm": 0.00021257749176584184,
      "learning_rate": 1.0005357334190508e-05,
      "loss": 0.3101,
      "step": 69960
    },
    {
      "epoch": 7.497053466195221,
      "grad_norm": 0.08292247354984283,
      "learning_rate": 1.0003928711739706e-05,
      "loss": 0.254,
      "step": 69970
    },
    {
      "epoch": 7.498124933033322,
      "grad_norm": 0.0012368815951049328,
      "learning_rate": 1.0002500089288905e-05,
      "loss": 0.0,
      "step": 69980
    },
    {
      "epoch": 7.499196399871424,
      "grad_norm": 0.004386586602777243,
      "learning_rate": 1.0001071466838101e-05,
      "loss": 0.3268,
      "step": 69990
    },
    {
      "epoch": 7.5002678667095255,
      "grad_norm": 0.03884048014879227,
      "learning_rate": 9.9996428443873e-06,
      "loss": 0.1487,
      "step": 70000
    },
    {
      "epoch": 7.501339333547627,
      "grad_norm": 0.6343730092048645,
      "learning_rate": 9.998214221936498e-06,
      "loss": 0.0028,
      "step": 70010
    },
    {
      "epoch": 7.502410800385728,
      "grad_norm": 0.001906889141537249,
      "learning_rate": 9.996785599485696e-06,
      "loss": 0.0001,
      "step": 70020
    },
    {
      "epoch": 7.50348226722383,
      "grad_norm": 0.004797846078872681,
      "learning_rate": 9.995356977034895e-06,
      "loss": 0.0012,
      "step": 70030
    },
    {
      "epoch": 7.504553734061931,
      "grad_norm": 0.015340116806328297,
      "learning_rate": 9.993928354584093e-06,
      "loss": 0.0012,
      "step": 70040
    },
    {
      "epoch": 7.505625200900032,
      "grad_norm": 0.00043582258513197303,
      "learning_rate": 9.992499732133292e-06,
      "loss": 0.0001,
      "step": 70050
    },
    {
      "epoch": 7.506696667738133,
      "grad_norm": 0.008536561392247677,
      "learning_rate": 9.99107110968249e-06,
      "loss": 0.0,
      "step": 70060
    },
    {
      "epoch": 7.507768134576235,
      "grad_norm": 0.4345037639141083,
      "learning_rate": 9.989642487231688e-06,
      "loss": 0.271,
      "step": 70070
    },
    {
      "epoch": 7.508839601414336,
      "grad_norm": 0.0007902532815933228,
      "learning_rate": 9.988213864780885e-06,
      "loss": 0.1345,
      "step": 70080
    },
    {
      "epoch": 7.509911068252437,
      "grad_norm": 0.004054914228618145,
      "learning_rate": 9.986785242330083e-06,
      "loss": 0.2208,
      "step": 70090
    },
    {
      "epoch": 7.510982535090539,
      "grad_norm": 0.6099585890769958,
      "learning_rate": 9.985356619879282e-06,
      "loss": 0.0013,
      "step": 70100
    },
    {
      "epoch": 7.51205400192864,
      "grad_norm": 48.43284225463867,
      "learning_rate": 9.98392799742848e-06,
      "loss": 0.1047,
      "step": 70110
    },
    {
      "epoch": 7.5131254687667415,
      "grad_norm": 0.004815195687115192,
      "learning_rate": 9.98249937497768e-06,
      "loss": 0.1063,
      "step": 70120
    },
    {
      "epoch": 7.5141969356048435,
      "grad_norm": 0.0004737321869470179,
      "learning_rate": 9.981070752526877e-06,
      "loss": 0.1124,
      "step": 70130
    },
    {
      "epoch": 7.515268402442945,
      "grad_norm": 0.0021909482311457396,
      "learning_rate": 9.979642130076075e-06,
      "loss": 0.0003,
      "step": 70140
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 0.0003286749415565282,
      "learning_rate": 9.978213507625273e-06,
      "loss": 0.0001,
      "step": 70150
    },
    {
      "epoch": 7.517411336119147,
      "grad_norm": 0.007631372660398483,
      "learning_rate": 9.97678488517447e-06,
      "loss": 0.0001,
      "step": 70160
    },
    {
      "epoch": 7.518482802957249,
      "grad_norm": 0.0004097043420188129,
      "learning_rate": 9.97535626272367e-06,
      "loss": 0.0849,
      "step": 70170
    },
    {
      "epoch": 7.51955426979535,
      "grad_norm": 0.0008901034016162157,
      "learning_rate": 9.973927640272867e-06,
      "loss": 0.0001,
      "step": 70180
    },
    {
      "epoch": 7.520625736633451,
      "grad_norm": 0.0005246257060207427,
      "learning_rate": 9.972499017822067e-06,
      "loss": 0.0698,
      "step": 70190
    },
    {
      "epoch": 7.521697203471552,
      "grad_norm": 0.001002766890451312,
      "learning_rate": 9.971070395371264e-06,
      "loss": 0.0001,
      "step": 70200
    },
    {
      "epoch": 7.522768670309654,
      "grad_norm": 0.11587945371866226,
      "learning_rate": 9.969641772920462e-06,
      "loss": 0.0015,
      "step": 70210
    },
    {
      "epoch": 7.523840137147755,
      "grad_norm": 0.008511709049344063,
      "learning_rate": 9.96821315046966e-06,
      "loss": 0.0,
      "step": 70220
    },
    {
      "epoch": 7.524911603985856,
      "grad_norm": 0.0006036373670212924,
      "learning_rate": 9.966784528018859e-06,
      "loss": 0.0,
      "step": 70230
    },
    {
      "epoch": 7.525983070823958,
      "grad_norm": 0.00033620119211263955,
      "learning_rate": 9.965355905568057e-06,
      "loss": 0.0003,
      "step": 70240
    },
    {
      "epoch": 7.5270545376620595,
      "grad_norm": 0.0006828843615949154,
      "learning_rate": 9.963927283117254e-06,
      "loss": 0.1297,
      "step": 70250
    },
    {
      "epoch": 7.528126004500161,
      "grad_norm": 0.00672028586268425,
      "learning_rate": 9.962498660666454e-06,
      "loss": 0.0009,
      "step": 70260
    },
    {
      "epoch": 7.529197471338263,
      "grad_norm": 0.0029941461980342865,
      "learning_rate": 9.961070038215651e-06,
      "loss": 0.0086,
      "step": 70270
    },
    {
      "epoch": 7.530268938176364,
      "grad_norm": 0.00029940117383375764,
      "learning_rate": 9.959641415764849e-06,
      "loss": 0.062,
      "step": 70280
    },
    {
      "epoch": 7.531340405014465,
      "grad_norm": 0.04847469925880432,
      "learning_rate": 9.958212793314048e-06,
      "loss": 0.0001,
      "step": 70290
    },
    {
      "epoch": 7.532411871852566,
      "grad_norm": 0.00031902181217446923,
      "learning_rate": 9.956784170863246e-06,
      "loss": 0.1206,
      "step": 70300
    },
    {
      "epoch": 7.533483338690668,
      "grad_norm": 0.0003436552360653877,
      "learning_rate": 9.955355548412444e-06,
      "loss": 0.0027,
      "step": 70310
    },
    {
      "epoch": 7.534554805528769,
      "grad_norm": 0.01966015249490738,
      "learning_rate": 9.953926925961641e-06,
      "loss": 0.0001,
      "step": 70320
    },
    {
      "epoch": 7.53562627236687,
      "grad_norm": 0.00027532814419828355,
      "learning_rate": 9.95249830351084e-06,
      "loss": 0.0037,
      "step": 70330
    },
    {
      "epoch": 7.536697739204971,
      "grad_norm": 0.00018384447321295738,
      "learning_rate": 9.951069681060038e-06,
      "loss": 0.0005,
      "step": 70340
    },
    {
      "epoch": 7.537769206043073,
      "grad_norm": 0.02409815974533558,
      "learning_rate": 9.949641058609238e-06,
      "loss": 0.0013,
      "step": 70350
    },
    {
      "epoch": 7.538840672881174,
      "grad_norm": 0.00028659813688136637,
      "learning_rate": 9.948212436158436e-06,
      "loss": 0.0,
      "step": 70360
    },
    {
      "epoch": 7.539912139719275,
      "grad_norm": 0.00019084893574472517,
      "learning_rate": 9.946783813707633e-06,
      "loss": 0.1299,
      "step": 70370
    },
    {
      "epoch": 7.540983606557377,
      "grad_norm": 0.001906834775581956,
      "learning_rate": 9.945355191256831e-06,
      "loss": 0.0001,
      "step": 70380
    },
    {
      "epoch": 7.5420550733954785,
      "grad_norm": 0.011583556421101093,
      "learning_rate": 9.943926568806029e-06,
      "loss": 0.0,
      "step": 70390
    },
    {
      "epoch": 7.54312654023358,
      "grad_norm": 0.00020886221318505704,
      "learning_rate": 9.942497946355228e-06,
      "loss": 0.0,
      "step": 70400
    },
    {
      "epoch": 7.544198007071681,
      "grad_norm": 0.0012713019968941808,
      "learning_rate": 9.941069323904427e-06,
      "loss": 0.0007,
      "step": 70410
    },
    {
      "epoch": 7.545269473909783,
      "grad_norm": 0.00018685484246816486,
      "learning_rate": 9.939640701453625e-06,
      "loss": 0.0002,
      "step": 70420
    },
    {
      "epoch": 7.546340940747884,
      "grad_norm": 0.0011707571102306247,
      "learning_rate": 9.938212079002823e-06,
      "loss": 0.0,
      "step": 70430
    },
    {
      "epoch": 7.547412407585985,
      "grad_norm": 0.00015985289064701647,
      "learning_rate": 9.93678345655202e-06,
      "loss": 0.2531,
      "step": 70440
    },
    {
      "epoch": 7.548483874424086,
      "grad_norm": 0.006444437429308891,
      "learning_rate": 9.935354834101218e-06,
      "loss": 0.0002,
      "step": 70450
    },
    {
      "epoch": 7.549555341262188,
      "grad_norm": 0.0014222105965018272,
      "learning_rate": 9.933926211650417e-06,
      "loss": 0.0005,
      "step": 70460
    },
    {
      "epoch": 7.550626808100289,
      "grad_norm": 0.0003321723488625139,
      "learning_rate": 9.932497589199615e-06,
      "loss": 0.3264,
      "step": 70470
    },
    {
      "epoch": 7.55169827493839,
      "grad_norm": 0.07868320494890213,
      "learning_rate": 9.931068966748814e-06,
      "loss": 0.0001,
      "step": 70480
    },
    {
      "epoch": 7.552769741776492,
      "grad_norm": 125.79591369628906,
      "learning_rate": 9.929640344298012e-06,
      "loss": 0.1999,
      "step": 70490
    },
    {
      "epoch": 7.553841208614593,
      "grad_norm": 0.0005059881368651986,
      "learning_rate": 9.92821172184721e-06,
      "loss": 0.001,
      "step": 70500
    },
    {
      "epoch": 7.5549126754526945,
      "grad_norm": 0.00042773890891112387,
      "learning_rate": 9.926783099396407e-06,
      "loss": 0.0003,
      "step": 70510
    },
    {
      "epoch": 7.5559841422907965,
      "grad_norm": 0.0003238523786421865,
      "learning_rate": 9.925354476945605e-06,
      "loss": 0.0002,
      "step": 70520
    },
    {
      "epoch": 7.557055609128898,
      "grad_norm": 0.007276614662259817,
      "learning_rate": 9.923925854494804e-06,
      "loss": 0.1337,
      "step": 70530
    },
    {
      "epoch": 7.558127075966999,
      "grad_norm": 0.0003093105333391577,
      "learning_rate": 9.922497232044002e-06,
      "loss": 0.0,
      "step": 70540
    },
    {
      "epoch": 7.5591985428051,
      "grad_norm": 0.00031481811311095953,
      "learning_rate": 9.921068609593201e-06,
      "loss": 0.0,
      "step": 70550
    },
    {
      "epoch": 7.560270009643202,
      "grad_norm": 0.0034064622595906258,
      "learning_rate": 9.919639987142399e-06,
      "loss": 0.0001,
      "step": 70560
    },
    {
      "epoch": 7.561341476481303,
      "grad_norm": 0.0002571315271779895,
      "learning_rate": 9.918211364691597e-06,
      "loss": 0.1114,
      "step": 70570
    },
    {
      "epoch": 7.562412943319404,
      "grad_norm": 0.0003074229462072253,
      "learning_rate": 9.916782742240794e-06,
      "loss": 0.0,
      "step": 70580
    },
    {
      "epoch": 7.563484410157505,
      "grad_norm": 0.0015820274129509926,
      "learning_rate": 9.915354119789994e-06,
      "loss": 0.2424,
      "step": 70590
    },
    {
      "epoch": 7.564555876995607,
      "grad_norm": 0.00032122249831445515,
      "learning_rate": 9.913925497339192e-06,
      "loss": 0.0001,
      "step": 70600
    },
    {
      "epoch": 7.565627343833708,
      "grad_norm": 0.0003768254828173667,
      "learning_rate": 9.91249687488839e-06,
      "loss": 0.0013,
      "step": 70610
    },
    {
      "epoch": 7.566698810671809,
      "grad_norm": 0.00295618805103004,
      "learning_rate": 9.911068252437589e-06,
      "loss": 0.1502,
      "step": 70620
    },
    {
      "epoch": 7.567770277509911,
      "grad_norm": 0.000449655664851889,
      "learning_rate": 9.909639629986786e-06,
      "loss": 0.0,
      "step": 70630
    },
    {
      "epoch": 7.5688417443480125,
      "grad_norm": 0.004727913998067379,
      "learning_rate": 9.908211007535984e-06,
      "loss": 0.0001,
      "step": 70640
    },
    {
      "epoch": 7.569913211186114,
      "grad_norm": 0.00025678236852400005,
      "learning_rate": 9.906782385085183e-06,
      "loss": 0.0,
      "step": 70650
    },
    {
      "epoch": 7.570984678024216,
      "grad_norm": 0.00023656677512917668,
      "learning_rate": 9.905353762634381e-06,
      "loss": 0.0001,
      "step": 70660
    },
    {
      "epoch": 7.572056144862317,
      "grad_norm": 0.0021320641972124577,
      "learning_rate": 9.903925140183579e-06,
      "loss": 0.0003,
      "step": 70670
    },
    {
      "epoch": 7.573127611700418,
      "grad_norm": 0.00045394012704491615,
      "learning_rate": 9.902496517732776e-06,
      "loss": 0.0,
      "step": 70680
    },
    {
      "epoch": 7.574199078538519,
      "grad_norm": 0.00042995624244213104,
      "learning_rate": 9.901067895281976e-06,
      "loss": 0.0,
      "step": 70690
    },
    {
      "epoch": 7.575270545376621,
      "grad_norm": 0.0002615935809444636,
      "learning_rate": 9.899639272831173e-06,
      "loss": 0.0,
      "step": 70700
    },
    {
      "epoch": 7.576342012214722,
      "grad_norm": 0.003690623212605715,
      "learning_rate": 9.898210650380371e-06,
      "loss": 0.0001,
      "step": 70710
    },
    {
      "epoch": 7.577413479052823,
      "grad_norm": 0.00044231986976228654,
      "learning_rate": 9.89678202792957e-06,
      "loss": 0.0,
      "step": 70720
    },
    {
      "epoch": 7.578484945890924,
      "grad_norm": 0.005279622506350279,
      "learning_rate": 9.895353405478768e-06,
      "loss": 0.231,
      "step": 70730
    },
    {
      "epoch": 7.579556412729026,
      "grad_norm": 0.0032748165540397167,
      "learning_rate": 9.893924783027966e-06,
      "loss": 0.1957,
      "step": 70740
    },
    {
      "epoch": 7.580627879567127,
      "grad_norm": 46.815513610839844,
      "learning_rate": 9.892496160577163e-06,
      "loss": 0.1665,
      "step": 70750
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 0.010637353174388409,
      "learning_rate": 9.891067538126363e-06,
      "loss": 0.0001,
      "step": 70760
    },
    {
      "epoch": 7.5827708132433305,
      "grad_norm": 0.004925699904561043,
      "learning_rate": 9.88963891567556e-06,
      "loss": 0.0001,
      "step": 70770
    },
    {
      "epoch": 7.583842280081432,
      "grad_norm": 0.0007961023366078734,
      "learning_rate": 9.88821029322476e-06,
      "loss": 0.0001,
      "step": 70780
    },
    {
      "epoch": 7.584913746919533,
      "grad_norm": 0.00026178339612670243,
      "learning_rate": 9.886781670773957e-06,
      "loss": 0.0036,
      "step": 70790
    },
    {
      "epoch": 7.585985213757635,
      "grad_norm": 0.00026258756406605244,
      "learning_rate": 9.885353048323155e-06,
      "loss": 0.0001,
      "step": 70800
    },
    {
      "epoch": 7.587056680595736,
      "grad_norm": 50.23069381713867,
      "learning_rate": 9.883924425872353e-06,
      "loss": 0.2024,
      "step": 70810
    },
    {
      "epoch": 7.588128147433837,
      "grad_norm": 0.0058224997483193874,
      "learning_rate": 9.88249580342155e-06,
      "loss": 0.0576,
      "step": 70820
    },
    {
      "epoch": 7.589199614271938,
      "grad_norm": 0.04546112194657326,
      "learning_rate": 9.88106718097075e-06,
      "loss": 0.0001,
      "step": 70830
    },
    {
      "epoch": 7.59027108111004,
      "grad_norm": 0.0002489366743247956,
      "learning_rate": 9.87963855851995e-06,
      "loss": 0.0,
      "step": 70840
    },
    {
      "epoch": 7.591342547948141,
      "grad_norm": 0.00025922307395376265,
      "learning_rate": 9.878209936069147e-06,
      "loss": 0.0001,
      "step": 70850
    },
    {
      "epoch": 7.592414014786242,
      "grad_norm": 0.00018467595509719104,
      "learning_rate": 9.876781313618345e-06,
      "loss": 0.0,
      "step": 70860
    },
    {
      "epoch": 7.593485481624343,
      "grad_norm": 3.472318172454834,
      "learning_rate": 9.875352691167542e-06,
      "loss": 0.0005,
      "step": 70870
    },
    {
      "epoch": 7.594556948462445,
      "grad_norm": 0.0021132887341082096,
      "learning_rate": 9.87392406871674e-06,
      "loss": 0.0,
      "step": 70880
    },
    {
      "epoch": 7.595628415300546,
      "grad_norm": 0.000729168183170259,
      "learning_rate": 9.872495446265938e-06,
      "loss": 0.0001,
      "step": 70890
    },
    {
      "epoch": 7.5966998821386476,
      "grad_norm": 0.0011637305142357945,
      "learning_rate": 9.871066823815137e-06,
      "loss": 0.0001,
      "step": 70900
    },
    {
      "epoch": 7.5977713489767496,
      "grad_norm": 0.00043997494503855705,
      "learning_rate": 9.869638201364336e-06,
      "loss": 0.0,
      "step": 70910
    },
    {
      "epoch": 7.598842815814851,
      "grad_norm": 0.0009433010709472001,
      "learning_rate": 9.868209578913534e-06,
      "loss": 0.0,
      "step": 70920
    },
    {
      "epoch": 7.599914282652952,
      "grad_norm": 0.00037935376167297363,
      "learning_rate": 9.866780956462732e-06,
      "loss": 0.4584,
      "step": 70930
    },
    {
      "epoch": 7.600985749491053,
      "grad_norm": 0.001916547305881977,
      "learning_rate": 9.86535233401193e-06,
      "loss": 0.1148,
      "step": 70940
    },
    {
      "epoch": 7.602057216329155,
      "grad_norm": 0.24877984821796417,
      "learning_rate": 9.863923711561127e-06,
      "loss": 0.0006,
      "step": 70950
    },
    {
      "epoch": 7.603128683167256,
      "grad_norm": 0.021049095317721367,
      "learning_rate": 9.862495089110326e-06,
      "loss": 0.0002,
      "step": 70960
    },
    {
      "epoch": 7.604200150005357,
      "grad_norm": 0.0006695740157738328,
      "learning_rate": 9.861066466659524e-06,
      "loss": 0.0001,
      "step": 70970
    },
    {
      "epoch": 7.605271616843458,
      "grad_norm": 0.0008416821947321296,
      "learning_rate": 9.859637844208723e-06,
      "loss": 0.0,
      "step": 70980
    },
    {
      "epoch": 7.60634308368156,
      "grad_norm": 0.003007045481353998,
      "learning_rate": 9.858209221757921e-06,
      "loss": 0.0036,
      "step": 70990
    },
    {
      "epoch": 7.607414550519661,
      "grad_norm": 0.0007692954386584461,
      "learning_rate": 9.856780599307119e-06,
      "loss": 0.0,
      "step": 71000
    },
    {
      "epoch": 7.608486017357762,
      "grad_norm": 0.005445943679660559,
      "learning_rate": 9.855351976856316e-06,
      "loss": 0.0004,
      "step": 71010
    },
    {
      "epoch": 7.609557484195864,
      "grad_norm": 0.001416248851455748,
      "learning_rate": 9.853923354405516e-06,
      "loss": 0.0,
      "step": 71020
    },
    {
      "epoch": 7.6106289510339655,
      "grad_norm": 0.0011336150346323848,
      "learning_rate": 9.852494731954713e-06,
      "loss": 0.0002,
      "step": 71030
    },
    {
      "epoch": 7.611700417872067,
      "grad_norm": 0.001274161972105503,
      "learning_rate": 9.851066109503911e-06,
      "loss": 0.1133,
      "step": 71040
    },
    {
      "epoch": 7.612771884710169,
      "grad_norm": 0.0002863007830455899,
      "learning_rate": 9.84963748705311e-06,
      "loss": 0.0004,
      "step": 71050
    },
    {
      "epoch": 7.61384335154827,
      "grad_norm": 0.00026235132827423513,
      "learning_rate": 9.848208864602308e-06,
      "loss": 0.0,
      "step": 71060
    },
    {
      "epoch": 7.614914818386371,
      "grad_norm": 0.0002506841265130788,
      "learning_rate": 9.846780242151506e-06,
      "loss": 0.0001,
      "step": 71070
    },
    {
      "epoch": 7.615986285224472,
      "grad_norm": 0.06814324110746384,
      "learning_rate": 9.845351619700705e-06,
      "loss": 0.1933,
      "step": 71080
    },
    {
      "epoch": 7.617057752062574,
      "grad_norm": 0.006189643871039152,
      "learning_rate": 9.843922997249903e-06,
      "loss": 0.0,
      "step": 71090
    },
    {
      "epoch": 7.618129218900675,
      "grad_norm": 0.0010406075743958354,
      "learning_rate": 9.8424943747991e-06,
      "loss": 0.0001,
      "step": 71100
    },
    {
      "epoch": 7.619200685738776,
      "grad_norm": 0.14392219483852386,
      "learning_rate": 9.841065752348298e-06,
      "loss": 0.0002,
      "step": 71110
    },
    {
      "epoch": 7.620272152576877,
      "grad_norm": 0.0005746756796725094,
      "learning_rate": 9.839637129897498e-06,
      "loss": 0.0,
      "step": 71120
    },
    {
      "epoch": 7.621343619414979,
      "grad_norm": 0.005598496180027723,
      "learning_rate": 9.838208507446695e-06,
      "loss": 0.2799,
      "step": 71130
    },
    {
      "epoch": 7.62241508625308,
      "grad_norm": 0.00027226240490563214,
      "learning_rate": 9.836779884995895e-06,
      "loss": 0.2907,
      "step": 71140
    },
    {
      "epoch": 7.6234865530911815,
      "grad_norm": 0.06704375147819519,
      "learning_rate": 9.835351262545092e-06,
      "loss": 0.1384,
      "step": 71150
    },
    {
      "epoch": 7.6245580199292835,
      "grad_norm": 7.807032108306885,
      "learning_rate": 9.83392264009429e-06,
      "loss": 0.0753,
      "step": 71160
    },
    {
      "epoch": 7.625629486767385,
      "grad_norm": 0.043550871312618256,
      "learning_rate": 9.832494017643488e-06,
      "loss": 0.0002,
      "step": 71170
    },
    {
      "epoch": 7.626700953605486,
      "grad_norm": 0.004234724212437868,
      "learning_rate": 9.831065395192685e-06,
      "loss": 0.0001,
      "step": 71180
    },
    {
      "epoch": 7.627772420443588,
      "grad_norm": 0.006428143475204706,
      "learning_rate": 9.829636772741885e-06,
      "loss": 0.1903,
      "step": 71190
    },
    {
      "epoch": 7.628843887281689,
      "grad_norm": 0.0014858458889648318,
      "learning_rate": 9.828208150291082e-06,
      "loss": 0.0002,
      "step": 71200
    },
    {
      "epoch": 7.62991535411979,
      "grad_norm": 0.00019090638670604676,
      "learning_rate": 9.826779527840282e-06,
      "loss": 0.1837,
      "step": 71210
    },
    {
      "epoch": 7.630986820957891,
      "grad_norm": 0.0007965209661051631,
      "learning_rate": 9.82535090538948e-06,
      "loss": 0.0003,
      "step": 71220
    },
    {
      "epoch": 7.632058287795993,
      "grad_norm": 0.0038402657955884933,
      "learning_rate": 9.823922282938677e-06,
      "loss": 0.0001,
      "step": 71230
    },
    {
      "epoch": 7.633129754634094,
      "grad_norm": 0.00044896427425555885,
      "learning_rate": 9.822493660487875e-06,
      "loss": 0.0001,
      "step": 71240
    },
    {
      "epoch": 7.634201221472195,
      "grad_norm": 0.0006937998114153743,
      "learning_rate": 9.821065038037072e-06,
      "loss": 0.0745,
      "step": 71250
    },
    {
      "epoch": 7.635272688310296,
      "grad_norm": 0.0004312921373639256,
      "learning_rate": 9.819636415586272e-06,
      "loss": 0.0479,
      "step": 71260
    },
    {
      "epoch": 7.636344155148398,
      "grad_norm": 0.043112076818943024,
      "learning_rate": 9.81820779313547e-06,
      "loss": 0.0052,
      "step": 71270
    },
    {
      "epoch": 7.6374156219864995,
      "grad_norm": 0.0025932276621460915,
      "learning_rate": 9.816779170684669e-06,
      "loss": 0.0001,
      "step": 71280
    },
    {
      "epoch": 7.638487088824601,
      "grad_norm": 0.0004713604284916073,
      "learning_rate": 9.815350548233866e-06,
      "loss": 0.2653,
      "step": 71290
    },
    {
      "epoch": 7.639558555662703,
      "grad_norm": 0.7207874655723572,
      "learning_rate": 9.813921925783064e-06,
      "loss": 0.0025,
      "step": 71300
    },
    {
      "epoch": 7.640630022500804,
      "grad_norm": 0.0003188257396686822,
      "learning_rate": 9.812493303332262e-06,
      "loss": 0.0872,
      "step": 71310
    },
    {
      "epoch": 7.641701489338905,
      "grad_norm": 6.224961280822754,
      "learning_rate": 9.811064680881461e-06,
      "loss": 0.1363,
      "step": 71320
    },
    {
      "epoch": 7.642772956177007,
      "grad_norm": 0.01099844928830862,
      "learning_rate": 9.809636058430659e-06,
      "loss": 0.0002,
      "step": 71330
    },
    {
      "epoch": 7.643844423015108,
      "grad_norm": 0.00021545558411162347,
      "learning_rate": 9.808207435979857e-06,
      "loss": 0.0001,
      "step": 71340
    },
    {
      "epoch": 7.644915889853209,
      "grad_norm": 0.0001972742611542344,
      "learning_rate": 9.806778813529056e-06,
      "loss": 0.0003,
      "step": 71350
    },
    {
      "epoch": 7.64598735669131,
      "grad_norm": 19.557764053344727,
      "learning_rate": 9.805350191078254e-06,
      "loss": 0.2428,
      "step": 71360
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.0003731649194378406,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.0001,
      "step": 71370
    },
    {
      "epoch": 7.648130290367513,
      "grad_norm": 0.00015489848738070577,
      "learning_rate": 9.80249294617665e-06,
      "loss": 0.0,
      "step": 71380
    },
    {
      "epoch": 7.649201757205614,
      "grad_norm": 20.37186050415039,
      "learning_rate": 9.801064323725848e-06,
      "loss": 0.1918,
      "step": 71390
    },
    {
      "epoch": 7.6502732240437155,
      "grad_norm": 0.0002764035598374903,
      "learning_rate": 9.799635701275046e-06,
      "loss": 0.0009,
      "step": 71400
    },
    {
      "epoch": 7.6513446908818175,
      "grad_norm": 0.0067132203839719296,
      "learning_rate": 9.798207078824245e-06,
      "loss": 0.0027,
      "step": 71410
    },
    {
      "epoch": 7.652416157719919,
      "grad_norm": 0.0010143703548237681,
      "learning_rate": 9.796778456373443e-06,
      "loss": 0.0002,
      "step": 71420
    },
    {
      "epoch": 7.65348762455802,
      "grad_norm": 0.005253084469586611,
      "learning_rate": 9.79534983392264e-06,
      "loss": 0.001,
      "step": 71430
    },
    {
      "epoch": 7.654559091396122,
      "grad_norm": 0.011360358446836472,
      "learning_rate": 9.79392121147184e-06,
      "loss": 0.1848,
      "step": 71440
    },
    {
      "epoch": 7.655630558234223,
      "grad_norm": 0.00038097292417660356,
      "learning_rate": 9.792492589021038e-06,
      "loss": 0.0011,
      "step": 71450
    },
    {
      "epoch": 7.656702025072324,
      "grad_norm": 0.00030113215325400233,
      "learning_rate": 9.791063966570235e-06,
      "loss": 0.0002,
      "step": 71460
    },
    {
      "epoch": 7.657773491910425,
      "grad_norm": 0.00015513907419517636,
      "learning_rate": 9.789635344119433e-06,
      "loss": 0.0,
      "step": 71470
    },
    {
      "epoch": 7.658844958748527,
      "grad_norm": 0.00014255318092182279,
      "learning_rate": 9.788206721668632e-06,
      "loss": 0.0001,
      "step": 71480
    },
    {
      "epoch": 7.659916425586628,
      "grad_norm": 0.00042009222670458257,
      "learning_rate": 9.78677809921783e-06,
      "loss": 0.0001,
      "step": 71490
    },
    {
      "epoch": 7.660987892424729,
      "grad_norm": 0.0003193496377207339,
      "learning_rate": 9.78534947676703e-06,
      "loss": 0.0001,
      "step": 71500
    },
    {
      "epoch": 7.66205935926283,
      "grad_norm": 0.01434947270900011,
      "learning_rate": 9.783920854316227e-06,
      "loss": 0.0003,
      "step": 71510
    },
    {
      "epoch": 7.663130826100932,
      "grad_norm": 0.00018842756981030107,
      "learning_rate": 9.782492231865425e-06,
      "loss": 0.0002,
      "step": 71520
    },
    {
      "epoch": 7.664202292939033,
      "grad_norm": 0.00022684615396428853,
      "learning_rate": 9.781063609414622e-06,
      "loss": 0.156,
      "step": 71530
    },
    {
      "epoch": 7.6652737597771345,
      "grad_norm": 0.0005352820735424757,
      "learning_rate": 9.77963498696382e-06,
      "loss": 0.0001,
      "step": 71540
    },
    {
      "epoch": 7.6663452266152365,
      "grad_norm": 6.376527309417725,
      "learning_rate": 9.77820636451302e-06,
      "loss": 0.0049,
      "step": 71550
    },
    {
      "epoch": 7.667416693453338,
      "grad_norm": 0.00015786447329446673,
      "learning_rate": 9.776777742062217e-06,
      "loss": 0.0001,
      "step": 71560
    },
    {
      "epoch": 7.668488160291439,
      "grad_norm": 0.00010248510079691187,
      "learning_rate": 9.775349119611417e-06,
      "loss": 0.0005,
      "step": 71570
    },
    {
      "epoch": 7.669559627129541,
      "grad_norm": 0.00016605576092842966,
      "learning_rate": 9.773920497160614e-06,
      "loss": 0.0,
      "step": 71580
    },
    {
      "epoch": 7.670631093967642,
      "grad_norm": 0.0001223690778715536,
      "learning_rate": 9.772491874709812e-06,
      "loss": 0.0001,
      "step": 71590
    },
    {
      "epoch": 7.671702560805743,
      "grad_norm": 0.003893099958077073,
      "learning_rate": 9.77106325225901e-06,
      "loss": 0.0001,
      "step": 71600
    },
    {
      "epoch": 7.672774027643844,
      "grad_norm": 0.003046042751520872,
      "learning_rate": 9.769634629808207e-06,
      "loss": 0.1812,
      "step": 71610
    },
    {
      "epoch": 7.673845494481946,
      "grad_norm": 0.0014722346095368266,
      "learning_rate": 9.768206007357407e-06,
      "loss": 0.0001,
      "step": 71620
    },
    {
      "epoch": 7.674916961320047,
      "grad_norm": 0.000269695941824466,
      "learning_rate": 9.766777384906604e-06,
      "loss": 0.2041,
      "step": 71630
    },
    {
      "epoch": 7.675988428158148,
      "grad_norm": 0.00015816849190741777,
      "learning_rate": 9.765348762455804e-06,
      "loss": 0.1437,
      "step": 71640
    },
    {
      "epoch": 7.677059894996249,
      "grad_norm": 0.00019289521151222289,
      "learning_rate": 9.763920140005001e-06,
      "loss": 0.4281,
      "step": 71650
    },
    {
      "epoch": 7.678131361834351,
      "grad_norm": 0.00010096700862050056,
      "learning_rate": 9.762491517554199e-06,
      "loss": 0.0921,
      "step": 71660
    },
    {
      "epoch": 7.6792028286724525,
      "grad_norm": 0.010067601688206196,
      "learning_rate": 9.761062895103397e-06,
      "loss": 0.0003,
      "step": 71670
    },
    {
      "epoch": 7.680274295510554,
      "grad_norm": 0.005783093627542257,
      "learning_rate": 9.759634272652594e-06,
      "loss": 0.2147,
      "step": 71680
    },
    {
      "epoch": 7.681345762348656,
      "grad_norm": 0.00013052155554760247,
      "learning_rate": 9.758205650201794e-06,
      "loss": 0.0003,
      "step": 71690
    },
    {
      "epoch": 7.682417229186757,
      "grad_norm": 0.026612384244799614,
      "learning_rate": 9.756777027750991e-06,
      "loss": 0.0001,
      "step": 71700
    },
    {
      "epoch": 7.683488696024858,
      "grad_norm": 0.007651969324797392,
      "learning_rate": 9.75534840530019e-06,
      "loss": 0.0007,
      "step": 71710
    },
    {
      "epoch": 7.68456016286296,
      "grad_norm": 0.012319817207753658,
      "learning_rate": 9.753919782849388e-06,
      "loss": 0.0001,
      "step": 71720
    },
    {
      "epoch": 7.685631629701061,
      "grad_norm": 0.0003385631425771862,
      "learning_rate": 9.752491160398586e-06,
      "loss": 0.0001,
      "step": 71730
    },
    {
      "epoch": 7.686703096539162,
      "grad_norm": 0.012467784807085991,
      "learning_rate": 9.751062537947784e-06,
      "loss": 0.0001,
      "step": 71740
    },
    {
      "epoch": 7.687774563377263,
      "grad_norm": 50.75086975097656,
      "learning_rate": 9.749633915496983e-06,
      "loss": 0.1975,
      "step": 71750
    },
    {
      "epoch": 7.688846030215365,
      "grad_norm": 0.0017816124018281698,
      "learning_rate": 9.74820529304618e-06,
      "loss": 0.1522,
      "step": 71760
    },
    {
      "epoch": 7.689917497053466,
      "grad_norm": 0.005368763115257025,
      "learning_rate": 9.746776670595378e-06,
      "loss": 0.0,
      "step": 71770
    },
    {
      "epoch": 7.690988963891567,
      "grad_norm": 0.49636492133140564,
      "learning_rate": 9.745348048144578e-06,
      "loss": 0.154,
      "step": 71780
    },
    {
      "epoch": 7.6920604307296685,
      "grad_norm": 0.000256144703598693,
      "learning_rate": 9.743919425693776e-06,
      "loss": 0.141,
      "step": 71790
    },
    {
      "epoch": 7.6931318975677705,
      "grad_norm": 0.0002079682017210871,
      "learning_rate": 9.742490803242973e-06,
      "loss": 0.0021,
      "step": 71800
    },
    {
      "epoch": 7.694203364405872,
      "grad_norm": 0.0003476231067907065,
      "learning_rate": 9.741062180792173e-06,
      "loss": 0.0001,
      "step": 71810
    },
    {
      "epoch": 7.695274831243973,
      "grad_norm": 0.00017693234258331358,
      "learning_rate": 9.73963355834137e-06,
      "loss": 0.0001,
      "step": 71820
    },
    {
      "epoch": 7.696346298082075,
      "grad_norm": 0.008353328332304955,
      "learning_rate": 9.738204935890568e-06,
      "loss": 0.3009,
      "step": 71830
    },
    {
      "epoch": 7.697417764920176,
      "grad_norm": 0.014984942972660065,
      "learning_rate": 9.736776313439766e-06,
      "loss": 0.0004,
      "step": 71840
    },
    {
      "epoch": 7.698489231758277,
      "grad_norm": 0.0002109620108967647,
      "learning_rate": 9.735347690988965e-06,
      "loss": 0.001,
      "step": 71850
    },
    {
      "epoch": 7.699560698596379,
      "grad_norm": 0.17567436397075653,
      "learning_rate": 9.733919068538163e-06,
      "loss": 0.0002,
      "step": 71860
    },
    {
      "epoch": 7.70063216543448,
      "grad_norm": 0.00016224657883867621,
      "learning_rate": 9.732490446087362e-06,
      "loss": 0.219,
      "step": 71870
    },
    {
      "epoch": 7.701703632272581,
      "grad_norm": 0.0003681097296066582,
      "learning_rate": 9.73106182363656e-06,
      "loss": 0.0,
      "step": 71880
    },
    {
      "epoch": 7.702775099110682,
      "grad_norm": 0.08298205584287643,
      "learning_rate": 9.729633201185757e-06,
      "loss": 0.0001,
      "step": 71890
    },
    {
      "epoch": 7.703846565948784,
      "grad_norm": 0.003557771211490035,
      "learning_rate": 9.728204578734955e-06,
      "loss": 0.07,
      "step": 71900
    },
    {
      "epoch": 7.704918032786885,
      "grad_norm": 0.0002478702808730304,
      "learning_rate": 9.726775956284153e-06,
      "loss": 0.0,
      "step": 71910
    },
    {
      "epoch": 7.7059894996249865,
      "grad_norm": 0.0007101689698174596,
      "learning_rate": 9.725347333833352e-06,
      "loss": 0.0005,
      "step": 71920
    },
    {
      "epoch": 7.707060966463088,
      "grad_norm": 0.0005678395391441882,
      "learning_rate": 9.723918711382551e-06,
      "loss": 0.1453,
      "step": 71930
    },
    {
      "epoch": 7.70813243330119,
      "grad_norm": 0.027735767886042595,
      "learning_rate": 9.722490088931749e-06,
      "loss": 0.0004,
      "step": 71940
    },
    {
      "epoch": 7.709203900139291,
      "grad_norm": 0.09328096359968185,
      "learning_rate": 9.721061466480947e-06,
      "loss": 0.1332,
      "step": 71950
    },
    {
      "epoch": 7.710275366977392,
      "grad_norm": 0.00014633261889684945,
      "learning_rate": 9.719632844030144e-06,
      "loss": 0.0003,
      "step": 71960
    },
    {
      "epoch": 7.711346833815494,
      "grad_norm": 0.00014714774442836642,
      "learning_rate": 9.718204221579342e-06,
      "loss": 0.0,
      "step": 71970
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.011998724192380905,
      "learning_rate": 9.716775599128541e-06,
      "loss": 0.0,
      "step": 71980
    },
    {
      "epoch": 7.713489767491696,
      "grad_norm": 0.0001547420833958313,
      "learning_rate": 9.715346976677739e-06,
      "loss": 0.0,
      "step": 71990
    },
    {
      "epoch": 7.714561234329797,
      "grad_norm": 0.004604513291269541,
      "learning_rate": 9.713918354226939e-06,
      "loss": 0.0002,
      "step": 72000
    },
    {
      "epoch": 7.715632701167899,
      "grad_norm": 0.00017200295405928046,
      "learning_rate": 9.712489731776136e-06,
      "loss": 0.0,
      "step": 72010
    },
    {
      "epoch": 7.716704168006,
      "grad_norm": 0.0009392361389473081,
      "learning_rate": 9.711061109325334e-06,
      "loss": 0.0017,
      "step": 72020
    },
    {
      "epoch": 7.717775634844101,
      "grad_norm": 0.0001289086212636903,
      "learning_rate": 9.709632486874532e-06,
      "loss": 0.0532,
      "step": 72030
    },
    {
      "epoch": 7.7188471016822024,
      "grad_norm": 0.0002799576614052057,
      "learning_rate": 9.70820386442373e-06,
      "loss": 0.1723,
      "step": 72040
    },
    {
      "epoch": 7.7199185685203044,
      "grad_norm": 23.741422653198242,
      "learning_rate": 9.706775241972929e-06,
      "loss": 0.1647,
      "step": 72050
    },
    {
      "epoch": 7.720990035358406,
      "grad_norm": 0.00043942933552898467,
      "learning_rate": 9.705346619522126e-06,
      "loss": 0.1247,
      "step": 72060
    },
    {
      "epoch": 7.722061502196507,
      "grad_norm": 0.016680825501680374,
      "learning_rate": 9.703917997071326e-06,
      "loss": 0.0,
      "step": 72070
    },
    {
      "epoch": 7.723132969034609,
      "grad_norm": 67.42178344726562,
      "learning_rate": 9.702489374620523e-06,
      "loss": 0.2907,
      "step": 72080
    },
    {
      "epoch": 7.72420443587271,
      "grad_norm": 0.00020328322716522962,
      "learning_rate": 9.701060752169721e-06,
      "loss": 0.0,
      "step": 72090
    },
    {
      "epoch": 7.725275902710811,
      "grad_norm": 0.00016543081437703222,
      "learning_rate": 9.699632129718919e-06,
      "loss": 0.0001,
      "step": 72100
    },
    {
      "epoch": 7.726347369548913,
      "grad_norm": 0.014560907147824764,
      "learning_rate": 9.698203507268118e-06,
      "loss": 0.001,
      "step": 72110
    },
    {
      "epoch": 7.727418836387014,
      "grad_norm": 0.0001422400091541931,
      "learning_rate": 9.696774884817316e-06,
      "loss": 0.0027,
      "step": 72120
    },
    {
      "epoch": 7.728490303225115,
      "grad_norm": 0.004558122716844082,
      "learning_rate": 9.695346262366513e-06,
      "loss": 0.0,
      "step": 72130
    },
    {
      "epoch": 7.729561770063216,
      "grad_norm": 0.010966540314257145,
      "learning_rate": 9.693917639915713e-06,
      "loss": 0.0795,
      "step": 72140
    },
    {
      "epoch": 7.730633236901318,
      "grad_norm": 0.00647898530587554,
      "learning_rate": 9.69248901746491e-06,
      "loss": 0.1769,
      "step": 72150
    },
    {
      "epoch": 7.731704703739419,
      "grad_norm": 51.45551681518555,
      "learning_rate": 9.691060395014108e-06,
      "loss": 0.103,
      "step": 72160
    },
    {
      "epoch": 7.73277617057752,
      "grad_norm": 0.18736335635185242,
      "learning_rate": 9.689631772563307e-06,
      "loss": 0.0101,
      "step": 72170
    },
    {
      "epoch": 7.7338476374156215,
      "grad_norm": 0.00434479396790266,
      "learning_rate": 9.688203150112505e-06,
      "loss": 0.0001,
      "step": 72180
    },
    {
      "epoch": 7.7349191042537235,
      "grad_norm": 0.0001844280632212758,
      "learning_rate": 9.686774527661703e-06,
      "loss": 0.0001,
      "step": 72190
    },
    {
      "epoch": 7.735990571091825,
      "grad_norm": 0.00012928222713526338,
      "learning_rate": 9.6853459052109e-06,
      "loss": 0.0187,
      "step": 72200
    },
    {
      "epoch": 7.737062037929926,
      "grad_norm": 0.001171309151686728,
      "learning_rate": 9.6839172827601e-06,
      "loss": 0.1483,
      "step": 72210
    },
    {
      "epoch": 7.738133504768028,
      "grad_norm": 0.03265919163823128,
      "learning_rate": 9.682488660309297e-06,
      "loss": 0.0006,
      "step": 72220
    },
    {
      "epoch": 7.739204971606129,
      "grad_norm": 0.00014756550081074238,
      "learning_rate": 9.681060037858497e-06,
      "loss": 0.1148,
      "step": 72230
    },
    {
      "epoch": 7.74027643844423,
      "grad_norm": 0.44851478934288025,
      "learning_rate": 9.679631415407694e-06,
      "loss": 0.0002,
      "step": 72240
    },
    {
      "epoch": 7.741347905282332,
      "grad_norm": 0.0002221328904852271,
      "learning_rate": 9.678202792956892e-06,
      "loss": 0.366,
      "step": 72250
    },
    {
      "epoch": 7.742419372120433,
      "grad_norm": 0.00187332509085536,
      "learning_rate": 9.67677417050609e-06,
      "loss": 0.0,
      "step": 72260
    },
    {
      "epoch": 7.743490838958534,
      "grad_norm": 0.0037086724769324064,
      "learning_rate": 9.675345548055288e-06,
      "loss": 0.0001,
      "step": 72270
    },
    {
      "epoch": 7.744562305796635,
      "grad_norm": 0.000213689636439085,
      "learning_rate": 9.673916925604487e-06,
      "loss": 0.1921,
      "step": 72280
    },
    {
      "epoch": 7.745633772634737,
      "grad_norm": 0.00019144683028571308,
      "learning_rate": 9.672488303153685e-06,
      "loss": 0.0,
      "step": 72290
    },
    {
      "epoch": 7.746705239472838,
      "grad_norm": 0.00014789719716645777,
      "learning_rate": 9.671059680702884e-06,
      "loss": 0.0,
      "step": 72300
    },
    {
      "epoch": 7.7477767063109395,
      "grad_norm": 0.000329664908349514,
      "learning_rate": 9.669631058252082e-06,
      "loss": 0.0002,
      "step": 72310
    },
    {
      "epoch": 7.748848173149041,
      "grad_norm": 0.006134130526334047,
      "learning_rate": 9.66820243580128e-06,
      "loss": 0.1978,
      "step": 72320
    },
    {
      "epoch": 7.749919639987143,
      "grad_norm": 0.007707970216870308,
      "learning_rate": 9.666773813350477e-06,
      "loss": 0.0001,
      "step": 72330
    },
    {
      "epoch": 7.750991106825244,
      "grad_norm": 0.00017158522678073496,
      "learning_rate": 9.665345190899675e-06,
      "loss": 0.0001,
      "step": 72340
    },
    {
      "epoch": 7.752062573663345,
      "grad_norm": 158.4216766357422,
      "learning_rate": 9.663916568448874e-06,
      "loss": 0.0758,
      "step": 72350
    },
    {
      "epoch": 7.753134040501447,
      "grad_norm": 0.00030871457420289516,
      "learning_rate": 9.662487945998072e-06,
      "loss": 0.0806,
      "step": 72360
    },
    {
      "epoch": 7.754205507339548,
      "grad_norm": 0.0012457981938496232,
      "learning_rate": 9.661059323547271e-06,
      "loss": 0.0006,
      "step": 72370
    },
    {
      "epoch": 7.755276974177649,
      "grad_norm": 0.00017587705224286765,
      "learning_rate": 9.659630701096469e-06,
      "loss": 0.0,
      "step": 72380
    },
    {
      "epoch": 7.756348441015751,
      "grad_norm": 0.0002532387152314186,
      "learning_rate": 9.658202078645666e-06,
      "loss": 0.1193,
      "step": 72390
    },
    {
      "epoch": 7.757419907853852,
      "grad_norm": 0.006271363236010075,
      "learning_rate": 9.656773456194864e-06,
      "loss": 0.0006,
      "step": 72400
    },
    {
      "epoch": 7.758491374691953,
      "grad_norm": 0.0001504265092080459,
      "learning_rate": 9.655344833744063e-06,
      "loss": 0.0001,
      "step": 72410
    },
    {
      "epoch": 7.759562841530054,
      "grad_norm": 13.630698204040527,
      "learning_rate": 9.653916211293261e-06,
      "loss": 0.044,
      "step": 72420
    },
    {
      "epoch": 7.760634308368156,
      "grad_norm": 0.00019485267694108188,
      "learning_rate": 9.65248758884246e-06,
      "loss": 0.2912,
      "step": 72430
    },
    {
      "epoch": 7.7617057752062575,
      "grad_norm": 0.006220524664968252,
      "learning_rate": 9.651058966391658e-06,
      "loss": 0.1015,
      "step": 72440
    },
    {
      "epoch": 7.762777242044359,
      "grad_norm": 0.0023277716245502234,
      "learning_rate": 9.649630343940856e-06,
      "loss": 0.0008,
      "step": 72450
    },
    {
      "epoch": 7.76384870888246,
      "grad_norm": 0.00014699125313200057,
      "learning_rate": 9.648201721490053e-06,
      "loss": 0.0001,
      "step": 72460
    },
    {
      "epoch": 7.764920175720562,
      "grad_norm": 0.002075537806376815,
      "learning_rate": 9.646773099039253e-06,
      "loss": 0.0002,
      "step": 72470
    },
    {
      "epoch": 7.765991642558663,
      "grad_norm": 0.00014306488446891308,
      "learning_rate": 9.64534447658845e-06,
      "loss": 0.0124,
      "step": 72480
    },
    {
      "epoch": 7.767063109396764,
      "grad_norm": 0.0030602440237998962,
      "learning_rate": 9.643915854137648e-06,
      "loss": 0.2593,
      "step": 72490
    },
    {
      "epoch": 7.768134576234866,
      "grad_norm": 0.00014081889821682125,
      "learning_rate": 9.642487231686848e-06,
      "loss": 0.1828,
      "step": 72500
    },
    {
      "epoch": 7.769206043072967,
      "grad_norm": 0.004544184077531099,
      "learning_rate": 9.641058609236045e-06,
      "loss": 0.0001,
      "step": 72510
    },
    {
      "epoch": 7.770277509911068,
      "grad_norm": 0.00017599023703951389,
      "learning_rate": 9.639629986785243e-06,
      "loss": 0.0,
      "step": 72520
    },
    {
      "epoch": 7.771348976749169,
      "grad_norm": 0.00016300083370879292,
      "learning_rate": 9.63820136433444e-06,
      "loss": 0.0,
      "step": 72530
    },
    {
      "epoch": 7.772420443587271,
      "grad_norm": 0.00032100913813337684,
      "learning_rate": 9.63677274188364e-06,
      "loss": 0.1961,
      "step": 72540
    },
    {
      "epoch": 7.773491910425372,
      "grad_norm": 0.0010215810034424067,
      "learning_rate": 9.635344119432838e-06,
      "loss": 0.0001,
      "step": 72550
    },
    {
      "epoch": 7.7745633772634735,
      "grad_norm": 0.00016273753135465086,
      "learning_rate": 9.633915496982035e-06,
      "loss": 0.0011,
      "step": 72560
    },
    {
      "epoch": 7.775634844101575,
      "grad_norm": 0.4681820273399353,
      "learning_rate": 9.632486874531235e-06,
      "loss": 0.0002,
      "step": 72570
    },
    {
      "epoch": 7.776706310939677,
      "grad_norm": 0.0001535729825263843,
      "learning_rate": 9.631058252080432e-06,
      "loss": 0.0,
      "step": 72580
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 0.0001864280056906864,
      "learning_rate": 9.62962962962963e-06,
      "loss": 0.1765,
      "step": 72590
    },
    {
      "epoch": 7.778849244615879,
      "grad_norm": 0.006403376813977957,
      "learning_rate": 9.62820100717883e-06,
      "loss": 0.0001,
      "step": 72600
    },
    {
      "epoch": 7.779920711453981,
      "grad_norm": 0.00026688186335377395,
      "learning_rate": 9.626772384728027e-06,
      "loss": 0.0003,
      "step": 72610
    },
    {
      "epoch": 7.780992178292082,
      "grad_norm": 0.007459248881787062,
      "learning_rate": 9.625343762277225e-06,
      "loss": 0.2725,
      "step": 72620
    },
    {
      "epoch": 7.782063645130183,
      "grad_norm": 0.00016821103054098785,
      "learning_rate": 9.623915139826422e-06,
      "loss": 0.0059,
      "step": 72630
    },
    {
      "epoch": 7.783135111968285,
      "grad_norm": 0.0043646483682096004,
      "learning_rate": 9.622486517375622e-06,
      "loss": 0.0002,
      "step": 72640
    },
    {
      "epoch": 7.784206578806386,
      "grad_norm": 0.0002073982177535072,
      "learning_rate": 9.62105789492482e-06,
      "loss": 0.0001,
      "step": 72650
    },
    {
      "epoch": 7.785278045644487,
      "grad_norm": 0.009341674856841564,
      "learning_rate": 9.619629272474019e-06,
      "loss": 0.1573,
      "step": 72660
    },
    {
      "epoch": 7.786349512482588,
      "grad_norm": 0.008573882281780243,
      "learning_rate": 9.618200650023216e-06,
      "loss": 0.1481,
      "step": 72670
    },
    {
      "epoch": 7.78742097932069,
      "grad_norm": 0.00019191527098882943,
      "learning_rate": 9.616772027572414e-06,
      "loss": 0.1721,
      "step": 72680
    },
    {
      "epoch": 7.788492446158791,
      "grad_norm": 0.0011121885618194938,
      "learning_rate": 9.615343405121612e-06,
      "loss": 0.0002,
      "step": 72690
    },
    {
      "epoch": 7.7895639129968925,
      "grad_norm": 0.005553762894123793,
      "learning_rate": 9.61391478267081e-06,
      "loss": 0.1092,
      "step": 72700
    },
    {
      "epoch": 7.790635379834994,
      "grad_norm": 0.0019256430678069592,
      "learning_rate": 9.612486160220009e-06,
      "loss": 0.248,
      "step": 72710
    },
    {
      "epoch": 7.791706846673096,
      "grad_norm": 0.0002749532868620008,
      "learning_rate": 9.611057537769206e-06,
      "loss": 0.1082,
      "step": 72720
    },
    {
      "epoch": 7.792778313511197,
      "grad_norm": 76.09034729003906,
      "learning_rate": 9.609628915318406e-06,
      "loss": 0.1017,
      "step": 72730
    },
    {
      "epoch": 7.793849780349298,
      "grad_norm": 0.00020250566012691706,
      "learning_rate": 9.608200292867604e-06,
      "loss": 0.0291,
      "step": 72740
    },
    {
      "epoch": 7.7949212471874,
      "grad_norm": 0.012131393887102604,
      "learning_rate": 9.606771670416801e-06,
      "loss": 0.1951,
      "step": 72750
    },
    {
      "epoch": 7.795992714025501,
      "grad_norm": 0.0002425834391033277,
      "learning_rate": 9.605343047965999e-06,
      "loss": 0.2287,
      "step": 72760
    },
    {
      "epoch": 7.797064180863602,
      "grad_norm": 0.00029845625977031887,
      "learning_rate": 9.603914425515197e-06,
      "loss": 0.0064,
      "step": 72770
    },
    {
      "epoch": 7.798135647701704,
      "grad_norm": 0.00022902447381056845,
      "learning_rate": 9.602485803064396e-06,
      "loss": 0.2733,
      "step": 72780
    },
    {
      "epoch": 7.799207114539805,
      "grad_norm": 0.0048898737877607346,
      "learning_rate": 9.601057180613594e-06,
      "loss": 0.0001,
      "step": 72790
    },
    {
      "epoch": 7.800278581377906,
      "grad_norm": 0.0029288632795214653,
      "learning_rate": 9.599628558162793e-06,
      "loss": 0.2773,
      "step": 72800
    },
    {
      "epoch": 7.801350048216007,
      "grad_norm": 0.0043800147250294685,
      "learning_rate": 9.59819993571199e-06,
      "loss": 0.0633,
      "step": 72810
    },
    {
      "epoch": 7.802421515054109,
      "grad_norm": 0.8637372851371765,
      "learning_rate": 9.596771313261188e-06,
      "loss": 0.0015,
      "step": 72820
    },
    {
      "epoch": 7.8034929818922105,
      "grad_norm": 0.0017124706646427512,
      "learning_rate": 9.595342690810386e-06,
      "loss": 0.0006,
      "step": 72830
    },
    {
      "epoch": 7.804564448730312,
      "grad_norm": 0.05757194757461548,
      "learning_rate": 9.593914068359585e-06,
      "loss": 0.0008,
      "step": 72840
    },
    {
      "epoch": 7.805635915568413,
      "grad_norm": 0.08338187634944916,
      "learning_rate": 9.592485445908783e-06,
      "loss": 0.0004,
      "step": 72850
    },
    {
      "epoch": 7.806707382406515,
      "grad_norm": 0.0005813768948428333,
      "learning_rate": 9.59105682345798e-06,
      "loss": 0.0002,
      "step": 72860
    },
    {
      "epoch": 7.807778849244616,
      "grad_norm": 0.0004936158074997365,
      "learning_rate": 9.58962820100718e-06,
      "loss": 0.0001,
      "step": 72870
    },
    {
      "epoch": 7.808850316082717,
      "grad_norm": 0.0005700348410755396,
      "learning_rate": 9.588199578556378e-06,
      "loss": 0.0002,
      "step": 72880
    },
    {
      "epoch": 7.809921782920819,
      "grad_norm": 0.00041815039003267884,
      "learning_rate": 9.586770956105575e-06,
      "loss": 0.0002,
      "step": 72890
    },
    {
      "epoch": 7.81099324975892,
      "grad_norm": 0.0038140963297337294,
      "learning_rate": 9.585342333654775e-06,
      "loss": 0.2476,
      "step": 72900
    },
    {
      "epoch": 7.812064716597021,
      "grad_norm": 0.008602234534919262,
      "learning_rate": 9.583913711203972e-06,
      "loss": 0.0002,
      "step": 72910
    },
    {
      "epoch": 7.813136183435123,
      "grad_norm": 0.002415739931166172,
      "learning_rate": 9.58248508875317e-06,
      "loss": 0.0,
      "step": 72920
    },
    {
      "epoch": 7.814207650273224,
      "grad_norm": 0.0003898360300809145,
      "learning_rate": 9.581056466302368e-06,
      "loss": 0.0,
      "step": 72930
    },
    {
      "epoch": 7.815279117111325,
      "grad_norm": 0.005976071581244469,
      "learning_rate": 9.579627843851567e-06,
      "loss": 0.1756,
      "step": 72940
    },
    {
      "epoch": 7.8163505839494265,
      "grad_norm": 0.0024612629786133766,
      "learning_rate": 9.578199221400765e-06,
      "loss": 0.0002,
      "step": 72950
    },
    {
      "epoch": 7.8174220507875285,
      "grad_norm": 0.01776156760752201,
      "learning_rate": 9.576770598949964e-06,
      "loss": 0.0002,
      "step": 72960
    },
    {
      "epoch": 7.81849351762563,
      "grad_norm": 0.2842070162296295,
      "learning_rate": 9.575341976499162e-06,
      "loss": 0.0007,
      "step": 72970
    },
    {
      "epoch": 7.819564984463731,
      "grad_norm": 0.0002625219931360334,
      "learning_rate": 9.57391335404836e-06,
      "loss": 0.0001,
      "step": 72980
    },
    {
      "epoch": 7.820636451301832,
      "grad_norm": 0.0008501752745360136,
      "learning_rate": 9.572484731597557e-06,
      "loss": 0.0011,
      "step": 72990
    },
    {
      "epoch": 7.821707918139934,
      "grad_norm": 0.0058427960611879826,
      "learning_rate": 9.571056109146757e-06,
      "loss": 0.0991,
      "step": 73000
    },
    {
      "epoch": 7.822779384978035,
      "grad_norm": 0.19798478484153748,
      "learning_rate": 9.569627486695954e-06,
      "loss": 0.0004,
      "step": 73010
    },
    {
      "epoch": 7.823850851816136,
      "grad_norm": 0.0006892674718983471,
      "learning_rate": 9.568198864245154e-06,
      "loss": 0.0945,
      "step": 73020
    },
    {
      "epoch": 7.824922318654238,
      "grad_norm": 25.394845962524414,
      "learning_rate": 9.566770241794351e-06,
      "loss": 0.1275,
      "step": 73030
    },
    {
      "epoch": 7.825993785492339,
      "grad_norm": 0.008951659314334393,
      "learning_rate": 9.565341619343549e-06,
      "loss": 0.0035,
      "step": 73040
    },
    {
      "epoch": 7.82706525233044,
      "grad_norm": 0.0011198613792657852,
      "learning_rate": 9.563912996892747e-06,
      "loss": 0.1317,
      "step": 73050
    },
    {
      "epoch": 7.828136719168541,
      "grad_norm": 0.0004543823597487062,
      "learning_rate": 9.562484374441944e-06,
      "loss": 0.0002,
      "step": 73060
    },
    {
      "epoch": 7.829208186006643,
      "grad_norm": 0.0872286707162857,
      "learning_rate": 9.561055751991144e-06,
      "loss": 0.0001,
      "step": 73070
    },
    {
      "epoch": 7.8302796528447445,
      "grad_norm": 0.01390914898365736,
      "learning_rate": 9.559627129540341e-06,
      "loss": 0.0002,
      "step": 73080
    },
    {
      "epoch": 7.831351119682846,
      "grad_norm": 0.011649544350802898,
      "learning_rate": 9.55819850708954e-06,
      "loss": 0.0389,
      "step": 73090
    },
    {
      "epoch": 7.832422586520947,
      "grad_norm": 0.0012299616355448961,
      "learning_rate": 9.556769884638738e-06,
      "loss": 0.0001,
      "step": 73100
    },
    {
      "epoch": 7.833494053359049,
      "grad_norm": 0.00023163841979112476,
      "learning_rate": 9.555341262187936e-06,
      "loss": 0.0114,
      "step": 73110
    },
    {
      "epoch": 7.83456552019715,
      "grad_norm": 0.004174107685685158,
      "learning_rate": 9.553912639737134e-06,
      "loss": 0.1583,
      "step": 73120
    },
    {
      "epoch": 7.835636987035251,
      "grad_norm": 39.7619514465332,
      "learning_rate": 9.552484017286331e-06,
      "loss": 0.3293,
      "step": 73130
    },
    {
      "epoch": 7.836708453873353,
      "grad_norm": 71.81465911865234,
      "learning_rate": 9.55105539483553e-06,
      "loss": 0.2037,
      "step": 73140
    },
    {
      "epoch": 7.837779920711454,
      "grad_norm": 0.003400019835680723,
      "learning_rate": 9.549626772384728e-06,
      "loss": 0.0009,
      "step": 73150
    },
    {
      "epoch": 7.838851387549555,
      "grad_norm": 0.004595637787133455,
      "learning_rate": 9.548198149933928e-06,
      "loss": 0.053,
      "step": 73160
    },
    {
      "epoch": 7.839922854387657,
      "grad_norm": 0.000498811190482229,
      "learning_rate": 9.546769527483125e-06,
      "loss": 0.1627,
      "step": 73170
    },
    {
      "epoch": 7.840994321225758,
      "grad_norm": 0.0008070762269198895,
      "learning_rate": 9.545340905032323e-06,
      "loss": 0.0867,
      "step": 73180
    },
    {
      "epoch": 7.842065788063859,
      "grad_norm": 0.0031345542520284653,
      "learning_rate": 9.54391228258152e-06,
      "loss": 0.0086,
      "step": 73190
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 0.0003985320799984038,
      "learning_rate": 9.54248366013072e-06,
      "loss": 0.0007,
      "step": 73200
    },
    {
      "epoch": 7.8442087217400625,
      "grad_norm": 0.0019223635317757726,
      "learning_rate": 9.541055037679918e-06,
      "loss": 0.0001,
      "step": 73210
    },
    {
      "epoch": 7.845280188578164,
      "grad_norm": 0.0009109340608119965,
      "learning_rate": 9.539626415229116e-06,
      "loss": 0.0,
      "step": 73220
    },
    {
      "epoch": 7.846351655416265,
      "grad_norm": 0.0017446704441681504,
      "learning_rate": 9.538197792778315e-06,
      "loss": 0.0001,
      "step": 73230
    },
    {
      "epoch": 7.847423122254366,
      "grad_norm": 0.0020339726470410824,
      "learning_rate": 9.536769170327513e-06,
      "loss": 0.0297,
      "step": 73240
    },
    {
      "epoch": 7.848494589092468,
      "grad_norm": 0.0002638675505295396,
      "learning_rate": 9.53534054787671e-06,
      "loss": 0.0001,
      "step": 73250
    },
    {
      "epoch": 7.849566055930569,
      "grad_norm": 0.0034887297078967094,
      "learning_rate": 9.53391192542591e-06,
      "loss": 0.1595,
      "step": 73260
    },
    {
      "epoch": 7.85063752276867,
      "grad_norm": 0.0002562291920185089,
      "learning_rate": 9.532483302975107e-06,
      "loss": 0.1947,
      "step": 73270
    },
    {
      "epoch": 7.851708989606772,
      "grad_norm": 0.0003821707796305418,
      "learning_rate": 9.531054680524305e-06,
      "loss": 0.0055,
      "step": 73280
    },
    {
      "epoch": 7.852780456444873,
      "grad_norm": 0.00021717905474361032,
      "learning_rate": 9.529626058073503e-06,
      "loss": 0.3515,
      "step": 73290
    },
    {
      "epoch": 7.853851923282974,
      "grad_norm": 0.00026396120665594935,
      "learning_rate": 9.528197435622702e-06,
      "loss": 0.0,
      "step": 73300
    },
    {
      "epoch": 7.854923390121076,
      "grad_norm": 0.007418624125421047,
      "learning_rate": 9.5267688131719e-06,
      "loss": 0.0002,
      "step": 73310
    },
    {
      "epoch": 7.855994856959177,
      "grad_norm": 0.000195333210285753,
      "learning_rate": 9.525340190721099e-06,
      "loss": 0.0001,
      "step": 73320
    },
    {
      "epoch": 7.857066323797278,
      "grad_norm": 0.00023878682986833155,
      "learning_rate": 9.523911568270297e-06,
      "loss": 0.0,
      "step": 73330
    },
    {
      "epoch": 7.8581377906353795,
      "grad_norm": 0.0002752822474576533,
      "learning_rate": 9.522482945819494e-06,
      "loss": 0.0002,
      "step": 73340
    },
    {
      "epoch": 7.8592092574734815,
      "grad_norm": 0.032517436891794205,
      "learning_rate": 9.521054323368692e-06,
      "loss": 0.1349,
      "step": 73350
    },
    {
      "epoch": 7.860280724311583,
      "grad_norm": 0.010020398534834385,
      "learning_rate": 9.51962570091789e-06,
      "loss": 0.0006,
      "step": 73360
    },
    {
      "epoch": 7.861352191149684,
      "grad_norm": 0.0003946054494008422,
      "learning_rate": 9.518197078467089e-06,
      "loss": 0.0002,
      "step": 73370
    },
    {
      "epoch": 7.862423657987785,
      "grad_norm": 0.004700013902038336,
      "learning_rate": 9.516768456016288e-06,
      "loss": 0.0006,
      "step": 73380
    },
    {
      "epoch": 7.863495124825887,
      "grad_norm": 0.42018917202949524,
      "learning_rate": 9.515339833565486e-06,
      "loss": 0.0076,
      "step": 73390
    },
    {
      "epoch": 7.864566591663988,
      "grad_norm": 0.011330081149935722,
      "learning_rate": 9.513911211114684e-06,
      "loss": 0.0002,
      "step": 73400
    },
    {
      "epoch": 7.865638058502089,
      "grad_norm": 0.0001655356027185917,
      "learning_rate": 9.512482588663881e-06,
      "loss": 0.1611,
      "step": 73410
    },
    {
      "epoch": 7.866709525340191,
      "grad_norm": 0.17561669647693634,
      "learning_rate": 9.511053966213079e-06,
      "loss": 0.0004,
      "step": 73420
    },
    {
      "epoch": 7.867780992178292,
      "grad_norm": 0.0002120729477610439,
      "learning_rate": 9.509625343762277e-06,
      "loss": 0.0002,
      "step": 73430
    },
    {
      "epoch": 7.868852459016393,
      "grad_norm": 0.00016967197007033974,
      "learning_rate": 9.508196721311476e-06,
      "loss": 0.0756,
      "step": 73440
    },
    {
      "epoch": 7.869923925854495,
      "grad_norm": 53.94624710083008,
      "learning_rate": 9.506768098860676e-06,
      "loss": 0.1517,
      "step": 73450
    },
    {
      "epoch": 7.870995392692596,
      "grad_norm": 0.00012590317055583,
      "learning_rate": 9.505339476409873e-06,
      "loss": 0.0001,
      "step": 73460
    },
    {
      "epoch": 7.8720668595306975,
      "grad_norm": 0.009053717367351055,
      "learning_rate": 9.503910853959071e-06,
      "loss": 0.1279,
      "step": 73470
    },
    {
      "epoch": 7.873138326368799,
      "grad_norm": 0.06606083363294601,
      "learning_rate": 9.502482231508269e-06,
      "loss": 0.1965,
      "step": 73480
    },
    {
      "epoch": 7.874209793206901,
      "grad_norm": 0.0002769084239844233,
      "learning_rate": 9.501053609057466e-06,
      "loss": 0.0009,
      "step": 73490
    },
    {
      "epoch": 7.875281260045002,
      "grad_norm": 0.0001968960277736187,
      "learning_rate": 9.499624986606666e-06,
      "loss": 0.0,
      "step": 73500
    },
    {
      "epoch": 7.876352726883103,
      "grad_norm": 0.006147992797195911,
      "learning_rate": 9.498196364155863e-06,
      "loss": 0.0002,
      "step": 73510
    },
    {
      "epoch": 7.877424193721204,
      "grad_norm": 0.00015469406207557768,
      "learning_rate": 9.496767741705063e-06,
      "loss": 0.1969,
      "step": 73520
    },
    {
      "epoch": 7.878495660559306,
      "grad_norm": 0.000606678775511682,
      "learning_rate": 9.49533911925426e-06,
      "loss": 0.0021,
      "step": 73530
    },
    {
      "epoch": 7.879567127397407,
      "grad_norm": 0.0040923915803432465,
      "learning_rate": 9.493910496803458e-06,
      "loss": 0.0005,
      "step": 73540
    },
    {
      "epoch": 7.880638594235508,
      "grad_norm": 0.00023868863354437053,
      "learning_rate": 9.492481874352656e-06,
      "loss": 0.0007,
      "step": 73550
    },
    {
      "epoch": 7.88171006107361,
      "grad_norm": 0.299174040555954,
      "learning_rate": 9.491053251901853e-06,
      "loss": 0.3646,
      "step": 73560
    },
    {
      "epoch": 7.882781527911711,
      "grad_norm": 0.00015396630624309182,
      "learning_rate": 9.489624629451053e-06,
      "loss": 0.0001,
      "step": 73570
    },
    {
      "epoch": 7.883852994749812,
      "grad_norm": 0.003348309313878417,
      "learning_rate": 9.48819600700025e-06,
      "loss": 0.1308,
      "step": 73580
    },
    {
      "epoch": 7.8849244615879135,
      "grad_norm": 0.0034041840117424726,
      "learning_rate": 9.48676738454945e-06,
      "loss": 0.0001,
      "step": 73590
    },
    {
      "epoch": 7.8859959284260155,
      "grad_norm": 0.0001575755450176075,
      "learning_rate": 9.485338762098647e-06,
      "loss": 0.0001,
      "step": 73600
    },
    {
      "epoch": 7.887067395264117,
      "grad_norm": 0.22986391186714172,
      "learning_rate": 9.483910139647845e-06,
      "loss": 0.0009,
      "step": 73610
    },
    {
      "epoch": 7.888138862102218,
      "grad_norm": 0.01833397150039673,
      "learning_rate": 9.482481517197043e-06,
      "loss": 0.1225,
      "step": 73620
    },
    {
      "epoch": 7.889210328940319,
      "grad_norm": 0.013286965899169445,
      "learning_rate": 9.481052894746242e-06,
      "loss": 0.1611,
      "step": 73630
    },
    {
      "epoch": 7.890281795778421,
      "grad_norm": 0.00208658236078918,
      "learning_rate": 9.47962427229544e-06,
      "loss": 0.0001,
      "step": 73640
    },
    {
      "epoch": 7.891353262616522,
      "grad_norm": 0.0017090961337089539,
      "learning_rate": 9.478195649844637e-06,
      "loss": 0.2456,
      "step": 73650
    },
    {
      "epoch": 7.892424729454623,
      "grad_norm": 0.00020489993039518595,
      "learning_rate": 9.476767027393837e-06,
      "loss": 0.0001,
      "step": 73660
    },
    {
      "epoch": 7.893496196292725,
      "grad_norm": 0.00016833779227454215,
      "learning_rate": 9.475338404943035e-06,
      "loss": 0.0,
      "step": 73670
    },
    {
      "epoch": 7.894567663130826,
      "grad_norm": 0.00023484116536565125,
      "learning_rate": 9.473909782492232e-06,
      "loss": 0.0008,
      "step": 73680
    },
    {
      "epoch": 7.895639129968927,
      "grad_norm": 0.00021754104818683118,
      "learning_rate": 9.472481160041432e-06,
      "loss": 0.0,
      "step": 73690
    },
    {
      "epoch": 7.896710596807029,
      "grad_norm": 0.00020455929916352034,
      "learning_rate": 9.47105253759063e-06,
      "loss": 0.0,
      "step": 73700
    },
    {
      "epoch": 7.89778206364513,
      "grad_norm": 0.00023198720009531826,
      "learning_rate": 9.469623915139827e-06,
      "loss": 0.2192,
      "step": 73710
    },
    {
      "epoch": 7.8988535304832315,
      "grad_norm": 0.00034492069971747696,
      "learning_rate": 9.468195292689025e-06,
      "loss": 0.0004,
      "step": 73720
    },
    {
      "epoch": 7.899924997321333,
      "grad_norm": 0.0020759967155754566,
      "learning_rate": 9.466766670238224e-06,
      "loss": 0.004,
      "step": 73730
    },
    {
      "epoch": 7.900996464159435,
      "grad_norm": 0.0003447030030656606,
      "learning_rate": 9.465338047787422e-06,
      "loss": 0.0198,
      "step": 73740
    },
    {
      "epoch": 7.902067930997536,
      "grad_norm": 0.026580408215522766,
      "learning_rate": 9.463909425336621e-06,
      "loss": 0.0001,
      "step": 73750
    },
    {
      "epoch": 7.903139397835637,
      "grad_norm": 0.003837435506284237,
      "learning_rate": 9.462480802885819e-06,
      "loss": 0.0,
      "step": 73760
    },
    {
      "epoch": 7.904210864673738,
      "grad_norm": 1.1488224267959595,
      "learning_rate": 9.461052180435016e-06,
      "loss": 0.0003,
      "step": 73770
    },
    {
      "epoch": 7.90528233151184,
      "grad_norm": 0.00017467622819822282,
      "learning_rate": 9.459623557984214e-06,
      "loss": 0.0001,
      "step": 73780
    },
    {
      "epoch": 7.906353798349941,
      "grad_norm": 0.00554087245836854,
      "learning_rate": 9.458194935533412e-06,
      "loss": 0.0001,
      "step": 73790
    },
    {
      "epoch": 7.907425265188042,
      "grad_norm": 0.0005817082128487527,
      "learning_rate": 9.456766313082611e-06,
      "loss": 0.1135,
      "step": 73800
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 0.00024103028408717364,
      "learning_rate": 9.455337690631809e-06,
      "loss": 0.0002,
      "step": 73810
    },
    {
      "epoch": 7.909568198864245,
      "grad_norm": 0.000184066710062325,
      "learning_rate": 9.453909068181008e-06,
      "loss": 0.0001,
      "step": 73820
    },
    {
      "epoch": 7.910639665702346,
      "grad_norm": 0.00021506189659703523,
      "learning_rate": 9.452480445730206e-06,
      "loss": 0.0,
      "step": 73830
    },
    {
      "epoch": 7.911711132540448,
      "grad_norm": 0.00020327676611486822,
      "learning_rate": 9.451051823279403e-06,
      "loss": 0.0002,
      "step": 73840
    },
    {
      "epoch": 7.912782599378549,
      "grad_norm": 0.0003204373933840543,
      "learning_rate": 9.449623200828601e-06,
      "loss": 0.0,
      "step": 73850
    },
    {
      "epoch": 7.9138540662166506,
      "grad_norm": 0.0011611365480348468,
      "learning_rate": 9.448194578377799e-06,
      "loss": 0.0251,
      "step": 73860
    },
    {
      "epoch": 7.914925533054752,
      "grad_norm": 0.0001644991571083665,
      "learning_rate": 9.446765955926998e-06,
      "loss": 0.0,
      "step": 73870
    },
    {
      "epoch": 7.915996999892854,
      "grad_norm": 0.0017961087869480252,
      "learning_rate": 9.445337333476196e-06,
      "loss": 0.0001,
      "step": 73880
    },
    {
      "epoch": 7.917068466730955,
      "grad_norm": 0.00023281890025828034,
      "learning_rate": 9.443908711025395e-06,
      "loss": 0.0,
      "step": 73890
    },
    {
      "epoch": 7.918139933569056,
      "grad_norm": 0.0001630814076634124,
      "learning_rate": 9.442480088574593e-06,
      "loss": 0.2964,
      "step": 73900
    },
    {
      "epoch": 7.919211400407157,
      "grad_norm": 0.003906771074980497,
      "learning_rate": 9.44105146612379e-06,
      "loss": 0.4791,
      "step": 73910
    },
    {
      "epoch": 7.920282867245259,
      "grad_norm": 0.002780228853225708,
      "learning_rate": 9.439622843672988e-06,
      "loss": 0.0002,
      "step": 73920
    },
    {
      "epoch": 7.92135433408336,
      "grad_norm": 0.00012654693273361772,
      "learning_rate": 9.438194221222188e-06,
      "loss": 0.0012,
      "step": 73930
    },
    {
      "epoch": 7.922425800921461,
      "grad_norm": 0.0001453206641599536,
      "learning_rate": 9.436765598771385e-06,
      "loss": 0.0005,
      "step": 73940
    },
    {
      "epoch": 7.923497267759563,
      "grad_norm": 0.003857075935229659,
      "learning_rate": 9.435336976320585e-06,
      "loss": 0.0023,
      "step": 73950
    },
    {
      "epoch": 7.924568734597664,
      "grad_norm": 0.00014890942838974297,
      "learning_rate": 9.433908353869782e-06,
      "loss": 0.0001,
      "step": 73960
    },
    {
      "epoch": 7.925640201435765,
      "grad_norm": 0.339267760515213,
      "learning_rate": 9.43247973141898e-06,
      "loss": 0.0551,
      "step": 73970
    },
    {
      "epoch": 7.926711668273867,
      "grad_norm": 0.0023367104586213827,
      "learning_rate": 9.431051108968178e-06,
      "loss": 0.2923,
      "step": 73980
    },
    {
      "epoch": 7.9277831351119685,
      "grad_norm": 0.0001504377432866022,
      "learning_rate": 9.429622486517377e-06,
      "loss": 0.2541,
      "step": 73990
    },
    {
      "epoch": 7.92885460195007,
      "grad_norm": 0.008595539256930351,
      "learning_rate": 9.428193864066575e-06,
      "loss": 0.0002,
      "step": 74000
    },
    {
      "epoch": 7.929926068788171,
      "grad_norm": 0.03825768455862999,
      "learning_rate": 9.426765241615772e-06,
      "loss": 0.0022,
      "step": 74010
    },
    {
      "epoch": 7.930997535626273,
      "grad_norm": 16.218835830688477,
      "learning_rate": 9.425336619164972e-06,
      "loss": 0.2381,
      "step": 74020
    },
    {
      "epoch": 7.932069002464374,
      "grad_norm": 0.00033148578950203955,
      "learning_rate": 9.42390799671417e-06,
      "loss": 0.0762,
      "step": 74030
    },
    {
      "epoch": 7.933140469302475,
      "grad_norm": 0.014597979374229908,
      "learning_rate": 9.422479374263367e-06,
      "loss": 0.0003,
      "step": 74040
    },
    {
      "epoch": 7.934211936140576,
      "grad_norm": 0.0005897182854823768,
      "learning_rate": 9.421050751812566e-06,
      "loss": 0.0002,
      "step": 74050
    },
    {
      "epoch": 7.935283402978678,
      "grad_norm": 0.35587674379348755,
      "learning_rate": 9.419622129361764e-06,
      "loss": 0.0011,
      "step": 74060
    },
    {
      "epoch": 7.936354869816779,
      "grad_norm": 0.018032949417829514,
      "learning_rate": 9.418193506910962e-06,
      "loss": 0.0605,
      "step": 74070
    },
    {
      "epoch": 7.93742633665488,
      "grad_norm": 0.016372868791222572,
      "learning_rate": 9.41676488446016e-06,
      "loss": 0.1489,
      "step": 74080
    },
    {
      "epoch": 7.938497803492982,
      "grad_norm": 0.00015802960842847824,
      "learning_rate": 9.415336262009359e-06,
      "loss": 0.0072,
      "step": 74090
    },
    {
      "epoch": 7.939569270331083,
      "grad_norm": 0.003460522508248687,
      "learning_rate": 9.413907639558556e-06,
      "loss": 0.1367,
      "step": 74100
    },
    {
      "epoch": 7.9406407371691845,
      "grad_norm": 0.016888892278075218,
      "learning_rate": 9.412479017107756e-06,
      "loss": 0.0,
      "step": 74110
    },
    {
      "epoch": 7.941712204007286,
      "grad_norm": 0.31042611598968506,
      "learning_rate": 9.411050394656953e-06,
      "loss": 0.0002,
      "step": 74120
    },
    {
      "epoch": 7.942783670845388,
      "grad_norm": 0.007899233140051365,
      "learning_rate": 9.409621772206151e-06,
      "loss": 0.0001,
      "step": 74130
    },
    {
      "epoch": 7.943855137683489,
      "grad_norm": 0.016099439933896065,
      "learning_rate": 9.408193149755349e-06,
      "loss": 0.0036,
      "step": 74140
    },
    {
      "epoch": 7.94492660452159,
      "grad_norm": 0.00014475111674983054,
      "learning_rate": 9.406764527304547e-06,
      "loss": 0.0487,
      "step": 74150
    },
    {
      "epoch": 7.945998071359691,
      "grad_norm": 0.0026991451159119606,
      "learning_rate": 9.405335904853746e-06,
      "loss": 0.0012,
      "step": 74160
    },
    {
      "epoch": 7.947069538197793,
      "grad_norm": 0.00025474836002103984,
      "learning_rate": 9.403907282402944e-06,
      "loss": 0.0002,
      "step": 74170
    },
    {
      "epoch": 7.948141005035894,
      "grad_norm": 0.0001547760039102286,
      "learning_rate": 9.402478659952143e-06,
      "loss": 0.0,
      "step": 74180
    },
    {
      "epoch": 7.949212471873995,
      "grad_norm": 0.0003115762665402144,
      "learning_rate": 9.40105003750134e-06,
      "loss": 0.1177,
      "step": 74190
    },
    {
      "epoch": 7.950283938712097,
      "grad_norm": 0.00010229305917164311,
      "learning_rate": 9.399621415050538e-06,
      "loss": 0.172,
      "step": 74200
    },
    {
      "epoch": 7.951355405550198,
      "grad_norm": 0.0035033710300922394,
      "learning_rate": 9.398192792599736e-06,
      "loss": 0.0005,
      "step": 74210
    },
    {
      "epoch": 7.952426872388299,
      "grad_norm": 0.6977677941322327,
      "learning_rate": 9.396764170148934e-06,
      "loss": 0.0008,
      "step": 74220
    },
    {
      "epoch": 7.953498339226401,
      "grad_norm": 9.143026545643806e-05,
      "learning_rate": 9.395335547698133e-06,
      "loss": 0.0,
      "step": 74230
    },
    {
      "epoch": 7.9545698060645025,
      "grad_norm": 0.00010984327673213556,
      "learning_rate": 9.39390692524733e-06,
      "loss": 0.0016,
      "step": 74240
    },
    {
      "epoch": 7.955641272902604,
      "grad_norm": 0.00012204149243189022,
      "learning_rate": 9.39247830279653e-06,
      "loss": 0.0002,
      "step": 74250
    },
    {
      "epoch": 7.956712739740705,
      "grad_norm": 0.00010512540757190436,
      "learning_rate": 9.391049680345728e-06,
      "loss": 0.0004,
      "step": 74260
    },
    {
      "epoch": 7.957784206578807,
      "grad_norm": 0.00011394615285098553,
      "learning_rate": 9.389621057894925e-06,
      "loss": 0.2588,
      "step": 74270
    },
    {
      "epoch": 7.958855673416908,
      "grad_norm": 0.0030536327976733446,
      "learning_rate": 9.388192435444123e-06,
      "loss": 0.0001,
      "step": 74280
    },
    {
      "epoch": 7.959927140255009,
      "grad_norm": 8.991151116788387e-05,
      "learning_rate": 9.386763812993322e-06,
      "loss": 0.0001,
      "step": 74290
    },
    {
      "epoch": 7.96099860709311,
      "grad_norm": 0.004313299898058176,
      "learning_rate": 9.38533519054252e-06,
      "loss": 0.0001,
      "step": 74300
    },
    {
      "epoch": 7.962070073931212,
      "grad_norm": 0.002243600320070982,
      "learning_rate": 9.383906568091718e-06,
      "loss": 0.0001,
      "step": 74310
    },
    {
      "epoch": 7.963141540769313,
      "grad_norm": 0.005610709078609943,
      "learning_rate": 9.382477945640917e-06,
      "loss": 0.0001,
      "step": 74320
    },
    {
      "epoch": 7.964213007607414,
      "grad_norm": 0.00011673472181428224,
      "learning_rate": 9.381049323190115e-06,
      "loss": 0.0006,
      "step": 74330
    },
    {
      "epoch": 7.965284474445516,
      "grad_norm": 0.016639698296785355,
      "learning_rate": 9.379620700739312e-06,
      "loss": 0.0031,
      "step": 74340
    },
    {
      "epoch": 7.966355941283617,
      "grad_norm": 0.00030379637610167265,
      "learning_rate": 9.37819207828851e-06,
      "loss": 0.0001,
      "step": 74350
    },
    {
      "epoch": 7.9674274081217185,
      "grad_norm": 9.213088196702302e-05,
      "learning_rate": 9.37676345583771e-06,
      "loss": 0.0,
      "step": 74360
    },
    {
      "epoch": 7.9684988749598205,
      "grad_norm": 0.004166711121797562,
      "learning_rate": 9.375334833386907e-06,
      "loss": 0.0,
      "step": 74370
    },
    {
      "epoch": 7.969570341797922,
      "grad_norm": 9.491816308582202e-05,
      "learning_rate": 9.373906210936105e-06,
      "loss": 0.0001,
      "step": 74380
    },
    {
      "epoch": 7.970641808636023,
      "grad_norm": 0.00011387615813873708,
      "learning_rate": 9.372477588485304e-06,
      "loss": 0.0,
      "step": 74390
    },
    {
      "epoch": 7.971713275474124,
      "grad_norm": 0.013573293574154377,
      "learning_rate": 9.371048966034502e-06,
      "loss": 0.0,
      "step": 74400
    },
    {
      "epoch": 7.972784742312226,
      "grad_norm": 0.0017732667038217187,
      "learning_rate": 9.3696203435837e-06,
      "loss": 0.0005,
      "step": 74410
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 7.841937622288242e-05,
      "learning_rate": 9.368191721132899e-06,
      "loss": 0.0,
      "step": 74420
    },
    {
      "epoch": 7.974927675988428,
      "grad_norm": 0.0001439304614905268,
      "learning_rate": 9.366763098682097e-06,
      "loss": 0.0011,
      "step": 74430
    },
    {
      "epoch": 7.975999142826529,
      "grad_norm": 0.00021593979909084737,
      "learning_rate": 9.365334476231294e-06,
      "loss": 0.0,
      "step": 74440
    },
    {
      "epoch": 7.977070609664631,
      "grad_norm": 0.013418872840702534,
      "learning_rate": 9.363905853780492e-06,
      "loss": 0.0,
      "step": 74450
    },
    {
      "epoch": 7.978142076502732,
      "grad_norm": 0.0001088228018488735,
      "learning_rate": 9.362477231329691e-06,
      "loss": 0.2329,
      "step": 74460
    },
    {
      "epoch": 7.979213543340833,
      "grad_norm": 0.0008231036481447518,
      "learning_rate": 9.361048608878889e-06,
      "loss": 0.0001,
      "step": 74470
    },
    {
      "epoch": 7.980285010178935,
      "grad_norm": 0.030286679044365883,
      "learning_rate": 9.359619986428088e-06,
      "loss": 0.0001,
      "step": 74480
    },
    {
      "epoch": 7.981356477017036,
      "grad_norm": 8.919733227230608e-05,
      "learning_rate": 9.358191363977286e-06,
      "loss": 0.0002,
      "step": 74490
    },
    {
      "epoch": 7.9824279438551375,
      "grad_norm": 7.22749246051535e-05,
      "learning_rate": 9.356762741526484e-06,
      "loss": 0.0,
      "step": 74500
    },
    {
      "epoch": 7.9834994106932395,
      "grad_norm": 7.81298876972869e-05,
      "learning_rate": 9.355334119075681e-06,
      "loss": 0.0001,
      "step": 74510
    },
    {
      "epoch": 7.984570877531341,
      "grad_norm": 8.757313480600715e-05,
      "learning_rate": 9.35390549662488e-06,
      "loss": 0.0003,
      "step": 74520
    },
    {
      "epoch": 7.985642344369442,
      "grad_norm": 0.00017986874445341527,
      "learning_rate": 9.352476874174078e-06,
      "loss": 0.0005,
      "step": 74530
    },
    {
      "epoch": 7.986713811207543,
      "grad_norm": 8.417394565185532e-05,
      "learning_rate": 9.351048251723278e-06,
      "loss": 0.0,
      "step": 74540
    },
    {
      "epoch": 7.987785278045645,
      "grad_norm": 0.00011207599163753912,
      "learning_rate": 9.349619629272475e-06,
      "loss": 0.3239,
      "step": 74550
    },
    {
      "epoch": 7.988856744883746,
      "grad_norm": 0.00011531652853591368,
      "learning_rate": 9.348191006821673e-06,
      "loss": 0.0001,
      "step": 74560
    },
    {
      "epoch": 7.989928211721847,
      "grad_norm": 0.000129652107716538,
      "learning_rate": 9.34676238437087e-06,
      "loss": 0.1879,
      "step": 74570
    },
    {
      "epoch": 7.990999678559948,
      "grad_norm": 0.0001324393815593794,
      "learning_rate": 9.345333761920068e-06,
      "loss": 0.0,
      "step": 74580
    },
    {
      "epoch": 7.99207114539805,
      "grad_norm": 0.00012254755711182952,
      "learning_rate": 9.343905139469268e-06,
      "loss": 0.0,
      "step": 74590
    },
    {
      "epoch": 7.993142612236151,
      "grad_norm": 0.00012461229925975204,
      "learning_rate": 9.342476517018465e-06,
      "loss": 0.0,
      "step": 74600
    },
    {
      "epoch": 7.994214079074252,
      "grad_norm": 0.0001129781812778674,
      "learning_rate": 9.341047894567665e-06,
      "loss": 0.0,
      "step": 74610
    },
    {
      "epoch": 7.995285545912354,
      "grad_norm": 0.0001783684128895402,
      "learning_rate": 9.339619272116863e-06,
      "loss": 0.0,
      "step": 74620
    },
    {
      "epoch": 7.9963570127504555,
      "grad_norm": 0.0017262175679206848,
      "learning_rate": 9.33819064966606e-06,
      "loss": 0.0,
      "step": 74630
    },
    {
      "epoch": 7.997428479588557,
      "grad_norm": 0.00011555053060874343,
      "learning_rate": 9.336762027215258e-06,
      "loss": 0.0001,
      "step": 74640
    },
    {
      "epoch": 7.998499946426658,
      "grad_norm": 0.0018519038567319512,
      "learning_rate": 9.335333404764456e-06,
      "loss": 0.0,
      "step": 74650
    },
    {
      "epoch": 7.99957141326476,
      "grad_norm": 0.00010952205047942698,
      "learning_rate": 9.333904782313655e-06,
      "loss": 0.0,
      "step": 74660
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9753333333333334,
      "eval_f1": 0.9009370816599731,
      "eval_loss": 0.18885797262191772,
      "eval_precision": 0.9131614654002713,
      "eval_recall": 0.8890356671070013,
      "eval_runtime": 393.8028,
      "eval_samples_per_second": 15.236,
      "eval_steps_per_second": 5.079,
      "step": 74664
    },
    {
      "epoch": 8.00064288010286,
      "grad_norm": 0.001164796412922442,
      "learning_rate": 9.332476159862853e-06,
      "loss": 0.2086,
      "step": 74670
    },
    {
      "epoch": 8.001714346940963,
      "grad_norm": 0.0009754528873600066,
      "learning_rate": 9.331047537412052e-06,
      "loss": 0.0001,
      "step": 74680
    },
    {
      "epoch": 8.002785813779063,
      "grad_norm": 0.0014586546458303928,
      "learning_rate": 9.32961891496125e-06,
      "loss": 0.0004,
      "step": 74690
    },
    {
      "epoch": 8.003857280617165,
      "grad_norm": 0.00013570096052717417,
      "learning_rate": 9.328190292510447e-06,
      "loss": 0.2392,
      "step": 74700
    },
    {
      "epoch": 8.004928747455267,
      "grad_norm": 0.0003038758004549891,
      "learning_rate": 9.326761670059645e-06,
      "loss": 0.0002,
      "step": 74710
    },
    {
      "epoch": 8.006000214293367,
      "grad_norm": 0.00017353545990772545,
      "learning_rate": 9.325333047608844e-06,
      "loss": 0.0001,
      "step": 74720
    },
    {
      "epoch": 8.00707168113147,
      "grad_norm": 0.0026771097909659147,
      "learning_rate": 9.323904425158042e-06,
      "loss": 0.1818,
      "step": 74730
    },
    {
      "epoch": 8.00814314796957,
      "grad_norm": 0.0001526276028016582,
      "learning_rate": 9.32247580270724e-06,
      "loss": 0.1759,
      "step": 74740
    },
    {
      "epoch": 8.009214614807671,
      "grad_norm": 0.0026141225825995207,
      "learning_rate": 9.321047180256439e-06,
      "loss": 0.1504,
      "step": 74750
    },
    {
      "epoch": 8.010286081645773,
      "grad_norm": 0.00038862202200107276,
      "learning_rate": 9.319618557805637e-06,
      "loss": 0.0001,
      "step": 74760
    },
    {
      "epoch": 8.011357548483874,
      "grad_norm": 0.0001875224697869271,
      "learning_rate": 9.318189935354834e-06,
      "loss": 0.0001,
      "step": 74770
    },
    {
      "epoch": 8.012429015321976,
      "grad_norm": 0.03622390702366829,
      "learning_rate": 9.316761312904034e-06,
      "loss": 0.0001,
      "step": 74780
    },
    {
      "epoch": 8.013500482160078,
      "grad_norm": 0.023820068687200546,
      "learning_rate": 9.315332690453231e-06,
      "loss": 0.0007,
      "step": 74790
    },
    {
      "epoch": 8.014571948998178,
      "grad_norm": 0.00019454221182968467,
      "learning_rate": 9.313904068002429e-06,
      "loss": 0.0001,
      "step": 74800
    },
    {
      "epoch": 8.01564341583628,
      "grad_norm": 0.004499063827097416,
      "learning_rate": 9.312475445551627e-06,
      "loss": 0.0001,
      "step": 74810
    },
    {
      "epoch": 8.016714882674382,
      "grad_norm": 0.000172429732629098,
      "learning_rate": 9.311046823100826e-06,
      "loss": 0.0001,
      "step": 74820
    },
    {
      "epoch": 8.017786349512482,
      "grad_norm": 0.00024995231069624424,
      "learning_rate": 9.309618200650024e-06,
      "loss": 0.0001,
      "step": 74830
    },
    {
      "epoch": 8.018857816350584,
      "grad_norm": 0.0007385484641417861,
      "learning_rate": 9.308189578199223e-06,
      "loss": 0.0,
      "step": 74840
    },
    {
      "epoch": 8.019929283188686,
      "grad_norm": 0.00013986177509650588,
      "learning_rate": 9.306760955748421e-06,
      "loss": 0.0,
      "step": 74850
    },
    {
      "epoch": 8.021000750026786,
      "grad_norm": 0.0002145919861504808,
      "learning_rate": 9.305332333297619e-06,
      "loss": 0.0,
      "step": 74860
    },
    {
      "epoch": 8.022072216864888,
      "grad_norm": 0.0029016213957220316,
      "learning_rate": 9.303903710846816e-06,
      "loss": 0.1979,
      "step": 74870
    },
    {
      "epoch": 8.023143683702989,
      "grad_norm": 0.005374687723815441,
      "learning_rate": 9.302475088396014e-06,
      "loss": 0.0017,
      "step": 74880
    },
    {
      "epoch": 8.02421515054109,
      "grad_norm": 0.00010994995682267472,
      "learning_rate": 9.301046465945213e-06,
      "loss": 0.0005,
      "step": 74890
    },
    {
      "epoch": 8.025286617379193,
      "grad_norm": 0.000106464431155473,
      "learning_rate": 9.299617843494413e-06,
      "loss": 0.1348,
      "step": 74900
    },
    {
      "epoch": 8.026358084217293,
      "grad_norm": 0.0030827319715172052,
      "learning_rate": 9.29818922104361e-06,
      "loss": 0.0,
      "step": 74910
    },
    {
      "epoch": 8.027429551055395,
      "grad_norm": 0.0001044284290401265,
      "learning_rate": 9.296760598592808e-06,
      "loss": 0.0,
      "step": 74920
    },
    {
      "epoch": 8.028501017893497,
      "grad_norm": 0.0006391710485331714,
      "learning_rate": 9.295331976142006e-06,
      "loss": 0.0008,
      "step": 74930
    },
    {
      "epoch": 8.029572484731597,
      "grad_norm": 9.988439705921337e-05,
      "learning_rate": 9.293903353691203e-06,
      "loss": 0.5141,
      "step": 74940
    },
    {
      "epoch": 8.030643951569699,
      "grad_norm": 0.5031067728996277,
      "learning_rate": 9.292474731240401e-06,
      "loss": 0.1399,
      "step": 74950
    },
    {
      "epoch": 8.031715418407801,
      "grad_norm": 9.477345884079114e-05,
      "learning_rate": 9.2910461087896e-06,
      "loss": 0.0001,
      "step": 74960
    },
    {
      "epoch": 8.032786885245901,
      "grad_norm": 0.051746077835559845,
      "learning_rate": 9.2896174863388e-06,
      "loss": 0.3751,
      "step": 74970
    },
    {
      "epoch": 8.033858352084003,
      "grad_norm": 0.00020495564967859536,
      "learning_rate": 9.288188863887997e-06,
      "loss": 0.0002,
      "step": 74980
    },
    {
      "epoch": 8.034929818922105,
      "grad_norm": 0.00025237209047190845,
      "learning_rate": 9.286760241437195e-06,
      "loss": 0.1976,
      "step": 74990
    },
    {
      "epoch": 8.036001285760205,
      "grad_norm": 0.005535387434065342,
      "learning_rate": 9.285331618986393e-06,
      "loss": 0.1165,
      "step": 75000
    },
    {
      "epoch": 8.037072752598307,
      "grad_norm": 0.01014198549091816,
      "learning_rate": 9.28390299653559e-06,
      "loss": 0.086,
      "step": 75010
    },
    {
      "epoch": 8.038144219436408,
      "grad_norm": 0.0013947243569418788,
      "learning_rate": 9.28247437408479e-06,
      "loss": 0.0004,
      "step": 75020
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 0.007099925074726343,
      "learning_rate": 9.281045751633987e-06,
      "loss": 0.0005,
      "step": 75030
    },
    {
      "epoch": 8.040287153112612,
      "grad_norm": 0.03956460580229759,
      "learning_rate": 9.279617129183187e-06,
      "loss": 0.2971,
      "step": 75040
    },
    {
      "epoch": 8.041358619950712,
      "grad_norm": 0.0002676261938177049,
      "learning_rate": 9.278188506732384e-06,
      "loss": 0.0006,
      "step": 75050
    },
    {
      "epoch": 8.042430086788814,
      "grad_norm": 0.0002586927730590105,
      "learning_rate": 9.276759884281582e-06,
      "loss": 0.0002,
      "step": 75060
    },
    {
      "epoch": 8.043501553626916,
      "grad_norm": 0.0017056618817150593,
      "learning_rate": 9.27533126183078e-06,
      "loss": 0.0006,
      "step": 75070
    },
    {
      "epoch": 8.044573020465016,
      "grad_norm": 0.0007255214150063694,
      "learning_rate": 9.27390263937998e-06,
      "loss": 0.0001,
      "step": 75080
    },
    {
      "epoch": 8.045644487303118,
      "grad_norm": 0.006785626523196697,
      "learning_rate": 9.272474016929177e-06,
      "loss": 0.0001,
      "step": 75090
    },
    {
      "epoch": 8.04671595414122,
      "grad_norm": 0.00015413195069413632,
      "learning_rate": 9.271045394478375e-06,
      "loss": 0.0001,
      "step": 75100
    },
    {
      "epoch": 8.04778742097932,
      "grad_norm": 0.002810806268826127,
      "learning_rate": 9.269616772027574e-06,
      "loss": 0.0014,
      "step": 75110
    },
    {
      "epoch": 8.048858887817422,
      "grad_norm": 0.00012614736624527723,
      "learning_rate": 9.268188149576772e-06,
      "loss": 0.1166,
      "step": 75120
    },
    {
      "epoch": 8.049930354655523,
      "grad_norm": 9.70983601291664e-05,
      "learning_rate": 9.26675952712597e-06,
      "loss": 0.0001,
      "step": 75130
    },
    {
      "epoch": 8.051001821493625,
      "grad_norm": 0.00011865924898302183,
      "learning_rate": 9.265330904675169e-06,
      "loss": 0.0011,
      "step": 75140
    },
    {
      "epoch": 8.052073288331727,
      "grad_norm": 0.021846110001206398,
      "learning_rate": 9.263902282224366e-06,
      "loss": 0.1185,
      "step": 75150
    },
    {
      "epoch": 8.053144755169827,
      "grad_norm": 0.0001299788273172453,
      "learning_rate": 9.262473659773564e-06,
      "loss": 0.0001,
      "step": 75160
    },
    {
      "epoch": 8.054216222007929,
      "grad_norm": 0.0047708493657410145,
      "learning_rate": 9.261045037322762e-06,
      "loss": 0.1475,
      "step": 75170
    },
    {
      "epoch": 8.05528768884603,
      "grad_norm": 0.0006033041281625628,
      "learning_rate": 9.259616414871961e-06,
      "loss": 0.0001,
      "step": 75180
    },
    {
      "epoch": 8.056359155684131,
      "grad_norm": 0.011507844552397728,
      "learning_rate": 9.258187792421159e-06,
      "loss": 0.0,
      "step": 75190
    },
    {
      "epoch": 8.057430622522233,
      "grad_norm": 0.00012150547991041094,
      "learning_rate": 9.256759169970358e-06,
      "loss": 0.0001,
      "step": 75200
    },
    {
      "epoch": 8.058502089360335,
      "grad_norm": 0.00012111459363950416,
      "learning_rate": 9.255330547519556e-06,
      "loss": 0.0001,
      "step": 75210
    },
    {
      "epoch": 8.059573556198435,
      "grad_norm": 0.000133384921355173,
      "learning_rate": 9.253901925068753e-06,
      "loss": 0.0001,
      "step": 75220
    },
    {
      "epoch": 8.060645023036537,
      "grad_norm": 25.330772399902344,
      "learning_rate": 9.252473302617951e-06,
      "loss": 0.2602,
      "step": 75230
    },
    {
      "epoch": 8.06171648987464,
      "grad_norm": 0.00014818548515904695,
      "learning_rate": 9.251044680167149e-06,
      "loss": 0.0,
      "step": 75240
    },
    {
      "epoch": 8.06278795671274,
      "grad_norm": 0.00010693861986510456,
      "learning_rate": 9.249616057716348e-06,
      "loss": 0.0002,
      "step": 75250
    },
    {
      "epoch": 8.063859423550841,
      "grad_norm": 0.00010308994387742132,
      "learning_rate": 9.248187435265546e-06,
      "loss": 0.1539,
      "step": 75260
    },
    {
      "epoch": 8.064930890388942,
      "grad_norm": 0.00011640321463346481,
      "learning_rate": 9.246758812814745e-06,
      "loss": 0.1146,
      "step": 75270
    },
    {
      "epoch": 8.066002357227044,
      "grad_norm": 0.0066148340702056885,
      "learning_rate": 9.245330190363943e-06,
      "loss": 0.0207,
      "step": 75280
    },
    {
      "epoch": 8.067073824065146,
      "grad_norm": 0.0030958072748035192,
      "learning_rate": 9.24390156791314e-06,
      "loss": 0.0009,
      "step": 75290
    },
    {
      "epoch": 8.068145290903246,
      "grad_norm": 0.00010915993334492669,
      "learning_rate": 9.242472945462338e-06,
      "loss": 0.1241,
      "step": 75300
    },
    {
      "epoch": 8.069216757741348,
      "grad_norm": 9.758115629665554e-05,
      "learning_rate": 9.241044323011536e-06,
      "loss": 0.0002,
      "step": 75310
    },
    {
      "epoch": 8.07028822457945,
      "grad_norm": 0.0033847650047391653,
      "learning_rate": 9.239615700560735e-06,
      "loss": 0.0001,
      "step": 75320
    },
    {
      "epoch": 8.07135969141755,
      "grad_norm": 0.000153489934746176,
      "learning_rate": 9.238187078109933e-06,
      "loss": 0.0,
      "step": 75330
    },
    {
      "epoch": 8.072431158255652,
      "grad_norm": 0.004294081591069698,
      "learning_rate": 9.236758455659132e-06,
      "loss": 0.0001,
      "step": 75340
    },
    {
      "epoch": 8.073502625093754,
      "grad_norm": 0.0028518312610685825,
      "learning_rate": 9.23532983320833e-06,
      "loss": 0.0,
      "step": 75350
    },
    {
      "epoch": 8.074574091931854,
      "grad_norm": 0.007654735352844,
      "learning_rate": 9.233901210757528e-06,
      "loss": 0.0011,
      "step": 75360
    },
    {
      "epoch": 8.075645558769956,
      "grad_norm": 0.0001007836326607503,
      "learning_rate": 9.232472588306725e-06,
      "loss": 0.0006,
      "step": 75370
    },
    {
      "epoch": 8.076717025608058,
      "grad_norm": 0.00043543943320401013,
      "learning_rate": 9.231043965855923e-06,
      "loss": 0.0356,
      "step": 75380
    },
    {
      "epoch": 8.077788492446158,
      "grad_norm": 0.0001056674518622458,
      "learning_rate": 9.229615343405122e-06,
      "loss": 0.0,
      "step": 75390
    },
    {
      "epoch": 8.07885995928426,
      "grad_norm": 9.368007886223495e-05,
      "learning_rate": 9.22818672095432e-06,
      "loss": 0.0006,
      "step": 75400
    },
    {
      "epoch": 8.07993142612236,
      "grad_norm": 9.005902393255383e-05,
      "learning_rate": 9.22675809850352e-06,
      "loss": 0.0,
      "step": 75410
    },
    {
      "epoch": 8.081002892960463,
      "grad_norm": 8.555407839594409e-05,
      "learning_rate": 9.225329476052717e-06,
      "loss": 0.0001,
      "step": 75420
    },
    {
      "epoch": 8.082074359798565,
      "grad_norm": 0.00012209526903461665,
      "learning_rate": 9.223900853601915e-06,
      "loss": 0.0001,
      "step": 75430
    },
    {
      "epoch": 8.083145826636665,
      "grad_norm": 0.00032706838101148605,
      "learning_rate": 9.222472231151112e-06,
      "loss": 0.0,
      "step": 75440
    },
    {
      "epoch": 8.084217293474767,
      "grad_norm": 0.0005155244143679738,
      "learning_rate": 9.221043608700312e-06,
      "loss": 0.0005,
      "step": 75450
    },
    {
      "epoch": 8.085288760312869,
      "grad_norm": 8.907399023883045e-05,
      "learning_rate": 9.21961498624951e-06,
      "loss": 0.2673,
      "step": 75460
    },
    {
      "epoch": 8.08636022715097,
      "grad_norm": 0.0001313550746999681,
      "learning_rate": 9.218186363798709e-06,
      "loss": 0.0001,
      "step": 75470
    },
    {
      "epoch": 8.087431693989071,
      "grad_norm": 0.006286198738962412,
      "learning_rate": 9.216757741347906e-06,
      "loss": 0.0004,
      "step": 75480
    },
    {
      "epoch": 8.088503160827173,
      "grad_norm": 0.00010365113848820329,
      "learning_rate": 9.215329118897104e-06,
      "loss": 0.0009,
      "step": 75490
    },
    {
      "epoch": 8.089574627665273,
      "grad_norm": 0.006562617141753435,
      "learning_rate": 9.213900496446302e-06,
      "loss": 0.0001,
      "step": 75500
    },
    {
      "epoch": 8.090646094503375,
      "grad_norm": 7.540971273556352e-05,
      "learning_rate": 9.212471873995501e-06,
      "loss": 0.0002,
      "step": 75510
    },
    {
      "epoch": 8.091717561341477,
      "grad_norm": 0.0043652597814798355,
      "learning_rate": 9.211043251544699e-06,
      "loss": 0.0001,
      "step": 75520
    },
    {
      "epoch": 8.092789028179578,
      "grad_norm": 17.77473258972168,
      "learning_rate": 9.209614629093896e-06,
      "loss": 0.2601,
      "step": 75530
    },
    {
      "epoch": 8.09386049501768,
      "grad_norm": 0.007992846891283989,
      "learning_rate": 9.208186006643096e-06,
      "loss": 0.0001,
      "step": 75540
    },
    {
      "epoch": 8.09493196185578,
      "grad_norm": 0.005675771739333868,
      "learning_rate": 9.206757384192294e-06,
      "loss": 0.0,
      "step": 75550
    },
    {
      "epoch": 8.096003428693882,
      "grad_norm": 0.009585880674421787,
      "learning_rate": 9.205328761741491e-06,
      "loss": 0.0005,
      "step": 75560
    },
    {
      "epoch": 8.097074895531984,
      "grad_norm": 0.02162337861955166,
      "learning_rate": 9.20390013929069e-06,
      "loss": 0.0001,
      "step": 75570
    },
    {
      "epoch": 8.098146362370084,
      "grad_norm": 8.049132884480059e-05,
      "learning_rate": 9.202471516839888e-06,
      "loss": 0.0,
      "step": 75580
    },
    {
      "epoch": 8.099217829208186,
      "grad_norm": 0.00010744088649516925,
      "learning_rate": 9.201042894389086e-06,
      "loss": 0.0005,
      "step": 75590
    },
    {
      "epoch": 8.100289296046288,
      "grad_norm": 7.724812894593924e-05,
      "learning_rate": 9.199614271938284e-06,
      "loss": 0.0,
      "step": 75600
    },
    {
      "epoch": 8.101360762884388,
      "grad_norm": 6.469742220360786e-05,
      "learning_rate": 9.198185649487483e-06,
      "loss": 0.0002,
      "step": 75610
    },
    {
      "epoch": 8.10243222972249,
      "grad_norm": 9.067529026651755e-05,
      "learning_rate": 9.19675702703668e-06,
      "loss": 0.1299,
      "step": 75620
    },
    {
      "epoch": 8.103503696560592,
      "grad_norm": 9.242515807272866e-05,
      "learning_rate": 9.19532840458588e-06,
      "loss": 0.0002,
      "step": 75630
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 0.3456026315689087,
      "learning_rate": 9.193899782135078e-06,
      "loss": 0.0005,
      "step": 75640
    },
    {
      "epoch": 8.105646630236794,
      "grad_norm": 0.0003043659671675414,
      "learning_rate": 9.192471159684275e-06,
      "loss": 0.0002,
      "step": 75650
    },
    {
      "epoch": 8.106718097074895,
      "grad_norm": 0.003393834689632058,
      "learning_rate": 9.191042537233473e-06,
      "loss": 0.0,
      "step": 75660
    },
    {
      "epoch": 8.107789563912997,
      "grad_norm": 0.0050363242626190186,
      "learning_rate": 9.18961391478267e-06,
      "loss": 0.041,
      "step": 75670
    },
    {
      "epoch": 8.108861030751099,
      "grad_norm": 8.256217552116141e-05,
      "learning_rate": 9.18818529233187e-06,
      "loss": 0.0001,
      "step": 75680
    },
    {
      "epoch": 8.109932497589199,
      "grad_norm": 8.23597438284196e-05,
      "learning_rate": 9.186756669881068e-06,
      "loss": 0.0001,
      "step": 75690
    },
    {
      "epoch": 8.1110039644273,
      "grad_norm": 0.0001780428137863055,
      "learning_rate": 9.185328047430267e-06,
      "loss": 0.0001,
      "step": 75700
    },
    {
      "epoch": 8.112075431265403,
      "grad_norm": 0.0002300645865034312,
      "learning_rate": 9.183899424979465e-06,
      "loss": 0.0002,
      "step": 75710
    },
    {
      "epoch": 8.113146898103503,
      "grad_norm": 7.363031909335405e-05,
      "learning_rate": 9.182470802528662e-06,
      "loss": 0.0,
      "step": 75720
    },
    {
      "epoch": 8.114218364941605,
      "grad_norm": 0.005463927052915096,
      "learning_rate": 9.18104218007786e-06,
      "loss": 0.0,
      "step": 75730
    },
    {
      "epoch": 8.115289831779707,
      "grad_norm": 8.415848424192518e-05,
      "learning_rate": 9.179613557627058e-06,
      "loss": 0.0001,
      "step": 75740
    },
    {
      "epoch": 8.116361298617807,
      "grad_norm": 0.015486499294638634,
      "learning_rate": 9.178184935176257e-06,
      "loss": 0.0001,
      "step": 75750
    },
    {
      "epoch": 8.11743276545591,
      "grad_norm": 0.00010464319348102435,
      "learning_rate": 9.176756312725455e-06,
      "loss": 0.434,
      "step": 75760
    },
    {
      "epoch": 8.118504232294011,
      "grad_norm": 0.11056194454431534,
      "learning_rate": 9.175327690274654e-06,
      "loss": 0.0002,
      "step": 75770
    },
    {
      "epoch": 8.119575699132112,
      "grad_norm": 0.005404177121818066,
      "learning_rate": 9.173899067823852e-06,
      "loss": 0.14,
      "step": 75780
    },
    {
      "epoch": 8.120647165970214,
      "grad_norm": 0.000156803842401132,
      "learning_rate": 9.17247044537305e-06,
      "loss": 0.0,
      "step": 75790
    },
    {
      "epoch": 8.121718632808314,
      "grad_norm": 0.0007378712762147188,
      "learning_rate": 9.171041822922247e-06,
      "loss": 0.0,
      "step": 75800
    },
    {
      "epoch": 8.122790099646416,
      "grad_norm": 0.006480725947767496,
      "learning_rate": 9.169613200471447e-06,
      "loss": 0.0001,
      "step": 75810
    },
    {
      "epoch": 8.123861566484518,
      "grad_norm": 0.00015323793923016638,
      "learning_rate": 9.168184578020644e-06,
      "loss": 0.0001,
      "step": 75820
    },
    {
      "epoch": 8.124933033322618,
      "grad_norm": 0.00015520694432780147,
      "learning_rate": 9.166755955569842e-06,
      "loss": 0.0,
      "step": 75830
    },
    {
      "epoch": 8.12600450016072,
      "grad_norm": 0.0034683863632380962,
      "learning_rate": 9.165327333119041e-06,
      "loss": 0.0,
      "step": 75840
    },
    {
      "epoch": 8.127075966998822,
      "grad_norm": 0.0028850622475147247,
      "learning_rate": 9.163898710668239e-06,
      "loss": 0.0001,
      "step": 75850
    },
    {
      "epoch": 8.128147433836922,
      "grad_norm": 0.003169151023030281,
      "learning_rate": 9.162470088217437e-06,
      "loss": 0.0001,
      "step": 75860
    },
    {
      "epoch": 8.129218900675024,
      "grad_norm": 0.00016394909471273422,
      "learning_rate": 9.161041465766636e-06,
      "loss": 0.0001,
      "step": 75870
    },
    {
      "epoch": 8.130290367513126,
      "grad_norm": 0.007667039521038532,
      "learning_rate": 9.159612843315834e-06,
      "loss": 0.0003,
      "step": 75880
    },
    {
      "epoch": 8.131361834351226,
      "grad_norm": 0.00011687255755532533,
      "learning_rate": 9.158184220865031e-06,
      "loss": 0.0,
      "step": 75890
    },
    {
      "epoch": 8.132433301189328,
      "grad_norm": 0.00012879399582743645,
      "learning_rate": 9.156755598414229e-06,
      "loss": 0.0,
      "step": 75900
    },
    {
      "epoch": 8.13350476802743,
      "grad_norm": 0.0001526800188003108,
      "learning_rate": 9.155326975963428e-06,
      "loss": 0.0,
      "step": 75910
    },
    {
      "epoch": 8.13457623486553,
      "grad_norm": 0.00013712032523471862,
      "learning_rate": 9.153898353512626e-06,
      "loss": 0.0001,
      "step": 75920
    },
    {
      "epoch": 8.135647701703633,
      "grad_norm": 0.005961722228676081,
      "learning_rate": 9.152469731061825e-06,
      "loss": 0.0,
      "step": 75930
    },
    {
      "epoch": 8.136719168541733,
      "grad_norm": 0.0001614194770809263,
      "learning_rate": 9.151041108611023e-06,
      "loss": 0.0015,
      "step": 75940
    },
    {
      "epoch": 8.137790635379835,
      "grad_norm": 0.00016937422333285213,
      "learning_rate": 9.14961248616022e-06,
      "loss": 0.1907,
      "step": 75950
    },
    {
      "epoch": 8.138862102217937,
      "grad_norm": 0.0003279365773778409,
      "learning_rate": 9.148183863709418e-06,
      "loss": 0.281,
      "step": 75960
    },
    {
      "epoch": 8.139933569056037,
      "grad_norm": 0.013675803318619728,
      "learning_rate": 9.146755241258616e-06,
      "loss": 0.0,
      "step": 75970
    },
    {
      "epoch": 8.141005035894139,
      "grad_norm": 0.0002307162358192727,
      "learning_rate": 9.145326618807815e-06,
      "loss": 0.0002,
      "step": 75980
    },
    {
      "epoch": 8.142076502732241,
      "grad_norm": 0.003225889289751649,
      "learning_rate": 9.143897996357015e-06,
      "loss": 0.0,
      "step": 75990
    },
    {
      "epoch": 8.143147969570341,
      "grad_norm": 0.002729550004005432,
      "learning_rate": 9.142469373906212e-06,
      "loss": 0.0,
      "step": 76000
    },
    {
      "epoch": 8.144219436408443,
      "grad_norm": 0.0002043908170890063,
      "learning_rate": 9.14104075145541e-06,
      "loss": 0.0001,
      "step": 76010
    },
    {
      "epoch": 8.145290903246545,
      "grad_norm": 0.00016079607303254306,
      "learning_rate": 9.139612129004608e-06,
      "loss": 0.0263,
      "step": 76020
    },
    {
      "epoch": 8.146362370084645,
      "grad_norm": 0.0001618231472093612,
      "learning_rate": 9.138183506553806e-06,
      "loss": 0.0,
      "step": 76030
    },
    {
      "epoch": 8.147433836922747,
      "grad_norm": 0.004344685468822718,
      "learning_rate": 9.136754884103005e-06,
      "loss": 0.0002,
      "step": 76040
    },
    {
      "epoch": 8.14850530376085,
      "grad_norm": 0.00019729659834410995,
      "learning_rate": 9.135326261652203e-06,
      "loss": 0.0001,
      "step": 76050
    },
    {
      "epoch": 8.14957677059895,
      "grad_norm": 0.0001838123716879636,
      "learning_rate": 9.133897639201402e-06,
      "loss": 0.0003,
      "step": 76060
    },
    {
      "epoch": 8.150648237437052,
      "grad_norm": 0.006082536652684212,
      "learning_rate": 9.1324690167506e-06,
      "loss": 0.0003,
      "step": 76070
    },
    {
      "epoch": 8.151719704275152,
      "grad_norm": 0.00010938589548459277,
      "learning_rate": 9.131040394299797e-06,
      "loss": 0.0001,
      "step": 76080
    },
    {
      "epoch": 8.152791171113254,
      "grad_norm": 0.00047601296682842076,
      "learning_rate": 9.129611771848995e-06,
      "loss": 0.0,
      "step": 76090
    },
    {
      "epoch": 8.153862637951356,
      "grad_norm": 0.000154219611431472,
      "learning_rate": 9.128183149398193e-06,
      "loss": 0.0001,
      "step": 76100
    },
    {
      "epoch": 8.154934104789456,
      "grad_norm": 0.00014581270806957036,
      "learning_rate": 9.126754526947392e-06,
      "loss": 0.0001,
      "step": 76110
    },
    {
      "epoch": 8.156005571627558,
      "grad_norm": 0.0001502668601460755,
      "learning_rate": 9.12532590449659e-06,
      "loss": 0.0,
      "step": 76120
    },
    {
      "epoch": 8.15707703846566,
      "grad_norm": 0.0030375360511243343,
      "learning_rate": 9.123897282045789e-06,
      "loss": 0.0,
      "step": 76130
    },
    {
      "epoch": 8.15814850530376,
      "grad_norm": 0.0023684739135205746,
      "learning_rate": 9.122468659594987e-06,
      "loss": 0.0,
      "step": 76140
    },
    {
      "epoch": 8.159219972141862,
      "grad_norm": 0.00020380542264319956,
      "learning_rate": 9.121040037144184e-06,
      "loss": 0.0,
      "step": 76150
    },
    {
      "epoch": 8.160291438979964,
      "grad_norm": 0.00016376878193113953,
      "learning_rate": 9.119611414693382e-06,
      "loss": 0.0003,
      "step": 76160
    },
    {
      "epoch": 8.161362905818065,
      "grad_norm": 0.00016610183229204267,
      "learning_rate": 9.11818279224258e-06,
      "loss": 0.0021,
      "step": 76170
    },
    {
      "epoch": 8.162434372656167,
      "grad_norm": 0.002453245921060443,
      "learning_rate": 9.116754169791779e-06,
      "loss": 0.0,
      "step": 76180
    },
    {
      "epoch": 8.163505839494267,
      "grad_norm": 0.008490614593029022,
      "learning_rate": 9.115325547340977e-06,
      "loss": 0.0,
      "step": 76190
    },
    {
      "epoch": 8.164577306332369,
      "grad_norm": 0.017702192068099976,
      "learning_rate": 9.113896924890176e-06,
      "loss": 0.0,
      "step": 76200
    },
    {
      "epoch": 8.16564877317047,
      "grad_norm": 0.0024067156482487917,
      "learning_rate": 9.112468302439374e-06,
      "loss": 0.0,
      "step": 76210
    },
    {
      "epoch": 8.166720240008571,
      "grad_norm": 0.00014260411262512207,
      "learning_rate": 9.111039679988571e-06,
      "loss": 0.0001,
      "step": 76220
    },
    {
      "epoch": 8.167791706846673,
      "grad_norm": 0.00011008622823283076,
      "learning_rate": 9.109611057537769e-06,
      "loss": 0.2812,
      "step": 76230
    },
    {
      "epoch": 8.168863173684775,
      "grad_norm": 0.00021113210823386908,
      "learning_rate": 9.108182435086968e-06,
      "loss": 0.3156,
      "step": 76240
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.00018235217430628836,
      "learning_rate": 9.106753812636166e-06,
      "loss": 0.0001,
      "step": 76250
    },
    {
      "epoch": 8.171006107360977,
      "grad_norm": 0.00014436790661420673,
      "learning_rate": 9.105325190185364e-06,
      "loss": 0.0,
      "step": 76260
    },
    {
      "epoch": 8.17207757419908,
      "grad_norm": 0.00015535169222857803,
      "learning_rate": 9.103896567734563e-06,
      "loss": 0.0002,
      "step": 76270
    },
    {
      "epoch": 8.17314904103718,
      "grad_norm": 0.006539554335176945,
      "learning_rate": 9.102467945283761e-06,
      "loss": 0.0001,
      "step": 76280
    },
    {
      "epoch": 8.174220507875281,
      "grad_norm": 0.0004733061941806227,
      "learning_rate": 9.101039322832959e-06,
      "loss": 0.0001,
      "step": 76290
    },
    {
      "epoch": 8.175291974713383,
      "grad_norm": 0.07501763850450516,
      "learning_rate": 9.099610700382158e-06,
      "loss": 0.0,
      "step": 76300
    },
    {
      "epoch": 8.176363441551484,
      "grad_norm": 0.0003866068727802485,
      "learning_rate": 9.098182077931356e-06,
      "loss": 0.0,
      "step": 76310
    },
    {
      "epoch": 8.177434908389586,
      "grad_norm": 0.003370021004229784,
      "learning_rate": 9.096753455480553e-06,
      "loss": 0.0004,
      "step": 76320
    },
    {
      "epoch": 8.178506375227686,
      "grad_norm": 0.04489688575267792,
      "learning_rate": 9.095324833029751e-06,
      "loss": 0.0001,
      "step": 76330
    },
    {
      "epoch": 8.179577842065788,
      "grad_norm": 0.010519943200051785,
      "learning_rate": 9.09389621057895e-06,
      "loss": 0.0001,
      "step": 76340
    },
    {
      "epoch": 8.18064930890389,
      "grad_norm": 0.00017559897969476879,
      "learning_rate": 9.092467588128148e-06,
      "loss": 0.0471,
      "step": 76350
    },
    {
      "epoch": 8.18172077574199,
      "grad_norm": 0.00011779112537624314,
      "learning_rate": 9.091038965677347e-06,
      "loss": 0.0001,
      "step": 76360
    },
    {
      "epoch": 8.182792242580092,
      "grad_norm": 0.0009620198397897184,
      "learning_rate": 9.089610343226545e-06,
      "loss": 0.0001,
      "step": 76370
    },
    {
      "epoch": 8.183863709418194,
      "grad_norm": 0.00016767022316344082,
      "learning_rate": 9.088181720775743e-06,
      "loss": 0.0004,
      "step": 76380
    },
    {
      "epoch": 8.184935176256294,
      "grad_norm": 0.00016258287359960377,
      "learning_rate": 9.08675309832494e-06,
      "loss": 0.0001,
      "step": 76390
    },
    {
      "epoch": 8.186006643094396,
      "grad_norm": 0.00010788861254695803,
      "learning_rate": 9.085324475874138e-06,
      "loss": 0.0002,
      "step": 76400
    },
    {
      "epoch": 8.187078109932498,
      "grad_norm": 0.00010990884038619697,
      "learning_rate": 9.083895853423337e-06,
      "loss": 0.1077,
      "step": 76410
    },
    {
      "epoch": 8.188149576770599,
      "grad_norm": 0.008731438778340816,
      "learning_rate": 9.082467230972535e-06,
      "loss": 0.0001,
      "step": 76420
    },
    {
      "epoch": 8.1892210436087,
      "grad_norm": 0.0010692602954804897,
      "learning_rate": 9.081038608521734e-06,
      "loss": 0.0001,
      "step": 76430
    },
    {
      "epoch": 8.190292510446803,
      "grad_norm": 0.00011812473530881107,
      "learning_rate": 9.079609986070932e-06,
      "loss": 0.0,
      "step": 76440
    },
    {
      "epoch": 8.191363977284903,
      "grad_norm": 0.006917526014149189,
      "learning_rate": 9.07818136362013e-06,
      "loss": 0.1872,
      "step": 76450
    },
    {
      "epoch": 8.192435444123005,
      "grad_norm": 18.03874397277832,
      "learning_rate": 9.076752741169327e-06,
      "loss": 0.3393,
      "step": 76460
    },
    {
      "epoch": 8.193506910961105,
      "grad_norm": 0.00024117484281305224,
      "learning_rate": 9.075324118718525e-06,
      "loss": 0.0002,
      "step": 76470
    },
    {
      "epoch": 8.194578377799207,
      "grad_norm": 0.00017773685976862907,
      "learning_rate": 9.073895496267724e-06,
      "loss": 0.0001,
      "step": 76480
    },
    {
      "epoch": 8.195649844637309,
      "grad_norm": 0.013335786759853363,
      "learning_rate": 9.072466873816924e-06,
      "loss": 0.0001,
      "step": 76490
    },
    {
      "epoch": 8.19672131147541,
      "grad_norm": 47.08890151977539,
      "learning_rate": 9.071038251366122e-06,
      "loss": 0.405,
      "step": 76500
    },
    {
      "epoch": 8.197792778313511,
      "grad_norm": 0.007702006958425045,
      "learning_rate": 9.06960962891532e-06,
      "loss": 0.0001,
      "step": 76510
    },
    {
      "epoch": 8.198864245151613,
      "grad_norm": 0.00017208968347404152,
      "learning_rate": 9.068181006464517e-06,
      "loss": 0.0001,
      "step": 76520
    },
    {
      "epoch": 8.199935711989713,
      "grad_norm": 0.0003380260895937681,
      "learning_rate": 9.066752384013715e-06,
      "loss": 0.1539,
      "step": 76530
    },
    {
      "epoch": 8.201007178827815,
      "grad_norm": 0.0005072877393104136,
      "learning_rate": 9.065323761562914e-06,
      "loss": 0.0005,
      "step": 76540
    },
    {
      "epoch": 8.202078645665917,
      "grad_norm": 0.0002619312726892531,
      "learning_rate": 9.063895139112112e-06,
      "loss": 0.0003,
      "step": 76550
    },
    {
      "epoch": 8.203150112504018,
      "grad_norm": 0.00023925873392727226,
      "learning_rate": 9.062466516661311e-06,
      "loss": 0.0001,
      "step": 76560
    },
    {
      "epoch": 8.20422157934212,
      "grad_norm": 0.0002716670569498092,
      "learning_rate": 9.061037894210509e-06,
      "loss": 0.0001,
      "step": 76570
    },
    {
      "epoch": 8.205293046180222,
      "grad_norm": 0.00014636780542787164,
      "learning_rate": 9.059609271759706e-06,
      "loss": 0.006,
      "step": 76580
    },
    {
      "epoch": 8.206364513018322,
      "grad_norm": 0.00017293880227953196,
      "learning_rate": 9.058180649308904e-06,
      "loss": 0.0,
      "step": 76590
    },
    {
      "epoch": 8.207435979856424,
      "grad_norm": 0.0036720093339681625,
      "learning_rate": 9.056752026858103e-06,
      "loss": 0.0,
      "step": 76600
    },
    {
      "epoch": 8.208507446694524,
      "grad_norm": 0.018499601632356644,
      "learning_rate": 9.055323404407301e-06,
      "loss": 0.0001,
      "step": 76610
    },
    {
      "epoch": 8.209578913532626,
      "grad_norm": 0.00019643607083708048,
      "learning_rate": 9.053894781956499e-06,
      "loss": 0.3358,
      "step": 76620
    },
    {
      "epoch": 8.210650380370728,
      "grad_norm": 0.004284275230020285,
      "learning_rate": 9.052466159505698e-06,
      "loss": 0.0001,
      "step": 76630
    },
    {
      "epoch": 8.211721847208828,
      "grad_norm": 0.0035019773058593273,
      "learning_rate": 9.051037537054896e-06,
      "loss": 0.0017,
      "step": 76640
    },
    {
      "epoch": 8.21279331404693,
      "grad_norm": 0.0005165516049601138,
      "learning_rate": 9.049608914604093e-06,
      "loss": 0.0001,
      "step": 76650
    },
    {
      "epoch": 8.213864780885032,
      "grad_norm": 0.03660867363214493,
      "learning_rate": 9.048180292153293e-06,
      "loss": 0.0001,
      "step": 76660
    },
    {
      "epoch": 8.214936247723132,
      "grad_norm": 0.0029847421683371067,
      "learning_rate": 9.04675166970249e-06,
      "loss": 0.0004,
      "step": 76670
    },
    {
      "epoch": 8.216007714561234,
      "grad_norm": 0.00040962168714031577,
      "learning_rate": 9.045323047251688e-06,
      "loss": 0.0001,
      "step": 76680
    },
    {
      "epoch": 8.217079181399336,
      "grad_norm": 0.00408535310998559,
      "learning_rate": 9.043894424800886e-06,
      "loss": 0.0,
      "step": 76690
    },
    {
      "epoch": 8.218150648237437,
      "grad_norm": 0.012605722062289715,
      "learning_rate": 9.042465802350085e-06,
      "loss": 0.0002,
      "step": 76700
    },
    {
      "epoch": 8.219222115075539,
      "grad_norm": 0.001300437143072486,
      "learning_rate": 9.041037179899283e-06,
      "loss": 0.1414,
      "step": 76710
    },
    {
      "epoch": 8.220293581913639,
      "grad_norm": 0.004006925504654646,
      "learning_rate": 9.039608557448482e-06,
      "loss": 0.0001,
      "step": 76720
    },
    {
      "epoch": 8.221365048751741,
      "grad_norm": 0.000411677872762084,
      "learning_rate": 9.03817993499768e-06,
      "loss": 0.0,
      "step": 76730
    },
    {
      "epoch": 8.222436515589843,
      "grad_norm": 0.004356993827968836,
      "learning_rate": 9.036751312546878e-06,
      "loss": 0.0003,
      "step": 76740
    },
    {
      "epoch": 8.223507982427943,
      "grad_norm": 0.09777551144361496,
      "learning_rate": 9.035322690096075e-06,
      "loss": 0.1588,
      "step": 76750
    },
    {
      "epoch": 8.224579449266045,
      "grad_norm": 0.0005984802846796811,
      "learning_rate": 9.033894067645273e-06,
      "loss": 0.0003,
      "step": 76760
    },
    {
      "epoch": 8.225650916104147,
      "grad_norm": 0.27337217330932617,
      "learning_rate": 9.032465445194472e-06,
      "loss": 0.0005,
      "step": 76770
    },
    {
      "epoch": 8.226722382942247,
      "grad_norm": 0.00017719097377266735,
      "learning_rate": 9.03103682274367e-06,
      "loss": 0.0001,
      "step": 76780
    },
    {
      "epoch": 8.22779384978035,
      "grad_norm": 0.00046694150660187006,
      "learning_rate": 9.02960820029287e-06,
      "loss": 0.0,
      "step": 76790
    },
    {
      "epoch": 8.228865316618451,
      "grad_norm": 0.0001691730140009895,
      "learning_rate": 9.028179577842067e-06,
      "loss": 0.0001,
      "step": 76800
    },
    {
      "epoch": 8.229936783456552,
      "grad_norm": 0.00019266945309937,
      "learning_rate": 9.026750955391265e-06,
      "loss": 0.0002,
      "step": 76810
    },
    {
      "epoch": 8.231008250294654,
      "grad_norm": 0.006020737811923027,
      "learning_rate": 9.025322332940462e-06,
      "loss": 0.0011,
      "step": 76820
    },
    {
      "epoch": 8.232079717132756,
      "grad_norm": 0.0016616127686575055,
      "learning_rate": 9.02389371048966e-06,
      "loss": 0.1491,
      "step": 76830
    },
    {
      "epoch": 8.233151183970856,
      "grad_norm": 0.0018575417343527079,
      "learning_rate": 9.02246508803886e-06,
      "loss": 0.0001,
      "step": 76840
    },
    {
      "epoch": 8.234222650808958,
      "grad_norm": 0.17686772346496582,
      "learning_rate": 9.021036465588057e-06,
      "loss": 0.0002,
      "step": 76850
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.00023182657605502754,
      "learning_rate": 9.019607843137256e-06,
      "loss": 0.0,
      "step": 76860
    },
    {
      "epoch": 8.23636558448516,
      "grad_norm": 0.00014999994891695678,
      "learning_rate": 9.018179220686454e-06,
      "loss": 0.0003,
      "step": 76870
    },
    {
      "epoch": 8.237437051323262,
      "grad_norm": 0.004331063944846392,
      "learning_rate": 9.016750598235652e-06,
      "loss": 0.0,
      "step": 76880
    },
    {
      "epoch": 8.238508518161362,
      "grad_norm": 0.0025880273897200823,
      "learning_rate": 9.01532197578485e-06,
      "loss": 0.0,
      "step": 76890
    },
    {
      "epoch": 8.239579984999464,
      "grad_norm": 0.0009992681443691254,
      "learning_rate": 9.013893353334049e-06,
      "loss": 0.1933,
      "step": 76900
    },
    {
      "epoch": 8.240651451837566,
      "grad_norm": 0.06389147788286209,
      "learning_rate": 9.012464730883246e-06,
      "loss": 0.0002,
      "step": 76910
    },
    {
      "epoch": 8.241722918675666,
      "grad_norm": 0.00017116457456722856,
      "learning_rate": 9.011036108432444e-06,
      "loss": 0.0544,
      "step": 76920
    },
    {
      "epoch": 8.242794385513768,
      "grad_norm": 0.00022078743495512754,
      "learning_rate": 9.009607485981643e-06,
      "loss": 0.0,
      "step": 76930
    },
    {
      "epoch": 8.24386585235187,
      "grad_norm": 279.24798583984375,
      "learning_rate": 9.008178863530841e-06,
      "loss": 0.0541,
      "step": 76940
    },
    {
      "epoch": 8.24493731918997,
      "grad_norm": 0.00020146268070675433,
      "learning_rate": 9.006750241080039e-06,
      "loss": 0.0001,
      "step": 76950
    },
    {
      "epoch": 8.246008786028073,
      "grad_norm": 0.00024002465943340212,
      "learning_rate": 9.005321618629238e-06,
      "loss": 0.0,
      "step": 76960
    },
    {
      "epoch": 8.247080252866175,
      "grad_norm": 0.0025746705941855907,
      "learning_rate": 9.003892996178436e-06,
      "loss": 0.0,
      "step": 76970
    },
    {
      "epoch": 8.248151719704275,
      "grad_norm": 0.0014209963846951723,
      "learning_rate": 9.002464373727634e-06,
      "loss": 0.0,
      "step": 76980
    },
    {
      "epoch": 8.249223186542377,
      "grad_norm": 0.0004993187612853944,
      "learning_rate": 9.001035751276833e-06,
      "loss": 0.0,
      "step": 76990
    },
    {
      "epoch": 8.250294653380477,
      "grad_norm": 0.00022012922272551805,
      "learning_rate": 8.99960712882603e-06,
      "loss": 0.0,
      "step": 77000
    },
    {
      "epoch": 8.251366120218579,
      "grad_norm": 0.0002673872222658247,
      "learning_rate": 8.998178506375228e-06,
      "loss": 0.0,
      "step": 77010
    },
    {
      "epoch": 8.252437587056681,
      "grad_norm": 0.00011775423627113923,
      "learning_rate": 8.996749883924426e-06,
      "loss": 0.0001,
      "step": 77020
    },
    {
      "epoch": 8.253509053894781,
      "grad_norm": 0.00021212843421380967,
      "learning_rate": 8.995321261473625e-06,
      "loss": 0.0006,
      "step": 77030
    },
    {
      "epoch": 8.254580520732883,
      "grad_norm": 0.002434779889881611,
      "learning_rate": 8.993892639022823e-06,
      "loss": 0.1121,
      "step": 77040
    },
    {
      "epoch": 8.255651987570985,
      "grad_norm": 0.001675465377047658,
      "learning_rate": 8.99246401657202e-06,
      "loss": 0.0714,
      "step": 77050
    },
    {
      "epoch": 8.256723454409086,
      "grad_norm": 23.857999801635742,
      "learning_rate": 8.99103539412122e-06,
      "loss": 0.1468,
      "step": 77060
    },
    {
      "epoch": 8.257794921247188,
      "grad_norm": 0.0003918749571312219,
      "learning_rate": 8.989606771670418e-06,
      "loss": 0.0,
      "step": 77070
    },
    {
      "epoch": 8.25886638808529,
      "grad_norm": 0.0006670195725746453,
      "learning_rate": 8.988178149219615e-06,
      "loss": 0.0,
      "step": 77080
    },
    {
      "epoch": 8.25993785492339,
      "grad_norm": 0.00019222205446567386,
      "learning_rate": 8.986749526768815e-06,
      "loss": 0.0,
      "step": 77090
    },
    {
      "epoch": 8.261009321761492,
      "grad_norm": 0.0010917438194155693,
      "learning_rate": 8.985320904318012e-06,
      "loss": 0.0001,
      "step": 77100
    },
    {
      "epoch": 8.262080788599594,
      "grad_norm": 0.00525173544883728,
      "learning_rate": 8.98389228186721e-06,
      "loss": 0.0,
      "step": 77110
    },
    {
      "epoch": 8.263152255437694,
      "grad_norm": 0.0011576882097870111,
      "learning_rate": 8.982463659416408e-06,
      "loss": 0.0002,
      "step": 77120
    },
    {
      "epoch": 8.264223722275796,
      "grad_norm": 0.12997134029865265,
      "learning_rate": 8.981035036965607e-06,
      "loss": 0.0002,
      "step": 77130
    },
    {
      "epoch": 8.265295189113896,
      "grad_norm": 0.0002781056391540915,
      "learning_rate": 8.979606414514805e-06,
      "loss": 0.0,
      "step": 77140
    },
    {
      "epoch": 8.266366655951998,
      "grad_norm": 0.00016157807840500027,
      "learning_rate": 8.978177792064004e-06,
      "loss": 0.0001,
      "step": 77150
    },
    {
      "epoch": 8.2674381227901,
      "grad_norm": 0.23360078036785126,
      "learning_rate": 8.976749169613202e-06,
      "loss": 0.1185,
      "step": 77160
    },
    {
      "epoch": 8.2685095896282,
      "grad_norm": 0.0004488800186663866,
      "learning_rate": 8.9753205471624e-06,
      "loss": 0.0,
      "step": 77170
    },
    {
      "epoch": 8.269581056466302,
      "grad_norm": 0.0024501837324351072,
      "learning_rate": 8.973891924711597e-06,
      "loss": 0.0,
      "step": 77180
    },
    {
      "epoch": 8.270652523304404,
      "grad_norm": 85.61226654052734,
      "learning_rate": 8.972463302260795e-06,
      "loss": 0.2396,
      "step": 77190
    },
    {
      "epoch": 8.271723990142505,
      "grad_norm": 0.029907600954174995,
      "learning_rate": 8.971034679809994e-06,
      "loss": 0.0002,
      "step": 77200
    },
    {
      "epoch": 8.272795456980607,
      "grad_norm": 0.00021938614372629672,
      "learning_rate": 8.969606057359192e-06,
      "loss": 0.0,
      "step": 77210
    },
    {
      "epoch": 8.273866923818709,
      "grad_norm": 0.002043001353740692,
      "learning_rate": 8.968177434908391e-06,
      "loss": 0.0009,
      "step": 77220
    },
    {
      "epoch": 8.274938390656809,
      "grad_norm": 0.00013186612341087312,
      "learning_rate": 8.966748812457589e-06,
      "loss": 0.0001,
      "step": 77230
    },
    {
      "epoch": 8.27600985749491,
      "grad_norm": 0.0009696981287561357,
      "learning_rate": 8.965320190006787e-06,
      "loss": 0.0,
      "step": 77240
    },
    {
      "epoch": 8.277081324333011,
      "grad_norm": 0.00013075958122499287,
      "learning_rate": 8.963891567555984e-06,
      "loss": 0.0,
      "step": 77250
    },
    {
      "epoch": 8.278152791171113,
      "grad_norm": 0.00019772155792452395,
      "learning_rate": 8.962462945105182e-06,
      "loss": 0.0,
      "step": 77260
    },
    {
      "epoch": 8.279224258009215,
      "grad_norm": 0.008261078037321568,
      "learning_rate": 8.961034322654381e-06,
      "loss": 0.1726,
      "step": 77270
    },
    {
      "epoch": 8.280295724847315,
      "grad_norm": 0.001904860371723771,
      "learning_rate": 8.959605700203579e-06,
      "loss": 0.0001,
      "step": 77280
    },
    {
      "epoch": 8.281367191685417,
      "grad_norm": 0.00011979429837083444,
      "learning_rate": 8.958177077752778e-06,
      "loss": 0.0,
      "step": 77290
    },
    {
      "epoch": 8.28243865852352,
      "grad_norm": 0.0001256704708794132,
      "learning_rate": 8.956748455301976e-06,
      "loss": 0.0,
      "step": 77300
    },
    {
      "epoch": 8.28351012536162,
      "grad_norm": 0.00017795912572182715,
      "learning_rate": 8.955319832851174e-06,
      "loss": 0.0,
      "step": 77310
    },
    {
      "epoch": 8.284581592199721,
      "grad_norm": 0.0005494698998518288,
      "learning_rate": 8.953891210400371e-06,
      "loss": 0.0,
      "step": 77320
    },
    {
      "epoch": 8.285653059037823,
      "grad_norm": 0.00019956052710767835,
      "learning_rate": 8.95246258794957e-06,
      "loss": 0.1386,
      "step": 77330
    },
    {
      "epoch": 8.286724525875924,
      "grad_norm": 0.00014465242566075176,
      "learning_rate": 8.951033965498768e-06,
      "loss": 0.0,
      "step": 77340
    },
    {
      "epoch": 8.287795992714026,
      "grad_norm": 0.0009639563504606485,
      "learning_rate": 8.949605343047966e-06,
      "loss": 0.0008,
      "step": 77350
    },
    {
      "epoch": 8.288867459552128,
      "grad_norm": 0.0014246080536395311,
      "learning_rate": 8.948176720597165e-06,
      "loss": 0.0008,
      "step": 77360
    },
    {
      "epoch": 8.289938926390228,
      "grad_norm": 194.32240295410156,
      "learning_rate": 8.946748098146363e-06,
      "loss": 0.2172,
      "step": 77370
    },
    {
      "epoch": 8.29101039322833,
      "grad_norm": 0.00011096675007138401,
      "learning_rate": 8.94531947569556e-06,
      "loss": 0.1804,
      "step": 77380
    },
    {
      "epoch": 8.29208186006643,
      "grad_norm": 0.002867779927328229,
      "learning_rate": 8.94389085324476e-06,
      "loss": 0.1436,
      "step": 77390
    },
    {
      "epoch": 8.293153326904532,
      "grad_norm": 0.00294736516661942,
      "learning_rate": 8.942462230793958e-06,
      "loss": 0.0852,
      "step": 77400
    },
    {
      "epoch": 8.294224793742634,
      "grad_norm": 0.00017051759641617537,
      "learning_rate": 8.941033608343155e-06,
      "loss": 0.0003,
      "step": 77410
    },
    {
      "epoch": 8.295296260580734,
      "grad_norm": 0.006131974048912525,
      "learning_rate": 8.939604985892353e-06,
      "loss": 0.3199,
      "step": 77420
    },
    {
      "epoch": 8.296367727418836,
      "grad_norm": 0.0014370946446433663,
      "learning_rate": 8.938176363441553e-06,
      "loss": 0.0001,
      "step": 77430
    },
    {
      "epoch": 8.297439194256938,
      "grad_norm": 0.00028543270309455693,
      "learning_rate": 8.93674774099075e-06,
      "loss": 0.0,
      "step": 77440
    },
    {
      "epoch": 8.298510661095039,
      "grad_norm": 0.023217760026454926,
      "learning_rate": 8.93531911853995e-06,
      "loss": 0.0,
      "step": 77450
    },
    {
      "epoch": 8.29958212793314,
      "grad_norm": 0.00027144834166392684,
      "learning_rate": 8.933890496089147e-06,
      "loss": 0.0,
      "step": 77460
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 0.0012109202798455954,
      "learning_rate": 8.932461873638345e-06,
      "loss": 0.0001,
      "step": 77470
    },
    {
      "epoch": 8.301725061609343,
      "grad_norm": 0.0005270156543701887,
      "learning_rate": 8.931033251187543e-06,
      "loss": 0.0,
      "step": 77480
    },
    {
      "epoch": 8.302796528447445,
      "grad_norm": 0.001210545189678669,
      "learning_rate": 8.92960462873674e-06,
      "loss": 0.0001,
      "step": 77490
    },
    {
      "epoch": 8.303867995285547,
      "grad_norm": 0.0006793972570449114,
      "learning_rate": 8.92817600628594e-06,
      "loss": 0.0,
      "step": 77500
    },
    {
      "epoch": 8.304939462123647,
      "grad_norm": 54.78335952758789,
      "learning_rate": 8.926747383835139e-06,
      "loss": 0.2329,
      "step": 77510
    },
    {
      "epoch": 8.306010928961749,
      "grad_norm": 0.005345027428120375,
      "learning_rate": 8.925318761384337e-06,
      "loss": 0.0,
      "step": 77520
    },
    {
      "epoch": 8.30708239579985,
      "grad_norm": 0.030379051342606544,
      "learning_rate": 8.923890138933534e-06,
      "loss": 0.0001,
      "step": 77530
    },
    {
      "epoch": 8.308153862637951,
      "grad_norm": 0.00438175443559885,
      "learning_rate": 8.922461516482732e-06,
      "loss": 0.0,
      "step": 77540
    },
    {
      "epoch": 8.309225329476053,
      "grad_norm": 0.002480634953826666,
      "learning_rate": 8.92103289403193e-06,
      "loss": 0.0,
      "step": 77550
    },
    {
      "epoch": 8.310296796314153,
      "grad_norm": 0.0029529184103012085,
      "learning_rate": 8.919604271581129e-06,
      "loss": 0.0001,
      "step": 77560
    },
    {
      "epoch": 8.311368263152255,
      "grad_norm": 0.005178582854568958,
      "learning_rate": 8.918175649130327e-06,
      "loss": 0.0,
      "step": 77570
    },
    {
      "epoch": 8.312439729990357,
      "grad_norm": 0.0013866614317521453,
      "learning_rate": 8.916747026679526e-06,
      "loss": 0.0001,
      "step": 77580
    },
    {
      "epoch": 8.313511196828458,
      "grad_norm": 0.002521563321352005,
      "learning_rate": 8.915318404228724e-06,
      "loss": 0.0002,
      "step": 77590
    },
    {
      "epoch": 8.31458266366656,
      "grad_norm": 0.001069630146957934,
      "learning_rate": 8.913889781777921e-06,
      "loss": 0.0001,
      "step": 77600
    },
    {
      "epoch": 8.315654130504662,
      "grad_norm": 0.0023181699216365814,
      "learning_rate": 8.912461159327119e-06,
      "loss": 0.3301,
      "step": 77610
    },
    {
      "epoch": 8.316725597342762,
      "grad_norm": 0.015756947919726372,
      "learning_rate": 8.911032536876317e-06,
      "loss": 0.2783,
      "step": 77620
    },
    {
      "epoch": 8.317797064180864,
      "grad_norm": 0.0004902742803096771,
      "learning_rate": 8.909603914425516e-06,
      "loss": 0.2626,
      "step": 77630
    },
    {
      "epoch": 8.318868531018964,
      "grad_norm": 0.00047162396367639303,
      "learning_rate": 8.908175291974714e-06,
      "loss": 0.0046,
      "step": 77640
    },
    {
      "epoch": 8.319939997857066,
      "grad_norm": 0.00021604631911031902,
      "learning_rate": 8.906746669523913e-06,
      "loss": 0.0009,
      "step": 77650
    },
    {
      "epoch": 8.321011464695168,
      "grad_norm": 0.010138560086488724,
      "learning_rate": 8.90531804707311e-06,
      "loss": 0.0001,
      "step": 77660
    },
    {
      "epoch": 8.322082931533268,
      "grad_norm": 0.00025339535204693675,
      "learning_rate": 8.903889424622309e-06,
      "loss": 0.007,
      "step": 77670
    },
    {
      "epoch": 8.32315439837137,
      "grad_norm": 0.006725131068378687,
      "learning_rate": 8.902460802171506e-06,
      "loss": 0.0001,
      "step": 77680
    },
    {
      "epoch": 8.324225865209472,
      "grad_norm": 0.0003137582680210471,
      "learning_rate": 8.901032179720706e-06,
      "loss": 0.0003,
      "step": 77690
    },
    {
      "epoch": 8.325297332047572,
      "grad_norm": 0.00016779218276496977,
      "learning_rate": 8.899603557269903e-06,
      "loss": 0.0297,
      "step": 77700
    },
    {
      "epoch": 8.326368798885674,
      "grad_norm": 0.000142133969347924,
      "learning_rate": 8.898174934819101e-06,
      "loss": 0.0,
      "step": 77710
    },
    {
      "epoch": 8.327440265723776,
      "grad_norm": 0.00018680247012525797,
      "learning_rate": 8.8967463123683e-06,
      "loss": 0.0,
      "step": 77720
    },
    {
      "epoch": 8.328511732561877,
      "grad_norm": 0.006178528536111116,
      "learning_rate": 8.895317689917498e-06,
      "loss": 0.0,
      "step": 77730
    },
    {
      "epoch": 8.329583199399979,
      "grad_norm": 0.06187760457396507,
      "learning_rate": 8.893889067466696e-06,
      "loss": 0.1362,
      "step": 77740
    },
    {
      "epoch": 8.33065466623808,
      "grad_norm": 0.000496518099680543,
      "learning_rate": 8.892460445015895e-06,
      "loss": 0.0004,
      "step": 77750
    },
    {
      "epoch": 8.331726133076181,
      "grad_norm": 0.4055537283420563,
      "learning_rate": 8.891031822565093e-06,
      "loss": 0.2269,
      "step": 77760
    },
    {
      "epoch": 8.332797599914283,
      "grad_norm": 0.0016995336627587676,
      "learning_rate": 8.88960320011429e-06,
      "loss": 0.126,
      "step": 77770
    },
    {
      "epoch": 8.333869066752385,
      "grad_norm": 0.00022846761567052454,
      "learning_rate": 8.888174577663488e-06,
      "loss": 0.0001,
      "step": 77780
    },
    {
      "epoch": 8.334940533590485,
      "grad_norm": 0.0002328074479009956,
      "learning_rate": 8.886745955212687e-06,
      "loss": 0.1606,
      "step": 77790
    },
    {
      "epoch": 8.336012000428587,
      "grad_norm": 0.00025017609004862607,
      "learning_rate": 8.885317332761885e-06,
      "loss": 0.0003,
      "step": 77800
    },
    {
      "epoch": 8.337083467266687,
      "grad_norm": 0.0002832571917679161,
      "learning_rate": 8.883888710311084e-06,
      "loss": 0.1519,
      "step": 77810
    },
    {
      "epoch": 8.33815493410479,
      "grad_norm": 0.00022774092212785035,
      "learning_rate": 8.882460087860282e-06,
      "loss": 0.0,
      "step": 77820
    },
    {
      "epoch": 8.339226400942891,
      "grad_norm": 0.00019796249398496002,
      "learning_rate": 8.88103146540948e-06,
      "loss": 0.0001,
      "step": 77830
    },
    {
      "epoch": 8.340297867780992,
      "grad_norm": 0.0003629258135333657,
      "learning_rate": 8.879602842958677e-06,
      "loss": 0.0,
      "step": 77840
    },
    {
      "epoch": 8.341369334619094,
      "grad_norm": 0.004065409768372774,
      "learning_rate": 8.878174220507875e-06,
      "loss": 0.0,
      "step": 77850
    },
    {
      "epoch": 8.342440801457196,
      "grad_norm": 0.00019981455989181995,
      "learning_rate": 8.876745598057074e-06,
      "loss": 0.1338,
      "step": 77860
    },
    {
      "epoch": 8.343512268295296,
      "grad_norm": 0.00015039108984638005,
      "learning_rate": 8.875316975606272e-06,
      "loss": 0.0001,
      "step": 77870
    },
    {
      "epoch": 8.344583735133398,
      "grad_norm": 0.00017719528113957494,
      "learning_rate": 8.873888353155471e-06,
      "loss": 0.011,
      "step": 77880
    },
    {
      "epoch": 8.3456552019715,
      "grad_norm": 0.00013745634350925684,
      "learning_rate": 8.87245973070467e-06,
      "loss": 0.0,
      "step": 77890
    },
    {
      "epoch": 8.3467266688096,
      "grad_norm": 0.00016070094716269523,
      "learning_rate": 8.871031108253867e-06,
      "loss": 0.0001,
      "step": 77900
    },
    {
      "epoch": 8.347798135647702,
      "grad_norm": 0.005472989287227392,
      "learning_rate": 8.869602485803065e-06,
      "loss": 0.0,
      "step": 77910
    },
    {
      "epoch": 8.348869602485802,
      "grad_norm": 0.00018632628780324012,
      "learning_rate": 8.868173863352262e-06,
      "loss": 0.0001,
      "step": 77920
    },
    {
      "epoch": 8.349941069323904,
      "grad_norm": 0.003641377668827772,
      "learning_rate": 8.866745240901462e-06,
      "loss": 0.0,
      "step": 77930
    },
    {
      "epoch": 8.351012536162006,
      "grad_norm": 0.0386749729514122,
      "learning_rate": 8.86531661845066e-06,
      "loss": 0.0001,
      "step": 77940
    },
    {
      "epoch": 8.352084003000106,
      "grad_norm": 0.00014409665891434997,
      "learning_rate": 8.863887995999859e-06,
      "loss": 0.0001,
      "step": 77950
    },
    {
      "epoch": 8.353155469838208,
      "grad_norm": 0.05058140307664871,
      "learning_rate": 8.862459373549056e-06,
      "loss": 0.0001,
      "step": 77960
    },
    {
      "epoch": 8.35422693667631,
      "grad_norm": 0.0028908634558320045,
      "learning_rate": 8.861030751098254e-06,
      "loss": 0.2823,
      "step": 77970
    },
    {
      "epoch": 8.35529840351441,
      "grad_norm": 0.003227673703804612,
      "learning_rate": 8.859602128647452e-06,
      "loss": 0.0001,
      "step": 77980
    },
    {
      "epoch": 8.356369870352513,
      "grad_norm": 0.0012033125385642052,
      "learning_rate": 8.85817350619665e-06,
      "loss": 0.0,
      "step": 77990
    },
    {
      "epoch": 8.357441337190615,
      "grad_norm": 0.0010871144477277994,
      "learning_rate": 8.856744883745849e-06,
      "loss": 0.0,
      "step": 78000
    },
    {
      "epoch": 8.358512804028715,
      "grad_norm": 53.13872146606445,
      "learning_rate": 8.855316261295048e-06,
      "loss": 0.2585,
      "step": 78010
    },
    {
      "epoch": 8.359584270866817,
      "grad_norm": 0.0001579224190209061,
      "learning_rate": 8.853887638844246e-06,
      "loss": 0.0001,
      "step": 78020
    },
    {
      "epoch": 8.360655737704919,
      "grad_norm": 0.00030958018032833934,
      "learning_rate": 8.852459016393443e-06,
      "loss": 0.0009,
      "step": 78030
    },
    {
      "epoch": 8.361727204543019,
      "grad_norm": 0.00018023648590315133,
      "learning_rate": 8.851030393942641e-06,
      "loss": 0.0112,
      "step": 78040
    },
    {
      "epoch": 8.362798671381121,
      "grad_norm": 0.00032497328356839716,
      "learning_rate": 8.849601771491839e-06,
      "loss": 0.0,
      "step": 78050
    },
    {
      "epoch": 8.363870138219221,
      "grad_norm": 0.00018519598233979195,
      "learning_rate": 8.848173149041038e-06,
      "loss": 0.0,
      "step": 78060
    },
    {
      "epoch": 8.364941605057323,
      "grad_norm": 0.1387089043855667,
      "learning_rate": 8.846744526590236e-06,
      "loss": 0.0959,
      "step": 78070
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 0.0069099473766982555,
      "learning_rate": 8.845315904139435e-06,
      "loss": 0.1849,
      "step": 78080
    },
    {
      "epoch": 8.367084538733526,
      "grad_norm": 0.00024603508063592017,
      "learning_rate": 8.843887281688633e-06,
      "loss": 0.3258,
      "step": 78090
    },
    {
      "epoch": 8.368156005571628,
      "grad_norm": 0.03960498422384262,
      "learning_rate": 8.84245865923783e-06,
      "loss": 0.0001,
      "step": 78100
    },
    {
      "epoch": 8.36922747240973,
      "grad_norm": 0.0014282774645835161,
      "learning_rate": 8.841030036787028e-06,
      "loss": 0.0002,
      "step": 78110
    },
    {
      "epoch": 8.37029893924783,
      "grad_norm": 0.0002619634033180773,
      "learning_rate": 8.839601414336227e-06,
      "loss": 0.0001,
      "step": 78120
    },
    {
      "epoch": 8.371370406085932,
      "grad_norm": 0.00021746661514043808,
      "learning_rate": 8.838172791885425e-06,
      "loss": 0.0006,
      "step": 78130
    },
    {
      "epoch": 8.372441872924034,
      "grad_norm": 0.004590480588376522,
      "learning_rate": 8.836744169434623e-06,
      "loss": 0.1331,
      "step": 78140
    },
    {
      "epoch": 8.373513339762134,
      "grad_norm": 0.00033941466244868934,
      "learning_rate": 8.835315546983822e-06,
      "loss": 0.1128,
      "step": 78150
    },
    {
      "epoch": 8.374584806600236,
      "grad_norm": 0.04994640871882439,
      "learning_rate": 8.83388692453302e-06,
      "loss": 0.0002,
      "step": 78160
    },
    {
      "epoch": 8.375656273438338,
      "grad_norm": 0.00048227052320726216,
      "learning_rate": 8.832458302082218e-06,
      "loss": 0.0001,
      "step": 78170
    },
    {
      "epoch": 8.376727740276438,
      "grad_norm": 0.0001744619949022308,
      "learning_rate": 8.831029679631417e-06,
      "loss": 0.0012,
      "step": 78180
    },
    {
      "epoch": 8.37779920711454,
      "grad_norm": 0.4910503625869751,
      "learning_rate": 8.829601057180615e-06,
      "loss": 0.0009,
      "step": 78190
    },
    {
      "epoch": 8.37887067395264,
      "grad_norm": 0.00019255492952652276,
      "learning_rate": 8.828172434729812e-06,
      "loss": 0.0,
      "step": 78200
    },
    {
      "epoch": 8.379942140790742,
      "grad_norm": 0.005057128146290779,
      "learning_rate": 8.82674381227901e-06,
      "loss": 0.0005,
      "step": 78210
    },
    {
      "epoch": 8.381013607628844,
      "grad_norm": 0.00020073007908649743,
      "learning_rate": 8.82531518982821e-06,
      "loss": 0.189,
      "step": 78220
    },
    {
      "epoch": 8.382085074466945,
      "grad_norm": 0.0012707215500995517,
      "learning_rate": 8.823886567377407e-06,
      "loss": 0.0001,
      "step": 78230
    },
    {
      "epoch": 8.383156541305047,
      "grad_norm": 0.0030154301784932613,
      "learning_rate": 8.822457944926606e-06,
      "loss": 0.0005,
      "step": 78240
    },
    {
      "epoch": 8.384228008143149,
      "grad_norm": 0.08584889769554138,
      "learning_rate": 8.821029322475804e-06,
      "loss": 0.0001,
      "step": 78250
    },
    {
      "epoch": 8.385299474981249,
      "grad_norm": 0.0010478432523086667,
      "learning_rate": 8.819600700025002e-06,
      "loss": 0.0001,
      "step": 78260
    },
    {
      "epoch": 8.38637094181935,
      "grad_norm": 0.05068236589431763,
      "learning_rate": 8.8181720775742e-06,
      "loss": 0.0002,
      "step": 78270
    },
    {
      "epoch": 8.387442408657453,
      "grad_norm": 0.0001716159749776125,
      "learning_rate": 8.816743455123397e-06,
      "loss": 0.3034,
      "step": 78280
    },
    {
      "epoch": 8.388513875495553,
      "grad_norm": 0.00016251709894277155,
      "learning_rate": 8.815314832672596e-06,
      "loss": 0.0,
      "step": 78290
    },
    {
      "epoch": 8.389585342333655,
      "grad_norm": 0.0036476580426096916,
      "learning_rate": 8.813886210221794e-06,
      "loss": 0.0912,
      "step": 78300
    },
    {
      "epoch": 8.390656809171755,
      "grad_norm": 0.002592785283923149,
      "learning_rate": 8.812457587770993e-06,
      "loss": 0.1258,
      "step": 78310
    },
    {
      "epoch": 8.391728276009857,
      "grad_norm": 0.00024492546799592674,
      "learning_rate": 8.811028965320191e-06,
      "loss": 0.2366,
      "step": 78320
    },
    {
      "epoch": 8.39279974284796,
      "grad_norm": 0.00024741055676713586,
      "learning_rate": 8.809600342869389e-06,
      "loss": 0.2629,
      "step": 78330
    },
    {
      "epoch": 8.39387120968606,
      "grad_norm": 0.001203481457196176,
      "learning_rate": 8.808171720418586e-06,
      "loss": 0.0001,
      "step": 78340
    },
    {
      "epoch": 8.394942676524161,
      "grad_norm": 0.000207350924029015,
      "learning_rate": 8.806743097967784e-06,
      "loss": 0.0001,
      "step": 78350
    },
    {
      "epoch": 8.396014143362263,
      "grad_norm": 0.0002219690941274166,
      "learning_rate": 8.805314475516983e-06,
      "loss": 0.2442,
      "step": 78360
    },
    {
      "epoch": 8.397085610200364,
      "grad_norm": 0.00019720999989658594,
      "learning_rate": 8.803885853066181e-06,
      "loss": 0.0006,
      "step": 78370
    },
    {
      "epoch": 8.398157077038466,
      "grad_norm": 0.029851939529180527,
      "learning_rate": 8.80245723061538e-06,
      "loss": 0.1053,
      "step": 78380
    },
    {
      "epoch": 8.399228543876568,
      "grad_norm": 0.0002478051173966378,
      "learning_rate": 8.801028608164578e-06,
      "loss": 0.0087,
      "step": 78390
    },
    {
      "epoch": 8.400300010714668,
      "grad_norm": 0.005849996116012335,
      "learning_rate": 8.799599985713776e-06,
      "loss": 0.0001,
      "step": 78400
    },
    {
      "epoch": 8.40137147755277,
      "grad_norm": 0.001448279363103211,
      "learning_rate": 8.798171363262974e-06,
      "loss": 0.0002,
      "step": 78410
    },
    {
      "epoch": 8.402442944390872,
      "grad_norm": 14.894522666931152,
      "learning_rate": 8.796742740812173e-06,
      "loss": 0.0193,
      "step": 78420
    },
    {
      "epoch": 8.403514411228972,
      "grad_norm": 0.002846826333552599,
      "learning_rate": 8.79531411836137e-06,
      "loss": 0.0002,
      "step": 78430
    },
    {
      "epoch": 8.404585878067074,
      "grad_norm": 0.005978618282824755,
      "learning_rate": 8.793885495910568e-06,
      "loss": 0.3989,
      "step": 78440
    },
    {
      "epoch": 8.405657344905174,
      "grad_norm": 0.0005407274002209306,
      "learning_rate": 8.792456873459768e-06,
      "loss": 0.0005,
      "step": 78450
    },
    {
      "epoch": 8.406728811743276,
      "grad_norm": 0.001155540463514626,
      "learning_rate": 8.791028251008965e-06,
      "loss": 0.0001,
      "step": 78460
    },
    {
      "epoch": 8.407800278581378,
      "grad_norm": 0.014009165577590466,
      "learning_rate": 8.789599628558163e-06,
      "loss": 0.0001,
      "step": 78470
    },
    {
      "epoch": 8.408871745419479,
      "grad_norm": 0.0005198898143135011,
      "learning_rate": 8.788171006107362e-06,
      "loss": 0.0001,
      "step": 78480
    },
    {
      "epoch": 8.40994321225758,
      "grad_norm": 0.0008134983945637941,
      "learning_rate": 8.78674238365656e-06,
      "loss": 0.0004,
      "step": 78490
    },
    {
      "epoch": 8.411014679095683,
      "grad_norm": 0.00047991983592510223,
      "learning_rate": 8.785313761205758e-06,
      "loss": 0.0001,
      "step": 78500
    },
    {
      "epoch": 8.412086145933783,
      "grad_norm": 0.0048653362318873405,
      "learning_rate": 8.783885138754955e-06,
      "loss": 0.0003,
      "step": 78510
    },
    {
      "epoch": 8.413157612771885,
      "grad_norm": 0.002559822052717209,
      "learning_rate": 8.782456516304155e-06,
      "loss": 0.0001,
      "step": 78520
    },
    {
      "epoch": 8.414229079609987,
      "grad_norm": 0.0027198297902941704,
      "learning_rate": 8.781027893853352e-06,
      "loss": 0.0001,
      "step": 78530
    },
    {
      "epoch": 8.415300546448087,
      "grad_norm": 0.002755669178441167,
      "learning_rate": 8.779599271402552e-06,
      "loss": 0.272,
      "step": 78540
    },
    {
      "epoch": 8.416372013286189,
      "grad_norm": 0.004976956639438868,
      "learning_rate": 8.77817064895175e-06,
      "loss": 0.2853,
      "step": 78550
    },
    {
      "epoch": 8.417443480124291,
      "grad_norm": 0.035097189247608185,
      "learning_rate": 8.776742026500947e-06,
      "loss": 0.1559,
      "step": 78560
    },
    {
      "epoch": 8.418514946962391,
      "grad_norm": 0.0038685102481395006,
      "learning_rate": 8.775313404050145e-06,
      "loss": 0.0016,
      "step": 78570
    },
    {
      "epoch": 8.419586413800493,
      "grad_norm": 0.008945675566792488,
      "learning_rate": 8.773884781599344e-06,
      "loss": 0.2505,
      "step": 78580
    },
    {
      "epoch": 8.420657880638593,
      "grad_norm": 0.0007589340675622225,
      "learning_rate": 8.772456159148542e-06,
      "loss": 0.0003,
      "step": 78590
    },
    {
      "epoch": 8.421729347476695,
      "grad_norm": 0.000713133835233748,
      "learning_rate": 8.771027536697741e-06,
      "loss": 0.0017,
      "step": 78600
    },
    {
      "epoch": 8.422800814314797,
      "grad_norm": 0.006571498233824968,
      "learning_rate": 8.769598914246939e-06,
      "loss": 0.0001,
      "step": 78610
    },
    {
      "epoch": 8.423872281152898,
      "grad_norm": 0.014287648722529411,
      "learning_rate": 8.768170291796137e-06,
      "loss": 0.0001,
      "step": 78620
    },
    {
      "epoch": 8.424943747991,
      "grad_norm": 0.0038422788493335247,
      "learning_rate": 8.766741669345334e-06,
      "loss": 0.0001,
      "step": 78630
    },
    {
      "epoch": 8.426015214829102,
      "grad_norm": 0.04161796718835831,
      "learning_rate": 8.765313046894532e-06,
      "loss": 0.116,
      "step": 78640
    },
    {
      "epoch": 8.427086681667202,
      "grad_norm": 0.0006108314264565706,
      "learning_rate": 8.763884424443731e-06,
      "loss": 0.0011,
      "step": 78650
    },
    {
      "epoch": 8.428158148505304,
      "grad_norm": 22.30774688720703,
      "learning_rate": 8.762455801992929e-06,
      "loss": 0.1962,
      "step": 78660
    },
    {
      "epoch": 8.429229615343406,
      "grad_norm": 0.0005710904952138662,
      "learning_rate": 8.761027179542128e-06,
      "loss": 0.0011,
      "step": 78670
    },
    {
      "epoch": 8.430301082181506,
      "grad_norm": 0.0014142560539767146,
      "learning_rate": 8.759598557091326e-06,
      "loss": 0.0,
      "step": 78680
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.04307404160499573,
      "learning_rate": 8.758169934640524e-06,
      "loss": 0.0001,
      "step": 78690
    },
    {
      "epoch": 8.432444015857708,
      "grad_norm": 0.0009921930031850934,
      "learning_rate": 8.756741312189721e-06,
      "loss": 0.0001,
      "step": 78700
    },
    {
      "epoch": 8.43351548269581,
      "grad_norm": 0.00399093609303236,
      "learning_rate": 8.755312689738919e-06,
      "loss": 0.0011,
      "step": 78710
    },
    {
      "epoch": 8.434586949533912,
      "grad_norm": 0.00043423078022897243,
      "learning_rate": 8.753884067288118e-06,
      "loss": 0.0751,
      "step": 78720
    },
    {
      "epoch": 8.435658416372013,
      "grad_norm": 0.0006137734744697809,
      "learning_rate": 8.752455444837316e-06,
      "loss": 0.1022,
      "step": 78730
    },
    {
      "epoch": 8.436729883210115,
      "grad_norm": 0.0006919127190485597,
      "learning_rate": 8.751026822386515e-06,
      "loss": 0.0363,
      "step": 78740
    },
    {
      "epoch": 8.437801350048217,
      "grad_norm": 0.0012922383612021804,
      "learning_rate": 8.749598199935713e-06,
      "loss": 0.0001,
      "step": 78750
    },
    {
      "epoch": 8.438872816886317,
      "grad_norm": 0.0006060548475943506,
      "learning_rate": 8.74816957748491e-06,
      "loss": 0.0595,
      "step": 78760
    },
    {
      "epoch": 8.439944283724419,
      "grad_norm": 0.00037453489494509995,
      "learning_rate": 8.746740955034108e-06,
      "loss": 0.0,
      "step": 78770
    },
    {
      "epoch": 8.44101575056252,
      "grad_norm": 0.0003223743988201022,
      "learning_rate": 8.745312332583308e-06,
      "loss": 0.0011,
      "step": 78780
    },
    {
      "epoch": 8.442087217400621,
      "grad_norm": 0.0023141317069530487,
      "learning_rate": 8.743883710132505e-06,
      "loss": 0.0,
      "step": 78790
    },
    {
      "epoch": 8.443158684238723,
      "grad_norm": 0.004298383370041847,
      "learning_rate": 8.742455087681703e-06,
      "loss": 0.0024,
      "step": 78800
    },
    {
      "epoch": 8.444230151076825,
      "grad_norm": 0.003099493682384491,
      "learning_rate": 8.741026465230902e-06,
      "loss": 0.0003,
      "step": 78810
    },
    {
      "epoch": 8.445301617914925,
      "grad_norm": 0.00030732841696590185,
      "learning_rate": 8.7395978427801e-06,
      "loss": 0.0008,
      "step": 78820
    },
    {
      "epoch": 8.446373084753027,
      "grad_norm": 33.69925308227539,
      "learning_rate": 8.738169220329298e-06,
      "loss": 0.3598,
      "step": 78830
    },
    {
      "epoch": 8.44744455159113,
      "grad_norm": 0.004239625763148069,
      "learning_rate": 8.736740597878495e-06,
      "loss": 0.1257,
      "step": 78840
    },
    {
      "epoch": 8.44851601842923,
      "grad_norm": 0.0010653319768607616,
      "learning_rate": 8.735311975427695e-06,
      "loss": 0.0001,
      "step": 78850
    },
    {
      "epoch": 8.449587485267331,
      "grad_norm": 0.002768070437014103,
      "learning_rate": 8.733883352976893e-06,
      "loss": 0.0003,
      "step": 78860
    },
    {
      "epoch": 8.450658952105432,
      "grad_norm": 17.498760223388672,
      "learning_rate": 8.73245473052609e-06,
      "loss": 0.1904,
      "step": 78870
    },
    {
      "epoch": 8.451730418943534,
      "grad_norm": 0.004497430752962828,
      "learning_rate": 8.73102610807529e-06,
      "loss": 0.0007,
      "step": 78880
    },
    {
      "epoch": 8.452801885781636,
      "grad_norm": 36.82483673095703,
      "learning_rate": 8.729597485624487e-06,
      "loss": 0.1639,
      "step": 78890
    },
    {
      "epoch": 8.453873352619736,
      "grad_norm": 0.0003672035236377269,
      "learning_rate": 8.728168863173685e-06,
      "loss": 0.0005,
      "step": 78900
    },
    {
      "epoch": 8.454944819457838,
      "grad_norm": 0.0003494450356811285,
      "learning_rate": 8.726740240722884e-06,
      "loss": 0.0001,
      "step": 78910
    },
    {
      "epoch": 8.45601628629594,
      "grad_norm": 0.23277483880519867,
      "learning_rate": 8.725311618272082e-06,
      "loss": 0.0002,
      "step": 78920
    },
    {
      "epoch": 8.45708775313404,
      "grad_norm": 0.0011217650026082993,
      "learning_rate": 8.72388299582128e-06,
      "loss": 0.0069,
      "step": 78930
    },
    {
      "epoch": 8.458159219972142,
      "grad_norm": 0.0016948964912444353,
      "learning_rate": 8.722454373370477e-06,
      "loss": 0.0002,
      "step": 78940
    },
    {
      "epoch": 8.459230686810244,
      "grad_norm": 23.768070220947266,
      "learning_rate": 8.721025750919677e-06,
      "loss": 0.278,
      "step": 78950
    },
    {
      "epoch": 8.460302153648344,
      "grad_norm": 0.004560456145554781,
      "learning_rate": 8.719597128468874e-06,
      "loss": 0.3113,
      "step": 78960
    },
    {
      "epoch": 8.461373620486446,
      "grad_norm": 0.000872303731739521,
      "learning_rate": 8.718168506018074e-06,
      "loss": 0.0127,
      "step": 78970
    },
    {
      "epoch": 8.462445087324546,
      "grad_norm": 0.0004588039009831846,
      "learning_rate": 8.716739883567271e-06,
      "loss": 0.0,
      "step": 78980
    },
    {
      "epoch": 8.463516554162648,
      "grad_norm": 0.00043500636820681393,
      "learning_rate": 8.715311261116469e-06,
      "loss": 0.0008,
      "step": 78990
    },
    {
      "epoch": 8.46458802100075,
      "grad_norm": 0.20076537132263184,
      "learning_rate": 8.713882638665667e-06,
      "loss": 0.0008,
      "step": 79000
    },
    {
      "epoch": 8.46565948783885,
      "grad_norm": 0.006543926429003477,
      "learning_rate": 8.712454016214864e-06,
      "loss": 0.0002,
      "step": 79010
    },
    {
      "epoch": 8.466730954676953,
      "grad_norm": 0.0007777842693030834,
      "learning_rate": 8.711025393764064e-06,
      "loss": 0.0001,
      "step": 79020
    },
    {
      "epoch": 8.467802421515055,
      "grad_norm": 0.00033503849408589303,
      "learning_rate": 8.709596771313263e-06,
      "loss": 0.0001,
      "step": 79030
    },
    {
      "epoch": 8.468873888353155,
      "grad_norm": 0.009002194739878178,
      "learning_rate": 8.70816814886246e-06,
      "loss": 0.0002,
      "step": 79040
    },
    {
      "epoch": 8.469945355191257,
      "grad_norm": 0.0055765858851373196,
      "learning_rate": 8.706739526411658e-06,
      "loss": 0.0006,
      "step": 79050
    },
    {
      "epoch": 8.471016822029359,
      "grad_norm": 0.0018567569786682725,
      "learning_rate": 8.705310903960856e-06,
      "loss": 0.0,
      "step": 79060
    },
    {
      "epoch": 8.47208828886746,
      "grad_norm": 0.0005333971930667758,
      "learning_rate": 8.703882281510054e-06,
      "loss": 0.0,
      "step": 79070
    },
    {
      "epoch": 8.473159755705561,
      "grad_norm": 0.017152082175016403,
      "learning_rate": 8.702453659059251e-06,
      "loss": 0.0001,
      "step": 79080
    },
    {
      "epoch": 8.474231222543663,
      "grad_norm": 0.004397776443511248,
      "learning_rate": 8.70102503660845e-06,
      "loss": 0.0001,
      "step": 79090
    },
    {
      "epoch": 8.475302689381763,
      "grad_norm": 0.006868446245789528,
      "learning_rate": 8.69959641415765e-06,
      "loss": 0.1693,
      "step": 79100
    },
    {
      "epoch": 8.476374156219865,
      "grad_norm": 0.0035204787272959948,
      "learning_rate": 8.698167791706848e-06,
      "loss": 0.0695,
      "step": 79110
    },
    {
      "epoch": 8.477445623057966,
      "grad_norm": 0.006668418180197477,
      "learning_rate": 8.696739169256046e-06,
      "loss": 0.0002,
      "step": 79120
    },
    {
      "epoch": 8.478517089896068,
      "grad_norm": 0.003916457761079073,
      "learning_rate": 8.695310546805243e-06,
      "loss": 0.1038,
      "step": 79130
    },
    {
      "epoch": 8.47958855673417,
      "grad_norm": 0.00043200067011639476,
      "learning_rate": 8.693881924354441e-06,
      "loss": 0.0001,
      "step": 79140
    },
    {
      "epoch": 8.48066002357227,
      "grad_norm": 0.0011934059439226985,
      "learning_rate": 8.69245330190364e-06,
      "loss": 0.0003,
      "step": 79150
    },
    {
      "epoch": 8.481731490410372,
      "grad_norm": 0.005354630295187235,
      "learning_rate": 8.691024679452838e-06,
      "loss": 0.1129,
      "step": 79160
    },
    {
      "epoch": 8.482802957248474,
      "grad_norm": 0.0010964712128043175,
      "learning_rate": 8.689596057002037e-06,
      "loss": 0.0,
      "step": 79170
    },
    {
      "epoch": 8.483874424086574,
      "grad_norm": 0.0005528501933440566,
      "learning_rate": 8.688167434551235e-06,
      "loss": 0.0922,
      "step": 79180
    },
    {
      "epoch": 8.484945890924676,
      "grad_norm": 0.010912339203059673,
      "learning_rate": 8.686738812100433e-06,
      "loss": 0.0,
      "step": 79190
    },
    {
      "epoch": 8.486017357762778,
      "grad_norm": 0.012554572895169258,
      "learning_rate": 8.68531018964963e-06,
      "loss": 0.0022,
      "step": 79200
    },
    {
      "epoch": 8.487088824600878,
      "grad_norm": 0.03235344588756561,
      "learning_rate": 8.68388156719883e-06,
      "loss": 0.0001,
      "step": 79210
    },
    {
      "epoch": 8.48816029143898,
      "grad_norm": 0.003836462739855051,
      "learning_rate": 8.682452944748027e-06,
      "loss": 0.0,
      "step": 79220
    },
    {
      "epoch": 8.489231758277082,
      "grad_norm": 0.0005208056536503136,
      "learning_rate": 8.681024322297225e-06,
      "loss": 0.0,
      "step": 79230
    },
    {
      "epoch": 8.490303225115182,
      "grad_norm": 0.0003858054697047919,
      "learning_rate": 8.679595699846424e-06,
      "loss": 0.0,
      "step": 79240
    },
    {
      "epoch": 8.491374691953284,
      "grad_norm": 0.0003173232835251838,
      "learning_rate": 8.678167077395622e-06,
      "loss": 0.0003,
      "step": 79250
    },
    {
      "epoch": 8.492446158791385,
      "grad_norm": 0.0018643962685018778,
      "learning_rate": 8.67673845494482e-06,
      "loss": 0.0479,
      "step": 79260
    },
    {
      "epoch": 8.493517625629487,
      "grad_norm": 0.00047656436800025403,
      "learning_rate": 8.675309832494019e-06,
      "loss": 0.0009,
      "step": 79270
    },
    {
      "epoch": 8.494589092467589,
      "grad_norm": 0.0003097347798757255,
      "learning_rate": 8.673881210043217e-06,
      "loss": 0.0,
      "step": 79280
    },
    {
      "epoch": 8.495660559305689,
      "grad_norm": 0.0005794515600427985,
      "learning_rate": 8.672452587592414e-06,
      "loss": 0.0001,
      "step": 79290
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 0.020174387842416763,
      "learning_rate": 8.671023965141612e-06,
      "loss": 0.0001,
      "step": 79300
    },
    {
      "epoch": 8.497803492981893,
      "grad_norm": 0.30076760053634644,
      "learning_rate": 8.669595342690811e-06,
      "loss": 0.0005,
      "step": 79310
    },
    {
      "epoch": 8.498874959819993,
      "grad_norm": 0.0020354047883301973,
      "learning_rate": 8.66816672024001e-06,
      "loss": 0.0,
      "step": 79320
    },
    {
      "epoch": 8.499946426658095,
      "grad_norm": 0.0031624084804207087,
      "learning_rate": 8.666738097789209e-06,
      "loss": 0.0,
      "step": 79330
    },
    {
      "epoch": 8.501017893496197,
      "grad_norm": 0.0011612590169534087,
      "learning_rate": 8.665309475338406e-06,
      "loss": 0.1629,
      "step": 79340
    },
    {
      "epoch": 8.502089360334297,
      "grad_norm": 0.002314596436917782,
      "learning_rate": 8.663880852887604e-06,
      "loss": 0.0,
      "step": 79350
    },
    {
      "epoch": 8.5031608271724,
      "grad_norm": 0.00041073159081861377,
      "learning_rate": 8.662452230436802e-06,
      "loss": 0.0,
      "step": 79360
    },
    {
      "epoch": 8.5042322940105,
      "grad_norm": 0.00033648652606643736,
      "learning_rate": 8.661023607986e-06,
      "loss": 0.0,
      "step": 79370
    },
    {
      "epoch": 8.505303760848602,
      "grad_norm": 46.83859634399414,
      "learning_rate": 8.659594985535199e-06,
      "loss": 0.0699,
      "step": 79380
    },
    {
      "epoch": 8.506375227686704,
      "grad_norm": 0.0002164599281968549,
      "learning_rate": 8.658166363084396e-06,
      "loss": 0.0004,
      "step": 79390
    },
    {
      "epoch": 8.507446694524804,
      "grad_norm": 0.00032712146639823914,
      "learning_rate": 8.656737740633596e-06,
      "loss": 0.0003,
      "step": 79400
    },
    {
      "epoch": 8.508518161362906,
      "grad_norm": 0.0003183348453603685,
      "learning_rate": 8.655309118182793e-06,
      "loss": 0.0,
      "step": 79410
    },
    {
      "epoch": 8.509589628201008,
      "grad_norm": 27.901411056518555,
      "learning_rate": 8.653880495731991e-06,
      "loss": 0.3111,
      "step": 79420
    },
    {
      "epoch": 8.510661095039108,
      "grad_norm": 0.0002860566310118884,
      "learning_rate": 8.652451873281189e-06,
      "loss": 0.0002,
      "step": 79430
    },
    {
      "epoch": 8.51173256187721,
      "grad_norm": 0.0003041703312192112,
      "learning_rate": 8.651023250830386e-06,
      "loss": 0.2169,
      "step": 79440
    },
    {
      "epoch": 8.512804028715312,
      "grad_norm": 0.0018371822079643607,
      "learning_rate": 8.649594628379586e-06,
      "loss": 0.0001,
      "step": 79450
    },
    {
      "epoch": 8.513875495553412,
      "grad_norm": 0.020253226161003113,
      "learning_rate": 8.648166005928783e-06,
      "loss": 0.0002,
      "step": 79460
    },
    {
      "epoch": 8.514946962391514,
      "grad_norm": 0.0003751710173673928,
      "learning_rate": 8.646737383477983e-06,
      "loss": 0.0001,
      "step": 79470
    },
    {
      "epoch": 8.516018429229616,
      "grad_norm": 0.004897955805063248,
      "learning_rate": 8.64530876102718e-06,
      "loss": 0.0001,
      "step": 79480
    },
    {
      "epoch": 8.517089896067716,
      "grad_norm": 0.0005864467239007354,
      "learning_rate": 8.643880138576378e-06,
      "loss": 0.0118,
      "step": 79490
    },
    {
      "epoch": 8.518161362905818,
      "grad_norm": 0.00032786731026135385,
      "learning_rate": 8.642451516125576e-06,
      "loss": 0.001,
      "step": 79500
    },
    {
      "epoch": 8.519232829743919,
      "grad_norm": 0.00019904655346181244,
      "learning_rate": 8.641022893674775e-06,
      "loss": 0.0002,
      "step": 79510
    },
    {
      "epoch": 8.52030429658202,
      "grad_norm": 0.0012609667610377073,
      "learning_rate": 8.639594271223973e-06,
      "loss": 0.0001,
      "step": 79520
    },
    {
      "epoch": 8.521375763420123,
      "grad_norm": 0.0002421040553599596,
      "learning_rate": 8.638165648773172e-06,
      "loss": 0.0001,
      "step": 79530
    },
    {
      "epoch": 8.522447230258223,
      "grad_norm": 0.000245286850258708,
      "learning_rate": 8.63673702632237e-06,
      "loss": 0.1615,
      "step": 79540
    },
    {
      "epoch": 8.523518697096325,
      "grad_norm": 0.04254892095923424,
      "learning_rate": 8.635308403871567e-06,
      "loss": 0.173,
      "step": 79550
    },
    {
      "epoch": 8.524590163934427,
      "grad_norm": 0.00023955032520461828,
      "learning_rate": 8.633879781420765e-06,
      "loss": 0.1239,
      "step": 79560
    },
    {
      "epoch": 8.525661630772527,
      "grad_norm": 0.00046115455916151404,
      "learning_rate": 8.632451158969965e-06,
      "loss": 0.0002,
      "step": 79570
    },
    {
      "epoch": 8.526733097610629,
      "grad_norm": 0.00037569450796581805,
      "learning_rate": 8.631022536519162e-06,
      "loss": 0.0001,
      "step": 79580
    },
    {
      "epoch": 8.527804564448731,
      "grad_norm": 0.00021889085473958403,
      "learning_rate": 8.62959391406836e-06,
      "loss": 0.0001,
      "step": 79590
    },
    {
      "epoch": 8.528876031286831,
      "grad_norm": 0.00019909368711523712,
      "learning_rate": 8.62816529161756e-06,
      "loss": 0.0,
      "step": 79600
    },
    {
      "epoch": 8.529947498124933,
      "grad_norm": 0.006048146635293961,
      "learning_rate": 8.626736669166757e-06,
      "loss": 0.1267,
      "step": 79610
    },
    {
      "epoch": 8.531018964963035,
      "grad_norm": 0.029966184869408607,
      "learning_rate": 8.625308046715955e-06,
      "loss": 0.0001,
      "step": 79620
    },
    {
      "epoch": 8.532090431801135,
      "grad_norm": 0.002952959155663848,
      "learning_rate": 8.623879424265154e-06,
      "loss": 0.1939,
      "step": 79630
    },
    {
      "epoch": 8.533161898639237,
      "grad_norm": 0.000645435182377696,
      "learning_rate": 8.622450801814352e-06,
      "loss": 0.1247,
      "step": 79640
    },
    {
      "epoch": 8.534233365477338,
      "grad_norm": 0.01460000779479742,
      "learning_rate": 8.62102217936355e-06,
      "loss": 0.0,
      "step": 79650
    },
    {
      "epoch": 8.53530483231544,
      "grad_norm": 0.00025163625832647085,
      "learning_rate": 8.619593556912747e-06,
      "loss": 0.0002,
      "step": 79660
    },
    {
      "epoch": 8.536376299153542,
      "grad_norm": 0.0002706233353819698,
      "learning_rate": 8.618164934461946e-06,
      "loss": 0.0061,
      "step": 79670
    },
    {
      "epoch": 8.537447765991642,
      "grad_norm": 0.00030208646785467863,
      "learning_rate": 8.616736312011144e-06,
      "loss": 0.0,
      "step": 79680
    },
    {
      "epoch": 8.538519232829744,
      "grad_norm": 0.00022072039428167045,
      "learning_rate": 8.615307689560343e-06,
      "loss": 0.0002,
      "step": 79690
    },
    {
      "epoch": 8.539590699667846,
      "grad_norm": 0.0032794796861708164,
      "learning_rate": 8.613879067109541e-06,
      "loss": 0.0591,
      "step": 79700
    },
    {
      "epoch": 8.540662166505946,
      "grad_norm": 0.00038523940020240843,
      "learning_rate": 8.612450444658739e-06,
      "loss": 0.0001,
      "step": 79710
    },
    {
      "epoch": 8.541733633344048,
      "grad_norm": 0.23654691874980927,
      "learning_rate": 8.611021822207936e-06,
      "loss": 0.2162,
      "step": 79720
    },
    {
      "epoch": 8.54280510018215,
      "grad_norm": 0.001394761959090829,
      "learning_rate": 8.609593199757134e-06,
      "loss": 0.0001,
      "step": 79730
    },
    {
      "epoch": 8.54387656702025,
      "grad_norm": 0.00024767080321907997,
      "learning_rate": 8.608164577306333e-06,
      "loss": 0.1195,
      "step": 79740
    },
    {
      "epoch": 8.544948033858352,
      "grad_norm": 0.0002620235027279705,
      "learning_rate": 8.606735954855531e-06,
      "loss": 0.0001,
      "step": 79750
    },
    {
      "epoch": 8.546019500696453,
      "grad_norm": 0.02943066507577896,
      "learning_rate": 8.60530733240473e-06,
      "loss": 0.0005,
      "step": 79760
    },
    {
      "epoch": 8.547090967534555,
      "grad_norm": 0.008793928660452366,
      "learning_rate": 8.603878709953928e-06,
      "loss": 0.0004,
      "step": 79770
    },
    {
      "epoch": 8.548162434372657,
      "grad_norm": 0.006618971936404705,
      "learning_rate": 8.602450087503126e-06,
      "loss": 0.0001,
      "step": 79780
    },
    {
      "epoch": 8.549233901210757,
      "grad_norm": 0.00034755904925987124,
      "learning_rate": 8.601021465052323e-06,
      "loss": 0.0001,
      "step": 79790
    },
    {
      "epoch": 8.550305368048859,
      "grad_norm": 0.00023592817888129503,
      "learning_rate": 8.599592842601521e-06,
      "loss": 0.0007,
      "step": 79800
    },
    {
      "epoch": 8.55137683488696,
      "grad_norm": 0.0001605657598702237,
      "learning_rate": 8.59816422015072e-06,
      "loss": 0.0,
      "step": 79810
    },
    {
      "epoch": 8.552448301725061,
      "grad_norm": 0.00020231475355103612,
      "learning_rate": 8.596735597699918e-06,
      "loss": 0.0,
      "step": 79820
    },
    {
      "epoch": 8.553519768563163,
      "grad_norm": 0.009512819349765778,
      "learning_rate": 8.595306975249118e-06,
      "loss": 0.0001,
      "step": 79830
    },
    {
      "epoch": 8.554591235401265,
      "grad_norm": 0.00023446879640687257,
      "learning_rate": 8.593878352798315e-06,
      "loss": 0.0003,
      "step": 79840
    },
    {
      "epoch": 8.555662702239365,
      "grad_norm": 0.001848546671681106,
      "learning_rate": 8.592449730347513e-06,
      "loss": 0.0,
      "step": 79850
    },
    {
      "epoch": 8.556734169077467,
      "grad_norm": 0.08583323657512665,
      "learning_rate": 8.59102110789671e-06,
      "loss": 0.0002,
      "step": 79860
    },
    {
      "epoch": 8.55780563591557,
      "grad_norm": 0.0002276327577419579,
      "learning_rate": 8.589592485445908e-06,
      "loss": 0.0,
      "step": 79870
    },
    {
      "epoch": 8.55887710275367,
      "grad_norm": 4.718028545379639,
      "learning_rate": 8.588163862995108e-06,
      "loss": 0.3133,
      "step": 79880
    },
    {
      "epoch": 8.559948569591771,
      "grad_norm": 0.0002548488846514374,
      "learning_rate": 8.586735240544305e-06,
      "loss": 0.0,
      "step": 79890
    },
    {
      "epoch": 8.561020036429873,
      "grad_norm": 0.00015790251200087368,
      "learning_rate": 8.585306618093505e-06,
      "loss": 0.0052,
      "step": 79900
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 0.00018323799304198474,
      "learning_rate": 8.583877995642702e-06,
      "loss": 0.0,
      "step": 79910
    },
    {
      "epoch": 8.563162970106076,
      "grad_norm": 0.012952357530593872,
      "learning_rate": 8.5824493731919e-06,
      "loss": 0.0001,
      "step": 79920
    },
    {
      "epoch": 8.564234436944176,
      "grad_norm": 0.00015388158499263227,
      "learning_rate": 8.581020750741098e-06,
      "loss": 0.0004,
      "step": 79930
    },
    {
      "epoch": 8.565305903782278,
      "grad_norm": 0.2716462016105652,
      "learning_rate": 8.579592128290297e-06,
      "loss": 0.0003,
      "step": 79940
    },
    {
      "epoch": 8.56637737062038,
      "grad_norm": 0.0001484643726143986,
      "learning_rate": 8.578163505839495e-06,
      "loss": 0.0,
      "step": 79950
    },
    {
      "epoch": 8.56744883745848,
      "grad_norm": 0.003765902016311884,
      "learning_rate": 8.576734883388692e-06,
      "loss": 0.0001,
      "step": 79960
    },
    {
      "epoch": 8.568520304296582,
      "grad_norm": 0.0019657050725072622,
      "learning_rate": 8.575306260937892e-06,
      "loss": 0.1577,
      "step": 79970
    },
    {
      "epoch": 8.569591771134684,
      "grad_norm": 0.00017400280921719968,
      "learning_rate": 8.57387763848709e-06,
      "loss": 0.0,
      "step": 79980
    },
    {
      "epoch": 8.570663237972784,
      "grad_norm": 0.00017644702165853232,
      "learning_rate": 8.572449016036287e-06,
      "loss": 0.0,
      "step": 79990
    },
    {
      "epoch": 8.571734704810886,
      "grad_norm": 0.0001989498850889504,
      "learning_rate": 8.571020393585486e-06,
      "loss": 0.1535,
      "step": 80000
    },
    {
      "epoch": 8.572806171648988,
      "grad_norm": 0.0036461851559579372,
      "learning_rate": 8.569591771134684e-06,
      "loss": 0.0006,
      "step": 80010
    },
    {
      "epoch": 8.573877638487089,
      "grad_norm": 0.000159895746037364,
      "learning_rate": 8.568163148683882e-06,
      "loss": 0.0002,
      "step": 80020
    },
    {
      "epoch": 8.57494910532519,
      "grad_norm": 0.0001917153858812526,
      "learning_rate": 8.56673452623308e-06,
      "loss": 0.0,
      "step": 80030
    },
    {
      "epoch": 8.57602057216329,
      "grad_norm": 56.59050369262695,
      "learning_rate": 8.565305903782279e-06,
      "loss": 0.135,
      "step": 80040
    },
    {
      "epoch": 8.577092039001393,
      "grad_norm": 0.00016327941557392478,
      "learning_rate": 8.563877281331477e-06,
      "loss": 0.0,
      "step": 80050
    },
    {
      "epoch": 8.578163505839495,
      "grad_norm": 0.0005471032927744091,
      "learning_rate": 8.562448658880676e-06,
      "loss": 0.0001,
      "step": 80060
    },
    {
      "epoch": 8.579234972677595,
      "grad_norm": 0.0035398981999605894,
      "learning_rate": 8.561020036429874e-06,
      "loss": 0.0,
      "step": 80070
    },
    {
      "epoch": 8.580306439515697,
      "grad_norm": 0.8463109135627747,
      "learning_rate": 8.559591413979071e-06,
      "loss": 0.0006,
      "step": 80080
    },
    {
      "epoch": 8.581377906353799,
      "grad_norm": 0.00015523667389061302,
      "learning_rate": 8.558162791528269e-06,
      "loss": 0.0001,
      "step": 80090
    },
    {
      "epoch": 8.5824493731919,
      "grad_norm": 0.00014680085587315261,
      "learning_rate": 8.556734169077468e-06,
      "loss": 0.0,
      "step": 80100
    },
    {
      "epoch": 8.583520840030001,
      "grad_norm": 0.00016914612206164747,
      "learning_rate": 8.555305546626666e-06,
      "loss": 0.1405,
      "step": 80110
    },
    {
      "epoch": 8.584592306868103,
      "grad_norm": 0.020520055666565895,
      "learning_rate": 8.553876924175865e-06,
      "loss": 0.0077,
      "step": 80120
    },
    {
      "epoch": 8.585663773706203,
      "grad_norm": 0.024943236261606216,
      "learning_rate": 8.552448301725063e-06,
      "loss": 0.0002,
      "step": 80130
    },
    {
      "epoch": 8.586735240544305,
      "grad_norm": 0.00027103666798211634,
      "learning_rate": 8.55101967927426e-06,
      "loss": 0.3299,
      "step": 80140
    },
    {
      "epoch": 8.587806707382406,
      "grad_norm": 0.00014704612840432674,
      "learning_rate": 8.549591056823458e-06,
      "loss": 0.0002,
      "step": 80150
    },
    {
      "epoch": 8.588878174220508,
      "grad_norm": 0.00018134429410565645,
      "learning_rate": 8.548162434372656e-06,
      "loss": 0.0707,
      "step": 80160
    },
    {
      "epoch": 8.58994964105861,
      "grad_norm": 0.00015507075295317918,
      "learning_rate": 8.546733811921855e-06,
      "loss": 0.0,
      "step": 80170
    },
    {
      "epoch": 8.59102110789671,
      "grad_norm": 0.0018312573665753007,
      "learning_rate": 8.545305189471053e-06,
      "loss": 0.132,
      "step": 80180
    },
    {
      "epoch": 8.592092574734812,
      "grad_norm": 0.0002760439820121974,
      "learning_rate": 8.543876567020252e-06,
      "loss": 0.269,
      "step": 80190
    },
    {
      "epoch": 8.593164041572914,
      "grad_norm": 2.2799465656280518,
      "learning_rate": 8.54244794456945e-06,
      "loss": 0.0872,
      "step": 80200
    },
    {
      "epoch": 8.594235508411014,
      "grad_norm": 0.0056388345547020435,
      "learning_rate": 8.541019322118648e-06,
      "loss": 0.0024,
      "step": 80210
    },
    {
      "epoch": 8.595306975249116,
      "grad_norm": 0.2098488211631775,
      "learning_rate": 8.539590699667845e-06,
      "loss": 0.1056,
      "step": 80220
    },
    {
      "epoch": 8.596378442087218,
      "grad_norm": 0.00019040291954297572,
      "learning_rate": 8.538162077217043e-06,
      "loss": 0.0007,
      "step": 80230
    },
    {
      "epoch": 8.597449908925318,
      "grad_norm": 0.00014890008606016636,
      "learning_rate": 8.536733454766242e-06,
      "loss": 0.164,
      "step": 80240
    },
    {
      "epoch": 8.59852137576342,
      "grad_norm": 0.000164060911629349,
      "learning_rate": 8.53530483231544e-06,
      "loss": 0.0003,
      "step": 80250
    },
    {
      "epoch": 8.599592842601522,
      "grad_norm": 0.8671821355819702,
      "learning_rate": 8.53387620986464e-06,
      "loss": 0.0011,
      "step": 80260
    },
    {
      "epoch": 8.600664309439622,
      "grad_norm": 0.005248786881566048,
      "learning_rate": 8.532447587413837e-06,
      "loss": 0.0001,
      "step": 80270
    },
    {
      "epoch": 8.601735776277724,
      "grad_norm": 13.460027694702148,
      "learning_rate": 8.531018964963035e-06,
      "loss": 0.0624,
      "step": 80280
    },
    {
      "epoch": 8.602807243115826,
      "grad_norm": 0.00015726330457255244,
      "learning_rate": 8.529590342512233e-06,
      "loss": 0.0,
      "step": 80290
    },
    {
      "epoch": 8.603878709953927,
      "grad_norm": 0.00026844223611988127,
      "learning_rate": 8.528161720061432e-06,
      "loss": 0.0519,
      "step": 80300
    },
    {
      "epoch": 8.604950176792029,
      "grad_norm": 0.00040034676203504205,
      "learning_rate": 8.52673309761063e-06,
      "loss": 0.1766,
      "step": 80310
    },
    {
      "epoch": 8.606021643630129,
      "grad_norm": 0.0005266540101729333,
      "learning_rate": 8.525304475159827e-06,
      "loss": 0.0001,
      "step": 80320
    },
    {
      "epoch": 8.607093110468231,
      "grad_norm": 0.005755873396992683,
      "learning_rate": 8.523875852709027e-06,
      "loss": 0.1519,
      "step": 80330
    },
    {
      "epoch": 8.608164577306333,
      "grad_norm": 0.00018205033848062158,
      "learning_rate": 8.522447230258224e-06,
      "loss": 0.0001,
      "step": 80340
    },
    {
      "epoch": 8.609236044144433,
      "grad_norm": 0.00018972711404785514,
      "learning_rate": 8.521018607807422e-06,
      "loss": 0.0,
      "step": 80350
    },
    {
      "epoch": 8.610307510982535,
      "grad_norm": 0.23248212039470673,
      "learning_rate": 8.519589985356621e-06,
      "loss": 0.0003,
      "step": 80360
    },
    {
      "epoch": 8.611378977820637,
      "grad_norm": 0.00015731414896436036,
      "learning_rate": 8.518161362905819e-06,
      "loss": 0.0,
      "step": 80370
    },
    {
      "epoch": 8.612450444658737,
      "grad_norm": 0.0001599431416252628,
      "learning_rate": 8.516732740455017e-06,
      "loss": 0.0722,
      "step": 80380
    },
    {
      "epoch": 8.61352191149684,
      "grad_norm": 0.0022554562892764807,
      "learning_rate": 8.515304118004214e-06,
      "loss": 0.0,
      "step": 80390
    },
    {
      "epoch": 8.614593378334941,
      "grad_norm": 0.019226184114813805,
      "learning_rate": 8.513875495553414e-06,
      "loss": 0.295,
      "step": 80400
    },
    {
      "epoch": 8.615664845173042,
      "grad_norm": 0.00043004684266634285,
      "learning_rate": 8.512446873102611e-06,
      "loss": 0.1057,
      "step": 80410
    },
    {
      "epoch": 8.616736312011144,
      "grad_norm": 0.004188175313174725,
      "learning_rate": 8.51101825065181e-06,
      "loss": 0.0005,
      "step": 80420
    },
    {
      "epoch": 8.617807778849244,
      "grad_norm": 0.0007060058414936066,
      "learning_rate": 8.509589628201008e-06,
      "loss": 0.3226,
      "step": 80430
    },
    {
      "epoch": 8.618879245687346,
      "grad_norm": 0.00039430116885341704,
      "learning_rate": 8.508161005750206e-06,
      "loss": 0.0,
      "step": 80440
    },
    {
      "epoch": 8.619950712525448,
      "grad_norm": 0.00034182946546934545,
      "learning_rate": 8.506732383299404e-06,
      "loss": 0.0,
      "step": 80450
    },
    {
      "epoch": 8.621022179363548,
      "grad_norm": 0.0005149313365109265,
      "learning_rate": 8.505303760848601e-06,
      "loss": 0.0024,
      "step": 80460
    },
    {
      "epoch": 8.62209364620165,
      "grad_norm": 0.12138180434703827,
      "learning_rate": 8.5038751383978e-06,
      "loss": 0.0002,
      "step": 80470
    },
    {
      "epoch": 8.623165113039752,
      "grad_norm": 0.00025608419673517346,
      "learning_rate": 8.502446515947e-06,
      "loss": 0.0014,
      "step": 80480
    },
    {
      "epoch": 8.624236579877852,
      "grad_norm": 0.020209815353155136,
      "learning_rate": 8.501017893496198e-06,
      "loss": 0.0008,
      "step": 80490
    },
    {
      "epoch": 8.625308046715954,
      "grad_norm": 0.00026474223705008626,
      "learning_rate": 8.499589271045396e-06,
      "loss": 0.2045,
      "step": 80500
    },
    {
      "epoch": 8.626379513554056,
      "grad_norm": 14.428994178771973,
      "learning_rate": 8.498160648594593e-06,
      "loss": 0.0058,
      "step": 80510
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 53.10009765625,
      "learning_rate": 8.496732026143791e-06,
      "loss": 0.0548,
      "step": 80520
    },
    {
      "epoch": 8.628522447230258,
      "grad_norm": 0.0006935471319593489,
      "learning_rate": 8.495303403692989e-06,
      "loss": 0.0,
      "step": 80530
    },
    {
      "epoch": 8.62959391406836,
      "grad_norm": 0.0003124620416201651,
      "learning_rate": 8.493874781242188e-06,
      "loss": 0.0002,
      "step": 80540
    },
    {
      "epoch": 8.63066538090646,
      "grad_norm": 0.0002537495456635952,
      "learning_rate": 8.492446158791387e-06,
      "loss": 0.0001,
      "step": 80550
    },
    {
      "epoch": 8.631736847744563,
      "grad_norm": 0.004094474483281374,
      "learning_rate": 8.491017536340585e-06,
      "loss": 0.0,
      "step": 80560
    },
    {
      "epoch": 8.632808314582663,
      "grad_norm": 0.22724932432174683,
      "learning_rate": 8.489588913889783e-06,
      "loss": 0.0001,
      "step": 80570
    },
    {
      "epoch": 8.633879781420765,
      "grad_norm": 0.0017807736294344068,
      "learning_rate": 8.48816029143898e-06,
      "loss": 0.0014,
      "step": 80580
    },
    {
      "epoch": 8.634951248258867,
      "grad_norm": 0.0020046611316502094,
      "learning_rate": 8.486731668988178e-06,
      "loss": 0.0912,
      "step": 80590
    },
    {
      "epoch": 8.636022715096967,
      "grad_norm": 0.0004516477638389915,
      "learning_rate": 8.485303046537377e-06,
      "loss": 0.0,
      "step": 80600
    },
    {
      "epoch": 8.637094181935069,
      "grad_norm": 0.00016421268810518086,
      "learning_rate": 8.483874424086575e-06,
      "loss": 0.0004,
      "step": 80610
    },
    {
      "epoch": 8.638165648773171,
      "grad_norm": 0.00023445910483133048,
      "learning_rate": 8.482445801635774e-06,
      "loss": 0.0025,
      "step": 80620
    },
    {
      "epoch": 8.639237115611271,
      "grad_norm": 0.0033961066510528326,
      "learning_rate": 8.481017179184972e-06,
      "loss": 0.0001,
      "step": 80630
    },
    {
      "epoch": 8.640308582449373,
      "grad_norm": 0.008028173819184303,
      "learning_rate": 8.47958855673417e-06,
      "loss": 0.1424,
      "step": 80640
    },
    {
      "epoch": 8.641380049287475,
      "grad_norm": 0.00015479073044843972,
      "learning_rate": 8.478159934283367e-06,
      "loss": 0.0,
      "step": 80650
    },
    {
      "epoch": 8.642451516125575,
      "grad_norm": 0.00019817391876131296,
      "learning_rate": 8.476731311832565e-06,
      "loss": 0.0016,
      "step": 80660
    },
    {
      "epoch": 8.643522982963677,
      "grad_norm": 0.00084639125270769,
      "learning_rate": 8.475302689381764e-06,
      "loss": 0.0002,
      "step": 80670
    },
    {
      "epoch": 8.64459444980178,
      "grad_norm": 0.00016476295422762632,
      "learning_rate": 8.473874066930962e-06,
      "loss": 0.2287,
      "step": 80680
    },
    {
      "epoch": 8.64566591663988,
      "grad_norm": 0.00018135280697606504,
      "learning_rate": 8.472445444480161e-06,
      "loss": 0.124,
      "step": 80690
    },
    {
      "epoch": 8.646737383477982,
      "grad_norm": 0.0020146872848272324,
      "learning_rate": 8.471016822029359e-06,
      "loss": 0.0,
      "step": 80700
    },
    {
      "epoch": 8.647808850316082,
      "grad_norm": 0.0008182490128092468,
      "learning_rate": 8.469588199578557e-06,
      "loss": 0.2714,
      "step": 80710
    },
    {
      "epoch": 8.648880317154184,
      "grad_norm": 0.005326850339770317,
      "learning_rate": 8.468159577127754e-06,
      "loss": 0.0,
      "step": 80720
    },
    {
      "epoch": 8.649951783992286,
      "grad_norm": 0.05190049484372139,
      "learning_rate": 8.466730954676954e-06,
      "loss": 0.0009,
      "step": 80730
    },
    {
      "epoch": 8.651023250830386,
      "grad_norm": 0.0002458234375808388,
      "learning_rate": 8.465302332226152e-06,
      "loss": 0.0012,
      "step": 80740
    },
    {
      "epoch": 8.652094717668488,
      "grad_norm": 0.007177460007369518,
      "learning_rate": 8.46387370977535e-06,
      "loss": 0.0001,
      "step": 80750
    },
    {
      "epoch": 8.65316618450659,
      "grad_norm": 0.0004878355248365551,
      "learning_rate": 8.462445087324549e-06,
      "loss": 0.146,
      "step": 80760
    },
    {
      "epoch": 8.65423765134469,
      "grad_norm": 0.00017589839990250766,
      "learning_rate": 8.461016464873746e-06,
      "loss": 0.0,
      "step": 80770
    },
    {
      "epoch": 8.655309118182792,
      "grad_norm": 0.2550067603588104,
      "learning_rate": 8.459587842422944e-06,
      "loss": 0.0002,
      "step": 80780
    },
    {
      "epoch": 8.656380585020894,
      "grad_norm": 0.0043908399529755116,
      "learning_rate": 8.458159219972143e-06,
      "loss": 0.0001,
      "step": 80790
    },
    {
      "epoch": 8.657452051858995,
      "grad_norm": 0.0002665554638952017,
      "learning_rate": 8.456730597521341e-06,
      "loss": 0.0,
      "step": 80800
    },
    {
      "epoch": 8.658523518697097,
      "grad_norm": 0.0021959885489195585,
      "learning_rate": 8.455301975070539e-06,
      "loss": 0.1143,
      "step": 80810
    },
    {
      "epoch": 8.659594985535197,
      "grad_norm": 0.0001645018346607685,
      "learning_rate": 8.453873352619736e-06,
      "loss": 0.2551,
      "step": 80820
    },
    {
      "epoch": 8.660666452373299,
      "grad_norm": 0.0026588814798742533,
      "learning_rate": 8.452444730168936e-06,
      "loss": 0.0,
      "step": 80830
    },
    {
      "epoch": 8.6617379192114,
      "grad_norm": 5.166001796722412,
      "learning_rate": 8.451016107718133e-06,
      "loss": 0.0013,
      "step": 80840
    },
    {
      "epoch": 8.662809386049501,
      "grad_norm": 27.61787986755371,
      "learning_rate": 8.449587485267333e-06,
      "loss": 0.1047,
      "step": 80850
    },
    {
      "epoch": 8.663880852887603,
      "grad_norm": 0.00023714992858003825,
      "learning_rate": 8.44815886281653e-06,
      "loss": 0.0001,
      "step": 80860
    },
    {
      "epoch": 8.664952319725705,
      "grad_norm": 0.00021280506916809827,
      "learning_rate": 8.446730240365728e-06,
      "loss": 0.0,
      "step": 80870
    },
    {
      "epoch": 8.666023786563805,
      "grad_norm": 0.00901859812438488,
      "learning_rate": 8.445301617914926e-06,
      "loss": 0.0,
      "step": 80880
    },
    {
      "epoch": 8.667095253401907,
      "grad_norm": 0.0002273472782690078,
      "learning_rate": 8.443872995464123e-06,
      "loss": 0.1278,
      "step": 80890
    },
    {
      "epoch": 8.66816672024001,
      "grad_norm": 0.004523098468780518,
      "learning_rate": 8.442444373013323e-06,
      "loss": 0.0,
      "step": 80900
    },
    {
      "epoch": 8.66923818707811,
      "grad_norm": 0.0034798341803252697,
      "learning_rate": 8.44101575056252e-06,
      "loss": 0.0006,
      "step": 80910
    },
    {
      "epoch": 8.670309653916211,
      "grad_norm": 0.002078910591080785,
      "learning_rate": 8.43958712811172e-06,
      "loss": 0.0,
      "step": 80920
    },
    {
      "epoch": 8.671381120754313,
      "grad_norm": 0.00017229504010174423,
      "learning_rate": 8.438158505660917e-06,
      "loss": 0.0002,
      "step": 80930
    },
    {
      "epoch": 8.672452587592414,
      "grad_norm": 0.0002506081946194172,
      "learning_rate": 8.436729883210115e-06,
      "loss": 0.0,
      "step": 80940
    },
    {
      "epoch": 8.673524054430516,
      "grad_norm": 0.00018849712796509266,
      "learning_rate": 8.435301260759313e-06,
      "loss": 0.0,
      "step": 80950
    },
    {
      "epoch": 8.674595521268618,
      "grad_norm": 0.0001688835327513516,
      "learning_rate": 8.43387263830851e-06,
      "loss": 0.0001,
      "step": 80960
    },
    {
      "epoch": 8.675666988106718,
      "grad_norm": 0.000203598290681839,
      "learning_rate": 8.43244401585771e-06,
      "loss": 0.0,
      "step": 80970
    },
    {
      "epoch": 8.67673845494482,
      "grad_norm": 0.0013386583887040615,
      "learning_rate": 8.431015393406908e-06,
      "loss": 0.0,
      "step": 80980
    },
    {
      "epoch": 8.67780992178292,
      "grad_norm": 0.000336723227519542,
      "learning_rate": 8.429586770956107e-06,
      "loss": 0.4279,
      "step": 80990
    },
    {
      "epoch": 8.678881388621022,
      "grad_norm": 0.0003063281183131039,
      "learning_rate": 8.428158148505305e-06,
      "loss": 0.1868,
      "step": 81000
    },
    {
      "epoch": 8.679952855459124,
      "grad_norm": 28.688215255737305,
      "learning_rate": 8.426729526054502e-06,
      "loss": 0.2609,
      "step": 81010
    },
    {
      "epoch": 8.681024322297224,
      "grad_norm": 0.008697024546563625,
      "learning_rate": 8.4253009036037e-06,
      "loss": 0.0001,
      "step": 81020
    },
    {
      "epoch": 8.682095789135326,
      "grad_norm": 0.00534439692273736,
      "learning_rate": 8.4238722811529e-06,
      "loss": 0.0001,
      "step": 81030
    },
    {
      "epoch": 8.683167255973428,
      "grad_norm": 0.0006558269960805774,
      "learning_rate": 8.422443658702097e-06,
      "loss": 0.001,
      "step": 81040
    },
    {
      "epoch": 8.684238722811529,
      "grad_norm": 0.0002929236798081547,
      "learning_rate": 8.421015036251296e-06,
      "loss": 0.0001,
      "step": 81050
    },
    {
      "epoch": 8.68531018964963,
      "grad_norm": 0.0020770090632140636,
      "learning_rate": 8.419586413800494e-06,
      "loss": 0.0,
      "step": 81060
    },
    {
      "epoch": 8.686381656487733,
      "grad_norm": 0.0015253432793542743,
      "learning_rate": 8.418157791349692e-06,
      "loss": 0.0001,
      "step": 81070
    },
    {
      "epoch": 8.687453123325833,
      "grad_norm": 0.0003727204166352749,
      "learning_rate": 8.41672916889889e-06,
      "loss": 0.2493,
      "step": 81080
    },
    {
      "epoch": 8.688524590163935,
      "grad_norm": 0.00631032045930624,
      "learning_rate": 8.415300546448089e-06,
      "loss": 0.0004,
      "step": 81090
    },
    {
      "epoch": 8.689596057002035,
      "grad_norm": 0.0028128272388130426,
      "learning_rate": 8.413871923997286e-06,
      "loss": 0.1201,
      "step": 81100
    },
    {
      "epoch": 8.690667523840137,
      "grad_norm": 0.00022000091848894954,
      "learning_rate": 8.412443301546484e-06,
      "loss": 0.0001,
      "step": 81110
    },
    {
      "epoch": 8.691738990678239,
      "grad_norm": 0.00022220647952053696,
      "learning_rate": 8.411014679095683e-06,
      "loss": 0.0002,
      "step": 81120
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 0.0004527199489530176,
      "learning_rate": 8.409586056644881e-06,
      "loss": 0.3038,
      "step": 81130
    },
    {
      "epoch": 8.693881924354441,
      "grad_norm": 0.04330265894532204,
      "learning_rate": 8.408157434194079e-06,
      "loss": 0.0005,
      "step": 81140
    },
    {
      "epoch": 8.694953391192543,
      "grad_norm": 0.00048028765013441443,
      "learning_rate": 8.406728811743278e-06,
      "loss": 0.0002,
      "step": 81150
    },
    {
      "epoch": 8.696024858030643,
      "grad_norm": 0.000689248729031533,
      "learning_rate": 8.405300189292476e-06,
      "loss": 0.0002,
      "step": 81160
    },
    {
      "epoch": 8.697096324868745,
      "grad_norm": 0.0003553016867954284,
      "learning_rate": 8.403871566841673e-06,
      "loss": 0.0001,
      "step": 81170
    },
    {
      "epoch": 8.698167791706847,
      "grad_norm": 0.00042083137668669224,
      "learning_rate": 8.402442944390871e-06,
      "loss": 0.0636,
      "step": 81180
    },
    {
      "epoch": 8.699239258544948,
      "grad_norm": 0.003528046887367964,
      "learning_rate": 8.40101432194007e-06,
      "loss": 0.0001,
      "step": 81190
    },
    {
      "epoch": 8.70031072538305,
      "grad_norm": 0.0009050829103216529,
      "learning_rate": 8.399585699489268e-06,
      "loss": 0.0,
      "step": 81200
    },
    {
      "epoch": 8.70138219222115,
      "grad_norm": 0.004010985605418682,
      "learning_rate": 8.398157077038468e-06,
      "loss": 0.1846,
      "step": 81210
    },
    {
      "epoch": 8.702453659059252,
      "grad_norm": 0.00043258455116301775,
      "learning_rate": 8.396728454587665e-06,
      "loss": 0.216,
      "step": 81220
    },
    {
      "epoch": 8.703525125897354,
      "grad_norm": 0.00536330696195364,
      "learning_rate": 8.395299832136863e-06,
      "loss": 0.0001,
      "step": 81230
    },
    {
      "epoch": 8.704596592735454,
      "grad_norm": 0.3262600600719452,
      "learning_rate": 8.39387120968606e-06,
      "loss": 0.001,
      "step": 81240
    },
    {
      "epoch": 8.705668059573556,
      "grad_norm": 0.00027068107738159597,
      "learning_rate": 8.392442587235258e-06,
      "loss": 0.0,
      "step": 81250
    },
    {
      "epoch": 8.706739526411658,
      "grad_norm": 0.009491975419223309,
      "learning_rate": 8.391013964784458e-06,
      "loss": 0.1669,
      "step": 81260
    },
    {
      "epoch": 8.707810993249758,
      "grad_norm": 0.0005991546204313636,
      "learning_rate": 8.389585342333655e-06,
      "loss": 0.0003,
      "step": 81270
    },
    {
      "epoch": 8.70888246008786,
      "grad_norm": 0.007616961840540171,
      "learning_rate": 8.388156719882855e-06,
      "loss": 0.0947,
      "step": 81280
    },
    {
      "epoch": 8.709953926925962,
      "grad_norm": 0.0017895377241075039,
      "learning_rate": 8.386728097432052e-06,
      "loss": 0.0001,
      "step": 81290
    },
    {
      "epoch": 8.711025393764062,
      "grad_norm": 0.000829267140943557,
      "learning_rate": 8.38529947498125e-06,
      "loss": 0.0001,
      "step": 81300
    },
    {
      "epoch": 8.712096860602164,
      "grad_norm": 0.08259977400302887,
      "learning_rate": 8.383870852530448e-06,
      "loss": 0.0002,
      "step": 81310
    },
    {
      "epoch": 8.713168327440266,
      "grad_norm": 1.1076123714447021,
      "learning_rate": 8.382442230079645e-06,
      "loss": 0.0006,
      "step": 81320
    },
    {
      "epoch": 8.714239794278367,
      "grad_norm": 0.001330440049059689,
      "learning_rate": 8.381013607628845e-06,
      "loss": 0.0001,
      "step": 81330
    },
    {
      "epoch": 8.715311261116469,
      "grad_norm": 0.00048223312478512526,
      "learning_rate": 8.379584985178042e-06,
      "loss": 0.0001,
      "step": 81340
    },
    {
      "epoch": 8.71638272795457,
      "grad_norm": 0.00045450759353116155,
      "learning_rate": 8.378156362727242e-06,
      "loss": 0.2934,
      "step": 81350
    },
    {
      "epoch": 8.717454194792671,
      "grad_norm": 0.018782109022140503,
      "learning_rate": 8.37672774027644e-06,
      "loss": 0.0001,
      "step": 81360
    },
    {
      "epoch": 8.718525661630773,
      "grad_norm": 0.0006635068566538393,
      "learning_rate": 8.375299117825637e-06,
      "loss": 0.0001,
      "step": 81370
    },
    {
      "epoch": 8.719597128468873,
      "grad_norm": 0.0014745397493243217,
      "learning_rate": 8.373870495374835e-06,
      "loss": 0.0009,
      "step": 81380
    },
    {
      "epoch": 8.720668595306975,
      "grad_norm": 0.00028279985417611897,
      "learning_rate": 8.372441872924034e-06,
      "loss": 0.0,
      "step": 81390
    },
    {
      "epoch": 8.721740062145077,
      "grad_norm": 0.0006996660376898944,
      "learning_rate": 8.371013250473232e-06,
      "loss": 0.0,
      "step": 81400
    },
    {
      "epoch": 8.722811528983177,
      "grad_norm": 0.0007595407660119236,
      "learning_rate": 8.36958462802243e-06,
      "loss": 0.0,
      "step": 81410
    },
    {
      "epoch": 8.72388299582128,
      "grad_norm": 0.004052548669278622,
      "learning_rate": 8.368156005571629e-06,
      "loss": 0.0005,
      "step": 81420
    },
    {
      "epoch": 8.724954462659381,
      "grad_norm": 0.0019401663448661566,
      "learning_rate": 8.366727383120826e-06,
      "loss": 0.0001,
      "step": 81430
    },
    {
      "epoch": 8.726025929497482,
      "grad_norm": 0.059831682592630386,
      "learning_rate": 8.365298760670024e-06,
      "loss": 0.0004,
      "step": 81440
    },
    {
      "epoch": 8.727097396335584,
      "grad_norm": 0.0003128537500742823,
      "learning_rate": 8.363870138219224e-06,
      "loss": 0.0,
      "step": 81450
    },
    {
      "epoch": 8.728168863173686,
      "grad_norm": 0.001733002602122724,
      "learning_rate": 8.362441515768421e-06,
      "loss": 0.0,
      "step": 81460
    },
    {
      "epoch": 8.729240330011786,
      "grad_norm": 0.0011946185259148479,
      "learning_rate": 8.361012893317619e-06,
      "loss": 0.0002,
      "step": 81470
    },
    {
      "epoch": 8.730311796849888,
      "grad_norm": 0.0027450588531792164,
      "learning_rate": 8.359584270866817e-06,
      "loss": 0.0001,
      "step": 81480
    },
    {
      "epoch": 8.731383263687988,
      "grad_norm": 0.0007852703565731645,
      "learning_rate": 8.358155648416016e-06,
      "loss": 0.0,
      "step": 81490
    },
    {
      "epoch": 8.73245473052609,
      "grad_norm": 0.0002297911123605445,
      "learning_rate": 8.356727025965214e-06,
      "loss": 0.0,
      "step": 81500
    },
    {
      "epoch": 8.733526197364192,
      "grad_norm": 0.00023705177591182292,
      "learning_rate": 8.355298403514413e-06,
      "loss": 0.1665,
      "step": 81510
    },
    {
      "epoch": 8.734597664202292,
      "grad_norm": 0.0011256181169301271,
      "learning_rate": 8.35386978106361e-06,
      "loss": 0.0001,
      "step": 81520
    },
    {
      "epoch": 8.735669131040394,
      "grad_norm": 0.0009818430989980698,
      "learning_rate": 8.352441158612808e-06,
      "loss": 0.0,
      "step": 81530
    },
    {
      "epoch": 8.736740597878496,
      "grad_norm": 23.397724151611328,
      "learning_rate": 8.351012536162006e-06,
      "loss": 0.1815,
      "step": 81540
    },
    {
      "epoch": 8.737812064716596,
      "grad_norm": 0.00020958590903319418,
      "learning_rate": 8.349583913711204e-06,
      "loss": 0.0003,
      "step": 81550
    },
    {
      "epoch": 8.738883531554698,
      "grad_norm": 0.0013284357264637947,
      "learning_rate": 8.348155291260403e-06,
      "loss": 0.0,
      "step": 81560
    },
    {
      "epoch": 8.7399549983928,
      "grad_norm": 0.00036439707037061453,
      "learning_rate": 8.3467266688096e-06,
      "loss": 0.0,
      "step": 81570
    },
    {
      "epoch": 8.7410264652309,
      "grad_norm": 0.0050412374548614025,
      "learning_rate": 8.3452980463588e-06,
      "loss": 0.0001,
      "step": 81580
    },
    {
      "epoch": 8.742097932069003,
      "grad_norm": 0.0041441828943789005,
      "learning_rate": 8.343869423907998e-06,
      "loss": 0.0,
      "step": 81590
    },
    {
      "epoch": 8.743169398907105,
      "grad_norm": 0.0027538565918803215,
      "learning_rate": 8.342440801457195e-06,
      "loss": 0.0,
      "step": 81600
    },
    {
      "epoch": 8.744240865745205,
      "grad_norm": 0.0015630640555173159,
      "learning_rate": 8.341012179006393e-06,
      "loss": 0.0,
      "step": 81610
    },
    {
      "epoch": 8.745312332583307,
      "grad_norm": 0.013370273634791374,
      "learning_rate": 8.339583556555592e-06,
      "loss": 0.0001,
      "step": 81620
    },
    {
      "epoch": 8.746383799421407,
      "grad_norm": 0.00030267558759078383,
      "learning_rate": 8.33815493410479e-06,
      "loss": 0.0003,
      "step": 81630
    },
    {
      "epoch": 8.747455266259509,
      "grad_norm": 0.0005677829612977803,
      "learning_rate": 8.33672631165399e-06,
      "loss": 0.2667,
      "step": 81640
    },
    {
      "epoch": 8.748526733097611,
      "grad_norm": 0.0003473092510830611,
      "learning_rate": 8.335297689203187e-06,
      "loss": 0.0001,
      "step": 81650
    },
    {
      "epoch": 8.749598199935711,
      "grad_norm": 0.009165946394205093,
      "learning_rate": 8.333869066752385e-06,
      "loss": 0.0,
      "step": 81660
    },
    {
      "epoch": 8.750669666773813,
      "grad_norm": 4.839033603668213,
      "learning_rate": 8.332440444301582e-06,
      "loss": 0.0097,
      "step": 81670
    },
    {
      "epoch": 8.751741133611915,
      "grad_norm": 0.00039263934013433754,
      "learning_rate": 8.33101182185078e-06,
      "loss": 0.0,
      "step": 81680
    },
    {
      "epoch": 8.752812600450016,
      "grad_norm": 0.0018071125959977508,
      "learning_rate": 8.32958319939998e-06,
      "loss": 0.0001,
      "step": 81690
    },
    {
      "epoch": 8.753884067288118,
      "grad_norm": 0.0023118762765079737,
      "learning_rate": 8.328154576949177e-06,
      "loss": 0.1599,
      "step": 81700
    },
    {
      "epoch": 8.75495553412622,
      "grad_norm": 0.002223475370556116,
      "learning_rate": 8.326725954498377e-06,
      "loss": 0.0,
      "step": 81710
    },
    {
      "epoch": 8.75602700096432,
      "grad_norm": 0.0030406212899833918,
      "learning_rate": 8.325297332047574e-06,
      "loss": 0.0,
      "step": 81720
    },
    {
      "epoch": 8.757098467802422,
      "grad_norm": 0.004579506348818541,
      "learning_rate": 8.323868709596772e-06,
      "loss": 0.231,
      "step": 81730
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 0.2430875599384308,
      "learning_rate": 8.32244008714597e-06,
      "loss": 0.0004,
      "step": 81740
    },
    {
      "epoch": 8.759241401478624,
      "grad_norm": 0.009432087652385235,
      "learning_rate": 8.321011464695167e-06,
      "loss": 0.0001,
      "step": 81750
    },
    {
      "epoch": 8.760312868316726,
      "grad_norm": 0.0002504427102394402,
      "learning_rate": 8.319582842244367e-06,
      "loss": 0.0001,
      "step": 81760
    },
    {
      "epoch": 8.761384335154826,
      "grad_norm": 0.0013195279752835631,
      "learning_rate": 8.318154219793564e-06,
      "loss": 0.0,
      "step": 81770
    },
    {
      "epoch": 8.762455801992928,
      "grad_norm": 0.006813635118305683,
      "learning_rate": 8.316725597342764e-06,
      "loss": 0.0003,
      "step": 81780
    },
    {
      "epoch": 8.76352726883103,
      "grad_norm": 0.0051383934915065765,
      "learning_rate": 8.315296974891961e-06,
      "loss": 0.0001,
      "step": 81790
    },
    {
      "epoch": 8.76459873566913,
      "grad_norm": 0.006421723403036594,
      "learning_rate": 8.313868352441159e-06,
      "loss": 0.0,
      "step": 81800
    },
    {
      "epoch": 8.765670202507232,
      "grad_norm": 0.00024082906020339578,
      "learning_rate": 8.312439729990357e-06,
      "loss": 0.0,
      "step": 81810
    },
    {
      "epoch": 8.766741669345334,
      "grad_norm": 0.0003359162656124681,
      "learning_rate": 8.311011107539556e-06,
      "loss": 0.0004,
      "step": 81820
    },
    {
      "epoch": 8.767813136183435,
      "grad_norm": 0.00024309895525220782,
      "learning_rate": 8.309582485088754e-06,
      "loss": 0.0001,
      "step": 81830
    },
    {
      "epoch": 8.768884603021537,
      "grad_norm": 53.40536117553711,
      "learning_rate": 8.308153862637951e-06,
      "loss": 0.4313,
      "step": 81840
    },
    {
      "epoch": 8.769956069859639,
      "grad_norm": 0.011170933954417706,
      "learning_rate": 8.30672524018715e-06,
      "loss": 0.0039,
      "step": 81850
    },
    {
      "epoch": 8.771027536697739,
      "grad_norm": 17.13773536682129,
      "learning_rate": 8.305296617736348e-06,
      "loss": 0.1675,
      "step": 81860
    },
    {
      "epoch": 8.77209900353584,
      "grad_norm": 0.00030149982194416225,
      "learning_rate": 8.303867995285546e-06,
      "loss": 0.1442,
      "step": 81870
    },
    {
      "epoch": 8.773170470373941,
      "grad_norm": 0.013126403093338013,
      "learning_rate": 8.302439372834745e-06,
      "loss": 0.0007,
      "step": 81880
    },
    {
      "epoch": 8.774241937212043,
      "grad_norm": 0.0002144831814803183,
      "learning_rate": 8.301010750383943e-06,
      "loss": 0.0,
      "step": 81890
    },
    {
      "epoch": 8.775313404050145,
      "grad_norm": 0.00039344283868558705,
      "learning_rate": 8.29958212793314e-06,
      "loss": 0.1151,
      "step": 81900
    },
    {
      "epoch": 8.776384870888245,
      "grad_norm": 0.0007498182822018862,
      "learning_rate": 8.298153505482338e-06,
      "loss": 0.0008,
      "step": 81910
    },
    {
      "epoch": 8.777456337726347,
      "grad_norm": 0.028528209775686264,
      "learning_rate": 8.296724883031538e-06,
      "loss": 0.1307,
      "step": 81920
    },
    {
      "epoch": 8.77852780456445,
      "grad_norm": 0.0008827555575408041,
      "learning_rate": 8.295296260580736e-06,
      "loss": 0.0,
      "step": 81930
    },
    {
      "epoch": 8.77959927140255,
      "grad_norm": 0.0002596181002445519,
      "learning_rate": 8.293867638129935e-06,
      "loss": 0.0,
      "step": 81940
    },
    {
      "epoch": 8.780670738240651,
      "grad_norm": 0.003197978250682354,
      "learning_rate": 8.292439015679133e-06,
      "loss": 0.0,
      "step": 81950
    },
    {
      "epoch": 8.781742205078753,
      "grad_norm": 0.00033796459320001304,
      "learning_rate": 8.29101039322833e-06,
      "loss": 0.1437,
      "step": 81960
    },
    {
      "epoch": 8.782813671916854,
      "grad_norm": 0.0010921135544776917,
      "learning_rate": 8.289581770777528e-06,
      "loss": 0.0,
      "step": 81970
    },
    {
      "epoch": 8.783885138754956,
      "grad_norm": 27.642627716064453,
      "learning_rate": 8.288153148326726e-06,
      "loss": 0.1842,
      "step": 81980
    },
    {
      "epoch": 8.784956605593058,
      "grad_norm": 0.003993962425738573,
      "learning_rate": 8.286724525875925e-06,
      "loss": 0.0,
      "step": 81990
    },
    {
      "epoch": 8.786028072431158,
      "grad_norm": 0.00026086962316185236,
      "learning_rate": 8.285295903425123e-06,
      "loss": 0.0011,
      "step": 82000
    },
    {
      "epoch": 8.78709953926926,
      "grad_norm": 0.0005073756910860538,
      "learning_rate": 8.283867280974322e-06,
      "loss": 0.0,
      "step": 82010
    },
    {
      "epoch": 8.788171006107362,
      "grad_norm": 0.0005088883335702121,
      "learning_rate": 8.28243865852352e-06,
      "loss": 0.0001,
      "step": 82020
    },
    {
      "epoch": 8.789242472945462,
      "grad_norm": 0.0003927054931409657,
      "learning_rate": 8.281010036072717e-06,
      "loss": 0.0622,
      "step": 82030
    },
    {
      "epoch": 8.790313939783564,
      "grad_norm": 0.014792690053582191,
      "learning_rate": 8.279581413621915e-06,
      "loss": 0.0,
      "step": 82040
    },
    {
      "epoch": 8.791385406621664,
      "grad_norm": 0.00020325607329141349,
      "learning_rate": 8.278152791171113e-06,
      "loss": 0.0004,
      "step": 82050
    },
    {
      "epoch": 8.792456873459766,
      "grad_norm": 0.00018941336020361632,
      "learning_rate": 8.276724168720312e-06,
      "loss": 0.0001,
      "step": 82060
    },
    {
      "epoch": 8.793528340297868,
      "grad_norm": 0.00034903112100437284,
      "learning_rate": 8.275295546269511e-06,
      "loss": 0.0001,
      "step": 82070
    },
    {
      "epoch": 8.794599807135969,
      "grad_norm": 0.0002142973680747673,
      "learning_rate": 8.273866923818709e-06,
      "loss": 0.0001,
      "step": 82080
    },
    {
      "epoch": 8.79567127397407,
      "grad_norm": 0.0021017969120293856,
      "learning_rate": 8.272438301367907e-06,
      "loss": 0.0,
      "step": 82090
    },
    {
      "epoch": 8.796742740812173,
      "grad_norm": 0.001223991741426289,
      "learning_rate": 8.271009678917104e-06,
      "loss": 0.0001,
      "step": 82100
    },
    {
      "epoch": 8.797814207650273,
      "grad_norm": 0.0003661581431515515,
      "learning_rate": 8.269581056466302e-06,
      "loss": 0.0001,
      "step": 82110
    },
    {
      "epoch": 8.798885674488375,
      "grad_norm": 0.0005560436402447522,
      "learning_rate": 8.268152434015501e-06,
      "loss": 0.0,
      "step": 82120
    },
    {
      "epoch": 8.799957141326477,
      "grad_norm": 0.0016358366701751947,
      "learning_rate": 8.266723811564699e-06,
      "loss": 0.0,
      "step": 82130
    },
    {
      "epoch": 8.801028608164577,
      "grad_norm": 0.0002253427228424698,
      "learning_rate": 8.265295189113899e-06,
      "loss": 0.0003,
      "step": 82140
    },
    {
      "epoch": 8.802100075002679,
      "grad_norm": 0.00015267095295712352,
      "learning_rate": 8.263866566663096e-06,
      "loss": 0.0,
      "step": 82150
    },
    {
      "epoch": 8.80317154184078,
      "grad_norm": 0.00017692991241347045,
      "learning_rate": 8.262437944212294e-06,
      "loss": 0.0,
      "step": 82160
    },
    {
      "epoch": 8.804243008678881,
      "grad_norm": 0.00015838265244383365,
      "learning_rate": 8.261009321761492e-06,
      "loss": 0.0006,
      "step": 82170
    },
    {
      "epoch": 8.805314475516983,
      "grad_norm": 0.00021084841864649206,
      "learning_rate": 8.259580699310691e-06,
      "loss": 0.0001,
      "step": 82180
    },
    {
      "epoch": 8.806385942355083,
      "grad_norm": 0.0001444398076273501,
      "learning_rate": 8.258152076859889e-06,
      "loss": 0.0,
      "step": 82190
    },
    {
      "epoch": 8.807457409193185,
      "grad_norm": 0.003320167539641261,
      "learning_rate": 8.256723454409086e-06,
      "loss": 0.0006,
      "step": 82200
    },
    {
      "epoch": 8.808528876031287,
      "grad_norm": 0.001043546712026,
      "learning_rate": 8.255294831958286e-06,
      "loss": 0.0007,
      "step": 82210
    },
    {
      "epoch": 8.809600342869388,
      "grad_norm": 0.0014696832513436675,
      "learning_rate": 8.253866209507483e-06,
      "loss": 0.0004,
      "step": 82220
    },
    {
      "epoch": 8.81067180970749,
      "grad_norm": 0.00035000452771782875,
      "learning_rate": 8.252437587056681e-06,
      "loss": 0.0,
      "step": 82230
    },
    {
      "epoch": 8.811743276545592,
      "grad_norm": 0.0010554116452112794,
      "learning_rate": 8.25100896460588e-06,
      "loss": 0.0001,
      "step": 82240
    },
    {
      "epoch": 8.812814743383692,
      "grad_norm": 0.00024283018137793988,
      "learning_rate": 8.249580342155078e-06,
      "loss": 0.2349,
      "step": 82250
    },
    {
      "epoch": 8.813886210221794,
      "grad_norm": 0.0004815302963834256,
      "learning_rate": 8.248151719704276e-06,
      "loss": 0.0001,
      "step": 82260
    },
    {
      "epoch": 8.814957677059894,
      "grad_norm": 0.0012183734215795994,
      "learning_rate": 8.246723097253473e-06,
      "loss": 0.0,
      "step": 82270
    },
    {
      "epoch": 8.816029143897996,
      "grad_norm": 0.00028373015811666846,
      "learning_rate": 8.245294474802673e-06,
      "loss": 0.0002,
      "step": 82280
    },
    {
      "epoch": 8.817100610736098,
      "grad_norm": 0.00015122703916858882,
      "learning_rate": 8.24386585235187e-06,
      "loss": 0.0,
      "step": 82290
    },
    {
      "epoch": 8.818172077574198,
      "grad_norm": 0.001192285562865436,
      "learning_rate": 8.24243722990107e-06,
      "loss": 0.0,
      "step": 82300
    },
    {
      "epoch": 8.8192435444123,
      "grad_norm": 0.003693289589136839,
      "learning_rate": 8.241008607450267e-06,
      "loss": 0.0,
      "step": 82310
    },
    {
      "epoch": 8.820315011250402,
      "grad_norm": 0.0002439142408547923,
      "learning_rate": 8.239579984999465e-06,
      "loss": 0.0005,
      "step": 82320
    },
    {
      "epoch": 8.821386478088503,
      "grad_norm": 0.00013335277617443353,
      "learning_rate": 8.238151362548663e-06,
      "loss": 0.0,
      "step": 82330
    },
    {
      "epoch": 8.822457944926605,
      "grad_norm": 0.0001669110934017226,
      "learning_rate": 8.23672274009786e-06,
      "loss": 0.0,
      "step": 82340
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 1.7107051610946655,
      "learning_rate": 8.23529411764706e-06,
      "loss": 0.001,
      "step": 82350
    },
    {
      "epoch": 8.824600878602807,
      "grad_norm": 0.00012463940947782248,
      "learning_rate": 8.233865495196257e-06,
      "loss": 0.1687,
      "step": 82360
    },
    {
      "epoch": 8.825672345440909,
      "grad_norm": 0.00014801030920352787,
      "learning_rate": 8.232436872745457e-06,
      "loss": 0.0,
      "step": 82370
    },
    {
      "epoch": 8.82674381227901,
      "grad_norm": 0.0007997367065399885,
      "learning_rate": 8.231008250294655e-06,
      "loss": 0.0,
      "step": 82380
    },
    {
      "epoch": 8.827815279117111,
      "grad_norm": 0.001037107896991074,
      "learning_rate": 8.229579627843852e-06,
      "loss": 0.0,
      "step": 82390
    },
    {
      "epoch": 8.828886745955213,
      "grad_norm": 0.00016815761046018451,
      "learning_rate": 8.22815100539305e-06,
      "loss": 0.0,
      "step": 82400
    },
    {
      "epoch": 8.829958212793315,
      "grad_norm": 0.00017797904729377478,
      "learning_rate": 8.226722382942248e-06,
      "loss": 0.0001,
      "step": 82410
    },
    {
      "epoch": 8.831029679631415,
      "grad_norm": 0.0001028242550091818,
      "learning_rate": 8.225293760491447e-06,
      "loss": 0.0,
      "step": 82420
    },
    {
      "epoch": 8.832101146469517,
      "grad_norm": 0.15567456185817719,
      "learning_rate": 8.223865138040645e-06,
      "loss": 0.1118,
      "step": 82430
    },
    {
      "epoch": 8.833172613307617,
      "grad_norm": 0.000137009410536848,
      "learning_rate": 8.222436515589844e-06,
      "loss": 0.1803,
      "step": 82440
    },
    {
      "epoch": 8.83424408014572,
      "grad_norm": 0.002154075540602207,
      "learning_rate": 8.221007893139042e-06,
      "loss": 0.0001,
      "step": 82450
    },
    {
      "epoch": 8.835315546983821,
      "grad_norm": 0.0037008707877248526,
      "learning_rate": 8.21957927068824e-06,
      "loss": 0.0,
      "step": 82460
    },
    {
      "epoch": 8.836387013821922,
      "grad_norm": 0.00043409454519860446,
      "learning_rate": 8.218150648237437e-06,
      "loss": 0.0,
      "step": 82470
    },
    {
      "epoch": 8.837458480660024,
      "grad_norm": 0.0005409005098044872,
      "learning_rate": 8.216722025786635e-06,
      "loss": 0.0002,
      "step": 82480
    },
    {
      "epoch": 8.838529947498126,
      "grad_norm": 0.003146600676700473,
      "learning_rate": 8.215293403335834e-06,
      "loss": 0.6617,
      "step": 82490
    },
    {
      "epoch": 8.839601414336226,
      "grad_norm": 0.003476422978565097,
      "learning_rate": 8.213864780885032e-06,
      "loss": 0.1431,
      "step": 82500
    },
    {
      "epoch": 8.840672881174328,
      "grad_norm": 0.0035715228877961636,
      "learning_rate": 8.212436158434231e-06,
      "loss": 0.0003,
      "step": 82510
    },
    {
      "epoch": 8.84174434801243,
      "grad_norm": 0.00016952729492913932,
      "learning_rate": 8.211007535983429e-06,
      "loss": 0.0,
      "step": 82520
    },
    {
      "epoch": 8.84281581485053,
      "grad_norm": 0.00013744315947405994,
      "learning_rate": 8.209578913532626e-06,
      "loss": 0.0,
      "step": 82530
    },
    {
      "epoch": 8.843887281688632,
      "grad_norm": 0.0001279704738408327,
      "learning_rate": 8.208150291081824e-06,
      "loss": 0.0008,
      "step": 82540
    },
    {
      "epoch": 8.844958748526732,
      "grad_norm": 0.009961415082216263,
      "learning_rate": 8.206721668631023e-06,
      "loss": 0.0004,
      "step": 82550
    },
    {
      "epoch": 8.846030215364834,
      "grad_norm": 0.00017267347720917314,
      "learning_rate": 8.205293046180221e-06,
      "loss": 0.0005,
      "step": 82560
    },
    {
      "epoch": 8.847101682202936,
      "grad_norm": 0.00014245232159737498,
      "learning_rate": 8.203864423729419e-06,
      "loss": 0.0,
      "step": 82570
    },
    {
      "epoch": 8.848173149041036,
      "grad_norm": 0.006187261547893286,
      "learning_rate": 8.202435801278618e-06,
      "loss": 0.4933,
      "step": 82580
    },
    {
      "epoch": 8.849244615879138,
      "grad_norm": 0.00045938670518808067,
      "learning_rate": 8.201007178827816e-06,
      "loss": 0.0009,
      "step": 82590
    },
    {
      "epoch": 8.85031608271724,
      "grad_norm": 0.00022647777223028243,
      "learning_rate": 8.199578556377013e-06,
      "loss": 0.1104,
      "step": 82600
    },
    {
      "epoch": 8.85138754955534,
      "grad_norm": 0.00024145936185959727,
      "learning_rate": 8.198149933926213e-06,
      "loss": 0.1271,
      "step": 82610
    },
    {
      "epoch": 8.852459016393443,
      "grad_norm": 0.0010138396173715591,
      "learning_rate": 8.19672131147541e-06,
      "loss": 0.1213,
      "step": 82620
    },
    {
      "epoch": 8.853530483231545,
      "grad_norm": 0.09775771200656891,
      "learning_rate": 8.195292689024608e-06,
      "loss": 0.0001,
      "step": 82630
    },
    {
      "epoch": 8.854601950069645,
      "grad_norm": 0.018433082848787308,
      "learning_rate": 8.193864066573808e-06,
      "loss": 0.0002,
      "step": 82640
    },
    {
      "epoch": 8.855673416907747,
      "grad_norm": 0.00023863703245297074,
      "learning_rate": 8.192435444123005e-06,
      "loss": 0.0002,
      "step": 82650
    },
    {
      "epoch": 8.856744883745849,
      "grad_norm": 0.020822059363126755,
      "learning_rate": 8.191006821672203e-06,
      "loss": 0.2823,
      "step": 82660
    },
    {
      "epoch": 8.85781635058395,
      "grad_norm": 0.00019558703934308141,
      "learning_rate": 8.189578199221402e-06,
      "loss": 0.0003,
      "step": 82670
    },
    {
      "epoch": 8.858887817422051,
      "grad_norm": 0.00016325138858519495,
      "learning_rate": 8.1881495767706e-06,
      "loss": 0.0001,
      "step": 82680
    },
    {
      "epoch": 8.859959284260151,
      "grad_norm": 0.00043100171023979783,
      "learning_rate": 8.186720954319798e-06,
      "loss": 0.0002,
      "step": 82690
    },
    {
      "epoch": 8.861030751098253,
      "grad_norm": 0.0002559361164458096,
      "learning_rate": 8.185292331868995e-06,
      "loss": 0.0002,
      "step": 82700
    },
    {
      "epoch": 8.862102217936355,
      "grad_norm": 0.0003157386090606451,
      "learning_rate": 8.183863709418195e-06,
      "loss": 0.2145,
      "step": 82710
    },
    {
      "epoch": 8.863173684774456,
      "grad_norm": 0.002745097503066063,
      "learning_rate": 8.182435086967392e-06,
      "loss": 0.0002,
      "step": 82720
    },
    {
      "epoch": 8.864245151612558,
      "grad_norm": 0.0006699954974465072,
      "learning_rate": 8.181006464516592e-06,
      "loss": 0.0903,
      "step": 82730
    },
    {
      "epoch": 8.86531661845066,
      "grad_norm": 0.00013366418716032058,
      "learning_rate": 8.17957784206579e-06,
      "loss": 0.0001,
      "step": 82740
    },
    {
      "epoch": 8.86638808528876,
      "grad_norm": 0.017473967745900154,
      "learning_rate": 8.178149219614987e-06,
      "loss": 0.0001,
      "step": 82750
    },
    {
      "epoch": 8.867459552126862,
      "grad_norm": 0.010370454750955105,
      "learning_rate": 8.176720597164185e-06,
      "loss": 0.0001,
      "step": 82760
    },
    {
      "epoch": 8.868531018964964,
      "grad_norm": 0.001130096148699522,
      "learning_rate": 8.175291974713382e-06,
      "loss": 0.2169,
      "step": 82770
    },
    {
      "epoch": 8.869602485803064,
      "grad_norm": 0.019715992733836174,
      "learning_rate": 8.173863352262582e-06,
      "loss": 0.0004,
      "step": 82780
    },
    {
      "epoch": 8.870673952641166,
      "grad_norm": 0.00014135392848402262,
      "learning_rate": 8.17243472981178e-06,
      "loss": 0.0036,
      "step": 82790
    },
    {
      "epoch": 8.871745419479268,
      "grad_norm": 0.15644367039203644,
      "learning_rate": 8.171006107360979e-06,
      "loss": 0.0015,
      "step": 82800
    },
    {
      "epoch": 8.872816886317368,
      "grad_norm": 0.00016884924843907356,
      "learning_rate": 8.169577484910176e-06,
      "loss": 0.0001,
      "step": 82810
    },
    {
      "epoch": 8.87388835315547,
      "grad_norm": 0.006889670621603727,
      "learning_rate": 8.168148862459374e-06,
      "loss": 0.0002,
      "step": 82820
    },
    {
      "epoch": 8.87495981999357,
      "grad_norm": 0.03654387965798378,
      "learning_rate": 8.166720240008572e-06,
      "loss": 0.0003,
      "step": 82830
    },
    {
      "epoch": 8.876031286831672,
      "grad_norm": 0.1138855516910553,
      "learning_rate": 8.16529161755777e-06,
      "loss": 0.0008,
      "step": 82840
    },
    {
      "epoch": 8.877102753669774,
      "grad_norm": 0.011051293462514877,
      "learning_rate": 8.163862995106969e-06,
      "loss": 0.0002,
      "step": 82850
    },
    {
      "epoch": 8.878174220507875,
      "grad_norm": 23.618803024291992,
      "learning_rate": 8.162434372656167e-06,
      "loss": 0.1525,
      "step": 82860
    },
    {
      "epoch": 8.879245687345977,
      "grad_norm": 0.016815032809972763,
      "learning_rate": 8.161005750205366e-06,
      "loss": 0.0015,
      "step": 82870
    },
    {
      "epoch": 8.880317154184079,
      "grad_norm": 0.0001383828348480165,
      "learning_rate": 8.159577127754564e-06,
      "loss": 0.1805,
      "step": 82880
    },
    {
      "epoch": 8.881388621022179,
      "grad_norm": 0.00019571674056351185,
      "learning_rate": 8.158148505303761e-06,
      "loss": 0.0001,
      "step": 82890
    },
    {
      "epoch": 8.88246008786028,
      "grad_norm": 0.09349624067544937,
      "learning_rate": 8.156719882852959e-06,
      "loss": 0.0987,
      "step": 82900
    },
    {
      "epoch": 8.883531554698383,
      "grad_norm": 0.006925768218934536,
      "learning_rate": 8.155291260402158e-06,
      "loss": 0.0011,
      "step": 82910
    },
    {
      "epoch": 8.884603021536483,
      "grad_norm": 17.02826499938965,
      "learning_rate": 8.153862637951356e-06,
      "loss": 0.1471,
      "step": 82920
    },
    {
      "epoch": 8.885674488374585,
      "grad_norm": 0.00011705549695761874,
      "learning_rate": 8.152434015500554e-06,
      "loss": 0.0002,
      "step": 82930
    },
    {
      "epoch": 8.886745955212685,
      "grad_norm": 0.03223220258951187,
      "learning_rate": 8.151005393049753e-06,
      "loss": 0.0003,
      "step": 82940
    },
    {
      "epoch": 8.887817422050787,
      "grad_norm": 0.00011035476200049743,
      "learning_rate": 8.14957677059895e-06,
      "loss": 0.0003,
      "step": 82950
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 0.01553391758352518,
      "learning_rate": 8.148148148148148e-06,
      "loss": 0.0014,
      "step": 82960
    },
    {
      "epoch": 8.88996035572699,
      "grad_norm": 0.02017354778945446,
      "learning_rate": 8.146719525697348e-06,
      "loss": 0.0001,
      "step": 82970
    },
    {
      "epoch": 8.891031822565092,
      "grad_norm": 0.00016930620768107474,
      "learning_rate": 8.145290903246545e-06,
      "loss": 0.0001,
      "step": 82980
    },
    {
      "epoch": 8.892103289403194,
      "grad_norm": 9.154449799098074e-05,
      "learning_rate": 8.143862280795743e-06,
      "loss": 0.0001,
      "step": 82990
    },
    {
      "epoch": 8.893174756241294,
      "grad_norm": 0.031412865966558456,
      "learning_rate": 8.14243365834494e-06,
      "loss": 0.0001,
      "step": 83000
    },
    {
      "epoch": 8.894246223079396,
      "grad_norm": 9.145079820882529e-05,
      "learning_rate": 8.14100503589414e-06,
      "loss": 0.0001,
      "step": 83010
    },
    {
      "epoch": 8.895317689917498,
      "grad_norm": 0.00012558842718135566,
      "learning_rate": 8.139576413443338e-06,
      "loss": 0.0,
      "step": 83020
    },
    {
      "epoch": 8.896389156755598,
      "grad_norm": 0.0001282428711419925,
      "learning_rate": 8.138147790992537e-06,
      "loss": 0.0001,
      "step": 83030
    },
    {
      "epoch": 8.8974606235937,
      "grad_norm": 0.011730529367923737,
      "learning_rate": 8.136719168541735e-06,
      "loss": 0.0001,
      "step": 83040
    },
    {
      "epoch": 8.898532090431802,
      "grad_norm": 0.3305538296699524,
      "learning_rate": 8.135290546090932e-06,
      "loss": 0.3164,
      "step": 83050
    },
    {
      "epoch": 8.899603557269902,
      "grad_norm": 0.00013796471466775984,
      "learning_rate": 8.13386192364013e-06,
      "loss": 0.0001,
      "step": 83060
    },
    {
      "epoch": 8.900675024108004,
      "grad_norm": 0.006042155437171459,
      "learning_rate": 8.132433301189328e-06,
      "loss": 0.0,
      "step": 83070
    },
    {
      "epoch": 8.901746490946106,
      "grad_norm": 0.00020700585446320474,
      "learning_rate": 8.131004678738527e-06,
      "loss": 0.0001,
      "step": 83080
    },
    {
      "epoch": 8.902817957784206,
      "grad_norm": 0.00014752488641534,
      "learning_rate": 8.129576056287727e-06,
      "loss": 0.0,
      "step": 83090
    },
    {
      "epoch": 8.903889424622308,
      "grad_norm": 0.0002394640032434836,
      "learning_rate": 8.128147433836924e-06,
      "loss": 0.0001,
      "step": 83100
    },
    {
      "epoch": 8.904960891460409,
      "grad_norm": 0.00017378316260874271,
      "learning_rate": 8.126718811386122e-06,
      "loss": 0.0,
      "step": 83110
    },
    {
      "epoch": 8.90603235829851,
      "grad_norm": 0.00016939172928687185,
      "learning_rate": 8.12529018893532e-06,
      "loss": 0.0,
      "step": 83120
    },
    {
      "epoch": 8.907103825136613,
      "grad_norm": 0.0011178877903148532,
      "learning_rate": 8.123861566484517e-06,
      "loss": 0.0,
      "step": 83130
    },
    {
      "epoch": 8.908175291974713,
      "grad_norm": 0.0007006030064076185,
      "learning_rate": 8.122432944033717e-06,
      "loss": 0.0004,
      "step": 83140
    },
    {
      "epoch": 8.909246758812815,
      "grad_norm": 0.0001754007098497823,
      "learning_rate": 8.121004321582914e-06,
      "loss": 0.0001,
      "step": 83150
    },
    {
      "epoch": 8.910318225650917,
      "grad_norm": 0.008622575551271439,
      "learning_rate": 8.119575699132114e-06,
      "loss": 0.0001,
      "step": 83160
    },
    {
      "epoch": 8.911389692489017,
      "grad_norm": 0.0001592007902218029,
      "learning_rate": 8.118147076681311e-06,
      "loss": 0.11,
      "step": 83170
    },
    {
      "epoch": 8.912461159327119,
      "grad_norm": 0.006014869082719088,
      "learning_rate": 8.116718454230509e-06,
      "loss": 0.0,
      "step": 83180
    },
    {
      "epoch": 8.913532626165221,
      "grad_norm": 0.005924468860030174,
      "learning_rate": 8.115289831779707e-06,
      "loss": 0.1504,
      "step": 83190
    },
    {
      "epoch": 8.914604093003321,
      "grad_norm": 0.00015919265570119023,
      "learning_rate": 8.113861209328904e-06,
      "loss": 0.0004,
      "step": 83200
    },
    {
      "epoch": 8.915675559841423,
      "grad_norm": 0.0014945028815418482,
      "learning_rate": 8.112432586878104e-06,
      "loss": 0.0003,
      "step": 83210
    },
    {
      "epoch": 8.916747026679523,
      "grad_norm": 0.0007170318276621401,
      "learning_rate": 8.111003964427301e-06,
      "loss": 0.1345,
      "step": 83220
    },
    {
      "epoch": 8.917818493517625,
      "grad_norm": 8.840941154630855e-05,
      "learning_rate": 8.1095753419765e-06,
      "loss": 0.001,
      "step": 83230
    },
    {
      "epoch": 8.918889960355727,
      "grad_norm": 0.00017038302030414343,
      "learning_rate": 8.108146719525698e-06,
      "loss": 0.1978,
      "step": 83240
    },
    {
      "epoch": 8.919961427193828,
      "grad_norm": 0.0050212019123137,
      "learning_rate": 8.106718097074896e-06,
      "loss": 0.0,
      "step": 83250
    },
    {
      "epoch": 8.92103289403193,
      "grad_norm": 0.2006954401731491,
      "learning_rate": 8.105289474624094e-06,
      "loss": 0.001,
      "step": 83260
    },
    {
      "epoch": 8.922104360870032,
      "grad_norm": 0.00282683246769011,
      "learning_rate": 8.103860852173293e-06,
      "loss": 0.2456,
      "step": 83270
    },
    {
      "epoch": 8.923175827708132,
      "grad_norm": 0.0003757224476430565,
      "learning_rate": 8.10243222972249e-06,
      "loss": 0.4523,
      "step": 83280
    },
    {
      "epoch": 8.924247294546234,
      "grad_norm": 1.1262344121932983,
      "learning_rate": 8.101003607271688e-06,
      "loss": 0.0003,
      "step": 83290
    },
    {
      "epoch": 8.925318761384336,
      "grad_norm": 0.007921969518065453,
      "learning_rate": 8.099574984820888e-06,
      "loss": 0.1996,
      "step": 83300
    },
    {
      "epoch": 8.926390228222436,
      "grad_norm": 0.009697155095636845,
      "learning_rate": 8.098146362370085e-06,
      "loss": 0.0001,
      "step": 83310
    },
    {
      "epoch": 8.927461695060538,
      "grad_norm": 0.00019798534049186856,
      "learning_rate": 8.096717739919283e-06,
      "loss": 0.0002,
      "step": 83320
    },
    {
      "epoch": 8.928533161898638,
      "grad_norm": 0.0027471233624964952,
      "learning_rate": 8.095289117468483e-06,
      "loss": 0.0001,
      "step": 83330
    },
    {
      "epoch": 8.92960462873674,
      "grad_norm": 0.02114764228463173,
      "learning_rate": 8.09386049501768e-06,
      "loss": 0.0001,
      "step": 83340
    },
    {
      "epoch": 8.930676095574842,
      "grad_norm": 0.00400847801938653,
      "learning_rate": 8.092431872566878e-06,
      "loss": 0.1445,
      "step": 83350
    },
    {
      "epoch": 8.931747562412943,
      "grad_norm": 0.015143814496695995,
      "learning_rate": 8.091003250116076e-06,
      "loss": 0.0002,
      "step": 83360
    },
    {
      "epoch": 8.932819029251045,
      "grad_norm": 0.002093660645186901,
      "learning_rate": 8.089574627665275e-06,
      "loss": 0.0823,
      "step": 83370
    },
    {
      "epoch": 8.933890496089147,
      "grad_norm": 0.5039697885513306,
      "learning_rate": 8.088146005214473e-06,
      "loss": 0.3833,
      "step": 83380
    },
    {
      "epoch": 8.934961962927247,
      "grad_norm": 0.000624499109108001,
      "learning_rate": 8.08671738276367e-06,
      "loss": 0.1549,
      "step": 83390
    },
    {
      "epoch": 8.936033429765349,
      "grad_norm": 0.0020486554130911827,
      "learning_rate": 8.08528876031287e-06,
      "loss": 0.0006,
      "step": 83400
    },
    {
      "epoch": 8.93710489660345,
      "grad_norm": 0.8188039064407349,
      "learning_rate": 8.083860137862067e-06,
      "loss": 0.0005,
      "step": 83410
    },
    {
      "epoch": 8.938176363441551,
      "grad_norm": 0.00392709206789732,
      "learning_rate": 8.082431515411265e-06,
      "loss": 0.2545,
      "step": 83420
    },
    {
      "epoch": 8.939247830279653,
      "grad_norm": 0.0007583608385175467,
      "learning_rate": 8.081002892960463e-06,
      "loss": 0.0143,
      "step": 83430
    },
    {
      "epoch": 8.940319297117755,
      "grad_norm": 0.00798817165195942,
      "learning_rate": 8.079574270509662e-06,
      "loss": 0.0001,
      "step": 83440
    },
    {
      "epoch": 8.941390763955855,
      "grad_norm": 0.0008294932777062058,
      "learning_rate": 8.07814564805886e-06,
      "loss": 0.0953,
      "step": 83450
    },
    {
      "epoch": 8.942462230793957,
      "grad_norm": 0.00046920732711441815,
      "learning_rate": 8.076717025608059e-06,
      "loss": 0.1745,
      "step": 83460
    },
    {
      "epoch": 8.94353369763206,
      "grad_norm": 0.006761058233678341,
      "learning_rate": 8.075288403157257e-06,
      "loss": 0.0001,
      "step": 83470
    },
    {
      "epoch": 8.94460516447016,
      "grad_norm": 0.2655392289161682,
      "learning_rate": 8.073859780706454e-06,
      "loss": 0.0008,
      "step": 83480
    },
    {
      "epoch": 8.945676631308261,
      "grad_norm": 0.0014788844855502248,
      "learning_rate": 8.072431158255652e-06,
      "loss": 0.0002,
      "step": 83490
    },
    {
      "epoch": 8.946748098146362,
      "grad_norm": 0.0006650469149462879,
      "learning_rate": 8.07100253580485e-06,
      "loss": 0.2191,
      "step": 83500
    },
    {
      "epoch": 8.947819564984464,
      "grad_norm": 0.02511337585747242,
      "learning_rate": 8.069573913354049e-06,
      "loss": 0.0037,
      "step": 83510
    },
    {
      "epoch": 8.948891031822566,
      "grad_norm": 0.000925177417229861,
      "learning_rate": 8.068145290903247e-06,
      "loss": 0.1101,
      "step": 83520
    },
    {
      "epoch": 8.949962498660666,
      "grad_norm": 0.008882894180715084,
      "learning_rate": 8.066716668452446e-06,
      "loss": 0.001,
      "step": 83530
    },
    {
      "epoch": 8.951033965498768,
      "grad_norm": 0.0017649681540206075,
      "learning_rate": 8.065288046001644e-06,
      "loss": 0.0004,
      "step": 83540
    },
    {
      "epoch": 8.95210543233687,
      "grad_norm": 0.012701628729701042,
      "learning_rate": 8.063859423550841e-06,
      "loss": 0.0002,
      "step": 83550
    },
    {
      "epoch": 8.95317689917497,
      "grad_norm": 0.0009169055847451091,
      "learning_rate": 8.06243080110004e-06,
      "loss": 0.0001,
      "step": 83560
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 0.00043619086500257254,
      "learning_rate": 8.061002178649237e-06,
      "loss": 0.001,
      "step": 83570
    },
    {
      "epoch": 8.955319832851174,
      "grad_norm": 0.0017417266499251127,
      "learning_rate": 8.059573556198436e-06,
      "loss": 0.0003,
      "step": 83580
    },
    {
      "epoch": 8.956391299689274,
      "grad_norm": 0.007148419041186571,
      "learning_rate": 8.058144933747636e-06,
      "loss": 0.0007,
      "step": 83590
    },
    {
      "epoch": 8.957462766527376,
      "grad_norm": 0.00033635165891610086,
      "learning_rate": 8.056716311296833e-06,
      "loss": 0.099,
      "step": 83600
    },
    {
      "epoch": 8.958534233365476,
      "grad_norm": 0.002029001247137785,
      "learning_rate": 8.055287688846031e-06,
      "loss": 0.2205,
      "step": 83610
    },
    {
      "epoch": 8.959605700203578,
      "grad_norm": 0.000569471507333219,
      "learning_rate": 8.053859066395229e-06,
      "loss": 0.0004,
      "step": 83620
    },
    {
      "epoch": 8.96067716704168,
      "grad_norm": 0.021019183099269867,
      "learning_rate": 8.052430443944426e-06,
      "loss": 0.0003,
      "step": 83630
    },
    {
      "epoch": 8.96174863387978,
      "grad_norm": 0.0020639917347580194,
      "learning_rate": 8.051001821493626e-06,
      "loss": 0.0001,
      "step": 83640
    },
    {
      "epoch": 8.962820100717883,
      "grad_norm": 0.0018926599295809865,
      "learning_rate": 8.049573199042823e-06,
      "loss": 0.0001,
      "step": 83650
    },
    {
      "epoch": 8.963891567555985,
      "grad_norm": 0.0006839303532615304,
      "learning_rate": 8.048144576592023e-06,
      "loss": 0.0001,
      "step": 83660
    },
    {
      "epoch": 8.964963034394085,
      "grad_norm": 0.009446583688259125,
      "learning_rate": 8.04671595414122e-06,
      "loss": 0.0003,
      "step": 83670
    },
    {
      "epoch": 8.966034501232187,
      "grad_norm": 0.0005636824644170702,
      "learning_rate": 8.045287331690418e-06,
      "loss": 0.2901,
      "step": 83680
    },
    {
      "epoch": 8.967105968070289,
      "grad_norm": 0.0018202863866463304,
      "learning_rate": 8.043858709239616e-06,
      "loss": 0.0,
      "step": 83690
    },
    {
      "epoch": 8.96817743490839,
      "grad_norm": 0.0008568284101784229,
      "learning_rate": 8.042430086788815e-06,
      "loss": 0.3497,
      "step": 83700
    },
    {
      "epoch": 8.969248901746491,
      "grad_norm": 1.0030380487442017,
      "learning_rate": 8.041001464338013e-06,
      "loss": 0.0012,
      "step": 83710
    },
    {
      "epoch": 8.970320368584591,
      "grad_norm": 0.016913961619138718,
      "learning_rate": 8.03957284188721e-06,
      "loss": 0.0003,
      "step": 83720
    },
    {
      "epoch": 8.971391835422693,
      "grad_norm": 0.002549476455897093,
      "learning_rate": 8.03814421943641e-06,
      "loss": 0.0001,
      "step": 83730
    },
    {
      "epoch": 8.972463302260795,
      "grad_norm": 0.0004948015557602048,
      "learning_rate": 8.036715596985607e-06,
      "loss": 0.0001,
      "step": 83740
    },
    {
      "epoch": 8.973534769098896,
      "grad_norm": 0.00044651393545791507,
      "learning_rate": 8.035286974534805e-06,
      "loss": 0.3351,
      "step": 83750
    },
    {
      "epoch": 8.974606235936998,
      "grad_norm": 0.002650174545124173,
      "learning_rate": 8.033858352084004e-06,
      "loss": 0.0009,
      "step": 83760
    },
    {
      "epoch": 8.9756777027751,
      "grad_norm": 0.004983093123883009,
      "learning_rate": 8.032429729633202e-06,
      "loss": 0.0001,
      "step": 83770
    },
    {
      "epoch": 8.9767491696132,
      "grad_norm": 0.0017737731104716659,
      "learning_rate": 8.0310011071824e-06,
      "loss": 0.0001,
      "step": 83780
    },
    {
      "epoch": 8.977820636451302,
      "grad_norm": 0.3448584973812103,
      "learning_rate": 8.029572484731597e-06,
      "loss": 0.001,
      "step": 83790
    },
    {
      "epoch": 8.978892103289404,
      "grad_norm": 0.0003952715778723359,
      "learning_rate": 8.028143862280797e-06,
      "loss": 0.0005,
      "step": 83800
    },
    {
      "epoch": 8.979963570127504,
      "grad_norm": 0.0055354624055325985,
      "learning_rate": 8.026715239829995e-06,
      "loss": 0.0,
      "step": 83810
    },
    {
      "epoch": 8.981035036965606,
      "grad_norm": 0.0004053137672599405,
      "learning_rate": 8.025286617379194e-06,
      "loss": 0.0,
      "step": 83820
    },
    {
      "epoch": 8.982106503803708,
      "grad_norm": 0.007072707172483206,
      "learning_rate": 8.023857994928392e-06,
      "loss": 0.0002,
      "step": 83830
    },
    {
      "epoch": 8.983177970641808,
      "grad_norm": 0.00042461941484361887,
      "learning_rate": 8.02242937247759e-06,
      "loss": 0.1166,
      "step": 83840
    },
    {
      "epoch": 8.98424943747991,
      "grad_norm": 0.008126749657094479,
      "learning_rate": 8.021000750026787e-06,
      "loss": 0.0894,
      "step": 83850
    },
    {
      "epoch": 8.985320904318012,
      "grad_norm": 0.00033305404940620065,
      "learning_rate": 8.019572127575985e-06,
      "loss": 0.0001,
      "step": 83860
    },
    {
      "epoch": 8.986392371156112,
      "grad_norm": 0.0008971493225544691,
      "learning_rate": 8.018143505125184e-06,
      "loss": 0.0,
      "step": 83870
    },
    {
      "epoch": 8.987463837994214,
      "grad_norm": 0.00037681881804019213,
      "learning_rate": 8.016714882674382e-06,
      "loss": 0.0017,
      "step": 83880
    },
    {
      "epoch": 8.988535304832315,
      "grad_norm": 0.0003659013891592622,
      "learning_rate": 8.015286260223581e-06,
      "loss": 0.217,
      "step": 83890
    },
    {
      "epoch": 8.989606771670417,
      "grad_norm": 0.32259923219680786,
      "learning_rate": 8.013857637772779e-06,
      "loss": 0.0003,
      "step": 83900
    },
    {
      "epoch": 8.990678238508519,
      "grad_norm": 0.006909811869263649,
      "learning_rate": 8.012429015321976e-06,
      "loss": 0.0032,
      "step": 83910
    },
    {
      "epoch": 8.991749705346619,
      "grad_norm": 0.0002789958380162716,
      "learning_rate": 8.011000392871174e-06,
      "loss": 0.0001,
      "step": 83920
    },
    {
      "epoch": 8.99282117218472,
      "grad_norm": 0.001560461358167231,
      "learning_rate": 8.009571770420372e-06,
      "loss": 0.0001,
      "step": 83930
    },
    {
      "epoch": 8.993892639022823,
      "grad_norm": 0.0007692314684391022,
      "learning_rate": 8.008143147969571e-06,
      "loss": 0.0867,
      "step": 83940
    },
    {
      "epoch": 8.994964105860923,
      "grad_norm": 0.00038297660648822784,
      "learning_rate": 8.006714525518769e-06,
      "loss": 0.0002,
      "step": 83950
    },
    {
      "epoch": 8.996035572699025,
      "grad_norm": 0.0003583270881790668,
      "learning_rate": 8.005285903067968e-06,
      "loss": 0.167,
      "step": 83960
    },
    {
      "epoch": 8.997107039537127,
      "grad_norm": 0.00506465882062912,
      "learning_rate": 8.003857280617166e-06,
      "loss": 0.2405,
      "step": 83970
    },
    {
      "epoch": 8.998178506375227,
      "grad_norm": 0.006749039515852928,
      "learning_rate": 8.002428658166363e-06,
      "loss": 0.0005,
      "step": 83980
    },
    {
      "epoch": 8.99924997321333,
      "grad_norm": 0.0023080427199602127,
      "learning_rate": 8.001000035715561e-06,
      "loss": 0.0,
      "step": 83990
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9771666666666666,
      "eval_f1": 0.9084836339345357,
      "eval_loss": 0.1529829055070877,
      "eval_precision": 0.918918918918919,
      "eval_recall": 0.8982826948480845,
      "eval_runtime": 388.1028,
      "eval_samples_per_second": 15.46,
      "eval_steps_per_second": 5.153,
      "step": 83997
    },
    {
      "epoch": 9.00032144005143,
      "grad_norm": 0.00025327890762127936,
      "learning_rate": 7.99957141326476e-06,
      "loss": 0.0001,
      "step": 84000
    },
    {
      "epoch": 9.001392906889532,
      "grad_norm": 0.000669555040076375,
      "learning_rate": 7.998142790813958e-06,
      "loss": 0.0001,
      "step": 84010
    },
    {
      "epoch": 9.002464373727634,
      "grad_norm": 0.00032995620858855546,
      "learning_rate": 7.996714168363156e-06,
      "loss": 0.0001,
      "step": 84020
    },
    {
      "epoch": 9.003535840565734,
      "grad_norm": 0.0048393867909908295,
      "learning_rate": 7.995285545912355e-06,
      "loss": 0.0001,
      "step": 84030
    },
    {
      "epoch": 9.004607307403836,
      "grad_norm": 0.002001805929467082,
      "learning_rate": 7.993856923461553e-06,
      "loss": 0.0892,
      "step": 84040
    },
    {
      "epoch": 9.005678774241938,
      "grad_norm": 0.0006838981062173843,
      "learning_rate": 7.99242830101075e-06,
      "loss": 0.0007,
      "step": 84050
    },
    {
      "epoch": 9.006750241080038,
      "grad_norm": 0.0002906071313191205,
      "learning_rate": 7.99099967855995e-06,
      "loss": 0.0,
      "step": 84060
    },
    {
      "epoch": 9.00782170791814,
      "grad_norm": 0.009173783473670483,
      "learning_rate": 7.989571056109148e-06,
      "loss": 0.0003,
      "step": 84070
    },
    {
      "epoch": 9.008893174756242,
      "grad_norm": 0.0016946513205766678,
      "learning_rate": 7.988142433658345e-06,
      "loss": 0.0001,
      "step": 84080
    },
    {
      "epoch": 9.009964641594342,
      "grad_norm": 0.0011809602146968246,
      "learning_rate": 7.986713811207543e-06,
      "loss": 0.0,
      "step": 84090
    },
    {
      "epoch": 9.011036108432444,
      "grad_norm": 0.00033941332367248833,
      "learning_rate": 7.985285188756742e-06,
      "loss": 0.0006,
      "step": 84100
    },
    {
      "epoch": 9.012107575270546,
      "grad_norm": 0.0004123187100049108,
      "learning_rate": 7.98385656630594e-06,
      "loss": 0.0,
      "step": 84110
    },
    {
      "epoch": 9.013179042108646,
      "grad_norm": 0.0015800177352502942,
      "learning_rate": 7.98242794385514e-06,
      "loss": 0.0001,
      "step": 84120
    },
    {
      "epoch": 9.014250508946748,
      "grad_norm": 0.000276655686320737,
      "learning_rate": 7.980999321404337e-06,
      "loss": 0.0,
      "step": 84130
    },
    {
      "epoch": 9.015321975784849,
      "grad_norm": 1.2752788066864014,
      "learning_rate": 7.979570698953535e-06,
      "loss": 0.0024,
      "step": 84140
    },
    {
      "epoch": 9.01639344262295,
      "grad_norm": 0.0006263111135922372,
      "learning_rate": 7.978142076502732e-06,
      "loss": 0.0,
      "step": 84150
    },
    {
      "epoch": 9.017464909461053,
      "grad_norm": 0.0002802567614708096,
      "learning_rate": 7.976713454051932e-06,
      "loss": 0.0,
      "step": 84160
    },
    {
      "epoch": 9.018536376299153,
      "grad_norm": 0.0002933194919023663,
      "learning_rate": 7.97528483160113e-06,
      "loss": 0.0,
      "step": 84170
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 42.015464782714844,
      "learning_rate": 7.973856209150329e-06,
      "loss": 0.2175,
      "step": 84180
    },
    {
      "epoch": 9.020679309975357,
      "grad_norm": 0.0018181509803980589,
      "learning_rate": 7.972427586699526e-06,
      "loss": 0.0,
      "step": 84190
    },
    {
      "epoch": 9.021750776813457,
      "grad_norm": 0.0002594833786133677,
      "learning_rate": 7.970998964248724e-06,
      "loss": 0.0,
      "step": 84200
    },
    {
      "epoch": 9.022822243651559,
      "grad_norm": 0.0005405056290328503,
      "learning_rate": 7.969570341797922e-06,
      "loss": 0.0125,
      "step": 84210
    },
    {
      "epoch": 9.023893710489661,
      "grad_norm": 0.0002746113168541342,
      "learning_rate": 7.96814171934712e-06,
      "loss": 0.0017,
      "step": 84220
    },
    {
      "epoch": 9.024965177327761,
      "grad_norm": 0.00023823244555387646,
      "learning_rate": 7.966713096896319e-06,
      "loss": 0.0,
      "step": 84230
    },
    {
      "epoch": 9.026036644165863,
      "grad_norm": 0.00023533635248895735,
      "learning_rate": 7.965284474445516e-06,
      "loss": 0.0001,
      "step": 84240
    },
    {
      "epoch": 9.027108111003965,
      "grad_norm": 0.0026054074987769127,
      "learning_rate": 7.963855851994716e-06,
      "loss": 0.0001,
      "step": 84250
    },
    {
      "epoch": 9.028179577842065,
      "grad_norm": 0.0029637778643518686,
      "learning_rate": 7.962427229543914e-06,
      "loss": 0.1932,
      "step": 84260
    },
    {
      "epoch": 9.029251044680167,
      "grad_norm": 0.00035405775997787714,
      "learning_rate": 7.960998607093111e-06,
      "loss": 0.1604,
      "step": 84270
    },
    {
      "epoch": 9.030322511518268,
      "grad_norm": 0.0044048018753528595,
      "learning_rate": 7.959569984642309e-06,
      "loss": 0.0,
      "step": 84280
    },
    {
      "epoch": 9.03139397835637,
      "grad_norm": 0.0015832640929147601,
      "learning_rate": 7.958141362191507e-06,
      "loss": 0.0005,
      "step": 84290
    },
    {
      "epoch": 9.032465445194472,
      "grad_norm": 0.0008842964307405055,
      "learning_rate": 7.956712739740706e-06,
      "loss": 0.0002,
      "step": 84300
    },
    {
      "epoch": 9.033536912032572,
      "grad_norm": 0.001705211354419589,
      "learning_rate": 7.955284117289904e-06,
      "loss": 0.0,
      "step": 84310
    },
    {
      "epoch": 9.034608378870674,
      "grad_norm": 0.00043169379932805896,
      "learning_rate": 7.953855494839103e-06,
      "loss": 0.0,
      "step": 84320
    },
    {
      "epoch": 9.035679845708776,
      "grad_norm": 0.00021168029343243688,
      "learning_rate": 7.9524268723883e-06,
      "loss": 0.0005,
      "step": 84330
    },
    {
      "epoch": 9.036751312546876,
      "grad_norm": 0.0019575455226004124,
      "learning_rate": 7.950998249937498e-06,
      "loss": 0.0008,
      "step": 84340
    },
    {
      "epoch": 9.037822779384978,
      "grad_norm": 0.0004141447425354272,
      "learning_rate": 7.949569627486696e-06,
      "loss": 0.0007,
      "step": 84350
    },
    {
      "epoch": 9.03889424622308,
      "grad_norm": 0.0013510949211195111,
      "learning_rate": 7.948141005035894e-06,
      "loss": 0.0003,
      "step": 84360
    },
    {
      "epoch": 9.03996571306118,
      "grad_norm": 0.0008468311280012131,
      "learning_rate": 7.946712382585093e-06,
      "loss": 0.0,
      "step": 84370
    },
    {
      "epoch": 9.041037179899282,
      "grad_norm": 0.053898826241493225,
      "learning_rate": 7.94528376013429e-06,
      "loss": 0.0001,
      "step": 84380
    },
    {
      "epoch": 9.042108646737384,
      "grad_norm": 0.00013376555580180138,
      "learning_rate": 7.94385513768349e-06,
      "loss": 0.0023,
      "step": 84390
    },
    {
      "epoch": 9.043180113575485,
      "grad_norm": 0.00017656500858720392,
      "learning_rate": 7.942426515232688e-06,
      "loss": 0.0005,
      "step": 84400
    },
    {
      "epoch": 9.044251580413587,
      "grad_norm": 0.00020258745644241571,
      "learning_rate": 7.940997892781885e-06,
      "loss": 0.0004,
      "step": 84410
    },
    {
      "epoch": 9.045323047251687,
      "grad_norm": 0.00014005530101712793,
      "learning_rate": 7.939569270331083e-06,
      "loss": 0.0,
      "step": 84420
    },
    {
      "epoch": 9.046394514089789,
      "grad_norm": 0.00044034066377207637,
      "learning_rate": 7.938140647880282e-06,
      "loss": 0.0,
      "step": 84430
    },
    {
      "epoch": 9.04746598092789,
      "grad_norm": 0.0013142077950760722,
      "learning_rate": 7.93671202542948e-06,
      "loss": 0.0,
      "step": 84440
    },
    {
      "epoch": 9.048537447765991,
      "grad_norm": 0.00018950625963043422,
      "learning_rate": 7.935283402978678e-06,
      "loss": 0.3364,
      "step": 84450
    },
    {
      "epoch": 9.049608914604093,
      "grad_norm": 0.0005920372204855084,
      "learning_rate": 7.933854780527877e-06,
      "loss": 0.0,
      "step": 84460
    },
    {
      "epoch": 9.050680381442195,
      "grad_norm": 0.0011606665793806314,
      "learning_rate": 7.932426158077075e-06,
      "loss": 0.0,
      "step": 84470
    },
    {
      "epoch": 9.051751848280295,
      "grad_norm": 0.0003171946154907346,
      "learning_rate": 7.930997535626272e-06,
      "loss": 0.1776,
      "step": 84480
    },
    {
      "epoch": 9.052823315118397,
      "grad_norm": 0.0003123660571873188,
      "learning_rate": 7.929568913175472e-06,
      "loss": 0.0004,
      "step": 84490
    },
    {
      "epoch": 9.0538947819565,
      "grad_norm": 0.001512240502052009,
      "learning_rate": 7.92814029072467e-06,
      "loss": 0.0973,
      "step": 84500
    },
    {
      "epoch": 9.0549662487946,
      "grad_norm": 0.0004768426588270813,
      "learning_rate": 7.926711668273867e-06,
      "loss": 0.0,
      "step": 84510
    },
    {
      "epoch": 9.056037715632701,
      "grad_norm": 0.009712484665215015,
      "learning_rate": 7.925283045823065e-06,
      "loss": 0.0,
      "step": 84520
    },
    {
      "epoch": 9.057109182470802,
      "grad_norm": 0.0006696050986647606,
      "learning_rate": 7.923854423372264e-06,
      "loss": 0.0017,
      "step": 84530
    },
    {
      "epoch": 9.058180649308904,
      "grad_norm": 0.0005932567873969674,
      "learning_rate": 7.922425800921462e-06,
      "loss": 0.0001,
      "step": 84540
    },
    {
      "epoch": 9.059252116147006,
      "grad_norm": 0.00031187382410280406,
      "learning_rate": 7.920997178470661e-06,
      "loss": 0.0001,
      "step": 84550
    },
    {
      "epoch": 9.060323582985106,
      "grad_norm": 0.0004184498102404177,
      "learning_rate": 7.919568556019859e-06,
      "loss": 0.0,
      "step": 84560
    },
    {
      "epoch": 9.061395049823208,
      "grad_norm": 0.0006623276276513934,
      "learning_rate": 7.918139933569057e-06,
      "loss": 0.0,
      "step": 84570
    },
    {
      "epoch": 9.06246651666131,
      "grad_norm": 0.0011704949429258704,
      "learning_rate": 7.916711311118254e-06,
      "loss": 0.0002,
      "step": 84580
    },
    {
      "epoch": 9.06353798349941,
      "grad_norm": 0.0004954706528224051,
      "learning_rate": 7.915282688667452e-06,
      "loss": 0.0003,
      "step": 84590
    },
    {
      "epoch": 9.064609450337512,
      "grad_norm": 0.0006097736186347902,
      "learning_rate": 7.913854066216651e-06,
      "loss": 0.0,
      "step": 84600
    },
    {
      "epoch": 9.065680917175614,
      "grad_norm": 0.0004554886254481971,
      "learning_rate": 7.91242544376585e-06,
      "loss": 0.0001,
      "step": 84610
    },
    {
      "epoch": 9.066752384013714,
      "grad_norm": 0.04466859623789787,
      "learning_rate": 7.910996821315048e-06,
      "loss": 0.0001,
      "step": 84620
    },
    {
      "epoch": 9.067823850851816,
      "grad_norm": 0.000606161484029144,
      "learning_rate": 7.909568198864246e-06,
      "loss": 0.0935,
      "step": 84630
    },
    {
      "epoch": 9.068895317689918,
      "grad_norm": 0.00147371762432158,
      "learning_rate": 7.908139576413444e-06,
      "loss": 0.0002,
      "step": 84640
    },
    {
      "epoch": 9.069966784528019,
      "grad_norm": 0.0007506475085392594,
      "learning_rate": 7.906710953962641e-06,
      "loss": 0.3411,
      "step": 84650
    },
    {
      "epoch": 9.07103825136612,
      "grad_norm": 0.002238665008917451,
      "learning_rate": 7.905282331511839e-06,
      "loss": 0.0019,
      "step": 84660
    },
    {
      "epoch": 9.07210971820422,
      "grad_norm": 0.0002657943405210972,
      "learning_rate": 7.903853709061038e-06,
      "loss": 0.0,
      "step": 84670
    },
    {
      "epoch": 9.073181185042323,
      "grad_norm": 0.0002264767827000469,
      "learning_rate": 7.902425086610238e-06,
      "loss": 0.0001,
      "step": 84680
    },
    {
      "epoch": 9.074252651880425,
      "grad_norm": 0.004692464601248503,
      "learning_rate": 7.900996464159435e-06,
      "loss": 0.0001,
      "step": 84690
    },
    {
      "epoch": 9.075324118718525,
      "grad_norm": 0.0005291489651426673,
      "learning_rate": 7.899567841708633e-06,
      "loss": 0.0,
      "step": 84700
    },
    {
      "epoch": 9.076395585556627,
      "grad_norm": 0.0002977267431560904,
      "learning_rate": 7.89813921925783e-06,
      "loss": 0.0001,
      "step": 84710
    },
    {
      "epoch": 9.077467052394729,
      "grad_norm": 0.0028304182924330235,
      "learning_rate": 7.896710596807028e-06,
      "loss": 0.0001,
      "step": 84720
    },
    {
      "epoch": 9.07853851923283,
      "grad_norm": 0.00024285688414238393,
      "learning_rate": 7.895281974356228e-06,
      "loss": 0.0001,
      "step": 84730
    },
    {
      "epoch": 9.079609986070931,
      "grad_norm": 0.0021080553997308016,
      "learning_rate": 7.893853351905425e-06,
      "loss": 0.0,
      "step": 84740
    },
    {
      "epoch": 9.080681452909033,
      "grad_norm": 0.012791351415216923,
      "learning_rate": 7.892424729454625e-06,
      "loss": 0.0001,
      "step": 84750
    },
    {
      "epoch": 9.081752919747133,
      "grad_norm": 0.00028770286007784307,
      "learning_rate": 7.890996107003823e-06,
      "loss": 0.0,
      "step": 84760
    },
    {
      "epoch": 9.082824386585235,
      "grad_norm": 0.0002652276016306132,
      "learning_rate": 7.88956748455302e-06,
      "loss": 0.0002,
      "step": 84770
    },
    {
      "epoch": 9.083895853423337,
      "grad_norm": 0.00026201384025625885,
      "learning_rate": 7.888138862102218e-06,
      "loss": 0.0,
      "step": 84780
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 0.0002349595888517797,
      "learning_rate": 7.886710239651417e-06,
      "loss": 0.0001,
      "step": 84790
    },
    {
      "epoch": 9.08603878709954,
      "grad_norm": 0.00016667046293150634,
      "learning_rate": 7.885281617200615e-06,
      "loss": 0.0,
      "step": 84800
    },
    {
      "epoch": 9.08711025393764,
      "grad_norm": 0.0006387602188624442,
      "learning_rate": 7.883852994749813e-06,
      "loss": 0.0001,
      "step": 84810
    },
    {
      "epoch": 9.088181720775742,
      "grad_norm": 0.0018776805372908711,
      "learning_rate": 7.882424372299012e-06,
      "loss": 0.0,
      "step": 84820
    },
    {
      "epoch": 9.089253187613844,
      "grad_norm": 0.00029241963056847453,
      "learning_rate": 7.88099574984821e-06,
      "loss": 0.0,
      "step": 84830
    },
    {
      "epoch": 9.090324654451944,
      "grad_norm": 0.0007664589793421328,
      "learning_rate": 7.879567127397407e-06,
      "loss": 0.0,
      "step": 84840
    },
    {
      "epoch": 9.091396121290046,
      "grad_norm": 0.0008615360129624605,
      "learning_rate": 7.878138504946607e-06,
      "loss": 0.0001,
      "step": 84850
    },
    {
      "epoch": 9.092467588128148,
      "grad_norm": 0.01350583415478468,
      "learning_rate": 7.876709882495804e-06,
      "loss": 0.0001,
      "step": 84860
    },
    {
      "epoch": 9.093539054966248,
      "grad_norm": 0.00016906874952837825,
      "learning_rate": 7.875281260045002e-06,
      "loss": 0.0007,
      "step": 84870
    },
    {
      "epoch": 9.09461052180435,
      "grad_norm": 0.0013409820385277271,
      "learning_rate": 7.8738526375942e-06,
      "loss": 0.0001,
      "step": 84880
    },
    {
      "epoch": 9.095681988642452,
      "grad_norm": 0.0009901983430609107,
      "learning_rate": 7.872424015143399e-06,
      "loss": 0.0001,
      "step": 84890
    },
    {
      "epoch": 9.096753455480552,
      "grad_norm": 0.00426331115886569,
      "learning_rate": 7.870995392692597e-06,
      "loss": 0.1037,
      "step": 84900
    },
    {
      "epoch": 9.097824922318654,
      "grad_norm": 0.00027234602021053433,
      "learning_rate": 7.869566770241796e-06,
      "loss": 0.0001,
      "step": 84910
    },
    {
      "epoch": 9.098896389156756,
      "grad_norm": 0.008164546452462673,
      "learning_rate": 7.868138147790994e-06,
      "loss": 0.0003,
      "step": 84920
    },
    {
      "epoch": 9.099967855994857,
      "grad_norm": 0.07493584603071213,
      "learning_rate": 7.866709525340191e-06,
      "loss": 0.1049,
      "step": 84930
    },
    {
      "epoch": 9.101039322832959,
      "grad_norm": 0.005207326263189316,
      "learning_rate": 7.865280902889389e-06,
      "loss": 0.0001,
      "step": 84940
    },
    {
      "epoch": 9.102110789671059,
      "grad_norm": 0.002805182710289955,
      "learning_rate": 7.863852280438587e-06,
      "loss": 0.0,
      "step": 84950
    },
    {
      "epoch": 9.103182256509161,
      "grad_norm": 0.00022263883147388697,
      "learning_rate": 7.862423657987786e-06,
      "loss": 0.1929,
      "step": 84960
    },
    {
      "epoch": 9.104253723347263,
      "grad_norm": 0.0007940570940263569,
      "learning_rate": 7.860995035536984e-06,
      "loss": 0.1177,
      "step": 84970
    },
    {
      "epoch": 9.105325190185363,
      "grad_norm": 0.0001715669350232929,
      "learning_rate": 7.859566413086183e-06,
      "loss": 0.0,
      "step": 84980
    },
    {
      "epoch": 9.106396657023465,
      "grad_norm": 0.0002216691500507295,
      "learning_rate": 7.858137790635381e-06,
      "loss": 0.0,
      "step": 84990
    },
    {
      "epoch": 9.107468123861567,
      "grad_norm": 0.002252332866191864,
      "learning_rate": 7.856709168184579e-06,
      "loss": 0.0,
      "step": 85000
    },
    {
      "epoch": 9.108539590699667,
      "grad_norm": 0.0002677916781976819,
      "learning_rate": 7.855280545733776e-06,
      "loss": 0.0,
      "step": 85010
    },
    {
      "epoch": 9.10961105753777,
      "grad_norm": 0.0001748180075082928,
      "learning_rate": 7.853851923282974e-06,
      "loss": 0.2169,
      "step": 85020
    },
    {
      "epoch": 9.110682524375871,
      "grad_norm": 0.00021208440011832863,
      "learning_rate": 7.852423300832173e-06,
      "loss": 0.0,
      "step": 85030
    },
    {
      "epoch": 9.111753991213972,
      "grad_norm": 0.0026315278373658657,
      "learning_rate": 7.850994678381371e-06,
      "loss": 0.0001,
      "step": 85040
    },
    {
      "epoch": 9.112825458052074,
      "grad_norm": 0.00023437845811713487,
      "learning_rate": 7.84956605593057e-06,
      "loss": 0.0001,
      "step": 85050
    },
    {
      "epoch": 9.113896924890174,
      "grad_norm": 0.0002994311216752976,
      "learning_rate": 7.848137433479768e-06,
      "loss": 0.0004,
      "step": 85060
    },
    {
      "epoch": 9.114968391728276,
      "grad_norm": 0.0001874932204373181,
      "learning_rate": 7.846708811028966e-06,
      "loss": 0.0002,
      "step": 85070
    },
    {
      "epoch": 9.116039858566378,
      "grad_norm": 0.0044972035102546215,
      "learning_rate": 7.845280188578163e-06,
      "loss": 0.0,
      "step": 85080
    },
    {
      "epoch": 9.117111325404478,
      "grad_norm": 0.000249171513132751,
      "learning_rate": 7.843851566127363e-06,
      "loss": 0.0001,
      "step": 85090
    },
    {
      "epoch": 9.11818279224258,
      "grad_norm": 0.0006427334155887365,
      "learning_rate": 7.84242294367656e-06,
      "loss": 0.0,
      "step": 85100
    },
    {
      "epoch": 9.119254259080682,
      "grad_norm": 0.0002521924616303295,
      "learning_rate": 7.84099432122576e-06,
      "loss": 0.0,
      "step": 85110
    },
    {
      "epoch": 9.120325725918782,
      "grad_norm": 0.0002272781712235883,
      "learning_rate": 7.839565698774957e-06,
      "loss": 0.0,
      "step": 85120
    },
    {
      "epoch": 9.121397192756884,
      "grad_norm": 0.013514227233827114,
      "learning_rate": 7.838137076324155e-06,
      "loss": 0.1592,
      "step": 85130
    },
    {
      "epoch": 9.122468659594986,
      "grad_norm": 0.0034770560450851917,
      "learning_rate": 7.836708453873353e-06,
      "loss": 0.0,
      "step": 85140
    },
    {
      "epoch": 9.123540126433086,
      "grad_norm": 0.0015897154808044434,
      "learning_rate": 7.835279831422552e-06,
      "loss": 0.0,
      "step": 85150
    },
    {
      "epoch": 9.124611593271188,
      "grad_norm": 0.47765329480171204,
      "learning_rate": 7.83385120897175e-06,
      "loss": 0.0626,
      "step": 85160
    },
    {
      "epoch": 9.12568306010929,
      "grad_norm": 0.0011209246004000306,
      "learning_rate": 7.832422586520947e-06,
      "loss": 0.0,
      "step": 85170
    },
    {
      "epoch": 9.12675452694739,
      "grad_norm": 0.00032832560827955604,
      "learning_rate": 7.830993964070147e-06,
      "loss": 0.0,
      "step": 85180
    },
    {
      "epoch": 9.127825993785493,
      "grad_norm": 0.004075033590197563,
      "learning_rate": 7.829565341619344e-06,
      "loss": 0.0001,
      "step": 85190
    },
    {
      "epoch": 9.128897460623593,
      "grad_norm": 0.0023831187281757593,
      "learning_rate": 7.828136719168542e-06,
      "loss": 0.0,
      "step": 85200
    },
    {
      "epoch": 9.129968927461695,
      "grad_norm": 0.0003932529943995178,
      "learning_rate": 7.82670809671774e-06,
      "loss": 0.0,
      "step": 85210
    },
    {
      "epoch": 9.131040394299797,
      "grad_norm": 0.0003550186229404062,
      "learning_rate": 7.82527947426694e-06,
      "loss": 0.0093,
      "step": 85220
    },
    {
      "epoch": 9.132111861137897,
      "grad_norm": 0.0005558694247156382,
      "learning_rate": 7.823850851816137e-06,
      "loss": 0.0,
      "step": 85230
    },
    {
      "epoch": 9.133183327975999,
      "grad_norm": 0.00013939087511971593,
      "learning_rate": 7.822422229365335e-06,
      "loss": 0.0,
      "step": 85240
    },
    {
      "epoch": 9.134254794814101,
      "grad_norm": 0.0008462810656055808,
      "learning_rate": 7.820993606914534e-06,
      "loss": 0.0,
      "step": 85250
    },
    {
      "epoch": 9.135326261652201,
      "grad_norm": 0.00016124833200592548,
      "learning_rate": 7.819564984463732e-06,
      "loss": 0.0,
      "step": 85260
    },
    {
      "epoch": 9.136397728490303,
      "grad_norm": 0.0003535458818078041,
      "learning_rate": 7.81813636201293e-06,
      "loss": 0.0,
      "step": 85270
    },
    {
      "epoch": 9.137469195328405,
      "grad_norm": 0.0015597747405990958,
      "learning_rate": 7.816707739562129e-06,
      "loss": 0.0,
      "step": 85280
    },
    {
      "epoch": 9.138540662166506,
      "grad_norm": 0.00014391870354302227,
      "learning_rate": 7.815279117111326e-06,
      "loss": 0.0,
      "step": 85290
    },
    {
      "epoch": 9.139612129004608,
      "grad_norm": 0.0001629906619200483,
      "learning_rate": 7.813850494660524e-06,
      "loss": 0.0,
      "step": 85300
    },
    {
      "epoch": 9.14068359584271,
      "grad_norm": 0.000621957122348249,
      "learning_rate": 7.812421872209722e-06,
      "loss": 0.0,
      "step": 85310
    },
    {
      "epoch": 9.14175506268081,
      "grad_norm": 0.00013347134517971426,
      "learning_rate": 7.810993249758921e-06,
      "loss": 0.0001,
      "step": 85320
    },
    {
      "epoch": 9.142826529518912,
      "grad_norm": 0.0015149099053815007,
      "learning_rate": 7.809564627308119e-06,
      "loss": 0.0001,
      "step": 85330
    },
    {
      "epoch": 9.143897996357012,
      "grad_norm": 0.0025354702956974506,
      "learning_rate": 7.808136004857318e-06,
      "loss": 0.0001,
      "step": 85340
    },
    {
      "epoch": 9.144969463195114,
      "grad_norm": 0.2618252635002136,
      "learning_rate": 7.806707382406516e-06,
      "loss": 0.0002,
      "step": 85350
    },
    {
      "epoch": 9.146040930033216,
      "grad_norm": 0.00014047976583242416,
      "learning_rate": 7.805278759955713e-06,
      "loss": 0.0,
      "step": 85360
    },
    {
      "epoch": 9.147112396871316,
      "grad_norm": 0.0005349005805328488,
      "learning_rate": 7.803850137504911e-06,
      "loss": 0.0004,
      "step": 85370
    },
    {
      "epoch": 9.148183863709418,
      "grad_norm": 0.0010211365297436714,
      "learning_rate": 7.802421515054109e-06,
      "loss": 0.0,
      "step": 85380
    },
    {
      "epoch": 9.14925533054752,
      "grad_norm": 0.0001265314349438995,
      "learning_rate": 7.800992892603308e-06,
      "loss": 0.0044,
      "step": 85390
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 0.0008568720077164471,
      "learning_rate": 7.799564270152506e-06,
      "loss": 0.0,
      "step": 85400
    },
    {
      "epoch": 9.151398264223722,
      "grad_norm": 0.0001146071299444884,
      "learning_rate": 7.798135647701705e-06,
      "loss": 0.0,
      "step": 85410
    },
    {
      "epoch": 9.152469731061824,
      "grad_norm": 0.003348112804815173,
      "learning_rate": 7.796707025250903e-06,
      "loss": 0.0,
      "step": 85420
    },
    {
      "epoch": 9.153541197899925,
      "grad_norm": 0.0003606842365115881,
      "learning_rate": 7.7952784028001e-06,
      "loss": 0.0,
      "step": 85430
    },
    {
      "epoch": 9.154612664738027,
      "grad_norm": 0.0005234492127783597,
      "learning_rate": 7.793849780349298e-06,
      "loss": 0.0,
      "step": 85440
    },
    {
      "epoch": 9.155684131576129,
      "grad_norm": 0.000190494378330186,
      "learning_rate": 7.792421157898496e-06,
      "loss": 0.0,
      "step": 85450
    },
    {
      "epoch": 9.156755598414229,
      "grad_norm": 0.00017986077000387013,
      "learning_rate": 7.790992535447695e-06,
      "loss": 0.0,
      "step": 85460
    },
    {
      "epoch": 9.15782706525233,
      "grad_norm": 0.0002375805634073913,
      "learning_rate": 7.789563912996893e-06,
      "loss": 0.0,
      "step": 85470
    },
    {
      "epoch": 9.158898532090431,
      "grad_norm": 0.000867177383042872,
      "learning_rate": 7.788135290546092e-06,
      "loss": 0.0,
      "step": 85480
    },
    {
      "epoch": 9.159969998928533,
      "grad_norm": 0.0079626040533185,
      "learning_rate": 7.78670666809529e-06,
      "loss": 0.0,
      "step": 85490
    },
    {
      "epoch": 9.161041465766635,
      "grad_norm": 0.00013909560220781714,
      "learning_rate": 7.785278045644488e-06,
      "loss": 0.0,
      "step": 85500
    },
    {
      "epoch": 9.162112932604735,
      "grad_norm": 0.00018043264572042972,
      "learning_rate": 7.783849423193685e-06,
      "loss": 0.0,
      "step": 85510
    },
    {
      "epoch": 9.163184399442837,
      "grad_norm": 0.0008968333713710308,
      "learning_rate": 7.782420800742885e-06,
      "loss": 0.0,
      "step": 85520
    },
    {
      "epoch": 9.16425586628094,
      "grad_norm": 0.00012459841673262417,
      "learning_rate": 7.780992178292082e-06,
      "loss": 0.0,
      "step": 85530
    },
    {
      "epoch": 9.16532733311904,
      "grad_norm": 0.0001417556923115626,
      "learning_rate": 7.77956355584128e-06,
      "loss": 0.0041,
      "step": 85540
    },
    {
      "epoch": 9.166398799957141,
      "grad_norm": 0.0049122911877930164,
      "learning_rate": 7.77813493339048e-06,
      "loss": 0.0676,
      "step": 85550
    },
    {
      "epoch": 9.167470266795243,
      "grad_norm": 0.00031837591086514294,
      "learning_rate": 7.776706310939677e-06,
      "loss": 0.0,
      "step": 85560
    },
    {
      "epoch": 9.168541733633344,
      "grad_norm": 0.00010072122677229345,
      "learning_rate": 7.775277688488875e-06,
      "loss": 0.0,
      "step": 85570
    },
    {
      "epoch": 9.169613200471446,
      "grad_norm": 0.00015897263074293733,
      "learning_rate": 7.773849066038074e-06,
      "loss": 0.0,
      "step": 85580
    },
    {
      "epoch": 9.170684667309546,
      "grad_norm": 0.000929419242311269,
      "learning_rate": 7.772420443587272e-06,
      "loss": 0.4588,
      "step": 85590
    },
    {
      "epoch": 9.171756134147648,
      "grad_norm": 0.4556303918361664,
      "learning_rate": 7.77099182113647e-06,
      "loss": 0.0002,
      "step": 85600
    },
    {
      "epoch": 9.17282760098575,
      "grad_norm": 0.00021216248569544405,
      "learning_rate": 7.769563198685667e-06,
      "loss": 0.0,
      "step": 85610
    },
    {
      "epoch": 9.17389906782385,
      "grad_norm": 0.00014541181735694408,
      "learning_rate": 7.768134576234866e-06,
      "loss": 0.0,
      "step": 85620
    },
    {
      "epoch": 9.174970534661952,
      "grad_norm": 0.00046294109779410064,
      "learning_rate": 7.766705953784064e-06,
      "loss": 0.0652,
      "step": 85630
    },
    {
      "epoch": 9.176042001500054,
      "grad_norm": 30.64964485168457,
      "learning_rate": 7.765277331333263e-06,
      "loss": 0.1963,
      "step": 85640
    },
    {
      "epoch": 9.177113468338154,
      "grad_norm": 0.0014866229612380266,
      "learning_rate": 7.763848708882461e-06,
      "loss": 0.0,
      "step": 85650
    },
    {
      "epoch": 9.178184935176256,
      "grad_norm": 0.0011306264204904437,
      "learning_rate": 7.762420086431659e-06,
      "loss": 0.0002,
      "step": 85660
    },
    {
      "epoch": 9.179256402014358,
      "grad_norm": 0.00016711661010049284,
      "learning_rate": 7.760991463980856e-06,
      "loss": 0.2171,
      "step": 85670
    },
    {
      "epoch": 9.180327868852459,
      "grad_norm": 0.0014576760586351156,
      "learning_rate": 7.759562841530056e-06,
      "loss": 0.0001,
      "step": 85680
    },
    {
      "epoch": 9.18139933569056,
      "grad_norm": 0.00711044343188405,
      "learning_rate": 7.758134219079254e-06,
      "loss": 0.0,
      "step": 85690
    },
    {
      "epoch": 9.182470802528663,
      "grad_norm": 0.00326360366307199,
      "learning_rate": 7.756705596628453e-06,
      "loss": 0.0002,
      "step": 85700
    },
    {
      "epoch": 9.183542269366763,
      "grad_norm": 0.0015325485728681087,
      "learning_rate": 7.75527697417765e-06,
      "loss": 0.2411,
      "step": 85710
    },
    {
      "epoch": 9.184613736204865,
      "grad_norm": 0.0003896077978424728,
      "learning_rate": 7.753848351726848e-06,
      "loss": 0.1203,
      "step": 85720
    },
    {
      "epoch": 9.185685203042965,
      "grad_norm": 0.00021812091290485114,
      "learning_rate": 7.752419729276046e-06,
      "loss": 0.0,
      "step": 85730
    },
    {
      "epoch": 9.186756669881067,
      "grad_norm": 0.0021506939083337784,
      "learning_rate": 7.750991106825244e-06,
      "loss": 0.1221,
      "step": 85740
    },
    {
      "epoch": 9.187828136719169,
      "grad_norm": 0.0001863412617240101,
      "learning_rate": 7.749562484374443e-06,
      "loss": 0.0,
      "step": 85750
    },
    {
      "epoch": 9.18889960355727,
      "grad_norm": 0.00018458360864315182,
      "learning_rate": 7.74813386192364e-06,
      "loss": 0.0001,
      "step": 85760
    },
    {
      "epoch": 9.189971070395371,
      "grad_norm": 0.09490450471639633,
      "learning_rate": 7.74670523947284e-06,
      "loss": 0.0002,
      "step": 85770
    },
    {
      "epoch": 9.191042537233473,
      "grad_norm": 0.0018334905616939068,
      "learning_rate": 7.745276617022038e-06,
      "loss": 0.0,
      "step": 85780
    },
    {
      "epoch": 9.192114004071573,
      "grad_norm": 0.009232842363417149,
      "learning_rate": 7.743847994571235e-06,
      "loss": 0.0,
      "step": 85790
    },
    {
      "epoch": 9.193185470909675,
      "grad_norm": 0.00018064212054014206,
      "learning_rate": 7.742419372120433e-06,
      "loss": 0.0001,
      "step": 85800
    },
    {
      "epoch": 9.194256937747777,
      "grad_norm": 0.0005247806548140943,
      "learning_rate": 7.74099074966963e-06,
      "loss": 0.0,
      "step": 85810
    },
    {
      "epoch": 9.195328404585878,
      "grad_norm": 0.001475862110964954,
      "learning_rate": 7.73956212721883e-06,
      "loss": 0.0001,
      "step": 85820
    },
    {
      "epoch": 9.19639987142398,
      "grad_norm": 0.0014153250958770514,
      "learning_rate": 7.738133504768028e-06,
      "loss": 0.0001,
      "step": 85830
    },
    {
      "epoch": 9.197471338262082,
      "grad_norm": 20.276260375976562,
      "learning_rate": 7.736704882317227e-06,
      "loss": 0.3161,
      "step": 85840
    },
    {
      "epoch": 9.198542805100182,
      "grad_norm": 0.0024902233853936195,
      "learning_rate": 7.735276259866425e-06,
      "loss": 0.1362,
      "step": 85850
    },
    {
      "epoch": 9.199614271938284,
      "grad_norm": 0.0004324142646510154,
      "learning_rate": 7.733847637415622e-06,
      "loss": 0.0,
      "step": 85860
    },
    {
      "epoch": 9.200685738776384,
      "grad_norm": 0.0008406526176258922,
      "learning_rate": 7.73241901496482e-06,
      "loss": 0.0025,
      "step": 85870
    },
    {
      "epoch": 9.201757205614486,
      "grad_norm": 0.000582193024456501,
      "learning_rate": 7.73099039251402e-06,
      "loss": 0.0009,
      "step": 85880
    },
    {
      "epoch": 9.202828672452588,
      "grad_norm": 0.00020629243226721883,
      "learning_rate": 7.729561770063217e-06,
      "loss": 0.0,
      "step": 85890
    },
    {
      "epoch": 9.203900139290688,
      "grad_norm": 0.00017798933549784124,
      "learning_rate": 7.728133147612415e-06,
      "loss": 0.0,
      "step": 85900
    },
    {
      "epoch": 9.20497160612879,
      "grad_norm": 0.001271469984203577,
      "learning_rate": 7.726704525161614e-06,
      "loss": 0.0018,
      "step": 85910
    },
    {
      "epoch": 9.206043072966892,
      "grad_norm": 0.00022248888853937387,
      "learning_rate": 7.725275902710812e-06,
      "loss": 0.0,
      "step": 85920
    },
    {
      "epoch": 9.207114539804993,
      "grad_norm": 0.00019182253163307905,
      "learning_rate": 7.72384728026001e-06,
      "loss": 0.0,
      "step": 85930
    },
    {
      "epoch": 9.208186006643095,
      "grad_norm": 0.00016406868235208094,
      "learning_rate": 7.722418657809209e-06,
      "loss": 0.0001,
      "step": 85940
    },
    {
      "epoch": 9.209257473481196,
      "grad_norm": 0.0025628828443586826,
      "learning_rate": 7.720990035358407e-06,
      "loss": 0.0,
      "step": 85950
    },
    {
      "epoch": 9.210328940319297,
      "grad_norm": 0.04386521875858307,
      "learning_rate": 7.719561412907604e-06,
      "loss": 0.0,
      "step": 85960
    },
    {
      "epoch": 9.211400407157399,
      "grad_norm": 0.00023704375780653208,
      "learning_rate": 7.718132790456802e-06,
      "loss": 0.0,
      "step": 85970
    },
    {
      "epoch": 9.2124718739955,
      "grad_norm": 0.0001311226369580254,
      "learning_rate": 7.716704168006001e-06,
      "loss": 0.0,
      "step": 85980
    },
    {
      "epoch": 9.213543340833601,
      "grad_norm": 1.8161932229995728,
      "learning_rate": 7.715275545555199e-06,
      "loss": 0.0014,
      "step": 85990
    },
    {
      "epoch": 9.214614807671703,
      "grad_norm": 0.00011144777090521529,
      "learning_rate": 7.713846923104398e-06,
      "loss": 0.0,
      "step": 86000
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 0.0003990305121988058,
      "learning_rate": 7.712418300653596e-06,
      "loss": 0.0001,
      "step": 86010
    },
    {
      "epoch": 9.216757741347905,
      "grad_norm": 0.0001497079065302387,
      "learning_rate": 7.710989678202794e-06,
      "loss": 0.0026,
      "step": 86020
    },
    {
      "epoch": 9.217829208186007,
      "grad_norm": 0.00016233083442784846,
      "learning_rate": 7.709561055751991e-06,
      "loss": 0.0003,
      "step": 86030
    },
    {
      "epoch": 9.218900675024107,
      "grad_norm": 0.0001719830179354176,
      "learning_rate": 7.708132433301189e-06,
      "loss": 0.1757,
      "step": 86040
    },
    {
      "epoch": 9.21997214186221,
      "grad_norm": 0.00011501603876240551,
      "learning_rate": 7.706703810850388e-06,
      "loss": 0.0,
      "step": 86050
    },
    {
      "epoch": 9.221043608700311,
      "grad_norm": 0.0001827176020015031,
      "learning_rate": 7.705275188399586e-06,
      "loss": 0.0,
      "step": 86060
    },
    {
      "epoch": 9.222115075538412,
      "grad_norm": 0.00011613537935772911,
      "learning_rate": 7.703846565948785e-06,
      "loss": 0.0,
      "step": 86070
    },
    {
      "epoch": 9.223186542376514,
      "grad_norm": 0.00012025015166727826,
      "learning_rate": 7.702417943497983e-06,
      "loss": 0.2499,
      "step": 86080
    },
    {
      "epoch": 9.224258009214616,
      "grad_norm": 8.993242227006704e-05,
      "learning_rate": 7.70098932104718e-06,
      "loss": 0.0,
      "step": 86090
    },
    {
      "epoch": 9.225329476052716,
      "grad_norm": 0.00013091570872347802,
      "learning_rate": 7.699560698596378e-06,
      "loss": 0.0001,
      "step": 86100
    },
    {
      "epoch": 9.226400942890818,
      "grad_norm": 0.00010517522605368868,
      "learning_rate": 7.698132076145576e-06,
      "loss": 0.0006,
      "step": 86110
    },
    {
      "epoch": 9.227472409728918,
      "grad_norm": 0.00017862190725281835,
      "learning_rate": 7.696703453694775e-06,
      "loss": 0.0,
      "step": 86120
    },
    {
      "epoch": 9.22854387656702,
      "grad_norm": 0.00979340635240078,
      "learning_rate": 7.695274831243975e-06,
      "loss": 0.0,
      "step": 86130
    },
    {
      "epoch": 9.229615343405122,
      "grad_norm": 9.029165812535211e-05,
      "learning_rate": 7.693846208793172e-06,
      "loss": 0.0,
      "step": 86140
    },
    {
      "epoch": 9.230686810243222,
      "grad_norm": 8.849544246913865e-05,
      "learning_rate": 7.69241758634237e-06,
      "loss": 0.0001,
      "step": 86150
    },
    {
      "epoch": 9.231758277081324,
      "grad_norm": 0.3185924291610718,
      "learning_rate": 7.690988963891568e-06,
      "loss": 0.2575,
      "step": 86160
    },
    {
      "epoch": 9.232829743919426,
      "grad_norm": 0.0006898490246385336,
      "learning_rate": 7.689560341440766e-06,
      "loss": 0.3302,
      "step": 86170
    },
    {
      "epoch": 9.233901210757526,
      "grad_norm": 0.00027916801627725363,
      "learning_rate": 7.688131718989963e-06,
      "loss": 0.0001,
      "step": 86180
    },
    {
      "epoch": 9.234972677595628,
      "grad_norm": 0.00019589193107094616,
      "learning_rate": 7.686703096539163e-06,
      "loss": 0.0,
      "step": 86190
    },
    {
      "epoch": 9.23604414443373,
      "grad_norm": 0.0007319684373214841,
      "learning_rate": 7.685274474088362e-06,
      "loss": 0.0,
      "step": 86200
    },
    {
      "epoch": 9.23711561127183,
      "grad_norm": 0.00037682682159356773,
      "learning_rate": 7.68384585163756e-06,
      "loss": 0.0,
      "step": 86210
    },
    {
      "epoch": 9.238187078109933,
      "grad_norm": 0.01179439201951027,
      "learning_rate": 7.682417229186757e-06,
      "loss": 0.0,
      "step": 86220
    },
    {
      "epoch": 9.239258544948035,
      "grad_norm": 0.0004364257038105279,
      "learning_rate": 7.680988606735955e-06,
      "loss": 0.0001,
      "step": 86230
    },
    {
      "epoch": 9.240330011786135,
      "grad_norm": 0.0002211158280260861,
      "learning_rate": 7.679559984285153e-06,
      "loss": 0.0002,
      "step": 86240
    },
    {
      "epoch": 9.241401478624237,
      "grad_norm": 0.012631254270672798,
      "learning_rate": 7.678131361834352e-06,
      "loss": 0.0,
      "step": 86250
    },
    {
      "epoch": 9.242472945462337,
      "grad_norm": 0.00012423373118508607,
      "learning_rate": 7.67670273938355e-06,
      "loss": 0.2271,
      "step": 86260
    },
    {
      "epoch": 9.243544412300439,
      "grad_norm": 0.028097741305828094,
      "learning_rate": 7.675274116932749e-06,
      "loss": 0.0005,
      "step": 86270
    },
    {
      "epoch": 9.244615879138541,
      "grad_norm": 0.0005785531830042601,
      "learning_rate": 7.673845494481947e-06,
      "loss": 0.3704,
      "step": 86280
    },
    {
      "epoch": 9.245687345976641,
      "grad_norm": 0.00012852057989221066,
      "learning_rate": 7.672416872031144e-06,
      "loss": 0.0001,
      "step": 86290
    },
    {
      "epoch": 9.246758812814743,
      "grad_norm": 0.01185342762619257,
      "learning_rate": 7.670988249580342e-06,
      "loss": 0.0001,
      "step": 86300
    },
    {
      "epoch": 9.247830279652845,
      "grad_norm": 0.025532551109790802,
      "learning_rate": 7.669559627129541e-06,
      "loss": 0.0001,
      "step": 86310
    },
    {
      "epoch": 9.248901746490946,
      "grad_norm": 0.00014361263311002403,
      "learning_rate": 7.668131004678739e-06,
      "loss": 0.0802,
      "step": 86320
    },
    {
      "epoch": 9.249973213329048,
      "grad_norm": 0.017656559124588966,
      "learning_rate": 7.666702382227937e-06,
      "loss": 0.0001,
      "step": 86330
    },
    {
      "epoch": 9.25104468016715,
      "grad_norm": 0.0002001854300033301,
      "learning_rate": 7.665273759777136e-06,
      "loss": 0.1005,
      "step": 86340
    },
    {
      "epoch": 9.25211614700525,
      "grad_norm": 0.003906744997948408,
      "learning_rate": 7.663845137326334e-06,
      "loss": 0.0213,
      "step": 86350
    },
    {
      "epoch": 9.253187613843352,
      "grad_norm": 0.00012765094288624823,
      "learning_rate": 7.662416514875531e-06,
      "loss": 0.0,
      "step": 86360
    },
    {
      "epoch": 9.254259080681454,
      "grad_norm": 0.0002034875360550359,
      "learning_rate": 7.66098789242473e-06,
      "loss": 0.0002,
      "step": 86370
    },
    {
      "epoch": 9.255330547519554,
      "grad_norm": 0.0006569587276317179,
      "learning_rate": 7.659559269973928e-06,
      "loss": 0.17,
      "step": 86380
    },
    {
      "epoch": 9.256402014357656,
      "grad_norm": 0.00016884096839930862,
      "learning_rate": 7.658130647523126e-06,
      "loss": 0.0,
      "step": 86390
    },
    {
      "epoch": 9.257473481195756,
      "grad_norm": 0.0059082359075546265,
      "learning_rate": 7.656702025072324e-06,
      "loss": 0.0001,
      "step": 86400
    },
    {
      "epoch": 9.258544948033858,
      "grad_norm": 0.0015991982072591782,
      "learning_rate": 7.655273402621523e-06,
      "loss": 0.0009,
      "step": 86410
    },
    {
      "epoch": 9.25961641487196,
      "grad_norm": 3.7440836429595947,
      "learning_rate": 7.653844780170721e-06,
      "loss": 0.0022,
      "step": 86420
    },
    {
      "epoch": 9.26068788171006,
      "grad_norm": 0.0001569081941852346,
      "learning_rate": 7.65241615771992e-06,
      "loss": 0.0,
      "step": 86430
    },
    {
      "epoch": 9.261759348548162,
      "grad_norm": 0.0001333083346253261,
      "learning_rate": 7.650987535269118e-06,
      "loss": 0.0,
      "step": 86440
    },
    {
      "epoch": 9.262830815386264,
      "grad_norm": 0.00017760983610060066,
      "learning_rate": 7.649558912818316e-06,
      "loss": 0.0,
      "step": 86450
    },
    {
      "epoch": 9.263902282224365,
      "grad_norm": 3.575016736984253,
      "learning_rate": 7.648130290367513e-06,
      "loss": 0.0544,
      "step": 86460
    },
    {
      "epoch": 9.264973749062467,
      "grad_norm": 0.0021925345063209534,
      "learning_rate": 7.646701667916711e-06,
      "loss": 0.0963,
      "step": 86470
    },
    {
      "epoch": 9.266045215900569,
      "grad_norm": 0.0004269519413355738,
      "learning_rate": 7.64527304546591e-06,
      "loss": 0.0032,
      "step": 86480
    },
    {
      "epoch": 9.267116682738669,
      "grad_norm": 0.00013062311336398125,
      "learning_rate": 7.643844423015108e-06,
      "loss": 0.0,
      "step": 86490
    },
    {
      "epoch": 9.26818814957677,
      "grad_norm": 0.0003055979614146054,
      "learning_rate": 7.642415800564307e-06,
      "loss": 0.0001,
      "step": 86500
    },
    {
      "epoch": 9.269259616414871,
      "grad_norm": 0.0009827041067183018,
      "learning_rate": 7.640987178113505e-06,
      "loss": 0.0006,
      "step": 86510
    },
    {
      "epoch": 9.270331083252973,
      "grad_norm": 0.0006234791944734752,
      "learning_rate": 7.639558555662703e-06,
      "loss": 0.0,
      "step": 86520
    },
    {
      "epoch": 9.271402550091075,
      "grad_norm": 0.32749518752098083,
      "learning_rate": 7.6381299332119e-06,
      "loss": 0.1287,
      "step": 86530
    },
    {
      "epoch": 9.272474016929175,
      "grad_norm": 0.0007376912981271744,
      "learning_rate": 7.636701310761098e-06,
      "loss": 0.0,
      "step": 86540
    },
    {
      "epoch": 9.273545483767277,
      "grad_norm": 0.00010783062316477299,
      "learning_rate": 7.635272688310297e-06,
      "loss": 0.0002,
      "step": 86550
    },
    {
      "epoch": 9.27461695060538,
      "grad_norm": 0.00023579316621180624,
      "learning_rate": 7.633844065859495e-06,
      "loss": 0.2008,
      "step": 86560
    },
    {
      "epoch": 9.27568841744348,
      "grad_norm": 9.955996210919693e-05,
      "learning_rate": 7.632415443408694e-06,
      "loss": 0.001,
      "step": 86570
    },
    {
      "epoch": 9.276759884281581,
      "grad_norm": 0.00018414953956380486,
      "learning_rate": 7.630986820957892e-06,
      "loss": 0.0,
      "step": 86580
    },
    {
      "epoch": 9.277831351119683,
      "grad_norm": 7.59736867621541e-05,
      "learning_rate": 7.62955819850709e-06,
      "loss": 0.0001,
      "step": 86590
    },
    {
      "epoch": 9.278902817957784,
      "grad_norm": 0.00016029112157411873,
      "learning_rate": 7.628129576056288e-06,
      "loss": 0.0007,
      "step": 86600
    },
    {
      "epoch": 9.279974284795886,
      "grad_norm": 0.00018005701713263988,
      "learning_rate": 7.626700953605487e-06,
      "loss": 0.0001,
      "step": 86610
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 0.002620808081701398,
      "learning_rate": 7.625272331154685e-06,
      "loss": 0.0002,
      "step": 86620
    },
    {
      "epoch": 9.282117218472088,
      "grad_norm": 0.0001779173471732065,
      "learning_rate": 7.623843708703883e-06,
      "loss": 0.0,
      "step": 86630
    },
    {
      "epoch": 9.28318868531019,
      "grad_norm": 0.00011131350038340315,
      "learning_rate": 7.622415086253081e-06,
      "loss": 0.1432,
      "step": 86640
    },
    {
      "epoch": 9.284260152148292,
      "grad_norm": 0.00048816337948665023,
      "learning_rate": 7.620986463802279e-06,
      "loss": 0.0,
      "step": 86650
    },
    {
      "epoch": 9.285331618986392,
      "grad_norm": 0.0002473378845024854,
      "learning_rate": 7.619557841351477e-06,
      "loss": 0.0,
      "step": 86660
    },
    {
      "epoch": 9.286403085824494,
      "grad_norm": 0.00012594957661349326,
      "learning_rate": 7.618129218900676e-06,
      "loss": 0.0,
      "step": 86670
    },
    {
      "epoch": 9.287474552662594,
      "grad_norm": 0.00016677069652359933,
      "learning_rate": 7.616700596449874e-06,
      "loss": 0.0,
      "step": 86680
    },
    {
      "epoch": 9.288546019500696,
      "grad_norm": 0.00028098042821511626,
      "learning_rate": 7.6152719739990724e-06,
      "loss": 0.0,
      "step": 86690
    },
    {
      "epoch": 9.289617486338798,
      "grad_norm": 0.002488234778866172,
      "learning_rate": 7.61384335154827e-06,
      "loss": 0.0002,
      "step": 86700
    },
    {
      "epoch": 9.290688953176899,
      "grad_norm": 0.0002214263513451442,
      "learning_rate": 7.612414729097468e-06,
      "loss": 0.0,
      "step": 86710
    },
    {
      "epoch": 9.291760420015,
      "grad_norm": 0.001489634858444333,
      "learning_rate": 7.610986106646666e-06,
      "loss": 0.0005,
      "step": 86720
    },
    {
      "epoch": 9.292831886853103,
      "grad_norm": 0.00010242671123705804,
      "learning_rate": 7.609557484195866e-06,
      "loss": 0.0,
      "step": 86730
    },
    {
      "epoch": 9.293903353691203,
      "grad_norm": 0.0007132557802833617,
      "learning_rate": 7.608128861745063e-06,
      "loss": 0.0,
      "step": 86740
    },
    {
      "epoch": 9.294974820529305,
      "grad_norm": 0.00018947693752124906,
      "learning_rate": 7.606700239294261e-06,
      "loss": 0.1641,
      "step": 86750
    },
    {
      "epoch": 9.296046287367407,
      "grad_norm": 9.173974103759974e-05,
      "learning_rate": 7.6052716168434595e-06,
      "loss": 0.0,
      "step": 86760
    },
    {
      "epoch": 9.297117754205507,
      "grad_norm": 0.0004649003967642784,
      "learning_rate": 7.603842994392657e-06,
      "loss": 0.0,
      "step": 86770
    },
    {
      "epoch": 9.298189221043609,
      "grad_norm": 0.0006019354332238436,
      "learning_rate": 7.602414371941855e-06,
      "loss": 0.1224,
      "step": 86780
    },
    {
      "epoch": 9.29926068788171,
      "grad_norm": 9.386301098857075e-05,
      "learning_rate": 7.600985749491054e-06,
      "loss": 0.1663,
      "step": 86790
    },
    {
      "epoch": 9.300332154719811,
      "grad_norm": 0.00011057101073674858,
      "learning_rate": 7.599557127040253e-06,
      "loss": 0.0,
      "step": 86800
    },
    {
      "epoch": 9.301403621557913,
      "grad_norm": 0.00019287191389594227,
      "learning_rate": 7.5981285045894504e-06,
      "loss": 0.0,
      "step": 86810
    },
    {
      "epoch": 9.302475088396013,
      "grad_norm": 0.4219362139701843,
      "learning_rate": 7.596699882138648e-06,
      "loss": 0.0032,
      "step": 86820
    },
    {
      "epoch": 9.303546555234115,
      "grad_norm": 0.0023410820867866278,
      "learning_rate": 7.595271259687847e-06,
      "loss": 0.0,
      "step": 86830
    },
    {
      "epoch": 9.304618022072217,
      "grad_norm": 0.001589325605891645,
      "learning_rate": 7.593842637237044e-06,
      "loss": 0.0001,
      "step": 86840
    },
    {
      "epoch": 9.305689488910318,
      "grad_norm": 0.0002431868779240176,
      "learning_rate": 7.592414014786244e-06,
      "loss": 0.0,
      "step": 86850
    },
    {
      "epoch": 9.30676095574842,
      "grad_norm": 0.00010265081800753251,
      "learning_rate": 7.590985392335441e-06,
      "loss": 0.0,
      "step": 86860
    },
    {
      "epoch": 9.307832422586522,
      "grad_norm": 0.08012309670448303,
      "learning_rate": 7.58955676988464e-06,
      "loss": 0.0,
      "step": 86870
    },
    {
      "epoch": 9.308903889424622,
      "grad_norm": 9.574009891366586e-05,
      "learning_rate": 7.5881281474338375e-06,
      "loss": 0.2405,
      "step": 86880
    },
    {
      "epoch": 9.309975356262724,
      "grad_norm": 8.110344060696661e-05,
      "learning_rate": 7.586699524983035e-06,
      "loss": 0.0012,
      "step": 86890
    },
    {
      "epoch": 9.311046823100826,
      "grad_norm": 7.850309339119121e-05,
      "learning_rate": 7.585270902532234e-06,
      "loss": 0.1718,
      "step": 86900
    },
    {
      "epoch": 9.312118289938926,
      "grad_norm": 0.00010147102875635028,
      "learning_rate": 7.583842280081432e-06,
      "loss": 0.0641,
      "step": 86910
    },
    {
      "epoch": 9.313189756777028,
      "grad_norm": 9.593791037332267e-05,
      "learning_rate": 7.582413657630631e-06,
      "loss": 0.2242,
      "step": 86920
    },
    {
      "epoch": 9.314261223615128,
      "grad_norm": 0.00015919898578431457,
      "learning_rate": 7.5809850351798284e-06,
      "loss": 0.0,
      "step": 86930
    },
    {
      "epoch": 9.31533269045323,
      "grad_norm": 0.00015464142779819667,
      "learning_rate": 7.579556412729027e-06,
      "loss": 0.0001,
      "step": 86940
    },
    {
      "epoch": 9.316404157291332,
      "grad_norm": 0.0003682842361740768,
      "learning_rate": 7.578127790278225e-06,
      "loss": 0.0,
      "step": 86950
    },
    {
      "epoch": 9.317475624129433,
      "grad_norm": 0.0030186944641172886,
      "learning_rate": 7.576699167827422e-06,
      "loss": 0.0,
      "step": 86960
    },
    {
      "epoch": 9.318547090967535,
      "grad_norm": 0.00010869058314710855,
      "learning_rate": 7.575270545376622e-06,
      "loss": 0.002,
      "step": 86970
    },
    {
      "epoch": 9.319618557805637,
      "grad_norm": 8.211160456994548e-05,
      "learning_rate": 7.57384192292582e-06,
      "loss": 0.0,
      "step": 86980
    },
    {
      "epoch": 9.320690024643737,
      "grad_norm": 1.569205641746521,
      "learning_rate": 7.572413300475018e-06,
      "loss": 0.0001,
      "step": 86990
    },
    {
      "epoch": 9.321761491481839,
      "grad_norm": 0.0017388598062098026,
      "learning_rate": 7.5709846780242155e-06,
      "loss": 0.0,
      "step": 87000
    },
    {
      "epoch": 9.32283295831994,
      "grad_norm": 0.0001156436264864169,
      "learning_rate": 7.569556055573414e-06,
      "loss": 0.1727,
      "step": 87010
    },
    {
      "epoch": 9.323904425158041,
      "grad_norm": 9.567242523189634e-05,
      "learning_rate": 7.568127433122612e-06,
      "loss": 0.0,
      "step": 87020
    },
    {
      "epoch": 9.324975891996143,
      "grad_norm": 0.001581275719217956,
      "learning_rate": 7.566698810671809e-06,
      "loss": 0.4941,
      "step": 87030
    },
    {
      "epoch": 9.326047358834245,
      "grad_norm": 0.1362946629524231,
      "learning_rate": 7.565270188221009e-06,
      "loss": 0.3487,
      "step": 87040
    },
    {
      "epoch": 9.327118825672345,
      "grad_norm": 0.021063383668661118,
      "learning_rate": 7.563841565770207e-06,
      "loss": 0.0728,
      "step": 87050
    },
    {
      "epoch": 9.328190292510447,
      "grad_norm": 0.002152032218873501,
      "learning_rate": 7.562412943319405e-06,
      "loss": 0.0003,
      "step": 87060
    },
    {
      "epoch": 9.329261759348547,
      "grad_norm": 0.05534232035279274,
      "learning_rate": 7.560984320868603e-06,
      "loss": 0.0002,
      "step": 87070
    },
    {
      "epoch": 9.33033322618665,
      "grad_norm": 0.0031398762948811054,
      "learning_rate": 7.559555698417801e-06,
      "loss": 0.0001,
      "step": 87080
    },
    {
      "epoch": 9.331404693024751,
      "grad_norm": 0.0005685128271579742,
      "learning_rate": 7.558127075966999e-06,
      "loss": 0.0,
      "step": 87090
    },
    {
      "epoch": 9.332476159862852,
      "grad_norm": 0.002140733413398266,
      "learning_rate": 7.556698453516198e-06,
      "loss": 0.0001,
      "step": 87100
    },
    {
      "epoch": 9.333547626700954,
      "grad_norm": 0.0005445164279080927,
      "learning_rate": 7.555269831065396e-06,
      "loss": 0.0005,
      "step": 87110
    },
    {
      "epoch": 9.334619093539056,
      "grad_norm": 0.0030156143475323915,
      "learning_rate": 7.553841208614594e-06,
      "loss": 0.0003,
      "step": 87120
    },
    {
      "epoch": 9.335690560377156,
      "grad_norm": 0.0002730008272919804,
      "learning_rate": 7.552412586163792e-06,
      "loss": 0.0003,
      "step": 87130
    },
    {
      "epoch": 9.336762027215258,
      "grad_norm": 0.0002893713244702667,
      "learning_rate": 7.55098396371299e-06,
      "loss": 0.0001,
      "step": 87140
    },
    {
      "epoch": 9.33783349405336,
      "grad_norm": 0.000426722428528592,
      "learning_rate": 7.549555341262188e-06,
      "loss": 0.0002,
      "step": 87150
    },
    {
      "epoch": 9.33890496089146,
      "grad_norm": 0.0008249111124314368,
      "learning_rate": 7.548126718811387e-06,
      "loss": 0.1436,
      "step": 87160
    },
    {
      "epoch": 9.339976427729562,
      "grad_norm": 0.002864842303097248,
      "learning_rate": 7.546698096360585e-06,
      "loss": 0.0005,
      "step": 87170
    },
    {
      "epoch": 9.341047894567662,
      "grad_norm": 0.10809407383203506,
      "learning_rate": 7.545269473909783e-06,
      "loss": 0.0006,
      "step": 87180
    },
    {
      "epoch": 9.342119361405764,
      "grad_norm": 0.0015660441713407636,
      "learning_rate": 7.5438408514589815e-06,
      "loss": 0.0011,
      "step": 87190
    },
    {
      "epoch": 9.343190828243866,
      "grad_norm": 0.0004934804746881127,
      "learning_rate": 7.542412229008179e-06,
      "loss": 0.0006,
      "step": 87200
    },
    {
      "epoch": 9.344262295081966,
      "grad_norm": 0.00023492857872042805,
      "learning_rate": 7.540983606557377e-06,
      "loss": 0.0004,
      "step": 87210
    },
    {
      "epoch": 9.345333761920068,
      "grad_norm": 0.0022731295321136713,
      "learning_rate": 7.539554984106576e-06,
      "loss": 0.0,
      "step": 87220
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 0.005718125496059656,
      "learning_rate": 7.538126361655774e-06,
      "loss": 0.0001,
      "step": 87230
    },
    {
      "epoch": 9.34747669559627,
      "grad_norm": 0.0007155698840506375,
      "learning_rate": 7.536697739204972e-06,
      "loss": 0.0004,
      "step": 87240
    },
    {
      "epoch": 9.348548162434373,
      "grad_norm": 0.00018890218052547425,
      "learning_rate": 7.53526911675417e-06,
      "loss": 0.0,
      "step": 87250
    },
    {
      "epoch": 9.349619629272475,
      "grad_norm": 0.00021390104666352272,
      "learning_rate": 7.5338404943033686e-06,
      "loss": 0.0,
      "step": 87260
    },
    {
      "epoch": 9.350691096110575,
      "grad_norm": 0.00030595282441936433,
      "learning_rate": 7.532411871852566e-06,
      "loss": 0.1272,
      "step": 87270
    },
    {
      "epoch": 9.351762562948677,
      "grad_norm": 0.0006604712107218802,
      "learning_rate": 7.530983249401766e-06,
      "loss": 0.0,
      "step": 87280
    },
    {
      "epoch": 9.352834029786779,
      "grad_norm": 0.0004483778902795166,
      "learning_rate": 7.529554626950963e-06,
      "loss": 0.0,
      "step": 87290
    },
    {
      "epoch": 9.35390549662488,
      "grad_norm": 0.00022156970226205885,
      "learning_rate": 7.528126004500162e-06,
      "loss": 0.1891,
      "step": 87300
    },
    {
      "epoch": 9.354976963462981,
      "grad_norm": 0.0010371791431680322,
      "learning_rate": 7.5266973820493595e-06,
      "loss": 0.0,
      "step": 87310
    },
    {
      "epoch": 9.356048430301081,
      "grad_norm": 0.02174621820449829,
      "learning_rate": 7.525268759598557e-06,
      "loss": 0.0,
      "step": 87320
    },
    {
      "epoch": 9.357119897139183,
      "grad_norm": 0.00028032303089275956,
      "learning_rate": 7.523840137147756e-06,
      "loss": 0.0,
      "step": 87330
    },
    {
      "epoch": 9.358191363977285,
      "grad_norm": 0.00026857946068048477,
      "learning_rate": 7.522411514696954e-06,
      "loss": 0.0,
      "step": 87340
    },
    {
      "epoch": 9.359262830815386,
      "grad_norm": 0.0004793065309058875,
      "learning_rate": 7.520982892246153e-06,
      "loss": 0.0002,
      "step": 87350
    },
    {
      "epoch": 9.360334297653488,
      "grad_norm": 0.00036108758649788797,
      "learning_rate": 7.51955426979535e-06,
      "loss": 0.0,
      "step": 87360
    },
    {
      "epoch": 9.36140576449159,
      "grad_norm": 0.0005570134380832314,
      "learning_rate": 7.518125647344549e-06,
      "loss": 0.0001,
      "step": 87370
    },
    {
      "epoch": 9.36247723132969,
      "grad_norm": 0.003721721703186631,
      "learning_rate": 7.5166970248937466e-06,
      "loss": 0.3363,
      "step": 87380
    },
    {
      "epoch": 9.363548698167792,
      "grad_norm": 0.07458719611167908,
      "learning_rate": 7.515268402442944e-06,
      "loss": 0.0001,
      "step": 87390
    },
    {
      "epoch": 9.364620165005894,
      "grad_norm": 0.001292916713282466,
      "learning_rate": 7.513839779992144e-06,
      "loss": 0.0,
      "step": 87400
    },
    {
      "epoch": 9.365691631843994,
      "grad_norm": 0.002371168928220868,
      "learning_rate": 7.512411157541341e-06,
      "loss": 0.0001,
      "step": 87410
    },
    {
      "epoch": 9.366763098682096,
      "grad_norm": 0.001474703778512776,
      "learning_rate": 7.51098253509054e-06,
      "loss": 0.0001,
      "step": 87420
    },
    {
      "epoch": 9.367834565520198,
      "grad_norm": 0.0013723690062761307,
      "learning_rate": 7.5095539126397375e-06,
      "loss": 0.0,
      "step": 87430
    },
    {
      "epoch": 9.368906032358298,
      "grad_norm": 0.0004032861324958503,
      "learning_rate": 7.508125290188936e-06,
      "loss": 0.0,
      "step": 87440
    },
    {
      "epoch": 9.3699774991964,
      "grad_norm": 0.00025774730602279305,
      "learning_rate": 7.506696667738134e-06,
      "loss": 0.0003,
      "step": 87450
    },
    {
      "epoch": 9.3710489660345,
      "grad_norm": 0.0003656432090792805,
      "learning_rate": 7.505268045287333e-06,
      "loss": 0.0001,
      "step": 87460
    },
    {
      "epoch": 9.372120432872602,
      "grad_norm": 0.0014763964572921395,
      "learning_rate": 7.503839422836531e-06,
      "loss": 0.0001,
      "step": 87470
    },
    {
      "epoch": 9.373191899710704,
      "grad_norm": 0.0004277779080439359,
      "learning_rate": 7.502410800385728e-06,
      "loss": 0.0002,
      "step": 87480
    },
    {
      "epoch": 9.374263366548805,
      "grad_norm": 0.0003092861734330654,
      "learning_rate": 7.500982177934927e-06,
      "loss": 0.0,
      "step": 87490
    },
    {
      "epoch": 9.375334833386907,
      "grad_norm": 0.0003725108690559864,
      "learning_rate": 7.4995535554841246e-06,
      "loss": 0.0,
      "step": 87500
    },
    {
      "epoch": 9.376406300225009,
      "grad_norm": 0.00023056744248606265,
      "learning_rate": 7.498124933033323e-06,
      "loss": 0.0037,
      "step": 87510
    },
    {
      "epoch": 9.377477767063109,
      "grad_norm": 0.000474605243653059,
      "learning_rate": 7.496696310582522e-06,
      "loss": 0.0,
      "step": 87520
    },
    {
      "epoch": 9.37854923390121,
      "grad_norm": 0.0004697902768384665,
      "learning_rate": 7.49526768813172e-06,
      "loss": 0.0,
      "step": 87530
    },
    {
      "epoch": 9.379620700739313,
      "grad_norm": 0.002236866159364581,
      "learning_rate": 7.493839065680918e-06,
      "loss": 0.0001,
      "step": 87540
    },
    {
      "epoch": 9.380692167577413,
      "grad_norm": 0.0005538947880268097,
      "learning_rate": 7.492410443230116e-06,
      "loss": 0.1804,
      "step": 87550
    },
    {
      "epoch": 9.381763634415515,
      "grad_norm": 0.00719679007306695,
      "learning_rate": 7.490981820779314e-06,
      "loss": 0.0001,
      "step": 87560
    },
    {
      "epoch": 9.382835101253615,
      "grad_norm": 0.0027008894830942154,
      "learning_rate": 7.489553198328512e-06,
      "loss": 0.0,
      "step": 87570
    },
    {
      "epoch": 9.383906568091717,
      "grad_norm": 0.00044117963989265263,
      "learning_rate": 7.488124575877711e-06,
      "loss": 0.1926,
      "step": 87580
    },
    {
      "epoch": 9.38497803492982,
      "grad_norm": 0.0006320400279946625,
      "learning_rate": 7.486695953426909e-06,
      "loss": 0.0,
      "step": 87590
    },
    {
      "epoch": 9.38604950176792,
      "grad_norm": 0.003364366013556719,
      "learning_rate": 7.485267330976107e-06,
      "loss": 0.0019,
      "step": 87600
    },
    {
      "epoch": 9.387120968606022,
      "grad_norm": 0.005043076351284981,
      "learning_rate": 7.483838708525305e-06,
      "loss": 0.0,
      "step": 87610
    },
    {
      "epoch": 9.388192435444124,
      "grad_norm": 0.0006484671030193567,
      "learning_rate": 7.482410086074503e-06,
      "loss": 0.0,
      "step": 87620
    },
    {
      "epoch": 9.389263902282224,
      "grad_norm": 0.000333931646309793,
      "learning_rate": 7.480981463623701e-06,
      "loss": 0.0,
      "step": 87630
    },
    {
      "epoch": 9.390335369120326,
      "grad_norm": 0.0007410243852064013,
      "learning_rate": 7.4795528411729005e-06,
      "loss": 0.0064,
      "step": 87640
    },
    {
      "epoch": 9.391406835958428,
      "grad_norm": 0.03254597634077072,
      "learning_rate": 7.478124218722098e-06,
      "loss": 0.0,
      "step": 87650
    },
    {
      "epoch": 9.392478302796528,
      "grad_norm": 0.022067973390221596,
      "learning_rate": 7.476695596271296e-06,
      "loss": 0.0,
      "step": 87660
    },
    {
      "epoch": 9.39354976963463,
      "grad_norm": 0.00027632652199827135,
      "learning_rate": 7.475266973820494e-06,
      "loss": 0.0,
      "step": 87670
    },
    {
      "epoch": 9.394621236472732,
      "grad_norm": 0.0003748861781787127,
      "learning_rate": 7.473838351369692e-06,
      "loss": 0.0983,
      "step": 87680
    },
    {
      "epoch": 9.395692703310832,
      "grad_norm": 0.00048635544953867793,
      "learning_rate": 7.4724097289188905e-06,
      "loss": 0.0,
      "step": 87690
    },
    {
      "epoch": 9.396764170148934,
      "grad_norm": 0.0017463573021814227,
      "learning_rate": 7.470981106468089e-06,
      "loss": 0.0002,
      "step": 87700
    },
    {
      "epoch": 9.397835636987034,
      "grad_norm": 0.00014104359433986247,
      "learning_rate": 7.4695524840172875e-06,
      "loss": 0.0002,
      "step": 87710
    },
    {
      "epoch": 9.398907103825136,
      "grad_norm": 0.0003432595985941589,
      "learning_rate": 7.468123861566485e-06,
      "loss": 0.0001,
      "step": 87720
    },
    {
      "epoch": 9.399978570663238,
      "grad_norm": 0.000711386208422482,
      "learning_rate": 7.466695239115683e-06,
      "loss": 0.0003,
      "step": 87730
    },
    {
      "epoch": 9.401050037501339,
      "grad_norm": 0.00041437576874159276,
      "learning_rate": 7.465266616664881e-06,
      "loss": 0.0,
      "step": 87740
    },
    {
      "epoch": 9.40212150433944,
      "grad_norm": 0.002191298408433795,
      "learning_rate": 7.463837994214079e-06,
      "loss": 0.0016,
      "step": 87750
    },
    {
      "epoch": 9.403192971177543,
      "grad_norm": 0.004152009263634682,
      "learning_rate": 7.4624093717632785e-06,
      "loss": 0.0011,
      "step": 87760
    },
    {
      "epoch": 9.404264438015643,
      "grad_norm": 0.00025556140462867916,
      "learning_rate": 7.460980749312476e-06,
      "loss": 0.0,
      "step": 87770
    },
    {
      "epoch": 9.405335904853745,
      "grad_norm": 0.0013810310047119856,
      "learning_rate": 7.459552126861675e-06,
      "loss": 0.0004,
      "step": 87780
    },
    {
      "epoch": 9.406407371691847,
      "grad_norm": 0.00600942550227046,
      "learning_rate": 7.458123504410872e-06,
      "loss": 0.2485,
      "step": 87790
    },
    {
      "epoch": 9.407478838529947,
      "grad_norm": 0.00013919251796323806,
      "learning_rate": 7.45669488196007e-06,
      "loss": 0.0,
      "step": 87800
    },
    {
      "epoch": 9.408550305368049,
      "grad_norm": 0.0007606142316944897,
      "learning_rate": 7.4552662595092685e-06,
      "loss": 0.0004,
      "step": 87810
    },
    {
      "epoch": 9.409621772206151,
      "grad_norm": 0.0009421327849850059,
      "learning_rate": 7.453837637058468e-06,
      "loss": 0.0,
      "step": 87820
    },
    {
      "epoch": 9.410693239044251,
      "grad_norm": 0.0002722846111282706,
      "learning_rate": 7.4524090146076655e-06,
      "loss": 0.2647,
      "step": 87830
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 0.00019027164671570063,
      "learning_rate": 7.450980392156863e-06,
      "loss": 0.0,
      "step": 87840
    },
    {
      "epoch": 9.412836172720453,
      "grad_norm": 0.0011149040656164289,
      "learning_rate": 7.449551769706062e-06,
      "loss": 0.0,
      "step": 87850
    },
    {
      "epoch": 9.413907639558555,
      "grad_norm": 0.0015872686635702848,
      "learning_rate": 7.448123147255259e-06,
      "loss": 0.0,
      "step": 87860
    },
    {
      "epoch": 9.414979106396657,
      "grad_norm": 0.0003260953526478261,
      "learning_rate": 7.446694524804458e-06,
      "loss": 0.0,
      "step": 87870
    },
    {
      "epoch": 9.416050573234758,
      "grad_norm": 0.0005821459926664829,
      "learning_rate": 7.4452659023536565e-06,
      "loss": 0.1291,
      "step": 87880
    },
    {
      "epoch": 9.41712204007286,
      "grad_norm": 0.0006440783618018031,
      "learning_rate": 7.443837279902855e-06,
      "loss": 0.0003,
      "step": 87890
    },
    {
      "epoch": 9.418193506910962,
      "grad_norm": 0.0002957453252747655,
      "learning_rate": 7.442408657452053e-06,
      "loss": 0.0,
      "step": 87900
    },
    {
      "epoch": 9.419264973749062,
      "grad_norm": 0.0007207534508779645,
      "learning_rate": 7.44098003500125e-06,
      "loss": 0.0,
      "step": 87910
    },
    {
      "epoch": 9.420336440587164,
      "grad_norm": 0.00019968450942542404,
      "learning_rate": 7.439551412550449e-06,
      "loss": 0.0,
      "step": 87920
    },
    {
      "epoch": 9.421407907425266,
      "grad_norm": 0.0005145135801285505,
      "learning_rate": 7.4381227900996465e-06,
      "loss": 0.0,
      "step": 87930
    },
    {
      "epoch": 9.422479374263366,
      "grad_norm": 0.0008554795058444142,
      "learning_rate": 7.436694167648845e-06,
      "loss": 0.0,
      "step": 87940
    },
    {
      "epoch": 9.423550841101468,
      "grad_norm": 0.005051759537309408,
      "learning_rate": 7.4352655451980435e-06,
      "loss": 0.0,
      "step": 87950
    },
    {
      "epoch": 9.42462230793957,
      "grad_norm": 0.0002685029758140445,
      "learning_rate": 7.433836922747242e-06,
      "loss": 0.0001,
      "step": 87960
    },
    {
      "epoch": 9.42569377477767,
      "grad_norm": 0.00022882064513396472,
      "learning_rate": 7.43240830029644e-06,
      "loss": 0.0,
      "step": 87970
    },
    {
      "epoch": 9.426765241615772,
      "grad_norm": 0.006345176603645086,
      "learning_rate": 7.430979677845637e-06,
      "loss": 0.0001,
      "step": 87980
    },
    {
      "epoch": 9.427836708453873,
      "grad_norm": 0.0047902753576636314,
      "learning_rate": 7.429551055394836e-06,
      "loss": 0.0001,
      "step": 87990
    },
    {
      "epoch": 9.428908175291975,
      "grad_norm": 0.00193306605797261,
      "learning_rate": 7.428122432944034e-06,
      "loss": 0.0001,
      "step": 88000
    },
    {
      "epoch": 9.429979642130077,
      "grad_norm": 0.0011311630951240659,
      "learning_rate": 7.426693810493233e-06,
      "loss": 0.0,
      "step": 88010
    },
    {
      "epoch": 9.431051108968177,
      "grad_norm": 0.00011618358257692307,
      "learning_rate": 7.425265188042431e-06,
      "loss": 0.0,
      "step": 88020
    },
    {
      "epoch": 9.432122575806279,
      "grad_norm": 14.64209270477295,
      "learning_rate": 7.423836565591629e-06,
      "loss": 0.2098,
      "step": 88030
    },
    {
      "epoch": 9.43319404264438,
      "grad_norm": 0.05135292187333107,
      "learning_rate": 7.422407943140827e-06,
      "loss": 0.4066,
      "step": 88040
    },
    {
      "epoch": 9.434265509482481,
      "grad_norm": 0.000523769180290401,
      "learning_rate": 7.4209793206900245e-06,
      "loss": 0.0,
      "step": 88050
    },
    {
      "epoch": 9.435336976320583,
      "grad_norm": 0.004549070727080107,
      "learning_rate": 7.419550698239223e-06,
      "loss": 0.0,
      "step": 88060
    },
    {
      "epoch": 9.436408443158685,
      "grad_norm": 0.001121767912991345,
      "learning_rate": 7.418122075788422e-06,
      "loss": 0.0,
      "step": 88070
    },
    {
      "epoch": 9.437479909996785,
      "grad_norm": 0.003393528051674366,
      "learning_rate": 7.41669345333762e-06,
      "loss": 0.0002,
      "step": 88080
    },
    {
      "epoch": 9.438551376834887,
      "grad_norm": 0.0006468751234933734,
      "learning_rate": 7.415264830886818e-06,
      "loss": 0.0,
      "step": 88090
    },
    {
      "epoch": 9.43962284367299,
      "grad_norm": 0.0010642182314768434,
      "learning_rate": 7.413836208436016e-06,
      "loss": 0.0,
      "step": 88100
    },
    {
      "epoch": 9.44069431051109,
      "grad_norm": 0.000481289200251922,
      "learning_rate": 7.412407585985214e-06,
      "loss": 0.0006,
      "step": 88110
    },
    {
      "epoch": 9.441765777349191,
      "grad_norm": 0.0029509044252336025,
      "learning_rate": 7.4109789635344125e-06,
      "loss": 0.0,
      "step": 88120
    },
    {
      "epoch": 9.442837244187292,
      "grad_norm": 0.00038628390757367015,
      "learning_rate": 7.409550341083611e-06,
      "loss": 0.2346,
      "step": 88130
    },
    {
      "epoch": 9.443908711025394,
      "grad_norm": 0.0005134881939738989,
      "learning_rate": 7.4081217186328095e-06,
      "loss": 0.1489,
      "step": 88140
    },
    {
      "epoch": 9.444980177863496,
      "grad_norm": 0.0008282503113150597,
      "learning_rate": 7.406693096182007e-06,
      "loss": 0.0063,
      "step": 88150
    },
    {
      "epoch": 9.446051644701596,
      "grad_norm": 0.0022325506433844566,
      "learning_rate": 7.405264473731205e-06,
      "loss": 0.0001,
      "step": 88160
    },
    {
      "epoch": 9.447123111539698,
      "grad_norm": 0.00041118531953543425,
      "learning_rate": 7.403835851280403e-06,
      "loss": 0.0002,
      "step": 88170
    },
    {
      "epoch": 9.4481945783778,
      "grad_norm": 0.00017919046513270587,
      "learning_rate": 7.402407228829601e-06,
      "loss": 0.0,
      "step": 88180
    },
    {
      "epoch": 9.4492660452159,
      "grad_norm": 0.00016306864563375711,
      "learning_rate": 7.4009786063788e-06,
      "loss": 0.0,
      "step": 88190
    },
    {
      "epoch": 9.450337512054002,
      "grad_norm": 0.0014538716059178114,
      "learning_rate": 7.399549983927998e-06,
      "loss": 0.0,
      "step": 88200
    },
    {
      "epoch": 9.451408978892104,
      "grad_norm": 0.004165627993643284,
      "learning_rate": 7.398121361477197e-06,
      "loss": 0.0001,
      "step": 88210
    },
    {
      "epoch": 9.452480445730204,
      "grad_norm": 0.00018520433513913304,
      "learning_rate": 7.396692739026394e-06,
      "loss": 0.0,
      "step": 88220
    },
    {
      "epoch": 9.453551912568306,
      "grad_norm": 0.001563407015055418,
      "learning_rate": 7.395264116575592e-06,
      "loss": 0.0,
      "step": 88230
    },
    {
      "epoch": 9.454623379406407,
      "grad_norm": 0.000673629401717335,
      "learning_rate": 7.3938354941247905e-06,
      "loss": 0.0,
      "step": 88240
    },
    {
      "epoch": 9.455694846244509,
      "grad_norm": 0.0001774704287527129,
      "learning_rate": 7.39240687167399e-06,
      "loss": 0.0003,
      "step": 88250
    },
    {
      "epoch": 9.45676631308261,
      "grad_norm": 0.0007402265910059214,
      "learning_rate": 7.3909782492231875e-06,
      "loss": 0.0,
      "step": 88260
    },
    {
      "epoch": 9.45783777992071,
      "grad_norm": 0.0006208003615029156,
      "learning_rate": 7.389549626772385e-06,
      "loss": 0.257,
      "step": 88270
    },
    {
      "epoch": 9.458909246758813,
      "grad_norm": 0.0003300950338598341,
      "learning_rate": 7.388121004321584e-06,
      "loss": 0.0004,
      "step": 88280
    },
    {
      "epoch": 9.459980713596915,
      "grad_norm": 0.04775112867355347,
      "learning_rate": 7.386692381870781e-06,
      "loss": 0.318,
      "step": 88290
    },
    {
      "epoch": 9.461052180435015,
      "grad_norm": 0.008678165264427662,
      "learning_rate": 7.385263759419979e-06,
      "loss": 0.0001,
      "step": 88300
    },
    {
      "epoch": 9.462123647273117,
      "grad_norm": 0.00014093700156081468,
      "learning_rate": 7.383835136969178e-06,
      "loss": 0.0001,
      "step": 88310
    },
    {
      "epoch": 9.463195114111219,
      "grad_norm": 0.0002093161310767755,
      "learning_rate": 7.382406514518377e-06,
      "loss": 0.0003,
      "step": 88320
    },
    {
      "epoch": 9.46426658094932,
      "grad_norm": 0.0003668355057016015,
      "learning_rate": 7.380977892067575e-06,
      "loss": 0.2324,
      "step": 88330
    },
    {
      "epoch": 9.465338047787421,
      "grad_norm": 0.002131560817360878,
      "learning_rate": 7.379549269616772e-06,
      "loss": 0.0003,
      "step": 88340
    },
    {
      "epoch": 9.466409514625523,
      "grad_norm": 0.012975139543414116,
      "learning_rate": 7.378120647165971e-06,
      "loss": 0.0004,
      "step": 88350
    },
    {
      "epoch": 9.467480981463623,
      "grad_norm": 0.062241021543741226,
      "learning_rate": 7.3766920247151685e-06,
      "loss": 0.0003,
      "step": 88360
    },
    {
      "epoch": 9.468552448301725,
      "grad_norm": 0.001251204521395266,
      "learning_rate": 7.375263402264368e-06,
      "loss": 0.0001,
      "step": 88370
    },
    {
      "epoch": 9.469623915139826,
      "grad_norm": 0.00036751723382622004,
      "learning_rate": 7.3738347798135655e-06,
      "loss": 0.0003,
      "step": 88380
    },
    {
      "epoch": 9.470695381977928,
      "grad_norm": 0.04944019392132759,
      "learning_rate": 7.372406157362764e-06,
      "loss": 0.0001,
      "step": 88390
    },
    {
      "epoch": 9.47176684881603,
      "grad_norm": 0.001435616402886808,
      "learning_rate": 7.370977534911962e-06,
      "loss": 0.0001,
      "step": 88400
    },
    {
      "epoch": 9.47283831565413,
      "grad_norm": 0.00014786240353714675,
      "learning_rate": 7.369548912461159e-06,
      "loss": 0.108,
      "step": 88410
    },
    {
      "epoch": 9.473909782492232,
      "grad_norm": 0.004652401898056269,
      "learning_rate": 7.368120290010358e-06,
      "loss": 0.0919,
      "step": 88420
    },
    {
      "epoch": 9.474981249330334,
      "grad_norm": 0.0010769788641482592,
      "learning_rate": 7.366691667559556e-06,
      "loss": 0.0001,
      "step": 88430
    },
    {
      "epoch": 9.476052716168434,
      "grad_norm": 0.0001661209244048223,
      "learning_rate": 7.365263045108755e-06,
      "loss": 0.2072,
      "step": 88440
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 0.02888910286128521,
      "learning_rate": 7.363834422657953e-06,
      "loss": 0.1141,
      "step": 88450
    },
    {
      "epoch": 9.478195649844638,
      "grad_norm": 19.152393341064453,
      "learning_rate": 7.362405800207151e-06,
      "loss": 0.1778,
      "step": 88460
    },
    {
      "epoch": 9.479267116682738,
      "grad_norm": 0.01155031006783247,
      "learning_rate": 7.360977177756349e-06,
      "loss": 0.0001,
      "step": 88470
    },
    {
      "epoch": 9.48033858352084,
      "grad_norm": 0.1731555163860321,
      "learning_rate": 7.3595485553055464e-06,
      "loss": 0.0003,
      "step": 88480
    },
    {
      "epoch": 9.481410050358942,
      "grad_norm": 0.0004654236836358905,
      "learning_rate": 7.358119932854746e-06,
      "loss": 0.0003,
      "step": 88490
    },
    {
      "epoch": 9.482481517197042,
      "grad_norm": 0.004626913461834192,
      "learning_rate": 7.3566913104039435e-06,
      "loss": 0.0003,
      "step": 88500
    },
    {
      "epoch": 9.483552984035144,
      "grad_norm": 0.021014029160141945,
      "learning_rate": 7.355262687953142e-06,
      "loss": 0.0002,
      "step": 88510
    },
    {
      "epoch": 9.484624450873245,
      "grad_norm": 0.02238532528281212,
      "learning_rate": 7.35383406550234e-06,
      "loss": 0.0001,
      "step": 88520
    },
    {
      "epoch": 9.485695917711347,
      "grad_norm": 0.04006465524435043,
      "learning_rate": 7.352405443051538e-06,
      "loss": 0.0003,
      "step": 88530
    },
    {
      "epoch": 9.486767384549449,
      "grad_norm": 0.0003495491109788418,
      "learning_rate": 7.350976820600736e-06,
      "loss": 0.011,
      "step": 88540
    },
    {
      "epoch": 9.487838851387549,
      "grad_norm": 0.00036182443727739155,
      "learning_rate": 7.349548198149935e-06,
      "loss": 0.0,
      "step": 88550
    },
    {
      "epoch": 9.488910318225651,
      "grad_norm": 0.002041972940787673,
      "learning_rate": 7.348119575699133e-06,
      "loss": 0.0,
      "step": 88560
    },
    {
      "epoch": 9.489981785063753,
      "grad_norm": 0.0004119064542464912,
      "learning_rate": 7.3466909532483314e-06,
      "loss": 0.0,
      "step": 88570
    },
    {
      "epoch": 9.491053251901853,
      "grad_norm": 0.0030130483210086823,
      "learning_rate": 7.345262330797529e-06,
      "loss": 0.0,
      "step": 88580
    },
    {
      "epoch": 9.492124718739955,
      "grad_norm": 0.0001829132961574942,
      "learning_rate": 7.343833708346727e-06,
      "loss": 0.0,
      "step": 88590
    },
    {
      "epoch": 9.493196185578057,
      "grad_norm": 0.3330686390399933,
      "learning_rate": 7.342405085895925e-06,
      "loss": 0.1959,
      "step": 88600
    },
    {
      "epoch": 9.494267652416157,
      "grad_norm": 0.011476489715278149,
      "learning_rate": 7.340976463445124e-06,
      "loss": 0.0001,
      "step": 88610
    },
    {
      "epoch": 9.49533911925426,
      "grad_norm": 0.0009155742591246963,
      "learning_rate": 7.339547840994322e-06,
      "loss": 0.2264,
      "step": 88620
    },
    {
      "epoch": 9.49641058609236,
      "grad_norm": 0.00020662487077061087,
      "learning_rate": 7.33811921854352e-06,
      "loss": 0.0006,
      "step": 88630
    },
    {
      "epoch": 9.497482052930462,
      "grad_norm": 0.04016512259840965,
      "learning_rate": 7.3366905960927185e-06,
      "loss": 0.005,
      "step": 88640
    },
    {
      "epoch": 9.498553519768564,
      "grad_norm": 0.005279052071273327,
      "learning_rate": 7.335261973641916e-06,
      "loss": 0.0003,
      "step": 88650
    },
    {
      "epoch": 9.499624986606664,
      "grad_norm": 0.00013104674872010946,
      "learning_rate": 7.333833351191114e-06,
      "loss": 0.0,
      "step": 88660
    },
    {
      "epoch": 9.500696453444766,
      "grad_norm": 0.05341333523392677,
      "learning_rate": 7.332404728740313e-06,
      "loss": 0.0001,
      "step": 88670
    },
    {
      "epoch": 9.501767920282868,
      "grad_norm": 0.00031740308622829616,
      "learning_rate": 7.330976106289511e-06,
      "loss": 0.0027,
      "step": 88680
    },
    {
      "epoch": 9.502839387120968,
      "grad_norm": 0.00041079893708229065,
      "learning_rate": 7.3295474838387094e-06,
      "loss": 0.0006,
      "step": 88690
    },
    {
      "epoch": 9.50391085395907,
      "grad_norm": 0.0036647343076765537,
      "learning_rate": 7.328118861387907e-06,
      "loss": 0.0002,
      "step": 88700
    },
    {
      "epoch": 9.504982320797172,
      "grad_norm": 0.00022867697407491505,
      "learning_rate": 7.326690238937106e-06,
      "loss": 0.2062,
      "step": 88710
    },
    {
      "epoch": 9.506053787635272,
      "grad_norm": 0.0005420331726782024,
      "learning_rate": 7.325261616486303e-06,
      "loss": 0.0001,
      "step": 88720
    },
    {
      "epoch": 9.507125254473374,
      "grad_norm": 0.0024777506478130817,
      "learning_rate": 7.323832994035503e-06,
      "loss": 0.0,
      "step": 88730
    },
    {
      "epoch": 9.508196721311476,
      "grad_norm": 0.0006121114129200578,
      "learning_rate": 7.3224043715847e-06,
      "loss": 0.0001,
      "step": 88740
    },
    {
      "epoch": 9.509268188149576,
      "grad_norm": 0.0006550122052431107,
      "learning_rate": 7.320975749133898e-06,
      "loss": 0.2006,
      "step": 88750
    },
    {
      "epoch": 9.510339654987678,
      "grad_norm": 0.000590154028031975,
      "learning_rate": 7.3195471266830965e-06,
      "loss": 0.0002,
      "step": 88760
    },
    {
      "epoch": 9.51141112182578,
      "grad_norm": 0.007421996910125017,
      "learning_rate": 7.318118504232294e-06,
      "loss": 0.0,
      "step": 88770
    },
    {
      "epoch": 9.51248258866388,
      "grad_norm": 0.053751591593027115,
      "learning_rate": 7.316689881781493e-06,
      "loss": 0.0001,
      "step": 88780
    },
    {
      "epoch": 9.513554055501983,
      "grad_norm": 0.00017327528621535748,
      "learning_rate": 7.315261259330691e-06,
      "loss": 0.0001,
      "step": 88790
    },
    {
      "epoch": 9.514625522340083,
      "grad_norm": 0.0001518713979749009,
      "learning_rate": 7.31383263687989e-06,
      "loss": 0.0003,
      "step": 88800
    },
    {
      "epoch": 9.515696989178185,
      "grad_norm": 0.0005576311377808452,
      "learning_rate": 7.3124040144290874e-06,
      "loss": 0.0,
      "step": 88810
    },
    {
      "epoch": 9.516768456016287,
      "grad_norm": 0.09751240909099579,
      "learning_rate": 7.310975391978286e-06,
      "loss": 0.0002,
      "step": 88820
    },
    {
      "epoch": 9.517839922854387,
      "grad_norm": 0.00015842562424950302,
      "learning_rate": 7.309546769527484e-06,
      "loss": 0.0007,
      "step": 88830
    },
    {
      "epoch": 9.518911389692489,
      "grad_norm": 0.00020512986520770937,
      "learning_rate": 7.308118147076681e-06,
      "loss": 0.3965,
      "step": 88840
    },
    {
      "epoch": 9.519982856530591,
      "grad_norm": 0.0005753607838414609,
      "learning_rate": 7.30668952462588e-06,
      "loss": 0.0,
      "step": 88850
    },
    {
      "epoch": 9.521054323368691,
      "grad_norm": 0.000202987328520976,
      "learning_rate": 7.305260902175078e-06,
      "loss": 0.0001,
      "step": 88860
    },
    {
      "epoch": 9.522125790206793,
      "grad_norm": 0.0014324712101370096,
      "learning_rate": 7.303832279724277e-06,
      "loss": 0.1067,
      "step": 88870
    },
    {
      "epoch": 9.523197257044895,
      "grad_norm": 0.000813175633084029,
      "learning_rate": 7.3024036572734745e-06,
      "loss": 0.1877,
      "step": 88880
    },
    {
      "epoch": 9.524268723882996,
      "grad_norm": 0.006261641159653664,
      "learning_rate": 7.300975034822673e-06,
      "loss": 0.0002,
      "step": 88890
    },
    {
      "epoch": 9.525340190721097,
      "grad_norm": 0.0001813674025470391,
      "learning_rate": 7.299546412371871e-06,
      "loss": 0.0,
      "step": 88900
    },
    {
      "epoch": 9.526411657559198,
      "grad_norm": 0.0019433405250310898,
      "learning_rate": 7.298117789921068e-06,
      "loss": 0.0,
      "step": 88910
    },
    {
      "epoch": 9.5274831243973,
      "grad_norm": 0.17147693037986755,
      "learning_rate": 7.296689167470268e-06,
      "loss": 0.0003,
      "step": 88920
    },
    {
      "epoch": 9.528554591235402,
      "grad_norm": 0.006401293445378542,
      "learning_rate": 7.2952605450194654e-06,
      "loss": 0.0,
      "step": 88930
    },
    {
      "epoch": 9.529626058073502,
      "grad_norm": 0.00011974999506492168,
      "learning_rate": 7.293831922568664e-06,
      "loss": 0.0,
      "step": 88940
    },
    {
      "epoch": 9.530697524911604,
      "grad_norm": 0.00011858661309815943,
      "learning_rate": 7.292403300117862e-06,
      "loss": 0.0001,
      "step": 88950
    },
    {
      "epoch": 9.531768991749706,
      "grad_norm": 0.001751593081280589,
      "learning_rate": 7.29097467766706e-06,
      "loss": 0.0003,
      "step": 88960
    },
    {
      "epoch": 9.532840458587806,
      "grad_norm": 0.00011951028136536479,
      "learning_rate": 7.289546055216258e-06,
      "loss": 0.0,
      "step": 88970
    },
    {
      "epoch": 9.533911925425908,
      "grad_norm": 0.04239601641893387,
      "learning_rate": 7.288117432765457e-06,
      "loss": 0.0001,
      "step": 88980
    },
    {
      "epoch": 9.53498339226401,
      "grad_norm": 0.0007500870269723237,
      "learning_rate": 7.286688810314655e-06,
      "loss": 0.2216,
      "step": 88990
    },
    {
      "epoch": 9.53605485910211,
      "grad_norm": 0.00011458786320872605,
      "learning_rate": 7.2852601878638525e-06,
      "loss": 0.0002,
      "step": 89000
    },
    {
      "epoch": 9.537126325940212,
      "grad_norm": 0.05215423181653023,
      "learning_rate": 7.283831565413051e-06,
      "loss": 0.0001,
      "step": 89010
    },
    {
      "epoch": 9.538197792778313,
      "grad_norm": 0.0001212959541589953,
      "learning_rate": 7.282402942962249e-06,
      "loss": 0.0003,
      "step": 89020
    },
    {
      "epoch": 9.539269259616415,
      "grad_norm": 0.0011429742444306612,
      "learning_rate": 7.280974320511447e-06,
      "loss": 0.0002,
      "step": 89030
    },
    {
      "epoch": 9.540340726454517,
      "grad_norm": 0.00011361047654645517,
      "learning_rate": 7.279545698060646e-06,
      "loss": 0.0001,
      "step": 89040
    },
    {
      "epoch": 9.541412193292617,
      "grad_norm": 0.0014210044173523784,
      "learning_rate": 7.278117075609844e-06,
      "loss": 0.0,
      "step": 89050
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 9.875954128801823e-05,
      "learning_rate": 7.276688453159042e-06,
      "loss": 0.0002,
      "step": 89060
    },
    {
      "epoch": 9.54355512696882,
      "grad_norm": 0.05336906760931015,
      "learning_rate": 7.2752598307082405e-06,
      "loss": 0.0001,
      "step": 89070
    },
    {
      "epoch": 9.544626593806921,
      "grad_norm": 0.00671608978882432,
      "learning_rate": 7.273831208257438e-06,
      "loss": 0.0001,
      "step": 89080
    },
    {
      "epoch": 9.545698060645023,
      "grad_norm": 0.01694674976170063,
      "learning_rate": 7.272402585806636e-06,
      "loss": 0.1554,
      "step": 89090
    },
    {
      "epoch": 9.546769527483125,
      "grad_norm": 0.00013275146193336695,
      "learning_rate": 7.270973963355835e-06,
      "loss": 0.0001,
      "step": 89100
    },
    {
      "epoch": 9.547840994321225,
      "grad_norm": 9.916179260471836e-05,
      "learning_rate": 7.269545340905033e-06,
      "loss": 0.0001,
      "step": 89110
    },
    {
      "epoch": 9.548912461159327,
      "grad_norm": 0.0003885634650941938,
      "learning_rate": 7.268116718454231e-06,
      "loss": 0.0051,
      "step": 89120
    },
    {
      "epoch": 9.54998392799743,
      "grad_norm": 0.0010662832064554095,
      "learning_rate": 7.266688096003429e-06,
      "loss": 0.0001,
      "step": 89130
    },
    {
      "epoch": 9.55105539483553,
      "grad_norm": 0.00011083848221460357,
      "learning_rate": 7.2652594735526276e-06,
      "loss": 0.1308,
      "step": 89140
    },
    {
      "epoch": 9.552126861673631,
      "grad_norm": 9.541933104628697e-05,
      "learning_rate": 7.263830851101825e-06,
      "loss": 0.0,
      "step": 89150
    },
    {
      "epoch": 9.553198328511733,
      "grad_norm": 0.0027291839942336082,
      "learning_rate": 7.262402228651025e-06,
      "loss": 0.0001,
      "step": 89160
    },
    {
      "epoch": 9.554269795349834,
      "grad_norm": 0.0006058542639948428,
      "learning_rate": 7.260973606200222e-06,
      "loss": 0.0001,
      "step": 89170
    },
    {
      "epoch": 9.555341262187936,
      "grad_norm": 0.00013731388025917113,
      "learning_rate": 7.25954498374942e-06,
      "loss": 0.0833,
      "step": 89180
    },
    {
      "epoch": 9.556412729026036,
      "grad_norm": 0.0008661189349368215,
      "learning_rate": 7.2581163612986185e-06,
      "loss": 0.0005,
      "step": 89190
    },
    {
      "epoch": 9.557484195864138,
      "grad_norm": 0.00012588566460181028,
      "learning_rate": 7.256687738847816e-06,
      "loss": 0.0,
      "step": 89200
    },
    {
      "epoch": 9.55855566270224,
      "grad_norm": 0.00010301690053893253,
      "learning_rate": 7.255259116397015e-06,
      "loss": 0.2303,
      "step": 89210
    },
    {
      "epoch": 9.55962712954034,
      "grad_norm": 0.0003006034530699253,
      "learning_rate": 7.253830493946213e-06,
      "loss": 0.0003,
      "step": 89220
    },
    {
      "epoch": 9.560698596378442,
      "grad_norm": 9.692637831903994e-05,
      "learning_rate": 7.252401871495412e-06,
      "loss": 0.0001,
      "step": 89230
    },
    {
      "epoch": 9.561770063216544,
      "grad_norm": 0.0009496030979789793,
      "learning_rate": 7.250973249044609e-06,
      "loss": 0.0001,
      "step": 89240
    },
    {
      "epoch": 9.562841530054644,
      "grad_norm": 0.0001066562399500981,
      "learning_rate": 7.249544626593807e-06,
      "loss": 0.1581,
      "step": 89250
    },
    {
      "epoch": 9.563912996892746,
      "grad_norm": 0.002305521396920085,
      "learning_rate": 7.2481160041430056e-06,
      "loss": 0.1179,
      "step": 89260
    },
    {
      "epoch": 9.564984463730848,
      "grad_norm": 0.00011540340346982703,
      "learning_rate": 7.246687381692203e-06,
      "loss": 0.0001,
      "step": 89270
    },
    {
      "epoch": 9.566055930568949,
      "grad_norm": 0.00010809139348566532,
      "learning_rate": 7.245258759241403e-06,
      "loss": 0.2757,
      "step": 89280
    },
    {
      "epoch": 9.56712739740705,
      "grad_norm": 0.0020910839084535837,
      "learning_rate": 7.2438301367906e-06,
      "loss": 0.0001,
      "step": 89290
    },
    {
      "epoch": 9.56819886424515,
      "grad_norm": 0.000133738576550968,
      "learning_rate": 7.242401514339799e-06,
      "loss": 0.0002,
      "step": 89300
    },
    {
      "epoch": 9.569270331083253,
      "grad_norm": 0.00014892133185639977,
      "learning_rate": 7.2409728918889965e-06,
      "loss": 0.0011,
      "step": 89310
    },
    {
      "epoch": 9.570341797921355,
      "grad_norm": 0.1136535033583641,
      "learning_rate": 7.239544269438194e-06,
      "loss": 0.0002,
      "step": 89320
    },
    {
      "epoch": 9.571413264759455,
      "grad_norm": 0.004061469808220863,
      "learning_rate": 7.238115646987393e-06,
      "loss": 0.2619,
      "step": 89330
    },
    {
      "epoch": 9.572484731597557,
      "grad_norm": 0.00048810982843860984,
      "learning_rate": 7.236687024536592e-06,
      "loss": 0.0,
      "step": 89340
    },
    {
      "epoch": 9.573556198435659,
      "grad_norm": 0.00012786673323716968,
      "learning_rate": 7.23525840208579e-06,
      "loss": 0.0,
      "step": 89350
    },
    {
      "epoch": 9.57462766527376,
      "grad_norm": 0.00011329961125738919,
      "learning_rate": 7.233829779634987e-06,
      "loss": 0.0,
      "step": 89360
    },
    {
      "epoch": 9.575699132111861,
      "grad_norm": 0.00012894671817775816,
      "learning_rate": 7.232401157184186e-06,
      "loss": 0.2661,
      "step": 89370
    },
    {
      "epoch": 9.576770598949963,
      "grad_norm": 0.00012534504639916122,
      "learning_rate": 7.2309725347333836e-06,
      "loss": 0.076,
      "step": 89380
    },
    {
      "epoch": 9.577842065788063,
      "grad_norm": 0.10191213339567184,
      "learning_rate": 7.229543912282582e-06,
      "loss": 0.1838,
      "step": 89390
    },
    {
      "epoch": 9.578913532626165,
      "grad_norm": 0.017632149159908295,
      "learning_rate": 7.228115289831781e-06,
      "loss": 0.0001,
      "step": 89400
    },
    {
      "epoch": 9.579984999464267,
      "grad_norm": 0.0013583932304754853,
      "learning_rate": 7.226686667380979e-06,
      "loss": 0.0003,
      "step": 89410
    },
    {
      "epoch": 9.581056466302368,
      "grad_norm": 0.0001237284013768658,
      "learning_rate": 7.225258044930177e-06,
      "loss": 0.1983,
      "step": 89420
    },
    {
      "epoch": 9.58212793314047,
      "grad_norm": 0.001019891002215445,
      "learning_rate": 7.2238294224793745e-06,
      "loss": 0.0002,
      "step": 89430
    },
    {
      "epoch": 9.58319939997857,
      "grad_norm": 0.008059686049818993,
      "learning_rate": 7.222400800028573e-06,
      "loss": 0.0001,
      "step": 89440
    },
    {
      "epoch": 9.584270866816672,
      "grad_norm": 0.00012484550825320184,
      "learning_rate": 7.220972177577771e-06,
      "loss": 0.0031,
      "step": 89450
    },
    {
      "epoch": 9.585342333654774,
      "grad_norm": 9.848666377365589e-05,
      "learning_rate": 7.21954355512697e-06,
      "loss": 0.0001,
      "step": 89460
    },
    {
      "epoch": 9.586413800492874,
      "grad_norm": 0.011427761986851692,
      "learning_rate": 7.218114932676168e-06,
      "loss": 0.0,
      "step": 89470
    },
    {
      "epoch": 9.587485267330976,
      "grad_norm": 0.00027015741216018796,
      "learning_rate": 7.216686310225366e-06,
      "loss": 0.0007,
      "step": 89480
    },
    {
      "epoch": 9.588556734169078,
      "grad_norm": 0.005565132480114698,
      "learning_rate": 7.215257687774564e-06,
      "loss": 0.0,
      "step": 89490
    },
    {
      "epoch": 9.589628201007178,
      "grad_norm": 0.003372807754203677,
      "learning_rate": 7.2138290653237616e-06,
      "loss": 0.1842,
      "step": 89500
    },
    {
      "epoch": 9.59069966784528,
      "grad_norm": 0.00011653461842797697,
      "learning_rate": 7.21240044287296e-06,
      "loss": 0.0002,
      "step": 89510
    },
    {
      "epoch": 9.591771134683382,
      "grad_norm": 0.00014019156515132636,
      "learning_rate": 7.2109718204221594e-06,
      "loss": 0.0034,
      "step": 89520
    },
    {
      "epoch": 9.592842601521482,
      "grad_norm": 0.00012056584091624245,
      "learning_rate": 7.209543197971357e-06,
      "loss": 0.0001,
      "step": 89530
    },
    {
      "epoch": 9.593914068359584,
      "grad_norm": 0.0013534637400880456,
      "learning_rate": 7.208114575520555e-06,
      "loss": 0.0,
      "step": 89540
    },
    {
      "epoch": 9.594985535197686,
      "grad_norm": 0.00010100135114043951,
      "learning_rate": 7.206685953069753e-06,
      "loss": 0.0001,
      "step": 89550
    },
    {
      "epoch": 9.596057002035787,
      "grad_norm": 9.623696678318083e-05,
      "learning_rate": 7.205257330618951e-06,
      "loss": 0.0005,
      "step": 89560
    },
    {
      "epoch": 9.597128468873889,
      "grad_norm": 0.0020186903420835733,
      "learning_rate": 7.203828708168149e-06,
      "loss": 0.191,
      "step": 89570
    },
    {
      "epoch": 9.598199935711989,
      "grad_norm": 0.0001447430404368788,
      "learning_rate": 7.202400085717348e-06,
      "loss": 0.0009,
      "step": 89580
    },
    {
      "epoch": 9.599271402550091,
      "grad_norm": 0.00011257657024543732,
      "learning_rate": 7.2009714632665465e-06,
      "loss": 0.0002,
      "step": 89590
    },
    {
      "epoch": 9.600342869388193,
      "grad_norm": 0.00011123021977255121,
      "learning_rate": 7.199542840815744e-06,
      "loss": 0.0009,
      "step": 89600
    },
    {
      "epoch": 9.601414336226293,
      "grad_norm": 0.0001083395691239275,
      "learning_rate": 7.198114218364942e-06,
      "loss": 0.0001,
      "step": 89610
    },
    {
      "epoch": 9.602485803064395,
      "grad_norm": 0.02169223316013813,
      "learning_rate": 7.19668559591414e-06,
      "loss": 0.0002,
      "step": 89620
    },
    {
      "epoch": 9.603557269902497,
      "grad_norm": 0.0001281435979763046,
      "learning_rate": 7.195256973463338e-06,
      "loss": 0.0002,
      "step": 89630
    },
    {
      "epoch": 9.604628736740597,
      "grad_norm": 0.00018147284572478384,
      "learning_rate": 7.1938283510125374e-06,
      "loss": 0.2372,
      "step": 89640
    },
    {
      "epoch": 9.6057002035787,
      "grad_norm": 9.437749395146966e-05,
      "learning_rate": 7.192399728561735e-06,
      "loss": 0.0,
      "step": 89650
    },
    {
      "epoch": 9.606771670416801,
      "grad_norm": 0.0004417186719365418,
      "learning_rate": 7.190971106110934e-06,
      "loss": 0.0001,
      "step": 89660
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 0.0014475382631644607,
      "learning_rate": 7.189542483660131e-06,
      "loss": 0.0001,
      "step": 89670
    },
    {
      "epoch": 9.608914604093004,
      "grad_norm": 0.009415936656296253,
      "learning_rate": 7.188113861209329e-06,
      "loss": 0.0,
      "step": 89680
    },
    {
      "epoch": 9.609986070931104,
      "grad_norm": 0.00012374477228149772,
      "learning_rate": 7.1866852387585275e-06,
      "loss": 0.1604,
      "step": 89690
    },
    {
      "epoch": 9.611057537769206,
      "grad_norm": 0.0002959514386020601,
      "learning_rate": 7.185256616307726e-06,
      "loss": 0.0003,
      "step": 89700
    },
    {
      "epoch": 9.612129004607308,
      "grad_norm": 8.245118078775704e-05,
      "learning_rate": 7.1838279938569245e-06,
      "loss": 0.0,
      "step": 89710
    },
    {
      "epoch": 9.613200471445408,
      "grad_norm": 0.00013468416000250727,
      "learning_rate": 7.182399371406122e-06,
      "loss": 0.0002,
      "step": 89720
    },
    {
      "epoch": 9.61427193828351,
      "grad_norm": 0.00010355898120906204,
      "learning_rate": 7.180970748955321e-06,
      "loss": 0.0001,
      "step": 89730
    },
    {
      "epoch": 9.615343405121612,
      "grad_norm": 0.0005236206343397498,
      "learning_rate": 7.179542126504518e-06,
      "loss": 0.0001,
      "step": 89740
    },
    {
      "epoch": 9.616414871959712,
      "grad_norm": 9.68779277172871e-05,
      "learning_rate": 7.178113504053716e-06,
      "loss": 0.0,
      "step": 89750
    },
    {
      "epoch": 9.617486338797814,
      "grad_norm": 0.00617824774235487,
      "learning_rate": 7.176684881602915e-06,
      "loss": 0.0001,
      "step": 89760
    },
    {
      "epoch": 9.618557805635916,
      "grad_norm": 0.0016320119611918926,
      "learning_rate": 7.175256259152114e-06,
      "loss": 0.0,
      "step": 89770
    },
    {
      "epoch": 9.619629272474016,
      "grad_norm": 0.00011825977708213031,
      "learning_rate": 7.173827636701312e-06,
      "loss": 0.176,
      "step": 89780
    },
    {
      "epoch": 9.620700739312118,
      "grad_norm": 0.00011070131586166099,
      "learning_rate": 7.172399014250509e-06,
      "loss": 0.0002,
      "step": 89790
    },
    {
      "epoch": 9.62177220615022,
      "grad_norm": 0.001279509044252336,
      "learning_rate": 7.170970391799708e-06,
      "loss": 0.0,
      "step": 89800
    },
    {
      "epoch": 9.62284367298832,
      "grad_norm": 0.30450716614723206,
      "learning_rate": 7.1695417693489055e-06,
      "loss": 0.0004,
      "step": 89810
    },
    {
      "epoch": 9.623915139826423,
      "grad_norm": 0.0004519250651355833,
      "learning_rate": 7.168113146898103e-06,
      "loss": 0.0002,
      "step": 89820
    },
    {
      "epoch": 9.624986606664525,
      "grad_norm": 0.000156786001753062,
      "learning_rate": 7.1666845244473025e-06,
      "loss": 0.0,
      "step": 89830
    },
    {
      "epoch": 9.626058073502625,
      "grad_norm": 0.00046251172898337245,
      "learning_rate": 7.165255901996501e-06,
      "loss": 0.0,
      "step": 89840
    },
    {
      "epoch": 9.627129540340727,
      "grad_norm": 0.00012482181773521006,
      "learning_rate": 7.163827279545699e-06,
      "loss": 0.0001,
      "step": 89850
    },
    {
      "epoch": 9.628201007178827,
      "grad_norm": 0.001760268583893776,
      "learning_rate": 7.162398657094896e-06,
      "loss": 0.0,
      "step": 89860
    },
    {
      "epoch": 9.629272474016929,
      "grad_norm": 0.00034691084874793887,
      "learning_rate": 7.160970034644095e-06,
      "loss": 0.1089,
      "step": 89870
    },
    {
      "epoch": 9.630343940855031,
      "grad_norm": 0.0007324213511310518,
      "learning_rate": 7.159541412193293e-06,
      "loss": 0.1159,
      "step": 89880
    },
    {
      "epoch": 9.631415407693131,
      "grad_norm": 0.00011003066174453124,
      "learning_rate": 7.158112789742492e-06,
      "loss": 0.0,
      "step": 89890
    },
    {
      "epoch": 9.632486874531233,
      "grad_norm": 0.00032651639776304364,
      "learning_rate": 7.15668416729169e-06,
      "loss": 0.0,
      "step": 89900
    },
    {
      "epoch": 9.633558341369335,
      "grad_norm": 0.00028820158331654966,
      "learning_rate": 7.155255544840888e-06,
      "loss": 0.0,
      "step": 89910
    },
    {
      "epoch": 9.634629808207436,
      "grad_norm": 0.00010334598482586443,
      "learning_rate": 7.153826922390086e-06,
      "loss": 0.0001,
      "step": 89920
    },
    {
      "epoch": 9.635701275045538,
      "grad_norm": 0.000103683203633409,
      "learning_rate": 7.1523982999392835e-06,
      "loss": 0.0,
      "step": 89930
    },
    {
      "epoch": 9.63677274188364,
      "grad_norm": 0.8538202047348022,
      "learning_rate": 7.150969677488482e-06,
      "loss": 0.1705,
      "step": 89940
    },
    {
      "epoch": 9.63784420872174,
      "grad_norm": 0.00013260830019135028,
      "learning_rate": 7.1495410550376805e-06,
      "loss": 0.0924,
      "step": 89950
    },
    {
      "epoch": 9.638915675559842,
      "grad_norm": 0.00016379967564716935,
      "learning_rate": 7.148112432586879e-06,
      "loss": 0.0,
      "step": 89960
    },
    {
      "epoch": 9.639987142397942,
      "grad_norm": 0.00011150447971886024,
      "learning_rate": 7.146683810136077e-06,
      "loss": 0.1258,
      "step": 89970
    },
    {
      "epoch": 9.641058609236044,
      "grad_norm": 0.00013101845979690552,
      "learning_rate": 7.145255187685275e-06,
      "loss": 0.0002,
      "step": 89980
    },
    {
      "epoch": 9.642130076074146,
      "grad_norm": 0.0177929550409317,
      "learning_rate": 7.143826565234473e-06,
      "loss": 0.0001,
      "step": 89990
    },
    {
      "epoch": 9.643201542912246,
      "grad_norm": 0.0007553807809017599,
      "learning_rate": 7.142397942783671e-06,
      "loss": 0.0009,
      "step": 90000
    },
    {
      "epoch": 9.644273009750348,
      "grad_norm": 0.00012091442476958036,
      "learning_rate": 7.14096932033287e-06,
      "loss": 0.0001,
      "step": 90010
    },
    {
      "epoch": 9.64534447658845,
      "grad_norm": 8.638074359623715e-05,
      "learning_rate": 7.139540697882068e-06,
      "loss": 0.0005,
      "step": 90020
    },
    {
      "epoch": 9.64641594342655,
      "grad_norm": 0.00011012793402187526,
      "learning_rate": 7.138112075431266e-06,
      "loss": 0.0017,
      "step": 90030
    },
    {
      "epoch": 9.647487410264652,
      "grad_norm": 0.0005930936895310879,
      "learning_rate": 7.136683452980464e-06,
      "loss": 0.3416,
      "step": 90040
    },
    {
      "epoch": 9.648558877102754,
      "grad_norm": 0.04012319818139076,
      "learning_rate": 7.135254830529662e-06,
      "loss": 0.0001,
      "step": 90050
    },
    {
      "epoch": 9.649630343940855,
      "grad_norm": 0.00011068228195654228,
      "learning_rate": 7.13382620807886e-06,
      "loss": 0.0,
      "step": 90060
    },
    {
      "epoch": 9.650701810778957,
      "grad_norm": 0.06269659847021103,
      "learning_rate": 7.132397585628059e-06,
      "loss": 0.0002,
      "step": 90070
    },
    {
      "epoch": 9.651773277617057,
      "grad_norm": 0.0020877975039184093,
      "learning_rate": 7.130968963177257e-06,
      "loss": 0.0,
      "step": 90080
    },
    {
      "epoch": 9.652844744455159,
      "grad_norm": 0.00027076006517745554,
      "learning_rate": 7.129540340726456e-06,
      "loss": 0.0,
      "step": 90090
    },
    {
      "epoch": 9.65391621129326,
      "grad_norm": 9.364433208247647e-05,
      "learning_rate": 7.128111718275653e-06,
      "loss": 0.0,
      "step": 90100
    },
    {
      "epoch": 9.654987678131361,
      "grad_norm": 8.763770892983302e-05,
      "learning_rate": 7.126683095824851e-06,
      "loss": 0.0002,
      "step": 90110
    },
    {
      "epoch": 9.656059144969463,
      "grad_norm": 0.0008307467214763165,
      "learning_rate": 7.1252544733740494e-06,
      "loss": 0.0,
      "step": 90120
    },
    {
      "epoch": 9.657130611807565,
      "grad_norm": 9.659770148573443e-05,
      "learning_rate": 7.123825850923248e-06,
      "loss": 0.0001,
      "step": 90130
    },
    {
      "epoch": 9.658202078645665,
      "grad_norm": 0.00019033055286854506,
      "learning_rate": 7.1223972284724465e-06,
      "loss": 0.0,
      "step": 90140
    },
    {
      "epoch": 9.659273545483767,
      "grad_norm": 0.10944795608520508,
      "learning_rate": 7.120968606021644e-06,
      "loss": 0.0001,
      "step": 90150
    },
    {
      "epoch": 9.66034501232187,
      "grad_norm": 0.002687199041247368,
      "learning_rate": 7.119539983570843e-06,
      "loss": 0.0,
      "step": 90160
    },
    {
      "epoch": 9.66141647915997,
      "grad_norm": 0.0006754084606654942,
      "learning_rate": 7.11811136112004e-06,
      "loss": 0.0,
      "step": 90170
    },
    {
      "epoch": 9.662487945998071,
      "grad_norm": 0.0009582510101608932,
      "learning_rate": 7.116682738669238e-06,
      "loss": 0.0,
      "step": 90180
    },
    {
      "epoch": 9.663559412836173,
      "grad_norm": 0.00010848866077139974,
      "learning_rate": 7.115254116218437e-06,
      "loss": 0.0,
      "step": 90190
    },
    {
      "epoch": 9.664630879674274,
      "grad_norm": 0.0069018700160086155,
      "learning_rate": 7.113825493767635e-06,
      "loss": 0.5193,
      "step": 90200
    },
    {
      "epoch": 9.665702346512376,
      "grad_norm": 9.421724826097488e-05,
      "learning_rate": 7.112396871316834e-06,
      "loss": 0.0121,
      "step": 90210
    },
    {
      "epoch": 9.666773813350478,
      "grad_norm": 8.996417454909533e-05,
      "learning_rate": 7.110968248866031e-06,
      "loss": 0.0,
      "step": 90220
    },
    {
      "epoch": 9.667845280188578,
      "grad_norm": 0.0001894531596917659,
      "learning_rate": 7.10953962641523e-06,
      "loss": 0.0,
      "step": 90230
    },
    {
      "epoch": 9.66891674702668,
      "grad_norm": 0.0017148115439340472,
      "learning_rate": 7.1081110039644274e-06,
      "loss": 0.0004,
      "step": 90240
    },
    {
      "epoch": 9.66998821386478,
      "grad_norm": 8.909703319659457e-05,
      "learning_rate": 7.106682381513627e-06,
      "loss": 0.0,
      "step": 90250
    },
    {
      "epoch": 9.671059680702882,
      "grad_norm": 0.00010406623914605007,
      "learning_rate": 7.1052537590628245e-06,
      "loss": 0.0,
      "step": 90260
    },
    {
      "epoch": 9.672131147540984,
      "grad_norm": 0.0010712434304878116,
      "learning_rate": 7.103825136612022e-06,
      "loss": 0.1789,
      "step": 90270
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 0.0013744498137384653,
      "learning_rate": 7.102396514161221e-06,
      "loss": 0.0004,
      "step": 90280
    },
    {
      "epoch": 9.674274081217186,
      "grad_norm": 0.004291964694857597,
      "learning_rate": 7.100967891710418e-06,
      "loss": 0.0734,
      "step": 90290
    },
    {
      "epoch": 9.675345548055288,
      "grad_norm": 0.007202719338238239,
      "learning_rate": 7.099539269259617e-06,
      "loss": 0.0001,
      "step": 90300
    },
    {
      "epoch": 9.676417014893389,
      "grad_norm": 0.10817946493625641,
      "learning_rate": 7.098110646808815e-06,
      "loss": 0.0002,
      "step": 90310
    },
    {
      "epoch": 9.67748848173149,
      "grad_norm": 0.001810458954423666,
      "learning_rate": 7.096682024358014e-06,
      "loss": 0.0002,
      "step": 90320
    },
    {
      "epoch": 9.678559948569593,
      "grad_norm": 0.06613639742136002,
      "learning_rate": 7.095253401907212e-06,
      "loss": 0.1217,
      "step": 90330
    },
    {
      "epoch": 9.679631415407693,
      "grad_norm": 0.00010307080810889602,
      "learning_rate": 7.09382477945641e-06,
      "loss": 0.0013,
      "step": 90340
    },
    {
      "epoch": 9.680702882245795,
      "grad_norm": 9.681812662165612e-05,
      "learning_rate": 7.092396157005608e-06,
      "loss": 0.0,
      "step": 90350
    },
    {
      "epoch": 9.681774349083895,
      "grad_norm": 9.449416393181309e-05,
      "learning_rate": 7.0909675345548054e-06,
      "loss": 0.1637,
      "step": 90360
    },
    {
      "epoch": 9.682845815921997,
      "grad_norm": 9.895828407024965e-05,
      "learning_rate": 7.089538912104005e-06,
      "loss": 0.0,
      "step": 90370
    },
    {
      "epoch": 9.683917282760099,
      "grad_norm": 0.0018400620901957154,
      "learning_rate": 7.0881102896532025e-06,
      "loss": 0.1712,
      "step": 90380
    },
    {
      "epoch": 9.6849887495982,
      "grad_norm": 0.08182676881551743,
      "learning_rate": 7.086681667202401e-06,
      "loss": 0.0005,
      "step": 90390
    },
    {
      "epoch": 9.686060216436301,
      "grad_norm": 0.0023274302948266268,
      "learning_rate": 7.085253044751599e-06,
      "loss": 0.0,
      "step": 90400
    },
    {
      "epoch": 9.687131683274403,
      "grad_norm": 9.673914610175416e-05,
      "learning_rate": 7.083824422300797e-06,
      "loss": 0.1702,
      "step": 90410
    },
    {
      "epoch": 9.688203150112503,
      "grad_norm": 0.00012014160165563226,
      "learning_rate": 7.082395799849995e-06,
      "loss": 0.2715,
      "step": 90420
    },
    {
      "epoch": 9.689274616950605,
      "grad_norm": 8.770054409978911e-05,
      "learning_rate": 7.080967177399194e-06,
      "loss": 0.0003,
      "step": 90430
    },
    {
      "epoch": 9.690346083788707,
      "grad_norm": 8.148798951879144e-05,
      "learning_rate": 7.079538554948392e-06,
      "loss": 0.0007,
      "step": 90440
    },
    {
      "epoch": 9.691417550626808,
      "grad_norm": 0.00014151507639326155,
      "learning_rate": 7.07810993249759e-06,
      "loss": 0.0002,
      "step": 90450
    },
    {
      "epoch": 9.69248901746491,
      "grad_norm": 8.577563858125359e-05,
      "learning_rate": 7.076681310046788e-06,
      "loss": 0.16,
      "step": 90460
    },
    {
      "epoch": 9.693560484303012,
      "grad_norm": 0.016334427520632744,
      "learning_rate": 7.075252687595986e-06,
      "loss": 0.0002,
      "step": 90470
    },
    {
      "epoch": 9.694631951141112,
      "grad_norm": 33.97135543823242,
      "learning_rate": 7.073824065145184e-06,
      "loss": 0.1008,
      "step": 90480
    },
    {
      "epoch": 9.695703417979214,
      "grad_norm": 9.853363735601306e-05,
      "learning_rate": 7.072395442694383e-06,
      "loss": 0.1635,
      "step": 90490
    },
    {
      "epoch": 9.696774884817314,
      "grad_norm": 0.00849679671227932,
      "learning_rate": 7.070966820243581e-06,
      "loss": 0.0001,
      "step": 90500
    },
    {
      "epoch": 9.697846351655416,
      "grad_norm": 7.286464824574068e-05,
      "learning_rate": 7.069538197792779e-06,
      "loss": 0.2577,
      "step": 90510
    },
    {
      "epoch": 9.698917818493518,
      "grad_norm": 0.004226494114845991,
      "learning_rate": 7.068109575341977e-06,
      "loss": 0.1914,
      "step": 90520
    },
    {
      "epoch": 9.699989285331618,
      "grad_norm": 0.00011790615099016577,
      "learning_rate": 7.066680952891175e-06,
      "loss": 0.0,
      "step": 90530
    },
    {
      "epoch": 9.70106075216972,
      "grad_norm": 0.00014424821711145341,
      "learning_rate": 7.065252330440373e-06,
      "loss": 0.0002,
      "step": 90540
    },
    {
      "epoch": 9.702132219007822,
      "grad_norm": 0.02150639519095421,
      "learning_rate": 7.063823707989572e-06,
      "loss": 0.0043,
      "step": 90550
    },
    {
      "epoch": 9.703203685845923,
      "grad_norm": 7.87717872299254e-05,
      "learning_rate": 7.06239508553877e-06,
      "loss": 0.0,
      "step": 90560
    },
    {
      "epoch": 9.704275152684025,
      "grad_norm": 8.32540390547365e-05,
      "learning_rate": 7.0609664630879684e-06,
      "loss": 0.0002,
      "step": 90570
    },
    {
      "epoch": 9.705346619522127,
      "grad_norm": 0.010513878427445889,
      "learning_rate": 7.059537840637166e-06,
      "loss": 0.0005,
      "step": 90580
    },
    {
      "epoch": 9.706418086360227,
      "grad_norm": 0.0017750647384673357,
      "learning_rate": 7.058109218186364e-06,
      "loss": 0.0,
      "step": 90590
    },
    {
      "epoch": 9.707489553198329,
      "grad_norm": 0.0012736025964841247,
      "learning_rate": 7.056680595735562e-06,
      "loss": 0.0,
      "step": 90600
    },
    {
      "epoch": 9.70856102003643,
      "grad_norm": 7.89952464401722e-05,
      "learning_rate": 7.055251973284762e-06,
      "loss": 0.0,
      "step": 90610
    },
    {
      "epoch": 9.709632486874531,
      "grad_norm": 7.239889237098396e-05,
      "learning_rate": 7.053823350833959e-06,
      "loss": 0.0001,
      "step": 90620
    },
    {
      "epoch": 9.710703953712633,
      "grad_norm": 0.0001036490430124104,
      "learning_rate": 7.052394728383157e-06,
      "loss": 0.0,
      "step": 90630
    },
    {
      "epoch": 9.711775420550733,
      "grad_norm": 0.0001225751475431025,
      "learning_rate": 7.0509661059323555e-06,
      "loss": 0.0,
      "step": 90640
    },
    {
      "epoch": 9.712846887388835,
      "grad_norm": 7.938555791042745e-05,
      "learning_rate": 7.049537483481553e-06,
      "loss": 0.0007,
      "step": 90650
    },
    {
      "epoch": 9.713918354226937,
      "grad_norm": 9.633891022531316e-05,
      "learning_rate": 7.048108861030752e-06,
      "loss": 0.0,
      "step": 90660
    },
    {
      "epoch": 9.714989821065037,
      "grad_norm": 0.0020747368689626455,
      "learning_rate": 7.046680238579949e-06,
      "loss": 0.0094,
      "step": 90670
    },
    {
      "epoch": 9.71606128790314,
      "grad_norm": 8.144444291247055e-05,
      "learning_rate": 7.045251616129149e-06,
      "loss": 0.0001,
      "step": 90680
    },
    {
      "epoch": 9.717132754741241,
      "grad_norm": 0.0021698055788874626,
      "learning_rate": 7.0438229936783464e-06,
      "loss": 0.0,
      "step": 90690
    },
    {
      "epoch": 9.718204221579342,
      "grad_norm": 7.8846889664419e-05,
      "learning_rate": 7.042394371227544e-06,
      "loss": 0.0002,
      "step": 90700
    },
    {
      "epoch": 9.719275688417444,
      "grad_norm": 8.742879435885698e-05,
      "learning_rate": 7.040965748776743e-06,
      "loss": 0.0001,
      "step": 90710
    },
    {
      "epoch": 9.720347155255546,
      "grad_norm": 0.08454346656799316,
      "learning_rate": 7.03953712632594e-06,
      "loss": 0.0016,
      "step": 90720
    },
    {
      "epoch": 9.721418622093646,
      "grad_norm": 2.138916015625,
      "learning_rate": 7.038108503875139e-06,
      "loss": 0.0005,
      "step": 90730
    },
    {
      "epoch": 9.722490088931748,
      "grad_norm": 7.76017113821581e-05,
      "learning_rate": 7.036679881424337e-06,
      "loss": 0.0,
      "step": 90740
    },
    {
      "epoch": 9.723561555769848,
      "grad_norm": 6.631475844187662e-05,
      "learning_rate": 7.035251258973536e-06,
      "loss": 0.1273,
      "step": 90750
    },
    {
      "epoch": 9.72463302260795,
      "grad_norm": 7.969015859998763e-05,
      "learning_rate": 7.0338226365227335e-06,
      "loss": 0.0,
      "step": 90760
    },
    {
      "epoch": 9.725704489446052,
      "grad_norm": 0.0008997720433399081,
      "learning_rate": 7.032394014071931e-06,
      "loss": 0.2227,
      "step": 90770
    },
    {
      "epoch": 9.726775956284152,
      "grad_norm": 8.75098048709333e-05,
      "learning_rate": 7.03096539162113e-06,
      "loss": 0.0,
      "step": 90780
    },
    {
      "epoch": 9.727847423122254,
      "grad_norm": 0.48078498244285583,
      "learning_rate": 7.029536769170327e-06,
      "loss": 0.001,
      "step": 90790
    },
    {
      "epoch": 9.728918889960356,
      "grad_norm": 0.00010037251195171848,
      "learning_rate": 7.028108146719527e-06,
      "loss": 0.0936,
      "step": 90800
    },
    {
      "epoch": 9.729990356798456,
      "grad_norm": 0.0029102794360369444,
      "learning_rate": 7.0266795242687244e-06,
      "loss": 0.0002,
      "step": 90810
    },
    {
      "epoch": 9.731061823636558,
      "grad_norm": 9.374220826430246e-05,
      "learning_rate": 7.025250901817923e-06,
      "loss": 0.0,
      "step": 90820
    },
    {
      "epoch": 9.73213329047466,
      "grad_norm": 0.0012635566527023911,
      "learning_rate": 7.023822279367121e-06,
      "loss": 0.0001,
      "step": 90830
    },
    {
      "epoch": 9.73320475731276,
      "grad_norm": 8.76259509823285e-05,
      "learning_rate": 7.022393656916318e-06,
      "loss": 0.0006,
      "step": 90840
    },
    {
      "epoch": 9.734276224150863,
      "grad_norm": 7.494327292079106e-05,
      "learning_rate": 7.020965034465517e-06,
      "loss": 0.0,
      "step": 90850
    },
    {
      "epoch": 9.735347690988965,
      "grad_norm": 0.001430120668374002,
      "learning_rate": 7.019536412014716e-06,
      "loss": 0.0002,
      "step": 90860
    },
    {
      "epoch": 9.736419157827065,
      "grad_norm": 0.0011506034061312675,
      "learning_rate": 7.018107789563914e-06,
      "loss": 0.0003,
      "step": 90870
    },
    {
      "epoch": 9.737490624665167,
      "grad_norm": 0.0015554330311715603,
      "learning_rate": 7.0166791671131115e-06,
      "loss": 0.0,
      "step": 90880
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 0.0008131940267048776,
      "learning_rate": 7.01525054466231e-06,
      "loss": 0.0001,
      "step": 90890
    },
    {
      "epoch": 9.73963355834137,
      "grad_norm": 0.001858829753473401,
      "learning_rate": 7.013821922211508e-06,
      "loss": 0.1584,
      "step": 90900
    },
    {
      "epoch": 9.740705025179471,
      "grad_norm": 0.12302640825510025,
      "learning_rate": 7.012393299760706e-06,
      "loss": 0.0003,
      "step": 90910
    },
    {
      "epoch": 9.741776492017571,
      "grad_norm": 0.0013081541983410716,
      "learning_rate": 7.010964677309905e-06,
      "loss": 0.0001,
      "step": 90920
    },
    {
      "epoch": 9.742847958855673,
      "grad_norm": 0.7980085611343384,
      "learning_rate": 7.009536054859103e-06,
      "loss": 0.0003,
      "step": 90930
    },
    {
      "epoch": 9.743919425693775,
      "grad_norm": 8.950482151703909e-05,
      "learning_rate": 7.008107432408301e-06,
      "loss": 0.0,
      "step": 90940
    },
    {
      "epoch": 9.744990892531876,
      "grad_norm": 1.6382694244384766,
      "learning_rate": 7.006678809957499e-06,
      "loss": 0.2768,
      "step": 90950
    },
    {
      "epoch": 9.746062359369978,
      "grad_norm": 0.00028316344833001494,
      "learning_rate": 7.005250187506697e-06,
      "loss": 0.0,
      "step": 90960
    },
    {
      "epoch": 9.74713382620808,
      "grad_norm": 0.0001042501608026214,
      "learning_rate": 7.003821565055895e-06,
      "loss": 0.0003,
      "step": 90970
    },
    {
      "epoch": 9.74820529304618,
      "grad_norm": 7.67909295973368e-05,
      "learning_rate": 7.002392942605094e-06,
      "loss": 0.3644,
      "step": 90980
    },
    {
      "epoch": 9.749276759884282,
      "grad_norm": 0.006638046819716692,
      "learning_rate": 7.000964320154292e-06,
      "loss": 0.0001,
      "step": 90990
    },
    {
      "epoch": 9.750348226722384,
      "grad_norm": 7.799766171956435e-05,
      "learning_rate": 6.99953569770349e-06,
      "loss": 0.0,
      "step": 91000
    },
    {
      "epoch": 9.751419693560484,
      "grad_norm": 0.0013388314982876182,
      "learning_rate": 6.998107075252688e-06,
      "loss": 0.0001,
      "step": 91010
    },
    {
      "epoch": 9.752491160398586,
      "grad_norm": 0.00014254634152166545,
      "learning_rate": 6.996678452801886e-06,
      "loss": 0.2005,
      "step": 91020
    },
    {
      "epoch": 9.753562627236686,
      "grad_norm": 0.0016472531715407968,
      "learning_rate": 6.995249830351084e-06,
      "loss": 0.0,
      "step": 91030
    },
    {
      "epoch": 9.754634094074788,
      "grad_norm": 8.279923349618912e-05,
      "learning_rate": 6.993821207900284e-06,
      "loss": 0.0002,
      "step": 91040
    },
    {
      "epoch": 9.75570556091289,
      "grad_norm": 53.402015686035156,
      "learning_rate": 6.992392585449481e-06,
      "loss": 0.2265,
      "step": 91050
    },
    {
      "epoch": 9.75677702775099,
      "grad_norm": 0.0020624431781470776,
      "learning_rate": 6.990963962998679e-06,
      "loss": 0.0001,
      "step": 91060
    },
    {
      "epoch": 9.757848494589092,
      "grad_norm": 0.0001669371995376423,
      "learning_rate": 6.9895353405478775e-06,
      "loss": 0.0,
      "step": 91070
    },
    {
      "epoch": 9.758919961427194,
      "grad_norm": 0.005449159070849419,
      "learning_rate": 6.988106718097075e-06,
      "loss": 0.0001,
      "step": 91080
    },
    {
      "epoch": 9.759991428265295,
      "grad_norm": 0.00011065651051467285,
      "learning_rate": 6.986678095646273e-06,
      "loss": 0.0004,
      "step": 91090
    },
    {
      "epoch": 9.761062895103397,
      "grad_norm": 9.854537347564474e-05,
      "learning_rate": 6.985249473195472e-06,
      "loss": 0.0007,
      "step": 91100
    },
    {
      "epoch": 9.762134361941499,
      "grad_norm": 0.00014277338050305843,
      "learning_rate": 6.983820850744671e-06,
      "loss": 0.0001,
      "step": 91110
    },
    {
      "epoch": 9.763205828779599,
      "grad_norm": 0.00016317356494255364,
      "learning_rate": 6.982392228293868e-06,
      "loss": 0.0,
      "step": 91120
    },
    {
      "epoch": 9.7642772956177,
      "grad_norm": 8.784327656030655e-05,
      "learning_rate": 6.980963605843066e-06,
      "loss": 0.0007,
      "step": 91130
    },
    {
      "epoch": 9.765348762455801,
      "grad_norm": 0.00823100097477436,
      "learning_rate": 6.9795349833922646e-06,
      "loss": 0.0,
      "step": 91140
    },
    {
      "epoch": 9.766420229293903,
      "grad_norm": 8.10990241006948e-05,
      "learning_rate": 6.978106360941462e-06,
      "loss": 0.0001,
      "step": 91150
    },
    {
      "epoch": 9.767491696132005,
      "grad_norm": 0.00017798974295146763,
      "learning_rate": 6.976677738490662e-06,
      "loss": 0.0,
      "step": 91160
    },
    {
      "epoch": 9.768563162970105,
      "grad_norm": 0.006090587005019188,
      "learning_rate": 6.975249116039859e-06,
      "loss": 0.0,
      "step": 91170
    },
    {
      "epoch": 9.769634629808207,
      "grad_norm": 0.0005716251907870173,
      "learning_rate": 6.973820493589058e-06,
      "loss": 0.1503,
      "step": 91180
    },
    {
      "epoch": 9.77070609664631,
      "grad_norm": 0.01535731554031372,
      "learning_rate": 6.9723918711382555e-06,
      "loss": 0.0,
      "step": 91190
    },
    {
      "epoch": 9.77177756348441,
      "grad_norm": 7.744220783933997e-05,
      "learning_rate": 6.970963248687453e-06,
      "loss": 0.1707,
      "step": 91200
    },
    {
      "epoch": 9.772849030322512,
      "grad_norm": 0.5034013986587524,
      "learning_rate": 6.969534626236652e-06,
      "loss": 0.0007,
      "step": 91210
    },
    {
      "epoch": 9.773920497160614,
      "grad_norm": 9.712331666378304e-05,
      "learning_rate": 6.96810600378585e-06,
      "loss": 0.0004,
      "step": 91220
    },
    {
      "epoch": 9.774991963998714,
      "grad_norm": 9.32043039938435e-05,
      "learning_rate": 6.966677381335049e-06,
      "loss": 0.0,
      "step": 91230
    },
    {
      "epoch": 9.776063430836816,
      "grad_norm": 9.074806439457461e-05,
      "learning_rate": 6.965248758884246e-06,
      "loss": 0.0,
      "step": 91240
    },
    {
      "epoch": 9.777134897674918,
      "grad_norm": 8.746792445890605e-05,
      "learning_rate": 6.963820136433445e-06,
      "loss": 0.0001,
      "step": 91250
    },
    {
      "epoch": 9.778206364513018,
      "grad_norm": 0.0003789805923588574,
      "learning_rate": 6.9623915139826426e-06,
      "loss": 0.0,
      "step": 91260
    },
    {
      "epoch": 9.77927783135112,
      "grad_norm": 36.23303985595703,
      "learning_rate": 6.96096289153184e-06,
      "loss": 0.2255,
      "step": 91270
    },
    {
      "epoch": 9.780349298189222,
      "grad_norm": 7.770321826683357e-05,
      "learning_rate": 6.95953426908104e-06,
      "loss": 0.0,
      "step": 91280
    },
    {
      "epoch": 9.781420765027322,
      "grad_norm": 0.0027073624078184366,
      "learning_rate": 6.958105646630237e-06,
      "loss": 0.0003,
      "step": 91290
    },
    {
      "epoch": 9.782492231865424,
      "grad_norm": 0.0021067822817713022,
      "learning_rate": 6.956677024179436e-06,
      "loss": 0.1885,
      "step": 91300
    },
    {
      "epoch": 9.783563698703524,
      "grad_norm": 0.04101340100169182,
      "learning_rate": 6.9552484017286335e-06,
      "loss": 0.1574,
      "step": 91310
    },
    {
      "epoch": 9.784635165541626,
      "grad_norm": 0.00045380587107501924,
      "learning_rate": 6.953819779277832e-06,
      "loss": 0.0004,
      "step": 91320
    },
    {
      "epoch": 9.785706632379728,
      "grad_norm": 0.00010521537478780374,
      "learning_rate": 6.95239115682703e-06,
      "loss": 0.0007,
      "step": 91330
    },
    {
      "epoch": 9.786778099217829,
      "grad_norm": 0.0030919439159333706,
      "learning_rate": 6.950962534376229e-06,
      "loss": 0.0001,
      "step": 91340
    },
    {
      "epoch": 9.78784956605593,
      "grad_norm": 0.0001852290879469365,
      "learning_rate": 6.949533911925427e-06,
      "loss": 0.0,
      "step": 91350
    },
    {
      "epoch": 9.788921032894033,
      "grad_norm": 0.0002892469638027251,
      "learning_rate": 6.948105289474625e-06,
      "loss": 0.001,
      "step": 91360
    },
    {
      "epoch": 9.789992499732133,
      "grad_norm": 0.004209805279970169,
      "learning_rate": 6.946676667023823e-06,
      "loss": 0.1517,
      "step": 91370
    },
    {
      "epoch": 9.791063966570235,
      "grad_norm": 0.00011281182378297672,
      "learning_rate": 6.9452480445730206e-06,
      "loss": 0.0001,
      "step": 91380
    },
    {
      "epoch": 9.792135433408337,
      "grad_norm": 0.0014855380868539214,
      "learning_rate": 6.943819422122219e-06,
      "loss": 0.0002,
      "step": 91390
    },
    {
      "epoch": 9.793206900246437,
      "grad_norm": 0.0012308541918173432,
      "learning_rate": 6.942390799671418e-06,
      "loss": 0.1879,
      "step": 91400
    },
    {
      "epoch": 9.794278367084539,
      "grad_norm": 0.0011734776198863983,
      "learning_rate": 6.940962177220616e-06,
      "loss": 0.1881,
      "step": 91410
    },
    {
      "epoch": 9.79534983392264,
      "grad_norm": 0.052766311913728714,
      "learning_rate": 6.939533554769814e-06,
      "loss": 0.0,
      "step": 91420
    },
    {
      "epoch": 9.796421300760741,
      "grad_norm": 7.101595838321373e-05,
      "learning_rate": 6.938104932319012e-06,
      "loss": 0.0007,
      "step": 91430
    },
    {
      "epoch": 9.797492767598843,
      "grad_norm": 7.28020240785554e-05,
      "learning_rate": 6.93667630986821e-06,
      "loss": 0.0003,
      "step": 91440
    },
    {
      "epoch": 9.798564234436943,
      "grad_norm": 0.0013701367424800992,
      "learning_rate": 6.935247687417408e-06,
      "loss": 0.0009,
      "step": 91450
    },
    {
      "epoch": 9.799635701275045,
      "grad_norm": 8.828254067339003e-05,
      "learning_rate": 6.933819064966607e-06,
      "loss": 0.0005,
      "step": 91460
    },
    {
      "epoch": 9.800707168113147,
      "grad_norm": 0.0016706216847524047,
      "learning_rate": 6.932390442515805e-06,
      "loss": 0.2024,
      "step": 91470
    },
    {
      "epoch": 9.801778634951248,
      "grad_norm": 9.046243212651461e-05,
      "learning_rate": 6.930961820065003e-06,
      "loss": 0.0002,
      "step": 91480
    },
    {
      "epoch": 9.80285010178935,
      "grad_norm": 0.00011072255438193679,
      "learning_rate": 6.929533197614201e-06,
      "loss": 0.0,
      "step": 91490
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.00986911728978157,
      "learning_rate": 6.928104575163399e-06,
      "loss": 0.0002,
      "step": 91500
    },
    {
      "epoch": 9.804993035465552,
      "grad_norm": 0.0031802253797650337,
      "learning_rate": 6.926675952712597e-06,
      "loss": 0.0003,
      "step": 91510
    },
    {
      "epoch": 9.806064502303654,
      "grad_norm": 0.0023773256689310074,
      "learning_rate": 6.925247330261795e-06,
      "loss": 0.0004,
      "step": 91520
    },
    {
      "epoch": 9.807135969141756,
      "grad_norm": 0.007217795122414827,
      "learning_rate": 6.923818707810994e-06,
      "loss": 0.1883,
      "step": 91530
    },
    {
      "epoch": 9.808207435979856,
      "grad_norm": 0.004659473430365324,
      "learning_rate": 6.922390085360192e-06,
      "loss": 0.0001,
      "step": 91540
    },
    {
      "epoch": 9.809278902817958,
      "grad_norm": 7.304556493181735e-05,
      "learning_rate": 6.92096146290939e-06,
      "loss": 0.0003,
      "step": 91550
    },
    {
      "epoch": 9.810350369656058,
      "grad_norm": 0.017494529485702515,
      "learning_rate": 6.919532840458588e-06,
      "loss": 0.0001,
      "step": 91560
    },
    {
      "epoch": 9.81142183649416,
      "grad_norm": 0.001640597707591951,
      "learning_rate": 6.9181042180077865e-06,
      "loss": 0.0001,
      "step": 91570
    },
    {
      "epoch": 9.812493303332262,
      "grad_norm": 6.303854752331972e-05,
      "learning_rate": 6.916675595556984e-06,
      "loss": 0.0,
      "step": 91580
    },
    {
      "epoch": 9.813564770170363,
      "grad_norm": 6.921952444827184e-05,
      "learning_rate": 6.9152469731061835e-06,
      "loss": 0.1567,
      "step": 91590
    },
    {
      "epoch": 9.814636237008465,
      "grad_norm": 0.0015212188009172678,
      "learning_rate": 6.913818350655381e-06,
      "loss": 0.0002,
      "step": 91600
    },
    {
      "epoch": 9.815707703846567,
      "grad_norm": 9.420546120963991e-05,
      "learning_rate": 6.91238972820458e-06,
      "loss": 0.0002,
      "step": 91610
    },
    {
      "epoch": 9.816779170684667,
      "grad_norm": 6.805073644500226e-05,
      "learning_rate": 6.910961105753777e-06,
      "loss": 0.0004,
      "step": 91620
    },
    {
      "epoch": 9.817850637522769,
      "grad_norm": 0.0014803605154156685,
      "learning_rate": 6.909532483302975e-06,
      "loss": 0.143,
      "step": 91630
    },
    {
      "epoch": 9.81892210436087,
      "grad_norm": 0.002133872825652361,
      "learning_rate": 6.908103860852174e-06,
      "loss": 0.1517,
      "step": 91640
    },
    {
      "epoch": 9.819993571198971,
      "grad_norm": 6.665199907729402e-05,
      "learning_rate": 6.906675238401372e-06,
      "loss": 0.0013,
      "step": 91650
    },
    {
      "epoch": 9.821065038037073,
      "grad_norm": 0.00020730840333271772,
      "learning_rate": 6.905246615950571e-06,
      "loss": 0.0006,
      "step": 91660
    },
    {
      "epoch": 9.822136504875175,
      "grad_norm": 5.639722803607583e-05,
      "learning_rate": 6.903817993499768e-06,
      "loss": 0.1627,
      "step": 91670
    },
    {
      "epoch": 9.823207971713275,
      "grad_norm": 7.667700265301391e-05,
      "learning_rate": 6.902389371048967e-06,
      "loss": 0.2909,
      "step": 91680
    },
    {
      "epoch": 9.824279438551377,
      "grad_norm": 0.002189593855291605,
      "learning_rate": 6.9009607485981645e-06,
      "loss": 0.0,
      "step": 91690
    },
    {
      "epoch": 9.825350905389477,
      "grad_norm": 0.21624252200126648,
      "learning_rate": 6.899532126147362e-06,
      "loss": 0.1512,
      "step": 91700
    },
    {
      "epoch": 9.82642237222758,
      "grad_norm": 0.0007926851394586265,
      "learning_rate": 6.8981035036965615e-06,
      "loss": 0.0006,
      "step": 91710
    },
    {
      "epoch": 9.827493839065681,
      "grad_norm": 0.00010476196621311828,
      "learning_rate": 6.896674881245759e-06,
      "loss": 0.0,
      "step": 91720
    },
    {
      "epoch": 9.828565305903782,
      "grad_norm": 0.00015836715465411544,
      "learning_rate": 6.895246258794958e-06,
      "loss": 0.0004,
      "step": 91730
    },
    {
      "epoch": 9.829636772741884,
      "grad_norm": 0.00011499534593895078,
      "learning_rate": 6.893817636344155e-06,
      "loss": 0.0007,
      "step": 91740
    },
    {
      "epoch": 9.830708239579986,
      "grad_norm": 0.4992579519748688,
      "learning_rate": 6.892389013893354e-06,
      "loss": 0.0003,
      "step": 91750
    },
    {
      "epoch": 9.831779706418086,
      "grad_norm": 0.0010933908633887768,
      "learning_rate": 6.890960391442552e-06,
      "loss": 0.0,
      "step": 91760
    },
    {
      "epoch": 9.832851173256188,
      "grad_norm": 6.799398397561163e-05,
      "learning_rate": 6.889531768991751e-06,
      "loss": 0.0,
      "step": 91770
    },
    {
      "epoch": 9.83392264009429,
      "grad_norm": 0.27242064476013184,
      "learning_rate": 6.888103146540949e-06,
      "loss": 0.0465,
      "step": 91780
    },
    {
      "epoch": 9.83499410693239,
      "grad_norm": 5.805876571685076e-05,
      "learning_rate": 6.886674524090146e-06,
      "loss": 0.0,
      "step": 91790
    },
    {
      "epoch": 9.836065573770492,
      "grad_norm": 6.81920355418697e-05,
      "learning_rate": 6.885245901639345e-06,
      "loss": 0.0,
      "step": 91800
    },
    {
      "epoch": 9.837137040608592,
      "grad_norm": 0.0009821226121857762,
      "learning_rate": 6.8838172791885425e-06,
      "loss": 0.0001,
      "step": 91810
    },
    {
      "epoch": 9.838208507446694,
      "grad_norm": 6.410809146473184e-05,
      "learning_rate": 6.882388656737741e-06,
      "loss": 0.0,
      "step": 91820
    },
    {
      "epoch": 9.839279974284796,
      "grad_norm": 0.0006026081391610205,
      "learning_rate": 6.8809600342869395e-06,
      "loss": 0.0003,
      "step": 91830
    },
    {
      "epoch": 9.840351441122897,
      "grad_norm": 0.0008174321847036481,
      "learning_rate": 6.879531411836138e-06,
      "loss": 0.0001,
      "step": 91840
    },
    {
      "epoch": 9.841422907960999,
      "grad_norm": 0.0001399226312059909,
      "learning_rate": 6.878102789385336e-06,
      "loss": 0.0005,
      "step": 91850
    },
    {
      "epoch": 9.8424943747991,
      "grad_norm": 0.0031345931347459555,
      "learning_rate": 6.876674166934533e-06,
      "loss": 0.0002,
      "step": 91860
    },
    {
      "epoch": 9.8435658416372,
      "grad_norm": 0.0004803332849405706,
      "learning_rate": 6.875245544483732e-06,
      "loss": 0.0,
      "step": 91870
    },
    {
      "epoch": 9.844637308475303,
      "grad_norm": 8.440275269094855e-05,
      "learning_rate": 6.87381692203293e-06,
      "loss": 0.0,
      "step": 91880
    },
    {
      "epoch": 9.845708775313405,
      "grad_norm": 5.8507830544840544e-05,
      "learning_rate": 6.872388299582129e-06,
      "loss": 0.0,
      "step": 91890
    },
    {
      "epoch": 9.846780242151505,
      "grad_norm": 5.8566522056935355e-05,
      "learning_rate": 6.870959677131327e-06,
      "loss": 0.0001,
      "step": 91900
    },
    {
      "epoch": 9.847851708989607,
      "grad_norm": 0.002653382485732436,
      "learning_rate": 6.869531054680525e-06,
      "loss": 0.157,
      "step": 91910
    },
    {
      "epoch": 9.848923175827709,
      "grad_norm": 0.0003865994221996516,
      "learning_rate": 6.868102432229723e-06,
      "loss": 0.0,
      "step": 91920
    },
    {
      "epoch": 9.84999464266581,
      "grad_norm": 0.1496097445487976,
      "learning_rate": 6.866673809778921e-06,
      "loss": 0.1832,
      "step": 91930
    },
    {
      "epoch": 9.851066109503911,
      "grad_norm": 6.575370935024694e-05,
      "learning_rate": 6.865245187328119e-06,
      "loss": 0.0011,
      "step": 91940
    },
    {
      "epoch": 9.852137576342013,
      "grad_norm": 0.07475939393043518,
      "learning_rate": 6.863816564877318e-06,
      "loss": 0.0,
      "step": 91950
    },
    {
      "epoch": 9.853209043180113,
      "grad_norm": 4.640574479708448e-05,
      "learning_rate": 6.862387942426516e-06,
      "loss": 0.0005,
      "step": 91960
    },
    {
      "epoch": 9.854280510018215,
      "grad_norm": 6.062681131879799e-05,
      "learning_rate": 6.860959319975714e-06,
      "loss": 0.0,
      "step": 91970
    },
    {
      "epoch": 9.855351976856316,
      "grad_norm": 0.0002433062472846359,
      "learning_rate": 6.859530697524912e-06,
      "loss": 0.1425,
      "step": 91980
    },
    {
      "epoch": 9.856423443694418,
      "grad_norm": 0.001964605413377285,
      "learning_rate": 6.85810207507411e-06,
      "loss": 0.2895,
      "step": 91990
    },
    {
      "epoch": 9.85749491053252,
      "grad_norm": 5.1569746574386954e-05,
      "learning_rate": 6.8566734526233084e-06,
      "loss": 0.0,
      "step": 92000
    },
    {
      "epoch": 9.85856637737062,
      "grad_norm": 0.0031383156310766935,
      "learning_rate": 6.855244830172507e-06,
      "loss": 0.241,
      "step": 92010
    },
    {
      "epoch": 9.859637844208722,
      "grad_norm": 0.002846736926585436,
      "learning_rate": 6.8538162077217055e-06,
      "loss": 0.0,
      "step": 92020
    },
    {
      "epoch": 9.860709311046824,
      "grad_norm": 9.078327275346965e-05,
      "learning_rate": 6.852387585270903e-06,
      "loss": 0.0005,
      "step": 92030
    },
    {
      "epoch": 9.861780777884924,
      "grad_norm": 0.008324661292135715,
      "learning_rate": 6.850958962820101e-06,
      "loss": 0.0,
      "step": 92040
    },
    {
      "epoch": 9.862852244723026,
      "grad_norm": 0.0015002231812104583,
      "learning_rate": 6.849530340369299e-06,
      "loss": 0.0,
      "step": 92050
    },
    {
      "epoch": 9.863923711561128,
      "grad_norm": 0.0012224485399201512,
      "learning_rate": 6.848101717918497e-06,
      "loss": 0.0004,
      "step": 92060
    },
    {
      "epoch": 9.864995178399228,
      "grad_norm": 0.06331654638051987,
      "learning_rate": 6.846673095467696e-06,
      "loss": 0.0001,
      "step": 92070
    },
    {
      "epoch": 9.86606664523733,
      "grad_norm": 6.490122905233875e-05,
      "learning_rate": 6.845244473016894e-06,
      "loss": 0.0007,
      "step": 92080
    },
    {
      "epoch": 9.86713811207543,
      "grad_norm": 7.15004134690389e-05,
      "learning_rate": 6.8438158505660926e-06,
      "loss": 0.0006,
      "step": 92090
    },
    {
      "epoch": 9.868209578913532,
      "grad_norm": 0.00014602184819523245,
      "learning_rate": 6.84238722811529e-06,
      "loss": 0.0001,
      "step": 92100
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 6.621654029004276e-05,
      "learning_rate": 6.840958605664488e-06,
      "loss": 0.2454,
      "step": 92110
    },
    {
      "epoch": 9.870352512589735,
      "grad_norm": 7.71870109019801e-05,
      "learning_rate": 6.8395299832136864e-06,
      "loss": 0.0001,
      "step": 92120
    },
    {
      "epoch": 9.871423979427837,
      "grad_norm": 7.859073957661167e-05,
      "learning_rate": 6.838101360762886e-06,
      "loss": 0.1576,
      "step": 92130
    },
    {
      "epoch": 9.872495446265939,
      "grad_norm": 0.007218499202281237,
      "learning_rate": 6.8366727383120835e-06,
      "loss": 0.0,
      "step": 92140
    },
    {
      "epoch": 9.873566913104039,
      "grad_norm": 0.0006295025814324617,
      "learning_rate": 6.835244115861281e-06,
      "loss": 0.0001,
      "step": 92150
    },
    {
      "epoch": 9.87463837994214,
      "grad_norm": 0.00024284390383400023,
      "learning_rate": 6.83381549341048e-06,
      "loss": 0.0,
      "step": 92160
    },
    {
      "epoch": 9.875709846780243,
      "grad_norm": 0.0010145765263587236,
      "learning_rate": 6.832386870959677e-06,
      "loss": 0.0004,
      "step": 92170
    },
    {
      "epoch": 9.876781313618343,
      "grad_norm": 5.367703488445841e-05,
      "learning_rate": 6.830958248508876e-06,
      "loss": 0.0001,
      "step": 92180
    },
    {
      "epoch": 9.877852780456445,
      "grad_norm": 0.0995388776063919,
      "learning_rate": 6.829529626058074e-06,
      "loss": 0.0878,
      "step": 92190
    },
    {
      "epoch": 9.878924247294545,
      "grad_norm": 0.0014729320537298918,
      "learning_rate": 6.828101003607273e-06,
      "loss": 0.0001,
      "step": 92200
    },
    {
      "epoch": 9.879995714132647,
      "grad_norm": 0.008738312870264053,
      "learning_rate": 6.8266723811564706e-06,
      "loss": 0.0,
      "step": 92210
    },
    {
      "epoch": 9.88106718097075,
      "grad_norm": 6.211693835211918e-05,
      "learning_rate": 6.825243758705668e-06,
      "loss": 0.0,
      "step": 92220
    },
    {
      "epoch": 9.88213864780885,
      "grad_norm": 5.831808448419906e-05,
      "learning_rate": 6.823815136254867e-06,
      "loss": 0.0,
      "step": 92230
    },
    {
      "epoch": 9.883210114646952,
      "grad_norm": 0.005176146049052477,
      "learning_rate": 6.8223865138040644e-06,
      "loss": 0.0,
      "step": 92240
    },
    {
      "epoch": 9.884281581485054,
      "grad_norm": 0.001216988661326468,
      "learning_rate": 6.820957891353264e-06,
      "loss": 0.0002,
      "step": 92250
    },
    {
      "epoch": 9.885353048323154,
      "grad_norm": 0.0031104532536119223,
      "learning_rate": 6.8195292689024615e-06,
      "loss": 0.0001,
      "step": 92260
    },
    {
      "epoch": 9.886424515161256,
      "grad_norm": 4.977757635060698e-05,
      "learning_rate": 6.81810064645166e-06,
      "loss": 0.0,
      "step": 92270
    },
    {
      "epoch": 9.887495981999358,
      "grad_norm": 0.0009503719047643244,
      "learning_rate": 6.816672024000858e-06,
      "loss": 0.0004,
      "step": 92280
    },
    {
      "epoch": 9.888567448837458,
      "grad_norm": 6.687568384222686e-05,
      "learning_rate": 6.815243401550055e-06,
      "loss": 0.1181,
      "step": 92290
    },
    {
      "epoch": 9.88963891567556,
      "grad_norm": 6.922772445250303e-05,
      "learning_rate": 6.813814779099254e-06,
      "loss": 0.0003,
      "step": 92300
    },
    {
      "epoch": 9.890710382513662,
      "grad_norm": 0.0028150833677500486,
      "learning_rate": 6.812386156648453e-06,
      "loss": 0.0001,
      "step": 92310
    },
    {
      "epoch": 9.891781849351762,
      "grad_norm": 4.959600482834503e-05,
      "learning_rate": 6.810957534197651e-06,
      "loss": 0.0,
      "step": 92320
    },
    {
      "epoch": 9.892853316189864,
      "grad_norm": 5.0669157644733787e-05,
      "learning_rate": 6.8095289117468486e-06,
      "loss": 0.0,
      "step": 92330
    },
    {
      "epoch": 9.893924783027966,
      "grad_norm": 8.074553625192493e-05,
      "learning_rate": 6.808100289296047e-06,
      "loss": 0.0,
      "step": 92340
    },
    {
      "epoch": 9.894996249866066,
      "grad_norm": 0.004252440296113491,
      "learning_rate": 6.806671666845245e-06,
      "loss": 0.0,
      "step": 92350
    },
    {
      "epoch": 9.896067716704168,
      "grad_norm": 0.000605711480602622,
      "learning_rate": 6.8052430443944424e-06,
      "loss": 0.0,
      "step": 92360
    },
    {
      "epoch": 9.897139183542269,
      "grad_norm": 18.545669555664062,
      "learning_rate": 6.803814421943642e-06,
      "loss": 0.1268,
      "step": 92370
    },
    {
      "epoch": 9.89821065038037,
      "grad_norm": 6.208217382663861e-05,
      "learning_rate": 6.80238579949284e-06,
      "loss": 0.0002,
      "step": 92380
    },
    {
      "epoch": 9.899282117218473,
      "grad_norm": 6.666728586424142e-05,
      "learning_rate": 6.800957177042038e-06,
      "loss": 0.0,
      "step": 92390
    },
    {
      "epoch": 9.900353584056573,
      "grad_norm": 0.222969189286232,
      "learning_rate": 6.799528554591236e-06,
      "loss": 0.0007,
      "step": 92400
    },
    {
      "epoch": 9.901425050894675,
      "grad_norm": 0.017741456627845764,
      "learning_rate": 6.798099932140434e-06,
      "loss": 0.0,
      "step": 92410
    },
    {
      "epoch": 9.902496517732777,
      "grad_norm": 6.593650323338807e-05,
      "learning_rate": 6.796671309689632e-06,
      "loss": 0.0,
      "step": 92420
    },
    {
      "epoch": 9.903567984570877,
      "grad_norm": 6.303077680058777e-05,
      "learning_rate": 6.79524268723883e-06,
      "loss": 0.0,
      "step": 92430
    },
    {
      "epoch": 9.904639451408979,
      "grad_norm": 5.404779585660435e-05,
      "learning_rate": 6.793814064788029e-06,
      "loss": 0.3372,
      "step": 92440
    },
    {
      "epoch": 9.905710918247081,
      "grad_norm": 0.005813976749777794,
      "learning_rate": 6.792385442337227e-06,
      "loss": 0.0,
      "step": 92450
    },
    {
      "epoch": 9.906782385085181,
      "grad_norm": 8.673363481648266e-05,
      "learning_rate": 6.790956819886425e-06,
      "loss": 0.0,
      "step": 92460
    },
    {
      "epoch": 9.907853851923283,
      "grad_norm": 0.3497169315814972,
      "learning_rate": 6.789528197435623e-06,
      "loss": 0.0002,
      "step": 92470
    },
    {
      "epoch": 9.908925318761383,
      "grad_norm": 9.386675810674205e-05,
      "learning_rate": 6.788099574984821e-06,
      "loss": 0.0,
      "step": 92480
    },
    {
      "epoch": 9.909996785599485,
      "grad_norm": 0.00011363029625499621,
      "learning_rate": 6.786670952534019e-06,
      "loss": 0.0,
      "step": 92490
    },
    {
      "epoch": 9.911068252437587,
      "grad_norm": 0.0005904313875362277,
      "learning_rate": 6.785242330083218e-06,
      "loss": 0.1642,
      "step": 92500
    },
    {
      "epoch": 9.912139719275688,
      "grad_norm": 8.411041926592588e-05,
      "learning_rate": 6.783813707632416e-06,
      "loss": 0.0,
      "step": 92510
    },
    {
      "epoch": 9.91321118611379,
      "grad_norm": 8.197794522857293e-05,
      "learning_rate": 6.7823850851816145e-06,
      "loss": 0.0014,
      "step": 92520
    },
    {
      "epoch": 9.914282652951892,
      "grad_norm": 8.218257426051423e-05,
      "learning_rate": 6.780956462730812e-06,
      "loss": 0.0091,
      "step": 92530
    },
    {
      "epoch": 9.915354119789992,
      "grad_norm": 5.890974716749042e-05,
      "learning_rate": 6.77952784028001e-06,
      "loss": 0.0003,
      "step": 92540
    },
    {
      "epoch": 9.916425586628094,
      "grad_norm": 6.885687616886571e-05,
      "learning_rate": 6.778099217829208e-06,
      "loss": 0.0001,
      "step": 92550
    },
    {
      "epoch": 9.917497053466196,
      "grad_norm": 0.000554486527107656,
      "learning_rate": 6.776670595378408e-06,
      "loss": 0.0,
      "step": 92560
    },
    {
      "epoch": 9.918568520304296,
      "grad_norm": 6.221132207429036e-05,
      "learning_rate": 6.775241972927605e-06,
      "loss": 0.0003,
      "step": 92570
    },
    {
      "epoch": 9.919639987142398,
      "grad_norm": 0.0017338161123916507,
      "learning_rate": 6.773813350476803e-06,
      "loss": 0.0006,
      "step": 92580
    },
    {
      "epoch": 9.920711453980498,
      "grad_norm": 5.218503429205157e-05,
      "learning_rate": 6.772384728026002e-06,
      "loss": 0.0,
      "step": 92590
    },
    {
      "epoch": 9.9217829208186,
      "grad_norm": 5.335767855285667e-05,
      "learning_rate": 6.770956105575199e-06,
      "loss": 0.0001,
      "step": 92600
    },
    {
      "epoch": 9.922854387656702,
      "grad_norm": 5.962306750006974e-05,
      "learning_rate": 6.769527483124397e-06,
      "loss": 0.0002,
      "step": 92610
    },
    {
      "epoch": 9.923925854494803,
      "grad_norm": 0.00010609766468405724,
      "learning_rate": 6.768098860673596e-06,
      "loss": 0.0,
      "step": 92620
    },
    {
      "epoch": 9.924997321332905,
      "grad_norm": 0.3379358947277069,
      "learning_rate": 6.766670238222795e-06,
      "loss": 0.1642,
      "step": 92630
    },
    {
      "epoch": 9.926068788171007,
      "grad_norm": 4.799565067514777e-05,
      "learning_rate": 6.7652416157719925e-06,
      "loss": 0.0001,
      "step": 92640
    },
    {
      "epoch": 9.927140255009107,
      "grad_norm": 0.0008638366707600653,
      "learning_rate": 6.76381299332119e-06,
      "loss": 0.0001,
      "step": 92650
    },
    {
      "epoch": 9.928211721847209,
      "grad_norm": 0.004622871521860361,
      "learning_rate": 6.762384370870389e-06,
      "loss": 0.0001,
      "step": 92660
    },
    {
      "epoch": 9.92928318868531,
      "grad_norm": 5.6594562920508906e-05,
      "learning_rate": 6.760955748419586e-06,
      "loss": 0.0,
      "step": 92670
    },
    {
      "epoch": 9.930354655523411,
      "grad_norm": 7.430337427649647e-05,
      "learning_rate": 6.759527125968786e-06,
      "loss": 0.0001,
      "step": 92680
    },
    {
      "epoch": 9.931426122361513,
      "grad_norm": 7.631352491443977e-05,
      "learning_rate": 6.758098503517983e-06,
      "loss": 0.2047,
      "step": 92690
    },
    {
      "epoch": 9.932497589199615,
      "grad_norm": 0.0006689747096970677,
      "learning_rate": 6.756669881067182e-06,
      "loss": 0.1637,
      "step": 92700
    },
    {
      "epoch": 9.933569056037715,
      "grad_norm": 9.230423165718094e-05,
      "learning_rate": 6.75524125861638e-06,
      "loss": 0.0,
      "step": 92710
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 0.0013341434532776475,
      "learning_rate": 6.753812636165577e-06,
      "loss": 0.0,
      "step": 92720
    },
    {
      "epoch": 9.93571198971392,
      "grad_norm": 0.03601008281111717,
      "learning_rate": 6.752384013714776e-06,
      "loss": 0.0,
      "step": 92730
    },
    {
      "epoch": 9.93678345655202,
      "grad_norm": 6.510171806439757e-05,
      "learning_rate": 6.750955391263974e-06,
      "loss": 0.0002,
      "step": 92740
    },
    {
      "epoch": 9.937854923390121,
      "grad_norm": 0.004122427199035883,
      "learning_rate": 6.749526768813173e-06,
      "loss": 0.0,
      "step": 92750
    },
    {
      "epoch": 9.938926390228222,
      "grad_norm": 5.653639527736232e-05,
      "learning_rate": 6.7480981463623705e-06,
      "loss": 0.0,
      "step": 92760
    },
    {
      "epoch": 9.939997857066324,
      "grad_norm": 6.654141907347366e-05,
      "learning_rate": 6.746669523911569e-06,
      "loss": 0.3381,
      "step": 92770
    },
    {
      "epoch": 9.941069323904426,
      "grad_norm": 6.713862239848822e-05,
      "learning_rate": 6.745240901460767e-06,
      "loss": 0.0,
      "step": 92780
    },
    {
      "epoch": 9.942140790742526,
      "grad_norm": 7.504389941459522e-05,
      "learning_rate": 6.743812279009964e-06,
      "loss": 0.0001,
      "step": 92790
    },
    {
      "epoch": 9.943212257580628,
      "grad_norm": 0.0037289417814463377,
      "learning_rate": 6.742383656559164e-06,
      "loss": 0.0,
      "step": 92800
    },
    {
      "epoch": 9.94428372441873,
      "grad_norm": 6.361323175951838e-05,
      "learning_rate": 6.740955034108361e-06,
      "loss": 0.0009,
      "step": 92810
    },
    {
      "epoch": 9.94535519125683,
      "grad_norm": 6.21853323536925e-05,
      "learning_rate": 6.73952641165756e-06,
      "loss": 0.0,
      "step": 92820
    },
    {
      "epoch": 9.946426658094932,
      "grad_norm": 0.0025074935983866453,
      "learning_rate": 6.738097789206758e-06,
      "loss": 0.0004,
      "step": 92830
    },
    {
      "epoch": 9.947498124933034,
      "grad_norm": 4.544520561466925e-05,
      "learning_rate": 6.736669166755956e-06,
      "loss": 0.0,
      "step": 92840
    },
    {
      "epoch": 9.948569591771134,
      "grad_norm": 7.420641486532986e-05,
      "learning_rate": 6.735240544305154e-06,
      "loss": 0.1721,
      "step": 92850
    },
    {
      "epoch": 9.949641058609236,
      "grad_norm": 0.0008753256406635046,
      "learning_rate": 6.733811921854353e-06,
      "loss": 0.0,
      "step": 92860
    },
    {
      "epoch": 9.950712525447337,
      "grad_norm": 5.166504342923872e-05,
      "learning_rate": 6.732383299403551e-06,
      "loss": 0.0001,
      "step": 92870
    },
    {
      "epoch": 9.951783992285439,
      "grad_norm": 5.860915916855447e-05,
      "learning_rate": 6.730954676952749e-06,
      "loss": 0.0,
      "step": 92880
    },
    {
      "epoch": 9.95285545912354,
      "grad_norm": 5.598272036877461e-05,
      "learning_rate": 6.729526054501947e-06,
      "loss": 0.1651,
      "step": 92890
    },
    {
      "epoch": 9.95392692596164,
      "grad_norm": 0.002343491418287158,
      "learning_rate": 6.728097432051145e-06,
      "loss": 0.0001,
      "step": 92900
    },
    {
      "epoch": 9.954998392799743,
      "grad_norm": 0.021733617410063744,
      "learning_rate": 6.726668809600343e-06,
      "loss": 0.0,
      "step": 92910
    },
    {
      "epoch": 9.956069859637845,
      "grad_norm": 0.00021217514586169273,
      "learning_rate": 6.725240187149542e-06,
      "loss": 0.0,
      "step": 92920
    },
    {
      "epoch": 9.957141326475945,
      "grad_norm": 8.409378642681986e-05,
      "learning_rate": 6.72381156469874e-06,
      "loss": 0.2977,
      "step": 92930
    },
    {
      "epoch": 9.958212793314047,
      "grad_norm": 0.0016294788802042603,
      "learning_rate": 6.722382942247938e-06,
      "loss": 0.0,
      "step": 92940
    },
    {
      "epoch": 9.959284260152149,
      "grad_norm": 5.359526403481141e-05,
      "learning_rate": 6.7209543197971365e-06,
      "loss": 0.0001,
      "step": 92950
    },
    {
      "epoch": 9.96035572699025,
      "grad_norm": 0.0016557157505303621,
      "learning_rate": 6.719525697346334e-06,
      "loss": 0.0,
      "step": 92960
    },
    {
      "epoch": 9.961427193828351,
      "grad_norm": 7.827601075405255e-05,
      "learning_rate": 6.718097074895532e-06,
      "loss": 0.0014,
      "step": 92970
    },
    {
      "epoch": 9.962498660666453,
      "grad_norm": 0.002201716648414731,
      "learning_rate": 6.716668452444731e-06,
      "loss": 0.0007,
      "step": 92980
    },
    {
      "epoch": 9.963570127504553,
      "grad_norm": 6.221959483809769e-05,
      "learning_rate": 6.715239829993929e-06,
      "loss": 0.3259,
      "step": 92990
    },
    {
      "epoch": 9.964641594342655,
      "grad_norm": 6.841509457444772e-05,
      "learning_rate": 6.713811207543127e-06,
      "loss": 0.0,
      "step": 93000
    },
    {
      "epoch": 9.965713061180757,
      "grad_norm": 5.553437949856743e-05,
      "learning_rate": 6.712382585092325e-06,
      "loss": 0.0,
      "step": 93010
    },
    {
      "epoch": 9.966784528018858,
      "grad_norm": 0.0019383030012249947,
      "learning_rate": 6.7109539626415236e-06,
      "loss": 0.3766,
      "step": 93020
    },
    {
      "epoch": 9.96785599485696,
      "grad_norm": 22.89752769470215,
      "learning_rate": 6.709525340190721e-06,
      "loss": 0.1704,
      "step": 93030
    },
    {
      "epoch": 9.96892746169506,
      "grad_norm": 0.0012347032316029072,
      "learning_rate": 6.708096717739921e-06,
      "loss": 0.0002,
      "step": 93040
    },
    {
      "epoch": 9.969998928533162,
      "grad_norm": 0.0034606102854013443,
      "learning_rate": 6.706668095289118e-06,
      "loss": 0.1621,
      "step": 93050
    },
    {
      "epoch": 9.971070395371264,
      "grad_norm": 0.00017724755161907524,
      "learning_rate": 6.705239472838316e-06,
      "loss": 0.0016,
      "step": 93060
    },
    {
      "epoch": 9.972141862209364,
      "grad_norm": 0.00046453721006400883,
      "learning_rate": 6.7038108503875145e-06,
      "loss": 0.0002,
      "step": 93070
    },
    {
      "epoch": 9.973213329047466,
      "grad_norm": 0.012029353529214859,
      "learning_rate": 6.702382227936712e-06,
      "loss": 0.0,
      "step": 93080
    },
    {
      "epoch": 9.974284795885568,
      "grad_norm": 9.423477604286745e-05,
      "learning_rate": 6.700953605485911e-06,
      "loss": 0.0,
      "step": 93090
    },
    {
      "epoch": 9.975356262723668,
      "grad_norm": 9.101093019125983e-05,
      "learning_rate": 6.699524983035109e-06,
      "loss": 0.0002,
      "step": 93100
    },
    {
      "epoch": 9.97642772956177,
      "grad_norm": 0.005342711694538593,
      "learning_rate": 6.698096360584308e-06,
      "loss": 0.0076,
      "step": 93110
    },
    {
      "epoch": 9.977499196399872,
      "grad_norm": 0.00013321438746061176,
      "learning_rate": 6.696667738133505e-06,
      "loss": 0.0001,
      "step": 93120
    },
    {
      "epoch": 9.978570663237972,
      "grad_norm": 0.0031697971280664206,
      "learning_rate": 6.695239115682704e-06,
      "loss": 0.0,
      "step": 93130
    },
    {
      "epoch": 9.979642130076074,
      "grad_norm": 0.00014871684834361076,
      "learning_rate": 6.6938104932319016e-06,
      "loss": 0.0001,
      "step": 93140
    },
    {
      "epoch": 9.980713596914175,
      "grad_norm": 0.00011142310540890321,
      "learning_rate": 6.692381870781099e-06,
      "loss": 0.0,
      "step": 93150
    },
    {
      "epoch": 9.981785063752277,
      "grad_norm": 0.00408678874373436,
      "learning_rate": 6.690953248330299e-06,
      "loss": 0.0001,
      "step": 93160
    },
    {
      "epoch": 9.982856530590379,
      "grad_norm": 0.0017704623751342297,
      "learning_rate": 6.689524625879496e-06,
      "loss": 0.0,
      "step": 93170
    },
    {
      "epoch": 9.983927997428479,
      "grad_norm": 0.021497026085853577,
      "learning_rate": 6.688096003428695e-06,
      "loss": 0.0001,
      "step": 93180
    },
    {
      "epoch": 9.984999464266581,
      "grad_norm": 7.987467688508332e-05,
      "learning_rate": 6.6866673809778925e-06,
      "loss": 0.4424,
      "step": 93190
    },
    {
      "epoch": 9.986070931104683,
      "grad_norm": 8.449215965811163e-05,
      "learning_rate": 6.685238758527091e-06,
      "loss": 0.159,
      "step": 93200
    },
    {
      "epoch": 9.987142397942783,
      "grad_norm": 7.046440441627055e-05,
      "learning_rate": 6.683810136076289e-06,
      "loss": 0.0001,
      "step": 93210
    },
    {
      "epoch": 9.988213864780885,
      "grad_norm": 5.610129301203415e-05,
      "learning_rate": 6.682381513625488e-06,
      "loss": 0.0003,
      "step": 93220
    },
    {
      "epoch": 9.989285331618987,
      "grad_norm": 0.00017508550081402063,
      "learning_rate": 6.680952891174686e-06,
      "loss": 0.0,
      "step": 93230
    },
    {
      "epoch": 9.990356798457087,
      "grad_norm": 6.294831109698862e-05,
      "learning_rate": 6.679524268723883e-06,
      "loss": 0.0012,
      "step": 93240
    },
    {
      "epoch": 9.99142826529519,
      "grad_norm": 8.634421828901395e-05,
      "learning_rate": 6.678095646273082e-06,
      "loss": 0.0005,
      "step": 93250
    },
    {
      "epoch": 9.99249973213329,
      "grad_norm": 0.0009409344638697803,
      "learning_rate": 6.6766670238222796e-06,
      "loss": 0.0035,
      "step": 93260
    },
    {
      "epoch": 9.993571198971392,
      "grad_norm": 7.091866427799687e-05,
      "learning_rate": 6.675238401371478e-06,
      "loss": 0.0001,
      "step": 93270
    },
    {
      "epoch": 9.994642665809494,
      "grad_norm": 0.0006143294158391654,
      "learning_rate": 6.673809778920677e-06,
      "loss": 0.0002,
      "step": 93280
    },
    {
      "epoch": 9.995714132647594,
      "grad_norm": 0.0006444553146138787,
      "learning_rate": 6.672381156469875e-06,
      "loss": 0.0,
      "step": 93290
    },
    {
      "epoch": 9.996785599485696,
      "grad_norm": 0.007157846819609404,
      "learning_rate": 6.670952534019073e-06,
      "loss": 0.0004,
      "step": 93300
    },
    {
      "epoch": 9.997857066323798,
      "grad_norm": 0.004504438955336809,
      "learning_rate": 6.6695239115682705e-06,
      "loss": 0.0007,
      "step": 93310
    },
    {
      "epoch": 9.998928533161898,
      "grad_norm": 5.531856731977314e-05,
      "learning_rate": 6.668095289117469e-06,
      "loss": 0.0,
      "step": 93320
    },
    {
      "epoch": 10.0,
      "grad_norm": 7.128225115593523e-05,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.1466,
      "step": 93330
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9791666666666666,
      "eval_f1": 0.9182472204054938,
      "eval_loss": 0.16232506930828094,
      "eval_precision": 0.9093264248704663,
      "eval_recall": 0.9273447820343461,
      "eval_runtime": 391.8506,
      "eval_samples_per_second": 15.312,
      "eval_steps_per_second": 5.104,
      "step": 93330
    },
    {
      "epoch": 10.001071466838102,
      "grad_norm": 7.222079148050398e-05,
      "learning_rate": 6.665238044215865e-06,
      "loss": 0.0,
      "step": 93340
    },
    {
      "epoch": 10.002142933676202,
      "grad_norm": 0.3930867910385132,
      "learning_rate": 6.663809421765064e-06,
      "loss": 0.0013,
      "step": 93350
    },
    {
      "epoch": 10.003214400514304,
      "grad_norm": 0.003445039037615061,
      "learning_rate": 6.662380799314262e-06,
      "loss": 0.0008,
      "step": 93360
    },
    {
      "epoch": 10.004285867352406,
      "grad_norm": 6.358055543387309e-05,
      "learning_rate": 6.66095217686346e-06,
      "loss": 0.0,
      "step": 93370
    },
    {
      "epoch": 10.005357334190506,
      "grad_norm": 0.005241831764578819,
      "learning_rate": 6.6595235544126576e-06,
      "loss": 0.0001,
      "step": 93380
    },
    {
      "epoch": 10.006428801028608,
      "grad_norm": 9.726431017043069e-05,
      "learning_rate": 6.658094931961856e-06,
      "loss": 0.0001,
      "step": 93390
    },
    {
      "epoch": 10.007500267866709,
      "grad_norm": 0.0007903225487098098,
      "learning_rate": 6.656666309511054e-06,
      "loss": 0.0,
      "step": 93400
    },
    {
      "epoch": 10.00857173470481,
      "grad_norm": 7.183429261203855e-05,
      "learning_rate": 6.655237687060253e-06,
      "loss": 0.1443,
      "step": 93410
    },
    {
      "epoch": 10.009643201542913,
      "grad_norm": 7.140926754800603e-05,
      "learning_rate": 6.653809064609451e-06,
      "loss": 0.0,
      "step": 93420
    },
    {
      "epoch": 10.010714668381013,
      "grad_norm": 0.024431021884083748,
      "learning_rate": 6.652380442158649e-06,
      "loss": 0.0001,
      "step": 93430
    },
    {
      "epoch": 10.011786135219115,
      "grad_norm": 6.156847666716203e-05,
      "learning_rate": 6.650951819707847e-06,
      "loss": 0.0001,
      "step": 93440
    },
    {
      "epoch": 10.012857602057217,
      "grad_norm": 0.001971777994185686,
      "learning_rate": 6.6495231972570455e-06,
      "loss": 0.0,
      "step": 93450
    },
    {
      "epoch": 10.013929068895317,
      "grad_norm": 0.001343075535260141,
      "learning_rate": 6.648094574806243e-06,
      "loss": 0.0001,
      "step": 93460
    },
    {
      "epoch": 10.015000535733419,
      "grad_norm": 0.0005776415346190333,
      "learning_rate": 6.6466659523554425e-06,
      "loss": 0.0003,
      "step": 93470
    },
    {
      "epoch": 10.016072002571521,
      "grad_norm": 6.142014171928167e-05,
      "learning_rate": 6.64523732990464e-06,
      "loss": 0.0001,
      "step": 93480
    },
    {
      "epoch": 10.017143469409621,
      "grad_norm": 0.0006586667150259018,
      "learning_rate": 6.643808707453838e-06,
      "loss": 0.0,
      "step": 93490
    },
    {
      "epoch": 10.018214936247723,
      "grad_norm": 4.673928197007626e-05,
      "learning_rate": 6.642380085003036e-06,
      "loss": 0.0,
      "step": 93500
    },
    {
      "epoch": 10.019286403085825,
      "grad_norm": 0.20967818796634674,
      "learning_rate": 6.640951462552234e-06,
      "loss": 0.0005,
      "step": 93510
    },
    {
      "epoch": 10.020357869923926,
      "grad_norm": 0.0006601855857297778,
      "learning_rate": 6.639522840101433e-06,
      "loss": 0.0003,
      "step": 93520
    },
    {
      "epoch": 10.021429336762028,
      "grad_norm": 5.2980325563112274e-05,
      "learning_rate": 6.638094217650631e-06,
      "loss": 0.0002,
      "step": 93530
    },
    {
      "epoch": 10.022500803600128,
      "grad_norm": 5.048891034675762e-05,
      "learning_rate": 6.63666559519983e-06,
      "loss": 0.0,
      "step": 93540
    },
    {
      "epoch": 10.02357227043823,
      "grad_norm": 0.009436044842004776,
      "learning_rate": 6.635236972749027e-06,
      "loss": 0.0,
      "step": 93550
    },
    {
      "epoch": 10.024643737276332,
      "grad_norm": 4.955185795552097e-05,
      "learning_rate": 6.633808350298225e-06,
      "loss": 0.0,
      "step": 93560
    },
    {
      "epoch": 10.025715204114432,
      "grad_norm": 0.004401064477860928,
      "learning_rate": 6.6323797278474235e-06,
      "loss": 0.0,
      "step": 93570
    },
    {
      "epoch": 10.026786670952534,
      "grad_norm": 5.379754657042213e-05,
      "learning_rate": 6.630951105396621e-06,
      "loss": 0.0,
      "step": 93580
    },
    {
      "epoch": 10.027858137790636,
      "grad_norm": 5.8073543186765164e-05,
      "learning_rate": 6.6295224829458205e-06,
      "loss": 0.0,
      "step": 93590
    },
    {
      "epoch": 10.028929604628736,
      "grad_norm": 4.9243633839068934e-05,
      "learning_rate": 6.628093860495018e-06,
      "loss": 0.0,
      "step": 93600
    },
    {
      "epoch": 10.030001071466838,
      "grad_norm": 6.444678729167208e-05,
      "learning_rate": 6.626665238044217e-06,
      "loss": 0.0004,
      "step": 93610
    },
    {
      "epoch": 10.03107253830494,
      "grad_norm": 5.018524097977206e-05,
      "learning_rate": 6.625236615593414e-06,
      "loss": 0.0001,
      "step": 93620
    },
    {
      "epoch": 10.03214400514304,
      "grad_norm": 0.0023612636141479015,
      "learning_rate": 6.623807993142612e-06,
      "loss": 0.0,
      "step": 93630
    },
    {
      "epoch": 10.033215471981142,
      "grad_norm": 0.011508232913911343,
      "learning_rate": 6.622379370691811e-06,
      "loss": 0.0,
      "step": 93640
    },
    {
      "epoch": 10.034286938819244,
      "grad_norm": 0.0029903657268732786,
      "learning_rate": 6.62095074824101e-06,
      "loss": 0.3232,
      "step": 93650
    },
    {
      "epoch": 10.035358405657345,
      "grad_norm": 0.010879714973270893,
      "learning_rate": 6.619522125790208e-06,
      "loss": 0.0002,
      "step": 93660
    },
    {
      "epoch": 10.036429872495447,
      "grad_norm": 0.0006923150504007936,
      "learning_rate": 6.618093503339405e-06,
      "loss": 0.1409,
      "step": 93670
    },
    {
      "epoch": 10.037501339333547,
      "grad_norm": 19.66727066040039,
      "learning_rate": 6.616664880888604e-06,
      "loss": 0.1573,
      "step": 93680
    },
    {
      "epoch": 10.038572806171649,
      "grad_norm": 6.314260826911777e-05,
      "learning_rate": 6.6152362584378015e-06,
      "loss": 0.1457,
      "step": 93690
    },
    {
      "epoch": 10.03964427300975,
      "grad_norm": 13.971969604492188,
      "learning_rate": 6.613807635987e-06,
      "loss": 0.1245,
      "step": 93700
    },
    {
      "epoch": 10.040715739847851,
      "grad_norm": 0.002030021511018276,
      "learning_rate": 6.6123790135361985e-06,
      "loss": 0.0,
      "step": 93710
    },
    {
      "epoch": 10.041787206685953,
      "grad_norm": 0.00019068384426645935,
      "learning_rate": 6.610950391085397e-06,
      "loss": 0.0,
      "step": 93720
    },
    {
      "epoch": 10.042858673524055,
      "grad_norm": 0.056923720985651016,
      "learning_rate": 6.609521768634595e-06,
      "loss": 0.0,
      "step": 93730
    },
    {
      "epoch": 10.043930140362155,
      "grad_norm": 0.0001232228532899171,
      "learning_rate": 6.608093146183792e-06,
      "loss": 0.0001,
      "step": 93740
    },
    {
      "epoch": 10.045001607200257,
      "grad_norm": 6.792425119783729e-05,
      "learning_rate": 6.606664523732991e-06,
      "loss": 0.0,
      "step": 93750
    },
    {
      "epoch": 10.04607307403836,
      "grad_norm": 6.300918175838888e-05,
      "learning_rate": 6.605235901282189e-06,
      "loss": 0.0,
      "step": 93760
    },
    {
      "epoch": 10.04714454087646,
      "grad_norm": 5.894163768971339e-05,
      "learning_rate": 6.603807278831388e-06,
      "loss": 0.0,
      "step": 93770
    },
    {
      "epoch": 10.048216007714561,
      "grad_norm": 7.486190588679165e-05,
      "learning_rate": 6.602378656380586e-06,
      "loss": 0.1095,
      "step": 93780
    },
    {
      "epoch": 10.049287474552663,
      "grad_norm": 0.0937594547867775,
      "learning_rate": 6.600950033929784e-06,
      "loss": 0.102,
      "step": 93790
    },
    {
      "epoch": 10.050358941390764,
      "grad_norm": 7.424310024362057e-05,
      "learning_rate": 6.599521411478982e-06,
      "loss": 0.0,
      "step": 93800
    },
    {
      "epoch": 10.051430408228866,
      "grad_norm": 0.003863109275698662,
      "learning_rate": 6.5980927890281795e-06,
      "loss": 0.0003,
      "step": 93810
    },
    {
      "epoch": 10.052501875066966,
      "grad_norm": 0.001819087890908122,
      "learning_rate": 6.596664166577378e-06,
      "loss": 0.0,
      "step": 93820
    },
    {
      "epoch": 10.053573341905068,
      "grad_norm": 5.1519386033760384e-05,
      "learning_rate": 6.595235544126577e-06,
      "loss": 0.0,
      "step": 93830
    },
    {
      "epoch": 10.05464480874317,
      "grad_norm": 0.0011791478609666228,
      "learning_rate": 6.593806921675775e-06,
      "loss": 0.1517,
      "step": 93840
    },
    {
      "epoch": 10.05571627558127,
      "grad_norm": 5.828771099913865e-05,
      "learning_rate": 6.592378299224973e-06,
      "loss": 0.0,
      "step": 93850
    },
    {
      "epoch": 10.056787742419372,
      "grad_norm": 5.3576877689920366e-05,
      "learning_rate": 6.590949676774171e-06,
      "loss": 0.0842,
      "step": 93860
    },
    {
      "epoch": 10.057859209257474,
      "grad_norm": 6.630738789681345e-05,
      "learning_rate": 6.589521054323369e-06,
      "loss": 0.0,
      "step": 93870
    },
    {
      "epoch": 10.058930676095574,
      "grad_norm": 0.003587912069633603,
      "learning_rate": 6.588092431872567e-06,
      "loss": 0.0,
      "step": 93880
    },
    {
      "epoch": 10.060002142933676,
      "grad_norm": 6.378151010721922e-05,
      "learning_rate": 6.586663809421766e-06,
      "loss": 0.0,
      "step": 93890
    },
    {
      "epoch": 10.061073609771778,
      "grad_norm": 5.81715939915739e-05,
      "learning_rate": 6.5852351869709645e-06,
      "loss": 0.0746,
      "step": 93900
    },
    {
      "epoch": 10.062145076609879,
      "grad_norm": 5.7817331253318116e-05,
      "learning_rate": 6.583806564520162e-06,
      "loss": 0.0,
      "step": 93910
    },
    {
      "epoch": 10.06321654344798,
      "grad_norm": 0.00025625506532378495,
      "learning_rate": 6.58237794206936e-06,
      "loss": 0.0,
      "step": 93920
    },
    {
      "epoch": 10.06428801028608,
      "grad_norm": 0.0015715520130470395,
      "learning_rate": 6.580949319618558e-06,
      "loss": 0.001,
      "step": 93930
    },
    {
      "epoch": 10.065359477124183,
      "grad_norm": 6.821865099482238e-05,
      "learning_rate": 6.579520697167756e-06,
      "loss": 0.1563,
      "step": 93940
    },
    {
      "epoch": 10.066430943962285,
      "grad_norm": 0.04772092029452324,
      "learning_rate": 6.578092074716955e-06,
      "loss": 0.0081,
      "step": 93950
    },
    {
      "epoch": 10.067502410800385,
      "grad_norm": 8.812743908492848e-05,
      "learning_rate": 6.576663452266153e-06,
      "loss": 0.0,
      "step": 93960
    },
    {
      "epoch": 10.068573877638487,
      "grad_norm": 6.000542634865269e-05,
      "learning_rate": 6.5752348298153516e-06,
      "loss": 0.0,
      "step": 93970
    },
    {
      "epoch": 10.069645344476589,
      "grad_norm": 7.62698327889666e-05,
      "learning_rate": 6.573806207364549e-06,
      "loss": 0.0,
      "step": 93980
    },
    {
      "epoch": 10.07071681131469,
      "grad_norm": 0.004740165080875158,
      "learning_rate": 6.572377584913747e-06,
      "loss": 0.0,
      "step": 93990
    },
    {
      "epoch": 10.071788278152791,
      "grad_norm": 0.0012064818292856216,
      "learning_rate": 6.5709489624629454e-06,
      "loss": 0.0738,
      "step": 94000
    },
    {
      "epoch": 10.072859744990893,
      "grad_norm": 0.0010669706389307976,
      "learning_rate": 6.569520340012144e-06,
      "loss": 0.0703,
      "step": 94010
    },
    {
      "epoch": 10.073931211828993,
      "grad_norm": 31.750280380249023,
      "learning_rate": 6.5680917175613425e-06,
      "loss": 0.0306,
      "step": 94020
    },
    {
      "epoch": 10.075002678667095,
      "grad_norm": 6.438852869905531e-05,
      "learning_rate": 6.56666309511054e-06,
      "loss": 0.0,
      "step": 94030
    },
    {
      "epoch": 10.076074145505197,
      "grad_norm": 0.0005435306811705232,
      "learning_rate": 6.565234472659739e-06,
      "loss": 0.0,
      "step": 94040
    },
    {
      "epoch": 10.077145612343298,
      "grad_norm": 0.0014815888134762645,
      "learning_rate": 6.563805850208936e-06,
      "loss": 0.0007,
      "step": 94050
    },
    {
      "epoch": 10.0782170791814,
      "grad_norm": 0.0008912408957257867,
      "learning_rate": 6.562377227758134e-06,
      "loss": 0.0,
      "step": 94060
    },
    {
      "epoch": 10.0792885460195,
      "grad_norm": 0.34879547357559204,
      "learning_rate": 6.560948605307333e-06,
      "loss": 0.1437,
      "step": 94070
    },
    {
      "epoch": 10.080360012857602,
      "grad_norm": 7.173046469688416e-05,
      "learning_rate": 6.559519982856531e-06,
      "loss": 0.0801,
      "step": 94080
    },
    {
      "epoch": 10.081431479695704,
      "grad_norm": 0.0017329343827441335,
      "learning_rate": 6.5580913604057296e-06,
      "loss": 0.0,
      "step": 94090
    },
    {
      "epoch": 10.082502946533804,
      "grad_norm": 6.140538607724011e-05,
      "learning_rate": 6.556662737954927e-06,
      "loss": 0.0,
      "step": 94100
    },
    {
      "epoch": 10.083574413371906,
      "grad_norm": 0.0006281505920924246,
      "learning_rate": 6.555234115504126e-06,
      "loss": 0.0,
      "step": 94110
    },
    {
      "epoch": 10.084645880210008,
      "grad_norm": 0.0004404709907248616,
      "learning_rate": 6.5538054930533234e-06,
      "loss": 0.0,
      "step": 94120
    },
    {
      "epoch": 10.085717347048108,
      "grad_norm": 0.3424987196922302,
      "learning_rate": 6.552376870602523e-06,
      "loss": 0.0002,
      "step": 94130
    },
    {
      "epoch": 10.08678881388621,
      "grad_norm": 0.0010919596534222364,
      "learning_rate": 6.5509482481517205e-06,
      "loss": 0.0,
      "step": 94140
    },
    {
      "epoch": 10.087860280724312,
      "grad_norm": 6.427407788578421e-05,
      "learning_rate": 6.549519625700919e-06,
      "loss": 0.0034,
      "step": 94150
    },
    {
      "epoch": 10.088931747562413,
      "grad_norm": 5.6694349041208625e-05,
      "learning_rate": 6.548091003250117e-06,
      "loss": 0.0025,
      "step": 94160
    },
    {
      "epoch": 10.090003214400515,
      "grad_norm": 5.1000733947148547e-05,
      "learning_rate": 6.546662380799314e-06,
      "loss": 0.0,
      "step": 94170
    },
    {
      "epoch": 10.091074681238617,
      "grad_norm": 0.0004865225637331605,
      "learning_rate": 6.545233758348513e-06,
      "loss": 0.0,
      "step": 94180
    },
    {
      "epoch": 10.092146148076717,
      "grad_norm": 0.1434333622455597,
      "learning_rate": 6.543805135897711e-06,
      "loss": 0.0001,
      "step": 94190
    },
    {
      "epoch": 10.093217614914819,
      "grad_norm": 0.0002888757735490799,
      "learning_rate": 6.54237651344691e-06,
      "loss": 0.0,
      "step": 94200
    },
    {
      "epoch": 10.094289081752919,
      "grad_norm": 6.0116977692814544e-05,
      "learning_rate": 6.5409478909961076e-06,
      "loss": 0.0002,
      "step": 94210
    },
    {
      "epoch": 10.095360548591021,
      "grad_norm": 5.37250452907756e-05,
      "learning_rate": 6.539519268545306e-06,
      "loss": 0.0001,
      "step": 94220
    },
    {
      "epoch": 10.096432015429123,
      "grad_norm": 0.00072205945616588,
      "learning_rate": 6.538090646094504e-06,
      "loss": 0.0,
      "step": 94230
    },
    {
      "epoch": 10.097503482267223,
      "grad_norm": 6.9749730755575e-05,
      "learning_rate": 6.5366620236437014e-06,
      "loss": 0.0013,
      "step": 94240
    },
    {
      "epoch": 10.098574949105325,
      "grad_norm": 0.0003433575911913067,
      "learning_rate": 6.5352334011929e-06,
      "loss": 0.0001,
      "step": 94250
    },
    {
      "epoch": 10.099646415943427,
      "grad_norm": 0.0007208854658529162,
      "learning_rate": 6.5338047787420985e-06,
      "loss": 0.0,
      "step": 94260
    },
    {
      "epoch": 10.100717882781527,
      "grad_norm": 0.00045964939636178315,
      "learning_rate": 6.532376156291297e-06,
      "loss": 0.0,
      "step": 94270
    },
    {
      "epoch": 10.10178934961963,
      "grad_norm": 0.015249544754624367,
      "learning_rate": 6.530947533840495e-06,
      "loss": 0.1196,
      "step": 94280
    },
    {
      "epoch": 10.102860816457731,
      "grad_norm": 7.154278864618391e-05,
      "learning_rate": 6.529518911389693e-06,
      "loss": 0.0,
      "step": 94290
    },
    {
      "epoch": 10.103932283295832,
      "grad_norm": 0.00018012705550063401,
      "learning_rate": 6.528090288938891e-06,
      "loss": 0.0,
      "step": 94300
    },
    {
      "epoch": 10.105003750133934,
      "grad_norm": 6.245428812690079e-05,
      "learning_rate": 6.5266616664880885e-06,
      "loss": 0.2026,
      "step": 94310
    },
    {
      "epoch": 10.106075216972036,
      "grad_norm": 6.280105299083516e-05,
      "learning_rate": 6.525233044037288e-06,
      "loss": 0.0,
      "step": 94320
    },
    {
      "epoch": 10.107146683810136,
      "grad_norm": 6.0971316997893155e-05,
      "learning_rate": 6.5238044215864856e-06,
      "loss": 0.0,
      "step": 94330
    },
    {
      "epoch": 10.108218150648238,
      "grad_norm": 0.00026377427275292575,
      "learning_rate": 6.522375799135684e-06,
      "loss": 0.0,
      "step": 94340
    },
    {
      "epoch": 10.109289617486338,
      "grad_norm": 9.969411621568725e-05,
      "learning_rate": 6.520947176684882e-06,
      "loss": 0.0034,
      "step": 94350
    },
    {
      "epoch": 10.11036108432444,
      "grad_norm": 5.7859211665345356e-05,
      "learning_rate": 6.51951855423408e-06,
      "loss": 0.0769,
      "step": 94360
    },
    {
      "epoch": 10.111432551162542,
      "grad_norm": 0.0005274403956718743,
      "learning_rate": 6.518089931783278e-06,
      "loss": 0.0,
      "step": 94370
    },
    {
      "epoch": 10.112504018000642,
      "grad_norm": 5.4231135436566547e-05,
      "learning_rate": 6.516661309332477e-06,
      "loss": 0.0,
      "step": 94380
    },
    {
      "epoch": 10.113575484838744,
      "grad_norm": 0.00032191662467084825,
      "learning_rate": 6.515232686881675e-06,
      "loss": 0.2124,
      "step": 94390
    },
    {
      "epoch": 10.114646951676846,
      "grad_norm": 0.0001032221334753558,
      "learning_rate": 6.5138040644308735e-06,
      "loss": 0.4426,
      "step": 94400
    },
    {
      "epoch": 10.115718418514946,
      "grad_norm": 0.00042814493644982576,
      "learning_rate": 6.512375441980071e-06,
      "loss": 0.0006,
      "step": 94410
    },
    {
      "epoch": 10.116789885353048,
      "grad_norm": 0.00015341784455813468,
      "learning_rate": 6.510946819529269e-06,
      "loss": 0.0,
      "step": 94420
    },
    {
      "epoch": 10.11786135219115,
      "grad_norm": 0.00017587900219950825,
      "learning_rate": 6.509518197078467e-06,
      "loss": 0.0,
      "step": 94430
    },
    {
      "epoch": 10.11893281902925,
      "grad_norm": 0.00036963741877116263,
      "learning_rate": 6.508089574627666e-06,
      "loss": 0.0,
      "step": 94440
    },
    {
      "epoch": 10.120004285867353,
      "grad_norm": 0.0003432715020608157,
      "learning_rate": 6.506660952176864e-06,
      "loss": 0.0,
      "step": 94450
    },
    {
      "epoch": 10.121075752705453,
      "grad_norm": 0.00011328313121339306,
      "learning_rate": 6.505232329726062e-06,
      "loss": 0.1313,
      "step": 94460
    },
    {
      "epoch": 10.122147219543555,
      "grad_norm": 0.00035062304232269526,
      "learning_rate": 6.503803707275261e-06,
      "loss": 0.0002,
      "step": 94470
    },
    {
      "epoch": 10.123218686381657,
      "grad_norm": 4.606062889099121,
      "learning_rate": 6.502375084824458e-06,
      "loss": 0.2737,
      "step": 94480
    },
    {
      "epoch": 10.124290153219757,
      "grad_norm": 8.684848580742255e-05,
      "learning_rate": 6.500946462373656e-06,
      "loss": 0.0,
      "step": 94490
    },
    {
      "epoch": 10.12536162005786,
      "grad_norm": 0.0001400797482347116,
      "learning_rate": 6.499517839922855e-06,
      "loss": 0.0,
      "step": 94500
    },
    {
      "epoch": 10.126433086895961,
      "grad_norm": 0.0006586950621567667,
      "learning_rate": 6.498089217472053e-06,
      "loss": 0.0,
      "step": 94510
    },
    {
      "epoch": 10.127504553734061,
      "grad_norm": 0.0005694912397302687,
      "learning_rate": 6.4966605950212515e-06,
      "loss": 0.0005,
      "step": 94520
    },
    {
      "epoch": 10.128576020572163,
      "grad_norm": 0.00043030045344494283,
      "learning_rate": 6.495231972570449e-06,
      "loss": 0.0,
      "step": 94530
    },
    {
      "epoch": 10.129647487410265,
      "grad_norm": 0.03993043303489685,
      "learning_rate": 6.493803350119648e-06,
      "loss": 0.0,
      "step": 94540
    },
    {
      "epoch": 10.130718954248366,
      "grad_norm": 0.0001104688853956759,
      "learning_rate": 6.492374727668845e-06,
      "loss": 0.0,
      "step": 94550
    },
    {
      "epoch": 10.131790421086468,
      "grad_norm": 0.00010054767335532233,
      "learning_rate": 6.490946105218045e-06,
      "loss": 0.0,
      "step": 94560
    },
    {
      "epoch": 10.13286188792457,
      "grad_norm": 0.0003421724250074476,
      "learning_rate": 6.489517482767242e-06,
      "loss": 0.1496,
      "step": 94570
    },
    {
      "epoch": 10.13393335476267,
      "grad_norm": 7.667527825105935e-05,
      "learning_rate": 6.48808886031644e-06,
      "loss": 0.0,
      "step": 94580
    },
    {
      "epoch": 10.135004821600772,
      "grad_norm": 0.0015460780123248696,
      "learning_rate": 6.486660237865639e-06,
      "loss": 0.1649,
      "step": 94590
    },
    {
      "epoch": 10.136076288438872,
      "grad_norm": 8.573418745072559e-05,
      "learning_rate": 6.485231615414836e-06,
      "loss": 0.0,
      "step": 94600
    },
    {
      "epoch": 10.137147755276974,
      "grad_norm": 0.001040932722389698,
      "learning_rate": 6.483802992964035e-06,
      "loss": 0.0001,
      "step": 94610
    },
    {
      "epoch": 10.138219222115076,
      "grad_norm": 0.00019118994532618672,
      "learning_rate": 6.482374370513233e-06,
      "loss": 0.0,
      "step": 94620
    },
    {
      "epoch": 10.139290688953176,
      "grad_norm": 0.0005250796093605459,
      "learning_rate": 6.480945748062432e-06,
      "loss": 0.0001,
      "step": 94630
    },
    {
      "epoch": 10.140362155791278,
      "grad_norm": 0.030256420373916626,
      "learning_rate": 6.4795171256116295e-06,
      "loss": 0.0,
      "step": 94640
    },
    {
      "epoch": 10.14143362262938,
      "grad_norm": 0.0004406214284244925,
      "learning_rate": 6.478088503160827e-06,
      "loss": 0.0,
      "step": 94650
    },
    {
      "epoch": 10.14250508946748,
      "grad_norm": 9.925542690325528e-05,
      "learning_rate": 6.476659880710026e-06,
      "loss": 0.2276,
      "step": 94660
    },
    {
      "epoch": 10.143576556305582,
      "grad_norm": 0.0006313319900073111,
      "learning_rate": 6.475231258259223e-06,
      "loss": 0.0001,
      "step": 94670
    },
    {
      "epoch": 10.144648023143684,
      "grad_norm": 0.9179748296737671,
      "learning_rate": 6.473802635808423e-06,
      "loss": 0.0012,
      "step": 94680
    },
    {
      "epoch": 10.145719489981785,
      "grad_norm": 0.002196812303736806,
      "learning_rate": 6.47237401335762e-06,
      "loss": 0.0,
      "step": 94690
    },
    {
      "epoch": 10.146790956819887,
      "grad_norm": 0.000204833981115371,
      "learning_rate": 6.470945390906819e-06,
      "loss": 0.0,
      "step": 94700
    },
    {
      "epoch": 10.147862423657989,
      "grad_norm": 0.002133263973519206,
      "learning_rate": 6.469516768456017e-06,
      "loss": 0.0,
      "step": 94710
    },
    {
      "epoch": 10.148933890496089,
      "grad_norm": 9.51632609940134e-05,
      "learning_rate": 6.468088146005215e-06,
      "loss": 0.0,
      "step": 94720
    },
    {
      "epoch": 10.15000535733419,
      "grad_norm": 9.196396422339603e-05,
      "learning_rate": 6.466659523554413e-06,
      "loss": 0.1535,
      "step": 94730
    },
    {
      "epoch": 10.151076824172291,
      "grad_norm": 0.0013171432074159384,
      "learning_rate": 6.465230901103612e-06,
      "loss": 0.1348,
      "step": 94740
    },
    {
      "epoch": 10.152148291010393,
      "grad_norm": 9.01942330528982e-05,
      "learning_rate": 6.46380227865281e-06,
      "loss": 0.0001,
      "step": 94750
    },
    {
      "epoch": 10.153219757848495,
      "grad_norm": 0.00010225485311821103,
      "learning_rate": 6.4623736562020075e-06,
      "loss": 0.0845,
      "step": 94760
    },
    {
      "epoch": 10.154291224686595,
      "grad_norm": 0.0029732915572822094,
      "learning_rate": 6.460945033751206e-06,
      "loss": 0.0005,
      "step": 94770
    },
    {
      "epoch": 10.155362691524697,
      "grad_norm": 9.383464930579066e-05,
      "learning_rate": 6.459516411300404e-06,
      "loss": 0.0,
      "step": 94780
    },
    {
      "epoch": 10.1564341583628,
      "grad_norm": 9.448434866499156e-05,
      "learning_rate": 6.458087788849602e-06,
      "loss": 0.2152,
      "step": 94790
    },
    {
      "epoch": 10.1575056252009,
      "grad_norm": 25.530210494995117,
      "learning_rate": 6.456659166398801e-06,
      "loss": 0.2984,
      "step": 94800
    },
    {
      "epoch": 10.158577092039001,
      "grad_norm": 0.3142727017402649,
      "learning_rate": 6.455230543947999e-06,
      "loss": 0.0004,
      "step": 94810
    },
    {
      "epoch": 10.159648558877103,
      "grad_norm": 0.000903498032130301,
      "learning_rate": 6.453801921497197e-06,
      "loss": 0.0001,
      "step": 94820
    },
    {
      "epoch": 10.160720025715204,
      "grad_norm": 9.323655831394717e-05,
      "learning_rate": 6.452373299046395e-06,
      "loss": 0.0003,
      "step": 94830
    },
    {
      "epoch": 10.161791492553306,
      "grad_norm": 0.06920851022005081,
      "learning_rate": 6.450944676595593e-06,
      "loss": 0.0001,
      "step": 94840
    },
    {
      "epoch": 10.162862959391408,
      "grad_norm": 8.441889804089442e-05,
      "learning_rate": 6.449516054144791e-06,
      "loss": 0.0002,
      "step": 94850
    },
    {
      "epoch": 10.163934426229508,
      "grad_norm": 8.688153320690617e-05,
      "learning_rate": 6.44808743169399e-06,
      "loss": 0.0969,
      "step": 94860
    },
    {
      "epoch": 10.16500589306761,
      "grad_norm": 0.00019603983673732728,
      "learning_rate": 6.446658809243188e-06,
      "loss": 0.0002,
      "step": 94870
    },
    {
      "epoch": 10.16607735990571,
      "grad_norm": 7.90423946455121e-05,
      "learning_rate": 6.445230186792386e-06,
      "loss": 0.1048,
      "step": 94880
    },
    {
      "epoch": 10.167148826743812,
      "grad_norm": 7.90448539191857e-05,
      "learning_rate": 6.443801564341584e-06,
      "loss": 0.0011,
      "step": 94890
    },
    {
      "epoch": 10.168220293581914,
      "grad_norm": 7.732362428214401e-05,
      "learning_rate": 6.442372941890782e-06,
      "loss": 0.0002,
      "step": 94900
    },
    {
      "epoch": 10.169291760420014,
      "grad_norm": 0.00010070120333693922,
      "learning_rate": 6.44094431943998e-06,
      "loss": 0.0,
      "step": 94910
    },
    {
      "epoch": 10.170363227258116,
      "grad_norm": 8.426809654338285e-05,
      "learning_rate": 6.43951569698918e-06,
      "loss": 0.0,
      "step": 94920
    },
    {
      "epoch": 10.171434694096218,
      "grad_norm": 0.005303462501615286,
      "learning_rate": 6.438087074538377e-06,
      "loss": 0.0004,
      "step": 94930
    },
    {
      "epoch": 10.172506160934319,
      "grad_norm": 9.0064961113967e-05,
      "learning_rate": 6.436658452087575e-06,
      "loss": 0.0001,
      "step": 94940
    },
    {
      "epoch": 10.17357762777242,
      "grad_norm": 78.66648864746094,
      "learning_rate": 6.4352298296367735e-06,
      "loss": 0.2753,
      "step": 94950
    },
    {
      "epoch": 10.174649094610523,
      "grad_norm": 0.03297123685479164,
      "learning_rate": 6.433801207185971e-06,
      "loss": 0.0003,
      "step": 94960
    },
    {
      "epoch": 10.175720561448623,
      "grad_norm": 8.80418810993433e-05,
      "learning_rate": 6.43237258473517e-06,
      "loss": 0.0,
      "step": 94970
    },
    {
      "epoch": 10.176792028286725,
      "grad_norm": 0.00011701736366376281,
      "learning_rate": 6.430943962284368e-06,
      "loss": 0.0001,
      "step": 94980
    },
    {
      "epoch": 10.177863495124825,
      "grad_norm": 0.00010304283205186948,
      "learning_rate": 6.429515339833567e-06,
      "loss": 0.0007,
      "step": 94990
    },
    {
      "epoch": 10.178934961962927,
      "grad_norm": 0.00010451670823385939,
      "learning_rate": 6.428086717382764e-06,
      "loss": 0.0001,
      "step": 95000
    },
    {
      "epoch": 10.180006428801029,
      "grad_norm": 0.00010789080988615751,
      "learning_rate": 6.426658094931962e-06,
      "loss": 0.0001,
      "step": 95010
    },
    {
      "epoch": 10.18107789563913,
      "grad_norm": 8.071490447036922e-05,
      "learning_rate": 6.4252294724811605e-06,
      "loss": 0.0,
      "step": 95020
    },
    {
      "epoch": 10.182149362477231,
      "grad_norm": 0.00010433476563775912,
      "learning_rate": 6.423800850030358e-06,
      "loss": 0.0001,
      "step": 95030
    },
    {
      "epoch": 10.183220829315333,
      "grad_norm": 0.0011909173335880041,
      "learning_rate": 6.422372227579558e-06,
      "loss": 0.0,
      "step": 95040
    },
    {
      "epoch": 10.184292296153433,
      "grad_norm": 0.002718884265050292,
      "learning_rate": 6.420943605128755e-06,
      "loss": 0.0,
      "step": 95050
    },
    {
      "epoch": 10.185363762991535,
      "grad_norm": 0.00010354892583563924,
      "learning_rate": 6.419514982677954e-06,
      "loss": 0.0001,
      "step": 95060
    },
    {
      "epoch": 10.186435229829637,
      "grad_norm": 0.0026697865687310696,
      "learning_rate": 6.4180863602271515e-06,
      "loss": 0.0,
      "step": 95070
    },
    {
      "epoch": 10.187506696667738,
      "grad_norm": 0.0030332740861922503,
      "learning_rate": 6.416657737776349e-06,
      "loss": 0.0,
      "step": 95080
    },
    {
      "epoch": 10.18857816350584,
      "grad_norm": 8.678245649207383e-05,
      "learning_rate": 6.415229115325548e-06,
      "loss": 0.0,
      "step": 95090
    },
    {
      "epoch": 10.189649630343942,
      "grad_norm": 0.00010279796697432175,
      "learning_rate": 6.413800492874747e-06,
      "loss": 0.0001,
      "step": 95100
    },
    {
      "epoch": 10.190721097182042,
      "grad_norm": 0.001380638568662107,
      "learning_rate": 6.412371870423945e-06,
      "loss": 0.0001,
      "step": 95110
    },
    {
      "epoch": 10.191792564020144,
      "grad_norm": 6.432297232095152e-05,
      "learning_rate": 6.410943247973142e-06,
      "loss": 0.0931,
      "step": 95120
    },
    {
      "epoch": 10.192864030858244,
      "grad_norm": 0.002511258702725172,
      "learning_rate": 6.409514625522341e-06,
      "loss": 0.003,
      "step": 95130
    },
    {
      "epoch": 10.193935497696346,
      "grad_norm": 0.00010367244249209762,
      "learning_rate": 6.4080860030715385e-06,
      "loss": 0.0,
      "step": 95140
    },
    {
      "epoch": 10.195006964534448,
      "grad_norm": 7.452363206539303e-05,
      "learning_rate": 6.406657380620736e-06,
      "loss": 0.0,
      "step": 95150
    },
    {
      "epoch": 10.196078431372548,
      "grad_norm": 7.915713649708778e-05,
      "learning_rate": 6.405228758169935e-06,
      "loss": 0.0,
      "step": 95160
    },
    {
      "epoch": 10.19714989821065,
      "grad_norm": 0.0023346056696027517,
      "learning_rate": 6.403800135719134e-06,
      "loss": 0.0002,
      "step": 95170
    },
    {
      "epoch": 10.198221365048752,
      "grad_norm": 0.0018512117676436901,
      "learning_rate": 6.402371513268332e-06,
      "loss": 0.0,
      "step": 95180
    },
    {
      "epoch": 10.199292831886853,
      "grad_norm": 0.0015426200116053224,
      "learning_rate": 6.4009428908175294e-06,
      "loss": 0.0,
      "step": 95190
    },
    {
      "epoch": 10.200364298724955,
      "grad_norm": 0.00012457865523174405,
      "learning_rate": 6.399514268366728e-06,
      "loss": 0.3345,
      "step": 95200
    },
    {
      "epoch": 10.201435765563057,
      "grad_norm": 0.001706872251816094,
      "learning_rate": 6.398085645915926e-06,
      "loss": 0.0,
      "step": 95210
    },
    {
      "epoch": 10.202507232401157,
      "grad_norm": 0.00305747939273715,
      "learning_rate": 6.396657023465124e-06,
      "loss": 0.0,
      "step": 95220
    },
    {
      "epoch": 10.203578699239259,
      "grad_norm": 0.0026010898873209953,
      "learning_rate": 6.395228401014323e-06,
      "loss": 0.0,
      "step": 95230
    },
    {
      "epoch": 10.20465016607736,
      "grad_norm": 0.00013251072959974408,
      "learning_rate": 6.393799778563521e-06,
      "loss": 0.0,
      "step": 95240
    },
    {
      "epoch": 10.205721632915461,
      "grad_norm": 0.00010956500773318112,
      "learning_rate": 6.392371156112719e-06,
      "loss": 0.0,
      "step": 95250
    },
    {
      "epoch": 10.206793099753563,
      "grad_norm": 0.00017584745364729315,
      "learning_rate": 6.3909425336619165e-06,
      "loss": 0.0,
      "step": 95260
    },
    {
      "epoch": 10.207864566591663,
      "grad_norm": 0.00011395354522392154,
      "learning_rate": 6.389513911211115e-06,
      "loss": 0.0,
      "step": 95270
    },
    {
      "epoch": 10.208936033429765,
      "grad_norm": 0.001568267005495727,
      "learning_rate": 6.388085288760313e-06,
      "loss": 0.0,
      "step": 95280
    },
    {
      "epoch": 10.210007500267867,
      "grad_norm": 0.00010828357335412875,
      "learning_rate": 6.386656666309512e-06,
      "loss": 0.0,
      "step": 95290
    },
    {
      "epoch": 10.211078967105967,
      "grad_norm": 147.9804229736328,
      "learning_rate": 6.38522804385871e-06,
      "loss": 0.4714,
      "step": 95300
    },
    {
      "epoch": 10.21215043394407,
      "grad_norm": 0.002049479866400361,
      "learning_rate": 6.383799421407908e-06,
      "loss": 0.0,
      "step": 95310
    },
    {
      "epoch": 10.213221900782171,
      "grad_norm": 0.00023055470956023782,
      "learning_rate": 6.382370798957106e-06,
      "loss": 0.0,
      "step": 95320
    },
    {
      "epoch": 10.214293367620272,
      "grad_norm": 0.0029001464135944843,
      "learning_rate": 6.380942176506304e-06,
      "loss": 0.0,
      "step": 95330
    },
    {
      "epoch": 10.215364834458374,
      "grad_norm": 0.004464565776288509,
      "learning_rate": 6.379513554055502e-06,
      "loss": 0.0,
      "step": 95340
    },
    {
      "epoch": 10.216436301296476,
      "grad_norm": 0.00012528782826848328,
      "learning_rate": 6.378084931604701e-06,
      "loss": 0.0,
      "step": 95350
    },
    {
      "epoch": 10.217507768134576,
      "grad_norm": 0.00015661907673347741,
      "learning_rate": 6.376656309153899e-06,
      "loss": 0.0,
      "step": 95360
    },
    {
      "epoch": 10.218579234972678,
      "grad_norm": 0.06247446686029434,
      "learning_rate": 6.375227686703097e-06,
      "loss": 0.1882,
      "step": 95370
    },
    {
      "epoch": 10.219650701810778,
      "grad_norm": 0.00019434090063441545,
      "learning_rate": 6.373799064252295e-06,
      "loss": 0.1494,
      "step": 95380
    },
    {
      "epoch": 10.22072216864888,
      "grad_norm": 0.00018905027536675334,
      "learning_rate": 6.372370441801493e-06,
      "loss": 0.0,
      "step": 95390
    },
    {
      "epoch": 10.221793635486982,
      "grad_norm": 0.005492164753377438,
      "learning_rate": 6.370941819350691e-06,
      "loss": 0.0001,
      "step": 95400
    },
    {
      "epoch": 10.222865102325082,
      "grad_norm": 0.00013948998821433634,
      "learning_rate": 6.36951319689989e-06,
      "loss": 0.0,
      "step": 95410
    },
    {
      "epoch": 10.223936569163184,
      "grad_norm": 0.0012493921676650643,
      "learning_rate": 6.368084574449089e-06,
      "loss": 0.0903,
      "step": 95420
    },
    {
      "epoch": 10.225008036001286,
      "grad_norm": 0.0007517433259636164,
      "learning_rate": 6.366655951998286e-06,
      "loss": 0.0028,
      "step": 95430
    },
    {
      "epoch": 10.226079502839386,
      "grad_norm": 0.00012195392628200352,
      "learning_rate": 6.365227329547484e-06,
      "loss": 0.0001,
      "step": 95440
    },
    {
      "epoch": 10.227150969677488,
      "grad_norm": 0.00020866257546003908,
      "learning_rate": 6.3637987070966825e-06,
      "loss": 0.0002,
      "step": 95450
    },
    {
      "epoch": 10.22822243651559,
      "grad_norm": 0.0031524179503321648,
      "learning_rate": 6.36237008464588e-06,
      "loss": 0.0,
      "step": 95460
    },
    {
      "epoch": 10.22929390335369,
      "grad_norm": 0.00013798759027849883,
      "learning_rate": 6.3609414621950795e-06,
      "loss": 0.0,
      "step": 95470
    },
    {
      "epoch": 10.230365370191793,
      "grad_norm": 7.620439282618463e-05,
      "learning_rate": 6.359512839744277e-06,
      "loss": 0.0,
      "step": 95480
    },
    {
      "epoch": 10.231436837029895,
      "grad_norm": 0.0006468311767093837,
      "learning_rate": 6.358084217293476e-06,
      "loss": 0.0001,
      "step": 95490
    },
    {
      "epoch": 10.232508303867995,
      "grad_norm": 0.00014878902584314346,
      "learning_rate": 6.356655594842673e-06,
      "loss": 0.0,
      "step": 95500
    },
    {
      "epoch": 10.233579770706097,
      "grad_norm": 0.00011719153553713113,
      "learning_rate": 6.355226972391871e-06,
      "loss": 0.0,
      "step": 95510
    },
    {
      "epoch": 10.234651237544197,
      "grad_norm": 0.00011336021270835772,
      "learning_rate": 6.35379834994107e-06,
      "loss": 0.2379,
      "step": 95520
    },
    {
      "epoch": 10.2357227043823,
      "grad_norm": 0.006582674570381641,
      "learning_rate": 6.352369727490268e-06,
      "loss": 0.0,
      "step": 95530
    },
    {
      "epoch": 10.236794171220401,
      "grad_norm": 0.0025363026652485132,
      "learning_rate": 6.350941105039467e-06,
      "loss": 0.0,
      "step": 95540
    },
    {
      "epoch": 10.237865638058501,
      "grad_norm": 0.0003971587575506419,
      "learning_rate": 6.349512482588664e-06,
      "loss": 0.0,
      "step": 95550
    },
    {
      "epoch": 10.238937104896603,
      "grad_norm": 0.026455478742718697,
      "learning_rate": 6.348083860137863e-06,
      "loss": 0.0001,
      "step": 95560
    },
    {
      "epoch": 10.240008571734705,
      "grad_norm": 0.0013671761844307184,
      "learning_rate": 6.3466552376870605e-06,
      "loss": 0.0005,
      "step": 95570
    },
    {
      "epoch": 10.241080038572806,
      "grad_norm": 0.00010015197767643258,
      "learning_rate": 6.345226615236258e-06,
      "loss": 0.0,
      "step": 95580
    },
    {
      "epoch": 10.242151505410908,
      "grad_norm": 0.0001197704259539023,
      "learning_rate": 6.3437979927854575e-06,
      "loss": 0.0,
      "step": 95590
    },
    {
      "epoch": 10.24322297224901,
      "grad_norm": 0.00043333525536581874,
      "learning_rate": 6.342369370334655e-06,
      "loss": 0.0,
      "step": 95600
    },
    {
      "epoch": 10.24429443908711,
      "grad_norm": 0.00010051024582935497,
      "learning_rate": 6.340940747883854e-06,
      "loss": 0.0,
      "step": 95610
    },
    {
      "epoch": 10.245365905925212,
      "grad_norm": 0.0017881047679111362,
      "learning_rate": 6.339512125433051e-06,
      "loss": 0.0,
      "step": 95620
    },
    {
      "epoch": 10.246437372763314,
      "grad_norm": 0.00010001844930229709,
      "learning_rate": 6.33808350298225e-06,
      "loss": 0.2552,
      "step": 95630
    },
    {
      "epoch": 10.247508839601414,
      "grad_norm": 0.0016213118797168136,
      "learning_rate": 6.336654880531448e-06,
      "loss": 0.0,
      "step": 95640
    },
    {
      "epoch": 10.248580306439516,
      "grad_norm": 0.041203297674655914,
      "learning_rate": 6.335226258080647e-06,
      "loss": 0.1477,
      "step": 95650
    },
    {
      "epoch": 10.249651773277616,
      "grad_norm": 0.00011150736827403307,
      "learning_rate": 6.333797635629845e-06,
      "loss": 0.0,
      "step": 95660
    },
    {
      "epoch": 10.250723240115718,
      "grad_norm": 0.04520004615187645,
      "learning_rate": 6.332369013179043e-06,
      "loss": 0.0,
      "step": 95670
    },
    {
      "epoch": 10.25179470695382,
      "grad_norm": 0.00035371657577343285,
      "learning_rate": 6.330940390728241e-06,
      "loss": 0.0,
      "step": 95680
    },
    {
      "epoch": 10.25286617379192,
      "grad_norm": 0.0005051564075984061,
      "learning_rate": 6.3295117682774385e-06,
      "loss": 0.3211,
      "step": 95690
    },
    {
      "epoch": 10.253937640630022,
      "grad_norm": 0.0013322806917130947,
      "learning_rate": 6.328083145826637e-06,
      "loss": 0.0,
      "step": 95700
    },
    {
      "epoch": 10.255009107468124,
      "grad_norm": 0.0020775001030415297,
      "learning_rate": 6.3266545233758355e-06,
      "loss": 0.1304,
      "step": 95710
    },
    {
      "epoch": 10.256080574306225,
      "grad_norm": 0.00013047046377323568,
      "learning_rate": 6.325225900925034e-06,
      "loss": 0.0,
      "step": 95720
    },
    {
      "epoch": 10.257152041144327,
      "grad_norm": 16.087568283081055,
      "learning_rate": 6.323797278474232e-06,
      "loss": 0.0849,
      "step": 95730
    },
    {
      "epoch": 10.258223507982429,
      "grad_norm": 0.0005087638273835182,
      "learning_rate": 6.32236865602343e-06,
      "loss": 0.0001,
      "step": 95740
    },
    {
      "epoch": 10.259294974820529,
      "grad_norm": 0.00019443064229562879,
      "learning_rate": 6.320940033572628e-06,
      "loss": 0.0001,
      "step": 95750
    },
    {
      "epoch": 10.26036644165863,
      "grad_norm": 0.0013998291688039899,
      "learning_rate": 6.319511411121826e-06,
      "loss": 0.0023,
      "step": 95760
    },
    {
      "epoch": 10.261437908496733,
      "grad_norm": 0.0009290659218095243,
      "learning_rate": 6.318082788671025e-06,
      "loss": 0.0,
      "step": 95770
    },
    {
      "epoch": 10.262509375334833,
      "grad_norm": 0.05910629406571388,
      "learning_rate": 6.316654166220223e-06,
      "loss": 0.0008,
      "step": 95780
    },
    {
      "epoch": 10.263580842172935,
      "grad_norm": 0.0008715004660189152,
      "learning_rate": 6.315225543769421e-06,
      "loss": 0.0002,
      "step": 95790
    },
    {
      "epoch": 10.264652309011035,
      "grad_norm": 0.010150800459086895,
      "learning_rate": 6.313796921318619e-06,
      "loss": 0.0,
      "step": 95800
    },
    {
      "epoch": 10.265723775849137,
      "grad_norm": 0.0013856474542990327,
      "learning_rate": 6.312368298867817e-06,
      "loss": 0.0038,
      "step": 95810
    },
    {
      "epoch": 10.26679524268724,
      "grad_norm": 0.0021629075054079294,
      "learning_rate": 6.310939676417015e-06,
      "loss": 0.0843,
      "step": 95820
    },
    {
      "epoch": 10.26786670952534,
      "grad_norm": 0.0014518037205561996,
      "learning_rate": 6.309511053966214e-06,
      "loss": 0.0,
      "step": 95830
    },
    {
      "epoch": 10.268938176363442,
      "grad_norm": 0.007785232737660408,
      "learning_rate": 6.308082431515412e-06,
      "loss": 0.0,
      "step": 95840
    },
    {
      "epoch": 10.270009643201544,
      "grad_norm": 0.001428364310413599,
      "learning_rate": 6.30665380906461e-06,
      "loss": 0.0699,
      "step": 95850
    },
    {
      "epoch": 10.271081110039644,
      "grad_norm": 0.00013967955601401627,
      "learning_rate": 6.305225186613808e-06,
      "loss": 0.0001,
      "step": 95860
    },
    {
      "epoch": 10.272152576877746,
      "grad_norm": 0.00015034490206744522,
      "learning_rate": 6.303796564163006e-06,
      "loss": 0.1277,
      "step": 95870
    },
    {
      "epoch": 10.273224043715848,
      "grad_norm": 0.004744207952171564,
      "learning_rate": 6.3023679417122044e-06,
      "loss": 0.0,
      "step": 95880
    },
    {
      "epoch": 10.274295510553948,
      "grad_norm": 0.002181878313422203,
      "learning_rate": 6.300939319261403e-06,
      "loss": 0.0,
      "step": 95890
    },
    {
      "epoch": 10.27536697739205,
      "grad_norm": 0.0019059954211115837,
      "learning_rate": 6.2995106968106015e-06,
      "loss": 0.0002,
      "step": 95900
    },
    {
      "epoch": 10.276438444230152,
      "grad_norm": 0.06699291616678238,
      "learning_rate": 6.298082074359799e-06,
      "loss": 0.0001,
      "step": 95910
    },
    {
      "epoch": 10.277509911068252,
      "grad_norm": 0.0001262372825294733,
      "learning_rate": 6.296653451908998e-06,
      "loss": 0.0008,
      "step": 95920
    },
    {
      "epoch": 10.278581377906354,
      "grad_norm": 9.923083416651934e-05,
      "learning_rate": 6.295224829458195e-06,
      "loss": 0.0077,
      "step": 95930
    },
    {
      "epoch": 10.279652844744454,
      "grad_norm": 0.00022814450494479388,
      "learning_rate": 6.293796207007393e-06,
      "loss": 0.3268,
      "step": 95940
    },
    {
      "epoch": 10.280724311582556,
      "grad_norm": 0.00016186974244192243,
      "learning_rate": 6.292367584556592e-06,
      "loss": 0.0003,
      "step": 95950
    },
    {
      "epoch": 10.281795778420658,
      "grad_norm": 0.004074855707585812,
      "learning_rate": 6.29093896210579e-06,
      "loss": 0.0003,
      "step": 95960
    },
    {
      "epoch": 10.282867245258759,
      "grad_norm": 0.004143603146076202,
      "learning_rate": 6.2895103396549886e-06,
      "loss": 0.0001,
      "step": 95970
    },
    {
      "epoch": 10.28393871209686,
      "grad_norm": 0.0002679907192941755,
      "learning_rate": 6.288081717204186e-06,
      "loss": 0.0,
      "step": 95980
    },
    {
      "epoch": 10.285010178934963,
      "grad_norm": 0.004841262008994818,
      "learning_rate": 6.286653094753385e-06,
      "loss": 0.0001,
      "step": 95990
    },
    {
      "epoch": 10.286081645773063,
      "grad_norm": 0.00011721276678144932,
      "learning_rate": 6.2852244723025824e-06,
      "loss": 0.0003,
      "step": 96000
    },
    {
      "epoch": 10.287153112611165,
      "grad_norm": 0.00011354369053151459,
      "learning_rate": 6.283795849851782e-06,
      "loss": 0.0946,
      "step": 96010
    },
    {
      "epoch": 10.288224579449267,
      "grad_norm": 0.00854042824357748,
      "learning_rate": 6.2823672274009795e-06,
      "loss": 0.0,
      "step": 96020
    },
    {
      "epoch": 10.289296046287367,
      "grad_norm": 9.689535363577306e-05,
      "learning_rate": 6.280938604950177e-06,
      "loss": 0.0,
      "step": 96030
    },
    {
      "epoch": 10.290367513125469,
      "grad_norm": 0.0011286463122814894,
      "learning_rate": 6.279509982499376e-06,
      "loss": 0.0,
      "step": 96040
    },
    {
      "epoch": 10.29143897996357,
      "grad_norm": 0.00011507640010677278,
      "learning_rate": 6.278081360048573e-06,
      "loss": 0.0,
      "step": 96050
    },
    {
      "epoch": 10.292510446801671,
      "grad_norm": 0.0001018115144688636,
      "learning_rate": 6.276652737597772e-06,
      "loss": 0.0,
      "step": 96060
    },
    {
      "epoch": 10.293581913639773,
      "grad_norm": 0.0001048286649165675,
      "learning_rate": 6.2752241151469695e-06,
      "loss": 0.0052,
      "step": 96070
    },
    {
      "epoch": 10.294653380477873,
      "grad_norm": 9.72161433310248e-05,
      "learning_rate": 6.273795492696169e-06,
      "loss": 0.0,
      "step": 96080
    },
    {
      "epoch": 10.295724847315975,
      "grad_norm": 0.00010038227628683671,
      "learning_rate": 6.2723668702453666e-06,
      "loss": 0.0,
      "step": 96090
    },
    {
      "epoch": 10.296796314154077,
      "grad_norm": 0.0011392587330192327,
      "learning_rate": 6.270938247794564e-06,
      "loss": 0.0,
      "step": 96100
    },
    {
      "epoch": 10.297867780992178,
      "grad_norm": 0.00012016264372505248,
      "learning_rate": 6.269509625343763e-06,
      "loss": 0.001,
      "step": 96110
    },
    {
      "epoch": 10.29893924783028,
      "grad_norm": 0.0013431651750579476,
      "learning_rate": 6.2680810028929604e-06,
      "loss": 0.0006,
      "step": 96120
    },
    {
      "epoch": 10.300010714668382,
      "grad_norm": 0.00293034128844738,
      "learning_rate": 6.266652380442159e-06,
      "loss": 0.0002,
      "step": 96130
    },
    {
      "epoch": 10.301082181506482,
      "grad_norm": 0.00042511068750172853,
      "learning_rate": 6.2652237579913575e-06,
      "loss": 0.0001,
      "step": 96140
    },
    {
      "epoch": 10.302153648344584,
      "grad_norm": 0.0001078837231034413,
      "learning_rate": 6.263795135540556e-06,
      "loss": 0.1944,
      "step": 96150
    },
    {
      "epoch": 10.303225115182686,
      "grad_norm": 9.590322588337585e-05,
      "learning_rate": 6.262366513089754e-06,
      "loss": 0.0,
      "step": 96160
    },
    {
      "epoch": 10.304296582020786,
      "grad_norm": 0.00018327233556192368,
      "learning_rate": 6.260937890638951e-06,
      "loss": 0.0001,
      "step": 96170
    },
    {
      "epoch": 10.305368048858888,
      "grad_norm": 0.20521901547908783,
      "learning_rate": 6.25950926818815e-06,
      "loss": 0.0004,
      "step": 96180
    },
    {
      "epoch": 10.306439515696988,
      "grad_norm": 0.00011641621676972136,
      "learning_rate": 6.2580806457373475e-06,
      "loss": 0.0,
      "step": 96190
    },
    {
      "epoch": 10.30751098253509,
      "grad_norm": 0.3285945653915405,
      "learning_rate": 6.256652023286547e-06,
      "loss": 0.0002,
      "step": 96200
    },
    {
      "epoch": 10.308582449373192,
      "grad_norm": 0.00022552504378836602,
      "learning_rate": 6.2552234008357446e-06,
      "loss": 0.0024,
      "step": 96210
    },
    {
      "epoch": 10.309653916211293,
      "grad_norm": 9.90074549918063e-05,
      "learning_rate": 6.253794778384943e-06,
      "loss": 0.4772,
      "step": 96220
    },
    {
      "epoch": 10.310725383049395,
      "grad_norm": 0.0028914196882396936,
      "learning_rate": 6.252366155934141e-06,
      "loss": 0.0,
      "step": 96230
    },
    {
      "epoch": 10.311796849887497,
      "grad_norm": 0.0007736884290352464,
      "learning_rate": 6.250937533483339e-06,
      "loss": 0.0,
      "step": 96240
    },
    {
      "epoch": 10.312868316725597,
      "grad_norm": 0.0012379385298117995,
      "learning_rate": 6.249508911032537e-06,
      "loss": 0.0,
      "step": 96250
    },
    {
      "epoch": 10.313939783563699,
      "grad_norm": 0.0011369817657396197,
      "learning_rate": 6.248080288581736e-06,
      "loss": 0.0,
      "step": 96260
    },
    {
      "epoch": 10.3150112504018,
      "grad_norm": 0.00013682922872249037,
      "learning_rate": 6.246651666130934e-06,
      "loss": 0.0,
      "step": 96270
    },
    {
      "epoch": 10.316082717239901,
      "grad_norm": 0.11917588859796524,
      "learning_rate": 6.245223043680132e-06,
      "loss": 0.0001,
      "step": 96280
    },
    {
      "epoch": 10.317154184078003,
      "grad_norm": 0.00013734215463045985,
      "learning_rate": 6.24379442122933e-06,
      "loss": 0.0,
      "step": 96290
    },
    {
      "epoch": 10.318225650916105,
      "grad_norm": 0.0011553328949958086,
      "learning_rate": 6.242365798778528e-06,
      "loss": 0.0,
      "step": 96300
    },
    {
      "epoch": 10.319297117754205,
      "grad_norm": 0.00014271076361183077,
      "learning_rate": 6.240937176327726e-06,
      "loss": 0.0,
      "step": 96310
    },
    {
      "epoch": 10.320368584592307,
      "grad_norm": 0.00017368729459121823,
      "learning_rate": 6.239508553876925e-06,
      "loss": 0.187,
      "step": 96320
    },
    {
      "epoch": 10.321440051430407,
      "grad_norm": 0.0001653635554248467,
      "learning_rate": 6.238079931426123e-06,
      "loss": 0.0068,
      "step": 96330
    },
    {
      "epoch": 10.32251151826851,
      "grad_norm": 0.00010966778791043907,
      "learning_rate": 6.236651308975321e-06,
      "loss": 0.0,
      "step": 96340
    },
    {
      "epoch": 10.323582985106611,
      "grad_norm": 8.808324491837993e-05,
      "learning_rate": 6.235222686524519e-06,
      "loss": 0.0003,
      "step": 96350
    },
    {
      "epoch": 10.324654451944712,
      "grad_norm": 9.467008931096643e-05,
      "learning_rate": 6.233794064073717e-06,
      "loss": 0.0031,
      "step": 96360
    },
    {
      "epoch": 10.325725918782814,
      "grad_norm": 0.00010028333781519905,
      "learning_rate": 6.232365441622915e-06,
      "loss": 0.0,
      "step": 96370
    },
    {
      "epoch": 10.326797385620916,
      "grad_norm": 0.0001224945590365678,
      "learning_rate": 6.230936819172114e-06,
      "loss": 0.0,
      "step": 96380
    },
    {
      "epoch": 10.327868852459016,
      "grad_norm": 0.002332535805180669,
      "learning_rate": 6.229508196721312e-06,
      "loss": 0.0,
      "step": 96390
    },
    {
      "epoch": 10.328940319297118,
      "grad_norm": 0.00021404685685411096,
      "learning_rate": 6.2280795742705105e-06,
      "loss": 0.0,
      "step": 96400
    },
    {
      "epoch": 10.33001178613522,
      "grad_norm": 0.0032072230242192745,
      "learning_rate": 6.226650951819708e-06,
      "loss": 0.2404,
      "step": 96410
    },
    {
      "epoch": 10.33108325297332,
      "grad_norm": 0.00014058547094464302,
      "learning_rate": 6.225222329368906e-06,
      "loss": 0.0,
      "step": 96420
    },
    {
      "epoch": 10.332154719811422,
      "grad_norm": 9.303240949520841e-05,
      "learning_rate": 6.223793706918104e-06,
      "loss": 0.0,
      "step": 96430
    },
    {
      "epoch": 10.333226186649522,
      "grad_norm": 0.00011592912778723985,
      "learning_rate": 6.222365084467304e-06,
      "loss": 0.1016,
      "step": 96440
    },
    {
      "epoch": 10.334297653487624,
      "grad_norm": 16.05048179626465,
      "learning_rate": 6.220936462016501e-06,
      "loss": 0.1251,
      "step": 96450
    },
    {
      "epoch": 10.335369120325726,
      "grad_norm": 0.7277097105979919,
      "learning_rate": 6.219507839565699e-06,
      "loss": 0.0809,
      "step": 96460
    },
    {
      "epoch": 10.336440587163827,
      "grad_norm": 0.00010485809616511688,
      "learning_rate": 6.218079217114898e-06,
      "loss": 0.123,
      "step": 96470
    },
    {
      "epoch": 10.337512054001929,
      "grad_norm": 0.00015246268594637513,
      "learning_rate": 6.216650594664095e-06,
      "loss": 0.0,
      "step": 96480
    },
    {
      "epoch": 10.33858352084003,
      "grad_norm": 0.00012058067659381777,
      "learning_rate": 6.215221972213294e-06,
      "loss": 0.0,
      "step": 96490
    },
    {
      "epoch": 10.33965498767813,
      "grad_norm": 0.0005060154944658279,
      "learning_rate": 6.213793349762492e-06,
      "loss": 0.0,
      "step": 96500
    },
    {
      "epoch": 10.340726454516233,
      "grad_norm": 0.006705894600600004,
      "learning_rate": 6.212364727311691e-06,
      "loss": 0.0,
      "step": 96510
    },
    {
      "epoch": 10.341797921354335,
      "grad_norm": 0.00011336855095578358,
      "learning_rate": 6.2109361048608885e-06,
      "loss": 0.0,
      "step": 96520
    },
    {
      "epoch": 10.342869388192435,
      "grad_norm": 9.727201540954411e-05,
      "learning_rate": 6.209507482410086e-06,
      "loss": 0.0116,
      "step": 96530
    },
    {
      "epoch": 10.343940855030537,
      "grad_norm": 0.00014433989417739213,
      "learning_rate": 6.208078859959285e-06,
      "loss": 0.3359,
      "step": 96540
    },
    {
      "epoch": 10.345012321868639,
      "grad_norm": 0.0027079833671450615,
      "learning_rate": 6.206650237508482e-06,
      "loss": 0.0001,
      "step": 96550
    },
    {
      "epoch": 10.34608378870674,
      "grad_norm": 0.00010588970326352865,
      "learning_rate": 6.205221615057682e-06,
      "loss": 0.0,
      "step": 96560
    },
    {
      "epoch": 10.347155255544841,
      "grad_norm": 0.00011251350224483758,
      "learning_rate": 6.203792992606879e-06,
      "loss": 0.0,
      "step": 96570
    },
    {
      "epoch": 10.348226722382941,
      "grad_norm": 0.0001527094136690721,
      "learning_rate": 6.202364370156078e-06,
      "loss": 0.0001,
      "step": 96580
    },
    {
      "epoch": 10.349298189221043,
      "grad_norm": 0.0059904418885707855,
      "learning_rate": 6.200935747705276e-06,
      "loss": 0.0001,
      "step": 96590
    },
    {
      "epoch": 10.350369656059145,
      "grad_norm": 0.0001321508752880618,
      "learning_rate": 6.199507125254473e-06,
      "loss": 0.0001,
      "step": 96600
    },
    {
      "epoch": 10.351441122897246,
      "grad_norm": 0.0024974283296614885,
      "learning_rate": 6.198078502803672e-06,
      "loss": 0.0005,
      "step": 96610
    },
    {
      "epoch": 10.352512589735348,
      "grad_norm": 0.0018142902990803123,
      "learning_rate": 6.196649880352871e-06,
      "loss": 0.0,
      "step": 96620
    },
    {
      "epoch": 10.35358405657345,
      "grad_norm": 8.328672265633941e-05,
      "learning_rate": 6.195221257902069e-06,
      "loss": 0.1317,
      "step": 96630
    },
    {
      "epoch": 10.35465552341155,
      "grad_norm": 0.0008456904906779528,
      "learning_rate": 6.1937926354512665e-06,
      "loss": 0.0001,
      "step": 96640
    },
    {
      "epoch": 10.355726990249652,
      "grad_norm": 0.00011205756891286,
      "learning_rate": 6.192364013000465e-06,
      "loss": 0.0,
      "step": 96650
    },
    {
      "epoch": 10.356798457087754,
      "grad_norm": 0.0028496989980340004,
      "learning_rate": 6.190935390549663e-06,
      "loss": 0.0001,
      "step": 96660
    },
    {
      "epoch": 10.357869923925854,
      "grad_norm": 0.37159305810928345,
      "learning_rate": 6.18950676809886e-06,
      "loss": 0.0006,
      "step": 96670
    },
    {
      "epoch": 10.358941390763956,
      "grad_norm": 0.0022535717580467463,
      "learning_rate": 6.18807814564806e-06,
      "loss": 0.0,
      "step": 96680
    },
    {
      "epoch": 10.360012857602058,
      "grad_norm": 8.774399611866102e-05,
      "learning_rate": 6.186649523197258e-06,
      "loss": 0.0,
      "step": 96690
    },
    {
      "epoch": 10.361084324440158,
      "grad_norm": 8.946313027990982e-05,
      "learning_rate": 6.185220900746456e-06,
      "loss": 0.0,
      "step": 96700
    },
    {
      "epoch": 10.36215579127826,
      "grad_norm": 0.00010561074304860085,
      "learning_rate": 6.183792278295654e-06,
      "loss": 0.0,
      "step": 96710
    },
    {
      "epoch": 10.36322725811636,
      "grad_norm": 0.0001010176056297496,
      "learning_rate": 6.182363655844852e-06,
      "loss": 0.0,
      "step": 96720
    },
    {
      "epoch": 10.364298724954462,
      "grad_norm": 9.62600825005211e-05,
      "learning_rate": 6.18093503339405e-06,
      "loss": 0.0,
      "step": 96730
    },
    {
      "epoch": 10.365370191792564,
      "grad_norm": 0.001826878753490746,
      "learning_rate": 6.179506410943249e-06,
      "loss": 0.0,
      "step": 96740
    },
    {
      "epoch": 10.366441658630665,
      "grad_norm": 0.003488351358100772,
      "learning_rate": 6.178077788492447e-06,
      "loss": 0.1507,
      "step": 96750
    },
    {
      "epoch": 10.367513125468767,
      "grad_norm": 0.0007961506489664316,
      "learning_rate": 6.176649166041645e-06,
      "loss": 0.0,
      "step": 96760
    },
    {
      "epoch": 10.368584592306869,
      "grad_norm": 0.011387137696146965,
      "learning_rate": 6.175220543590843e-06,
      "loss": 0.2661,
      "step": 96770
    },
    {
      "epoch": 10.369656059144969,
      "grad_norm": 0.0001142527034971863,
      "learning_rate": 6.173791921140041e-06,
      "loss": 0.0001,
      "step": 96780
    },
    {
      "epoch": 10.370727525983071,
      "grad_norm": 0.0001150012030848302,
      "learning_rate": 6.172363298689239e-06,
      "loss": 0.0019,
      "step": 96790
    },
    {
      "epoch": 10.371798992821173,
      "grad_norm": 1.1297460794448853,
      "learning_rate": 6.170934676238438e-06,
      "loss": 0.0028,
      "step": 96800
    },
    {
      "epoch": 10.372870459659273,
      "grad_norm": 0.0030524716712534428,
      "learning_rate": 6.169506053787636e-06,
      "loss": 0.0001,
      "step": 96810
    },
    {
      "epoch": 10.373941926497375,
      "grad_norm": 0.005492549855262041,
      "learning_rate": 6.168077431336834e-06,
      "loss": 0.1073,
      "step": 96820
    },
    {
      "epoch": 10.375013393335477,
      "grad_norm": 0.003926190081983805,
      "learning_rate": 6.1666488088860324e-06,
      "loss": 0.0009,
      "step": 96830
    },
    {
      "epoch": 10.376084860173577,
      "grad_norm": 9.151096310233697e-05,
      "learning_rate": 6.16522018643523e-06,
      "loss": 0.0981,
      "step": 96840
    },
    {
      "epoch": 10.37715632701168,
      "grad_norm": 0.00010084768291562796,
      "learning_rate": 6.163791563984428e-06,
      "loss": 0.0012,
      "step": 96850
    },
    {
      "epoch": 10.37822779384978,
      "grad_norm": 0.00011006894055753946,
      "learning_rate": 6.162362941533627e-06,
      "loss": 0.1876,
      "step": 96860
    },
    {
      "epoch": 10.379299260687882,
      "grad_norm": 0.00011242835898883641,
      "learning_rate": 6.160934319082825e-06,
      "loss": 0.0,
      "step": 96870
    },
    {
      "epoch": 10.380370727525984,
      "grad_norm": 9.195386519422755e-05,
      "learning_rate": 6.159505696632023e-06,
      "loss": 0.0,
      "step": 96880
    },
    {
      "epoch": 10.381442194364084,
      "grad_norm": 8.50922879180871e-05,
      "learning_rate": 6.158077074181221e-06,
      "loss": 0.0002,
      "step": 96890
    },
    {
      "epoch": 10.382513661202186,
      "grad_norm": 0.00010941831715172157,
      "learning_rate": 6.1566484517304195e-06,
      "loss": 0.2999,
      "step": 96900
    },
    {
      "epoch": 10.383585128040288,
      "grad_norm": 0.004350066184997559,
      "learning_rate": 6.155219829279617e-06,
      "loss": 0.1713,
      "step": 96910
    },
    {
      "epoch": 10.384656594878388,
      "grad_norm": 0.005780246574431658,
      "learning_rate": 6.153791206828817e-06,
      "loss": 0.0001,
      "step": 96920
    },
    {
      "epoch": 10.38572806171649,
      "grad_norm": 0.0045014359056949615,
      "learning_rate": 6.152362584378014e-06,
      "loss": 0.0,
      "step": 96930
    },
    {
      "epoch": 10.386799528554592,
      "grad_norm": 0.00013400260650087148,
      "learning_rate": 6.150933961927213e-06,
      "loss": 0.0001,
      "step": 96940
    },
    {
      "epoch": 10.387870995392692,
      "grad_norm": 0.00011608326894929633,
      "learning_rate": 6.1495053394764104e-06,
      "loss": 0.0,
      "step": 96950
    },
    {
      "epoch": 10.388942462230794,
      "grad_norm": 0.00033705204259604216,
      "learning_rate": 6.148076717025608e-06,
      "loss": 0.0,
      "step": 96960
    },
    {
      "epoch": 10.390013929068896,
      "grad_norm": 0.00013234352809377015,
      "learning_rate": 6.146648094574807e-06,
      "loss": 0.0001,
      "step": 96970
    },
    {
      "epoch": 10.391085395906996,
      "grad_norm": 0.0014619027497246861,
      "learning_rate": 6.145219472124004e-06,
      "loss": 0.0,
      "step": 96980
    },
    {
      "epoch": 10.392156862745098,
      "grad_norm": 0.0001360201567877084,
      "learning_rate": 6.143790849673204e-06,
      "loss": 0.1217,
      "step": 96990
    },
    {
      "epoch": 10.393228329583199,
      "grad_norm": 0.00011257356527494267,
      "learning_rate": 6.142362227222401e-06,
      "loss": 0.0,
      "step": 97000
    },
    {
      "epoch": 10.3942997964213,
      "grad_norm": 0.00010259318514727056,
      "learning_rate": 6.1409336047716e-06,
      "loss": 0.0,
      "step": 97010
    },
    {
      "epoch": 10.395371263259403,
      "grad_norm": 0.00021295306214597076,
      "learning_rate": 6.1395049823207975e-06,
      "loss": 0.1345,
      "step": 97020
    },
    {
      "epoch": 10.396442730097503,
      "grad_norm": 0.00016481807688251138,
      "learning_rate": 6.138076359869995e-06,
      "loss": 0.0,
      "step": 97030
    },
    {
      "epoch": 10.397514196935605,
      "grad_norm": 9.626134851714596e-05,
      "learning_rate": 6.136647737419194e-06,
      "loss": 0.0,
      "step": 97040
    },
    {
      "epoch": 10.398585663773707,
      "grad_norm": 0.5025810599327087,
      "learning_rate": 6.135219114968392e-06,
      "loss": 0.0002,
      "step": 97050
    },
    {
      "epoch": 10.399657130611807,
      "grad_norm": 0.0002333509037271142,
      "learning_rate": 6.133790492517591e-06,
      "loss": 0.0003,
      "step": 97060
    },
    {
      "epoch": 10.400728597449909,
      "grad_norm": 0.00013627261796500534,
      "learning_rate": 6.1323618700667884e-06,
      "loss": 0.001,
      "step": 97070
    },
    {
      "epoch": 10.401800064288011,
      "grad_norm": 0.00012074646656401455,
      "learning_rate": 6.130933247615987e-06,
      "loss": 0.0001,
      "step": 97080
    },
    {
      "epoch": 10.402871531126111,
      "grad_norm": 0.00527036702260375,
      "learning_rate": 6.129504625165185e-06,
      "loss": 0.0,
      "step": 97090
    },
    {
      "epoch": 10.403942997964213,
      "grad_norm": 9.309537563240156e-05,
      "learning_rate": 6.128076002714382e-06,
      "loss": 0.0008,
      "step": 97100
    },
    {
      "epoch": 10.405014464802314,
      "grad_norm": 0.0001109360164264217,
      "learning_rate": 6.126647380263582e-06,
      "loss": 0.0,
      "step": 97110
    },
    {
      "epoch": 10.406085931640416,
      "grad_norm": 9.187430259771645e-05,
      "learning_rate": 6.125218757812779e-06,
      "loss": 0.0026,
      "step": 97120
    },
    {
      "epoch": 10.407157398478518,
      "grad_norm": 0.0018836286617442966,
      "learning_rate": 6.123790135361978e-06,
      "loss": 0.0003,
      "step": 97130
    },
    {
      "epoch": 10.408228865316618,
      "grad_norm": 0.001237149117514491,
      "learning_rate": 6.1223615129111755e-06,
      "loss": 0.0,
      "step": 97140
    },
    {
      "epoch": 10.40930033215472,
      "grad_norm": 9.129712998401374e-05,
      "learning_rate": 6.120932890460374e-06,
      "loss": 0.0,
      "step": 97150
    },
    {
      "epoch": 10.410371798992822,
      "grad_norm": 0.0001126208808273077,
      "learning_rate": 6.119504268009572e-06,
      "loss": 0.0,
      "step": 97160
    },
    {
      "epoch": 10.411443265830922,
      "grad_norm": 9.680409857537597e-05,
      "learning_rate": 6.118075645558771e-06,
      "loss": 0.0,
      "step": 97170
    },
    {
      "epoch": 10.412514732669024,
      "grad_norm": 8.79183498909697e-05,
      "learning_rate": 6.116647023107969e-06,
      "loss": 0.0,
      "step": 97180
    },
    {
      "epoch": 10.413586199507126,
      "grad_norm": 0.0019439394818618894,
      "learning_rate": 6.115218400657167e-06,
      "loss": 0.0,
      "step": 97190
    },
    {
      "epoch": 10.414657666345226,
      "grad_norm": 0.003323906334117055,
      "learning_rate": 6.113789778206365e-06,
      "loss": 0.0008,
      "step": 97200
    },
    {
      "epoch": 10.415729133183328,
      "grad_norm": 0.0008152453228831291,
      "learning_rate": 6.112361155755563e-06,
      "loss": 0.0,
      "step": 97210
    },
    {
      "epoch": 10.41680060002143,
      "grad_norm": 8.188928768504411e-05,
      "learning_rate": 6.110932533304761e-06,
      "loss": 0.1243,
      "step": 97220
    },
    {
      "epoch": 10.41787206685953,
      "grad_norm": 0.0008911858894862235,
      "learning_rate": 6.10950391085396e-06,
      "loss": 0.0,
      "step": 97230
    },
    {
      "epoch": 10.418943533697632,
      "grad_norm": 7.559321238659322e-05,
      "learning_rate": 6.108075288403158e-06,
      "loss": 0.0,
      "step": 97240
    },
    {
      "epoch": 10.420015000535733,
      "grad_norm": 8.519243419868872e-05,
      "learning_rate": 6.106646665952356e-06,
      "loss": 0.0003,
      "step": 97250
    },
    {
      "epoch": 10.421086467373835,
      "grad_norm": 0.001467587542720139,
      "learning_rate": 6.105218043501554e-06,
      "loss": 0.0,
      "step": 97260
    },
    {
      "epoch": 10.422157934211937,
      "grad_norm": 165.50999450683594,
      "learning_rate": 6.103789421050752e-06,
      "loss": 0.2717,
      "step": 97270
    },
    {
      "epoch": 10.423229401050037,
      "grad_norm": 9.098092414205894e-05,
      "learning_rate": 6.10236079859995e-06,
      "loss": 0.0,
      "step": 97280
    },
    {
      "epoch": 10.424300867888139,
      "grad_norm": 0.00011278520833002403,
      "learning_rate": 6.100932176149149e-06,
      "loss": 0.0,
      "step": 97290
    },
    {
      "epoch": 10.42537233472624,
      "grad_norm": 0.0008376259938813746,
      "learning_rate": 6.099503553698347e-06,
      "loss": 0.0,
      "step": 97300
    },
    {
      "epoch": 10.426443801564341,
      "grad_norm": 0.00010681006824597716,
      "learning_rate": 6.098074931247545e-06,
      "loss": 0.1602,
      "step": 97310
    },
    {
      "epoch": 10.427515268402443,
      "grad_norm": 7.522511441493407e-05,
      "learning_rate": 6.096646308796743e-06,
      "loss": 0.0007,
      "step": 97320
    },
    {
      "epoch": 10.428586735240545,
      "grad_norm": 9.65148356044665e-05,
      "learning_rate": 6.0952176863459415e-06,
      "loss": 0.0,
      "step": 97330
    },
    {
      "epoch": 10.429658202078645,
      "grad_norm": 9.540769679006189e-05,
      "learning_rate": 6.093789063895139e-06,
      "loss": 0.0,
      "step": 97340
    },
    {
      "epoch": 10.430729668916747,
      "grad_norm": 8.671633986523375e-05,
      "learning_rate": 6.0923604414443385e-06,
      "loss": 0.0,
      "step": 97350
    },
    {
      "epoch": 10.43180113575485,
      "grad_norm": 0.0011314204894006252,
      "learning_rate": 6.090931818993536e-06,
      "loss": 0.0,
      "step": 97360
    },
    {
      "epoch": 10.43287260259295,
      "grad_norm": 0.0023759352043271065,
      "learning_rate": 6.089503196542734e-06,
      "loss": 0.0,
      "step": 97370
    },
    {
      "epoch": 10.433944069431051,
      "grad_norm": 0.00010085291432915255,
      "learning_rate": 6.088074574091932e-06,
      "loss": 0.0006,
      "step": 97380
    },
    {
      "epoch": 10.435015536269152,
      "grad_norm": 0.0008459299569949508,
      "learning_rate": 6.08664595164113e-06,
      "loss": 0.4116,
      "step": 97390
    },
    {
      "epoch": 10.436087003107254,
      "grad_norm": 0.0002086187741952017,
      "learning_rate": 6.085217329190329e-06,
      "loss": 0.0001,
      "step": 97400
    },
    {
      "epoch": 10.437158469945356,
      "grad_norm": 0.00035591659252531826,
      "learning_rate": 6.083788706739527e-06,
      "loss": 0.0001,
      "step": 97410
    },
    {
      "epoch": 10.438229936783456,
      "grad_norm": 0.00013797655992675573,
      "learning_rate": 6.082360084288726e-06,
      "loss": 0.0008,
      "step": 97420
    },
    {
      "epoch": 10.439301403621558,
      "grad_norm": 0.00014835481124464422,
      "learning_rate": 6.080931461837923e-06,
      "loss": 0.0,
      "step": 97430
    },
    {
      "epoch": 10.44037287045966,
      "grad_norm": 0.00127001095097512,
      "learning_rate": 6.079502839387121e-06,
      "loss": 0.1679,
      "step": 97440
    },
    {
      "epoch": 10.44144433729776,
      "grad_norm": 0.03145626187324524,
      "learning_rate": 6.0780742169363195e-06,
      "loss": 0.0,
      "step": 97450
    },
    {
      "epoch": 10.442515804135862,
      "grad_norm": 0.004880878608673811,
      "learning_rate": 6.076645594485517e-06,
      "loss": 0.0,
      "step": 97460
    },
    {
      "epoch": 10.443587270973964,
      "grad_norm": 19.27684211730957,
      "learning_rate": 6.0752169720347165e-06,
      "loss": 0.1246,
      "step": 97470
    },
    {
      "epoch": 10.444658737812064,
      "grad_norm": 137.60304260253906,
      "learning_rate": 6.073788349583914e-06,
      "loss": 0.1906,
      "step": 97480
    },
    {
      "epoch": 10.445730204650166,
      "grad_norm": 0.0010313157690688968,
      "learning_rate": 6.072359727133113e-06,
      "loss": 0.0,
      "step": 97490
    },
    {
      "epoch": 10.446801671488267,
      "grad_norm": 0.0006251040613278747,
      "learning_rate": 6.07093110468231e-06,
      "loss": 0.0,
      "step": 97500
    },
    {
      "epoch": 10.447873138326369,
      "grad_norm": 0.00014198102871887386,
      "learning_rate": 6.069502482231509e-06,
      "loss": 0.0,
      "step": 97510
    },
    {
      "epoch": 10.44894460516447,
      "grad_norm": 0.0009739489178173244,
      "learning_rate": 6.068073859780707e-06,
      "loss": 0.0,
      "step": 97520
    },
    {
      "epoch": 10.45001607200257,
      "grad_norm": 0.000140793330501765,
      "learning_rate": 6.066645237329906e-06,
      "loss": 0.0001,
      "step": 97530
    },
    {
      "epoch": 10.451087538840673,
      "grad_norm": 0.0019225028809159994,
      "learning_rate": 6.065216614879104e-06,
      "loss": 0.0,
      "step": 97540
    },
    {
      "epoch": 10.452159005678775,
      "grad_norm": 0.00013437207962851971,
      "learning_rate": 6.063787992428301e-06,
      "loss": 0.0,
      "step": 97550
    },
    {
      "epoch": 10.453230472516875,
      "grad_norm": 0.000402654055505991,
      "learning_rate": 6.0623593699775e-06,
      "loss": 0.0,
      "step": 97560
    },
    {
      "epoch": 10.454301939354977,
      "grad_norm": 0.0008398488280363381,
      "learning_rate": 6.0609307475266975e-06,
      "loss": 0.0,
      "step": 97570
    },
    {
      "epoch": 10.455373406193079,
      "grad_norm": 0.0002646868524607271,
      "learning_rate": 6.059502125075896e-06,
      "loss": 0.0008,
      "step": 97580
    },
    {
      "epoch": 10.45644487303118,
      "grad_norm": 0.0005521528073586524,
      "learning_rate": 6.0580735026250945e-06,
      "loss": 0.0009,
      "step": 97590
    },
    {
      "epoch": 10.457516339869281,
      "grad_norm": 0.00013323166058398783,
      "learning_rate": 6.056644880174293e-06,
      "loss": 0.0,
      "step": 97600
    },
    {
      "epoch": 10.458587806707383,
      "grad_norm": 0.004748512525111437,
      "learning_rate": 6.055216257723491e-06,
      "loss": 0.0,
      "step": 97610
    },
    {
      "epoch": 10.459659273545483,
      "grad_norm": 0.00015746369899716228,
      "learning_rate": 6.053787635272688e-06,
      "loss": 0.0,
      "step": 97620
    },
    {
      "epoch": 10.460730740383585,
      "grad_norm": 0.0016305717872455716,
      "learning_rate": 6.052359012821887e-06,
      "loss": 0.0,
      "step": 97630
    },
    {
      "epoch": 10.461802207221686,
      "grad_norm": 0.00011699809692800045,
      "learning_rate": 6.050930390371085e-06,
      "loss": 0.0,
      "step": 97640
    },
    {
      "epoch": 10.462873674059788,
      "grad_norm": 0.0001356184802716598,
      "learning_rate": 6.049501767920284e-06,
      "loss": 0.0006,
      "step": 97650
    },
    {
      "epoch": 10.46394514089789,
      "grad_norm": 0.00012828181206714362,
      "learning_rate": 6.048073145469482e-06,
      "loss": 0.0,
      "step": 97660
    },
    {
      "epoch": 10.46501660773599,
      "grad_norm": 0.00032880555954761803,
      "learning_rate": 6.04664452301868e-06,
      "loss": 0.1639,
      "step": 97670
    },
    {
      "epoch": 10.466088074574092,
      "grad_norm": 0.000697474111802876,
      "learning_rate": 6.045215900567878e-06,
      "loss": 0.0,
      "step": 97680
    },
    {
      "epoch": 10.467159541412194,
      "grad_norm": 0.000989023596048355,
      "learning_rate": 6.0437872781170755e-06,
      "loss": 0.0,
      "step": 97690
    },
    {
      "epoch": 10.468231008250294,
      "grad_norm": 0.00014307945093605667,
      "learning_rate": 6.042358655666274e-06,
      "loss": 0.0,
      "step": 97700
    },
    {
      "epoch": 10.469302475088396,
      "grad_norm": 0.017119670286774635,
      "learning_rate": 6.040930033215473e-06,
      "loss": 0.2058,
      "step": 97710
    },
    {
      "epoch": 10.470373941926498,
      "grad_norm": 0.01759822852909565,
      "learning_rate": 6.039501410764671e-06,
      "loss": 0.0,
      "step": 97720
    },
    {
      "epoch": 10.471445408764598,
      "grad_norm": 0.0007495401077903807,
      "learning_rate": 6.038072788313869e-06,
      "loss": 0.0,
      "step": 97730
    },
    {
      "epoch": 10.4725168756027,
      "grad_norm": 0.00018264070968143642,
      "learning_rate": 6.036644165863067e-06,
      "loss": 0.0,
      "step": 97740
    },
    {
      "epoch": 10.473588342440802,
      "grad_norm": 0.00013123128155712038,
      "learning_rate": 6.035215543412265e-06,
      "loss": 0.0,
      "step": 97750
    },
    {
      "epoch": 10.474659809278903,
      "grad_norm": 0.002034802921116352,
      "learning_rate": 6.033786920961463e-06,
      "loss": 0.0001,
      "step": 97760
    },
    {
      "epoch": 10.475731276117004,
      "grad_norm": 0.00013218051753938198,
      "learning_rate": 6.032358298510662e-06,
      "loss": 0.0,
      "step": 97770
    },
    {
      "epoch": 10.476802742955105,
      "grad_norm": 0.00013056860188953578,
      "learning_rate": 6.0309296760598605e-06,
      "loss": 0.0,
      "step": 97780
    },
    {
      "epoch": 10.477874209793207,
      "grad_norm": 0.00015695691399741918,
      "learning_rate": 6.029501053609058e-06,
      "loss": 0.0001,
      "step": 97790
    },
    {
      "epoch": 10.478945676631309,
      "grad_norm": 0.00015424734738189727,
      "learning_rate": 6.028072431158256e-06,
      "loss": 0.0,
      "step": 97800
    },
    {
      "epoch": 10.480017143469409,
      "grad_norm": 0.0043142749927937984,
      "learning_rate": 6.026643808707454e-06,
      "loss": 0.0,
      "step": 97810
    },
    {
      "epoch": 10.481088610307511,
      "grad_norm": 0.0001337414578301832,
      "learning_rate": 6.025215186256652e-06,
      "loss": 0.0969,
      "step": 97820
    },
    {
      "epoch": 10.482160077145613,
      "grad_norm": 0.00017187984485644847,
      "learning_rate": 6.023786563805851e-06,
      "loss": 0.0,
      "step": 97830
    },
    {
      "epoch": 10.483231543983713,
      "grad_norm": 0.00023078960657585412,
      "learning_rate": 6.022357941355049e-06,
      "loss": 0.0001,
      "step": 97840
    },
    {
      "epoch": 10.484303010821815,
      "grad_norm": 0.00014268601080402732,
      "learning_rate": 6.0209293189042476e-06,
      "loss": 0.0,
      "step": 97850
    },
    {
      "epoch": 10.485374477659917,
      "grad_norm": 0.0006075858254916966,
      "learning_rate": 6.019500696453445e-06,
      "loss": 0.0,
      "step": 97860
    },
    {
      "epoch": 10.486445944498017,
      "grad_norm": 0.0011806967668235302,
      "learning_rate": 6.018072074002643e-06,
      "loss": 0.0,
      "step": 97870
    },
    {
      "epoch": 10.48751741133612,
      "grad_norm": 0.0019686284940689802,
      "learning_rate": 6.016643451551841e-06,
      "loss": 0.0,
      "step": 97880
    },
    {
      "epoch": 10.488588878174221,
      "grad_norm": 0.00034448259975761175,
      "learning_rate": 6.015214829101039e-06,
      "loss": 0.2509,
      "step": 97890
    },
    {
      "epoch": 10.489660345012322,
      "grad_norm": 0.0008984414162114263,
      "learning_rate": 6.0137862066502385e-06,
      "loss": 0.0001,
      "step": 97900
    },
    {
      "epoch": 10.490731811850424,
      "grad_norm": 0.0007235119701363146,
      "learning_rate": 6.012357584199436e-06,
      "loss": 0.0,
      "step": 97910
    },
    {
      "epoch": 10.491803278688524,
      "grad_norm": 0.010553247295320034,
      "learning_rate": 6.010928961748635e-06,
      "loss": 0.1076,
      "step": 97920
    },
    {
      "epoch": 10.492874745526626,
      "grad_norm": 0.08107461780309677,
      "learning_rate": 6.009500339297832e-06,
      "loss": 0.1417,
      "step": 97930
    },
    {
      "epoch": 10.493946212364728,
      "grad_norm": 0.0006847723852843046,
      "learning_rate": 6.00807171684703e-06,
      "loss": 0.0,
      "step": 97940
    },
    {
      "epoch": 10.495017679202828,
      "grad_norm": 0.0001663633156567812,
      "learning_rate": 6.0066430943962285e-06,
      "loss": 0.0,
      "step": 97950
    },
    {
      "epoch": 10.49608914604093,
      "grad_norm": 0.0001293934037676081,
      "learning_rate": 6.005214471945428e-06,
      "loss": 0.1745,
      "step": 97960
    },
    {
      "epoch": 10.497160612879032,
      "grad_norm": 0.00029561592964455485,
      "learning_rate": 6.0037858494946256e-06,
      "loss": 0.0,
      "step": 97970
    },
    {
      "epoch": 10.498232079717132,
      "grad_norm": 0.0001559104712214321,
      "learning_rate": 6.002357227043823e-06,
      "loss": 0.0002,
      "step": 97980
    },
    {
      "epoch": 10.499303546555234,
      "grad_norm": 0.0008948964532464743,
      "learning_rate": 6.000928604593022e-06,
      "loss": 0.0003,
      "step": 97990
    },
    {
      "epoch": 10.500375013393336,
      "grad_norm": 0.00016146645066328347,
      "learning_rate": 5.999499982142219e-06,
      "loss": 0.0006,
      "step": 98000
    },
    {
      "epoch": 10.501446480231436,
      "grad_norm": 0.0466361902654171,
      "learning_rate": 5.998071359691417e-06,
      "loss": 0.0,
      "step": 98010
    },
    {
      "epoch": 10.502517947069538,
      "grad_norm": 0.00015136468573473394,
      "learning_rate": 5.9966427372406165e-06,
      "loss": 0.0,
      "step": 98020
    },
    {
      "epoch": 10.50358941390764,
      "grad_norm": 0.0009274753974750638,
      "learning_rate": 5.995214114789815e-06,
      "loss": 0.0004,
      "step": 98030
    },
    {
      "epoch": 10.50466088074574,
      "grad_norm": 0.00013044499792158604,
      "learning_rate": 5.993785492339013e-06,
      "loss": 0.0,
      "step": 98040
    },
    {
      "epoch": 10.505732347583843,
      "grad_norm": 0.0007286359905265272,
      "learning_rate": 5.99235686988821e-06,
      "loss": 0.0003,
      "step": 98050
    },
    {
      "epoch": 10.506803814421943,
      "grad_norm": 0.002327790716663003,
      "learning_rate": 5.990928247437409e-06,
      "loss": 0.0,
      "step": 98060
    },
    {
      "epoch": 10.507875281260045,
      "grad_norm": 0.00021849022596143186,
      "learning_rate": 5.9894996249866065e-06,
      "loss": 0.0,
      "step": 98070
    },
    {
      "epoch": 10.508946748098147,
      "grad_norm": 0.0002605420595500618,
      "learning_rate": 5.988071002535806e-06,
      "loss": 0.0001,
      "step": 98080
    },
    {
      "epoch": 10.510018214936247,
      "grad_norm": 0.0008332875440828502,
      "learning_rate": 5.9866423800850036e-06,
      "loss": 0.0002,
      "step": 98090
    },
    {
      "epoch": 10.511089681774349,
      "grad_norm": 0.00014026682765688747,
      "learning_rate": 5.985213757634202e-06,
      "loss": 0.0,
      "step": 98100
    },
    {
      "epoch": 10.512161148612451,
      "grad_norm": 0.0001361802133033052,
      "learning_rate": 5.9837851351834e-06,
      "loss": 0.0,
      "step": 98110
    },
    {
      "epoch": 10.513232615450551,
      "grad_norm": 0.00020750972907990217,
      "learning_rate": 5.982356512732597e-06,
      "loss": 0.0,
      "step": 98120
    },
    {
      "epoch": 10.514304082288653,
      "grad_norm": 0.0001367109944112599,
      "learning_rate": 5.980927890281796e-06,
      "loss": 0.0001,
      "step": 98130
    },
    {
      "epoch": 10.515375549126755,
      "grad_norm": 0.0005231474060565233,
      "learning_rate": 5.9794992678309945e-06,
      "loss": 0.0,
      "step": 98140
    },
    {
      "epoch": 10.516447015964856,
      "grad_norm": 0.00022841207101009786,
      "learning_rate": 5.978070645380193e-06,
      "loss": 0.0978,
      "step": 98150
    },
    {
      "epoch": 10.517518482802958,
      "grad_norm": 0.00014665655908174813,
      "learning_rate": 5.976642022929391e-06,
      "loss": 0.1525,
      "step": 98160
    },
    {
      "epoch": 10.518589949641058,
      "grad_norm": 0.0008869323064573109,
      "learning_rate": 5.975213400478589e-06,
      "loss": 0.0,
      "step": 98170
    },
    {
      "epoch": 10.51966141647916,
      "grad_norm": 0.0013019233010709286,
      "learning_rate": 5.973784778027787e-06,
      "loss": 0.0,
      "step": 98180
    },
    {
      "epoch": 10.520732883317262,
      "grad_norm": 0.0001416603772668168,
      "learning_rate": 5.9723561555769845e-06,
      "loss": 0.0,
      "step": 98190
    },
    {
      "epoch": 10.521804350155362,
      "grad_norm": 0.0001557966897962615,
      "learning_rate": 5.970927533126184e-06,
      "loss": 0.0,
      "step": 98200
    },
    {
      "epoch": 10.522875816993464,
      "grad_norm": 0.00019704375881701708,
      "learning_rate": 5.969498910675382e-06,
      "loss": 0.0,
      "step": 98210
    },
    {
      "epoch": 10.523947283831566,
      "grad_norm": 0.00013821171887684613,
      "learning_rate": 5.96807028822458e-06,
      "loss": 0.0,
      "step": 98220
    },
    {
      "epoch": 10.525018750669666,
      "grad_norm": 0.0001449769188184291,
      "learning_rate": 5.966641665773778e-06,
      "loss": 0.0002,
      "step": 98230
    },
    {
      "epoch": 10.526090217507768,
      "grad_norm": 0.0001157088772743009,
      "learning_rate": 5.965213043322976e-06,
      "loss": 0.0,
      "step": 98240
    },
    {
      "epoch": 10.52716168434587,
      "grad_norm": 0.00012760308163706213,
      "learning_rate": 5.963784420872174e-06,
      "loss": 0.3017,
      "step": 98250
    },
    {
      "epoch": 10.52823315118397,
      "grad_norm": 0.00014889994054101408,
      "learning_rate": 5.962355798421373e-06,
      "loss": 0.0,
      "step": 98260
    },
    {
      "epoch": 10.529304618022072,
      "grad_norm": 0.00012421621067915112,
      "learning_rate": 5.960927175970571e-06,
      "loss": 0.0001,
      "step": 98270
    },
    {
      "epoch": 10.530376084860174,
      "grad_norm": 0.0002371783193666488,
      "learning_rate": 5.9594985535197695e-06,
      "loss": 0.0001,
      "step": 98280
    },
    {
      "epoch": 10.531447551698275,
      "grad_norm": 0.00014221503806766123,
      "learning_rate": 5.958069931068967e-06,
      "loss": 0.0,
      "step": 98290
    },
    {
      "epoch": 10.532519018536377,
      "grad_norm": 0.0001200651386170648,
      "learning_rate": 5.956641308618165e-06,
      "loss": 0.0,
      "step": 98300
    },
    {
      "epoch": 10.533590485374477,
      "grad_norm": 0.001468520611524582,
      "learning_rate": 5.955212686167363e-06,
      "loss": 0.0,
      "step": 98310
    },
    {
      "epoch": 10.534661952212579,
      "grad_norm": 0.0001519698853371665,
      "learning_rate": 5.953784063716562e-06,
      "loss": 0.0,
      "step": 98320
    },
    {
      "epoch": 10.53573341905068,
      "grad_norm": 0.0007932799053378403,
      "learning_rate": 5.95235544126576e-06,
      "loss": 0.0,
      "step": 98330
    },
    {
      "epoch": 10.536804885888781,
      "grad_norm": 0.00012729110312648118,
      "learning_rate": 5.950926818814958e-06,
      "loss": 0.0,
      "step": 98340
    },
    {
      "epoch": 10.537876352726883,
      "grad_norm": 0.00016612364561297,
      "learning_rate": 5.949498196364157e-06,
      "loss": 0.0014,
      "step": 98350
    },
    {
      "epoch": 10.538947819564985,
      "grad_norm": 0.00010439434845466167,
      "learning_rate": 5.948069573913354e-06,
      "loss": 0.0,
      "step": 98360
    },
    {
      "epoch": 10.540019286403085,
      "grad_norm": 0.00016187457367777824,
      "learning_rate": 5.946640951462552e-06,
      "loss": 0.0,
      "step": 98370
    },
    {
      "epoch": 10.541090753241187,
      "grad_norm": 0.0001971342135220766,
      "learning_rate": 5.945212329011751e-06,
      "loss": 0.0002,
      "step": 98380
    },
    {
      "epoch": 10.54216222007929,
      "grad_norm": 0.0006239403155632317,
      "learning_rate": 5.943783706560949e-06,
      "loss": 0.0,
      "step": 98390
    },
    {
      "epoch": 10.54323368691739,
      "grad_norm": 0.00012982978660147637,
      "learning_rate": 5.9423550841101475e-06,
      "loss": 0.0001,
      "step": 98400
    },
    {
      "epoch": 10.544305153755491,
      "grad_norm": 0.0001290773507207632,
      "learning_rate": 5.940926461659345e-06,
      "loss": 0.0,
      "step": 98410
    },
    {
      "epoch": 10.545376620593593,
      "grad_norm": 0.0014970538904890418,
      "learning_rate": 5.939497839208544e-06,
      "loss": 0.0,
      "step": 98420
    },
    {
      "epoch": 10.546448087431694,
      "grad_norm": 0.0001310047518927604,
      "learning_rate": 5.938069216757741e-06,
      "loss": 0.0,
      "step": 98430
    },
    {
      "epoch": 10.547519554269796,
      "grad_norm": 43.23965835571289,
      "learning_rate": 5.936640594306941e-06,
      "loss": 0.2084,
      "step": 98440
    },
    {
      "epoch": 10.548591021107896,
      "grad_norm": 0.024953462183475494,
      "learning_rate": 5.935211971856138e-06,
      "loss": 0.0,
      "step": 98450
    },
    {
      "epoch": 10.549662487945998,
      "grad_norm": 0.0005374595057219267,
      "learning_rate": 5.933783349405337e-06,
      "loss": 0.0,
      "step": 98460
    },
    {
      "epoch": 10.5507339547841,
      "grad_norm": 0.00015566436923108995,
      "learning_rate": 5.932354726954535e-06,
      "loss": 0.0,
      "step": 98470
    },
    {
      "epoch": 10.5518054216222,
      "grad_norm": 0.002351431641727686,
      "learning_rate": 5.930926104503732e-06,
      "loss": 0.0,
      "step": 98480
    },
    {
      "epoch": 10.552876888460302,
      "grad_norm": 0.0011768239783123136,
      "learning_rate": 5.929497482052931e-06,
      "loss": 0.0,
      "step": 98490
    },
    {
      "epoch": 10.553948355298404,
      "grad_norm": 0.015988826751708984,
      "learning_rate": 5.928068859602129e-06,
      "loss": 0.3062,
      "step": 98500
    },
    {
      "epoch": 10.555019822136504,
      "grad_norm": 0.00011140018614241853,
      "learning_rate": 5.926640237151328e-06,
      "loss": 0.0005,
      "step": 98510
    },
    {
      "epoch": 10.556091288974606,
      "grad_norm": 0.00418508006259799,
      "learning_rate": 5.9252116147005255e-06,
      "loss": 0.0,
      "step": 98520
    },
    {
      "epoch": 10.557162755812708,
      "grad_norm": 0.00012772229092661291,
      "learning_rate": 5.923782992249724e-06,
      "loss": 0.0,
      "step": 98530
    },
    {
      "epoch": 10.558234222650809,
      "grad_norm": 0.0025847293436527252,
      "learning_rate": 5.922354369798922e-06,
      "loss": 0.0,
      "step": 98540
    },
    {
      "epoch": 10.55930568948891,
      "grad_norm": 0.004603133536875248,
      "learning_rate": 5.920925747348119e-06,
      "loss": 0.0,
      "step": 98550
    },
    {
      "epoch": 10.56037715632701,
      "grad_norm": 0.0008508928003720939,
      "learning_rate": 5.919497124897319e-06,
      "loss": 0.0,
      "step": 98560
    },
    {
      "epoch": 10.561448623165113,
      "grad_norm": 0.0031734013464301825,
      "learning_rate": 5.918068502446516e-06,
      "loss": 0.0,
      "step": 98570
    },
    {
      "epoch": 10.562520090003215,
      "grad_norm": 0.3530811071395874,
      "learning_rate": 5.916639879995715e-06,
      "loss": 0.0006,
      "step": 98580
    },
    {
      "epoch": 10.563591556841315,
      "grad_norm": 0.0001300940493820235,
      "learning_rate": 5.915211257544913e-06,
      "loss": 0.0031,
      "step": 98590
    },
    {
      "epoch": 10.564663023679417,
      "grad_norm": 0.022249532863497734,
      "learning_rate": 5.913782635094111e-06,
      "loss": 0.0,
      "step": 98600
    },
    {
      "epoch": 10.565734490517519,
      "grad_norm": 57.078102111816406,
      "learning_rate": 5.912354012643309e-06,
      "loss": 0.2633,
      "step": 98610
    },
    {
      "epoch": 10.56680595735562,
      "grad_norm": 0.00033592493855394423,
      "learning_rate": 5.910925390192508e-06,
      "loss": 0.0,
      "step": 98620
    },
    {
      "epoch": 10.567877424193721,
      "grad_norm": 0.002051660092547536,
      "learning_rate": 5.909496767741706e-06,
      "loss": 0.0,
      "step": 98630
    },
    {
      "epoch": 10.568948891031823,
      "grad_norm": 0.00011862767860293388,
      "learning_rate": 5.9080681452909035e-06,
      "loss": 0.0,
      "step": 98640
    },
    {
      "epoch": 10.570020357869923,
      "grad_norm": 0.00014584475138690323,
      "learning_rate": 5.906639522840102e-06,
      "loss": 0.0,
      "step": 98650
    },
    {
      "epoch": 10.571091824708025,
      "grad_norm": 0.00013532015145756304,
      "learning_rate": 5.9052109003893e-06,
      "loss": 0.0004,
      "step": 98660
    },
    {
      "epoch": 10.572163291546127,
      "grad_norm": 0.0011859090300276875,
      "learning_rate": 5.903782277938498e-06,
      "loss": 0.0,
      "step": 98670
    },
    {
      "epoch": 10.573234758384228,
      "grad_norm": 0.00011038382217520848,
      "learning_rate": 5.902353655487697e-06,
      "loss": 0.0,
      "step": 98680
    },
    {
      "epoch": 10.57430622522233,
      "grad_norm": 0.0001188418100355193,
      "learning_rate": 5.900925033036895e-06,
      "loss": 0.0,
      "step": 98690
    },
    {
      "epoch": 10.575377692060432,
      "grad_norm": 0.0014629886718466878,
      "learning_rate": 5.899496410586093e-06,
      "loss": 0.0,
      "step": 98700
    },
    {
      "epoch": 10.576449158898532,
      "grad_norm": 0.00012812756176572293,
      "learning_rate": 5.8980677881352914e-06,
      "loss": 0.0,
      "step": 98710
    },
    {
      "epoch": 10.577520625736634,
      "grad_norm": 0.00014461616228800267,
      "learning_rate": 5.896639165684489e-06,
      "loss": 0.0,
      "step": 98720
    },
    {
      "epoch": 10.578592092574734,
      "grad_norm": 0.00011493936472106725,
      "learning_rate": 5.895210543233687e-06,
      "loss": 0.0,
      "step": 98730
    },
    {
      "epoch": 10.579663559412836,
      "grad_norm": 0.001098829903639853,
      "learning_rate": 5.893781920782886e-06,
      "loss": 0.0,
      "step": 98740
    },
    {
      "epoch": 10.580735026250938,
      "grad_norm": 9.947785292752087e-05,
      "learning_rate": 5.892353298332084e-06,
      "loss": 0.0003,
      "step": 98750
    },
    {
      "epoch": 10.581806493089038,
      "grad_norm": 20.730037689208984,
      "learning_rate": 5.890924675881282e-06,
      "loss": 0.3054,
      "step": 98760
    },
    {
      "epoch": 10.58287795992714,
      "grad_norm": 0.00039804057450965047,
      "learning_rate": 5.88949605343048e-06,
      "loss": 0.0002,
      "step": 98770
    },
    {
      "epoch": 10.583949426765242,
      "grad_norm": 0.0011393239255994558,
      "learning_rate": 5.8880674309796785e-06,
      "loss": 0.0,
      "step": 98780
    },
    {
      "epoch": 10.585020893603343,
      "grad_norm": 0.00015707204875070602,
      "learning_rate": 5.886638808528876e-06,
      "loss": 0.0,
      "step": 98790
    },
    {
      "epoch": 10.586092360441445,
      "grad_norm": 0.002305292524397373,
      "learning_rate": 5.885210186078074e-06,
      "loss": 0.0,
      "step": 98800
    },
    {
      "epoch": 10.587163827279547,
      "grad_norm": 0.0068921917118132114,
      "learning_rate": 5.883781563627273e-06,
      "loss": 0.0001,
      "step": 98810
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 0.00017810368444770575,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.0,
      "step": 98820
    },
    {
      "epoch": 10.589306760955749,
      "grad_norm": 0.008465610444545746,
      "learning_rate": 5.8809243187256694e-06,
      "loss": 0.0,
      "step": 98830
    },
    {
      "epoch": 10.590378227793849,
      "grad_norm": 0.0017317738384008408,
      "learning_rate": 5.879495696274867e-06,
      "loss": 0.0,
      "step": 98840
    },
    {
      "epoch": 10.591449694631951,
      "grad_norm": 0.002444260520860553,
      "learning_rate": 5.878067073824066e-06,
      "loss": 0.0,
      "step": 98850
    },
    {
      "epoch": 10.592521161470053,
      "grad_norm": 0.00011899720993824303,
      "learning_rate": 5.876638451373263e-06,
      "loss": 0.0,
      "step": 98860
    },
    {
      "epoch": 10.593592628308153,
      "grad_norm": 0.00010966966510750353,
      "learning_rate": 5.875209828922463e-06,
      "loss": 0.0,
      "step": 98870
    },
    {
      "epoch": 10.594664095146255,
      "grad_norm": 0.00010252183710690588,
      "learning_rate": 5.87378120647166e-06,
      "loss": 0.0001,
      "step": 98880
    },
    {
      "epoch": 10.595735561984357,
      "grad_norm": 0.00011257349251536652,
      "learning_rate": 5.872352584020858e-06,
      "loss": 0.3004,
      "step": 98890
    },
    {
      "epoch": 10.596807028822457,
      "grad_norm": 0.00013002511695958674,
      "learning_rate": 5.8709239615700565e-06,
      "loss": 0.0,
      "step": 98900
    },
    {
      "epoch": 10.59787849566056,
      "grad_norm": 1.6701546907424927,
      "learning_rate": 5.869495339119254e-06,
      "loss": 0.0019,
      "step": 98910
    },
    {
      "epoch": 10.598949962498661,
      "grad_norm": 0.002880312269553542,
      "learning_rate": 5.868066716668453e-06,
      "loss": 0.0,
      "step": 98920
    },
    {
      "epoch": 10.600021429336762,
      "grad_norm": 0.009488776326179504,
      "learning_rate": 5.866638094217651e-06,
      "loss": 0.3144,
      "step": 98930
    },
    {
      "epoch": 10.601092896174864,
      "grad_norm": 0.061852987855672836,
      "learning_rate": 5.86520947176685e-06,
      "loss": 0.1773,
      "step": 98940
    },
    {
      "epoch": 10.602164363012964,
      "grad_norm": 0.008186141029000282,
      "learning_rate": 5.8637808493160474e-06,
      "loss": 0.0,
      "step": 98950
    },
    {
      "epoch": 10.603235829851066,
      "grad_norm": 0.013491401448845863,
      "learning_rate": 5.862352226865245e-06,
      "loss": 0.0001,
      "step": 98960
    },
    {
      "epoch": 10.604307296689168,
      "grad_norm": 0.011008811183273792,
      "learning_rate": 5.860923604414444e-06,
      "loss": 0.0001,
      "step": 98970
    },
    {
      "epoch": 10.605378763527268,
      "grad_norm": 0.00011765420640585944,
      "learning_rate": 5.859494981963641e-06,
      "loss": 0.0001,
      "step": 98980
    },
    {
      "epoch": 10.60645023036537,
      "grad_norm": 0.0001342320756521076,
      "learning_rate": 5.858066359512841e-06,
      "loss": 0.0001,
      "step": 98990
    },
    {
      "epoch": 10.607521697203472,
      "grad_norm": 0.00014096694940235466,
      "learning_rate": 5.856637737062038e-06,
      "loss": 0.0004,
      "step": 99000
    },
    {
      "epoch": 10.608593164041572,
      "grad_norm": 0.00012600577611010522,
      "learning_rate": 5.855209114611237e-06,
      "loss": 0.0006,
      "step": 99010
    },
    {
      "epoch": 10.609664630879674,
      "grad_norm": 0.3121192157268524,
      "learning_rate": 5.8537804921604345e-06,
      "loss": 0.0001,
      "step": 99020
    },
    {
      "epoch": 10.610736097717776,
      "grad_norm": 8.67729468154721e-05,
      "learning_rate": 5.852351869709633e-06,
      "loss": 0.1202,
      "step": 99030
    },
    {
      "epoch": 10.611807564555876,
      "grad_norm": 0.003075476735830307,
      "learning_rate": 5.850923247258831e-06,
      "loss": 0.1944,
      "step": 99040
    },
    {
      "epoch": 10.612879031393978,
      "grad_norm": 0.03600059822201729,
      "learning_rate": 5.84949462480803e-06,
      "loss": 0.0002,
      "step": 99050
    },
    {
      "epoch": 10.61395049823208,
      "grad_norm": 0.006824272219091654,
      "learning_rate": 5.848066002357228e-06,
      "loss": 0.2138,
      "step": 99060
    },
    {
      "epoch": 10.61502196507018,
      "grad_norm": 0.00012051960948156193,
      "learning_rate": 5.8466373799064254e-06,
      "loss": 0.2311,
      "step": 99070
    },
    {
      "epoch": 10.616093431908283,
      "grad_norm": 0.00630932254716754,
      "learning_rate": 5.845208757455624e-06,
      "loss": 0.0001,
      "step": 99080
    },
    {
      "epoch": 10.617164898746385,
      "grad_norm": 0.0001155654972535558,
      "learning_rate": 5.843780135004822e-06,
      "loss": 0.0,
      "step": 99090
    },
    {
      "epoch": 10.618236365584485,
      "grad_norm": 0.005584393162280321,
      "learning_rate": 5.84235151255402e-06,
      "loss": 0.0038,
      "step": 99100
    },
    {
      "epoch": 10.619307832422587,
      "grad_norm": 0.0006305899587459862,
      "learning_rate": 5.840922890103219e-06,
      "loss": 0.0,
      "step": 99110
    },
    {
      "epoch": 10.620379299260687,
      "grad_norm": 0.00015890550275798887,
      "learning_rate": 5.839494267652417e-06,
      "loss": 0.0001,
      "step": 99120
    },
    {
      "epoch": 10.62145076609879,
      "grad_norm": 0.0029185358434915543,
      "learning_rate": 5.838065645201615e-06,
      "loss": 0.0001,
      "step": 99130
    },
    {
      "epoch": 10.622522232936891,
      "grad_norm": 19.417612075805664,
      "learning_rate": 5.8366370227508125e-06,
      "loss": 0.1597,
      "step": 99140
    },
    {
      "epoch": 10.623593699774991,
      "grad_norm": 0.00398564338684082,
      "learning_rate": 5.835208400300011e-06,
      "loss": 0.0002,
      "step": 99150
    },
    {
      "epoch": 10.624665166613093,
      "grad_norm": 110.28658294677734,
      "learning_rate": 5.833779777849209e-06,
      "loss": 0.1138,
      "step": 99160
    },
    {
      "epoch": 10.625736633451195,
      "grad_norm": 0.00011995388194918633,
      "learning_rate": 5.832351155398408e-06,
      "loss": 0.0002,
      "step": 99170
    },
    {
      "epoch": 10.626808100289296,
      "grad_norm": 0.00011546143650775775,
      "learning_rate": 5.830922532947606e-06,
      "loss": 0.0007,
      "step": 99180
    },
    {
      "epoch": 10.627879567127398,
      "grad_norm": 0.003397203516215086,
      "learning_rate": 5.829493910496804e-06,
      "loss": 0.0,
      "step": 99190
    },
    {
      "epoch": 10.6289510339655,
      "grad_norm": 0.1167319044470787,
      "learning_rate": 5.828065288046002e-06,
      "loss": 0.1001,
      "step": 99200
    },
    {
      "epoch": 10.6300225008036,
      "grad_norm": 0.014947747811675072,
      "learning_rate": 5.8266366655952e-06,
      "loss": 0.2064,
      "step": 99210
    },
    {
      "epoch": 10.631093967641702,
      "grad_norm": 0.005186554975807667,
      "learning_rate": 5.825208043144398e-06,
      "loss": 0.0001,
      "step": 99220
    },
    {
      "epoch": 10.632165434479802,
      "grad_norm": 0.0003018852439709008,
      "learning_rate": 5.8237794206935975e-06,
      "loss": 0.0006,
      "step": 99230
    },
    {
      "epoch": 10.633236901317904,
      "grad_norm": 0.00014169636415317655,
      "learning_rate": 5.822350798242795e-06,
      "loss": 0.0001,
      "step": 99240
    },
    {
      "epoch": 10.634308368156006,
      "grad_norm": 0.00011762137728510424,
      "learning_rate": 5.820922175791993e-06,
      "loss": 0.0004,
      "step": 99250
    },
    {
      "epoch": 10.635379834994106,
      "grad_norm": 0.002074706368148327,
      "learning_rate": 5.819493553341191e-06,
      "loss": 0.0001,
      "step": 99260
    },
    {
      "epoch": 10.636451301832208,
      "grad_norm": 0.010250897146761417,
      "learning_rate": 5.818064930890389e-06,
      "loss": 0.1415,
      "step": 99270
    },
    {
      "epoch": 10.63752276867031,
      "grad_norm": 0.0001235127856489271,
      "learning_rate": 5.8166363084395876e-06,
      "loss": 0.0002,
      "step": 99280
    },
    {
      "epoch": 10.63859423550841,
      "grad_norm": 0.00010518264025449753,
      "learning_rate": 5.815207685988786e-06,
      "loss": 0.0001,
      "step": 99290
    },
    {
      "epoch": 10.639665702346512,
      "grad_norm": 0.0006163231446407735,
      "learning_rate": 5.813779063537985e-06,
      "loss": 0.0028,
      "step": 99300
    },
    {
      "epoch": 10.640737169184614,
      "grad_norm": 0.00011591561633395031,
      "learning_rate": 5.812350441087182e-06,
      "loss": 0.0,
      "step": 99310
    },
    {
      "epoch": 10.641808636022715,
      "grad_norm": 0.008445203304290771,
      "learning_rate": 5.81092181863638e-06,
      "loss": 0.0,
      "step": 99320
    },
    {
      "epoch": 10.642880102860817,
      "grad_norm": 0.004432749003171921,
      "learning_rate": 5.8094931961855785e-06,
      "loss": 0.0,
      "step": 99330
    },
    {
      "epoch": 10.643951569698919,
      "grad_norm": 0.00438886322081089,
      "learning_rate": 5.808064573734776e-06,
      "loss": 0.0,
      "step": 99340
    },
    {
      "epoch": 10.645023036537019,
      "grad_norm": 0.0001231214264407754,
      "learning_rate": 5.8066359512839755e-06,
      "loss": 0.0,
      "step": 99350
    },
    {
      "epoch": 10.64609450337512,
      "grad_norm": 0.002251283498480916,
      "learning_rate": 5.805207328833173e-06,
      "loss": 0.0,
      "step": 99360
    },
    {
      "epoch": 10.647165970213221,
      "grad_norm": 0.00011347067629685625,
      "learning_rate": 5.803778706382372e-06,
      "loss": 0.0,
      "step": 99370
    },
    {
      "epoch": 10.648237437051323,
      "grad_norm": 0.00010991730960085988,
      "learning_rate": 5.802350083931569e-06,
      "loss": 0.0001,
      "step": 99380
    },
    {
      "epoch": 10.649308903889425,
      "grad_norm": 0.00011572526273084804,
      "learning_rate": 5.800921461480767e-06,
      "loss": 0.0,
      "step": 99390
    },
    {
      "epoch": 10.650380370727525,
      "grad_norm": 0.0034534467849880457,
      "learning_rate": 5.7994928390299656e-06,
      "loss": 0.0,
      "step": 99400
    },
    {
      "epoch": 10.651451837565627,
      "grad_norm": 0.00015918903227429837,
      "learning_rate": 5.798064216579165e-06,
      "loss": 0.0,
      "step": 99410
    },
    {
      "epoch": 10.65252330440373,
      "grad_norm": 0.003187615657225251,
      "learning_rate": 5.796635594128363e-06,
      "loss": 0.0,
      "step": 99420
    },
    {
      "epoch": 10.65359477124183,
      "grad_norm": 0.003350588260218501,
      "learning_rate": 5.79520697167756e-06,
      "loss": 0.0024,
      "step": 99430
    },
    {
      "epoch": 10.654666238079932,
      "grad_norm": 0.00010226897575194016,
      "learning_rate": 5.793778349226759e-06,
      "loss": 0.0,
      "step": 99440
    },
    {
      "epoch": 10.655737704918034,
      "grad_norm": 0.0539216585457325,
      "learning_rate": 5.7923497267759565e-06,
      "loss": 0.0001,
      "step": 99450
    },
    {
      "epoch": 10.656809171756134,
      "grad_norm": 8.52704033604823e-05,
      "learning_rate": 5.790921104325154e-06,
      "loss": 0.0,
      "step": 99460
    },
    {
      "epoch": 10.657880638594236,
      "grad_norm": 9.818468242883682e-05,
      "learning_rate": 5.7894924818743535e-06,
      "loss": 0.0001,
      "step": 99470
    },
    {
      "epoch": 10.658952105432338,
      "grad_norm": 0.004254395607858896,
      "learning_rate": 5.788063859423552e-06,
      "loss": 0.2335,
      "step": 99480
    },
    {
      "epoch": 10.660023572270438,
      "grad_norm": 0.006291894242167473,
      "learning_rate": 5.78663523697275e-06,
      "loss": 0.1502,
      "step": 99490
    },
    {
      "epoch": 10.66109503910854,
      "grad_norm": 9.014997340273112e-05,
      "learning_rate": 5.785206614521947e-06,
      "loss": 0.0001,
      "step": 99500
    },
    {
      "epoch": 10.66216650594664,
      "grad_norm": 9.850487549556419e-05,
      "learning_rate": 5.783777992071146e-06,
      "loss": 0.0,
      "step": 99510
    },
    {
      "epoch": 10.663237972784742,
      "grad_norm": 9.647830302128568e-05,
      "learning_rate": 5.7823493696203436e-06,
      "loss": 0.0,
      "step": 99520
    },
    {
      "epoch": 10.664309439622844,
      "grad_norm": 0.005867662839591503,
      "learning_rate": 5.780920747169543e-06,
      "loss": 0.0005,
      "step": 99530
    },
    {
      "epoch": 10.665380906460944,
      "grad_norm": 0.0001842482015490532,
      "learning_rate": 5.779492124718741e-06,
      "loss": 0.0002,
      "step": 99540
    },
    {
      "epoch": 10.666452373299046,
      "grad_norm": 0.00011950576299568638,
      "learning_rate": 5.778063502267939e-06,
      "loss": 0.0005,
      "step": 99550
    },
    {
      "epoch": 10.667523840137148,
      "grad_norm": 0.0014915983192622662,
      "learning_rate": 5.776634879817137e-06,
      "loss": 0.0001,
      "step": 99560
    },
    {
      "epoch": 10.668595306975249,
      "grad_norm": 0.00010476888564880937,
      "learning_rate": 5.7752062573663345e-06,
      "loss": 0.0,
      "step": 99570
    },
    {
      "epoch": 10.66966677381335,
      "grad_norm": 0.0020379258785396814,
      "learning_rate": 5.773777634915533e-06,
      "loss": 0.0003,
      "step": 99580
    },
    {
      "epoch": 10.670738240651453,
      "grad_norm": 0.003008716506883502,
      "learning_rate": 5.7723490124647315e-06,
      "loss": 0.0005,
      "step": 99590
    },
    {
      "epoch": 10.671809707489553,
      "grad_norm": 0.00010128247231477872,
      "learning_rate": 5.77092039001393e-06,
      "loss": 0.0001,
      "step": 99600
    },
    {
      "epoch": 10.672881174327655,
      "grad_norm": 0.0027178723830729723,
      "learning_rate": 5.769491767563128e-06,
      "loss": 0.0,
      "step": 99610
    },
    {
      "epoch": 10.673952641165755,
      "grad_norm": 0.0027249313425272703,
      "learning_rate": 5.768063145112326e-06,
      "loss": 0.0,
      "step": 99620
    },
    {
      "epoch": 10.675024108003857,
      "grad_norm": 0.0017421654192730784,
      "learning_rate": 5.766634522661524e-06,
      "loss": 0.0002,
      "step": 99630
    },
    {
      "epoch": 10.676095574841959,
      "grad_norm": 0.00012758930097334087,
      "learning_rate": 5.7652059002107216e-06,
      "loss": 0.0,
      "step": 99640
    },
    {
      "epoch": 10.67716704168006,
      "grad_norm": 8.805137622402981e-05,
      "learning_rate": 5.763777277759921e-06,
      "loss": 0.0,
      "step": 99650
    },
    {
      "epoch": 10.678238508518161,
      "grad_norm": 9.90281259873882e-05,
      "learning_rate": 5.762348655309119e-06,
      "loss": 0.0,
      "step": 99660
    },
    {
      "epoch": 10.679309975356263,
      "grad_norm": 0.005257098004221916,
      "learning_rate": 5.760920032858317e-06,
      "loss": 0.0,
      "step": 99670
    },
    {
      "epoch": 10.680381442194363,
      "grad_norm": 0.0021129671949893236,
      "learning_rate": 5.759491410407515e-06,
      "loss": 0.0,
      "step": 99680
    },
    {
      "epoch": 10.681452909032465,
      "grad_norm": 8.775218157097697e-05,
      "learning_rate": 5.758062787956713e-06,
      "loss": 0.0,
      "step": 99690
    },
    {
      "epoch": 10.682524375870567,
      "grad_norm": 0.00010076964099425822,
      "learning_rate": 5.756634165505911e-06,
      "loss": 0.0001,
      "step": 99700
    },
    {
      "epoch": 10.683595842708668,
      "grad_norm": 0.0015980518655851483,
      "learning_rate": 5.755205543055109e-06,
      "loss": 0.0,
      "step": 99710
    },
    {
      "epoch": 10.68466730954677,
      "grad_norm": 0.002874924335628748,
      "learning_rate": 5.753776920604308e-06,
      "loss": 0.0,
      "step": 99720
    },
    {
      "epoch": 10.685738776384872,
      "grad_norm": 0.003329400671645999,
      "learning_rate": 5.7523482981535066e-06,
      "loss": 0.0,
      "step": 99730
    },
    {
      "epoch": 10.686810243222972,
      "grad_norm": 0.00010035994637291878,
      "learning_rate": 5.750919675702704e-06,
      "loss": 0.0,
      "step": 99740
    },
    {
      "epoch": 10.687881710061074,
      "grad_norm": 9.633848821977153e-05,
      "learning_rate": 5.749491053251902e-06,
      "loss": 0.0001,
      "step": 99750
    },
    {
      "epoch": 10.688953176899176,
      "grad_norm": 0.00010979159560520202,
      "learning_rate": 5.7480624308011e-06,
      "loss": 0.0,
      "step": 99760
    },
    {
      "epoch": 10.690024643737276,
      "grad_norm": 9.446607145946473e-05,
      "learning_rate": 5.746633808350298e-06,
      "loss": 0.0,
      "step": 99770
    },
    {
      "epoch": 10.691096110575378,
      "grad_norm": 0.002165068406611681,
      "learning_rate": 5.7452051858994975e-06,
      "loss": 0.0,
      "step": 99780
    },
    {
      "epoch": 10.692167577413478,
      "grad_norm": 8.73001990839839e-05,
      "learning_rate": 5.743776563448695e-06,
      "loss": 0.0,
      "step": 99790
    },
    {
      "epoch": 10.69323904425158,
      "grad_norm": 9.681456140242517e-05,
      "learning_rate": 5.742347940997894e-06,
      "loss": 0.0,
      "step": 99800
    },
    {
      "epoch": 10.694310511089682,
      "grad_norm": 8.698726742295548e-05,
      "learning_rate": 5.740919318547091e-06,
      "loss": 0.0,
      "step": 99810
    },
    {
      "epoch": 10.695381977927783,
      "grad_norm": 8.305316441692412e-05,
      "learning_rate": 5.739490696096289e-06,
      "loss": 0.0,
      "step": 99820
    },
    {
      "epoch": 10.696453444765885,
      "grad_norm": 0.00018408236792311072,
      "learning_rate": 5.7380620736454875e-06,
      "loss": 0.0,
      "step": 99830
    },
    {
      "epoch": 10.697524911603987,
      "grad_norm": 0.00012147117377026007,
      "learning_rate": 5.736633451194686e-06,
      "loss": 0.0,
      "step": 99840
    },
    {
      "epoch": 10.698596378442087,
      "grad_norm": 0.00010694029333535582,
      "learning_rate": 5.7352048287438846e-06,
      "loss": 0.0,
      "step": 99850
    },
    {
      "epoch": 10.699667845280189,
      "grad_norm": 0.0035842484794557095,
      "learning_rate": 5.733776206293082e-06,
      "loss": 0.0,
      "step": 99860
    },
    {
      "epoch": 10.70073931211829,
      "grad_norm": 0.0027836007066071033,
      "learning_rate": 5.732347583842281e-06,
      "loss": 0.0,
      "step": 99870
    },
    {
      "epoch": 10.701810778956391,
      "grad_norm": 0.001611783867701888,
      "learning_rate": 5.730918961391478e-06,
      "loss": 0.0,
      "step": 99880
    },
    {
      "epoch": 10.702882245794493,
      "grad_norm": 0.0013094282476231456,
      "learning_rate": 5.729490338940676e-06,
      "loss": 0.0003,
      "step": 99890
    },
    {
      "epoch": 10.703953712632593,
      "grad_norm": 0.09345188736915588,
      "learning_rate": 5.7280617164898755e-06,
      "loss": 0.3286,
      "step": 99900
    },
    {
      "epoch": 10.705025179470695,
      "grad_norm": 9.452395897824317e-05,
      "learning_rate": 5.726633094039073e-06,
      "loss": 0.0,
      "step": 99910
    },
    {
      "epoch": 10.706096646308797,
      "grad_norm": 0.003206198336556554,
      "learning_rate": 5.725204471588272e-06,
      "loss": 0.0005,
      "step": 99920
    },
    {
      "epoch": 10.707168113146897,
      "grad_norm": 0.00010021709749707952,
      "learning_rate": 5.723775849137469e-06,
      "loss": 0.0002,
      "step": 99930
    },
    {
      "epoch": 10.708239579985,
      "grad_norm": 0.0002616223646327853,
      "learning_rate": 5.722347226686668e-06,
      "loss": 0.0,
      "step": 99940
    },
    {
      "epoch": 10.709311046823101,
      "grad_norm": 9.50686153373681e-05,
      "learning_rate": 5.7209186042358655e-06,
      "loss": 0.0,
      "step": 99950
    },
    {
      "epoch": 10.710382513661202,
      "grad_norm": 8.515945955878124e-05,
      "learning_rate": 5.719489981785065e-06,
      "loss": 0.0,
      "step": 99960
    },
    {
      "epoch": 10.711453980499304,
      "grad_norm": 8.99742153706029e-05,
      "learning_rate": 5.7180613593342626e-06,
      "loss": 0.0002,
      "step": 99970
    },
    {
      "epoch": 10.712525447337406,
      "grad_norm": 7.685109449084848e-05,
      "learning_rate": 5.716632736883461e-06,
      "loss": 0.0,
      "step": 99980
    },
    {
      "epoch": 10.713596914175506,
      "grad_norm": 9.839041013037786e-05,
      "learning_rate": 5.715204114432659e-06,
      "loss": 0.0,
      "step": 99990
    },
    {
      "epoch": 10.714668381013608,
      "grad_norm": 0.00010257603571517393,
      "learning_rate": 5.713775491981856e-06,
      "loss": 0.0,
      "step": 100000
    },
    {
      "epoch": 10.715739847851708,
      "grad_norm": 0.00386879313737154,
      "learning_rate": 5.712346869531055e-06,
      "loss": 0.3107,
      "step": 100010
    },
    {
      "epoch": 10.71681131468981,
      "grad_norm": 8.630052616354078e-05,
      "learning_rate": 5.7109182470802535e-06,
      "loss": 0.0003,
      "step": 100020
    },
    {
      "epoch": 10.717882781527912,
      "grad_norm": 8.956676174420863e-05,
      "learning_rate": 5.709489624629452e-06,
      "loss": 0.0,
      "step": 100030
    },
    {
      "epoch": 10.718954248366012,
      "grad_norm": 0.0001267834595637396,
      "learning_rate": 5.70806100217865e-06,
      "loss": 0.0,
      "step": 100040
    },
    {
      "epoch": 10.720025715204114,
      "grad_norm": 9.389557089889422e-05,
      "learning_rate": 5.706632379727848e-06,
      "loss": 0.3605,
      "step": 100050
    },
    {
      "epoch": 10.721097182042216,
      "grad_norm": 0.009400777518749237,
      "learning_rate": 5.705203757277046e-06,
      "loss": 0.0,
      "step": 100060
    },
    {
      "epoch": 10.722168648880317,
      "grad_norm": 0.00016645558935124427,
      "learning_rate": 5.7037751348262435e-06,
      "loss": 0.0001,
      "step": 100070
    },
    {
      "epoch": 10.723240115718419,
      "grad_norm": 0.011590373702347279,
      "learning_rate": 5.702346512375443e-06,
      "loss": 0.0871,
      "step": 100080
    },
    {
      "epoch": 10.72431158255652,
      "grad_norm": 8.43093148432672e-05,
      "learning_rate": 5.7009178899246406e-06,
      "loss": 0.0004,
      "step": 100090
    },
    {
      "epoch": 10.72538304939462,
      "grad_norm": 1.1549853086471558,
      "learning_rate": 5.699489267473839e-06,
      "loss": 0.0028,
      "step": 100100
    },
    {
      "epoch": 10.726454516232723,
      "grad_norm": 7.293136150110513e-05,
      "learning_rate": 5.698060645023037e-06,
      "loss": 0.0,
      "step": 100110
    },
    {
      "epoch": 10.727525983070825,
      "grad_norm": 8.08958284324035e-05,
      "learning_rate": 5.696632022572235e-06,
      "loss": 0.0001,
      "step": 100120
    },
    {
      "epoch": 10.728597449908925,
      "grad_norm": 8.205327321775258e-05,
      "learning_rate": 5.695203400121433e-06,
      "loss": 0.0002,
      "step": 100130
    },
    {
      "epoch": 10.729668916747027,
      "grad_norm": 0.0009531370596960187,
      "learning_rate": 5.693774777670632e-06,
      "loss": 0.0009,
      "step": 100140
    },
    {
      "epoch": 10.730740383585129,
      "grad_norm": 0.0532878041267395,
      "learning_rate": 5.69234615521983e-06,
      "loss": 0.0001,
      "step": 100150
    },
    {
      "epoch": 10.73181185042323,
      "grad_norm": 0.06269792467355728,
      "learning_rate": 5.690917532769028e-06,
      "loss": 0.0001,
      "step": 100160
    },
    {
      "epoch": 10.732883317261331,
      "grad_norm": 7.600311801070347e-05,
      "learning_rate": 5.689488910318226e-06,
      "loss": 0.2067,
      "step": 100170
    },
    {
      "epoch": 10.733954784099431,
      "grad_norm": 0.019357828423380852,
      "learning_rate": 5.688060287867424e-06,
      "loss": 0.0001,
      "step": 100180
    },
    {
      "epoch": 10.735026250937533,
      "grad_norm": 9.753623453434557e-05,
      "learning_rate": 5.686631665416622e-06,
      "loss": 0.0,
      "step": 100190
    },
    {
      "epoch": 10.736097717775635,
      "grad_norm": 8.440058445557952e-05,
      "learning_rate": 5.685203042965821e-06,
      "loss": 0.0,
      "step": 100200
    },
    {
      "epoch": 10.737169184613736,
      "grad_norm": 0.00011945707956328988,
      "learning_rate": 5.683774420515019e-06,
      "loss": 0.0005,
      "step": 100210
    },
    {
      "epoch": 10.738240651451838,
      "grad_norm": 0.00455356203019619,
      "learning_rate": 5.682345798064217e-06,
      "loss": 0.0,
      "step": 100220
    },
    {
      "epoch": 10.73931211828994,
      "grad_norm": 8.710973634151742e-05,
      "learning_rate": 5.680917175613415e-06,
      "loss": 0.0001,
      "step": 100230
    },
    {
      "epoch": 10.74038358512804,
      "grad_norm": 0.0027620727196335793,
      "learning_rate": 5.679488553162613e-06,
      "loss": 0.0,
      "step": 100240
    },
    {
      "epoch": 10.741455051966142,
      "grad_norm": 9.414437954546884e-05,
      "learning_rate": 5.678059930711811e-06,
      "loss": 0.0001,
      "step": 100250
    },
    {
      "epoch": 10.742526518804244,
      "grad_norm": 0.00019660149700939655,
      "learning_rate": 5.67663130826101e-06,
      "loss": 0.0001,
      "step": 100260
    },
    {
      "epoch": 10.743597985642344,
      "grad_norm": 8.130191417876631e-05,
      "learning_rate": 5.675202685810208e-06,
      "loss": 0.0001,
      "step": 100270
    },
    {
      "epoch": 10.744669452480446,
      "grad_norm": 8.877760410541669e-05,
      "learning_rate": 5.6737740633594065e-06,
      "loss": 0.1932,
      "step": 100280
    },
    {
      "epoch": 10.745740919318546,
      "grad_norm": 8.731850539334118e-05,
      "learning_rate": 5.672345440908604e-06,
      "loss": 0.0004,
      "step": 100290
    },
    {
      "epoch": 10.746812386156648,
      "grad_norm": 0.006546976510435343,
      "learning_rate": 5.670916818457803e-06,
      "loss": 0.1895,
      "step": 100300
    },
    {
      "epoch": 10.74788385299475,
      "grad_norm": 0.002956320531666279,
      "learning_rate": 5.669488196007e-06,
      "loss": 0.0018,
      "step": 100310
    },
    {
      "epoch": 10.74895531983285,
      "grad_norm": 9.412716462975368e-05,
      "learning_rate": 5.6680595735562e-06,
      "loss": 0.0001,
      "step": 100320
    },
    {
      "epoch": 10.750026786670952,
      "grad_norm": 8.265188080258667e-05,
      "learning_rate": 5.666630951105397e-06,
      "loss": 0.0,
      "step": 100330
    },
    {
      "epoch": 10.751098253509054,
      "grad_norm": 0.0001013904475257732,
      "learning_rate": 5.665202328654595e-06,
      "loss": 0.0,
      "step": 100340
    },
    {
      "epoch": 10.752169720347155,
      "grad_norm": 7.946938421810046e-05,
      "learning_rate": 5.663773706203794e-06,
      "loss": 0.0001,
      "step": 100350
    },
    {
      "epoch": 10.753241187185257,
      "grad_norm": 36.29079055786133,
      "learning_rate": 5.662345083752991e-06,
      "loss": 0.4396,
      "step": 100360
    },
    {
      "epoch": 10.754312654023359,
      "grad_norm": 0.005878187716007233,
      "learning_rate": 5.66091646130219e-06,
      "loss": 0.0003,
      "step": 100370
    },
    {
      "epoch": 10.755384120861459,
      "grad_norm": 0.004435770679265261,
      "learning_rate": 5.659487838851388e-06,
      "loss": 0.2145,
      "step": 100380
    },
    {
      "epoch": 10.756455587699561,
      "grad_norm": 0.00012043750757584348,
      "learning_rate": 5.658059216400587e-06,
      "loss": 0.0,
      "step": 100390
    },
    {
      "epoch": 10.757527054537663,
      "grad_norm": 0.00563067989423871,
      "learning_rate": 5.6566305939497845e-06,
      "loss": 0.0001,
      "step": 100400
    },
    {
      "epoch": 10.758598521375763,
      "grad_norm": 0.00012776895891875029,
      "learning_rate": 5.655201971498982e-06,
      "loss": 0.0,
      "step": 100410
    },
    {
      "epoch": 10.759669988213865,
      "grad_norm": 0.0006192316650412977,
      "learning_rate": 5.653773349048181e-06,
      "loss": 0.2154,
      "step": 100420
    },
    {
      "epoch": 10.760741455051965,
      "grad_norm": 0.002546448027715087,
      "learning_rate": 5.652344726597378e-06,
      "loss": 0.0,
      "step": 100430
    },
    {
      "epoch": 10.761812921890067,
      "grad_norm": 0.010261882096529007,
      "learning_rate": 5.650916104146578e-06,
      "loss": 0.0002,
      "step": 100440
    },
    {
      "epoch": 10.76288438872817,
      "grad_norm": 0.0018958202563226223,
      "learning_rate": 5.649487481695775e-06,
      "loss": 0.0003,
      "step": 100450
    },
    {
      "epoch": 10.76395585556627,
      "grad_norm": 0.0036483285948634148,
      "learning_rate": 5.648058859244974e-06,
      "loss": 0.0001,
      "step": 100460
    },
    {
      "epoch": 10.765027322404372,
      "grad_norm": 0.0015582331689074636,
      "learning_rate": 5.646630236794172e-06,
      "loss": 0.0,
      "step": 100470
    },
    {
      "epoch": 10.766098789242474,
      "grad_norm": 0.0020747771486639977,
      "learning_rate": 5.645201614343369e-06,
      "loss": 0.0,
      "step": 100480
    },
    {
      "epoch": 10.767170256080574,
      "grad_norm": 0.0066987392492592335,
      "learning_rate": 5.643772991892568e-06,
      "loss": 0.0,
      "step": 100490
    },
    {
      "epoch": 10.768241722918676,
      "grad_norm": 0.010481659322977066,
      "learning_rate": 5.642344369441767e-06,
      "loss": 0.0,
      "step": 100500
    },
    {
      "epoch": 10.769313189756778,
      "grad_norm": 0.004379989579319954,
      "learning_rate": 5.640915746990965e-06,
      "loss": 0.0001,
      "step": 100510
    },
    {
      "epoch": 10.770384656594878,
      "grad_norm": 0.00011023048136848956,
      "learning_rate": 5.6394871245401625e-06,
      "loss": 0.0006,
      "step": 100520
    },
    {
      "epoch": 10.77145612343298,
      "grad_norm": 0.0028727876488119364,
      "learning_rate": 5.638058502089361e-06,
      "loss": 0.0,
      "step": 100530
    },
    {
      "epoch": 10.772527590271082,
      "grad_norm": 0.00018109602387994528,
      "learning_rate": 5.636629879638559e-06,
      "loss": 0.0,
      "step": 100540
    },
    {
      "epoch": 10.773599057109182,
      "grad_norm": 0.00323481229133904,
      "learning_rate": 5.635201257187757e-06,
      "loss": 0.1813,
      "step": 100550
    },
    {
      "epoch": 10.774670523947284,
      "grad_norm": 0.0012917352141812444,
      "learning_rate": 5.633772634736956e-06,
      "loss": 0.0,
      "step": 100560
    },
    {
      "epoch": 10.775741990785384,
      "grad_norm": 0.0017988394247367978,
      "learning_rate": 5.632344012286154e-06,
      "loss": 0.0,
      "step": 100570
    },
    {
      "epoch": 10.776813457623486,
      "grad_norm": 0.0014714786084368825,
      "learning_rate": 5.630915389835352e-06,
      "loss": 0.0,
      "step": 100580
    },
    {
      "epoch": 10.777884924461588,
      "grad_norm": 0.0020214130636304617,
      "learning_rate": 5.62948676738455e-06,
      "loss": 0.0001,
      "step": 100590
    },
    {
      "epoch": 10.778956391299689,
      "grad_norm": 0.00012294025509618223,
      "learning_rate": 5.628058144933748e-06,
      "loss": 0.0,
      "step": 100600
    },
    {
      "epoch": 10.78002785813779,
      "grad_norm": 0.00010813933477038518,
      "learning_rate": 5.626629522482946e-06,
      "loss": 0.0,
      "step": 100610
    },
    {
      "epoch": 10.781099324975893,
      "grad_norm": 0.0001067152334144339,
      "learning_rate": 5.625200900032144e-06,
      "loss": 0.0021,
      "step": 100620
    },
    {
      "epoch": 10.782170791813993,
      "grad_norm": 0.007214696146547794,
      "learning_rate": 5.623772277581343e-06,
      "loss": 0.0,
      "step": 100630
    },
    {
      "epoch": 10.783242258652095,
      "grad_norm": 0.013804265297949314,
      "learning_rate": 5.622343655130541e-06,
      "loss": 0.1312,
      "step": 100640
    },
    {
      "epoch": 10.784313725490197,
      "grad_norm": 16.864625930786133,
      "learning_rate": 5.620915032679739e-06,
      "loss": 0.1357,
      "step": 100650
    },
    {
      "epoch": 10.785385192328297,
      "grad_norm": 0.0001067603807314299,
      "learning_rate": 5.619486410228937e-06,
      "loss": 0.0,
      "step": 100660
    },
    {
      "epoch": 10.786456659166399,
      "grad_norm": 0.0001346504141110927,
      "learning_rate": 5.618057787778135e-06,
      "loss": 0.0007,
      "step": 100670
    },
    {
      "epoch": 10.7875281260045,
      "grad_norm": 0.00012543929915409535,
      "learning_rate": 5.616629165327333e-06,
      "loss": 0.0,
      "step": 100680
    },
    {
      "epoch": 10.788599592842601,
      "grad_norm": 9.595679875928909e-05,
      "learning_rate": 5.615200542876532e-06,
      "loss": 0.0,
      "step": 100690
    },
    {
      "epoch": 10.789671059680703,
      "grad_norm": 0.00020650457008741796,
      "learning_rate": 5.61377192042573e-06,
      "loss": 0.1995,
      "step": 100700
    },
    {
      "epoch": 10.790742526518804,
      "grad_norm": 0.0016686635790392756,
      "learning_rate": 5.6123432979749284e-06,
      "loss": 0.0011,
      "step": 100710
    },
    {
      "epoch": 10.791813993356905,
      "grad_norm": 0.00010837706213351339,
      "learning_rate": 5.610914675524126e-06,
      "loss": 0.0,
      "step": 100720
    },
    {
      "epoch": 10.792885460195007,
      "grad_norm": 0.0019186728168278933,
      "learning_rate": 5.609486053073324e-06,
      "loss": 0.0,
      "step": 100730
    },
    {
      "epoch": 10.793956927033108,
      "grad_norm": 0.0007988412398844957,
      "learning_rate": 5.608057430622522e-06,
      "loss": 0.0004,
      "step": 100740
    },
    {
      "epoch": 10.79502839387121,
      "grad_norm": 0.000858148152474314,
      "learning_rate": 5.606628808171722e-06,
      "loss": 0.0002,
      "step": 100750
    },
    {
      "epoch": 10.796099860709312,
      "grad_norm": 0.007110496051609516,
      "learning_rate": 5.605200185720919e-06,
      "loss": 0.0006,
      "step": 100760
    },
    {
      "epoch": 10.797171327547412,
      "grad_norm": 0.14918291568756104,
      "learning_rate": 5.603771563270117e-06,
      "loss": 0.0007,
      "step": 100770
    },
    {
      "epoch": 10.798242794385514,
      "grad_norm": 0.0006509954109787941,
      "learning_rate": 5.6023429408193155e-06,
      "loss": 0.0,
      "step": 100780
    },
    {
      "epoch": 10.799314261223616,
      "grad_norm": 0.00010739042772911489,
      "learning_rate": 5.600914318368513e-06,
      "loss": 0.142,
      "step": 100790
    },
    {
      "epoch": 10.800385728061716,
      "grad_norm": 0.2035437375307083,
      "learning_rate": 5.599485695917711e-06,
      "loss": 0.001,
      "step": 100800
    },
    {
      "epoch": 10.801457194899818,
      "grad_norm": 0.0001342892792308703,
      "learning_rate": 5.59805707346691e-06,
      "loss": 0.0,
      "step": 100810
    },
    {
      "epoch": 10.80252866173792,
      "grad_norm": 0.013000819832086563,
      "learning_rate": 5.596628451016109e-06,
      "loss": 0.0003,
      "step": 100820
    },
    {
      "epoch": 10.80360012857602,
      "grad_norm": 0.00010375578131061047,
      "learning_rate": 5.5951998285653064e-06,
      "loss": 0.0,
      "step": 100830
    },
    {
      "epoch": 10.804671595414122,
      "grad_norm": 9.865801257546991e-05,
      "learning_rate": 5.593771206114504e-06,
      "loss": 0.0,
      "step": 100840
    },
    {
      "epoch": 10.805743062252223,
      "grad_norm": 9.830807539401576e-05,
      "learning_rate": 5.592342583663703e-06,
      "loss": 0.0006,
      "step": 100850
    },
    {
      "epoch": 10.806814529090325,
      "grad_norm": 0.00012755986244883388,
      "learning_rate": 5.5909139612129e-06,
      "loss": 0.0,
      "step": 100860
    },
    {
      "epoch": 10.807885995928427,
      "grad_norm": 0.00011493054626043886,
      "learning_rate": 5.5894853387621e-06,
      "loss": 0.2778,
      "step": 100870
    },
    {
      "epoch": 10.808957462766527,
      "grad_norm": 0.0009910163935273886,
      "learning_rate": 5.588056716311297e-06,
      "loss": 0.0,
      "step": 100880
    },
    {
      "epoch": 10.810028929604629,
      "grad_norm": 0.001114367856644094,
      "learning_rate": 5.586628093860496e-06,
      "loss": 0.0,
      "step": 100890
    },
    {
      "epoch": 10.81110039644273,
      "grad_norm": 0.00010585932614048943,
      "learning_rate": 5.5851994714096935e-06,
      "loss": 0.0,
      "step": 100900
    },
    {
      "epoch": 10.812171863280831,
      "grad_norm": 0.00011182040179846808,
      "learning_rate": 5.583770848958891e-06,
      "loss": 0.0002,
      "step": 100910
    },
    {
      "epoch": 10.813243330118933,
      "grad_norm": 0.02023928053677082,
      "learning_rate": 5.58234222650809e-06,
      "loss": 0.3207,
      "step": 100920
    },
    {
      "epoch": 10.814314796957035,
      "grad_norm": 0.00027997963479720056,
      "learning_rate": 5.580913604057288e-06,
      "loss": 0.0006,
      "step": 100930
    },
    {
      "epoch": 10.815386263795135,
      "grad_norm": 0.00010878629836952314,
      "learning_rate": 5.579484981606487e-06,
      "loss": 0.3321,
      "step": 100940
    },
    {
      "epoch": 10.816457730633237,
      "grad_norm": 0.004199147690087557,
      "learning_rate": 5.5780563591556844e-06,
      "loss": 0.0,
      "step": 100950
    },
    {
      "epoch": 10.817529197471337,
      "grad_norm": 0.0033272902946919203,
      "learning_rate": 5.576627736704883e-06,
      "loss": 0.0,
      "step": 100960
    },
    {
      "epoch": 10.81860066430944,
      "grad_norm": 0.0021520915906876326,
      "learning_rate": 5.575199114254081e-06,
      "loss": 0.0,
      "step": 100970
    },
    {
      "epoch": 10.819672131147541,
      "grad_norm": 0.010866781696677208,
      "learning_rate": 5.573770491803278e-06,
      "loss": 0.0004,
      "step": 100980
    },
    {
      "epoch": 10.820743597985642,
      "grad_norm": 0.00023776356829330325,
      "learning_rate": 5.572341869352478e-06,
      "loss": 0.0,
      "step": 100990
    },
    {
      "epoch": 10.821815064823744,
      "grad_norm": 0.0007819513557478786,
      "learning_rate": 5.570913246901676e-06,
      "loss": 0.1253,
      "step": 101000
    },
    {
      "epoch": 10.822886531661846,
      "grad_norm": 0.00012096493446733803,
      "learning_rate": 5.569484624450874e-06,
      "loss": 0.0002,
      "step": 101010
    },
    {
      "epoch": 10.823957998499946,
      "grad_norm": 0.0046430169604718685,
      "learning_rate": 5.5680560020000715e-06,
      "loss": 0.1143,
      "step": 101020
    },
    {
      "epoch": 10.825029465338048,
      "grad_norm": 0.0065244752913713455,
      "learning_rate": 5.56662737954927e-06,
      "loss": 0.1408,
      "step": 101030
    },
    {
      "epoch": 10.82610093217615,
      "grad_norm": 0.00017561862478032708,
      "learning_rate": 5.565198757098468e-06,
      "loss": 0.0,
      "step": 101040
    },
    {
      "epoch": 10.82717239901425,
      "grad_norm": 0.00014241076132748276,
      "learning_rate": 5.563770134647667e-06,
      "loss": 0.0,
      "step": 101050
    },
    {
      "epoch": 10.828243865852352,
      "grad_norm": 0.01759253442287445,
      "learning_rate": 5.562341512196865e-06,
      "loss": 0.0,
      "step": 101060
    },
    {
      "epoch": 10.829315332690452,
      "grad_norm": 0.0003099200257565826,
      "learning_rate": 5.560912889746063e-06,
      "loss": 0.0001,
      "step": 101070
    },
    {
      "epoch": 10.830386799528554,
      "grad_norm": 0.00019427866209298372,
      "learning_rate": 5.559484267295261e-06,
      "loss": 0.0001,
      "step": 101080
    },
    {
      "epoch": 10.831458266366656,
      "grad_norm": 0.0031857804860919714,
      "learning_rate": 5.558055644844459e-06,
      "loss": 0.0,
      "step": 101090
    },
    {
      "epoch": 10.832529733204757,
      "grad_norm": 0.00016549807332921773,
      "learning_rate": 5.556627022393657e-06,
      "loss": 0.0,
      "step": 101100
    },
    {
      "epoch": 10.833601200042859,
      "grad_norm": 0.007144683040678501,
      "learning_rate": 5.555198399942856e-06,
      "loss": 0.0,
      "step": 101110
    },
    {
      "epoch": 10.83467266688096,
      "grad_norm": 0.0001939040084835142,
      "learning_rate": 5.553769777492054e-06,
      "loss": 0.0,
      "step": 101120
    },
    {
      "epoch": 10.83574413371906,
      "grad_norm": 0.00013402920740190893,
      "learning_rate": 5.552341155041252e-06,
      "loss": 0.0001,
      "step": 101130
    },
    {
      "epoch": 10.836815600557163,
      "grad_norm": 0.00022513563453685492,
      "learning_rate": 5.55091253259045e-06,
      "loss": 0.0,
      "step": 101140
    },
    {
      "epoch": 10.837887067395265,
      "grad_norm": 75.92523193359375,
      "learning_rate": 5.549483910139648e-06,
      "loss": 0.2018,
      "step": 101150
    },
    {
      "epoch": 10.838958534233365,
      "grad_norm": 0.0476071797311306,
      "learning_rate": 5.548055287688846e-06,
      "loss": 0.0001,
      "step": 101160
    },
    {
      "epoch": 10.840030001071467,
      "grad_norm": 0.00029145233565941453,
      "learning_rate": 5.546626665238045e-06,
      "loss": 0.0,
      "step": 101170
    },
    {
      "epoch": 10.841101467909569,
      "grad_norm": 0.0012440572027117014,
      "learning_rate": 5.545198042787243e-06,
      "loss": 0.0,
      "step": 101180
    },
    {
      "epoch": 10.84217293474767,
      "grad_norm": 0.0012129738461226225,
      "learning_rate": 5.543769420336441e-06,
      "loss": 0.0002,
      "step": 101190
    },
    {
      "epoch": 10.843244401585771,
      "grad_norm": 0.05455949902534485,
      "learning_rate": 5.542340797885639e-06,
      "loss": 0.0001,
      "step": 101200
    },
    {
      "epoch": 10.844315868423873,
      "grad_norm": 0.004870258271694183,
      "learning_rate": 5.5409121754348375e-06,
      "loss": 0.2529,
      "step": 101210
    },
    {
      "epoch": 10.845387335261973,
      "grad_norm": 20.2308406829834,
      "learning_rate": 5.539483552984035e-06,
      "loss": 0.0904,
      "step": 101220
    },
    {
      "epoch": 10.846458802100075,
      "grad_norm": 0.00013796903658658266,
      "learning_rate": 5.5380549305332345e-06,
      "loss": 0.0,
      "step": 101230
    },
    {
      "epoch": 10.847530268938176,
      "grad_norm": 0.00015189587429631501,
      "learning_rate": 5.536626308082432e-06,
      "loss": 0.0,
      "step": 101240
    },
    {
      "epoch": 10.848601735776278,
      "grad_norm": 0.0002872708428185433,
      "learning_rate": 5.535197685631631e-06,
      "loss": 0.0003,
      "step": 101250
    },
    {
      "epoch": 10.84967320261438,
      "grad_norm": 0.00020552604109980166,
      "learning_rate": 5.533769063180828e-06,
      "loss": 0.0797,
      "step": 101260
    },
    {
      "epoch": 10.85074466945248,
      "grad_norm": 0.06659281998872757,
      "learning_rate": 5.532340440730026e-06,
      "loss": 0.0001,
      "step": 101270
    },
    {
      "epoch": 10.851816136290582,
      "grad_norm": 0.0012107231887057424,
      "learning_rate": 5.5309118182792246e-06,
      "loss": 0.0,
      "step": 101280
    },
    {
      "epoch": 10.852887603128684,
      "grad_norm": 0.0026057413779199123,
      "learning_rate": 5.529483195828423e-06,
      "loss": 0.0001,
      "step": 101290
    },
    {
      "epoch": 10.853959069966784,
      "grad_norm": 0.013006465509533882,
      "learning_rate": 5.528054573377622e-06,
      "loss": 0.0002,
      "step": 101300
    },
    {
      "epoch": 10.855030536804886,
      "grad_norm": 0.00012729740410577506,
      "learning_rate": 5.526625950926819e-06,
      "loss": 0.0,
      "step": 101310
    },
    {
      "epoch": 10.856102003642988,
      "grad_norm": 0.0008701645419932902,
      "learning_rate": 5.525197328476018e-06,
      "loss": 0.0004,
      "step": 101320
    },
    {
      "epoch": 10.857173470481088,
      "grad_norm": 0.00015655231254640967,
      "learning_rate": 5.5237687060252155e-06,
      "loss": 0.0,
      "step": 101330
    },
    {
      "epoch": 10.85824493731919,
      "grad_norm": 0.0001270435022888705,
      "learning_rate": 5.522340083574413e-06,
      "loss": 0.0,
      "step": 101340
    },
    {
      "epoch": 10.85931640415729,
      "grad_norm": 0.00014612916857004166,
      "learning_rate": 5.5209114611236125e-06,
      "loss": 0.0001,
      "step": 101350
    },
    {
      "epoch": 10.860387870995392,
      "grad_norm": 0.0001973264297703281,
      "learning_rate": 5.51948283867281e-06,
      "loss": 0.0,
      "step": 101360
    },
    {
      "epoch": 10.861459337833494,
      "grad_norm": 4.843814373016357,
      "learning_rate": 5.518054216222009e-06,
      "loss": 0.0046,
      "step": 101370
    },
    {
      "epoch": 10.862530804671595,
      "grad_norm": 0.0021382998675107956,
      "learning_rate": 5.516625593771206e-06,
      "loss": 0.0,
      "step": 101380
    },
    {
      "epoch": 10.863602271509697,
      "grad_norm": 0.0001355079293716699,
      "learning_rate": 5.515196971320405e-06,
      "loss": 0.001,
      "step": 101390
    },
    {
      "epoch": 10.864673738347799,
      "grad_norm": 0.00014649878721684217,
      "learning_rate": 5.5137683488696026e-06,
      "loss": 0.0,
      "step": 101400
    },
    {
      "epoch": 10.865745205185899,
      "grad_norm": 0.0006270399899221957,
      "learning_rate": 5.512339726418802e-06,
      "loss": 0.0949,
      "step": 101410
    },
    {
      "epoch": 10.866816672024001,
      "grad_norm": 0.0001430739794159308,
      "learning_rate": 5.510911103968e-06,
      "loss": 0.0,
      "step": 101420
    },
    {
      "epoch": 10.867888138862103,
      "grad_norm": 0.013345270417630672,
      "learning_rate": 5.509482481517197e-06,
      "loss": 0.0,
      "step": 101430
    },
    {
      "epoch": 10.868959605700203,
      "grad_norm": 0.0001667768956394866,
      "learning_rate": 5.508053859066396e-06,
      "loss": 0.1528,
      "step": 101440
    },
    {
      "epoch": 10.870031072538305,
      "grad_norm": 0.0001211669878102839,
      "learning_rate": 5.5066252366155935e-06,
      "loss": 0.0,
      "step": 101450
    },
    {
      "epoch": 10.871102539376405,
      "grad_norm": 0.0001261941943084821,
      "learning_rate": 5.505196614164792e-06,
      "loss": 0.0,
      "step": 101460
    },
    {
      "epoch": 10.872174006214507,
      "grad_norm": 0.0011679577874019742,
      "learning_rate": 5.5037679917139905e-06,
      "loss": 0.0,
      "step": 101470
    },
    {
      "epoch": 10.87324547305261,
      "grad_norm": 0.00012721840175800025,
      "learning_rate": 5.502339369263189e-06,
      "loss": 0.0956,
      "step": 101480
    },
    {
      "epoch": 10.87431693989071,
      "grad_norm": 0.0001192789277411066,
      "learning_rate": 5.500910746812387e-06,
      "loss": 0.0001,
      "step": 101490
    },
    {
      "epoch": 10.875388406728812,
      "grad_norm": 0.0008049365133047104,
      "learning_rate": 5.499482124361584e-06,
      "loss": 0.0001,
      "step": 101500
    },
    {
      "epoch": 10.876459873566914,
      "grad_norm": 0.00011199570872122422,
      "learning_rate": 5.498053501910783e-06,
      "loss": 0.2611,
      "step": 101510
    },
    {
      "epoch": 10.877531340405014,
      "grad_norm": 0.0006127270171418786,
      "learning_rate": 5.4966248794599806e-06,
      "loss": 0.0,
      "step": 101520
    },
    {
      "epoch": 10.878602807243116,
      "grad_norm": 0.002993617905303836,
      "learning_rate": 5.495196257009179e-06,
      "loss": 0.0,
      "step": 101530
    },
    {
      "epoch": 10.879674274081218,
      "grad_norm": 0.0008797857444733381,
      "learning_rate": 5.493767634558378e-06,
      "loss": 0.0,
      "step": 101540
    },
    {
      "epoch": 10.880745740919318,
      "grad_norm": 0.0001911023136926815,
      "learning_rate": 5.492339012107576e-06,
      "loss": 0.0,
      "step": 101550
    },
    {
      "epoch": 10.88181720775742,
      "grad_norm": 0.0008866232819855213,
      "learning_rate": 5.490910389656774e-06,
      "loss": 0.0003,
      "step": 101560
    },
    {
      "epoch": 10.882888674595522,
      "grad_norm": 0.0011070751352235675,
      "learning_rate": 5.489481767205972e-06,
      "loss": 0.0011,
      "step": 101570
    },
    {
      "epoch": 10.883960141433622,
      "grad_norm": 0.000481671275338158,
      "learning_rate": 5.48805314475517e-06,
      "loss": 0.0,
      "step": 101580
    },
    {
      "epoch": 10.885031608271724,
      "grad_norm": 0.13636071979999542,
      "learning_rate": 5.486624522304368e-06,
      "loss": 0.0002,
      "step": 101590
    },
    {
      "epoch": 10.886103075109826,
      "grad_norm": 0.00017155692330561578,
      "learning_rate": 5.485195899853567e-06,
      "loss": 0.0,
      "step": 101600
    },
    {
      "epoch": 10.887174541947926,
      "grad_norm": 0.0008057613740675151,
      "learning_rate": 5.483767277402765e-06,
      "loss": 0.0,
      "step": 101610
    },
    {
      "epoch": 10.888246008786028,
      "grad_norm": 0.0008293363498523831,
      "learning_rate": 5.482338654951963e-06,
      "loss": 0.0,
      "step": 101620
    },
    {
      "epoch": 10.889317475624129,
      "grad_norm": 0.00011835032637463883,
      "learning_rate": 5.480910032501161e-06,
      "loss": 0.0,
      "step": 101630
    },
    {
      "epoch": 10.89038894246223,
      "grad_norm": 0.0009027292253449559,
      "learning_rate": 5.479481410050359e-06,
      "loss": 0.0,
      "step": 101640
    },
    {
      "epoch": 10.891460409300333,
      "grad_norm": 0.00019334051467012614,
      "learning_rate": 5.478052787599557e-06,
      "loss": 0.0,
      "step": 101650
    },
    {
      "epoch": 10.892531876138433,
      "grad_norm": 0.00012058611901011318,
      "learning_rate": 5.4766241651487565e-06,
      "loss": 0.0,
      "step": 101660
    },
    {
      "epoch": 10.893603342976535,
      "grad_norm": 9.504097397439182e-05,
      "learning_rate": 5.475195542697954e-06,
      "loss": 0.0,
      "step": 101670
    },
    {
      "epoch": 10.894674809814637,
      "grad_norm": 0.0019923315849155188,
      "learning_rate": 5.473766920247152e-06,
      "loss": 0.0001,
      "step": 101680
    },
    {
      "epoch": 10.895746276652737,
      "grad_norm": 0.0015817864332348108,
      "learning_rate": 5.47233829779635e-06,
      "loss": 0.0,
      "step": 101690
    },
    {
      "epoch": 10.896817743490839,
      "grad_norm": 9.737451182445511e-05,
      "learning_rate": 5.470909675345548e-06,
      "loss": 0.3258,
      "step": 101700
    },
    {
      "epoch": 10.897889210328941,
      "grad_norm": 0.00010141284292330965,
      "learning_rate": 5.4694810528947465e-06,
      "loss": 0.0002,
      "step": 101710
    },
    {
      "epoch": 10.898960677167041,
      "grad_norm": 0.0006358401151373982,
      "learning_rate": 5.468052430443945e-06,
      "loss": 0.0,
      "step": 101720
    },
    {
      "epoch": 10.900032144005143,
      "grad_norm": 0.005569837987422943,
      "learning_rate": 5.4666238079931435e-06,
      "loss": 0.0,
      "step": 101730
    },
    {
      "epoch": 10.901103610843244,
      "grad_norm": 0.001495943171903491,
      "learning_rate": 5.465195185542341e-06,
      "loss": 0.0,
      "step": 101740
    },
    {
      "epoch": 10.902175077681346,
      "grad_norm": 0.00011889847519341856,
      "learning_rate": 5.463766563091539e-06,
      "loss": 0.0,
      "step": 101750
    },
    {
      "epoch": 10.903246544519448,
      "grad_norm": 0.00012477868585847318,
      "learning_rate": 5.462337940640737e-06,
      "loss": 0.0,
      "step": 101760
    },
    {
      "epoch": 10.904318011357548,
      "grad_norm": 0.00010728648339863867,
      "learning_rate": 5.460909318189935e-06,
      "loss": 0.0,
      "step": 101770
    },
    {
      "epoch": 10.90538947819565,
      "grad_norm": 0.0015923125902190804,
      "learning_rate": 5.4594806957391345e-06,
      "loss": 0.0,
      "step": 101780
    },
    {
      "epoch": 10.906460945033752,
      "grad_norm": 0.00032788788666948676,
      "learning_rate": 5.458052073288332e-06,
      "loss": 0.0,
      "step": 101790
    },
    {
      "epoch": 10.907532411871852,
      "grad_norm": 0.0011003209510818124,
      "learning_rate": 5.456623450837531e-06,
      "loss": 0.2712,
      "step": 101800
    },
    {
      "epoch": 10.908603878709954,
      "grad_norm": 0.00040430150693282485,
      "learning_rate": 5.455194828386728e-06,
      "loss": 0.0,
      "step": 101810
    },
    {
      "epoch": 10.909675345548056,
      "grad_norm": 0.0002848002186510712,
      "learning_rate": 5.453766205935927e-06,
      "loss": 0.0,
      "step": 101820
    },
    {
      "epoch": 10.910746812386156,
      "grad_norm": 0.00010696022945921868,
      "learning_rate": 5.4523375834851245e-06,
      "loss": 0.0,
      "step": 101830
    },
    {
      "epoch": 10.911818279224258,
      "grad_norm": 0.0008023379486985505,
      "learning_rate": 5.450908961034324e-06,
      "loss": 0.0,
      "step": 101840
    },
    {
      "epoch": 10.91288974606236,
      "grad_norm": 0.0001109880831791088,
      "learning_rate": 5.4494803385835215e-06,
      "loss": 0.0,
      "step": 101850
    },
    {
      "epoch": 10.91396121290046,
      "grad_norm": 0.6709322929382324,
      "learning_rate": 5.448051716132719e-06,
      "loss": 0.4097,
      "step": 101860
    },
    {
      "epoch": 10.915032679738562,
      "grad_norm": 0.00010864956129807979,
      "learning_rate": 5.446623093681918e-06,
      "loss": 0.0,
      "step": 101870
    },
    {
      "epoch": 10.916104146576664,
      "grad_norm": 0.01083256397396326,
      "learning_rate": 5.445194471231115e-06,
      "loss": 0.0,
      "step": 101880
    },
    {
      "epoch": 10.917175613414765,
      "grad_norm": 0.00011725177319021896,
      "learning_rate": 5.443765848780314e-06,
      "loss": 0.0,
      "step": 101890
    },
    {
      "epoch": 10.918247080252867,
      "grad_norm": 0.0005401740781962872,
      "learning_rate": 5.4423372263295124e-06,
      "loss": 0.0,
      "step": 101900
    },
    {
      "epoch": 10.919318547090967,
      "grad_norm": 0.0006304373382590711,
      "learning_rate": 5.440908603878711e-06,
      "loss": 0.0,
      "step": 101910
    },
    {
      "epoch": 10.920390013929069,
      "grad_norm": 0.0012798499083146453,
      "learning_rate": 5.439479981427909e-06,
      "loss": 0.0001,
      "step": 101920
    },
    {
      "epoch": 10.92146148076717,
      "grad_norm": 0.00018125191854778677,
      "learning_rate": 5.438051358977106e-06,
      "loss": 0.0,
      "step": 101930
    },
    {
      "epoch": 10.922532947605271,
      "grad_norm": 0.0033898402471095324,
      "learning_rate": 5.436622736526305e-06,
      "loss": 0.0,
      "step": 101940
    },
    {
      "epoch": 10.923604414443373,
      "grad_norm": 0.0005472180782817304,
      "learning_rate": 5.4351941140755025e-06,
      "loss": 0.0,
      "step": 101950
    },
    {
      "epoch": 10.924675881281475,
      "grad_norm": 0.0033382554538547993,
      "learning_rate": 5.433765491624702e-06,
      "loss": 0.0,
      "step": 101960
    },
    {
      "epoch": 10.925747348119575,
      "grad_norm": 0.000182416319148615,
      "learning_rate": 5.4323368691738995e-06,
      "loss": 0.0001,
      "step": 101970
    },
    {
      "epoch": 10.926818814957677,
      "grad_norm": 0.0001827972591854632,
      "learning_rate": 5.430908246723098e-06,
      "loss": 0.0,
      "step": 101980
    },
    {
      "epoch": 10.92789028179578,
      "grad_norm": 0.0009629467967897654,
      "learning_rate": 5.429479624272296e-06,
      "loss": 0.0,
      "step": 101990
    },
    {
      "epoch": 10.92896174863388,
      "grad_norm": 0.0006059226579964161,
      "learning_rate": 5.428051001821493e-06,
      "loss": 0.0,
      "step": 102000
    },
    {
      "epoch": 10.930033215471981,
      "grad_norm": 0.00010899620974669233,
      "learning_rate": 5.426622379370692e-06,
      "loss": 0.0016,
      "step": 102010
    },
    {
      "epoch": 10.931104682310082,
      "grad_norm": 0.0004355858836788684,
      "learning_rate": 5.425193756919891e-06,
      "loss": 0.0,
      "step": 102020
    },
    {
      "epoch": 10.932176149148184,
      "grad_norm": 0.002310991520062089,
      "learning_rate": 5.423765134469089e-06,
      "loss": 0.2543,
      "step": 102030
    },
    {
      "epoch": 10.933247615986286,
      "grad_norm": 0.0009431533399038017,
      "learning_rate": 5.422336512018287e-06,
      "loss": 0.0,
      "step": 102040
    },
    {
      "epoch": 10.934319082824386,
      "grad_norm": 0.30683067440986633,
      "learning_rate": 5.420907889567485e-06,
      "loss": 0.0002,
      "step": 102050
    },
    {
      "epoch": 10.935390549662488,
      "grad_norm": 0.003051038831472397,
      "learning_rate": 5.419479267116683e-06,
      "loss": 0.0,
      "step": 102060
    },
    {
      "epoch": 10.93646201650059,
      "grad_norm": 0.0011988607002422214,
      "learning_rate": 5.418050644665881e-06,
      "loss": 0.0001,
      "step": 102070
    },
    {
      "epoch": 10.93753348333869,
      "grad_norm": 0.00014677464787382632,
      "learning_rate": 5.41662202221508e-06,
      "loss": 0.0001,
      "step": 102080
    },
    {
      "epoch": 10.938604950176792,
      "grad_norm": 0.034301500767469406,
      "learning_rate": 5.415193399764278e-06,
      "loss": 0.0001,
      "step": 102090
    },
    {
      "epoch": 10.939676417014894,
      "grad_norm": 34.0771598815918,
      "learning_rate": 5.413764777313476e-06,
      "loss": 0.1811,
      "step": 102100
    },
    {
      "epoch": 10.940747883852994,
      "grad_norm": 0.00016545133257750422,
      "learning_rate": 5.412336154862674e-06,
      "loss": 0.0,
      "step": 102110
    },
    {
      "epoch": 10.941819350691096,
      "grad_norm": 0.00019391457317396998,
      "learning_rate": 5.410907532411872e-06,
      "loss": 0.0,
      "step": 102120
    },
    {
      "epoch": 10.942890817529197,
      "grad_norm": 0.0019784187898039818,
      "learning_rate": 5.40947890996107e-06,
      "loss": 0.0002,
      "step": 102130
    },
    {
      "epoch": 10.943962284367299,
      "grad_norm": 0.0006473678513430059,
      "learning_rate": 5.408050287510269e-06,
      "loss": 0.0,
      "step": 102140
    },
    {
      "epoch": 10.9450337512054,
      "grad_norm": 0.02621651440858841,
      "learning_rate": 5.406621665059467e-06,
      "loss": 0.0,
      "step": 102150
    },
    {
      "epoch": 10.9461052180435,
      "grad_norm": 0.0015226632822304964,
      "learning_rate": 5.4051930426086655e-06,
      "loss": 0.0,
      "step": 102160
    },
    {
      "epoch": 10.947176684881603,
      "grad_norm": 0.0009113203268498182,
      "learning_rate": 5.403764420157863e-06,
      "loss": 0.0,
      "step": 102170
    },
    {
      "epoch": 10.948248151719705,
      "grad_norm": 0.00013987190322950482,
      "learning_rate": 5.402335797707061e-06,
      "loss": 0.0001,
      "step": 102180
    },
    {
      "epoch": 10.949319618557805,
      "grad_norm": 0.0003677212807815522,
      "learning_rate": 5.400907175256259e-06,
      "loss": 0.0,
      "step": 102190
    },
    {
      "epoch": 10.950391085395907,
      "grad_norm": 9.546709770802408e-05,
      "learning_rate": 5.399478552805459e-06,
      "loss": 0.0002,
      "step": 102200
    },
    {
      "epoch": 10.951462552234009,
      "grad_norm": 0.00010404644126538187,
      "learning_rate": 5.398049930354656e-06,
      "loss": 0.0,
      "step": 102210
    },
    {
      "epoch": 10.95253401907211,
      "grad_norm": 0.0004886412061750889,
      "learning_rate": 5.396621307903854e-06,
      "loss": 0.0003,
      "step": 102220
    },
    {
      "epoch": 10.953605485910211,
      "grad_norm": 0.000231371377594769,
      "learning_rate": 5.395192685453053e-06,
      "loss": 0.0,
      "step": 102230
    },
    {
      "epoch": 10.954676952748313,
      "grad_norm": 0.0006823247531428933,
      "learning_rate": 5.39376406300225e-06,
      "loss": 0.2697,
      "step": 102240
    },
    {
      "epoch": 10.955748419586413,
      "grad_norm": 0.00016588927246630192,
      "learning_rate": 5.392335440551448e-06,
      "loss": 0.0,
      "step": 102250
    },
    {
      "epoch": 10.956819886424515,
      "grad_norm": 0.0025643028784543276,
      "learning_rate": 5.390906818100647e-06,
      "loss": 0.0,
      "step": 102260
    },
    {
      "epoch": 10.957891353262617,
      "grad_norm": 0.0011273708660155535,
      "learning_rate": 5.389478195649846e-06,
      "loss": 0.0,
      "step": 102270
    },
    {
      "epoch": 10.958962820100718,
      "grad_norm": 9.58970922511071e-05,
      "learning_rate": 5.3880495731990435e-06,
      "loss": 0.0,
      "step": 102280
    },
    {
      "epoch": 10.96003428693882,
      "grad_norm": 0.0010322390589863062,
      "learning_rate": 5.386620950748241e-06,
      "loss": 0.2203,
      "step": 102290
    },
    {
      "epoch": 10.96110575377692,
      "grad_norm": 0.02395407110452652,
      "learning_rate": 5.38519232829744e-06,
      "loss": 0.0002,
      "step": 102300
    },
    {
      "epoch": 10.962177220615022,
      "grad_norm": 0.02922447770833969,
      "learning_rate": 5.383763705846637e-06,
      "loss": 0.0001,
      "step": 102310
    },
    {
      "epoch": 10.963248687453124,
      "grad_norm": 0.0034065779764205217,
      "learning_rate": 5.382335083395837e-06,
      "loss": 0.0,
      "step": 102320
    },
    {
      "epoch": 10.964320154291224,
      "grad_norm": 0.0008125173044390976,
      "learning_rate": 5.380906460945034e-06,
      "loss": 0.0001,
      "step": 102330
    },
    {
      "epoch": 10.965391621129326,
      "grad_norm": 0.012683709152042866,
      "learning_rate": 5.379477838494233e-06,
      "loss": 0.0001,
      "step": 102340
    },
    {
      "epoch": 10.966463087967428,
      "grad_norm": 0.033254653215408325,
      "learning_rate": 5.378049216043431e-06,
      "loss": 0.0001,
      "step": 102350
    },
    {
      "epoch": 10.967534554805528,
      "grad_norm": 0.00011640790762612596,
      "learning_rate": 5.376620593592628e-06,
      "loss": 0.0,
      "step": 102360
    },
    {
      "epoch": 10.96860602164363,
      "grad_norm": 0.0045091197825968266,
      "learning_rate": 5.375191971141827e-06,
      "loss": 0.0,
      "step": 102370
    },
    {
      "epoch": 10.969677488481732,
      "grad_norm": 0.0007135018240660429,
      "learning_rate": 5.373763348691025e-06,
      "loss": 0.1499,
      "step": 102380
    },
    {
      "epoch": 10.970748955319833,
      "grad_norm": 0.0008630734519101679,
      "learning_rate": 5.372334726240224e-06,
      "loss": 0.0,
      "step": 102390
    },
    {
      "epoch": 10.971820422157935,
      "grad_norm": 0.009302057325839996,
      "learning_rate": 5.3709061037894215e-06,
      "loss": 0.0,
      "step": 102400
    },
    {
      "epoch": 10.972891888996035,
      "grad_norm": 0.00011063790589105338,
      "learning_rate": 5.36947748133862e-06,
      "loss": 0.0,
      "step": 102410
    },
    {
      "epoch": 10.973963355834137,
      "grad_norm": 0.00015909649664536119,
      "learning_rate": 5.368048858887818e-06,
      "loss": 0.0,
      "step": 102420
    },
    {
      "epoch": 10.975034822672239,
      "grad_norm": 0.00020934536587446928,
      "learning_rate": 5.366620236437015e-06,
      "loss": 0.2,
      "step": 102430
    },
    {
      "epoch": 10.976106289510339,
      "grad_norm": 0.00010923654190264642,
      "learning_rate": 5.365191613986214e-06,
      "loss": 0.0,
      "step": 102440
    },
    {
      "epoch": 10.977177756348441,
      "grad_norm": 0.00014280376490205526,
      "learning_rate": 5.363762991535412e-06,
      "loss": 0.1236,
      "step": 102450
    },
    {
      "epoch": 10.978249223186543,
      "grad_norm": 0.00018061394803225994,
      "learning_rate": 5.362334369084611e-06,
      "loss": 0.1278,
      "step": 102460
    },
    {
      "epoch": 10.979320690024643,
      "grad_norm": 0.00015076520503498614,
      "learning_rate": 5.360905746633809e-06,
      "loss": 0.0004,
      "step": 102470
    },
    {
      "epoch": 10.980392156862745,
      "grad_norm": 9.159462206298485e-05,
      "learning_rate": 5.359477124183007e-06,
      "loss": 0.0001,
      "step": 102480
    },
    {
      "epoch": 10.981463623700847,
      "grad_norm": 0.00013073014270048589,
      "learning_rate": 5.358048501732205e-06,
      "loss": 0.0,
      "step": 102490
    },
    {
      "epoch": 10.982535090538947,
      "grad_norm": 0.0017400409560650587,
      "learning_rate": 5.3566198792814024e-06,
      "loss": 0.0,
      "step": 102500
    },
    {
      "epoch": 10.98360655737705,
      "grad_norm": 8.80707084434107e-05,
      "learning_rate": 5.355191256830602e-06,
      "loss": 0.0001,
      "step": 102510
    },
    {
      "epoch": 10.98467802421515,
      "grad_norm": 0.0017430272419005632,
      "learning_rate": 5.3537626343798e-06,
      "loss": 0.0001,
      "step": 102520
    },
    {
      "epoch": 10.985749491053252,
      "grad_norm": 0.0014163961168378592,
      "learning_rate": 5.352334011928998e-06,
      "loss": 0.0,
      "step": 102530
    },
    {
      "epoch": 10.986820957891354,
      "grad_norm": 0.00011803007510025054,
      "learning_rate": 5.350905389478196e-06,
      "loss": 0.0,
      "step": 102540
    },
    {
      "epoch": 10.987892424729454,
      "grad_norm": 0.01454536709934473,
      "learning_rate": 5.349476767027394e-06,
      "loss": 0.0001,
      "step": 102550
    },
    {
      "epoch": 10.988963891567556,
      "grad_norm": 0.003518000477924943,
      "learning_rate": 5.348048144576592e-06,
      "loss": 0.2955,
      "step": 102560
    },
    {
      "epoch": 10.990035358405658,
      "grad_norm": 0.00012597865134011954,
      "learning_rate": 5.346619522125791e-06,
      "loss": 0.0001,
      "step": 102570
    },
    {
      "epoch": 10.991106825243758,
      "grad_norm": 0.00018256052862852812,
      "learning_rate": 5.345190899674989e-06,
      "loss": 0.0002,
      "step": 102580
    },
    {
      "epoch": 10.99217829208186,
      "grad_norm": 0.00013795414997730404,
      "learning_rate": 5.3437622772241874e-06,
      "loss": 0.0,
      "step": 102590
    },
    {
      "epoch": 10.993249758919962,
      "grad_norm": 0.00015383500431198627,
      "learning_rate": 5.342333654773385e-06,
      "loss": 0.0,
      "step": 102600
    },
    {
      "epoch": 10.994321225758062,
      "grad_norm": 0.2661840617656708,
      "learning_rate": 5.340905032322583e-06,
      "loss": 0.0003,
      "step": 102610
    },
    {
      "epoch": 10.995392692596164,
      "grad_norm": 0.06090416759252548,
      "learning_rate": 5.339476409871781e-06,
      "loss": 0.0,
      "step": 102620
    },
    {
      "epoch": 10.996464159434266,
      "grad_norm": 0.33947691321372986,
      "learning_rate": 5.33804778742098e-06,
      "loss": 0.0002,
      "step": 102630
    },
    {
      "epoch": 10.997535626272366,
      "grad_norm": 0.00011431339225964621,
      "learning_rate": 5.336619164970178e-06,
      "loss": 0.0003,
      "step": 102640
    },
    {
      "epoch": 10.998607093110468,
      "grad_norm": 9.766220318851992e-05,
      "learning_rate": 5.335190542519376e-06,
      "loss": 0.0,
      "step": 102650
    },
    {
      "epoch": 10.99967855994857,
      "grad_norm": 0.00010330357326893136,
      "learning_rate": 5.3337619200685745e-06,
      "loss": 0.0,
      "step": 102660
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9791666666666666,
      "eval_f1": 0.9172733289212442,
      "eval_loss": 0.17374804615974426,
      "eval_precision": 0.9190981432360743,
      "eval_recall": 0.9154557463672391,
      "eval_runtime": 517.8184,
      "eval_samples_per_second": 11.587,
      "eval_steps_per_second": 3.862,
      "step": 102663
    },
    {
      "epoch": 11.00075002678667,
      "grad_norm": 0.0001756939454935491,
      "learning_rate": 5.332333297617772e-06,
      "loss": 0.0,
      "step": 102670
    },
    {
      "epoch": 11.001821493624773,
      "grad_norm": 0.0017042207764461637,
      "learning_rate": 5.33090467516697e-06,
      "loss": 0.0,
      "step": 102680
    },
    {
      "epoch": 11.002892960462873,
      "grad_norm": 0.00017498142551630735,
      "learning_rate": 5.329476052716169e-06,
      "loss": 0.0,
      "step": 102690
    },
    {
      "epoch": 11.003964427300975,
      "grad_norm": 0.0019466634839773178,
      "learning_rate": 5.328047430265367e-06,
      "loss": 0.0,
      "step": 102700
    },
    {
      "epoch": 11.005035894139077,
      "grad_norm": 0.30402982234954834,
      "learning_rate": 5.3266188078145654e-06,
      "loss": 0.0027,
      "step": 102710
    },
    {
      "epoch": 11.006107360977177,
      "grad_norm": 9.903860336635262e-05,
      "learning_rate": 5.325190185363763e-06,
      "loss": 0.0,
      "step": 102720
    },
    {
      "epoch": 11.00717882781528,
      "grad_norm": 0.00013698326074518263,
      "learning_rate": 5.323761562912962e-06,
      "loss": 0.1016,
      "step": 102730
    },
    {
      "epoch": 11.008250294653381,
      "grad_norm": 0.00010688097245292738,
      "learning_rate": 5.322332940462159e-06,
      "loss": 0.0,
      "step": 102740
    },
    {
      "epoch": 11.009321761491481,
      "grad_norm": 0.001038860180415213,
      "learning_rate": 5.320904318011359e-06,
      "loss": 0.0001,
      "step": 102750
    },
    {
      "epoch": 11.010393228329583,
      "grad_norm": 0.00011454225750640035,
      "learning_rate": 5.319475695560556e-06,
      "loss": 0.0,
      "step": 102760
    },
    {
      "epoch": 11.011464695167685,
      "grad_norm": 9.123553172685206e-05,
      "learning_rate": 5.318047073109755e-06,
      "loss": 0.0,
      "step": 102770
    },
    {
      "epoch": 11.012536162005786,
      "grad_norm": 0.0008583997841924429,
      "learning_rate": 5.3166184506589525e-06,
      "loss": 0.0,
      "step": 102780
    },
    {
      "epoch": 11.013607628843888,
      "grad_norm": 0.0011501343687996268,
      "learning_rate": 5.31518982820815e-06,
      "loss": 0.0,
      "step": 102790
    },
    {
      "epoch": 11.014679095681988,
      "grad_norm": 0.00010019845649367198,
      "learning_rate": 5.313761205757349e-06,
      "loss": 0.0004,
      "step": 102800
    },
    {
      "epoch": 11.01575056252009,
      "grad_norm": 0.00010913270671153441,
      "learning_rate": 5.312332583306547e-06,
      "loss": 0.0,
      "step": 102810
    },
    {
      "epoch": 11.016822029358192,
      "grad_norm": 0.0001448370749130845,
      "learning_rate": 5.310903960855746e-06,
      "loss": 0.0,
      "step": 102820
    },
    {
      "epoch": 11.017893496196292,
      "grad_norm": 9.537653386360034e-05,
      "learning_rate": 5.3094753384049434e-06,
      "loss": 0.0,
      "step": 102830
    },
    {
      "epoch": 11.018964963034394,
      "grad_norm": 0.00010295467654941604,
      "learning_rate": 5.308046715954142e-06,
      "loss": 0.0,
      "step": 102840
    },
    {
      "epoch": 11.020036429872496,
      "grad_norm": 0.0007486399845220149,
      "learning_rate": 5.30661809350334e-06,
      "loss": 0.0,
      "step": 102850
    },
    {
      "epoch": 11.021107896710596,
      "grad_norm": 8.873130718711764e-05,
      "learning_rate": 5.305189471052537e-06,
      "loss": 0.0001,
      "step": 102860
    },
    {
      "epoch": 11.022179363548698,
      "grad_norm": 0.07353254407644272,
      "learning_rate": 5.303760848601737e-06,
      "loss": 0.0,
      "step": 102870
    },
    {
      "epoch": 11.0232508303868,
      "grad_norm": 0.0005843253456987441,
      "learning_rate": 5.302332226150934e-06,
      "loss": 0.0,
      "step": 102880
    },
    {
      "epoch": 11.0243222972249,
      "grad_norm": 0.013370043598115444,
      "learning_rate": 5.300903603700133e-06,
      "loss": 0.0,
      "step": 102890
    },
    {
      "epoch": 11.025393764063002,
      "grad_norm": 8.9605113316793e-05,
      "learning_rate": 5.2994749812493305e-06,
      "loss": 0.0,
      "step": 102900
    },
    {
      "epoch": 11.026465230901104,
      "grad_norm": 0.00044175147195346653,
      "learning_rate": 5.298046358798529e-06,
      "loss": 0.0,
      "step": 102910
    },
    {
      "epoch": 11.027536697739205,
      "grad_norm": 0.00035114798811264336,
      "learning_rate": 5.296617736347727e-06,
      "loss": 0.0001,
      "step": 102920
    },
    {
      "epoch": 11.028608164577307,
      "grad_norm": 0.0003867728519253433,
      "learning_rate": 5.295189113896926e-06,
      "loss": 0.0,
      "step": 102930
    },
    {
      "epoch": 11.029679631415407,
      "grad_norm": 0.35608041286468506,
      "learning_rate": 5.293760491446124e-06,
      "loss": 0.0001,
      "step": 102940
    },
    {
      "epoch": 11.030751098253509,
      "grad_norm": 0.0013953392626717687,
      "learning_rate": 5.2923318689953214e-06,
      "loss": 0.0001,
      "step": 102950
    },
    {
      "epoch": 11.03182256509161,
      "grad_norm": 0.0008133130613714457,
      "learning_rate": 5.29090324654452e-06,
      "loss": 0.0,
      "step": 102960
    },
    {
      "epoch": 11.032894031929711,
      "grad_norm": 0.0007111701997928321,
      "learning_rate": 5.289474624093718e-06,
      "loss": 0.0,
      "step": 102970
    },
    {
      "epoch": 11.033965498767813,
      "grad_norm": 9.553170821163803e-05,
      "learning_rate": 5.288046001642916e-06,
      "loss": 0.0003,
      "step": 102980
    },
    {
      "epoch": 11.035036965605915,
      "grad_norm": 0.00014457220095209777,
      "learning_rate": 5.286617379192115e-06,
      "loss": 0.1761,
      "step": 102990
    },
    {
      "epoch": 11.036108432444015,
      "grad_norm": 0.0003533037379384041,
      "learning_rate": 5.285188756741313e-06,
      "loss": 0.0,
      "step": 103000
    },
    {
      "epoch": 11.037179899282117,
      "grad_norm": 0.010658183135092258,
      "learning_rate": 5.283760134290511e-06,
      "loss": 0.0,
      "step": 103010
    },
    {
      "epoch": 11.03825136612022,
      "grad_norm": 8.636478014523163e-05,
      "learning_rate": 5.2823315118397085e-06,
      "loss": 0.0035,
      "step": 103020
    },
    {
      "epoch": 11.03932283295832,
      "grad_norm": 8.812314626993611e-05,
      "learning_rate": 5.280902889388907e-06,
      "loss": 0.0,
      "step": 103030
    },
    {
      "epoch": 11.040394299796422,
      "grad_norm": 8.3238905062899e-05,
      "learning_rate": 5.279474266938105e-06,
      "loss": 0.0,
      "step": 103040
    },
    {
      "epoch": 11.041465766634524,
      "grad_norm": 9.243191016139463e-05,
      "learning_rate": 5.278045644487304e-06,
      "loss": 0.0001,
      "step": 103050
    },
    {
      "epoch": 11.042537233472624,
      "grad_norm": 0.0008099897531792521,
      "learning_rate": 5.276617022036502e-06,
      "loss": 0.0,
      "step": 103060
    },
    {
      "epoch": 11.043608700310726,
      "grad_norm": 0.002147580496966839,
      "learning_rate": 5.2751883995857e-06,
      "loss": 0.0763,
      "step": 103070
    },
    {
      "epoch": 11.044680167148826,
      "grad_norm": 0.0003179941850248724,
      "learning_rate": 5.273759777134898e-06,
      "loss": 0.0,
      "step": 103080
    },
    {
      "epoch": 11.045751633986928,
      "grad_norm": 0.0014013828476890922,
      "learning_rate": 5.2723311546840965e-06,
      "loss": 0.0,
      "step": 103090
    },
    {
      "epoch": 11.04682310082503,
      "grad_norm": 7.33316337573342e-05,
      "learning_rate": 5.270902532233294e-06,
      "loss": 0.0,
      "step": 103100
    },
    {
      "epoch": 11.04789456766313,
      "grad_norm": 0.00010122155799763277,
      "learning_rate": 5.2694739097824935e-06,
      "loss": 0.0,
      "step": 103110
    },
    {
      "epoch": 11.048966034501232,
      "grad_norm": 8.221054304158315e-05,
      "learning_rate": 5.268045287331691e-06,
      "loss": 0.0012,
      "step": 103120
    },
    {
      "epoch": 11.050037501339334,
      "grad_norm": 7.154566992539912e-05,
      "learning_rate": 5.266616664880889e-06,
      "loss": 0.0,
      "step": 103130
    },
    {
      "epoch": 11.051108968177434,
      "grad_norm": 0.0005585481994785368,
      "learning_rate": 5.265188042430087e-06,
      "loss": 0.0,
      "step": 103140
    },
    {
      "epoch": 11.052180435015536,
      "grad_norm": 0.00010322186426492408,
      "learning_rate": 5.263759419979285e-06,
      "loss": 0.0,
      "step": 103150
    },
    {
      "epoch": 11.053251901853638,
      "grad_norm": 9.24339474295266e-05,
      "learning_rate": 5.2623307975284836e-06,
      "loss": 0.0002,
      "step": 103160
    },
    {
      "epoch": 11.054323368691739,
      "grad_norm": 0.000696625909768045,
      "learning_rate": 5.260902175077682e-06,
      "loss": 0.0,
      "step": 103170
    },
    {
      "epoch": 11.05539483552984,
      "grad_norm": 0.0001257690746570006,
      "learning_rate": 5.259473552626881e-06,
      "loss": 0.0,
      "step": 103180
    },
    {
      "epoch": 11.056466302367943,
      "grad_norm": 9.056882845470682e-05,
      "learning_rate": 5.258044930176078e-06,
      "loss": 0.0011,
      "step": 103190
    },
    {
      "epoch": 11.057537769206043,
      "grad_norm": 0.00037003893521614373,
      "learning_rate": 5.256616307725276e-06,
      "loss": 0.0,
      "step": 103200
    },
    {
      "epoch": 11.058609236044145,
      "grad_norm": 7.821312465239316e-05,
      "learning_rate": 5.2551876852744745e-06,
      "loss": 0.0,
      "step": 103210
    },
    {
      "epoch": 11.059680702882245,
      "grad_norm": 0.00036827835720032454,
      "learning_rate": 5.253759062823672e-06,
      "loss": 0.0,
      "step": 103220
    },
    {
      "epoch": 11.060752169720347,
      "grad_norm": 0.009024577215313911,
      "learning_rate": 5.2523304403728715e-06,
      "loss": 0.0,
      "step": 103230
    },
    {
      "epoch": 11.061823636558449,
      "grad_norm": 9.268261783290654e-05,
      "learning_rate": 5.250901817922069e-06,
      "loss": 0.0006,
      "step": 103240
    },
    {
      "epoch": 11.06289510339655,
      "grad_norm": 9.767035953700542e-05,
      "learning_rate": 5.249473195471268e-06,
      "loss": 0.0,
      "step": 103250
    },
    {
      "epoch": 11.063966570234651,
      "grad_norm": 0.0002731955610215664,
      "learning_rate": 5.248044573020465e-06,
      "loss": 0.0,
      "step": 103260
    },
    {
      "epoch": 11.065038037072753,
      "grad_norm": 0.0003699548833537847,
      "learning_rate": 5.246615950569663e-06,
      "loss": 0.1258,
      "step": 103270
    },
    {
      "epoch": 11.066109503910853,
      "grad_norm": 8.307878306368366e-05,
      "learning_rate": 5.2451873281188616e-06,
      "loss": 0.0,
      "step": 103280
    },
    {
      "epoch": 11.067180970748955,
      "grad_norm": 8.928190072765574e-05,
      "learning_rate": 5.243758705668061e-06,
      "loss": 0.0,
      "step": 103290
    },
    {
      "epoch": 11.068252437587057,
      "grad_norm": 0.0003470500814728439,
      "learning_rate": 5.242330083217259e-06,
      "loss": 0.0,
      "step": 103300
    },
    {
      "epoch": 11.069323904425158,
      "grad_norm": 0.00012451925431378186,
      "learning_rate": 5.240901460766456e-06,
      "loss": 0.0,
      "step": 103310
    },
    {
      "epoch": 11.07039537126326,
      "grad_norm": 9.953566768672317e-05,
      "learning_rate": 5.239472838315655e-06,
      "loss": 0.0,
      "step": 103320
    },
    {
      "epoch": 11.07146683810136,
      "grad_norm": 0.40314981341362,
      "learning_rate": 5.2380442158648525e-06,
      "loss": 0.0008,
      "step": 103330
    },
    {
      "epoch": 11.072538304939462,
      "grad_norm": 8.685792272444814e-05,
      "learning_rate": 5.236615593414051e-06,
      "loss": 0.0,
      "step": 103340
    },
    {
      "epoch": 11.073609771777564,
      "grad_norm": 0.00028889073291793466,
      "learning_rate": 5.235186970963249e-06,
      "loss": 0.0,
      "step": 103350
    },
    {
      "epoch": 11.074681238615664,
      "grad_norm": 7.917991024442017e-05,
      "learning_rate": 5.233758348512448e-06,
      "loss": 0.0,
      "step": 103360
    },
    {
      "epoch": 11.075752705453766,
      "grad_norm": 0.0016789493383839726,
      "learning_rate": 5.232329726061646e-06,
      "loss": 0.0,
      "step": 103370
    },
    {
      "epoch": 11.076824172291868,
      "grad_norm": 7.334105612244457e-05,
      "learning_rate": 5.230901103610843e-06,
      "loss": 0.0001,
      "step": 103380
    },
    {
      "epoch": 11.077895639129968,
      "grad_norm": 7.12418113835156e-05,
      "learning_rate": 5.229472481160042e-06,
      "loss": 0.0,
      "step": 103390
    },
    {
      "epoch": 11.07896710596807,
      "grad_norm": 0.00010017900785896927,
      "learning_rate": 5.2280438587092396e-06,
      "loss": 0.0,
      "step": 103400
    },
    {
      "epoch": 11.080038572806172,
      "grad_norm": 0.00014701482723467052,
      "learning_rate": 5.226615236258438e-06,
      "loss": 0.0,
      "step": 103410
    },
    {
      "epoch": 11.081110039644273,
      "grad_norm": 9.330636385129765e-05,
      "learning_rate": 5.225186613807637e-06,
      "loss": 0.2966,
      "step": 103420
    },
    {
      "epoch": 11.082181506482375,
      "grad_norm": 0.0005450287717394531,
      "learning_rate": 5.223757991356835e-06,
      "loss": 0.0,
      "step": 103430
    },
    {
      "epoch": 11.083252973320477,
      "grad_norm": 0.002880306215956807,
      "learning_rate": 5.222329368906033e-06,
      "loss": 0.0,
      "step": 103440
    },
    {
      "epoch": 11.084324440158577,
      "grad_norm": 0.00026675217668525875,
      "learning_rate": 5.2209007464552305e-06,
      "loss": 0.0,
      "step": 103450
    },
    {
      "epoch": 11.085395906996679,
      "grad_norm": 8.942024578573182e-05,
      "learning_rate": 5.219472124004429e-06,
      "loss": 0.0,
      "step": 103460
    },
    {
      "epoch": 11.086467373834779,
      "grad_norm": 0.0002995676186401397,
      "learning_rate": 5.218043501553627e-06,
      "loss": 0.0,
      "step": 103470
    },
    {
      "epoch": 11.087538840672881,
      "grad_norm": 7.79749098001048e-05,
      "learning_rate": 5.216614879102826e-06,
      "loss": 0.0,
      "step": 103480
    },
    {
      "epoch": 11.088610307510983,
      "grad_norm": 0.00011105510202469304,
      "learning_rate": 5.215186256652024e-06,
      "loss": 0.0,
      "step": 103490
    },
    {
      "epoch": 11.089681774349083,
      "grad_norm": 0.015597539953887463,
      "learning_rate": 5.213757634201222e-06,
      "loss": 0.0,
      "step": 103500
    },
    {
      "epoch": 11.090753241187185,
      "grad_norm": 0.0002920968399848789,
      "learning_rate": 5.21232901175042e-06,
      "loss": 0.0,
      "step": 103510
    },
    {
      "epoch": 11.091824708025287,
      "grad_norm": 0.001363163348287344,
      "learning_rate": 5.2109003892996176e-06,
      "loss": 0.1462,
      "step": 103520
    },
    {
      "epoch": 11.092896174863387,
      "grad_norm": 0.003090208861976862,
      "learning_rate": 5.209471766848816e-06,
      "loss": 0.0,
      "step": 103530
    },
    {
      "epoch": 11.09396764170149,
      "grad_norm": 0.00029769347747787833,
      "learning_rate": 5.2080431443980154e-06,
      "loss": 0.0,
      "step": 103540
    },
    {
      "epoch": 11.095039108539591,
      "grad_norm": 8.384760440094396e-05,
      "learning_rate": 5.206614521947213e-06,
      "loss": 0.1191,
      "step": 103550
    },
    {
      "epoch": 11.096110575377692,
      "grad_norm": 0.0006152536370791495,
      "learning_rate": 5.205185899496411e-06,
      "loss": 0.0,
      "step": 103560
    },
    {
      "epoch": 11.097182042215794,
      "grad_norm": 0.0003047302016057074,
      "learning_rate": 5.203757277045609e-06,
      "loss": 0.0,
      "step": 103570
    },
    {
      "epoch": 11.098253509053896,
      "grad_norm": 0.0003099174064118415,
      "learning_rate": 5.202328654594807e-06,
      "loss": 0.0,
      "step": 103580
    },
    {
      "epoch": 11.099324975891996,
      "grad_norm": 9.931045497069135e-05,
      "learning_rate": 5.200900032144005e-06,
      "loss": 0.0,
      "step": 103590
    },
    {
      "epoch": 11.100396442730098,
      "grad_norm": 0.000822689151391387,
      "learning_rate": 5.199471409693204e-06,
      "loss": 0.0,
      "step": 103600
    },
    {
      "epoch": 11.101467909568198,
      "grad_norm": 9.529488306725398e-05,
      "learning_rate": 5.1980427872424025e-06,
      "loss": 0.0007,
      "step": 103610
    },
    {
      "epoch": 11.1025393764063,
      "grad_norm": 8.932343916967511e-05,
      "learning_rate": 5.1966141647916e-06,
      "loss": 0.0026,
      "step": 103620
    },
    {
      "epoch": 11.103610843244402,
      "grad_norm": 0.00016895803855732083,
      "learning_rate": 5.195185542340798e-06,
      "loss": 0.0,
      "step": 103630
    },
    {
      "epoch": 11.104682310082502,
      "grad_norm": 7.808676309650764e-05,
      "learning_rate": 5.193756919889996e-06,
      "loss": 0.0,
      "step": 103640
    },
    {
      "epoch": 11.105753776920604,
      "grad_norm": 0.0002761548385024071,
      "learning_rate": 5.192328297439194e-06,
      "loss": 0.1653,
      "step": 103650
    },
    {
      "epoch": 11.106825243758706,
      "grad_norm": 8.915852231439203e-05,
      "learning_rate": 5.1908996749883934e-06,
      "loss": 0.0,
      "step": 103660
    },
    {
      "epoch": 11.107896710596806,
      "grad_norm": 0.40877461433410645,
      "learning_rate": 5.189471052537591e-06,
      "loss": 0.0007,
      "step": 103670
    },
    {
      "epoch": 11.108968177434908,
      "grad_norm": 0.0019866672810167074,
      "learning_rate": 5.18804243008679e-06,
      "loss": 0.0,
      "step": 103680
    },
    {
      "epoch": 11.11003964427301,
      "grad_norm": 9.569385292707011e-05,
      "learning_rate": 5.186613807635987e-06,
      "loss": 0.0,
      "step": 103690
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 7.002294296398759e-05,
      "learning_rate": 5.185185185185185e-06,
      "loss": 0.0,
      "step": 103700
    },
    {
      "epoch": 11.112182577949213,
      "grad_norm": 9.36227515921928e-05,
      "learning_rate": 5.1837565627343835e-06,
      "loss": 0.0,
      "step": 103710
    },
    {
      "epoch": 11.113254044787315,
      "grad_norm": 0.00011226160859223455,
      "learning_rate": 5.182327940283582e-06,
      "loss": 0.0,
      "step": 103720
    },
    {
      "epoch": 11.114325511625415,
      "grad_norm": 0.0003181250358466059,
      "learning_rate": 5.1808993178327805e-06,
      "loss": 0.0,
      "step": 103730
    },
    {
      "epoch": 11.115396978463517,
      "grad_norm": 6.860202120151371e-05,
      "learning_rate": 5.179470695381978e-06,
      "loss": 0.0,
      "step": 103740
    },
    {
      "epoch": 11.116468445301617,
      "grad_norm": 0.00026742630871012807,
      "learning_rate": 5.178042072931177e-06,
      "loss": 0.0,
      "step": 103750
    },
    {
      "epoch": 11.11753991213972,
      "grad_norm": 0.0006411612266674638,
      "learning_rate": 5.176613450480374e-06,
      "loss": 0.0,
      "step": 103760
    },
    {
      "epoch": 11.118611378977821,
      "grad_norm": 0.0004689591296482831,
      "learning_rate": 5.175184828029572e-06,
      "loss": 0.0,
      "step": 103770
    },
    {
      "epoch": 11.119682845815921,
      "grad_norm": 6.962908082641661e-05,
      "learning_rate": 5.1737562055787714e-06,
      "loss": 0.0,
      "step": 103780
    },
    {
      "epoch": 11.120754312654023,
      "grad_norm": 0.0004900614148937166,
      "learning_rate": 5.17232758312797e-06,
      "loss": 0.0,
      "step": 103790
    },
    {
      "epoch": 11.121825779492125,
      "grad_norm": 0.0006894454127177596,
      "learning_rate": 5.170898960677168e-06,
      "loss": 0.0,
      "step": 103800
    },
    {
      "epoch": 11.122897246330226,
      "grad_norm": 0.0002603440370876342,
      "learning_rate": 5.169470338226365e-06,
      "loss": 0.0,
      "step": 103810
    },
    {
      "epoch": 11.123968713168328,
      "grad_norm": 7.432123675243929e-05,
      "learning_rate": 5.168041715775564e-06,
      "loss": 0.0,
      "step": 103820
    },
    {
      "epoch": 11.12504018000643,
      "grad_norm": 8.225245255744085e-05,
      "learning_rate": 5.1666130933247615e-06,
      "loss": 0.0,
      "step": 103830
    },
    {
      "epoch": 11.12611164684453,
      "grad_norm": 0.00010078281775349751,
      "learning_rate": 5.165184470873961e-06,
      "loss": 0.0,
      "step": 103840
    },
    {
      "epoch": 11.127183113682632,
      "grad_norm": 7.747624476905912e-05,
      "learning_rate": 5.1637558484231585e-06,
      "loss": 0.0,
      "step": 103850
    },
    {
      "epoch": 11.128254580520732,
      "grad_norm": 0.00038274837424978614,
      "learning_rate": 5.162327225972357e-06,
      "loss": 0.0,
      "step": 103860
    },
    {
      "epoch": 11.129326047358834,
      "grad_norm": 0.0008080002735368907,
      "learning_rate": 5.160898603521555e-06,
      "loss": 0.0,
      "step": 103870
    },
    {
      "epoch": 11.130397514196936,
      "grad_norm": 0.0006063159671612084,
      "learning_rate": 5.159469981070752e-06,
      "loss": 0.0,
      "step": 103880
    },
    {
      "epoch": 11.131468981035036,
      "grad_norm": 0.0002846688439603895,
      "learning_rate": 5.158041358619951e-06,
      "loss": 0.2458,
      "step": 103890
    },
    {
      "epoch": 11.132540447873138,
      "grad_norm": 0.06893476843833923,
      "learning_rate": 5.1566127361691494e-06,
      "loss": 0.0003,
      "step": 103900
    },
    {
      "epoch": 11.13361191471124,
      "grad_norm": 0.0002793873136397451,
      "learning_rate": 5.155184113718348e-06,
      "loss": 0.0,
      "step": 103910
    },
    {
      "epoch": 11.13468338154934,
      "grad_norm": 7.868223474361002e-05,
      "learning_rate": 5.153755491267546e-06,
      "loss": 0.0,
      "step": 103920
    },
    {
      "epoch": 11.135754848387442,
      "grad_norm": 0.00013053296424914151,
      "learning_rate": 5.152326868816744e-06,
      "loss": 0.343,
      "step": 103930
    },
    {
      "epoch": 11.136826315225544,
      "grad_norm": 0.01022362895309925,
      "learning_rate": 5.150898246365942e-06,
      "loss": 0.0,
      "step": 103940
    },
    {
      "epoch": 11.137897782063645,
      "grad_norm": 0.00010334113176213577,
      "learning_rate": 5.1494696239151395e-06,
      "loss": 0.1572,
      "step": 103950
    },
    {
      "epoch": 11.138969248901747,
      "grad_norm": 0.0006233903113752604,
      "learning_rate": 5.148041001464339e-06,
      "loss": 0.0001,
      "step": 103960
    },
    {
      "epoch": 11.140040715739849,
      "grad_norm": 8.600921864854172e-05,
      "learning_rate": 5.1466123790135365e-06,
      "loss": 0.0786,
      "step": 103970
    },
    {
      "epoch": 11.141112182577949,
      "grad_norm": 0.0005188906216062605,
      "learning_rate": 5.145183756562735e-06,
      "loss": 0.1376,
      "step": 103980
    },
    {
      "epoch": 11.14218364941605,
      "grad_norm": 0.00012533254630398005,
      "learning_rate": 5.143755134111933e-06,
      "loss": 0.0001,
      "step": 103990
    },
    {
      "epoch": 11.143255116254151,
      "grad_norm": 7.804710185155272e-05,
      "learning_rate": 5.142326511661131e-06,
      "loss": 0.0,
      "step": 104000
    },
    {
      "epoch": 11.144326583092253,
      "grad_norm": 0.0005465071299113333,
      "learning_rate": 5.140897889210329e-06,
      "loss": 0.0,
      "step": 104010
    },
    {
      "epoch": 11.145398049930355,
      "grad_norm": 0.1331004947423935,
      "learning_rate": 5.139469266759528e-06,
      "loss": 0.0001,
      "step": 104020
    },
    {
      "epoch": 11.146469516768455,
      "grad_norm": 8.148812048602849e-05,
      "learning_rate": 5.138040644308726e-06,
      "loss": 0.0,
      "step": 104030
    },
    {
      "epoch": 11.147540983606557,
      "grad_norm": 9.406806930201128e-05,
      "learning_rate": 5.1366120218579245e-06,
      "loss": 0.0,
      "step": 104040
    },
    {
      "epoch": 11.14861245044466,
      "grad_norm": 0.0030459449626505375,
      "learning_rate": 5.135183399407122e-06,
      "loss": 0.0001,
      "step": 104050
    },
    {
      "epoch": 11.14968391728276,
      "grad_norm": 8.675480785313994e-05,
      "learning_rate": 5.13375477695632e-06,
      "loss": 0.0003,
      "step": 104060
    },
    {
      "epoch": 11.150755384120862,
      "grad_norm": 7.736390398349613e-05,
      "learning_rate": 5.132326154505518e-06,
      "loss": 0.0,
      "step": 104070
    },
    {
      "epoch": 11.151826850958964,
      "grad_norm": 0.00012662635708693415,
      "learning_rate": 5.130897532054717e-06,
      "loss": 0.0,
      "step": 104080
    },
    {
      "epoch": 11.152898317797064,
      "grad_norm": 1.4028472900390625,
      "learning_rate": 5.129468909603915e-06,
      "loss": 0.0008,
      "step": 104090
    },
    {
      "epoch": 11.153969784635166,
      "grad_norm": 9.236115147359669e-05,
      "learning_rate": 5.128040287153113e-06,
      "loss": 0.1911,
      "step": 104100
    },
    {
      "epoch": 11.155041251473268,
      "grad_norm": 0.00011139972775708884,
      "learning_rate": 5.126611664702312e-06,
      "loss": 0.1866,
      "step": 104110
    },
    {
      "epoch": 11.156112718311368,
      "grad_norm": 0.001164587796665728,
      "learning_rate": 5.125183042251509e-06,
      "loss": 0.0005,
      "step": 104120
    },
    {
      "epoch": 11.15718418514947,
      "grad_norm": 0.0007892079302109778,
      "learning_rate": 5.123754419800707e-06,
      "loss": 0.0,
      "step": 104130
    },
    {
      "epoch": 11.15825565198757,
      "grad_norm": 0.00015659132623113692,
      "learning_rate": 5.122325797349906e-06,
      "loss": 0.0,
      "step": 104140
    },
    {
      "epoch": 11.159327118825672,
      "grad_norm": 0.00012707289715763181,
      "learning_rate": 5.120897174899104e-06,
      "loss": 0.2631,
      "step": 104150
    },
    {
      "epoch": 11.160398585663774,
      "grad_norm": 0.0005320219206623733,
      "learning_rate": 5.1194685524483025e-06,
      "loss": 0.0,
      "step": 104160
    },
    {
      "epoch": 11.161470052501874,
      "grad_norm": 8.176905248546973e-05,
      "learning_rate": 5.1180399299975e-06,
      "loss": 0.0,
      "step": 104170
    },
    {
      "epoch": 11.162541519339976,
      "grad_norm": 0.003056814894080162,
      "learning_rate": 5.116611307546699e-06,
      "loss": 0.0,
      "step": 104180
    },
    {
      "epoch": 11.163612986178078,
      "grad_norm": 0.0018695652252063155,
      "learning_rate": 5.115182685095896e-06,
      "loss": 0.0002,
      "step": 104190
    },
    {
      "epoch": 11.164684453016179,
      "grad_norm": 7.547432323917747e-05,
      "learning_rate": 5.113754062645096e-06,
      "loss": 0.0,
      "step": 104200
    },
    {
      "epoch": 11.16575591985428,
      "grad_norm": 7.712270598858595e-05,
      "learning_rate": 5.112325440194293e-06,
      "loss": 0.0,
      "step": 104210
    },
    {
      "epoch": 11.166827386692383,
      "grad_norm": 9.852797666098922e-05,
      "learning_rate": 5.110896817743491e-06,
      "loss": 0.0,
      "step": 104220
    },
    {
      "epoch": 11.167898853530483,
      "grad_norm": 8.544613228878006e-05,
      "learning_rate": 5.10946819529269e-06,
      "loss": 0.0002,
      "step": 104230
    },
    {
      "epoch": 11.168970320368585,
      "grad_norm": 7.67481469665654e-05,
      "learning_rate": 5.108039572841887e-06,
      "loss": 0.0,
      "step": 104240
    },
    {
      "epoch": 11.170041787206685,
      "grad_norm": 0.00017119149561040103,
      "learning_rate": 5.106610950391086e-06,
      "loss": 0.0,
      "step": 104250
    },
    {
      "epoch": 11.171113254044787,
      "grad_norm": 0.007763783447444439,
      "learning_rate": 5.1051823279402834e-06,
      "loss": 0.0,
      "step": 104260
    },
    {
      "epoch": 11.172184720882889,
      "grad_norm": 0.001120203291065991,
      "learning_rate": 5.103753705489483e-06,
      "loss": 0.0001,
      "step": 104270
    },
    {
      "epoch": 11.17325618772099,
      "grad_norm": 18.909677505493164,
      "learning_rate": 5.1023250830386805e-06,
      "loss": 0.1006,
      "step": 104280
    },
    {
      "epoch": 11.174327654559091,
      "grad_norm": 0.00014546839520335197,
      "learning_rate": 5.100896460587878e-06,
      "loss": 0.0774,
      "step": 104290
    },
    {
      "epoch": 11.175399121397193,
      "grad_norm": 0.0010471896966919303,
      "learning_rate": 5.099467838137077e-06,
      "loss": 0.0,
      "step": 104300
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 0.0009031937224790454,
      "learning_rate": 5.098039215686274e-06,
      "loss": 0.0,
      "step": 104310
    },
    {
      "epoch": 11.177542055073395,
      "grad_norm": 8.856180647853762e-05,
      "learning_rate": 5.096610593235473e-06,
      "loss": 0.0,
      "step": 104320
    },
    {
      "epoch": 11.178613521911497,
      "grad_norm": 0.0005443179397843778,
      "learning_rate": 5.095181970784671e-06,
      "loss": 0.0,
      "step": 104330
    },
    {
      "epoch": 11.179684988749598,
      "grad_norm": 9.13543626666069e-05,
      "learning_rate": 5.09375334833387e-06,
      "loss": 0.0,
      "step": 104340
    },
    {
      "epoch": 11.1807564555877,
      "grad_norm": 8.246154175139964e-05,
      "learning_rate": 5.092324725883068e-06,
      "loss": 0.0,
      "step": 104350
    },
    {
      "epoch": 11.181827922425802,
      "grad_norm": 0.0012006001779809594,
      "learning_rate": 5.090896103432266e-06,
      "loss": 0.0,
      "step": 104360
    },
    {
      "epoch": 11.182899389263902,
      "grad_norm": 6.99201482348144e-05,
      "learning_rate": 5.089467480981464e-06,
      "loss": 0.0023,
      "step": 104370
    },
    {
      "epoch": 11.183970856102004,
      "grad_norm": 7.654070213902742e-05,
      "learning_rate": 5.0880388585306614e-06,
      "loss": 0.0,
      "step": 104380
    },
    {
      "epoch": 11.185042322940104,
      "grad_norm": 8.781275391811505e-05,
      "learning_rate": 5.086610236079861e-06,
      "loss": 0.0221,
      "step": 104390
    },
    {
      "epoch": 11.186113789778206,
      "grad_norm": 0.00046130589907988906,
      "learning_rate": 5.0851816136290585e-06,
      "loss": 0.0,
      "step": 104400
    },
    {
      "epoch": 11.187185256616308,
      "grad_norm": 8.394260657951236e-05,
      "learning_rate": 5.083752991178257e-06,
      "loss": 0.0001,
      "step": 104410
    },
    {
      "epoch": 11.188256723454408,
      "grad_norm": 7.306208863155916e-05,
      "learning_rate": 5.082324368727455e-06,
      "loss": 0.0003,
      "step": 104420
    },
    {
      "epoch": 11.18932819029251,
      "grad_norm": 9.41049147513695e-05,
      "learning_rate": 5.080895746276653e-06,
      "loss": 0.0,
      "step": 104430
    },
    {
      "epoch": 11.190399657130612,
      "grad_norm": 2.8015315532684326,
      "learning_rate": 5.079467123825851e-06,
      "loss": 0.0026,
      "step": 104440
    },
    {
      "epoch": 11.191471123968713,
      "grad_norm": 0.00031902806949801743,
      "learning_rate": 5.07803850137505e-06,
      "loss": 0.0,
      "step": 104450
    },
    {
      "epoch": 11.192542590806815,
      "grad_norm": 24.946887969970703,
      "learning_rate": 5.076609878924248e-06,
      "loss": 0.2501,
      "step": 104460
    },
    {
      "epoch": 11.193614057644917,
      "grad_norm": 7.460865163011476e-05,
      "learning_rate": 5.0751812564734456e-06,
      "loss": 0.0,
      "step": 104470
    },
    {
      "epoch": 11.194685524483017,
      "grad_norm": 7.69815087551251e-05,
      "learning_rate": 5.073752634022644e-06,
      "loss": 0.0,
      "step": 104480
    },
    {
      "epoch": 11.195756991321119,
      "grad_norm": 0.0010510918218642473,
      "learning_rate": 5.072324011571842e-06,
      "loss": 0.0,
      "step": 104490
    },
    {
      "epoch": 11.19682845815922,
      "grad_norm": 0.00684609217569232,
      "learning_rate": 5.07089538912104e-06,
      "loss": 0.0002,
      "step": 104500
    },
    {
      "epoch": 11.197899924997321,
      "grad_norm": 0.00028388446662575006,
      "learning_rate": 5.069466766670239e-06,
      "loss": 0.0,
      "step": 104510
    },
    {
      "epoch": 11.198971391835423,
      "grad_norm": 20.939624786376953,
      "learning_rate": 5.068038144219437e-06,
      "loss": 0.2053,
      "step": 104520
    },
    {
      "epoch": 11.200042858673523,
      "grad_norm": 0.0005868567386642098,
      "learning_rate": 5.066609521768635e-06,
      "loss": 0.0,
      "step": 104530
    },
    {
      "epoch": 11.201114325511625,
      "grad_norm": 9.649142884882167e-05,
      "learning_rate": 5.065180899317833e-06,
      "loss": 0.0,
      "step": 104540
    },
    {
      "epoch": 11.202185792349727,
      "grad_norm": 7.956542685860768e-05,
      "learning_rate": 5.063752276867031e-06,
      "loss": 0.0001,
      "step": 104550
    },
    {
      "epoch": 11.203257259187827,
      "grad_norm": 8.00500056357123e-05,
      "learning_rate": 5.062323654416229e-06,
      "loss": 0.0,
      "step": 104560
    },
    {
      "epoch": 11.20432872602593,
      "grad_norm": 8.509187318850309e-05,
      "learning_rate": 5.060895031965428e-06,
      "loss": 0.0001,
      "step": 104570
    },
    {
      "epoch": 11.205400192864031,
      "grad_norm": 8.267878729384392e-05,
      "learning_rate": 5.059466409514626e-06,
      "loss": 0.0243,
      "step": 104580
    },
    {
      "epoch": 11.206471659702132,
      "grad_norm": 37.53131103515625,
      "learning_rate": 5.058037787063824e-06,
      "loss": 0.2379,
      "step": 104590
    },
    {
      "epoch": 11.207543126540234,
      "grad_norm": 0.007973560132086277,
      "learning_rate": 5.056609164613022e-06,
      "loss": 0.0001,
      "step": 104600
    },
    {
      "epoch": 11.208614593378336,
      "grad_norm": 0.00032260146690532565,
      "learning_rate": 5.055180542162221e-06,
      "loss": 0.0,
      "step": 104610
    },
    {
      "epoch": 11.209686060216436,
      "grad_norm": 0.0036681147757917643,
      "learning_rate": 5.053751919711418e-06,
      "loss": 0.0003,
      "step": 104620
    },
    {
      "epoch": 11.210757527054538,
      "grad_norm": 7.705143070779741e-05,
      "learning_rate": 5.052323297260618e-06,
      "loss": 0.0001,
      "step": 104630
    },
    {
      "epoch": 11.21182899389264,
      "grad_norm": 0.00010418207239126787,
      "learning_rate": 5.050894674809815e-06,
      "loss": 0.0001,
      "step": 104640
    },
    {
      "epoch": 11.21290046073074,
      "grad_norm": 0.006753054913133383,
      "learning_rate": 5.049466052359013e-06,
      "loss": 0.0004,
      "step": 104650
    },
    {
      "epoch": 11.213971927568842,
      "grad_norm": 8.196974522434175e-05,
      "learning_rate": 5.0480374299082115e-06,
      "loss": 0.0,
      "step": 104660
    },
    {
      "epoch": 11.215043394406942,
      "grad_norm": 0.029258783906698227,
      "learning_rate": 5.046608807457409e-06,
      "loss": 0.0007,
      "step": 104670
    },
    {
      "epoch": 11.216114861245044,
      "grad_norm": 0.00023528930614702404,
      "learning_rate": 5.045180185006608e-06,
      "loss": 0.0001,
      "step": 104680
    },
    {
      "epoch": 11.217186328083146,
      "grad_norm": 0.004755240865051746,
      "learning_rate": 5.043751562555806e-06,
      "loss": 0.0002,
      "step": 104690
    },
    {
      "epoch": 11.218257794921247,
      "grad_norm": 7.120346708688885e-05,
      "learning_rate": 5.042322940105005e-06,
      "loss": 0.0,
      "step": 104700
    },
    {
      "epoch": 11.219329261759349,
      "grad_norm": 7.462874782504514e-05,
      "learning_rate": 5.040894317654202e-06,
      "loss": 0.2428,
      "step": 104710
    },
    {
      "epoch": 11.22040072859745,
      "grad_norm": 7.242442370625213e-05,
      "learning_rate": 5.0394656952034e-06,
      "loss": 0.0,
      "step": 104720
    },
    {
      "epoch": 11.22147219543555,
      "grad_norm": 7.881835335865617e-05,
      "learning_rate": 5.038037072752599e-06,
      "loss": 0.0,
      "step": 104730
    },
    {
      "epoch": 11.222543662273653,
      "grad_norm": 7.051718421280384e-05,
      "learning_rate": 5.036608450301796e-06,
      "loss": 0.0,
      "step": 104740
    },
    {
      "epoch": 11.223615129111755,
      "grad_norm": 0.0026845468673855066,
      "learning_rate": 5.035179827850996e-06,
      "loss": 0.0002,
      "step": 104750
    },
    {
      "epoch": 11.224686595949855,
      "grad_norm": 0.0009184161899611354,
      "learning_rate": 5.033751205400193e-06,
      "loss": 0.0,
      "step": 104760
    },
    {
      "epoch": 11.225758062787957,
      "grad_norm": 6.90735032549128e-05,
      "learning_rate": 5.032322582949392e-06,
      "loss": 0.0002,
      "step": 104770
    },
    {
      "epoch": 11.226829529626059,
      "grad_norm": 0.0010212352499365807,
      "learning_rate": 5.0308939604985895e-06,
      "loss": 0.0,
      "step": 104780
    },
    {
      "epoch": 11.22790099646416,
      "grad_norm": 8.021019311854616e-05,
      "learning_rate": 5.029465338047787e-06,
      "loss": 0.128,
      "step": 104790
    },
    {
      "epoch": 11.228972463302261,
      "grad_norm": 0.07047772407531738,
      "learning_rate": 5.028036715596986e-06,
      "loss": 0.0003,
      "step": 104800
    },
    {
      "epoch": 11.230043930140361,
      "grad_norm": 7.808719237800688e-05,
      "learning_rate": 5.026608093146185e-06,
      "loss": 0.0,
      "step": 104810
    },
    {
      "epoch": 11.231115396978463,
      "grad_norm": 0.0010435455478727818,
      "learning_rate": 5.025179470695383e-06,
      "loss": 0.0,
      "step": 104820
    },
    {
      "epoch": 11.232186863816565,
      "grad_norm": 7.28621962480247e-05,
      "learning_rate": 5.02375084824458e-06,
      "loss": 0.0,
      "step": 104830
    },
    {
      "epoch": 11.233258330654666,
      "grad_norm": 0.02137576974928379,
      "learning_rate": 5.022322225793779e-06,
      "loss": 0.0,
      "step": 104840
    },
    {
      "epoch": 11.234329797492768,
      "grad_norm": 6.894494435982779e-05,
      "learning_rate": 5.020893603342977e-06,
      "loss": 0.0004,
      "step": 104850
    },
    {
      "epoch": 11.23540126433087,
      "grad_norm": 8.280545443994924e-05,
      "learning_rate": 5.019464980892175e-06,
      "loss": 0.0011,
      "step": 104860
    },
    {
      "epoch": 11.23647273116897,
      "grad_norm": 0.005855231545865536,
      "learning_rate": 5.018036358441374e-06,
      "loss": 0.0007,
      "step": 104870
    },
    {
      "epoch": 11.237544198007072,
      "grad_norm": 6.913312972756103e-05,
      "learning_rate": 5.016607735990572e-06,
      "loss": 0.0001,
      "step": 104880
    },
    {
      "epoch": 11.238615664845174,
      "grad_norm": 8.773058652877808e-05,
      "learning_rate": 5.01517911353977e-06,
      "loss": 0.0,
      "step": 104890
    },
    {
      "epoch": 11.239687131683274,
      "grad_norm": 7.045242091408e-05,
      "learning_rate": 5.0137504910889675e-06,
      "loss": 0.0,
      "step": 104900
    },
    {
      "epoch": 11.240758598521376,
      "grad_norm": 6.465132173616439e-05,
      "learning_rate": 5.012321868638166e-06,
      "loss": 0.0001,
      "step": 104910
    },
    {
      "epoch": 11.241830065359476,
      "grad_norm": 0.013599814847111702,
      "learning_rate": 5.010893246187364e-06,
      "loss": 0.0,
      "step": 104920
    },
    {
      "epoch": 11.242901532197578,
      "grad_norm": 0.002043703803792596,
      "learning_rate": 5.009464623736563e-06,
      "loss": 0.0,
      "step": 104930
    },
    {
      "epoch": 11.24397299903568,
      "grad_norm": 6.905834015924484e-05,
      "learning_rate": 5.008036001285761e-06,
      "loss": 0.0,
      "step": 104940
    },
    {
      "epoch": 11.24504446587378,
      "grad_norm": 0.002400845754891634,
      "learning_rate": 5.006607378834959e-06,
      "loss": 0.0,
      "step": 104950
    },
    {
      "epoch": 11.246115932711882,
      "grad_norm": 7.056623871903867e-05,
      "learning_rate": 5.005178756384157e-06,
      "loss": 0.0001,
      "step": 104960
    },
    {
      "epoch": 11.247187399549984,
      "grad_norm": 0.0013990027364343405,
      "learning_rate": 5.003750133933355e-06,
      "loss": 0.0,
      "step": 104970
    },
    {
      "epoch": 11.248258866388085,
      "grad_norm": 0.00039789601578377187,
      "learning_rate": 5.002321511482553e-06,
      "loss": 0.0001,
      "step": 104980
    },
    {
      "epoch": 11.249330333226187,
      "grad_norm": 6.976493750698864e-05,
      "learning_rate": 5.000892889031752e-06,
      "loss": 0.0,
      "step": 104990
    },
    {
      "epoch": 11.250401800064289,
      "grad_norm": 6.479227158706635e-05,
      "learning_rate": 4.999464266580949e-06,
      "loss": 0.0001,
      "step": 105000
    },
    {
      "epoch": 11.251473266902389,
      "grad_norm": 7.70624537835829e-05,
      "learning_rate": 4.998035644130148e-06,
      "loss": 0.0,
      "step": 105010
    },
    {
      "epoch": 11.252544733740491,
      "grad_norm": 7.50044418964535e-05,
      "learning_rate": 4.996607021679346e-06,
      "loss": 0.0,
      "step": 105020
    },
    {
      "epoch": 11.253616200578593,
      "grad_norm": 6.280540401348844e-05,
      "learning_rate": 4.995178399228544e-06,
      "loss": 0.0,
      "step": 105030
    },
    {
      "epoch": 11.254687667416693,
      "grad_norm": 6.375089287757874e-05,
      "learning_rate": 4.9937497767777426e-06,
      "loss": 0.0,
      "step": 105040
    },
    {
      "epoch": 11.255759134254795,
      "grad_norm": 0.0007907224935479462,
      "learning_rate": 4.99232115432694e-06,
      "loss": 0.0,
      "step": 105050
    },
    {
      "epoch": 11.256830601092895,
      "grad_norm": 7.072967127896845e-05,
      "learning_rate": 4.990892531876139e-06,
      "loss": 0.1656,
      "step": 105060
    },
    {
      "epoch": 11.257902067930997,
      "grad_norm": 6.728040898451582e-05,
      "learning_rate": 4.989463909425337e-06,
      "loss": 0.0,
      "step": 105070
    },
    {
      "epoch": 11.2589735347691,
      "grad_norm": 6.794399087084457e-05,
      "learning_rate": 4.988035286974535e-06,
      "loss": 0.0,
      "step": 105080
    },
    {
      "epoch": 11.2600450016072,
      "grad_norm": 6.709453737130389e-05,
      "learning_rate": 4.9866066645237335e-06,
      "loss": 0.0,
      "step": 105090
    },
    {
      "epoch": 11.261116468445302,
      "grad_norm": 0.007415538653731346,
      "learning_rate": 4.985178042072932e-06,
      "loss": 0.0003,
      "step": 105100
    },
    {
      "epoch": 11.262187935283404,
      "grad_norm": 0.00010159738303627819,
      "learning_rate": 4.98374941962213e-06,
      "loss": 0.0,
      "step": 105110
    },
    {
      "epoch": 11.263259402121504,
      "grad_norm": 0.008652912452816963,
      "learning_rate": 4.982320797171328e-06,
      "loss": 0.0,
      "step": 105120
    },
    {
      "epoch": 11.264330868959606,
      "grad_norm": 6.24976892140694e-05,
      "learning_rate": 4.980892174720527e-06,
      "loss": 0.0,
      "step": 105130
    },
    {
      "epoch": 11.265402335797708,
      "grad_norm": 8.42981826281175e-05,
      "learning_rate": 4.979463552269724e-06,
      "loss": 0.0,
      "step": 105140
    },
    {
      "epoch": 11.266473802635808,
      "grad_norm": 0.0006478924187831581,
      "learning_rate": 4.978034929818922e-06,
      "loss": 0.0001,
      "step": 105150
    },
    {
      "epoch": 11.26754526947391,
      "grad_norm": 0.00016625023272354156,
      "learning_rate": 4.9766063073681206e-06,
      "loss": 0.0,
      "step": 105160
    },
    {
      "epoch": 11.268616736312012,
      "grad_norm": 6.480469164671376e-05,
      "learning_rate": 4.975177684917319e-06,
      "loss": 0.2371,
      "step": 105170
    },
    {
      "epoch": 11.269688203150112,
      "grad_norm": 7.001727499300614e-05,
      "learning_rate": 4.973749062466517e-06,
      "loss": 0.0,
      "step": 105180
    },
    {
      "epoch": 11.270759669988214,
      "grad_norm": 6.063254477339797e-05,
      "learning_rate": 4.972320440015715e-06,
      "loss": 0.0,
      "step": 105190
    },
    {
      "epoch": 11.271831136826314,
      "grad_norm": 0.0015497059794142842,
      "learning_rate": 4.970891817564914e-06,
      "loss": 0.0001,
      "step": 105200
    },
    {
      "epoch": 11.272902603664416,
      "grad_norm": 6.430097710108384e-05,
      "learning_rate": 4.9694631951141115e-06,
      "loss": 0.1681,
      "step": 105210
    },
    {
      "epoch": 11.273974070502518,
      "grad_norm": 6.690846203127876e-05,
      "learning_rate": 4.96803457266331e-06,
      "loss": 0.0,
      "step": 105220
    },
    {
      "epoch": 11.275045537340619,
      "grad_norm": 6.942571053514257e-05,
      "learning_rate": 4.966605950212508e-06,
      "loss": 0.0001,
      "step": 105230
    },
    {
      "epoch": 11.27611700417872,
      "grad_norm": 6.219554779818282e-05,
      "learning_rate": 4.965177327761706e-06,
      "loss": 0.0002,
      "step": 105240
    },
    {
      "epoch": 11.277188471016823,
      "grad_norm": 0.0010176163632422686,
      "learning_rate": 4.963748705310905e-06,
      "loss": 0.0001,
      "step": 105250
    },
    {
      "epoch": 11.278259937854923,
      "grad_norm": 6.629875861108303e-05,
      "learning_rate": 4.962320082860102e-06,
      "loss": 0.0,
      "step": 105260
    },
    {
      "epoch": 11.279331404693025,
      "grad_norm": 6.906969065312296e-05,
      "learning_rate": 4.960891460409301e-06,
      "loss": 0.0012,
      "step": 105270
    },
    {
      "epoch": 11.280402871531127,
      "grad_norm": 6.502716132672504e-05,
      "learning_rate": 4.959462837958499e-06,
      "loss": 0.0,
      "step": 105280
    },
    {
      "epoch": 11.281474338369227,
      "grad_norm": 0.0005259980098344386,
      "learning_rate": 4.958034215507697e-06,
      "loss": 0.0001,
      "step": 105290
    },
    {
      "epoch": 11.282545805207329,
      "grad_norm": 7.156818173825741e-05,
      "learning_rate": 4.956605593056895e-06,
      "loss": 0.0,
      "step": 105300
    },
    {
      "epoch": 11.28361727204543,
      "grad_norm": 7.971472223289311e-05,
      "learning_rate": 4.955176970606094e-06,
      "loss": 0.0001,
      "step": 105310
    },
    {
      "epoch": 11.284688738883531,
      "grad_norm": 6.851441867183894e-05,
      "learning_rate": 4.953748348155292e-06,
      "loss": 0.0,
      "step": 105320
    },
    {
      "epoch": 11.285760205721633,
      "grad_norm": 0.009068840183317661,
      "learning_rate": 4.9523197257044895e-06,
      "loss": 0.0,
      "step": 105330
    },
    {
      "epoch": 11.286831672559734,
      "grad_norm": 0.3875332474708557,
      "learning_rate": 4.950891103253688e-06,
      "loss": 0.2359,
      "step": 105340
    },
    {
      "epoch": 11.287903139397836,
      "grad_norm": 8.442140824627131e-05,
      "learning_rate": 4.9494624808028865e-06,
      "loss": 0.2904,
      "step": 105350
    },
    {
      "epoch": 11.288974606235938,
      "grad_norm": 6.270186713663861e-05,
      "learning_rate": 4.948033858352084e-06,
      "loss": 0.0001,
      "step": 105360
    },
    {
      "epoch": 11.290046073074038,
      "grad_norm": 6.910162483109161e-05,
      "learning_rate": 4.946605235901283e-06,
      "loss": 0.0,
      "step": 105370
    },
    {
      "epoch": 11.29111753991214,
      "grad_norm": 7.04387275618501e-05,
      "learning_rate": 4.945176613450481e-06,
      "loss": 0.0,
      "step": 105380
    },
    {
      "epoch": 11.292189006750242,
      "grad_norm": 6.229924474610016e-05,
      "learning_rate": 4.943747990999679e-06,
      "loss": 0.0,
      "step": 105390
    },
    {
      "epoch": 11.293260473588342,
      "grad_norm": 6.590683187823743e-05,
      "learning_rate": 4.942319368548877e-06,
      "loss": 0.0,
      "step": 105400
    },
    {
      "epoch": 11.294331940426444,
      "grad_norm": 6.131694681243971e-05,
      "learning_rate": 4.940890746098075e-06,
      "loss": 0.0,
      "step": 105410
    },
    {
      "epoch": 11.295403407264546,
      "grad_norm": 6.698593642795458e-05,
      "learning_rate": 4.939462123647274e-06,
      "loss": 0.1749,
      "step": 105420
    },
    {
      "epoch": 11.296474874102646,
      "grad_norm": 6.527364894282073e-05,
      "learning_rate": 4.938033501196472e-06,
      "loss": 0.2408,
      "step": 105430
    },
    {
      "epoch": 11.297546340940748,
      "grad_norm": 7.295378600247204e-05,
      "learning_rate": 4.93660487874567e-06,
      "loss": 0.0,
      "step": 105440
    },
    {
      "epoch": 11.298617807778848,
      "grad_norm": 6.146675150375813e-05,
      "learning_rate": 4.935176256294868e-06,
      "loss": 0.0,
      "step": 105450
    },
    {
      "epoch": 11.29968927461695,
      "grad_norm": 5.945859447820112e-05,
      "learning_rate": 4.933747633844067e-06,
      "loss": 0.0,
      "step": 105460
    },
    {
      "epoch": 11.300760741455052,
      "grad_norm": 6.280017259996384e-05,
      "learning_rate": 4.9323190113932645e-06,
      "loss": 0.0,
      "step": 105470
    },
    {
      "epoch": 11.301832208293153,
      "grad_norm": 0.009727654978632927,
      "learning_rate": 4.930890388942462e-06,
      "loss": 0.0,
      "step": 105480
    },
    {
      "epoch": 11.302903675131255,
      "grad_norm": 7.004789222264662e-05,
      "learning_rate": 4.929461766491661e-06,
      "loss": 0.0001,
      "step": 105490
    },
    {
      "epoch": 11.303975141969357,
      "grad_norm": 6.554667197633535e-05,
      "learning_rate": 4.928033144040859e-06,
      "loss": 0.0,
      "step": 105500
    },
    {
      "epoch": 11.305046608807457,
      "grad_norm": 6.293124170042574e-05,
      "learning_rate": 4.926604521590057e-06,
      "loss": 0.0,
      "step": 105510
    },
    {
      "epoch": 11.306118075645559,
      "grad_norm": 0.0010195139329880476,
      "learning_rate": 4.925175899139255e-06,
      "loss": 0.0566,
      "step": 105520
    },
    {
      "epoch": 11.30718954248366,
      "grad_norm": 6.0547747125383466e-05,
      "learning_rate": 4.923747276688454e-06,
      "loss": 0.0,
      "step": 105530
    },
    {
      "epoch": 11.308261009321761,
      "grad_norm": 6.353239587042481e-05,
      "learning_rate": 4.922318654237652e-06,
      "loss": 0.2617,
      "step": 105540
    },
    {
      "epoch": 11.309332476159863,
      "grad_norm": 8.145377069013193e-05,
      "learning_rate": 4.92089003178685e-06,
      "loss": 0.0,
      "step": 105550
    },
    {
      "epoch": 11.310403942997965,
      "grad_norm": 7.476970495190471e-05,
      "learning_rate": 4.919461409336049e-06,
      "loss": 0.0003,
      "step": 105560
    },
    {
      "epoch": 11.311475409836065,
      "grad_norm": 8.782881195656955e-05,
      "learning_rate": 4.918032786885246e-06,
      "loss": 0.0,
      "step": 105570
    },
    {
      "epoch": 11.312546876674167,
      "grad_norm": 7.517652556998655e-05,
      "learning_rate": 4.916604164434444e-06,
      "loss": 0.0,
      "step": 105580
    },
    {
      "epoch": 11.313618343512267,
      "grad_norm": 6.354015931719914e-05,
      "learning_rate": 4.9151755419836425e-06,
      "loss": 0.0,
      "step": 105590
    },
    {
      "epoch": 11.31468981035037,
      "grad_norm": 7.173487392719835e-05,
      "learning_rate": 4.913746919532841e-06,
      "loss": 0.0,
      "step": 105600
    },
    {
      "epoch": 11.315761277188471,
      "grad_norm": 0.0007736681727692485,
      "learning_rate": 4.912318297082039e-06,
      "loss": 0.1826,
      "step": 105610
    },
    {
      "epoch": 11.316832744026572,
      "grad_norm": 3.145986795425415,
      "learning_rate": 4.910889674631237e-06,
      "loss": 0.0119,
      "step": 105620
    },
    {
      "epoch": 11.317904210864674,
      "grad_norm": 8.186748891603202e-05,
      "learning_rate": 4.909461052180436e-06,
      "loss": 0.0,
      "step": 105630
    },
    {
      "epoch": 11.318975677702776,
      "grad_norm": 0.00010053357254946604,
      "learning_rate": 4.908032429729633e-06,
      "loss": 0.0,
      "step": 105640
    },
    {
      "epoch": 11.320047144540876,
      "grad_norm": 0.0005922162672504783,
      "learning_rate": 4.906603807278832e-06,
      "loss": 0.0,
      "step": 105650
    },
    {
      "epoch": 11.321118611378978,
      "grad_norm": 28.328218460083008,
      "learning_rate": 4.90517518482803e-06,
      "loss": 0.2711,
      "step": 105660
    },
    {
      "epoch": 11.32219007821708,
      "grad_norm": 7.30131650925614e-05,
      "learning_rate": 4.903746562377228e-06,
      "loss": 0.0,
      "step": 105670
    },
    {
      "epoch": 11.32326154505518,
      "grad_norm": 9.715218038763851e-05,
      "learning_rate": 4.902317939926427e-06,
      "loss": 0.0,
      "step": 105680
    },
    {
      "epoch": 11.324333011893282,
      "grad_norm": 6.475083500845358e-05,
      "learning_rate": 4.900889317475624e-06,
      "loss": 0.0,
      "step": 105690
    },
    {
      "epoch": 11.325404478731384,
      "grad_norm": 6.689008296234533e-05,
      "learning_rate": 4.899460695024823e-06,
      "loss": 0.0793,
      "step": 105700
    },
    {
      "epoch": 11.326475945569484,
      "grad_norm": 7.039192860247567e-05,
      "learning_rate": 4.898032072574021e-06,
      "loss": 0.0,
      "step": 105710
    },
    {
      "epoch": 11.327547412407586,
      "grad_norm": 0.0009161003399640322,
      "learning_rate": 4.896603450123219e-06,
      "loss": 0.0,
      "step": 105720
    },
    {
      "epoch": 11.328618879245687,
      "grad_norm": 0.0013775224797427654,
      "learning_rate": 4.895174827672417e-06,
      "loss": 0.0,
      "step": 105730
    },
    {
      "epoch": 11.329690346083789,
      "grad_norm": 0.005218548700213432,
      "learning_rate": 4.893746205221615e-06,
      "loss": 0.0,
      "step": 105740
    },
    {
      "epoch": 11.33076181292189,
      "grad_norm": 6.762756675016135e-05,
      "learning_rate": 4.892317582770814e-06,
      "loss": 0.0,
      "step": 105750
    },
    {
      "epoch": 11.33183327975999,
      "grad_norm": 0.0006915449048392475,
      "learning_rate": 4.890888960320011e-06,
      "loss": 0.0,
      "step": 105760
    },
    {
      "epoch": 11.332904746598093,
      "grad_norm": 0.0015486811753362417,
      "learning_rate": 4.88946033786921e-06,
      "loss": 0.0259,
      "step": 105770
    },
    {
      "epoch": 11.333976213436195,
      "grad_norm": 6.609444972127676e-05,
      "learning_rate": 4.8880317154184084e-06,
      "loss": 0.0,
      "step": 105780
    },
    {
      "epoch": 11.335047680274295,
      "grad_norm": 7.785073830746114e-05,
      "learning_rate": 4.886603092967606e-06,
      "loss": 0.0,
      "step": 105790
    },
    {
      "epoch": 11.336119147112397,
      "grad_norm": 6.452415254898369e-05,
      "learning_rate": 4.885174470516805e-06,
      "loss": 0.1754,
      "step": 105800
    },
    {
      "epoch": 11.337190613950499,
      "grad_norm": 6.64845501887612e-05,
      "learning_rate": 4.883745848066002e-06,
      "loss": 0.001,
      "step": 105810
    },
    {
      "epoch": 11.3382620807886,
      "grad_norm": 0.004546854645013809,
      "learning_rate": 4.882317225615201e-06,
      "loss": 0.0,
      "step": 105820
    },
    {
      "epoch": 11.339333547626701,
      "grad_norm": 0.0005448680021800101,
      "learning_rate": 4.880888603164399e-06,
      "loss": 0.0,
      "step": 105830
    },
    {
      "epoch": 11.340405014464803,
      "grad_norm": 0.0008485309081152081,
      "learning_rate": 4.879459980713597e-06,
      "loss": 0.0,
      "step": 105840
    },
    {
      "epoch": 11.341476481302903,
      "grad_norm": 8.736805466469377e-05,
      "learning_rate": 4.8780313582627955e-06,
      "loss": 0.0,
      "step": 105850
    },
    {
      "epoch": 11.342547948141005,
      "grad_norm": 7.928646664367989e-05,
      "learning_rate": 4.876602735811994e-06,
      "loss": 0.0,
      "step": 105860
    },
    {
      "epoch": 11.343619414979106,
      "grad_norm": 6.95799826644361e-05,
      "learning_rate": 4.875174113361192e-06,
      "loss": 0.0002,
      "step": 105870
    },
    {
      "epoch": 11.344690881817208,
      "grad_norm": 6.705958367092535e-05,
      "learning_rate": 4.87374549091039e-06,
      "loss": 0.0,
      "step": 105880
    },
    {
      "epoch": 11.34576234865531,
      "grad_norm": 0.0013153573963791132,
      "learning_rate": 4.872316868459589e-06,
      "loss": 0.0001,
      "step": 105890
    },
    {
      "epoch": 11.34683381549341,
      "grad_norm": 0.001699813874438405,
      "learning_rate": 4.8708882460087864e-06,
      "loss": 0.0,
      "step": 105900
    },
    {
      "epoch": 11.347905282331512,
      "grad_norm": 0.014398411847651005,
      "learning_rate": 4.869459623557984e-06,
      "loss": 0.0573,
      "step": 105910
    },
    {
      "epoch": 11.348976749169614,
      "grad_norm": 0.0004177273949608207,
      "learning_rate": 4.868031001107183e-06,
      "loss": 0.0,
      "step": 105920
    },
    {
      "epoch": 11.350048216007714,
      "grad_norm": 0.0001459451304981485,
      "learning_rate": 4.866602378656381e-06,
      "loss": 0.0,
      "step": 105930
    },
    {
      "epoch": 11.351119682845816,
      "grad_norm": 0.0006936806603334844,
      "learning_rate": 4.865173756205579e-06,
      "loss": 0.0,
      "step": 105940
    },
    {
      "epoch": 11.352191149683918,
      "grad_norm": 6.779895920772105e-05,
      "learning_rate": 4.863745133754777e-06,
      "loss": 0.0007,
      "step": 105950
    },
    {
      "epoch": 11.353262616522018,
      "grad_norm": 6.47987617412582e-05,
      "learning_rate": 4.862316511303976e-06,
      "loss": 0.0,
      "step": 105960
    },
    {
      "epoch": 11.35433408336012,
      "grad_norm": 0.00042700275662355125,
      "learning_rate": 4.8608878888531735e-06,
      "loss": 0.0,
      "step": 105970
    },
    {
      "epoch": 11.35540555019822,
      "grad_norm": 0.00472576217725873,
      "learning_rate": 4.859459266402372e-06,
      "loss": 0.0,
      "step": 105980
    },
    {
      "epoch": 11.356477017036323,
      "grad_norm": 0.0010989537695422769,
      "learning_rate": 4.85803064395157e-06,
      "loss": 0.0,
      "step": 105990
    },
    {
      "epoch": 11.357548483874425,
      "grad_norm": 7.028503023320809e-05,
      "learning_rate": 4.856602021500768e-06,
      "loss": 0.0,
      "step": 106000
    },
    {
      "epoch": 11.358619950712525,
      "grad_norm": 6.229682912817225e-05,
      "learning_rate": 4.855173399049967e-06,
      "loss": 0.2004,
      "step": 106010
    },
    {
      "epoch": 11.359691417550627,
      "grad_norm": 0.001070609432645142,
      "learning_rate": 4.8537447765991644e-06,
      "loss": 0.0,
      "step": 106020
    },
    {
      "epoch": 11.360762884388729,
      "grad_norm": 7.488899427698925e-05,
      "learning_rate": 4.852316154148363e-06,
      "loss": 0.0,
      "step": 106030
    },
    {
      "epoch": 11.361834351226829,
      "grad_norm": 0.00032247064518742263,
      "learning_rate": 4.8508875316975615e-06,
      "loss": 0.0,
      "step": 106040
    },
    {
      "epoch": 11.362905818064931,
      "grad_norm": 7.633643690496683e-05,
      "learning_rate": 4.849458909246759e-06,
      "loss": 0.0001,
      "step": 106050
    },
    {
      "epoch": 11.363977284903033,
      "grad_norm": 7.041883509373292e-05,
      "learning_rate": 4.848030286795957e-06,
      "loss": 0.0001,
      "step": 106060
    },
    {
      "epoch": 11.365048751741133,
      "grad_norm": 6.975353608140722e-05,
      "learning_rate": 4.846601664345156e-06,
      "loss": 0.0,
      "step": 106070
    },
    {
      "epoch": 11.366120218579235,
      "grad_norm": 6.456786650232971e-05,
      "learning_rate": 4.845173041894354e-06,
      "loss": 0.0001,
      "step": 106080
    },
    {
      "epoch": 11.367191685417337,
      "grad_norm": 7.389122765744105e-05,
      "learning_rate": 4.8437444194435515e-06,
      "loss": 0.0,
      "step": 106090
    },
    {
      "epoch": 11.368263152255437,
      "grad_norm": 6.785210280213505e-05,
      "learning_rate": 4.84231579699275e-06,
      "loss": 0.0,
      "step": 106100
    },
    {
      "epoch": 11.36933461909354,
      "grad_norm": 0.0003924427437596023,
      "learning_rate": 4.8408871745419486e-06,
      "loss": 0.0,
      "step": 106110
    },
    {
      "epoch": 11.37040608593164,
      "grad_norm": 6.681771628791466e-05,
      "learning_rate": 4.839458552091146e-06,
      "loss": 0.0,
      "step": 106120
    },
    {
      "epoch": 11.371477552769742,
      "grad_norm": 7.059243944240734e-05,
      "learning_rate": 4.838029929640345e-06,
      "loss": 0.01,
      "step": 106130
    },
    {
      "epoch": 11.372549019607844,
      "grad_norm": 0.0008637027931399643,
      "learning_rate": 4.836601307189543e-06,
      "loss": 0.0,
      "step": 106140
    },
    {
      "epoch": 11.373620486445944,
      "grad_norm": 5.9226073062745854e-05,
      "learning_rate": 4.835172684738741e-06,
      "loss": 0.0,
      "step": 106150
    },
    {
      "epoch": 11.374691953284046,
      "grad_norm": 8.384093234781176e-05,
      "learning_rate": 4.8337440622879395e-06,
      "loss": 0.0,
      "step": 106160
    },
    {
      "epoch": 11.375763420122148,
      "grad_norm": 6.388060137396678e-05,
      "learning_rate": 4.832315439837137e-06,
      "loss": 0.0,
      "step": 106170
    },
    {
      "epoch": 11.376834886960248,
      "grad_norm": 6.902183667989448e-05,
      "learning_rate": 4.830886817386336e-06,
      "loss": 0.0,
      "step": 106180
    },
    {
      "epoch": 11.37790635379835,
      "grad_norm": 5.708781463908963e-05,
      "learning_rate": 4.829458194935534e-06,
      "loss": 0.0,
      "step": 106190
    },
    {
      "epoch": 11.378977820636452,
      "grad_norm": 5.9167181461816654e-05,
      "learning_rate": 4.828029572484732e-06,
      "loss": 0.0,
      "step": 106200
    },
    {
      "epoch": 11.380049287474552,
      "grad_norm": 0.0005730107077397406,
      "learning_rate": 4.82660095003393e-06,
      "loss": 0.0,
      "step": 106210
    },
    {
      "epoch": 11.381120754312654,
      "grad_norm": 7.08220322849229e-05,
      "learning_rate": 4.825172327583129e-06,
      "loss": 0.0,
      "step": 106220
    },
    {
      "epoch": 11.382192221150756,
      "grad_norm": 6.973435665713623e-05,
      "learning_rate": 4.8237437051323266e-06,
      "loss": 0.0,
      "step": 106230
    },
    {
      "epoch": 11.383263687988856,
      "grad_norm": 6.37376942904666e-05,
      "learning_rate": 4.822315082681524e-06,
      "loss": 0.2904,
      "step": 106240
    },
    {
      "epoch": 11.384335154826958,
      "grad_norm": 6.992481939960271e-05,
      "learning_rate": 4.820886460230723e-06,
      "loss": 0.0,
      "step": 106250
    },
    {
      "epoch": 11.385406621665059,
      "grad_norm": 7.883721264079213e-05,
      "learning_rate": 4.819457837779921e-06,
      "loss": 0.108,
      "step": 106260
    },
    {
      "epoch": 11.38647808850316,
      "grad_norm": 8.894482743926346e-05,
      "learning_rate": 4.818029215329119e-06,
      "loss": 0.0,
      "step": 106270
    },
    {
      "epoch": 11.387549555341263,
      "grad_norm": 0.010445586405694485,
      "learning_rate": 4.8166005928783175e-06,
      "loss": 0.0,
      "step": 106280
    },
    {
      "epoch": 11.388621022179363,
      "grad_norm": 7.6735632319469e-05,
      "learning_rate": 4.815171970427516e-06,
      "loss": 0.1499,
      "step": 106290
    },
    {
      "epoch": 11.389692489017465,
      "grad_norm": 0.0008972446084953845,
      "learning_rate": 4.813743347976714e-06,
      "loss": 0.0001,
      "step": 106300
    },
    {
      "epoch": 11.390763955855567,
      "grad_norm": 0.00040069507667794824,
      "learning_rate": 4.812314725525912e-06,
      "loss": 0.0,
      "step": 106310
    },
    {
      "epoch": 11.391835422693667,
      "grad_norm": 0.000977142946794629,
      "learning_rate": 4.81088610307511e-06,
      "loss": 0.0,
      "step": 106320
    },
    {
      "epoch": 11.392906889531769,
      "grad_norm": 7.801865285728127e-05,
      "learning_rate": 4.809457480624308e-06,
      "loss": 0.0,
      "step": 106330
    },
    {
      "epoch": 11.393978356369871,
      "grad_norm": 0.0006857990520074964,
      "learning_rate": 4.808028858173507e-06,
      "loss": 0.0,
      "step": 106340
    },
    {
      "epoch": 11.395049823207971,
      "grad_norm": 8.72598247951828e-05,
      "learning_rate": 4.8066002357227046e-06,
      "loss": 0.0,
      "step": 106350
    },
    {
      "epoch": 11.396121290046073,
      "grad_norm": 7.710394129389897e-05,
      "learning_rate": 4.805171613271903e-06,
      "loss": 0.0002,
      "step": 106360
    },
    {
      "epoch": 11.397192756884174,
      "grad_norm": 7.602044206578285e-05,
      "learning_rate": 4.803742990821102e-06,
      "loss": 0.1614,
      "step": 106370
    },
    {
      "epoch": 11.398264223722276,
      "grad_norm": 0.0779513567686081,
      "learning_rate": 4.802314368370299e-06,
      "loss": 0.0001,
      "step": 106380
    },
    {
      "epoch": 11.399335690560378,
      "grad_norm": 0.00024864618899300694,
      "learning_rate": 4.800885745919498e-06,
      "loss": 0.0,
      "step": 106390
    },
    {
      "epoch": 11.400407157398478,
      "grad_norm": 0.00048091309145092964,
      "learning_rate": 4.799457123468696e-06,
      "loss": 0.0,
      "step": 106400
    },
    {
      "epoch": 11.40147862423658,
      "grad_norm": 0.010420601814985275,
      "learning_rate": 4.798028501017894e-06,
      "loss": 0.0008,
      "step": 106410
    },
    {
      "epoch": 11.402550091074682,
      "grad_norm": 8.429876470472664e-05,
      "learning_rate": 4.796599878567092e-06,
      "loss": 0.0,
      "step": 106420
    },
    {
      "epoch": 11.403621557912782,
      "grad_norm": 0.001068483921699226,
      "learning_rate": 4.79517125611629e-06,
      "loss": 0.0,
      "step": 106430
    },
    {
      "epoch": 11.404693024750884,
      "grad_norm": 0.0014779220800846815,
      "learning_rate": 4.793742633665489e-06,
      "loss": 0.0001,
      "step": 106440
    },
    {
      "epoch": 11.405764491588986,
      "grad_norm": 8.093812357401475e-05,
      "learning_rate": 4.792314011214686e-06,
      "loss": 0.0,
      "step": 106450
    },
    {
      "epoch": 11.406835958427086,
      "grad_norm": 0.0004062983498442918,
      "learning_rate": 4.790885388763885e-06,
      "loss": 0.0001,
      "step": 106460
    },
    {
      "epoch": 11.407907425265188,
      "grad_norm": 8.077405800577253e-05,
      "learning_rate": 4.789456766313083e-06,
      "loss": 0.0006,
      "step": 106470
    },
    {
      "epoch": 11.40897889210329,
      "grad_norm": 0.0003469919029157609,
      "learning_rate": 4.788028143862281e-06,
      "loss": 0.0,
      "step": 106480
    },
    {
      "epoch": 11.41005035894139,
      "grad_norm": 0.002743352437391877,
      "learning_rate": 4.786599521411479e-06,
      "loss": 0.0,
      "step": 106490
    },
    {
      "epoch": 11.411121825779492,
      "grad_norm": 0.0018717703642323613,
      "learning_rate": 4.785170898960677e-06,
      "loss": 0.0,
      "step": 106500
    },
    {
      "epoch": 11.412193292617593,
      "grad_norm": 6.754280911991373e-05,
      "learning_rate": 4.783742276509876e-06,
      "loss": 0.0,
      "step": 106510
    },
    {
      "epoch": 11.413264759455695,
      "grad_norm": 7.24011188140139e-05,
      "learning_rate": 4.7823136540590735e-06,
      "loss": 0.0,
      "step": 106520
    },
    {
      "epoch": 11.414336226293797,
      "grad_norm": 0.0019466549856588244,
      "learning_rate": 4.780885031608272e-06,
      "loss": 0.0,
      "step": 106530
    },
    {
      "epoch": 11.415407693131897,
      "grad_norm": 0.04324699565768242,
      "learning_rate": 4.7794564091574705e-06,
      "loss": 0.0001,
      "step": 106540
    },
    {
      "epoch": 11.416479159969999,
      "grad_norm": 0.0001079316352843307,
      "learning_rate": 4.778027786706668e-06,
      "loss": 0.0,
      "step": 106550
    },
    {
      "epoch": 11.4175506268081,
      "grad_norm": 0.05566307157278061,
      "learning_rate": 4.776599164255867e-06,
      "loss": 0.0001,
      "step": 106560
    },
    {
      "epoch": 11.418622093646201,
      "grad_norm": 109.62299346923828,
      "learning_rate": 4.775170541805064e-06,
      "loss": 0.1878,
      "step": 106570
    },
    {
      "epoch": 11.419693560484303,
      "grad_norm": 0.0003756701189558953,
      "learning_rate": 4.773741919354263e-06,
      "loss": 0.1353,
      "step": 106580
    },
    {
      "epoch": 11.420765027322405,
      "grad_norm": 7.491520227631554e-05,
      "learning_rate": 4.772313296903461e-06,
      "loss": 0.0,
      "step": 106590
    },
    {
      "epoch": 11.421836494160505,
      "grad_norm": 0.0051973420195281506,
      "learning_rate": 4.770884674452659e-06,
      "loss": 0.0768,
      "step": 106600
    },
    {
      "epoch": 11.422907960998607,
      "grad_norm": 7.174099300755188e-05,
      "learning_rate": 4.769456052001858e-06,
      "loss": 0.1999,
      "step": 106610
    },
    {
      "epoch": 11.42397942783671,
      "grad_norm": 0.0009524626657366753,
      "learning_rate": 4.768027429551056e-06,
      "loss": 0.1631,
      "step": 106620
    },
    {
      "epoch": 11.42505089467481,
      "grad_norm": 8.591108053224161e-05,
      "learning_rate": 4.766598807100254e-06,
      "loss": 0.0003,
      "step": 106630
    },
    {
      "epoch": 11.426122361512911,
      "grad_norm": 0.00038952394970692694,
      "learning_rate": 4.765170184649452e-06,
      "loss": 0.0003,
      "step": 106640
    },
    {
      "epoch": 11.427193828351012,
      "grad_norm": 7.706777250859886e-05,
      "learning_rate": 4.763741562198651e-06,
      "loss": 0.0006,
      "step": 106650
    },
    {
      "epoch": 11.428265295189114,
      "grad_norm": 0.001264378777705133,
      "learning_rate": 4.7623129397478485e-06,
      "loss": 0.0002,
      "step": 106660
    },
    {
      "epoch": 11.429336762027216,
      "grad_norm": 0.028966380283236504,
      "learning_rate": 4.760884317297046e-06,
      "loss": 0.0,
      "step": 106670
    },
    {
      "epoch": 11.430408228865316,
      "grad_norm": 7.386218203464523e-05,
      "learning_rate": 4.759455694846245e-06,
      "loss": 0.0,
      "step": 106680
    },
    {
      "epoch": 11.431479695703418,
      "grad_norm": 7.823596388334408e-05,
      "learning_rate": 4.758027072395443e-06,
      "loss": 0.0,
      "step": 106690
    },
    {
      "epoch": 11.43255116254152,
      "grad_norm": 7.067650585668162e-05,
      "learning_rate": 4.756598449944641e-06,
      "loss": 0.0,
      "step": 106700
    },
    {
      "epoch": 11.43362262937962,
      "grad_norm": 7.259509584400803e-05,
      "learning_rate": 4.755169827493839e-06,
      "loss": 0.1538,
      "step": 106710
    },
    {
      "epoch": 11.434694096217722,
      "grad_norm": 7.62857380323112e-05,
      "learning_rate": 4.753741205043038e-06,
      "loss": 0.0001,
      "step": 106720
    },
    {
      "epoch": 11.435765563055824,
      "grad_norm": 0.0011748209362849593,
      "learning_rate": 4.752312582592236e-06,
      "loss": 0.0001,
      "step": 106730
    },
    {
      "epoch": 11.436837029893924,
      "grad_norm": 0.00031746545573696494,
      "learning_rate": 4.750883960141434e-06,
      "loss": 0.1736,
      "step": 106740
    },
    {
      "epoch": 11.437908496732026,
      "grad_norm": 8.044349669944495e-05,
      "learning_rate": 4.749455337690632e-06,
      "loss": 0.0925,
      "step": 106750
    },
    {
      "epoch": 11.438979963570128,
      "grad_norm": 8.079117105808109e-05,
      "learning_rate": 4.74802671523983e-06,
      "loss": 0.0,
      "step": 106760
    },
    {
      "epoch": 11.440051430408229,
      "grad_norm": 0.0012318326625972986,
      "learning_rate": 4.746598092789029e-06,
      "loss": 0.18,
      "step": 106770
    },
    {
      "epoch": 11.44112289724633,
      "grad_norm": 0.00015801223344169557,
      "learning_rate": 4.7451694703382265e-06,
      "loss": 0.0,
      "step": 106780
    },
    {
      "epoch": 11.44219436408443,
      "grad_norm": 7.939504575915635e-05,
      "learning_rate": 4.743740847887425e-06,
      "loss": 0.0,
      "step": 106790
    },
    {
      "epoch": 11.443265830922533,
      "grad_norm": 8.010573219507933e-05,
      "learning_rate": 4.7423122254366236e-06,
      "loss": 0.0,
      "step": 106800
    },
    {
      "epoch": 11.444337297760635,
      "grad_norm": 8.656325371703133e-05,
      "learning_rate": 4.740883602985821e-06,
      "loss": 0.0005,
      "step": 106810
    },
    {
      "epoch": 11.445408764598735,
      "grad_norm": 5.516812324523926,
      "learning_rate": 4.739454980535019e-06,
      "loss": 0.0024,
      "step": 106820
    },
    {
      "epoch": 11.446480231436837,
      "grad_norm": 0.001268541906028986,
      "learning_rate": 4.738026358084218e-06,
      "loss": 0.0,
      "step": 106830
    },
    {
      "epoch": 11.447551698274939,
      "grad_norm": 7.194052159320563e-05,
      "learning_rate": 4.736597735633416e-06,
      "loss": 0.0,
      "step": 106840
    },
    {
      "epoch": 11.44862316511304,
      "grad_norm": 8.317685569636524e-05,
      "learning_rate": 4.735169113182614e-06,
      "loss": 0.0,
      "step": 106850
    },
    {
      "epoch": 11.449694631951141,
      "grad_norm": 9.59175595198758e-05,
      "learning_rate": 4.733740490731812e-06,
      "loss": 0.0,
      "step": 106860
    },
    {
      "epoch": 11.450766098789243,
      "grad_norm": 0.0017714148852974176,
      "learning_rate": 4.732311868281011e-06,
      "loss": 0.0003,
      "step": 106870
    },
    {
      "epoch": 11.451837565627343,
      "grad_norm": 0.0008638062863610685,
      "learning_rate": 4.730883245830208e-06,
      "loss": 0.0,
      "step": 106880
    },
    {
      "epoch": 11.452909032465445,
      "grad_norm": 7.812512194504961e-05,
      "learning_rate": 4.729454623379407e-06,
      "loss": 0.0,
      "step": 106890
    },
    {
      "epoch": 11.453980499303547,
      "grad_norm": 7.348779763560742e-05,
      "learning_rate": 4.728026000928605e-06,
      "loss": 0.0,
      "step": 106900
    },
    {
      "epoch": 11.455051966141648,
      "grad_norm": 7.340503361774608e-05,
      "learning_rate": 4.726597378477803e-06,
      "loss": 0.0,
      "step": 106910
    },
    {
      "epoch": 11.45612343297975,
      "grad_norm": 7.245402230182663e-05,
      "learning_rate": 4.7251687560270016e-06,
      "loss": 0.0,
      "step": 106920
    },
    {
      "epoch": 11.45719489981785,
      "grad_norm": 7.537726924056187e-05,
      "learning_rate": 4.723740133576199e-06,
      "loss": 0.0002,
      "step": 106930
    },
    {
      "epoch": 11.458266366655952,
      "grad_norm": 8.873026672517881e-05,
      "learning_rate": 4.722311511125398e-06,
      "loss": 0.0007,
      "step": 106940
    },
    {
      "epoch": 11.459337833494054,
      "grad_norm": 0.0065398444421589375,
      "learning_rate": 4.720882888674596e-06,
      "loss": 0.0002,
      "step": 106950
    },
    {
      "epoch": 11.460409300332154,
      "grad_norm": 7.083835225785151e-05,
      "learning_rate": 4.719454266223794e-06,
      "loss": 0.1075,
      "step": 106960
    },
    {
      "epoch": 11.461480767170256,
      "grad_norm": 8.477688243146986e-05,
      "learning_rate": 4.7180256437729925e-06,
      "loss": 0.0,
      "step": 106970
    },
    {
      "epoch": 11.462552234008358,
      "grad_norm": 0.017643077298998833,
      "learning_rate": 4.716597021322191e-06,
      "loss": 0.0,
      "step": 106980
    },
    {
      "epoch": 11.463623700846458,
      "grad_norm": 0.00019575742771849036,
      "learning_rate": 4.715168398871389e-06,
      "loss": 0.0,
      "step": 106990
    },
    {
      "epoch": 11.46469516768456,
      "grad_norm": 0.0006117705488577485,
      "learning_rate": 4.713739776420586e-06,
      "loss": 0.0002,
      "step": 107000
    },
    {
      "epoch": 11.465766634522662,
      "grad_norm": 6.992414273554459e-05,
      "learning_rate": 4.712311153969785e-06,
      "loss": 0.2115,
      "step": 107010
    },
    {
      "epoch": 11.466838101360763,
      "grad_norm": 0.0007151493919081986,
      "learning_rate": 4.710882531518983e-06,
      "loss": 0.0,
      "step": 107020
    },
    {
      "epoch": 11.467909568198865,
      "grad_norm": 0.0005290332483127713,
      "learning_rate": 4.709453909068181e-06,
      "loss": 0.0,
      "step": 107030
    },
    {
      "epoch": 11.468981035036965,
      "grad_norm": 0.031371794641017914,
      "learning_rate": 4.7080252866173795e-06,
      "loss": 0.0,
      "step": 107040
    },
    {
      "epoch": 11.470052501875067,
      "grad_norm": 6.71471789246425e-05,
      "learning_rate": 4.706596664166578e-06,
      "loss": 0.0073,
      "step": 107050
    },
    {
      "epoch": 11.471123968713169,
      "grad_norm": 7.545413973275572e-05,
      "learning_rate": 4.705168041715776e-06,
      "loss": 0.3381,
      "step": 107060
    },
    {
      "epoch": 11.472195435551269,
      "grad_norm": 7.962960080476478e-05,
      "learning_rate": 4.703739419264974e-06,
      "loss": 0.0,
      "step": 107070
    },
    {
      "epoch": 11.473266902389371,
      "grad_norm": 9.204995876643807e-05,
      "learning_rate": 4.702310796814172e-06,
      "loss": 0.0,
      "step": 107080
    },
    {
      "epoch": 11.474338369227473,
      "grad_norm": 0.00032457566703669727,
      "learning_rate": 4.7008821743633705e-06,
      "loss": 0.0009,
      "step": 107090
    },
    {
      "epoch": 11.475409836065573,
      "grad_norm": 0.015091990120708942,
      "learning_rate": 4.699453551912569e-06,
      "loss": 0.0,
      "step": 107100
    },
    {
      "epoch": 11.476481302903675,
      "grad_norm": 0.00010936531180050224,
      "learning_rate": 4.698024929461767e-06,
      "loss": 0.1432,
      "step": 107110
    },
    {
      "epoch": 11.477552769741777,
      "grad_norm": 0.00020703313930425793,
      "learning_rate": 4.696596307010965e-06,
      "loss": 0.0,
      "step": 107120
    },
    {
      "epoch": 11.478624236579877,
      "grad_norm": 0.00011672372784232721,
      "learning_rate": 4.695167684560164e-06,
      "loss": 0.0,
      "step": 107130
    },
    {
      "epoch": 11.47969570341798,
      "grad_norm": 0.0017572775250300765,
      "learning_rate": 4.693739062109361e-06,
      "loss": 0.0,
      "step": 107140
    },
    {
      "epoch": 11.480767170256081,
      "grad_norm": 0.0009628255502320826,
      "learning_rate": 4.69231043965856e-06,
      "loss": 0.0,
      "step": 107150
    },
    {
      "epoch": 11.481838637094182,
      "grad_norm": 9.107842925004661e-05,
      "learning_rate": 4.690881817207758e-06,
      "loss": 0.0007,
      "step": 107160
    },
    {
      "epoch": 11.482910103932284,
      "grad_norm": 0.00039787200512364507,
      "learning_rate": 4.689453194756956e-06,
      "loss": 0.187,
      "step": 107170
    },
    {
      "epoch": 11.483981570770384,
      "grad_norm": 0.03222314268350601,
      "learning_rate": 4.688024572306154e-06,
      "loss": 0.0,
      "step": 107180
    },
    {
      "epoch": 11.485053037608486,
      "grad_norm": 0.00040207285201177,
      "learning_rate": 4.686595949855352e-06,
      "loss": 0.0003,
      "step": 107190
    },
    {
      "epoch": 11.486124504446588,
      "grad_norm": 0.00018940948939416558,
      "learning_rate": 4.685167327404551e-06,
      "loss": 0.0,
      "step": 107200
    },
    {
      "epoch": 11.487195971284688,
      "grad_norm": 0.000255450839176774,
      "learning_rate": 4.6837387049537485e-06,
      "loss": 0.0,
      "step": 107210
    },
    {
      "epoch": 11.48826743812279,
      "grad_norm": 0.0003620147763285786,
      "learning_rate": 4.682310082502947e-06,
      "loss": 0.0013,
      "step": 107220
    },
    {
      "epoch": 11.489338904960892,
      "grad_norm": 8.875840285327286e-05,
      "learning_rate": 4.6808814600521455e-06,
      "loss": 0.0,
      "step": 107230
    },
    {
      "epoch": 11.490410371798992,
      "grad_norm": 9.09927548491396e-05,
      "learning_rate": 4.679452837601343e-06,
      "loss": 0.0,
      "step": 107240
    },
    {
      "epoch": 11.491481838637094,
      "grad_norm": 0.003819734090939164,
      "learning_rate": 4.678024215150542e-06,
      "loss": 0.0,
      "step": 107250
    },
    {
      "epoch": 11.492553305475196,
      "grad_norm": 0.000259755237493664,
      "learning_rate": 4.676595592699739e-06,
      "loss": 0.0,
      "step": 107260
    },
    {
      "epoch": 11.493624772313296,
      "grad_norm": 0.1398400515317917,
      "learning_rate": 4.675166970248938e-06,
      "loss": 0.0003,
      "step": 107270
    },
    {
      "epoch": 11.494696239151398,
      "grad_norm": 0.003908778075128794,
      "learning_rate": 4.673738347798136e-06,
      "loss": 0.102,
      "step": 107280
    },
    {
      "epoch": 11.4957677059895,
      "grad_norm": 0.00014331848069559783,
      "learning_rate": 4.672309725347334e-06,
      "loss": 0.0,
      "step": 107290
    },
    {
      "epoch": 11.4968391728276,
      "grad_norm": 0.22296969592571259,
      "learning_rate": 4.670881102896533e-06,
      "loss": 0.0054,
      "step": 107300
    },
    {
      "epoch": 11.497910639665703,
      "grad_norm": 7.879363693064079e-05,
      "learning_rate": 4.669452480445731e-06,
      "loss": 0.0,
      "step": 107310
    },
    {
      "epoch": 11.498982106503803,
      "grad_norm": 8.663749758852646e-05,
      "learning_rate": 4.668023857994929e-06,
      "loss": 0.0,
      "step": 107320
    },
    {
      "epoch": 11.500053573341905,
      "grad_norm": 0.00019546880503185093,
      "learning_rate": 4.6665952355441265e-06,
      "loss": 0.0,
      "step": 107330
    },
    {
      "epoch": 11.501125040180007,
      "grad_norm": 0.000278612831607461,
      "learning_rate": 4.665166613093326e-06,
      "loss": 0.0004,
      "step": 107340
    },
    {
      "epoch": 11.502196507018107,
      "grad_norm": 9.141308692051098e-05,
      "learning_rate": 4.6637379906425235e-06,
      "loss": 0.0,
      "step": 107350
    },
    {
      "epoch": 11.50326797385621,
      "grad_norm": 0.0288743544369936,
      "learning_rate": 4.662309368191721e-06,
      "loss": 0.0,
      "step": 107360
    },
    {
      "epoch": 11.504339440694311,
      "grad_norm": 0.0007466609822586179,
      "learning_rate": 4.66088074574092e-06,
      "loss": 0.0029,
      "step": 107370
    },
    {
      "epoch": 11.505410907532411,
      "grad_norm": 0.00030959644936956465,
      "learning_rate": 4.659452123290118e-06,
      "loss": 0.0,
      "step": 107380
    },
    {
      "epoch": 11.506482374370513,
      "grad_norm": 8.003196126082912e-05,
      "learning_rate": 4.658023500839316e-06,
      "loss": 0.0,
      "step": 107390
    },
    {
      "epoch": 11.507553841208615,
      "grad_norm": 3.6916072368621826,
      "learning_rate": 4.656594878388514e-06,
      "loss": 0.0019,
      "step": 107400
    },
    {
      "epoch": 11.508625308046716,
      "grad_norm": 0.00010856417065951973,
      "learning_rate": 4.655166255937713e-06,
      "loss": 0.0,
      "step": 107410
    },
    {
      "epoch": 11.509696774884818,
      "grad_norm": 7.482305954908952e-05,
      "learning_rate": 4.653737633486911e-06,
      "loss": 0.0,
      "step": 107420
    },
    {
      "epoch": 11.510768241722918,
      "grad_norm": 0.000601146079134196,
      "learning_rate": 4.652309011036108e-06,
      "loss": 0.0,
      "step": 107430
    },
    {
      "epoch": 11.51183970856102,
      "grad_norm": 0.00030332087771967053,
      "learning_rate": 4.650880388585307e-06,
      "loss": 0.0,
      "step": 107440
    },
    {
      "epoch": 11.512911175399122,
      "grad_norm": 0.000178405549377203,
      "learning_rate": 4.649451766134505e-06,
      "loss": 0.0,
      "step": 107450
    },
    {
      "epoch": 11.513982642237222,
      "grad_norm": 7.633766654180363e-05,
      "learning_rate": 4.648023143683703e-06,
      "loss": 0.0001,
      "step": 107460
    },
    {
      "epoch": 11.515054109075324,
      "grad_norm": 0.00021348960581235588,
      "learning_rate": 4.6465945212329015e-06,
      "loss": 0.0,
      "step": 107470
    },
    {
      "epoch": 11.516125575913426,
      "grad_norm": 7.562770770164207e-05,
      "learning_rate": 4.6451658987821e-06,
      "loss": 0.0,
      "step": 107480
    },
    {
      "epoch": 11.517197042751526,
      "grad_norm": 0.00011741384514607489,
      "learning_rate": 4.643737276331298e-06,
      "loss": 0.0,
      "step": 107490
    },
    {
      "epoch": 11.518268509589628,
      "grad_norm": 0.01111238356679678,
      "learning_rate": 4.642308653880496e-06,
      "loss": 0.0536,
      "step": 107500
    },
    {
      "epoch": 11.51933997642773,
      "grad_norm": 9.37880904530175e-05,
      "learning_rate": 4.640880031429694e-06,
      "loss": 0.0001,
      "step": 107510
    },
    {
      "epoch": 11.52041144326583,
      "grad_norm": 0.0035634685773402452,
      "learning_rate": 4.639451408978892e-06,
      "loss": 0.0,
      "step": 107520
    },
    {
      "epoch": 11.521482910103932,
      "grad_norm": 7.305439794436097e-05,
      "learning_rate": 4.638022786528091e-06,
      "loss": 0.0,
      "step": 107530
    },
    {
      "epoch": 11.522554376942034,
      "grad_norm": 6.48695495328866e-05,
      "learning_rate": 4.636594164077289e-06,
      "loss": 0.0,
      "step": 107540
    },
    {
      "epoch": 11.523625843780135,
      "grad_norm": 9.659028728492558e-05,
      "learning_rate": 4.635165541626487e-06,
      "loss": 0.0,
      "step": 107550
    },
    {
      "epoch": 11.524697310618237,
      "grad_norm": 9.051830420503393e-05,
      "learning_rate": 4.633736919175686e-06,
      "loss": 0.0,
      "step": 107560
    },
    {
      "epoch": 11.525768777456339,
      "grad_norm": 7.08059742464684e-05,
      "learning_rate": 4.632308296724883e-06,
      "loss": 0.0,
      "step": 107570
    },
    {
      "epoch": 11.526840244294439,
      "grad_norm": 7.38852031645365e-05,
      "learning_rate": 4.630879674274081e-06,
      "loss": 0.0,
      "step": 107580
    },
    {
      "epoch": 11.52791171113254,
      "grad_norm": 0.000207342513022013,
      "learning_rate": 4.62945105182328e-06,
      "loss": 0.0,
      "step": 107590
    },
    {
      "epoch": 11.528983177970641,
      "grad_norm": 7.919067866168916e-05,
      "learning_rate": 4.628022429372478e-06,
      "loss": 0.0,
      "step": 107600
    },
    {
      "epoch": 11.530054644808743,
      "grad_norm": 0.0422590970993042,
      "learning_rate": 4.626593806921676e-06,
      "loss": 0.1565,
      "step": 107610
    },
    {
      "epoch": 11.531126111646845,
      "grad_norm": 6.59260549582541e-05,
      "learning_rate": 4.625165184470874e-06,
      "loss": 0.0,
      "step": 107620
    },
    {
      "epoch": 11.532197578484945,
      "grad_norm": 0.00020150188356637955,
      "learning_rate": 4.623736562020073e-06,
      "loss": 0.0,
      "step": 107630
    },
    {
      "epoch": 11.533269045323047,
      "grad_norm": 8.382532541872934e-05,
      "learning_rate": 4.62230793956927e-06,
      "loss": 0.0,
      "step": 107640
    },
    {
      "epoch": 11.53434051216115,
      "grad_norm": 8.774382149567828e-05,
      "learning_rate": 4.620879317118469e-06,
      "loss": 0.2427,
      "step": 107650
    },
    {
      "epoch": 11.53541197899925,
      "grad_norm": 8.649144001537934e-05,
      "learning_rate": 4.6194506946676674e-06,
      "loss": 0.0005,
      "step": 107660
    },
    {
      "epoch": 11.536483445837352,
      "grad_norm": 6.958853191463277e-05,
      "learning_rate": 4.618022072216865e-06,
      "loss": 0.0,
      "step": 107670
    },
    {
      "epoch": 11.537554912675454,
      "grad_norm": 7.53615822759457e-05,
      "learning_rate": 4.616593449766064e-06,
      "loss": 0.1867,
      "step": 107680
    },
    {
      "epoch": 11.538626379513554,
      "grad_norm": 0.00021297490457072854,
      "learning_rate": 4.615164827315261e-06,
      "loss": 0.0,
      "step": 107690
    },
    {
      "epoch": 11.539697846351656,
      "grad_norm": 0.0008857283974066377,
      "learning_rate": 4.61373620486446e-06,
      "loss": 0.0,
      "step": 107700
    },
    {
      "epoch": 11.540769313189756,
      "grad_norm": 6.910396041348577e-05,
      "learning_rate": 4.612307582413658e-06,
      "loss": 0.0,
      "step": 107710
    },
    {
      "epoch": 11.541840780027858,
      "grad_norm": 0.03593683987855911,
      "learning_rate": 4.610878959962856e-06,
      "loss": 0.0038,
      "step": 107720
    },
    {
      "epoch": 11.54291224686596,
      "grad_norm": 6.425855099223554e-05,
      "learning_rate": 4.6094503375120545e-06,
      "loss": 0.0149,
      "step": 107730
    },
    {
      "epoch": 11.54398371370406,
      "grad_norm": 0.00019923766376450658,
      "learning_rate": 4.608021715061253e-06,
      "loss": 0.0,
      "step": 107740
    },
    {
      "epoch": 11.545055180542162,
      "grad_norm": 0.0004423974023666233,
      "learning_rate": 4.606593092610451e-06,
      "loss": 0.0,
      "step": 107750
    },
    {
      "epoch": 11.546126647380264,
      "grad_norm": 0.00019988507847301662,
      "learning_rate": 4.605164470159648e-06,
      "loss": 0.0,
      "step": 107760
    },
    {
      "epoch": 11.547198114218364,
      "grad_norm": 0.0006724986014887691,
      "learning_rate": 4.603735847708847e-06,
      "loss": 0.0,
      "step": 107770
    },
    {
      "epoch": 11.548269581056466,
      "grad_norm": 0.0002387155982432887,
      "learning_rate": 4.6023072252580454e-06,
      "loss": 0.1237,
      "step": 107780
    },
    {
      "epoch": 11.549341047894568,
      "grad_norm": 0.01540390681475401,
      "learning_rate": 4.600878602807243e-06,
      "loss": 0.0,
      "step": 107790
    },
    {
      "epoch": 11.550412514732669,
      "grad_norm": 7.028439722489566e-05,
      "learning_rate": 4.599449980356442e-06,
      "loss": 0.0,
      "step": 107800
    },
    {
      "epoch": 11.55148398157077,
      "grad_norm": 6.907748320372775e-05,
      "learning_rate": 4.59802135790564e-06,
      "loss": 0.0,
      "step": 107810
    },
    {
      "epoch": 11.55255544840887,
      "grad_norm": 0.00024279205536004156,
      "learning_rate": 4.596592735454838e-06,
      "loss": 0.0,
      "step": 107820
    },
    {
      "epoch": 11.553626915246973,
      "grad_norm": 0.0007640959229320288,
      "learning_rate": 4.595164113004036e-06,
      "loss": 0.0,
      "step": 107830
    },
    {
      "epoch": 11.554698382085075,
      "grad_norm": 0.00036810385063290596,
      "learning_rate": 4.593735490553234e-06,
      "loss": 0.0,
      "step": 107840
    },
    {
      "epoch": 11.555769848923175,
      "grad_norm": 7.075368921505287e-05,
      "learning_rate": 4.5923068681024325e-06,
      "loss": 0.0,
      "step": 107850
    },
    {
      "epoch": 11.556841315761277,
      "grad_norm": 0.0002583822642918676,
      "learning_rate": 4.590878245651631e-06,
      "loss": 0.0,
      "step": 107860
    },
    {
      "epoch": 11.557912782599379,
      "grad_norm": 7.307828491320834e-05,
      "learning_rate": 4.589449623200829e-06,
      "loss": 0.0,
      "step": 107870
    },
    {
      "epoch": 11.55898424943748,
      "grad_norm": 0.00011287209781585261,
      "learning_rate": 4.588021000750027e-06,
      "loss": 0.0617,
      "step": 107880
    },
    {
      "epoch": 11.560055716275581,
      "grad_norm": 7.734218525001779e-05,
      "learning_rate": 4.586592378299226e-06,
      "loss": 0.0627,
      "step": 107890
    },
    {
      "epoch": 11.561127183113683,
      "grad_norm": 0.0003270710294600576,
      "learning_rate": 4.5851637558484234e-06,
      "loss": 0.0424,
      "step": 107900
    },
    {
      "epoch": 11.562198649951783,
      "grad_norm": 4.569241046905518,
      "learning_rate": 4.583735133397622e-06,
      "loss": 0.0012,
      "step": 107910
    },
    {
      "epoch": 11.563270116789885,
      "grad_norm": 7.011412526480854e-05,
      "learning_rate": 4.5823065109468205e-06,
      "loss": 0.0,
      "step": 107920
    },
    {
      "epoch": 11.564341583627987,
      "grad_norm": 0.0019450013060122728,
      "learning_rate": 4.580877888496018e-06,
      "loss": 0.0,
      "step": 107930
    },
    {
      "epoch": 11.565413050466088,
      "grad_norm": 7.120530790416524e-05,
      "learning_rate": 4.579449266045216e-06,
      "loss": 0.0007,
      "step": 107940
    },
    {
      "epoch": 11.56648451730419,
      "grad_norm": 0.0002552312216721475,
      "learning_rate": 4.578020643594414e-06,
      "loss": 0.0,
      "step": 107950
    },
    {
      "epoch": 11.567555984142292,
      "grad_norm": 0.012753740884363651,
      "learning_rate": 4.576592021143613e-06,
      "loss": 0.0,
      "step": 107960
    },
    {
      "epoch": 11.568627450980392,
      "grad_norm": 7.096552872098982e-05,
      "learning_rate": 4.5751633986928105e-06,
      "loss": 0.0296,
      "step": 107970
    },
    {
      "epoch": 11.569698917818494,
      "grad_norm": 0.0008374081808142364,
      "learning_rate": 4.573734776242009e-06,
      "loss": 0.0,
      "step": 107980
    },
    {
      "epoch": 11.570770384656594,
      "grad_norm": 0.00030900209094397724,
      "learning_rate": 4.5723061537912076e-06,
      "loss": 0.31,
      "step": 107990
    },
    {
      "epoch": 11.571841851494696,
      "grad_norm": 7.215300865937024e-05,
      "learning_rate": 4.570877531340405e-06,
      "loss": 0.0001,
      "step": 108000
    },
    {
      "epoch": 11.572913318332798,
      "grad_norm": 6.702997052343562e-05,
      "learning_rate": 4.569448908889604e-06,
      "loss": 0.0,
      "step": 108010
    },
    {
      "epoch": 11.573984785170898,
      "grad_norm": 6.74097245791927e-05,
      "learning_rate": 4.5680202864388014e-06,
      "loss": 0.0007,
      "step": 108020
    },
    {
      "epoch": 11.575056252009,
      "grad_norm": 0.00455136364325881,
      "learning_rate": 4.566591663988e-06,
      "loss": 0.0,
      "step": 108030
    },
    {
      "epoch": 11.576127718847102,
      "grad_norm": 0.00013551385200116783,
      "learning_rate": 4.5651630415371985e-06,
      "loss": 0.193,
      "step": 108040
    },
    {
      "epoch": 11.577199185685203,
      "grad_norm": 0.013090058229863644,
      "learning_rate": 4.563734419086396e-06,
      "loss": 0.0,
      "step": 108050
    },
    {
      "epoch": 11.578270652523305,
      "grad_norm": 7.417760934913531e-05,
      "learning_rate": 4.562305796635595e-06,
      "loss": 0.0005,
      "step": 108060
    },
    {
      "epoch": 11.579342119361407,
      "grad_norm": 6.79920194670558e-05,
      "learning_rate": 4.560877174184793e-06,
      "loss": 0.1019,
      "step": 108070
    },
    {
      "epoch": 11.580413586199507,
      "grad_norm": 7.417696178890765e-05,
      "learning_rate": 4.559448551733991e-06,
      "loss": 0.0002,
      "step": 108080
    },
    {
      "epoch": 11.581485053037609,
      "grad_norm": 0.0008754870505072176,
      "learning_rate": 4.5580199292831885e-06,
      "loss": 0.0,
      "step": 108090
    },
    {
      "epoch": 11.582556519875709,
      "grad_norm": 7.490622374461964e-05,
      "learning_rate": 4.556591306832388e-06,
      "loss": 0.0,
      "step": 108100
    },
    {
      "epoch": 11.583627986713811,
      "grad_norm": 0.0004485041426960379,
      "learning_rate": 4.5551626843815856e-06,
      "loss": 0.0001,
      "step": 108110
    },
    {
      "epoch": 11.584699453551913,
      "grad_norm": 6.620161002501845e-05,
      "learning_rate": 4.553734061930783e-06,
      "loss": 0.0,
      "step": 108120
    },
    {
      "epoch": 11.585770920390013,
      "grad_norm": 0.0005219813319854438,
      "learning_rate": 4.552305439479982e-06,
      "loss": 0.0,
      "step": 108130
    },
    {
      "epoch": 11.586842387228115,
      "grad_norm": 8.432041067862883e-05,
      "learning_rate": 4.55087681702918e-06,
      "loss": 0.0,
      "step": 108140
    },
    {
      "epoch": 11.587913854066217,
      "grad_norm": 0.0005183632019907236,
      "learning_rate": 4.549448194578378e-06,
      "loss": 0.0001,
      "step": 108150
    },
    {
      "epoch": 11.588985320904317,
      "grad_norm": 7.457133324351162e-05,
      "learning_rate": 4.5480195721275765e-06,
      "loss": 0.0,
      "step": 108160
    },
    {
      "epoch": 11.59005678774242,
      "grad_norm": 6.410695641534403e-05,
      "learning_rate": 4.546590949676775e-06,
      "loss": 0.0001,
      "step": 108170
    },
    {
      "epoch": 11.591128254580521,
      "grad_norm": 8.73267199494876e-05,
      "learning_rate": 4.545162327225973e-06,
      "loss": 0.0001,
      "step": 108180
    },
    {
      "epoch": 11.592199721418622,
      "grad_norm": 0.1270562708377838,
      "learning_rate": 4.543733704775171e-06,
      "loss": 0.0001,
      "step": 108190
    },
    {
      "epoch": 11.593271188256724,
      "grad_norm": 0.00041470746509730816,
      "learning_rate": 4.542305082324369e-06,
      "loss": 0.1426,
      "step": 108200
    },
    {
      "epoch": 11.594342655094826,
      "grad_norm": 7.753493264317513e-05,
      "learning_rate": 4.540876459873567e-06,
      "loss": 0.0,
      "step": 108210
    },
    {
      "epoch": 11.595414121932926,
      "grad_norm": 0.00056001654593274,
      "learning_rate": 4.539447837422766e-06,
      "loss": 0.0001,
      "step": 108220
    },
    {
      "epoch": 11.596485588771028,
      "grad_norm": 7.771429955027997e-05,
      "learning_rate": 4.5380192149719636e-06,
      "loss": 0.0,
      "step": 108230
    },
    {
      "epoch": 11.597557055609128,
      "grad_norm": 0.0017193603562191129,
      "learning_rate": 4.536590592521162e-06,
      "loss": 0.0,
      "step": 108240
    },
    {
      "epoch": 11.59862852244723,
      "grad_norm": 6.736900104442611e-05,
      "learning_rate": 4.535161970070361e-06,
      "loss": 0.0,
      "step": 108250
    },
    {
      "epoch": 11.599699989285332,
      "grad_norm": 8.26659525046125e-05,
      "learning_rate": 4.533733347619558e-06,
      "loss": 0.1464,
      "step": 108260
    },
    {
      "epoch": 11.600771456123432,
      "grad_norm": 7.675838423892856e-05,
      "learning_rate": 4.532304725168756e-06,
      "loss": 0.0001,
      "step": 108270
    },
    {
      "epoch": 11.601842922961534,
      "grad_norm": 9.210410644300282e-05,
      "learning_rate": 4.5308761027179545e-06,
      "loss": 0.0,
      "step": 108280
    },
    {
      "epoch": 11.602914389799636,
      "grad_norm": 0.0005640053423121572,
      "learning_rate": 4.529447480267153e-06,
      "loss": 0.0,
      "step": 108290
    },
    {
      "epoch": 11.603985856637737,
      "grad_norm": 0.0006943379412405193,
      "learning_rate": 4.528018857816351e-06,
      "loss": 0.0,
      "step": 108300
    },
    {
      "epoch": 11.605057323475839,
      "grad_norm": 0.00036125764017924666,
      "learning_rate": 4.526590235365549e-06,
      "loss": 0.0089,
      "step": 108310
    },
    {
      "epoch": 11.60612879031394,
      "grad_norm": 7.82459246693179e-05,
      "learning_rate": 4.525161612914748e-06,
      "loss": 0.0,
      "step": 108320
    },
    {
      "epoch": 11.60720025715204,
      "grad_norm": 0.03554924950003624,
      "learning_rate": 4.523732990463945e-06,
      "loss": 0.0,
      "step": 108330
    },
    {
      "epoch": 11.608271723990143,
      "grad_norm": 0.00040759373223409057,
      "learning_rate": 4.522304368013143e-06,
      "loss": 0.0,
      "step": 108340
    },
    {
      "epoch": 11.609343190828245,
      "grad_norm": 0.00031977149774320424,
      "learning_rate": 4.520875745562342e-06,
      "loss": 0.0,
      "step": 108350
    },
    {
      "epoch": 11.610414657666345,
      "grad_norm": 0.00012235176109243184,
      "learning_rate": 4.51944712311154e-06,
      "loss": 0.0,
      "step": 108360
    },
    {
      "epoch": 11.611486124504447,
      "grad_norm": 0.0006778660463169217,
      "learning_rate": 4.518018500660738e-06,
      "loss": 0.0,
      "step": 108370
    },
    {
      "epoch": 11.612557591342547,
      "grad_norm": 0.00010781257878988981,
      "learning_rate": 4.516589878209936e-06,
      "loss": 0.0,
      "step": 108380
    },
    {
      "epoch": 11.61362905818065,
      "grad_norm": 0.0005879220552742481,
      "learning_rate": 4.515161255759135e-06,
      "loss": 0.0,
      "step": 108390
    },
    {
      "epoch": 11.614700525018751,
      "grad_norm": 7.093323074514046e-05,
      "learning_rate": 4.5137326333083325e-06,
      "loss": 0.0001,
      "step": 108400
    },
    {
      "epoch": 11.615771991856851,
      "grad_norm": 0.0018629331607371569,
      "learning_rate": 4.512304010857531e-06,
      "loss": 0.0,
      "step": 108410
    },
    {
      "epoch": 11.616843458694953,
      "grad_norm": 8.043862180784345e-05,
      "learning_rate": 4.5108753884067295e-06,
      "loss": 0.0,
      "step": 108420
    },
    {
      "epoch": 11.617914925533055,
      "grad_norm": 25.39776039123535,
      "learning_rate": 4.509446765955927e-06,
      "loss": 0.1783,
      "step": 108430
    },
    {
      "epoch": 11.618986392371156,
      "grad_norm": 7.45404904591851e-05,
      "learning_rate": 4.508018143505126e-06,
      "loss": 0.0,
      "step": 108440
    },
    {
      "epoch": 11.620057859209258,
      "grad_norm": 9.573922579875216e-05,
      "learning_rate": 4.506589521054323e-06,
      "loss": 0.0,
      "step": 108450
    },
    {
      "epoch": 11.62112932604736,
      "grad_norm": 8.113758667604998e-05,
      "learning_rate": 4.505160898603522e-06,
      "loss": 0.0001,
      "step": 108460
    },
    {
      "epoch": 11.62220079288546,
      "grad_norm": 31.46444320678711,
      "learning_rate": 4.50373227615272e-06,
      "loss": 0.1651,
      "step": 108470
    },
    {
      "epoch": 11.623272259723562,
      "grad_norm": 8.380163490073755e-05,
      "learning_rate": 4.502303653701918e-06,
      "loss": 0.0,
      "step": 108480
    },
    {
      "epoch": 11.624343726561662,
      "grad_norm": 8.955252269515768e-05,
      "learning_rate": 4.500875031251117e-06,
      "loss": 0.0,
      "step": 108490
    },
    {
      "epoch": 11.625415193399764,
      "grad_norm": 7.465248927474022e-05,
      "learning_rate": 4.499446408800315e-06,
      "loss": 0.0,
      "step": 108500
    },
    {
      "epoch": 11.626486660237866,
      "grad_norm": 7.993765029823408e-05,
      "learning_rate": 4.498017786349513e-06,
      "loss": 0.0899,
      "step": 108510
    },
    {
      "epoch": 11.627558127075966,
      "grad_norm": 0.00011726828233804554,
      "learning_rate": 4.4965891638987105e-06,
      "loss": 0.1368,
      "step": 108520
    },
    {
      "epoch": 11.628629593914068,
      "grad_norm": 0.017888378351926804,
      "learning_rate": 4.495160541447909e-06,
      "loss": 0.0001,
      "step": 108530
    },
    {
      "epoch": 11.62970106075217,
      "grad_norm": 0.000358257326297462,
      "learning_rate": 4.4937319189971075e-06,
      "loss": 0.0,
      "step": 108540
    },
    {
      "epoch": 11.63077252759027,
      "grad_norm": 8.232374966610223e-05,
      "learning_rate": 4.492303296546305e-06,
      "loss": 0.0,
      "step": 108550
    },
    {
      "epoch": 11.631843994428372,
      "grad_norm": 0.000294912897516042,
      "learning_rate": 4.490874674095504e-06,
      "loss": 0.0006,
      "step": 108560
    },
    {
      "epoch": 11.632915461266474,
      "grad_norm": 0.0003462481254246086,
      "learning_rate": 4.489446051644702e-06,
      "loss": 0.0,
      "step": 108570
    },
    {
      "epoch": 11.633986928104575,
      "grad_norm": 0.0007229245966300368,
      "learning_rate": 4.4880174291939e-06,
      "loss": 0.0,
      "step": 108580
    },
    {
      "epoch": 11.635058394942677,
      "grad_norm": 0.000154962734086439,
      "learning_rate": 4.486588806743098e-06,
      "loss": 0.0,
      "step": 108590
    },
    {
      "epoch": 11.636129861780779,
      "grad_norm": 7.666152669116855e-05,
      "learning_rate": 4.485160184292296e-06,
      "loss": 0.0,
      "step": 108600
    },
    {
      "epoch": 11.637201328618879,
      "grad_norm": 8.391545998165384e-05,
      "learning_rate": 4.483731561841495e-06,
      "loss": 0.0,
      "step": 108610
    },
    {
      "epoch": 11.638272795456981,
      "grad_norm": 0.0039047840982675552,
      "learning_rate": 4.482302939390693e-06,
      "loss": 0.0,
      "step": 108620
    },
    {
      "epoch": 11.639344262295083,
      "grad_norm": 8.962120773503557e-05,
      "learning_rate": 4.480874316939891e-06,
      "loss": 0.0,
      "step": 108630
    },
    {
      "epoch": 11.640415729133183,
      "grad_norm": 0.0003570644767023623,
      "learning_rate": 4.479445694489089e-06,
      "loss": 0.006,
      "step": 108640
    },
    {
      "epoch": 11.641487195971285,
      "grad_norm": 0.0005084514268673956,
      "learning_rate": 4.478017072038288e-06,
      "loss": 0.0025,
      "step": 108650
    },
    {
      "epoch": 11.642558662809385,
      "grad_norm": 0.0002485724980942905,
      "learning_rate": 4.4765884495874855e-06,
      "loss": 0.0,
      "step": 108660
    },
    {
      "epoch": 11.643630129647487,
      "grad_norm": 0.0003380747511982918,
      "learning_rate": 4.475159827136684e-06,
      "loss": 0.0,
      "step": 108670
    },
    {
      "epoch": 11.64470159648559,
      "grad_norm": 0.00016178732039406896,
      "learning_rate": 4.4737312046858825e-06,
      "loss": 0.0002,
      "step": 108680
    },
    {
      "epoch": 11.64577306332369,
      "grad_norm": 9.853860683506355e-05,
      "learning_rate": 4.47230258223508e-06,
      "loss": 0.1969,
      "step": 108690
    },
    {
      "epoch": 11.646844530161792,
      "grad_norm": 0.0003957829612772912,
      "learning_rate": 4.470873959784278e-06,
      "loss": 0.0,
      "step": 108700
    },
    {
      "epoch": 11.647915996999894,
      "grad_norm": 0.0007408899837173522,
      "learning_rate": 4.469445337333476e-06,
      "loss": 0.0,
      "step": 108710
    },
    {
      "epoch": 11.648987463837994,
      "grad_norm": 0.0011339581105858088,
      "learning_rate": 4.468016714882675e-06,
      "loss": 0.0,
      "step": 108720
    },
    {
      "epoch": 11.650058930676096,
      "grad_norm": 7.996999920578673e-05,
      "learning_rate": 4.466588092431873e-06,
      "loss": 0.0153,
      "step": 108730
    },
    {
      "epoch": 11.651130397514198,
      "grad_norm": 0.0004383140476420522,
      "learning_rate": 4.465159469981071e-06,
      "loss": 0.0,
      "step": 108740
    },
    {
      "epoch": 11.652201864352298,
      "grad_norm": 0.0006742925033904612,
      "learning_rate": 4.46373084753027e-06,
      "loss": 0.1302,
      "step": 108750
    },
    {
      "epoch": 11.6532733311904,
      "grad_norm": 9.120165486820042e-05,
      "learning_rate": 4.462302225079467e-06,
      "loss": 0.0,
      "step": 108760
    },
    {
      "epoch": 11.6543447980285,
      "grad_norm": 0.00016551243606954813,
      "learning_rate": 4.460873602628666e-06,
      "loss": 0.0,
      "step": 108770
    },
    {
      "epoch": 11.655416264866602,
      "grad_norm": 0.00026779365725815296,
      "learning_rate": 4.4594449801778635e-06,
      "loss": 0.0,
      "step": 108780
    },
    {
      "epoch": 11.656487731704704,
      "grad_norm": 8.458603406324983e-05,
      "learning_rate": 4.458016357727062e-06,
      "loss": 0.0038,
      "step": 108790
    },
    {
      "epoch": 11.657559198542804,
      "grad_norm": 0.0005101703573018312,
      "learning_rate": 4.4565877352762605e-06,
      "loss": 0.0,
      "step": 108800
    },
    {
      "epoch": 11.658630665380906,
      "grad_norm": 9.319397940998897e-05,
      "learning_rate": 4.455159112825458e-06,
      "loss": 0.0005,
      "step": 108810
    },
    {
      "epoch": 11.659702132219008,
      "grad_norm": 6.775150541216135e-05,
      "learning_rate": 4.453730490374657e-06,
      "loss": 0.0,
      "step": 108820
    },
    {
      "epoch": 11.660773599057109,
      "grad_norm": 7.127124263206497e-05,
      "learning_rate": 4.452301867923855e-06,
      "loss": 0.0,
      "step": 108830
    },
    {
      "epoch": 11.66184506589521,
      "grad_norm": 0.0037685197312384844,
      "learning_rate": 4.450873245473053e-06,
      "loss": 0.0,
      "step": 108840
    },
    {
      "epoch": 11.662916532733313,
      "grad_norm": 0.00010842303890967742,
      "learning_rate": 4.449444623022251e-06,
      "loss": 0.0,
      "step": 108850
    },
    {
      "epoch": 11.663987999571413,
      "grad_norm": 0.00022130817524157465,
      "learning_rate": 4.44801600057145e-06,
      "loss": 0.0,
      "step": 108860
    },
    {
      "epoch": 11.665059466409515,
      "grad_norm": 9.042704186867923e-05,
      "learning_rate": 4.446587378120648e-06,
      "loss": 0.0002,
      "step": 108870
    },
    {
      "epoch": 11.666130933247615,
      "grad_norm": 0.06786099076271057,
      "learning_rate": 4.445158755669845e-06,
      "loss": 0.0,
      "step": 108880
    },
    {
      "epoch": 11.667202400085717,
      "grad_norm": 9.389197657583281e-05,
      "learning_rate": 4.443730133219044e-06,
      "loss": 0.0001,
      "step": 108890
    },
    {
      "epoch": 11.668273866923819,
      "grad_norm": 0.00044821531628258526,
      "learning_rate": 4.442301510768242e-06,
      "loss": 0.0,
      "step": 108900
    },
    {
      "epoch": 11.66934533376192,
      "grad_norm": 7.54286302253604e-05,
      "learning_rate": 4.44087288831744e-06,
      "loss": 0.0,
      "step": 108910
    },
    {
      "epoch": 11.670416800600021,
      "grad_norm": 7.981017552083358e-05,
      "learning_rate": 4.4394442658666385e-06,
      "loss": 0.0,
      "step": 108920
    },
    {
      "epoch": 11.671488267438123,
      "grad_norm": 0.0002396906929789111,
      "learning_rate": 4.438015643415837e-06,
      "loss": 0.0,
      "step": 108930
    },
    {
      "epoch": 11.672559734276224,
      "grad_norm": 7.272890798049048e-05,
      "learning_rate": 4.436587020965035e-06,
      "loss": 0.0001,
      "step": 108940
    },
    {
      "epoch": 11.673631201114326,
      "grad_norm": 30.768768310546875,
      "learning_rate": 4.435158398514233e-06,
      "loss": 0.0062,
      "step": 108950
    },
    {
      "epoch": 11.674702667952428,
      "grad_norm": 6.751973705831915e-05,
      "learning_rate": 4.433729776063431e-06,
      "loss": 0.0,
      "step": 108960
    },
    {
      "epoch": 11.675774134790528,
      "grad_norm": 22.951608657836914,
      "learning_rate": 4.4323011536126294e-06,
      "loss": 0.0732,
      "step": 108970
    },
    {
      "epoch": 11.67684560162863,
      "grad_norm": 7.155506318667904e-05,
      "learning_rate": 4.430872531161828e-06,
      "loss": 0.0,
      "step": 108980
    },
    {
      "epoch": 11.677917068466732,
      "grad_norm": 0.00018943959730677307,
      "learning_rate": 4.429443908711026e-06,
      "loss": 0.1551,
      "step": 108990
    },
    {
      "epoch": 11.678988535304832,
      "grad_norm": 0.00044594399514608085,
      "learning_rate": 4.428015286260224e-06,
      "loss": 0.0002,
      "step": 109000
    },
    {
      "epoch": 11.680060002142934,
      "grad_norm": 0.46465981006622314,
      "learning_rate": 4.426586663809423e-06,
      "loss": 0.0003,
      "step": 109010
    },
    {
      "epoch": 11.681131468981036,
      "grad_norm": 7.610125612700358e-05,
      "learning_rate": 4.42515804135862e-06,
      "loss": 0.0,
      "step": 109020
    },
    {
      "epoch": 11.682202935819136,
      "grad_norm": 0.0008102013962343335,
      "learning_rate": 4.423729418907818e-06,
      "loss": 0.0,
      "step": 109030
    },
    {
      "epoch": 11.683274402657238,
      "grad_norm": 0.0019641865510493517,
      "learning_rate": 4.4223007964570165e-06,
      "loss": 0.0,
      "step": 109040
    },
    {
      "epoch": 11.684345869495338,
      "grad_norm": 6.640586798312142e-05,
      "learning_rate": 4.420872174006215e-06,
      "loss": 0.0,
      "step": 109050
    },
    {
      "epoch": 11.68541733633344,
      "grad_norm": 6.599323387490585e-05,
      "learning_rate": 4.419443551555413e-06,
      "loss": 0.0002,
      "step": 109060
    },
    {
      "epoch": 11.686488803171542,
      "grad_norm": 0.0003400460700504482,
      "learning_rate": 4.418014929104611e-06,
      "loss": 0.0,
      "step": 109070
    },
    {
      "epoch": 11.687560270009643,
      "grad_norm": 7.27609294699505e-05,
      "learning_rate": 4.41658630665381e-06,
      "loss": 0.0,
      "step": 109080
    },
    {
      "epoch": 11.688631736847745,
      "grad_norm": 7.332218956435099e-05,
      "learning_rate": 4.4151576842030074e-06,
      "loss": 0.0,
      "step": 109090
    },
    {
      "epoch": 11.689703203685847,
      "grad_norm": 0.00016006837540771812,
      "learning_rate": 4.413729061752206e-06,
      "loss": 0.0,
      "step": 109100
    },
    {
      "epoch": 11.690774670523947,
      "grad_norm": 0.00015720025112386793,
      "learning_rate": 4.412300439301404e-06,
      "loss": 0.0,
      "step": 109110
    },
    {
      "epoch": 11.691846137362049,
      "grad_norm": 6.619442137889564e-05,
      "learning_rate": 4.410871816850602e-06,
      "loss": 0.1675,
      "step": 109120
    },
    {
      "epoch": 11.69291760420015,
      "grad_norm": 0.1465017944574356,
      "learning_rate": 4.409443194399801e-06,
      "loss": 0.0001,
      "step": 109130
    },
    {
      "epoch": 11.693989071038251,
      "grad_norm": 7.415413710987195e-05,
      "learning_rate": 4.408014571948998e-06,
      "loss": 0.001,
      "step": 109140
    },
    {
      "epoch": 11.695060537876353,
      "grad_norm": 7.199258834589273e-05,
      "learning_rate": 4.406585949498197e-06,
      "loss": 0.0,
      "step": 109150
    },
    {
      "epoch": 11.696132004714453,
      "grad_norm": 0.011041723191738129,
      "learning_rate": 4.405157327047395e-06,
      "loss": 0.0,
      "step": 109160
    },
    {
      "epoch": 11.697203471552555,
      "grad_norm": 0.0003980180772487074,
      "learning_rate": 4.403728704596593e-06,
      "loss": 0.0,
      "step": 109170
    },
    {
      "epoch": 11.698274938390657,
      "grad_norm": 0.03443422541022301,
      "learning_rate": 4.402300082145792e-06,
      "loss": 0.0008,
      "step": 109180
    },
    {
      "epoch": 11.699346405228757,
      "grad_norm": 6.979527097428218e-05,
      "learning_rate": 4.400871459694989e-06,
      "loss": 0.0,
      "step": 109190
    },
    {
      "epoch": 11.70041787206686,
      "grad_norm": 6.991349800955504e-05,
      "learning_rate": 4.399442837244188e-06,
      "loss": 0.0,
      "step": 109200
    },
    {
      "epoch": 11.701489338904961,
      "grad_norm": 6.930428935447708e-05,
      "learning_rate": 4.3980142147933854e-06,
      "loss": 0.0,
      "step": 109210
    },
    {
      "epoch": 11.702560805743062,
      "grad_norm": 6.76955605740659e-05,
      "learning_rate": 4.396585592342584e-06,
      "loss": 0.1264,
      "step": 109220
    },
    {
      "epoch": 11.703632272581164,
      "grad_norm": 0.0003613016160670668,
      "learning_rate": 4.3951569698917825e-06,
      "loss": 0.0001,
      "step": 109230
    },
    {
      "epoch": 11.704703739419266,
      "grad_norm": 7.551239832537249e-05,
      "learning_rate": 4.39372834744098e-06,
      "loss": 0.0,
      "step": 109240
    },
    {
      "epoch": 11.705775206257366,
      "grad_norm": 7.399334572255611e-05,
      "learning_rate": 4.392299724990179e-06,
      "loss": 0.0,
      "step": 109250
    },
    {
      "epoch": 11.706846673095468,
      "grad_norm": 125.6376953125,
      "learning_rate": 4.390871102539377e-06,
      "loss": 0.2025,
      "step": 109260
    },
    {
      "epoch": 11.707918139933568,
      "grad_norm": 0.0001526825944893062,
      "learning_rate": 4.389442480088575e-06,
      "loss": 0.0,
      "step": 109270
    },
    {
      "epoch": 11.70898960677167,
      "grad_norm": 0.0003280641103629023,
      "learning_rate": 4.3880138576377725e-06,
      "loss": 0.0,
      "step": 109280
    },
    {
      "epoch": 11.710061073609772,
      "grad_norm": 0.0007321795565076172,
      "learning_rate": 4.386585235186971e-06,
      "loss": 0.0,
      "step": 109290
    },
    {
      "epoch": 11.711132540447872,
      "grad_norm": 8.279411849798635e-05,
      "learning_rate": 4.38515661273617e-06,
      "loss": 0.0,
      "step": 109300
    },
    {
      "epoch": 11.712204007285974,
      "grad_norm": 0.01687636785209179,
      "learning_rate": 4.383727990285367e-06,
      "loss": 0.0,
      "step": 109310
    },
    {
      "epoch": 11.713275474124076,
      "grad_norm": 0.00017491636390332133,
      "learning_rate": 4.382299367834566e-06,
      "loss": 0.1822,
      "step": 109320
    },
    {
      "epoch": 11.714346940962177,
      "grad_norm": 0.003660098649561405,
      "learning_rate": 4.380870745383764e-06,
      "loss": 0.0001,
      "step": 109330
    },
    {
      "epoch": 11.715418407800279,
      "grad_norm": 6.63362443447113e-05,
      "learning_rate": 4.379442122932962e-06,
      "loss": 0.0,
      "step": 109340
    },
    {
      "epoch": 11.71648987463838,
      "grad_norm": 0.0042869821190834045,
      "learning_rate": 4.3780135004821605e-06,
      "loss": 0.0001,
      "step": 109350
    },
    {
      "epoch": 11.71756134147648,
      "grad_norm": 7.085013930918649e-05,
      "learning_rate": 4.376584878031358e-06,
      "loss": 0.0,
      "step": 109360
    },
    {
      "epoch": 11.718632808314583,
      "grad_norm": 0.0005883857375010848,
      "learning_rate": 4.375156255580557e-06,
      "loss": 0.0,
      "step": 109370
    },
    {
      "epoch": 11.719704275152685,
      "grad_norm": 0.0002347773261135444,
      "learning_rate": 4.373727633129755e-06,
      "loss": 0.0,
      "step": 109380
    },
    {
      "epoch": 11.720775741990785,
      "grad_norm": 7.352702232310548e-05,
      "learning_rate": 4.372299010678953e-06,
      "loss": 0.0,
      "step": 109390
    },
    {
      "epoch": 11.721847208828887,
      "grad_norm": 0.0001566409191582352,
      "learning_rate": 4.370870388228151e-06,
      "loss": 0.0,
      "step": 109400
    },
    {
      "epoch": 11.722918675666989,
      "grad_norm": 6.980454054428264e-05,
      "learning_rate": 4.36944176577735e-06,
      "loss": 0.0012,
      "step": 109410
    },
    {
      "epoch": 11.72399014250509,
      "grad_norm": 0.08796194195747375,
      "learning_rate": 4.368013143326548e-06,
      "loss": 0.0001,
      "step": 109420
    },
    {
      "epoch": 11.725061609343191,
      "grad_norm": 0.0003622597432695329,
      "learning_rate": 4.366584520875746e-06,
      "loss": 0.0,
      "step": 109430
    },
    {
      "epoch": 11.726133076181291,
      "grad_norm": 7.236409146571532e-05,
      "learning_rate": 4.365155898424945e-06,
      "loss": 0.0,
      "step": 109440
    },
    {
      "epoch": 11.727204543019393,
      "grad_norm": 9.218318155035377e-05,
      "learning_rate": 4.363727275974142e-06,
      "loss": 0.1141,
      "step": 109450
    },
    {
      "epoch": 11.728276009857495,
      "grad_norm": 0.00015790725592523813,
      "learning_rate": 4.36229865352334e-06,
      "loss": 0.0,
      "step": 109460
    },
    {
      "epoch": 11.729347476695596,
      "grad_norm": 6.551559636136517e-05,
      "learning_rate": 4.3608700310725385e-06,
      "loss": 0.0004,
      "step": 109470
    },
    {
      "epoch": 11.730418943533698,
      "grad_norm": 0.0007164755370467901,
      "learning_rate": 4.359441408621737e-06,
      "loss": 0.0,
      "step": 109480
    },
    {
      "epoch": 11.7314904103718,
      "grad_norm": 0.03034830652177334,
      "learning_rate": 4.358012786170935e-06,
      "loss": 0.0,
      "step": 109490
    },
    {
      "epoch": 11.7325618772099,
      "grad_norm": 6.661401130259037e-05,
      "learning_rate": 4.356584163720133e-06,
      "loss": 0.0,
      "step": 109500
    },
    {
      "epoch": 11.733633344048002,
      "grad_norm": 0.00030764396069571376,
      "learning_rate": 4.355155541269332e-06,
      "loss": 0.0001,
      "step": 109510
    },
    {
      "epoch": 11.734704810886104,
      "grad_norm": 6.280937668634579e-05,
      "learning_rate": 4.353726918818529e-06,
      "loss": 0.0001,
      "step": 109520
    },
    {
      "epoch": 11.735776277724204,
      "grad_norm": 6.034906255081296e-05,
      "learning_rate": 4.352298296367728e-06,
      "loss": 0.2163,
      "step": 109530
    },
    {
      "epoch": 11.736847744562306,
      "grad_norm": 8.297268504975364e-05,
      "learning_rate": 4.350869673916926e-06,
      "loss": 0.0,
      "step": 109540
    },
    {
      "epoch": 11.737919211400406,
      "grad_norm": 6.906240741955116e-05,
      "learning_rate": 4.349441051466124e-06,
      "loss": 0.0,
      "step": 109550
    },
    {
      "epoch": 11.738990678238508,
      "grad_norm": 8.65450274432078e-05,
      "learning_rate": 4.348012429015323e-06,
      "loss": 0.0004,
      "step": 109560
    },
    {
      "epoch": 11.74006214507661,
      "grad_norm": 6.637600745307282e-05,
      "learning_rate": 4.34658380656452e-06,
      "loss": 0.0,
      "step": 109570
    },
    {
      "epoch": 11.74113361191471,
      "grad_norm": 7.687263860134408e-05,
      "learning_rate": 4.345155184113719e-06,
      "loss": 0.1405,
      "step": 109580
    },
    {
      "epoch": 11.742205078752812,
      "grad_norm": 0.00013023556675761938,
      "learning_rate": 4.343726561662917e-06,
      "loss": 0.0,
      "step": 109590
    },
    {
      "epoch": 11.743276545590914,
      "grad_norm": 0.0006646813708357513,
      "learning_rate": 4.342297939212115e-06,
      "loss": 0.0002,
      "step": 109600
    },
    {
      "epoch": 11.744348012429015,
      "grad_norm": 6.86649582348764e-05,
      "learning_rate": 4.340869316761313e-06,
      "loss": 0.0,
      "step": 109610
    },
    {
      "epoch": 11.745419479267117,
      "grad_norm": 0.00016753982345107943,
      "learning_rate": 4.339440694310512e-06,
      "loss": 0.0,
      "step": 109620
    },
    {
      "epoch": 11.746490946105219,
      "grad_norm": 0.499124675989151,
      "learning_rate": 4.33801207185971e-06,
      "loss": 0.0001,
      "step": 109630
    },
    {
      "epoch": 11.747562412943319,
      "grad_norm": 0.000236832260270603,
      "learning_rate": 4.336583449408907e-06,
      "loss": 0.0,
      "step": 109640
    },
    {
      "epoch": 11.748633879781421,
      "grad_norm": 0.0003220077487640083,
      "learning_rate": 4.335154826958106e-06,
      "loss": 0.1359,
      "step": 109650
    },
    {
      "epoch": 11.749705346619523,
      "grad_norm": 0.0013377758441492915,
      "learning_rate": 4.3337262045073044e-06,
      "loss": 0.0,
      "step": 109660
    },
    {
      "epoch": 11.750776813457623,
      "grad_norm": 0.00015297604841180146,
      "learning_rate": 4.332297582056502e-06,
      "loss": 0.0,
      "step": 109670
    },
    {
      "epoch": 11.751848280295725,
      "grad_norm": 6.73178001306951e-05,
      "learning_rate": 4.330868959605701e-06,
      "loss": 0.1535,
      "step": 109680
    },
    {
      "epoch": 11.752919747133827,
      "grad_norm": 9.111730469157919e-05,
      "learning_rate": 4.329440337154899e-06,
      "loss": 0.0,
      "step": 109690
    },
    {
      "epoch": 11.753991213971927,
      "grad_norm": 0.09909379482269287,
      "learning_rate": 4.328011714704097e-06,
      "loss": 0.0,
      "step": 109700
    },
    {
      "epoch": 11.75506268081003,
      "grad_norm": 0.0001715772523311898,
      "learning_rate": 4.326583092253295e-06,
      "loss": 0.081,
      "step": 109710
    },
    {
      "epoch": 11.75613414764813,
      "grad_norm": 0.00018904043827205896,
      "learning_rate": 4.325154469802493e-06,
      "loss": 0.0,
      "step": 109720
    },
    {
      "epoch": 11.757205614486232,
      "grad_norm": 0.00011867941066157073,
      "learning_rate": 4.3237258473516915e-06,
      "loss": 0.0,
      "step": 109730
    },
    {
      "epoch": 11.758277081324334,
      "grad_norm": 0.001565022161230445,
      "learning_rate": 4.32229722490089e-06,
      "loss": 0.0,
      "step": 109740
    },
    {
      "epoch": 11.759348548162434,
      "grad_norm": 0.00010935583850368857,
      "learning_rate": 4.320868602450088e-06,
      "loss": 0.0001,
      "step": 109750
    },
    {
      "epoch": 11.760420015000536,
      "grad_norm": 0.019690124318003654,
      "learning_rate": 4.319439979999286e-06,
      "loss": 0.0,
      "step": 109760
    },
    {
      "epoch": 11.761491481838638,
      "grad_norm": 0.00018975372950080782,
      "learning_rate": 4.318011357548485e-06,
      "loss": 0.0008,
      "step": 109770
    },
    {
      "epoch": 11.762562948676738,
      "grad_norm": 7.308696513064206e-05,
      "learning_rate": 4.3165827350976824e-06,
      "loss": 0.0,
      "step": 109780
    },
    {
      "epoch": 11.76363441551484,
      "grad_norm": 0.00015757183427922428,
      "learning_rate": 4.31515411264688e-06,
      "loss": 0.0,
      "step": 109790
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 0.0002038664824794978,
      "learning_rate": 4.313725490196079e-06,
      "loss": 0.0,
      "step": 109800
    },
    {
      "epoch": 11.765777349191042,
      "grad_norm": 6.396540265996009e-05,
      "learning_rate": 4.312296867745277e-06,
      "loss": 0.0,
      "step": 109810
    },
    {
      "epoch": 11.766848816029144,
      "grad_norm": 9.400914132129401e-05,
      "learning_rate": 4.310868245294475e-06,
      "loss": 0.0009,
      "step": 109820
    },
    {
      "epoch": 11.767920282867244,
      "grad_norm": 6.189232954056934e-05,
      "learning_rate": 4.309439622843673e-06,
      "loss": 0.0,
      "step": 109830
    },
    {
      "epoch": 11.768991749705346,
      "grad_norm": 0.00013710101484321058,
      "learning_rate": 4.308011000392872e-06,
      "loss": 0.0,
      "step": 109840
    },
    {
      "epoch": 11.770063216543448,
      "grad_norm": 7.261132850544527e-05,
      "learning_rate": 4.3065823779420695e-06,
      "loss": 0.0001,
      "step": 109850
    },
    {
      "epoch": 11.771134683381549,
      "grad_norm": 6.379877595463768e-05,
      "learning_rate": 4.305153755491268e-06,
      "loss": 0.0,
      "step": 109860
    },
    {
      "epoch": 11.77220615021965,
      "grad_norm": 0.00014046915748622268,
      "learning_rate": 4.303725133040466e-06,
      "loss": 0.0,
      "step": 109870
    },
    {
      "epoch": 11.773277617057753,
      "grad_norm": 5.955435335636139e-05,
      "learning_rate": 4.302296510589664e-06,
      "loss": 0.0,
      "step": 109880
    },
    {
      "epoch": 11.774349083895853,
      "grad_norm": 6.372497591655701e-05,
      "learning_rate": 4.300867888138863e-06,
      "loss": 0.0,
      "step": 109890
    },
    {
      "epoch": 11.775420550733955,
      "grad_norm": 0.0013402424519881606,
      "learning_rate": 4.2994392656880604e-06,
      "loss": 0.0001,
      "step": 109900
    },
    {
      "epoch": 11.776492017572057,
      "grad_norm": 6.339800165733323e-05,
      "learning_rate": 4.298010643237259e-06,
      "loss": 0.0,
      "step": 109910
    },
    {
      "epoch": 11.777563484410157,
      "grad_norm": 6.577903695870191e-05,
      "learning_rate": 4.2965820207864575e-06,
      "loss": 0.0014,
      "step": 109920
    },
    {
      "epoch": 11.778634951248259,
      "grad_norm": 6.0482714616227895e-05,
      "learning_rate": 4.295153398335655e-06,
      "loss": 0.0,
      "step": 109930
    },
    {
      "epoch": 11.77970641808636,
      "grad_norm": 6.441164441639557e-05,
      "learning_rate": 4.293724775884854e-06,
      "loss": 0.0,
      "step": 109940
    },
    {
      "epoch": 11.780777884924461,
      "grad_norm": 5.7367309636902064e-05,
      "learning_rate": 4.292296153434052e-06,
      "loss": 0.0,
      "step": 109950
    },
    {
      "epoch": 11.781849351762563,
      "grad_norm": 6.598544132430106e-05,
      "learning_rate": 4.29086753098325e-06,
      "loss": 0.0005,
      "step": 109960
    },
    {
      "epoch": 11.782920818600664,
      "grad_norm": 6.763363489881158e-05,
      "learning_rate": 4.2894389085324475e-06,
      "loss": 0.0,
      "step": 109970
    },
    {
      "epoch": 11.783992285438766,
      "grad_norm": 0.0001681388239376247,
      "learning_rate": 4.288010286081646e-06,
      "loss": 0.2853,
      "step": 109980
    },
    {
      "epoch": 11.785063752276868,
      "grad_norm": 0.00017997373652178794,
      "learning_rate": 4.2865816636308446e-06,
      "loss": 0.0,
      "step": 109990
    },
    {
      "epoch": 11.786135219114968,
      "grad_norm": 0.0036147194914519787,
      "learning_rate": 4.285153041180042e-06,
      "loss": 0.0,
      "step": 110000
    },
    {
      "epoch": 11.78720668595307,
      "grad_norm": 7.739330612821504e-05,
      "learning_rate": 4.283724418729241e-06,
      "loss": 0.0,
      "step": 110010
    },
    {
      "epoch": 11.788278152791172,
      "grad_norm": 0.06329093873500824,
      "learning_rate": 4.282295796278439e-06,
      "loss": 0.1213,
      "step": 110020
    },
    {
      "epoch": 11.789349619629272,
      "grad_norm": 0.00013460489572025836,
      "learning_rate": 4.280867173827637e-06,
      "loss": 0.0003,
      "step": 110030
    },
    {
      "epoch": 11.790421086467374,
      "grad_norm": 8.282860653707758e-05,
      "learning_rate": 4.2794385513768355e-06,
      "loss": 0.0,
      "step": 110040
    },
    {
      "epoch": 11.791492553305476,
      "grad_norm": 8.284192153951153e-05,
      "learning_rate": 4.278009928926033e-06,
      "loss": 0.0,
      "step": 110050
    },
    {
      "epoch": 11.792564020143576,
      "grad_norm": 6.937142461538315e-05,
      "learning_rate": 4.276581306475232e-06,
      "loss": 0.0,
      "step": 110060
    },
    {
      "epoch": 11.793635486981678,
      "grad_norm": 6.587515235878527e-05,
      "learning_rate": 4.27515268402443e-06,
      "loss": 0.0001,
      "step": 110070
    },
    {
      "epoch": 11.79470695381978,
      "grad_norm": 7.484001980628818e-05,
      "learning_rate": 4.273724061573628e-06,
      "loss": 0.0,
      "step": 110080
    },
    {
      "epoch": 11.79577842065788,
      "grad_norm": 0.0705319419503212,
      "learning_rate": 4.272295439122826e-06,
      "loss": 0.1283,
      "step": 110090
    },
    {
      "epoch": 11.796849887495982,
      "grad_norm": 7.723524322500452e-05,
      "learning_rate": 4.270866816672024e-06,
      "loss": 0.0,
      "step": 110100
    },
    {
      "epoch": 11.797921354334083,
      "grad_norm": 7.291017391253263e-05,
      "learning_rate": 4.2694381942212226e-06,
      "loss": 0.0,
      "step": 110110
    },
    {
      "epoch": 11.798992821172185,
      "grad_norm": 6.734774797223508e-05,
      "learning_rate": 4.26800957177042e-06,
      "loss": 0.0,
      "step": 110120
    },
    {
      "epoch": 11.800064288010287,
      "grad_norm": 0.0003511582617647946,
      "learning_rate": 4.266580949319619e-06,
      "loss": 0.0,
      "step": 110130
    },
    {
      "epoch": 11.801135754848387,
      "grad_norm": 0.0032240930013358593,
      "learning_rate": 4.265152326868817e-06,
      "loss": 0.0,
      "step": 110140
    },
    {
      "epoch": 11.802207221686489,
      "grad_norm": 6.594781734747812e-05,
      "learning_rate": 4.263723704418015e-06,
      "loss": 0.0,
      "step": 110150
    },
    {
      "epoch": 11.80327868852459,
      "grad_norm": 6.41099686617963e-05,
      "learning_rate": 4.2622950819672135e-06,
      "loss": 0.0004,
      "step": 110160
    },
    {
      "epoch": 11.804350155362691,
      "grad_norm": 6.308581214398146e-05,
      "learning_rate": 4.260866459516412e-06,
      "loss": 0.0,
      "step": 110170
    },
    {
      "epoch": 11.805421622200793,
      "grad_norm": 0.0003026013437192887,
      "learning_rate": 4.25943783706561e-06,
      "loss": 0.0,
      "step": 110180
    },
    {
      "epoch": 11.806493089038895,
      "grad_norm": 6.700461381115019e-05,
      "learning_rate": 4.258009214614808e-06,
      "loss": 0.0,
      "step": 110190
    },
    {
      "epoch": 11.807564555876995,
      "grad_norm": 0.00013374914124142379,
      "learning_rate": 4.256580592164007e-06,
      "loss": 0.0,
      "step": 110200
    },
    {
      "epoch": 11.808636022715097,
      "grad_norm": 0.00013727454643230885,
      "learning_rate": 4.255151969713204e-06,
      "loss": 0.0025,
      "step": 110210
    },
    {
      "epoch": 11.809707489553197,
      "grad_norm": 0.05842777341604233,
      "learning_rate": 4.253723347262402e-06,
      "loss": 0.0,
      "step": 110220
    },
    {
      "epoch": 11.8107789563913,
      "grad_norm": 6.446114275604486e-05,
      "learning_rate": 4.2522947248116006e-06,
      "loss": 0.0,
      "step": 110230
    },
    {
      "epoch": 11.811850423229401,
      "grad_norm": 0.00014585208555217832,
      "learning_rate": 4.250866102360799e-06,
      "loss": 0.0,
      "step": 110240
    },
    {
      "epoch": 11.812921890067502,
      "grad_norm": 7.74113941588439e-05,
      "learning_rate": 4.249437479909997e-06,
      "loss": 0.0025,
      "step": 110250
    },
    {
      "epoch": 11.813993356905604,
      "grad_norm": 0.004691522568464279,
      "learning_rate": 4.248008857459195e-06,
      "loss": 0.0001,
      "step": 110260
    },
    {
      "epoch": 11.815064823743706,
      "grad_norm": 0.00024753910838626325,
      "learning_rate": 4.246580235008394e-06,
      "loss": 0.0003,
      "step": 110270
    },
    {
      "epoch": 11.816136290581806,
      "grad_norm": 0.00013790049706585705,
      "learning_rate": 4.2451516125575915e-06,
      "loss": 0.0,
      "step": 110280
    },
    {
      "epoch": 11.817207757419908,
      "grad_norm": 6.594587466679513e-05,
      "learning_rate": 4.24372299010679e-06,
      "loss": 0.0,
      "step": 110290
    },
    {
      "epoch": 11.81827922425801,
      "grad_norm": 0.0002153882960556075,
      "learning_rate": 4.242294367655988e-06,
      "loss": 0.0,
      "step": 110300
    },
    {
      "epoch": 11.81935069109611,
      "grad_norm": 6.322970875771716e-05,
      "learning_rate": 4.240865745205186e-06,
      "loss": 0.0,
      "step": 110310
    },
    {
      "epoch": 11.820422157934212,
      "grad_norm": 0.00012952213000971824,
      "learning_rate": 4.239437122754385e-06,
      "loss": 0.0,
      "step": 110320
    },
    {
      "epoch": 11.821493624772312,
      "grad_norm": 0.014584633521735668,
      "learning_rate": 4.238008500303582e-06,
      "loss": 0.0021,
      "step": 110330
    },
    {
      "epoch": 11.822565091610414,
      "grad_norm": 7.69880207371898e-05,
      "learning_rate": 4.236579877852781e-06,
      "loss": 0.0,
      "step": 110340
    },
    {
      "epoch": 11.823636558448516,
      "grad_norm": 0.008781366981565952,
      "learning_rate": 4.235151255401979e-06,
      "loss": 0.0,
      "step": 110350
    },
    {
      "epoch": 11.824708025286617,
      "grad_norm": 0.00012076971324859187,
      "learning_rate": 4.233722632951177e-06,
      "loss": 0.0,
      "step": 110360
    },
    {
      "epoch": 11.825779492124719,
      "grad_norm": 0.00012720863742288202,
      "learning_rate": 4.232294010500375e-06,
      "loss": 0.0,
      "step": 110370
    },
    {
      "epoch": 11.82685095896282,
      "grad_norm": 0.00013005030632484704,
      "learning_rate": 4.230865388049574e-06,
      "loss": 0.0,
      "step": 110380
    },
    {
      "epoch": 11.82792242580092,
      "grad_norm": 0.0001413098070770502,
      "learning_rate": 4.229436765598772e-06,
      "loss": 0.1388,
      "step": 110390
    },
    {
      "epoch": 11.828993892639023,
      "grad_norm": 6.601150380447507e-05,
      "learning_rate": 4.2280081431479695e-06,
      "loss": 0.0,
      "step": 110400
    },
    {
      "epoch": 11.830065359477125,
      "grad_norm": 0.0001409264950780198,
      "learning_rate": 4.226579520697168e-06,
      "loss": 0.0001,
      "step": 110410
    },
    {
      "epoch": 11.831136826315225,
      "grad_norm": 6.704967381665483e-05,
      "learning_rate": 4.2251508982463665e-06,
      "loss": 0.0,
      "step": 110420
    },
    {
      "epoch": 11.832208293153327,
      "grad_norm": 0.00628188531845808,
      "learning_rate": 4.223722275795564e-06,
      "loss": 0.0,
      "step": 110430
    },
    {
      "epoch": 11.833279759991429,
      "grad_norm": 0.00013198792294133455,
      "learning_rate": 4.222293653344763e-06,
      "loss": 0.0,
      "step": 110440
    },
    {
      "epoch": 11.83435122682953,
      "grad_norm": 7.055559399304911e-05,
      "learning_rate": 4.220865030893961e-06,
      "loss": 0.0,
      "step": 110450
    },
    {
      "epoch": 11.835422693667631,
      "grad_norm": 6.446537736337632e-05,
      "learning_rate": 4.219436408443159e-06,
      "loss": 0.0,
      "step": 110460
    },
    {
      "epoch": 11.836494160505733,
      "grad_norm": 0.006070893723517656,
      "learning_rate": 4.218007785992357e-06,
      "loss": 0.0,
      "step": 110470
    },
    {
      "epoch": 11.837565627343833,
      "grad_norm": 6.223734089871868e-05,
      "learning_rate": 4.216579163541555e-06,
      "loss": 0.0,
      "step": 110480
    },
    {
      "epoch": 11.838637094181935,
      "grad_norm": 0.00011704720964189619,
      "learning_rate": 4.215150541090754e-06,
      "loss": 0.0,
      "step": 110490
    },
    {
      "epoch": 11.839708561020036,
      "grad_norm": 0.00013016225420869887,
      "learning_rate": 4.213721918639952e-06,
      "loss": 0.0,
      "step": 110500
    },
    {
      "epoch": 11.840780027858138,
      "grad_norm": 6.539306923514232e-05,
      "learning_rate": 4.21229329618915e-06,
      "loss": 0.0,
      "step": 110510
    },
    {
      "epoch": 11.84185149469624,
      "grad_norm": 6.066839341656305e-05,
      "learning_rate": 4.210864673738348e-06,
      "loss": 0.1978,
      "step": 110520
    },
    {
      "epoch": 11.84292296153434,
      "grad_norm": 6.211083382368088e-05,
      "learning_rate": 4.209436051287547e-06,
      "loss": 0.0,
      "step": 110530
    },
    {
      "epoch": 11.843994428372442,
      "grad_norm": 6.433518865378574e-05,
      "learning_rate": 4.2080074288367445e-06,
      "loss": 0.0,
      "step": 110540
    },
    {
      "epoch": 11.845065895210544,
      "grad_norm": 8.01666101324372e-05,
      "learning_rate": 4.206578806385942e-06,
      "loss": 0.0,
      "step": 110550
    },
    {
      "epoch": 11.846137362048644,
      "grad_norm": 6.273225153563544e-05,
      "learning_rate": 4.205150183935141e-06,
      "loss": 0.0,
      "step": 110560
    },
    {
      "epoch": 11.847208828886746,
      "grad_norm": 6.643616507062688e-05,
      "learning_rate": 4.203721561484339e-06,
      "loss": 0.0,
      "step": 110570
    },
    {
      "epoch": 11.848280295724848,
      "grad_norm": 0.0009600701159797609,
      "learning_rate": 4.202292939033537e-06,
      "loss": 0.0,
      "step": 110580
    },
    {
      "epoch": 11.849351762562948,
      "grad_norm": 6.950693932594731e-05,
      "learning_rate": 4.200864316582735e-06,
      "loss": 0.0,
      "step": 110590
    },
    {
      "epoch": 11.85042322940105,
      "grad_norm": 0.00010132395254913718,
      "learning_rate": 4.199435694131934e-06,
      "loss": 0.0,
      "step": 110600
    },
    {
      "epoch": 11.85149469623915,
      "grad_norm": 6.430190114770085e-05,
      "learning_rate": 4.198007071681132e-06,
      "loss": 0.0,
      "step": 110610
    },
    {
      "epoch": 11.852566163077253,
      "grad_norm": 0.0012962175533175468,
      "learning_rate": 4.19657844923033e-06,
      "loss": 0.0505,
      "step": 110620
    },
    {
      "epoch": 11.853637629915355,
      "grad_norm": 6.788923928979784e-05,
      "learning_rate": 4.195149826779528e-06,
      "loss": 0.0,
      "step": 110630
    },
    {
      "epoch": 11.854709096753455,
      "grad_norm": 0.0004873522266279906,
      "learning_rate": 4.193721204328726e-06,
      "loss": 0.0,
      "step": 110640
    },
    {
      "epoch": 11.855780563591557,
      "grad_norm": 6.248407589737326e-05,
      "learning_rate": 4.192292581877925e-06,
      "loss": 0.0,
      "step": 110650
    },
    {
      "epoch": 11.856852030429659,
      "grad_norm": 6.800278060836717e-05,
      "learning_rate": 4.1908639594271225e-06,
      "loss": 0.0,
      "step": 110660
    },
    {
      "epoch": 11.857923497267759,
      "grad_norm": 6.189981650095433e-05,
      "learning_rate": 4.189435336976321e-06,
      "loss": 0.0,
      "step": 110670
    },
    {
      "epoch": 11.858994964105861,
      "grad_norm": 6.800944538554177e-05,
      "learning_rate": 4.1880067145255195e-06,
      "loss": 0.0,
      "step": 110680
    },
    {
      "epoch": 11.860066430943963,
      "grad_norm": 0.001469959388487041,
      "learning_rate": 4.186578092074717e-06,
      "loss": 0.0,
      "step": 110690
    },
    {
      "epoch": 11.861137897782063,
      "grad_norm": 0.00017737223242875189,
      "learning_rate": 4.185149469623916e-06,
      "loss": 0.0,
      "step": 110700
    },
    {
      "epoch": 11.862209364620165,
      "grad_norm": 6.445133476518095e-05,
      "learning_rate": 4.183720847173114e-06,
      "loss": 0.0,
      "step": 110710
    },
    {
      "epoch": 11.863280831458267,
      "grad_norm": 6.477687566075474e-05,
      "learning_rate": 4.182292224722312e-06,
      "loss": 0.0011,
      "step": 110720
    },
    {
      "epoch": 11.864352298296367,
      "grad_norm": 0.004331606440246105,
      "learning_rate": 4.18086360227151e-06,
      "loss": 0.0,
      "step": 110730
    },
    {
      "epoch": 11.86542376513447,
      "grad_norm": 0.00015538463776465505,
      "learning_rate": 4.179434979820708e-06,
      "loss": 0.0,
      "step": 110740
    },
    {
      "epoch": 11.866495231972571,
      "grad_norm": 6.807418685639277e-05,
      "learning_rate": 4.178006357369907e-06,
      "loss": 0.0,
      "step": 110750
    },
    {
      "epoch": 11.867566698810672,
      "grad_norm": 0.00022621997050009668,
      "learning_rate": 4.176577734919104e-06,
      "loss": 0.0,
      "step": 110760
    },
    {
      "epoch": 11.868638165648774,
      "grad_norm": 0.00015199242625385523,
      "learning_rate": 4.175149112468303e-06,
      "loss": 0.0002,
      "step": 110770
    },
    {
      "epoch": 11.869709632486874,
      "grad_norm": 0.0001356642897007987,
      "learning_rate": 4.173720490017501e-06,
      "loss": 0.0,
      "step": 110780
    },
    {
      "epoch": 11.870781099324976,
      "grad_norm": 0.0001240384008269757,
      "learning_rate": 4.172291867566699e-06,
      "loss": 0.0,
      "step": 110790
    },
    {
      "epoch": 11.871852566163078,
      "grad_norm": 6.112609116826206e-05,
      "learning_rate": 4.1708632451158975e-06,
      "loss": 0.0,
      "step": 110800
    },
    {
      "epoch": 11.872924033001178,
      "grad_norm": 0.0019739563576877117,
      "learning_rate": 4.169434622665095e-06,
      "loss": 0.0,
      "step": 110810
    },
    {
      "epoch": 11.87399549983928,
      "grad_norm": 0.0001343967451248318,
      "learning_rate": 4.168006000214294e-06,
      "loss": 0.0,
      "step": 110820
    },
    {
      "epoch": 11.875066966677382,
      "grad_norm": 0.0009119726601056755,
      "learning_rate": 4.166577377763492e-06,
      "loss": 0.0,
      "step": 110830
    },
    {
      "epoch": 11.876138433515482,
      "grad_norm": 6.090729948482476e-05,
      "learning_rate": 4.16514875531269e-06,
      "loss": 0.0,
      "step": 110840
    },
    {
      "epoch": 11.877209900353584,
      "grad_norm": 6.477707211161032e-05,
      "learning_rate": 4.1637201328618884e-06,
      "loss": 0.0004,
      "step": 110850
    },
    {
      "epoch": 11.878281367191686,
      "grad_norm": 7.166878640418872e-05,
      "learning_rate": 4.162291510411087e-06,
      "loss": 0.0,
      "step": 110860
    },
    {
      "epoch": 11.879352834029786,
      "grad_norm": 6.144453072920442e-05,
      "learning_rate": 4.160862887960285e-06,
      "loss": 0.0,
      "step": 110870
    },
    {
      "epoch": 11.880424300867888,
      "grad_norm": 0.00019476190209388733,
      "learning_rate": 4.159434265509482e-06,
      "loss": 0.0,
      "step": 110880
    },
    {
      "epoch": 11.881495767705989,
      "grad_norm": 0.0002844708214979619,
      "learning_rate": 4.158005643058682e-06,
      "loss": 0.0,
      "step": 110890
    },
    {
      "epoch": 11.88256723454409,
      "grad_norm": 5.999592394800857e-05,
      "learning_rate": 4.156577020607879e-06,
      "loss": 0.0,
      "step": 110900
    },
    {
      "epoch": 11.883638701382193,
      "grad_norm": 0.00011347309191478416,
      "learning_rate": 4.155148398157077e-06,
      "loss": 0.0,
      "step": 110910
    },
    {
      "epoch": 11.884710168220293,
      "grad_norm": 0.00016229574976023287,
      "learning_rate": 4.1537197757062755e-06,
      "loss": 0.2655,
      "step": 110920
    },
    {
      "epoch": 11.885781635058395,
      "grad_norm": 6.033998943166807e-05,
      "learning_rate": 4.152291153255474e-06,
      "loss": 0.0588,
      "step": 110930
    },
    {
      "epoch": 11.886853101896497,
      "grad_norm": 6.583869981113821e-05,
      "learning_rate": 4.150862530804672e-06,
      "loss": 0.0733,
      "step": 110940
    },
    {
      "epoch": 11.887924568734597,
      "grad_norm": 7.13175322744064e-05,
      "learning_rate": 4.14943390835387e-06,
      "loss": 0.0,
      "step": 110950
    },
    {
      "epoch": 11.8889960355727,
      "grad_norm": 6.111499533290043e-05,
      "learning_rate": 4.148005285903069e-06,
      "loss": 0.0,
      "step": 110960
    },
    {
      "epoch": 11.890067502410801,
      "grad_norm": 0.0004607133159879595,
      "learning_rate": 4.1465766634522664e-06,
      "loss": 0.0,
      "step": 110970
    },
    {
      "epoch": 11.891138969248901,
      "grad_norm": 0.00018583633936941624,
      "learning_rate": 4.145148041001465e-06,
      "loss": 0.0,
      "step": 110980
    },
    {
      "epoch": 11.892210436087003,
      "grad_norm": 6.139658944448456e-05,
      "learning_rate": 4.143719418550663e-06,
      "loss": 0.0001,
      "step": 110990
    },
    {
      "epoch": 11.893281902925104,
      "grad_norm": 5.8457644627196714e-05,
      "learning_rate": 4.142290796099861e-06,
      "loss": 0.0,
      "step": 111000
    },
    {
      "epoch": 11.894353369763206,
      "grad_norm": 0.0002705010410863906,
      "learning_rate": 4.140862173649059e-06,
      "loss": 0.0,
      "step": 111010
    },
    {
      "epoch": 11.895424836601308,
      "grad_norm": 0.00015684362733736634,
      "learning_rate": 4.139433551198257e-06,
      "loss": 0.0164,
      "step": 111020
    },
    {
      "epoch": 11.896496303439408,
      "grad_norm": 6.0432590544223785e-05,
      "learning_rate": 4.138004928747456e-06,
      "loss": 0.0,
      "step": 111030
    },
    {
      "epoch": 11.89756777027751,
      "grad_norm": 5.747680552303791e-05,
      "learning_rate": 4.1365763062966535e-06,
      "loss": 0.0,
      "step": 111040
    },
    {
      "epoch": 11.898639237115612,
      "grad_norm": 0.0005296192248351872,
      "learning_rate": 4.135147683845852e-06,
      "loss": 0.0,
      "step": 111050
    },
    {
      "epoch": 11.899710703953712,
      "grad_norm": 5.942290590610355e-05,
      "learning_rate": 4.13371906139505e-06,
      "loss": 0.0,
      "step": 111060
    },
    {
      "epoch": 11.900782170791814,
      "grad_norm": 0.0002514515654183924,
      "learning_rate": 4.132290438944248e-06,
      "loss": 0.0,
      "step": 111070
    },
    {
      "epoch": 11.901853637629916,
      "grad_norm": 6.789842882426456e-05,
      "learning_rate": 4.130861816493447e-06,
      "loss": 0.3517,
      "step": 111080
    },
    {
      "epoch": 11.902925104468016,
      "grad_norm": 6.590255361516029e-05,
      "learning_rate": 4.1294331940426444e-06,
      "loss": 0.0001,
      "step": 111090
    },
    {
      "epoch": 11.903996571306118,
      "grad_norm": 0.0007374986889772117,
      "learning_rate": 4.128004571591843e-06,
      "loss": 0.0,
      "step": 111100
    },
    {
      "epoch": 11.90506803814422,
      "grad_norm": 0.0010386321227997541,
      "learning_rate": 4.1265759491410415e-06,
      "loss": 0.0,
      "step": 111110
    },
    {
      "epoch": 11.90613950498232,
      "grad_norm": 6.298490188783035e-05,
      "learning_rate": 4.125147326690239e-06,
      "loss": 0.0004,
      "step": 111120
    },
    {
      "epoch": 11.907210971820422,
      "grad_norm": 6.35971809970215e-05,
      "learning_rate": 4.123718704239437e-06,
      "loss": 0.0,
      "step": 111130
    },
    {
      "epoch": 11.908282438658524,
      "grad_norm": 0.0003233339812140912,
      "learning_rate": 4.122290081788635e-06,
      "loss": 0.0,
      "step": 111140
    },
    {
      "epoch": 11.909353905496625,
      "grad_norm": 0.0010137525387108326,
      "learning_rate": 4.120861459337834e-06,
      "loss": 0.0,
      "step": 111150
    },
    {
      "epoch": 11.910425372334727,
      "grad_norm": 0.0005549067864194512,
      "learning_rate": 4.1194328368870315e-06,
      "loss": 0.1697,
      "step": 111160
    },
    {
      "epoch": 11.911496839172827,
      "grad_norm": 6.406586908269674e-05,
      "learning_rate": 4.11800421443623e-06,
      "loss": 0.0,
      "step": 111170
    },
    {
      "epoch": 11.912568306010929,
      "grad_norm": 6.594830483663827e-05,
      "learning_rate": 4.1165755919854286e-06,
      "loss": 0.0,
      "step": 111180
    },
    {
      "epoch": 11.91363977284903,
      "grad_norm": 0.00026783772045746446,
      "learning_rate": 4.115146969534626e-06,
      "loss": 0.0,
      "step": 111190
    },
    {
      "epoch": 11.914711239687131,
      "grad_norm": 0.0002465545549057424,
      "learning_rate": 4.113718347083825e-06,
      "loss": 0.0,
      "step": 111200
    },
    {
      "epoch": 11.915782706525233,
      "grad_norm": 0.00036660052137449384,
      "learning_rate": 4.112289724633023e-06,
      "loss": 0.0,
      "step": 111210
    },
    {
      "epoch": 11.916854173363335,
      "grad_norm": 5.976962347631343e-05,
      "learning_rate": 4.110861102182221e-06,
      "loss": 0.0011,
      "step": 111220
    },
    {
      "epoch": 11.917925640201435,
      "grad_norm": 6.027408016961999e-05,
      "learning_rate": 4.1094324797314195e-06,
      "loss": 0.0,
      "step": 111230
    },
    {
      "epoch": 11.918997107039537,
      "grad_norm": 6.38134588371031e-05,
      "learning_rate": 4.108003857280617e-06,
      "loss": 0.0,
      "step": 111240
    },
    {
      "epoch": 11.92006857387764,
      "grad_norm": 6.461817974923179e-05,
      "learning_rate": 4.106575234829816e-06,
      "loss": 0.0,
      "step": 111250
    },
    {
      "epoch": 11.92114004071574,
      "grad_norm": 5.780515857622959e-05,
      "learning_rate": 4.105146612379014e-06,
      "loss": 0.0,
      "step": 111260
    },
    {
      "epoch": 11.922211507553842,
      "grad_norm": 6.266685522859916e-05,
      "learning_rate": 4.103717989928212e-06,
      "loss": 0.0,
      "step": 111270
    },
    {
      "epoch": 11.923282974391942,
      "grad_norm": 6.191701686475426e-05,
      "learning_rate": 4.10228936747741e-06,
      "loss": 0.0,
      "step": 111280
    },
    {
      "epoch": 11.924354441230044,
      "grad_norm": 6.229045538930222e-05,
      "learning_rate": 4.100860745026609e-06,
      "loss": 0.0,
      "step": 111290
    },
    {
      "epoch": 11.925425908068146,
      "grad_norm": 6.55160765745677e-05,
      "learning_rate": 4.0994321225758066e-06,
      "loss": 0.0,
      "step": 111300
    },
    {
      "epoch": 11.926497374906246,
      "grad_norm": 6.156179733807221e-05,
      "learning_rate": 4.098003500125004e-06,
      "loss": 0.0,
      "step": 111310
    },
    {
      "epoch": 11.927568841744348,
      "grad_norm": 6.800262053729966e-05,
      "learning_rate": 4.096574877674203e-06,
      "loss": 0.0,
      "step": 111320
    },
    {
      "epoch": 11.92864030858245,
      "grad_norm": 8.736106246942654e-05,
      "learning_rate": 4.095146255223401e-06,
      "loss": 0.0,
      "step": 111330
    },
    {
      "epoch": 11.92971177542055,
      "grad_norm": 0.0005427580326795578,
      "learning_rate": 4.093717632772599e-06,
      "loss": 0.0001,
      "step": 111340
    },
    {
      "epoch": 11.930783242258652,
      "grad_norm": 0.00020568656327668577,
      "learning_rate": 4.0922890103217975e-06,
      "loss": 0.0994,
      "step": 111350
    },
    {
      "epoch": 11.931854709096754,
      "grad_norm": 0.0007318425923585892,
      "learning_rate": 4.090860387870996e-06,
      "loss": 0.0,
      "step": 111360
    },
    {
      "epoch": 11.932926175934854,
      "grad_norm": 6.587633106391877e-05,
      "learning_rate": 4.089431765420194e-06,
      "loss": 0.0001,
      "step": 111370
    },
    {
      "epoch": 11.933997642772956,
      "grad_norm": 5.887784209335223e-05,
      "learning_rate": 4.088003142969392e-06,
      "loss": 0.0,
      "step": 111380
    },
    {
      "epoch": 11.935069109611057,
      "grad_norm": 0.00023111741757020354,
      "learning_rate": 4.08657452051859e-06,
      "loss": 0.3984,
      "step": 111390
    },
    {
      "epoch": 11.936140576449159,
      "grad_norm": 7.809855014784262e-05,
      "learning_rate": 4.085145898067788e-06,
      "loss": 0.1904,
      "step": 111400
    },
    {
      "epoch": 11.93721204328726,
      "grad_norm": 0.0109374038875103,
      "learning_rate": 4.083717275616987e-06,
      "loss": 0.0001,
      "step": 111410
    },
    {
      "epoch": 11.93828351012536,
      "grad_norm": 7.345368067035452e-05,
      "learning_rate": 4.0822886531661846e-06,
      "loss": 0.0,
      "step": 111420
    },
    {
      "epoch": 11.939354976963463,
      "grad_norm": 0.0002827609714586288,
      "learning_rate": 4.080860030715383e-06,
      "loss": 0.0,
      "step": 111430
    },
    {
      "epoch": 11.940426443801565,
      "grad_norm": 8.167151099769399e-05,
      "learning_rate": 4.079431408264582e-06,
      "loss": 0.0,
      "step": 111440
    },
    {
      "epoch": 11.941497910639665,
      "grad_norm": 6.833748193457723e-05,
      "learning_rate": 4.078002785813779e-06,
      "loss": 0.0,
      "step": 111450
    },
    {
      "epoch": 11.942569377477767,
      "grad_norm": 7.74649452068843e-05,
      "learning_rate": 4.076574163362978e-06,
      "loss": 0.0,
      "step": 111460
    },
    {
      "epoch": 11.943640844315869,
      "grad_norm": 9.0786736109294e-05,
      "learning_rate": 4.075145540912176e-06,
      "loss": 0.0,
      "step": 111470
    },
    {
      "epoch": 11.94471231115397,
      "grad_norm": 0.0001215359297930263,
      "learning_rate": 4.073716918461374e-06,
      "loss": 0.1681,
      "step": 111480
    },
    {
      "epoch": 11.945783777992071,
      "grad_norm": 8.544557204004377e-05,
      "learning_rate": 4.072288296010572e-06,
      "loss": 0.0,
      "step": 111490
    },
    {
      "epoch": 11.946855244830173,
      "grad_norm": 7.086619734764099e-05,
      "learning_rate": 4.07085967355977e-06,
      "loss": 0.0002,
      "step": 111500
    },
    {
      "epoch": 11.947926711668273,
      "grad_norm": 0.0023562987335026264,
      "learning_rate": 4.069431051108969e-06,
      "loss": 0.2137,
      "step": 111510
    },
    {
      "epoch": 11.948998178506375,
      "grad_norm": 8.692683331901208e-05,
      "learning_rate": 4.068002428658166e-06,
      "loss": 0.0,
      "step": 111520
    },
    {
      "epoch": 11.950069645344477,
      "grad_norm": 7.972961611812934e-05,
      "learning_rate": 4.066573806207365e-06,
      "loss": 0.0002,
      "step": 111530
    },
    {
      "epoch": 11.951141112182578,
      "grad_norm": 0.044291842728853226,
      "learning_rate": 4.065145183756563e-06,
      "loss": 0.0,
      "step": 111540
    },
    {
      "epoch": 11.95221257902068,
      "grad_norm": 7.12855689926073e-05,
      "learning_rate": 4.063716561305761e-06,
      "loss": 0.0,
      "step": 111550
    },
    {
      "epoch": 11.95328404585878,
      "grad_norm": 0.0007984215626493096,
      "learning_rate": 4.06228793885496e-06,
      "loss": 0.0001,
      "step": 111560
    },
    {
      "epoch": 11.954355512696882,
      "grad_norm": 7.948558777570724e-05,
      "learning_rate": 4.060859316404157e-06,
      "loss": 0.2074,
      "step": 111570
    },
    {
      "epoch": 11.955426979534984,
      "grad_norm": 7.649337203474715e-05,
      "learning_rate": 4.059430693953356e-06,
      "loss": 0.0,
      "step": 111580
    },
    {
      "epoch": 11.956498446373084,
      "grad_norm": 0.0024642390199005604,
      "learning_rate": 4.058002071502554e-06,
      "loss": 0.0002,
      "step": 111590
    },
    {
      "epoch": 11.957569913211186,
      "grad_norm": 7.206836016848683e-05,
      "learning_rate": 4.056573449051752e-06,
      "loss": 0.0006,
      "step": 111600
    },
    {
      "epoch": 11.958641380049288,
      "grad_norm": 0.010411991737782955,
      "learning_rate": 4.0551448266009505e-06,
      "loss": 0.0012,
      "step": 111610
    },
    {
      "epoch": 11.959712846887388,
      "grad_norm": 0.00010627424489939585,
      "learning_rate": 4.053716204150149e-06,
      "loss": 0.0001,
      "step": 111620
    },
    {
      "epoch": 11.96078431372549,
      "grad_norm": 0.00030226362287066877,
      "learning_rate": 4.052287581699347e-06,
      "loss": 0.0,
      "step": 111630
    },
    {
      "epoch": 11.961855780563592,
      "grad_norm": 0.0002617119171191007,
      "learning_rate": 4.050858959248544e-06,
      "loss": 0.1305,
      "step": 111640
    },
    {
      "epoch": 11.962927247401693,
      "grad_norm": 0.000294030352961272,
      "learning_rate": 4.049430336797744e-06,
      "loss": 0.0,
      "step": 111650
    },
    {
      "epoch": 11.963998714239795,
      "grad_norm": 0.016179852187633514,
      "learning_rate": 4.048001714346941e-06,
      "loss": 0.0834,
      "step": 111660
    },
    {
      "epoch": 11.965070181077895,
      "grad_norm": 7.04683770891279e-05,
      "learning_rate": 4.046573091896139e-06,
      "loss": 0.0,
      "step": 111670
    },
    {
      "epoch": 11.966141647915997,
      "grad_norm": 0.0010943631641566753,
      "learning_rate": 4.045144469445338e-06,
      "loss": 0.0,
      "step": 111680
    },
    {
      "epoch": 11.967213114754099,
      "grad_norm": 6.769799074390903e-05,
      "learning_rate": 4.043715846994536e-06,
      "loss": 0.0,
      "step": 111690
    },
    {
      "epoch": 11.968284581592199,
      "grad_norm": 6.918803410371765e-05,
      "learning_rate": 4.042287224543734e-06,
      "loss": 0.0003,
      "step": 111700
    },
    {
      "epoch": 11.969356048430301,
      "grad_norm": 7.608996384078637e-05,
      "learning_rate": 4.040858602092932e-06,
      "loss": 0.14,
      "step": 111710
    },
    {
      "epoch": 11.970427515268403,
      "grad_norm": 7.315356197068468e-05,
      "learning_rate": 4.039429979642131e-06,
      "loss": 0.0,
      "step": 111720
    },
    {
      "epoch": 11.971498982106503,
      "grad_norm": 7.024893420748413e-05,
      "learning_rate": 4.0380013571913285e-06,
      "loss": 0.0,
      "step": 111730
    },
    {
      "epoch": 11.972570448944605,
      "grad_norm": 6.883203604957089e-05,
      "learning_rate": 4.036572734740527e-06,
      "loss": 0.0002,
      "step": 111740
    },
    {
      "epoch": 11.973641915782707,
      "grad_norm": 0.00048453969066031277,
      "learning_rate": 4.035144112289725e-06,
      "loss": 0.0,
      "step": 111750
    },
    {
      "epoch": 11.974713382620807,
      "grad_norm": 7.290041685337201e-05,
      "learning_rate": 4.033715489838923e-06,
      "loss": 0.0,
      "step": 111760
    },
    {
      "epoch": 11.97578484945891,
      "grad_norm": 6.729760934831575e-05,
      "learning_rate": 4.032286867388122e-06,
      "loss": 0.1452,
      "step": 111770
    },
    {
      "epoch": 11.976856316297011,
      "grad_norm": 0.008133461698889732,
      "learning_rate": 4.030858244937319e-06,
      "loss": 0.0002,
      "step": 111780
    },
    {
      "epoch": 11.977927783135112,
      "grad_norm": 0.00022113423619884998,
      "learning_rate": 4.029429622486518e-06,
      "loss": 0.1289,
      "step": 111790
    },
    {
      "epoch": 11.978999249973214,
      "grad_norm": 7.912373985163867e-05,
      "learning_rate": 4.0280010000357165e-06,
      "loss": 0.0,
      "step": 111800
    },
    {
      "epoch": 11.980070716811314,
      "grad_norm": 8.190418884623796e-05,
      "learning_rate": 4.026572377584914e-06,
      "loss": 0.0004,
      "step": 111810
    },
    {
      "epoch": 11.981142183649416,
      "grad_norm": 0.0006150208064354956,
      "learning_rate": 4.025143755134112e-06,
      "loss": 0.0,
      "step": 111820
    },
    {
      "epoch": 11.982213650487518,
      "grad_norm": 7.529692084062845e-05,
      "learning_rate": 4.02371513268331e-06,
      "loss": 0.0105,
      "step": 111830
    },
    {
      "epoch": 11.983285117325618,
      "grad_norm": 8.25614552013576e-05,
      "learning_rate": 4.022286510232509e-06,
      "loss": 0.1833,
      "step": 111840
    },
    {
      "epoch": 11.98435658416372,
      "grad_norm": 8.165034523699433e-05,
      "learning_rate": 4.0208578877817065e-06,
      "loss": 0.0,
      "step": 111850
    },
    {
      "epoch": 11.985428051001822,
      "grad_norm": 7.244651351356879e-05,
      "learning_rate": 4.019429265330905e-06,
      "loss": 0.0,
      "step": 111860
    },
    {
      "epoch": 11.986499517839922,
      "grad_norm": 0.0010442601051181555,
      "learning_rate": 4.0180006428801036e-06,
      "loss": 0.0001,
      "step": 111870
    },
    {
      "epoch": 11.987570984678024,
      "grad_norm": 7.272430957527831e-05,
      "learning_rate": 4.016572020429301e-06,
      "loss": 0.0,
      "step": 111880
    },
    {
      "epoch": 11.988642451516126,
      "grad_norm": 0.00018847212777473032,
      "learning_rate": 4.0151433979785e-06,
      "loss": 0.0,
      "step": 111890
    },
    {
      "epoch": 11.989713918354227,
      "grad_norm": 26.87678337097168,
      "learning_rate": 4.013714775527697e-06,
      "loss": 0.1488,
      "step": 111900
    },
    {
      "epoch": 11.990785385192329,
      "grad_norm": 0.001962857088074088,
      "learning_rate": 4.012286153076896e-06,
      "loss": 0.0,
      "step": 111910
    },
    {
      "epoch": 11.99185685203043,
      "grad_norm": 29.41729164123535,
      "learning_rate": 4.010857530626094e-06,
      "loss": 0.1209,
      "step": 111920
    },
    {
      "epoch": 11.99292831886853,
      "grad_norm": 8.20104542071931e-05,
      "learning_rate": 4.009428908175292e-06,
      "loss": 0.0,
      "step": 111930
    },
    {
      "epoch": 11.993999785706633,
      "grad_norm": 0.0010550494771450758,
      "learning_rate": 4.008000285724491e-06,
      "loss": 0.0,
      "step": 111940
    },
    {
      "epoch": 11.995071252544733,
      "grad_norm": 0.015506266616284847,
      "learning_rate": 4.006571663273688e-06,
      "loss": 0.0007,
      "step": 111950
    },
    {
      "epoch": 11.996142719382835,
      "grad_norm": 7.251023635035381e-05,
      "learning_rate": 4.005143040822887e-06,
      "loss": 0.0,
      "step": 111960
    },
    {
      "epoch": 11.997214186220937,
      "grad_norm": 0.0006956015131436288,
      "learning_rate": 4.003714418372085e-06,
      "loss": 0.0,
      "step": 111970
    },
    {
      "epoch": 11.998285653059037,
      "grad_norm": 7.821369945304468e-05,
      "learning_rate": 4.002285795921283e-06,
      "loss": 0.0,
      "step": 111980
    },
    {
      "epoch": 11.99935711989714,
      "grad_norm": 0.00016127509297803044,
      "learning_rate": 4.0008571734704816e-06,
      "loss": 0.408,
      "step": 111990
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9761666666666666,
      "eval_f1": 0.907563025210084,
      "eval_loss": 0.18208982050418854,
      "eval_precision": 0.8886075949367088,
      "eval_recall": 0.9273447820343461,
      "eval_runtime": 542.3282,
      "eval_samples_per_second": 11.063,
      "eval_steps_per_second": 3.688,
      "step": 111996
    },
    {
      "epoch": 12.000428586735241,
      "grad_norm": 9.896920528262854e-05,
      "learning_rate": 3.999428551019679e-06,
      "loss": 0.0002,
      "step": 112000
    },
    {
      "epoch": 12.001500053573341,
      "grad_norm": 0.00015867907495703548,
      "learning_rate": 3.997999928568878e-06,
      "loss": 0.0001,
      "step": 112010
    },
    {
      "epoch": 12.002571520411443,
      "grad_norm": 0.0003130877739749849,
      "learning_rate": 3.996571306118076e-06,
      "loss": 0.0,
      "step": 112020
    },
    {
      "epoch": 12.003642987249545,
      "grad_norm": 0.0003464070032350719,
      "learning_rate": 3.995142683667274e-06,
      "loss": 0.0,
      "step": 112030
    },
    {
      "epoch": 12.004714454087646,
      "grad_norm": 8.948911272455007e-05,
      "learning_rate": 3.9937140612164725e-06,
      "loss": 0.0,
      "step": 112040
    },
    {
      "epoch": 12.005785920925748,
      "grad_norm": 0.01136889960616827,
      "learning_rate": 3.992285438765671e-06,
      "loss": 0.0,
      "step": 112050
    },
    {
      "epoch": 12.00685738776385,
      "grad_norm": 0.00022649142192676663,
      "learning_rate": 3.990856816314869e-06,
      "loss": 0.0,
      "step": 112060
    },
    {
      "epoch": 12.00792885460195,
      "grad_norm": 7.984162220964208e-05,
      "learning_rate": 3.989428193864066e-06,
      "loss": 0.0,
      "step": 112070
    },
    {
      "epoch": 12.009000321440052,
      "grad_norm": 0.0005411003949120641,
      "learning_rate": 3.987999571413265e-06,
      "loss": 0.0,
      "step": 112080
    },
    {
      "epoch": 12.010071788278152,
      "grad_norm": 7.811101386323571e-05,
      "learning_rate": 3.986570948962463e-06,
      "loss": 0.0,
      "step": 112090
    },
    {
      "epoch": 12.011143255116254,
      "grad_norm": 9.202938235830516e-05,
      "learning_rate": 3.985142326511661e-06,
      "loss": 0.0,
      "step": 112100
    },
    {
      "epoch": 12.012214721954356,
      "grad_norm": 9.864055755315349e-05,
      "learning_rate": 3.9837137040608596e-06,
      "loss": 0.0,
      "step": 112110
    },
    {
      "epoch": 12.013286188792456,
      "grad_norm": 0.0013408120721578598,
      "learning_rate": 3.982285081610058e-06,
      "loss": 0.0,
      "step": 112120
    },
    {
      "epoch": 12.014357655630558,
      "grad_norm": 8.253078704001382e-05,
      "learning_rate": 3.980856459159256e-06,
      "loss": 0.1548,
      "step": 112130
    },
    {
      "epoch": 12.01542912246866,
      "grad_norm": 0.00012278048961889,
      "learning_rate": 3.979427836708454e-06,
      "loss": 0.0512,
      "step": 112140
    },
    {
      "epoch": 12.01650058930676,
      "grad_norm": 0.028707824647426605,
      "learning_rate": 3.977999214257652e-06,
      "loss": 0.1078,
      "step": 112150
    },
    {
      "epoch": 12.017572056144862,
      "grad_norm": 0.00036598293809220195,
      "learning_rate": 3.9765705918068505e-06,
      "loss": 0.0,
      "step": 112160
    },
    {
      "epoch": 12.018643522982964,
      "grad_norm": 9.461250010645017e-05,
      "learning_rate": 3.975141969356049e-06,
      "loss": 0.0,
      "step": 112170
    },
    {
      "epoch": 12.019714989821065,
      "grad_norm": 9.864432649919763e-05,
      "learning_rate": 3.973713346905247e-06,
      "loss": 0.0001,
      "step": 112180
    },
    {
      "epoch": 12.020786456659167,
      "grad_norm": 0.0002604229375720024,
      "learning_rate": 3.972284724454445e-06,
      "loss": 0.0001,
      "step": 112190
    },
    {
      "epoch": 12.021857923497267,
      "grad_norm": 9.16686694836244e-05,
      "learning_rate": 3.970856102003644e-06,
      "loss": 0.1076,
      "step": 112200
    },
    {
      "epoch": 12.022929390335369,
      "grad_norm": 8.894532220438123e-05,
      "learning_rate": 3.969427479552841e-06,
      "loss": 0.0,
      "step": 112210
    },
    {
      "epoch": 12.024000857173471,
      "grad_norm": 0.00023969261383172125,
      "learning_rate": 3.96799885710204e-06,
      "loss": 0.0,
      "step": 112220
    },
    {
      "epoch": 12.025072324011571,
      "grad_norm": 0.0010016229934990406,
      "learning_rate": 3.966570234651238e-06,
      "loss": 0.0,
      "step": 112230
    },
    {
      "epoch": 12.026143790849673,
      "grad_norm": 0.0001082945746020414,
      "learning_rate": 3.965141612200436e-06,
      "loss": 0.0,
      "step": 112240
    },
    {
      "epoch": 12.027215257687775,
      "grad_norm": 9.307335130870342e-05,
      "learning_rate": 3.963712989749634e-06,
      "loss": 0.0,
      "step": 112250
    },
    {
      "epoch": 12.028286724525875,
      "grad_norm": 0.00010886725794989616,
      "learning_rate": 3.962284367298832e-06,
      "loss": 0.0,
      "step": 112260
    },
    {
      "epoch": 12.029358191363977,
      "grad_norm": 0.00011345226084813476,
      "learning_rate": 3.960855744848031e-06,
      "loss": 0.0007,
      "step": 112270
    },
    {
      "epoch": 12.03042965820208,
      "grad_norm": 0.0023163221776485443,
      "learning_rate": 3.9594271223972285e-06,
      "loss": 0.0329,
      "step": 112280
    },
    {
      "epoch": 12.03150112504018,
      "grad_norm": 8.09792400104925e-05,
      "learning_rate": 3.957998499946427e-06,
      "loss": 0.0,
      "step": 112290
    },
    {
      "epoch": 12.032572591878282,
      "grad_norm": 0.00012117937876610085,
      "learning_rate": 3.9565698774956255e-06,
      "loss": 0.0035,
      "step": 112300
    },
    {
      "epoch": 12.033644058716384,
      "grad_norm": 8.965106098912656e-05,
      "learning_rate": 3.955141255044823e-06,
      "loss": 0.2775,
      "step": 112310
    },
    {
      "epoch": 12.034715525554484,
      "grad_norm": 9.301446698373184e-05,
      "learning_rate": 3.953712632594022e-06,
      "loss": 0.0,
      "step": 112320
    },
    {
      "epoch": 12.035786992392586,
      "grad_norm": 0.00022032416018191725,
      "learning_rate": 3.952284010143219e-06,
      "loss": 0.0,
      "step": 112330
    },
    {
      "epoch": 12.036858459230686,
      "grad_norm": 0.00012068015348631889,
      "learning_rate": 3.950855387692418e-06,
      "loss": 0.0,
      "step": 112340
    },
    {
      "epoch": 12.037929926068788,
      "grad_norm": 0.00011112771608168259,
      "learning_rate": 3.949426765241616e-06,
      "loss": 0.0,
      "step": 112350
    },
    {
      "epoch": 12.03900139290689,
      "grad_norm": 0.00010009317338699475,
      "learning_rate": 3.947998142790814e-06,
      "loss": 0.0,
      "step": 112360
    },
    {
      "epoch": 12.04007285974499,
      "grad_norm": 0.004273542668670416,
      "learning_rate": 3.946569520340013e-06,
      "loss": 0.0,
      "step": 112370
    },
    {
      "epoch": 12.041144326583092,
      "grad_norm": 0.00011578565317904577,
      "learning_rate": 3.945140897889211e-06,
      "loss": 0.0,
      "step": 112380
    },
    {
      "epoch": 12.042215793421194,
      "grad_norm": 0.0010035648010671139,
      "learning_rate": 3.943712275438409e-06,
      "loss": 0.0,
      "step": 112390
    },
    {
      "epoch": 12.043287260259294,
      "grad_norm": 0.0002660010941326618,
      "learning_rate": 3.9422836529876065e-06,
      "loss": 0.0635,
      "step": 112400
    },
    {
      "epoch": 12.044358727097396,
      "grad_norm": 7.901682693045586e-05,
      "learning_rate": 3.940855030536806e-06,
      "loss": 0.0,
      "step": 112410
    },
    {
      "epoch": 12.045430193935498,
      "grad_norm": 8.972692012321204e-05,
      "learning_rate": 3.9394264080860035e-06,
      "loss": 0.0,
      "step": 112420
    },
    {
      "epoch": 12.046501660773599,
      "grad_norm": 0.00010058321640826762,
      "learning_rate": 3.937997785635201e-06,
      "loss": 0.0,
      "step": 112430
    },
    {
      "epoch": 12.0475731276117,
      "grad_norm": 0.0006846816395409405,
      "learning_rate": 3.9365691631844e-06,
      "loss": 0.0,
      "step": 112440
    },
    {
      "epoch": 12.048644594449803,
      "grad_norm": 0.011469648219645023,
      "learning_rate": 3.935140540733598e-06,
      "loss": 0.0,
      "step": 112450
    },
    {
      "epoch": 12.049716061287903,
      "grad_norm": 0.0009745881543494761,
      "learning_rate": 3.933711918282796e-06,
      "loss": 0.0009,
      "step": 112460
    },
    {
      "epoch": 12.050787528126005,
      "grad_norm": 0.45773687958717346,
      "learning_rate": 3.932283295831994e-06,
      "loss": 0.0001,
      "step": 112470
    },
    {
      "epoch": 12.051858994964105,
      "grad_norm": 8.979059202829376e-05,
      "learning_rate": 3.930854673381193e-06,
      "loss": 0.0,
      "step": 112480
    },
    {
      "epoch": 12.052930461802207,
      "grad_norm": 0.00011536315287230536,
      "learning_rate": 3.929426050930391e-06,
      "loss": 0.0,
      "step": 112490
    },
    {
      "epoch": 12.054001928640309,
      "grad_norm": 0.00026430055731907487,
      "learning_rate": 3.927997428479589e-06,
      "loss": 0.0,
      "step": 112500
    },
    {
      "epoch": 12.05507339547841,
      "grad_norm": 0.0003540503385011107,
      "learning_rate": 3.926568806028787e-06,
      "loss": 0.0001,
      "step": 112510
    },
    {
      "epoch": 12.056144862316511,
      "grad_norm": 0.00019881479965988547,
      "learning_rate": 3.925140183577985e-06,
      "loss": 0.0,
      "step": 112520
    },
    {
      "epoch": 12.057216329154613,
      "grad_norm": 8.37822153698653e-05,
      "learning_rate": 3.923711561127184e-06,
      "loss": 0.0006,
      "step": 112530
    },
    {
      "epoch": 12.058287795992713,
      "grad_norm": 9.652398875914514e-05,
      "learning_rate": 3.9222829386763815e-06,
      "loss": 0.1548,
      "step": 112540
    },
    {
      "epoch": 12.059359262830815,
      "grad_norm": 0.002252888400107622,
      "learning_rate": 3.92085431622558e-06,
      "loss": 0.0,
      "step": 112550
    },
    {
      "epoch": 12.060430729668917,
      "grad_norm": 9.9736571428366e-05,
      "learning_rate": 3.9194256937747785e-06,
      "loss": 0.0,
      "step": 112560
    },
    {
      "epoch": 12.061502196507018,
      "grad_norm": 0.00012592473649419844,
      "learning_rate": 3.917997071323976e-06,
      "loss": 0.0,
      "step": 112570
    },
    {
      "epoch": 12.06257366334512,
      "grad_norm": 0.00027339078951627016,
      "learning_rate": 3.916568448873174e-06,
      "loss": 0.0,
      "step": 112580
    },
    {
      "epoch": 12.063645130183222,
      "grad_norm": 0.00010355212725698948,
      "learning_rate": 3.915139826422372e-06,
      "loss": 0.0998,
      "step": 112590
    },
    {
      "epoch": 12.064716597021322,
      "grad_norm": 0.0001888557308120653,
      "learning_rate": 3.913711203971571e-06,
      "loss": 0.0,
      "step": 112600
    },
    {
      "epoch": 12.065788063859424,
      "grad_norm": 0.00010504377860343084,
      "learning_rate": 3.912282581520769e-06,
      "loss": 0.0,
      "step": 112610
    },
    {
      "epoch": 12.066859530697524,
      "grad_norm": 9.06822388060391e-05,
      "learning_rate": 3.910853959069967e-06,
      "loss": 0.0,
      "step": 112620
    },
    {
      "epoch": 12.067930997535626,
      "grad_norm": 0.00010235935769742355,
      "learning_rate": 3.909425336619166e-06,
      "loss": 0.0001,
      "step": 112630
    },
    {
      "epoch": 12.069002464373728,
      "grad_norm": 0.0004206961311865598,
      "learning_rate": 3.907996714168363e-06,
      "loss": 0.0,
      "step": 112640
    },
    {
      "epoch": 12.070073931211828,
      "grad_norm": 9.280727681471035e-05,
      "learning_rate": 3.906568091717562e-06,
      "loss": 0.0,
      "step": 112650
    },
    {
      "epoch": 12.07114539804993,
      "grad_norm": 0.0031569954007864,
      "learning_rate": 3.9051394692667595e-06,
      "loss": 0.0,
      "step": 112660
    },
    {
      "epoch": 12.072216864888032,
      "grad_norm": 0.0005927614402025938,
      "learning_rate": 3.903710846815958e-06,
      "loss": 0.0,
      "step": 112670
    },
    {
      "epoch": 12.073288331726133,
      "grad_norm": 0.00010268812184222043,
      "learning_rate": 3.9022822243651565e-06,
      "loss": 0.0,
      "step": 112680
    },
    {
      "epoch": 12.074359798564235,
      "grad_norm": 9.384439181303605e-05,
      "learning_rate": 3.900853601914354e-06,
      "loss": 0.0011,
      "step": 112690
    },
    {
      "epoch": 12.075431265402337,
      "grad_norm": 0.0008393918978981674,
      "learning_rate": 3.899424979463553e-06,
      "loss": 0.0,
      "step": 112700
    },
    {
      "epoch": 12.076502732240437,
      "grad_norm": 0.00026602117577567697,
      "learning_rate": 3.897996357012751e-06,
      "loss": 0.0,
      "step": 112710
    },
    {
      "epoch": 12.077574199078539,
      "grad_norm": 0.00029665068723261356,
      "learning_rate": 3.896567734561949e-06,
      "loss": 0.0,
      "step": 112720
    },
    {
      "epoch": 12.078645665916639,
      "grad_norm": 8.42728913994506e-05,
      "learning_rate": 3.8951391121111474e-06,
      "loss": 0.0,
      "step": 112730
    },
    {
      "epoch": 12.079717132754741,
      "grad_norm": 9.751820471137762e-05,
      "learning_rate": 3.893710489660346e-06,
      "loss": 0.0,
      "step": 112740
    },
    {
      "epoch": 12.080788599592843,
      "grad_norm": 0.00010221791308140382,
      "learning_rate": 3.892281867209544e-06,
      "loss": 0.0,
      "step": 112750
    },
    {
      "epoch": 12.081860066430943,
      "grad_norm": 0.0003485285851638764,
      "learning_rate": 3.890853244758741e-06,
      "loss": 0.0,
      "step": 112760
    },
    {
      "epoch": 12.082931533269045,
      "grad_norm": 0.0007525202236138284,
      "learning_rate": 3.88942462230794e-06,
      "loss": 0.0,
      "step": 112770
    },
    {
      "epoch": 12.084003000107147,
      "grad_norm": 0.00012112761032767594,
      "learning_rate": 3.887995999857138e-06,
      "loss": 0.0,
      "step": 112780
    },
    {
      "epoch": 12.085074466945247,
      "grad_norm": 0.02791607566177845,
      "learning_rate": 3.886567377406336e-06,
      "loss": 0.2127,
      "step": 112790
    },
    {
      "epoch": 12.08614593378335,
      "grad_norm": 0.0004001430934295058,
      "learning_rate": 3.8851387549555345e-06,
      "loss": 0.0,
      "step": 112800
    },
    {
      "epoch": 12.087217400621451,
      "grad_norm": 0.0002598574501462281,
      "learning_rate": 3.883710132504733e-06,
      "loss": 0.0,
      "step": 112810
    },
    {
      "epoch": 12.088288867459552,
      "grad_norm": 9.255541954189539e-05,
      "learning_rate": 3.882281510053931e-06,
      "loss": 0.0026,
      "step": 112820
    },
    {
      "epoch": 12.089360334297654,
      "grad_norm": 9.536452853353694e-05,
      "learning_rate": 3.880852887603128e-06,
      "loss": 0.0,
      "step": 112830
    },
    {
      "epoch": 12.090431801135756,
      "grad_norm": 0.00023667096684221178,
      "learning_rate": 3.879424265152327e-06,
      "loss": 0.0655,
      "step": 112840
    },
    {
      "epoch": 12.091503267973856,
      "grad_norm": 9.55511350184679e-05,
      "learning_rate": 3.8779956427015254e-06,
      "loss": 0.0,
      "step": 112850
    },
    {
      "epoch": 12.092574734811958,
      "grad_norm": 0.00010701278370106593,
      "learning_rate": 3.876567020250723e-06,
      "loss": 0.0,
      "step": 112860
    },
    {
      "epoch": 12.093646201650058,
      "grad_norm": 9.441517613595352e-05,
      "learning_rate": 3.875138397799922e-06,
      "loss": 0.0,
      "step": 112870
    },
    {
      "epoch": 12.09471766848816,
      "grad_norm": 8.448181324638426e-05,
      "learning_rate": 3.87370977534912e-06,
      "loss": 0.0012,
      "step": 112880
    },
    {
      "epoch": 12.095789135326262,
      "grad_norm": 0.0309204813092947,
      "learning_rate": 3.872281152898318e-06,
      "loss": 0.0,
      "step": 112890
    },
    {
      "epoch": 12.096860602164362,
      "grad_norm": 0.00021175164147280157,
      "learning_rate": 3.870852530447516e-06,
      "loss": 0.0,
      "step": 112900
    },
    {
      "epoch": 12.097932069002464,
      "grad_norm": 8.616612467449158e-05,
      "learning_rate": 3.869423907996714e-06,
      "loss": 0.1685,
      "step": 112910
    },
    {
      "epoch": 12.099003535840566,
      "grad_norm": 0.0001476384641136974,
      "learning_rate": 3.8679952855459125e-06,
      "loss": 0.0001,
      "step": 112920
    },
    {
      "epoch": 12.100075002678667,
      "grad_norm": 0.0006256686174310744,
      "learning_rate": 3.866566663095111e-06,
      "loss": 0.0,
      "step": 112930
    },
    {
      "epoch": 12.101146469516769,
      "grad_norm": 9.736935317050666e-05,
      "learning_rate": 3.865138040644309e-06,
      "loss": 0.0,
      "step": 112940
    },
    {
      "epoch": 12.10221793635487,
      "grad_norm": 0.00013339168799575418,
      "learning_rate": 3.863709418193507e-06,
      "loss": 0.1746,
      "step": 112950
    },
    {
      "epoch": 12.10328940319297,
      "grad_norm": 9.442776354262605e-05,
      "learning_rate": 3.862280795742706e-06,
      "loss": 0.0,
      "step": 112960
    },
    {
      "epoch": 12.104360870031073,
      "grad_norm": 9.298052464146167e-05,
      "learning_rate": 3.8608521732919034e-06,
      "loss": 0.2562,
      "step": 112970
    },
    {
      "epoch": 12.105432336869175,
      "grad_norm": 0.00023305641661863774,
      "learning_rate": 3.859423550841102e-06,
      "loss": 0.0,
      "step": 112980
    },
    {
      "epoch": 12.106503803707275,
      "grad_norm": 0.00026628217892721295,
      "learning_rate": 3.8579949283903005e-06,
      "loss": 0.0164,
      "step": 112990
    },
    {
      "epoch": 12.107575270545377,
      "grad_norm": 0.00011218846339033917,
      "learning_rate": 3.856566305939498e-06,
      "loss": 0.0,
      "step": 113000
    },
    {
      "epoch": 12.108646737383477,
      "grad_norm": 0.00015547963266726583,
      "learning_rate": 3.855137683488696e-06,
      "loss": 0.0,
      "step": 113010
    },
    {
      "epoch": 12.10971820422158,
      "grad_norm": 0.0001611172774573788,
      "learning_rate": 3.853709061037894e-06,
      "loss": 0.0,
      "step": 113020
    },
    {
      "epoch": 12.110789671059681,
      "grad_norm": 0.04257669299840927,
      "learning_rate": 3.852280438587093e-06,
      "loss": 0.0001,
      "step": 113030
    },
    {
      "epoch": 12.111861137897781,
      "grad_norm": 9.248357673641294e-05,
      "learning_rate": 3.8508518161362905e-06,
      "loss": 0.0011,
      "step": 113040
    },
    {
      "epoch": 12.112932604735883,
      "grad_norm": 0.0002057730162050575,
      "learning_rate": 3.849423193685489e-06,
      "loss": 0.0,
      "step": 113050
    },
    {
      "epoch": 12.114004071573985,
      "grad_norm": 0.0002716387389227748,
      "learning_rate": 3.8479945712346876e-06,
      "loss": 0.0004,
      "step": 113060
    },
    {
      "epoch": 12.115075538412086,
      "grad_norm": 0.00010580098023638129,
      "learning_rate": 3.846565948783885e-06,
      "loss": 0.0,
      "step": 113070
    },
    {
      "epoch": 12.116147005250188,
      "grad_norm": 0.00014176506374496967,
      "learning_rate": 3.845137326333084e-06,
      "loss": 0.0001,
      "step": 113080
    },
    {
      "epoch": 12.11721847208829,
      "grad_norm": 0.00040656919009052217,
      "learning_rate": 3.8437087038822814e-06,
      "loss": 0.0,
      "step": 113090
    },
    {
      "epoch": 12.11828993892639,
      "grad_norm": 0.0019054129952564836,
      "learning_rate": 3.84228008143148e-06,
      "loss": 0.0002,
      "step": 113100
    },
    {
      "epoch": 12.119361405764492,
      "grad_norm": 8.62875604070723e-05,
      "learning_rate": 3.8408514589806785e-06,
      "loss": 0.0,
      "step": 113110
    },
    {
      "epoch": 12.120432872602592,
      "grad_norm": 0.00010966992704197764,
      "learning_rate": 3.839422836529876e-06,
      "loss": 0.0,
      "step": 113120
    },
    {
      "epoch": 12.121504339440694,
      "grad_norm": 9.045286424225196e-05,
      "learning_rate": 3.837994214079075e-06,
      "loss": 0.0,
      "step": 113130
    },
    {
      "epoch": 12.122575806278796,
      "grad_norm": 0.007845182903110981,
      "learning_rate": 3.836565591628273e-06,
      "loss": 0.0,
      "step": 113140
    },
    {
      "epoch": 12.123647273116896,
      "grad_norm": 0.00032590472255833447,
      "learning_rate": 3.835136969177471e-06,
      "loss": 0.0,
      "step": 113150
    },
    {
      "epoch": 12.124718739954998,
      "grad_norm": 9.283439430873841e-05,
      "learning_rate": 3.8337083467266685e-06,
      "loss": 0.0,
      "step": 113160
    },
    {
      "epoch": 12.1257902067931,
      "grad_norm": 0.0003079810703638941,
      "learning_rate": 3.832279724275868e-06,
      "loss": 0.0,
      "step": 113170
    },
    {
      "epoch": 12.1268616736312,
      "grad_norm": 9.233489981852472e-05,
      "learning_rate": 3.8308511018250656e-06,
      "loss": 0.0004,
      "step": 113180
    },
    {
      "epoch": 12.127933140469302,
      "grad_norm": 8.118816913338378e-05,
      "learning_rate": 3.829422479374263e-06,
      "loss": 0.0,
      "step": 113190
    },
    {
      "epoch": 12.129004607307404,
      "grad_norm": 9.109852544497699e-05,
      "learning_rate": 3.827993856923462e-06,
      "loss": 0.0,
      "step": 113200
    },
    {
      "epoch": 12.130076074145505,
      "grad_norm": 0.0013789462391287088,
      "learning_rate": 3.82656523447266e-06,
      "loss": 0.0167,
      "step": 113210
    },
    {
      "epoch": 12.131147540983607,
      "grad_norm": 9.440723806619644e-05,
      "learning_rate": 3.825136612021858e-06,
      "loss": 0.0,
      "step": 113220
    },
    {
      "epoch": 12.132219007821709,
      "grad_norm": 8.194077236112207e-05,
      "learning_rate": 3.8237079895710565e-06,
      "loss": 0.0,
      "step": 113230
    },
    {
      "epoch": 12.133290474659809,
      "grad_norm": 0.03124065510928631,
      "learning_rate": 3.822279367120255e-06,
      "loss": 0.0,
      "step": 113240
    },
    {
      "epoch": 12.134361941497911,
      "grad_norm": 9.242242958862334e-05,
      "learning_rate": 3.820850744669453e-06,
      "loss": 0.1521,
      "step": 113250
    },
    {
      "epoch": 12.135433408336011,
      "grad_norm": 0.00018145878857467324,
      "learning_rate": 3.819422122218651e-06,
      "loss": 0.0,
      "step": 113260
    },
    {
      "epoch": 12.136504875174113,
      "grad_norm": 0.00021677077165804803,
      "learning_rate": 3.817993499767849e-06,
      "loss": 0.0,
      "step": 113270
    },
    {
      "epoch": 12.137576342012215,
      "grad_norm": 8.209067163988948e-05,
      "learning_rate": 3.816564877317047e-06,
      "loss": 0.091,
      "step": 113280
    },
    {
      "epoch": 12.138647808850315,
      "grad_norm": 8.096433157334104e-05,
      "learning_rate": 3.815136254866246e-06,
      "loss": 0.0,
      "step": 113290
    },
    {
      "epoch": 12.139719275688417,
      "grad_norm": 0.00016971936565823853,
      "learning_rate": 3.8137076324154436e-06,
      "loss": 0.0006,
      "step": 113300
    },
    {
      "epoch": 12.14079074252652,
      "grad_norm": 8.376213372685015e-05,
      "learning_rate": 3.8122790099646417e-06,
      "loss": 0.0,
      "step": 113310
    },
    {
      "epoch": 12.14186220936462,
      "grad_norm": 8.516616799170151e-05,
      "learning_rate": 3.81085038751384e-06,
      "loss": 0.0,
      "step": 113320
    },
    {
      "epoch": 12.142933676202722,
      "grad_norm": 0.00032286689383909106,
      "learning_rate": 3.8094217650630383e-06,
      "loss": 0.0,
      "step": 113330
    },
    {
      "epoch": 12.144005143040824,
      "grad_norm": 8.470776083413512e-05,
      "learning_rate": 3.8079931426122364e-06,
      "loss": 0.0,
      "step": 113340
    },
    {
      "epoch": 12.145076609878924,
      "grad_norm": 0.00028646213468164206,
      "learning_rate": 3.806564520161435e-06,
      "loss": 0.0001,
      "step": 113350
    },
    {
      "epoch": 12.146148076717026,
      "grad_norm": 9.051923552760854e-05,
      "learning_rate": 3.805135897710633e-06,
      "loss": 0.0,
      "step": 113360
    },
    {
      "epoch": 12.147219543555128,
      "grad_norm": 8.757695468375459e-05,
      "learning_rate": 3.8037072752598307e-06,
      "loss": 0.0,
      "step": 113370
    },
    {
      "epoch": 12.148291010393228,
      "grad_norm": 0.00020352845604065806,
      "learning_rate": 3.8022786528090296e-06,
      "loss": 0.2221,
      "step": 113380
    },
    {
      "epoch": 12.14936247723133,
      "grad_norm": 8.857016655383632e-05,
      "learning_rate": 3.8008500303582273e-06,
      "loss": 0.0,
      "step": 113390
    },
    {
      "epoch": 12.15043394406943,
      "grad_norm": 0.0003828021581284702,
      "learning_rate": 3.7994214079074254e-06,
      "loss": 0.0,
      "step": 113400
    },
    {
      "epoch": 12.151505410907532,
      "grad_norm": 8.696778968442231e-05,
      "learning_rate": 3.797992785456624e-06,
      "loss": 0.0,
      "step": 113410
    },
    {
      "epoch": 12.152576877745634,
      "grad_norm": 8.623979374533519e-05,
      "learning_rate": 3.796564163005822e-06,
      "loss": 0.0,
      "step": 113420
    },
    {
      "epoch": 12.153648344583734,
      "grad_norm": 9.507867798674852e-05,
      "learning_rate": 3.79513554055502e-06,
      "loss": 0.0,
      "step": 113430
    },
    {
      "epoch": 12.154719811421836,
      "grad_norm": 8.823805546853691e-05,
      "learning_rate": 3.7937069181042186e-06,
      "loss": 0.0,
      "step": 113440
    },
    {
      "epoch": 12.155791278259938,
      "grad_norm": 8.054036152316257e-05,
      "learning_rate": 3.7922782956534167e-06,
      "loss": 0.0005,
      "step": 113450
    },
    {
      "epoch": 12.156862745098039,
      "grad_norm": 8.158262789947912e-05,
      "learning_rate": 3.7908496732026144e-06,
      "loss": 0.0001,
      "step": 113460
    },
    {
      "epoch": 12.15793421193614,
      "grad_norm": 0.0005136123509146273,
      "learning_rate": 3.789421050751813e-06,
      "loss": 0.0,
      "step": 113470
    },
    {
      "epoch": 12.159005678774243,
      "grad_norm": 0.007861671037971973,
      "learning_rate": 3.787992428301011e-06,
      "loss": 0.0,
      "step": 113480
    },
    {
      "epoch": 12.160077145612343,
      "grad_norm": 8.648624498164281e-05,
      "learning_rate": 3.786563805850209e-06,
      "loss": 0.0,
      "step": 113490
    },
    {
      "epoch": 12.161148612450445,
      "grad_norm": 0.0002320287749171257,
      "learning_rate": 3.7851351833994076e-06,
      "loss": 0.2633,
      "step": 113500
    },
    {
      "epoch": 12.162220079288547,
      "grad_norm": 9.472211240790784e-05,
      "learning_rate": 3.7837065609486057e-06,
      "loss": 0.0,
      "step": 113510
    },
    {
      "epoch": 12.163291546126647,
      "grad_norm": 0.00012250433792360127,
      "learning_rate": 3.782277938497804e-06,
      "loss": 0.0,
      "step": 113520
    },
    {
      "epoch": 12.164363012964749,
      "grad_norm": 7.699772686464712e-05,
      "learning_rate": 3.7808493160470023e-06,
      "loss": 0.0,
      "step": 113530
    },
    {
      "epoch": 12.16543447980285,
      "grad_norm": 0.8871186971664429,
      "learning_rate": 3.7794206935962004e-06,
      "loss": 0.0004,
      "step": 113540
    },
    {
      "epoch": 12.166505946640951,
      "grad_norm": 0.0003702043031807989,
      "learning_rate": 3.777992071145398e-06,
      "loss": 0.0,
      "step": 113550
    },
    {
      "epoch": 12.167577413479053,
      "grad_norm": 0.00016780228179413825,
      "learning_rate": 3.7765634486945966e-06,
      "loss": 0.0,
      "step": 113560
    },
    {
      "epoch": 12.168648880317154,
      "grad_norm": 8.667919610161334e-05,
      "learning_rate": 3.7751348262437947e-06,
      "loss": 0.016,
      "step": 113570
    },
    {
      "epoch": 12.169720347155256,
      "grad_norm": 8.258522575488314e-05,
      "learning_rate": 3.773706203792993e-06,
      "loss": 0.0,
      "step": 113580
    },
    {
      "epoch": 12.170791813993358,
      "grad_norm": 0.00013620145909953862,
      "learning_rate": 3.7722775813421913e-06,
      "loss": 0.0,
      "step": 113590
    },
    {
      "epoch": 12.171863280831458,
      "grad_norm": 0.0002686917723622173,
      "learning_rate": 3.7708489588913894e-06,
      "loss": 0.0918,
      "step": 113600
    },
    {
      "epoch": 12.17293474766956,
      "grad_norm": 8.726084342924878e-05,
      "learning_rate": 3.7694203364405875e-06,
      "loss": 0.0,
      "step": 113610
    },
    {
      "epoch": 12.174006214507662,
      "grad_norm": 9.202024375554174e-05,
      "learning_rate": 3.767991713989786e-06,
      "loss": 0.3036,
      "step": 113620
    },
    {
      "epoch": 12.175077681345762,
      "grad_norm": 0.00011906386498594657,
      "learning_rate": 3.766563091538984e-06,
      "loss": 0.099,
      "step": 113630
    },
    {
      "epoch": 12.176149148183864,
      "grad_norm": 8.868595614330843e-05,
      "learning_rate": 3.765134469088182e-06,
      "loss": 0.0,
      "step": 113640
    },
    {
      "epoch": 12.177220615021966,
      "grad_norm": 0.0001306250342167914,
      "learning_rate": 3.7637058466373803e-06,
      "loss": 0.0001,
      "step": 113650
    },
    {
      "epoch": 12.178292081860066,
      "grad_norm": 9.024098835652694e-05,
      "learning_rate": 3.7622772241865784e-06,
      "loss": 0.0,
      "step": 113660
    },
    {
      "epoch": 12.179363548698168,
      "grad_norm": 8.239640737883747e-05,
      "learning_rate": 3.7608486017357765e-06,
      "loss": 0.0,
      "step": 113670
    },
    {
      "epoch": 12.180435015536268,
      "grad_norm": 9.987144585466012e-05,
      "learning_rate": 3.759419979284975e-06,
      "loss": 0.0,
      "step": 113680
    },
    {
      "epoch": 12.18150648237437,
      "grad_norm": 0.0002254888677271083,
      "learning_rate": 3.757991356834173e-06,
      "loss": 0.0001,
      "step": 113690
    },
    {
      "epoch": 12.182577949212472,
      "grad_norm": 8.102166611934081e-05,
      "learning_rate": 3.7565627343833712e-06,
      "loss": 0.0,
      "step": 113700
    },
    {
      "epoch": 12.183649416050573,
      "grad_norm": 9.294373739976436e-05,
      "learning_rate": 3.7551341119325697e-06,
      "loss": 0.0,
      "step": 113710
    },
    {
      "epoch": 12.184720882888675,
      "grad_norm": 0.7195618748664856,
      "learning_rate": 3.7537054894817674e-06,
      "loss": 0.0004,
      "step": 113720
    },
    {
      "epoch": 12.185792349726777,
      "grad_norm": 0.00012819810945075005,
      "learning_rate": 3.7522768670309655e-06,
      "loss": 0.0,
      "step": 113730
    },
    {
      "epoch": 12.186863816564877,
      "grad_norm": 8.202492608688772e-05,
      "learning_rate": 3.7508482445801636e-06,
      "loss": 0.0626,
      "step": 113740
    },
    {
      "epoch": 12.187935283402979,
      "grad_norm": 9.027298801811412e-05,
      "learning_rate": 3.749419622129362e-06,
      "loss": 0.0901,
      "step": 113750
    },
    {
      "epoch": 12.18900675024108,
      "grad_norm": 0.0002908328897319734,
      "learning_rate": 3.7479909996785602e-06,
      "loss": 0.0013,
      "step": 113760
    },
    {
      "epoch": 12.190078217079181,
      "grad_norm": 8.252274710685015e-05,
      "learning_rate": 3.7465623772277583e-06,
      "loss": 0.0,
      "step": 113770
    },
    {
      "epoch": 12.191149683917283,
      "grad_norm": 0.0001868537365226075,
      "learning_rate": 3.745133754776957e-06,
      "loss": 0.0,
      "step": 113780
    },
    {
      "epoch": 12.192221150755383,
      "grad_norm": 9.274863259634003e-05,
      "learning_rate": 3.743705132326155e-06,
      "loss": 0.0,
      "step": 113790
    },
    {
      "epoch": 12.193292617593485,
      "grad_norm": 0.0002204877237090841,
      "learning_rate": 3.7422765098753526e-06,
      "loss": 0.0,
      "step": 113800
    },
    {
      "epoch": 12.194364084431587,
      "grad_norm": 0.00011628765059867874,
      "learning_rate": 3.740847887424551e-06,
      "loss": 0.0,
      "step": 113810
    },
    {
      "epoch": 12.195435551269687,
      "grad_norm": 0.00014070312317926437,
      "learning_rate": 3.7394192649737492e-06,
      "loss": 0.0,
      "step": 113820
    },
    {
      "epoch": 12.19650701810779,
      "grad_norm": 0.00023023004177957773,
      "learning_rate": 3.7379906425229473e-06,
      "loss": 0.1751,
      "step": 113830
    },
    {
      "epoch": 12.197578484945891,
      "grad_norm": 8.601667650509626e-05,
      "learning_rate": 3.736562020072146e-06,
      "loss": 0.0,
      "step": 113840
    },
    {
      "epoch": 12.198649951783992,
      "grad_norm": 0.0011008328292518854,
      "learning_rate": 3.735133397621344e-06,
      "loss": 0.0,
      "step": 113850
    },
    {
      "epoch": 12.199721418622094,
      "grad_norm": 9.035148832481354e-05,
      "learning_rate": 3.733704775170542e-06,
      "loss": 0.0,
      "step": 113860
    },
    {
      "epoch": 12.200792885460196,
      "grad_norm": 0.0002039890387095511,
      "learning_rate": 3.7322761527197405e-06,
      "loss": 0.0,
      "step": 113870
    },
    {
      "epoch": 12.201864352298296,
      "grad_norm": 0.0002892291231546551,
      "learning_rate": 3.7308475302689382e-06,
      "loss": 0.0,
      "step": 113880
    },
    {
      "epoch": 12.202935819136398,
      "grad_norm": 9.730690362630412e-05,
      "learning_rate": 3.7294189078181363e-06,
      "loss": 0.0,
      "step": 113890
    },
    {
      "epoch": 12.2040072859745,
      "grad_norm": 0.0003340463154017925,
      "learning_rate": 3.727990285367335e-06,
      "loss": 0.0,
      "step": 113900
    },
    {
      "epoch": 12.2050787528126,
      "grad_norm": 0.00011956132220802829,
      "learning_rate": 3.726561662916533e-06,
      "loss": 0.0,
      "step": 113910
    },
    {
      "epoch": 12.206150219650702,
      "grad_norm": 0.00029235193505883217,
      "learning_rate": 3.725133040465731e-06,
      "loss": 0.0,
      "step": 113920
    },
    {
      "epoch": 12.207221686488802,
      "grad_norm": 0.00012050248187733814,
      "learning_rate": 3.7237044180149295e-06,
      "loss": 0.0,
      "step": 113930
    },
    {
      "epoch": 12.208293153326904,
      "grad_norm": 0.009949124418199062,
      "learning_rate": 3.7222757955641276e-06,
      "loss": 0.0,
      "step": 113940
    },
    {
      "epoch": 12.209364620165006,
      "grad_norm": 9.667785343481228e-05,
      "learning_rate": 3.7208471731133257e-06,
      "loss": 0.0,
      "step": 113950
    },
    {
      "epoch": 12.210436087003107,
      "grad_norm": 0.0002618394501041621,
      "learning_rate": 3.7194185506625243e-06,
      "loss": 0.0,
      "step": 113960
    },
    {
      "epoch": 12.211507553841209,
      "grad_norm": 0.0006458432180806994,
      "learning_rate": 3.717989928211722e-06,
      "loss": 0.0,
      "step": 113970
    },
    {
      "epoch": 12.21257902067931,
      "grad_norm": 0.0003016627160832286,
      "learning_rate": 3.71656130576092e-06,
      "loss": 0.1415,
      "step": 113980
    },
    {
      "epoch": 12.21365048751741,
      "grad_norm": 8.62170709297061e-05,
      "learning_rate": 3.7151326833101185e-06,
      "loss": 0.0,
      "step": 113990
    },
    {
      "epoch": 12.214721954355513,
      "grad_norm": 0.0002291473065270111,
      "learning_rate": 3.7137040608593166e-06,
      "loss": 0.0,
      "step": 114000
    },
    {
      "epoch": 12.215793421193615,
      "grad_norm": 0.00024219881743192673,
      "learning_rate": 3.7122754384085147e-06,
      "loss": 0.0027,
      "step": 114010
    },
    {
      "epoch": 12.216864888031715,
      "grad_norm": 0.00010278077388647944,
      "learning_rate": 3.7108468159577133e-06,
      "loss": 0.0,
      "step": 114020
    },
    {
      "epoch": 12.217936354869817,
      "grad_norm": 0.014996705576777458,
      "learning_rate": 3.7094181935069114e-06,
      "loss": 0.0,
      "step": 114030
    },
    {
      "epoch": 12.219007821707919,
      "grad_norm": 0.00010963540989905596,
      "learning_rate": 3.707989571056109e-06,
      "loss": 0.0001,
      "step": 114040
    },
    {
      "epoch": 12.22007928854602,
      "grad_norm": 8.675691788084805e-05,
      "learning_rate": 3.706560948605308e-06,
      "loss": 0.0002,
      "step": 114050
    },
    {
      "epoch": 12.221150755384121,
      "grad_norm": 7.91572019807063e-05,
      "learning_rate": 3.7051323261545056e-06,
      "loss": 0.1376,
      "step": 114060
    },
    {
      "epoch": 12.222222222222221,
      "grad_norm": 0.001183805288746953,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 0.0,
      "step": 114070
    },
    {
      "epoch": 12.223293689060323,
      "grad_norm": 44.20566940307617,
      "learning_rate": 3.7022750812529023e-06,
      "loss": 0.2417,
      "step": 114080
    },
    {
      "epoch": 12.224365155898425,
      "grad_norm": 0.003471628064289689,
      "learning_rate": 3.7008464588021004e-06,
      "loss": 0.0,
      "step": 114090
    },
    {
      "epoch": 12.225436622736526,
      "grad_norm": 0.00013976229820400476,
      "learning_rate": 3.6994178363512985e-06,
      "loss": 0.0,
      "step": 114100
    },
    {
      "epoch": 12.226508089574628,
      "grad_norm": 0.0003646841214504093,
      "learning_rate": 3.697989213900497e-06,
      "loss": 0.0,
      "step": 114110
    },
    {
      "epoch": 12.22757955641273,
      "grad_norm": 9.976066939998418e-05,
      "learning_rate": 3.696560591449695e-06,
      "loss": 0.0,
      "step": 114120
    },
    {
      "epoch": 12.22865102325083,
      "grad_norm": 0.00022887004888616502,
      "learning_rate": 3.6951319689988927e-06,
      "loss": 0.0,
      "step": 114130
    },
    {
      "epoch": 12.229722490088932,
      "grad_norm": 0.0004024370282422751,
      "learning_rate": 3.6937033465480917e-06,
      "loss": 0.0,
      "step": 114140
    },
    {
      "epoch": 12.230793956927034,
      "grad_norm": 0.0014398128259927034,
      "learning_rate": 3.6922747240972894e-06,
      "loss": 0.0001,
      "step": 114150
    },
    {
      "epoch": 12.231865423765134,
      "grad_norm": 9.790997864911333e-05,
      "learning_rate": 3.6908461016464875e-06,
      "loss": 0.0,
      "step": 114160
    },
    {
      "epoch": 12.232936890603236,
      "grad_norm": 0.00011435481428634375,
      "learning_rate": 3.689417479195686e-06,
      "loss": 0.0009,
      "step": 114170
    },
    {
      "epoch": 12.234008357441336,
      "grad_norm": 0.0003100208705291152,
      "learning_rate": 3.687988856744884e-06,
      "loss": 0.0,
      "step": 114180
    },
    {
      "epoch": 12.235079824279438,
      "grad_norm": 0.0003157954488415271,
      "learning_rate": 3.686560234294082e-06,
      "loss": 0.0001,
      "step": 114190
    },
    {
      "epoch": 12.23615129111754,
      "grad_norm": 0.00010636213846737519,
      "learning_rate": 3.6851316118432807e-06,
      "loss": 0.0,
      "step": 114200
    },
    {
      "epoch": 12.23722275795564,
      "grad_norm": 0.0003007394843734801,
      "learning_rate": 3.6837029893924788e-06,
      "loss": 0.0,
      "step": 114210
    },
    {
      "epoch": 12.238294224793743,
      "grad_norm": 9.9699835118372e-05,
      "learning_rate": 3.6822743669416765e-06,
      "loss": 0.0,
      "step": 114220
    },
    {
      "epoch": 12.239365691631845,
      "grad_norm": 0.0001235958479810506,
      "learning_rate": 3.680845744490875e-06,
      "loss": 0.0,
      "step": 114230
    },
    {
      "epoch": 12.240437158469945,
      "grad_norm": 0.00011194112448720261,
      "learning_rate": 3.679417122040073e-06,
      "loss": 0.0,
      "step": 114240
    },
    {
      "epoch": 12.241508625308047,
      "grad_norm": 0.02871173433959484,
      "learning_rate": 3.677988499589271e-06,
      "loss": 0.0,
      "step": 114250
    },
    {
      "epoch": 12.242580092146149,
      "grad_norm": 0.00010422150080557913,
      "learning_rate": 3.6765598771384697e-06,
      "loss": 0.0,
      "step": 114260
    },
    {
      "epoch": 12.243651558984249,
      "grad_norm": 0.00015731315943412483,
      "learning_rate": 3.6751312546876678e-06,
      "loss": 0.0001,
      "step": 114270
    },
    {
      "epoch": 12.244723025822351,
      "grad_norm": 0.00012077933206455782,
      "learning_rate": 3.673702632236866e-06,
      "loss": 0.0,
      "step": 114280
    },
    {
      "epoch": 12.245794492660453,
      "grad_norm": 0.00010399831080576405,
      "learning_rate": 3.6722740097860644e-06,
      "loss": 0.0,
      "step": 114290
    },
    {
      "epoch": 12.246865959498553,
      "grad_norm": 0.00010892962745856494,
      "learning_rate": 3.6708453873352625e-06,
      "loss": 0.0004,
      "step": 114300
    },
    {
      "epoch": 12.247937426336655,
      "grad_norm": 9.770136239239946e-05,
      "learning_rate": 3.66941676488446e-06,
      "loss": 0.0,
      "step": 114310
    },
    {
      "epoch": 12.249008893174755,
      "grad_norm": 0.00023968532332219183,
      "learning_rate": 3.6679881424336587e-06,
      "loss": 0.0,
      "step": 114320
    },
    {
      "epoch": 12.250080360012857,
      "grad_norm": 0.0009926198981702328,
      "learning_rate": 3.6665595199828568e-06,
      "loss": 0.0,
      "step": 114330
    },
    {
      "epoch": 12.25115182685096,
      "grad_norm": 8.861957758199424e-05,
      "learning_rate": 3.665130897532055e-06,
      "loss": 0.0,
      "step": 114340
    },
    {
      "epoch": 12.25222329368906,
      "grad_norm": 0.00021518573339562863,
      "learning_rate": 3.6637022750812534e-06,
      "loss": 0.0,
      "step": 114350
    },
    {
      "epoch": 12.253294760527162,
      "grad_norm": 0.5637051463127136,
      "learning_rate": 3.6622736526304515e-06,
      "loss": 0.0004,
      "step": 114360
    },
    {
      "epoch": 12.254366227365264,
      "grad_norm": 9.151384438155219e-05,
      "learning_rate": 3.6608450301796496e-06,
      "loss": 0.0,
      "step": 114370
    },
    {
      "epoch": 12.255437694203364,
      "grad_norm": 8.77447600942105e-05,
      "learning_rate": 3.659416407728848e-06,
      "loss": 0.0,
      "step": 114380
    },
    {
      "epoch": 12.256509161041466,
      "grad_norm": 0.00011152711522299796,
      "learning_rate": 3.6579877852780458e-06,
      "loss": 0.0,
      "step": 114390
    },
    {
      "epoch": 12.257580627879568,
      "grad_norm": 0.00010448460670886561,
      "learning_rate": 3.656559162827244e-06,
      "loss": 0.0,
      "step": 114400
    },
    {
      "epoch": 12.258652094717668,
      "grad_norm": 0.00010531084262765944,
      "learning_rate": 3.6551305403764424e-06,
      "loss": 0.0,
      "step": 114410
    },
    {
      "epoch": 12.25972356155577,
      "grad_norm": 8.878624794306234e-05,
      "learning_rate": 3.6537019179256405e-06,
      "loss": 0.0013,
      "step": 114420
    },
    {
      "epoch": 12.260795028393872,
      "grad_norm": 8.380380313610658e-05,
      "learning_rate": 3.6522732954748386e-06,
      "loss": 0.0,
      "step": 114430
    },
    {
      "epoch": 12.261866495231972,
      "grad_norm": 9.750313620315865e-05,
      "learning_rate": 3.650844673024037e-06,
      "loss": 0.0,
      "step": 114440
    },
    {
      "epoch": 12.262937962070074,
      "grad_norm": 0.0004270398640073836,
      "learning_rate": 3.649416050573235e-06,
      "loss": 0.0,
      "step": 114450
    },
    {
      "epoch": 12.264009428908174,
      "grad_norm": 8.505379082635045e-05,
      "learning_rate": 3.6479874281224333e-06,
      "loss": 0.0,
      "step": 114460
    },
    {
      "epoch": 12.265080895746276,
      "grad_norm": 9.700044029159471e-05,
      "learning_rate": 3.646558805671632e-06,
      "loss": 0.0,
      "step": 114470
    },
    {
      "epoch": 12.266152362584378,
      "grad_norm": 0.0003471417003311217,
      "learning_rate": 3.6451301832208295e-06,
      "loss": 0.0,
      "step": 114480
    },
    {
      "epoch": 12.267223829422479,
      "grad_norm": 0.00014861085219308734,
      "learning_rate": 3.6437015607700276e-06,
      "loss": 0.0,
      "step": 114490
    },
    {
      "epoch": 12.26829529626058,
      "grad_norm": 5.540523052215576,
      "learning_rate": 3.642272938319226e-06,
      "loss": 0.0012,
      "step": 114500
    },
    {
      "epoch": 12.269366763098683,
      "grad_norm": 7.800790626788512e-05,
      "learning_rate": 3.640844315868424e-06,
      "loss": 0.1696,
      "step": 114510
    },
    {
      "epoch": 12.270438229936783,
      "grad_norm": 9.699296060716733e-05,
      "learning_rate": 3.6394156934176223e-06,
      "loss": 0.0,
      "step": 114520
    },
    {
      "epoch": 12.271509696774885,
      "grad_norm": 0.00011411836021579802,
      "learning_rate": 3.637987070966821e-06,
      "loss": 0.0,
      "step": 114530
    },
    {
      "epoch": 12.272581163612987,
      "grad_norm": 0.00010020100307883695,
      "learning_rate": 3.636558448516019e-06,
      "loss": 0.0,
      "step": 114540
    },
    {
      "epoch": 12.273652630451087,
      "grad_norm": 9.277760545955971e-05,
      "learning_rate": 3.635129826065217e-06,
      "loss": 0.2489,
      "step": 114550
    },
    {
      "epoch": 12.27472409728919,
      "grad_norm": 0.00028572091832756996,
      "learning_rate": 3.6337012036144155e-06,
      "loss": 0.0003,
      "step": 114560
    },
    {
      "epoch": 12.275795564127291,
      "grad_norm": 9.220583888236433e-05,
      "learning_rate": 3.632272581163613e-06,
      "loss": 0.0005,
      "step": 114570
    },
    {
      "epoch": 12.276867030965391,
      "grad_norm": 0.00012320297537371516,
      "learning_rate": 3.6308439587128113e-06,
      "loss": 0.0002,
      "step": 114580
    },
    {
      "epoch": 12.277938497803493,
      "grad_norm": 0.2090356945991516,
      "learning_rate": 3.62941533626201e-06,
      "loss": 0.086,
      "step": 114590
    },
    {
      "epoch": 12.279009964641594,
      "grad_norm": 0.0001322562893619761,
      "learning_rate": 3.627986713811208e-06,
      "loss": 0.0001,
      "step": 114600
    },
    {
      "epoch": 12.280081431479696,
      "grad_norm": 0.00017238370492123067,
      "learning_rate": 3.626558091360406e-06,
      "loss": 0.1767,
      "step": 114610
    },
    {
      "epoch": 12.281152898317798,
      "grad_norm": 0.00018534511036705226,
      "learning_rate": 3.6251294689096045e-06,
      "loss": 0.1617,
      "step": 114620
    },
    {
      "epoch": 12.282224365155898,
      "grad_norm": 0.002541483147069812,
      "learning_rate": 3.6237008464588026e-06,
      "loss": 0.0,
      "step": 114630
    },
    {
      "epoch": 12.283295831994,
      "grad_norm": 0.00016728478658478707,
      "learning_rate": 3.6222722240080003e-06,
      "loss": 0.0,
      "step": 114640
    },
    {
      "epoch": 12.284367298832102,
      "grad_norm": 0.004105329513549805,
      "learning_rate": 3.6208436015571984e-06,
      "loss": 0.0001,
      "step": 114650
    },
    {
      "epoch": 12.285438765670202,
      "grad_norm": 9.448063792660832e-05,
      "learning_rate": 3.619414979106397e-06,
      "loss": 0.0,
      "step": 114660
    },
    {
      "epoch": 12.286510232508304,
      "grad_norm": 0.0038990366738289595,
      "learning_rate": 3.617986356655595e-06,
      "loss": 0.0,
      "step": 114670
    },
    {
      "epoch": 12.287581699346406,
      "grad_norm": 0.00020710998796857893,
      "learning_rate": 3.616557734204793e-06,
      "loss": 0.0,
      "step": 114680
    },
    {
      "epoch": 12.288653166184506,
      "grad_norm": 0.00019531737780198455,
      "learning_rate": 3.6151291117539916e-06,
      "loss": 0.0025,
      "step": 114690
    },
    {
      "epoch": 12.289724633022608,
      "grad_norm": 9.600217890692875e-05,
      "learning_rate": 3.6137004893031897e-06,
      "loss": 0.0,
      "step": 114700
    },
    {
      "epoch": 12.29079609986071,
      "grad_norm": 0.00019771310326177627,
      "learning_rate": 3.612271866852388e-06,
      "loss": 0.0001,
      "step": 114710
    },
    {
      "epoch": 12.29186756669881,
      "grad_norm": 0.0026958405505865812,
      "learning_rate": 3.6108432444015863e-06,
      "loss": 0.0003,
      "step": 114720
    },
    {
      "epoch": 12.292939033536912,
      "grad_norm": 0.016660667955875397,
      "learning_rate": 3.609414621950784e-06,
      "loss": 0.0,
      "step": 114730
    },
    {
      "epoch": 12.294010500375013,
      "grad_norm": 8.928586612455547e-05,
      "learning_rate": 3.607985999499982e-06,
      "loss": 0.0,
      "step": 114740
    },
    {
      "epoch": 12.295081967213115,
      "grad_norm": 8.380934013985097e-05,
      "learning_rate": 3.6065573770491806e-06,
      "loss": 0.0,
      "step": 114750
    },
    {
      "epoch": 12.296153434051217,
      "grad_norm": 0.00019996338232886046,
      "learning_rate": 3.6051287545983787e-06,
      "loss": 0.0,
      "step": 114760
    },
    {
      "epoch": 12.297224900889317,
      "grad_norm": 0.00030081698787398636,
      "learning_rate": 3.603700132147577e-06,
      "loss": 0.0,
      "step": 114770
    },
    {
      "epoch": 12.298296367727419,
      "grad_norm": 0.00016118664643727243,
      "learning_rate": 3.6022715096967753e-06,
      "loss": 0.0,
      "step": 114780
    },
    {
      "epoch": 12.29936783456552,
      "grad_norm": 0.00010010780533775687,
      "learning_rate": 3.6008428872459734e-06,
      "loss": 0.0,
      "step": 114790
    },
    {
      "epoch": 12.300439301403621,
      "grad_norm": 0.00021719789947383106,
      "learning_rate": 3.599414264795171e-06,
      "loss": 0.0,
      "step": 114800
    },
    {
      "epoch": 12.301510768241723,
      "grad_norm": 0.00030441992566920817,
      "learning_rate": 3.59798564234437e-06,
      "loss": 0.0014,
      "step": 114810
    },
    {
      "epoch": 12.302582235079825,
      "grad_norm": 0.0001588531449669972,
      "learning_rate": 3.5965570198935677e-06,
      "loss": 0.0849,
      "step": 114820
    },
    {
      "epoch": 12.303653701917925,
      "grad_norm": 8.797356713330373e-05,
      "learning_rate": 3.595128397442766e-06,
      "loss": 0.0,
      "step": 114830
    },
    {
      "epoch": 12.304725168756027,
      "grad_norm": 9.370496991323307e-05,
      "learning_rate": 3.5936997749919643e-06,
      "loss": 0.0003,
      "step": 114840
    },
    {
      "epoch": 12.305796635594128,
      "grad_norm": 0.00020251679234206676,
      "learning_rate": 3.5922711525411624e-06,
      "loss": 0.0,
      "step": 114850
    },
    {
      "epoch": 12.30686810243223,
      "grad_norm": 0.00011502079723868519,
      "learning_rate": 3.5908425300903605e-06,
      "loss": 0.0,
      "step": 114860
    },
    {
      "epoch": 12.307939569270332,
      "grad_norm": 9.186050738207996e-05,
      "learning_rate": 3.589413907639559e-06,
      "loss": 0.0,
      "step": 114870
    },
    {
      "epoch": 12.309011036108432,
      "grad_norm": 0.0001284930040128529,
      "learning_rate": 3.587985285188757e-06,
      "loss": 0.0,
      "step": 114880
    },
    {
      "epoch": 12.310082502946534,
      "grad_norm": 0.00024489572388119996,
      "learning_rate": 3.586556662737955e-06,
      "loss": 0.0,
      "step": 114890
    },
    {
      "epoch": 12.311153969784636,
      "grad_norm": 0.00022617366630584002,
      "learning_rate": 3.5851280402871538e-06,
      "loss": 0.0,
      "step": 114900
    },
    {
      "epoch": 12.312225436622736,
      "grad_norm": 7.476694008801132e-05,
      "learning_rate": 3.5836994178363514e-06,
      "loss": 0.0058,
      "step": 114910
    },
    {
      "epoch": 12.313296903460838,
      "grad_norm": 0.00011764439841499552,
      "learning_rate": 3.5822707953855495e-06,
      "loss": 0.0,
      "step": 114920
    },
    {
      "epoch": 12.31436837029894,
      "grad_norm": 8.136584801832214e-05,
      "learning_rate": 3.580842172934748e-06,
      "loss": 0.0,
      "step": 114930
    },
    {
      "epoch": 12.31543983713704,
      "grad_norm": 0.3150087893009186,
      "learning_rate": 3.579413550483946e-06,
      "loss": 0.0001,
      "step": 114940
    },
    {
      "epoch": 12.316511303975142,
      "grad_norm": 9.355587098980322e-05,
      "learning_rate": 3.5779849280331442e-06,
      "loss": 0.0,
      "step": 114950
    },
    {
      "epoch": 12.317582770813244,
      "grad_norm": 8.21826106403023e-05,
      "learning_rate": 3.5765563055823428e-06,
      "loss": 0.0173,
      "step": 114960
    },
    {
      "epoch": 12.318654237651344,
      "grad_norm": 8.352413715329021e-05,
      "learning_rate": 3.575127683131541e-06,
      "loss": 0.0,
      "step": 114970
    },
    {
      "epoch": 12.319725704489446,
      "grad_norm": 9.130189573625103e-05,
      "learning_rate": 3.5736990606807385e-06,
      "loss": 0.0,
      "step": 114980
    },
    {
      "epoch": 12.320797171327547,
      "grad_norm": 8.88793365447782e-05,
      "learning_rate": 3.572270438229937e-06,
      "loss": 0.0,
      "step": 114990
    },
    {
      "epoch": 12.321868638165649,
      "grad_norm": 0.0001888132537715137,
      "learning_rate": 3.570841815779135e-06,
      "loss": 0.0,
      "step": 115000
    },
    {
      "epoch": 12.32294010500375,
      "grad_norm": 0.00012309417070355266,
      "learning_rate": 3.5694131933283332e-06,
      "loss": 0.0,
      "step": 115010
    },
    {
      "epoch": 12.32401157184185,
      "grad_norm": 8.486625301884487e-05,
      "learning_rate": 3.5679845708775318e-06,
      "loss": 0.0,
      "step": 115020
    },
    {
      "epoch": 12.325083038679953,
      "grad_norm": 0.0005551769281737506,
      "learning_rate": 3.56655594842673e-06,
      "loss": 0.0,
      "step": 115030
    },
    {
      "epoch": 12.326154505518055,
      "grad_norm": 0.00016810827946756035,
      "learning_rate": 3.565127325975928e-06,
      "loss": 0.0,
      "step": 115040
    },
    {
      "epoch": 12.327225972356155,
      "grad_norm": 7.439720502588898e-05,
      "learning_rate": 3.5636987035251265e-06,
      "loss": 0.0,
      "step": 115050
    },
    {
      "epoch": 12.328297439194257,
      "grad_norm": 8.872165199136361e-05,
      "learning_rate": 3.5622700810743246e-06,
      "loss": 0.0,
      "step": 115060
    },
    {
      "epoch": 12.329368906032359,
      "grad_norm": 0.00033241035998798907,
      "learning_rate": 3.5608414586235222e-06,
      "loss": 0.1389,
      "step": 115070
    },
    {
      "epoch": 12.33044037287046,
      "grad_norm": 0.00044990202877670527,
      "learning_rate": 3.5594128361727208e-06,
      "loss": 0.0,
      "step": 115080
    },
    {
      "epoch": 12.331511839708561,
      "grad_norm": 0.0002766454708762467,
      "learning_rate": 3.557984213721919e-06,
      "loss": 0.0,
      "step": 115090
    },
    {
      "epoch": 12.332583306546663,
      "grad_norm": 0.0005032697808928788,
      "learning_rate": 3.556555591271117e-06,
      "loss": 0.0,
      "step": 115100
    },
    {
      "epoch": 12.333654773384763,
      "grad_norm": 9.629705891711637e-05,
      "learning_rate": 3.5551269688203155e-06,
      "loss": 0.0005,
      "step": 115110
    },
    {
      "epoch": 12.334726240222865,
      "grad_norm": 0.11738390475511551,
      "learning_rate": 3.5536983463695136e-06,
      "loss": 0.0002,
      "step": 115120
    },
    {
      "epoch": 12.335797707060966,
      "grad_norm": 8.02223730715923e-05,
      "learning_rate": 3.5522697239187117e-06,
      "loss": 0.0,
      "step": 115130
    },
    {
      "epoch": 12.336869173899068,
      "grad_norm": 7.816876313881949e-05,
      "learning_rate": 3.55084110146791e-06,
      "loss": 0.0,
      "step": 115140
    },
    {
      "epoch": 12.33794064073717,
      "grad_norm": 0.021207040175795555,
      "learning_rate": 3.549412479017108e-06,
      "loss": 0.0,
      "step": 115150
    },
    {
      "epoch": 12.33901210757527,
      "grad_norm": 9.628784755477682e-05,
      "learning_rate": 3.547983856566306e-06,
      "loss": 0.0,
      "step": 115160
    },
    {
      "epoch": 12.340083574413372,
      "grad_norm": 0.00038422923535108566,
      "learning_rate": 3.5465552341155045e-06,
      "loss": 0.0,
      "step": 115170
    },
    {
      "epoch": 12.341155041251474,
      "grad_norm": 0.00016569392755627632,
      "learning_rate": 3.5451266116647026e-06,
      "loss": 0.0,
      "step": 115180
    },
    {
      "epoch": 12.342226508089574,
      "grad_norm": 8.663396147312596e-05,
      "learning_rate": 3.5436979892139007e-06,
      "loss": 0.0,
      "step": 115190
    },
    {
      "epoch": 12.343297974927676,
      "grad_norm": 0.00029724216437898576,
      "learning_rate": 3.542269366763099e-06,
      "loss": 0.0,
      "step": 115200
    },
    {
      "epoch": 12.344369441765778,
      "grad_norm": 7.994626503204927e-05,
      "learning_rate": 3.5408407443122973e-06,
      "loss": 0.0,
      "step": 115210
    },
    {
      "epoch": 12.345440908603878,
      "grad_norm": 8.302398782689124e-05,
      "learning_rate": 3.5394121218614954e-06,
      "loss": 0.0,
      "step": 115220
    },
    {
      "epoch": 12.34651237544198,
      "grad_norm": 7.808182272128761e-05,
      "learning_rate": 3.537983499410694e-06,
      "loss": 0.0021,
      "step": 115230
    },
    {
      "epoch": 12.34758384228008,
      "grad_norm": 7.845246000215411e-05,
      "learning_rate": 3.5365548769598916e-06,
      "loss": 0.0,
      "step": 115240
    },
    {
      "epoch": 12.348655309118183,
      "grad_norm": 8.2803177065216e-05,
      "learning_rate": 3.5351262545090897e-06,
      "loss": 0.0,
      "step": 115250
    },
    {
      "epoch": 12.349726775956285,
      "grad_norm": 7.77278546593152e-05,
      "learning_rate": 3.533697632058288e-06,
      "loss": 0.0,
      "step": 115260
    },
    {
      "epoch": 12.350798242794385,
      "grad_norm": 0.00025027888477779925,
      "learning_rate": 3.5322690096074863e-06,
      "loss": 0.0,
      "step": 115270
    },
    {
      "epoch": 12.351869709632487,
      "grad_norm": 7.18503215466626e-05,
      "learning_rate": 3.5308403871566844e-06,
      "loss": 0.0,
      "step": 115280
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 0.00014072084741201252,
      "learning_rate": 3.529411764705883e-06,
      "loss": 0.0,
      "step": 115290
    },
    {
      "epoch": 12.354012643308689,
      "grad_norm": 7.885440572863445e-05,
      "learning_rate": 3.527983142255081e-06,
      "loss": 0.3327,
      "step": 115300
    },
    {
      "epoch": 12.355084110146791,
      "grad_norm": 0.0001493906311225146,
      "learning_rate": 3.526554519804279e-06,
      "loss": 0.0,
      "step": 115310
    },
    {
      "epoch": 12.356155576984893,
      "grad_norm": 8.435243216808885e-05,
      "learning_rate": 3.5251258973534776e-06,
      "loss": 0.0,
      "step": 115320
    },
    {
      "epoch": 12.357227043822993,
      "grad_norm": 7.443151844199747e-05,
      "learning_rate": 3.5236972749026753e-06,
      "loss": 0.0,
      "step": 115330
    },
    {
      "epoch": 12.358298510661095,
      "grad_norm": 8.131413778755814e-05,
      "learning_rate": 3.5222686524518734e-06,
      "loss": 0.1625,
      "step": 115340
    },
    {
      "epoch": 12.359369977499197,
      "grad_norm": 8.029377204366028e-05,
      "learning_rate": 3.520840030001072e-06,
      "loss": 0.0,
      "step": 115350
    },
    {
      "epoch": 12.360441444337297,
      "grad_norm": 0.0003581089258659631,
      "learning_rate": 3.51941140755027e-06,
      "loss": 0.0,
      "step": 115360
    },
    {
      "epoch": 12.3615129111754,
      "grad_norm": 7.232875941554084e-05,
      "learning_rate": 3.517982785099468e-06,
      "loss": 0.002,
      "step": 115370
    },
    {
      "epoch": 12.3625843780135,
      "grad_norm": 0.00018016272224485874,
      "learning_rate": 3.5165541626486666e-06,
      "loss": 0.0,
      "step": 115380
    },
    {
      "epoch": 12.363655844851602,
      "grad_norm": 7.544066465925425e-05,
      "learning_rate": 3.5151255401978647e-06,
      "loss": 0.0,
      "step": 115390
    },
    {
      "epoch": 12.364727311689704,
      "grad_norm": 0.0003048083162866533,
      "learning_rate": 3.5136969177470624e-06,
      "loss": 0.0,
      "step": 115400
    },
    {
      "epoch": 12.365798778527804,
      "grad_norm": 0.00015754920605104417,
      "learning_rate": 3.5122682952962613e-06,
      "loss": 0.0,
      "step": 115410
    },
    {
      "epoch": 12.366870245365906,
      "grad_norm": 0.013111713342368603,
      "learning_rate": 3.510839672845459e-06,
      "loss": 0.065,
      "step": 115420
    },
    {
      "epoch": 12.367941712204008,
      "grad_norm": 8.517780224792659e-05,
      "learning_rate": 3.509411050394657e-06,
      "loss": 0.0,
      "step": 115430
    },
    {
      "epoch": 12.369013179042108,
      "grad_norm": 0.0009266583365388215,
      "learning_rate": 3.5079824279438556e-06,
      "loss": 0.0001,
      "step": 115440
    },
    {
      "epoch": 12.37008464588021,
      "grad_norm": 7.684863521717489e-05,
      "learning_rate": 3.5065538054930537e-06,
      "loss": 0.0051,
      "step": 115450
    },
    {
      "epoch": 12.371156112718312,
      "grad_norm": 7.892520079622045e-05,
      "learning_rate": 3.505125183042252e-06,
      "loss": 0.0,
      "step": 115460
    },
    {
      "epoch": 12.372227579556412,
      "grad_norm": 7.48539823689498e-05,
      "learning_rate": 3.5036965605914503e-06,
      "loss": 0.0,
      "step": 115470
    },
    {
      "epoch": 12.373299046394514,
      "grad_norm": 7.626761362189427e-05,
      "learning_rate": 3.5022679381406484e-06,
      "loss": 0.0003,
      "step": 115480
    },
    {
      "epoch": 12.374370513232616,
      "grad_norm": 0.00011195539264008403,
      "learning_rate": 3.500839315689846e-06,
      "loss": 0.0831,
      "step": 115490
    },
    {
      "epoch": 12.375441980070716,
      "grad_norm": 8.23828304419294e-05,
      "learning_rate": 3.4994106932390446e-06,
      "loss": 0.0,
      "step": 115500
    },
    {
      "epoch": 12.376513446908818,
      "grad_norm": 7.419505709549412e-05,
      "learning_rate": 3.4979820707882427e-06,
      "loss": 0.0,
      "step": 115510
    },
    {
      "epoch": 12.377584913746919,
      "grad_norm": 9.096427675103769e-05,
      "learning_rate": 3.496553448337441e-06,
      "loss": 0.0,
      "step": 115520
    },
    {
      "epoch": 12.37865638058502,
      "grad_norm": 7.466529496014118e-05,
      "learning_rate": 3.495124825886639e-06,
      "loss": 0.0,
      "step": 115530
    },
    {
      "epoch": 12.379727847423123,
      "grad_norm": 7.212580385385081e-05,
      "learning_rate": 3.4936962034358374e-06,
      "loss": 0.0,
      "step": 115540
    },
    {
      "epoch": 12.380799314261223,
      "grad_norm": 6.800150731578469e-05,
      "learning_rate": 3.4922675809850355e-06,
      "loss": 0.0,
      "step": 115550
    },
    {
      "epoch": 12.381870781099325,
      "grad_norm": 0.00024156170547939837,
      "learning_rate": 3.490838958534233e-06,
      "loss": 0.0,
      "step": 115560
    },
    {
      "epoch": 12.382942247937427,
      "grad_norm": 7.580734381917864e-05,
      "learning_rate": 3.489410336083432e-06,
      "loss": 0.127,
      "step": 115570
    },
    {
      "epoch": 12.384013714775527,
      "grad_norm": 8.144612365867943e-05,
      "learning_rate": 3.48798171363263e-06,
      "loss": 0.0,
      "step": 115580
    },
    {
      "epoch": 12.38508518161363,
      "grad_norm": 0.0009725039126351476,
      "learning_rate": 3.486553091181828e-06,
      "loss": 0.0,
      "step": 115590
    },
    {
      "epoch": 12.386156648451731,
      "grad_norm": 0.0009701659437268972,
      "learning_rate": 3.4851244687310264e-06,
      "loss": 0.0,
      "step": 115600
    },
    {
      "epoch": 12.387228115289831,
      "grad_norm": 7.318766438402236e-05,
      "learning_rate": 3.4836958462802245e-06,
      "loss": 0.0,
      "step": 115610
    },
    {
      "epoch": 12.388299582127933,
      "grad_norm": 8.56077967910096e-05,
      "learning_rate": 3.4822672238294226e-06,
      "loss": 0.0,
      "step": 115620
    },
    {
      "epoch": 12.389371048966035,
      "grad_norm": 0.0001397862797603011,
      "learning_rate": 3.480838601378621e-06,
      "loss": 0.0001,
      "step": 115630
    },
    {
      "epoch": 12.390442515804136,
      "grad_norm": 0.1619109958410263,
      "learning_rate": 3.4794099789278192e-06,
      "loss": 0.0002,
      "step": 115640
    },
    {
      "epoch": 12.391513982642238,
      "grad_norm": 7.762019959045574e-05,
      "learning_rate": 3.477981356477017e-06,
      "loss": 0.0448,
      "step": 115650
    },
    {
      "epoch": 12.392585449480338,
      "grad_norm": 7.554905459983274e-05,
      "learning_rate": 3.476552734026216e-06,
      "loss": 0.2594,
      "step": 115660
    },
    {
      "epoch": 12.39365691631844,
      "grad_norm": 8.18128974060528e-05,
      "learning_rate": 3.4751241115754135e-06,
      "loss": 0.0,
      "step": 115670
    },
    {
      "epoch": 12.394728383156542,
      "grad_norm": 8.880653331289068e-05,
      "learning_rate": 3.4736954891246116e-06,
      "loss": 0.1881,
      "step": 115680
    },
    {
      "epoch": 12.395799849994642,
      "grad_norm": 0.00021201650088187307,
      "learning_rate": 3.47226686667381e-06,
      "loss": 0.0,
      "step": 115690
    },
    {
      "epoch": 12.396871316832744,
      "grad_norm": 0.0001664663286646828,
      "learning_rate": 3.4708382442230082e-06,
      "loss": 0.0019,
      "step": 115700
    },
    {
      "epoch": 12.397942783670846,
      "grad_norm": 0.0014633407117798924,
      "learning_rate": 3.4694096217722063e-06,
      "loss": 0.0,
      "step": 115710
    },
    {
      "epoch": 12.399014250508946,
      "grad_norm": 7.463427755283192e-05,
      "learning_rate": 3.467980999321405e-06,
      "loss": 0.0,
      "step": 115720
    },
    {
      "epoch": 12.400085717347048,
      "grad_norm": 7.570604793727398e-05,
      "learning_rate": 3.466552376870603e-06,
      "loss": 0.0,
      "step": 115730
    },
    {
      "epoch": 12.40115718418515,
      "grad_norm": 0.0004015248268842697,
      "learning_rate": 3.4651237544198006e-06,
      "loss": 0.0,
      "step": 115740
    },
    {
      "epoch": 12.40222865102325,
      "grad_norm": 0.0004564055416267365,
      "learning_rate": 3.463695131968999e-06,
      "loss": 0.0,
      "step": 115750
    },
    {
      "epoch": 12.403300117861352,
      "grad_norm": 7.010235276538879e-05,
      "learning_rate": 3.4622665095181972e-06,
      "loss": 0.0002,
      "step": 115760
    },
    {
      "epoch": 12.404371584699454,
      "grad_norm": 0.00015267527487594634,
      "learning_rate": 3.4608378870673953e-06,
      "loss": 0.0,
      "step": 115770
    },
    {
      "epoch": 12.405443051537555,
      "grad_norm": 0.007304645609110594,
      "learning_rate": 3.459409264616594e-06,
      "loss": 0.0,
      "step": 115780
    },
    {
      "epoch": 12.406514518375657,
      "grad_norm": 0.002359685953706503,
      "learning_rate": 3.457980642165792e-06,
      "loss": 0.0,
      "step": 115790
    },
    {
      "epoch": 12.407585985213757,
      "grad_norm": 8.363798406207934e-05,
      "learning_rate": 3.45655201971499e-06,
      "loss": 0.0,
      "step": 115800
    },
    {
      "epoch": 12.408657452051859,
      "grad_norm": 0.0003958938759751618,
      "learning_rate": 3.4551233972641885e-06,
      "loss": 0.0,
      "step": 115810
    },
    {
      "epoch": 12.40972891888996,
      "grad_norm": 0.5437725782394409,
      "learning_rate": 3.4536947748133866e-06,
      "loss": 0.0001,
      "step": 115820
    },
    {
      "epoch": 12.410800385728061,
      "grad_norm": 0.00015794235514476895,
      "learning_rate": 3.4522661523625843e-06,
      "loss": 0.0005,
      "step": 115830
    },
    {
      "epoch": 12.411871852566163,
      "grad_norm": 0.00025404305779375136,
      "learning_rate": 3.450837529911783e-06,
      "loss": 0.0,
      "step": 115840
    },
    {
      "epoch": 12.412943319404265,
      "grad_norm": 0.0002044344146270305,
      "learning_rate": 3.449408907460981e-06,
      "loss": 0.0,
      "step": 115850
    },
    {
      "epoch": 12.414014786242365,
      "grad_norm": 0.0002892466145567596,
      "learning_rate": 3.447980285010179e-06,
      "loss": 0.0,
      "step": 115860
    },
    {
      "epoch": 12.415086253080467,
      "grad_norm": 0.00015565201465506107,
      "learning_rate": 3.4465516625593775e-06,
      "loss": 0.0,
      "step": 115870
    },
    {
      "epoch": 12.41615771991857,
      "grad_norm": 7.426074444083497e-05,
      "learning_rate": 3.4451230401085756e-06,
      "loss": 0.0,
      "step": 115880
    },
    {
      "epoch": 12.41722918675667,
      "grad_norm": 0.0010707869660109282,
      "learning_rate": 3.4436944176577737e-06,
      "loss": 0.3201,
      "step": 115890
    },
    {
      "epoch": 12.418300653594772,
      "grad_norm": 7.904590893303975e-05,
      "learning_rate": 3.4422657952069723e-06,
      "loss": 0.0002,
      "step": 115900
    },
    {
      "epoch": 12.419372120432872,
      "grad_norm": 7.96148378867656e-05,
      "learning_rate": 3.44083717275617e-06,
      "loss": 0.0,
      "step": 115910
    },
    {
      "epoch": 12.420443587270974,
      "grad_norm": 6.997691525612026e-05,
      "learning_rate": 3.439408550305368e-06,
      "loss": 0.0,
      "step": 115920
    },
    {
      "epoch": 12.421515054109076,
      "grad_norm": 0.00015594663273077458,
      "learning_rate": 3.4379799278545665e-06,
      "loss": 0.0,
      "step": 115930
    },
    {
      "epoch": 12.422586520947176,
      "grad_norm": 0.02385335974395275,
      "learning_rate": 3.4365513054037646e-06,
      "loss": 0.0,
      "step": 115940
    },
    {
      "epoch": 12.423657987785278,
      "grad_norm": 7.580257079098374e-05,
      "learning_rate": 3.4351226829529627e-06,
      "loss": 0.0018,
      "step": 115950
    },
    {
      "epoch": 12.42472945462338,
      "grad_norm": 8.651560347061604e-05,
      "learning_rate": 3.4336940605021613e-06,
      "loss": 0.0,
      "step": 115960
    },
    {
      "epoch": 12.42580092146148,
      "grad_norm": 7.121240196283907e-05,
      "learning_rate": 3.4322654380513594e-06,
      "loss": 0.0,
      "step": 115970
    },
    {
      "epoch": 12.426872388299582,
      "grad_norm": 6.905948248459026e-05,
      "learning_rate": 3.4308368156005574e-06,
      "loss": 0.0,
      "step": 115980
    },
    {
      "epoch": 12.427943855137684,
      "grad_norm": 7.653216744074598e-05,
      "learning_rate": 3.429408193149756e-06,
      "loss": 0.0001,
      "step": 115990
    },
    {
      "epoch": 12.429015321975784,
      "grad_norm": 7.130880112526938e-05,
      "learning_rate": 3.4279795706989536e-06,
      "loss": 0.0007,
      "step": 116000
    },
    {
      "epoch": 12.430086788813886,
      "grad_norm": 0.0007571409223601222,
      "learning_rate": 3.4265509482481517e-06,
      "loss": 0.0,
      "step": 116010
    },
    {
      "epoch": 12.431158255651988,
      "grad_norm": 0.000879614264704287,
      "learning_rate": 3.4251223257973503e-06,
      "loss": 0.0,
      "step": 116020
    },
    {
      "epoch": 12.432229722490089,
      "grad_norm": 7.31782492948696e-05,
      "learning_rate": 3.4236937033465483e-06,
      "loss": 0.1272,
      "step": 116030
    },
    {
      "epoch": 12.43330118932819,
      "grad_norm": 0.603531002998352,
      "learning_rate": 3.4222650808957464e-06,
      "loss": 0.0657,
      "step": 116040
    },
    {
      "epoch": 12.43437265616629,
      "grad_norm": 7.529548020102084e-05,
      "learning_rate": 3.420836458444945e-06,
      "loss": 0.0,
      "step": 116050
    },
    {
      "epoch": 12.435444123004393,
      "grad_norm": 0.00048129245988093317,
      "learning_rate": 3.419407835994143e-06,
      "loss": 0.0,
      "step": 116060
    },
    {
      "epoch": 12.436515589842495,
      "grad_norm": 7.241569983307272e-05,
      "learning_rate": 3.417979213543341e-06,
      "loss": 0.0,
      "step": 116070
    },
    {
      "epoch": 12.437587056680595,
      "grad_norm": 0.0004658883553929627,
      "learning_rate": 3.4165505910925397e-06,
      "loss": 0.0,
      "step": 116080
    },
    {
      "epoch": 12.438658523518697,
      "grad_norm": 0.0004925403627566993,
      "learning_rate": 3.4151219686417373e-06,
      "loss": 0.1258,
      "step": 116090
    },
    {
      "epoch": 12.439729990356799,
      "grad_norm": 0.0004592740151565522,
      "learning_rate": 3.4136933461909354e-06,
      "loss": 0.0,
      "step": 116100
    },
    {
      "epoch": 12.4408014571949,
      "grad_norm": 0.0010715459939092398,
      "learning_rate": 3.412264723740134e-06,
      "loss": 0.0,
      "step": 116110
    },
    {
      "epoch": 12.441872924033001,
      "grad_norm": 9.00149461813271e-05,
      "learning_rate": 3.410836101289332e-06,
      "loss": 0.0,
      "step": 116120
    },
    {
      "epoch": 12.442944390871103,
      "grad_norm": 0.000675227667670697,
      "learning_rate": 3.40940747883853e-06,
      "loss": 0.0,
      "step": 116130
    },
    {
      "epoch": 12.444015857709203,
      "grad_norm": 0.00020022699027322233,
      "learning_rate": 3.4079788563877287e-06,
      "loss": 0.0,
      "step": 116140
    },
    {
      "epoch": 12.445087324547305,
      "grad_norm": 0.00029240312869660556,
      "learning_rate": 3.4065502339369268e-06,
      "loss": 0.0,
      "step": 116150
    },
    {
      "epoch": 12.446158791385407,
      "grad_norm": 8.832099410938099e-05,
      "learning_rate": 3.4051216114861244e-06,
      "loss": 0.0,
      "step": 116160
    },
    {
      "epoch": 12.447230258223508,
      "grad_norm": 0.16778621077537537,
      "learning_rate": 3.4036929890353234e-06,
      "loss": 0.0001,
      "step": 116170
    },
    {
      "epoch": 12.44830172506161,
      "grad_norm": 0.00035304558696225286,
      "learning_rate": 3.402264366584521e-06,
      "loss": 0.0,
      "step": 116180
    },
    {
      "epoch": 12.44937319189971,
      "grad_norm": 6.886231858516112e-05,
      "learning_rate": 3.400835744133719e-06,
      "loss": 0.0011,
      "step": 116190
    },
    {
      "epoch": 12.450444658737812,
      "grad_norm": 0.0002816664637066424,
      "learning_rate": 3.3994071216829177e-06,
      "loss": 0.0,
      "step": 116200
    },
    {
      "epoch": 12.451516125575914,
      "grad_norm": 6.77165953675285e-05,
      "learning_rate": 3.3979784992321158e-06,
      "loss": 0.0,
      "step": 116210
    },
    {
      "epoch": 12.452587592414014,
      "grad_norm": 0.000208677927730605,
      "learning_rate": 3.396549876781314e-06,
      "loss": 0.0,
      "step": 116220
    },
    {
      "epoch": 12.453659059252116,
      "grad_norm": 7.300255674635991e-05,
      "learning_rate": 3.3951212543305124e-06,
      "loss": 0.0,
      "step": 116230
    },
    {
      "epoch": 12.454730526090218,
      "grad_norm": 6.841996219009161e-05,
      "learning_rate": 3.3936926318797105e-06,
      "loss": 0.0005,
      "step": 116240
    },
    {
      "epoch": 12.455801992928318,
      "grad_norm": 0.0002974832314066589,
      "learning_rate": 3.392264009428908e-06,
      "loss": 0.0,
      "step": 116250
    },
    {
      "epoch": 12.45687345976642,
      "grad_norm": 0.00015564939531031996,
      "learning_rate": 3.3908353869781067e-06,
      "loss": 0.0,
      "step": 116260
    },
    {
      "epoch": 12.457944926604522,
      "grad_norm": 0.0007384385098703206,
      "learning_rate": 3.3894067645273048e-06,
      "loss": 0.0,
      "step": 116270
    },
    {
      "epoch": 12.459016393442623,
      "grad_norm": 7.432582788169384e-05,
      "learning_rate": 3.387978142076503e-06,
      "loss": 0.0001,
      "step": 116280
    },
    {
      "epoch": 12.460087860280725,
      "grad_norm": 7.230251503642648e-05,
      "learning_rate": 3.3865495196257014e-06,
      "loss": 0.0003,
      "step": 116290
    },
    {
      "epoch": 12.461159327118825,
      "grad_norm": 6.695339834550396e-05,
      "learning_rate": 3.3851208971748995e-06,
      "loss": 0.0,
      "step": 116300
    },
    {
      "epoch": 12.462230793956927,
      "grad_norm": 7.545694097643718e-05,
      "learning_rate": 3.3836922747240976e-06,
      "loss": 0.0,
      "step": 116310
    },
    {
      "epoch": 12.463302260795029,
      "grad_norm": 6.619344640057534e-05,
      "learning_rate": 3.382263652273296e-06,
      "loss": 0.1135,
      "step": 116320
    },
    {
      "epoch": 12.464373727633129,
      "grad_norm": 6.944090273464099e-05,
      "learning_rate": 3.380835029822494e-06,
      "loss": 0.0,
      "step": 116330
    },
    {
      "epoch": 12.465445194471231,
      "grad_norm": 6.17566256551072e-05,
      "learning_rate": 3.379406407371692e-06,
      "loss": 0.0,
      "step": 116340
    },
    {
      "epoch": 12.466516661309333,
      "grad_norm": 0.00023160736600402743,
      "learning_rate": 3.3779777849208904e-06,
      "loss": 0.2204,
      "step": 116350
    },
    {
      "epoch": 12.467588128147433,
      "grad_norm": 0.00019231982878409326,
      "learning_rate": 3.3765491624700885e-06,
      "loss": 0.0,
      "step": 116360
    },
    {
      "epoch": 12.468659594985535,
      "grad_norm": 0.00023884001711849123,
      "learning_rate": 3.3751205400192866e-06,
      "loss": 0.0,
      "step": 116370
    },
    {
      "epoch": 12.469731061823637,
      "grad_norm": 7.297278352780268e-05,
      "learning_rate": 3.373691917568485e-06,
      "loss": 0.0,
      "step": 116380
    },
    {
      "epoch": 12.470802528661737,
      "grad_norm": 0.000406692415708676,
      "learning_rate": 3.372263295117683e-06,
      "loss": 0.0,
      "step": 116390
    },
    {
      "epoch": 12.47187399549984,
      "grad_norm": 8.308875112561509e-05,
      "learning_rate": 3.3708346726668813e-06,
      "loss": 0.0,
      "step": 116400
    },
    {
      "epoch": 12.472945462337941,
      "grad_norm": 7.086725963745266e-05,
      "learning_rate": 3.36940605021608e-06,
      "loss": 0.0,
      "step": 116410
    },
    {
      "epoch": 12.474016929176042,
      "grad_norm": 6.789007602492347e-05,
      "learning_rate": 3.367977427765278e-06,
      "loss": 0.0,
      "step": 116420
    },
    {
      "epoch": 12.475088396014144,
      "grad_norm": 0.0002017855877056718,
      "learning_rate": 3.3665488053144756e-06,
      "loss": 0.004,
      "step": 116430
    },
    {
      "epoch": 12.476159862852244,
      "grad_norm": 7.92836508480832e-05,
      "learning_rate": 3.3651201828636737e-06,
      "loss": 0.0,
      "step": 116440
    },
    {
      "epoch": 12.477231329690346,
      "grad_norm": 0.00023566062736790627,
      "learning_rate": 3.363691560412872e-06,
      "loss": 0.1012,
      "step": 116450
    },
    {
      "epoch": 12.478302796528448,
      "grad_norm": 0.00010847979137906805,
      "learning_rate": 3.3622629379620703e-06,
      "loss": 0.0,
      "step": 116460
    },
    {
      "epoch": 12.479374263366548,
      "grad_norm": 0.0020251839887350798,
      "learning_rate": 3.3608343155112684e-06,
      "loss": 0.01,
      "step": 116470
    },
    {
      "epoch": 12.48044573020465,
      "grad_norm": 6.958946323720738e-05,
      "learning_rate": 3.359405693060467e-06,
      "loss": 0.0,
      "step": 116480
    },
    {
      "epoch": 12.481517197042752,
      "grad_norm": 0.0002529537887312472,
      "learning_rate": 3.357977070609665e-06,
      "loss": 0.0,
      "step": 116490
    },
    {
      "epoch": 12.482588663880852,
      "grad_norm": 6.49375215289183e-05,
      "learning_rate": 3.3565484481588627e-06,
      "loss": 0.0,
      "step": 116500
    },
    {
      "epoch": 12.483660130718954,
      "grad_norm": 8.820153016131371e-05,
      "learning_rate": 3.355119825708061e-06,
      "loss": 0.0,
      "step": 116510
    },
    {
      "epoch": 12.484731597557056,
      "grad_norm": 0.01860719732940197,
      "learning_rate": 3.3536912032572593e-06,
      "loss": 0.0,
      "step": 116520
    },
    {
      "epoch": 12.485803064395157,
      "grad_norm": 6.887216295581311e-05,
      "learning_rate": 3.3522625808064574e-06,
      "loss": 0.0,
      "step": 116530
    },
    {
      "epoch": 12.486874531233259,
      "grad_norm": 35.2386360168457,
      "learning_rate": 3.350833958355656e-06,
      "loss": 0.0036,
      "step": 116540
    },
    {
      "epoch": 12.48794599807136,
      "grad_norm": 6.908984505571425e-05,
      "learning_rate": 3.349405335904854e-06,
      "loss": 0.0,
      "step": 116550
    },
    {
      "epoch": 12.48901746490946,
      "grad_norm": 7.030347478576005e-05,
      "learning_rate": 3.347976713454052e-06,
      "loss": 0.0,
      "step": 116560
    },
    {
      "epoch": 12.490088931747563,
      "grad_norm": 7.429018296534196e-05,
      "learning_rate": 3.3465480910032506e-06,
      "loss": 0.0,
      "step": 116570
    },
    {
      "epoch": 12.491160398585663,
      "grad_norm": 7.407827797578648e-05,
      "learning_rate": 3.3451194685524487e-06,
      "loss": 0.0,
      "step": 116580
    },
    {
      "epoch": 12.492231865423765,
      "grad_norm": 7.705217285547405e-05,
      "learning_rate": 3.3436908461016464e-06,
      "loss": 0.0,
      "step": 116590
    },
    {
      "epoch": 12.493303332261867,
      "grad_norm": 7.00152013450861e-05,
      "learning_rate": 3.342262223650845e-06,
      "loss": 0.0,
      "step": 116600
    },
    {
      "epoch": 12.494374799099967,
      "grad_norm": 6.974257121328264e-05,
      "learning_rate": 3.340833601200043e-06,
      "loss": 0.0,
      "step": 116610
    },
    {
      "epoch": 12.49544626593807,
      "grad_norm": 8.070221520029008e-05,
      "learning_rate": 3.339404978749241e-06,
      "loss": 0.0,
      "step": 116620
    },
    {
      "epoch": 12.496517732776171,
      "grad_norm": 0.0002371590817347169,
      "learning_rate": 3.3379763562984396e-06,
      "loss": 0.0,
      "step": 116630
    },
    {
      "epoch": 12.497589199614271,
      "grad_norm": 0.00014285864017438143,
      "learning_rate": 3.3365477338476377e-06,
      "loss": 0.0,
      "step": 116640
    },
    {
      "epoch": 12.498660666452373,
      "grad_norm": 6.859051791252568e-05,
      "learning_rate": 3.335119111396836e-06,
      "loss": 0.0001,
      "step": 116650
    },
    {
      "epoch": 12.499732133290475,
      "grad_norm": 6.700655649183318e-05,
      "learning_rate": 3.3336904889460343e-06,
      "loss": 0.0,
      "step": 116660
    },
    {
      "epoch": 12.500803600128576,
      "grad_norm": 6.988393579376861e-05,
      "learning_rate": 3.332261866495232e-06,
      "loss": 0.2611,
      "step": 116670
    },
    {
      "epoch": 12.501875066966678,
      "grad_norm": 7.269920024555176e-05,
      "learning_rate": 3.33083324404443e-06,
      "loss": 0.0,
      "step": 116680
    },
    {
      "epoch": 12.502946533804778,
      "grad_norm": 9.791025513550267e-05,
      "learning_rate": 3.3294046215936286e-06,
      "loss": 0.0002,
      "step": 116690
    },
    {
      "epoch": 12.50401800064288,
      "grad_norm": 7.579974044347182e-05,
      "learning_rate": 3.3279759991428267e-06,
      "loss": 0.0,
      "step": 116700
    },
    {
      "epoch": 12.505089467480982,
      "grad_norm": 0.0002478380047250539,
      "learning_rate": 3.326547376692025e-06,
      "loss": 0.0,
      "step": 116710
    },
    {
      "epoch": 12.506160934319082,
      "grad_norm": 0.00020641017181333154,
      "learning_rate": 3.3251187542412233e-06,
      "loss": 0.0,
      "step": 116720
    },
    {
      "epoch": 12.507232401157184,
      "grad_norm": 0.00021467670740094036,
      "learning_rate": 3.3236901317904214e-06,
      "loss": 0.0,
      "step": 116730
    },
    {
      "epoch": 12.508303867995286,
      "grad_norm": 0.0003265940467827022,
      "learning_rate": 3.3222615093396195e-06,
      "loss": 0.0,
      "step": 116740
    },
    {
      "epoch": 12.509375334833386,
      "grad_norm": 0.00027578321169130504,
      "learning_rate": 3.320832886888818e-06,
      "loss": 0.0,
      "step": 116750
    },
    {
      "epoch": 12.510446801671488,
      "grad_norm": 6.453063542721793e-05,
      "learning_rate": 3.3194042644380157e-06,
      "loss": 0.0083,
      "step": 116760
    },
    {
      "epoch": 12.51151826850959,
      "grad_norm": 0.0005191005184315145,
      "learning_rate": 3.317975641987214e-06,
      "loss": 0.0,
      "step": 116770
    },
    {
      "epoch": 12.51258973534769,
      "grad_norm": 7.326808554353192e-05,
      "learning_rate": 3.3165470195364123e-06,
      "loss": 0.0,
      "step": 116780
    },
    {
      "epoch": 12.513661202185792,
      "grad_norm": 0.00033184600761160254,
      "learning_rate": 3.3151183970856104e-06,
      "loss": 0.0,
      "step": 116790
    },
    {
      "epoch": 12.514732669023894,
      "grad_norm": 0.0002339836792089045,
      "learning_rate": 3.3136897746348085e-06,
      "loss": 0.0,
      "step": 116800
    },
    {
      "epoch": 12.515804135861995,
      "grad_norm": 7.686080789426342e-05,
      "learning_rate": 3.312261152184007e-06,
      "loss": 0.0,
      "step": 116810
    },
    {
      "epoch": 12.516875602700097,
      "grad_norm": 6.847815529908985e-05,
      "learning_rate": 3.310832529733205e-06,
      "loss": 0.0,
      "step": 116820
    },
    {
      "epoch": 12.517947069538199,
      "grad_norm": 8.107712346827611e-05,
      "learning_rate": 3.309403907282403e-06,
      "loss": 0.0,
      "step": 116830
    },
    {
      "epoch": 12.519018536376299,
      "grad_norm": 0.00012330751633271575,
      "learning_rate": 3.3079752848316018e-06,
      "loss": 0.0,
      "step": 116840
    },
    {
      "epoch": 12.520090003214401,
      "grad_norm": 0.0002027217560680583,
      "learning_rate": 3.3065466623807994e-06,
      "loss": 0.0,
      "step": 116850
    },
    {
      "epoch": 12.521161470052501,
      "grad_norm": 7.143061520764604e-05,
      "learning_rate": 3.3051180399299975e-06,
      "loss": 0.0003,
      "step": 116860
    },
    {
      "epoch": 12.522232936890603,
      "grad_norm": 0.00012285588309168816,
      "learning_rate": 3.303689417479196e-06,
      "loss": 0.0,
      "step": 116870
    },
    {
      "epoch": 12.523304403728705,
      "grad_norm": 0.0001613318017916754,
      "learning_rate": 3.302260795028394e-06,
      "loss": 0.0,
      "step": 116880
    },
    {
      "epoch": 12.524375870566805,
      "grad_norm": 6.314146594377235e-05,
      "learning_rate": 3.3008321725775922e-06,
      "loss": 0.0,
      "step": 116890
    },
    {
      "epoch": 12.525447337404907,
      "grad_norm": 0.025172334164381027,
      "learning_rate": 3.2994035501267908e-06,
      "loss": 0.0,
      "step": 116900
    },
    {
      "epoch": 12.52651880424301,
      "grad_norm": 6.130815745564178e-05,
      "learning_rate": 3.297974927675989e-06,
      "loss": 0.0,
      "step": 116910
    },
    {
      "epoch": 12.52759027108111,
      "grad_norm": 0.0002538554253987968,
      "learning_rate": 3.2965463052251865e-06,
      "loss": 0.0,
      "step": 116920
    },
    {
      "epoch": 12.528661737919212,
      "grad_norm": 0.0007311005610972643,
      "learning_rate": 3.2951176827743855e-06,
      "loss": 0.0,
      "step": 116930
    },
    {
      "epoch": 12.529733204757314,
      "grad_norm": 6.060904706828296e-05,
      "learning_rate": 3.293689060323583e-06,
      "loss": 0.0001,
      "step": 116940
    },
    {
      "epoch": 12.530804671595414,
      "grad_norm": 0.00030851660994812846,
      "learning_rate": 3.2922604378727812e-06,
      "loss": 0.0,
      "step": 116950
    },
    {
      "epoch": 12.531876138433516,
      "grad_norm": 7.057910988805816e-05,
      "learning_rate": 3.2908318154219798e-06,
      "loss": 0.0002,
      "step": 116960
    },
    {
      "epoch": 12.532947605271616,
      "grad_norm": 0.00034547707764431834,
      "learning_rate": 3.289403192971178e-06,
      "loss": 0.0,
      "step": 116970
    },
    {
      "epoch": 12.534019072109718,
      "grad_norm": 0.0001164208006230183,
      "learning_rate": 3.287974570520376e-06,
      "loss": 0.0,
      "step": 116980
    },
    {
      "epoch": 12.53509053894782,
      "grad_norm": 0.0001720365835353732,
      "learning_rate": 3.2865459480695745e-06,
      "loss": 0.0,
      "step": 116990
    },
    {
      "epoch": 12.53616200578592,
      "grad_norm": 7.573805487481877e-05,
      "learning_rate": 3.2851173256187726e-06,
      "loss": 0.0,
      "step": 117000
    },
    {
      "epoch": 12.537233472624022,
      "grad_norm": 6.862744339741766e-05,
      "learning_rate": 3.2836887031679702e-06,
      "loss": 0.0,
      "step": 117010
    },
    {
      "epoch": 12.538304939462124,
      "grad_norm": 7.694912346778437e-05,
      "learning_rate": 3.2822600807171688e-06,
      "loss": 0.0,
      "step": 117020
    },
    {
      "epoch": 12.539376406300224,
      "grad_norm": 0.00016740361752454191,
      "learning_rate": 3.280831458266367e-06,
      "loss": 0.0,
      "step": 117030
    },
    {
      "epoch": 12.540447873138326,
      "grad_norm": 6.611191929550841e-05,
      "learning_rate": 3.279402835815565e-06,
      "loss": 0.0,
      "step": 117040
    },
    {
      "epoch": 12.541519339976428,
      "grad_norm": 0.00014505954459309578,
      "learning_rate": 3.2779742133647635e-06,
      "loss": 0.0,
      "step": 117050
    },
    {
      "epoch": 12.542590806814529,
      "grad_norm": 6.708968430757523e-05,
      "learning_rate": 3.2765455909139616e-06,
      "loss": 0.0,
      "step": 117060
    },
    {
      "epoch": 12.54366227365263,
      "grad_norm": 6.629382551182061e-05,
      "learning_rate": 3.2751169684631597e-06,
      "loss": 0.0,
      "step": 117070
    },
    {
      "epoch": 12.544733740490733,
      "grad_norm": 8.688936213729903e-05,
      "learning_rate": 3.273688346012358e-06,
      "loss": 0.0,
      "step": 117080
    },
    {
      "epoch": 12.545805207328833,
      "grad_norm": 0.00013727125769946724,
      "learning_rate": 3.2722597235615563e-06,
      "loss": 0.0,
      "step": 117090
    },
    {
      "epoch": 12.546876674166935,
      "grad_norm": 8.574985986342654e-05,
      "learning_rate": 3.270831101110754e-06,
      "loss": 0.0,
      "step": 117100
    },
    {
      "epoch": 12.547948141005035,
      "grad_norm": 0.0006875062827020884,
      "learning_rate": 3.2694024786599525e-06,
      "loss": 0.0,
      "step": 117110
    },
    {
      "epoch": 12.549019607843137,
      "grad_norm": 6.398540426744148e-05,
      "learning_rate": 3.2679738562091506e-06,
      "loss": 0.0,
      "step": 117120
    },
    {
      "epoch": 12.550091074681239,
      "grad_norm": 0.00047964774421416223,
      "learning_rate": 3.2665452337583487e-06,
      "loss": 0.0,
      "step": 117130
    },
    {
      "epoch": 12.55116254151934,
      "grad_norm": 0.00014160863065626472,
      "learning_rate": 3.265116611307547e-06,
      "loss": 0.0009,
      "step": 117140
    },
    {
      "epoch": 12.552234008357441,
      "grad_norm": 0.00019993660680484027,
      "learning_rate": 3.2636879888567453e-06,
      "loss": 0.0,
      "step": 117150
    },
    {
      "epoch": 12.553305475195543,
      "grad_norm": 7.166741124819964e-05,
      "learning_rate": 3.2622593664059434e-06,
      "loss": 0.0,
      "step": 117160
    },
    {
      "epoch": 12.554376942033644,
      "grad_norm": 0.00012447903282009065,
      "learning_rate": 3.260830743955142e-06,
      "loss": 0.0,
      "step": 117170
    },
    {
      "epoch": 12.555448408871746,
      "grad_norm": 0.00014082473353482783,
      "learning_rate": 3.2594021215043396e-06,
      "loss": 0.0,
      "step": 117180
    },
    {
      "epoch": 12.556519875709848,
      "grad_norm": 7.781733438605443e-05,
      "learning_rate": 3.2579734990535377e-06,
      "loss": 0.0,
      "step": 117190
    },
    {
      "epoch": 12.557591342547948,
      "grad_norm": 6.745119753759354e-05,
      "learning_rate": 3.256544876602736e-06,
      "loss": 0.0,
      "step": 117200
    },
    {
      "epoch": 12.55866280938605,
      "grad_norm": 0.00013269225019030273,
      "learning_rate": 3.2551162541519343e-06,
      "loss": 0.0,
      "step": 117210
    },
    {
      "epoch": 12.559734276224152,
      "grad_norm": 7.323315367102623e-05,
      "learning_rate": 3.2536876317011324e-06,
      "loss": 0.0,
      "step": 117220
    },
    {
      "epoch": 12.560805743062252,
      "grad_norm": 7.345935591729358e-05,
      "learning_rate": 3.252259009250331e-06,
      "loss": 0.0,
      "step": 117230
    },
    {
      "epoch": 12.561877209900354,
      "grad_norm": 0.00040301313856616616,
      "learning_rate": 3.250830386799529e-06,
      "loss": 0.0,
      "step": 117240
    },
    {
      "epoch": 12.562948676738454,
      "grad_norm": 0.00018806483421940356,
      "learning_rate": 3.249401764348727e-06,
      "loss": 0.0,
      "step": 117250
    },
    {
      "epoch": 12.564020143576556,
      "grad_norm": 8.43341913423501e-05,
      "learning_rate": 3.2479731418979256e-06,
      "loss": 0.2563,
      "step": 117260
    },
    {
      "epoch": 12.565091610414658,
      "grad_norm": 7.097595516825095e-05,
      "learning_rate": 3.2465445194471233e-06,
      "loss": 0.0,
      "step": 117270
    },
    {
      "epoch": 12.566163077252758,
      "grad_norm": 0.0020026518031954765,
      "learning_rate": 3.2451158969963214e-06,
      "loss": 0.0,
      "step": 117280
    },
    {
      "epoch": 12.56723454409086,
      "grad_norm": 0.0008592355297878385,
      "learning_rate": 3.24368727454552e-06,
      "loss": 0.0,
      "step": 117290
    },
    {
      "epoch": 12.568306010928962,
      "grad_norm": 8.03071161499247e-05,
      "learning_rate": 3.242258652094718e-06,
      "loss": 0.0026,
      "step": 117300
    },
    {
      "epoch": 12.569377477767063,
      "grad_norm": 7.404464122373611e-05,
      "learning_rate": 3.240830029643916e-06,
      "loss": 0.0002,
      "step": 117310
    },
    {
      "epoch": 12.570448944605165,
      "grad_norm": 0.007189822383224964,
      "learning_rate": 3.2394014071931146e-06,
      "loss": 0.2598,
      "step": 117320
    },
    {
      "epoch": 12.571520411443267,
      "grad_norm": 0.0002245980140287429,
      "learning_rate": 3.2379727847423127e-06,
      "loss": 0.0,
      "step": 117330
    },
    {
      "epoch": 12.572591878281367,
      "grad_norm": 7.515535980928689e-05,
      "learning_rate": 3.236544162291511e-06,
      "loss": 0.0,
      "step": 117340
    },
    {
      "epoch": 12.573663345119469,
      "grad_norm": 6.483300239779055e-05,
      "learning_rate": 3.2351155398407085e-06,
      "loss": 0.0011,
      "step": 117350
    },
    {
      "epoch": 12.574734811957569,
      "grad_norm": 7.769995863782242e-05,
      "learning_rate": 3.233686917389907e-06,
      "loss": 0.3431,
      "step": 117360
    },
    {
      "epoch": 12.575806278795671,
      "grad_norm": 6.60753357806243e-05,
      "learning_rate": 3.232258294939105e-06,
      "loss": 0.0,
      "step": 117370
    },
    {
      "epoch": 12.576877745633773,
      "grad_norm": 0.00018169246322941035,
      "learning_rate": 3.230829672488303e-06,
      "loss": 0.0,
      "step": 117380
    },
    {
      "epoch": 12.577949212471873,
      "grad_norm": 0.00022758370323572308,
      "learning_rate": 3.2294010500375017e-06,
      "loss": 0.0,
      "step": 117390
    },
    {
      "epoch": 12.579020679309975,
      "grad_norm": 0.00016462824714835733,
      "learning_rate": 3.2279724275866998e-06,
      "loss": 0.1634,
      "step": 117400
    },
    {
      "epoch": 12.580092146148077,
      "grad_norm": 7.316228584386408e-05,
      "learning_rate": 3.226543805135898e-06,
      "loss": 0.0,
      "step": 117410
    },
    {
      "epoch": 12.581163612986177,
      "grad_norm": 6.997526361374184e-05,
      "learning_rate": 3.2251151826850964e-06,
      "loss": 0.0,
      "step": 117420
    },
    {
      "epoch": 12.58223507982428,
      "grad_norm": 0.0004352177493274212,
      "learning_rate": 3.223686560234294e-06,
      "loss": 0.2232,
      "step": 117430
    },
    {
      "epoch": 12.583306546662381,
      "grad_norm": 9.315956413047388e-05,
      "learning_rate": 3.222257937783492e-06,
      "loss": 0.0001,
      "step": 117440
    },
    {
      "epoch": 12.584378013500482,
      "grad_norm": 6.891466910019517e-05,
      "learning_rate": 3.2208293153326907e-06,
      "loss": 0.0,
      "step": 117450
    },
    {
      "epoch": 12.585449480338584,
      "grad_norm": 1.0021668672561646,
      "learning_rate": 3.2194006928818888e-06,
      "loss": 0.0002,
      "step": 117460
    },
    {
      "epoch": 12.586520947176686,
      "grad_norm": 0.00023841277288738638,
      "learning_rate": 3.217972070431087e-06,
      "loss": 0.0026,
      "step": 117470
    },
    {
      "epoch": 12.587592414014786,
      "grad_norm": 0.0006220042705535889,
      "learning_rate": 3.2165434479802854e-06,
      "loss": 0.0009,
      "step": 117480
    },
    {
      "epoch": 12.588663880852888,
      "grad_norm": 7.162390102166682e-05,
      "learning_rate": 3.2151148255294835e-06,
      "loss": 0.0,
      "step": 117490
    },
    {
      "epoch": 12.58973534769099,
      "grad_norm": 0.0003233605239074677,
      "learning_rate": 3.2136862030786816e-06,
      "loss": 0.0,
      "step": 117500
    },
    {
      "epoch": 12.59080681452909,
      "grad_norm": 0.0002983711601700634,
      "learning_rate": 3.21225758062788e-06,
      "loss": 0.0,
      "step": 117510
    },
    {
      "epoch": 12.591878281367192,
      "grad_norm": 7.218687096610665e-05,
      "learning_rate": 3.2108289581770778e-06,
      "loss": 0.0,
      "step": 117520
    },
    {
      "epoch": 12.592949748205292,
      "grad_norm": 0.00036711650318466127,
      "learning_rate": 3.209400335726276e-06,
      "loss": 0.1431,
      "step": 117530
    },
    {
      "epoch": 12.594021215043394,
      "grad_norm": 0.0010416931472718716,
      "learning_rate": 3.2079717132754744e-06,
      "loss": 0.0,
      "step": 117540
    },
    {
      "epoch": 12.595092681881496,
      "grad_norm": 6.576598389074206e-05,
      "learning_rate": 3.2065430908246725e-06,
      "loss": 0.0,
      "step": 117550
    },
    {
      "epoch": 12.596164148719597,
      "grad_norm": 7.041219214443117e-05,
      "learning_rate": 3.2051144683738706e-06,
      "loss": 0.0,
      "step": 117560
    },
    {
      "epoch": 12.597235615557699,
      "grad_norm": 0.0027339754160493612,
      "learning_rate": 3.203685845923069e-06,
      "loss": 0.0,
      "step": 117570
    },
    {
      "epoch": 12.5983070823958,
      "grad_norm": 6.630498683080077e-05,
      "learning_rate": 3.202257223472267e-06,
      "loss": 0.0,
      "step": 117580
    },
    {
      "epoch": 12.5993785492339,
      "grad_norm": 0.08221866190433502,
      "learning_rate": 3.200828601021465e-06,
      "loss": 0.0,
      "step": 117590
    },
    {
      "epoch": 12.600450016072003,
      "grad_norm": 0.00023425905965268612,
      "learning_rate": 3.199399978570664e-06,
      "loss": 0.1261,
      "step": 117600
    },
    {
      "epoch": 12.601521482910105,
      "grad_norm": 0.005547247361391783,
      "learning_rate": 3.1979713561198615e-06,
      "loss": 0.0,
      "step": 117610
    },
    {
      "epoch": 12.602592949748205,
      "grad_norm": 7.933096640044823e-05,
      "learning_rate": 3.1965427336690596e-06,
      "loss": 0.0,
      "step": 117620
    },
    {
      "epoch": 12.603664416586307,
      "grad_norm": 7.688358891755342e-05,
      "learning_rate": 3.195114111218258e-06,
      "loss": 0.0,
      "step": 117630
    },
    {
      "epoch": 12.604735883424407,
      "grad_norm": 6.97428549756296e-05,
      "learning_rate": 3.193685488767456e-06,
      "loss": 0.0,
      "step": 117640
    },
    {
      "epoch": 12.60580735026251,
      "grad_norm": 0.0002971723151858896,
      "learning_rate": 3.1922568663166543e-06,
      "loss": 0.0,
      "step": 117650
    },
    {
      "epoch": 12.606878817100611,
      "grad_norm": 0.0018609805265441537,
      "learning_rate": 3.190828243865853e-06,
      "loss": 0.0,
      "step": 117660
    },
    {
      "epoch": 12.607950283938711,
      "grad_norm": 7.583301339764148e-05,
      "learning_rate": 3.189399621415051e-06,
      "loss": 0.1775,
      "step": 117670
    },
    {
      "epoch": 12.609021750776813,
      "grad_norm": 0.00041261373553425074,
      "learning_rate": 3.1879709989642486e-06,
      "loss": 0.0,
      "step": 117680
    },
    {
      "epoch": 12.610093217614915,
      "grad_norm": 6.750169268343598e-05,
      "learning_rate": 3.1865423765134475e-06,
      "loss": 0.0,
      "step": 117690
    },
    {
      "epoch": 12.611164684453016,
      "grad_norm": 7.152584294090047e-05,
      "learning_rate": 3.185113754062645e-06,
      "loss": 0.0,
      "step": 117700
    },
    {
      "epoch": 12.612236151291118,
      "grad_norm": 8.192366658477113e-05,
      "learning_rate": 3.1836851316118433e-06,
      "loss": 0.0,
      "step": 117710
    },
    {
      "epoch": 12.61330761812922,
      "grad_norm": 6.770308391423896e-05,
      "learning_rate": 3.182256509161042e-06,
      "loss": 0.0008,
      "step": 117720
    },
    {
      "epoch": 12.61437908496732,
      "grad_norm": 0.14343984425067902,
      "learning_rate": 3.18082788671024e-06,
      "loss": 0.0,
      "step": 117730
    },
    {
      "epoch": 12.615450551805422,
      "grad_norm": 7.264081796165556e-05,
      "learning_rate": 3.179399264259438e-06,
      "loss": 0.0,
      "step": 117740
    },
    {
      "epoch": 12.616522018643522,
      "grad_norm": 6.783657590858638e-05,
      "learning_rate": 3.1779706418086365e-06,
      "loss": 0.0,
      "step": 117750
    },
    {
      "epoch": 12.617593485481624,
      "grad_norm": 0.0016776790143921971,
      "learning_rate": 3.1765420193578346e-06,
      "loss": 0.2883,
      "step": 117760
    },
    {
      "epoch": 12.618664952319726,
      "grad_norm": 0.0005613859975710511,
      "learning_rate": 3.1751133969070323e-06,
      "loss": 0.0001,
      "step": 117770
    },
    {
      "epoch": 12.619736419157826,
      "grad_norm": 0.0003579145995900035,
      "learning_rate": 3.173684774456231e-06,
      "loss": 0.0,
      "step": 117780
    },
    {
      "epoch": 12.620807885995928,
      "grad_norm": 0.0015379743417724967,
      "learning_rate": 3.172256152005429e-06,
      "loss": 0.0,
      "step": 117790
    },
    {
      "epoch": 12.62187935283403,
      "grad_norm": 6.369574111886322e-05,
      "learning_rate": 3.170827529554627e-06,
      "loss": 0.0,
      "step": 117800
    },
    {
      "epoch": 12.62295081967213,
      "grad_norm": 7.010265835560858e-05,
      "learning_rate": 3.1693989071038255e-06,
      "loss": 0.0,
      "step": 117810
    },
    {
      "epoch": 12.624022286510233,
      "grad_norm": 31.247055053710938,
      "learning_rate": 3.1679702846530236e-06,
      "loss": 0.1988,
      "step": 117820
    },
    {
      "epoch": 12.625093753348335,
      "grad_norm": 6.62858146824874e-05,
      "learning_rate": 3.1665416622022217e-06,
      "loss": 0.0,
      "step": 117830
    },
    {
      "epoch": 12.626165220186435,
      "grad_norm": 0.0005466608563438058,
      "learning_rate": 3.1651130397514202e-06,
      "loss": 0.0,
      "step": 117840
    },
    {
      "epoch": 12.627236687024537,
      "grad_norm": 0.0005417721695266664,
      "learning_rate": 3.1636844173006183e-06,
      "loss": 0.0,
      "step": 117850
    },
    {
      "epoch": 12.628308153862639,
      "grad_norm": 7.843856292311102e-05,
      "learning_rate": 3.162255794849816e-06,
      "loss": 0.0,
      "step": 117860
    },
    {
      "epoch": 12.629379620700739,
      "grad_norm": 0.00010941971413558349,
      "learning_rate": 3.1608271723990145e-06,
      "loss": 0.0915,
      "step": 117870
    },
    {
      "epoch": 12.630451087538841,
      "grad_norm": 8.123730367515236e-05,
      "learning_rate": 3.1593985499482126e-06,
      "loss": 0.0003,
      "step": 117880
    },
    {
      "epoch": 12.631522554376943,
      "grad_norm": 0.0046313730999827385,
      "learning_rate": 3.1579699274974107e-06,
      "loss": 0.0002,
      "step": 117890
    },
    {
      "epoch": 12.632594021215043,
      "grad_norm": 0.00940321758389473,
      "learning_rate": 3.1565413050466092e-06,
      "loss": 0.0,
      "step": 117900
    },
    {
      "epoch": 12.633665488053145,
      "grad_norm": 8.281546615762636e-05,
      "learning_rate": 3.1551126825958073e-06,
      "loss": 0.0,
      "step": 117910
    },
    {
      "epoch": 12.634736954891245,
      "grad_norm": 7.805774657754228e-05,
      "learning_rate": 3.1536840601450054e-06,
      "loss": 0.0002,
      "step": 117920
    },
    {
      "epoch": 12.635808421729347,
      "grad_norm": 0.0002800538204610348,
      "learning_rate": 3.152255437694204e-06,
      "loss": 0.0,
      "step": 117930
    },
    {
      "epoch": 12.63687988856745,
      "grad_norm": 0.02870168164372444,
      "learning_rate": 3.1508268152434016e-06,
      "loss": 0.0001,
      "step": 117940
    },
    {
      "epoch": 12.63795135540555,
      "grad_norm": 7.64912911108695e-05,
      "learning_rate": 3.1493981927925997e-06,
      "loss": 0.0,
      "step": 117950
    },
    {
      "epoch": 12.639022822243652,
      "grad_norm": 0.0003457444836385548,
      "learning_rate": 3.1479695703417982e-06,
      "loss": 0.0,
      "step": 117960
    },
    {
      "epoch": 12.640094289081754,
      "grad_norm": 0.000361050246283412,
      "learning_rate": 3.1465409478909963e-06,
      "loss": 0.0009,
      "step": 117970
    },
    {
      "epoch": 12.641165755919854,
      "grad_norm": 7.280649151653051e-05,
      "learning_rate": 3.1451123254401944e-06,
      "loss": 0.0,
      "step": 117980
    },
    {
      "epoch": 12.642237222757956,
      "grad_norm": 9.052436507772654e-05,
      "learning_rate": 3.143683702989393e-06,
      "loss": 0.1207,
      "step": 117990
    },
    {
      "epoch": 12.643308689596058,
      "grad_norm": 0.0002555606479290873,
      "learning_rate": 3.142255080538591e-06,
      "loss": 0.0,
      "step": 118000
    },
    {
      "epoch": 12.644380156434158,
      "grad_norm": 7.297776028281078e-05,
      "learning_rate": 3.140826458087789e-06,
      "loss": 0.0,
      "step": 118010
    },
    {
      "epoch": 12.64545162327226,
      "grad_norm": 7.861068297643214e-05,
      "learning_rate": 3.1393978356369877e-06,
      "loss": 0.0,
      "step": 118020
    },
    {
      "epoch": 12.64652309011036,
      "grad_norm": 0.00037151004653424025,
      "learning_rate": 3.1379692131861853e-06,
      "loss": 0.0,
      "step": 118030
    },
    {
      "epoch": 12.647594556948462,
      "grad_norm": 0.00011078592069679871,
      "learning_rate": 3.1365405907353834e-06,
      "loss": 0.0,
      "step": 118040
    },
    {
      "epoch": 12.648666023786564,
      "grad_norm": 8.106919995043427e-05,
      "learning_rate": 3.135111968284582e-06,
      "loss": 0.0,
      "step": 118050
    },
    {
      "epoch": 12.649737490624664,
      "grad_norm": 8.173794049071148e-05,
      "learning_rate": 3.13368334583378e-06,
      "loss": 0.0,
      "step": 118060
    },
    {
      "epoch": 12.650808957462766,
      "grad_norm": 0.20602856576442719,
      "learning_rate": 3.132254723382978e-06,
      "loss": 0.0003,
      "step": 118070
    },
    {
      "epoch": 12.651880424300868,
      "grad_norm": 0.0004243812581989914,
      "learning_rate": 3.1308261009321767e-06,
      "loss": 0.0,
      "step": 118080
    },
    {
      "epoch": 12.652951891138969,
      "grad_norm": 6.946747453184798e-05,
      "learning_rate": 3.1293974784813748e-06,
      "loss": 0.0,
      "step": 118090
    },
    {
      "epoch": 12.65402335797707,
      "grad_norm": 7.032136636553332e-05,
      "learning_rate": 3.127968856030573e-06,
      "loss": 0.0059,
      "step": 118100
    },
    {
      "epoch": 12.655094824815173,
      "grad_norm": 0.0003360035188961774,
      "learning_rate": 3.1265402335797714e-06,
      "loss": 0.0,
      "step": 118110
    },
    {
      "epoch": 12.656166291653273,
      "grad_norm": 0.004648320376873016,
      "learning_rate": 3.125111611128969e-06,
      "loss": 0.0,
      "step": 118120
    },
    {
      "epoch": 12.657237758491375,
      "grad_norm": 0.0007752719102427363,
      "learning_rate": 3.123682988678167e-06,
      "loss": 0.0,
      "step": 118130
    },
    {
      "epoch": 12.658309225329475,
      "grad_norm": 6.877993291709572e-05,
      "learning_rate": 3.1222543662273657e-06,
      "loss": 0.0,
      "step": 118140
    },
    {
      "epoch": 12.659380692167577,
      "grad_norm": 0.00018232694128528237,
      "learning_rate": 3.1208257437765638e-06,
      "loss": 0.0,
      "step": 118150
    },
    {
      "epoch": 12.660452159005679,
      "grad_norm": 0.0036888672038912773,
      "learning_rate": 3.119397121325762e-06,
      "loss": 0.0001,
      "step": 118160
    },
    {
      "epoch": 12.66152362584378,
      "grad_norm": 9.146540105575696e-05,
      "learning_rate": 3.1179684988749604e-06,
      "loss": 0.0,
      "step": 118170
    },
    {
      "epoch": 12.662595092681881,
      "grad_norm": 6.841131835244596e-05,
      "learning_rate": 3.1165398764241585e-06,
      "loss": 0.0,
      "step": 118180
    },
    {
      "epoch": 12.663666559519983,
      "grad_norm": 7.107918645488098e-05,
      "learning_rate": 3.115111253973356e-06,
      "loss": 0.0,
      "step": 118190
    },
    {
      "epoch": 12.664738026358084,
      "grad_norm": 0.00016472696734126657,
      "learning_rate": 3.113682631522555e-06,
      "loss": 0.0,
      "step": 118200
    },
    {
      "epoch": 12.665809493196186,
      "grad_norm": 0.00023047448485158384,
      "learning_rate": 3.1122540090717528e-06,
      "loss": 0.0,
      "step": 118210
    },
    {
      "epoch": 12.666880960034288,
      "grad_norm": 0.0002477691159583628,
      "learning_rate": 3.110825386620951e-06,
      "loss": 0.0,
      "step": 118220
    },
    {
      "epoch": 12.667952426872388,
      "grad_norm": 6.683224637527019e-05,
      "learning_rate": 3.1093967641701494e-06,
      "loss": 0.0,
      "step": 118230
    },
    {
      "epoch": 12.66902389371049,
      "grad_norm": 9.133499406743795e-05,
      "learning_rate": 3.1079681417193475e-06,
      "loss": 0.0986,
      "step": 118240
    },
    {
      "epoch": 12.670095360548592,
      "grad_norm": 7.65759905334562e-05,
      "learning_rate": 3.1065395192685456e-06,
      "loss": 0.0,
      "step": 118250
    },
    {
      "epoch": 12.671166827386692,
      "grad_norm": 6.575320730917156e-05,
      "learning_rate": 3.1051108968177437e-06,
      "loss": 0.0,
      "step": 118260
    },
    {
      "epoch": 12.672238294224794,
      "grad_norm": 0.00022192457981873304,
      "learning_rate": 3.103682274366942e-06,
      "loss": 0.0,
      "step": 118270
    },
    {
      "epoch": 12.673309761062896,
      "grad_norm": 0.0001092198072001338,
      "learning_rate": 3.10225365191614e-06,
      "loss": 0.0,
      "step": 118280
    },
    {
      "epoch": 12.674381227900996,
      "grad_norm": 0.00043444999027997255,
      "learning_rate": 3.100825029465338e-06,
      "loss": 0.0001,
      "step": 118290
    },
    {
      "epoch": 12.675452694739098,
      "grad_norm": 0.00031509416294284165,
      "learning_rate": 3.0993964070145365e-06,
      "loss": 0.0,
      "step": 118300
    },
    {
      "epoch": 12.676524161577198,
      "grad_norm": 0.6222585439682007,
      "learning_rate": 3.0979677845637346e-06,
      "loss": 0.0002,
      "step": 118310
    },
    {
      "epoch": 12.6775956284153,
      "grad_norm": 0.00021385088621173054,
      "learning_rate": 3.0965391621129327e-06,
      "loss": 0.0,
      "step": 118320
    },
    {
      "epoch": 12.678667095253402,
      "grad_norm": 0.00021594911231659353,
      "learning_rate": 3.095110539662131e-06,
      "loss": 0.0,
      "step": 118330
    },
    {
      "epoch": 12.679738562091503,
      "grad_norm": 0.0002080722915707156,
      "learning_rate": 3.0936819172113293e-06,
      "loss": 0.0002,
      "step": 118340
    },
    {
      "epoch": 12.680810028929605,
      "grad_norm": 7.958092464832589e-05,
      "learning_rate": 3.092253294760527e-06,
      "loss": 0.0,
      "step": 118350
    },
    {
      "epoch": 12.681881495767707,
      "grad_norm": 0.0007863897481001914,
      "learning_rate": 3.090824672309726e-06,
      "loss": 0.0003,
      "step": 118360
    },
    {
      "epoch": 12.682952962605807,
      "grad_norm": 8.712617272976786e-05,
      "learning_rate": 3.0893960498589236e-06,
      "loss": 0.0,
      "step": 118370
    },
    {
      "epoch": 12.684024429443909,
      "grad_norm": 7.39691749913618e-05,
      "learning_rate": 3.0879674274081217e-06,
      "loss": 0.0,
      "step": 118380
    },
    {
      "epoch": 12.68509589628201,
      "grad_norm": 6.914170080563053e-05,
      "learning_rate": 3.08653880495732e-06,
      "loss": 0.1561,
      "step": 118390
    },
    {
      "epoch": 12.686167363120111,
      "grad_norm": 0.0001299622090300545,
      "learning_rate": 3.0851101825065183e-06,
      "loss": 0.0,
      "step": 118400
    },
    {
      "epoch": 12.687238829958213,
      "grad_norm": 7.071351865306497e-05,
      "learning_rate": 3.0836815600557164e-06,
      "loss": 0.0,
      "step": 118410
    },
    {
      "epoch": 12.688310296796313,
      "grad_norm": 0.0005108576733618975,
      "learning_rate": 3.082252937604915e-06,
      "loss": 0.0006,
      "step": 118420
    },
    {
      "epoch": 12.689381763634415,
      "grad_norm": 6.926702917553484e-05,
      "learning_rate": 3.080824315154113e-06,
      "loss": 0.0,
      "step": 118430
    },
    {
      "epoch": 12.690453230472517,
      "grad_norm": 0.0005310466513037682,
      "learning_rate": 3.0793956927033107e-06,
      "loss": 0.0023,
      "step": 118440
    },
    {
      "epoch": 12.691524697310617,
      "grad_norm": 0.00010324492905056104,
      "learning_rate": 3.0779670702525096e-06,
      "loss": 0.0,
      "step": 118450
    },
    {
      "epoch": 12.69259616414872,
      "grad_norm": 0.0007644532597623765,
      "learning_rate": 3.0765384478017073e-06,
      "loss": 0.0,
      "step": 118460
    },
    {
      "epoch": 12.693667630986821,
      "grad_norm": 6.456476694438607e-05,
      "learning_rate": 3.0751098253509054e-06,
      "loss": 0.0001,
      "step": 118470
    },
    {
      "epoch": 12.694739097824922,
      "grad_norm": 0.00015952574904076755,
      "learning_rate": 3.073681202900104e-06,
      "loss": 0.0,
      "step": 118480
    },
    {
      "epoch": 12.695810564663024,
      "grad_norm": 6.745867722202092e-05,
      "learning_rate": 3.072252580449302e-06,
      "loss": 0.0,
      "step": 118490
    },
    {
      "epoch": 12.696882031501126,
      "grad_norm": 0.0002170197549276054,
      "learning_rate": 3.0708239579985e-06,
      "loss": 0.0,
      "step": 118500
    },
    {
      "epoch": 12.697953498339226,
      "grad_norm": 7.120506779756397e-05,
      "learning_rate": 3.0693953355476986e-06,
      "loss": 0.0,
      "step": 118510
    },
    {
      "epoch": 12.699024965177328,
      "grad_norm": 0.000826998904813081,
      "learning_rate": 3.0679667130968967e-06,
      "loss": 0.0973,
      "step": 118520
    },
    {
      "epoch": 12.70009643201543,
      "grad_norm": 132.06295776367188,
      "learning_rate": 3.0665380906460944e-06,
      "loss": 0.0352,
      "step": 118530
    },
    {
      "epoch": 12.70116789885353,
      "grad_norm": 0.00018063053721562028,
      "learning_rate": 3.065109468195293e-06,
      "loss": 0.0,
      "step": 118540
    },
    {
      "epoch": 12.702239365691632,
      "grad_norm": 6.434083479689434e-05,
      "learning_rate": 3.063680845744491e-06,
      "loss": 0.0765,
      "step": 118550
    },
    {
      "epoch": 12.703310832529734,
      "grad_norm": 0.00019842507026623935,
      "learning_rate": 3.062252223293689e-06,
      "loss": 0.0,
      "step": 118560
    },
    {
      "epoch": 12.704382299367834,
      "grad_norm": 6.641317304456607e-05,
      "learning_rate": 3.0608236008428876e-06,
      "loss": 0.0,
      "step": 118570
    },
    {
      "epoch": 12.705453766205936,
      "grad_norm": 8.939427061704919e-05,
      "learning_rate": 3.0593949783920857e-06,
      "loss": 0.0,
      "step": 118580
    },
    {
      "epoch": 12.706525233044037,
      "grad_norm": 0.00018979862215928733,
      "learning_rate": 3.057966355941284e-06,
      "loss": 0.0,
      "step": 118590
    },
    {
      "epoch": 12.707596699882139,
      "grad_norm": 0.0004235297383274883,
      "learning_rate": 3.0565377334904823e-06,
      "loss": 0.0003,
      "step": 118600
    },
    {
      "epoch": 12.70866816672024,
      "grad_norm": 0.00018887853366322815,
      "learning_rate": 3.0551091110396804e-06,
      "loss": 0.0,
      "step": 118610
    },
    {
      "epoch": 12.70973963355834,
      "grad_norm": 6.842276343377307e-05,
      "learning_rate": 3.053680488588878e-06,
      "loss": 0.0,
      "step": 118620
    },
    {
      "epoch": 12.710811100396443,
      "grad_norm": 6.555850268341601e-05,
      "learning_rate": 3.0522518661380766e-06,
      "loss": 0.0,
      "step": 118630
    },
    {
      "epoch": 12.711882567234545,
      "grad_norm": 7.726674812147394e-05,
      "learning_rate": 3.0508232436872747e-06,
      "loss": 0.0,
      "step": 118640
    },
    {
      "epoch": 12.712954034072645,
      "grad_norm": 6.67209824314341e-05,
      "learning_rate": 3.049394621236473e-06,
      "loss": 0.0,
      "step": 118650
    },
    {
      "epoch": 12.714025500910747,
      "grad_norm": 7.128145807655528e-05,
      "learning_rate": 3.0479659987856713e-06,
      "loss": 0.0,
      "step": 118660
    },
    {
      "epoch": 12.715096967748849,
      "grad_norm": 5.74760815652553e-05,
      "learning_rate": 3.0465373763348694e-06,
      "loss": 0.0,
      "step": 118670
    },
    {
      "epoch": 12.71616843458695,
      "grad_norm": 6.458511052187532e-05,
      "learning_rate": 3.0451087538840675e-06,
      "loss": 0.0,
      "step": 118680
    },
    {
      "epoch": 12.717239901425051,
      "grad_norm": 6.96702190907672e-05,
      "learning_rate": 3.043680131433266e-06,
      "loss": 0.2291,
      "step": 118690
    },
    {
      "epoch": 12.718311368263151,
      "grad_norm": 0.0005138209671713412,
      "learning_rate": 3.0422515089824637e-06,
      "loss": 0.0,
      "step": 118700
    },
    {
      "epoch": 12.719382835101253,
      "grad_norm": 0.0009032892994582653,
      "learning_rate": 3.040822886531662e-06,
      "loss": 0.0009,
      "step": 118710
    },
    {
      "epoch": 12.720454301939355,
      "grad_norm": 0.00028108441620133817,
      "learning_rate": 3.0393942640808603e-06,
      "loss": 0.0,
      "step": 118720
    },
    {
      "epoch": 12.721525768777456,
      "grad_norm": 6.0783619119320065e-05,
      "learning_rate": 3.0379656416300584e-06,
      "loss": 0.0,
      "step": 118730
    },
    {
      "epoch": 12.722597235615558,
      "grad_norm": 6.33371455478482e-05,
      "learning_rate": 3.0365370191792565e-06,
      "loss": 0.0,
      "step": 118740
    },
    {
      "epoch": 12.72366870245366,
      "grad_norm": 0.00020282359037082642,
      "learning_rate": 3.035108396728455e-06,
      "loss": 0.0,
      "step": 118750
    },
    {
      "epoch": 12.72474016929176,
      "grad_norm": 8.72533128131181e-05,
      "learning_rate": 3.033679774277653e-06,
      "loss": 0.2592,
      "step": 118760
    },
    {
      "epoch": 12.725811636129862,
      "grad_norm": 0.00031460169702768326,
      "learning_rate": 3.0322511518268512e-06,
      "loss": 0.0,
      "step": 118770
    },
    {
      "epoch": 12.726883102967964,
      "grad_norm": 0.00034224832779727876,
      "learning_rate": 3.0308225293760497e-06,
      "loss": 0.0,
      "step": 118780
    },
    {
      "epoch": 12.727954569806064,
      "grad_norm": 6.263852264964953e-05,
      "learning_rate": 3.0293939069252474e-06,
      "loss": 0.0001,
      "step": 118790
    },
    {
      "epoch": 12.729026036644166,
      "grad_norm": 0.0003897089045494795,
      "learning_rate": 3.0279652844744455e-06,
      "loss": 0.0,
      "step": 118800
    },
    {
      "epoch": 12.730097503482266,
      "grad_norm": 6.21940489509143e-05,
      "learning_rate": 3.026536662023644e-06,
      "loss": 0.0,
      "step": 118810
    },
    {
      "epoch": 12.731168970320368,
      "grad_norm": 0.0001669017074164003,
      "learning_rate": 3.025108039572842e-06,
      "loss": 0.0001,
      "step": 118820
    },
    {
      "epoch": 12.73224043715847,
      "grad_norm": 6.416313408408314e-05,
      "learning_rate": 3.0236794171220402e-06,
      "loss": 0.0002,
      "step": 118830
    },
    {
      "epoch": 12.73331190399657,
      "grad_norm": 7.37500304239802e-05,
      "learning_rate": 3.0222507946712387e-06,
      "loss": 0.0002,
      "step": 118840
    },
    {
      "epoch": 12.734383370834673,
      "grad_norm": 8.416764467256144e-05,
      "learning_rate": 3.020822172220437e-06,
      "loss": 0.2775,
      "step": 118850
    },
    {
      "epoch": 12.735454837672775,
      "grad_norm": 0.00017892310279421508,
      "learning_rate": 3.0193935497696345e-06,
      "loss": 0.0001,
      "step": 118860
    },
    {
      "epoch": 12.736526304510875,
      "grad_norm": 0.0001801221224013716,
      "learning_rate": 3.0179649273188335e-06,
      "loss": 0.0,
      "step": 118870
    },
    {
      "epoch": 12.737597771348977,
      "grad_norm": 7.07029175828211e-05,
      "learning_rate": 3.016536304868031e-06,
      "loss": 0.0003,
      "step": 118880
    },
    {
      "epoch": 12.738669238187079,
      "grad_norm": 7.212840864667669e-05,
      "learning_rate": 3.0151076824172292e-06,
      "loss": 0.0,
      "step": 118890
    },
    {
      "epoch": 12.739740705025179,
      "grad_norm": 0.0002546687319409102,
      "learning_rate": 3.0136790599664277e-06,
      "loss": 0.0,
      "step": 118900
    },
    {
      "epoch": 12.740812171863281,
      "grad_norm": 7.154617924243212e-05,
      "learning_rate": 3.012250437515626e-06,
      "loss": 0.0,
      "step": 118910
    },
    {
      "epoch": 12.741883638701383,
      "grad_norm": 0.5448618531227112,
      "learning_rate": 3.010821815064824e-06,
      "loss": 0.1307,
      "step": 118920
    },
    {
      "epoch": 12.742955105539483,
      "grad_norm": 8.87274945853278e-05,
      "learning_rate": 3.0093931926140225e-06,
      "loss": 0.0,
      "step": 118930
    },
    {
      "epoch": 12.744026572377585,
      "grad_norm": 0.00010984783875755966,
      "learning_rate": 3.0079645701632206e-06,
      "loss": 0.0,
      "step": 118940
    },
    {
      "epoch": 12.745098039215687,
      "grad_norm": 9.202669025398791e-05,
      "learning_rate": 3.0065359477124182e-06,
      "loss": 0.0,
      "step": 118950
    },
    {
      "epoch": 12.746169506053787,
      "grad_norm": 6.733699410688132e-05,
      "learning_rate": 3.005107325261617e-06,
      "loss": 0.0001,
      "step": 118960
    },
    {
      "epoch": 12.74724097289189,
      "grad_norm": 9.643354860600084e-05,
      "learning_rate": 3.003678702810815e-06,
      "loss": 0.0,
      "step": 118970
    },
    {
      "epoch": 12.74831243972999,
      "grad_norm": 9.615116141503677e-05,
      "learning_rate": 3.002250080360013e-06,
      "loss": 0.2544,
      "step": 118980
    },
    {
      "epoch": 12.749383906568092,
      "grad_norm": 7.61409683036618e-05,
      "learning_rate": 3.0008214579092115e-06,
      "loss": 0.0,
      "step": 118990
    },
    {
      "epoch": 12.750455373406194,
      "grad_norm": 0.0001778981095412746,
      "learning_rate": 2.9993928354584096e-06,
      "loss": 0.0,
      "step": 119000
    },
    {
      "epoch": 12.751526840244294,
      "grad_norm": 7.336151611525565e-05,
      "learning_rate": 2.9979642130076076e-06,
      "loss": 0.0,
      "step": 119010
    },
    {
      "epoch": 12.752598307082396,
      "grad_norm": 0.00012742597027681768,
      "learning_rate": 2.996535590556806e-06,
      "loss": 0.0,
      "step": 119020
    },
    {
      "epoch": 12.753669773920498,
      "grad_norm": 7.739354623481631e-05,
      "learning_rate": 2.9951069681060043e-06,
      "loss": 0.0,
      "step": 119030
    },
    {
      "epoch": 12.754741240758598,
      "grad_norm": 0.0003401852445676923,
      "learning_rate": 2.993678345655202e-06,
      "loss": 0.0,
      "step": 119040
    },
    {
      "epoch": 12.7558127075967,
      "grad_norm": 6.772481719963253e-05,
      "learning_rate": 2.9922497232044005e-06,
      "loss": 0.0,
      "step": 119050
    },
    {
      "epoch": 12.756884174434802,
      "grad_norm": 0.00021193244901951402,
      "learning_rate": 2.9908211007535986e-06,
      "loss": 0.0,
      "step": 119060
    },
    {
      "epoch": 12.757955641272902,
      "grad_norm": 7.324343459913507e-05,
      "learning_rate": 2.9893924783027966e-06,
      "loss": 0.0,
      "step": 119070
    },
    {
      "epoch": 12.759027108111004,
      "grad_norm": 0.0019802539609372616,
      "learning_rate": 2.987963855851995e-06,
      "loss": 0.0,
      "step": 119080
    },
    {
      "epoch": 12.760098574949104,
      "grad_norm": 0.00010698713595047593,
      "learning_rate": 2.9865352334011933e-06,
      "loss": 0.0,
      "step": 119090
    },
    {
      "epoch": 12.761170041787206,
      "grad_norm": 6.786019366700202e-05,
      "learning_rate": 2.9851066109503914e-06,
      "loss": 0.0,
      "step": 119100
    },
    {
      "epoch": 12.762241508625308,
      "grad_norm": 7.645554433111101e-05,
      "learning_rate": 2.98367798849959e-06,
      "loss": 0.0,
      "step": 119110
    },
    {
      "epoch": 12.763312975463409,
      "grad_norm": 0.0002933868963737041,
      "learning_rate": 2.982249366048788e-06,
      "loss": 0.1402,
      "step": 119120
    },
    {
      "epoch": 12.76438444230151,
      "grad_norm": 74.27572631835938,
      "learning_rate": 2.9808207435979856e-06,
      "loss": 0.1312,
      "step": 119130
    },
    {
      "epoch": 12.765455909139613,
      "grad_norm": 0.0004549730510916561,
      "learning_rate": 2.979392121147184e-06,
      "loss": 0.0,
      "step": 119140
    },
    {
      "epoch": 12.766527375977713,
      "grad_norm": 6.664355169050395e-05,
      "learning_rate": 2.9779634986963823e-06,
      "loss": 0.0,
      "step": 119150
    },
    {
      "epoch": 12.767598842815815,
      "grad_norm": 0.00014966042363084853,
      "learning_rate": 2.9765348762455804e-06,
      "loss": 0.0,
      "step": 119160
    },
    {
      "epoch": 12.768670309653917,
      "grad_norm": 8.63170062075369e-05,
      "learning_rate": 2.9751062537947785e-06,
      "loss": 0.0,
      "step": 119170
    },
    {
      "epoch": 12.769741776492017,
      "grad_norm": 7.769612420815974e-05,
      "learning_rate": 2.973677631343977e-06,
      "loss": 0.0494,
      "step": 119180
    },
    {
      "epoch": 12.77081324333012,
      "grad_norm": 0.9869715571403503,
      "learning_rate": 2.972249008893175e-06,
      "loss": 0.001,
      "step": 119190
    },
    {
      "epoch": 12.77188471016822,
      "grad_norm": 8.807557605905458e-05,
      "learning_rate": 2.9708203864423727e-06,
      "loss": 0.0,
      "step": 119200
    },
    {
      "epoch": 12.772956177006321,
      "grad_norm": 0.00016272938228212297,
      "learning_rate": 2.9693917639915713e-06,
      "loss": 0.0,
      "step": 119210
    },
    {
      "epoch": 12.774027643844423,
      "grad_norm": 0.0004085053224116564,
      "learning_rate": 2.9679631415407694e-06,
      "loss": 0.0,
      "step": 119220
    },
    {
      "epoch": 12.775099110682524,
      "grad_norm": 6.444378959713504e-05,
      "learning_rate": 2.9665345190899675e-06,
      "loss": 0.0,
      "step": 119230
    },
    {
      "epoch": 12.776170577520626,
      "grad_norm": 0.0001671554200584069,
      "learning_rate": 2.965105896639166e-06,
      "loss": 0.2121,
      "step": 119240
    },
    {
      "epoch": 12.777242044358728,
      "grad_norm": 0.00041051674634218216,
      "learning_rate": 2.963677274188364e-06,
      "loss": 0.0001,
      "step": 119250
    },
    {
      "epoch": 12.778313511196828,
      "grad_norm": 7.824457134120166e-05,
      "learning_rate": 2.962248651737562e-06,
      "loss": 0.0806,
      "step": 119260
    },
    {
      "epoch": 12.77938497803493,
      "grad_norm": 0.00043081212788820267,
      "learning_rate": 2.9608200292867607e-06,
      "loss": 0.0,
      "step": 119270
    },
    {
      "epoch": 12.780456444873032,
      "grad_norm": 7.785999332554638e-05,
      "learning_rate": 2.9593914068359588e-06,
      "loss": 0.0061,
      "step": 119280
    },
    {
      "epoch": 12.781527911711132,
      "grad_norm": 7.353512773988768e-05,
      "learning_rate": 2.9579627843851565e-06,
      "loss": 0.0042,
      "step": 119290
    },
    {
      "epoch": 12.782599378549234,
      "grad_norm": 0.0002784810494631529,
      "learning_rate": 2.956534161934355e-06,
      "loss": 0.0,
      "step": 119300
    },
    {
      "epoch": 12.783670845387336,
      "grad_norm": 173.29478454589844,
      "learning_rate": 2.955105539483553e-06,
      "loss": 0.1064,
      "step": 119310
    },
    {
      "epoch": 12.784742312225436,
      "grad_norm": 0.00020973045320715755,
      "learning_rate": 2.953676917032751e-06,
      "loss": 0.0,
      "step": 119320
    },
    {
      "epoch": 12.785813779063538,
      "grad_norm": 6.413554365281016e-05,
      "learning_rate": 2.9522482945819497e-06,
      "loss": 0.0,
      "step": 119330
    },
    {
      "epoch": 12.78688524590164,
      "grad_norm": 7.0463604060933e-05,
      "learning_rate": 2.9508196721311478e-06,
      "loss": 0.0,
      "step": 119340
    },
    {
      "epoch": 12.78795671273974,
      "grad_norm": 7.584672857774422e-05,
      "learning_rate": 2.949391049680346e-06,
      "loss": 0.0,
      "step": 119350
    },
    {
      "epoch": 12.789028179577842,
      "grad_norm": 7.256335084093735e-05,
      "learning_rate": 2.9479624272295444e-06,
      "loss": 0.0,
      "step": 119360
    },
    {
      "epoch": 12.790099646415943,
      "grad_norm": 9.70066903391853e-05,
      "learning_rate": 2.9465338047787425e-06,
      "loss": 0.2699,
      "step": 119370
    },
    {
      "epoch": 12.791171113254045,
      "grad_norm": 6.950070383027196e-05,
      "learning_rate": 2.94510518232794e-06,
      "loss": 0.0,
      "step": 119380
    },
    {
      "epoch": 12.792242580092147,
      "grad_norm": 0.00010417591693112627,
      "learning_rate": 2.9436765598771387e-06,
      "loss": 0.0,
      "step": 119390
    },
    {
      "epoch": 12.793314046930247,
      "grad_norm": 0.0005818754434585571,
      "learning_rate": 2.9422479374263368e-06,
      "loss": 0.0,
      "step": 119400
    },
    {
      "epoch": 12.794385513768349,
      "grad_norm": 0.0005434678751043975,
      "learning_rate": 2.940819314975535e-06,
      "loss": 0.0,
      "step": 119410
    },
    {
      "epoch": 12.79545698060645,
      "grad_norm": 6.849794590380043e-05,
      "learning_rate": 2.9393906925247334e-06,
      "loss": 0.0005,
      "step": 119420
    },
    {
      "epoch": 12.796528447444551,
      "grad_norm": 8.516096568200737e-05,
      "learning_rate": 2.9379620700739315e-06,
      "loss": 0.0,
      "step": 119430
    },
    {
      "epoch": 12.797599914282653,
      "grad_norm": 0.46364733576774597,
      "learning_rate": 2.9365334476231296e-06,
      "loss": 0.0007,
      "step": 119440
    },
    {
      "epoch": 12.798671381120755,
      "grad_norm": 0.0001714481768431142,
      "learning_rate": 2.935104825172328e-06,
      "loss": 0.0,
      "step": 119450
    },
    {
      "epoch": 12.799742847958855,
      "grad_norm": 7.909376290626824e-05,
      "learning_rate": 2.9336762027215258e-06,
      "loss": 0.0,
      "step": 119460
    },
    {
      "epoch": 12.800814314796957,
      "grad_norm": 0.00016970398428384215,
      "learning_rate": 2.932247580270724e-06,
      "loss": 0.0,
      "step": 119470
    },
    {
      "epoch": 12.801885781635058,
      "grad_norm": 7.403764902846888e-05,
      "learning_rate": 2.9308189578199224e-06,
      "loss": 0.2165,
      "step": 119480
    },
    {
      "epoch": 12.80295724847316,
      "grad_norm": 7.79434631112963e-05,
      "learning_rate": 2.9293903353691205e-06,
      "loss": 0.0001,
      "step": 119490
    },
    {
      "epoch": 12.804028715311262,
      "grad_norm": 8.515840454492718e-05,
      "learning_rate": 2.9279617129183186e-06,
      "loss": 0.0,
      "step": 119500
    },
    {
      "epoch": 12.805100182149362,
      "grad_norm": 7.057654875097796e-05,
      "learning_rate": 2.926533090467517e-06,
      "loss": 0.0,
      "step": 119510
    },
    {
      "epoch": 12.806171648987464,
      "grad_norm": 6.840132118668407e-05,
      "learning_rate": 2.925104468016715e-06,
      "loss": 0.0,
      "step": 119520
    },
    {
      "epoch": 12.807243115825566,
      "grad_norm": 7.042090874165297e-05,
      "learning_rate": 2.9236758455659133e-06,
      "loss": 0.0002,
      "step": 119530
    },
    {
      "epoch": 12.808314582663666,
      "grad_norm": 6.775585643481463e-05,
      "learning_rate": 2.922247223115112e-06,
      "loss": 0.0,
      "step": 119540
    },
    {
      "epoch": 12.809386049501768,
      "grad_norm": 6.734357157256454e-05,
      "learning_rate": 2.9208186006643095e-06,
      "loss": 0.0,
      "step": 119550
    },
    {
      "epoch": 12.81045751633987,
      "grad_norm": 7.05352213117294e-05,
      "learning_rate": 2.9193899782135076e-06,
      "loss": 0.0,
      "step": 119560
    },
    {
      "epoch": 12.81152898317797,
      "grad_norm": 7.02168108546175e-05,
      "learning_rate": 2.917961355762706e-06,
      "loss": 0.0,
      "step": 119570
    },
    {
      "epoch": 12.812600450016072,
      "grad_norm": 17.493148803710938,
      "learning_rate": 2.916532733311904e-06,
      "loss": 0.0845,
      "step": 119580
    },
    {
      "epoch": 12.813671916854174,
      "grad_norm": 7.703462324570864e-05,
      "learning_rate": 2.9151041108611023e-06,
      "loss": 0.0,
      "step": 119590
    },
    {
      "epoch": 12.814743383692274,
      "grad_norm": 0.0002510967315174639,
      "learning_rate": 2.913675488410301e-06,
      "loss": 0.0,
      "step": 119600
    },
    {
      "epoch": 12.815814850530376,
      "grad_norm": 0.00015592934505548328,
      "learning_rate": 2.912246865959499e-06,
      "loss": 0.0,
      "step": 119610
    },
    {
      "epoch": 12.816886317368478,
      "grad_norm": 0.06901773810386658,
      "learning_rate": 2.9108182435086966e-06,
      "loss": 0.0001,
      "step": 119620
    },
    {
      "epoch": 12.817957784206579,
      "grad_norm": 7.924052624730393e-05,
      "learning_rate": 2.9093896210578955e-06,
      "loss": 0.0001,
      "step": 119630
    },
    {
      "epoch": 12.81902925104468,
      "grad_norm": 7.001931226113811e-05,
      "learning_rate": 2.907960998607093e-06,
      "loss": 0.0002,
      "step": 119640
    },
    {
      "epoch": 12.82010071788278,
      "grad_norm": 0.00255220802500844,
      "learning_rate": 2.9065323761562913e-06,
      "loss": 0.0959,
      "step": 119650
    },
    {
      "epoch": 12.821172184720883,
      "grad_norm": 6.425311585189775e-05,
      "learning_rate": 2.90510375370549e-06,
      "loss": 0.0,
      "step": 119660
    },
    {
      "epoch": 12.822243651558985,
      "grad_norm": 6.715013296343386e-05,
      "learning_rate": 2.903675131254688e-06,
      "loss": 0.0,
      "step": 119670
    },
    {
      "epoch": 12.823315118397085,
      "grad_norm": 0.0011091743363067508,
      "learning_rate": 2.902246508803886e-06,
      "loss": 0.0,
      "step": 119680
    },
    {
      "epoch": 12.824386585235187,
      "grad_norm": 6.71652378514409e-05,
      "learning_rate": 2.9008178863530845e-06,
      "loss": 0.0,
      "step": 119690
    },
    {
      "epoch": 12.825458052073289,
      "grad_norm": 7.051420834613964e-05,
      "learning_rate": 2.8993892639022826e-06,
      "loss": 0.0002,
      "step": 119700
    },
    {
      "epoch": 12.82652951891139,
      "grad_norm": 6.930560630280524e-05,
      "learning_rate": 2.8979606414514803e-06,
      "loss": 0.0,
      "step": 119710
    },
    {
      "epoch": 12.827600985749491,
      "grad_norm": 0.00027908533229492605,
      "learning_rate": 2.8965320190006792e-06,
      "loss": 0.0,
      "step": 119720
    },
    {
      "epoch": 12.828672452587593,
      "grad_norm": 0.018136177211999893,
      "learning_rate": 2.895103396549877e-06,
      "loss": 0.0,
      "step": 119730
    },
    {
      "epoch": 12.829743919425693,
      "grad_norm": 8.086332672974095e-05,
      "learning_rate": 2.893674774099075e-06,
      "loss": 0.0,
      "step": 119740
    },
    {
      "epoch": 12.830815386263795,
      "grad_norm": 0.00030938154668547213,
      "learning_rate": 2.8922461516482735e-06,
      "loss": 0.0,
      "step": 119750
    },
    {
      "epoch": 12.831886853101896,
      "grad_norm": 0.00016632764891255647,
      "learning_rate": 2.8908175291974716e-06,
      "loss": 0.0,
      "step": 119760
    },
    {
      "epoch": 12.832958319939998,
      "grad_norm": 0.0021233372390270233,
      "learning_rate": 2.8893889067466697e-06,
      "loss": 0.0001,
      "step": 119770
    },
    {
      "epoch": 12.8340297867781,
      "grad_norm": 6.733980990247801e-05,
      "learning_rate": 2.8879602842958682e-06,
      "loss": 0.0,
      "step": 119780
    },
    {
      "epoch": 12.8351012536162,
      "grad_norm": 0.0004432953428477049,
      "learning_rate": 2.8865316618450663e-06,
      "loss": 0.0,
      "step": 119790
    },
    {
      "epoch": 12.836172720454302,
      "grad_norm": 0.00019045226508751512,
      "learning_rate": 2.885103039394264e-06,
      "loss": 0.0,
      "step": 119800
    },
    {
      "epoch": 12.837244187292404,
      "grad_norm": 7.802640175214037e-05,
      "learning_rate": 2.8836744169434625e-06,
      "loss": 0.0,
      "step": 119810
    },
    {
      "epoch": 12.838315654130504,
      "grad_norm": 9.255304757971317e-05,
      "learning_rate": 2.8822457944926606e-06,
      "loss": 0.0,
      "step": 119820
    },
    {
      "epoch": 12.839387120968606,
      "grad_norm": 9.917691932059824e-05,
      "learning_rate": 2.8808171720418587e-06,
      "loss": 0.0003,
      "step": 119830
    },
    {
      "epoch": 12.840458587806708,
      "grad_norm": 7.825483044143766e-05,
      "learning_rate": 2.8793885495910572e-06,
      "loss": 0.0,
      "step": 119840
    },
    {
      "epoch": 12.841530054644808,
      "grad_norm": 7.147646829253063e-05,
      "learning_rate": 2.8779599271402553e-06,
      "loss": 0.0015,
      "step": 119850
    },
    {
      "epoch": 12.84260152148291,
      "grad_norm": 0.000158535607624799,
      "learning_rate": 2.8765313046894534e-06,
      "loss": 0.0,
      "step": 119860
    },
    {
      "epoch": 12.84367298832101,
      "grad_norm": 7.011018897173926e-05,
      "learning_rate": 2.875102682238652e-06,
      "loss": 0.0,
      "step": 119870
    },
    {
      "epoch": 12.844744455159113,
      "grad_norm": 0.0002647832443471998,
      "learning_rate": 2.87367405978785e-06,
      "loss": 0.0,
      "step": 119880
    },
    {
      "epoch": 12.845815921997215,
      "grad_norm": 0.00034488766686990857,
      "learning_rate": 2.8722454373370477e-06,
      "loss": 0.0,
      "step": 119890
    },
    {
      "epoch": 12.846887388835315,
      "grad_norm": 8.028706361074e-05,
      "learning_rate": 2.8708168148862462e-06,
      "loss": 0.0,
      "step": 119900
    },
    {
      "epoch": 12.847958855673417,
      "grad_norm": 8.784775127423927e-05,
      "learning_rate": 2.8693881924354443e-06,
      "loss": 0.0,
      "step": 119910
    },
    {
      "epoch": 12.849030322511519,
      "grad_norm": 7.196350634330884e-05,
      "learning_rate": 2.8679595699846424e-06,
      "loss": 0.0727,
      "step": 119920
    },
    {
      "epoch": 12.850101789349619,
      "grad_norm": 0.0004743337049148977,
      "learning_rate": 2.866530947533841e-06,
      "loss": 0.0,
      "step": 119930
    },
    {
      "epoch": 12.851173256187721,
      "grad_norm": 0.00010258606198476627,
      "learning_rate": 2.865102325083039e-06,
      "loss": 0.364,
      "step": 119940
    },
    {
      "epoch": 12.852244723025823,
      "grad_norm": 7.113417086657137e-05,
      "learning_rate": 2.863673702632237e-06,
      "loss": 0.0,
      "step": 119950
    },
    {
      "epoch": 12.853316189863923,
      "grad_norm": 7.30927349650301e-05,
      "learning_rate": 2.8622450801814357e-06,
      "loss": 0.0,
      "step": 119960
    },
    {
      "epoch": 12.854387656702025,
      "grad_norm": 8.391465235035866e-05,
      "learning_rate": 2.8608164577306333e-06,
      "loss": 0.0783,
      "step": 119970
    },
    {
      "epoch": 12.855459123540127,
      "grad_norm": 8.474948845105246e-05,
      "learning_rate": 2.8593878352798314e-06,
      "loss": 0.0,
      "step": 119980
    },
    {
      "epoch": 12.856530590378227,
      "grad_norm": 7.073111191857606e-05,
      "learning_rate": 2.85795921282903e-06,
      "loss": 0.0,
      "step": 119990
    },
    {
      "epoch": 12.85760205721633,
      "grad_norm": 6.860259600216523e-05,
      "learning_rate": 2.856530590378228e-06,
      "loss": 0.0,
      "step": 120000
    },
    {
      "epoch": 12.858673524054431,
      "grad_norm": 0.002895880723372102,
      "learning_rate": 2.855101967927426e-06,
      "loss": 0.0,
      "step": 120010
    },
    {
      "epoch": 12.859744990892532,
      "grad_norm": 7.009749242570251e-05,
      "learning_rate": 2.8536733454766247e-06,
      "loss": 0.0,
      "step": 120020
    },
    {
      "epoch": 12.860816457730634,
      "grad_norm": 0.0001854561414802447,
      "learning_rate": 2.8522447230258228e-06,
      "loss": 0.0,
      "step": 120030
    },
    {
      "epoch": 12.861887924568734,
      "grad_norm": 0.000318853126373142,
      "learning_rate": 2.850816100575021e-06,
      "loss": 0.0001,
      "step": 120040
    },
    {
      "epoch": 12.862959391406836,
      "grad_norm": 7.769063086016104e-05,
      "learning_rate": 2.8493874781242194e-06,
      "loss": 0.0,
      "step": 120050
    },
    {
      "epoch": 12.864030858244938,
      "grad_norm": 0.004469148814678192,
      "learning_rate": 2.847958855673417e-06,
      "loss": 0.0001,
      "step": 120060
    },
    {
      "epoch": 12.865102325083038,
      "grad_norm": 6.542108167195693e-05,
      "learning_rate": 2.846530233222615e-06,
      "loss": 0.0,
      "step": 120070
    },
    {
      "epoch": 12.86617379192114,
      "grad_norm": 6.678280624328181e-05,
      "learning_rate": 2.8451016107718132e-06,
      "loss": 0.0,
      "step": 120080
    },
    {
      "epoch": 12.867245258759242,
      "grad_norm": 0.0008336197352036834,
      "learning_rate": 2.8436729883210118e-06,
      "loss": 0.0005,
      "step": 120090
    },
    {
      "epoch": 12.868316725597342,
      "grad_norm": 6.860544090159237e-05,
      "learning_rate": 2.84224436587021e-06,
      "loss": 0.0001,
      "step": 120100
    },
    {
      "epoch": 12.869388192435444,
      "grad_norm": 6.557154119946063e-05,
      "learning_rate": 2.840815743419408e-06,
      "loss": 0.0,
      "step": 120110
    },
    {
      "epoch": 12.870459659273546,
      "grad_norm": 0.00036925525637343526,
      "learning_rate": 2.8393871209686065e-06,
      "loss": 0.0,
      "step": 120120
    },
    {
      "epoch": 12.871531126111647,
      "grad_norm": 0.00029141592676751316,
      "learning_rate": 2.8379584985178046e-06,
      "loss": 0.0,
      "step": 120130
    },
    {
      "epoch": 12.872602592949749,
      "grad_norm": 0.0002527315227780491,
      "learning_rate": 2.8365298760670022e-06,
      "loss": 0.0,
      "step": 120140
    },
    {
      "epoch": 12.873674059787849,
      "grad_norm": 0.0014321607304736972,
      "learning_rate": 2.8351012536162008e-06,
      "loss": 0.0,
      "step": 120150
    },
    {
      "epoch": 12.87474552662595,
      "grad_norm": 7.748001371510327e-05,
      "learning_rate": 2.833672631165399e-06,
      "loss": 0.0,
      "step": 120160
    },
    {
      "epoch": 12.875816993464053,
      "grad_norm": 0.0004837765882257372,
      "learning_rate": 2.832244008714597e-06,
      "loss": 0.0545,
      "step": 120170
    },
    {
      "epoch": 12.876888460302153,
      "grad_norm": 8.77752318046987e-05,
      "learning_rate": 2.8308153862637955e-06,
      "loss": 0.0,
      "step": 120180
    },
    {
      "epoch": 12.877959927140255,
      "grad_norm": 0.0004844849754590541,
      "learning_rate": 2.8293867638129936e-06,
      "loss": 0.0,
      "step": 120190
    },
    {
      "epoch": 12.879031393978357,
      "grad_norm": 0.018236955627799034,
      "learning_rate": 2.8279581413621917e-06,
      "loss": 0.0,
      "step": 120200
    },
    {
      "epoch": 12.880102860816457,
      "grad_norm": 69.68984985351562,
      "learning_rate": 2.82652951891139e-06,
      "loss": 0.2589,
      "step": 120210
    },
    {
      "epoch": 12.88117432765456,
      "grad_norm": 0.00040815924876369536,
      "learning_rate": 2.825100896460588e-06,
      "loss": 0.0,
      "step": 120220
    },
    {
      "epoch": 12.882245794492661,
      "grad_norm": 0.0005836564232595265,
      "learning_rate": 2.823672274009786e-06,
      "loss": 0.0064,
      "step": 120230
    },
    {
      "epoch": 12.883317261330761,
      "grad_norm": 6.285202834988013e-05,
      "learning_rate": 2.8222436515589845e-06,
      "loss": 0.0,
      "step": 120240
    },
    {
      "epoch": 12.884388728168863,
      "grad_norm": 6.648800626862794e-05,
      "learning_rate": 2.8208150291081826e-06,
      "loss": 0.1575,
      "step": 120250
    },
    {
      "epoch": 12.885460195006964,
      "grad_norm": 7.841368642402813e-05,
      "learning_rate": 2.8193864066573807e-06,
      "loss": 0.0,
      "step": 120260
    },
    {
      "epoch": 12.886531661845066,
      "grad_norm": 34.22438049316406,
      "learning_rate": 2.817957784206579e-06,
      "loss": 0.1525,
      "step": 120270
    },
    {
      "epoch": 12.887603128683168,
      "grad_norm": 7.719454151811078e-05,
      "learning_rate": 2.8165291617557773e-06,
      "loss": 0.0,
      "step": 120280
    },
    {
      "epoch": 12.888674595521268,
      "grad_norm": 0.0005581045406870544,
      "learning_rate": 2.8151005393049754e-06,
      "loss": 0.0,
      "step": 120290
    },
    {
      "epoch": 12.88974606235937,
      "grad_norm": 7.117895438568667e-05,
      "learning_rate": 2.813671916854174e-06,
      "loss": 0.0,
      "step": 120300
    },
    {
      "epoch": 12.890817529197472,
      "grad_norm": 61.71611022949219,
      "learning_rate": 2.8122432944033716e-06,
      "loss": 0.0087,
      "step": 120310
    },
    {
      "epoch": 12.891888996035572,
      "grad_norm": 6.815903179813176e-05,
      "learning_rate": 2.8108146719525697e-06,
      "loss": 0.0,
      "step": 120320
    },
    {
      "epoch": 12.892960462873674,
      "grad_norm": 7.044889207463712e-05,
      "learning_rate": 2.809386049501768e-06,
      "loss": 0.0001,
      "step": 120330
    },
    {
      "epoch": 12.894031929711776,
      "grad_norm": 0.05857553333044052,
      "learning_rate": 2.8079574270509663e-06,
      "loss": 0.0001,
      "step": 120340
    },
    {
      "epoch": 12.895103396549876,
      "grad_norm": 0.0001967812277143821,
      "learning_rate": 2.8065288046001644e-06,
      "loss": 0.0,
      "step": 120350
    },
    {
      "epoch": 12.896174863387978,
      "grad_norm": 6.782446871511638e-05,
      "learning_rate": 2.805100182149363e-06,
      "loss": 0.0001,
      "step": 120360
    },
    {
      "epoch": 12.89724633022608,
      "grad_norm": 0.005593049339950085,
      "learning_rate": 2.803671559698561e-06,
      "loss": 0.0005,
      "step": 120370
    },
    {
      "epoch": 12.89831779706418,
      "grad_norm": 8.140879799611866e-05,
      "learning_rate": 2.8022429372477587e-06,
      "loss": 0.0,
      "step": 120380
    },
    {
      "epoch": 12.899389263902282,
      "grad_norm": 0.0007085941033437848,
      "learning_rate": 2.8008143147969576e-06,
      "loss": 0.0,
      "step": 120390
    },
    {
      "epoch": 12.900460730740384,
      "grad_norm": 0.0070196655578911304,
      "learning_rate": 2.7993856923461553e-06,
      "loss": 0.0,
      "step": 120400
    },
    {
      "epoch": 12.901532197578485,
      "grad_norm": 0.00040386480395682156,
      "learning_rate": 2.7979570698953534e-06,
      "loss": 0.0001,
      "step": 120410
    },
    {
      "epoch": 12.902603664416587,
      "grad_norm": 0.00020556157687678933,
      "learning_rate": 2.796528447444552e-06,
      "loss": 0.0,
      "step": 120420
    },
    {
      "epoch": 12.903675131254687,
      "grad_norm": 6.765193393221125e-05,
      "learning_rate": 2.79509982499375e-06,
      "loss": 0.0,
      "step": 120430
    },
    {
      "epoch": 12.904746598092789,
      "grad_norm": 6.276282510953024e-05,
      "learning_rate": 2.793671202542948e-06,
      "loss": 0.0009,
      "step": 120440
    },
    {
      "epoch": 12.905818064930891,
      "grad_norm": 7.16767244739458e-05,
      "learning_rate": 2.7922425800921466e-06,
      "loss": 0.0,
      "step": 120450
    },
    {
      "epoch": 12.906889531768991,
      "grad_norm": 0.00010361009481130168,
      "learning_rate": 2.7908139576413447e-06,
      "loss": 0.0,
      "step": 120460
    },
    {
      "epoch": 12.907960998607093,
      "grad_norm": 7.730783545412123e-05,
      "learning_rate": 2.7893853351905424e-06,
      "loss": 0.0415,
      "step": 120470
    },
    {
      "epoch": 12.909032465445195,
      "grad_norm": 0.0001966000272659585,
      "learning_rate": 2.7879567127397413e-06,
      "loss": 0.0,
      "step": 120480
    },
    {
      "epoch": 12.910103932283295,
      "grad_norm": 7.655506487935781e-05,
      "learning_rate": 2.786528090288939e-06,
      "loss": 0.0007,
      "step": 120490
    },
    {
      "epoch": 12.911175399121397,
      "grad_norm": 6.80016673868522e-05,
      "learning_rate": 2.785099467838137e-06,
      "loss": 0.0,
      "step": 120500
    },
    {
      "epoch": 12.9122468659595,
      "grad_norm": 0.00011233768600504845,
      "learning_rate": 2.7836708453873356e-06,
      "loss": 0.0001,
      "step": 120510
    },
    {
      "epoch": 12.9133183327976,
      "grad_norm": 6.929242954356596e-05,
      "learning_rate": 2.7822422229365337e-06,
      "loss": 0.0,
      "step": 120520
    },
    {
      "epoch": 12.914389799635702,
      "grad_norm": 5.9074111049994826e-05,
      "learning_rate": 2.780813600485732e-06,
      "loss": 0.0,
      "step": 120530
    },
    {
      "epoch": 12.915461266473802,
      "grad_norm": 6.262877286644652e-05,
      "learning_rate": 2.7793849780349303e-06,
      "loss": 0.0,
      "step": 120540
    },
    {
      "epoch": 12.916532733311904,
      "grad_norm": 7.865747465984896e-05,
      "learning_rate": 2.7779563555841284e-06,
      "loss": 0.0,
      "step": 120550
    },
    {
      "epoch": 12.917604200150006,
      "grad_norm": 6.326691072899848e-05,
      "learning_rate": 2.776527733133326e-06,
      "loss": 0.0,
      "step": 120560
    },
    {
      "epoch": 12.918675666988106,
      "grad_norm": 5.9662550484063104e-05,
      "learning_rate": 2.7750991106825246e-06,
      "loss": 0.0,
      "step": 120570
    },
    {
      "epoch": 12.919747133826208,
      "grad_norm": 7.859969628043473e-05,
      "learning_rate": 2.7736704882317227e-06,
      "loss": 0.0,
      "step": 120580
    },
    {
      "epoch": 12.92081860066431,
      "grad_norm": 0.0011733963619917631,
      "learning_rate": 2.772241865780921e-06,
      "loss": 0.0,
      "step": 120590
    },
    {
      "epoch": 12.92189006750241,
      "grad_norm": 0.0007767406641505659,
      "learning_rate": 2.7708132433301193e-06,
      "loss": 0.0,
      "step": 120600
    },
    {
      "epoch": 12.922961534340512,
      "grad_norm": 7.891697168815881e-05,
      "learning_rate": 2.7693846208793174e-06,
      "loss": 0.0001,
      "step": 120610
    },
    {
      "epoch": 12.924033001178614,
      "grad_norm": 0.0001895068126032129,
      "learning_rate": 2.7679559984285155e-06,
      "loss": 0.0,
      "step": 120620
    },
    {
      "epoch": 12.925104468016714,
      "grad_norm": 6.746893632225692e-05,
      "learning_rate": 2.766527375977714e-06,
      "loss": 0.0,
      "step": 120630
    },
    {
      "epoch": 12.926175934854816,
      "grad_norm": 6.201844371389598e-05,
      "learning_rate": 2.765098753526912e-06,
      "loss": 0.0,
      "step": 120640
    },
    {
      "epoch": 12.927247401692918,
      "grad_norm": 0.00020010187290608883,
      "learning_rate": 2.76367013107611e-06,
      "loss": 0.0,
      "step": 120650
    },
    {
      "epoch": 12.928318868531019,
      "grad_norm": 6.619578198296949e-05,
      "learning_rate": 2.7622415086253083e-06,
      "loss": 0.0,
      "step": 120660
    },
    {
      "epoch": 12.92939033536912,
      "grad_norm": 0.00025597307831048965,
      "learning_rate": 2.7608128861745064e-06,
      "loss": 0.0,
      "step": 120670
    },
    {
      "epoch": 12.93046180220722,
      "grad_norm": 0.00034952719579450786,
      "learning_rate": 2.7593842637237045e-06,
      "loss": 0.0,
      "step": 120680
    },
    {
      "epoch": 12.931533269045323,
      "grad_norm": 0.0017563225701451302,
      "learning_rate": 2.757955641272903e-06,
      "loss": 0.0007,
      "step": 120690
    },
    {
      "epoch": 12.932604735883425,
      "grad_norm": 6.554811989190057e-05,
      "learning_rate": 2.756527018822101e-06,
      "loss": 0.0,
      "step": 120700
    },
    {
      "epoch": 12.933676202721525,
      "grad_norm": 0.0710354596376419,
      "learning_rate": 2.7550983963712992e-06,
      "loss": 0.0,
      "step": 120710
    },
    {
      "epoch": 12.934747669559627,
      "grad_norm": 6.229873542906716e-05,
      "learning_rate": 2.7536697739204977e-06,
      "loss": 0.0,
      "step": 120720
    },
    {
      "epoch": 12.935819136397729,
      "grad_norm": 0.00044919276842847466,
      "learning_rate": 2.7522411514696954e-06,
      "loss": 0.0226,
      "step": 120730
    },
    {
      "epoch": 12.93689060323583,
      "grad_norm": 6.199183553690091e-05,
      "learning_rate": 2.7508125290188935e-06,
      "loss": 0.0,
      "step": 120740
    },
    {
      "epoch": 12.937962070073931,
      "grad_norm": 6.197179027367383e-05,
      "learning_rate": 2.749383906568092e-06,
      "loss": 0.0,
      "step": 120750
    },
    {
      "epoch": 12.939033536912033,
      "grad_norm": 6.185416714288294e-05,
      "learning_rate": 2.74795528411729e-06,
      "loss": 0.0,
      "step": 120760
    },
    {
      "epoch": 12.940105003750134,
      "grad_norm": 0.00026944305864162743,
      "learning_rate": 2.7465266616664882e-06,
      "loss": 0.0,
      "step": 120770
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 7.295995601452887e-05,
      "learning_rate": 2.7450980392156867e-06,
      "loss": 0.0,
      "step": 120780
    },
    {
      "epoch": 12.942247937426338,
      "grad_norm": 0.0002442512195557356,
      "learning_rate": 2.743669416764885e-06,
      "loss": 0.1606,
      "step": 120790
    },
    {
      "epoch": 12.943319404264438,
      "grad_norm": 0.06620372086763382,
      "learning_rate": 2.742240794314083e-06,
      "loss": 0.0,
      "step": 120800
    },
    {
      "epoch": 12.94439087110254,
      "grad_norm": 6.337004742817953e-05,
      "learning_rate": 2.7408121718632815e-06,
      "loss": 0.1659,
      "step": 120810
    },
    {
      "epoch": 12.94546233794064,
      "grad_norm": 0.0001609621976967901,
      "learning_rate": 2.739383549412479e-06,
      "loss": 0.027,
      "step": 120820
    },
    {
      "epoch": 12.946533804778742,
      "grad_norm": 6.460242002503946e-05,
      "learning_rate": 2.7379549269616772e-06,
      "loss": 0.0,
      "step": 120830
    },
    {
      "epoch": 12.947605271616844,
      "grad_norm": 6.505914643639699e-05,
      "learning_rate": 2.7365263045108757e-06,
      "loss": 0.0,
      "step": 120840
    },
    {
      "epoch": 12.948676738454944,
      "grad_norm": 0.0010082352673634887,
      "learning_rate": 2.735097682060074e-06,
      "loss": 0.0,
      "step": 120850
    },
    {
      "epoch": 12.949748205293046,
      "grad_norm": 0.00021479891438502818,
      "learning_rate": 2.733669059609272e-06,
      "loss": 0.0,
      "step": 120860
    },
    {
      "epoch": 12.950819672131148,
      "grad_norm": 7.235672092065215e-05,
      "learning_rate": 2.7322404371584705e-06,
      "loss": 0.0,
      "step": 120870
    },
    {
      "epoch": 12.951891138969248,
      "grad_norm": 6.962390762055293e-05,
      "learning_rate": 2.7308118147076685e-06,
      "loss": 0.0,
      "step": 120880
    },
    {
      "epoch": 12.95296260580735,
      "grad_norm": 6.807053432567045e-05,
      "learning_rate": 2.7293831922568666e-06,
      "loss": 0.0243,
      "step": 120890
    },
    {
      "epoch": 12.954034072645452,
      "grad_norm": 8.314868318848312e-05,
      "learning_rate": 2.727954569806065e-06,
      "loss": 0.0,
      "step": 120900
    },
    {
      "epoch": 12.955105539483553,
      "grad_norm": 7.44453354855068e-05,
      "learning_rate": 2.726525947355263e-06,
      "loss": 0.0001,
      "step": 120910
    },
    {
      "epoch": 12.956177006321655,
      "grad_norm": 0.02474505640566349,
      "learning_rate": 2.725097324904461e-06,
      "loss": 0.0437,
      "step": 120920
    },
    {
      "epoch": 12.957248473159755,
      "grad_norm": 265.0708312988281,
      "learning_rate": 2.7236687024536595e-06,
      "loss": 0.2344,
      "step": 120930
    },
    {
      "epoch": 12.958319939997857,
      "grad_norm": 6.88430227455683e-05,
      "learning_rate": 2.7222400800028575e-06,
      "loss": 0.0,
      "step": 120940
    },
    {
      "epoch": 12.959391406835959,
      "grad_norm": 0.019419366493821144,
      "learning_rate": 2.7208114575520556e-06,
      "loss": 0.0117,
      "step": 120950
    },
    {
      "epoch": 12.960462873674059,
      "grad_norm": 7.099498271942139,
      "learning_rate": 2.719382835101254e-06,
      "loss": 0.1248,
      "step": 120960
    },
    {
      "epoch": 12.961534340512161,
      "grad_norm": 0.00015645823441445827,
      "learning_rate": 2.7179542126504523e-06,
      "loss": 0.0,
      "step": 120970
    },
    {
      "epoch": 12.962605807350263,
      "grad_norm": 0.00024441329878754914,
      "learning_rate": 2.71652559019965e-06,
      "loss": 0.0,
      "step": 120980
    },
    {
      "epoch": 12.963677274188363,
      "grad_norm": 6.669099821010605e-05,
      "learning_rate": 2.715096967748848e-06,
      "loss": 0.0,
      "step": 120990
    },
    {
      "epoch": 12.964748741026465,
      "grad_norm": 0.0003685108677018434,
      "learning_rate": 2.7136683452980465e-06,
      "loss": 0.0001,
      "step": 121000
    },
    {
      "epoch": 12.965820207864567,
      "grad_norm": 0.005692200269550085,
      "learning_rate": 2.7122397228472446e-06,
      "loss": 0.0,
      "step": 121010
    },
    {
      "epoch": 12.966891674702667,
      "grad_norm": 0.0011152827646583319,
      "learning_rate": 2.7108111003964427e-06,
      "loss": 0.0,
      "step": 121020
    },
    {
      "epoch": 12.96796314154077,
      "grad_norm": 0.00023696817515883595,
      "learning_rate": 2.7093824779456413e-06,
      "loss": 0.0001,
      "step": 121030
    },
    {
      "epoch": 12.969034608378871,
      "grad_norm": 0.00021065784676466137,
      "learning_rate": 2.7079538554948394e-06,
      "loss": 0.0,
      "step": 121040
    },
    {
      "epoch": 12.970106075216972,
      "grad_norm": 7.278248813236132e-05,
      "learning_rate": 2.7065252330440375e-06,
      "loss": 0.0,
      "step": 121050
    },
    {
      "epoch": 12.971177542055074,
      "grad_norm": 6.861703150207177e-05,
      "learning_rate": 2.705096610593236e-06,
      "loss": 0.0,
      "step": 121060
    },
    {
      "epoch": 12.972249008893176,
      "grad_norm": 7.00853779562749e-05,
      "learning_rate": 2.7036679881424336e-06,
      "loss": 0.0,
      "step": 121070
    },
    {
      "epoch": 12.973320475731276,
      "grad_norm": 6.577186286449432e-05,
      "learning_rate": 2.7022393656916317e-06,
      "loss": 0.0,
      "step": 121080
    },
    {
      "epoch": 12.974391942569378,
      "grad_norm": 6.876492989249527e-05,
      "learning_rate": 2.7008107432408303e-06,
      "loss": 0.0,
      "step": 121090
    },
    {
      "epoch": 12.975463409407478,
      "grad_norm": 35.11997604370117,
      "learning_rate": 2.6993821207900284e-06,
      "loss": 0.152,
      "step": 121100
    },
    {
      "epoch": 12.97653487624558,
      "grad_norm": 237.523193359375,
      "learning_rate": 2.6979534983392265e-06,
      "loss": 0.0652,
      "step": 121110
    },
    {
      "epoch": 12.977606343083682,
      "grad_norm": 6.844958988949656e-05,
      "learning_rate": 2.696524875888425e-06,
      "loss": 0.0,
      "step": 121120
    },
    {
      "epoch": 12.978677809921782,
      "grad_norm": 0.0006558163440786302,
      "learning_rate": 2.695096253437623e-06,
      "loss": 0.0,
      "step": 121130
    },
    {
      "epoch": 12.979749276759884,
      "grad_norm": 0.00019948475528508425,
      "learning_rate": 2.6936676309868207e-06,
      "loss": 0.0001,
      "step": 121140
    },
    {
      "epoch": 12.980820743597986,
      "grad_norm": 0.00020732767006848007,
      "learning_rate": 2.6922390085360197e-06,
      "loss": 0.0,
      "step": 121150
    },
    {
      "epoch": 12.981892210436087,
      "grad_norm": 0.00012676388723775744,
      "learning_rate": 2.6908103860852174e-06,
      "loss": 0.0,
      "step": 121160
    },
    {
      "epoch": 12.982963677274189,
      "grad_norm": 7.392185943899676e-05,
      "learning_rate": 2.6893817636344154e-06,
      "loss": 0.0,
      "step": 121170
    },
    {
      "epoch": 12.98403514411229,
      "grad_norm": 0.0001618328969925642,
      "learning_rate": 2.687953141183614e-06,
      "loss": 0.0001,
      "step": 121180
    },
    {
      "epoch": 12.98510661095039,
      "grad_norm": 0.00021425231534522027,
      "learning_rate": 2.686524518732812e-06,
      "loss": 0.0,
      "step": 121190
    },
    {
      "epoch": 12.986178077788493,
      "grad_norm": 6.958185258554295e-05,
      "learning_rate": 2.68509589628201e-06,
      "loss": 0.0,
      "step": 121200
    },
    {
      "epoch": 12.987249544626593,
      "grad_norm": 8.127357432385907e-05,
      "learning_rate": 2.6836672738312087e-06,
      "loss": 0.0,
      "step": 121210
    },
    {
      "epoch": 12.988321011464695,
      "grad_norm": 8.945733134169132e-05,
      "learning_rate": 2.6822386513804068e-06,
      "loss": 0.0,
      "step": 121220
    },
    {
      "epoch": 12.989392478302797,
      "grad_norm": 6.693084287689999e-05,
      "learning_rate": 2.6808100289296044e-06,
      "loss": 0.0,
      "step": 121230
    },
    {
      "epoch": 12.990463945140897,
      "grad_norm": 0.008089983835816383,
      "learning_rate": 2.6793814064788034e-06,
      "loss": 0.0,
      "step": 121240
    },
    {
      "epoch": 12.991535411979,
      "grad_norm": 32.88932418823242,
      "learning_rate": 2.677952784028001e-06,
      "loss": 0.2389,
      "step": 121250
    },
    {
      "epoch": 12.992606878817101,
      "grad_norm": 7.903642108431086e-05,
      "learning_rate": 2.676524161577199e-06,
      "loss": 0.1874,
      "step": 121260
    },
    {
      "epoch": 12.993678345655201,
      "grad_norm": 0.0001717486884444952,
      "learning_rate": 2.6750955391263977e-06,
      "loss": 0.0,
      "step": 121270
    },
    {
      "epoch": 12.994749812493303,
      "grad_norm": 0.00019671993504744023,
      "learning_rate": 2.6736669166755958e-06,
      "loss": 0.2067,
      "step": 121280
    },
    {
      "epoch": 12.995821279331405,
      "grad_norm": 0.07277669757604599,
      "learning_rate": 2.672238294224794e-06,
      "loss": 0.0001,
      "step": 121290
    },
    {
      "epoch": 12.996892746169506,
      "grad_norm": 0.0013220570981502533,
      "learning_rate": 2.6708096717739924e-06,
      "loss": 0.0,
      "step": 121300
    },
    {
      "epoch": 12.997964213007608,
      "grad_norm": 7.42800475563854e-05,
      "learning_rate": 2.6693810493231905e-06,
      "loss": 0.0042,
      "step": 121310
    },
    {
      "epoch": 12.999035679845708,
      "grad_norm": 0.02255919761955738,
      "learning_rate": 2.667952426872388e-06,
      "loss": 0.0,
      "step": 121320
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.9791666666666666,
      "eval_f1": 0.9179251477347341,
      "eval_loss": 0.18526297807693481,
      "eval_precision": 0.912532637075718,
      "eval_recall": 0.9233817701453104,
      "eval_runtime": 517.4949,
      "eval_samples_per_second": 11.594,
      "eval_steps_per_second": 3.865,
      "step": 121329
    },
    {
      "epoch": 13.00010714668381,
      "grad_norm": 6.52436792734079e-05,
      "learning_rate": 2.6665238044215867e-06,
      "loss": 0.0,
      "step": 121330
    },
    {
      "epoch": 13.001178613521912,
      "grad_norm": 0.006463723257184029,
      "learning_rate": 2.6650951819707848e-06,
      "loss": 0.0,
      "step": 121340
    },
    {
      "epoch": 13.002250080360012,
      "grad_norm": 0.00017150893108919263,
      "learning_rate": 2.663666559519983e-06,
      "loss": 0.0,
      "step": 121350
    },
    {
      "epoch": 13.003321547198114,
      "grad_norm": 0.00016138503269758075,
      "learning_rate": 2.6622379370691814e-06,
      "loss": 0.0,
      "step": 121360
    },
    {
      "epoch": 13.004393014036216,
      "grad_norm": 9.574339492246509e-05,
      "learning_rate": 2.6608093146183795e-06,
      "loss": 0.0,
      "step": 121370
    },
    {
      "epoch": 13.005464480874316,
      "grad_norm": 0.0001367085933452472,
      "learning_rate": 2.6593806921675776e-06,
      "loss": 0.0,
      "step": 121380
    },
    {
      "epoch": 13.006535947712418,
      "grad_norm": 7.680362614337355e-05,
      "learning_rate": 2.657952069716776e-06,
      "loss": 0.0607,
      "step": 121390
    },
    {
      "epoch": 13.00760741455052,
      "grad_norm": 8.213295950554311e-05,
      "learning_rate": 2.656523447265974e-06,
      "loss": 0.0,
      "step": 121400
    },
    {
      "epoch": 13.00867888138862,
      "grad_norm": 8.075546065811068e-05,
      "learning_rate": 2.655094824815172e-06,
      "loss": 0.1032,
      "step": 121410
    },
    {
      "epoch": 13.009750348226722,
      "grad_norm": 3.3363499641418457,
      "learning_rate": 2.6536662023643704e-06,
      "loss": 0.0041,
      "step": 121420
    },
    {
      "epoch": 13.010821815064824,
      "grad_norm": 8.252453699242324e-05,
      "learning_rate": 2.6522375799135685e-06,
      "loss": 0.0,
      "step": 121430
    },
    {
      "epoch": 13.011893281902925,
      "grad_norm": 6.318733358057216e-05,
      "learning_rate": 2.6508089574627666e-06,
      "loss": 0.0021,
      "step": 121440
    },
    {
      "epoch": 13.012964748741027,
      "grad_norm": 0.012948339805006981,
      "learning_rate": 2.649380335011965e-06,
      "loss": 0.0076,
      "step": 121450
    },
    {
      "epoch": 13.014036215579129,
      "grad_norm": 0.00012037004489684477,
      "learning_rate": 2.647951712561163e-06,
      "loss": 0.0001,
      "step": 121460
    },
    {
      "epoch": 13.015107682417229,
      "grad_norm": 0.00029931720928288996,
      "learning_rate": 2.6465230901103613e-06,
      "loss": 0.0,
      "step": 121470
    },
    {
      "epoch": 13.016179149255331,
      "grad_norm": 6.706599378958344e-05,
      "learning_rate": 2.64509446765956e-06,
      "loss": 0.0001,
      "step": 121480
    },
    {
      "epoch": 13.017250616093431,
      "grad_norm": 0.00018619555339682847,
      "learning_rate": 2.6436658452087575e-06,
      "loss": 0.0,
      "step": 121490
    },
    {
      "epoch": 13.018322082931533,
      "grad_norm": 0.00022476466256193817,
      "learning_rate": 2.6422372227579556e-06,
      "loss": 0.0,
      "step": 121500
    },
    {
      "epoch": 13.019393549769635,
      "grad_norm": 0.00014349840057548136,
      "learning_rate": 2.640808600307154e-06,
      "loss": 0.0,
      "step": 121510
    },
    {
      "epoch": 13.020465016607735,
      "grad_norm": 0.00012179287296021357,
      "learning_rate": 2.639379977856352e-06,
      "loss": 0.0,
      "step": 121520
    },
    {
      "epoch": 13.021536483445837,
      "grad_norm": 7.201469270512462e-05,
      "learning_rate": 2.6379513554055503e-06,
      "loss": 0.0001,
      "step": 121530
    },
    {
      "epoch": 13.02260795028394,
      "grad_norm": 6.968824891373515e-05,
      "learning_rate": 2.636522732954749e-06,
      "loss": 0.0,
      "step": 121540
    },
    {
      "epoch": 13.02367941712204,
      "grad_norm": 7.224499859148636e-05,
      "learning_rate": 2.635094110503947e-06,
      "loss": 0.0,
      "step": 121550
    },
    {
      "epoch": 13.024750883960142,
      "grad_norm": 8.177832933142781e-05,
      "learning_rate": 2.633665488053145e-06,
      "loss": 0.0,
      "step": 121560
    },
    {
      "epoch": 13.025822350798244,
      "grad_norm": 0.0001793869596440345,
      "learning_rate": 2.6322368656023435e-06,
      "loss": 0.108,
      "step": 121570
    },
    {
      "epoch": 13.026893817636344,
      "grad_norm": 6.937558646313846e-05,
      "learning_rate": 2.630808243151541e-06,
      "loss": 0.0002,
      "step": 121580
    },
    {
      "epoch": 13.027965284474446,
      "grad_norm": 7.317796553252265e-05,
      "learning_rate": 2.6293796207007393e-06,
      "loss": 0.0159,
      "step": 121590
    },
    {
      "epoch": 13.029036751312546,
      "grad_norm": 7.249950431287289e-05,
      "learning_rate": 2.627950998249938e-06,
      "loss": 0.0,
      "step": 121600
    },
    {
      "epoch": 13.030108218150648,
      "grad_norm": 7.348756480496377e-05,
      "learning_rate": 2.626522375799136e-06,
      "loss": 0.0,
      "step": 121610
    },
    {
      "epoch": 13.03117968498875,
      "grad_norm": 0.0003384329902473837,
      "learning_rate": 2.625093753348334e-06,
      "loss": 0.0,
      "step": 121620
    },
    {
      "epoch": 13.03225115182685,
      "grad_norm": 6.907178612891585e-05,
      "learning_rate": 2.6236651308975325e-06,
      "loss": 0.0,
      "step": 121630
    },
    {
      "epoch": 13.033322618664952,
      "grad_norm": 7.559586083516479e-05,
      "learning_rate": 2.6222365084467306e-06,
      "loss": 0.0,
      "step": 121640
    },
    {
      "epoch": 13.034394085503054,
      "grad_norm": 7.083782838890329e-05,
      "learning_rate": 2.6208078859959283e-06,
      "loss": 0.0001,
      "step": 121650
    },
    {
      "epoch": 13.035465552341154,
      "grad_norm": 7.449516851920635e-05,
      "learning_rate": 2.6193792635451272e-06,
      "loss": 0.309,
      "step": 121660
    },
    {
      "epoch": 13.036537019179256,
      "grad_norm": 6.789791223127395e-05,
      "learning_rate": 2.617950641094325e-06,
      "loss": 0.0,
      "step": 121670
    },
    {
      "epoch": 13.037608486017358,
      "grad_norm": 6.653899617958814e-05,
      "learning_rate": 2.616522018643523e-06,
      "loss": 0.0,
      "step": 121680
    },
    {
      "epoch": 13.038679952855459,
      "grad_norm": 7.086421828716993e-05,
      "learning_rate": 2.6150933961927215e-06,
      "loss": 0.0,
      "step": 121690
    },
    {
      "epoch": 13.03975141969356,
      "grad_norm": 0.00020150656928308308,
      "learning_rate": 2.6136647737419196e-06,
      "loss": 0.0,
      "step": 121700
    },
    {
      "epoch": 13.040822886531663,
      "grad_norm": 6.704802945023403e-05,
      "learning_rate": 2.6122361512911177e-06,
      "loss": 0.0002,
      "step": 121710
    },
    {
      "epoch": 13.041894353369763,
      "grad_norm": 6.5351247030776e-05,
      "learning_rate": 2.6108075288403162e-06,
      "loss": 0.2179,
      "step": 121720
    },
    {
      "epoch": 13.042965820207865,
      "grad_norm": 0.00015208261902444065,
      "learning_rate": 2.6093789063895143e-06,
      "loss": 0.0,
      "step": 121730
    },
    {
      "epoch": 13.044037287045965,
      "grad_norm": 0.00029316311702132225,
      "learning_rate": 2.607950283938712e-06,
      "loss": 0.0,
      "step": 121740
    },
    {
      "epoch": 13.045108753884067,
      "grad_norm": 0.00028930744156241417,
      "learning_rate": 2.606521661487911e-06,
      "loss": 0.0001,
      "step": 121750
    },
    {
      "epoch": 13.046180220722169,
      "grad_norm": 9.714370389701799e-05,
      "learning_rate": 2.6050930390371086e-06,
      "loss": 0.4279,
      "step": 121760
    },
    {
      "epoch": 13.04725168756027,
      "grad_norm": 0.00015540291497018188,
      "learning_rate": 2.6036644165863067e-06,
      "loss": 0.0,
      "step": 121770
    },
    {
      "epoch": 13.048323154398371,
      "grad_norm": 0.0002826355048455298,
      "learning_rate": 2.6022357941355052e-06,
      "loss": 0.0,
      "step": 121780
    },
    {
      "epoch": 13.049394621236473,
      "grad_norm": 8.281596819870174e-05,
      "learning_rate": 2.6008071716847033e-06,
      "loss": 0.0,
      "step": 121790
    },
    {
      "epoch": 13.050466088074574,
      "grad_norm": 0.006301593035459518,
      "learning_rate": 2.5993785492339014e-06,
      "loss": 0.0,
      "step": 121800
    },
    {
      "epoch": 13.051537554912676,
      "grad_norm": 7.106522389221936e-05,
      "learning_rate": 2.5979499267831e-06,
      "loss": 0.0,
      "step": 121810
    },
    {
      "epoch": 13.052609021750778,
      "grad_norm": 7.955996261443943e-05,
      "learning_rate": 2.596521304332298e-06,
      "loss": 0.0,
      "step": 121820
    },
    {
      "epoch": 13.053680488588878,
      "grad_norm": 8.183094905689359e-05,
      "learning_rate": 2.5950926818814957e-06,
      "loss": 0.0,
      "step": 121830
    },
    {
      "epoch": 13.05475195542698,
      "grad_norm": 8.082961721811444e-05,
      "learning_rate": 2.5936640594306942e-06,
      "loss": 0.0,
      "step": 121840
    },
    {
      "epoch": 13.055823422265082,
      "grad_norm": 0.01528544258326292,
      "learning_rate": 2.5922354369798923e-06,
      "loss": 0.0,
      "step": 121850
    },
    {
      "epoch": 13.056894889103182,
      "grad_norm": 0.09984233230352402,
      "learning_rate": 2.5908068145290904e-06,
      "loss": 0.0001,
      "step": 121860
    },
    {
      "epoch": 13.057966355941284,
      "grad_norm": 0.0002875288191717118,
      "learning_rate": 2.589378192078289e-06,
      "loss": 0.0,
      "step": 121870
    },
    {
      "epoch": 13.059037822779384,
      "grad_norm": 8.618733409093693e-05,
      "learning_rate": 2.587949569627487e-06,
      "loss": 0.0,
      "step": 121880
    },
    {
      "epoch": 13.060109289617486,
      "grad_norm": 8.055230864556506e-05,
      "learning_rate": 2.586520947176685e-06,
      "loss": 0.0,
      "step": 121890
    },
    {
      "epoch": 13.061180756455588,
      "grad_norm": 7.247316534630954e-05,
      "learning_rate": 2.585092324725883e-06,
      "loss": 0.0,
      "step": 121900
    },
    {
      "epoch": 13.062252223293688,
      "grad_norm": 8.577423432143405e-05,
      "learning_rate": 2.5836637022750818e-06,
      "loss": 0.0,
      "step": 121910
    },
    {
      "epoch": 13.06332369013179,
      "grad_norm": 8.774945308687165e-05,
      "learning_rate": 2.5822350798242794e-06,
      "loss": 0.001,
      "step": 121920
    },
    {
      "epoch": 13.064395156969892,
      "grad_norm": 7.845320942578837e-05,
      "learning_rate": 2.5808064573734775e-06,
      "loss": 0.0,
      "step": 121930
    },
    {
      "epoch": 13.065466623807993,
      "grad_norm": 7.123610703274608e-05,
      "learning_rate": 2.579377834922676e-06,
      "loss": 0.0,
      "step": 121940
    },
    {
      "epoch": 13.066538090646095,
      "grad_norm": 0.00011235693091293797,
      "learning_rate": 2.577949212471874e-06,
      "loss": 0.0,
      "step": 121950
    },
    {
      "epoch": 13.067609557484197,
      "grad_norm": 8.042048284551129e-05,
      "learning_rate": 2.5765205900210722e-06,
      "loss": 0.0,
      "step": 121960
    },
    {
      "epoch": 13.068681024322297,
      "grad_norm": 0.0001234393857885152,
      "learning_rate": 2.5750919675702708e-06,
      "loss": 0.0,
      "step": 121970
    },
    {
      "epoch": 13.069752491160399,
      "grad_norm": 0.00019740684365388006,
      "learning_rate": 2.573663345119469e-06,
      "loss": 0.0,
      "step": 121980
    },
    {
      "epoch": 13.070823957998499,
      "grad_norm": 7.4426454375498e-05,
      "learning_rate": 2.5722347226686665e-06,
      "loss": 0.0,
      "step": 121990
    },
    {
      "epoch": 13.071895424836601,
      "grad_norm": 7.226727029774338e-05,
      "learning_rate": 2.570806100217865e-06,
      "loss": 0.0001,
      "step": 122000
    },
    {
      "epoch": 13.072966891674703,
      "grad_norm": 8.103336585918441e-05,
      "learning_rate": 2.569377477767063e-06,
      "loss": 0.0,
      "step": 122010
    },
    {
      "epoch": 13.074038358512803,
      "grad_norm": 7.626779552083462e-05,
      "learning_rate": 2.5679488553162612e-06,
      "loss": 0.0,
      "step": 122020
    },
    {
      "epoch": 13.075109825350905,
      "grad_norm": 0.00018463093147147447,
      "learning_rate": 2.5665202328654598e-06,
      "loss": 0.0,
      "step": 122030
    },
    {
      "epoch": 13.076181292189007,
      "grad_norm": 7.247415487654507e-05,
      "learning_rate": 2.565091610414658e-06,
      "loss": 0.0,
      "step": 122040
    },
    {
      "epoch": 13.077252759027107,
      "grad_norm": 0.00010870023834286258,
      "learning_rate": 2.563662987963856e-06,
      "loss": 0.0,
      "step": 122050
    },
    {
      "epoch": 13.07832422586521,
      "grad_norm": 8.983896259451285e-05,
      "learning_rate": 2.5622343655130545e-06,
      "loss": 0.0,
      "step": 122060
    },
    {
      "epoch": 13.079395692703311,
      "grad_norm": 0.00015208883269224316,
      "learning_rate": 2.5608057430622526e-06,
      "loss": 0.0001,
      "step": 122070
    },
    {
      "epoch": 13.080467159541412,
      "grad_norm": 6.58689605188556e-05,
      "learning_rate": 2.5593771206114502e-06,
      "loss": 0.0,
      "step": 122080
    },
    {
      "epoch": 13.081538626379514,
      "grad_norm": 8.45959220896475e-05,
      "learning_rate": 2.5579484981606488e-06,
      "loss": 0.0,
      "step": 122090
    },
    {
      "epoch": 13.082610093217616,
      "grad_norm": 0.0001471668219892308,
      "learning_rate": 2.556519875709847e-06,
      "loss": 0.1533,
      "step": 122100
    },
    {
      "epoch": 13.083681560055716,
      "grad_norm": 0.0001399282627971843,
      "learning_rate": 2.555091253259045e-06,
      "loss": 0.0,
      "step": 122110
    },
    {
      "epoch": 13.084753026893818,
      "grad_norm": 7.635070505784824e-05,
      "learning_rate": 2.5536626308082435e-06,
      "loss": 0.0,
      "step": 122120
    },
    {
      "epoch": 13.085824493731918,
      "grad_norm": 0.0013663930585607886,
      "learning_rate": 2.5522340083574416e-06,
      "loss": 0.0,
      "step": 122130
    },
    {
      "epoch": 13.08689596057002,
      "grad_norm": 9.567150846123695e-05,
      "learning_rate": 2.5508053859066397e-06,
      "loss": 0.1509,
      "step": 122140
    },
    {
      "epoch": 13.087967427408122,
      "grad_norm": 0.00016127951676025987,
      "learning_rate": 2.549376763455838e-06,
      "loss": 0.0004,
      "step": 122150
    },
    {
      "epoch": 13.089038894246222,
      "grad_norm": 7.394651038339362e-05,
      "learning_rate": 2.5479481410050363e-06,
      "loss": 0.0,
      "step": 122160
    },
    {
      "epoch": 13.090110361084324,
      "grad_norm": 7.900944183347747e-05,
      "learning_rate": 2.546519518554234e-06,
      "loss": 0.0001,
      "step": 122170
    },
    {
      "epoch": 13.091181827922426,
      "grad_norm": 0.00011181818990735337,
      "learning_rate": 2.5450908961034325e-06,
      "loss": 0.0,
      "step": 122180
    },
    {
      "epoch": 13.092253294760527,
      "grad_norm": 0.00010291325452271849,
      "learning_rate": 2.5436622736526306e-06,
      "loss": 0.0313,
      "step": 122190
    },
    {
      "epoch": 13.093324761598629,
      "grad_norm": 0.00024125416530296206,
      "learning_rate": 2.5422336512018287e-06,
      "loss": 0.0001,
      "step": 122200
    },
    {
      "epoch": 13.09439622843673,
      "grad_norm": 7.736490806564689e-05,
      "learning_rate": 2.540805028751027e-06,
      "loss": 0.0007,
      "step": 122210
    },
    {
      "epoch": 13.09546769527483,
      "grad_norm": 0.02739751897752285,
      "learning_rate": 2.5393764063002253e-06,
      "loss": 0.0,
      "step": 122220
    },
    {
      "epoch": 13.096539162112933,
      "grad_norm": 0.00013427299563772976,
      "learning_rate": 2.5379477838494234e-06,
      "loss": 0.0,
      "step": 122230
    },
    {
      "epoch": 13.097610628951035,
      "grad_norm": 0.00014020816888660192,
      "learning_rate": 2.536519161398622e-06,
      "loss": 0.0,
      "step": 122240
    },
    {
      "epoch": 13.098682095789135,
      "grad_norm": 7.075782195897773e-05,
      "learning_rate": 2.5350905389478196e-06,
      "loss": 0.0,
      "step": 122250
    },
    {
      "epoch": 13.099753562627237,
      "grad_norm": 15.357227325439453,
      "learning_rate": 2.5336619164970177e-06,
      "loss": 0.1116,
      "step": 122260
    },
    {
      "epoch": 13.100825029465337,
      "grad_norm": 7.765069312881678e-05,
      "learning_rate": 2.532233294046216e-06,
      "loss": 0.0,
      "step": 122270
    },
    {
      "epoch": 13.10189649630344,
      "grad_norm": 8.282780618174002e-05,
      "learning_rate": 2.5308046715954143e-06,
      "loss": 0.0,
      "step": 122280
    },
    {
      "epoch": 13.102967963141541,
      "grad_norm": 0.0001818864984670654,
      "learning_rate": 2.5293760491446124e-06,
      "loss": 0.0,
      "step": 122290
    },
    {
      "epoch": 13.104039429979641,
      "grad_norm": 0.00018430090858601034,
      "learning_rate": 2.527947426693811e-06,
      "loss": 0.0,
      "step": 122300
    },
    {
      "epoch": 13.105110896817743,
      "grad_norm": 7.304937025764957e-05,
      "learning_rate": 2.526518804243009e-06,
      "loss": 0.0,
      "step": 122310
    },
    {
      "epoch": 13.106182363655845,
      "grad_norm": 6.802395364502445e-05,
      "learning_rate": 2.525090181792207e-06,
      "loss": 0.0,
      "step": 122320
    },
    {
      "epoch": 13.107253830493946,
      "grad_norm": 0.00023416097974404693,
      "learning_rate": 2.5236615593414056e-06,
      "loss": 0.0,
      "step": 122330
    },
    {
      "epoch": 13.108325297332048,
      "grad_norm": 8.2617778389249e-05,
      "learning_rate": 2.5222329368906033e-06,
      "loss": 0.1445,
      "step": 122340
    },
    {
      "epoch": 13.10939676417015,
      "grad_norm": 8.06113239377737e-05,
      "learning_rate": 2.5208043144398014e-06,
      "loss": 0.0,
      "step": 122350
    },
    {
      "epoch": 13.11046823100825,
      "grad_norm": 0.00014975697558838874,
      "learning_rate": 2.519375691989e-06,
      "loss": 0.0,
      "step": 122360
    },
    {
      "epoch": 13.111539697846352,
      "grad_norm": 0.00024895090609788895,
      "learning_rate": 2.517947069538198e-06,
      "loss": 0.0,
      "step": 122370
    },
    {
      "epoch": 13.112611164684454,
      "grad_norm": 8.506502490490675e-05,
      "learning_rate": 2.516518447087396e-06,
      "loss": 0.0,
      "step": 122380
    },
    {
      "epoch": 13.113682631522554,
      "grad_norm": 0.00016080048226285726,
      "learning_rate": 2.5150898246365946e-06,
      "loss": 0.0,
      "step": 122390
    },
    {
      "epoch": 13.114754098360656,
      "grad_norm": 7.115755579434335e-05,
      "learning_rate": 2.5136612021857927e-06,
      "loss": 0.0,
      "step": 122400
    },
    {
      "epoch": 13.115825565198756,
      "grad_norm": 7.615464710397646e-05,
      "learning_rate": 2.5122325797349904e-06,
      "loss": 0.0,
      "step": 122410
    },
    {
      "epoch": 13.116897032036858,
      "grad_norm": 8.037892257561907e-05,
      "learning_rate": 2.5108039572841893e-06,
      "loss": 0.1683,
      "step": 122420
    },
    {
      "epoch": 13.11796849887496,
      "grad_norm": 0.00012900406727567315,
      "learning_rate": 2.509375334833387e-06,
      "loss": 0.0,
      "step": 122430
    },
    {
      "epoch": 13.11903996571306,
      "grad_norm": 0.00010405364446341991,
      "learning_rate": 2.507946712382585e-06,
      "loss": 0.0,
      "step": 122440
    },
    {
      "epoch": 13.120111432551163,
      "grad_norm": 0.00024246264365501702,
      "learning_rate": 2.5065180899317836e-06,
      "loss": 0.0,
      "step": 122450
    },
    {
      "epoch": 13.121182899389265,
      "grad_norm": 0.00017619089339859784,
      "learning_rate": 2.5050894674809817e-06,
      "loss": 0.0,
      "step": 122460
    },
    {
      "epoch": 13.122254366227365,
      "grad_norm": 7.648317114217207e-05,
      "learning_rate": 2.50366084503018e-06,
      "loss": 0.0,
      "step": 122470
    },
    {
      "epoch": 13.123325833065467,
      "grad_norm": 7.758974970784038e-05,
      "learning_rate": 2.5022322225793783e-06,
      "loss": 0.0,
      "step": 122480
    },
    {
      "epoch": 13.124397299903569,
      "grad_norm": 9.13308176677674e-05,
      "learning_rate": 2.5008036001285764e-06,
      "loss": 0.0,
      "step": 122490
    },
    {
      "epoch": 13.125468766741669,
      "grad_norm": 0.00024771931930445135,
      "learning_rate": 2.4993749776777745e-06,
      "loss": 0.0,
      "step": 122500
    },
    {
      "epoch": 13.126540233579771,
      "grad_norm": 8.68804709170945e-05,
      "learning_rate": 2.4979463552269726e-06,
      "loss": 0.0,
      "step": 122510
    },
    {
      "epoch": 13.127611700417873,
      "grad_norm": 0.00011347113468218595,
      "learning_rate": 2.4965177327761707e-06,
      "loss": 0.0001,
      "step": 122520
    },
    {
      "epoch": 13.128683167255973,
      "grad_norm": 0.0003686193667817861,
      "learning_rate": 2.4950891103253692e-06,
      "loss": 0.0139,
      "step": 122530
    },
    {
      "epoch": 13.129754634094075,
      "grad_norm": 7.74817744968459e-05,
      "learning_rate": 2.4936604878745673e-06,
      "loss": 0.0,
      "step": 122540
    },
    {
      "epoch": 13.130826100932175,
      "grad_norm": 8.280604379251599e-05,
      "learning_rate": 2.4922318654237654e-06,
      "loss": 0.0,
      "step": 122550
    },
    {
      "epoch": 13.131897567770277,
      "grad_norm": 0.00014750378613825887,
      "learning_rate": 2.4908032429729635e-06,
      "loss": 0.0,
      "step": 122560
    },
    {
      "epoch": 13.13296903460838,
      "grad_norm": 0.0002831566089298576,
      "learning_rate": 2.4893746205221616e-06,
      "loss": 0.0,
      "step": 122570
    },
    {
      "epoch": 13.13404050144648,
      "grad_norm": 8.176130359061062e-05,
      "learning_rate": 2.48794599807136e-06,
      "loss": 0.0,
      "step": 122580
    },
    {
      "epoch": 13.135111968284582,
      "grad_norm": 7.044155790936202e-05,
      "learning_rate": 2.486517375620558e-06,
      "loss": 0.0,
      "step": 122590
    },
    {
      "epoch": 13.136183435122684,
      "grad_norm": 0.00011937368981307372,
      "learning_rate": 2.4850887531697563e-06,
      "loss": 0.0,
      "step": 122600
    },
    {
      "epoch": 13.137254901960784,
      "grad_norm": 0.00022535977768711746,
      "learning_rate": 2.4836601307189544e-06,
      "loss": 0.0,
      "step": 122610
    },
    {
      "epoch": 13.138326368798886,
      "grad_norm": 7.518604979850352e-05,
      "learning_rate": 2.4822315082681525e-06,
      "loss": 0.0,
      "step": 122620
    },
    {
      "epoch": 13.139397835636988,
      "grad_norm": 0.0003074795240536332,
      "learning_rate": 2.4808028858173506e-06,
      "loss": 0.0,
      "step": 122630
    },
    {
      "epoch": 13.140469302475088,
      "grad_norm": 7.476643804693595e-05,
      "learning_rate": 2.479374263366549e-06,
      "loss": 0.0,
      "step": 122640
    },
    {
      "epoch": 13.14154076931319,
      "grad_norm": 0.002970731584355235,
      "learning_rate": 2.4779456409157472e-06,
      "loss": 0.0,
      "step": 122650
    },
    {
      "epoch": 13.14261223615129,
      "grad_norm": 0.00014705595094710588,
      "learning_rate": 2.4765170184649453e-06,
      "loss": 0.0002,
      "step": 122660
    },
    {
      "epoch": 13.143683702989392,
      "grad_norm": 0.00013732067600358278,
      "learning_rate": 2.475088396014144e-06,
      "loss": 0.0,
      "step": 122670
    },
    {
      "epoch": 13.144755169827494,
      "grad_norm": 0.0002570241049397737,
      "learning_rate": 2.4736597735633415e-06,
      "loss": 0.0,
      "step": 122680
    },
    {
      "epoch": 13.145826636665594,
      "grad_norm": 7.521417137468234e-05,
      "learning_rate": 2.47223115111254e-06,
      "loss": 0.0001,
      "step": 122690
    },
    {
      "epoch": 13.146898103503696,
      "grad_norm": 0.00032861941144801676,
      "learning_rate": 2.470802528661738e-06,
      "loss": 0.0,
      "step": 122700
    },
    {
      "epoch": 13.147969570341798,
      "grad_norm": 0.12488172203302383,
      "learning_rate": 2.4693739062109362e-06,
      "loss": 0.0001,
      "step": 122710
    },
    {
      "epoch": 13.149041037179899,
      "grad_norm": 8.731221896596253e-05,
      "learning_rate": 2.4679452837601343e-06,
      "loss": 0.149,
      "step": 122720
    },
    {
      "epoch": 13.150112504018,
      "grad_norm": 8.131052163662389e-05,
      "learning_rate": 2.466516661309333e-06,
      "loss": 0.0,
      "step": 122730
    },
    {
      "epoch": 13.151183970856103,
      "grad_norm": 0.00016344935283996165,
      "learning_rate": 2.465088038858531e-06,
      "loss": 0.0,
      "step": 122740
    },
    {
      "epoch": 13.152255437694203,
      "grad_norm": 0.00015346157306339592,
      "learning_rate": 2.463659416407729e-06,
      "loss": 0.0,
      "step": 122750
    },
    {
      "epoch": 13.153326904532305,
      "grad_norm": 0.00019457584130577743,
      "learning_rate": 2.462230793956927e-06,
      "loss": 0.0009,
      "step": 122760
    },
    {
      "epoch": 13.154398371370407,
      "grad_norm": 0.0001350459933746606,
      "learning_rate": 2.4608021715061252e-06,
      "loss": 0.0,
      "step": 122770
    },
    {
      "epoch": 13.155469838208507,
      "grad_norm": 0.00016689865151420236,
      "learning_rate": 2.4593735490553237e-06,
      "loss": 0.0,
      "step": 122780
    },
    {
      "epoch": 13.15654130504661,
      "grad_norm": 7.479923806386068e-05,
      "learning_rate": 2.457944926604522e-06,
      "loss": 0.0,
      "step": 122790
    },
    {
      "epoch": 13.15761277188471,
      "grad_norm": 0.00012231215077918023,
      "learning_rate": 2.45651630415372e-06,
      "loss": 0.0775,
      "step": 122800
    },
    {
      "epoch": 13.158684238722811,
      "grad_norm": 0.00306259049102664,
      "learning_rate": 2.455087681702918e-06,
      "loss": 0.0,
      "step": 122810
    },
    {
      "epoch": 13.159755705560913,
      "grad_norm": 0.00017756711167749017,
      "learning_rate": 2.4536590592521165e-06,
      "loss": 0.0,
      "step": 122820
    },
    {
      "epoch": 13.160827172399014,
      "grad_norm": 7.854081923142076e-05,
      "learning_rate": 2.4522304368013146e-06,
      "loss": 0.0,
      "step": 122830
    },
    {
      "epoch": 13.161898639237116,
      "grad_norm": 7.899665797594935e-05,
      "learning_rate": 2.4508018143505127e-06,
      "loss": 0.0009,
      "step": 122840
    },
    {
      "epoch": 13.162970106075218,
      "grad_norm": 7.104844553396106e-05,
      "learning_rate": 2.449373191899711e-06,
      "loss": 0.0,
      "step": 122850
    },
    {
      "epoch": 13.164041572913318,
      "grad_norm": 0.0002060482365777716,
      "learning_rate": 2.447944569448909e-06,
      "loss": 0.0007,
      "step": 122860
    },
    {
      "epoch": 13.16511303975142,
      "grad_norm": 7.512101728934795e-05,
      "learning_rate": 2.4465159469981074e-06,
      "loss": 0.0,
      "step": 122870
    },
    {
      "epoch": 13.166184506589522,
      "grad_norm": 7.094954344211146e-05,
      "learning_rate": 2.4450873245473055e-06,
      "loss": 0.0,
      "step": 122880
    },
    {
      "epoch": 13.167255973427622,
      "grad_norm": 0.00019096674805041403,
      "learning_rate": 2.4436587020965036e-06,
      "loss": 0.0,
      "step": 122890
    },
    {
      "epoch": 13.168327440265724,
      "grad_norm": 9.232855518348515e-05,
      "learning_rate": 2.4422300796457017e-06,
      "loss": 0.0003,
      "step": 122900
    },
    {
      "epoch": 13.169398907103826,
      "grad_norm": 6.926897913217545e-05,
      "learning_rate": 2.4408014571949003e-06,
      "loss": 0.0,
      "step": 122910
    },
    {
      "epoch": 13.170470373941926,
      "grad_norm": 0.005974230822175741,
      "learning_rate": 2.4393728347440983e-06,
      "loss": 0.0,
      "step": 122920
    },
    {
      "epoch": 13.171541840780028,
      "grad_norm": 0.00015241667279042304,
      "learning_rate": 2.4379442122932964e-06,
      "loss": 0.0,
      "step": 122930
    },
    {
      "epoch": 13.172613307618128,
      "grad_norm": 0.00013227618183009326,
      "learning_rate": 2.4365155898424945e-06,
      "loss": 0.0004,
      "step": 122940
    },
    {
      "epoch": 13.17368477445623,
      "grad_norm": 6.950714305276051e-05,
      "learning_rate": 2.4350869673916926e-06,
      "loss": 0.0,
      "step": 122950
    },
    {
      "epoch": 13.174756241294332,
      "grad_norm": 0.00013976327318232507,
      "learning_rate": 2.433658344940891e-06,
      "loss": 0.0,
      "step": 122960
    },
    {
      "epoch": 13.175827708132433,
      "grad_norm": 7.452735735569149e-05,
      "learning_rate": 2.4322297224900893e-06,
      "loss": 0.0,
      "step": 122970
    },
    {
      "epoch": 13.176899174970535,
      "grad_norm": 9.83096324489452e-05,
      "learning_rate": 2.4308011000392873e-06,
      "loss": 0.1014,
      "step": 122980
    },
    {
      "epoch": 13.177970641808637,
      "grad_norm": 0.11723946779966354,
      "learning_rate": 2.4293724775884854e-06,
      "loss": 0.0001,
      "step": 122990
    },
    {
      "epoch": 13.179042108646737,
      "grad_norm": 7.089169230312109e-05,
      "learning_rate": 2.427943855137684e-06,
      "loss": 0.0,
      "step": 123000
    },
    {
      "epoch": 13.180113575484839,
      "grad_norm": 7.803340849932283e-05,
      "learning_rate": 2.4265152326868816e-06,
      "loss": 0.0,
      "step": 123010
    },
    {
      "epoch": 13.18118504232294,
      "grad_norm": 7.961129449540749e-05,
      "learning_rate": 2.42508661023608e-06,
      "loss": 0.0,
      "step": 123020
    },
    {
      "epoch": 13.182256509161041,
      "grad_norm": 0.0008622423047199845,
      "learning_rate": 2.4236579877852783e-06,
      "loss": 0.2708,
      "step": 123030
    },
    {
      "epoch": 13.183327975999143,
      "grad_norm": 6.564075010828674e-05,
      "learning_rate": 2.4222293653344763e-06,
      "loss": 0.0,
      "step": 123040
    },
    {
      "epoch": 13.184399442837243,
      "grad_norm": 0.0002833512844517827,
      "learning_rate": 2.420800742883675e-06,
      "loss": 0.0,
      "step": 123050
    },
    {
      "epoch": 13.185470909675345,
      "grad_norm": 7.85870142863132e-05,
      "learning_rate": 2.4193721204328725e-06,
      "loss": 0.0006,
      "step": 123060
    },
    {
      "epoch": 13.186542376513447,
      "grad_norm": 8.084867295110598e-05,
      "learning_rate": 2.417943497982071e-06,
      "loss": 0.0,
      "step": 123070
    },
    {
      "epoch": 13.187613843351548,
      "grad_norm": 7.997720967978239e-05,
      "learning_rate": 2.416514875531269e-06,
      "loss": 0.0,
      "step": 123080
    },
    {
      "epoch": 13.18868531018965,
      "grad_norm": 7.493173325201496e-05,
      "learning_rate": 2.4150862530804673e-06,
      "loss": 0.0,
      "step": 123090
    },
    {
      "epoch": 13.189756777027752,
      "grad_norm": 8.30695717013441e-05,
      "learning_rate": 2.4136576306296653e-06,
      "loss": 0.0,
      "step": 123100
    },
    {
      "epoch": 13.190828243865852,
      "grad_norm": 7.335018017329276e-05,
      "learning_rate": 2.412229008178864e-06,
      "loss": 0.0,
      "step": 123110
    },
    {
      "epoch": 13.191899710703954,
      "grad_norm": 0.00016441001207567751,
      "learning_rate": 2.410800385728062e-06,
      "loss": 0.0,
      "step": 123120
    },
    {
      "epoch": 13.192971177542056,
      "grad_norm": 7.67327073845081e-05,
      "learning_rate": 2.40937176327726e-06,
      "loss": 0.0,
      "step": 123130
    },
    {
      "epoch": 13.194042644380156,
      "grad_norm": 7.393945270450786e-05,
      "learning_rate": 2.407943140826458e-06,
      "loss": 0.0,
      "step": 123140
    },
    {
      "epoch": 13.195114111218258,
      "grad_norm": 0.0028396081179380417,
      "learning_rate": 2.4065145183756563e-06,
      "loss": 0.0,
      "step": 123150
    },
    {
      "epoch": 13.19618557805636,
      "grad_norm": 7.7207681897562e-05,
      "learning_rate": 2.4050858959248548e-06,
      "loss": 0.0,
      "step": 123160
    },
    {
      "epoch": 13.19725704489446,
      "grad_norm": 6.959514576010406e-05,
      "learning_rate": 2.403657273474053e-06,
      "loss": 0.0,
      "step": 123170
    },
    {
      "epoch": 13.198328511732562,
      "grad_norm": 0.0012290095910429955,
      "learning_rate": 2.402228651023251e-06,
      "loss": 0.0,
      "step": 123180
    },
    {
      "epoch": 13.199399978570662,
      "grad_norm": 6.895202386658639e-05,
      "learning_rate": 2.400800028572449e-06,
      "loss": 0.0,
      "step": 123190
    },
    {
      "epoch": 13.200471445408764,
      "grad_norm": 0.00017933077469933778,
      "learning_rate": 2.3993714061216476e-06,
      "loss": 0.0,
      "step": 123200
    },
    {
      "epoch": 13.201542912246866,
      "grad_norm": 0.00017218927678186446,
      "learning_rate": 2.3979427836708457e-06,
      "loss": 0.0,
      "step": 123210
    },
    {
      "epoch": 13.202614379084967,
      "grad_norm": 8.853994950186461e-05,
      "learning_rate": 2.3965141612200438e-06,
      "loss": 0.0,
      "step": 123220
    },
    {
      "epoch": 13.203685845923069,
      "grad_norm": 6.88908839947544e-05,
      "learning_rate": 2.395085538769242e-06,
      "loss": 0.0,
      "step": 123230
    },
    {
      "epoch": 13.20475731276117,
      "grad_norm": 0.20698998868465424,
      "learning_rate": 2.39365691631844e-06,
      "loss": 0.0002,
      "step": 123240
    },
    {
      "epoch": 13.20582877959927,
      "grad_norm": 7.067986007314175e-05,
      "learning_rate": 2.3922282938676385e-06,
      "loss": 0.0,
      "step": 123250
    },
    {
      "epoch": 13.206900246437373,
      "grad_norm": 7.863828795962036e-05,
      "learning_rate": 2.3907996714168366e-06,
      "loss": 0.0,
      "step": 123260
    },
    {
      "epoch": 13.207971713275475,
      "grad_norm": 0.0001241030840901658,
      "learning_rate": 2.3893710489660347e-06,
      "loss": 0.0,
      "step": 123270
    },
    {
      "epoch": 13.209043180113575,
      "grad_norm": 0.0006056767888367176,
      "learning_rate": 2.3879424265152328e-06,
      "loss": 0.0,
      "step": 123280
    },
    {
      "epoch": 13.210114646951677,
      "grad_norm": 0.0004450544947758317,
      "learning_rate": 2.3865138040644313e-06,
      "loss": 0.0,
      "step": 123290
    },
    {
      "epoch": 13.211186113789779,
      "grad_norm": 7.461465429514647e-05,
      "learning_rate": 2.3850851816136294e-06,
      "loss": 0.0,
      "step": 123300
    },
    {
      "epoch": 13.21225758062788,
      "grad_norm": 9.951740503311157e-05,
      "learning_rate": 2.3836565591628275e-06,
      "loss": 0.0,
      "step": 123310
    },
    {
      "epoch": 13.213329047465981,
      "grad_norm": 0.01756253093481064,
      "learning_rate": 2.3822279367120256e-06,
      "loss": 0.0,
      "step": 123320
    },
    {
      "epoch": 13.214400514304081,
      "grad_norm": 0.00011588264897000045,
      "learning_rate": 2.3807993142612237e-06,
      "loss": 0.0,
      "step": 123330
    },
    {
      "epoch": 13.215471981142183,
      "grad_norm": 7.136319618439302e-05,
      "learning_rate": 2.379370691810422e-06,
      "loss": 0.0,
      "step": 123340
    },
    {
      "epoch": 13.216543447980285,
      "grad_norm": 7.38590897526592e-05,
      "learning_rate": 2.3779420693596203e-06,
      "loss": 0.0,
      "step": 123350
    },
    {
      "epoch": 13.217614914818386,
      "grad_norm": 0.00018096607527695596,
      "learning_rate": 2.3765134469088184e-06,
      "loss": 0.0,
      "step": 123360
    },
    {
      "epoch": 13.218686381656488,
      "grad_norm": 7.016611198196188e-05,
      "learning_rate": 2.3750848244580165e-06,
      "loss": 0.0,
      "step": 123370
    },
    {
      "epoch": 13.21975784849459,
      "grad_norm": 0.0009173538419418037,
      "learning_rate": 2.373656202007215e-06,
      "loss": 0.0,
      "step": 123380
    },
    {
      "epoch": 13.22082931533269,
      "grad_norm": 0.00017144542653113604,
      "learning_rate": 2.3722275795564127e-06,
      "loss": 0.0,
      "step": 123390
    },
    {
      "epoch": 13.221900782170792,
      "grad_norm": 7.371592801064253e-05,
      "learning_rate": 2.370798957105611e-06,
      "loss": 0.0,
      "step": 123400
    },
    {
      "epoch": 13.222972249008894,
      "grad_norm": 6.878342537675053e-05,
      "learning_rate": 2.3693703346548093e-06,
      "loss": 0.0,
      "step": 123410
    },
    {
      "epoch": 13.224043715846994,
      "grad_norm": 7.123703835532069e-05,
      "learning_rate": 2.3679417122040074e-06,
      "loss": 0.0,
      "step": 123420
    },
    {
      "epoch": 13.225115182685096,
      "grad_norm": 0.0001592530752532184,
      "learning_rate": 2.366513089753206e-06,
      "loss": 0.0,
      "step": 123430
    },
    {
      "epoch": 13.226186649523198,
      "grad_norm": 0.002755126915872097,
      "learning_rate": 2.365084467302404e-06,
      "loss": 0.0,
      "step": 123440
    },
    {
      "epoch": 13.227258116361298,
      "grad_norm": 7.462514622602612e-05,
      "learning_rate": 2.363655844851602e-06,
      "loss": 0.0,
      "step": 123450
    },
    {
      "epoch": 13.2283295831994,
      "grad_norm": 0.00020091267651878297,
      "learning_rate": 2.3622272224008e-06,
      "loss": 0.0,
      "step": 123460
    },
    {
      "epoch": 13.2294010500375,
      "grad_norm": 7.294938404811546e-05,
      "learning_rate": 2.3607985999499983e-06,
      "loss": 0.0364,
      "step": 123470
    },
    {
      "epoch": 13.230472516875603,
      "grad_norm": 0.00014423362154047936,
      "learning_rate": 2.3593699774991964e-06,
      "loss": 0.0,
      "step": 123480
    },
    {
      "epoch": 13.231543983713705,
      "grad_norm": 7.745360198896378e-05,
      "learning_rate": 2.357941355048395e-06,
      "loss": 0.0519,
      "step": 123490
    },
    {
      "epoch": 13.232615450551805,
      "grad_norm": 7.095139881130308e-05,
      "learning_rate": 2.356512732597593e-06,
      "loss": 0.0644,
      "step": 123500
    },
    {
      "epoch": 13.233686917389907,
      "grad_norm": 0.0006034194375388324,
      "learning_rate": 2.355084110146791e-06,
      "loss": 0.0,
      "step": 123510
    },
    {
      "epoch": 13.234758384228009,
      "grad_norm": 7.779052975820377e-05,
      "learning_rate": 2.353655487695989e-06,
      "loss": 0.0,
      "step": 123520
    },
    {
      "epoch": 13.235829851066109,
      "grad_norm": 7.017140160314739e-05,
      "learning_rate": 2.3522268652451873e-06,
      "loss": 0.0,
      "step": 123530
    },
    {
      "epoch": 13.236901317904211,
      "grad_norm": 0.004865732509642839,
      "learning_rate": 2.350798242794386e-06,
      "loss": 0.0,
      "step": 123540
    },
    {
      "epoch": 13.237972784742313,
      "grad_norm": 7.031570567050949e-05,
      "learning_rate": 2.349369620343584e-06,
      "loss": 0.0444,
      "step": 123550
    },
    {
      "epoch": 13.239044251580413,
      "grad_norm": 8.015113417059183e-05,
      "learning_rate": 2.347940997892782e-06,
      "loss": 0.0,
      "step": 123560
    },
    {
      "epoch": 13.240115718418515,
      "grad_norm": 7.303095480892807e-05,
      "learning_rate": 2.34651237544198e-06,
      "loss": 0.0999,
      "step": 123570
    },
    {
      "epoch": 13.241187185256617,
      "grad_norm": 0.00017804816889110953,
      "learning_rate": 2.3450837529911786e-06,
      "loss": 0.0,
      "step": 123580
    },
    {
      "epoch": 13.242258652094717,
      "grad_norm": 0.000226921183639206,
      "learning_rate": 2.3436551305403767e-06,
      "loss": 0.0,
      "step": 123590
    },
    {
      "epoch": 13.24333011893282,
      "grad_norm": 0.005136934574693441,
      "learning_rate": 2.342226508089575e-06,
      "loss": 0.0,
      "step": 123600
    },
    {
      "epoch": 13.24440158577092,
      "grad_norm": 0.00026202949811704457,
      "learning_rate": 2.340797885638773e-06,
      "loss": 0.0,
      "step": 123610
    },
    {
      "epoch": 13.245473052609022,
      "grad_norm": 0.00022368496865965426,
      "learning_rate": 2.339369263187971e-06,
      "loss": 0.0,
      "step": 123620
    },
    {
      "epoch": 13.246544519447124,
      "grad_norm": 7.046778046060354e-05,
      "learning_rate": 2.3379406407371695e-06,
      "loss": 0.0,
      "step": 123630
    },
    {
      "epoch": 13.247615986285224,
      "grad_norm": 0.0009934194386005402,
      "learning_rate": 2.3365120182863676e-06,
      "loss": 0.0,
      "step": 123640
    },
    {
      "epoch": 13.248687453123326,
      "grad_norm": 0.0001637409150134772,
      "learning_rate": 2.3350833958355657e-06,
      "loss": 0.2027,
      "step": 123650
    },
    {
      "epoch": 13.249758919961428,
      "grad_norm": 0.00010403155465610325,
      "learning_rate": 2.333654773384764e-06,
      "loss": 0.0,
      "step": 123660
    },
    {
      "epoch": 13.250830386799528,
      "grad_norm": 6.528222002089024e-05,
      "learning_rate": 2.3322261509339623e-06,
      "loss": 0.0001,
      "step": 123670
    },
    {
      "epoch": 13.25190185363763,
      "grad_norm": 0.00018539204029366374,
      "learning_rate": 2.33079752848316e-06,
      "loss": 0.0,
      "step": 123680
    },
    {
      "epoch": 13.252973320475732,
      "grad_norm": 6.0617610870394856e-05,
      "learning_rate": 2.3293689060323585e-06,
      "loss": 0.0,
      "step": 123690
    },
    {
      "epoch": 13.254044787313832,
      "grad_norm": 0.00032783631468191743,
      "learning_rate": 2.3279402835815566e-06,
      "loss": 0.0,
      "step": 123700
    },
    {
      "epoch": 13.255116254151934,
      "grad_norm": 7.634003122802824e-05,
      "learning_rate": 2.3265116611307547e-06,
      "loss": 0.0,
      "step": 123710
    },
    {
      "epoch": 13.256187720990035,
      "grad_norm": 7.270041533047333e-05,
      "learning_rate": 2.3250830386799532e-06,
      "loss": 0.0,
      "step": 123720
    },
    {
      "epoch": 13.257259187828137,
      "grad_norm": 7.163920236052945e-05,
      "learning_rate": 2.3236544162291513e-06,
      "loss": 0.0928,
      "step": 123730
    },
    {
      "epoch": 13.258330654666239,
      "grad_norm": 0.00018168205861002207,
      "learning_rate": 2.3222257937783494e-06,
      "loss": 0.0,
      "step": 123740
    },
    {
      "epoch": 13.259402121504339,
      "grad_norm": 0.00016321797738783062,
      "learning_rate": 2.3207971713275475e-06,
      "loss": 0.0,
      "step": 123750
    },
    {
      "epoch": 13.26047358834244,
      "grad_norm": 7.927727710921317e-05,
      "learning_rate": 2.319368548876746e-06,
      "loss": 0.0,
      "step": 123760
    },
    {
      "epoch": 13.261545055180543,
      "grad_norm": 0.00010155441850656644,
      "learning_rate": 2.3179399264259437e-06,
      "loss": 0.0,
      "step": 123770
    },
    {
      "epoch": 13.262616522018643,
      "grad_norm": 7.325221667997539e-05,
      "learning_rate": 2.3165113039751422e-06,
      "loss": 0.0,
      "step": 123780
    },
    {
      "epoch": 13.263687988856745,
      "grad_norm": 7.726448529865593e-05,
      "learning_rate": 2.3150826815243403e-06,
      "loss": 0.0,
      "step": 123790
    },
    {
      "epoch": 13.264759455694847,
      "grad_norm": 0.00020298025629017502,
      "learning_rate": 2.3136540590735384e-06,
      "loss": 0.0,
      "step": 123800
    },
    {
      "epoch": 13.265830922532947,
      "grad_norm": 0.00018313780310563743,
      "learning_rate": 2.312225436622737e-06,
      "loss": 0.0,
      "step": 123810
    },
    {
      "epoch": 13.26690238937105,
      "grad_norm": 0.17728199064731598,
      "learning_rate": 2.310796814171935e-06,
      "loss": 0.0,
      "step": 123820
    },
    {
      "epoch": 13.267973856209151,
      "grad_norm": 0.00022431339311879128,
      "learning_rate": 2.309368191721133e-06,
      "loss": 0.0,
      "step": 123830
    },
    {
      "epoch": 13.269045323047251,
      "grad_norm": 0.0003461245505604893,
      "learning_rate": 2.3079395692703312e-06,
      "loss": 0.0,
      "step": 123840
    },
    {
      "epoch": 13.270116789885353,
      "grad_norm": 0.0001494083844590932,
      "learning_rate": 2.3065109468195298e-06,
      "loss": 0.0,
      "step": 123850
    },
    {
      "epoch": 13.271188256723454,
      "grad_norm": 0.00010560436930973083,
      "learning_rate": 2.3050823243687274e-06,
      "loss": 0.0,
      "step": 123860
    },
    {
      "epoch": 13.272259723561556,
      "grad_norm": 0.00020081216644030064,
      "learning_rate": 2.303653701917926e-06,
      "loss": 0.0003,
      "step": 123870
    },
    {
      "epoch": 13.273331190399658,
      "grad_norm": 0.030585553497076035,
      "learning_rate": 2.302225079467124e-06,
      "loss": 0.0116,
      "step": 123880
    },
    {
      "epoch": 13.274402657237758,
      "grad_norm": 0.00015487903147004545,
      "learning_rate": 2.300796457016322e-06,
      "loss": 0.0,
      "step": 123890
    },
    {
      "epoch": 13.27547412407586,
      "grad_norm": 7.814814307494089e-05,
      "learning_rate": 2.2993678345655202e-06,
      "loss": 0.0,
      "step": 123900
    },
    {
      "epoch": 13.276545590913962,
      "grad_norm": 0.00029512797482311726,
      "learning_rate": 2.2979392121147187e-06,
      "loss": 0.0,
      "step": 123910
    },
    {
      "epoch": 13.277617057752062,
      "grad_norm": 6.729536107741296e-05,
      "learning_rate": 2.296510589663917e-06,
      "loss": 0.0,
      "step": 123920
    },
    {
      "epoch": 13.278688524590164,
      "grad_norm": 8.515033550793305e-05,
      "learning_rate": 2.295081967213115e-06,
      "loss": 0.0,
      "step": 123930
    },
    {
      "epoch": 13.279759991428266,
      "grad_norm": 7.138537330320105e-05,
      "learning_rate": 2.293653344762313e-06,
      "loss": 0.17,
      "step": 123940
    },
    {
      "epoch": 13.280831458266366,
      "grad_norm": 7.081824878696352e-05,
      "learning_rate": 2.292224722311511e-06,
      "loss": 0.0,
      "step": 123950
    },
    {
      "epoch": 13.281902925104468,
      "grad_norm": 0.00010055496386485174,
      "learning_rate": 2.2907960998607097e-06,
      "loss": 0.0,
      "step": 123960
    },
    {
      "epoch": 13.28297439194257,
      "grad_norm": 7.012123387539759e-05,
      "learning_rate": 2.2893674774099077e-06,
      "loss": 0.0,
      "step": 123970
    },
    {
      "epoch": 13.28404585878067,
      "grad_norm": 7.565668056486174e-05,
      "learning_rate": 2.287938854959106e-06,
      "loss": 0.0002,
      "step": 123980
    },
    {
      "epoch": 13.285117325618772,
      "grad_norm": 8.880242239683867e-05,
      "learning_rate": 2.286510232508304e-06,
      "loss": 0.0,
      "step": 123990
    },
    {
      "epoch": 13.286188792456873,
      "grad_norm": 0.00021391475456766784,
      "learning_rate": 2.285081610057502e-06,
      "loss": 0.0004,
      "step": 124000
    },
    {
      "epoch": 13.287260259294975,
      "grad_norm": 0.00036504180752672255,
      "learning_rate": 2.2836529876067006e-06,
      "loss": 0.0,
      "step": 124010
    },
    {
      "epoch": 13.288331726133077,
      "grad_norm": 0.04791923612356186,
      "learning_rate": 2.2822243651558987e-06,
      "loss": 0.0,
      "step": 124020
    },
    {
      "epoch": 13.289403192971177,
      "grad_norm": 0.0029079546220600605,
      "learning_rate": 2.2807957427050967e-06,
      "loss": 0.0,
      "step": 124030
    },
    {
      "epoch": 13.290474659809279,
      "grad_norm": 7.239502156153321e-05,
      "learning_rate": 2.279367120254295e-06,
      "loss": 0.0,
      "step": 124040
    },
    {
      "epoch": 13.29154612664738,
      "grad_norm": 6.770563777536154e-05,
      "learning_rate": 2.2779384978034934e-06,
      "loss": 0.0,
      "step": 124050
    },
    {
      "epoch": 13.292617593485481,
      "grad_norm": 7.424777140840888e-05,
      "learning_rate": 2.276509875352691e-06,
      "loss": 0.0,
      "step": 124060
    },
    {
      "epoch": 13.293689060323583,
      "grad_norm": 7.365585770457983e-05,
      "learning_rate": 2.2750812529018896e-06,
      "loss": 0.0,
      "step": 124070
    },
    {
      "epoch": 13.294760527161685,
      "grad_norm": 7.056238973746076e-05,
      "learning_rate": 2.2736526304510877e-06,
      "loss": 0.0,
      "step": 124080
    },
    {
      "epoch": 13.295831993999785,
      "grad_norm": 7.501189247705042e-05,
      "learning_rate": 2.2722240080002857e-06,
      "loss": 0.0,
      "step": 124090
    },
    {
      "epoch": 13.296903460837887,
      "grad_norm": 7.025878585409373e-05,
      "learning_rate": 2.2707953855494843e-06,
      "loss": 0.0001,
      "step": 124100
    },
    {
      "epoch": 13.297974927675988,
      "grad_norm": 7.194342470029369e-05,
      "learning_rate": 2.2693667630986824e-06,
      "loss": 0.0,
      "step": 124110
    },
    {
      "epoch": 13.29904639451409,
      "grad_norm": 7.301530422409996e-05,
      "learning_rate": 2.2679381406478805e-06,
      "loss": 0.0,
      "step": 124120
    },
    {
      "epoch": 13.300117861352192,
      "grad_norm": 8.85628251126036e-05,
      "learning_rate": 2.2665095181970786e-06,
      "loss": 0.0,
      "step": 124130
    },
    {
      "epoch": 13.301189328190292,
      "grad_norm": 7.464629015885293e-05,
      "learning_rate": 2.265080895746277e-06,
      "loss": 0.0,
      "step": 124140
    },
    {
      "epoch": 13.302260795028394,
      "grad_norm": 7.517771882703528e-05,
      "learning_rate": 2.2636522732954747e-06,
      "loss": 0.0,
      "step": 124150
    },
    {
      "epoch": 13.303332261866496,
      "grad_norm": 7.324825855903327e-05,
      "learning_rate": 2.2622236508446733e-06,
      "loss": 0.0,
      "step": 124160
    },
    {
      "epoch": 13.304403728704596,
      "grad_norm": 7.688858022447675e-05,
      "learning_rate": 2.2607950283938714e-06,
      "loss": 0.0,
      "step": 124170
    },
    {
      "epoch": 13.305475195542698,
      "grad_norm": 8.424502448178828e-05,
      "learning_rate": 2.2593664059430695e-06,
      "loss": 0.0,
      "step": 124180
    },
    {
      "epoch": 13.3065466623808,
      "grad_norm": 8.323226211359724e-05,
      "learning_rate": 2.257937783492268e-06,
      "loss": 0.0,
      "step": 124190
    },
    {
      "epoch": 13.3076181292189,
      "grad_norm": 0.00026145458105020225,
      "learning_rate": 2.256509161041466e-06,
      "loss": 0.0,
      "step": 124200
    },
    {
      "epoch": 13.308689596057002,
      "grad_norm": 0.0023291308898478746,
      "learning_rate": 2.255080538590664e-06,
      "loss": 0.0,
      "step": 124210
    },
    {
      "epoch": 13.309761062895104,
      "grad_norm": 0.00014388382260221988,
      "learning_rate": 2.2536519161398623e-06,
      "loss": 0.0,
      "step": 124220
    },
    {
      "epoch": 13.310832529733204,
      "grad_norm": 0.0002163435856346041,
      "learning_rate": 2.2522232936890608e-06,
      "loss": 0.0,
      "step": 124230
    },
    {
      "epoch": 13.311903996571306,
      "grad_norm": 0.00014762385399080813,
      "learning_rate": 2.2507946712382585e-06,
      "loss": 0.0,
      "step": 124240
    },
    {
      "epoch": 13.312975463409407,
      "grad_norm": 0.00031771318754181266,
      "learning_rate": 2.249366048787457e-06,
      "loss": 0.0,
      "step": 124250
    },
    {
      "epoch": 13.314046930247509,
      "grad_norm": 0.00016892682469915599,
      "learning_rate": 2.247937426336655e-06,
      "loss": 0.0,
      "step": 124260
    },
    {
      "epoch": 13.31511839708561,
      "grad_norm": 0.0001663471630308777,
      "learning_rate": 2.246508803885853e-06,
      "loss": 0.0,
      "step": 124270
    },
    {
      "epoch": 13.31618986392371,
      "grad_norm": 7.521664520027116e-05,
      "learning_rate": 2.2450801814350513e-06,
      "loss": 0.0,
      "step": 124280
    },
    {
      "epoch": 13.317261330761813,
      "grad_norm": 7.729870412731543e-05,
      "learning_rate": 2.2436515589842498e-06,
      "loss": 0.0,
      "step": 124290
    },
    {
      "epoch": 13.318332797599915,
      "grad_norm": 0.00010873345308937132,
      "learning_rate": 2.242222936533448e-06,
      "loss": 0.0,
      "step": 124300
    },
    {
      "epoch": 13.319404264438015,
      "grad_norm": 0.00012485409388318658,
      "learning_rate": 2.240794314082646e-06,
      "loss": 0.0033,
      "step": 124310
    },
    {
      "epoch": 13.320475731276117,
      "grad_norm": 6.22683364781551e-05,
      "learning_rate": 2.2393656916318445e-06,
      "loss": 0.0002,
      "step": 124320
    },
    {
      "epoch": 13.321547198114219,
      "grad_norm": 0.00011980655835941434,
      "learning_rate": 2.237937069181042e-06,
      "loss": 0.0001,
      "step": 124330
    },
    {
      "epoch": 13.32261866495232,
      "grad_norm": 0.00012091881217202172,
      "learning_rate": 2.2365084467302407e-06,
      "loss": 0.0,
      "step": 124340
    },
    {
      "epoch": 13.323690131790421,
      "grad_norm": 6.487900827778503e-05,
      "learning_rate": 2.2350798242794388e-06,
      "loss": 0.0,
      "step": 124350
    },
    {
      "epoch": 13.324761598628523,
      "grad_norm": 6.468037463491783e-05,
      "learning_rate": 2.233651201828637e-06,
      "loss": 0.0003,
      "step": 124360
    },
    {
      "epoch": 13.325833065466623,
      "grad_norm": 6.959716120036319e-05,
      "learning_rate": 2.232222579377835e-06,
      "loss": 0.0,
      "step": 124370
    },
    {
      "epoch": 13.326904532304725,
      "grad_norm": 7.11604006937705e-05,
      "learning_rate": 2.230793956927033e-06,
      "loss": 0.0,
      "step": 124380
    },
    {
      "epoch": 13.327975999142826,
      "grad_norm": 0.004925413988530636,
      "learning_rate": 2.2293653344762316e-06,
      "loss": 0.0,
      "step": 124390
    },
    {
      "epoch": 13.329047465980928,
      "grad_norm": 6.840378773631528e-05,
      "learning_rate": 2.2279367120254297e-06,
      "loss": 0.0,
      "step": 124400
    },
    {
      "epoch": 13.33011893281903,
      "grad_norm": 6.384253356372938e-05,
      "learning_rate": 2.2265080895746278e-06,
      "loss": 0.0,
      "step": 124410
    },
    {
      "epoch": 13.33119039965713,
      "grad_norm": 0.11115080118179321,
      "learning_rate": 2.225079467123826e-06,
      "loss": 0.0001,
      "step": 124420
    },
    {
      "epoch": 13.332261866495232,
      "grad_norm": 6.822939758421853e-05,
      "learning_rate": 2.2236508446730244e-06,
      "loss": 0.0,
      "step": 124430
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.00015098540461622179,
      "learning_rate": 2.222222222222222e-06,
      "loss": 0.0,
      "step": 124440
    },
    {
      "epoch": 13.334404800171434,
      "grad_norm": 7.375566201517358e-05,
      "learning_rate": 2.2207935997714206e-06,
      "loss": 0.0,
      "step": 124450
    },
    {
      "epoch": 13.335476267009536,
      "grad_norm": 6.732971087330952e-05,
      "learning_rate": 2.2193649773206187e-06,
      "loss": 0.0,
      "step": 124460
    },
    {
      "epoch": 13.336547733847638,
      "grad_norm": 0.0001680044224485755,
      "learning_rate": 2.2179363548698168e-06,
      "loss": 0.0,
      "step": 124470
    },
    {
      "epoch": 13.337619200685738,
      "grad_norm": 0.00016216713993344456,
      "learning_rate": 2.2165077324190153e-06,
      "loss": 0.0,
      "step": 124480
    },
    {
      "epoch": 13.33869066752384,
      "grad_norm": 6.545999349327758e-05,
      "learning_rate": 2.2150791099682134e-06,
      "loss": 0.0,
      "step": 124490
    },
    {
      "epoch": 13.33976213436194,
      "grad_norm": 0.00013349228538572788,
      "learning_rate": 2.2136504875174115e-06,
      "loss": 0.0,
      "step": 124500
    },
    {
      "epoch": 13.340833601200043,
      "grad_norm": 6.789746839785948e-05,
      "learning_rate": 2.2122218650666096e-06,
      "loss": 0.0,
      "step": 124510
    },
    {
      "epoch": 13.341905068038145,
      "grad_norm": 7.271103095263243e-05,
      "learning_rate": 2.210793242615808e-06,
      "loss": 0.0,
      "step": 124520
    },
    {
      "epoch": 13.342976534876245,
      "grad_norm": 6.275097985053435e-05,
      "learning_rate": 2.2093646201650058e-06,
      "loss": 0.0,
      "step": 124530
    },
    {
      "epoch": 13.344048001714347,
      "grad_norm": 6.634676537942141e-05,
      "learning_rate": 2.2079359977142043e-06,
      "loss": 0.0,
      "step": 124540
    },
    {
      "epoch": 13.345119468552449,
      "grad_norm": 6.240326183615252e-05,
      "learning_rate": 2.2065073752634024e-06,
      "loss": 0.0,
      "step": 124550
    },
    {
      "epoch": 13.346190935390549,
      "grad_norm": 6.527371442643926e-05,
      "learning_rate": 2.2050787528126005e-06,
      "loss": 0.0,
      "step": 124560
    },
    {
      "epoch": 13.347262402228651,
      "grad_norm": 0.00031854381086304784,
      "learning_rate": 2.203650130361799e-06,
      "loss": 0.0,
      "step": 124570
    },
    {
      "epoch": 13.348333869066753,
      "grad_norm": 0.001345321536064148,
      "learning_rate": 2.202221507910997e-06,
      "loss": 0.0,
      "step": 124580
    },
    {
      "epoch": 13.349405335904853,
      "grad_norm": 0.00021363490668591112,
      "learning_rate": 2.200792885460195e-06,
      "loss": 0.0,
      "step": 124590
    },
    {
      "epoch": 13.350476802742955,
      "grad_norm": 0.0021965941414237022,
      "learning_rate": 2.1993642630093933e-06,
      "loss": 0.0,
      "step": 124600
    },
    {
      "epoch": 13.351548269581057,
      "grad_norm": 0.00015776792133692652,
      "learning_rate": 2.197935640558592e-06,
      "loss": 0.14,
      "step": 124610
    },
    {
      "epoch": 13.352619736419157,
      "grad_norm": 6.694092007819563e-05,
      "learning_rate": 2.1965070181077895e-06,
      "loss": 0.0001,
      "step": 124620
    },
    {
      "epoch": 13.35369120325726,
      "grad_norm": 0.00016882765339687467,
      "learning_rate": 2.195078395656988e-06,
      "loss": 0.0,
      "step": 124630
    },
    {
      "epoch": 13.354762670095361,
      "grad_norm": 0.0001158938612206839,
      "learning_rate": 2.193649773206186e-06,
      "loss": 0.0,
      "step": 124640
    },
    {
      "epoch": 13.355834136933462,
      "grad_norm": 7.227651076391339e-05,
      "learning_rate": 2.192221150755384e-06,
      "loss": 0.0005,
      "step": 124650
    },
    {
      "epoch": 13.356905603771564,
      "grad_norm": 0.00011671188258333132,
      "learning_rate": 2.1907925283045823e-06,
      "loss": 0.0002,
      "step": 124660
    },
    {
      "epoch": 13.357977070609664,
      "grad_norm": 6.597454921575263e-05,
      "learning_rate": 2.189363905853781e-06,
      "loss": 0.0,
      "step": 124670
    },
    {
      "epoch": 13.359048537447766,
      "grad_norm": 6.681127706542611e-05,
      "learning_rate": 2.187935283402979e-06,
      "loss": 0.0,
      "step": 124680
    },
    {
      "epoch": 13.360120004285868,
      "grad_norm": 0.0008786753751337528,
      "learning_rate": 2.186506660952177e-06,
      "loss": 0.0,
      "step": 124690
    },
    {
      "epoch": 13.361191471123968,
      "grad_norm": 6.801576819270849e-05,
      "learning_rate": 2.1850780385013755e-06,
      "loss": 0.0,
      "step": 124700
    },
    {
      "epoch": 13.36226293796207,
      "grad_norm": 0.00010773423127830029,
      "learning_rate": 2.183649416050573e-06,
      "loss": 0.0,
      "step": 124710
    },
    {
      "epoch": 13.363334404800172,
      "grad_norm": 6.806237070122734e-05,
      "learning_rate": 2.1822207935997717e-06,
      "loss": 0.147,
      "step": 124720
    },
    {
      "epoch": 13.364405871638272,
      "grad_norm": 6.88024956616573e-05,
      "learning_rate": 2.18079217114897e-06,
      "loss": 0.0,
      "step": 124730
    },
    {
      "epoch": 13.365477338476374,
      "grad_norm": 0.00020108863827772439,
      "learning_rate": 2.179363548698168e-06,
      "loss": 0.0001,
      "step": 124740
    },
    {
      "epoch": 13.366548805314476,
      "grad_norm": 0.0001459606282878667,
      "learning_rate": 2.177934926247366e-06,
      "loss": 0.0,
      "step": 124750
    },
    {
      "epoch": 13.367620272152577,
      "grad_norm": 0.00013938687334302813,
      "learning_rate": 2.1765063037965645e-06,
      "loss": 0.0,
      "step": 124760
    },
    {
      "epoch": 13.368691738990679,
      "grad_norm": 0.0010002456838265061,
      "learning_rate": 2.1750776813457626e-06,
      "loss": 0.0,
      "step": 124770
    },
    {
      "epoch": 13.369763205828779,
      "grad_norm": 6.761252006981522e-05,
      "learning_rate": 2.1736490588949607e-06,
      "loss": 0.0,
      "step": 124780
    },
    {
      "epoch": 13.37083467266688,
      "grad_norm": 9.282390237785876e-05,
      "learning_rate": 2.172220436444159e-06,
      "loss": 0.0,
      "step": 124790
    },
    {
      "epoch": 13.371906139504983,
      "grad_norm": 0.00010651836055330932,
      "learning_rate": 2.170791813993357e-06,
      "loss": 0.0,
      "step": 124800
    },
    {
      "epoch": 13.372977606343083,
      "grad_norm": 0.00016125396359711885,
      "learning_rate": 2.1693631915425554e-06,
      "loss": 0.0,
      "step": 124810
    },
    {
      "epoch": 13.374049073181185,
      "grad_norm": 6.653310265392065e-05,
      "learning_rate": 2.167934569091753e-06,
      "loss": 0.0,
      "step": 124820
    },
    {
      "epoch": 13.375120540019287,
      "grad_norm": 6.240616494324058e-05,
      "learning_rate": 2.1665059466409516e-06,
      "loss": 0.0,
      "step": 124830
    },
    {
      "epoch": 13.376192006857387,
      "grad_norm": 7.641335105290636e-05,
      "learning_rate": 2.1650773241901497e-06,
      "loss": 0.0,
      "step": 124840
    },
    {
      "epoch": 13.37726347369549,
      "grad_norm": 6.674018368357792e-05,
      "learning_rate": 2.163648701739348e-06,
      "loss": 0.0,
      "step": 124850
    },
    {
      "epoch": 13.378334940533591,
      "grad_norm": 0.00012141017941758037,
      "learning_rate": 2.1622200792885463e-06,
      "loss": 0.0,
      "step": 124860
    },
    {
      "epoch": 13.379406407371691,
      "grad_norm": 0.00012671720469370484,
      "learning_rate": 2.1607914568377444e-06,
      "loss": 0.0,
      "step": 124870
    },
    {
      "epoch": 13.380477874209793,
      "grad_norm": 0.0002691128756850958,
      "learning_rate": 2.1593628343869425e-06,
      "loss": 0.0,
      "step": 124880
    },
    {
      "epoch": 13.381549341047895,
      "grad_norm": 6.290088640525937e-05,
      "learning_rate": 2.1579342119361406e-06,
      "loss": 0.0,
      "step": 124890
    },
    {
      "epoch": 13.382620807885996,
      "grad_norm": 0.00016308444901369512,
      "learning_rate": 2.156505589485339e-06,
      "loss": 0.0,
      "step": 124900
    },
    {
      "epoch": 13.383692274724098,
      "grad_norm": 6.866328476462513e-05,
      "learning_rate": 2.155076967034537e-06,
      "loss": 0.0,
      "step": 124910
    },
    {
      "epoch": 13.384763741562198,
      "grad_norm": 6.825642049079761e-05,
      "learning_rate": 2.1536483445837353e-06,
      "loss": 0.0,
      "step": 124920
    },
    {
      "epoch": 13.3858352084003,
      "grad_norm": 0.00013727587065659463,
      "learning_rate": 2.1522197221329334e-06,
      "loss": 0.0,
      "step": 124930
    },
    {
      "epoch": 13.386906675238402,
      "grad_norm": 7.18015871825628e-05,
      "learning_rate": 2.1507910996821315e-06,
      "loss": 0.0,
      "step": 124940
    },
    {
      "epoch": 13.387978142076502,
      "grad_norm": 0.0002050493931164965,
      "learning_rate": 2.14936247723133e-06,
      "loss": 0.0,
      "step": 124950
    },
    {
      "epoch": 13.389049608914604,
      "grad_norm": 9.17980432859622e-05,
      "learning_rate": 2.147933854780528e-06,
      "loss": 0.0,
      "step": 124960
    },
    {
      "epoch": 13.390121075752706,
      "grad_norm": 6.871402001706883e-05,
      "learning_rate": 2.1465052323297262e-06,
      "loss": 0.0,
      "step": 124970
    },
    {
      "epoch": 13.391192542590806,
      "grad_norm": 0.0010705317836254835,
      "learning_rate": 2.1450766098789243e-06,
      "loss": 0.0,
      "step": 124980
    },
    {
      "epoch": 13.392264009428908,
      "grad_norm": 0.0003219528589397669,
      "learning_rate": 2.143647987428123e-06,
      "loss": 0.0003,
      "step": 124990
    },
    {
      "epoch": 13.39333547626701,
      "grad_norm": 6.878782733110711e-05,
      "learning_rate": 2.1422193649773205e-06,
      "loss": 0.0,
      "step": 125000
    },
    {
      "epoch": 13.39440694310511,
      "grad_norm": 6.811080675106496e-05,
      "learning_rate": 2.140790742526519e-06,
      "loss": 0.0,
      "step": 125010
    },
    {
      "epoch": 13.395478409943212,
      "grad_norm": 6.518258305732161e-05,
      "learning_rate": 2.139362120075717e-06,
      "loss": 0.0,
      "step": 125020
    },
    {
      "epoch": 13.396549876781314,
      "grad_norm": 6.390293128788471e-05,
      "learning_rate": 2.1379334976249152e-06,
      "loss": 0.0001,
      "step": 125030
    },
    {
      "epoch": 13.397621343619415,
      "grad_norm": 7.559343066532165e-05,
      "learning_rate": 2.1365048751741133e-06,
      "loss": 0.0,
      "step": 125040
    },
    {
      "epoch": 13.398692810457517,
      "grad_norm": 6.914839468663558e-05,
      "learning_rate": 2.135076252723312e-06,
      "loss": 0.0,
      "step": 125050
    },
    {
      "epoch": 13.399764277295617,
      "grad_norm": 0.26912522315979004,
      "learning_rate": 2.13364763027251e-06,
      "loss": 0.0003,
      "step": 125060
    },
    {
      "epoch": 13.400835744133719,
      "grad_norm": 6.46273183519952e-05,
      "learning_rate": 2.132219007821708e-06,
      "loss": 0.0,
      "step": 125070
    },
    {
      "epoch": 13.401907210971821,
      "grad_norm": 0.0002095795498462394,
      "learning_rate": 2.1307903853709066e-06,
      "loss": 0.0,
      "step": 125080
    },
    {
      "epoch": 13.402978677809921,
      "grad_norm": 6.842956645414233e-05,
      "learning_rate": 2.1293617629201042e-06,
      "loss": 0.0,
      "step": 125090
    },
    {
      "epoch": 13.404050144648023,
      "grad_norm": 6.570298864971846e-05,
      "learning_rate": 2.1279331404693028e-06,
      "loss": 0.0,
      "step": 125100
    },
    {
      "epoch": 13.405121611486125,
      "grad_norm": 7.152174657676369e-05,
      "learning_rate": 2.126504518018501e-06,
      "loss": 0.0,
      "step": 125110
    },
    {
      "epoch": 13.406193078324225,
      "grad_norm": 0.00012047372729284689,
      "learning_rate": 2.125075895567699e-06,
      "loss": 0.0,
      "step": 125120
    },
    {
      "epoch": 13.407264545162327,
      "grad_norm": 0.00012911023804917932,
      "learning_rate": 2.123647273116897e-06,
      "loss": 0.0,
      "step": 125130
    },
    {
      "epoch": 13.40833601200043,
      "grad_norm": 0.0001306226768065244,
      "learning_rate": 2.1222186506660956e-06,
      "loss": 0.0,
      "step": 125140
    },
    {
      "epoch": 13.40940747883853,
      "grad_norm": 6.212251901160926e-05,
      "learning_rate": 2.1207900282152937e-06,
      "loss": 0.0,
      "step": 125150
    },
    {
      "epoch": 13.410478945676632,
      "grad_norm": 0.00017403883975930512,
      "learning_rate": 2.1193614057644918e-06,
      "loss": 0.0033,
      "step": 125160
    },
    {
      "epoch": 13.411550412514732,
      "grad_norm": 6.392136856447905e-05,
      "learning_rate": 2.11793278331369e-06,
      "loss": 0.0,
      "step": 125170
    },
    {
      "epoch": 13.412621879352834,
      "grad_norm": 0.35393044352531433,
      "learning_rate": 2.116504160862888e-06,
      "loss": 0.0005,
      "step": 125180
    },
    {
      "epoch": 13.413693346190936,
      "grad_norm": 6.450765795307234e-05,
      "learning_rate": 2.1150755384120865e-06,
      "loss": 0.0,
      "step": 125190
    },
    {
      "epoch": 13.414764813029036,
      "grad_norm": 6.846173346275464e-05,
      "learning_rate": 2.1136469159612846e-06,
      "loss": 0.0001,
      "step": 125200
    },
    {
      "epoch": 13.415836279867138,
      "grad_norm": 0.00010140034282812849,
      "learning_rate": 2.1122182935104827e-06,
      "loss": 0.0,
      "step": 125210
    },
    {
      "epoch": 13.41690774670524,
      "grad_norm": 6.829681660747156e-05,
      "learning_rate": 2.1107896710596808e-06,
      "loss": 0.0,
      "step": 125220
    },
    {
      "epoch": 13.41797921354334,
      "grad_norm": 0.00011570122296689078,
      "learning_rate": 2.1093610486088793e-06,
      "loss": 0.0,
      "step": 125230
    },
    {
      "epoch": 13.419050680381442,
      "grad_norm": 0.0001887083926703781,
      "learning_rate": 2.1079324261580774e-06,
      "loss": 0.0,
      "step": 125240
    },
    {
      "epoch": 13.420122147219544,
      "grad_norm": 0.00011027490108972415,
      "learning_rate": 2.1065038037072755e-06,
      "loss": 0.0,
      "step": 125250
    },
    {
      "epoch": 13.421193614057644,
      "grad_norm": 6.472531822510064e-05,
      "learning_rate": 2.1050751812564736e-06,
      "loss": 0.0,
      "step": 125260
    },
    {
      "epoch": 13.422265080895746,
      "grad_norm": 0.0002100209821946919,
      "learning_rate": 2.1036465588056717e-06,
      "loss": 0.0,
      "step": 125270
    },
    {
      "epoch": 13.423336547733848,
      "grad_norm": 6.188677798490971e-05,
      "learning_rate": 2.10221793635487e-06,
      "loss": 0.0,
      "step": 125280
    },
    {
      "epoch": 13.424408014571949,
      "grad_norm": 0.00011412141611799598,
      "learning_rate": 2.100789313904068e-06,
      "loss": 0.0,
      "step": 125290
    },
    {
      "epoch": 13.42547948141005,
      "grad_norm": 6.0973907238803804e-05,
      "learning_rate": 2.0993606914532664e-06,
      "loss": 0.0,
      "step": 125300
    },
    {
      "epoch": 13.42655094824815,
      "grad_norm": 0.0001000029151327908,
      "learning_rate": 2.0979320690024645e-06,
      "loss": 0.0,
      "step": 125310
    },
    {
      "epoch": 13.427622415086253,
      "grad_norm": 0.0036740025971084833,
      "learning_rate": 2.0965034465516626e-06,
      "loss": 0.0,
      "step": 125320
    },
    {
      "epoch": 13.428693881924355,
      "grad_norm": 5.9784248151117936e-05,
      "learning_rate": 2.095074824100861e-06,
      "loss": 0.0,
      "step": 125330
    },
    {
      "epoch": 13.429765348762455,
      "grad_norm": 6.048324212315492e-05,
      "learning_rate": 2.093646201650059e-06,
      "loss": 0.0,
      "step": 125340
    },
    {
      "epoch": 13.430836815600557,
      "grad_norm": 6.787874008296058e-05,
      "learning_rate": 2.0922175791992573e-06,
      "loss": 0.0,
      "step": 125350
    },
    {
      "epoch": 13.431908282438659,
      "grad_norm": 7.003842620179057e-05,
      "learning_rate": 2.0907889567484554e-06,
      "loss": 0.0,
      "step": 125360
    },
    {
      "epoch": 13.43297974927676,
      "grad_norm": 0.00012181924830656499,
      "learning_rate": 2.089360334297654e-06,
      "loss": 0.0,
      "step": 125370
    },
    {
      "epoch": 13.434051216114861,
      "grad_norm": 6.53491952107288e-05,
      "learning_rate": 2.0879317118468516e-06,
      "loss": 0.0,
      "step": 125380
    },
    {
      "epoch": 13.435122682952963,
      "grad_norm": 5.832588431076147e-05,
      "learning_rate": 2.08650308939605e-06,
      "loss": 0.0,
      "step": 125390
    },
    {
      "epoch": 13.436194149791064,
      "grad_norm": 6.025807306286879e-05,
      "learning_rate": 2.085074466945248e-06,
      "loss": 0.0,
      "step": 125400
    },
    {
      "epoch": 13.437265616629166,
      "grad_norm": 5.733313810196705e-05,
      "learning_rate": 2.0836458444944463e-06,
      "loss": 0.0,
      "step": 125410
    },
    {
      "epoch": 13.438337083467268,
      "grad_norm": 0.0001273089146707207,
      "learning_rate": 2.0822172220436444e-06,
      "loss": 0.0,
      "step": 125420
    },
    {
      "epoch": 13.439408550305368,
      "grad_norm": 6.790425686631352e-05,
      "learning_rate": 2.080788599592843e-06,
      "loss": 0.0,
      "step": 125430
    },
    {
      "epoch": 13.44048001714347,
      "grad_norm": 6.220645445864648e-05,
      "learning_rate": 2.079359977142041e-06,
      "loss": 0.1547,
      "step": 125440
    },
    {
      "epoch": 13.44155148398157,
      "grad_norm": 0.00011959419498452917,
      "learning_rate": 2.077931354691239e-06,
      "loss": 0.0,
      "step": 125450
    },
    {
      "epoch": 13.442622950819672,
      "grad_norm": 6.455145194195211e-05,
      "learning_rate": 2.0765027322404376e-06,
      "loss": 0.0,
      "step": 125460
    },
    {
      "epoch": 13.443694417657774,
      "grad_norm": 0.00010457254393259063,
      "learning_rate": 2.0750741097896353e-06,
      "loss": 0.0,
      "step": 125470
    },
    {
      "epoch": 13.444765884495874,
      "grad_norm": 6.681674858555198e-05,
      "learning_rate": 2.073645487338834e-06,
      "loss": 0.0,
      "step": 125480
    },
    {
      "epoch": 13.445837351333976,
      "grad_norm": 6.608785770367831e-05,
      "learning_rate": 2.072216864888032e-06,
      "loss": 0.0,
      "step": 125490
    },
    {
      "epoch": 13.446908818172078,
      "grad_norm": 0.0001692010264378041,
      "learning_rate": 2.07078824243723e-06,
      "loss": 0.0,
      "step": 125500
    },
    {
      "epoch": 13.447980285010178,
      "grad_norm": 7.575008930871263e-05,
      "learning_rate": 2.069359619986428e-06,
      "loss": 0.0,
      "step": 125510
    },
    {
      "epoch": 13.44905175184828,
      "grad_norm": 7.014023140072823e-05,
      "learning_rate": 2.0679309975356266e-06,
      "loss": 0.0,
      "step": 125520
    },
    {
      "epoch": 13.450123218686382,
      "grad_norm": 6.334127829177305e-05,
      "learning_rate": 2.0665023750848247e-06,
      "loss": 0.0,
      "step": 125530
    },
    {
      "epoch": 13.451194685524483,
      "grad_norm": 6.792385102016851e-05,
      "learning_rate": 2.065073752634023e-06,
      "loss": 0.0,
      "step": 125540
    },
    {
      "epoch": 13.452266152362585,
      "grad_norm": 6.497590948129073e-05,
      "learning_rate": 2.063645130183221e-06,
      "loss": 0.0,
      "step": 125550
    },
    {
      "epoch": 13.453337619200685,
      "grad_norm": 0.00020677762222476304,
      "learning_rate": 2.062216507732419e-06,
      "loss": 0.0,
      "step": 125560
    },
    {
      "epoch": 13.454409086038787,
      "grad_norm": 6.75357659929432e-05,
      "learning_rate": 2.0607878852816175e-06,
      "loss": 0.0,
      "step": 125570
    },
    {
      "epoch": 13.455480552876889,
      "grad_norm": 6.535434658871964e-05,
      "learning_rate": 2.0593592628308156e-06,
      "loss": 0.0,
      "step": 125580
    },
    {
      "epoch": 13.456552019714989,
      "grad_norm": 0.00015533770783804357,
      "learning_rate": 2.0579306403800137e-06,
      "loss": 0.0,
      "step": 125590
    },
    {
      "epoch": 13.457623486553091,
      "grad_norm": 8.19288834463805e-05,
      "learning_rate": 2.056502017929212e-06,
      "loss": 0.0142,
      "step": 125600
    },
    {
      "epoch": 13.458694953391193,
      "grad_norm": 6.641689833486453e-05,
      "learning_rate": 2.0550733954784103e-06,
      "loss": 0.0,
      "step": 125610
    },
    {
      "epoch": 13.459766420229293,
      "grad_norm": 6.68379434500821e-05,
      "learning_rate": 2.0536447730276084e-06,
      "loss": 0.0004,
      "step": 125620
    },
    {
      "epoch": 13.460837887067395,
      "grad_norm": 6.042985842213966e-05,
      "learning_rate": 2.0522161505768065e-06,
      "loss": 0.0,
      "step": 125630
    },
    {
      "epoch": 13.461909353905497,
      "grad_norm": 7.702837319811806e-05,
      "learning_rate": 2.0507875281260046e-06,
      "loss": 0.0,
      "step": 125640
    },
    {
      "epoch": 13.462980820743597,
      "grad_norm": 7.439241016982123e-05,
      "learning_rate": 2.0493589056752027e-06,
      "loss": 0.4338,
      "step": 125650
    },
    {
      "epoch": 13.4640522875817,
      "grad_norm": 0.09479979425668716,
      "learning_rate": 2.0479302832244012e-06,
      "loss": 0.0,
      "step": 125660
    },
    {
      "epoch": 13.465123754419801,
      "grad_norm": 7.631353219039738e-05,
      "learning_rate": 2.0465016607735993e-06,
      "loss": 0.0,
      "step": 125670
    },
    {
      "epoch": 13.466195221257902,
      "grad_norm": 6.887827476020902e-05,
      "learning_rate": 2.0450730383227974e-06,
      "loss": 0.0,
      "step": 125680
    },
    {
      "epoch": 13.467266688096004,
      "grad_norm": 6.973103882046416e-05,
      "learning_rate": 2.0436444158719955e-06,
      "loss": 0.0,
      "step": 125690
    },
    {
      "epoch": 13.468338154934106,
      "grad_norm": 0.005877015646547079,
      "learning_rate": 2.042215793421194e-06,
      "loss": 0.0,
      "step": 125700
    },
    {
      "epoch": 13.469409621772206,
      "grad_norm": 0.006531398743391037,
      "learning_rate": 2.040787170970392e-06,
      "loss": 0.0,
      "step": 125710
    },
    {
      "epoch": 13.470481088610308,
      "grad_norm": 7.521982479374856e-05,
      "learning_rate": 2.0393585485195902e-06,
      "loss": 0.0234,
      "step": 125720
    },
    {
      "epoch": 13.471552555448408,
      "grad_norm": 7.929097773740068e-05,
      "learning_rate": 2.0379299260687883e-06,
      "loss": 0.0,
      "step": 125730
    },
    {
      "epoch": 13.47262402228651,
      "grad_norm": 7.615814683958888e-05,
      "learning_rate": 2.0365013036179864e-06,
      "loss": 0.0011,
      "step": 125740
    },
    {
      "epoch": 13.473695489124612,
      "grad_norm": 0.0003162592474836856,
      "learning_rate": 2.035072681167185e-06,
      "loss": 0.0,
      "step": 125750
    },
    {
      "epoch": 13.474766955962712,
      "grad_norm": 6.950922397663817e-05,
      "learning_rate": 2.0336440587163826e-06,
      "loss": 0.0,
      "step": 125760
    },
    {
      "epoch": 13.475838422800814,
      "grad_norm": 7.327775529120117e-05,
      "learning_rate": 2.032215436265581e-06,
      "loss": 0.0003,
      "step": 125770
    },
    {
      "epoch": 13.476909889638916,
      "grad_norm": 6.916165875736624e-05,
      "learning_rate": 2.0307868138147792e-06,
      "loss": 0.0,
      "step": 125780
    },
    {
      "epoch": 13.477981356477017,
      "grad_norm": 0.00015054405957926065,
      "learning_rate": 2.0293581913639773e-06,
      "loss": 0.0,
      "step": 125790
    },
    {
      "epoch": 13.479052823315119,
      "grad_norm": 0.00013881007907912135,
      "learning_rate": 2.0279295689131754e-06,
      "loss": 0.0,
      "step": 125800
    },
    {
      "epoch": 13.48012429015322,
      "grad_norm": 8.22516594780609e-05,
      "learning_rate": 2.026500946462374e-06,
      "loss": 0.0,
      "step": 125810
    },
    {
      "epoch": 13.48119575699132,
      "grad_norm": 8.31201541586779e-05,
      "learning_rate": 2.025072324011572e-06,
      "loss": 0.0,
      "step": 125820
    },
    {
      "epoch": 13.482267223829423,
      "grad_norm": 0.12388644367456436,
      "learning_rate": 2.02364370156077e-06,
      "loss": 0.0001,
      "step": 125830
    },
    {
      "epoch": 13.483338690667523,
      "grad_norm": 7.922679651528597e-05,
      "learning_rate": 2.0222150791099686e-06,
      "loss": 0.0,
      "step": 125840
    },
    {
      "epoch": 13.484410157505625,
      "grad_norm": 0.0005765292444266379,
      "learning_rate": 2.0207864566591663e-06,
      "loss": 0.0003,
      "step": 125850
    },
    {
      "epoch": 13.485481624343727,
      "grad_norm": 7.169240416260436e-05,
      "learning_rate": 2.019357834208365e-06,
      "loss": 0.0,
      "step": 125860
    },
    {
      "epoch": 13.486553091181827,
      "grad_norm": 0.0001438834733562544,
      "learning_rate": 2.017929211757563e-06,
      "loss": 0.0,
      "step": 125870
    },
    {
      "epoch": 13.48762455801993,
      "grad_norm": 0.00014196748088579625,
      "learning_rate": 2.016500589306761e-06,
      "loss": 0.0,
      "step": 125880
    },
    {
      "epoch": 13.488696024858031,
      "grad_norm": 0.00013867011875845492,
      "learning_rate": 2.015071966855959e-06,
      "loss": 0.4313,
      "step": 125890
    },
    {
      "epoch": 13.489767491696131,
      "grad_norm": 9.062146273208782e-05,
      "learning_rate": 2.0136433444051576e-06,
      "loss": 0.0,
      "step": 125900
    },
    {
      "epoch": 13.490838958534233,
      "grad_norm": 0.00013032033166382462,
      "learning_rate": 2.0122147219543557e-06,
      "loss": 0.0,
      "step": 125910
    },
    {
      "epoch": 13.491910425372335,
      "grad_norm": 9.058350406121463e-05,
      "learning_rate": 2.010786099503554e-06,
      "loss": 0.0,
      "step": 125920
    },
    {
      "epoch": 13.492981892210436,
      "grad_norm": 8.956008241511881e-05,
      "learning_rate": 2.009357477052752e-06,
      "loss": 0.0,
      "step": 125930
    },
    {
      "epoch": 13.494053359048538,
      "grad_norm": 0.00015363846614491194,
      "learning_rate": 2.00792885460195e-06,
      "loss": 0.0878,
      "step": 125940
    },
    {
      "epoch": 13.49512482588664,
      "grad_norm": 8.086059096967801e-05,
      "learning_rate": 2.0065002321511486e-06,
      "loss": 0.0,
      "step": 125950
    },
    {
      "epoch": 13.49619629272474,
      "grad_norm": 0.00010320551518816501,
      "learning_rate": 2.0050716097003466e-06,
      "loss": 0.0001,
      "step": 125960
    },
    {
      "epoch": 13.497267759562842,
      "grad_norm": 0.01543800812214613,
      "learning_rate": 2.0036429872495447e-06,
      "loss": 0.0,
      "step": 125970
    },
    {
      "epoch": 13.498339226400942,
      "grad_norm": 0.00010539561480982229,
      "learning_rate": 2.002214364798743e-06,
      "loss": 0.0001,
      "step": 125980
    },
    {
      "epoch": 13.499410693239044,
      "grad_norm": 8.128535409923643e-05,
      "learning_rate": 2.0007857423479414e-06,
      "loss": 0.0,
      "step": 125990
    },
    {
      "epoch": 13.500482160077146,
      "grad_norm": 0.0001468679984100163,
      "learning_rate": 1.9993571198971395e-06,
      "loss": 0.0001,
      "step": 126000
    },
    {
      "epoch": 13.501553626915246,
      "grad_norm": 0.00012189844710519537,
      "learning_rate": 1.9979284974463376e-06,
      "loss": 0.0,
      "step": 126010
    },
    {
      "epoch": 13.502625093753348,
      "grad_norm": 8.079472900135443e-05,
      "learning_rate": 1.9964998749955356e-06,
      "loss": 0.0,
      "step": 126020
    },
    {
      "epoch": 13.50369656059145,
      "grad_norm": 0.0001527258282294497,
      "learning_rate": 1.9950712525447337e-06,
      "loss": 0.0,
      "step": 126030
    },
    {
      "epoch": 13.50476802742955,
      "grad_norm": 0.00011366781836841255,
      "learning_rate": 1.9936426300939323e-06,
      "loss": 0.0002,
      "step": 126040
    },
    {
      "epoch": 13.505839494267653,
      "grad_norm": 8.113655349006876e-05,
      "learning_rate": 1.9922140076431304e-06,
      "loss": 0.0006,
      "step": 126050
    },
    {
      "epoch": 13.506910961105755,
      "grad_norm": 0.00023481833341065794,
      "learning_rate": 1.9907853851923285e-06,
      "loss": 0.2163,
      "step": 126060
    },
    {
      "epoch": 13.507982427943855,
      "grad_norm": 8.415515185333788e-05,
      "learning_rate": 1.9893567627415266e-06,
      "loss": 0.0006,
      "step": 126070
    },
    {
      "epoch": 13.509053894781957,
      "grad_norm": 7.49144601286389e-05,
      "learning_rate": 1.987928140290725e-06,
      "loss": 0.0,
      "step": 126080
    },
    {
      "epoch": 13.510125361620059,
      "grad_norm": 8.364727545995265e-05,
      "learning_rate": 1.9864995178399227e-06,
      "loss": 0.0,
      "step": 126090
    },
    {
      "epoch": 13.511196828458159,
      "grad_norm": 8.168486965587363e-05,
      "learning_rate": 1.9850708953891213e-06,
      "loss": 0.0,
      "step": 126100
    },
    {
      "epoch": 13.512268295296261,
      "grad_norm": 0.0001336646091658622,
      "learning_rate": 1.9836422729383194e-06,
      "loss": 0.0,
      "step": 126110
    },
    {
      "epoch": 13.513339762134361,
      "grad_norm": 8.621357847005129e-05,
      "learning_rate": 1.9822136504875175e-06,
      "loss": 0.0,
      "step": 126120
    },
    {
      "epoch": 13.514411228972463,
      "grad_norm": 0.0003418803680688143,
      "learning_rate": 1.980785028036716e-06,
      "loss": 0.0,
      "step": 126130
    },
    {
      "epoch": 13.515482695810565,
      "grad_norm": 7.874805305618793e-05,
      "learning_rate": 1.979356405585914e-06,
      "loss": 0.0,
      "step": 126140
    },
    {
      "epoch": 13.516554162648665,
      "grad_norm": 0.00017320031474810094,
      "learning_rate": 1.977927783135112e-06,
      "loss": 0.0,
      "step": 126150
    },
    {
      "epoch": 13.517625629486767,
      "grad_norm": 0.0003632234875112772,
      "learning_rate": 1.9764991606843103e-06,
      "loss": 0.0,
      "step": 126160
    },
    {
      "epoch": 13.51869709632487,
      "grad_norm": 0.00024760820087976754,
      "learning_rate": 1.9750705382335088e-06,
      "loss": 0.0003,
      "step": 126170
    },
    {
      "epoch": 13.51976856316297,
      "grad_norm": 0.00012282971874810755,
      "learning_rate": 1.9736419157827065e-06,
      "loss": 0.0,
      "step": 126180
    },
    {
      "epoch": 13.520840030001072,
      "grad_norm": 0.00011757947504520416,
      "learning_rate": 1.972213293331905e-06,
      "loss": 0.152,
      "step": 126190
    },
    {
      "epoch": 13.521911496839174,
      "grad_norm": 0.00014208597713150084,
      "learning_rate": 1.970784670881103e-06,
      "loss": 0.0008,
      "step": 126200
    },
    {
      "epoch": 13.522982963677274,
      "grad_norm": 0.0001228811452165246,
      "learning_rate": 1.969356048430301e-06,
      "loss": 0.0,
      "step": 126210
    },
    {
      "epoch": 13.524054430515376,
      "grad_norm": 0.00015745582641102374,
      "learning_rate": 1.9679274259794997e-06,
      "loss": 0.0,
      "step": 126220
    },
    {
      "epoch": 13.525125897353476,
      "grad_norm": 0.00010274313535774127,
      "learning_rate": 1.9664988035286974e-06,
      "loss": 0.0,
      "step": 126230
    },
    {
      "epoch": 13.526197364191578,
      "grad_norm": 0.0002717060851864517,
      "learning_rate": 1.965070181077896e-06,
      "loss": 0.0,
      "step": 126240
    },
    {
      "epoch": 13.52726883102968,
      "grad_norm": 0.00010300088615622371,
      "learning_rate": 1.963641558627094e-06,
      "loss": 0.0655,
      "step": 126250
    },
    {
      "epoch": 13.52834029786778,
      "grad_norm": 0.00011263316264376044,
      "learning_rate": 1.962212936176292e-06,
      "loss": 0.0,
      "step": 126260
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 8.043288107728586e-05,
      "learning_rate": 1.96078431372549e-06,
      "loss": 0.0,
      "step": 126270
    },
    {
      "epoch": 13.530483231543984,
      "grad_norm": 0.0001254895905731246,
      "learning_rate": 1.9593556912746887e-06,
      "loss": 0.0,
      "step": 126280
    },
    {
      "epoch": 13.531554698382084,
      "grad_norm": 0.0001175804718513973,
      "learning_rate": 1.9579270688238868e-06,
      "loss": 0.0,
      "step": 126290
    },
    {
      "epoch": 13.532626165220186,
      "grad_norm": 8.250641985796392e-05,
      "learning_rate": 1.956498446373085e-06,
      "loss": 0.1948,
      "step": 126300
    },
    {
      "epoch": 13.533697632058288,
      "grad_norm": 8.499191608279943e-05,
      "learning_rate": 1.955069823922283e-06,
      "loss": 0.0,
      "step": 126310
    },
    {
      "epoch": 13.534769098896389,
      "grad_norm": 0.00015705903933849186,
      "learning_rate": 1.953641201471481e-06,
      "loss": 0.0,
      "step": 126320
    },
    {
      "epoch": 13.53584056573449,
      "grad_norm": 0.000583087676204741,
      "learning_rate": 1.9522125790206796e-06,
      "loss": 0.0,
      "step": 126330
    },
    {
      "epoch": 13.536912032572593,
      "grad_norm": 9.386999590788037e-05,
      "learning_rate": 1.9507839565698777e-06,
      "loss": 0.0002,
      "step": 126340
    },
    {
      "epoch": 13.537983499410693,
      "grad_norm": 9.537672303849831e-05,
      "learning_rate": 1.9493553341190758e-06,
      "loss": 0.0,
      "step": 126350
    },
    {
      "epoch": 13.539054966248795,
      "grad_norm": 0.000152708642417565,
      "learning_rate": 1.947926711668274e-06,
      "loss": 0.0,
      "step": 126360
    },
    {
      "epoch": 13.540126433086897,
      "grad_norm": 8.141914440784603e-05,
      "learning_rate": 1.9464980892174724e-06,
      "loss": 0.3127,
      "step": 126370
    },
    {
      "epoch": 13.541197899924997,
      "grad_norm": 0.00010525255493121222,
      "learning_rate": 1.9450694667666705e-06,
      "loss": 0.0,
      "step": 126380
    },
    {
      "epoch": 13.5422693667631,
      "grad_norm": 0.00046495621791109443,
      "learning_rate": 1.9436408443158686e-06,
      "loss": 0.0,
      "step": 126390
    },
    {
      "epoch": 13.5433408336012,
      "grad_norm": 8.367467671632767e-05,
      "learning_rate": 1.9422122218650667e-06,
      "loss": 0.0,
      "step": 126400
    },
    {
      "epoch": 13.544412300439301,
      "grad_norm": 9.016582771437243e-05,
      "learning_rate": 1.9407835994142648e-06,
      "loss": 0.0293,
      "step": 126410
    },
    {
      "epoch": 13.545483767277403,
      "grad_norm": 0.00015738524962216616,
      "learning_rate": 1.9393549769634633e-06,
      "loss": 0.0,
      "step": 126420
    },
    {
      "epoch": 13.546555234115504,
      "grad_norm": 9.967970254365355e-05,
      "learning_rate": 1.9379263545126614e-06,
      "loss": 0.0,
      "step": 126430
    },
    {
      "epoch": 13.547626700953606,
      "grad_norm": 8.13860388007015e-05,
      "learning_rate": 1.9364977320618595e-06,
      "loss": 0.0,
      "step": 126440
    },
    {
      "epoch": 13.548698167791708,
      "grad_norm": 0.00012010213686153293,
      "learning_rate": 1.9350691096110576e-06,
      "loss": 0.1166,
      "step": 126450
    },
    {
      "epoch": 13.549769634629808,
      "grad_norm": 9.464300819672644e-05,
      "learning_rate": 1.933640487160256e-06,
      "loss": 0.0,
      "step": 126460
    },
    {
      "epoch": 13.55084110146791,
      "grad_norm": 8.405086555285379e-05,
      "learning_rate": 1.9322118647094538e-06,
      "loss": 0.2121,
      "step": 126470
    },
    {
      "epoch": 13.551912568306012,
      "grad_norm": 8.486756269121543e-05,
      "learning_rate": 1.9307832422586523e-06,
      "loss": 0.0,
      "step": 126480
    },
    {
      "epoch": 13.552984035144112,
      "grad_norm": 0.00010193443449679762,
      "learning_rate": 1.9293546198078504e-06,
      "loss": 0.0002,
      "step": 126490
    },
    {
      "epoch": 13.554055501982214,
      "grad_norm": 8.145289757521823e-05,
      "learning_rate": 1.9279259973570485e-06,
      "loss": 0.0001,
      "step": 126500
    },
    {
      "epoch": 13.555126968820314,
      "grad_norm": 8.146384789142758e-05,
      "learning_rate": 1.926497374906247e-06,
      "loss": 0.0,
      "step": 126510
    },
    {
      "epoch": 13.556198435658416,
      "grad_norm": 0.00013339522411115468,
      "learning_rate": 1.925068752455445e-06,
      "loss": 0.0006,
      "step": 126520
    },
    {
      "epoch": 13.557269902496518,
      "grad_norm": 0.0001373418199364096,
      "learning_rate": 1.923640130004643e-06,
      "loss": 0.0,
      "step": 126530
    },
    {
      "epoch": 13.558341369334618,
      "grad_norm": 8.515774243278429e-05,
      "learning_rate": 1.9222115075538413e-06,
      "loss": 0.0,
      "step": 126540
    },
    {
      "epoch": 13.55941283617272,
      "grad_norm": 8.410090958932415e-05,
      "learning_rate": 1.92078288510304e-06,
      "loss": 0.0,
      "step": 126550
    },
    {
      "epoch": 13.560484303010822,
      "grad_norm": 7.678983092773706e-05,
      "learning_rate": 1.9193542626522375e-06,
      "loss": 0.0,
      "step": 126560
    },
    {
      "epoch": 13.561555769848923,
      "grad_norm": 0.0001507528795627877,
      "learning_rate": 1.917925640201436e-06,
      "loss": 0.0,
      "step": 126570
    },
    {
      "epoch": 13.562627236687025,
      "grad_norm": 0.00025747448671609163,
      "learning_rate": 1.916497017750634e-06,
      "loss": 0.0,
      "step": 126580
    },
    {
      "epoch": 13.563698703525127,
      "grad_norm": 0.00022579195501748472,
      "learning_rate": 1.915068395299832e-06,
      "loss": 0.0,
      "step": 126590
    },
    {
      "epoch": 13.564770170363227,
      "grad_norm": 8.490819163853303e-05,
      "learning_rate": 1.9136397728490307e-06,
      "loss": 0.0004,
      "step": 126600
    },
    {
      "epoch": 13.565841637201329,
      "grad_norm": 0.0002427539584459737,
      "learning_rate": 1.912211150398229e-06,
      "loss": 0.0,
      "step": 126610
    },
    {
      "epoch": 13.566913104039429,
      "grad_norm": 1.8585118055343628,
      "learning_rate": 1.910782527947427e-06,
      "loss": 0.1851,
      "step": 126620
    },
    {
      "epoch": 13.567984570877531,
      "grad_norm": 0.0003619459457695484,
      "learning_rate": 1.909353905496625e-06,
      "loss": 0.0,
      "step": 126630
    },
    {
      "epoch": 13.569056037715633,
      "grad_norm": 0.00047914934111759067,
      "learning_rate": 1.907925283045823e-06,
      "loss": 0.0,
      "step": 126640
    },
    {
      "epoch": 13.570127504553733,
      "grad_norm": 0.0001690360513748601,
      "learning_rate": 1.9064966605950214e-06,
      "loss": 0.0,
      "step": 126650
    },
    {
      "epoch": 13.571198971391835,
      "grad_norm": 8.330414857482538e-05,
      "learning_rate": 1.9050680381442197e-06,
      "loss": 0.0,
      "step": 126660
    },
    {
      "epoch": 13.572270438229937,
      "grad_norm": 8.694266580278054e-05,
      "learning_rate": 1.9036394156934176e-06,
      "loss": 0.0,
      "step": 126670
    },
    {
      "epoch": 13.573341905068038,
      "grad_norm": 0.00010243077122140676,
      "learning_rate": 1.902210793242616e-06,
      "loss": 0.0,
      "step": 126680
    },
    {
      "epoch": 13.57441337190614,
      "grad_norm": 0.00015877874102443457,
      "learning_rate": 1.9007821707918142e-06,
      "loss": 0.0,
      "step": 126690
    },
    {
      "epoch": 13.575484838744242,
      "grad_norm": 0.00024345707788597792,
      "learning_rate": 1.8993535483410121e-06,
      "loss": 0.0,
      "step": 126700
    },
    {
      "epoch": 13.576556305582342,
      "grad_norm": 8.92866519279778e-05,
      "learning_rate": 1.8979249258902104e-06,
      "loss": 0.0,
      "step": 126710
    },
    {
      "epoch": 13.577627772420444,
      "grad_norm": 0.00012037039414281026,
      "learning_rate": 1.8964963034394087e-06,
      "loss": 0.0,
      "step": 126720
    },
    {
      "epoch": 13.578699239258546,
      "grad_norm": 9.98177783912979e-05,
      "learning_rate": 1.8950676809886068e-06,
      "loss": 0.0,
      "step": 126730
    },
    {
      "epoch": 13.579770706096646,
      "grad_norm": 0.00011769629782065749,
      "learning_rate": 1.8936390585378051e-06,
      "loss": 0.0001,
      "step": 126740
    },
    {
      "epoch": 13.580842172934748,
      "grad_norm": 0.00017434229084756225,
      "learning_rate": 1.8922104360870034e-06,
      "loss": 0.0,
      "step": 126750
    },
    {
      "epoch": 13.58191363977285,
      "grad_norm": 0.00010390418174210936,
      "learning_rate": 1.8907818136362013e-06,
      "loss": 0.0,
      "step": 126760
    },
    {
      "epoch": 13.58298510661095,
      "grad_norm": 0.0001932042941916734,
      "learning_rate": 1.8893531911853996e-06,
      "loss": 0.0,
      "step": 126770
    },
    {
      "epoch": 13.584056573449052,
      "grad_norm": 8.42644294607453e-05,
      "learning_rate": 1.887924568734598e-06,
      "loss": 0.0,
      "step": 126780
    },
    {
      "epoch": 13.585128040287152,
      "grad_norm": 0.0002138535783160478,
      "learning_rate": 1.8864959462837958e-06,
      "loss": 0.0,
      "step": 126790
    },
    {
      "epoch": 13.586199507125254,
      "grad_norm": 8.334450831171125e-05,
      "learning_rate": 1.8850673238329941e-06,
      "loss": 0.0,
      "step": 126800
    },
    {
      "epoch": 13.587270973963356,
      "grad_norm": 9.32585826376453e-05,
      "learning_rate": 1.8836387013821924e-06,
      "loss": 0.0,
      "step": 126810
    },
    {
      "epoch": 13.588342440801457,
      "grad_norm": 0.00020121379930060357,
      "learning_rate": 1.8822100789313905e-06,
      "loss": 0.0003,
      "step": 126820
    },
    {
      "epoch": 13.589413907639559,
      "grad_norm": 0.00014056877989787608,
      "learning_rate": 1.8807814564805888e-06,
      "loss": 0.0,
      "step": 126830
    },
    {
      "epoch": 13.59048537447766,
      "grad_norm": 7.956734043546021e-05,
      "learning_rate": 1.879352834029787e-06,
      "loss": 0.0,
      "step": 126840
    },
    {
      "epoch": 13.59155684131576,
      "grad_norm": 9.158004104392603e-05,
      "learning_rate": 1.877924211578985e-06,
      "loss": 0.0,
      "step": 126850
    },
    {
      "epoch": 13.592628308153863,
      "grad_norm": 8.485659054713324e-05,
      "learning_rate": 1.8764955891281833e-06,
      "loss": 0.0,
      "step": 126860
    },
    {
      "epoch": 13.593699774991965,
      "grad_norm": 0.000121704040793702,
      "learning_rate": 1.8750669666773816e-06,
      "loss": 0.0,
      "step": 126870
    },
    {
      "epoch": 13.594771241830065,
      "grad_norm": 0.0001773777330527082,
      "learning_rate": 1.8736383442265795e-06,
      "loss": 0.0,
      "step": 126880
    },
    {
      "epoch": 13.595842708668167,
      "grad_norm": 8.85406116140075e-05,
      "learning_rate": 1.8722097217757778e-06,
      "loss": 0.1467,
      "step": 126890
    },
    {
      "epoch": 13.596914175506267,
      "grad_norm": 9.971469262382016e-05,
      "learning_rate": 1.8707810993249761e-06,
      "loss": 0.0,
      "step": 126900
    },
    {
      "epoch": 13.59798564234437,
      "grad_norm": 0.0005719846813008189,
      "learning_rate": 1.8693524768741742e-06,
      "loss": 0.0073,
      "step": 126910
    },
    {
      "epoch": 13.599057109182471,
      "grad_norm": 0.0001969134755199775,
      "learning_rate": 1.8679238544233723e-06,
      "loss": 0.0,
      "step": 126920
    },
    {
      "epoch": 13.600128576020571,
      "grad_norm": 0.0001318448776146397,
      "learning_rate": 1.8664952319725706e-06,
      "loss": 0.0015,
      "step": 126930
    },
    {
      "epoch": 13.601200042858673,
      "grad_norm": 8.084097498795018e-05,
      "learning_rate": 1.8650666095217687e-06,
      "loss": 0.0,
      "step": 126940
    },
    {
      "epoch": 13.602271509696775,
      "grad_norm": 9.590583067620173e-05,
      "learning_rate": 1.863637987070967e-06,
      "loss": 0.0,
      "step": 126950
    },
    {
      "epoch": 13.603342976534876,
      "grad_norm": 0.0001001649652607739,
      "learning_rate": 1.8622093646201654e-06,
      "loss": 0.0,
      "step": 126960
    },
    {
      "epoch": 13.604414443372978,
      "grad_norm": 0.00020332320127636194,
      "learning_rate": 1.8607807421693632e-06,
      "loss": 0.0,
      "step": 126970
    },
    {
      "epoch": 13.60548591021108,
      "grad_norm": 7.903687219368294e-05,
      "learning_rate": 1.8593521197185615e-06,
      "loss": 0.0,
      "step": 126980
    },
    {
      "epoch": 13.60655737704918,
      "grad_norm": 0.0007817013538442552,
      "learning_rate": 1.8579234972677599e-06,
      "loss": 0.0,
      "step": 126990
    },
    {
      "epoch": 13.607628843887282,
      "grad_norm": 7.865185762057081e-05,
      "learning_rate": 1.8564948748169577e-06,
      "loss": 0.0,
      "step": 127000
    },
    {
      "epoch": 13.608700310725382,
      "grad_norm": 0.000151658765389584,
      "learning_rate": 1.855066252366156e-06,
      "loss": 0.0015,
      "step": 127010
    },
    {
      "epoch": 13.609771777563484,
      "grad_norm": 0.00019595911726355553,
      "learning_rate": 1.8536376299153544e-06,
      "loss": 0.0,
      "step": 127020
    },
    {
      "epoch": 13.610843244401586,
      "grad_norm": 0.00015922810416668653,
      "learning_rate": 1.8522090074645525e-06,
      "loss": 0.0,
      "step": 127030
    },
    {
      "epoch": 13.611914711239686,
      "grad_norm": 0.0002954072260763496,
      "learning_rate": 1.8507803850137508e-06,
      "loss": 0.0002,
      "step": 127040
    },
    {
      "epoch": 13.612986178077788,
      "grad_norm": 7.38507296773605e-05,
      "learning_rate": 1.8493517625629489e-06,
      "loss": 0.0,
      "step": 127050
    },
    {
      "epoch": 13.61405764491589,
      "grad_norm": 9.368670725962147e-05,
      "learning_rate": 1.847923140112147e-06,
      "loss": 0.0,
      "step": 127060
    },
    {
      "epoch": 13.61512911175399,
      "grad_norm": 8.756915485719219e-05,
      "learning_rate": 1.8464945176613453e-06,
      "loss": 0.0,
      "step": 127070
    },
    {
      "epoch": 13.616200578592093,
      "grad_norm": 0.00016932366997934878,
      "learning_rate": 1.8450658952105436e-06,
      "loss": 0.0,
      "step": 127080
    },
    {
      "epoch": 13.617272045430195,
      "grad_norm": 0.00011909924069186673,
      "learning_rate": 1.8436372727597415e-06,
      "loss": 0.0,
      "step": 127090
    },
    {
      "epoch": 13.618343512268295,
      "grad_norm": 7.356012793025002e-05,
      "learning_rate": 1.8422086503089398e-06,
      "loss": 0.0,
      "step": 127100
    },
    {
      "epoch": 13.619414979106397,
      "grad_norm": 9.875278919935226e-05,
      "learning_rate": 1.8407800278581379e-06,
      "loss": 0.0,
      "step": 127110
    },
    {
      "epoch": 13.620486445944499,
      "grad_norm": 0.00016299633716698736,
      "learning_rate": 1.8393514054073362e-06,
      "loss": 0.0,
      "step": 127120
    },
    {
      "epoch": 13.621557912782599,
      "grad_norm": 0.0001578834926476702,
      "learning_rate": 1.8379227829565345e-06,
      "loss": 0.0,
      "step": 127130
    },
    {
      "epoch": 13.622629379620701,
      "grad_norm": 9.11813840502873e-05,
      "learning_rate": 1.8364941605057324e-06,
      "loss": 0.2155,
      "step": 127140
    },
    {
      "epoch": 13.623700846458803,
      "grad_norm": 8.657181024318561e-05,
      "learning_rate": 1.8350655380549307e-06,
      "loss": 0.0012,
      "step": 127150
    },
    {
      "epoch": 13.624772313296903,
      "grad_norm": 9.598495671525598e-05,
      "learning_rate": 1.833636915604129e-06,
      "loss": 0.0,
      "step": 127160
    },
    {
      "epoch": 13.625843780135005,
      "grad_norm": 0.0001666087773628533,
      "learning_rate": 1.8322082931533269e-06,
      "loss": 0.0,
      "step": 127170
    },
    {
      "epoch": 13.626915246973105,
      "grad_norm": 0.00014582213771063834,
      "learning_rate": 1.8307796707025252e-06,
      "loss": 0.0,
      "step": 127180
    },
    {
      "epoch": 13.627986713811207,
      "grad_norm": 0.00013830966781824827,
      "learning_rate": 1.8293510482517235e-06,
      "loss": 0.0,
      "step": 127190
    },
    {
      "epoch": 13.62905818064931,
      "grad_norm": 8.297144813695922e-05,
      "learning_rate": 1.8279224258009216e-06,
      "loss": 0.0005,
      "step": 127200
    },
    {
      "epoch": 13.63012964748741,
      "grad_norm": 9.217927436111495e-05,
      "learning_rate": 1.8264938033501199e-06,
      "loss": 0.0,
      "step": 127210
    },
    {
      "epoch": 13.631201114325512,
      "grad_norm": 0.0013266380410641432,
      "learning_rate": 1.825065180899318e-06,
      "loss": 0.0,
      "step": 127220
    },
    {
      "epoch": 13.632272581163614,
      "grad_norm": 9.35518037294969e-05,
      "learning_rate": 1.823636558448516e-06,
      "loss": 0.0005,
      "step": 127230
    },
    {
      "epoch": 13.633344048001714,
      "grad_norm": 8.285983494715765e-05,
      "learning_rate": 1.8222079359977144e-06,
      "loss": 0.0003,
      "step": 127240
    },
    {
      "epoch": 13.634415514839816,
      "grad_norm": 0.00018534238915890455,
      "learning_rate": 1.8207793135469127e-06,
      "loss": 0.0,
      "step": 127250
    },
    {
      "epoch": 13.635486981677918,
      "grad_norm": 8.281214104499668e-05,
      "learning_rate": 1.8193506910961106e-06,
      "loss": 0.0,
      "step": 127260
    },
    {
      "epoch": 13.636558448516018,
      "grad_norm": 0.00010483903315616772,
      "learning_rate": 1.8179220686453089e-06,
      "loss": 0.0,
      "step": 127270
    },
    {
      "epoch": 13.63762991535412,
      "grad_norm": 0.28124332427978516,
      "learning_rate": 1.8164934461945072e-06,
      "loss": 0.0005,
      "step": 127280
    },
    {
      "epoch": 13.63870138219222,
      "grad_norm": 8.132192306220531e-05,
      "learning_rate": 1.8150648237437053e-06,
      "loss": 0.0,
      "step": 127290
    },
    {
      "epoch": 13.639772849030322,
      "grad_norm": 8.51625154609792e-05,
      "learning_rate": 1.8136362012929034e-06,
      "loss": 0.0002,
      "step": 127300
    },
    {
      "epoch": 13.640844315868424,
      "grad_norm": 7.875062874518335e-05,
      "learning_rate": 1.8122075788421017e-06,
      "loss": 0.0,
      "step": 127310
    },
    {
      "epoch": 13.641915782706524,
      "grad_norm": 8.688489469932392e-05,
      "learning_rate": 1.8107789563912998e-06,
      "loss": 0.0,
      "step": 127320
    },
    {
      "epoch": 13.642987249544626,
      "grad_norm": 8.337180042872205e-05,
      "learning_rate": 1.809350333940498e-06,
      "loss": 0.0,
      "step": 127330
    },
    {
      "epoch": 13.644058716382728,
      "grad_norm": 0.00012135360884713009,
      "learning_rate": 1.8079217114896964e-06,
      "loss": 0.0,
      "step": 127340
    },
    {
      "epoch": 13.645130183220829,
      "grad_norm": 0.00011619480210356414,
      "learning_rate": 1.8064930890388943e-06,
      "loss": 0.0,
      "step": 127350
    },
    {
      "epoch": 13.64620165005893,
      "grad_norm": 8.662901382194832e-05,
      "learning_rate": 1.8050644665880926e-06,
      "loss": 0.0002,
      "step": 127360
    },
    {
      "epoch": 13.647273116897033,
      "grad_norm": 0.04806632921099663,
      "learning_rate": 1.8036358441372909e-06,
      "loss": 0.0,
      "step": 127370
    },
    {
      "epoch": 13.648344583735133,
      "grad_norm": 0.00012204406084492803,
      "learning_rate": 1.8022072216864888e-06,
      "loss": 0.0,
      "step": 127380
    },
    {
      "epoch": 13.649416050573235,
      "grad_norm": 8.605326729593799e-05,
      "learning_rate": 1.800778599235687e-06,
      "loss": 0.0,
      "step": 127390
    },
    {
      "epoch": 13.650487517411337,
      "grad_norm": 0.00014504390128422529,
      "learning_rate": 1.7993499767848854e-06,
      "loss": 0.0,
      "step": 127400
    },
    {
      "epoch": 13.651558984249437,
      "grad_norm": 7.735251710982993e-05,
      "learning_rate": 1.7979213543340835e-06,
      "loss": 0.0,
      "step": 127410
    },
    {
      "epoch": 13.65263045108754,
      "grad_norm": 0.0001428574905730784,
      "learning_rate": 1.7964927318832818e-06,
      "loss": 0.001,
      "step": 127420
    },
    {
      "epoch": 13.653701917925641,
      "grad_norm": 0.0002466283622197807,
      "learning_rate": 1.7950641094324799e-06,
      "loss": 0.0,
      "step": 127430
    },
    {
      "epoch": 13.654773384763741,
      "grad_norm": 8.16233005025424e-05,
      "learning_rate": 1.793635486981678e-06,
      "loss": 0.0,
      "step": 127440
    },
    {
      "epoch": 13.655844851601843,
      "grad_norm": 0.00011559478298295289,
      "learning_rate": 1.7922068645308763e-06,
      "loss": 0.0,
      "step": 127450
    },
    {
      "epoch": 13.656916318439944,
      "grad_norm": 0.00013271468924358487,
      "learning_rate": 1.7907782420800746e-06,
      "loss": 0.0,
      "step": 127460
    },
    {
      "epoch": 13.657987785278046,
      "grad_norm": 0.00018044306489173323,
      "learning_rate": 1.7893496196292725e-06,
      "loss": 0.0,
      "step": 127470
    },
    {
      "epoch": 13.659059252116148,
      "grad_norm": 8.085464651230723e-05,
      "learning_rate": 1.7879209971784708e-06,
      "loss": 0.3115,
      "step": 127480
    },
    {
      "epoch": 13.660130718954248,
      "grad_norm": 8.890569006325677e-05,
      "learning_rate": 1.786492374727669e-06,
      "loss": 0.1031,
      "step": 127490
    },
    {
      "epoch": 13.66120218579235,
      "grad_norm": 7.846939843147993e-05,
      "learning_rate": 1.7850637522768672e-06,
      "loss": 0.0,
      "step": 127500
    },
    {
      "epoch": 13.662273652630452,
      "grad_norm": 0.0035342841874808073,
      "learning_rate": 1.7836351298260655e-06,
      "loss": 0.0373,
      "step": 127510
    },
    {
      "epoch": 13.663345119468552,
      "grad_norm": 0.0002183408651035279,
      "learning_rate": 1.7822065073752636e-06,
      "loss": 0.0,
      "step": 127520
    },
    {
      "epoch": 13.664416586306654,
      "grad_norm": 8.024873386602849e-05,
      "learning_rate": 1.7807778849244617e-06,
      "loss": 0.0,
      "step": 127530
    },
    {
      "epoch": 13.665488053144756,
      "grad_norm": 0.0002230344107374549,
      "learning_rate": 1.77934926247366e-06,
      "loss": 0.0,
      "step": 127540
    },
    {
      "epoch": 13.666559519982856,
      "grad_norm": 0.00011346759856678545,
      "learning_rate": 1.7779206400228579e-06,
      "loss": 0.0,
      "step": 127550
    },
    {
      "epoch": 13.667630986820958,
      "grad_norm": 0.00012759817764163017,
      "learning_rate": 1.7764920175720562e-06,
      "loss": 0.0,
      "step": 127560
    },
    {
      "epoch": 13.668702453659058,
      "grad_norm": 8.676875586388633e-05,
      "learning_rate": 1.7750633951212545e-06,
      "loss": 0.0,
      "step": 127570
    },
    {
      "epoch": 13.66977392049716,
      "grad_norm": 8.389361755689606e-05,
      "learning_rate": 1.7736347726704526e-06,
      "loss": 0.0,
      "step": 127580
    },
    {
      "epoch": 13.670845387335262,
      "grad_norm": 8.080345287453383e-05,
      "learning_rate": 1.772206150219651e-06,
      "loss": 0.0313,
      "step": 127590
    },
    {
      "epoch": 13.671916854173363,
      "grad_norm": 9.550729009788483e-05,
      "learning_rate": 1.770777527768849e-06,
      "loss": 0.0,
      "step": 127600
    },
    {
      "epoch": 13.672988321011465,
      "grad_norm": 7.674505468457937e-05,
      "learning_rate": 1.769348905318047e-06,
      "loss": 0.0,
      "step": 127610
    },
    {
      "epoch": 13.674059787849567,
      "grad_norm": 0.00053156673675403,
      "learning_rate": 1.7679202828672454e-06,
      "loss": 0.0333,
      "step": 127620
    },
    {
      "epoch": 13.675131254687667,
      "grad_norm": 0.00017631797527428716,
      "learning_rate": 1.7664916604164437e-06,
      "loss": 0.0,
      "step": 127630
    },
    {
      "epoch": 13.676202721525769,
      "grad_norm": 8.526938472641632e-05,
      "learning_rate": 1.7650630379656416e-06,
      "loss": 0.3159,
      "step": 127640
    },
    {
      "epoch": 13.67727418836387,
      "grad_norm": 8.631229138700292e-05,
      "learning_rate": 1.76363441551484e-06,
      "loss": 0.0,
      "step": 127650
    },
    {
      "epoch": 13.678345655201971,
      "grad_norm": 0.0001385499199386686,
      "learning_rate": 1.7622057930640382e-06,
      "loss": 0.0,
      "step": 127660
    },
    {
      "epoch": 13.679417122040073,
      "grad_norm": 8.355335739906877e-05,
      "learning_rate": 1.7607771706132363e-06,
      "loss": 0.0,
      "step": 127670
    },
    {
      "epoch": 13.680488588878173,
      "grad_norm": 0.00017083763668779284,
      "learning_rate": 1.7593485481624344e-06,
      "loss": 0.0,
      "step": 127680
    },
    {
      "epoch": 13.681560055716275,
      "grad_norm": 8.072138734860346e-05,
      "learning_rate": 1.7579199257116327e-06,
      "loss": 0.0029,
      "step": 127690
    },
    {
      "epoch": 13.682631522554377,
      "grad_norm": 8.276718290289864e-05,
      "learning_rate": 1.7564913032608308e-06,
      "loss": 0.0,
      "step": 127700
    },
    {
      "epoch": 13.683702989392478,
      "grad_norm": 0.00011457972141215578,
      "learning_rate": 1.7550626808100291e-06,
      "loss": 0.0,
      "step": 127710
    },
    {
      "epoch": 13.68477445623058,
      "grad_norm": 8.239347516791895e-05,
      "learning_rate": 1.7536340583592274e-06,
      "loss": 0.0002,
      "step": 127720
    },
    {
      "epoch": 13.685845923068682,
      "grad_norm": 8.65926849655807e-05,
      "learning_rate": 1.7522054359084253e-06,
      "loss": 0.2829,
      "step": 127730
    },
    {
      "epoch": 13.686917389906782,
      "grad_norm": 0.00014590509817935526,
      "learning_rate": 1.7507768134576236e-06,
      "loss": 0.0,
      "step": 127740
    },
    {
      "epoch": 13.687988856744884,
      "grad_norm": 0.00014564984303433448,
      "learning_rate": 1.749348191006822e-06,
      "loss": 0.0,
      "step": 127750
    },
    {
      "epoch": 13.689060323582986,
      "grad_norm": 0.06570141762495041,
      "learning_rate": 1.7479195685560198e-06,
      "loss": 0.0003,
      "step": 127760
    },
    {
      "epoch": 13.690131790421086,
      "grad_norm": 8.372458978556097e-05,
      "learning_rate": 1.7464909461052181e-06,
      "loss": 0.0,
      "step": 127770
    },
    {
      "epoch": 13.691203257259188,
      "grad_norm": 8.557271939935163e-05,
      "learning_rate": 1.7450623236544164e-06,
      "loss": 0.0,
      "step": 127780
    },
    {
      "epoch": 13.69227472409729,
      "grad_norm": 0.00013444418436847627,
      "learning_rate": 1.7436337012036145e-06,
      "loss": 0.0,
      "step": 127790
    },
    {
      "epoch": 13.69334619093539,
      "grad_norm": 8.50737196742557e-05,
      "learning_rate": 1.7422050787528128e-06,
      "loss": 0.0,
      "step": 127800
    },
    {
      "epoch": 13.694417657773492,
      "grad_norm": 0.00010833654232556,
      "learning_rate": 1.740776456302011e-06,
      "loss": 0.1045,
      "step": 127810
    },
    {
      "epoch": 13.695489124611594,
      "grad_norm": 0.0001872115390142426,
      "learning_rate": 1.739347833851209e-06,
      "loss": 0.0,
      "step": 127820
    },
    {
      "epoch": 13.696560591449694,
      "grad_norm": 8.315945160575211e-05,
      "learning_rate": 1.7379192114004073e-06,
      "loss": 0.2279,
      "step": 127830
    },
    {
      "epoch": 13.697632058287796,
      "grad_norm": 8.414294279646128e-05,
      "learning_rate": 1.7364905889496056e-06,
      "loss": 0.0,
      "step": 127840
    },
    {
      "epoch": 13.698703525125897,
      "grad_norm": 0.0004493002488743514,
      "learning_rate": 1.7350619664988035e-06,
      "loss": 0.0,
      "step": 127850
    },
    {
      "epoch": 13.699774991963999,
      "grad_norm": 0.00019428053929004818,
      "learning_rate": 1.7336333440480018e-06,
      "loss": 0.0,
      "step": 127860
    },
    {
      "epoch": 13.7008464588021,
      "grad_norm": 0.00031021531322039664,
      "learning_rate": 1.7322047215972001e-06,
      "loss": 0.0,
      "step": 127870
    },
    {
      "epoch": 13.7019179256402,
      "grad_norm": 9.50212124735117e-05,
      "learning_rate": 1.7307760991463982e-06,
      "loss": 0.0,
      "step": 127880
    },
    {
      "epoch": 13.702989392478303,
      "grad_norm": 0.021471792832016945,
      "learning_rate": 1.7293474766955963e-06,
      "loss": 0.0,
      "step": 127890
    },
    {
      "epoch": 13.704060859316405,
      "grad_norm": 0.00013666327868122607,
      "learning_rate": 1.7279188542447946e-06,
      "loss": 0.0,
      "step": 127900
    },
    {
      "epoch": 13.705132326154505,
      "grad_norm": 0.00026425483520142734,
      "learning_rate": 1.7264902317939927e-06,
      "loss": 0.0,
      "step": 127910
    },
    {
      "epoch": 13.706203792992607,
      "grad_norm": 0.00012419930135365576,
      "learning_rate": 1.725061609343191e-06,
      "loss": 0.0,
      "step": 127920
    },
    {
      "epoch": 13.707275259830709,
      "grad_norm": 9.822017455007881e-05,
      "learning_rate": 1.7236329868923894e-06,
      "loss": 0.0,
      "step": 127930
    },
    {
      "epoch": 13.70834672666881,
      "grad_norm": 0.48969146609306335,
      "learning_rate": 1.7222043644415872e-06,
      "loss": 0.0001,
      "step": 127940
    },
    {
      "epoch": 13.709418193506911,
      "grad_norm": 0.00010043257498182356,
      "learning_rate": 1.7207757419907855e-06,
      "loss": 0.2967,
      "step": 127950
    },
    {
      "epoch": 13.710489660345011,
      "grad_norm": 8.477108349325135e-05,
      "learning_rate": 1.7193471195399839e-06,
      "loss": 0.0,
      "step": 127960
    },
    {
      "epoch": 13.711561127183113,
      "grad_norm": 8.804017852526158e-05,
      "learning_rate": 1.717918497089182e-06,
      "loss": 0.0003,
      "step": 127970
    },
    {
      "epoch": 13.712632594021215,
      "grad_norm": 8.716418960830197e-05,
      "learning_rate": 1.71648987463838e-06,
      "loss": 0.1452,
      "step": 127980
    },
    {
      "epoch": 13.713704060859316,
      "grad_norm": 9.490742377238348e-05,
      "learning_rate": 1.7150612521875781e-06,
      "loss": 0.0,
      "step": 127990
    },
    {
      "epoch": 13.714775527697418,
      "grad_norm": 8.18156186142005e-05,
      "learning_rate": 1.7136326297367764e-06,
      "loss": 0.1798,
      "step": 128000
    },
    {
      "epoch": 13.71584699453552,
      "grad_norm": 0.00020202566520310938,
      "learning_rate": 1.7122040072859748e-06,
      "loss": 0.0,
      "step": 128010
    },
    {
      "epoch": 13.71691846137362,
      "grad_norm": 9.747283183969557e-05,
      "learning_rate": 1.7107753848351726e-06,
      "loss": 0.0,
      "step": 128020
    },
    {
      "epoch": 13.717989928211722,
      "grad_norm": 0.0001392379344906658,
      "learning_rate": 1.709346762384371e-06,
      "loss": 0.0,
      "step": 128030
    },
    {
      "epoch": 13.719061395049824,
      "grad_norm": 0.00018694280879572034,
      "learning_rate": 1.7079181399335693e-06,
      "loss": 0.0002,
      "step": 128040
    },
    {
      "epoch": 13.720132861887924,
      "grad_norm": 0.00015182807692326605,
      "learning_rate": 1.7064895174827674e-06,
      "loss": 0.0,
      "step": 128050
    },
    {
      "epoch": 13.721204328726026,
      "grad_norm": 0.00016880498151294887,
      "learning_rate": 1.7050608950319654e-06,
      "loss": 0.0013,
      "step": 128060
    },
    {
      "epoch": 13.722275795564126,
      "grad_norm": 0.00015902631275821477,
      "learning_rate": 1.7036322725811638e-06,
      "loss": 0.0,
      "step": 128070
    },
    {
      "epoch": 13.723347262402228,
      "grad_norm": 274.9048156738281,
      "learning_rate": 1.7022036501303619e-06,
      "loss": 0.1305,
      "step": 128080
    },
    {
      "epoch": 13.72441872924033,
      "grad_norm": 0.4981994926929474,
      "learning_rate": 1.7007750276795602e-06,
      "loss": 0.0002,
      "step": 128090
    },
    {
      "epoch": 13.72549019607843,
      "grad_norm": 9.283979306928813e-05,
      "learning_rate": 1.6993464052287585e-06,
      "loss": 0.0,
      "step": 128100
    },
    {
      "epoch": 13.726561662916533,
      "grad_norm": 9.72975030890666e-05,
      "learning_rate": 1.6979177827779564e-06,
      "loss": 0.0071,
      "step": 128110
    },
    {
      "epoch": 13.727633129754635,
      "grad_norm": 0.0001070169237209484,
      "learning_rate": 1.6964891603271547e-06,
      "loss": 0.0,
      "step": 128120
    },
    {
      "epoch": 13.728704596592735,
      "grad_norm": 9.179139306070283e-05,
      "learning_rate": 1.695060537876353e-06,
      "loss": 0.0,
      "step": 128130
    },
    {
      "epoch": 13.729776063430837,
      "grad_norm": 8.807212725514546e-05,
      "learning_rate": 1.6936319154255509e-06,
      "loss": 0.0,
      "step": 128140
    },
    {
      "epoch": 13.730847530268939,
      "grad_norm": 8.602686284575611e-05,
      "learning_rate": 1.6922032929747492e-06,
      "loss": 0.0,
      "step": 128150
    },
    {
      "epoch": 13.731918997107039,
      "grad_norm": 9.31669637793675e-05,
      "learning_rate": 1.6907746705239475e-06,
      "loss": 0.0,
      "step": 128160
    },
    {
      "epoch": 13.732990463945141,
      "grad_norm": 9.527654037810862e-05,
      "learning_rate": 1.6893460480731456e-06,
      "loss": 0.0,
      "step": 128170
    },
    {
      "epoch": 13.734061930783243,
      "grad_norm": 0.00011283406638540328,
      "learning_rate": 1.6879174256223439e-06,
      "loss": 0.0004,
      "step": 128180
    },
    {
      "epoch": 13.735133397621343,
      "grad_norm": 0.00013211421901360154,
      "learning_rate": 1.686488803171542e-06,
      "loss": 0.0323,
      "step": 128190
    },
    {
      "epoch": 13.736204864459445,
      "grad_norm": 8.914920908864588e-05,
      "learning_rate": 1.68506018072074e-06,
      "loss": 0.0,
      "step": 128200
    },
    {
      "epoch": 13.737276331297547,
      "grad_norm": 9.320110257249326e-05,
      "learning_rate": 1.6836315582699384e-06,
      "loss": 0.0,
      "step": 128210
    },
    {
      "epoch": 13.738347798135647,
      "grad_norm": 0.00014883761468809098,
      "learning_rate": 1.6822029358191367e-06,
      "loss": 0.0,
      "step": 128220
    },
    {
      "epoch": 13.73941926497375,
      "grad_norm": 0.013825252652168274,
      "learning_rate": 1.6807743133683346e-06,
      "loss": 0.0002,
      "step": 128230
    },
    {
      "epoch": 13.74049073181185,
      "grad_norm": 0.00013943896919954568,
      "learning_rate": 1.6793456909175329e-06,
      "loss": 0.0002,
      "step": 128240
    },
    {
      "epoch": 13.741562198649952,
      "grad_norm": 9.92653367575258e-05,
      "learning_rate": 1.6779170684667312e-06,
      "loss": 0.0,
      "step": 128250
    },
    {
      "epoch": 13.742633665488054,
      "grad_norm": 0.00013779746950604022,
      "learning_rate": 1.6764884460159293e-06,
      "loss": 0.0003,
      "step": 128260
    },
    {
      "epoch": 13.743705132326154,
      "grad_norm": 0.00017791044956538826,
      "learning_rate": 1.6750598235651274e-06,
      "loss": 0.0,
      "step": 128270
    },
    {
      "epoch": 13.744776599164256,
      "grad_norm": 0.00016256612434517592,
      "learning_rate": 1.6736312011143257e-06,
      "loss": 0.0,
      "step": 128280
    },
    {
      "epoch": 13.745848066002358,
      "grad_norm": 8.837629138724878e-05,
      "learning_rate": 1.6722025786635238e-06,
      "loss": 0.109,
      "step": 128290
    },
    {
      "epoch": 13.746919532840458,
      "grad_norm": 0.0010227147722616792,
      "learning_rate": 1.670773956212722e-06,
      "loss": 0.0,
      "step": 128300
    },
    {
      "epoch": 13.74799099967856,
      "grad_norm": 0.00015179807087406516,
      "learning_rate": 1.6693453337619204e-06,
      "loss": 0.0,
      "step": 128310
    },
    {
      "epoch": 13.749062466516662,
      "grad_norm": 0.027904199436306953,
      "learning_rate": 1.6679167113111183e-06,
      "loss": 0.0001,
      "step": 128320
    },
    {
      "epoch": 13.750133933354762,
      "grad_norm": 8.691840048413724e-05,
      "learning_rate": 1.6664880888603166e-06,
      "loss": 0.0,
      "step": 128330
    },
    {
      "epoch": 13.751205400192864,
      "grad_norm": 9.72299458226189e-05,
      "learning_rate": 1.6650594664095149e-06,
      "loss": 0.0,
      "step": 128340
    },
    {
      "epoch": 13.752276867030965,
      "grad_norm": 8.431195601588115e-05,
      "learning_rate": 1.663630843958713e-06,
      "loss": 0.0,
      "step": 128350
    },
    {
      "epoch": 13.753348333869067,
      "grad_norm": 8.879164670361206e-05,
      "learning_rate": 1.662202221507911e-06,
      "loss": 0.0,
      "step": 128360
    },
    {
      "epoch": 13.754419800707169,
      "grad_norm": 8.804410026641563e-05,
      "learning_rate": 1.6607735990571094e-06,
      "loss": 0.0,
      "step": 128370
    },
    {
      "epoch": 13.755491267545269,
      "grad_norm": 0.00010415799624752253,
      "learning_rate": 1.6593449766063075e-06,
      "loss": 0.0,
      "step": 128380
    },
    {
      "epoch": 13.75656273438337,
      "grad_norm": 0.00013314015814103186,
      "learning_rate": 1.6579163541555058e-06,
      "loss": 0.0,
      "step": 128390
    },
    {
      "epoch": 13.757634201221473,
      "grad_norm": 8.973055810201913e-05,
      "learning_rate": 1.656487731704704e-06,
      "loss": 0.0001,
      "step": 128400
    },
    {
      "epoch": 13.758705668059573,
      "grad_norm": 0.00014444177213590592,
      "learning_rate": 1.655059109253902e-06,
      "loss": 0.0,
      "step": 128410
    },
    {
      "epoch": 13.759777134897675,
      "grad_norm": 8.066531881922856e-05,
      "learning_rate": 1.6536304868031003e-06,
      "loss": 0.2857,
      "step": 128420
    },
    {
      "epoch": 13.760848601735777,
      "grad_norm": 0.0002025348658207804,
      "learning_rate": 1.6522018643522986e-06,
      "loss": 0.0,
      "step": 128430
    },
    {
      "epoch": 13.761920068573877,
      "grad_norm": 9.021114237839356e-05,
      "learning_rate": 1.6507732419014965e-06,
      "loss": 0.0,
      "step": 128440
    },
    {
      "epoch": 13.76299153541198,
      "grad_norm": 0.00046656178892590106,
      "learning_rate": 1.6493446194506948e-06,
      "loss": 0.1604,
      "step": 128450
    },
    {
      "epoch": 13.764063002250081,
      "grad_norm": 9.306589345214888e-05,
      "learning_rate": 1.6479159969998929e-06,
      "loss": 0.2731,
      "step": 128460
    },
    {
      "epoch": 13.765134469088181,
      "grad_norm": 0.0002101781137753278,
      "learning_rate": 1.6464873745490912e-06,
      "loss": 0.0,
      "step": 128470
    },
    {
      "epoch": 13.766205935926283,
      "grad_norm": 0.00023181895085144788,
      "learning_rate": 1.6450587520982895e-06,
      "loss": 0.0,
      "step": 128480
    },
    {
      "epoch": 13.767277402764385,
      "grad_norm": 9.156220039585605e-05,
      "learning_rate": 1.6436301296474874e-06,
      "loss": 0.1592,
      "step": 128490
    },
    {
      "epoch": 13.768348869602486,
      "grad_norm": 0.00858063530176878,
      "learning_rate": 1.6422015071966857e-06,
      "loss": 0.0,
      "step": 128500
    },
    {
      "epoch": 13.769420336440588,
      "grad_norm": 0.00010392115655122325,
      "learning_rate": 1.640772884745884e-06,
      "loss": 0.0,
      "step": 128510
    },
    {
      "epoch": 13.770491803278688,
      "grad_norm": 9.965575736714527e-05,
      "learning_rate": 1.6393442622950819e-06,
      "loss": 0.0,
      "step": 128520
    },
    {
      "epoch": 13.77156327011679,
      "grad_norm": 0.00010530211147852242,
      "learning_rate": 1.6379156398442802e-06,
      "loss": 0.0,
      "step": 128530
    },
    {
      "epoch": 13.772634736954892,
      "grad_norm": 0.00010151728929486126,
      "learning_rate": 1.6364870173934785e-06,
      "loss": 0.0,
      "step": 128540
    },
    {
      "epoch": 13.773706203792992,
      "grad_norm": 0.0002369163848925382,
      "learning_rate": 1.6350583949426766e-06,
      "loss": 0.0,
      "step": 128550
    },
    {
      "epoch": 13.774777670631094,
      "grad_norm": 9.575313015375286e-05,
      "learning_rate": 1.633629772491875e-06,
      "loss": 0.3686,
      "step": 128560
    },
    {
      "epoch": 13.775849137469196,
      "grad_norm": 9.788218449102715e-05,
      "learning_rate": 1.632201150041073e-06,
      "loss": 0.0,
      "step": 128570
    },
    {
      "epoch": 13.776920604307296,
      "grad_norm": 0.0025262844283133745,
      "learning_rate": 1.630772527590271e-06,
      "loss": 0.0,
      "step": 128580
    },
    {
      "epoch": 13.777992071145398,
      "grad_norm": 0.00010216031660092995,
      "learning_rate": 1.6293439051394694e-06,
      "loss": 0.0,
      "step": 128590
    },
    {
      "epoch": 13.7790635379835,
      "grad_norm": 0.00017860364459920675,
      "learning_rate": 1.6279152826886677e-06,
      "loss": 0.0001,
      "step": 128600
    },
    {
      "epoch": 13.7801350048216,
      "grad_norm": 0.0002388909924775362,
      "learning_rate": 1.6264866602378656e-06,
      "loss": 0.0,
      "step": 128610
    },
    {
      "epoch": 13.781206471659702,
      "grad_norm": 0.00015081421588547528,
      "learning_rate": 1.625058037787064e-06,
      "loss": 0.0,
      "step": 128620
    },
    {
      "epoch": 13.782277938497803,
      "grad_norm": 0.00023606895410921425,
      "learning_rate": 1.6236294153362622e-06,
      "loss": 0.0,
      "step": 128630
    },
    {
      "epoch": 13.783349405335905,
      "grad_norm": 9.352593770017847e-05,
      "learning_rate": 1.6222007928854603e-06,
      "loss": 0.0,
      "step": 128640
    },
    {
      "epoch": 13.784420872174007,
      "grad_norm": 0.0012872063089162111,
      "learning_rate": 1.6207721704346584e-06,
      "loss": 0.0002,
      "step": 128650
    },
    {
      "epoch": 13.785492339012107,
      "grad_norm": 0.00010587971337372437,
      "learning_rate": 1.6193435479838567e-06,
      "loss": 0.3443,
      "step": 128660
    },
    {
      "epoch": 13.786563805850209,
      "grad_norm": 0.0008035816717892885,
      "learning_rate": 1.6179149255330548e-06,
      "loss": 0.0,
      "step": 128670
    },
    {
      "epoch": 13.787635272688311,
      "grad_norm": 9.865214087767527e-05,
      "learning_rate": 1.6164863030822531e-06,
      "loss": 0.0,
      "step": 128680
    },
    {
      "epoch": 13.788706739526411,
      "grad_norm": 0.0001755973935360089,
      "learning_rate": 1.6150576806314514e-06,
      "loss": 0.0,
      "step": 128690
    },
    {
      "epoch": 13.789778206364513,
      "grad_norm": 0.00012436961696948856,
      "learning_rate": 1.6136290581806493e-06,
      "loss": 0.0,
      "step": 128700
    },
    {
      "epoch": 13.790849673202615,
      "grad_norm": 0.014082763344049454,
      "learning_rate": 1.6122004357298476e-06,
      "loss": 0.0,
      "step": 128710
    },
    {
      "epoch": 13.791921140040715,
      "grad_norm": 8.87633505044505e-05,
      "learning_rate": 1.610771813279046e-06,
      "loss": 0.0,
      "step": 128720
    },
    {
      "epoch": 13.792992606878817,
      "grad_norm": 0.0007233042852021754,
      "learning_rate": 1.6093431908282438e-06,
      "loss": 0.0,
      "step": 128730
    },
    {
      "epoch": 13.794064073716918,
      "grad_norm": 0.00013959741045255214,
      "learning_rate": 1.6079145683774421e-06,
      "loss": 0.021,
      "step": 128740
    },
    {
      "epoch": 13.79513554055502,
      "grad_norm": 9.959490853361785e-05,
      "learning_rate": 1.6064859459266404e-06,
      "loss": 0.0,
      "step": 128750
    },
    {
      "epoch": 13.796207007393122,
      "grad_norm": 0.00014682646724395454,
      "learning_rate": 1.6050573234758385e-06,
      "loss": 0.0,
      "step": 128760
    },
    {
      "epoch": 13.797278474231222,
      "grad_norm": 0.0001203009087475948,
      "learning_rate": 1.6036287010250368e-06,
      "loss": 0.0,
      "step": 128770
    },
    {
      "epoch": 13.798349941069324,
      "grad_norm": 8.894427446648479e-05,
      "learning_rate": 1.6022000785742351e-06,
      "loss": 0.0,
      "step": 128780
    },
    {
      "epoch": 13.799421407907426,
      "grad_norm": 0.019959965720772743,
      "learning_rate": 1.600771456123433e-06,
      "loss": 0.0043,
      "step": 128790
    },
    {
      "epoch": 13.800492874745526,
      "grad_norm": 0.00015267434355337173,
      "learning_rate": 1.5993428336726313e-06,
      "loss": 0.0,
      "step": 128800
    },
    {
      "epoch": 13.801564341583628,
      "grad_norm": 0.00018528691725805402,
      "learning_rate": 1.5979142112218296e-06,
      "loss": 0.0,
      "step": 128810
    },
    {
      "epoch": 13.80263580842173,
      "grad_norm": 0.00010627345909597352,
      "learning_rate": 1.5964855887710275e-06,
      "loss": 0.0,
      "step": 128820
    },
    {
      "epoch": 13.80370727525983,
      "grad_norm": 0.0001061926013790071,
      "learning_rate": 1.5950569663202258e-06,
      "loss": 0.0,
      "step": 128830
    },
    {
      "epoch": 13.804778742097932,
      "grad_norm": 0.00018916346016339958,
      "learning_rate": 1.5936283438694241e-06,
      "loss": 0.0,
      "step": 128840
    },
    {
      "epoch": 13.805850208936034,
      "grad_norm": 0.005810949951410294,
      "learning_rate": 1.5921997214186222e-06,
      "loss": 0.0,
      "step": 128850
    },
    {
      "epoch": 13.806921675774134,
      "grad_norm": 8.787529804976657e-05,
      "learning_rate": 1.5907710989678205e-06,
      "loss": 0.0,
      "step": 128860
    },
    {
      "epoch": 13.807993142612236,
      "grad_norm": 0.00018366557196713984,
      "learning_rate": 1.5893424765170186e-06,
      "loss": 0.0022,
      "step": 128870
    },
    {
      "epoch": 13.809064609450338,
      "grad_norm": 0.00010133633622899652,
      "learning_rate": 1.5879138540662167e-06,
      "loss": 0.0,
      "step": 128880
    },
    {
      "epoch": 13.810136076288439,
      "grad_norm": 9.184140071738511e-05,
      "learning_rate": 1.586485231615415e-06,
      "loss": 0.0001,
      "step": 128890
    },
    {
      "epoch": 13.81120754312654,
      "grad_norm": 0.00013338781718630344,
      "learning_rate": 1.585056609164613e-06,
      "loss": 0.0,
      "step": 128900
    },
    {
      "epoch": 13.81227900996464,
      "grad_norm": 0.0015057413838803768,
      "learning_rate": 1.5836279867138112e-06,
      "loss": 0.0005,
      "step": 128910
    },
    {
      "epoch": 13.813350476802743,
      "grad_norm": 0.00014521264529321343,
      "learning_rate": 1.5821993642630095e-06,
      "loss": 0.0004,
      "step": 128920
    },
    {
      "epoch": 13.814421943640845,
      "grad_norm": 0.00016157272330019623,
      "learning_rate": 1.5807707418122076e-06,
      "loss": 0.0,
      "step": 128930
    },
    {
      "epoch": 13.815493410478945,
      "grad_norm": 84.96925354003906,
      "learning_rate": 1.579342119361406e-06,
      "loss": 0.0525,
      "step": 128940
    },
    {
      "epoch": 13.816564877317047,
      "grad_norm": 8.71035226737149e-05,
      "learning_rate": 1.577913496910604e-06,
      "loss": 0.0,
      "step": 128950
    },
    {
      "epoch": 13.817636344155149,
      "grad_norm": 0.00014630290388595313,
      "learning_rate": 1.5764848744598021e-06,
      "loss": 0.0,
      "step": 128960
    },
    {
      "epoch": 13.81870781099325,
      "grad_norm": 0.00010350924276281148,
      "learning_rate": 1.5750562520090004e-06,
      "loss": 0.0822,
      "step": 128970
    },
    {
      "epoch": 13.819779277831351,
      "grad_norm": 0.00024262465012725443,
      "learning_rate": 1.5736276295581988e-06,
      "loss": 0.0,
      "step": 128980
    },
    {
      "epoch": 13.820850744669453,
      "grad_norm": 0.00014605546311940998,
      "learning_rate": 1.5721990071073966e-06,
      "loss": 0.0014,
      "step": 128990
    },
    {
      "epoch": 13.821922211507554,
      "grad_norm": 0.0001306909107370302,
      "learning_rate": 1.570770384656595e-06,
      "loss": 0.0,
      "step": 129000
    },
    {
      "epoch": 13.822993678345656,
      "grad_norm": 0.0001351460232399404,
      "learning_rate": 1.5693417622057933e-06,
      "loss": 0.185,
      "step": 129010
    },
    {
      "epoch": 13.824065145183756,
      "grad_norm": 0.0013142641400918365,
      "learning_rate": 1.5679131397549913e-06,
      "loss": 0.0,
      "step": 129020
    },
    {
      "epoch": 13.825136612021858,
      "grad_norm": 9.780932305147871e-05,
      "learning_rate": 1.5664845173041894e-06,
      "loss": 0.0,
      "step": 129030
    },
    {
      "epoch": 13.82620807885996,
      "grad_norm": 0.0024052404332906008,
      "learning_rate": 1.5650558948533878e-06,
      "loss": 0.0,
      "step": 129040
    },
    {
      "epoch": 13.82727954569806,
      "grad_norm": 0.00016679269901942462,
      "learning_rate": 1.5636272724025858e-06,
      "loss": 0.2048,
      "step": 129050
    },
    {
      "epoch": 13.828351012536162,
      "grad_norm": 0.0003160478954669088,
      "learning_rate": 1.5621986499517842e-06,
      "loss": 0.0,
      "step": 129060
    },
    {
      "epoch": 13.829422479374264,
      "grad_norm": 0.00011823654494946823,
      "learning_rate": 1.5607700275009825e-06,
      "loss": 0.0,
      "step": 129070
    },
    {
      "epoch": 13.830493946212364,
      "grad_norm": 0.0006302915280684829,
      "learning_rate": 1.5593414050501803e-06,
      "loss": 0.0,
      "step": 129080
    },
    {
      "epoch": 13.831565413050466,
      "grad_norm": 0.00013491760182660073,
      "learning_rate": 1.5579127825993787e-06,
      "loss": 0.1695,
      "step": 129090
    },
    {
      "epoch": 13.832636879888568,
      "grad_norm": 0.0015699319774284959,
      "learning_rate": 1.556484160148577e-06,
      "loss": 0.0,
      "step": 129100
    },
    {
      "epoch": 13.833708346726668,
      "grad_norm": 8.45825343276374e-05,
      "learning_rate": 1.5550555376977748e-06,
      "loss": 0.0,
      "step": 129110
    },
    {
      "epoch": 13.83477981356477,
      "grad_norm": 5.500279426574707,
      "learning_rate": 1.5536269152469732e-06,
      "loss": 0.002,
      "step": 129120
    },
    {
      "epoch": 13.83585128040287,
      "grad_norm": 0.0001733012031763792,
      "learning_rate": 1.5521982927961715e-06,
      "loss": 0.0,
      "step": 129130
    },
    {
      "epoch": 13.836922747240973,
      "grad_norm": 0.00760924955829978,
      "learning_rate": 1.5507696703453696e-06,
      "loss": 0.0,
      "step": 129140
    },
    {
      "epoch": 13.837994214079075,
      "grad_norm": 0.00011869837180711329,
      "learning_rate": 1.5493410478945679e-06,
      "loss": 0.0,
      "step": 129150
    },
    {
      "epoch": 13.839065680917175,
      "grad_norm": 0.00022248677851166576,
      "learning_rate": 1.5479124254437662e-06,
      "loss": 0.0,
      "step": 129160
    },
    {
      "epoch": 13.840137147755277,
      "grad_norm": 0.00015698424249421805,
      "learning_rate": 1.546483802992964e-06,
      "loss": 0.1246,
      "step": 129170
    },
    {
      "epoch": 13.841208614593379,
      "grad_norm": 0.00011253429693169892,
      "learning_rate": 1.5450551805421624e-06,
      "loss": 0.0,
      "step": 129180
    },
    {
      "epoch": 13.842280081431479,
      "grad_norm": 17.902156829833984,
      "learning_rate": 1.5436265580913607e-06,
      "loss": 0.1629,
      "step": 129190
    },
    {
      "epoch": 13.843351548269581,
      "grad_norm": 0.00012823755969293416,
      "learning_rate": 1.5421979356405586e-06,
      "loss": 0.0,
      "step": 129200
    },
    {
      "epoch": 13.844423015107683,
      "grad_norm": 0.00015291279123630375,
      "learning_rate": 1.5407693131897569e-06,
      "loss": 0.0036,
      "step": 129210
    },
    {
      "epoch": 13.845494481945783,
      "grad_norm": 0.00020125671289861202,
      "learning_rate": 1.5393406907389552e-06,
      "loss": 0.0002,
      "step": 129220
    },
    {
      "epoch": 13.846565948783885,
      "grad_norm": 9.393868094775826e-05,
      "learning_rate": 1.5379120682881533e-06,
      "loss": 0.0,
      "step": 129230
    },
    {
      "epoch": 13.847637415621987,
      "grad_norm": 0.0003646514087449759,
      "learning_rate": 1.5364834458373516e-06,
      "loss": 0.0,
      "step": 129240
    },
    {
      "epoch": 13.848708882460087,
      "grad_norm": 8.58602361404337e-05,
      "learning_rate": 1.5350548233865497e-06,
      "loss": 0.0,
      "step": 129250
    },
    {
      "epoch": 13.84978034929819,
      "grad_norm": 0.00012632978905458003,
      "learning_rate": 1.5336262009357478e-06,
      "loss": 0.0,
      "step": 129260
    },
    {
      "epoch": 13.850851816136291,
      "grad_norm": 8.94043332664296e-05,
      "learning_rate": 1.532197578484946e-06,
      "loss": 0.0,
      "step": 129270
    },
    {
      "epoch": 13.851923282974392,
      "grad_norm": 0.0016632074257358909,
      "learning_rate": 1.5307689560341444e-06,
      "loss": 0.0,
      "step": 129280
    },
    {
      "epoch": 13.852994749812494,
      "grad_norm": 0.00030487298499792814,
      "learning_rate": 1.5293403335833423e-06,
      "loss": 0.0,
      "step": 129290
    },
    {
      "epoch": 13.854066216650594,
      "grad_norm": 0.0016074309824034572,
      "learning_rate": 1.5279117111325406e-06,
      "loss": 0.0,
      "step": 129300
    },
    {
      "epoch": 13.855137683488696,
      "grad_norm": 9.581235644873232e-05,
      "learning_rate": 1.5264830886817389e-06,
      "loss": 0.0001,
      "step": 129310
    },
    {
      "epoch": 13.856209150326798,
      "grad_norm": 0.00011488958989502862,
      "learning_rate": 1.525054466230937e-06,
      "loss": 0.0,
      "step": 129320
    },
    {
      "epoch": 13.857280617164898,
      "grad_norm": 0.0010750002693384886,
      "learning_rate": 1.523625843780135e-06,
      "loss": 0.0668,
      "step": 129330
    },
    {
      "epoch": 13.858352084003,
      "grad_norm": 0.0001505417312728241,
      "learning_rate": 1.5221972213293334e-06,
      "loss": 0.0,
      "step": 129340
    },
    {
      "epoch": 13.859423550841102,
      "grad_norm": 9.74120557657443e-05,
      "learning_rate": 1.5207685988785315e-06,
      "loss": 0.0,
      "step": 129350
    },
    {
      "epoch": 13.860495017679202,
      "grad_norm": 0.00010120375372935086,
      "learning_rate": 1.5193399764277298e-06,
      "loss": 0.0,
      "step": 129360
    },
    {
      "epoch": 13.861566484517304,
      "grad_norm": 9.726206189952791e-05,
      "learning_rate": 1.5179113539769277e-06,
      "loss": 0.0,
      "step": 129370
    },
    {
      "epoch": 13.862637951355406,
      "grad_norm": 8.877415530150756e-05,
      "learning_rate": 1.516482731526126e-06,
      "loss": 0.0,
      "step": 129380
    },
    {
      "epoch": 13.863709418193507,
      "grad_norm": 0.00016313602100126445,
      "learning_rate": 1.5150541090753243e-06,
      "loss": 0.0,
      "step": 129390
    },
    {
      "epoch": 13.864780885031609,
      "grad_norm": 9.527248766971752e-05,
      "learning_rate": 1.5136254866245224e-06,
      "loss": 0.0,
      "step": 129400
    },
    {
      "epoch": 13.865852351869709,
      "grad_norm": 0.00010259354166919366,
      "learning_rate": 1.5121968641737205e-06,
      "loss": 0.0,
      "step": 129410
    },
    {
      "epoch": 13.86692381870781,
      "grad_norm": 0.00019695662194862962,
      "learning_rate": 1.5107682417229188e-06,
      "loss": 0.0,
      "step": 129420
    },
    {
      "epoch": 13.867995285545913,
      "grad_norm": 0.00010835432476596907,
      "learning_rate": 1.5093396192721169e-06,
      "loss": 0.0,
      "step": 129430
    },
    {
      "epoch": 13.869066752384013,
      "grad_norm": 9.791199408937246e-05,
      "learning_rate": 1.5079109968213152e-06,
      "loss": 0.0,
      "step": 129440
    },
    {
      "epoch": 13.870138219222115,
      "grad_norm": 0.0001243581500602886,
      "learning_rate": 1.5064823743705135e-06,
      "loss": 0.0,
      "step": 129450
    },
    {
      "epoch": 13.871209686060217,
      "grad_norm": 9.650246647652239e-05,
      "learning_rate": 1.5050537519197114e-06,
      "loss": 0.0,
      "step": 129460
    },
    {
      "epoch": 13.872281152898317,
      "grad_norm": 0.00011634858674369752,
      "learning_rate": 1.5036251294689097e-06,
      "loss": 0.0,
      "step": 129470
    },
    {
      "epoch": 13.87335261973642,
      "grad_norm": 0.00012756189971696585,
      "learning_rate": 1.502196507018108e-06,
      "loss": 0.0,
      "step": 129480
    },
    {
      "epoch": 13.874424086574521,
      "grad_norm": 0.00011542150605237111,
      "learning_rate": 1.5007678845673059e-06,
      "loss": 0.0,
      "step": 129490
    },
    {
      "epoch": 13.875495553412621,
      "grad_norm": 9.416958346264437e-05,
      "learning_rate": 1.4993392621165042e-06,
      "loss": 0.0501,
      "step": 129500
    },
    {
      "epoch": 13.876567020250723,
      "grad_norm": 9.776571823749691e-05,
      "learning_rate": 1.4979106396657025e-06,
      "loss": 0.0,
      "step": 129510
    },
    {
      "epoch": 13.877638487088825,
      "grad_norm": 0.0001195333170471713,
      "learning_rate": 1.4964820172149006e-06,
      "loss": 0.0,
      "step": 129520
    },
    {
      "epoch": 13.878709953926926,
      "grad_norm": 9.125987708102912e-05,
      "learning_rate": 1.495053394764099e-06,
      "loss": 0.3076,
      "step": 129530
    },
    {
      "epoch": 13.879781420765028,
      "grad_norm": 0.00010153137554880232,
      "learning_rate": 1.4936247723132972e-06,
      "loss": 0.0,
      "step": 129540
    },
    {
      "epoch": 13.880852887603128,
      "grad_norm": 0.00011235318379476666,
      "learning_rate": 1.492196149862495e-06,
      "loss": 0.0,
      "step": 129550
    },
    {
      "epoch": 13.88192435444123,
      "grad_norm": 0.0001661392889218405,
      "learning_rate": 1.4907675274116934e-06,
      "loss": 0.013,
      "step": 129560
    },
    {
      "epoch": 13.882995821279332,
      "grad_norm": 0.00011497644300106913,
      "learning_rate": 1.4893389049608917e-06,
      "loss": 0.0,
      "step": 129570
    },
    {
      "epoch": 13.884067288117432,
      "grad_norm": 9.289698209613562e-05,
      "learning_rate": 1.4879102825100896e-06,
      "loss": 0.0,
      "step": 129580
    },
    {
      "epoch": 13.885138754955534,
      "grad_norm": 0.0001364972413284704,
      "learning_rate": 1.486481660059288e-06,
      "loss": 0.0,
      "step": 129590
    },
    {
      "epoch": 13.886210221793636,
      "grad_norm": 0.0001422951027052477,
      "learning_rate": 1.4850530376084862e-06,
      "loss": 0.0,
      "step": 129600
    },
    {
      "epoch": 13.887281688631736,
      "grad_norm": 0.0013616287615150213,
      "learning_rate": 1.4836244151576843e-06,
      "loss": 0.0604,
      "step": 129610
    },
    {
      "epoch": 13.888353155469838,
      "grad_norm": 0.000135703943669796,
      "learning_rate": 1.4821957927068826e-06,
      "loss": 0.0,
      "step": 129620
    },
    {
      "epoch": 13.88942462230794,
      "grad_norm": 0.00011561656720004976,
      "learning_rate": 1.4807671702560807e-06,
      "loss": 0.0,
      "step": 129630
    },
    {
      "epoch": 13.89049608914604,
      "grad_norm": 0.00014275821740739048,
      "learning_rate": 1.4793385478052788e-06,
      "loss": 0.0,
      "step": 129640
    },
    {
      "epoch": 13.891567555984143,
      "grad_norm": 0.0013375973794609308,
      "learning_rate": 1.4779099253544771e-06,
      "loss": 0.0876,
      "step": 129650
    },
    {
      "epoch": 13.892639022822244,
      "grad_norm": 8.375586912734434e-05,
      "learning_rate": 1.4764813029036754e-06,
      "loss": 0.0002,
      "step": 129660
    },
    {
      "epoch": 13.893710489660345,
      "grad_norm": 0.00031817369745112956,
      "learning_rate": 1.4750526804528733e-06,
      "loss": 0.0,
      "step": 129670
    },
    {
      "epoch": 13.894781956498447,
      "grad_norm": 9.416652756044641e-05,
      "learning_rate": 1.4736240580020716e-06,
      "loss": 0.0,
      "step": 129680
    },
    {
      "epoch": 13.895853423336547,
      "grad_norm": 0.00018272556189913303,
      "learning_rate": 1.47219543555127e-06,
      "loss": 0.0,
      "step": 129690
    },
    {
      "epoch": 13.896924890174649,
      "grad_norm": 0.00010502566146897152,
      "learning_rate": 1.470766813100468e-06,
      "loss": 0.0,
      "step": 129700
    },
    {
      "epoch": 13.897996357012751,
      "grad_norm": 0.0009577962337061763,
      "learning_rate": 1.4693381906496661e-06,
      "loss": 0.0,
      "step": 129710
    },
    {
      "epoch": 13.899067823850851,
      "grad_norm": 9.31769100134261e-05,
      "learning_rate": 1.4679095681988644e-06,
      "loss": 0.0,
      "step": 129720
    },
    {
      "epoch": 13.900139290688953,
      "grad_norm": 9.231952572008595e-05,
      "learning_rate": 1.4664809457480625e-06,
      "loss": 0.1637,
      "step": 129730
    },
    {
      "epoch": 13.901210757527055,
      "grad_norm": 0.0002574164536781609,
      "learning_rate": 1.4650523232972608e-06,
      "loss": 0.0001,
      "step": 129740
    },
    {
      "epoch": 13.902282224365155,
      "grad_norm": 0.00019063665240537375,
      "learning_rate": 1.4636237008464591e-06,
      "loss": 0.0,
      "step": 129750
    },
    {
      "epoch": 13.903353691203257,
      "grad_norm": 0.0001733180833980441,
      "learning_rate": 1.462195078395657e-06,
      "loss": 0.0,
      "step": 129760
    },
    {
      "epoch": 13.90442515804136,
      "grad_norm": 9.504565969109535e-05,
      "learning_rate": 1.4607664559448553e-06,
      "loss": 0.0,
      "step": 129770
    },
    {
      "epoch": 13.90549662487946,
      "grad_norm": 9.048101492226124e-05,
      "learning_rate": 1.4593378334940536e-06,
      "loss": 0.0001,
      "step": 129780
    },
    {
      "epoch": 13.906568091717562,
      "grad_norm": 0.00010261328134220093,
      "learning_rate": 1.4579092110432515e-06,
      "loss": 0.0,
      "step": 129790
    },
    {
      "epoch": 13.907639558555662,
      "grad_norm": 0.00013555506302509457,
      "learning_rate": 1.4564805885924498e-06,
      "loss": 0.0,
      "step": 129800
    },
    {
      "epoch": 13.908711025393764,
      "grad_norm": 0.00012776043149642646,
      "learning_rate": 1.455051966141648e-06,
      "loss": 0.0771,
      "step": 129810
    },
    {
      "epoch": 13.909782492231866,
      "grad_norm": 0.00017779866175260395,
      "learning_rate": 1.4536233436908462e-06,
      "loss": 0.0,
      "step": 129820
    },
    {
      "epoch": 13.910853959069966,
      "grad_norm": 9.659754869062454e-05,
      "learning_rate": 1.4521947212400445e-06,
      "loss": 0.0,
      "step": 129830
    },
    {
      "epoch": 13.911925425908068,
      "grad_norm": 0.08190693706274033,
      "learning_rate": 1.4507660987892424e-06,
      "loss": 0.0,
      "step": 129840
    },
    {
      "epoch": 13.91299689274617,
      "grad_norm": 0.0001252304355148226,
      "learning_rate": 1.4493374763384407e-06,
      "loss": 0.0,
      "step": 129850
    },
    {
      "epoch": 13.91406835958427,
      "grad_norm": 0.00014463452680502087,
      "learning_rate": 1.447908853887639e-06,
      "loss": 0.0,
      "step": 129860
    },
    {
      "epoch": 13.915139826422372,
      "grad_norm": 0.00011604392784647644,
      "learning_rate": 1.446480231436837e-06,
      "loss": 0.0,
      "step": 129870
    },
    {
      "epoch": 13.916211293260474,
      "grad_norm": 9.339328244095668e-05,
      "learning_rate": 1.4450516089860352e-06,
      "loss": 0.0002,
      "step": 129880
    },
    {
      "epoch": 13.917282760098574,
      "grad_norm": 9.881073492579162e-05,
      "learning_rate": 1.4436229865352335e-06,
      "loss": 0.0,
      "step": 129890
    },
    {
      "epoch": 13.918354226936676,
      "grad_norm": 0.00015367718879133463,
      "learning_rate": 1.4421943640844316e-06,
      "loss": 0.0001,
      "step": 129900
    },
    {
      "epoch": 13.919425693774778,
      "grad_norm": 9.121278708335012e-05,
      "learning_rate": 1.44076574163363e-06,
      "loss": 0.0,
      "step": 129910
    },
    {
      "epoch": 13.920497160612879,
      "grad_norm": 9.065106132766232e-05,
      "learning_rate": 1.4393371191828283e-06,
      "loss": 0.1027,
      "step": 129920
    },
    {
      "epoch": 13.92156862745098,
      "grad_norm": 0.000154420908074826,
      "learning_rate": 1.4379084967320261e-06,
      "loss": 0.0,
      "step": 129930
    },
    {
      "epoch": 13.922640094289083,
      "grad_norm": 9.011816291604191e-05,
      "learning_rate": 1.4364798742812244e-06,
      "loss": 0.1463,
      "step": 129940
    },
    {
      "epoch": 13.923711561127183,
      "grad_norm": 8.893736230675131e-05,
      "learning_rate": 1.4350512518304228e-06,
      "loss": 0.0001,
      "step": 129950
    },
    {
      "epoch": 13.924783027965285,
      "grad_norm": 9.636300819693133e-05,
      "learning_rate": 1.4336226293796206e-06,
      "loss": 0.0,
      "step": 129960
    },
    {
      "epoch": 13.925854494803385,
      "grad_norm": 0.00010796953574754298,
      "learning_rate": 1.432194006928819e-06,
      "loss": 0.0016,
      "step": 129970
    },
    {
      "epoch": 13.926925961641487,
      "grad_norm": 0.00011347799591021612,
      "learning_rate": 1.4307653844780173e-06,
      "loss": 0.0,
      "step": 129980
    },
    {
      "epoch": 13.927997428479589,
      "grad_norm": 0.00031329449848271906,
      "learning_rate": 1.4293367620272153e-06,
      "loss": 0.0,
      "step": 129990
    },
    {
      "epoch": 13.92906889531769,
      "grad_norm": 9.698143549030647e-05,
      "learning_rate": 1.4279081395764137e-06,
      "loss": 0.0071,
      "step": 130000
    },
    {
      "epoch": 13.930140362155791,
      "grad_norm": 9.135033178608865e-05,
      "learning_rate": 1.4264795171256118e-06,
      "loss": 0.0,
      "step": 130010
    },
    {
      "epoch": 13.931211828993893,
      "grad_norm": 0.00017446291167289019,
      "learning_rate": 1.4250508946748098e-06,
      "loss": 0.0,
      "step": 130020
    },
    {
      "epoch": 13.932283295831994,
      "grad_norm": 0.00010701350402086973,
      "learning_rate": 1.4236222722240082e-06,
      "loss": 0.0,
      "step": 130030
    },
    {
      "epoch": 13.933354762670096,
      "grad_norm": 0.00016337713168468326,
      "learning_rate": 1.4221936497732065e-06,
      "loss": 0.0,
      "step": 130040
    },
    {
      "epoch": 13.934426229508198,
      "grad_norm": 0.0001720613508950919,
      "learning_rate": 1.4207650273224043e-06,
      "loss": 0.0,
      "step": 130050
    },
    {
      "epoch": 13.935497696346298,
      "grad_norm": 9.112091356655583e-05,
      "learning_rate": 1.4193364048716027e-06,
      "loss": 0.0,
      "step": 130060
    },
    {
      "epoch": 13.9365691631844,
      "grad_norm": 0.0007280936697497964,
      "learning_rate": 1.417907782420801e-06,
      "loss": 0.0,
      "step": 130070
    },
    {
      "epoch": 13.9376406300225,
      "grad_norm": 0.00019633135525509715,
      "learning_rate": 1.416479159969999e-06,
      "loss": 0.0,
      "step": 130080
    },
    {
      "epoch": 13.938712096860602,
      "grad_norm": 0.00010988336725858971,
      "learning_rate": 1.4150505375191972e-06,
      "loss": 0.0,
      "step": 130090
    },
    {
      "epoch": 13.939783563698704,
      "grad_norm": 8.946329762693495e-05,
      "learning_rate": 1.4136219150683955e-06,
      "loss": 0.0,
      "step": 130100
    },
    {
      "epoch": 13.940855030536804,
      "grad_norm": 0.0003013046516571194,
      "learning_rate": 1.4121932926175936e-06,
      "loss": 0.0,
      "step": 130110
    },
    {
      "epoch": 13.941926497374906,
      "grad_norm": 0.0004937409539707005,
      "learning_rate": 1.4107646701667919e-06,
      "loss": 0.0,
      "step": 130120
    },
    {
      "epoch": 13.942997964213008,
      "grad_norm": 0.00025506148813292384,
      "learning_rate": 1.4093360477159902e-06,
      "loss": 0.0,
      "step": 130130
    },
    {
      "epoch": 13.944069431051108,
      "grad_norm": 0.028799347579479218,
      "learning_rate": 1.407907425265188e-06,
      "loss": 0.0,
      "step": 130140
    },
    {
      "epoch": 13.94514089788921,
      "grad_norm": 0.00015855133824516088,
      "learning_rate": 1.4064788028143864e-06,
      "loss": 0.0,
      "step": 130150
    },
    {
      "epoch": 13.946212364727312,
      "grad_norm": 9.035678522195667e-05,
      "learning_rate": 1.4050501803635847e-06,
      "loss": 0.0,
      "step": 130160
    },
    {
      "epoch": 13.947283831565413,
      "grad_norm": 8.743617217987776e-05,
      "learning_rate": 1.4036215579127826e-06,
      "loss": 0.0,
      "step": 130170
    },
    {
      "epoch": 13.948355298403515,
      "grad_norm": 0.0035621703136712313,
      "learning_rate": 1.4021929354619809e-06,
      "loss": 0.0,
      "step": 130180
    },
    {
      "epoch": 13.949426765241615,
      "grad_norm": 0.0001654066436458379,
      "learning_rate": 1.4007643130111792e-06,
      "loss": 0.0,
      "step": 130190
    },
    {
      "epoch": 13.950498232079717,
      "grad_norm": 0.0004914806340821087,
      "learning_rate": 1.3993356905603773e-06,
      "loss": 0.0,
      "step": 130200
    },
    {
      "epoch": 13.951569698917819,
      "grad_norm": 9.654286259319633e-05,
      "learning_rate": 1.3979070681095756e-06,
      "loss": 0.0,
      "step": 130210
    },
    {
      "epoch": 13.952641165755919,
      "grad_norm": 0.0022392836399376392,
      "learning_rate": 1.3964784456587737e-06,
      "loss": 0.0461,
      "step": 130220
    },
    {
      "epoch": 13.953712632594021,
      "grad_norm": 270.39678955078125,
      "learning_rate": 1.3950498232079718e-06,
      "loss": 0.169,
      "step": 130230
    },
    {
      "epoch": 13.954784099432123,
      "grad_norm": 0.00011298991739749908,
      "learning_rate": 1.39362120075717e-06,
      "loss": 0.0,
      "step": 130240
    },
    {
      "epoch": 13.955855566270223,
      "grad_norm": 9.19237281777896e-05,
      "learning_rate": 1.3921925783063684e-06,
      "loss": 0.0,
      "step": 130250
    },
    {
      "epoch": 13.956927033108325,
      "grad_norm": 0.00014010300219524652,
      "learning_rate": 1.3907639558555663e-06,
      "loss": 0.0,
      "step": 130260
    },
    {
      "epoch": 13.957998499946427,
      "grad_norm": 0.0003709486045408994,
      "learning_rate": 1.3893353334047646e-06,
      "loss": 0.0,
      "step": 130270
    },
    {
      "epoch": 13.959069966784527,
      "grad_norm": 0.0002298131148563698,
      "learning_rate": 1.3879067109539627e-06,
      "loss": 0.0,
      "step": 130280
    },
    {
      "epoch": 13.96014143362263,
      "grad_norm": 0.00017489294987171888,
      "learning_rate": 1.386478088503161e-06,
      "loss": 0.0,
      "step": 130290
    },
    {
      "epoch": 13.961212900460731,
      "grad_norm": 9.274717012885958e-05,
      "learning_rate": 1.385049466052359e-06,
      "loss": 0.0,
      "step": 130300
    },
    {
      "epoch": 13.962284367298832,
      "grad_norm": 9.275181218981743e-05,
      "learning_rate": 1.3836208436015572e-06,
      "loss": 0.0,
      "step": 130310
    },
    {
      "epoch": 13.963355834136934,
      "grad_norm": 0.00018032001389656216,
      "learning_rate": 1.3821922211507555e-06,
      "loss": 0.0,
      "step": 130320
    },
    {
      "epoch": 13.964427300975036,
      "grad_norm": 0.12319398671388626,
      "learning_rate": 1.3807635986999538e-06,
      "loss": 0.0001,
      "step": 130330
    },
    {
      "epoch": 13.965498767813136,
      "grad_norm": 0.00018530472880229354,
      "learning_rate": 1.3793349762491517e-06,
      "loss": 0.0,
      "step": 130340
    },
    {
      "epoch": 13.966570234651238,
      "grad_norm": 8.908173913368955e-05,
      "learning_rate": 1.37790635379835e-06,
      "loss": 0.0,
      "step": 130350
    },
    {
      "epoch": 13.967641701489338,
      "grad_norm": 0.00010416476288810372,
      "learning_rate": 1.3764777313475483e-06,
      "loss": 0.0,
      "step": 130360
    },
    {
      "epoch": 13.96871316832744,
      "grad_norm": 9.976056026061997e-05,
      "learning_rate": 1.3750491088967464e-06,
      "loss": 0.0,
      "step": 130370
    },
    {
      "epoch": 13.969784635165542,
      "grad_norm": 0.0002203861076850444,
      "learning_rate": 1.3736204864459447e-06,
      "loss": 0.0,
      "step": 130380
    },
    {
      "epoch": 13.970856102003642,
      "grad_norm": 0.061552129685878754,
      "learning_rate": 1.3721918639951428e-06,
      "loss": 0.0001,
      "step": 130390
    },
    {
      "epoch": 13.971927568841744,
      "grad_norm": 0.00012694204633589834,
      "learning_rate": 1.3707632415443409e-06,
      "loss": 0.0,
      "step": 130400
    },
    {
      "epoch": 13.972999035679846,
      "grad_norm": 0.00011129881022498012,
      "learning_rate": 1.3693346190935392e-06,
      "loss": 0.0,
      "step": 130410
    },
    {
      "epoch": 13.974070502517947,
      "grad_norm": 0.00011246076610404998,
      "learning_rate": 1.3679059966427375e-06,
      "loss": 0.1242,
      "step": 130420
    },
    {
      "epoch": 13.975141969356049,
      "grad_norm": 0.0002946348686236888,
      "learning_rate": 1.3664773741919354e-06,
      "loss": 0.0,
      "step": 130430
    },
    {
      "epoch": 13.97621343619415,
      "grad_norm": 0.00011920734687009826,
      "learning_rate": 1.3650487517411337e-06,
      "loss": 0.0,
      "step": 130440
    },
    {
      "epoch": 13.97728490303225,
      "grad_norm": 9.149756806436926e-05,
      "learning_rate": 1.363620129290332e-06,
      "loss": 0.0,
      "step": 130450
    },
    {
      "epoch": 13.978356369870353,
      "grad_norm": 0.00012348999734967947,
      "learning_rate": 1.36219150683953e-06,
      "loss": 0.0,
      "step": 130460
    },
    {
      "epoch": 13.979427836708453,
      "grad_norm": 0.00013995888002682477,
      "learning_rate": 1.3607628843887282e-06,
      "loss": 0.0,
      "step": 130470
    },
    {
      "epoch": 13.980499303546555,
      "grad_norm": 9.52977134147659e-05,
      "learning_rate": 1.3593342619379265e-06,
      "loss": 0.0,
      "step": 130480
    },
    {
      "epoch": 13.981570770384657,
      "grad_norm": 8.745908417040482e-05,
      "learning_rate": 1.3579056394871246e-06,
      "loss": 0.0068,
      "step": 130490
    },
    {
      "epoch": 13.982642237222757,
      "grad_norm": 9.344574937131256e-05,
      "learning_rate": 1.356477017036323e-06,
      "loss": 0.0,
      "step": 130500
    },
    {
      "epoch": 13.98371370406086,
      "grad_norm": 0.0001881103089544922,
      "learning_rate": 1.3550483945855212e-06,
      "loss": 0.0,
      "step": 130510
    },
    {
      "epoch": 13.984785170898961,
      "grad_norm": 8.369093848159537e-05,
      "learning_rate": 1.353619772134719e-06,
      "loss": 0.0,
      "step": 130520
    },
    {
      "epoch": 13.985856637737061,
      "grad_norm": 0.0005380654474720359,
      "learning_rate": 1.3521911496839174e-06,
      "loss": 0.0,
      "step": 130530
    },
    {
      "epoch": 13.986928104575163,
      "grad_norm": 0.00012945497292093933,
      "learning_rate": 1.3507625272331157e-06,
      "loss": 0.0,
      "step": 130540
    },
    {
      "epoch": 13.987999571413265,
      "grad_norm": 0.00011773059668485075,
      "learning_rate": 1.3493339047823136e-06,
      "loss": 0.0,
      "step": 130550
    },
    {
      "epoch": 13.989071038251366,
      "grad_norm": 0.00010063981608254835,
      "learning_rate": 1.347905282331512e-06,
      "loss": 0.0,
      "step": 130560
    },
    {
      "epoch": 13.990142505089468,
      "grad_norm": 0.00010161953832721338,
      "learning_rate": 1.3464766598807102e-06,
      "loss": 0.1513,
      "step": 130570
    },
    {
      "epoch": 13.99121397192757,
      "grad_norm": 0.00011472587357275188,
      "learning_rate": 1.3450480374299083e-06,
      "loss": 0.0,
      "step": 130580
    },
    {
      "epoch": 13.99228543876567,
      "grad_norm": 0.00011667187209241092,
      "learning_rate": 1.3436194149791066e-06,
      "loss": 0.0,
      "step": 130590
    },
    {
      "epoch": 13.993356905603772,
      "grad_norm": 0.0001004062287393026,
      "learning_rate": 1.3421907925283047e-06,
      "loss": 0.0,
      "step": 130600
    },
    {
      "epoch": 13.994428372441872,
      "grad_norm": 0.00013572447642218322,
      "learning_rate": 1.3407621700775028e-06,
      "loss": 0.0003,
      "step": 130610
    },
    {
      "epoch": 13.995499839279974,
      "grad_norm": 0.0001321210147580132,
      "learning_rate": 1.3393335476267011e-06,
      "loss": 0.0,
      "step": 130620
    },
    {
      "epoch": 13.996571306118076,
      "grad_norm": 8.627612987766042e-05,
      "learning_rate": 1.3379049251758994e-06,
      "loss": 0.0,
      "step": 130630
    },
    {
      "epoch": 13.997642772956176,
      "grad_norm": 9.018240962177515e-05,
      "learning_rate": 1.3364763027250973e-06,
      "loss": 0.0,
      "step": 130640
    },
    {
      "epoch": 13.998714239794278,
      "grad_norm": 0.00011772191646741703,
      "learning_rate": 1.3350476802742956e-06,
      "loss": 0.0006,
      "step": 130650
    },
    {
      "epoch": 13.99978570663238,
      "grad_norm": 0.0001239501143572852,
      "learning_rate": 1.333619057823494e-06,
      "loss": 0.0,
      "step": 130660
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9795,
      "eval_f1": 0.918918918918919,
      "eval_loss": 0.20174695551395416,
      "eval_precision": 0.9171052631578948,
      "eval_recall": 0.9207397622192867,
      "eval_runtime": 589.7324,
      "eval_samples_per_second": 10.174,
      "eval_steps_per_second": 3.391,
      "step": 130662
    }
  ],
  "logging_steps": 10,
  "max_steps": 139995,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.318814850160557e+16,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
