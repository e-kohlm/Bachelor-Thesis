{
  "best_metric": 0.9589285714285714,
  "best_model_checkpoint": "../saved_models/xss_20000/checkpoint-2180",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0045871559633027525,
      "grad_norm": 39.33083724975586,
      "learning_rate": 1.9990825688073398e-05,
      "loss": 0.6759,
      "step": 1
    },
    {
      "epoch": 0.045871559633027525,
      "grad_norm": 12.165680885314941,
      "learning_rate": 1.9908256880733945e-05,
      "loss": 0.3634,
      "step": 10
    },
    {
      "epoch": 0.09174311926605505,
      "grad_norm": 22.544357299804688,
      "learning_rate": 1.9816513761467893e-05,
      "loss": 0.3504,
      "step": 20
    },
    {
      "epoch": 0.13761467889908258,
      "grad_norm": 8.841131210327148,
      "learning_rate": 1.9724770642201837e-05,
      "loss": 0.2863,
      "step": 30
    },
    {
      "epoch": 0.1834862385321101,
      "grad_norm": 33.115684509277344,
      "learning_rate": 1.963302752293578e-05,
      "loss": 0.3196,
      "step": 40
    },
    {
      "epoch": 0.22935779816513763,
      "grad_norm": 5.363890647888184,
      "learning_rate": 1.9541284403669728e-05,
      "loss": 0.2812,
      "step": 50
    },
    {
      "epoch": 0.27522935779816515,
      "grad_norm": 5.784350395202637,
      "learning_rate": 1.944954128440367e-05,
      "loss": 0.2683,
      "step": 60
    },
    {
      "epoch": 0.3211009174311927,
      "grad_norm": 5.417497158050537,
      "learning_rate": 1.9357798165137615e-05,
      "loss": 0.2445,
      "step": 70
    },
    {
      "epoch": 0.3669724770642202,
      "grad_norm": 6.775005340576172,
      "learning_rate": 1.9266055045871563e-05,
      "loss": 0.2494,
      "step": 80
    },
    {
      "epoch": 0.41284403669724773,
      "grad_norm": 6.544876575469971,
      "learning_rate": 1.9174311926605506e-05,
      "loss": 0.217,
      "step": 90
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 5.25764799118042,
      "learning_rate": 1.9082568807339454e-05,
      "loss": 0.2477,
      "step": 100
    },
    {
      "epoch": 0.5045871559633027,
      "grad_norm": 5.461574554443359,
      "learning_rate": 1.8990825688073394e-05,
      "loss": 0.2203,
      "step": 110
    },
    {
      "epoch": 0.5504587155963303,
      "grad_norm": 3.8887345790863037,
      "learning_rate": 1.889908256880734e-05,
      "loss": 0.2201,
      "step": 120
    },
    {
      "epoch": 0.5963302752293578,
      "grad_norm": 4.330960273742676,
      "learning_rate": 1.8807339449541285e-05,
      "loss": 0.1714,
      "step": 130
    },
    {
      "epoch": 0.6422018348623854,
      "grad_norm": 4.550745010375977,
      "learning_rate": 1.8715596330275232e-05,
      "loss": 0.1606,
      "step": 140
    },
    {
      "epoch": 0.6880733944954128,
      "grad_norm": 8.549683570861816,
      "learning_rate": 1.8623853211009176e-05,
      "loss": 0.2034,
      "step": 150
    },
    {
      "epoch": 0.7339449541284404,
      "grad_norm": 2.6587605476379395,
      "learning_rate": 1.853211009174312e-05,
      "loss": 0.1837,
      "step": 160
    },
    {
      "epoch": 0.7798165137614679,
      "grad_norm": 3.745560646057129,
      "learning_rate": 1.8440366972477067e-05,
      "loss": 0.1376,
      "step": 170
    },
    {
      "epoch": 0.8256880733944955,
      "grad_norm": 3.6516530513763428,
      "learning_rate": 1.834862385321101e-05,
      "loss": 0.1684,
      "step": 180
    },
    {
      "epoch": 0.8715596330275229,
      "grad_norm": 5.857728004455566,
      "learning_rate": 1.8256880733944955e-05,
      "loss": 0.1597,
      "step": 190
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 2.063873529434204,
      "learning_rate": 1.81651376146789e-05,
      "loss": 0.1486,
      "step": 200
    },
    {
      "epoch": 0.963302752293578,
      "grad_norm": 4.51611852645874,
      "learning_rate": 1.8073394495412846e-05,
      "loss": 0.1458,
      "step": 210
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9493649732620321,
      "eval_f1": 0.6717226435536294,
      "eval_loss": 0.12743736803531647,
      "eval_precision": 0.8806818181818182,
      "eval_recall": 0.542907180385289,
      "eval_runtime": 73.4732,
      "eval_samples_per_second": 81.662,
      "eval_steps_per_second": 2.559,
      "step": 218
    },
    {
      "epoch": 1.0091743119266054,
      "grad_norm": 2.581105947494507,
      "learning_rate": 1.798165137614679e-05,
      "loss": 0.1395,
      "step": 220
    },
    {
      "epoch": 1.0550458715596331,
      "grad_norm": 3.6109261512756348,
      "learning_rate": 1.7889908256880734e-05,
      "loss": 0.1216,
      "step": 230
    },
    {
      "epoch": 1.1009174311926606,
      "grad_norm": 4.555790424346924,
      "learning_rate": 1.779816513761468e-05,
      "loss": 0.1087,
      "step": 240
    },
    {
      "epoch": 1.146788990825688,
      "grad_norm": 5.333306312561035,
      "learning_rate": 1.7706422018348625e-05,
      "loss": 0.112,
      "step": 250
    },
    {
      "epoch": 1.1926605504587156,
      "grad_norm": 5.545262336730957,
      "learning_rate": 1.7614678899082572e-05,
      "loss": 0.1063,
      "step": 260
    },
    {
      "epoch": 1.238532110091743,
      "grad_norm": 3.9861292839050293,
      "learning_rate": 1.7522935779816516e-05,
      "loss": 0.129,
      "step": 270
    },
    {
      "epoch": 1.2844036697247707,
      "grad_norm": 3.711235284805298,
      "learning_rate": 1.743119266055046e-05,
      "loss": 0.1148,
      "step": 280
    },
    {
      "epoch": 1.3302752293577982,
      "grad_norm": 8.452630996704102,
      "learning_rate": 1.7339449541284407e-05,
      "loss": 0.0979,
      "step": 290
    },
    {
      "epoch": 1.3761467889908257,
      "grad_norm": 3.6987802982330322,
      "learning_rate": 1.724770642201835e-05,
      "loss": 0.0958,
      "step": 300
    },
    {
      "epoch": 1.4220183486238533,
      "grad_norm": 4.063821315765381,
      "learning_rate": 1.7155963302752295e-05,
      "loss": 0.0839,
      "step": 310
    },
    {
      "epoch": 1.4678899082568808,
      "grad_norm": 2.5899155139923096,
      "learning_rate": 1.706422018348624e-05,
      "loss": 0.0824,
      "step": 320
    },
    {
      "epoch": 1.5137614678899083,
      "grad_norm": 3.743821382522583,
      "learning_rate": 1.6972477064220186e-05,
      "loss": 0.083,
      "step": 330
    },
    {
      "epoch": 1.5596330275229358,
      "grad_norm": 2.7529876232147217,
      "learning_rate": 1.688073394495413e-05,
      "loss": 0.0712,
      "step": 340
    },
    {
      "epoch": 1.6055045871559632,
      "grad_norm": 3.4200687408447266,
      "learning_rate": 1.6788990825688073e-05,
      "loss": 0.0885,
      "step": 350
    },
    {
      "epoch": 1.6513761467889907,
      "grad_norm": 3.689361333847046,
      "learning_rate": 1.669724770642202e-05,
      "loss": 0.0674,
      "step": 360
    },
    {
      "epoch": 1.6972477064220184,
      "grad_norm": 2.364255666732788,
      "learning_rate": 1.6605504587155964e-05,
      "loss": 0.0794,
      "step": 370
    },
    {
      "epoch": 1.7431192660550459,
      "grad_norm": 1.7685463428497314,
      "learning_rate": 1.6513761467889912e-05,
      "loss": 0.0729,
      "step": 380
    },
    {
      "epoch": 1.7889908256880735,
      "grad_norm": 3.475437641143799,
      "learning_rate": 1.6422018348623852e-05,
      "loss": 0.0525,
      "step": 390
    },
    {
      "epoch": 1.834862385321101,
      "grad_norm": 2.692713737487793,
      "learning_rate": 1.63302752293578e-05,
      "loss": 0.064,
      "step": 400
    },
    {
      "epoch": 1.8807339449541285,
      "grad_norm": 2.6511921882629395,
      "learning_rate": 1.6238532110091743e-05,
      "loss": 0.0621,
      "step": 410
    },
    {
      "epoch": 1.926605504587156,
      "grad_norm": 1.361423134803772,
      "learning_rate": 1.614678899082569e-05,
      "loss": 0.0456,
      "step": 420
    },
    {
      "epoch": 1.9724770642201834,
      "grad_norm": 4.083419322967529,
      "learning_rate": 1.6055045871559634e-05,
      "loss": 0.0584,
      "step": 430
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9710895721925134,
      "eval_f1": 0.8232890704800818,
      "eval_loss": 0.09161684662103653,
      "eval_precision": 0.9877450980392157,
      "eval_recall": 0.7057793345008757,
      "eval_runtime": 69.5222,
      "eval_samples_per_second": 86.303,
      "eval_steps_per_second": 2.704,
      "step": 436
    },
    {
      "epoch": 2.018348623853211,
      "grad_norm": 6.9517130851745605,
      "learning_rate": 1.5963302752293578e-05,
      "loss": 0.072,
      "step": 440
    },
    {
      "epoch": 2.0642201834862384,
      "grad_norm": 3.1788833141326904,
      "learning_rate": 1.5871559633027525e-05,
      "loss": 0.0432,
      "step": 450
    },
    {
      "epoch": 2.1100917431192663,
      "grad_norm": 2.299335479736328,
      "learning_rate": 1.577981651376147e-05,
      "loss": 0.056,
      "step": 460
    },
    {
      "epoch": 2.1559633027522938,
      "grad_norm": 7.631072998046875,
      "learning_rate": 1.5688073394495413e-05,
      "loss": 0.0327,
      "step": 470
    },
    {
      "epoch": 2.2018348623853212,
      "grad_norm": 3.1027212142944336,
      "learning_rate": 1.559633027522936e-05,
      "loss": 0.0543,
      "step": 480
    },
    {
      "epoch": 2.2477064220183487,
      "grad_norm": 2.616420269012451,
      "learning_rate": 1.5504587155963304e-05,
      "loss": 0.0367,
      "step": 490
    },
    {
      "epoch": 2.293577981651376,
      "grad_norm": 6.7857465744018555,
      "learning_rate": 1.541284403669725e-05,
      "loss": 0.0466,
      "step": 500
    },
    {
      "epoch": 2.3394495412844036,
      "grad_norm": 1.315669298171997,
      "learning_rate": 1.5321100917431192e-05,
      "loss": 0.0402,
      "step": 510
    },
    {
      "epoch": 2.385321100917431,
      "grad_norm": 3.6942381858825684,
      "learning_rate": 1.5229357798165139e-05,
      "loss": 0.0572,
      "step": 520
    },
    {
      "epoch": 2.4311926605504586,
      "grad_norm": 2.7474355697631836,
      "learning_rate": 1.5137614678899085e-05,
      "loss": 0.0386,
      "step": 530
    },
    {
      "epoch": 2.477064220183486,
      "grad_norm": 1.5308021306991577,
      "learning_rate": 1.504587155963303e-05,
      "loss": 0.0449,
      "step": 540
    },
    {
      "epoch": 2.522935779816514,
      "grad_norm": 2.097383975982666,
      "learning_rate": 1.4954128440366972e-05,
      "loss": 0.0515,
      "step": 550
    },
    {
      "epoch": 2.5688073394495414,
      "grad_norm": 2.0016350746154785,
      "learning_rate": 1.4862385321100918e-05,
      "loss": 0.0299,
      "step": 560
    },
    {
      "epoch": 2.614678899082569,
      "grad_norm": 1.9364233016967773,
      "learning_rate": 1.4770642201834863e-05,
      "loss": 0.0311,
      "step": 570
    },
    {
      "epoch": 2.6605504587155964,
      "grad_norm": 2.4345335960388184,
      "learning_rate": 1.4678899082568809e-05,
      "loss": 0.0318,
      "step": 580
    },
    {
      "epoch": 2.706422018348624,
      "grad_norm": 3.4649741649627686,
      "learning_rate": 1.4587155963302753e-05,
      "loss": 0.0417,
      "step": 590
    },
    {
      "epoch": 2.7522935779816513,
      "grad_norm": 1.945937156677246,
      "learning_rate": 1.4495412844036698e-05,
      "loss": 0.0234,
      "step": 600
    },
    {
      "epoch": 2.7981651376146788,
      "grad_norm": 1.2842192649841309,
      "learning_rate": 1.4403669724770644e-05,
      "loss": 0.0273,
      "step": 610
    },
    {
      "epoch": 2.8440366972477067,
      "grad_norm": 0.5765545964241028,
      "learning_rate": 1.431192660550459e-05,
      "loss": 0.0432,
      "step": 620
    },
    {
      "epoch": 2.8899082568807337,
      "grad_norm": 2.3568036556243896,
      "learning_rate": 1.4220183486238533e-05,
      "loss": 0.0383,
      "step": 630
    },
    {
      "epoch": 2.9357798165137616,
      "grad_norm": 3.8244965076446533,
      "learning_rate": 1.4128440366972477e-05,
      "loss": 0.0506,
      "step": 640
    },
    {
      "epoch": 2.981651376146789,
      "grad_norm": 1.9051024913787842,
      "learning_rate": 1.4036697247706423e-05,
      "loss": 0.0442,
      "step": 650
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.984792780748663,
      "eval_f1": 0.921619293712317,
      "eval_loss": 0.039789289236068726,
      "eval_precision": 0.9067796610169492,
      "eval_recall": 0.9369527145359019,
      "eval_runtime": 70.8973,
      "eval_samples_per_second": 84.629,
      "eval_steps_per_second": 2.652,
      "step": 654
    },
    {
      "epoch": 3.0275229357798166,
      "grad_norm": 2.053915500640869,
      "learning_rate": 1.3944954128440368e-05,
      "loss": 0.0316,
      "step": 660
    },
    {
      "epoch": 3.073394495412844,
      "grad_norm": 2.453355073928833,
      "learning_rate": 1.3853211009174312e-05,
      "loss": 0.0169,
      "step": 670
    },
    {
      "epoch": 3.1192660550458715,
      "grad_norm": 0.7952638864517212,
      "learning_rate": 1.3761467889908258e-05,
      "loss": 0.0268,
      "step": 680
    },
    {
      "epoch": 3.165137614678899,
      "grad_norm": 1.8123831748962402,
      "learning_rate": 1.3669724770642203e-05,
      "loss": 0.0375,
      "step": 690
    },
    {
      "epoch": 3.2110091743119265,
      "grad_norm": 0.07808741182088852,
      "learning_rate": 1.3577981651376149e-05,
      "loss": 0.0236,
      "step": 700
    },
    {
      "epoch": 3.2568807339449544,
      "grad_norm": 1.6905971765518188,
      "learning_rate": 1.3486238532110092e-05,
      "loss": 0.0232,
      "step": 710
    },
    {
      "epoch": 3.302752293577982,
      "grad_norm": 1.6249005794525146,
      "learning_rate": 1.3394495412844038e-05,
      "loss": 0.0221,
      "step": 720
    },
    {
      "epoch": 3.3486238532110093,
      "grad_norm": 0.522628903388977,
      "learning_rate": 1.3302752293577984e-05,
      "loss": 0.0285,
      "step": 730
    },
    {
      "epoch": 3.3944954128440368,
      "grad_norm": 1.3810418844223022,
      "learning_rate": 1.3211009174311929e-05,
      "loss": 0.0236,
      "step": 740
    },
    {
      "epoch": 3.4403669724770642,
      "grad_norm": 1.686134934425354,
      "learning_rate": 1.3119266055045871e-05,
      "loss": 0.0402,
      "step": 750
    },
    {
      "epoch": 3.4862385321100917,
      "grad_norm": 2.590010166168213,
      "learning_rate": 1.3027522935779817e-05,
      "loss": 0.0305,
      "step": 760
    },
    {
      "epoch": 3.532110091743119,
      "grad_norm": 1.3720479011535645,
      "learning_rate": 1.2935779816513762e-05,
      "loss": 0.0298,
      "step": 770
    },
    {
      "epoch": 3.5779816513761467,
      "grad_norm": 1.0058971643447876,
      "learning_rate": 1.2844036697247708e-05,
      "loss": 0.0218,
      "step": 780
    },
    {
      "epoch": 3.623853211009174,
      "grad_norm": 0.7500117421150208,
      "learning_rate": 1.2752293577981652e-05,
      "loss": 0.0179,
      "step": 790
    },
    {
      "epoch": 3.669724770642202,
      "grad_norm": 1.0714106559753418,
      "learning_rate": 1.2660550458715597e-05,
      "loss": 0.0236,
      "step": 800
    },
    {
      "epoch": 3.7155963302752295,
      "grad_norm": 5.113437175750732,
      "learning_rate": 1.2568807339449543e-05,
      "loss": 0.0328,
      "step": 810
    },
    {
      "epoch": 3.761467889908257,
      "grad_norm": 1.2296675443649292,
      "learning_rate": 1.2477064220183488e-05,
      "loss": 0.0244,
      "step": 820
    },
    {
      "epoch": 3.8073394495412844,
      "grad_norm": 0.21570052206516266,
      "learning_rate": 1.238532110091743e-05,
      "loss": 0.0212,
      "step": 830
    },
    {
      "epoch": 3.853211009174312,
      "grad_norm": 3.939201593399048,
      "learning_rate": 1.2293577981651376e-05,
      "loss": 0.0288,
      "step": 840
    },
    {
      "epoch": 3.8990825688073394,
      "grad_norm": 3.793339252471924,
      "learning_rate": 1.2201834862385321e-05,
      "loss": 0.0394,
      "step": 850
    },
    {
      "epoch": 3.944954128440367,
      "grad_norm": 5.0458221435546875,
      "learning_rate": 1.2110091743119267e-05,
      "loss": 0.0328,
      "step": 860
    },
    {
      "epoch": 3.9908256880733948,
      "grad_norm": 0.17469413578510284,
      "learning_rate": 1.2018348623853211e-05,
      "loss": 0.0355,
      "step": 870
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9876336898395722,
      "eval_f1": 0.9319852941176471,
      "eval_loss": 0.035343483090400696,
      "eval_precision": 0.9806576402321083,
      "eval_recall": 0.8879159369527145,
      "eval_runtime": 70.3491,
      "eval_samples_per_second": 85.289,
      "eval_steps_per_second": 2.672,
      "step": 872
    },
    {
      "epoch": 4.036697247706422,
      "grad_norm": 3.0996549129486084,
      "learning_rate": 1.1926605504587156e-05,
      "loss": 0.0225,
      "step": 880
    },
    {
      "epoch": 4.08256880733945,
      "grad_norm": 2.1752023696899414,
      "learning_rate": 1.1834862385321102e-05,
      "loss": 0.01,
      "step": 890
    },
    {
      "epoch": 4.128440366972477,
      "grad_norm": 0.7447885870933533,
      "learning_rate": 1.1743119266055047e-05,
      "loss": 0.0125,
      "step": 900
    },
    {
      "epoch": 4.174311926605505,
      "grad_norm": 1.4207080602645874,
      "learning_rate": 1.1651376146788991e-05,
      "loss": 0.014,
      "step": 910
    },
    {
      "epoch": 4.220183486238533,
      "grad_norm": 1.160989761352539,
      "learning_rate": 1.1559633027522937e-05,
      "loss": 0.0089,
      "step": 920
    },
    {
      "epoch": 4.26605504587156,
      "grad_norm": 1.3973199129104614,
      "learning_rate": 1.1467889908256882e-05,
      "loss": 0.0209,
      "step": 930
    },
    {
      "epoch": 4.3119266055045875,
      "grad_norm": 3.0314269065856934,
      "learning_rate": 1.1376146788990828e-05,
      "loss": 0.0329,
      "step": 940
    },
    {
      "epoch": 4.3577981651376145,
      "grad_norm": 2.735502243041992,
      "learning_rate": 1.128440366972477e-05,
      "loss": 0.0134,
      "step": 950
    },
    {
      "epoch": 4.4036697247706424,
      "grad_norm": 0.5312979817390442,
      "learning_rate": 1.1192660550458716e-05,
      "loss": 0.0141,
      "step": 960
    },
    {
      "epoch": 4.4495412844036695,
      "grad_norm": 0.499255895614624,
      "learning_rate": 1.1100917431192661e-05,
      "loss": 0.0137,
      "step": 970
    },
    {
      "epoch": 4.495412844036697,
      "grad_norm": 5.289927005767822,
      "learning_rate": 1.1009174311926607e-05,
      "loss": 0.0268,
      "step": 980
    },
    {
      "epoch": 4.541284403669724,
      "grad_norm": 1.789269208908081,
      "learning_rate": 1.091743119266055e-05,
      "loss": 0.0144,
      "step": 990
    },
    {
      "epoch": 4.587155963302752,
      "grad_norm": 2.189891815185547,
      "learning_rate": 1.0825688073394496e-05,
      "loss": 0.0176,
      "step": 1000
    },
    {
      "epoch": 4.63302752293578,
      "grad_norm": 0.4758739471435547,
      "learning_rate": 1.0733944954128442e-05,
      "loss": 0.0183,
      "step": 1010
    },
    {
      "epoch": 4.678899082568807,
      "grad_norm": 1.0646533966064453,
      "learning_rate": 1.0642201834862387e-05,
      "loss": 0.0281,
      "step": 1020
    },
    {
      "epoch": 4.724770642201835,
      "grad_norm": 0.8570214509963989,
      "learning_rate": 1.055045871559633e-05,
      "loss": 0.0171,
      "step": 1030
    },
    {
      "epoch": 4.770642201834862,
      "grad_norm": 2.9479596614837646,
      "learning_rate": 1.0458715596330275e-05,
      "loss": 0.0218,
      "step": 1040
    },
    {
      "epoch": 4.81651376146789,
      "grad_norm": 3.6791458129882812,
      "learning_rate": 1.036697247706422e-05,
      "loss": 0.0303,
      "step": 1050
    },
    {
      "epoch": 4.862385321100917,
      "grad_norm": 1.512947678565979,
      "learning_rate": 1.0275229357798166e-05,
      "loss": 0.0121,
      "step": 1060
    },
    {
      "epoch": 4.908256880733945,
      "grad_norm": 1.6955760717391968,
      "learning_rate": 1.018348623853211e-05,
      "loss": 0.0254,
      "step": 1070
    },
    {
      "epoch": 4.954128440366972,
      "grad_norm": 1.3680882453918457,
      "learning_rate": 1.0091743119266055e-05,
      "loss": 0.0184,
      "step": 1080
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.9061307907104492,
      "learning_rate": 1e-05,
      "loss": 0.0261,
      "step": 1090
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9871323529411765,
      "eval_f1": 0.9340188517566409,
      "eval_loss": 0.03829898312687874,
      "eval_precision": 0.9144295302013423,
      "eval_recall": 0.9544658493870403,
      "eval_runtime": 69.1081,
      "eval_samples_per_second": 86.821,
      "eval_steps_per_second": 2.72,
      "step": 1090
    },
    {
      "epoch": 5.045871559633028,
      "grad_norm": 0.5141751766204834,
      "learning_rate": 9.908256880733946e-06,
      "loss": 0.0126,
      "step": 1100
    },
    {
      "epoch": 5.091743119266055,
      "grad_norm": 1.0183547735214233,
      "learning_rate": 9.81651376146789e-06,
      "loss": 0.0189,
      "step": 1110
    },
    {
      "epoch": 5.137614678899083,
      "grad_norm": 0.49908527731895447,
      "learning_rate": 9.724770642201836e-06,
      "loss": 0.0128,
      "step": 1120
    },
    {
      "epoch": 5.18348623853211,
      "grad_norm": 1.342716097831726,
      "learning_rate": 9.633027522935781e-06,
      "loss": 0.0114,
      "step": 1130
    },
    {
      "epoch": 5.229357798165138,
      "grad_norm": 0.11558928340673447,
      "learning_rate": 9.541284403669727e-06,
      "loss": 0.0155,
      "step": 1140
    },
    {
      "epoch": 5.275229357798165,
      "grad_norm": 2.5559616088867188,
      "learning_rate": 9.44954128440367e-06,
      "loss": 0.0189,
      "step": 1150
    },
    {
      "epoch": 5.321100917431193,
      "grad_norm": 1.5667428970336914,
      "learning_rate": 9.357798165137616e-06,
      "loss": 0.017,
      "step": 1160
    },
    {
      "epoch": 5.36697247706422,
      "grad_norm": 1.0296231508255005,
      "learning_rate": 9.26605504587156e-06,
      "loss": 0.0147,
      "step": 1170
    },
    {
      "epoch": 5.412844036697248,
      "grad_norm": 1.9263877868652344,
      "learning_rate": 9.174311926605506e-06,
      "loss": 0.0223,
      "step": 1180
    },
    {
      "epoch": 5.458715596330276,
      "grad_norm": 2.100658655166626,
      "learning_rate": 9.08256880733945e-06,
      "loss": 0.0165,
      "step": 1190
    },
    {
      "epoch": 5.504587155963303,
      "grad_norm": 2.389707565307617,
      "learning_rate": 8.990825688073395e-06,
      "loss": 0.0174,
      "step": 1200
    },
    {
      "epoch": 5.5504587155963305,
      "grad_norm": 0.3097780644893646,
      "learning_rate": 8.89908256880734e-06,
      "loss": 0.0142,
      "step": 1210
    },
    {
      "epoch": 5.5963302752293576,
      "grad_norm": 0.5990757942199707,
      "learning_rate": 8.807339449541286e-06,
      "loss": 0.0233,
      "step": 1220
    },
    {
      "epoch": 5.6422018348623855,
      "grad_norm": 1.7329866886138916,
      "learning_rate": 8.71559633027523e-06,
      "loss": 0.0119,
      "step": 1230
    },
    {
      "epoch": 5.6880733944954125,
      "grad_norm": 0.04774319380521774,
      "learning_rate": 8.623853211009175e-06,
      "loss": 0.0159,
      "step": 1240
    },
    {
      "epoch": 5.73394495412844,
      "grad_norm": 0.2808407247066498,
      "learning_rate": 8.53211009174312e-06,
      "loss": 0.0127,
      "step": 1250
    },
    {
      "epoch": 5.779816513761467,
      "grad_norm": 0.8001452088356018,
      "learning_rate": 8.440366972477065e-06,
      "loss": 0.0117,
      "step": 1260
    },
    {
      "epoch": 5.825688073394495,
      "grad_norm": 1.7880263328552246,
      "learning_rate": 8.34862385321101e-06,
      "loss": 0.0139,
      "step": 1270
    },
    {
      "epoch": 5.871559633027523,
      "grad_norm": 1.8432024717330933,
      "learning_rate": 8.256880733944956e-06,
      "loss": 0.0072,
      "step": 1280
    },
    {
      "epoch": 5.91743119266055,
      "grad_norm": 2.3398571014404297,
      "learning_rate": 8.1651376146789e-06,
      "loss": 0.026,
      "step": 1290
    },
    {
      "epoch": 5.963302752293578,
      "grad_norm": 2.6108570098876953,
      "learning_rate": 8.073394495412845e-06,
      "loss": 0.0153,
      "step": 1300
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9906417112299465,
      "eval_f1": 0.9507908611599296,
      "eval_loss": 0.030399521812796593,
      "eval_precision": 0.9541446208112875,
      "eval_recall": 0.9474605954465849,
      "eval_runtime": 70.4428,
      "eval_samples_per_second": 85.176,
      "eval_steps_per_second": 2.669,
      "step": 1308
    },
    {
      "epoch": 6.009174311926605,
      "grad_norm": 1.548058032989502,
      "learning_rate": 7.981651376146789e-06,
      "loss": 0.0167,
      "step": 1310
    },
    {
      "epoch": 6.055045871559633,
      "grad_norm": 2.1366708278656006,
      "learning_rate": 7.889908256880735e-06,
      "loss": 0.0083,
      "step": 1320
    },
    {
      "epoch": 6.10091743119266,
      "grad_norm": 0.882915198802948,
      "learning_rate": 7.79816513761468e-06,
      "loss": 0.0082,
      "step": 1330
    },
    {
      "epoch": 6.146788990825688,
      "grad_norm": 4.896032333374023,
      "learning_rate": 7.706422018348626e-06,
      "loss": 0.0056,
      "step": 1340
    },
    {
      "epoch": 6.192660550458716,
      "grad_norm": 0.14779740571975708,
      "learning_rate": 7.6146788990825695e-06,
      "loss": 0.0085,
      "step": 1350
    },
    {
      "epoch": 6.238532110091743,
      "grad_norm": 1.608376383781433,
      "learning_rate": 7.522935779816515e-06,
      "loss": 0.0191,
      "step": 1360
    },
    {
      "epoch": 6.284403669724771,
      "grad_norm": 0.22718393802642822,
      "learning_rate": 7.431192660550459e-06,
      "loss": 0.0107,
      "step": 1370
    },
    {
      "epoch": 6.330275229357798,
      "grad_norm": 1.230259656906128,
      "learning_rate": 7.3394495412844045e-06,
      "loss": 0.0061,
      "step": 1380
    },
    {
      "epoch": 6.376146788990826,
      "grad_norm": 0.08819787204265594,
      "learning_rate": 7.247706422018349e-06,
      "loss": 0.0047,
      "step": 1390
    },
    {
      "epoch": 6.422018348623853,
      "grad_norm": 0.02825840935111046,
      "learning_rate": 7.155963302752295e-06,
      "loss": 0.0124,
      "step": 1400
    },
    {
      "epoch": 6.467889908256881,
      "grad_norm": 0.29146334528923035,
      "learning_rate": 7.0642201834862385e-06,
      "loss": 0.0104,
      "step": 1410
    },
    {
      "epoch": 6.513761467889909,
      "grad_norm": 0.6663784980773926,
      "learning_rate": 6.972477064220184e-06,
      "loss": 0.0105,
      "step": 1420
    },
    {
      "epoch": 6.559633027522936,
      "grad_norm": 1.0377203226089478,
      "learning_rate": 6.880733944954129e-06,
      "loss": 0.0089,
      "step": 1430
    },
    {
      "epoch": 6.605504587155964,
      "grad_norm": 0.03381093218922615,
      "learning_rate": 6.788990825688074e-06,
      "loss": 0.0102,
      "step": 1440
    },
    {
      "epoch": 6.651376146788991,
      "grad_norm": 1.259756326675415,
      "learning_rate": 6.697247706422019e-06,
      "loss": 0.0148,
      "step": 1450
    },
    {
      "epoch": 6.697247706422019,
      "grad_norm": 0.5761376023292542,
      "learning_rate": 6.6055045871559645e-06,
      "loss": 0.01,
      "step": 1460
    },
    {
      "epoch": 6.743119266055046,
      "grad_norm": 2.6269538402557373,
      "learning_rate": 6.513761467889908e-06,
      "loss": 0.0107,
      "step": 1470
    },
    {
      "epoch": 6.7889908256880735,
      "grad_norm": 0.656464695930481,
      "learning_rate": 6.422018348623854e-06,
      "loss": 0.0139,
      "step": 1480
    },
    {
      "epoch": 6.834862385321101,
      "grad_norm": 1.2636029720306396,
      "learning_rate": 6.330275229357799e-06,
      "loss": 0.0062,
      "step": 1490
    },
    {
      "epoch": 6.8807339449541285,
      "grad_norm": 1.5380324125289917,
      "learning_rate": 6.238532110091744e-06,
      "loss": 0.011,
      "step": 1500
    },
    {
      "epoch": 6.926605504587156,
      "grad_norm": 0.4382280111312866,
      "learning_rate": 6.146788990825688e-06,
      "loss": 0.0086,
      "step": 1510
    },
    {
      "epoch": 6.972477064220183,
      "grad_norm": 1.196585774421692,
      "learning_rate": 6.0550458715596335e-06,
      "loss": 0.0057,
      "step": 1520
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9921457219251337,
      "eval_f1": 0.9582222222222223,
      "eval_loss": 0.0290644820779562,
      "eval_precision": 0.9729241877256317,
      "eval_recall": 0.9439579684763573,
      "eval_runtime": 71.8841,
      "eval_samples_per_second": 83.468,
      "eval_steps_per_second": 2.615,
      "step": 1526
    },
    {
      "epoch": 7.018348623853211,
      "grad_norm": 1.5178618431091309,
      "learning_rate": 5.963302752293578e-06,
      "loss": 0.0096,
      "step": 1530
    },
    {
      "epoch": 7.064220183486238,
      "grad_norm": 1.4593493938446045,
      "learning_rate": 5.871559633027524e-06,
      "loss": 0.0071,
      "step": 1540
    },
    {
      "epoch": 7.110091743119266,
      "grad_norm": 0.4695064425468445,
      "learning_rate": 5.7798165137614684e-06,
      "loss": 0.0039,
      "step": 1550
    },
    {
      "epoch": 7.155963302752293,
      "grad_norm": 0.01893235556781292,
      "learning_rate": 5.688073394495414e-06,
      "loss": 0.0096,
      "step": 1560
    },
    {
      "epoch": 7.201834862385321,
      "grad_norm": 0.3105333745479584,
      "learning_rate": 5.596330275229358e-06,
      "loss": 0.0113,
      "step": 1570
    },
    {
      "epoch": 7.247706422018348,
      "grad_norm": 1.2961903810501099,
      "learning_rate": 5.504587155963303e-06,
      "loss": 0.0213,
      "step": 1580
    },
    {
      "epoch": 7.293577981651376,
      "grad_norm": 0.047522228211164474,
      "learning_rate": 5.412844036697248e-06,
      "loss": 0.0114,
      "step": 1590
    },
    {
      "epoch": 7.339449541284404,
      "grad_norm": 1.2770757675170898,
      "learning_rate": 5.3211009174311936e-06,
      "loss": 0.0051,
      "step": 1600
    },
    {
      "epoch": 7.385321100917431,
      "grad_norm": 0.24789126217365265,
      "learning_rate": 5.229357798165137e-06,
      "loss": 0.0101,
      "step": 1610
    },
    {
      "epoch": 7.431192660550459,
      "grad_norm": 0.1670876443386078,
      "learning_rate": 5.137614678899083e-06,
      "loss": 0.0098,
      "step": 1620
    },
    {
      "epoch": 7.477064220183486,
      "grad_norm": 0.41662752628326416,
      "learning_rate": 5.045871559633028e-06,
      "loss": 0.0077,
      "step": 1630
    },
    {
      "epoch": 7.522935779816514,
      "grad_norm": 0.7579917907714844,
      "learning_rate": 4.954128440366973e-06,
      "loss": 0.0149,
      "step": 1640
    },
    {
      "epoch": 7.568807339449541,
      "grad_norm": 0.42289432883262634,
      "learning_rate": 4.862385321100918e-06,
      "loss": 0.0106,
      "step": 1650
    },
    {
      "epoch": 7.614678899082569,
      "grad_norm": 0.026725633069872856,
      "learning_rate": 4.770642201834863e-06,
      "loss": 0.0042,
      "step": 1660
    },
    {
      "epoch": 7.660550458715596,
      "grad_norm": 3.45890212059021,
      "learning_rate": 4.678899082568808e-06,
      "loss": 0.0117,
      "step": 1670
    },
    {
      "epoch": 7.706422018348624,
      "grad_norm": 0.24580705165863037,
      "learning_rate": 4.587155963302753e-06,
      "loss": 0.0136,
      "step": 1680
    },
    {
      "epoch": 7.752293577981652,
      "grad_norm": 0.11340556293725967,
      "learning_rate": 4.4954128440366975e-06,
      "loss": 0.005,
      "step": 1690
    },
    {
      "epoch": 7.798165137614679,
      "grad_norm": 0.12667332589626312,
      "learning_rate": 4.403669724770643e-06,
      "loss": 0.0086,
      "step": 1700
    },
    {
      "epoch": 7.844036697247707,
      "grad_norm": 0.020224900916218758,
      "learning_rate": 4.311926605504588e-06,
      "loss": 0.0076,
      "step": 1710
    },
    {
      "epoch": 7.889908256880734,
      "grad_norm": 0.09943689405918121,
      "learning_rate": 4.220183486238532e-06,
      "loss": 0.0102,
      "step": 1720
    },
    {
      "epoch": 7.935779816513762,
      "grad_norm": 1.5883656740188599,
      "learning_rate": 4.128440366972478e-06,
      "loss": 0.0109,
      "step": 1730
    },
    {
      "epoch": 7.981651376146789,
      "grad_norm": 1.2212544679641724,
      "learning_rate": 4.036697247706423e-06,
      "loss": 0.0075,
      "step": 1740
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9918114973262032,
      "eval_f1": 0.9561324977618622,
      "eval_loss": 0.027307480573654175,
      "eval_precision": 0.978021978021978,
      "eval_recall": 0.9352014010507881,
      "eval_runtime": 70.5287,
      "eval_samples_per_second": 85.072,
      "eval_steps_per_second": 2.666,
      "step": 1744
    },
    {
      "epoch": 8.027522935779816,
      "grad_norm": 0.1114778146147728,
      "learning_rate": 3.944954128440367e-06,
      "loss": 0.0096,
      "step": 1750
    },
    {
      "epoch": 8.073394495412844,
      "grad_norm": 0.060192618519067764,
      "learning_rate": 3.853211009174313e-06,
      "loss": 0.0016,
      "step": 1760
    },
    {
      "epoch": 8.119266055045872,
      "grad_norm": 3.1706230640411377,
      "learning_rate": 3.7614678899082575e-06,
      "loss": 0.008,
      "step": 1770
    },
    {
      "epoch": 8.1651376146789,
      "grad_norm": 0.7993589639663696,
      "learning_rate": 3.6697247706422022e-06,
      "loss": 0.0084,
      "step": 1780
    },
    {
      "epoch": 8.211009174311927,
      "grad_norm": 0.040677815675735474,
      "learning_rate": 3.5779816513761473e-06,
      "loss": 0.0064,
      "step": 1790
    },
    {
      "epoch": 8.256880733944953,
      "grad_norm": 0.7585932016372681,
      "learning_rate": 3.486238532110092e-06,
      "loss": 0.0053,
      "step": 1800
    },
    {
      "epoch": 8.302752293577981,
      "grad_norm": 2.3862740993499756,
      "learning_rate": 3.394495412844037e-06,
      "loss": 0.0039,
      "step": 1810
    },
    {
      "epoch": 8.34862385321101,
      "grad_norm": 2.270658493041992,
      "learning_rate": 3.3027522935779823e-06,
      "loss": 0.0107,
      "step": 1820
    },
    {
      "epoch": 8.394495412844037,
      "grad_norm": 0.2664090096950531,
      "learning_rate": 3.211009174311927e-06,
      "loss": 0.0077,
      "step": 1830
    },
    {
      "epoch": 8.440366972477065,
      "grad_norm": 0.07752574980258942,
      "learning_rate": 3.119266055045872e-06,
      "loss": 0.0051,
      "step": 1840
    },
    {
      "epoch": 8.486238532110091,
      "grad_norm": 2.4098849296569824,
      "learning_rate": 3.0275229357798168e-06,
      "loss": 0.0084,
      "step": 1850
    },
    {
      "epoch": 8.53211009174312,
      "grad_norm": 1.8057539463043213,
      "learning_rate": 2.935779816513762e-06,
      "loss": 0.0126,
      "step": 1860
    },
    {
      "epoch": 8.577981651376147,
      "grad_norm": 3.7644429206848145,
      "learning_rate": 2.844036697247707e-06,
      "loss": 0.0085,
      "step": 1870
    },
    {
      "epoch": 8.623853211009175,
      "grad_norm": 1.2660528421401978,
      "learning_rate": 2.7522935779816517e-06,
      "loss": 0.0095,
      "step": 1880
    },
    {
      "epoch": 8.669724770642201,
      "grad_norm": 0.9818743467330933,
      "learning_rate": 2.6605504587155968e-06,
      "loss": 0.0097,
      "step": 1890
    },
    {
      "epoch": 8.715596330275229,
      "grad_norm": 0.019892146810889244,
      "learning_rate": 2.5688073394495415e-06,
      "loss": 0.0081,
      "step": 1900
    },
    {
      "epoch": 8.761467889908257,
      "grad_norm": 0.3700783848762512,
      "learning_rate": 2.4770642201834866e-06,
      "loss": 0.0077,
      "step": 1910
    },
    {
      "epoch": 8.807339449541285,
      "grad_norm": 0.13744962215423584,
      "learning_rate": 2.3853211009174317e-06,
      "loss": 0.0047,
      "step": 1920
    },
    {
      "epoch": 8.853211009174313,
      "grad_norm": 1.357177495956421,
      "learning_rate": 2.2935779816513764e-06,
      "loss": 0.0033,
      "step": 1930
    },
    {
      "epoch": 8.899082568807339,
      "grad_norm": 1.4238430261611938,
      "learning_rate": 2.2018348623853215e-06,
      "loss": 0.0101,
      "step": 1940
    },
    {
      "epoch": 8.944954128440367,
      "grad_norm": 0.5894904732704163,
      "learning_rate": 2.110091743119266e-06,
      "loss": 0.0028,
      "step": 1950
    },
    {
      "epoch": 8.990825688073395,
      "grad_norm": 2.6629679203033447,
      "learning_rate": 2.0183486238532113e-06,
      "loss": 0.0138,
      "step": 1960
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9921457219251337,
      "eval_f1": 0.9584438549955792,
      "eval_loss": 0.028789162635803223,
      "eval_precision": 0.9678571428571429,
      "eval_recall": 0.9492119089316988,
      "eval_runtime": 68.1503,
      "eval_samples_per_second": 88.041,
      "eval_steps_per_second": 2.759,
      "step": 1962
    },
    {
      "epoch": 9.036697247706423,
      "grad_norm": 1.6401386260986328,
      "learning_rate": 1.9266055045871564e-06,
      "loss": 0.0046,
      "step": 1970
    },
    {
      "epoch": 9.082568807339449,
      "grad_norm": 0.6083863377571106,
      "learning_rate": 1.8348623853211011e-06,
      "loss": 0.0074,
      "step": 1980
    },
    {
      "epoch": 9.128440366972477,
      "grad_norm": 3.1577374935150146,
      "learning_rate": 1.743119266055046e-06,
      "loss": 0.0066,
      "step": 1990
    },
    {
      "epoch": 9.174311926605505,
      "grad_norm": 0.25315484404563904,
      "learning_rate": 1.6513761467889911e-06,
      "loss": 0.0031,
      "step": 2000
    },
    {
      "epoch": 9.220183486238533,
      "grad_norm": 0.00992482528090477,
      "learning_rate": 1.559633027522936e-06,
      "loss": 0.0071,
      "step": 2010
    },
    {
      "epoch": 9.26605504587156,
      "grad_norm": 1.4962931871414185,
      "learning_rate": 1.467889908256881e-06,
      "loss": 0.0056,
      "step": 2020
    },
    {
      "epoch": 9.311926605504587,
      "grad_norm": 0.16733135282993317,
      "learning_rate": 1.3761467889908258e-06,
      "loss": 0.0069,
      "step": 2030
    },
    {
      "epoch": 9.357798165137615,
      "grad_norm": 1.0740220546722412,
      "learning_rate": 1.2844036697247707e-06,
      "loss": 0.0113,
      "step": 2040
    },
    {
      "epoch": 9.403669724770642,
      "grad_norm": 0.5075809955596924,
      "learning_rate": 1.1926605504587159e-06,
      "loss": 0.008,
      "step": 2050
    },
    {
      "epoch": 9.44954128440367,
      "grad_norm": 0.5617335438728333,
      "learning_rate": 1.1009174311926608e-06,
      "loss": 0.0068,
      "step": 2060
    },
    {
      "epoch": 9.495412844036696,
      "grad_norm": 0.763378918170929,
      "learning_rate": 1.0091743119266057e-06,
      "loss": 0.0063,
      "step": 2070
    },
    {
      "epoch": 9.541284403669724,
      "grad_norm": 0.13851584494113922,
      "learning_rate": 9.174311926605506e-07,
      "loss": 0.0069,
      "step": 2080
    },
    {
      "epoch": 9.587155963302752,
      "grad_norm": 2.288036346435547,
      "learning_rate": 8.256880733944956e-07,
      "loss": 0.0109,
      "step": 2090
    },
    {
      "epoch": 9.63302752293578,
      "grad_norm": 0.8570536375045776,
      "learning_rate": 7.339449541284405e-07,
      "loss": 0.0026,
      "step": 2100
    },
    {
      "epoch": 9.678899082568808,
      "grad_norm": 0.5174475312232971,
      "learning_rate": 6.422018348623854e-07,
      "loss": 0.0054,
      "step": 2110
    },
    {
      "epoch": 9.724770642201834,
      "grad_norm": 0.7411878705024719,
      "learning_rate": 5.504587155963304e-07,
      "loss": 0.0048,
      "step": 2120
    },
    {
      "epoch": 9.770642201834862,
      "grad_norm": 0.2737652659416199,
      "learning_rate": 4.587155963302753e-07,
      "loss": 0.0046,
      "step": 2130
    },
    {
      "epoch": 9.81651376146789,
      "grad_norm": 1.0671396255493164,
      "learning_rate": 3.6697247706422023e-07,
      "loss": 0.0062,
      "step": 2140
    },
    {
      "epoch": 9.862385321100918,
      "grad_norm": 1.7737425565719604,
      "learning_rate": 2.752293577981652e-07,
      "loss": 0.0113,
      "step": 2150
    },
    {
      "epoch": 9.908256880733944,
      "grad_norm": 0.7235888838768005,
      "learning_rate": 1.8348623853211012e-07,
      "loss": 0.0048,
      "step": 2160
    },
    {
      "epoch": 9.954128440366972,
      "grad_norm": 1.3409563302993774,
      "learning_rate": 9.174311926605506e-08,
      "loss": 0.0026,
      "step": 2170
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.15663903951644897,
      "learning_rate": 0.0,
      "loss": 0.004,
      "step": 2180
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9923128342245989,
      "eval_f1": 0.9589285714285714,
      "eval_loss": 0.030183080583810806,
      "eval_precision": 0.9781420765027322,
      "eval_recall": 0.9404553415061296,
      "eval_runtime": 75.2072,
      "eval_samples_per_second": 79.78,
      "eval_steps_per_second": 2.5,
      "step": 2180
    }
  ],
  "logging_steps": 10,
  "max_steps": 2180,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.290574669536256e+16,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
