{
  "best_metric": 0.9602327837051406,
  "best_model_checkpoint": "../saved_models/remote_code_execution_40000/checkpoint-14000",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 14000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005714285714285715,
      "grad_norm": 76.87299346923828,
      "learning_rate": 1.9998857142857143e-05,
      "loss": 0.6657,
      "step": 1
    },
    {
      "epoch": 0.005714285714285714,
      "grad_norm": 18.14280891418457,
      "learning_rate": 1.9988571428571432e-05,
      "loss": 0.4013,
      "step": 10
    },
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 0.7548051476478577,
      "learning_rate": 1.997714285714286e-05,
      "loss": 0.22,
      "step": 20
    },
    {
      "epoch": 0.017142857142857144,
      "grad_norm": 28.359867095947266,
      "learning_rate": 1.996571428571429e-05,
      "loss": 0.7036,
      "step": 30
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 25.256196975708008,
      "learning_rate": 1.9954285714285715e-05,
      "loss": 0.414,
      "step": 40
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 17.554439544677734,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 0.3818,
      "step": 50
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 15.665655136108398,
      "learning_rate": 1.9931428571428572e-05,
      "loss": 0.3938,
      "step": 60
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.278337478637695,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.3453,
      "step": 70
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 2.790323257446289,
      "learning_rate": 1.990857142857143e-05,
      "loss": 0.251,
      "step": 80
    },
    {
      "epoch": 0.05142857142857143,
      "grad_norm": 22.34389877319336,
      "learning_rate": 1.989714285714286e-05,
      "loss": 0.4751,
      "step": 90
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 3.307598114013672,
      "learning_rate": 1.988571428571429e-05,
      "loss": 0.3434,
      "step": 100
    },
    {
      "epoch": 0.06285714285714286,
      "grad_norm": 2.799938917160034,
      "learning_rate": 1.9874285714285716e-05,
      "loss": 0.2871,
      "step": 110
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 16.131132125854492,
      "learning_rate": 1.9862857142857143e-05,
      "loss": 0.4969,
      "step": 120
    },
    {
      "epoch": 0.07428571428571429,
      "grad_norm": 10.734574317932129,
      "learning_rate": 1.9851428571428573e-05,
      "loss": 0.1932,
      "step": 130
    },
    {
      "epoch": 0.08,
      "grad_norm": 14.912859916687012,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 0.4253,
      "step": 140
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 2.4497783184051514,
      "learning_rate": 1.982857142857143e-05,
      "loss": 0.3549,
      "step": 150
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 16.75859832763672,
      "learning_rate": 1.981714285714286e-05,
      "loss": 0.305,
      "step": 160
    },
    {
      "epoch": 0.09714285714285714,
      "grad_norm": 12.923510551452637,
      "learning_rate": 1.9805714285714287e-05,
      "loss": 0.2292,
      "step": 170
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 14.686028480529785,
      "learning_rate": 1.9794285714285717e-05,
      "loss": 0.4464,
      "step": 180
    },
    {
      "epoch": 0.10857142857142857,
      "grad_norm": 12.175662994384766,
      "learning_rate": 1.9782857142857144e-05,
      "loss": 0.2462,
      "step": 190
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 20.23836326599121,
      "learning_rate": 1.9771428571428574e-05,
      "loss": 0.3768,
      "step": 200
    },
    {
      "epoch": 0.12,
      "grad_norm": 13.405160903930664,
      "learning_rate": 1.976e-05,
      "loss": 0.2691,
      "step": 210
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 10.221792221069336,
      "learning_rate": 1.974857142857143e-05,
      "loss": 0.4008,
      "step": 220
    },
    {
      "epoch": 0.13142857142857142,
      "grad_norm": 18.707853317260742,
      "learning_rate": 1.973714285714286e-05,
      "loss": 0.2803,
      "step": 230
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 7.358837604522705,
      "learning_rate": 1.9725714285714288e-05,
      "loss": 0.2411,
      "step": 240
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 9.204212188720703,
      "learning_rate": 1.9714285714285718e-05,
      "loss": 0.2961,
      "step": 250
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 3.961744785308838,
      "learning_rate": 1.9702857142857144e-05,
      "loss": 0.231,
      "step": 260
    },
    {
      "epoch": 0.15428571428571428,
      "grad_norm": 13.038115501403809,
      "learning_rate": 1.969142857142857e-05,
      "loss": 0.415,
      "step": 270
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.680549621582031,
      "learning_rate": 1.968e-05,
      "loss": 0.2734,
      "step": 280
    },
    {
      "epoch": 0.1657142857142857,
      "grad_norm": 5.794684886932373,
      "learning_rate": 1.966857142857143e-05,
      "loss": 0.35,
      "step": 290
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 11.670273780822754,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 0.3284,
      "step": 300
    },
    {
      "epoch": 0.17714285714285713,
      "grad_norm": 6.495169162750244,
      "learning_rate": 1.964571428571429e-05,
      "loss": 0.2578,
      "step": 310
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 7.767366409301758,
      "learning_rate": 1.963428571428572e-05,
      "loss": 0.3154,
      "step": 320
    },
    {
      "epoch": 0.18857142857142858,
      "grad_norm": 4.184342384338379,
      "learning_rate": 1.9622857142857142e-05,
      "loss": 0.2975,
      "step": 330
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 10.823018074035645,
      "learning_rate": 1.9611428571428572e-05,
      "loss": 0.2389,
      "step": 340
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.038521766662598,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.2624,
      "step": 350
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 8.129961013793945,
      "learning_rate": 1.958857142857143e-05,
      "loss": 0.2744,
      "step": 360
    },
    {
      "epoch": 0.21142857142857144,
      "grad_norm": 18.52522087097168,
      "learning_rate": 1.957714285714286e-05,
      "loss": 0.3392,
      "step": 370
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 10.356365203857422,
      "learning_rate": 1.956571428571429e-05,
      "loss": 0.2641,
      "step": 380
    },
    {
      "epoch": 0.22285714285714286,
      "grad_norm": 6.159036636352539,
      "learning_rate": 1.9554285714285716e-05,
      "loss": 0.2359,
      "step": 390
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 9.71982479095459,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 0.4013,
      "step": 400
    },
    {
      "epoch": 0.2342857142857143,
      "grad_norm": 7.9284539222717285,
      "learning_rate": 1.9531428571428573e-05,
      "loss": 0.322,
      "step": 410
    },
    {
      "epoch": 0.24,
      "grad_norm": 9.216031074523926,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.3094,
      "step": 420
    },
    {
      "epoch": 0.24571428571428572,
      "grad_norm": 12.052425384521484,
      "learning_rate": 1.950857142857143e-05,
      "loss": 0.376,
      "step": 430
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 9.306233406066895,
      "learning_rate": 1.949714285714286e-05,
      "loss": 0.2114,
      "step": 440
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 9.059666633605957,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 0.3189,
      "step": 450
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 15.302523612976074,
      "learning_rate": 1.9474285714285717e-05,
      "loss": 0.295,
      "step": 460
    },
    {
      "epoch": 0.26857142857142857,
      "grad_norm": 1.625240445137024,
      "learning_rate": 1.9462857142857147e-05,
      "loss": 0.2476,
      "step": 470
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 15.517702102661133,
      "learning_rate": 1.9451428571428573e-05,
      "loss": 0.3088,
      "step": 480
    },
    {
      "epoch": 0.28,
      "grad_norm": 21.832609176635742,
      "learning_rate": 1.944e-05,
      "loss": 0.4599,
      "step": 490
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 22.214401245117188,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.2803,
      "step": 500
    },
    {
      "epoch": 0.2914285714285714,
      "grad_norm": 11.2572021484375,
      "learning_rate": 1.941714285714286e-05,
      "loss": 0.2167,
      "step": 510
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 13.449040412902832,
      "learning_rate": 1.9405714285714287e-05,
      "loss": 0.3618,
      "step": 520
    },
    {
      "epoch": 0.3028571428571429,
      "grad_norm": 2.5615291595458984,
      "learning_rate": 1.9394285714285717e-05,
      "loss": 0.2213,
      "step": 530
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 4.296047687530518,
      "learning_rate": 1.9382857142857144e-05,
      "loss": 0.3681,
      "step": 540
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 7.278306484222412,
      "learning_rate": 1.937142857142857e-05,
      "loss": 0.2719,
      "step": 550
    },
    {
      "epoch": 0.32,
      "grad_norm": 11.805389404296875,
      "learning_rate": 1.936e-05,
      "loss": 0.3399,
      "step": 560
    },
    {
      "epoch": 0.32571428571428573,
      "grad_norm": 9.044734001159668,
      "learning_rate": 1.934857142857143e-05,
      "loss": 0.3097,
      "step": 570
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 15.053021430969238,
      "learning_rate": 1.9337142857142858e-05,
      "loss": 0.3572,
      "step": 580
    },
    {
      "epoch": 0.33714285714285713,
      "grad_norm": 7.988247871398926,
      "learning_rate": 1.9325714285714288e-05,
      "loss": 0.2843,
      "step": 590
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 15.736842155456543,
      "learning_rate": 1.9314285714285718e-05,
      "loss": 0.2025,
      "step": 600
    },
    {
      "epoch": 0.3485714285714286,
      "grad_norm": 20.875268936157227,
      "learning_rate": 1.9302857142857145e-05,
      "loss": 0.2748,
      "step": 610
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 6.9188408851623535,
      "learning_rate": 1.929142857142857e-05,
      "loss": 0.3455,
      "step": 620
    },
    {
      "epoch": 0.36,
      "grad_norm": 7.449994087219238,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 0.2569,
      "step": 630
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 5.044151306152344,
      "learning_rate": 1.926857142857143e-05,
      "loss": 0.4408,
      "step": 640
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 9.638265609741211,
      "learning_rate": 1.925714285714286e-05,
      "loss": 0.292,
      "step": 650
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 8.288509368896484,
      "learning_rate": 1.924571428571429e-05,
      "loss": 0.2311,
      "step": 660
    },
    {
      "epoch": 0.38285714285714284,
      "grad_norm": 3.1956658363342285,
      "learning_rate": 1.9234285714285716e-05,
      "loss": 0.3014,
      "step": 670
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 8.744956016540527,
      "learning_rate": 1.9222857142857146e-05,
      "loss": 0.2389,
      "step": 680
    },
    {
      "epoch": 0.3942857142857143,
      "grad_norm": 16.757205963134766,
      "learning_rate": 1.9211428571428572e-05,
      "loss": 0.2393,
      "step": 690
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.329363822937012,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.2477,
      "step": 700
    },
    {
      "epoch": 0.4057142857142857,
      "grad_norm": 11.514151573181152,
      "learning_rate": 1.918857142857143e-05,
      "loss": 0.3162,
      "step": 710
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 7.280807971954346,
      "learning_rate": 1.917714285714286e-05,
      "loss": 0.2081,
      "step": 720
    },
    {
      "epoch": 0.41714285714285715,
      "grad_norm": 4.926568984985352,
      "learning_rate": 1.9165714285714286e-05,
      "loss": 0.1194,
      "step": 730
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 7.250629425048828,
      "learning_rate": 1.9154285714285716e-05,
      "loss": 0.2929,
      "step": 740
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 15.771639823913574,
      "learning_rate": 1.9142857142857146e-05,
      "loss": 0.2315,
      "step": 750
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 17.428539276123047,
      "learning_rate": 1.9131428571428573e-05,
      "loss": 0.3278,
      "step": 760
    },
    {
      "epoch": 0.44,
      "grad_norm": 12.938117980957031,
      "learning_rate": 1.912e-05,
      "loss": 0.2586,
      "step": 770
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 8.26186466217041,
      "learning_rate": 1.910857142857143e-05,
      "loss": 0.2923,
      "step": 780
    },
    {
      "epoch": 0.4514285714285714,
      "grad_norm": 6.66814661026001,
      "learning_rate": 1.909714285714286e-05,
      "loss": 0.1682,
      "step": 790
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 18.420167922973633,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 0.2491,
      "step": 800
    },
    {
      "epoch": 0.46285714285714286,
      "grad_norm": 6.142080307006836,
      "learning_rate": 1.9074285714285717e-05,
      "loss": 0.2044,
      "step": 810
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 11.78304386138916,
      "learning_rate": 1.9062857142857144e-05,
      "loss": 0.2573,
      "step": 820
    },
    {
      "epoch": 0.4742857142857143,
      "grad_norm": 6.544371604919434,
      "learning_rate": 1.9051428571428574e-05,
      "loss": 0.2921,
      "step": 830
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.815251350402832,
      "learning_rate": 1.904e-05,
      "loss": 0.2048,
      "step": 840
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 3.204611301422119,
      "learning_rate": 1.902857142857143e-05,
      "loss": 0.1461,
      "step": 850
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 8.315884590148926,
      "learning_rate": 1.9017142857142858e-05,
      "loss": 0.1985,
      "step": 860
    },
    {
      "epoch": 0.49714285714285716,
      "grad_norm": 10.914306640625,
      "learning_rate": 1.9005714285714288e-05,
      "loss": 0.2032,
      "step": 870
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 0.882561445236206,
      "learning_rate": 1.8994285714285718e-05,
      "loss": 0.173,
      "step": 880
    },
    {
      "epoch": 0.5085714285714286,
      "grad_norm": 7.433055877685547,
      "learning_rate": 1.8982857142857145e-05,
      "loss": 0.2297,
      "step": 890
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 13.785260200500488,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 0.2059,
      "step": 900
    },
    {
      "epoch": 0.52,
      "grad_norm": 9.406671524047852,
      "learning_rate": 1.896e-05,
      "loss": 0.2045,
      "step": 910
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 7.79182243347168,
      "learning_rate": 1.8948571428571428e-05,
      "loss": 0.2369,
      "step": 920
    },
    {
      "epoch": 0.5314285714285715,
      "grad_norm": 1.412692666053772,
      "learning_rate": 1.893714285714286e-05,
      "loss": 0.1157,
      "step": 930
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 0.877750813961029,
      "learning_rate": 1.892571428571429e-05,
      "loss": 0.2799,
      "step": 940
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 7.486632347106934,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 0.1561,
      "step": 950
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 68.16688537597656,
      "learning_rate": 1.8902857142857145e-05,
      "loss": 0.2745,
      "step": 960
    },
    {
      "epoch": 0.5542857142857143,
      "grad_norm": 5.9456634521484375,
      "learning_rate": 1.8891428571428575e-05,
      "loss": 0.2247,
      "step": 970
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.8732805252075195,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 0.1623,
      "step": 980
    },
    {
      "epoch": 0.5657142857142857,
      "grad_norm": 0.2813437879085541,
      "learning_rate": 1.886857142857143e-05,
      "loss": 0.2923,
      "step": 990
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 8.513208389282227,
      "learning_rate": 1.885714285714286e-05,
      "loss": 0.2442,
      "step": 1000
    },
    {
      "epoch": 0.5771428571428572,
      "grad_norm": 3.1096878051757812,
      "learning_rate": 1.8845714285714286e-05,
      "loss": 0.1942,
      "step": 1010
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 0.5329040288925171,
      "learning_rate": 1.8834285714285716e-05,
      "loss": 0.2025,
      "step": 1020
    },
    {
      "epoch": 0.5885714285714285,
      "grad_norm": 13.860546112060547,
      "learning_rate": 1.8822857142857146e-05,
      "loss": 0.1988,
      "step": 1030
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 8.452577590942383,
      "learning_rate": 1.8811428571428573e-05,
      "loss": 0.2556,
      "step": 1040
    },
    {
      "epoch": 0.6,
      "grad_norm": 19.21830177307129,
      "learning_rate": 1.88e-05,
      "loss": 0.2839,
      "step": 1050
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 8.637642860412598,
      "learning_rate": 1.878857142857143e-05,
      "loss": 0.1652,
      "step": 1060
    },
    {
      "epoch": 0.6114285714285714,
      "grad_norm": 1.5158990621566772,
      "learning_rate": 1.877714285714286e-05,
      "loss": 0.1114,
      "step": 1070
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 1.091326355934143,
      "learning_rate": 1.8765714285714287e-05,
      "loss": 0.2541,
      "step": 1080
    },
    {
      "epoch": 0.6228571428571429,
      "grad_norm": 5.8540778160095215,
      "learning_rate": 1.8754285714285717e-05,
      "loss": 0.0965,
      "step": 1090
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 8.637648582458496,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 0.1465,
      "step": 1100
    },
    {
      "epoch": 0.6342857142857142,
      "grad_norm": 7.3509087562561035,
      "learning_rate": 1.8731428571428574e-05,
      "loss": 0.2006,
      "step": 1110
    },
    {
      "epoch": 0.64,
      "grad_norm": 8.26927375793457,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.2395,
      "step": 1120
    },
    {
      "epoch": 0.6457142857142857,
      "grad_norm": 8.078055381774902,
      "learning_rate": 1.870857142857143e-05,
      "loss": 0.1792,
      "step": 1130
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 1.452763557434082,
      "learning_rate": 1.8697142857142857e-05,
      "loss": 0.276,
      "step": 1140
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 5.439986228942871,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 0.0974,
      "step": 1150
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 10.475287437438965,
      "learning_rate": 1.8674285714285717e-05,
      "loss": 0.122,
      "step": 1160
    },
    {
      "epoch": 0.6685714285714286,
      "grad_norm": 6.382414817810059,
      "learning_rate": 1.8662857142857144e-05,
      "loss": 0.2293,
      "step": 1170
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 11.632244110107422,
      "learning_rate": 1.8651428571428574e-05,
      "loss": 0.1014,
      "step": 1180
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.8836030960083,
      "learning_rate": 1.864e-05,
      "loss": 0.247,
      "step": 1190
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 10.151372909545898,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 0.2656,
      "step": 1200
    },
    {
      "epoch": 0.6914285714285714,
      "grad_norm": 11.706192970275879,
      "learning_rate": 1.8617142857142858e-05,
      "loss": 0.242,
      "step": 1210
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 12.490046501159668,
      "learning_rate": 1.8605714285714288e-05,
      "loss": 0.1549,
      "step": 1220
    },
    {
      "epoch": 0.7028571428571428,
      "grad_norm": 8.442486763000488,
      "learning_rate": 1.8594285714285715e-05,
      "loss": 0.1811,
      "step": 1230
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 8.962122917175293,
      "learning_rate": 1.8582857142857145e-05,
      "loss": 0.1651,
      "step": 1240
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 3.9584641456604004,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.2156,
      "step": 1250
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.965023994445801,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 0.1638,
      "step": 1260
    },
    {
      "epoch": 0.7257142857142858,
      "grad_norm": 1.2384241819381714,
      "learning_rate": 1.854857142857143e-05,
      "loss": 0.1994,
      "step": 1270
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 7.593405246734619,
      "learning_rate": 1.853714285714286e-05,
      "loss": 0.0996,
      "step": 1280
    },
    {
      "epoch": 0.7371428571428571,
      "grad_norm": 14.288475036621094,
      "learning_rate": 1.8525714285714285e-05,
      "loss": 0.3136,
      "step": 1290
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 16.040679931640625,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 0.295,
      "step": 1300
    },
    {
      "epoch": 0.7485714285714286,
      "grad_norm": 7.5496368408203125,
      "learning_rate": 1.8502857142857146e-05,
      "loss": 0.1918,
      "step": 1310
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 22.547670364379883,
      "learning_rate": 1.8491428571428573e-05,
      "loss": 0.1037,
      "step": 1320
    },
    {
      "epoch": 0.76,
      "grad_norm": 13.722551345825195,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 0.3189,
      "step": 1330
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 1.2311760187149048,
      "learning_rate": 1.846857142857143e-05,
      "loss": 0.1484,
      "step": 1340
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 0.42324963212013245,
      "learning_rate": 1.845714285714286e-05,
      "loss": 0.1007,
      "step": 1350
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 12.4439058303833,
      "learning_rate": 1.8445714285714286e-05,
      "loss": 0.1372,
      "step": 1360
    },
    {
      "epoch": 0.7828571428571428,
      "grad_norm": 19.29983139038086,
      "learning_rate": 1.8434285714285716e-05,
      "loss": 0.3213,
      "step": 1370
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 0.7685604691505432,
      "learning_rate": 1.8422857142857143e-05,
      "loss": 0.1744,
      "step": 1380
    },
    {
      "epoch": 0.7942857142857143,
      "grad_norm": 19.742185592651367,
      "learning_rate": 1.8411428571428573e-05,
      "loss": 0.2921,
      "step": 1390
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5660924911499023,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.0848,
      "step": 1400
    },
    {
      "epoch": 0.8057142857142857,
      "grad_norm": 6.778749465942383,
      "learning_rate": 1.838857142857143e-05,
      "loss": 0.1429,
      "step": 1410
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 1.1746724843978882,
      "learning_rate": 1.8377142857142857e-05,
      "loss": 0.1153,
      "step": 1420
    },
    {
      "epoch": 0.8171428571428572,
      "grad_norm": 14.544530868530273,
      "learning_rate": 1.8365714285714287e-05,
      "loss": 0.1769,
      "step": 1430
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 11.453691482543945,
      "learning_rate": 1.8354285714285717e-05,
      "loss": 0.0917,
      "step": 1440
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 0.9973060488700867,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 0.162,
      "step": 1450
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 17.1185359954834,
      "learning_rate": 1.8331428571428574e-05,
      "loss": 0.1766,
      "step": 1460
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.27030086517334,
      "learning_rate": 1.832e-05,
      "loss": 0.1168,
      "step": 1470
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 2.8749496936798096,
      "learning_rate": 1.830857142857143e-05,
      "loss": 0.2677,
      "step": 1480
    },
    {
      "epoch": 0.8514285714285714,
      "grad_norm": 9.439648628234863,
      "learning_rate": 1.8297142857142858e-05,
      "loss": 0.1895,
      "step": 1490
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 19.418548583984375,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 0.1546,
      "step": 1500
    },
    {
      "epoch": 0.8628571428571429,
      "grad_norm": 0.24393439292907715,
      "learning_rate": 1.8274285714285715e-05,
      "loss": 0.1362,
      "step": 1510
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 0.2560511529445648,
      "learning_rate": 1.8262857142857145e-05,
      "loss": 0.0782,
      "step": 1520
    },
    {
      "epoch": 0.8742857142857143,
      "grad_norm": 13.036953926086426,
      "learning_rate": 1.8251428571428575e-05,
      "loss": 0.1719,
      "step": 1530
    },
    {
      "epoch": 0.88,
      "grad_norm": 9.778173446655273,
      "learning_rate": 1.824e-05,
      "loss": 0.1359,
      "step": 1540
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 0.1071612760424614,
      "learning_rate": 1.822857142857143e-05,
      "loss": 0.1442,
      "step": 1550
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 10.268096923828125,
      "learning_rate": 1.821714285714286e-05,
      "loss": 0.0809,
      "step": 1560
    },
    {
      "epoch": 0.8971428571428571,
      "grad_norm": 0.07987454533576965,
      "learning_rate": 1.8205714285714285e-05,
      "loss": 0.1106,
      "step": 1570
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 0.04680251330137253,
      "learning_rate": 1.8194285714285715e-05,
      "loss": 0.0915,
      "step": 1580
    },
    {
      "epoch": 0.9085714285714286,
      "grad_norm": 22.01266098022461,
      "learning_rate": 1.8182857142857145e-05,
      "loss": 0.2371,
      "step": 1590
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.1819198727607727,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 0.0873,
      "step": 1600
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.37021565437316895,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 0.0971,
      "step": 1610
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 13.134354591369629,
      "learning_rate": 1.8148571428571432e-05,
      "loss": 0.1435,
      "step": 1620
    },
    {
      "epoch": 0.9314285714285714,
      "grad_norm": 7.753052711486816,
      "learning_rate": 1.813714285714286e-05,
      "loss": 0.2313,
      "step": 1630
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 1.2648731470108032,
      "learning_rate": 1.8125714285714286e-05,
      "loss": 0.0968,
      "step": 1640
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 0.9709857106208801,
      "learning_rate": 1.8114285714285716e-05,
      "loss": 0.1712,
      "step": 1650
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 26.407590866088867,
      "learning_rate": 1.8102857142857143e-05,
      "loss": 0.0762,
      "step": 1660
    },
    {
      "epoch": 0.9542857142857143,
      "grad_norm": 27.53882598876953,
      "learning_rate": 1.8091428571428573e-05,
      "loss": 0.2143,
      "step": 1670
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.043849773705005646,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.1442,
      "step": 1680
    },
    {
      "epoch": 0.9657142857142857,
      "grad_norm": 16.048824310302734,
      "learning_rate": 1.806857142857143e-05,
      "loss": 0.0428,
      "step": 1690
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 2.0039114952087402,
      "learning_rate": 1.8057142857142857e-05,
      "loss": 0.1516,
      "step": 1700
    },
    {
      "epoch": 0.9771428571428571,
      "grad_norm": 5.217144012451172,
      "learning_rate": 1.8045714285714287e-05,
      "loss": 0.1457,
      "step": 1710
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 4.496680736541748,
      "learning_rate": 1.8034285714285717e-05,
      "loss": 0.0972,
      "step": 1720
    },
    {
      "epoch": 0.9885714285714285,
      "grad_norm": 6.722559452056885,
      "learning_rate": 1.8022857142857144e-05,
      "loss": 0.1418,
      "step": 1730
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 13.874602317810059,
      "learning_rate": 1.8011428571428574e-05,
      "loss": 0.1863,
      "step": 1740
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.862339198589325,
      "learning_rate": 1.8e-05,
      "loss": 0.0777,
      "step": 1750
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9727606951871658,
      "eval_f1": 0.8348530901722391,
      "eval_loss": 0.10226953774690628,
      "eval_precision": 0.8747346072186837,
      "eval_recall": 0.7984496124031008,
      "eval_runtime": 52.6994,
      "eval_samples_per_second": 113.853,
      "eval_steps_per_second": 3.567,
      "step": 1750
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 6.353757858276367,
      "learning_rate": 1.798857142857143e-05,
      "loss": 0.0736,
      "step": 1760
    },
    {
      "epoch": 1.0114285714285713,
      "grad_norm": 0.03823649138212204,
      "learning_rate": 1.797714285714286e-05,
      "loss": 0.0512,
      "step": 1770
    },
    {
      "epoch": 1.0171428571428571,
      "grad_norm": 0.5985352993011475,
      "learning_rate": 1.7965714285714287e-05,
      "loss": 0.117,
      "step": 1780
    },
    {
      "epoch": 1.022857142857143,
      "grad_norm": 0.2616190016269684,
      "learning_rate": 1.7954285714285714e-05,
      "loss": 0.06,
      "step": 1790
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 1.7172636985778809,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 0.0165,
      "step": 1800
    },
    {
      "epoch": 1.0342857142857143,
      "grad_norm": 0.02102251723408699,
      "learning_rate": 1.7931428571428574e-05,
      "loss": 0.0458,
      "step": 1810
    },
    {
      "epoch": 1.04,
      "grad_norm": 13.48149299621582,
      "learning_rate": 1.792e-05,
      "loss": 0.2205,
      "step": 1820
    },
    {
      "epoch": 1.0457142857142858,
      "grad_norm": 7.79714298248291,
      "learning_rate": 1.790857142857143e-05,
      "loss": 0.0459,
      "step": 1830
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 0.027752410620450974,
      "learning_rate": 1.7897142857142858e-05,
      "loss": 0.14,
      "step": 1840
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 0.20138131082057953,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 0.06,
      "step": 1850
    },
    {
      "epoch": 1.062857142857143,
      "grad_norm": 11.877124786376953,
      "learning_rate": 1.7874285714285715e-05,
      "loss": 0.0823,
      "step": 1860
    },
    {
      "epoch": 1.0685714285714285,
      "grad_norm": 36.12617874145508,
      "learning_rate": 1.7862857142857145e-05,
      "loss": 0.154,
      "step": 1870
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 0.05295714735984802,
      "learning_rate": 1.7851428571428572e-05,
      "loss": 0.1232,
      "step": 1880
    },
    {
      "epoch": 1.08,
      "grad_norm": 10.746734619140625,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 0.1038,
      "step": 1890
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.09509223699569702,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 0.0846,
      "step": 1900
    },
    {
      "epoch": 1.0914285714285714,
      "grad_norm": 0.16938038170337677,
      "learning_rate": 1.781714285714286e-05,
      "loss": 0.0623,
      "step": 1910
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 0.06822577118873596,
      "learning_rate": 1.7805714285714286e-05,
      "loss": 0.15,
      "step": 1920
    },
    {
      "epoch": 1.1028571428571428,
      "grad_norm": 0.04710991308093071,
      "learning_rate": 1.7794285714285716e-05,
      "loss": 0.1092,
      "step": 1930
    },
    {
      "epoch": 1.1085714285714285,
      "grad_norm": 8.716117858886719,
      "learning_rate": 1.7782857142857142e-05,
      "loss": 0.3061,
      "step": 1940
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 8.825746536254883,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 0.1135,
      "step": 1950
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9534406661987305,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.0888,
      "step": 1960
    },
    {
      "epoch": 1.1257142857142857,
      "grad_norm": 19.258304595947266,
      "learning_rate": 1.774857142857143e-05,
      "loss": 0.0825,
      "step": 1970
    },
    {
      "epoch": 1.1314285714285715,
      "grad_norm": 0.19274762272834778,
      "learning_rate": 1.773714285714286e-05,
      "loss": 0.1133,
      "step": 1980
    },
    {
      "epoch": 1.1371428571428572,
      "grad_norm": 0.33797919750213623,
      "learning_rate": 1.7725714285714286e-05,
      "loss": 0.1882,
      "step": 1990
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.7260485887527466,
      "learning_rate": 1.7714285714285717e-05,
      "loss": 0.0844,
      "step": 2000
    },
    {
      "epoch": 1.1485714285714286,
      "grad_norm": 8.192856788635254,
      "learning_rate": 1.7702857142857143e-05,
      "loss": 0.0215,
      "step": 2010
    },
    {
      "epoch": 1.1542857142857144,
      "grad_norm": 0.25658339262008667,
      "learning_rate": 1.7691428571428573e-05,
      "loss": 0.093,
      "step": 2020
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.3219074010849,
      "learning_rate": 1.768e-05,
      "loss": 0.1336,
      "step": 2030
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 0.08830270916223526,
      "learning_rate": 1.766857142857143e-05,
      "loss": 0.0759,
      "step": 2040
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 9.508801460266113,
      "learning_rate": 1.765714285714286e-05,
      "loss": 0.0761,
      "step": 2050
    },
    {
      "epoch": 1.177142857142857,
      "grad_norm": 0.19379426538944244,
      "learning_rate": 1.7645714285714287e-05,
      "loss": 0.0947,
      "step": 2060
    },
    {
      "epoch": 1.1828571428571428,
      "grad_norm": 0.02860923670232296,
      "learning_rate": 1.7634285714285714e-05,
      "loss": 0.0959,
      "step": 2070
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 0.12976069748401642,
      "learning_rate": 1.7622857142857144e-05,
      "loss": 0.1712,
      "step": 2080
    },
    {
      "epoch": 1.1942857142857144,
      "grad_norm": 0.3321794271469116,
      "learning_rate": 1.7611428571428574e-05,
      "loss": 0.0425,
      "step": 2090
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.049718547612428665,
      "learning_rate": 1.76e-05,
      "loss": 0.0894,
      "step": 2100
    },
    {
      "epoch": 1.2057142857142857,
      "grad_norm": 8.60500717163086,
      "learning_rate": 1.758857142857143e-05,
      "loss": 0.0843,
      "step": 2110
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 14.9984712600708,
      "learning_rate": 1.7577142857142858e-05,
      "loss": 0.0713,
      "step": 2120
    },
    {
      "epoch": 1.217142857142857,
      "grad_norm": 9.439584732055664,
      "learning_rate": 1.7565714285714288e-05,
      "loss": 0.0377,
      "step": 2130
    },
    {
      "epoch": 1.2228571428571429,
      "grad_norm": 13.013995170593262,
      "learning_rate": 1.7554285714285715e-05,
      "loss": 0.2092,
      "step": 2140
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 0.44220224022865295,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 0.0482,
      "step": 2150
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 0.04494534805417061,
      "learning_rate": 1.753142857142857e-05,
      "loss": 0.1026,
      "step": 2160
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.04273740574717522,
      "learning_rate": 1.752e-05,
      "loss": 0.1295,
      "step": 2170
    },
    {
      "epoch": 1.2457142857142858,
      "grad_norm": 11.540960311889648,
      "learning_rate": 1.7508571428571432e-05,
      "loss": 0.0745,
      "step": 2180
    },
    {
      "epoch": 1.2514285714285713,
      "grad_norm": 0.29625892639160156,
      "learning_rate": 1.749714285714286e-05,
      "loss": 0.0816,
      "step": 2190
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.1724279522895813,
      "learning_rate": 1.748571428571429e-05,
      "loss": 0.0515,
      "step": 2200
    },
    {
      "epoch": 1.262857142857143,
      "grad_norm": 0.05287393182516098,
      "learning_rate": 1.7474285714285715e-05,
      "loss": 0.068,
      "step": 2210
    },
    {
      "epoch": 1.2685714285714287,
      "grad_norm": 8.723602294921875,
      "learning_rate": 1.7462857142857142e-05,
      "loss": 0.0972,
      "step": 2220
    },
    {
      "epoch": 1.2742857142857142,
      "grad_norm": 19.870647430419922,
      "learning_rate": 1.7451428571428572e-05,
      "loss": 0.0583,
      "step": 2230
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.030830899253487587,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.0625,
      "step": 2240
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.11675906181335449,
      "learning_rate": 1.742857142857143e-05,
      "loss": 0.1982,
      "step": 2250
    },
    {
      "epoch": 1.2914285714285714,
      "grad_norm": 2.6774089336395264,
      "learning_rate": 1.741714285714286e-05,
      "loss": 0.1916,
      "step": 2260
    },
    {
      "epoch": 1.2971428571428572,
      "grad_norm": 1.043289065361023,
      "learning_rate": 1.740571428571429e-05,
      "loss": 0.0577,
      "step": 2270
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 17.227115631103516,
      "learning_rate": 1.7394285714285716e-05,
      "loss": 0.1361,
      "step": 2280
    },
    {
      "epoch": 1.3085714285714285,
      "grad_norm": 18.86759376525879,
      "learning_rate": 1.7382857142857143e-05,
      "loss": 0.1538,
      "step": 2290
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 0.4680166244506836,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 0.0143,
      "step": 2300
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.02322542667388916,
      "learning_rate": 1.736e-05,
      "loss": 0.1092,
      "step": 2310
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 0.5757408738136292,
      "learning_rate": 1.734857142857143e-05,
      "loss": 0.0775,
      "step": 2320
    },
    {
      "epoch": 1.3314285714285714,
      "grad_norm": 10.588197708129883,
      "learning_rate": 1.733714285714286e-05,
      "loss": 0.0689,
      "step": 2330
    },
    {
      "epoch": 1.3371428571428572,
      "grad_norm": 16.111099243164062,
      "learning_rate": 1.7325714285714287e-05,
      "loss": 0.037,
      "step": 2340
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 0.24175246059894562,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 0.1301,
      "step": 2350
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 5.962893486022949,
      "learning_rate": 1.7302857142857144e-05,
      "loss": 0.0897,
      "step": 2360
    },
    {
      "epoch": 1.3542857142857143,
      "grad_norm": 0.3113013803958893,
      "learning_rate": 1.7291428571428574e-05,
      "loss": 0.0445,
      "step": 2370
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.7966474890708923,
      "learning_rate": 1.728e-05,
      "loss": 0.0739,
      "step": 2380
    },
    {
      "epoch": 1.3657142857142857,
      "grad_norm": 3.497298240661621,
      "learning_rate": 1.726857142857143e-05,
      "loss": 0.0744,
      "step": 2390
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 2.858593702316284,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 0.0258,
      "step": 2400
    },
    {
      "epoch": 1.3771428571428572,
      "grad_norm": 6.790745735168457,
      "learning_rate": 1.7245714285714288e-05,
      "loss": 0.0652,
      "step": 2410
    },
    {
      "epoch": 1.3828571428571428,
      "grad_norm": 0.5124850273132324,
      "learning_rate": 1.7234285714285718e-05,
      "loss": 0.1613,
      "step": 2420
    },
    {
      "epoch": 1.3885714285714286,
      "grad_norm": 0.2011006474494934,
      "learning_rate": 1.7222857142857144e-05,
      "loss": 0.0784,
      "step": 2430
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 0.09083187580108643,
      "learning_rate": 1.721142857142857e-05,
      "loss": 0.0642,
      "step": 2440
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7098996043205261,
      "learning_rate": 1.72e-05,
      "loss": 0.0621,
      "step": 2450
    },
    {
      "epoch": 1.4057142857142857,
      "grad_norm": 13.579873085021973,
      "learning_rate": 1.718857142857143e-05,
      "loss": 0.0294,
      "step": 2460
    },
    {
      "epoch": 1.4114285714285715,
      "grad_norm": 31.14784049987793,
      "learning_rate": 1.7177142857142858e-05,
      "loss": 0.0901,
      "step": 2470
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 0.11263404786586761,
      "learning_rate": 1.716571428571429e-05,
      "loss": 0.0609,
      "step": 2480
    },
    {
      "epoch": 1.4228571428571428,
      "grad_norm": 0.19540995359420776,
      "learning_rate": 1.7154285714285715e-05,
      "loss": 0.0627,
      "step": 2490
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 10.46889877319336,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.0727,
      "step": 2500
    },
    {
      "epoch": 1.4342857142857142,
      "grad_norm": 0.6594525575637817,
      "learning_rate": 1.7131428571428572e-05,
      "loss": 0.149,
      "step": 2510
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.04998910054564476,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.2582,
      "step": 2520
    },
    {
      "epoch": 1.4457142857142857,
      "grad_norm": 0.20558151602745056,
      "learning_rate": 1.710857142857143e-05,
      "loss": 0.0896,
      "step": 2530
    },
    {
      "epoch": 1.4514285714285715,
      "grad_norm": 23.678796768188477,
      "learning_rate": 1.709714285714286e-05,
      "loss": 0.158,
      "step": 2540
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 24.145780563354492,
      "learning_rate": 1.708571428571429e-05,
      "loss": 0.0599,
      "step": 2550
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 0.16207455098628998,
      "learning_rate": 1.7074285714285716e-05,
      "loss": 0.1611,
      "step": 2560
    },
    {
      "epoch": 1.4685714285714286,
      "grad_norm": 6.6822285652160645,
      "learning_rate": 1.7062857142857143e-05,
      "loss": 0.0501,
      "step": 2570
    },
    {
      "epoch": 1.4742857142857142,
      "grad_norm": 0.9765140414237976,
      "learning_rate": 1.7051428571428573e-05,
      "loss": 0.0348,
      "step": 2580
    },
    {
      "epoch": 1.48,
      "grad_norm": 12.498139381408691,
      "learning_rate": 1.704e-05,
      "loss": 0.1348,
      "step": 2590
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.4662298262119293,
      "learning_rate": 1.702857142857143e-05,
      "loss": 0.0039,
      "step": 2600
    },
    {
      "epoch": 1.4914285714285715,
      "grad_norm": 0.02916708029806614,
      "learning_rate": 1.701714285714286e-05,
      "loss": 0.0412,
      "step": 2610
    },
    {
      "epoch": 1.497142857142857,
      "grad_norm": 2.49613356590271,
      "learning_rate": 1.7005714285714286e-05,
      "loss": 0.0702,
      "step": 2620
    },
    {
      "epoch": 1.502857142857143,
      "grad_norm": 0.09309712052345276,
      "learning_rate": 1.6994285714285717e-05,
      "loss": 0.0901,
      "step": 2630
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 0.009581970982253551,
      "learning_rate": 1.6982857142857143e-05,
      "loss": 0.1078,
      "step": 2640
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 0.295939564704895,
      "learning_rate": 1.6971428571428574e-05,
      "loss": 0.1089,
      "step": 2650
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5252013206481934,
      "learning_rate": 1.696e-05,
      "loss": 0.1007,
      "step": 2660
    },
    {
      "epoch": 1.5257142857142858,
      "grad_norm": 0.0907123014330864,
      "learning_rate": 1.694857142857143e-05,
      "loss": 0.0234,
      "step": 2670
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 0.010430854745209217,
      "learning_rate": 1.6937142857142857e-05,
      "loss": 0.2099,
      "step": 2680
    },
    {
      "epoch": 1.5371428571428571,
      "grad_norm": 0.013105576857924461,
      "learning_rate": 1.6925714285714287e-05,
      "loss": 0.0416,
      "step": 2690
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 0.09286754578351974,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 0.0555,
      "step": 2700
    },
    {
      "epoch": 1.5485714285714285,
      "grad_norm": 1.1952091455459595,
      "learning_rate": 1.6902857142857144e-05,
      "loss": 0.0181,
      "step": 2710
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 14.31192398071289,
      "learning_rate": 1.689142857142857e-05,
      "loss": 0.1007,
      "step": 2720
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6805949211120605,
      "learning_rate": 1.688e-05,
      "loss": 0.1088,
      "step": 2730
    },
    {
      "epoch": 1.5657142857142858,
      "grad_norm": 0.01873672381043434,
      "learning_rate": 1.686857142857143e-05,
      "loss": 0.0622,
      "step": 2740
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.0365251861512661,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 0.0779,
      "step": 2750
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 0.7857515811920166,
      "learning_rate": 1.6845714285714288e-05,
      "loss": 0.0629,
      "step": 2760
    },
    {
      "epoch": 1.5828571428571427,
      "grad_norm": 19.24161148071289,
      "learning_rate": 1.6834285714285715e-05,
      "loss": 0.0339,
      "step": 2770
    },
    {
      "epoch": 1.5885714285714285,
      "grad_norm": 12.88279914855957,
      "learning_rate": 1.6822857142857145e-05,
      "loss": 0.0688,
      "step": 2780
    },
    {
      "epoch": 1.5942857142857143,
      "grad_norm": 0.18851710855960846,
      "learning_rate": 1.681142857142857e-05,
      "loss": 0.059,
      "step": 2790
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.02783038653433323,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0264,
      "step": 2800
    },
    {
      "epoch": 1.6057142857142859,
      "grad_norm": 28.57181739807129,
      "learning_rate": 1.678857142857143e-05,
      "loss": 0.093,
      "step": 2810
    },
    {
      "epoch": 1.6114285714285714,
      "grad_norm": 0.2816150486469269,
      "learning_rate": 1.677714285714286e-05,
      "loss": 0.1062,
      "step": 2820
    },
    {
      "epoch": 1.617142857142857,
      "grad_norm": 28.290573120117188,
      "learning_rate": 1.676571428571429e-05,
      "loss": 0.0755,
      "step": 2830
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 0.2109375298023224,
      "learning_rate": 1.6754285714285716e-05,
      "loss": 0.1159,
      "step": 2840
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 27.772415161132812,
      "learning_rate": 1.6742857142857146e-05,
      "loss": 0.0723,
      "step": 2850
    },
    {
      "epoch": 1.6342857142857143,
      "grad_norm": 3.0662333965301514,
      "learning_rate": 1.6731428571428572e-05,
      "loss": 0.062,
      "step": 2860
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 24.796772003173828,
      "learning_rate": 1.672e-05,
      "loss": 0.1402,
      "step": 2870
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 0.023764725774526596,
      "learning_rate": 1.670857142857143e-05,
      "loss": 0.0575,
      "step": 2880
    },
    {
      "epoch": 1.6514285714285715,
      "grad_norm": 6.382003307342529,
      "learning_rate": 1.669714285714286e-05,
      "loss": 0.0846,
      "step": 2890
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.014615907333791256,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 0.104,
      "step": 2900
    },
    {
      "epoch": 1.6628571428571428,
      "grad_norm": 26.598913192749023,
      "learning_rate": 1.6674285714285716e-05,
      "loss": 0.1549,
      "step": 2910
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 6.530212879180908,
      "learning_rate": 1.6662857142857146e-05,
      "loss": 0.0512,
      "step": 2920
    },
    {
      "epoch": 1.6742857142857144,
      "grad_norm": 0.46716195344924927,
      "learning_rate": 1.6651428571428573e-05,
      "loss": 0.0578,
      "step": 2930
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.002577781677246,
      "learning_rate": 1.664e-05,
      "loss": 0.0558,
      "step": 2940
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 0.043688349425792694,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.0871,
      "step": 2950
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 17.328250885009766,
      "learning_rate": 1.6617142857142857e-05,
      "loss": 0.125,
      "step": 2960
    },
    {
      "epoch": 1.697142857142857,
      "grad_norm": 7.6921234130859375,
      "learning_rate": 1.6605714285714287e-05,
      "loss": 0.0494,
      "step": 2970
    },
    {
      "epoch": 1.7028571428571428,
      "grad_norm": 33.53318405151367,
      "learning_rate": 1.6594285714285717e-05,
      "loss": 0.0837,
      "step": 2980
    },
    {
      "epoch": 1.7085714285714286,
      "grad_norm": 0.006631003692746162,
      "learning_rate": 1.6582857142857144e-05,
      "loss": 0.1417,
      "step": 2990
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.13156357407569885,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 0.1408,
      "step": 3000
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.036736369132995605,
      "learning_rate": 1.656e-05,
      "loss": 0.008,
      "step": 3010
    },
    {
      "epoch": 1.7257142857142858,
      "grad_norm": 0.08548989146947861,
      "learning_rate": 1.654857142857143e-05,
      "loss": 0.1214,
      "step": 3020
    },
    {
      "epoch": 1.7314285714285713,
      "grad_norm": 0.052397917956113815,
      "learning_rate": 1.6537142857142858e-05,
      "loss": 0.1047,
      "step": 3030
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 0.6655505895614624,
      "learning_rate": 1.6525714285714288e-05,
      "loss": 0.0043,
      "step": 3040
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.03305254131555557,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.0313,
      "step": 3050
    },
    {
      "epoch": 1.7485714285714287,
      "grad_norm": 0.9521520137786865,
      "learning_rate": 1.6502857142857145e-05,
      "loss": 0.007,
      "step": 3060
    },
    {
      "epoch": 1.7542857142857144,
      "grad_norm": 0.09691152721643448,
      "learning_rate": 1.6491428571428575e-05,
      "loss": 0.0744,
      "step": 3070
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.164318561553955,
      "learning_rate": 1.648e-05,
      "loss": 0.1311,
      "step": 3080
    },
    {
      "epoch": 1.7657142857142856,
      "grad_norm": 0.09208960086107254,
      "learning_rate": 1.6468571428571428e-05,
      "loss": 0.1578,
      "step": 3090
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 0.6177377104759216,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.0458,
      "step": 3100
    },
    {
      "epoch": 1.7771428571428571,
      "grad_norm": 0.061998527497053146,
      "learning_rate": 1.644571428571429e-05,
      "loss": 0.0834,
      "step": 3110
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 0.05964335799217224,
      "learning_rate": 1.6434285714285715e-05,
      "loss": 0.065,
      "step": 3120
    },
    {
      "epoch": 1.7885714285714287,
      "grad_norm": 0.16134177148342133,
      "learning_rate": 1.6422857142857145e-05,
      "loss": 0.0776,
      "step": 3130
    },
    {
      "epoch": 1.7942857142857143,
      "grad_norm": 0.3960702419281006,
      "learning_rate": 1.6411428571428572e-05,
      "loss": 0.0041,
      "step": 3140
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.6480553150177002,
      "learning_rate": 1.64e-05,
      "loss": 0.1642,
      "step": 3150
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 6.843593597412109,
      "learning_rate": 1.638857142857143e-05,
      "loss": 0.0706,
      "step": 3160
    },
    {
      "epoch": 1.8114285714285714,
      "grad_norm": 13.45482349395752,
      "learning_rate": 1.637714285714286e-05,
      "loss": 0.0652,
      "step": 3170
    },
    {
      "epoch": 1.8171428571428572,
      "grad_norm": 0.26387327909469604,
      "learning_rate": 1.6365714285714286e-05,
      "loss": 0.096,
      "step": 3180
    },
    {
      "epoch": 1.822857142857143,
      "grad_norm": 25.613967895507812,
      "learning_rate": 1.6354285714285716e-05,
      "loss": 0.1189,
      "step": 3190
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.026886815205216408,
      "learning_rate": 1.6342857142857146e-05,
      "loss": 0.0284,
      "step": 3200
    },
    {
      "epoch": 1.8342857142857143,
      "grad_norm": 1.5953367948532104,
      "learning_rate": 1.6331428571428573e-05,
      "loss": 0.0866,
      "step": 3210
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.014760484918951988,
      "learning_rate": 1.632e-05,
      "loss": 0.1057,
      "step": 3220
    },
    {
      "epoch": 1.8457142857142856,
      "grad_norm": 0.025487618520855904,
      "learning_rate": 1.630857142857143e-05,
      "loss": 0.1694,
      "step": 3230
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 0.06694620847702026,
      "learning_rate": 1.6297142857142856e-05,
      "loss": 0.0745,
      "step": 3240
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 9.005376815795898,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.1116,
      "step": 3250
    },
    {
      "epoch": 1.862857142857143,
      "grad_norm": 31.147974014282227,
      "learning_rate": 1.6274285714285717e-05,
      "loss": 0.0869,
      "step": 3260
    },
    {
      "epoch": 1.8685714285714285,
      "grad_norm": 14.163762092590332,
      "learning_rate": 1.6262857142857143e-05,
      "loss": 0.0642,
      "step": 3270
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 0.3770424425601959,
      "learning_rate": 1.6251428571428574e-05,
      "loss": 0.0007,
      "step": 3280
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.014775687828660011,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 0.1352,
      "step": 3290
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 0.055723220109939575,
      "learning_rate": 1.622857142857143e-05,
      "loss": 0.0577,
      "step": 3300
    },
    {
      "epoch": 1.8914285714285715,
      "grad_norm": 4.811773777008057,
      "learning_rate": 1.6217142857142857e-05,
      "loss": 0.0503,
      "step": 3310
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 0.11673588305711746,
      "learning_rate": 1.6205714285714287e-05,
      "loss": 0.0281,
      "step": 3320
    },
    {
      "epoch": 1.9028571428571428,
      "grad_norm": 0.01669255644083023,
      "learning_rate": 1.6194285714285714e-05,
      "loss": 0.0294,
      "step": 3330
    },
    {
      "epoch": 1.9085714285714286,
      "grad_norm": 20.8463191986084,
      "learning_rate": 1.6182857142857144e-05,
      "loss": 0.2713,
      "step": 3340
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 23.72241973876953,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 0.0797,
      "step": 3350
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.2690635919570923,
      "learning_rate": 1.616e-05,
      "loss": 0.0512,
      "step": 3360
    },
    {
      "epoch": 1.9257142857142857,
      "grad_norm": 0.034779276698827744,
      "learning_rate": 1.6148571428571428e-05,
      "loss": 0.1117,
      "step": 3370
    },
    {
      "epoch": 1.9314285714285715,
      "grad_norm": 0.3942123055458069,
      "learning_rate": 1.6137142857142858e-05,
      "loss": 0.0845,
      "step": 3380
    },
    {
      "epoch": 1.9371428571428573,
      "grad_norm": 0.15869884192943573,
      "learning_rate": 1.6125714285714288e-05,
      "loss": 0.0049,
      "step": 3390
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 0.019818652421236038,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.0255,
      "step": 3400
    },
    {
      "epoch": 1.9485714285714286,
      "grad_norm": 0.1341051608324051,
      "learning_rate": 1.6102857142857145e-05,
      "loss": 0.0493,
      "step": 3410
    },
    {
      "epoch": 1.9542857142857142,
      "grad_norm": 0.03296579420566559,
      "learning_rate": 1.6091428571428572e-05,
      "loss": 0.0931,
      "step": 3420
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.061288151890039444,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.0353,
      "step": 3430
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 15.396246910095215,
      "learning_rate": 1.606857142857143e-05,
      "loss": 0.1732,
      "step": 3440
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 0.043350592255592346,
      "learning_rate": 1.605714285714286e-05,
      "loss": 0.0555,
      "step": 3450
    },
    {
      "epoch": 1.977142857142857,
      "grad_norm": 0.19121870398521423,
      "learning_rate": 1.6045714285714286e-05,
      "loss": 0.0802,
      "step": 3460
    },
    {
      "epoch": 1.9828571428571429,
      "grad_norm": 0.062197405844926834,
      "learning_rate": 1.6034285714285716e-05,
      "loss": 0.115,
      "step": 3470
    },
    {
      "epoch": 1.9885714285714284,
      "grad_norm": 0.4407791495323181,
      "learning_rate": 1.6022857142857146e-05,
      "loss": 0.0365,
      "step": 3480
    },
    {
      "epoch": 1.9942857142857142,
      "grad_norm": 7.060105323791504,
      "learning_rate": 1.6011428571428573e-05,
      "loss": 0.0587,
      "step": 3490
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.129677772521973,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.1147,
      "step": 3500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9857954545454546,
      "eval_f1": 0.9147442326980942,
      "eval_loss": 0.06241607666015625,
      "eval_precision": 0.9480249480249481,
      "eval_recall": 0.8837209302325582,
      "eval_runtime": 51.9494,
      "eval_samples_per_second": 115.497,
      "eval_steps_per_second": 3.619,
      "step": 3500
    },
    {
      "epoch": 2.005714285714286,
      "grad_norm": 0.05750001594424248,
      "learning_rate": 1.598857142857143e-05,
      "loss": 0.0595,
      "step": 3510
    },
    {
      "epoch": 2.0114285714285716,
      "grad_norm": 0.18493057787418365,
      "learning_rate": 1.5977142857142856e-05,
      "loss": 0.0023,
      "step": 3520
    },
    {
      "epoch": 2.0171428571428573,
      "grad_norm": 0.11730175465345383,
      "learning_rate": 1.5965714285714286e-05,
      "loss": 0.0411,
      "step": 3530
    },
    {
      "epoch": 2.0228571428571427,
      "grad_norm": 0.04281238839030266,
      "learning_rate": 1.5954285714285716e-05,
      "loss": 0.0036,
      "step": 3540
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 29.51845932006836,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 0.0521,
      "step": 3550
    },
    {
      "epoch": 2.0342857142857143,
      "grad_norm": 0.08203942328691483,
      "learning_rate": 1.5931428571428573e-05,
      "loss": 0.0379,
      "step": 3560
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.1997624635696411,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.0177,
      "step": 3570
    },
    {
      "epoch": 2.045714285714286,
      "grad_norm": 0.017285354435443878,
      "learning_rate": 1.590857142857143e-05,
      "loss": 0.0006,
      "step": 3580
    },
    {
      "epoch": 2.0514285714285716,
      "grad_norm": 1.7102359533309937,
      "learning_rate": 1.5897142857142857e-05,
      "loss": 0.0587,
      "step": 3590
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 5.957832336425781,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.0494,
      "step": 3600
    },
    {
      "epoch": 2.0628571428571427,
      "grad_norm": 0.018604489043354988,
      "learning_rate": 1.5874285714285714e-05,
      "loss": 0.0356,
      "step": 3610
    },
    {
      "epoch": 2.0685714285714285,
      "grad_norm": 8.164778709411621,
      "learning_rate": 1.5862857142857144e-05,
      "loss": 0.0691,
      "step": 3620
    },
    {
      "epoch": 2.0742857142857143,
      "grad_norm": 0.1601090282201767,
      "learning_rate": 1.5851428571428574e-05,
      "loss": 0.0767,
      "step": 3630
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.07184162735939026,
      "learning_rate": 1.584e-05,
      "loss": 0.08,
      "step": 3640
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 0.009186791256070137,
      "learning_rate": 1.582857142857143e-05,
      "loss": 0.0018,
      "step": 3650
    },
    {
      "epoch": 2.0914285714285716,
      "grad_norm": 0.013635561801493168,
      "learning_rate": 1.5817142857142858e-05,
      "loss": 0.001,
      "step": 3660
    },
    {
      "epoch": 2.097142857142857,
      "grad_norm": 0.04742851480841637,
      "learning_rate": 1.5805714285714288e-05,
      "loss": 0.056,
      "step": 3670
    },
    {
      "epoch": 2.1028571428571428,
      "grad_norm": 23.017423629760742,
      "learning_rate": 1.5794285714285715e-05,
      "loss": 0.0742,
      "step": 3680
    },
    {
      "epoch": 2.1085714285714285,
      "grad_norm": 0.19039657711982727,
      "learning_rate": 1.5782857142857145e-05,
      "loss": 0.051,
      "step": 3690
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 29.589794158935547,
      "learning_rate": 1.577142857142857e-05,
      "loss": 0.0548,
      "step": 3700
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.025050818920135498,
      "learning_rate": 1.576e-05,
      "loss": 0.0314,
      "step": 3710
    },
    {
      "epoch": 2.125714285714286,
      "grad_norm": 2.3973357677459717,
      "learning_rate": 1.5748571428571432e-05,
      "loss": 0.0344,
      "step": 3720
    },
    {
      "epoch": 2.1314285714285712,
      "grad_norm": 1.4585347175598145,
      "learning_rate": 1.573714285714286e-05,
      "loss": 0.0481,
      "step": 3730
    },
    {
      "epoch": 2.137142857142857,
      "grad_norm": 0.3423963189125061,
      "learning_rate": 1.5725714285714285e-05,
      "loss": 0.0055,
      "step": 3740
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.010641510598361492,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0002,
      "step": 3750
    },
    {
      "epoch": 2.1485714285714286,
      "grad_norm": 0.7207039594650269,
      "learning_rate": 1.5702857142857145e-05,
      "loss": 0.0101,
      "step": 3760
    },
    {
      "epoch": 2.1542857142857144,
      "grad_norm": 0.01229262724518776,
      "learning_rate": 1.5691428571428572e-05,
      "loss": 0.084,
      "step": 3770
    },
    {
      "epoch": 2.16,
      "grad_norm": 31.808338165283203,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 0.0537,
      "step": 3780
    },
    {
      "epoch": 2.1657142857142855,
      "grad_norm": 17.97323989868164,
      "learning_rate": 1.566857142857143e-05,
      "loss": 0.0889,
      "step": 3790
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 14.707483291625977,
      "learning_rate": 1.5657142857142856e-05,
      "loss": 0.0684,
      "step": 3800
    },
    {
      "epoch": 2.177142857142857,
      "grad_norm": 13.2730073928833,
      "learning_rate": 1.5645714285714286e-05,
      "loss": 0.1013,
      "step": 3810
    },
    {
      "epoch": 2.182857142857143,
      "grad_norm": 0.015432458370923996,
      "learning_rate": 1.5634285714285716e-05,
      "loss": 0.001,
      "step": 3820
    },
    {
      "epoch": 2.1885714285714286,
      "grad_norm": 0.02595355547964573,
      "learning_rate": 1.5622857142857143e-05,
      "loss": 0.0513,
      "step": 3830
    },
    {
      "epoch": 2.1942857142857144,
      "grad_norm": 0.01629631221294403,
      "learning_rate": 1.5611428571428573e-05,
      "loss": 0.0194,
      "step": 3840
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.3265991508960724,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0488,
      "step": 3850
    },
    {
      "epoch": 2.2057142857142855,
      "grad_norm": 0.018337426707148552,
      "learning_rate": 1.558857142857143e-05,
      "loss": 0.0274,
      "step": 3860
    },
    {
      "epoch": 2.2114285714285713,
      "grad_norm": 0.5387138724327087,
      "learning_rate": 1.5577142857142857e-05,
      "loss": 0.0034,
      "step": 3870
    },
    {
      "epoch": 2.217142857142857,
      "grad_norm": 0.0041023013181984425,
      "learning_rate": 1.5565714285714287e-05,
      "loss": 0.0033,
      "step": 3880
    },
    {
      "epoch": 2.222857142857143,
      "grad_norm": 0.026265142485499382,
      "learning_rate": 1.5554285714285713e-05,
      "loss": 0.0245,
      "step": 3890
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 13.749733924865723,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 0.1322,
      "step": 3900
    },
    {
      "epoch": 2.2342857142857144,
      "grad_norm": 35.79449462890625,
      "learning_rate": 1.5531428571428574e-05,
      "loss": 0.0496,
      "step": 3910
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.009150252677500248,
      "learning_rate": 1.552e-05,
      "loss": 0.016,
      "step": 3920
    },
    {
      "epoch": 2.2457142857142856,
      "grad_norm": 0.006270120851695538,
      "learning_rate": 1.550857142857143e-05,
      "loss": 0.0674,
      "step": 3930
    },
    {
      "epoch": 2.2514285714285713,
      "grad_norm": 0.010114449076354504,
      "learning_rate": 1.549714285714286e-05,
      "loss": 0.0693,
      "step": 3940
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 0.009281599894165993,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 0.0022,
      "step": 3950
    },
    {
      "epoch": 2.262857142857143,
      "grad_norm": 0.7180471420288086,
      "learning_rate": 1.5474285714285714e-05,
      "loss": 0.0393,
      "step": 3960
    },
    {
      "epoch": 2.2685714285714287,
      "grad_norm": 0.06735969334840775,
      "learning_rate": 1.5462857142857144e-05,
      "loss": 0.0216,
      "step": 3970
    },
    {
      "epoch": 2.2742857142857145,
      "grad_norm": 0.019197575747966766,
      "learning_rate": 1.545142857142857e-05,
      "loss": 0.0405,
      "step": 3980
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 16.099306106567383,
      "learning_rate": 1.544e-05,
      "loss": 0.0439,
      "step": 3990
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.03475202992558479,
      "learning_rate": 1.542857142857143e-05,
      "loss": 0.0706,
      "step": 4000
    },
    {
      "epoch": 2.2914285714285714,
      "grad_norm": 12.74494457244873,
      "learning_rate": 1.5417142857142858e-05,
      "loss": 0.0481,
      "step": 4010
    },
    {
      "epoch": 2.297142857142857,
      "grad_norm": 19.052257537841797,
      "learning_rate": 1.5405714285714285e-05,
      "loss": 0.066,
      "step": 4020
    },
    {
      "epoch": 2.302857142857143,
      "grad_norm": 0.9121796488761902,
      "learning_rate": 1.5394285714285715e-05,
      "loss": 0.0603,
      "step": 4030
    },
    {
      "epoch": 2.3085714285714287,
      "grad_norm": 0.01996692083775997,
      "learning_rate": 1.5382857142857145e-05,
      "loss": 0.0792,
      "step": 4040
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 0.015675639733672142,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.044,
      "step": 4050
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.036077193915843964,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 0.0314,
      "step": 4060
    },
    {
      "epoch": 2.3257142857142856,
      "grad_norm": 0.017360372468829155,
      "learning_rate": 1.534857142857143e-05,
      "loss": 0.0092,
      "step": 4070
    },
    {
      "epoch": 2.3314285714285714,
      "grad_norm": 0.012494638562202454,
      "learning_rate": 1.533714285714286e-05,
      "loss": 0.0376,
      "step": 4080
    },
    {
      "epoch": 2.337142857142857,
      "grad_norm": 4.033924102783203,
      "learning_rate": 1.5325714285714286e-05,
      "loss": 0.0027,
      "step": 4090
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 0.004306906834244728,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 0.0436,
      "step": 4100
    },
    {
      "epoch": 2.3485714285714288,
      "grad_norm": 0.14145046472549438,
      "learning_rate": 1.5302857142857143e-05,
      "loss": 0.0004,
      "step": 4110
    },
    {
      "epoch": 2.354285714285714,
      "grad_norm": 18.361045837402344,
      "learning_rate": 1.5291428571428573e-05,
      "loss": 0.0443,
      "step": 4120
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.0019661039113998413,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 0.0002,
      "step": 4130
    },
    {
      "epoch": 2.3657142857142857,
      "grad_norm": 7.510149002075195,
      "learning_rate": 1.526857142857143e-05,
      "loss": 0.0331,
      "step": 4140
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 27.714963912963867,
      "learning_rate": 1.525714285714286e-05,
      "loss": 0.0033,
      "step": 4150
    },
    {
      "epoch": 2.3771428571428572,
      "grad_norm": 0.0027342112734913826,
      "learning_rate": 1.5245714285714286e-05,
      "loss": 0.0705,
      "step": 4160
    },
    {
      "epoch": 2.382857142857143,
      "grad_norm": 0.016695335507392883,
      "learning_rate": 1.5234285714285715e-05,
      "loss": 0.0964,
      "step": 4170
    },
    {
      "epoch": 2.388571428571429,
      "grad_norm": 0.012214523740112782,
      "learning_rate": 1.5222857142857143e-05,
      "loss": 0.0152,
      "step": 4180
    },
    {
      "epoch": 2.394285714285714,
      "grad_norm": 0.00617917301133275,
      "learning_rate": 1.5211428571428572e-05,
      "loss": 0.1643,
      "step": 4190
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.10397543758153915,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.0515,
      "step": 4200
    },
    {
      "epoch": 2.4057142857142857,
      "grad_norm": 8.62343978881836,
      "learning_rate": 1.518857142857143e-05,
      "loss": 0.003,
      "step": 4210
    },
    {
      "epoch": 2.4114285714285715,
      "grad_norm": 0.045122452080249786,
      "learning_rate": 1.5177142857142859e-05,
      "loss": 0.0765,
      "step": 4220
    },
    {
      "epoch": 2.4171428571428573,
      "grad_norm": 0.04935980588197708,
      "learning_rate": 1.5165714285714289e-05,
      "loss": 0.0013,
      "step": 4230
    },
    {
      "epoch": 2.422857142857143,
      "grad_norm": 13.013548851013184,
      "learning_rate": 1.5154285714285714e-05,
      "loss": 0.0471,
      "step": 4240
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.5958148241043091,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 0.0141,
      "step": 4250
    },
    {
      "epoch": 2.434285714285714,
      "grad_norm": 0.014297377318143845,
      "learning_rate": 1.5131428571428572e-05,
      "loss": 0.0264,
      "step": 4260
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.008510158397257328,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.0021,
      "step": 4270
    },
    {
      "epoch": 2.4457142857142857,
      "grad_norm": 0.004707157611846924,
      "learning_rate": 1.5108571428571431e-05,
      "loss": 0.046,
      "step": 4280
    },
    {
      "epoch": 2.4514285714285715,
      "grad_norm": 0.062059979885816574,
      "learning_rate": 1.509714285714286e-05,
      "loss": 0.0002,
      "step": 4290
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.00795011781156063,
      "learning_rate": 1.5085714285714288e-05,
      "loss": 0.0478,
      "step": 4300
    },
    {
      "epoch": 2.4628571428571426,
      "grad_norm": 0.03063935413956642,
      "learning_rate": 1.5074285714285715e-05,
      "loss": 0.0792,
      "step": 4310
    },
    {
      "epoch": 2.4685714285714284,
      "grad_norm": 0.032356586307287216,
      "learning_rate": 1.5062857142857143e-05,
      "loss": 0.0143,
      "step": 4320
    },
    {
      "epoch": 2.474285714285714,
      "grad_norm": 21.567302703857422,
      "learning_rate": 1.5051428571428572e-05,
      "loss": 0.0682,
      "step": 4330
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.008531800471246243,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.0522,
      "step": 4340
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 0.011983059346675873,
      "learning_rate": 1.502857142857143e-05,
      "loss": 0.0679,
      "step": 4350
    },
    {
      "epoch": 2.4914285714285715,
      "grad_norm": 9.634493827819824,
      "learning_rate": 1.5017142857142859e-05,
      "loss": 0.0312,
      "step": 4360
    },
    {
      "epoch": 2.4971428571428573,
      "grad_norm": 0.06837397813796997,
      "learning_rate": 1.5005714285714289e-05,
      "loss": 0.0829,
      "step": 4370
    },
    {
      "epoch": 2.5028571428571427,
      "grad_norm": 0.0259132981300354,
      "learning_rate": 1.4994285714285714e-05,
      "loss": 0.0214,
      "step": 4380
    },
    {
      "epoch": 2.5085714285714285,
      "grad_norm": 0.030468756332993507,
      "learning_rate": 1.4982857142857144e-05,
      "loss": 0.0731,
      "step": 4390
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.6321688294410706,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.0263,
      "step": 4400
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.056054193526506424,
      "learning_rate": 1.496e-05,
      "loss": 0.0027,
      "step": 4410
    },
    {
      "epoch": 2.525714285714286,
      "grad_norm": 0.00314270774833858,
      "learning_rate": 1.4948571428571431e-05,
      "loss": 0.0008,
      "step": 4420
    },
    {
      "epoch": 2.5314285714285716,
      "grad_norm": 0.028161276131868362,
      "learning_rate": 1.493714285714286e-05,
      "loss": 0.0971,
      "step": 4430
    },
    {
      "epoch": 2.5371428571428574,
      "grad_norm": 77.01972961425781,
      "learning_rate": 1.4925714285714288e-05,
      "loss": 0.0127,
      "step": 4440
    },
    {
      "epoch": 2.5428571428571427,
      "grad_norm": 0.03888671472668648,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.0408,
      "step": 4450
    },
    {
      "epoch": 2.5485714285714285,
      "grad_norm": 0.007010599132627249,
      "learning_rate": 1.4902857142857143e-05,
      "loss": 0.0462,
      "step": 4460
    },
    {
      "epoch": 2.5542857142857143,
      "grad_norm": 0.021726734936237335,
      "learning_rate": 1.4891428571428571e-05,
      "loss": 0.0109,
      "step": 4470
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.01153014600276947,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 0.0644,
      "step": 4480
    },
    {
      "epoch": 2.565714285714286,
      "grad_norm": 12.986044883728027,
      "learning_rate": 1.486857142857143e-05,
      "loss": 0.1281,
      "step": 4490
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 14.456367492675781,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.0741,
      "step": 4500
    },
    {
      "epoch": 2.5771428571428574,
      "grad_norm": 0.036901794373989105,
      "learning_rate": 1.4845714285714289e-05,
      "loss": 0.035,
      "step": 4510
    },
    {
      "epoch": 2.5828571428571427,
      "grad_norm": 0.03061390295624733,
      "learning_rate": 1.4834285714285714e-05,
      "loss": 0.0716,
      "step": 4520
    },
    {
      "epoch": 2.5885714285714285,
      "grad_norm": 20.23719024658203,
      "learning_rate": 1.4822857142857144e-05,
      "loss": 0.017,
      "step": 4530
    },
    {
      "epoch": 2.5942857142857143,
      "grad_norm": 0.6105289459228516,
      "learning_rate": 1.4811428571428572e-05,
      "loss": 0.0235,
      "step": 4540
    },
    {
      "epoch": 2.6,
      "grad_norm": 63.34515380859375,
      "learning_rate": 1.48e-05,
      "loss": 0.0701,
      "step": 4550
    },
    {
      "epoch": 2.605714285714286,
      "grad_norm": 0.06972751021385193,
      "learning_rate": 1.478857142857143e-05,
      "loss": 0.0466,
      "step": 4560
    },
    {
      "epoch": 2.611428571428571,
      "grad_norm": 0.00792469922453165,
      "learning_rate": 1.477714285714286e-05,
      "loss": 0.043,
      "step": 4570
    },
    {
      "epoch": 2.617142857142857,
      "grad_norm": 1.0220314264297485,
      "learning_rate": 1.4765714285714288e-05,
      "loss": 0.0487,
      "step": 4580
    },
    {
      "epoch": 2.6228571428571428,
      "grad_norm": 0.04782070964574814,
      "learning_rate": 1.4754285714285716e-05,
      "loss": 0.0196,
      "step": 4590
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 8.679120063781738,
      "learning_rate": 1.4742857142857143e-05,
      "loss": 0.0023,
      "step": 4600
    },
    {
      "epoch": 2.6342857142857143,
      "grad_norm": 0.006942846346646547,
      "learning_rate": 1.4731428571428571e-05,
      "loss": 0.0832,
      "step": 4610
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.0809188038110733,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.0005,
      "step": 4620
    },
    {
      "epoch": 2.645714285714286,
      "grad_norm": 0.06270893663167953,
      "learning_rate": 1.470857142857143e-05,
      "loss": 0.0288,
      "step": 4630
    },
    {
      "epoch": 2.6514285714285712,
      "grad_norm": 18.29107093811035,
      "learning_rate": 1.4697142857142858e-05,
      "loss": 0.0221,
      "step": 4640
    },
    {
      "epoch": 2.657142857142857,
      "grad_norm": 0.02207694947719574,
      "learning_rate": 1.4685714285714288e-05,
      "loss": 0.0067,
      "step": 4650
    },
    {
      "epoch": 2.662857142857143,
      "grad_norm": 11.279571533203125,
      "learning_rate": 1.4674285714285717e-05,
      "loss": 0.0879,
      "step": 4660
    },
    {
      "epoch": 2.6685714285714286,
      "grad_norm": 0.09319750219583511,
      "learning_rate": 1.4662857142857144e-05,
      "loss": 0.1229,
      "step": 4670
    },
    {
      "epoch": 2.6742857142857144,
      "grad_norm": 16.225902557373047,
      "learning_rate": 1.4651428571428572e-05,
      "loss": 0.0536,
      "step": 4680
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.601009488105774,
      "learning_rate": 1.464e-05,
      "loss": 0.0236,
      "step": 4690
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 0.019733630120754242,
      "learning_rate": 1.462857142857143e-05,
      "loss": 0.0703,
      "step": 4700
    },
    {
      "epoch": 2.6914285714285713,
      "grad_norm": 0.4506043791770935,
      "learning_rate": 1.4617142857142859e-05,
      "loss": 0.0154,
      "step": 4710
    },
    {
      "epoch": 2.697142857142857,
      "grad_norm": 0.029796790331602097,
      "learning_rate": 1.4605714285714287e-05,
      "loss": 0.0208,
      "step": 4720
    },
    {
      "epoch": 2.702857142857143,
      "grad_norm": 0.004896902479231358,
      "learning_rate": 1.4594285714285716e-05,
      "loss": 0.0009,
      "step": 4730
    },
    {
      "epoch": 2.7085714285714286,
      "grad_norm": 0.35072705149650574,
      "learning_rate": 1.4582857142857143e-05,
      "loss": 0.0013,
      "step": 4740
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.017229845747351646,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.0649,
      "step": 4750
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.02488437481224537,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.0244,
      "step": 4760
    },
    {
      "epoch": 2.725714285714286,
      "grad_norm": 0.6417055130004883,
      "learning_rate": 1.454857142857143e-05,
      "loss": 0.0096,
      "step": 4770
    },
    {
      "epoch": 2.7314285714285713,
      "grad_norm": 0.017574284225702286,
      "learning_rate": 1.4537142857142858e-05,
      "loss": 0.0515,
      "step": 4780
    },
    {
      "epoch": 2.737142857142857,
      "grad_norm": 0.04537717625498772,
      "learning_rate": 1.4525714285714288e-05,
      "loss": 0.0387,
      "step": 4790
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 14.840996742248535,
      "learning_rate": 1.4514285714285717e-05,
      "loss": 0.0935,
      "step": 4800
    },
    {
      "epoch": 2.7485714285714287,
      "grad_norm": 17.389225006103516,
      "learning_rate": 1.4502857142857143e-05,
      "loss": 0.0639,
      "step": 4810
    },
    {
      "epoch": 2.7542857142857144,
      "grad_norm": 0.060743242502212524,
      "learning_rate": 1.4491428571428572e-05,
      "loss": 0.0518,
      "step": 4820
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.030541885644197464,
      "learning_rate": 1.448e-05,
      "loss": 0.0735,
      "step": 4830
    },
    {
      "epoch": 2.7657142857142856,
      "grad_norm": 0.042258843779563904,
      "learning_rate": 1.446857142857143e-05,
      "loss": 0.0295,
      "step": 4840
    },
    {
      "epoch": 2.7714285714285714,
      "grad_norm": 0.018188495188951492,
      "learning_rate": 1.4457142857142859e-05,
      "loss": 0.0006,
      "step": 4850
    },
    {
      "epoch": 2.777142857142857,
      "grad_norm": 0.4962560832500458,
      "learning_rate": 1.4445714285714287e-05,
      "loss": 0.0871,
      "step": 4860
    },
    {
      "epoch": 2.782857142857143,
      "grad_norm": 0.20344828069210052,
      "learning_rate": 1.4434285714285716e-05,
      "loss": 0.0172,
      "step": 4870
    },
    {
      "epoch": 2.7885714285714287,
      "grad_norm": 29.075166702270508,
      "learning_rate": 1.4422857142857146e-05,
      "loss": 0.0971,
      "step": 4880
    },
    {
      "epoch": 2.7942857142857145,
      "grad_norm": 0.07365508377552032,
      "learning_rate": 1.4411428571428573e-05,
      "loss": 0.0711,
      "step": 4890
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.05655379593372345,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0038,
      "step": 4900
    },
    {
      "epoch": 2.8057142857142856,
      "grad_norm": 0.008485398255288601,
      "learning_rate": 1.438857142857143e-05,
      "loss": 0.05,
      "step": 4910
    },
    {
      "epoch": 2.8114285714285714,
      "grad_norm": 0.016358736902475357,
      "learning_rate": 1.4377142857142858e-05,
      "loss": 0.0527,
      "step": 4920
    },
    {
      "epoch": 2.817142857142857,
      "grad_norm": 0.04528173804283142,
      "learning_rate": 1.4365714285714288e-05,
      "loss": 0.0439,
      "step": 4930
    },
    {
      "epoch": 2.822857142857143,
      "grad_norm": 0.0314517579972744,
      "learning_rate": 1.4354285714285716e-05,
      "loss": 0.02,
      "step": 4940
    },
    {
      "epoch": 2.8285714285714287,
      "grad_norm": 0.007048412691801786,
      "learning_rate": 1.4342857142857145e-05,
      "loss": 0.047,
      "step": 4950
    },
    {
      "epoch": 2.8342857142857145,
      "grad_norm": 0.0028188484720885754,
      "learning_rate": 1.4331428571428572e-05,
      "loss": 0.0004,
      "step": 4960
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.013307462446391582,
      "learning_rate": 1.432e-05,
      "loss": 0.0538,
      "step": 4970
    },
    {
      "epoch": 2.8457142857142856,
      "grad_norm": 0.022826261818408966,
      "learning_rate": 1.430857142857143e-05,
      "loss": 0.0128,
      "step": 4980
    },
    {
      "epoch": 2.8514285714285714,
      "grad_norm": 0.004372190684080124,
      "learning_rate": 1.4297142857142859e-05,
      "loss": 0.0244,
      "step": 4990
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.009040838107466698,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.0056,
      "step": 5000
    },
    {
      "epoch": 2.862857142857143,
      "grad_norm": 0.007115171290934086,
      "learning_rate": 1.4274285714285716e-05,
      "loss": 0.0269,
      "step": 5010
    },
    {
      "epoch": 2.8685714285714283,
      "grad_norm": 43.643211364746094,
      "learning_rate": 1.4262857142857146e-05,
      "loss": 0.0235,
      "step": 5020
    },
    {
      "epoch": 2.8742857142857146,
      "grad_norm": 0.009437265805900097,
      "learning_rate": 1.4251428571428572e-05,
      "loss": 0.0576,
      "step": 5030
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.01395074836909771,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.0458,
      "step": 5040
    },
    {
      "epoch": 2.8857142857142857,
      "grad_norm": 0.007894930429756641,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.0006,
      "step": 5050
    },
    {
      "epoch": 2.8914285714285715,
      "grad_norm": 0.007953710854053497,
      "learning_rate": 1.4217142857142858e-05,
      "loss": 0.0264,
      "step": 5060
    },
    {
      "epoch": 2.8971428571428572,
      "grad_norm": 0.026739895343780518,
      "learning_rate": 1.4205714285714288e-05,
      "loss": 0.0292,
      "step": 5070
    },
    {
      "epoch": 2.902857142857143,
      "grad_norm": 0.004489532671868801,
      "learning_rate": 1.4194285714285716e-05,
      "loss": 0.0013,
      "step": 5080
    },
    {
      "epoch": 2.9085714285714284,
      "grad_norm": 0.002178715541958809,
      "learning_rate": 1.4182857142857145e-05,
      "loss": 0.0406,
      "step": 5090
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 0.02202467992901802,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 0.0273,
      "step": 5100
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.00868407916277647,
      "learning_rate": 1.416e-05,
      "loss": 0.0353,
      "step": 5110
    },
    {
      "epoch": 2.9257142857142857,
      "grad_norm": 0.004284251015633345,
      "learning_rate": 1.414857142857143e-05,
      "loss": 0.0525,
      "step": 5120
    },
    {
      "epoch": 2.9314285714285715,
      "grad_norm": 0.030480116605758667,
      "learning_rate": 1.4137142857142859e-05,
      "loss": 0.0259,
      "step": 5130
    },
    {
      "epoch": 2.9371428571428573,
      "grad_norm": 0.009083275683224201,
      "learning_rate": 1.4125714285714287e-05,
      "loss": 0.0223,
      "step": 5140
    },
    {
      "epoch": 2.942857142857143,
      "grad_norm": 24.991779327392578,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.0645,
      "step": 5150
    },
    {
      "epoch": 2.9485714285714284,
      "grad_norm": 0.07579182088375092,
      "learning_rate": 1.4102857142857146e-05,
      "loss": 0.0502,
      "step": 5160
    },
    {
      "epoch": 2.954285714285714,
      "grad_norm": 0.08197921514511108,
      "learning_rate": 1.4091428571428574e-05,
      "loss": 0.0406,
      "step": 5170
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.02339952625334263,
      "learning_rate": 1.408e-05,
      "loss": 0.0491,
      "step": 5180
    },
    {
      "epoch": 2.9657142857142857,
      "grad_norm": 0.006380849983543158,
      "learning_rate": 1.406857142857143e-05,
      "loss": 0.1095,
      "step": 5190
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 12.192839622497559,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.0718,
      "step": 5200
    },
    {
      "epoch": 2.977142857142857,
      "grad_norm": 53.343204498291016,
      "learning_rate": 1.4045714285714288e-05,
      "loss": 0.0586,
      "step": 5210
    },
    {
      "epoch": 2.982857142857143,
      "grad_norm": 0.0949333906173706,
      "learning_rate": 1.4034285714285716e-05,
      "loss": 0.0065,
      "step": 5220
    },
    {
      "epoch": 2.9885714285714284,
      "grad_norm": 0.02419598400592804,
      "learning_rate": 1.4022857142857145e-05,
      "loss": 0.0415,
      "step": 5230
    },
    {
      "epoch": 2.994285714285714,
      "grad_norm": 18.694875717163086,
      "learning_rate": 1.4011428571428573e-05,
      "loss": 0.1277,
      "step": 5240
    },
    {
      "epoch": 3.0,
      "grad_norm": 28.48348045349121,
      "learning_rate": 1.4e-05,
      "loss": 0.0359,
      "step": 5250
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9896390374331551,
      "eval_f1": 0.940952380952381,
      "eval_loss": 0.0547831729054451,
      "eval_precision": 0.9250936329588015,
      "eval_recall": 0.9573643410852714,
      "eval_runtime": 51.0376,
      "eval_samples_per_second": 117.56,
      "eval_steps_per_second": 3.684,
      "step": 5250
    },
    {
      "epoch": 3.005714285714286,
      "grad_norm": 0.006890258751809597,
      "learning_rate": 1.398857142857143e-05,
      "loss": 0.0176,
      "step": 5260
    },
    {
      "epoch": 3.0114285714285716,
      "grad_norm": 0.007581917569041252,
      "learning_rate": 1.3977142857142858e-05,
      "loss": 0.0001,
      "step": 5270
    },
    {
      "epoch": 3.0171428571428573,
      "grad_norm": 0.009929655119776726,
      "learning_rate": 1.3965714285714287e-05,
      "loss": 0.0082,
      "step": 5280
    },
    {
      "epoch": 3.0228571428571427,
      "grad_norm": 0.3854723870754242,
      "learning_rate": 1.3954285714285715e-05,
      "loss": 0.0003,
      "step": 5290
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 0.008043690584599972,
      "learning_rate": 1.3942857142857145e-05,
      "loss": 0.0867,
      "step": 5300
    },
    {
      "epoch": 3.0342857142857143,
      "grad_norm": 0.015279903076589108,
      "learning_rate": 1.3931428571428574e-05,
      "loss": 0.0085,
      "step": 5310
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.38685354590415955,
      "learning_rate": 1.392e-05,
      "loss": 0.0004,
      "step": 5320
    },
    {
      "epoch": 3.045714285714286,
      "grad_norm": 18.352081298828125,
      "learning_rate": 1.3908571428571429e-05,
      "loss": 0.0601,
      "step": 5330
    },
    {
      "epoch": 3.0514285714285716,
      "grad_norm": 0.014979136176407337,
      "learning_rate": 1.3897142857142857e-05,
      "loss": 0.035,
      "step": 5340
    },
    {
      "epoch": 3.057142857142857,
      "grad_norm": 0.03858782723546028,
      "learning_rate": 1.3885714285714288e-05,
      "loss": 0.0015,
      "step": 5350
    },
    {
      "epoch": 3.0628571428571427,
      "grad_norm": 0.04005138576030731,
      "learning_rate": 1.3874285714285716e-05,
      "loss": 0.0013,
      "step": 5360
    },
    {
      "epoch": 3.0685714285714285,
      "grad_norm": 0.011144629679620266,
      "learning_rate": 1.3862857142857144e-05,
      "loss": 0.0107,
      "step": 5370
    },
    {
      "epoch": 3.0742857142857143,
      "grad_norm": 0.43361151218414307,
      "learning_rate": 1.3851428571428573e-05,
      "loss": 0.049,
      "step": 5380
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.005908658728003502,
      "learning_rate": 1.384e-05,
      "loss": 0.033,
      "step": 5390
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 0.00890802126377821,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.0566,
      "step": 5400
    },
    {
      "epoch": 3.0914285714285716,
      "grad_norm": 0.009753533639013767,
      "learning_rate": 1.3817142857142858e-05,
      "loss": 0.0004,
      "step": 5410
    },
    {
      "epoch": 3.097142857142857,
      "grad_norm": 0.004676868207752705,
      "learning_rate": 1.3805714285714287e-05,
      "loss": 0.0382,
      "step": 5420
    },
    {
      "epoch": 3.1028571428571428,
      "grad_norm": 0.006363599561154842,
      "learning_rate": 1.3794285714285715e-05,
      "loss": 0.0003,
      "step": 5430
    },
    {
      "epoch": 3.1085714285714285,
      "grad_norm": 0.03879231587052345,
      "learning_rate": 1.3782857142857145e-05,
      "loss": 0.0213,
      "step": 5440
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 0.6126925349235535,
      "learning_rate": 1.3771428571428574e-05,
      "loss": 0.0482,
      "step": 5450
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.02043328806757927,
      "learning_rate": 1.376e-05,
      "loss": 0.0005,
      "step": 5460
    },
    {
      "epoch": 3.125714285714286,
      "grad_norm": 0.004975008778274059,
      "learning_rate": 1.3748571428571429e-05,
      "loss": 0.0217,
      "step": 5470
    },
    {
      "epoch": 3.1314285714285712,
      "grad_norm": 10.127165794372559,
      "learning_rate": 1.3737142857142857e-05,
      "loss": 0.0051,
      "step": 5480
    },
    {
      "epoch": 3.137142857142857,
      "grad_norm": 0.005991506855934858,
      "learning_rate": 1.3725714285714287e-05,
      "loss": 0.0077,
      "step": 5490
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.00709491828456521,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.06,
      "step": 5500
    },
    {
      "epoch": 3.1485714285714286,
      "grad_norm": 0.039208412170410156,
      "learning_rate": 1.3702857142857144e-05,
      "loss": 0.0007,
      "step": 5510
    },
    {
      "epoch": 3.1542857142857144,
      "grad_norm": 0.008171356283128262,
      "learning_rate": 1.3691428571428573e-05,
      "loss": 0.0005,
      "step": 5520
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.012040995992720127,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 0.0002,
      "step": 5530
    },
    {
      "epoch": 3.1657142857142855,
      "grad_norm": 0.004163756966590881,
      "learning_rate": 1.366857142857143e-05,
      "loss": 0.0453,
      "step": 5540
    },
    {
      "epoch": 3.1714285714285713,
      "grad_norm": 0.02428271435201168,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.0301,
      "step": 5550
    },
    {
      "epoch": 3.177142857142857,
      "grad_norm": 42.786842346191406,
      "learning_rate": 1.3645714285714286e-05,
      "loss": 0.0191,
      "step": 5560
    },
    {
      "epoch": 3.182857142857143,
      "grad_norm": 0.02494638040661812,
      "learning_rate": 1.3634285714285715e-05,
      "loss": 0.0001,
      "step": 5570
    },
    {
      "epoch": 3.1885714285714286,
      "grad_norm": 0.01982075907289982,
      "learning_rate": 1.3622857142857145e-05,
      "loss": 0.0001,
      "step": 5580
    },
    {
      "epoch": 3.1942857142857144,
      "grad_norm": 0.0032623771112412214,
      "learning_rate": 1.3611428571428573e-05,
      "loss": 0.0446,
      "step": 5590
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.004822207614779472,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0557,
      "step": 5600
    },
    {
      "epoch": 3.2057142857142855,
      "grad_norm": 0.001707311486825347,
      "learning_rate": 1.3588571428571429e-05,
      "loss": 0.0081,
      "step": 5610
    },
    {
      "epoch": 3.2114285714285713,
      "grad_norm": 0.030547907575964928,
      "learning_rate": 1.3577142857142857e-05,
      "loss": 0.0303,
      "step": 5620
    },
    {
      "epoch": 3.217142857142857,
      "grad_norm": 0.01396399550139904,
      "learning_rate": 1.3565714285714287e-05,
      "loss": 0.0008,
      "step": 5630
    },
    {
      "epoch": 3.222857142857143,
      "grad_norm": 2.071983814239502,
      "learning_rate": 1.3554285714285716e-05,
      "loss": 0.0702,
      "step": 5640
    },
    {
      "epoch": 3.2285714285714286,
      "grad_norm": 0.0078120362013578415,
      "learning_rate": 1.3542857142857144e-05,
      "loss": 0.0002,
      "step": 5650
    },
    {
      "epoch": 3.2342857142857144,
      "grad_norm": 0.0025328844785690308,
      "learning_rate": 1.3531428571428573e-05,
      "loss": 0.0076,
      "step": 5660
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.004108133260160685,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.026,
      "step": 5670
    },
    {
      "epoch": 3.2457142857142856,
      "grad_norm": 33.56218338012695,
      "learning_rate": 1.350857142857143e-05,
      "loss": 0.0048,
      "step": 5680
    },
    {
      "epoch": 3.2514285714285713,
      "grad_norm": 0.004501720424741507,
      "learning_rate": 1.3497142857142858e-05,
      "loss": 0.0384,
      "step": 5690
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 0.03735961765050888,
      "learning_rate": 1.3485714285714286e-05,
      "loss": 0.0002,
      "step": 5700
    },
    {
      "epoch": 3.262857142857143,
      "grad_norm": 0.0036841752007603645,
      "learning_rate": 1.3474285714285715e-05,
      "loss": 0.0469,
      "step": 5710
    },
    {
      "epoch": 3.2685714285714287,
      "grad_norm": 1.0107101202011108,
      "learning_rate": 1.3462857142857145e-05,
      "loss": 0.0004,
      "step": 5720
    },
    {
      "epoch": 3.2742857142857145,
      "grad_norm": 0.06051581725478172,
      "learning_rate": 1.3451428571428573e-05,
      "loss": 0.0607,
      "step": 5730
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.017819970846176147,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 0.0002,
      "step": 5740
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 7.7993316650390625,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.0317,
      "step": 5750
    },
    {
      "epoch": 3.2914285714285714,
      "grad_norm": 0.0554807111620903,
      "learning_rate": 1.3417142857142857e-05,
      "loss": 0.0009,
      "step": 5760
    },
    {
      "epoch": 3.297142857142857,
      "grad_norm": 0.009164383634924889,
      "learning_rate": 1.3405714285714287e-05,
      "loss": 0.043,
      "step": 5770
    },
    {
      "epoch": 3.302857142857143,
      "grad_norm": 7.467813014984131,
      "learning_rate": 1.3394285714285716e-05,
      "loss": 0.1087,
      "step": 5780
    },
    {
      "epoch": 3.3085714285714287,
      "grad_norm": 0.10656126588582993,
      "learning_rate": 1.3382857142857144e-05,
      "loss": 0.0144,
      "step": 5790
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 0.01059781014919281,
      "learning_rate": 1.3371428571428572e-05,
      "loss": 0.0013,
      "step": 5800
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.0046451338566839695,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 0.0378,
      "step": 5810
    },
    {
      "epoch": 3.3257142857142856,
      "grad_norm": 8.643447875976562,
      "learning_rate": 1.3348571428571431e-05,
      "loss": 0.0042,
      "step": 5820
    },
    {
      "epoch": 3.3314285714285714,
      "grad_norm": 0.04037541523575783,
      "learning_rate": 1.3337142857142858e-05,
      "loss": 0.0003,
      "step": 5830
    },
    {
      "epoch": 3.337142857142857,
      "grad_norm": 9.439892768859863,
      "learning_rate": 1.3325714285714286e-05,
      "loss": 0.0067,
      "step": 5840
    },
    {
      "epoch": 3.342857142857143,
      "grad_norm": 0.33550724387168884,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.0404,
      "step": 5850
    },
    {
      "epoch": 3.3485714285714288,
      "grad_norm": 0.17416435480117798,
      "learning_rate": 1.3302857142857145e-05,
      "loss": 0.1058,
      "step": 5860
    },
    {
      "epoch": 3.354285714285714,
      "grad_norm": 0.1823030561208725,
      "learning_rate": 1.3291428571428573e-05,
      "loss": 0.0688,
      "step": 5870
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.01988094486296177,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.0475,
      "step": 5880
    },
    {
      "epoch": 3.3657142857142857,
      "grad_norm": 0.046062618494033813,
      "learning_rate": 1.326857142857143e-05,
      "loss": 0.0042,
      "step": 5890
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 0.113675557076931,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.0094,
      "step": 5900
    },
    {
      "epoch": 3.3771428571428572,
      "grad_norm": 0.010340091772377491,
      "learning_rate": 1.3245714285714287e-05,
      "loss": 0.0005,
      "step": 5910
    },
    {
      "epoch": 3.382857142857143,
      "grad_norm": 0.007182558998465538,
      "learning_rate": 1.3234285714285715e-05,
      "loss": 0.0341,
      "step": 5920
    },
    {
      "epoch": 3.388571428571429,
      "grad_norm": 0.023373130708932877,
      "learning_rate": 1.3222857142857144e-05,
      "loss": 0.0411,
      "step": 5930
    },
    {
      "epoch": 3.394285714285714,
      "grad_norm": 0.042031820863485336,
      "learning_rate": 1.3211428571428572e-05,
      "loss": 0.0073,
      "step": 5940
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.004277982749044895,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.036,
      "step": 5950
    },
    {
      "epoch": 3.4057142857142857,
      "grad_norm": 0.04238537698984146,
      "learning_rate": 1.318857142857143e-05,
      "loss": 0.0001,
      "step": 5960
    },
    {
      "epoch": 3.4114285714285715,
      "grad_norm": 0.5726981163024902,
      "learning_rate": 1.3177142857142858e-05,
      "loss": 0.0268,
      "step": 5970
    },
    {
      "epoch": 3.4171428571428573,
      "grad_norm": 0.00912199355661869,
      "learning_rate": 1.3165714285714286e-05,
      "loss": 0.0221,
      "step": 5980
    },
    {
      "epoch": 3.422857142857143,
      "grad_norm": 0.005131641868501902,
      "learning_rate": 1.3154285714285714e-05,
      "loss": 0.0574,
      "step": 5990
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.1283520609140396,
      "learning_rate": 1.3142857142857145e-05,
      "loss": 0.0052,
      "step": 6000
    },
    {
      "epoch": 3.434285714285714,
      "grad_norm": 14.011561393737793,
      "learning_rate": 1.3131428571428573e-05,
      "loss": 0.0054,
      "step": 6010
    },
    {
      "epoch": 3.44,
      "grad_norm": 22.367712020874023,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.0099,
      "step": 6020
    },
    {
      "epoch": 3.4457142857142857,
      "grad_norm": 0.005453350953757763,
      "learning_rate": 1.310857142857143e-05,
      "loss": 0.119,
      "step": 6030
    },
    {
      "epoch": 3.4514285714285715,
      "grad_norm": 0.011773492209613323,
      "learning_rate": 1.3097142857142857e-05,
      "loss": 0.0002,
      "step": 6040
    },
    {
      "epoch": 3.4571428571428573,
      "grad_norm": 0.014780822210013866,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 0.0027,
      "step": 6050
    },
    {
      "epoch": 3.4628571428571426,
      "grad_norm": 0.04902517795562744,
      "learning_rate": 1.3074285714285715e-05,
      "loss": 0.1141,
      "step": 6060
    },
    {
      "epoch": 3.4685714285714284,
      "grad_norm": 17.374818801879883,
      "learning_rate": 1.3062857142857144e-05,
      "loss": 0.006,
      "step": 6070
    },
    {
      "epoch": 3.474285714285714,
      "grad_norm": 0.00843365304172039,
      "learning_rate": 1.3051428571428572e-05,
      "loss": 0.009,
      "step": 6080
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.0050784386694431305,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.0003,
      "step": 6090
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 0.008579321205615997,
      "learning_rate": 1.302857142857143e-05,
      "loss": 0.0003,
      "step": 6100
    },
    {
      "epoch": 3.4914285714285715,
      "grad_norm": 0.003823559731245041,
      "learning_rate": 1.3017142857142859e-05,
      "loss": 0.0001,
      "step": 6110
    },
    {
      "epoch": 3.4971428571428573,
      "grad_norm": 0.006802530027925968,
      "learning_rate": 1.3005714285714286e-05,
      "loss": 0.0002,
      "step": 6120
    },
    {
      "epoch": 3.5028571428571427,
      "grad_norm": 8.908297538757324,
      "learning_rate": 1.2994285714285714e-05,
      "loss": 0.0041,
      "step": 6130
    },
    {
      "epoch": 3.5085714285714285,
      "grad_norm": 0.39452889561653137,
      "learning_rate": 1.2982857142857144e-05,
      "loss": 0.0007,
      "step": 6140
    },
    {
      "epoch": 3.5142857142857142,
      "grad_norm": 0.004089336842298508,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.0091,
      "step": 6150
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.053748846054077,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 0.0011,
      "step": 6160
    },
    {
      "epoch": 3.525714285714286,
      "grad_norm": 7.355197906494141,
      "learning_rate": 1.294857142857143e-05,
      "loss": 0.159,
      "step": 6170
    },
    {
      "epoch": 3.5314285714285716,
      "grad_norm": 0.016156811267137527,
      "learning_rate": 1.293714285714286e-05,
      "loss": 0.0449,
      "step": 6180
    },
    {
      "epoch": 3.5371428571428574,
      "grad_norm": 0.07672859728336334,
      "learning_rate": 1.2925714285714287e-05,
      "loss": 0.0054,
      "step": 6190
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 0.021156078204512596,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.0111,
      "step": 6200
    },
    {
      "epoch": 3.5485714285714285,
      "grad_norm": 0.031473882496356964,
      "learning_rate": 1.2902857142857143e-05,
      "loss": 0.0369,
      "step": 6210
    },
    {
      "epoch": 3.5542857142857143,
      "grad_norm": 0.0017190221697092056,
      "learning_rate": 1.2891428571428572e-05,
      "loss": 0.0737,
      "step": 6220
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.9642653465270996,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.1519,
      "step": 6230
    },
    {
      "epoch": 3.565714285714286,
      "grad_norm": 0.10181576013565063,
      "learning_rate": 1.286857142857143e-05,
      "loss": 0.0491,
      "step": 6240
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.029746929183602333,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.0005,
      "step": 6250
    },
    {
      "epoch": 3.5771428571428574,
      "grad_norm": 0.10659459233283997,
      "learning_rate": 1.2845714285714286e-05,
      "loss": 0.0004,
      "step": 6260
    },
    {
      "epoch": 3.5828571428571427,
      "grad_norm": 0.02167377434670925,
      "learning_rate": 1.2834285714285714e-05,
      "loss": 0.0449,
      "step": 6270
    },
    {
      "epoch": 3.5885714285714285,
      "grad_norm": 0.0067459470592439175,
      "learning_rate": 1.2822857142857144e-05,
      "loss": 0.0002,
      "step": 6280
    },
    {
      "epoch": 3.5942857142857143,
      "grad_norm": 0.013014604337513447,
      "learning_rate": 1.2811428571428573e-05,
      "loss": 0.0201,
      "step": 6290
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.003613878972828388,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0089,
      "step": 6300
    },
    {
      "epoch": 3.605714285714286,
      "grad_norm": 0.006784942001104355,
      "learning_rate": 1.278857142857143e-05,
      "loss": 0.0003,
      "step": 6310
    },
    {
      "epoch": 3.611428571428571,
      "grad_norm": 0.010714178904891014,
      "learning_rate": 1.277714285714286e-05,
      "loss": 0.0186,
      "step": 6320
    },
    {
      "epoch": 3.617142857142857,
      "grad_norm": 0.010223934426903725,
      "learning_rate": 1.2765714285714286e-05,
      "loss": 0.0274,
      "step": 6330
    },
    {
      "epoch": 3.6228571428571428,
      "grad_norm": 0.08724767714738846,
      "learning_rate": 1.2754285714285715e-05,
      "loss": 0.0003,
      "step": 6340
    },
    {
      "epoch": 3.6285714285714286,
      "grad_norm": 0.03217829391360283,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 0.0005,
      "step": 6350
    },
    {
      "epoch": 3.6342857142857143,
      "grad_norm": 0.01805797964334488,
      "learning_rate": 1.2731428571428572e-05,
      "loss": 0.0031,
      "step": 6360
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.08921666443347931,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.022,
      "step": 6370
    },
    {
      "epoch": 3.645714285714286,
      "grad_norm": 0.00939234159886837,
      "learning_rate": 1.270857142857143e-05,
      "loss": 0.003,
      "step": 6380
    },
    {
      "epoch": 3.6514285714285712,
      "grad_norm": 24.13121223449707,
      "learning_rate": 1.2697142857142859e-05,
      "loss": 0.0847,
      "step": 6390
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 0.007560119964182377,
      "learning_rate": 1.2685714285714286e-05,
      "loss": 0.0972,
      "step": 6400
    },
    {
      "epoch": 3.662857142857143,
      "grad_norm": 0.0034164106473326683,
      "learning_rate": 1.2674285714285714e-05,
      "loss": 0.001,
      "step": 6410
    },
    {
      "epoch": 3.6685714285714286,
      "grad_norm": 0.0023661083541810513,
      "learning_rate": 1.2662857142857144e-05,
      "loss": 0.0001,
      "step": 6420
    },
    {
      "epoch": 3.6742857142857144,
      "grad_norm": 0.004060761537402868,
      "learning_rate": 1.2651428571428573e-05,
      "loss": 0.0001,
      "step": 6430
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.017669595777988434,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.0001,
      "step": 6440
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 14.306819915771484,
      "learning_rate": 1.262857142857143e-05,
      "loss": 0.004,
      "step": 6450
    },
    {
      "epoch": 3.6914285714285713,
      "grad_norm": 0.002179826842620969,
      "learning_rate": 1.261714285714286e-05,
      "loss": 0.0652,
      "step": 6460
    },
    {
      "epoch": 3.697142857142857,
      "grad_norm": 0.00883402582257986,
      "learning_rate": 1.2605714285714288e-05,
      "loss": 0.0002,
      "step": 6470
    },
    {
      "epoch": 3.702857142857143,
      "grad_norm": 0.013844643719494343,
      "learning_rate": 1.2594285714285715e-05,
      "loss": 0.0274,
      "step": 6480
    },
    {
      "epoch": 3.7085714285714286,
      "grad_norm": 0.006747706793248653,
      "learning_rate": 1.2582857142857143e-05,
      "loss": 0.0314,
      "step": 6490
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.0014483253471553326,
      "learning_rate": 1.2571428571428572e-05,
      "loss": 0.0026,
      "step": 6500
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.0028078733012080193,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.0508,
      "step": 6510
    },
    {
      "epoch": 3.725714285714286,
      "grad_norm": 0.0021147760562598705,
      "learning_rate": 1.254857142857143e-05,
      "loss": 0.03,
      "step": 6520
    },
    {
      "epoch": 3.7314285714285713,
      "grad_norm": 0.004428152460604906,
      "learning_rate": 1.2537142857142859e-05,
      "loss": 0.0236,
      "step": 6530
    },
    {
      "epoch": 3.737142857142857,
      "grad_norm": 0.22665414214134216,
      "learning_rate": 1.2525714285714287e-05,
      "loss": 0.0852,
      "step": 6540
    },
    {
      "epoch": 3.742857142857143,
      "grad_norm": 0.0014089734759181738,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 0.0299,
      "step": 6550
    },
    {
      "epoch": 3.7485714285714287,
      "grad_norm": 0.0008875589701347053,
      "learning_rate": 1.2502857142857144e-05,
      "loss": 0.0001,
      "step": 6560
    },
    {
      "epoch": 3.7542857142857144,
      "grad_norm": 19.68297576904297,
      "learning_rate": 1.2491428571428572e-05,
      "loss": 0.0311,
      "step": 6570
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.028895653784275055,
      "learning_rate": 1.248e-05,
      "loss": 0.024,
      "step": 6580
    },
    {
      "epoch": 3.7657142857142856,
      "grad_norm": 0.03437710180878639,
      "learning_rate": 1.246857142857143e-05,
      "loss": 0.0049,
      "step": 6590
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 0.015184472315013409,
      "learning_rate": 1.245714285714286e-05,
      "loss": 0.0001,
      "step": 6600
    },
    {
      "epoch": 3.777142857142857,
      "grad_norm": 0.003580999094992876,
      "learning_rate": 1.2445714285714288e-05,
      "loss": 0.0126,
      "step": 6610
    },
    {
      "epoch": 3.782857142857143,
      "grad_norm": 0.0016596823697909713,
      "learning_rate": 1.2434285714285715e-05,
      "loss": 0.0002,
      "step": 6620
    },
    {
      "epoch": 3.7885714285714287,
      "grad_norm": 0.001021674950607121,
      "learning_rate": 1.2422857142857143e-05,
      "loss": 0.0003,
      "step": 6630
    },
    {
      "epoch": 3.7942857142857145,
      "grad_norm": 15.848737716674805,
      "learning_rate": 1.2411428571428571e-05,
      "loss": 0.0372,
      "step": 6640
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.002852943493053317,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0004,
      "step": 6650
    },
    {
      "epoch": 3.8057142857142856,
      "grad_norm": 0.0025189341977238655,
      "learning_rate": 1.238857142857143e-05,
      "loss": 0.0912,
      "step": 6660
    },
    {
      "epoch": 3.8114285714285714,
      "grad_norm": 0.10187073796987534,
      "learning_rate": 1.2377142857142858e-05,
      "loss": 0.0306,
      "step": 6670
    },
    {
      "epoch": 3.817142857142857,
      "grad_norm": 0.013575812801718712,
      "learning_rate": 1.2365714285714287e-05,
      "loss": 0.0883,
      "step": 6680
    },
    {
      "epoch": 3.822857142857143,
      "grad_norm": 0.005449343007057905,
      "learning_rate": 1.2354285714285714e-05,
      "loss": 0.0766,
      "step": 6690
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 0.39343294501304626,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.0003,
      "step": 6700
    },
    {
      "epoch": 3.8342857142857145,
      "grad_norm": 0.10280916094779968,
      "learning_rate": 1.2331428571428572e-05,
      "loss": 0.0435,
      "step": 6710
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.00270877149887383,
      "learning_rate": 1.232e-05,
      "loss": 0.012,
      "step": 6720
    },
    {
      "epoch": 3.8457142857142856,
      "grad_norm": 0.0027107982896268368,
      "learning_rate": 1.2308571428571429e-05,
      "loss": 0.0165,
      "step": 6730
    },
    {
      "epoch": 3.8514285714285714,
      "grad_norm": 0.03719381242990494,
      "learning_rate": 1.229714285714286e-05,
      "loss": 0.154,
      "step": 6740
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 0.06475181877613068,
      "learning_rate": 1.2285714285714288e-05,
      "loss": 0.0564,
      "step": 6750
    },
    {
      "epoch": 3.862857142857143,
      "grad_norm": 0.352855920791626,
      "learning_rate": 1.2274285714285716e-05,
      "loss": 0.0059,
      "step": 6760
    },
    {
      "epoch": 3.8685714285714283,
      "grad_norm": 0.004596400540322065,
      "learning_rate": 1.2262857142857143e-05,
      "loss": 0.0338,
      "step": 6770
    },
    {
      "epoch": 3.8742857142857146,
      "grad_norm": 0.013818339444696903,
      "learning_rate": 1.2251428571428571e-05,
      "loss": 0.028,
      "step": 6780
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.023622095584869385,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.0833,
      "step": 6790
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 0.010053635574877262,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.1404,
      "step": 6800
    },
    {
      "epoch": 3.8914285714285715,
      "grad_norm": 0.0704096257686615,
      "learning_rate": 1.2217142857142858e-05,
      "loss": 0.0328,
      "step": 6810
    },
    {
      "epoch": 3.8971428571428572,
      "grad_norm": 0.04138719663023949,
      "learning_rate": 1.2205714285714287e-05,
      "loss": 0.0255,
      "step": 6820
    },
    {
      "epoch": 3.902857142857143,
      "grad_norm": 0.232254758477211,
      "learning_rate": 1.2194285714285717e-05,
      "loss": 0.0238,
      "step": 6830
    },
    {
      "epoch": 3.9085714285714284,
      "grad_norm": 0.01003242563456297,
      "learning_rate": 1.2182857142857144e-05,
      "loss": 0.0015,
      "step": 6840
    },
    {
      "epoch": 3.914285714285714,
      "grad_norm": 0.04025939106941223,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.0004,
      "step": 6850
    },
    {
      "epoch": 3.92,
      "grad_norm": 15.591384887695312,
      "learning_rate": 1.216e-05,
      "loss": 0.0183,
      "step": 6860
    },
    {
      "epoch": 3.9257142857142857,
      "grad_norm": 0.07515290379524231,
      "learning_rate": 1.2148571428571429e-05,
      "loss": 0.0004,
      "step": 6870
    },
    {
      "epoch": 3.9314285714285715,
      "grad_norm": 0.0044641438871622086,
      "learning_rate": 1.2137142857142859e-05,
      "loss": 0.0611,
      "step": 6880
    },
    {
      "epoch": 3.9371428571428573,
      "grad_norm": 0.0171878170222044,
      "learning_rate": 1.2125714285714287e-05,
      "loss": 0.0001,
      "step": 6890
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 0.019635295495390892,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.0139,
      "step": 6900
    },
    {
      "epoch": 3.9485714285714284,
      "grad_norm": 0.00843170378357172,
      "learning_rate": 1.2102857142857143e-05,
      "loss": 0.0012,
      "step": 6910
    },
    {
      "epoch": 3.954285714285714,
      "grad_norm": 0.08585172146558762,
      "learning_rate": 1.2091428571428571e-05,
      "loss": 0.0122,
      "step": 6920
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.0018778415396809578,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.0009,
      "step": 6930
    },
    {
      "epoch": 3.9657142857142857,
      "grad_norm": 22.710098266601562,
      "learning_rate": 1.206857142857143e-05,
      "loss": 0.0504,
      "step": 6940
    },
    {
      "epoch": 3.9714285714285715,
      "grad_norm": 0.0009059446165338159,
      "learning_rate": 1.2057142857142858e-05,
      "loss": 0.0073,
      "step": 6950
    },
    {
      "epoch": 3.977142857142857,
      "grad_norm": 29.736217498779297,
      "learning_rate": 1.2045714285714287e-05,
      "loss": 0.0294,
      "step": 6960
    },
    {
      "epoch": 3.982857142857143,
      "grad_norm": 10.647730827331543,
      "learning_rate": 1.2034285714285717e-05,
      "loss": 0.0623,
      "step": 6970
    },
    {
      "epoch": 3.9885714285714284,
      "grad_norm": 0.009304310195147991,
      "learning_rate": 1.2022857142857143e-05,
      "loss": 0.0449,
      "step": 6980
    },
    {
      "epoch": 3.994285714285714,
      "grad_norm": 0.01230853982269764,
      "learning_rate": 1.2011428571428572e-05,
      "loss": 0.0839,
      "step": 6990
    },
    {
      "epoch": 4.0,
      "grad_norm": 11.94773006439209,
      "learning_rate": 1.2e-05,
      "loss": 0.0511,
      "step": 7000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9903074866310161,
      "eval_f1": 0.9428007889546351,
      "eval_loss": 0.050441619008779526,
      "eval_precision": 0.9598393574297188,
      "eval_recall": 0.9263565891472868,
      "eval_runtime": 51.9636,
      "eval_samples_per_second": 115.466,
      "eval_steps_per_second": 3.618,
      "step": 7000
    },
    {
      "epoch": 4.005714285714285,
      "grad_norm": 0.14597593247890472,
      "learning_rate": 1.1988571428571429e-05,
      "loss": 0.0003,
      "step": 7010
    },
    {
      "epoch": 4.011428571428572,
      "grad_norm": 0.02301626093685627,
      "learning_rate": 1.1977142857142859e-05,
      "loss": 0.0007,
      "step": 7020
    },
    {
      "epoch": 4.017142857142857,
      "grad_norm": 0.010809461586177349,
      "learning_rate": 1.1965714285714287e-05,
      "loss": 0.0013,
      "step": 7030
    },
    {
      "epoch": 4.022857142857143,
      "grad_norm": 1.0823540687561035,
      "learning_rate": 1.1954285714285716e-05,
      "loss": 0.0232,
      "step": 7040
    },
    {
      "epoch": 4.0285714285714285,
      "grad_norm": 0.0031199513468891382,
      "learning_rate": 1.1942857142857144e-05,
      "loss": 0.0127,
      "step": 7050
    },
    {
      "epoch": 4.034285714285715,
      "grad_norm": 0.029392603784799576,
      "learning_rate": 1.1931428571428571e-05,
      "loss": 0.0017,
      "step": 7060
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.008978971280157566,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.0005,
      "step": 7070
    },
    {
      "epoch": 4.045714285714285,
      "grad_norm": 0.008564779534935951,
      "learning_rate": 1.190857142857143e-05,
      "loss": 0.0001,
      "step": 7080
    },
    {
      "epoch": 4.051428571428572,
      "grad_norm": 0.0026349176187068224,
      "learning_rate": 1.1897142857142858e-05,
      "loss": 0.0002,
      "step": 7090
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 0.15003830194473267,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 0.025,
      "step": 7100
    },
    {
      "epoch": 4.062857142857143,
      "grad_norm": 0.0027860570698976517,
      "learning_rate": 1.1874285714285717e-05,
      "loss": 0.0001,
      "step": 7110
    },
    {
      "epoch": 4.0685714285714285,
      "grad_norm": 0.0013893815921619534,
      "learning_rate": 1.1862857142857145e-05,
      "loss": 0.0001,
      "step": 7120
    },
    {
      "epoch": 4.074285714285715,
      "grad_norm": 0.0022960836067795753,
      "learning_rate": 1.1851428571428572e-05,
      "loss": 0.0002,
      "step": 7130
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.002434713067486882,
      "learning_rate": 1.184e-05,
      "loss": 0.0105,
      "step": 7140
    },
    {
      "epoch": 4.085714285714285,
      "grad_norm": 0.05971410498023033,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.0001,
      "step": 7150
    },
    {
      "epoch": 4.091428571428572,
      "grad_norm": 0.0184862669557333,
      "learning_rate": 1.1817142857142859e-05,
      "loss": 0.0279,
      "step": 7160
    },
    {
      "epoch": 4.097142857142857,
      "grad_norm": 0.009344283491373062,
      "learning_rate": 1.1805714285714287e-05,
      "loss": 0.0001,
      "step": 7170
    },
    {
      "epoch": 4.102857142857143,
      "grad_norm": 0.0018779304809868336,
      "learning_rate": 1.1794285714285716e-05,
      "loss": 0.0001,
      "step": 7180
    },
    {
      "epoch": 4.1085714285714285,
      "grad_norm": 0.0019514210289344192,
      "learning_rate": 1.1782857142857144e-05,
      "loss": 0.1,
      "step": 7190
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 0.04055147245526314,
      "learning_rate": 1.177142857142857e-05,
      "loss": 0.0002,
      "step": 7200
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.01654200628399849,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.0138,
      "step": 7210
    },
    {
      "epoch": 4.1257142857142854,
      "grad_norm": 0.0015851241769269109,
      "learning_rate": 1.174857142857143e-05,
      "loss": 0.0002,
      "step": 7220
    },
    {
      "epoch": 4.131428571428572,
      "grad_norm": 0.001217127894051373,
      "learning_rate": 1.1737142857142858e-05,
      "loss": 0.0,
      "step": 7230
    },
    {
      "epoch": 4.137142857142857,
      "grad_norm": 0.005096531007438898,
      "learning_rate": 1.1725714285714286e-05,
      "loss": 0.0278,
      "step": 7240
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 35.024112701416016,
      "learning_rate": 1.1714285714285716e-05,
      "loss": 0.0299,
      "step": 7250
    },
    {
      "epoch": 4.148571428571429,
      "grad_norm": 0.034359049052000046,
      "learning_rate": 1.1702857142857145e-05,
      "loss": 0.0001,
      "step": 7260
    },
    {
      "epoch": 4.154285714285714,
      "grad_norm": 0.006654868833720684,
      "learning_rate": 1.1691428571428572e-05,
      "loss": 0.0001,
      "step": 7270
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.012797056697309017,
      "learning_rate": 1.168e-05,
      "loss": 0.0263,
      "step": 7280
    },
    {
      "epoch": 4.1657142857142855,
      "grad_norm": 20.6877384185791,
      "learning_rate": 1.1668571428571428e-05,
      "loss": 0.0364,
      "step": 7290
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 0.5072633028030396,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.0002,
      "step": 7300
    },
    {
      "epoch": 4.177142857142857,
      "grad_norm": 0.00296373525634408,
      "learning_rate": 1.1645714285714287e-05,
      "loss": 0.023,
      "step": 7310
    },
    {
      "epoch": 4.182857142857143,
      "grad_norm": 0.02939336746931076,
      "learning_rate": 1.1634285714285715e-05,
      "loss": 0.0001,
      "step": 7320
    },
    {
      "epoch": 4.188571428571429,
      "grad_norm": 0.04737721011042595,
      "learning_rate": 1.1622857142857144e-05,
      "loss": 0.0001,
      "step": 7330
    },
    {
      "epoch": 4.194285714285714,
      "grad_norm": 0.002093601506203413,
      "learning_rate": 1.161142857142857e-05,
      "loss": 0.0,
      "step": 7340
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.000567261187825352,
      "learning_rate": 1.16e-05,
      "loss": 0.0001,
      "step": 7350
    },
    {
      "epoch": 4.2057142857142855,
      "grad_norm": 0.007875097915530205,
      "learning_rate": 1.158857142857143e-05,
      "loss": 0.0387,
      "step": 7360
    },
    {
      "epoch": 4.211428571428572,
      "grad_norm": 0.005895700305700302,
      "learning_rate": 1.1577142857142858e-05,
      "loss": 0.0,
      "step": 7370
    },
    {
      "epoch": 4.217142857142857,
      "grad_norm": 0.006754730828106403,
      "learning_rate": 1.1565714285714286e-05,
      "loss": 0.0001,
      "step": 7380
    },
    {
      "epoch": 4.222857142857142,
      "grad_norm": 0.030534878373146057,
      "learning_rate": 1.1554285714285716e-05,
      "loss": 0.0,
      "step": 7390
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 0.002833332633599639,
      "learning_rate": 1.1542857142857145e-05,
      "loss": 0.0154,
      "step": 7400
    },
    {
      "epoch": 4.234285714285714,
      "grad_norm": 5.967689037322998,
      "learning_rate": 1.1531428571428573e-05,
      "loss": 0.002,
      "step": 7410
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.0006055250996723771,
      "learning_rate": 1.152e-05,
      "loss": 0.0516,
      "step": 7420
    },
    {
      "epoch": 4.2457142857142856,
      "grad_norm": 0.0006676566554233432,
      "learning_rate": 1.1508571428571428e-05,
      "loss": 0.0002,
      "step": 7430
    },
    {
      "epoch": 4.251428571428572,
      "grad_norm": 0.0009412558283656836,
      "learning_rate": 1.1497142857142858e-05,
      "loss": 0.0295,
      "step": 7440
    },
    {
      "epoch": 4.257142857142857,
      "grad_norm": 0.0034183289390057325,
      "learning_rate": 1.1485714285714287e-05,
      "loss": 0.0002,
      "step": 7450
    },
    {
      "epoch": 4.2628571428571425,
      "grad_norm": 0.000681876263115555,
      "learning_rate": 1.1474285714285715e-05,
      "loss": 0.0014,
      "step": 7460
    },
    {
      "epoch": 4.268571428571429,
      "grad_norm": 0.01160711981356144,
      "learning_rate": 1.1462857142857144e-05,
      "loss": 0.0,
      "step": 7470
    },
    {
      "epoch": 4.274285714285714,
      "grad_norm": 0.014383235946297646,
      "learning_rate": 1.1451428571428574e-05,
      "loss": 0.0005,
      "step": 7480
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.013470210134983063,
      "learning_rate": 1.144e-05,
      "loss": 0.0,
      "step": 7490
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.0011224433546885848,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0336,
      "step": 7500
    },
    {
      "epoch": 4.291428571428572,
      "grad_norm": 19.168323516845703,
      "learning_rate": 1.1417142857142857e-05,
      "loss": 0.0305,
      "step": 7510
    },
    {
      "epoch": 4.297142857142857,
      "grad_norm": 0.0012307196157053113,
      "learning_rate": 1.1405714285714286e-05,
      "loss": 0.0044,
      "step": 7520
    },
    {
      "epoch": 4.3028571428571425,
      "grad_norm": 47.703304290771484,
      "learning_rate": 1.1394285714285716e-05,
      "loss": 0.0094,
      "step": 7530
    },
    {
      "epoch": 4.308571428571429,
      "grad_norm": 0.006054895929992199,
      "learning_rate": 1.1382857142857144e-05,
      "loss": 0.0321,
      "step": 7540
    },
    {
      "epoch": 4.314285714285714,
      "grad_norm": 30.8623046875,
      "learning_rate": 1.1371428571428573e-05,
      "loss": 0.0078,
      "step": 7550
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.0035865679383277893,
      "learning_rate": 1.136e-05,
      "loss": 0.0457,
      "step": 7560
    },
    {
      "epoch": 4.325714285714286,
      "grad_norm": 0.07039976119995117,
      "learning_rate": 1.1348571428571428e-05,
      "loss": 0.1298,
      "step": 7570
    },
    {
      "epoch": 4.331428571428571,
      "grad_norm": 50.15009689331055,
      "learning_rate": 1.1337142857142858e-05,
      "loss": 0.0534,
      "step": 7580
    },
    {
      "epoch": 4.337142857142857,
      "grad_norm": 0.02422928437590599,
      "learning_rate": 1.1325714285714287e-05,
      "loss": 0.0124,
      "step": 7590
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 0.005309833213686943,
      "learning_rate": 1.1314285714285715e-05,
      "loss": 0.0457,
      "step": 7600
    },
    {
      "epoch": 4.348571428571429,
      "grad_norm": 0.01978965476155281,
      "learning_rate": 1.1302857142857144e-05,
      "loss": 0.0251,
      "step": 7610
    },
    {
      "epoch": 4.354285714285714,
      "grad_norm": 0.046737439930438995,
      "learning_rate": 1.1291428571428574e-05,
      "loss": 0.0504,
      "step": 7620
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.01752602867782116,
      "learning_rate": 1.128e-05,
      "loss": 0.0167,
      "step": 7630
    },
    {
      "epoch": 4.365714285714286,
      "grad_norm": 0.007363943383097649,
      "learning_rate": 1.1268571428571429e-05,
      "loss": 0.0001,
      "step": 7640
    },
    {
      "epoch": 4.371428571428572,
      "grad_norm": 0.004445945378392935,
      "learning_rate": 1.1257142857142857e-05,
      "loss": 0.0002,
      "step": 7650
    },
    {
      "epoch": 4.377142857142857,
      "grad_norm": 0.0008947136229835451,
      "learning_rate": 1.1245714285714286e-05,
      "loss": 0.0001,
      "step": 7660
    },
    {
      "epoch": 4.382857142857143,
      "grad_norm": 0.003688335884362459,
      "learning_rate": 1.1234285714285716e-05,
      "loss": 0.0288,
      "step": 7670
    },
    {
      "epoch": 4.388571428571429,
      "grad_norm": 0.005412994883954525,
      "learning_rate": 1.1222857142857144e-05,
      "loss": 0.0001,
      "step": 7680
    },
    {
      "epoch": 4.394285714285714,
      "grad_norm": 0.003969715908169746,
      "learning_rate": 1.1211428571428573e-05,
      "loss": 0.0001,
      "step": 7690
    },
    {
      "epoch": 4.4,
      "grad_norm": 13.136045455932617,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0381,
      "step": 7700
    },
    {
      "epoch": 4.405714285714286,
      "grad_norm": 0.1811983585357666,
      "learning_rate": 1.1188571428571428e-05,
      "loss": 0.0009,
      "step": 7710
    },
    {
      "epoch": 4.411428571428571,
      "grad_norm": 0.046064991503953934,
      "learning_rate": 1.1177142857142858e-05,
      "loss": 0.0075,
      "step": 7720
    },
    {
      "epoch": 4.417142857142857,
      "grad_norm": 0.0028019314631819725,
      "learning_rate": 1.1165714285714287e-05,
      "loss": 0.0003,
      "step": 7730
    },
    {
      "epoch": 4.422857142857143,
      "grad_norm": 0.003593241795897484,
      "learning_rate": 1.1154285714285715e-05,
      "loss": 0.0515,
      "step": 7740
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.014138019643723965,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 0.0188,
      "step": 7750
    },
    {
      "epoch": 4.434285714285714,
      "grad_norm": 0.0031776169780641794,
      "learning_rate": 1.1131428571428574e-05,
      "loss": 0.0004,
      "step": 7760
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.0059349979273974895,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.0144,
      "step": 7770
    },
    {
      "epoch": 4.445714285714286,
      "grad_norm": 0.013201061636209488,
      "learning_rate": 1.1108571428571429e-05,
      "loss": 0.0001,
      "step": 7780
    },
    {
      "epoch": 4.451428571428571,
      "grad_norm": 0.0037897382862865925,
      "learning_rate": 1.1097142857142857e-05,
      "loss": 0.0498,
      "step": 7790
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 0.13398195803165436,
      "learning_rate": 1.1085714285714286e-05,
      "loss": 0.0001,
      "step": 7800
    },
    {
      "epoch": 4.462857142857143,
      "grad_norm": 0.006192883476614952,
      "learning_rate": 1.1074285714285716e-05,
      "loss": 0.0454,
      "step": 7810
    },
    {
      "epoch": 4.468571428571429,
      "grad_norm": 0.01903424970805645,
      "learning_rate": 1.1062857142857144e-05,
      "loss": 0.0001,
      "step": 7820
    },
    {
      "epoch": 4.474285714285714,
      "grad_norm": 0.0031477573793381453,
      "learning_rate": 1.1051428571428573e-05,
      "loss": 0.0435,
      "step": 7830
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.005563411861658096,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.006,
      "step": 7840
    },
    {
      "epoch": 4.485714285714286,
      "grad_norm": 17.88210678100586,
      "learning_rate": 1.1028571428571428e-05,
      "loss": 0.0159,
      "step": 7850
    },
    {
      "epoch": 4.491428571428571,
      "grad_norm": 0.1562596559524536,
      "learning_rate": 1.1017142857142858e-05,
      "loss": 0.0128,
      "step": 7860
    },
    {
      "epoch": 4.497142857142857,
      "grad_norm": 0.004275858402252197,
      "learning_rate": 1.1005714285714286e-05,
      "loss": 0.042,
      "step": 7870
    },
    {
      "epoch": 4.502857142857143,
      "grad_norm": 0.010007712058722973,
      "learning_rate": 1.0994285714285715e-05,
      "loss": 0.0001,
      "step": 7880
    },
    {
      "epoch": 4.508571428571429,
      "grad_norm": 0.0047253635711967945,
      "learning_rate": 1.0982857142857143e-05,
      "loss": 0.0001,
      "step": 7890
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 0.0014633070677518845,
      "learning_rate": 1.0971428571428573e-05,
      "loss": 0.0002,
      "step": 7900
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.033982135355472565,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.0001,
      "step": 7910
    },
    {
      "epoch": 4.525714285714286,
      "grad_norm": 0.001604737713932991,
      "learning_rate": 1.0948571428571429e-05,
      "loss": 0.0001,
      "step": 7920
    },
    {
      "epoch": 4.531428571428571,
      "grad_norm": 13.549403190612793,
      "learning_rate": 1.0937142857142857e-05,
      "loss": 0.0025,
      "step": 7930
    },
    {
      "epoch": 4.537142857142857,
      "grad_norm": 0.016815070062875748,
      "learning_rate": 1.0925714285714285e-05,
      "loss": 0.0016,
      "step": 7940
    },
    {
      "epoch": 4.542857142857143,
      "grad_norm": 0.06613568216562271,
      "learning_rate": 1.0914285714285716e-05,
      "loss": 0.1814,
      "step": 7950
    },
    {
      "epoch": 4.548571428571429,
      "grad_norm": 22.148183822631836,
      "learning_rate": 1.0902857142857144e-05,
      "loss": 0.0818,
      "step": 7960
    },
    {
      "epoch": 4.554285714285714,
      "grad_norm": 0.0024947947822511196,
      "learning_rate": 1.0891428571428572e-05,
      "loss": 0.0052,
      "step": 7970
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 10.398622512817383,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.0351,
      "step": 7980
    },
    {
      "epoch": 4.565714285714286,
      "grad_norm": 0.005605827551335096,
      "learning_rate": 1.0868571428571431e-05,
      "loss": 0.0035,
      "step": 7990
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.012146557681262493,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 0.0247,
      "step": 8000
    },
    {
      "epoch": 4.577142857142857,
      "grad_norm": 0.016461120918393135,
      "learning_rate": 1.0845714285714286e-05,
      "loss": 0.0436,
      "step": 8010
    },
    {
      "epoch": 4.582857142857143,
      "grad_norm": 1.7600927352905273,
      "learning_rate": 1.0834285714285715e-05,
      "loss": 0.0008,
      "step": 8020
    },
    {
      "epoch": 4.588571428571429,
      "grad_norm": 13.402667045593262,
      "learning_rate": 1.0822857142857143e-05,
      "loss": 0.0062,
      "step": 8030
    },
    {
      "epoch": 4.594285714285714,
      "grad_norm": 0.02158554457128048,
      "learning_rate": 1.0811428571428573e-05,
      "loss": 0.0048,
      "step": 8040
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.06946730613708496,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0398,
      "step": 8050
    },
    {
      "epoch": 4.605714285714286,
      "grad_norm": 0.0019246051087975502,
      "learning_rate": 1.078857142857143e-05,
      "loss": 0.0218,
      "step": 8060
    },
    {
      "epoch": 4.611428571428571,
      "grad_norm": 54.74468994140625,
      "learning_rate": 1.0777142857142857e-05,
      "loss": 0.0168,
      "step": 8070
    },
    {
      "epoch": 4.617142857142857,
      "grad_norm": 0.0004243908333592117,
      "learning_rate": 1.0765714285714285e-05,
      "loss": 0.0015,
      "step": 8080
    },
    {
      "epoch": 4.622857142857143,
      "grad_norm": 0.0006048123468644917,
      "learning_rate": 1.0754285714285715e-05,
      "loss": 0.0155,
      "step": 8090
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 0.3785906732082367,
      "learning_rate": 1.0742857142857144e-05,
      "loss": 0.0881,
      "step": 8100
    },
    {
      "epoch": 4.634285714285714,
      "grad_norm": 0.0019357858691364527,
      "learning_rate": 1.0731428571428572e-05,
      "loss": 0.0237,
      "step": 8110
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.008366747759282589,
      "learning_rate": 1.072e-05,
      "loss": 0.0609,
      "step": 8120
    },
    {
      "epoch": 4.645714285714286,
      "grad_norm": 0.021336708217859268,
      "learning_rate": 1.070857142857143e-05,
      "loss": 0.0008,
      "step": 8130
    },
    {
      "epoch": 4.651428571428571,
      "grad_norm": 0.008963173255324364,
      "learning_rate": 1.0697142857142858e-05,
      "loss": 0.0552,
      "step": 8140
    },
    {
      "epoch": 4.6571428571428575,
      "grad_norm": 0.0036192103289067745,
      "learning_rate": 1.0685714285714286e-05,
      "loss": 0.0002,
      "step": 8150
    },
    {
      "epoch": 4.662857142857143,
      "grad_norm": 11.257292747497559,
      "learning_rate": 1.0674285714285714e-05,
      "loss": 0.0399,
      "step": 8160
    },
    {
      "epoch": 4.668571428571429,
      "grad_norm": 0.00685866130515933,
      "learning_rate": 1.0662857142857143e-05,
      "loss": 0.0011,
      "step": 8170
    },
    {
      "epoch": 4.674285714285714,
      "grad_norm": 0.13523247838020325,
      "learning_rate": 1.0651428571428573e-05,
      "loss": 0.0223,
      "step": 8180
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.5595299005508423,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.0003,
      "step": 8190
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 0.008689368143677711,
      "learning_rate": 1.062857142857143e-05,
      "loss": 0.0501,
      "step": 8200
    },
    {
      "epoch": 4.691428571428571,
      "grad_norm": 0.024385662749409676,
      "learning_rate": 1.0617142857142857e-05,
      "loss": 0.0432,
      "step": 8210
    },
    {
      "epoch": 4.6971428571428575,
      "grad_norm": 0.020255686715245247,
      "learning_rate": 1.0605714285714285e-05,
      "loss": 0.0015,
      "step": 8220
    },
    {
      "epoch": 4.702857142857143,
      "grad_norm": 0.008343130350112915,
      "learning_rate": 1.0594285714285715e-05,
      "loss": 0.0001,
      "step": 8230
    },
    {
      "epoch": 4.708571428571428,
      "grad_norm": 0.0029630293138325214,
      "learning_rate": 1.0582857142857144e-05,
      "loss": 0.0001,
      "step": 8240
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 0.004762416705489159,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 0.0037,
      "step": 8250
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.006983693223446608,
      "learning_rate": 1.056e-05,
      "loss": 0.0002,
      "step": 8260
    },
    {
      "epoch": 4.725714285714286,
      "grad_norm": 25.711097717285156,
      "learning_rate": 1.054857142857143e-05,
      "loss": 0.0236,
      "step": 8270
    },
    {
      "epoch": 4.731428571428571,
      "grad_norm": 15.825028419494629,
      "learning_rate": 1.0537142857142857e-05,
      "loss": 0.0053,
      "step": 8280
    },
    {
      "epoch": 4.737142857142857,
      "grad_norm": 0.006233525928109884,
      "learning_rate": 1.0525714285714286e-05,
      "loss": 0.0012,
      "step": 8290
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 0.005484973546117544,
      "learning_rate": 1.0514285714285714e-05,
      "loss": 0.0004,
      "step": 8300
    },
    {
      "epoch": 4.748571428571428,
      "grad_norm": 0.0008147411863319576,
      "learning_rate": 1.0502857142857143e-05,
      "loss": 0.0019,
      "step": 8310
    },
    {
      "epoch": 4.7542857142857144,
      "grad_norm": 0.005071301944553852,
      "learning_rate": 1.0491428571428573e-05,
      "loss": 0.021,
      "step": 8320
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.004642164334654808,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.0002,
      "step": 8330
    },
    {
      "epoch": 4.765714285714286,
      "grad_norm": 0.001169887138530612,
      "learning_rate": 1.046857142857143e-05,
      "loss": 0.0067,
      "step": 8340
    },
    {
      "epoch": 4.771428571428571,
      "grad_norm": 0.003644804935902357,
      "learning_rate": 1.045714285714286e-05,
      "loss": 0.0299,
      "step": 8350
    },
    {
      "epoch": 4.777142857142858,
      "grad_norm": 0.004124058410525322,
      "learning_rate": 1.0445714285714285e-05,
      "loss": 0.0099,
      "step": 8360
    },
    {
      "epoch": 4.782857142857143,
      "grad_norm": 0.0059679304249584675,
      "learning_rate": 1.0434285714285715e-05,
      "loss": 0.0,
      "step": 8370
    },
    {
      "epoch": 4.788571428571428,
      "grad_norm": 0.016248730942606926,
      "learning_rate": 1.0422857142857143e-05,
      "loss": 0.0,
      "step": 8380
    },
    {
      "epoch": 4.7942857142857145,
      "grad_norm": 0.003516520606353879,
      "learning_rate": 1.0411428571428572e-05,
      "loss": 0.0422,
      "step": 8390
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.0359780490398407,
      "learning_rate": 1.04e-05,
      "loss": 0.0006,
      "step": 8400
    },
    {
      "epoch": 4.805714285714286,
      "grad_norm": 0.015658700838685036,
      "learning_rate": 1.038857142857143e-05,
      "loss": 0.0027,
      "step": 8410
    },
    {
      "epoch": 4.811428571428571,
      "grad_norm": 0.002084242645651102,
      "learning_rate": 1.0377142857142859e-05,
      "loss": 0.0267,
      "step": 8420
    },
    {
      "epoch": 4.817142857142857,
      "grad_norm": 0.005355674773454666,
      "learning_rate": 1.0365714285714286e-05,
      "loss": 0.033,
      "step": 8430
    },
    {
      "epoch": 4.822857142857143,
      "grad_norm": 0.0029262357857078314,
      "learning_rate": 1.0354285714285714e-05,
      "loss": 0.0334,
      "step": 8440
    },
    {
      "epoch": 4.828571428571428,
      "grad_norm": 0.027980981394648552,
      "learning_rate": 1.0342857142857143e-05,
      "loss": 0.0082,
      "step": 8450
    },
    {
      "epoch": 4.8342857142857145,
      "grad_norm": 0.0008309066179208457,
      "learning_rate": 1.0331428571428573e-05,
      "loss": 0.0022,
      "step": 8460
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.03980123996734619,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.0539,
      "step": 8470
    },
    {
      "epoch": 4.845714285714286,
      "grad_norm": 10.657282829284668,
      "learning_rate": 1.030857142857143e-05,
      "loss": 0.062,
      "step": 8480
    },
    {
      "epoch": 4.851428571428571,
      "grad_norm": 0.1975860446691513,
      "learning_rate": 1.029714285714286e-05,
      "loss": 0.0003,
      "step": 8490
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 22.62602996826172,
      "learning_rate": 1.0285714285714285e-05,
      "loss": 0.0121,
      "step": 8500
    },
    {
      "epoch": 4.862857142857143,
      "grad_norm": 0.00404014578089118,
      "learning_rate": 1.0274285714285715e-05,
      "loss": 0.0001,
      "step": 8510
    },
    {
      "epoch": 4.868571428571428,
      "grad_norm": 0.0033734573516994715,
      "learning_rate": 1.0262857142857143e-05,
      "loss": 0.0003,
      "step": 8520
    },
    {
      "epoch": 4.8742857142857146,
      "grad_norm": 0.0006040520966053009,
      "learning_rate": 1.0251428571428572e-05,
      "loss": 0.0001,
      "step": 8530
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.010668989270925522,
      "learning_rate": 1.024e-05,
      "loss": 0.0001,
      "step": 8540
    },
    {
      "epoch": 4.885714285714286,
      "grad_norm": 0.04828682914376259,
      "learning_rate": 1.022857142857143e-05,
      "loss": 0.0002,
      "step": 8550
    },
    {
      "epoch": 4.8914285714285715,
      "grad_norm": 0.00160272850189358,
      "learning_rate": 1.0217142857142859e-05,
      "loss": 0.0,
      "step": 8560
    },
    {
      "epoch": 4.897142857142857,
      "grad_norm": 0.010985425673425198,
      "learning_rate": 1.0205714285714286e-05,
      "loss": 0.0001,
      "step": 8570
    },
    {
      "epoch": 4.902857142857143,
      "grad_norm": 0.0020317297894507647,
      "learning_rate": 1.0194285714285714e-05,
      "loss": 0.0,
      "step": 8580
    },
    {
      "epoch": 4.908571428571428,
      "grad_norm": 0.10632231086492538,
      "learning_rate": 1.0182857142857142e-05,
      "loss": 0.0004,
      "step": 8590
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 0.08849157392978668,
      "learning_rate": 1.0171428571428573e-05,
      "loss": 0.0099,
      "step": 8600
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.08957401663064957,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.0,
      "step": 8610
    },
    {
      "epoch": 4.925714285714285,
      "grad_norm": 0.003314708359539509,
      "learning_rate": 1.014857142857143e-05,
      "loss": 0.0008,
      "step": 8620
    },
    {
      "epoch": 4.9314285714285715,
      "grad_norm": 41.60385513305664,
      "learning_rate": 1.013714285714286e-05,
      "loss": 0.0408,
      "step": 8630
    },
    {
      "epoch": 4.937142857142857,
      "grad_norm": 11.54893970489502,
      "learning_rate": 1.0125714285714288e-05,
      "loss": 0.1616,
      "step": 8640
    },
    {
      "epoch": 4.942857142857143,
      "grad_norm": 0.04411543533205986,
      "learning_rate": 1.0114285714285715e-05,
      "loss": 0.0202,
      "step": 8650
    },
    {
      "epoch": 4.948571428571428,
      "grad_norm": 0.0034897183068096638,
      "learning_rate": 1.0102857142857143e-05,
      "loss": 0.0001,
      "step": 8660
    },
    {
      "epoch": 4.954285714285715,
      "grad_norm": 0.013858565129339695,
      "learning_rate": 1.0091428571428572e-05,
      "loss": 0.0001,
      "step": 8670
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.0007285537431016564,
      "learning_rate": 1.008e-05,
      "loss": 0.0226,
      "step": 8680
    },
    {
      "epoch": 4.965714285714286,
      "grad_norm": 0.0015605331864207983,
      "learning_rate": 1.006857142857143e-05,
      "loss": 0.002,
      "step": 8690
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 0.008191284723579884,
      "learning_rate": 1.0057142857142859e-05,
      "loss": 0.0002,
      "step": 8700
    },
    {
      "epoch": 4.977142857142857,
      "grad_norm": 0.2139115184545517,
      "learning_rate": 1.0045714285714287e-05,
      "loss": 0.0001,
      "step": 8710
    },
    {
      "epoch": 4.982857142857143,
      "grad_norm": 0.0037947064265608788,
      "learning_rate": 1.0034285714285714e-05,
      "loss": 0.0,
      "step": 8720
    },
    {
      "epoch": 4.988571428571428,
      "grad_norm": 0.002089675283059478,
      "learning_rate": 1.0022857142857142e-05,
      "loss": 0.0001,
      "step": 8730
    },
    {
      "epoch": 4.994285714285715,
      "grad_norm": 0.0013627249281853437,
      "learning_rate": 1.0011428571428572e-05,
      "loss": 0.02,
      "step": 8740
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0013723040465265512,
      "learning_rate": 1e-05,
      "loss": 0.0051,
      "step": 8750
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9904745989304813,
      "eval_f1": 0.9444985394352483,
      "eval_loss": 0.05630466714501381,
      "eval_precision": 0.949119373776908,
      "eval_recall": 0.939922480620155,
      "eval_runtime": 51.1378,
      "eval_samples_per_second": 117.33,
      "eval_steps_per_second": 3.676,
      "step": 8750
    },
    {
      "epoch": 5.005714285714285,
      "grad_norm": 0.0030183701310306787,
      "learning_rate": 9.98857142857143e-06,
      "loss": 0.0007,
      "step": 8760
    },
    {
      "epoch": 5.011428571428572,
      "grad_norm": 0.0023154316004365683,
      "learning_rate": 9.977142857142858e-06,
      "loss": 0.0001,
      "step": 8770
    },
    {
      "epoch": 5.017142857142857,
      "grad_norm": 0.005254108924418688,
      "learning_rate": 9.965714285714286e-06,
      "loss": 0.0335,
      "step": 8780
    },
    {
      "epoch": 5.022857142857143,
      "grad_norm": 0.2899019420146942,
      "learning_rate": 9.954285714285715e-06,
      "loss": 0.0106,
      "step": 8790
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 0.20363262295722961,
      "learning_rate": 9.942857142857145e-06,
      "loss": 0.0004,
      "step": 8800
    },
    {
      "epoch": 5.034285714285715,
      "grad_norm": 0.0017129115294665098,
      "learning_rate": 9.931428571428571e-06,
      "loss": 0.0427,
      "step": 8810
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.0003913608961738646,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.0002,
      "step": 8820
    },
    {
      "epoch": 5.045714285714285,
      "grad_norm": 0.0007261387654580176,
      "learning_rate": 9.90857142857143e-06,
      "loss": 0.0045,
      "step": 8830
    },
    {
      "epoch": 5.051428571428572,
      "grad_norm": 0.011391487903892994,
      "learning_rate": 9.897142857142858e-06,
      "loss": 0.0001,
      "step": 8840
    },
    {
      "epoch": 5.057142857142857,
      "grad_norm": 0.010310783982276917,
      "learning_rate": 9.885714285714287e-06,
      "loss": 0.0348,
      "step": 8850
    },
    {
      "epoch": 5.062857142857143,
      "grad_norm": 0.0015309039736166596,
      "learning_rate": 9.874285714285715e-06,
      "loss": 0.0001,
      "step": 8860
    },
    {
      "epoch": 5.0685714285714285,
      "grad_norm": 8.518332481384277,
      "learning_rate": 9.862857142857144e-06,
      "loss": 0.0053,
      "step": 8870
    },
    {
      "epoch": 5.074285714285715,
      "grad_norm": 0.0013960441574454308,
      "learning_rate": 9.851428571428572e-06,
      "loss": 0.0,
      "step": 8880
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.009741349145770073,
      "learning_rate": 9.84e-06,
      "loss": 0.0,
      "step": 8890
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 0.0027033621445298195,
      "learning_rate": 9.828571428571429e-06,
      "loss": 0.0001,
      "step": 8900
    },
    {
      "epoch": 5.091428571428572,
      "grad_norm": 0.0059251924976706505,
      "learning_rate": 9.81714285714286e-06,
      "loss": 0.0052,
      "step": 8910
    },
    {
      "epoch": 5.097142857142857,
      "grad_norm": 39.33042526245117,
      "learning_rate": 9.805714285714286e-06,
      "loss": 0.0263,
      "step": 8920
    },
    {
      "epoch": 5.102857142857143,
      "grad_norm": 0.0027549888473004103,
      "learning_rate": 9.794285714285714e-06,
      "loss": 0.0,
      "step": 8930
    },
    {
      "epoch": 5.1085714285714285,
      "grad_norm": 0.0012871240032836795,
      "learning_rate": 9.782857142857145e-06,
      "loss": 0.0002,
      "step": 8940
    },
    {
      "epoch": 5.114285714285714,
      "grad_norm": 9.762740135192871,
      "learning_rate": 9.771428571428571e-06,
      "loss": 0.0209,
      "step": 8950
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.06418778747320175,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.0001,
      "step": 8960
    },
    {
      "epoch": 5.1257142857142854,
      "grad_norm": 0.0005419256631284952,
      "learning_rate": 9.74857142857143e-06,
      "loss": 0.0,
      "step": 8970
    },
    {
      "epoch": 5.131428571428572,
      "grad_norm": 0.09150548279285431,
      "learning_rate": 9.737142857142858e-06,
      "loss": 0.006,
      "step": 8980
    },
    {
      "epoch": 5.137142857142857,
      "grad_norm": 0.0013315018732100725,
      "learning_rate": 9.725714285714287e-06,
      "loss": 0.0024,
      "step": 8990
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.0010167740983888507,
      "learning_rate": 9.714285714285715e-06,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 5.148571428571429,
      "grad_norm": 0.0010374418925493956,
      "learning_rate": 9.702857142857144e-06,
      "loss": 0.0,
      "step": 9010
    },
    {
      "epoch": 5.154285714285714,
      "grad_norm": 0.0005600271979346871,
      "learning_rate": 9.691428571428572e-06,
      "loss": 0.0,
      "step": 9020
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.0016023489879444242,
      "learning_rate": 9.68e-06,
      "loss": 0.0537,
      "step": 9030
    },
    {
      "epoch": 5.1657142857142855,
      "grad_norm": 0.000677010859362781,
      "learning_rate": 9.668571428571429e-06,
      "loss": 0.0,
      "step": 9040
    },
    {
      "epoch": 5.171428571428572,
      "grad_norm": 0.001161825261078775,
      "learning_rate": 9.657142857142859e-06,
      "loss": 0.0,
      "step": 9050
    },
    {
      "epoch": 5.177142857142857,
      "grad_norm": 0.3144776225090027,
      "learning_rate": 9.645714285714286e-06,
      "loss": 0.0002,
      "step": 9060
    },
    {
      "epoch": 5.182857142857143,
      "grad_norm": 0.006127552129328251,
      "learning_rate": 9.634285714285714e-06,
      "loss": 0.0002,
      "step": 9070
    },
    {
      "epoch": 5.188571428571429,
      "grad_norm": 0.8455358147621155,
      "learning_rate": 9.622857142857144e-06,
      "loss": 0.0002,
      "step": 9080
    },
    {
      "epoch": 5.194285714285714,
      "grad_norm": 0.0005485012079589069,
      "learning_rate": 9.611428571428573e-06,
      "loss": 0.0011,
      "step": 9090
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.0003375932283233851,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0001,
      "step": 9100
    },
    {
      "epoch": 5.2057142857142855,
      "grad_norm": 0.0027011651545763016,
      "learning_rate": 9.58857142857143e-06,
      "loss": 0.0549,
      "step": 9110
    },
    {
      "epoch": 5.211428571428572,
      "grad_norm": 0.005358085036277771,
      "learning_rate": 9.577142857142858e-06,
      "loss": 0.0085,
      "step": 9120
    },
    {
      "epoch": 5.217142857142857,
      "grad_norm": 0.0007369386148639023,
      "learning_rate": 9.565714285714287e-06,
      "loss": 0.0108,
      "step": 9130
    },
    {
      "epoch": 5.222857142857142,
      "grad_norm": 0.021065933629870415,
      "learning_rate": 9.554285714285715e-06,
      "loss": 0.0068,
      "step": 9140
    },
    {
      "epoch": 5.228571428571429,
      "grad_norm": 0.0014812737936154008,
      "learning_rate": 9.542857142857143e-06,
      "loss": 0.023,
      "step": 9150
    },
    {
      "epoch": 5.234285714285714,
      "grad_norm": 0.0007361521129496396,
      "learning_rate": 9.531428571428572e-06,
      "loss": 0.0,
      "step": 9160
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.1254347413778305,
      "learning_rate": 9.52e-06,
      "loss": 0.016,
      "step": 9170
    },
    {
      "epoch": 5.2457142857142856,
      "grad_norm": 0.08325976133346558,
      "learning_rate": 9.508571428571429e-06,
      "loss": 0.0001,
      "step": 9180
    },
    {
      "epoch": 5.251428571428572,
      "grad_norm": 0.003462796099483967,
      "learning_rate": 9.497142857142859e-06,
      "loss": 0.0,
      "step": 9190
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 0.0006404617452062666,
      "learning_rate": 9.485714285714287e-06,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 5.2628571428571425,
      "grad_norm": 0.0018175897421315312,
      "learning_rate": 9.474285714285714e-06,
      "loss": 0.0665,
      "step": 9210
    },
    {
      "epoch": 5.268571428571429,
      "grad_norm": 0.009201892651617527,
      "learning_rate": 9.462857142857144e-06,
      "loss": 0.0002,
      "step": 9220
    },
    {
      "epoch": 5.274285714285714,
      "grad_norm": 0.005814201198518276,
      "learning_rate": 9.451428571428573e-06,
      "loss": 0.0002,
      "step": 9230
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.0023695770651102066,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.0051,
      "step": 9240
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.006515116896480322,
      "learning_rate": 9.42857142857143e-06,
      "loss": 0.0002,
      "step": 9250
    },
    {
      "epoch": 5.291428571428572,
      "grad_norm": 0.004407163243740797,
      "learning_rate": 9.417142857142858e-06,
      "loss": 0.0006,
      "step": 9260
    },
    {
      "epoch": 5.297142857142857,
      "grad_norm": 0.0006060252781026065,
      "learning_rate": 9.405714285714286e-06,
      "loss": 0.0001,
      "step": 9270
    },
    {
      "epoch": 5.3028571428571425,
      "grad_norm": 0.013618092983961105,
      "learning_rate": 9.394285714285715e-06,
      "loss": 0.0275,
      "step": 9280
    },
    {
      "epoch": 5.308571428571429,
      "grad_norm": 0.0008152562659233809,
      "learning_rate": 9.382857142857143e-06,
      "loss": 0.0,
      "step": 9290
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 0.060735855251550674,
      "learning_rate": 9.371428571428572e-06,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.0004296177066862583,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.0001,
      "step": 9310
    },
    {
      "epoch": 5.325714285714286,
      "grad_norm": 0.03137350454926491,
      "learning_rate": 9.348571428571429e-06,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 5.331428571428571,
      "grad_norm": 0.0006139736506156623,
      "learning_rate": 9.337142857142859e-06,
      "loss": 0.0481,
      "step": 9330
    },
    {
      "epoch": 5.337142857142857,
      "grad_norm": 0.0017905945423990488,
      "learning_rate": 9.325714285714287e-06,
      "loss": 0.0351,
      "step": 9340
    },
    {
      "epoch": 5.3428571428571425,
      "grad_norm": 0.0065316492691636086,
      "learning_rate": 9.314285714285714e-06,
      "loss": 0.0065,
      "step": 9350
    },
    {
      "epoch": 5.348571428571429,
      "grad_norm": 0.0031099666375666857,
      "learning_rate": 9.302857142857144e-06,
      "loss": 0.0001,
      "step": 9360
    },
    {
      "epoch": 5.354285714285714,
      "grad_norm": 0.0017557719256728888,
      "learning_rate": 9.291428571428572e-06,
      "loss": 0.0,
      "step": 9370
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.0048438808880746365,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.0001,
      "step": 9380
    },
    {
      "epoch": 5.365714285714286,
      "grad_norm": 0.005633202847093344,
      "learning_rate": 9.26857142857143e-06,
      "loss": 0.0001,
      "step": 9390
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 1.0784834623336792,
      "learning_rate": 9.257142857142858e-06,
      "loss": 0.0002,
      "step": 9400
    },
    {
      "epoch": 5.377142857142857,
      "grad_norm": 0.0003129261313006282,
      "learning_rate": 9.245714285714286e-06,
      "loss": 0.0003,
      "step": 9410
    },
    {
      "epoch": 5.382857142857143,
      "grad_norm": 0.0007433061837218702,
      "learning_rate": 9.234285714285715e-06,
      "loss": 0.0001,
      "step": 9420
    },
    {
      "epoch": 5.388571428571429,
      "grad_norm": 0.001538170618005097,
      "learning_rate": 9.222857142857143e-06,
      "loss": 0.0007,
      "step": 9430
    },
    {
      "epoch": 5.394285714285714,
      "grad_norm": 0.0002109538036165759,
      "learning_rate": 9.211428571428572e-06,
      "loss": 0.0,
      "step": 9440
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.0006138509488664567,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0001,
      "step": 9450
    },
    {
      "epoch": 5.405714285714286,
      "grad_norm": 0.00037442249595187604,
      "learning_rate": 9.188571428571428e-06,
      "loss": 0.0,
      "step": 9460
    },
    {
      "epoch": 5.411428571428571,
      "grad_norm": 0.003993692342191935,
      "learning_rate": 9.177142857142859e-06,
      "loss": 0.0,
      "step": 9470
    },
    {
      "epoch": 5.417142857142857,
      "grad_norm": 0.000667631218675524,
      "learning_rate": 9.165714285714287e-06,
      "loss": 0.0,
      "step": 9480
    },
    {
      "epoch": 5.422857142857143,
      "grad_norm": 0.0038002568762749434,
      "learning_rate": 9.154285714285715e-06,
      "loss": 0.0033,
      "step": 9490
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.000573960947804153,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 5.434285714285714,
      "grad_norm": 0.001299964846111834,
      "learning_rate": 9.131428571428572e-06,
      "loss": 0.0,
      "step": 9510
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.0009595986921340227,
      "learning_rate": 9.12e-06,
      "loss": 0.0,
      "step": 9520
    },
    {
      "epoch": 5.445714285714286,
      "grad_norm": 0.0003428052004892379,
      "learning_rate": 9.10857142857143e-06,
      "loss": 0.0,
      "step": 9530
    },
    {
      "epoch": 5.451428571428571,
      "grad_norm": 0.0012059536529704928,
      "learning_rate": 9.097142857142858e-06,
      "loss": 0.0,
      "step": 9540
    },
    {
      "epoch": 5.457142857142857,
      "grad_norm": 0.0003208823036402464,
      "learning_rate": 9.085714285714286e-06,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 5.462857142857143,
      "grad_norm": 0.0016132778255268931,
      "learning_rate": 9.074285714285716e-06,
      "loss": 0.0,
      "step": 9560
    },
    {
      "epoch": 5.468571428571429,
      "grad_norm": 0.0007473170990124345,
      "learning_rate": 9.062857142857143e-06,
      "loss": 0.0,
      "step": 9570
    },
    {
      "epoch": 5.474285714285714,
      "grad_norm": 0.0006082836189307272,
      "learning_rate": 9.051428571428571e-06,
      "loss": 0.0344,
      "step": 9580
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.0006246707052923739,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.0073,
      "step": 9590
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 0.002044565975666046,
      "learning_rate": 9.028571428571428e-06,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 5.491428571428571,
      "grad_norm": 0.0006864931201562285,
      "learning_rate": 9.017142857142858e-06,
      "loss": 0.0002,
      "step": 9610
    },
    {
      "epoch": 5.497142857142857,
      "grad_norm": 0.0008316017920151353,
      "learning_rate": 9.005714285714287e-06,
      "loss": 0.0537,
      "step": 9620
    },
    {
      "epoch": 5.502857142857143,
      "grad_norm": 0.0009114596759900451,
      "learning_rate": 8.994285714285715e-06,
      "loss": 0.0,
      "step": 9630
    },
    {
      "epoch": 5.508571428571429,
      "grad_norm": 0.0002980981080327183,
      "learning_rate": 8.982857142857144e-06,
      "loss": 0.0049,
      "step": 9640
    },
    {
      "epoch": 5.514285714285714,
      "grad_norm": 0.0002453574270475656,
      "learning_rate": 8.971428571428572e-06,
      "loss": 0.0,
      "step": 9650
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.21944497525691986,
      "learning_rate": 8.96e-06,
      "loss": 0.0201,
      "step": 9660
    },
    {
      "epoch": 5.525714285714286,
      "grad_norm": 0.011575364507734776,
      "learning_rate": 8.948571428571429e-06,
      "loss": 0.0029,
      "step": 9670
    },
    {
      "epoch": 5.531428571428571,
      "grad_norm": 0.01053941622376442,
      "learning_rate": 8.937142857142857e-06,
      "loss": 0.0001,
      "step": 9680
    },
    {
      "epoch": 5.537142857142857,
      "grad_norm": 0.0013651970075443387,
      "learning_rate": 8.925714285714286e-06,
      "loss": 0.0001,
      "step": 9690
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 0.06396022439002991,
      "learning_rate": 8.914285714285716e-06,
      "loss": 0.0005,
      "step": 9700
    },
    {
      "epoch": 5.548571428571429,
      "grad_norm": 0.0017482696566730738,
      "learning_rate": 8.902857142857143e-06,
      "loss": 0.0445,
      "step": 9710
    },
    {
      "epoch": 5.554285714285714,
      "grad_norm": 19.3223876953125,
      "learning_rate": 8.891428571428571e-06,
      "loss": 0.0194,
      "step": 9720
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 0.00020498941012192518,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.0,
      "step": 9730
    },
    {
      "epoch": 5.565714285714286,
      "grad_norm": 0.005745842587202787,
      "learning_rate": 8.86857142857143e-06,
      "loss": 0.0026,
      "step": 9740
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.0008110525668598711,
      "learning_rate": 8.857142857142858e-06,
      "loss": 0.0,
      "step": 9750
    },
    {
      "epoch": 5.577142857142857,
      "grad_norm": 0.0007653941283933818,
      "learning_rate": 8.845714285714287e-06,
      "loss": 0.0,
      "step": 9760
    },
    {
      "epoch": 5.582857142857143,
      "grad_norm": 0.005266315769404173,
      "learning_rate": 8.834285714285715e-06,
      "loss": 0.0,
      "step": 9770
    },
    {
      "epoch": 5.588571428571429,
      "grad_norm": 0.00025591038865968585,
      "learning_rate": 8.822857142857144e-06,
      "loss": 0.0001,
      "step": 9780
    },
    {
      "epoch": 5.594285714285714,
      "grad_norm": 0.0002876323997043073,
      "learning_rate": 8.811428571428572e-06,
      "loss": 0.0001,
      "step": 9790
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.0002829764853231609,
      "learning_rate": 8.8e-06,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 5.605714285714286,
      "grad_norm": 0.00252077030017972,
      "learning_rate": 8.788571428571429e-06,
      "loss": 0.0562,
      "step": 9810
    },
    {
      "epoch": 5.611428571428571,
      "grad_norm": 0.011690782383084297,
      "learning_rate": 8.777142857142857e-06,
      "loss": 0.0137,
      "step": 9820
    },
    {
      "epoch": 5.617142857142857,
      "grad_norm": 0.003175143850967288,
      "learning_rate": 8.765714285714286e-06,
      "loss": 0.0001,
      "step": 9830
    },
    {
      "epoch": 5.622857142857143,
      "grad_norm": 0.002400451572611928,
      "learning_rate": 8.754285714285716e-06,
      "loss": 0.0193,
      "step": 9840
    },
    {
      "epoch": 5.628571428571428,
      "grad_norm": 0.0008815090986900032,
      "learning_rate": 8.742857142857144e-06,
      "loss": 0.0003,
      "step": 9850
    },
    {
      "epoch": 5.634285714285714,
      "grad_norm": 0.019281217828392982,
      "learning_rate": 8.731428571428571e-06,
      "loss": 0.031,
      "step": 9860
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.01731640100479126,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.0,
      "step": 9870
    },
    {
      "epoch": 5.645714285714286,
      "grad_norm": 0.000586855283472687,
      "learning_rate": 8.70857142857143e-06,
      "loss": 0.0007,
      "step": 9880
    },
    {
      "epoch": 5.651428571428571,
      "grad_norm": 0.010827050544321537,
      "learning_rate": 8.697142857142858e-06,
      "loss": 0.0,
      "step": 9890
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 0.006439457647502422,
      "learning_rate": 8.685714285714287e-06,
      "loss": 0.0,
      "step": 9900
    },
    {
      "epoch": 5.662857142857143,
      "grad_norm": 0.000447578466264531,
      "learning_rate": 8.674285714285715e-06,
      "loss": 0.0001,
      "step": 9910
    },
    {
      "epoch": 5.668571428571429,
      "grad_norm": 0.26533806324005127,
      "learning_rate": 8.662857142857143e-06,
      "loss": 0.0005,
      "step": 9920
    },
    {
      "epoch": 5.674285714285714,
      "grad_norm": 0.0006412561633624136,
      "learning_rate": 8.651428571428572e-06,
      "loss": 0.0001,
      "step": 9930
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.005376108456403017,
      "learning_rate": 8.64e-06,
      "loss": 0.0245,
      "step": 9940
    },
    {
      "epoch": 5.685714285714286,
      "grad_norm": 2.4594178199768066,
      "learning_rate": 8.628571428571429e-06,
      "loss": 0.0773,
      "step": 9950
    },
    {
      "epoch": 5.691428571428571,
      "grad_norm": 0.0008415757911279798,
      "learning_rate": 8.617142857142859e-06,
      "loss": 0.0001,
      "step": 9960
    },
    {
      "epoch": 5.6971428571428575,
      "grad_norm": 0.00046071343240328133,
      "learning_rate": 8.605714285714286e-06,
      "loss": 0.0019,
      "step": 9970
    },
    {
      "epoch": 5.702857142857143,
      "grad_norm": 0.0015572092961519957,
      "learning_rate": 8.594285714285716e-06,
      "loss": 0.0115,
      "step": 9980
    },
    {
      "epoch": 5.708571428571428,
      "grad_norm": 5.64646053314209,
      "learning_rate": 8.582857142857144e-06,
      "loss": 0.0005,
      "step": 9990
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.0034978517796844244,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.0005,
      "step": 10000
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.0005341226351447403,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.0006,
      "step": 10010
    },
    {
      "epoch": 5.725714285714286,
      "grad_norm": 0.0020022878888994455,
      "learning_rate": 8.54857142857143e-06,
      "loss": 0.0,
      "step": 10020
    },
    {
      "epoch": 5.731428571428571,
      "grad_norm": 0.0006428425549529493,
      "learning_rate": 8.537142857142858e-06,
      "loss": 0.0,
      "step": 10030
    },
    {
      "epoch": 5.737142857142857,
      "grad_norm": 0.00039765401743352413,
      "learning_rate": 8.525714285714286e-06,
      "loss": 0.0003,
      "step": 10040
    },
    {
      "epoch": 5.742857142857143,
      "grad_norm": 0.0005974832456558943,
      "learning_rate": 8.514285714285715e-06,
      "loss": 0.0025,
      "step": 10050
    },
    {
      "epoch": 5.748571428571428,
      "grad_norm": 0.0008435621857643127,
      "learning_rate": 8.502857142857143e-06,
      "loss": 0.0131,
      "step": 10060
    },
    {
      "epoch": 5.7542857142857144,
      "grad_norm": 0.384337455034256,
      "learning_rate": 8.491428571428572e-06,
      "loss": 0.0273,
      "step": 10070
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.026302395388484,
      "learning_rate": 8.48e-06,
      "loss": 0.0001,
      "step": 10080
    },
    {
      "epoch": 5.765714285714286,
      "grad_norm": 0.00044907486881129444,
      "learning_rate": 8.468571428571429e-06,
      "loss": 0.0007,
      "step": 10090
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 0.0002093127550324425,
      "learning_rate": 8.457142857142859e-06,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 5.777142857142858,
      "grad_norm": 0.0028956595342606306,
      "learning_rate": 8.445714285714285e-06,
      "loss": 0.0,
      "step": 10110
    },
    {
      "epoch": 5.782857142857143,
      "grad_norm": 0.0007087714620865881,
      "learning_rate": 8.434285714285716e-06,
      "loss": 0.0005,
      "step": 10120
    },
    {
      "epoch": 5.788571428571428,
      "grad_norm": 0.0018473888048902154,
      "learning_rate": 8.422857142857144e-06,
      "loss": 0.0499,
      "step": 10130
    },
    {
      "epoch": 5.7942857142857145,
      "grad_norm": 0.13989590108394623,
      "learning_rate": 8.411428571428572e-06,
      "loss": 0.0,
      "step": 10140
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.0002605998597573489,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0014,
      "step": 10150
    },
    {
      "epoch": 5.805714285714286,
      "grad_norm": 0.000436510395957157,
      "learning_rate": 8.38857142857143e-06,
      "loss": 0.0001,
      "step": 10160
    },
    {
      "epoch": 5.811428571428571,
      "grad_norm": 0.00018046502373181283,
      "learning_rate": 8.377142857142858e-06,
      "loss": 0.0019,
      "step": 10170
    },
    {
      "epoch": 5.817142857142857,
      "grad_norm": 0.00019874150166288018,
      "learning_rate": 8.365714285714286e-06,
      "loss": 0.0,
      "step": 10180
    },
    {
      "epoch": 5.822857142857143,
      "grad_norm": 0.008803501725196838,
      "learning_rate": 8.354285714285715e-06,
      "loss": 0.0277,
      "step": 10190
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 0.00020677276188507676,
      "learning_rate": 8.342857142857143e-06,
      "loss": 0.0,
      "step": 10200
    },
    {
      "epoch": 5.8342857142857145,
      "grad_norm": 0.41566306352615356,
      "learning_rate": 8.331428571428573e-06,
      "loss": 0.0002,
      "step": 10210
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.0007056776084937155,
      "learning_rate": 8.32e-06,
      "loss": 0.0707,
      "step": 10220
    },
    {
      "epoch": 5.845714285714286,
      "grad_norm": 0.0014950394397601485,
      "learning_rate": 8.308571428571428e-06,
      "loss": 0.0,
      "step": 10230
    },
    {
      "epoch": 5.851428571428571,
      "grad_norm": 0.0005277777090668678,
      "learning_rate": 8.297142857142859e-06,
      "loss": 0.0,
      "step": 10240
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 0.0004974016337655485,
      "learning_rate": 8.285714285714287e-06,
      "loss": 0.0003,
      "step": 10250
    },
    {
      "epoch": 5.862857142857143,
      "grad_norm": 0.0015449360944330692,
      "learning_rate": 8.274285714285715e-06,
      "loss": 0.0002,
      "step": 10260
    },
    {
      "epoch": 5.868571428571428,
      "grad_norm": 0.0026808963157236576,
      "learning_rate": 8.262857142857144e-06,
      "loss": 0.0,
      "step": 10270
    },
    {
      "epoch": 5.8742857142857146,
      "grad_norm": 0.0002549449272919446,
      "learning_rate": 8.251428571428572e-06,
      "loss": 0.001,
      "step": 10280
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.00040638723294250667,
      "learning_rate": 8.24e-06,
      "loss": 0.0,
      "step": 10290
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 58.84355926513672,
      "learning_rate": 8.22857142857143e-06,
      "loss": 0.013,
      "step": 10300
    },
    {
      "epoch": 5.8914285714285715,
      "grad_norm": 8.180492401123047,
      "learning_rate": 8.217142857142858e-06,
      "loss": 0.0365,
      "step": 10310
    },
    {
      "epoch": 5.897142857142857,
      "grad_norm": 0.0012354024220257998,
      "learning_rate": 8.205714285714286e-06,
      "loss": 0.023,
      "step": 10320
    },
    {
      "epoch": 5.902857142857143,
      "grad_norm": 0.010537249967455864,
      "learning_rate": 8.194285714285714e-06,
      "loss": 0.0,
      "step": 10330
    },
    {
      "epoch": 5.908571428571428,
      "grad_norm": 0.0005483728600665927,
      "learning_rate": 8.182857142857143e-06,
      "loss": 0.0,
      "step": 10340
    },
    {
      "epoch": 5.914285714285715,
      "grad_norm": 0.0005567066255025566,
      "learning_rate": 8.171428571428573e-06,
      "loss": 0.0,
      "step": 10350
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.033727195113897324,
      "learning_rate": 8.16e-06,
      "loss": 0.0,
      "step": 10360
    },
    {
      "epoch": 5.925714285714285,
      "grad_norm": 0.00012989016249775887,
      "learning_rate": 8.148571428571428e-06,
      "loss": 0.0,
      "step": 10370
    },
    {
      "epoch": 5.9314285714285715,
      "grad_norm": 0.0006150331464596093,
      "learning_rate": 8.137142857142858e-06,
      "loss": 0.0562,
      "step": 10380
    },
    {
      "epoch": 5.937142857142857,
      "grad_norm": 0.0003475717385299504,
      "learning_rate": 8.125714285714287e-06,
      "loss": 0.0,
      "step": 10390
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 0.0003375411906745285,
      "learning_rate": 8.114285714285715e-06,
      "loss": 0.0011,
      "step": 10400
    },
    {
      "epoch": 5.948571428571428,
      "grad_norm": 0.0016328642377629876,
      "learning_rate": 8.102857142857144e-06,
      "loss": 0.0,
      "step": 10410
    },
    {
      "epoch": 5.954285714285715,
      "grad_norm": 0.00020502382540144026,
      "learning_rate": 8.091428571428572e-06,
      "loss": 0.0,
      "step": 10420
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.0003138354513794184,
      "learning_rate": 8.08e-06,
      "loss": 0.0,
      "step": 10430
    },
    {
      "epoch": 5.965714285714286,
      "grad_norm": 0.00035551300970837474,
      "learning_rate": 8.068571428571429e-06,
      "loss": 0.0002,
      "step": 10440
    },
    {
      "epoch": 5.9714285714285715,
      "grad_norm": 0.0028265875298529863,
      "learning_rate": 8.057142857142857e-06,
      "loss": 0.0481,
      "step": 10450
    },
    {
      "epoch": 5.977142857142857,
      "grad_norm": 0.0012361689005047083,
      "learning_rate": 8.045714285714286e-06,
      "loss": 0.0021,
      "step": 10460
    },
    {
      "epoch": 5.982857142857143,
      "grad_norm": 0.0005368637503124774,
      "learning_rate": 8.034285714285714e-06,
      "loss": 0.0,
      "step": 10470
    },
    {
      "epoch": 5.988571428571428,
      "grad_norm": 0.14060959219932556,
      "learning_rate": 8.022857142857143e-06,
      "loss": 0.0,
      "step": 10480
    },
    {
      "epoch": 5.994285714285715,
      "grad_norm": 0.0009415769018232822,
      "learning_rate": 8.011428571428573e-06,
      "loss": 0.0588,
      "step": 10490
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.000985679100267589,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0001,
      "step": 10500
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9903074866310161,
      "eval_f1": 0.9439071566731141,
      "eval_loss": 0.06733512133359909,
      "eval_precision": 0.9420849420849421,
      "eval_recall": 0.9457364341085271,
      "eval_runtime": 51.2642,
      "eval_samples_per_second": 117.041,
      "eval_steps_per_second": 3.667,
      "step": 10500
    },
    {
      "epoch": 6.005714285714285,
      "grad_norm": 0.002210926963016391,
      "learning_rate": 7.988571428571428e-06,
      "loss": 0.0,
      "step": 10510
    },
    {
      "epoch": 6.011428571428572,
      "grad_norm": 0.008352150209248066,
      "learning_rate": 7.977142857142858e-06,
      "loss": 0.0,
      "step": 10520
    },
    {
      "epoch": 6.017142857142857,
      "grad_norm": 10.578023910522461,
      "learning_rate": 7.965714285714287e-06,
      "loss": 0.0427,
      "step": 10530
    },
    {
      "epoch": 6.022857142857143,
      "grad_norm": 0.021182941272854805,
      "learning_rate": 7.954285714285715e-06,
      "loss": 0.0001,
      "step": 10540
    },
    {
      "epoch": 6.0285714285714285,
      "grad_norm": 0.008699874393641949,
      "learning_rate": 7.942857142857144e-06,
      "loss": 0.0011,
      "step": 10550
    },
    {
      "epoch": 6.034285714285715,
      "grad_norm": 0.0010312815429642797,
      "learning_rate": 7.931428571428572e-06,
      "loss": 0.0,
      "step": 10560
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.007302486803382635,
      "learning_rate": 7.92e-06,
      "loss": 0.0,
      "step": 10570
    },
    {
      "epoch": 6.045714285714285,
      "grad_norm": 0.0008607865893281996,
      "learning_rate": 7.908571428571429e-06,
      "loss": 0.0,
      "step": 10580
    },
    {
      "epoch": 6.051428571428572,
      "grad_norm": 0.0010654384968802333,
      "learning_rate": 7.897142857142857e-06,
      "loss": 0.0,
      "step": 10590
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 0.008036905899643898,
      "learning_rate": 7.885714285714286e-06,
      "loss": 0.0,
      "step": 10600
    },
    {
      "epoch": 6.062857142857143,
      "grad_norm": 0.0008074067300185561,
      "learning_rate": 7.874285714285716e-06,
      "loss": 0.0,
      "step": 10610
    },
    {
      "epoch": 6.0685714285714285,
      "grad_norm": 0.0008971191709861159,
      "learning_rate": 7.862857142857143e-06,
      "loss": 0.0331,
      "step": 10620
    },
    {
      "epoch": 6.074285714285715,
      "grad_norm": 0.002718450967222452,
      "learning_rate": 7.851428571428573e-06,
      "loss": 0.0002,
      "step": 10630
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.0007662451826035976,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.0,
      "step": 10640
    },
    {
      "epoch": 6.085714285714285,
      "grad_norm": 0.0005492193740792572,
      "learning_rate": 7.828571428571428e-06,
      "loss": 0.0,
      "step": 10650
    },
    {
      "epoch": 6.091428571428572,
      "grad_norm": 0.0050836242735385895,
      "learning_rate": 7.817142857142858e-06,
      "loss": 0.0001,
      "step": 10660
    },
    {
      "epoch": 6.097142857142857,
      "grad_norm": 0.0024117000866681337,
      "learning_rate": 7.805714285714286e-06,
      "loss": 0.037,
      "step": 10670
    },
    {
      "epoch": 6.102857142857143,
      "grad_norm": 0.0012336480431258678,
      "learning_rate": 7.794285714285715e-06,
      "loss": 0.0332,
      "step": 10680
    },
    {
      "epoch": 6.1085714285714285,
      "grad_norm": 0.001746483496390283,
      "learning_rate": 7.782857142857143e-06,
      "loss": 0.0216,
      "step": 10690
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 0.004232039209455252,
      "learning_rate": 7.771428571428572e-06,
      "loss": 0.0,
      "step": 10700
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.0006972227129153907,
      "learning_rate": 7.76e-06,
      "loss": 0.0,
      "step": 10710
    },
    {
      "epoch": 6.1257142857142854,
      "grad_norm": 0.018574882298707962,
      "learning_rate": 7.74857142857143e-06,
      "loss": 0.0,
      "step": 10720
    },
    {
      "epoch": 6.131428571428572,
      "grad_norm": 0.0005922286654822528,
      "learning_rate": 7.737142857142857e-06,
      "loss": 0.0482,
      "step": 10730
    },
    {
      "epoch": 6.137142857142857,
      "grad_norm": 0.0009959120070561767,
      "learning_rate": 7.725714285714286e-06,
      "loss": 0.0,
      "step": 10740
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.0055355713702738285,
      "learning_rate": 7.714285714285716e-06,
      "loss": 0.0,
      "step": 10750
    },
    {
      "epoch": 6.148571428571429,
      "grad_norm": 0.0021933279931545258,
      "learning_rate": 7.702857142857142e-06,
      "loss": 0.0,
      "step": 10760
    },
    {
      "epoch": 6.154285714285714,
      "grad_norm": 0.015581987798213959,
      "learning_rate": 7.691428571428573e-06,
      "loss": 0.0001,
      "step": 10770
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.01744711585342884,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.0021,
      "step": 10780
    },
    {
      "epoch": 6.1657142857142855,
      "grad_norm": 0.0020529511384665966,
      "learning_rate": 7.66857142857143e-06,
      "loss": 0.0,
      "step": 10790
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 0.0014503693673759699,
      "learning_rate": 7.657142857142858e-06,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 6.177142857142857,
      "grad_norm": 0.0003936601569876075,
      "learning_rate": 7.645714285714286e-06,
      "loss": 0.0356,
      "step": 10810
    },
    {
      "epoch": 6.182857142857143,
      "grad_norm": 0.007409122306853533,
      "learning_rate": 7.634285714285715e-06,
      "loss": 0.0,
      "step": 10820
    },
    {
      "epoch": 6.188571428571429,
      "grad_norm": 0.004946815315634012,
      "learning_rate": 7.622857142857143e-06,
      "loss": 0.0001,
      "step": 10830
    },
    {
      "epoch": 6.194285714285714,
      "grad_norm": 0.002971040550619364,
      "learning_rate": 7.611428571428572e-06,
      "loss": 0.0001,
      "step": 10840
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.0021088230423629284,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0313,
      "step": 10850
    },
    {
      "epoch": 6.2057142857142855,
      "grad_norm": 0.0016632883343845606,
      "learning_rate": 7.588571428571429e-06,
      "loss": 0.0001,
      "step": 10860
    },
    {
      "epoch": 6.211428571428572,
      "grad_norm": 0.4910103976726532,
      "learning_rate": 7.577142857142857e-06,
      "loss": 0.0001,
      "step": 10870
    },
    {
      "epoch": 6.217142857142857,
      "grad_norm": 0.0055135018192231655,
      "learning_rate": 7.565714285714286e-06,
      "loss": 0.0,
      "step": 10880
    },
    {
      "epoch": 6.222857142857142,
      "grad_norm": 0.003539816476404667,
      "learning_rate": 7.5542857142857155e-06,
      "loss": 0.0002,
      "step": 10890
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 0.003126799128949642,
      "learning_rate": 7.542857142857144e-06,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 6.234285714285714,
      "grad_norm": 0.004756930749863386,
      "learning_rate": 7.5314285714285716e-06,
      "loss": 0.0001,
      "step": 10910
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.0008759109769016504,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.0,
      "step": 10920
    },
    {
      "epoch": 6.2457142857142856,
      "grad_norm": 0.004137808457016945,
      "learning_rate": 7.508571428571429e-06,
      "loss": 0.0001,
      "step": 10930
    },
    {
      "epoch": 6.251428571428572,
      "grad_norm": 0.001068160287104547,
      "learning_rate": 7.497142857142857e-06,
      "loss": 0.0,
      "step": 10940
    },
    {
      "epoch": 6.257142857142857,
      "grad_norm": 0.0022892921697348356,
      "learning_rate": 7.485714285714286e-06,
      "loss": 0.0,
      "step": 10950
    },
    {
      "epoch": 6.2628571428571425,
      "grad_norm": 0.0023920165840536356,
      "learning_rate": 7.4742857142857154e-06,
      "loss": 0.0002,
      "step": 10960
    },
    {
      "epoch": 6.268571428571429,
      "grad_norm": 0.0033826003782451153,
      "learning_rate": 7.462857142857144e-06,
      "loss": 0.0001,
      "step": 10970
    },
    {
      "epoch": 6.274285714285714,
      "grad_norm": 0.001877165399491787,
      "learning_rate": 7.4514285714285715e-06,
      "loss": 0.0,
      "step": 10980
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.0005419448134489357,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.0,
      "step": 10990
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.0025030949618667364,
      "learning_rate": 7.428571428571429e-06,
      "loss": 0.0001,
      "step": 11000
    },
    {
      "epoch": 6.291428571428572,
      "grad_norm": 0.0062334430404007435,
      "learning_rate": 7.417142857142857e-06,
      "loss": 0.0,
      "step": 11010
    },
    {
      "epoch": 6.297142857142857,
      "grad_norm": 0.0038117484655231237,
      "learning_rate": 7.405714285714286e-06,
      "loss": 0.0,
      "step": 11020
    },
    {
      "epoch": 6.3028571428571425,
      "grad_norm": 0.0004711345536634326,
      "learning_rate": 7.394285714285715e-06,
      "loss": 0.0,
      "step": 11030
    },
    {
      "epoch": 6.308571428571429,
      "grad_norm": 0.0003119881439488381,
      "learning_rate": 7.382857142857144e-06,
      "loss": 0.0142,
      "step": 11040
    },
    {
      "epoch": 6.314285714285714,
      "grad_norm": 0.46869218349456787,
      "learning_rate": 7.371428571428571e-06,
      "loss": 0.0001,
      "step": 11050
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.0004415613948367536,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.0,
      "step": 11060
    },
    {
      "epoch": 6.325714285714286,
      "grad_norm": 0.000780804839450866,
      "learning_rate": 7.348571428571429e-06,
      "loss": 0.0,
      "step": 11070
    },
    {
      "epoch": 6.331428571428571,
      "grad_norm": 0.0033495097886770964,
      "learning_rate": 7.337142857142858e-06,
      "loss": 0.0007,
      "step": 11080
    },
    {
      "epoch": 6.337142857142857,
      "grad_norm": 0.0009882851736620069,
      "learning_rate": 7.325714285714286e-06,
      "loss": 0.0114,
      "step": 11090
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 0.0007761357701383531,
      "learning_rate": 7.314285714285715e-06,
      "loss": 0.0,
      "step": 11100
    },
    {
      "epoch": 6.348571428571429,
      "grad_norm": 0.21364517509937286,
      "learning_rate": 7.302857142857144e-06,
      "loss": 0.0339,
      "step": 11110
    },
    {
      "epoch": 6.354285714285714,
      "grad_norm": 0.0010453525464981794,
      "learning_rate": 7.291428571428571e-06,
      "loss": 0.0,
      "step": 11120
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.0011024975683540106,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.0,
      "step": 11130
    },
    {
      "epoch": 6.365714285714286,
      "grad_norm": 0.0002517540124244988,
      "learning_rate": 7.268571428571429e-06,
      "loss": 0.0,
      "step": 11140
    },
    {
      "epoch": 6.371428571428572,
      "grad_norm": 0.008006111718714237,
      "learning_rate": 7.257142857142858e-06,
      "loss": 0.0,
      "step": 11150
    },
    {
      "epoch": 6.377142857142857,
      "grad_norm": 0.0005602855235338211,
      "learning_rate": 7.245714285714286e-06,
      "loss": 0.0,
      "step": 11160
    },
    {
      "epoch": 6.382857142857143,
      "grad_norm": 0.0002301886270288378,
      "learning_rate": 7.234285714285715e-06,
      "loss": 0.0072,
      "step": 11170
    },
    {
      "epoch": 6.388571428571429,
      "grad_norm": 0.0008002045215107501,
      "learning_rate": 7.222857142857144e-06,
      "loss": 0.0,
      "step": 11180
    },
    {
      "epoch": 6.394285714285714,
      "grad_norm": 0.00026172329671680927,
      "learning_rate": 7.211428571428573e-06,
      "loss": 0.0,
      "step": 11190
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.0007739889551885426,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 6.405714285714286,
      "grad_norm": 0.002828408032655716,
      "learning_rate": 7.188571428571429e-06,
      "loss": 0.0,
      "step": 11210
    },
    {
      "epoch": 6.411428571428571,
      "grad_norm": 0.00028097262838855386,
      "learning_rate": 7.177142857142858e-06,
      "loss": 0.0,
      "step": 11220
    },
    {
      "epoch": 6.417142857142857,
      "grad_norm": 0.0006863223388791084,
      "learning_rate": 7.165714285714286e-06,
      "loss": 0.0,
      "step": 11230
    },
    {
      "epoch": 6.422857142857143,
      "grad_norm": 0.010860538110136986,
      "learning_rate": 7.154285714285715e-06,
      "loss": 0.0405,
      "step": 11240
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.0037593618035316467,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.0,
      "step": 11250
    },
    {
      "epoch": 6.434285714285714,
      "grad_norm": 0.012448020279407501,
      "learning_rate": 7.131428571428573e-06,
      "loss": 0.0,
      "step": 11260
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.010036548599600792,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.0043,
      "step": 11270
    },
    {
      "epoch": 6.445714285714286,
      "grad_norm": 0.0023161342833191156,
      "learning_rate": 7.108571428571429e-06,
      "loss": 0.0002,
      "step": 11280
    },
    {
      "epoch": 6.451428571428571,
      "grad_norm": 0.001829927321523428,
      "learning_rate": 7.097142857142858e-06,
      "loss": 0.0,
      "step": 11290
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 0.00039367348654195666,
      "learning_rate": 7.085714285714286e-06,
      "loss": 0.0001,
      "step": 11300
    },
    {
      "epoch": 6.462857142857143,
      "grad_norm": 0.0010008577955886722,
      "learning_rate": 7.074285714285715e-06,
      "loss": 0.0001,
      "step": 11310
    },
    {
      "epoch": 6.468571428571429,
      "grad_norm": 0.002428516512736678,
      "learning_rate": 7.0628571428571435e-06,
      "loss": 0.0,
      "step": 11320
    },
    {
      "epoch": 6.474285714285714,
      "grad_norm": 0.0011073130881413817,
      "learning_rate": 7.051428571428573e-06,
      "loss": 0.0,
      "step": 11330
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.005592901259660721,
      "learning_rate": 7.04e-06,
      "loss": 0.0,
      "step": 11340
    },
    {
      "epoch": 6.485714285714286,
      "grad_norm": 0.001035568886436522,
      "learning_rate": 7.028571428571429e-06,
      "loss": 0.0,
      "step": 11350
    },
    {
      "epoch": 6.491428571428571,
      "grad_norm": 7.890036106109619,
      "learning_rate": 7.017142857142858e-06,
      "loss": 0.0038,
      "step": 11360
    },
    {
      "epoch": 6.497142857142857,
      "grad_norm": 0.00030939653515815735,
      "learning_rate": 7.0057142857142865e-06,
      "loss": 0.0,
      "step": 11370
    },
    {
      "epoch": 6.502857142857143,
      "grad_norm": 0.14115369319915771,
      "learning_rate": 6.994285714285715e-06,
      "loss": 0.0003,
      "step": 11380
    },
    {
      "epoch": 6.508571428571429,
      "grad_norm": 0.00015217646432574838,
      "learning_rate": 6.982857142857143e-06,
      "loss": 0.0,
      "step": 11390
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 0.2547641694545746,
      "learning_rate": 6.971428571428573e-06,
      "loss": 0.0003,
      "step": 11400
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.00019615456403698772,
      "learning_rate": 6.96e-06,
      "loss": 0.0,
      "step": 11410
    },
    {
      "epoch": 6.525714285714286,
      "grad_norm": 0.00037287597660906613,
      "learning_rate": 6.948571428571429e-06,
      "loss": 0.0253,
      "step": 11420
    },
    {
      "epoch": 6.531428571428571,
      "grad_norm": 10.283875465393066,
      "learning_rate": 6.937142857142858e-06,
      "loss": 0.0453,
      "step": 11430
    },
    {
      "epoch": 6.537142857142857,
      "grad_norm": 0.00031953465077094734,
      "learning_rate": 6.9257142857142864e-06,
      "loss": 0.0,
      "step": 11440
    },
    {
      "epoch": 6.542857142857143,
      "grad_norm": 0.000494165753480047,
      "learning_rate": 6.914285714285715e-06,
      "loss": 0.0,
      "step": 11450
    },
    {
      "epoch": 6.548571428571429,
      "grad_norm": 0.0005356412730179727,
      "learning_rate": 6.902857142857143e-06,
      "loss": 0.0111,
      "step": 11460
    },
    {
      "epoch": 6.554285714285714,
      "grad_norm": 0.001199292833916843,
      "learning_rate": 6.891428571428573e-06,
      "loss": 0.0003,
      "step": 11470
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.0024048734921962023,
      "learning_rate": 6.88e-06,
      "loss": 0.0,
      "step": 11480
    },
    {
      "epoch": 6.565714285714286,
      "grad_norm": 0.00016697625687811524,
      "learning_rate": 6.868571428571429e-06,
      "loss": 0.0001,
      "step": 11490
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.0005785238463431597,
      "learning_rate": 6.857142857142858e-06,
      "loss": 0.0,
      "step": 11500
    },
    {
      "epoch": 6.577142857142857,
      "grad_norm": 0.00026460696244612336,
      "learning_rate": 6.845714285714286e-06,
      "loss": 0.0,
      "step": 11510
    },
    {
      "epoch": 6.582857142857143,
      "grad_norm": 0.0009762870613485575,
      "learning_rate": 6.834285714285715e-06,
      "loss": 0.0,
      "step": 11520
    },
    {
      "epoch": 6.588571428571429,
      "grad_norm": 0.0005516047822311521,
      "learning_rate": 6.822857142857143e-06,
      "loss": 0.0009,
      "step": 11530
    },
    {
      "epoch": 6.594285714285714,
      "grad_norm": 0.00020297626906540245,
      "learning_rate": 6.8114285714285725e-06,
      "loss": 0.0,
      "step": 11540
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.00016325684555340558,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0,
      "step": 11550
    },
    {
      "epoch": 6.605714285714286,
      "grad_norm": 0.0024420693516731262,
      "learning_rate": 6.7885714285714286e-06,
      "loss": 0.0,
      "step": 11560
    },
    {
      "epoch": 6.611428571428571,
      "grad_norm": 7.67776946304366e-05,
      "learning_rate": 6.777142857142858e-06,
      "loss": 0.0,
      "step": 11570
    },
    {
      "epoch": 6.617142857142857,
      "grad_norm": 0.0006039831205271184,
      "learning_rate": 6.765714285714286e-06,
      "loss": 0.0,
      "step": 11580
    },
    {
      "epoch": 6.622857142857143,
      "grad_norm": 0.00033634400460869074,
      "learning_rate": 6.754285714285715e-06,
      "loss": 0.0,
      "step": 11590
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 0.00014104528236202896,
      "learning_rate": 6.742857142857143e-06,
      "loss": 0.0,
      "step": 11600
    },
    {
      "epoch": 6.634285714285714,
      "grad_norm": 0.00041814116411842406,
      "learning_rate": 6.7314285714285724e-06,
      "loss": 0.0002,
      "step": 11610
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.00026219739811494946,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.0017,
      "step": 11620
    },
    {
      "epoch": 6.645714285714286,
      "grad_norm": 0.00023435500042978674,
      "learning_rate": 6.7085714285714285e-06,
      "loss": 0.0,
      "step": 11630
    },
    {
      "epoch": 6.651428571428571,
      "grad_norm": 0.0037371593061834574,
      "learning_rate": 6.697142857142858e-06,
      "loss": 0.0,
      "step": 11640
    },
    {
      "epoch": 6.6571428571428575,
      "grad_norm": 0.0005381813389249146,
      "learning_rate": 6.685714285714286e-06,
      "loss": 0.0,
      "step": 11650
    },
    {
      "epoch": 6.662857142857143,
      "grad_norm": 0.00010640339314704761,
      "learning_rate": 6.6742857142857155e-06,
      "loss": 0.0001,
      "step": 11660
    },
    {
      "epoch": 6.668571428571429,
      "grad_norm": 0.00045487144961953163,
      "learning_rate": 6.662857142857143e-06,
      "loss": 0.0,
      "step": 11670
    },
    {
      "epoch": 6.674285714285714,
      "grad_norm": 0.0001767711219144985,
      "learning_rate": 6.651428571428572e-06,
      "loss": 0.0,
      "step": 11680
    },
    {
      "epoch": 6.68,
      "grad_norm": 7.465218368452042e-05,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.0,
      "step": 11690
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 0.0012944793561473489,
      "learning_rate": 6.628571428571428e-06,
      "loss": 0.0299,
      "step": 11700
    },
    {
      "epoch": 6.691428571428571,
      "grad_norm": 0.0001150782045442611,
      "learning_rate": 6.617142857142858e-06,
      "loss": 0.0001,
      "step": 11710
    },
    {
      "epoch": 6.6971428571428575,
      "grad_norm": 0.004955706186592579,
      "learning_rate": 6.605714285714286e-06,
      "loss": 0.0004,
      "step": 11720
    },
    {
      "epoch": 6.702857142857143,
      "grad_norm": 0.00012581251212395728,
      "learning_rate": 6.594285714285715e-06,
      "loss": 0.0,
      "step": 11730
    },
    {
      "epoch": 6.708571428571428,
      "grad_norm": 0.0007463698857463896,
      "learning_rate": 6.582857142857143e-06,
      "loss": 0.0,
      "step": 11740
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 9.069788211490959e-05,
      "learning_rate": 6.571428571428572e-06,
      "loss": 0.0001,
      "step": 11750
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.0002634876291267574,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.0,
      "step": 11760
    },
    {
      "epoch": 6.725714285714286,
      "grad_norm": 0.0002965013263747096,
      "learning_rate": 6.548571428571428e-06,
      "loss": 0.0001,
      "step": 11770
    },
    {
      "epoch": 6.731428571428571,
      "grad_norm": 0.1541915237903595,
      "learning_rate": 6.537142857142858e-06,
      "loss": 0.012,
      "step": 11780
    },
    {
      "epoch": 6.737142857142857,
      "grad_norm": 0.0001739537692628801,
      "learning_rate": 6.525714285714286e-06,
      "loss": 0.0769,
      "step": 11790
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 0.00012263852113392204,
      "learning_rate": 6.514285714285715e-06,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 6.748571428571428,
      "grad_norm": 0.00808937381953001,
      "learning_rate": 6.502857142857143e-06,
      "loss": 0.0,
      "step": 11810
    },
    {
      "epoch": 6.7542857142857144,
      "grad_norm": 12.338478088378906,
      "learning_rate": 6.491428571428572e-06,
      "loss": 0.0009,
      "step": 11820
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.00032986709265969694,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.0,
      "step": 11830
    },
    {
      "epoch": 6.765714285714286,
      "grad_norm": 0.00020175518875475973,
      "learning_rate": 6.46857142857143e-06,
      "loss": 0.0,
      "step": 11840
    },
    {
      "epoch": 6.771428571428571,
      "grad_norm": 0.0008831913582980633,
      "learning_rate": 6.4571428571428575e-06,
      "loss": 0.0,
      "step": 11850
    },
    {
      "epoch": 6.777142857142858,
      "grad_norm": 0.08847735822200775,
      "learning_rate": 6.445714285714286e-06,
      "loss": 0.0001,
      "step": 11860
    },
    {
      "epoch": 6.782857142857143,
      "grad_norm": 0.007850417867302895,
      "learning_rate": 6.434285714285715e-06,
      "loss": 0.0,
      "step": 11870
    },
    {
      "epoch": 6.788571428571428,
      "grad_norm": 0.00024970853701233864,
      "learning_rate": 6.422857142857143e-06,
      "loss": 0.0,
      "step": 11880
    },
    {
      "epoch": 6.7942857142857145,
      "grad_norm": 41.296390533447266,
      "learning_rate": 6.411428571428572e-06,
      "loss": 0.0199,
      "step": 11890
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.000929167727008462,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0438,
      "step": 11900
    },
    {
      "epoch": 6.805714285714286,
      "grad_norm": 0.003432351164519787,
      "learning_rate": 6.38857142857143e-06,
      "loss": 0.0,
      "step": 11910
    },
    {
      "epoch": 6.811428571428571,
      "grad_norm": 0.0033738024067133665,
      "learning_rate": 6.3771428571428574e-06,
      "loss": 0.0462,
      "step": 11920
    },
    {
      "epoch": 6.817142857142857,
      "grad_norm": 0.00042769909487105906,
      "learning_rate": 6.365714285714286e-06,
      "loss": 0.0002,
      "step": 11930
    },
    {
      "epoch": 6.822857142857143,
      "grad_norm": 0.010363318957388401,
      "learning_rate": 6.354285714285715e-06,
      "loss": 0.0,
      "step": 11940
    },
    {
      "epoch": 6.828571428571428,
      "grad_norm": 0.0003625063400249928,
      "learning_rate": 6.342857142857143e-06,
      "loss": 0.0,
      "step": 11950
    },
    {
      "epoch": 6.8342857142857145,
      "grad_norm": 0.002609327668324113,
      "learning_rate": 6.331428571428572e-06,
      "loss": 0.0447,
      "step": 11960
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.0010754837421700358,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.0012,
      "step": 11970
    },
    {
      "epoch": 6.845714285714286,
      "grad_norm": 0.0002761393552646041,
      "learning_rate": 6.30857142857143e-06,
      "loss": 0.0,
      "step": 11980
    },
    {
      "epoch": 6.851428571428571,
      "grad_norm": 0.0002577270788606256,
      "learning_rate": 6.297142857142857e-06,
      "loss": 0.0185,
      "step": 11990
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.0010345684131607413,
      "learning_rate": 6.285714285714286e-06,
      "loss": 0.0306,
      "step": 12000
    },
    {
      "epoch": 6.862857142857143,
      "grad_norm": 0.0019235368818044662,
      "learning_rate": 6.274285714285715e-06,
      "loss": 0.0,
      "step": 12010
    },
    {
      "epoch": 6.868571428571428,
      "grad_norm": 22.08095932006836,
      "learning_rate": 6.2628571428571435e-06,
      "loss": 0.0878,
      "step": 12020
    },
    {
      "epoch": 6.8742857142857146,
      "grad_norm": 0.0007381896139122546,
      "learning_rate": 6.251428571428572e-06,
      "loss": 0.0,
      "step": 12030
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.002505709184333682,
      "learning_rate": 6.24e-06,
      "loss": 0.0,
      "step": 12040
    },
    {
      "epoch": 6.885714285714286,
      "grad_norm": 0.0010498411720618606,
      "learning_rate": 6.22857142857143e-06,
      "loss": 0.0459,
      "step": 12050
    },
    {
      "epoch": 6.8914285714285715,
      "grad_norm": 0.0006995692965574563,
      "learning_rate": 6.217142857142857e-06,
      "loss": 0.0,
      "step": 12060
    },
    {
      "epoch": 6.897142857142857,
      "grad_norm": 0.012358365580439568,
      "learning_rate": 6.205714285714286e-06,
      "loss": 0.0003,
      "step": 12070
    },
    {
      "epoch": 6.902857142857143,
      "grad_norm": 0.0006913790130056441,
      "learning_rate": 6.194285714285715e-06,
      "loss": 0.0,
      "step": 12080
    },
    {
      "epoch": 6.908571428571428,
      "grad_norm": 0.0001892979198601097,
      "learning_rate": 6.1828571428571434e-06,
      "loss": 0.0,
      "step": 12090
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 0.00025524268858134747,
      "learning_rate": 6.171428571428572e-06,
      "loss": 0.0271,
      "step": 12100
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.0022991590667515993,
      "learning_rate": 6.16e-06,
      "loss": 0.0502,
      "step": 12110
    },
    {
      "epoch": 6.925714285714285,
      "grad_norm": 0.0007290915818884969,
      "learning_rate": 6.14857142857143e-06,
      "loss": 0.0,
      "step": 12120
    },
    {
      "epoch": 6.9314285714285715,
      "grad_norm": 0.0013174648629501462,
      "learning_rate": 6.137142857142858e-06,
      "loss": 0.0205,
      "step": 12130
    },
    {
      "epoch": 6.937142857142857,
      "grad_norm": 0.0007756527629680932,
      "learning_rate": 6.125714285714286e-06,
      "loss": 0.03,
      "step": 12140
    },
    {
      "epoch": 6.942857142857143,
      "grad_norm": 0.0007286115433089435,
      "learning_rate": 6.114285714285715e-06,
      "loss": 0.0102,
      "step": 12150
    },
    {
      "epoch": 6.948571428571428,
      "grad_norm": 0.0006033400422893465,
      "learning_rate": 6.102857142857143e-06,
      "loss": 0.0,
      "step": 12160
    },
    {
      "epoch": 6.954285714285715,
      "grad_norm": 0.011733360588550568,
      "learning_rate": 6.091428571428572e-06,
      "loss": 0.0003,
      "step": 12170
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.0003122699854429811,
      "learning_rate": 6.08e-06,
      "loss": 0.0,
      "step": 12180
    },
    {
      "epoch": 6.965714285714286,
      "grad_norm": 0.003876353846862912,
      "learning_rate": 6.0685714285714295e-06,
      "loss": 0.0,
      "step": 12190
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 0.000838058243971318,
      "learning_rate": 6.057142857142858e-06,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 6.977142857142857,
      "grad_norm": 0.0029892351012676954,
      "learning_rate": 6.0457142857142855e-06,
      "loss": 0.0026,
      "step": 12210
    },
    {
      "epoch": 6.982857142857143,
      "grad_norm": 0.00014913656923454255,
      "learning_rate": 6.034285714285715e-06,
      "loss": 0.0002,
      "step": 12220
    },
    {
      "epoch": 6.988571428571428,
      "grad_norm": 0.00039562780875712633,
      "learning_rate": 6.022857142857143e-06,
      "loss": 0.0,
      "step": 12230
    },
    {
      "epoch": 6.994285714285715,
      "grad_norm": 0.0076597910374403,
      "learning_rate": 6.011428571428572e-06,
      "loss": 0.0,
      "step": 12240
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0006077215075492859,
      "learning_rate": 6e-06,
      "loss": 0.0,
      "step": 12250
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9919786096256684,
      "eval_f1": 0.953757225433526,
      "eval_loss": 0.05890536308288574,
      "eval_precision": 0.9482758620689655,
      "eval_recall": 0.9593023255813954,
      "eval_runtime": 51.3204,
      "eval_samples_per_second": 116.913,
      "eval_steps_per_second": 3.663,
      "step": 12250
    },
    {
      "epoch": 7.005714285714285,
      "grad_norm": 0.001072620740160346,
      "learning_rate": 5.9885714285714294e-06,
      "loss": 0.0001,
      "step": 12260
    },
    {
      "epoch": 7.011428571428572,
      "grad_norm": 0.002071151975542307,
      "learning_rate": 5.977142857142858e-06,
      "loss": 0.0,
      "step": 12270
    },
    {
      "epoch": 7.017142857142857,
      "grad_norm": 0.00021693017333745956,
      "learning_rate": 5.9657142857142855e-06,
      "loss": 0.0,
      "step": 12280
    },
    {
      "epoch": 7.022857142857143,
      "grad_norm": 0.00016435103316325694,
      "learning_rate": 5.954285714285715e-06,
      "loss": 0.0,
      "step": 12290
    },
    {
      "epoch": 7.0285714285714285,
      "grad_norm": 0.0005188734503462911,
      "learning_rate": 5.942857142857143e-06,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 7.034285714285715,
      "grad_norm": 0.0004311880620662123,
      "learning_rate": 5.9314285714285725e-06,
      "loss": 0.0,
      "step": 12310
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.00019921972125303,
      "learning_rate": 5.92e-06,
      "loss": 0.0,
      "step": 12320
    },
    {
      "epoch": 7.045714285714285,
      "grad_norm": 0.00020204867178108543,
      "learning_rate": 5.908571428571429e-06,
      "loss": 0.0,
      "step": 12330
    },
    {
      "epoch": 7.051428571428572,
      "grad_norm": 0.00038245582254603505,
      "learning_rate": 5.897142857142858e-06,
      "loss": 0.0245,
      "step": 12340
    },
    {
      "epoch": 7.057142857142857,
      "grad_norm": 0.00025357535923831165,
      "learning_rate": 5.885714285714285e-06,
      "loss": 0.0,
      "step": 12350
    },
    {
      "epoch": 7.062857142857143,
      "grad_norm": 0.01559329591691494,
      "learning_rate": 5.874285714285715e-06,
      "loss": 0.0,
      "step": 12360
    },
    {
      "epoch": 7.0685714285714285,
      "grad_norm": 0.028480196371674538,
      "learning_rate": 5.862857142857143e-06,
      "loss": 0.0,
      "step": 12370
    },
    {
      "epoch": 7.074285714285715,
      "grad_norm": 0.00020121056877542287,
      "learning_rate": 5.851428571428572e-06,
      "loss": 0.0,
      "step": 12380
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.0009885457111522555,
      "learning_rate": 5.84e-06,
      "loss": 0.013,
      "step": 12390
    },
    {
      "epoch": 7.085714285714285,
      "grad_norm": 0.0006192804430611432,
      "learning_rate": 5.828571428571429e-06,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 7.091428571428572,
      "grad_norm": 0.0005609247600659728,
      "learning_rate": 5.817142857142858e-06,
      "loss": 0.0,
      "step": 12410
    },
    {
      "epoch": 7.097142857142857,
      "grad_norm": 0.0022258753888309,
      "learning_rate": 5.805714285714285e-06,
      "loss": 0.0,
      "step": 12420
    },
    {
      "epoch": 7.102857142857143,
      "grad_norm": 0.0004808191442862153,
      "learning_rate": 5.794285714285715e-06,
      "loss": 0.0,
      "step": 12430
    },
    {
      "epoch": 7.1085714285714285,
      "grad_norm": 0.0005293559515848756,
      "learning_rate": 5.782857142857143e-06,
      "loss": 0.0,
      "step": 12440
    },
    {
      "epoch": 7.114285714285714,
      "grad_norm": 0.007115360349416733,
      "learning_rate": 5.771428571428572e-06,
      "loss": 0.0753,
      "step": 12450
    },
    {
      "epoch": 7.12,
      "grad_norm": 0.0013405667850747705,
      "learning_rate": 5.76e-06,
      "loss": 0.0,
      "step": 12460
    },
    {
      "epoch": 7.1257142857142854,
      "grad_norm": 0.004122670274227858,
      "learning_rate": 5.748571428571429e-06,
      "loss": 0.0,
      "step": 12470
    },
    {
      "epoch": 7.131428571428572,
      "grad_norm": 0.002480798400938511,
      "learning_rate": 5.737142857142858e-06,
      "loss": 0.0366,
      "step": 12480
    },
    {
      "epoch": 7.137142857142857,
      "grad_norm": 0.0018394315848127007,
      "learning_rate": 5.725714285714287e-06,
      "loss": 0.0,
      "step": 12490
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.007239132188260555,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.0001,
      "step": 12500
    },
    {
      "epoch": 7.148571428571429,
      "grad_norm": 0.7795376181602478,
      "learning_rate": 5.702857142857143e-06,
      "loss": 0.0001,
      "step": 12510
    },
    {
      "epoch": 7.154285714285714,
      "grad_norm": 0.0009754550410434604,
      "learning_rate": 5.691428571428572e-06,
      "loss": 0.0,
      "step": 12520
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.00041911660810001194,
      "learning_rate": 5.68e-06,
      "loss": 0.0,
      "step": 12530
    },
    {
      "epoch": 7.1657142857142855,
      "grad_norm": 0.0003614622983150184,
      "learning_rate": 5.668571428571429e-06,
      "loss": 0.0011,
      "step": 12540
    },
    {
      "epoch": 7.171428571428572,
      "grad_norm": 0.00027669768314808607,
      "learning_rate": 5.6571428571428576e-06,
      "loss": 0.0,
      "step": 12550
    },
    {
      "epoch": 7.177142857142857,
      "grad_norm": 0.00021822375128977,
      "learning_rate": 5.645714285714287e-06,
      "loss": 0.0119,
      "step": 12560
    },
    {
      "epoch": 7.182857142857143,
      "grad_norm": 0.0004123401886317879,
      "learning_rate": 5.6342857142857144e-06,
      "loss": 0.0,
      "step": 12570
    },
    {
      "epoch": 7.188571428571429,
      "grad_norm": 0.000540938985068351,
      "learning_rate": 5.622857142857143e-06,
      "loss": 0.0068,
      "step": 12580
    },
    {
      "epoch": 7.194285714285714,
      "grad_norm": 0.03514905646443367,
      "learning_rate": 5.611428571428572e-06,
      "loss": 0.0004,
      "step": 12590
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.00788772851228714,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0,
      "step": 12600
    },
    {
      "epoch": 7.2057142857142855,
      "grad_norm": 0.000912576331757009,
      "learning_rate": 5.588571428571429e-06,
      "loss": 0.0002,
      "step": 12610
    },
    {
      "epoch": 7.211428571428572,
      "grad_norm": 0.00044447468826547265,
      "learning_rate": 5.5771428571428575e-06,
      "loss": 0.0053,
      "step": 12620
    },
    {
      "epoch": 7.217142857142857,
      "grad_norm": 0.000840024440549314,
      "learning_rate": 5.565714285714287e-06,
      "loss": 0.0,
      "step": 12630
    },
    {
      "epoch": 7.222857142857142,
      "grad_norm": 0.0036305098328739405,
      "learning_rate": 5.554285714285714e-06,
      "loss": 0.0,
      "step": 12640
    },
    {
      "epoch": 7.228571428571429,
      "grad_norm": 0.000630508060567081,
      "learning_rate": 5.542857142857143e-06,
      "loss": 0.0,
      "step": 12650
    },
    {
      "epoch": 7.234285714285714,
      "grad_norm": 0.0013200734974816442,
      "learning_rate": 5.531428571428572e-06,
      "loss": 0.0,
      "step": 12660
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.0004430271510500461,
      "learning_rate": 5.5200000000000005e-06,
      "loss": 0.0,
      "step": 12670
    },
    {
      "epoch": 7.2457142857142856,
      "grad_norm": 0.003982097841799259,
      "learning_rate": 5.508571428571429e-06,
      "loss": 0.001,
      "step": 12680
    },
    {
      "epoch": 7.251428571428572,
      "grad_norm": 0.00021934449614491314,
      "learning_rate": 5.497142857142857e-06,
      "loss": 0.0003,
      "step": 12690
    },
    {
      "epoch": 7.257142857142857,
      "grad_norm": 0.0005039238603785634,
      "learning_rate": 5.485714285714287e-06,
      "loss": 0.0387,
      "step": 12700
    },
    {
      "epoch": 7.2628571428571425,
      "grad_norm": 0.0020412132143974304,
      "learning_rate": 5.474285714285714e-06,
      "loss": 0.0,
      "step": 12710
    },
    {
      "epoch": 7.268571428571429,
      "grad_norm": 0.001167781068943441,
      "learning_rate": 5.462857142857143e-06,
      "loss": 0.0,
      "step": 12720
    },
    {
      "epoch": 7.274285714285714,
      "grad_norm": 0.0005817419732920825,
      "learning_rate": 5.451428571428572e-06,
      "loss": 0.03,
      "step": 12730
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.0003226636035833508,
      "learning_rate": 5.4400000000000004e-06,
      "loss": 0.0,
      "step": 12740
    },
    {
      "epoch": 7.285714285714286,
      "grad_norm": 0.0010102131636813283,
      "learning_rate": 5.428571428571429e-06,
      "loss": 0.022,
      "step": 12750
    },
    {
      "epoch": 7.291428571428572,
      "grad_norm": 0.0004593977064359933,
      "learning_rate": 5.417142857142857e-06,
      "loss": 0.0,
      "step": 12760
    },
    {
      "epoch": 7.297142857142857,
      "grad_norm": 0.0003062203759327531,
      "learning_rate": 5.405714285714287e-06,
      "loss": 0.0,
      "step": 12770
    },
    {
      "epoch": 7.3028571428571425,
      "grad_norm": 0.10074464976787567,
      "learning_rate": 5.394285714285715e-06,
      "loss": 0.0,
      "step": 12780
    },
    {
      "epoch": 7.308571428571429,
      "grad_norm": 0.020292038097977638,
      "learning_rate": 5.382857142857143e-06,
      "loss": 0.0,
      "step": 12790
    },
    {
      "epoch": 7.314285714285714,
      "grad_norm": 0.00032605190062895417,
      "learning_rate": 5.371428571428572e-06,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.00015140810864977539,
      "learning_rate": 5.36e-06,
      "loss": 0.0,
      "step": 12810
    },
    {
      "epoch": 7.325714285714286,
      "grad_norm": 0.0002281214838149026,
      "learning_rate": 5.348571428571429e-06,
      "loss": 0.0,
      "step": 12820
    },
    {
      "epoch": 7.331428571428571,
      "grad_norm": 0.00021042194566689432,
      "learning_rate": 5.337142857142857e-06,
      "loss": 0.0101,
      "step": 12830
    },
    {
      "epoch": 7.337142857142857,
      "grad_norm": 0.006939187180250883,
      "learning_rate": 5.3257142857142865e-06,
      "loss": 0.0,
      "step": 12840
    },
    {
      "epoch": 7.3428571428571425,
      "grad_norm": 0.0018251261208206415,
      "learning_rate": 5.314285714285715e-06,
      "loss": 0.0,
      "step": 12850
    },
    {
      "epoch": 7.348571428571429,
      "grad_norm": 0.00019554767641238868,
      "learning_rate": 5.3028571428571425e-06,
      "loss": 0.0,
      "step": 12860
    },
    {
      "epoch": 7.354285714285714,
      "grad_norm": 0.04463537409901619,
      "learning_rate": 5.291428571428572e-06,
      "loss": 0.0,
      "step": 12870
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.0001901184004964307,
      "learning_rate": 5.28e-06,
      "loss": 0.0,
      "step": 12880
    },
    {
      "epoch": 7.365714285714286,
      "grad_norm": 31.528837203979492,
      "learning_rate": 5.268571428571429e-06,
      "loss": 0.0024,
      "step": 12890
    },
    {
      "epoch": 7.371428571428572,
      "grad_norm": 0.00026509896269999444,
      "learning_rate": 5.257142857142857e-06,
      "loss": 0.0001,
      "step": 12900
    },
    {
      "epoch": 7.377142857142857,
      "grad_norm": 0.0003047757491003722,
      "learning_rate": 5.2457142857142864e-06,
      "loss": 0.0,
      "step": 12910
    },
    {
      "epoch": 7.382857142857143,
      "grad_norm": 0.0022472869604825974,
      "learning_rate": 5.234285714285715e-06,
      "loss": 0.0,
      "step": 12920
    },
    {
      "epoch": 7.388571428571429,
      "grad_norm": 0.0005068889586254954,
      "learning_rate": 5.2228571428571425e-06,
      "loss": 0.0,
      "step": 12930
    },
    {
      "epoch": 7.394285714285714,
      "grad_norm": 0.0004550243611447513,
      "learning_rate": 5.211428571428572e-06,
      "loss": 0.0,
      "step": 12940
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.0002889490860980004,
      "learning_rate": 5.2e-06,
      "loss": 0.0,
      "step": 12950
    },
    {
      "epoch": 7.405714285714286,
      "grad_norm": 8.957645331975073e-05,
      "learning_rate": 5.1885714285714295e-06,
      "loss": 0.0295,
      "step": 12960
    },
    {
      "epoch": 7.411428571428571,
      "grad_norm": 0.0008738260949030519,
      "learning_rate": 5.177142857142857e-06,
      "loss": 0.0043,
      "step": 12970
    },
    {
      "epoch": 7.417142857142857,
      "grad_norm": 33.16351318359375,
      "learning_rate": 5.165714285714286e-06,
      "loss": 0.0198,
      "step": 12980
    },
    {
      "epoch": 7.422857142857143,
      "grad_norm": 0.25309067964553833,
      "learning_rate": 5.154285714285715e-06,
      "loss": 0.0001,
      "step": 12990
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 0.025135885924100876,
      "learning_rate": 5.142857142857142e-06,
      "loss": 0.0745,
      "step": 13000
    },
    {
      "epoch": 7.434285714285714,
      "grad_norm": 0.008259888738393784,
      "learning_rate": 5.131428571428572e-06,
      "loss": 0.0,
      "step": 13010
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.002499264432117343,
      "learning_rate": 5.12e-06,
      "loss": 0.0,
      "step": 13020
    },
    {
      "epoch": 7.445714285714286,
      "grad_norm": 0.0022578369826078415,
      "learning_rate": 5.108571428571429e-06,
      "loss": 0.0001,
      "step": 13030
    },
    {
      "epoch": 7.451428571428571,
      "grad_norm": 0.0024409086909145117,
      "learning_rate": 5.097142857142857e-06,
      "loss": 0.0,
      "step": 13040
    },
    {
      "epoch": 7.457142857142857,
      "grad_norm": 0.012578125111758709,
      "learning_rate": 5.085714285714286e-06,
      "loss": 0.0001,
      "step": 13050
    },
    {
      "epoch": 7.462857142857143,
      "grad_norm": 0.0007740905275568366,
      "learning_rate": 5.074285714285715e-06,
      "loss": 0.0,
      "step": 13060
    },
    {
      "epoch": 7.468571428571429,
      "grad_norm": 0.0006754416390322149,
      "learning_rate": 5.062857142857144e-06,
      "loss": 0.0,
      "step": 13070
    },
    {
      "epoch": 7.474285714285714,
      "grad_norm": 0.0008847956778481603,
      "learning_rate": 5.051428571428572e-06,
      "loss": 0.0001,
      "step": 13080
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.0013587470166385174,
      "learning_rate": 5.04e-06,
      "loss": 0.0178,
      "step": 13090
    },
    {
      "epoch": 7.485714285714286,
      "grad_norm": 0.00221481011249125,
      "learning_rate": 5.028571428571429e-06,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 7.491428571428571,
      "grad_norm": 0.0006168594700284302,
      "learning_rate": 5.017142857142857e-06,
      "loss": 0.0001,
      "step": 13110
    },
    {
      "epoch": 7.497142857142857,
      "grad_norm": 0.029689332470297813,
      "learning_rate": 5.005714285714286e-06,
      "loss": 0.0,
      "step": 13120
    },
    {
      "epoch": 7.502857142857143,
      "grad_norm": 0.03272891044616699,
      "learning_rate": 4.994285714285715e-06,
      "loss": 0.0002,
      "step": 13130
    },
    {
      "epoch": 7.508571428571429,
      "grad_norm": 0.008527718484401703,
      "learning_rate": 4.982857142857143e-06,
      "loss": 0.0001,
      "step": 13140
    },
    {
      "epoch": 7.514285714285714,
      "grad_norm": 0.0003728108131326735,
      "learning_rate": 4.971428571428572e-06,
      "loss": 0.0,
      "step": 13150
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.00013384262274485081,
      "learning_rate": 4.960000000000001e-06,
      "loss": 0.0,
      "step": 13160
    },
    {
      "epoch": 7.525714285714286,
      "grad_norm": 0.00017925145220942795,
      "learning_rate": 4.948571428571429e-06,
      "loss": 0.0,
      "step": 13170
    },
    {
      "epoch": 7.531428571428571,
      "grad_norm": 0.017928991466760635,
      "learning_rate": 4.937142857142858e-06,
      "loss": 0.0,
      "step": 13180
    },
    {
      "epoch": 7.537142857142857,
      "grad_norm": 0.0031037498265504837,
      "learning_rate": 4.925714285714286e-06,
      "loss": 0.0,
      "step": 13190
    },
    {
      "epoch": 7.542857142857143,
      "grad_norm": 0.0003323881537653506,
      "learning_rate": 4.9142857142857145e-06,
      "loss": 0.0049,
      "step": 13200
    },
    {
      "epoch": 7.548571428571429,
      "grad_norm": 0.0004457789473235607,
      "learning_rate": 4.902857142857143e-06,
      "loss": 0.0186,
      "step": 13210
    },
    {
      "epoch": 7.554285714285714,
      "grad_norm": 0.00035435750032775104,
      "learning_rate": 4.891428571428572e-06,
      "loss": 0.0,
      "step": 13220
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.00025150427245534956,
      "learning_rate": 4.880000000000001e-06,
      "loss": 0.0,
      "step": 13230
    },
    {
      "epoch": 7.565714285714286,
      "grad_norm": 0.0005330152343958616,
      "learning_rate": 4.868571428571429e-06,
      "loss": 0.0,
      "step": 13240
    },
    {
      "epoch": 7.571428571428571,
      "grad_norm": 7.032910346984863,
      "learning_rate": 4.857142857142858e-06,
      "loss": 0.0149,
      "step": 13250
    },
    {
      "epoch": 7.577142857142857,
      "grad_norm": 0.00021476228721439838,
      "learning_rate": 4.845714285714286e-06,
      "loss": 0.0,
      "step": 13260
    },
    {
      "epoch": 7.582857142857143,
      "grad_norm": 0.000160190713359043,
      "learning_rate": 4.8342857142857145e-06,
      "loss": 0.0,
      "step": 13270
    },
    {
      "epoch": 7.588571428571429,
      "grad_norm": 0.0004469228151720017,
      "learning_rate": 4.822857142857143e-06,
      "loss": 0.0,
      "step": 13280
    },
    {
      "epoch": 7.594285714285714,
      "grad_norm": 0.00045700499322265387,
      "learning_rate": 4.811428571428572e-06,
      "loss": 0.0011,
      "step": 13290
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.00015553961566183716,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 7.605714285714286,
      "grad_norm": 0.0003142052155453712,
      "learning_rate": 4.788571428571429e-06,
      "loss": 0.0,
      "step": 13310
    },
    {
      "epoch": 7.611428571428571,
      "grad_norm": 0.00014004617696627975,
      "learning_rate": 4.7771428571428575e-06,
      "loss": 0.0,
      "step": 13320
    },
    {
      "epoch": 7.617142857142857,
      "grad_norm": 0.00022877444280311465,
      "learning_rate": 4.765714285714286e-06,
      "loss": 0.0,
      "step": 13330
    },
    {
      "epoch": 7.622857142857143,
      "grad_norm": 0.00023736861476209015,
      "learning_rate": 4.754285714285714e-06,
      "loss": 0.0,
      "step": 13340
    },
    {
      "epoch": 7.628571428571428,
      "grad_norm": 0.011767533607780933,
      "learning_rate": 4.742857142857144e-06,
      "loss": 0.0,
      "step": 13350
    },
    {
      "epoch": 7.634285714285714,
      "grad_norm": 0.00011460565292509273,
      "learning_rate": 4.731428571428572e-06,
      "loss": 0.0,
      "step": 13360
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.00011020509555237368,
      "learning_rate": 4.7200000000000005e-06,
      "loss": 0.0,
      "step": 13370
    },
    {
      "epoch": 7.645714285714286,
      "grad_norm": 0.002127457642927766,
      "learning_rate": 4.708571428571429e-06,
      "loss": 0.0,
      "step": 13380
    },
    {
      "epoch": 7.651428571428571,
      "grad_norm": 0.00012604804942384362,
      "learning_rate": 4.6971428571428574e-06,
      "loss": 0.0,
      "step": 13390
    },
    {
      "epoch": 7.6571428571428575,
      "grad_norm": 9.93794747046195e-05,
      "learning_rate": 4.685714285714286e-06,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 7.662857142857143,
      "grad_norm": 0.00023020135995466262,
      "learning_rate": 4.674285714285714e-06,
      "loss": 0.0001,
      "step": 13410
    },
    {
      "epoch": 7.668571428571429,
      "grad_norm": 0.0005985107854939997,
      "learning_rate": 4.662857142857144e-06,
      "loss": 0.0,
      "step": 13420
    },
    {
      "epoch": 7.674285714285714,
      "grad_norm": 0.00017644806939642876,
      "learning_rate": 4.651428571428572e-06,
      "loss": 0.0,
      "step": 13430
    },
    {
      "epoch": 7.68,
      "grad_norm": 9.296343341702595e-05,
      "learning_rate": 4.6400000000000005e-06,
      "loss": 0.0,
      "step": 13440
    },
    {
      "epoch": 7.685714285714286,
      "grad_norm": 0.0001224489533342421,
      "learning_rate": 4.628571428571429e-06,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 7.691428571428571,
      "grad_norm": 9.663842502050102e-05,
      "learning_rate": 4.617142857142857e-06,
      "loss": 0.0,
      "step": 13460
    },
    {
      "epoch": 7.6971428571428575,
      "grad_norm": 0.0002187148784287274,
      "learning_rate": 4.605714285714286e-06,
      "loss": 0.0,
      "step": 13470
    },
    {
      "epoch": 7.702857142857143,
      "grad_norm": 0.02573978342115879,
      "learning_rate": 4.594285714285714e-06,
      "loss": 0.0025,
      "step": 13480
    },
    {
      "epoch": 7.708571428571428,
      "grad_norm": 0.00018454484234098345,
      "learning_rate": 4.5828571428571435e-06,
      "loss": 0.0,
      "step": 13490
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 0.002112374873831868,
      "learning_rate": 4.571428571428572e-06,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.0007682040450163186,
      "learning_rate": 4.56e-06,
      "loss": 0.0006,
      "step": 13510
    },
    {
      "epoch": 7.725714285714286,
      "grad_norm": 0.0002736618334893137,
      "learning_rate": 4.548571428571429e-06,
      "loss": 0.0,
      "step": 13520
    },
    {
      "epoch": 7.731428571428571,
      "grad_norm": 57.882991790771484,
      "learning_rate": 4.537142857142858e-06,
      "loss": 0.0324,
      "step": 13530
    },
    {
      "epoch": 7.737142857142857,
      "grad_norm": 0.00027120113372802734,
      "learning_rate": 4.525714285714286e-06,
      "loss": 0.0001,
      "step": 13540
    },
    {
      "epoch": 7.742857142857143,
      "grad_norm": 0.00018151296535506845,
      "learning_rate": 4.514285714285714e-06,
      "loss": 0.0,
      "step": 13550
    },
    {
      "epoch": 7.748571428571428,
      "grad_norm": 0.0058174156583845615,
      "learning_rate": 4.5028571428571434e-06,
      "loss": 0.0334,
      "step": 13560
    },
    {
      "epoch": 7.7542857142857144,
      "grad_norm": 0.0005192571552470326,
      "learning_rate": 4.491428571428572e-06,
      "loss": 0.0,
      "step": 13570
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.0013468447141349316,
      "learning_rate": 4.48e-06,
      "loss": 0.0,
      "step": 13580
    },
    {
      "epoch": 7.765714285714286,
      "grad_norm": 0.0009047170169651508,
      "learning_rate": 4.468571428571429e-06,
      "loss": 0.0001,
      "step": 13590
    },
    {
      "epoch": 7.771428571428571,
      "grad_norm": 0.01785757578909397,
      "learning_rate": 4.457142857142858e-06,
      "loss": 0.0,
      "step": 13600
    },
    {
      "epoch": 7.777142857142858,
      "grad_norm": 0.008714432828128338,
      "learning_rate": 4.445714285714286e-06,
      "loss": 0.0,
      "step": 13610
    },
    {
      "epoch": 7.782857142857143,
      "grad_norm": 2.227720022201538,
      "learning_rate": 4.434285714285715e-06,
      "loss": 0.0007,
      "step": 13620
    },
    {
      "epoch": 7.788571428571428,
      "grad_norm": 0.01581282541155815,
      "learning_rate": 4.422857142857143e-06,
      "loss": 0.0,
      "step": 13630
    },
    {
      "epoch": 7.7942857142857145,
      "grad_norm": 9.322136611444876e-05,
      "learning_rate": 4.411428571428572e-06,
      "loss": 0.0,
      "step": 13640
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.00013967066479381174,
      "learning_rate": 4.4e-06,
      "loss": 0.0024,
      "step": 13650
    },
    {
      "epoch": 7.805714285714286,
      "grad_norm": 9.280555241275579e-05,
      "learning_rate": 4.388571428571429e-06,
      "loss": 0.0,
      "step": 13660
    },
    {
      "epoch": 7.811428571428571,
      "grad_norm": 0.0007120296359062195,
      "learning_rate": 4.377142857142858e-06,
      "loss": 0.0,
      "step": 13670
    },
    {
      "epoch": 7.817142857142857,
      "grad_norm": 0.0002270643162773922,
      "learning_rate": 4.3657142857142855e-06,
      "loss": 0.0008,
      "step": 13680
    },
    {
      "epoch": 7.822857142857143,
      "grad_norm": 0.000957110314629972,
      "learning_rate": 4.354285714285715e-06,
      "loss": 0.0,
      "step": 13690
    },
    {
      "epoch": 7.828571428571428,
      "grad_norm": 0.000281676824670285,
      "learning_rate": 4.342857142857143e-06,
      "loss": 0.0,
      "step": 13700
    },
    {
      "epoch": 7.8342857142857145,
      "grad_norm": 0.02015131153166294,
      "learning_rate": 4.331428571428572e-06,
      "loss": 0.0528,
      "step": 13710
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.0010338688734918833,
      "learning_rate": 4.32e-06,
      "loss": 0.0,
      "step": 13720
    },
    {
      "epoch": 7.845714285714286,
      "grad_norm": 0.001681468216702342,
      "learning_rate": 4.3085714285714294e-06,
      "loss": 0.0,
      "step": 13730
    },
    {
      "epoch": 7.851428571428571,
      "grad_norm": 0.0002382544189458713,
      "learning_rate": 4.297142857142858e-06,
      "loss": 0.0147,
      "step": 13740
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.0008261508774012327,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 0.0,
      "step": 13750
    },
    {
      "epoch": 7.862857142857143,
      "grad_norm": 0.0010656958911567926,
      "learning_rate": 4.274285714285715e-06,
      "loss": 0.0001,
      "step": 13760
    },
    {
      "epoch": 7.868571428571428,
      "grad_norm": 0.015769824385643005,
      "learning_rate": 4.262857142857143e-06,
      "loss": 0.0,
      "step": 13770
    },
    {
      "epoch": 7.8742857142857146,
      "grad_norm": 0.00039533741073682904,
      "learning_rate": 4.251428571428572e-06,
      "loss": 0.0,
      "step": 13780
    },
    {
      "epoch": 7.88,
      "grad_norm": 0.0003908018406946212,
      "learning_rate": 4.24e-06,
      "loss": 0.002,
      "step": 13790
    },
    {
      "epoch": 7.885714285714286,
      "grad_norm": 0.001157050603069365,
      "learning_rate": 4.228571428571429e-06,
      "loss": 0.0,
      "step": 13800
    },
    {
      "epoch": 7.8914285714285715,
      "grad_norm": 0.00017380200733896345,
      "learning_rate": 4.217142857142858e-06,
      "loss": 0.0157,
      "step": 13810
    },
    {
      "epoch": 7.897142857142857,
      "grad_norm": 0.00030416485969908535,
      "learning_rate": 4.205714285714286e-06,
      "loss": 0.0061,
      "step": 13820
    },
    {
      "epoch": 7.902857142857143,
      "grad_norm": 0.0004714141832664609,
      "learning_rate": 4.194285714285715e-06,
      "loss": 0.0,
      "step": 13830
    },
    {
      "epoch": 7.908571428571428,
      "grad_norm": 0.0002502184361219406,
      "learning_rate": 4.182857142857143e-06,
      "loss": 0.0005,
      "step": 13840
    },
    {
      "epoch": 7.914285714285715,
      "grad_norm": 0.00027326244162395597,
      "learning_rate": 4.1714285714285715e-06,
      "loss": 0.0003,
      "step": 13850
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.00013094700989313424,
      "learning_rate": 4.16e-06,
      "loss": 0.0,
      "step": 13860
    },
    {
      "epoch": 7.925714285714285,
      "grad_norm": 0.0005358212511055171,
      "learning_rate": 4.148571428571429e-06,
      "loss": 0.0,
      "step": 13870
    },
    {
      "epoch": 7.9314285714285715,
      "grad_norm": 0.000228390796110034,
      "learning_rate": 4.137142857142858e-06,
      "loss": 0.0,
      "step": 13880
    },
    {
      "epoch": 7.937142857142857,
      "grad_norm": 0.0005903037963435054,
      "learning_rate": 4.125714285714286e-06,
      "loss": 0.0,
      "step": 13890
    },
    {
      "epoch": 7.942857142857143,
      "grad_norm": 0.00029029467259533703,
      "learning_rate": 4.114285714285715e-06,
      "loss": 0.0,
      "step": 13900
    },
    {
      "epoch": 7.948571428571428,
      "grad_norm": 0.00021570900571532547,
      "learning_rate": 4.102857142857143e-06,
      "loss": 0.0,
      "step": 13910
    },
    {
      "epoch": 7.954285714285715,
      "grad_norm": 0.003190062940120697,
      "learning_rate": 4.0914285714285715e-06,
      "loss": 0.0,
      "step": 13920
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.00091454794164747,
      "learning_rate": 4.08e-06,
      "loss": 0.0505,
      "step": 13930
    },
    {
      "epoch": 7.965714285714286,
      "grad_norm": 0.326305627822876,
      "learning_rate": 4.068571428571429e-06,
      "loss": 0.0001,
      "step": 13940
    },
    {
      "epoch": 7.9714285714285715,
      "grad_norm": 0.0015250492142513394,
      "learning_rate": 4.057142857142858e-06,
      "loss": 0.0,
      "step": 13950
    },
    {
      "epoch": 7.977142857142857,
      "grad_norm": 0.0001719909196253866,
      "learning_rate": 4.045714285714286e-06,
      "loss": 0.0,
      "step": 13960
    },
    {
      "epoch": 7.982857142857143,
      "grad_norm": 0.00035957287764176726,
      "learning_rate": 4.0342857142857145e-06,
      "loss": 0.0,
      "step": 13970
    },
    {
      "epoch": 7.988571428571428,
      "grad_norm": 0.0004388849774841219,
      "learning_rate": 4.022857142857143e-06,
      "loss": 0.0,
      "step": 13980
    },
    {
      "epoch": 7.994285714285715,
      "grad_norm": 8.306921517942101e-05,
      "learning_rate": 4.011428571428571e-06,
      "loss": 0.0,
      "step": 13990
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.00019186797726433724,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9931483957219251,
      "eval_f1": 0.9602327837051406,
      "eval_loss": 0.06117987632751465,
      "eval_precision": 0.9611650485436893,
      "eval_recall": 0.9593023255813954,
      "eval_runtime": 51.3317,
      "eval_samples_per_second": 116.887,
      "eval_steps_per_second": 3.662,
      "step": 14000
    }
  ],
  "logging_steps": 10,
  "max_steps": 17500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.762196830639456e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
